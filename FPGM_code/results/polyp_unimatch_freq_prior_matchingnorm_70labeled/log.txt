[00:51:40.257] Namespace(config='/home/wth/My_codes/SSL_MIS_Exps/Freq_adaptive_modulation/configs/kvasir.yaml', labeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/5%_labeled.txt', unlabeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/5%_unlabeled.txt', save_path='/home/wth/My_codes/SSL_MIS_Exps/models/KVASIR', seed=1337, deterministic=1, local_rank=0, port=None)
[00:51:43.780] iteration 1: loss: 0.748287, loss_s1: 0.074569, loss_fp: 0.144312, loss_freq: 0.056687
[00:51:44.443] iteration 2: loss: 0.925813, loss_s1: 0.354121, loss_fp: 0.018907, loss_freq: 0.338020
[00:51:45.051] iteration 3: loss: 1.269010, loss_s1: 0.510687, loss_fp: 0.502542, loss_freq: 0.509022
[00:51:45.664] iteration 4: loss: 1.221565, loss_s1: 0.505696, loss_fp: 0.500261, loss_freq: 0.505048
[00:51:46.304] iteration 5: loss: 1.165187, loss_s1: 0.506756, loss_fp: 0.501037, loss_freq: 0.506300
[00:51:46.911] iteration 6: loss: 1.164590, loss_s1: 0.504287, loss_fp: 0.503608, loss_freq: 0.504793
[00:51:47.520] iteration 7: loss: 1.125607, loss_s1: 0.500791, loss_fp: 0.501251, loss_freq: 0.503738
[00:51:48.128] iteration 8: loss: 1.081053, loss_s1: 0.500635, loss_fp: 0.500822, loss_freq: 0.502229
[00:51:48.740] iteration 9: loss: 1.072008, loss_s1: 0.500386, loss_fp: 0.501116, loss_freq: 0.501031
[00:51:49.351] iteration 10: loss: 1.085596, loss_s1: 0.500762, loss_fp: 0.502102, loss_freq: 0.500781
[00:51:49.960] iteration 11: loss: 1.081935, loss_s1: 0.500820, loss_fp: 0.500803, loss_freq: 0.501157
[00:51:50.577] iteration 12: loss: 1.136450, loss_s1: 0.500391, loss_fp: 0.500424, loss_freq: 0.500674
[00:51:51.184] iteration 13: loss: 1.091927, loss_s1: 0.501384, loss_fp: 0.500806, loss_freq: 0.501043
[00:51:51.792] iteration 14: loss: 1.072158, loss_s1: 0.500402, loss_fp: 0.500807, loss_freq: 0.500539
[00:51:52.394] iteration 15: loss: 1.090540, loss_s1: 0.500815, loss_fp: 0.500545, loss_freq: 0.501131
[00:51:53.013] iteration 16: loss: 1.046466, loss_s1: 0.500856, loss_fp: 0.501105, loss_freq: 0.500707
[00:51:53.626] iteration 17: loss: 1.095175, loss_s1: 0.500679, loss_fp: 0.500210, loss_freq: 0.500639
[00:51:54.240] iteration 18: loss: 1.047324, loss_s1: 0.500778, loss_fp: 0.500127, loss_freq: 0.500553
[00:51:54.851] iteration 19: loss: 1.072485, loss_s1: 0.500455, loss_fp: 0.500178, loss_freq: 0.500920
[00:51:55.471] iteration 20: loss: 1.084715, loss_s1: 0.501024, loss_fp: 0.500408, loss_freq: 0.501478
[00:51:56.097] iteration 21: loss: 1.085503, loss_s1: 0.501755, loss_fp: 0.500292, loss_freq: 0.502262
[00:51:56.714] iteration 22: loss: 1.081921, loss_s1: 0.501325, loss_fp: 0.500270, loss_freq: 0.501211
[00:51:57.335] iteration 23: loss: 1.072772, loss_s1: 0.500442, loss_fp: 0.500267, loss_freq: 0.500894
[00:51:57.954] iteration 24: loss: 1.052685, loss_s1: 0.501620, loss_fp: 0.500330, loss_freq: 0.501562
[00:51:58.574] iteration 25: loss: 1.052766, loss_s1: 0.502383, loss_fp: 0.500282, loss_freq: 0.501369
[00:51:59.184] iteration 26: loss: 1.080689, loss_s1: 0.500221, loss_fp: 0.500299, loss_freq: 0.500855
[00:51:59.800] iteration 27: loss: 1.058513, loss_s1: 0.500416, loss_fp: 0.500140, loss_freq: 0.500621
[00:52:00.417] iteration 28: loss: 1.061751, loss_s1: 0.500859, loss_fp: 0.500308, loss_freq: 0.501453
[00:52:01.032] iteration 29: loss: 1.083485, loss_s1: 0.500377, loss_fp: 0.500059, loss_freq: 0.500939
[00:52:01.644] iteration 30: loss: 1.088242, loss_s1: 0.501293, loss_fp: 0.500194, loss_freq: 0.501254
[00:52:02.255] iteration 31: loss: 1.030857, loss_s1: 0.501230, loss_fp: 0.500118, loss_freq: 0.500806
[00:52:02.864] iteration 32: loss: 1.101002, loss_s1: 0.501739, loss_fp: 0.500525, loss_freq: 0.500642
[00:52:03.473] iteration 33: loss: 1.025360, loss_s1: 0.501874, loss_fp: 0.500243, loss_freq: 0.500970
[00:52:04.118] iteration 34: loss: 1.060494, loss_s1: 0.502944, loss_fp: 0.500150, loss_freq: 0.501776
[00:52:04.983] iteration 35: loss: 1.071654, loss_s1: 0.500479, loss_fp: 0.500069, loss_freq: 0.500657
[00:52:05.758] iteration 36: loss: 1.046677, loss_s1: 0.500842, loss_fp: 0.500436, loss_freq: 0.500481
[00:52:06.483] iteration 37: loss: 1.055897, loss_s1: 0.500430, loss_fp: 0.500154, loss_freq: 0.500634
[00:52:07.137] iteration 38: loss: 1.106745, loss_s1: 0.500897, loss_fp: 0.500122, loss_freq: 0.500743
[00:52:07.745] iteration 39: loss: 1.125354, loss_s1: 0.501110, loss_fp: 0.500199, loss_freq: 0.500616
[00:52:08.360] iteration 40: loss: 1.021668, loss_s1: 0.501553, loss_fp: 0.500095, loss_freq: 0.501560
[00:52:08.967] iteration 41: loss: 1.054860, loss_s1: 0.502853, loss_fp: 0.500280, loss_freq: 0.501002
[00:52:09.586] iteration 42: loss: 1.045247, loss_s1: 0.501088, loss_fp: 0.500135, loss_freq: 0.500861
[00:52:10.196] iteration 43: loss: 1.041744, loss_s1: 0.500246, loss_fp: 0.500407, loss_freq: 0.501110
[00:52:10.802] iteration 44: loss: 1.040529, loss_s1: 0.501507, loss_fp: 0.500239, loss_freq: 0.501578
[00:52:11.416] iteration 45: loss: 1.040266, loss_s1: 0.500327, loss_fp: 0.500058, loss_freq: 0.500967
[00:52:12.035] iteration 46: loss: 1.083674, loss_s1: 0.501105, loss_fp: 0.501031, loss_freq: 0.501521
[00:52:12.655] iteration 47: loss: 1.115213, loss_s1: 0.502506, loss_fp: 0.500257, loss_freq: 0.502346
[00:52:13.267] iteration 48: loss: 1.068974, loss_s1: 0.501751, loss_fp: 0.500140, loss_freq: 0.501985
[00:52:13.884] iteration 49: loss: 1.021841, loss_s1: 0.500903, loss_fp: 0.500381, loss_freq: 0.501318
[00:52:14.503] iteration 50: loss: 1.055358, loss_s1: 0.501359, loss_fp: 0.500669, loss_freq: 0.501451
[00:52:15.126] iteration 51: loss: 1.024094, loss_s1: 0.501118, loss_fp: 0.500390, loss_freq: 0.500483
[00:52:15.739] iteration 52: loss: 1.066869, loss_s1: 0.500278, loss_fp: 0.500154, loss_freq: 0.500504
[00:52:16.355] iteration 53: loss: 1.047369, loss_s1: 0.500959, loss_fp: 0.500197, loss_freq: 0.500858
[00:52:16.964] iteration 54: loss: 1.053963, loss_s1: 0.500730, loss_fp: 0.500173, loss_freq: 0.500546
[00:52:17.574] iteration 55: loss: 1.099248, loss_s1: 0.503016, loss_fp: 0.500462, loss_freq: 0.501522
[00:52:18.195] iteration 56: loss: 1.069755, loss_s1: 0.501293, loss_fp: 0.500248, loss_freq: 0.500992
[00:52:18.818] iteration 57: loss: 1.066457, loss_s1: 0.500386, loss_fp: 0.500141, loss_freq: 0.500528
[00:52:19.437] iteration 58: loss: 1.038802, loss_s1: 0.500854, loss_fp: 0.500090, loss_freq: 0.500627
[00:52:20.053] iteration 59: loss: 1.034979, loss_s1: 0.501812, loss_fp: 0.500758, loss_freq: 0.500931
[00:52:20.667] iteration 60: loss: 1.037051, loss_s1: 0.501399, loss_fp: 0.500206, loss_freq: 0.500599
[00:52:21.283] iteration 61: loss: 1.079041, loss_s1: 0.500617, loss_fp: 0.500258, loss_freq: 0.500556
[00:52:21.897] iteration 62: loss: 1.056877, loss_s1: 0.500487, loss_fp: 0.500213, loss_freq: 0.500656
[00:52:22.516] iteration 63: loss: 1.046900, loss_s1: 0.503015, loss_fp: 0.501081, loss_freq: 0.500788
[00:52:23.156] iteration 64: loss: 1.093793, loss_s1: 0.502114, loss_fp: 0.500821, loss_freq: 0.500931
[00:52:23.770] iteration 65: loss: 1.070774, loss_s1: 0.501229, loss_fp: 0.500015, loss_freq: 0.500756
[00:52:24.386] iteration 66: loss: 1.021323, loss_s1: 0.502101, loss_fp: 0.500571, loss_freq: 0.501212
[00:52:24.999] iteration 67: loss: 1.064553, loss_s1: 0.501775, loss_fp: 0.500310, loss_freq: 0.501018
[00:52:25.610] iteration 68: loss: 1.019747, loss_s1: 0.501303, loss_fp: 0.500441, loss_freq: 0.501209
[00:52:26.217] iteration 69: loss: 1.039880, loss_s1: 0.505034, loss_fp: 0.500315, loss_freq: 0.501633
[00:52:26.822] iteration 70: loss: 1.060377, loss_s1: 0.501336, loss_fp: 0.500375, loss_freq: 0.500839
[00:52:27.431] iteration 71: loss: 1.043701, loss_s1: 0.502395, loss_fp: 0.500132, loss_freq: 0.500721
[00:52:28.040] iteration 72: loss: 1.044418, loss_s1: 0.501015, loss_fp: 0.500461, loss_freq: 0.501249
[00:52:28.646] iteration 73: loss: 1.098756, loss_s1: 0.501705, loss_fp: 0.501153, loss_freq: 0.502530
[00:52:29.253] iteration 74: loss: 1.060099, loss_s1: 0.501082, loss_fp: 0.502079, loss_freq: 0.500939
[00:52:29.865] iteration 75: loss: 1.016200, loss_s1: 0.500929, loss_fp: 0.500213, loss_freq: 0.501260
[00:52:30.494] iteration 76: loss: 1.024776, loss_s1: 0.501957, loss_fp: 0.500255, loss_freq: 0.501102
[00:52:31.125] iteration 77: loss: 1.049462, loss_s1: 0.502297, loss_fp: 0.500585, loss_freq: 0.501069
[00:52:31.746] iteration 78: loss: 1.082105, loss_s1: 0.502436, loss_fp: 0.500358, loss_freq: 0.501197
[00:52:32.372] iteration 79: loss: 1.031076, loss_s1: 0.501965, loss_fp: 0.500275, loss_freq: 0.500749
[00:52:33.005] iteration 80: loss: 1.036600, loss_s1: 0.501975, loss_fp: 0.500440, loss_freq: 0.501527
[00:52:33.633] iteration 81: loss: 1.067945, loss_s1: 0.502027, loss_fp: 0.500375, loss_freq: 0.501258
[00:52:34.319] iteration 82: loss: 1.082120, loss_s1: 0.501288, loss_fp: 0.500350, loss_freq: 0.501417
[00:52:34.985] iteration 83: loss: 1.089360, loss_s1: 0.503183, loss_fp: 0.500825, loss_freq: 0.501574
[00:52:35.616] iteration 84: loss: 1.012334, loss_s1: 0.501817, loss_fp: 0.500671, loss_freq: 0.500470
[00:52:36.248] iteration 85: loss: 1.062403, loss_s1: 0.501160, loss_fp: 0.500083, loss_freq: 0.500714
[00:52:36.866] iteration 86: loss: 1.036594, loss_s1: 0.501916, loss_fp: 0.500702, loss_freq: 0.500938
[00:52:37.475] iteration 87: loss: 1.058867, loss_s1: 0.502173, loss_fp: 0.500564, loss_freq: 0.500472
[00:52:38.081] iteration 88: loss: 1.034771, loss_s1: 0.501803, loss_fp: 0.500185, loss_freq: 0.500789
[00:52:38.693] iteration 89: loss: 1.035702, loss_s1: 0.501933, loss_fp: 0.500212, loss_freq: 0.501276
[00:52:39.295] iteration 90: loss: 1.097132, loss_s1: 0.501811, loss_fp: 0.500296, loss_freq: 0.501266
[00:52:39.900] iteration 91: loss: 1.057810, loss_s1: 0.501370, loss_fp: 0.500387, loss_freq: 0.500504
[00:52:40.498] iteration 92: loss: 1.046264, loss_s1: 0.501380, loss_fp: 0.500159, loss_freq: 0.501257
[00:52:41.103] iteration 93: loss: 1.023397, loss_s1: 0.501329, loss_fp: 0.500076, loss_freq: 0.500690
[00:52:41.705] iteration 94: loss: 1.013162, loss_s1: 0.500643, loss_fp: 0.500074, loss_freq: 0.501144
[00:52:42.309] iteration 95: loss: 1.035546, loss_s1: 0.500753, loss_fp: 0.500153, loss_freq: 0.500498
[00:52:42.963] iteration 96: loss: 1.054829, loss_s1: 0.500914, loss_fp: 0.500274, loss_freq: 0.500879
[00:52:43.587] iteration 97: loss: 1.044841, loss_s1: 0.500546, loss_fp: 0.500780, loss_freq: 0.500577
[00:52:44.215] iteration 98: loss: 1.033375, loss_s1: 0.501742, loss_fp: 0.500018, loss_freq: 0.500757
[00:52:44.835] iteration 99: loss: 1.073470, loss_s1: 0.500434, loss_fp: 0.500224, loss_freq: 0.500716
[00:52:45.441] iteration 100: loss: 1.052180, loss_s1: 0.500800, loss_fp: 0.500126, loss_freq: 0.500947
[00:52:46.050] iteration 101: loss: 0.995255, loss_s1: 0.500526, loss_fp: 0.500070, loss_freq: 0.500727
[00:52:46.652] iteration 102: loss: 1.049617, loss_s1: 0.502082, loss_fp: 0.500659, loss_freq: 0.501179
[00:52:47.254] iteration 103: loss: 1.013904, loss_s1: 0.503942, loss_fp: 0.500114, loss_freq: 0.500911
[00:52:47.861] iteration 104: loss: 1.033293, loss_s1: 0.503482, loss_fp: 0.500512, loss_freq: 0.502053
[00:52:48.474] iteration 105: loss: 1.050370, loss_s1: 0.503008, loss_fp: 0.500514, loss_freq: 0.501433
[00:52:49.081] iteration 106: loss: 1.017011, loss_s1: 0.501671, loss_fp: 0.500642, loss_freq: 0.501328
[00:52:49.694] iteration 107: loss: 1.027638, loss_s1: 0.502287, loss_fp: 0.500557, loss_freq: 0.501190
[00:52:50.303] iteration 108: loss: 1.105473, loss_s1: 0.503304, loss_fp: 0.500710, loss_freq: 0.502174
[00:52:50.912] iteration 109: loss: 1.051791, loss_s1: 0.503596, loss_fp: 0.500332, loss_freq: 0.502408
[00:52:51.526] iteration 110: loss: 1.000817, loss_s1: 0.501092, loss_fp: 0.500224, loss_freq: 0.500986
[00:52:52.138] iteration 111: loss: 1.005076, loss_s1: 0.501765, loss_fp: 0.500122, loss_freq: 0.501613
[00:52:52.754] iteration 112: loss: 1.030507, loss_s1: 0.505055, loss_fp: 0.500383, loss_freq: 0.501024
[00:52:53.361] iteration 113: loss: 1.057685, loss_s1: 0.502403, loss_fp: 0.500580, loss_freq: 0.500686
[00:52:54.016] iteration 114: loss: 1.016453, loss_s1: 0.504299, loss_fp: 0.500609, loss_freq: 0.501365
[00:52:54.641] iteration 115: loss: 1.035556, loss_s1: 0.504162, loss_fp: 0.500320, loss_freq: 0.503467
[00:52:55.271] iteration 116: loss: 1.063106, loss_s1: 0.503161, loss_fp: 0.500374, loss_freq: 0.501108
[00:52:55.891] iteration 117: loss: 1.065771, loss_s1: 0.502467, loss_fp: 0.500082, loss_freq: 0.502042
[00:52:56.515] iteration 118: loss: 1.050811, loss_s1: 0.503252, loss_fp: 0.500177, loss_freq: 0.501417
[00:52:57.135] iteration 119: loss: 1.002933, loss_s1: 0.501098, loss_fp: 0.500330, loss_freq: 0.501361
[00:52:57.759] iteration 120: loss: 1.011255, loss_s1: 0.502907, loss_fp: 0.500289, loss_freq: 0.502605
[00:52:58.378] iteration 121: loss: 1.012403, loss_s1: 0.501616, loss_fp: 0.500360, loss_freq: 0.501270
[00:52:58.999] iteration 122: loss: 1.032839, loss_s1: 0.500265, loss_fp: 0.500152, loss_freq: 0.500393
[00:52:59.620] iteration 123: loss: 1.031436, loss_s1: 0.500963, loss_fp: 0.500205, loss_freq: 0.501516
[00:53:00.233] iteration 124: loss: 1.007247, loss_s1: 0.502385, loss_fp: 0.500122, loss_freq: 0.500760
[00:53:00.860] iteration 125: loss: 1.099861, loss_s1: 0.500877, loss_fp: 0.500061, loss_freq: 0.501127
[00:53:01.476] iteration 126: loss: 1.036565, loss_s1: 0.503344, loss_fp: 0.500159, loss_freq: 0.502755
[00:53:02.098] iteration 127: loss: 1.022093, loss_s1: 0.500509, loss_fp: 0.500136, loss_freq: 0.501669
[00:53:02.715] iteration 128: loss: 1.025476, loss_s1: 0.500629, loss_fp: 0.500316, loss_freq: 0.502068
[00:53:03.335] iteration 129: loss: 1.003641, loss_s1: 0.501344, loss_fp: 0.500441, loss_freq: 0.500788
[00:53:03.958] iteration 130: loss: 1.021892, loss_s1: 0.501127, loss_fp: 0.500194, loss_freq: 0.501779
[00:53:04.586] iteration 131: loss: 1.027097, loss_s1: 0.501169, loss_fp: 0.500159, loss_freq: 0.501352
[00:53:05.215] iteration 132: loss: 1.056818, loss_s1: 0.501593, loss_fp: 0.500086, loss_freq: 0.500856
[00:53:05.833] iteration 133: loss: 1.023711, loss_s1: 0.502228, loss_fp: 0.500441, loss_freq: 0.501931
[00:53:06.457] iteration 134: loss: 1.085743, loss_s1: 0.501647, loss_fp: 0.500499, loss_freq: 0.501090
[00:53:07.080] iteration 135: loss: 1.051316, loss_s1: 0.502325, loss_fp: 0.500106, loss_freq: 0.500686
[00:53:07.694] iteration 136: loss: 0.972532, loss_s1: 0.501721, loss_fp: 0.500302, loss_freq: 0.500810
[00:53:08.315] iteration 137: loss: 1.038391, loss_s1: 0.501181, loss_fp: 0.500099, loss_freq: 0.502195
[00:53:08.931] iteration 138: loss: 1.006341, loss_s1: 0.503117, loss_fp: 0.500234, loss_freq: 0.501513
[00:53:09.557] iteration 139: loss: 1.048165, loss_s1: 0.501252, loss_fp: 0.500192, loss_freq: 0.500740
[00:53:10.164] iteration 140: loss: 1.029387, loss_s1: 0.500875, loss_fp: 0.500186, loss_freq: 0.500421
[00:53:10.778] iteration 141: loss: 1.020873, loss_s1: 0.501711, loss_fp: 0.500272, loss_freq: 0.501350
[00:53:11.384] iteration 142: loss: 1.033282, loss_s1: 0.503459, loss_fp: 0.500156, loss_freq: 0.501198
[00:53:11.994] iteration 143: loss: 1.076139, loss_s1: 0.503136, loss_fp: 0.500167, loss_freq: 0.501250
[00:53:12.604] iteration 144: loss: 1.040976, loss_s1: 0.504705, loss_fp: 0.500432, loss_freq: 0.500679
[00:53:13.214] iteration 145: loss: 1.001170, loss_s1: 0.501747, loss_fp: 0.500265, loss_freq: 0.500674
[00:53:13.825] iteration 146: loss: 0.989442, loss_s1: 0.501125, loss_fp: 0.500265, loss_freq: 0.500858
[00:53:14.430] iteration 147: loss: 1.029419, loss_s1: 0.503412, loss_fp: 0.500134, loss_freq: 0.500650
[00:53:15.044] iteration 148: loss: 1.022141, loss_s1: 0.501813, loss_fp: 0.500437, loss_freq: 0.500384
[00:53:15.649] iteration 149: loss: 1.002264, loss_s1: 0.502989, loss_fp: 0.500504, loss_freq: 0.501647
[00:53:16.309] iteration 150: loss: 1.015649, loss_s1: 0.500979, loss_fp: 0.500236, loss_freq: 0.501058
[00:53:16.939] iteration 151: loss: 1.051603, loss_s1: 0.502327, loss_fp: 0.500272, loss_freq: 0.501578
[00:53:17.573] iteration 152: loss: 1.075141, loss_s1: 0.502188, loss_fp: 0.500204, loss_freq: 0.501200
[00:53:18.203] iteration 153: loss: 1.020010, loss_s1: 0.500675, loss_fp: 0.500127, loss_freq: 0.502759
[00:53:18.830] iteration 154: loss: 0.990400, loss_s1: 0.501137, loss_fp: 0.500140, loss_freq: 0.500956
[00:53:19.473] iteration 155: loss: 1.006239, loss_s1: 0.501182, loss_fp: 0.500121, loss_freq: 0.500774
[00:53:20.090] iteration 156: loss: 1.001834, loss_s1: 0.502428, loss_fp: 0.500121, loss_freq: 0.500866
[00:53:20.697] iteration 157: loss: 1.048942, loss_s1: 0.503816, loss_fp: 0.500207, loss_freq: 0.501434
[00:53:21.298] iteration 158: loss: 1.017822, loss_s1: 0.502294, loss_fp: 0.500079, loss_freq: 0.500823
[00:53:21.906] iteration 159: loss: 0.989607, loss_s1: 0.501804, loss_fp: 0.500174, loss_freq: 0.501574
[00:53:22.513] iteration 160: loss: 1.063342, loss_s1: 0.502572, loss_fp: 0.500204, loss_freq: 0.500690
[00:53:23.118] iteration 161: loss: 1.018471, loss_s1: 0.503147, loss_fp: 0.500078, loss_freq: 0.501437
[00:53:23.731] iteration 162: loss: 1.021397, loss_s1: 0.502937, loss_fp: 0.500103, loss_freq: 0.501064
[00:53:24.341] iteration 163: loss: 1.014800, loss_s1: 0.501736, loss_fp: 0.500189, loss_freq: 0.500963
[00:53:24.952] iteration 164: loss: 0.999637, loss_s1: 0.500472, loss_fp: 0.500164, loss_freq: 0.500698
[00:53:25.564] iteration 165: loss: 1.024851, loss_s1: 0.501880, loss_fp: 0.500380, loss_freq: 0.500879
[00:53:26.179] iteration 166: loss: 1.012163, loss_s1: 0.502658, loss_fp: 0.500110, loss_freq: 0.500604
[00:53:26.785] iteration 167: loss: 1.030453, loss_s1: 0.502026, loss_fp: 0.500935, loss_freq: 0.500715
[00:53:27.394] iteration 168: loss: 1.004435, loss_s1: 0.503730, loss_fp: 0.500152, loss_freq: 0.501632
[00:53:27.996] iteration 169: loss: 1.072604, loss_s1: 0.501765, loss_fp: 0.500177, loss_freq: 0.500792
[00:53:28.598] iteration 170: loss: 1.024686, loss_s1: 0.505520, loss_fp: 0.500183, loss_freq: 0.500602
[00:53:29.557] iteration 171: loss: 1.015407, loss_s1: 0.503204, loss_fp: 0.500275, loss_freq: 0.501585
[00:53:30.182] iteration 172: loss: 1.006916, loss_s1: 0.504397, loss_fp: 0.500123, loss_freq: 0.500825
[00:53:30.794] iteration 173: loss: 1.078135, loss_s1: 0.502302, loss_fp: 0.500181, loss_freq: 0.501556
[00:53:31.405] iteration 174: loss: 1.014855, loss_s1: 0.504080, loss_fp: 0.500340, loss_freq: 0.500550
[00:53:32.043] iteration 175: loss: 0.985422, loss_s1: 0.503068, loss_fp: 0.500145, loss_freq: 0.500543
[00:53:32.649] iteration 176: loss: 1.000329, loss_s1: 0.501649, loss_fp: 0.500221, loss_freq: 0.500383
[00:53:33.261] iteration 177: loss: 1.001279, loss_s1: 0.501637, loss_fp: 0.500108, loss_freq: 0.500936
[00:53:33.871] iteration 178: loss: 1.092587, loss_s1: 0.503152, loss_fp: 0.500111, loss_freq: 0.500553
[00:53:34.476] iteration 179: loss: 1.013353, loss_s1: 0.501906, loss_fp: 0.500049, loss_freq: 0.500244
[00:53:35.079] iteration 180: loss: 1.031784, loss_s1: 0.501525, loss_fp: 0.500092, loss_freq: 0.500676
[00:53:35.684] iteration 181: loss: 1.035982, loss_s1: 0.501476, loss_fp: 0.500419, loss_freq: 0.501138
[00:53:36.295] iteration 182: loss: 1.029341, loss_s1: 0.502341, loss_fp: 0.500209, loss_freq: 0.501006
[00:53:36.903] iteration 183: loss: 1.017359, loss_s1: 0.502255, loss_fp: 0.500365, loss_freq: 0.501072
[00:53:37.506] iteration 184: loss: 1.014094, loss_s1: 0.502655, loss_fp: 0.500300, loss_freq: 0.501106
[00:53:38.118] iteration 185: loss: 1.029632, loss_s1: 0.505208, loss_fp: 0.500672, loss_freq: 0.501198
[00:53:38.727] iteration 186: loss: 1.054429, loss_s1: 0.502025, loss_fp: 0.500159, loss_freq: 0.500325
[00:53:39.324] iteration 187: loss: 1.022201, loss_s1: 0.503022, loss_fp: 0.500208, loss_freq: 0.500398
[00:53:39.931] iteration 188: loss: 1.058481, loss_s1: 0.501781, loss_fp: 0.500329, loss_freq: 0.500425
[00:53:40.533] iteration 189: loss: 0.979437, loss_s1: 0.500659, loss_fp: 0.500167, loss_freq: 0.500399
[00:53:41.139] iteration 190: loss: 1.067171, loss_s1: 0.501028, loss_fp: 0.500297, loss_freq: 0.501101
[00:53:41.747] iteration 191: loss: 1.013006, loss_s1: 0.501186, loss_fp: 0.500103, loss_freq: 0.501515
[00:53:42.357] iteration 192: loss: 1.021607, loss_s1: 0.501342, loss_fp: 0.500324, loss_freq: 0.500562
[00:53:42.963] iteration 193: loss: 1.038994, loss_s1: 0.501321, loss_fp: 0.500158, loss_freq: 0.500303
[00:53:43.568] iteration 194: loss: 0.986362, loss_s1: 0.501001, loss_fp: 0.500203, loss_freq: 0.500789
[00:53:44.180] iteration 195: loss: 1.009326, loss_s1: 0.500882, loss_fp: 0.500287, loss_freq: 0.500511
[00:53:44.783] iteration 196: loss: 1.024229, loss_s1: 0.501353, loss_fp: 0.500080, loss_freq: 0.500278
[00:53:45.396] iteration 197: loss: 0.993215, loss_s1: 0.500798, loss_fp: 0.500129, loss_freq: 0.500297
[00:53:46.012] iteration 198: loss: 0.998412, loss_s1: 0.500824, loss_fp: 0.500154, loss_freq: 0.501613
[00:53:46.619] iteration 199: loss: 1.055048, loss_s1: 0.500500, loss_fp: 0.500184, loss_freq: 0.501282
[00:53:47.231] iteration 200: loss: 1.060309, loss_s1: 0.501445, loss_fp: 0.500341, loss_freq: 0.501801
[00:53:50.110] iteration 200 : mean_dice : 0.063436
[00:53:50.803] iteration 201: loss: 0.967860, loss_s1: 0.500970, loss_fp: 0.500625, loss_freq: 0.500501
[00:53:51.443] iteration 202: loss: 1.047230, loss_s1: 0.508380, loss_fp: 0.500192, loss_freq: 0.501569
[00:53:52.055] iteration 203: loss: 1.008868, loss_s1: 0.504086, loss_fp: 0.500095, loss_freq: 0.501170
[00:53:52.679] iteration 204: loss: 1.065110, loss_s1: 0.505501, loss_fp: 0.500108, loss_freq: 0.502911
[00:53:53.309] iteration 205: loss: 1.019480, loss_s1: 0.502547, loss_fp: 0.500172, loss_freq: 0.501516
[00:53:53.953] iteration 206: loss: 0.999331, loss_s1: 0.502394, loss_fp: 0.500063, loss_freq: 0.500529
[00:53:54.557] iteration 207: loss: 1.006817, loss_s1: 0.502147, loss_fp: 0.500682, loss_freq: 0.501207
[00:53:55.164] iteration 208: loss: 1.093940, loss_s1: 0.505434, loss_fp: 0.500043, loss_freq: 0.500196
[00:53:55.770] iteration 209: loss: 1.037652, loss_s1: 0.501296, loss_fp: 0.500315, loss_freq: 0.500643
[00:53:56.380] iteration 210: loss: 0.989263, loss_s1: 0.501644, loss_fp: 0.500531, loss_freq: 0.501030
[00:53:56.991] iteration 211: loss: 0.978685, loss_s1: 0.503178, loss_fp: 0.500522, loss_freq: 0.501050
[00:53:57.600] iteration 212: loss: 0.997192, loss_s1: 0.501977, loss_fp: 0.500117, loss_freq: 0.500798
[00:53:58.206] iteration 213: loss: 1.018380, loss_s1: 0.501261, loss_fp: 0.500320, loss_freq: 0.500733
[00:53:58.817] iteration 214: loss: 0.977816, loss_s1: 0.501853, loss_fp: 0.502605, loss_freq: 0.500762
[00:53:59.430] iteration 215: loss: 0.991004, loss_s1: 0.500759, loss_fp: 0.500435, loss_freq: 0.500762
[00:54:00.039] iteration 216: loss: 1.027975, loss_s1: 0.501067, loss_fp: 0.501961, loss_freq: 0.502889
[00:54:00.646] iteration 217: loss: 1.078917, loss_s1: 0.501304, loss_fp: 0.500223, loss_freq: 0.501694
[00:54:01.257] iteration 218: loss: 1.010502, loss_s1: 0.503061, loss_fp: 0.500136, loss_freq: 0.501850
[00:54:01.867] iteration 219: loss: 0.983300, loss_s1: 0.501141, loss_fp: 0.500528, loss_freq: 0.500950
[00:54:02.476] iteration 220: loss: 1.008928, loss_s1: 0.505768, loss_fp: 0.500297, loss_freq: 0.501929
[00:54:03.084] iteration 221: loss: 1.018747, loss_s1: 0.502150, loss_fp: 0.500185, loss_freq: 0.501196
[00:54:03.860] iteration 222: loss: 0.964450, loss_s1: 0.502844, loss_fp: 0.500144, loss_freq: 0.501872
[00:54:04.555] iteration 223: loss: 1.015024, loss_s1: 0.503456, loss_fp: 0.500331, loss_freq: 0.501573
[00:54:05.331] iteration 224: loss: 0.988660, loss_s1: 0.502139, loss_fp: 0.500152, loss_freq: 0.500594
[00:54:06.052] iteration 225: loss: 1.086709, loss_s1: 0.507661, loss_fp: 0.500386, loss_freq: 0.502012
[00:54:06.728] iteration 226: loss: 1.033865, loss_s1: 0.504841, loss_fp: 0.500224, loss_freq: 0.502290
[00:54:07.474] iteration 227: loss: 0.980778, loss_s1: 0.505389, loss_fp: 0.500584, loss_freq: 0.501454
[00:54:08.175] iteration 228: loss: 1.012654, loss_s1: 0.504072, loss_fp: 0.500221, loss_freq: 0.501469
[00:54:08.862] iteration 229: loss: 0.992440, loss_s1: 0.503622, loss_fp: 0.500293, loss_freq: 0.500602
[00:54:09.701] iteration 230: loss: 0.993999, loss_s1: 0.505488, loss_fp: 0.500972, loss_freq: 0.500706
[00:54:10.573] iteration 231: loss: 1.053886, loss_s1: 0.505452, loss_fp: 0.500162, loss_freq: 0.500442
[00:54:11.348] iteration 232: loss: 1.061165, loss_s1: 0.504739, loss_fp: 0.500156, loss_freq: 0.500520
[00:54:12.262] iteration 233: loss: 1.012619, loss_s1: 0.505053, loss_fp: 0.500489, loss_freq: 0.500419
[00:54:13.007] iteration 234: loss: 1.073925, loss_s1: 0.504377, loss_fp: 0.500297, loss_freq: 0.500458
[00:54:13.745] iteration 235: loss: 1.030739, loss_s1: 0.504630, loss_fp: 0.500185, loss_freq: 0.500226
[00:54:14.384] iteration 236: loss: 0.967869, loss_s1: 0.501871, loss_fp: 0.500312, loss_freq: 0.500562
[00:54:15.025] iteration 237: loss: 1.037686, loss_s1: 0.505867, loss_fp: 0.500198, loss_freq: 0.500429
[00:54:15.660] iteration 238: loss: 1.007357, loss_s1: 0.508969, loss_fp: 0.500048, loss_freq: 0.500411
[00:54:16.285] iteration 239: loss: 1.036512, loss_s1: 0.502394, loss_fp: 0.500099, loss_freq: 0.500479
[00:54:16.911] iteration 240: loss: 1.029673, loss_s1: 0.501819, loss_fp: 0.500572, loss_freq: 0.500682
[00:54:17.531] iteration 241: loss: 1.014268, loss_s1: 0.504450, loss_fp: 0.500202, loss_freq: 0.500487
[00:54:18.155] iteration 242: loss: 0.992088, loss_s1: 0.501199, loss_fp: 0.500253, loss_freq: 0.500747
[00:54:18.781] iteration 243: loss: 1.058172, loss_s1: 0.505004, loss_fp: 0.500124, loss_freq: 0.501834
[00:54:19.400] iteration 244: loss: 0.993228, loss_s1: 0.501374, loss_fp: 0.500195, loss_freq: 0.501186
[00:54:20.028] iteration 245: loss: 1.009999, loss_s1: 0.502054, loss_fp: 0.500147, loss_freq: 0.502114
[00:54:20.653] iteration 246: loss: 0.978639, loss_s1: 0.501622, loss_fp: 0.500275, loss_freq: 0.500638
[00:54:21.334] iteration 247: loss: 0.995259, loss_s1: 0.500887, loss_fp: 0.500340, loss_freq: 0.500704
[00:54:21.961] iteration 248: loss: 1.070155, loss_s1: 0.500799, loss_fp: 0.500252, loss_freq: 0.500378
[00:54:22.627] iteration 249: loss: 0.999710, loss_s1: 0.501137, loss_fp: 0.500067, loss_freq: 0.500299
[00:54:23.259] iteration 250: loss: 1.036154, loss_s1: 0.501219, loss_fp: 0.500320, loss_freq: 0.500400
[00:54:23.877] iteration 251: loss: 1.020619, loss_s1: 0.501529, loss_fp: 0.500225, loss_freq: 0.500336
[00:54:24.492] iteration 252: loss: 1.046390, loss_s1: 0.500810, loss_fp: 0.500801, loss_freq: 0.500613
[00:54:25.112] iteration 253: loss: 1.029004, loss_s1: 0.501147, loss_fp: 0.500191, loss_freq: 0.500619
[00:54:25.725] iteration 254: loss: 1.017353, loss_s1: 0.500953, loss_fp: 0.500314, loss_freq: 0.500707
[00:54:26.342] iteration 255: loss: 1.011204, loss_s1: 0.504083, loss_fp: 0.500136, loss_freq: 0.501183
[00:54:26.955] iteration 256: loss: 1.004596, loss_s1: 0.503883, loss_fp: 0.501109, loss_freq: 0.500317
[00:54:27.574] iteration 257: loss: 0.986817, loss_s1: 0.504906, loss_fp: 0.500360, loss_freq: 0.500253
[00:54:28.189] iteration 258: loss: 1.025724, loss_s1: 0.500309, loss_fp: 0.500146, loss_freq: 0.500344
[00:54:28.803] iteration 259: loss: 0.964643, loss_s1: 0.501370, loss_fp: 0.500200, loss_freq: 0.500697
[00:54:29.418] iteration 260: loss: 1.112592, loss_s1: 0.504682, loss_fp: 0.500111, loss_freq: 0.501040
[00:54:30.036] iteration 261: loss: 1.036432, loss_s1: 0.502329, loss_fp: 0.500294, loss_freq: 0.500817
[00:54:30.653] iteration 262: loss: 0.974228, loss_s1: 0.504349, loss_fp: 0.500276, loss_freq: 0.501724
[00:54:31.465] iteration 263: loss: 1.009317, loss_s1: 0.504400, loss_fp: 0.500055, loss_freq: 0.500226
[00:54:32.456] iteration 264: loss: 0.966928, loss_s1: 0.502333, loss_fp: 0.500228, loss_freq: 0.500568
[00:54:33.308] iteration 265: loss: 0.996971, loss_s1: 0.500596, loss_fp: 0.500070, loss_freq: 0.500204
[00:54:34.003] iteration 266: loss: 1.026775, loss_s1: 0.501863, loss_fp: 0.500097, loss_freq: 0.500184
[00:54:34.638] iteration 267: loss: 1.047223, loss_s1: 0.506371, loss_fp: 0.500173, loss_freq: 0.500342
[00:54:35.256] iteration 268: loss: 1.001114, loss_s1: 0.504537, loss_fp: 0.500315, loss_freq: 0.500623
[00:54:35.879] iteration 269: loss: 1.067265, loss_s1: 0.500636, loss_fp: 0.500157, loss_freq: 0.500154
[00:54:36.505] iteration 270: loss: 1.036873, loss_s1: 0.502134, loss_fp: 0.500599, loss_freq: 0.500519
[00:54:37.179] iteration 271: loss: 0.998872, loss_s1: 0.501311, loss_fp: 0.500692, loss_freq: 0.500574
[00:54:37.840] iteration 272: loss: 1.012311, loss_s1: 0.501212, loss_fp: 0.500291, loss_freq: 0.500549
[00:54:38.506] iteration 273: loss: 0.975437, loss_s1: 0.502917, loss_fp: 0.500085, loss_freq: 0.500152
[00:54:39.166] iteration 274: loss: 1.022911, loss_s1: 0.503214, loss_fp: 0.500127, loss_freq: 0.500380
[00:54:39.835] iteration 275: loss: 1.009361, loss_s1: 0.500590, loss_fp: 0.500108, loss_freq: 0.500679
[00:54:40.463] iteration 276: loss: 0.979808, loss_s1: 0.501557, loss_fp: 0.500119, loss_freq: 0.501005
[00:54:41.094] iteration 277: loss: 0.982664, loss_s1: 0.501367, loss_fp: 0.500119, loss_freq: 0.500555
[00:54:41.722] iteration 278: loss: 1.041991, loss_s1: 0.503478, loss_fp: 0.500114, loss_freq: 0.501490
[00:54:42.355] iteration 279: loss: 1.006086, loss_s1: 0.501740, loss_fp: 0.500142, loss_freq: 0.500378
[00:54:42.982] iteration 280: loss: 1.005940, loss_s1: 0.500883, loss_fp: 0.500247, loss_freq: 0.500295
[00:54:43.700] iteration 281: loss: 0.991202, loss_s1: 0.501672, loss_fp: 0.500133, loss_freq: 0.500649
[00:54:44.397] iteration 282: loss: 0.984499, loss_s1: 0.502084, loss_fp: 0.500133, loss_freq: 0.500704
[00:54:45.069] iteration 283: loss: 1.015754, loss_s1: 0.503454, loss_fp: 0.500187, loss_freq: 0.500130
[00:54:45.733] iteration 284: loss: 0.995064, loss_s1: 0.503856, loss_fp: 0.500280, loss_freq: 0.500318
[00:54:46.452] iteration 285: loss: 1.008524, loss_s1: 0.504861, loss_fp: 0.500214, loss_freq: 0.502043
[00:54:47.091] iteration 286: loss: 1.006855, loss_s1: 0.502952, loss_fp: 0.500217, loss_freq: 0.501102
[00:54:47.778] iteration 287: loss: 1.009003, loss_s1: 0.502056, loss_fp: 0.500234, loss_freq: 0.500655
[00:54:48.433] iteration 288: loss: 1.026217, loss_s1: 0.501265, loss_fp: 0.500077, loss_freq: 0.500697
[00:54:49.109] iteration 289: loss: 0.968255, loss_s1: 0.504016, loss_fp: 0.500890, loss_freq: 0.503104
[00:54:49.920] iteration 290: loss: 0.966799, loss_s1: 0.504440, loss_fp: 0.500419, loss_freq: 0.502275
[00:54:50.673] iteration 291: loss: 1.003033, loss_s1: 0.503978, loss_fp: 0.500230, loss_freq: 0.500367
[00:54:51.345] iteration 292: loss: 0.988765, loss_s1: 0.502800, loss_fp: 0.500240, loss_freq: 0.501035
[00:54:52.101] iteration 293: loss: 0.962491, loss_s1: 0.501622, loss_fp: 0.500382, loss_freq: 0.501507
[00:54:52.754] iteration 294: loss: 0.958182, loss_s1: 0.501810, loss_fp: 0.500275, loss_freq: 0.500937
[00:54:53.590] iteration 295: loss: 1.005774, loss_s1: 0.502007, loss_fp: 0.500282, loss_freq: 0.500979
[00:54:54.301] iteration 296: loss: 1.008588, loss_s1: 0.503561, loss_fp: 0.500202, loss_freq: 0.500548
[00:54:55.047] iteration 297: loss: 0.993469, loss_s1: 0.503046, loss_fp: 0.500559, loss_freq: 0.502350
[00:54:55.667] iteration 298: loss: 0.994287, loss_s1: 0.503976, loss_fp: 0.500131, loss_freq: 0.501529
[00:54:56.286] iteration 299: loss: 0.937364, loss_s1: 0.503474, loss_fp: 0.500348, loss_freq: 0.500462
[00:54:56.903] iteration 300: loss: 0.981516, loss_s1: 0.503910, loss_fp: 0.500203, loss_freq: 0.501713
[00:54:57.525] iteration 301: loss: 1.005084, loss_s1: 0.503797, loss_fp: 0.500750, loss_freq: 0.501094
[00:54:58.151] iteration 302: loss: 1.007820, loss_s1: 0.504284, loss_fp: 0.500417, loss_freq: 0.500684
[00:54:58.782] iteration 303: loss: 0.979537, loss_s1: 0.502238, loss_fp: 0.500326, loss_freq: 0.501107
[00:54:59.413] iteration 304: loss: 1.062195, loss_s1: 0.508315, loss_fp: 0.500374, loss_freq: 0.500955
[00:55:00.065] iteration 305: loss: 1.056906, loss_s1: 0.502336, loss_fp: 0.500486, loss_freq: 0.500639
[00:55:00.712] iteration 306: loss: 0.923131, loss_s1: 0.504311, loss_fp: 0.500238, loss_freq: 0.501850
[00:55:01.362] iteration 307: loss: 1.012115, loss_s1: 0.504379, loss_fp: 0.500536, loss_freq: 0.501518
[00:55:02.009] iteration 308: loss: 0.965023, loss_s1: 0.502160, loss_fp: 0.500241, loss_freq: 0.500627
[00:55:02.630] iteration 309: loss: 0.994263, loss_s1: 0.502678, loss_fp: 0.500228, loss_freq: 0.500744
[00:55:03.248] iteration 310: loss: 0.990188, loss_s1: 0.503926, loss_fp: 0.500230, loss_freq: 0.500456
[00:55:03.860] iteration 311: loss: 1.013485, loss_s1: 0.502808, loss_fp: 0.500109, loss_freq: 0.500786
[00:55:04.477] iteration 312: loss: 0.977958, loss_s1: 0.504121, loss_fp: 0.500072, loss_freq: 0.501392
[00:55:05.100] iteration 313: loss: 1.004050, loss_s1: 0.502981, loss_fp: 0.500120, loss_freq: 0.500732
[00:55:05.727] iteration 314: loss: 0.990174, loss_s1: 0.505146, loss_fp: 0.500621, loss_freq: 0.500732
[00:55:06.341] iteration 315: loss: 1.001371, loss_s1: 0.504184, loss_fp: 0.500099, loss_freq: 0.501407
[00:55:06.955] iteration 316: loss: 0.994199, loss_s1: 0.502105, loss_fp: 0.500355, loss_freq: 0.500876
[00:55:07.569] iteration 317: loss: 0.989748, loss_s1: 0.502004, loss_fp: 0.500201, loss_freq: 0.500474
[00:55:08.327] iteration 318: loss: 1.004163, loss_s1: 0.505994, loss_fp: 0.500122, loss_freq: 0.500484
[00:55:09.167] iteration 319: loss: 1.028749, loss_s1: 0.502651, loss_fp: 0.500094, loss_freq: 0.500327
[00:55:09.968] iteration 320: loss: 0.991410, loss_s1: 0.501021, loss_fp: 0.500100, loss_freq: 0.500516
[00:55:10.640] iteration 321: loss: 1.049608, loss_s1: 0.511078, loss_fp: 0.500070, loss_freq: 0.502091
[00:55:11.310] iteration 322: loss: 1.019133, loss_s1: 0.504586, loss_fp: 0.500124, loss_freq: 0.501479
[00:55:11.924] iteration 323: loss: 1.001966, loss_s1: 0.504055, loss_fp: 0.500070, loss_freq: 0.502037
[00:55:12.542] iteration 324: loss: 0.973384, loss_s1: 0.505527, loss_fp: 0.500246, loss_freq: 0.500668
[00:55:13.158] iteration 325: loss: 0.964493, loss_s1: 0.503749, loss_fp: 0.500128, loss_freq: 0.501468
[00:55:13.773] iteration 326: loss: 1.007905, loss_s1: 0.502206, loss_fp: 0.500096, loss_freq: 0.500866
[00:55:14.388] iteration 327: loss: 0.997035, loss_s1: 0.509295, loss_fp: 0.500167, loss_freq: 0.501062
[00:55:15.006] iteration 328: loss: 0.975915, loss_s1: 0.504719, loss_fp: 0.500221, loss_freq: 0.500400
[00:55:15.636] iteration 329: loss: 0.990919, loss_s1: 0.502459, loss_fp: 0.500202, loss_freq: 0.501805
[00:55:16.252] iteration 330: loss: 1.019668, loss_s1: 0.503280, loss_fp: 0.500703, loss_freq: 0.500351
[00:55:16.868] iteration 331: loss: 0.999873, loss_s1: 0.502808, loss_fp: 0.500710, loss_freq: 0.500409
[00:55:17.485] iteration 332: loss: 0.966654, loss_s1: 0.503655, loss_fp: 0.501353, loss_freq: 0.501006
[00:55:18.109] iteration 333: loss: 1.050174, loss_s1: 0.502559, loss_fp: 0.500352, loss_freq: 0.500830
[00:55:18.727] iteration 334: loss: 0.964033, loss_s1: 0.503865, loss_fp: 0.500242, loss_freq: 0.500658
[00:55:19.345] iteration 335: loss: 0.997589, loss_s1: 0.502820, loss_fp: 0.500914, loss_freq: 0.500363
[00:55:19.975] iteration 336: loss: 1.020856, loss_s1: 0.508615, loss_fp: 0.500104, loss_freq: 0.500426
[00:55:20.593] iteration 337: loss: 0.991024, loss_s1: 0.505401, loss_fp: 0.500329, loss_freq: 0.500515
[00:55:21.215] iteration 338: loss: 0.959160, loss_s1: 0.504455, loss_fp: 0.500391, loss_freq: 0.500984
[00:55:21.829] iteration 339: loss: 1.048500, loss_s1: 0.502321, loss_fp: 0.501551, loss_freq: 0.500575
[00:55:22.444] iteration 340: loss: 1.004448, loss_s1: 0.506102, loss_fp: 0.500350, loss_freq: 0.501365
[00:55:23.483] iteration 341: loss: 0.961080, loss_s1: 0.504000, loss_fp: 0.500492, loss_freq: 0.501168
[00:55:24.135] iteration 342: loss: 0.954250, loss_s1: 0.502885, loss_fp: 0.500189, loss_freq: 0.500517
[00:55:24.788] iteration 343: loss: 1.046225, loss_s1: 0.503042, loss_fp: 0.500378, loss_freq: 0.500366
[00:55:25.439] iteration 344: loss: 0.992206, loss_s1: 0.502433, loss_fp: 0.500579, loss_freq: 0.501110
[00:55:26.103] iteration 345: loss: 1.003399, loss_s1: 0.501697, loss_fp: 0.500602, loss_freq: 0.500609
[00:55:26.751] iteration 346: loss: 0.973386, loss_s1: 0.503455, loss_fp: 0.500430, loss_freq: 0.500280
[00:55:27.396] iteration 347: loss: 0.982347, loss_s1: 0.505658, loss_fp: 0.500421, loss_freq: 0.500513
[00:55:28.012] iteration 348: loss: 0.994406, loss_s1: 0.502725, loss_fp: 0.500164, loss_freq: 0.500492
[00:55:28.623] iteration 349: loss: 0.976462, loss_s1: 0.506115, loss_fp: 0.500271, loss_freq: 0.500561
[00:55:29.233] iteration 350: loss: 0.958239, loss_s1: 0.506430, loss_fp: 0.500289, loss_freq: 0.500767
[00:55:29.847] iteration 351: loss: 0.995428, loss_s1: 0.507613, loss_fp: 0.500368, loss_freq: 0.503226
[00:55:30.461] iteration 352: loss: 1.016333, loss_s1: 0.508214, loss_fp: 0.500161, loss_freq: 0.501375
[00:55:31.077] iteration 353: loss: 1.006908, loss_s1: 0.506296, loss_fp: 0.500162, loss_freq: 0.501434
[00:55:31.733] iteration 354: loss: 0.956423, loss_s1: 0.502588, loss_fp: 0.500303, loss_freq: 0.500804
[00:55:32.383] iteration 355: loss: 0.999500, loss_s1: 0.503163, loss_fp: 0.500405, loss_freq: 0.500916
[00:55:33.031] iteration 356: loss: 0.964545, loss_s1: 0.505001, loss_fp: 0.500063, loss_freq: 0.500578
[00:55:33.672] iteration 357: loss: 0.968769, loss_s1: 0.501822, loss_fp: 0.500639, loss_freq: 0.500307
[00:55:34.285] iteration 358: loss: 0.967460, loss_s1: 0.503217, loss_fp: 0.500253, loss_freq: 0.500685
[00:55:34.944] iteration 359: loss: 0.949634, loss_s1: 0.503935, loss_fp: 0.500321, loss_freq: 0.500382
[00:55:35.568] iteration 360: loss: 0.987533, loss_s1: 0.501672, loss_fp: 0.500075, loss_freq: 0.501006
[00:55:36.192] iteration 361: loss: 0.975277, loss_s1: 0.503246, loss_fp: 0.500374, loss_freq: 0.502123
[00:55:36.827] iteration 362: loss: 0.987809, loss_s1: 0.502060, loss_fp: 0.500060, loss_freq: 0.502791
[00:55:37.446] iteration 363: loss: 1.034213, loss_s1: 0.504474, loss_fp: 0.500264, loss_freq: 0.500587
[00:55:38.076] iteration 364: loss: 0.918615, loss_s1: 0.503786, loss_fp: 0.500227, loss_freq: 0.502088
[00:55:38.704] iteration 365: loss: 0.976843, loss_s1: 0.505994, loss_fp: 0.500171, loss_freq: 0.500627
[00:55:39.326] iteration 366: loss: 0.975298, loss_s1: 0.504927, loss_fp: 0.500472, loss_freq: 0.500902
[00:55:39.946] iteration 367: loss: 0.948734, loss_s1: 0.507140, loss_fp: 0.500183, loss_freq: 0.500737
[00:55:40.574] iteration 368: loss: 0.959098, loss_s1: 0.506730, loss_fp: 0.500223, loss_freq: 0.502334
[00:55:41.198] iteration 369: loss: 1.072287, loss_s1: 0.506311, loss_fp: 0.500524, loss_freq: 0.501946
[00:55:41.819] iteration 370: loss: 0.994662, loss_s1: 0.507717, loss_fp: 0.500858, loss_freq: 0.501819
[00:55:42.448] iteration 371: loss: 0.907287, loss_s1: 0.502648, loss_fp: 0.500106, loss_freq: 0.500758
[00:55:43.071] iteration 372: loss: 0.987886, loss_s1: 0.503622, loss_fp: 0.500059, loss_freq: 0.500695
[00:55:43.698] iteration 373: loss: 0.978660, loss_s1: 0.506773, loss_fp: 0.500122, loss_freq: 0.500761
[00:55:44.322] iteration 374: loss: 1.017613, loss_s1: 0.506991, loss_fp: 0.500292, loss_freq: 0.502916
[00:55:44.943] iteration 375: loss: 1.015719, loss_s1: 0.503280, loss_fp: 0.500369, loss_freq: 0.500520
[00:55:45.562] iteration 376: loss: 0.960757, loss_s1: 0.505588, loss_fp: 0.500088, loss_freq: 0.500384
[00:55:46.184] iteration 377: loss: 0.948416, loss_s1: 0.501711, loss_fp: 0.500353, loss_freq: 0.501035
[00:55:46.801] iteration 378: loss: 1.017292, loss_s1: 0.503626, loss_fp: 0.500065, loss_freq: 0.500249
[00:55:47.425] iteration 379: loss: 0.949988, loss_s1: 0.503786, loss_fp: 0.500589, loss_freq: 0.500334
[00:55:48.041] iteration 380: loss: 0.982577, loss_s1: 0.505830, loss_fp: 0.500115, loss_freq: 0.501268
[00:55:48.655] iteration 381: loss: 0.967873, loss_s1: 0.505411, loss_fp: 0.500696, loss_freq: 0.501433
[00:55:49.267] iteration 382: loss: 0.970330, loss_s1: 0.505297, loss_fp: 0.500298, loss_freq: 0.500579
[00:55:49.884] iteration 383: loss: 0.993429, loss_s1: 0.503598, loss_fp: 0.500161, loss_freq: 0.500541
[00:55:50.496] iteration 384: loss: 0.959101, loss_s1: 0.503218, loss_fp: 0.500271, loss_freq: 0.500495
[00:55:51.109] iteration 385: loss: 0.954271, loss_s1: 0.503964, loss_fp: 0.500234, loss_freq: 0.500637
[00:55:51.726] iteration 386: loss: 0.980311, loss_s1: 0.503442, loss_fp: 0.500262, loss_freq: 0.501865
[00:55:52.345] iteration 387: loss: 1.021162, loss_s1: 0.505611, loss_fp: 0.500198, loss_freq: 0.500495
[00:55:52.959] iteration 388: loss: 0.963284, loss_s1: 0.504239, loss_fp: 0.500171, loss_freq: 0.501485
[00:55:53.595] iteration 389: loss: 0.963813, loss_s1: 0.502115, loss_fp: 0.500398, loss_freq: 0.501032
[00:55:54.217] iteration 390: loss: 0.980314, loss_s1: 0.504681, loss_fp: 0.500182, loss_freq: 0.501452
[00:55:54.843] iteration 391: loss: 0.982276, loss_s1: 0.503601, loss_fp: 0.500032, loss_freq: 0.500857
[00:55:55.469] iteration 392: loss: 0.975885, loss_s1: 0.508615, loss_fp: 0.500154, loss_freq: 0.500446
[00:55:56.087] iteration 393: loss: 0.986006, loss_s1: 0.505548, loss_fp: 0.500068, loss_freq: 0.501472
[00:55:56.710] iteration 394: loss: 0.953312, loss_s1: 0.508760, loss_fp: 0.500177, loss_freq: 0.500371
[00:55:57.335] iteration 395: loss: 1.008554, loss_s1: 0.504127, loss_fp: 0.500062, loss_freq: 0.500936
[00:55:57.959] iteration 396: loss: 0.982605, loss_s1: 0.502180, loss_fp: 0.500124, loss_freq: 0.500916
[00:55:58.650] iteration 397: loss: 0.958634, loss_s1: 0.503897, loss_fp: 0.500600, loss_freq: 0.500378
[00:55:59.356] iteration 398: loss: 1.028479, loss_s1: 0.504264, loss_fp: 0.500339, loss_freq: 0.502054
[00:56:00.032] iteration 399: loss: 0.965069, loss_s1: 0.503333, loss_fp: 0.500321, loss_freq: 0.500713
[00:56:00.763] iteration 400: loss: 0.960836, loss_s1: 0.503450, loss_fp: 0.500543, loss_freq: 0.500621
[00:56:02.964] iteration 400 : mean_dice : 0.019708
[00:56:03.690] iteration 401: loss: 0.980379, loss_s1: 0.507740, loss_fp: 0.500269, loss_freq: 0.500396
[00:56:04.321] iteration 402: loss: 0.948233, loss_s1: 0.501682, loss_fp: 0.500210, loss_freq: 0.500365
[00:56:04.964] iteration 403: loss: 0.947435, loss_s1: 0.502097, loss_fp: 0.500389, loss_freq: 0.500489
[00:56:05.578] iteration 404: loss: 1.002962, loss_s1: 0.501645, loss_fp: 0.500331, loss_freq: 0.500203
[00:56:06.206] iteration 405: loss: 1.056020, loss_s1: 0.503832, loss_fp: 0.500406, loss_freq: 0.500687
[00:56:06.821] iteration 406: loss: 0.923724, loss_s1: 0.507863, loss_fp: 0.501172, loss_freq: 0.500689
[00:56:07.437] iteration 407: loss: 1.007464, loss_s1: 0.504119, loss_fp: 0.500150, loss_freq: 0.500379
[00:56:08.073] iteration 408: loss: 0.967973, loss_s1: 0.501321, loss_fp: 0.500119, loss_freq: 0.500150
[00:56:08.684] iteration 409: loss: 0.963753, loss_s1: 0.501268, loss_fp: 0.500375, loss_freq: 0.500341
[00:56:09.300] iteration 410: loss: 0.985022, loss_s1: 0.502299, loss_fp: 0.500251, loss_freq: 0.500232
[00:56:09.921] iteration 411: loss: 0.963563, loss_s1: 0.501533, loss_fp: 0.500287, loss_freq: 0.500565
[00:56:10.535] iteration 412: loss: 0.955628, loss_s1: 0.503577, loss_fp: 0.500116, loss_freq: 0.500214
[00:56:11.149] iteration 413: loss: 0.998830, loss_s1: 0.503919, loss_fp: 0.500189, loss_freq: 0.500855
[00:56:11.771] iteration 414: loss: 0.981583, loss_s1: 0.508158, loss_fp: 0.500175, loss_freq: 0.501623
[00:56:12.388] iteration 415: loss: 0.973318, loss_s1: 0.511411, loss_fp: 0.500127, loss_freq: 0.500696
[00:56:13.002] iteration 416: loss: 0.960455, loss_s1: 0.503818, loss_fp: 0.500047, loss_freq: 0.500557
[00:56:13.615] iteration 417: loss: 0.977041, loss_s1: 0.505750, loss_fp: 0.500343, loss_freq: 0.500512
[00:56:14.231] iteration 418: loss: 0.968563, loss_s1: 0.503961, loss_fp: 0.500202, loss_freq: 0.500457
[00:56:14.856] iteration 419: loss: 0.940781, loss_s1: 0.506727, loss_fp: 0.500502, loss_freq: 0.500407
[00:56:15.481] iteration 420: loss: 0.983658, loss_s1: 0.503713, loss_fp: 0.500133, loss_freq: 0.500692
[00:56:16.122] iteration 421: loss: 0.928724, loss_s1: 0.503234, loss_fp: 0.500368, loss_freq: 0.500846
[00:56:16.757] iteration 422: loss: 0.996754, loss_s1: 0.505505, loss_fp: 0.500242, loss_freq: 0.501218
[00:56:17.381] iteration 423: loss: 0.986220, loss_s1: 0.504609, loss_fp: 0.500218, loss_freq: 0.500397
[00:56:18.024] iteration 424: loss: 0.959606, loss_s1: 0.500595, loss_fp: 0.500149, loss_freq: 0.500833
[00:56:18.684] iteration 425: loss: 0.987580, loss_s1: 0.502846, loss_fp: 0.500181, loss_freq: 0.500902
[00:56:19.300] iteration 426: loss: 0.981534, loss_s1: 0.501753, loss_fp: 0.500119, loss_freq: 0.500707
[00:56:19.917] iteration 427: loss: 0.949699, loss_s1: 0.503888, loss_fp: 0.500154, loss_freq: 0.500256
[00:56:20.529] iteration 428: loss: 0.973691, loss_s1: 0.503892, loss_fp: 0.500184, loss_freq: 0.501087
[00:56:21.141] iteration 429: loss: 0.977783, loss_s1: 0.506749, loss_fp: 0.500267, loss_freq: 0.501164
[00:56:21.773] iteration 430: loss: 0.996488, loss_s1: 0.505726, loss_fp: 0.500570, loss_freq: 0.501690
[00:56:22.389] iteration 431: loss: 0.959472, loss_s1: 0.505790, loss_fp: 0.500150, loss_freq: 0.501850
[00:56:23.006] iteration 432: loss: 0.953676, loss_s1: 0.502838, loss_fp: 0.500154, loss_freq: 0.501131
[00:56:23.628] iteration 433: loss: 0.996284, loss_s1: 0.506879, loss_fp: 0.500215, loss_freq: 0.502262
[00:56:24.244] iteration 434: loss: 0.936944, loss_s1: 0.507277, loss_fp: 0.500136, loss_freq: 0.501277
[00:56:24.866] iteration 435: loss: 0.928562, loss_s1: 0.501794, loss_fp: 0.500537, loss_freq: 0.501201
[00:56:25.488] iteration 436: loss: 0.976873, loss_s1: 0.507045, loss_fp: 0.500075, loss_freq: 0.500108
[00:56:26.109] iteration 437: loss: 0.991471, loss_s1: 0.504259, loss_fp: 0.500087, loss_freq: 0.500091
[00:56:26.726] iteration 438: loss: 0.946065, loss_s1: 0.507246, loss_fp: 0.500159, loss_freq: 0.501522
[00:56:27.340] iteration 439: loss: 0.996016, loss_s1: 0.504405, loss_fp: 0.500147, loss_freq: 0.500857
[00:56:27.959] iteration 440: loss: 0.965317, loss_s1: 0.502452, loss_fp: 0.500192, loss_freq: 0.500448
[00:56:28.569] iteration 441: loss: 0.915197, loss_s1: 0.507866, loss_fp: 0.500320, loss_freq: 0.504141
[00:56:29.196] iteration 442: loss: 0.999850, loss_s1: 0.501103, loss_fp: 0.500083, loss_freq: 0.502079
[00:56:29.817] iteration 443: loss: 0.988035, loss_s1: 0.501160, loss_fp: 0.500092, loss_freq: 0.500177
[00:56:30.435] iteration 444: loss: 0.963347, loss_s1: 0.510911, loss_fp: 0.500286, loss_freq: 0.501511
[00:56:31.057] iteration 445: loss: 0.962506, loss_s1: 0.501581, loss_fp: 0.500122, loss_freq: 0.500544
[00:56:31.675] iteration 446: loss: 0.944747, loss_s1: 0.508210, loss_fp: 0.500365, loss_freq: 0.500412
[00:56:32.295] iteration 447: loss: 0.945060, loss_s1: 0.502836, loss_fp: 0.500050, loss_freq: 0.500718
[00:56:32.910] iteration 448: loss: 1.010789, loss_s1: 0.503829, loss_fp: 0.500171, loss_freq: 0.500708
[00:56:33.531] iteration 449: loss: 0.977233, loss_s1: 0.508262, loss_fp: 0.500197, loss_freq: 0.508551
[00:56:34.148] iteration 450: loss: 0.942098, loss_s1: 0.504631, loss_fp: 0.500081, loss_freq: 0.500721
[00:56:34.770] iteration 451: loss: 0.987882, loss_s1: 0.504277, loss_fp: 0.500035, loss_freq: 0.502409
[00:56:35.386] iteration 452: loss: 0.959991, loss_s1: 0.507236, loss_fp: 0.500865, loss_freq: 0.501315
[00:56:36.003] iteration 453: loss: 0.985297, loss_s1: 0.506550, loss_fp: 0.500149, loss_freq: 0.500540
[00:56:36.621] iteration 454: loss: 0.958163, loss_s1: 0.509072, loss_fp: 0.501590, loss_freq: 0.501486
[00:56:37.252] iteration 455: loss: 0.969781, loss_s1: 0.504775, loss_fp: 0.500150, loss_freq: 0.504924
[00:56:37.875] iteration 456: loss: 0.962097, loss_s1: 0.506244, loss_fp: 0.500246, loss_freq: 0.504934
[00:56:38.497] iteration 457: loss: 0.996933, loss_s1: 0.506729, loss_fp: 0.500139, loss_freq: 0.500878
[00:56:39.133] iteration 458: loss: 0.955981, loss_s1: 0.503791, loss_fp: 0.500319, loss_freq: 0.501282
[00:56:39.763] iteration 459: loss: 0.927481, loss_s1: 0.506923, loss_fp: 0.500651, loss_freq: 0.501650
[00:56:40.389] iteration 460: loss: 0.997421, loss_s1: 0.508936, loss_fp: 0.500334, loss_freq: 0.503556
[00:56:41.007] iteration 461: loss: 0.953269, loss_s1: 0.503740, loss_fp: 0.500376, loss_freq: 0.500394
[00:56:41.627] iteration 462: loss: 0.955161, loss_s1: 0.501829, loss_fp: 0.500701, loss_freq: 0.500828
[00:56:42.251] iteration 463: loss: 0.958193, loss_s1: 0.503293, loss_fp: 0.500330, loss_freq: 0.501349
[00:56:42.870] iteration 464: loss: 0.942939, loss_s1: 0.502005, loss_fp: 0.500113, loss_freq: 0.500974
[00:56:43.488] iteration 465: loss: 0.982161, loss_s1: 0.501758, loss_fp: 0.500103, loss_freq: 0.500713
[00:56:44.106] iteration 466: loss: 0.985577, loss_s1: 0.503326, loss_fp: 0.500263, loss_freq: 0.500479
[00:56:44.733] iteration 467: loss: 0.950367, loss_s1: 0.504229, loss_fp: 0.500309, loss_freq: 0.502884
[00:56:45.356] iteration 468: loss: 1.005499, loss_s1: 0.504662, loss_fp: 0.500232, loss_freq: 0.503665
[00:56:45.979] iteration 469: loss: 0.925940, loss_s1: 0.502083, loss_fp: 0.500144, loss_freq: 0.500603
[00:56:46.603] iteration 470: loss: 0.927484, loss_s1: 0.508067, loss_fp: 0.500122, loss_freq: 0.501231
[00:56:47.213] iteration 471: loss: 0.979178, loss_s1: 0.501435, loss_fp: 0.500161, loss_freq: 0.500790
[00:56:47.831] iteration 472: loss: 0.970396, loss_s1: 0.502214, loss_fp: 0.500064, loss_freq: 0.500751
[00:56:48.447] iteration 473: loss: 0.934026, loss_s1: 0.503143, loss_fp: 0.500113, loss_freq: 0.501121
[00:56:49.060] iteration 474: loss: 1.027544, loss_s1: 0.506415, loss_fp: 0.500619, loss_freq: 0.501086
[00:56:49.691] iteration 475: loss: 1.026055, loss_s1: 0.504204, loss_fp: 0.500484, loss_freq: 0.500475
[00:56:50.313] iteration 476: loss: 0.914202, loss_s1: 0.504172, loss_fp: 0.500272, loss_freq: 0.504748
[00:56:50.941] iteration 477: loss: 1.009079, loss_s1: 0.502751, loss_fp: 0.500228, loss_freq: 0.501043
[00:56:51.561] iteration 478: loss: 0.938390, loss_s1: 0.503827, loss_fp: 0.500368, loss_freq: 0.500536
[00:56:52.175] iteration 479: loss: 0.959894, loss_s1: 0.504085, loss_fp: 0.500354, loss_freq: 0.500727
[00:56:52.821] iteration 480: loss: 0.967526, loss_s1: 0.508398, loss_fp: 0.500113, loss_freq: 0.500497
[00:56:53.487] iteration 481: loss: 1.005236, loss_s1: 0.506556, loss_fp: 0.500084, loss_freq: 0.500916
[00:56:54.145] iteration 482: loss: 0.964087, loss_s1: 0.508965, loss_fp: 0.500084, loss_freq: 0.501133
[00:56:54.801] iteration 483: loss: 1.012945, loss_s1: 0.506232, loss_fp: 0.500106, loss_freq: 0.501931
[00:56:55.435] iteration 484: loss: 0.969857, loss_s1: 0.504475, loss_fp: 0.500161, loss_freq: 0.501239
[00:56:56.056] iteration 485: loss: 0.927803, loss_s1: 0.505375, loss_fp: 0.500159, loss_freq: 0.500854
[00:56:56.680] iteration 486: loss: 0.932069, loss_s1: 0.503394, loss_fp: 0.500086, loss_freq: 0.503004
[00:56:57.296] iteration 487: loss: 1.018297, loss_s1: 0.503651, loss_fp: 0.500292, loss_freq: 0.500290
[00:56:57.918] iteration 488: loss: 0.987533, loss_s1: 0.504635, loss_fp: 0.500430, loss_freq: 0.501492
[00:56:58.545] iteration 489: loss: 0.930288, loss_s1: 0.503736, loss_fp: 0.500234, loss_freq: 0.501005
[00:56:59.160] iteration 490: loss: 0.967731, loss_s1: 0.502491, loss_fp: 0.500218, loss_freq: 0.500760
[00:56:59.778] iteration 491: loss: 0.920428, loss_s1: 0.505845, loss_fp: 0.500080, loss_freq: 0.500903
[00:57:00.396] iteration 492: loss: 0.999500, loss_s1: 0.501718, loss_fp: 0.500403, loss_freq: 0.500685
[00:57:01.017] iteration 493: loss: 0.981877, loss_s1: 0.504597, loss_fp: 0.500398, loss_freq: 0.501240
[00:57:01.630] iteration 494: loss: 0.931383, loss_s1: 0.501828, loss_fp: 0.500057, loss_freq: 0.500481
[00:57:02.246] iteration 495: loss: 1.000243, loss_s1: 0.502651, loss_fp: 0.500568, loss_freq: 0.501897
[00:57:02.863] iteration 496: loss: 0.960747, loss_s1: 0.502998, loss_fp: 0.500078, loss_freq: 0.500629
[00:57:03.479] iteration 497: loss: 0.936761, loss_s1: 0.502092, loss_fp: 0.500788, loss_freq: 0.500970
[00:57:04.093] iteration 498: loss: 0.959378, loss_s1: 0.506409, loss_fp: 0.500144, loss_freq: 0.500657
[00:57:04.716] iteration 499: loss: 0.905041, loss_s1: 0.504202, loss_fp: 0.500036, loss_freq: 0.502208
[00:57:05.337] iteration 500: loss: 0.975165, loss_s1: 0.503695, loss_fp: 0.500195, loss_freq: 0.500404
[00:57:05.953] iteration 501: loss: 0.975400, loss_s1: 0.502394, loss_fp: 0.500157, loss_freq: 0.501391
[00:57:06.582] iteration 502: loss: 0.913755, loss_s1: 0.502970, loss_fp: 0.500106, loss_freq: 0.500719
[00:57:07.194] iteration 503: loss: 0.975518, loss_s1: 0.505605, loss_fp: 0.500319, loss_freq: 0.503020
[00:57:07.804] iteration 504: loss: 0.931185, loss_s1: 0.505093, loss_fp: 0.500514, loss_freq: 0.500615
[00:57:08.418] iteration 505: loss: 0.936876, loss_s1: 0.507868, loss_fp: 0.500456, loss_freq: 0.500471
[00:57:09.035] iteration 506: loss: 0.962323, loss_s1: 0.501449, loss_fp: 0.500442, loss_freq: 0.500677
[00:57:09.649] iteration 507: loss: 0.944484, loss_s1: 0.502877, loss_fp: 0.500136, loss_freq: 0.501027
[00:57:10.262] iteration 508: loss: 0.919472, loss_s1: 0.504169, loss_fp: 0.500252, loss_freq: 0.500523
[00:57:10.877] iteration 509: loss: 0.961526, loss_s1: 0.503890, loss_fp: 0.500168, loss_freq: 0.500584
[00:57:11.496] iteration 510: loss: 0.954185, loss_s1: 0.503740, loss_fp: 0.500627, loss_freq: 0.504271
[00:57:12.445] iteration 511: loss: 0.928885, loss_s1: 0.504632, loss_fp: 0.500249, loss_freq: 0.502393
[00:57:13.100] iteration 512: loss: 0.933336, loss_s1: 0.503767, loss_fp: 0.500539, loss_freq: 0.501002
[00:57:13.746] iteration 513: loss: 0.956056, loss_s1: 0.503060, loss_fp: 0.500344, loss_freq: 0.501159
[00:57:14.411] iteration 514: loss: 0.977674, loss_s1: 0.505094, loss_fp: 0.500089, loss_freq: 0.501344
[00:57:15.074] iteration 515: loss: 0.946126, loss_s1: 0.508152, loss_fp: 0.500381, loss_freq: 0.500914
[00:57:15.697] iteration 516: loss: 0.963300, loss_s1: 0.509894, loss_fp: 0.500072, loss_freq: 0.500268
[00:57:16.316] iteration 517: loss: 1.017980, loss_s1: 0.505794, loss_fp: 0.500224, loss_freq: 0.501275
[00:57:16.936] iteration 518: loss: 0.973242, loss_s1: 0.505035, loss_fp: 0.500809, loss_freq: 0.500259
[00:57:17.559] iteration 519: loss: 0.957651, loss_s1: 0.503464, loss_fp: 0.500259, loss_freq: 0.501499
[00:57:18.180] iteration 520: loss: 0.947753, loss_s1: 0.503449, loss_fp: 0.500148, loss_freq: 0.500628
[00:57:18.801] iteration 521: loss: 0.994302, loss_s1: 0.509814, loss_fp: 0.500129, loss_freq: 0.502675
[00:57:19.421] iteration 522: loss: 0.958604, loss_s1: 0.507550, loss_fp: 0.500141, loss_freq: 0.500294
[00:57:20.040] iteration 523: loss: 0.947241, loss_s1: 0.504568, loss_fp: 0.500191, loss_freq: 0.501234
[00:57:20.659] iteration 524: loss: 0.950471, loss_s1: 0.504833, loss_fp: 0.500121, loss_freq: 0.500371
[00:57:21.284] iteration 525: loss: 1.025746, loss_s1: 0.500917, loss_fp: 0.500220, loss_freq: 0.500333
[00:57:21.909] iteration 526: loss: 0.976635, loss_s1: 0.504583, loss_fp: 0.500168, loss_freq: 0.501168
[00:57:22.562] iteration 527: loss: 0.939263, loss_s1: 0.502364, loss_fp: 0.500225, loss_freq: 0.500443
[00:57:23.188] iteration 528: loss: 0.950182, loss_s1: 0.503878, loss_fp: 0.500057, loss_freq: 0.500336
[00:57:23.803] iteration 529: loss: 0.950667, loss_s1: 0.503713, loss_fp: 0.500044, loss_freq: 0.500132
[00:57:24.475] iteration 530: loss: 0.967580, loss_s1: 0.502528, loss_fp: 0.500384, loss_freq: 0.500506
[00:57:25.147] iteration 531: loss: 0.937721, loss_s1: 0.505771, loss_fp: 0.500208, loss_freq: 0.501422
[00:57:25.767] iteration 532: loss: 0.969654, loss_s1: 0.502112, loss_fp: 0.500052, loss_freq: 0.501032
[00:57:26.432] iteration 533: loss: 1.029290, loss_s1: 0.505800, loss_fp: 0.500260, loss_freq: 0.501971
[00:57:27.081] iteration 534: loss: 0.920109, loss_s1: 0.506593, loss_fp: 0.500468, loss_freq: 0.501420
[00:57:27.726] iteration 535: loss: 0.935516, loss_s1: 0.506724, loss_fp: 0.500184, loss_freq: 0.500508
[00:57:28.371] iteration 536: loss: 0.962615, loss_s1: 0.502303, loss_fp: 0.500844, loss_freq: 0.500679
[00:57:28.984] iteration 537: loss: 0.928937, loss_s1: 0.502724, loss_fp: 0.500074, loss_freq: 0.500456
[00:57:29.594] iteration 538: loss: 0.932189, loss_s1: 0.503190, loss_fp: 0.500381, loss_freq: 0.501454
[00:57:30.209] iteration 539: loss: 0.986236, loss_s1: 0.507212, loss_fp: 0.500253, loss_freq: 0.501362
[00:57:30.825] iteration 540: loss: 0.995200, loss_s1: 0.509722, loss_fp: 0.500300, loss_freq: 0.501971
[00:57:31.465] iteration 541: loss: 0.902479, loss_s1: 0.506082, loss_fp: 0.500116, loss_freq: 0.501088
[00:57:32.124] iteration 542: loss: 0.980701, loss_s1: 0.508867, loss_fp: 0.500193, loss_freq: 0.502419
[00:57:32.783] iteration 543: loss: 0.945464, loss_s1: 0.506784, loss_fp: 0.500287, loss_freq: 0.505608
[00:57:33.440] iteration 544: loss: 0.929514, loss_s1: 0.504069, loss_fp: 0.500211, loss_freq: 0.502171
[00:57:34.086] iteration 545: loss: 0.964668, loss_s1: 0.507825, loss_fp: 0.500390, loss_freq: 0.502427
[00:57:34.705] iteration 546: loss: 0.954350, loss_s1: 0.507808, loss_fp: 0.500251, loss_freq: 0.500327
[00:57:35.323] iteration 547: loss: 0.905026, loss_s1: 0.506213, loss_fp: 0.500061, loss_freq: 0.501430
[00:57:35.939] iteration 548: loss: 1.041904, loss_s1: 0.507374, loss_fp: 0.500188, loss_freq: 0.501166
[00:57:36.553] iteration 549: loss: 0.920769, loss_s1: 0.505196, loss_fp: 0.500294, loss_freq: 0.501103
[00:57:37.167] iteration 550: loss: 0.964957, loss_s1: 0.507065, loss_fp: 0.500220, loss_freq: 0.500728
[00:57:37.785] iteration 551: loss: 0.942138, loss_s1: 0.503705, loss_fp: 0.500278, loss_freq: 0.501110
[00:57:38.399] iteration 552: loss: 0.923288, loss_s1: 0.507981, loss_fp: 0.500143, loss_freq: 0.501692
[00:57:39.017] iteration 553: loss: 0.965238, loss_s1: 0.502851, loss_fp: 0.500330, loss_freq: 0.501192
[00:57:39.687] iteration 554: loss: 0.942694, loss_s1: 0.502188, loss_fp: 0.500073, loss_freq: 0.500699
[00:57:40.339] iteration 555: loss: 0.944784, loss_s1: 0.503789, loss_fp: 0.500351, loss_freq: 0.500466
[00:57:41.010] iteration 556: loss: 0.902305, loss_s1: 0.507346, loss_fp: 0.500557, loss_freq: 0.501171
[00:57:41.666] iteration 557: loss: 0.983590, loss_s1: 0.508605, loss_fp: 0.500332, loss_freq: 0.500691
[00:57:42.314] iteration 558: loss: 0.928654, loss_s1: 0.504239, loss_fp: 0.500140, loss_freq: 0.501571
[00:57:42.938] iteration 559: loss: 0.943213, loss_s1: 0.501371, loss_fp: 0.500464, loss_freq: 0.500953
[00:57:43.551] iteration 560: loss: 0.941437, loss_s1: 0.507797, loss_fp: 0.500300, loss_freq: 0.501245
[00:57:44.159] iteration 561: loss: 0.939446, loss_s1: 0.509141, loss_fp: 0.500117, loss_freq: 0.500790
[00:57:44.783] iteration 562: loss: 0.906418, loss_s1: 0.501073, loss_fp: 0.500106, loss_freq: 0.500432
[00:57:45.402] iteration 563: loss: 0.988241, loss_s1: 0.505140, loss_fp: 0.500139, loss_freq: 0.502250
[00:57:46.010] iteration 564: loss: 0.931095, loss_s1: 0.503825, loss_fp: 0.500210, loss_freq: 0.500800
[00:57:46.624] iteration 565: loss: 0.961673, loss_s1: 0.504618, loss_fp: 0.500231, loss_freq: 0.501615
[00:57:47.240] iteration 566: loss: 0.958110, loss_s1: 0.506175, loss_fp: 0.500048, loss_freq: 0.501559
[00:57:47.854] iteration 567: loss: 0.912392, loss_s1: 0.504815, loss_fp: 0.500945, loss_freq: 0.501634
[00:57:48.473] iteration 568: loss: 0.983006, loss_s1: 0.505503, loss_fp: 0.500161, loss_freq: 0.501291
[00:57:49.085] iteration 569: loss: 0.950405, loss_s1: 0.503769, loss_fp: 0.500433, loss_freq: 0.500343
[00:57:49.692] iteration 570: loss: 0.933273, loss_s1: 0.507625, loss_fp: 0.500099, loss_freq: 0.501422
[00:57:50.306] iteration 571: loss: 0.943440, loss_s1: 0.501427, loss_fp: 0.500174, loss_freq: 0.500592
[00:57:50.920] iteration 572: loss: 0.945996, loss_s1: 0.504499, loss_fp: 0.500233, loss_freq: 0.500617
[00:57:51.536] iteration 573: loss: 0.928135, loss_s1: 0.506526, loss_fp: 0.500078, loss_freq: 0.500719
[00:57:52.151] iteration 574: loss: 0.943976, loss_s1: 0.502535, loss_fp: 0.500042, loss_freq: 0.500254
[00:57:52.761] iteration 575: loss: 0.928289, loss_s1: 0.501199, loss_fp: 0.500110, loss_freq: 0.500831
[00:57:53.379] iteration 576: loss: 0.894976, loss_s1: 0.504813, loss_fp: 0.500121, loss_freq: 0.502175
[00:57:53.991] iteration 577: loss: 0.979484, loss_s1: 0.504702, loss_fp: 0.500067, loss_freq: 0.500684
[00:57:54.601] iteration 578: loss: 0.918790, loss_s1: 0.502425, loss_fp: 0.500093, loss_freq: 0.500696
[00:57:55.229] iteration 579: loss: 0.955466, loss_s1: 0.505333, loss_fp: 0.500170, loss_freq: 0.501337
[00:57:55.843] iteration 580: loss: 0.944935, loss_s1: 0.504593, loss_fp: 0.500103, loss_freq: 0.500772
[00:57:56.473] iteration 581: loss: 0.932862, loss_s1: 0.504030, loss_fp: 0.500078, loss_freq: 0.500621
[00:57:57.230] iteration 582: loss: 0.911999, loss_s1: 0.503546, loss_fp: 0.500063, loss_freq: 0.500846
[00:57:57.908] iteration 583: loss: 0.975737, loss_s1: 0.506319, loss_fp: 0.500078, loss_freq: 0.501110
[00:57:58.659] iteration 584: loss: 0.947364, loss_s1: 0.505416, loss_fp: 0.500100, loss_freq: 0.502199
[00:57:59.327] iteration 585: loss: 0.928674, loss_s1: 0.509858, loss_fp: 0.501192, loss_freq: 0.502282
[00:58:00.052] iteration 586: loss: 0.976287, loss_s1: 0.503491, loss_fp: 0.500170, loss_freq: 0.501699
[00:58:00.852] iteration 587: loss: 0.925929, loss_s1: 0.506364, loss_fp: 0.500260, loss_freq: 0.501072
[00:58:01.486] iteration 588: loss: 0.970086, loss_s1: 0.502018, loss_fp: 0.500221, loss_freq: 0.501333
[00:58:02.122] iteration 589: loss: 0.913361, loss_s1: 0.507716, loss_fp: 0.500297, loss_freq: 0.500506
[00:58:02.744] iteration 590: loss: 0.997278, loss_s1: 0.506179, loss_fp: 0.500396, loss_freq: 0.501861
[00:58:03.402] iteration 591: loss: 0.941080, loss_s1: 0.505052, loss_fp: 0.500128, loss_freq: 0.504084
[00:58:04.067] iteration 592: loss: 0.947617, loss_s1: 0.508967, loss_fp: 0.500097, loss_freq: 0.500880
[00:58:04.790] iteration 593: loss: 0.998685, loss_s1: 0.503546, loss_fp: 0.500376, loss_freq: 0.501708
[00:58:05.538] iteration 594: loss: 0.907863, loss_s1: 0.504012, loss_fp: 0.500229, loss_freq: 0.501112
[00:58:06.178] iteration 595: loss: 0.944877, loss_s1: 0.504370, loss_fp: 0.500256, loss_freq: 0.501226
[00:58:06.867] iteration 596: loss: 1.005389, loss_s1: 0.503437, loss_fp: 0.500625, loss_freq: 0.501067
[00:58:07.558] iteration 597: loss: 0.913227, loss_s1: 0.500813, loss_fp: 0.500289, loss_freq: 0.500401
[00:58:08.230] iteration 598: loss: 0.948594, loss_s1: 0.501838, loss_fp: 0.500215, loss_freq: 0.502030
[00:58:08.887] iteration 599: loss: 0.909230, loss_s1: 0.506717, loss_fp: 0.500209, loss_freq: 0.501711
[00:58:09.500] iteration 600: loss: 0.988354, loss_s1: 0.503168, loss_fp: 0.500098, loss_freq: 0.500765
[00:58:12.026] iteration 600 : mean_dice : 0.075958
[00:58:12.676] iteration 601: loss: 0.976330, loss_s1: 0.505249, loss_fp: 0.500466, loss_freq: 0.502453
[00:58:13.296] iteration 602: loss: 0.906844, loss_s1: 0.502709, loss_fp: 0.500129, loss_freq: 0.502050
[00:58:13.916] iteration 603: loss: 0.978973, loss_s1: 0.503356, loss_fp: 0.500103, loss_freq: 0.500903
[00:58:14.534] iteration 604: loss: 0.940237, loss_s1: 0.505885, loss_fp: 0.500103, loss_freq: 0.500682
[00:58:15.152] iteration 605: loss: 0.929779, loss_s1: 0.503640, loss_fp: 0.500252, loss_freq: 0.500400
[00:58:15.769] iteration 606: loss: 0.954906, loss_s1: 0.505503, loss_fp: 0.500107, loss_freq: 0.500183
[00:58:16.386] iteration 607: loss: 0.941669, loss_s1: 0.502486, loss_fp: 0.500232, loss_freq: 0.500442
[00:58:17.003] iteration 608: loss: 0.926690, loss_s1: 0.503900, loss_fp: 0.500749, loss_freq: 0.502044
[00:58:17.625] iteration 609: loss: 0.955418, loss_s1: 0.501987, loss_fp: 0.500333, loss_freq: 0.500573
[00:58:18.239] iteration 610: loss: 0.946714, loss_s1: 0.503779, loss_fp: 0.500552, loss_freq: 0.500991
[00:58:18.855] iteration 611: loss: 0.873238, loss_s1: 0.506353, loss_fp: 0.500364, loss_freq: 0.501447
[00:58:19.478] iteration 612: loss: 0.957276, loss_s1: 0.504558, loss_fp: 0.500188, loss_freq: 0.501396
[00:58:20.107] iteration 613: loss: 0.942254, loss_s1: 0.503137, loss_fp: 0.500044, loss_freq: 0.500580
[00:58:20.742] iteration 614: loss: 0.946377, loss_s1: 0.509406, loss_fp: 0.500260, loss_freq: 0.502832
[00:58:21.669] iteration 615: loss: 0.912899, loss_s1: 0.505876, loss_fp: 0.500045, loss_freq: 0.500630
[00:58:22.321] iteration 616: loss: 0.933339, loss_s1: 0.503680, loss_fp: 0.500372, loss_freq: 0.501486
[00:58:22.950] iteration 617: loss: 0.903769, loss_s1: 0.505360, loss_fp: 0.500305, loss_freq: 0.500310
[00:58:23.790] iteration 618: loss: 1.014105, loss_s1: 0.505468, loss_fp: 0.500348, loss_freq: 0.501171
[00:58:24.783] iteration 619: loss: 0.966789, loss_s1: 0.508201, loss_fp: 0.500080, loss_freq: 0.504907
[00:58:25.437] iteration 620: loss: 0.951191, loss_s1: 0.507254, loss_fp: 0.500201, loss_freq: 0.500471
[00:58:26.061] iteration 621: loss: 0.988579, loss_s1: 0.507052, loss_fp: 0.500124, loss_freq: 0.502900
[00:58:26.675] iteration 622: loss: 0.913829, loss_s1: 0.508086, loss_fp: 0.500627, loss_freq: 0.501961
[00:58:27.292] iteration 623: loss: 0.952443, loss_s1: 0.509056, loss_fp: 0.500163, loss_freq: 0.500223
[00:58:27.909] iteration 624: loss: 0.934465, loss_s1: 0.520595, loss_fp: 0.500252, loss_freq: 0.502501
[00:58:28.532] iteration 625: loss: 0.963130, loss_s1: 0.507466, loss_fp: 0.500100, loss_freq: 0.504616
[00:58:29.146] iteration 626: loss: 0.934429, loss_s1: 0.508533, loss_fp: 0.500445, loss_freq: 0.504467
[00:58:29.780] iteration 627: loss: 0.947489, loss_s1: 0.509318, loss_fp: 0.500617, loss_freq: 0.500810
[00:58:30.395] iteration 628: loss: 0.932003, loss_s1: 0.502683, loss_fp: 0.500537, loss_freq: 0.501757
[00:58:31.013] iteration 629: loss: 0.938137, loss_s1: 0.506502, loss_fp: 0.500073, loss_freq: 0.503066
[00:58:31.628] iteration 630: loss: 0.973089, loss_s1: 0.503950, loss_fp: 0.500136, loss_freq: 0.502082
[00:58:32.247] iteration 631: loss: 0.948535, loss_s1: 0.505586, loss_fp: 0.500379, loss_freq: 0.500427
[00:58:32.861] iteration 632: loss: 0.942460, loss_s1: 0.506344, loss_fp: 0.501491, loss_freq: 0.500656
[00:58:33.476] iteration 633: loss: 0.930760, loss_s1: 0.504298, loss_fp: 0.500347, loss_freq: 0.501766
[00:58:34.112] iteration 634: loss: 0.915912, loss_s1: 0.504706, loss_fp: 0.500129, loss_freq: 0.500855
[00:58:34.750] iteration 635: loss: 0.927333, loss_s1: 0.502602, loss_fp: 0.500097, loss_freq: 0.500743
[00:58:35.372] iteration 636: loss: 0.982141, loss_s1: 0.501465, loss_fp: 0.500051, loss_freq: 0.500380
[00:58:35.987] iteration 637: loss: 0.928941, loss_s1: 0.504591, loss_fp: 0.500078, loss_freq: 0.502957
[00:58:36.602] iteration 638: loss: 0.970129, loss_s1: 0.505203, loss_fp: 0.500507, loss_freq: 0.503480
[00:58:37.217] iteration 639: loss: 0.921865, loss_s1: 0.501483, loss_fp: 0.500148, loss_freq: 0.501164
[00:58:37.838] iteration 640: loss: 0.941796, loss_s1: 0.506391, loss_fp: 0.501531, loss_freq: 0.502241
[00:58:38.456] iteration 641: loss: 0.931860, loss_s1: 0.503609, loss_fp: 0.500267, loss_freq: 0.500436
[00:58:39.069] iteration 642: loss: 0.927521, loss_s1: 0.505358, loss_fp: 0.500192, loss_freq: 0.500828
[00:58:39.693] iteration 643: loss: 0.910664, loss_s1: 0.505862, loss_fp: 0.500066, loss_freq: 0.502893
[00:58:40.318] iteration 644: loss: 0.972458, loss_s1: 0.508237, loss_fp: 0.500058, loss_freq: 0.500699
[00:58:40.934] iteration 645: loss: 0.990428, loss_s1: 0.503659, loss_fp: 0.500078, loss_freq: 0.501661
[00:58:41.550] iteration 646: loss: 0.870988, loss_s1: 0.506994, loss_fp: 0.500130, loss_freq: 0.503903
[00:58:42.172] iteration 647: loss: 1.021124, loss_s1: 0.507626, loss_fp: 0.500262, loss_freq: 0.501695
[00:58:42.794] iteration 648: loss: 0.942237, loss_s1: 0.506236, loss_fp: 0.500240, loss_freq: 0.501648
[00:58:43.411] iteration 649: loss: 0.939418, loss_s1: 0.507045, loss_fp: 0.500222, loss_freq: 0.501064
[00:58:44.025] iteration 650: loss: 0.957769, loss_s1: 0.503784, loss_fp: 0.500190, loss_freq: 0.501197
[00:58:44.645] iteration 651: loss: 0.906698, loss_s1: 0.504521, loss_fp: 0.500578, loss_freq: 0.501187
[00:58:45.259] iteration 652: loss: 0.919302, loss_s1: 0.507672, loss_fp: 0.500111, loss_freq: 0.501509
[00:58:45.879] iteration 653: loss: 0.991628, loss_s1: 0.506902, loss_fp: 0.500094, loss_freq: 0.504182
[00:58:46.501] iteration 654: loss: 0.912595, loss_s1: 0.504946, loss_fp: 0.501114, loss_freq: 0.501258
[00:58:47.129] iteration 655: loss: 0.991874, loss_s1: 0.504523, loss_fp: 0.500241, loss_freq: 0.502420
[00:58:47.744] iteration 656: loss: 0.961384, loss_s1: 0.503981, loss_fp: 0.500426, loss_freq: 0.501755
[00:58:48.360] iteration 657: loss: 0.934209, loss_s1: 0.501270, loss_fp: 0.500100, loss_freq: 0.500655
[00:58:48.975] iteration 658: loss: 0.960216, loss_s1: 0.503595, loss_fp: 0.500100, loss_freq: 0.500524
[00:58:49.592] iteration 659: loss: 0.943953, loss_s1: 0.503393, loss_fp: 0.500911, loss_freq: 0.500504
[00:58:50.203] iteration 660: loss: 0.932847, loss_s1: 0.501094, loss_fp: 0.500270, loss_freq: 0.500387
[00:58:50.819] iteration 661: loss: 0.914763, loss_s1: 0.503490, loss_fp: 0.500046, loss_freq: 0.501282
[00:58:51.429] iteration 662: loss: 0.936888, loss_s1: 0.504682, loss_fp: 0.500199, loss_freq: 0.501389
[00:58:52.042] iteration 663: loss: 0.901368, loss_s1: 0.502027, loss_fp: 0.500113, loss_freq: 0.501894
[00:58:52.659] iteration 664: loss: 0.934293, loss_s1: 0.503792, loss_fp: 0.500154, loss_freq: 0.500913
[00:58:53.338] iteration 665: loss: 0.967797, loss_s1: 0.503972, loss_fp: 0.500109, loss_freq: 0.500607
[00:58:53.988] iteration 666: loss: 0.939615, loss_s1: 0.502639, loss_fp: 0.500132, loss_freq: 0.500886
[00:58:54.646] iteration 667: loss: 0.929947, loss_s1: 0.503611, loss_fp: 0.500487, loss_freq: 0.500733
[00:58:55.316] iteration 668: loss: 0.922426, loss_s1: 0.501883, loss_fp: 0.500157, loss_freq: 0.501198
[00:58:55.973] iteration 669: loss: 0.896504, loss_s1: 0.502185, loss_fp: 0.500137, loss_freq: 0.500963
[00:58:56.611] iteration 670: loss: 0.972185, loss_s1: 0.503593, loss_fp: 0.500203, loss_freq: 0.500413
[00:58:57.225] iteration 671: loss: 0.941077, loss_s1: 0.504771, loss_fp: 0.501010, loss_freq: 0.501312
[00:58:57.839] iteration 672: loss: 0.902764, loss_s1: 0.502307, loss_fp: 0.500123, loss_freq: 0.500593
[00:58:58.454] iteration 673: loss: 0.968765, loss_s1: 0.502623, loss_fp: 0.500119, loss_freq: 0.501636
[00:58:59.068] iteration 674: loss: 0.903844, loss_s1: 0.505165, loss_fp: 0.500292, loss_freq: 0.501363
[00:58:59.683] iteration 675: loss: 0.911406, loss_s1: 0.503145, loss_fp: 0.500240, loss_freq: 0.500363
[00:59:00.301] iteration 676: loss: 0.912321, loss_s1: 0.505958, loss_fp: 0.500181, loss_freq: 0.500995
[00:59:00.929] iteration 677: loss: 0.934916, loss_s1: 0.507990, loss_fp: 0.500113, loss_freq: 0.501112
[00:59:01.548] iteration 678: loss: 0.926330, loss_s1: 0.506767, loss_fp: 0.500194, loss_freq: 0.502730
[00:59:02.159] iteration 679: loss: 0.953044, loss_s1: 0.510928, loss_fp: 0.500140, loss_freq: 0.500887
[00:59:02.809] iteration 680: loss: 0.949343, loss_s1: 0.507830, loss_fp: 0.500240, loss_freq: 0.507233
[00:59:03.830] iteration 681: loss: 0.918498, loss_s1: 0.508549, loss_fp: 0.500174, loss_freq: 0.501789
[00:59:04.491] iteration 682: loss: 0.902935, loss_s1: 0.506977, loss_fp: 0.500188, loss_freq: 0.501417
[00:59:05.184] iteration 683: loss: 0.935146, loss_s1: 0.504519, loss_fp: 0.500142, loss_freq: 0.500866
[00:59:05.846] iteration 684: loss: 0.957816, loss_s1: 0.505507, loss_fp: 0.500208, loss_freq: 0.503120
[00:59:06.508] iteration 685: loss: 0.914998, loss_s1: 0.501326, loss_fp: 0.500262, loss_freq: 0.500691
[00:59:07.166] iteration 686: loss: 0.937281, loss_s1: 0.504726, loss_fp: 0.500101, loss_freq: 0.500642
[00:59:07.811] iteration 687: loss: 0.947588, loss_s1: 0.504671, loss_fp: 0.500106, loss_freq: 0.501112
[00:59:08.431] iteration 688: loss: 1.021248, loss_s1: 0.502980, loss_fp: 0.500076, loss_freq: 0.500271
[00:59:09.044] iteration 689: loss: 0.931717, loss_s1: 0.504264, loss_fp: 0.500262, loss_freq: 0.500274
[00:59:09.662] iteration 690: loss: 0.962368, loss_s1: 0.504592, loss_fp: 0.500175, loss_freq: 0.500334
[00:59:10.284] iteration 691: loss: 0.935355, loss_s1: 0.505186, loss_fp: 0.500040, loss_freq: 0.503999
[00:59:10.899] iteration 692: loss: 0.970405, loss_s1: 0.504927, loss_fp: 0.500089, loss_freq: 0.501230
[00:59:11.548] iteration 693: loss: 0.955475, loss_s1: 0.509778, loss_fp: 0.500265, loss_freq: 0.501197
[00:59:12.194] iteration 694: loss: 0.909315, loss_s1: 0.505696, loss_fp: 0.500329, loss_freq: 0.500858
[00:59:12.815] iteration 695: loss: 0.970407, loss_s1: 0.503007, loss_fp: 0.500198, loss_freq: 0.500498
[00:59:13.433] iteration 696: loss: 0.937059, loss_s1: 0.502875, loss_fp: 0.500422, loss_freq: 0.500658
[00:59:14.054] iteration 697: loss: 0.929341, loss_s1: 0.501630, loss_fp: 0.500093, loss_freq: 0.500512
[00:59:14.668] iteration 698: loss: 0.949029, loss_s1: 0.505691, loss_fp: 0.500355, loss_freq: 0.500401
[00:59:15.281] iteration 699: loss: 0.925782, loss_s1: 0.502610, loss_fp: 0.501523, loss_freq: 0.500429
[00:59:15.901] iteration 700: loss: 0.936355, loss_s1: 0.502007, loss_fp: 0.500465, loss_freq: 0.500764
[00:59:16.511] iteration 701: loss: 0.943201, loss_s1: 0.503837, loss_fp: 0.500056, loss_freq: 0.502150
[00:59:17.129] iteration 702: loss: 0.923282, loss_s1: 0.506055, loss_fp: 0.500227, loss_freq: 0.503821
[00:59:17.740] iteration 703: loss: 0.975293, loss_s1: 0.504021, loss_fp: 0.500143, loss_freq: 0.500930
[00:59:18.355] iteration 704: loss: 0.934457, loss_s1: 0.507369, loss_fp: 0.500033, loss_freq: 0.501478
[00:59:18.985] iteration 705: loss: 0.895485, loss_s1: 0.506940, loss_fp: 0.500384, loss_freq: 0.501153
[00:59:19.626] iteration 706: loss: 0.956202, loss_s1: 0.510533, loss_fp: 0.500391, loss_freq: 0.502388
[00:59:20.241] iteration 707: loss: 0.917072, loss_s1: 0.508565, loss_fp: 0.500231, loss_freq: 0.501607
[00:59:20.860] iteration 708: loss: 0.923617, loss_s1: 0.510344, loss_fp: 0.500987, loss_freq: 0.504502
[00:59:21.482] iteration 709: loss: 1.041650, loss_s1: 0.508635, loss_fp: 0.502663, loss_freq: 0.503358
[00:59:22.099] iteration 710: loss: 0.923727, loss_s1: 0.508918, loss_fp: 0.500038, loss_freq: 0.502296
[00:59:22.722] iteration 711: loss: 0.872067, loss_s1: 0.510063, loss_fp: 0.500692, loss_freq: 0.502505
[00:59:23.342] iteration 712: loss: 0.980443, loss_s1: 0.507845, loss_fp: 0.500259, loss_freq: 0.504514
[00:59:23.961] iteration 713: loss: 0.935823, loss_s1: 0.509599, loss_fp: 0.500557, loss_freq: 0.501884
[00:59:24.582] iteration 714: loss: 0.962055, loss_s1: 0.505811, loss_fp: 0.500120, loss_freq: 0.502982
[00:59:25.205] iteration 715: loss: 0.927819, loss_s1: 0.502797, loss_fp: 0.500384, loss_freq: 0.501982
[00:59:25.833] iteration 716: loss: 0.923694, loss_s1: 0.503588, loss_fp: 0.500079, loss_freq: 0.500396
[00:59:26.460] iteration 717: loss: 0.919573, loss_s1: 0.507277, loss_fp: 0.500544, loss_freq: 0.501204
[00:59:27.078] iteration 718: loss: 0.942634, loss_s1: 0.504219, loss_fp: 0.500095, loss_freq: 0.500499
[00:59:27.710] iteration 719: loss: 0.946538, loss_s1: 0.504270, loss_fp: 0.500366, loss_freq: 0.501224
[00:59:28.322] iteration 720: loss: 0.939861, loss_s1: 0.506248, loss_fp: 0.500322, loss_freq: 0.501557
[00:59:28.933] iteration 721: loss: 0.954233, loss_s1: 0.508500, loss_fp: 0.500070, loss_freq: 0.502273
[00:59:29.544] iteration 722: loss: 0.956126, loss_s1: 0.508660, loss_fp: 0.500309, loss_freq: 0.501618
[00:59:30.189] iteration 723: loss: 0.927076, loss_s1: 0.504564, loss_fp: 0.500266, loss_freq: 0.501435
[00:59:30.811] iteration 724: loss: 0.907178, loss_s1: 0.501886, loss_fp: 0.500206, loss_freq: 0.501588
[00:59:31.450] iteration 725: loss: 0.904877, loss_s1: 0.502974, loss_fp: 0.503703, loss_freq: 0.501686
[00:59:32.101] iteration 726: loss: 0.907597, loss_s1: 0.506338, loss_fp: 0.501260, loss_freq: 0.503106
[00:59:32.720] iteration 727: loss: 0.965185, loss_s1: 0.509611, loss_fp: 0.500076, loss_freq: 0.500984
[00:59:33.389] iteration 728: loss: 0.925945, loss_s1: 0.505614, loss_fp: 0.500123, loss_freq: 0.502066
[00:59:34.038] iteration 729: loss: 0.942361, loss_s1: 0.502977, loss_fp: 0.500095, loss_freq: 0.500772
[00:59:34.681] iteration 730: loss: 0.952980, loss_s1: 0.503273, loss_fp: 0.500273, loss_freq: 0.501851
[00:59:35.328] iteration 731: loss: 0.910355, loss_s1: 0.504862, loss_fp: 0.500167, loss_freq: 0.500838
[00:59:35.968] iteration 732: loss: 0.887937, loss_s1: 0.501550, loss_fp: 0.500228, loss_freq: 0.500362
[00:59:36.587] iteration 733: loss: 0.947391, loss_s1: 0.504405, loss_fp: 0.500106, loss_freq: 0.504416
[00:59:37.200] iteration 734: loss: 0.900057, loss_s1: 0.506658, loss_fp: 0.500504, loss_freq: 0.502309
[00:59:37.816] iteration 735: loss: 0.941647, loss_s1: 0.510645, loss_fp: 0.501063, loss_freq: 0.502261
[00:59:38.440] iteration 736: loss: 0.905357, loss_s1: 0.501795, loss_fp: 0.500095, loss_freq: 0.502086
[00:59:39.063] iteration 737: loss: 0.866854, loss_s1: 0.506035, loss_fp: 0.500307, loss_freq: 0.502149
[00:59:39.689] iteration 738: loss: 0.950500, loss_s1: 0.505183, loss_fp: 0.500227, loss_freq: 0.503248
[00:59:40.305] iteration 739: loss: 0.937748, loss_s1: 0.504704, loss_fp: 0.500935, loss_freq: 0.501647
[00:59:40.922] iteration 740: loss: 0.896654, loss_s1: 0.506774, loss_fp: 0.500507, loss_freq: 0.502550
[00:59:41.538] iteration 741: loss: 0.902797, loss_s1: 0.504763, loss_fp: 0.500297, loss_freq: 0.501686
[00:59:42.153] iteration 742: loss: 0.899319, loss_s1: 0.505094, loss_fp: 0.500443, loss_freq: 0.500622
[00:59:42.781] iteration 743: loss: 0.906100, loss_s1: 0.507042, loss_fp: 0.500149, loss_freq: 0.500959
[00:59:43.399] iteration 744: loss: 0.927067, loss_s1: 0.501351, loss_fp: 0.500209, loss_freq: 0.500688
[00:59:44.018] iteration 745: loss: 0.958626, loss_s1: 0.505966, loss_fp: 0.500093, loss_freq: 0.502610
[00:59:44.633] iteration 746: loss: 0.869476, loss_s1: 0.503354, loss_fp: 0.500194, loss_freq: 0.501317
[00:59:45.249] iteration 747: loss: 0.972760, loss_s1: 0.503731, loss_fp: 0.500080, loss_freq: 0.501343
[00:59:45.865] iteration 748: loss: 0.891000, loss_s1: 0.504701, loss_fp: 0.500193, loss_freq: 0.501929
[00:59:46.479] iteration 749: loss: 0.920941, loss_s1: 0.501766, loss_fp: 0.500287, loss_freq: 0.501645
[00:59:47.089] iteration 750: loss: 0.897414, loss_s1: 0.505942, loss_fp: 0.500392, loss_freq: 0.500894
[00:59:47.696] iteration 751: loss: 0.901530, loss_s1: 0.508628, loss_fp: 0.500087, loss_freq: 0.501475
[00:59:48.304] iteration 752: loss: 0.882936, loss_s1: 0.505694, loss_fp: 0.500067, loss_freq: 0.501658
[00:59:48.917] iteration 753: loss: 0.909027, loss_s1: 0.502768, loss_fp: 0.500069, loss_freq: 0.500743
[00:59:49.528] iteration 754: loss: 0.887994, loss_s1: 0.510836, loss_fp: 0.500270, loss_freq: 0.502581
[00:59:50.142] iteration 755: loss: 0.903269, loss_s1: 0.511552, loss_fp: 0.500176, loss_freq: 0.502126
[00:59:50.777] iteration 756: loss: 0.917548, loss_s1: 0.505445, loss_fp: 0.500125, loss_freq: 0.500824
[00:59:51.406] iteration 757: loss: 0.884583, loss_s1: 0.504534, loss_fp: 0.500058, loss_freq: 0.500764
[00:59:52.028] iteration 758: loss: 0.932056, loss_s1: 0.504398, loss_fp: 0.500447, loss_freq: 0.503536
[00:59:52.646] iteration 759: loss: 0.872484, loss_s1: 0.504650, loss_fp: 0.500626, loss_freq: 0.501812
[00:59:53.266] iteration 760: loss: 0.878744, loss_s1: 0.505005, loss_fp: 0.500275, loss_freq: 0.501847
[00:59:53.882] iteration 761: loss: 0.912964, loss_s1: 0.505881, loss_fp: 0.500475, loss_freq: 0.505768
[00:59:54.497] iteration 762: loss: 0.944238, loss_s1: 0.506692, loss_fp: 0.500073, loss_freq: 0.502567
[00:59:55.109] iteration 763: loss: 0.925173, loss_s1: 0.505303, loss_fp: 0.500198, loss_freq: 0.501861
[00:59:55.721] iteration 764: loss: 0.910098, loss_s1: 0.503672, loss_fp: 0.500127, loss_freq: 0.502073
[00:59:56.336] iteration 765: loss: 0.921513, loss_s1: 0.507557, loss_fp: 0.500186, loss_freq: 0.501421
[00:59:57.008] iteration 766: loss: 0.928006, loss_s1: 0.506424, loss_fp: 0.500623, loss_freq: 0.502922
[00:59:57.663] iteration 767: loss: 0.923007, loss_s1: 0.506658, loss_fp: 0.500512, loss_freq: 0.500496
[00:59:58.324] iteration 768: loss: 0.911791, loss_s1: 0.502383, loss_fp: 0.500152, loss_freq: 0.502272
[00:59:58.991] iteration 769: loss: 0.905757, loss_s1: 0.506804, loss_fp: 0.500291, loss_freq: 0.502741
[00:59:59.664] iteration 770: loss: 0.918654, loss_s1: 0.504625, loss_fp: 0.500102, loss_freq: 0.501355
[01:00:00.331] iteration 771: loss: 0.879010, loss_s1: 0.504119, loss_fp: 0.500049, loss_freq: 0.502103
[01:00:01.013] iteration 772: loss: 0.866733, loss_s1: 0.503302, loss_fp: 0.500801, loss_freq: 0.502474
[01:00:01.665] iteration 773: loss: 0.953580, loss_s1: 0.506818, loss_fp: 0.500084, loss_freq: 0.502189
[01:00:02.287] iteration 774: loss: 0.928970, loss_s1: 0.506146, loss_fp: 0.500283, loss_freq: 0.501285
[01:00:02.905] iteration 775: loss: 0.904947, loss_s1: 0.502405, loss_fp: 0.500335, loss_freq: 0.501120
[01:00:03.521] iteration 776: loss: 0.894086, loss_s1: 0.501614, loss_fp: 0.500555, loss_freq: 0.500241
[01:00:04.144] iteration 777: loss: 0.892577, loss_s1: 0.504590, loss_fp: 0.500061, loss_freq: 0.500297
[01:00:04.768] iteration 778: loss: 0.914131, loss_s1: 0.502159, loss_fp: 0.500069, loss_freq: 0.502294
[01:00:05.387] iteration 779: loss: 0.901321, loss_s1: 0.505427, loss_fp: 0.500174, loss_freq: 0.500440
[01:00:05.995] iteration 780: loss: 0.897903, loss_s1: 0.505110, loss_fp: 0.500111, loss_freq: 0.501083
[01:00:06.607] iteration 781: loss: 0.858379, loss_s1: 0.504898, loss_fp: 0.500297, loss_freq: 0.505865
[01:00:07.215] iteration 782: loss: 1.007918, loss_s1: 0.504898, loss_fp: 0.500127, loss_freq: 0.503285
[01:00:07.828] iteration 783: loss: 0.946223, loss_s1: 0.501735, loss_fp: 0.500141, loss_freq: 0.500307
[01:00:08.441] iteration 784: loss: 0.935723, loss_s1: 0.503656, loss_fp: 0.500062, loss_freq: 0.502403
[01:00:09.052] iteration 785: loss: 0.900879, loss_s1: 0.504756, loss_fp: 0.500147, loss_freq: 0.501189
[01:00:09.673] iteration 786: loss: 0.891530, loss_s1: 0.504932, loss_fp: 0.500073, loss_freq: 0.500734
[01:00:10.293] iteration 787: loss: 0.885100, loss_s1: 0.504502, loss_fp: 0.500337, loss_freq: 0.500921
[01:00:10.914] iteration 788: loss: 0.911625, loss_s1: 0.505031, loss_fp: 0.500088, loss_freq: 0.501088
[01:00:11.533] iteration 789: loss: 0.895188, loss_s1: 0.506225, loss_fp: 0.500118, loss_freq: 0.504317
[01:00:12.147] iteration 790: loss: 0.888109, loss_s1: 0.502627, loss_fp: 0.500394, loss_freq: 0.501282
[01:00:12.782] iteration 791: loss: 0.958754, loss_s1: 0.503924, loss_fp: 0.500091, loss_freq: 0.502396
[01:00:13.426] iteration 792: loss: 0.904980, loss_s1: 0.504947, loss_fp: 0.500128, loss_freq: 0.501601
[01:00:14.078] iteration 793: loss: 0.939709, loss_s1: 0.504661, loss_fp: 0.500134, loss_freq: 0.501030
[01:00:14.694] iteration 794: loss: 0.928327, loss_s1: 0.505938, loss_fp: 0.500216, loss_freq: 0.503118
[01:00:15.308] iteration 795: loss: 0.918972, loss_s1: 0.508921, loss_fp: 0.500161, loss_freq: 0.504032
[01:00:15.925] iteration 796: loss: 0.879071, loss_s1: 0.505996, loss_fp: 0.500121, loss_freq: 0.502319
[01:00:16.542] iteration 797: loss: 0.914923, loss_s1: 0.502306, loss_fp: 0.500428, loss_freq: 0.501711
[01:00:17.158] iteration 798: loss: 0.879477, loss_s1: 0.503494, loss_fp: 0.500057, loss_freq: 0.500523
[01:00:17.782] iteration 799: loss: 0.915093, loss_s1: 0.507322, loss_fp: 0.500152, loss_freq: 0.502850
[01:00:18.405] iteration 800: loss: 0.910675, loss_s1: 0.504438, loss_fp: 0.500118, loss_freq: 0.503570
[01:00:21.455] iteration 800 : mean_dice : 0.172297
[01:00:22.240] iteration 801: loss: 0.889193, loss_s1: 0.490925, loss_fp: 0.500257, loss_freq: 0.500414
[01:00:22.916] iteration 802: loss: 0.929175, loss_s1: 0.500947, loss_fp: 0.500149, loss_freq: 0.500742
[01:00:23.642] iteration 803: loss: 0.886652, loss_s1: 0.504843, loss_fp: 0.500289, loss_freq: 0.502563
[01:00:24.298] iteration 804: loss: 0.879256, loss_s1: 0.502881, loss_fp: 0.500087, loss_freq: 0.502935
[01:00:24.957] iteration 805: loss: 0.913198, loss_s1: 0.504580, loss_fp: 0.500091, loss_freq: 0.500459
[01:00:25.564] iteration 806: loss: 0.916105, loss_s1: 0.501695, loss_fp: 0.500067, loss_freq: 0.500535
[01:00:26.174] iteration 807: loss: 0.879340, loss_s1: 0.503281, loss_fp: 0.500108, loss_freq: 0.504318
[01:00:26.788] iteration 808: loss: 0.913842, loss_s1: 0.506033, loss_fp: 0.500036, loss_freq: 0.502789
[01:00:27.400] iteration 809: loss: 0.898284, loss_s1: 0.502250, loss_fp: 0.500335, loss_freq: 0.502648
[01:00:28.010] iteration 810: loss: 0.905872, loss_s1: 0.502424, loss_fp: 0.500167, loss_freq: 0.502811
[01:00:28.644] iteration 811: loss: 0.899552, loss_s1: 0.505056, loss_fp: 0.500523, loss_freq: 0.500671
[01:00:29.292] iteration 812: loss: 0.909671, loss_s1: 0.502036, loss_fp: 0.500124, loss_freq: 0.501118
[01:00:29.913] iteration 813: loss: 0.902122, loss_s1: 0.502883, loss_fp: 0.500671, loss_freq: 0.501646
[01:00:30.585] iteration 814: loss: 0.929312, loss_s1: 0.503756, loss_fp: 0.500069, loss_freq: 0.500496
[01:00:31.209] iteration 815: loss: 0.890357, loss_s1: 0.503961, loss_fp: 0.500052, loss_freq: 0.502462
[01:00:31.827] iteration 816: loss: 0.871535, loss_s1: 0.506021, loss_fp: 0.500113, loss_freq: 0.503212
[01:00:32.473] iteration 817: loss: 0.952138, loss_s1: 0.504219, loss_fp: 0.500043, loss_freq: 0.502315
[01:00:33.095] iteration 818: loss: 0.906856, loss_s1: 0.502143, loss_fp: 0.500137, loss_freq: 0.501175
[01:00:33.715] iteration 819: loss: 0.932031, loss_s1: 0.501280, loss_fp: 0.500219, loss_freq: 0.502694
[01:00:34.331] iteration 820: loss: 0.904205, loss_s1: 0.506764, loss_fp: 0.500183, loss_freq: 0.500656
[01:00:34.942] iteration 821: loss: 0.889982, loss_s1: 0.504972, loss_fp: 0.500136, loss_freq: 0.501772
[01:00:35.559] iteration 822: loss: 0.894125, loss_s1: 0.506388, loss_fp: 0.500083, loss_freq: 0.501729
[01:00:36.173] iteration 823: loss: 0.877049, loss_s1: 0.507927, loss_fp: 0.500171, loss_freq: 0.504730
[01:00:36.791] iteration 824: loss: 0.903010, loss_s1: 0.506352, loss_fp: 0.500206, loss_freq: 0.501242
[01:00:37.411] iteration 825: loss: 0.875351, loss_s1: 0.506745, loss_fp: 0.501929, loss_freq: 0.504401
[01:00:38.029] iteration 826: loss: 0.957838, loss_s1: 0.505885, loss_fp: 0.500865, loss_freq: 0.503801
[01:00:38.649] iteration 827: loss: 0.962017, loss_s1: 0.502245, loss_fp: 0.500123, loss_freq: 0.500937
[01:00:39.265] iteration 828: loss: 0.915689, loss_s1: 0.505579, loss_fp: 0.500047, loss_freq: 0.500846
[01:00:39.878] iteration 829: loss: 0.898841, loss_s1: 0.503877, loss_fp: 0.500111, loss_freq: 0.501149
[01:00:40.489] iteration 830: loss: 0.910731, loss_s1: 0.502969, loss_fp: 0.500243, loss_freq: 0.502667
[01:00:41.113] iteration 831: loss: 0.894244, loss_s1: 0.504572, loss_fp: 0.500086, loss_freq: 0.501822
[01:00:41.763] iteration 832: loss: 0.929342, loss_s1: 0.502227, loss_fp: 0.500098, loss_freq: 0.502032
[01:00:42.414] iteration 833: loss: 0.913074, loss_s1: 0.504119, loss_fp: 0.500139, loss_freq: 0.500827
[01:00:43.066] iteration 834: loss: 0.918169, loss_s1: 0.503863, loss_fp: 0.500148, loss_freq: 0.501729
[01:00:43.699] iteration 835: loss: 0.985602, loss_s1: 0.501517, loss_fp: 0.500119, loss_freq: 0.501863
[01:00:44.320] iteration 836: loss: 0.899860, loss_s1: 0.505963, loss_fp: 0.500084, loss_freq: 0.501370
[01:00:44.937] iteration 837: loss: 0.900073, loss_s1: 0.504810, loss_fp: 0.500068, loss_freq: 0.503323
[01:00:45.554] iteration 838: loss: 0.896868, loss_s1: 0.509856, loss_fp: 0.500127, loss_freq: 0.501142
[01:00:46.173] iteration 839: loss: 0.866579, loss_s1: 0.504127, loss_fp: 0.500038, loss_freq: 0.502911
[01:00:46.795] iteration 840: loss: 0.927347, loss_s1: 0.504388, loss_fp: 0.500104, loss_freq: 0.500457
[01:00:47.413] iteration 841: loss: 0.886089, loss_s1: 0.503314, loss_fp: 0.500076, loss_freq: 0.500547
[01:00:48.024] iteration 842: loss: 0.849774, loss_s1: 0.501121, loss_fp: 0.500022, loss_freq: 0.500461
[01:00:48.641] iteration 843: loss: 0.941682, loss_s1: 0.506259, loss_fp: 0.500114, loss_freq: 0.503949
[01:00:49.259] iteration 844: loss: 0.885013, loss_s1: 0.503294, loss_fp: 0.500101, loss_freq: 0.501470
[01:00:49.955] iteration 845: loss: 0.884373, loss_s1: 0.502981, loss_fp: 0.500035, loss_freq: 0.500300
[01:00:50.609] iteration 846: loss: 0.866563, loss_s1: 0.505211, loss_fp: 0.500234, loss_freq: 0.500336
[01:00:51.255] iteration 847: loss: 0.876624, loss_s1: 0.503496, loss_fp: 0.500087, loss_freq: 0.501630
[01:00:51.900] iteration 848: loss: 0.889371, loss_s1: 0.504658, loss_fp: 0.500336, loss_freq: 0.500726
[01:00:52.511] iteration 849: loss: 0.897755, loss_s1: 0.505639, loss_fp: 0.500105, loss_freq: 0.500994
[01:00:53.117] iteration 850: loss: 0.885249, loss_s1: 0.508676, loss_fp: 0.500219, loss_freq: 0.506909
[01:00:54.084] iteration 851: loss: 0.918772, loss_s1: 0.505095, loss_fp: 0.500311, loss_freq: 0.501430
[01:00:54.697] iteration 852: loss: 0.877054, loss_s1: 0.505581, loss_fp: 0.500435, loss_freq: 0.502191
[01:00:55.312] iteration 853: loss: 0.891880, loss_s1: 0.501270, loss_fp: 0.500420, loss_freq: 0.500327
[01:00:55.933] iteration 854: loss: 0.882703, loss_s1: 0.501152, loss_fp: 0.500029, loss_freq: 0.502045
[01:00:56.552] iteration 855: loss: 0.901342, loss_s1: 0.508675, loss_fp: 0.500105, loss_freq: 0.500626
[01:00:57.167] iteration 856: loss: 0.911969, loss_s1: 0.506890, loss_fp: 0.500053, loss_freq: 0.500981
[01:00:57.784] iteration 857: loss: 0.902859, loss_s1: 0.507594, loss_fp: 0.500115, loss_freq: 0.501365
[01:00:58.394] iteration 858: loss: 0.948985, loss_s1: 0.503154, loss_fp: 0.500258, loss_freq: 0.500422
[01:00:59.006] iteration 859: loss: 0.911349, loss_s1: 0.504973, loss_fp: 0.500060, loss_freq: 0.502743
[01:00:59.620] iteration 860: loss: 0.889927, loss_s1: 0.504253, loss_fp: 0.500789, loss_freq: 0.501153
[01:01:00.236] iteration 861: loss: 0.875194, loss_s1: 0.504200, loss_fp: 0.500148, loss_freq: 0.503685
[01:01:00.878] iteration 862: loss: 0.891169, loss_s1: 0.506302, loss_fp: 0.500073, loss_freq: 0.502947
[01:01:01.527] iteration 863: loss: 0.943696, loss_s1: 0.508579, loss_fp: 0.500368, loss_freq: 0.504032
[01:01:02.188] iteration 864: loss: 0.887483, loss_s1: 0.510908, loss_fp: 0.500111, loss_freq: 0.502435
[01:01:02.841] iteration 865: loss: 0.946926, loss_s1: 0.504566, loss_fp: 0.500037, loss_freq: 0.501462
[01:01:03.487] iteration 866: loss: 0.906637, loss_s1: 0.506419, loss_fp: 0.500072, loss_freq: 0.501387
[01:01:04.101] iteration 867: loss: 0.852479, loss_s1: 0.507469, loss_fp: 0.500421, loss_freq: 0.501225
[01:01:04.796] iteration 868: loss: 0.934431, loss_s1: 0.495555, loss_fp: 0.500182, loss_freq: 0.500860
[01:01:05.442] iteration 869: loss: 0.876253, loss_s1: 0.503120, loss_fp: 0.500236, loss_freq: 0.500503
[01:01:06.089] iteration 870: loss: 0.924870, loss_s1: 0.501876, loss_fp: 0.500092, loss_freq: 0.500748
[01:01:06.749] iteration 871: loss: 0.933668, loss_s1: 0.504900, loss_fp: 0.500164, loss_freq: 0.503167
[01:01:07.401] iteration 872: loss: 0.949739, loss_s1: 0.504014, loss_fp: 0.500147, loss_freq: 0.504464
[01:01:08.038] iteration 873: loss: 0.945061, loss_s1: 0.504977, loss_fp: 0.500167, loss_freq: 0.500580
[01:01:08.663] iteration 874: loss: 0.891070, loss_s1: 0.501920, loss_fp: 0.500100, loss_freq: 0.500977
[01:01:09.278] iteration 875: loss: 0.897340, loss_s1: 0.503510, loss_fp: 0.500070, loss_freq: 0.500354
[01:01:09.893] iteration 876: loss: 0.885322, loss_s1: 0.504161, loss_fp: 0.501362, loss_freq: 0.501018
[01:01:10.509] iteration 877: loss: 0.894613, loss_s1: 0.503943, loss_fp: 0.500191, loss_freq: 0.500345
[01:01:11.128] iteration 878: loss: 0.902624, loss_s1: 0.504468, loss_fp: 0.500076, loss_freq: 0.502580
[01:01:11.742] iteration 879: loss: 0.935471, loss_s1: 0.503528, loss_fp: 0.500293, loss_freq: 0.501610
[01:01:12.355] iteration 880: loss: 0.902098, loss_s1: 0.502709, loss_fp: 0.500144, loss_freq: 0.501202
[01:01:12.973] iteration 881: loss: 0.872218, loss_s1: 0.504241, loss_fp: 0.502195, loss_freq: 0.500664
[01:01:13.584] iteration 882: loss: 0.917621, loss_s1: 0.506204, loss_fp: 0.500322, loss_freq: 0.504313
[01:01:14.195] iteration 883: loss: 0.882548, loss_s1: 0.507608, loss_fp: 0.500865, loss_freq: 0.502055
[01:01:14.814] iteration 884: loss: 0.904783, loss_s1: 0.503412, loss_fp: 0.500207, loss_freq: 0.505020
[01:01:15.431] iteration 885: loss: 0.880297, loss_s1: 0.506651, loss_fp: 0.500234, loss_freq: 0.502381
[01:01:16.048] iteration 886: loss: 0.893609, loss_s1: 0.501136, loss_fp: 0.500333, loss_freq: 0.500658
[01:01:16.668] iteration 887: loss: 0.891810, loss_s1: 0.505581, loss_fp: 0.501194, loss_freq: 0.502069
[01:01:17.345] iteration 888: loss: 0.902215, loss_s1: 0.503600, loss_fp: 0.500183, loss_freq: 0.500933
[01:01:17.980] iteration 889: loss: 0.894978, loss_s1: 0.503260, loss_fp: 0.500220, loss_freq: 0.502233
[01:01:18.592] iteration 890: loss: 0.920824, loss_s1: 0.502470, loss_fp: 0.500041, loss_freq: 0.501360
[01:01:19.206] iteration 891: loss: 0.878277, loss_s1: 0.506017, loss_fp: 0.500292, loss_freq: 0.505643
[01:01:19.825] iteration 892: loss: 0.922133, loss_s1: 0.504119, loss_fp: 0.500099, loss_freq: 0.502851
[01:01:20.443] iteration 893: loss: 0.945660, loss_s1: 0.501781, loss_fp: 0.500225, loss_freq: 0.501841
[01:01:21.058] iteration 894: loss: 0.887527, loss_s1: 0.503783, loss_fp: 0.500333, loss_freq: 0.500651
[01:01:21.693] iteration 895: loss: 0.904353, loss_s1: 0.500293, loss_fp: 0.500146, loss_freq: 0.500915
[01:01:22.310] iteration 896: loss: 0.879931, loss_s1: 0.504365, loss_fp: 0.500200, loss_freq: 0.503382
[01:01:22.934] iteration 897: loss: 0.949053, loss_s1: 0.502855, loss_fp: 0.500336, loss_freq: 0.501607
[01:01:23.610] iteration 898: loss: 0.888011, loss_s1: 0.505182, loss_fp: 0.500257, loss_freq: 0.503730
[01:01:24.222] iteration 899: loss: 0.868633, loss_s1: 0.496849, loss_fp: 0.390804, loss_freq: 0.478909
[01:01:24.835] iteration 900: loss: 0.914609, loss_s1: 0.503362, loss_fp: 0.500018, loss_freq: 0.502212
[01:01:25.446] iteration 901: loss: 0.892677, loss_s1: 0.506602, loss_fp: 0.500197, loss_freq: 0.502058
[01:01:26.056] iteration 902: loss: 0.888167, loss_s1: 0.503899, loss_fp: 0.500104, loss_freq: 0.500454
[01:01:26.671] iteration 903: loss: 0.932423, loss_s1: 0.503987, loss_fp: 0.500028, loss_freq: 0.504991
[01:01:27.285] iteration 904: loss: 0.884125, loss_s1: 0.502886, loss_fp: 0.500108, loss_freq: 0.502215
[01:01:27.906] iteration 905: loss: 0.941564, loss_s1: 0.501907, loss_fp: 0.500019, loss_freq: 0.500899
[01:01:28.573] iteration 906: loss: 0.885711, loss_s1: 0.505582, loss_fp: 0.500096, loss_freq: 0.500366
[01:01:29.204] iteration 907: loss: 0.876142, loss_s1: 0.501527, loss_fp: 0.500106, loss_freq: 0.501627
[01:01:29.821] iteration 908: loss: 0.968478, loss_s1: 0.504320, loss_fp: 0.500023, loss_freq: 0.503642
[01:01:30.434] iteration 909: loss: 0.927583, loss_s1: 0.501096, loss_fp: 0.500052, loss_freq: 0.501088
[01:01:31.048] iteration 910: loss: 0.880534, loss_s1: 0.503913, loss_fp: 0.500030, loss_freq: 0.504207
[01:01:31.655] iteration 911: loss: 0.900072, loss_s1: 0.503021, loss_fp: 0.500207, loss_freq: 0.500839
[01:01:32.267] iteration 912: loss: 0.886478, loss_s1: 0.503280, loss_fp: 0.500038, loss_freq: 0.501263
[01:01:32.880] iteration 913: loss: 0.900836, loss_s1: 0.489548, loss_fp: 0.500056, loss_freq: 0.500960
[01:01:33.500] iteration 914: loss: 0.896019, loss_s1: 0.502391, loss_fp: 0.500046, loss_freq: 0.501025
[01:01:34.127] iteration 915: loss: 0.896109, loss_s1: 0.505324, loss_fp: 0.500052, loss_freq: 0.503649
[01:01:34.743] iteration 916: loss: 0.856538, loss_s1: 0.505990, loss_fp: 0.500024, loss_freq: 0.503084
[01:01:35.357] iteration 917: loss: 0.940562, loss_s1: 0.505854, loss_fp: 0.500028, loss_freq: 0.501282
[01:01:35.968] iteration 918: loss: 0.871187, loss_s1: 0.506056, loss_fp: 0.500104, loss_freq: 0.501762
[01:01:36.580] iteration 919: loss: 0.893344, loss_s1: 0.501187, loss_fp: 0.500045, loss_freq: 0.500987
[01:01:37.214] iteration 920: loss: 0.897345, loss_s1: 0.505081, loss_fp: 0.500038, loss_freq: 0.501244
[01:01:37.829] iteration 921: loss: 0.895629, loss_s1: 0.501604, loss_fp: 0.500194, loss_freq: 0.501414
[01:01:38.447] iteration 922: loss: 0.883476, loss_s1: 0.502798, loss_fp: 0.500072, loss_freq: 0.501063
[01:01:39.123] iteration 923: loss: 0.920166, loss_s1: 0.505980, loss_fp: 0.500070, loss_freq: 0.500503
[01:01:39.741] iteration 924: loss: 0.874130, loss_s1: 0.503275, loss_fp: 0.500049, loss_freq: 0.502863
[01:01:40.377] iteration 925: loss: 0.871219, loss_s1: 0.502017, loss_fp: 0.500254, loss_freq: 0.500909
[01:01:40.996] iteration 926: loss: 0.900916, loss_s1: 0.504043, loss_fp: 0.500039, loss_freq: 0.501165
[01:01:41.611] iteration 927: loss: 0.917339, loss_s1: 0.503910, loss_fp: 0.500063, loss_freq: 0.501428
[01:01:42.224] iteration 928: loss: 0.929258, loss_s1: 0.506079, loss_fp: 0.500129, loss_freq: 0.501378
[01:01:42.895] iteration 929: loss: 0.905332, loss_s1: 0.506034, loss_fp: 0.500115, loss_freq: 0.500921
[01:01:43.708] iteration 930: loss: 0.894046, loss_s1: 0.507758, loss_fp: 0.500231, loss_freq: 0.502373
[01:01:44.616] iteration 931: loss: 0.899743, loss_s1: 0.506268, loss_fp: 0.500071, loss_freq: 0.503955
[01:01:45.280] iteration 932: loss: 0.894665, loss_s1: 0.506415, loss_fp: 0.500056, loss_freq: 0.501468
[01:01:45.949] iteration 933: loss: 0.902275, loss_s1: 0.503651, loss_fp: 0.500116, loss_freq: 0.500667
[01:01:46.606] iteration 934: loss: 0.922040, loss_s1: 0.504135, loss_fp: 0.501380, loss_freq: 0.501497
[01:01:47.279] iteration 935: loss: 0.917792, loss_s1: 0.509518, loss_fp: 0.500128, loss_freq: 0.504149
[01:01:47.936] iteration 936: loss: 0.887290, loss_s1: 0.507146, loss_fp: 0.500057, loss_freq: 0.502305
[01:01:48.588] iteration 937: loss: 0.834241, loss_s1: 0.502326, loss_fp: 0.500164, loss_freq: 0.500199
[01:01:49.241] iteration 938: loss: 0.896034, loss_s1: 0.504503, loss_fp: 0.500028, loss_freq: 0.503311
[01:01:49.893] iteration 939: loss: 0.877633, loss_s1: 0.505786, loss_fp: 0.500060, loss_freq: 0.503618
[01:01:50.547] iteration 940: loss: 0.950558, loss_s1: 0.505340, loss_fp: 0.500027, loss_freq: 0.501391
[01:01:51.194] iteration 941: loss: 0.895294, loss_s1: 0.506296, loss_fp: 0.500427, loss_freq: 0.501468
[01:01:52.076] iteration 942: loss: 0.872336, loss_s1: 0.505110, loss_fp: 0.500162, loss_freq: 0.503548
[01:01:52.921] iteration 943: loss: 0.947824, loss_s1: 0.510630, loss_fp: 0.500249, loss_freq: 0.503384
[01:01:53.556] iteration 944: loss: 0.878396, loss_s1: 0.504054, loss_fp: 0.500054, loss_freq: 0.501005
[01:01:54.204] iteration 945: loss: 0.889117, loss_s1: 0.503342, loss_fp: 0.500064, loss_freq: 0.500413
[01:01:54.881] iteration 946: loss: 0.913035, loss_s1: 0.501140, loss_fp: 0.500069, loss_freq: 0.500304
[01:01:55.520] iteration 947: loss: 0.921885, loss_s1: 0.502649, loss_fp: 0.500077, loss_freq: 0.500836
[01:01:56.160] iteration 948: loss: 0.869780, loss_s1: 0.504845, loss_fp: 0.500025, loss_freq: 0.503621
[01:01:56.798] iteration 949: loss: 0.890819, loss_s1: 0.484403, loss_fp: 0.500071, loss_freq: 0.500249
[01:01:57.435] iteration 950: loss: 0.888075, loss_s1: 0.505235, loss_fp: 0.500035, loss_freq: 0.500496
[01:01:58.083] iteration 951: loss: 0.892289, loss_s1: 0.509096, loss_fp: 0.500164, loss_freq: 0.502351
[01:01:58.727] iteration 952: loss: 0.963821, loss_s1: 0.505154, loss_fp: 0.500012, loss_freq: 0.501559
[01:01:59.374] iteration 953: loss: 0.875439, loss_s1: 0.501621, loss_fp: 0.500036, loss_freq: 0.500199
[01:02:00.071] iteration 954: loss: 0.906222, loss_s1: 0.502087, loss_fp: 0.500455, loss_freq: 0.501422
[01:02:00.743] iteration 955: loss: 0.870449, loss_s1: 0.502563, loss_fp: 0.500116, loss_freq: 0.501464
[01:02:01.413] iteration 956: loss: 0.910279, loss_s1: 0.506641, loss_fp: 0.500061, loss_freq: 0.500598
[01:02:02.074] iteration 957: loss: 0.890032, loss_s1: 0.503839, loss_fp: 0.500080, loss_freq: 0.500642
[01:02:02.729] iteration 958: loss: 0.961297, loss_s1: 0.507181, loss_fp: 0.500044, loss_freq: 0.501111
[01:02:03.368] iteration 959: loss: 0.900864, loss_s1: 0.509380, loss_fp: 0.500088, loss_freq: 0.504075
[01:02:04.043] iteration 960: loss: 0.895284, loss_s1: 0.511034, loss_fp: 0.500057, loss_freq: 0.500594
[01:02:04.712] iteration 961: loss: 0.933445, loss_s1: 0.503814, loss_fp: 0.500072, loss_freq: 0.501489
[01:02:05.429] iteration 962: loss: 0.861573, loss_s1: 0.504108, loss_fp: 0.500101, loss_freq: 0.500722
[01:02:06.124] iteration 963: loss: 0.902863, loss_s1: 0.503735, loss_fp: 0.500042, loss_freq: 0.500300
[01:02:06.789] iteration 964: loss: 0.901260, loss_s1: 0.515074, loss_fp: 0.500119, loss_freq: 0.501653
[01:02:07.474] iteration 965: loss: 0.889239, loss_s1: 0.504780, loss_fp: 0.500175, loss_freq: 0.505505
[01:02:08.166] iteration 966: loss: 0.900177, loss_s1: 0.503397, loss_fp: 0.500069, loss_freq: 0.502670
[01:02:08.862] iteration 967: loss: 0.890032, loss_s1: 0.504411, loss_fp: 0.500343, loss_freq: 0.501630
[01:02:09.552] iteration 968: loss: 0.862150, loss_s1: 0.502582, loss_fp: 0.500219, loss_freq: 0.500666
[01:02:10.256] iteration 969: loss: 0.859817, loss_s1: 0.505438, loss_fp: 0.500028, loss_freq: 0.502954
[01:02:10.982] iteration 970: loss: 0.922346, loss_s1: 0.507661, loss_fp: 0.500048, loss_freq: 0.503448
[01:02:11.651] iteration 971: loss: 0.847592, loss_s1: 0.367605, loss_fp: 0.500073, loss_freq: 0.500379
[01:02:12.314] iteration 972: loss: 0.881335, loss_s1: 0.502236, loss_fp: 0.500149, loss_freq: 0.500553
[01:02:12.984] iteration 973: loss: 0.880259, loss_s1: 0.506010, loss_fp: 0.500107, loss_freq: 0.503549
[01:02:13.634] iteration 974: loss: 0.881440, loss_s1: 0.506571, loss_fp: 0.500216, loss_freq: 0.502113
[01:02:14.298] iteration 975: loss: 0.909312, loss_s1: 0.502500, loss_fp: 0.500167, loss_freq: 0.500988
[01:02:14.954] iteration 976: loss: 0.916098, loss_s1: 0.500418, loss_fp: 0.500043, loss_freq: 0.500541
[01:02:15.641] iteration 977: loss: 0.882115, loss_s1: 0.502819, loss_fp: 0.500068, loss_freq: 0.505116
[01:02:16.285] iteration 978: loss: 0.942607, loss_s1: 0.504127, loss_fp: 0.500037, loss_freq: 0.505568
[01:02:16.972] iteration 979: loss: 0.892466, loss_s1: 0.505690, loss_fp: 0.500091, loss_freq: 0.504105
[01:02:17.643] iteration 980: loss: 0.879457, loss_s1: 0.503066, loss_fp: 0.500182, loss_freq: 0.502618
[01:02:18.292] iteration 981: loss: 0.889741, loss_s1: 0.502849, loss_fp: 0.500049, loss_freq: 0.500445
[01:02:18.948] iteration 982: loss: 0.902093, loss_s1: 0.502487, loss_fp: 0.500078, loss_freq: 0.500556
[01:02:19.611] iteration 983: loss: 0.901639, loss_s1: 0.502405, loss_fp: 0.500178, loss_freq: 0.500719
[01:02:20.276] iteration 984: loss: 0.941051, loss_s1: 0.504638, loss_fp: 0.500106, loss_freq: 0.501094
[01:02:20.934] iteration 985: loss: 0.866588, loss_s1: 0.503212, loss_fp: 0.500123, loss_freq: 0.501038
[01:02:21.597] iteration 986: loss: 0.868314, loss_s1: 0.509946, loss_fp: 0.500020, loss_freq: 0.502916
[01:02:22.241] iteration 987: loss: 0.943956, loss_s1: 0.501612, loss_fp: 0.500097, loss_freq: 0.501576
[01:02:22.910] iteration 988: loss: 0.861569, loss_s1: 0.503863, loss_fp: 0.500092, loss_freq: 0.501373
[01:02:23.581] iteration 989: loss: 0.912300, loss_s1: 0.502298, loss_fp: 0.501043, loss_freq: 0.501682
[01:02:24.312] iteration 990: loss: 0.878131, loss_s1: 0.504287, loss_fp: 0.500180, loss_freq: 0.503391
[01:02:25.204] iteration 991: loss: 0.893113, loss_s1: 0.507843, loss_fp: 0.500187, loss_freq: 0.501357
[01:02:25.928] iteration 992: loss: 0.901814, loss_s1: 0.507751, loss_fp: 0.500030, loss_freq: 0.503274
[01:02:26.934] iteration 993: loss: 0.909448, loss_s1: 0.504384, loss_fp: 0.500219, loss_freq: 0.504720
[01:02:27.845] iteration 994: loss: 0.884350, loss_s1: 0.504871, loss_fp: 0.500734, loss_freq: 0.502130
[01:02:28.690] iteration 995: loss: 0.889274, loss_s1: 0.503251, loss_fp: 0.500378, loss_freq: 0.504503
[01:02:29.384] iteration 996: loss: 0.973215, loss_s1: 0.506264, loss_fp: 0.500024, loss_freq: 0.502215
[01:02:30.066] iteration 997: loss: 0.919660, loss_s1: 0.503106, loss_fp: 0.500430, loss_freq: 0.500405
[01:02:30.738] iteration 998: loss: 0.910892, loss_s1: 0.502267, loss_fp: 0.500055, loss_freq: 0.500479
[01:02:31.422] iteration 999: loss: 0.908214, loss_s1: 0.504687, loss_fp: 0.500030, loss_freq: 0.500311
[01:02:32.106] iteration 1000: loss: 0.938703, loss_s1: 0.502473, loss_fp: 0.500028, loss_freq: 0.501753
[01:02:34.543] iteration 1000 : mean_dice : 0.103653
[01:02:35.319] iteration 1001: loss: 0.885945, loss_s1: 0.502615, loss_fp: 0.500095, loss_freq: 0.500812
[01:02:36.096] iteration 1002: loss: 0.900043, loss_s1: 0.502342, loss_fp: 0.500515, loss_freq: 0.500921
[01:02:36.828] iteration 1003: loss: 0.910402, loss_s1: 0.503529, loss_fp: 0.500156, loss_freq: 0.501641
[01:02:37.502] iteration 1004: loss: 0.886698, loss_s1: 0.502371, loss_fp: 0.500138, loss_freq: 0.501602
[01:02:38.212] iteration 1005: loss: 0.947364, loss_s1: 0.503199, loss_fp: 0.500168, loss_freq: 0.501889
[01:02:38.898] iteration 1006: loss: 0.917656, loss_s1: 0.504963, loss_fp: 0.500531, loss_freq: 0.500828
[01:02:39.578] iteration 1007: loss: 0.864328, loss_s1: 0.503884, loss_fp: 0.500102, loss_freq: 0.501346
[01:02:40.266] iteration 1008: loss: 0.868975, loss_s1: 0.503232, loss_fp: 0.500422, loss_freq: 0.501713
[01:02:40.938] iteration 1009: loss: 0.859698, loss_s1: 0.502647, loss_fp: 0.500025, loss_freq: 0.501302
[01:02:41.660] iteration 1010: loss: 0.914144, loss_s1: 0.503469, loss_fp: 0.500088, loss_freq: 0.500326
[01:02:42.379] iteration 1011: loss: 0.896291, loss_s1: 0.501025, loss_fp: 0.500043, loss_freq: 0.500328
[01:02:43.110] iteration 1012: loss: 0.870066, loss_s1: 0.501433, loss_fp: 0.500105, loss_freq: 0.500359
[01:02:43.862] iteration 1013: loss: 0.925473, loss_s1: 0.503389, loss_fp: 0.500210, loss_freq: 0.502513
[01:02:44.552] iteration 1014: loss: 0.863850, loss_s1: 0.500645, loss_fp: 0.500277, loss_freq: 0.501087
[01:02:45.241] iteration 1015: loss: 0.874309, loss_s1: 0.502777, loss_fp: 0.500039, loss_freq: 0.500349
[01:02:45.925] iteration 1016: loss: 0.820227, loss_s1: 0.497080, loss_fp: 0.487282, loss_freq: 0.452070
[01:02:46.604] iteration 1017: loss: 0.870763, loss_s1: 0.503113, loss_fp: 0.500052, loss_freq: 0.500758
[01:02:47.283] iteration 1018: loss: 0.878008, loss_s1: 0.505012, loss_fp: 0.500094, loss_freq: 0.501068
[01:02:47.945] iteration 1019: loss: 0.562845, loss_s1: 0.504743, loss_fp: 0.066730, loss_freq: 0.317541
[01:02:48.602] iteration 1020: loss: 0.883217, loss_s1: 0.508323, loss_fp: 0.500112, loss_freq: 0.504047
[01:02:49.610] iteration 1021: loss: 0.910799, loss_s1: 0.504663, loss_fp: 0.500049, loss_freq: 0.500376
[01:02:50.272] iteration 1022: loss: 0.886071, loss_s1: 0.502270, loss_fp: 0.500030, loss_freq: 0.503753
[01:02:50.926] iteration 1023: loss: 0.940260, loss_s1: 0.503763, loss_fp: 0.500012, loss_freq: 0.500875
[01:02:51.585] iteration 1024: loss: 0.950085, loss_s1: 0.504506, loss_fp: 0.500018, loss_freq: 0.503799
[01:02:52.233] iteration 1025: loss: 0.919444, loss_s1: 0.505600, loss_fp: 0.500021, loss_freq: 0.502009
[01:02:52.880] iteration 1026: loss: 0.914761, loss_s1: 0.504382, loss_fp: 0.500023, loss_freq: 0.503170
[01:02:53.538] iteration 1027: loss: 0.985645, loss_s1: 0.502419, loss_fp: 0.500014, loss_freq: 0.502668
[01:02:54.184] iteration 1028: loss: 0.941730, loss_s1: 0.501026, loss_fp: 0.500091, loss_freq: 0.500238
[01:02:54.849] iteration 1029: loss: 1.001002, loss_s1: 0.509442, loss_fp: 0.500010, loss_freq: 0.502476
[01:02:55.526] iteration 1030: loss: 0.901596, loss_s1: 0.503254, loss_fp: 0.500029, loss_freq: 0.500633
[01:02:56.205] iteration 1031: loss: 0.869004, loss_s1: 0.502563, loss_fp: 0.500062, loss_freq: 0.501763
[01:02:56.877] iteration 1032: loss: 0.904420, loss_s1: 0.505244, loss_fp: 0.500026, loss_freq: 0.502903
[01:02:57.560] iteration 1033: loss: 0.888710, loss_s1: 0.508014, loss_fp: 0.500041, loss_freq: 0.502894
[01:02:58.225] iteration 1034: loss: 0.901414, loss_s1: 0.505672, loss_fp: 0.500062, loss_freq: 0.502213
[01:02:58.936] iteration 1035: loss: 1.008078, loss_s1: 0.502303, loss_fp: 0.500043, loss_freq: 0.500512
[01:02:59.625] iteration 1036: loss: 0.906360, loss_s1: 0.504351, loss_fp: 0.500376, loss_freq: 0.502645
[01:03:00.305] iteration 1037: loss: 0.881700, loss_s1: 0.503894, loss_fp: 0.500043, loss_freq: 0.500488
[01:03:00.996] iteration 1038: loss: 0.919659, loss_s1: 0.501117, loss_fp: 0.500019, loss_freq: 0.500334
[01:03:01.691] iteration 1039: loss: 0.881780, loss_s1: 0.503483, loss_fp: 0.500043, loss_freq: 0.500529
[01:03:02.384] iteration 1040: loss: 0.915040, loss_s1: 0.501033, loss_fp: 0.500059, loss_freq: 0.500400
[01:03:03.075] iteration 1041: loss: 0.906573, loss_s1: 0.503218, loss_fp: 0.500017, loss_freq: 0.502506
[01:03:03.743] iteration 1042: loss: 0.935055, loss_s1: 0.508327, loss_fp: 0.500037, loss_freq: 0.502262
[01:03:04.410] iteration 1043: loss: 0.903092, loss_s1: 0.504646, loss_fp: 0.500053, loss_freq: 0.500818
[01:03:05.078] iteration 1044: loss: 0.896552, loss_s1: 0.505344, loss_fp: 0.500043, loss_freq: 0.500965
[01:03:05.743] iteration 1045: loss: 0.869847, loss_s1: 0.500512, loss_fp: 0.500038, loss_freq: 0.500428
[01:03:06.401] iteration 1046: loss: 0.878946, loss_s1: 0.504454, loss_fp: 0.500109, loss_freq: 0.500796
[01:03:07.066] iteration 1047: loss: 0.866791, loss_s1: 0.501075, loss_fp: 0.500592, loss_freq: 0.500278
[01:03:07.756] iteration 1048: loss: 0.856709, loss_s1: 0.504240, loss_fp: 0.500081, loss_freq: 0.501473
[01:03:08.444] iteration 1049: loss: 0.897850, loss_s1: 0.504818, loss_fp: 0.500131, loss_freq: 0.500922
[01:03:09.119] iteration 1050: loss: 0.962515, loss_s1: 0.503771, loss_fp: 0.500289, loss_freq: 0.501103
[01:03:09.835] iteration 1051: loss: 0.869189, loss_s1: 0.501936, loss_fp: 0.500020, loss_freq: 0.500266
[01:03:10.583] iteration 1052: loss: 0.954552, loss_s1: 0.505955, loss_fp: 0.500025, loss_freq: 0.503638
[01:03:11.297] iteration 1053: loss: 0.914301, loss_s1: 0.507952, loss_fp: 0.500080, loss_freq: 0.504535
[01:03:12.127] iteration 1054: loss: 0.957537, loss_s1: 0.507603, loss_fp: 0.500455, loss_freq: 0.502547
[01:03:13.192] iteration 1055: loss: 0.888955, loss_s1: 0.502272, loss_fp: 0.500081, loss_freq: 0.501296
[01:03:14.124] iteration 1056: loss: 0.868493, loss_s1: 0.500631, loss_fp: 0.500176, loss_freq: 0.500373
[01:03:19.743] iteration 1057: loss: 0.884998, loss_s1: 0.502718, loss_fp: 0.500044, loss_freq: 0.500855
[01:03:40.575] iteration 1058: loss: 0.868136, loss_s1: 0.503976, loss_fp: 0.500176, loss_freq: 0.500397
[01:04:01.343] iteration 1059: loss: 0.888166, loss_s1: 0.506056, loss_fp: 0.500097, loss_freq: 0.502285
[01:04:22.218] iteration 1060: loss: 0.862872, loss_s1: 0.508486, loss_fp: 0.500088, loss_freq: 0.501146
[01:04:43.119] iteration 1061: loss: 0.907624, loss_s1: 0.506159, loss_fp: 0.500037, loss_freq: 0.504352
[01:05:03.945] iteration 1062: loss: 0.905083, loss_s1: 0.507824, loss_fp: 0.500040, loss_freq: 0.504049
[01:05:24.898] iteration 1063: loss: 0.885274, loss_s1: 0.505962, loss_fp: 0.500064, loss_freq: 0.500968
[01:05:45.077] iteration 1064: loss: 0.879225, loss_s1: 0.504143, loss_fp: 0.500105, loss_freq: 0.502186
[01:06:06.043] iteration 1065: loss: 0.885360, loss_s1: 0.504649, loss_fp: 0.500087, loss_freq: 0.501269
[01:06:26.921] iteration 1066: loss: 0.886834, loss_s1: 0.500882, loss_fp: 0.500125, loss_freq: 0.500555
[01:06:47.892] iteration 1067: loss: 0.911634, loss_s1: 0.502393, loss_fp: 0.500089, loss_freq: 0.500655
[01:07:08.774] iteration 1068: loss: 0.879723, loss_s1: 0.505021, loss_fp: 0.500105, loss_freq: 0.500830
[01:07:29.741] iteration 1069: loss: 0.882098, loss_s1: 0.501402, loss_fp: 0.500096, loss_freq: 0.500803
[01:07:50.707] iteration 1070: loss: 0.931257, loss_s1: 0.503950, loss_fp: 0.500019, loss_freq: 0.504613
[01:08:11.551] iteration 1071: loss: 0.851494, loss_s1: 0.504188, loss_fp: 0.500034, loss_freq: 0.500762
[01:08:32.511] iteration 1072: loss: 0.854942, loss_s1: 0.501941, loss_fp: 0.500067, loss_freq: 0.500422
[01:08:53.395] iteration 1073: loss: 0.887094, loss_s1: 0.503262, loss_fp: 0.500136, loss_freq: 0.504331
[01:09:14.357] iteration 1074: loss: 0.859527, loss_s1: 0.504378, loss_fp: 0.500497, loss_freq: 0.503508
[01:09:35.226] iteration 1075: loss: 0.922334, loss_s1: 0.504823, loss_fp: 0.500296, loss_freq: 0.502205
[01:09:56.199] iteration 1076: loss: 0.887314, loss_s1: 0.502528, loss_fp: 0.500031, loss_freq: 0.500567
[01:10:17.083] iteration 1077: loss: 0.867843, loss_s1: 0.504049, loss_fp: 0.500078, loss_freq: 0.500896
[01:10:38.043] iteration 1078: loss: 0.965464, loss_s1: 0.505907, loss_fp: 0.500090, loss_freq: 0.501410
[01:10:59.000] iteration 1079: loss: 0.899832, loss_s1: 0.501726, loss_fp: 0.500092, loss_freq: 0.500877
[01:11:19.882] iteration 1080: loss: 0.879409, loss_s1: 0.502419, loss_fp: 0.500073, loss_freq: 0.501019
[01:11:40.855] iteration 1081: loss: 0.914831, loss_s1: 0.503504, loss_fp: 0.500158, loss_freq: 0.500580
[01:12:01.717] iteration 1082: loss: 0.903644, loss_s1: 0.506756, loss_fp: 0.500050, loss_freq: 0.500269
[01:12:22.683] iteration 1083: loss: 0.909273, loss_s1: 0.503758, loss_fp: 0.500020, loss_freq: 0.501101
[01:12:43.562] iteration 1084: loss: 0.895130, loss_s1: 0.500969, loss_fp: 0.500016, loss_freq: 0.500664
[01:13:04.521] iteration 1085: loss: 0.863254, loss_s1: 0.503937, loss_fp: 0.500218, loss_freq: 0.501598
[01:13:25.363] iteration 1086: loss: 0.854923, loss_s1: 0.503391, loss_fp: 0.500075, loss_freq: 0.501003
[01:13:46.337] iteration 1087: loss: 0.923234, loss_s1: 0.504105, loss_fp: 0.500083, loss_freq: 0.501634
[01:14:07.290] iteration 1088: loss: 0.886873, loss_s1: 0.501255, loss_fp: 0.500185, loss_freq: 0.501736
[01:14:28.172] iteration 1089: loss: 0.911333, loss_s1: 0.503803, loss_fp: 0.500134, loss_freq: 0.500950
[01:14:49.131] iteration 1090: loss: 0.875683, loss_s1: 0.501666, loss_fp: 0.500034, loss_freq: 0.500380
[01:15:10.022] iteration 1091: loss: 0.889528, loss_s1: 0.501561, loss_fp: 0.500041, loss_freq: 0.500474
[01:15:30.988] iteration 1092: loss: 0.883668, loss_s1: 0.501127, loss_fp: 0.500057, loss_freq: 0.500764
[01:15:51.863] iteration 1093: loss: 0.964986, loss_s1: 0.500616, loss_fp: 0.500055, loss_freq: 0.500516
[01:16:12.829] iteration 1094: loss: 0.880126, loss_s1: 0.502689, loss_fp: 0.500112, loss_freq: 0.500930
[01:16:33.778] iteration 1095: loss: 0.877347, loss_s1: 0.500714, loss_fp: 0.500069, loss_freq: 0.500521
[01:16:54.752] iteration 1096: loss: 0.895427, loss_s1: 0.502315, loss_fp: 0.500115, loss_freq: 0.500609
[01:17:15.704] iteration 1097: loss: 0.902876, loss_s1: 0.502821, loss_fp: 0.500029, loss_freq: 0.501161
[01:17:36.664] iteration 1098: loss: 0.859629, loss_s1: 0.503434, loss_fp: 0.500188, loss_freq: 0.502340
[01:17:57.620] iteration 1099: loss: 0.854556, loss_s1: 0.502864, loss_fp: 0.500045, loss_freq: 0.501502
[01:18:18.508] iteration 1100: loss: 0.871804, loss_s1: 0.502201, loss_fp: 0.500039, loss_freq: 0.501268
[01:18:39.470] iteration 1101: loss: 0.882142, loss_s1: 0.503229, loss_fp: 0.500194, loss_freq: 0.502624
[01:18:55.626] iteration 1102: loss: 0.882074, loss_s1: 0.502134, loss_fp: 0.500103, loss_freq: 0.501643
[01:18:56.297] iteration 1103: loss: 0.860868, loss_s1: 0.501313, loss_fp: 0.500013, loss_freq: 0.500831
[01:18:56.994] iteration 1104: loss: 0.892293, loss_s1: 0.501750, loss_fp: 0.500063, loss_freq: 0.500997
[01:18:58.445] iteration 1105: loss: 0.917049, loss_s1: 0.504749, loss_fp: 0.500125, loss_freq: 0.503190
[01:18:59.855] iteration 1106: loss: 0.884733, loss_s1: 0.504674, loss_fp: 0.500035, loss_freq: 0.501525
[01:19:00.548] iteration 1107: loss: 0.903001, loss_s1: 0.501139, loss_fp: 0.500090, loss_freq: 0.500276
[01:19:01.256] iteration 1108: loss: 0.861961, loss_s1: 0.506171, loss_fp: 0.500043, loss_freq: 0.501710
[01:19:01.953] iteration 1109: loss: 0.879428, loss_s1: 0.504674, loss_fp: 0.500283, loss_freq: 0.502988
[01:19:02.647] iteration 1110: loss: 0.894448, loss_s1: 0.502296, loss_fp: 0.500028, loss_freq: 0.502321
[01:19:03.363] iteration 1111: loss: 0.873363, loss_s1: 0.504030, loss_fp: 0.500015, loss_freq: 0.503532
[01:19:04.037] iteration 1112: loss: 0.850313, loss_s1: 0.505277, loss_fp: 0.500072, loss_freq: 0.502933
[01:19:04.708] iteration 1113: loss: 0.885608, loss_s1: 0.503516, loss_fp: 0.500043, loss_freq: 0.502300
[01:19:05.380] iteration 1114: loss: 0.864296, loss_s1: 0.501993, loss_fp: 0.500052, loss_freq: 0.502795
[01:19:06.049] iteration 1115: loss: 0.863204, loss_s1: 0.501117, loss_fp: 0.500124, loss_freq: 0.500742
[01:19:06.740] iteration 1116: loss: 0.856405, loss_s1: 0.500831, loss_fp: 0.500056, loss_freq: 0.500166
[01:19:07.442] iteration 1117: loss: 0.887008, loss_s1: 0.502118, loss_fp: 0.500023, loss_freq: 0.500790
[01:19:08.143] iteration 1118: loss: 0.863856, loss_s1: 0.505671, loss_fp: 0.500046, loss_freq: 0.504953
[01:19:08.818] iteration 1119: loss: 0.889076, loss_s1: 0.501320, loss_fp: 0.500062, loss_freq: 0.500728
[01:19:09.508] iteration 1120: loss: 0.853042, loss_s1: 0.503940, loss_fp: 0.500066, loss_freq: 0.500812
[01:19:10.260] iteration 1121: loss: 0.830982, loss_s1: 0.508608, loss_fp: 0.500198, loss_freq: 0.501985
[01:19:11.085] iteration 1122: loss: 0.946878, loss_s1: 0.502408, loss_fp: 0.500417, loss_freq: 0.503032
[01:19:11.851] iteration 1123: loss: 0.885510, loss_s1: 0.503521, loss_fp: 0.500042, loss_freq: 0.500186
[01:19:12.538] iteration 1124: loss: 0.882138, loss_s1: 0.504599, loss_fp: 0.500235, loss_freq: 0.501559
[01:19:13.217] iteration 1125: loss: 0.852296, loss_s1: 0.503193, loss_fp: 0.500155, loss_freq: 0.502542
[01:19:13.946] iteration 1126: loss: 0.879654, loss_s1: 0.503341, loss_fp: 0.500015, loss_freq: 0.500993
[01:19:14.633] iteration 1127: loss: 0.844828, loss_s1: 0.504023, loss_fp: 0.500186, loss_freq: 0.500940
[01:19:15.292] iteration 1128: loss: 0.869725, loss_s1: 0.504610, loss_fp: 0.500135, loss_freq: 0.503030
[01:19:15.947] iteration 1129: loss: 0.909803, loss_s1: 0.503876, loss_fp: 0.500048, loss_freq: 0.505936
[01:19:16.613] iteration 1130: loss: 0.849694, loss_s1: 0.501091, loss_fp: 0.500245, loss_freq: 0.500581
[01:19:17.269] iteration 1131: loss: 0.915053, loss_s1: 0.500557, loss_fp: 0.500048, loss_freq: 0.500997
[01:19:17.938] iteration 1132: loss: 0.835751, loss_s1: 0.498802, loss_fp: 0.461519, loss_freq: 0.474668
[01:19:18.633] iteration 1133: loss: 0.820813, loss_s1: 0.382618, loss_fp: 0.500032, loss_freq: 0.500200
[01:19:19.327] iteration 1134: loss: 0.832615, loss_s1: 0.501396, loss_fp: 0.500032, loss_freq: 0.500569
[01:19:20.027] iteration 1135: loss: 0.890213, loss_s1: 0.506620, loss_fp: 0.500065, loss_freq: 0.503950
[01:19:20.716] iteration 1136: loss: 0.876168, loss_s1: 0.504410, loss_fp: 0.500069, loss_freq: 0.503436
[01:19:21.413] iteration 1137: loss: 0.898342, loss_s1: 0.502674, loss_fp: 0.500080, loss_freq: 0.501832
[01:19:22.083] iteration 1138: loss: 0.873287, loss_s1: 0.501904, loss_fp: 0.500041, loss_freq: 0.501399
[01:19:22.763] iteration 1139: loss: 0.867687, loss_s1: 0.501875, loss_fp: 0.500070, loss_freq: 0.501941
[01:19:23.452] iteration 1140: loss: 0.910347, loss_s1: 0.502942, loss_fp: 0.500064, loss_freq: 0.502086
[01:19:24.135] iteration 1141: loss: 0.892372, loss_s1: 0.500729, loss_fp: 0.500043, loss_freq: 0.500433
[01:19:24.826] iteration 1142: loss: 0.883058, loss_s1: 0.501928, loss_fp: 0.500015, loss_freq: 0.500886
[01:19:25.507] iteration 1143: loss: 0.879274, loss_s1: 0.503058, loss_fp: 0.500032, loss_freq: 0.501597
[01:19:26.185] iteration 1144: loss: 0.858899, loss_s1: 0.503088, loss_fp: 0.500017, loss_freq: 0.502171
[01:19:26.864] iteration 1145: loss: 0.865749, loss_s1: 0.501644, loss_fp: 0.500669, loss_freq: 0.501037
[01:19:27.539] iteration 1146: loss: 0.878489, loss_s1: 0.500806, loss_fp: 0.500007, loss_freq: 0.500163
[01:19:28.220] iteration 1147: loss: 0.866775, loss_s1: 0.506191, loss_fp: 0.500137, loss_freq: 0.503445
[01:19:28.944] iteration 1148: loss: 0.912458, loss_s1: 0.503432, loss_fp: 0.500033, loss_freq: 0.505202
[01:19:29.704] iteration 1149: loss: 0.870946, loss_s1: 0.500478, loss_fp: 0.500037, loss_freq: 0.501200
[01:19:30.455] iteration 1150: loss: 0.855679, loss_s1: 0.502193, loss_fp: 0.501471, loss_freq: 0.501844
[01:19:31.173] iteration 1151: loss: 0.871963, loss_s1: 0.501087, loss_fp: 0.500018, loss_freq: 0.500633
[01:19:31.887] iteration 1152: loss: 0.866999, loss_s1: 0.501191, loss_fp: 0.500034, loss_freq: 0.500475
[01:19:32.566] iteration 1153: loss: 0.858977, loss_s1: 0.501974, loss_fp: 0.500128, loss_freq: 0.500565
[01:19:33.280] iteration 1154: loss: 0.892377, loss_s1: 0.500393, loss_fp: 0.500034, loss_freq: 0.500381
[01:19:33.967] iteration 1155: loss: 0.867185, loss_s1: 0.501792, loss_fp: 0.500033, loss_freq: 0.500538
[01:19:34.650] iteration 1156: loss: 0.834925, loss_s1: 0.502168, loss_fp: 0.500102, loss_freq: 0.502225
[01:19:35.308] iteration 1157: loss: 0.943586, loss_s1: 0.501997, loss_fp: 0.500015, loss_freq: 0.500651
[01:19:35.988] iteration 1158: loss: 0.876886, loss_s1: 0.500519, loss_fp: 0.500036, loss_freq: 0.500561
[01:19:36.793] iteration 1159: loss: 0.868200, loss_s1: 0.501877, loss_fp: 0.500053, loss_freq: 0.501106
[01:19:37.543] iteration 1160: loss: 0.829473, loss_s1: 0.503779, loss_fp: 0.500241, loss_freq: 0.501266
[01:19:38.227] iteration 1161: loss: 0.882642, loss_s1: 0.501008, loss_fp: 0.500016, loss_freq: 0.500748
[01:19:39.015] iteration 1162: loss: 0.849945, loss_s1: 0.502337, loss_fp: 0.500109, loss_freq: 0.502032
[01:19:39.698] iteration 1163: loss: 0.898427, loss_s1: 0.503996, loss_fp: 0.500081, loss_freq: 0.502081
[01:19:40.389] iteration 1164: loss: 0.856474, loss_s1: 0.501918, loss_fp: 0.500071, loss_freq: 0.501525
[01:19:41.093] iteration 1165: loss: 0.844746, loss_s1: 0.501993, loss_fp: 0.500040, loss_freq: 0.502062
[01:19:41.827] iteration 1166: loss: 0.927792, loss_s1: 0.500480, loss_fp: 0.500056, loss_freq: 0.501371
[01:19:42.538] iteration 1167: loss: 0.896547, loss_s1: 0.500348, loss_fp: 0.500062, loss_freq: 0.500805
[01:19:43.287] iteration 1168: loss: 0.865486, loss_s1: 0.500702, loss_fp: 0.500103, loss_freq: 0.501505
[01:19:43.990] iteration 1169: loss: 0.855284, loss_s1: 0.502725, loss_fp: 0.500113, loss_freq: 0.500922
[01:19:44.644] iteration 1170: loss: 0.854935, loss_s1: 0.501075, loss_fp: 0.500140, loss_freq: 0.500632
[01:19:45.329] iteration 1171: loss: 0.872319, loss_s1: 0.504109, loss_fp: 0.500027, loss_freq: 0.500591
[01:19:46.112] iteration 1172: loss: 0.882844, loss_s1: 0.501390, loss_fp: 0.500051, loss_freq: 0.500957
[01:19:46.822] iteration 1173: loss: 0.872369, loss_s1: 0.500808, loss_fp: 0.500032, loss_freq: 0.500842
[01:19:47.526] iteration 1174: loss: 0.865482, loss_s1: 0.500413, loss_fp: 0.500099, loss_freq: 0.500664
[01:19:48.216] iteration 1175: loss: 0.908743, loss_s1: 0.502904, loss_fp: 0.500022, loss_freq: 0.501028
[01:19:48.900] iteration 1176: loss: 0.875445, loss_s1: 0.502232, loss_fp: 0.500080, loss_freq: 0.500855
[01:19:49.568] iteration 1177: loss: 0.852786, loss_s1: 0.502039, loss_fp: 0.500218, loss_freq: 0.502163
[01:19:50.240] iteration 1178: loss: 0.633869, loss_s1: 0.501343, loss_fp: 0.293878, loss_freq: 0.264499
[01:19:50.888] iteration 1179: loss: 0.856654, loss_s1: 0.502154, loss_fp: 0.500109, loss_freq: 0.500327
[01:19:51.531] iteration 1180: loss: 0.906962, loss_s1: 0.504572, loss_fp: 0.500040, loss_freq: 0.500330
[01:19:52.195] iteration 1181: loss: 0.922799, loss_s1: 0.478788, loss_fp: 0.500027, loss_freq: 0.500665
[01:19:52.857] iteration 1182: loss: 0.872050, loss_s1: 0.501820, loss_fp: 0.500026, loss_freq: 0.500134
[01:19:53.526] iteration 1183: loss: 0.929753, loss_s1: 0.502448, loss_fp: 0.500023, loss_freq: 0.502407
[01:19:54.188] iteration 1184: loss: 0.922812, loss_s1: 0.503070, loss_fp: 0.500035, loss_freq: 0.501059
[01:19:54.852] iteration 1185: loss: 0.801793, loss_s1: 0.336963, loss_fp: 0.500046, loss_freq: 0.500766
[01:19:55.516] iteration 1186: loss: 0.610155, loss_s1: 0.438713, loss_fp: 0.152878, loss_freq: 0.197234
[01:19:56.154] iteration 1187: loss: 0.954067, loss_s1: 0.505456, loss_fp: 0.501723, loss_freq: 0.500805
[01:19:56.812] iteration 1188: loss: 1.000527, loss_s1: 0.504027, loss_fp: 0.500787, loss_freq: 0.503572
[01:19:57.463] iteration 1189: loss: 0.971679, loss_s1: 0.505523, loss_fp: 0.500192, loss_freq: 0.502747
[01:19:58.313] iteration 1190: loss: 0.890249, loss_s1: 0.507437, loss_fp: 0.500320, loss_freq: 0.505532
[01:19:59.645] iteration 1191: loss: 0.903675, loss_s1: 0.509489, loss_fp: 0.500211, loss_freq: 0.501115
[01:20:00.509] iteration 1192: loss: 0.899245, loss_s1: 0.507601, loss_fp: 0.500017, loss_freq: 0.504702
[01:20:01.181] iteration 1193: loss: 0.967915, loss_s1: 0.502660, loss_fp: 0.500037, loss_freq: 0.500122
[01:20:01.854] iteration 1194: loss: 0.885442, loss_s1: 0.508918, loss_fp: 0.500055, loss_freq: 0.503467
[01:20:02.529] iteration 1195: loss: 0.903514, loss_s1: 0.509516, loss_fp: 0.500087, loss_freq: 0.502934
[01:20:03.195] iteration 1196: loss: 0.916042, loss_s1: 0.501897, loss_fp: 0.500032, loss_freq: 0.502388
[01:20:03.938] iteration 1197: loss: 0.918678, loss_s1: 0.502400, loss_fp: 0.500036, loss_freq: 0.503073
[01:20:04.616] iteration 1198: loss: 0.933638, loss_s1: 0.506983, loss_fp: 0.500219, loss_freq: 0.500266
[01:20:05.340] iteration 1199: loss: 0.912829, loss_s1: 0.510607, loss_fp: 0.500056, loss_freq: 0.502451
[01:20:06.049] iteration 1200: loss: 0.969595, loss_s1: 0.509455, loss_fp: 0.500072, loss_freq: 0.500349
[01:20:08.633] iteration 1200 : mean_dice : 0.129657
[01:20:09.415] iteration 1201: loss: 0.879730, loss_s1: 0.505873, loss_fp: 0.500052, loss_freq: 0.502961
[01:20:10.078] iteration 1202: loss: 0.890905, loss_s1: 0.505124, loss_fp: 0.500036, loss_freq: 0.501402
[01:20:10.770] iteration 1203: loss: 0.890822, loss_s1: 0.506577, loss_fp: 0.500094, loss_freq: 0.505617
[01:20:11.419] iteration 1204: loss: 1.051252, loss_s1: 0.501772, loss_fp: 0.500133, loss_freq: 0.501875
[01:20:12.065] iteration 1205: loss: 0.967488, loss_s1: 0.503891, loss_fp: 0.500061, loss_freq: 0.500430
[01:20:12.765] iteration 1206: loss: 0.895222, loss_s1: 0.506100, loss_fp: 0.500119, loss_freq: 0.501266
[01:20:13.412] iteration 1207: loss: 0.882032, loss_s1: 0.504991, loss_fp: 0.501203, loss_freq: 0.501694
[01:20:14.103] iteration 1208: loss: 0.897336, loss_s1: 0.502452, loss_fp: 0.500078, loss_freq: 0.500157
[01:20:14.750] iteration 1209: loss: 0.889038, loss_s1: 0.500979, loss_fp: 0.500126, loss_freq: 0.500718
[01:20:15.444] iteration 1210: loss: 0.905726, loss_s1: 0.503963, loss_fp: 0.500066, loss_freq: 0.501184
[01:20:16.168] iteration 1211: loss: 0.886883, loss_s1: 0.503529, loss_fp: 0.500028, loss_freq: 0.501723
[01:20:16.830] iteration 1212: loss: 0.955644, loss_s1: 0.505738, loss_fp: 0.500159, loss_freq: 0.502964
[01:20:17.551] iteration 1213: loss: 0.929129, loss_s1: 0.505668, loss_fp: 0.500187, loss_freq: 0.500863
[01:20:18.216] iteration 1214: loss: 0.866871, loss_s1: 0.505328, loss_fp: 0.500049, loss_freq: 0.502002
[01:20:18.898] iteration 1215: loss: 0.860087, loss_s1: 0.501881, loss_fp: 0.500102, loss_freq: 0.500572
[01:20:19.531] iteration 1216: loss: 0.904138, loss_s1: 0.503316, loss_fp: 0.500487, loss_freq: 0.501476
[01:20:20.190] iteration 1217: loss: 0.926097, loss_s1: 0.503713, loss_fp: 0.500041, loss_freq: 0.501705
[01:20:20.864] iteration 1218: loss: 0.879434, loss_s1: 0.508691, loss_fp: 0.500928, loss_freq: 0.502528
[01:20:21.506] iteration 1219: loss: 0.938667, loss_s1: 0.504572, loss_fp: 0.500346, loss_freq: 0.502090
[01:20:22.205] iteration 1220: loss: 0.917375, loss_s1: 0.504881, loss_fp: 0.500133, loss_freq: 0.500767
[01:20:22.924] iteration 1221: loss: 0.876075, loss_s1: 0.506456, loss_fp: 0.500075, loss_freq: 0.503632
[01:20:23.596] iteration 1222: loss: 0.939567, loss_s1: 0.506316, loss_fp: 0.500153, loss_freq: 0.504881
[01:20:24.319] iteration 1223: loss: 0.891918, loss_s1: 0.506075, loss_fp: 0.500158, loss_freq: 0.504833
[01:20:25.022] iteration 1224: loss: 0.899645, loss_s1: 0.505132, loss_fp: 0.500145, loss_freq: 0.501992
[01:20:25.733] iteration 1225: loss: 0.896579, loss_s1: 0.508991, loss_fp: 0.500107, loss_freq: 0.505836
[01:20:26.458] iteration 1226: loss: 0.916680, loss_s1: 0.505823, loss_fp: 0.500101, loss_freq: 0.500656
[01:20:27.157] iteration 1227: loss: 0.881179, loss_s1: 0.504556, loss_fp: 0.500155, loss_freq: 0.501412
[01:20:27.865] iteration 1228: loss: 0.920956, loss_s1: 0.506404, loss_fp: 0.500158, loss_freq: 0.500901
[01:20:28.565] iteration 1229: loss: 0.871475, loss_s1: 0.509857, loss_fp: 0.500065, loss_freq: 0.502010
[01:20:29.277] iteration 1230: loss: 0.883965, loss_s1: 0.508291, loss_fp: 0.500268, loss_freq: 0.503074
[01:20:29.908] iteration 1231: loss: 0.896262, loss_s1: 0.512439, loss_fp: 0.500056, loss_freq: 0.502392
[01:20:30.612] iteration 1232: loss: 0.873532, loss_s1: 0.508961, loss_fp: 0.500129, loss_freq: 0.503770
[01:20:31.300] iteration 1233: loss: 0.885593, loss_s1: 0.508327, loss_fp: 0.500059, loss_freq: 0.503052
[01:20:31.981] iteration 1234: loss: 0.866794, loss_s1: 0.504793, loss_fp: 0.500178, loss_freq: 0.501977
[01:20:32.643] iteration 1235: loss: 0.881959, loss_s1: 0.506498, loss_fp: 0.500135, loss_freq: 0.501226
[01:20:33.355] iteration 1236: loss: 0.864933, loss_s1: 0.505451, loss_fp: 0.500047, loss_freq: 0.503725
[01:20:34.048] iteration 1237: loss: 0.905243, loss_s1: 0.503742, loss_fp: 0.500855, loss_freq: 0.502042
[01:20:34.724] iteration 1238: loss: 0.915547, loss_s1: 0.504968, loss_fp: 0.500970, loss_freq: 0.502513
[01:20:35.414] iteration 1239: loss: 0.910308, loss_s1: 0.503936, loss_fp: 0.500064, loss_freq: 0.501801
[01:20:36.076] iteration 1240: loss: 0.906675, loss_s1: 0.502831, loss_fp: 0.500619, loss_freq: 0.504062
[01:20:36.710] iteration 1241: loss: 0.888136, loss_s1: 0.504771, loss_fp: 0.500070, loss_freq: 0.505414
[01:20:37.364] iteration 1242: loss: 0.858323, loss_s1: 0.506079, loss_fp: 0.500019, loss_freq: 0.501260
[01:20:38.025] iteration 1243: loss: 0.867250, loss_s1: 0.505050, loss_fp: 0.500041, loss_freq: 0.503175
[01:20:38.656] iteration 1244: loss: 0.868608, loss_s1: 0.506273, loss_fp: 0.500232, loss_freq: 0.503573
[01:20:39.314] iteration 1245: loss: 0.933850, loss_s1: 0.504846, loss_fp: 0.500201, loss_freq: 0.503822
[01:20:39.966] iteration 1246: loss: 0.852398, loss_s1: 0.502936, loss_fp: 0.500030, loss_freq: 0.500847
[01:20:40.599] iteration 1247: loss: 0.871815, loss_s1: 0.504386, loss_fp: 0.500611, loss_freq: 0.503446
[01:20:41.263] iteration 1248: loss: 0.897404, loss_s1: 0.506926, loss_fp: 0.500051, loss_freq: 0.503289
[01:20:41.892] iteration 1249: loss: 0.894963, loss_s1: 0.502302, loss_fp: 0.500032, loss_freq: 0.500954
[01:20:42.525] iteration 1250: loss: 0.904297, loss_s1: 0.509919, loss_fp: 0.500077, loss_freq: 0.503301
[01:20:43.194] iteration 1251: loss: 0.875603, loss_s1: 0.504015, loss_fp: 0.500021, loss_freq: 0.503006
[01:20:43.831] iteration 1252: loss: 0.915977, loss_s1: 0.506530, loss_fp: 0.500176, loss_freq: 0.501328
[01:20:44.497] iteration 1253: loss: 0.892082, loss_s1: 0.505609, loss_fp: 0.500021, loss_freq: 0.501993
[01:20:45.133] iteration 1254: loss: 0.914102, loss_s1: 0.504018, loss_fp: 0.500390, loss_freq: 0.502950
[01:20:45.797] iteration 1255: loss: 0.835158, loss_s1: 0.505964, loss_fp: 0.500077, loss_freq: 0.502838
[01:20:46.434] iteration 1256: loss: 0.864691, loss_s1: 0.505244, loss_fp: 0.500137, loss_freq: 0.503342
[01:20:47.101] iteration 1257: loss: 0.971548, loss_s1: 0.503721, loss_fp: 0.500175, loss_freq: 0.502919
[01:20:47.740] iteration 1258: loss: 0.850126, loss_s1: 0.500943, loss_fp: 0.500109, loss_freq: 0.501438
[01:20:48.410] iteration 1259: loss: 0.867244, loss_s1: 0.504778, loss_fp: 0.500039, loss_freq: 0.500854
[01:20:49.045] iteration 1260: loss: 0.886666, loss_s1: 0.506338, loss_fp: 0.500053, loss_freq: 0.501846
[01:20:49.686] iteration 1261: loss: 0.879416, loss_s1: 0.506938, loss_fp: 0.500054, loss_freq: 0.503532
[01:20:50.334] iteration 1262: loss: 0.888124, loss_s1: 0.504024, loss_fp: 0.500061, loss_freq: 0.501939
[01:20:50.973] iteration 1263: loss: 0.902611, loss_s1: 0.502880, loss_fp: 0.500593, loss_freq: 0.501523
[01:20:51.638] iteration 1264: loss: 0.860123, loss_s1: 0.503057, loss_fp: 0.500021, loss_freq: 0.503189
[01:20:52.278] iteration 1265: loss: 0.914490, loss_s1: 0.503010, loss_fp: 0.500134, loss_freq: 0.501347
[01:20:52.968] iteration 1266: loss: 0.877222, loss_s1: 0.502377, loss_fp: 0.500057, loss_freq: 0.501013
[01:20:53.679] iteration 1267: loss: 0.867085, loss_s1: 0.503071, loss_fp: 0.500105, loss_freq: 0.501083
[01:20:54.377] iteration 1268: loss: 0.869813, loss_s1: 0.503145, loss_fp: 0.500408, loss_freq: 0.502266
[01:20:55.080] iteration 1269: loss: 0.875207, loss_s1: 0.504028, loss_fp: 0.500101, loss_freq: 0.500678
[01:20:55.746] iteration 1270: loss: 0.852771, loss_s1: 0.503030, loss_fp: 0.500111, loss_freq: 0.503488
[01:20:56.441] iteration 1271: loss: 0.864048, loss_s1: 0.504131, loss_fp: 0.500077, loss_freq: 0.503845
[01:20:57.099] iteration 1272: loss: 0.886583, loss_s1: 0.503375, loss_fp: 0.500044, loss_freq: 0.501233
[01:20:57.773] iteration 1273: loss: 0.852876, loss_s1: 0.503026, loss_fp: 0.500078, loss_freq: 0.501650
[01:20:58.433] iteration 1274: loss: 0.879289, loss_s1: 0.504318, loss_fp: 0.500173, loss_freq: 0.501613
[01:20:59.138] iteration 1275: loss: 0.882976, loss_s1: 0.503934, loss_fp: 0.501073, loss_freq: 0.503196
[01:20:59.853] iteration 1276: loss: 0.858845, loss_s1: 0.503508, loss_fp: 0.500523, loss_freq: 0.502178
[01:21:00.544] iteration 1277: loss: 0.852661, loss_s1: 0.501876, loss_fp: 0.500021, loss_freq: 0.501375
[01:21:01.216] iteration 1278: loss: 0.855657, loss_s1: 0.502499, loss_fp: 0.500357, loss_freq: 0.501001
[01:21:01.893] iteration 1279: loss: 0.852096, loss_s1: 0.507328, loss_fp: 0.500040, loss_freq: 0.503824
[01:21:02.572] iteration 1280: loss: 0.872485, loss_s1: 0.502134, loss_fp: 0.500011, loss_freq: 0.501724
[01:21:03.263] iteration 1281: loss: 0.912693, loss_s1: 0.503108, loss_fp: 0.500068, loss_freq: 0.504128
[01:21:03.939] iteration 1282: loss: 0.835701, loss_s1: 0.502730, loss_fp: 0.500043, loss_freq: 0.501412
[01:21:04.624] iteration 1283: loss: 0.894953, loss_s1: 0.502442, loss_fp: 0.500067, loss_freq: 0.501355
[01:21:05.279] iteration 1284: loss: 0.872692, loss_s1: 0.503036, loss_fp: 0.500067, loss_freq: 0.503937
[01:21:05.914] iteration 1285: loss: 0.853703, loss_s1: 0.502898, loss_fp: 0.500020, loss_freq: 0.501574
[01:21:06.568] iteration 1286: loss: 0.873904, loss_s1: 0.502625, loss_fp: 0.500062, loss_freq: 0.500564
[01:21:07.201] iteration 1287: loss: 0.901222, loss_s1: 0.504613, loss_fp: 0.500145, loss_freq: 0.501769
[01:21:07.852] iteration 1288: loss: 0.848317, loss_s1: 0.504129, loss_fp: 0.500232, loss_freq: 0.502953
[01:21:08.480] iteration 1289: loss: 0.875925, loss_s1: 0.506648, loss_fp: 0.500219, loss_freq: 0.500834
[01:21:09.139] iteration 1290: loss: 0.872544, loss_s1: 0.504498, loss_fp: 0.500119, loss_freq: 0.502706
[01:21:09.765] iteration 1291: loss: 0.824289, loss_s1: 0.504850, loss_fp: 0.500269, loss_freq: 0.503604
[01:21:10.390] iteration 1292: loss: 0.928033, loss_s1: 0.506926, loss_fp: 0.500080, loss_freq: 0.504244
[01:21:11.044] iteration 1293: loss: 0.863931, loss_s1: 0.502782, loss_fp: 0.500071, loss_freq: 0.500344
[01:21:11.673] iteration 1294: loss: 0.872580, loss_s1: 0.505805, loss_fp: 0.500664, loss_freq: 0.502493
[01:21:12.350] iteration 1295: loss: 0.855814, loss_s1: 0.502424, loss_fp: 0.500299, loss_freq: 0.502439
[01:21:12.977] iteration 1296: loss: 0.877305, loss_s1: 0.504761, loss_fp: 0.500277, loss_freq: 0.503172
[01:21:13.642] iteration 1297: loss: 0.854213, loss_s1: 0.503698, loss_fp: 0.500109, loss_freq: 0.502312
[01:21:14.276] iteration 1298: loss: 0.888970, loss_s1: 0.507771, loss_fp: 0.500065, loss_freq: 0.501907
[01:21:14.908] iteration 1299: loss: 0.841921, loss_s1: 0.504117, loss_fp: 0.500506, loss_freq: 0.506749
[01:21:15.587] iteration 1300: loss: 0.855670, loss_s1: 0.502584, loss_fp: 0.500171, loss_freq: 0.501114
[01:21:16.235] iteration 1301: loss: 0.913216, loss_s1: 0.502581, loss_fp: 0.500036, loss_freq: 0.501991
[01:21:16.883] iteration 1302: loss: 0.706168, loss_s1: 0.472092, loss_fp: 0.242543, loss_freq: 0.391249
[01:21:17.531] iteration 1303: loss: 0.872461, loss_s1: 0.500334, loss_fp: 0.500128, loss_freq: 0.500663
[01:21:18.183] iteration 1304: loss: 0.864008, loss_s1: 0.503188, loss_fp: 0.500039, loss_freq: 0.501692
[01:21:18.843] iteration 1305: loss: 0.889107, loss_s1: 0.503136, loss_fp: 0.500174, loss_freq: 0.504401
[01:21:19.479] iteration 1306: loss: 0.857662, loss_s1: 0.501155, loss_fp: 0.500014, loss_freq: 0.502170
[01:21:20.140] iteration 1307: loss: 0.893542, loss_s1: 0.500647, loss_fp: 0.500060, loss_freq: 0.501598
[01:21:20.809] iteration 1308: loss: 0.912766, loss_s1: 0.499239, loss_fp: 0.500084, loss_freq: 0.501015
[01:21:21.479] iteration 1309: loss: 0.856081, loss_s1: 0.505173, loss_fp: 0.500311, loss_freq: 0.502243
[01:21:22.162] iteration 1310: loss: 0.936254, loss_s1: 0.504081, loss_fp: 0.500036, loss_freq: 0.501899
[01:21:22.860] iteration 1311: loss: 0.866568, loss_s1: 0.486677, loss_fp: 0.500003, loss_freq: 0.501094
[01:21:23.537] iteration 1312: loss: 0.903782, loss_s1: 0.501808, loss_fp: 0.500027, loss_freq: 0.500147
[01:21:24.215] iteration 1313: loss: 0.942288, loss_s1: 0.505815, loss_fp: 0.500926, loss_freq: 0.505527
[01:21:24.900] iteration 1314: loss: 0.897622, loss_s1: 0.506190, loss_fp: 0.500178, loss_freq: 0.505998
[01:21:25.582] iteration 1315: loss: 0.942115, loss_s1: 0.504277, loss_fp: 0.500077, loss_freq: 0.500620
[01:21:26.282] iteration 1316: loss: 0.883486, loss_s1: 0.508145, loss_fp: 0.500060, loss_freq: 0.501717
[01:21:26.954] iteration 1317: loss: 0.884399, loss_s1: 0.509519, loss_fp: 0.500124, loss_freq: 0.506622
[01:21:27.621] iteration 1318: loss: 0.907598, loss_s1: 0.506324, loss_fp: 0.500048, loss_freq: 0.510289
[01:21:28.334] iteration 1319: loss: 0.927770, loss_s1: 0.506787, loss_fp: 0.500045, loss_freq: 0.502628
[01:21:29.008] iteration 1320: loss: 0.865535, loss_s1: 0.507245, loss_fp: 0.500057, loss_freq: 0.505755
[01:21:29.675] iteration 1321: loss: 0.908040, loss_s1: 0.508249, loss_fp: 0.501014, loss_freq: 0.502269
[01:21:30.341] iteration 1322: loss: 0.901192, loss_s1: 0.503348, loss_fp: 0.500024, loss_freq: 0.501522
[01:21:31.011] iteration 1323: loss: 0.876992, loss_s1: 0.504872, loss_fp: 0.500090, loss_freq: 0.502243
[01:21:31.676] iteration 1324: loss: 0.924150, loss_s1: 0.509248, loss_fp: 0.500365, loss_freq: 0.502761
[01:21:32.338] iteration 1325: loss: 0.878159, loss_s1: 0.503912, loss_fp: 0.500042, loss_freq: 0.501250
[01:21:32.972] iteration 1326: loss: 0.859573, loss_s1: 0.501956, loss_fp: 0.500087, loss_freq: 0.503786
[01:21:33.633] iteration 1327: loss: 0.966229, loss_s1: 0.502561, loss_fp: 0.500096, loss_freq: 0.502010
[01:21:34.292] iteration 1328: loss: 0.844331, loss_s1: 0.469803, loss_fp: 0.500068, loss_freq: 0.500827
[01:21:34.921] iteration 1329: loss: 0.904576, loss_s1: 0.502020, loss_fp: 0.500154, loss_freq: 0.501320
[01:21:35.581] iteration 1330: loss: 0.905457, loss_s1: 0.501892, loss_fp: 0.500193, loss_freq: 0.502969
[01:21:36.235] iteration 1331: loss: 0.899367, loss_s1: 0.503479, loss_fp: 0.500351, loss_freq: 0.501488
[01:21:36.855] iteration 1332: loss: 0.880170, loss_s1: 0.505103, loss_fp: 0.500116, loss_freq: 0.502209
[01:21:37.513] iteration 1333: loss: 0.819666, loss_s1: 0.501166, loss_fp: 0.392566, loss_freq: 0.483096
[01:21:38.171] iteration 1334: loss: 0.875643, loss_s1: 0.506230, loss_fp: 0.500039, loss_freq: 0.501122
[01:21:38.792] iteration 1335: loss: 0.861885, loss_s1: 0.502420, loss_fp: 0.500258, loss_freq: 0.500648
[01:21:39.449] iteration 1336: loss: 0.901998, loss_s1: 0.502845, loss_fp: 0.500127, loss_freq: 0.500671
[01:21:40.160] iteration 1337: loss: 0.880067, loss_s1: 0.503273, loss_fp: 0.500237, loss_freq: 0.501360
[01:21:40.858] iteration 1338: loss: 0.903320, loss_s1: 0.504785, loss_fp: 0.500101, loss_freq: 0.500590
[01:21:41.592] iteration 1339: loss: 0.862967, loss_s1: 0.501934, loss_fp: 0.500160, loss_freq: 0.500293
[01:21:42.407] iteration 1340: loss: 0.893571, loss_s1: 0.501799, loss_fp: 0.500066, loss_freq: 0.501749
[01:21:43.078] iteration 1341: loss: 0.865952, loss_s1: 0.503098, loss_fp: 0.500083, loss_freq: 0.500758
[01:21:43.695] iteration 1342: loss: 0.932370, loss_s1: 0.504880, loss_fp: 0.500081, loss_freq: 0.501033
[01:21:44.345] iteration 1343: loss: 0.866482, loss_s1: 0.501991, loss_fp: 0.500096, loss_freq: 0.501876
[01:21:45.014] iteration 1344: loss: 0.855607, loss_s1: 0.504847, loss_fp: 0.500120, loss_freq: 0.502323
[01:21:45.689] iteration 1345: loss: 0.914521, loss_s1: 0.503412, loss_fp: 0.500137, loss_freq: 0.503005
[01:21:46.374] iteration 1346: loss: 0.874714, loss_s1: 0.501737, loss_fp: 0.500583, loss_freq: 0.501324
[01:21:47.069] iteration 1347: loss: 0.894846, loss_s1: 0.503809, loss_fp: 0.500553, loss_freq: 0.504804
[01:21:47.750] iteration 1348: loss: 0.864805, loss_s1: 0.505085, loss_fp: 0.500413, loss_freq: 0.502604
[01:21:48.493] iteration 1349: loss: 0.857100, loss_s1: 0.504045, loss_fp: 0.500140, loss_freq: 0.501238
[01:21:49.194] iteration 1350: loss: 0.855775, loss_s1: 0.503076, loss_fp: 0.500071, loss_freq: 0.501181
[01:21:49.883] iteration 1351: loss: 0.842108, loss_s1: 0.503737, loss_fp: 0.500014, loss_freq: 0.501750
[01:21:50.533] iteration 1352: loss: 0.824587, loss_s1: 0.502490, loss_fp: 0.500029, loss_freq: 0.500446
[01:21:51.264] iteration 1353: loss: 0.920021, loss_s1: 0.496524, loss_fp: 0.500099, loss_freq: 0.501939
[01:21:51.909] iteration 1354: loss: 0.903658, loss_s1: 0.504510, loss_fp: 0.500085, loss_freq: 0.500790
[01:21:52.539] iteration 1355: loss: 0.859011, loss_s1: 0.500732, loss_fp: 0.500086, loss_freq: 0.500197
[01:21:53.203] iteration 1356: loss: 0.633486, loss_s1: 0.426967, loss_fp: 0.394628, loss_freq: 0.175422
[01:21:53.894] iteration 1357: loss: 0.922077, loss_s1: 0.501025, loss_fp: 0.500039, loss_freq: 0.500750
[01:21:54.650] iteration 1358: loss: 0.862266, loss_s1: 0.502068, loss_fp: 0.500109, loss_freq: 0.500542
[01:21:55.307] iteration 1359: loss: 0.482053, loss_s1: 0.503715, loss_fp: 0.023830, loss_freq: 0.136423
[01:21:56.024] iteration 1360: loss: 0.897727, loss_s1: 0.503838, loss_fp: 0.500214, loss_freq: 0.505510
[01:21:56.995] iteration 1361: loss: 0.877028, loss_s1: 0.503720, loss_fp: 0.500092, loss_freq: 0.500359
[01:21:57.609] iteration 1362: loss: 0.894679, loss_s1: 0.500726, loss_fp: 0.500291, loss_freq: 0.502395
[01:21:58.228] iteration 1363: loss: 0.957730, loss_s1: 0.503715, loss_fp: 0.500039, loss_freq: 0.501698
[01:21:58.840] iteration 1364: loss: 0.943471, loss_s1: 0.503689, loss_fp: 0.500095, loss_freq: 0.505364
[01:21:59.454] iteration 1365: loss: 0.907172, loss_s1: 0.505444, loss_fp: 0.500024, loss_freq: 0.500579
[01:22:00.069] iteration 1366: loss: 0.930030, loss_s1: 0.506249, loss_fp: 0.500008, loss_freq: 0.504120
[01:22:00.681] iteration 1367: loss: 0.949702, loss_s1: 0.505374, loss_fp: 0.500118, loss_freq: 0.503178
[01:22:01.291] iteration 1368: loss: 0.915168, loss_s1: 0.502009, loss_fp: 0.500054, loss_freq: 0.501714
[01:22:01.906] iteration 1369: loss: 0.910688, loss_s1: 0.507786, loss_fp: 0.500008, loss_freq: 0.502202
[01:22:02.517] iteration 1370: loss: 0.913976, loss_s1: 0.504842, loss_fp: 0.500106, loss_freq: 0.500306
[01:22:03.127] iteration 1371: loss: 0.878114, loss_s1: 0.507886, loss_fp: 0.500005, loss_freq: 0.505715
[01:22:03.781] iteration 1372: loss: 0.892446, loss_s1: 0.506779, loss_fp: 0.500049, loss_freq: 0.504819
[01:22:04.399] iteration 1373: loss: 0.944501, loss_s1: 0.508557, loss_fp: 0.500067, loss_freq: 0.503759
[01:22:05.015] iteration 1374: loss: 0.924939, loss_s1: 0.504056, loss_fp: 0.500058, loss_freq: 0.504543
[01:22:05.635] iteration 1375: loss: 0.934163, loss_s1: 0.503764, loss_fp: 0.500174, loss_freq: 0.501207
[01:22:06.253] iteration 1376: loss: 0.931111, loss_s1: 0.504008, loss_fp: 0.500506, loss_freq: 0.501893
[01:22:06.933] iteration 1377: loss: 0.872101, loss_s1: 0.507601, loss_fp: 0.500052, loss_freq: 0.501241
[01:22:07.751] iteration 1378: loss: 0.774684, loss_s1: 0.286513, loss_fp: 0.500052, loss_freq: 0.500219
[01:22:08.579] iteration 1379: loss: 0.881501, loss_s1: 0.502218, loss_fp: 0.500020, loss_freq: 0.500645
[01:22:09.629] iteration 1380: loss: 0.940142, loss_s1: 0.500505, loss_fp: 0.500034, loss_freq: 0.500239
[01:22:10.256] iteration 1381: loss: 0.905202, loss_s1: 0.507761, loss_fp: 0.500078, loss_freq: 0.501233
[01:22:10.909] iteration 1382: loss: 0.898293, loss_s1: 0.506658, loss_fp: 0.500043, loss_freq: 0.500453
[01:22:11.562] iteration 1383: loss: 1.032260, loss_s1: 0.502475, loss_fp: 0.500088, loss_freq: 0.500479
[01:22:12.208] iteration 1384: loss: 1.087402, loss_s1: 0.501879, loss_fp: 0.500237, loss_freq: 0.500862
[01:22:12.863] iteration 1385: loss: 0.880049, loss_s1: 0.502284, loss_fp: 0.500145, loss_freq: 0.500687
[01:22:13.497] iteration 1386: loss: 0.903387, loss_s1: 0.504365, loss_fp: 0.500042, loss_freq: 0.500588
[01:22:14.139] iteration 1387: loss: 0.885423, loss_s1: 0.502492, loss_fp: 0.500021, loss_freq: 0.500956
[01:22:14.779] iteration 1388: loss: 0.881399, loss_s1: 0.509038, loss_fp: 0.500079, loss_freq: 0.503182
[01:22:15.431] iteration 1389: loss: 0.990404, loss_s1: 0.502905, loss_fp: 0.500194, loss_freq: 0.501150
[01:22:16.079] iteration 1390: loss: 0.882859, loss_s1: 0.502709, loss_fp: 0.500166, loss_freq: 0.501145
[01:22:16.736] iteration 1391: loss: 0.893503, loss_s1: 0.503315, loss_fp: 0.500064, loss_freq: 0.500516
[01:22:17.384] iteration 1392: loss: 0.916572, loss_s1: 0.505808, loss_fp: 0.500120, loss_freq: 0.506192
[01:22:18.028] iteration 1393: loss: 0.903250, loss_s1: 0.506806, loss_fp: 0.500040, loss_freq: 0.502308
[01:22:18.667] iteration 1394: loss: 0.905585, loss_s1: 0.504676, loss_fp: 0.500042, loss_freq: 0.502387
[01:22:19.303] iteration 1395: loss: 0.894642, loss_s1: 0.501416, loss_fp: 0.500136, loss_freq: 0.502438
[01:22:19.944] iteration 1396: loss: 0.871455, loss_s1: 0.501709, loss_fp: 0.500277, loss_freq: 0.500226
[01:22:20.589] iteration 1397: loss: 0.861545, loss_s1: 0.501587, loss_fp: 0.500771, loss_freq: 0.501518
[01:22:21.232] iteration 1398: loss: 0.894338, loss_s1: 0.506638, loss_fp: 0.500171, loss_freq: 0.500957
[01:22:21.929] iteration 1399: loss: 0.865991, loss_s1: 0.503631, loss_fp: 0.500288, loss_freq: 0.503013
[01:22:22.647] iteration 1400: loss: 0.878593, loss_s1: 0.505176, loss_fp: 0.500357, loss_freq: 0.502176
[01:22:25.530] iteration 1400 : mean_dice : 0.151119
[01:22:26.275] iteration 1401: loss: 0.890409, loss_s1: 0.507292, loss_fp: 0.500083, loss_freq: 0.504772
[01:22:26.997] iteration 1402: loss: 0.903344, loss_s1: 0.505743, loss_fp: 0.500155, loss_freq: 0.506134
[01:22:27.662] iteration 1403: loss: 0.882334, loss_s1: 0.502806, loss_fp: 0.500063, loss_freq: 0.504386
[01:22:28.330] iteration 1404: loss: 0.866891, loss_s1: 0.504380, loss_fp: 0.500044, loss_freq: 0.502562
[01:22:29.027] iteration 1405: loss: 0.897535, loss_s1: 0.502951, loss_fp: 0.500180, loss_freq: 0.501161
[01:22:29.665] iteration 1406: loss: 0.866210, loss_s1: 0.501140, loss_fp: 0.500183, loss_freq: 0.503644
[01:22:30.317] iteration 1407: loss: 0.886156, loss_s1: 0.500615, loss_fp: 0.500018, loss_freq: 0.501405
[01:22:30.976] iteration 1408: loss: 0.850986, loss_s1: 0.505991, loss_fp: 0.500073, loss_freq: 0.502543
[01:22:31.626] iteration 1409: loss: 0.854091, loss_s1: 0.502541, loss_fp: 0.500093, loss_freq: 0.502245
[01:22:32.282] iteration 1410: loss: 0.911897, loss_s1: 0.505795, loss_fp: 0.500120, loss_freq: 0.506118
[01:22:32.931] iteration 1411: loss: 0.854410, loss_s1: 0.504728, loss_fp: 0.500015, loss_freq: 0.500891
[01:22:33.566] iteration 1412: loss: 0.856912, loss_s1: 0.502566, loss_fp: 0.500023, loss_freq: 0.500852
[01:22:34.217] iteration 1413: loss: 0.877815, loss_s1: 0.507847, loss_fp: 0.500014, loss_freq: 0.506471
[01:22:34.877] iteration 1414: loss: 0.871925, loss_s1: 0.508316, loss_fp: 0.500696, loss_freq: 0.506277
[01:22:35.555] iteration 1415: loss: 0.871742, loss_s1: 0.502959, loss_fp: 0.500046, loss_freq: 0.505150
[01:22:36.205] iteration 1416: loss: 0.874379, loss_s1: 0.502838, loss_fp: 0.500028, loss_freq: 0.501462
[01:22:36.879] iteration 1417: loss: 0.853679, loss_s1: 0.503029, loss_fp: 0.500087, loss_freq: 0.503479
[01:22:37.545] iteration 1418: loss: 0.909621, loss_s1: 0.506663, loss_fp: 0.500010, loss_freq: 0.504017
[01:22:38.208] iteration 1419: loss: 0.939260, loss_s1: 0.501196, loss_fp: 0.500072, loss_freq: 0.500440
[01:22:38.864] iteration 1420: loss: 0.846256, loss_s1: 0.505216, loss_fp: 0.500126, loss_freq: 0.501540
[01:22:39.509] iteration 1421: loss: 0.887651, loss_s1: 0.504850, loss_fp: 0.500295, loss_freq: 0.501576
[01:22:40.159] iteration 1422: loss: 0.879449, loss_s1: 0.502319, loss_fp: 0.500038, loss_freq: 0.500834
[01:22:40.813] iteration 1423: loss: 0.845415, loss_s1: 0.501660, loss_fp: 0.500072, loss_freq: 0.500606
[01:22:41.471] iteration 1424: loss: 0.896836, loss_s1: 0.502609, loss_fp: 0.500022, loss_freq: 0.500765
[01:22:42.124] iteration 1425: loss: 0.841382, loss_s1: 0.503975, loss_fp: 0.500107, loss_freq: 0.502810
[01:22:42.783] iteration 1426: loss: 0.839116, loss_s1: 0.504094, loss_fp: 0.500098, loss_freq: 0.502438
[01:22:43.461] iteration 1427: loss: 0.941931, loss_s1: 0.501433, loss_fp: 0.500041, loss_freq: 0.502033
[01:22:44.170] iteration 1428: loss: 0.850273, loss_s1: 0.500455, loss_fp: 0.500838, loss_freq: 0.501578
[01:22:44.899] iteration 1429: loss: 0.864243, loss_s1: 0.502847, loss_fp: 0.500142, loss_freq: 0.501105
[01:22:45.600] iteration 1430: loss: 0.874237, loss_s1: 0.502982, loss_fp: 0.500032, loss_freq: 0.500627
[01:22:46.313] iteration 1431: loss: 0.861828, loss_s1: 0.502409, loss_fp: 0.500159, loss_freq: 0.501477
[01:22:47.015] iteration 1432: loss: 0.845631, loss_s1: 0.501519, loss_fp: 0.500177, loss_freq: 0.501465
[01:22:47.776] iteration 1433: loss: 0.922687, loss_s1: 0.503199, loss_fp: 0.500010, loss_freq: 0.500742
[01:22:48.491] iteration 1434: loss: 0.847489, loss_s1: 0.505609, loss_fp: 0.500020, loss_freq: 0.502110
[01:22:49.211] iteration 1435: loss: 0.845797, loss_s1: 0.502380, loss_fp: 0.500171, loss_freq: 0.501771
[01:22:49.930] iteration 1436: loss: 0.879434, loss_s1: 0.501174, loss_fp: 0.500061, loss_freq: 0.500641
[01:22:50.640] iteration 1437: loss: 0.901739, loss_s1: 0.502763, loss_fp: 0.500306, loss_freq: 0.500586
[01:22:51.362] iteration 1438: loss: 0.874135, loss_s1: 0.504094, loss_fp: 0.500019, loss_freq: 0.501807
[01:22:52.056] iteration 1439: loss: 0.835010, loss_s1: 0.503249, loss_fp: 0.500025, loss_freq: 0.500683
[01:22:52.748] iteration 1440: loss: 0.862517, loss_s1: 0.500665, loss_fp: 0.500169, loss_freq: 0.501812
[01:22:53.422] iteration 1441: loss: 0.843846, loss_s1: 0.501838, loss_fp: 0.500163, loss_freq: 0.501836
[01:22:54.107] iteration 1442: loss: 0.890257, loss_s1: 0.504133, loss_fp: 0.500078, loss_freq: 0.500536
[01:22:54.819] iteration 1443: loss: 0.841588, loss_s1: 0.502454, loss_fp: 0.500041, loss_freq: 0.500434
[01:22:55.539] iteration 1444: loss: 0.878701, loss_s1: 0.504482, loss_fp: 0.500073, loss_freq: 0.501260
[01:22:56.239] iteration 1445: loss: 0.868108, loss_s1: 0.503963, loss_fp: 0.500010, loss_freq: 0.502012
[01:22:56.909] iteration 1446: loss: 0.860543, loss_s1: 0.502499, loss_fp: 0.500040, loss_freq: 0.501003
[01:22:57.566] iteration 1447: loss: 0.855160, loss_s1: 0.502916, loss_fp: 0.500105, loss_freq: 0.500098
[01:22:58.240] iteration 1448: loss: 0.863208, loss_s1: 0.503710, loss_fp: 0.500018, loss_freq: 0.503168
[01:22:58.907] iteration 1449: loss: 0.850839, loss_s1: 0.507129, loss_fp: 0.500032, loss_freq: 0.502028
[01:22:59.578] iteration 1450: loss: 0.872826, loss_s1: 0.501434, loss_fp: 0.500065, loss_freq: 0.500816
[01:23:00.265] iteration 1451: loss: 0.846027, loss_s1: 0.503171, loss_fp: 0.500044, loss_freq: 0.504147
[01:23:00.937] iteration 1452: loss: 0.842243, loss_s1: 0.503207, loss_fp: 0.500147, loss_freq: 0.502870
[01:23:01.600] iteration 1453: loss: 0.887490, loss_s1: 0.505547, loss_fp: 0.500033, loss_freq: 0.501212
[01:23:02.258] iteration 1454: loss: 0.858688, loss_s1: 0.505575, loss_fp: 0.500026, loss_freq: 0.501677
[01:23:02.926] iteration 1455: loss: 0.866627, loss_s1: 0.503740, loss_fp: 0.500067, loss_freq: 0.500897
[01:23:03.590] iteration 1456: loss: 0.847797, loss_s1: 0.502491, loss_fp: 0.500035, loss_freq: 0.500250
[01:23:04.260] iteration 1457: loss: 0.873277, loss_s1: 0.504344, loss_fp: 0.500145, loss_freq: 0.501161
[01:23:04.923] iteration 1458: loss: 0.856883, loss_s1: 0.504773, loss_fp: 0.500026, loss_freq: 0.501998
[01:23:05.583] iteration 1459: loss: 0.837262, loss_s1: 0.502617, loss_fp: 0.500068, loss_freq: 0.501444
[01:23:06.236] iteration 1460: loss: 0.828930, loss_s1: 0.502756, loss_fp: 0.500079, loss_freq: 0.501426
[01:23:06.890] iteration 1461: loss: 0.811838, loss_s1: 0.502333, loss_fp: 0.500063, loss_freq: 0.502672
[01:23:07.559] iteration 1462: loss: 0.891222, loss_s1: 0.501576, loss_fp: 0.500029, loss_freq: 0.504383
[01:23:08.217] iteration 1463: loss: 0.727291, loss_s1: 0.495596, loss_fp: 0.281162, loss_freq: 0.476980
[01:23:08.869] iteration 1464: loss: 0.850002, loss_s1: 0.502472, loss_fp: 0.500255, loss_freq: 0.500930
[01:23:09.529] iteration 1465: loss: 0.493462, loss_s1: 0.417342, loss_fp: 0.013915, loss_freq: 0.352765
[01:23:10.217] iteration 1466: loss: 0.861298, loss_s1: 0.501736, loss_fp: 0.500086, loss_freq: 0.500551
[01:23:10.880] iteration 1467: loss: 0.723416, loss_s1: 0.225576, loss_fp: 0.500014, loss_freq: 0.500458
[01:23:11.540] iteration 1468: loss: 0.912261, loss_s1: 0.500496, loss_fp: 0.500003, loss_freq: 0.500074
[01:23:12.223] iteration 1469: loss: 0.908424, loss_s1: 0.502912, loss_fp: 0.500005, loss_freq: 0.504391
[01:23:12.892] iteration 1470: loss: 0.970798, loss_s1: 0.500673, loss_fp: 0.500008, loss_freq: 0.500188
[01:23:13.569] iteration 1471: loss: 0.935344, loss_s1: 0.500758, loss_fp: 0.500007, loss_freq: 0.500287
[01:23:14.248] iteration 1472: loss: 0.885972, loss_s1: 0.501710, loss_fp: 0.500002, loss_freq: 0.500646
[01:23:14.924] iteration 1473: loss: 0.354164, loss_s1: 0.163219, loss_fp: 0.005685, loss_freq: 0.086535
[01:23:15.697] iteration 1474: loss: 0.867027, loss_s1: 0.503382, loss_fp: 0.499999, loss_freq: 0.502235
[01:23:16.432] iteration 1475: loss: 0.898479, loss_s1: 0.507314, loss_fp: 0.500029, loss_freq: 0.502895
[01:23:17.136] iteration 1476: loss: 0.858194, loss_s1: 0.504278, loss_fp: 0.500028, loss_freq: 0.503888
[01:23:17.834] iteration 1477: loss: 0.968609, loss_s1: 0.503333, loss_fp: 0.500005, loss_freq: 0.501754
[01:23:18.532] iteration 1478: loss: 0.845616, loss_s1: 0.498468, loss_fp: 0.499999, loss_freq: 0.501023
[01:23:19.224] iteration 1479: loss: 0.874693, loss_s1: 0.511336, loss_fp: 0.500034, loss_freq: 0.501910
[01:23:19.899] iteration 1480: loss: 0.915219, loss_s1: 0.498066, loss_fp: 0.500009, loss_freq: 0.505798
[01:23:20.572] iteration 1481: loss: 0.818169, loss_s1: 0.412235, loss_fp: 0.500006, loss_freq: 0.500226
[01:23:21.289] iteration 1482: loss: 0.945454, loss_s1: 0.501927, loss_fp: 0.500032, loss_freq: 0.500538
[01:23:21.999] iteration 1483: loss: 0.872728, loss_s1: 0.505545, loss_fp: 0.500019, loss_freq: 0.503231
[01:23:22.691] iteration 1484: loss: 0.850410, loss_s1: 0.505609, loss_fp: 0.500018, loss_freq: 0.502091
[01:23:23.359] iteration 1485: loss: 0.862481, loss_s1: 0.500620, loss_fp: 0.500074, loss_freq: 0.500714
[01:23:24.022] iteration 1486: loss: 0.864527, loss_s1: 0.502055, loss_fp: 0.500027, loss_freq: 0.500520
[01:23:24.697] iteration 1487: loss: 0.878613, loss_s1: 0.505671, loss_fp: 0.500016, loss_freq: 0.504581
[01:23:25.387] iteration 1488: loss: 0.904134, loss_s1: 0.506896, loss_fp: 0.500004, loss_freq: 0.504530
[01:23:26.087] iteration 1489: loss: 0.855955, loss_s1: 0.505388, loss_fp: 0.500048, loss_freq: 0.506333
[01:23:26.804] iteration 1490: loss: 0.879868, loss_s1: 0.508665, loss_fp: 0.500180, loss_freq: 0.506009
[01:23:27.581] iteration 1491: loss: 0.782718, loss_s1: 0.495771, loss_fp: 0.280788, loss_freq: 0.499534
[01:23:28.335] iteration 1492: loss: 0.816066, loss_s1: 0.261261, loss_fp: 0.500039, loss_freq: 0.500834
[01:23:29.202] iteration 1493: loss: 0.894901, loss_s1: 0.504564, loss_fp: 0.500004, loss_freq: 0.501583
[01:23:30.416] iteration 1494: loss: 0.796200, loss_s1: 0.177362, loss_fp: 0.500075, loss_freq: 0.500094
[01:23:31.357] iteration 1495: loss: 0.839764, loss_s1: 0.365740, loss_fp: 0.500018, loss_freq: 0.500511
[01:23:52.175] iteration 1496: loss: 0.895383, loss_s1: 0.503866, loss_fp: 0.500006, loss_freq: 0.500761
[01:24:13.034] iteration 1497: loss: 1.049050, loss_s1: 0.500808, loss_fp: 0.500003, loss_freq: 0.500813
[01:24:33.808] iteration 1498: loss: 0.918046, loss_s1: 0.504626, loss_fp: 0.500004, loss_freq: 0.500307
[01:24:54.707] iteration 1499: loss: 1.008132, loss_s1: 0.502421, loss_fp: 0.500033, loss_freq: 0.502968
[01:25:15.555] iteration 1500: loss: 0.947192, loss_s1: 0.504578, loss_fp: 0.500069, loss_freq: 0.500125
[01:25:36.504] iteration 1501: loss: 0.947183, loss_s1: 0.502301, loss_fp: 0.500022, loss_freq: 0.500822
[01:25:57.373] iteration 1502: loss: 0.909734, loss_s1: 0.502939, loss_fp: 0.500013, loss_freq: 0.500424
[01:26:18.328] iteration 1503: loss: 0.920368, loss_s1: 0.501209, loss_fp: 0.500006, loss_freq: 0.502862
[01:26:39.221] iteration 1504: loss: 0.981371, loss_s1: 0.500888, loss_fp: 0.500046, loss_freq: 0.500170
[01:27:00.172] iteration 1505: loss: 0.963917, loss_s1: 0.500650, loss_fp: 0.500007, loss_freq: 0.500069
[01:27:21.141] iteration 1506: loss: 0.903608, loss_s1: 0.501051, loss_fp: 0.500002, loss_freq: 0.500620
[01:27:42.019] iteration 1507: loss: 0.914553, loss_s1: 0.501505, loss_fp: 0.500087, loss_freq: 0.500433
[01:28:02.977] iteration 1508: loss: 0.935253, loss_s1: 0.501977, loss_fp: 0.500034, loss_freq: 0.500380
[01:28:23.851] iteration 1509: loss: 0.880809, loss_s1: 0.505505, loss_fp: 0.500005, loss_freq: 0.501175
[01:28:44.813] iteration 1510: loss: 0.919663, loss_s1: 0.507843, loss_fp: 0.500184, loss_freq: 0.500894
[01:29:05.696] iteration 1511: loss: 0.884598, loss_s1: 0.506238, loss_fp: 0.500041, loss_freq: 0.501072
[01:29:26.661] iteration 1512: loss: 0.898858, loss_s1: 0.502922, loss_fp: 0.500021, loss_freq: 0.501368
[01:29:47.541] iteration 1513: loss: 0.925400, loss_s1: 0.504190, loss_fp: 0.500129, loss_freq: 0.504294
[01:30:08.515] iteration 1514: loss: 0.887645, loss_s1: 0.455608, loss_fp: 0.500032, loss_freq: 0.500358
[01:30:29.494] iteration 1515: loss: 0.899023, loss_s1: 0.504850, loss_fp: 0.500025, loss_freq: 0.501211
[01:30:50.387] iteration 1516: loss: 0.887635, loss_s1: 0.509341, loss_fp: 0.500039, loss_freq: 0.502720
[01:31:11.355] iteration 1517: loss: 0.867834, loss_s1: 0.503372, loss_fp: 0.500060, loss_freq: 0.503397
[01:31:32.250] iteration 1518: loss: 0.856422, loss_s1: 0.506110, loss_fp: 0.500135, loss_freq: 0.500614
[01:31:53.224] iteration 1519: loss: 0.859525, loss_s1: 0.504889, loss_fp: 0.500153, loss_freq: 0.503377
[01:32:14.088] iteration 1520: loss: 0.866375, loss_s1: 0.507142, loss_fp: 0.500016, loss_freq: 0.500908
[01:32:35.061] iteration 1521: loss: 0.886437, loss_s1: 0.507705, loss_fp: 0.500009, loss_freq: 0.502901
[01:32:55.953] iteration 1522: loss: 0.861369, loss_s1: 0.502778, loss_fp: 0.500014, loss_freq: 0.501870
[01:33:16.935] iteration 1523: loss: 0.948982, loss_s1: 0.504976, loss_fp: 0.500026, loss_freq: 0.504404
[01:33:37.910] iteration 1524: loss: 0.860694, loss_s1: 0.507513, loss_fp: 0.500136, loss_freq: 0.501808
[01:33:58.794] iteration 1525: loss: 0.860705, loss_s1: 0.471436, loss_fp: 0.500067, loss_freq: 0.501005
[01:34:19.751] iteration 1526: loss: 0.851938, loss_s1: 0.509297, loss_fp: 0.500154, loss_freq: 0.501354
[01:34:40.617] iteration 1527: loss: 0.854370, loss_s1: 0.504696, loss_fp: 0.500031, loss_freq: 0.501637
[01:35:01.581] iteration 1528: loss: 0.847803, loss_s1: 0.504747, loss_fp: 0.500078, loss_freq: 0.501097
[01:35:22.452] iteration 1529: loss: 0.889952, loss_s1: 0.505713, loss_fp: 0.500116, loss_freq: 0.500778
[01:35:43.412] iteration 1530: loss: 0.857768, loss_s1: 0.508100, loss_fp: 0.500026, loss_freq: 0.504279
[01:36:04.612] iteration 1531: loss: 0.871090, loss_s1: 0.508562, loss_fp: 0.500044, loss_freq: 0.500646
[01:36:25.578] iteration 1532: loss: 0.862924, loss_s1: 0.506602, loss_fp: 0.500025, loss_freq: 0.500635
[01:36:46.538] iteration 1533: loss: 0.861531, loss_s1: 0.501792, loss_fp: 0.500037, loss_freq: 0.500761
[01:37:07.408] iteration 1534: loss: 0.870959, loss_s1: 0.505811, loss_fp: 0.500078, loss_freq: 0.504126
[01:37:28.369] iteration 1535: loss: 0.876997, loss_s1: 0.502326, loss_fp: 0.500147, loss_freq: 0.501530
[01:37:49.239] iteration 1536: loss: 0.874197, loss_s1: 0.506517, loss_fp: 0.500020, loss_freq: 0.503224
[01:38:10.222] iteration 1537: loss: 0.857113, loss_s1: 0.505668, loss_fp: 0.500034, loss_freq: 0.503422
[01:38:31.079] iteration 1538: loss: 0.885240, loss_s1: 0.504647, loss_fp: 0.500291, loss_freq: 0.501284
[01:38:52.047] iteration 1539: loss: 0.860056, loss_s1: 0.505719, loss_fp: 0.500020, loss_freq: 0.501840
[01:39:13.005] iteration 1540: loss: 0.858118, loss_s1: 0.502217, loss_fp: 0.500044, loss_freq: 0.500746
[01:39:13.987] iteration 1541: loss: 0.846874, loss_s1: 0.502422, loss_fp: 0.500015, loss_freq: 0.502479
[01:39:14.673] iteration 1542: loss: 0.879615, loss_s1: 0.505772, loss_fp: 0.500019, loss_freq: 0.505273
[01:39:15.362] iteration 1543: loss: 0.860343, loss_s1: 0.507963, loss_fp: 0.500006, loss_freq: 0.504165
[01:39:17.126] iteration 1544: loss: 0.848451, loss_s1: 0.502466, loss_fp: 0.500026, loss_freq: 0.501911
[01:39:18.198] iteration 1545: loss: 0.905293, loss_s1: 0.501158, loss_fp: 0.500416, loss_freq: 0.500323
[01:39:18.884] iteration 1546: loss: 0.654195, loss_s1: 0.497011, loss_fp: 0.086547, loss_freq: 0.487799
[01:39:19.568] iteration 1547: loss: 0.849977, loss_s1: 0.503995, loss_fp: 0.500142, loss_freq: 0.502041
[01:39:20.259] iteration 1548: loss: 0.862873, loss_s1: 0.486075, loss_fp: 0.500029, loss_freq: 0.500482
[01:39:20.930] iteration 1549: loss: 0.887933, loss_s1: 0.502931, loss_fp: 0.500013, loss_freq: 0.500418
[01:39:21.634] iteration 1550: loss: 0.831544, loss_s1: 0.425157, loss_fp: 0.500020, loss_freq: 0.500343
[01:39:22.300] iteration 1551: loss: 0.883991, loss_s1: 0.506556, loss_fp: 0.500027, loss_freq: 0.502604
[01:39:22.953] iteration 1552: loss: 0.872407, loss_s1: 0.504052, loss_fp: 0.500035, loss_freq: 0.502000
[01:39:23.615] iteration 1553: loss: 0.921274, loss_s1: 0.479480, loss_fp: 0.500006, loss_freq: 0.501264
[01:39:24.272] iteration 1554: loss: 0.836683, loss_s1: 0.502917, loss_fp: 0.500076, loss_freq: 0.501665
[01:39:24.934] iteration 1555: loss: 0.862062, loss_s1: 0.500577, loss_fp: 0.500034, loss_freq: 0.500459
[01:39:25.623] iteration 1556: loss: 0.838047, loss_s1: 0.505605, loss_fp: 0.433303, loss_freq: 0.500380
[01:39:26.289] iteration 1557: loss: 0.859406, loss_s1: 0.501086, loss_fp: 0.500002, loss_freq: 0.501085
[01:39:26.971] iteration 1558: loss: 0.876655, loss_s1: 0.511894, loss_fp: 0.500099, loss_freq: 0.501924
[01:39:27.643] iteration 1559: loss: 0.899357, loss_s1: 0.502172, loss_fp: 0.500128, loss_freq: 0.501290
[01:39:28.295] iteration 1560: loss: 0.869928, loss_s1: 0.505213, loss_fp: 0.500008, loss_freq: 0.501464
[01:39:28.964] iteration 1561: loss: 0.837331, loss_s1: 0.506644, loss_fp: 0.500036, loss_freq: 0.501212
[01:39:29.618] iteration 1562: loss: 0.927131, loss_s1: 0.504358, loss_fp: 0.500006, loss_freq: 0.505107
[01:39:30.278] iteration 1563: loss: 0.873465, loss_s1: 0.502749, loss_fp: 0.500009, loss_freq: 0.504253
[01:39:30.949] iteration 1564: loss: 0.860174, loss_s1: 0.503015, loss_fp: 0.500014, loss_freq: 0.501086
[01:39:31.933] iteration 1565: loss: 0.836848, loss_s1: 0.504816, loss_fp: 0.500007, loss_freq: 0.505148
[01:39:32.838] iteration 1566: loss: 0.871034, loss_s1: 0.502606, loss_fp: 0.500040, loss_freq: 0.500147
[01:39:33.906] iteration 1567: loss: 0.867789, loss_s1: 0.503362, loss_fp: 0.500012, loss_freq: 0.502045
[01:39:34.633] iteration 1568: loss: 0.841694, loss_s1: 0.504253, loss_fp: 0.500011, loss_freq: 0.501274
[01:39:35.304] iteration 1569: loss: 0.848247, loss_s1: 0.501212, loss_fp: 0.500027, loss_freq: 0.501308
[01:39:35.964] iteration 1570: loss: 0.657439, loss_s1: 0.486720, loss_fp: 0.117956, loss_freq: 0.465076
[01:39:36.601] iteration 1571: loss: 0.873062, loss_s1: 0.504567, loss_fp: 0.500008, loss_freq: 0.503584
[01:39:37.263] iteration 1572: loss: 0.836045, loss_s1: 0.506503, loss_fp: 0.500005, loss_freq: 0.501630
[01:39:37.905] iteration 1573: loss: 0.619823, loss_s1: 0.501817, loss_fp: 0.082774, loss_freq: 0.405072
[01:39:38.553] iteration 1574: loss: 0.826244, loss_s1: 0.500824, loss_fp: 0.500008, loss_freq: 0.500393
[01:39:39.237] iteration 1575: loss: 0.921820, loss_s1: 0.502192, loss_fp: 0.499999, loss_freq: 0.500177
[01:39:39.903] iteration 1576: loss: 0.864974, loss_s1: 0.480111, loss_fp: 0.500007, loss_freq: 0.500151
[01:39:40.581] iteration 1577: loss: 0.981760, loss_s1: 0.464418, loss_fp: 0.500009, loss_freq: 0.500197
[01:39:41.250] iteration 1578: loss: 0.935502, loss_s1: 0.505390, loss_fp: 0.500018, loss_freq: 0.500474
[01:39:41.923] iteration 1579: loss: 0.585248, loss_s1: 0.405513, loss_fp: 0.055390, loss_freq: 0.351776
[01:39:42.600] iteration 1580: loss: 0.914609, loss_s1: 0.502220, loss_fp: 0.500013, loss_freq: 0.502920
[01:39:43.271] iteration 1581: loss: 0.931163, loss_s1: 0.502753, loss_fp: 0.500000, loss_freq: 0.500410
[01:39:43.967] iteration 1582: loss: 0.951916, loss_s1: 0.500556, loss_fp: 0.500005, loss_freq: 0.500238
[01:39:44.647] iteration 1583: loss: 0.892928, loss_s1: 0.502021, loss_fp: 0.499998, loss_freq: 0.503315
[01:39:45.322] iteration 1584: loss: 0.866812, loss_s1: 0.500869, loss_fp: 0.500017, loss_freq: 0.504102
[01:39:46.005] iteration 1585: loss: 0.886397, loss_s1: 0.501133, loss_fp: 0.500004, loss_freq: 0.500754
[01:39:46.688] iteration 1586: loss: 0.903351, loss_s1: 0.502815, loss_fp: 0.500001, loss_freq: 0.500466
[01:39:47.368] iteration 1587: loss: 0.630475, loss_s1: 0.460794, loss_fp: 0.096884, loss_freq: 0.488286
[01:39:48.088] iteration 1588: loss: 0.932128, loss_s1: 0.501483, loss_fp: 0.500007, loss_freq: 0.501082
[01:39:48.834] iteration 1589: loss: 0.602910, loss_s1: 0.490627, loss_fp: 0.030010, loss_freq: 0.273567
[01:39:49.541] iteration 1590: loss: 0.844126, loss_s1: 0.504210, loss_fp: 0.500000, loss_freq: 0.500399
[01:39:50.261] iteration 1591: loss: 0.970716, loss_s1: 0.502873, loss_fp: 0.500003, loss_freq: 0.501451
[01:39:51.001] iteration 1592: loss: 0.877225, loss_s1: 0.504703, loss_fp: 0.500002, loss_freq: 0.501811
[01:39:51.756] iteration 1593: loss: 0.884491, loss_s1: 0.501647, loss_fp: 0.500008, loss_freq: 0.500703
[01:39:52.493] iteration 1594: loss: 1.002230, loss_s1: 0.500569, loss_fp: 0.500129, loss_freq: 0.500318
[01:39:53.170] iteration 1595: loss: 0.949161, loss_s1: 0.502595, loss_fp: 0.500015, loss_freq: 0.500059
[01:39:53.908] iteration 1596: loss: 0.855543, loss_s1: 0.500681, loss_fp: 0.500000, loss_freq: 0.500268
[01:39:54.602] iteration 1597: loss: 0.985720, loss_s1: 0.503678, loss_fp: 0.500014, loss_freq: 0.500305
[01:39:55.333] iteration 1598: loss: 0.912467, loss_s1: 0.506810, loss_fp: 0.500019, loss_freq: 0.500206
[01:39:55.998] iteration 1599: loss: 0.937381, loss_s1: 0.502475, loss_fp: 0.500001, loss_freq: 0.500542
[01:39:56.697] iteration 1600: loss: 0.944437, loss_s1: 0.501662, loss_fp: 0.499999, loss_freq: 0.500168
[01:39:58.968] iteration 1600 : mean_dice : 0.070114
[01:39:59.943] iteration 1601: loss: 0.904734, loss_s1: 0.501441, loss_fp: 0.500000, loss_freq: 0.500443
[01:40:00.628] iteration 1602: loss: 0.924386, loss_s1: 0.500603, loss_fp: 0.499998, loss_freq: 0.500426
[01:40:01.310] iteration 1603: loss: 0.937761, loss_s1: 0.504950, loss_fp: 0.500006, loss_freq: 0.500811
[01:40:01.964] iteration 1604: loss: 0.900597, loss_s1: 0.505650, loss_fp: 0.500023, loss_freq: 0.501946
[01:40:02.643] iteration 1605: loss: 0.912637, loss_s1: 0.503637, loss_fp: 0.500070, loss_freq: 0.500730
[01:40:03.302] iteration 1606: loss: 0.917267, loss_s1: 0.501826, loss_fp: 0.499999, loss_freq: 0.500256
[01:40:03.966] iteration 1607: loss: 0.904554, loss_s1: 0.503141, loss_fp: 0.500015, loss_freq: 0.500216
[01:40:04.626] iteration 1608: loss: 0.922953, loss_s1: 0.501163, loss_fp: 0.499999, loss_freq: 0.500289
[01:40:05.276] iteration 1609: loss: 0.867680, loss_s1: 0.502226, loss_fp: 0.500007, loss_freq: 0.500178
[01:40:05.973] iteration 1610: loss: 0.909071, loss_s1: 0.501696, loss_fp: 0.500003, loss_freq: 0.500540
[01:40:06.655] iteration 1611: loss: 0.860040, loss_s1: 0.502015, loss_fp: 0.500007, loss_freq: 0.500867
[01:40:07.342] iteration 1612: loss: 0.883389, loss_s1: 0.500691, loss_fp: 0.500019, loss_freq: 0.500175
[01:40:08.014] iteration 1613: loss: 0.892028, loss_s1: 0.501551, loss_fp: 0.500020, loss_freq: 0.500162
[01:40:08.705] iteration 1614: loss: 0.894446, loss_s1: 0.502035, loss_fp: 0.500000, loss_freq: 0.500508
[01:40:09.383] iteration 1615: loss: 0.883724, loss_s1: 0.500666, loss_fp: 0.500000, loss_freq: 0.502132
[01:40:10.033] iteration 1616: loss: 0.870452, loss_s1: 0.500854, loss_fp: 0.500003, loss_freq: 0.500261
[01:40:10.705] iteration 1617: loss: 0.847838, loss_s1: 0.500990, loss_fp: 0.500003, loss_freq: 0.500219
[01:40:11.359] iteration 1618: loss: 0.871813, loss_s1: 0.501582, loss_fp: 0.500006, loss_freq: 0.500948
[01:40:12.016] iteration 1619: loss: 0.872959, loss_s1: 0.503400, loss_fp: 0.500005, loss_freq: 0.501875
[01:40:12.675] iteration 1620: loss: 0.869042, loss_s1: 0.501240, loss_fp: 0.500016, loss_freq: 0.500567
[01:40:13.340] iteration 1621: loss: 0.854377, loss_s1: 0.504783, loss_fp: 0.499999, loss_freq: 0.500948
[01:40:14.015] iteration 1622: loss: 0.845247, loss_s1: 0.504956, loss_fp: 0.500004, loss_freq: 0.502552
[01:40:14.736] iteration 1623: loss: 0.867294, loss_s1: 0.505696, loss_fp: 0.500078, loss_freq: 0.501593
[01:40:15.403] iteration 1624: loss: 0.851370, loss_s1: 0.504382, loss_fp: 0.500012, loss_freq: 0.502357
[01:40:16.063] iteration 1625: loss: 0.831912, loss_s1: 0.485152, loss_fp: 0.500006, loss_freq: 0.500587
[01:40:16.722] iteration 1626: loss: 0.856412, loss_s1: 0.501126, loss_fp: 0.500040, loss_freq: 0.500266
[01:40:17.404] iteration 1627: loss: 0.901616, loss_s1: 0.506271, loss_fp: 0.500018, loss_freq: 0.503120
[01:40:18.074] iteration 1628: loss: 0.885910, loss_s1: 0.507344, loss_fp: 0.500003, loss_freq: 0.504565
[01:40:18.769] iteration 1629: loss: 0.313725, loss_s1: 0.269732, loss_fp: 0.025027, loss_freq: 0.097798
[01:40:19.441] iteration 1630: loss: 0.851462, loss_s1: 0.502874, loss_fp: 0.500015, loss_freq: 0.500652
[01:40:20.105] iteration 1631: loss: 0.818181, loss_s1: 0.502935, loss_fp: 0.500006, loss_freq: 0.501700
[01:40:20.762] iteration 1632: loss: 0.906517, loss_s1: 0.503773, loss_fp: 0.499999, loss_freq: 0.501213
[01:40:21.436] iteration 1633: loss: 0.439159, loss_s1: 0.212771, loss_fp: 0.345448, loss_freq: 0.092999
[01:40:22.157] iteration 1634: loss: 0.534665, loss_s1: 0.498806, loss_fp: 0.007847, loss_freq: 0.313208
[01:40:22.855] iteration 1635: loss: 0.377216, loss_s1: 0.377606, loss_fp: 0.001825, loss_freq: 0.079856
[01:40:23.499] iteration 1636: loss: 0.712874, loss_s1: 0.488840, loss_fp: 0.124179, loss_freq: 0.428429
[01:40:24.165] iteration 1637: loss: 0.911274, loss_s1: 0.501763, loss_fp: 0.500007, loss_freq: 0.500717
[01:40:24.850] iteration 1638: loss: 1.012348, loss_s1: 0.500507, loss_fp: 0.500001, loss_freq: 0.500066
[01:40:25.506] iteration 1639: loss: 1.053092, loss_s1: 0.504928, loss_fp: 0.500005, loss_freq: 0.500997
[01:40:26.180] iteration 1640: loss: 1.056988, loss_s1: 0.502701, loss_fp: 0.500029, loss_freq: 0.500323
[01:40:26.882] iteration 1641: loss: 0.998909, loss_s1: 0.501209, loss_fp: 0.500002, loss_freq: 0.500736
[01:40:27.530] iteration 1642: loss: 1.008357, loss_s1: 0.503169, loss_fp: 0.500144, loss_freq: 0.500793
[01:40:28.182] iteration 1643: loss: 1.003945, loss_s1: 0.500834, loss_fp: 0.500001, loss_freq: 0.500081
[01:40:28.873] iteration 1644: loss: 1.015175, loss_s1: 0.501588, loss_fp: 0.500005, loss_freq: 0.501553
[01:40:29.515] iteration 1645: loss: 1.076900, loss_s1: 0.507481, loss_fp: 0.500002, loss_freq: 0.503753
[01:40:30.196] iteration 1646: loss: 0.997090, loss_s1: 0.503075, loss_fp: 0.500023, loss_freq: 0.504856
[01:40:30.861] iteration 1647: loss: 1.063730, loss_s1: 0.502976, loss_fp: 0.500006, loss_freq: 0.501413
[01:40:31.551] iteration 1648: loss: 0.995701, loss_s1: 0.501491, loss_fp: 0.500002, loss_freq: 0.501329
[01:40:32.195] iteration 1649: loss: 0.923596, loss_s1: 0.502605, loss_fp: 0.500012, loss_freq: 0.500499
[01:40:32.896] iteration 1650: loss: 0.975738, loss_s1: 0.502281, loss_fp: 0.500014, loss_freq: 0.501282
[01:40:33.537] iteration 1651: loss: 0.986787, loss_s1: 0.501853, loss_fp: 0.500007, loss_freq: 0.500377
[01:40:34.211] iteration 1652: loss: 0.996158, loss_s1: 0.500514, loss_fp: 0.500510, loss_freq: 0.500158
[01:40:34.853] iteration 1653: loss: 0.997849, loss_s1: 0.504315, loss_fp: 0.500015, loss_freq: 0.500965
[01:40:35.549] iteration 1654: loss: 0.938271, loss_s1: 0.500569, loss_fp: 0.500031, loss_freq: 0.501173
[01:40:36.185] iteration 1655: loss: 0.967953, loss_s1: 0.500367, loss_fp: 0.500549, loss_freq: 0.500531
[01:40:36.885] iteration 1656: loss: 1.003367, loss_s1: 0.500455, loss_fp: 0.500024, loss_freq: 0.500352
[01:40:37.521] iteration 1657: loss: 0.940499, loss_s1: 0.502374, loss_fp: 0.500018, loss_freq: 0.502464
[01:40:38.166] iteration 1658: loss: 1.003407, loss_s1: 0.503580, loss_fp: 0.500024, loss_freq: 0.501915
[01:40:38.834] iteration 1659: loss: 0.975743, loss_s1: 0.501579, loss_fp: 0.500281, loss_freq: 0.500453
[01:40:39.528] iteration 1660: loss: 0.920319, loss_s1: 0.503671, loss_fp: 0.500063, loss_freq: 0.501644
[01:40:40.168] iteration 1661: loss: 0.984297, loss_s1: 0.501272, loss_fp: 0.500052, loss_freq: 0.500237
[01:40:40.808] iteration 1662: loss: 0.965046, loss_s1: 0.500509, loss_fp: 0.500034, loss_freq: 0.500415
[01:40:41.533] iteration 1663: loss: 0.925946, loss_s1: 0.500416, loss_fp: 0.500045, loss_freq: 0.500641
[01:40:42.276] iteration 1664: loss: 0.996993, loss_s1: 0.504580, loss_fp: 0.500186, loss_freq: 0.500871
[01:40:42.939] iteration 1665: loss: 0.994322, loss_s1: 0.507146, loss_fp: 0.500070, loss_freq: 0.500515
[01:40:43.595] iteration 1666: loss: 0.914396, loss_s1: 0.501327, loss_fp: 0.500038, loss_freq: 0.501488
[01:40:44.306] iteration 1667: loss: 1.012211, loss_s1: 0.500816, loss_fp: 0.500039, loss_freq: 0.500394
[01:40:44.960] iteration 1668: loss: 0.927459, loss_s1: 0.501912, loss_fp: 0.500052, loss_freq: 0.500221
[01:40:45.651] iteration 1669: loss: 0.943870, loss_s1: 0.501833, loss_fp: 0.500088, loss_freq: 0.500268
[01:40:46.394] iteration 1670: loss: 0.929120, loss_s1: 0.502959, loss_fp: 0.500041, loss_freq: 0.500230
[01:40:47.061] iteration 1671: loss: 0.920339, loss_s1: 0.500912, loss_fp: 0.500015, loss_freq: 0.500274
[01:40:47.743] iteration 1672: loss: 0.928030, loss_s1: 0.503599, loss_fp: 0.500005, loss_freq: 0.500878
[01:40:48.513] iteration 1673: loss: 0.921972, loss_s1: 0.501660, loss_fp: 0.500042, loss_freq: 0.500393
[01:40:49.249] iteration 1674: loss: 0.929764, loss_s1: 0.509265, loss_fp: 0.500199, loss_freq: 0.500210
[01:40:49.966] iteration 1675: loss: 0.918352, loss_s1: 0.500855, loss_fp: 0.500242, loss_freq: 0.500548
[01:40:50.690] iteration 1676: loss: 0.939445, loss_s1: 0.503335, loss_fp: 0.500030, loss_freq: 0.500950
[01:40:51.411] iteration 1677: loss: 0.893413, loss_s1: 0.503259, loss_fp: 0.500059, loss_freq: 0.500089
[01:40:52.103] iteration 1678: loss: 0.915548, loss_s1: 0.506809, loss_fp: 0.500020, loss_freq: 0.500338
[01:40:52.771] iteration 1679: loss: 0.933729, loss_s1: 0.504129, loss_fp: 0.500109, loss_freq: 0.500571
[01:40:53.413] iteration 1680: loss: 0.674987, loss_s1: 0.459599, loss_fp: 0.109979, loss_freq: 0.443392
[01:40:54.077] iteration 1681: loss: 0.895363, loss_s1: 0.505103, loss_fp: 0.500096, loss_freq: 0.501189
[01:40:54.710] iteration 1682: loss: 0.974882, loss_s1: 0.502672, loss_fp: 0.500020, loss_freq: 0.500350
[01:40:55.373] iteration 1683: loss: 0.981309, loss_s1: 0.502628, loss_fp: 0.500129, loss_freq: 0.500635
[01:40:56.065] iteration 1684: loss: 0.996288, loss_s1: 0.500434, loss_fp: 0.500005, loss_freq: 0.500038
[01:40:56.706] iteration 1685: loss: 0.987780, loss_s1: 0.502594, loss_fp: 0.500052, loss_freq: 0.500295
[01:40:57.345] iteration 1686: loss: 0.919933, loss_s1: 0.502430, loss_fp: 0.500009, loss_freq: 0.500419
[01:40:58.051] iteration 1687: loss: 0.900234, loss_s1: 0.502943, loss_fp: 0.500032, loss_freq: 0.503091
[01:40:58.736] iteration 1688: loss: 0.909838, loss_s1: 0.508517, loss_fp: 0.500332, loss_freq: 0.501088
[01:40:59.402] iteration 1689: loss: 0.869732, loss_s1: 0.509877, loss_fp: 0.500014, loss_freq: 0.504861
[01:41:00.114] iteration 1690: loss: 0.886031, loss_s1: 0.505425, loss_fp: 0.500014, loss_freq: 0.500430
[01:41:00.817] iteration 1691: loss: 0.918877, loss_s1: 0.503158, loss_fp: 0.500009, loss_freq: 0.501628
[01:41:01.490] iteration 1692: loss: 0.522794, loss_s1: 0.502664, loss_fp: 0.042072, loss_freq: 0.213509
[01:41:02.165] iteration 1693: loss: 0.928281, loss_s1: 0.507417, loss_fp: 0.500050, loss_freq: 0.503044
[01:41:02.844] iteration 1694: loss: 0.859500, loss_s1: 0.504780, loss_fp: 0.500033, loss_freq: 0.500654
[01:41:03.482] iteration 1695: loss: 0.892520, loss_s1: 0.502382, loss_fp: 0.500199, loss_freq: 0.500031
[01:41:04.164] iteration 1696: loss: 0.522378, loss_s1: 0.498939, loss_fp: 0.027755, loss_freq: 0.174185
[01:41:04.802] iteration 1697: loss: 0.943583, loss_s1: 0.500346, loss_fp: 0.500018, loss_freq: 0.500114
[01:41:05.535] iteration 1698: loss: 0.901549, loss_s1: 0.504980, loss_fp: 0.500011, loss_freq: 0.500412
[01:41:06.235] iteration 1699: loss: 0.951746, loss_s1: 0.502730, loss_fp: 0.500005, loss_freq: 0.500048
[01:41:06.926] iteration 1700: loss: 0.888684, loss_s1: 0.502345, loss_fp: 0.500053, loss_freq: 0.500194
[01:41:07.994] iteration 1701: loss: 0.932199, loss_s1: 0.501599, loss_fp: 0.500015, loss_freq: 0.500160
[01:41:08.728] iteration 1702: loss: 0.882466, loss_s1: 0.500459, loss_fp: 0.500021, loss_freq: 0.501588
[01:41:09.462] iteration 1703: loss: 0.487595, loss_s1: 0.438645, loss_fp: 0.014117, loss_freq: 0.085071
[01:41:10.172] iteration 1704: loss: 0.945330, loss_s1: 0.501181, loss_fp: 0.500017, loss_freq: 0.502305
[01:41:10.881] iteration 1705: loss: 0.940899, loss_s1: 0.502496, loss_fp: 0.500004, loss_freq: 0.500006
[01:41:11.604] iteration 1706: loss: 0.953694, loss_s1: 0.501111, loss_fp: 0.500008, loss_freq: 0.500436
[01:41:12.329] iteration 1707: loss: 0.932344, loss_s1: 0.503900, loss_fp: 0.500140, loss_freq: 0.500773
[01:41:13.078] iteration 1708: loss: 0.956760, loss_s1: 0.503345, loss_fp: 0.500002, loss_freq: 0.500030
[01:41:13.798] iteration 1709: loss: 0.942228, loss_s1: 0.500504, loss_fp: 0.500006, loss_freq: 0.500038
[01:41:14.484] iteration 1710: loss: 0.900501, loss_s1: 0.503709, loss_fp: 0.500013, loss_freq: 0.500073
[01:41:15.180] iteration 1711: loss: 0.961825, loss_s1: 0.504365, loss_fp: 0.500008, loss_freq: 0.502706
[01:41:15.870] iteration 1712: loss: 0.962444, loss_s1: 0.504284, loss_fp: 0.500039, loss_freq: 0.502563
[01:41:16.576] iteration 1713: loss: 0.974603, loss_s1: 0.506395, loss_fp: 0.500031, loss_freq: 0.502547
[01:41:17.265] iteration 1714: loss: 0.877492, loss_s1: 0.501300, loss_fp: 0.500020, loss_freq: 0.500235
[01:41:17.900] iteration 1715: loss: 0.937901, loss_s1: 0.500373, loss_fp: 0.500003, loss_freq: 0.500074
[01:41:18.557] iteration 1716: loss: 0.885434, loss_s1: 0.502023, loss_fp: 0.500014, loss_freq: 0.500591
[01:41:19.196] iteration 1717: loss: 0.885607, loss_s1: 0.501802, loss_fp: 0.500078, loss_freq: 0.500989
[01:41:19.851] iteration 1718: loss: 0.903892, loss_s1: 0.500158, loss_fp: 0.500005, loss_freq: 0.500032
[01:41:20.516] iteration 1719: loss: 0.911234, loss_s1: 0.500744, loss_fp: 0.500002, loss_freq: 0.500014
[01:41:21.149] iteration 1720: loss: 0.876589, loss_s1: 0.500249, loss_fp: 0.500022, loss_freq: 0.500087
[01:41:21.826] iteration 1721: loss: 0.905834, loss_s1: 0.502610, loss_fp: 0.500061, loss_freq: 0.500372
[01:41:22.467] iteration 1722: loss: 0.881714, loss_s1: 0.502391, loss_fp: 0.500051, loss_freq: 0.501039
[01:41:23.124] iteration 1723: loss: 0.949503, loss_s1: 0.501027, loss_fp: 0.500017, loss_freq: 0.500091
[01:41:23.801] iteration 1724: loss: 0.879026, loss_s1: 0.501425, loss_fp: 0.500349, loss_freq: 0.500227
[01:41:24.441] iteration 1725: loss: 0.857216, loss_s1: 0.504236, loss_fp: 0.500084, loss_freq: 0.500126
[01:41:25.114] iteration 1726: loss: 0.931239, loss_s1: 0.500892, loss_fp: 0.500038, loss_freq: 0.500089
[01:41:25.744] iteration 1727: loss: 0.881309, loss_s1: 0.501202, loss_fp: 0.500009, loss_freq: 0.500046
[01:41:26.416] iteration 1728: loss: 0.876363, loss_s1: 0.501274, loss_fp: 0.500030, loss_freq: 0.500644
[01:41:27.057] iteration 1729: loss: 0.879190, loss_s1: 0.503471, loss_fp: 0.500014, loss_freq: 0.500196
[01:41:27.757] iteration 1730: loss: 0.878562, loss_s1: 0.501608, loss_fp: 0.500201, loss_freq: 0.500183
[01:41:28.462] iteration 1731: loss: 0.851539, loss_s1: 0.503281, loss_fp: 0.500021, loss_freq: 0.500199
[01:41:29.151] iteration 1732: loss: 0.939273, loss_s1: 0.502591, loss_fp: 0.500008, loss_freq: 0.501274
[01:41:29.811] iteration 1733: loss: 0.875426, loss_s1: 0.504898, loss_fp: 0.500087, loss_freq: 0.501404
[01:41:30.473] iteration 1734: loss: 0.880309, loss_s1: 0.501077, loss_fp: 0.500011, loss_freq: 0.500740
[01:41:31.151] iteration 1735: loss: 0.843319, loss_s1: 0.501390, loss_fp: 0.500044, loss_freq: 0.501845
[01:41:31.828] iteration 1736: loss: 0.884853, loss_s1: 0.492143, loss_fp: 0.500010, loss_freq: 0.500092
[01:41:32.557] iteration 1737: loss: 0.836189, loss_s1: 0.501809, loss_fp: 0.500013, loss_freq: 0.500465
[01:41:33.261] iteration 1738: loss: 0.896380, loss_s1: 0.502218, loss_fp: 0.500076, loss_freq: 0.500050
[01:41:33.942] iteration 1739: loss: 0.864753, loss_s1: 0.503969, loss_fp: 0.500022, loss_freq: 0.501107
[01:41:34.625] iteration 1740: loss: 0.868826, loss_s1: 0.505237, loss_fp: 0.500009, loss_freq: 0.500325
[01:41:35.317] iteration 1741: loss: 0.867093, loss_s1: 0.508328, loss_fp: 0.500029, loss_freq: 0.501565
[01:41:36.014] iteration 1742: loss: 0.861481, loss_s1: 0.506608, loss_fp: 0.500347, loss_freq: 0.501447
[01:41:36.704] iteration 1743: loss: 0.896389, loss_s1: 0.500475, loss_fp: 0.500001, loss_freq: 0.502138
[01:41:37.394] iteration 1744: loss: 0.866090, loss_s1: 0.502937, loss_fp: 0.500077, loss_freq: 0.502041
[01:41:38.111] iteration 1745: loss: 0.631873, loss_s1: 0.471166, loss_fp: 0.107745, loss_freq: 0.382064
[01:41:38.818] iteration 1746: loss: 0.755367, loss_s1: 0.339344, loss_fp: 0.500048, loss_freq: 0.501729
[01:41:39.517] iteration 1747: loss: 0.896954, loss_s1: 0.501464, loss_fp: 0.500013, loss_freq: 0.500267
[01:41:40.238] iteration 1748: loss: 0.872069, loss_s1: 0.502510, loss_fp: 0.500027, loss_freq: 0.500930
[01:41:40.955] iteration 1749: loss: 0.354673, loss_s1: 0.366014, loss_fp: 0.008237, loss_freq: 0.034330
[01:41:41.628] iteration 1750: loss: 0.976914, loss_s1: 0.505053, loss_fp: 0.500005, loss_freq: 0.501221
[01:41:42.306] iteration 1751: loss: 0.902693, loss_s1: 0.504320, loss_fp: 0.500062, loss_freq: 0.500765
[01:41:42.970] iteration 1752: loss: 0.488516, loss_s1: 0.489611, loss_fp: 0.046233, loss_freq: 0.127839
[01:41:43.695] iteration 1753: loss: 0.692205, loss_s1: 0.477959, loss_fp: 0.042774, loss_freq: 0.452572
[01:41:44.338] iteration 1754: loss: 0.964590, loss_s1: 0.502129, loss_fp: 0.500042, loss_freq: 0.501059
[01:41:45.011] iteration 1755: loss: 0.929772, loss_s1: 0.503075, loss_fp: 0.500045, loss_freq: 0.501578
[01:41:45.677] iteration 1756: loss: 1.008466, loss_s1: 0.501401, loss_fp: 0.500004, loss_freq: 0.500035
[01:41:46.346] iteration 1757: loss: 0.897255, loss_s1: 0.502364, loss_fp: 0.500024, loss_freq: 0.500504
[01:41:47.020] iteration 1758: loss: 1.003746, loss_s1: 0.505373, loss_fp: 0.500022, loss_freq: 0.500934
[01:41:47.664] iteration 1759: loss: 1.022544, loss_s1: 0.502257, loss_fp: 0.500022, loss_freq: 0.500240
[01:41:48.360] iteration 1760: loss: 0.863269, loss_s1: 0.502298, loss_fp: 0.500024, loss_freq: 0.501468
[01:41:49.004] iteration 1761: loss: 0.722325, loss_s1: 0.503012, loss_fp: 0.154473, loss_freq: 0.471661
[01:41:49.683] iteration 1762: loss: 0.901386, loss_s1: 0.507401, loss_fp: 0.500007, loss_freq: 0.500482
[01:41:50.351] iteration 1763: loss: 0.939264, loss_s1: 0.504582, loss_fp: 0.500008, loss_freq: 0.501375
[01:41:51.113] iteration 1764: loss: 0.291601, loss_s1: 0.144711, loss_fp: 0.001920, loss_freq: 0.041443
[01:41:51.895] iteration 1765: loss: 0.961277, loss_s1: 0.502041, loss_fp: 0.500224, loss_freq: 0.500524
[01:41:52.757] iteration 1766: loss: 0.886275, loss_s1: 0.500625, loss_fp: 0.500003, loss_freq: 0.500067
[01:41:53.647] iteration 1767: loss: 1.005790, loss_s1: 0.501544, loss_fp: 0.500004, loss_freq: 0.500050
[01:41:54.412] iteration 1768: loss: 0.931401, loss_s1: 0.500268, loss_fp: 0.500111, loss_freq: 0.500228
[01:41:55.124] iteration 1769: loss: 0.453017, loss_s1: 0.498097, loss_fp: 0.009008, loss_freq: 0.014516
[01:41:55.792] iteration 1770: loss: 0.507390, loss_s1: 0.497730, loss_fp: 0.059391, loss_freq: 0.090551
[01:41:56.412] iteration 1771: loss: 0.244983, loss_s1: 0.109042, loss_fp: 0.010937, loss_freq: 0.029244
[01:41:57.145] iteration 1772: loss: 0.894025, loss_s1: 0.454915, loss_fp: 0.500001, loss_freq: 0.500019
[01:41:57.853] iteration 1773: loss: 0.486815, loss_s1: 0.468741, loss_fp: 0.007997, loss_freq: 0.024918
[01:41:58.644] iteration 1774: loss: 0.943744, loss_s1: 0.501937, loss_fp: 0.500006, loss_freq: 0.500099
[01:41:59.368] iteration 1775: loss: 0.195740, loss_s1: 0.051702, loss_fp: 0.001400, loss_freq: 0.001892
[01:42:00.128] iteration 1776: loss: 0.971156, loss_s1: 0.502201, loss_fp: 0.500010, loss_freq: 0.500341
[01:42:00.933] iteration 1777: loss: 0.930194, loss_s1: 0.502588, loss_fp: 0.500022, loss_freq: 0.500025
[01:42:01.696] iteration 1778: loss: 0.508212, loss_s1: 0.429621, loss_fp: 0.013064, loss_freq: 0.180707
[01:42:02.731] iteration 1779: loss: 0.915394, loss_s1: 0.507449, loss_fp: 0.500011, loss_freq: 0.500054
[01:42:03.476] iteration 1780: loss: 0.908409, loss_s1: 0.503806, loss_fp: 0.500009, loss_freq: 0.500041
[01:42:04.299] iteration 1781: loss: 0.912952, loss_s1: 0.502238, loss_fp: 0.499999, loss_freq: 0.501456
[01:42:05.107] iteration 1782: loss: 0.976348, loss_s1: 0.500761, loss_fp: 0.500003, loss_freq: 0.500392
[01:42:05.912] iteration 1783: loss: 0.946971, loss_s1: 0.502066, loss_fp: 0.500004, loss_freq: 0.500169
[01:42:06.847] iteration 1784: loss: 0.917461, loss_s1: 0.502440, loss_fp: 0.500037, loss_freq: 0.500362
[01:42:07.600] iteration 1785: loss: 0.926987, loss_s1: 0.501467, loss_fp: 0.500064, loss_freq: 0.500219
[01:42:08.323] iteration 1786: loss: 0.943353, loss_s1: 0.501449, loss_fp: 0.500046, loss_freq: 0.500439
[01:42:09.017] iteration 1787: loss: 0.889509, loss_s1: 0.501965, loss_fp: 0.500006, loss_freq: 0.500063
[01:42:09.744] iteration 1788: loss: 0.944365, loss_s1: 0.500446, loss_fp: 0.500022, loss_freq: 0.500319
[01:42:10.410] iteration 1789: loss: 0.877288, loss_s1: 0.501880, loss_fp: 0.499997, loss_freq: 0.500351
[01:42:11.142] iteration 1790: loss: 0.921617, loss_s1: 0.502346, loss_fp: 0.500001, loss_freq: 0.500027
[01:42:11.853] iteration 1791: loss: 0.874117, loss_s1: 0.500068, loss_fp: 0.500005, loss_freq: 0.500489
[01:42:12.501] iteration 1792: loss: 0.846258, loss_s1: 0.502637, loss_fp: 0.500015, loss_freq: 0.500134
[01:42:13.166] iteration 1793: loss: 0.923200, loss_s1: 0.505477, loss_fp: 0.500047, loss_freq: 0.500247
[01:42:13.788] iteration 1794: loss: 0.886840, loss_s1: 0.501048, loss_fp: 0.500006, loss_freq: 0.500337
[01:42:14.429] iteration 1795: loss: 0.787725, loss_s1: 0.361114, loss_fp: 0.500005, loss_freq: 0.500150
[01:42:15.077] iteration 1796: loss: 0.352298, loss_s1: 0.426968, loss_fp: 0.002612, loss_freq: 0.006024
[01:42:15.729] iteration 1797: loss: 0.653391, loss_s1: 0.490215, loss_fp: 0.060259, loss_freq: 0.454300
[01:42:16.349] iteration 1798: loss: 0.880997, loss_s1: 0.500495, loss_fp: 0.500000, loss_freq: 0.500699
[01:42:16.977] iteration 1799: loss: 0.242071, loss_s1: 0.195732, loss_fp: 0.007060, loss_freq: 0.002704
[01:42:17.603] iteration 1800: loss: 0.876427, loss_s1: 0.500580, loss_fp: 0.500007, loss_freq: 0.500048
[01:42:20.306] iteration 1800 : mean_dice : 0.134958
[01:42:20.984] iteration 1801: loss: 0.862557, loss_s1: 0.501000, loss_fp: 0.500016, loss_freq: 0.500605
[01:42:21.644] iteration 1802: loss: 0.971049, loss_s1: 0.500952, loss_fp: 0.500001, loss_freq: 0.500187
[01:42:22.301] iteration 1803: loss: 0.689043, loss_s1: 0.143072, loss_fp: 0.500020, loss_freq: 0.500008
[01:42:22.955] iteration 1804: loss: 0.880229, loss_s1: 0.500490, loss_fp: 0.500013, loss_freq: 0.500322
[01:42:23.608] iteration 1805: loss: 0.856849, loss_s1: 0.500329, loss_fp: 0.499997, loss_freq: 0.500202
[01:42:24.278] iteration 1806: loss: 0.914336, loss_s1: 0.500854, loss_fp: 0.500003, loss_freq: 0.500365
[01:42:24.940] iteration 1807: loss: 0.876485, loss_s1: 0.500630, loss_fp: 0.500007, loss_freq: 0.500036
[01:42:25.597] iteration 1808: loss: 0.874359, loss_s1: 0.500381, loss_fp: 0.500024, loss_freq: 0.500631
[01:42:26.243] iteration 1809: loss: 0.884626, loss_s1: 0.502724, loss_fp: 0.500213, loss_freq: 0.500671
[01:42:26.903] iteration 1810: loss: 0.310585, loss_s1: 0.333525, loss_fp: 0.002720, loss_freq: 0.070358
[01:42:27.559] iteration 1811: loss: 0.947758, loss_s1: 0.502222, loss_fp: 0.500000, loss_freq: 0.500154
[01:42:28.317] iteration 1812: loss: 0.332832, loss_s1: 0.418518, loss_fp: 0.005193, loss_freq: 0.004000
[01:42:29.076] iteration 1813: loss: 0.511097, loss_s1: 0.389013, loss_fp: 0.127591, loss_freq: 0.208361
[01:42:29.842] iteration 1814: loss: 0.855111, loss_s1: 0.503681, loss_fp: 0.500007, loss_freq: 0.500007
[01:42:30.607] iteration 1815: loss: 0.959561, loss_s1: 0.501499, loss_fp: 0.500006, loss_freq: 0.500984
[01:42:31.359] iteration 1816: loss: 0.848272, loss_s1: 0.501513, loss_fp: 0.500002, loss_freq: 0.500177
[01:42:32.061] iteration 1817: loss: 0.954229, loss_s1: 0.502053, loss_fp: 0.499986, loss_freq: 0.500242
[01:42:32.777] iteration 1818: loss: 0.431211, loss_s1: 0.285753, loss_fp: 0.050325, loss_freq: 0.305920
[01:42:33.516] iteration 1819: loss: 0.903472, loss_s1: 0.502134, loss_fp: 0.500036, loss_freq: 0.501020
[01:42:34.484] iteration 1820: loss: 0.986331, loss_s1: 0.500474, loss_fp: 0.500000, loss_freq: 0.500008
[01:42:35.253] iteration 1821: loss: 0.953517, loss_s1: 0.500459, loss_fp: 0.499991, loss_freq: 0.500001
[01:42:35.952] iteration 1822: loss: 1.000816, loss_s1: 0.500213, loss_fp: 0.500012, loss_freq: 0.499997
[01:42:36.639] iteration 1823: loss: 0.878869, loss_s1: 0.500098, loss_fp: 0.500000, loss_freq: 0.500002
[01:42:37.338] iteration 1824: loss: 0.640362, loss_s1: 0.500822, loss_fp: 0.050627, loss_freq: 0.388883
[01:42:38.297] iteration 1825: loss: 0.929233, loss_s1: 0.500103, loss_fp: 0.499997, loss_freq: 0.500001
[01:42:39.246] iteration 1826: loss: 0.954775, loss_s1: 0.500265, loss_fp: 0.499994, loss_freq: 0.500002
[01:42:39.944] iteration 1827: loss: 0.881728, loss_s1: 0.500406, loss_fp: 0.500016, loss_freq: 0.500461
[01:42:40.646] iteration 1828: loss: 0.928482, loss_s1: 0.501163, loss_fp: 0.500105, loss_freq: 0.500339
[01:42:41.370] iteration 1829: loss: 0.904476, loss_s1: 0.502019, loss_fp: 0.500014, loss_freq: 0.501336
[01:42:42.120] iteration 1830: loss: 0.930306, loss_s1: 0.501418, loss_fp: 0.500001, loss_freq: 0.500269
[01:42:42.946] iteration 1831: loss: 0.926901, loss_s1: 0.501535, loss_fp: 0.499999, loss_freq: 0.500035
[01:42:43.674] iteration 1832: loss: 0.945091, loss_s1: 0.500586, loss_fp: 0.500001, loss_freq: 0.500071
[01:42:44.399] iteration 1833: loss: 0.912390, loss_s1: 0.500589, loss_fp: 0.499999, loss_freq: 0.500315
[01:42:45.179] iteration 1834: loss: 0.739860, loss_s1: 0.495285, loss_fp: 0.053297, loss_freq: 0.418499
[01:42:45.938] iteration 1835: loss: 0.926952, loss_s1: 0.504557, loss_fp: 0.500008, loss_freq: 0.500015
[01:42:46.893] iteration 1836: loss: 0.911581, loss_s1: 0.501226, loss_fp: 0.499998, loss_freq: 0.500132
[01:42:47.621] iteration 1837: loss: 1.034355, loss_s1: 0.500391, loss_fp: 0.499998, loss_freq: 0.500013
[01:42:48.322] iteration 1838: loss: 0.376997, loss_s1: 0.424990, loss_fp: 0.002282, loss_freq: 0.042416
[01:42:49.014] iteration 1839: loss: 0.788435, loss_s1: 0.159369, loss_fp: 0.499998, loss_freq: 0.500062
[01:42:49.712] iteration 1840: loss: 0.910325, loss_s1: 0.500612, loss_fp: 0.499999, loss_freq: 0.500000
[01:42:50.432] iteration 1841: loss: 0.367889, loss_s1: 0.234948, loss_fp: 0.004520, loss_freq: 0.010862
[01:42:51.384] iteration 1842: loss: 0.926985, loss_s1: 0.500102, loss_fp: 0.499997, loss_freq: 0.500011
[01:42:52.343] iteration 1843: loss: 0.479877, loss_s1: 0.356216, loss_fp: 0.000923, loss_freq: 0.124153
[01:42:53.047] iteration 1844: loss: 0.441773, loss_s1: 0.505025, loss_fp: 0.005438, loss_freq: 0.011548
[01:42:53.756] iteration 1845: loss: 0.487861, loss_s1: 0.424668, loss_fp: 0.007698, loss_freq: 0.016418
[01:42:54.538] iteration 1846: loss: 0.552173, loss_s1: 0.442429, loss_fp: 0.050659, loss_freq: 0.189833
[01:42:55.403] iteration 1847: loss: 0.211472, loss_s1: 0.055510, loss_fp: 0.003347, loss_freq: 0.006207
[01:42:56.121] iteration 1848: loss: 0.506994, loss_s1: 0.462735, loss_fp: 0.021907, loss_freq: 0.119266
[01:42:56.829] iteration 1849: loss: 0.927254, loss_s1: 0.501255, loss_fp: 0.500016, loss_freq: 0.500022
[01:42:57.730] iteration 1850: loss: 0.668417, loss_s1: 0.448875, loss_fp: 0.005830, loss_freq: 0.356424
[01:42:58.479] iteration 1851: loss: 0.383165, loss_s1: 0.275521, loss_fp: 0.072691, loss_freq: 0.150229
[01:42:59.283] iteration 1852: loss: 0.410375, loss_s1: 0.310042, loss_fp: 0.004181, loss_freq: 0.051282
[01:42:59.978] iteration 1853: loss: 0.878385, loss_s1: 0.504066, loss_fp: 0.307018, loss_freq: 0.498899
[01:43:00.764] iteration 1854: loss: 0.428870, loss_s1: 0.296608, loss_fp: 0.001812, loss_freq: 0.002779
[01:43:01.463] iteration 1855: loss: 0.524379, loss_s1: 0.245542, loss_fp: 0.005774, loss_freq: 0.081750
[01:43:02.207] iteration 1856: loss: 0.499800, loss_s1: 0.274023, loss_fp: 0.046329, loss_freq: 0.081268
[01:43:03.056] iteration 1857: loss: 0.357671, loss_s1: 0.189509, loss_fp: 0.003404, loss_freq: 0.128647
[01:43:03.836] iteration 1858: loss: 0.538561, loss_s1: 0.485866, loss_fp: 0.001162, loss_freq: 0.009620
[01:43:04.527] iteration 1859: loss: 0.716051, loss_s1: 0.502622, loss_fp: 0.050830, loss_freq: 0.427792
[01:43:05.246] iteration 1860: loss: 0.446108, loss_s1: 0.357976, loss_fp: 0.002254, loss_freq: 0.006634
[01:43:05.977] iteration 1861: loss: 0.482181, loss_s1: 0.284848, loss_fp: 0.001478, loss_freq: 0.003347
[01:43:06.681] iteration 1862: loss: 0.265436, loss_s1: 0.157387, loss_fp: 0.000621, loss_freq: 0.001339
[01:43:07.626] iteration 1863: loss: 1.052096, loss_s1: 0.502657, loss_fp: 0.500002, loss_freq: 0.500355
[01:43:08.361] iteration 1864: loss: 0.980748, loss_s1: 0.501558, loss_fp: 0.500003, loss_freq: 0.500237
[01:43:09.111] iteration 1865: loss: 1.016957, loss_s1: 0.500093, loss_fp: 0.500006, loss_freq: 0.500002
[01:43:10.022] iteration 1866: loss: 1.014763, loss_s1: 0.501044, loss_fp: 0.500003, loss_freq: 0.500046
[01:43:10.759] iteration 1867: loss: 1.000709, loss_s1: 0.501333, loss_fp: 0.499995, loss_freq: 0.500311
[01:43:11.503] iteration 1868: loss: 0.961392, loss_s1: 0.504489, loss_fp: 0.499997, loss_freq: 0.500077
[01:43:12.184] iteration 1869: loss: 1.126145, loss_s1: 0.502043, loss_fp: 0.500006, loss_freq: 0.500132
[01:43:12.881] iteration 1870: loss: 0.976325, loss_s1: 0.500792, loss_fp: 0.500015, loss_freq: 0.500796
[01:43:14.094] iteration 1871: loss: 0.993723, loss_s1: 0.501202, loss_fp: 0.500007, loss_freq: 0.500565
[01:43:14.916] iteration 1872: loss: 0.974255, loss_s1: 0.501726, loss_fp: 0.500055, loss_freq: 0.501257
[01:43:15.718] iteration 1873: loss: 1.000632, loss_s1: 0.500411, loss_fp: 0.500054, loss_freq: 0.500255
[01:43:16.436] iteration 1874: loss: 0.969982, loss_s1: 0.500573, loss_fp: 0.500004, loss_freq: 0.500571
[01:43:17.213] iteration 1875: loss: 0.955986, loss_s1: 0.500275, loss_fp: 0.500028, loss_freq: 0.500176
[01:43:17.928] iteration 1876: loss: 0.956301, loss_s1: 0.500191, loss_fp: 0.500021, loss_freq: 0.500202
[01:43:18.698] iteration 1877: loss: 0.965162, loss_s1: 0.500661, loss_fp: 0.500035, loss_freq: 0.500790
[01:43:19.435] iteration 1878: loss: 0.685634, loss_s1: 0.485826, loss_fp: 0.179173, loss_freq: 0.263663
[01:43:20.175] iteration 1879: loss: 0.307456, loss_s1: 0.208060, loss_fp: 0.037662, loss_freq: 0.005172
[01:43:20.957] iteration 1880: loss: 0.413588, loss_s1: 0.289031, loss_fp: 0.005725, loss_freq: 0.014905
[01:43:21.896] iteration 1881: loss: 0.814113, loss_s1: 0.283023, loss_fp: 0.500022, loss_freq: 0.500554
[01:43:22.622] iteration 1882: loss: 0.966888, loss_s1: 0.500727, loss_fp: 0.500002, loss_freq: 0.500232
[01:43:23.342] iteration 1883: loss: 0.967488, loss_s1: 0.504530, loss_fp: 0.500005, loss_freq: 0.505807
[01:43:24.077] iteration 1884: loss: 0.549802, loss_s1: 0.501703, loss_fp: 0.053455, loss_freq: 0.022964
[01:43:24.836] iteration 1885: loss: 1.094575, loss_s1: 0.467277, loss_fp: 0.500002, loss_freq: 0.500000
[01:43:25.810] iteration 1886: loss: 0.322444, loss_s1: 0.254672, loss_fp: 0.004389, loss_freq: 0.003542
[01:43:26.571] iteration 1887: loss: 0.929293, loss_s1: 0.501551, loss_fp: 0.499993, loss_freq: 0.500011
[01:43:27.311] iteration 1888: loss: 0.562490, loss_s1: 0.481727, loss_fp: 0.001280, loss_freq: 0.214557
[01:43:28.032] iteration 1889: loss: 0.873875, loss_s1: 0.335494, loss_fp: 0.499999, loss_freq: 0.500013
[01:43:28.929] iteration 1890: loss: 0.520188, loss_s1: 0.347694, loss_fp: 0.110035, loss_freq: 0.217695
[01:43:29.691] iteration 1891: loss: 0.974202, loss_s1: 0.501449, loss_fp: 0.500000, loss_freq: 0.500428
[01:43:30.575] iteration 1892: loss: 0.908574, loss_s1: 0.500360, loss_fp: 0.500002, loss_freq: 0.500017
[01:43:31.363] iteration 1893: loss: 1.051780, loss_s1: 0.500414, loss_fp: 0.500002, loss_freq: 0.500003
[01:43:32.337] iteration 1894: loss: 0.942863, loss_s1: 0.501335, loss_fp: 0.500000, loss_freq: 0.500016
[01:43:33.069] iteration 1895: loss: 0.833086, loss_s1: 0.326984, loss_fp: 0.499993, loss_freq: 0.500003
[01:43:33.790] iteration 1896: loss: 0.900097, loss_s1: 0.442508, loss_fp: 0.500004, loss_freq: 0.500008
[01:43:34.698] iteration 1897: loss: 0.213921, loss_s1: 0.028714, loss_fp: 0.004686, loss_freq: 0.005081
[01:43:35.575] iteration 1898: loss: 0.943577, loss_s1: 0.502423, loss_fp: 0.500007, loss_freq: 0.500083
[01:43:36.199] iteration 1899: loss: 1.010245, loss_s1: 0.500128, loss_fp: 0.500046, loss_freq: 0.500330
[01:43:36.916] iteration 1900: loss: 1.003674, loss_s1: 0.502360, loss_fp: 0.499977, loss_freq: 0.500003
[01:43:37.546] iteration 1901: loss: 0.980015, loss_s1: 0.500130, loss_fp: 0.499992, loss_freq: 0.499999
[01:43:38.171] iteration 1902: loss: 1.095813, loss_s1: 0.500806, loss_fp: 0.500008, loss_freq: 0.500099
[01:43:38.790] iteration 1903: loss: 0.926074, loss_s1: 0.502783, loss_fp: 0.500028, loss_freq: 0.500039
[01:43:39.416] iteration 1904: loss: 0.363412, loss_s1: 0.329988, loss_fp: 0.001433, loss_freq: 0.018684
[01:43:40.038] iteration 1905: loss: 0.551874, loss_s1: 0.448904, loss_fp: 0.003933, loss_freq: 0.240380
[01:43:40.667] iteration 1906: loss: 0.964149, loss_s1: 0.500638, loss_fp: 0.499986, loss_freq: 0.500057
[01:43:41.299] iteration 1907: loss: 0.903438, loss_s1: 0.502938, loss_fp: 0.500013, loss_freq: 0.500077
[01:43:41.932] iteration 1908: loss: 1.016988, loss_s1: 0.500400, loss_fp: 0.499994, loss_freq: 0.500004
[01:43:42.571] iteration 1909: loss: 1.060478, loss_s1: 0.502257, loss_fp: 0.500000, loss_freq: 0.500081
[01:43:43.198] iteration 1910: loss: 0.662991, loss_s1: 0.500350, loss_fp: 0.201600, loss_freq: 0.193408
[01:43:43.834] iteration 1911: loss: 0.965020, loss_s1: 0.500964, loss_fp: 0.499999, loss_freq: 0.500518
[01:43:44.470] iteration 1912: loss: 0.923407, loss_s1: 0.503061, loss_fp: 0.500035, loss_freq: 0.500449
[01:43:45.118] iteration 1913: loss: 0.365730, loss_s1: 0.304931, loss_fp: 0.001721, loss_freq: 0.002157
[01:43:45.765] iteration 1914: loss: 0.425580, loss_s1: 0.491317, loss_fp: 0.026501, loss_freq: 0.000927
[01:43:46.423] iteration 1915: loss: 0.571661, loss_s1: 0.489781, loss_fp: 0.034024, loss_freq: 0.117577
[01:43:47.061] iteration 1916: loss: 0.940915, loss_s1: 0.484249, loss_fp: 0.500016, loss_freq: 0.500005
[01:43:47.718] iteration 1917: loss: 0.596258, loss_s1: 0.463323, loss_fp: 0.002204, loss_freq: 0.067794
[01:43:48.405] iteration 1918: loss: 0.387324, loss_s1: 0.074048, loss_fp: 0.104770, loss_freq: 0.012775
[01:43:49.082] iteration 1919: loss: 0.339623, loss_s1: 0.085160, loss_fp: 0.006230, loss_freq: 0.004192
[01:43:49.749] iteration 1920: loss: 0.799592, loss_s1: 0.148648, loss_fp: 0.500025, loss_freq: 0.500642
[01:43:50.419] iteration 1921: loss: 0.967610, loss_s1: 0.500357, loss_fp: 0.500025, loss_freq: 0.500000
[01:43:51.073] iteration 1922: loss: 0.981914, loss_s1: 0.469256, loss_fp: 0.500043, loss_freq: 0.500004
[01:43:51.733] iteration 1923: loss: 0.957538, loss_s1: 0.501919, loss_fp: 0.500035, loss_freq: 0.500174
[01:43:52.396] iteration 1924: loss: 0.891797, loss_s1: 0.501425, loss_fp: 0.500045, loss_freq: 0.500299
[01:43:53.063] iteration 1925: loss: 1.017408, loss_s1: 0.500069, loss_fp: 0.500029, loss_freq: 0.500016
[01:43:53.781] iteration 1926: loss: 1.059411, loss_s1: 0.500725, loss_fp: 0.500040, loss_freq: 0.500008
[01:43:54.462] iteration 1927: loss: 0.459282, loss_s1: 0.450415, loss_fp: 0.013236, loss_freq: 0.061828
[01:43:55.156] iteration 1928: loss: 0.999730, loss_s1: 0.501309, loss_fp: 0.500053, loss_freq: 0.500406
[01:43:55.833] iteration 1929: loss: 0.976119, loss_s1: 0.489881, loss_fp: 0.500048, loss_freq: 0.500005
[01:43:56.508] iteration 1930: loss: 0.906586, loss_s1: 0.500894, loss_fp: 0.500034, loss_freq: 0.500064
[01:43:57.142] iteration 1931: loss: 0.656760, loss_s1: 0.441344, loss_fp: 0.232798, loss_freq: 0.153532
[01:43:57.788] iteration 1932: loss: 0.935414, loss_s1: 0.500444, loss_fp: 0.500030, loss_freq: 0.500020
[01:43:58.443] iteration 1933: loss: 0.895929, loss_s1: 0.463085, loss_fp: 0.500013, loss_freq: 0.500009
[01:43:59.079] iteration 1934: loss: 0.396133, loss_s1: 0.242787, loss_fp: 0.003079, loss_freq: 0.002689
[01:43:59.723] iteration 1935: loss: 0.514105, loss_s1: 0.501695, loss_fp: 0.003353, loss_freq: 0.003349
[01:44:00.358] iteration 1936: loss: 0.327741, loss_s1: 0.354333, loss_fp: 0.001284, loss_freq: 0.005293
[01:44:01.011] iteration 1937: loss: 1.001579, loss_s1: 0.403910, loss_fp: 0.500025, loss_freq: 0.500007
[01:44:01.647] iteration 1938: loss: 0.762823, loss_s1: 0.172344, loss_fp: 0.499998, loss_freq: 0.500012
[01:44:02.309] iteration 1939: loss: 0.371137, loss_s1: 0.307866, loss_fp: 0.001044, loss_freq: 0.001804
[01:44:02.954] iteration 1940: loss: 0.957284, loss_s1: 0.501406, loss_fp: 0.500085, loss_freq: 0.500015
[01:44:03.607] iteration 1941: loss: 0.667771, loss_s1: 0.500191, loss_fp: 0.064561, loss_freq: 0.375446
[01:44:04.268] iteration 1942: loss: 0.922509, loss_s1: 0.500864, loss_fp: 0.500017, loss_freq: 0.500006
[01:44:04.916] iteration 1943: loss: 0.529891, loss_s1: 0.444104, loss_fp: 0.003668, loss_freq: 0.046801
[01:44:05.555] iteration 1944: loss: 0.985409, loss_s1: 0.500045, loss_fp: 0.500121, loss_freq: 0.500100
[01:44:06.215] iteration 1945: loss: 0.250597, loss_s1: 0.150942, loss_fp: 0.010517, loss_freq: 0.006897
[01:44:06.870] iteration 1946: loss: 0.911308, loss_s1: 0.307490, loss_fp: 0.499940, loss_freq: 0.500119
[01:44:07.527] iteration 1947: loss: 0.966314, loss_s1: 0.501431, loss_fp: 0.500014, loss_freq: 0.500009
[01:44:08.189] iteration 1948: loss: 0.432018, loss_s1: 0.292706, loss_fp: 0.002742, loss_freq: 0.018152
[01:44:08.844] iteration 1949: loss: 0.240420, loss_s1: 0.097227, loss_fp: 0.010245, loss_freq: 0.010015
[01:44:09.476] iteration 1950: loss: 0.540187, loss_s1: 0.492071, loss_fp: 0.005154, loss_freq: 0.007081
[01:44:10.132] iteration 1951: loss: 0.915170, loss_s1: 0.500407, loss_fp: 0.500001, loss_freq: 0.500472
[01:44:10.812] iteration 1952: loss: 1.032011, loss_s1: 0.500517, loss_fp: 0.500008, loss_freq: 0.500014
[01:44:11.527] iteration 1953: loss: 0.894234, loss_s1: 0.386321, loss_fp: 0.500000, loss_freq: 0.500001
[01:44:12.209] iteration 1954: loss: 1.056767, loss_s1: 0.500251, loss_fp: 0.500019, loss_freq: 0.500001
[01:44:12.880] iteration 1955: loss: 1.016691, loss_s1: 0.500041, loss_fp: 0.499997, loss_freq: 0.499999
[01:44:13.556] iteration 1956: loss: 0.960675, loss_s1: 0.500203, loss_fp: 0.499993, loss_freq: 0.500000
[01:44:14.211] iteration 1957: loss: 0.985579, loss_s1: 0.500010, loss_fp: 0.500005, loss_freq: 0.499990
[01:44:14.880] iteration 1958: loss: 0.281468, loss_s1: 0.067072, loss_fp: 0.014323, loss_freq: 0.027963
[01:44:15.544] iteration 1959: loss: 0.980989, loss_s1: 0.501794, loss_fp: 0.499997, loss_freq: 0.500007
[01:44:16.201] iteration 1960: loss: 0.614226, loss_s1: 0.402625, loss_fp: 0.418477, loss_freq: 0.011082
[01:44:16.868] iteration 1961: loss: 0.717373, loss_s1: 0.010607, loss_fp: 0.500000, loss_freq: 0.500002
[01:44:17.534] iteration 1962: loss: 0.975389, loss_s1: 0.501546, loss_fp: 0.500005, loss_freq: 0.500224
[01:44:18.212] iteration 1963: loss: 1.025179, loss_s1: 0.504006, loss_fp: 0.499998, loss_freq: 0.500260
[01:44:18.881] iteration 1964: loss: 0.928849, loss_s1: 0.500226, loss_fp: 0.500009, loss_freq: 0.500464
[01:44:19.554] iteration 1965: loss: 0.278548, loss_s1: 0.139642, loss_fp: 0.007512, loss_freq: 0.002044
[01:44:20.198] iteration 1966: loss: 0.899669, loss_s1: 0.370815, loss_fp: 0.500196, loss_freq: 0.500000
[01:44:20.867] iteration 1967: loss: 0.499978, loss_s1: 0.496992, loss_fp: 0.019872, loss_freq: 0.011171
[01:44:21.534] iteration 1968: loss: 0.901706, loss_s1: 0.500799, loss_fp: 0.500027, loss_freq: 0.500300
[01:44:22.214] iteration 1969: loss: 0.370520, loss_s1: 0.249305, loss_fp: 0.001527, loss_freq: 0.001668
[01:44:22.889] iteration 1970: loss: 0.277465, loss_s1: 0.151470, loss_fp: 0.002957, loss_freq: 0.003651
[01:44:23.562] iteration 1971: loss: 0.369775, loss_s1: 0.335203, loss_fp: 0.033270, loss_freq: 0.050604
[01:44:24.248] iteration 1972: loss: 0.659171, loss_s1: 0.370242, loss_fp: 0.086564, loss_freq: 0.211599
[01:44:24.921] iteration 1973: loss: 0.473434, loss_s1: 0.310352, loss_fp: 0.003393, loss_freq: 0.078799
[01:44:25.597] iteration 1974: loss: 0.417339, loss_s1: 0.437237, loss_fp: 0.009434, loss_freq: 0.017760
[01:44:26.326] iteration 1975: loss: 0.297917, loss_s1: 0.213120, loss_fp: 0.007269, loss_freq: 0.006714
[01:44:27.024] iteration 1976: loss: 0.611967, loss_s1: 0.453750, loss_fp: 0.202626, loss_freq: 0.223727
[01:44:27.717] iteration 1977: loss: 0.457550, loss_s1: 0.447858, loss_fp: 0.083337, loss_freq: 0.005857
[01:44:28.381] iteration 1978: loss: 0.450743, loss_s1: 0.311368, loss_fp: 0.009412, loss_freq: 0.002055
[01:44:29.041] iteration 1979: loss: 1.013973, loss_s1: 0.500439, loss_fp: 0.500030, loss_freq: 0.500024
[01:44:29.705] iteration 1980: loss: 0.529333, loss_s1: 0.306245, loss_fp: 0.077319, loss_freq: 0.032437
[01:44:30.357] iteration 1981: loss: 1.155924, loss_s1: 0.500000, loss_fp: 0.500009, loss_freq: 0.500001
[01:44:31.011] iteration 1982: loss: 1.074204, loss_s1: 0.500000, loss_fp: 0.500002, loss_freq: 0.499999
[01:44:31.670] iteration 1983: loss: 1.034046, loss_s1: 0.500002, loss_fp: 0.500004, loss_freq: 0.499986
[01:44:32.323] iteration 1984: loss: 0.980615, loss_s1: 0.500005, loss_fp: 0.500044, loss_freq: 0.500000
[01:44:32.979] iteration 1985: loss: 1.027441, loss_s1: 0.500017, loss_fp: 0.500003, loss_freq: 0.500016
[01:44:33.623] iteration 1986: loss: 0.963137, loss_s1: 0.500042, loss_fp: 0.499997, loss_freq: 0.500025
[01:44:34.280] iteration 1987: loss: 1.037672, loss_s1: 0.500235, loss_fp: 0.499999, loss_freq: 0.500057
[01:44:34.931] iteration 1988: loss: 0.971884, loss_s1: 0.500248, loss_fp: 0.500022, loss_freq: 0.500052
[01:44:35.590] iteration 1989: loss: 1.010588, loss_s1: 0.501267, loss_fp: 0.500001, loss_freq: 0.500424
[01:44:36.247] iteration 1990: loss: 1.032129, loss_s1: 0.500692, loss_fp: 0.500000, loss_freq: 0.501231
[01:44:36.915] iteration 1991: loss: 0.468859, loss_s1: 0.230994, loss_fp: 0.014995, loss_freq: 0.250977
[01:44:37.596] iteration 1992: loss: 0.377144, loss_s1: 0.219844, loss_fp: 0.007258, loss_freq: 0.042649
[01:44:38.295] iteration 1993: loss: 0.777312, loss_s1: 0.500242, loss_fp: 0.147021, loss_freq: 0.493811
[01:44:38.998] iteration 1994: loss: 0.540819, loss_s1: 0.494945, loss_fp: 0.027804, loss_freq: 0.087828
[01:44:39.684] iteration 1995: loss: 0.769558, loss_s1: 0.046538, loss_fp: 0.500005, loss_freq: 0.500007
[01:44:40.400] iteration 1996: loss: 0.678653, loss_s1: 0.465649, loss_fp: 0.005351, loss_freq: 0.202723
[01:44:41.137] iteration 1997: loss: 1.052296, loss_s1: 0.500283, loss_fp: 0.500008, loss_freq: 0.500558
[01:44:41.851] iteration 1998: loss: 1.092322, loss_s1: 0.502513, loss_fp: 0.500005, loss_freq: 0.502450
[01:44:42.535] iteration 1999: loss: 0.400982, loss_s1: 0.231621, loss_fp: 0.006022, loss_freq: 0.060712
[01:44:43.214] iteration 2000: loss: 0.970013, loss_s1: 0.501779, loss_fp: 0.500006, loss_freq: 0.501555
[01:44:45.208] iteration 2000 : mean_dice : 0.020003
[01:44:45.884] iteration 2001: loss: 0.267432, loss_s1: 0.002994, loss_fp: 0.004184, loss_freq: 0.000734
[01:44:46.557] iteration 2002: loss: 0.431473, loss_s1: 0.328360, loss_fp: 0.001143, loss_freq: 0.018208
[01:44:47.219] iteration 2003: loss: 0.907756, loss_s1: 0.508849, loss_fp: 0.500001, loss_freq: 0.500207
[01:44:47.881] iteration 2004: loss: 0.556322, loss_s1: 0.453217, loss_fp: 0.000791, loss_freq: 0.003448
[01:44:48.540] iteration 2005: loss: 1.064947, loss_s1: 0.503551, loss_fp: 0.500005, loss_freq: 0.500007
[01:44:49.199] iteration 2006: loss: 0.909378, loss_s1: 0.504565, loss_fp: 0.500003, loss_freq: 0.500317
[01:44:49.864] iteration 2007: loss: 0.513925, loss_s1: 0.438727, loss_fp: 0.006415, loss_freq: 0.010476
[01:44:50.545] iteration 2008: loss: 0.316811, loss_s1: 0.273397, loss_fp: 0.000610, loss_freq: 0.001520
[01:44:51.226] iteration 2009: loss: 0.334876, loss_s1: 0.252995, loss_fp: 0.000587, loss_freq: 0.001240
[01:44:51.918] iteration 2010: loss: 0.961960, loss_s1: 0.504811, loss_fp: 0.500001, loss_freq: 0.500457
[01:44:52.743] iteration 2011: loss: 0.229070, loss_s1: 0.099458, loss_fp: 0.003019, loss_freq: 0.001202
[01:44:53.500] iteration 2012: loss: 0.930016, loss_s1: 0.504135, loss_fp: 0.500003, loss_freq: 0.500029
[01:44:54.384] iteration 2013: loss: 0.299905, loss_s1: 0.149146, loss_fp: 0.002157, loss_freq: 0.007117
[01:44:55.618] iteration 2014: loss: 0.408076, loss_s1: 0.344021, loss_fp: 0.002319, loss_freq: 0.012541
[01:44:56.708] iteration 2015: loss: 0.471263, loss_s1: 0.465448, loss_fp: 0.006639, loss_freq: 0.012392
[01:45:17.532] iteration 2016: loss: 0.793110, loss_s1: 0.499096, loss_fp: 0.198282, loss_freq: 0.399166
[01:45:38.400] iteration 2017: loss: 0.210111, loss_s1: 0.075382, loss_fp: 0.001767, loss_freq: 0.017429
[01:45:59.194] iteration 2018: loss: 0.247985, loss_s1: 0.141005, loss_fp: 0.004309, loss_freq: 0.001463
[01:46:20.090] iteration 2019: loss: 0.339356, loss_s1: 0.266150, loss_fp: 0.001274, loss_freq: 0.000970
[01:46:40.944] iteration 2020: loss: 0.993802, loss_s1: 0.501067, loss_fp: 0.500004, loss_freq: 0.500004
[01:47:01.896] iteration 2021: loss: 0.319948, loss_s1: 0.347934, loss_fp: 0.003811, loss_freq: 0.001603
[01:47:22.782] iteration 2022: loss: 0.928132, loss_s1: 0.502338, loss_fp: 0.499999, loss_freq: 0.500003
[01:47:43.740] iteration 2023: loss: 0.994650, loss_s1: 0.503992, loss_fp: 0.500007, loss_freq: 0.500013
[01:48:04.638] iteration 2024: loss: 0.457103, loss_s1: 0.501167, loss_fp: 0.001000, loss_freq: 0.016658
[01:48:25.600] iteration 2025: loss: 0.522004, loss_s1: 0.498509, loss_fp: 0.007185, loss_freq: 0.005194
[01:48:46.566] iteration 2026: loss: 0.427854, loss_s1: 0.339802, loss_fp: 0.003174, loss_freq: 0.126329
[01:49:07.467] iteration 2027: loss: 0.273094, loss_s1: 0.078450, loss_fp: 0.002838, loss_freq: 0.005158
[01:49:28.442] iteration 2028: loss: 0.483311, loss_s1: 0.410573, loss_fp: 0.087572, loss_freq: 0.033764
[01:49:49.310] iteration 2029: loss: 0.917303, loss_s1: 0.500075, loss_fp: 0.500025, loss_freq: 0.500049
[01:50:10.281] iteration 2030: loss: 0.481287, loss_s1: 0.462922, loss_fp: 0.001281, loss_freq: 0.011963
[01:50:31.131] iteration 2031: loss: 0.305523, loss_s1: 0.031801, loss_fp: 0.024502, loss_freq: 0.054765
[01:50:52.105] iteration 2032: loss: 0.263113, loss_s1: 0.192887, loss_fp: 0.003687, loss_freq: 0.007210
[01:51:12.960] iteration 2033: loss: 0.999306, loss_s1: 0.500118, loss_fp: 0.500000, loss_freq: 0.500001
[01:51:33.938] iteration 2034: loss: 0.291389, loss_s1: 0.141688, loss_fp: 0.002036, loss_freq: 0.000702
[01:51:54.915] iteration 2035: loss: 0.293353, loss_s1: 0.221214, loss_fp: 0.002017, loss_freq: 0.001143
[01:52:15.754] iteration 2036: loss: 0.455021, loss_s1: 0.446757, loss_fp: 0.000553, loss_freq: 0.000369
[01:52:36.745] iteration 2037: loss: 0.254562, loss_s1: 0.124259, loss_fp: 0.001217, loss_freq: 0.002253
[01:52:57.609] iteration 2038: loss: 0.907958, loss_s1: 0.501238, loss_fp: 0.499997, loss_freq: 0.499989
[01:53:18.577] iteration 2039: loss: 0.384208, loss_s1: 0.309731, loss_fp: 0.001838, loss_freq: 0.000647
[01:53:39.444] iteration 2040: loss: 0.416653, loss_s1: 0.389478, loss_fp: 0.009344, loss_freq: 0.014497
[01:54:00.749] iteration 2041: loss: 0.195787, loss_s1: 0.052750, loss_fp: 0.006400, loss_freq: 0.000520
[01:54:21.636] iteration 2042: loss: 0.948713, loss_s1: 0.500428, loss_fp: 0.500001, loss_freq: 0.499995
[01:54:42.607] iteration 2043: loss: 0.207332, loss_s1: 0.016392, loss_fp: 0.000692, loss_freq: 0.000660
[01:55:03.575] iteration 2044: loss: 0.429756, loss_s1: 0.445372, loss_fp: 0.001049, loss_freq: 0.000646
[01:55:24.470] iteration 2045: loss: 0.283841, loss_s1: 0.159169, loss_fp: 0.000904, loss_freq: 0.000904
[01:55:45.446] iteration 2046: loss: 0.732927, loss_s1: 0.058575, loss_fp: 0.499998, loss_freq: 0.500004
[01:56:06.337] iteration 2047: loss: 0.266664, loss_s1: 0.137401, loss_fp: 0.003768, loss_freq: 0.000991
[01:56:27.314] iteration 2048: loss: 0.254426, loss_s1: 0.136472, loss_fp: 0.001130, loss_freq: 0.001819
[01:56:48.198] iteration 2049: loss: 0.216254, loss_s1: 0.063965, loss_fp: 0.001068, loss_freq: 0.000744
[01:57:09.170] iteration 2050: loss: 0.433156, loss_s1: 0.437429, loss_fp: 0.001451, loss_freq: 0.000842
[01:57:30.125] iteration 2051: loss: 0.445440, loss_s1: 0.467677, loss_fp: 0.042319, loss_freq: 0.053310
[01:57:51.103] iteration 2052: loss: 0.971967, loss_s1: 0.501181, loss_fp: 0.500002, loss_freq: 0.500497
[01:58:12.069] iteration 2053: loss: 0.931652, loss_s1: 0.505052, loss_fp: 0.500003, loss_freq: 0.500478
[01:58:32.953] iteration 2054: loss: 0.321926, loss_s1: 0.289859, loss_fp: 0.009487, loss_freq: 0.001095
[01:58:53.923] iteration 2055: loss: 0.437291, loss_s1: 0.370665, loss_fp: 0.001798, loss_freq: 0.002554
[01:59:14.828] iteration 2056: loss: 0.945179, loss_s1: 0.500035, loss_fp: 0.500033, loss_freq: 0.500337
[01:59:35.798] iteration 2057: loss: 0.925663, loss_s1: 0.501958, loss_fp: 0.500004, loss_freq: 0.499993
[01:59:56.691] iteration 2058: loss: 0.329561, loss_s1: 0.234088, loss_fp: 0.000912, loss_freq: 0.000830
[02:00:17.653] iteration 2059: loss: 0.353251, loss_s1: 0.169914, loss_fp: 0.195702, loss_freq: 0.015556
[02:00:38.626] iteration 2060: loss: 0.471131, loss_s1: 0.499891, loss_fp: 0.000924, loss_freq: 0.001020
[02:00:40.165] iteration 2061: loss: 0.485211, loss_s1: 0.461472, loss_fp: 0.007269, loss_freq: 0.029695
[02:00:40.870] iteration 2062: loss: 0.909968, loss_s1: 0.500838, loss_fp: 0.500000, loss_freq: 0.499997
[02:00:41.595] iteration 2063: loss: 0.453130, loss_s1: 0.179106, loss_fp: 0.000984, loss_freq: 0.001195
[02:00:43.350] iteration 2064: loss: 0.971813, loss_s1: 0.500629, loss_fp: 0.499996, loss_freq: 0.499982
[02:00:44.414] iteration 2065: loss: 0.998465, loss_s1: 0.499991, loss_fp: 0.499990, loss_freq: 0.499979
[02:00:45.103] iteration 2066: loss: 0.552489, loss_s1: 0.458831, loss_fp: 0.010070, loss_freq: 0.142274
[02:00:45.813] iteration 2067: loss: 0.312970, loss_s1: 0.064427, loss_fp: 0.000943, loss_freq: 0.012555
[02:00:46.523] iteration 2068: loss: 0.184438, loss_s1: 0.008346, loss_fp: 0.000700, loss_freq: 0.002716
[02:00:47.210] iteration 2069: loss: 0.458938, loss_s1: 0.388569, loss_fp: 0.001802, loss_freq: 0.021304
[02:00:47.928] iteration 2070: loss: 0.698030, loss_s1: 0.501143, loss_fp: 0.015966, loss_freq: 0.420796
[02:00:48.578] iteration 2071: loss: 0.332419, loss_s1: 0.231037, loss_fp: 0.000906, loss_freq: 0.002589
[02:00:49.242] iteration 2072: loss: 0.409914, loss_s1: 0.254213, loss_fp: 0.003629, loss_freq: 0.098243
[02:00:49.905] iteration 2073: loss: 0.985258, loss_s1: 0.504214, loss_fp: 0.500005, loss_freq: 0.501126
[02:00:50.566] iteration 2074: loss: 0.196837, loss_s1: 0.084408, loss_fp: 0.000405, loss_freq: 0.002399
[02:00:51.254] iteration 2075: loss: 0.555282, loss_s1: 0.503272, loss_fp: 0.002389, loss_freq: 0.248190
[02:00:51.930] iteration 2076: loss: 0.516883, loss_s1: 0.485129, loss_fp: 0.001213, loss_freq: 0.024751
[02:00:52.610] iteration 2077: loss: 0.933276, loss_s1: 0.503002, loss_fp: 0.500004, loss_freq: 0.502463
[02:00:53.310] iteration 2078: loss: 0.265887, loss_s1: 0.035003, loss_fp: 0.000734, loss_freq: 0.001173
[02:00:54.010] iteration 2079: loss: 0.388925, loss_s1: 0.313884, loss_fp: 0.001982, loss_freq: 0.004280
[02:00:54.709] iteration 2080: loss: 0.309109, loss_s1: 0.276905, loss_fp: 0.000553, loss_freq: 0.008589
[02:00:55.408] iteration 2081: loss: 0.932327, loss_s1: 0.504150, loss_fp: 0.500003, loss_freq: 0.500576
[02:00:56.189] iteration 2082: loss: 0.370065, loss_s1: 0.325607, loss_fp: 0.006277, loss_freq: 0.065905
[02:00:56.865] iteration 2083: loss: 0.382824, loss_s1: 0.356695, loss_fp: 0.000698, loss_freq: 0.007778
[02:00:57.551] iteration 2084: loss: 0.314575, loss_s1: 0.251258, loss_fp: 0.005644, loss_freq: 0.020840
[02:00:58.229] iteration 2085: loss: 0.318600, loss_s1: 0.288966, loss_fp: 0.001348, loss_freq: 0.000712
[02:00:58.900] iteration 2086: loss: 0.388923, loss_s1: 0.488140, loss_fp: 0.002245, loss_freq: 0.003036
[02:00:59.582] iteration 2087: loss: 0.348399, loss_s1: 0.258445, loss_fp: 0.001087, loss_freq: 0.001753
[02:01:00.248] iteration 2088: loss: 0.917580, loss_s1: 0.496968, loss_fp: 0.500001, loss_freq: 0.500017
[02:01:00.905] iteration 2089: loss: 0.207513, loss_s1: 0.032050, loss_fp: 0.000640, loss_freq: 0.000632
[02:01:01.613] iteration 2090: loss: 0.969780, loss_s1: 0.504035, loss_fp: 0.500041, loss_freq: 0.502185
[02:01:02.308] iteration 2091: loss: 0.928438, loss_s1: 0.502068, loss_fp: 0.499998, loss_freq: 0.500323
[02:01:03.011] iteration 2092: loss: 0.225529, loss_s1: 0.120265, loss_fp: 0.005240, loss_freq: 0.004635
[02:01:03.751] iteration 2093: loss: 0.534692, loss_s1: 0.403370, loss_fp: 0.004555, loss_freq: 0.208562
[02:01:04.465] iteration 2094: loss: 0.909550, loss_s1: 0.500572, loss_fp: 0.500027, loss_freq: 0.500154
[02:01:05.174] iteration 2095: loss: 0.905102, loss_s1: 0.458409, loss_fp: 0.500002, loss_freq: 0.500010
[02:01:05.847] iteration 2096: loss: 0.250346, loss_s1: 0.125597, loss_fp: 0.000907, loss_freq: 0.002327
[02:01:06.516] iteration 2097: loss: 0.920210, loss_s1: 0.501435, loss_fp: 0.500014, loss_freq: 0.500302
[02:01:07.203] iteration 2098: loss: 0.301329, loss_s1: 0.001924, loss_fp: 0.000995, loss_freq: 0.001112
[02:01:07.889] iteration 2099: loss: 0.583063, loss_s1: 0.353379, loss_fp: 0.105536, loss_freq: 0.002258
[02:01:08.600] iteration 2100: loss: 0.908935, loss_s1: 0.504190, loss_fp: 0.500002, loss_freq: 0.500014
[02:01:09.277] iteration 2101: loss: 0.258163, loss_s1: 0.161346, loss_fp: 0.017099, loss_freq: 0.000713
[02:01:09.975] iteration 2102: loss: 0.910178, loss_s1: 0.501069, loss_fp: 0.500003, loss_freq: 0.500022
[02:01:10.659] iteration 2103: loss: 0.702586, loss_s1: 0.078576, loss_fp: 0.500000, loss_freq: 0.500002
[02:01:11.322] iteration 2104: loss: 0.266875, loss_s1: 0.133527, loss_fp: 0.001087, loss_freq: 0.001976
[02:01:11.997] iteration 2105: loss: 0.353567, loss_s1: 0.348095, loss_fp: 0.022675, loss_freq: 0.022283
[02:01:12.673] iteration 2106: loss: 0.353801, loss_s1: 0.374473, loss_fp: 0.002720, loss_freq: 0.007155
[02:01:13.340] iteration 2107: loss: 0.236359, loss_s1: 0.085276, loss_fp: 0.001223, loss_freq: 0.004019
[02:01:14.015] iteration 2108: loss: 0.338716, loss_s1: 0.334127, loss_fp: 0.004966, loss_freq: 0.017310
[02:01:14.725] iteration 2109: loss: 0.299701, loss_s1: 0.176322, loss_fp: 0.001091, loss_freq: 0.028506
[02:01:15.431] iteration 2110: loss: 0.954155, loss_s1: 0.500248, loss_fp: 0.499999, loss_freq: 0.499998
[02:01:16.145] iteration 2111: loss: 0.307361, loss_s1: 0.288962, loss_fp: 0.006861, loss_freq: 0.002342
[02:01:16.842] iteration 2112: loss: 0.342633, loss_s1: 0.327922, loss_fp: 0.005182, loss_freq: 0.041607
[02:01:17.544] iteration 2113: loss: 0.414199, loss_s1: 0.359355, loss_fp: 0.003531, loss_freq: 0.006718
[02:01:18.250] iteration 2114: loss: 1.025610, loss_s1: 0.500050, loss_fp: 0.500001, loss_freq: 0.500132
[02:01:18.982] iteration 2115: loss: 0.995961, loss_s1: 0.503685, loss_fp: 0.500001, loss_freq: 0.500362
[02:01:19.672] iteration 2116: loss: 0.349526, loss_s1: 0.043603, loss_fp: 0.030901, loss_freq: 0.000573
[02:01:20.463] iteration 2117: loss: 0.677805, loss_s1: 0.494410, loss_fp: 0.024666, loss_freq: 0.293841
[02:01:21.153] iteration 2118: loss: 0.289814, loss_s1: 0.153658, loss_fp: 0.001368, loss_freq: 0.000734
[02:01:21.926] iteration 2119: loss: 0.884485, loss_s1: 0.502106, loss_fp: 0.500008, loss_freq: 0.499994
[02:01:22.770] iteration 2120: loss: 0.355520, loss_s1: 0.221125, loss_fp: 0.002629, loss_freq: 0.000543
[02:01:23.463] iteration 2121: loss: 0.916322, loss_s1: 0.500937, loss_fp: 0.500020, loss_freq: 0.500864
[02:01:24.280] iteration 2122: loss: 0.319491, loss_s1: 0.109346, loss_fp: 0.006196, loss_freq: 0.001574
[02:01:25.050] iteration 2123: loss: 0.967973, loss_s1: 0.501955, loss_fp: 0.500028, loss_freq: 0.500001
[02:01:25.725] iteration 2124: loss: 0.394910, loss_s1: 0.369309, loss_fp: 0.008848, loss_freq: 0.009441
[02:01:26.468] iteration 2125: loss: 0.431269, loss_s1: 0.364717, loss_fp: 0.012512, loss_freq: 0.000890
[02:01:27.149] iteration 2126: loss: 0.929153, loss_s1: 0.501089, loss_fp: 0.500002, loss_freq: 0.499996
[02:01:27.870] iteration 2127: loss: 0.245096, loss_s1: 0.179063, loss_fp: 0.001845, loss_freq: 0.000627
[02:01:28.589] iteration 2128: loss: 0.327743, loss_s1: 0.305757, loss_fp: 0.012518, loss_freq: 0.002348
[02:01:29.392] iteration 2129: loss: 0.907305, loss_s1: 0.501113, loss_fp: 0.500009, loss_freq: 0.500005
[02:01:30.170] iteration 2130: loss: 0.930030, loss_s1: 0.500526, loss_fp: 0.500009, loss_freq: 0.500007
[02:01:30.869] iteration 2131: loss: 0.351314, loss_s1: 0.305176, loss_fp: 0.006459, loss_freq: 0.003519
[02:01:31.660] iteration 2132: loss: 0.883681, loss_s1: 0.501105, loss_fp: 0.500057, loss_freq: 0.500014
[02:01:32.372] iteration 2133: loss: 0.981815, loss_s1: 0.501042, loss_fp: 0.500185, loss_freq: 0.500270
[02:01:33.038] iteration 2134: loss: 0.916502, loss_s1: 0.500045, loss_fp: 0.500033, loss_freq: 0.500062
[02:01:33.691] iteration 2135: loss: 0.727787, loss_s1: 0.462269, loss_fp: 0.152047, loss_freq: 0.415803
[02:01:34.355] iteration 2136: loss: 0.957157, loss_s1: 0.500005, loss_fp: 0.500008, loss_freq: 0.500001
[02:01:35.011] iteration 2137: loss: 0.952865, loss_s1: 0.500052, loss_fp: 0.500003, loss_freq: 0.500005
[02:01:35.652] iteration 2138: loss: 0.893462, loss_s1: 0.500102, loss_fp: 0.500001, loss_freq: 0.500006
[02:01:36.320] iteration 2139: loss: 0.428720, loss_s1: 0.497350, loss_fp: 0.001880, loss_freq: 0.001409
[02:01:36.995] iteration 2140: loss: 0.908825, loss_s1: 0.496065, loss_fp: 0.500000, loss_freq: 0.499999
[02:01:37.641] iteration 2141: loss: 0.911049, loss_s1: 0.500020, loss_fp: 0.499999, loss_freq: 0.499990
[02:01:38.293] iteration 2142: loss: 1.025435, loss_s1: 0.500018, loss_fp: 0.500001, loss_freq: 0.500003
[02:01:38.941] iteration 2143: loss: 0.919501, loss_s1: 0.498302, loss_fp: 0.500003, loss_freq: 0.499998
[02:01:39.603] iteration 2144: loss: 0.902153, loss_s1: 0.500015, loss_fp: 0.499998, loss_freq: 0.500007
[02:01:40.243] iteration 2145: loss: 0.917963, loss_s1: 0.500010, loss_fp: 0.499999, loss_freq: 0.500003
[02:01:40.926] iteration 2146: loss: 0.926178, loss_s1: 0.500005, loss_fp: 0.499998, loss_freq: 0.500002
[02:01:41.622] iteration 2147: loss: 0.893629, loss_s1: 0.500008, loss_fp: 0.500000, loss_freq: 0.500000
[02:01:42.418] iteration 2148: loss: 0.897505, loss_s1: 0.500210, loss_fp: 0.499996, loss_freq: 0.500000
[02:01:43.310] iteration 2149: loss: 0.926488, loss_s1: 0.500816, loss_fp: 0.499998, loss_freq: 0.500065
[02:01:44.340] iteration 2150: loss: 0.899224, loss_s1: 0.500043, loss_fp: 0.500002, loss_freq: 0.500009
[02:01:45.126] iteration 2151: loss: 0.924118, loss_s1: 0.500503, loss_fp: 0.500002, loss_freq: 0.500026
[02:01:45.852] iteration 2152: loss: 0.888992, loss_s1: 0.500076, loss_fp: 0.500006, loss_freq: 0.500006
[02:01:46.495] iteration 2153: loss: 0.770356, loss_s1: 0.252104, loss_fp: 0.500002, loss_freq: 0.500003
[02:01:47.181] iteration 2154: loss: 0.924390, loss_s1: 0.500512, loss_fp: 0.499999, loss_freq: 0.500014
[02:01:47.820] iteration 2155: loss: 0.959158, loss_s1: 0.502641, loss_fp: 0.500001, loss_freq: 0.501950
[02:01:48.552] iteration 2156: loss: 0.888088, loss_s1: 0.500933, loss_fp: 0.500006, loss_freq: 0.500462
[02:01:49.187] iteration 2157: loss: 0.913193, loss_s1: 0.487197, loss_fp: 0.500010, loss_freq: 0.500543
[02:01:49.871] iteration 2158: loss: 0.368447, loss_s1: 0.339338, loss_fp: 0.060355, loss_freq: 0.079379
[02:01:50.512] iteration 2159: loss: 0.895364, loss_s1: 0.501093, loss_fp: 0.500006, loss_freq: 0.500650
[02:01:51.207] iteration 2160: loss: 0.958385, loss_s1: 0.505608, loss_fp: 0.500003, loss_freq: 0.500180
[02:01:51.854] iteration 2161: loss: 0.880029, loss_s1: 0.462520, loss_fp: 0.500021, loss_freq: 0.500005
[02:01:52.542] iteration 2162: loss: 0.906300, loss_s1: 0.500011, loss_fp: 0.500003, loss_freq: 0.500097
[02:01:53.194] iteration 2163: loss: 0.916220, loss_s1: 0.500860, loss_fp: 0.500004, loss_freq: 0.500411
[02:01:53.908] iteration 2164: loss: 0.880686, loss_s1: 0.500674, loss_fp: 0.500001, loss_freq: 0.500260
[02:01:54.553] iteration 2165: loss: 0.387233, loss_s1: 0.446356, loss_fp: 0.009243, loss_freq: 0.003833
[02:01:55.242] iteration 2166: loss: 0.941756, loss_s1: 0.501024, loss_fp: 0.500002, loss_freq: 0.500001
[02:01:55.880] iteration 2167: loss: 0.938025, loss_s1: 0.501543, loss_fp: 0.500005, loss_freq: 0.501805
[02:01:56.561] iteration 2168: loss: 0.945057, loss_s1: 0.500840, loss_fp: 0.500000, loss_freq: 0.500869
[02:01:57.226] iteration 2169: loss: 0.862771, loss_s1: 0.430971, loss_fp: 0.500003, loss_freq: 0.500019
[02:01:57.909] iteration 2170: loss: 0.905287, loss_s1: 0.500891, loss_fp: 0.500000, loss_freq: 0.500885
[02:01:58.544] iteration 2171: loss: 0.924954, loss_s1: 0.500052, loss_fp: 0.500003, loss_freq: 0.500050
[02:01:59.248] iteration 2172: loss: 0.871326, loss_s1: 0.500062, loss_fp: 0.500001, loss_freq: 0.500015
[02:01:59.887] iteration 2173: loss: 0.873166, loss_s1: 0.500120, loss_fp: 0.500004, loss_freq: 0.500002
[02:02:00.560] iteration 2174: loss: 0.908380, loss_s1: 0.500109, loss_fp: 0.500095, loss_freq: 0.500012
[02:02:01.222] iteration 2175: loss: 0.879949, loss_s1: 0.500007, loss_fp: 0.499999, loss_freq: 0.500008
[02:02:01.910] iteration 2176: loss: 0.874262, loss_s1: 0.500032, loss_fp: 0.500016, loss_freq: 0.500005
[02:02:02.551] iteration 2177: loss: 0.961183, loss_s1: 0.500016, loss_fp: 0.500001, loss_freq: 0.500021
[02:02:03.313] iteration 2178: loss: 0.886021, loss_s1: 0.500059, loss_fp: 0.499998, loss_freq: 0.500021
[02:02:04.024] iteration 2179: loss: 0.878428, loss_s1: 0.500040, loss_fp: 0.499998, loss_freq: 0.500002
[02:02:04.705] iteration 2180: loss: 0.900835, loss_s1: 0.500377, loss_fp: 0.500001, loss_freq: 0.500003
[02:02:05.408] iteration 2181: loss: 0.916289, loss_s1: 0.500033, loss_fp: 0.500000, loss_freq: 0.500002
[02:02:06.164] iteration 2182: loss: 0.888284, loss_s1: 0.500075, loss_fp: 0.500000, loss_freq: 0.500032
[02:02:06.954] iteration 2183: loss: 0.873697, loss_s1: 0.500052, loss_fp: 0.500016, loss_freq: 0.500356
[02:02:07.663] iteration 2184: loss: 0.856431, loss_s1: 0.500015, loss_fp: 0.500008, loss_freq: 0.500001
[02:02:08.405] iteration 2185: loss: 0.893499, loss_s1: 0.500930, loss_fp: 0.500045, loss_freq: 0.500150
[02:02:09.107] iteration 2186: loss: 0.923683, loss_s1: 0.501019, loss_fp: 0.500006, loss_freq: 0.500024
[02:02:09.819] iteration 2187: loss: 0.923948, loss_s1: 0.500213, loss_fp: 0.500002, loss_freq: 0.500022
[02:02:10.496] iteration 2188: loss: 0.909137, loss_s1: 0.500015, loss_fp: 0.499996, loss_freq: 0.500002
[02:02:11.203] iteration 2189: loss: 0.871584, loss_s1: 0.501322, loss_fp: 0.500006, loss_freq: 0.500011
[02:02:11.977] iteration 2190: loss: 0.886431, loss_s1: 0.500780, loss_fp: 0.500000, loss_freq: 0.500013
[02:02:12.678] iteration 2191: loss: 0.862158, loss_s1: 0.500378, loss_fp: 0.500011, loss_freq: 0.500034
[02:02:13.343] iteration 2192: loss: 0.869285, loss_s1: 0.500482, loss_fp: 0.500001, loss_freq: 0.500109
[02:02:13.978] iteration 2193: loss: 0.868389, loss_s1: 0.500113, loss_fp: 0.499999, loss_freq: 0.500047
[02:02:14.646] iteration 2194: loss: 0.875308, loss_s1: 0.500072, loss_fp: 0.500005, loss_freq: 0.500059
[02:02:15.302] iteration 2195: loss: 0.925014, loss_s1: 0.500707, loss_fp: 0.500013, loss_freq: 0.500230
[02:02:15.968] iteration 2196: loss: 0.898337, loss_s1: 0.500904, loss_fp: 0.500007, loss_freq: 0.500002
[02:02:16.614] iteration 2197: loss: 0.883306, loss_s1: 0.502890, loss_fp: 0.500024, loss_freq: 0.500049
[02:02:17.302] iteration 2198: loss: 0.902753, loss_s1: 0.500341, loss_fp: 0.500002, loss_freq: 0.500020
[02:02:17.957] iteration 2199: loss: 0.851272, loss_s1: 0.500152, loss_fp: 0.500004, loss_freq: 0.500032
[02:02:18.618] iteration 2200: loss: 0.879001, loss_s1: 0.500115, loss_fp: 0.500004, loss_freq: 0.500045
[02:02:21.245] iteration 2200 : mean_dice : 0.216144
[02:02:21.892] iteration 2201: loss: 0.842198, loss_s1: 0.500084, loss_fp: 0.500001, loss_freq: 0.500028
[02:02:22.569] iteration 2202: loss: 0.844078, loss_s1: 0.500093, loss_fp: 0.500001, loss_freq: 0.500003
[02:02:23.255] iteration 2203: loss: 0.935586, loss_s1: 0.501798, loss_fp: 0.500000, loss_freq: 0.500331
[02:02:23.903] iteration 2204: loss: 0.878649, loss_s1: 0.500923, loss_fp: 0.500153, loss_freq: 0.500045
[02:02:24.573] iteration 2205: loss: 0.853503, loss_s1: 0.500048, loss_fp: 0.500001, loss_freq: 0.499994
[02:02:25.257] iteration 2206: loss: 0.290856, loss_s1: 0.326655, loss_fp: 0.002890, loss_freq: 0.005626
[02:02:25.914] iteration 2207: loss: 0.858342, loss_s1: 0.500084, loss_fp: 0.500006, loss_freq: 0.500447
[02:02:26.601] iteration 2208: loss: 0.866120, loss_s1: 0.500107, loss_fp: 0.500003, loss_freq: 0.500006
[02:02:27.279] iteration 2209: loss: 0.867649, loss_s1: 0.500463, loss_fp: 0.500021, loss_freq: 0.500023
[02:02:27.991] iteration 2210: loss: 0.862075, loss_s1: 0.500411, loss_fp: 0.500005, loss_freq: 0.500579
[02:02:29.035] iteration 2211: loss: 0.892186, loss_s1: 0.500244, loss_fp: 0.500002, loss_freq: 0.500004
[02:02:29.714] iteration 2212: loss: 0.878885, loss_s1: 0.500359, loss_fp: 0.500092, loss_freq: 0.500005
[02:02:30.402] iteration 2213: loss: 0.865875, loss_s1: 0.500707, loss_fp: 0.500016, loss_freq: 0.500010
[02:02:31.135] iteration 2214: loss: 0.924277, loss_s1: 0.500254, loss_fp: 0.500004, loss_freq: 0.500043
[02:02:31.821] iteration 2215: loss: 0.831416, loss_s1: 0.500045, loss_fp: 0.499995, loss_freq: 0.500001
[02:02:32.512] iteration 2216: loss: 0.902173, loss_s1: 0.500023, loss_fp: 0.499999, loss_freq: 0.500008
[02:02:33.215] iteration 2217: loss: 0.875369, loss_s1: 0.500825, loss_fp: 0.500014, loss_freq: 0.500056
[02:02:33.886] iteration 2218: loss: 0.898721, loss_s1: 0.500025, loss_fp: 0.500002, loss_freq: 0.499998
[02:02:34.570] iteration 2219: loss: 0.868054, loss_s1: 0.500047, loss_fp: 0.499997, loss_freq: 0.500011
[02:02:35.243] iteration 2220: loss: 0.887232, loss_s1: 0.500124, loss_fp: 0.499996, loss_freq: 0.500008
[02:02:35.922] iteration 2221: loss: 0.884135, loss_s1: 0.500134, loss_fp: 0.500078, loss_freq: 0.500029
[02:02:36.591] iteration 2222: loss: 0.853533, loss_s1: 0.500533, loss_fp: 0.500103, loss_freq: 0.500078
[02:02:37.292] iteration 2223: loss: 0.924248, loss_s1: 0.500786, loss_fp: 0.500001, loss_freq: 0.500789
[02:02:38.007] iteration 2224: loss: 0.878567, loss_s1: 0.500170, loss_fp: 0.500004, loss_freq: 0.500005
[02:02:38.676] iteration 2225: loss: 0.934173, loss_s1: 0.500015, loss_fp: 0.499999, loss_freq: 0.500003
[02:02:39.388] iteration 2226: loss: 0.887687, loss_s1: 0.501851, loss_fp: 0.500001, loss_freq: 0.500227
[02:02:40.061] iteration 2227: loss: 0.866821, loss_s1: 0.500434, loss_fp: 0.500129, loss_freq: 0.500099
[02:02:40.749] iteration 2228: loss: 0.889981, loss_s1: 0.500719, loss_fp: 0.500023, loss_freq: 0.500000
[02:02:41.397] iteration 2229: loss: 0.851361, loss_s1: 0.500076, loss_fp: 0.500000, loss_freq: 0.500000
[02:02:42.089] iteration 2230: loss: 0.866427, loss_s1: 0.500614, loss_fp: 0.500004, loss_freq: 0.500016
[02:02:42.740] iteration 2231: loss: 0.849732, loss_s1: 0.500279, loss_fp: 0.500014, loss_freq: 0.500008
[02:02:43.408] iteration 2232: loss: 0.854211, loss_s1: 0.502392, loss_fp: 0.500006, loss_freq: 0.500106
[02:02:44.072] iteration 2233: loss: 0.929931, loss_s1: 0.500142, loss_fp: 0.500007, loss_freq: 0.500017
[02:02:44.724] iteration 2234: loss: 0.840259, loss_s1: 0.500389, loss_fp: 0.499999, loss_freq: 0.500025
[02:02:45.410] iteration 2235: loss: 0.842015, loss_s1: 0.500752, loss_fp: 0.500015, loss_freq: 0.500108
[02:02:46.060] iteration 2236: loss: 0.869695, loss_s1: 0.502159, loss_fp: 0.500002, loss_freq: 0.500012
[02:02:46.729] iteration 2237: loss: 0.869513, loss_s1: 0.500430, loss_fp: 0.500000, loss_freq: 0.499999
[02:02:47.416] iteration 2238: loss: 0.851003, loss_s1: 0.500359, loss_fp: 0.500000, loss_freq: 0.500184
[02:02:48.063] iteration 2239: loss: 0.932698, loss_s1: 0.500692, loss_fp: 0.500012, loss_freq: 0.500111
[02:02:48.752] iteration 2240: loss: 0.853164, loss_s1: 0.500462, loss_fp: 0.500004, loss_freq: 0.500013
[02:02:49.396] iteration 2241: loss: 0.827301, loss_s1: 0.500720, loss_fp: 0.500006, loss_freq: 0.500007
[02:02:50.096] iteration 2242: loss: 0.905053, loss_s1: 0.501189, loss_fp: 0.500004, loss_freq: 0.500286
[02:02:50.803] iteration 2243: loss: 0.842182, loss_s1: 0.500640, loss_fp: 0.500002, loss_freq: 0.500024
[02:02:51.508] iteration 2244: loss: 0.880239, loss_s1: 0.500211, loss_fp: 0.500067, loss_freq: 0.500654
[02:02:52.195] iteration 2245: loss: 0.847388, loss_s1: 0.501444, loss_fp: 0.500057, loss_freq: 0.500016
[02:02:52.870] iteration 2246: loss: 0.911716, loss_s1: 0.500039, loss_fp: 0.500010, loss_freq: 0.500017
[02:02:53.586] iteration 2247: loss: 0.872919, loss_s1: 0.500687, loss_fp: 0.500001, loss_freq: 0.500048
[02:02:54.254] iteration 2248: loss: 0.837493, loss_s1: 0.501786, loss_fp: 0.500002, loss_freq: 0.500025
[02:02:54.938] iteration 2249: loss: 0.850188, loss_s1: 0.500551, loss_fp: 0.500001, loss_freq: 0.500299
[02:02:55.616] iteration 2250: loss: 0.853573, loss_s1: 0.500164, loss_fp: 0.500011, loss_freq: 0.500009
[02:02:56.331] iteration 2251: loss: 0.914239, loss_s1: 0.500240, loss_fp: 0.500002, loss_freq: 0.500197
[02:02:57.032] iteration 2252: loss: 0.851860, loss_s1: 0.500322, loss_fp: 0.500002, loss_freq: 0.500417
[02:02:57.752] iteration 2253: loss: 0.872086, loss_s1: 0.500823, loss_fp: 0.500005, loss_freq: 0.500027
[02:02:58.484] iteration 2254: loss: 0.855989, loss_s1: 0.500204, loss_fp: 0.499998, loss_freq: 0.500093
[02:02:59.189] iteration 2255: loss: 0.883425, loss_s1: 0.500101, loss_fp: 0.500005, loss_freq: 0.500005
[02:02:59.939] iteration 2256: loss: 0.842441, loss_s1: 0.500231, loss_fp: 0.500004, loss_freq: 0.500157
[02:03:00.647] iteration 2257: loss: 0.846705, loss_s1: 0.500041, loss_fp: 0.499999, loss_freq: 0.500003
[02:03:01.349] iteration 2258: loss: 0.840625, loss_s1: 0.500570, loss_fp: 0.500008, loss_freq: 0.500259
[02:03:02.062] iteration 2259: loss: 0.879549, loss_s1: 0.501974, loss_fp: 0.500006, loss_freq: 0.500002
[02:03:02.745] iteration 2260: loss: 0.873943, loss_s1: 0.500587, loss_fp: 0.500003, loss_freq: 0.500083
[02:03:03.420] iteration 2261: loss: 0.847498, loss_s1: 0.502064, loss_fp: 0.499997, loss_freq: 0.500221
[02:03:04.099] iteration 2262: loss: 0.859215, loss_s1: 0.500534, loss_fp: 0.500003, loss_freq: 0.500050
[02:03:04.781] iteration 2263: loss: 0.923500, loss_s1: 0.500477, loss_fp: 0.500060, loss_freq: 0.500794
[02:03:05.451] iteration 2264: loss: 0.834582, loss_s1: 0.501536, loss_fp: 0.500046, loss_freq: 0.500396
[02:03:06.128] iteration 2265: loss: 0.865569, loss_s1: 0.500833, loss_fp: 0.500002, loss_freq: 0.500819
[02:03:06.896] iteration 2266: loss: 0.783935, loss_s1: 0.384618, loss_fp: 0.500031, loss_freq: 0.500832
[02:03:07.697] iteration 2267: loss: 0.824954, loss_s1: 0.500162, loss_fp: 0.500000, loss_freq: 0.500248
[02:03:08.445] iteration 2268: loss: 0.891231, loss_s1: 0.501595, loss_fp: 0.500014, loss_freq: 0.500139
[02:03:09.093] iteration 2269: loss: 0.869830, loss_s1: 0.500006, loss_fp: 0.500000, loss_freq: 0.499997
[02:03:09.731] iteration 2270: loss: 0.846667, loss_s1: 0.500089, loss_fp: 0.500008, loss_freq: 0.500041
[02:03:10.497] iteration 2271: loss: 0.708210, loss_s1: 0.158368, loss_fp: 0.500032, loss_freq: 0.500000
[02:03:11.166] iteration 2272: loss: 0.878757, loss_s1: 0.500010, loss_fp: 0.500001, loss_freq: 0.500002
[02:03:11.884] iteration 2273: loss: 0.885325, loss_s1: 0.500009, loss_fp: 0.500001, loss_freq: 0.499999
[02:03:12.560] iteration 2274: loss: 0.859585, loss_s1: 0.500071, loss_fp: 0.500000, loss_freq: 0.499999
[02:03:13.354] iteration 2275: loss: 0.907556, loss_s1: 0.500009, loss_fp: 0.499999, loss_freq: 0.500000
[02:03:14.013] iteration 2276: loss: 0.872832, loss_s1: 0.500007, loss_fp: 0.500000, loss_freq: 0.500002
[02:03:14.685] iteration 2277: loss: 0.991463, loss_s1: 0.500016, loss_fp: 0.499997, loss_freq: 0.500005
[02:03:15.359] iteration 2278: loss: 0.869325, loss_s1: 0.500009, loss_fp: 0.500018, loss_freq: 0.499987
[02:03:16.025] iteration 2279: loss: 0.904435, loss_s1: 0.500004, loss_fp: 0.500001, loss_freq: 0.500002
[02:03:16.792] iteration 2280: loss: 0.860161, loss_s1: 0.500009, loss_fp: 0.500085, loss_freq: 0.500010
[02:03:17.465] iteration 2281: loss: 0.906532, loss_s1: 0.500026, loss_fp: 0.500006, loss_freq: 0.500019
[02:03:18.211] iteration 2282: loss: 0.837478, loss_s1: 0.500010, loss_fp: 0.500012, loss_freq: 0.499999
[02:03:18.919] iteration 2283: loss: 0.928797, loss_s1: 0.500022, loss_fp: 0.500003, loss_freq: 0.500012
[02:03:19.623] iteration 2284: loss: 0.846468, loss_s1: 0.500017, loss_fp: 0.500002, loss_freq: 0.500002
[02:03:20.347] iteration 2285: loss: 0.887253, loss_s1: 0.500016, loss_fp: 0.499999, loss_freq: 0.500012
[02:03:20.996] iteration 2286: loss: 0.894897, loss_s1: 0.500010, loss_fp: 0.499993, loss_freq: 0.500004
[02:03:21.740] iteration 2287: loss: 0.874718, loss_s1: 0.500064, loss_fp: 0.500008, loss_freq: 0.500003
[02:03:22.397] iteration 2288: loss: 0.878075, loss_s1: 0.500098, loss_fp: 0.500001, loss_freq: 0.500003
[02:03:23.030] iteration 2289: loss: 0.859799, loss_s1: 0.500185, loss_fp: 0.500000, loss_freq: 0.500004
[02:03:23.671] iteration 2290: loss: 0.881905, loss_s1: 0.500051, loss_fp: 0.499997, loss_freq: 0.500003
[02:03:24.309] iteration 2291: loss: 0.847515, loss_s1: 0.500172, loss_fp: 0.499999, loss_freq: 0.500010
[02:03:24.946] iteration 2292: loss: 0.853983, loss_s1: 0.500105, loss_fp: 0.500001, loss_freq: 0.500017
[02:03:25.591] iteration 2293: loss: 0.891182, loss_s1: 0.500219, loss_fp: 0.500001, loss_freq: 0.500008
[02:03:26.239] iteration 2294: loss: 0.850855, loss_s1: 0.500750, loss_fp: 0.500001, loss_freq: 0.500008
[02:03:26.882] iteration 2295: loss: 0.915581, loss_s1: 0.500201, loss_fp: 0.500012, loss_freq: 0.500023
[02:03:27.522] iteration 2296: loss: 0.886258, loss_s1: 0.500190, loss_fp: 0.500009, loss_freq: 0.500320
[02:03:28.150] iteration 2297: loss: 0.831706, loss_s1: 0.500399, loss_fp: 0.500008, loss_freq: 0.500014
[02:03:28.839] iteration 2298: loss: 0.490717, loss_s1: 0.343665, loss_fp: 0.050858, loss_freq: 0.228346
[02:03:29.500] iteration 2299: loss: 0.833149, loss_s1: 0.500341, loss_fp: 0.500011, loss_freq: 0.500017
[02:03:30.151] iteration 2300: loss: 0.874976, loss_s1: 0.500090, loss_fp: 0.500004, loss_freq: 0.500011
[02:03:30.789] iteration 2301: loss: 0.946229, loss_s1: 0.500002, loss_fp: 0.500006, loss_freq: 0.500000
[02:03:31.432] iteration 2302: loss: 0.867136, loss_s1: 0.500015, loss_fp: 0.500044, loss_freq: 0.499999
[02:03:32.084] iteration 2303: loss: 0.908081, loss_s1: 0.500067, loss_fp: 0.500003, loss_freq: 0.500002
[02:03:32.710] iteration 2304: loss: 0.908930, loss_s1: 0.499999, loss_fp: 0.500003, loss_freq: 0.499998
[02:03:33.325] iteration 2305: loss: 0.938567, loss_s1: 0.499993, loss_fp: 0.500002, loss_freq: 0.499993
[02:03:33.951] iteration 2306: loss: 0.883892, loss_s1: 0.499999, loss_fp: 0.500012, loss_freq: 0.499997
[02:03:34.575] iteration 2307: loss: 0.917132, loss_s1: 0.499999, loss_fp: 0.500005, loss_freq: 0.499998
[02:03:35.222] iteration 2308: loss: 0.903321, loss_s1: 0.499998, loss_fp: 0.500004, loss_freq: 0.499999
[02:03:35.876] iteration 2309: loss: 0.907624, loss_s1: 0.499999, loss_fp: 0.499998, loss_freq: 0.499996
[02:03:36.532] iteration 2310: loss: 0.884695, loss_s1: 0.500010, loss_fp: 0.500010, loss_freq: 0.500000
[02:03:37.381] iteration 2311: loss: 0.846661, loss_s1: 0.500000, loss_fp: 0.500045, loss_freq: 0.499999
[02:03:38.200] iteration 2312: loss: 0.972306, loss_s1: 0.500001, loss_fp: 0.500007, loss_freq: 0.500000
[02:03:39.032] iteration 2313: loss: 0.907768, loss_s1: 0.499997, loss_fp: 0.500001, loss_freq: 0.499996
[02:03:39.774] iteration 2314: loss: 0.942893, loss_s1: 0.500001, loss_fp: 0.500010, loss_freq: 0.500002
[02:03:40.411] iteration 2315: loss: 0.870726, loss_s1: 0.500002, loss_fp: 0.500041, loss_freq: 0.499998
[02:03:41.091] iteration 2316: loss: 0.892734, loss_s1: 0.500001, loss_fp: 0.500026, loss_freq: 0.500000
[02:03:41.745] iteration 2317: loss: 0.886386, loss_s1: 0.500005, loss_fp: 0.500010, loss_freq: 0.499998
[02:03:42.393] iteration 2318: loss: 0.866700, loss_s1: 0.500009, loss_fp: 0.499994, loss_freq: 0.499996
[02:03:43.056] iteration 2319: loss: 0.865103, loss_s1: 0.500055, loss_fp: 0.500002, loss_freq: 0.500089
[02:03:43.713] iteration 2320: loss: 0.886822, loss_s1: 0.500005, loss_fp: 0.500035, loss_freq: 0.500001
[02:03:44.376] iteration 2321: loss: 0.871761, loss_s1: 0.500024, loss_fp: 0.500003, loss_freq: 0.500002
[02:03:45.044] iteration 2322: loss: 0.851129, loss_s1: 0.500015, loss_fp: 0.500002, loss_freq: 0.500000
[02:03:45.711] iteration 2323: loss: 0.712412, loss_s1: 0.166879, loss_fp: 0.500009, loss_freq: 0.499981
[02:03:46.372] iteration 2324: loss: 0.879209, loss_s1: 0.500012, loss_fp: 0.500015, loss_freq: 0.499999
[02:03:47.038] iteration 2325: loss: 0.884457, loss_s1: 0.500033, loss_fp: 0.500003, loss_freq: 0.500041
[02:03:47.704] iteration 2326: loss: 0.851589, loss_s1: 0.500040, loss_fp: 0.500001, loss_freq: 0.500101
[02:03:48.358] iteration 2327: loss: 0.898954, loss_s1: 0.500215, loss_fp: 0.500067, loss_freq: 0.500000
[02:03:49.026] iteration 2328: loss: 0.360165, loss_s1: 0.466874, loss_fp: 0.001715, loss_freq: 0.000831
[02:03:49.697] iteration 2329: loss: 0.897623, loss_s1: 0.500152, loss_fp: 0.500507, loss_freq: 0.500106
[02:03:50.369] iteration 2330: loss: 0.899737, loss_s1: 0.500109, loss_fp: 0.500028, loss_freq: 0.500012
[02:03:51.052] iteration 2331: loss: 0.369594, loss_s1: 0.182271, loss_fp: 0.264343, loss_freq: 0.055121
[02:03:51.758] iteration 2332: loss: 0.870350, loss_s1: 0.500016, loss_fp: 0.500005, loss_freq: 0.499997
[02:03:52.467] iteration 2333: loss: 0.915872, loss_s1: 0.500586, loss_fp: 0.499997, loss_freq: 0.500008
[02:03:53.172] iteration 2334: loss: 0.897397, loss_s1: 0.501030, loss_fp: 0.499997, loss_freq: 0.500103
[02:03:53.881] iteration 2335: loss: 0.874879, loss_s1: 0.501220, loss_fp: 0.500003, loss_freq: 0.500071
[02:03:54.588] iteration 2336: loss: 0.903680, loss_s1: 0.500128, loss_fp: 0.499998, loss_freq: 0.500157
[02:03:55.294] iteration 2337: loss: 0.875449, loss_s1: 0.500228, loss_fp: 0.500004, loss_freq: 0.500126
[02:03:56.015] iteration 2338: loss: 0.919286, loss_s1: 0.500079, loss_fp: 0.499997, loss_freq: 0.500062
[02:03:56.725] iteration 2339: loss: 0.242936, loss_s1: 0.247087, loss_fp: 0.002659, loss_freq: 0.019115
[02:03:57.464] iteration 2340: loss: 0.844426, loss_s1: 0.500567, loss_fp: 0.500053, loss_freq: 0.500325
[02:03:58.172] iteration 2341: loss: 0.873539, loss_s1: 0.500012, loss_fp: 0.499999, loss_freq: 0.500010
[02:03:58.851] iteration 2342: loss: 0.944837, loss_s1: 0.500030, loss_fp: 0.500005, loss_freq: 0.500010
[02:03:59.546] iteration 2343: loss: 0.901127, loss_s1: 0.500137, loss_fp: 0.499855, loss_freq: 0.500009
[02:04:00.245] iteration 2344: loss: 0.905465, loss_s1: 0.500022, loss_fp: 0.499995, loss_freq: 0.500007
[02:04:00.948] iteration 2345: loss: 0.892643, loss_s1: 0.500051, loss_fp: 0.500079, loss_freq: 0.500002
[02:04:01.641] iteration 2346: loss: 0.852379, loss_s1: 0.500012, loss_fp: 0.499957, loss_freq: 0.500006
[02:04:02.344] iteration 2347: loss: 0.975314, loss_s1: 0.500037, loss_fp: 0.500006, loss_freq: 0.500007
[02:04:03.007] iteration 2348: loss: 0.357453, loss_s1: 0.494346, loss_fp: 0.003788, loss_freq: 0.018128
[02:04:03.688] iteration 2349: loss: 0.893165, loss_s1: 0.500066, loss_fp: 0.499979, loss_freq: 0.500005
[02:04:04.357] iteration 2350: loss: 0.891820, loss_s1: 0.500135, loss_fp: 0.500003, loss_freq: 0.500012
[02:04:05.029] iteration 2351: loss: 0.906742, loss_s1: 0.500211, loss_fp: 0.499999, loss_freq: 0.500006
[02:04:05.709] iteration 2352: loss: 0.869250, loss_s1: 0.500091, loss_fp: 0.500005, loss_freq: 0.500106
[02:04:06.386] iteration 2353: loss: 0.899822, loss_s1: 0.500181, loss_fp: 0.500010, loss_freq: 0.500111
[02:04:07.067] iteration 2354: loss: 0.661009, loss_s1: 0.122753, loss_fp: 0.500006, loss_freq: 0.500009
[02:04:07.754] iteration 2355: loss: 0.851906, loss_s1: 0.500015, loss_fp: 0.500006, loss_freq: 0.499991
[02:04:08.442] iteration 2356: loss: 0.917513, loss_s1: 0.500143, loss_fp: 0.499935, loss_freq: 0.500003
[02:04:09.113] iteration 2357: loss: 0.279791, loss_s1: 0.308488, loss_fp: 0.000793, loss_freq: 0.009847
[02:04:09.797] iteration 2358: loss: 0.858179, loss_s1: 0.500044, loss_fp: 0.499998, loss_freq: 0.499996
[02:04:10.479] iteration 2359: loss: 0.852117, loss_s1: 0.500519, loss_fp: 0.499974, loss_freq: 0.500002
[02:04:11.164] iteration 2360: loss: 0.910496, loss_s1: 0.500068, loss_fp: 0.499981, loss_freq: 0.500012
[02:04:11.846] iteration 2361: loss: 0.849566, loss_s1: 0.500480, loss_fp: 0.499976, loss_freq: 0.500039
[02:04:12.519] iteration 2362: loss: 0.877675, loss_s1: 0.500066, loss_fp: 0.499994, loss_freq: 0.500058
[02:04:13.217] iteration 2363: loss: 0.853191, loss_s1: 0.500108, loss_fp: 0.499984, loss_freq: 0.500056
[02:04:13.918] iteration 2364: loss: 0.128590, loss_s1: 0.053609, loss_fp: 0.000783, loss_freq: 0.003075
[02:04:14.619] iteration 2365: loss: 0.926596, loss_s1: 0.500008, loss_fp: 0.499996, loss_freq: 0.500002
[02:04:15.311] iteration 2366: loss: 0.866694, loss_s1: 0.500456, loss_fp: 0.500004, loss_freq: 0.500020
[02:04:16.013] iteration 2367: loss: 0.837883, loss_s1: 0.500037, loss_fp: 0.499996, loss_freq: 0.500021
[02:04:16.707] iteration 2368: loss: 0.872399, loss_s1: 0.500028, loss_fp: 0.499989, loss_freq: 0.500003
[02:04:17.385] iteration 2369: loss: 0.836789, loss_s1: 0.500124, loss_fp: 0.499954, loss_freq: 0.500009
[02:04:18.066] iteration 2370: loss: 0.880101, loss_s1: 0.500028, loss_fp: 0.500007, loss_freq: 0.499996
[02:04:18.748] iteration 2371: loss: 0.838763, loss_s1: 0.500001, loss_fp: 0.499994, loss_freq: 0.499995
[02:04:19.468] iteration 2372: loss: 0.096711, loss_s1: 0.016079, loss_fp: 0.001351, loss_freq: 0.002641
[02:04:20.149] iteration 2373: loss: 0.879808, loss_s1: 0.500264, loss_fp: 0.499997, loss_freq: 0.500168
[02:04:20.834] iteration 2374: loss: 0.845191, loss_s1: 0.500006, loss_fp: 0.499996, loss_freq: 0.501190
[02:04:21.525] iteration 2375: loss: 0.279801, loss_s1: 0.379973, loss_fp: 0.001286, loss_freq: 0.001157
[02:04:22.202] iteration 2376: loss: 0.357052, loss_s1: 0.472168, loss_fp: 0.007538, loss_freq: 0.001045
[02:04:22.908] iteration 2377: loss: 0.887371, loss_s1: 0.500163, loss_fp: 0.499993, loss_freq: 0.500333
[02:04:23.589] iteration 2378: loss: 0.866040, loss_s1: 0.500003, loss_fp: 0.499997, loss_freq: 0.499994
[02:04:24.270] iteration 2379: loss: 0.347368, loss_s1: 0.456441, loss_fp: 0.003645, loss_freq: 0.056936
[02:04:24.965] iteration 2380: loss: 0.856597, loss_s1: 0.500483, loss_fp: 0.499990, loss_freq: 0.501330
[02:04:26.037] iteration 2381: loss: 0.385753, loss_s1: 0.506149, loss_fp: 0.000610, loss_freq: 0.000834
[02:04:26.714] iteration 2382: loss: 0.142233, loss_s1: 0.094010, loss_fp: 0.003966, loss_freq: 0.006287
[02:04:27.398] iteration 2383: loss: 0.876360, loss_s1: 0.502914, loss_fp: 0.500041, loss_freq: 0.499999
[02:04:28.078] iteration 2384: loss: 0.975825, loss_s1: 0.500141, loss_fp: 0.500008, loss_freq: 0.500004
[02:04:28.791] iteration 2385: loss: 0.424127, loss_s1: 0.501198, loss_fp: 0.084548, loss_freq: 0.006826
[02:04:29.469] iteration 2386: loss: 1.060910, loss_s1: 0.500868, loss_fp: 0.500028, loss_freq: 0.499995
[02:04:30.143] iteration 2387: loss: 0.961549, loss_s1: 0.500018, loss_fp: 0.500005, loss_freq: 0.500006
[02:04:30.820] iteration 2388: loss: 0.885401, loss_s1: 0.500070, loss_fp: 0.500006, loss_freq: 0.499997
[02:04:31.495] iteration 2389: loss: 0.814493, loss_s1: 0.288291, loss_fp: 0.500003, loss_freq: 0.499984
[02:04:32.173] iteration 2390: loss: 0.155277, loss_s1: 0.003784, loss_fp: 0.002566, loss_freq: 0.001327
[02:04:32.835] iteration 2391: loss: 0.854484, loss_s1: 0.500001, loss_fp: 0.499997, loss_freq: 0.499995
[02:04:33.554] iteration 2392: loss: 0.872227, loss_s1: 0.500050, loss_fp: 0.500001, loss_freq: 0.499999
[02:04:34.253] iteration 2393: loss: 0.875047, loss_s1: 0.502081, loss_fp: 0.499999, loss_freq: 0.500799
[02:04:34.951] iteration 2394: loss: 0.714161, loss_s1: 0.137966, loss_fp: 0.499995, loss_freq: 0.499984
[02:04:35.621] iteration 2395: loss: 0.783958, loss_s1: 0.139451, loss_fp: 0.499996, loss_freq: 0.499982
[02:04:36.281] iteration 2396: loss: 0.321306, loss_s1: 0.377119, loss_fp: 0.026298, loss_freq: 0.001104
[02:04:36.944] iteration 2397: loss: 0.868603, loss_s1: 0.500251, loss_fp: 0.499998, loss_freq: 0.500008
[02:04:37.603] iteration 2398: loss: 0.272839, loss_s1: 0.252216, loss_fp: 0.001558, loss_freq: 0.000883
[02:04:38.270] iteration 2399: loss: 0.857710, loss_s1: 0.500593, loss_fp: 0.500001, loss_freq: 0.499970
[02:04:38.936] iteration 2400: loss: 0.901633, loss_s1: 0.501738, loss_fp: 0.500040, loss_freq: 0.499993
[02:04:41.110] iteration 2400 : mean_dice : 0.088150
[02:04:41.821] iteration 2401: loss: 0.875124, loss_s1: 0.503200, loss_fp: 0.500000, loss_freq: 0.500304
[02:04:42.515] iteration 2402: loss: 0.991142, loss_s1: 0.504760, loss_fp: 0.499998, loss_freq: 0.500006
[02:04:43.209] iteration 2403: loss: 0.376206, loss_s1: 0.241866, loss_fp: 0.113468, loss_freq: 0.059460
[02:04:43.937] iteration 2404: loss: 0.840423, loss_s1: 0.500137, loss_fp: 0.499996, loss_freq: 0.500012
[02:04:44.650] iteration 2405: loss: 0.240010, loss_s1: 0.241877, loss_fp: 0.001072, loss_freq: 0.001119
[02:04:45.330] iteration 2406: loss: 0.389515, loss_s1: 0.496218, loss_fp: 0.000864, loss_freq: 0.000920
[02:04:46.022] iteration 2407: loss: 0.192892, loss_s1: 0.065729, loss_fp: 0.000886, loss_freq: 0.001214
[02:04:46.730] iteration 2408: loss: 0.898948, loss_s1: 0.500014, loss_fp: 0.499997, loss_freq: 0.499996
[02:04:47.424] iteration 2409: loss: 0.552351, loss_s1: 0.461217, loss_fp: 0.011448, loss_freq: 0.191519
[02:04:48.093] iteration 2410: loss: 1.036905, loss_s1: 0.501245, loss_fp: 0.500000, loss_freq: 0.500036
[02:04:48.771] iteration 2411: loss: 0.557720, loss_s1: 0.484335, loss_fp: 0.010228, loss_freq: 0.008995
[02:04:49.458] iteration 2412: loss: 1.324163, loss_s1: 0.500406, loss_fp: 0.500009, loss_freq: 0.500002
[02:04:50.133] iteration 2413: loss: 0.416268, loss_s1: 0.203102, loss_fp: 0.000664, loss_freq: 0.001602
[02:04:50.802] iteration 2414: loss: 0.434601, loss_s1: 0.236090, loss_fp: 0.002913, loss_freq: 0.001862
[02:04:51.473] iteration 2415: loss: 0.398557, loss_s1: 0.368385, loss_fp: 0.002598, loss_freq: 0.003127
[02:04:52.168] iteration 2416: loss: 1.034040, loss_s1: 0.500530, loss_fp: 0.500003, loss_freq: 0.500041
[02:04:52.887] iteration 2417: loss: 0.398643, loss_s1: 0.278142, loss_fp: 0.001414, loss_freq: 0.004833
[02:04:53.619] iteration 2418: loss: 1.180401, loss_s1: 0.500241, loss_fp: 0.500003, loss_freq: 0.500035
[02:04:54.310] iteration 2419: loss: 0.352227, loss_s1: 0.122164, loss_fp: 0.006626, loss_freq: 0.031494
[02:04:55.099] iteration 2420: loss: 0.565847, loss_s1: 0.356519, loss_fp: 0.065717, loss_freq: 0.097389
[02:04:56.213] iteration 2421: loss: 0.570379, loss_s1: 0.347652, loss_fp: 0.022141, loss_freq: 0.119631
[02:04:57.131] iteration 2422: loss: 1.010820, loss_s1: 0.473585, loss_fp: 0.499999, loss_freq: 0.499999
[02:04:57.994] iteration 2423: loss: 0.456024, loss_s1: 0.219467, loss_fp: 0.030883, loss_freq: 0.035915
[02:04:59.226] iteration 2424: loss: 0.972313, loss_s1: 0.499999, loss_fp: 0.500005, loss_freq: 0.500002
[02:05:03.567] iteration 2425: loss: 1.055270, loss_s1: 0.500012, loss_fp: 0.499997, loss_freq: 0.499996
[02:05:24.397] iteration 2426: loss: 0.990848, loss_s1: 0.499998, loss_fp: 0.500002, loss_freq: 0.499988
[02:05:45.240] iteration 2427: loss: 1.083500, loss_s1: 0.497004, loss_fp: 0.500007, loss_freq: 0.499994
[02:06:06.122] iteration 2428: loss: 1.048247, loss_s1: 0.500087, loss_fp: 0.500003, loss_freq: 0.500037
[02:06:27.016] iteration 2429: loss: 1.062187, loss_s1: 0.500101, loss_fp: 0.499998, loss_freq: 0.499991
[02:06:47.900] iteration 2430: loss: 1.041907, loss_s1: 0.500044, loss_fp: 0.500006, loss_freq: 0.499998
[02:07:08.859] iteration 2431: loss: 0.968209, loss_s1: 0.500382, loss_fp: 0.499998, loss_freq: 0.499996
[02:07:29.736] iteration 2432: loss: 0.999580, loss_s1: 0.500003, loss_fp: 0.500005, loss_freq: 0.499995
[02:07:50.698] iteration 2433: loss: 1.019001, loss_s1: 0.500011, loss_fp: 0.500004, loss_freq: 0.500012
[02:08:11.575] iteration 2434: loss: 0.978873, loss_s1: 0.500007, loss_fp: 0.500013, loss_freq: 0.500010
[02:08:32.542] iteration 2435: loss: 0.983303, loss_s1: 0.500020, loss_fp: 0.500001, loss_freq: 0.500012
[02:08:53.387] iteration 2436: loss: 1.031521, loss_s1: 0.500055, loss_fp: 0.500000, loss_freq: 0.500009
[02:09:14.350] iteration 2437: loss: 0.958962, loss_s1: 0.500023, loss_fp: 0.500005, loss_freq: 0.500041
[02:09:35.304] iteration 2438: loss: 1.016709, loss_s1: 0.500009, loss_fp: 0.500002, loss_freq: 0.500041
[02:09:56.191] iteration 2439: loss: 0.975117, loss_s1: 0.500033, loss_fp: 0.500015, loss_freq: 0.500005
[02:10:17.160] iteration 2440: loss: 0.969101, loss_s1: 0.500036, loss_fp: 0.500017, loss_freq: 0.500041
[02:10:38.054] iteration 2441: loss: 1.006519, loss_s1: 0.500021, loss_fp: 0.500009, loss_freq: 0.500002
[02:10:59.016] iteration 2442: loss: 0.972576, loss_s1: 0.500017, loss_fp: 0.500009, loss_freq: 0.500051
[02:11:19.879] iteration 2443: loss: 0.913205, loss_s1: 0.500052, loss_fp: 0.500007, loss_freq: 0.500022
[02:11:40.833] iteration 2444: loss: 1.010123, loss_s1: 0.500019, loss_fp: 0.500013, loss_freq: 0.500001
[02:12:01.718] iteration 2445: loss: 0.958249, loss_s1: 0.500004, loss_fp: 0.500002, loss_freq: 0.500002
[02:12:22.682] iteration 2446: loss: 0.908683, loss_s1: 0.500171, loss_fp: 0.500035, loss_freq: 0.500046
[02:12:43.639] iteration 2447: loss: 1.042866, loss_s1: 0.501165, loss_fp: 0.500025, loss_freq: 0.500028
[02:13:04.512] iteration 2448: loss: 0.926601, loss_s1: 0.500266, loss_fp: 0.500030, loss_freq: 0.500027
[02:13:25.472] iteration 2449: loss: 0.943823, loss_s1: 0.500360, loss_fp: 0.500005, loss_freq: 0.500069
[02:13:46.347] iteration 2450: loss: 0.963543, loss_s1: 0.500079, loss_fp: 0.500006, loss_freq: 0.500028
[02:14:07.315] iteration 2451: loss: 0.943712, loss_s1: 0.500705, loss_fp: 0.500015, loss_freq: 0.500082
[02:14:28.199] iteration 2452: loss: 0.917138, loss_s1: 0.500054, loss_fp: 0.500015, loss_freq: 0.500083
[02:14:49.154] iteration 2453: loss: 0.971672, loss_s1: 0.500117, loss_fp: 0.500015, loss_freq: 0.500034
[02:15:10.096] iteration 2454: loss: 0.973790, loss_s1: 0.500230, loss_fp: 0.500043, loss_freq: 0.500236
[02:15:31.064] iteration 2455: loss: 0.936142, loss_s1: 0.500231, loss_fp: 0.500018, loss_freq: 0.500143
[02:15:52.019] iteration 2456: loss: 0.967411, loss_s1: 0.500057, loss_fp: 0.500068, loss_freq: 0.500178
[02:16:12.921] iteration 2457: loss: 0.930145, loss_s1: 0.500137, loss_fp: 0.500019, loss_freq: 0.500060
[02:16:33.879] iteration 2458: loss: 0.991888, loss_s1: 0.500580, loss_fp: 0.500010, loss_freq: 0.500226
[02:16:54.760] iteration 2459: loss: 0.941755, loss_s1: 0.500952, loss_fp: 0.500006, loss_freq: 0.500062
[02:17:15.717] iteration 2460: loss: 0.975620, loss_s1: 0.501494, loss_fp: 0.500101, loss_freq: 0.500075
[02:17:36.605] iteration 2461: loss: 0.902226, loss_s1: 0.500374, loss_fp: 0.500007, loss_freq: 0.500079
[02:17:57.570] iteration 2462: loss: 0.941604, loss_s1: 0.500749, loss_fp: 0.500003, loss_freq: 0.500299
[02:18:18.528] iteration 2463: loss: 0.949495, loss_s1: 0.500295, loss_fp: 0.500018, loss_freq: 0.500538
[02:18:39.417] iteration 2464: loss: 0.929582, loss_s1: 0.500065, loss_fp: 0.500004, loss_freq: 0.500033
[02:19:00.375] iteration 2465: loss: 0.971793, loss_s1: 0.500401, loss_fp: 0.500021, loss_freq: 0.500169
[02:19:21.269] iteration 2466: loss: 0.911044, loss_s1: 0.500516, loss_fp: 0.500026, loss_freq: 0.500087
[02:19:42.236] iteration 2467: loss: 0.888400, loss_s1: 0.500070, loss_fp: 0.500014, loss_freq: 0.500015
[02:20:03.136] iteration 2468: loss: 0.927991, loss_s1: 0.500233, loss_fp: 0.500088, loss_freq: 0.500054
[02:20:24.096] iteration 2469: loss: 0.914582, loss_s1: 0.500451, loss_fp: 0.500017, loss_freq: 0.500473
[02:20:40.889] iteration 2470: loss: 0.919773, loss_s1: 0.500330, loss_fp: 0.500021, loss_freq: 0.500054
[02:20:41.553] iteration 2471: loss: 0.933694, loss_s1: 0.500461, loss_fp: 0.500026, loss_freq: 0.500140
[02:20:42.244] iteration 2472: loss: 0.867725, loss_s1: 0.500113, loss_fp: 0.500006, loss_freq: 0.500651
[02:20:43.479] iteration 2473: loss: 0.960977, loss_s1: 0.500406, loss_fp: 0.500003, loss_freq: 0.500097
[02:20:45.089] iteration 2474: loss: 0.931692, loss_s1: 0.501298, loss_fp: 0.500044, loss_freq: 0.500206
[02:20:45.781] iteration 2475: loss: 0.896470, loss_s1: 0.500022, loss_fp: 0.500021, loss_freq: 0.500012
[02:20:46.479] iteration 2476: loss: 0.949288, loss_s1: 0.500364, loss_fp: 0.500011, loss_freq: 0.500056
[02:20:47.159] iteration 2477: loss: 0.921277, loss_s1: 0.501741, loss_fp: 0.500007, loss_freq: 0.500056
[02:20:47.846] iteration 2478: loss: 0.893213, loss_s1: 0.500402, loss_fp: 0.500006, loss_freq: 0.500142
[02:20:48.540] iteration 2479: loss: 0.765702, loss_s1: 0.499516, loss_fp: 0.324307, loss_freq: 0.370255
[02:20:49.205] iteration 2480: loss: 0.911653, loss_s1: 0.500260, loss_fp: 0.500001, loss_freq: 0.500039
[02:20:49.858] iteration 2481: loss: 0.860877, loss_s1: 0.500574, loss_fp: 0.500003, loss_freq: 0.500107
[02:20:50.512] iteration 2482: loss: 0.984731, loss_s1: 0.500794, loss_fp: 0.500006, loss_freq: 0.500163
[02:20:51.167] iteration 2483: loss: 0.774052, loss_s1: 0.268870, loss_fp: 0.500015, loss_freq: 0.499994
[02:20:51.823] iteration 2484: loss: 0.963310, loss_s1: 0.500191, loss_fp: 0.500014, loss_freq: 0.500141
[02:20:52.510] iteration 2485: loss: 0.967421, loss_s1: 0.500096, loss_fp: 0.500002, loss_freq: 0.500068
[02:20:53.194] iteration 2486: loss: 0.950882, loss_s1: 0.500878, loss_fp: 0.500002, loss_freq: 0.500017
[02:20:53.885] iteration 2487: loss: 0.912066, loss_s1: 0.501134, loss_fp: 0.500004, loss_freq: 0.500029
[02:20:54.538] iteration 2488: loss: 0.923696, loss_s1: 0.502552, loss_fp: 0.500001, loss_freq: 0.500036
[02:20:55.208] iteration 2489: loss: 0.966172, loss_s1: 0.501978, loss_fp: 0.500001, loss_freq: 0.500454
[02:20:55.861] iteration 2490: loss: 0.512781, loss_s1: 0.499389, loss_fp: 0.015322, loss_freq: 0.162778
[02:20:56.525] iteration 2491: loss: 0.982603, loss_s1: 0.500471, loss_fp: 0.500014, loss_freq: 0.500013
[02:20:57.177] iteration 2492: loss: 0.926614, loss_s1: 0.500031, loss_fp: 0.499999, loss_freq: 0.499998
[02:20:57.844] iteration 2493: loss: 0.504971, loss_s1: 0.499724, loss_fp: 0.073169, loss_freq: 0.004482
[02:20:58.514] iteration 2494: loss: 0.922016, loss_s1: 0.500072, loss_fp: 0.500015, loss_freq: 0.500003
[02:20:59.201] iteration 2495: loss: 1.028420, loss_s1: 0.500716, loss_fp: 0.499996, loss_freq: 0.500094
[02:20:59.872] iteration 2496: loss: 0.899693, loss_s1: 0.500767, loss_fp: 0.500002, loss_freq: 0.500011
[02:21:00.600] iteration 2497: loss: 0.579684, loss_s1: 0.500220, loss_fp: 0.072995, loss_freq: 0.093438
[02:21:01.302] iteration 2498: loss: 0.934821, loss_s1: 0.500019, loss_fp: 0.500000, loss_freq: 0.499999
[02:21:01.999] iteration 2499: loss: 0.925755, loss_s1: 0.500012, loss_fp: 0.500002, loss_freq: 0.500006
[02:21:02.715] iteration 2500: loss: 0.930605, loss_s1: 0.500007, loss_fp: 0.500007, loss_freq: 0.500002
[02:21:03.414] iteration 2501: loss: 0.349613, loss_s1: 0.333374, loss_fp: 0.002297, loss_freq: 0.001010
[02:21:04.114] iteration 2502: loss: 0.168638, loss_s1: 0.002197, loss_fp: 0.000942, loss_freq: 0.001759
[02:21:04.793] iteration 2503: loss: 0.910568, loss_s1: 0.500099, loss_fp: 0.499992, loss_freq: 0.500005
[02:21:05.477] iteration 2504: loss: 0.881430, loss_s1: 0.500017, loss_fp: 0.499997, loss_freq: 0.499999
[02:21:06.172] iteration 2505: loss: 0.459644, loss_s1: 0.500684, loss_fp: 0.013833, loss_freq: 0.031982
[02:21:06.867] iteration 2506: loss: 0.965319, loss_s1: 0.499966, loss_fp: 0.499996, loss_freq: 0.499934
[02:21:07.524] iteration 2507: loss: 0.967374, loss_s1: 0.500836, loss_fp: 0.499985, loss_freq: 0.501168
[02:21:08.216] iteration 2508: loss: 0.992806, loss_s1: 0.500622, loss_fp: 0.499985, loss_freq: 0.500510
[02:21:08.894] iteration 2509: loss: 0.351289, loss_s1: 0.429875, loss_fp: 0.000650, loss_freq: 0.002562
[02:21:09.535] iteration 2510: loss: 0.912337, loss_s1: 0.501035, loss_fp: 0.500005, loss_freq: 0.501697
[02:21:10.231] iteration 2511: loss: 0.244429, loss_s1: 0.146715, loss_fp: 0.000451, loss_freq: 0.002989
[02:21:10.903] iteration 2512: loss: 0.395639, loss_s1: 0.495809, loss_fp: 0.001576, loss_freq: 0.003156
[02:21:11.548] iteration 2513: loss: 0.176355, loss_s1: 0.099281, loss_fp: 0.003049, loss_freq: 0.011451
[02:21:12.305] iteration 2514: loss: 0.260242, loss_s1: 0.179634, loss_fp: 0.001007, loss_freq: 0.050941
[02:21:12.985] iteration 2515: loss: 0.639981, loss_s1: 0.503040, loss_fp: 0.089707, loss_freq: 0.316030
[02:21:13.643] iteration 2516: loss: 0.974061, loss_s1: 0.501243, loss_fp: 0.500014, loss_freq: 0.501333
[02:21:14.320] iteration 2517: loss: 0.928949, loss_s1: 0.446343, loss_fp: 0.003994, loss_freq: 0.267887
[02:21:14.988] iteration 2518: loss: 1.103242, loss_s1: 0.501425, loss_fp: 0.500156, loss_freq: 0.500307
[02:21:15.743] iteration 2519: loss: 1.085873, loss_s1: 0.502726, loss_fp: 0.500005, loss_freq: 0.500062
[02:21:16.438] iteration 2520: loss: 1.077348, loss_s1: 0.501214, loss_fp: 0.500003, loss_freq: 0.500070
[02:21:17.134] iteration 2521: loss: 1.074308, loss_s1: 0.500295, loss_fp: 0.500002, loss_freq: 0.499997
[02:21:17.843] iteration 2522: loss: 1.050790, loss_s1: 0.500225, loss_fp: 0.499992, loss_freq: 0.500462
[02:21:18.536] iteration 2523: loss: 1.166790, loss_s1: 0.500372, loss_fp: 0.499978, loss_freq: 0.499999
[02:21:19.229] iteration 2524: loss: 1.040869, loss_s1: 0.500073, loss_fp: 0.500004, loss_freq: 0.500011
[02:21:19.928] iteration 2525: loss: 1.000046, loss_s1: 0.500035, loss_fp: 0.499988, loss_freq: 0.500024
[02:21:20.612] iteration 2526: loss: 1.085105, loss_s1: 0.500020, loss_fp: 0.499998, loss_freq: 0.500037
[02:21:21.282] iteration 2527: loss: 1.042910, loss_s1: 0.500005, loss_fp: 0.499989, loss_freq: 0.500002
[02:21:21.962] iteration 2528: loss: 1.052323, loss_s1: 0.500067, loss_fp: 0.500006, loss_freq: 0.500001
[02:21:22.634] iteration 2529: loss: 1.020905, loss_s1: 0.500042, loss_fp: 0.500000, loss_freq: 0.500032
[02:21:23.317] iteration 2530: loss: 1.012395, loss_s1: 0.500021, loss_fp: 0.499985, loss_freq: 0.500016
[02:21:24.011] iteration 2531: loss: 1.045705, loss_s1: 0.500022, loss_fp: 0.500001, loss_freq: 0.500008
[02:21:24.705] iteration 2532: loss: 1.051994, loss_s1: 0.500034, loss_fp: 0.500004, loss_freq: 0.500012
[02:21:25.413] iteration 2533: loss: 1.034068, loss_s1: 0.500031, loss_fp: 0.500002, loss_freq: 0.500039
[02:21:26.092] iteration 2534: loss: 0.996807, loss_s1: 0.500030, loss_fp: 0.500017, loss_freq: 0.500003
[02:21:26.747] iteration 2535: loss: 1.004171, loss_s1: 0.500049, loss_fp: 0.500000, loss_freq: 0.500010
[02:21:27.441] iteration 2536: loss: 1.020763, loss_s1: 0.500020, loss_fp: 0.500019, loss_freq: 0.500016
[02:21:28.400] iteration 2537: loss: 0.997228, loss_s1: 0.500024, loss_fp: 0.500016, loss_freq: 0.500023
[02:21:29.090] iteration 2538: loss: 0.994182, loss_s1: 0.500066, loss_fp: 0.500007, loss_freq: 0.500004
[02:21:29.786] iteration 2539: loss: 0.992626, loss_s1: 0.500033, loss_fp: 0.500031, loss_freq: 0.500088
[02:21:30.459] iteration 2540: loss: 1.008047, loss_s1: 0.500013, loss_fp: 0.500000, loss_freq: 0.500004
[02:21:31.146] iteration 2541: loss: 0.994607, loss_s1: 0.500180, loss_fp: 0.500006, loss_freq: 0.500021
[02:21:31.861] iteration 2542: loss: 0.994376, loss_s1: 0.500011, loss_fp: 0.500003, loss_freq: 0.500001
[02:21:32.517] iteration 2543: loss: 0.979996, loss_s1: 0.500069, loss_fp: 0.500006, loss_freq: 0.500023
[02:21:33.169] iteration 2544: loss: 1.007290, loss_s1: 0.500253, loss_fp: 0.500115, loss_freq: 0.500025
[02:21:33.817] iteration 2545: loss: 1.004295, loss_s1: 0.500134, loss_fp: 0.500086, loss_freq: 0.500021
[02:21:34.461] iteration 2546: loss: 0.963642, loss_s1: 0.500292, loss_fp: 0.500017, loss_freq: 0.500031
[02:21:35.112] iteration 2547: loss: 0.973676, loss_s1: 0.500606, loss_fp: 0.500005, loss_freq: 0.500197
[02:21:35.811] iteration 2548: loss: 0.980326, loss_s1: 0.500283, loss_fp: 0.500084, loss_freq: 0.500012
[02:21:36.450] iteration 2549: loss: 1.009268, loss_s1: 0.500277, loss_fp: 0.500014, loss_freq: 0.500007
[02:21:37.099] iteration 2550: loss: 1.037423, loss_s1: 0.500709, loss_fp: 0.500018, loss_freq: 0.500041
[02:21:38.095] iteration 2551: loss: 0.959133, loss_s1: 0.500950, loss_fp: 0.500001, loss_freq: 0.500025
[02:21:38.765] iteration 2552: loss: 0.971201, loss_s1: 0.501688, loss_fp: 0.500303, loss_freq: 0.500068
[02:21:39.447] iteration 2553: loss: 1.011509, loss_s1: 0.500496, loss_fp: 0.500009, loss_freq: 0.500024
[02:21:40.138] iteration 2554: loss: 1.006683, loss_s1: 0.500574, loss_fp: 0.500002, loss_freq: 0.500020
[02:21:40.825] iteration 2555: loss: 0.978180, loss_s1: 0.500158, loss_fp: 0.500003, loss_freq: 0.500002
[02:21:41.489] iteration 2556: loss: 0.983447, loss_s1: 0.500924, loss_fp: 0.500011, loss_freq: 0.500005
[02:21:42.208] iteration 2557: loss: 1.007118, loss_s1: 0.502471, loss_fp: 0.500009, loss_freq: 0.500028
[02:21:42.905] iteration 2558: loss: 1.019699, loss_s1: 0.500715, loss_fp: 0.500049, loss_freq: 0.500005
[02:21:43.573] iteration 2559: loss: 0.966009, loss_s1: 0.500320, loss_fp: 0.500001, loss_freq: 0.500014
[02:21:44.261] iteration 2560: loss: 1.004313, loss_s1: 0.501739, loss_fp: 0.500069, loss_freq: 0.500023
[02:21:44.902] iteration 2561: loss: 0.974423, loss_s1: 0.500458, loss_fp: 0.500012, loss_freq: 0.500080
[02:21:45.593] iteration 2562: loss: 0.962150, loss_s1: 0.500441, loss_fp: 0.500036, loss_freq: 0.500036
[02:21:46.231] iteration 2563: loss: 0.954641, loss_s1: 0.500174, loss_fp: 0.500016, loss_freq: 0.500080
[02:21:46.895] iteration 2564: loss: 0.929710, loss_s1: 0.501074, loss_fp: 0.500004, loss_freq: 0.500002
[02:21:47.528] iteration 2565: loss: 0.995016, loss_s1: 0.500200, loss_fp: 0.500017, loss_freq: 0.500012
[02:21:48.218] iteration 2566: loss: 0.938198, loss_s1: 0.500502, loss_fp: 0.500007, loss_freq: 0.500000
[02:21:48.845] iteration 2567: loss: 0.947496, loss_s1: 0.500558, loss_fp: 0.500019, loss_freq: 0.500000
[02:21:49.537] iteration 2568: loss: 0.941849, loss_s1: 0.500368, loss_fp: 0.500002, loss_freq: 0.500002
[02:21:50.185] iteration 2569: loss: 0.926895, loss_s1: 0.500470, loss_fp: 0.500023, loss_freq: 0.500005
[02:21:50.862] iteration 2570: loss: 0.929064, loss_s1: 0.500101, loss_fp: 0.500018, loss_freq: 0.500011
[02:21:51.508] iteration 2571: loss: 0.944630, loss_s1: 0.500160, loss_fp: 0.500010, loss_freq: 0.500021
[02:21:52.218] iteration 2572: loss: 0.995889, loss_s1: 0.500435, loss_fp: 0.500018, loss_freq: 0.500085
[02:21:52.861] iteration 2573: loss: 0.993428, loss_s1: 0.500244, loss_fp: 0.500026, loss_freq: 0.500155
[02:21:53.567] iteration 2574: loss: 0.970939, loss_s1: 0.500204, loss_fp: 0.500450, loss_freq: 0.500067
[02:21:54.222] iteration 2575: loss: 0.933654, loss_s1: 0.502088, loss_fp: 0.500558, loss_freq: 0.500007
[02:21:54.915] iteration 2576: loss: 0.910406, loss_s1: 0.500350, loss_fp: 0.500026, loss_freq: 0.500038
[02:21:55.607] iteration 2577: loss: 0.935400, loss_s1: 0.500301, loss_fp: 0.500015, loss_freq: 0.500003
[02:21:56.290] iteration 2578: loss: 0.961532, loss_s1: 0.501986, loss_fp: 0.500008, loss_freq: 0.500038
[02:21:56.967] iteration 2579: loss: 1.025953, loss_s1: 0.500854, loss_fp: 0.500005, loss_freq: 0.500043
[02:21:57.660] iteration 2580: loss: 0.935353, loss_s1: 0.500506, loss_fp: 0.500015, loss_freq: 0.500229
[02:21:58.314] iteration 2581: loss: 0.937158, loss_s1: 0.501218, loss_fp: 0.500027, loss_freq: 0.500013
[02:21:58.998] iteration 2582: loss: 0.978433, loss_s1: 0.500697, loss_fp: 0.500018, loss_freq: 0.500140
[02:21:59.710] iteration 2583: loss: 0.924539, loss_s1: 0.500695, loss_fp: 0.500007, loss_freq: 0.500028
[02:22:00.356] iteration 2584: loss: 0.953878, loss_s1: 0.500118, loss_fp: 0.500008, loss_freq: 0.500025
[02:22:01.056] iteration 2585: loss: 0.945007, loss_s1: 0.501231, loss_fp: 0.500130, loss_freq: 0.500010
[02:22:01.762] iteration 2586: loss: 0.915331, loss_s1: 0.500070, loss_fp: 0.500011, loss_freq: 0.500001
[02:22:02.474] iteration 2587: loss: 0.925203, loss_s1: 0.500624, loss_fp: 0.500031, loss_freq: 0.500020
[02:22:03.164] iteration 2588: loss: 0.979710, loss_s1: 0.500014, loss_fp: 0.500015, loss_freq: 0.500009
[02:22:03.886] iteration 2589: loss: 0.928471, loss_s1: 0.500281, loss_fp: 0.500059, loss_freq: 0.500019
[02:22:04.643] iteration 2590: loss: 0.947330, loss_s1: 0.501405, loss_fp: 0.500009, loss_freq: 0.500023
[02:22:05.363] iteration 2591: loss: 0.930389, loss_s1: 0.501205, loss_fp: 0.500024, loss_freq: 0.500103
[02:22:06.072] iteration 2592: loss: 0.938237, loss_s1: 0.500195, loss_fp: 0.500052, loss_freq: 0.500085
[02:22:06.765] iteration 2593: loss: 0.949869, loss_s1: 0.500093, loss_fp: 0.500014, loss_freq: 0.500002
[02:22:07.482] iteration 2594: loss: 0.918966, loss_s1: 0.500496, loss_fp: 0.500002, loss_freq: 0.500047
[02:22:08.196] iteration 2595: loss: 0.931451, loss_s1: 0.500388, loss_fp: 0.500040, loss_freq: 0.500007
[02:22:08.892] iteration 2596: loss: 0.886237, loss_s1: 0.500415, loss_fp: 0.500022, loss_freq: 0.500047
[02:22:09.600] iteration 2597: loss: 0.958154, loss_s1: 0.500697, loss_fp: 0.500020, loss_freq: 0.500010
[02:22:10.348] iteration 2598: loss: 0.920921, loss_s1: 0.500747, loss_fp: 0.500012, loss_freq: 0.500126
[02:22:11.062] iteration 2599: loss: 0.931363, loss_s1: 0.500124, loss_fp: 0.500020, loss_freq: 0.500008
[02:22:11.729] iteration 2600: loss: 1.012024, loss_s1: 0.500532, loss_fp: 0.500690, loss_freq: 0.500206
[02:22:13.938] iteration 2600 : mean_dice : 0.042033
[02:22:14.593] iteration 2601: loss: 0.946741, loss_s1: 0.500658, loss_fp: 0.500002, loss_freq: 0.500007
[02:22:15.265] iteration 2602: loss: 0.929675, loss_s1: 0.501297, loss_fp: 0.500006, loss_freq: 0.500008
[02:22:15.920] iteration 2603: loss: 0.940046, loss_s1: 0.501868, loss_fp: 0.500021, loss_freq: 0.500391
[02:22:16.592] iteration 2604: loss: 0.932994, loss_s1: 0.500890, loss_fp: 0.500013, loss_freq: 0.501026
[02:22:17.261] iteration 2605: loss: 0.942168, loss_s1: 0.500777, loss_fp: 0.500012, loss_freq: 0.500110
[02:22:17.896] iteration 2606: loss: 0.902444, loss_s1: 0.500859, loss_fp: 0.500011, loss_freq: 0.500018
[02:22:18.562] iteration 2607: loss: 0.912621, loss_s1: 0.501130, loss_fp: 0.500005, loss_freq: 0.500104
[02:22:19.201] iteration 2608: loss: 0.944102, loss_s1: 0.500391, loss_fp: 0.500040, loss_freq: 0.500159
[02:22:19.837] iteration 2609: loss: 0.960580, loss_s1: 0.500471, loss_fp: 0.500012, loss_freq: 0.500007
[02:22:20.507] iteration 2610: loss: 0.953479, loss_s1: 0.502410, loss_fp: 0.500003, loss_freq: 0.500021
[02:22:21.150] iteration 2611: loss: 0.930289, loss_s1: 0.501080, loss_fp: 0.500009, loss_freq: 0.500047
[02:22:21.829] iteration 2612: loss: 0.973817, loss_s1: 0.501062, loss_fp: 0.500009, loss_freq: 0.500291
[02:22:22.485] iteration 2613: loss: 0.936883, loss_s1: 0.501464, loss_fp: 0.501812, loss_freq: 0.500024
[02:22:23.164] iteration 2614: loss: 0.606031, loss_s1: 0.496777, loss_fp: 0.113676, loss_freq: 0.225345
[02:22:23.796] iteration 2615: loss: 0.936974, loss_s1: 0.500075, loss_fp: 0.500019, loss_freq: 0.499998
[02:22:24.466] iteration 2616: loss: 1.005271, loss_s1: 0.500026, loss_fp: 0.500007, loss_freq: 0.500001
[02:22:25.141] iteration 2617: loss: 1.059373, loss_s1: 0.500001, loss_fp: 0.500012, loss_freq: 0.499999
[02:22:25.804] iteration 2618: loss: 0.983223, loss_s1: 0.500019, loss_fp: 0.500015, loss_freq: 0.500001
[02:22:26.490] iteration 2619: loss: 1.024650, loss_s1: 0.500007, loss_fp: 0.500001, loss_freq: 0.499997
[02:22:27.164] iteration 2620: loss: 1.103902, loss_s1: 0.500004, loss_fp: 0.500000, loss_freq: 0.499995
[02:22:27.821] iteration 2621: loss: 1.035692, loss_s1: 0.500037, loss_fp: 0.500016, loss_freq: 0.500000
[02:22:28.526] iteration 2622: loss: 1.041302, loss_s1: 0.500002, loss_fp: 0.500004, loss_freq: 0.499994
[02:22:29.191] iteration 2623: loss: 0.999426, loss_s1: 0.500002, loss_fp: 0.500088, loss_freq: 0.499995
[02:22:29.863] iteration 2624: loss: 1.076842, loss_s1: 0.499998, loss_fp: 0.500009, loss_freq: 0.500000
[02:22:30.527] iteration 2625: loss: 1.038285, loss_s1: 0.500001, loss_fp: 0.500039, loss_freq: 0.499999
[02:22:31.224] iteration 2626: loss: 1.059740, loss_s1: 0.500000, loss_fp: 0.500201, loss_freq: 0.500000
[02:22:31.894] iteration 2627: loss: 1.038138, loss_s1: 0.500002, loss_fp: 0.500016, loss_freq: 0.499998
[02:22:32.572] iteration 2628: loss: 1.016056, loss_s1: 0.500005, loss_fp: 0.500048, loss_freq: 0.500008
[02:22:33.246] iteration 2629: loss: 0.980573, loss_s1: 0.500001, loss_fp: 0.500018, loss_freq: 0.500000
[02:22:33.965] iteration 2630: loss: 1.011887, loss_s1: 0.500005, loss_fp: 0.500032, loss_freq: 0.500005
[02:22:34.652] iteration 2631: loss: 1.034176, loss_s1: 0.500007, loss_fp: 0.500006, loss_freq: 0.500003
[02:22:35.361] iteration 2632: loss: 0.999153, loss_s1: 0.500007, loss_fp: 0.500081, loss_freq: 0.500003
[02:22:36.063] iteration 2633: loss: 1.004441, loss_s1: 0.500006, loss_fp: 0.500004, loss_freq: 0.500010
[02:22:36.710] iteration 2634: loss: 0.958901, loss_s1: 0.500004, loss_fp: 0.500004, loss_freq: 0.500002
[02:22:37.387] iteration 2635: loss: 0.984872, loss_s1: 0.500001, loss_fp: 0.500014, loss_freq: 0.500000
[02:22:38.050] iteration 2636: loss: 0.969799, loss_s1: 0.500006, loss_fp: 0.500027, loss_freq: 0.500002
[02:22:38.730] iteration 2637: loss: 0.943539, loss_s1: 0.499999, loss_fp: 0.500006, loss_freq: 0.499993
[02:22:39.410] iteration 2638: loss: 0.987126, loss_s1: 0.500038, loss_fp: 0.500026, loss_freq: 0.500000
[02:22:40.096] iteration 2639: loss: 0.942858, loss_s1: 0.500000, loss_fp: 0.500005, loss_freq: 0.499996
[02:22:40.729] iteration 2640: loss: 0.979469, loss_s1: 0.500047, loss_fp: 0.500023, loss_freq: 0.500000
[02:22:41.490] iteration 2641: loss: 0.953332, loss_s1: 0.500014, loss_fp: 0.500105, loss_freq: 0.499998
[02:22:42.204] iteration 2642: loss: 0.918660, loss_s1: 0.500007, loss_fp: 0.500027, loss_freq: 0.500001
[02:22:42.858] iteration 2643: loss: 1.022116, loss_s1: 0.500004, loss_fp: 0.500046, loss_freq: 0.500001
[02:22:43.547] iteration 2644: loss: 0.982044, loss_s1: 0.500011, loss_fp: 0.500017, loss_freq: 0.500007
[02:22:44.227] iteration 2645: loss: 0.958327, loss_s1: 0.500005, loss_fp: 0.500030, loss_freq: 0.499995
[02:22:44.925] iteration 2646: loss: 0.942957, loss_s1: 0.500005, loss_fp: 0.500009, loss_freq: 0.500001
[02:22:45.585] iteration 2647: loss: 0.931979, loss_s1: 0.500031, loss_fp: 0.500064, loss_freq: 0.499998
[02:22:46.294] iteration 2648: loss: 0.918659, loss_s1: 0.500015, loss_fp: 0.500020, loss_freq: 0.500002
[02:22:47.006] iteration 2649: loss: 0.992512, loss_s1: 0.500114, loss_fp: 0.500012, loss_freq: 0.499999
[02:22:47.703] iteration 2650: loss: 0.954766, loss_s1: 0.500764, loss_fp: 0.500014, loss_freq: 0.499996
[02:22:48.428] iteration 2651: loss: 0.898206, loss_s1: 0.500413, loss_fp: 0.500028, loss_freq: 0.500007
[02:22:49.135] iteration 2652: loss: 1.006341, loss_s1: 0.500071, loss_fp: 0.500017, loss_freq: 0.499999
[02:22:49.850] iteration 2653: loss: 0.956145, loss_s1: 0.500493, loss_fp: 0.500021, loss_freq: 0.499992
[02:22:50.530] iteration 2654: loss: 0.963019, loss_s1: 0.500143, loss_fp: 0.500113, loss_freq: 0.500007
[02:22:51.209] iteration 2655: loss: 0.925250, loss_s1: 0.500045, loss_fp: 0.500009, loss_freq: 0.500045
[02:22:51.921] iteration 2656: loss: 0.907727, loss_s1: 0.500593, loss_fp: 0.500009, loss_freq: 0.500004
[02:22:52.590] iteration 2657: loss: 0.906848, loss_s1: 0.500139, loss_fp: 0.500063, loss_freq: 0.499992
[02:22:53.264] iteration 2658: loss: 0.983506, loss_s1: 0.500299, loss_fp: 0.500147, loss_freq: 0.499995
[02:22:54.010] iteration 2659: loss: 0.984100, loss_s1: 0.500166, loss_fp: 0.500107, loss_freq: 0.500210
[02:22:54.721] iteration 2660: loss: 0.919991, loss_s1: 0.500312, loss_fp: 0.500035, loss_freq: 0.500011
[02:22:55.423] iteration 2661: loss: 0.967229, loss_s1: 0.500032, loss_fp: 0.500008, loss_freq: 0.500008
[02:22:56.097] iteration 2662: loss: 0.951536, loss_s1: 0.500523, loss_fp: 0.500051, loss_freq: 0.500086
[02:22:56.769] iteration 2663: loss: 0.938724, loss_s1: 0.500024, loss_fp: 0.500011, loss_freq: 0.499986
[02:22:57.440] iteration 2664: loss: 0.939701, loss_s1: 0.500227, loss_fp: 0.500025, loss_freq: 0.500141
[02:22:58.137] iteration 2665: loss: 0.931058, loss_s1: 0.500466, loss_fp: 0.500025, loss_freq: 0.500099
[02:22:58.765] iteration 2666: loss: 0.891119, loss_s1: 0.500308, loss_fp: 0.500044, loss_freq: 0.500009
[02:22:59.437] iteration 2667: loss: 0.927739, loss_s1: 0.500022, loss_fp: 0.500054, loss_freq: 0.500000
[02:23:00.141] iteration 2668: loss: 0.914138, loss_s1: 0.500524, loss_fp: 0.500004, loss_freq: 0.500001
[02:23:00.807] iteration 2669: loss: 0.928097, loss_s1: 0.500645, loss_fp: 0.500065, loss_freq: 0.500110
[02:23:01.510] iteration 2670: loss: 0.928621, loss_s1: 0.500152, loss_fp: 0.500025, loss_freq: 0.500086
[02:23:02.244] iteration 2671: loss: 0.899400, loss_s1: 0.500664, loss_fp: 0.500068, loss_freq: 0.499998
[02:23:02.967] iteration 2672: loss: 0.942881, loss_s1: 0.500004, loss_fp: 0.500018, loss_freq: 0.499999
[02:23:03.808] iteration 2673: loss: 0.929659, loss_s1: 0.500510, loss_fp: 0.500033, loss_freq: 0.500042
[02:23:04.629] iteration 2674: loss: 0.911876, loss_s1: 0.500115, loss_fp: 0.500062, loss_freq: 0.500039
[02:23:05.262] iteration 2675: loss: 0.913474, loss_s1: 0.500016, loss_fp: 0.500046, loss_freq: 0.499989
[02:23:05.872] iteration 2676: loss: 0.913702, loss_s1: 0.500088, loss_fp: 0.500027, loss_freq: 0.500010
[02:23:06.517] iteration 2677: loss: 0.864873, loss_s1: 0.500173, loss_fp: 0.500014, loss_freq: 0.500221
[02:23:07.217] iteration 2678: loss: 0.960944, loss_s1: 0.500523, loss_fp: 0.500018, loss_freq: 0.500585
[02:23:07.914] iteration 2679: loss: 0.884922, loss_s1: 0.500710, loss_fp: 0.500035, loss_freq: 0.500001
[02:23:08.587] iteration 2680: loss: 0.915671, loss_s1: 0.500506, loss_fp: 0.500014, loss_freq: 0.500049
[02:23:09.327] iteration 2681: loss: 0.958517, loss_s1: 0.500897, loss_fp: 0.500019, loss_freq: 0.500004
[02:23:10.034] iteration 2682: loss: 0.905014, loss_s1: 0.500383, loss_fp: 0.500086, loss_freq: 0.499997
[02:23:10.682] iteration 2683: loss: 0.916084, loss_s1: 0.500124, loss_fp: 0.500039, loss_freq: 0.500008
[02:23:11.333] iteration 2684: loss: 0.952501, loss_s1: 0.500335, loss_fp: 0.500052, loss_freq: 0.499999
[02:23:12.060] iteration 2685: loss: 0.919573, loss_s1: 0.501093, loss_fp: 0.500023, loss_freq: 0.499991
[02:23:12.724] iteration 2686: loss: 0.873516, loss_s1: 0.500111, loss_fp: 0.500046, loss_freq: 0.500007
[02:23:13.401] iteration 2687: loss: 0.978085, loss_s1: 0.500398, loss_fp: 0.500013, loss_freq: 0.500002
[02:23:14.040] iteration 2688: loss: 0.904574, loss_s1: 0.500005, loss_fp: 0.500008, loss_freq: 0.500004
[02:23:14.734] iteration 2689: loss: 0.885055, loss_s1: 0.500261, loss_fp: 0.500000, loss_freq: 0.499992
[02:23:15.422] iteration 2690: loss: 0.943657, loss_s1: 0.501475, loss_fp: 0.500013, loss_freq: 0.500034
[02:23:16.177] iteration 2691: loss: 0.915496, loss_s1: 0.501136, loss_fp: 0.500039, loss_freq: 0.500003
[02:23:16.890] iteration 2692: loss: 0.890059, loss_s1: 0.500237, loss_fp: 0.500033, loss_freq: 0.500026
[02:23:17.641] iteration 2693: loss: 0.876170, loss_s1: 0.500615, loss_fp: 0.500044, loss_freq: 0.500249
[02:23:18.280] iteration 2694: loss: 0.908319, loss_s1: 0.500161, loss_fp: 0.500006, loss_freq: 0.500001
[02:23:18.897] iteration 2695: loss: 0.879485, loss_s1: 0.500161, loss_fp: 0.500011, loss_freq: 0.500043
[02:23:19.512] iteration 2696: loss: 0.958846, loss_s1: 0.501212, loss_fp: 0.500045, loss_freq: 0.500006
[02:23:20.136] iteration 2697: loss: 0.894112, loss_s1: 0.500392, loss_fp: 0.500007, loss_freq: 0.499999
[02:23:20.762] iteration 2698: loss: 0.895861, loss_s1: 0.501325, loss_fp: 0.500006, loss_freq: 0.500008
[02:23:21.384] iteration 2699: loss: 0.896903, loss_s1: 0.501139, loss_fp: 0.500016, loss_freq: 0.500030
[02:23:22.003] iteration 2700: loss: 0.902140, loss_s1: 0.501232, loss_fp: 0.500027, loss_freq: 0.500096
[02:23:22.623] iteration 2701: loss: 0.901023, loss_s1: 0.500335, loss_fp: 0.500012, loss_freq: 0.500005
[02:23:23.237] iteration 2702: loss: 0.909836, loss_s1: 0.500432, loss_fp: 0.500011, loss_freq: 0.500119
[02:23:23.859] iteration 2703: loss: 0.877937, loss_s1: 0.501286, loss_fp: 0.500016, loss_freq: 0.500226
[02:23:24.477] iteration 2704: loss: 0.910687, loss_s1: 0.500764, loss_fp: 0.500022, loss_freq: 0.500010
[02:23:25.092] iteration 2705: loss: 0.933519, loss_s1: 0.500426, loss_fp: 0.500005, loss_freq: 0.500003
[02:23:25.714] iteration 2706: loss: 0.883259, loss_s1: 0.500494, loss_fp: 0.500017, loss_freq: 0.500147
[02:23:26.329] iteration 2707: loss: 0.876830, loss_s1: 0.500220, loss_fp: 0.500015, loss_freq: 0.500113
[02:23:26.946] iteration 2708: loss: 0.893468, loss_s1: 0.501061, loss_fp: 0.500058, loss_freq: 0.500137
[02:23:27.560] iteration 2709: loss: 0.927852, loss_s1: 0.500370, loss_fp: 0.500010, loss_freq: 0.500002
[02:23:28.169] iteration 2710: loss: 0.879479, loss_s1: 0.500543, loss_fp: 0.500100, loss_freq: 0.500002
[02:23:28.788] iteration 2711: loss: 0.882994, loss_s1: 0.500339, loss_fp: 0.500018, loss_freq: 0.500004
[02:23:29.398] iteration 2712: loss: 0.893455, loss_s1: 0.500123, loss_fp: 0.500002, loss_freq: 0.500047
[02:23:30.020] iteration 2713: loss: 0.969386, loss_s1: 0.500936, loss_fp: 0.500009, loss_freq: 0.500075
[02:23:30.646] iteration 2714: loss: 0.881041, loss_s1: 0.500170, loss_fp: 0.500016, loss_freq: 0.500047
[02:23:31.262] iteration 2715: loss: 0.873014, loss_s1: 0.500135, loss_fp: 0.500061, loss_freq: 0.500004
[02:23:32.081] iteration 2716: loss: 0.896035, loss_s1: 0.500020, loss_fp: 0.500004, loss_freq: 0.500001
[02:23:32.991] iteration 2717: loss: 0.889162, loss_s1: 0.500397, loss_fp: 0.500005, loss_freq: 0.500112
[02:23:33.841] iteration 2718: loss: 0.866649, loss_s1: 0.500086, loss_fp: 0.500031, loss_freq: 0.499998
[02:23:34.603] iteration 2719: loss: 0.950375, loss_s1: 0.501474, loss_fp: 0.500031, loss_freq: 0.500005
[02:23:35.346] iteration 2720: loss: 0.913529, loss_s1: 0.501544, loss_fp: 0.500013, loss_freq: 0.500064
[02:23:36.655] iteration 2721: loss: 0.870095, loss_s1: 0.500385, loss_fp: 0.500326, loss_freq: 0.499999
[02:23:37.293] iteration 2722: loss: 0.891116, loss_s1: 0.500495, loss_fp: 0.500011, loss_freq: 0.500010
[02:23:37.951] iteration 2723: loss: 0.874542, loss_s1: 0.500177, loss_fp: 0.500007, loss_freq: 0.499999
[02:23:38.621] iteration 2724: loss: 0.866311, loss_s1: 0.500079, loss_fp: 0.500009, loss_freq: 0.500053
[02:23:39.254] iteration 2725: loss: 0.885656, loss_s1: 0.500225, loss_fp: 0.500027, loss_freq: 0.500002
[02:23:39.879] iteration 2726: loss: 0.940280, loss_s1: 0.500680, loss_fp: 0.500013, loss_freq: 0.500104
[02:23:40.510] iteration 2727: loss: 0.879423, loss_s1: 0.500529, loss_fp: 0.500005, loss_freq: 0.500022
[02:23:41.143] iteration 2728: loss: 0.900926, loss_s1: 0.502697, loss_fp: 0.500009, loss_freq: 0.500028
[02:23:41.778] iteration 2729: loss: 0.884903, loss_s1: 0.500173, loss_fp: 0.500015, loss_freq: 0.500136
[02:23:42.407] iteration 2730: loss: 0.874580, loss_s1: 0.500428, loss_fp: 0.500018, loss_freq: 0.499997
[02:23:43.045] iteration 2731: loss: 0.860214, loss_s1: 0.500823, loss_fp: 0.500006, loss_freq: 0.500040
[02:23:43.687] iteration 2732: loss: 0.839888, loss_s1: 0.500707, loss_fp: 0.500005, loss_freq: 0.500192
[02:23:44.363] iteration 2733: loss: 0.871936, loss_s1: 0.501321, loss_fp: 0.500006, loss_freq: 0.500702
[02:23:45.004] iteration 2734: loss: 0.901539, loss_s1: 0.500032, loss_fp: 0.500002, loss_freq: 0.500183
[02:23:45.653] iteration 2735: loss: 0.946100, loss_s1: 0.500856, loss_fp: 0.500004, loss_freq: 0.500008
[02:23:46.292] iteration 2736: loss: 0.903332, loss_s1: 0.500493, loss_fp: 0.500010, loss_freq: 0.500091
[02:23:46.933] iteration 2737: loss: 0.881866, loss_s1: 0.501114, loss_fp: 0.500399, loss_freq: 0.500055
[02:23:47.570] iteration 2738: loss: 0.923814, loss_s1: 0.500096, loss_fp: 0.500012, loss_freq: 0.500000
[02:23:48.229] iteration 2739: loss: 0.888414, loss_s1: 0.500527, loss_fp: 0.500015, loss_freq: 0.499981
[02:23:48.909] iteration 2740: loss: 0.889534, loss_s1: 0.500108, loss_fp: 0.500029, loss_freq: 0.500000
[02:23:49.590] iteration 2741: loss: 0.894409, loss_s1: 0.501059, loss_fp: 0.500010, loss_freq: 0.500254
[02:23:50.273] iteration 2742: loss: 0.912705, loss_s1: 0.500635, loss_fp: 0.500005, loss_freq: 0.500302
[02:23:50.938] iteration 2743: loss: 0.948425, loss_s1: 0.500279, loss_fp: 0.500005, loss_freq: 0.500025
[02:23:51.615] iteration 2744: loss: 0.857251, loss_s1: 0.501140, loss_fp: 0.500001, loss_freq: 0.500030
[02:23:52.313] iteration 2745: loss: 0.849373, loss_s1: 0.502749, loss_fp: 0.500018, loss_freq: 0.500000
[02:23:52.977] iteration 2746: loss: 0.904606, loss_s1: 0.500727, loss_fp: 0.500033, loss_freq: 0.500012
[02:23:53.661] iteration 2747: loss: 0.902484, loss_s1: 0.501526, loss_fp: 0.500006, loss_freq: 0.500035
[02:23:54.344] iteration 2748: loss: 0.863467, loss_s1: 0.502461, loss_fp: 0.500012, loss_freq: 0.500146
[02:23:55.012] iteration 2749: loss: 0.861656, loss_s1: 0.500292, loss_fp: 0.500010, loss_freq: 0.500179
[02:23:55.688] iteration 2750: loss: 0.867528, loss_s1: 0.500498, loss_fp: 0.500009, loss_freq: 0.500055
[02:23:56.347] iteration 2751: loss: 0.861281, loss_s1: 0.501954, loss_fp: 0.500003, loss_freq: 0.500458
[02:23:57.007] iteration 2752: loss: 0.921021, loss_s1: 0.500499, loss_fp: 0.500008, loss_freq: 0.500673
[02:23:57.658] iteration 2753: loss: 0.917502, loss_s1: 0.500872, loss_fp: 0.500074, loss_freq: 0.500240
[02:23:58.337] iteration 2754: loss: 0.912468, loss_s1: 0.501223, loss_fp: 0.500011, loss_freq: 0.500086
[02:23:59.041] iteration 2755: loss: 0.870517, loss_s1: 0.501096, loss_fp: 0.500005, loss_freq: 0.500217
[02:23:59.728] iteration 2756: loss: 0.885382, loss_s1: 0.500297, loss_fp: 0.500005, loss_freq: 0.499995
[02:24:00.406] iteration 2757: loss: 0.868779, loss_s1: 0.500021, loss_fp: 0.500038, loss_freq: 0.500042
[02:24:01.113] iteration 2758: loss: 0.877531, loss_s1: 0.501235, loss_fp: 0.500010, loss_freq: 0.500019
[02:24:01.797] iteration 2759: loss: 0.876145, loss_s1: 0.501193, loss_fp: 0.500018, loss_freq: 0.500117
[02:24:02.469] iteration 2760: loss: 0.899102, loss_s1: 0.501074, loss_fp: 0.500018, loss_freq: 0.500108
[02:24:03.157] iteration 2761: loss: 0.900547, loss_s1: 0.501339, loss_fp: 0.500012, loss_freq: 0.500222
[02:24:03.839] iteration 2762: loss: 0.912028, loss_s1: 0.501284, loss_fp: 0.500050, loss_freq: 0.500051
[02:24:04.528] iteration 2763: loss: 0.883190, loss_s1: 0.500200, loss_fp: 0.500042, loss_freq: 0.500001
[02:24:05.185] iteration 2764: loss: 0.861754, loss_s1: 0.500412, loss_fp: 0.500096, loss_freq: 0.500035
[02:24:05.847] iteration 2765: loss: 0.897472, loss_s1: 0.500601, loss_fp: 0.500018, loss_freq: 0.500011
[02:24:06.495] iteration 2766: loss: 0.862695, loss_s1: 0.500103, loss_fp: 0.500004, loss_freq: 0.500078
[02:24:07.156] iteration 2767: loss: 0.858758, loss_s1: 0.500689, loss_fp: 0.500003, loss_freq: 0.500004
[02:24:07.859] iteration 2768: loss: 0.886755, loss_s1: 0.500513, loss_fp: 0.500009, loss_freq: 0.500007
[02:24:08.511] iteration 2769: loss: 0.885023, loss_s1: 0.500681, loss_fp: 0.500516, loss_freq: 0.500018
[02:24:09.147] iteration 2770: loss: 0.918665, loss_s1: 0.501109, loss_fp: 0.500005, loss_freq: 0.500275
[02:24:09.798] iteration 2771: loss: 0.869412, loss_s1: 0.501572, loss_fp: 0.500001, loss_freq: 0.500915
[02:24:10.444] iteration 2772: loss: 0.896170, loss_s1: 0.500120, loss_fp: 0.500035, loss_freq: 0.500044
[02:24:11.121] iteration 2773: loss: 0.864741, loss_s1: 0.500846, loss_fp: 0.500005, loss_freq: 0.500587
[02:24:11.798] iteration 2774: loss: 0.891802, loss_s1: 0.500474, loss_fp: 0.500010, loss_freq: 0.501575
[02:24:12.481] iteration 2775: loss: 0.855643, loss_s1: 0.500317, loss_fp: 0.500002, loss_freq: 0.500218
[02:24:13.162] iteration 2776: loss: 0.909236, loss_s1: 0.500107, loss_fp: 0.500007, loss_freq: 0.500014
[02:24:13.848] iteration 2777: loss: 0.858697, loss_s1: 0.463394, loss_fp: 0.500063, loss_freq: 0.500007
[02:24:14.532] iteration 2778: loss: 0.925744, loss_s1: 0.501289, loss_fp: 0.500117, loss_freq: 0.500254
[02:24:15.209] iteration 2779: loss: 0.756748, loss_s1: 0.257825, loss_fp: 0.499999, loss_freq: 0.499999
[02:24:15.904] iteration 2780: loss: 0.871589, loss_s1: 0.500088, loss_fp: 0.500003, loss_freq: 0.500676
[02:24:16.628] iteration 2781: loss: 0.748680, loss_s1: 0.434745, loss_fp: 0.483366, loss_freq: 0.312801
[02:24:17.293] iteration 2782: loss: 0.904921, loss_s1: 0.500002, loss_fp: 0.500034, loss_freq: 0.499997
[02:24:17.997] iteration 2783: loss: 0.898726, loss_s1: 0.500000, loss_fp: 0.500004, loss_freq: 0.499992
[02:24:18.695] iteration 2784: loss: 0.927583, loss_s1: 0.500000, loss_fp: 0.500015, loss_freq: 0.499989
[02:24:19.381] iteration 2785: loss: 1.006095, loss_s1: 0.499999, loss_fp: 0.500000, loss_freq: 0.499992
[02:24:20.056] iteration 2786: loss: 0.944035, loss_s1: 0.500002, loss_fp: 0.500005, loss_freq: 0.499994
[02:24:20.738] iteration 2787: loss: 1.085741, loss_s1: 0.500005, loss_fp: 0.500004, loss_freq: 0.499995
[02:24:21.407] iteration 2788: loss: 0.920323, loss_s1: 0.500000, loss_fp: 0.500006, loss_freq: 0.499997
[02:24:22.078] iteration 2789: loss: 0.890952, loss_s1: 0.500012, loss_fp: 0.500017, loss_freq: 0.499997
[02:24:22.763] iteration 2790: loss: 0.944539, loss_s1: 0.500005, loss_fp: 0.500003, loss_freq: 0.499998
[02:24:23.424] iteration 2791: loss: 0.921437, loss_s1: 0.500008, loss_fp: 0.500012, loss_freq: 0.500002
[02:24:24.091] iteration 2792: loss: 0.876008, loss_s1: 0.500000, loss_fp: 0.500000, loss_freq: 0.499998
[02:24:24.780] iteration 2793: loss: 0.910082, loss_s1: 0.500009, loss_fp: 0.500492, loss_freq: 0.500001
[02:24:25.488] iteration 2794: loss: 0.926191, loss_s1: 0.500021, loss_fp: 0.500010, loss_freq: 0.500006
[02:24:26.203] iteration 2795: loss: 0.962101, loss_s1: 0.500041, loss_fp: 0.500009, loss_freq: 0.500005
[02:24:26.902] iteration 2796: loss: 0.904703, loss_s1: 0.500013, loss_fp: 0.500002, loss_freq: 0.500003
[02:24:27.576] iteration 2797: loss: 0.884780, loss_s1: 0.500017, loss_fp: 0.500038, loss_freq: 0.499999
[02:24:28.233] iteration 2798: loss: 0.985461, loss_s1: 0.500011, loss_fp: 0.500008, loss_freq: 0.500004
[02:24:28.889] iteration 2799: loss: 0.889914, loss_s1: 0.500020, loss_fp: 0.500003, loss_freq: 0.500007
[02:24:29.545] iteration 2800: loss: 0.894680, loss_s1: 0.500083, loss_fp: 0.500004, loss_freq: 0.500009
[02:24:31.882] iteration 2800 : mean_dice : 0.070041
[02:24:32.608] iteration 2801: loss: 0.880086, loss_s1: 0.500031, loss_fp: 0.500016, loss_freq: 0.500005
[02:24:33.266] iteration 2802: loss: 0.865160, loss_s1: 0.500038, loss_fp: 0.500010, loss_freq: 0.500008
[02:24:33.924] iteration 2803: loss: 0.905329, loss_s1: 0.500022, loss_fp: 0.500015, loss_freq: 0.500000
[02:24:34.582] iteration 2804: loss: 0.910335, loss_s1: 0.496878, loss_fp: 0.500008, loss_freq: 0.500002
[02:24:35.262] iteration 2805: loss: 0.967955, loss_s1: 0.500046, loss_fp: 0.500008, loss_freq: 0.500005
[02:24:35.924] iteration 2806: loss: 0.872473, loss_s1: 0.500256, loss_fp: 0.500023, loss_freq: 0.500002
[02:24:36.597] iteration 2807: loss: 0.872300, loss_s1: 0.500071, loss_fp: 0.500061, loss_freq: 0.499992
[02:24:37.273] iteration 2808: loss: 0.876260, loss_s1: 0.500082, loss_fp: 0.500126, loss_freq: 0.500002
[02:24:37.972] iteration 2809: loss: 0.870476, loss_s1: 0.500105, loss_fp: 0.500010, loss_freq: 0.500011
[02:24:38.665] iteration 2810: loss: 0.865424, loss_s1: 0.499869, loss_fp: 0.500021, loss_freq: 0.500000
[02:24:39.362] iteration 2811: loss: 0.869814, loss_s1: 0.500226, loss_fp: 0.500049, loss_freq: 0.500006
[02:24:40.040] iteration 2812: loss: 0.872394, loss_s1: 0.500334, loss_fp: 0.500010, loss_freq: 0.500051
[02:24:40.716] iteration 2813: loss: 0.931397, loss_s1: 0.500214, loss_fp: 0.500010, loss_freq: 0.500001
[02:24:41.427] iteration 2814: loss: 0.882177, loss_s1: 0.500052, loss_fp: 0.500009, loss_freq: 0.500019
[02:24:42.110] iteration 2815: loss: 0.870199, loss_s1: 0.500093, loss_fp: 0.500002, loss_freq: 0.499999
[02:24:42.806] iteration 2816: loss: 0.249337, loss_s1: 0.239366, loss_fp: 0.006229, loss_freq: 0.004871
[02:24:43.507] iteration 2817: loss: 0.419485, loss_s1: 0.359164, loss_fp: 0.061555, loss_freq: 0.086884
[02:24:44.191] iteration 2818: loss: 0.433399, loss_s1: 0.426187, loss_fp: 0.100933, loss_freq: 0.091949
[02:24:44.895] iteration 2819: loss: 0.282600, loss_s1: 0.188827, loss_fp: 0.002924, loss_freq: 0.002425
[02:24:45.576] iteration 2820: loss: 0.929479, loss_s1: 0.500837, loss_fp: 0.500053, loss_freq: 0.500001
[02:24:46.251] iteration 2821: loss: 0.848393, loss_s1: 0.500028, loss_fp: 0.500003, loss_freq: 0.500002
[02:24:46.921] iteration 2822: loss: 0.934917, loss_s1: 0.500098, loss_fp: 0.500032, loss_freq: 0.500009
[02:24:47.612] iteration 2823: loss: 0.539411, loss_s1: 0.500017, loss_fp: 0.254141, loss_freq: 0.008944
[02:24:48.310] iteration 2824: loss: 0.498990, loss_s1: 0.424138, loss_fp: 0.084819, loss_freq: 0.116005
[02:24:48.977] iteration 2825: loss: 0.940522, loss_s1: 0.500068, loss_fp: 0.500010, loss_freq: 0.500077
[02:24:49.644] iteration 2826: loss: 0.902455, loss_s1: 0.500479, loss_fp: 0.500034, loss_freq: 0.499994
[02:24:50.316] iteration 2827: loss: 0.910293, loss_s1: 0.500111, loss_fp: 0.500005, loss_freq: 0.499983
[02:24:51.010] iteration 2828: loss: 0.214755, loss_s1: 0.194001, loss_fp: 0.001297, loss_freq: 0.001131
[02:24:51.702] iteration 2829: loss: 0.676816, loss_s1: 0.501433, loss_fp: 0.032420, loss_freq: 0.468101
[02:24:52.463] iteration 2830: loss: 0.853463, loss_s1: 0.500161, loss_fp: 0.280555, loss_freq: 0.468927
[02:24:53.290] iteration 2831: loss: 0.994625, loss_s1: 0.500450, loss_fp: 0.499993, loss_freq: 0.500140
[02:24:54.082] iteration 2832: loss: 0.409986, loss_s1: 0.432573, loss_fp: 0.013440, loss_freq: 0.020947
[02:24:54.993] iteration 2833: loss: 0.349269, loss_s1: 0.178501, loss_fp: 0.000810, loss_freq: 0.019463
[02:24:56.237] iteration 2834: loss: 0.205609, loss_s1: 0.127891, loss_fp: 0.000569, loss_freq: 0.000985
[02:25:00.524] iteration 2835: loss: 1.026663, loss_s1: 0.500492, loss_fp: 0.500004, loss_freq: 0.500122
[02:25:21.360] iteration 2836: loss: 0.904926, loss_s1: 0.500309, loss_fp: 0.500004, loss_freq: 0.500001
[02:25:42.214] iteration 2837: loss: 0.314172, loss_s1: 0.176876, loss_fp: 0.047313, loss_freq: 0.003013
[02:26:03.102] iteration 2838: loss: 0.212161, loss_s1: 0.079047, loss_fp: 0.006116, loss_freq: 0.002646
[02:26:24.004] iteration 2839: loss: 0.195788, loss_s1: 0.062851, loss_fp: 0.001974, loss_freq: 0.016065
[02:26:44.870] iteration 2840: loss: 0.970730, loss_s1: 0.500099, loss_fp: 0.499996, loss_freq: 0.499994
[02:27:05.833] iteration 2841: loss: 0.401578, loss_s1: 0.256415, loss_fp: 0.001243, loss_freq: 0.036135
[02:27:26.707] iteration 2842: loss: 0.253650, loss_s1: 0.078224, loss_fp: 0.001966, loss_freq: 0.003907
[02:27:47.688] iteration 2843: loss: 0.958102, loss_s1: 0.502835, loss_fp: 0.500003, loss_freq: 0.501111
[02:28:08.551] iteration 2844: loss: 0.353938, loss_s1: 0.137669, loss_fp: 0.000875, loss_freq: 0.175246
[02:28:29.516] iteration 2845: loss: 0.276150, loss_s1: 0.172293, loss_fp: 0.000725, loss_freq: 0.004593
[02:28:52.823] Namespace(config='/home/wth/My_codes/SSL_MIS_Exps/Freq_adaptive_modulation/configs/kvasir.yaml', labeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/5%_labeled.txt', unlabeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/5%_unlabeled.txt', save_path='/home/wth/My_codes/SSL_MIS_Exps/models/KVASIR', seed=1337, deterministic=1, local_rank=0, port=None)
[02:28:56.500] iteration 1: loss: 0.748287, loss_s1: 0.074555, loss_fp: 0.144312, loss_freq: 0.056702
[02:28:57.194] iteration 2: loss: 0.932822, loss_s1: 0.360638, loss_fp: 0.020986, loss_freq: 0.343396
[02:28:57.823] iteration 3: loss: 1.269111, loss_s1: 0.510669, loss_fp: 0.502613, loss_freq: 0.508419
[02:28:58.457] iteration 4: loss: 1.221941, loss_s1: 0.505483, loss_fp: 0.500226, loss_freq: 0.504475
[02:28:59.077] iteration 5: loss: 1.165905, loss_s1: 0.506920, loss_fp: 0.501008, loss_freq: 0.506419
[02:28:59.706] iteration 6: loss: 1.165899, loss_s1: 0.504450, loss_fp: 0.503481, loss_freq: 0.504753
[02:29:00.326] iteration 7: loss: 1.126351, loss_s1: 0.500789, loss_fp: 0.501208, loss_freq: 0.503764
[02:29:00.906] iteration 8: loss: 1.080491, loss_s1: 0.500638, loss_fp: 0.500786, loss_freq: 0.502224
[02:29:01.489] iteration 9: loss: 1.071336, loss_s1: 0.500387, loss_fp: 0.501041, loss_freq: 0.501019
[02:29:02.075] iteration 10: loss: 1.085202, loss_s1: 0.500799, loss_fp: 0.502089, loss_freq: 0.500778
[02:29:02.664] iteration 11: loss: 1.081601, loss_s1: 0.500868, loss_fp: 0.500842, loss_freq: 0.501195
[02:29:03.255] iteration 12: loss: 1.138243, loss_s1: 0.500409, loss_fp: 0.500416, loss_freq: 0.500695
[02:29:03.844] iteration 13: loss: 1.091057, loss_s1: 0.501441, loss_fp: 0.500805, loss_freq: 0.501067
[02:29:04.429] iteration 14: loss: 1.069968, loss_s1: 0.500425, loss_fp: 0.500826, loss_freq: 0.500562
[02:29:05.016] iteration 15: loss: 1.089633, loss_s1: 0.500850, loss_fp: 0.500533, loss_freq: 0.501151
[02:29:05.598] iteration 16: loss: 1.045891, loss_s1: 0.500900, loss_fp: 0.501103, loss_freq: 0.500726
[02:29:06.185] iteration 17: loss: 1.095399, loss_s1: 0.500763, loss_fp: 0.500221, loss_freq: 0.500653
[02:29:06.770] iteration 18: loss: 1.047293, loss_s1: 0.500824, loss_fp: 0.500137, loss_freq: 0.500569
[02:29:07.355] iteration 19: loss: 1.072308, loss_s1: 0.500470, loss_fp: 0.500174, loss_freq: 0.500926
[02:29:07.943] iteration 20: loss: 1.084080, loss_s1: 0.501058, loss_fp: 0.500412, loss_freq: 0.501503
[02:29:08.531] iteration 21: loss: 1.085832, loss_s1: 0.501765, loss_fp: 0.500293, loss_freq: 0.502277
[02:29:09.121] iteration 22: loss: 1.081046, loss_s1: 0.501306, loss_fp: 0.500274, loss_freq: 0.501189
[02:29:09.703] iteration 23: loss: 1.074872, loss_s1: 0.500429, loss_fp: 0.500250, loss_freq: 0.500907
[02:29:10.294] iteration 24: loss: 1.053240, loss_s1: 0.501588, loss_fp: 0.500323, loss_freq: 0.501523
[02:29:10.881] iteration 25: loss: 1.053231, loss_s1: 0.502287, loss_fp: 0.500292, loss_freq: 0.501366
[02:29:11.468] iteration 26: loss: 1.081627, loss_s1: 0.500193, loss_fp: 0.500295, loss_freq: 0.500838
[02:29:12.058] iteration 27: loss: 1.059977, loss_s1: 0.500392, loss_fp: 0.500124, loss_freq: 0.500607
[02:29:12.646] iteration 28: loss: 1.062513, loss_s1: 0.500817, loss_fp: 0.500302, loss_freq: 0.501427
[02:29:13.235] iteration 29: loss: 1.083484, loss_s1: 0.500373, loss_fp: 0.500054, loss_freq: 0.500927
[02:29:13.821] iteration 30: loss: 1.087850, loss_s1: 0.501321, loss_fp: 0.500199, loss_freq: 0.501290
[02:29:14.409] iteration 31: loss: 1.030467, loss_s1: 0.501193, loss_fp: 0.500127, loss_freq: 0.500801
[02:29:15.092] iteration 32: loss: 1.094391, loss_s1: 0.501769, loss_fp: 0.500551, loss_freq: 0.500674
[02:29:15.719] iteration 33: loss: 1.026121, loss_s1: 0.501981, loss_fp: 0.500240, loss_freq: 0.501012
[02:29:16.347] iteration 34: loss: 1.065966, loss_s1: 0.503205, loss_fp: 0.500154, loss_freq: 0.501943
[02:29:16.974] iteration 35: loss: 1.070762, loss_s1: 0.500534, loss_fp: 0.500067, loss_freq: 0.500698
[02:29:17.607] iteration 36: loss: 1.044327, loss_s1: 0.501123, loss_fp: 0.500498, loss_freq: 0.500573
[02:29:18.238] iteration 37: loss: 1.054194, loss_s1: 0.500556, loss_fp: 0.500211, loss_freq: 0.500831
[02:29:18.826] iteration 38: loss: 1.106148, loss_s1: 0.501040, loss_fp: 0.500133, loss_freq: 0.500847
[02:29:19.461] iteration 39: loss: 1.125112, loss_s1: 0.501263, loss_fp: 0.500247, loss_freq: 0.500738
[02:29:20.106] iteration 40: loss: 1.018861, loss_s1: 0.501587, loss_fp: 0.500101, loss_freq: 0.501646
[02:29:20.740] iteration 41: loss: 1.054301, loss_s1: 0.503156, loss_fp: 0.500270, loss_freq: 0.501052
[02:29:21.365] iteration 42: loss: 1.046168, loss_s1: 0.501131, loss_fp: 0.500130, loss_freq: 0.500842
[02:29:22.018] iteration 43: loss: 1.040726, loss_s1: 0.500264, loss_fp: 0.500392, loss_freq: 0.501045
[02:29:22.646] iteration 44: loss: 1.040315, loss_s1: 0.501494, loss_fp: 0.500231, loss_freq: 0.501433
[02:29:23.233] iteration 45: loss: 1.043734, loss_s1: 0.500349, loss_fp: 0.500060, loss_freq: 0.500884
[02:29:23.823] iteration 46: loss: 1.083806, loss_s1: 0.501001, loss_fp: 0.500980, loss_freq: 0.501455
[02:29:24.413] iteration 47: loss: 1.115555, loss_s1: 0.502632, loss_fp: 0.500257, loss_freq: 0.502299
[02:29:25.019] iteration 48: loss: 1.068804, loss_s1: 0.501676, loss_fp: 0.500176, loss_freq: 0.501994
[02:29:25.608] iteration 49: loss: 1.019794, loss_s1: 0.500889, loss_fp: 0.500413, loss_freq: 0.501266
[02:29:26.225] iteration 50: loss: 1.056133, loss_s1: 0.501429, loss_fp: 0.500584, loss_freq: 0.501464
[02:29:26.939] iteration 51: loss: 1.024565, loss_s1: 0.500993, loss_fp: 0.500352, loss_freq: 0.500469
[02:29:27.613] iteration 52: loss: 1.069552, loss_s1: 0.500246, loss_fp: 0.500143, loss_freq: 0.500489
[02:29:28.293] iteration 53: loss: 1.049688, loss_s1: 0.500842, loss_fp: 0.500169, loss_freq: 0.500968
[02:29:28.936] iteration 54: loss: 1.056250, loss_s1: 0.500699, loss_fp: 0.500171, loss_freq: 0.500526
[02:29:29.595] iteration 55: loss: 1.099169, loss_s1: 0.503128, loss_fp: 0.500448, loss_freq: 0.501538
[02:29:30.286] iteration 56: loss: 1.072800, loss_s1: 0.501053, loss_fp: 0.500216, loss_freq: 0.501040
[02:29:30.897] iteration 57: loss: 1.066926, loss_s1: 0.500375, loss_fp: 0.500144, loss_freq: 0.500506
[02:29:31.614] iteration 58: loss: 1.041790, loss_s1: 0.501047, loss_fp: 0.500091, loss_freq: 0.500758
[02:29:32.264] iteration 59: loss: 1.037424, loss_s1: 0.501992, loss_fp: 0.500848, loss_freq: 0.501134
[02:29:33.095] iteration 60: loss: 1.038380, loss_s1: 0.501139, loss_fp: 0.500167, loss_freq: 0.500613
[02:29:33.809] iteration 61: loss: 1.081069, loss_s1: 0.500609, loss_fp: 0.500297, loss_freq: 0.500619
[02:29:34.475] iteration 62: loss: 1.058904, loss_s1: 0.500457, loss_fp: 0.500190, loss_freq: 0.500638
[02:29:35.186] iteration 63: loss: 1.046468, loss_s1: 0.502958, loss_fp: 0.501038, loss_freq: 0.500904
[02:29:35.863] iteration 64: loss: 1.097929, loss_s1: 0.502069, loss_fp: 0.500719, loss_freq: 0.501076
[02:29:36.516] iteration 65: loss: 1.067095, loss_s1: 0.501170, loss_fp: 0.500015, loss_freq: 0.500838
[02:29:37.221] iteration 66: loss: 1.018858, loss_s1: 0.501981, loss_fp: 0.500427, loss_freq: 0.501211
[02:29:37.838] iteration 67: loss: 1.061579, loss_s1: 0.501710, loss_fp: 0.500304, loss_freq: 0.501183
[02:29:38.429] iteration 68: loss: 1.019835, loss_s1: 0.501492, loss_fp: 0.500415, loss_freq: 0.501352
[02:29:39.017] iteration 69: loss: 1.047578, loss_s1: 0.504966, loss_fp: 0.500302, loss_freq: 0.501930
[02:29:39.599] iteration 70: loss: 1.061150, loss_s1: 0.501101, loss_fp: 0.500379, loss_freq: 0.500917
[02:29:40.182] iteration 71: loss: 1.044924, loss_s1: 0.501962, loss_fp: 0.500175, loss_freq: 0.500816
[02:29:40.764] iteration 72: loss: 1.048188, loss_s1: 0.500929, loss_fp: 0.500565, loss_freq: 0.501158
[02:29:41.343] iteration 73: loss: 1.094465, loss_s1: 0.501719, loss_fp: 0.501204, loss_freq: 0.502330
[02:29:41.928] iteration 74: loss: 1.068020, loss_s1: 0.501058, loss_fp: 0.502145, loss_freq: 0.500933
[02:29:42.516] iteration 75: loss: 1.019927, loss_s1: 0.500928, loss_fp: 0.500282, loss_freq: 0.501233
[02:29:43.105] iteration 76: loss: 1.032061, loss_s1: 0.501671, loss_fp: 0.500293, loss_freq: 0.501116
[02:29:43.689] iteration 77: loss: 1.045794, loss_s1: 0.501864, loss_fp: 0.500677, loss_freq: 0.500982
[02:29:44.275] iteration 78: loss: 1.076861, loss_s1: 0.502277, loss_fp: 0.500499, loss_freq: 0.501137
[02:29:44.861] iteration 79: loss: 1.026595, loss_s1: 0.501963, loss_fp: 0.500373, loss_freq: 0.500692
[02:29:45.440] iteration 80: loss: 1.037005, loss_s1: 0.502003, loss_fp: 0.500827, loss_freq: 0.501662
[02:29:46.027] iteration 81: loss: 1.069982, loss_s1: 0.502619, loss_fp: 0.500505, loss_freq: 0.501695
[02:29:46.619] iteration 82: loss: 1.078897, loss_s1: 0.501963, loss_fp: 0.500314, loss_freq: 0.501726
[02:29:47.209] iteration 83: loss: 1.083368, loss_s1: 0.503601, loss_fp: 0.501326, loss_freq: 0.501975
[02:29:47.802] iteration 84: loss: 1.005522, loss_s1: 0.502647, loss_fp: 0.500935, loss_freq: 0.500459
[02:29:48.382] iteration 85: loss: 1.046081, loss_s1: 0.501899, loss_fp: 0.500183, loss_freq: 0.501243
[02:29:48.969] iteration 86: loss: 1.029613, loss_s1: 0.502627, loss_fp: 0.501332, loss_freq: 0.501254
[02:29:49.638] iteration 87: loss: 1.083286, loss_s1: 0.502692, loss_fp: 0.500801, loss_freq: 0.500756
[02:29:50.225] iteration 88: loss: 1.032526, loss_s1: 0.502152, loss_fp: 0.500170, loss_freq: 0.500962
[02:29:50.836] iteration 89: loss: 1.045400, loss_s1: 0.503275, loss_fp: 0.500264, loss_freq: 0.501561
[02:29:51.493] iteration 90: loss: 1.100763, loss_s1: 0.502994, loss_fp: 0.500270, loss_freq: 0.501406
[02:29:52.388] iteration 91: loss: 1.056380, loss_s1: 0.501698, loss_fp: 0.500458, loss_freq: 0.500559
[02:29:53.338] iteration 92: loss: 1.043890, loss_s1: 0.502617, loss_fp: 0.500225, loss_freq: 0.501229
[02:29:54.276] iteration 93: loss: 1.027620, loss_s1: 0.502332, loss_fp: 0.500156, loss_freq: 0.500634
[02:29:55.034] iteration 94: loss: 1.020111, loss_s1: 0.501145, loss_fp: 0.500159, loss_freq: 0.501144
[02:29:55.616] iteration 95: loss: 1.032116, loss_s1: 0.500771, loss_fp: 0.500263, loss_freq: 0.500462
[02:29:56.214] iteration 96: loss: 1.049960, loss_s1: 0.501032, loss_fp: 0.500389, loss_freq: 0.500858
[02:29:56.797] iteration 97: loss: 1.049927, loss_s1: 0.500602, loss_fp: 0.500820, loss_freq: 0.500467
[02:29:57.392] iteration 98: loss: 1.036104, loss_s1: 0.502129, loss_fp: 0.500021, loss_freq: 0.500845
[02:29:57.984] iteration 99: loss: 1.072129, loss_s1: 0.500570, loss_fp: 0.500298, loss_freq: 0.500822
[02:29:58.575] iteration 100: loss: 1.054176, loss_s1: 0.500934, loss_fp: 0.500130, loss_freq: 0.501080
[02:29:59.173] iteration 101: loss: 0.994312, loss_s1: 0.500701, loss_fp: 0.500086, loss_freq: 0.500821
[02:29:59.756] iteration 102: loss: 1.049632, loss_s1: 0.501958, loss_fp: 0.500557, loss_freq: 0.501170
[02:30:00.355] iteration 103: loss: 1.015305, loss_s1: 0.503794, loss_fp: 0.500101, loss_freq: 0.500889
[02:30:00.959] iteration 104: loss: 1.040904, loss_s1: 0.503669, loss_fp: 0.500411, loss_freq: 0.501950
[02:30:01.548] iteration 105: loss: 1.049299, loss_s1: 0.503017, loss_fp: 0.500491, loss_freq: 0.501359
[02:30:02.137] iteration 106: loss: 1.021856, loss_s1: 0.501319, loss_fp: 0.500464, loss_freq: 0.501090
[02:30:02.723] iteration 107: loss: 1.028064, loss_s1: 0.501714, loss_fp: 0.500388, loss_freq: 0.501319
[02:30:03.314] iteration 108: loss: 1.094723, loss_s1: 0.502779, loss_fp: 0.500523, loss_freq: 0.502009
[02:30:03.905] iteration 109: loss: 1.050001, loss_s1: 0.503014, loss_fp: 0.500291, loss_freq: 0.502337
[02:30:04.493] iteration 110: loss: 1.001181, loss_s1: 0.500910, loss_fp: 0.500180, loss_freq: 0.500811
[02:30:05.083] iteration 111: loss: 1.005271, loss_s1: 0.501377, loss_fp: 0.500089, loss_freq: 0.501523
[02:30:05.670] iteration 112: loss: 1.036888, loss_s1: 0.504525, loss_fp: 0.500291, loss_freq: 0.500939
[02:30:06.252] iteration 113: loss: 1.045631, loss_s1: 0.501970, loss_fp: 0.500563, loss_freq: 0.500647
[02:30:06.848] iteration 114: loss: 1.008717, loss_s1: 0.503493, loss_fp: 0.500675, loss_freq: 0.501373
[02:30:07.429] iteration 115: loss: 1.031703, loss_s1: 0.504073, loss_fp: 0.500308, loss_freq: 0.503831
[02:30:08.019] iteration 116: loss: 1.056704, loss_s1: 0.503074, loss_fp: 0.500194, loss_freq: 0.501360
[02:30:08.604] iteration 117: loss: 1.075724, loss_s1: 0.502526, loss_fp: 0.500087, loss_freq: 0.502335
[02:30:09.189] iteration 118: loss: 1.055946, loss_s1: 0.503051, loss_fp: 0.500122, loss_freq: 0.501477
[02:30:09.768] iteration 119: loss: 0.997757, loss_s1: 0.502197, loss_fp: 0.500410, loss_freq: 0.501115
[02:30:10.357] iteration 120: loss: 1.015555, loss_s1: 0.503159, loss_fp: 0.500305, loss_freq: 0.502360
[02:30:10.945] iteration 121: loss: 1.016908, loss_s1: 0.502090, loss_fp: 0.500376, loss_freq: 0.500950
[02:30:11.529] iteration 122: loss: 1.046059, loss_s1: 0.500504, loss_fp: 0.500186, loss_freq: 0.500303
[02:30:12.115] iteration 123: loss: 1.033059, loss_s1: 0.501135, loss_fp: 0.500194, loss_freq: 0.501302
[02:30:12.697] iteration 124: loss: 1.004275, loss_s1: 0.502373, loss_fp: 0.500076, loss_freq: 0.500744
[02:30:13.283] iteration 125: loss: 1.103512, loss_s1: 0.500970, loss_fp: 0.500057, loss_freq: 0.500963
[02:30:13.874] iteration 126: loss: 1.036861, loss_s1: 0.502371, loss_fp: 0.500158, loss_freq: 0.502706
[02:30:14.464] iteration 127: loss: 1.025791, loss_s1: 0.500714, loss_fp: 0.500082, loss_freq: 0.501688
[02:30:15.053] iteration 128: loss: 1.032341, loss_s1: 0.500455, loss_fp: 0.500207, loss_freq: 0.502075
[02:30:15.637] iteration 129: loss: 1.001457, loss_s1: 0.500968, loss_fp: 0.500412, loss_freq: 0.500878
[02:30:16.225] iteration 130: loss: 1.019833, loss_s1: 0.501581, loss_fp: 0.500157, loss_freq: 0.501627
[02:30:16.822] iteration 131: loss: 1.024817, loss_s1: 0.500775, loss_fp: 0.500085, loss_freq: 0.501422
[02:30:17.460] iteration 132: loss: 1.062635, loss_s1: 0.501974, loss_fp: 0.500077, loss_freq: 0.500611
[02:30:18.089] iteration 133: loss: 1.031517, loss_s1: 0.502788, loss_fp: 0.500342, loss_freq: 0.502015
[02:30:18.677] iteration 134: loss: 1.093200, loss_s1: 0.501802, loss_fp: 0.500434, loss_freq: 0.501220
[02:30:19.262] iteration 135: loss: 1.072049, loss_s1: 0.501884, loss_fp: 0.500109, loss_freq: 0.500652
[02:30:19.848] iteration 136: loss: 0.984934, loss_s1: 0.503391, loss_fp: 0.500085, loss_freq: 0.500375
[02:30:20.434] iteration 137: loss: 1.040103, loss_s1: 0.500937, loss_fp: 0.500070, loss_freq: 0.502199
[02:30:21.021] iteration 138: loss: 1.014589, loss_s1: 0.503097, loss_fp: 0.500168, loss_freq: 0.501362
[02:30:21.607] iteration 139: loss: 1.064482, loss_s1: 0.501227, loss_fp: 0.500220, loss_freq: 0.500932
[02:30:22.195] iteration 140: loss: 1.038637, loss_s1: 0.500852, loss_fp: 0.500153, loss_freq: 0.500373
[02:30:22.780] iteration 141: loss: 1.016511, loss_s1: 0.502069, loss_fp: 0.500171, loss_freq: 0.501148
[02:30:23.365] iteration 142: loss: 1.015305, loss_s1: 0.503417, loss_fp: 0.500143, loss_freq: 0.501013
[02:30:23.954] iteration 143: loss: 1.099182, loss_s1: 0.503214, loss_fp: 0.500170, loss_freq: 0.501031
[02:30:24.547] iteration 144: loss: 1.050030, loss_s1: 0.504626, loss_fp: 0.500300, loss_freq: 0.500607
[02:30:25.138] iteration 145: loss: 1.000182, loss_s1: 0.501364, loss_fp: 0.500219, loss_freq: 0.500547
[02:30:25.726] iteration 146: loss: 1.007320, loss_s1: 0.501064, loss_fp: 0.500306, loss_freq: 0.500582
[02:30:26.314] iteration 147: loss: 1.037142, loss_s1: 0.504071, loss_fp: 0.500129, loss_freq: 0.500650
[02:30:26.903] iteration 148: loss: 1.028545, loss_s1: 0.501784, loss_fp: 0.500305, loss_freq: 0.500337
[02:30:27.491] iteration 149: loss: 0.997033, loss_s1: 0.502758, loss_fp: 0.500396, loss_freq: 0.501454
[02:30:28.076] iteration 150: loss: 1.024588, loss_s1: 0.500953, loss_fp: 0.500188, loss_freq: 0.500742
[02:30:28.658] iteration 151: loss: 1.039732, loss_s1: 0.501884, loss_fp: 0.500237, loss_freq: 0.500986
[02:30:29.248] iteration 152: loss: 1.055107, loss_s1: 0.501169, loss_fp: 0.500143, loss_freq: 0.500847
[02:30:29.833] iteration 153: loss: 1.036964, loss_s1: 0.500522, loss_fp: 0.500133, loss_freq: 0.502129
[02:30:30.422] iteration 154: loss: 0.988046, loss_s1: 0.500869, loss_fp: 0.500162, loss_freq: 0.500787
[02:30:31.013] iteration 155: loss: 1.003302, loss_s1: 0.500998, loss_fp: 0.500134, loss_freq: 0.500596
[02:30:31.598] iteration 156: loss: 1.010645, loss_s1: 0.502193, loss_fp: 0.500104, loss_freq: 0.500897
[02:30:32.192] iteration 157: loss: 1.065065, loss_s1: 0.502962, loss_fp: 0.500184, loss_freq: 0.501092
[02:30:32.778] iteration 158: loss: 1.031093, loss_s1: 0.501716, loss_fp: 0.500063, loss_freq: 0.500447
[02:30:33.407] iteration 159: loss: 0.986659, loss_s1: 0.501109, loss_fp: 0.500175, loss_freq: 0.501157
[02:30:33.990] iteration 160: loss: 1.085110, loss_s1: 0.501745, loss_fp: 0.500213, loss_freq: 0.500424
[02:30:34.590] iteration 161: loss: 1.017255, loss_s1: 0.501539, loss_fp: 0.500056, loss_freq: 0.501010
[02:30:35.170] iteration 162: loss: 1.015995, loss_s1: 0.501630, loss_fp: 0.500097, loss_freq: 0.500369
[02:30:35.758] iteration 163: loss: 1.028090, loss_s1: 0.501135, loss_fp: 0.500112, loss_freq: 0.500703
[02:30:36.346] iteration 164: loss: 1.014069, loss_s1: 0.500242, loss_fp: 0.500186, loss_freq: 0.500484
[02:30:36.929] iteration 165: loss: 1.004620, loss_s1: 0.501196, loss_fp: 0.500274, loss_freq: 0.500542
[02:30:37.512] iteration 166: loss: 1.013215, loss_s1: 0.500677, loss_fp: 0.500173, loss_freq: 0.500476
[02:30:38.112] iteration 167: loss: 1.016502, loss_s1: 0.500683, loss_fp: 0.500845, loss_freq: 0.500404
[02:30:38.691] iteration 168: loss: 0.994942, loss_s1: 0.501539, loss_fp: 0.500135, loss_freq: 0.501096
[02:30:39.271] iteration 169: loss: 1.041944, loss_s1: 0.500695, loss_fp: 0.500193, loss_freq: 0.500510
[02:30:39.853] iteration 170: loss: 1.030720, loss_s1: 0.501563, loss_fp: 0.500213, loss_freq: 0.500772
[02:30:40.761] iteration 171: loss: 1.017182, loss_s1: 0.503102, loss_fp: 0.500253, loss_freq: 0.501087
[02:30:41.370] iteration 172: loss: 1.000663, loss_s1: 0.502550, loss_fp: 0.500161, loss_freq: 0.500490
[02:30:41.973] iteration 173: loss: 1.052356, loss_s1: 0.501938, loss_fp: 0.500156, loss_freq: 0.500993
[02:30:42.582] iteration 174: loss: 1.024108, loss_s1: 0.504304, loss_fp: 0.500237, loss_freq: 0.500672
[02:30:43.192] iteration 175: loss: 0.982068, loss_s1: 0.502385, loss_fp: 0.500150, loss_freq: 0.500230
[02:30:43.799] iteration 176: loss: 0.995207, loss_s1: 0.501505, loss_fp: 0.500201, loss_freq: 0.500230
[02:30:44.393] iteration 177: loss: 1.004673, loss_s1: 0.502357, loss_fp: 0.500131, loss_freq: 0.500867
[02:30:44.995] iteration 178: loss: 1.083422, loss_s1: 0.504346, loss_fp: 0.500120, loss_freq: 0.500422
[02:30:45.596] iteration 179: loss: 1.001680, loss_s1: 0.502167, loss_fp: 0.500042, loss_freq: 0.500287
[02:30:46.204] iteration 180: loss: 1.011705, loss_s1: 0.501774, loss_fp: 0.500128, loss_freq: 0.500820
[02:30:46.807] iteration 181: loss: 1.032179, loss_s1: 0.502185, loss_fp: 0.500107, loss_freq: 0.502044
[02:30:47.410] iteration 182: loss: 1.047405, loss_s1: 0.502341, loss_fp: 0.500175, loss_freq: 0.501454
[02:30:48.012] iteration 183: loss: 1.030270, loss_s1: 0.502897, loss_fp: 0.500363, loss_freq: 0.501251
[02:30:48.620] iteration 184: loss: 1.021583, loss_s1: 0.501647, loss_fp: 0.500146, loss_freq: 0.500570
[02:30:49.224] iteration 185: loss: 1.012208, loss_s1: 0.501766, loss_fp: 0.500236, loss_freq: 0.501109
[02:30:49.832] iteration 186: loss: 1.022421, loss_s1: 0.502131, loss_fp: 0.500164, loss_freq: 0.500234
[02:30:50.438] iteration 187: loss: 1.024925, loss_s1: 0.502392, loss_fp: 0.500224, loss_freq: 0.500287
[02:30:51.034] iteration 188: loss: 1.057054, loss_s1: 0.503716, loss_fp: 0.500178, loss_freq: 0.500360
[02:30:51.650] iteration 189: loss: 0.994758, loss_s1: 0.500579, loss_fp: 0.500096, loss_freq: 0.500363
[02:30:52.281] iteration 190: loss: 1.088177, loss_s1: 0.501426, loss_fp: 0.500232, loss_freq: 0.500994
[02:30:52.910] iteration 191: loss: 1.016445, loss_s1: 0.501814, loss_fp: 0.500086, loss_freq: 0.501165
[02:30:53.536] iteration 192: loss: 1.038052, loss_s1: 0.501582, loss_fp: 0.500278, loss_freq: 0.500493
[02:30:54.139] iteration 193: loss: 1.036150, loss_s1: 0.501440, loss_fp: 0.500115, loss_freq: 0.500334
[02:30:54.725] iteration 194: loss: 0.989085, loss_s1: 0.500708, loss_fp: 0.500129, loss_freq: 0.500635
[02:30:55.311] iteration 195: loss: 1.007920, loss_s1: 0.501035, loss_fp: 0.500269, loss_freq: 0.500609
[02:30:55.909] iteration 196: loss: 1.024991, loss_s1: 0.500697, loss_fp: 0.500052, loss_freq: 0.500448
[02:30:56.498] iteration 197: loss: 1.006033, loss_s1: 0.501427, loss_fp: 0.500056, loss_freq: 0.500353
[02:30:57.092] iteration 198: loss: 0.999971, loss_s1: 0.500773, loss_fp: 0.500125, loss_freq: 0.502144
[02:30:57.674] iteration 199: loss: 1.080298, loss_s1: 0.500913, loss_fp: 0.500168, loss_freq: 0.501327
[02:30:58.316] iteration 200: loss: 1.051413, loss_s1: 0.501836, loss_fp: 0.500292, loss_freq: 0.501460
[02:31:00.616] iteration 200 : mean_dice : 0.019135
[02:31:01.261] iteration 201: loss: 0.996400, loss_s1: 0.501337, loss_fp: 0.500399, loss_freq: 0.500450
[02:31:01.852] iteration 202: loss: 1.029922, loss_s1: 0.509590, loss_fp: 0.500152, loss_freq: 0.500663
[02:31:02.477] iteration 203: loss: 0.995464, loss_s1: 0.504314, loss_fp: 0.500144, loss_freq: 0.501238
[02:31:03.105] iteration 204: loss: 1.090487, loss_s1: 0.506692, loss_fp: 0.500083, loss_freq: 0.503886
[02:31:03.749] iteration 205: loss: 1.035300, loss_s1: 0.502588, loss_fp: 0.500155, loss_freq: 0.500862
[02:31:04.375] iteration 206: loss: 1.000898, loss_s1: 0.502884, loss_fp: 0.500048, loss_freq: 0.500493
[02:31:05.003] iteration 207: loss: 1.015810, loss_s1: 0.501363, loss_fp: 0.500397, loss_freq: 0.502234
[02:31:05.593] iteration 208: loss: 1.074355, loss_s1: 0.505593, loss_fp: 0.500028, loss_freq: 0.500219
[02:31:06.180] iteration 209: loss: 1.060780, loss_s1: 0.504181, loss_fp: 0.500189, loss_freq: 0.500822
[02:31:06.764] iteration 210: loss: 0.996393, loss_s1: 0.501386, loss_fp: 0.500364, loss_freq: 0.500896
[02:31:07.368] iteration 211: loss: 0.973564, loss_s1: 0.503538, loss_fp: 0.500277, loss_freq: 0.500532
[02:31:07.960] iteration 212: loss: 1.005123, loss_s1: 0.501166, loss_fp: 0.500133, loss_freq: 0.500493
[02:31:08.545] iteration 213: loss: 1.012123, loss_s1: 0.501386, loss_fp: 0.500245, loss_freq: 0.500628
[02:31:09.132] iteration 214: loss: 0.998258, loss_s1: 0.501114, loss_fp: 0.500814, loss_freq: 0.500467
[02:31:09.724] iteration 215: loss: 1.018715, loss_s1: 0.500331, loss_fp: 0.500233, loss_freq: 0.500621
[02:31:10.313] iteration 216: loss: 1.034810, loss_s1: 0.501392, loss_fp: 0.500171, loss_freq: 0.502565
[02:31:10.899] iteration 217: loss: 1.089307, loss_s1: 0.500890, loss_fp: 0.500313, loss_freq: 0.502025
[02:31:11.493] iteration 218: loss: 1.006175, loss_s1: 0.502621, loss_fp: 0.500102, loss_freq: 0.501024
[02:31:12.083] iteration 219: loss: 0.984439, loss_s1: 0.500316, loss_fp: 0.500171, loss_freq: 0.500435
[02:31:12.673] iteration 220: loss: 0.997167, loss_s1: 0.503375, loss_fp: 0.500261, loss_freq: 0.501417
[02:31:13.268] iteration 221: loss: 1.004835, loss_s1: 0.500713, loss_fp: 0.500264, loss_freq: 0.500307
[02:31:13.858] iteration 222: loss: 1.005434, loss_s1: 0.500704, loss_fp: 0.500153, loss_freq: 0.500895
[02:31:14.454] iteration 223: loss: 1.025611, loss_s1: 0.502571, loss_fp: 0.500307, loss_freq: 0.501001
[02:31:15.049] iteration 224: loss: 0.984500, loss_s1: 0.501144, loss_fp: 0.500121, loss_freq: 0.500802
[02:31:15.648] iteration 225: loss: 1.082821, loss_s1: 0.503084, loss_fp: 0.500203, loss_freq: 0.501534
[02:31:16.238] iteration 226: loss: 1.042521, loss_s1: 0.503415, loss_fp: 0.500360, loss_freq: 0.501531
[02:31:16.852] iteration 227: loss: 1.010884, loss_s1: 0.501744, loss_fp: 0.500257, loss_freq: 0.500911
[02:31:17.440] iteration 228: loss: 1.012475, loss_s1: 0.501794, loss_fp: 0.500136, loss_freq: 0.500474
[02:31:18.030] iteration 229: loss: 1.009731, loss_s1: 0.502265, loss_fp: 0.500249, loss_freq: 0.500413
[02:31:18.620] iteration 230: loss: 1.007574, loss_s1: 0.501979, loss_fp: 0.500645, loss_freq: 0.500468
[02:31:19.209] iteration 231: loss: 1.008207, loss_s1: 0.501744, loss_fp: 0.500112, loss_freq: 0.500541
[02:31:19.799] iteration 232: loss: 1.012535, loss_s1: 0.501114, loss_fp: 0.500150, loss_freq: 0.500652
[02:31:20.393] iteration 233: loss: 1.004432, loss_s1: 0.501892, loss_fp: 0.500255, loss_freq: 0.500396
[02:31:21.019] iteration 234: loss: 1.085866, loss_s1: 0.501844, loss_fp: 0.500220, loss_freq: 0.500583
[02:31:21.652] iteration 235: loss: 1.045617, loss_s1: 0.505392, loss_fp: 0.500214, loss_freq: 0.500861
[02:31:22.294] iteration 236: loss: 0.957049, loss_s1: 0.502006, loss_fp: 0.500520, loss_freq: 0.500705
[02:31:22.918] iteration 237: loss: 1.040742, loss_s1: 0.508110, loss_fp: 0.500193, loss_freq: 0.501523
[02:31:23.517] iteration 238: loss: 0.984284, loss_s1: 0.504023, loss_fp: 0.500043, loss_freq: 0.500336
[02:31:24.145] iteration 239: loss: 1.017618, loss_s1: 0.500792, loss_fp: 0.500092, loss_freq: 0.500899
[02:31:24.736] iteration 240: loss: 1.022703, loss_s1: 0.501716, loss_fp: 0.500422, loss_freq: 0.500613
[02:31:25.326] iteration 241: loss: 1.021732, loss_s1: 0.502442, loss_fp: 0.500277, loss_freq: 0.500435
[02:31:25.916] iteration 242: loss: 1.005747, loss_s1: 0.501047, loss_fp: 0.500127, loss_freq: 0.500382
[02:31:26.505] iteration 243: loss: 1.061783, loss_s1: 0.502575, loss_fp: 0.500149, loss_freq: 0.500739
[02:31:27.092] iteration 244: loss: 1.005613, loss_s1: 0.500975, loss_fp: 0.500353, loss_freq: 0.501147
[02:31:27.679] iteration 245: loss: 1.001146, loss_s1: 0.501217, loss_fp: 0.500163, loss_freq: 0.500409
[02:31:28.268] iteration 246: loss: 0.998568, loss_s1: 0.503189, loss_fp: 0.500229, loss_freq: 0.500872
[02:31:28.857] iteration 247: loss: 1.004391, loss_s1: 0.504609, loss_fp: 0.500384, loss_freq: 0.500959
[02:31:29.449] iteration 248: loss: 1.022461, loss_s1: 0.506396, loss_fp: 0.500533, loss_freq: 0.501215
[02:31:30.040] iteration 249: loss: 0.960279, loss_s1: 0.502938, loss_fp: 0.500136, loss_freq: 0.500802
[02:31:30.634] iteration 250: loss: 1.022440, loss_s1: 0.502930, loss_fp: 0.500224, loss_freq: 0.500410
[02:31:31.217] iteration 251: loss: 0.997932, loss_s1: 0.505070, loss_fp: 0.500715, loss_freq: 0.500776
[02:31:31.802] iteration 252: loss: 1.056395, loss_s1: 0.501308, loss_fp: 0.501472, loss_freq: 0.500675
[02:31:32.392] iteration 253: loss: 1.029650, loss_s1: 0.502172, loss_fp: 0.500104, loss_freq: 0.500977
[02:31:32.985] iteration 254: loss: 1.026700, loss_s1: 0.502185, loss_fp: 0.500286, loss_freq: 0.500511
[02:31:33.577] iteration 255: loss: 0.998931, loss_s1: 0.504772, loss_fp: 0.500124, loss_freq: 0.500932
[02:31:34.169] iteration 256: loss: 0.999803, loss_s1: 0.503106, loss_fp: 0.500258, loss_freq: 0.500174
[02:31:34.763] iteration 257: loss: 0.998087, loss_s1: 0.502315, loss_fp: 0.500449, loss_freq: 0.500271
[02:31:35.352] iteration 258: loss: 1.002928, loss_s1: 0.500810, loss_fp: 0.500115, loss_freq: 0.500508
[02:31:35.942] iteration 259: loss: 0.967370, loss_s1: 0.503859, loss_fp: 0.500440, loss_freq: 0.501392
[02:31:36.532] iteration 260: loss: 1.109383, loss_s1: 0.505920, loss_fp: 0.500147, loss_freq: 0.501089
[02:31:37.121] iteration 261: loss: 1.051144, loss_s1: 0.503284, loss_fp: 0.500297, loss_freq: 0.500801
[02:31:37.709] iteration 262: loss: 0.975173, loss_s1: 0.504685, loss_fp: 0.500200, loss_freq: 0.501066
[02:31:38.294] iteration 263: loss: 1.014187, loss_s1: 0.501626, loss_fp: 0.500031, loss_freq: 0.500655
[02:31:38.884] iteration 264: loss: 0.969011, loss_s1: 0.502465, loss_fp: 0.500189, loss_freq: 0.500824
[02:31:39.517] iteration 265: loss: 0.992237, loss_s1: 0.500685, loss_fp: 0.500049, loss_freq: 0.500190
[02:31:40.152] iteration 266: loss: 1.016531, loss_s1: 0.503092, loss_fp: 0.500089, loss_freq: 0.500179
[02:31:40.782] iteration 267: loss: 1.017320, loss_s1: 0.502900, loss_fp: 0.500140, loss_freq: 0.500187
[02:31:41.397] iteration 268: loss: 0.988136, loss_s1: 0.503834, loss_fp: 0.500228, loss_freq: 0.501310
[02:31:41.991] iteration 269: loss: 1.060530, loss_s1: 0.501965, loss_fp: 0.500051, loss_freq: 0.500254
[02:31:42.583] iteration 270: loss: 1.052601, loss_s1: 0.502237, loss_fp: 0.500178, loss_freq: 0.500433
[02:31:43.176] iteration 271: loss: 0.985533, loss_s1: 0.501086, loss_fp: 0.500243, loss_freq: 0.500939
[02:31:43.766] iteration 272: loss: 1.023791, loss_s1: 0.500963, loss_fp: 0.500157, loss_freq: 0.500585
[02:31:44.360] iteration 273: loss: 0.982358, loss_s1: 0.508961, loss_fp: 0.500064, loss_freq: 0.500262
[02:31:44.946] iteration 274: loss: 1.018481, loss_s1: 0.506776, loss_fp: 0.500214, loss_freq: 0.501324
[02:31:45.533] iteration 275: loss: 1.003624, loss_s1: 0.504174, loss_fp: 0.500139, loss_freq: 0.500641
[02:31:46.119] iteration 276: loss: 0.996502, loss_s1: 0.508735, loss_fp: 0.500151, loss_freq: 0.501674
[02:31:46.711] iteration 277: loss: 0.993399, loss_s1: 0.501805, loss_fp: 0.500118, loss_freq: 0.501313
[02:31:47.298] iteration 278: loss: 1.081884, loss_s1: 0.508688, loss_fp: 0.500078, loss_freq: 0.502261
[02:31:47.891] iteration 279: loss: 1.001842, loss_s1: 0.502563, loss_fp: 0.500073, loss_freq: 0.501156
[02:31:48.484] iteration 280: loss: 0.968739, loss_s1: 0.501866, loss_fp: 0.500134, loss_freq: 0.500301
[02:31:49.078] iteration 281: loss: 0.974549, loss_s1: 0.502921, loss_fp: 0.500121, loss_freq: 0.501188
[02:31:49.671] iteration 282: loss: 0.992099, loss_s1: 0.502024, loss_fp: 0.500155, loss_freq: 0.500703
[02:31:50.300] iteration 283: loss: 1.025831, loss_s1: 0.502840, loss_fp: 0.500164, loss_freq: 0.500140
[02:31:50.886] iteration 284: loss: 0.971277, loss_s1: 0.504133, loss_fp: 0.500237, loss_freq: 0.500382
[02:31:51.487] iteration 285: loss: 1.015369, loss_s1: 0.505519, loss_fp: 0.500131, loss_freq: 0.501624
[02:31:52.077] iteration 286: loss: 0.989594, loss_s1: 0.502199, loss_fp: 0.500337, loss_freq: 0.500783
[02:31:52.666] iteration 287: loss: 1.031733, loss_s1: 0.503781, loss_fp: 0.500105, loss_freq: 0.500736
[02:31:53.250] iteration 288: loss: 1.011469, loss_s1: 0.503425, loss_fp: 0.500138, loss_freq: 0.500349
[02:31:53.838] iteration 289: loss: 0.983965, loss_s1: 0.505361, loss_fp: 0.500174, loss_freq: 0.500563
[02:31:54.440] iteration 290: loss: 0.992223, loss_s1: 0.505861, loss_fp: 0.500257, loss_freq: 0.501534
[02:31:55.034] iteration 291: loss: 1.006420, loss_s1: 0.503277, loss_fp: 0.500400, loss_freq: 0.500397
[02:31:55.631] iteration 292: loss: 0.993615, loss_s1: 0.502130, loss_fp: 0.500145, loss_freq: 0.500421
[02:31:56.226] iteration 293: loss: 0.996852, loss_s1: 0.503902, loss_fp: 0.500380, loss_freq: 0.501042
[02:31:56.824] iteration 294: loss: 0.946228, loss_s1: 0.502366, loss_fp: 0.500117, loss_freq: 0.500358
[02:31:57.453] iteration 295: loss: 1.010861, loss_s1: 0.503089, loss_fp: 0.500089, loss_freq: 0.500385
[02:31:58.153] iteration 296: loss: 1.003582, loss_s1: 0.505651, loss_fp: 0.500212, loss_freq: 0.500682
[02:31:58.863] iteration 297: loss: 0.980744, loss_s1: 0.502411, loss_fp: 0.500502, loss_freq: 0.501597
[02:31:59.543] iteration 298: loss: 0.998872, loss_s1: 0.503666, loss_fp: 0.500073, loss_freq: 0.500955
[02:32:00.208] iteration 299: loss: 0.951174, loss_s1: 0.504491, loss_fp: 0.500640, loss_freq: 0.500735
[02:32:00.877] iteration 300: loss: 0.980439, loss_s1: 0.503061, loss_fp: 0.500187, loss_freq: 0.502622
[02:32:01.605] iteration 301: loss: 0.969405, loss_s1: 0.502103, loss_fp: 0.500502, loss_freq: 0.501101
[02:32:02.280] iteration 302: loss: 1.010623, loss_s1: 0.503729, loss_fp: 0.500160, loss_freq: 0.500708
[02:32:02.955] iteration 303: loss: 0.979105, loss_s1: 0.503207, loss_fp: 0.500202, loss_freq: 0.501327
[02:32:03.628] iteration 304: loss: 1.063815, loss_s1: 0.509148, loss_fp: 0.500432, loss_freq: 0.501173
[02:32:04.226] iteration 305: loss: 1.045420, loss_s1: 0.503707, loss_fp: 0.500173, loss_freq: 0.501210
[02:32:04.814] iteration 306: loss: 0.932274, loss_s1: 0.507540, loss_fp: 0.500241, loss_freq: 0.502615
[02:32:05.398] iteration 307: loss: 1.018267, loss_s1: 0.505861, loss_fp: 0.500712, loss_freq: 0.500983
[02:32:05.984] iteration 308: loss: 0.981640, loss_s1: 0.501739, loss_fp: 0.500153, loss_freq: 0.500764
[02:32:06.566] iteration 309: loss: 0.969311, loss_s1: 0.501617, loss_fp: 0.500187, loss_freq: 0.500298
[02:32:07.151] iteration 310: loss: 0.968099, loss_s1: 0.505024, loss_fp: 0.500216, loss_freq: 0.500445
[02:32:07.737] iteration 311: loss: 1.003948, loss_s1: 0.504084, loss_fp: 0.500099, loss_freq: 0.501719
[02:32:08.322] iteration 312: loss: 0.976157, loss_s1: 0.505815, loss_fp: 0.500050, loss_freq: 0.501270
[02:32:08.911] iteration 313: loss: 1.016819, loss_s1: 0.504805, loss_fp: 0.500058, loss_freq: 0.501243
[02:32:09.496] iteration 314: loss: 0.990210, loss_s1: 0.508582, loss_fp: 0.500287, loss_freq: 0.500982
[02:32:10.083] iteration 315: loss: 1.000097, loss_s1: 0.506797, loss_fp: 0.500162, loss_freq: 0.504008
[02:32:10.670] iteration 316: loss: 0.987554, loss_s1: 0.502650, loss_fp: 0.500317, loss_freq: 0.500776
[02:32:11.256] iteration 317: loss: 0.983506, loss_s1: 0.503086, loss_fp: 0.500143, loss_freq: 0.501529
[02:32:11.842] iteration 318: loss: 0.992839, loss_s1: 0.503789, loss_fp: 0.500075, loss_freq: 0.500380
[02:32:12.428] iteration 319: loss: 1.008975, loss_s1: 0.504818, loss_fp: 0.500100, loss_freq: 0.502020
[02:32:13.015] iteration 320: loss: 1.000194, loss_s1: 0.503225, loss_fp: 0.500103, loss_freq: 0.500825
[02:32:13.609] iteration 321: loss: 1.027134, loss_s1: 0.512458, loss_fp: 0.500099, loss_freq: 0.502893
[02:32:14.264] iteration 322: loss: 1.045708, loss_s1: 0.502148, loss_fp: 0.500066, loss_freq: 0.501298
[02:32:15.087] iteration 323: loss: 0.996126, loss_s1: 0.505822, loss_fp: 0.500083, loss_freq: 0.501732
[02:32:16.067] iteration 324: loss: 0.985142, loss_s1: 0.504923, loss_fp: 0.500320, loss_freq: 0.500602
[02:32:16.662] iteration 325: loss: 0.981714, loss_s1: 0.502086, loss_fp: 0.500120, loss_freq: 0.501029
[02:32:17.260] iteration 326: loss: 0.959719, loss_s1: 0.504561, loss_fp: 0.500217, loss_freq: 0.501179
[02:32:17.841] iteration 327: loss: 1.017586, loss_s1: 0.504879, loss_fp: 0.500081, loss_freq: 0.504464
[02:32:18.424] iteration 328: loss: 0.971845, loss_s1: 0.511424, loss_fp: 0.500175, loss_freq: 0.500645
[02:32:19.010] iteration 329: loss: 0.966672, loss_s1: 0.502601, loss_fp: 0.500600, loss_freq: 0.501636
[02:32:19.600] iteration 330: loss: 1.000894, loss_s1: 0.504211, loss_fp: 0.500468, loss_freq: 0.500265
[02:32:20.193] iteration 331: loss: 1.018817, loss_s1: 0.501477, loss_fp: 0.500540, loss_freq: 0.500718
[02:32:20.783] iteration 332: loss: 0.986923, loss_s1: 0.502371, loss_fp: 0.500378, loss_freq: 0.500964
[02:32:21.378] iteration 333: loss: 1.021083, loss_s1: 0.504071, loss_fp: 0.500126, loss_freq: 0.500620
[02:32:21.966] iteration 334: loss: 0.961975, loss_s1: 0.504853, loss_fp: 0.500064, loss_freq: 0.500668
[02:32:22.552] iteration 335: loss: 1.023763, loss_s1: 0.503828, loss_fp: 0.500692, loss_freq: 0.500279
[02:32:23.138] iteration 336: loss: 1.009682, loss_s1: 0.510457, loss_fp: 0.500110, loss_freq: 0.500214
[02:32:23.729] iteration 337: loss: 1.005379, loss_s1: 0.504023, loss_fp: 0.500109, loss_freq: 0.500380
[02:32:24.323] iteration 338: loss: 0.973131, loss_s1: 0.508966, loss_fp: 0.500205, loss_freq: 0.500925
[02:32:24.907] iteration 339: loss: 1.084232, loss_s1: 0.503128, loss_fp: 0.500153, loss_freq: 0.500363
[02:32:25.490] iteration 340: loss: 0.991206, loss_s1: 0.504447, loss_fp: 0.500208, loss_freq: 0.500565
[02:32:26.373] iteration 341: loss: 0.989376, loss_s1: 0.504215, loss_fp: 0.500223, loss_freq: 0.500523
[02:32:26.958] iteration 342: loss: 0.968924, loss_s1: 0.500971, loss_fp: 0.500112, loss_freq: 0.500550
[02:32:27.548] iteration 343: loss: 1.023452, loss_s1: 0.501680, loss_fp: 0.500206, loss_freq: 0.500364
[02:32:28.139] iteration 344: loss: 0.983597, loss_s1: 0.505313, loss_fp: 0.500220, loss_freq: 0.500595
[02:32:28.725] iteration 345: loss: 0.989588, loss_s1: 0.501595, loss_fp: 0.500464, loss_freq: 0.500322
[02:32:29.313] iteration 346: loss: 0.992480, loss_s1: 0.503395, loss_fp: 0.500644, loss_freq: 0.500667
[02:32:29.905] iteration 347: loss: 0.991190, loss_s1: 0.504842, loss_fp: 0.500258, loss_freq: 0.500945
[02:32:30.565] iteration 348: loss: 1.008282, loss_s1: 0.502466, loss_fp: 0.500116, loss_freq: 0.500424
[02:32:31.151] iteration 349: loss: 0.972226, loss_s1: 0.503309, loss_fp: 0.500201, loss_freq: 0.500633
[02:32:31.740] iteration 350: loss: 0.965726, loss_s1: 0.503349, loss_fp: 0.500075, loss_freq: 0.500889
[02:32:32.331] iteration 351: loss: 0.974232, loss_s1: 0.504996, loss_fp: 0.500254, loss_freq: 0.502585
[02:32:32.924] iteration 352: loss: 1.006804, loss_s1: 0.505109, loss_fp: 0.500078, loss_freq: 0.501156
[02:32:33.571] iteration 353: loss: 0.999485, loss_s1: 0.504297, loss_fp: 0.500209, loss_freq: 0.500795
[02:32:34.215] iteration 354: loss: 0.966784, loss_s1: 0.502225, loss_fp: 0.500136, loss_freq: 0.500803
[02:32:34.870] iteration 355: loss: 0.988623, loss_s1: 0.504242, loss_fp: 0.500230, loss_freq: 0.500752
[02:32:35.533] iteration 356: loss: 0.970033, loss_s1: 0.504855, loss_fp: 0.500082, loss_freq: 0.500609
[02:32:36.241] iteration 357: loss: 0.967318, loss_s1: 0.501547, loss_fp: 0.500098, loss_freq: 0.500117
[02:32:36.909] iteration 358: loss: 0.980579, loss_s1: 0.503020, loss_fp: 0.500125, loss_freq: 0.500820
[02:32:37.544] iteration 359: loss: 0.931922, loss_s1: 0.504569, loss_fp: 0.500108, loss_freq: 0.500154
[02:32:38.207] iteration 360: loss: 0.985284, loss_s1: 0.501840, loss_fp: 0.500106, loss_freq: 0.501028
[02:32:38.913] iteration 361: loss: 0.988336, loss_s1: 0.503789, loss_fp: 0.500320, loss_freq: 0.502179
[02:32:39.562] iteration 362: loss: 0.973021, loss_s1: 0.502019, loss_fp: 0.500043, loss_freq: 0.501494
[02:32:40.271] iteration 363: loss: 1.024787, loss_s1: 0.503705, loss_fp: 0.500137, loss_freq: 0.500548
[02:32:40.870] iteration 364: loss: 0.939899, loss_s1: 0.504037, loss_fp: 0.500196, loss_freq: 0.501595
[02:32:41.550] iteration 365: loss: 0.984151, loss_s1: 0.507792, loss_fp: 0.500202, loss_freq: 0.500706
[02:32:42.167] iteration 366: loss: 0.978878, loss_s1: 0.506198, loss_fp: 0.500205, loss_freq: 0.500573
[02:32:42.753] iteration 367: loss: 0.951780, loss_s1: 0.504753, loss_fp: 0.500144, loss_freq: 0.500633
[02:32:43.340] iteration 368: loss: 0.956652, loss_s1: 0.505403, loss_fp: 0.500199, loss_freq: 0.502727
[02:32:43.930] iteration 369: loss: 1.044118, loss_s1: 0.502254, loss_fp: 0.500266, loss_freq: 0.501999
[02:32:44.525] iteration 370: loss: 1.039480, loss_s1: 0.502230, loss_fp: 0.500337, loss_freq: 0.500680
[02:32:45.112] iteration 371: loss: 0.949860, loss_s1: 0.501036, loss_fp: 0.500074, loss_freq: 0.500198
[02:32:45.698] iteration 372: loss: 1.007625, loss_s1: 0.503066, loss_fp: 0.500076, loss_freq: 0.500532
[02:32:46.287] iteration 373: loss: 0.988650, loss_s1: 0.504843, loss_fp: 0.500113, loss_freq: 0.501072
[02:32:46.871] iteration 374: loss: 0.993512, loss_s1: 0.507979, loss_fp: 0.500341, loss_freq: 0.502247
[02:32:47.463] iteration 375: loss: 0.935423, loss_s1: 0.504888, loss_fp: 0.503080, loss_freq: 0.500652
[02:32:48.057] iteration 376: loss: 0.983763, loss_s1: 0.506313, loss_fp: 0.500084, loss_freq: 0.500493
[02:32:48.650] iteration 377: loss: 0.932276, loss_s1: 0.501861, loss_fp: 0.500448, loss_freq: 0.500464
[02:32:49.243] iteration 378: loss: 1.011497, loss_s1: 0.505654, loss_fp: 0.500097, loss_freq: 0.500141
[02:32:49.840] iteration 379: loss: 0.960965, loss_s1: 0.503081, loss_fp: 0.500199, loss_freq: 0.500407
[02:32:50.424] iteration 380: loss: 0.964051, loss_s1: 0.505261, loss_fp: 0.500130, loss_freq: 0.500344
[02:32:51.053] iteration 381: loss: 0.950406, loss_s1: 0.503533, loss_fp: 0.500282, loss_freq: 0.500728
[02:32:51.997] iteration 382: loss: 0.958095, loss_s1: 0.503224, loss_fp: 0.500259, loss_freq: 0.500760
[02:32:52.729] iteration 383: loss: 0.992266, loss_s1: 0.502861, loss_fp: 0.500336, loss_freq: 0.500817
[02:32:53.360] iteration 384: loss: 0.946228, loss_s1: 0.504348, loss_fp: 0.500573, loss_freq: 0.500572
[02:32:53.972] iteration 385: loss: 0.963967, loss_s1: 0.503679, loss_fp: 0.500346, loss_freq: 0.500523
[02:32:54.566] iteration 386: loss: 0.961069, loss_s1: 0.504814, loss_fp: 0.500253, loss_freq: 0.501388
[02:32:55.159] iteration 387: loss: 1.051862, loss_s1: 0.505150, loss_fp: 0.500410, loss_freq: 0.500293
[02:32:55.756] iteration 388: loss: 0.969609, loss_s1: 0.504990, loss_fp: 0.500186, loss_freq: 0.502151
[02:32:56.353] iteration 389: loss: 0.958462, loss_s1: 0.503369, loss_fp: 0.500155, loss_freq: 0.500655
[02:32:56.951] iteration 390: loss: 0.950001, loss_s1: 0.505068, loss_fp: 0.500106, loss_freq: 0.501525
[02:32:57.542] iteration 391: loss: 0.960796, loss_s1: 0.501919, loss_fp: 0.500036, loss_freq: 0.500438
[02:32:58.123] iteration 392: loss: 0.969325, loss_s1: 0.507628, loss_fp: 0.500130, loss_freq: 0.500494
[02:32:58.710] iteration 393: loss: 0.987187, loss_s1: 0.503345, loss_fp: 0.500157, loss_freq: 0.502593
[02:32:59.297] iteration 394: loss: 0.939043, loss_s1: 0.508709, loss_fp: 0.500160, loss_freq: 0.501473
[02:32:59.920] iteration 395: loss: 1.034225, loss_s1: 0.506818, loss_fp: 0.500051, loss_freq: 0.502477
[02:33:00.528] iteration 396: loss: 0.970745, loss_s1: 0.501968, loss_fp: 0.500065, loss_freq: 0.501604
[02:33:01.116] iteration 397: loss: 0.958220, loss_s1: 0.505475, loss_fp: 0.500223, loss_freq: 0.500722
[02:33:01.732] iteration 398: loss: 1.009337, loss_s1: 0.505128, loss_fp: 0.500151, loss_freq: 0.501718
[02:33:02.320] iteration 399: loss: 0.930359, loss_s1: 0.502733, loss_fp: 0.500226, loss_freq: 0.500659
[02:33:02.933] iteration 400: loss: 0.946533, loss_s1: 0.505300, loss_fp: 0.500068, loss_freq: 0.500770
[02:33:05.094] iteration 400 : mean_dice : 0.061638
[02:33:05.705] iteration 401: loss: 0.987069, loss_s1: 0.503624, loss_fp: 0.501094, loss_freq: 0.500503
[02:33:06.297] iteration 402: loss: 0.969309, loss_s1: 0.502393, loss_fp: 0.500165, loss_freq: 0.500627
[02:33:06.886] iteration 403: loss: 0.929533, loss_s1: 0.501672, loss_fp: 0.500193, loss_freq: 0.500647
[02:33:07.473] iteration 404: loss: 1.018811, loss_s1: 0.501696, loss_fp: 0.500119, loss_freq: 0.500346
[02:33:08.056] iteration 405: loss: 1.019610, loss_s1: 0.501927, loss_fp: 0.500128, loss_freq: 0.500428
[02:33:08.644] iteration 406: loss: 0.912294, loss_s1: 0.504115, loss_fp: 0.500073, loss_freq: 0.501376
[02:33:09.292] iteration 407: loss: 0.996413, loss_s1: 0.503799, loss_fp: 0.500235, loss_freq: 0.500417
[02:33:09.934] iteration 408: loss: 0.972606, loss_s1: 0.502165, loss_fp: 0.500095, loss_freq: 0.500299
[02:33:10.591] iteration 409: loss: 0.984728, loss_s1: 0.501369, loss_fp: 0.500468, loss_freq: 0.500690
[02:33:11.254] iteration 410: loss: 0.972180, loss_s1: 0.504774, loss_fp: 0.500829, loss_freq: 0.500738
[02:33:11.870] iteration 411: loss: 0.963581, loss_s1: 0.504271, loss_fp: 0.500144, loss_freq: 0.500717
[02:33:12.490] iteration 412: loss: 0.953578, loss_s1: 0.506776, loss_fp: 0.500141, loss_freq: 0.500617
[02:33:13.092] iteration 413: loss: 1.022996, loss_s1: 0.507186, loss_fp: 0.500192, loss_freq: 0.501056
[02:33:13.705] iteration 414: loss: 0.974249, loss_s1: 0.510083, loss_fp: 0.500115, loss_freq: 0.502418
[02:33:14.310] iteration 415: loss: 0.988732, loss_s1: 0.510015, loss_fp: 0.500241, loss_freq: 0.502173
[02:33:14.917] iteration 416: loss: 0.959637, loss_s1: 0.501642, loss_fp: 0.500026, loss_freq: 0.500920
[02:33:15.563] iteration 417: loss: 0.970637, loss_s1: 0.503076, loss_fp: 0.500229, loss_freq: 0.500901
[02:33:16.193] iteration 418: loss: 1.000795, loss_s1: 0.502776, loss_fp: 0.500046, loss_freq: 0.500630
[02:33:16.820] iteration 419: loss: 0.979403, loss_s1: 0.507475, loss_fp: 0.500122, loss_freq: 0.500966
[02:33:17.450] iteration 420: loss: 0.968745, loss_s1: 0.504236, loss_fp: 0.500114, loss_freq: 0.500726
[02:33:18.075] iteration 421: loss: 0.966702, loss_s1: 0.504170, loss_fp: 0.500183, loss_freq: 0.501118
[02:33:18.702] iteration 422: loss: 1.011093, loss_s1: 0.507306, loss_fp: 0.500245, loss_freq: 0.500617
[02:33:19.329] iteration 423: loss: 0.975533, loss_s1: 0.506098, loss_fp: 0.500120, loss_freq: 0.500631
[02:33:19.941] iteration 424: loss: 0.963946, loss_s1: 0.500988, loss_fp: 0.500248, loss_freq: 0.501314
[02:33:20.527] iteration 425: loss: 0.968450, loss_s1: 0.502562, loss_fp: 0.500157, loss_freq: 0.500874
[02:33:21.115] iteration 426: loss: 0.956291, loss_s1: 0.502360, loss_fp: 0.500218, loss_freq: 0.500774
[02:33:21.716] iteration 427: loss: 0.954492, loss_s1: 0.501578, loss_fp: 0.500575, loss_freq: 0.500336
[02:33:22.325] iteration 428: loss: 0.986912, loss_s1: 0.503211, loss_fp: 0.500424, loss_freq: 0.500607
[02:33:22.914] iteration 429: loss: 0.933594, loss_s1: 0.502640, loss_fp: 0.500284, loss_freq: 0.500403
[02:33:23.502] iteration 430: loss: 1.005285, loss_s1: 0.503295, loss_fp: 0.500214, loss_freq: 0.500997
[02:33:24.090] iteration 431: loss: 0.947259, loss_s1: 0.504327, loss_fp: 0.500174, loss_freq: 0.501464
[02:33:24.688] iteration 432: loss: 0.948681, loss_s1: 0.506925, loss_fp: 0.500249, loss_freq: 0.502056
[02:33:25.282] iteration 433: loss: 1.039016, loss_s1: 0.505726, loss_fp: 0.500412, loss_freq: 0.501267
[02:33:25.879] iteration 434: loss: 0.940960, loss_s1: 0.503654, loss_fp: 0.500152, loss_freq: 0.501811
[02:33:26.464] iteration 435: loss: 0.946418, loss_s1: 0.500262, loss_fp: 0.500339, loss_freq: 0.500202
[02:33:27.075] iteration 436: loss: 0.992901, loss_s1: 0.503656, loss_fp: 0.500048, loss_freq: 0.500143
[02:33:27.657] iteration 437: loss: 1.008098, loss_s1: 0.503312, loss_fp: 0.500113, loss_freq: 0.500168
[02:33:28.242] iteration 438: loss: 0.965638, loss_s1: 0.504062, loss_fp: 0.500137, loss_freq: 0.502065
[02:33:28.828] iteration 439: loss: 1.030078, loss_s1: 0.506917, loss_fp: 0.500168, loss_freq: 0.500460
[02:33:29.412] iteration 440: loss: 0.990430, loss_s1: 0.504121, loss_fp: 0.500133, loss_freq: 0.500410
[02:33:29.999] iteration 441: loss: 0.930172, loss_s1: 0.507852, loss_fp: 0.500308, loss_freq: 0.501565
[02:33:30.621] iteration 442: loss: 1.023301, loss_s1: 0.505401, loss_fp: 0.500254, loss_freq: 0.501535
[02:33:31.207] iteration 443: loss: 0.977138, loss_s1: 0.500973, loss_fp: 0.500514, loss_freq: 0.500144
[02:33:31.801] iteration 444: loss: 0.963425, loss_s1: 0.508431, loss_fp: 0.500207, loss_freq: 0.501254
[02:33:32.395] iteration 445: loss: 0.955093, loss_s1: 0.502486, loss_fp: 0.500108, loss_freq: 0.500389
[02:33:33.002] iteration 446: loss: 0.936890, loss_s1: 0.505933, loss_fp: 0.500212, loss_freq: 0.500367
[02:33:33.612] iteration 447: loss: 0.944762, loss_s1: 0.502343, loss_fp: 0.500082, loss_freq: 0.500583
[02:33:34.206] iteration 448: loss: 1.027728, loss_s1: 0.506100, loss_fp: 0.500336, loss_freq: 0.500787
[02:33:34.791] iteration 449: loss: 0.977424, loss_s1: 0.508338, loss_fp: 0.500212, loss_freq: 0.507258
[02:33:35.385] iteration 450: loss: 0.963966, loss_s1: 0.503479, loss_fp: 0.500111, loss_freq: 0.500652
[02:33:35.975] iteration 451: loss: 0.975538, loss_s1: 0.503420, loss_fp: 0.500063, loss_freq: 0.501903
[02:33:36.566] iteration 452: loss: 0.944224, loss_s1: 0.504910, loss_fp: 0.500605, loss_freq: 0.500893
[02:33:37.159] iteration 453: loss: 1.006043, loss_s1: 0.505174, loss_fp: 0.500101, loss_freq: 0.500139
[02:33:37.758] iteration 454: loss: 0.950588, loss_s1: 0.505728, loss_fp: 0.500181, loss_freq: 0.500288
[02:33:38.358] iteration 455: loss: 0.964529, loss_s1: 0.505829, loss_fp: 0.500629, loss_freq: 0.504370
[02:33:38.952] iteration 456: loss: 0.955626, loss_s1: 0.506941, loss_fp: 0.500188, loss_freq: 0.503634
[02:33:39.545] iteration 457: loss: 0.994613, loss_s1: 0.504688, loss_fp: 0.500215, loss_freq: 0.500600
[02:33:40.144] iteration 458: loss: 0.959155, loss_s1: 0.502270, loss_fp: 0.500110, loss_freq: 0.500798
[02:33:40.740] iteration 459: loss: 0.944978, loss_s1: 0.504263, loss_fp: 0.500473, loss_freq: 0.505490
[02:33:41.333] iteration 460: loss: 0.951315, loss_s1: 0.507886, loss_fp: 0.500264, loss_freq: 0.504305
[02:33:41.921] iteration 461: loss: 0.979002, loss_s1: 0.503447, loss_fp: 0.500337, loss_freq: 0.500906
[02:33:42.514] iteration 462: loss: 0.940470, loss_s1: 0.502686, loss_fp: 0.500264, loss_freq: 0.500706
[02:33:43.106] iteration 463: loss: 0.924906, loss_s1: 0.501779, loss_fp: 0.500471, loss_freq: 0.501027
[02:33:43.701] iteration 464: loss: 0.905829, loss_s1: 0.503342, loss_fp: 0.500117, loss_freq: 0.503246
[02:33:44.288] iteration 465: loss: 0.950756, loss_s1: 0.501639, loss_fp: 0.500064, loss_freq: 0.500646
[02:33:44.877] iteration 466: loss: 1.021179, loss_s1: 0.503518, loss_fp: 0.500265, loss_freq: 0.500317
[02:33:45.463] iteration 467: loss: 0.953533, loss_s1: 0.503056, loss_fp: 0.500156, loss_freq: 0.501887
[02:33:46.113] iteration 468: loss: 0.979075, loss_s1: 0.503382, loss_fp: 0.500131, loss_freq: 0.506424
[02:33:46.769] iteration 469: loss: 0.919739, loss_s1: 0.501860, loss_fp: 0.500105, loss_freq: 0.501364
[02:33:47.415] iteration 470: loss: 0.917499, loss_s1: 0.509889, loss_fp: 0.500228, loss_freq: 0.501775
[02:33:48.040] iteration 471: loss: 0.962300, loss_s1: 0.501622, loss_fp: 0.500131, loss_freq: 0.500497
[02:33:48.647] iteration 472: loss: 0.958826, loss_s1: 0.501860, loss_fp: 0.500108, loss_freq: 0.500686
[02:33:49.247] iteration 473: loss: 0.943520, loss_s1: 0.505054, loss_fp: 0.500061, loss_freq: 0.501776
[02:33:49.850] iteration 474: loss: 1.029974, loss_s1: 0.507066, loss_fp: 0.500387, loss_freq: 0.501066
[02:33:50.456] iteration 475: loss: 1.008082, loss_s1: 0.506587, loss_fp: 0.500139, loss_freq: 0.501133
[02:33:51.058] iteration 476: loss: 0.908449, loss_s1: 0.503080, loss_fp: 0.500352, loss_freq: 0.504247
[02:33:51.708] iteration 477: loss: 1.002731, loss_s1: 0.505531, loss_fp: 0.500160, loss_freq: 0.501257
[02:33:52.338] iteration 478: loss: 0.930260, loss_s1: 0.505549, loss_fp: 0.500441, loss_freq: 0.500795
[02:33:52.963] iteration 479: loss: 0.948499, loss_s1: 0.503004, loss_fp: 0.500425, loss_freq: 0.500592
[02:33:53.576] iteration 480: loss: 0.931452, loss_s1: 0.505638, loss_fp: 0.500049, loss_freq: 0.500260
[02:33:54.167] iteration 481: loss: 0.960186, loss_s1: 0.507619, loss_fp: 0.500231, loss_freq: 0.501485
[02:33:54.784] iteration 482: loss: 0.935397, loss_s1: 0.506668, loss_fp: 0.500170, loss_freq: 0.501583
[02:33:55.373] iteration 483: loss: 0.990051, loss_s1: 0.502844, loss_fp: 0.500113, loss_freq: 0.501772
[02:33:55.962] iteration 484: loss: 0.928118, loss_s1: 0.506917, loss_fp: 0.500256, loss_freq: 0.501125
[02:33:56.553] iteration 485: loss: 1.014264, loss_s1: 0.506814, loss_fp: 0.500319, loss_freq: 0.503034
[02:33:57.144] iteration 486: loss: 0.930566, loss_s1: 0.503621, loss_fp: 0.500054, loss_freq: 0.501763
[02:33:57.736] iteration 487: loss: 1.001229, loss_s1: 0.504528, loss_fp: 0.500404, loss_freq: 0.500475
[02:33:58.339] iteration 488: loss: 0.967978, loss_s1: 0.506477, loss_fp: 0.500088, loss_freq: 0.500577
[02:33:58.944] iteration 489: loss: 0.976514, loss_s1: 0.503389, loss_fp: 0.500046, loss_freq: 0.501376
[02:33:59.555] iteration 490: loss: 0.938728, loss_s1: 0.503523, loss_fp: 0.500074, loss_freq: 0.501318
[02:34:00.159] iteration 491: loss: 0.975141, loss_s1: 0.506736, loss_fp: 0.500047, loss_freq: 0.502808
[02:34:00.749] iteration 492: loss: 1.040354, loss_s1: 0.504471, loss_fp: 0.500081, loss_freq: 0.500875
[02:34:01.336] iteration 493: loss: 0.990355, loss_s1: 0.504247, loss_fp: 0.500711, loss_freq: 0.501605
[02:34:01.923] iteration 494: loss: 1.011186, loss_s1: 0.503291, loss_fp: 0.500166, loss_freq: 0.500780
[02:34:02.512] iteration 495: loss: 0.981261, loss_s1: 0.506074, loss_fp: 0.500341, loss_freq: 0.501280
[02:34:03.103] iteration 496: loss: 0.978765, loss_s1: 0.505452, loss_fp: 0.500048, loss_freq: 0.501314
[02:34:03.686] iteration 497: loss: 0.987951, loss_s1: 0.503336, loss_fp: 0.500449, loss_freq: 0.501603
[02:34:04.297] iteration 498: loss: 0.948104, loss_s1: 0.504976, loss_fp: 0.500077, loss_freq: 0.500553
[02:34:04.882] iteration 499: loss: 0.914202, loss_s1: 0.502385, loss_fp: 0.500060, loss_freq: 0.501294
[02:34:05.467] iteration 500: loss: 0.950010, loss_s1: 0.502593, loss_fp: 0.500123, loss_freq: 0.500235
[02:34:06.054] iteration 501: loss: 0.983591, loss_s1: 0.501458, loss_fp: 0.500288, loss_freq: 0.500569
[02:34:06.637] iteration 502: loss: 0.921353, loss_s1: 0.501126, loss_fp: 0.500041, loss_freq: 0.500458
[02:34:07.225] iteration 503: loss: 0.993268, loss_s1: 0.502474, loss_fp: 0.500435, loss_freq: 0.502605
[02:34:07.811] iteration 504: loss: 0.938260, loss_s1: 0.502126, loss_fp: 0.500305, loss_freq: 0.500440
[02:34:08.401] iteration 505: loss: 0.915601, loss_s1: 0.504636, loss_fp: 0.500111, loss_freq: 0.500263
[02:34:08.994] iteration 506: loss: 0.966448, loss_s1: 0.503954, loss_fp: 0.500623, loss_freq: 0.501146
[02:34:09.583] iteration 507: loss: 0.925419, loss_s1: 0.503319, loss_fp: 0.500129, loss_freq: 0.500489
[02:34:10.173] iteration 508: loss: 0.930709, loss_s1: 0.505793, loss_fp: 0.500113, loss_freq: 0.500439
[02:34:10.762] iteration 509: loss: 1.001606, loss_s1: 0.512094, loss_fp: 0.500097, loss_freq: 0.500478
[02:34:11.355] iteration 510: loss: 0.953338, loss_s1: 0.506779, loss_fp: 0.500152, loss_freq: 0.502714
[02:34:12.306] iteration 511: loss: 0.909744, loss_s1: 0.504650, loss_fp: 0.500141, loss_freq: 0.501061
[02:34:12.933] iteration 512: loss: 0.944410, loss_s1: 0.502259, loss_fp: 0.500090, loss_freq: 0.500591
[02:34:13.568] iteration 513: loss: 0.940958, loss_s1: 0.504116, loss_fp: 0.500063, loss_freq: 0.501511
[02:34:14.196] iteration 514: loss: 0.946983, loss_s1: 0.502604, loss_fp: 0.500036, loss_freq: 0.502052
[02:34:14.811] iteration 515: loss: 0.942188, loss_s1: 0.507372, loss_fp: 0.500072, loss_freq: 0.501840
[02:34:15.404] iteration 516: loss: 0.955964, loss_s1: 0.505447, loss_fp: 0.500294, loss_freq: 0.501002
[02:34:15.994] iteration 517: loss: 0.948374, loss_s1: 0.512160, loss_fp: 0.500162, loss_freq: 0.502094
[02:34:16.587] iteration 518: loss: 0.969937, loss_s1: 0.502761, loss_fp: 0.500666, loss_freq: 0.500391
[02:34:17.179] iteration 519: loss: 0.941303, loss_s1: 0.503417, loss_fp: 0.500143, loss_freq: 0.502447
[02:34:17.770] iteration 520: loss: 0.978972, loss_s1: 0.505329, loss_fp: 0.500199, loss_freq: 0.500335
[02:34:18.359] iteration 521: loss: 0.927551, loss_s1: 0.507460, loss_fp: 0.500229, loss_freq: 0.506523
[02:34:18.945] iteration 522: loss: 0.958703, loss_s1: 0.509387, loss_fp: 0.500173, loss_freq: 0.501225
[02:34:19.551] iteration 523: loss: 0.961960, loss_s1: 0.506229, loss_fp: 0.500469, loss_freq: 0.505334
[02:34:20.140] iteration 524: loss: 0.960986, loss_s1: 0.506549, loss_fp: 0.500170, loss_freq: 0.500715
[02:34:20.734] iteration 525: loss: 1.014994, loss_s1: 0.504212, loss_fp: 0.500121, loss_freq: 0.500539
[02:34:21.325] iteration 526: loss: 0.975127, loss_s1: 0.500675, loss_fp: 0.500143, loss_freq: 0.500675
[02:34:21.912] iteration 527: loss: 0.964840, loss_s1: 0.508529, loss_fp: 0.500230, loss_freq: 0.500518
[02:34:22.499] iteration 528: loss: 0.961276, loss_s1: 0.508957, loss_fp: 0.500169, loss_freq: 0.500439
[02:34:23.085] iteration 529: loss: 0.935132, loss_s1: 0.510203, loss_fp: 0.500072, loss_freq: 0.500298
[02:34:23.668] iteration 530: loss: 0.990620, loss_s1: 0.502385, loss_fp: 0.500165, loss_freq: 0.500739
[02:34:24.253] iteration 531: loss: 0.980203, loss_s1: 0.506050, loss_fp: 0.500062, loss_freq: 0.501925
[02:34:24.839] iteration 532: loss: 1.011593, loss_s1: 0.505005, loss_fp: 0.500045, loss_freq: 0.500653
[02:34:25.423] iteration 533: loss: 0.995315, loss_s1: 0.504849, loss_fp: 0.500081, loss_freq: 0.500457
[02:34:26.071] iteration 534: loss: 0.960172, loss_s1: 0.504402, loss_fp: 0.500194, loss_freq: 0.500911
[02:34:26.721] iteration 535: loss: 0.957984, loss_s1: 0.504638, loss_fp: 0.500045, loss_freq: 0.500799
[02:34:27.329] iteration 536: loss: 0.973753, loss_s1: 0.502560, loss_fp: 0.500055, loss_freq: 0.500616
[02:34:27.929] iteration 537: loss: 0.927611, loss_s1: 0.501833, loss_fp: 0.500109, loss_freq: 0.500500
[02:34:28.536] iteration 538: loss: 0.956255, loss_s1: 0.502543, loss_fp: 0.500115, loss_freq: 0.502415
[02:34:29.141] iteration 539: loss: 1.067502, loss_s1: 0.506003, loss_fp: 0.500136, loss_freq: 0.501768
[02:34:29.742] iteration 540: loss: 0.997243, loss_s1: 0.503081, loss_fp: 0.500110, loss_freq: 0.501352
[02:34:30.350] iteration 541: loss: 0.897442, loss_s1: 0.504053, loss_fp: 0.500259, loss_freq: 0.502123
[02:34:30.952] iteration 542: loss: 0.997293, loss_s1: 0.508212, loss_fp: 0.500120, loss_freq: 0.500734
[02:34:31.573] iteration 543: loss: 0.956615, loss_s1: 0.502937, loss_fp: 0.500109, loss_freq: 0.500957
[02:34:32.238] iteration 544: loss: 0.960900, loss_s1: 0.501115, loss_fp: 0.500161, loss_freq: 0.501257
[02:34:32.861] iteration 545: loss: 0.957011, loss_s1: 0.503934, loss_fp: 0.500171, loss_freq: 0.501117
[02:34:33.486] iteration 546: loss: 0.958963, loss_s1: 0.504348, loss_fp: 0.500091, loss_freq: 0.500639
[02:34:34.107] iteration 547: loss: 0.922523, loss_s1: 0.505661, loss_fp: 0.500101, loss_freq: 0.500525
[02:34:34.714] iteration 548: loss: 0.986919, loss_s1: 0.503494, loss_fp: 0.500124, loss_freq: 0.500463
[02:34:35.306] iteration 549: loss: 0.940085, loss_s1: 0.504036, loss_fp: 0.500174, loss_freq: 0.500600
[02:34:35.894] iteration 550: loss: 0.936624, loss_s1: 0.506687, loss_fp: 0.500112, loss_freq: 0.500970
[02:34:36.519] iteration 551: loss: 0.941788, loss_s1: 0.502829, loss_fp: 0.500138, loss_freq: 0.501584
[02:34:37.145] iteration 552: loss: 0.929313, loss_s1: 0.505281, loss_fp: 0.500191, loss_freq: 0.500652
[02:34:37.779] iteration 553: loss: 0.972132, loss_s1: 0.502699, loss_fp: 0.500236, loss_freq: 0.501318
[02:34:38.389] iteration 554: loss: 0.909218, loss_s1: 0.502095, loss_fp: 0.500063, loss_freq: 0.500953
[02:34:38.996] iteration 555: loss: 0.924294, loss_s1: 0.503900, loss_fp: 0.500178, loss_freq: 0.500726
[02:34:39.610] iteration 556: loss: 0.946961, loss_s1: 0.508834, loss_fp: 0.501115, loss_freq: 0.503195
[02:34:40.211] iteration 557: loss: 0.970541, loss_s1: 0.507326, loss_fp: 0.500335, loss_freq: 0.500567
[02:34:40.819] iteration 558: loss: 0.977471, loss_s1: 0.502136, loss_fp: 0.500235, loss_freq: 0.501934
[02:34:41.429] iteration 559: loss: 0.952462, loss_s1: 0.502249, loss_fp: 0.500134, loss_freq: 0.500551
[02:34:42.036] iteration 560: loss: 0.915858, loss_s1: 0.505797, loss_fp: 0.500058, loss_freq: 0.501146
[02:34:42.640] iteration 561: loss: 0.964297, loss_s1: 0.511971, loss_fp: 0.500111, loss_freq: 0.501342
[02:34:43.249] iteration 562: loss: 0.901384, loss_s1: 0.501452, loss_fp: 0.500078, loss_freq: 0.500356
[02:34:43.856] iteration 563: loss: 0.966555, loss_s1: 0.505245, loss_fp: 0.500133, loss_freq: 0.501880
[02:34:44.469] iteration 564: loss: 0.919280, loss_s1: 0.505623, loss_fp: 0.500123, loss_freq: 0.501970
[02:34:45.074] iteration 565: loss: 0.949130, loss_s1: 0.503875, loss_fp: 0.500107, loss_freq: 0.500903
[02:34:45.687] iteration 566: loss: 0.953496, loss_s1: 0.504104, loss_fp: 0.500044, loss_freq: 0.500903
[02:34:46.297] iteration 567: loss: 0.911030, loss_s1: 0.502422, loss_fp: 0.500367, loss_freq: 0.500896
[02:34:46.905] iteration 568: loss: 0.973257, loss_s1: 0.504741, loss_fp: 0.500207, loss_freq: 0.501403
[02:34:47.513] iteration 569: loss: 0.954776, loss_s1: 0.500862, loss_fp: 0.500203, loss_freq: 0.500324
[02:34:48.119] iteration 570: loss: 0.922242, loss_s1: 0.508698, loss_fp: 0.500249, loss_freq: 0.500497
[02:34:48.727] iteration 571: loss: 0.937680, loss_s1: 0.502241, loss_fp: 0.500265, loss_freq: 0.500307
[02:34:49.343] iteration 572: loss: 0.959441, loss_s1: 0.504579, loss_fp: 0.500155, loss_freq: 0.500239
[02:34:49.952] iteration 573: loss: 0.921295, loss_s1: 0.509884, loss_fp: 0.500591, loss_freq: 0.500964
[02:34:50.558] iteration 574: loss: 0.951334, loss_s1: 0.500556, loss_fp: 0.500030, loss_freq: 0.500282
[02:34:51.161] iteration 575: loss: 0.943316, loss_s1: 0.501805, loss_fp: 0.500239, loss_freq: 0.500209
[02:34:51.766] iteration 576: loss: 0.887160, loss_s1: 0.504369, loss_fp: 0.500139, loss_freq: 0.501972
[02:34:52.370] iteration 577: loss: 0.989472, loss_s1: 0.503145, loss_fp: 0.500127, loss_freq: 0.500403
[02:34:52.973] iteration 578: loss: 0.916323, loss_s1: 0.505853, loss_fp: 0.500081, loss_freq: 0.500400
[02:34:53.577] iteration 579: loss: 0.959143, loss_s1: 0.506126, loss_fp: 0.500150, loss_freq: 0.502169
[02:34:54.191] iteration 580: loss: 0.909049, loss_s1: 0.504975, loss_fp: 0.500168, loss_freq: 0.500464
[02:34:54.781] iteration 581: loss: 0.912086, loss_s1: 0.504353, loss_fp: 0.500051, loss_freq: 0.500790
[02:34:55.411] iteration 582: loss: 0.940323, loss_s1: 0.504042, loss_fp: 0.500031, loss_freq: 0.500790
[02:34:56.036] iteration 583: loss: 0.959757, loss_s1: 0.503954, loss_fp: 0.500164, loss_freq: 0.500922
[02:34:56.673] iteration 584: loss: 0.914673, loss_s1: 0.506316, loss_fp: 0.500124, loss_freq: 0.501137
[02:34:57.309] iteration 585: loss: 0.935113, loss_s1: 0.511778, loss_fp: 0.500596, loss_freq: 0.503652
[02:34:57.940] iteration 586: loss: 0.944100, loss_s1: 0.504109, loss_fp: 0.500211, loss_freq: 0.501085
[02:34:58.529] iteration 587: loss: 0.922953, loss_s1: 0.503370, loss_fp: 0.500366, loss_freq: 0.501188
[02:34:59.124] iteration 588: loss: 0.948576, loss_s1: 0.502235, loss_fp: 0.500157, loss_freq: 0.501552
[02:34:59.714] iteration 589: loss: 0.929954, loss_s1: 0.508912, loss_fp: 0.501122, loss_freq: 0.501544
[02:35:00.302] iteration 590: loss: 0.930866, loss_s1: 0.506829, loss_fp: 0.500462, loss_freq: 0.501028
[02:35:00.892] iteration 591: loss: 0.923957, loss_s1: 0.505816, loss_fp: 0.500239, loss_freq: 0.502875
[02:35:01.479] iteration 592: loss: 0.934701, loss_s1: 0.508790, loss_fp: 0.500234, loss_freq: 0.501853
[02:35:02.069] iteration 593: loss: 0.981892, loss_s1: 0.504729, loss_fp: 0.500370, loss_freq: 0.501017
[02:35:02.733] iteration 594: loss: 0.902144, loss_s1: 0.504538, loss_fp: 0.500438, loss_freq: 0.502887
[02:35:03.359] iteration 595: loss: 0.984314, loss_s1: 0.504691, loss_fp: 0.500246, loss_freq: 0.503580
[02:35:03.984] iteration 596: loss: 0.950117, loss_s1: 0.502180, loss_fp: 0.500226, loss_freq: 0.501075
[02:35:04.615] iteration 597: loss: 0.916431, loss_s1: 0.501249, loss_fp: 0.500573, loss_freq: 0.500150
[02:35:05.205] iteration 598: loss: 0.961587, loss_s1: 0.505929, loss_fp: 0.500184, loss_freq: 0.501604
[02:35:05.790] iteration 599: loss: 0.902632, loss_s1: 0.506080, loss_fp: 0.500183, loss_freq: 0.501160
[02:35:06.381] iteration 600: loss: 0.987494, loss_s1: 0.504787, loss_fp: 0.500229, loss_freq: 0.501646
[02:35:08.520] iteration 600 : mean_dice : 0.072932
[02:35:09.152] iteration 601: loss: 0.963395, loss_s1: 0.506459, loss_fp: 0.500208, loss_freq: 0.500908
[02:35:09.745] iteration 602: loss: 0.934877, loss_s1: 0.501524, loss_fp: 0.500049, loss_freq: 0.500564
[02:35:10.380] iteration 603: loss: 0.984045, loss_s1: 0.505887, loss_fp: 0.500120, loss_freq: 0.500789
[02:35:11.010] iteration 604: loss: 0.910584, loss_s1: 0.509228, loss_fp: 0.500175, loss_freq: 0.500645
[02:35:11.640] iteration 605: loss: 0.951586, loss_s1: 0.504629, loss_fp: 0.500115, loss_freq: 0.500176
[02:35:12.228] iteration 606: loss: 0.929977, loss_s1: 0.505174, loss_fp: 0.500186, loss_freq: 0.500365
[02:35:12.817] iteration 607: loss: 0.941452, loss_s1: 0.504559, loss_fp: 0.500111, loss_freq: 0.500268
[02:35:13.406] iteration 608: loss: 0.944255, loss_s1: 0.503863, loss_fp: 0.501165, loss_freq: 0.503139
[02:35:14.057] iteration 609: loss: 0.972801, loss_s1: 0.503727, loss_fp: 0.500143, loss_freq: 0.500591
[02:35:14.686] iteration 610: loss: 0.983312, loss_s1: 0.504122, loss_fp: 0.500102, loss_freq: 0.501111
[02:35:15.315] iteration 611: loss: 0.900694, loss_s1: 0.509293, loss_fp: 0.500134, loss_freq: 0.502850
[02:35:15.939] iteration 612: loss: 0.955148, loss_s1: 0.507066, loss_fp: 0.500273, loss_freq: 0.501339
[02:35:16.566] iteration 613: loss: 0.954403, loss_s1: 0.503836, loss_fp: 0.500049, loss_freq: 0.500420
[02:35:17.153] iteration 614: loss: 0.947384, loss_s1: 0.507040, loss_fp: 0.500202, loss_freq: 0.502343
[02:35:17.738] iteration 615: loss: 0.926342, loss_s1: 0.506602, loss_fp: 0.500042, loss_freq: 0.500709
[02:35:18.319] iteration 616: loss: 0.914766, loss_s1: 0.503140, loss_fp: 0.500386, loss_freq: 0.500382
[02:35:18.906] iteration 617: loss: 0.898059, loss_s1: 0.507772, loss_fp: 0.500390, loss_freq: 0.500926
[02:35:19.489] iteration 618: loss: 0.980041, loss_s1: 0.504127, loss_fp: 0.500187, loss_freq: 0.501526
[02:35:20.078] iteration 619: loss: 0.944848, loss_s1: 0.508572, loss_fp: 0.500245, loss_freq: 0.507495
[02:35:20.669] iteration 620: loss: 0.978211, loss_s1: 0.504601, loss_fp: 0.500065, loss_freq: 0.500538
[02:35:21.258] iteration 621: loss: 0.931722, loss_s1: 0.503471, loss_fp: 0.500051, loss_freq: 0.501695
[02:35:21.848] iteration 622: loss: 0.929698, loss_s1: 0.507808, loss_fp: 0.500194, loss_freq: 0.502535
[02:35:22.433] iteration 623: loss: 0.963323, loss_s1: 0.503938, loss_fp: 0.500131, loss_freq: 0.500535
[02:35:23.021] iteration 624: loss: 1.009465, loss_s1: 0.512933, loss_fp: 0.500122, loss_freq: 0.503482
[02:35:23.606] iteration 625: loss: 0.961560, loss_s1: 0.504740, loss_fp: 0.500170, loss_freq: 0.505703
[02:35:24.198] iteration 626: loss: 0.977592, loss_s1: 0.509349, loss_fp: 0.500343, loss_freq: 0.507335
[02:35:24.786] iteration 627: loss: 0.994547, loss_s1: 0.506801, loss_fp: 0.500759, loss_freq: 0.503281
[02:35:25.373] iteration 628: loss: 1.008770, loss_s1: 0.503624, loss_fp: 0.500117, loss_freq: 0.501539
[02:35:25.958] iteration 629: loss: 0.958047, loss_s1: 0.509619, loss_fp: 0.500102, loss_freq: 0.505622
[02:35:26.546] iteration 630: loss: 0.962554, loss_s1: 0.507186, loss_fp: 0.500081, loss_freq: 0.504683
[02:35:27.136] iteration 631: loss: 0.961083, loss_s1: 0.502194, loss_fp: 0.500447, loss_freq: 0.500441
[02:35:27.725] iteration 632: loss: 0.943704, loss_s1: 0.511205, loss_fp: 0.500487, loss_freq: 0.500277
[02:35:28.318] iteration 633: loss: 0.930919, loss_s1: 0.506210, loss_fp: 0.500724, loss_freq: 0.500974
[02:35:28.904] iteration 634: loss: 0.916364, loss_s1: 0.510820, loss_fp: 0.500162, loss_freq: 0.501221
[02:35:29.490] iteration 635: loss: 0.962769, loss_s1: 0.505999, loss_fp: 0.500071, loss_freq: 0.500133
[02:35:30.077] iteration 636: loss: 0.977310, loss_s1: 0.503012, loss_fp: 0.500058, loss_freq: 0.500287
[02:35:30.667] iteration 637: loss: 0.967779, loss_s1: 0.504418, loss_fp: 0.500057, loss_freq: 0.501483
[02:35:31.334] iteration 638: loss: 0.974885, loss_s1: 0.505094, loss_fp: 0.500150, loss_freq: 0.502407
[02:35:31.964] iteration 639: loss: 0.938475, loss_s1: 0.501804, loss_fp: 0.500077, loss_freq: 0.500550
[02:35:32.596] iteration 640: loss: 0.977372, loss_s1: 0.503491, loss_fp: 0.500316, loss_freq: 0.502966
[02:35:33.227] iteration 641: loss: 0.974630, loss_s1: 0.501156, loss_fp: 0.500198, loss_freq: 0.500251
[02:35:33.859] iteration 642: loss: 0.958540, loss_s1: 0.502805, loss_fp: 0.500184, loss_freq: 0.500821
[02:35:34.453] iteration 643: loss: 0.920204, loss_s1: 0.503737, loss_fp: 0.500174, loss_freq: 0.500918
[02:35:35.041] iteration 644: loss: 0.972564, loss_s1: 0.510835, loss_fp: 0.500080, loss_freq: 0.500328
[02:35:35.630] iteration 645: loss: 1.016993, loss_s1: 0.501865, loss_fp: 0.500086, loss_freq: 0.500837
[02:35:36.220] iteration 646: loss: 0.910124, loss_s1: 0.501163, loss_fp: 0.500200, loss_freq: 0.501828
[02:35:36.811] iteration 647: loss: 0.971784, loss_s1: 0.504961, loss_fp: 0.500370, loss_freq: 0.502793
[02:35:37.402] iteration 648: loss: 0.934998, loss_s1: 0.504689, loss_fp: 0.500112, loss_freq: 0.500984
[02:35:37.987] iteration 649: loss: 0.968985, loss_s1: 0.506963, loss_fp: 0.500039, loss_freq: 0.501124
[02:35:38.577] iteration 650: loss: 0.984490, loss_s1: 0.501850, loss_fp: 0.500170, loss_freq: 0.500708
[02:35:39.164] iteration 651: loss: 0.927605, loss_s1: 0.505149, loss_fp: 0.500474, loss_freq: 0.500605
[02:35:39.755] iteration 652: loss: 0.955391, loss_s1: 0.507839, loss_fp: 0.500297, loss_freq: 0.501092
[02:35:40.347] iteration 653: loss: 0.962709, loss_s1: 0.509785, loss_fp: 0.500066, loss_freq: 0.500653
[02:35:40.943] iteration 654: loss: 0.984563, loss_s1: 0.507206, loss_fp: 0.500093, loss_freq: 0.500519
[02:35:41.530] iteration 655: loss: 0.940775, loss_s1: 0.505370, loss_fp: 0.500197, loss_freq: 0.501251
[02:35:42.118] iteration 656: loss: 0.958315, loss_s1: 0.504661, loss_fp: 0.500517, loss_freq: 0.501204
[02:35:42.727] iteration 657: loss: 0.959861, loss_s1: 0.501874, loss_fp: 0.500085, loss_freq: 0.500428
[02:35:43.319] iteration 658: loss: 0.975844, loss_s1: 0.504996, loss_fp: 0.500120, loss_freq: 0.500314
[02:35:43.910] iteration 659: loss: 0.947237, loss_s1: 0.505671, loss_fp: 0.500264, loss_freq: 0.501358
[02:35:44.499] iteration 660: loss: 0.963021, loss_s1: 0.501270, loss_fp: 0.500161, loss_freq: 0.500656
[02:35:45.083] iteration 661: loss: 0.940090, loss_s1: 0.504250, loss_fp: 0.500100, loss_freq: 0.501649
[02:35:45.669] iteration 662: loss: 0.996061, loss_s1: 0.505782, loss_fp: 0.500287, loss_freq: 0.501488
[02:35:46.253] iteration 663: loss: 0.943672, loss_s1: 0.504942, loss_fp: 0.500258, loss_freq: 0.504088
[02:35:46.839] iteration 664: loss: 0.936764, loss_s1: 0.503785, loss_fp: 0.500091, loss_freq: 0.500665
[02:35:47.429] iteration 665: loss: 0.969911, loss_s1: 0.502849, loss_fp: 0.500096, loss_freq: 0.501286
[02:35:48.018] iteration 666: loss: 0.935926, loss_s1: 0.504018, loss_fp: 0.500265, loss_freq: 0.501178
[02:35:48.603] iteration 667: loss: 0.917547, loss_s1: 0.502276, loss_fp: 0.500326, loss_freq: 0.502008
[02:35:49.189] iteration 668: loss: 0.945061, loss_s1: 0.502892, loss_fp: 0.500666, loss_freq: 0.501587
[02:35:49.784] iteration 669: loss: 0.906254, loss_s1: 0.505423, loss_fp: 0.500205, loss_freq: 0.504671
[02:35:50.374] iteration 670: loss: 0.948501, loss_s1: 0.506022, loss_fp: 0.500178, loss_freq: 0.500404
[02:35:50.962] iteration 671: loss: 0.959816, loss_s1: 0.501879, loss_fp: 0.500488, loss_freq: 0.500952
[02:35:51.555] iteration 672: loss: 0.907633, loss_s1: 0.502006, loss_fp: 0.500046, loss_freq: 0.501821
[02:35:52.148] iteration 673: loss: 0.943929, loss_s1: 0.503234, loss_fp: 0.500103, loss_freq: 0.503425
[02:35:52.735] iteration 674: loss: 0.906479, loss_s1: 0.502307, loss_fp: 0.500273, loss_freq: 0.501123
[02:35:53.370] iteration 675: loss: 0.906976, loss_s1: 0.505969, loss_fp: 0.500460, loss_freq: 0.500457
[02:35:54.003] iteration 676: loss: 0.938630, loss_s1: 0.507635, loss_fp: 0.500247, loss_freq: 0.500762
[02:35:54.654] iteration 677: loss: 0.949661, loss_s1: 0.503559, loss_fp: 0.500096, loss_freq: 0.501592
[02:35:55.282] iteration 678: loss: 0.911534, loss_s1: 0.504281, loss_fp: 0.500119, loss_freq: 0.500723
[02:35:55.866] iteration 679: loss: 0.999230, loss_s1: 0.507189, loss_fp: 0.500149, loss_freq: 0.500627
[02:35:56.452] iteration 680: loss: 0.944296, loss_s1: 0.506371, loss_fp: 0.501563, loss_freq: 0.503544
[02:35:57.387] iteration 681: loss: 0.930264, loss_s1: 0.502182, loss_fp: 0.500146, loss_freq: 0.500682
[02:35:58.015] iteration 682: loss: 0.932908, loss_s1: 0.508861, loss_fp: 0.500428, loss_freq: 0.500709
[02:35:58.627] iteration 683: loss: 0.933263, loss_s1: 0.504061, loss_fp: 0.500195, loss_freq: 0.500250
[02:35:59.214] iteration 684: loss: 0.956036, loss_s1: 0.504595, loss_fp: 0.500198, loss_freq: 0.502401
[02:35:59.803] iteration 685: loss: 0.897354, loss_s1: 0.502360, loss_fp: 0.500255, loss_freq: 0.500537
[02:36:00.393] iteration 686: loss: 0.926861, loss_s1: 0.506296, loss_fp: 0.500060, loss_freq: 0.500972
[02:36:00.979] iteration 687: loss: 0.975457, loss_s1: 0.507389, loss_fp: 0.500155, loss_freq: 0.501789
[02:36:01.566] iteration 688: loss: 0.988145, loss_s1: 0.504231, loss_fp: 0.500069, loss_freq: 0.501352
[02:36:02.393] iteration 689: loss: 0.986887, loss_s1: 0.507470, loss_fp: 0.500118, loss_freq: 0.502217
[02:36:03.254] iteration 690: loss: 0.954649, loss_s1: 0.505701, loss_fp: 0.500081, loss_freq: 0.501363
[02:36:04.017] iteration 691: loss: 0.960268, loss_s1: 0.505504, loss_fp: 0.500047, loss_freq: 0.503296
[02:36:04.762] iteration 692: loss: 0.948918, loss_s1: 0.504542, loss_fp: 0.500050, loss_freq: 0.501595
[02:36:05.400] iteration 693: loss: 0.945440, loss_s1: 0.512826, loss_fp: 0.500322, loss_freq: 0.503663
[02:36:06.023] iteration 694: loss: 0.921223, loss_s1: 0.507098, loss_fp: 0.500219, loss_freq: 0.500888
[02:36:06.649] iteration 695: loss: 0.977960, loss_s1: 0.505016, loss_fp: 0.500053, loss_freq: 0.500626
[02:36:07.242] iteration 696: loss: 0.936527, loss_s1: 0.507172, loss_fp: 0.500183, loss_freq: 0.500594
[02:36:07.823] iteration 697: loss: 0.928056, loss_s1: 0.502101, loss_fp: 0.500091, loss_freq: 0.500340
[02:36:08.406] iteration 698: loss: 0.946780, loss_s1: 0.505686, loss_fp: 0.500083, loss_freq: 0.500425
[02:36:09.024] iteration 699: loss: 0.903636, loss_s1: 0.504626, loss_fp: 0.500081, loss_freq: 0.500401
[02:36:09.610] iteration 700: loss: 0.936629, loss_s1: 0.504847, loss_fp: 0.500121, loss_freq: 0.500603
[02:36:10.197] iteration 701: loss: 0.954982, loss_s1: 0.504194, loss_fp: 0.500038, loss_freq: 0.501642
[02:36:10.785] iteration 702: loss: 0.953620, loss_s1: 0.505845, loss_fp: 0.500540, loss_freq: 0.504620
[02:36:11.368] iteration 703: loss: 0.972854, loss_s1: 0.505362, loss_fp: 0.500097, loss_freq: 0.500865
[02:36:11.959] iteration 704: loss: 0.915764, loss_s1: 0.509360, loss_fp: 0.500033, loss_freq: 0.501740
[02:36:12.553] iteration 705: loss: 0.903817, loss_s1: 0.505900, loss_fp: 0.500131, loss_freq: 0.500936
[02:36:13.138] iteration 706: loss: 0.949661, loss_s1: 0.504517, loss_fp: 0.500421, loss_freq: 0.501009
[02:36:13.765] iteration 707: loss: 0.900865, loss_s1: 0.503597, loss_fp: 0.500121, loss_freq: 0.501001
[02:36:14.352] iteration 708: loss: 0.920771, loss_s1: 0.505116, loss_fp: 0.500380, loss_freq: 0.502561
[02:36:14.940] iteration 709: loss: 0.992054, loss_s1: 0.506987, loss_fp: 0.500310, loss_freq: 0.503747
[02:36:15.525] iteration 710: loss: 0.993965, loss_s1: 0.505541, loss_fp: 0.500032, loss_freq: 0.500813
[02:36:16.108] iteration 711: loss: 0.883008, loss_s1: 0.505456, loss_fp: 0.500211, loss_freq: 0.500871
[02:36:16.693] iteration 712: loss: 0.974370, loss_s1: 0.505088, loss_fp: 0.500129, loss_freq: 0.505039
[02:36:17.276] iteration 713: loss: 0.954636, loss_s1: 0.509425, loss_fp: 0.500252, loss_freq: 0.502067
[02:36:17.861] iteration 714: loss: 0.959499, loss_s1: 0.505524, loss_fp: 0.500050, loss_freq: 0.504287
[02:36:18.458] iteration 715: loss: 0.962954, loss_s1: 0.501989, loss_fp: 0.500126, loss_freq: 0.501486
[02:36:19.046] iteration 716: loss: 0.909353, loss_s1: 0.503815, loss_fp: 0.500096, loss_freq: 0.500704
[02:36:19.636] iteration 717: loss: 0.926976, loss_s1: 0.507463, loss_fp: 0.500294, loss_freq: 0.501854
[02:36:20.223] iteration 718: loss: 0.931979, loss_s1: 0.501600, loss_fp: 0.500042, loss_freq: 0.500603
[02:36:20.809] iteration 719: loss: 0.928432, loss_s1: 0.504387, loss_fp: 0.500045, loss_freq: 0.500901
[02:36:21.396] iteration 720: loss: 0.932796, loss_s1: 0.504090, loss_fp: 0.500216, loss_freq: 0.501245
[02:36:22.010] iteration 721: loss: 0.947046, loss_s1: 0.509803, loss_fp: 0.500059, loss_freq: 0.501553
[02:36:22.595] iteration 722: loss: 0.925526, loss_s1: 0.503275, loss_fp: 0.500101, loss_freq: 0.501330
[02:36:23.184] iteration 723: loss: 0.933309, loss_s1: 0.502421, loss_fp: 0.500106, loss_freq: 0.500404
[02:36:23.770] iteration 724: loss: 0.910177, loss_s1: 0.501727, loss_fp: 0.500189, loss_freq: 0.500479
[02:36:24.356] iteration 725: loss: 0.924513, loss_s1: 0.503201, loss_fp: 0.500104, loss_freq: 0.501522
[02:36:24.959] iteration 726: loss: 0.908330, loss_s1: 0.509195, loss_fp: 0.500528, loss_freq: 0.501997
[02:36:25.542] iteration 727: loss: 0.958536, loss_s1: 0.503405, loss_fp: 0.500039, loss_freq: 0.500172
[02:36:26.120] iteration 728: loss: 0.920429, loss_s1: 0.503893, loss_fp: 0.500125, loss_freq: 0.501521
[02:36:26.735] iteration 729: loss: 0.938857, loss_s1: 0.502916, loss_fp: 0.500029, loss_freq: 0.500447
[02:36:27.320] iteration 730: loss: 0.939742, loss_s1: 0.503233, loss_fp: 0.500782, loss_freq: 0.502499
[02:36:27.909] iteration 731: loss: 0.913407, loss_s1: 0.503157, loss_fp: 0.500235, loss_freq: 0.502974
[02:36:28.506] iteration 732: loss: 0.884750, loss_s1: 0.503276, loss_fp: 0.500113, loss_freq: 0.500353
[02:36:29.205] iteration 733: loss: 0.939362, loss_s1: 0.505328, loss_fp: 0.500167, loss_freq: 0.505958
[02:36:29.891] iteration 734: loss: 0.911311, loss_s1: 0.506894, loss_fp: 0.500302, loss_freq: 0.503273
[02:36:30.565] iteration 735: loss: 0.944807, loss_s1: 0.505844, loss_fp: 0.500520, loss_freq: 0.502009
[02:36:31.183] iteration 736: loss: 0.923744, loss_s1: 0.501466, loss_fp: 0.500049, loss_freq: 0.500885
[02:36:31.867] iteration 737: loss: 0.867834, loss_s1: 0.501504, loss_fp: 0.500068, loss_freq: 0.500454
[02:36:32.548] iteration 738: loss: 0.956937, loss_s1: 0.506083, loss_fp: 0.500158, loss_freq: 0.501888
[02:36:33.191] iteration 739: loss: 0.938817, loss_s1: 0.501731, loss_fp: 0.500440, loss_freq: 0.500599
[02:36:33.787] iteration 740: loss: 0.909559, loss_s1: 0.504566, loss_fp: 0.500129, loss_freq: 0.501216
[02:36:34.443] iteration 741: loss: 0.916763, loss_s1: 0.505312, loss_fp: 0.500177, loss_freq: 0.500281
[02:36:35.038] iteration 742: loss: 0.903138, loss_s1: 0.504679, loss_fp: 0.500239, loss_freq: 0.500632
[02:36:35.637] iteration 743: loss: 0.902317, loss_s1: 0.508428, loss_fp: 0.500133, loss_freq: 0.501165
[02:36:36.225] iteration 744: loss: 0.926921, loss_s1: 0.501666, loss_fp: 0.500080, loss_freq: 0.500646
[02:36:36.819] iteration 745: loss: 0.937704, loss_s1: 0.502862, loss_fp: 0.500167, loss_freq: 0.500970
[02:36:37.410] iteration 746: loss: 0.884580, loss_s1: 0.506074, loss_fp: 0.500059, loss_freq: 0.500953
[02:36:37.995] iteration 747: loss: 0.956351, loss_s1: 0.504690, loss_fp: 0.500058, loss_freq: 0.500583
[02:36:38.580] iteration 748: loss: 0.908119, loss_s1: 0.505289, loss_fp: 0.500141, loss_freq: 0.500214
[02:36:39.172] iteration 749: loss: 0.919870, loss_s1: 0.502920, loss_fp: 0.500068, loss_freq: 0.500752
[02:36:39.758] iteration 750: loss: 0.918100, loss_s1: 0.505022, loss_fp: 0.500129, loss_freq: 0.500897
[02:36:40.346] iteration 751: loss: 0.912019, loss_s1: 0.508883, loss_fp: 0.500100, loss_freq: 0.501407
[02:36:40.931] iteration 752: loss: 0.940417, loss_s1: 0.505087, loss_fp: 0.500062, loss_freq: 0.501155
[02:36:41.516] iteration 753: loss: 0.918104, loss_s1: 0.503633, loss_fp: 0.500168, loss_freq: 0.500215
[02:36:42.165] iteration 754: loss: 0.889519, loss_s1: 0.507069, loss_fp: 0.500059, loss_freq: 0.502042
[02:36:42.764] iteration 755: loss: 0.909716, loss_s1: 0.512828, loss_fp: 0.500217, loss_freq: 0.502922
[02:36:43.455] iteration 756: loss: 0.907581, loss_s1: 0.505368, loss_fp: 0.500065, loss_freq: 0.500771
[02:36:44.283] iteration 757: loss: 0.892954, loss_s1: 0.508694, loss_fp: 0.500035, loss_freq: 0.501042
[02:36:45.040] iteration 758: loss: 0.891041, loss_s1: 0.502660, loss_fp: 0.500165, loss_freq: 0.502498
[02:36:45.769] iteration 759: loss: 0.889654, loss_s1: 0.505604, loss_fp: 0.500571, loss_freq: 0.501289
[02:36:46.350] iteration 760: loss: 0.866002, loss_s1: 0.506804, loss_fp: 0.500133, loss_freq: 0.501057
[02:36:46.948] iteration 761: loss: 0.904237, loss_s1: 0.507885, loss_fp: 0.500278, loss_freq: 0.504032
[02:36:47.527] iteration 762: loss: 0.887970, loss_s1: 0.508532, loss_fp: 0.500284, loss_freq: 0.502404
[02:36:48.116] iteration 763: loss: 0.879106, loss_s1: 0.504952, loss_fp: 0.500097, loss_freq: 0.501492
[02:36:48.802] iteration 764: loss: 0.876898, loss_s1: 0.504179, loss_fp: 0.500106, loss_freq: 0.502218
[02:36:49.427] iteration 765: loss: 0.951844, loss_s1: 0.505711, loss_fp: 0.500132, loss_freq: 0.503484
[02:36:50.056] iteration 766: loss: 0.904754, loss_s1: 0.505924, loss_fp: 0.500304, loss_freq: 0.503151
[02:36:50.642] iteration 767: loss: 0.897511, loss_s1: 0.506609, loss_fp: 0.500138, loss_freq: 0.501151
[02:36:51.231] iteration 768: loss: 0.908412, loss_s1: 0.503728, loss_fp: 0.500132, loss_freq: 0.504023
[02:36:51.820] iteration 769: loss: 0.906610, loss_s1: 0.504734, loss_fp: 0.500483, loss_freq: 0.503907
[02:36:52.406] iteration 770: loss: 0.939093, loss_s1: 0.502367, loss_fp: 0.500102, loss_freq: 0.501669
[02:36:52.992] iteration 771: loss: 0.880801, loss_s1: 0.506826, loss_fp: 0.500014, loss_freq: 0.504108
[02:36:53.581] iteration 772: loss: 0.876225, loss_s1: 0.502228, loss_fp: 0.500134, loss_freq: 0.503449
[02:36:54.194] iteration 773: loss: 1.030349, loss_s1: 0.505888, loss_fp: 0.500124, loss_freq: 0.503344
[02:36:54.781] iteration 774: loss: 0.945202, loss_s1: 0.503344, loss_fp: 0.500156, loss_freq: 0.501907
[02:36:55.364] iteration 775: loss: 0.909028, loss_s1: 0.503574, loss_fp: 0.500210, loss_freq: 0.501110
[02:36:55.946] iteration 776: loss: 0.903941, loss_s1: 0.501045, loss_fp: 0.500054, loss_freq: 0.500257
[02:36:56.529] iteration 777: loss: 0.902728, loss_s1: 0.506106, loss_fp: 0.500074, loss_freq: 0.500897
[02:36:57.107] iteration 778: loss: 0.912707, loss_s1: 0.504023, loss_fp: 0.500067, loss_freq: 0.504819
[02:36:57.685] iteration 779: loss: 0.894336, loss_s1: 0.504137, loss_fp: 0.500166, loss_freq: 0.501107
[02:36:58.267] iteration 780: loss: 0.898520, loss_s1: 0.503496, loss_fp: 0.500125, loss_freq: 0.501011
[02:36:58.861] iteration 781: loss: 0.872070, loss_s1: 0.506299, loss_fp: 0.500135, loss_freq: 0.501888
[02:36:59.456] iteration 782: loss: 0.997476, loss_s1: 0.503507, loss_fp: 0.500112, loss_freq: 0.501696
[02:37:00.054] iteration 783: loss: 0.919663, loss_s1: 0.501442, loss_fp: 0.500084, loss_freq: 0.500208
[02:37:00.647] iteration 784: loss: 0.954738, loss_s1: 0.503022, loss_fp: 0.500239, loss_freq: 0.501796
[02:37:01.236] iteration 785: loss: 0.891641, loss_s1: 0.506926, loss_fp: 0.500239, loss_freq: 0.500835
[02:37:01.826] iteration 786: loss: 0.898546, loss_s1: 0.505620, loss_fp: 0.500055, loss_freq: 0.500678
[02:37:02.408] iteration 787: loss: 0.901124, loss_s1: 0.505597, loss_fp: 0.500104, loss_freq: 0.500847
[02:37:02.996] iteration 788: loss: 0.913041, loss_s1: 0.505111, loss_fp: 0.500123, loss_freq: 0.500568
[02:37:03.583] iteration 789: loss: 0.915601, loss_s1: 0.505736, loss_fp: 0.500071, loss_freq: 0.505411
[02:37:04.171] iteration 790: loss: 0.900475, loss_s1: 0.504617, loss_fp: 0.500172, loss_freq: 0.500839
[02:37:04.766] iteration 791: loss: 0.923803, loss_s1: 0.504304, loss_fp: 0.500037, loss_freq: 0.501778
[02:37:05.357] iteration 792: loss: 0.883878, loss_s1: 0.505399, loss_fp: 0.500051, loss_freq: 0.501390
[02:37:05.950] iteration 793: loss: 0.917688, loss_s1: 0.502417, loss_fp: 0.500266, loss_freq: 0.500419
[02:37:06.542] iteration 794: loss: 0.915043, loss_s1: 0.507221, loss_fp: 0.500297, loss_freq: 0.502089
[02:37:07.126] iteration 795: loss: 0.882703, loss_s1: 0.505758, loss_fp: 0.500079, loss_freq: 0.504519
[02:37:07.708] iteration 796: loss: 0.875207, loss_s1: 0.504362, loss_fp: 0.500171, loss_freq: 0.506791
[02:37:08.291] iteration 797: loss: 0.902130, loss_s1: 0.505283, loss_fp: 0.500264, loss_freq: 0.502067
[02:37:08.876] iteration 798: loss: 0.924263, loss_s1: 0.501339, loss_fp: 0.500062, loss_freq: 0.501979
[02:37:09.470] iteration 799: loss: 0.913520, loss_s1: 0.507766, loss_fp: 0.500133, loss_freq: 0.506287
[02:37:10.065] iteration 800: loss: 0.917409, loss_s1: 0.508375, loss_fp: 0.500043, loss_freq: 0.503550
[02:37:12.709] iteration 800 : mean_dice : 0.176398
[02:37:13.323] iteration 801: loss: 0.882176, loss_s1: 0.506656, loss_fp: 0.500249, loss_freq: 0.500715
[02:37:13.908] iteration 802: loss: 0.931583, loss_s1: 0.500809, loss_fp: 0.500109, loss_freq: 0.500488
[02:37:14.493] iteration 803: loss: 0.882654, loss_s1: 0.505226, loss_fp: 0.500197, loss_freq: 0.502204
[02:37:15.083] iteration 804: loss: 0.901854, loss_s1: 0.504903, loss_fp: 0.500068, loss_freq: 0.505342
[02:37:15.666] iteration 805: loss: 0.922537, loss_s1: 0.506641, loss_fp: 0.500180, loss_freq: 0.501533
[02:37:16.247] iteration 806: loss: 0.917129, loss_s1: 0.502814, loss_fp: 0.500101, loss_freq: 0.500668
[02:37:16.834] iteration 807: loss: 0.884560, loss_s1: 0.502862, loss_fp: 0.500070, loss_freq: 0.503121
[02:37:17.421] iteration 808: loss: 0.930192, loss_s1: 0.505966, loss_fp: 0.500094, loss_freq: 0.507842
[02:37:18.011] iteration 809: loss: 0.905027, loss_s1: 0.506029, loss_fp: 0.500151, loss_freq: 0.502978
[02:37:18.599] iteration 810: loss: 0.928612, loss_s1: 0.502220, loss_fp: 0.500144, loss_freq: 0.502691
[02:37:19.183] iteration 811: loss: 0.907138, loss_s1: 0.503991, loss_fp: 0.500320, loss_freq: 0.501010
[02:37:19.765] iteration 812: loss: 0.916640, loss_s1: 0.503620, loss_fp: 0.500095, loss_freq: 0.501306
[02:37:20.349] iteration 813: loss: 0.899687, loss_s1: 0.502704, loss_fp: 0.500461, loss_freq: 0.503176
[02:37:20.942] iteration 814: loss: 0.927741, loss_s1: 0.505425, loss_fp: 0.500044, loss_freq: 0.501661
[02:37:21.525] iteration 815: loss: 0.912352, loss_s1: 0.504675, loss_fp: 0.500050, loss_freq: 0.501013
[02:37:22.114] iteration 816: loss: 0.863799, loss_s1: 0.506060, loss_fp: 0.500234, loss_freq: 0.503182
[02:37:22.698] iteration 817: loss: 0.966291, loss_s1: 0.503436, loss_fp: 0.500019, loss_freq: 0.503314
[02:37:23.281] iteration 818: loss: 0.885427, loss_s1: 0.503939, loss_fp: 0.500324, loss_freq: 0.501867
[02:37:23.864] iteration 819: loss: 0.928535, loss_s1: 0.502541, loss_fp: 0.500034, loss_freq: 0.501508
[02:37:24.445] iteration 820: loss: 0.906358, loss_s1: 0.509552, loss_fp: 0.500434, loss_freq: 0.502636
[02:37:25.029] iteration 821: loss: 0.881180, loss_s1: 0.505467, loss_fp: 0.500355, loss_freq: 0.503915
[02:37:25.611] iteration 822: loss: 0.939886, loss_s1: 0.506245, loss_fp: 0.500086, loss_freq: 0.504366
[02:37:26.193] iteration 823: loss: 0.885634, loss_s1: 0.505056, loss_fp: 0.500074, loss_freq: 0.504548
[02:37:26.774] iteration 824: loss: 0.939807, loss_s1: 0.503524, loss_fp: 0.500086, loss_freq: 0.501844
[02:37:27.379] iteration 825: loss: 0.870254, loss_s1: 0.503075, loss_fp: 0.500145, loss_freq: 0.504003
[02:37:28.033] iteration 826: loss: 0.921530, loss_s1: 0.504235, loss_fp: 0.500316, loss_freq: 0.502220
[02:37:28.665] iteration 827: loss: 0.864497, loss_s1: 0.371919, loss_fp: 0.500207, loss_freq: 0.502371
[02:37:29.296] iteration 828: loss: 0.971819, loss_s1: 0.502853, loss_fp: 0.500080, loss_freq: 0.501054
[02:37:29.925] iteration 829: loss: 0.907300, loss_s1: 0.503431, loss_fp: 0.500469, loss_freq: 0.502542
[02:37:30.516] iteration 830: loss: 0.963876, loss_s1: 0.504644, loss_fp: 0.500231, loss_freq: 0.502312
[02:37:31.105] iteration 831: loss: 0.885847, loss_s1: 0.506137, loss_fp: 0.500059, loss_freq: 0.501429
[02:37:31.695] iteration 832: loss: 0.952131, loss_s1: 0.506966, loss_fp: 0.500066, loss_freq: 0.500647
[02:37:32.282] iteration 833: loss: 1.006407, loss_s1: 0.508542, loss_fp: 0.500332, loss_freq: 0.503567
[02:37:32.878] iteration 834: loss: 0.975457, loss_s1: 0.501439, loss_fp: 0.500284, loss_freq: 0.500991
[02:37:33.473] iteration 835: loss: 0.975093, loss_s1: 0.503536, loss_fp: 0.500048, loss_freq: 0.501034
[02:37:34.071] iteration 836: loss: 0.929343, loss_s1: 0.506770, loss_fp: 0.500310, loss_freq: 0.502033
[02:37:34.660] iteration 837: loss: 0.951723, loss_s1: 0.503654, loss_fp: 0.500060, loss_freq: 0.502287
[02:37:35.257] iteration 838: loss: 0.929817, loss_s1: 0.504941, loss_fp: 0.500103, loss_freq: 0.500779
[02:37:35.883] iteration 839: loss: 0.887177, loss_s1: 0.502632, loss_fp: 0.500060, loss_freq: 0.502015
[02:37:36.509] iteration 840: loss: 0.944254, loss_s1: 0.505165, loss_fp: 0.500153, loss_freq: 0.500319
[02:37:37.139] iteration 841: loss: 0.925895, loss_s1: 0.503121, loss_fp: 0.500106, loss_freq: 0.500842
[02:37:37.798] iteration 842: loss: 0.896322, loss_s1: 0.500898, loss_fp: 0.500036, loss_freq: 0.500571
[02:37:38.397] iteration 843: loss: 0.934186, loss_s1: 0.505754, loss_fp: 0.500128, loss_freq: 0.503057
[02:37:39.082] iteration 844: loss: 0.945788, loss_s1: 0.505812, loss_fp: 0.500110, loss_freq: 0.500657
[02:37:39.754] iteration 845: loss: 0.889837, loss_s1: 0.501903, loss_fp: 0.500061, loss_freq: 0.500286
[02:37:40.349] iteration 846: loss: 0.891881, loss_s1: 0.506942, loss_fp: 0.500341, loss_freq: 0.500621
[02:37:40.966] iteration 847: loss: 0.897310, loss_s1: 0.504053, loss_fp: 0.500516, loss_freq: 0.500616
[02:37:41.564] iteration 848: loss: 0.905641, loss_s1: 0.505173, loss_fp: 0.500358, loss_freq: 0.500754
[02:37:42.150] iteration 849: loss: 0.940812, loss_s1: 0.502349, loss_fp: 0.500081, loss_freq: 0.500468
[02:37:42.813] iteration 850: loss: 0.928224, loss_s1: 0.508355, loss_fp: 0.500203, loss_freq: 0.503785
[02:37:43.693] iteration 851: loss: 0.895535, loss_s1: 0.504694, loss_fp: 0.500473, loss_freq: 0.501745
[02:37:44.333] iteration 852: loss: 0.884218, loss_s1: 0.502623, loss_fp: 0.500072, loss_freq: 0.500495
[02:37:44.977] iteration 853: loss: 0.897010, loss_s1: 0.502539, loss_fp: 0.500243, loss_freq: 0.500481
[02:37:45.619] iteration 854: loss: 0.918142, loss_s1: 0.502569, loss_fp: 0.500032, loss_freq: 0.502880
[02:37:46.266] iteration 855: loss: 0.884594, loss_s1: 0.504866, loss_fp: 0.500058, loss_freq: 0.500562
[02:37:46.884] iteration 856: loss: 0.945287, loss_s1: 0.503759, loss_fp: 0.500111, loss_freq: 0.500711
[02:37:47.496] iteration 857: loss: 0.915300, loss_s1: 0.507911, loss_fp: 0.500062, loss_freq: 0.503435
[02:37:48.103] iteration 858: loss: 0.973830, loss_s1: 0.504845, loss_fp: 0.500042, loss_freq: 0.502677
[02:37:48.715] iteration 859: loss: 0.932836, loss_s1: 0.502963, loss_fp: 0.500211, loss_freq: 0.502179
[02:37:49.302] iteration 860: loss: 0.877490, loss_s1: 0.505557, loss_fp: 0.500089, loss_freq: 0.501877
[02:37:49.888] iteration 861: loss: 0.905863, loss_s1: 0.503280, loss_fp: 0.500077, loss_freq: 0.503319
[02:37:50.479] iteration 862: loss: 0.898837, loss_s1: 0.506546, loss_fp: 0.500062, loss_freq: 0.502025
[02:37:51.079] iteration 863: loss: 0.961411, loss_s1: 0.509435, loss_fp: 0.500312, loss_freq: 0.502561
[02:37:51.663] iteration 864: loss: 0.900654, loss_s1: 0.506965, loss_fp: 0.500134, loss_freq: 0.502140
[02:37:52.247] iteration 865: loss: 0.962657, loss_s1: 0.504449, loss_fp: 0.500037, loss_freq: 0.500943
[02:37:52.838] iteration 866: loss: 0.954697, loss_s1: 0.500905, loss_fp: 0.500148, loss_freq: 0.500637
[02:37:53.459] iteration 867: loss: 0.886709, loss_s1: 0.505395, loss_fp: 0.500227, loss_freq: 0.500498
[02:37:54.046] iteration 868: loss: 0.955094, loss_s1: 0.503717, loss_fp: 0.500089, loss_freq: 0.500677
[02:37:54.637] iteration 869: loss: 0.893644, loss_s1: 0.501370, loss_fp: 0.500082, loss_freq: 0.500699
[02:37:55.222] iteration 870: loss: 0.954249, loss_s1: 0.504154, loss_fp: 0.500132, loss_freq: 0.500634
[02:37:55.810] iteration 871: loss: 0.931292, loss_s1: 0.509222, loss_fp: 0.500107, loss_freq: 0.502147
[02:37:56.400] iteration 872: loss: 0.974908, loss_s1: 0.504579, loss_fp: 0.500033, loss_freq: 0.501468
[02:37:56.989] iteration 873: loss: 0.931078, loss_s1: 0.503834, loss_fp: 0.500405, loss_freq: 0.500611
[02:37:57.579] iteration 874: loss: 0.894750, loss_s1: 0.503552, loss_fp: 0.500103, loss_freq: 0.501229
[02:37:58.231] iteration 875: loss: 0.912707, loss_s1: 0.504280, loss_fp: 0.500123, loss_freq: 0.500862
[02:37:58.858] iteration 876: loss: 0.920866, loss_s1: 0.501662, loss_fp: 0.502278, loss_freq: 0.500453
[02:37:59.466] iteration 877: loss: 0.925393, loss_s1: 0.501868, loss_fp: 0.500181, loss_freq: 0.500742
[02:38:00.064] iteration 878: loss: 0.896879, loss_s1: 0.504399, loss_fp: 0.500162, loss_freq: 0.501364
[02:38:00.686] iteration 879: loss: 0.913086, loss_s1: 0.503853, loss_fp: 0.500243, loss_freq: 0.501021
[02:38:01.316] iteration 880: loss: 0.916516, loss_s1: 0.501662, loss_fp: 0.500101, loss_freq: 0.500270
[02:38:01.951] iteration 881: loss: 0.883827, loss_s1: 0.503451, loss_fp: 0.500242, loss_freq: 0.501307
[02:38:02.574] iteration 882: loss: 0.940353, loss_s1: 0.504601, loss_fp: 0.500187, loss_freq: 0.501233
[02:38:03.198] iteration 883: loss: 0.884210, loss_s1: 0.504480, loss_fp: 0.500378, loss_freq: 0.502766
[02:38:03.825] iteration 884: loss: 0.915630, loss_s1: 0.503394, loss_fp: 0.500230, loss_freq: 0.504046
[02:38:04.407] iteration 885: loss: 0.891499, loss_s1: 0.506034, loss_fp: 0.500279, loss_freq: 0.504418
[02:38:04.998] iteration 886: loss: 0.887668, loss_s1: 0.500854, loss_fp: 0.500125, loss_freq: 0.500518
[02:38:05.585] iteration 887: loss: 0.883945, loss_s1: 0.504021, loss_fp: 0.500354, loss_freq: 0.502482
[02:38:06.179] iteration 888: loss: 0.982574, loss_s1: 0.503820, loss_fp: 0.500148, loss_freq: 0.501047
[02:38:06.789] iteration 889: loss: 0.926342, loss_s1: 0.505440, loss_fp: 0.500213, loss_freq: 0.501380
[02:38:07.398] iteration 890: loss: 0.871613, loss_s1: 0.502907, loss_fp: 0.500075, loss_freq: 0.503474
[02:38:08.322] iteration 891: loss: 0.901883, loss_s1: 0.502153, loss_fp: 0.500371, loss_freq: 0.501286
[02:38:08.970] iteration 892: loss: 0.924629, loss_s1: 0.504091, loss_fp: 0.500210, loss_freq: 0.505049
[02:38:09.575] iteration 893: loss: 0.957415, loss_s1: 0.504335, loss_fp: 0.500118, loss_freq: 0.501424
[02:38:10.163] iteration 894: loss: 0.938421, loss_s1: 0.503220, loss_fp: 0.500165, loss_freq: 0.501575
[02:38:10.755] iteration 895: loss: 0.911136, loss_s1: 0.500749, loss_fp: 0.500102, loss_freq: 0.501714
[02:38:11.346] iteration 896: loss: 0.877748, loss_s1: 0.504996, loss_fp: 0.500271, loss_freq: 0.503687
[02:38:11.929] iteration 897: loss: 0.948132, loss_s1: 0.503285, loss_fp: 0.500228, loss_freq: 0.500921
[02:38:12.517] iteration 898: loss: 0.897511, loss_s1: 0.506417, loss_fp: 0.500231, loss_freq: 0.502543
[02:38:13.112] iteration 899: loss: 0.919566, loss_s1: 0.502066, loss_fp: 0.500277, loss_freq: 0.501769
[02:38:13.708] iteration 900: loss: 0.920669, loss_s1: 0.503853, loss_fp: 0.500087, loss_freq: 0.505854
[02:38:14.302] iteration 901: loss: 0.923930, loss_s1: 0.504300, loss_fp: 0.500179, loss_freq: 0.503591
[02:38:14.899] iteration 902: loss: 0.867332, loss_s1: 0.504340, loss_fp: 0.500128, loss_freq: 0.503649
[02:38:15.486] iteration 903: loss: 0.868770, loss_s1: 0.503186, loss_fp: 0.500095, loss_freq: 0.504810
[02:38:16.074] iteration 904: loss: 0.873546, loss_s1: 0.502662, loss_fp: 0.500246, loss_freq: 0.504816
[02:38:16.670] iteration 905: loss: 0.922943, loss_s1: 0.502125, loss_fp: 0.500105, loss_freq: 0.502158
[02:38:17.255] iteration 906: loss: 0.884858, loss_s1: 0.503363, loss_fp: 0.500201, loss_freq: 0.501451
[02:38:17.846] iteration 907: loss: 0.913569, loss_s1: 0.502757, loss_fp: 0.500281, loss_freq: 0.501505
[02:38:18.430] iteration 908: loss: 0.939901, loss_s1: 0.501646, loss_fp: 0.500175, loss_freq: 0.502068
[02:38:19.023] iteration 909: loss: 0.909952, loss_s1: 0.496987, loss_fp: 0.500079, loss_freq: 0.500588
[02:38:19.609] iteration 910: loss: 0.877857, loss_s1: 0.505570, loss_fp: 0.500028, loss_freq: 0.503902
[02:38:20.197] iteration 911: loss: 0.862385, loss_s1: 0.430013, loss_fp: 0.500162, loss_freq: 0.500473
[02:38:20.784] iteration 912: loss: 0.875717, loss_s1: 0.502101, loss_fp: 0.500084, loss_freq: 0.500562
[02:38:21.376] iteration 913: loss: 0.918759, loss_s1: 0.503476, loss_fp: 0.500088, loss_freq: 0.501774
[02:38:21.970] iteration 914: loss: 0.642942, loss_s1: 0.471954, loss_fp: 0.172381, loss_freq: 0.352771
[02:38:22.558] iteration 915: loss: 0.938941, loss_s1: 0.500734, loss_fp: 0.500048, loss_freq: 0.500870
[02:38:23.147] iteration 916: loss: 0.930292, loss_s1: 0.503387, loss_fp: 0.500028, loss_freq: 0.501737
[02:38:23.774] iteration 917: loss: 1.056416, loss_s1: 0.501438, loss_fp: 0.500027, loss_freq: 0.500700
[02:38:24.412] iteration 918: loss: 0.966087, loss_s1: 0.501890, loss_fp: 0.500155, loss_freq: 0.500256
[02:38:25.040] iteration 919: loss: 0.916775, loss_s1: 0.501814, loss_fp: 0.500062, loss_freq: 0.501577
[02:38:25.624] iteration 920: loss: 0.928641, loss_s1: 0.503615, loss_fp: 0.500017, loss_freq: 0.500152
[02:38:26.209] iteration 921: loss: 0.928427, loss_s1: 0.502209, loss_fp: 0.500024, loss_freq: 0.501105
[02:38:26.803] iteration 922: loss: 0.896078, loss_s1: 0.501241, loss_fp: 0.500219, loss_freq: 0.500840
[02:38:27.397] iteration 923: loss: 1.010930, loss_s1: 0.506094, loss_fp: 0.500038, loss_freq: 0.501320
[02:38:28.018] iteration 924: loss: 0.954065, loss_s1: 0.505465, loss_fp: 0.500015, loss_freq: 0.502162
[02:38:28.612] iteration 925: loss: 0.896498, loss_s1: 0.507016, loss_fp: 0.500115, loss_freq: 0.502122
[02:38:29.198] iteration 926: loss: 0.909751, loss_s1: 0.503417, loss_fp: 0.500023, loss_freq: 0.501522
[02:38:29.786] iteration 927: loss: 0.953658, loss_s1: 0.503525, loss_fp: 0.500520, loss_freq: 0.501601
[02:38:30.373] iteration 928: loss: 0.991491, loss_s1: 0.509294, loss_fp: 0.500172, loss_freq: 0.503241
[02:38:30.965] iteration 929: loss: 0.899100, loss_s1: 0.506694, loss_fp: 0.500035, loss_freq: 0.500956
[02:38:31.549] iteration 930: loss: 0.914054, loss_s1: 0.505576, loss_fp: 0.500155, loss_freq: 0.502021
[02:38:32.145] iteration 931: loss: 0.902030, loss_s1: 0.503518, loss_fp: 0.500039, loss_freq: 0.501833
[02:38:32.728] iteration 932: loss: 0.928141, loss_s1: 0.505584, loss_fp: 0.500019, loss_freq: 0.501699
[02:38:33.309] iteration 933: loss: 0.920283, loss_s1: 0.507974, loss_fp: 0.500014, loss_freq: 0.500250
[02:38:33.895] iteration 934: loss: 0.921951, loss_s1: 0.503675, loss_fp: 0.501558, loss_freq: 0.500425
[02:38:34.475] iteration 935: loss: 0.905213, loss_s1: 0.506674, loss_fp: 0.500063, loss_freq: 0.501389
[02:38:35.122] iteration 936: loss: 0.910833, loss_s1: 0.500888, loss_fp: 0.500088, loss_freq: 0.500343
[02:38:35.777] iteration 937: loss: 0.891608, loss_s1: 0.504152, loss_fp: 0.500048, loss_freq: 0.500617
[02:38:36.376] iteration 938: loss: 0.912814, loss_s1: 0.503587, loss_fp: 0.500054, loss_freq: 0.501741
[02:38:36.984] iteration 939: loss: 0.872534, loss_s1: 0.504654, loss_fp: 0.500093, loss_freq: 0.500559
[02:38:37.587] iteration 940: loss: 0.945398, loss_s1: 0.503264, loss_fp: 0.500172, loss_freq: 0.500936
[02:38:38.192] iteration 941: loss: 0.899927, loss_s1: 0.502671, loss_fp: 0.500038, loss_freq: 0.501753
[02:38:38.795] iteration 942: loss: 0.860862, loss_s1: 0.501360, loss_fp: 0.500055, loss_freq: 0.501334
[02:38:39.401] iteration 943: loss: 0.928320, loss_s1: 0.506528, loss_fp: 0.500147, loss_freq: 0.500903
[02:38:40.053] iteration 944: loss: 0.887901, loss_s1: 0.502580, loss_fp: 0.500088, loss_freq: 0.500434
[02:38:40.685] iteration 945: loss: 0.888907, loss_s1: 0.503682, loss_fp: 0.500080, loss_freq: 0.500209
[02:38:41.308] iteration 946: loss: 0.919100, loss_s1: 0.501462, loss_fp: 0.500339, loss_freq: 0.500160
[02:38:41.888] iteration 947: loss: 0.942199, loss_s1: 0.502607, loss_fp: 0.500101, loss_freq: 0.500485
[02:38:42.471] iteration 948: loss: 0.887223, loss_s1: 0.504196, loss_fp: 0.500030, loss_freq: 0.500707
[02:38:43.052] iteration 949: loss: 0.894787, loss_s1: 0.502507, loss_fp: 0.500023, loss_freq: 0.500272
[02:38:43.639] iteration 950: loss: 0.889420, loss_s1: 0.505797, loss_fp: 0.500050, loss_freq: 0.500899
[02:38:44.222] iteration 951: loss: 0.858335, loss_s1: 0.503850, loss_fp: 0.500122, loss_freq: 0.503155
[02:38:44.806] iteration 952: loss: 0.950058, loss_s1: 0.506339, loss_fp: 0.500058, loss_freq: 0.502244
[02:38:45.398] iteration 953: loss: 0.893185, loss_s1: 0.502115, loss_fp: 0.500076, loss_freq: 0.500260
[02:38:45.991] iteration 954: loss: 0.914285, loss_s1: 0.504430, loss_fp: 0.500142, loss_freq: 0.503736
[02:38:46.587] iteration 955: loss: 0.859236, loss_s1: 0.502508, loss_fp: 0.500080, loss_freq: 0.501153
[02:38:47.175] iteration 956: loss: 0.879808, loss_s1: 0.505279, loss_fp: 0.500008, loss_freq: 0.500895
[02:38:47.762] iteration 957: loss: 0.885526, loss_s1: 0.507128, loss_fp: 0.500075, loss_freq: 0.501253
[02:38:48.363] iteration 958: loss: 0.895175, loss_s1: 0.504720, loss_fp: 0.500007, loss_freq: 0.500362
[02:38:48.968] iteration 959: loss: 0.922715, loss_s1: 0.505201, loss_fp: 0.500278, loss_freq: 0.506462
[02:38:49.587] iteration 960: loss: 0.875332, loss_s1: 0.505387, loss_fp: 0.500043, loss_freq: 0.501006
[02:38:50.186] iteration 961: loss: 0.986149, loss_s1: 0.505229, loss_fp: 0.500540, loss_freq: 0.501879
[02:38:50.788] iteration 962: loss: 0.856145, loss_s1: 0.501020, loss_fp: 0.500072, loss_freq: 0.501013
[02:38:51.387] iteration 963: loss: 0.853904, loss_s1: 0.464331, loss_fp: 0.500069, loss_freq: 0.500366
[02:38:52.020] iteration 964: loss: 0.895402, loss_s1: 0.503928, loss_fp: 0.500178, loss_freq: 0.502512
[02:38:52.649] iteration 965: loss: 0.936403, loss_s1: 0.507660, loss_fp: 0.500187, loss_freq: 0.504306
[02:38:53.283] iteration 966: loss: 0.879078, loss_s1: 0.503230, loss_fp: 0.500342, loss_freq: 0.504051
[02:38:53.886] iteration 967: loss: 0.876964, loss_s1: 0.502741, loss_fp: 0.500156, loss_freq: 0.502846
[02:38:54.485] iteration 968: loss: 0.873428, loss_s1: 0.501340, loss_fp: 0.500027, loss_freq: 0.500822
[02:38:55.082] iteration 969: loss: 0.863000, loss_s1: 0.503864, loss_fp: 0.500068, loss_freq: 0.502803
[02:38:55.675] iteration 970: loss: 0.927901, loss_s1: 0.504022, loss_fp: 0.500081, loss_freq: 0.502545
[02:38:56.295] iteration 971: loss: 0.929406, loss_s1: 0.500734, loss_fp: 0.500024, loss_freq: 0.500442
[02:38:56.884] iteration 972: loss: 0.882750, loss_s1: 0.501479, loss_fp: 0.500054, loss_freq: 0.500400
[02:38:57.473] iteration 973: loss: 0.871051, loss_s1: 0.502797, loss_fp: 0.500053, loss_freq: 0.501861
[02:38:58.066] iteration 974: loss: 0.880626, loss_s1: 0.503084, loss_fp: 0.500023, loss_freq: 0.502038
[02:38:58.655] iteration 975: loss: 0.891362, loss_s1: 0.501396, loss_fp: 0.500039, loss_freq: 0.500274
[02:38:59.251] iteration 976: loss: 0.892700, loss_s1: 0.500638, loss_fp: 0.500020, loss_freq: 0.500751
[02:38:59.843] iteration 977: loss: 0.865825, loss_s1: 0.501087, loss_fp: 0.500093, loss_freq: 0.505764
[02:39:00.435] iteration 978: loss: 0.907511, loss_s1: 0.503972, loss_fp: 0.500027, loss_freq: 0.505834
[02:39:01.083] iteration 979: loss: 0.888200, loss_s1: 0.502891, loss_fp: 0.500094, loss_freq: 0.502556
[02:39:01.674] iteration 980: loss: 0.877402, loss_s1: 0.504630, loss_fp: 0.500187, loss_freq: 0.502714
[02:39:02.268] iteration 981: loss: 0.885725, loss_s1: 0.502317, loss_fp: 0.500065, loss_freq: 0.500422
[02:39:02.861] iteration 982: loss: 0.891588, loss_s1: 0.502605, loss_fp: 0.500015, loss_freq: 0.502106
[02:39:03.457] iteration 983: loss: 0.901076, loss_s1: 0.503907, loss_fp: 0.500057, loss_freq: 0.501981
[02:39:04.082] iteration 984: loss: 0.942818, loss_s1: 0.502537, loss_fp: 0.500494, loss_freq: 0.501577
[02:39:04.678] iteration 985: loss: 0.893529, loss_s1: 0.503804, loss_fp: 0.500039, loss_freq: 0.500845
[02:39:05.268] iteration 986: loss: 0.846253, loss_s1: 0.507966, loss_fp: 0.500149, loss_freq: 0.502298
[02:39:05.860] iteration 987: loss: 0.924377, loss_s1: 0.502249, loss_fp: 0.500031, loss_freq: 0.502843
[02:39:06.446] iteration 988: loss: 0.904730, loss_s1: 0.502467, loss_fp: 0.500017, loss_freq: 0.501080
[02:39:07.039] iteration 989: loss: 0.897509, loss_s1: 0.501817, loss_fp: 0.500034, loss_freq: 0.501415
[02:39:07.693] iteration 990: loss: 0.872378, loss_s1: 0.505939, loss_fp: 0.500542, loss_freq: 0.502603
[02:39:08.332] iteration 991: loss: 0.893426, loss_s1: 0.507955, loss_fp: 0.500248, loss_freq: 0.502214
[02:39:08.967] iteration 992: loss: 0.893801, loss_s1: 0.507508, loss_fp: 0.500069, loss_freq: 0.503080
[02:39:09.558] iteration 993: loss: 0.895341, loss_s1: 0.505953, loss_fp: 0.500031, loss_freq: 0.502780
[02:39:10.150] iteration 994: loss: 0.860841, loss_s1: 0.503968, loss_fp: 0.500034, loss_freq: 0.502074
[02:39:10.743] iteration 995: loss: 0.868815, loss_s1: 0.503083, loss_fp: 0.500300, loss_freq: 0.501818
[02:39:11.332] iteration 996: loss: 0.903103, loss_s1: 0.503307, loss_fp: 0.500029, loss_freq: 0.502018
[02:39:11.921] iteration 997: loss: 0.860165, loss_s1: 0.440777, loss_fp: 0.500187, loss_freq: 0.501777
[02:39:12.510] iteration 998: loss: 0.885696, loss_s1: 0.502150, loss_fp: 0.500058, loss_freq: 0.500764
[02:39:13.101] iteration 999: loss: 0.863097, loss_s1: 0.506427, loss_fp: 0.500037, loss_freq: 0.502850
[02:39:13.691] iteration 1000: loss: 0.878374, loss_s1: 0.503101, loss_fp: 0.500079, loss_freq: 0.500604
[02:39:15.962] iteration 1000 : mean_dice : 0.096547
[02:39:16.581] iteration 1001: loss: 0.884434, loss_s1: 0.503140, loss_fp: 0.500242, loss_freq: 0.501644
[02:39:17.169] iteration 1002: loss: 0.902397, loss_s1: 0.502237, loss_fp: 0.500133, loss_freq: 0.500521
[02:39:17.762] iteration 1003: loss: 0.892004, loss_s1: 0.504753, loss_fp: 0.500027, loss_freq: 0.501094
[02:39:18.355] iteration 1004: loss: 0.854124, loss_s1: 0.501902, loss_fp: 0.500062, loss_freq: 0.500765
[02:39:18.944] iteration 1005: loss: 0.918398, loss_s1: 0.501904, loss_fp: 0.500017, loss_freq: 0.500359
[02:39:19.534] iteration 1006: loss: 0.898762, loss_s1: 0.505382, loss_fp: 0.500028, loss_freq: 0.500608
[02:39:20.122] iteration 1007: loss: 0.895025, loss_s1: 0.504582, loss_fp: 0.500029, loss_freq: 0.502261
[02:39:20.710] iteration 1008: loss: 0.876274, loss_s1: 0.503348, loss_fp: 0.500068, loss_freq: 0.501465
[02:39:21.298] iteration 1009: loss: 0.851158, loss_s1: 0.501945, loss_fp: 0.500051, loss_freq: 0.500936
[02:39:21.888] iteration 1010: loss: 0.906170, loss_s1: 0.504324, loss_fp: 0.500038, loss_freq: 0.500676
[02:39:22.474] iteration 1011: loss: 0.884911, loss_s1: 0.503825, loss_fp: 0.500020, loss_freq: 0.501571
[02:39:23.068] iteration 1012: loss: 0.856069, loss_s1: 0.501750, loss_fp: 0.500394, loss_freq: 0.500881
[02:39:23.657] iteration 1013: loss: 0.923968, loss_s1: 0.501977, loss_fp: 0.500020, loss_freq: 0.504605
[02:39:24.305] iteration 1014: loss: 0.859961, loss_s1: 0.500856, loss_fp: 0.500068, loss_freq: 0.501048
[02:39:24.956] iteration 1015: loss: 0.866917, loss_s1: 0.507878, loss_fp: 0.500050, loss_freq: 0.500460
[02:39:25.603] iteration 1016: loss: 0.765048, loss_s1: 0.494032, loss_fp: 0.342969, loss_freq: 0.458998
[02:39:26.255] iteration 1017: loss: 0.873231, loss_s1: 0.504909, loss_fp: 0.500023, loss_freq: 0.500395
[02:39:26.872] iteration 1018: loss: 0.922600, loss_s1: 0.504447, loss_fp: 0.500016, loss_freq: 0.501415
[02:39:27.461] iteration 1019: loss: 0.900618, loss_s1: 0.505096, loss_fp: 0.500088, loss_freq: 0.501533
[02:39:28.047] iteration 1020: loss: 0.891089, loss_s1: 0.507605, loss_fp: 0.500029, loss_freq: 0.506530
[02:39:28.943] iteration 1021: loss: 0.893340, loss_s1: 0.503583, loss_fp: 0.500056, loss_freq: 0.502527
[02:39:29.573] iteration 1022: loss: 0.897977, loss_s1: 0.503019, loss_fp: 0.500012, loss_freq: 0.501712
[02:39:30.206] iteration 1023: loss: 0.897956, loss_s1: 0.502536, loss_fp: 0.500036, loss_freq: 0.502968
[02:39:30.838] iteration 1024: loss: 0.907670, loss_s1: 0.507395, loss_fp: 0.500007, loss_freq: 0.506189
[02:39:31.470] iteration 1025: loss: 0.894059, loss_s1: 0.511065, loss_fp: 0.500015, loss_freq: 0.502364
[02:39:32.065] iteration 1026: loss: 0.912026, loss_s1: 0.506631, loss_fp: 0.500131, loss_freq: 0.502555
[02:39:32.648] iteration 1027: loss: 0.937623, loss_s1: 0.503816, loss_fp: 0.500071, loss_freq: 0.505473
[02:39:33.239] iteration 1028: loss: 0.904504, loss_s1: 0.504065, loss_fp: 0.500162, loss_freq: 0.501674
[02:39:33.831] iteration 1029: loss: 0.894801, loss_s1: 0.506395, loss_fp: 0.500091, loss_freq: 0.505974
[02:39:34.470] iteration 1030: loss: 0.889436, loss_s1: 0.505719, loss_fp: 0.500579, loss_freq: 0.502345
[02:39:35.103] iteration 1031: loss: 0.900905, loss_s1: 0.504452, loss_fp: 0.500013, loss_freq: 0.503009
[02:39:35.737] iteration 1032: loss: 0.927251, loss_s1: 0.508281, loss_fp: 0.500006, loss_freq: 0.507694
[02:39:36.377] iteration 1033: loss: 0.892979, loss_s1: 0.512596, loss_fp: 0.500012, loss_freq: 0.505968
[02:39:37.002] iteration 1034: loss: 0.912075, loss_s1: 0.505879, loss_fp: 0.500053, loss_freq: 0.503235
[02:39:37.602] iteration 1035: loss: 0.989509, loss_s1: 0.505317, loss_fp: 0.500013, loss_freq: 0.503555
[02:39:38.187] iteration 1036: loss: 0.685778, loss_s1: 0.506750, loss_fp: 0.130611, loss_freq: 0.485232
[02:39:38.787] iteration 1037: loss: 0.893900, loss_s1: 0.506057, loss_fp: 0.500436, loss_freq: 0.502485
[02:39:39.411] iteration 1038: loss: 0.977903, loss_s1: 0.499527, loss_fp: 0.500015, loss_freq: 0.500781
[02:39:40.007] iteration 1039: loss: 0.893289, loss_s1: 0.505354, loss_fp: 0.500009, loss_freq: 0.501329
[02:39:40.597] iteration 1040: loss: 1.006946, loss_s1: 0.504067, loss_fp: 0.500033, loss_freq: 0.501182
[02:39:41.193] iteration 1041: loss: 0.930088, loss_s1: 0.505918, loss_fp: 0.500021, loss_freq: 0.505313
[02:39:41.783] iteration 1042: loss: 0.933868, loss_s1: 0.511203, loss_fp: 0.500041, loss_freq: 0.505823
[02:39:42.386] iteration 1043: loss: 0.985237, loss_s1: 0.504077, loss_fp: 0.500009, loss_freq: 0.501022
[02:39:43.036] iteration 1044: loss: 0.906326, loss_s1: 0.505137, loss_fp: 0.500069, loss_freq: 0.501053
[02:39:43.624] iteration 1045: loss: 0.897909, loss_s1: 0.501473, loss_fp: 0.500099, loss_freq: 0.500518
[02:39:44.225] iteration 1046: loss: 0.706487, loss_s1: 0.493725, loss_fp: 0.219787, loss_freq: 0.433676
[02:39:44.821] iteration 1047: loss: 0.893342, loss_s1: 0.501214, loss_fp: 0.500020, loss_freq: 0.500408
[02:39:45.418] iteration 1048: loss: 0.900264, loss_s1: 0.506278, loss_fp: 0.500014, loss_freq: 0.502265
[02:39:46.020] iteration 1049: loss: 0.997344, loss_s1: 0.503125, loss_fp: 0.500014, loss_freq: 0.501138
[02:39:46.613] iteration 1050: loss: 1.001141, loss_s1: 0.500415, loss_fp: 0.500021, loss_freq: 0.501458
[02:39:47.207] iteration 1051: loss: 0.948894, loss_s1: 0.501284, loss_fp: 0.500058, loss_freq: 0.500293
[02:39:47.800] iteration 1052: loss: 0.972525, loss_s1: 0.503246, loss_fp: 0.500019, loss_freq: 0.501436
[02:39:48.391] iteration 1053: loss: 0.986808, loss_s1: 0.507928, loss_fp: 0.500021, loss_freq: 0.501576
[02:39:48.986] iteration 1054: loss: 0.970511, loss_s1: 0.504544, loss_fp: 0.500039, loss_freq: 0.501500
[02:39:49.620] iteration 1055: loss: 0.934727, loss_s1: 0.502210, loss_fp: 0.500138, loss_freq: 0.501029
[02:39:50.251] iteration 1056: loss: 0.900188, loss_s1: 0.502322, loss_fp: 0.500106, loss_freq: 0.500341
[02:39:50.910] iteration 1057: loss: 0.933563, loss_s1: 0.506455, loss_fp: 0.500291, loss_freq: 0.501436
[02:39:51.537] iteration 1058: loss: 0.968964, loss_s1: 0.503194, loss_fp: 0.500007, loss_freq: 0.500877
[02:39:52.139] iteration 1059: loss: 0.925902, loss_s1: 0.502942, loss_fp: 0.500049, loss_freq: 0.500833
[02:39:52.728] iteration 1060: loss: 0.925204, loss_s1: 0.509050, loss_fp: 0.500012, loss_freq: 0.501424
[02:39:53.324] iteration 1061: loss: 0.952619, loss_s1: 0.504063, loss_fp: 0.500023, loss_freq: 0.501562
[02:39:53.922] iteration 1062: loss: 0.924394, loss_s1: 0.506686, loss_fp: 0.500062, loss_freq: 0.502759
[02:39:54.515] iteration 1063: loss: 0.916193, loss_s1: 0.505516, loss_fp: 0.500032, loss_freq: 0.500843
[02:39:55.109] iteration 1064: loss: 0.931941, loss_s1: 0.505420, loss_fp: 0.500133, loss_freq: 0.501306
[02:39:55.704] iteration 1065: loss: 0.932401, loss_s1: 0.503345, loss_fp: 0.500018, loss_freq: 0.500765
[02:39:56.292] iteration 1066: loss: 0.889186, loss_s1: 0.501997, loss_fp: 0.500117, loss_freq: 0.502860
[02:39:56.879] iteration 1067: loss: 0.999715, loss_s1: 0.507462, loss_fp: 0.500100, loss_freq: 0.500956
[02:39:57.469] iteration 1068: loss: 0.921633, loss_s1: 0.505312, loss_fp: 0.500286, loss_freq: 0.503883
[02:39:58.054] iteration 1069: loss: 0.922978, loss_s1: 0.500833, loss_fp: 0.500011, loss_freq: 0.500576
[02:39:58.646] iteration 1070: loss: 0.934240, loss_s1: 0.503573, loss_fp: 0.500049, loss_freq: 0.504010
[02:39:59.233] iteration 1071: loss: 0.882466, loss_s1: 0.504381, loss_fp: 0.500069, loss_freq: 0.501675
[02:39:59.823] iteration 1072: loss: 0.891579, loss_s1: 0.503115, loss_fp: 0.500192, loss_freq: 0.500529
[02:40:00.414] iteration 1073: loss: 0.964532, loss_s1: 0.505364, loss_fp: 0.500150, loss_freq: 0.503265
[02:40:01.050] iteration 1074: loss: 0.908438, loss_s1: 0.502820, loss_fp: 0.500025, loss_freq: 0.500810
[02:40:01.639] iteration 1075: loss: 0.998678, loss_s1: 0.510067, loss_fp: 0.500010, loss_freq: 0.502268
[02:40:02.275] iteration 1076: loss: 0.899544, loss_s1: 0.504576, loss_fp: 0.500013, loss_freq: 0.500552
[02:40:02.903] iteration 1077: loss: 0.863107, loss_s1: 0.502127, loss_fp: 0.500027, loss_freq: 0.500701
[02:40:03.529] iteration 1078: loss: 0.961491, loss_s1: 0.505193, loss_fp: 0.500842, loss_freq: 0.503374
[02:40:04.154] iteration 1079: loss: 0.910727, loss_s1: 0.504544, loss_fp: 0.500117, loss_freq: 0.500201
[02:40:04.782] iteration 1080: loss: 0.907926, loss_s1: 0.507296, loss_fp: 0.500009, loss_freq: 0.502012
[02:40:05.387] iteration 1081: loss: 0.922615, loss_s1: 0.504376, loss_fp: 0.500038, loss_freq: 0.502003
[02:40:05.976] iteration 1082: loss: 0.902820, loss_s1: 0.503481, loss_fp: 0.500043, loss_freq: 0.500604
[02:40:06.567] iteration 1083: loss: 0.897832, loss_s1: 0.502125, loss_fp: 0.500036, loss_freq: 0.500462
[02:40:07.158] iteration 1084: loss: 0.907222, loss_s1: 0.500379, loss_fp: 0.500009, loss_freq: 0.500237
[02:40:07.750] iteration 1085: loss: 0.886472, loss_s1: 0.502300, loss_fp: 0.500032, loss_freq: 0.501210
[02:40:08.336] iteration 1086: loss: 0.859429, loss_s1: 0.501499, loss_fp: 0.500034, loss_freq: 0.502683
[02:40:08.935] iteration 1087: loss: 0.938082, loss_s1: 0.504913, loss_fp: 0.500038, loss_freq: 0.501227
[02:40:09.863] iteration 1088: loss: 0.894673, loss_s1: 0.506642, loss_fp: 0.500197, loss_freq: 0.501768
[02:40:10.723] iteration 1089: loss: 0.906517, loss_s1: 0.505454, loss_fp: 0.500011, loss_freq: 0.500884
[02:40:11.616] iteration 1090: loss: 0.899203, loss_s1: 0.501171, loss_fp: 0.500023, loss_freq: 0.500226
[02:40:12.242] iteration 1091: loss: 0.938672, loss_s1: 0.507720, loss_fp: 0.500131, loss_freq: 0.500398
[02:40:12.859] iteration 1092: loss: 0.903745, loss_s1: 0.504475, loss_fp: 0.500092, loss_freq: 0.501267
[02:40:13.447] iteration 1093: loss: 0.926520, loss_s1: 0.501396, loss_fp: 0.500008, loss_freq: 0.500363
[02:40:14.041] iteration 1094: loss: 0.877208, loss_s1: 0.507278, loss_fp: 0.500077, loss_freq: 0.501359
[02:40:14.622] iteration 1095: loss: 0.881250, loss_s1: 0.505508, loss_fp: 0.500161, loss_freq: 0.502745
[02:40:15.214] iteration 1096: loss: 0.890557, loss_s1: 0.504768, loss_fp: 0.500189, loss_freq: 0.502545
[02:40:15.805] iteration 1097: loss: 0.882530, loss_s1: 0.505639, loss_fp: 0.500008, loss_freq: 0.501354
[02:40:16.421] iteration 1098: loss: 0.888995, loss_s1: 0.506233, loss_fp: 0.500088, loss_freq: 0.504477
[02:40:17.049] iteration 1099: loss: 0.865416, loss_s1: 0.504576, loss_fp: 0.500083, loss_freq: 0.502524
[02:40:17.682] iteration 1100: loss: 0.883293, loss_s1: 0.507223, loss_fp: 0.500047, loss_freq: 0.501403
[02:40:18.314] iteration 1101: loss: 0.878358, loss_s1: 0.506240, loss_fp: 0.500837, loss_freq: 0.507991
[02:40:18.929] iteration 1102: loss: 0.913428, loss_s1: 0.503479, loss_fp: 0.500104, loss_freq: 0.503219
[02:40:19.523] iteration 1103: loss: 0.865922, loss_s1: 0.501213, loss_fp: 0.500053, loss_freq: 0.500876
[02:40:20.107] iteration 1104: loss: 0.877948, loss_s1: 0.501673, loss_fp: 0.500063, loss_freq: 0.502848
[02:40:20.699] iteration 1105: loss: 0.928027, loss_s1: 0.504989, loss_fp: 0.500065, loss_freq: 0.503154
[02:40:21.285] iteration 1106: loss: 0.889665, loss_s1: 0.505571, loss_fp: 0.500149, loss_freq: 0.502180
[02:40:21.877] iteration 1107: loss: 0.912809, loss_s1: 0.500971, loss_fp: 0.500077, loss_freq: 0.500196
[02:40:22.463] iteration 1108: loss: 0.877240, loss_s1: 0.506600, loss_fp: 0.500043, loss_freq: 0.502445
[02:40:23.055] iteration 1109: loss: 0.873441, loss_s1: 0.503638, loss_fp: 0.500060, loss_freq: 0.502727
[02:40:23.648] iteration 1110: loss: 0.904558, loss_s1: 0.502231, loss_fp: 0.500009, loss_freq: 0.502814
[02:40:24.236] iteration 1111: loss: 0.875584, loss_s1: 0.504520, loss_fp: 0.500040, loss_freq: 0.501962
[02:40:24.831] iteration 1112: loss: 0.831935, loss_s1: 0.503628, loss_fp: 0.500143, loss_freq: 0.503631
[02:40:25.427] iteration 1113: loss: 0.913553, loss_s1: 0.504586, loss_fp: 0.500022, loss_freq: 0.503637
[02:40:26.024] iteration 1114: loss: 0.874818, loss_s1: 0.503067, loss_fp: 0.500070, loss_freq: 0.501336
[02:40:26.632] iteration 1115: loss: 0.884907, loss_s1: 0.501010, loss_fp: 0.500083, loss_freq: 0.500768
[02:40:27.214] iteration 1116: loss: 0.858605, loss_s1: 0.500763, loss_fp: 0.500010, loss_freq: 0.500453
[02:40:27.802] iteration 1117: loss: 0.869499, loss_s1: 0.506161, loss_fp: 0.500118, loss_freq: 0.501902
[02:40:28.430] iteration 1118: loss: 0.891279, loss_s1: 0.507500, loss_fp: 0.500095, loss_freq: 0.501786
[02:40:29.059] iteration 1119: loss: 0.900257, loss_s1: 0.501471, loss_fp: 0.500048, loss_freq: 0.501639
[02:40:29.669] iteration 1120: loss: 0.861581, loss_s1: 0.506047, loss_fp: 0.500021, loss_freq: 0.501993
[02:40:30.262] iteration 1121: loss: 0.832100, loss_s1: 0.505201, loss_fp: 0.500195, loss_freq: 0.504421
[02:40:30.849] iteration 1122: loss: 0.938300, loss_s1: 0.503377, loss_fp: 0.500533, loss_freq: 0.502134
[02:40:31.441] iteration 1123: loss: 0.882037, loss_s1: 0.501250, loss_fp: 0.500092, loss_freq: 0.500348
[02:40:32.037] iteration 1124: loss: 0.922827, loss_s1: 0.510025, loss_fp: 0.500090, loss_freq: 0.503732
[02:40:32.630] iteration 1125: loss: 0.855113, loss_s1: 0.505506, loss_fp: 0.500022, loss_freq: 0.501780
[02:40:33.219] iteration 1126: loss: 0.892108, loss_s1: 0.504654, loss_fp: 0.500000, loss_freq: 0.502186
[02:40:33.818] iteration 1127: loss: 0.867243, loss_s1: 0.504359, loss_fp: 0.500052, loss_freq: 0.501246
[02:40:34.408] iteration 1128: loss: 0.877192, loss_s1: 0.504125, loss_fp: 0.500030, loss_freq: 0.500410
[02:40:35.007] iteration 1129: loss: 0.880507, loss_s1: 0.505661, loss_fp: 0.500071, loss_freq: 0.509065
[02:40:35.607] iteration 1130: loss: 0.859017, loss_s1: 0.503012, loss_fp: 0.500051, loss_freq: 0.500784
[02:40:36.204] iteration 1131: loss: 0.943971, loss_s1: 0.501966, loss_fp: 0.500010, loss_freq: 0.502897
[02:40:36.797] iteration 1132: loss: 0.770354, loss_s1: 0.501015, loss_fp: 0.296815, loss_freq: 0.489080
[02:40:37.399] iteration 1133: loss: 0.829503, loss_s1: 0.335846, loss_fp: 0.500049, loss_freq: 0.500507
[02:40:37.987] iteration 1134: loss: 0.846116, loss_s1: 0.501950, loss_fp: 0.500010, loss_freq: 0.501409
[02:40:38.578] iteration 1135: loss: 0.873248, loss_s1: 0.506200, loss_fp: 0.500075, loss_freq: 0.505255
[02:40:39.210] iteration 1136: loss: 0.912801, loss_s1: 0.505559, loss_fp: 0.500028, loss_freq: 0.508569
[02:40:39.796] iteration 1137: loss: 0.923157, loss_s1: 0.504404, loss_fp: 0.500093, loss_freq: 0.501551
[02:40:40.383] iteration 1138: loss: 0.880942, loss_s1: 0.500805, loss_fp: 0.500009, loss_freq: 0.500692
[02:40:40.980] iteration 1139: loss: 0.885729, loss_s1: 0.503409, loss_fp: 0.500024, loss_freq: 0.506377
[02:40:41.570] iteration 1140: loss: 0.951156, loss_s1: 0.505255, loss_fp: 0.500006, loss_freq: 0.504914
[02:40:42.157] iteration 1141: loss: 0.950848, loss_s1: 0.500317, loss_fp: 0.500051, loss_freq: 0.500340
[02:40:42.781] iteration 1142: loss: 0.885270, loss_s1: 0.503817, loss_fp: 0.500025, loss_freq: 0.500573
[02:40:43.416] iteration 1143: loss: 0.904085, loss_s1: 0.503743, loss_fp: 0.500027, loss_freq: 0.502585
[02:40:44.045] iteration 1144: loss: 0.878378, loss_s1: 0.503160, loss_fp: 0.500016, loss_freq: 0.504959
[02:40:44.677] iteration 1145: loss: 0.918176, loss_s1: 0.504221, loss_fp: 0.500006, loss_freq: 0.500352
[02:40:45.316] iteration 1146: loss: 0.882546, loss_s1: 0.501679, loss_fp: 0.500005, loss_freq: 0.500351
[02:40:45.953] iteration 1147: loss: 0.917855, loss_s1: 0.503877, loss_fp: 0.500010, loss_freq: 0.505394
[02:40:46.586] iteration 1148: loss: 0.909876, loss_s1: 0.505356, loss_fp: 0.500277, loss_freq: 0.504451
[02:40:47.180] iteration 1149: loss: 0.876411, loss_s1: 0.502000, loss_fp: 0.500020, loss_freq: 0.503778
[02:40:47.770] iteration 1150: loss: 0.892850, loss_s1: 0.503975, loss_fp: 0.500033, loss_freq: 0.502347
[02:40:48.362] iteration 1151: loss: 0.913339, loss_s1: 0.500912, loss_fp: 0.500131, loss_freq: 0.500275
[02:40:48.956] iteration 1152: loss: 0.916172, loss_s1: 0.500786, loss_fp: 0.500041, loss_freq: 0.500221
[02:40:49.550] iteration 1153: loss: 0.885444, loss_s1: 0.502599, loss_fp: 0.500013, loss_freq: 0.500863
[02:40:50.142] iteration 1154: loss: 0.903971, loss_s1: 0.502793, loss_fp: 0.500016, loss_freq: 0.500540
[02:40:50.733] iteration 1155: loss: 0.935251, loss_s1: 0.502548, loss_fp: 0.500000, loss_freq: 0.500727
[02:40:51.338] iteration 1156: loss: 0.855845, loss_s1: 0.503372, loss_fp: 0.500012, loss_freq: 0.504313
[02:40:51.921] iteration 1157: loss: 0.940133, loss_s1: 0.502366, loss_fp: 0.500018, loss_freq: 0.501180
[02:40:52.512] iteration 1158: loss: 0.874486, loss_s1: 0.500786, loss_fp: 0.500055, loss_freq: 0.500398
[02:40:53.102] iteration 1159: loss: 0.889408, loss_s1: 0.501951, loss_fp: 0.500009, loss_freq: 0.501127
[02:40:53.691] iteration 1160: loss: 0.857953, loss_s1: 0.502632, loss_fp: 0.500028, loss_freq: 0.502801
[02:40:54.282] iteration 1161: loss: 0.877729, loss_s1: 0.501834, loss_fp: 0.500011, loss_freq: 0.500563
[02:40:54.876] iteration 1162: loss: 0.872416, loss_s1: 0.502532, loss_fp: 0.500012, loss_freq: 0.502544
[02:40:55.470] iteration 1163: loss: 0.926711, loss_s1: 0.502369, loss_fp: 0.500009, loss_freq: 0.503051
[02:40:56.067] iteration 1164: loss: 0.870291, loss_s1: 0.502112, loss_fp: 0.500026, loss_freq: 0.500621
[02:40:56.655] iteration 1165: loss: 0.884958, loss_s1: 0.501594, loss_fp: 0.500961, loss_freq: 0.502233
[02:40:57.244] iteration 1166: loss: 0.922996, loss_s1: 0.500614, loss_fp: 0.500022, loss_freq: 0.502030
[02:40:57.837] iteration 1167: loss: 0.865994, loss_s1: 0.500551, loss_fp: 0.500005, loss_freq: 0.501041
[02:40:58.430] iteration 1168: loss: 0.905523, loss_s1: 0.502545, loss_fp: 0.500173, loss_freq: 0.501840
[02:40:59.024] iteration 1169: loss: 0.910271, loss_s1: 0.503335, loss_fp: 0.500003, loss_freq: 0.504759
[02:40:59.613] iteration 1170: loss: 0.891664, loss_s1: 0.502716, loss_fp: 0.500095, loss_freq: 0.503136
[02:41:00.204] iteration 1171: loss: 0.891351, loss_s1: 0.504910, loss_fp: 0.500004, loss_freq: 0.500862
[02:41:00.801] iteration 1172: loss: 0.900647, loss_s1: 0.505168, loss_fp: 0.500033, loss_freq: 0.502319
[02:41:01.387] iteration 1173: loss: 0.871995, loss_s1: 0.504845, loss_fp: 0.500042, loss_freq: 0.503459
[02:41:01.976] iteration 1174: loss: 0.914345, loss_s1: 0.501447, loss_fp: 0.500028, loss_freq: 0.501211
[02:41:02.560] iteration 1175: loss: 0.908401, loss_s1: 0.503009, loss_fp: 0.500084, loss_freq: 0.500835
[02:41:03.156] iteration 1176: loss: 0.882811, loss_s1: 0.501883, loss_fp: 0.500009, loss_freq: 0.502184
[02:41:03.748] iteration 1177: loss: 0.789860, loss_s1: 0.501305, loss_fp: 0.394222, loss_freq: 0.492412
[02:41:04.349] iteration 1178: loss: 0.863338, loss_s1: 0.503976, loss_fp: 0.500054, loss_freq: 0.502230
[02:41:04.941] iteration 1179: loss: 0.859187, loss_s1: 0.506531, loss_fp: 0.500011, loss_freq: 0.501504
[02:41:05.533] iteration 1180: loss: 0.940253, loss_s1: 0.506047, loss_fp: 0.500014, loss_freq: 0.501124
[02:41:06.124] iteration 1181: loss: 0.898784, loss_s1: 0.506120, loss_fp: 0.500029, loss_freq: 0.501687
[02:41:06.717] iteration 1182: loss: 0.862092, loss_s1: 0.501171, loss_fp: 0.500006, loss_freq: 0.500666
[02:41:07.317] iteration 1183: loss: 0.877575, loss_s1: 0.502926, loss_fp: 0.499997, loss_freq: 0.504188
[02:41:07.910] iteration 1184: loss: 0.855843, loss_s1: 0.504008, loss_fp: 0.500004, loss_freq: 0.504530
[02:41:08.551] iteration 1185: loss: 0.876327, loss_s1: 0.502462, loss_fp: 0.500003, loss_freq: 0.502260
[02:41:09.181] iteration 1186: loss: 0.771674, loss_s1: 0.498948, loss_fp: 0.219645, loss_freq: 0.489711
[02:41:09.808] iteration 1187: loss: 0.888141, loss_s1: 0.502294, loss_fp: 0.500008, loss_freq: 0.503717
[02:41:10.445] iteration 1188: loss: 0.897333, loss_s1: 0.504043, loss_fp: 0.500000, loss_freq: 0.500229
[02:41:11.075] iteration 1189: loss: 0.936927, loss_s1: 0.502649, loss_fp: 0.500007, loss_freq: 0.501263
[02:41:11.700] iteration 1190: loss: 0.881968, loss_s1: 0.502056, loss_fp: 0.500031, loss_freq: 0.503326
[02:41:12.639] iteration 1191: loss: 0.914966, loss_s1: 0.501276, loss_fp: 0.500001, loss_freq: 0.501449
[02:41:13.267] iteration 1192: loss: 0.893462, loss_s1: 0.502414, loss_fp: 0.500016, loss_freq: 0.500561
[02:41:13.903] iteration 1193: loss: 0.907956, loss_s1: 0.500710, loss_fp: 0.500060, loss_freq: 0.500671
[02:41:14.511] iteration 1194: loss: 0.897830, loss_s1: 0.501816, loss_fp: 0.500022, loss_freq: 0.502511
[02:41:15.117] iteration 1195: loss: 0.919655, loss_s1: 0.500960, loss_fp: 0.500000, loss_freq: 0.500973
[02:41:15.721] iteration 1196: loss: 0.905856, loss_s1: 0.505767, loss_fp: 0.500005, loss_freq: 0.500953
[02:41:16.329] iteration 1197: loss: 0.962667, loss_s1: 0.507099, loss_fp: 0.500221, loss_freq: 0.502232
[02:41:16.937] iteration 1198: loss: 1.083803, loss_s1: 0.506194, loss_fp: 0.500017, loss_freq: 0.501926
[02:41:17.536] iteration 1199: loss: 0.958609, loss_s1: 0.502636, loss_fp: 0.500109, loss_freq: 0.504078
[02:41:18.141] iteration 1200: loss: 0.981006, loss_s1: 0.507070, loss_fp: 0.500019, loss_freq: 0.503215
[02:41:20.557] iteration 1200 : mean_dice : 0.162631
[02:41:21.204] iteration 1201: loss: 0.935941, loss_s1: 0.507064, loss_fp: 0.500017, loss_freq: 0.504223
[02:41:21.792] iteration 1202: loss: 0.968462, loss_s1: 0.503397, loss_fp: 0.500011, loss_freq: 0.506879
[02:41:22.389] iteration 1203: loss: 0.982870, loss_s1: 0.504453, loss_fp: 0.500010, loss_freq: 0.505998
[02:41:23.052] iteration 1204: loss: 0.945800, loss_s1: 0.502276, loss_fp: 0.500050, loss_freq: 0.501225
[02:41:23.648] iteration 1205: loss: 0.943264, loss_s1: 0.504854, loss_fp: 0.500006, loss_freq: 0.501623
[02:41:24.237] iteration 1206: loss: 0.902202, loss_s1: 0.508152, loss_fp: 0.500042, loss_freq: 0.501205
[02:41:24.828] iteration 1207: loss: 0.927362, loss_s1: 0.506026, loss_fp: 0.500030, loss_freq: 0.501682
[02:41:25.420] iteration 1208: loss: 0.921026, loss_s1: 0.504233, loss_fp: 0.500051, loss_freq: 0.500454
[02:41:26.012] iteration 1209: loss: 0.906355, loss_s1: 0.501141, loss_fp: 0.500026, loss_freq: 0.500258
[02:41:26.600] iteration 1210: loss: 0.923178, loss_s1: 0.503030, loss_fp: 0.500011, loss_freq: 0.500241
[02:41:27.193] iteration 1211: loss: 0.907944, loss_s1: 0.503402, loss_fp: 0.500011, loss_freq: 0.501588
[02:41:27.783] iteration 1212: loss: 0.980617, loss_s1: 0.504862, loss_fp: 0.500010, loss_freq: 0.500688
[02:41:28.368] iteration 1213: loss: 0.954402, loss_s1: 0.502827, loss_fp: 0.500003, loss_freq: 0.500299
[02:41:29.003] iteration 1214: loss: 0.869197, loss_s1: 0.505137, loss_fp: 0.500006, loss_freq: 0.501166
[02:41:29.599] iteration 1215: loss: 0.876081, loss_s1: 0.500991, loss_fp: 0.500074, loss_freq: 0.500715
[02:41:30.195] iteration 1216: loss: 0.909008, loss_s1: 0.501402, loss_fp: 0.500071, loss_freq: 0.501915
[02:41:30.781] iteration 1217: loss: 0.963662, loss_s1: 0.500786, loss_fp: 0.500011, loss_freq: 0.500596
[02:41:31.375] iteration 1218: loss: 0.915455, loss_s1: 0.505828, loss_fp: 0.500101, loss_freq: 0.502835
[02:41:31.958] iteration 1219: loss: 0.971018, loss_s1: 0.501794, loss_fp: 0.500013, loss_freq: 0.501675
[02:41:32.592] iteration 1220: loss: 0.937628, loss_s1: 0.502260, loss_fp: 0.500016, loss_freq: 0.500624
[02:41:33.227] iteration 1221: loss: 0.882654, loss_s1: 0.503273, loss_fp: 0.500145, loss_freq: 0.500803
[02:41:33.817] iteration 1222: loss: 0.933888, loss_s1: 0.503169, loss_fp: 0.500029, loss_freq: 0.500777
[02:41:34.417] iteration 1223: loss: 0.883340, loss_s1: 0.501757, loss_fp: 0.500094, loss_freq: 0.501570
[02:41:35.016] iteration 1224: loss: 0.928827, loss_s1: 0.501112, loss_fp: 0.500028, loss_freq: 0.501358
[02:41:35.609] iteration 1225: loss: 0.908145, loss_s1: 0.506115, loss_fp: 0.500072, loss_freq: 0.503607
[02:41:36.203] iteration 1226: loss: 0.916612, loss_s1: 0.502821, loss_fp: 0.500039, loss_freq: 0.500528
[02:41:36.805] iteration 1227: loss: 0.889039, loss_s1: 0.503728, loss_fp: 0.500032, loss_freq: 0.501089
[02:41:37.391] iteration 1228: loss: 0.881974, loss_s1: 0.503464, loss_fp: 0.500012, loss_freq: 0.500450
[02:41:37.989] iteration 1229: loss: 0.891926, loss_s1: 0.505134, loss_fp: 0.500041, loss_freq: 0.501335
[02:41:38.720] iteration 1230: loss: 0.908376, loss_s1: 0.504965, loss_fp: 0.500050, loss_freq: 0.502053
[02:41:39.348] iteration 1231: loss: 0.908242, loss_s1: 0.508473, loss_fp: 0.500034, loss_freq: 0.502731
[02:41:40.035] iteration 1232: loss: 0.881829, loss_s1: 0.504411, loss_fp: 0.500010, loss_freq: 0.502679
[02:41:40.776] iteration 1233: loss: 0.863350, loss_s1: 0.502616, loss_fp: 0.500013, loss_freq: 0.500407
[02:41:41.462] iteration 1234: loss: 0.881794, loss_s1: 0.503077, loss_fp: 0.500017, loss_freq: 0.501033
[02:41:42.172] iteration 1235: loss: 0.887075, loss_s1: 0.501702, loss_fp: 0.500005, loss_freq: 0.500352
[02:41:42.810] iteration 1236: loss: 0.887193, loss_s1: 0.507752, loss_fp: 0.500517, loss_freq: 0.504587
[02:41:43.560] iteration 1237: loss: 0.949642, loss_s1: 0.501225, loss_fp: 0.500080, loss_freq: 0.501058
[02:41:44.163] iteration 1238: loss: 0.900699, loss_s1: 0.503748, loss_fp: 0.500021, loss_freq: 0.504173
[02:41:44.868] iteration 1239: loss: 0.909863, loss_s1: 0.504213, loss_fp: 0.500172, loss_freq: 0.500388
[02:41:45.583] iteration 1240: loss: 0.927190, loss_s1: 0.501806, loss_fp: 0.500014, loss_freq: 0.503250
[02:41:46.241] iteration 1241: loss: 0.891919, loss_s1: 0.502576, loss_fp: 0.500014, loss_freq: 0.504036
[02:41:46.987] iteration 1242: loss: 0.857060, loss_s1: 0.503823, loss_fp: 0.500018, loss_freq: 0.501168
[02:41:47.607] iteration 1243: loss: 0.894136, loss_s1: 0.504071, loss_fp: 0.500005, loss_freq: 0.508235
[02:41:48.322] iteration 1244: loss: 0.883991, loss_s1: 0.505378, loss_fp: 0.500067, loss_freq: 0.504832
[02:41:48.930] iteration 1245: loss: 0.920756, loss_s1: 0.502738, loss_fp: 0.500016, loss_freq: 0.501152
[02:41:49.710] iteration 1246: loss: 0.845050, loss_s1: 0.502180, loss_fp: 0.500055, loss_freq: 0.501041
[02:41:50.315] iteration 1247: loss: 0.859776, loss_s1: 0.503746, loss_fp: 0.500307, loss_freq: 0.502099
[02:41:50.904] iteration 1248: loss: 0.891642, loss_s1: 0.501926, loss_fp: 0.500073, loss_freq: 0.503496
[02:41:51.493] iteration 1249: loss: 0.902762, loss_s1: 0.500540, loss_fp: 0.500019, loss_freq: 0.500849
[02:41:52.082] iteration 1250: loss: 0.887403, loss_s1: 0.506132, loss_fp: 0.500043, loss_freq: 0.502013
[02:41:52.671] iteration 1251: loss: 0.757141, loss_s1: 0.497500, loss_fp: 0.246573, loss_freq: 0.496516
[02:41:53.259] iteration 1252: loss: 0.939865, loss_s1: 0.500914, loss_fp: 0.500012, loss_freq: 0.500659
[02:41:53.850] iteration 1253: loss: 0.912509, loss_s1: 0.504894, loss_fp: 0.500040, loss_freq: 0.501084
[02:41:54.438] iteration 1254: loss: 0.891364, loss_s1: 0.501067, loss_fp: 0.500038, loss_freq: 0.500558
[02:41:55.107] iteration 1255: loss: 0.844235, loss_s1: 0.503343, loss_fp: 0.500104, loss_freq: 0.502185
[02:41:55.733] iteration 1256: loss: 0.853971, loss_s1: 0.506011, loss_fp: 0.500069, loss_freq: 0.504904
[02:41:56.364] iteration 1257: loss: 0.929585, loss_s1: 0.505115, loss_fp: 0.500013, loss_freq: 0.503011
[02:41:56.992] iteration 1258: loss: 0.866031, loss_s1: 0.506497, loss_fp: 0.500015, loss_freq: 0.501362
[02:41:57.604] iteration 1259: loss: 0.885989, loss_s1: 0.504647, loss_fp: 0.500009, loss_freq: 0.503574
[02:41:58.187] iteration 1260: loss: 0.909144, loss_s1: 0.505833, loss_fp: 0.500009, loss_freq: 0.501318
[02:41:58.778] iteration 1261: loss: 0.916749, loss_s1: 0.508118, loss_fp: 0.499998, loss_freq: 0.501461
[02:41:59.366] iteration 1262: loss: 0.896743, loss_s1: 0.505860, loss_fp: 0.500016, loss_freq: 0.503694
[02:41:59.959] iteration 1263: loss: 0.861885, loss_s1: 0.503533, loss_fp: 0.500002, loss_freq: 0.502067
[02:42:00.545] iteration 1264: loss: 0.909918, loss_s1: 0.504947, loss_fp: 0.502248, loss_freq: 0.506976
[02:42:01.130] iteration 1265: loss: 0.912139, loss_s1: 0.504370, loss_fp: 0.500056, loss_freq: 0.501526
[02:42:01.759] iteration 1266: loss: 0.874437, loss_s1: 0.502864, loss_fp: 0.500044, loss_freq: 0.500384
[02:42:02.344] iteration 1267: loss: 0.863895, loss_s1: 0.501918, loss_fp: 0.500001, loss_freq: 0.501864
[02:42:02.984] iteration 1268: loss: 0.871757, loss_s1: 0.502783, loss_fp: 0.500007, loss_freq: 0.501859
[02:42:03.567] iteration 1269: loss: 0.918891, loss_s1: 0.506195, loss_fp: 0.500003, loss_freq: 0.503670
[02:42:04.154] iteration 1270: loss: 0.894859, loss_s1: 0.501018, loss_fp: 0.500043, loss_freq: 0.501680
[02:42:04.746] iteration 1271: loss: 0.895006, loss_s1: 0.501492, loss_fp: 0.500018, loss_freq: 0.502290
[02:42:05.334] iteration 1272: loss: 0.929355, loss_s1: 0.502113, loss_fp: 0.500031, loss_freq: 0.501556
[02:42:05.924] iteration 1273: loss: 0.882966, loss_s1: 0.501478, loss_fp: 0.500004, loss_freq: 0.500799
[02:42:06.713] iteration 1274: loss: 0.894979, loss_s1: 0.501212, loss_fp: 0.500020, loss_freq: 0.500887
[02:42:07.486] iteration 1275: loss: 0.899532, loss_s1: 0.502342, loss_fp: 0.500146, loss_freq: 0.502042
[02:42:08.144] iteration 1276: loss: 0.870307, loss_s1: 0.501422, loss_fp: 0.500048, loss_freq: 0.500836
[02:42:08.779] iteration 1277: loss: 0.864784, loss_s1: 0.500953, loss_fp: 0.500047, loss_freq: 0.500267
[02:42:09.360] iteration 1278: loss: 0.874981, loss_s1: 0.501978, loss_fp: 0.500003, loss_freq: 0.501744
[02:42:09.945] iteration 1279: loss: 0.871220, loss_s1: 0.502250, loss_fp: 0.500010, loss_freq: 0.501018
[02:42:10.538] iteration 1280: loss: 0.888415, loss_s1: 0.500997, loss_fp: 0.500154, loss_freq: 0.501542
[02:42:11.138] iteration 1281: loss: 0.908466, loss_s1: 0.503168, loss_fp: 0.500004, loss_freq: 0.501765
[02:42:11.736] iteration 1282: loss: 0.846156, loss_s1: 0.501554, loss_fp: 0.500003, loss_freq: 0.502261
[02:42:12.326] iteration 1283: loss: 0.914941, loss_s1: 0.503143, loss_fp: 0.500028, loss_freq: 0.501744
[02:42:12.917] iteration 1284: loss: 0.882846, loss_s1: 0.503023, loss_fp: 0.500056, loss_freq: 0.501744
[02:42:13.517] iteration 1285: loss: 0.863795, loss_s1: 0.502021, loss_fp: 0.499998, loss_freq: 0.500260
[02:42:14.110] iteration 1286: loss: 0.877531, loss_s1: 0.502779, loss_fp: 0.500006, loss_freq: 0.500564
[02:42:14.705] iteration 1287: loss: 0.948187, loss_s1: 0.504970, loss_fp: 0.500013, loss_freq: 0.500865
[02:42:15.297] iteration 1288: loss: 0.878021, loss_s1: 0.503206, loss_fp: 0.500041, loss_freq: 0.504857
[02:42:15.887] iteration 1289: loss: 0.875853, loss_s1: 0.504413, loss_fp: 0.500005, loss_freq: 0.500682
[02:42:16.489] iteration 1290: loss: 0.863439, loss_s1: 0.504388, loss_fp: 0.500225, loss_freq: 0.501364
[02:42:17.081] iteration 1291: loss: 0.835436, loss_s1: 0.504243, loss_fp: 0.500079, loss_freq: 0.502331
[02:42:17.671] iteration 1292: loss: 0.910632, loss_s1: 0.503241, loss_fp: 0.500010, loss_freq: 0.502896
[02:42:18.257] iteration 1293: loss: 0.867647, loss_s1: 0.502850, loss_fp: 0.500012, loss_freq: 0.500300
[02:42:18.861] iteration 1294: loss: 0.891021, loss_s1: 0.504886, loss_fp: 0.500023, loss_freq: 0.504269
[02:42:19.446] iteration 1295: loss: 0.859075, loss_s1: 0.501190, loss_fp: 0.500020, loss_freq: 0.502575
[02:42:20.025] iteration 1296: loss: 0.887141, loss_s1: 0.502445, loss_fp: 0.500069, loss_freq: 0.502304
[02:42:20.614] iteration 1297: loss: 0.851503, loss_s1: 0.502399, loss_fp: 0.500000, loss_freq: 0.501669
[02:42:21.202] iteration 1298: loss: 0.874797, loss_s1: 0.506220, loss_fp: 0.500007, loss_freq: 0.500252
[02:42:21.789] iteration 1299: loss: 0.878556, loss_s1: 0.504201, loss_fp: 0.500008, loss_freq: 0.509792
[02:42:22.372] iteration 1300: loss: 0.843717, loss_s1: 0.502430, loss_fp: 0.499997, loss_freq: 0.500528
[02:42:22.965] iteration 1301: loss: 0.873109, loss_s1: 0.502530, loss_fp: 0.500009, loss_freq: 0.501927
[02:42:23.591] iteration 1302: loss: 0.874198, loss_s1: 0.501615, loss_fp: 0.500009, loss_freq: 0.500648
[02:42:24.223] iteration 1303: loss: 0.864054, loss_s1: 0.500524, loss_fp: 0.500151, loss_freq: 0.500199
[02:42:24.857] iteration 1304: loss: 0.865422, loss_s1: 0.505416, loss_fp: 0.500042, loss_freq: 0.502388
[02:42:25.490] iteration 1305: loss: 0.889071, loss_s1: 0.502035, loss_fp: 0.502067, loss_freq: 0.505956
[02:42:26.148] iteration 1306: loss: 0.875359, loss_s1: 0.502616, loss_fp: 0.500022, loss_freq: 0.506152
[02:42:26.787] iteration 1307: loss: 0.857236, loss_s1: 0.504066, loss_fp: 0.500007, loss_freq: 0.501770
[02:42:27.422] iteration 1308: loss: 0.634163, loss_s1: 0.485533, loss_fp: 0.089787, loss_freq: 0.435614
[02:42:28.047] iteration 1309: loss: 0.894131, loss_s1: 0.501767, loss_fp: 0.500171, loss_freq: 0.500829
[02:42:28.641] iteration 1310: loss: 0.932598, loss_s1: 0.502348, loss_fp: 0.500006, loss_freq: 0.503917
[02:42:29.241] iteration 1311: loss: 0.861309, loss_s1: 0.501098, loss_fp: 0.499998, loss_freq: 0.500286
[02:42:29.835] iteration 1312: loss: 0.872408, loss_s1: 0.502393, loss_fp: 0.500025, loss_freq: 0.500526
[02:42:30.434] iteration 1313: loss: 0.848512, loss_s1: 0.502180, loss_fp: 0.500005, loss_freq: 0.502469
[02:42:31.096] iteration 1314: loss: 0.861741, loss_s1: 0.501893, loss_fp: 0.500013, loss_freq: 0.503619
[02:42:31.728] iteration 1315: loss: 0.877637, loss_s1: 0.502473, loss_fp: 0.499999, loss_freq: 0.500668
[02:42:32.362] iteration 1316: loss: 0.851798, loss_s1: 0.502532, loss_fp: 0.500002, loss_freq: 0.500512
[02:42:32.953] iteration 1317: loss: 0.874388, loss_s1: 0.505516, loss_fp: 0.500076, loss_freq: 0.504161
[02:42:33.553] iteration 1318: loss: 0.893663, loss_s1: 0.502928, loss_fp: 0.500040, loss_freq: 0.505387
[02:42:34.147] iteration 1319: loss: 0.855400, loss_s1: 0.502479, loss_fp: 0.500003, loss_freq: 0.504593
[02:42:34.740] iteration 1320: loss: 0.883047, loss_s1: 0.503443, loss_fp: 0.500016, loss_freq: 0.503739
[02:42:35.332] iteration 1321: loss: 0.865338, loss_s1: 0.503336, loss_fp: 0.500009, loss_freq: 0.500461
[02:42:35.932] iteration 1322: loss: 0.861350, loss_s1: 0.501162, loss_fp: 0.500003, loss_freq: 0.500484
[02:42:36.525] iteration 1323: loss: 0.869013, loss_s1: 0.501406, loss_fp: 0.500004, loss_freq: 0.500519
[02:42:37.118] iteration 1324: loss: 0.872285, loss_s1: 0.505950, loss_fp: 0.500009, loss_freq: 0.502141
[02:42:37.716] iteration 1325: loss: 0.890358, loss_s1: 0.504197, loss_fp: 0.500005, loss_freq: 0.500687
[02:42:38.365] iteration 1326: loss: 0.823538, loss_s1: 0.502607, loss_fp: 0.500006, loss_freq: 0.501410
[02:42:39.000] iteration 1327: loss: 0.920105, loss_s1: 0.502611, loss_fp: 0.500174, loss_freq: 0.501413
[02:42:39.596] iteration 1328: loss: 0.549140, loss_s1: 0.377795, loss_fp: 0.078727, loss_freq: 0.440688
[02:42:40.187] iteration 1329: loss: 0.854308, loss_s1: 0.500930, loss_fp: 0.500000, loss_freq: 0.500664
[02:42:40.790] iteration 1330: loss: 0.878631, loss_s1: 0.501041, loss_fp: 0.500028, loss_freq: 0.501009
[02:42:41.394] iteration 1331: loss: 0.879712, loss_s1: 0.491950, loss_fp: 0.439220, loss_freq: 0.483978
[02:42:42.004] iteration 1332: loss: 0.886781, loss_s1: 0.501596, loss_fp: 0.500000, loss_freq: 0.500731
[02:42:42.601] iteration 1333: loss: 0.897575, loss_s1: 0.495166, loss_fp: 0.499999, loss_freq: 0.500377
[02:42:43.198] iteration 1334: loss: 0.938706, loss_s1: 0.503650, loss_fp: 0.500026, loss_freq: 0.500782
[02:42:43.790] iteration 1335: loss: 1.117583, loss_s1: 0.502518, loss_fp: 0.500020, loss_freq: 0.500165
[02:42:44.384] iteration 1336: loss: 0.927076, loss_s1: 0.500961, loss_fp: 0.500008, loss_freq: 0.500351
[02:42:44.981] iteration 1337: loss: 0.492552, loss_s1: 0.456467, loss_fp: 0.036033, loss_freq: 0.162225
[02:42:45.572] iteration 1338: loss: 0.446179, loss_s1: 0.426592, loss_fp: 0.019102, loss_freq: 0.050441
[02:42:46.168] iteration 1339: loss: 0.864055, loss_s1: 0.501584, loss_fp: 0.500004, loss_freq: 0.500840
[02:42:46.760] iteration 1340: loss: 0.443364, loss_s1: 0.186606, loss_fp: 0.054683, loss_freq: 0.061835
[02:42:47.353] iteration 1341: loss: 0.719307, loss_s1: 0.431240, loss_fp: 0.005488, loss_freq: 0.301559
[02:42:47.949] iteration 1342: loss: 0.643271, loss_s1: 0.380382, loss_fp: 0.023043, loss_freq: 0.082564
[02:42:48.544] iteration 1343: loss: 1.010480, loss_s1: 0.500321, loss_fp: 0.500014, loss_freq: 0.500210
[02:42:49.134] iteration 1344: loss: 0.698258, loss_s1: 0.334654, loss_fp: 0.031235, loss_freq: 0.255606
[02:42:49.732] iteration 1345: loss: 0.685962, loss_s1: 0.452152, loss_fp: 0.014552, loss_freq: 0.247336
[02:42:50.329] iteration 1346: loss: 0.965893, loss_s1: 0.503332, loss_fp: 0.500005, loss_freq: 0.500523
[02:42:50.920] iteration 1347: loss: 1.114658, loss_s1: 0.501551, loss_fp: 0.500030, loss_freq: 0.500584
[02:42:51.513] iteration 1348: loss: 1.050404, loss_s1: 0.503622, loss_fp: 0.500061, loss_freq: 0.500121
[02:42:52.106] iteration 1349: loss: 1.057146, loss_s1: 0.500842, loss_fp: 0.500068, loss_freq: 0.500743
[02:42:52.697] iteration 1350: loss: 1.011365, loss_s1: 0.506282, loss_fp: 0.500013, loss_freq: 0.500126
[02:42:53.294] iteration 1351: loss: 0.700389, loss_s1: 0.481913, loss_fp: 0.056897, loss_freq: 0.451292
[02:42:53.888] iteration 1352: loss: 1.032359, loss_s1: 0.504585, loss_fp: 0.500018, loss_freq: 0.500681
[02:42:54.481] iteration 1353: loss: 0.787136, loss_s1: 0.456476, loss_fp: 0.147326, loss_freq: 0.409992
[02:42:55.072] iteration 1354: loss: 0.957352, loss_s1: 0.502071, loss_fp: 0.500101, loss_freq: 0.501082
[02:42:55.673] iteration 1355: loss: 0.522389, loss_s1: 0.495858, loss_fp: 0.013884, loss_freq: 0.066741
[02:42:56.270] iteration 1356: loss: 0.651073, loss_s1: 0.477196, loss_fp: 0.025007, loss_freq: 0.311298
[02:42:56.863] iteration 1357: loss: 1.121919, loss_s1: 0.504215, loss_fp: 0.500019, loss_freq: 0.501300
[02:42:57.467] iteration 1358: loss: 0.923197, loss_s1: 0.512197, loss_fp: 0.500010, loss_freq: 0.501874
[02:42:58.056] iteration 1359: loss: 1.106334, loss_s1: 0.506879, loss_fp: 0.500022, loss_freq: 0.501071
[02:42:58.657] iteration 1360: loss: 1.041744, loss_s1: 0.511572, loss_fp: 0.500006, loss_freq: 0.503161
[02:42:59.581] iteration 1361: loss: 0.698079, loss_s1: 0.474262, loss_fp: 0.017493, loss_freq: 0.392950
[02:43:00.186] iteration 1362: loss: 0.965639, loss_s1: 0.504844, loss_fp: 0.500006, loss_freq: 0.501793
[02:43:00.786] iteration 1363: loss: 0.718265, loss_s1: 0.507724, loss_fp: 0.020550, loss_freq: 0.140662
[02:43:01.379] iteration 1364: loss: 0.851492, loss_s1: 0.495408, loss_fp: 0.174869, loss_freq: 0.497492
[02:43:01.975] iteration 1365: loss: 1.068120, loss_s1: 0.505175, loss_fp: 0.500025, loss_freq: 0.500541
[02:43:02.562] iteration 1366: loss: 1.046951, loss_s1: 0.505147, loss_fp: 0.500000, loss_freq: 0.500457
[02:43:03.153] iteration 1367: loss: 1.103077, loss_s1: 0.501550, loss_fp: 0.500004, loss_freq: 0.500796
[02:43:03.745] iteration 1368: loss: 1.001540, loss_s1: 0.503392, loss_fp: 0.500024, loss_freq: 0.502205
[02:43:04.338] iteration 1369: loss: 0.952428, loss_s1: 0.504505, loss_fp: 0.500337, loss_freq: 0.502813
[02:43:04.933] iteration 1370: loss: 0.987741, loss_s1: 0.506388, loss_fp: 0.500001, loss_freq: 0.500591
[02:43:05.570] iteration 1371: loss: 1.024485, loss_s1: 0.506391, loss_fp: 0.500000, loss_freq: 0.502648
[02:43:06.236] iteration 1372: loss: 1.038005, loss_s1: 0.501586, loss_fp: 0.499999, loss_freq: 0.501177
[02:43:06.869] iteration 1373: loss: 1.080610, loss_s1: 0.507583, loss_fp: 0.500136, loss_freq: 0.502295
[02:43:07.502] iteration 1374: loss: 0.969656, loss_s1: 0.505613, loss_fp: 0.500016, loss_freq: 0.505032
[02:43:08.132] iteration 1375: loss: 0.986167, loss_s1: 0.506637, loss_fp: 0.500012, loss_freq: 0.501299
[02:43:08.767] iteration 1376: loss: 0.972256, loss_s1: 0.504693, loss_fp: 0.500060, loss_freq: 0.500536
[02:43:09.359] iteration 1377: loss: 0.991574, loss_s1: 0.505067, loss_fp: 0.500008, loss_freq: 0.500599
[02:43:09.947] iteration 1378: loss: 0.989173, loss_s1: 0.508522, loss_fp: 0.500099, loss_freq: 0.501447
[02:43:10.535] iteration 1379: loss: 0.962080, loss_s1: 0.506126, loss_fp: 0.500023, loss_freq: 0.500140
[02:43:11.129] iteration 1380: loss: 1.011162, loss_s1: 0.503551, loss_fp: 0.500070, loss_freq: 0.500890
[02:43:11.719] iteration 1381: loss: 0.974839, loss_s1: 0.507659, loss_fp: 0.500008, loss_freq: 0.502735
[02:43:12.313] iteration 1382: loss: 0.979369, loss_s1: 0.506366, loss_fp: 0.500058, loss_freq: 0.501065
[02:43:12.904] iteration 1383: loss: 0.996527, loss_s1: 0.504531, loss_fp: 0.500044, loss_freq: 0.501436
[02:43:13.496] iteration 1384: loss: 0.935027, loss_s1: 0.507554, loss_fp: 0.500016, loss_freq: 0.503261
[02:43:14.095] iteration 1385: loss: 0.947672, loss_s1: 0.512363, loss_fp: 0.500022, loss_freq: 0.501091
[02:43:14.692] iteration 1386: loss: 0.967531, loss_s1: 0.507779, loss_fp: 0.500053, loss_freq: 0.501985
[02:43:15.286] iteration 1387: loss: 0.967007, loss_s1: 0.511233, loss_fp: 0.500095, loss_freq: 0.501234
[02:43:15.885] iteration 1388: loss: 0.951956, loss_s1: 0.514958, loss_fp: 0.500060, loss_freq: 0.503994
[02:43:16.488] iteration 1389: loss: 1.037203, loss_s1: 0.509251, loss_fp: 0.500150, loss_freq: 0.506164
[02:43:17.087] iteration 1390: loss: 0.966658, loss_s1: 0.507865, loss_fp: 0.500077, loss_freq: 0.502002
[02:43:17.675] iteration 1391: loss: 0.920120, loss_s1: 0.508998, loss_fp: 0.500448, loss_freq: 0.501877
[02:43:18.266] iteration 1392: loss: 0.975043, loss_s1: 0.509748, loss_fp: 0.500032, loss_freq: 0.501842
[02:43:18.859] iteration 1393: loss: 0.712084, loss_s1: 0.508656, loss_fp: 0.367381, loss_freq: 0.212946
[02:43:19.451] iteration 1394: loss: 0.533104, loss_s1: 0.402205, loss_fp: 0.018467, loss_freq: 0.265465
[02:43:20.044] iteration 1395: loss: 0.974204, loss_s1: 0.504630, loss_fp: 0.500052, loss_freq: 0.501428
[02:43:20.638] iteration 1396: loss: 0.993275, loss_s1: 0.504607, loss_fp: 0.500022, loss_freq: 0.500420
[02:43:21.234] iteration 1397: loss: 0.907428, loss_s1: 0.505132, loss_fp: 0.500043, loss_freq: 0.500899
[02:43:21.832] iteration 1398: loss: 1.034409, loss_s1: 0.506078, loss_fp: 0.500318, loss_freq: 0.500400
[02:43:22.420] iteration 1399: loss: 1.017849, loss_s1: 0.501786, loss_fp: 0.500043, loss_freq: 0.500246
[02:43:23.025] iteration 1400: loss: 1.012311, loss_s1: 0.504563, loss_fp: 0.500070, loss_freq: 0.500630
[02:43:25.213] iteration 1400 : mean_dice : 0.019295
[02:43:25.893] iteration 1401: loss: 0.955310, loss_s1: 0.507485, loss_fp: 0.500078, loss_freq: 0.501087
[02:43:26.547] iteration 1402: loss: 0.951214, loss_s1: 0.504107, loss_fp: 0.500041, loss_freq: 0.502182
[02:43:27.185] iteration 1403: loss: 0.562882, loss_s1: 0.477505, loss_fp: 0.079408, loss_freq: 0.200104
[02:43:27.814] iteration 1404: loss: 0.927577, loss_s1: 0.506783, loss_fp: 0.500141, loss_freq: 0.500565
[02:43:28.413] iteration 1405: loss: 0.633519, loss_s1: 0.444774, loss_fp: 0.128551, loss_freq: 0.312833
[02:43:29.019] iteration 1406: loss: 0.907492, loss_s1: 0.503407, loss_fp: 0.500026, loss_freq: 0.501802
[02:43:29.618] iteration 1407: loss: 1.023960, loss_s1: 0.502024, loss_fp: 0.500005, loss_freq: 0.500438
[02:43:30.213] iteration 1408: loss: 0.961734, loss_s1: 0.509901, loss_fp: 0.500004, loss_freq: 0.502200
[02:43:30.807] iteration 1409: loss: 0.862581, loss_s1: 0.255247, loss_fp: 0.500004, loss_freq: 0.500551
[02:43:31.419] iteration 1410: loss: 0.984553, loss_s1: 0.512403, loss_fp: 0.500010, loss_freq: 0.502527
[02:43:32.022] iteration 1411: loss: 0.979385, loss_s1: 0.505415, loss_fp: 0.500003, loss_freq: 0.502695
[02:43:32.613] iteration 1412: loss: 1.001593, loss_s1: 0.504857, loss_fp: 0.500037, loss_freq: 0.500789
[02:43:33.215] iteration 1413: loss: 1.053331, loss_s1: 0.503687, loss_fp: 0.500005, loss_freq: 0.500797
[02:43:33.811] iteration 1414: loss: 0.926306, loss_s1: 0.506222, loss_fp: 0.500040, loss_freq: 0.502210
[02:43:34.406] iteration 1415: loss: 1.023023, loss_s1: 0.501371, loss_fp: 0.500000, loss_freq: 0.501048
[02:43:35.005] iteration 1416: loss: 1.010393, loss_s1: 0.504358, loss_fp: 0.500002, loss_freq: 0.500317
[02:43:35.632] iteration 1417: loss: 0.990328, loss_s1: 0.503285, loss_fp: 0.500023, loss_freq: 0.500099
[02:43:36.247] iteration 1418: loss: 1.008725, loss_s1: 0.507461, loss_fp: 0.500006, loss_freq: 0.501001
[02:43:36.851] iteration 1419: loss: 0.996692, loss_s1: 0.501906, loss_fp: 0.500010, loss_freq: 0.500370
[02:43:37.454] iteration 1420: loss: 0.940939, loss_s1: 0.503404, loss_fp: 0.500087, loss_freq: 0.500518
[02:43:38.042] iteration 1421: loss: 1.010666, loss_s1: 0.502628, loss_fp: 0.500002, loss_freq: 0.500302
[02:43:38.633] iteration 1422: loss: 0.984443, loss_s1: 0.503405, loss_fp: 0.500003, loss_freq: 0.500401
[02:43:39.234] iteration 1423: loss: 0.920869, loss_s1: 0.505195, loss_fp: 0.500044, loss_freq: 0.500225
[02:43:39.833] iteration 1424: loss: 1.050223, loss_s1: 0.501521, loss_fp: 0.500001, loss_freq: 0.500200
[02:43:40.420] iteration 1425: loss: 0.962185, loss_s1: 0.503550, loss_fp: 0.500007, loss_freq: 0.501051
[02:43:41.005] iteration 1426: loss: 0.910672, loss_s1: 0.504006, loss_fp: 0.500003, loss_freq: 0.500405
[02:43:41.587] iteration 1427: loss: 0.965357, loss_s1: 0.503092, loss_fp: 0.500014, loss_freq: 0.500963
[02:43:42.173] iteration 1428: loss: 0.941196, loss_s1: 0.500545, loss_fp: 0.500004, loss_freq: 0.500530
[02:43:42.761] iteration 1429: loss: 0.989598, loss_s1: 0.504255, loss_fp: 0.500027, loss_freq: 0.502233
[02:43:43.344] iteration 1430: loss: 0.966073, loss_s1: 0.502583, loss_fp: 0.500003, loss_freq: 0.500279
[02:43:43.928] iteration 1431: loss: 0.935954, loss_s1: 0.503485, loss_fp: 0.500021, loss_freq: 0.500684
[02:43:44.560] iteration 1432: loss: 0.891590, loss_s1: 0.507295, loss_fp: 0.500080, loss_freq: 0.500554
[02:43:45.143] iteration 1433: loss: 0.992406, loss_s1: 0.505381, loss_fp: 0.500053, loss_freq: 0.500787
[02:43:45.731] iteration 1434: loss: 0.933419, loss_s1: 0.508641, loss_fp: 0.500001, loss_freq: 0.500857
[02:43:46.322] iteration 1435: loss: 0.947454, loss_s1: 0.506711, loss_fp: 0.500013, loss_freq: 0.501600
[02:43:46.947] iteration 1436: loss: 0.916988, loss_s1: 0.502531, loss_fp: 0.500016, loss_freq: 0.503525
[02:43:47.554] iteration 1437: loss: 0.925846, loss_s1: 0.505870, loss_fp: 0.500035, loss_freq: 0.501403
[02:43:48.141] iteration 1438: loss: 0.988953, loss_s1: 0.512321, loss_fp: 0.500014, loss_freq: 0.501658
[02:43:48.739] iteration 1439: loss: 0.918832, loss_s1: 0.503808, loss_fp: 0.500012, loss_freq: 0.500594
[02:43:49.333] iteration 1440: loss: 0.521463, loss_s1: 0.402110, loss_fp: 0.020255, loss_freq: 0.232910
[02:43:49.932] iteration 1441: loss: 0.874486, loss_s1: 0.504234, loss_fp: 0.500028, loss_freq: 0.502319
[02:43:50.531] iteration 1442: loss: 0.965601, loss_s1: 0.505898, loss_fp: 0.500016, loss_freq: 0.500881
[02:43:51.128] iteration 1443: loss: 0.935363, loss_s1: 0.502298, loss_fp: 0.500067, loss_freq: 0.500261
[02:43:51.724] iteration 1444: loss: 1.031772, loss_s1: 0.503785, loss_fp: 0.500048, loss_freq: 0.502124
[02:43:52.311] iteration 1445: loss: 1.056873, loss_s1: 0.510290, loss_fp: 0.500013, loss_freq: 0.503389
[02:43:52.902] iteration 1446: loss: 0.940076, loss_s1: 0.502707, loss_fp: 0.500066, loss_freq: 0.502877
[02:43:53.497] iteration 1447: loss: 0.899663, loss_s1: 0.501001, loss_fp: 0.500011, loss_freq: 0.500304
[02:43:54.088] iteration 1448: loss: 0.941751, loss_s1: 0.504565, loss_fp: 0.500020, loss_freq: 0.503128
[02:43:54.686] iteration 1449: loss: 0.867661, loss_s1: 0.505336, loss_fp: 0.500026, loss_freq: 0.500570
[02:43:55.285] iteration 1450: loss: 0.941328, loss_s1: 0.501578, loss_fp: 0.500014, loss_freq: 0.500880
[02:43:55.887] iteration 1451: loss: 0.919916, loss_s1: 0.506436, loss_fp: 0.500016, loss_freq: 0.501225
[02:43:56.487] iteration 1452: loss: 0.855921, loss_s1: 0.503872, loss_fp: 0.500787, loss_freq: 0.502338
[02:43:57.075] iteration 1453: loss: 0.964538, loss_s1: 0.508073, loss_fp: 0.500101, loss_freq: 0.500783
[02:43:57.666] iteration 1454: loss: 0.893425, loss_s1: 0.506727, loss_fp: 0.500021, loss_freq: 0.500929
[02:43:58.247] iteration 1455: loss: 0.909572, loss_s1: 0.499929, loss_fp: 0.500019, loss_freq: 0.500436
[02:43:58.838] iteration 1456: loss: 0.888538, loss_s1: 0.503098, loss_fp: 0.500029, loss_freq: 0.500160
[02:43:59.424] iteration 1457: loss: 0.896387, loss_s1: 0.502274, loss_fp: 0.500025, loss_freq: 0.500929
[02:44:00.023] iteration 1458: loss: 0.909661, loss_s1: 0.505594, loss_fp: 0.500007, loss_freq: 0.501963
[02:44:00.610] iteration 1459: loss: 0.917293, loss_s1: 0.501593, loss_fp: 0.500048, loss_freq: 0.500172
[02:44:01.197] iteration 1460: loss: 0.880139, loss_s1: 0.509057, loss_fp: 0.500014, loss_freq: 0.500868
[02:44:01.790] iteration 1461: loss: 0.871849, loss_s1: 0.504128, loss_fp: 0.500012, loss_freq: 0.501008
[02:44:02.389] iteration 1462: loss: 0.938065, loss_s1: 0.505071, loss_fp: 0.500013, loss_freq: 0.503733
[02:44:02.983] iteration 1463: loss: 0.895628, loss_s1: 0.502834, loss_fp: 0.500017, loss_freq: 0.500222
[02:44:03.621] iteration 1464: loss: 0.948331, loss_s1: 0.508774, loss_fp: 0.500039, loss_freq: 0.503910
[02:44:04.258] iteration 1465: loss: 0.896666, loss_s1: 0.504661, loss_fp: 0.500018, loss_freq: 0.501571
[02:44:04.881] iteration 1466: loss: 0.872889, loss_s1: 0.509138, loss_fp: 0.500030, loss_freq: 0.500890
[02:44:05.481] iteration 1467: loss: 0.898967, loss_s1: 0.509394, loss_fp: 0.500026, loss_freq: 0.502887
[02:44:06.083] iteration 1468: loss: 0.924061, loss_s1: 0.511753, loss_fp: 0.500039, loss_freq: 0.501232
[02:44:06.687] iteration 1469: loss: 0.895793, loss_s1: 0.509214, loss_fp: 0.500016, loss_freq: 0.510976
[02:44:07.280] iteration 1470: loss: 0.900427, loss_s1: 0.504360, loss_fp: 0.500037, loss_freq: 0.501848
[02:44:07.872] iteration 1471: loss: 0.969313, loss_s1: 0.505610, loss_fp: 0.500040, loss_freq: 0.505702
[02:44:08.468] iteration 1472: loss: 0.888988, loss_s1: 0.501908, loss_fp: 0.500020, loss_freq: 0.502034
[02:44:09.060] iteration 1473: loss: 0.830981, loss_s1: 0.275610, loss_fp: 0.500040, loss_freq: 0.500470
[02:44:09.649] iteration 1474: loss: 0.873276, loss_s1: 0.503627, loss_fp: 0.500020, loss_freq: 0.502537
[02:44:10.245] iteration 1475: loss: 0.942833, loss_s1: 0.508860, loss_fp: 0.500039, loss_freq: 0.504117
[02:44:10.833] iteration 1476: loss: 0.870996, loss_s1: 0.506588, loss_fp: 0.500142, loss_freq: 0.504406
[02:44:11.436] iteration 1477: loss: 0.884696, loss_s1: 0.504206, loss_fp: 0.500038, loss_freq: 0.501710
[02:44:12.038] iteration 1478: loss: 0.634068, loss_s1: 0.480493, loss_fp: 0.077381, loss_freq: 0.464684
[02:44:12.623] iteration 1479: loss: 0.910749, loss_s1: 0.507705, loss_fp: 0.500082, loss_freq: 0.504247
[02:44:13.217] iteration 1480: loss: 0.951482, loss_s1: 0.503726, loss_fp: 0.500017, loss_freq: 0.503671
[02:44:13.807] iteration 1481: loss: 0.542308, loss_s1: 0.444432, loss_fp: 0.025233, loss_freq: 0.233073
[02:44:14.405] iteration 1482: loss: 0.879965, loss_s1: 0.414733, loss_fp: 0.500064, loss_freq: 0.500210
[02:44:14.998] iteration 1483: loss: 0.896613, loss_s1: 0.503593, loss_fp: 0.500016, loss_freq: 0.501744
[02:44:15.594] iteration 1484: loss: 0.898699, loss_s1: 0.505602, loss_fp: 0.500017, loss_freq: 0.501240
[02:44:16.187] iteration 1485: loss: 0.926782, loss_s1: 0.500045, loss_fp: 0.500015, loss_freq: 0.500163
[02:44:16.776] iteration 1486: loss: 0.997459, loss_s1: 0.502438, loss_fp: 0.500007, loss_freq: 0.500321
[02:44:17.380] iteration 1487: loss: 0.885002, loss_s1: 0.504963, loss_fp: 0.500008, loss_freq: 0.502887
[02:44:18.021] iteration 1488: loss: 0.989022, loss_s1: 0.506366, loss_fp: 0.500002, loss_freq: 0.504613
[02:44:18.661] iteration 1489: loss: 0.446435, loss_s1: 0.281248, loss_fp: 0.008377, loss_freq: 0.279794
[02:44:19.303] iteration 1490: loss: 0.886109, loss_s1: 0.505095, loss_fp: 0.500030, loss_freq: 0.501821
[02:44:19.938] iteration 1491: loss: 0.944111, loss_s1: 0.501979, loss_fp: 0.500008, loss_freq: 0.500061
[02:44:20.554] iteration 1492: loss: 1.031657, loss_s1: 0.502501, loss_fp: 0.500005, loss_freq: 0.500191
[02:44:21.134] iteration 1493: loss: 0.910899, loss_s1: 0.503297, loss_fp: 0.500020, loss_freq: 0.500474
[02:44:21.727] iteration 1494: loss: 0.554437, loss_s1: 0.501660, loss_fp: 0.070594, loss_freq: 0.126617
[02:44:22.318] iteration 1495: loss: 1.033551, loss_s1: 0.503682, loss_fp: 0.500039, loss_freq: 0.500788
[02:44:22.911] iteration 1496: loss: 0.862011, loss_s1: 0.503727, loss_fp: 0.500020, loss_freq: 0.501736
[02:44:23.621] iteration 1497: loss: 1.093841, loss_s1: 0.501355, loss_fp: 0.500006, loss_freq: 0.500387
[02:44:24.250] iteration 1498: loss: 0.883111, loss_s1: 0.506894, loss_fp: 0.500006, loss_freq: 0.500812
[02:44:24.880] iteration 1499: loss: 0.968286, loss_s1: 0.504424, loss_fp: 0.500071, loss_freq: 0.500125
[02:44:25.512] iteration 1500: loss: 0.933505, loss_s1: 0.509847, loss_fp: 0.500002, loss_freq: 0.500317
[02:44:26.144] iteration 1501: loss: 0.926594, loss_s1: 0.506226, loss_fp: 0.500015, loss_freq: 0.500839
[02:44:26.791] iteration 1502: loss: 0.916787, loss_s1: 0.507094, loss_fp: 0.500020, loss_freq: 0.500736
[02:44:27.392] iteration 1503: loss: 0.995558, loss_s1: 0.506697, loss_fp: 0.500006, loss_freq: 0.500487
[02:44:27.988] iteration 1504: loss: 0.956054, loss_s1: 0.505260, loss_fp: 0.500002, loss_freq: 0.500262
[02:44:28.619] iteration 1505: loss: 0.960719, loss_s1: 0.505619, loss_fp: 0.500005, loss_freq: 0.501086
[02:44:29.257] iteration 1506: loss: 0.904772, loss_s1: 0.503726, loss_fp: 0.500011, loss_freq: 0.501210
[02:44:29.896] iteration 1507: loss: 0.919711, loss_s1: 0.506155, loss_fp: 0.500026, loss_freq: 0.500167
[02:44:30.536] iteration 1508: loss: 0.967810, loss_s1: 0.506997, loss_fp: 0.500005, loss_freq: 0.500098
[02:44:31.128] iteration 1509: loss: 0.907369, loss_s1: 0.509538, loss_fp: 0.500010, loss_freq: 0.500359
[02:44:31.727] iteration 1510: loss: 0.904496, loss_s1: 0.504493, loss_fp: 0.500021, loss_freq: 0.500342
[02:44:32.328] iteration 1511: loss: 0.922854, loss_s1: 0.504855, loss_fp: 0.500011, loss_freq: 0.500711
[02:44:32.917] iteration 1512: loss: 0.930267, loss_s1: 0.504057, loss_fp: 0.500011, loss_freq: 0.500502
[02:44:33.517] iteration 1513: loss: 0.935636, loss_s1: 0.503777, loss_fp: 0.500003, loss_freq: 0.501007
[02:44:34.115] iteration 1514: loss: 0.884698, loss_s1: 0.460692, loss_fp: 0.487021, loss_freq: 0.497768
[02:44:34.706] iteration 1515: loss: 0.929973, loss_s1: 0.505305, loss_fp: 0.500011, loss_freq: 0.500271
[02:44:35.304] iteration 1516: loss: 0.904619, loss_s1: 0.507235, loss_fp: 0.500052, loss_freq: 0.500717
[02:44:35.935] iteration 1517: loss: 0.919290, loss_s1: 0.499284, loss_fp: 0.500003, loss_freq: 0.501023
[02:44:36.569] iteration 1518: loss: 0.866319, loss_s1: 0.507528, loss_fp: 0.500008, loss_freq: 0.500741
[02:44:37.199] iteration 1519: loss: 0.865282, loss_s1: 0.499468, loss_fp: 0.500008, loss_freq: 0.500403
[02:44:37.824] iteration 1520: loss: 0.919878, loss_s1: 0.504150, loss_fp: 0.500026, loss_freq: 0.501264
[02:44:38.425] iteration 1521: loss: 0.905606, loss_s1: 0.508762, loss_fp: 0.500027, loss_freq: 0.501589
[02:44:39.031] iteration 1522: loss: 0.766728, loss_s1: 0.320161, loss_fp: 0.500045, loss_freq: 0.500384
[02:44:39.624] iteration 1523: loss: 1.055289, loss_s1: 0.505817, loss_fp: 0.500012, loss_freq: 0.502236
[02:44:40.211] iteration 1524: loss: 0.888237, loss_s1: 0.502437, loss_fp: 0.500231, loss_freq: 0.502638
[02:44:40.808] iteration 1525: loss: 0.394783, loss_s1: 0.395129, loss_fp: 0.036711, loss_freq: 0.083322
[02:44:41.398] iteration 1526: loss: 0.489973, loss_s1: 0.497878, loss_fp: 0.048157, loss_freq: 0.165440
[02:44:41.992] iteration 1527: loss: 0.898668, loss_s1: 0.498430, loss_fp: 0.500021, loss_freq: 0.500706
[02:44:42.580] iteration 1528: loss: 0.877771, loss_s1: 0.500569, loss_fp: 0.500014, loss_freq: 0.500415
[02:44:43.170] iteration 1529: loss: 0.581768, loss_s1: 0.490188, loss_fp: 0.028602, loss_freq: 0.070846
[02:44:43.755] iteration 1530: loss: 0.930147, loss_s1: 0.503553, loss_fp: 0.500012, loss_freq: 0.501971
[02:44:44.692] iteration 1531: loss: 0.668340, loss_s1: 0.495178, loss_fp: 0.092771, loss_freq: 0.427328
[02:44:45.291] iteration 1532: loss: 0.865978, loss_s1: 0.424639, loss_fp: 0.500015, loss_freq: 0.500431
[02:44:45.882] iteration 1533: loss: 0.349042, loss_s1: 0.191019, loss_fp: 0.009538, loss_freq: 0.049770
[02:44:46.476] iteration 1534: loss: 0.994658, loss_s1: 0.500862, loss_fp: 0.500001, loss_freq: 0.500136
[02:44:47.076] iteration 1535: loss: 0.376827, loss_s1: 0.209177, loss_fp: 0.003693, loss_freq: 0.014881
[02:44:47.676] iteration 1536: loss: 1.054433, loss_s1: 0.501070, loss_fp: 0.500006, loss_freq: 0.500477
[02:44:48.267] iteration 1537: loss: 1.001373, loss_s1: 0.501701, loss_fp: 0.500148, loss_freq: 0.500869
[02:44:48.878] iteration 1538: loss: 0.968214, loss_s1: 0.501709, loss_fp: 0.500005, loss_freq: 0.500394
[02:44:49.478] iteration 1539: loss: 0.894249, loss_s1: 0.502750, loss_fp: 0.500001, loss_freq: 0.502019
[02:44:50.077] iteration 1540: loss: 1.045151, loss_s1: 0.501126, loss_fp: 0.500012, loss_freq: 0.500476
[02:44:50.681] iteration 1541: loss: 0.921247, loss_s1: 0.501607, loss_fp: 0.499999, loss_freq: 0.500761
[02:44:51.353] iteration 1542: loss: 1.014895, loss_s1: 0.503641, loss_fp: 0.500013, loss_freq: 0.501850
[02:44:52.006] iteration 1543: loss: 1.025444, loss_s1: 0.503752, loss_fp: 0.500006, loss_freq: 0.500632
[02:44:52.605] iteration 1544: loss: 0.904208, loss_s1: 0.501225, loss_fp: 0.500008, loss_freq: 0.501740
[02:44:53.197] iteration 1545: loss: 0.961187, loss_s1: 0.501866, loss_fp: 0.500003, loss_freq: 0.500601
[02:44:53.799] iteration 1546: loss: 0.960268, loss_s1: 0.504340, loss_fp: 0.499999, loss_freq: 0.500391
[02:44:54.391] iteration 1547: loss: 0.941266, loss_s1: 0.503632, loss_fp: 0.500001, loss_freq: 0.500189
[02:44:55.037] iteration 1548: loss: 0.940472, loss_s1: 0.494783, loss_fp: 0.500011, loss_freq: 0.500284
[02:44:55.621] iteration 1549: loss: 0.924730, loss_s1: 0.501770, loss_fp: 0.500004, loss_freq: 0.500214
[02:44:56.214] iteration 1550: loss: 0.880406, loss_s1: 0.375190, loss_fp: 0.500018, loss_freq: 0.500682
[02:44:56.800] iteration 1551: loss: 0.991212, loss_s1: 0.504726, loss_fp: 0.500003, loss_freq: 0.502115
[02:44:57.392] iteration 1552: loss: 0.990662, loss_s1: 0.502471, loss_fp: 0.500022, loss_freq: 0.500517
[02:44:57.979] iteration 1553: loss: 0.977167, loss_s1: 0.500575, loss_fp: 0.500002, loss_freq: 0.500166
[02:44:58.584] iteration 1554: loss: 0.920044, loss_s1: 0.500812, loss_fp: 0.500015, loss_freq: 0.500376
[02:44:59.173] iteration 1555: loss: 0.929572, loss_s1: 0.501600, loss_fp: 0.500001, loss_freq: 0.500243
[02:44:59.771] iteration 1556: loss: 0.919113, loss_s1: 0.503896, loss_fp: 0.500010, loss_freq: 0.500167
[02:45:00.378] iteration 1557: loss: 0.956115, loss_s1: 0.501408, loss_fp: 0.500013, loss_freq: 0.500081
[02:45:00.968] iteration 1558: loss: 0.921057, loss_s1: 0.507294, loss_fp: 0.500002, loss_freq: 0.500819
[02:45:01.570] iteration 1559: loss: 0.704934, loss_s1: 0.478122, loss_fp: 0.088034, loss_freq: 0.488395
[02:45:02.171] iteration 1560: loss: 0.945314, loss_s1: 0.502743, loss_fp: 0.500033, loss_freq: 0.500722
[02:45:02.764] iteration 1561: loss: 0.896176, loss_s1: 0.502661, loss_fp: 0.500022, loss_freq: 0.500290
[02:45:03.370] iteration 1562: loss: 0.964178, loss_s1: 0.501636, loss_fp: 0.500011, loss_freq: 0.501214
[02:45:03.976] iteration 1563: loss: 0.883397, loss_s1: 0.501484, loss_fp: 0.500011, loss_freq: 0.502455
[02:45:04.578] iteration 1564: loss: 0.898657, loss_s1: 0.500792, loss_fp: 0.500003, loss_freq: 0.501596
[02:45:05.172] iteration 1565: loss: 0.895147, loss_s1: 0.501632, loss_fp: 0.500020, loss_freq: 0.500484
[02:45:05.793] iteration 1566: loss: 0.934294, loss_s1: 0.500317, loss_fp: 0.499999, loss_freq: 0.500127
[02:45:06.402] iteration 1567: loss: 0.899976, loss_s1: 0.503539, loss_fp: 0.500005, loss_freq: 0.501687
[02:45:07.121] iteration 1568: loss: 0.929169, loss_s1: 0.502667, loss_fp: 0.500005, loss_freq: 0.500209
[02:45:07.793] iteration 1569: loss: 0.916191, loss_s1: 0.501488, loss_fp: 0.500018, loss_freq: 0.502235
[02:45:08.540] iteration 1570: loss: 0.933509, loss_s1: 0.505977, loss_fp: 0.500010, loss_freq: 0.502618
[02:45:09.165] iteration 1571: loss: 0.896222, loss_s1: 0.503467, loss_fp: 0.500002, loss_freq: 0.502748
[02:45:09.909] iteration 1572: loss: 0.883983, loss_s1: 0.504598, loss_fp: 0.500006, loss_freq: 0.502133
[02:45:10.593] iteration 1573: loss: 0.938013, loss_s1: 0.503522, loss_fp: 0.500003, loss_freq: 0.500318
[02:45:11.298] iteration 1574: loss: 0.747309, loss_s1: 0.498958, loss_fp: 0.258260, loss_freq: 0.485536
[02:45:11.992] iteration 1575: loss: 0.982302, loss_s1: 0.504124, loss_fp: 0.500017, loss_freq: 0.500946
[02:45:12.599] iteration 1576: loss: 0.867535, loss_s1: 0.509408, loss_fp: 0.500012, loss_freq: 0.505024
[02:45:13.293] iteration 1577: loss: 0.995382, loss_s1: 0.500921, loss_fp: 0.500007, loss_freq: 0.500309
[02:45:13.950] iteration 1578: loss: 0.976750, loss_s1: 0.507184, loss_fp: 0.500002, loss_freq: 0.502083
[02:45:14.691] iteration 1579: loss: 0.766665, loss_s1: 0.463672, loss_fp: 0.012146, loss_freq: 0.474690
[02:45:15.301] iteration 1580: loss: 0.923221, loss_s1: 0.503980, loss_fp: 0.500006, loss_freq: 0.504519
[02:45:16.024] iteration 1581: loss: 0.922714, loss_s1: 0.505629, loss_fp: 0.499998, loss_freq: 0.508695
[02:45:16.696] iteration 1582: loss: 0.952403, loss_s1: 0.503904, loss_fp: 0.500020, loss_freq: 0.500536
[02:45:17.385] iteration 1583: loss: 0.963803, loss_s1: 0.509877, loss_fp: 0.499998, loss_freq: 0.501288
[02:45:18.092] iteration 1584: loss: 0.891952, loss_s1: 0.505862, loss_fp: 0.501036, loss_freq: 0.506923
[02:45:18.742] iteration 1585: loss: 0.989555, loss_s1: 0.504015, loss_fp: 0.499993, loss_freq: 0.501477
[02:45:19.337] iteration 1586: loss: 0.954783, loss_s1: 0.502884, loss_fp: 0.499999, loss_freq: 0.500185
[02:45:19.920] iteration 1587: loss: 0.913820, loss_s1: 0.505347, loss_fp: 0.500007, loss_freq: 0.503368
[02:45:20.506] iteration 1588: loss: 0.961253, loss_s1: 0.503055, loss_fp: 0.500000, loss_freq: 0.502041
[02:45:21.087] iteration 1589: loss: 1.050182, loss_s1: 0.502410, loss_fp: 0.499999, loss_freq: 0.500417
[02:45:21.671] iteration 1590: loss: 0.903017, loss_s1: 0.507053, loss_fp: 0.500011, loss_freq: 0.500861
[02:45:22.283] iteration 1591: loss: 0.470021, loss_s1: 0.478799, loss_fp: 0.013808, loss_freq: 0.107327
[02:45:22.923] iteration 1592: loss: 0.930558, loss_s1: 0.501972, loss_fp: 0.500004, loss_freq: 0.501038
[02:45:23.518] iteration 1593: loss: 0.896931, loss_s1: 0.503667, loss_fp: 0.500013, loss_freq: 0.501305
[02:45:24.111] iteration 1594: loss: 0.635220, loss_s1: 0.459069, loss_fp: 0.085086, loss_freq: 0.374294
[02:45:24.696] iteration 1595: loss: 0.951382, loss_s1: 0.503206, loss_fp: 0.500001, loss_freq: 0.500613
[02:45:25.287] iteration 1596: loss: 0.891697, loss_s1: 0.500890, loss_fp: 0.500005, loss_freq: 0.501230
[02:45:25.876] iteration 1597: loss: 1.033686, loss_s1: 0.503780, loss_fp: 0.500005, loss_freq: 0.500166
[02:45:26.468] iteration 1598: loss: 0.953799, loss_s1: 0.506481, loss_fp: 0.500119, loss_freq: 0.500755
[02:45:27.058] iteration 1599: loss: 0.622778, loss_s1: 0.493244, loss_fp: 0.015046, loss_freq: 0.429920
[02:45:27.656] iteration 1600: loss: 0.873642, loss_s1: 0.501678, loss_fp: 0.500012, loss_freq: 0.500350
[02:45:29.899] iteration 1600 : mean_dice : 0.097166
[02:45:30.580] iteration 1601: loss: 0.995038, loss_s1: 0.504827, loss_fp: 0.500006, loss_freq: 0.500237
[02:45:31.179] iteration 1602: loss: 0.922332, loss_s1: 0.501318, loss_fp: 0.500006, loss_freq: 0.500920
[02:45:31.783] iteration 1603: loss: 0.974640, loss_s1: 0.502205, loss_fp: 0.500001, loss_freq: 0.500262
[02:45:32.454] iteration 1604: loss: 0.938145, loss_s1: 0.503437, loss_fp: 0.500007, loss_freq: 0.501240
[02:45:33.051] iteration 1605: loss: 0.610946, loss_s1: 0.502069, loss_fp: 0.009691, loss_freq: 0.426610
[02:45:33.648] iteration 1606: loss: 0.954135, loss_s1: 0.501381, loss_fp: 0.500003, loss_freq: 0.500476
[02:45:34.237] iteration 1607: loss: 0.899059, loss_s1: 0.506804, loss_fp: 0.499999, loss_freq: 0.500255
[02:45:34.864] iteration 1608: loss: 0.921878, loss_s1: 0.503888, loss_fp: 0.499999, loss_freq: 0.500780
[02:45:35.691] iteration 1609: loss: 0.601953, loss_s1: 0.484220, loss_fp: 0.015949, loss_freq: 0.411201
[02:45:36.497] iteration 1610: loss: 0.959431, loss_s1: 0.502942, loss_fp: 0.500008, loss_freq: 0.500472
[02:45:37.303] iteration 1611: loss: 0.897547, loss_s1: 0.502687, loss_fp: 0.500029, loss_freq: 0.501191
[02:45:37.910] iteration 1612: loss: 0.917869, loss_s1: 0.502819, loss_fp: 0.499997, loss_freq: 0.500346
[02:45:38.507] iteration 1613: loss: 0.948626, loss_s1: 0.503170, loss_fp: 0.500009, loss_freq: 0.500158
[02:45:39.090] iteration 1614: loss: 0.900695, loss_s1: 0.502575, loss_fp: 0.500000, loss_freq: 0.500411
[02:45:39.676] iteration 1615: loss: 0.939008, loss_s1: 0.502640, loss_fp: 0.500001, loss_freq: 0.500453
[02:45:40.265] iteration 1616: loss: 0.910683, loss_s1: 0.501798, loss_fp: 0.500001, loss_freq: 0.500417
[02:45:40.852] iteration 1617: loss: 0.874804, loss_s1: 0.501427, loss_fp: 0.500002, loss_freq: 0.500131
[02:45:41.444] iteration 1618: loss: 0.918995, loss_s1: 0.501916, loss_fp: 0.500002, loss_freq: 0.501449
[02:45:42.037] iteration 1619: loss: 0.873509, loss_s1: 0.501240, loss_fp: 0.499998, loss_freq: 0.500377
[02:45:42.639] iteration 1620: loss: 0.912953, loss_s1: 0.501385, loss_fp: 0.500008, loss_freq: 0.500482
[02:45:43.241] iteration 1621: loss: 0.904794, loss_s1: 0.501696, loss_fp: 0.500000, loss_freq: 0.500943
[02:45:43.838] iteration 1622: loss: 0.859380, loss_s1: 0.501760, loss_fp: 0.500000, loss_freq: 0.500392
[02:45:44.429] iteration 1623: loss: 0.904909, loss_s1: 0.502690, loss_fp: 0.500004, loss_freq: 0.500388
[02:45:45.037] iteration 1624: loss: 0.888669, loss_s1: 0.504301, loss_fp: 0.500007, loss_freq: 0.500604
[02:45:45.633] iteration 1625: loss: 0.881241, loss_s1: 0.501097, loss_fp: 0.500001, loss_freq: 0.500077
[02:45:46.221] iteration 1626: loss: 0.881455, loss_s1: 0.500391, loss_fp: 0.499998, loss_freq: 0.500178
[02:45:46.812] iteration 1627: loss: 0.900145, loss_s1: 0.502667, loss_fp: 0.500004, loss_freq: 0.500661
[02:45:47.406] iteration 1628: loss: 0.890011, loss_s1: 0.504270, loss_fp: 0.500001, loss_freq: 0.501164
[02:45:48.002] iteration 1629: loss: 0.581510, loss_s1: 0.488906, loss_fp: 0.065016, loss_freq: 0.329675
[02:45:48.594] iteration 1630: loss: 0.891060, loss_s1: 0.504255, loss_fp: 0.500001, loss_freq: 0.500411
[02:45:49.190] iteration 1631: loss: 0.843441, loss_s1: 0.502447, loss_fp: 0.500001, loss_freq: 0.500330
[02:45:49.782] iteration 1632: loss: 0.896041, loss_s1: 0.504175, loss_fp: 0.499999, loss_freq: 0.500756
[02:45:50.379] iteration 1633: loss: 0.872792, loss_s1: 0.500059, loss_fp: 0.499998, loss_freq: 0.500068
[02:45:50.974] iteration 1634: loss: 0.939789, loss_s1: 0.500747, loss_fp: 0.500001, loss_freq: 0.500824
[02:45:51.573] iteration 1635: loss: 0.904586, loss_s1: 0.500366, loss_fp: 0.500003, loss_freq: 0.500324
[02:45:52.168] iteration 1636: loss: 0.891017, loss_s1: 0.501501, loss_fp: 0.499993, loss_freq: 0.501705
[02:45:52.765] iteration 1637: loss: 0.871797, loss_s1: 0.502397, loss_fp: 0.500003, loss_freq: 0.500730
[02:45:53.356] iteration 1638: loss: 0.881977, loss_s1: 0.503220, loss_fp: 0.499993, loss_freq: 0.500154
[02:45:53.984] iteration 1639: loss: 0.866709, loss_s1: 0.505725, loss_fp: 0.500010, loss_freq: 0.505064
[02:45:54.583] iteration 1640: loss: 0.627003, loss_s1: 0.498649, loss_fp: 0.075767, loss_freq: 0.411629
[02:45:55.217] iteration 1641: loss: 0.929618, loss_s1: 0.500989, loss_fp: 0.499997, loss_freq: 0.500973
[02:45:55.853] iteration 1642: loss: 0.879372, loss_s1: 0.501297, loss_fp: 0.500000, loss_freq: 0.500490
[02:45:56.483] iteration 1643: loss: 0.922275, loss_s1: 0.501260, loss_fp: 0.500003, loss_freq: 0.500117
[02:45:57.117] iteration 1644: loss: 0.874806, loss_s1: 0.501267, loss_fp: 0.500009, loss_freq: 0.500942
[02:45:57.746] iteration 1645: loss: 0.908749, loss_s1: 0.502756, loss_fp: 0.499991, loss_freq: 0.503192
[02:45:58.351] iteration 1646: loss: 0.866323, loss_s1: 0.501133, loss_fp: 0.500000, loss_freq: 0.505343
[02:45:58.943] iteration 1647: loss: 0.903257, loss_s1: 0.501813, loss_fp: 0.500028, loss_freq: 0.500323
[02:45:59.535] iteration 1648: loss: 0.880641, loss_s1: 0.500217, loss_fp: 0.500003, loss_freq: 0.500082
[02:46:00.132] iteration 1649: loss: 0.884127, loss_s1: 0.502893, loss_fp: 0.499999, loss_freq: 0.501810
[02:46:00.721] iteration 1650: loss: 0.955265, loss_s1: 0.501410, loss_fp: 0.499997, loss_freq: 0.501300
[02:46:01.353] iteration 1651: loss: 0.829115, loss_s1: 0.409786, loss_fp: 0.500027, loss_freq: 0.500041
[02:46:02.022] iteration 1652: loss: 0.464806, loss_s1: 0.156243, loss_fp: 0.468194, loss_freq: 0.032121
[02:46:02.668] iteration 1653: loss: 0.897396, loss_s1: 0.503553, loss_fp: 0.499997, loss_freq: 0.500718
[02:46:03.268] iteration 1654: loss: 0.870001, loss_s1: 0.500894, loss_fp: 0.500018, loss_freq: 0.500470
[02:46:03.865] iteration 1655: loss: 1.002096, loss_s1: 0.501343, loss_fp: 0.499999, loss_freq: 0.500106
[02:46:04.460] iteration 1656: loss: 0.976756, loss_s1: 0.501963, loss_fp: 0.499997, loss_freq: 0.500093
[02:46:05.062] iteration 1657: loss: 0.908497, loss_s1: 0.500631, loss_fp: 0.499995, loss_freq: 0.500404
[02:46:05.664] iteration 1658: loss: 0.973562, loss_s1: 0.500903, loss_fp: 0.500004, loss_freq: 0.501331
[02:46:06.260] iteration 1659: loss: 0.923293, loss_s1: 0.501828, loss_fp: 0.500003, loss_freq: 0.501231
[02:46:06.857] iteration 1660: loss: 0.882905, loss_s1: 0.503468, loss_fp: 0.499998, loss_freq: 0.500323
[02:46:07.450] iteration 1661: loss: 0.935958, loss_s1: 0.500965, loss_fp: 0.499997, loss_freq: 0.500343
[02:46:08.046] iteration 1662: loss: 0.957935, loss_s1: 0.500797, loss_fp: 0.500012, loss_freq: 0.500321
[02:46:08.642] iteration 1663: loss: 0.877250, loss_s1: 0.501346, loss_fp: 0.500006, loss_freq: 0.500902
[02:46:09.236] iteration 1664: loss: 0.914243, loss_s1: 0.503083, loss_fp: 0.499998, loss_freq: 0.501086
[02:46:09.825] iteration 1665: loss: 0.961991, loss_s1: 0.504069, loss_fp: 0.500036, loss_freq: 0.500667
[02:46:10.422] iteration 1666: loss: 0.863302, loss_s1: 0.502321, loss_fp: 0.499997, loss_freq: 0.501482
[02:46:11.014] iteration 1667: loss: 0.916667, loss_s1: 0.503936, loss_fp: 0.500038, loss_freq: 0.501513
[02:46:11.607] iteration 1668: loss: 0.894226, loss_s1: 0.494158, loss_fp: 0.500002, loss_freq: 0.501348
[02:46:12.200] iteration 1669: loss: 0.892196, loss_s1: 0.507253, loss_fp: 0.500010, loss_freq: 0.500776
[02:46:12.795] iteration 1670: loss: 0.876855, loss_s1: 0.506609, loss_fp: 0.499995, loss_freq: 0.501665
[02:46:13.385] iteration 1671: loss: 0.888076, loss_s1: 0.503433, loss_fp: 0.500024, loss_freq: 0.503643
[02:46:13.978] iteration 1672: loss: 0.873686, loss_s1: 0.507964, loss_fp: 0.500002, loss_freq: 0.502057
[02:46:14.571] iteration 1673: loss: 0.921087, loss_s1: 0.506578, loss_fp: 0.500020, loss_freq: 0.505200
[02:46:15.160] iteration 1674: loss: 0.893048, loss_s1: 0.508615, loss_fp: 0.500002, loss_freq: 0.500887
[02:46:15.756] iteration 1675: loss: 0.878765, loss_s1: 0.501953, loss_fp: 0.500042, loss_freq: 0.500838
[02:46:16.352] iteration 1676: loss: 0.899145, loss_s1: 0.506502, loss_fp: 0.500003, loss_freq: 0.500777
[02:46:16.944] iteration 1677: loss: 0.419678, loss_s1: 0.413365, loss_fp: 0.012683, loss_freq: 0.132237
[02:46:17.537] iteration 1678: loss: 0.904707, loss_s1: 0.507344, loss_fp: 0.500032, loss_freq: 0.500464
[02:46:18.128] iteration 1679: loss: 0.803968, loss_s1: 0.502981, loss_fp: 0.398793, loss_freq: 0.499504
[02:46:18.717] iteration 1680: loss: 0.655913, loss_s1: 0.480276, loss_fp: 0.045056, loss_freq: 0.366158
[02:46:19.307] iteration 1681: loss: 1.050465, loss_s1: 0.501450, loss_fp: 0.500091, loss_freq: 0.500726
[02:46:19.898] iteration 1682: loss: 1.163466, loss_s1: 0.502808, loss_fp: 0.500003, loss_freq: 0.500354
[02:46:20.489] iteration 1683: loss: 0.982358, loss_s1: 0.501384, loss_fp: 0.500020, loss_freq: 0.501610
[02:46:21.088] iteration 1684: loss: 0.879913, loss_s1: 0.482752, loss_fp: 0.168530, loss_freq: 0.426666
[02:46:21.687] iteration 1685: loss: 1.097059, loss_s1: 0.501767, loss_fp: 0.500009, loss_freq: 0.501431
[02:46:22.350] iteration 1686: loss: 0.972654, loss_s1: 0.503462, loss_fp: 0.500005, loss_freq: 0.500317
[02:46:23.140] iteration 1687: loss: 1.065056, loss_s1: 0.501267, loss_fp: 0.499999, loss_freq: 0.500051
[02:46:23.807] iteration 1688: loss: 1.126704, loss_s1: 0.501431, loss_fp: 0.500016, loss_freq: 0.500184
[02:46:24.591] iteration 1689: loss: 1.027921, loss_s1: 0.501157, loss_fp: 0.499995, loss_freq: 0.500213
[02:46:25.285] iteration 1690: loss: 1.033804, loss_s1: 0.502698, loss_fp: 0.500000, loss_freq: 0.500025
[02:46:25.881] iteration 1691: loss: 1.020167, loss_s1: 0.500253, loss_fp: 0.500002, loss_freq: 0.500849
[02:46:26.478] iteration 1692: loss: 0.999242, loss_s1: 0.501028, loss_fp: 0.500003, loss_freq: 0.500098
[02:46:27.069] iteration 1693: loss: 0.991707, loss_s1: 0.502914, loss_fp: 0.500008, loss_freq: 0.500293
[02:46:27.666] iteration 1694: loss: 0.951578, loss_s1: 0.502695, loss_fp: 0.500013, loss_freq: 0.500166
[02:46:28.274] iteration 1695: loss: 0.962154, loss_s1: 0.502214, loss_fp: 0.500014, loss_freq: 0.500088
[02:46:28.870] iteration 1696: loss: 1.054254, loss_s1: 0.501824, loss_fp: 0.500011, loss_freq: 0.500321
[02:46:29.464] iteration 1697: loss: 0.988487, loss_s1: 0.501430, loss_fp: 0.500006, loss_freq: 0.500495
[02:46:30.055] iteration 1698: loss: 0.947458, loss_s1: 0.501658, loss_fp: 0.500011, loss_freq: 0.500348
[02:46:30.639] iteration 1699: loss: 1.061654, loss_s1: 0.501165, loss_fp: 0.500007, loss_freq: 0.500468
[02:46:31.222] iteration 1700: loss: 1.009517, loss_s1: 0.503262, loss_fp: 0.500018, loss_freq: 0.501406
[02:46:32.178] iteration 1701: loss: 0.965544, loss_s1: 0.501221, loss_fp: 0.500016, loss_freq: 0.500445
[02:46:32.766] iteration 1702: loss: 0.947168, loss_s1: 0.500841, loss_fp: 0.500017, loss_freq: 0.500302
[02:46:33.358] iteration 1703: loss: 1.039974, loss_s1: 0.500688, loss_fp: 0.500007, loss_freq: 0.500311
[02:46:33.954] iteration 1704: loss: 0.982505, loss_s1: 0.500963, loss_fp: 0.500012, loss_freq: 0.500305
[02:46:34.550] iteration 1705: loss: 0.970060, loss_s1: 0.501060, loss_fp: 0.500005, loss_freq: 0.500251
[02:46:35.144] iteration 1706: loss: 0.963621, loss_s1: 0.501860, loss_fp: 0.500004, loss_freq: 0.500112
[02:46:35.738] iteration 1707: loss: 0.944700, loss_s1: 0.503116, loss_fp: 0.500038, loss_freq: 0.500329
[02:46:36.339] iteration 1708: loss: 1.008564, loss_s1: 0.503226, loss_fp: 0.500004, loss_freq: 0.500214
[02:46:36.926] iteration 1709: loss: 0.919066, loss_s1: 0.460436, loss_fp: 0.500006, loss_freq: 0.500217
[02:46:37.556] iteration 1710: loss: 0.971423, loss_s1: 0.500960, loss_fp: 0.500017, loss_freq: 0.500058
[02:46:38.189] iteration 1711: loss: 0.937404, loss_s1: 0.502286, loss_fp: 0.500004, loss_freq: 0.500451
[02:46:38.813] iteration 1712: loss: 0.976948, loss_s1: 0.503339, loss_fp: 0.500014, loss_freq: 0.501055
[02:46:39.446] iteration 1713: loss: 0.999910, loss_s1: 0.502392, loss_fp: 0.500039, loss_freq: 0.501072
[02:46:40.062] iteration 1714: loss: 0.947900, loss_s1: 0.504548, loss_fp: 0.500020, loss_freq: 0.500080
[02:46:40.661] iteration 1715: loss: 0.971034, loss_s1: 0.500566, loss_fp: 0.500016, loss_freq: 0.500167
[02:46:41.257] iteration 1716: loss: 0.948257, loss_s1: 0.502462, loss_fp: 0.500038, loss_freq: 0.500076
[02:46:41.848] iteration 1717: loss: 0.928605, loss_s1: 0.502908, loss_fp: 0.500038, loss_freq: 0.500118
[02:46:42.442] iteration 1718: loss: 0.956924, loss_s1: 0.502571, loss_fp: 0.500018, loss_freq: 0.500182
[02:46:43.032] iteration 1719: loss: 0.921071, loss_s1: 0.500546, loss_fp: 0.500016, loss_freq: 0.500033
[02:46:43.623] iteration 1720: loss: 0.918906, loss_s1: 0.500489, loss_fp: 0.500068, loss_freq: 0.500963
[02:46:44.221] iteration 1721: loss: 0.981707, loss_s1: 0.501005, loss_fp: 0.500038, loss_freq: 0.500774
[02:46:44.829] iteration 1722: loss: 0.932674, loss_s1: 0.506522, loss_fp: 0.500043, loss_freq: 0.503443
[02:46:45.468] iteration 1723: loss: 0.963669, loss_s1: 0.501396, loss_fp: 0.500029, loss_freq: 0.500367
[02:46:46.061] iteration 1724: loss: 0.916608, loss_s1: 0.502604, loss_fp: 0.500036, loss_freq: 0.501136
[02:46:46.653] iteration 1725: loss: 0.904548, loss_s1: 0.504695, loss_fp: 0.500013, loss_freq: 0.500517
[02:46:47.252] iteration 1726: loss: 0.978410, loss_s1: 0.501580, loss_fp: 0.500035, loss_freq: 0.500168
[02:46:47.843] iteration 1727: loss: 0.906360, loss_s1: 0.501123, loss_fp: 0.500023, loss_freq: 0.500801
[02:46:48.436] iteration 1728: loss: 0.893911, loss_s1: 0.501121, loss_fp: 0.500009, loss_freq: 0.501104
[02:46:49.029] iteration 1729: loss: 1.020222, loss_s1: 0.505920, loss_fp: 0.500015, loss_freq: 0.503369
[02:46:49.619] iteration 1730: loss: 0.932922, loss_s1: 0.502079, loss_fp: 0.500049, loss_freq: 0.500687
[02:46:50.204] iteration 1731: loss: 0.891623, loss_s1: 0.505562, loss_fp: 0.500016, loss_freq: 0.500505
[02:46:50.799] iteration 1732: loss: 0.935475, loss_s1: 0.504091, loss_fp: 0.500007, loss_freq: 0.502193
[02:46:51.402] iteration 1733: loss: 0.930522, loss_s1: 0.506135, loss_fp: 0.500082, loss_freq: 0.501403
[02:46:51.996] iteration 1734: loss: 0.907358, loss_s1: 0.500667, loss_fp: 0.500011, loss_freq: 0.500855
[02:46:52.585] iteration 1735: loss: 0.919093, loss_s1: 0.501113, loss_fp: 0.500021, loss_freq: 0.501463
[02:46:53.177] iteration 1736: loss: 0.905982, loss_s1: 0.500051, loss_fp: 0.500005, loss_freq: 0.500189
[02:46:53.787] iteration 1737: loss: 0.892850, loss_s1: 0.502941, loss_fp: 0.500008, loss_freq: 0.500910
[02:46:54.415] iteration 1738: loss: 0.957438, loss_s1: 0.504930, loss_fp: 0.500051, loss_freq: 0.500219
[02:46:55.080] iteration 1739: loss: 0.916977, loss_s1: 0.501691, loss_fp: 0.500073, loss_freq: 0.500470
[02:46:55.716] iteration 1740: loss: 0.919207, loss_s1: 0.503534, loss_fp: 0.500021, loss_freq: 0.500711
[02:46:56.364] iteration 1741: loss: 0.904204, loss_s1: 0.505578, loss_fp: 0.500043, loss_freq: 0.501879
[02:46:57.005] iteration 1742: loss: 0.884747, loss_s1: 0.503457, loss_fp: 0.500042, loss_freq: 0.501773
[02:46:57.638] iteration 1743: loss: 0.953581, loss_s1: 0.503943, loss_fp: 0.500000, loss_freq: 0.500776
[02:46:58.264] iteration 1744: loss: 0.902802, loss_s1: 0.501904, loss_fp: 0.500010, loss_freq: 0.500847
[02:46:58.871] iteration 1745: loss: 0.923326, loss_s1: 0.501028, loss_fp: 0.500004, loss_freq: 0.500611
[02:46:59.480] iteration 1746: loss: 0.860712, loss_s1: 0.503334, loss_fp: 0.500028, loss_freq: 0.500267
[02:47:00.077] iteration 1747: loss: 0.920264, loss_s1: 0.503864, loss_fp: 0.500039, loss_freq: 0.500461
[02:47:00.690] iteration 1748: loss: 0.916253, loss_s1: 0.504992, loss_fp: 0.500035, loss_freq: 0.502241
[02:47:01.280] iteration 1749: loss: 0.680052, loss_s1: 0.504137, loss_fp: 0.094038, loss_freq: 0.449046
[02:47:01.876] iteration 1750: loss: 0.940288, loss_s1: 0.505304, loss_fp: 0.500010, loss_freq: 0.501690
[02:47:02.471] iteration 1751: loss: 0.903260, loss_s1: 0.509151, loss_fp: 0.500012, loss_freq: 0.502048
[02:47:03.063] iteration 1752: loss: 0.930800, loss_s1: 0.501449, loss_fp: 0.500003, loss_freq: 0.500027
[02:47:03.657] iteration 1753: loss: 0.946346, loss_s1: 0.506313, loss_fp: 0.500006, loss_freq: 0.507183
[02:47:04.249] iteration 1754: loss: 0.910025, loss_s1: 0.504414, loss_fp: 0.500005, loss_freq: 0.504023
[02:47:04.841] iteration 1755: loss: 0.930305, loss_s1: 0.505403, loss_fp: 0.500006, loss_freq: 0.501323
[02:47:05.437] iteration 1756: loss: 0.890297, loss_s1: 0.500964, loss_fp: 0.500010, loss_freq: 0.500399
[02:47:06.023] iteration 1757: loss: 0.695680, loss_s1: 0.503934, loss_fp: 0.187005, loss_freq: 0.470543
[02:47:06.629] iteration 1758: loss: 0.946770, loss_s1: 0.503547, loss_fp: 0.500012, loss_freq: 0.501973
[02:47:07.229] iteration 1759: loss: 0.970988, loss_s1: 0.502312, loss_fp: 0.500048, loss_freq: 0.500387
[02:47:07.816] iteration 1760: loss: 0.703018, loss_s1: 0.504230, loss_fp: 0.088006, loss_freq: 0.501014
[02:47:08.406] iteration 1761: loss: 0.634325, loss_s1: 0.488080, loss_fp: 0.014068, loss_freq: 0.468179
[02:47:08.994] iteration 1762: loss: 0.947059, loss_s1: 0.505992, loss_fp: 0.500000, loss_freq: 0.502305
[02:47:09.582] iteration 1763: loss: 0.913461, loss_s1: 0.500653, loss_fp: 0.500005, loss_freq: 0.500847
[02:47:10.171] iteration 1764: loss: 0.648378, loss_s1: 0.488702, loss_fp: 0.033167, loss_freq: 0.454120
[02:47:10.768] iteration 1765: loss: 0.979848, loss_s1: 0.500600, loss_fp: 0.500000, loss_freq: 0.500199
[02:47:11.366] iteration 1766: loss: 0.869138, loss_s1: 0.502872, loss_fp: 0.499994, loss_freq: 0.501646
[02:47:12.066] iteration 1767: loss: 0.991776, loss_s1: 0.473247, loss_fp: 0.499999, loss_freq: 0.500138
[02:47:12.742] iteration 1768: loss: 0.939038, loss_s1: 0.502756, loss_fp: 0.499994, loss_freq: 0.500420
[02:47:13.438] iteration 1769: loss: 0.942146, loss_s1: 0.503016, loss_fp: 0.499978, loss_freq: 0.501816
[02:47:14.107] iteration 1770: loss: 0.888277, loss_s1: 0.500728, loss_fp: 0.499972, loss_freq: 0.500173
[02:47:14.847] iteration 1771: loss: 0.951348, loss_s1: 0.502716, loss_fp: 0.499944, loss_freq: 0.500497
[02:47:15.472] iteration 1772: loss: 0.906657, loss_s1: 0.502671, loss_fp: 0.499966, loss_freq: 0.500182
[02:47:16.123] iteration 1773: loss: 0.936979, loss_s1: 0.502392, loss_fp: 0.499989, loss_freq: 0.500225
[02:47:16.785] iteration 1774: loss: 0.903887, loss_s1: 0.501102, loss_fp: 0.500002, loss_freq: 0.500643
[02:47:17.464] iteration 1775: loss: 0.922833, loss_s1: 0.501768, loss_fp: 0.499971, loss_freq: 0.501383
[02:47:18.138] iteration 1776: loss: 0.987436, loss_s1: 0.500756, loss_fp: 0.500003, loss_freq: 0.500566
[02:47:18.825] iteration 1777: loss: 0.945152, loss_s1: 0.500911, loss_fp: 0.499991, loss_freq: 0.501164
[02:47:19.682] iteration 1778: loss: 0.933486, loss_s1: 0.503773, loss_fp: 0.499985, loss_freq: 0.501129
[02:47:20.269] iteration 1779: loss: 0.911564, loss_s1: 0.502291, loss_fp: 0.499953, loss_freq: 0.500858
[02:47:21.096] iteration 1780: loss: 0.908443, loss_s1: 0.501789, loss_fp: 0.499987, loss_freq: 0.500226
[02:47:21.693] iteration 1781: loss: 0.881023, loss_s1: 0.504043, loss_fp: 0.499963, loss_freq: 0.500573
[02:47:22.336] iteration 1782: loss: 0.904434, loss_s1: 0.501817, loss_fp: 0.499990, loss_freq: 0.500658
[02:47:22.968] iteration 1783: loss: 0.947008, loss_s1: 0.503462, loss_fp: 0.499979, loss_freq: 0.500740
[02:47:23.711] iteration 1784: loss: 0.921556, loss_s1: 0.500441, loss_fp: 0.499997, loss_freq: 0.500362
[02:47:24.341] iteration 1785: loss: 0.946702, loss_s1: 0.501433, loss_fp: 0.499992, loss_freq: 0.500488
[02:47:24.934] iteration 1786: loss: 0.898612, loss_s1: 0.502420, loss_fp: 0.499998, loss_freq: 0.500545
[02:47:25.531] iteration 1787: loss: 0.839354, loss_s1: 0.500765, loss_fp: 0.499985, loss_freq: 0.500229
[02:47:26.130] iteration 1788: loss: 0.903671, loss_s1: 0.503906, loss_fp: 0.500003, loss_freq: 0.501397
[02:47:26.720] iteration 1789: loss: 0.883008, loss_s1: 0.503784, loss_fp: 0.499992, loss_freq: 0.500809
[02:47:27.309] iteration 1790: loss: 0.911605, loss_s1: 0.501996, loss_fp: 0.499987, loss_freq: 0.500958
[02:47:27.908] iteration 1791: loss: 0.884297, loss_s1: 0.502632, loss_fp: 0.499982, loss_freq: 0.501551
[02:47:28.518] iteration 1792: loss: 0.844483, loss_s1: 0.502496, loss_fp: 0.499990, loss_freq: 0.501167
[02:47:29.125] iteration 1793: loss: 0.906758, loss_s1: 0.507506, loss_fp: 0.499988, loss_freq: 0.500779
[02:47:29.726] iteration 1794: loss: 0.874673, loss_s1: 0.503458, loss_fp: 0.499991, loss_freq: 0.500696
[02:47:30.334] iteration 1795: loss: 0.871794, loss_s1: 0.500771, loss_fp: 0.499997, loss_freq: 0.500213
[02:47:30.934] iteration 1796: loss: 0.932278, loss_s1: 0.502290, loss_fp: 0.499983, loss_freq: 0.500148
[02:47:31.539] iteration 1797: loss: 0.862485, loss_s1: 0.502907, loss_fp: 0.500005, loss_freq: 0.500820
[02:47:32.147] iteration 1798: loss: 0.870070, loss_s1: 0.502641, loss_fp: 0.499982, loss_freq: 0.501002
[02:47:32.756] iteration 1799: loss: 0.941828, loss_s1: 0.502074, loss_fp: 0.500007, loss_freq: 0.500175
[02:47:33.360] iteration 1800: loss: 0.851702, loss_s1: 0.504147, loss_fp: 0.500006, loss_freq: 0.500448
[02:47:35.746] iteration 1800 : mean_dice : 0.143833
[02:47:36.722] iteration 1801: loss: 0.865825, loss_s1: 0.505178, loss_fp: 0.500000, loss_freq: 0.501412
[02:47:37.721] iteration 1802: loss: 0.937894, loss_s1: 0.505678, loss_fp: 0.499999, loss_freq: 0.502174
[02:47:38.411] iteration 1803: loss: 0.880261, loss_s1: 0.500809, loss_fp: 0.500003, loss_freq: 0.500036
[02:47:39.003] iteration 1804: loss: 0.919633, loss_s1: 0.506539, loss_fp: 0.500035, loss_freq: 0.502357
[02:47:39.586] iteration 1805: loss: 0.862905, loss_s1: 0.502941, loss_fp: 0.499994, loss_freq: 0.500430
[02:47:40.176] iteration 1806: loss: 0.889650, loss_s1: 0.506394, loss_fp: 0.500009, loss_freq: 0.501489
[02:47:40.763] iteration 1807: loss: 0.890491, loss_s1: 0.502312, loss_fp: 0.500007, loss_freq: 0.500616
[02:47:41.357] iteration 1808: loss: 0.900879, loss_s1: 0.507266, loss_fp: 0.500002, loss_freq: 0.500377
[02:47:41.943] iteration 1809: loss: 0.865828, loss_s1: 0.507038, loss_fp: 0.499994, loss_freq: 0.508610
[02:47:42.532] iteration 1810: loss: 0.873902, loss_s1: 0.503021, loss_fp: 0.499997, loss_freq: 0.500570
[02:47:43.123] iteration 1811: loss: 0.893172, loss_s1: 0.502805, loss_fp: 0.499995, loss_freq: 0.501066
[02:47:43.719] iteration 1812: loss: 0.872255, loss_s1: 0.503007, loss_fp: 0.499972, loss_freq: 0.500331
[02:47:44.312] iteration 1813: loss: 0.912720, loss_s1: 0.499220, loss_fp: 0.499984, loss_freq: 0.500042
[02:47:44.908] iteration 1814: loss: 0.896723, loss_s1: 0.505387, loss_fp: 0.500003, loss_freq: 0.501255
[02:47:45.500] iteration 1815: loss: 0.890942, loss_s1: 0.505220, loss_fp: 0.499994, loss_freq: 0.505002
[02:47:46.095] iteration 1816: loss: 0.868604, loss_s1: 0.504119, loss_fp: 0.500002, loss_freq: 0.504605
[02:47:46.688] iteration 1817: loss: 0.882452, loss_s1: 0.500952, loss_fp: 0.499995, loss_freq: 0.500479
[02:47:47.280] iteration 1818: loss: 0.547073, loss_s1: 0.493667, loss_fp: 0.011871, loss_freq: 0.389766
[02:47:47.873] iteration 1819: loss: 0.857874, loss_s1: 0.503892, loss_fp: 0.499997, loss_freq: 0.502070
[02:47:48.461] iteration 1820: loss: 0.919881, loss_s1: 0.505176, loss_fp: 0.499999, loss_freq: 0.503602
[02:47:49.060] iteration 1821: loss: 0.896186, loss_s1: 0.503873, loss_fp: 0.499992, loss_freq: 0.500128
[02:47:49.658] iteration 1822: loss: 0.853132, loss_s1: 0.498933, loss_fp: 0.486267, loss_freq: 0.468952
[02:47:50.259] iteration 1823: loss: 0.874589, loss_s1: 0.501594, loss_fp: 0.500028, loss_freq: 0.501322
[02:47:50.854] iteration 1824: loss: 0.862725, loss_s1: 0.503871, loss_fp: 0.499993, loss_freq: 0.500569
[02:47:51.448] iteration 1825: loss: 0.925838, loss_s1: 0.500743, loss_fp: 0.499999, loss_freq: 0.500715
[02:47:52.045] iteration 1826: loss: 0.923191, loss_s1: 0.501449, loss_fp: 0.499996, loss_freq: 0.500052
[02:47:52.641] iteration 1827: loss: 0.885590, loss_s1: 0.500826, loss_fp: 0.499994, loss_freq: 0.505227
[02:47:53.239] iteration 1828: loss: 0.947347, loss_s1: 0.502480, loss_fp: 0.499993, loss_freq: 0.503133
[02:47:53.838] iteration 1829: loss: 0.869580, loss_s1: 0.503047, loss_fp: 0.499994, loss_freq: 0.500204
[02:47:54.455] iteration 1830: loss: 0.876421, loss_s1: 0.503480, loss_fp: 0.500006, loss_freq: 0.500859
[02:47:55.047] iteration 1831: loss: 0.871065, loss_s1: 0.501713, loss_fp: 0.499990, loss_freq: 0.500058
[02:47:55.639] iteration 1832: loss: 0.919454, loss_s1: 0.500280, loss_fp: 0.500004, loss_freq: 0.500169
[02:47:56.231] iteration 1833: loss: 0.898796, loss_s1: 0.501373, loss_fp: 0.499990, loss_freq: 0.500262
[02:47:56.827] iteration 1834: loss: 0.953790, loss_s1: 0.502884, loss_fp: 0.499976, loss_freq: 0.500068
[02:47:57.419] iteration 1835: loss: 0.919001, loss_s1: 0.505913, loss_fp: 0.499998, loss_freq: 0.500209
[02:47:58.017] iteration 1836: loss: 0.870396, loss_s1: 0.502636, loss_fp: 0.500001, loss_freq: 0.500760
[02:47:58.603] iteration 1837: loss: 0.970002, loss_s1: 0.503517, loss_fp: 0.499984, loss_freq: 0.500577
[02:47:59.200] iteration 1838: loss: 0.463735, loss_s1: 0.492497, loss_fp: 0.001688, loss_freq: 0.156154
[02:47:59.784] iteration 1839: loss: 0.886111, loss_s1: 0.501088, loss_fp: 0.499992, loss_freq: 0.500203
[02:48:00.378] iteration 1840: loss: 0.903232, loss_s1: 0.502551, loss_fp: 0.500003, loss_freq: 0.500897
[02:48:00.973] iteration 1841: loss: 0.977915, loss_s1: 0.501365, loss_fp: 0.499996, loss_freq: 0.500188
[02:48:01.564] iteration 1842: loss: 0.919505, loss_s1: 0.502556, loss_fp: 0.499993, loss_freq: 0.500524
[02:48:02.157] iteration 1843: loss: 0.838361, loss_s1: 0.445804, loss_fp: 0.499987, loss_freq: 0.500326
[02:48:02.744] iteration 1844: loss: 0.939272, loss_s1: 0.504278, loss_fp: 0.499989, loss_freq: 0.500083
[02:48:03.336] iteration 1845: loss: 1.001361, loss_s1: 0.500546, loss_fp: 0.460701, loss_freq: 0.484075
[02:48:03.925] iteration 1846: loss: 0.928551, loss_s1: 0.502427, loss_fp: 0.500000, loss_freq: 0.500261
[02:48:04.514] iteration 1847: loss: 0.166688, loss_s1: 0.007634, loss_fp: 0.002017, loss_freq: 0.038761
[02:48:05.102] iteration 1848: loss: 0.394456, loss_s1: 0.350189, loss_fp: 0.006517, loss_freq: 0.025900
[02:48:05.696] iteration 1849: loss: 0.880733, loss_s1: 0.501062, loss_fp: 0.500005, loss_freq: 0.500692
[02:48:06.288] iteration 1850: loss: 0.373756, loss_s1: 0.386462, loss_fp: 0.002389, loss_freq: 0.017334
[02:48:06.884] iteration 1851: loss: 0.864431, loss_s1: 0.500741, loss_fp: 0.500001, loss_freq: 0.500358
[02:48:07.475] iteration 1852: loss: 0.885843, loss_s1: 0.501005, loss_fp: 0.500000, loss_freq: 0.500141
[02:48:08.067] iteration 1853: loss: 0.892159, loss_s1: 0.500819, loss_fp: 0.499979, loss_freq: 0.500420
[02:48:08.661] iteration 1854: loss: 0.659950, loss_s1: 0.491120, loss_fp: 0.011031, loss_freq: 0.485069
[02:48:09.246] iteration 1855: loss: 0.934383, loss_s1: 0.500356, loss_fp: 0.499990, loss_freq: 0.500173
[02:48:09.836] iteration 1856: loss: 0.884764, loss_s1: 0.500150, loss_fp: 0.499996, loss_freq: 0.500292
[02:48:10.423] iteration 1857: loss: 0.865166, loss_s1: 0.500077, loss_fp: 0.499995, loss_freq: 0.500317
[02:48:11.009] iteration 1858: loss: 0.888305, loss_s1: 0.501012, loss_fp: 0.499991, loss_freq: 0.500226
[02:48:11.594] iteration 1859: loss: 0.882140, loss_s1: 0.501273, loss_fp: 0.499999, loss_freq: 0.500736
[02:48:12.182] iteration 1860: loss: 0.896160, loss_s1: 0.501102, loss_fp: 0.499996, loss_freq: 0.500309
[02:48:12.769] iteration 1861: loss: 0.910147, loss_s1: 0.500538, loss_fp: 0.499978, loss_freq: 0.500254
[02:48:13.360] iteration 1862: loss: 0.245099, loss_s1: 0.229531, loss_fp: 0.001251, loss_freq: 0.034752
[02:48:13.956] iteration 1863: loss: 0.888095, loss_s1: 0.447933, loss_fp: 0.499988, loss_freq: 0.500374
[02:48:14.551] iteration 1864: loss: 0.890677, loss_s1: 0.501483, loss_fp: 0.500000, loss_freq: 0.501061
[02:48:15.139] iteration 1865: loss: 0.713204, loss_s1: 0.130940, loss_fp: 0.499999, loss_freq: 0.500024
[02:48:15.740] iteration 1866: loss: 0.968255, loss_s1: 0.501068, loss_fp: 0.500007, loss_freq: 0.500100
[02:48:16.329] iteration 1867: loss: 0.961488, loss_s1: 0.500657, loss_fp: 0.499997, loss_freq: 0.500843
[02:48:16.923] iteration 1868: loss: 0.871999, loss_s1: 0.501251, loss_fp: 0.500010, loss_freq: 0.500059
[02:48:17.514] iteration 1869: loss: 0.415005, loss_s1: 0.401326, loss_fp: 0.003134, loss_freq: 0.059605
[02:48:18.101] iteration 1870: loss: 0.901153, loss_s1: 0.500053, loss_fp: 0.500002, loss_freq: 0.500447
[02:48:19.000] iteration 1871: loss: 0.439920, loss_s1: 0.482202, loss_fp: 0.004293, loss_freq: 0.076640
[02:48:19.628] iteration 1872: loss: 0.910517, loss_s1: 0.445768, loss_fp: 0.499999, loss_freq: 0.500069
[02:48:20.256] iteration 1873: loss: 0.880572, loss_s1: 0.500279, loss_fp: 0.500002, loss_freq: 0.500026
[02:48:20.880] iteration 1874: loss: 0.928202, loss_s1: 0.500258, loss_fp: 0.499998, loss_freq: 0.500104
[02:48:21.489] iteration 1875: loss: 0.322903, loss_s1: 0.081676, loss_fp: 0.002329, loss_freq: 0.009330
[02:48:22.077] iteration 1876: loss: 0.991655, loss_s1: 0.500033, loss_fp: 0.499997, loss_freq: 0.500032
[02:48:22.673] iteration 1877: loss: 0.898637, loss_s1: 0.500175, loss_fp: 0.499999, loss_freq: 0.500309
[02:48:23.308] iteration 1878: loss: 0.297437, loss_s1: 0.226284, loss_fp: 0.003954, loss_freq: 0.030070
[02:48:23.949] iteration 1879: loss: 0.920050, loss_s1: 0.500281, loss_fp: 0.500004, loss_freq: 0.500046
[02:48:24.588] iteration 1880: loss: 0.491581, loss_s1: 0.455520, loss_fp: 0.101774, loss_freq: 0.077797
[02:48:25.227] iteration 1881: loss: 0.899850, loss_s1: 0.501736, loss_fp: 0.500000, loss_freq: 0.501162
[02:48:25.866] iteration 1882: loss: 0.906686, loss_s1: 0.502049, loss_fp: 0.500005, loss_freq: 0.502648
[02:48:26.516] iteration 1883: loss: 0.893917, loss_s1: 0.505209, loss_fp: 0.499997, loss_freq: 0.500604
[02:48:27.206] iteration 1884: loss: 0.957045, loss_s1: 0.502314, loss_fp: 0.500015, loss_freq: 0.501047
[02:48:27.996] iteration 1885: loss: 0.301827, loss_s1: 0.106192, loss_fp: 0.003335, loss_freq: 0.013792
[02:48:28.873] iteration 1886: loss: 0.626352, loss_s1: 0.501838, loss_fp: 0.007499, loss_freq: 0.323649
[02:48:29.531] iteration 1887: loss: 0.898160, loss_s1: 0.500139, loss_fp: 0.500004, loss_freq: 0.500220
[02:48:30.271] iteration 1888: loss: 0.406339, loss_s1: 0.285773, loss_fp: 0.002923, loss_freq: 0.060880
[02:48:30.897] iteration 1889: loss: 0.940666, loss_s1: 0.501115, loss_fp: 0.499999, loss_freq: 0.500006
[02:48:31.488] iteration 1890: loss: 0.974062, loss_s1: 0.500932, loss_fp: 0.500006, loss_freq: 0.500006
[02:48:32.144] iteration 1891: loss: 0.991961, loss_s1: 0.500829, loss_fp: 0.500003, loss_freq: 0.500278
[02:48:32.776] iteration 1892: loss: 1.003355, loss_s1: 0.500448, loss_fp: 0.500000, loss_freq: 0.500265
[02:48:33.413] iteration 1893: loss: 1.010245, loss_s1: 0.500447, loss_fp: 0.500000, loss_freq: 0.500015
[02:48:34.051] iteration 1894: loss: 0.893656, loss_s1: 0.500431, loss_fp: 0.499996, loss_freq: 0.500054
[02:48:34.656] iteration 1895: loss: 0.908221, loss_s1: 0.500219, loss_fp: 0.500001, loss_freq: 0.500022
[02:48:35.259] iteration 1896: loss: 0.929889, loss_s1: 0.501085, loss_fp: 0.500010, loss_freq: 0.500012
[02:48:35.904] iteration 1897: loss: 0.911191, loss_s1: 0.500527, loss_fp: 0.500005, loss_freq: 0.500036
[02:48:36.504] iteration 1898: loss: 0.925209, loss_s1: 0.500404, loss_fp: 0.500005, loss_freq: 0.500348
[02:48:37.109] iteration 1899: loss: 0.756873, loss_s1: 0.487398, loss_fp: 0.104008, loss_freq: 0.408765
[02:48:37.708] iteration 1900: loss: 0.943135, loss_s1: 0.500985, loss_fp: 0.500000, loss_freq: 0.500109
[02:48:38.302] iteration 1901: loss: 0.924306, loss_s1: 0.500675, loss_fp: 0.500034, loss_freq: 0.500058
[02:48:38.898] iteration 1902: loss: 1.005449, loss_s1: 0.500362, loss_fp: 0.500002, loss_freq: 0.500107
[02:48:39.488] iteration 1903: loss: 0.926661, loss_s1: 0.501445, loss_fp: 0.500001, loss_freq: 0.500178
[02:48:40.083] iteration 1904: loss: 0.925672, loss_s1: 0.500062, loss_fp: 0.500012, loss_freq: 0.500206
[02:48:40.680] iteration 1905: loss: 0.899957, loss_s1: 0.500309, loss_fp: 0.500002, loss_freq: 0.500331
[02:48:41.268] iteration 1906: loss: 0.934919, loss_s1: 0.500290, loss_fp: 0.500000, loss_freq: 0.500016
[02:48:41.858] iteration 1907: loss: 0.884792, loss_s1: 0.500650, loss_fp: 0.499998, loss_freq: 0.500138
[02:48:42.444] iteration 1908: loss: 0.933074, loss_s1: 0.500252, loss_fp: 0.499995, loss_freq: 0.500013
[02:48:43.034] iteration 1909: loss: 0.971170, loss_s1: 0.501278, loss_fp: 0.500006, loss_freq: 0.500548
[02:48:43.680] iteration 1910: loss: 0.953664, loss_s1: 0.500498, loss_fp: 0.500016, loss_freq: 0.500082
[02:48:44.277] iteration 1911: loss: 0.919354, loss_s1: 0.500975, loss_fp: 0.500003, loss_freq: 0.500311
[02:48:44.875] iteration 1912: loss: 0.877910, loss_s1: 0.503071, loss_fp: 0.500003, loss_freq: 0.500116
[02:48:45.466] iteration 1913: loss: 0.927857, loss_s1: 0.501762, loss_fp: 0.500011, loss_freq: 0.500023
[02:48:46.059] iteration 1914: loss: 0.894043, loss_s1: 0.500506, loss_fp: 0.500003, loss_freq: 0.500146
[02:48:46.733] iteration 1915: loss: 0.886486, loss_s1: 0.501824, loss_fp: 0.499999, loss_freq: 0.500280
[02:48:47.364] iteration 1916: loss: 0.862677, loss_s1: 0.502016, loss_fp: 0.500010, loss_freq: 0.500430
[02:48:47.964] iteration 1917: loss: 0.924430, loss_s1: 0.500475, loss_fp: 0.499995, loss_freq: 0.500051
[02:48:48.564] iteration 1918: loss: 0.918328, loss_s1: 0.501324, loss_fp: 0.500004, loss_freq: 0.500294
[02:48:49.157] iteration 1919: loss: 0.916225, loss_s1: 0.501495, loss_fp: 0.500002, loss_freq: 0.500319
[02:48:49.758] iteration 1920: loss: 0.887597, loss_s1: 0.500733, loss_fp: 0.500000, loss_freq: 0.500588
[02:48:50.354] iteration 1921: loss: 0.889213, loss_s1: 0.506593, loss_fp: 0.500025, loss_freq: 0.501223
[02:48:50.940] iteration 1922: loss: 0.886784, loss_s1: 0.501413, loss_fp: 0.500005, loss_freq: 0.500248
[02:48:51.545] iteration 1923: loss: 0.892170, loss_s1: 0.501803, loss_fp: 0.500000, loss_freq: 0.505415
[02:48:52.140] iteration 1924: loss: 0.893920, loss_s1: 0.504743, loss_fp: 0.500053, loss_freq: 0.503798
[02:48:52.731] iteration 1925: loss: 0.864882, loss_s1: 0.503563, loss_fp: 0.500059, loss_freq: 0.500992
[02:48:53.325] iteration 1926: loss: 0.878683, loss_s1: 0.500741, loss_fp: 0.500000, loss_freq: 0.500447
[02:48:53.918] iteration 1927: loss: 0.887529, loss_s1: 0.503154, loss_fp: 0.500003, loss_freq: 0.500407
[02:48:54.513] iteration 1928: loss: 0.901710, loss_s1: 0.502119, loss_fp: 0.500011, loss_freq: 0.501587
[02:48:55.108] iteration 1929: loss: 0.936620, loss_s1: 0.500703, loss_fp: 0.500008, loss_freq: 0.500312
[02:48:55.698] iteration 1930: loss: 0.876800, loss_s1: 0.502080, loss_fp: 0.500016, loss_freq: 0.500249
[02:48:56.291] iteration 1931: loss: 0.883902, loss_s1: 0.503174, loss_fp: 0.500003, loss_freq: 0.500088
[02:48:56.883] iteration 1932: loss: 0.903425, loss_s1: 0.500982, loss_fp: 0.500009, loss_freq: 0.501419
[02:48:57.488] iteration 1933: loss: 0.863899, loss_s1: 0.502069, loss_fp: 0.500003, loss_freq: 0.500431
[02:48:58.084] iteration 1934: loss: 0.934614, loss_s1: 0.501733, loss_fp: 0.499999, loss_freq: 0.500506
[02:48:58.671] iteration 1935: loss: 0.894708, loss_s1: 0.500549, loss_fp: 0.499998, loss_freq: 0.500289
[02:48:59.262] iteration 1936: loss: 0.872566, loss_s1: 0.502959, loss_fp: 0.500004, loss_freq: 0.500126
[02:48:59.853] iteration 1937: loss: 0.959588, loss_s1: 0.502158, loss_fp: 0.500013, loss_freq: 0.500079
[02:49:00.444] iteration 1938: loss: 0.869497, loss_s1: 0.502085, loss_fp: 0.500002, loss_freq: 0.500453
[02:49:01.034] iteration 1939: loss: 0.919464, loss_s1: 0.505370, loss_fp: 0.500005, loss_freq: 0.500150
[02:49:01.622] iteration 1940: loss: 0.895781, loss_s1: 0.502137, loss_fp: 0.500000, loss_freq: 0.500029
[02:49:02.207] iteration 1941: loss: 0.877724, loss_s1: 0.501273, loss_fp: 0.500003, loss_freq: 0.501208
[02:49:02.794] iteration 1942: loss: 0.870091, loss_s1: 0.500553, loss_fp: 0.500010, loss_freq: 0.500068
[02:49:03.391] iteration 1943: loss: 0.906199, loss_s1: 0.503015, loss_fp: 0.501624, loss_freq: 0.500285
[02:49:03.981] iteration 1944: loss: 0.856362, loss_s1: 0.501778, loss_fp: 0.500003, loss_freq: 0.500580
[02:49:04.574] iteration 1945: loss: 0.867888, loss_s1: 0.502284, loss_fp: 0.500007, loss_freq: 0.500968
[02:49:05.166] iteration 1946: loss: 0.883816, loss_s1: 0.500464, loss_fp: 0.499999, loss_freq: 0.500300
[02:49:05.760] iteration 1947: loss: 0.904176, loss_s1: 0.504728, loss_fp: 0.500000, loss_freq: 0.501034
[02:49:06.354] iteration 1948: loss: 0.895685, loss_s1: 0.503288, loss_fp: 0.500001, loss_freq: 0.501997
[02:49:06.953] iteration 1949: loss: 0.910880, loss_s1: 0.502521, loss_fp: 0.499996, loss_freq: 0.500858
[02:49:07.543] iteration 1950: loss: 0.861021, loss_s1: 0.503520, loss_fp: 0.500023, loss_freq: 0.500467
[02:49:08.137] iteration 1951: loss: 0.865089, loss_s1: 0.501911, loss_fp: 0.499997, loss_freq: 0.501458
[02:49:08.726] iteration 1952: loss: 0.890731, loss_s1: 0.500849, loss_fp: 0.500009, loss_freq: 0.501358
[02:49:09.316] iteration 1953: loss: 0.869922, loss_s1: 0.506963, loss_fp: 0.500011, loss_freq: 0.500287
[02:49:09.908] iteration 1954: loss: 0.901451, loss_s1: 0.501930, loss_fp: 0.500006, loss_freq: 0.500256
[02:49:10.497] iteration 1955: loss: 0.924841, loss_s1: 0.501268, loss_fp: 0.500003, loss_freq: 0.500465
[02:49:11.086] iteration 1956: loss: 0.863503, loss_s1: 0.503495, loss_fp: 0.500004, loss_freq: 0.500609
[02:49:11.667] iteration 1957: loss: 0.840806, loss_s1: 0.500208, loss_fp: 0.500003, loss_freq: 0.500001
[02:49:12.254] iteration 1958: loss: 0.859213, loss_s1: 0.501611, loss_fp: 0.500000, loss_freq: 0.501288
[02:49:12.916] iteration 1959: loss: 0.827188, loss_s1: 0.502382, loss_fp: 0.500008, loss_freq: 0.500217
[02:49:13.552] iteration 1960: loss: 0.858613, loss_s1: 0.504049, loss_fp: 0.500011, loss_freq: 0.500859
[02:49:14.189] iteration 1961: loss: 0.866595, loss_s1: 0.503449, loss_fp: 0.500005, loss_freq: 0.500941
[02:49:14.777] iteration 1962: loss: 0.836595, loss_s1: 0.501021, loss_fp: 0.500012, loss_freq: 0.500431
[02:49:15.365] iteration 1963: loss: 0.904557, loss_s1: 0.505561, loss_fp: 0.500000, loss_freq: 0.501237
[02:49:15.954] iteration 1964: loss: 0.857473, loss_s1: 0.501471, loss_fp: 0.500003, loss_freq: 0.501896
[02:49:16.544] iteration 1965: loss: 0.878671, loss_s1: 0.500776, loss_fp: 0.499999, loss_freq: 0.500141
[02:49:17.131] iteration 1966: loss: 0.885549, loss_s1: 0.503009, loss_fp: 0.500053, loss_freq: 0.500066
[02:49:17.713] iteration 1967: loss: 0.863581, loss_s1: 0.501526, loss_fp: 0.500000, loss_freq: 0.502422
[02:49:18.298] iteration 1968: loss: 0.861171, loss_s1: 0.503413, loss_fp: 0.500005, loss_freq: 0.501394
[02:49:18.882] iteration 1969: loss: 0.880893, loss_s1: 0.501556, loss_fp: 0.500001, loss_freq: 0.500065
[02:49:19.467] iteration 1970: loss: 0.819472, loss_s1: 0.502926, loss_fp: 0.500003, loss_freq: 0.500760
[02:49:20.046] iteration 1971: loss: 0.841283, loss_s1: 0.503884, loss_fp: 0.500078, loss_freq: 0.500132
[02:49:20.634] iteration 1972: loss: 0.908655, loss_s1: 0.501503, loss_fp: 0.500001, loss_freq: 0.501367
[02:49:21.219] iteration 1973: loss: 0.836789, loss_s1: 0.500274, loss_fp: 0.500005, loss_freq: 0.500061
[02:49:21.804] iteration 1974: loss: 0.897612, loss_s1: 0.506563, loss_fp: 0.500003, loss_freq: 0.500915
[02:49:22.393] iteration 1975: loss: 0.857336, loss_s1: 0.502441, loss_fp: 0.500162, loss_freq: 0.501054
[02:49:22.986] iteration 1976: loss: 0.851394, loss_s1: 0.502225, loss_fp: 0.499996, loss_freq: 0.500313
[02:49:23.574] iteration 1977: loss: 0.884568, loss_s1: 0.503839, loss_fp: 0.499997, loss_freq: 0.500443
[02:49:24.161] iteration 1978: loss: 0.850394, loss_s1: 0.501846, loss_fp: 0.499998, loss_freq: 0.500138
[02:49:24.754] iteration 1979: loss: 0.853524, loss_s1: 0.503949, loss_fp: 0.499999, loss_freq: 0.504171
[02:49:25.342] iteration 1980: loss: 0.857545, loss_s1: 0.500358, loss_fp: 0.500007, loss_freq: 0.500124
[02:49:25.934] iteration 1981: loss: 0.876321, loss_s1: 0.501901, loss_fp: 0.500003, loss_freq: 0.502095
[02:49:26.522] iteration 1982: loss: 0.856351, loss_s1: 0.503918, loss_fp: 0.500000, loss_freq: 0.500528
[02:49:27.123] iteration 1983: loss: 0.905181, loss_s1: 0.501107, loss_fp: 0.500006, loss_freq: 0.500026
[02:49:27.711] iteration 1984: loss: 0.866168, loss_s1: 0.503538, loss_fp: 0.500002, loss_freq: 0.500894
[02:49:28.313] iteration 1985: loss: 0.862251, loss_s1: 0.503439, loss_fp: 0.500030, loss_freq: 0.503938
[02:49:28.910] iteration 1986: loss: 0.849455, loss_s1: 0.504187, loss_fp: 0.499998, loss_freq: 0.501827
[02:49:29.499] iteration 1987: loss: 0.836415, loss_s1: 0.502324, loss_fp: 0.500001, loss_freq: 0.501912
[02:49:30.099] iteration 1988: loss: 0.821840, loss_s1: 0.500321, loss_fp: 0.500005, loss_freq: 0.500628
[02:49:30.684] iteration 1989: loss: 0.851988, loss_s1: 0.506243, loss_fp: 0.500001, loss_freq: 0.502363
[02:49:31.271] iteration 1990: loss: 0.899484, loss_s1: 0.500525, loss_fp: 0.500002, loss_freq: 0.501883
[02:49:31.862] iteration 1991: loss: 0.863825, loss_s1: 0.500358, loss_fp: 0.500002, loss_freq: 0.500196
[02:49:32.454] iteration 1992: loss: 0.879473, loss_s1: 0.501370, loss_fp: 0.500007, loss_freq: 0.500294
[02:49:33.041] iteration 1993: loss: 0.869565, loss_s1: 0.501510, loss_fp: 0.500164, loss_freq: 0.501581
[02:49:33.634] iteration 1994: loss: 0.836457, loss_s1: 0.503897, loss_fp: 0.500001, loss_freq: 0.501349
[02:49:34.225] iteration 1995: loss: 0.837479, loss_s1: 0.500560, loss_fp: 0.500006, loss_freq: 0.500318
[02:49:34.816] iteration 1996: loss: 0.867533, loss_s1: 0.502292, loss_fp: 0.500000, loss_freq: 0.500122
[02:49:35.411] iteration 1997: loss: 0.866720, loss_s1: 0.502447, loss_fp: 0.499999, loss_freq: 0.503733
[02:49:36.008] iteration 1998: loss: 0.897896, loss_s1: 0.500816, loss_fp: 0.500011, loss_freq: 0.503303
[02:49:36.598] iteration 1999: loss: 0.865050, loss_s1: 0.503415, loss_fp: 0.500000, loss_freq: 0.501198
[02:49:37.199] iteration 2000: loss: 0.870532, loss_s1: 0.502663, loss_fp: 0.499999, loss_freq: 0.502415
[02:49:39.965] iteration 2000 : mean_dice : 0.214466
[02:49:40.642] iteration 2001: loss: 0.895356, loss_s1: 0.500097, loss_fp: 0.500048, loss_freq: 0.500172
[02:49:41.283] iteration 2002: loss: 0.845231, loss_s1: 0.500603, loss_fp: 0.500029, loss_freq: 0.500542
[02:49:41.910] iteration 2003: loss: 0.862850, loss_s1: 0.501177, loss_fp: 0.499999, loss_freq: 0.500440
[02:49:42.499] iteration 2004: loss: 0.847057, loss_s1: 0.503015, loss_fp: 0.500017, loss_freq: 0.500420
[02:49:43.099] iteration 2005: loss: 0.877317, loss_s1: 0.501074, loss_fp: 0.499994, loss_freq: 0.500378
[02:49:43.734] iteration 2006: loss: 0.829699, loss_s1: 0.502688, loss_fp: 0.499982, loss_freq: 0.500795
[02:49:44.326] iteration 2007: loss: 0.913507, loss_s1: 0.500937, loss_fp: 0.499999, loss_freq: 0.501051
[02:49:44.927] iteration 2008: loss: 0.855272, loss_s1: 0.500573, loss_fp: 0.500006, loss_freq: 0.500340
[02:49:45.521] iteration 2009: loss: 0.891579, loss_s1: 0.500639, loss_fp: 0.499999, loss_freq: 0.500898
[02:49:46.115] iteration 2010: loss: 0.829392, loss_s1: 0.502314, loss_fp: 0.500001, loss_freq: 0.500388
[02:49:46.806] iteration 2011: loss: 0.860653, loss_s1: 0.503060, loss_fp: 0.500008, loss_freq: 0.500391
[02:49:47.488] iteration 2012: loss: 0.874909, loss_s1: 0.502791, loss_fp: 0.500002, loss_freq: 0.500322
[02:49:48.183] iteration 2013: loss: 0.856794, loss_s1: 0.500622, loss_fp: 0.500001, loss_freq: 0.502056
[02:49:48.836] iteration 2014: loss: 0.843656, loss_s1: 0.501392, loss_fp: 0.500005, loss_freq: 0.500584
[02:49:49.559] iteration 2015: loss: 0.862755, loss_s1: 0.502827, loss_fp: 0.500061, loss_freq: 0.500437
[02:49:50.168] iteration 2016: loss: 0.870614, loss_s1: 0.500800, loss_fp: 0.499998, loss_freq: 0.500720
[02:49:50.857] iteration 2017: loss: 0.855597, loss_s1: 0.500083, loss_fp: 0.500072, loss_freq: 0.500286
[02:49:51.515] iteration 2018: loss: 0.826865, loss_s1: 0.500183, loss_fp: 0.500028, loss_freq: 0.500070
[02:49:52.276] iteration 2019: loss: 0.837085, loss_s1: 0.502575, loss_fp: 0.499991, loss_freq: 0.500509
[02:49:52.953] iteration 2020: loss: 0.857510, loss_s1: 0.501245, loss_fp: 0.500002, loss_freq: 0.500983
[02:49:53.654] iteration 2021: loss: 0.831824, loss_s1: 0.501436, loss_fp: 0.500005, loss_freq: 0.500666
[02:49:54.267] iteration 2022: loss: 0.828201, loss_s1: 0.502484, loss_fp: 0.499998, loss_freq: 0.501089
[02:49:54.903] iteration 2023: loss: 0.857047, loss_s1: 0.501768, loss_fp: 0.500001, loss_freq: 0.502020
[02:49:55.555] iteration 2024: loss: 0.814683, loss_s1: 0.463351, loss_fp: 0.500000, loss_freq: 0.500707
[02:49:56.152] iteration 2025: loss: 0.927793, loss_s1: 0.501748, loss_fp: 0.500005, loss_freq: 0.500614
[02:49:56.853] iteration 2026: loss: 0.843873, loss_s1: 0.501167, loss_fp: 0.499998, loss_freq: 0.500212
[02:49:57.509] iteration 2027: loss: 0.863323, loss_s1: 0.501029, loss_fp: 0.500093, loss_freq: 0.500848
[02:49:58.185] iteration 2028: loss: 0.857530, loss_s1: 0.500713, loss_fp: 0.499998, loss_freq: 0.500381
[02:49:58.789] iteration 2029: loss: 0.846324, loss_s1: 0.503329, loss_fp: 0.499993, loss_freq: 0.500399
[02:49:59.413] iteration 2030: loss: 0.855132, loss_s1: 0.501960, loss_fp: 0.500003, loss_freq: 0.500249
[02:50:00.002] iteration 2031: loss: 0.822701, loss_s1: 0.500278, loss_fp: 0.499995, loss_freq: 0.500217
[02:50:00.591] iteration 2032: loss: 0.837667, loss_s1: 0.500100, loss_fp: 0.500004, loss_freq: 0.500082
[02:50:01.180] iteration 2033: loss: 0.892043, loss_s1: 0.500852, loss_fp: 0.500007, loss_freq: 0.501376
[02:50:01.765] iteration 2034: loss: 0.846975, loss_s1: 0.501528, loss_fp: 0.500000, loss_freq: 0.500457
[02:50:02.350] iteration 2035: loss: 0.824636, loss_s1: 0.500115, loss_fp: 0.500008, loss_freq: 0.500076
[02:50:02.947] iteration 2036: loss: 0.414728, loss_s1: 0.442715, loss_fp: 0.002486, loss_freq: 0.188093
[02:50:03.537] iteration 2037: loss: 0.841030, loss_s1: 0.502200, loss_fp: 0.499996, loss_freq: 0.500295
[02:50:04.131] iteration 2038: loss: 0.855818, loss_s1: 0.503242, loss_fp: 0.500000, loss_freq: 0.500412
[02:50:04.718] iteration 2039: loss: 0.348065, loss_s1: 0.412048, loss_fp: 0.001594, loss_freq: 0.063846
[02:50:05.304] iteration 2040: loss: 0.895705, loss_s1: 0.500065, loss_fp: 0.500005, loss_freq: 0.500276
[02:50:06.203] iteration 2041: loss: 0.964267, loss_s1: 0.500331, loss_fp: 0.499998, loss_freq: 0.500012
[02:50:06.840] iteration 2042: loss: 0.922512, loss_s1: 0.500528, loss_fp: 0.500000, loss_freq: 0.500256
[02:50:07.475] iteration 2043: loss: 0.962742, loss_s1: 0.500069, loss_fp: 0.500001, loss_freq: 0.500008
[02:50:08.111] iteration 2044: loss: 0.921652, loss_s1: 0.501316, loss_fp: 0.500009, loss_freq: 0.500416
[02:50:08.743] iteration 2045: loss: 0.606704, loss_s1: 0.499988, loss_fp: 0.225616, loss_freq: 0.262740
[02:50:09.360] iteration 2046: loss: 0.907733, loss_s1: 0.500041, loss_fp: 0.500002, loss_freq: 0.500074
[02:50:09.955] iteration 2047: loss: 0.907540, loss_s1: 0.500431, loss_fp: 0.500001, loss_freq: 0.500062
[02:50:10.545] iteration 2048: loss: 0.561589, loss_s1: 0.493421, loss_fp: 0.032996, loss_freq: 0.210577
[02:50:11.139] iteration 2049: loss: 0.972188, loss_s1: 0.500249, loss_fp: 0.499998, loss_freq: 0.500008
[02:50:11.732] iteration 2050: loss: 0.526603, loss_s1: 0.494863, loss_fp: 0.002991, loss_freq: 0.005104
[02:50:12.520] iteration 2051: loss: 0.531532, loss_s1: 0.279492, loss_fp: 0.089633, loss_freq: 0.415552
[02:50:13.311] iteration 2052: loss: 0.951612, loss_s1: 0.500077, loss_fp: 0.499999, loss_freq: 0.500005
[02:50:14.078] iteration 2053: loss: 0.994387, loss_s1: 0.500060, loss_fp: 0.499976, loss_freq: 0.500032
[02:50:14.671] iteration 2054: loss: 1.093345, loss_s1: 0.500014, loss_fp: 0.500008, loss_freq: 0.500001
[02:50:15.270] iteration 2055: loss: 1.193525, loss_s1: 0.500062, loss_fp: 0.500014, loss_freq: 0.500006
[02:50:15.860] iteration 2056: loss: 0.397722, loss_s1: 0.192910, loss_fp: 0.023559, loss_freq: 0.115651
[02:50:16.452] iteration 2057: loss: 0.894138, loss_s1: 0.502058, loss_fp: 0.500039, loss_freq: 0.501745
[02:50:17.059] iteration 2058: loss: 0.351245, loss_s1: 0.238743, loss_fp: 0.001555, loss_freq: 0.000994
[02:50:17.653] iteration 2059: loss: 0.230318, loss_s1: 0.135301, loss_fp: 0.001084, loss_freq: 0.004632
[02:50:18.260] iteration 2060: loss: 0.298059, loss_s1: 0.185691, loss_fp: 0.012464, loss_freq: 0.003495
[02:50:18.850] iteration 2061: loss: 0.672175, loss_s1: 0.467239, loss_fp: 0.088849, loss_freq: 0.310502
[02:50:19.440] iteration 2062: loss: 0.704423, loss_s1: 0.353561, loss_fp: 0.323806, loss_freq: 0.233619
[02:50:20.033] iteration 2063: loss: 0.387166, loss_s1: 0.199512, loss_fp: 0.002069, loss_freq: 0.017932
[02:50:20.625] iteration 2064: loss: 0.361761, loss_s1: 0.334877, loss_fp: 0.007639, loss_freq: 0.078683
[02:50:21.211] iteration 2065: loss: 0.202849, loss_s1: 0.006089, loss_fp: 0.002553, loss_freq: 0.005351
[02:50:21.800] iteration 2066: loss: 0.381318, loss_s1: 0.316682, loss_fp: 0.000741, loss_freq: 0.003128
[02:50:22.389] iteration 2067: loss: 0.272430, loss_s1: 0.073655, loss_fp: 0.000854, loss_freq: 0.006100
[02:50:23.014] iteration 2068: loss: 0.355211, loss_s1: 0.282765, loss_fp: 0.001962, loss_freq: 0.138463
[02:50:23.602] iteration 2069: loss: 0.450276, loss_s1: 0.409685, loss_fp: 0.003078, loss_freq: 0.015220
[02:50:24.186] iteration 2070: loss: 0.431909, loss_s1: 0.194446, loss_fp: 0.006176, loss_freq: 0.176129
[02:50:24.775] iteration 2071: loss: 0.446295, loss_s1: 0.381025, loss_fp: 0.001047, loss_freq: 0.040705
[02:50:25.367] iteration 2072: loss: 0.738251, loss_s1: 0.468610, loss_fp: 0.004430, loss_freq: 0.063218
[02:50:25.956] iteration 2073: loss: 0.556183, loss_s1: 0.500568, loss_fp: 0.005028, loss_freq: 0.089924
[02:50:26.558] iteration 2074: loss: 0.555359, loss_s1: 0.406671, loss_fp: 0.004109, loss_freq: 0.008118
[02:50:27.155] iteration 2075: loss: 0.548221, loss_s1: 0.501238, loss_fp: 0.041684, loss_freq: 0.135569
[02:50:27.746] iteration 2076: loss: 0.790268, loss_s1: 0.494135, loss_fp: 0.132754, loss_freq: 0.374128
[02:50:28.346] iteration 2077: loss: 0.844546, loss_s1: 0.293108, loss_fp: 0.500040, loss_freq: 0.500243
[02:50:28.938] iteration 2078: loss: 0.721374, loss_s1: 0.492328, loss_fp: 0.345040, loss_freq: 0.063516
[02:50:29.555] iteration 2079: loss: 0.833807, loss_s1: 0.156178, loss_fp: 0.500073, loss_freq: 0.500947
[02:50:30.143] iteration 2080: loss: 0.623533, loss_s1: 0.493643, loss_fp: 0.016575, loss_freq: 0.056419
[02:50:30.758] iteration 2081: loss: 1.055277, loss_s1: 0.500840, loss_fp: 0.500014, loss_freq: 0.501323
[02:50:31.370] iteration 2082: loss: 1.080513, loss_s1: 0.502223, loss_fp: 0.500000, loss_freq: 0.501157
[02:50:31.985] iteration 2083: loss: 0.558122, loss_s1: 0.444292, loss_fp: 0.023586, loss_freq: 0.012998
[02:50:32.628] iteration 2084: loss: 0.961262, loss_s1: 0.503172, loss_fp: 0.499978, loss_freq: 0.500019
[02:50:33.499] iteration 2085: loss: 1.076587, loss_s1: 0.501780, loss_fp: 0.500052, loss_freq: 0.500098
[02:50:34.264] iteration 2086: loss: 0.956396, loss_s1: 0.486191, loss_fp: 0.500032, loss_freq: 0.500303
[02:50:34.991] iteration 2087: loss: 1.011400, loss_s1: 0.500415, loss_fp: 0.500123, loss_freq: 0.500087
[02:50:35.631] iteration 2088: loss: 1.022041, loss_s1: 0.500872, loss_fp: 0.500015, loss_freq: 0.501733
[02:50:36.220] iteration 2089: loss: 0.293955, loss_s1: 0.112430, loss_fp: 0.001548, loss_freq: 0.033380
[02:50:36.806] iteration 2090: loss: 0.963412, loss_s1: 0.502055, loss_fp: 0.500054, loss_freq: 0.500274
[02:50:37.399] iteration 2091: loss: 0.957611, loss_s1: 0.501572, loss_fp: 0.500006, loss_freq: 0.500243
[02:50:37.992] iteration 2092: loss: 0.987954, loss_s1: 0.500218, loss_fp: 0.500065, loss_freq: 0.500033
[02:50:38.587] iteration 2093: loss: 0.642920, loss_s1: 0.483959, loss_fp: 0.081659, loss_freq: 0.299499
[02:50:39.186] iteration 2094: loss: 0.934948, loss_s1: 0.503005, loss_fp: 0.500039, loss_freq: 0.500131
[02:50:39.904] iteration 2095: loss: 0.982412, loss_s1: 0.501053, loss_fp: 0.500010, loss_freq: 0.500128
[02:50:40.580] iteration 2096: loss: 1.016344, loss_s1: 0.500280, loss_fp: 0.500010, loss_freq: 0.500022
[02:50:41.199] iteration 2097: loss: 0.952199, loss_s1: 0.500841, loss_fp: 0.500143, loss_freq: 0.500109
[02:50:41.943] iteration 2098: loss: 1.051720, loss_s1: 0.500236, loss_fp: 0.500142, loss_freq: 0.500082
[02:50:42.550] iteration 2099: loss: 1.034667, loss_s1: 0.500966, loss_fp: 0.500077, loss_freq: 0.500073
[02:50:43.237] iteration 2100: loss: 0.912740, loss_s1: 0.503407, loss_fp: 0.500044, loss_freq: 0.500045
[02:50:43.935] iteration 2101: loss: 0.514468, loss_s1: 0.281520, loss_fp: 0.188630, loss_freq: 0.086437
[02:50:44.575] iteration 2102: loss: 0.980576, loss_s1: 0.500232, loss_fp: 0.500043, loss_freq: 0.500155
[02:50:45.310] iteration 2103: loss: 0.770760, loss_s1: 0.171150, loss_fp: 0.500037, loss_freq: 0.500029
[02:50:45.990] iteration 2104: loss: 0.441334, loss_s1: 0.272029, loss_fp: 0.015326, loss_freq: 0.007620
[02:50:46.689] iteration 2105: loss: 1.001017, loss_s1: 0.500259, loss_fp: 0.500003, loss_freq: 0.500045
[02:50:47.377] iteration 2106: loss: 0.953115, loss_s1: 0.501212, loss_fp: 0.500013, loss_freq: 0.500045
[02:50:48.041] iteration 2107: loss: 1.014139, loss_s1: 0.434407, loss_fp: 0.500046, loss_freq: 0.500051
[02:50:48.755] iteration 2108: loss: 0.934414, loss_s1: 0.500250, loss_fp: 0.500012, loss_freq: 0.500067
[02:50:49.354] iteration 2109: loss: 0.376022, loss_s1: 0.255668, loss_fp: 0.078981, loss_freq: 0.043306
[02:50:50.062] iteration 2110: loss: 0.933913, loss_s1: 0.500433, loss_fp: 0.500227, loss_freq: 0.500019
[02:50:50.680] iteration 2111: loss: 0.895257, loss_s1: 0.349259, loss_fp: 0.500059, loss_freq: 0.500123
[02:50:51.270] iteration 2112: loss: 0.910421, loss_s1: 0.500182, loss_fp: 0.500081, loss_freq: 0.500133
[02:50:51.904] iteration 2113: loss: 0.650944, loss_s1: 0.501286, loss_fp: 0.088596, loss_freq: 0.162389
[02:50:52.498] iteration 2114: loss: 0.999313, loss_s1: 0.500166, loss_fp: 0.500014, loss_freq: 0.500232
[02:50:53.089] iteration 2115: loss: 0.987494, loss_s1: 0.501614, loss_fp: 0.500034, loss_freq: 0.500071
[02:50:53.686] iteration 2116: loss: 0.973532, loss_s1: 0.500025, loss_fp: 0.500032, loss_freq: 0.500041
[02:50:54.272] iteration 2117: loss: 0.921641, loss_s1: 0.500112, loss_fp: 0.500004, loss_freq: 0.500017
[02:50:54.869] iteration 2118: loss: 0.446890, loss_s1: 0.454341, loss_fp: 0.003611, loss_freq: 0.009145
[02:50:55.466] iteration 2119: loss: 0.402765, loss_s1: 0.369601, loss_fp: 0.063738, loss_freq: 0.019134
[02:50:56.064] iteration 2120: loss: 0.981987, loss_s1: 0.501162, loss_fp: 0.500017, loss_freq: 0.500023
[02:50:56.646] iteration 2121: loss: 0.903068, loss_s1: 0.500635, loss_fp: 0.500002, loss_freq: 0.500026
[02:50:57.231] iteration 2122: loss: 0.488432, loss_s1: 0.339068, loss_fp: 0.022707, loss_freq: 0.236662
[02:50:57.821] iteration 2123: loss: 0.382111, loss_s1: 0.365710, loss_fp: 0.001905, loss_freq: 0.027091
[02:50:58.409] iteration 2124: loss: 1.027478, loss_s1: 0.500081, loss_fp: 0.500008, loss_freq: 0.500004
[02:50:59.000] iteration 2125: loss: 1.014538, loss_s1: 0.500264, loss_fp: 0.500037, loss_freq: 0.500023
[02:50:59.592] iteration 2126: loss: 0.925372, loss_s1: 0.500099, loss_fp: 0.500008, loss_freq: 0.500025
[02:51:00.182] iteration 2127: loss: 0.931482, loss_s1: 0.500021, loss_fp: 0.499994, loss_freq: 0.499999
[02:51:00.813] iteration 2128: loss: 0.954732, loss_s1: 0.497626, loss_fp: 0.491165, loss_freq: 0.465359
[02:51:01.445] iteration 2129: loss: 0.927200, loss_s1: 0.500019, loss_fp: 0.500014, loss_freq: 0.500041
[02:51:02.082] iteration 2130: loss: 0.955701, loss_s1: 0.500408, loss_fp: 0.500000, loss_freq: 0.500029
[02:51:02.710] iteration 2131: loss: 0.967558, loss_s1: 0.501182, loss_fp: 0.500011, loss_freq: 0.500037
[02:51:03.412] iteration 2132: loss: 0.897881, loss_s1: 0.487178, loss_fp: 0.499999, loss_freq: 0.500040
[02:51:04.328] iteration 2133: loss: 0.487277, loss_s1: 0.282019, loss_fp: 0.169563, loss_freq: 0.070639
[02:51:05.128] iteration 2134: loss: 0.887110, loss_s1: 0.500616, loss_fp: 0.500020, loss_freq: 0.500055
[02:51:05.718] iteration 2135: loss: 0.857623, loss_s1: 0.449041, loss_fp: 0.500016, loss_freq: 0.500158
[02:51:06.395] iteration 2136: loss: 0.968740, loss_s1: 0.500577, loss_fp: 0.500006, loss_freq: 0.500006
[02:51:07.010] iteration 2137: loss: 0.966496, loss_s1: 0.500790, loss_fp: 0.500011, loss_freq: 0.500043
[02:51:07.594] iteration 2138: loss: 0.892743, loss_s1: 0.501410, loss_fp: 0.500004, loss_freq: 0.501968
[02:51:08.182] iteration 2139: loss: 0.367918, loss_s1: 0.432680, loss_fp: 0.005418, loss_freq: 0.003702
[02:51:08.773] iteration 2140: loss: 0.869169, loss_s1: 0.500485, loss_fp: 0.500002, loss_freq: 0.500208
[02:51:09.395] iteration 2141: loss: 0.808319, loss_s1: 0.498607, loss_fp: 0.251333, loss_freq: 0.465084
[02:51:10.019] iteration 2142: loss: 0.951088, loss_s1: 0.500861, loss_fp: 0.500007, loss_freq: 0.501083
[02:51:10.613] iteration 2143: loss: 0.748602, loss_s1: 0.184749, loss_fp: 0.500002, loss_freq: 0.499997
[02:51:11.206] iteration 2144: loss: 0.952864, loss_s1: 0.506899, loss_fp: 0.500001, loss_freq: 0.500044
[02:51:11.805] iteration 2145: loss: 0.260927, loss_s1: 0.132685, loss_fp: 0.001287, loss_freq: 0.005957
[02:51:12.405] iteration 2146: loss: 0.910586, loss_s1: 0.500484, loss_fp: 0.500003, loss_freq: 0.500053
[02:51:12.997] iteration 2147: loss: 0.896416, loss_s1: 0.501130, loss_fp: 0.500004, loss_freq: 0.500021
[02:51:13.611] iteration 2148: loss: 1.011978, loss_s1: 0.503103, loss_fp: 0.499998, loss_freq: 0.500020
[02:51:14.217] iteration 2149: loss: 0.944148, loss_s1: 0.502517, loss_fp: 0.499996, loss_freq: 0.500336
[02:51:14.827] iteration 2150: loss: 0.355424, loss_s1: 0.233535, loss_fp: 0.001100, loss_freq: 0.006356
[02:51:15.422] iteration 2151: loss: 0.960835, loss_s1: 0.500698, loss_fp: 0.500000, loss_freq: 0.500197
[02:51:16.018] iteration 2152: loss: 0.913676, loss_s1: 0.500019, loss_fp: 0.500003, loss_freq: 0.500013
[02:51:16.637] iteration 2153: loss: 0.311805, loss_s1: 0.226029, loss_fp: 0.001528, loss_freq: 0.001820
[02:51:17.229] iteration 2154: loss: 0.888058, loss_s1: 0.500909, loss_fp: 0.500001, loss_freq: 0.500007
[02:51:17.826] iteration 2155: loss: 0.958905, loss_s1: 0.501212, loss_fp: 0.499999, loss_freq: 0.501279
[02:51:18.419] iteration 2156: loss: 0.896451, loss_s1: 0.500554, loss_fp: 0.500008, loss_freq: 0.500195
[02:51:19.013] iteration 2157: loss: 0.942308, loss_s1: 0.500671, loss_fp: 0.500007, loss_freq: 0.500042
[02:51:19.612] iteration 2158: loss: 0.605509, loss_s1: 0.487030, loss_fp: 0.017532, loss_freq: 0.335142
[02:51:20.208] iteration 2159: loss: 0.920265, loss_s1: 0.500057, loss_fp: 0.499989, loss_freq: 0.500105
[02:51:20.809] iteration 2160: loss: 1.013975, loss_s1: 0.502364, loss_fp: 0.500002, loss_freq: 0.500558
[02:51:21.418] iteration 2161: loss: 0.970210, loss_s1: 0.500018, loss_fp: 0.500006, loss_freq: 0.500012
[02:51:22.007] iteration 2162: loss: 0.618286, loss_s1: 0.501465, loss_fp: 0.072477, loss_freq: 0.320225
[02:51:22.596] iteration 2163: loss: 0.584521, loss_s1: 0.354324, loss_fp: 0.004014, loss_freq: 0.489023
[02:51:23.188] iteration 2164: loss: 0.902915, loss_s1: 0.502267, loss_fp: 0.499999, loss_freq: 0.500459
[02:51:23.774] iteration 2165: loss: 0.929846, loss_s1: 0.500941, loss_fp: 0.500000, loss_freq: 0.500532
[02:51:24.364] iteration 2166: loss: 0.937471, loss_s1: 0.500559, loss_fp: 0.500005, loss_freq: 0.500008
[02:51:24.957] iteration 2167: loss: 0.968359, loss_s1: 0.500686, loss_fp: 0.500026, loss_freq: 0.500386
[02:51:25.544] iteration 2168: loss: 0.927511, loss_s1: 0.501823, loss_fp: 0.500000, loss_freq: 0.500130
[02:51:26.132] iteration 2169: loss: 0.880325, loss_s1: 0.377804, loss_fp: 0.500001, loss_freq: 0.500688
[02:51:26.719] iteration 2170: loss: 0.904795, loss_s1: 0.500306, loss_fp: 0.499996, loss_freq: 0.500069
[02:51:27.305] iteration 2171: loss: 0.944234, loss_s1: 0.500046, loss_fp: 0.500001, loss_freq: 0.500024
[02:51:27.905] iteration 2172: loss: 0.924801, loss_s1: 0.490143, loss_fp: 0.500000, loss_freq: 0.500004
[02:51:28.497] iteration 2173: loss: 0.922588, loss_s1: 0.500768, loss_fp: 0.500004, loss_freq: 0.500021
[02:51:29.086] iteration 2174: loss: 0.424265, loss_s1: 0.462856, loss_fp: 0.010741, loss_freq: 0.018030
[02:51:29.680] iteration 2175: loss: 0.914504, loss_s1: 0.500097, loss_fp: 0.500006, loss_freq: 0.500020
[02:51:30.273] iteration 2176: loss: 0.909097, loss_s1: 0.500070, loss_fp: 0.500005, loss_freq: 0.500065
[02:51:30.864] iteration 2177: loss: 1.000276, loss_s1: 0.477186, loss_fp: 0.500002, loss_freq: 0.500042
[02:51:31.463] iteration 2178: loss: 0.273500, loss_s1: 0.309406, loss_fp: 0.003443, loss_freq: 0.006790
[02:51:32.053] iteration 2179: loss: 0.392475, loss_s1: 0.433184, loss_fp: 0.005072, loss_freq: 0.039222
[02:51:32.640] iteration 2180: loss: 0.427821, loss_s1: 0.502051, loss_fp: 0.002516, loss_freq: 0.020173
[02:51:33.232] iteration 2181: loss: 0.202511, loss_s1: 0.019077, loss_fp: 0.002851, loss_freq: 0.013921
[02:51:33.818] iteration 2182: loss: 0.936703, loss_s1: 0.500444, loss_fp: 0.499998, loss_freq: 0.500042
[02:51:34.408] iteration 2183: loss: 0.909599, loss_s1: 0.499999, loss_fp: 0.500003, loss_freq: 0.500040
[02:51:35.002] iteration 2184: loss: 0.928354, loss_s1: 0.500044, loss_fp: 0.500000, loss_freq: 0.500008
[02:51:35.593] iteration 2185: loss: 0.963250, loss_s1: 0.500028, loss_fp: 0.499999, loss_freq: 0.500003
[02:51:36.185] iteration 2186: loss: 0.941896, loss_s1: 0.500028, loss_fp: 0.499987, loss_freq: 0.500007
[02:51:36.769] iteration 2187: loss: 0.941086, loss_s1: 0.500004, loss_fp: 0.500014, loss_freq: 0.500029
[02:51:37.356] iteration 2188: loss: 0.927790, loss_s1: 0.500064, loss_fp: 0.500004, loss_freq: 0.500006
[02:51:37.946] iteration 2189: loss: 0.876377, loss_s1: 0.500250, loss_fp: 0.500001, loss_freq: 0.500006
[02:51:38.533] iteration 2190: loss: 0.927942, loss_s1: 0.500085, loss_fp: 0.499999, loss_freq: 0.500082
[02:51:39.120] iteration 2191: loss: 0.861797, loss_s1: 0.500571, loss_fp: 0.499990, loss_freq: 0.500041
[02:51:39.709] iteration 2192: loss: 0.900917, loss_s1: 0.500637, loss_fp: 0.500000, loss_freq: 0.500066
[02:51:40.294] iteration 2193: loss: 0.919935, loss_s1: 0.500428, loss_fp: 0.500002, loss_freq: 0.500107
[02:51:40.878] iteration 2194: loss: 0.907470, loss_s1: 0.500113, loss_fp: 0.500004, loss_freq: 0.500025
[02:51:41.462] iteration 2195: loss: 0.964188, loss_s1: 0.500066, loss_fp: 0.499999, loss_freq: 0.500105
[02:51:42.049] iteration 2196: loss: 0.908284, loss_s1: 0.502679, loss_fp: 0.500008, loss_freq: 0.500196
[02:51:42.631] iteration 2197: loss: 0.563646, loss_s1: 0.488073, loss_fp: 0.020518, loss_freq: 0.344747
[02:51:43.214] iteration 2198: loss: 0.389497, loss_s1: 0.449672, loss_fp: 0.005219, loss_freq: 0.036779
[02:51:43.794] iteration 2199: loss: 0.884453, loss_s1: 0.500007, loss_fp: 0.500001, loss_freq: 0.500037
[02:51:44.370] iteration 2200: loss: 0.957658, loss_s1: 0.500013, loss_fp: 0.500037, loss_freq: 0.500004
[02:51:46.395] iteration 2200 : mean_dice : 0.040733
[02:51:47.020] iteration 2201: loss: 0.477284, loss_s1: 0.041343, loss_fp: 0.311307, loss_freq: 0.217284
[02:51:47.606] iteration 2202: loss: 0.128734, loss_s1: 0.006787, loss_fp: 0.001010, loss_freq: 0.006999
[02:51:48.256] iteration 2203: loss: 0.487016, loss_s1: 0.273976, loss_fp: 0.002973, loss_freq: 0.007973
[02:51:48.856] iteration 2204: loss: 0.421559, loss_s1: 0.381671, loss_fp: 0.024344, loss_freq: 0.001034
[02:51:49.441] iteration 2205: loss: 0.469936, loss_s1: 0.498177, loss_fp: 0.014032, loss_freq: 0.002818
[02:51:50.028] iteration 2206: loss: 0.416162, loss_s1: 0.299945, loss_fp: 0.001000, loss_freq: 0.001038
[02:51:50.617] iteration 2207: loss: 0.408058, loss_s1: 0.087186, loss_fp: 0.003963, loss_freq: 0.017998
[02:51:51.202] iteration 2208: loss: 0.241746, loss_s1: 0.001269, loss_fp: 0.005895, loss_freq: 0.001145
[02:51:51.781] iteration 2209: loss: 1.023674, loss_s1: 0.501784, loss_fp: 0.500003, loss_freq: 0.500296
[02:51:52.359] iteration 2210: loss: 1.071328, loss_s1: 0.500093, loss_fp: 0.500006, loss_freq: 0.500003
[02:51:53.236] iteration 2211: loss: 0.255437, loss_s1: 0.016363, loss_fp: 0.018239, loss_freq: 0.001178
[02:51:53.820] iteration 2212: loss: 0.452843, loss_s1: 0.421378, loss_fp: 0.005635, loss_freq: 0.003257
[02:51:54.405] iteration 2213: loss: 0.480413, loss_s1: 0.427561, loss_fp: 0.008485, loss_freq: 0.001826
[02:51:54.992] iteration 2214: loss: 1.002885, loss_s1: 0.500552, loss_fp: 0.500008, loss_freq: 0.500002
[02:51:55.576] iteration 2215: loss: 0.472269, loss_s1: 0.268156, loss_fp: 0.009318, loss_freq: 0.002115
[02:51:56.157] iteration 2216: loss: 0.971570, loss_s1: 0.501575, loss_fp: 0.500003, loss_freq: 0.500006
[02:51:56.738] iteration 2217: loss: 0.943717, loss_s1: 0.500250, loss_fp: 0.500010, loss_freq: 0.500010
[02:51:57.320] iteration 2218: loss: 1.005168, loss_s1: 0.500161, loss_fp: 0.500061, loss_freq: 0.499998
[02:51:57.903] iteration 2219: loss: 0.987631, loss_s1: 0.500129, loss_fp: 0.500029, loss_freq: 0.500002
[02:51:58.540] iteration 2220: loss: 1.008943, loss_s1: 0.500113, loss_fp: 0.500027, loss_freq: 0.500000
[02:51:59.168] iteration 2221: loss: 0.946443, loss_s1: 0.500048, loss_fp: 0.500002, loss_freq: 0.500013
[02:51:59.793] iteration 2222: loss: 0.911203, loss_s1: 0.500162, loss_fp: 0.500014, loss_freq: 0.500008
[02:52:00.417] iteration 2223: loss: 1.043841, loss_s1: 0.500056, loss_fp: 0.500010, loss_freq: 0.500011
[02:52:01.040] iteration 2224: loss: 1.000478, loss_s1: 0.500061, loss_fp: 0.500003, loss_freq: 0.500001
[02:52:01.672] iteration 2225: loss: 0.964138, loss_s1: 0.500032, loss_fp: 0.500007, loss_freq: 0.500003
[02:52:02.253] iteration 2226: loss: 0.336820, loss_s1: 0.201259, loss_fp: 0.005123, loss_freq: 0.029085
[02:52:02.878] iteration 2227: loss: 1.001346, loss_s1: 0.475113, loss_fp: 0.500053, loss_freq: 0.500014
[02:52:03.501] iteration 2228: loss: 0.493601, loss_s1: 0.497167, loss_fp: 0.002300, loss_freq: 0.003598
[02:52:04.122] iteration 2229: loss: 0.795389, loss_s1: 0.501267, loss_fp: 0.116055, loss_freq: 0.425473
[02:52:04.772] iteration 2230: loss: 0.409931, loss_s1: 0.156380, loss_fp: 0.009994, loss_freq: 0.132672
[02:52:05.366] iteration 2231: loss: 0.791539, loss_s1: 0.356538, loss_fp: 0.038612, loss_freq: 0.365070
[02:52:06.056] iteration 2232: loss: 0.461620, loss_s1: 0.359867, loss_fp: 0.005301, loss_freq: 0.034444
[02:52:06.659] iteration 2233: loss: 0.689785, loss_s1: 0.408221, loss_fp: 0.082777, loss_freq: 0.130039
[02:52:07.260] iteration 2234: loss: 0.665120, loss_s1: 0.382846, loss_fp: 0.052763, loss_freq: 0.179544
[02:52:07.903] iteration 2235: loss: 0.984773, loss_s1: 0.500444, loss_fp: 0.499998, loss_freq: 0.500057
[02:52:08.491] iteration 2236: loss: 0.619151, loss_s1: 0.490481, loss_fp: 0.182438, loss_freq: 0.043136
[02:52:09.079] iteration 2237: loss: 0.455538, loss_s1: 0.217211, loss_fp: 0.077044, loss_freq: 0.022571
[02:52:09.671] iteration 2238: loss: 1.053351, loss_s1: 0.502774, loss_fp: 0.500004, loss_freq: 0.500005
[02:52:10.270] iteration 2239: loss: 1.032315, loss_s1: 0.503334, loss_fp: 0.500009, loss_freq: 0.500057
[02:52:10.866] iteration 2240: loss: 1.038995, loss_s1: 0.500960, loss_fp: 0.500026, loss_freq: 0.500095
[02:52:11.455] iteration 2241: loss: 1.012812, loss_s1: 0.500270, loss_fp: 0.500008, loss_freq: 0.500000
[02:52:12.107] iteration 2242: loss: 1.090280, loss_s1: 0.503881, loss_fp: 0.500008, loss_freq: 0.500321
[02:52:12.703] iteration 2243: loss: 1.087840, loss_s1: 0.501972, loss_fp: 0.500026, loss_freq: 0.500007
[02:52:13.300] iteration 2244: loss: 0.602535, loss_s1: 0.453171, loss_fp: 0.000937, loss_freq: 0.084991
[02:52:13.895] iteration 2245: loss: 0.599190, loss_s1: 0.438862, loss_fp: 0.127700, loss_freq: 0.102677
[02:52:14.485] iteration 2246: loss: 1.010801, loss_s1: 0.500685, loss_fp: 0.500018, loss_freq: 0.500019
[02:52:15.082] iteration 2247: loss: 1.030713, loss_s1: 0.500060, loss_fp: 0.500024, loss_freq: 0.500007
[02:52:15.712] iteration 2248: loss: 1.033755, loss_s1: 0.500515, loss_fp: 0.499999, loss_freq: 0.500004
[02:52:16.355] iteration 2249: loss: 1.055844, loss_s1: 0.500756, loss_fp: 0.500104, loss_freq: 0.500190
[02:52:16.988] iteration 2250: loss: 1.055223, loss_s1: 0.501157, loss_fp: 0.500019, loss_freq: 0.500017
[02:52:17.614] iteration 2251: loss: 0.993260, loss_s1: 0.500102, loss_fp: 0.500003, loss_freq: 0.500046
[02:52:18.211] iteration 2252: loss: 0.997215, loss_s1: 0.501092, loss_fp: 0.499999, loss_freq: 0.500334
[02:52:18.798] iteration 2253: loss: 1.029781, loss_s1: 0.500151, loss_fp: 0.500001, loss_freq: 0.500030
[02:52:19.391] iteration 2254: loss: 0.957498, loss_s1: 0.500161, loss_fp: 0.500007, loss_freq: 0.500018
[02:52:19.986] iteration 2255: loss: 1.003324, loss_s1: 0.500186, loss_fp: 0.499999, loss_freq: 0.500012
[02:52:20.574] iteration 2256: loss: 0.938287, loss_s1: 0.501035, loss_fp: 0.500000, loss_freq: 0.500014
[02:52:21.163] iteration 2257: loss: 1.003388, loss_s1: 0.500036, loss_fp: 0.500002, loss_freq: 0.500014
[02:52:21.761] iteration 2258: loss: 0.973039, loss_s1: 0.500119, loss_fp: 0.500013, loss_freq: 0.500026
[02:52:22.354] iteration 2259: loss: 0.692785, loss_s1: 0.498322, loss_fp: 0.171651, loss_freq: 0.214225
[02:52:22.944] iteration 2260: loss: 0.960102, loss_s1: 0.501832, loss_fp: 0.500000, loss_freq: 0.500079
[02:52:23.538] iteration 2261: loss: 0.955046, loss_s1: 0.500808, loss_fp: 0.500008, loss_freq: 0.500005
[02:52:24.139] iteration 2262: loss: 0.945288, loss_s1: 0.500192, loss_fp: 0.500005, loss_freq: 0.500001
[02:52:24.739] iteration 2263: loss: 0.965856, loss_s1: 0.500768, loss_fp: 0.500005, loss_freq: 0.500012
[02:52:25.342] iteration 2264: loss: 0.934613, loss_s1: 0.500413, loss_fp: 0.500014, loss_freq: 0.500001
[02:52:25.952] iteration 2265: loss: 0.970403, loss_s1: 0.500647, loss_fp: 0.499999, loss_freq: 0.500001
[02:52:26.543] iteration 2266: loss: 0.756798, loss_s1: 0.028863, loss_fp: 0.500001, loss_freq: 0.500011
[02:52:27.132] iteration 2267: loss: 0.327798, loss_s1: 0.195038, loss_fp: 0.031310, loss_freq: 0.065157
[02:52:27.722] iteration 2268: loss: 0.602999, loss_s1: 0.500964, loss_fp: 0.040514, loss_freq: 0.082420
[02:52:28.316] iteration 2269: loss: 0.973205, loss_s1: 0.500013, loss_fp: 0.500005, loss_freq: 0.499995
[02:52:28.911] iteration 2270: loss: 0.896228, loss_s1: 0.500070, loss_fp: 0.500021, loss_freq: 0.499998
[02:52:29.502] iteration 2271: loss: 0.450389, loss_s1: 0.439022, loss_fp: 0.004942, loss_freq: 0.003380
[02:52:30.095] iteration 2272: loss: 0.991972, loss_s1: 0.500413, loss_fp: 0.500007, loss_freq: 0.500001
[02:52:30.692] iteration 2273: loss: 0.975734, loss_s1: 0.500191, loss_fp: 0.499998, loss_freq: 0.499997
[02:52:31.283] iteration 2274: loss: 0.312863, loss_s1: 0.147413, loss_fp: 0.001202, loss_freq: 0.002566
[02:52:31.874] iteration 2275: loss: 1.052391, loss_s1: 0.500150, loss_fp: 0.500003, loss_freq: 0.499998
[02:52:32.462] iteration 2276: loss: 1.011240, loss_s1: 0.500391, loss_fp: 0.500002, loss_freq: 0.499992
[02:52:33.053] iteration 2277: loss: 1.034868, loss_s1: 0.500080, loss_fp: 0.500006, loss_freq: 0.499998
[02:52:33.644] iteration 2278: loss: 0.963992, loss_s1: 0.500771, loss_fp: 0.500019, loss_freq: 0.500001
[02:52:34.230] iteration 2279: loss: 0.243960, loss_s1: 0.018207, loss_fp: 0.001396, loss_freq: 0.000917
[02:52:34.821] iteration 2280: loss: 0.993690, loss_s1: 0.500500, loss_fp: 0.500000, loss_freq: 0.499994
[02:52:35.418] iteration 2281: loss: 0.965341, loss_s1: 0.503318, loss_fp: 0.500000, loss_freq: 0.500295
[02:52:36.014] iteration 2282: loss: 0.857396, loss_s1: 0.381395, loss_fp: 0.500001, loss_freq: 0.499986
[02:52:36.603] iteration 2283: loss: 0.276182, loss_s1: 0.035979, loss_fp: 0.001495, loss_freq: 0.002536
[02:52:37.194] iteration 2284: loss: 0.955371, loss_s1: 0.501233, loss_fp: 0.499996, loss_freq: 0.500002
[02:52:37.787] iteration 2285: loss: 0.355401, loss_s1: 0.075287, loss_fp: 0.000994, loss_freq: 0.086937
[02:52:38.371] iteration 2286: loss: 0.742205, loss_s1: 0.489914, loss_fp: 0.085984, loss_freq: 0.480035
[02:52:39.257] iteration 2287: loss: 0.956549, loss_s1: 0.500045, loss_fp: 0.500008, loss_freq: 0.500010
[02:52:40.062] iteration 2288: loss: 0.430793, loss_s1: 0.288509, loss_fp: 0.002810, loss_freq: 0.047989
[02:52:40.786] iteration 2289: loss: 0.339708, loss_s1: 0.277648, loss_fp: 0.008315, loss_freq: 0.066609
[02:52:41.419] iteration 2290: loss: 0.361231, loss_s1: 0.188286, loss_fp: 0.002223, loss_freq: 0.004201
[02:52:42.007] iteration 2291: loss: 0.896369, loss_s1: 0.500432, loss_fp: 0.499997, loss_freq: 0.500000
[02:52:42.594] iteration 2292: loss: 0.943849, loss_s1: 0.500036, loss_fp: 0.499996, loss_freq: 0.500018
[02:52:43.211] iteration 2293: loss: 0.353863, loss_s1: 0.196872, loss_fp: 0.012303, loss_freq: 0.007897
[02:52:43.803] iteration 2294: loss: 0.540731, loss_s1: 0.500410, loss_fp: 0.055268, loss_freq: 0.048350
[02:52:44.389] iteration 2295: loss: 0.478847, loss_s1: 0.422032, loss_fp: 0.000919, loss_freq: 0.007559
[02:52:44.981] iteration 2296: loss: 1.003168, loss_s1: 0.500734, loss_fp: 0.500014, loss_freq: 0.499999
[02:52:45.576] iteration 2297: loss: 0.933108, loss_s1: 0.500098, loss_fp: 0.500009, loss_freq: 0.499987
[02:52:46.200] iteration 2298: loss: 0.503741, loss_s1: 0.499694, loss_fp: 0.001313, loss_freq: 0.001643
[02:52:46.795] iteration 2299: loss: 0.981225, loss_s1: 0.500532, loss_fp: 0.500002, loss_freq: 0.500004
[02:52:47.393] iteration 2300: loss: 0.948790, loss_s1: 0.500099, loss_fp: 0.499997, loss_freq: 0.500005
[02:52:47.986] iteration 2301: loss: 0.965658, loss_s1: 0.501641, loss_fp: 0.500024, loss_freq: 0.500016
[02:52:48.580] iteration 2302: loss: 0.902111, loss_s1: 0.500522, loss_fp: 0.499993, loss_freq: 0.500000
[02:52:49.176] iteration 2303: loss: 0.944241, loss_s1: 0.500299, loss_fp: 0.499995, loss_freq: 0.500063
[02:52:49.761] iteration 2304: loss: 0.926220, loss_s1: 0.500476, loss_fp: 0.499974, loss_freq: 0.500032
[02:52:50.368] iteration 2305: loss: 0.919146, loss_s1: 0.500360, loss_fp: 0.500006, loss_freq: 0.500002
[02:52:51.000] iteration 2306: loss: 0.944318, loss_s1: 0.500204, loss_fp: 0.500002, loss_freq: 0.500008
[02:52:51.598] iteration 2307: loss: 0.417627, loss_s1: 0.356075, loss_fp: 0.005900, loss_freq: 0.065077
[02:52:52.198] iteration 2308: loss: 0.949314, loss_s1: 0.500149, loss_fp: 0.499995, loss_freq: 0.500052
[02:52:52.794] iteration 2309: loss: 0.293884, loss_s1: 0.174168, loss_fp: 0.001056, loss_freq: 0.002215
[02:52:53.383] iteration 2310: loss: 0.909544, loss_s1: 0.500141, loss_fp: 0.499997, loss_freq: 0.500005
[02:52:53.977] iteration 2311: loss: 0.759009, loss_s1: 0.499555, loss_fp: 0.364917, loss_freq: 0.411643
[02:52:54.569] iteration 2312: loss: 1.000705, loss_s1: 0.500075, loss_fp: 0.499987, loss_freq: 0.500004
[02:52:55.162] iteration 2313: loss: 0.824311, loss_s1: 0.178095, loss_fp: 0.500003, loss_freq: 0.500000
[02:52:55.751] iteration 2314: loss: 0.208126, loss_s1: 0.007809, loss_fp: 0.001562, loss_freq: 0.004723
[02:52:56.346] iteration 2315: loss: 0.242786, loss_s1: 0.126618, loss_fp: 0.001323, loss_freq: 0.001587
[02:52:56.954] iteration 2316: loss: 0.335055, loss_s1: 0.275601, loss_fp: 0.003128, loss_freq: 0.003185
[02:52:57.590] iteration 2317: loss: 0.747912, loss_s1: 0.144576, loss_fp: 0.500001, loss_freq: 0.500005
[02:52:58.190] iteration 2318: loss: 0.325264, loss_s1: 0.098861, loss_fp: 0.001618, loss_freq: 0.001505
[02:52:58.776] iteration 2319: loss: 0.990591, loss_s1: 0.500899, loss_fp: 0.499996, loss_freq: 0.500143
[02:52:59.371] iteration 2320: loss: 0.376008, loss_s1: 0.297925, loss_fp: 0.001112, loss_freq: 0.001150
[02:52:59.954] iteration 2321: loss: 0.955419, loss_s1: 0.501525, loss_fp: 0.499994, loss_freq: 0.500076
[02:53:00.538] iteration 2322: loss: 0.389966, loss_s1: 0.387760, loss_fp: 0.001993, loss_freq: 0.002630
[02:53:01.126] iteration 2323: loss: 0.341558, loss_s1: 0.172596, loss_fp: 0.002630, loss_freq: 0.001737
[02:53:01.712] iteration 2324: loss: 0.982027, loss_s1: 0.503549, loss_fp: 0.499996, loss_freq: 0.500011
[02:53:02.305] iteration 2325: loss: 0.992395, loss_s1: 0.502361, loss_fp: 0.500002, loss_freq: 0.501669
[02:53:02.897] iteration 2326: loss: 0.955521, loss_s1: 0.501323, loss_fp: 0.499997, loss_freq: 0.500060
[02:53:03.483] iteration 2327: loss: 0.392990, loss_s1: 0.297466, loss_fp: 0.001588, loss_freq: 0.003197
[02:53:04.077] iteration 2328: loss: 0.411866, loss_s1: 0.474594, loss_fp: 0.003680, loss_freq: 0.002651
[02:53:04.663] iteration 2329: loss: 0.965713, loss_s1: 0.503161, loss_fp: 0.500013, loss_freq: 0.500217
[02:53:05.260] iteration 2330: loss: 0.755097, loss_s1: 0.477808, loss_fp: 0.197209, loss_freq: 0.477163
[02:53:05.846] iteration 2331: loss: 0.377466, loss_s1: 0.301347, loss_fp: 0.037353, loss_freq: 0.040507
[02:53:06.430] iteration 2332: loss: 0.349969, loss_s1: 0.341731, loss_fp: 0.001646, loss_freq: 0.001106
[02:53:07.036] iteration 2333: loss: 0.944546, loss_s1: 0.501374, loss_fp: 0.499995, loss_freq: 0.501478
[02:53:07.624] iteration 2334: loss: 0.406133, loss_s1: 0.429525, loss_fp: 0.001036, loss_freq: 0.023151
[02:53:08.217] iteration 2335: loss: 0.306176, loss_s1: 0.173317, loss_fp: 0.003473, loss_freq: 0.018856
[02:53:08.842] iteration 2336: loss: 0.534029, loss_s1: 0.347417, loss_fp: 0.002747, loss_freq: 0.232732
[02:53:09.438] iteration 2337: loss: 0.927024, loss_s1: 0.503856, loss_fp: 0.500003, loss_freq: 0.502090
[02:53:10.031] iteration 2338: loss: 1.014280, loss_s1: 0.504661, loss_fp: 0.499991, loss_freq: 0.501814
[02:53:10.626] iteration 2339: loss: 0.379231, loss_s1: 0.310347, loss_fp: 0.001227, loss_freq: 0.023544
[02:53:11.228] iteration 2340: loss: 0.896556, loss_s1: 0.505318, loss_fp: 0.499998, loss_freq: 0.500986
[02:53:11.822] iteration 2341: loss: 0.937331, loss_s1: 0.499997, loss_fp: 0.499994, loss_freq: 0.499997
[02:53:12.411] iteration 2342: loss: 0.284968, loss_s1: 0.143200, loss_fp: 0.000601, loss_freq: 0.005301
[02:53:13.060] iteration 2343: loss: 0.936820, loss_s1: 0.501702, loss_fp: 0.500002, loss_freq: 0.500013
[02:53:13.694] iteration 2344: loss: 0.408871, loss_s1: 0.286871, loss_fp: 0.001758, loss_freq: 0.001516
[02:53:14.328] iteration 2345: loss: 1.003930, loss_s1: 0.500848, loss_fp: 0.500008, loss_freq: 0.500017
[02:53:14.932] iteration 2346: loss: 0.949142, loss_s1: 0.500234, loss_fp: 0.500004, loss_freq: 0.500009
[02:53:15.527] iteration 2347: loss: 1.079009, loss_s1: 0.500025, loss_fp: 0.499978, loss_freq: 0.500005
[02:53:16.110] iteration 2348: loss: 0.449686, loss_s1: 0.499750, loss_fp: 0.000855, loss_freq: 0.002785
[02:53:16.696] iteration 2349: loss: 0.941970, loss_s1: 0.500026, loss_fp: 0.499998, loss_freq: 0.500002
[02:53:17.292] iteration 2350: loss: 0.950853, loss_s1: 0.500756, loss_fp: 0.499998, loss_freq: 0.500007
[02:53:17.885] iteration 2351: loss: 0.451073, loss_s1: 0.496228, loss_fp: 0.002115, loss_freq: 0.014433
[02:53:18.469] iteration 2352: loss: 0.930027, loss_s1: 0.500125, loss_fp: 0.499985, loss_freq: 0.500014
[02:53:19.055] iteration 2353: loss: 0.983825, loss_s1: 0.500035, loss_fp: 0.499998, loss_freq: 0.500023
[02:53:19.638] iteration 2354: loss: 0.956026, loss_s1: 0.500038, loss_fp: 0.500001, loss_freq: 0.500016
[02:53:20.223] iteration 2355: loss: 0.930281, loss_s1: 0.500026, loss_fp: 0.499997, loss_freq: 0.500001
[02:53:20.812] iteration 2356: loss: 0.941185, loss_s1: 0.500054, loss_fp: 0.499992, loss_freq: 0.500012
[02:53:21.397] iteration 2357: loss: 0.933568, loss_s1: 0.500038, loss_fp: 0.499994, loss_freq: 0.500004
[02:53:21.981] iteration 2358: loss: 0.326928, loss_s1: 0.209046, loss_fp: 0.008916, loss_freq: 0.008626
[02:53:22.573] iteration 2359: loss: 0.885269, loss_s1: 0.500018, loss_fp: 0.499991, loss_freq: 0.500008
[02:53:23.168] iteration 2360: loss: 0.955514, loss_s1: 0.500084, loss_fp: 0.500000, loss_freq: 0.500007
[02:53:23.756] iteration 2361: loss: 0.893425, loss_s1: 0.500114, loss_fp: 0.500001, loss_freq: 0.500005
[02:53:24.351] iteration 2362: loss: 0.939053, loss_s1: 0.500188, loss_fp: 0.500005, loss_freq: 0.500017
[02:53:24.938] iteration 2363: loss: 0.917427, loss_s1: 0.500048, loss_fp: 0.500001, loss_freq: 0.500080
[02:53:25.532] iteration 2364: loss: 0.904173, loss_s1: 0.500024, loss_fp: 0.499991, loss_freq: 0.500002
[02:53:26.126] iteration 2365: loss: 0.939711, loss_s1: 0.500059, loss_fp: 0.500002, loss_freq: 0.500030
[02:53:26.723] iteration 2366: loss: 0.883772, loss_s1: 0.500064, loss_fp: 0.500026, loss_freq: 0.500020
[02:53:27.358] iteration 2367: loss: 0.882898, loss_s1: 0.500001, loss_fp: 0.500004, loss_freq: 0.500058
[02:53:27.986] iteration 2368: loss: 0.900327, loss_s1: 0.500143, loss_fp: 0.500001, loss_freq: 0.500040
[02:53:28.585] iteration 2369: loss: 0.863990, loss_s1: 0.500322, loss_fp: 0.500001, loss_freq: 0.500133
[02:53:29.182] iteration 2370: loss: 0.942273, loss_s1: 0.500307, loss_fp: 0.500000, loss_freq: 0.500010
[02:53:29.781] iteration 2371: loss: 0.910606, loss_s1: 0.500131, loss_fp: 0.500002, loss_freq: 0.500029
[02:53:30.379] iteration 2372: loss: 0.890742, loss_s1: 0.500100, loss_fp: 0.500001, loss_freq: 0.500009
[02:53:31.031] iteration 2373: loss: 0.926826, loss_s1: 0.501034, loss_fp: 0.500002, loss_freq: 0.500071
[02:53:31.664] iteration 2374: loss: 0.889774, loss_s1: 0.500496, loss_fp: 0.499997, loss_freq: 0.500089
[02:53:32.287] iteration 2375: loss: 0.279577, loss_s1: 0.266631, loss_fp: 0.021903, loss_freq: 0.023228
[02:53:32.919] iteration 2376: loss: 0.283871, loss_s1: 0.276144, loss_fp: 0.008414, loss_freq: 0.007919
[02:53:33.551] iteration 2377: loss: 0.899441, loss_s1: 0.500320, loss_fp: 0.499988, loss_freq: 0.500041
[02:53:34.153] iteration 2378: loss: 0.885668, loss_s1: 0.500446, loss_fp: 0.500002, loss_freq: 0.500005
[02:53:34.743] iteration 2379: loss: 0.364903, loss_s1: 0.404944, loss_fp: 0.001835, loss_freq: 0.012645
[02:53:35.334] iteration 2380: loss: 0.900797, loss_s1: 0.500032, loss_fp: 0.499996, loss_freq: 0.500155
[02:53:36.271] iteration 2381: loss: 0.410410, loss_s1: 0.493146, loss_fp: 0.001029, loss_freq: 0.004688
[02:53:36.866] iteration 2382: loss: 0.854982, loss_s1: 0.443040, loss_fp: 0.499997, loss_freq: 0.500012
[02:53:37.454] iteration 2383: loss: 0.885168, loss_s1: 0.501100, loss_fp: 0.500008, loss_freq: 0.500005
[02:53:38.049] iteration 2384: loss: 0.940337, loss_s1: 0.500671, loss_fp: 0.499996, loss_freq: 0.500031
[02:53:38.636] iteration 2385: loss: 0.370152, loss_s1: 0.397137, loss_fp: 0.003073, loss_freq: 0.005596
[02:53:39.228] iteration 2386: loss: 0.982084, loss_s1: 0.500819, loss_fp: 0.500034, loss_freq: 0.500045
[02:53:39.817] iteration 2387: loss: 0.214056, loss_s1: 0.062795, loss_fp: 0.000902, loss_freq: 0.008750
[02:53:40.412] iteration 2388: loss: 0.905573, loss_s1: 0.500126, loss_fp: 0.500005, loss_freq: 0.500023
[02:53:40.997] iteration 2389: loss: 0.866792, loss_s1: 0.500126, loss_fp: 0.499993, loss_freq: 0.500001
[02:53:41.583] iteration 2390: loss: 0.908986, loss_s1: 0.500074, loss_fp: 0.499999, loss_freq: 0.499994
[02:53:42.173] iteration 2391: loss: 0.902116, loss_s1: 0.500267, loss_fp: 0.500019, loss_freq: 0.500015
[02:53:42.764] iteration 2392: loss: 0.888218, loss_s1: 0.500458, loss_fp: 0.499982, loss_freq: 0.500006
[02:53:43.356] iteration 2393: loss: 0.884663, loss_s1: 0.500497, loss_fp: 0.500002, loss_freq: 0.500048
[02:53:43.948] iteration 2394: loss: 0.907535, loss_s1: 0.500000, loss_fp: 0.499998, loss_freq: 0.500009
[02:53:44.549] iteration 2395: loss: 0.986097, loss_s1: 0.496140, loss_fp: 0.499993, loss_freq: 0.499998
[02:53:45.182] iteration 2396: loss: 0.886503, loss_s1: 0.500752, loss_fp: 0.499999, loss_freq: 0.499997
[02:53:45.808] iteration 2397: loss: 0.867836, loss_s1: 0.500344, loss_fp: 0.500000, loss_freq: 0.499994
[02:53:46.437] iteration 2398: loss: 0.899417, loss_s1: 0.454913, loss_fp: 0.499987, loss_freq: 0.500000
[02:53:47.071] iteration 2399: loss: 0.873097, loss_s1: 0.500014, loss_fp: 0.500004, loss_freq: 0.500001
[02:53:47.701] iteration 2400: loss: 0.905759, loss_s1: 0.499748, loss_fp: 0.499998, loss_freq: 0.500005
[02:53:50.300] iteration 2400 : mean_dice : 0.137122
[02:53:50.939] iteration 2401: loss: 0.886903, loss_s1: 0.500092, loss_fp: 0.499998, loss_freq: 0.500043
[02:53:51.536] iteration 2402: loss: 0.949388, loss_s1: 0.490520, loss_fp: 0.500001, loss_freq: 0.500188
[02:53:52.133] iteration 2403: loss: 0.904704, loss_s1: 0.475451, loss_fp: 0.500004, loss_freq: 0.500002
[02:53:52.796] iteration 2404: loss: 0.856195, loss_s1: 0.500163, loss_fp: 0.499998, loss_freq: 0.500007
[02:53:53.387] iteration 2405: loss: 0.864625, loss_s1: 0.492876, loss_fp: 0.499995, loss_freq: 0.499999
[02:53:53.977] iteration 2406: loss: 0.301836, loss_s1: 0.338107, loss_fp: 0.001500, loss_freq: 0.001337
[02:53:54.569] iteration 2407: loss: 0.906458, loss_s1: 0.499750, loss_fp: 0.500001, loss_freq: 0.499997
[02:53:55.158] iteration 2408: loss: 0.889339, loss_s1: 0.501113, loss_fp: 0.499996, loss_freq: 0.500063
[02:53:55.769] iteration 2409: loss: 0.322803, loss_s1: 0.248096, loss_fp: 0.001133, loss_freq: 0.020582
[02:53:56.359] iteration 2410: loss: 0.899030, loss_s1: 0.501291, loss_fp: 0.499999, loss_freq: 0.500234
[02:53:56.944] iteration 2411: loss: 0.751447, loss_s1: 0.496717, loss_fp: 0.290991, loss_freq: 0.313028
[02:53:57.533] iteration 2412: loss: 0.959730, loss_s1: 0.402338, loss_fp: 0.499997, loss_freq: 0.500059
[02:53:58.116] iteration 2413: loss: 0.929924, loss_s1: 0.500148, loss_fp: 0.499999, loss_freq: 0.500213
[02:53:58.701] iteration 2414: loss: 0.449896, loss_s1: 0.497151, loss_fp: 0.004840, loss_freq: 0.002622
[02:53:59.285] iteration 2415: loss: 1.014571, loss_s1: 0.500065, loss_fp: 0.500004, loss_freq: 0.500003
[02:53:59.873] iteration 2416: loss: 0.443892, loss_s1: 0.096723, loss_fp: 0.136922, loss_freq: 0.028967
[02:54:00.494] iteration 2417: loss: 0.978139, loss_s1: 0.500182, loss_fp: 0.500012, loss_freq: 0.500004
[02:54:01.086] iteration 2418: loss: 0.677874, loss_s1: 0.497403, loss_fp: 0.004464, loss_freq: 0.106495
[02:54:01.679] iteration 2419: loss: 0.554510, loss_s1: 0.232592, loss_fp: 0.002924, loss_freq: 0.011738
[02:54:02.291] iteration 2420: loss: 0.625515, loss_s1: 0.312089, loss_fp: 0.141844, loss_freq: 0.219303
[02:54:02.896] iteration 2421: loss: 0.713121, loss_s1: 0.431922, loss_fp: 0.125755, loss_freq: 0.314051
[02:54:03.496] iteration 2422: loss: 0.743088, loss_s1: 0.412549, loss_fp: 0.365498, loss_freq: 0.116405
[02:54:04.091] iteration 2423: loss: 0.510504, loss_s1: 0.429075, loss_fp: 0.056473, loss_freq: 0.047792
[02:54:04.687] iteration 2424: loss: 0.580382, loss_s1: 0.436420, loss_fp: 0.133667, loss_freq: 0.069411
[02:54:05.284] iteration 2425: loss: 1.031988, loss_s1: 0.499177, loss_fp: 0.500003, loss_freq: 0.499997
[02:54:05.881] iteration 2426: loss: 1.030639, loss_s1: 0.500006, loss_fp: 0.500007, loss_freq: 0.500007
[02:54:06.483] iteration 2427: loss: 1.133135, loss_s1: 0.499997, loss_fp: 0.500004, loss_freq: 0.499999
[02:54:07.088] iteration 2428: loss: 1.144789, loss_s1: 0.500000, loss_fp: 0.500005, loss_freq: 0.499996
[02:54:07.696] iteration 2429: loss: 1.051036, loss_s1: 0.499990, loss_fp: 0.500004, loss_freq: 0.499997
[02:54:08.305] iteration 2430: loss: 1.057795, loss_s1: 0.500001, loss_fp: 0.500007, loss_freq: 0.499994
[02:54:08.898] iteration 2431: loss: 1.030870, loss_s1: 0.499999, loss_fp: 0.500002, loss_freq: 0.499999
[02:54:09.548] iteration 2432: loss: 1.078241, loss_s1: 0.500002, loss_fp: 0.499997, loss_freq: 0.500003
[02:54:10.139] iteration 2433: loss: 1.078744, loss_s1: 0.500021, loss_fp: 0.500003, loss_freq: 0.500005
[02:54:10.738] iteration 2434: loss: 1.027697, loss_s1: 0.499996, loss_fp: 0.499997, loss_freq: 0.499989
[02:54:11.331] iteration 2435: loss: 1.105539, loss_s1: 0.500008, loss_fp: 0.499995, loss_freq: 0.500007
[02:54:11.944] iteration 2436: loss: 1.045061, loss_s1: 0.500036, loss_fp: 0.500017, loss_freq: 0.500010
[02:54:12.537] iteration 2437: loss: 1.103527, loss_s1: 0.500015, loss_fp: 0.500021, loss_freq: 0.500017
[02:54:13.125] iteration 2438: loss: 1.023388, loss_s1: 0.500004, loss_fp: 0.500010, loss_freq: 0.500001
[02:54:13.711] iteration 2439: loss: 1.001863, loss_s1: 0.500048, loss_fp: 0.499999, loss_freq: 0.500007
[02:54:14.301] iteration 2440: loss: 1.002508, loss_s1: 0.500013, loss_fp: 0.500016, loss_freq: 0.500012
[02:54:14.892] iteration 2441: loss: 1.072972, loss_s1: 0.500004, loss_fp: 0.500004, loss_freq: 0.500005
[02:54:15.481] iteration 2442: loss: 1.052500, loss_s1: 0.500003, loss_fp: 0.499999, loss_freq: 0.500005
[02:54:16.106] iteration 2443: loss: 1.024872, loss_s1: 0.500004, loss_fp: 0.500008, loss_freq: 0.500016
[02:54:16.727] iteration 2444: loss: 1.061724, loss_s1: 0.500006, loss_fp: 0.499993, loss_freq: 0.500001
[02:54:17.350] iteration 2445: loss: 1.055653, loss_s1: 0.500003, loss_fp: 0.500003, loss_freq: 0.500005
[02:54:17.972] iteration 2446: loss: 1.031378, loss_s1: 0.500016, loss_fp: 0.500002, loss_freq: 0.500011
[02:54:18.594] iteration 2447: loss: 1.095100, loss_s1: 0.500106, loss_fp: 0.500014, loss_freq: 0.500021
[02:54:19.216] iteration 2448: loss: 0.996947, loss_s1: 0.500044, loss_fp: 0.499997, loss_freq: 0.500023
[02:54:19.800] iteration 2449: loss: 0.984520, loss_s1: 0.500147, loss_fp: 0.500003, loss_freq: 0.500016
[02:54:20.388] iteration 2450: loss: 0.997401, loss_s1: 0.500001, loss_fp: 0.500000, loss_freq: 0.500008
[02:54:21.048] iteration 2451: loss: 1.028146, loss_s1: 0.500056, loss_fp: 0.500023, loss_freq: 0.500016
[02:54:21.777] iteration 2452: loss: 0.968959, loss_s1: 0.500042, loss_fp: 0.500005, loss_freq: 0.500005
[02:54:22.504] iteration 2453: loss: 1.049891, loss_s1: 0.500050, loss_fp: 0.500004, loss_freq: 0.500023
[02:54:23.150] iteration 2454: loss: 1.048825, loss_s1: 0.500029, loss_fp: 0.500003, loss_freq: 0.500023
[02:54:23.859] iteration 2455: loss: 1.003863, loss_s1: 0.502295, loss_fp: 0.500001, loss_freq: 0.500024
[02:54:24.480] iteration 2456: loss: 0.968974, loss_s1: 0.501060, loss_fp: 0.500009, loss_freq: 0.500049
[02:54:25.220] iteration 2457: loss: 0.989288, loss_s1: 0.500389, loss_fp: 0.500004, loss_freq: 0.500010
[02:54:25.818] iteration 2458: loss: 1.043343, loss_s1: 0.502033, loss_fp: 0.500001, loss_freq: 0.500056
[02:54:26.491] iteration 2459: loss: 1.011961, loss_s1: 0.501522, loss_fp: 0.500009, loss_freq: 0.500053
[02:54:27.117] iteration 2460: loss: 1.018674, loss_s1: 0.500537, loss_fp: 0.500004, loss_freq: 0.500024
[02:54:27.831] iteration 2461: loss: 1.006590, loss_s1: 0.500829, loss_fp: 0.500002, loss_freq: 0.500080
[02:54:28.530] iteration 2462: loss: 1.042084, loss_s1: 0.500308, loss_fp: 0.500000, loss_freq: 0.500023
[02:54:29.234] iteration 2463: loss: 1.024886, loss_s1: 0.502565, loss_fp: 0.500003, loss_freq: 0.500037
[02:54:29.969] iteration 2464: loss: 0.995264, loss_s1: 0.500121, loss_fp: 0.500003, loss_freq: 0.500020
[02:54:30.582] iteration 2465: loss: 0.977077, loss_s1: 0.500950, loss_fp: 0.500004, loss_freq: 0.500004
[02:54:31.310] iteration 2466: loss: 0.956067, loss_s1: 0.502799, loss_fp: 0.500003, loss_freq: 0.500057
[02:54:31.992] iteration 2467: loss: 0.999652, loss_s1: 0.500073, loss_fp: 0.500029, loss_freq: 0.500000
[02:54:32.759] iteration 2468: loss: 0.993671, loss_s1: 0.501216, loss_fp: 0.500009, loss_freq: 0.500053
[02:54:33.370] iteration 2469: loss: 0.950163, loss_s1: 0.503564, loss_fp: 0.500025, loss_freq: 0.500008
[02:54:33.963] iteration 2470: loss: 1.028096, loss_s1: 0.500769, loss_fp: 0.500030, loss_freq: 0.500022
[02:54:34.551] iteration 2471: loss: 1.026283, loss_s1: 0.500973, loss_fp: 0.500002, loss_freq: 0.500019
[02:54:35.146] iteration 2472: loss: 0.954253, loss_s1: 0.500239, loss_fp: 0.500001, loss_freq: 0.500303
[02:54:35.737] iteration 2473: loss: 1.020071, loss_s1: 0.500049, loss_fp: 0.500001, loss_freq: 0.500151
[02:54:36.317] iteration 2474: loss: 0.947388, loss_s1: 0.500332, loss_fp: 0.500009, loss_freq: 0.500166
[02:54:36.901] iteration 2475: loss: 0.957871, loss_s1: 0.502922, loss_fp: 0.500006, loss_freq: 0.500004
[02:54:37.483] iteration 2476: loss: 0.986051, loss_s1: 0.500228, loss_fp: 0.500040, loss_freq: 0.500007
[02:54:38.067] iteration 2477: loss: 1.000505, loss_s1: 0.500799, loss_fp: 0.500022, loss_freq: 0.500009
[02:54:38.646] iteration 2478: loss: 0.926413, loss_s1: 0.500238, loss_fp: 0.500034, loss_freq: 0.500307
[02:54:39.255] iteration 2479: loss: 1.031373, loss_s1: 0.501130, loss_fp: 0.500046, loss_freq: 0.500063
[02:54:39.850] iteration 2480: loss: 1.009443, loss_s1: 0.501637, loss_fp: 0.500002, loss_freq: 0.500016
[02:54:40.455] iteration 2481: loss: 0.920530, loss_s1: 0.501841, loss_fp: 0.500014, loss_freq: 0.500377
[02:54:41.050] iteration 2482: loss: 0.992072, loss_s1: 0.500339, loss_fp: 0.500003, loss_freq: 0.500096
[02:54:41.647] iteration 2483: loss: 0.964423, loss_s1: 0.500167, loss_fp: 0.500030, loss_freq: 0.500004
[02:54:42.243] iteration 2484: loss: 0.996997, loss_s1: 0.501091, loss_fp: 0.500007, loss_freq: 0.500176
[02:54:42.844] iteration 2485: loss: 0.965817, loss_s1: 0.500318, loss_fp: 0.500038, loss_freq: 0.500040
[02:54:43.444] iteration 2486: loss: 0.948490, loss_s1: 0.500032, loss_fp: 0.500008, loss_freq: 0.500019
[02:54:44.037] iteration 2487: loss: 0.917466, loss_s1: 0.501388, loss_fp: 0.500010, loss_freq: 0.500147
[02:54:44.649] iteration 2488: loss: 1.038936, loss_s1: 0.501079, loss_fp: 0.500002, loss_freq: 0.500047
[02:54:45.251] iteration 2489: loss: 0.978326, loss_s1: 0.500678, loss_fp: 0.500038, loss_freq: 0.503641
[02:54:45.853] iteration 2490: loss: 0.968475, loss_s1: 0.500047, loss_fp: 0.500004, loss_freq: 0.500009
[02:54:46.470] iteration 2491: loss: 0.958147, loss_s1: 0.500680, loss_fp: 0.500003, loss_freq: 0.500013
[02:54:47.282] iteration 2492: loss: 0.961282, loss_s1: 0.500623, loss_fp: 0.500003, loss_freq: 0.500012
[02:54:48.093] iteration 2493: loss: 0.999859, loss_s1: 0.502719, loss_fp: 0.500025, loss_freq: 0.500004
[02:54:48.806] iteration 2494: loss: 0.931071, loss_s1: 0.500210, loss_fp: 0.500001, loss_freq: 0.500016
[02:54:49.420] iteration 2495: loss: 0.969318, loss_s1: 0.502506, loss_fp: 0.500008, loss_freq: 0.500262
[02:54:50.011] iteration 2496: loss: 0.917394, loss_s1: 0.502050, loss_fp: 0.500002, loss_freq: 0.500591
[02:54:50.599] iteration 2497: loss: 0.998421, loss_s1: 0.501510, loss_fp: 0.500005, loss_freq: 0.500040
[02:54:51.189] iteration 2498: loss: 0.961721, loss_s1: 0.500138, loss_fp: 0.500005, loss_freq: 0.500039
[02:54:51.775] iteration 2499: loss: 0.959335, loss_s1: 0.500317, loss_fp: 0.500045, loss_freq: 0.501527
[02:54:52.361] iteration 2500: loss: 0.955385, loss_s1: 0.501523, loss_fp: 0.500011, loss_freq: 0.501334
[02:54:52.944] iteration 2501: loss: 0.951008, loss_s1: 0.500635, loss_fp: 0.500004, loss_freq: 0.500021
[02:54:53.536] iteration 2502: loss: 1.003099, loss_s1: 0.500037, loss_fp: 0.500002, loss_freq: 0.500051
[02:54:54.124] iteration 2503: loss: 0.943926, loss_s1: 0.504301, loss_fp: 0.500008, loss_freq: 0.500121
[02:54:54.729] iteration 2504: loss: 0.898446, loss_s1: 0.500588, loss_fp: 0.500002, loss_freq: 0.500302
[02:54:55.316] iteration 2505: loss: 0.999444, loss_s1: 0.502411, loss_fp: 0.500006, loss_freq: 0.499999
[02:54:55.901] iteration 2506: loss: 0.993757, loss_s1: 0.500329, loss_fp: 0.500010, loss_freq: 0.500024
[02:54:56.531] iteration 2507: loss: 0.962296, loss_s1: 0.502344, loss_fp: 0.500007, loss_freq: 0.500049
[02:54:57.161] iteration 2508: loss: 1.014156, loss_s1: 0.501886, loss_fp: 0.500025, loss_freq: 0.500718
[02:54:57.806] iteration 2509: loss: 0.931427, loss_s1: 0.500351, loss_fp: 0.500010, loss_freq: 0.500012
[02:54:58.429] iteration 2510: loss: 0.906482, loss_s1: 0.503828, loss_fp: 0.500013, loss_freq: 0.500790
[02:54:59.055] iteration 2511: loss: 0.996758, loss_s1: 0.500395, loss_fp: 0.500034, loss_freq: 0.500421
[02:54:59.638] iteration 2512: loss: 0.962261, loss_s1: 0.500969, loss_fp: 0.500011, loss_freq: 0.500025
[02:55:00.223] iteration 2513: loss: 0.913774, loss_s1: 0.500551, loss_fp: 0.500008, loss_freq: 0.500254
[02:55:00.812] iteration 2514: loss: 1.041376, loss_s1: 0.502244, loss_fp: 0.500004, loss_freq: 0.500015
[02:55:01.400] iteration 2515: loss: 1.038292, loss_s1: 0.501143, loss_fp: 0.500002, loss_freq: 0.500004
[02:55:01.982] iteration 2516: loss: 0.909554, loss_s1: 0.500557, loss_fp: 0.500013, loss_freq: 0.500021
[02:55:02.565] iteration 2517: loss: 0.981703, loss_s1: 0.500074, loss_fp: 0.500003, loss_freq: 0.500055
[02:55:03.156] iteration 2518: loss: 0.921137, loss_s1: 0.500277, loss_fp: 0.500010, loss_freq: 0.500052
[02:55:03.744] iteration 2519: loss: 0.941915, loss_s1: 0.500585, loss_fp: 0.500011, loss_freq: 0.500010
[02:55:04.343] iteration 2520: loss: 0.943044, loss_s1: 0.500332, loss_fp: 0.500025, loss_freq: 0.500010
[02:55:05.035] iteration 2521: loss: 0.927752, loss_s1: 0.501255, loss_fp: 0.500005, loss_freq: 0.500015
[02:55:05.661] iteration 2522: loss: 0.903859, loss_s1: 0.500095, loss_fp: 0.500007, loss_freq: 0.500012
[02:55:06.289] iteration 2523: loss: 0.998112, loss_s1: 0.503974, loss_fp: 0.500000, loss_freq: 0.500023
[02:55:06.879] iteration 2524: loss: 0.940504, loss_s1: 0.500154, loss_fp: 0.500011, loss_freq: 0.500415
[02:55:07.464] iteration 2525: loss: 0.971727, loss_s1: 0.500169, loss_fp: 0.500006, loss_freq: 0.500017
[02:55:08.090] iteration 2526: loss: 0.931975, loss_s1: 0.500582, loss_fp: 0.500005, loss_freq: 0.500172
[02:55:08.720] iteration 2527: loss: 0.951202, loss_s1: 0.500540, loss_fp: 0.500020, loss_freq: 0.500004
[02:55:09.346] iteration 2528: loss: 0.986330, loss_s1: 0.501650, loss_fp: 0.500001, loss_freq: 0.500004
[02:55:09.934] iteration 2529: loss: 0.900760, loss_s1: 0.500029, loss_fp: 0.500007, loss_freq: 0.500107
[02:55:10.532] iteration 2530: loss: 0.941421, loss_s1: 0.500214, loss_fp: 0.500001, loss_freq: 0.500063
[02:55:11.164] iteration 2531: loss: 0.896170, loss_s1: 0.502117, loss_fp: 0.500002, loss_freq: 0.500010
[02:55:11.792] iteration 2532: loss: 0.973663, loss_s1: 0.503867, loss_fp: 0.500000, loss_freq: 0.500013
[02:55:12.421] iteration 2533: loss: 0.936059, loss_s1: 0.502220, loss_fp: 0.500002, loss_freq: 0.500072
[02:55:13.050] iteration 2534: loss: 0.935062, loss_s1: 0.500091, loss_fp: 0.500001, loss_freq: 0.500014
[02:55:13.652] iteration 2535: loss: 0.938240, loss_s1: 0.501839, loss_fp: 0.499999, loss_freq: 0.500081
[02:55:14.240] iteration 2536: loss: 0.913691, loss_s1: 0.502496, loss_fp: 0.500006, loss_freq: 0.500035
[02:55:14.828] iteration 2537: loss: 0.964420, loss_s1: 0.500138, loss_fp: 0.500008, loss_freq: 0.500039
[02:55:15.415] iteration 2538: loss: 0.928888, loss_s1: 0.504844, loss_fp: 0.500064, loss_freq: 0.500019
[02:55:15.991] iteration 2539: loss: 0.910087, loss_s1: 0.500028, loss_fp: 0.500014, loss_freq: 0.500076
[02:55:16.583] iteration 2540: loss: 0.960636, loss_s1: 0.500252, loss_fp: 0.500002, loss_freq: 0.500009
[02:55:17.201] iteration 2541: loss: 0.957429, loss_s1: 0.500218, loss_fp: 0.500013, loss_freq: 0.500082
[02:55:17.781] iteration 2542: loss: 0.892201, loss_s1: 0.500401, loss_fp: 0.500006, loss_freq: 0.500104
[02:55:18.360] iteration 2543: loss: 0.975275, loss_s1: 0.500143, loss_fp: 0.500000, loss_freq: 0.500027
[02:55:18.944] iteration 2544: loss: 0.914767, loss_s1: 0.501018, loss_fp: 0.500026, loss_freq: 0.500048
[02:55:19.535] iteration 2545: loss: 0.896727, loss_s1: 0.500071, loss_fp: 0.500001, loss_freq: 0.500008
[02:55:20.117] iteration 2546: loss: 0.944435, loss_s1: 0.501908, loss_fp: 0.500004, loss_freq: 0.500043
[02:55:20.697] iteration 2547: loss: 0.915970, loss_s1: 0.500281, loss_fp: 0.500002, loss_freq: 0.500091
[02:55:21.283] iteration 2548: loss: 0.898147, loss_s1: 0.500107, loss_fp: 0.500019, loss_freq: 0.500010
[02:55:21.869] iteration 2549: loss: 0.953138, loss_s1: 0.503233, loss_fp: 0.500002, loss_freq: 0.500028
[02:55:22.529] iteration 2550: loss: 0.922454, loss_s1: 0.501578, loss_fp: 0.500002, loss_freq: 0.500556
[02:55:23.449] iteration 2551: loss: 0.906783, loss_s1: 0.505518, loss_fp: 0.500011, loss_freq: 0.500022
[02:55:24.042] iteration 2552: loss: 0.899583, loss_s1: 0.503349, loss_fp: 0.500004, loss_freq: 0.500065
[02:55:24.630] iteration 2553: loss: 0.999561, loss_s1: 0.501107, loss_fp: 0.500018, loss_freq: 0.500045
[02:55:25.218] iteration 2554: loss: 0.955532, loss_s1: 0.500473, loss_fp: 0.500032, loss_freq: 0.500099
[02:55:25.806] iteration 2555: loss: 0.936126, loss_s1: 0.500512, loss_fp: 0.500001, loss_freq: 0.500088
[02:55:26.460] iteration 2556: loss: 0.928778, loss_s1: 0.502060, loss_fp: 0.500002, loss_freq: 0.500246
[02:55:27.139] iteration 2557: loss: 0.945914, loss_s1: 0.502301, loss_fp: 0.500007, loss_freq: 0.500060
[02:55:27.793] iteration 2558: loss: 0.983757, loss_s1: 0.504206, loss_fp: 0.500002, loss_freq: 0.500001
[02:55:28.410] iteration 2559: loss: 0.891659, loss_s1: 0.500015, loss_fp: 0.500002, loss_freq: 0.500308
[02:55:28.996] iteration 2560: loss: 0.926026, loss_s1: 0.503056, loss_fp: 0.500013, loss_freq: 0.500008
[02:55:29.590] iteration 2561: loss: 0.890340, loss_s1: 0.501772, loss_fp: 0.500000, loss_freq: 0.500798
[02:55:30.187] iteration 2562: loss: 0.949140, loss_s1: 0.501546, loss_fp: 0.500004, loss_freq: 0.500837
[02:55:30.777] iteration 2563: loss: 0.971269, loss_s1: 0.502664, loss_fp: 0.500006, loss_freq: 0.503003
[02:55:31.369] iteration 2564: loss: 0.919402, loss_s1: 0.501345, loss_fp: 0.500010, loss_freq: 0.500035
[02:55:31.964] iteration 2565: loss: 0.979877, loss_s1: 0.500438, loss_fp: 0.500003, loss_freq: 0.500066
[02:55:32.550] iteration 2566: loss: 0.890584, loss_s1: 0.501278, loss_fp: 0.500150, loss_freq: 0.500012
[02:55:33.145] iteration 2567: loss: 0.936737, loss_s1: 0.501970, loss_fp: 0.500011, loss_freq: 0.500063
[02:55:33.733] iteration 2568: loss: 0.911121, loss_s1: 0.500719, loss_fp: 0.499995, loss_freq: 0.500007
[02:55:34.319] iteration 2569: loss: 0.881946, loss_s1: 0.501090, loss_fp: 0.500004, loss_freq: 0.500008
[02:55:34.909] iteration 2570: loss: 0.937697, loss_s1: 0.500744, loss_fp: 0.500017, loss_freq: 0.500064
[02:55:35.497] iteration 2571: loss: 0.921028, loss_s1: 0.501125, loss_fp: 0.500011, loss_freq: 0.500123
[02:55:36.091] iteration 2572: loss: 0.941818, loss_s1: 0.501845, loss_fp: 0.500042, loss_freq: 0.501947
[02:55:36.682] iteration 2573: loss: 0.990069, loss_s1: 0.500065, loss_fp: 0.500062, loss_freq: 0.500015
[02:55:37.272] iteration 2574: loss: 0.920530, loss_s1: 0.500519, loss_fp: 0.500002, loss_freq: 0.500191
[02:55:37.858] iteration 2575: loss: 0.914802, loss_s1: 0.500968, loss_fp: 0.500003, loss_freq: 0.500086
[02:55:38.443] iteration 2576: loss: 0.959975, loss_s1: 0.500515, loss_fp: 0.500029, loss_freq: 0.500024
[02:55:39.028] iteration 2577: loss: 0.915138, loss_s1: 0.500289, loss_fp: 0.500007, loss_freq: 0.500010
[02:55:39.613] iteration 2578: loss: 0.894542, loss_s1: 0.504256, loss_fp: 0.500077, loss_freq: 0.500092
[02:55:40.196] iteration 2579: loss: 0.993907, loss_s1: 0.500368, loss_fp: 0.500003, loss_freq: 0.500229
[02:55:40.787] iteration 2580: loss: 0.920498, loss_s1: 0.500322, loss_fp: 0.500093, loss_freq: 0.500039
[02:55:41.373] iteration 2581: loss: 0.893612, loss_s1: 0.503899, loss_fp: 0.500012, loss_freq: 0.500343
[02:55:41.970] iteration 2582: loss: 0.980366, loss_s1: 0.502410, loss_fp: 0.500029, loss_freq: 0.500295
[02:55:42.562] iteration 2583: loss: 0.929931, loss_s1: 0.502294, loss_fp: 0.499998, loss_freq: 0.500040
[02:55:43.149] iteration 2584: loss: 0.918006, loss_s1: 0.500993, loss_fp: 0.500060, loss_freq: 0.500169
[02:55:43.734] iteration 2585: loss: 0.941196, loss_s1: 0.501299, loss_fp: 0.500030, loss_freq: 0.500394
[02:55:44.317] iteration 2586: loss: 0.913765, loss_s1: 0.500021, loss_fp: 0.500218, loss_freq: 0.500015
[02:55:44.911] iteration 2587: loss: 0.890920, loss_s1: 0.501907, loss_fp: 0.500000, loss_freq: 0.500241
[02:55:45.500] iteration 2588: loss: 0.939546, loss_s1: 0.500024, loss_fp: 0.500001, loss_freq: 0.500007
[02:55:46.089] iteration 2589: loss: 0.885053, loss_s1: 0.503226, loss_fp: 0.500080, loss_freq: 0.500154
[02:55:46.681] iteration 2590: loss: 0.909344, loss_s1: 0.503215, loss_fp: 0.500001, loss_freq: 0.500067
[02:55:47.340] iteration 2591: loss: 0.904265, loss_s1: 0.502867, loss_fp: 0.500006, loss_freq: 0.501527
[02:55:47.970] iteration 2592: loss: 0.933187, loss_s1: 0.502615, loss_fp: 0.500014, loss_freq: 0.500047
[02:55:48.597] iteration 2593: loss: 0.940785, loss_s1: 0.502506, loss_fp: 0.500002, loss_freq: 0.500115
[02:55:49.190] iteration 2594: loss: 0.884055, loss_s1: 0.501115, loss_fp: 0.500023, loss_freq: 0.500300
[02:55:49.823] iteration 2595: loss: 0.909487, loss_s1: 0.500528, loss_fp: 0.500006, loss_freq: 0.500073
[02:55:50.415] iteration 2596: loss: 0.893254, loss_s1: 0.500573, loss_fp: 0.500042, loss_freq: 0.500680
[02:55:51.006] iteration 2597: loss: 0.956653, loss_s1: 0.500147, loss_fp: 0.500025, loss_freq: 0.500080
[02:55:51.596] iteration 2598: loss: 0.942623, loss_s1: 0.501037, loss_fp: 0.500186, loss_freq: 0.500104
[02:55:52.187] iteration 2599: loss: 0.908563, loss_s1: 0.501168, loss_fp: 0.500005, loss_freq: 0.500211
[02:55:52.781] iteration 2600: loss: 0.944551, loss_s1: 0.502222, loss_fp: 0.500005, loss_freq: 0.500320
[02:55:55.363] iteration 2600 : mean_dice : 0.192597
[02:55:55.994] iteration 2601: loss: 0.892995, loss_s1: 0.502480, loss_fp: 0.500000, loss_freq: 0.500049
[02:55:56.590] iteration 2602: loss: 0.922944, loss_s1: 0.500809, loss_fp: 0.500001, loss_freq: 0.500097
[02:55:57.179] iteration 2603: loss: 0.889156, loss_s1: 0.500626, loss_fp: 0.500000, loss_freq: 0.500787
[02:55:57.768] iteration 2604: loss: 0.890457, loss_s1: 0.502792, loss_fp: 0.499999, loss_freq: 0.500209
[02:55:58.356] iteration 2605: loss: 0.915062, loss_s1: 0.500166, loss_fp: 0.500005, loss_freq: 0.500018
[02:55:58.940] iteration 2606: loss: 0.890739, loss_s1: 0.500396, loss_fp: 0.500000, loss_freq: 0.500057
[02:55:59.565] iteration 2607: loss: 0.871193, loss_s1: 0.500714, loss_fp: 0.500001, loss_freq: 0.500103
[02:56:00.151] iteration 2608: loss: 0.929313, loss_s1: 0.501024, loss_fp: 0.500001, loss_freq: 0.500715
[02:56:00.741] iteration 2609: loss: 0.922436, loss_s1: 0.500932, loss_fp: 0.500006, loss_freq: 0.500114
[02:56:01.337] iteration 2610: loss: 0.913033, loss_s1: 0.506903, loss_fp: 0.500003, loss_freq: 0.500022
[02:56:01.966] iteration 2611: loss: 0.972641, loss_s1: 0.501041, loss_fp: 0.500004, loss_freq: 0.500045
[02:56:02.603] iteration 2612: loss: 0.881565, loss_s1: 0.500526, loss_fp: 0.500009, loss_freq: 0.500020
[02:56:03.192] iteration 2613: loss: 0.879004, loss_s1: 0.501460, loss_fp: 0.500009, loss_freq: 0.500170
[02:56:03.779] iteration 2614: loss: 0.913885, loss_s1: 0.502321, loss_fp: 0.500036, loss_freq: 0.500007
[02:56:04.455] iteration 2615: loss: 0.930363, loss_s1: 0.502217, loss_fp: 0.500005, loss_freq: 0.500072
[02:56:05.084] iteration 2616: loss: 0.888519, loss_s1: 0.500609, loss_fp: 0.500012, loss_freq: 0.500066
[02:56:05.685] iteration 2617: loss: 0.986035, loss_s1: 0.501220, loss_fp: 0.500017, loss_freq: 0.500134
[02:56:06.279] iteration 2618: loss: 0.906028, loss_s1: 0.501545, loss_fp: 0.500014, loss_freq: 0.500231
[02:56:06.874] iteration 2619: loss: 0.679610, loss_s1: 0.498680, loss_fp: 0.098675, loss_freq: 0.454737
[02:56:07.478] iteration 2620: loss: 0.918271, loss_s1: 0.500100, loss_fp: 0.500099, loss_freq: 0.500050
[02:56:08.076] iteration 2621: loss: 0.876029, loss_s1: 0.502325, loss_fp: 0.500523, loss_freq: 0.500431
[02:56:08.672] iteration 2622: loss: 0.871822, loss_s1: 0.501320, loss_fp: 0.500011, loss_freq: 0.500019
[02:56:09.266] iteration 2623: loss: 0.939701, loss_s1: 0.500476, loss_fp: 0.500006, loss_freq: 0.500022
[02:56:09.867] iteration 2624: loss: 0.939753, loss_s1: 0.501937, loss_fp: 0.500002, loss_freq: 0.500152
[02:56:10.478] iteration 2625: loss: 0.930310, loss_s1: 0.500544, loss_fp: 0.500003, loss_freq: 0.500237
[02:56:11.077] iteration 2626: loss: 0.905438, loss_s1: 0.501072, loss_fp: 0.499997, loss_freq: 0.500083
[02:56:11.672] iteration 2627: loss: 0.929989, loss_s1: 0.501506, loss_fp: 0.500004, loss_freq: 0.500085
[02:56:12.272] iteration 2628: loss: 0.975542, loss_s1: 0.503961, loss_fp: 0.500062, loss_freq: 0.500059
[02:56:12.867] iteration 2629: loss: 0.930355, loss_s1: 0.500328, loss_fp: 0.499997, loss_freq: 0.500096
[02:56:13.463] iteration 2630: loss: 0.885985, loss_s1: 0.501301, loss_fp: 0.499999, loss_freq: 0.500015
[02:56:14.063] iteration 2631: loss: 0.883793, loss_s1: 0.501397, loss_fp: 0.500002, loss_freq: 0.500988
[02:56:14.654] iteration 2632: loss: 0.880529, loss_s1: 0.501267, loss_fp: 0.500042, loss_freq: 0.500765
[02:56:15.245] iteration 2633: loss: 0.918356, loss_s1: 0.501412, loss_fp: 0.500017, loss_freq: 0.500561
[02:56:15.838] iteration 2634: loss: 0.899632, loss_s1: 0.502500, loss_fp: 0.500000, loss_freq: 0.500018
[02:56:16.427] iteration 2635: loss: 0.916538, loss_s1: 0.500378, loss_fp: 0.500001, loss_freq: 0.500011
[02:56:17.011] iteration 2636: loss: 0.855112, loss_s1: 0.501860, loss_fp: 0.499997, loss_freq: 0.500220
[02:56:17.601] iteration 2637: loss: 0.902609, loss_s1: 0.500266, loss_fp: 0.500563, loss_freq: 0.500012
[02:56:18.200] iteration 2638: loss: 0.920182, loss_s1: 0.501552, loss_fp: 0.500071, loss_freq: 0.500120
[02:56:18.796] iteration 2639: loss: 0.865615, loss_s1: 0.500669, loss_fp: 0.500001, loss_freq: 0.500195
[02:56:19.390] iteration 2640: loss: 0.872657, loss_s1: 0.501403, loss_fp: 0.500012, loss_freq: 0.502030
[02:56:19.985] iteration 2641: loss: 0.904696, loss_s1: 0.503124, loss_fp: 0.500032, loss_freq: 0.500058
[02:56:20.606] iteration 2642: loss: 0.856356, loss_s1: 0.502115, loss_fp: 0.500012, loss_freq: 0.501443
[02:56:21.235] iteration 2643: loss: 0.945218, loss_s1: 0.502452, loss_fp: 0.499998, loss_freq: 0.500204
[02:56:21.857] iteration 2644: loss: 0.883461, loss_s1: 0.501010, loss_fp: 0.500008, loss_freq: 0.501343
[02:56:22.449] iteration 2645: loss: 0.862156, loss_s1: 0.500464, loss_fp: 0.500001, loss_freq: 0.500006
[02:56:23.036] iteration 2646: loss: 0.931537, loss_s1: 0.500524, loss_fp: 0.500002, loss_freq: 0.500025
[02:56:23.629] iteration 2647: loss: 0.878403, loss_s1: 0.501590, loss_fp: 0.500004, loss_freq: 0.500132
[02:56:24.217] iteration 2648: loss: 0.892160, loss_s1: 0.504403, loss_fp: 0.500000, loss_freq: 0.500644
[02:56:24.805] iteration 2649: loss: 0.382471, loss_s1: 0.349997, loss_fp: 0.011322, loss_freq: 0.064795
[02:56:25.399] iteration 2650: loss: 0.893989, loss_s1: 0.500266, loss_fp: 0.500003, loss_freq: 0.500011
[02:56:25.988] iteration 2651: loss: 0.861881, loss_s1: 0.505382, loss_fp: 0.500014, loss_freq: 0.501640
[02:56:26.578] iteration 2652: loss: 0.993027, loss_s1: 0.500613, loss_fp: 0.500003, loss_freq: 0.500491
[02:56:27.167] iteration 2653: loss: 0.947237, loss_s1: 0.502408, loss_fp: 0.499997, loss_freq: 0.500022
[02:56:27.753] iteration 2654: loss: 0.989018, loss_s1: 0.504582, loss_fp: 0.499998, loss_freq: 0.500603
[02:56:28.345] iteration 2655: loss: 0.940390, loss_s1: 0.503724, loss_fp: 0.499999, loss_freq: 0.500095
[02:56:28.931] iteration 2656: loss: 0.915327, loss_s1: 0.500627, loss_fp: 0.500002, loss_freq: 0.500187
[02:56:29.517] iteration 2657: loss: 0.902395, loss_s1: 0.501442, loss_fp: 0.500009, loss_freq: 0.500011
[02:56:30.105] iteration 2658: loss: 0.782558, loss_s1: 0.499215, loss_fp: 0.169361, loss_freq: 0.470989
[02:56:30.697] iteration 2659: loss: 0.925934, loss_s1: 0.500600, loss_fp: 0.500148, loss_freq: 0.500124
[02:56:31.291] iteration 2660: loss: 0.930240, loss_s1: 0.501390, loss_fp: 0.499998, loss_freq: 0.500001
[02:56:31.888] iteration 2661: loss: 0.930691, loss_s1: 0.500008, loss_fp: 0.499990, loss_freq: 0.500020
[02:56:32.537] iteration 2662: loss: 0.970804, loss_s1: 0.500243, loss_fp: 0.499998, loss_freq: 0.500029
[02:56:33.162] iteration 2663: loss: 1.014224, loss_s1: 0.500037, loss_fp: 0.500001, loss_freq: 0.499997
[02:56:33.790] iteration 2664: loss: 1.004437, loss_s1: 0.500028, loss_fp: 0.499998, loss_freq: 0.500040
[02:56:34.418] iteration 2665: loss: 0.959072, loss_s1: 0.500081, loss_fp: 0.500008, loss_freq: 0.501889
[02:56:35.039] iteration 2666: loss: 0.979960, loss_s1: 0.500785, loss_fp: 0.500002, loss_freq: 0.500087
[02:56:35.667] iteration 2667: loss: 1.040586, loss_s1: 0.500337, loss_fp: 0.500004, loss_freq: 0.500121
[02:56:36.253] iteration 2668: loss: 1.020967, loss_s1: 0.500214, loss_fp: 0.500003, loss_freq: 0.500051
[02:56:36.841] iteration 2669: loss: 0.994113, loss_s1: 0.500168, loss_fp: 0.500000, loss_freq: 0.500038
[02:56:37.485] iteration 2670: loss: 0.986194, loss_s1: 0.500142, loss_fp: 0.500001, loss_freq: 0.500090
[02:56:38.128] iteration 2671: loss: 0.965482, loss_s1: 0.500042, loss_fp: 0.499997, loss_freq: 0.500020
[02:56:38.773] iteration 2672: loss: 1.034961, loss_s1: 0.500043, loss_fp: 0.500004, loss_freq: 0.500006
[02:56:39.402] iteration 2673: loss: 0.974847, loss_s1: 0.500003, loss_fp: 0.500003, loss_freq: 0.500010
[02:56:40.034] iteration 2674: loss: 0.927312, loss_s1: 0.500017, loss_fp: 0.499999, loss_freq: 0.500041
[02:56:40.674] iteration 2675: loss: 0.972164, loss_s1: 0.500010, loss_fp: 0.499992, loss_freq: 0.500008
[02:56:41.298] iteration 2676: loss: 0.990740, loss_s1: 0.500113, loss_fp: 0.500003, loss_freq: 0.500031
[02:56:41.911] iteration 2677: loss: 0.915009, loss_s1: 0.500124, loss_fp: 0.499978, loss_freq: 0.500026
[02:56:42.499] iteration 2678: loss: 0.974964, loss_s1: 0.500770, loss_fp: 0.500002, loss_freq: 0.500107
[02:56:43.089] iteration 2679: loss: 0.945665, loss_s1: 0.500141, loss_fp: 0.500002, loss_freq: 0.500008
[02:56:43.684] iteration 2680: loss: 0.917002, loss_s1: 0.500031, loss_fp: 0.500005, loss_freq: 0.500278
[02:56:44.278] iteration 2681: loss: 0.974992, loss_s1: 0.500096, loss_fp: 0.500010, loss_freq: 0.500035
[02:56:44.869] iteration 2682: loss: 1.006434, loss_s1: 0.500180, loss_fp: 0.500002, loss_freq: 0.500020
[02:56:45.492] iteration 2683: loss: 0.896645, loss_s1: 0.500022, loss_fp: 0.499995, loss_freq: 0.500057
[02:56:46.080] iteration 2684: loss: 0.691518, loss_s1: 0.497233, loss_fp: 0.093121, loss_freq: 0.317451
[02:56:46.663] iteration 2685: loss: 0.986005, loss_s1: 0.501265, loss_fp: 0.499995, loss_freq: 0.500003
[02:56:47.249] iteration 2686: loss: 0.911797, loss_s1: 0.500107, loss_fp: 0.500005, loss_freq: 0.500047
[02:56:47.834] iteration 2687: loss: 0.988911, loss_s1: 0.501266, loss_fp: 0.500000, loss_freq: 0.500099
[02:56:48.420] iteration 2688: loss: 0.945904, loss_s1: 0.500187, loss_fp: 0.499996, loss_freq: 0.500007
[02:56:49.006] iteration 2689: loss: 0.934334, loss_s1: 0.500058, loss_fp: 0.500003, loss_freq: 0.500003
[02:56:49.698] iteration 2690: loss: 1.015543, loss_s1: 0.500536, loss_fp: 0.500012, loss_freq: 0.500002
[02:56:50.383] iteration 2691: loss: 0.944859, loss_s1: 0.501488, loss_fp: 0.500005, loss_freq: 0.500031
[02:56:51.008] iteration 2692: loss: 0.900801, loss_s1: 0.500189, loss_fp: 0.500000, loss_freq: 0.500002
[02:56:51.660] iteration 2693: loss: 0.946838, loss_s1: 0.500665, loss_fp: 0.500005, loss_freq: 0.500335
[02:56:52.248] iteration 2694: loss: 0.950208, loss_s1: 0.500264, loss_fp: 0.500003, loss_freq: 0.500009
[02:56:52.862] iteration 2695: loss: 0.938986, loss_s1: 0.500105, loss_fp: 0.500001, loss_freq: 0.500035
[02:56:53.459] iteration 2696: loss: 0.952928, loss_s1: 0.501852, loss_fp: 0.499998, loss_freq: 0.500123
[02:56:54.051] iteration 2697: loss: 0.433978, loss_s1: 0.474316, loss_fp: 0.003331, loss_freq: 0.005366
[02:56:54.643] iteration 2698: loss: 0.973575, loss_s1: 0.500972, loss_fp: 0.499997, loss_freq: 0.500020
[02:56:55.236] iteration 2699: loss: 0.916080, loss_s1: 0.500747, loss_fp: 0.500009, loss_freq: 0.500132
[02:56:55.823] iteration 2700: loss: 0.961372, loss_s1: 0.500115, loss_fp: 0.500006, loss_freq: 0.500031
[02:56:56.414] iteration 2701: loss: 0.900874, loss_s1: 0.502486, loss_fp: 0.499992, loss_freq: 0.500054
[02:56:57.007] iteration 2702: loss: 0.977727, loss_s1: 0.501479, loss_fp: 0.499998, loss_freq: 0.500133
[02:56:57.600] iteration 2703: loss: 0.910167, loss_s1: 0.501336, loss_fp: 0.499993, loss_freq: 0.500461
[02:56:58.200] iteration 2704: loss: 0.949185, loss_s1: 0.500188, loss_fp: 0.500003, loss_freq: 0.500007
[02:56:58.795] iteration 2705: loss: 0.934543, loss_s1: 0.501621, loss_fp: 0.500016, loss_freq: 0.500007
[02:56:59.395] iteration 2706: loss: 0.901768, loss_s1: 0.500141, loss_fp: 0.499993, loss_freq: 0.500010
[02:56:59.988] iteration 2707: loss: 0.971282, loss_s1: 0.500152, loss_fp: 0.500001, loss_freq: 0.500008
[02:57:00.577] iteration 2708: loss: 0.886373, loss_s1: 0.501325, loss_fp: 0.499979, loss_freq: 0.500026
[02:57:01.179] iteration 2709: loss: 0.916204, loss_s1: 0.500289, loss_fp: 0.499997, loss_freq: 0.500024
[02:57:01.804] iteration 2710: loss: 0.940546, loss_s1: 0.500114, loss_fp: 0.499995, loss_freq: 0.500004
[02:57:02.434] iteration 2711: loss: 0.959098, loss_s1: 0.500126, loss_fp: 0.500001, loss_freq: 0.500009
[02:57:03.022] iteration 2712: loss: 0.913263, loss_s1: 0.500065, loss_fp: 0.499978, loss_freq: 0.500012
[02:57:03.621] iteration 2713: loss: 0.924736, loss_s1: 0.500343, loss_fp: 0.499996, loss_freq: 0.500010
[02:57:04.210] iteration 2714: loss: 0.881900, loss_s1: 0.500154, loss_fp: 0.499994, loss_freq: 0.500010
[02:57:04.806] iteration 2715: loss: 0.894944, loss_s1: 0.500736, loss_fp: 0.499994, loss_freq: 0.500008
[02:57:05.396] iteration 2716: loss: 0.232982, loss_s1: 0.028610, loss_fp: 0.001339, loss_freq: 0.018090
[02:57:05.982] iteration 2717: loss: 0.906918, loss_s1: 0.502021, loss_fp: 0.500000, loss_freq: 0.500361
[02:57:06.623] iteration 2718: loss: 0.886375, loss_s1: 0.500188, loss_fp: 0.500001, loss_freq: 0.500011
[02:57:07.213] iteration 2719: loss: 0.540303, loss_s1: 0.500096, loss_fp: 0.001974, loss_freq: 0.227348
[02:57:07.806] iteration 2720: loss: 0.908178, loss_s1: 0.503367, loss_fp: 0.500003, loss_freq: 0.501137
[02:57:08.754] iteration 2721: loss: 0.917856, loss_s1: 0.504982, loss_fp: 0.500011, loss_freq: 0.500009
[02:57:09.351] iteration 2722: loss: 0.921205, loss_s1: 0.503108, loss_fp: 0.499994, loss_freq: 0.500463
[02:57:09.952] iteration 2723: loss: 0.530696, loss_s1: 0.494937, loss_fp: 0.001622, loss_freq: 0.040827
[02:57:10.551] iteration 2724: loss: 0.941296, loss_s1: 0.503013, loss_fp: 0.500003, loss_freq: 0.500962
[02:57:11.201] iteration 2725: loss: 0.492248, loss_s1: 0.462608, loss_fp: 0.004193, loss_freq: 0.174337
[02:57:11.857] iteration 2726: loss: 0.954102, loss_s1: 0.500629, loss_fp: 0.499996, loss_freq: 0.501166
[02:57:12.508] iteration 2727: loss: 0.909948, loss_s1: 0.502194, loss_fp: 0.500000, loss_freq: 0.500060
[02:57:13.153] iteration 2728: loss: 0.457094, loss_s1: 0.488561, loss_fp: 0.009495, loss_freq: 0.012357
[02:57:13.748] iteration 2729: loss: 0.913260, loss_s1: 0.500264, loss_fp: 0.499996, loss_freq: 0.500024
[02:57:14.340] iteration 2730: loss: 0.499442, loss_s1: 0.494173, loss_fp: 0.078779, loss_freq: 0.103957
[02:57:14.937] iteration 2731: loss: 0.891344, loss_s1: 0.500584, loss_fp: 0.499989, loss_freq: 0.500224
[02:57:15.549] iteration 2732: loss: 0.888256, loss_s1: 0.501122, loss_fp: 0.499998, loss_freq: 0.500111
[02:57:16.159] iteration 2733: loss: 0.965956, loss_s1: 0.501439, loss_fp: 0.499996, loss_freq: 0.501788
[02:57:16.775] iteration 2734: loss: 0.447221, loss_s1: 0.197627, loss_fp: 0.005028, loss_freq: 0.144580
[02:57:17.389] iteration 2735: loss: 1.041777, loss_s1: 0.499998, loss_fp: 0.499992, loss_freq: 0.499995
[02:57:18.003] iteration 2736: loss: 0.954777, loss_s1: 0.500228, loss_fp: 0.500097, loss_freq: 0.500027
[02:57:18.614] iteration 2737: loss: 0.429950, loss_s1: 0.422531, loss_fp: 0.045717, loss_freq: 0.005259
[02:57:19.223] iteration 2738: loss: 1.103617, loss_s1: 0.500001, loss_fp: 0.499996, loss_freq: 0.499998
[02:57:19.833] iteration 2739: loss: 1.020680, loss_s1: 0.499997, loss_fp: 0.500004, loss_freq: 0.499992
[02:57:20.434] iteration 2740: loss: 1.005375, loss_s1: 0.499999, loss_fp: 0.499998, loss_freq: 0.499998
[02:57:21.034] iteration 2741: loss: 0.935013, loss_s1: 0.500018, loss_fp: 0.499990, loss_freq: 0.499999
[02:57:21.625] iteration 2742: loss: 0.997924, loss_s1: 0.500005, loss_fp: 0.500000, loss_freq: 0.500001
[02:57:22.212] iteration 2743: loss: 1.006315, loss_s1: 0.500000, loss_fp: 0.499999, loss_freq: 0.500001
[02:57:22.804] iteration 2744: loss: 0.905681, loss_s1: 0.500004, loss_fp: 0.499996, loss_freq: 0.500003
[02:57:23.395] iteration 2745: loss: 0.945593, loss_s1: 0.500055, loss_fp: 0.499999, loss_freq: 0.500000
[02:57:24.022] iteration 2746: loss: 0.996008, loss_s1: 0.500031, loss_fp: 0.500005, loss_freq: 0.500003
[02:57:24.616] iteration 2747: loss: 0.950378, loss_s1: 0.500020, loss_fp: 0.499999, loss_freq: 0.500002
[02:57:25.223] iteration 2748: loss: 0.956448, loss_s1: 0.500141, loss_fp: 0.499998, loss_freq: 0.500008
[02:57:25.824] iteration 2749: loss: 1.103106, loss_s1: 0.500135, loss_fp: 0.500007, loss_freq: 0.500003
[02:57:26.416] iteration 2750: loss: 0.969925, loss_s1: 0.500004, loss_fp: 0.499998, loss_freq: 0.500006
[02:57:27.006] iteration 2751: loss: 0.911186, loss_s1: 0.500003, loss_fp: 0.499999, loss_freq: 0.499999
[02:57:27.594] iteration 2752: loss: 0.959180, loss_s1: 0.500053, loss_fp: 0.500000, loss_freq: 0.500016
[02:57:28.187] iteration 2753: loss: 0.946521, loss_s1: 0.500428, loss_fp: 0.499972, loss_freq: 0.500000
[02:57:28.777] iteration 2754: loss: 0.979259, loss_s1: 0.500582, loss_fp: 0.500000, loss_freq: 0.500013
[02:57:29.376] iteration 2755: loss: 0.974351, loss_s1: 0.500174, loss_fp: 0.500001, loss_freq: 0.500010
[02:57:29.984] iteration 2756: loss: 0.939099, loss_s1: 0.500086, loss_fp: 0.500005, loss_freq: 0.499997
[02:57:30.589] iteration 2757: loss: 0.911983, loss_s1: 0.500014, loss_fp: 0.499993, loss_freq: 0.500014
[02:57:31.194] iteration 2758: loss: 1.014435, loss_s1: 0.500627, loss_fp: 0.499999, loss_freq: 0.499999
[02:57:31.799] iteration 2759: loss: 0.966903, loss_s1: 0.500189, loss_fp: 0.500003, loss_freq: 0.500008
[02:57:32.398] iteration 2760: loss: 0.982816, loss_s1: 0.500009, loss_fp: 0.499992, loss_freq: 0.500001
[02:57:33.000] iteration 2761: loss: 0.928944, loss_s1: 0.500762, loss_fp: 0.500006, loss_freq: 0.500077
[02:57:33.604] iteration 2762: loss: 0.931414, loss_s1: 0.500081, loss_fp: 0.500001, loss_freq: 0.500004
[02:57:34.216] iteration 2763: loss: 0.994647, loss_s1: 0.500009, loss_fp: 0.499999, loss_freq: 0.499999
[02:57:34.810] iteration 2764: loss: 0.909060, loss_s1: 0.500365, loss_fp: 0.499992, loss_freq: 0.499996
[02:57:35.420] iteration 2765: loss: 0.920946, loss_s1: 0.500337, loss_fp: 0.500005, loss_freq: 0.500001
[02:57:36.014] iteration 2766: loss: 0.894036, loss_s1: 0.500000, loss_fp: 0.500012, loss_freq: 0.499997
[02:57:36.603] iteration 2767: loss: 0.984970, loss_s1: 0.500079, loss_fp: 0.499995, loss_freq: 0.499993
[02:57:37.199] iteration 2768: loss: 0.962953, loss_s1: 0.500030, loss_fp: 0.499999, loss_freq: 0.500008
[02:57:37.790] iteration 2769: loss: 0.906143, loss_s1: 0.500015, loss_fp: 0.500001, loss_freq: 0.499998
[02:57:38.376] iteration 2770: loss: 0.944629, loss_s1: 0.500107, loss_fp: 0.499997, loss_freq: 0.500104
[02:57:38.974] iteration 2771: loss: 0.907869, loss_s1: 0.500024, loss_fp: 0.500000, loss_freq: 0.500046
[02:57:39.574] iteration 2772: loss: 0.929288, loss_s1: 0.500028, loss_fp: 0.499997, loss_freq: 0.499996
[02:57:40.169] iteration 2773: loss: 0.940790, loss_s1: 0.500398, loss_fp: 0.499996, loss_freq: 0.500413
[02:57:40.763] iteration 2774: loss: 0.929824, loss_s1: 0.500209, loss_fp: 0.499999, loss_freq: 0.500988
[02:57:41.364] iteration 2775: loss: 0.976191, loss_s1: 0.500427, loss_fp: 0.499999, loss_freq: 0.500000
[02:57:41.955] iteration 2776: loss: 0.965343, loss_s1: 0.500004, loss_fp: 0.500001, loss_freq: 0.499999
[02:57:42.551] iteration 2777: loss: 0.913125, loss_s1: 0.500030, loss_fp: 0.500010, loss_freq: 0.500001
[02:57:43.147] iteration 2778: loss: 0.967849, loss_s1: 0.500040, loss_fp: 0.500011, loss_freq: 0.500005
[02:57:43.746] iteration 2779: loss: 0.895733, loss_s1: 0.500008, loss_fp: 0.499996, loss_freq: 0.499996
[02:57:44.341] iteration 2780: loss: 0.878112, loss_s1: 0.500039, loss_fp: 0.500004, loss_freq: 0.500012
[02:57:44.934] iteration 2781: loss: 0.938334, loss_s1: 0.500104, loss_fp: 0.500004, loss_freq: 0.499995
[02:57:45.528] iteration 2782: loss: 0.908392, loss_s1: 0.500487, loss_fp: 0.500000, loss_freq: 0.499997
[02:57:46.117] iteration 2783: loss: 0.889638, loss_s1: 0.500013, loss_fp: 0.500004, loss_freq: 0.499999
[02:57:46.710] iteration 2784: loss: 0.970049, loss_s1: 0.499995, loss_fp: 0.500001, loss_freq: 0.499993
[02:57:47.302] iteration 2785: loss: 0.945324, loss_s1: 0.500220, loss_fp: 0.500000, loss_freq: 0.500009
[02:57:47.893] iteration 2786: loss: 0.882054, loss_s1: 0.500118, loss_fp: 0.500000, loss_freq: 0.500004
[02:57:48.482] iteration 2787: loss: 0.961807, loss_s1: 0.500250, loss_fp: 0.500002, loss_freq: 0.500007
[02:57:49.075] iteration 2788: loss: 0.888968, loss_s1: 0.501233, loss_fp: 0.500006, loss_freq: 0.500002
[02:57:49.673] iteration 2789: loss: 0.886144, loss_s1: 0.500527, loss_fp: 0.499989, loss_freq: 0.500008
[02:57:50.270] iteration 2790: loss: 0.924982, loss_s1: 0.500176, loss_fp: 0.500000, loss_freq: 0.499999
[02:57:50.864] iteration 2791: loss: 0.891147, loss_s1: 0.500178, loss_fp: 0.499993, loss_freq: 0.500061
[02:57:51.455] iteration 2792: loss: 0.876731, loss_s1: 0.500113, loss_fp: 0.500002, loss_freq: 0.499999
[02:57:52.044] iteration 2793: loss: 0.899714, loss_s1: 0.500151, loss_fp: 0.500149, loss_freq: 0.500004
[02:57:52.634] iteration 2794: loss: 0.909281, loss_s1: 0.500226, loss_fp: 0.499993, loss_freq: 0.500005
[02:57:53.219] iteration 2795: loss: 0.920241, loss_s1: 0.500773, loss_fp: 0.500003, loss_freq: 0.500024
[02:57:53.855] iteration 2796: loss: 0.923520, loss_s1: 0.500055, loss_fp: 0.500000, loss_freq: 0.500039
[02:57:54.475] iteration 2797: loss: 0.881280, loss_s1: 0.501553, loss_fp: 0.499995, loss_freq: 0.500006
[02:57:55.063] iteration 2798: loss: 0.955211, loss_s1: 0.500957, loss_fp: 0.500018, loss_freq: 0.500011
[02:57:55.652] iteration 2799: loss: 0.898389, loss_s1: 0.500101, loss_fp: 0.499994, loss_freq: 0.500005
[02:57:56.244] iteration 2800: loss: 0.904018, loss_s1: 0.500894, loss_fp: 0.499998, loss_freq: 0.500041
[02:57:58.874] iteration 2800 : mean_dice : 0.210064
[02:57:59.513] iteration 2801: loss: 0.883145, loss_s1: 0.500524, loss_fp: 0.500014, loss_freq: 0.500043
[02:58:00.096] iteration 2802: loss: 0.877208, loss_s1: 0.500991, loss_fp: 0.500010, loss_freq: 0.500025
[02:58:00.691] iteration 2803: loss: 0.881975, loss_s1: 0.500017, loss_fp: 0.500017, loss_freq: 0.500012
[02:58:01.278] iteration 2804: loss: 0.905324, loss_s1: 0.500187, loss_fp: 0.499994, loss_freq: 0.500001
[02:58:01.869] iteration 2805: loss: 0.923419, loss_s1: 0.500400, loss_fp: 0.500000, loss_freq: 0.500002
[02:58:02.460] iteration 2806: loss: 0.895981, loss_s1: 0.500251, loss_fp: 0.500000, loss_freq: 0.500007
[02:58:03.056] iteration 2807: loss: 0.909947, loss_s1: 0.500359, loss_fp: 0.500013, loss_freq: 0.500056
[02:58:03.648] iteration 2808: loss: 0.400576, loss_s1: 0.473213, loss_fp: 0.004551, loss_freq: 0.004445
[02:58:04.243] iteration 2809: loss: 0.869886, loss_s1: 0.500657, loss_fp: 0.500003, loss_freq: 0.500009
[02:58:04.833] iteration 2810: loss: 0.881239, loss_s1: 0.500771, loss_fp: 0.499998, loss_freq: 0.500005
[02:58:05.419] iteration 2811: loss: 0.904590, loss_s1: 0.501051, loss_fp: 0.500000, loss_freq: 0.500264
[02:58:06.010] iteration 2812: loss: 0.895136, loss_s1: 0.500222, loss_fp: 0.499998, loss_freq: 0.500532
[02:58:06.604] iteration 2813: loss: 0.709454, loss_s1: 0.500373, loss_fp: 0.343552, loss_freq: 0.252253
[02:58:07.192] iteration 2814: loss: 0.877974, loss_s1: 0.500327, loss_fp: 0.499994, loss_freq: 0.500003
[02:58:07.777] iteration 2815: loss: 0.240583, loss_s1: 0.111112, loss_fp: 0.015097, loss_freq: 0.010422
[02:58:08.370] iteration 2816: loss: 0.928526, loss_s1: 0.500000, loss_fp: 0.499997, loss_freq: 0.499990
[02:58:08.971] iteration 2817: loss: 0.970195, loss_s1: 0.500102, loss_fp: 0.500002, loss_freq: 0.499998
[02:58:09.560] iteration 2818: loss: 0.917747, loss_s1: 0.500195, loss_fp: 0.499999, loss_freq: 0.499996
[02:58:10.153] iteration 2819: loss: 1.057520, loss_s1: 0.500022, loss_fp: 0.500001, loss_freq: 0.499990
[02:58:10.743] iteration 2820: loss: 0.978186, loss_s1: 0.500276, loss_fp: 0.500013, loss_freq: 0.499992
[02:58:11.330] iteration 2821: loss: 0.893585, loss_s1: 0.500196, loss_fp: 0.500004, loss_freq: 0.500020
[02:58:11.922] iteration 2822: loss: 1.057192, loss_s1: 0.500018, loss_fp: 0.500002, loss_freq: 0.499994
[02:58:12.511] iteration 2823: loss: 0.931682, loss_s1: 0.499999, loss_fp: 0.500001, loss_freq: 0.499982
[02:58:13.179] iteration 2824: loss: 0.930467, loss_s1: 0.500162, loss_fp: 0.500003, loss_freq: 0.500002
[02:58:13.809] iteration 2825: loss: 0.919621, loss_s1: 0.500408, loss_fp: 0.499999, loss_freq: 0.499997
[02:58:14.438] iteration 2826: loss: 0.905729, loss_s1: 0.500014, loss_fp: 0.499996, loss_freq: 0.500002
[02:58:15.068] iteration 2827: loss: 0.891456, loss_s1: 0.500049, loss_fp: 0.499986, loss_freq: 0.499996
[02:58:15.654] iteration 2828: loss: 0.939861, loss_s1: 0.500029, loss_fp: 0.500031, loss_freq: 0.499997
[02:58:16.246] iteration 2829: loss: 0.930666, loss_s1: 0.501415, loss_fp: 0.499995, loss_freq: 0.500065
[02:58:16.839] iteration 2830: loss: 0.918970, loss_s1: 0.500649, loss_fp: 0.499998, loss_freq: 0.499993
[02:58:17.433] iteration 2831: loss: 0.918269, loss_s1: 0.500448, loss_fp: 0.499981, loss_freq: 0.499998
[02:58:18.112] iteration 2832: loss: 0.909822, loss_s1: 0.500269, loss_fp: 0.499984, loss_freq: 0.500003
[02:58:18.750] iteration 2833: loss: 0.927931, loss_s1: 0.500001, loss_fp: 0.499998, loss_freq: 0.499988
[02:58:19.391] iteration 2834: loss: 0.948137, loss_s1: 0.500562, loss_fp: 0.499998, loss_freq: 0.499997
[02:58:20.026] iteration 2835: loss: 0.960533, loss_s1: 0.502508, loss_fp: 0.499992, loss_freq: 0.500301
[02:58:20.663] iteration 2836: loss: 0.886855, loss_s1: 0.501064, loss_fp: 0.499999, loss_freq: 0.500466
[02:58:21.309] iteration 2837: loss: 0.920270, loss_s1: 0.500092, loss_fp: 0.499995, loss_freq: 0.500004
[02:58:21.906] iteration 2838: loss: 0.924581, loss_s1: 0.500653, loss_fp: 0.499997, loss_freq: 0.499997
[02:58:22.501] iteration 2839: loss: 0.868508, loss_s1: 0.500318, loss_fp: 0.499998, loss_freq: 0.500041
[02:58:23.185] iteration 2840: loss: 0.930502, loss_s1: 0.500006, loss_fp: 0.499994, loss_freq: 0.500090
[02:58:23.825] iteration 2841: loss: 0.939848, loss_s1: 0.500385, loss_fp: 0.499994, loss_freq: 0.499996
[02:58:24.463] iteration 2842: loss: 0.910253, loss_s1: 0.500133, loss_fp: 0.500001, loss_freq: 0.499998
[02:58:25.101] iteration 2843: loss: 0.892842, loss_s1: 0.500708, loss_fp: 0.500018, loss_freq: 0.500839
[02:58:25.721] iteration 2844: loss: 0.857779, loss_s1: 0.500158, loss_fp: 0.500007, loss_freq: 0.500001
[02:58:26.314] iteration 2845: loss: 0.910309, loss_s1: 0.500248, loss_fp: 0.500000, loss_freq: 0.499986
[02:58:26.912] iteration 2846: loss: 0.905393, loss_s1: 0.500438, loss_fp: 0.500006, loss_freq: 0.499994
[02:58:27.511] iteration 2847: loss: 0.884879, loss_s1: 0.501614, loss_fp: 0.499984, loss_freq: 0.500710
[02:58:28.104] iteration 2848: loss: 0.921594, loss_s1: 0.500447, loss_fp: 0.499996, loss_freq: 0.500123
[02:58:28.697] iteration 2849: loss: 0.899761, loss_s1: 0.500033, loss_fp: 0.500000, loss_freq: 0.500023
[02:58:29.294] iteration 2850: loss: 0.852361, loss_s1: 0.500259, loss_fp: 0.499996, loss_freq: 0.500566
[02:58:29.884] iteration 2851: loss: 0.924442, loss_s1: 0.500176, loss_fp: 0.500005, loss_freq: 0.499996
[02:58:30.478] iteration 2852: loss: 0.904115, loss_s1: 0.500008, loss_fp: 0.500001, loss_freq: 0.499997
[02:58:31.066] iteration 2853: loss: 0.866771, loss_s1: 0.501035, loss_fp: 0.499996, loss_freq: 0.500000
[02:58:31.657] iteration 2854: loss: 0.938572, loss_s1: 0.501111, loss_fp: 0.499998, loss_freq: 0.500000
[02:58:32.257] iteration 2855: loss: 0.880204, loss_s1: 0.501703, loss_fp: 0.499996, loss_freq: 0.499998
[02:58:32.849] iteration 2856: loss: 0.871482, loss_s1: 0.500442, loss_fp: 0.500003, loss_freq: 0.500181
[02:58:33.437] iteration 2857: loss: 0.917218, loss_s1: 0.501329, loss_fp: 0.499999, loss_freq: 0.500005
[02:58:34.040] iteration 2858: loss: 0.171167, loss_s1: 0.032290, loss_fp: 0.001086, loss_freq: 0.001327
[02:58:34.632] iteration 2859: loss: 0.890388, loss_s1: 0.500306, loss_fp: 0.499998, loss_freq: 0.500003
[02:58:35.233] iteration 2860: loss: 0.878774, loss_s1: 0.501768, loss_fp: 0.501278, loss_freq: 0.500005
[02:58:35.820] iteration 2861: loss: 0.403087, loss_s1: 0.493576, loss_fp: 0.007405, loss_freq: 0.067698
[02:58:36.415] iteration 2862: loss: 0.867527, loss_s1: 0.500211, loss_fp: 0.500002, loss_freq: 0.500005
[02:58:37.008] iteration 2863: loss: 0.874193, loss_s1: 0.500013, loss_fp: 0.500009, loss_freq: 0.500002
[02:58:37.606] iteration 2864: loss: 0.908616, loss_s1: 0.500023, loss_fp: 0.499998, loss_freq: 0.499999
[02:58:38.207] iteration 2865: loss: 0.906229, loss_s1: 0.500000, loss_fp: 0.499999, loss_freq: 0.499982
[02:58:38.804] iteration 2866: loss: 0.920617, loss_s1: 0.500009, loss_fp: 0.499996, loss_freq: 0.499995
[02:58:39.395] iteration 2867: loss: 0.382607, loss_s1: 0.431399, loss_fp: 0.006322, loss_freq: 0.006542
[02:58:40.025] iteration 2868: loss: 0.166106, loss_s1: 0.010788, loss_fp: 0.003211, loss_freq: 0.005665
[02:58:40.631] iteration 2869: loss: 0.880748, loss_s1: 0.500025, loss_fp: 0.499999, loss_freq: 0.499994
[02:58:41.243] iteration 2870: loss: 0.384065, loss_s1: 0.427347, loss_fp: 0.001160, loss_freq: 0.035499
[02:58:41.850] iteration 2871: loss: 0.863805, loss_s1: 0.500071, loss_fp: 0.500008, loss_freq: 0.500002
[02:58:42.476] iteration 2872: loss: 0.223944, loss_s1: 0.155360, loss_fp: 0.001224, loss_freq: 0.001765
[02:58:43.088] iteration 2873: loss: 0.897121, loss_s1: 0.500083, loss_fp: 0.499995, loss_freq: 0.500004
[02:58:43.703] iteration 2874: loss: 0.179802, loss_s1: 0.017483, loss_fp: 0.006868, loss_freq: 0.014566
[02:58:44.324] iteration 2875: loss: 1.017301, loss_s1: 0.501678, loss_fp: 0.499995, loss_freq: 0.500013
[02:58:44.938] iteration 2876: loss: 0.883044, loss_s1: 0.501398, loss_fp: 0.500000, loss_freq: 0.500097
[02:58:45.547] iteration 2877: loss: 0.273662, loss_s1: 0.178931, loss_fp: 0.003060, loss_freq: 0.021135
[02:58:46.158] iteration 2878: loss: 0.249963, loss_s1: 0.227180, loss_fp: 0.001216, loss_freq: 0.001621
[02:58:46.770] iteration 2879: loss: 0.804876, loss_s1: 0.500968, loss_fp: 0.413083, loss_freq: 0.496492
[02:58:47.388] iteration 2880: loss: 0.645420, loss_s1: 0.002093, loss_fp: 0.500002, loss_freq: 0.499998
[02:58:47.995] iteration 2881: loss: 0.299692, loss_s1: 0.279014, loss_fp: 0.001985, loss_freq: 0.000939
[02:58:48.599] iteration 2882: loss: 0.224593, loss_s1: 0.205447, loss_fp: 0.001763, loss_freq: 0.001315
[02:58:49.186] iteration 2883: loss: 0.780892, loss_s1: 0.497101, loss_fp: 0.247415, loss_freq: 0.434073
[02:58:49.775] iteration 2884: loss: 0.382477, loss_s1: 0.345379, loss_fp: 0.002731, loss_freq: 0.098415
[02:58:50.374] iteration 2885: loss: 0.357131, loss_s1: 0.304652, loss_fp: 0.074835, loss_freq: 0.002091
[02:58:50.975] iteration 2886: loss: 0.513563, loss_s1: 0.494163, loss_fp: 0.001927, loss_freq: 0.003497
[02:58:51.570] iteration 2887: loss: 1.039507, loss_s1: 0.500000, loss_fp: 0.499999, loss_freq: 0.499988
[02:58:52.168] iteration 2888: loss: 0.953237, loss_s1: 0.499991, loss_fp: 0.500002, loss_freq: 0.499988
[02:58:52.766] iteration 2889: loss: 1.089723, loss_s1: 0.499992, loss_fp: 0.499997, loss_freq: 0.499990
[02:58:53.361] iteration 2890: loss: 1.055882, loss_s1: 0.499997, loss_fp: 0.500000, loss_freq: 0.499997
[02:58:54.300] iteration 2891: loss: 1.100190, loss_s1: 0.499992, loss_fp: 0.499992, loss_freq: 0.499994
[02:58:54.968] iteration 2892: loss: 0.994064, loss_s1: 0.499997, loss_fp: 0.499995, loss_freq: 0.499992
[02:58:55.570] iteration 2893: loss: 1.059057, loss_s1: 0.499996, loss_fp: 0.499989, loss_freq: 0.499995
[02:58:56.223] iteration 2894: loss: 1.046796, loss_s1: 0.499996, loss_fp: 0.499993, loss_freq: 0.499993
[02:58:56.971] iteration 2895: loss: 1.039503, loss_s1: 0.499997, loss_fp: 0.499993, loss_freq: 0.499995
[02:58:57.601] iteration 2896: loss: 1.031892, loss_s1: 0.499998, loss_fp: 0.499998, loss_freq: 0.499997
[02:58:58.245] iteration 2897: loss: 1.018602, loss_s1: 0.500009, loss_fp: 0.500005, loss_freq: 0.500001
[02:58:58.840] iteration 2898: loss: 1.025493, loss_s1: 0.500108, loss_fp: 0.499998, loss_freq: 0.500002
[02:58:59.479] iteration 2899: loss: 0.943443, loss_s1: 0.500008, loss_fp: 0.500003, loss_freq: 0.499998
[02:59:00.067] iteration 2900: loss: 0.375371, loss_s1: 0.195415, loss_fp: 0.002337, loss_freq: 0.028837
[02:59:00.658] iteration 2901: loss: 0.952062, loss_s1: 0.501365, loss_fp: 0.499999, loss_freq: 0.500015
[02:59:01.245] iteration 2902: loss: 1.003235, loss_s1: 0.503888, loss_fp: 0.499994, loss_freq: 0.500191
[02:59:01.834] iteration 2903: loss: 0.989104, loss_s1: 0.502019, loss_fp: 0.500021, loss_freq: 0.500326
[02:59:02.422] iteration 2904: loss: 0.966938, loss_s1: 0.502499, loss_fp: 0.499998, loss_freq: 0.499998
[02:59:03.017] iteration 2905: loss: 0.886095, loss_s1: 0.290474, loss_fp: 0.500000, loss_freq: 0.500003
[02:59:03.606] iteration 2906: loss: 0.934286, loss_s1: 0.505115, loss_fp: 0.500009, loss_freq: 0.500086
[02:59:04.197] iteration 2907: loss: 0.416517, loss_s1: 0.382169, loss_fp: 0.011604, loss_freq: 0.025970
[02:59:04.796] iteration 2908: loss: 0.353357, loss_s1: 0.239135, loss_fp: 0.003741, loss_freq: 0.049719
[02:59:05.388] iteration 2909: loss: 0.911111, loss_s1: 0.502901, loss_fp: 0.500017, loss_freq: 0.499992
[02:59:05.982] iteration 2910: loss: 0.342913, loss_s1: 0.274305, loss_fp: 0.002602, loss_freq: 0.002060
[02:59:06.567] iteration 2911: loss: 0.944367, loss_s1: 0.503161, loss_fp: 0.499998, loss_freq: 0.500006
[02:59:07.157] iteration 2912: loss: 0.826847, loss_s1: 0.498518, loss_fp: 0.180746, loss_freq: 0.499012
[02:59:07.755] iteration 2913: loss: 0.305052, loss_s1: 0.109150, loss_fp: 0.002139, loss_freq: 0.002577
[02:59:08.351] iteration 2914: loss: 0.364552, loss_s1: 0.401183, loss_fp: 0.002541, loss_freq: 0.007627
[02:59:08.938] iteration 2915: loss: 0.937419, loss_s1: 0.500581, loss_fp: 0.499994, loss_freq: 0.499993
[02:59:09.530] iteration 2916: loss: 0.347447, loss_s1: 0.249448, loss_fp: 0.000705, loss_freq: 0.001061
[02:59:10.137] iteration 2917: loss: 0.264924, loss_s1: 0.061068, loss_fp: 0.001044, loss_freq: 0.001382
[02:59:10.795] iteration 2918: loss: 0.241779, loss_s1: 0.109865, loss_fp: 0.014220, loss_freq: 0.010641
[02:59:11.436] iteration 2919: loss: 0.691302, loss_s1: 0.500927, loss_fp: 0.212975, loss_freq: 0.199714
[02:59:12.087] iteration 2920: loss: 0.957673, loss_s1: 0.500036, loss_fp: 0.499999, loss_freq: 0.499994
[02:59:12.693] iteration 2921: loss: 0.503448, loss_s1: 0.336700, loss_fp: 0.034099, loss_freq: 0.066174
[02:59:13.292] iteration 2922: loss: 0.780813, loss_s1: 0.485790, loss_fp: 0.022185, loss_freq: 0.365472
[02:59:13.895] iteration 2923: loss: 0.956041, loss_s1: 0.500638, loss_fp: 0.500018, loss_freq: 0.500011
[02:59:14.487] iteration 2924: loss: 0.224880, loss_s1: 0.084182, loss_fp: 0.000838, loss_freq: 0.001069
[02:59:15.083] iteration 2925: loss: 0.369643, loss_s1: 0.302808, loss_fp: 0.001134, loss_freq: 0.006005
[02:59:15.683] iteration 2926: loss: 0.319016, loss_s1: 0.128807, loss_fp: 0.003649, loss_freq: 0.002794
[02:59:16.289] iteration 2927: loss: 0.937674, loss_s1: 0.452487, loss_fp: 0.500002, loss_freq: 0.500496
[02:59:16.903] iteration 2928: loss: 1.106487, loss_s1: 0.508235, loss_fp: 0.500004, loss_freq: 0.500179
[02:59:17.502] iteration 2929: loss: 0.431949, loss_s1: 0.359338, loss_fp: 0.000993, loss_freq: 0.003216
[02:59:18.107] iteration 2930: loss: 0.440542, loss_s1: 0.345586, loss_fp: 0.001791, loss_freq: 0.023149
[02:59:18.704] iteration 2931: loss: 0.998239, loss_s1: 0.507464, loss_fp: 0.499988, loss_freq: 0.500882
[02:59:19.306] iteration 2932: loss: 0.953467, loss_s1: 0.503772, loss_fp: 0.499991, loss_freq: 0.500088
[02:59:19.908] iteration 2933: loss: 0.346971, loss_s1: 0.283906, loss_fp: 0.000617, loss_freq: 0.001582
[02:59:20.509] iteration 2934: loss: 0.322942, loss_s1: 0.221266, loss_fp: 0.002495, loss_freq: 0.055925
[02:59:21.108] iteration 2935: loss: 0.381815, loss_s1: 0.325166, loss_fp: 0.000338, loss_freq: 0.027008
[02:59:21.707] iteration 2936: loss: 0.336058, loss_s1: 0.251876, loss_fp: 0.000768, loss_freq: 0.064174
[02:59:22.309] iteration 2937: loss: 0.345270, loss_s1: 0.006138, loss_fp: 0.000884, loss_freq: 0.001269
[02:59:22.906] iteration 2938: loss: 0.200726, loss_s1: 0.024797, loss_fp: 0.001563, loss_freq: 0.001379
[02:59:23.500] iteration 2939: loss: 0.224863, loss_s1: 0.051979, loss_fp: 0.000302, loss_freq: 0.000901
[02:59:24.098] iteration 2940: loss: 0.999128, loss_s1: 0.501407, loss_fp: 0.500040, loss_freq: 0.500205
[02:59:24.724] iteration 2941: loss: 0.500881, loss_s1: 0.503533, loss_fp: 0.010075, loss_freq: 0.158315
[02:59:25.372] iteration 2942: loss: 0.217935, loss_s1: 0.030347, loss_fp: 0.000384, loss_freq: 0.001163
[02:59:26.031] iteration 2943: loss: 0.420727, loss_s1: 0.298169, loss_fp: 0.000694, loss_freq: 0.039020
[02:59:26.776] iteration 2944: loss: 0.256050, loss_s1: 0.035938, loss_fp: 0.005813, loss_freq: 0.001894
[02:59:27.423] iteration 2945: loss: 0.598351, loss_s1: 0.378369, loss_fp: 0.004634, loss_freq: 0.248343
[02:59:28.072] iteration 2946: loss: 1.131302, loss_s1: 0.501672, loss_fp: 0.500282, loss_freq: 0.500286
[02:59:28.670] iteration 2947: loss: 0.499171, loss_s1: 0.438609, loss_fp: 0.042747, loss_freq: 0.078266
[02:59:29.285] iteration 2948: loss: 1.055006, loss_s1: 0.500145, loss_fp: 0.500002, loss_freq: 0.500058
[02:59:29.902] iteration 2949: loss: 0.654599, loss_s1: 0.393470, loss_fp: 0.001517, loss_freq: 0.305391
[02:59:30.570] iteration 2950: loss: 0.362438, loss_s1: 0.069825, loss_fp: 0.084748, loss_freq: 0.107520
[02:59:31.199] iteration 2951: loss: 0.422235, loss_s1: 0.321459, loss_fp: 0.002229, loss_freq: 0.010383
[02:59:31.895] iteration 2952: loss: 0.386914, loss_s1: 0.267508, loss_fp: 0.001596, loss_freq: 0.044850
[02:59:32.486] iteration 2953: loss: 0.367881, loss_s1: 0.248951, loss_fp: 0.001752, loss_freq: 0.044495
[02:59:33.134] iteration 2954: loss: 0.561267, loss_s1: 0.322356, loss_fp: 0.001099, loss_freq: 0.002502
[02:59:33.842] iteration 2955: loss: 0.400270, loss_s1: 0.287532, loss_fp: 0.000871, loss_freq: 0.002069
[02:59:34.517] iteration 2956: loss: 0.264104, loss_s1: 0.038853, loss_fp: 0.000961, loss_freq: 0.020848
[02:59:35.386] iteration 2957: loss: 0.495484, loss_s1: 0.378541, loss_fp: 0.000890, loss_freq: 0.005058
[02:59:36.056] iteration 2958: loss: 0.283926, loss_s1: 0.120390, loss_fp: 0.001590, loss_freq: 0.014587
[02:59:36.732] iteration 2959: loss: 0.251250, loss_s1: 0.006481, loss_fp: 0.002169, loss_freq: 0.006714
[02:59:37.326] iteration 2960: loss: 0.505696, loss_s1: 0.398978, loss_fp: 0.010971, loss_freq: 0.003868
[02:59:37.922] iteration 2961: loss: 0.354252, loss_s1: 0.239437, loss_fp: 0.001083, loss_freq: 0.003566
[02:59:38.510] iteration 2962: loss: 0.320338, loss_s1: 0.284647, loss_fp: 0.012242, loss_freq: 0.003983
[02:59:39.108] iteration 2963: loss: 0.576514, loss_s1: 0.502859, loss_fp: 0.000809, loss_freq: 0.002678
[02:59:39.705] iteration 2964: loss: 0.394241, loss_s1: 0.259165, loss_fp: 0.001232, loss_freq: 0.008786
[02:59:40.293] iteration 2965: loss: 0.326131, loss_s1: 0.131932, loss_fp: 0.002878, loss_freq: 0.002558
[02:59:40.889] iteration 2966: loss: 0.355300, loss_s1: 0.275912, loss_fp: 0.001001, loss_freq: 0.002270
[02:59:41.496] iteration 2967: loss: 0.471667, loss_s1: 0.475986, loss_fp: 0.001980, loss_freq: 0.002718
[02:59:42.084] iteration 2968: loss: 0.463367, loss_s1: 0.472434, loss_fp: 0.000628, loss_freq: 0.001189
[02:59:42.677] iteration 2969: loss: 0.591389, loss_s1: 0.502049, loss_fp: 0.007078, loss_freq: 0.205716
[02:59:43.290] iteration 2970: loss: 0.461698, loss_s1: 0.482872, loss_fp: 0.001912, loss_freq: 0.005157
[02:59:43.882] iteration 2971: loss: 0.938181, loss_s1: 0.501230, loss_fp: 0.499999, loss_freq: 0.500012
[02:59:44.474] iteration 2972: loss: 0.453357, loss_s1: 0.391743, loss_fp: 0.001325, loss_freq: 0.003222
[02:59:45.061] iteration 2973: loss: 0.343104, loss_s1: 0.109322, loss_fp: 0.001764, loss_freq: 0.033661
[02:59:45.660] iteration 2974: loss: 0.948406, loss_s1: 0.500965, loss_fp: 0.499995, loss_freq: 0.500006
[02:59:46.258] iteration 2975: loss: 1.031554, loss_s1: 0.500812, loss_fp: 0.500000, loss_freq: 0.500001
[02:59:46.870] iteration 2976: loss: 0.475890, loss_s1: 0.436591, loss_fp: 0.010504, loss_freq: 0.087264
[02:59:47.541] iteration 2977: loss: 0.429169, loss_s1: 0.406309, loss_fp: 0.024858, loss_freq: 0.008039
[02:59:48.283] iteration 2978: loss: 0.392196, loss_s1: 0.336324, loss_fp: 0.002080, loss_freq: 0.004083
[02:59:48.991] iteration 2979: loss: 0.498792, loss_s1: 0.500546, loss_fp: 0.035153, loss_freq: 0.079672
[02:59:49.597] iteration 2980: loss: 0.981770, loss_s1: 0.500622, loss_fp: 0.499999, loss_freq: 0.500343
[02:59:50.193] iteration 2981: loss: 0.521643, loss_s1: 0.349294, loss_fp: 0.032403, loss_freq: 0.010406
[02:59:50.784] iteration 2982: loss: 0.619609, loss_s1: 0.502680, loss_fp: 0.006555, loss_freq: 0.404056
[02:59:51.448] iteration 2983: loss: 0.456524, loss_s1: 0.291001, loss_fp: 0.000501, loss_freq: 0.027712
[02:59:52.082] iteration 2984: loss: 0.463481, loss_s1: 0.326982, loss_fp: 0.001367, loss_freq: 0.046418
[02:59:52.718] iteration 2985: loss: 0.318687, loss_s1: 0.036132, loss_fp: 0.001005, loss_freq: 0.048067
[02:59:53.342] iteration 2986: loss: 0.473206, loss_s1: 0.494324, loss_fp: 0.000793, loss_freq: 0.001773
[02:59:53.940] iteration 2987: loss: 0.372730, loss_s1: 0.165838, loss_fp: 0.001418, loss_freq: 0.002545
[02:59:54.535] iteration 2988: loss: 0.965785, loss_s1: 0.504100, loss_fp: 0.500000, loss_freq: 0.500182
[02:59:55.119] iteration 2989: loss: 0.534093, loss_s1: 0.326833, loss_fp: 0.001563, loss_freq: 0.006950
[02:59:55.725] iteration 2990: loss: 0.493159, loss_s1: 0.327978, loss_fp: 0.003068, loss_freq: 0.062072
[02:59:56.309] iteration 2991: loss: 0.356030, loss_s1: 0.139257, loss_fp: 0.000679, loss_freq: 0.001425
[02:59:56.899] iteration 2992: loss: 0.886594, loss_s1: 0.125581, loss_fp: 0.500000, loss_freq: 0.500589
[02:59:57.493] iteration 2993: loss: 0.309286, loss_s1: 0.075789, loss_fp: 0.001008, loss_freq: 0.003107
[02:59:58.080] iteration 2994: loss: 0.490681, loss_s1: 0.448671, loss_fp: 0.002911, loss_freq: 0.019849
[02:59:58.682] iteration 2995: loss: 0.372737, loss_s1: 0.243028, loss_fp: 0.001743, loss_freq: 0.007931
[02:59:59.282] iteration 2996: loss: 0.987351, loss_s1: 0.500370, loss_fp: 0.499996, loss_freq: 0.500028
[02:59:59.872] iteration 2997: loss: 0.308904, loss_s1: 0.155763, loss_fp: 0.001574, loss_freq: 0.004742
[03:00:00.467] iteration 2998: loss: 0.385995, loss_s1: 0.033819, loss_fp: 0.002156, loss_freq: 0.032775
[03:00:01.067] iteration 2999: loss: 1.035368, loss_s1: 0.502208, loss_fp: 0.499999, loss_freq: 0.500064
[03:00:01.657] iteration 3000: loss: 0.415768, loss_s1: 0.248904, loss_fp: 0.000886, loss_freq: 0.002138
[03:00:03.946] iteration 3000 : mean_dice : 0.059734
[03:00:04.602] iteration 3001: loss: 1.024872, loss_s1: 0.500494, loss_fp: 0.499992, loss_freq: 0.500014
[03:00:05.217] iteration 3002: loss: 0.451288, loss_s1: 0.499828, loss_fp: 0.003305, loss_freq: 0.002626
[03:00:05.812] iteration 3003: loss: 0.421446, loss_s1: 0.363447, loss_fp: 0.000698, loss_freq: 0.002000
[03:00:06.441] iteration 3004: loss: 0.885958, loss_s1: 0.503193, loss_fp: 0.463931, loss_freq: 0.416160
[03:00:07.072] iteration 3005: loss: 0.977013, loss_s1: 0.502812, loss_fp: 0.500001, loss_freq: 0.503717
[03:00:07.701] iteration 3006: loss: 0.921793, loss_s1: 0.500039, loss_fp: 0.499998, loss_freq: 0.500481
[03:00:08.299] iteration 3007: loss: 0.456457, loss_s1: 0.359382, loss_fp: 0.002988, loss_freq: 0.007562
[03:00:08.894] iteration 3008: loss: 0.365794, loss_s1: 0.178516, loss_fp: 0.001186, loss_freq: 0.001114
[03:00:09.485] iteration 3009: loss: 0.984254, loss_s1: 0.500934, loss_fp: 0.500000, loss_freq: 0.500107
[03:00:10.083] iteration 3010: loss: 0.979843, loss_s1: 0.501842, loss_fp: 0.500000, loss_freq: 0.500269
[03:00:10.676] iteration 3011: loss: 0.973656, loss_s1: 0.499141, loss_fp: 0.500000, loss_freq: 0.499999
[03:00:11.272] iteration 3012: loss: 0.959788, loss_s1: 0.500166, loss_fp: 0.500002, loss_freq: 0.499996
[03:00:11.856] iteration 3013: loss: 0.973042, loss_s1: 0.501142, loss_fp: 0.499998, loss_freq: 0.500054
[03:00:12.453] iteration 3014: loss: 0.926465, loss_s1: 0.500822, loss_fp: 0.499998, loss_freq: 0.500009
[03:00:13.044] iteration 3015: loss: 0.858988, loss_s1: 0.237706, loss_fp: 0.499992, loss_freq: 0.499994
[03:00:13.640] iteration 3016: loss: 0.992244, loss_s1: 0.500209, loss_fp: 0.499999, loss_freq: 0.499999
[03:00:14.230] iteration 3017: loss: 0.997909, loss_s1: 0.500263, loss_fp: 0.499999, loss_freq: 0.500396
[03:00:14.824] iteration 3018: loss: 1.031270, loss_s1: 0.500036, loss_fp: 0.500001, loss_freq: 0.500176
[03:00:15.410] iteration 3019: loss: 0.438483, loss_s1: 0.498913, loss_fp: 0.001208, loss_freq: 0.003452
[03:00:16.000] iteration 3020: loss: 0.949045, loss_s1: 0.500906, loss_fp: 0.500000, loss_freq: 0.500165
[03:00:16.586] iteration 3021: loss: 0.290067, loss_s1: 0.104710, loss_fp: 0.001822, loss_freq: 0.005794
[03:00:17.178] iteration 3022: loss: 0.205917, loss_s1: 0.007223, loss_fp: 0.005647, loss_freq: 0.002793
[03:00:17.770] iteration 3023: loss: 0.943813, loss_s1: 0.500005, loss_fp: 0.499998, loss_freq: 0.500002
[03:00:18.363] iteration 3024: loss: 0.311879, loss_s1: 0.055320, loss_fp: 0.001426, loss_freq: 0.001610
[03:00:18.959] iteration 3025: loss: 0.978895, loss_s1: 0.500234, loss_fp: 0.500010, loss_freq: 0.499997
[03:00:19.542] iteration 3026: loss: 0.959846, loss_s1: 0.500271, loss_fp: 0.500004, loss_freq: 0.499999
[03:00:20.150] iteration 3027: loss: 1.033208, loss_s1: 0.500011, loss_fp: 0.500004, loss_freq: 0.500010
[03:00:20.744] iteration 3028: loss: 0.333960, loss_s1: 0.255638, loss_fp: 0.001063, loss_freq: 0.001457
[03:00:21.337] iteration 3029: loss: 0.232554, loss_s1: 0.091260, loss_fp: 0.001390, loss_freq: 0.002230
[03:00:21.929] iteration 3030: loss: 0.406633, loss_s1: 0.409569, loss_fp: 0.003061, loss_freq: 0.002022
[03:00:22.522] iteration 3031: loss: 0.418929, loss_s1: 0.429928, loss_fp: 0.002325, loss_freq: 0.001618
[03:00:23.118] iteration 3032: loss: 0.930602, loss_s1: 0.500924, loss_fp: 0.499999, loss_freq: 0.500005
[03:00:23.703] iteration 3033: loss: 0.391231, loss_s1: 0.212653, loss_fp: 0.002698, loss_freq: 0.001832
[03:00:24.292] iteration 3034: loss: 0.375839, loss_s1: 0.257050, loss_fp: 0.001084, loss_freq: 0.000900
[03:00:24.925] iteration 3035: loss: 0.324593, loss_s1: 0.155571, loss_fp: 0.001390, loss_freq: 0.000870
[03:00:25.559] iteration 3036: loss: 0.985828, loss_s1: 0.500472, loss_fp: 0.499998, loss_freq: 0.500065
[03:00:26.191] iteration 3037: loss: 0.245913, loss_s1: 0.097957, loss_fp: 0.000776, loss_freq: 0.001462
[03:00:26.829] iteration 3038: loss: 0.307049, loss_s1: 0.204739, loss_fp: 0.001399, loss_freq: 0.005018
[03:00:27.438] iteration 3039: loss: 0.250264, loss_s1: 0.155787, loss_fp: 0.003039, loss_freq: 0.010122
[03:00:28.029] iteration 3040: loss: 0.224417, loss_s1: 0.029026, loss_fp: 0.001093, loss_freq: 0.018928
[03:00:28.622] iteration 3041: loss: 0.903271, loss_s1: 0.502714, loss_fp: 0.500001, loss_freq: 0.500008
[03:00:29.209] iteration 3042: loss: 0.543586, loss_s1: 0.471876, loss_fp: 0.015651, loss_freq: 0.030871
[03:00:29.804] iteration 3043: loss: 0.958409, loss_s1: 0.500117, loss_fp: 0.500002, loss_freq: 0.500007
[03:00:30.400] iteration 3044: loss: 0.276903, loss_s1: 0.071204, loss_fp: 0.001466, loss_freq: 0.001005
[03:00:30.990] iteration 3045: loss: 0.244983, loss_s1: 0.003762, loss_fp: 0.001061, loss_freq: 0.002189
[03:00:31.578] iteration 3046: loss: 0.334121, loss_s1: 0.296238, loss_fp: 0.000817, loss_freq: 0.000884
[03:00:32.168] iteration 3047: loss: 0.380575, loss_s1: 0.394880, loss_fp: 0.000889, loss_freq: 0.001052
[03:00:32.757] iteration 3048: loss: 0.240672, loss_s1: 0.084551, loss_fp: 0.001087, loss_freq: 0.000910
[03:00:33.346] iteration 3049: loss: 0.262635, loss_s1: 0.163076, loss_fp: 0.004919, loss_freq: 0.036734
[03:00:33.936] iteration 3050: loss: 0.422105, loss_s1: 0.439942, loss_fp: 0.008550, loss_freq: 0.001810
[03:00:34.525] iteration 3051: loss: 0.300955, loss_s1: 0.143188, loss_fp: 0.000665, loss_freq: 0.001057
[03:00:35.114] iteration 3052: loss: 0.276235, loss_s1: 0.248351, loss_fp: 0.001009, loss_freq: 0.000726
[03:00:35.706] iteration 3053: loss: 0.318326, loss_s1: 0.107607, loss_fp: 0.000949, loss_freq: 0.002462
[03:00:36.301] iteration 3054: loss: 0.250155, loss_s1: 0.127181, loss_fp: 0.000911, loss_freq: 0.000928
[03:00:36.891] iteration 3055: loss: 0.154372, loss_s1: 0.002661, loss_fp: 0.000781, loss_freq: 0.001365
[03:00:37.485] iteration 3056: loss: 0.348623, loss_s1: 0.184701, loss_fp: 0.000459, loss_freq: 0.000641
[03:00:38.077] iteration 3057: loss: 0.271119, loss_s1: 0.119376, loss_fp: 0.005106, loss_freq: 0.052792
[03:00:38.669] iteration 3058: loss: 0.901072, loss_s1: 0.501029, loss_fp: 0.499997, loss_freq: 0.499997
[03:00:39.258] iteration 3059: loss: 0.359427, loss_s1: 0.133421, loss_fp: 0.003742, loss_freq: 0.030010
[03:00:39.846] iteration 3060: loss: 0.371003, loss_s1: 0.344429, loss_fp: 0.000995, loss_freq: 0.036143
[03:00:40.759] iteration 3061: loss: 0.228794, loss_s1: 0.087922, loss_fp: 0.001142, loss_freq: 0.002423
[03:00:41.352] iteration 3062: loss: 0.204874, loss_s1: 0.082367, loss_fp: 0.002389, loss_freq: 0.002937
[03:00:41.942] iteration 3063: loss: 0.339635, loss_s1: 0.109007, loss_fp: 0.000672, loss_freq: 0.000832
[03:00:42.540] iteration 3064: loss: 0.200301, loss_s1: 0.019191, loss_fp: 0.001413, loss_freq: 0.000985
[03:00:43.182] iteration 3065: loss: 0.306793, loss_s1: 0.153563, loss_fp: 0.000626, loss_freq: 0.001139
[03:00:43.816] iteration 3066: loss: 0.449353, loss_s1: 0.390765, loss_fp: 0.007159, loss_freq: 0.005042
[03:00:44.457] iteration 3067: loss: 0.424350, loss_s1: 0.402513, loss_fp: 0.001290, loss_freq: 0.001715
[03:00:45.054] iteration 3068: loss: 0.290251, loss_s1: 0.149022, loss_fp: 0.000983, loss_freq: 0.001558
[03:00:45.648] iteration 3069: loss: 0.234214, loss_s1: 0.122139, loss_fp: 0.001670, loss_freq: 0.000856
[03:00:46.239] iteration 3070: loss: 0.251410, loss_s1: 0.084944, loss_fp: 0.000630, loss_freq: 0.001270
[03:00:46.838] iteration 3071: loss: 0.941784, loss_s1: 0.500380, loss_fp: 0.499993, loss_freq: 0.500024
[03:00:47.436] iteration 3072: loss: 0.389883, loss_s1: 0.294382, loss_fp: 0.000633, loss_freq: 0.002634
[03:00:48.029] iteration 3073: loss: 0.978645, loss_s1: 0.500839, loss_fp: 0.499993, loss_freq: 0.500624
[03:00:48.622] iteration 3074: loss: 0.251066, loss_s1: 0.073116, loss_fp: 0.002154, loss_freq: 0.001575
[03:00:49.220] iteration 3075: loss: 0.267623, loss_s1: 0.024007, loss_fp: 0.001547, loss_freq: 0.011140
[03:00:49.806] iteration 3076: loss: 0.432529, loss_s1: 0.439595, loss_fp: 0.000701, loss_freq: 0.001075
[03:00:50.397] iteration 3077: loss: 0.609433, loss_s1: 0.486967, loss_fp: 0.226572, loss_freq: 0.137636
[03:00:50.981] iteration 3078: loss: 0.344086, loss_s1: 0.295049, loss_fp: 0.015305, loss_freq: 0.001385
[03:00:51.573] iteration 3079: loss: 0.379078, loss_s1: 0.360967, loss_fp: 0.006490, loss_freq: 0.001870
[03:00:52.168] iteration 3080: loss: 0.447603, loss_s1: 0.395593, loss_fp: 0.001280, loss_freq: 0.001816
[03:00:52.769] iteration 3081: loss: 0.427844, loss_s1: 0.251102, loss_fp: 0.025555, loss_freq: 0.034888
[03:00:53.374] iteration 3082: loss: 1.044425, loss_s1: 0.503310, loss_fp: 0.499996, loss_freq: 0.500398
[03:00:53.968] iteration 3083: loss: 1.065128, loss_s1: 0.500693, loss_fp: 0.500000, loss_freq: 0.499995
[03:00:54.569] iteration 3084: loss: 0.952759, loss_s1: 0.500102, loss_fp: 0.499997, loss_freq: 0.500000
[03:00:55.167] iteration 3085: loss: 0.982180, loss_s1: 0.500204, loss_fp: 0.499999, loss_freq: 0.499999
[03:00:55.766] iteration 3086: loss: 0.916244, loss_s1: 0.324137, loss_fp: 0.500003, loss_freq: 0.499996
[03:00:56.374] iteration 3087: loss: 1.016976, loss_s1: 0.500001, loss_fp: 0.500010, loss_freq: 0.499997
[03:00:56.972] iteration 3088: loss: 0.940154, loss_s1: 0.500589, loss_fp: 0.500002, loss_freq: 0.500005
[03:00:57.574] iteration 3089: loss: 0.961807, loss_s1: 0.500127, loss_fp: 0.500000, loss_freq: 0.499995
[03:00:58.217] iteration 3090: loss: 1.001317, loss_s1: 0.500044, loss_fp: 0.500001, loss_freq: 0.499999
[03:00:58.821] iteration 3091: loss: 1.024661, loss_s1: 0.500030, loss_fp: 0.500010, loss_freq: 0.499998
[03:00:59.429] iteration 3092: loss: 1.019706, loss_s1: 0.500066, loss_fp: 0.500017, loss_freq: 0.500001
[03:01:00.036] iteration 3093: loss: 0.974172, loss_s1: 0.500068, loss_fp: 0.500014, loss_freq: 0.500017
[03:01:00.706] iteration 3094: loss: 0.940613, loss_s1: 0.500010, loss_fp: 0.500002, loss_freq: 0.500012
[03:01:01.618] iteration 3095: loss: 0.981979, loss_s1: 0.500756, loss_fp: 0.500012, loss_freq: 0.500009
[03:01:02.278] iteration 3096: loss: 0.995912, loss_s1: 0.500002, loss_fp: 0.500002, loss_freq: 0.499997
[03:01:02.874] iteration 3097: loss: 0.961043, loss_s1: 0.500253, loss_fp: 0.500008, loss_freq: 0.500004
[03:01:03.469] iteration 3098: loss: 0.996454, loss_s1: 0.500081, loss_fp: 0.500002, loss_freq: 0.500002
[03:01:04.056] iteration 3099: loss: 1.000125, loss_s1: 0.500297, loss_fp: 0.500004, loss_freq: 0.500005
[03:01:04.652] iteration 3100: loss: 1.009038, loss_s1: 0.500851, loss_fp: 0.499997, loss_freq: 0.500020
[03:01:05.249] iteration 3101: loss: 0.988665, loss_s1: 0.501449, loss_fp: 0.500008, loss_freq: 0.500004
[03:01:05.843] iteration 3102: loss: 0.957197, loss_s1: 0.500175, loss_fp: 0.500017, loss_freq: 0.500042
[03:01:06.441] iteration 3103: loss: 0.391956, loss_s1: 0.285581, loss_fp: 0.030341, loss_freq: 0.007749
[03:01:07.029] iteration 3104: loss: 0.947078, loss_s1: 0.500188, loss_fp: 0.500000, loss_freq: 0.500003
[03:01:07.617] iteration 3105: loss: 1.003819, loss_s1: 0.500331, loss_fp: 0.500015, loss_freq: 0.499999
[03:01:08.201] iteration 3106: loss: 0.907677, loss_s1: 0.500456, loss_fp: 0.500002, loss_freq: 0.500001
[03:01:08.790] iteration 3107: loss: 0.960404, loss_s1: 0.479797, loss_fp: 0.500034, loss_freq: 0.499997
[03:01:09.383] iteration 3108: loss: 0.486369, loss_s1: 0.481850, loss_fp: 0.004022, loss_freq: 0.005440
[03:01:09.972] iteration 3109: loss: 0.334230, loss_s1: 0.177258, loss_fp: 0.007839, loss_freq: 0.011035
[03:01:10.566] iteration 3110: loss: 0.986247, loss_s1: 0.500237, loss_fp: 0.499999, loss_freq: 0.500008
[03:01:11.162] iteration 3111: loss: 0.918483, loss_s1: 0.500516, loss_fp: 0.500013, loss_freq: 0.500001
[03:01:11.797] iteration 3112: loss: 0.971736, loss_s1: 0.500486, loss_fp: 0.500003, loss_freq: 0.499991
[03:01:12.388] iteration 3113: loss: 0.980031, loss_s1: 0.502885, loss_fp: 0.500001, loss_freq: 0.500073
[03:01:12.985] iteration 3114: loss: 0.909209, loss_s1: 0.500157, loss_fp: 0.500005, loss_freq: 0.500083
[03:01:13.586] iteration 3115: loss: 0.936522, loss_s1: 0.500875, loss_fp: 0.500003, loss_freq: 0.500002
[03:01:14.183] iteration 3116: loss: 0.214708, loss_s1: 0.022152, loss_fp: 0.002873, loss_freq: 0.002563
[03:01:14.785] iteration 3117: loss: 0.396173, loss_s1: 0.416622, loss_fp: 0.001871, loss_freq: 0.001512
[03:01:15.415] iteration 3118: loss: 0.996418, loss_s1: 0.500232, loss_fp: 0.500002, loss_freq: 0.500006
[03:01:16.014] iteration 3119: loss: 0.351328, loss_s1: 0.284133, loss_fp: 0.001854, loss_freq: 0.001647
[03:01:16.639] iteration 3120: loss: 0.917244, loss_s1: 0.500200, loss_fp: 0.500000, loss_freq: 0.500006
[03:01:17.240] iteration 3121: loss: 0.317506, loss_s1: 0.097313, loss_fp: 0.004161, loss_freq: 0.002069
[03:01:17.833] iteration 3122: loss: 0.945605, loss_s1: 0.500165, loss_fp: 0.500002, loss_freq: 0.500004
[03:01:18.431] iteration 3123: loss: 0.917021, loss_s1: 0.500038, loss_fp: 0.500010, loss_freq: 0.500000
[03:01:19.078] iteration 3124: loss: 0.212651, loss_s1: 0.044039, loss_fp: 0.000969, loss_freq: 0.001682
[03:01:19.674] iteration 3125: loss: 0.934868, loss_s1: 0.500235, loss_fp: 0.500003, loss_freq: 0.500006
[03:01:20.275] iteration 3126: loss: 0.278930, loss_s1: 0.184067, loss_fp: 0.003897, loss_freq: 0.003197
[03:01:20.869] iteration 3127: loss: 0.967934, loss_s1: 0.477476, loss_fp: 0.499998, loss_freq: 0.500018
[03:01:21.467] iteration 3128: loss: 0.275346, loss_s1: 0.164388, loss_fp: 0.001753, loss_freq: 0.006128
[03:01:22.079] iteration 3129: loss: 0.343360, loss_s1: 0.276996, loss_fp: 0.007281, loss_freq: 0.015591
[03:01:22.682] iteration 3130: loss: 0.952766, loss_s1: 0.500001, loss_fp: 0.499997, loss_freq: 0.500003
[03:01:23.282] iteration 3131: loss: 0.329493, loss_s1: 0.275647, loss_fp: 0.004080, loss_freq: 0.002609
[03:01:23.881] iteration 3132: loss: 0.919739, loss_s1: 0.500002, loss_fp: 0.500003, loss_freq: 0.500001
[03:01:24.477] iteration 3133: loss: 0.415691, loss_s1: 0.392442, loss_fp: 0.002175, loss_freq: 0.006132
[03:01:25.077] iteration 3134: loss: 0.938217, loss_s1: 0.500150, loss_fp: 0.499991, loss_freq: 0.500003
[03:01:25.679] iteration 3135: loss: 0.465555, loss_s1: 0.403181, loss_fp: 0.000995, loss_freq: 0.040550
[03:01:26.289] iteration 3136: loss: 0.955291, loss_s1: 0.500530, loss_fp: 0.500000, loss_freq: 0.500079
[03:01:26.891] iteration 3137: loss: 0.953275, loss_s1: 0.501297, loss_fp: 0.499997, loss_freq: 0.500003
[03:01:27.505] iteration 3138: loss: 0.566875, loss_s1: 0.489373, loss_fp: 0.022408, loss_freq: 0.119470
[03:01:28.105] iteration 3139: loss: 0.452473, loss_s1: 0.479278, loss_fp: 0.007552, loss_freq: 0.004823
[03:01:28.710] iteration 3140: loss: 0.297653, loss_s1: 0.128533, loss_fp: 0.003094, loss_freq: 0.004940
[03:01:29.311] iteration 3141: loss: 0.927104, loss_s1: 0.500918, loss_fp: 0.500000, loss_freq: 0.501511
[03:01:29.934] iteration 3142: loss: 1.017495, loss_s1: 0.500658, loss_fp: 0.499993, loss_freq: 0.500215
[03:01:30.536] iteration 3143: loss: 0.530234, loss_s1: 0.493725, loss_fp: 0.021689, loss_freq: 0.067746
[03:01:31.133] iteration 3144: loss: 0.394208, loss_s1: 0.278583, loss_fp: 0.009515, loss_freq: 0.026761
[03:01:31.732] iteration 3145: loss: 0.444472, loss_s1: 0.387378, loss_fp: 0.001357, loss_freq: 0.009255
[03:01:32.329] iteration 3146: loss: 0.960986, loss_s1: 0.500041, loss_fp: 0.500001, loss_freq: 0.499998
[03:01:32.926] iteration 3147: loss: 0.224407, loss_s1: 0.073988, loss_fp: 0.000874, loss_freq: 0.000837
[03:01:33.554] iteration 3148: loss: 0.434098, loss_s1: 0.391958, loss_fp: 0.000657, loss_freq: 0.005142
[03:01:34.182] iteration 3149: loss: 0.915805, loss_s1: 0.500293, loss_fp: 0.500001, loss_freq: 0.500000
[03:01:34.789] iteration 3150: loss: 0.920515, loss_s1: 0.502725, loss_fp: 0.499994, loss_freq: 0.499998
[03:01:35.392] iteration 3151: loss: 0.436912, loss_s1: 0.471093, loss_fp: 0.020833, loss_freq: 0.017939
[03:01:35.992] iteration 3152: loss: 0.637074, loss_s1: 0.500586, loss_fp: 0.011462, loss_freq: 0.462497
[03:01:36.598] iteration 3153: loss: 0.245277, loss_s1: 0.051551, loss_fp: 0.000686, loss_freq: 0.001887
[03:01:37.251] iteration 3154: loss: 0.887792, loss_s1: 0.500051, loss_fp: 0.499990, loss_freq: 0.499999
[03:01:37.853] iteration 3155: loss: 0.335598, loss_s1: 0.161062, loss_fp: 0.000754, loss_freq: 0.025248
[03:01:38.448] iteration 3156: loss: 0.661764, loss_s1: 0.477930, loss_fp: 0.040365, loss_freq: 0.366897
[03:01:39.046] iteration 3157: loss: 0.278910, loss_s1: 0.082092, loss_fp: 0.002606, loss_freq: 0.001608
[03:01:39.641] iteration 3158: loss: 0.946780, loss_s1: 0.500241, loss_fp: 0.499994, loss_freq: 0.500027
[03:01:40.240] iteration 3159: loss: 0.305684, loss_s1: 0.127433, loss_fp: 0.000511, loss_freq: 0.003955
[03:01:40.840] iteration 3160: loss: 0.283890, loss_s1: 0.217865, loss_fp: 0.003341, loss_freq: 0.002725
[03:01:41.439] iteration 3161: loss: 0.199434, loss_s1: 0.067915, loss_fp: 0.000639, loss_freq: 0.011504
[03:01:42.040] iteration 3162: loss: 0.215814, loss_s1: 0.013719, loss_fp: 0.002275, loss_freq: 0.004801
[03:01:42.682] iteration 3163: loss: 0.308951, loss_s1: 0.196385, loss_fp: 0.001205, loss_freq: 0.017688
[03:01:43.324] iteration 3164: loss: 0.328604, loss_s1: 0.264419, loss_fp: 0.000928, loss_freq: 0.001774
[03:01:43.961] iteration 3165: loss: 0.278664, loss_s1: 0.156817, loss_fp: 0.000525, loss_freq: 0.001740
[03:01:44.567] iteration 3166: loss: 0.350766, loss_s1: 0.369773, loss_fp: 0.001038, loss_freq: 0.006006
[03:01:45.162] iteration 3167: loss: 0.699701, loss_s1: 0.032481, loss_fp: 0.499989, loss_freq: 0.500000
[03:01:45.755] iteration 3168: loss: 0.232417, loss_s1: 0.079011, loss_fp: 0.000641, loss_freq: 0.000874
[03:01:46.356] iteration 3169: loss: 0.968268, loss_s1: 0.502218, loss_fp: 0.499998, loss_freq: 0.505778
[03:01:46.961] iteration 3170: loss: 0.303509, loss_s1: 0.154946, loss_fp: 0.000678, loss_freq: 0.000810
[03:01:47.558] iteration 3171: loss: 0.950249, loss_s1: 0.496115, loss_fp: 0.499998, loss_freq: 0.500016
[03:01:48.161] iteration 3172: loss: 0.395746, loss_s1: 0.386982, loss_fp: 0.000649, loss_freq: 0.000528
[03:01:48.776] iteration 3173: loss: 0.256865, loss_s1: 0.059180, loss_fp: 0.000582, loss_freq: 0.000869
[03:01:49.399] iteration 3174: loss: 0.294161, loss_s1: 0.257998, loss_fp: 0.001232, loss_freq: 0.009037
[03:01:50.020] iteration 3175: loss: 0.988385, loss_s1: 0.503971, loss_fp: 0.499997, loss_freq: 0.500902
[03:01:50.623] iteration 3176: loss: 0.904378, loss_s1: 0.506442, loss_fp: 0.499984, loss_freq: 0.500819
[03:01:51.241] iteration 3177: loss: 0.277866, loss_s1: 0.156179, loss_fp: 0.000501, loss_freq: 0.039379
[03:01:51.848] iteration 3178: loss: 0.264230, loss_s1: 0.154637, loss_fp: 0.000610, loss_freq: 0.033109
[03:01:52.441] iteration 3179: loss: 0.912037, loss_s1: 0.505592, loss_fp: 0.499995, loss_freq: 0.501542
[03:01:53.036] iteration 3180: loss: 0.326546, loss_s1: 0.201079, loss_fp: 0.000864, loss_freq: 0.032889
[03:01:53.664] iteration 3181: loss: 0.251543, loss_s1: 0.048998, loss_fp: 0.000857, loss_freq: 0.001556
[03:01:54.249] iteration 3182: loss: 0.324322, loss_s1: 0.303567, loss_fp: 0.000418, loss_freq: 0.000738
[03:01:54.845] iteration 3183: loss: 0.459006, loss_s1: 0.434531, loss_fp: 0.001843, loss_freq: 0.160934
[03:01:55.436] iteration 3184: loss: 0.187708, loss_s1: 0.084540, loss_fp: 0.001542, loss_freq: 0.001035
[03:01:56.026] iteration 3185: loss: 0.232379, loss_s1: 0.049020, loss_fp: 0.005940, loss_freq: 0.001327
[03:01:56.617] iteration 3186: loss: 0.290422, loss_s1: 0.172763, loss_fp: 0.001223, loss_freq: 0.001230
[03:01:57.205] iteration 3187: loss: 0.874760, loss_s1: 0.501101, loss_fp: 0.499991, loss_freq: 0.500902
[03:01:57.800] iteration 3188: loss: 0.457187, loss_s1: 0.331749, loss_fp: 0.002131, loss_freq: 0.075921
[03:01:58.395] iteration 3189: loss: 0.160219, loss_s1: 0.021738, loss_fp: 0.000798, loss_freq: 0.003211
[03:01:58.982] iteration 3190: loss: 0.895329, loss_s1: 0.501241, loss_fp: 0.500000, loss_freq: 0.500084
[03:01:59.578] iteration 3191: loss: 0.295596, loss_s1: 0.124679, loss_fp: 0.000876, loss_freq: 0.030773
[03:02:00.169] iteration 3192: loss: 0.253897, loss_s1: 0.137758, loss_fp: 0.001451, loss_freq: 0.009570
[03:02:00.760] iteration 3193: loss: 0.910905, loss_s1: 0.502136, loss_fp: 0.500017, loss_freq: 0.499998
[03:02:01.346] iteration 3194: loss: 0.220072, loss_s1: 0.021256, loss_fp: 0.000770, loss_freq: 0.003939
[03:02:01.937] iteration 3195: loss: 0.352977, loss_s1: 0.301278, loss_fp: 0.005475, loss_freq: 0.021333
[03:02:02.531] iteration 3196: loss: 0.429464, loss_s1: 0.476509, loss_fp: 0.005385, loss_freq: 0.062356
[03:02:03.125] iteration 3197: loss: 0.445322, loss_s1: 0.407915, loss_fp: 0.001838, loss_freq: 0.002801
[03:02:03.723] iteration 3198: loss: 0.288585, loss_s1: 0.266745, loss_fp: 0.000837, loss_freq: 0.002279
[03:02:04.323] iteration 3199: loss: 0.196471, loss_s1: 0.100066, loss_fp: 0.000677, loss_freq: 0.001552
[03:02:04.914] iteration 3200: loss: 0.214767, loss_s1: 0.096816, loss_fp: 0.004977, loss_freq: 0.004676
[03:02:07.421] iteration 3200 : mean_dice : 0.123047
[03:02:08.052] iteration 3201: loss: 0.363361, loss_s1: 0.349007, loss_fp: 0.011076, loss_freq: 0.011630
[03:02:08.638] iteration 3202: loss: 0.884722, loss_s1: 0.500131, loss_fp: 0.500002, loss_freq: 0.500006
[03:02:09.224] iteration 3203: loss: 0.394230, loss_s1: 0.204693, loss_fp: 0.001249, loss_freq: 0.001606
[03:02:09.819] iteration 3204: loss: 0.244751, loss_s1: 0.139025, loss_fp: 0.001217, loss_freq: 0.000514
[03:02:10.404] iteration 3205: loss: 0.230434, loss_s1: 0.012450, loss_fp: 0.000658, loss_freq: 0.001916
[03:02:10.987] iteration 3206: loss: 0.191769, loss_s1: 0.018986, loss_fp: 0.001246, loss_freq: 0.000798
[03:02:11.573] iteration 3207: loss: 0.296784, loss_s1: 0.236653, loss_fp: 0.000960, loss_freq: 0.002561
[03:02:12.161] iteration 3208: loss: 0.264358, loss_s1: 0.152375, loss_fp: 0.001383, loss_freq: 0.002829
[03:02:12.757] iteration 3209: loss: 0.141610, loss_s1: 0.020838, loss_fp: 0.000675, loss_freq: 0.001062
[03:02:13.344] iteration 3210: loss: 0.231350, loss_s1: 0.160877, loss_fp: 0.000437, loss_freq: 0.000972
[03:02:13.953] iteration 3211: loss: 0.388377, loss_s1: 0.502569, loss_fp: 0.002494, loss_freq: 0.003674
[03:02:14.544] iteration 3212: loss: 0.414116, loss_s1: 0.407010, loss_fp: 0.000863, loss_freq: 0.003430
[03:02:15.159] iteration 3213: loss: 0.929972, loss_s1: 0.501990, loss_fp: 0.499998, loss_freq: 0.500250
[03:02:15.764] iteration 3214: loss: 0.175960, loss_s1: 0.002437, loss_fp: 0.000762, loss_freq: 0.000887
[03:02:16.422] iteration 3215: loss: 0.302705, loss_s1: 0.189185, loss_fp: 0.001269, loss_freq: 0.030899
[03:02:17.023] iteration 3216: loss: 0.292178, loss_s1: 0.217663, loss_fp: 0.000522, loss_freq: 0.001573
[03:02:17.619] iteration 3217: loss: 0.242165, loss_s1: 0.185030, loss_fp: 0.001862, loss_freq: 0.000563
[03:02:18.222] iteration 3218: loss: 0.213547, loss_s1: 0.066236, loss_fp: 0.000616, loss_freq: 0.000796
[03:02:18.822] iteration 3219: loss: 0.214889, loss_s1: 0.187656, loss_fp: 0.000690, loss_freq: 0.002078
[03:02:19.419] iteration 3220: loss: 0.335896, loss_s1: 0.340175, loss_fp: 0.001340, loss_freq: 0.000802
[03:02:20.011] iteration 3221: loss: 0.328057, loss_s1: 0.418900, loss_fp: 0.000950, loss_freq: 0.001207
[03:02:20.650] iteration 3222: loss: 0.146095, loss_s1: 0.008256, loss_fp: 0.000883, loss_freq: 0.000706
[03:02:21.248] iteration 3223: loss: 0.426065, loss_s1: 0.326253, loss_fp: 0.000710, loss_freq: 0.032976
[03:02:21.853] iteration 3224: loss: 0.336163, loss_s1: 0.384146, loss_fp: 0.000992, loss_freq: 0.001351
[03:02:22.451] iteration 3225: loss: 0.162776, loss_s1: 0.023074, loss_fp: 0.000239, loss_freq: 0.000840
[03:02:23.053] iteration 3226: loss: 0.250208, loss_s1: 0.072821, loss_fp: 0.001009, loss_freq: 0.005680
[03:02:23.655] iteration 3227: loss: 0.281383, loss_s1: 0.219968, loss_fp: 0.019345, loss_freq: 0.022129
[03:02:24.250] iteration 3228: loss: 0.748439, loss_s1: 0.206550, loss_fp: 0.500000, loss_freq: 0.500001
[03:02:24.843] iteration 3229: loss: 0.287933, loss_s1: 0.110567, loss_fp: 0.001048, loss_freq: 0.001776
[03:02:25.430] iteration 3230: loss: 0.376842, loss_s1: 0.353184, loss_fp: 0.000766, loss_freq: 0.120224
[03:02:26.357] iteration 3231: loss: 0.287829, loss_s1: 0.266060, loss_fp: 0.000567, loss_freq: 0.000566
[03:02:26.944] iteration 3232: loss: 0.231911, loss_s1: 0.180021, loss_fp: 0.000744, loss_freq: 0.000983
[03:02:27.542] iteration 3233: loss: 0.181985, loss_s1: 0.083913, loss_fp: 0.000628, loss_freq: 0.003112
[03:02:28.143] iteration 3234: loss: 0.360935, loss_s1: 0.345313, loss_fp: 0.001376, loss_freq: 0.003331
[03:02:28.739] iteration 3235: loss: 0.317441, loss_s1: 0.290181, loss_fp: 0.000603, loss_freq: 0.000767
[03:02:29.372] iteration 3236: loss: 0.340209, loss_s1: 0.258411, loss_fp: 0.002976, loss_freq: 0.002117
[03:02:29.965] iteration 3237: loss: 0.337594, loss_s1: 0.341699, loss_fp: 0.001267, loss_freq: 0.076980
[03:02:30.560] iteration 3238: loss: 0.263489, loss_s1: 0.181844, loss_fp: 0.000659, loss_freq: 0.013269
[03:02:31.154] iteration 3239: loss: 0.249812, loss_s1: 0.202754, loss_fp: 0.000511, loss_freq: 0.009916
[03:02:31.751] iteration 3240: loss: 0.266582, loss_s1: 0.201499, loss_fp: 0.006758, loss_freq: 0.011611
[03:02:32.350] iteration 3241: loss: 0.929879, loss_s1: 0.500036, loss_fp: 0.500001, loss_freq: 0.500017
[03:02:32.946] iteration 3242: loss: 0.934461, loss_s1: 0.501167, loss_fp: 0.499994, loss_freq: 0.500022
[03:02:33.538] iteration 3243: loss: 0.314667, loss_s1: 0.274747, loss_fp: 0.000892, loss_freq: 0.007805
[03:02:34.186] iteration 3244: loss: 0.258566, loss_s1: 0.206662, loss_fp: 0.001616, loss_freq: 0.003090
[03:02:34.819] iteration 3245: loss: 0.434862, loss_s1: 0.424935, loss_fp: 0.001152, loss_freq: 0.021269
[03:02:35.416] iteration 3246: loss: 0.244369, loss_s1: 0.136522, loss_fp: 0.001144, loss_freq: 0.001175
[03:02:36.004] iteration 3247: loss: 0.302778, loss_s1: 0.268100, loss_fp: 0.002260, loss_freq: 0.000939
[03:02:36.604] iteration 3248: loss: 0.222124, loss_s1: 0.071258, loss_fp: 0.000722, loss_freq: 0.005945
[03:02:37.196] iteration 3249: loss: 0.221577, loss_s1: 0.182814, loss_fp: 0.000594, loss_freq: 0.005657
[03:02:37.791] iteration 3250: loss: 0.360347, loss_s1: 0.440869, loss_fp: 0.002171, loss_freq: 0.000995
[03:02:38.384] iteration 3251: loss: 0.384288, loss_s1: 0.314777, loss_fp: 0.002735, loss_freq: 0.065736
[03:02:38.980] iteration 3252: loss: 0.346525, loss_s1: 0.329174, loss_fp: 0.001036, loss_freq: 0.000647
[03:02:39.574] iteration 3253: loss: 0.255446, loss_s1: 0.130198, loss_fp: 0.000681, loss_freq: 0.003413
[03:02:40.188] iteration 3254: loss: 0.293457, loss_s1: 0.192361, loss_fp: 0.001787, loss_freq: 0.001571
[03:02:40.788] iteration 3255: loss: 0.203108, loss_s1: 0.121902, loss_fp: 0.000918, loss_freq: 0.000718
[03:02:41.383] iteration 3256: loss: 0.206052, loss_s1: 0.043420, loss_fp: 0.000726, loss_freq: 0.000538
[03:02:41.984] iteration 3257: loss: 0.236720, loss_s1: 0.081707, loss_fp: 0.000562, loss_freq: 0.000701
[03:02:42.587] iteration 3258: loss: 0.896832, loss_s1: 0.502272, loss_fp: 0.499998, loss_freq: 0.499997
[03:02:43.184] iteration 3259: loss: 0.413900, loss_s1: 0.347763, loss_fp: 0.001967, loss_freq: 0.000832
[03:02:43.787] iteration 3260: loss: 0.920147, loss_s1: 0.500309, loss_fp: 0.499997, loss_freq: 0.499987
[03:02:44.382] iteration 3261: loss: 0.278489, loss_s1: 0.149373, loss_fp: 0.000712, loss_freq: 0.016842
[03:02:44.973] iteration 3262: loss: 0.403009, loss_s1: 0.258568, loss_fp: 0.002916, loss_freq: 0.004736
[03:02:45.571] iteration 3263: loss: 0.193119, loss_s1: 0.086404, loss_fp: 0.000663, loss_freq: 0.002599
[03:02:46.170] iteration 3264: loss: 0.155410, loss_s1: 0.027074, loss_fp: 0.001022, loss_freq: 0.003284
[03:02:46.762] iteration 3265: loss: 0.332824, loss_s1: 0.304247, loss_fp: 0.001458, loss_freq: 0.000780
[03:02:47.357] iteration 3266: loss: 0.260400, loss_s1: 0.148259, loss_fp: 0.002113, loss_freq: 0.004713
[03:02:47.944] iteration 3267: loss: 0.906179, loss_s1: 0.500992, loss_fp: 0.500002, loss_freq: 0.499996
[03:02:48.535] iteration 3268: loss: 0.286418, loss_s1: 0.136419, loss_fp: 0.001084, loss_freq: 0.012978
[03:02:49.130] iteration 3269: loss: 0.347808, loss_s1: 0.336765, loss_fp: 0.003013, loss_freq: 0.002236
[03:02:49.717] iteration 3270: loss: 0.240794, loss_s1: 0.016289, loss_fp: 0.001119, loss_freq: 0.026841
[03:02:50.310] iteration 3271: loss: 0.182205, loss_s1: 0.015223, loss_fp: 0.002857, loss_freq: 0.004629
[03:02:50.903] iteration 3272: loss: 0.394525, loss_s1: 0.444631, loss_fp: 0.016599, loss_freq: 0.032164
[03:02:51.497] iteration 3273: loss: 0.333960, loss_s1: 0.224610, loss_fp: 0.000564, loss_freq: 0.056625
[03:02:52.088] iteration 3274: loss: 0.225821, loss_s1: 0.147696, loss_fp: 0.000543, loss_freq: 0.000579
[03:02:52.681] iteration 3275: loss: 0.267744, loss_s1: 0.166515, loss_fp: 0.000589, loss_freq: 0.009823
[03:02:53.272] iteration 3276: loss: 0.191845, loss_s1: 0.129273, loss_fp: 0.002492, loss_freq: 0.003092
[03:02:53.871] iteration 3277: loss: 0.234931, loss_s1: 0.132093, loss_fp: 0.001115, loss_freq: 0.006979
[03:02:54.470] iteration 3278: loss: 0.243742, loss_s1: 0.095371, loss_fp: 0.001919, loss_freq: 0.000711
[03:02:55.060] iteration 3279: loss: 0.418443, loss_s1: 0.493177, loss_fp: 0.000435, loss_freq: 0.000480
[03:02:55.666] iteration 3280: loss: 0.343085, loss_s1: 0.242044, loss_fp: 0.001104, loss_freq: 0.061240
[03:02:56.254] iteration 3281: loss: 0.898936, loss_s1: 0.500314, loss_fp: 0.500000, loss_freq: 0.500032
[03:02:56.855] iteration 3282: loss: 0.279071, loss_s1: 0.240048, loss_fp: 0.000411, loss_freq: 0.006068
[03:02:57.451] iteration 3283: loss: 0.265165, loss_s1: 0.243807, loss_fp: 0.003350, loss_freq: 0.001145
[03:02:58.054] iteration 3284: loss: 0.409812, loss_s1: 0.355449, loss_fp: 0.001293, loss_freq: 0.186784
[03:02:58.647] iteration 3285: loss: 0.193133, loss_s1: 0.001044, loss_fp: 0.008450, loss_freq: 0.009907
[03:02:59.240] iteration 3286: loss: 0.309016, loss_s1: 0.038726, loss_fp: 0.000681, loss_freq: 0.000809
[03:02:59.837] iteration 3287: loss: 0.500773, loss_s1: 0.494670, loss_fp: 0.155153, loss_freq: 0.011546
[03:03:00.428] iteration 3288: loss: 1.070932, loss_s1: 0.500830, loss_fp: 0.499984, loss_freq: 0.499996
[03:03:01.026] iteration 3289: loss: 0.599187, loss_s1: 0.199645, loss_fp: 0.002000, loss_freq: 0.105457
[03:03:01.621] iteration 3290: loss: 0.339273, loss_s1: 0.021566, loss_fp: 0.002354, loss_freq: 0.065257
[03:03:02.214] iteration 3291: loss: 0.412686, loss_s1: 0.132886, loss_fp: 0.048020, loss_freq: 0.030346
[03:03:02.811] iteration 3292: loss: 0.469687, loss_s1: 0.227772, loss_fp: 0.000688, loss_freq: 0.065101
[03:03:03.407] iteration 3293: loss: 0.427211, loss_s1: 0.320791, loss_fp: 0.000814, loss_freq: 0.016956
[03:03:04.245] iteration 3294: loss: 1.063169, loss_s1: 0.390511, loss_fp: 0.500000, loss_freq: 0.500535
[03:03:05.128] iteration 3295: loss: 0.249907, loss_s1: 0.006622, loss_fp: 0.000749, loss_freq: 0.021068
[03:03:05.869] iteration 3296: loss: 0.304557, loss_s1: 0.048963, loss_fp: 0.002012, loss_freq: 0.091432
[03:03:06.463] iteration 3297: loss: 0.398527, loss_s1: 0.237642, loss_fp: 0.003789, loss_freq: 0.002747
[03:03:07.050] iteration 3298: loss: 0.362930, loss_s1: 0.304216, loss_fp: 0.000306, loss_freq: 0.028009
[03:03:07.640] iteration 3299: loss: 0.561671, loss_s1: 0.376144, loss_fp: 0.001555, loss_freq: 0.066465
[03:03:08.227] iteration 3300: loss: 0.362287, loss_s1: 0.177140, loss_fp: 0.001381, loss_freq: 0.025591
[03:03:08.805] iteration 3301: loss: 0.335052, loss_s1: 0.207610, loss_fp: 0.000568, loss_freq: 0.043778
[03:03:09.403] iteration 3302: loss: 0.998103, loss_s1: 0.500146, loss_fp: 0.499998, loss_freq: 0.500000
[03:03:09.992] iteration 3303: loss: 0.650434, loss_s1: 0.392811, loss_fp: 0.096245, loss_freq: 0.123160
[03:03:10.585] iteration 3304: loss: 0.971523, loss_s1: 0.484402, loss_fp: 0.500000, loss_freq: 0.500287
[03:03:11.179] iteration 3305: loss: 0.522871, loss_s1: 0.336892, loss_fp: 0.007810, loss_freq: 0.276818
[03:03:11.776] iteration 3306: loss: 0.286505, loss_s1: 0.092386, loss_fp: 0.000987, loss_freq: 0.011868
[03:03:12.376] iteration 3307: loss: 0.479699, loss_s1: 0.073801, loss_fp: 0.011679, loss_freq: 0.431636
[03:03:12.972] iteration 3308: loss: 0.537624, loss_s1: 0.479356, loss_fp: 0.008849, loss_freq: 0.003022
[03:03:13.567] iteration 3309: loss: 0.382372, loss_s1: 0.427690, loss_fp: 0.035257, loss_freq: 0.006109
[03:03:14.161] iteration 3310: loss: 0.352732, loss_s1: 0.287385, loss_fp: 0.000608, loss_freq: 0.001454
[03:03:14.760] iteration 3311: loss: 0.960883, loss_s1: 0.502421, loss_fp: 0.500002, loss_freq: 0.499989
[03:03:15.417] iteration 3312: loss: 0.408924, loss_s1: 0.299788, loss_fp: 0.002137, loss_freq: 0.000770
[03:03:16.020] iteration 3313: loss: 0.775965, loss_s1: 0.165524, loss_fp: 0.500002, loss_freq: 0.499997
[03:03:16.628] iteration 3314: loss: 0.291523, loss_s1: 0.167343, loss_fp: 0.001168, loss_freq: 0.001087
[03:03:17.247] iteration 3315: loss: 0.977457, loss_s1: 0.457484, loss_fp: 0.500002, loss_freq: 0.499999
[03:03:17.835] iteration 3316: loss: 0.486343, loss_s1: 0.473822, loss_fp: 0.024469, loss_freq: 0.051582
[03:03:18.439] iteration 3317: loss: 0.347440, loss_s1: 0.266721, loss_fp: 0.003698, loss_freq: 0.001260
[03:03:19.121] iteration 3318: loss: 0.371584, loss_s1: 0.287180, loss_fp: 0.002254, loss_freq: 0.006535
[03:03:19.796] iteration 3319: loss: 0.919114, loss_s1: 0.500565, loss_fp: 0.500008, loss_freq: 0.499996
[03:03:20.478] iteration 3320: loss: 0.955091, loss_s1: 0.500218, loss_fp: 0.500010, loss_freq: 0.499999
[03:03:21.105] iteration 3321: loss: 0.966220, loss_s1: 0.500649, loss_fp: 0.500001, loss_freq: 0.500071
[03:03:21.786] iteration 3322: loss: 0.926978, loss_s1: 0.500725, loss_fp: 0.500001, loss_freq: 0.500045
[03:03:22.511] iteration 3323: loss: 0.484422, loss_s1: 0.499233, loss_fp: 0.030162, loss_freq: 0.013694
[03:03:23.162] iteration 3324: loss: 0.337244, loss_s1: 0.334050, loss_fp: 0.001136, loss_freq: 0.001688
[03:03:23.900] iteration 3325: loss: 0.370217, loss_s1: 0.342248, loss_fp: 0.001471, loss_freq: 0.001006
[03:03:24.541] iteration 3326: loss: 0.280699, loss_s1: 0.079403, loss_fp: 0.001993, loss_freq: 0.012036
[03:03:25.232] iteration 3327: loss: 0.391554, loss_s1: 0.345565, loss_fp: 0.006846, loss_freq: 0.032946
[03:03:25.965] iteration 3328: loss: 0.905825, loss_s1: 0.500019, loss_fp: 0.499998, loss_freq: 0.500001
[03:03:26.582] iteration 3329: loss: 0.263476, loss_s1: 0.027515, loss_fp: 0.002152, loss_freq: 0.030395
[03:03:27.309] iteration 3330: loss: 0.950584, loss_s1: 0.500039, loss_fp: 0.499998, loss_freq: 0.499993
[03:03:27.930] iteration 3331: loss: 0.201877, loss_s1: 0.102833, loss_fp: 0.001317, loss_freq: 0.001507
[03:03:28.649] iteration 3332: loss: 0.443339, loss_s1: 0.491074, loss_fp: 0.001450, loss_freq: 0.001597
[03:03:29.314] iteration 3333: loss: 0.316647, loss_s1: 0.226777, loss_fp: 0.000856, loss_freq: 0.017486
[03:03:29.951] iteration 3334: loss: 0.352155, loss_s1: 0.310770, loss_fp: 0.000529, loss_freq: 0.008725
[03:03:30.556] iteration 3335: loss: 0.221602, loss_s1: 0.082009, loss_fp: 0.000968, loss_freq: 0.002598
[03:03:31.147] iteration 3336: loss: 0.918189, loss_s1: 0.500070, loss_fp: 0.499999, loss_freq: 0.500001
[03:03:31.733] iteration 3337: loss: 0.147816, loss_s1: 0.003010, loss_fp: 0.004593, loss_freq: 0.001243
[03:03:32.378] iteration 3338: loss: 0.300203, loss_s1: 0.153161, loss_fp: 0.018641, loss_freq: 0.004493
[03:03:32.967] iteration 3339: loss: 0.913452, loss_s1: 0.500880, loss_fp: 0.499997, loss_freq: 0.500002
[03:03:33.563] iteration 3340: loss: 0.249817, loss_s1: 0.209916, loss_fp: 0.002066, loss_freq: 0.000774
[03:03:34.155] iteration 3341: loss: 0.200675, loss_s1: 0.017166, loss_fp: 0.000544, loss_freq: 0.001242
[03:03:34.746] iteration 3342: loss: 0.172390, loss_s1: 0.047484, loss_fp: 0.001074, loss_freq: 0.009945
[03:03:35.382] iteration 3343: loss: 0.168195, loss_s1: 0.017183, loss_fp: 0.000371, loss_freq: 0.000718
[03:03:35.986] iteration 3344: loss: 0.243052, loss_s1: 0.153947, loss_fp: 0.001822, loss_freq: 0.001392
[03:03:36.600] iteration 3345: loss: 0.911131, loss_s1: 0.502815, loss_fp: 0.499997, loss_freq: 0.501407
[03:03:37.205] iteration 3346: loss: 0.899856, loss_s1: 0.502484, loss_fp: 0.500000, loss_freq: 0.500762
[03:03:37.808] iteration 3347: loss: 0.157376, loss_s1: 0.053951, loss_fp: 0.005989, loss_freq: 0.001570
[03:03:38.403] iteration 3348: loss: 0.249518, loss_s1: 0.244882, loss_fp: 0.000764, loss_freq: 0.000596
[03:03:38.994] iteration 3349: loss: 0.206245, loss_s1: 0.149260, loss_fp: 0.002097, loss_freq: 0.020281
[03:03:39.586] iteration 3350: loss: 0.420168, loss_s1: 0.490621, loss_fp: 0.000762, loss_freq: 0.001080
[03:03:40.180] iteration 3351: loss: 0.269583, loss_s1: 0.212233, loss_fp: 0.000921, loss_freq: 0.001721
[03:03:40.922] iteration 3352: loss: 0.352594, loss_s1: 0.423238, loss_fp: 0.000561, loss_freq: 0.000629
[03:03:41.870] iteration 3353: loss: 0.923376, loss_s1: 0.501569, loss_fp: 0.500007, loss_freq: 0.500201
[03:03:42.817] iteration 3354: loss: 0.119118, loss_s1: 0.015127, loss_fp: 0.000777, loss_freq: 0.001189
[03:03:43.489] iteration 3355: loss: 0.157527, loss_s1: 0.033343, loss_fp: 0.005878, loss_freq: 0.005698
[03:03:44.079] iteration 3356: loss: 0.251601, loss_s1: 0.194348, loss_fp: 0.001242, loss_freq: 0.007735
[03:03:44.666] iteration 3357: loss: 0.884413, loss_s1: 0.501639, loss_fp: 0.499997, loss_freq: 0.501287
[03:03:45.254] iteration 3358: loss: 0.922175, loss_s1: 0.500592, loss_fp: 0.499987, loss_freq: 0.500068
[03:03:45.852] iteration 3359: loss: 0.150003, loss_s1: 0.015895, loss_fp: 0.000687, loss_freq: 0.000917
[03:03:46.449] iteration 3360: loss: 0.194605, loss_s1: 0.015024, loss_fp: 0.000951, loss_freq: 0.106332
[03:03:47.047] iteration 3361: loss: 0.193781, loss_s1: 0.004905, loss_fp: 0.001773, loss_freq: 0.000521
[03:03:47.638] iteration 3362: loss: 0.232742, loss_s1: 0.105658, loss_fp: 0.002203, loss_freq: 0.002387
[03:03:48.230] iteration 3363: loss: 0.299512, loss_s1: 0.341635, loss_fp: 0.001059, loss_freq: 0.000840
[03:03:48.821] iteration 3364: loss: 0.220554, loss_s1: 0.160963, loss_fp: 0.000593, loss_freq: 0.002325
[03:03:49.415] iteration 3365: loss: 0.901548, loss_s1: 0.503165, loss_fp: 0.500004, loss_freq: 0.500014
[03:03:50.001] iteration 3366: loss: 0.403563, loss_s1: 0.479627, loss_fp: 0.001965, loss_freq: 0.103593
[03:03:50.588] iteration 3367: loss: 0.294677, loss_s1: 0.144754, loss_fp: 0.000915, loss_freq: 0.001299
[03:03:51.178] iteration 3368: loss: 0.207238, loss_s1: 0.179340, loss_fp: 0.000666, loss_freq: 0.001681
[03:03:51.767] iteration 3369: loss: 0.177693, loss_s1: 0.040287, loss_fp: 0.000532, loss_freq: 0.027326
[03:03:52.359] iteration 3370: loss: 0.251537, loss_s1: 0.186414, loss_fp: 0.001906, loss_freq: 0.000525
[03:03:52.953] iteration 3371: loss: 0.183591, loss_s1: 0.056147, loss_fp: 0.000696, loss_freq: 0.000499
[03:03:53.553] iteration 3372: loss: 0.443245, loss_s1: 0.456129, loss_fp: 0.080503, loss_freq: 0.107660
[03:03:54.147] iteration 3373: loss: 0.333951, loss_s1: 0.163700, loss_fp: 0.002452, loss_freq: 0.019743
[03:03:54.736] iteration 3374: loss: 0.139568, loss_s1: 0.002983, loss_fp: 0.000967, loss_freq: 0.001614
[03:03:55.331] iteration 3375: loss: 0.305992, loss_s1: 0.242973, loss_fp: 0.000727, loss_freq: 0.001454
[03:03:55.925] iteration 3376: loss: 0.281402, loss_s1: 0.158522, loss_fp: 0.000710, loss_freq: 0.000717
[03:03:56.517] iteration 3377: loss: 0.341498, loss_s1: 0.283903, loss_fp: 0.000374, loss_freq: 0.045116
[03:03:57.114] iteration 3378: loss: 0.398534, loss_s1: 0.381712, loss_fp: 0.019646, loss_freq: 0.026509
[03:03:57.704] iteration 3379: loss: 0.243763, loss_s1: 0.111123, loss_fp: 0.015189, loss_freq: 0.062614
[03:03:58.295] iteration 3380: loss: 0.327441, loss_s1: 0.239034, loss_fp: 0.000407, loss_freq: 0.011210
[03:03:58.885] iteration 3381: loss: 0.297912, loss_s1: 0.322142, loss_fp: 0.002320, loss_freq: 0.025010
[03:03:59.477] iteration 3382: loss: 0.244178, loss_s1: 0.182208, loss_fp: 0.001245, loss_freq: 0.000450
[03:04:00.115] iteration 3383: loss: 0.469084, loss_s1: 0.500041, loss_fp: 0.002855, loss_freq: 0.109595
[03:04:00.708] iteration 3384: loss: 0.192235, loss_s1: 0.069741, loss_fp: 0.002867, loss_freq: 0.015353
[03:04:01.307] iteration 3385: loss: 0.348122, loss_s1: 0.233267, loss_fp: 0.000798, loss_freq: 0.008581
[03:04:01.900] iteration 3386: loss: 0.157868, loss_s1: 0.024378, loss_fp: 0.000830, loss_freq: 0.000823
[03:04:02.491] iteration 3387: loss: 0.225523, loss_s1: 0.074471, loss_fp: 0.000977, loss_freq: 0.013432
[03:04:03.080] iteration 3388: loss: 0.206349, loss_s1: 0.054283, loss_fp: 0.001602, loss_freq: 0.022802
[03:04:03.685] iteration 3389: loss: 0.221091, loss_s1: 0.104925, loss_fp: 0.001966, loss_freq: 0.002249
[03:04:04.284] iteration 3390: loss: 0.250436, loss_s1: 0.071514, loss_fp: 0.025042, loss_freq: 0.001966
[03:04:04.874] iteration 3391: loss: 0.200160, loss_s1: 0.018068, loss_fp: 0.000425, loss_freq: 0.004144
[03:04:05.465] iteration 3392: loss: 0.168232, loss_s1: 0.016814, loss_fp: 0.000569, loss_freq: 0.028719
[03:04:06.053] iteration 3393: loss: 0.441953, loss_s1: 0.484076, loss_fp: 0.001060, loss_freq: 0.007629
[03:04:06.646] iteration 3394: loss: 0.174765, loss_s1: 0.043307, loss_fp: 0.000499, loss_freq: 0.000581
[03:04:07.237] iteration 3395: loss: 0.247766, loss_s1: 0.179079, loss_fp: 0.000661, loss_freq: 0.001322
[03:04:07.836] iteration 3396: loss: 0.251404, loss_s1: 0.136822, loss_fp: 0.000715, loss_freq: 0.007646
[03:04:08.425] iteration 3397: loss: 0.203628, loss_s1: 0.132436, loss_fp: 0.000967, loss_freq: 0.002092
[03:04:09.011] iteration 3398: loss: 0.204745, loss_s1: 0.099718, loss_fp: 0.000625, loss_freq: 0.000491
[03:04:09.599] iteration 3399: loss: 0.275524, loss_s1: 0.211863, loss_fp: 0.000538, loss_freq: 0.000833
[03:04:10.187] iteration 3400: loss: 0.295769, loss_s1: 0.284731, loss_fp: 0.001581, loss_freq: 0.020471
[03:04:12.665] iteration 3400 : mean_dice : 0.182325
[03:04:13.701] iteration 3401: loss: 0.226053, loss_s1: 0.130487, loss_fp: 0.000414, loss_freq: 0.000468
[03:04:14.369] iteration 3402: loss: 0.127024, loss_s1: 0.022542, loss_fp: 0.000937, loss_freq: 0.000551
[03:04:15.012] iteration 3403: loss: 0.303014, loss_s1: 0.188601, loss_fp: 0.000473, loss_freq: 0.000640
[03:04:15.650] iteration 3404: loss: 0.223327, loss_s1: 0.113048, loss_fp: 0.000871, loss_freq: 0.000624
[03:04:16.310] iteration 3405: loss: 0.331798, loss_s1: 0.317241, loss_fp: 0.000657, loss_freq: 0.004572
[03:04:17.007] iteration 3406: loss: 0.295005, loss_s1: 0.164655, loss_fp: 0.000863, loss_freq: 0.022888
[03:04:17.633] iteration 3407: loss: 0.217887, loss_s1: 0.134115, loss_fp: 0.000577, loss_freq: 0.000999
[03:04:18.235] iteration 3408: loss: 0.203836, loss_s1: 0.062027, loss_fp: 0.000420, loss_freq: 0.016971
[03:04:18.880] iteration 3409: loss: 0.203309, loss_s1: 0.106420, loss_fp: 0.001124, loss_freq: 0.026636
[03:04:19.517] iteration 3410: loss: 0.291352, loss_s1: 0.218250, loss_fp: 0.000436, loss_freq: 0.006393
[03:04:20.159] iteration 3411: loss: 0.328700, loss_s1: 0.357660, loss_fp: 0.001670, loss_freq: 0.030477
[03:04:20.803] iteration 3412: loss: 0.863980, loss_s1: 0.502212, loss_fp: 0.499989, loss_freq: 0.500021
[03:04:21.448] iteration 3413: loss: 0.903287, loss_s1: 0.500950, loss_fp: 0.499998, loss_freq: 0.500009
[03:04:22.098] iteration 3414: loss: 0.220840, loss_s1: 0.132377, loss_fp: 0.000685, loss_freq: 0.001891
[03:04:22.743] iteration 3415: loss: 0.311766, loss_s1: 0.199743, loss_fp: 0.000787, loss_freq: 0.002033
[03:04:23.358] iteration 3416: loss: 0.245861, loss_s1: 0.252753, loss_fp: 0.001274, loss_freq: 0.006662
[03:04:23.951] iteration 3417: loss: 0.145570, loss_s1: 0.028289, loss_fp: 0.002456, loss_freq: 0.006792
[03:04:24.549] iteration 3418: loss: 0.151813, loss_s1: 0.055273, loss_fp: 0.000597, loss_freq: 0.000636
[03:04:25.142] iteration 3419: loss: 0.232285, loss_s1: 0.217928, loss_fp: 0.000753, loss_freq: 0.000912
[03:04:25.766] iteration 3420: loss: 0.330200, loss_s1: 0.351627, loss_fp: 0.000806, loss_freq: 0.003352
[03:04:26.402] iteration 3421: loss: 0.289641, loss_s1: 0.255436, loss_fp: 0.000633, loss_freq: 0.003106
[03:04:27.038] iteration 3422: loss: 0.310284, loss_s1: 0.299877, loss_fp: 0.000565, loss_freq: 0.000633
[03:04:27.672] iteration 3423: loss: 0.263662, loss_s1: 0.160118, loss_fp: 0.000616, loss_freq: 0.004077
[03:04:28.260] iteration 3424: loss: 0.317399, loss_s1: 0.282701, loss_fp: 0.000975, loss_freq: 0.021732
[03:04:28.851] iteration 3425: loss: 0.161280, loss_s1: 0.060287, loss_fp: 0.000577, loss_freq: 0.001147
[03:04:29.443] iteration 3426: loss: 0.311907, loss_s1: 0.318549, loss_fp: 0.000514, loss_freq: 0.002464
[03:04:30.041] iteration 3427: loss: 0.262759, loss_s1: 0.160190, loss_fp: 0.000454, loss_freq: 0.008126
[03:04:30.632] iteration 3428: loss: 0.909127, loss_s1: 0.500504, loss_fp: 0.499998, loss_freq: 0.499999
[03:04:31.227] iteration 3429: loss: 0.387552, loss_s1: 0.199572, loss_fp: 0.000742, loss_freq: 0.000847
[03:04:31.817] iteration 3430: loss: 0.386458, loss_s1: 0.445420, loss_fp: 0.000672, loss_freq: 0.000705
[03:04:32.411] iteration 3431: loss: 0.257004, loss_s1: 0.217967, loss_fp: 0.000529, loss_freq: 0.011395
[03:04:33.038] iteration 3432: loss: 0.372888, loss_s1: 0.365060, loss_fp: 0.001161, loss_freq: 0.001250
[03:04:33.676] iteration 3433: loss: 0.131372, loss_s1: 0.036534, loss_fp: 0.001520, loss_freq: 0.014084
[03:04:34.313] iteration 3434: loss: 0.172085, loss_s1: 0.055827, loss_fp: 0.000680, loss_freq: 0.007042
[03:04:34.982] iteration 3435: loss: 0.237305, loss_s1: 0.222134, loss_fp: 0.000483, loss_freq: 0.006129
[03:04:35.610] iteration 3436: loss: 0.197644, loss_s1: 0.057035, loss_fp: 0.000672, loss_freq: 0.001011
[03:04:36.246] iteration 3437: loss: 0.179153, loss_s1: 0.078729, loss_fp: 0.002102, loss_freq: 0.017429
[03:04:36.879] iteration 3438: loss: 0.240341, loss_s1: 0.162711, loss_fp: 0.002613, loss_freq: 0.005733
[03:04:37.505] iteration 3439: loss: 0.303907, loss_s1: 0.236556, loss_fp: 0.006004, loss_freq: 0.008913
[03:04:38.103] iteration 3440: loss: 0.348515, loss_s1: 0.380030, loss_fp: 0.000610, loss_freq: 0.010085
[03:04:38.696] iteration 3441: loss: 0.417268, loss_s1: 0.430812, loss_fp: 0.001113, loss_freq: 0.041200
[03:04:39.288] iteration 3442: loss: 0.150647, loss_s1: 0.073705, loss_fp: 0.000757, loss_freq: 0.005684
[03:04:39.888] iteration 3443: loss: 0.239470, loss_s1: 0.106329, loss_fp: 0.004406, loss_freq: 0.042079
[03:04:40.485] iteration 3444: loss: 0.225509, loss_s1: 0.178698, loss_fp: 0.001296, loss_freq: 0.000457
[03:04:41.083] iteration 3445: loss: 0.153788, loss_s1: 0.007582, loss_fp: 0.000645, loss_freq: 0.000604
[03:04:41.758] iteration 3446: loss: 0.295461, loss_s1: 0.320592, loss_fp: 0.000413, loss_freq: 0.000796
[03:04:42.355] iteration 3447: loss: 0.220576, loss_s1: 0.038969, loss_fp: 0.000575, loss_freq: 0.003739
[03:04:42.976] iteration 3448: loss: 0.308114, loss_s1: 0.253471, loss_fp: 0.000468, loss_freq: 0.001157
[03:04:43.569] iteration 3449: loss: 0.187594, loss_s1: 0.039505, loss_fp: 0.004405, loss_freq: 0.001071
[03:04:44.157] iteration 3450: loss: 0.321139, loss_s1: 0.202785, loss_fp: 0.001148, loss_freq: 0.024307
[03:04:44.752] iteration 3451: loss: 0.290776, loss_s1: 0.330612, loss_fp: 0.001260, loss_freq: 0.003263
[03:04:45.347] iteration 3452: loss: 0.195131, loss_s1: 0.083481, loss_fp: 0.000765, loss_freq: 0.013616
[03:04:45.939] iteration 3453: loss: 0.318199, loss_s1: 0.370428, loss_fp: 0.000761, loss_freq: 0.000964
[03:04:46.527] iteration 3454: loss: 0.264392, loss_s1: 0.277982, loss_fp: 0.001806, loss_freq: 0.002531
[03:04:47.125] iteration 3455: loss: 0.206609, loss_s1: 0.045047, loss_fp: 0.000848, loss_freq: 0.001805
[03:04:47.717] iteration 3456: loss: 0.130441, loss_s1: 0.015641, loss_fp: 0.000561, loss_freq: 0.000366
[03:04:48.306] iteration 3457: loss: 0.233325, loss_s1: 0.209012, loss_fp: 0.000796, loss_freq: 0.000870
[03:04:48.898] iteration 3458: loss: 0.338644, loss_s1: 0.294462, loss_fp: 0.000659, loss_freq: 0.002824
[03:04:49.488] iteration 3459: loss: 0.393424, loss_s1: 0.356409, loss_fp: 0.000764, loss_freq: 0.037841
[03:04:50.083] iteration 3460: loss: 0.437727, loss_s1: 0.452832, loss_fp: 0.001979, loss_freq: 0.200639
[03:04:50.702] iteration 3461: loss: 0.181910, loss_s1: 0.114442, loss_fp: 0.001886, loss_freq: 0.007346
[03:04:51.317] iteration 3462: loss: 0.315396, loss_s1: 0.167664, loss_fp: 0.002474, loss_freq: 0.015332
[03:04:51.963] iteration 3463: loss: 0.134841, loss_s1: 0.004764, loss_fp: 0.000653, loss_freq: 0.000467
[03:04:52.595] iteration 3464: loss: 0.235752, loss_s1: 0.045043, loss_fp: 0.000538, loss_freq: 0.036597
[03:04:53.200] iteration 3465: loss: 0.503521, loss_s1: 0.417325, loss_fp: 0.000526, loss_freq: 0.183972
[03:04:53.798] iteration 3466: loss: 0.260115, loss_s1: 0.219276, loss_fp: 0.000562, loss_freq: 0.009642
[03:04:54.393] iteration 3467: loss: 0.332936, loss_s1: 0.297978, loss_fp: 0.000639, loss_freq: 0.001060
[03:04:54.986] iteration 3468: loss: 0.274109, loss_s1: 0.214619, loss_fp: 0.000764, loss_freq: 0.024460
[03:04:55.583] iteration 3469: loss: 0.234887, loss_s1: 0.155453, loss_fp: 0.000512, loss_freq: 0.001118
[03:04:56.179] iteration 3470: loss: 0.233197, loss_s1: 0.178151, loss_fp: 0.000605, loss_freq: 0.010595
[03:04:56.771] iteration 3471: loss: 0.180791, loss_s1: 0.061187, loss_fp: 0.000550, loss_freq: 0.001778
[03:04:57.361] iteration 3472: loss: 0.169247, loss_s1: 0.034238, loss_fp: 0.000673, loss_freq: 0.000918
[03:04:57.953] iteration 3473: loss: 0.205078, loss_s1: 0.004519, loss_fp: 0.000453, loss_freq: 0.001601
[03:04:58.544] iteration 3474: loss: 0.387338, loss_s1: 0.440428, loss_fp: 0.000737, loss_freq: 0.007017
[03:04:59.135] iteration 3475: loss: 0.439541, loss_s1: 0.484032, loss_fp: 0.000721, loss_freq: 0.001624
[03:04:59.730] iteration 3476: loss: 0.203530, loss_s1: 0.003834, loss_fp: 0.000657, loss_freq: 0.002816
[03:05:00.321] iteration 3477: loss: 0.259120, loss_s1: 0.138861, loss_fp: 0.000722, loss_freq: 0.010422
[03:05:00.910] iteration 3478: loss: 0.274392, loss_s1: 0.013589, loss_fp: 0.000454, loss_freq: 0.001676
[03:05:01.509] iteration 3479: loss: 0.160409, loss_s1: 0.013984, loss_fp: 0.000761, loss_freq: 0.048242
[03:05:02.115] iteration 3480: loss: 0.255208, loss_s1: 0.161940, loss_fp: 0.000748, loss_freq: 0.006492
[03:05:02.703] iteration 3481: loss: 0.916013, loss_s1: 0.502961, loss_fp: 0.500004, loss_freq: 0.500544
[03:05:03.295] iteration 3482: loss: 0.298883, loss_s1: 0.144558, loss_fp: 0.001279, loss_freq: 0.172148
[03:05:03.888] iteration 3483: loss: 0.222302, loss_s1: 0.189127, loss_fp: 0.001194, loss_freq: 0.007956
[03:05:04.476] iteration 3484: loss: 0.261088, loss_s1: 0.135703, loss_fp: 0.000447, loss_freq: 0.003229
[03:05:05.071] iteration 3485: loss: 0.291448, loss_s1: 0.222127, loss_fp: 0.000629, loss_freq: 0.024318
[03:05:05.656] iteration 3486: loss: 0.379367, loss_s1: 0.451810, loss_fp: 0.000534, loss_freq: 0.018237
[03:05:06.252] iteration 3487: loss: 0.234715, loss_s1: 0.187553, loss_fp: 0.001147, loss_freq: 0.003785
[03:05:07.090] iteration 3488: loss: 0.216017, loss_s1: 0.110842, loss_fp: 0.000713, loss_freq: 0.014467
[03:05:07.728] iteration 3489: loss: 0.466308, loss_s1: 0.486327, loss_fp: 0.110437, loss_freq: 0.033873
[03:05:08.322] iteration 3490: loss: 0.355366, loss_s1: 0.388951, loss_fp: 0.000935, loss_freq: 0.022634
[03:05:09.011] iteration 3491: loss: 0.255688, loss_s1: 0.156201, loss_fp: 0.000670, loss_freq: 0.061315
[03:05:09.598] iteration 3492: loss: 0.359403, loss_s1: 0.255925, loss_fp: 0.001193, loss_freq: 0.178935
[03:05:10.186] iteration 3493: loss: 0.258624, loss_s1: 0.166611, loss_fp: 0.001565, loss_freq: 0.001473
[03:05:10.807] iteration 3494: loss: 0.199457, loss_s1: 0.106020, loss_fp: 0.000641, loss_freq: 0.001113
[03:05:11.395] iteration 3495: loss: 0.305527, loss_s1: 0.343533, loss_fp: 0.000574, loss_freq: 0.003695
[03:05:11.983] iteration 3496: loss: 0.282295, loss_s1: 0.230816, loss_fp: 0.000505, loss_freq: 0.052155
[03:05:12.578] iteration 3497: loss: 0.289576, loss_s1: 0.205866, loss_fp: 0.000993, loss_freq: 0.001083
[03:05:13.170] iteration 3498: loss: 0.913947, loss_s1: 0.501160, loss_fp: 0.499997, loss_freq: 0.500441
[03:05:13.763] iteration 3499: loss: 0.237449, loss_s1: 0.137749, loss_fp: 0.000651, loss_freq: 0.005023
[03:05:14.358] iteration 3500: loss: 0.158493, loss_s1: 0.048844, loss_fp: 0.000561, loss_freq: 0.005856
[03:05:14.951] iteration 3501: loss: 0.237188, loss_s1: 0.117030, loss_fp: 0.000610, loss_freq: 0.040700
[03:05:15.547] iteration 3502: loss: 0.200849, loss_s1: 0.028442, loss_fp: 0.000754, loss_freq: 0.001779
[03:05:16.139] iteration 3503: loss: 0.176015, loss_s1: 0.042764, loss_fp: 0.000437, loss_freq: 0.000733
[03:05:16.733] iteration 3504: loss: 0.275897, loss_s1: 0.193115, loss_fp: 0.000557, loss_freq: 0.011487
[03:05:17.325] iteration 3505: loss: 0.184140, loss_s1: 0.030799, loss_fp: 0.000497, loss_freq: 0.004479
[03:05:17.912] iteration 3506: loss: 0.267905, loss_s1: 0.239118, loss_fp: 0.000559, loss_freq: 0.003066
[03:05:18.501] iteration 3507: loss: 0.156740, loss_s1: 0.043137, loss_fp: 0.000662, loss_freq: 0.004681
[03:05:19.093] iteration 3508: loss: 0.149519, loss_s1: 0.064002, loss_fp: 0.000419, loss_freq: 0.002048
[03:05:19.682] iteration 3509: loss: 0.890384, loss_s1: 0.503814, loss_fp: 0.499991, loss_freq: 0.500946
[03:05:20.276] iteration 3510: loss: 0.172700, loss_s1: 0.044021, loss_fp: 0.000561, loss_freq: 0.004734
[03:05:20.867] iteration 3511: loss: 0.394898, loss_s1: 0.432458, loss_fp: 0.001754, loss_freq: 0.059130
[03:05:21.456] iteration 3512: loss: 0.204478, loss_s1: 0.155617, loss_fp: 0.001295, loss_freq: 0.004739
[03:05:22.098] iteration 3513: loss: 0.212059, loss_s1: 0.100390, loss_fp: 0.000602, loss_freq: 0.015092
[03:05:22.731] iteration 3514: loss: 0.168485, loss_s1: 0.077933, loss_fp: 0.002087, loss_freq: 0.002714
[03:05:23.365] iteration 3515: loss: 0.695734, loss_s1: 0.482705, loss_fp: 0.001705, loss_freq: 0.482918
[03:05:24.002] iteration 3516: loss: 0.887569, loss_s1: 0.501050, loss_fp: 0.500004, loss_freq: 0.500603
[03:05:24.614] iteration 3517: loss: 0.192752, loss_s1: 0.130472, loss_fp: 0.000984, loss_freq: 0.009861
[03:05:25.207] iteration 3518: loss: 0.180291, loss_s1: 0.123511, loss_fp: 0.000440, loss_freq: 0.000693
[03:05:25.797] iteration 3519: loss: 0.397835, loss_s1: 0.392306, loss_fp: 0.007015, loss_freq: 0.144921
[03:05:26.391] iteration 3520: loss: 0.147843, loss_s1: 0.001678, loss_fp: 0.002768, loss_freq: 0.004285
[03:05:26.984] iteration 3521: loss: 0.203470, loss_s1: 0.134235, loss_fp: 0.000593, loss_freq: 0.005894
[03:05:27.581] iteration 3522: loss: 0.131737, loss_s1: 0.050697, loss_fp: 0.000644, loss_freq: 0.004879
[03:05:28.175] iteration 3523: loss: 0.450489, loss_s1: 0.399762, loss_fp: 0.001721, loss_freq: 0.178742
[03:05:28.839] iteration 3524: loss: 0.156332, loss_s1: 0.079718, loss_fp: 0.000887, loss_freq: 0.003864
[03:05:29.479] iteration 3525: loss: 0.277225, loss_s1: 0.270309, loss_fp: 0.000773, loss_freq: 0.001465
[03:05:30.072] iteration 3526: loss: 0.254941, loss_s1: 0.151433, loss_fp: 0.000549, loss_freq: 0.006173
[03:05:30.668] iteration 3527: loss: 0.875461, loss_s1: 0.501098, loss_fp: 0.500001, loss_freq: 0.500488
[03:05:31.261] iteration 3528: loss: 0.328497, loss_s1: 0.193545, loss_fp: 0.000688, loss_freq: 0.052658
[03:05:31.853] iteration 3529: loss: 0.223982, loss_s1: 0.187017, loss_fp: 0.000645, loss_freq: 0.001877
[03:05:32.457] iteration 3530: loss: 0.437084, loss_s1: 0.488694, loss_fp: 0.002091, loss_freq: 0.153992
[03:05:33.056] iteration 3531: loss: 0.184643, loss_s1: 0.050368, loss_fp: 0.001098, loss_freq: 0.000612
[03:05:33.653] iteration 3532: loss: 0.315638, loss_s1: 0.249951, loss_fp: 0.000563, loss_freq: 0.019970
[03:05:34.253] iteration 3533: loss: 0.330807, loss_s1: 0.385745, loss_fp: 0.001483, loss_freq: 0.000667
[03:05:34.847] iteration 3534: loss: 0.391742, loss_s1: 0.385689, loss_fp: 0.002269, loss_freq: 0.011233
[03:05:35.442] iteration 3535: loss: 0.454797, loss_s1: 0.430179, loss_fp: 0.008499, loss_freq: 0.129941
[03:05:36.076] iteration 3536: loss: 0.212726, loss_s1: 0.103853, loss_fp: 0.000604, loss_freq: 0.050874
[03:05:36.667] iteration 3537: loss: 0.314016, loss_s1: 0.200759, loss_fp: 0.000605, loss_freq: 0.022225
[03:05:37.255] iteration 3538: loss: 0.151076, loss_s1: 0.063453, loss_fp: 0.000611, loss_freq: 0.010597
[03:05:37.855] iteration 3539: loss: 0.199400, loss_s1: 0.106021, loss_fp: 0.000543, loss_freq: 0.021701
[03:05:38.449] iteration 3540: loss: 0.234747, loss_s1: 0.022995, loss_fp: 0.001332, loss_freq: 0.159099
[03:05:39.047] iteration 3541: loss: 0.196929, loss_s1: 0.028438, loss_fp: 0.000753, loss_freq: 0.039223
[03:05:39.636] iteration 3542: loss: 0.347084, loss_s1: 0.338739, loss_fp: 0.003063, loss_freq: 0.005548
[03:05:40.234] iteration 3543: loss: 0.207258, loss_s1: 0.086245, loss_fp: 0.000614, loss_freq: 0.003250
[03:05:40.829] iteration 3544: loss: 0.288394, loss_s1: 0.224407, loss_fp: 0.000831, loss_freq: 0.016107
[03:05:41.430] iteration 3545: loss: 0.226787, loss_s1: 0.076596, loss_fp: 0.000872, loss_freq: 0.030948
[03:05:42.015] iteration 3546: loss: 0.153288, loss_s1: 0.002522, loss_fp: 0.007183, loss_freq: 0.000875
[03:05:42.602] iteration 3547: loss: 0.171757, loss_s1: 0.040990, loss_fp: 0.000443, loss_freq: 0.005271
[03:05:43.219] iteration 3548: loss: 0.244616, loss_s1: 0.102723, loss_fp: 0.000738, loss_freq: 0.006157
[03:05:43.889] iteration 3549: loss: 0.167098, loss_s1: 0.061288, loss_fp: 0.000480, loss_freq: 0.005204
[03:05:44.488] iteration 3550: loss: 0.263235, loss_s1: 0.196742, loss_fp: 0.000543, loss_freq: 0.014557
[03:05:45.095] iteration 3551: loss: 0.208744, loss_s1: 0.135323, loss_fp: 0.000886, loss_freq: 0.001054
[03:05:45.729] iteration 3552: loss: 0.271234, loss_s1: 0.334249, loss_fp: 0.000799, loss_freq: 0.001183
[03:05:46.399] iteration 3553: loss: 0.414480, loss_s1: 0.364535, loss_fp: 0.001451, loss_freq: 0.129736
[03:05:47.020] iteration 3554: loss: 0.299621, loss_s1: 0.223771, loss_fp: 0.000487, loss_freq: 0.004736
[03:05:47.628] iteration 3555: loss: 0.246805, loss_s1: 0.129136, loss_fp: 0.000841, loss_freq: 0.063128
[03:05:48.257] iteration 3556: loss: 0.212117, loss_s1: 0.181816, loss_fp: 0.001499, loss_freq: 0.006238
[03:05:48.892] iteration 3557: loss: 0.182173, loss_s1: 0.115153, loss_fp: 0.000825, loss_freq: 0.014420
[03:05:49.506] iteration 3558: loss: 0.198269, loss_s1: 0.129173, loss_fp: 0.000458, loss_freq: 0.003002
[03:05:50.126] iteration 3559: loss: 0.251047, loss_s1: 0.302819, loss_fp: 0.000771, loss_freq: 0.008579
[03:05:50.748] iteration 3560: loss: 0.268804, loss_s1: 0.198465, loss_fp: 0.004925, loss_freq: 0.012773
[03:05:51.350] iteration 3561: loss: 0.223805, loss_s1: 0.119890, loss_fp: 0.001041, loss_freq: 0.003612
[03:05:51.955] iteration 3562: loss: 0.128096, loss_s1: 0.054053, loss_fp: 0.000682, loss_freq: 0.001035
[03:05:52.565] iteration 3563: loss: 0.289505, loss_s1: 0.180881, loss_fp: 0.000881, loss_freq: 0.021008
[03:05:53.154] iteration 3564: loss: 0.275061, loss_s1: 0.275306, loss_fp: 0.000683, loss_freq: 0.000720
[03:05:53.741] iteration 3565: loss: 0.251697, loss_s1: 0.257201, loss_fp: 0.001011, loss_freq: 0.005206
[03:05:54.332] iteration 3566: loss: 0.214668, loss_s1: 0.120114, loss_fp: 0.000458, loss_freq: 0.024032
[03:05:54.932] iteration 3567: loss: 0.154008, loss_s1: 0.053120, loss_fp: 0.000884, loss_freq: 0.048770
[03:05:55.528] iteration 3568: loss: 0.283874, loss_s1: 0.336607, loss_fp: 0.000690, loss_freq: 0.000512
[03:05:56.113] iteration 3569: loss: 0.320065, loss_s1: 0.369244, loss_fp: 0.001479, loss_freq: 0.003550
[03:05:56.700] iteration 3570: loss: 0.228841, loss_s1: 0.186050, loss_fp: 0.000780, loss_freq: 0.049923
[03:05:57.655] iteration 3571: loss: 0.199856, loss_s1: 0.058425, loss_fp: 0.000633, loss_freq: 0.005797
[03:05:58.289] iteration 3572: loss: 0.136236, loss_s1: 0.018032, loss_fp: 0.000523, loss_freq: 0.003543
[03:05:58.923] iteration 3573: loss: 0.162154, loss_s1: 0.012118, loss_fp: 0.000430, loss_freq: 0.000514
[03:05:59.520] iteration 3574: loss: 0.262492, loss_s1: 0.205027, loss_fp: 0.000850, loss_freq: 0.000901
[03:06:00.123] iteration 3575: loss: 0.268381, loss_s1: 0.165822, loss_fp: 0.000537, loss_freq: 0.012152
[03:06:00.712] iteration 3576: loss: 0.249372, loss_s1: 0.093550, loss_fp: 0.000886, loss_freq: 0.042661
[03:06:01.295] iteration 3577: loss: 0.159437, loss_s1: 0.055856, loss_fp: 0.000470, loss_freq: 0.005388
[03:06:01.879] iteration 3578: loss: 0.237630, loss_s1: 0.115976, loss_fp: 0.000551, loss_freq: 0.020825
[03:06:02.462] iteration 3579: loss: 0.354702, loss_s1: 0.316483, loss_fp: 0.000867, loss_freq: 0.100204
[03:06:03.048] iteration 3580: loss: 0.176505, loss_s1: 0.048351, loss_fp: 0.000528, loss_freq: 0.006416
[03:06:03.723] iteration 3581: loss: 0.177745, loss_s1: 0.041039, loss_fp: 0.001305, loss_freq: 0.029666
[03:06:04.354] iteration 3582: loss: 0.296237, loss_s1: 0.277824, loss_fp: 0.000869, loss_freq: 0.076949
[03:06:04.984] iteration 3583: loss: 0.314638, loss_s1: 0.255206, loss_fp: 0.001310, loss_freq: 0.101779
[03:06:05.608] iteration 3584: loss: 0.148109, loss_s1: 0.024326, loss_fp: 0.000663, loss_freq: 0.012758
[03:06:06.233] iteration 3585: loss: 0.210396, loss_s1: 0.071834, loss_fp: 0.000778, loss_freq: 0.000841
[03:06:06.860] iteration 3586: loss: 0.164272, loss_s1: 0.082836, loss_fp: 0.000843, loss_freq: 0.006283
[03:06:07.457] iteration 3587: loss: 0.288116, loss_s1: 0.291184, loss_fp: 0.005624, loss_freq: 0.061786
[03:06:08.047] iteration 3588: loss: 0.237525, loss_s1: 0.129903, loss_fp: 0.001967, loss_freq: 0.003103
[03:06:08.641] iteration 3589: loss: 0.192625, loss_s1: 0.139936, loss_fp: 0.000685, loss_freq: 0.020694
[03:06:09.287] iteration 3590: loss: 0.260501, loss_s1: 0.166220, loss_fp: 0.000601, loss_freq: 0.018815
[03:06:09.891] iteration 3591: loss: 0.197169, loss_s1: 0.138496, loss_fp: 0.088702, loss_freq: 0.008467
[03:06:10.533] iteration 3592: loss: 0.193310, loss_s1: 0.127509, loss_fp: 0.000669, loss_freq: 0.003075
[03:06:11.181] iteration 3593: loss: 0.212733, loss_s1: 0.029908, loss_fp: 0.000572, loss_freq: 0.003561
[03:06:11.789] iteration 3594: loss: 0.151329, loss_s1: 0.080773, loss_fp: 0.001035, loss_freq: 0.002029
[03:06:12.384] iteration 3595: loss: 0.110897, loss_s1: 0.026173, loss_fp: 0.000390, loss_freq: 0.001279
[03:06:12.971] iteration 3596: loss: 0.254197, loss_s1: 0.140505, loss_fp: 0.000590, loss_freq: 0.000823
[03:06:13.564] iteration 3597: loss: 0.175721, loss_s1: 0.093912, loss_fp: 0.000588, loss_freq: 0.003417
[03:06:14.165] iteration 3598: loss: 0.274138, loss_s1: 0.277002, loss_fp: 0.001319, loss_freq: 0.016503
[03:06:14.763] iteration 3599: loss: 0.364256, loss_s1: 0.169544, loss_fp: 0.000685, loss_freq: 0.004108
[03:06:15.360] iteration 3600: loss: 0.213504, loss_s1: 0.176078, loss_fp: 0.000948, loss_freq: 0.001246
[03:06:17.943] iteration 3600 : mean_dice : 0.191029
[03:06:18.611] iteration 3601: loss: 0.183527, loss_s1: 0.169228, loss_fp: 0.000703, loss_freq: 0.005054
[03:06:19.252] iteration 3602: loss: 0.230683, loss_s1: 0.135531, loss_fp: 0.000839, loss_freq: 0.003532
[03:06:19.894] iteration 3603: loss: 0.171730, loss_s1: 0.067022, loss_fp: 0.000507, loss_freq: 0.013787
[03:06:20.526] iteration 3604: loss: 0.251495, loss_s1: 0.213616, loss_fp: 0.000464, loss_freq: 0.001512
[03:06:21.151] iteration 3605: loss: 0.191801, loss_s1: 0.152433, loss_fp: 0.000768, loss_freq: 0.006354
[03:06:21.783] iteration 3606: loss: 0.165114, loss_s1: 0.019511, loss_fp: 0.000803, loss_freq: 0.001384
[03:06:22.419] iteration 3607: loss: 0.461438, loss_s1: 0.493380, loss_fp: 0.035697, loss_freq: 0.192380
[03:06:23.039] iteration 3608: loss: 0.240116, loss_s1: 0.212590, loss_fp: 0.000379, loss_freq: 0.006329
[03:06:23.639] iteration 3609: loss: 0.144056, loss_s1: 0.018973, loss_fp: 0.001124, loss_freq: 0.004984
[03:06:24.268] iteration 3610: loss: 0.189789, loss_s1: 0.085821, loss_fp: 0.006803, loss_freq: 0.012876
[03:06:24.917] iteration 3611: loss: 0.336550, loss_s1: 0.413299, loss_fp: 0.000721, loss_freq: 0.003308
[03:06:25.551] iteration 3612: loss: 0.218633, loss_s1: 0.188373, loss_fp: 0.000645, loss_freq: 0.020122
[03:06:26.188] iteration 3613: loss: 0.246117, loss_s1: 0.168568, loss_fp: 0.004109, loss_freq: 0.038166
[03:06:26.798] iteration 3614: loss: 0.211088, loss_s1: 0.135108, loss_fp: 0.001524, loss_freq: 0.012002
[03:06:27.397] iteration 3615: loss: 0.241387, loss_s1: 0.219625, loss_fp: 0.000372, loss_freq: 0.008988
[03:06:27.992] iteration 3616: loss: 0.223185, loss_s1: 0.205606, loss_fp: 0.000747, loss_freq: 0.000841
[03:06:28.593] iteration 3617: loss: 0.167198, loss_s1: 0.080769, loss_fp: 0.001168, loss_freq: 0.009801
[03:06:29.209] iteration 3618: loss: 0.165930, loss_s1: 0.069101, loss_fp: 0.000253, loss_freq: 0.000415
[03:06:29.870] iteration 3619: loss: 0.152213, loss_s1: 0.049797, loss_fp: 0.000564, loss_freq: 0.000828
[03:06:30.472] iteration 3620: loss: 0.252834, loss_s1: 0.179194, loss_fp: 0.000906, loss_freq: 0.054944
[03:06:31.066] iteration 3621: loss: 0.422464, loss_s1: 0.360815, loss_fp: 0.001262, loss_freq: 0.275006
[03:06:31.657] iteration 3622: loss: 0.364915, loss_s1: 0.429050, loss_fp: 0.000974, loss_freq: 0.025797
[03:06:32.253] iteration 3623: loss: 0.372780, loss_s1: 0.369606, loss_fp: 0.000447, loss_freq: 0.084590
[03:06:32.851] iteration 3624: loss: 0.257296, loss_s1: 0.166617, loss_fp: 0.000948, loss_freq: 0.071254
[03:06:33.447] iteration 3625: loss: 0.318919, loss_s1: 0.201945, loss_fp: 0.000809, loss_freq: 0.028995
[03:06:34.072] iteration 3626: loss: 0.323651, loss_s1: 0.075588, loss_fp: 0.001295, loss_freq: 0.013251
[03:06:34.672] iteration 3627: loss: 0.256448, loss_s1: 0.229595, loss_fp: 0.000520, loss_freq: 0.000845
[03:06:35.270] iteration 3628: loss: 0.335103, loss_s1: 0.187404, loss_fp: 0.000583, loss_freq: 0.100411
[03:06:35.865] iteration 3629: loss: 0.404698, loss_s1: 0.193819, loss_fp: 0.000725, loss_freq: 0.058948
[03:06:36.455] iteration 3630: loss: 0.264745, loss_s1: 0.014161, loss_fp: 0.021956, loss_freq: 0.210902
[03:06:37.047] iteration 3631: loss: 0.276068, loss_s1: 0.210415, loss_fp: 0.000891, loss_freq: 0.029771
[03:06:37.641] iteration 3632: loss: 0.353541, loss_s1: 0.329538, loss_fp: 0.009103, loss_freq: 0.045054
[03:06:38.241] iteration 3633: loss: 0.180311, loss_s1: 0.114105, loss_fp: 0.000642, loss_freq: 0.001830
[03:06:38.836] iteration 3634: loss: 0.267143, loss_s1: 0.183441, loss_fp: 0.001101, loss_freq: 0.014630
[03:06:39.438] iteration 3635: loss: 0.212990, loss_s1: 0.180577, loss_fp: 0.000705, loss_freq: 0.015069
[03:06:40.027] iteration 3636: loss: 0.158898, loss_s1: 0.076656, loss_fp: 0.000614, loss_freq: 0.025920
[03:06:40.612] iteration 3637: loss: 0.183392, loss_s1: 0.013949, loss_fp: 0.001012, loss_freq: 0.001850
[03:06:41.208] iteration 3638: loss: 0.179528, loss_s1: 0.096236, loss_fp: 0.002016, loss_freq: 0.027062
[03:06:41.862] iteration 3639: loss: 0.265070, loss_s1: 0.231326, loss_fp: 0.001633, loss_freq: 0.015430
[03:06:42.494] iteration 3640: loss: 0.209357, loss_s1: 0.091373, loss_fp: 0.000536, loss_freq: 0.008167
[03:06:43.124] iteration 3641: loss: 0.229050, loss_s1: 0.141262, loss_fp: 0.000656, loss_freq: 0.028735
[03:06:43.729] iteration 3642: loss: 0.147706, loss_s1: 0.077364, loss_fp: 0.000577, loss_freq: 0.004121
[03:06:44.321] iteration 3643: loss: 0.189744, loss_s1: 0.134030, loss_fp: 0.000780, loss_freq: 0.013003
[03:06:44.906] iteration 3644: loss: 0.336327, loss_s1: 0.326391, loss_fp: 0.001252, loss_freq: 0.110100
[03:06:45.495] iteration 3645: loss: 0.358913, loss_s1: 0.407533, loss_fp: 0.000632, loss_freq: 0.005460
[03:06:46.085] iteration 3646: loss: 0.258847, loss_s1: 0.201733, loss_fp: 0.006276, loss_freq: 0.042297
[03:06:46.675] iteration 3647: loss: 0.223230, loss_s1: 0.167717, loss_fp: 0.000550, loss_freq: 0.002821
[03:06:47.269] iteration 3648: loss: 0.228991, loss_s1: 0.118620, loss_fp: 0.000872, loss_freq: 0.058631
[03:06:47.860] iteration 3649: loss: 0.201065, loss_s1: 0.089650, loss_fp: 0.000793, loss_freq: 0.047153
[03:06:48.453] iteration 3650: loss: 0.222358, loss_s1: 0.107889, loss_fp: 0.000616, loss_freq: 0.025600
[03:06:49.114] iteration 3651: loss: 0.358481, loss_s1: 0.324811, loss_fp: 0.003870, loss_freq: 0.146411
[03:06:49.746] iteration 3652: loss: 0.195875, loss_s1: 0.133408, loss_fp: 0.000989, loss_freq: 0.008511
[03:06:50.340] iteration 3653: loss: 0.253115, loss_s1: 0.223607, loss_fp: 0.001489, loss_freq: 0.005173
[03:06:50.935] iteration 3654: loss: 0.203929, loss_s1: 0.057898, loss_fp: 0.001405, loss_freq: 0.003746
[03:06:51.530] iteration 3655: loss: 0.276554, loss_s1: 0.148843, loss_fp: 0.000623, loss_freq: 0.007793
[03:06:52.185] iteration 3656: loss: 0.242577, loss_s1: 0.202179, loss_fp: 0.000962, loss_freq: 0.031010
[03:06:52.823] iteration 3657: loss: 0.096793, loss_s1: 0.014521, loss_fp: 0.000659, loss_freq: 0.002416
[03:06:53.459] iteration 3658: loss: 0.280105, loss_s1: 0.110552, loss_fp: 0.000497, loss_freq: 0.007203
[03:06:54.094] iteration 3659: loss: 0.284885, loss_s1: 0.222162, loss_fp: 0.001874, loss_freq: 0.060067
[03:06:54.705] iteration 3660: loss: 0.155563, loss_s1: 0.028580, loss_fp: 0.000925, loss_freq: 0.042502
[03:06:55.302] iteration 3661: loss: 0.162386, loss_s1: 0.079195, loss_fp: 0.005160, loss_freq: 0.006204
[03:06:55.896] iteration 3662: loss: 0.152598, loss_s1: 0.117498, loss_fp: 0.001604, loss_freq: 0.002642
[03:06:56.492] iteration 3663: loss: 0.181919, loss_s1: 0.051934, loss_fp: 0.006438, loss_freq: 0.002568
[03:06:57.131] iteration 3664: loss: 0.195271, loss_s1: 0.088077, loss_fp: 0.000696, loss_freq: 0.000538
[03:06:57.728] iteration 3665: loss: 0.217435, loss_s1: 0.227704, loss_fp: 0.000938, loss_freq: 0.010747
[03:06:58.320] iteration 3666: loss: 0.221890, loss_s1: 0.082055, loss_fp: 0.001033, loss_freq: 0.013804
[03:06:58.914] iteration 3667: loss: 0.200566, loss_s1: 0.142834, loss_fp: 0.001014, loss_freq: 0.011933
[03:06:59.506] iteration 3668: loss: 0.449765, loss_s1: 0.490691, loss_fp: 0.011997, loss_freq: 0.181364
[03:07:00.097] iteration 3669: loss: 0.327234, loss_s1: 0.316018, loss_fp: 0.000882, loss_freq: 0.008191
[03:07:00.692] iteration 3670: loss: 0.252812, loss_s1: 0.285148, loss_fp: 0.000527, loss_freq: 0.000665
[03:07:01.280] iteration 3671: loss: 0.223696, loss_s1: 0.166640, loss_fp: 0.000423, loss_freq: 0.008655
[03:07:01.878] iteration 3672: loss: 0.204836, loss_s1: 0.082588, loss_fp: 0.000820, loss_freq: 0.002012
[03:07:02.480] iteration 3673: loss: 0.223815, loss_s1: 0.166725, loss_fp: 0.000700, loss_freq: 0.008977
[03:07:03.072] iteration 3674: loss: 0.233462, loss_s1: 0.070482, loss_fp: 0.000540, loss_freq: 0.006576
[03:07:03.664] iteration 3675: loss: 0.219877, loss_s1: 0.074956, loss_fp: 0.002320, loss_freq: 0.002189
[03:07:04.258] iteration 3676: loss: 0.213727, loss_s1: 0.175941, loss_fp: 0.000563, loss_freq: 0.002696
[03:07:04.841] iteration 3677: loss: 0.198068, loss_s1: 0.199730, loss_fp: 0.000812, loss_freq: 0.014383
[03:07:05.434] iteration 3678: loss: 0.167223, loss_s1: 0.080772, loss_fp: 0.000420, loss_freq: 0.004253
[03:07:06.025] iteration 3679: loss: 0.859378, loss_s1: 0.500899, loss_fp: 0.499986, loss_freq: 0.500084
[03:07:06.615] iteration 3680: loss: 0.204870, loss_s1: 0.112006, loss_fp: 0.000606, loss_freq: 0.009386
[03:07:07.215] iteration 3681: loss: 0.236076, loss_s1: 0.170847, loss_fp: 0.000602, loss_freq: 0.003982
[03:07:07.852] iteration 3682: loss: 0.183786, loss_s1: 0.113006, loss_fp: 0.000592, loss_freq: 0.002296
[03:07:08.484] iteration 3683: loss: 0.214670, loss_s1: 0.094100, loss_fp: 0.000378, loss_freq: 0.009432
[03:07:09.119] iteration 3684: loss: 0.230004, loss_s1: 0.167240, loss_fp: 0.000656, loss_freq: 0.006585
[03:07:09.754] iteration 3685: loss: 0.879095, loss_s1: 0.502844, loss_fp: 0.500007, loss_freq: 0.503431
[03:07:10.392] iteration 3686: loss: 0.389938, loss_s1: 0.372888, loss_fp: 0.000798, loss_freq: 0.170202
[03:07:11.025] iteration 3687: loss: 0.267929, loss_s1: 0.200336, loss_fp: 0.003823, loss_freq: 0.009792
[03:07:11.929] iteration 3688: loss: 0.221010, loss_s1: 0.191059, loss_fp: 0.000361, loss_freq: 0.000879
[03:07:12.605] iteration 3689: loss: 0.395939, loss_s1: 0.485487, loss_fp: 0.000741, loss_freq: 0.029341
[03:07:13.209] iteration 3690: loss: 0.321814, loss_s1: 0.096311, loss_fp: 0.000732, loss_freq: 0.002640
[03:07:13.883] iteration 3691: loss: 0.245790, loss_s1: 0.181675, loss_fp: 0.005730, loss_freq: 0.021949
[03:07:14.473] iteration 3692: loss: 0.160380, loss_s1: 0.109152, loss_fp: 0.001055, loss_freq: 0.022262
[03:07:15.100] iteration 3693: loss: 0.290302, loss_s1: 0.313998, loss_fp: 0.003655, loss_freq: 0.016636
[03:07:15.734] iteration 3694: loss: 0.177285, loss_s1: 0.171191, loss_fp: 0.001917, loss_freq: 0.007482
[03:07:16.359] iteration 3695: loss: 0.213071, loss_s1: 0.104312, loss_fp: 0.001379, loss_freq: 0.004535
[03:07:16.947] iteration 3696: loss: 0.182792, loss_s1: 0.205277, loss_fp: 0.006614, loss_freq: 0.000496
[03:07:17.545] iteration 3697: loss: 0.751232, loss_s1: 0.469744, loss_fp: 0.283998, loss_freq: 0.491319
[03:07:18.145] iteration 3698: loss: 0.403084, loss_s1: 0.358884, loss_fp: 0.000971, loss_freq: 0.030642
[03:07:18.734] iteration 3699: loss: 0.130804, loss_s1: 0.054079, loss_fp: 0.000383, loss_freq: 0.005369
[03:07:19.325] iteration 3700: loss: 0.620823, loss_s1: 0.500603, loss_fp: 0.024142, loss_freq: 0.492263
[03:07:19.914] iteration 3701: loss: 0.317093, loss_s1: 0.346428, loss_fp: 0.001263, loss_freq: 0.046184
[03:07:20.508] iteration 3702: loss: 0.291642, loss_s1: 0.225386, loss_fp: 0.001623, loss_freq: 0.022494
[03:07:21.126] iteration 3703: loss: 0.299262, loss_s1: 0.336267, loss_fp: 0.000548, loss_freq: 0.000824
[03:07:21.717] iteration 3704: loss: 0.258572, loss_s1: 0.188651, loss_fp: 0.000392, loss_freq: 0.004543
[03:07:22.309] iteration 3705: loss: 0.302690, loss_s1: 0.385433, loss_fp: 0.001660, loss_freq: 0.009553
[03:07:22.940] iteration 3706: loss: 0.324940, loss_s1: 0.340262, loss_fp: 0.001117, loss_freq: 0.007520
[03:07:23.580] iteration 3707: loss: 0.315193, loss_s1: 0.272306, loss_fp: 0.000823, loss_freq: 0.005264
[03:07:24.206] iteration 3708: loss: 0.158324, loss_s1: 0.067103, loss_fp: 0.000395, loss_freq: 0.003610
[03:07:24.790] iteration 3709: loss: 0.258884, loss_s1: 0.138303, loss_fp: 0.001118, loss_freq: 0.050761
[03:07:25.379] iteration 3710: loss: 0.259820, loss_s1: 0.141614, loss_fp: 0.000790, loss_freq: 0.030400
[03:07:25.964] iteration 3711: loss: 0.206396, loss_s1: 0.051593, loss_fp: 0.001184, loss_freq: 0.020115
[03:07:26.561] iteration 3712: loss: 0.238639, loss_s1: 0.177135, loss_fp: 0.000893, loss_freq: 0.020588
[03:07:27.152] iteration 3713: loss: 0.170903, loss_s1: 0.056492, loss_fp: 0.000472, loss_freq: 0.006037
[03:07:27.749] iteration 3714: loss: 0.226710, loss_s1: 0.182179, loss_fp: 0.000835, loss_freq: 0.007205
[03:07:28.339] iteration 3715: loss: 0.244171, loss_s1: 0.187544, loss_fp: 0.000637, loss_freq: 0.039061
[03:07:28.931] iteration 3716: loss: 0.168289, loss_s1: 0.070771, loss_fp: 0.001698, loss_freq: 0.016568
[03:07:29.524] iteration 3717: loss: 0.155958, loss_s1: 0.010196, loss_fp: 0.000354, loss_freq: 0.013903
[03:07:30.118] iteration 3718: loss: 0.176801, loss_s1: 0.059063, loss_fp: 0.000498, loss_freq: 0.057893
[03:07:30.713] iteration 3719: loss: 0.195235, loss_s1: 0.045422, loss_fp: 0.000714, loss_freq: 0.054619
[03:07:31.311] iteration 3720: loss: 0.222845, loss_s1: 0.129549, loss_fp: 0.000833, loss_freq: 0.021403
[03:07:31.904] iteration 3721: loss: 0.157464, loss_s1: 0.106193, loss_fp: 0.000785, loss_freq: 0.005093
[03:07:32.502] iteration 3722: loss: 0.163971, loss_s1: 0.023290, loss_fp: 0.001733, loss_freq: 0.023771
[03:07:33.094] iteration 3723: loss: 0.200414, loss_s1: 0.140711, loss_fp: 0.000673, loss_freq: 0.018035
[03:07:33.687] iteration 3724: loss: 0.137536, loss_s1: 0.036670, loss_fp: 0.005528, loss_freq: 0.004688
[03:07:34.284] iteration 3725: loss: 0.247552, loss_s1: 0.105659, loss_fp: 0.000689, loss_freq: 0.069775
[03:07:34.879] iteration 3726: loss: 0.278331, loss_s1: 0.334210, loss_fp: 0.000494, loss_freq: 0.005254
[03:07:35.475] iteration 3727: loss: 0.121277, loss_s1: 0.038917, loss_fp: 0.000317, loss_freq: 0.001579
[03:07:36.087] iteration 3728: loss: 0.180681, loss_s1: 0.045565, loss_fp: 0.000263, loss_freq: 0.001746
[03:07:36.692] iteration 3729: loss: 0.157650, loss_s1: 0.091901, loss_fp: 0.000997, loss_freq: 0.023176
[03:07:37.298] iteration 3730: loss: 0.248129, loss_s1: 0.145513, loss_fp: 0.000509, loss_freq: 0.002702
[03:07:37.905] iteration 3731: loss: 0.202566, loss_s1: 0.126845, loss_fp: 0.002557, loss_freq: 0.014592
[03:07:38.505] iteration 3732: loss: 0.183512, loss_s1: 0.135596, loss_fp: 0.000569, loss_freq: 0.004514
[03:07:39.104] iteration 3733: loss: 0.221172, loss_s1: 0.048857, loss_fp: 0.000441, loss_freq: 0.039805
[03:07:39.715] iteration 3734: loss: 0.260394, loss_s1: 0.284630, loss_fp: 0.000483, loss_freq: 0.001424
[03:07:40.331] iteration 3735: loss: 0.139623, loss_s1: 0.025546, loss_fp: 0.000420, loss_freq: 0.009544
[03:07:40.936] iteration 3736: loss: 0.280163, loss_s1: 0.343312, loss_fp: 0.001536, loss_freq: 0.024756
[03:07:41.592] iteration 3737: loss: 0.237523, loss_s1: 0.159195, loss_fp: 0.001005, loss_freq: 0.033430
[03:07:42.388] iteration 3738: loss: 0.127163, loss_s1: 0.029150, loss_fp: 0.000531, loss_freq: 0.000358
[03:07:43.084] iteration 3739: loss: 0.173806, loss_s1: 0.071079, loss_fp: 0.000768, loss_freq: 0.005549
[03:07:43.735] iteration 3740: loss: 0.222057, loss_s1: 0.257442, loss_fp: 0.001300, loss_freq: 0.029944
[03:07:44.707] iteration 3741: loss: 0.211358, loss_s1: 0.198876, loss_fp: 0.000711, loss_freq: 0.002432
[03:07:45.301] iteration 3742: loss: 0.112261, loss_s1: 0.001797, loss_fp: 0.001156, loss_freq: 0.012516
[03:07:46.000] iteration 3743: loss: 0.154683, loss_s1: 0.061275, loss_fp: 0.000504, loss_freq: 0.031042
[03:07:46.684] iteration 3744: loss: 0.163757, loss_s1: 0.086463, loss_fp: 0.007061, loss_freq: 0.015962
[03:07:47.349] iteration 3745: loss: 0.161523, loss_s1: 0.065237, loss_fp: 0.000379, loss_freq: 0.006468
[03:07:48.095] iteration 3746: loss: 0.207098, loss_s1: 0.130797, loss_fp: 0.000692, loss_freq: 0.035031
[03:07:48.728] iteration 3747: loss: 0.192456, loss_s1: 0.179634, loss_fp: 0.000686, loss_freq: 0.006614
[03:07:49.348] iteration 3748: loss: 0.189077, loss_s1: 0.066892, loss_fp: 0.002078, loss_freq: 0.036140
[03:07:49.979] iteration 3749: loss: 0.252921, loss_s1: 0.132271, loss_fp: 0.000638, loss_freq: 0.023108
[03:07:50.677] iteration 3750: loss: 0.232508, loss_s1: 0.172396, loss_fp: 0.000848, loss_freq: 0.024459
[03:07:51.451] iteration 3751: loss: 0.204497, loss_s1: 0.101640, loss_fp: 0.000451, loss_freq: 0.075883
[03:07:52.119] iteration 3752: loss: 0.226425, loss_s1: 0.140172, loss_fp: 0.001907, loss_freq: 0.096571
[03:07:52.733] iteration 3753: loss: 0.290144, loss_s1: 0.200624, loss_fp: 0.000930, loss_freq: 0.158535
[03:07:53.336] iteration 3754: loss: 0.245691, loss_s1: 0.124210, loss_fp: 0.000709, loss_freq: 0.054948
[03:07:53.928] iteration 3755: loss: 0.253293, loss_s1: 0.071852, loss_fp: 0.000772, loss_freq: 0.013356
[03:07:54.521] iteration 3756: loss: 0.189439, loss_s1: 0.153061, loss_fp: 0.004463, loss_freq: 0.011319
[03:07:55.110] iteration 3757: loss: 0.185797, loss_s1: 0.154426, loss_fp: 0.005151, loss_freq: 0.008252
[03:07:55.736] iteration 3758: loss: 0.158967, loss_s1: 0.063560, loss_fp: 0.000555, loss_freq: 0.026437
[03:07:56.333] iteration 3759: loss: 0.143581, loss_s1: 0.068867, loss_fp: 0.001813, loss_freq: 0.053866
[03:07:56.921] iteration 3760: loss: 0.157599, loss_s1: 0.092560, loss_fp: 0.000606, loss_freq: 0.005395
[03:07:57.518] iteration 3761: loss: 0.245234, loss_s1: 0.283290, loss_fp: 0.001342, loss_freq: 0.029963
[03:07:58.107] iteration 3762: loss: 0.232771, loss_s1: 0.274979, loss_fp: 0.001090, loss_freq: 0.001743
[03:07:58.707] iteration 3763: loss: 0.246530, loss_s1: 0.115445, loss_fp: 0.000589, loss_freq: 0.035480
[03:07:59.302] iteration 3764: loss: 0.236769, loss_s1: 0.156423, loss_fp: 0.000450, loss_freq: 0.003721
[03:07:59.891] iteration 3765: loss: 0.132964, loss_s1: 0.054807, loss_fp: 0.000550, loss_freq: 0.001252
[03:08:00.477] iteration 3766: loss: 0.155490, loss_s1: 0.126003, loss_fp: 0.005937, loss_freq: 0.013592
[03:08:01.068] iteration 3767: loss: 0.145690, loss_s1: 0.025818, loss_fp: 0.000631, loss_freq: 0.012079
[03:08:01.674] iteration 3768: loss: 0.223016, loss_s1: 0.130704, loss_fp: 0.000789, loss_freq: 0.090116
[03:08:02.267] iteration 3769: loss: 0.277471, loss_s1: 0.101555, loss_fp: 0.000561, loss_freq: 0.006845
[03:08:02.855] iteration 3770: loss: 0.278212, loss_s1: 0.322248, loss_fp: 0.000690, loss_freq: 0.001219
[03:08:03.443] iteration 3771: loss: 0.226881, loss_s1: 0.218883, loss_fp: 0.012869, loss_freq: 0.021872
[03:08:04.027] iteration 3772: loss: 0.318476, loss_s1: 0.209001, loss_fp: 0.000695, loss_freq: 0.011494
[03:08:04.615] iteration 3773: loss: 0.151291, loss_s1: 0.067952, loss_fp: 0.004733, loss_freq: 0.015343
[03:08:05.266] iteration 3774: loss: 0.162305, loss_s1: 0.131739, loss_fp: 0.000388, loss_freq: 0.002894
[03:08:05.893] iteration 3775: loss: 0.236807, loss_s1: 0.169771, loss_fp: 0.020087, loss_freq: 0.052993
[03:08:06.789] iteration 3776: loss: 0.171657, loss_s1: 0.053043, loss_fp: 0.000603, loss_freq: 0.014360
[03:08:07.596] iteration 3777: loss: 0.140140, loss_s1: 0.100958, loss_fp: 0.005700, loss_freq: 0.002548
[03:08:08.341] iteration 3778: loss: 0.145728, loss_s1: 0.063972, loss_fp: 0.000414, loss_freq: 0.005741
[03:08:08.994] iteration 3779: loss: 0.202145, loss_s1: 0.153704, loss_fp: 0.000683, loss_freq: 0.009733
[03:08:09.602] iteration 3780: loss: 0.281996, loss_s1: 0.218120, loss_fp: 0.001331, loss_freq: 0.033924
[03:08:10.229] iteration 3781: loss: 0.270086, loss_s1: 0.299356, loss_fp: 0.000715, loss_freq: 0.004515
[03:08:10.819] iteration 3782: loss: 0.217385, loss_s1: 0.253839, loss_fp: 0.000880, loss_freq: 0.011423
[03:08:11.416] iteration 3783: loss: 0.172432, loss_s1: 0.107782, loss_fp: 0.000587, loss_freq: 0.023908
[03:08:12.010] iteration 3784: loss: 0.250844, loss_s1: 0.289326, loss_fp: 0.001031, loss_freq: 0.008350
[03:08:12.603] iteration 3785: loss: 0.152622, loss_s1: 0.050965, loss_fp: 0.000456, loss_freq: 0.016450
[03:08:13.193] iteration 3786: loss: 0.150641, loss_s1: 0.051826, loss_fp: 0.004344, loss_freq: 0.012622
[03:08:13.788] iteration 3787: loss: 0.202465, loss_s1: 0.210352, loss_fp: 0.000872, loss_freq: 0.001769
[03:08:14.386] iteration 3788: loss: 0.171610, loss_s1: 0.068542, loss_fp: 0.000699, loss_freq: 0.005254
[03:08:14.976] iteration 3789: loss: 0.173362, loss_s1: 0.077198, loss_fp: 0.000339, loss_freq: 0.002512
[03:08:15.631] iteration 3790: loss: 0.215374, loss_s1: 0.182655, loss_fp: 0.000439, loss_freq: 0.044538
[03:08:16.265] iteration 3791: loss: 0.357708, loss_s1: 0.407836, loss_fp: 0.023783, loss_freq: 0.109055
[03:08:16.854] iteration 3792: loss: 0.184621, loss_s1: 0.152063, loss_fp: 0.000556, loss_freq: 0.009002
[03:08:17.446] iteration 3793: loss: 0.171646, loss_s1: 0.101315, loss_fp: 0.000783, loss_freq: 0.012569
[03:08:18.031] iteration 3794: loss: 0.161250, loss_s1: 0.124685, loss_fp: 0.000887, loss_freq: 0.021012
[03:08:18.622] iteration 3795: loss: 0.278649, loss_s1: 0.224468, loss_fp: 0.000624, loss_freq: 0.026164
[03:08:19.216] iteration 3796: loss: 0.121140, loss_s1: 0.018004, loss_fp: 0.001219, loss_freq: 0.005276
[03:08:19.806] iteration 3797: loss: 0.210767, loss_s1: 0.158761, loss_fp: 0.000880, loss_freq: 0.015276
[03:08:20.402] iteration 3798: loss: 0.313499, loss_s1: 0.234559, loss_fp: 0.000786, loss_freq: 0.094654
[03:08:20.986] iteration 3799: loss: 0.188970, loss_s1: 0.074817, loss_fp: 0.000439, loss_freq: 0.009257
[03:08:21.581] iteration 3800: loss: 0.196025, loss_s1: 0.151107, loss_fp: 0.000924, loss_freq: 0.066699
[03:08:24.322] iteration 3800 : mean_dice : 0.306856
[03:08:24.936] iteration 3801: loss: 0.182618, loss_s1: 0.064516, loss_fp: 0.002004, loss_freq: 0.009108
[03:08:25.530] iteration 3802: loss: 0.239886, loss_s1: 0.184857, loss_fp: 0.001195, loss_freq: 0.002240
[03:08:26.129] iteration 3803: loss: 0.205179, loss_s1: 0.212101, loss_fp: 0.000823, loss_freq: 0.018431
[03:08:26.714] iteration 3804: loss: 0.234654, loss_s1: 0.121973, loss_fp: 0.001020, loss_freq: 0.042151
[03:08:27.306] iteration 3805: loss: 0.283955, loss_s1: 0.232822, loss_fp: 0.000652, loss_freq: 0.024047
[03:08:27.900] iteration 3806: loss: 0.184840, loss_s1: 0.107947, loss_fp: 0.001884, loss_freq: 0.029052
[03:08:28.528] iteration 3807: loss: 0.278384, loss_s1: 0.088375, loss_fp: 0.000397, loss_freq: 0.006601
[03:08:29.159] iteration 3808: loss: 0.220550, loss_s1: 0.177608, loss_fp: 0.002169, loss_freq: 0.069640
[03:08:29.797] iteration 3809: loss: 0.177097, loss_s1: 0.069423, loss_fp: 0.000658, loss_freq: 0.010670
[03:08:30.397] iteration 3810: loss: 0.124632, loss_s1: 0.067720, loss_fp: 0.000397, loss_freq: 0.003569
[03:08:31.020] iteration 3811: loss: 0.214516, loss_s1: 0.143263, loss_fp: 0.000407, loss_freq: 0.034538
[03:08:31.629] iteration 3812: loss: 0.122127, loss_s1: 0.061049, loss_fp: 0.000615, loss_freq: 0.002752
[03:08:32.225] iteration 3813: loss: 0.235994, loss_s1: 0.222707, loss_fp: 0.003569, loss_freq: 0.027242
[03:08:32.820] iteration 3814: loss: 0.207539, loss_s1: 0.181595, loss_fp: 0.000718, loss_freq: 0.049043
[03:08:33.414] iteration 3815: loss: 0.230973, loss_s1: 0.073291, loss_fp: 0.000882, loss_freq: 0.088692
[03:08:34.008] iteration 3816: loss: 0.202178, loss_s1: 0.056227, loss_fp: 0.000895, loss_freq: 0.031571
[03:08:34.677] iteration 3817: loss: 0.172629, loss_s1: 0.145143, loss_fp: 0.001206, loss_freq: 0.027394
[03:08:35.315] iteration 3818: loss: 0.206153, loss_s1: 0.055834, loss_fp: 0.000636, loss_freq: 0.012185
[03:08:35.914] iteration 3819: loss: 0.211273, loss_s1: 0.183083, loss_fp: 0.004184, loss_freq: 0.045249
[03:08:36.508] iteration 3820: loss: 0.194591, loss_s1: 0.114409, loss_fp: 0.001681, loss_freq: 0.042348
[03:08:37.100] iteration 3821: loss: 0.389362, loss_s1: 0.213498, loss_fp: 0.001976, loss_freq: 0.299457
[03:08:37.693] iteration 3822: loss: 0.151210, loss_s1: 0.111137, loss_fp: 0.000560, loss_freq: 0.024806
[03:08:38.288] iteration 3823: loss: 0.150397, loss_s1: 0.068441, loss_fp: 0.003108, loss_freq: 0.008627
[03:08:38.931] iteration 3824: loss: 0.175142, loss_s1: 0.103104, loss_fp: 0.000567, loss_freq: 0.004379
[03:08:39.558] iteration 3825: loss: 0.204227, loss_s1: 0.119212, loss_fp: 0.000730, loss_freq: 0.002295
[03:08:40.266] iteration 3826: loss: 0.178361, loss_s1: 0.131752, loss_fp: 0.000570, loss_freq: 0.072694
[03:08:40.967] iteration 3827: loss: 0.253688, loss_s1: 0.155342, loss_fp: 0.000708, loss_freq: 0.042916
[03:08:41.648] iteration 3828: loss: 0.184873, loss_s1: 0.061095, loss_fp: 0.003425, loss_freq: 0.042129
[03:08:42.343] iteration 3829: loss: 0.202725, loss_s1: 0.207342, loss_fp: 0.000957, loss_freq: 0.039640
[03:08:42.981] iteration 3830: loss: 0.315106, loss_s1: 0.336151, loss_fp: 0.000698, loss_freq: 0.015177
[03:08:43.731] iteration 3831: loss: 0.205788, loss_s1: 0.168716, loss_fp: 0.000538, loss_freq: 0.025436
[03:08:44.371] iteration 3832: loss: 0.214895, loss_s1: 0.159585, loss_fp: 0.000631, loss_freq: 0.032222
[03:08:45.083] iteration 3833: loss: 0.237908, loss_s1: 0.223348, loss_fp: 0.000402, loss_freq: 0.002458
[03:08:45.835] iteration 3834: loss: 0.116843, loss_s1: 0.019753, loss_fp: 0.000447, loss_freq: 0.001570
[03:08:46.501] iteration 3835: loss: 0.138378, loss_s1: 0.020841, loss_fp: 0.000516, loss_freq: 0.007800
[03:08:47.145] iteration 3836: loss: 0.193491, loss_s1: 0.115281, loss_fp: 0.003621, loss_freq: 0.025862
[03:08:47.781] iteration 3837: loss: 0.184842, loss_s1: 0.123407, loss_fp: 0.000788, loss_freq: 0.023520
[03:08:48.493] iteration 3838: loss: 0.351676, loss_s1: 0.358597, loss_fp: 0.001289, loss_freq: 0.146835
[03:08:49.156] iteration 3839: loss: 0.193519, loss_s1: 0.077346, loss_fp: 0.001134, loss_freq: 0.035867
[03:08:49.788] iteration 3840: loss: 0.166525, loss_s1: 0.082386, loss_fp: 0.000765, loss_freq: 0.018723
[03:08:50.412] iteration 3841: loss: 0.246373, loss_s1: 0.126703, loss_fp: 0.000809, loss_freq: 0.026379
[03:08:51.000] iteration 3842: loss: 0.240771, loss_s1: 0.076229, loss_fp: 0.000593, loss_freq: 0.013220
[03:08:51.594] iteration 3843: loss: 0.178431, loss_s1: 0.077267, loss_fp: 0.000556, loss_freq: 0.002909
[03:08:52.183] iteration 3844: loss: 0.169470, loss_s1: 0.057680, loss_fp: 0.000932, loss_freq: 0.015815
[03:08:52.773] iteration 3845: loss: 0.171738, loss_s1: 0.046500, loss_fp: 0.001195, loss_freq: 0.005928
[03:08:53.361] iteration 3846: loss: 0.258645, loss_s1: 0.114070, loss_fp: 0.000673, loss_freq: 0.002630
[03:08:53.953] iteration 3847: loss: 0.201098, loss_s1: 0.162823, loss_fp: 0.000580, loss_freq: 0.015139
[03:08:54.545] iteration 3848: loss: 0.221710, loss_s1: 0.244195, loss_fp: 0.000543, loss_freq: 0.022306
[03:08:55.135] iteration 3849: loss: 0.479485, loss_s1: 0.434110, loss_fp: 0.000876, loss_freq: 0.271601
[03:08:55.728] iteration 3850: loss: 0.221220, loss_s1: 0.111757, loss_fp: 0.000419, loss_freq: 0.015044
[03:08:56.323] iteration 3851: loss: 0.273711, loss_s1: 0.212896, loss_fp: 0.000708, loss_freq: 0.005444
[03:08:56.908] iteration 3852: loss: 0.187959, loss_s1: 0.177930, loss_fp: 0.000626, loss_freq: 0.008283
[03:08:57.500] iteration 3853: loss: 0.234346, loss_s1: 0.195400, loss_fp: 0.000638, loss_freq: 0.015711
[03:08:58.108] iteration 3854: loss: 0.252825, loss_s1: 0.229616, loss_fp: 0.001262, loss_freq: 0.023552
[03:08:58.717] iteration 3855: loss: 0.319426, loss_s1: 0.288525, loss_fp: 0.011261, loss_freq: 0.059736
[03:08:59.328] iteration 3856: loss: 0.234618, loss_s1: 0.177740, loss_fp: 0.000565, loss_freq: 0.019010
[03:08:59.989] iteration 3857: loss: 0.155209, loss_s1: 0.088673, loss_fp: 0.000612, loss_freq: 0.028527
[03:09:00.620] iteration 3858: loss: 0.136849, loss_s1: 0.068584, loss_fp: 0.004068, loss_freq: 0.003696
[03:09:01.246] iteration 3859: loss: 0.248033, loss_s1: 0.164831, loss_fp: 0.000574, loss_freq: 0.044549
[03:09:01.878] iteration 3860: loss: 0.200994, loss_s1: 0.118873, loss_fp: 0.000490, loss_freq: 0.022512
[03:09:02.498] iteration 3861: loss: 0.127377, loss_s1: 0.075238, loss_fp: 0.000366, loss_freq: 0.005576
[03:09:03.191] iteration 3862: loss: 0.172064, loss_s1: 0.107373, loss_fp: 0.000927, loss_freq: 0.020477
[03:09:03.879] iteration 3863: loss: 0.228847, loss_s1: 0.190551, loss_fp: 0.003438, loss_freq: 0.055600
[03:09:04.630] iteration 3864: loss: 0.154154, loss_s1: 0.111343, loss_fp: 0.003715, loss_freq: 0.005765
[03:09:05.216] iteration 3865: loss: 0.279668, loss_s1: 0.276813, loss_fp: 0.001710, loss_freq: 0.007874
[03:09:05.808] iteration 3866: loss: 0.179812, loss_s1: 0.109054, loss_fp: 0.002430, loss_freq: 0.023807
[03:09:06.396] iteration 3867: loss: 0.258465, loss_s1: 0.134177, loss_fp: 0.001159, loss_freq: 0.153490
[03:09:06.980] iteration 3868: loss: 0.260616, loss_s1: 0.132055, loss_fp: 0.001035, loss_freq: 0.040332
[03:09:07.562] iteration 3869: loss: 0.114357, loss_s1: 0.025614, loss_fp: 0.000402, loss_freq: 0.002184
[03:09:08.150] iteration 3870: loss: 0.194844, loss_s1: 0.190606, loss_fp: 0.000581, loss_freq: 0.006639
[03:09:08.735] iteration 3871: loss: 0.225370, loss_s1: 0.139848, loss_fp: 0.000927, loss_freq: 0.105566
[03:09:09.323] iteration 3872: loss: 0.289234, loss_s1: 0.106514, loss_fp: 0.000699, loss_freq: 0.048596
[03:09:09.911] iteration 3873: loss: 0.149585, loss_s1: 0.051159, loss_fp: 0.002483, loss_freq: 0.000916
[03:09:10.503] iteration 3874: loss: 0.276699, loss_s1: 0.172315, loss_fp: 0.000780, loss_freq: 0.030423
[03:09:11.094] iteration 3875: loss: 0.281489, loss_s1: 0.218290, loss_fp: 0.001070, loss_freq: 0.156918
[03:09:11.686] iteration 3876: loss: 0.140466, loss_s1: 0.057528, loss_fp: 0.000721, loss_freq: 0.050168
[03:09:12.331] iteration 3877: loss: 0.277380, loss_s1: 0.083332, loss_fp: 0.000768, loss_freq: 0.018652
[03:09:12.949] iteration 3878: loss: 0.161267, loss_s1: 0.138447, loss_fp: 0.000407, loss_freq: 0.008846
[03:09:13.544] iteration 3879: loss: 0.320080, loss_s1: 0.270741, loss_fp: 0.000574, loss_freq: 0.065210
[03:09:14.134] iteration 3880: loss: 0.189068, loss_s1: 0.131907, loss_fp: 0.002303, loss_freq: 0.044574
[03:09:14.724] iteration 3881: loss: 0.179139, loss_s1: 0.081032, loss_fp: 0.001256, loss_freq: 0.037205
[03:09:15.313] iteration 3882: loss: 0.104996, loss_s1: 0.021160, loss_fp: 0.001283, loss_freq: 0.004858
[03:09:15.906] iteration 3883: loss: 0.213427, loss_s1: 0.231171, loss_fp: 0.001012, loss_freq: 0.005350
[03:09:16.516] iteration 3884: loss: 0.188695, loss_s1: 0.180358, loss_fp: 0.000558, loss_freq: 0.022635
[03:09:17.199] iteration 3885: loss: 0.190989, loss_s1: 0.097080, loss_fp: 0.000424, loss_freq: 0.041854
[03:09:17.844] iteration 3886: loss: 0.159720, loss_s1: 0.073236, loss_fp: 0.000610, loss_freq: 0.004149
[03:09:18.502] iteration 3887: loss: 0.197089, loss_s1: 0.132649, loss_fp: 0.000486, loss_freq: 0.032142
[03:09:19.143] iteration 3888: loss: 0.241289, loss_s1: 0.172972, loss_fp: 0.002556, loss_freq: 0.079734
[03:09:19.759] iteration 3889: loss: 0.243148, loss_s1: 0.247398, loss_fp: 0.001056, loss_freq: 0.019493
[03:09:20.360] iteration 3890: loss: 0.182034, loss_s1: 0.135665, loss_fp: 0.000722, loss_freq: 0.013828
[03:09:20.945] iteration 3891: loss: 0.208424, loss_s1: 0.181619, loss_fp: 0.002958, loss_freq: 0.020452
[03:09:21.535] iteration 3892: loss: 0.429087, loss_s1: 0.227255, loss_fp: 0.272310, loss_freq: 0.184399
[03:09:22.133] iteration 3893: loss: 0.178163, loss_s1: 0.151634, loss_fp: 0.001297, loss_freq: 0.028615
[03:09:22.724] iteration 3894: loss: 0.175352, loss_s1: 0.057258, loss_fp: 0.000738, loss_freq: 0.009166
[03:09:23.373] iteration 3895: loss: 0.295748, loss_s1: 0.206443, loss_fp: 0.000799, loss_freq: 0.022331
[03:09:23.962] iteration 3896: loss: 0.241770, loss_s1: 0.193643, loss_fp: 0.000835, loss_freq: 0.017246
[03:09:24.545] iteration 3897: loss: 0.194642, loss_s1: 0.044158, loss_fp: 0.000474, loss_freq: 0.013747
[03:09:25.133] iteration 3898: loss: 0.143671, loss_s1: 0.054929, loss_fp: 0.000663, loss_freq: 0.004285
[03:09:25.775] iteration 3899: loss: 0.206800, loss_s1: 0.155089, loss_fp: 0.000591, loss_freq: 0.020065
[03:09:26.415] iteration 3900: loss: 0.241234, loss_s1: 0.186222, loss_fp: 0.003127, loss_freq: 0.029084
[03:09:26.997] iteration 3901: loss: 0.114352, loss_s1: 0.011177, loss_fp: 0.000454, loss_freq: 0.001441
[03:09:27.583] iteration 3902: loss: 0.173032, loss_s1: 0.063265, loss_fp: 0.000543, loss_freq: 0.010578
[03:09:28.171] iteration 3903: loss: 0.228715, loss_s1: 0.139056, loss_fp: 0.000480, loss_freq: 0.015229
[03:09:28.755] iteration 3904: loss: 0.180588, loss_s1: 0.113722, loss_fp: 0.000607, loss_freq: 0.002702
[03:09:29.345] iteration 3905: loss: 0.116045, loss_s1: 0.061608, loss_fp: 0.000671, loss_freq: 0.013942
[03:09:29.933] iteration 3906: loss: 0.292562, loss_s1: 0.203246, loss_fp: 0.001141, loss_freq: 0.051375
[03:09:30.526] iteration 3907: loss: 0.161825, loss_s1: 0.056312, loss_fp: 0.000479, loss_freq: 0.070957
[03:09:31.126] iteration 3908: loss: 0.140478, loss_s1: 0.080814, loss_fp: 0.000668, loss_freq: 0.001948
[03:09:31.713] iteration 3909: loss: 0.168443, loss_s1: 0.055908, loss_fp: 0.004212, loss_freq: 0.004765
[03:09:32.299] iteration 3910: loss: 0.146449, loss_s1: 0.112107, loss_fp: 0.000644, loss_freq: 0.022679
[03:09:33.241] iteration 3911: loss: 0.164382, loss_s1: 0.077603, loss_fp: 0.000731, loss_freq: 0.010817
[03:09:33.867] iteration 3912: loss: 0.116802, loss_s1: 0.034515, loss_fp: 0.000542, loss_freq: 0.003143
[03:09:34.496] iteration 3913: loss: 0.164817, loss_s1: 0.098545, loss_fp: 0.000829, loss_freq: 0.020527
[03:09:35.088] iteration 3914: loss: 0.206415, loss_s1: 0.068494, loss_fp: 0.001189, loss_freq: 0.036134
[03:09:35.678] iteration 3915: loss: 0.158635, loss_s1: 0.074101, loss_fp: 0.000332, loss_freq: 0.013819
[03:09:36.266] iteration 3916: loss: 0.237629, loss_s1: 0.124739, loss_fp: 0.014519, loss_freq: 0.014421
[03:09:36.904] iteration 3917: loss: 0.107781, loss_s1: 0.065318, loss_fp: 0.000661, loss_freq: 0.006555
[03:09:37.535] iteration 3918: loss: 0.164417, loss_s1: 0.063348, loss_fp: 0.000452, loss_freq: 0.017806
[03:09:38.171] iteration 3919: loss: 0.193191, loss_s1: 0.045697, loss_fp: 0.000439, loss_freq: 0.043181
[03:09:38.802] iteration 3920: loss: 0.152605, loss_s1: 0.050367, loss_fp: 0.004889, loss_freq: 0.021706
[03:09:39.406] iteration 3921: loss: 0.178955, loss_s1: 0.048548, loss_fp: 0.000628, loss_freq: 0.048808
[03:09:40.000] iteration 3922: loss: 0.152252, loss_s1: 0.112257, loss_fp: 0.000773, loss_freq: 0.027506
[03:09:40.593] iteration 3923: loss: 0.156093, loss_s1: 0.062697, loss_fp: 0.000729, loss_freq: 0.045267
[03:09:41.183] iteration 3924: loss: 0.196790, loss_s1: 0.130102, loss_fp: 0.001004, loss_freq: 0.021775
[03:09:41.772] iteration 3925: loss: 0.212156, loss_s1: 0.140742, loss_fp: 0.000489, loss_freq: 0.006950
[03:09:42.364] iteration 3926: loss: 0.150188, loss_s1: 0.102485, loss_fp: 0.001806, loss_freq: 0.004069
[03:09:42.950] iteration 3927: loss: 0.222607, loss_s1: 0.150034, loss_fp: 0.008226, loss_freq: 0.095646
[03:09:43.537] iteration 3928: loss: 0.183096, loss_s1: 0.070343, loss_fp: 0.000420, loss_freq: 0.003252
[03:09:44.130] iteration 3929: loss: 0.098734, loss_s1: 0.031534, loss_fp: 0.000710, loss_freq: 0.013215
[03:09:44.715] iteration 3930: loss: 0.168750, loss_s1: 0.134307, loss_fp: 0.000937, loss_freq: 0.032366
[03:09:45.340] iteration 3931: loss: 0.211250, loss_s1: 0.179788, loss_fp: 0.000529, loss_freq: 0.015875
[03:09:45.927] iteration 3932: loss: 0.121917, loss_s1: 0.025787, loss_fp: 0.005687, loss_freq: 0.001401
[03:09:46.512] iteration 3933: loss: 0.164431, loss_s1: 0.078477, loss_fp: 0.000659, loss_freq: 0.006095
[03:09:47.094] iteration 3934: loss: 0.132085, loss_s1: 0.080293, loss_fp: 0.000805, loss_freq: 0.008774
[03:09:47.681] iteration 3935: loss: 0.139815, loss_s1: 0.079280, loss_fp: 0.000530, loss_freq: 0.004558
[03:09:48.265] iteration 3936: loss: 0.144941, loss_s1: 0.115573, loss_fp: 0.000544, loss_freq: 0.010992
[03:09:48.852] iteration 3937: loss: 0.134792, loss_s1: 0.033764, loss_fp: 0.001884, loss_freq: 0.005181
[03:09:49.439] iteration 3938: loss: 0.345890, loss_s1: 0.302527, loss_fp: 0.001553, loss_freq: 0.223149
[03:09:50.035] iteration 3939: loss: 0.200131, loss_s1: 0.052910, loss_fp: 0.001115, loss_freq: 0.016793
[03:09:50.631] iteration 3940: loss: 0.130948, loss_s1: 0.086201, loss_fp: 0.000814, loss_freq: 0.028992
[03:09:51.230] iteration 3941: loss: 0.136091, loss_s1: 0.108556, loss_fp: 0.000768, loss_freq: 0.013133
[03:09:51.825] iteration 3942: loss: 0.240363, loss_s1: 0.132058, loss_fp: 0.001052, loss_freq: 0.021652
[03:09:52.427] iteration 3943: loss: 0.208420, loss_s1: 0.215946, loss_fp: 0.000645, loss_freq: 0.021885
[03:09:53.016] iteration 3944: loss: 0.117001, loss_s1: 0.073206, loss_fp: 0.001850, loss_freq: 0.008124
[03:09:53.607] iteration 3945: loss: 0.103818, loss_s1: 0.034867, loss_fp: 0.001951, loss_freq: 0.012921
[03:09:54.238] iteration 3946: loss: 0.168799, loss_s1: 0.088179, loss_fp: 0.000712, loss_freq: 0.009882
[03:09:54.831] iteration 3947: loss: 0.164479, loss_s1: 0.120106, loss_fp: 0.001189, loss_freq: 0.018804
[03:09:55.472] iteration 3948: loss: 0.187945, loss_s1: 0.177064, loss_fp: 0.000485, loss_freq: 0.016857
[03:09:56.106] iteration 3949: loss: 0.200765, loss_s1: 0.221337, loss_fp: 0.000822, loss_freq: 0.022127
[03:09:56.742] iteration 3950: loss: 0.265130, loss_s1: 0.282380, loss_fp: 0.003266, loss_freq: 0.069948
[03:09:57.405] iteration 3951: loss: 0.344009, loss_s1: 0.271131, loss_fp: 0.001016, loss_freq: 0.194853
[03:09:58.035] iteration 3952: loss: 0.191096, loss_s1: 0.143814, loss_fp: 0.000996, loss_freq: 0.028885
[03:09:58.667] iteration 3953: loss: 0.163612, loss_s1: 0.115009, loss_fp: 0.000725, loss_freq: 0.029284
[03:09:59.297] iteration 3954: loss: 0.154909, loss_s1: 0.072730, loss_fp: 0.002052, loss_freq: 0.029425
[03:09:59.909] iteration 3955: loss: 0.132178, loss_s1: 0.032423, loss_fp: 0.003523, loss_freq: 0.015048
[03:10:00.533] iteration 3956: loss: 0.117615, loss_s1: 0.066373, loss_fp: 0.000481, loss_freq: 0.003687
[03:10:01.126] iteration 3957: loss: 0.118999, loss_s1: 0.079681, loss_fp: 0.002881, loss_freq: 0.014555
[03:10:01.715] iteration 3958: loss: 0.122041, loss_s1: 0.095724, loss_fp: 0.000901, loss_freq: 0.001577
[03:10:02.309] iteration 3959: loss: 0.161832, loss_s1: 0.028557, loss_fp: 0.000859, loss_freq: 0.003030
[03:10:02.898] iteration 3960: loss: 0.289551, loss_s1: 0.325300, loss_fp: 0.000575, loss_freq: 0.021739
[03:10:03.485] iteration 3961: loss: 0.218884, loss_s1: 0.256060, loss_fp: 0.000828, loss_freq: 0.032934
[03:10:04.074] iteration 3962: loss: 0.124975, loss_s1: 0.070391, loss_fp: 0.000613, loss_freq: 0.018561
[03:10:04.669] iteration 3963: loss: 0.233842, loss_s1: 0.209464, loss_fp: 0.000721, loss_freq: 0.049699
[03:10:05.259] iteration 3964: loss: 0.294803, loss_s1: 0.338332, loss_fp: 0.016336, loss_freq: 0.078693
[03:10:05.844] iteration 3965: loss: 0.160337, loss_s1: 0.045451, loss_fp: 0.000632, loss_freq: 0.046170
[03:10:06.465] iteration 3966: loss: 0.184816, loss_s1: 0.182718, loss_fp: 0.000795, loss_freq: 0.011595
[03:10:07.052] iteration 3967: loss: 0.168176, loss_s1: 0.187011, loss_fp: 0.000567, loss_freq: 0.013367
[03:10:07.640] iteration 3968: loss: 0.343065, loss_s1: 0.296627, loss_fp: 0.000842, loss_freq: 0.116962
[03:10:08.227] iteration 3969: loss: 0.285731, loss_s1: 0.235956, loss_fp: 0.002816, loss_freq: 0.030975
[03:10:08.815] iteration 3970: loss: 0.242779, loss_s1: 0.189611, loss_fp: 0.011867, loss_freq: 0.098474
[03:10:09.404] iteration 3971: loss: 0.164823, loss_s1: 0.148128, loss_fp: 0.001364, loss_freq: 0.018904
[03:10:10.040] iteration 3972: loss: 0.203049, loss_s1: 0.065693, loss_fp: 0.017844, loss_freq: 0.045529
[03:10:10.634] iteration 3973: loss: 0.143233, loss_s1: 0.097943, loss_fp: 0.000641, loss_freq: 0.025171
[03:10:11.287] iteration 3974: loss: 0.206156, loss_s1: 0.066065, loss_fp: 0.001390, loss_freq: 0.032633
[03:10:11.922] iteration 3975: loss: 0.228246, loss_s1: 0.278964, loss_fp: 0.003107, loss_freq: 0.016336
[03:10:12.558] iteration 3976: loss: 0.121790, loss_s1: 0.040490, loss_fp: 0.000929, loss_freq: 0.018045
[03:10:13.185] iteration 3977: loss: 0.207677, loss_s1: 0.071631, loss_fp: 0.000578, loss_freq: 0.010987
[03:10:13.788] iteration 3978: loss: 0.160471, loss_s1: 0.029120, loss_fp: 0.001843, loss_freq: 0.064276
[03:10:14.383] iteration 3979: loss: 0.174526, loss_s1: 0.050499, loss_fp: 0.000402, loss_freq: 0.015273
[03:10:14.974] iteration 3980: loss: 0.157555, loss_s1: 0.068553, loss_fp: 0.000462, loss_freq: 0.022114
[03:10:15.564] iteration 3981: loss: 0.200812, loss_s1: 0.153004, loss_fp: 0.001067, loss_freq: 0.037287
[03:10:16.154] iteration 3982: loss: 0.140342, loss_s1: 0.086405, loss_fp: 0.000565, loss_freq: 0.010033
[03:10:16.743] iteration 3983: loss: 0.124472, loss_s1: 0.067561, loss_fp: 0.000408, loss_freq: 0.005963
[03:10:17.333] iteration 3984: loss: 0.232623, loss_s1: 0.188369, loss_fp: 0.000554, loss_freq: 0.037930
[03:10:17.924] iteration 3985: loss: 0.236119, loss_s1: 0.126386, loss_fp: 0.003277, loss_freq: 0.074789
[03:10:18.513] iteration 3986: loss: 0.116670, loss_s1: 0.063855, loss_fp: 0.000538, loss_freq: 0.012990
[03:10:19.100] iteration 3987: loss: 0.179834, loss_s1: 0.134312, loss_fp: 0.001030, loss_freq: 0.041394
[03:10:19.692] iteration 3988: loss: 0.150735, loss_s1: 0.092689, loss_fp: 0.000554, loss_freq: 0.017402
[03:10:20.283] iteration 3989: loss: 0.138798, loss_s1: 0.061268, loss_fp: 0.000538, loss_freq: 0.072866
[03:10:20.875] iteration 3990: loss: 0.177537, loss_s1: 0.116366, loss_fp: 0.001676, loss_freq: 0.021438
[03:10:21.470] iteration 3991: loss: 0.208084, loss_s1: 0.137995, loss_fp: 0.000672, loss_freq: 0.092950
[03:10:22.111] iteration 3992: loss: 0.147248, loss_s1: 0.120203, loss_fp: 0.000613, loss_freq: 0.014720
[03:10:22.775] iteration 3993: loss: 0.141414, loss_s1: 0.092091, loss_fp: 0.002862, loss_freq: 0.020347
[03:10:23.402] iteration 3994: loss: 0.223309, loss_s1: 0.163056, loss_fp: 0.000566, loss_freq: 0.025303
[03:10:24.037] iteration 3995: loss: 0.164610, loss_s1: 0.110533, loss_fp: 0.000796, loss_freq: 0.001902
[03:10:24.669] iteration 3996: loss: 0.191336, loss_s1: 0.100785, loss_fp: 0.003371, loss_freq: 0.083647
[03:10:25.294] iteration 3997: loss: 0.222065, loss_s1: 0.196148, loss_fp: 0.000471, loss_freq: 0.048053
[03:10:25.878] iteration 3998: loss: 0.226569, loss_s1: 0.157171, loss_fp: 0.002928, loss_freq: 0.042514
[03:10:26.466] iteration 3999: loss: 0.259893, loss_s1: 0.347758, loss_fp: 0.001172, loss_freq: 0.022771
[03:10:27.055] iteration 4000: loss: 0.144988, loss_s1: 0.096233, loss_fp: 0.001206, loss_freq: 0.016142
[03:10:29.987] iteration 4000 : mean_dice : 0.365139
[03:10:30.637] iteration 4001: loss: 0.195981, loss_s1: 0.145502, loss_fp: 0.000544, loss_freq: 0.089157
[03:10:31.225] iteration 4002: loss: 0.173126, loss_s1: 0.104400, loss_fp: 0.003634, loss_freq: 0.089458
[03:10:31.817] iteration 4003: loss: 0.211259, loss_s1: 0.108411, loss_fp: 0.000938, loss_freq: 0.029638
[03:10:32.412] iteration 4004: loss: 0.146482, loss_s1: 0.057334, loss_fp: 0.001047, loss_freq: 0.032942
[03:10:33.003] iteration 4005: loss: 0.148082, loss_s1: 0.084545, loss_fp: 0.000338, loss_freq: 0.007452
[03:10:33.594] iteration 4006: loss: 0.125826, loss_s1: 0.085078, loss_fp: 0.000444, loss_freq: 0.018566
[03:10:34.182] iteration 4007: loss: 0.188617, loss_s1: 0.107678, loss_fp: 0.009530, loss_freq: 0.019778
[03:10:34.770] iteration 4008: loss: 0.310851, loss_s1: 0.159078, loss_fp: 0.001489, loss_freq: 0.251842
[03:10:35.361] iteration 4009: loss: 0.139582, loss_s1: 0.046206, loss_fp: 0.001143, loss_freq: 0.017674
[03:10:35.948] iteration 4010: loss: 0.110505, loss_s1: 0.045742, loss_fp: 0.000694, loss_freq: 0.002868
[03:10:36.536] iteration 4011: loss: 0.267638, loss_s1: 0.230760, loss_fp: 0.025539, loss_freq: 0.084948
[03:10:37.182] iteration 4012: loss: 0.187938, loss_s1: 0.092602, loss_fp: 0.001092, loss_freq: 0.022481
[03:10:37.815] iteration 4013: loss: 0.173674, loss_s1: 0.106945, loss_fp: 0.000640, loss_freq: 0.019996
[03:10:38.447] iteration 4014: loss: 0.186348, loss_s1: 0.102882, loss_fp: 0.006822, loss_freq: 0.026514
[03:10:39.072] iteration 4015: loss: 0.098166, loss_s1: 0.040360, loss_fp: 0.001101, loss_freq: 0.008726
[03:10:39.657] iteration 4016: loss: 0.198583, loss_s1: 0.051741, loss_fp: 0.000448, loss_freq: 0.025480
[03:10:40.248] iteration 4017: loss: 0.168814, loss_s1: 0.106223, loss_fp: 0.000586, loss_freq: 0.032427
[03:10:40.836] iteration 4018: loss: 0.176280, loss_s1: 0.111892, loss_fp: 0.000999, loss_freq: 0.004766
[03:10:41.444] iteration 4019: loss: 0.452742, loss_s1: 0.338708, loss_fp: 0.016693, loss_freq: 0.373410
[03:10:42.102] iteration 4020: loss: 0.197827, loss_s1: 0.186065, loss_fp: 0.000416, loss_freq: 0.015559
[03:10:42.751] iteration 4021: loss: 0.174597, loss_s1: 0.077750, loss_fp: 0.015867, loss_freq: 0.016447
[03:10:43.383] iteration 4022: loss: 0.134146, loss_s1: 0.082198, loss_fp: 0.000665, loss_freq: 0.012158
[03:10:43.974] iteration 4023: loss: 0.175311, loss_s1: 0.112763, loss_fp: 0.000551, loss_freq: 0.039946
[03:10:44.565] iteration 4024: loss: 0.124670, loss_s1: 0.049215, loss_fp: 0.000493, loss_freq: 0.034046
[03:10:45.155] iteration 4025: loss: 0.323302, loss_s1: 0.203828, loss_fp: 0.000979, loss_freq: 0.209323
[03:10:45.741] iteration 4026: loss: 0.171327, loss_s1: 0.082291, loss_fp: 0.001578, loss_freq: 0.028508
[03:10:46.332] iteration 4027: loss: 0.163702, loss_s1: 0.132331, loss_fp: 0.001034, loss_freq: 0.041050
[03:10:46.960] iteration 4028: loss: 0.108499, loss_s1: 0.023401, loss_fp: 0.000383, loss_freq: 0.009637
[03:10:47.589] iteration 4029: loss: 0.166898, loss_s1: 0.035216, loss_fp: 0.000771, loss_freq: 0.123841
[03:10:48.219] iteration 4030: loss: 0.208349, loss_s1: 0.115970, loss_fp: 0.001967, loss_freq: 0.009116
[03:10:48.847] iteration 4031: loss: 0.150541, loss_s1: 0.118099, loss_fp: 0.000670, loss_freq: 0.014173
[03:10:49.457] iteration 4032: loss: 0.167842, loss_s1: 0.137188, loss_fp: 0.001576, loss_freq: 0.023361
[03:10:50.047] iteration 4033: loss: 0.231458, loss_s1: 0.070871, loss_fp: 0.017592, loss_freq: 0.124447
[03:10:50.638] iteration 4034: loss: 0.122545, loss_s1: 0.103124, loss_fp: 0.001381, loss_freq: 0.013432
[03:10:51.228] iteration 4035: loss: 0.290672, loss_s1: 0.320384, loss_fp: 0.001124, loss_freq: 0.045354
[03:10:51.819] iteration 4036: loss: 0.142979, loss_s1: 0.034362, loss_fp: 0.001219, loss_freq: 0.008042
[03:10:52.407] iteration 4037: loss: 0.432755, loss_s1: 0.303304, loss_fp: 0.011091, loss_freq: 0.345763
[03:10:53.046] iteration 4038: loss: 0.242481, loss_s1: 0.146974, loss_fp: 0.003940, loss_freq: 0.047490
[03:10:53.682] iteration 4039: loss: 0.217341, loss_s1: 0.182129, loss_fp: 0.002095, loss_freq: 0.017625
[03:10:54.273] iteration 4040: loss: 0.127048, loss_s1: 0.067631, loss_fp: 0.000789, loss_freq: 0.016146
[03:10:54.873] iteration 4041: loss: 0.198997, loss_s1: 0.166440, loss_fp: 0.005887, loss_freq: 0.055495
[03:10:55.468] iteration 4042: loss: 0.271707, loss_s1: 0.099922, loss_fp: 0.000617, loss_freq: 0.007234
[03:10:56.061] iteration 4043: loss: 0.163970, loss_s1: 0.119185, loss_fp: 0.000622, loss_freq: 0.006816
[03:10:56.648] iteration 4044: loss: 0.184265, loss_s1: 0.166682, loss_fp: 0.000800, loss_freq: 0.019481
[03:10:57.243] iteration 4045: loss: 0.166743, loss_s1: 0.083355, loss_fp: 0.001083, loss_freq: 0.011832
[03:10:57.832] iteration 4046: loss: 0.200864, loss_s1: 0.141378, loss_fp: 0.001553, loss_freq: 0.043685
[03:10:58.420] iteration 4047: loss: 0.190538, loss_s1: 0.123446, loss_fp: 0.000543, loss_freq: 0.010368
[03:10:59.020] iteration 4048: loss: 0.150941, loss_s1: 0.115444, loss_fp: 0.004459, loss_freq: 0.013054
[03:10:59.619] iteration 4049: loss: 0.187617, loss_s1: 0.143181, loss_fp: 0.000771, loss_freq: 0.040343
[03:11:00.237] iteration 4050: loss: 0.241737, loss_s1: 0.221079, loss_fp: 0.005530, loss_freq: 0.031427
[03:11:00.828] iteration 4051: loss: 0.284361, loss_s1: 0.216870, loss_fp: 0.005764, loss_freq: 0.065164
[03:11:01.416] iteration 4052: loss: 0.128594, loss_s1: 0.063965, loss_fp: 0.002415, loss_freq: 0.006939
[03:11:02.005] iteration 4053: loss: 0.185270, loss_s1: 0.103541, loss_fp: 0.001508, loss_freq: 0.023182
[03:11:02.595] iteration 4054: loss: 0.134911, loss_s1: 0.086691, loss_fp: 0.000458, loss_freq: 0.007372
[03:11:03.184] iteration 4055: loss: 0.166207, loss_s1: 0.074111, loss_fp: 0.002802, loss_freq: 0.058640
[03:11:03.784] iteration 4056: loss: 0.147022, loss_s1: 0.055642, loss_fp: 0.002905, loss_freq: 0.023442
[03:11:04.381] iteration 4057: loss: 0.117813, loss_s1: 0.032049, loss_fp: 0.000723, loss_freq: 0.036298
[03:11:04.989] iteration 4058: loss: 0.212638, loss_s1: 0.134533, loss_fp: 0.008876, loss_freq: 0.037248
[03:11:05.574] iteration 4059: loss: 0.172706, loss_s1: 0.160304, loss_fp: 0.000699, loss_freq: 0.021534
[03:11:06.163] iteration 4060: loss: 0.162390, loss_s1: 0.097522, loss_fp: 0.002581, loss_freq: 0.018178
[03:11:06.752] iteration 4061: loss: 0.221613, loss_s1: 0.224229, loss_fp: 0.001321, loss_freq: 0.014199
[03:11:07.378] iteration 4062: loss: 0.174533, loss_s1: 0.100042, loss_fp: 0.001717, loss_freq: 0.069212
[03:11:07.973] iteration 4063: loss: 0.191944, loss_s1: 0.143520, loss_fp: 0.001167, loss_freq: 0.078764
[03:11:08.564] iteration 4064: loss: 0.138781, loss_s1: 0.077186, loss_fp: 0.000386, loss_freq: 0.025351
[03:11:09.154] iteration 4065: loss: 0.168641, loss_s1: 0.044072, loss_fp: 0.000531, loss_freq: 0.038779
[03:11:09.742] iteration 4066: loss: 0.164035, loss_s1: 0.121907, loss_fp: 0.000914, loss_freq: 0.026625
[03:11:10.337] iteration 4067: loss: 0.119101, loss_s1: 0.042968, loss_fp: 0.001203, loss_freq: 0.006246
[03:11:10.931] iteration 4068: loss: 0.158497, loss_s1: 0.033620, loss_fp: 0.000433, loss_freq: 0.021147
[03:11:11.522] iteration 4069: loss: 0.134036, loss_s1: 0.109510, loss_fp: 0.001157, loss_freq: 0.015078
[03:11:12.116] iteration 4070: loss: 0.143669, loss_s1: 0.073552, loss_fp: 0.001344, loss_freq: 0.037239
[03:11:12.716] iteration 4071: loss: 0.113470, loss_s1: 0.092502, loss_fp: 0.000912, loss_freq: 0.010923
[03:11:13.323] iteration 4072: loss: 0.152681, loss_s1: 0.143516, loss_fp: 0.000472, loss_freq: 0.004960
[03:11:13.927] iteration 4073: loss: 0.192470, loss_s1: 0.104515, loss_fp: 0.002177, loss_freq: 0.035410
[03:11:14.520] iteration 4074: loss: 0.117046, loss_s1: 0.054942, loss_fp: 0.000759, loss_freq: 0.020377
[03:11:15.112] iteration 4075: loss: 0.145018, loss_s1: 0.049958, loss_fp: 0.000607, loss_freq: 0.022437
[03:11:15.705] iteration 4076: loss: 0.182475, loss_s1: 0.101765, loss_fp: 0.001534, loss_freq: 0.028235
[03:11:16.296] iteration 4077: loss: 0.213101, loss_s1: 0.138894, loss_fp: 0.001259, loss_freq: 0.074524
[03:11:16.892] iteration 4078: loss: 0.139342, loss_s1: 0.101564, loss_fp: 0.000400, loss_freq: 0.007018
[03:11:17.524] iteration 4079: loss: 0.175242, loss_s1: 0.172284, loss_fp: 0.000977, loss_freq: 0.009118
[03:11:18.157] iteration 4080: loss: 0.117761, loss_s1: 0.069171, loss_fp: 0.000604, loss_freq: 0.042101
[03:11:19.101] iteration 4081: loss: 0.163260, loss_s1: 0.065209, loss_fp: 0.000543, loss_freq: 0.016295
[03:11:19.767] iteration 4082: loss: 0.089100, loss_s1: 0.024356, loss_fp: 0.000421, loss_freq: 0.011243
[03:11:20.362] iteration 4083: loss: 0.152234, loss_s1: 0.064914, loss_fp: 0.001020, loss_freq: 0.041928
[03:11:20.952] iteration 4084: loss: 0.149400, loss_s1: 0.097533, loss_fp: 0.003268, loss_freq: 0.026979
[03:11:21.547] iteration 4085: loss: 0.129484, loss_s1: 0.055805, loss_fp: 0.000622, loss_freq: 0.019739
[03:11:22.151] iteration 4086: loss: 0.155471, loss_s1: 0.071597, loss_fp: 0.006037, loss_freq: 0.010797
[03:11:22.841] iteration 4087: loss: 0.138776, loss_s1: 0.041077, loss_fp: 0.017891, loss_freq: 0.007340
[03:11:23.441] iteration 4088: loss: 0.114110, loss_s1: 0.033825, loss_fp: 0.000501, loss_freq: 0.016663
[03:11:24.040] iteration 4089: loss: 0.165526, loss_s1: 0.088195, loss_fp: 0.000934, loss_freq: 0.031457
[03:11:24.769] iteration 4090: loss: 0.184698, loss_s1: 0.119298, loss_fp: 0.009125, loss_freq: 0.039517
[03:11:25.355] iteration 4091: loss: 0.165499, loss_s1: 0.075099, loss_fp: 0.005415, loss_freq: 0.049841
[03:11:25.945] iteration 4092: loss: 0.153236, loss_s1: 0.078973, loss_fp: 0.017585, loss_freq: 0.068368
[03:11:26.537] iteration 4093: loss: 0.204873, loss_s1: 0.174912, loss_fp: 0.002904, loss_freq: 0.055467
[03:11:27.126] iteration 4094: loss: 0.181013, loss_s1: 0.098837, loss_fp: 0.000475, loss_freq: 0.054711
[03:11:27.720] iteration 4095: loss: 0.115509, loss_s1: 0.034893, loss_fp: 0.001098, loss_freq: 0.008560
[03:11:28.326] iteration 4096: loss: 0.130477, loss_s1: 0.059692, loss_fp: 0.000491, loss_freq: 0.016873
[03:11:28.922] iteration 4097: loss: 0.258934, loss_s1: 0.161649, loss_fp: 0.000751, loss_freq: 0.128595
[03:11:29.515] iteration 4098: loss: 0.179314, loss_s1: 0.073773, loss_fp: 0.000878, loss_freq: 0.019562
[03:11:30.110] iteration 4099: loss: 0.101223, loss_s1: 0.059464, loss_fp: 0.002070, loss_freq: 0.025197
[03:11:30.704] iteration 4100: loss: 0.148672, loss_s1: 0.110073, loss_fp: 0.000726, loss_freq: 0.020906
[03:11:31.296] iteration 4101: loss: 0.146156, loss_s1: 0.115886, loss_fp: 0.001557, loss_freq: 0.017846
[03:11:31.891] iteration 4102: loss: 0.262802, loss_s1: 0.184323, loss_fp: 0.010015, loss_freq: 0.041004
[03:11:32.484] iteration 4103: loss: 0.182452, loss_s1: 0.087402, loss_fp: 0.000791, loss_freq: 0.016436
[03:11:33.078] iteration 4104: loss: 0.141954, loss_s1: 0.074450, loss_fp: 0.002600, loss_freq: 0.021756
[03:11:33.664] iteration 4105: loss: 0.251021, loss_s1: 0.302460, loss_fp: 0.002033, loss_freq: 0.011677
[03:11:34.261] iteration 4106: loss: 0.164656, loss_s1: 0.078389, loss_fp: 0.000564, loss_freq: 0.020916
[03:11:34.857] iteration 4107: loss: 0.131117, loss_s1: 0.067465, loss_fp: 0.005566, loss_freq: 0.005783
[03:11:35.449] iteration 4108: loss: 0.189778, loss_s1: 0.149203, loss_fp: 0.002092, loss_freq: 0.050355
[03:11:36.039] iteration 4109: loss: 0.201215, loss_s1: 0.083826, loss_fp: 0.005005, loss_freq: 0.012817
[03:11:36.631] iteration 4110: loss: 0.102243, loss_s1: 0.038157, loss_fp: 0.001123, loss_freq: 0.010287
[03:11:37.219] iteration 4111: loss: 0.171956, loss_s1: 0.128641, loss_fp: 0.000799, loss_freq: 0.022053
[03:11:37.816] iteration 4112: loss: 0.224316, loss_s1: 0.166281, loss_fp: 0.001062, loss_freq: 0.020008
[03:11:38.411] iteration 4113: loss: 0.225458, loss_s1: 0.186371, loss_fp: 0.002100, loss_freq: 0.027807
[03:11:39.040] iteration 4114: loss: 0.154173, loss_s1: 0.108597, loss_fp: 0.000547, loss_freq: 0.015880
[03:11:39.673] iteration 4115: loss: 0.212476, loss_s1: 0.241785, loss_fp: 0.001067, loss_freq: 0.028798
[03:11:40.305] iteration 4116: loss: 0.141066, loss_s1: 0.090097, loss_fp: 0.000860, loss_freq: 0.003945
[03:11:40.897] iteration 4117: loss: 0.134893, loss_s1: 0.102001, loss_fp: 0.002451, loss_freq: 0.006404
[03:11:41.491] iteration 4118: loss: 0.132952, loss_s1: 0.092775, loss_fp: 0.000713, loss_freq: 0.015839
[03:11:42.087] iteration 4119: loss: 0.143940, loss_s1: 0.074271, loss_fp: 0.033249, loss_freq: 0.014384
[03:11:42.681] iteration 4120: loss: 0.207470, loss_s1: 0.178887, loss_fp: 0.001511, loss_freq: 0.056485
[03:11:43.274] iteration 4121: loss: 0.187105, loss_s1: 0.083967, loss_fp: 0.000697, loss_freq: 0.071457
[03:11:43.859] iteration 4122: loss: 0.158840, loss_s1: 0.142299, loss_fp: 0.001064, loss_freq: 0.050825
[03:11:44.454] iteration 4123: loss: 0.174487, loss_s1: 0.106754, loss_fp: 0.000748, loss_freq: 0.040059
[03:11:45.049] iteration 4124: loss: 0.291063, loss_s1: 0.298793, loss_fp: 0.000357, loss_freq: 0.051983
[03:11:45.638] iteration 4125: loss: 0.187156, loss_s1: 0.142962, loss_fp: 0.003252, loss_freq: 0.026722
[03:11:46.227] iteration 4126: loss: 0.135431, loss_s1: 0.028415, loss_fp: 0.000878, loss_freq: 0.022420
[03:11:46.826] iteration 4127: loss: 0.183884, loss_s1: 0.103308, loss_fp: 0.000812, loss_freq: 0.015986
[03:11:47.426] iteration 4128: loss: 0.209484, loss_s1: 0.107326, loss_fp: 0.000629, loss_freq: 0.043857
[03:11:48.016] iteration 4129: loss: 0.127317, loss_s1: 0.078926, loss_fp: 0.000801, loss_freq: 0.012155
[03:11:48.615] iteration 4130: loss: 0.166418, loss_s1: 0.110436, loss_fp: 0.000601, loss_freq: 0.026556
[03:11:49.213] iteration 4131: loss: 0.232331, loss_s1: 0.236129, loss_fp: 0.002088, loss_freq: 0.088698
[03:11:49.807] iteration 4132: loss: 0.177896, loss_s1: 0.181518, loss_fp: 0.000795, loss_freq: 0.016833
[03:11:50.405] iteration 4133: loss: 0.231385, loss_s1: 0.124520, loss_fp: 0.000603, loss_freq: 0.101001
[03:11:51.001] iteration 4134: loss: 0.134337, loss_s1: 0.033752, loss_fp: 0.009415, loss_freq: 0.039123
[03:11:51.593] iteration 4135: loss: 0.151008, loss_s1: 0.056840, loss_fp: 0.000814, loss_freq: 0.009374
[03:11:52.190] iteration 4136: loss: 0.094933, loss_s1: 0.036394, loss_fp: 0.000926, loss_freq: 0.014268
[03:11:52.784] iteration 4137: loss: 0.123990, loss_s1: 0.066223, loss_fp: 0.000888, loss_freq: 0.008194
[03:11:53.383] iteration 4138: loss: 0.248473, loss_s1: 0.167660, loss_fp: 0.011801, loss_freq: 0.092851
[03:11:53.971] iteration 4139: loss: 0.143459, loss_s1: 0.053163, loss_fp: 0.000853, loss_freq: 0.025418
[03:11:54.562] iteration 4140: loss: 0.190172, loss_s1: 0.156956, loss_fp: 0.000885, loss_freq: 0.028706
[03:11:55.164] iteration 4141: loss: 0.111577, loss_s1: 0.050543, loss_fp: 0.001271, loss_freq: 0.023072
[03:11:55.762] iteration 4142: loss: 0.154791, loss_s1: 0.096748, loss_fp: 0.002251, loss_freq: 0.038471
[03:11:56.354] iteration 4143: loss: 0.153611, loss_s1: 0.136024, loss_fp: 0.000906, loss_freq: 0.007494
[03:11:57.005] iteration 4144: loss: 0.244843, loss_s1: 0.108794, loss_fp: 0.001598, loss_freq: 0.061544
[03:11:57.604] iteration 4145: loss: 0.152778, loss_s1: 0.077994, loss_fp: 0.001114, loss_freq: 0.037128
[03:11:58.194] iteration 4146: loss: 0.177843, loss_s1: 0.182159, loss_fp: 0.000687, loss_freq: 0.009879
[03:11:58.792] iteration 4147: loss: 0.222973, loss_s1: 0.088129, loss_fp: 0.000529, loss_freq: 0.010499
[03:11:59.383] iteration 4148: loss: 0.157739, loss_s1: 0.091248, loss_fp: 0.000800, loss_freq: 0.042331
[03:11:59.973] iteration 4149: loss: 0.149820, loss_s1: 0.065330, loss_fp: 0.000479, loss_freq: 0.036545
[03:12:00.565] iteration 4150: loss: 0.130730, loss_s1: 0.066631, loss_fp: 0.000791, loss_freq: 0.025356
[03:12:01.160] iteration 4151: loss: 0.146793, loss_s1: 0.041622, loss_fp: 0.001279, loss_freq: 0.040657
[03:12:01.755] iteration 4152: loss: 0.112776, loss_s1: 0.053376, loss_fp: 0.002894, loss_freq: 0.007899
[03:12:02.358] iteration 4153: loss: 0.109399, loss_s1: 0.041817, loss_fp: 0.000917, loss_freq: 0.017509
[03:12:02.949] iteration 4154: loss: 0.192504, loss_s1: 0.151236, loss_fp: 0.000832, loss_freq: 0.050535
[03:12:03.562] iteration 4155: loss: 0.170581, loss_s1: 0.090853, loss_fp: 0.008472, loss_freq: 0.062058
[03:12:04.194] iteration 4156: loss: 0.155553, loss_s1: 0.087206, loss_fp: 0.000788, loss_freq: 0.037924
[03:12:04.818] iteration 4157: loss: 0.145417, loss_s1: 0.058963, loss_fp: 0.009896, loss_freq: 0.033070
[03:12:05.451] iteration 4158: loss: 0.195919, loss_s1: 0.144818, loss_fp: 0.002677, loss_freq: 0.058526
[03:12:06.054] iteration 4159: loss: 0.116347, loss_s1: 0.076205, loss_fp: 0.000849, loss_freq: 0.040285
[03:12:06.655] iteration 4160: loss: 0.186569, loss_s1: 0.110681, loss_fp: 0.001428, loss_freq: 0.019561
[03:12:07.248] iteration 4161: loss: 0.225717, loss_s1: 0.099177, loss_fp: 0.003781, loss_freq: 0.087893
[03:12:07.832] iteration 4162: loss: 0.134738, loss_s1: 0.093994, loss_fp: 0.000767, loss_freq: 0.014687
[03:12:08.423] iteration 4163: loss: 0.187110, loss_s1: 0.065194, loss_fp: 0.002579, loss_freq: 0.014962
[03:12:09.008] iteration 4164: loss: 0.198225, loss_s1: 0.069125, loss_fp: 0.001542, loss_freq: 0.028789
[03:12:09.603] iteration 4165: loss: 0.188889, loss_s1: 0.102737, loss_fp: 0.007628, loss_freq: 0.035150
[03:12:10.192] iteration 4166: loss: 0.161257, loss_s1: 0.057658, loss_fp: 0.031702, loss_freq: 0.048773
[03:12:10.787] iteration 4167: loss: 0.184170, loss_s1: 0.158304, loss_fp: 0.000503, loss_freq: 0.017199
[03:12:11.375] iteration 4168: loss: 0.133311, loss_s1: 0.095315, loss_fp: 0.001163, loss_freq: 0.016170
[03:12:11.964] iteration 4169: loss: 0.130472, loss_s1: 0.037157, loss_fp: 0.000833, loss_freq: 0.037980
[03:12:12.558] iteration 4170: loss: 0.137308, loss_s1: 0.041468, loss_fp: 0.001407, loss_freq: 0.016741
[03:12:13.151] iteration 4171: loss: 0.173768, loss_s1: 0.122134, loss_fp: 0.009564, loss_freq: 0.058011
[03:12:13.744] iteration 4172: loss: 0.186666, loss_s1: 0.193590, loss_fp: 0.001015, loss_freq: 0.029427
[03:12:14.336] iteration 4173: loss: 0.136257, loss_s1: 0.019856, loss_fp: 0.000564, loss_freq: 0.030079
[03:12:14.935] iteration 4174: loss: 0.133733, loss_s1: 0.089654, loss_fp: 0.002261, loss_freq: 0.016068
[03:12:15.529] iteration 4175: loss: 0.124240, loss_s1: 0.100662, loss_fp: 0.001396, loss_freq: 0.016548
[03:12:16.126] iteration 4176: loss: 0.179648, loss_s1: 0.124972, loss_fp: 0.000469, loss_freq: 0.036529
[03:12:16.713] iteration 4177: loss: 0.157902, loss_s1: 0.046678, loss_fp: 0.006103, loss_freq: 0.043193
[03:12:17.302] iteration 4178: loss: 0.173871, loss_s1: 0.175461, loss_fp: 0.003604, loss_freq: 0.029433
[03:12:17.893] iteration 4179: loss: 0.143334, loss_s1: 0.088686, loss_fp: 0.000824, loss_freq: 0.024658
[03:12:18.486] iteration 4180: loss: 0.163696, loss_s1: 0.120705, loss_fp: 0.000612, loss_freq: 0.005541
[03:12:19.074] iteration 4181: loss: 0.235085, loss_s1: 0.215363, loss_fp: 0.001146, loss_freq: 0.085486
[03:12:19.664] iteration 4182: loss: 0.189681, loss_s1: 0.132434, loss_fp: 0.000811, loss_freq: 0.021791
[03:12:20.250] iteration 4183: loss: 0.141993, loss_s1: 0.081211, loss_fp: 0.000544, loss_freq: 0.020230
[03:12:20.840] iteration 4184: loss: 0.196831, loss_s1: 0.102135, loss_fp: 0.001513, loss_freq: 0.041250
[03:12:21.440] iteration 4185: loss: 0.131695, loss_s1: 0.043239, loss_fp: 0.001003, loss_freq: 0.011722
[03:12:22.070] iteration 4186: loss: 0.171758, loss_s1: 0.080437, loss_fp: 0.000682, loss_freq: 0.015650
[03:12:22.662] iteration 4187: loss: 0.187039, loss_s1: 0.101064, loss_fp: 0.000605, loss_freq: 0.043889
[03:12:23.251] iteration 4188: loss: 0.165339, loss_s1: 0.077039, loss_fp: 0.002246, loss_freq: 0.017777
[03:12:23.931] iteration 4189: loss: 0.218079, loss_s1: 0.125016, loss_fp: 0.000855, loss_freq: 0.118981
[03:12:24.627] iteration 4190: loss: 0.181983, loss_s1: 0.059161, loss_fp: 0.000686, loss_freq: 0.020641
[03:12:25.332] iteration 4191: loss: 0.241400, loss_s1: 0.095946, loss_fp: 0.001076, loss_freq: 0.063992
[03:12:25.997] iteration 4192: loss: 0.157851, loss_s1: 0.086166, loss_fp: 0.001756, loss_freq: 0.022097
[03:12:26.715] iteration 4193: loss: 0.194962, loss_s1: 0.143354, loss_fp: 0.000681, loss_freq: 0.025814
[03:12:27.338] iteration 4194: loss: 0.159293, loss_s1: 0.074312, loss_fp: 0.008257, loss_freq: 0.031714
[03:12:28.072] iteration 4195: loss: 0.278284, loss_s1: 0.264816, loss_fp: 0.006486, loss_freq: 0.054909
[03:12:28.809] iteration 4196: loss: 0.208824, loss_s1: 0.203158, loss_fp: 0.000869, loss_freq: 0.034966
[03:12:29.478] iteration 4197: loss: 0.170179, loss_s1: 0.154587, loss_fp: 0.000655, loss_freq: 0.018033
[03:12:30.184] iteration 4198: loss: 0.143678, loss_s1: 0.047108, loss_fp: 0.000792, loss_freq: 0.005878
[03:12:30.863] iteration 4199: loss: 0.253656, loss_s1: 0.192432, loss_fp: 0.001176, loss_freq: 0.094723
[03:12:31.677] iteration 4200: loss: 0.097293, loss_s1: 0.017716, loss_fp: 0.003762, loss_freq: 0.018225
[03:12:34.928] iteration 4200 : mean_dice : 0.425267
[03:12:35.622] iteration 4201: loss: 0.110823, loss_s1: 0.034148, loss_fp: 0.000590, loss_freq: 0.009504
[03:12:36.244] iteration 4202: loss: 0.148192, loss_s1: 0.129695, loss_fp: 0.000697, loss_freq: 0.023647
[03:12:36.834] iteration 4203: loss: 0.190449, loss_s1: 0.117600, loss_fp: 0.004615, loss_freq: 0.118857
[03:12:37.425] iteration 4204: loss: 0.143042, loss_s1: 0.117807, loss_fp: 0.001730, loss_freq: 0.042582
[03:12:38.055] iteration 4205: loss: 0.124841, loss_s1: 0.060077, loss_fp: 0.000607, loss_freq: 0.021631
[03:12:38.682] iteration 4206: loss: 0.120385, loss_s1: 0.025087, loss_fp: 0.000825, loss_freq: 0.005406
[03:12:39.274] iteration 4207: loss: 0.370126, loss_s1: 0.397338, loss_fp: 0.025819, loss_freq: 0.176346
[03:12:39.861] iteration 4208: loss: 0.221074, loss_s1: 0.073843, loss_fp: 0.001051, loss_freq: 0.125485
[03:12:40.452] iteration 4209: loss: 0.156132, loss_s1: 0.136654, loss_fp: 0.000569, loss_freq: 0.012837
[03:12:41.038] iteration 4210: loss: 0.205236, loss_s1: 0.159350, loss_fp: 0.006541, loss_freq: 0.068786
[03:12:41.625] iteration 4211: loss: 0.287086, loss_s1: 0.138445, loss_fp: 0.004030, loss_freq: 0.119557
[03:12:42.257] iteration 4212: loss: 0.175408, loss_s1: 0.048594, loss_fp: 0.001022, loss_freq: 0.016400
[03:12:42.847] iteration 4213: loss: 0.127154, loss_s1: 0.072960, loss_fp: 0.001125, loss_freq: 0.012134
[03:12:43.433] iteration 4214: loss: 0.212475, loss_s1: 0.155454, loss_fp: 0.004215, loss_freq: 0.021040
[03:12:44.036] iteration 4215: loss: 0.172561, loss_s1: 0.117376, loss_fp: 0.002248, loss_freq: 0.027420
[03:12:44.639] iteration 4216: loss: 0.206094, loss_s1: 0.083483, loss_fp: 0.001068, loss_freq: 0.059585
[03:12:45.224] iteration 4217: loss: 0.247638, loss_s1: 0.156294, loss_fp: 0.000834, loss_freq: 0.027588
[03:12:45.809] iteration 4218: loss: 0.191203, loss_s1: 0.140155, loss_fp: 0.002573, loss_freq: 0.078916
[03:12:46.399] iteration 4219: loss: 0.250324, loss_s1: 0.162118, loss_fp: 0.000861, loss_freq: 0.055206
[03:12:46.986] iteration 4220: loss: 0.259171, loss_s1: 0.180308, loss_fp: 0.003134, loss_freq: 0.062354
[03:12:47.573] iteration 4221: loss: 0.217978, loss_s1: 0.154759, loss_fp: 0.003642, loss_freq: 0.041235
[03:12:48.167] iteration 4222: loss: 0.160728, loss_s1: 0.059486, loss_fp: 0.001298, loss_freq: 0.019519
[03:12:48.863] iteration 4223: loss: 0.162309, loss_s1: 0.139876, loss_fp: 0.000671, loss_freq: 0.026044
[03:12:49.807] iteration 4224: loss: 0.154751, loss_s1: 0.067340, loss_fp: 0.000721, loss_freq: 0.011656
[03:12:50.743] iteration 4225: loss: 0.149353, loss_s1: 0.055032, loss_fp: 0.001621, loss_freq: 0.038608
[03:12:51.513] iteration 4226: loss: 0.207053, loss_s1: 0.108589, loss_fp: 0.000456, loss_freq: 0.031314
[03:12:52.110] iteration 4227: loss: 0.137796, loss_s1: 0.055114, loss_fp: 0.001341, loss_freq: 0.030922
[03:12:52.693] iteration 4228: loss: 0.167619, loss_s1: 0.070107, loss_fp: 0.003586, loss_freq: 0.049383
[03:12:53.277] iteration 4229: loss: 0.203110, loss_s1: 0.144012, loss_fp: 0.001570, loss_freq: 0.049629
[03:12:53.863] iteration 4230: loss: 0.145938, loss_s1: 0.089564, loss_fp: 0.001539, loss_freq: 0.013712
[03:12:54.456] iteration 4231: loss: 0.174548, loss_s1: 0.149199, loss_fp: 0.000777, loss_freq: 0.008757
[03:12:55.047] iteration 4232: loss: 0.187142, loss_s1: 0.191550, loss_fp: 0.001732, loss_freq: 0.022245
[03:12:55.637] iteration 4233: loss: 0.171497, loss_s1: 0.056068, loss_fp: 0.000664, loss_freq: 0.109331
[03:12:56.231] iteration 4234: loss: 0.142469, loss_s1: 0.074038, loss_fp: 0.000519, loss_freq: 0.025797
[03:12:56.815] iteration 4235: loss: 0.333502, loss_s1: 0.118707, loss_fp: 0.001343, loss_freq: 0.085308
[03:12:57.411] iteration 4236: loss: 0.168980, loss_s1: 0.149100, loss_fp: 0.000906, loss_freq: 0.007177
[03:12:58.005] iteration 4237: loss: 0.104115, loss_s1: 0.062999, loss_fp: 0.001376, loss_freq: 0.017858
[03:12:58.595] iteration 4238: loss: 0.153899, loss_s1: 0.060937, loss_fp: 0.000815, loss_freq: 0.040181
[03:12:59.222] iteration 4239: loss: 0.132728, loss_s1: 0.071424, loss_fp: 0.013356, loss_freq: 0.036825
[03:12:59.825] iteration 4240: loss: 0.167661, loss_s1: 0.084383, loss_fp: 0.001754, loss_freq: 0.040078
[03:13:00.418] iteration 4241: loss: 0.120804, loss_s1: 0.137612, loss_fp: 0.000933, loss_freq: 0.006173
[03:13:01.007] iteration 4242: loss: 0.169253, loss_s1: 0.117024, loss_fp: 0.015163, loss_freq: 0.036146
[03:13:01.597] iteration 4243: loss: 0.179415, loss_s1: 0.069503, loss_fp: 0.000970, loss_freq: 0.045802
[03:13:02.194] iteration 4244: loss: 0.136205, loss_s1: 0.074745, loss_fp: 0.002977, loss_freq: 0.013496
[03:13:02.827] iteration 4245: loss: 0.108415, loss_s1: 0.060873, loss_fp: 0.001527, loss_freq: 0.014628
[03:13:03.419] iteration 4246: loss: 0.135741, loss_s1: 0.099180, loss_fp: 0.000511, loss_freq: 0.010745
[03:13:04.011] iteration 4247: loss: 0.128467, loss_s1: 0.045491, loss_fp: 0.001101, loss_freq: 0.051166
[03:13:04.600] iteration 4248: loss: 0.111951, loss_s1: 0.071084, loss_fp: 0.000711, loss_freq: 0.007496
[03:13:05.184] iteration 4249: loss: 0.230654, loss_s1: 0.083962, loss_fp: 0.001140, loss_freq: 0.036108
[03:13:05.768] iteration 4250: loss: 0.204124, loss_s1: 0.098573, loss_fp: 0.001042, loss_freq: 0.152572
[03:13:06.697] iteration 4251: loss: 0.123252, loss_s1: 0.034509, loss_fp: 0.001004, loss_freq: 0.006968
[03:13:07.286] iteration 4252: loss: 0.158758, loss_s1: 0.135016, loss_fp: 0.007964, loss_freq: 0.021854
[03:13:07.883] iteration 4253: loss: 0.107078, loss_s1: 0.057206, loss_fp: 0.000586, loss_freq: 0.042621
[03:13:08.505] iteration 4254: loss: 0.139881, loss_s1: 0.044544, loss_fp: 0.001588, loss_freq: 0.040219
[03:13:09.110] iteration 4255: loss: 0.141503, loss_s1: 0.115122, loss_fp: 0.001313, loss_freq: 0.019333
[03:13:09.711] iteration 4256: loss: 0.206318, loss_s1: 0.107335, loss_fp: 0.000877, loss_freq: 0.067604
[03:13:10.303] iteration 4257: loss: 0.161615, loss_s1: 0.102540, loss_fp: 0.003727, loss_freq: 0.036384
[03:13:10.894] iteration 4258: loss: 0.136071, loss_s1: 0.057059, loss_fp: 0.003472, loss_freq: 0.037947
[03:13:11.486] iteration 4259: loss: 0.151324, loss_s1: 0.076636, loss_fp: 0.001157, loss_freq: 0.038366
[03:13:12.119] iteration 4260: loss: 0.168680, loss_s1: 0.087021, loss_fp: 0.006963, loss_freq: 0.040097
[03:13:12.757] iteration 4261: loss: 0.172065, loss_s1: 0.092540, loss_fp: 0.000580, loss_freq: 0.063882
[03:13:13.388] iteration 4262: loss: 0.192501, loss_s1: 0.140017, loss_fp: 0.004414, loss_freq: 0.072023
[03:13:13.981] iteration 4263: loss: 0.155184, loss_s1: 0.095097, loss_fp: 0.002577, loss_freq: 0.079680
[03:13:14.574] iteration 4264: loss: 0.140817, loss_s1: 0.088827, loss_fp: 0.001646, loss_freq: 0.024116
[03:13:15.168] iteration 4265: loss: 0.194508, loss_s1: 0.095162, loss_fp: 0.000653, loss_freq: 0.020729
[03:13:15.763] iteration 4266: loss: 0.114766, loss_s1: 0.064059, loss_fp: 0.001831, loss_freq: 0.043631
[03:13:16.356] iteration 4267: loss: 0.226892, loss_s1: 0.104126, loss_fp: 0.005951, loss_freq: 0.113200
[03:13:16.951] iteration 4268: loss: 0.145072, loss_s1: 0.052942, loss_fp: 0.001274, loss_freq: 0.018176
[03:13:17.542] iteration 4269: loss: 0.120271, loss_s1: 0.066209, loss_fp: 0.001331, loss_freq: 0.034225
[03:13:18.135] iteration 4270: loss: 0.166049, loss_s1: 0.108849, loss_fp: 0.003944, loss_freq: 0.022132
[03:13:18.724] iteration 4271: loss: 0.207283, loss_s1: 0.105716, loss_fp: 0.001506, loss_freq: 0.022825
[03:13:19.317] iteration 4272: loss: 0.147798, loss_s1: 0.061425, loss_fp: 0.000458, loss_freq: 0.029198
[03:13:19.915] iteration 4273: loss: 0.209727, loss_s1: 0.076711, loss_fp: 0.000648, loss_freq: 0.013063
[03:13:20.511] iteration 4274: loss: 0.183551, loss_s1: 0.137105, loss_fp: 0.001046, loss_freq: 0.045264
[03:13:21.100] iteration 4275: loss: 0.149745, loss_s1: 0.133497, loss_fp: 0.000377, loss_freq: 0.013099
[03:13:21.693] iteration 4276: loss: 0.146692, loss_s1: 0.066328, loss_fp: 0.001339, loss_freq: 0.035983
[03:13:22.295] iteration 4277: loss: 0.189404, loss_s1: 0.121748, loss_fp: 0.001865, loss_freq: 0.008949
[03:13:22.910] iteration 4278: loss: 0.195287, loss_s1: 0.139702, loss_fp: 0.007985, loss_freq: 0.049565
[03:13:23.496] iteration 4279: loss: 0.241079, loss_s1: 0.197670, loss_fp: 0.000454, loss_freq: 0.013265
[03:13:24.086] iteration 4280: loss: 0.193823, loss_s1: 0.169243, loss_fp: 0.002749, loss_freq: 0.016399
[03:13:24.678] iteration 4281: loss: 0.119928, loss_s1: 0.109283, loss_fp: 0.000774, loss_freq: 0.003091
[03:13:25.265] iteration 4282: loss: 0.186607, loss_s1: 0.109092, loss_fp: 0.001616, loss_freq: 0.026422
[03:13:25.850] iteration 4283: loss: 0.146081, loss_s1: 0.066717, loss_fp: 0.002561, loss_freq: 0.009303
[03:13:26.449] iteration 4284: loss: 0.115100, loss_s1: 0.080202, loss_fp: 0.000357, loss_freq: 0.004219
[03:13:27.042] iteration 4285: loss: 0.120874, loss_s1: 0.064177, loss_fp: 0.000795, loss_freq: 0.045858
[03:13:27.636] iteration 4286: loss: 0.204585, loss_s1: 0.047189, loss_fp: 0.000852, loss_freq: 0.010186
[03:13:28.265] iteration 4287: loss: 0.170152, loss_s1: 0.152076, loss_fp: 0.001143, loss_freq: 0.051689
[03:13:28.877] iteration 4288: loss: 0.109333, loss_s1: 0.066379, loss_fp: 0.001972, loss_freq: 0.028501
[03:13:29.492] iteration 4289: loss: 0.225544, loss_s1: 0.235458, loss_fp: 0.000856, loss_freq: 0.074177
[03:13:30.115] iteration 4290: loss: 0.218720, loss_s1: 0.193375, loss_fp: 0.002519, loss_freq: 0.061032
[03:13:30.725] iteration 4291: loss: 0.188753, loss_s1: 0.168270, loss_fp: 0.004880, loss_freq: 0.038004
[03:13:31.333] iteration 4292: loss: 0.161736, loss_s1: 0.065697, loss_fp: 0.002095, loss_freq: 0.062812
[03:13:31.941] iteration 4293: loss: 0.138089, loss_s1: 0.109706, loss_fp: 0.001627, loss_freq: 0.040676
[03:13:32.599] iteration 4294: loss: 0.143461, loss_s1: 0.124457, loss_fp: 0.001269, loss_freq: 0.051998
[03:13:33.195] iteration 4295: loss: 0.150664, loss_s1: 0.073419, loss_fp: 0.001570, loss_freq: 0.030674
[03:13:33.792] iteration 4296: loss: 0.166720, loss_s1: 0.106285, loss_fp: 0.004872, loss_freq: 0.009345
[03:13:34.390] iteration 4297: loss: 0.146767, loss_s1: 0.125204, loss_fp: 0.001300, loss_freq: 0.013375
[03:13:34.986] iteration 4298: loss: 0.117780, loss_s1: 0.049241, loss_fp: 0.008897, loss_freq: 0.013173
[03:13:35.577] iteration 4299: loss: 0.118073, loss_s1: 0.051841, loss_fp: 0.000622, loss_freq: 0.011355
[03:13:36.218] iteration 4300: loss: 0.133295, loss_s1: 0.035075, loss_fp: 0.000953, loss_freq: 0.020161
[03:13:36.816] iteration 4301: loss: 0.154499, loss_s1: 0.089719, loss_fp: 0.003473, loss_freq: 0.064094
[03:13:37.416] iteration 4302: loss: 0.148842, loss_s1: 0.125152, loss_fp: 0.002627, loss_freq: 0.028544
[03:13:38.012] iteration 4303: loss: 0.151817, loss_s1: 0.101449, loss_fp: 0.000830, loss_freq: 0.039431
[03:13:38.612] iteration 4304: loss: 0.279540, loss_s1: 0.243466, loss_fp: 0.017211, loss_freq: 0.103437
[03:13:39.207] iteration 4305: loss: 0.218132, loss_s1: 0.124261, loss_fp: 0.003432, loss_freq: 0.077610
[03:13:39.838] iteration 4306: loss: 0.113986, loss_s1: 0.040881, loss_fp: 0.000686, loss_freq: 0.017117
[03:13:40.462] iteration 4307: loss: 0.150555, loss_s1: 0.143742, loss_fp: 0.000827, loss_freq: 0.020791
[03:13:41.089] iteration 4308: loss: 0.178483, loss_s1: 0.091715, loss_fp: 0.001199, loss_freq: 0.079188
[03:13:41.732] iteration 4309: loss: 0.180930, loss_s1: 0.122483, loss_fp: 0.001979, loss_freq: 0.038787
[03:13:42.359] iteration 4310: loss: 0.163519, loss_s1: 0.075422, loss_fp: 0.000776, loss_freq: 0.056135
[03:13:42.943] iteration 4311: loss: 0.126042, loss_s1: 0.066049, loss_fp: 0.002772, loss_freq: 0.020230
[03:13:43.532] iteration 4312: loss: 0.230513, loss_s1: 0.146407, loss_fp: 0.006016, loss_freq: 0.026740
[03:13:44.122] iteration 4313: loss: 0.108277, loss_s1: 0.061170, loss_fp: 0.001250, loss_freq: 0.006782
[03:13:44.707] iteration 4314: loss: 0.347769, loss_s1: 0.301236, loss_fp: 0.002647, loss_freq: 0.058340
[03:13:45.292] iteration 4315: loss: 0.190949, loss_s1: 0.167378, loss_fp: 0.003066, loss_freq: 0.031259
[03:13:45.875] iteration 4316: loss: 0.141675, loss_s1: 0.066125, loss_fp: 0.032200, loss_freq: 0.034035
[03:13:46.474] iteration 4317: loss: 0.210377, loss_s1: 0.162150, loss_fp: 0.000918, loss_freq: 0.037269
[03:13:47.062] iteration 4318: loss: 0.101881, loss_s1: 0.082459, loss_fp: 0.001263, loss_freq: 0.014345
[03:13:47.655] iteration 4319: loss: 0.172231, loss_s1: 0.142194, loss_fp: 0.000794, loss_freq: 0.017959
[03:13:48.242] iteration 4320: loss: 0.136622, loss_s1: 0.070221, loss_fp: 0.000866, loss_freq: 0.009418
[03:13:48.824] iteration 4321: loss: 0.208886, loss_s1: 0.085581, loss_fp: 0.001373, loss_freq: 0.072698
[03:13:49.410] iteration 4322: loss: 0.118212, loss_s1: 0.030682, loss_fp: 0.011253, loss_freq: 0.028891
[03:13:50.000] iteration 4323: loss: 0.103029, loss_s1: 0.051834, loss_fp: 0.001010, loss_freq: 0.026917
[03:13:50.585] iteration 4324: loss: 0.157026, loss_s1: 0.117641, loss_fp: 0.001335, loss_freq: 0.041677
[03:13:51.172] iteration 4325: loss: 0.240318, loss_s1: 0.127536, loss_fp: 0.006184, loss_freq: 0.059834
[03:13:51.760] iteration 4326: loss: 0.133201, loss_s1: 0.044721, loss_fp: 0.000715, loss_freq: 0.036595
[03:13:52.348] iteration 4327: loss: 0.145245, loss_s1: 0.093303, loss_fp: 0.000808, loss_freq: 0.024230
[03:13:52.938] iteration 4328: loss: 0.184439, loss_s1: 0.062330, loss_fp: 0.002411, loss_freq: 0.043846
[03:13:53.526] iteration 4329: loss: 0.130115, loss_s1: 0.046509, loss_fp: 0.002135, loss_freq: 0.044825
[03:13:54.115] iteration 4330: loss: 0.123372, loss_s1: 0.060540, loss_fp: 0.001213, loss_freq: 0.014724
[03:13:54.713] iteration 4331: loss: 0.183533, loss_s1: 0.059304, loss_fp: 0.008963, loss_freq: 0.094716
[03:13:55.307] iteration 4332: loss: 0.086929, loss_s1: 0.062236, loss_fp: 0.001604, loss_freq: 0.013098
[03:13:55.893] iteration 4333: loss: 0.177213, loss_s1: 0.172082, loss_fp: 0.003165, loss_freq: 0.029143
[03:13:56.492] iteration 4334: loss: 0.152844, loss_s1: 0.065539, loss_fp: 0.000878, loss_freq: 0.018001
[03:13:57.155] iteration 4335: loss: 0.130983, loss_s1: 0.055140, loss_fp: 0.016212, loss_freq: 0.007391
[03:13:57.788] iteration 4336: loss: 0.135287, loss_s1: 0.074618, loss_fp: 0.004161, loss_freq: 0.056771
[03:13:58.421] iteration 4337: loss: 0.169496, loss_s1: 0.179094, loss_fp: 0.000462, loss_freq: 0.059340
[03:13:59.047] iteration 4338: loss: 0.212386, loss_s1: 0.143032, loss_fp: 0.000683, loss_freq: 0.049331
[03:13:59.673] iteration 4339: loss: 0.197171, loss_s1: 0.128768, loss_fp: 0.007726, loss_freq: 0.113084
[03:14:00.303] iteration 4340: loss: 0.159797, loss_s1: 0.129979, loss_fp: 0.015012, loss_freq: 0.016834
[03:14:00.906] iteration 4341: loss: 0.146372, loss_s1: 0.142227, loss_fp: 0.000668, loss_freq: 0.050779
[03:14:01.499] iteration 4342: loss: 0.141301, loss_s1: 0.099449, loss_fp: 0.001571, loss_freq: 0.045101
[03:14:02.102] iteration 4343: loss: 0.201266, loss_s1: 0.153274, loss_fp: 0.002061, loss_freq: 0.049450
[03:14:02.727] iteration 4344: loss: 0.110095, loss_s1: 0.058799, loss_fp: 0.001711, loss_freq: 0.025272
[03:14:03.319] iteration 4345: loss: 0.183415, loss_s1: 0.124580, loss_fp: 0.005197, loss_freq: 0.050639
[03:14:03.948] iteration 4346: loss: 0.119995, loss_s1: 0.060008, loss_fp: 0.002689, loss_freq: 0.064286
[03:14:04.579] iteration 4347: loss: 0.209982, loss_s1: 0.096139, loss_fp: 0.005093, loss_freq: 0.032769
[03:14:05.205] iteration 4348: loss: 0.156798, loss_s1: 0.133415, loss_fp: 0.002183, loss_freq: 0.045799
[03:14:05.836] iteration 4349: loss: 0.148510, loss_s1: 0.074518, loss_fp: 0.000635, loss_freq: 0.031985
[03:14:06.464] iteration 4350: loss: 0.113705, loss_s1: 0.110169, loss_fp: 0.001090, loss_freq: 0.022597
[03:14:07.062] iteration 4351: loss: 0.200428, loss_s1: 0.135526, loss_fp: 0.001072, loss_freq: 0.094939
[03:14:07.658] iteration 4352: loss: 0.246523, loss_s1: 0.113712, loss_fp: 0.003382, loss_freq: 0.030110
[03:14:08.248] iteration 4353: loss: 0.128058, loss_s1: 0.033712, loss_fp: 0.009637, loss_freq: 0.018143
[03:14:08.843] iteration 4354: loss: 0.140519, loss_s1: 0.091411, loss_fp: 0.000555, loss_freq: 0.036984
[03:14:09.444] iteration 4355: loss: 0.163658, loss_s1: 0.172340, loss_fp: 0.000882, loss_freq: 0.039037
[03:14:10.077] iteration 4356: loss: 0.143414, loss_s1: 0.067792, loss_fp: 0.001385, loss_freq: 0.035299
[03:14:10.707] iteration 4357: loss: 0.106998, loss_s1: 0.042499, loss_fp: 0.000550, loss_freq: 0.013507
[03:14:11.337] iteration 4358: loss: 0.115130, loss_s1: 0.074437, loss_fp: 0.000690, loss_freq: 0.016232
[03:14:11.968] iteration 4359: loss: 0.273537, loss_s1: 0.172117, loss_fp: 0.004358, loss_freq: 0.182559
[03:14:12.597] iteration 4360: loss: 0.138216, loss_s1: 0.042921, loss_fp: 0.002152, loss_freq: 0.015474
[03:14:13.231] iteration 4361: loss: 0.190380, loss_s1: 0.054704, loss_fp: 0.001119, loss_freq: 0.038330
[03:14:13.859] iteration 4362: loss: 0.136274, loss_s1: 0.132756, loss_fp: 0.001729, loss_freq: 0.006574
[03:14:14.485] iteration 4363: loss: 0.114775, loss_s1: 0.057937, loss_fp: 0.001152, loss_freq: 0.030855
[03:14:15.078] iteration 4364: loss: 0.192284, loss_s1: 0.090325, loss_fp: 0.001156, loss_freq: 0.081719
[03:14:15.674] iteration 4365: loss: 0.278963, loss_s1: 0.274347, loss_fp: 0.001559, loss_freq: 0.084352
[03:14:16.262] iteration 4366: loss: 0.187062, loss_s1: 0.126432, loss_fp: 0.002581, loss_freq: 0.047331
[03:14:16.855] iteration 4367: loss: 0.200371, loss_s1: 0.054815, loss_fp: 0.000908, loss_freq: 0.094455
[03:14:17.440] iteration 4368: loss: 0.124165, loss_s1: 0.048793, loss_fp: 0.000982, loss_freq: 0.028438
[03:14:18.026] iteration 4369: loss: 0.137565, loss_s1: 0.037441, loss_fp: 0.002781, loss_freq: 0.092941
[03:14:18.678] iteration 4370: loss: 0.151949, loss_s1: 0.070067, loss_fp: 0.002943, loss_freq: 0.017841
[03:14:19.307] iteration 4371: loss: 0.113834, loss_s1: 0.081555, loss_fp: 0.000649, loss_freq: 0.003845
[03:14:19.941] iteration 4372: loss: 0.111728, loss_s1: 0.070447, loss_fp: 0.002408, loss_freq: 0.028573
[03:14:20.557] iteration 4373: loss: 0.152488, loss_s1: 0.078823, loss_fp: 0.001341, loss_freq: 0.065878
[03:14:21.150] iteration 4374: loss: 0.170508, loss_s1: 0.092416, loss_fp: 0.008779, loss_freq: 0.119007
[03:14:21.780] iteration 4375: loss: 0.145489, loss_s1: 0.054151, loss_fp: 0.002845, loss_freq: 0.035181
[03:14:22.408] iteration 4376: loss: 0.134340, loss_s1: 0.140666, loss_fp: 0.000740, loss_freq: 0.006255
[03:14:23.030] iteration 4377: loss: 0.253880, loss_s1: 0.151575, loss_fp: 0.003057, loss_freq: 0.174527
[03:14:23.620] iteration 4378: loss: 0.188185, loss_s1: 0.073665, loss_fp: 0.002204, loss_freq: 0.107243
[03:14:24.211] iteration 4379: loss: 0.135835, loss_s1: 0.048443, loss_fp: 0.000431, loss_freq: 0.026407
[03:14:24.797] iteration 4380: loss: 0.206770, loss_s1: 0.202146, loss_fp: 0.001452, loss_freq: 0.076161
[03:14:25.380] iteration 4381: loss: 0.165175, loss_s1: 0.130612, loss_fp: 0.000541, loss_freq: 0.043414
[03:14:25.970] iteration 4382: loss: 0.176692, loss_s1: 0.078472, loss_fp: 0.003141, loss_freq: 0.029928
[03:14:26.563] iteration 4383: loss: 0.110021, loss_s1: 0.070933, loss_fp: 0.002225, loss_freq: 0.011009
[03:14:27.157] iteration 4384: loss: 0.153335, loss_s1: 0.134214, loss_fp: 0.000909, loss_freq: 0.037418
[03:14:27.750] iteration 4385: loss: 0.193634, loss_s1: 0.231616, loss_fp: 0.001724, loss_freq: 0.024245
[03:14:28.339] iteration 4386: loss: 0.211322, loss_s1: 0.202068, loss_fp: 0.005575, loss_freq: 0.042640
[03:14:28.932] iteration 4387: loss: 0.167990, loss_s1: 0.087848, loss_fp: 0.001713, loss_freq: 0.006148
[03:14:29.521] iteration 4388: loss: 0.104190, loss_s1: 0.061890, loss_fp: 0.001653, loss_freq: 0.013750
[03:14:30.107] iteration 4389: loss: 0.195493, loss_s1: 0.130905, loss_fp: 0.000836, loss_freq: 0.088830
[03:14:30.699] iteration 4390: loss: 0.202068, loss_s1: 0.221656, loss_fp: 0.001736, loss_freq: 0.050052
[03:14:31.300] iteration 4391: loss: 0.172094, loss_s1: 0.132380, loss_fp: 0.015402, loss_freq: 0.041907
[03:14:31.886] iteration 4392: loss: 0.129568, loss_s1: 0.052928, loss_fp: 0.004188, loss_freq: 0.067083
[03:14:32.473] iteration 4393: loss: 0.194919, loss_s1: 0.113058, loss_fp: 0.002677, loss_freq: 0.065326
[03:14:33.069] iteration 4394: loss: 0.138417, loss_s1: 0.084590, loss_fp: 0.001621, loss_freq: 0.035836
[03:14:33.667] iteration 4395: loss: 0.189551, loss_s1: 0.095195, loss_fp: 0.034029, loss_freq: 0.045148
[03:14:34.286] iteration 4396: loss: 0.127281, loss_s1: 0.089052, loss_fp: 0.003412, loss_freq: 0.034154
[03:14:34.876] iteration 4397: loss: 0.148446, loss_s1: 0.084517, loss_fp: 0.004005, loss_freq: 0.040897
[03:14:35.519] iteration 4398: loss: 0.178539, loss_s1: 0.148138, loss_fp: 0.001299, loss_freq: 0.043249
[03:14:36.113] iteration 4399: loss: 0.243812, loss_s1: 0.222274, loss_fp: 0.001092, loss_freq: 0.060054
[03:14:36.710] iteration 4400: loss: 0.122323, loss_s1: 0.063623, loss_fp: 0.001581, loss_freq: 0.030140
[03:14:39.744] iteration 4400 : mean_dice : 0.527791
[03:14:40.379] iteration 4401: loss: 0.136892, loss_s1: 0.089588, loss_fp: 0.002228, loss_freq: 0.022570
[03:14:40.968] iteration 4402: loss: 0.143654, loss_s1: 0.095907, loss_fp: 0.001088, loss_freq: 0.031535
[03:14:41.568] iteration 4403: loss: 0.193293, loss_s1: 0.075233, loss_fp: 0.056039, loss_freq: 0.020652
[03:14:42.161] iteration 4404: loss: 0.138694, loss_s1: 0.108451, loss_fp: 0.002127, loss_freq: 0.033391
[03:14:42.757] iteration 4405: loss: 0.248135, loss_s1: 0.163255, loss_fp: 0.001996, loss_freq: 0.064187
[03:14:43.396] iteration 4406: loss: 0.157020, loss_s1: 0.114025, loss_fp: 0.001272, loss_freq: 0.006516
[03:14:44.043] iteration 4407: loss: 0.100186, loss_s1: 0.021736, loss_fp: 0.001519, loss_freq: 0.014244
[03:14:44.664] iteration 4408: loss: 0.144659, loss_s1: 0.080243, loss_fp: 0.002417, loss_freq: 0.032010
[03:14:45.286] iteration 4409: loss: 0.103976, loss_s1: 0.033578, loss_fp: 0.005950, loss_freq: 0.032403
[03:14:45.874] iteration 4410: loss: 0.162201, loss_s1: 0.154964, loss_fp: 0.000642, loss_freq: 0.015188
[03:14:46.472] iteration 4411: loss: 0.135681, loss_s1: 0.092631, loss_fp: 0.000827, loss_freq: 0.010187
[03:14:47.062] iteration 4412: loss: 0.159810, loss_s1: 0.141330, loss_fp: 0.001512, loss_freq: 0.035549
[03:14:47.658] iteration 4413: loss: 0.159522, loss_s1: 0.080407, loss_fp: 0.001625, loss_freq: 0.079723
[03:14:48.248] iteration 4414: loss: 0.098480, loss_s1: 0.075441, loss_fp: 0.000809, loss_freq: 0.023960
[03:14:48.838] iteration 4415: loss: 0.133495, loss_s1: 0.095578, loss_fp: 0.000743, loss_freq: 0.013785
[03:14:49.426] iteration 4416: loss: 0.183949, loss_s1: 0.102838, loss_fp: 0.000663, loss_freq: 0.095058
[03:14:50.019] iteration 4417: loss: 0.185581, loss_s1: 0.107632, loss_fp: 0.001397, loss_freq: 0.042747
[03:14:50.609] iteration 4418: loss: 0.112063, loss_s1: 0.036830, loss_fp: 0.001245, loss_freq: 0.005664
[03:14:51.193] iteration 4419: loss: 0.141669, loss_s1: 0.064765, loss_fp: 0.001918, loss_freq: 0.041255
[03:14:51.781] iteration 4420: loss: 0.198817, loss_s1: 0.167906, loss_fp: 0.000615, loss_freq: 0.117402
[03:14:52.772] iteration 4421: loss: 0.138659, loss_s1: 0.071951, loss_fp: 0.001139, loss_freq: 0.015773
[03:14:53.397] iteration 4422: loss: 0.183815, loss_s1: 0.199683, loss_fp: 0.000679, loss_freq: 0.028556
[03:14:54.024] iteration 4423: loss: 0.144631, loss_s1: 0.070342, loss_fp: 0.016711, loss_freq: 0.063869
[03:14:54.662] iteration 4424: loss: 0.123432, loss_s1: 0.096211, loss_fp: 0.001701, loss_freq: 0.008534
[03:14:55.299] iteration 4425: loss: 0.144364, loss_s1: 0.049564, loss_fp: 0.000653, loss_freq: 0.042309
[03:14:55.930] iteration 4426: loss: 0.197993, loss_s1: 0.039000, loss_fp: 0.001382, loss_freq: 0.044818
[03:14:56.567] iteration 4427: loss: 0.262891, loss_s1: 0.177567, loss_fp: 0.004075, loss_freq: 0.025476
[03:14:57.167] iteration 4428: loss: 0.145150, loss_s1: 0.074458, loss_fp: 0.003399, loss_freq: 0.043571
[03:14:57.758] iteration 4429: loss: 0.101185, loss_s1: 0.052147, loss_fp: 0.000462, loss_freq: 0.014099
[03:14:58.347] iteration 4430: loss: 0.112619, loss_s1: 0.070313, loss_fp: 0.000733, loss_freq: 0.009969
[03:14:58.978] iteration 4431: loss: 0.148381, loss_s1: 0.040487, loss_fp: 0.000706, loss_freq: 0.083313
[03:14:59.623] iteration 4432: loss: 0.170848, loss_s1: 0.113762, loss_fp: 0.000536, loss_freq: 0.034442
[03:15:00.252] iteration 4433: loss: 0.159262, loss_s1: 0.052355, loss_fp: 0.001246, loss_freq: 0.045665
[03:15:00.885] iteration 4434: loss: 0.147186, loss_s1: 0.046121, loss_fp: 0.003083, loss_freq: 0.072382
[03:15:01.520] iteration 4435: loss: 0.146706, loss_s1: 0.085278, loss_fp: 0.002931, loss_freq: 0.011750
[03:15:02.149] iteration 4436: loss: 0.130559, loss_s1: 0.040246, loss_fp: 0.006074, loss_freq: 0.025937
[03:15:02.777] iteration 4437: loss: 0.176663, loss_s1: 0.107159, loss_fp: 0.001844, loss_freq: 0.094386
[03:15:03.374] iteration 4438: loss: 0.159660, loss_s1: 0.050925, loss_fp: 0.000944, loss_freq: 0.008777
[03:15:03.964] iteration 4439: loss: 0.105910, loss_s1: 0.090330, loss_fp: 0.000601, loss_freq: 0.020949
[03:15:04.576] iteration 4440: loss: 0.145225, loss_s1: 0.082431, loss_fp: 0.018082, loss_freq: 0.031721
[03:15:05.187] iteration 4441: loss: 0.127104, loss_s1: 0.089578, loss_fp: 0.003880, loss_freq: 0.019697
[03:15:05.822] iteration 4442: loss: 0.160288, loss_s1: 0.071624, loss_fp: 0.000691, loss_freq: 0.013333
[03:15:06.425] iteration 4443: loss: 0.156679, loss_s1: 0.078376, loss_fp: 0.000654, loss_freq: 0.018738
[03:15:07.012] iteration 4444: loss: 0.188765, loss_s1: 0.121392, loss_fp: 0.000705, loss_freq: 0.063949
[03:15:07.602] iteration 4445: loss: 0.075391, loss_s1: 0.029001, loss_fp: 0.000481, loss_freq: 0.007880
[03:15:08.196] iteration 4446: loss: 0.211424, loss_s1: 0.188926, loss_fp: 0.000598, loss_freq: 0.023222
[03:15:08.788] iteration 4447: loss: 0.133938, loss_s1: 0.044142, loss_fp: 0.002789, loss_freq: 0.019670
[03:15:09.379] iteration 4448: loss: 0.237730, loss_s1: 0.144379, loss_fp: 0.000954, loss_freq: 0.144281
[03:15:09.969] iteration 4449: loss: 0.155857, loss_s1: 0.095627, loss_fp: 0.000674, loss_freq: 0.010742
[03:15:10.562] iteration 4450: loss: 0.135354, loss_s1: 0.150379, loss_fp: 0.001814, loss_freq: 0.017182
[03:15:11.149] iteration 4451: loss: 0.164083, loss_s1: 0.088713, loss_fp: 0.001367, loss_freq: 0.041657
[03:15:11.737] iteration 4452: loss: 0.164684, loss_s1: 0.082697, loss_fp: 0.004677, loss_freq: 0.028399
[03:15:12.328] iteration 4453: loss: 0.114261, loss_s1: 0.062778, loss_fp: 0.001381, loss_freq: 0.018535
[03:15:12.921] iteration 4454: loss: 0.081323, loss_s1: 0.037650, loss_fp: 0.000765, loss_freq: 0.010406
[03:15:13.517] iteration 4455: loss: 0.120209, loss_s1: 0.065191, loss_fp: 0.004347, loss_freq: 0.025574
[03:15:14.115] iteration 4456: loss: 0.122853, loss_s1: 0.072031, loss_fp: 0.006293, loss_freq: 0.018453
[03:15:14.713] iteration 4457: loss: 0.135824, loss_s1: 0.080645, loss_fp: 0.016598, loss_freq: 0.022423
[03:15:15.311] iteration 4458: loss: 0.157721, loss_s1: 0.114091, loss_fp: 0.000960, loss_freq: 0.021935
[03:15:15.895] iteration 4459: loss: 0.147418, loss_s1: 0.082410, loss_fp: 0.000854, loss_freq: 0.047087
[03:15:16.505] iteration 4460: loss: 0.189836, loss_s1: 0.100962, loss_fp: 0.003169, loss_freq: 0.053623
[03:15:17.138] iteration 4461: loss: 0.192804, loss_s1: 0.189399, loss_fp: 0.000716, loss_freq: 0.025800
[03:15:17.770] iteration 4462: loss: 0.187734, loss_s1: 0.111532, loss_fp: 0.002858, loss_freq: 0.046726
[03:15:18.399] iteration 4463: loss: 0.130777, loss_s1: 0.061031, loss_fp: 0.007522, loss_freq: 0.028667
[03:15:19.028] iteration 4464: loss: 0.165772, loss_s1: 0.071760, loss_fp: 0.001498, loss_freq: 0.066221
[03:15:19.623] iteration 4465: loss: 0.132149, loss_s1: 0.061453, loss_fp: 0.003343, loss_freq: 0.028993
[03:15:20.211] iteration 4466: loss: 0.124226, loss_s1: 0.059621, loss_fp: 0.001724, loss_freq: 0.036592
[03:15:20.801] iteration 4467: loss: 0.122398, loss_s1: 0.051348, loss_fp: 0.001555, loss_freq: 0.010874
[03:15:21.397] iteration 4468: loss: 0.127931, loss_s1: 0.030780, loss_fp: 0.009462, loss_freq: 0.019129
[03:15:21.989] iteration 4469: loss: 0.105766, loss_s1: 0.049706, loss_fp: 0.000429, loss_freq: 0.007590
[03:15:22.582] iteration 4470: loss: 0.133013, loss_s1: 0.047964, loss_fp: 0.014953, loss_freq: 0.029107
[03:15:23.171] iteration 4471: loss: 0.146169, loss_s1: 0.129087, loss_fp: 0.001606, loss_freq: 0.051199
[03:15:23.761] iteration 4472: loss: 0.149667, loss_s1: 0.109829, loss_fp: 0.004527, loss_freq: 0.079497
[03:15:24.351] iteration 4473: loss: 0.177179, loss_s1: 0.102155, loss_fp: 0.002806, loss_freq: 0.086871
[03:15:24.949] iteration 4474: loss: 0.199843, loss_s1: 0.125390, loss_fp: 0.013000, loss_freq: 0.146488
[03:15:25.545] iteration 4475: loss: 0.180730, loss_s1: 0.062607, loss_fp: 0.002821, loss_freq: 0.103442
[03:15:26.147] iteration 4476: loss: 0.161182, loss_s1: 0.099105, loss_fp: 0.001552, loss_freq: 0.034826
[03:15:26.742] iteration 4477: loss: 0.088415, loss_s1: 0.041688, loss_fp: 0.001538, loss_freq: 0.021956
[03:15:27.338] iteration 4478: loss: 0.177241, loss_s1: 0.095904, loss_fp: 0.007437, loss_freq: 0.037040
[03:15:27.928] iteration 4479: loss: 0.188282, loss_s1: 0.124828, loss_fp: 0.007597, loss_freq: 0.030810
[03:15:28.517] iteration 4480: loss: 0.233583, loss_s1: 0.193466, loss_fp: 0.011689, loss_freq: 0.088028
[03:15:29.105] iteration 4481: loss: 0.126599, loss_s1: 0.110702, loss_fp: 0.000914, loss_freq: 0.019150
[03:15:29.695] iteration 4482: loss: 0.183241, loss_s1: 0.068567, loss_fp: 0.003945, loss_freq: 0.042460
[03:15:30.284] iteration 4483: loss: 0.104807, loss_s1: 0.057896, loss_fp: 0.000966, loss_freq: 0.018390
[03:15:30.882] iteration 4484: loss: 0.186940, loss_s1: 0.126384, loss_fp: 0.004482, loss_freq: 0.057543
[03:15:31.475] iteration 4485: loss: 0.174303, loss_s1: 0.101228, loss_fp: 0.000629, loss_freq: 0.039813
[03:15:32.066] iteration 4486: loss: 0.163466, loss_s1: 0.168037, loss_fp: 0.001072, loss_freq: 0.021395
[03:15:32.659] iteration 4487: loss: 0.222299, loss_s1: 0.049191, loss_fp: 0.002931, loss_freq: 0.030493
[03:15:33.460] iteration 4488: loss: 0.144463, loss_s1: 0.094240, loss_fp: 0.000793, loss_freq: 0.029428
[03:15:34.064] iteration 4489: loss: 0.116667, loss_s1: 0.039705, loss_fp: 0.001259, loss_freq: 0.012679
[03:15:35.002] iteration 4490: loss: 0.097178, loss_s1: 0.075337, loss_fp: 0.000659, loss_freq: 0.010155
[03:15:35.799] iteration 4491: loss: 0.160880, loss_s1: 0.078733, loss_fp: 0.001112, loss_freq: 0.046478
[03:15:36.387] iteration 4492: loss: 0.140738, loss_s1: 0.109631, loss_fp: 0.000574, loss_freq: 0.003752
[03:15:36.974] iteration 4493: loss: 0.149903, loss_s1: 0.097958, loss_fp: 0.000671, loss_freq: 0.025496
[03:15:37.555] iteration 4494: loss: 0.123957, loss_s1: 0.055821, loss_fp: 0.002846, loss_freq: 0.037886
[03:15:38.145] iteration 4495: loss: 0.208118, loss_s1: 0.077335, loss_fp: 0.001201, loss_freq: 0.042680
[03:15:38.735] iteration 4496: loss: 0.197612, loss_s1: 0.139837, loss_fp: 0.001636, loss_freq: 0.041745
[03:15:39.328] iteration 4497: loss: 0.139374, loss_s1: 0.116137, loss_fp: 0.001032, loss_freq: 0.016122
[03:15:39.916] iteration 4498: loss: 0.155868, loss_s1: 0.080771, loss_fp: 0.002081, loss_freq: 0.018754
[03:15:40.503] iteration 4499: loss: 0.156095, loss_s1: 0.049953, loss_fp: 0.012344, loss_freq: 0.044958
[03:15:41.092] iteration 4500: loss: 0.106102, loss_s1: 0.034893, loss_fp: 0.003071, loss_freq: 0.009967
[03:15:41.683] iteration 4501: loss: 0.183039, loss_s1: 0.157465, loss_fp: 0.004135, loss_freq: 0.055610
[03:15:42.272] iteration 4502: loss: 0.115083, loss_s1: 0.085670, loss_fp: 0.001230, loss_freq: 0.022355
[03:15:42.860] iteration 4503: loss: 0.221439, loss_s1: 0.207797, loss_fp: 0.003717, loss_freq: 0.027468
[03:15:43.451] iteration 4504: loss: 0.134178, loss_s1: 0.077497, loss_fp: 0.005711, loss_freq: 0.032548
[03:15:44.044] iteration 4505: loss: 0.137787, loss_s1: 0.079476, loss_fp: 0.000878, loss_freq: 0.022435
[03:15:44.641] iteration 4506: loss: 0.131410, loss_s1: 0.054925, loss_fp: 0.005154, loss_freq: 0.077159
[03:15:45.225] iteration 4507: loss: 0.138387, loss_s1: 0.069708, loss_fp: 0.003109, loss_freq: 0.078096
[03:15:45.851] iteration 4508: loss: 0.213608, loss_s1: 0.168581, loss_fp: 0.004733, loss_freq: 0.033942
[03:15:46.441] iteration 4509: loss: 0.141279, loss_s1: 0.096562, loss_fp: 0.006979, loss_freq: 0.054641
[03:15:47.037] iteration 4510: loss: 0.183004, loss_s1: 0.138755, loss_fp: 0.003339, loss_freq: 0.064291
[03:15:47.632] iteration 4511: loss: 0.112427, loss_s1: 0.050396, loss_fp: 0.000614, loss_freq: 0.030410
[03:15:48.226] iteration 4512: loss: 0.144970, loss_s1: 0.074944, loss_fp: 0.003168, loss_freq: 0.079456
[03:15:48.819] iteration 4513: loss: 0.123616, loss_s1: 0.041256, loss_fp: 0.005987, loss_freq: 0.026128
[03:15:49.426] iteration 4514: loss: 0.113799, loss_s1: 0.053985, loss_fp: 0.000732, loss_freq: 0.018815
[03:15:50.011] iteration 4515: loss: 0.126410, loss_s1: 0.114337, loss_fp: 0.000616, loss_freq: 0.014857
[03:15:50.600] iteration 4516: loss: 0.108344, loss_s1: 0.087445, loss_fp: 0.003635, loss_freq: 0.025414
[03:15:51.187] iteration 4517: loss: 0.146461, loss_s1: 0.041957, loss_fp: 0.000927, loss_freq: 0.058681
[03:15:51.774] iteration 4518: loss: 0.114351, loss_s1: 0.080901, loss_fp: 0.000968, loss_freq: 0.007674
[03:15:52.366] iteration 4519: loss: 0.123925, loss_s1: 0.068115, loss_fp: 0.000573, loss_freq: 0.033889
[03:15:52.960] iteration 4520: loss: 0.099126, loss_s1: 0.083982, loss_fp: 0.000639, loss_freq: 0.013301
[03:15:53.549] iteration 4521: loss: 0.219373, loss_s1: 0.182618, loss_fp: 0.019424, loss_freq: 0.109989
[03:15:54.133] iteration 4522: loss: 0.135701, loss_s1: 0.037366, loss_fp: 0.002894, loss_freq: 0.026820
[03:15:54.733] iteration 4523: loss: 0.112852, loss_s1: 0.040076, loss_fp: 0.000432, loss_freq: 0.015329
[03:15:55.320] iteration 4524: loss: 0.129313, loss_s1: 0.021693, loss_fp: 0.001341, loss_freq: 0.042640
[03:15:55.907] iteration 4525: loss: 0.133359, loss_s1: 0.094429, loss_fp: 0.001060, loss_freq: 0.037558
[03:15:56.495] iteration 4526: loss: 0.145441, loss_s1: 0.068274, loss_fp: 0.001715, loss_freq: 0.040499
[03:15:57.084] iteration 4527: loss: 0.111836, loss_s1: 0.045233, loss_fp: 0.007942, loss_freq: 0.043504
[03:15:57.670] iteration 4528: loss: 0.179539, loss_s1: 0.187142, loss_fp: 0.000660, loss_freq: 0.020892
[03:15:58.260] iteration 4529: loss: 0.206401, loss_s1: 0.126610, loss_fp: 0.001220, loss_freq: 0.151867
[03:15:58.843] iteration 4530: loss: 0.133828, loss_s1: 0.081834, loss_fp: 0.005059, loss_freq: 0.012148
[03:15:59.432] iteration 4531: loss: 0.240346, loss_s1: 0.142714, loss_fp: 0.002238, loss_freq: 0.039409
[03:16:00.016] iteration 4532: loss: 0.169972, loss_s1: 0.116309, loss_fp: 0.008801, loss_freq: 0.017233
[03:16:00.604] iteration 4533: loss: 0.119958, loss_s1: 0.082626, loss_fp: 0.002704, loss_freq: 0.014909
[03:16:01.196] iteration 4534: loss: 0.101787, loss_s1: 0.053175, loss_fp: 0.000470, loss_freq: 0.036992
[03:16:01.780] iteration 4535: loss: 0.331736, loss_s1: 0.294626, loss_fp: 0.007895, loss_freq: 0.172885
[03:16:02.371] iteration 4536: loss: 0.191106, loss_s1: 0.113681, loss_fp: 0.013174, loss_freq: 0.125589
[03:16:02.966] iteration 4537: loss: 0.194893, loss_s1: 0.106784, loss_fp: 0.005459, loss_freq: 0.075964
[03:16:03.555] iteration 4538: loss: 0.139636, loss_s1: 0.152477, loss_fp: 0.002428, loss_freq: 0.015325
[03:16:04.145] iteration 4539: loss: 0.267190, loss_s1: 0.233647, loss_fp: 0.000934, loss_freq: 0.120349
[03:16:04.806] iteration 4540: loss: 0.185396, loss_s1: 0.104270, loss_fp: 0.000385, loss_freq: 0.022860
[03:16:05.437] iteration 4541: loss: 0.098726, loss_s1: 0.069051, loss_fp: 0.001029, loss_freq: 0.004754
[03:16:06.025] iteration 4542: loss: 0.090004, loss_s1: 0.045283, loss_fp: 0.000830, loss_freq: 0.016576
[03:16:06.608] iteration 4543: loss: 0.153501, loss_s1: 0.093559, loss_fp: 0.006857, loss_freq: 0.056047
[03:16:07.194] iteration 4544: loss: 0.135251, loss_s1: 0.125682, loss_fp: 0.002614, loss_freq: 0.022112
[03:16:07.787] iteration 4545: loss: 0.127960, loss_s1: 0.076477, loss_fp: 0.001533, loss_freq: 0.025299
[03:16:08.371] iteration 4546: loss: 0.146207, loss_s1: 0.059683, loss_fp: 0.000547, loss_freq: 0.017250
[03:16:08.959] iteration 4547: loss: 0.220109, loss_s1: 0.221855, loss_fp: 0.003679, loss_freq: 0.040321
[03:16:09.554] iteration 4548: loss: 0.230369, loss_s1: 0.104575, loss_fp: 0.002059, loss_freq: 0.126208
[03:16:10.142] iteration 4549: loss: 0.138031, loss_s1: 0.109921, loss_fp: 0.000564, loss_freq: 0.007406
[03:16:10.730] iteration 4550: loss: 0.159721, loss_s1: 0.156696, loss_fp: 0.000929, loss_freq: 0.017844
[03:16:11.318] iteration 4551: loss: 0.187838, loss_s1: 0.145946, loss_fp: 0.001618, loss_freq: 0.076695
[03:16:11.906] iteration 4552: loss: 0.205023, loss_s1: 0.064739, loss_fp: 0.004653, loss_freq: 0.048503
[03:16:12.492] iteration 4553: loss: 0.106927, loss_s1: 0.022177, loss_fp: 0.000515, loss_freq: 0.023382
[03:16:13.081] iteration 4554: loss: 0.181842, loss_s1: 0.162805, loss_fp: 0.002623, loss_freq: 0.030882
[03:16:13.671] iteration 4555: loss: 0.145621, loss_s1: 0.093171, loss_fp: 0.012339, loss_freq: 0.078055
[03:16:14.264] iteration 4556: loss: 0.124053, loss_s1: 0.071262, loss_fp: 0.002518, loss_freq: 0.048653
[03:16:14.851] iteration 4557: loss: 0.149467, loss_s1: 0.068973, loss_fp: 0.000677, loss_freq: 0.007062
[03:16:15.440] iteration 4558: loss: 0.164423, loss_s1: 0.107521, loss_fp: 0.001134, loss_freq: 0.032819
[03:16:16.030] iteration 4559: loss: 0.149201, loss_s1: 0.125574, loss_fp: 0.012678, loss_freq: 0.038079
[03:16:16.661] iteration 4560: loss: 0.182933, loss_s1: 0.119622, loss_fp: 0.003378, loss_freq: 0.111954
[03:16:17.257] iteration 4561: loss: 0.129275, loss_s1: 0.060660, loss_fp: 0.000921, loss_freq: 0.029467
[03:16:17.850] iteration 4562: loss: 0.122071, loss_s1: 0.084872, loss_fp: 0.005534, loss_freq: 0.030297
[03:16:18.447] iteration 4563: loss: 0.114998, loss_s1: 0.085458, loss_fp: 0.001030, loss_freq: 0.030762
[03:16:19.044] iteration 4564: loss: 0.117941, loss_s1: 0.048448, loss_fp: 0.000895, loss_freq: 0.009653
[03:16:19.643] iteration 4565: loss: 0.164312, loss_s1: 0.104930, loss_fp: 0.011140, loss_freq: 0.054566
[03:16:20.245] iteration 4566: loss: 0.163964, loss_s1: 0.084343, loss_fp: 0.001606, loss_freq: 0.028556
[03:16:20.834] iteration 4567: loss: 0.121415, loss_s1: 0.038202, loss_fp: 0.009787, loss_freq: 0.054674
[03:16:21.425] iteration 4568: loss: 0.225975, loss_s1: 0.115493, loss_fp: 0.003734, loss_freq: 0.055159
[03:16:22.018] iteration 4569: loss: 0.146977, loss_s1: 0.088685, loss_fp: 0.001381, loss_freq: 0.062643
[03:16:22.608] iteration 4570: loss: 0.120421, loss_s1: 0.059692, loss_fp: 0.001030, loss_freq: 0.029877
[03:16:23.197] iteration 4571: loss: 0.123877, loss_s1: 0.062451, loss_fp: 0.001397, loss_freq: 0.025421
[03:16:23.789] iteration 4572: loss: 0.117118, loss_s1: 0.071958, loss_fp: 0.002010, loss_freq: 0.021340
[03:16:24.380] iteration 4573: loss: 0.138157, loss_s1: 0.095860, loss_fp: 0.003386, loss_freq: 0.053604
[03:16:24.974] iteration 4574: loss: 0.137509, loss_s1: 0.081470, loss_fp: 0.010357, loss_freq: 0.030351
[03:16:25.566] iteration 4575: loss: 0.212396, loss_s1: 0.116981, loss_fp: 0.004013, loss_freq: 0.077595
[03:16:26.156] iteration 4576: loss: 0.083777, loss_s1: 0.038950, loss_fp: 0.001233, loss_freq: 0.025871
[03:16:26.746] iteration 4577: loss: 0.102192, loss_s1: 0.041096, loss_fp: 0.002191, loss_freq: 0.027828
[03:16:27.331] iteration 4578: loss: 0.131132, loss_s1: 0.047160, loss_fp: 0.000777, loss_freq: 0.047701
[03:16:27.916] iteration 4579: loss: 0.099934, loss_s1: 0.081841, loss_fp: 0.000683, loss_freq: 0.017151
[03:16:28.512] iteration 4580: loss: 0.150825, loss_s1: 0.118244, loss_fp: 0.000714, loss_freq: 0.033648
[03:16:29.101] iteration 4581: loss: 0.103729, loss_s1: 0.050744, loss_fp: 0.002323, loss_freq: 0.019259
[03:16:29.695] iteration 4582: loss: 0.149929, loss_s1: 0.089031, loss_fp: 0.006927, loss_freq: 0.017082
[03:16:30.284] iteration 4583: loss: 0.142002, loss_s1: 0.010847, loss_fp: 0.003560, loss_freq: 0.031629
[03:16:30.873] iteration 4584: loss: 0.176305, loss_s1: 0.140441, loss_fp: 0.000893, loss_freq: 0.023813
[03:16:31.465] iteration 4585: loss: 0.123679, loss_s1: 0.144727, loss_fp: 0.002950, loss_freq: 0.015927
[03:16:32.056] iteration 4586: loss: 0.133629, loss_s1: 0.092139, loss_fp: 0.000943, loss_freq: 0.051989
[03:16:32.648] iteration 4587: loss: 0.129306, loss_s1: 0.097948, loss_fp: 0.001120, loss_freq: 0.025546
[03:16:33.239] iteration 4588: loss: 0.102340, loss_s1: 0.061773, loss_fp: 0.001825, loss_freq: 0.005745
[03:16:33.828] iteration 4589: loss: 0.212943, loss_s1: 0.127817, loss_fp: 0.002599, loss_freq: 0.063378
[03:16:34.415] iteration 4590: loss: 0.208550, loss_s1: 0.190622, loss_fp: 0.002634, loss_freq: 0.119126
[03:16:35.367] iteration 4591: loss: 0.106252, loss_s1: 0.030899, loss_fp: 0.000545, loss_freq: 0.020866
[03:16:35.997] iteration 4592: loss: 0.109903, loss_s1: 0.090250, loss_fp: 0.001243, loss_freq: 0.016977
[03:16:36.624] iteration 4593: loss: 0.165252, loss_s1: 0.150236, loss_fp: 0.003218, loss_freq: 0.042653
[03:16:37.245] iteration 4594: loss: 0.120268, loss_s1: 0.058929, loss_fp: 0.001700, loss_freq: 0.018495
[03:16:37.833] iteration 4595: loss: 0.149507, loss_s1: 0.137863, loss_fp: 0.000750, loss_freq: 0.024483
[03:16:38.423] iteration 4596: loss: 0.102590, loss_s1: 0.054168, loss_fp: 0.000682, loss_freq: 0.015798
[03:16:39.010] iteration 4597: loss: 0.160877, loss_s1: 0.116747, loss_fp: 0.004891, loss_freq: 0.067510
[03:16:39.608] iteration 4598: loss: 0.132680, loss_s1: 0.081916, loss_fp: 0.001400, loss_freq: 0.045235
[03:16:40.204] iteration 4599: loss: 0.171101, loss_s1: 0.113538, loss_fp: 0.002183, loss_freq: 0.032738
[03:16:40.795] iteration 4600: loss: 0.121019, loss_s1: 0.080865, loss_fp: 0.000483, loss_freq: 0.047420
[03:16:44.093] iteration 4600 : mean_dice : 0.560233
[03:16:44.749] iteration 4601: loss: 0.166080, loss_s1: 0.124032, loss_fp: 0.005857, loss_freq: 0.038820
[03:16:45.352] iteration 4602: loss: 0.123647, loss_s1: 0.075410, loss_fp: 0.000781, loss_freq: 0.080324
[03:16:45.942] iteration 4603: loss: 0.093487, loss_s1: 0.051011, loss_fp: 0.000788, loss_freq: 0.011763
[03:16:46.531] iteration 4604: loss: 0.120607, loss_s1: 0.079924, loss_fp: 0.006521, loss_freq: 0.013363
[03:16:47.124] iteration 4605: loss: 0.188056, loss_s1: 0.105795, loss_fp: 0.002557, loss_freq: 0.027500
[03:16:47.716] iteration 4606: loss: 0.141686, loss_s1: 0.111139, loss_fp: 0.003989, loss_freq: 0.017880
[03:16:48.309] iteration 4607: loss: 0.217779, loss_s1: 0.234839, loss_fp: 0.001588, loss_freq: 0.066470
[03:16:48.927] iteration 4608: loss: 0.115841, loss_s1: 0.025604, loss_fp: 0.001298, loss_freq: 0.030340
[03:16:49.521] iteration 4609: loss: 0.118908, loss_s1: 0.118355, loss_fp: 0.006486, loss_freq: 0.040090
[03:16:50.120] iteration 4610: loss: 0.145316, loss_s1: 0.096579, loss_fp: 0.000862, loss_freq: 0.029485
[03:16:50.713] iteration 4611: loss: 0.153249, loss_s1: 0.172839, loss_fp: 0.001004, loss_freq: 0.018487
[03:16:51.301] iteration 4612: loss: 0.164365, loss_s1: 0.057128, loss_fp: 0.001157, loss_freq: 0.023956
[03:16:51.893] iteration 4613: loss: 0.184397, loss_s1: 0.058578, loss_fp: 0.001564, loss_freq: 0.020630
[03:16:52.498] iteration 4614: loss: 0.170637, loss_s1: 0.133281, loss_fp: 0.002134, loss_freq: 0.051817
[03:16:53.103] iteration 4615: loss: 0.123969, loss_s1: 0.101057, loss_fp: 0.000301, loss_freq: 0.011849
[03:16:53.702] iteration 4616: loss: 0.115017, loss_s1: 0.074376, loss_fp: 0.000666, loss_freq: 0.046445
[03:16:54.290] iteration 4617: loss: 0.141385, loss_s1: 0.098461, loss_fp: 0.002638, loss_freq: 0.011532
[03:16:54.879] iteration 4618: loss: 0.172817, loss_s1: 0.115585, loss_fp: 0.006639, loss_freq: 0.063467
[03:16:55.474] iteration 4619: loss: 0.167824, loss_s1: 0.088561, loss_fp: 0.003235, loss_freq: 0.028221
[03:16:56.057] iteration 4620: loss: 0.137655, loss_s1: 0.136888, loss_fp: 0.003668, loss_freq: 0.044901
[03:16:56.647] iteration 4621: loss: 0.114399, loss_s1: 0.074970, loss_fp: 0.002643, loss_freq: 0.030982
[03:16:57.235] iteration 4622: loss: 0.159701, loss_s1: 0.095099, loss_fp: 0.002274, loss_freq: 0.063320
[03:16:57.822] iteration 4623: loss: 0.130425, loss_s1: 0.030015, loss_fp: 0.004478, loss_freq: 0.025065
[03:16:58.414] iteration 4624: loss: 0.076018, loss_s1: 0.028083, loss_fp: 0.000823, loss_freq: 0.014090
[03:16:58.998] iteration 4625: loss: 0.143779, loss_s1: 0.127148, loss_fp: 0.001783, loss_freq: 0.042995
[03:16:59.590] iteration 4626: loss: 0.123923, loss_s1: 0.073073, loss_fp: 0.000301, loss_freq: 0.008932
[03:17:00.186] iteration 4627: loss: 0.134169, loss_s1: 0.051293, loss_fp: 0.005070, loss_freq: 0.038825
[03:17:00.778] iteration 4628: loss: 0.105560, loss_s1: 0.063630, loss_fp: 0.001952, loss_freq: 0.046064
[03:17:01.367] iteration 4629: loss: 0.154209, loss_s1: 0.107670, loss_fp: 0.008453, loss_freq: 0.040442
[03:17:01.953] iteration 4630: loss: 0.165054, loss_s1: 0.108046, loss_fp: 0.005203, loss_freq: 0.069192
[03:17:02.543] iteration 4631: loss: 0.195109, loss_s1: 0.145959, loss_fp: 0.000832, loss_freq: 0.081405
[03:17:03.127] iteration 4632: loss: 0.143416, loss_s1: 0.131463, loss_fp: 0.001870, loss_freq: 0.040427
[03:17:03.720] iteration 4633: loss: 0.137248, loss_s1: 0.091300, loss_fp: 0.007396, loss_freq: 0.027759
[03:17:04.317] iteration 4634: loss: 0.124897, loss_s1: 0.041648, loss_fp: 0.001208, loss_freq: 0.076573
[03:17:04.913] iteration 4635: loss: 0.134194, loss_s1: 0.023774, loss_fp: 0.001920, loss_freq: 0.035819
[03:17:05.501] iteration 4636: loss: 0.136565, loss_s1: 0.106535, loss_fp: 0.000923, loss_freq: 0.018464
[03:17:06.093] iteration 4637: loss: 0.103964, loss_s1: 0.082096, loss_fp: 0.003390, loss_freq: 0.006767
[03:17:06.690] iteration 4638: loss: 0.144822, loss_s1: 0.105157, loss_fp: 0.000611, loss_freq: 0.025003
[03:17:07.287] iteration 4639: loss: 0.143401, loss_s1: 0.064861, loss_fp: 0.001022, loss_freq: 0.019874
[03:17:07.883] iteration 4640: loss: 0.152869, loss_s1: 0.052680, loss_fp: 0.002265, loss_freq: 0.034615
[03:17:08.484] iteration 4641: loss: 0.146312, loss_s1: 0.094168, loss_fp: 0.004684, loss_freq: 0.088788
[03:17:09.129] iteration 4642: loss: 0.112829, loss_s1: 0.105291, loss_fp: 0.000671, loss_freq: 0.025592
[03:17:09.775] iteration 4643: loss: 0.144481, loss_s1: 0.061629, loss_fp: 0.003935, loss_freq: 0.080960
[03:17:10.372] iteration 4644: loss: 0.282204, loss_s1: 0.382552, loss_fp: 0.000601, loss_freq: 0.076280
[03:17:10.971] iteration 4645: loss: 0.191895, loss_s1: 0.106844, loss_fp: 0.014626, loss_freq: 0.089367
[03:17:11.601] iteration 4646: loss: 0.101719, loss_s1: 0.075052, loss_fp: 0.004117, loss_freq: 0.019156
[03:17:12.229] iteration 4647: loss: 0.122414, loss_s1: 0.090380, loss_fp: 0.002408, loss_freq: 0.027824
[03:17:12.895] iteration 4648: loss: 0.189845, loss_s1: 0.108419, loss_fp: 0.011788, loss_freq: 0.038825
[03:17:13.525] iteration 4649: loss: 0.141678, loss_s1: 0.047954, loss_fp: 0.004926, loss_freq: 0.018662
[03:17:14.123] iteration 4650: loss: 0.154812, loss_s1: 0.122930, loss_fp: 0.001723, loss_freq: 0.047041
[03:17:14.715] iteration 4651: loss: 0.099235, loss_s1: 0.096922, loss_fp: 0.002160, loss_freq: 0.028680
[03:17:15.309] iteration 4652: loss: 0.145357, loss_s1: 0.062917, loss_fp: 0.008874, loss_freq: 0.044465
[03:17:15.905] iteration 4653: loss: 0.118661, loss_s1: 0.063608, loss_fp: 0.002332, loss_freq: 0.020459
[03:17:16.495] iteration 4654: loss: 0.122608, loss_s1: 0.075761, loss_fp: 0.001503, loss_freq: 0.025272
[03:17:17.087] iteration 4655: loss: 0.174902, loss_s1: 0.127190, loss_fp: 0.002902, loss_freq: 0.035667
[03:17:17.722] iteration 4656: loss: 0.117783, loss_s1: 0.068216, loss_fp: 0.001446, loss_freq: 0.049301
[03:17:18.350] iteration 4657: loss: 0.121520, loss_s1: 0.058468, loss_fp: 0.012564, loss_freq: 0.006402
[03:17:18.977] iteration 4658: loss: 0.189093, loss_s1: 0.182990, loss_fp: 0.001055, loss_freq: 0.031547
[03:17:19.570] iteration 4659: loss: 0.086613, loss_s1: 0.035499, loss_fp: 0.000811, loss_freq: 0.015534
[03:17:20.159] iteration 4660: loss: 0.139136, loss_s1: 0.060501, loss_fp: 0.006701, loss_freq: 0.045337
[03:17:20.747] iteration 4661: loss: 0.202672, loss_s1: 0.066438, loss_fp: 0.002342, loss_freq: 0.064503
[03:17:21.341] iteration 4662: loss: 0.086921, loss_s1: 0.029259, loss_fp: 0.002941, loss_freq: 0.016692
[03:17:21.933] iteration 4663: loss: 0.126230, loss_s1: 0.076235, loss_fp: 0.002917, loss_freq: 0.023986
[03:17:22.528] iteration 4664: loss: 0.221578, loss_s1: 0.221733, loss_fp: 0.001064, loss_freq: 0.065275
[03:17:23.122] iteration 4665: loss: 0.170835, loss_s1: 0.089277, loss_fp: 0.001309, loss_freq: 0.060515
[03:17:23.718] iteration 4666: loss: 0.143155, loss_s1: 0.074853, loss_fp: 0.005327, loss_freq: 0.050106
[03:17:24.306] iteration 4667: loss: 0.088418, loss_s1: 0.019746, loss_fp: 0.004919, loss_freq: 0.017415
[03:17:24.894] iteration 4668: loss: 0.161315, loss_s1: 0.070060, loss_fp: 0.001487, loss_freq: 0.039011
[03:17:25.485] iteration 4669: loss: 0.190965, loss_s1: 0.151384, loss_fp: 0.000882, loss_freq: 0.059015
[03:17:26.074] iteration 4670: loss: 0.122715, loss_s1: 0.099346, loss_fp: 0.000923, loss_freq: 0.019347
[03:17:26.661] iteration 4671: loss: 0.164303, loss_s1: 0.084284, loss_fp: 0.001317, loss_freq: 0.015900
[03:17:27.252] iteration 4672: loss: 0.124348, loss_s1: 0.071241, loss_fp: 0.002424, loss_freq: 0.064145
[03:17:27.841] iteration 4673: loss: 0.172134, loss_s1: 0.064048, loss_fp: 0.002150, loss_freq: 0.070713
[03:17:28.437] iteration 4674: loss: 0.110975, loss_s1: 0.062261, loss_fp: 0.002017, loss_freq: 0.015269
[03:17:29.032] iteration 4675: loss: 0.123432, loss_s1: 0.052874, loss_fp: 0.014540, loss_freq: 0.018178
[03:17:29.624] iteration 4676: loss: 0.127211, loss_s1: 0.078383, loss_fp: 0.002426, loss_freq: 0.057926
[03:17:30.215] iteration 4677: loss: 0.162867, loss_s1: 0.131458, loss_fp: 0.003006, loss_freq: 0.066582
[03:17:30.807] iteration 4678: loss: 0.156230, loss_s1: 0.097514, loss_fp: 0.002093, loss_freq: 0.064286
[03:17:31.397] iteration 4679: loss: 0.154995, loss_s1: 0.101617, loss_fp: 0.004333, loss_freq: 0.076533
[03:17:31.990] iteration 4680: loss: 0.139686, loss_s1: 0.065275, loss_fp: 0.003216, loss_freq: 0.037683
[03:17:32.576] iteration 4681: loss: 0.129182, loss_s1: 0.057493, loss_fp: 0.005891, loss_freq: 0.031210
[03:17:33.164] iteration 4682: loss: 0.174638, loss_s1: 0.137512, loss_fp: 0.009391, loss_freq: 0.052432
[03:17:33.764] iteration 4683: loss: 0.176017, loss_s1: 0.095793, loss_fp: 0.015642, loss_freq: 0.052900
[03:17:34.361] iteration 4684: loss: 0.122362, loss_s1: 0.059959, loss_fp: 0.004872, loss_freq: 0.032077
[03:17:34.956] iteration 4685: loss: 0.085109, loss_s1: 0.059213, loss_fp: 0.000878, loss_freq: 0.012523
[03:17:35.551] iteration 4686: loss: 0.145336, loss_s1: 0.071932, loss_fp: 0.003164, loss_freq: 0.033871
[03:17:36.140] iteration 4687: loss: 0.132778, loss_s1: 0.089542, loss_fp: 0.001490, loss_freq: 0.015839
[03:17:36.727] iteration 4688: loss: 0.170088, loss_s1: 0.076915, loss_fp: 0.011603, loss_freq: 0.110547
[03:17:37.314] iteration 4689: loss: 0.153482, loss_s1: 0.061434, loss_fp: 0.002473, loss_freq: 0.032168
[03:17:37.907] iteration 4690: loss: 0.077700, loss_s1: 0.051204, loss_fp: 0.000573, loss_freq: 0.012773
[03:17:38.709] iteration 4691: loss: 0.117498, loss_s1: 0.046784, loss_fp: 0.001393, loss_freq: 0.049591
[03:17:39.575] iteration 4692: loss: 0.192774, loss_s1: 0.080810, loss_fp: 0.001587, loss_freq: 0.078407
[03:17:40.305] iteration 4693: loss: 0.100927, loss_s1: 0.025950, loss_fp: 0.001337, loss_freq: 0.020934
[03:17:41.043] iteration 4694: loss: 0.097692, loss_s1: 0.038393, loss_fp: 0.002813, loss_freq: 0.031966
[03:17:41.672] iteration 4695: loss: 0.133590, loss_s1: 0.066173, loss_fp: 0.001631, loss_freq: 0.028406
[03:17:42.305] iteration 4696: loss: 0.154142, loss_s1: 0.061334, loss_fp: 0.012412, loss_freq: 0.035238
[03:17:42.938] iteration 4697: loss: 0.121481, loss_s1: 0.059866, loss_fp: 0.005701, loss_freq: 0.049220
[03:17:43.567] iteration 4698: loss: 0.076731, loss_s1: 0.027231, loss_fp: 0.002218, loss_freq: 0.022018
[03:17:44.194] iteration 4699: loss: 0.170874, loss_s1: 0.067983, loss_fp: 0.019786, loss_freq: 0.133103
[03:17:44.826] iteration 4700: loss: 0.163011, loss_s1: 0.063533, loss_fp: 0.002977, loss_freq: 0.023456
[03:17:45.430] iteration 4701: loss: 0.166887, loss_s1: 0.099202, loss_fp: 0.002934, loss_freq: 0.050874
[03:17:46.018] iteration 4702: loss: 0.110738, loss_s1: 0.059310, loss_fp: 0.002198, loss_freq: 0.017847
[03:17:46.605] iteration 4703: loss: 0.103670, loss_s1: 0.062422, loss_fp: 0.004495, loss_freq: 0.030358
[03:17:47.199] iteration 4704: loss: 0.112047, loss_s1: 0.063608, loss_fp: 0.001651, loss_freq: 0.039132
[03:17:47.791] iteration 4705: loss: 0.251759, loss_s1: 0.169095, loss_fp: 0.005369, loss_freq: 0.104767
[03:17:48.383] iteration 4706: loss: 0.150681, loss_s1: 0.093418, loss_fp: 0.009996, loss_freq: 0.020471
[03:17:48.976] iteration 4707: loss: 0.169439, loss_s1: 0.055197, loss_fp: 0.002114, loss_freq: 0.073329
[03:17:49.570] iteration 4708: loss: 0.110283, loss_s1: 0.030001, loss_fp: 0.000649, loss_freq: 0.015880
[03:17:50.167] iteration 4709: loss: 0.189165, loss_s1: 0.078181, loss_fp: 0.015689, loss_freq: 0.134332
[03:17:50.757] iteration 4710: loss: 0.127671, loss_s1: 0.086243, loss_fp: 0.001897, loss_freq: 0.010842
[03:17:51.346] iteration 4711: loss: 0.084979, loss_s1: 0.043373, loss_fp: 0.001917, loss_freq: 0.006210
[03:17:51.933] iteration 4712: loss: 0.111754, loss_s1: 0.053732, loss_fp: 0.001978, loss_freq: 0.021600
[03:17:52.525] iteration 4713: loss: 0.168958, loss_s1: 0.044598, loss_fp: 0.001273, loss_freq: 0.063337
[03:17:53.116] iteration 4714: loss: 0.109422, loss_s1: 0.114532, loss_fp: 0.003254, loss_freq: 0.015438
[03:17:53.708] iteration 4715: loss: 0.152205, loss_s1: 0.106683, loss_fp: 0.003605, loss_freq: 0.040736
[03:17:54.299] iteration 4716: loss: 0.149846, loss_s1: 0.139511, loss_fp: 0.001841, loss_freq: 0.011737
[03:17:54.894] iteration 4717: loss: 0.236554, loss_s1: 0.172938, loss_fp: 0.011836, loss_freq: 0.175281
[03:17:55.483] iteration 4718: loss: 0.187354, loss_s1: 0.120064, loss_fp: 0.002109, loss_freq: 0.071956
[03:17:56.065] iteration 4719: loss: 0.106984, loss_s1: 0.047269, loss_fp: 0.002745, loss_freq: 0.026564
[03:17:56.649] iteration 4720: loss: 0.187539, loss_s1: 0.139207, loss_fp: 0.002827, loss_freq: 0.088678
[03:17:57.239] iteration 4721: loss: 0.109561, loss_s1: 0.084474, loss_fp: 0.001154, loss_freq: 0.036168
[03:17:57.830] iteration 4722: loss: 0.188415, loss_s1: 0.088392, loss_fp: 0.001129, loss_freq: 0.034993
[03:17:58.420] iteration 4723: loss: 0.130764, loss_s1: 0.140509, loss_fp: 0.005986, loss_freq: 0.015997
[03:17:59.015] iteration 4724: loss: 0.106242, loss_s1: 0.060007, loss_fp: 0.004271, loss_freq: 0.030409
[03:17:59.604] iteration 4725: loss: 0.187743, loss_s1: 0.161342, loss_fp: 0.002773, loss_freq: 0.056724
[03:18:00.269] iteration 4726: loss: 0.114180, loss_s1: 0.051531, loss_fp: 0.000748, loss_freq: 0.046297
[03:18:00.864] iteration 4727: loss: 0.223601, loss_s1: 0.145640, loss_fp: 0.005975, loss_freq: 0.005784
[03:18:01.459] iteration 4728: loss: 0.135032, loss_s1: 0.076906, loss_fp: 0.007185, loss_freq: 0.023095
[03:18:02.099] iteration 4729: loss: 0.148770, loss_s1: 0.107123, loss_fp: 0.002421, loss_freq: 0.042187
[03:18:02.741] iteration 4730: loss: 0.158492, loss_s1: 0.165867, loss_fp: 0.002203, loss_freq: 0.038353
[03:18:03.353] iteration 4731: loss: 0.153689, loss_s1: 0.089079, loss_fp: 0.009911, loss_freq: 0.062212
[03:18:03.993] iteration 4732: loss: 0.090370, loss_s1: 0.025911, loss_fp: 0.010857, loss_freq: 0.017860
[03:18:04.628] iteration 4733: loss: 0.128629, loss_s1: 0.092932, loss_fp: 0.001786, loss_freq: 0.037171
[03:18:05.227] iteration 4734: loss: 0.116242, loss_s1: 0.074542, loss_fp: 0.001411, loss_freq: 0.026217
[03:18:05.817] iteration 4735: loss: 0.133148, loss_s1: 0.067186, loss_fp: 0.000850, loss_freq: 0.040501
[03:18:06.407] iteration 4736: loss: 0.111071, loss_s1: 0.064294, loss_fp: 0.000861, loss_freq: 0.032623
[03:18:07.001] iteration 4737: loss: 0.123547, loss_s1: 0.087121, loss_fp: 0.002677, loss_freq: 0.030128
[03:18:07.592] iteration 4738: loss: 0.119627, loss_s1: 0.091787, loss_fp: 0.002304, loss_freq: 0.057683
[03:18:08.179] iteration 4739: loss: 0.157767, loss_s1: 0.097495, loss_fp: 0.001157, loss_freq: 0.058599
[03:18:08.807] iteration 4740: loss: 0.110212, loss_s1: 0.030566, loss_fp: 0.003530, loss_freq: 0.033013
[03:18:09.440] iteration 4741: loss: 0.137080, loss_s1: 0.049511, loss_fp: 0.006762, loss_freq: 0.045297
[03:18:10.106] iteration 4742: loss: 0.157674, loss_s1: 0.099032, loss_fp: 0.002119, loss_freq: 0.070754
[03:18:10.732] iteration 4743: loss: 0.197460, loss_s1: 0.112161, loss_fp: 0.019988, loss_freq: 0.094037
[03:18:11.362] iteration 4744: loss: 0.117638, loss_s1: 0.105087, loss_fp: 0.001156, loss_freq: 0.017139
[03:18:11.989] iteration 4745: loss: 0.193998, loss_s1: 0.084396, loss_fp: 0.001722, loss_freq: 0.061344
[03:18:12.584] iteration 4746: loss: 0.153715, loss_s1: 0.108721, loss_fp: 0.002833, loss_freq: 0.057668
[03:18:13.175] iteration 4747: loss: 0.087838, loss_s1: 0.041253, loss_fp: 0.000545, loss_freq: 0.023229
[03:18:13.768] iteration 4748: loss: 0.165274, loss_s1: 0.087277, loss_fp: 0.003659, loss_freq: 0.057446
[03:18:14.361] iteration 4749: loss: 0.093100, loss_s1: 0.054611, loss_fp: 0.001545, loss_freq: 0.013743
[03:18:14.952] iteration 4750: loss: 0.151757, loss_s1: 0.125922, loss_fp: 0.003553, loss_freq: 0.028270
[03:18:15.543] iteration 4751: loss: 0.056893, loss_s1: 0.017183, loss_fp: 0.000827, loss_freq: 0.010437
[03:18:16.133] iteration 4752: loss: 0.083264, loss_s1: 0.037806, loss_fp: 0.005066, loss_freq: 0.008963
[03:18:16.724] iteration 4753: loss: 0.139295, loss_s1: 0.091573, loss_fp: 0.001364, loss_freq: 0.013948
[03:18:17.323] iteration 4754: loss: 0.200025, loss_s1: 0.063697, loss_fp: 0.008952, loss_freq: 0.015751
[03:18:17.923] iteration 4755: loss: 0.109756, loss_s1: 0.072221, loss_fp: 0.005020, loss_freq: 0.016128
[03:18:18.511] iteration 4756: loss: 0.136259, loss_s1: 0.105503, loss_fp: 0.004986, loss_freq: 0.036341
[03:18:19.103] iteration 4757: loss: 0.140953, loss_s1: 0.044739, loss_fp: 0.001298, loss_freq: 0.077236
[03:18:19.700] iteration 4758: loss: 0.093756, loss_s1: 0.057231, loss_fp: 0.001091, loss_freq: 0.017238
[03:18:20.291] iteration 4759: loss: 0.147401, loss_s1: 0.047671, loss_fp: 0.003203, loss_freq: 0.043740
[03:18:20.879] iteration 4760: loss: 0.147001, loss_s1: 0.078360, loss_fp: 0.001192, loss_freq: 0.119899
[03:18:21.815] iteration 4761: loss: 0.096791, loss_s1: 0.027022, loss_fp: 0.000898, loss_freq: 0.012742
[03:18:22.465] iteration 4762: loss: 0.116160, loss_s1: 0.046097, loss_fp: 0.000479, loss_freq: 0.023769
[03:18:23.064] iteration 4763: loss: 0.144677, loss_s1: 0.124292, loss_fp: 0.002479, loss_freq: 0.025845
[03:18:23.659] iteration 4764: loss: 0.124691, loss_s1: 0.070919, loss_fp: 0.000982, loss_freq: 0.020229
[03:18:24.256] iteration 4765: loss: 0.128972, loss_s1: 0.056624, loss_fp: 0.001086, loss_freq: 0.026667
[03:18:24.850] iteration 4766: loss: 0.137546, loss_s1: 0.078158, loss_fp: 0.006447, loss_freq: 0.017890
[03:18:25.444] iteration 4767: loss: 0.105102, loss_s1: 0.061953, loss_fp: 0.001330, loss_freq: 0.054390
[03:18:26.037] iteration 4768: loss: 0.172797, loss_s1: 0.064400, loss_fp: 0.002411, loss_freq: 0.027474
[03:18:26.702] iteration 4769: loss: 0.112493, loss_s1: 0.061939, loss_fp: 0.001950, loss_freq: 0.027981
[03:18:27.338] iteration 4770: loss: 0.132064, loss_s1: 0.089637, loss_fp: 0.010216, loss_freq: 0.041479
[03:18:27.971] iteration 4771: loss: 0.143858, loss_s1: 0.096185, loss_fp: 0.004000, loss_freq: 0.031282
[03:18:28.608] iteration 4772: loss: 0.173382, loss_s1: 0.145166, loss_fp: 0.002474, loss_freq: 0.069096
[03:18:29.240] iteration 4773: loss: 0.109348, loss_s1: 0.047833, loss_fp: 0.001304, loss_freq: 0.069668
[03:18:29.860] iteration 4774: loss: 0.103918, loss_s1: 0.060238, loss_fp: 0.003143, loss_freq: 0.021532
[03:18:30.492] iteration 4775: loss: 0.171374, loss_s1: 0.130962, loss_fp: 0.000437, loss_freq: 0.015242
[03:18:31.117] iteration 4776: loss: 0.106501, loss_s1: 0.039129, loss_fp: 0.001354, loss_freq: 0.009788
[03:18:31.746] iteration 4777: loss: 0.178713, loss_s1: 0.104003, loss_fp: 0.001200, loss_freq: 0.068206
[03:18:32.382] iteration 4778: loss: 0.130768, loss_s1: 0.072207, loss_fp: 0.002666, loss_freq: 0.028281
[03:18:33.011] iteration 4779: loss: 0.123822, loss_s1: 0.083360, loss_fp: 0.001598, loss_freq: 0.048389
[03:18:33.644] iteration 4780: loss: 0.131836, loss_s1: 0.092224, loss_fp: 0.002494, loss_freq: 0.032033
[03:18:34.236] iteration 4781: loss: 0.130370, loss_s1: 0.109278, loss_fp: 0.002112, loss_freq: 0.063958
[03:18:34.849] iteration 4782: loss: 0.147211, loss_s1: 0.061324, loss_fp: 0.001143, loss_freq: 0.045721
[03:18:35.457] iteration 4783: loss: 0.176753, loss_s1: 0.103638, loss_fp: 0.001861, loss_freq: 0.014243
[03:18:36.067] iteration 4784: loss: 0.090643, loss_s1: 0.037097, loss_fp: 0.002628, loss_freq: 0.019819
[03:18:36.675] iteration 4785: loss: 0.125093, loss_s1: 0.093452, loss_fp: 0.001403, loss_freq: 0.020387
[03:18:37.290] iteration 4786: loss: 0.112994, loss_s1: 0.083245, loss_fp: 0.001082, loss_freq: 0.045890
[03:18:37.899] iteration 4787: loss: 0.100756, loss_s1: 0.056152, loss_fp: 0.001984, loss_freq: 0.010255
[03:18:38.509] iteration 4788: loss: 0.200515, loss_s1: 0.122347, loss_fp: 0.012714, loss_freq: 0.086539
[03:18:39.121] iteration 4789: loss: 0.179290, loss_s1: 0.033879, loss_fp: 0.008550, loss_freq: 0.024392
[03:18:39.730] iteration 4790: loss: 0.110260, loss_s1: 0.094157, loss_fp: 0.001022, loss_freq: 0.021498
[03:18:40.335] iteration 4791: loss: 0.130727, loss_s1: 0.092588, loss_fp: 0.006523, loss_freq: 0.015835
[03:18:40.947] iteration 4792: loss: 0.153959, loss_s1: 0.044490, loss_fp: 0.001256, loss_freq: 0.024220
[03:18:41.558] iteration 4793: loss: 0.181919, loss_s1: 0.119754, loss_fp: 0.004819, loss_freq: 0.014707
[03:18:42.168] iteration 4794: loss: 0.087202, loss_s1: 0.033298, loss_fp: 0.000658, loss_freq: 0.012623
[03:18:42.780] iteration 4795: loss: 0.143099, loss_s1: 0.075060, loss_fp: 0.001963, loss_freq: 0.058555
[03:18:43.386] iteration 4796: loss: 0.127651, loss_s1: 0.034286, loss_fp: 0.002119, loss_freq: 0.007822
[03:18:44.003] iteration 4797: loss: 0.139511, loss_s1: 0.103930, loss_fp: 0.000657, loss_freq: 0.062052
[03:18:44.608] iteration 4798: loss: 0.119618, loss_s1: 0.059829, loss_fp: 0.023884, loss_freq: 0.018923
[03:18:45.210] iteration 4799: loss: 0.224009, loss_s1: 0.188088, loss_fp: 0.000655, loss_freq: 0.075531
[03:18:45.812] iteration 4800: loss: 0.184759, loss_s1: 0.180767, loss_fp: 0.003326, loss_freq: 0.032098
[03:18:49.119] iteration 4800 : mean_dice : 0.540586
[03:18:49.760] iteration 4801: loss: 0.153928, loss_s1: 0.114342, loss_fp: 0.009244, loss_freq: 0.036929
[03:18:50.357] iteration 4802: loss: 0.126389, loss_s1: 0.059760, loss_fp: 0.002507, loss_freq: 0.046488
[03:18:50.959] iteration 4803: loss: 0.201305, loss_s1: 0.165890, loss_fp: 0.001256, loss_freq: 0.050541
[03:18:51.591] iteration 4804: loss: 0.208468, loss_s1: 0.156879, loss_fp: 0.003589, loss_freq: 0.129814
[03:18:52.222] iteration 4805: loss: 0.161034, loss_s1: 0.100818, loss_fp: 0.004743, loss_freq: 0.042026
[03:18:52.848] iteration 4806: loss: 0.122848, loss_s1: 0.106542, loss_fp: 0.001024, loss_freq: 0.026479
[03:18:53.478] iteration 4807: loss: 0.078364, loss_s1: 0.043924, loss_fp: 0.001718, loss_freq: 0.011317
[03:18:54.086] iteration 4808: loss: 0.139046, loss_s1: 0.069476, loss_fp: 0.008304, loss_freq: 0.048987
[03:18:54.674] iteration 4809: loss: 0.112322, loss_s1: 0.070125, loss_fp: 0.006699, loss_freq: 0.018263
[03:18:55.269] iteration 4810: loss: 0.108045, loss_s1: 0.032021, loss_fp: 0.001235, loss_freq: 0.030644
[03:18:55.902] iteration 4811: loss: 0.199162, loss_s1: 0.081316, loss_fp: 0.001259, loss_freq: 0.123470
[03:18:56.488] iteration 4812: loss: 0.083049, loss_s1: 0.051905, loss_fp: 0.001697, loss_freq: 0.014738
[03:18:57.081] iteration 4813: loss: 0.153833, loss_s1: 0.051200, loss_fp: 0.002171, loss_freq: 0.085527
[03:18:57.676] iteration 4814: loss: 0.132847, loss_s1: 0.076273, loss_fp: 0.001032, loss_freq: 0.053659
[03:18:58.267] iteration 4815: loss: 0.208208, loss_s1: 0.028763, loss_fp: 0.005783, loss_freq: 0.141185
[03:18:58.858] iteration 4816: loss: 0.144763, loss_s1: 0.142691, loss_fp: 0.000606, loss_freq: 0.021294
[03:18:59.489] iteration 4817: loss: 0.104009, loss_s1: 0.073251, loss_fp: 0.000805, loss_freq: 0.020934
[03:19:00.079] iteration 4818: loss: 0.126117, loss_s1: 0.053635, loss_fp: 0.001134, loss_freq: 0.008312
[03:19:00.668] iteration 4819: loss: 0.152942, loss_s1: 0.061326, loss_fp: 0.001520, loss_freq: 0.048700
[03:19:01.258] iteration 4820: loss: 0.139177, loss_s1: 0.085634, loss_fp: 0.008849, loss_freq: 0.039155
[03:19:01.850] iteration 4821: loss: 0.131736, loss_s1: 0.046078, loss_fp: 0.004400, loss_freq: 0.060483
[03:19:02.445] iteration 4822: loss: 0.129307, loss_s1: 0.046050, loss_fp: 0.005358, loss_freq: 0.044364
[03:19:03.035] iteration 4823: loss: 0.119264, loss_s1: 0.069744, loss_fp: 0.000831, loss_freq: 0.041115
[03:19:03.627] iteration 4824: loss: 0.170100, loss_s1: 0.135515, loss_fp: 0.001319, loss_freq: 0.045259
[03:19:04.215] iteration 4825: loss: 0.158686, loss_s1: 0.109661, loss_fp: 0.001270, loss_freq: 0.029150
[03:19:04.803] iteration 4826: loss: 0.135336, loss_s1: 0.081658, loss_fp: 0.000862, loss_freq: 0.042861
[03:19:05.393] iteration 4827: loss: 0.157658, loss_s1: 0.068626, loss_fp: 0.008097, loss_freq: 0.028356
[03:19:05.978] iteration 4828: loss: 0.126990, loss_s1: 0.099554, loss_fp: 0.003423, loss_freq: 0.042002
[03:19:06.585] iteration 4829: loss: 0.105631, loss_s1: 0.048349, loss_fp: 0.001208, loss_freq: 0.041626
[03:19:07.245] iteration 4830: loss: 0.111684, loss_s1: 0.052312, loss_fp: 0.002067, loss_freq: 0.033452
[03:19:07.871] iteration 4831: loss: 0.159345, loss_s1: 0.059951, loss_fp: 0.002396, loss_freq: 0.072538
[03:19:08.495] iteration 4832: loss: 0.128709, loss_s1: 0.094906, loss_fp: 0.003322, loss_freq: 0.017379
[03:19:09.095] iteration 4833: loss: 0.155569, loss_s1: 0.136696, loss_fp: 0.002086, loss_freq: 0.010747
[03:19:09.678] iteration 4834: loss: 0.177992, loss_s1: 0.164778, loss_fp: 0.000842, loss_freq: 0.055165
[03:19:10.266] iteration 4835: loss: 0.174981, loss_s1: 0.097042, loss_fp: 0.001311, loss_freq: 0.058830
[03:19:10.862] iteration 4836: loss: 0.133999, loss_s1: 0.071744, loss_fp: 0.000995, loss_freq: 0.057965
[03:19:11.453] iteration 4837: loss: 0.096796, loss_s1: 0.074682, loss_fp: 0.002522, loss_freq: 0.017712
[03:19:12.041] iteration 4838: loss: 0.167784, loss_s1: 0.064513, loss_fp: 0.003942, loss_freq: 0.045093
[03:19:12.625] iteration 4839: loss: 0.089462, loss_s1: 0.036258, loss_fp: 0.002358, loss_freq: 0.034776
[03:19:13.209] iteration 4840: loss: 0.098661, loss_s1: 0.040052, loss_fp: 0.001019, loss_freq: 0.026445
[03:19:13.801] iteration 4841: loss: 0.204801, loss_s1: 0.111122, loss_fp: 0.001088, loss_freq: 0.059496
[03:19:14.388] iteration 4842: loss: 0.102931, loss_s1: 0.058304, loss_fp: 0.001288, loss_freq: 0.029013
[03:19:14.983] iteration 4843: loss: 0.243585, loss_s1: 0.216721, loss_fp: 0.002371, loss_freq: 0.081517
[03:19:15.577] iteration 4844: loss: 0.117167, loss_s1: 0.024631, loss_fp: 0.002102, loss_freq: 0.016506
[03:19:16.172] iteration 4845: loss: 0.125397, loss_s1: 0.060586, loss_fp: 0.001729, loss_freq: 0.014521
[03:19:16.849] iteration 4846: loss: 0.111131, loss_s1: 0.061541, loss_fp: 0.002836, loss_freq: 0.053453
[03:19:17.482] iteration 4847: loss: 0.155657, loss_s1: 0.153267, loss_fp: 0.000968, loss_freq: 0.063287
[03:19:18.118] iteration 4848: loss: 0.140797, loss_s1: 0.061353, loss_fp: 0.001113, loss_freq: 0.066825
[03:19:18.746] iteration 4849: loss: 0.128215, loss_s1: 0.078763, loss_fp: 0.001783, loss_freq: 0.083060
[03:19:19.384] iteration 4850: loss: 0.158307, loss_s1: 0.113288, loss_fp: 0.001463, loss_freq: 0.047835
[03:19:19.981] iteration 4851: loss: 0.102347, loss_s1: 0.085213, loss_fp: 0.000646, loss_freq: 0.023757
[03:19:20.605] iteration 4852: loss: 0.120968, loss_s1: 0.075454, loss_fp: 0.005112, loss_freq: 0.072308
[03:19:21.242] iteration 4853: loss: 0.170709, loss_s1: 0.104784, loss_fp: 0.002347, loss_freq: 0.055041
[03:19:21.876] iteration 4854: loss: 0.161619, loss_s1: 0.081348, loss_fp: 0.000715, loss_freq: 0.016680
[03:19:22.512] iteration 4855: loss: 0.087317, loss_s1: 0.025362, loss_fp: 0.001349, loss_freq: 0.049924
[03:19:23.136] iteration 4856: loss: 0.138285, loss_s1: 0.087566, loss_fp: 0.000991, loss_freq: 0.033115
[03:19:23.729] iteration 4857: loss: 0.142946, loss_s1: 0.074915, loss_fp: 0.002041, loss_freq: 0.038083
[03:19:24.324] iteration 4858: loss: 0.111575, loss_s1: 0.076464, loss_fp: 0.018459, loss_freq: 0.019563
[03:19:24.922] iteration 4859: loss: 0.157888, loss_s1: 0.103425, loss_fp: 0.000628, loss_freq: 0.047356
[03:19:25.556] iteration 4860: loss: 0.088370, loss_s1: 0.036099, loss_fp: 0.006573, loss_freq: 0.010391
[03:19:26.183] iteration 4861: loss: 0.133956, loss_s1: 0.109305, loss_fp: 0.006842, loss_freq: 0.027567
[03:19:26.831] iteration 4862: loss: 0.146920, loss_s1: 0.091700, loss_fp: 0.000644, loss_freq: 0.038786
[03:19:27.472] iteration 4863: loss: 0.098285, loss_s1: 0.039918, loss_fp: 0.001125, loss_freq: 0.019727
[03:19:28.070] iteration 4864: loss: 0.089531, loss_s1: 0.028460, loss_fp: 0.000506, loss_freq: 0.016710
[03:19:28.664] iteration 4865: loss: 0.153921, loss_s1: 0.076993, loss_fp: 0.004344, loss_freq: 0.061865
[03:19:29.257] iteration 4866: loss: 0.160852, loss_s1: 0.081545, loss_fp: 0.004187, loss_freq: 0.053964
[03:19:29.850] iteration 4867: loss: 0.112849, loss_s1: 0.063235, loss_fp: 0.001352, loss_freq: 0.025108
[03:19:30.450] iteration 4868: loss: 0.101506, loss_s1: 0.065960, loss_fp: 0.002772, loss_freq: 0.027057
[03:19:31.044] iteration 4869: loss: 0.175437, loss_s1: 0.095103, loss_fp: 0.004744, loss_freq: 0.122083
[03:19:31.637] iteration 4870: loss: 0.172025, loss_s1: 0.077217, loss_fp: 0.000712, loss_freq: 0.015124
[03:19:32.227] iteration 4871: loss: 0.166029, loss_s1: 0.173766, loss_fp: 0.000878, loss_freq: 0.009806
[03:19:32.821] iteration 4872: loss: 0.128620, loss_s1: 0.120352, loss_fp: 0.004106, loss_freq: 0.026618
[03:19:33.414] iteration 4873: loss: 0.141320, loss_s1: 0.155977, loss_fp: 0.000517, loss_freq: 0.020382
[03:19:34.020] iteration 4874: loss: 0.137036, loss_s1: 0.120921, loss_fp: 0.001200, loss_freq: 0.044205
[03:19:34.649] iteration 4875: loss: 0.206621, loss_s1: 0.133437, loss_fp: 0.004347, loss_freq: 0.116284
[03:19:35.282] iteration 4876: loss: 0.140823, loss_s1: 0.045646, loss_fp: 0.005573, loss_freq: 0.075345
[03:19:35.916] iteration 4877: loss: 0.135339, loss_s1: 0.067186, loss_fp: 0.001165, loss_freq: 0.042696
[03:19:36.550] iteration 4878: loss: 0.078598, loss_s1: 0.039886, loss_fp: 0.003373, loss_freq: 0.022672
[03:19:37.183] iteration 4879: loss: 0.180430, loss_s1: 0.098337, loss_fp: 0.001684, loss_freq: 0.110556
[03:19:37.816] iteration 4880: loss: 0.107290, loss_s1: 0.045603, loss_fp: 0.000487, loss_freq: 0.020682
[03:19:38.446] iteration 4881: loss: 0.105584, loss_s1: 0.098745, loss_fp: 0.001580, loss_freq: 0.006008
[03:19:39.040] iteration 4882: loss: 0.072862, loss_s1: 0.044553, loss_fp: 0.005433, loss_freq: 0.020956
[03:19:39.635] iteration 4883: loss: 0.171966, loss_s1: 0.113843, loss_fp: 0.004726, loss_freq: 0.055206
[03:19:40.227] iteration 4884: loss: 0.102359, loss_s1: 0.060672, loss_fp: 0.001615, loss_freq: 0.044838
[03:19:40.820] iteration 4885: loss: 0.178881, loss_s1: 0.122139, loss_fp: 0.004941, loss_freq: 0.081380
[03:19:41.407] iteration 4886: loss: 0.149361, loss_s1: 0.107028, loss_fp: 0.000871, loss_freq: 0.006856
[03:19:41.998] iteration 4887: loss: 0.306861, loss_s1: 0.248199, loss_fp: 0.019080, loss_freq: 0.216291
[03:19:42.591] iteration 4888: loss: 0.222637, loss_s1: 0.075965, loss_fp: 0.000516, loss_freq: 0.135890
[03:19:43.177] iteration 4889: loss: 0.116586, loss_s1: 0.036017, loss_fp: 0.002115, loss_freq: 0.010654
[03:19:43.910] iteration 4890: loss: 0.142624, loss_s1: 0.059845, loss_fp: 0.000930, loss_freq: 0.036762
[03:19:44.789] iteration 4891: loss: 0.160052, loss_s1: 0.061279, loss_fp: 0.002180, loss_freq: 0.044150
[03:19:45.540] iteration 4892: loss: 0.199851, loss_s1: 0.048849, loss_fp: 0.001576, loss_freq: 0.018132
[03:19:46.274] iteration 4893: loss: 0.135314, loss_s1: 0.084989, loss_fp: 0.003873, loss_freq: 0.006821
[03:19:46.921] iteration 4894: loss: 0.149769, loss_s1: 0.056984, loss_fp: 0.004824, loss_freq: 0.021633
[03:19:47.511] iteration 4895: loss: 0.098060, loss_s1: 0.027727, loss_fp: 0.003435, loss_freq: 0.050431
[03:19:48.143] iteration 4896: loss: 0.109040, loss_s1: 0.076755, loss_fp: 0.000801, loss_freq: 0.010736
[03:19:48.755] iteration 4897: loss: 0.206213, loss_s1: 0.083551, loss_fp: 0.003378, loss_freq: 0.019997
[03:19:49.347] iteration 4898: loss: 0.075136, loss_s1: 0.027126, loss_fp: 0.002230, loss_freq: 0.016277
[03:19:49.950] iteration 4899: loss: 0.116013, loss_s1: 0.057623, loss_fp: 0.001075, loss_freq: 0.026952
[03:19:50.540] iteration 4900: loss: 0.220495, loss_s1: 0.221059, loss_fp: 0.003562, loss_freq: 0.075431
[03:19:51.129] iteration 4901: loss: 0.170610, loss_s1: 0.130142, loss_fp: 0.000832, loss_freq: 0.053691
[03:19:51.716] iteration 4902: loss: 0.103794, loss_s1: 0.069917, loss_fp: 0.000888, loss_freq: 0.033115
[03:19:52.340] iteration 4903: loss: 0.120475, loss_s1: 0.055543, loss_fp: 0.003052, loss_freq: 0.021913
[03:19:52.934] iteration 4904: loss: 0.146806, loss_s1: 0.091584, loss_fp: 0.014322, loss_freq: 0.022222
[03:19:53.547] iteration 4905: loss: 0.142606, loss_s1: 0.136942, loss_fp: 0.003248, loss_freq: 0.040540
[03:19:54.176] iteration 4906: loss: 0.129300, loss_s1: 0.077669, loss_fp: 0.001124, loss_freq: 0.020294
[03:19:54.773] iteration 4907: loss: 0.112870, loss_s1: 0.058615, loss_fp: 0.003298, loss_freq: 0.030425
[03:19:55.372] iteration 4908: loss: 0.153614, loss_s1: 0.115806, loss_fp: 0.009370, loss_freq: 0.048918
[03:19:55.968] iteration 4909: loss: 0.170288, loss_s1: 0.164111, loss_fp: 0.000803, loss_freq: 0.052449
[03:19:56.565] iteration 4910: loss: 0.104730, loss_s1: 0.031439, loss_fp: 0.001884, loss_freq: 0.019508
[03:19:57.161] iteration 4911: loss: 0.127512, loss_s1: 0.086758, loss_fp: 0.000984, loss_freq: 0.022912
[03:19:57.754] iteration 4912: loss: 0.132954, loss_s1: 0.097455, loss_fp: 0.001837, loss_freq: 0.038020
[03:19:58.353] iteration 4913: loss: 0.184743, loss_s1: 0.147576, loss_fp: 0.007544, loss_freq: 0.049860
[03:19:58.996] iteration 4914: loss: 0.101704, loss_s1: 0.049219, loss_fp: 0.001044, loss_freq: 0.028930
[03:19:59.599] iteration 4915: loss: 0.254002, loss_s1: 0.179359, loss_fp: 0.004447, loss_freq: 0.069953
[03:20:00.195] iteration 4916: loss: 0.118855, loss_s1: 0.088660, loss_fp: 0.002450, loss_freq: 0.053272
[03:20:00.787] iteration 4917: loss: 0.083453, loss_s1: 0.044228, loss_fp: 0.000680, loss_freq: 0.021189
[03:20:01.383] iteration 4918: loss: 0.125188, loss_s1: 0.068938, loss_fp: 0.002632, loss_freq: 0.040527
[03:20:01.980] iteration 4919: loss: 0.091440, loss_s1: 0.079575, loss_fp: 0.002291, loss_freq: 0.014685
[03:20:02.570] iteration 4920: loss: 0.119992, loss_s1: 0.078261, loss_fp: 0.000888, loss_freq: 0.020702
[03:20:03.164] iteration 4921: loss: 0.106141, loss_s1: 0.107379, loss_fp: 0.001426, loss_freq: 0.011077
[03:20:03.763] iteration 4922: loss: 0.127561, loss_s1: 0.106662, loss_fp: 0.012127, loss_freq: 0.016034
[03:20:04.362] iteration 4923: loss: 0.188948, loss_s1: 0.120110, loss_fp: 0.011677, loss_freq: 0.032824
[03:20:04.961] iteration 4924: loss: 0.147983, loss_s1: 0.110770, loss_fp: 0.001080, loss_freq: 0.036083
[03:20:05.560] iteration 4925: loss: 0.109405, loss_s1: 0.064113, loss_fp: 0.000866, loss_freq: 0.020436
[03:20:06.154] iteration 4926: loss: 0.174168, loss_s1: 0.145630, loss_fp: 0.003130, loss_freq: 0.037775
[03:20:06.746] iteration 4927: loss: 0.150064, loss_s1: 0.047097, loss_fp: 0.009021, loss_freq: 0.046433
[03:20:07.335] iteration 4928: loss: 0.109149, loss_s1: 0.069051, loss_fp: 0.005771, loss_freq: 0.015354
[03:20:07.921] iteration 4929: loss: 0.114742, loss_s1: 0.046615, loss_fp: 0.004094, loss_freq: 0.039934
[03:20:08.505] iteration 4930: loss: 0.159611, loss_s1: 0.083418, loss_fp: 0.006442, loss_freq: 0.108887
[03:20:09.396] iteration 4931: loss: 0.102052, loss_s1: 0.029991, loss_fp: 0.005410, loss_freq: 0.013037
[03:20:10.033] iteration 4932: loss: 0.095922, loss_s1: 0.043771, loss_fp: 0.001472, loss_freq: 0.030867
[03:20:10.631] iteration 4933: loss: 0.125508, loss_s1: 0.065724, loss_fp: 0.001857, loss_freq: 0.048548
[03:20:11.224] iteration 4934: loss: 0.114797, loss_s1: 0.078973, loss_fp: 0.002954, loss_freq: 0.037846
[03:20:11.824] iteration 4935: loss: 0.134714, loss_s1: 0.090978, loss_fp: 0.002066, loss_freq: 0.036073
[03:20:12.463] iteration 4936: loss: 0.165528, loss_s1: 0.157623, loss_fp: 0.002748, loss_freq: 0.023465
[03:20:13.056] iteration 4937: loss: 0.173265, loss_s1: 0.109711, loss_fp: 0.007215, loss_freq: 0.065698
[03:20:13.649] iteration 4938: loss: 0.144148, loss_s1: 0.039391, loss_fp: 0.001740, loss_freq: 0.037892
[03:20:14.245] iteration 4939: loss: 0.100812, loss_s1: 0.024411, loss_fp: 0.005856, loss_freq: 0.053100
[03:20:14.837] iteration 4940: loss: 0.132136, loss_s1: 0.077983, loss_fp: 0.003775, loss_freq: 0.035708
[03:20:15.429] iteration 4941: loss: 0.119322, loss_s1: 0.038682, loss_fp: 0.003605, loss_freq: 0.082369
[03:20:16.074] iteration 4942: loss: 0.114322, loss_s1: 0.066327, loss_fp: 0.001575, loss_freq: 0.080560
[03:20:16.668] iteration 4943: loss: 0.117151, loss_s1: 0.049385, loss_fp: 0.001689, loss_freq: 0.028016
[03:20:17.308] iteration 4944: loss: 0.135553, loss_s1: 0.083300, loss_fp: 0.003937, loss_freq: 0.024952
[03:20:17.908] iteration 4945: loss: 0.138392, loss_s1: 0.070563, loss_fp: 0.004424, loss_freq: 0.013418
[03:20:18.505] iteration 4946: loss: 0.109071, loss_s1: 0.077849, loss_fp: 0.004284, loss_freq: 0.018653
[03:20:19.099] iteration 4947: loss: 0.200893, loss_s1: 0.086640, loss_fp: 0.022894, loss_freq: 0.135961
[03:20:19.714] iteration 4948: loss: 0.123751, loss_s1: 0.083934, loss_fp: 0.003099, loss_freq: 0.014834
[03:20:20.306] iteration 4949: loss: 0.104164, loss_s1: 0.110205, loss_fp: 0.007475, loss_freq: 0.024501
[03:20:20.901] iteration 4950: loss: 0.150624, loss_s1: 0.084442, loss_fp: 0.001779, loss_freq: 0.028058
[03:20:21.500] iteration 4951: loss: 0.131691, loss_s1: 0.069666, loss_fp: 0.018579, loss_freq: 0.038204
[03:20:22.099] iteration 4952: loss: 0.120798, loss_s1: 0.077114, loss_fp: 0.003080, loss_freq: 0.044755
[03:20:22.694] iteration 4953: loss: 0.202317, loss_s1: 0.108976, loss_fp: 0.003985, loss_freq: 0.017230
[03:20:23.281] iteration 4954: loss: 0.127112, loss_s1: 0.061196, loss_fp: 0.000872, loss_freq: 0.047111
[03:20:23.878] iteration 4955: loss: 0.078892, loss_s1: 0.019174, loss_fp: 0.000547, loss_freq: 0.006821
[03:20:24.474] iteration 4956: loss: 0.208326, loss_s1: 0.126689, loss_fp: 0.001805, loss_freq: 0.062594
[03:20:25.071] iteration 4957: loss: 0.112403, loss_s1: 0.064547, loss_fp: 0.001085, loss_freq: 0.027722
[03:20:25.659] iteration 4958: loss: 0.202478, loss_s1: 0.170186, loss_fp: 0.002857, loss_freq: 0.111190
[03:20:26.245] iteration 4959: loss: 0.135017, loss_s1: 0.030084, loss_fp: 0.015235, loss_freq: 0.020019
[03:20:26.831] iteration 4960: loss: 0.111433, loss_s1: 0.056747, loss_fp: 0.001096, loss_freq: 0.037796
[03:20:27.423] iteration 4961: loss: 0.122582, loss_s1: 0.070381, loss_fp: 0.002070, loss_freq: 0.072802
[03:20:28.011] iteration 4962: loss: 0.210647, loss_s1: 0.114435, loss_fp: 0.001799, loss_freq: 0.040675
[03:20:28.604] iteration 4963: loss: 0.131458, loss_s1: 0.129091, loss_fp: 0.001046, loss_freq: 0.022134
[03:20:29.202] iteration 4964: loss: 0.141105, loss_s1: 0.084372, loss_fp: 0.003810, loss_freq: 0.021189
[03:20:29.786] iteration 4965: loss: 0.188690, loss_s1: 0.126992, loss_fp: 0.005260, loss_freq: 0.071683
[03:20:30.403] iteration 4966: loss: 0.125255, loss_s1: 0.038666, loss_fp: 0.001223, loss_freq: 0.009490
[03:20:31.029] iteration 4967: loss: 0.116893, loss_s1: 0.079439, loss_fp: 0.000970, loss_freq: 0.024440
[03:20:31.687] iteration 4968: loss: 0.136321, loss_s1: 0.053201, loss_fp: 0.000908, loss_freq: 0.014015
[03:20:32.283] iteration 4969: loss: 0.134685, loss_s1: 0.107933, loss_fp: 0.002809, loss_freq: 0.035307
[03:20:32.875] iteration 4970: loss: 0.123190, loss_s1: 0.064691, loss_fp: 0.000733, loss_freq: 0.031308
[03:20:33.469] iteration 4971: loss: 0.177198, loss_s1: 0.186196, loss_fp: 0.001112, loss_freq: 0.043155
[03:20:34.062] iteration 4972: loss: 0.171542, loss_s1: 0.190993, loss_fp: 0.001318, loss_freq: 0.040470
[03:20:34.649] iteration 4973: loss: 0.141046, loss_s1: 0.042446, loss_fp: 0.003029, loss_freq: 0.046945
[03:20:35.243] iteration 4974: loss: 0.227441, loss_s1: 0.215834, loss_fp: 0.000849, loss_freq: 0.124571
[03:20:35.833] iteration 4975: loss: 0.138137, loss_s1: 0.060929, loss_fp: 0.006073, loss_freq: 0.052263
[03:20:36.420] iteration 4976: loss: 0.110132, loss_s1: 0.062854, loss_fp: 0.015218, loss_freq: 0.039325
[03:20:37.009] iteration 4977: loss: 0.118665, loss_s1: 0.091201, loss_fp: 0.001431, loss_freq: 0.027486
[03:20:37.602] iteration 4978: loss: 0.117821, loss_s1: 0.053091, loss_fp: 0.000873, loss_freq: 0.056032
[03:20:38.192] iteration 4979: loss: 0.155012, loss_s1: 0.145760, loss_fp: 0.007168, loss_freq: 0.028064
[03:20:38.780] iteration 4980: loss: 0.198083, loss_s1: 0.127010, loss_fp: 0.000798, loss_freq: 0.077877
[03:20:39.373] iteration 4981: loss: 0.192295, loss_s1: 0.162284, loss_fp: 0.003316, loss_freq: 0.059394
[03:20:39.964] iteration 4982: loss: 0.108947, loss_s1: 0.076918, loss_fp: 0.002220, loss_freq: 0.028953
[03:20:40.596] iteration 4983: loss: 0.129842, loss_s1: 0.045611, loss_fp: 0.000980, loss_freq: 0.033157
[03:20:41.238] iteration 4984: loss: 0.157919, loss_s1: 0.133889, loss_fp: 0.004149, loss_freq: 0.050777
[03:20:41.873] iteration 4985: loss: 0.206604, loss_s1: 0.139045, loss_fp: 0.000680, loss_freq: 0.114173
[03:20:42.507] iteration 4986: loss: 0.117696, loss_s1: 0.023356, loss_fp: 0.001433, loss_freq: 0.017483
[03:20:43.135] iteration 4987: loss: 0.123477, loss_s1: 0.104044, loss_fp: 0.000959, loss_freq: 0.025114
[03:20:43.762] iteration 4988: loss: 0.138364, loss_s1: 0.083294, loss_fp: 0.001155, loss_freq: 0.033551
[03:20:44.350] iteration 4989: loss: 0.162724, loss_s1: 0.102371, loss_fp: 0.003032, loss_freq: 0.049917
[03:20:44.942] iteration 4990: loss: 0.151612, loss_s1: 0.132191, loss_fp: 0.002739, loss_freq: 0.057320
[03:20:45.534] iteration 4991: loss: 0.106477, loss_s1: 0.044070, loss_fp: 0.003378, loss_freq: 0.019436
[03:20:46.123] iteration 4992: loss: 0.158762, loss_s1: 0.072383, loss_fp: 0.003221, loss_freq: 0.056284
[03:20:46.712] iteration 4993: loss: 0.098600, loss_s1: 0.050699, loss_fp: 0.000654, loss_freq: 0.016888
[03:20:47.304] iteration 4994: loss: 0.130435, loss_s1: 0.067398, loss_fp: 0.002957, loss_freq: 0.038697
[03:20:47.903] iteration 4995: loss: 0.107955, loss_s1: 0.036189, loss_fp: 0.001127, loss_freq: 0.011853
[03:20:48.492] iteration 4996: loss: 0.123058, loss_s1: 0.072323, loss_fp: 0.002858, loss_freq: 0.032066
[03:20:49.084] iteration 4997: loss: 0.188317, loss_s1: 0.079361, loss_fp: 0.002215, loss_freq: 0.011176
[03:20:49.677] iteration 4998: loss: 0.162990, loss_s1: 0.082338, loss_fp: 0.004820, loss_freq: 0.035691
[03:20:50.270] iteration 4999: loss: 0.083003, loss_s1: 0.030588, loss_fp: 0.014732, loss_freq: 0.017004
[03:20:50.857] iteration 5000: loss: 0.143837, loss_s1: 0.098989, loss_fp: 0.010797, loss_freq: 0.033501
[03:20:54.266] iteration 5000 : mean_dice : 0.598368
[03:20:54.895] iteration 5001: loss: 0.114471, loss_s1: 0.057100, loss_fp: 0.000745, loss_freq: 0.055476
[03:20:55.487] iteration 5002: loss: 0.099786, loss_s1: 0.030443, loss_fp: 0.002002, loss_freq: 0.035524
[03:20:56.077] iteration 5003: loss: 0.093673, loss_s1: 0.061608, loss_fp: 0.003542, loss_freq: 0.034843
[03:20:56.665] iteration 5004: loss: 0.168371, loss_s1: 0.193051, loss_fp: 0.001201, loss_freq: 0.015527
[03:20:57.252] iteration 5005: loss: 0.200137, loss_s1: 0.157565, loss_fp: 0.000762, loss_freq: 0.073160
[03:20:57.840] iteration 5006: loss: 0.155892, loss_s1: 0.127573, loss_fp: 0.005151, loss_freq: 0.038094
[03:20:58.427] iteration 5007: loss: 0.120252, loss_s1: 0.090851, loss_fp: 0.000794, loss_freq: 0.032684
[03:20:59.022] iteration 5008: loss: 0.167052, loss_s1: 0.154555, loss_fp: 0.002096, loss_freq: 0.049763
[03:20:59.617] iteration 5009: loss: 0.171578, loss_s1: 0.171002, loss_fp: 0.002152, loss_freq: 0.052308
[03:21:00.223] iteration 5010: loss: 0.121865, loss_s1: 0.042815, loss_fp: 0.000574, loss_freq: 0.018736
[03:21:00.858] iteration 5011: loss: 0.128628, loss_s1: 0.061564, loss_fp: 0.004062, loss_freq: 0.059038
[03:21:01.494] iteration 5012: loss: 0.128049, loss_s1: 0.088852, loss_fp: 0.001409, loss_freq: 0.063194
[03:21:02.152] iteration 5013: loss: 0.175145, loss_s1: 0.139047, loss_fp: 0.017295, loss_freq: 0.060697
[03:21:02.785] iteration 5014: loss: 0.096097, loss_s1: 0.057649, loss_fp: 0.003998, loss_freq: 0.045189
[03:21:03.387] iteration 5015: loss: 0.134305, loss_s1: 0.062158, loss_fp: 0.001172, loss_freq: 0.024004
[03:21:03.996] iteration 5016: loss: 0.097355, loss_s1: 0.054587, loss_fp: 0.005602, loss_freq: 0.042374
[03:21:04.711] iteration 5017: loss: 0.114946, loss_s1: 0.113535, loss_fp: 0.000947, loss_freq: 0.036549
[03:21:05.343] iteration 5018: loss: 0.072937, loss_s1: 0.025444, loss_fp: 0.001936, loss_freq: 0.013285
[03:21:06.083] iteration 5019: loss: 0.099540, loss_s1: 0.069147, loss_fp: 0.001679, loss_freq: 0.019303
[03:21:06.750] iteration 5020: loss: 0.139798, loss_s1: 0.088748, loss_fp: 0.001029, loss_freq: 0.022410
[03:21:07.434] iteration 5021: loss: 0.087236, loss_s1: 0.058590, loss_fp: 0.002103, loss_freq: 0.017292
[03:21:08.250] iteration 5022: loss: 0.150225, loss_s1: 0.108890, loss_fp: 0.005703, loss_freq: 0.029036
[03:21:08.854] iteration 5023: loss: 0.197858, loss_s1: 0.117824, loss_fp: 0.001272, loss_freq: 0.033080
[03:21:09.574] iteration 5024: loss: 0.105310, loss_s1: 0.069366, loss_fp: 0.003667, loss_freq: 0.021246
[03:21:10.212] iteration 5025: loss: 0.156040, loss_s1: 0.166331, loss_fp: 0.000877, loss_freq: 0.035986
[03:21:10.851] iteration 5026: loss: 0.105704, loss_s1: 0.057985, loss_fp: 0.002297, loss_freq: 0.034354
[03:21:11.611] iteration 5027: loss: 0.142732, loss_s1: 0.064064, loss_fp: 0.001915, loss_freq: 0.042547
[03:21:12.321] iteration 5028: loss: 0.103367, loss_s1: 0.073031, loss_fp: 0.003220, loss_freq: 0.024242
[03:21:13.027] iteration 5029: loss: 0.106734, loss_s1: 0.049508, loss_fp: 0.003720, loss_freq: 0.027937
[03:21:13.738] iteration 5030: loss: 0.070851, loss_s1: 0.040197, loss_fp: 0.000948, loss_freq: 0.013509
[03:21:14.355] iteration 5031: loss: 0.152172, loss_s1: 0.095502, loss_fp: 0.001088, loss_freq: 0.097640
[03:21:15.123] iteration 5032: loss: 0.123393, loss_s1: 0.042020, loss_fp: 0.000560, loss_freq: 0.051848
[03:21:15.780] iteration 5033: loss: 0.124773, loss_s1: 0.076127, loss_fp: 0.000909, loss_freq: 0.025786
[03:21:16.379] iteration 5034: loss: 0.082382, loss_s1: 0.015218, loss_fp: 0.000771, loss_freq: 0.016635
[03:21:17.108] iteration 5035: loss: 0.091870, loss_s1: 0.055480, loss_fp: 0.004121, loss_freq: 0.023268
[03:21:17.713] iteration 5036: loss: 0.105455, loss_s1: 0.033643, loss_fp: 0.002436, loss_freq: 0.028635
[03:21:18.315] iteration 5037: loss: 0.096065, loss_s1: 0.038718, loss_fp: 0.003442, loss_freq: 0.034396
[03:21:19.157] iteration 5038: loss: 0.117378, loss_s1: 0.081043, loss_fp: 0.001850, loss_freq: 0.040827
[03:21:19.788] iteration 5039: loss: 0.184707, loss_s1: 0.148896, loss_fp: 0.001829, loss_freq: 0.084666
[03:21:20.405] iteration 5040: loss: 0.108968, loss_s1: 0.061172, loss_fp: 0.001007, loss_freq: 0.015099
[03:21:21.003] iteration 5041: loss: 0.131567, loss_s1: 0.068423, loss_fp: 0.003488, loss_freq: 0.019758
[03:21:21.643] iteration 5042: loss: 0.064718, loss_s1: 0.038377, loss_fp: 0.003895, loss_freq: 0.009833
[03:21:22.233] iteration 5043: loss: 0.109938, loss_s1: 0.101451, loss_fp: 0.001717, loss_freq: 0.019293
[03:21:22.838] iteration 5044: loss: 0.104530, loss_s1: 0.072126, loss_fp: 0.001571, loss_freq: 0.023542
[03:21:23.434] iteration 5045: loss: 0.180495, loss_s1: 0.159556, loss_fp: 0.004115, loss_freq: 0.080054
[03:21:24.027] iteration 5046: loss: 0.137289, loss_s1: 0.047790, loss_fp: 0.003538, loss_freq: 0.036300
[03:21:24.615] iteration 5047: loss: 0.132934, loss_s1: 0.057368, loss_fp: 0.002396, loss_freq: 0.055271
[03:21:25.210] iteration 5048: loss: 0.093915, loss_s1: 0.047378, loss_fp: 0.001138, loss_freq: 0.033310
[03:21:25.799] iteration 5049: loss: 0.229155, loss_s1: 0.133754, loss_fp: 0.004242, loss_freq: 0.201778
[03:21:26.392] iteration 5050: loss: 0.130941, loss_s1: 0.084754, loss_fp: 0.001366, loss_freq: 0.023353
[03:21:26.979] iteration 5051: loss: 0.079816, loss_s1: 0.047774, loss_fp: 0.000808, loss_freq: 0.010377
[03:21:27.569] iteration 5052: loss: 0.137040, loss_s1: 0.077388, loss_fp: 0.002294, loss_freq: 0.060541
[03:21:28.151] iteration 5053: loss: 0.144059, loss_s1: 0.069729, loss_fp: 0.006992, loss_freq: 0.025875
[03:21:28.742] iteration 5054: loss: 0.172008, loss_s1: 0.162533, loss_fp: 0.021715, loss_freq: 0.065689
[03:21:29.375] iteration 5055: loss: 0.102149, loss_s1: 0.034006, loss_fp: 0.019987, loss_freq: 0.027291
[03:21:30.026] iteration 5056: loss: 0.090255, loss_s1: 0.088620, loss_fp: 0.000560, loss_freq: 0.006411
[03:21:30.656] iteration 5057: loss: 0.168120, loss_s1: 0.109906, loss_fp: 0.001353, loss_freq: 0.134448
[03:21:31.285] iteration 5058: loss: 0.174749, loss_s1: 0.131576, loss_fp: 0.000963, loss_freq: 0.049026
[03:21:31.938] iteration 5059: loss: 0.149991, loss_s1: 0.112810, loss_fp: 0.002683, loss_freq: 0.027604
[03:21:32.567] iteration 5060: loss: 0.192340, loss_s1: 0.214173, loss_fp: 0.006130, loss_freq: 0.066017
[03:21:33.161] iteration 5061: loss: 0.153571, loss_s1: 0.163948, loss_fp: 0.004193, loss_freq: 0.042265
[03:21:33.779] iteration 5062: loss: 0.151765, loss_s1: 0.055931, loss_fp: 0.039939, loss_freq: 0.026765
[03:21:34.366] iteration 5063: loss: 0.198232, loss_s1: 0.178739, loss_fp: 0.035573, loss_freq: 0.070658
[03:21:34.954] iteration 5064: loss: 0.117557, loss_s1: 0.061902, loss_fp: 0.002336, loss_freq: 0.040216
[03:21:35.544] iteration 5065: loss: 0.184028, loss_s1: 0.134013, loss_fp: 0.002649, loss_freq: 0.100792
[03:21:36.133] iteration 5066: loss: 0.066147, loss_s1: 0.006092, loss_fp: 0.004937, loss_freq: 0.011396
[03:21:36.783] iteration 5067: loss: 0.205392, loss_s1: 0.151033, loss_fp: 0.001596, loss_freq: 0.009923
[03:21:37.422] iteration 5068: loss: 0.056287, loss_s1: 0.012855, loss_fp: 0.003132, loss_freq: 0.009532
[03:21:38.060] iteration 5069: loss: 0.169798, loss_s1: 0.130687, loss_fp: 0.027485, loss_freq: 0.089253
[03:21:38.663] iteration 5070: loss: 0.087989, loss_s1: 0.071346, loss_fp: 0.002289, loss_freq: 0.022150
[03:21:39.261] iteration 5071: loss: 0.147177, loss_s1: 0.147082, loss_fp: 0.004148, loss_freq: 0.027399
[03:21:39.853] iteration 5072: loss: 0.091907, loss_s1: 0.060100, loss_fp: 0.003895, loss_freq: 0.018588
[03:21:40.448] iteration 5073: loss: 0.174043, loss_s1: 0.168509, loss_fp: 0.009409, loss_freq: 0.054235
[03:21:41.043] iteration 5074: loss: 0.131896, loss_s1: 0.132248, loss_fp: 0.001720, loss_freq: 0.036717
[03:21:41.635] iteration 5075: loss: 0.095884, loss_s1: 0.055770, loss_fp: 0.001718, loss_freq: 0.047584
[03:21:42.301] iteration 5076: loss: 0.138765, loss_s1: 0.062151, loss_fp: 0.002337, loss_freq: 0.024733
[03:21:42.930] iteration 5077: loss: 0.091360, loss_s1: 0.069749, loss_fp: 0.008662, loss_freq: 0.031624
[03:21:43.558] iteration 5078: loss: 0.147361, loss_s1: 0.128261, loss_fp: 0.000977, loss_freq: 0.051020
[03:21:44.178] iteration 5079: loss: 0.139665, loss_s1: 0.119103, loss_fp: 0.002980, loss_freq: 0.068391
[03:21:44.769] iteration 5080: loss: 0.114126, loss_s1: 0.033946, loss_fp: 0.013012, loss_freq: 0.033446
[03:21:45.362] iteration 5081: loss: 0.152230, loss_s1: 0.116324, loss_fp: 0.003191, loss_freq: 0.032485
[03:21:45.949] iteration 5082: loss: 0.113437, loss_s1: 0.077105, loss_fp: 0.001566, loss_freq: 0.056788
[03:21:46.539] iteration 5083: loss: 0.134389, loss_s1: 0.072808, loss_fp: 0.011608, loss_freq: 0.056869
[03:21:47.131] iteration 5084: loss: 0.106303, loss_s1: 0.060395, loss_fp: 0.002619, loss_freq: 0.035021
[03:21:47.721] iteration 5085: loss: 0.188230, loss_s1: 0.111003, loss_fp: 0.002130, loss_freq: 0.048091
[03:21:48.308] iteration 5086: loss: 0.136703, loss_s1: 0.089468, loss_fp: 0.002787, loss_freq: 0.050017
[03:21:48.900] iteration 5087: loss: 0.114738, loss_s1: 0.060939, loss_fp: 0.004004, loss_freq: 0.056946
[03:21:49.504] iteration 5088: loss: 0.191157, loss_s1: 0.095167, loss_fp: 0.002232, loss_freq: 0.090443
[03:21:50.096] iteration 5089: loss: 0.069828, loss_s1: 0.025546, loss_fp: 0.005331, loss_freq: 0.028510
[03:21:50.695] iteration 5090: loss: 0.127841, loss_s1: 0.090651, loss_fp: 0.005024, loss_freq: 0.039859
[03:21:51.300] iteration 5091: loss: 0.109438, loss_s1: 0.061693, loss_fp: 0.003722, loss_freq: 0.011349
[03:21:51.896] iteration 5092: loss: 0.108421, loss_s1: 0.065327, loss_fp: 0.003297, loss_freq: 0.012145
[03:21:52.485] iteration 5093: loss: 0.150867, loss_s1: 0.037744, loss_fp: 0.001500, loss_freq: 0.033606
[03:21:53.072] iteration 5094: loss: 0.170739, loss_s1: 0.131467, loss_fp: 0.005904, loss_freq: 0.049474
[03:21:53.660] iteration 5095: loss: 0.097093, loss_s1: 0.066765, loss_fp: 0.005149, loss_freq: 0.023267
[03:21:54.250] iteration 5096: loss: 0.145934, loss_s1: 0.111115, loss_fp: 0.006379, loss_freq: 0.044141
[03:21:54.841] iteration 5097: loss: 0.122361, loss_s1: 0.059883, loss_fp: 0.000511, loss_freq: 0.060219
[03:21:55.428] iteration 5098: loss: 0.113544, loss_s1: 0.106178, loss_fp: 0.001150, loss_freq: 0.011834
[03:21:56.014] iteration 5099: loss: 0.160412, loss_s1: 0.122631, loss_fp: 0.001785, loss_freq: 0.064153
[03:21:56.605] iteration 5100: loss: 0.125388, loss_s1: 0.065898, loss_fp: 0.006084, loss_freq: 0.021838
[03:21:57.544] iteration 5101: loss: 0.111901, loss_s1: 0.068762, loss_fp: 0.005856, loss_freq: 0.022985
[03:21:58.133] iteration 5102: loss: 0.075177, loss_s1: 0.039797, loss_fp: 0.000389, loss_freq: 0.021366
[03:21:58.726] iteration 5103: loss: 0.139800, loss_s1: 0.096808, loss_fp: 0.002135, loss_freq: 0.046742
[03:21:59.316] iteration 5104: loss: 0.107348, loss_s1: 0.075428, loss_fp: 0.001444, loss_freq: 0.019282
[03:21:59.905] iteration 5105: loss: 0.162579, loss_s1: 0.090373, loss_fp: 0.007134, loss_freq: 0.043192
[03:22:00.493] iteration 5106: loss: 0.110415, loss_s1: 0.076466, loss_fp: 0.006495, loss_freq: 0.023946
[03:22:01.083] iteration 5107: loss: 0.101217, loss_s1: 0.028397, loss_fp: 0.001737, loss_freq: 0.030901
[03:22:01.674] iteration 5108: loss: 0.110916, loss_s1: 0.067162, loss_fp: 0.002429, loss_freq: 0.026463
[03:22:02.271] iteration 5109: loss: 0.102566, loss_s1: 0.097828, loss_fp: 0.003296, loss_freq: 0.024610
[03:22:02.864] iteration 5110: loss: 0.141313, loss_s1: 0.116601, loss_fp: 0.003550, loss_freq: 0.051800
[03:22:03.457] iteration 5111: loss: 0.101009, loss_s1: 0.040442, loss_fp: 0.000944, loss_freq: 0.037618
[03:22:04.050] iteration 5112: loss: 0.142024, loss_s1: 0.122607, loss_fp: 0.000879, loss_freq: 0.042572
[03:22:04.638] iteration 5113: loss: 0.121309, loss_s1: 0.046290, loss_fp: 0.001685, loss_freq: 0.064411
[03:22:05.221] iteration 5114: loss: 0.072458, loss_s1: 0.031468, loss_fp: 0.003110, loss_freq: 0.013204
[03:22:05.808] iteration 5115: loss: 0.102837, loss_s1: 0.075670, loss_fp: 0.004250, loss_freq: 0.015486
[03:22:06.398] iteration 5116: loss: 0.103994, loss_s1: 0.033008, loss_fp: 0.006642, loss_freq: 0.022297
[03:22:06.987] iteration 5117: loss: 0.183690, loss_s1: 0.143406, loss_fp: 0.002594, loss_freq: 0.090168
[03:22:07.580] iteration 5118: loss: 0.110753, loss_s1: 0.048915, loss_fp: 0.000719, loss_freq: 0.018179
[03:22:08.166] iteration 5119: loss: 0.130223, loss_s1: 0.111488, loss_fp: 0.005687, loss_freq: 0.054311
[03:22:08.754] iteration 5120: loss: 0.151825, loss_s1: 0.100486, loss_fp: 0.000531, loss_freq: 0.025403
[03:22:09.349] iteration 5121: loss: 0.125268, loss_s1: 0.080992, loss_fp: 0.012431, loss_freq: 0.024932
[03:22:09.945] iteration 5122: loss: 0.148275, loss_s1: 0.055043, loss_fp: 0.003464, loss_freq: 0.053498
[03:22:10.545] iteration 5123: loss: 0.167276, loss_s1: 0.059550, loss_fp: 0.003258, loss_freq: 0.019125
[03:22:11.142] iteration 5124: loss: 0.079833, loss_s1: 0.032461, loss_fp: 0.000546, loss_freq: 0.012483
[03:22:11.735] iteration 5125: loss: 0.092300, loss_s1: 0.081434, loss_fp: 0.003456, loss_freq: 0.007976
[03:22:12.324] iteration 5126: loss: 0.136844, loss_s1: 0.108122, loss_fp: 0.002110, loss_freq: 0.051017
[03:22:12.910] iteration 5127: loss: 0.100641, loss_s1: 0.061112, loss_fp: 0.002507, loss_freq: 0.023661
[03:22:13.501] iteration 5128: loss: 0.158414, loss_s1: 0.096220, loss_fp: 0.004153, loss_freq: 0.057963
[03:22:14.131] iteration 5129: loss: 0.120656, loss_s1: 0.060225, loss_fp: 0.000967, loss_freq: 0.022624
[03:22:14.737] iteration 5130: loss: 0.083440, loss_s1: 0.056849, loss_fp: 0.000978, loss_freq: 0.032713
[03:22:15.336] iteration 5131: loss: 0.115965, loss_s1: 0.092992, loss_fp: 0.002017, loss_freq: 0.026342
[03:22:15.929] iteration 5132: loss: 0.158503, loss_s1: 0.094605, loss_fp: 0.004506, loss_freq: 0.036498
[03:22:16.521] iteration 5133: loss: 0.155349, loss_s1: 0.132631, loss_fp: 0.005400, loss_freq: 0.027373
[03:22:17.133] iteration 5134: loss: 0.095739, loss_s1: 0.085160, loss_fp: 0.003488, loss_freq: 0.011490
[03:22:17.726] iteration 5135: loss: 0.094020, loss_s1: 0.064128, loss_fp: 0.004428, loss_freq: 0.017445
[03:22:18.341] iteration 5136: loss: 0.085892, loss_s1: 0.050579, loss_fp: 0.003088, loss_freq: 0.010146
[03:22:18.941] iteration 5137: loss: 0.119637, loss_s1: 0.081836, loss_fp: 0.009615, loss_freq: 0.040777
[03:22:19.530] iteration 5138: loss: 0.141992, loss_s1: 0.144320, loss_fp: 0.001035, loss_freq: 0.025206
[03:22:20.122] iteration 5139: loss: 0.153735, loss_s1: 0.129131, loss_fp: 0.000975, loss_freq: 0.059980
[03:22:20.711] iteration 5140: loss: 0.180698, loss_s1: 0.121006, loss_fp: 0.010563, loss_freq: 0.075028
[03:22:21.304] iteration 5141: loss: 0.158773, loss_s1: 0.118690, loss_fp: 0.000743, loss_freq: 0.060979
[03:22:21.909] iteration 5142: loss: 0.172548, loss_s1: 0.128582, loss_fp: 0.008720, loss_freq: 0.045816
[03:22:22.500] iteration 5143: loss: 0.125198, loss_s1: 0.082312, loss_fp: 0.014529, loss_freq: 0.059737
[03:22:23.090] iteration 5144: loss: 0.212621, loss_s1: 0.196285, loss_fp: 0.002968, loss_freq: 0.112833
[03:22:23.683] iteration 5145: loss: 0.166561, loss_s1: 0.047665, loss_fp: 0.002065, loss_freq: 0.034909
[03:22:24.275] iteration 5146: loss: 0.111364, loss_s1: 0.097502, loss_fp: 0.003103, loss_freq: 0.019633
[03:22:24.864] iteration 5147: loss: 0.118517, loss_s1: 0.072216, loss_fp: 0.001790, loss_freq: 0.014925
[03:22:25.451] iteration 5148: loss: 0.079476, loss_s1: 0.018033, loss_fp: 0.001349, loss_freq: 0.020026
[03:22:26.041] iteration 5149: loss: 0.134143, loss_s1: 0.089478, loss_fp: 0.006761, loss_freq: 0.046579
[03:22:26.627] iteration 5150: loss: 0.107216, loss_s1: 0.049892, loss_fp: 0.000644, loss_freq: 0.021379
[03:22:27.219] iteration 5151: loss: 0.119124, loss_s1: 0.080657, loss_fp: 0.004277, loss_freq: 0.072059
[03:22:27.819] iteration 5152: loss: 0.109080, loss_s1: 0.064284, loss_fp: 0.014302, loss_freq: 0.047640
[03:22:28.477] iteration 5153: loss: 0.151757, loss_s1: 0.063914, loss_fp: 0.002260, loss_freq: 0.064968
[03:22:29.118] iteration 5154: loss: 0.138011, loss_s1: 0.080548, loss_fp: 0.001983, loss_freq: 0.064465
[03:22:29.756] iteration 5155: loss: 0.142345, loss_s1: 0.028721, loss_fp: 0.001392, loss_freq: 0.079806
[03:22:30.341] iteration 5156: loss: 0.117184, loss_s1: 0.050760, loss_fp: 0.000889, loss_freq: 0.046167
[03:22:30.933] iteration 5157: loss: 0.091347, loss_s1: 0.048618, loss_fp: 0.001157, loss_freq: 0.015685
[03:22:31.520] iteration 5158: loss: 0.108829, loss_s1: 0.057507, loss_fp: 0.008748, loss_freq: 0.012256
[03:22:32.106] iteration 5159: loss: 0.181538, loss_s1: 0.070965, loss_fp: 0.000577, loss_freq: 0.029547
[03:22:32.693] iteration 5160: loss: 0.174082, loss_s1: 0.174702, loss_fp: 0.003719, loss_freq: 0.086616
[03:22:33.276] iteration 5161: loss: 0.105975, loss_s1: 0.047877, loss_fp: 0.001218, loss_freq: 0.040154
[03:22:33.860] iteration 5162: loss: 0.111495, loss_s1: 0.049593, loss_fp: 0.007779, loss_freq: 0.029283
[03:22:34.455] iteration 5163: loss: 0.087783, loss_s1: 0.049118, loss_fp: 0.000630, loss_freq: 0.012021
[03:22:35.052] iteration 5164: loss: 0.155234, loss_s1: 0.081014, loss_fp: 0.000485, loss_freq: 0.048719
[03:22:35.679] iteration 5165: loss: 0.066754, loss_s1: 0.023760, loss_fp: 0.000412, loss_freq: 0.015125
[03:22:36.312] iteration 5166: loss: 0.095236, loss_s1: 0.040286, loss_fp: 0.004107, loss_freq: 0.025416
[03:22:36.947] iteration 5167: loss: 0.133858, loss_s1: 0.069669, loss_fp: 0.000988, loss_freq: 0.012083
[03:22:37.581] iteration 5168: loss: 0.220130, loss_s1: 0.272885, loss_fp: 0.003870, loss_freq: 0.060180
[03:22:38.213] iteration 5169: loss: 0.096707, loss_s1: 0.045231, loss_fp: 0.000385, loss_freq: 0.016580
[03:22:38.837] iteration 5170: loss: 0.134541, loss_s1: 0.084361, loss_fp: 0.002110, loss_freq: 0.019601
[03:22:39.434] iteration 5171: loss: 0.145642, loss_s1: 0.092772, loss_fp: 0.004019, loss_freq: 0.044476
[03:22:40.024] iteration 5172: loss: 0.084070, loss_s1: 0.024540, loss_fp: 0.002122, loss_freq: 0.014843
[03:22:40.689] iteration 5173: loss: 0.099433, loss_s1: 0.034730, loss_fp: 0.003259, loss_freq: 0.039229
[03:22:41.318] iteration 5174: loss: 0.159505, loss_s1: 0.141164, loss_fp: 0.008993, loss_freq: 0.025639
[03:22:41.950] iteration 5175: loss: 0.171399, loss_s1: 0.097600, loss_fp: 0.004537, loss_freq: 0.089780
[03:22:42.588] iteration 5176: loss: 0.137451, loss_s1: 0.092426, loss_fp: 0.001983, loss_freq: 0.033371
[03:22:43.187] iteration 5177: loss: 0.077097, loss_s1: 0.056668, loss_fp: 0.000854, loss_freq: 0.023858
[03:22:43.778] iteration 5178: loss: 0.211060, loss_s1: 0.086676, loss_fp: 0.001342, loss_freq: 0.077495
[03:22:44.372] iteration 5179: loss: 0.090873, loss_s1: 0.037695, loss_fp: 0.002229, loss_freq: 0.040296
[03:22:44.961] iteration 5180: loss: 0.130536, loss_s1: 0.094243, loss_fp: 0.004009, loss_freq: 0.033015
[03:22:45.551] iteration 5181: loss: 0.157138, loss_s1: 0.072750, loss_fp: 0.004044, loss_freq: 0.050239
[03:22:46.147] iteration 5182: loss: 0.104297, loss_s1: 0.075090, loss_fp: 0.007579, loss_freq: 0.012716
[03:22:46.741] iteration 5183: loss: 0.120880, loss_s1: 0.056117, loss_fp: 0.001892, loss_freq: 0.079958
[03:22:47.396] iteration 5184: loss: 0.119631, loss_s1: 0.085817, loss_fp: 0.000675, loss_freq: 0.019385
[03:22:48.060] iteration 5185: loss: 0.127191, loss_s1: 0.107628, loss_fp: 0.002195, loss_freq: 0.014244
[03:22:48.659] iteration 5186: loss: 0.105907, loss_s1: 0.057318, loss_fp: 0.002001, loss_freq: 0.042118
[03:22:49.257] iteration 5187: loss: 0.158107, loss_s1: 0.137975, loss_fp: 0.002350, loss_freq: 0.083935
[03:22:49.850] iteration 5188: loss: 0.138276, loss_s1: 0.065365, loss_fp: 0.003243, loss_freq: 0.046059
[03:22:50.445] iteration 5189: loss: 0.176806, loss_s1: 0.097427, loss_fp: 0.002613, loss_freq: 0.109149
[03:22:51.036] iteration 5190: loss: 0.110151, loss_s1: 0.072962, loss_fp: 0.000691, loss_freq: 0.021129
[03:22:51.628] iteration 5191: loss: 0.095576, loss_s1: 0.066202, loss_fp: 0.001973, loss_freq: 0.024258
[03:22:52.221] iteration 5192: loss: 0.112619, loss_s1: 0.074197, loss_fp: 0.000912, loss_freq: 0.031751
[03:22:52.813] iteration 5193: loss: 0.187219, loss_s1: 0.121088, loss_fp: 0.001997, loss_freq: 0.075019
[03:22:53.406] iteration 5194: loss: 0.124583, loss_s1: 0.100162, loss_fp: 0.001350, loss_freq: 0.029729
[03:22:53.997] iteration 5195: loss: 0.081151, loss_s1: 0.057465, loss_fp: 0.000826, loss_freq: 0.014105
[03:22:54.591] iteration 5196: loss: 0.098683, loss_s1: 0.054280, loss_fp: 0.001686, loss_freq: 0.039979
[03:22:55.183] iteration 5197: loss: 0.133012, loss_s1: 0.091245, loss_fp: 0.001272, loss_freq: 0.045264
[03:22:55.780] iteration 5198: loss: 0.100504, loss_s1: 0.052066, loss_fp: 0.003626, loss_freq: 0.029887
[03:22:56.374] iteration 5199: loss: 0.099090, loss_s1: 0.078075, loss_fp: 0.003275, loss_freq: 0.024543
[03:22:56.961] iteration 5200: loss: 0.101302, loss_s1: 0.044136, loss_fp: 0.000544, loss_freq: 0.016796
[03:23:00.130] iteration 5200 : mean_dice : 0.589139
[03:23:00.771] iteration 5201: loss: 0.178481, loss_s1: 0.152845, loss_fp: 0.002838, loss_freq: 0.066631
[03:23:01.368] iteration 5202: loss: 0.126331, loss_s1: 0.070224, loss_fp: 0.004073, loss_freq: 0.021438
[03:23:01.961] iteration 5203: loss: 0.073319, loss_s1: 0.038822, loss_fp: 0.001351, loss_freq: 0.025894
[03:23:02.549] iteration 5204: loss: 0.109898, loss_s1: 0.057461, loss_fp: 0.002181, loss_freq: 0.032862
[03:23:03.132] iteration 5205: loss: 0.113367, loss_s1: 0.060759, loss_fp: 0.000942, loss_freq: 0.038808
[03:23:03.723] iteration 5206: loss: 0.135821, loss_s1: 0.084965, loss_fp: 0.001626, loss_freq: 0.057962
[03:23:04.310] iteration 5207: loss: 0.101438, loss_s1: 0.060495, loss_fp: 0.000569, loss_freq: 0.020296
[03:23:04.904] iteration 5208: loss: 0.132673, loss_s1: 0.128925, loss_fp: 0.001146, loss_freq: 0.031444
[03:23:05.498] iteration 5209: loss: 0.172751, loss_s1: 0.106806, loss_fp: 0.007412, loss_freq: 0.103748
[03:23:06.087] iteration 5210: loss: 0.120965, loss_s1: 0.114431, loss_fp: 0.002144, loss_freq: 0.022668
[03:23:06.677] iteration 5211: loss: 0.127888, loss_s1: 0.071240, loss_fp: 0.001580, loss_freq: 0.035323
[03:23:07.271] iteration 5212: loss: 0.110498, loss_s1: 0.051425, loss_fp: 0.000910, loss_freq: 0.078493
[03:23:07.869] iteration 5213: loss: 0.099121, loss_s1: 0.073254, loss_fp: 0.001304, loss_freq: 0.029411
[03:23:08.461] iteration 5214: loss: 0.089001, loss_s1: 0.032387, loss_fp: 0.010607, loss_freq: 0.027742
[03:23:09.052] iteration 5215: loss: 0.179422, loss_s1: 0.119857, loss_fp: 0.006551, loss_freq: 0.068118
[03:23:09.662] iteration 5216: loss: 0.121496, loss_s1: 0.077112, loss_fp: 0.001250, loss_freq: 0.062933
[03:23:10.254] iteration 5217: loss: 0.133821, loss_s1: 0.095763, loss_fp: 0.000844, loss_freq: 0.096737
[03:23:10.841] iteration 5218: loss: 0.099180, loss_s1: 0.045088, loss_fp: 0.006915, loss_freq: 0.046431
[03:23:11.431] iteration 5219: loss: 0.199198, loss_s1: 0.123828, loss_fp: 0.002054, loss_freq: 0.125214
[03:23:12.023] iteration 5220: loss: 0.112126, loss_s1: 0.062841, loss_fp: 0.002943, loss_freq: 0.022873
[03:23:12.614] iteration 5221: loss: 0.112717, loss_s1: 0.047970, loss_fp: 0.000851, loss_freq: 0.015243
[03:23:13.246] iteration 5222: loss: 0.134659, loss_s1: 0.125551, loss_fp: 0.003808, loss_freq: 0.048967
[03:23:13.848] iteration 5223: loss: 0.191547, loss_s1: 0.160457, loss_fp: 0.001636, loss_freq: 0.063275
[03:23:14.443] iteration 5224: loss: 0.125501, loss_s1: 0.066426, loss_fp: 0.007933, loss_freq: 0.082106
[03:23:15.034] iteration 5225: loss: 0.108556, loss_s1: 0.060769, loss_fp: 0.007428, loss_freq: 0.031001
[03:23:15.632] iteration 5226: loss: 0.107513, loss_s1: 0.073633, loss_fp: 0.000743, loss_freq: 0.017545
[03:23:16.220] iteration 5227: loss: 0.202758, loss_s1: 0.079749, loss_fp: 0.021241, loss_freq: 0.196944
[03:23:16.815] iteration 5228: loss: 0.161357, loss_s1: 0.070216, loss_fp: 0.001985, loss_freq: 0.118529
[03:23:17.403] iteration 5229: loss: 0.074740, loss_s1: 0.025522, loss_fp: 0.001098, loss_freq: 0.005065
[03:23:17.994] iteration 5230: loss: 0.158815, loss_s1: 0.178094, loss_fp: 0.001196, loss_freq: 0.065284
[03:23:18.589] iteration 5231: loss: 0.117879, loss_s1: 0.058027, loss_fp: 0.006292, loss_freq: 0.074454
[03:23:19.194] iteration 5232: loss: 0.152371, loss_s1: 0.076601, loss_fp: 0.000397, loss_freq: 0.006705
[03:23:19.785] iteration 5233: loss: 0.172154, loss_s1: 0.141294, loss_fp: 0.020140, loss_freq: 0.032995
[03:23:20.383] iteration 5234: loss: 0.144759, loss_s1: 0.117263, loss_fp: 0.004545, loss_freq: 0.028268
[03:23:20.982] iteration 5235: loss: 0.089433, loss_s1: 0.041316, loss_fp: 0.000721, loss_freq: 0.037916
[03:23:21.580] iteration 5236: loss: 0.122566, loss_s1: 0.084510, loss_fp: 0.008037, loss_freq: 0.041531
[03:23:22.168] iteration 5237: loss: 0.189289, loss_s1: 0.048781, loss_fp: 0.001557, loss_freq: 0.036193
[03:23:22.753] iteration 5238: loss: 0.151542, loss_s1: 0.063113, loss_fp: 0.005216, loss_freq: 0.042798
[03:23:23.343] iteration 5239: loss: 0.221932, loss_s1: 0.256893, loss_fp: 0.002174, loss_freq: 0.088268
[03:23:23.935] iteration 5240: loss: 0.128490, loss_s1: 0.130760, loss_fp: 0.002379, loss_freq: 0.023235
[03:23:24.530] iteration 5241: loss: 0.133524, loss_s1: 0.126706, loss_fp: 0.004165, loss_freq: 0.024975
[03:23:25.122] iteration 5242: loss: 0.126445, loss_s1: 0.068796, loss_fp: 0.000950, loss_freq: 0.061780
[03:23:25.717] iteration 5243: loss: 0.150348, loss_s1: 0.117800, loss_fp: 0.000901, loss_freq: 0.074151
[03:23:26.312] iteration 5244: loss: 0.112256, loss_s1: 0.032068, loss_fp: 0.002930, loss_freq: 0.018307
[03:23:26.911] iteration 5245: loss: 0.112530, loss_s1: 0.080503, loss_fp: 0.000686, loss_freq: 0.024791
[03:23:27.507] iteration 5246: loss: 0.109419, loss_s1: 0.040209, loss_fp: 0.003023, loss_freq: 0.054383
[03:23:28.103] iteration 5247: loss: 0.158425, loss_s1: 0.095310, loss_fp: 0.002235, loss_freq: 0.027340
[03:23:28.691] iteration 5248: loss: 0.179799, loss_s1: 0.172109, loss_fp: 0.001332, loss_freq: 0.069564
[03:23:29.274] iteration 5249: loss: 0.160228, loss_s1: 0.104784, loss_fp: 0.003394, loss_freq: 0.044340
[03:23:29.861] iteration 5250: loss: 0.108105, loss_s1: 0.040779, loss_fp: 0.000395, loss_freq: 0.026946
[03:23:30.454] iteration 5251: loss: 0.122311, loss_s1: 0.101297, loss_fp: 0.001021, loss_freq: 0.016411
[03:23:31.044] iteration 5252: loss: 0.186204, loss_s1: 0.107292, loss_fp: 0.002499, loss_freq: 0.037413
[03:23:31.627] iteration 5253: loss: 0.097478, loss_s1: 0.039523, loss_fp: 0.000802, loss_freq: 0.031202
[03:23:32.217] iteration 5254: loss: 0.108238, loss_s1: 0.060024, loss_fp: 0.001335, loss_freq: 0.026313
[03:23:32.808] iteration 5255: loss: 0.155425, loss_s1: 0.082482, loss_fp: 0.003017, loss_freq: 0.040756
[03:23:33.409] iteration 5256: loss: 0.087817, loss_s1: 0.032414, loss_fp: 0.001423, loss_freq: 0.037892
[03:23:34.000] iteration 5257: loss: 0.109515, loss_s1: 0.070960, loss_fp: 0.001662, loss_freq: 0.037052
[03:23:34.589] iteration 5258: loss: 0.145338, loss_s1: 0.098017, loss_fp: 0.006942, loss_freq: 0.057340
[03:23:35.183] iteration 5259: loss: 0.089030, loss_s1: 0.057480, loss_fp: 0.004352, loss_freq: 0.040279
[03:23:35.773] iteration 5260: loss: 0.154291, loss_s1: 0.089266, loss_fp: 0.001872, loss_freq: 0.022218
[03:23:36.365] iteration 5261: loss: 0.077173, loss_s1: 0.053779, loss_fp: 0.002204, loss_freq: 0.012379
[03:23:36.957] iteration 5262: loss: 0.095650, loss_s1: 0.033002, loss_fp: 0.001421, loss_freq: 0.015643
[03:23:37.546] iteration 5263: loss: 0.142906, loss_s1: 0.067841, loss_fp: 0.005930, loss_freq: 0.012275
[03:23:38.142] iteration 5264: loss: 0.078498, loss_s1: 0.060384, loss_fp: 0.001636, loss_freq: 0.011201
[03:23:38.733] iteration 5265: loss: 0.095346, loss_s1: 0.053925, loss_fp: 0.003219, loss_freq: 0.030736
[03:23:39.334] iteration 5266: loss: 0.188090, loss_s1: 0.203807, loss_fp: 0.002606, loss_freq: 0.055622
[03:23:39.926] iteration 5267: loss: 0.111062, loss_s1: 0.061206, loss_fp: 0.002494, loss_freq: 0.030492
[03:23:40.548] iteration 5268: loss: 0.152589, loss_s1: 0.125975, loss_fp: 0.001930, loss_freq: 0.027849
[03:23:41.173] iteration 5269: loss: 0.206281, loss_s1: 0.093917, loss_fp: 0.002958, loss_freq: 0.079703
[03:23:41.800] iteration 5270: loss: 0.184563, loss_s1: 0.167862, loss_fp: 0.000736, loss_freq: 0.105837
[03:23:42.803] iteration 5271: loss: 0.154100, loss_s1: 0.086990, loss_fp: 0.002014, loss_freq: 0.032237
[03:23:43.437] iteration 5272: loss: 0.123931, loss_s1: 0.128179, loss_fp: 0.000597, loss_freq: 0.021881
[03:23:44.039] iteration 5273: loss: 0.133294, loss_s1: 0.138114, loss_fp: 0.003624, loss_freq: 0.048508
[03:23:44.667] iteration 5274: loss: 0.132759, loss_s1: 0.041088, loss_fp: 0.001419, loss_freq: 0.026113
[03:23:45.266] iteration 5275: loss: 0.096376, loss_s1: 0.056223, loss_fp: 0.001188, loss_freq: 0.031396
[03:23:45.868] iteration 5276: loss: 0.119545, loss_s1: 0.061742, loss_fp: 0.002438, loss_freq: 0.040776
[03:23:46.466] iteration 5277: loss: 0.107291, loss_s1: 0.102806, loss_fp: 0.001212, loss_freq: 0.043601
[03:23:47.062] iteration 5278: loss: 0.153434, loss_s1: 0.138359, loss_fp: 0.001192, loss_freq: 0.047669
[03:23:47.654] iteration 5279: loss: 0.138365, loss_s1: 0.077126, loss_fp: 0.001431, loss_freq: 0.031391
[03:23:48.263] iteration 5280: loss: 0.147659, loss_s1: 0.122075, loss_fp: 0.007550, loss_freq: 0.034824
[03:23:48.851] iteration 5281: loss: 0.156419, loss_s1: 0.042204, loss_fp: 0.001583, loss_freq: 0.087864
[03:23:49.441] iteration 5282: loss: 0.105649, loss_s1: 0.051345, loss_fp: 0.000442, loss_freq: 0.058084
[03:23:50.035] iteration 5283: loss: 0.153020, loss_s1: 0.053908, loss_fp: 0.003211, loss_freq: 0.083969
[03:23:50.624] iteration 5284: loss: 0.112422, loss_s1: 0.031722, loss_fp: 0.012033, loss_freq: 0.022506
[03:23:51.239] iteration 5285: loss: 0.141779, loss_s1: 0.147463, loss_fp: 0.001112, loss_freq: 0.026099
[03:23:51.832] iteration 5286: loss: 0.080595, loss_s1: 0.039430, loss_fp: 0.010705, loss_freq: 0.027728
[03:23:52.423] iteration 5287: loss: 0.162251, loss_s1: 0.099261, loss_fp: 0.001537, loss_freq: 0.052285
[03:23:53.016] iteration 5288: loss: 0.119245, loss_s1: 0.040098, loss_fp: 0.000878, loss_freq: 0.009133
[03:23:53.608] iteration 5289: loss: 0.102284, loss_s1: 0.093622, loss_fp: 0.000843, loss_freq: 0.029413
[03:23:54.203] iteration 5290: loss: 0.114115, loss_s1: 0.078734, loss_fp: 0.002949, loss_freq: 0.025953
[03:23:54.853] iteration 5291: loss: 0.083703, loss_s1: 0.035187, loss_fp: 0.001257, loss_freq: 0.046187
[03:23:55.580] iteration 5292: loss: 0.093521, loss_s1: 0.027217, loss_fp: 0.001459, loss_freq: 0.013836
[03:23:56.323] iteration 5293: loss: 0.116851, loss_s1: 0.062206, loss_fp: 0.008554, loss_freq: 0.020397
[03:23:57.014] iteration 5294: loss: 0.082105, loss_s1: 0.039880, loss_fp: 0.002120, loss_freq: 0.017357
[03:23:57.609] iteration 5295: loss: 0.134008, loss_s1: 0.153984, loss_fp: 0.000705, loss_freq: 0.015717
[03:23:58.203] iteration 5296: loss: 0.129243, loss_s1: 0.101430, loss_fp: 0.002182, loss_freq: 0.047879
[03:23:58.799] iteration 5297: loss: 0.112473, loss_s1: 0.084281, loss_fp: 0.002690, loss_freq: 0.018973
[03:23:59.387] iteration 5298: loss: 0.219596, loss_s1: 0.216302, loss_fp: 0.012148, loss_freq: 0.065905
[03:23:59.976] iteration 5299: loss: 0.186612, loss_s1: 0.097213, loss_fp: 0.008924, loss_freq: 0.029876
[03:24:00.572] iteration 5300: loss: 0.110312, loss_s1: 0.080185, loss_fp: 0.003726, loss_freq: 0.013545
[03:24:01.161] iteration 5301: loss: 0.128161, loss_s1: 0.099196, loss_fp: 0.003135, loss_freq: 0.037867
[03:24:01.750] iteration 5302: loss: 0.159952, loss_s1: 0.081898, loss_fp: 0.001939, loss_freq: 0.056412
[03:24:02.338] iteration 5303: loss: 0.159329, loss_s1: 0.131604, loss_fp: 0.001298, loss_freq: 0.047622
[03:24:02.925] iteration 5304: loss: 0.088077, loss_s1: 0.066295, loss_fp: 0.001925, loss_freq: 0.009938
[03:24:03.517] iteration 5305: loss: 0.089854, loss_s1: 0.061880, loss_fp: 0.003103, loss_freq: 0.028284
[03:24:04.149] iteration 5306: loss: 0.092323, loss_s1: 0.041204, loss_fp: 0.003255, loss_freq: 0.011766
[03:24:04.747] iteration 5307: loss: 0.091275, loss_s1: 0.041604, loss_fp: 0.010769, loss_freq: 0.022419
[03:24:05.343] iteration 5308: loss: 0.105655, loss_s1: 0.101878, loss_fp: 0.004969, loss_freq: 0.019609
[03:24:05.931] iteration 5309: loss: 0.170490, loss_s1: 0.117941, loss_fp: 0.001504, loss_freq: 0.083723
[03:24:06.523] iteration 5310: loss: 0.153314, loss_s1: 0.115945, loss_fp: 0.001799, loss_freq: 0.060938
[03:24:07.117] iteration 5311: loss: 0.162953, loss_s1: 0.105956, loss_fp: 0.001782, loss_freq: 0.059407
[03:24:07.702] iteration 5312: loss: 0.118387, loss_s1: 0.070507, loss_fp: 0.007975, loss_freq: 0.064947
[03:24:08.289] iteration 5313: loss: 0.132064, loss_s1: 0.119987, loss_fp: 0.003316, loss_freq: 0.049184
[03:24:08.880] iteration 5314: loss: 0.164010, loss_s1: 0.107380, loss_fp: 0.006443, loss_freq: 0.130076
[03:24:09.478] iteration 5315: loss: 0.122868, loss_s1: 0.077684, loss_fp: 0.003101, loss_freq: 0.030407
[03:24:10.064] iteration 5316: loss: 0.109230, loss_s1: 0.044966, loss_fp: 0.002402, loss_freq: 0.034962
[03:24:10.663] iteration 5317: loss: 0.123724, loss_s1: 0.100159, loss_fp: 0.003902, loss_freq: 0.013911
[03:24:11.254] iteration 5318: loss: 0.129819, loss_s1: 0.101565, loss_fp: 0.001661, loss_freq: 0.041687
[03:24:11.880] iteration 5319: loss: 0.131648, loss_s1: 0.075898, loss_fp: 0.001048, loss_freq: 0.020245
[03:24:12.513] iteration 5320: loss: 0.110040, loss_s1: 0.075669, loss_fp: 0.001915, loss_freq: 0.011542
[03:24:13.148] iteration 5321: loss: 0.121154, loss_s1: 0.087209, loss_fp: 0.002148, loss_freq: 0.054920
[03:24:13.749] iteration 5322: loss: 0.129693, loss_s1: 0.116567, loss_fp: 0.002972, loss_freq: 0.040902
[03:24:14.350] iteration 5323: loss: 0.153343, loss_s1: 0.097364, loss_fp: 0.003686, loss_freq: 0.064795
[03:24:14.944] iteration 5324: loss: 0.159418, loss_s1: 0.145868, loss_fp: 0.002238, loss_freq: 0.101667
[03:24:15.536] iteration 5325: loss: 0.147883, loss_s1: 0.097484, loss_fp: 0.003168, loss_freq: 0.053391
[03:24:16.133] iteration 5326: loss: 0.113993, loss_s1: 0.092605, loss_fp: 0.001071, loss_freq: 0.046132
[03:24:16.730] iteration 5327: loss: 0.096252, loss_s1: 0.062719, loss_fp: 0.000492, loss_freq: 0.030842
[03:24:17.365] iteration 5328: loss: 0.153745, loss_s1: 0.113537, loss_fp: 0.004621, loss_freq: 0.023433
[03:24:17.999] iteration 5329: loss: 0.135415, loss_s1: 0.082483, loss_fp: 0.006277, loss_freq: 0.034871
[03:24:18.635] iteration 5330: loss: 0.128403, loss_s1: 0.099999, loss_fp: 0.007732, loss_freq: 0.045473
[03:24:19.272] iteration 5331: loss: 0.088746, loss_s1: 0.055502, loss_fp: 0.002874, loss_freq: 0.037544
[03:24:19.903] iteration 5332: loss: 0.160400, loss_s1: 0.054394, loss_fp: 0.008755, loss_freq: 0.065695
[03:24:20.529] iteration 5333: loss: 0.118669, loss_s1: 0.105647, loss_fp: 0.001988, loss_freq: 0.010938
[03:24:21.129] iteration 5334: loss: 0.121395, loss_s1: 0.067310, loss_fp: 0.018328, loss_freq: 0.026649
[03:24:21.723] iteration 5335: loss: 0.127230, loss_s1: 0.139247, loss_fp: 0.000603, loss_freq: 0.014003
[03:24:22.315] iteration 5336: loss: 0.143069, loss_s1: 0.140809, loss_fp: 0.001602, loss_freq: 0.015699
[03:24:22.905] iteration 5337: loss: 0.101797, loss_s1: 0.050323, loss_fp: 0.001021, loss_freq: 0.010752
[03:24:23.498] iteration 5338: loss: 0.122490, loss_s1: 0.116444, loss_fp: 0.002097, loss_freq: 0.039106
[03:24:24.093] iteration 5339: loss: 0.105320, loss_s1: 0.019076, loss_fp: 0.002052, loss_freq: 0.016091
[03:24:24.678] iteration 5340: loss: 0.108008, loss_s1: 0.078181, loss_fp: 0.001419, loss_freq: 0.028958
[03:24:25.259] iteration 5341: loss: 0.119148, loss_s1: 0.038973, loss_fp: 0.002881, loss_freq: 0.047417
[03:24:25.851] iteration 5342: loss: 0.099245, loss_s1: 0.044244, loss_fp: 0.001096, loss_freq: 0.019743
[03:24:26.442] iteration 5343: loss: 0.151302, loss_s1: 0.112902, loss_fp: 0.005387, loss_freq: 0.037647
[03:24:27.029] iteration 5344: loss: 0.181206, loss_s1: 0.140197, loss_fp: 0.002269, loss_freq: 0.105314
[03:24:27.611] iteration 5345: loss: 0.183323, loss_s1: 0.114617, loss_fp: 0.001586, loss_freq: 0.081928
[03:24:28.198] iteration 5346: loss: 0.119268, loss_s1: 0.046004, loss_fp: 0.001099, loss_freq: 0.031207
[03:24:28.786] iteration 5347: loss: 0.094278, loss_s1: 0.041192, loss_fp: 0.005180, loss_freq: 0.042319
[03:24:29.377] iteration 5348: loss: 0.181587, loss_s1: 0.159855, loss_fp: 0.003015, loss_freq: 0.053241
[03:24:29.966] iteration 5349: loss: 0.095248, loss_s1: 0.047029, loss_fp: 0.001937, loss_freq: 0.028022
[03:24:30.555] iteration 5350: loss: 0.107036, loss_s1: 0.044201, loss_fp: 0.000493, loss_freq: 0.026461
[03:24:31.141] iteration 5351: loss: 0.116812, loss_s1: 0.085319, loss_fp: 0.003798, loss_freq: 0.034034
[03:24:31.732] iteration 5352: loss: 0.101202, loss_s1: 0.052982, loss_fp: 0.001326, loss_freq: 0.030895
[03:24:32.323] iteration 5353: loss: 0.156246, loss_s1: 0.139582, loss_fp: 0.003052, loss_freq: 0.053250
[03:24:32.910] iteration 5354: loss: 0.132746, loss_s1: 0.097305, loss_fp: 0.001769, loss_freq: 0.062052
[03:24:33.503] iteration 5355: loss: 0.164361, loss_s1: 0.052321, loss_fp: 0.010768, loss_freq: 0.035652
[03:24:34.096] iteration 5356: loss: 0.112248, loss_s1: 0.097828, loss_fp: 0.007597, loss_freq: 0.037479
[03:24:34.691] iteration 5357: loss: 0.118162, loss_s1: 0.098435, loss_fp: 0.001303, loss_freq: 0.054064
[03:24:35.283] iteration 5358: loss: 0.141898, loss_s1: 0.087645, loss_fp: 0.000896, loss_freq: 0.039934
[03:24:35.880] iteration 5359: loss: 0.148444, loss_s1: 0.062834, loss_fp: 0.005521, loss_freq: 0.111866
[03:24:36.475] iteration 5360: loss: 0.134600, loss_s1: 0.069581, loss_fp: 0.006777, loss_freq: 0.069942
[03:24:37.069] iteration 5361: loss: 0.097679, loss_s1: 0.051436, loss_fp: 0.012164, loss_freq: 0.037891
[03:24:37.664] iteration 5362: loss: 0.100696, loss_s1: 0.077892, loss_fp: 0.000873, loss_freq: 0.023024
[03:24:38.268] iteration 5363: loss: 0.149782, loss_s1: 0.142662, loss_fp: 0.001392, loss_freq: 0.038473
[03:24:38.859] iteration 5364: loss: 0.086521, loss_s1: 0.058508, loss_fp: 0.002176, loss_freq: 0.010142
[03:24:39.453] iteration 5365: loss: 0.115496, loss_s1: 0.131289, loss_fp: 0.002196, loss_freq: 0.016959
[03:24:40.069] iteration 5366: loss: 0.105643, loss_s1: 0.066930, loss_fp: 0.002625, loss_freq: 0.012267
[03:24:40.659] iteration 5367: loss: 0.165253, loss_s1: 0.084234, loss_fp: 0.013611, loss_freq: 0.039457
[03:24:41.253] iteration 5368: loss: 0.135139, loss_s1: 0.124125, loss_fp: 0.002292, loss_freq: 0.026593
[03:24:41.846] iteration 5369: loss: 0.148508, loss_s1: 0.088503, loss_fp: 0.007706, loss_freq: 0.066387
[03:24:42.445] iteration 5370: loss: 0.088586, loss_s1: 0.053946, loss_fp: 0.001995, loss_freq: 0.007641
[03:24:43.035] iteration 5371: loss: 0.139909, loss_s1: 0.040581, loss_fp: 0.001210, loss_freq: 0.028573
[03:24:43.623] iteration 5372: loss: 0.107762, loss_s1: 0.072413, loss_fp: 0.000404, loss_freq: 0.031039
[03:24:44.255] iteration 5373: loss: 0.082967, loss_s1: 0.045854, loss_fp: 0.000498, loss_freq: 0.042434
[03:24:44.883] iteration 5374: loss: 0.081101, loss_s1: 0.044324, loss_fp: 0.002595, loss_freq: 0.013266
[03:24:45.520] iteration 5375: loss: 0.097308, loss_s1: 0.059423, loss_fp: 0.007289, loss_freq: 0.041692
[03:24:46.112] iteration 5376: loss: 0.150586, loss_s1: 0.046796, loss_fp: 0.008268, loss_freq: 0.040955
[03:24:46.703] iteration 5377: loss: 0.099955, loss_s1: 0.042855, loss_fp: 0.005232, loss_freq: 0.038998
[03:24:47.286] iteration 5378: loss: 0.095481, loss_s1: 0.051453, loss_fp: 0.004921, loss_freq: 0.016227
[03:24:47.876] iteration 5379: loss: 0.190756, loss_s1: 0.107361, loss_fp: 0.002662, loss_freq: 0.151850
[03:24:48.463] iteration 5380: loss: 0.120401, loss_s1: 0.063604, loss_fp: 0.003731, loss_freq: 0.018692
[03:24:49.058] iteration 5381: loss: 0.105794, loss_s1: 0.049637, loss_fp: 0.003428, loss_freq: 0.031602
[03:24:49.657] iteration 5382: loss: 0.096100, loss_s1: 0.061330, loss_fp: 0.002037, loss_freq: 0.024914
[03:24:50.241] iteration 5383: loss: 0.080889, loss_s1: 0.047935, loss_fp: 0.000854, loss_freq: 0.035027
[03:24:50.830] iteration 5384: loss: 0.118255, loss_s1: 0.057303, loss_fp: 0.007382, loss_freq: 0.043540
[03:24:51.424] iteration 5385: loss: 0.152244, loss_s1: 0.075831, loss_fp: 0.013060, loss_freq: 0.091900
[03:24:52.016] iteration 5386: loss: 0.127339, loss_s1: 0.072400, loss_fp: 0.006579, loss_freq: 0.037790
[03:24:52.602] iteration 5387: loss: 0.156669, loss_s1: 0.127904, loss_fp: 0.006277, loss_freq: 0.057942
[03:24:53.202] iteration 5388: loss: 0.094181, loss_s1: 0.050460, loss_fp: 0.001392, loss_freq: 0.017415
[03:24:53.798] iteration 5389: loss: 0.177091, loss_s1: 0.149883, loss_fp: 0.004735, loss_freq: 0.051572
[03:24:54.388] iteration 5390: loss: 0.114322, loss_s1: 0.079306, loss_fp: 0.002878, loss_freq: 0.016820
[03:24:54.986] iteration 5391: loss: 0.074949, loss_s1: 0.040926, loss_fp: 0.000792, loss_freq: 0.012005
[03:24:55.590] iteration 5392: loss: 0.133264, loss_s1: 0.133944, loss_fp: 0.009434, loss_freq: 0.021248
[03:24:56.184] iteration 5393: loss: 0.119444, loss_s1: 0.062431, loss_fp: 0.000917, loss_freq: 0.057515
[03:24:56.781] iteration 5394: loss: 0.099781, loss_s1: 0.044573, loss_fp: 0.001387, loss_freq: 0.058299
[03:24:57.370] iteration 5395: loss: 0.140615, loss_s1: 0.105319, loss_fp: 0.027699, loss_freq: 0.035602
[03:24:57.972] iteration 5396: loss: 0.148514, loss_s1: 0.095306, loss_fp: 0.000941, loss_freq: 0.009559
[03:24:58.565] iteration 5397: loss: 0.178147, loss_s1: 0.093374, loss_fp: 0.033625, loss_freq: 0.149698
[03:24:59.154] iteration 5398: loss: 0.142028, loss_s1: 0.114926, loss_fp: 0.003704, loss_freq: 0.047098
[03:24:59.749] iteration 5399: loss: 0.150649, loss_s1: 0.094121, loss_fp: 0.003339, loss_freq: 0.009444
[03:25:00.407] iteration 5400: loss: 0.138041, loss_s1: 0.120997, loss_fp: 0.001907, loss_freq: 0.026484
[03:25:03.875] iteration 5400 : mean_dice : 0.587364
[03:25:04.542] iteration 5401: loss: 0.125185, loss_s1: 0.118738, loss_fp: 0.001178, loss_freq: 0.033280
[03:25:05.179] iteration 5402: loss: 0.169323, loss_s1: 0.082176, loss_fp: 0.003659, loss_freq: 0.024751
[03:25:05.777] iteration 5403: loss: 0.108133, loss_s1: 0.089006, loss_fp: 0.005262, loss_freq: 0.020417
[03:25:06.369] iteration 5404: loss: 0.142654, loss_s1: 0.139176, loss_fp: 0.005323, loss_freq: 0.042913
[03:25:06.957] iteration 5405: loss: 0.196238, loss_s1: 0.170271, loss_fp: 0.002764, loss_freq: 0.146099
[03:25:07.544] iteration 5406: loss: 0.116023, loss_s1: 0.073093, loss_fp: 0.001389, loss_freq: 0.048070
[03:25:08.135] iteration 5407: loss: 0.118971, loss_s1: 0.047386, loss_fp: 0.002928, loss_freq: 0.018270
[03:25:08.769] iteration 5408: loss: 0.078638, loss_s1: 0.045657, loss_fp: 0.003501, loss_freq: 0.015130
[03:25:09.399] iteration 5409: loss: 0.138402, loss_s1: 0.113995, loss_fp: 0.011285, loss_freq: 0.061490
[03:25:10.030] iteration 5410: loss: 0.121115, loss_s1: 0.108181, loss_fp: 0.009308, loss_freq: 0.026172
[03:25:10.665] iteration 5411: loss: 0.101639, loss_s1: 0.068080, loss_fp: 0.002532, loss_freq: 0.035715
[03:25:11.262] iteration 5412: loss: 0.128323, loss_s1: 0.052958, loss_fp: 0.000494, loss_freq: 0.067327
[03:25:11.858] iteration 5413: loss: 0.130771, loss_s1: 0.088244, loss_fp: 0.001946, loss_freq: 0.047083
[03:25:12.460] iteration 5414: loss: 0.104066, loss_s1: 0.087734, loss_fp: 0.003876, loss_freq: 0.019529
[03:25:13.050] iteration 5415: loss: 0.173104, loss_s1: 0.166555, loss_fp: 0.000528, loss_freq: 0.034975
[03:25:13.649] iteration 5416: loss: 0.156035, loss_s1: 0.105918, loss_fp: 0.002802, loss_freq: 0.055516
[03:25:14.309] iteration 5417: loss: 0.130310, loss_s1: 0.097648, loss_fp: 0.003209, loss_freq: 0.060267
[03:25:14.946] iteration 5418: loss: 0.125570, loss_s1: 0.096124, loss_fp: 0.002933, loss_freq: 0.056902
[03:25:15.636] iteration 5419: loss: 0.136377, loss_s1: 0.079668, loss_fp: 0.001974, loss_freq: 0.076034
[03:25:16.303] iteration 5420: loss: 0.122503, loss_s1: 0.066162, loss_fp: 0.002176, loss_freq: 0.036247
[03:25:16.925] iteration 5421: loss: 0.111188, loss_s1: 0.055499, loss_fp: 0.001846, loss_freq: 0.013423
[03:25:17.524] iteration 5422: loss: 0.106318, loss_s1: 0.081847, loss_fp: 0.006211, loss_freq: 0.037428
[03:25:18.117] iteration 5423: loss: 0.185471, loss_s1: 0.185128, loss_fp: 0.002805, loss_freq: 0.055831
[03:25:18.714] iteration 5424: loss: 0.077639, loss_s1: 0.025594, loss_fp: 0.002086, loss_freq: 0.016498
[03:25:19.302] iteration 5425: loss: 0.118511, loss_s1: 0.069260, loss_fp: 0.002114, loss_freq: 0.056671
[03:25:19.896] iteration 5426: loss: 0.093532, loss_s1: 0.082633, loss_fp: 0.001637, loss_freq: 0.030849
[03:25:20.487] iteration 5427: loss: 0.065625, loss_s1: 0.030441, loss_fp: 0.002811, loss_freq: 0.025019
[03:25:21.077] iteration 5428: loss: 0.136350, loss_s1: 0.133795, loss_fp: 0.003688, loss_freq: 0.038616
[03:25:21.671] iteration 5429: loss: 0.080778, loss_s1: 0.045040, loss_fp: 0.005448, loss_freq: 0.019386
[03:25:22.268] iteration 5430: loss: 0.094780, loss_s1: 0.047785, loss_fp: 0.001326, loss_freq: 0.030486
[03:25:22.860] iteration 5431: loss: 0.065512, loss_s1: 0.030628, loss_fp: 0.003122, loss_freq: 0.006417
[03:25:23.449] iteration 5432: loss: 0.074687, loss_s1: 0.024574, loss_fp: 0.005408, loss_freq: 0.014394
[03:25:24.038] iteration 5433: loss: 0.100280, loss_s1: 0.069367, loss_fp: 0.003789, loss_freq: 0.017864
[03:25:24.628] iteration 5434: loss: 0.092718, loss_s1: 0.036969, loss_fp: 0.001319, loss_freq: 0.020490
[03:25:25.219] iteration 5435: loss: 0.091964, loss_s1: 0.089389, loss_fp: 0.001469, loss_freq: 0.008228
[03:25:25.805] iteration 5436: loss: 0.111740, loss_s1: 0.071733, loss_fp: 0.002442, loss_freq: 0.037704
[03:25:26.390] iteration 5437: loss: 0.142058, loss_s1: 0.086812, loss_fp: 0.003847, loss_freq: 0.042085
[03:25:26.984] iteration 5438: loss: 0.118880, loss_s1: 0.107206, loss_fp: 0.001882, loss_freq: 0.024028
[03:25:27.568] iteration 5439: loss: 0.097522, loss_s1: 0.042788, loss_fp: 0.006246, loss_freq: 0.034113
[03:25:28.154] iteration 5440: loss: 0.137112, loss_s1: 0.094074, loss_fp: 0.008081, loss_freq: 0.097567
[03:25:29.063] iteration 5441: loss: 0.118732, loss_s1: 0.080064, loss_fp: 0.003018, loss_freq: 0.037814
[03:25:29.669] iteration 5442: loss: 0.122157, loss_s1: 0.129136, loss_fp: 0.001887, loss_freq: 0.017496
[03:25:30.259] iteration 5443: loss: 0.134219, loss_s1: 0.065637, loss_fp: 0.000981, loss_freq: 0.070781
[03:25:30.852] iteration 5444: loss: 0.079269, loss_s1: 0.052200, loss_fp: 0.005184, loss_freq: 0.011141
[03:25:31.447] iteration 5445: loss: 0.120455, loss_s1: 0.087037, loss_fp: 0.003578, loss_freq: 0.043898
[03:25:32.049] iteration 5446: loss: 0.122346, loss_s1: 0.059038, loss_fp: 0.001997, loss_freq: 0.040450
[03:25:32.647] iteration 5447: loss: 0.150602, loss_s1: 0.086712, loss_fp: 0.008549, loss_freq: 0.028222
[03:25:33.248] iteration 5448: loss: 0.101851, loss_s1: 0.060127, loss_fp: 0.006718, loss_freq: 0.026879
[03:25:33.839] iteration 5449: loss: 0.107706, loss_s1: 0.057679, loss_fp: 0.001080, loss_freq: 0.028770
[03:25:34.440] iteration 5450: loss: 0.127158, loss_s1: 0.065452, loss_fp: 0.000741, loss_freq: 0.047063
[03:25:35.079] iteration 5451: loss: 0.124142, loss_s1: 0.033068, loss_fp: 0.000646, loss_freq: 0.093678
[03:25:35.712] iteration 5452: loss: 0.099884, loss_s1: 0.044181, loss_fp: 0.001246, loss_freq: 0.071075
[03:25:36.485] iteration 5453: loss: 0.123558, loss_s1: 0.085470, loss_fp: 0.001974, loss_freq: 0.070300
[03:25:37.162] iteration 5454: loss: 0.082060, loss_s1: 0.055175, loss_fp: 0.000536, loss_freq: 0.018057
[03:25:37.916] iteration 5455: loss: 0.130022, loss_s1: 0.044308, loss_fp: 0.001296, loss_freq: 0.021823
[03:25:38.594] iteration 5456: loss: 0.106590, loss_s1: 0.111614, loss_fp: 0.002892, loss_freq: 0.012352
[03:25:39.304] iteration 5457: loss: 0.118357, loss_s1: 0.086731, loss_fp: 0.004798, loss_freq: 0.074798
[03:25:39.987] iteration 5458: loss: 0.115257, loss_s1: 0.049744, loss_fp: 0.001027, loss_freq: 0.014541
[03:25:40.648] iteration 5459: loss: 0.085783, loss_s1: 0.076032, loss_fp: 0.002540, loss_freq: 0.030488
[03:25:41.369] iteration 5460: loss: 0.109429, loss_s1: 0.052511, loss_fp: 0.002027, loss_freq: 0.034503
[03:25:42.011] iteration 5461: loss: 0.070150, loss_s1: 0.039080, loss_fp: 0.003580, loss_freq: 0.013096
[03:25:42.766] iteration 5462: loss: 0.175290, loss_s1: 0.110814, loss_fp: 0.001398, loss_freq: 0.051381
[03:25:43.430] iteration 5463: loss: 0.147258, loss_s1: 0.096906, loss_fp: 0.005460, loss_freq: 0.020871
[03:25:44.168] iteration 5464: loss: 0.105079, loss_s1: 0.040062, loss_fp: 0.003238, loss_freq: 0.037939
[03:25:44.854] iteration 5465: loss: 0.106469, loss_s1: 0.106122, loss_fp: 0.000716, loss_freq: 0.020382
[03:25:45.468] iteration 5466: loss: 0.126765, loss_s1: 0.094399, loss_fp: 0.000770, loss_freq: 0.045248
[03:25:46.065] iteration 5467: loss: 0.108115, loss_s1: 0.045625, loss_fp: 0.002112, loss_freq: 0.019856
[03:25:46.739] iteration 5468: loss: 0.230796, loss_s1: 0.278433, loss_fp: 0.001984, loss_freq: 0.049839
[03:25:47.550] iteration 5469: loss: 0.145733, loss_s1: 0.092208, loss_fp: 0.004641, loss_freq: 0.029626
[03:25:48.158] iteration 5470: loss: 0.078932, loss_s1: 0.042908, loss_fp: 0.004683, loss_freq: 0.034332
[03:25:48.742] iteration 5471: loss: 0.109723, loss_s1: 0.061386, loss_fp: 0.000747, loss_freq: 0.043112
[03:25:49.327] iteration 5472: loss: 0.130156, loss_s1: 0.057034, loss_fp: 0.003434, loss_freq: 0.022750
[03:25:49.921] iteration 5473: loss: 0.103116, loss_s1: 0.112772, loss_fp: 0.001129, loss_freq: 0.008901
[03:25:50.504] iteration 5474: loss: 0.104352, loss_s1: 0.030855, loss_fp: 0.004290, loss_freq: 0.018907
[03:25:51.091] iteration 5475: loss: 0.119320, loss_s1: 0.094218, loss_fp: 0.000989, loss_freq: 0.071518
[03:25:51.683] iteration 5476: loss: 0.091836, loss_s1: 0.052712, loss_fp: 0.001985, loss_freq: 0.015375
[03:25:52.276] iteration 5477: loss: 0.090403, loss_s1: 0.029302, loss_fp: 0.003277, loss_freq: 0.039870
[03:25:52.868] iteration 5478: loss: 0.065757, loss_s1: 0.043293, loss_fp: 0.001360, loss_freq: 0.017166
[03:25:53.457] iteration 5479: loss: 0.127018, loss_s1: 0.050939, loss_fp: 0.008981, loss_freq: 0.061215
[03:25:54.047] iteration 5480: loss: 0.116714, loss_s1: 0.075470, loss_fp: 0.004878, loss_freq: 0.055864
[03:25:54.642] iteration 5481: loss: 0.149807, loss_s1: 0.106663, loss_fp: 0.001019, loss_freq: 0.074901
[03:25:55.233] iteration 5482: loss: 0.176292, loss_s1: 0.136475, loss_fp: 0.006373, loss_freq: 0.074695
[03:25:55.833] iteration 5483: loss: 0.176232, loss_s1: 0.117754, loss_fp: 0.007048, loss_freq: 0.097814
[03:25:56.421] iteration 5484: loss: 0.146569, loss_s1: 0.125918, loss_fp: 0.001029, loss_freq: 0.097304
[03:25:57.013] iteration 5485: loss: 0.143530, loss_s1: 0.060447, loss_fp: 0.001109, loss_freq: 0.065505
[03:25:57.785] iteration 5486: loss: 0.142866, loss_s1: 0.105068, loss_fp: 0.001584, loss_freq: 0.041880
[03:25:58.612] iteration 5487: loss: 0.091559, loss_s1: 0.040689, loss_fp: 0.004987, loss_freq: 0.011566
[03:25:59.413] iteration 5488: loss: 0.100997, loss_s1: 0.065267, loss_fp: 0.000838, loss_freq: 0.036852
[03:26:00.280] iteration 5489: loss: 0.145897, loss_s1: 0.115073, loss_fp: 0.001687, loss_freq: 0.017933
[03:26:00.963] iteration 5490: loss: 0.117652, loss_s1: 0.083388, loss_fp: 0.001663, loss_freq: 0.034633
[03:26:01.641] iteration 5491: loss: 0.105400, loss_s1: 0.040656, loss_fp: 0.002948, loss_freq: 0.056578
[03:26:02.403] iteration 5492: loss: 0.087707, loss_s1: 0.049129, loss_fp: 0.001676, loss_freq: 0.030156
[03:26:03.020] iteration 5493: loss: 0.132327, loss_s1: 0.092809, loss_fp: 0.002141, loss_freq: 0.055908
[03:26:03.616] iteration 5494: loss: 0.181792, loss_s1: 0.130022, loss_fp: 0.011528, loss_freq: 0.081410
[03:26:04.210] iteration 5495: loss: 0.110885, loss_s1: 0.048254, loss_fp: 0.002435, loss_freq: 0.063933
[03:26:04.802] iteration 5496: loss: 0.102559, loss_s1: 0.061105, loss_fp: 0.000514, loss_freq: 0.032096
[03:26:05.394] iteration 5497: loss: 0.114881, loss_s1: 0.077857, loss_fp: 0.002230, loss_freq: 0.028002
[03:26:05.986] iteration 5498: loss: 0.122163, loss_s1: 0.087411, loss_fp: 0.006483, loss_freq: 0.017105
[03:26:06.583] iteration 5499: loss: 0.190433, loss_s1: 0.103909, loss_fp: 0.000681, loss_freq: 0.061948
[03:26:07.218] iteration 5500: loss: 0.101611, loss_s1: 0.076333, loss_fp: 0.001938, loss_freq: 0.028525
[03:26:07.816] iteration 5501: loss: 0.084131, loss_s1: 0.048712, loss_fp: 0.010282, loss_freq: 0.028343
[03:26:08.405] iteration 5502: loss: 0.158005, loss_s1: 0.116996, loss_fp: 0.002954, loss_freq: 0.044981
[03:26:09.003] iteration 5503: loss: 0.096871, loss_s1: 0.072692, loss_fp: 0.001585, loss_freq: 0.020135
[03:26:09.595] iteration 5504: loss: 0.136779, loss_s1: 0.079683, loss_fp: 0.003466, loss_freq: 0.020439
[03:26:10.182] iteration 5505: loss: 0.083808, loss_s1: 0.043983, loss_fp: 0.001226, loss_freq: 0.011616
[03:26:10.770] iteration 5506: loss: 0.111827, loss_s1: 0.068897, loss_fp: 0.000855, loss_freq: 0.024437
[03:26:11.362] iteration 5507: loss: 0.125335, loss_s1: 0.062431, loss_fp: 0.003058, loss_freq: 0.014727
[03:26:11.954] iteration 5508: loss: 0.203740, loss_s1: 0.138135, loss_fp: 0.003381, loss_freq: 0.048543
[03:26:12.545] iteration 5509: loss: 0.122043, loss_s1: 0.070364, loss_fp: 0.000623, loss_freq: 0.009825
[03:26:13.183] iteration 5510: loss: 0.093973, loss_s1: 0.047473, loss_fp: 0.005001, loss_freq: 0.018880
[03:26:13.834] iteration 5511: loss: 0.162651, loss_s1: 0.145857, loss_fp: 0.001471, loss_freq: 0.050642
[03:26:14.483] iteration 5512: loss: 0.087002, loss_s1: 0.065010, loss_fp: 0.003086, loss_freq: 0.007476
[03:26:15.135] iteration 5513: loss: 0.112779, loss_s1: 0.106701, loss_fp: 0.000753, loss_freq: 0.015226
[03:26:15.759] iteration 5514: loss: 0.094619, loss_s1: 0.021268, loss_fp: 0.001223, loss_freq: 0.050904
[03:26:16.362] iteration 5515: loss: 0.148413, loss_s1: 0.065893, loss_fp: 0.002575, loss_freq: 0.065865
[03:26:16.966] iteration 5516: loss: 0.091277, loss_s1: 0.024300, loss_fp: 0.003874, loss_freq: 0.017467
[03:26:17.575] iteration 5517: loss: 0.102976, loss_s1: 0.074880, loss_fp: 0.000613, loss_freq: 0.016497
[03:26:18.161] iteration 5518: loss: 0.162633, loss_s1: 0.106327, loss_fp: 0.002031, loss_freq: 0.035740
[03:26:18.746] iteration 5519: loss: 0.075817, loss_s1: 0.044692, loss_fp: 0.002186, loss_freq: 0.023514
[03:26:19.333] iteration 5520: loss: 0.109195, loss_s1: 0.054178, loss_fp: 0.002530, loss_freq: 0.041108
[03:26:19.920] iteration 5521: loss: 0.145972, loss_s1: 0.077415, loss_fp: 0.001570, loss_freq: 0.079551
[03:26:20.512] iteration 5522: loss: 0.092674, loss_s1: 0.060064, loss_fp: 0.001995, loss_freq: 0.038990
[03:26:21.101] iteration 5523: loss: 0.200667, loss_s1: 0.136800, loss_fp: 0.003032, loss_freq: 0.068111
[03:26:21.682] iteration 5524: loss: 0.091638, loss_s1: 0.026631, loss_fp: 0.007095, loss_freq: 0.020448
[03:26:22.274] iteration 5525: loss: 0.145618, loss_s1: 0.100813, loss_fp: 0.001863, loss_freq: 0.035783
[03:26:22.901] iteration 5526: loss: 0.075833, loss_s1: 0.038221, loss_fp: 0.002549, loss_freq: 0.014079
[03:26:23.496] iteration 5527: loss: 0.079429, loss_s1: 0.057034, loss_fp: 0.002949, loss_freq: 0.031331
[03:26:24.089] iteration 5528: loss: 0.108978, loss_s1: 0.045582, loss_fp: 0.004797, loss_freq: 0.035396
[03:26:24.674] iteration 5529: loss: 0.122688, loss_s1: 0.102622, loss_fp: 0.001817, loss_freq: 0.079283
[03:26:25.271] iteration 5530: loss: 0.078703, loss_s1: 0.016312, loss_fp: 0.001256, loss_freq: 0.036658
[03:26:25.857] iteration 5531: loss: 0.128985, loss_s1: 0.107543, loss_fp: 0.000954, loss_freq: 0.050872
[03:26:26.458] iteration 5532: loss: 0.121938, loss_s1: 0.083437, loss_fp: 0.002098, loss_freq: 0.055121
[03:26:27.059] iteration 5533: loss: 0.134282, loss_s1: 0.078884, loss_fp: 0.004809, loss_freq: 0.044513
[03:26:27.652] iteration 5534: loss: 0.092048, loss_s1: 0.035584, loss_fp: 0.004845, loss_freq: 0.013067
[03:26:28.243] iteration 5535: loss: 0.120727, loss_s1: 0.083082, loss_fp: 0.003164, loss_freq: 0.032404
[03:26:28.834] iteration 5536: loss: 0.116617, loss_s1: 0.106024, loss_fp: 0.001108, loss_freq: 0.058913
[03:26:29.424] iteration 5537: loss: 0.202872, loss_s1: 0.149125, loss_fp: 0.002113, loss_freq: 0.091683
[03:26:30.012] iteration 5538: loss: 0.133369, loss_s1: 0.119542, loss_fp: 0.010578, loss_freq: 0.015086
[03:26:30.604] iteration 5539: loss: 0.119021, loss_s1: 0.062602, loss_fp: 0.008511, loss_freq: 0.056322
[03:26:31.201] iteration 5540: loss: 0.090092, loss_s1: 0.064549, loss_fp: 0.003297, loss_freq: 0.016250
[03:26:31.797] iteration 5541: loss: 0.111606, loss_s1: 0.021029, loss_fp: 0.001721, loss_freq: 0.078343
[03:26:32.389] iteration 5542: loss: 0.130688, loss_s1: 0.057324, loss_fp: 0.001103, loss_freq: 0.043165
[03:26:32.982] iteration 5543: loss: 0.082667, loss_s1: 0.037296, loss_fp: 0.001154, loss_freq: 0.026415
[03:26:33.578] iteration 5544: loss: 0.110659, loss_s1: 0.021702, loss_fp: 0.003155, loss_freq: 0.035541
[03:26:34.168] iteration 5545: loss: 0.093901, loss_s1: 0.063578, loss_fp: 0.001241, loss_freq: 0.027221
[03:26:34.758] iteration 5546: loss: 0.119625, loss_s1: 0.099748, loss_fp: 0.007230, loss_freq: 0.040197
[03:26:35.351] iteration 5547: loss: 0.118906, loss_s1: 0.066514, loss_fp: 0.015953, loss_freq: 0.045563
[03:26:35.978] iteration 5548: loss: 0.070775, loss_s1: 0.009916, loss_fp: 0.001897, loss_freq: 0.027872
[03:26:36.568] iteration 5549: loss: 0.220829, loss_s1: 0.199319, loss_fp: 0.008499, loss_freq: 0.060185
[03:26:37.166] iteration 5550: loss: 0.079239, loss_s1: 0.020439, loss_fp: 0.002752, loss_freq: 0.026919
[03:26:37.867] iteration 5551: loss: 0.168653, loss_s1: 0.071152, loss_fp: 0.001132, loss_freq: 0.065030
[03:26:38.499] iteration 5552: loss: 0.082953, loss_s1: 0.052116, loss_fp: 0.000841, loss_freq: 0.017888
[03:26:39.122] iteration 5553: loss: 0.078312, loss_s1: 0.031379, loss_fp: 0.001493, loss_freq: 0.028522
[03:26:39.724] iteration 5554: loss: 0.111807, loss_s1: 0.105457, loss_fp: 0.003061, loss_freq: 0.042329
[03:26:40.319] iteration 5555: loss: 0.182694, loss_s1: 0.079377, loss_fp: 0.016514, loss_freq: 0.066697
[03:26:40.905] iteration 5556: loss: 0.093234, loss_s1: 0.068806, loss_fp: 0.002368, loss_freq: 0.034912
[03:26:41.496] iteration 5557: loss: 0.097774, loss_s1: 0.038949, loss_fp: 0.001631, loss_freq: 0.046286
[03:26:42.108] iteration 5558: loss: 0.096866, loss_s1: 0.067668, loss_fp: 0.000790, loss_freq: 0.020617
[03:26:42.697] iteration 5559: loss: 0.108838, loss_s1: 0.058291, loss_fp: 0.014000, loss_freq: 0.067853
[03:26:43.325] iteration 5560: loss: 0.095209, loss_s1: 0.046198, loss_fp: 0.008618, loss_freq: 0.028422
[03:26:43.919] iteration 5561: loss: 0.073188, loss_s1: 0.050022, loss_fp: 0.000354, loss_freq: 0.015965
[03:26:44.647] iteration 5562: loss: 0.106160, loss_s1: 0.022558, loss_fp: 0.011232, loss_freq: 0.030059
[03:26:45.316] iteration 5563: loss: 0.142459, loss_s1: 0.140396, loss_fp: 0.002326, loss_freq: 0.026539
[03:26:46.044] iteration 5564: loss: 0.075756, loss_s1: 0.042878, loss_fp: 0.012283, loss_freq: 0.015315
[03:26:46.678] iteration 5565: loss: 0.102814, loss_s1: 0.063215, loss_fp: 0.002866, loss_freq: 0.038100
[03:26:47.344] iteration 5566: loss: 0.109877, loss_s1: 0.057035, loss_fp: 0.002695, loss_freq: 0.009832
[03:26:48.013] iteration 5567: loss: 0.184414, loss_s1: 0.145986, loss_fp: 0.001307, loss_freq: 0.099122
[03:26:48.738] iteration 5568: loss: 0.146967, loss_s1: 0.095498, loss_fp: 0.001772, loss_freq: 0.058167
[03:26:49.413] iteration 5569: loss: 0.084733, loss_s1: 0.045799, loss_fp: 0.000831, loss_freq: 0.010347
[03:26:50.089] iteration 5570: loss: 0.087080, loss_s1: 0.064224, loss_fp: 0.001848, loss_freq: 0.023607
[03:26:50.786] iteration 5571: loss: 0.140702, loss_s1: 0.186651, loss_fp: 0.001487, loss_freq: 0.017158
[03:26:51.435] iteration 5572: loss: 0.117324, loss_s1: 0.049890, loss_fp: 0.002349, loss_freq: 0.007222
[03:26:52.153] iteration 5573: loss: 0.137994, loss_s1: 0.115451, loss_fp: 0.000390, loss_freq: 0.046276
[03:26:52.777] iteration 5574: loss: 0.119206, loss_s1: 0.064507, loss_fp: 0.002793, loss_freq: 0.046686
[03:26:53.501] iteration 5575: loss: 0.121114, loss_s1: 0.117347, loss_fp: 0.007185, loss_freq: 0.021093
[03:26:54.133] iteration 5576: loss: 0.091845, loss_s1: 0.024310, loss_fp: 0.006737, loss_freq: 0.032449
[03:26:54.823] iteration 5577: loss: 0.129459, loss_s1: 0.066887, loss_fp: 0.002716, loss_freq: 0.013881
[03:26:55.504] iteration 5578: loss: 0.107516, loss_s1: 0.052407, loss_fp: 0.002307, loss_freq: 0.011400
[03:26:56.177] iteration 5579: loss: 0.131013, loss_s1: 0.096931, loss_fp: 0.001803, loss_freq: 0.033620
[03:26:56.820] iteration 5580: loss: 0.119167, loss_s1: 0.097292, loss_fp: 0.003189, loss_freq: 0.066418
[03:26:57.413] iteration 5581: loss: 0.106436, loss_s1: 0.083345, loss_fp: 0.004313, loss_freq: 0.030442
[03:26:58.005] iteration 5582: loss: 0.136773, loss_s1: 0.117179, loss_fp: 0.002414, loss_freq: 0.065350
[03:26:58.596] iteration 5583: loss: 0.123279, loss_s1: 0.086996, loss_fp: 0.005653, loss_freq: 0.060946
[03:26:59.195] iteration 5584: loss: 0.119151, loss_s1: 0.052227, loss_fp: 0.002069, loss_freq: 0.019922
[03:26:59.791] iteration 5585: loss: 0.082534, loss_s1: 0.036499, loss_fp: 0.002203, loss_freq: 0.042142
[03:27:00.384] iteration 5586: loss: 0.092135, loss_s1: 0.037159, loss_fp: 0.000954, loss_freq: 0.045792
[03:27:00.975] iteration 5587: loss: 0.110786, loss_s1: 0.091447, loss_fp: 0.002106, loss_freq: 0.034102
[03:27:01.594] iteration 5588: loss: 0.103870, loss_s1: 0.059230, loss_fp: 0.001629, loss_freq: 0.021189
[03:27:02.182] iteration 5589: loss: 0.157838, loss_s1: 0.194691, loss_fp: 0.001225, loss_freq: 0.048393
[03:27:02.765] iteration 5590: loss: 0.106054, loss_s1: 0.051569, loss_fp: 0.001004, loss_freq: 0.026859
[03:27:03.352] iteration 5591: loss: 0.093465, loss_s1: 0.055041, loss_fp: 0.001262, loss_freq: 0.012113
[03:27:03.946] iteration 5592: loss: 0.091512, loss_s1: 0.047966, loss_fp: 0.003444, loss_freq: 0.019923
[03:27:04.535] iteration 5593: loss: 0.125220, loss_s1: 0.093392, loss_fp: 0.002515, loss_freq: 0.020663
[03:27:05.128] iteration 5594: loss: 0.098751, loss_s1: 0.055932, loss_fp: 0.001357, loss_freq: 0.033649
[03:27:05.762] iteration 5595: loss: 0.218056, loss_s1: 0.107457, loss_fp: 0.001138, loss_freq: 0.050452
[03:27:06.354] iteration 5596: loss: 0.119569, loss_s1: 0.111263, loss_fp: 0.003459, loss_freq: 0.015440
[03:27:07.060] iteration 5597: loss: 0.152402, loss_s1: 0.129815, loss_fp: 0.004404, loss_freq: 0.065324
[03:27:07.782] iteration 5598: loss: 0.131801, loss_s1: 0.092844, loss_fp: 0.003151, loss_freq: 0.035345
[03:27:08.562] iteration 5599: loss: 0.089253, loss_s1: 0.061628, loss_fp: 0.001946, loss_freq: 0.053164
[03:27:09.282] iteration 5600: loss: 0.138647, loss_s1: 0.085722, loss_fp: 0.001089, loss_freq: 0.020910
[03:27:12.800] iteration 5600 : mean_dice : 0.577241
[03:27:13.487] iteration 5601: loss: 0.064227, loss_s1: 0.029618, loss_fp: 0.000364, loss_freq: 0.005482
[03:27:14.125] iteration 5602: loss: 0.113860, loss_s1: 0.068936, loss_fp: 0.002079, loss_freq: 0.010932
[03:27:14.781] iteration 5603: loss: 0.180813, loss_s1: 0.112844, loss_fp: 0.001524, loss_freq: 0.040860
[03:27:15.458] iteration 5604: loss: 0.103135, loss_s1: 0.066532, loss_fp: 0.001898, loss_freq: 0.022794
[03:27:16.118] iteration 5605: loss: 0.098567, loss_s1: 0.101245, loss_fp: 0.002467, loss_freq: 0.008443
[03:27:16.778] iteration 5606: loss: 0.179415, loss_s1: 0.157144, loss_fp: 0.002188, loss_freq: 0.078686
[03:27:17.390] iteration 5607: loss: 0.081575, loss_s1: 0.042972, loss_fp: 0.000771, loss_freq: 0.037897
[03:27:18.003] iteration 5608: loss: 0.093347, loss_s1: 0.063477, loss_fp: 0.001189, loss_freq: 0.010997
[03:27:18.612] iteration 5609: loss: 0.137818, loss_s1: 0.094878, loss_fp: 0.001626, loss_freq: 0.042190
[03:27:19.222] iteration 5610: loss: 0.164358, loss_s1: 0.142312, loss_fp: 0.004065, loss_freq: 0.113524
[03:27:20.210] iteration 5611: loss: 0.108597, loss_s1: 0.053454, loss_fp: 0.003742, loss_freq: 0.009909
[03:27:20.850] iteration 5612: loss: 0.101169, loss_s1: 0.062847, loss_fp: 0.006139, loss_freq: 0.026965
[03:27:21.459] iteration 5613: loss: 0.126311, loss_s1: 0.073564, loss_fp: 0.004239, loss_freq: 0.027149
[03:27:22.114] iteration 5614: loss: 0.102118, loss_s1: 0.055143, loss_fp: 0.001434, loss_freq: 0.036184
[03:27:22.728] iteration 5615: loss: 0.101426, loss_s1: 0.110629, loss_fp: 0.000994, loss_freq: 0.020955
[03:27:23.348] iteration 5616: loss: 0.116121, loss_s1: 0.022764, loss_fp: 0.002212, loss_freq: 0.018186
[03:27:23.972] iteration 5617: loss: 0.105424, loss_s1: 0.071970, loss_fp: 0.011185, loss_freq: 0.042833
[03:27:24.586] iteration 5618: loss: 0.112715, loss_s1: 0.101021, loss_fp: 0.007798, loss_freq: 0.044966
[03:27:25.206] iteration 5619: loss: 0.093158, loss_s1: 0.080517, loss_fp: 0.003360, loss_freq: 0.032788
[03:27:25.822] iteration 5620: loss: 0.138163, loss_s1: 0.079089, loss_fp: 0.008705, loss_freq: 0.064165
[03:27:26.509] iteration 5621: loss: 0.116962, loss_s1: 0.027034, loss_fp: 0.005408, loss_freq: 0.085560
[03:27:27.163] iteration 5622: loss: 0.113806, loss_s1: 0.047479, loss_fp: 0.014359, loss_freq: 0.060066
[03:27:27.816] iteration 5623: loss: 0.108049, loss_s1: 0.040703, loss_fp: 0.003883, loss_freq: 0.070500
[03:27:28.477] iteration 5624: loss: 0.076172, loss_s1: 0.041307, loss_fp: 0.001647, loss_freq: 0.011541
[03:27:29.136] iteration 5625: loss: 0.120893, loss_s1: 0.061592, loss_fp: 0.001265, loss_freq: 0.024777
[03:27:29.778] iteration 5626: loss: 0.079302, loss_s1: 0.051355, loss_fp: 0.001443, loss_freq: 0.044279
[03:27:30.401] iteration 5627: loss: 0.136628, loss_s1: 0.099441, loss_fp: 0.012016, loss_freq: 0.079797
[03:27:31.013] iteration 5628: loss: 0.123231, loss_s1: 0.068169, loss_fp: 0.001937, loss_freq: 0.021317
[03:27:31.618] iteration 5629: loss: 0.121811, loss_s1: 0.115850, loss_fp: 0.007083, loss_freq: 0.043620
[03:27:32.253] iteration 5630: loss: 0.109044, loss_s1: 0.086050, loss_fp: 0.004513, loss_freq: 0.026065
[03:27:32.881] iteration 5631: loss: 0.062252, loss_s1: 0.027530, loss_fp: 0.002037, loss_freq: 0.014856
[03:27:33.504] iteration 5632: loss: 0.164569, loss_s1: 0.153052, loss_fp: 0.005798, loss_freq: 0.038767
[03:27:34.138] iteration 5633: loss: 0.163548, loss_s1: 0.112827, loss_fp: 0.000780, loss_freq: 0.013523
[03:27:34.771] iteration 5634: loss: 0.107803, loss_s1: 0.075685, loss_fp: 0.001008, loss_freq: 0.058748
[03:27:35.393] iteration 5635: loss: 0.102546, loss_s1: 0.070033, loss_fp: 0.001039, loss_freq: 0.028524
[03:27:36.011] iteration 5636: loss: 0.088294, loss_s1: 0.061047, loss_fp: 0.001143, loss_freq: 0.029050
[03:27:36.621] iteration 5637: loss: 0.082704, loss_s1: 0.070399, loss_fp: 0.002375, loss_freq: 0.005006
[03:27:37.249] iteration 5638: loss: 0.182911, loss_s1: 0.173680, loss_fp: 0.003242, loss_freq: 0.066268
[03:27:37.879] iteration 5639: loss: 0.100190, loss_s1: 0.037544, loss_fp: 0.002639, loss_freq: 0.022194
[03:27:38.544] iteration 5640: loss: 0.098432, loss_s1: 0.110762, loss_fp: 0.000590, loss_freq: 0.015661
[03:27:39.194] iteration 5641: loss: 0.114415, loss_s1: 0.110632, loss_fp: 0.002455, loss_freq: 0.028547
[03:27:39.844] iteration 5642: loss: 0.153740, loss_s1: 0.076545, loss_fp: 0.000919, loss_freq: 0.035352
[03:27:40.495] iteration 5643: loss: 0.144787, loss_s1: 0.145059, loss_fp: 0.003667, loss_freq: 0.024984
[03:27:41.154] iteration 5644: loss: 0.111088, loss_s1: 0.074280, loss_fp: 0.003273, loss_freq: 0.020723
[03:27:41.768] iteration 5645: loss: 0.126290, loss_s1: 0.115731, loss_fp: 0.001134, loss_freq: 0.043166
[03:27:42.377] iteration 5646: loss: 0.100254, loss_s1: 0.054770, loss_fp: 0.003586, loss_freq: 0.026333
[03:27:42.988] iteration 5647: loss: 0.115029, loss_s1: 0.074019, loss_fp: 0.000840, loss_freq: 0.040979
[03:27:43.598] iteration 5648: loss: 0.134921, loss_s1: 0.079372, loss_fp: 0.001132, loss_freq: 0.014581
[03:27:44.215] iteration 5649: loss: 0.166533, loss_s1: 0.095786, loss_fp: 0.001354, loss_freq: 0.028748
[03:27:44.820] iteration 5650: loss: 0.112717, loss_s1: 0.097487, loss_fp: 0.002881, loss_freq: 0.039253
[03:27:45.434] iteration 5651: loss: 0.154081, loss_s1: 0.141172, loss_fp: 0.000505, loss_freq: 0.071478
[03:27:46.048] iteration 5652: loss: 0.130338, loss_s1: 0.096966, loss_fp: 0.005763, loss_freq: 0.042219
[03:27:46.661] iteration 5653: loss: 0.163741, loss_s1: 0.127870, loss_fp: 0.001377, loss_freq: 0.077992
[03:27:47.280] iteration 5654: loss: 0.119857, loss_s1: 0.113743, loss_fp: 0.002738, loss_freq: 0.056919
[03:27:47.893] iteration 5655: loss: 0.140353, loss_s1: 0.117408, loss_fp: 0.001588, loss_freq: 0.035065
[03:27:48.508] iteration 5656: loss: 0.143323, loss_s1: 0.050936, loss_fp: 0.002844, loss_freq: 0.058452
[03:27:49.125] iteration 5657: loss: 0.105777, loss_s1: 0.082568, loss_fp: 0.005266, loss_freq: 0.020952
[03:27:49.737] iteration 5658: loss: 0.112525, loss_s1: 0.121833, loss_fp: 0.000424, loss_freq: 0.017523
[03:27:50.353] iteration 5659: loss: 0.130905, loss_s1: 0.104529, loss_fp: 0.001966, loss_freq: 0.018926
[03:27:50.973] iteration 5660: loss: 0.096253, loss_s1: 0.040338, loss_fp: 0.001895, loss_freq: 0.041158
[03:27:51.589] iteration 5661: loss: 0.124764, loss_s1: 0.087027, loss_fp: 0.003875, loss_freq: 0.052500
[03:27:52.195] iteration 5662: loss: 0.091756, loss_s1: 0.045705, loss_fp: 0.001859, loss_freq: 0.038842
[03:27:52.803] iteration 5663: loss: 0.110620, loss_s1: 0.049224, loss_fp: 0.001384, loss_freq: 0.068899
[03:27:53.412] iteration 5664: loss: 0.225745, loss_s1: 0.141185, loss_fp: 0.001926, loss_freq: 0.225562
[03:27:54.022] iteration 5665: loss: 0.195729, loss_s1: 0.048955, loss_fp: 0.020342, loss_freq: 0.159764
[03:27:54.644] iteration 5666: loss: 0.100779, loss_s1: 0.078029, loss_fp: 0.001950, loss_freq: 0.015638
[03:27:55.269] iteration 5667: loss: 0.128950, loss_s1: 0.063494, loss_fp: 0.010370, loss_freq: 0.045465
[03:27:55.884] iteration 5668: loss: 0.117268, loss_s1: 0.066967, loss_fp: 0.000721, loss_freq: 0.054779
[03:27:56.495] iteration 5669: loss: 0.122111, loss_s1: 0.106911, loss_fp: 0.002900, loss_freq: 0.022855
[03:27:57.106] iteration 5670: loss: 0.112224, loss_s1: 0.077285, loss_fp: 0.001562, loss_freq: 0.047774
[03:27:57.718] iteration 5671: loss: 0.109012, loss_s1: 0.070169, loss_fp: 0.001304, loss_freq: 0.039583
[03:27:58.335] iteration 5672: loss: 0.137938, loss_s1: 0.116400, loss_fp: 0.010994, loss_freq: 0.026200
[03:27:58.946] iteration 5673: loss: 0.101397, loss_s1: 0.070565, loss_fp: 0.000592, loss_freq: 0.026475
[03:27:59.554] iteration 5674: loss: 0.075591, loss_s1: 0.036135, loss_fp: 0.001168, loss_freq: 0.020361
[03:28:00.164] iteration 5675: loss: 0.127100, loss_s1: 0.137089, loss_fp: 0.001987, loss_freq: 0.021877
[03:28:00.776] iteration 5676: loss: 0.117003, loss_s1: 0.063690, loss_fp: 0.001897, loss_freq: 0.045158
[03:28:01.385] iteration 5677: loss: 0.134221, loss_s1: 0.094810, loss_fp: 0.003684, loss_freq: 0.020116
[03:28:02.003] iteration 5678: loss: 0.146057, loss_s1: 0.135572, loss_fp: 0.007329, loss_freq: 0.051852
[03:28:02.613] iteration 5679: loss: 0.071055, loss_s1: 0.020091, loss_fp: 0.001047, loss_freq: 0.028921
[03:28:03.222] iteration 5680: loss: 0.088170, loss_s1: 0.041167, loss_fp: 0.005982, loss_freq: 0.022199
[03:28:03.832] iteration 5681: loss: 0.118111, loss_s1: 0.048413, loss_fp: 0.001263, loss_freq: 0.077353
[03:28:04.522] iteration 5682: loss: 0.079688, loss_s1: 0.043461, loss_fp: 0.003340, loss_freq: 0.015661
[03:28:05.157] iteration 5683: loss: 0.077141, loss_s1: 0.040790, loss_fp: 0.002508, loss_freq: 0.039545
[03:28:05.798] iteration 5684: loss: 0.161984, loss_s1: 0.180280, loss_fp: 0.005508, loss_freq: 0.040285
[03:28:06.426] iteration 5685: loss: 0.103023, loss_s1: 0.039492, loss_fp: 0.004665, loss_freq: 0.055523
[03:28:07.049] iteration 5686: loss: 0.106809, loss_s1: 0.077969, loss_fp: 0.002009, loss_freq: 0.029498
[03:28:07.667] iteration 5687: loss: 0.070485, loss_s1: 0.048289, loss_fp: 0.002359, loss_freq: 0.022576
[03:28:08.284] iteration 5688: loss: 0.129479, loss_s1: 0.084943, loss_fp: 0.005271, loss_freq: 0.063845
[03:28:08.903] iteration 5689: loss: 0.091946, loss_s1: 0.043969, loss_fp: 0.004862, loss_freq: 0.035744
[03:28:09.513] iteration 5690: loss: 0.087469, loss_s1: 0.052960, loss_fp: 0.000698, loss_freq: 0.020271
[03:28:10.128] iteration 5691: loss: 0.146435, loss_s1: 0.102536, loss_fp: 0.000620, loss_freq: 0.040015
[03:28:10.739] iteration 5692: loss: 0.103709, loss_s1: 0.114188, loss_fp: 0.002926, loss_freq: 0.017290
[03:28:11.345] iteration 5693: loss: 0.190243, loss_s1: 0.201139, loss_fp: 0.003946, loss_freq: 0.034697
[03:28:11.953] iteration 5694: loss: 0.108727, loss_s1: 0.063556, loss_fp: 0.002566, loss_freq: 0.013088
[03:28:12.634] iteration 5695: loss: 0.109725, loss_s1: 0.121306, loss_fp: 0.006025, loss_freq: 0.009386
[03:28:13.246] iteration 5696: loss: 0.085249, loss_s1: 0.055278, loss_fp: 0.002064, loss_freq: 0.044799
[03:28:13.852] iteration 5697: loss: 0.129491, loss_s1: 0.128250, loss_fp: 0.008993, loss_freq: 0.042046
[03:28:14.461] iteration 5698: loss: 0.120119, loss_s1: 0.064950, loss_fp: 0.005309, loss_freq: 0.058561
[03:28:15.067] iteration 5699: loss: 0.101290, loss_s1: 0.058497, loss_fp: 0.002363, loss_freq: 0.049659
[03:28:15.673] iteration 5700: loss: 0.133580, loss_s1: 0.066672, loss_fp: 0.001511, loss_freq: 0.040362
[03:28:16.286] iteration 5701: loss: 0.106748, loss_s1: 0.061565, loss_fp: 0.021573, loss_freq: 0.055209
[03:28:16.898] iteration 5702: loss: 0.088876, loss_s1: 0.059166, loss_fp: 0.003442, loss_freq: 0.041124
[03:28:17.510] iteration 5703: loss: 0.171819, loss_s1: 0.113275, loss_fp: 0.002454, loss_freq: 0.108226
[03:28:18.128] iteration 5704: loss: 0.125149, loss_s1: 0.065655, loss_fp: 0.000858, loss_freq: 0.037622
[03:28:18.741] iteration 5705: loss: 0.077526, loss_s1: 0.042441, loss_fp: 0.000735, loss_freq: 0.032207
[03:28:19.349] iteration 5706: loss: 0.094979, loss_s1: 0.073583, loss_fp: 0.001618, loss_freq: 0.037728
[03:28:19.960] iteration 5707: loss: 0.147430, loss_s1: 0.079833, loss_fp: 0.006449, loss_freq: 0.034014
[03:28:20.572] iteration 5708: loss: 0.120469, loss_s1: 0.084538, loss_fp: 0.013893, loss_freq: 0.040713
[03:28:21.187] iteration 5709: loss: 0.100561, loss_s1: 0.072301, loss_fp: 0.006788, loss_freq: 0.041511
[03:28:21.800] iteration 5710: loss: 0.073043, loss_s1: 0.043158, loss_fp: 0.003939, loss_freq: 0.028008
[03:28:22.417] iteration 5711: loss: 0.090361, loss_s1: 0.051174, loss_fp: 0.001484, loss_freq: 0.044835
[03:28:23.047] iteration 5712: loss: 0.115704, loss_s1: 0.091142, loss_fp: 0.001624, loss_freq: 0.049018
[03:28:23.675] iteration 5713: loss: 0.074889, loss_s1: 0.017241, loss_fp: 0.007143, loss_freq: 0.033866
[03:28:24.295] iteration 5714: loss: 0.104966, loss_s1: 0.040739, loss_fp: 0.001429, loss_freq: 0.021309
[03:28:24.911] iteration 5715: loss: 0.088605, loss_s1: 0.031338, loss_fp: 0.001131, loss_freq: 0.049094
[03:28:25.531] iteration 5716: loss: 0.110460, loss_s1: 0.072585, loss_fp: 0.001104, loss_freq: 0.039782
[03:28:26.144] iteration 5717: loss: 0.097938, loss_s1: 0.042125, loss_fp: 0.000897, loss_freq: 0.015340
[03:28:26.761] iteration 5718: loss: 0.087961, loss_s1: 0.051700, loss_fp: 0.002376, loss_freq: 0.034174
[03:28:27.368] iteration 5719: loss: 0.206661, loss_s1: 0.161131, loss_fp: 0.009832, loss_freq: 0.149029
[03:28:27.983] iteration 5720: loss: 0.117211, loss_s1: 0.047021, loss_fp: 0.002107, loss_freq: 0.050001
[03:28:28.597] iteration 5721: loss: 0.099960, loss_s1: 0.069454, loss_fp: 0.000900, loss_freq: 0.031416
[03:28:29.212] iteration 5722: loss: 0.125864, loss_s1: 0.147071, loss_fp: 0.001416, loss_freq: 0.023438
[03:28:29.829] iteration 5723: loss: 0.067350, loss_s1: 0.053471, loss_fp: 0.001103, loss_freq: 0.018312
[03:28:30.444] iteration 5724: loss: 0.102284, loss_s1: 0.033278, loss_fp: 0.004836, loss_freq: 0.027021
[03:28:31.062] iteration 5725: loss: 0.119130, loss_s1: 0.079537, loss_fp: 0.007898, loss_freq: 0.063731
[03:28:31.687] iteration 5726: loss: 0.111367, loss_s1: 0.090783, loss_fp: 0.003890, loss_freq: 0.036829
[03:28:32.301] iteration 5727: loss: 0.134289, loss_s1: 0.056843, loss_fp: 0.006777, loss_freq: 0.046202
[03:28:32.922] iteration 5728: loss: 0.086961, loss_s1: 0.035283, loss_fp: 0.000733, loss_freq: 0.044847
[03:28:33.545] iteration 5729: loss: 0.191668, loss_s1: 0.149326, loss_fp: 0.004470, loss_freq: 0.127204
[03:28:34.165] iteration 5730: loss: 0.182061, loss_s1: 0.097204, loss_fp: 0.000984, loss_freq: 0.032884
[03:28:34.790] iteration 5731: loss: 0.131036, loss_s1: 0.109059, loss_fp: 0.005848, loss_freq: 0.028217
[03:28:35.415] iteration 5732: loss: 0.095181, loss_s1: 0.080445, loss_fp: 0.003586, loss_freq: 0.034972
[03:28:36.038] iteration 5733: loss: 0.111008, loss_s1: 0.060944, loss_fp: 0.012947, loss_freq: 0.025496
[03:28:36.651] iteration 5734: loss: 0.075301, loss_s1: 0.045085, loss_fp: 0.006142, loss_freq: 0.025759
[03:28:37.266] iteration 5735: loss: 0.128375, loss_s1: 0.066565, loss_fp: 0.002659, loss_freq: 0.077231
[03:28:37.884] iteration 5736: loss: 0.104211, loss_s1: 0.088279, loss_fp: 0.000640, loss_freq: 0.006132
[03:28:38.500] iteration 5737: loss: 0.184430, loss_s1: 0.121906, loss_fp: 0.001807, loss_freq: 0.160932
[03:28:39.118] iteration 5738: loss: 0.130134, loss_s1: 0.074350, loss_fp: 0.002831, loss_freq: 0.082801
[03:28:39.778] iteration 5739: loss: 0.125933, loss_s1: 0.055861, loss_fp: 0.004693, loss_freq: 0.053381
[03:28:40.426] iteration 5740: loss: 0.197759, loss_s1: 0.222876, loss_fp: 0.002912, loss_freq: 0.092448
[03:28:41.039] iteration 5741: loss: 0.098732, loss_s1: 0.045998, loss_fp: 0.004139, loss_freq: 0.035051
[03:28:41.655] iteration 5742: loss: 0.112852, loss_s1: 0.030131, loss_fp: 0.000781, loss_freq: 0.028781
[03:28:42.312] iteration 5743: loss: 0.128501, loss_s1: 0.097450, loss_fp: 0.006002, loss_freq: 0.056821
[03:28:42.959] iteration 5744: loss: 0.096293, loss_s1: 0.070470, loss_fp: 0.005003, loss_freq: 0.045164
[03:28:43.621] iteration 5745: loss: 0.175175, loss_s1: 0.118996, loss_fp: 0.001944, loss_freq: 0.107483
[03:28:44.279] iteration 5746: loss: 0.107727, loss_s1: 0.068878, loss_fp: 0.001252, loss_freq: 0.034614
[03:28:44.888] iteration 5747: loss: 0.226203, loss_s1: 0.108610, loss_fp: 0.001997, loss_freq: 0.035194
[03:28:45.499] iteration 5748: loss: 0.137493, loss_s1: 0.167021, loss_fp: 0.003575, loss_freq: 0.031465
[03:28:46.110] iteration 5749: loss: 0.196924, loss_s1: 0.140432, loss_fp: 0.019510, loss_freq: 0.122448
[03:28:46.718] iteration 5750: loss: 0.123617, loss_s1: 0.140780, loss_fp: 0.003116, loss_freq: 0.032676
[03:28:47.325] iteration 5751: loss: 0.167524, loss_s1: 0.165646, loss_fp: 0.005323, loss_freq: 0.045543
[03:28:47.934] iteration 5752: loss: 0.091197, loss_s1: 0.051521, loss_fp: 0.002102, loss_freq: 0.014978
[03:28:48.542] iteration 5753: loss: 0.099488, loss_s1: 0.091193, loss_fp: 0.000577, loss_freq: 0.012614
[03:28:49.150] iteration 5754: loss: 0.117589, loss_s1: 0.095871, loss_fp: 0.002836, loss_freq: 0.011718
[03:28:49.764] iteration 5755: loss: 0.096067, loss_s1: 0.059960, loss_fp: 0.001774, loss_freq: 0.024887
[03:28:50.382] iteration 5756: loss: 0.122575, loss_s1: 0.089830, loss_fp: 0.002687, loss_freq: 0.051604
[03:28:51.000] iteration 5757: loss: 0.128469, loss_s1: 0.119612, loss_fp: 0.003132, loss_freq: 0.046735
[03:28:51.626] iteration 5758: loss: 0.110871, loss_s1: 0.073631, loss_fp: 0.002969, loss_freq: 0.046140
[03:28:52.247] iteration 5759: loss: 0.101741, loss_s1: 0.026358, loss_fp: 0.003477, loss_freq: 0.039470
[03:28:52.864] iteration 5760: loss: 0.105741, loss_s1: 0.062713, loss_fp: 0.001786, loss_freq: 0.026230
[03:28:53.481] iteration 5761: loss: 0.107842, loss_s1: 0.081281, loss_fp: 0.006907, loss_freq: 0.022955
[03:28:54.097] iteration 5762: loss: 0.105495, loss_s1: 0.066448, loss_fp: 0.004063, loss_freq: 0.043449
[03:28:54.712] iteration 5763: loss: 0.181250, loss_s1: 0.153847, loss_fp: 0.003575, loss_freq: 0.111293
[03:28:55.321] iteration 5764: loss: 0.100175, loss_s1: 0.036254, loss_fp: 0.014889, loss_freq: 0.023669
[03:28:55.931] iteration 5765: loss: 0.148052, loss_s1: 0.086581, loss_fp: 0.002529, loss_freq: 0.044784
[03:28:56.541] iteration 5766: loss: 0.120140, loss_s1: 0.061964, loss_fp: 0.002269, loss_freq: 0.040106
[03:28:57.153] iteration 5767: loss: 0.084065, loss_s1: 0.023914, loss_fp: 0.002919, loss_freq: 0.028076
[03:28:57.764] iteration 5768: loss: 0.110227, loss_s1: 0.083640, loss_fp: 0.001297, loss_freq: 0.037202
[03:28:58.375] iteration 5769: loss: 0.089728, loss_s1: 0.075556, loss_fp: 0.004940, loss_freq: 0.007878
[03:28:58.989] iteration 5770: loss: 0.089427, loss_s1: 0.055047, loss_fp: 0.003462, loss_freq: 0.017499
[03:28:59.596] iteration 5771: loss: 0.073063, loss_s1: 0.045751, loss_fp: 0.002922, loss_freq: 0.009523
[03:29:00.206] iteration 5772: loss: 0.113621, loss_s1: 0.111870, loss_fp: 0.000572, loss_freq: 0.026211
[03:29:00.813] iteration 5773: loss: 0.117692, loss_s1: 0.046046, loss_fp: 0.001275, loss_freq: 0.034318
[03:29:01.425] iteration 5774: loss: 0.071147, loss_s1: 0.049340, loss_fp: 0.001852, loss_freq: 0.015545
[03:29:02.038] iteration 5775: loss: 0.086178, loss_s1: 0.029696, loss_fp: 0.001019, loss_freq: 0.027077
[03:29:02.649] iteration 5776: loss: 0.150560, loss_s1: 0.129273, loss_fp: 0.002967, loss_freq: 0.062473
[03:29:03.262] iteration 5777: loss: 0.112193, loss_s1: 0.094995, loss_fp: 0.002904, loss_freq: 0.035721
[03:29:03.874] iteration 5778: loss: 0.186531, loss_s1: 0.261921, loss_fp: 0.001544, loss_freq: 0.013217
[03:29:04.481] iteration 5779: loss: 0.129955, loss_s1: 0.063725, loss_fp: 0.002168, loss_freq: 0.073113
[03:29:05.100] iteration 5780: loss: 0.138800, loss_s1: 0.102572, loss_fp: 0.002045, loss_freq: 0.081472
[03:29:06.046] iteration 5781: loss: 0.087936, loss_s1: 0.062926, loss_fp: 0.001005, loss_freq: 0.018529
[03:29:06.680] iteration 5782: loss: 0.096861, loss_s1: 0.079727, loss_fp: 0.000925, loss_freq: 0.021615
[03:29:07.285] iteration 5783: loss: 0.124914, loss_s1: 0.049802, loss_fp: 0.006634, loss_freq: 0.059750
[03:29:07.896] iteration 5784: loss: 0.087766, loss_s1: 0.060608, loss_fp: 0.001379, loss_freq: 0.032615
[03:29:08.512] iteration 5785: loss: 0.095895, loss_s1: 0.046574, loss_fp: 0.002322, loss_freq: 0.024146
[03:29:09.130] iteration 5786: loss: 0.137924, loss_s1: 0.071216, loss_fp: 0.010242, loss_freq: 0.025965
[03:29:09.744] iteration 5787: loss: 0.107426, loss_s1: 0.093602, loss_fp: 0.003462, loss_freq: 0.039904
[03:29:10.351] iteration 5788: loss: 0.102182, loss_s1: 0.058325, loss_fp: 0.003234, loss_freq: 0.030944
[03:29:10.958] iteration 5789: loss: 0.100332, loss_s1: 0.052484, loss_fp: 0.004445, loss_freq: 0.049995
[03:29:11.565] iteration 5790: loss: 0.146981, loss_s1: 0.137345, loss_fp: 0.001286, loss_freq: 0.070482
[03:29:12.178] iteration 5791: loss: 0.118071, loss_s1: 0.035678, loss_fp: 0.006166, loss_freq: 0.080400
[03:29:12.788] iteration 5792: loss: 0.144812, loss_s1: 0.067661, loss_fp: 0.001463, loss_freq: 0.105835
[03:29:13.407] iteration 5793: loss: 0.140841, loss_s1: 0.117604, loss_fp: 0.005722, loss_freq: 0.037215
[03:29:14.024] iteration 5794: loss: 0.085183, loss_s1: 0.049603, loss_fp: 0.001685, loss_freq: 0.045334
[03:29:14.681] iteration 5795: loss: 0.135661, loss_s1: 0.062854, loss_fp: 0.002613, loss_freq: 0.031141
[03:29:15.343] iteration 5796: loss: 0.100202, loss_s1: 0.047464, loss_fp: 0.005842, loss_freq: 0.053739
[03:29:15.996] iteration 5797: loss: 0.163661, loss_s1: 0.110156, loss_fp: 0.014754, loss_freq: 0.119040
[03:29:16.612] iteration 5798: loss: 0.095030, loss_s1: 0.059205, loss_fp: 0.002626, loss_freq: 0.017743
[03:29:17.228] iteration 5799: loss: 0.073936, loss_s1: 0.040572, loss_fp: 0.003459, loss_freq: 0.031437
[03:29:17.846] iteration 5800: loss: 0.099267, loss_s1: 0.085807, loss_fp: 0.001464, loss_freq: 0.023308
[03:29:21.063] iteration 5800 : mean_dice : 0.604830
[03:29:21.714] iteration 5801: loss: 0.090939, loss_s1: 0.039787, loss_fp: 0.002116, loss_freq: 0.026412
[03:29:22.368] iteration 5802: loss: 0.134042, loss_s1: 0.116427, loss_fp: 0.006176, loss_freq: 0.053450
[03:29:23.028] iteration 5803: loss: 0.163153, loss_s1: 0.103750, loss_fp: 0.006709, loss_freq: 0.035938
[03:29:23.694] iteration 5804: loss: 0.124432, loss_s1: 0.090750, loss_fp: 0.000674, loss_freq: 0.081709
[03:29:24.354] iteration 5805: loss: 0.086217, loss_s1: 0.068181, loss_fp: 0.001319, loss_freq: 0.023889
[03:29:25.008] iteration 5806: loss: 0.103693, loss_s1: 0.082179, loss_fp: 0.002509, loss_freq: 0.062070
[03:29:25.628] iteration 5807: loss: 0.120476, loss_s1: 0.064191, loss_fp: 0.000813, loss_freq: 0.020417
[03:29:26.243] iteration 5808: loss: 0.159744, loss_s1: 0.089410, loss_fp: 0.004480, loss_freq: 0.076624
[03:29:26.855] iteration 5809: loss: 0.137086, loss_s1: 0.099954, loss_fp: 0.003316, loss_freq: 0.038905
[03:29:27.467] iteration 5810: loss: 0.093595, loss_s1: 0.085260, loss_fp: 0.000403, loss_freq: 0.039490
[03:29:28.086] iteration 5811: loss: 0.081905, loss_s1: 0.047234, loss_fp: 0.000928, loss_freq: 0.038677
[03:29:28.703] iteration 5812: loss: 0.130245, loss_s1: 0.048330, loss_fp: 0.001305, loss_freq: 0.049094
[03:29:29.315] iteration 5813: loss: 0.111921, loss_s1: 0.058644, loss_fp: 0.001682, loss_freq: 0.049462
[03:29:29.953] iteration 5814: loss: 0.110869, loss_s1: 0.110240, loss_fp: 0.006850, loss_freq: 0.021609
[03:29:30.569] iteration 5815: loss: 0.107136, loss_s1: 0.081858, loss_fp: 0.016259, loss_freq: 0.045731
[03:29:31.182] iteration 5816: loss: 0.124286, loss_s1: 0.057447, loss_fp: 0.001278, loss_freq: 0.010664
[03:29:31.800] iteration 5817: loss: 0.083791, loss_s1: 0.051515, loss_fp: 0.001643, loss_freq: 0.019827
[03:29:32.414] iteration 5818: loss: 0.063014, loss_s1: 0.043761, loss_fp: 0.000842, loss_freq: 0.007436
[03:29:33.024] iteration 5819: loss: 0.097041, loss_s1: 0.066826, loss_fp: 0.009293, loss_freq: 0.026283
[03:29:33.641] iteration 5820: loss: 0.125617, loss_s1: 0.111822, loss_fp: 0.001745, loss_freq: 0.041953
[03:29:34.256] iteration 5821: loss: 0.160507, loss_s1: 0.164370, loss_fp: 0.002197, loss_freq: 0.057257
[03:29:34.867] iteration 5822: loss: 0.127639, loss_s1: 0.066652, loss_fp: 0.005301, loss_freq: 0.084140
[03:29:35.480] iteration 5823: loss: 0.121469, loss_s1: 0.110694, loss_fp: 0.000612, loss_freq: 0.065310
[03:29:36.089] iteration 5824: loss: 0.091198, loss_s1: 0.071228, loss_fp: 0.001376, loss_freq: 0.047364
[03:29:36.703] iteration 5825: loss: 0.088969, loss_s1: 0.037145, loss_fp: 0.001249, loss_freq: 0.026804
[03:29:37.313] iteration 5826: loss: 0.080330, loss_s1: 0.067608, loss_fp: 0.001008, loss_freq: 0.010702
[03:29:37.931] iteration 5827: loss: 0.082637, loss_s1: 0.078526, loss_fp: 0.001809, loss_freq: 0.016962
[03:29:38.547] iteration 5828: loss: 0.125716, loss_s1: 0.104522, loss_fp: 0.001027, loss_freq: 0.054887
[03:29:39.164] iteration 5829: loss: 0.100690, loss_s1: 0.074466, loss_fp: 0.003544, loss_freq: 0.023761
[03:29:39.778] iteration 5830: loss: 0.094759, loss_s1: 0.064930, loss_fp: 0.001107, loss_freq: 0.017357
[03:29:40.386] iteration 5831: loss: 0.115903, loss_s1: 0.067412, loss_fp: 0.008967, loss_freq: 0.079322
[03:29:40.997] iteration 5832: loss: 0.113902, loss_s1: 0.125791, loss_fp: 0.003022, loss_freq: 0.036706
[03:29:41.604] iteration 5833: loss: 0.123096, loss_s1: 0.060584, loss_fp: 0.002368, loss_freq: 0.041309
[03:29:42.211] iteration 5834: loss: 0.185957, loss_s1: 0.179853, loss_fp: 0.017214, loss_freq: 0.084972
[03:29:42.823] iteration 5835: loss: 0.147811, loss_s1: 0.078597, loss_fp: 0.000953, loss_freq: 0.083403
[03:29:43.434] iteration 5836: loss: 0.082872, loss_s1: 0.069627, loss_fp: 0.004086, loss_freq: 0.021243
[03:29:44.048] iteration 5837: loss: 0.080562, loss_s1: 0.036744, loss_fp: 0.001277, loss_freq: 0.032714
[03:29:44.661] iteration 5838: loss: 0.099892, loss_s1: 0.091582, loss_fp: 0.001086, loss_freq: 0.015977
[03:29:45.269] iteration 5839: loss: 0.115900, loss_s1: 0.047161, loss_fp: 0.007649, loss_freq: 0.032953
[03:29:45.881] iteration 5840: loss: 0.149990, loss_s1: 0.153889, loss_fp: 0.003619, loss_freq: 0.078174
[03:29:46.507] iteration 5841: loss: 0.112787, loss_s1: 0.074340, loss_fp: 0.001790, loss_freq: 0.043326
[03:29:47.126] iteration 5842: loss: 0.153899, loss_s1: 0.051869, loss_fp: 0.004650, loss_freq: 0.035934
[03:29:47.737] iteration 5843: loss: 0.081187, loss_s1: 0.039273, loss_fp: 0.002571, loss_freq: 0.015221
[03:29:48.355] iteration 5844: loss: 0.075093, loss_s1: 0.057890, loss_fp: 0.001468, loss_freq: 0.021328
[03:29:48.969] iteration 5845: loss: 0.131055, loss_s1: 0.159817, loss_fp: 0.002044, loss_freq: 0.025254
[03:29:49.590] iteration 5846: loss: 0.127958, loss_s1: 0.112757, loss_fp: 0.001663, loss_freq: 0.025602
[03:29:50.204] iteration 5847: loss: 0.107604, loss_s1: 0.072311, loss_fp: 0.003722, loss_freq: 0.013188
[03:29:50.817] iteration 5848: loss: 0.140322, loss_s1: 0.115697, loss_fp: 0.002030, loss_freq: 0.064039
[03:29:51.428] iteration 5849: loss: 0.079331, loss_s1: 0.047107, loss_fp: 0.001571, loss_freq: 0.016716
[03:29:52.045] iteration 5850: loss: 0.088333, loss_s1: 0.050510, loss_fp: 0.000904, loss_freq: 0.030357
[03:29:52.657] iteration 5851: loss: 0.132426, loss_s1: 0.094597, loss_fp: 0.002374, loss_freq: 0.056841
[03:29:53.270] iteration 5852: loss: 0.083254, loss_s1: 0.048395, loss_fp: 0.001293, loss_freq: 0.015772
[03:29:53.886] iteration 5853: loss: 0.100025, loss_s1: 0.063405, loss_fp: 0.007933, loss_freq: 0.035312
[03:29:54.497] iteration 5854: loss: 0.108645, loss_s1: 0.107787, loss_fp: 0.001268, loss_freq: 0.028187
[03:29:55.114] iteration 5855: loss: 0.182527, loss_s1: 0.118919, loss_fp: 0.005268, loss_freq: 0.054267
[03:29:55.727] iteration 5856: loss: 0.108383, loss_s1: 0.032025, loss_fp: 0.000877, loss_freq: 0.058383
[03:29:56.338] iteration 5857: loss: 0.089642, loss_s1: 0.066920, loss_fp: 0.001313, loss_freq: 0.017132
[03:29:56.950] iteration 5858: loss: 0.118839, loss_s1: 0.054483, loss_fp: 0.006635, loss_freq: 0.030848
[03:29:57.573] iteration 5859: loss: 0.095053, loss_s1: 0.061252, loss_fp: 0.001286, loss_freq: 0.053994
[03:29:58.241] iteration 5860: loss: 0.098009, loss_s1: 0.067318, loss_fp: 0.002549, loss_freq: 0.009319
[03:29:58.911] iteration 5861: loss: 0.139274, loss_s1: 0.079448, loss_fp: 0.005116, loss_freq: 0.077011
[03:29:59.584] iteration 5862: loss: 0.149065, loss_s1: 0.127227, loss_fp: 0.001412, loss_freq: 0.087883
[03:30:00.226] iteration 5863: loss: 0.168313, loss_s1: 0.154501, loss_fp: 0.002617, loss_freq: 0.039275
[03:30:00.840] iteration 5864: loss: 0.113919, loss_s1: 0.074801, loss_fp: 0.018622, loss_freq: 0.019040
[03:30:01.453] iteration 5865: loss: 0.135987, loss_s1: 0.106882, loss_fp: 0.002956, loss_freq: 0.027740
[03:30:02.063] iteration 5866: loss: 0.110120, loss_s1: 0.065700, loss_fp: 0.003242, loss_freq: 0.052761
[03:30:02.680] iteration 5867: loss: 0.134265, loss_s1: 0.101758, loss_fp: 0.006184, loss_freq: 0.074581
[03:30:03.301] iteration 5868: loss: 0.126458, loss_s1: 0.032409, loss_fp: 0.001331, loss_freq: 0.082700
[03:30:03.916] iteration 5869: loss: 0.138802, loss_s1: 0.111593, loss_fp: 0.007028, loss_freq: 0.084684
[03:30:04.529] iteration 5870: loss: 0.113329, loss_s1: 0.085231, loss_fp: 0.001356, loss_freq: 0.013286
[03:30:05.148] iteration 5871: loss: 0.091956, loss_s1: 0.027864, loss_fp: 0.000900, loss_freq: 0.016233
[03:30:05.800] iteration 5872: loss: 0.132002, loss_s1: 0.100766, loss_fp: 0.005949, loss_freq: 0.074656
[03:30:06.430] iteration 5873: loss: 0.103628, loss_s1: 0.054125, loss_fp: 0.003030, loss_freq: 0.048096
[03:30:07.043] iteration 5874: loss: 0.177105, loss_s1: 0.068454, loss_fp: 0.001563, loss_freq: 0.021499
[03:30:07.658] iteration 5875: loss: 0.099387, loss_s1: 0.087170, loss_fp: 0.000667, loss_freq: 0.014316
[03:30:08.548] iteration 5876: loss: 0.081373, loss_s1: 0.062575, loss_fp: 0.001604, loss_freq: 0.024650
[03:30:09.390] iteration 5877: loss: 0.142587, loss_s1: 0.069973, loss_fp: 0.001079, loss_freq: 0.044680
[03:30:10.158] iteration 5878: loss: 0.086201, loss_s1: 0.043873, loss_fp: 0.002035, loss_freq: 0.029421
[03:30:10.834] iteration 5879: loss: 0.099799, loss_s1: 0.057127, loss_fp: 0.000992, loss_freq: 0.044257
[03:30:11.493] iteration 5880: loss: 0.090351, loss_s1: 0.073031, loss_fp: 0.001836, loss_freq: 0.025311
[03:30:12.128] iteration 5881: loss: 0.093990, loss_s1: 0.041666, loss_fp: 0.003072, loss_freq: 0.040251
[03:30:12.762] iteration 5882: loss: 0.121761, loss_s1: 0.077126, loss_fp: 0.001580, loss_freq: 0.054236
[03:30:13.370] iteration 5883: loss: 0.090244, loss_s1: 0.060761, loss_fp: 0.000681, loss_freq: 0.024094
[03:30:13.988] iteration 5884: loss: 0.071903, loss_s1: 0.025950, loss_fp: 0.002227, loss_freq: 0.027004
[03:30:14.594] iteration 5885: loss: 0.140789, loss_s1: 0.099378, loss_fp: 0.010186, loss_freq: 0.087910
[03:30:15.215] iteration 5886: loss: 0.123828, loss_s1: 0.067959, loss_fp: 0.003842, loss_freq: 0.037442
[03:30:15.825] iteration 5887: loss: 0.115415, loss_s1: 0.090042, loss_fp: 0.006500, loss_freq: 0.030524
[03:30:16.443] iteration 5888: loss: 0.089124, loss_s1: 0.044099, loss_fp: 0.001005, loss_freq: 0.017700
[03:30:17.056] iteration 5889: loss: 0.138000, loss_s1: 0.062750, loss_fp: 0.003312, loss_freq: 0.080996
[03:30:17.675] iteration 5890: loss: 0.074558, loss_s1: 0.027626, loss_fp: 0.001303, loss_freq: 0.013365
[03:30:18.296] iteration 5891: loss: 0.085375, loss_s1: 0.049558, loss_fp: 0.005787, loss_freq: 0.026616
[03:30:18.909] iteration 5892: loss: 0.086332, loss_s1: 0.022819, loss_fp: 0.002860, loss_freq: 0.035159
[03:30:19.518] iteration 5893: loss: 0.056284, loss_s1: 0.034287, loss_fp: 0.000650, loss_freq: 0.005838
[03:30:20.131] iteration 5894: loss: 0.125782, loss_s1: 0.108326, loss_fp: 0.002978, loss_freq: 0.033341
[03:30:20.741] iteration 5895: loss: 0.148222, loss_s1: 0.101056, loss_fp: 0.005207, loss_freq: 0.042546
[03:30:21.422] iteration 5896: loss: 0.086494, loss_s1: 0.047687, loss_fp: 0.002148, loss_freq: 0.034906
[03:30:22.075] iteration 5897: loss: 0.116756, loss_s1: 0.068517, loss_fp: 0.004406, loss_freq: 0.083362
[03:30:22.730] iteration 5898: loss: 0.085096, loss_s1: 0.048927, loss_fp: 0.000811, loss_freq: 0.031735
[03:30:23.388] iteration 5899: loss: 0.181224, loss_s1: 0.142496, loss_fp: 0.006708, loss_freq: 0.074864
[03:30:24.004] iteration 5900: loss: 0.093880, loss_s1: 0.071164, loss_fp: 0.006169, loss_freq: 0.014192
[03:30:24.621] iteration 5901: loss: 0.079867, loss_s1: 0.053808, loss_fp: 0.001242, loss_freq: 0.009831
[03:30:25.238] iteration 5902: loss: 0.125161, loss_s1: 0.069210, loss_fp: 0.002675, loss_freq: 0.064270
[03:30:25.848] iteration 5903: loss: 0.096222, loss_s1: 0.054142, loss_fp: 0.003708, loss_freq: 0.038126
[03:30:26.487] iteration 5904: loss: 0.085326, loss_s1: 0.046804, loss_fp: 0.010774, loss_freq: 0.034120
[03:30:27.095] iteration 5905: loss: 0.136428, loss_s1: 0.092890, loss_fp: 0.000878, loss_freq: 0.032236
[03:30:27.711] iteration 5906: loss: 0.147927, loss_s1: 0.166337, loss_fp: 0.007376, loss_freq: 0.018671
[03:30:28.325] iteration 5907: loss: 0.158807, loss_s1: 0.106344, loss_fp: 0.013725, loss_freq: 0.101914
[03:30:28.945] iteration 5908: loss: 0.086523, loss_s1: 0.032370, loss_fp: 0.007823, loss_freq: 0.031103
[03:30:29.557] iteration 5909: loss: 0.075550, loss_s1: 0.056353, loss_fp: 0.000726, loss_freq: 0.013182
[03:30:30.172] iteration 5910: loss: 0.132714, loss_s1: 0.127821, loss_fp: 0.001732, loss_freq: 0.050323
[03:30:30.797] iteration 5911: loss: 0.122249, loss_s1: 0.125065, loss_fp: 0.001754, loss_freq: 0.055663
[03:30:31.441] iteration 5912: loss: 0.122610, loss_s1: 0.034788, loss_fp: 0.002896, loss_freq: 0.021392
[03:30:32.162] iteration 5913: loss: 0.115863, loss_s1: 0.058047, loss_fp: 0.001562, loss_freq: 0.074407
[03:30:32.840] iteration 5914: loss: 0.157008, loss_s1: 0.105074, loss_fp: 0.006372, loss_freq: 0.037438
[03:30:33.593] iteration 5915: loss: 0.141492, loss_s1: 0.091632, loss_fp: 0.004120, loss_freq: 0.103353
[03:30:34.257] iteration 5916: loss: 0.088608, loss_s1: 0.048152, loss_fp: 0.001124, loss_freq: 0.026366
[03:30:34.967] iteration 5917: loss: 0.189917, loss_s1: 0.160651, loss_fp: 0.001188, loss_freq: 0.026104
[03:30:35.665] iteration 5918: loss: 0.097948, loss_s1: 0.057235, loss_fp: 0.007715, loss_freq: 0.053324
[03:30:36.339] iteration 5919: loss: 0.146418, loss_s1: 0.149046, loss_fp: 0.001295, loss_freq: 0.053340
[03:30:37.086] iteration 5920: loss: 0.090033, loss_s1: 0.069112, loss_fp: 0.001192, loss_freq: 0.038773
[03:30:37.717] iteration 5921: loss: 0.123977, loss_s1: 0.060021, loss_fp: 0.003669, loss_freq: 0.020394
[03:30:38.551] iteration 5922: loss: 0.130285, loss_s1: 0.112377, loss_fp: 0.002327, loss_freq: 0.033672
[03:30:39.181] iteration 5923: loss: 0.166607, loss_s1: 0.132326, loss_fp: 0.005339, loss_freq: 0.055173
[03:30:39.879] iteration 5924: loss: 0.106545, loss_s1: 0.102045, loss_fp: 0.001417, loss_freq: 0.019918
[03:30:40.642] iteration 5925: loss: 0.095703, loss_s1: 0.044012, loss_fp: 0.004119, loss_freq: 0.025686
[03:30:41.286] iteration 5926: loss: 0.112711, loss_s1: 0.064001, loss_fp: 0.000958, loss_freq: 0.022076
[03:30:41.969] iteration 5927: loss: 0.123027, loss_s1: 0.117099, loss_fp: 0.004246, loss_freq: 0.032085
[03:30:42.610] iteration 5928: loss: 0.159440, loss_s1: 0.169454, loss_fp: 0.001509, loss_freq: 0.054249
[03:30:43.291] iteration 5929: loss: 0.113132, loss_s1: 0.110917, loss_fp: 0.004421, loss_freq: 0.051107
[03:30:43.922] iteration 5930: loss: 0.099414, loss_s1: 0.053444, loss_fp: 0.004870, loss_freq: 0.030575
[03:30:44.530] iteration 5931: loss: 0.117817, loss_s1: 0.100129, loss_fp: 0.000743, loss_freq: 0.031240
[03:30:45.143] iteration 5932: loss: 0.092300, loss_s1: 0.040224, loss_fp: 0.002688, loss_freq: 0.050687
[03:30:45.759] iteration 5933: loss: 0.155872, loss_s1: 0.086062, loss_fp: 0.005764, loss_freq: 0.066457
[03:30:46.376] iteration 5934: loss: 0.086053, loss_s1: 0.069360, loss_fp: 0.001706, loss_freq: 0.023051
[03:30:46.989] iteration 5935: loss: 0.120233, loss_s1: 0.109991, loss_fp: 0.002917, loss_freq: 0.039994
[03:30:47.609] iteration 5936: loss: 0.106733, loss_s1: 0.068230, loss_fp: 0.004587, loss_freq: 0.018301
[03:30:48.226] iteration 5937: loss: 0.094637, loss_s1: 0.030573, loss_fp: 0.001687, loss_freq: 0.043720
[03:30:48.840] iteration 5938: loss: 0.083559, loss_s1: 0.042426, loss_fp: 0.011111, loss_freq: 0.039569
[03:30:49.453] iteration 5939: loss: 0.126774, loss_s1: 0.112502, loss_fp: 0.003701, loss_freq: 0.082024
[03:30:50.067] iteration 5940: loss: 0.110853, loss_s1: 0.085958, loss_fp: 0.003694, loss_freq: 0.023893
[03:30:50.678] iteration 5941: loss: 0.097581, loss_s1: 0.090755, loss_fp: 0.000806, loss_freq: 0.005367
[03:30:51.325] iteration 5942: loss: 0.084265, loss_s1: 0.079709, loss_fp: 0.001163, loss_freq: 0.011904
[03:30:51.932] iteration 5943: loss: 0.120251, loss_s1: 0.038176, loss_fp: 0.001092, loss_freq: 0.038552
[03:30:52.547] iteration 5944: loss: 0.086261, loss_s1: 0.051476, loss_fp: 0.011395, loss_freq: 0.024554
[03:30:53.200] iteration 5945: loss: 0.090887, loss_s1: 0.047738, loss_fp: 0.001153, loss_freq: 0.017027
[03:30:53.958] iteration 5946: loss: 0.109911, loss_s1: 0.118613, loss_fp: 0.005010, loss_freq: 0.028117
[03:30:54.836] iteration 5947: loss: 0.116673, loss_s1: 0.081036, loss_fp: 0.002584, loss_freq: 0.043193
[03:30:55.649] iteration 5948: loss: 0.135207, loss_s1: 0.154775, loss_fp: 0.001448, loss_freq: 0.024659
[03:30:56.443] iteration 5949: loss: 0.105988, loss_s1: 0.068123, loss_fp: 0.001493, loss_freq: 0.058210
[03:30:57.050] iteration 5950: loss: 0.121151, loss_s1: 0.089260, loss_fp: 0.003096, loss_freq: 0.068525
[03:30:57.978] iteration 5951: loss: 0.095981, loss_s1: 0.058116, loss_fp: 0.001263, loss_freq: 0.022154
[03:30:58.592] iteration 5952: loss: 0.110836, loss_s1: 0.100497, loss_fp: 0.002068, loss_freq: 0.039030
[03:30:59.223] iteration 5953: loss: 0.082806, loss_s1: 0.037580, loss_fp: 0.004493, loss_freq: 0.057781
[03:30:59.835] iteration 5954: loss: 0.080862, loss_s1: 0.031705, loss_fp: 0.002870, loss_freq: 0.026331
[03:31:00.468] iteration 5955: loss: 0.134446, loss_s1: 0.111586, loss_fp: 0.002709, loss_freq: 0.040206
[03:31:01.084] iteration 5956: loss: 0.114152, loss_s1: 0.086636, loss_fp: 0.001710, loss_freq: 0.017914
[03:31:01.732] iteration 5957: loss: 0.092264, loss_s1: 0.058177, loss_fp: 0.015783, loss_freq: 0.041570
[03:31:02.348] iteration 5958: loss: 0.129158, loss_s1: 0.086091, loss_fp: 0.000992, loss_freq: 0.044192
[03:31:02.964] iteration 5959: loss: 0.123669, loss_s1: 0.161690, loss_fp: 0.002175, loss_freq: 0.017525
[03:31:03.581] iteration 5960: loss: 0.127795, loss_s1: 0.079474, loss_fp: 0.005604, loss_freq: 0.038989
[03:31:04.199] iteration 5961: loss: 0.164216, loss_s1: 0.080509, loss_fp: 0.004858, loss_freq: 0.065060
[03:31:04.816] iteration 5962: loss: 0.103597, loss_s1: 0.077290, loss_fp: 0.001087, loss_freq: 0.048210
[03:31:05.434] iteration 5963: loss: 0.145685, loss_s1: 0.097238, loss_fp: 0.001664, loss_freq: 0.096244
[03:31:06.045] iteration 5964: loss: 0.068933, loss_s1: 0.030705, loss_fp: 0.001379, loss_freq: 0.027297
[03:31:06.659] iteration 5965: loss: 0.138345, loss_s1: 0.075187, loss_fp: 0.004651, loss_freq: 0.061687
[03:31:07.278] iteration 5966: loss: 0.111813, loss_s1: 0.083394, loss_fp: 0.007285, loss_freq: 0.035607
[03:31:07.952] iteration 5967: loss: 0.148088, loss_s1: 0.116719, loss_fp: 0.005041, loss_freq: 0.061757
[03:31:08.612] iteration 5968: loss: 0.144894, loss_s1: 0.041540, loss_fp: 0.002322, loss_freq: 0.013377
[03:31:09.268] iteration 5969: loss: 0.117122, loss_s1: 0.127200, loss_fp: 0.007276, loss_freq: 0.024167
[03:31:09.930] iteration 5970: loss: 0.106689, loss_s1: 0.092126, loss_fp: 0.001769, loss_freq: 0.030609
[03:31:10.557] iteration 5971: loss: 0.085994, loss_s1: 0.072973, loss_fp: 0.003104, loss_freq: 0.026643
[03:31:11.203] iteration 5972: loss: 0.133931, loss_s1: 0.143706, loss_fp: 0.016643, loss_freq: 0.010652
[03:31:11.887] iteration 5973: loss: 0.107902, loss_s1: 0.043319, loss_fp: 0.000916, loss_freq: 0.024180
[03:31:12.542] iteration 5974: loss: 0.087809, loss_s1: 0.027494, loss_fp: 0.001629, loss_freq: 0.020466
[03:31:13.207] iteration 5975: loss: 0.132948, loss_s1: 0.133720, loss_fp: 0.000552, loss_freq: 0.028358
[03:31:13.845] iteration 5976: loss: 0.155931, loss_s1: 0.134700, loss_fp: 0.001695, loss_freq: 0.038508
[03:31:14.466] iteration 5977: loss: 0.134191, loss_s1: 0.095804, loss_fp: 0.001112, loss_freq: 0.025604
[03:31:15.095] iteration 5978: loss: 0.217038, loss_s1: 0.213396, loss_fp: 0.001252, loss_freq: 0.075746
[03:31:15.707] iteration 5979: loss: 0.206546, loss_s1: 0.098326, loss_fp: 0.001892, loss_freq: 0.052826
[03:31:16.404] iteration 5980: loss: 0.078333, loss_s1: 0.058946, loss_fp: 0.001529, loss_freq: 0.029258
[03:31:17.070] iteration 5981: loss: 0.113832, loss_s1: 0.059870, loss_fp: 0.003997, loss_freq: 0.032040
[03:31:17.733] iteration 5982: loss: 0.149925, loss_s1: 0.119277, loss_fp: 0.003628, loss_freq: 0.060407
[03:31:18.391] iteration 5983: loss: 0.147754, loss_s1: 0.089848, loss_fp: 0.000831, loss_freq: 0.034026
[03:31:19.022] iteration 5984: loss: 0.075318, loss_s1: 0.048600, loss_fp: 0.000546, loss_freq: 0.009213
[03:31:19.637] iteration 5985: loss: 0.102990, loss_s1: 0.057314, loss_fp: 0.002009, loss_freq: 0.052643
[03:31:20.264] iteration 5986: loss: 0.106332, loss_s1: 0.062479, loss_fp: 0.003378, loss_freq: 0.021535
[03:31:20.882] iteration 5987: loss: 0.127390, loss_s1: 0.104418, loss_fp: 0.000963, loss_freq: 0.053177
[03:31:21.505] iteration 5988: loss: 0.084157, loss_s1: 0.073827, loss_fp: 0.006370, loss_freq: 0.015514
[03:31:22.148] iteration 5989: loss: 0.126164, loss_s1: 0.135090, loss_fp: 0.004069, loss_freq: 0.026926
[03:31:22.779] iteration 5990: loss: 0.157293, loss_s1: 0.093743, loss_fp: 0.008036, loss_freq: 0.047534
[03:31:23.444] iteration 5991: loss: 0.166680, loss_s1: 0.130757, loss_fp: 0.002004, loss_freq: 0.094086
[03:31:24.106] iteration 5992: loss: 0.111009, loss_s1: 0.103424, loss_fp: 0.004410, loss_freq: 0.042504
[03:31:24.761] iteration 5993: loss: 0.121873, loss_s1: 0.091065, loss_fp: 0.000733, loss_freq: 0.061314
[03:31:25.373] iteration 5994: loss: 0.160878, loss_s1: 0.124338, loss_fp: 0.005431, loss_freq: 0.105774
[03:31:25.988] iteration 5995: loss: 0.084420, loss_s1: 0.045245, loss_fp: 0.001892, loss_freq: 0.025975
[03:31:26.599] iteration 5996: loss: 0.119918, loss_s1: 0.095989, loss_fp: 0.000438, loss_freq: 0.046606
[03:31:27.217] iteration 5997: loss: 0.075907, loss_s1: 0.056807, loss_fp: 0.004244, loss_freq: 0.012767
[03:31:27.835] iteration 5998: loss: 0.139253, loss_s1: 0.103683, loss_fp: 0.007490, loss_freq: 0.040918
[03:31:28.448] iteration 5999: loss: 0.121116, loss_s1: 0.092816, loss_fp: 0.001330, loss_freq: 0.012421
[03:31:29.062] iteration 6000: loss: 0.126984, loss_s1: 0.095953, loss_fp: 0.000491, loss_freq: 0.016669
[03:31:32.686] iteration 6000 : mean_dice : 0.619251
[03:31:33.394] iteration 6001: loss: 0.077213, loss_s1: 0.019083, loss_fp: 0.002160, loss_freq: 0.050568
[03:31:34.054] iteration 6002: loss: 0.125508, loss_s1: 0.115195, loss_fp: 0.000778, loss_freq: 0.034405
[03:31:34.718] iteration 6003: loss: 0.095691, loss_s1: 0.037165, loss_fp: 0.000923, loss_freq: 0.028931
[03:31:35.386] iteration 6004: loss: 0.106974, loss_s1: 0.115187, loss_fp: 0.001044, loss_freq: 0.037085
[03:31:36.027] iteration 6005: loss: 0.169548, loss_s1: 0.051274, loss_fp: 0.000949, loss_freq: 0.122918
[03:31:36.641] iteration 6006: loss: 0.088029, loss_s1: 0.049478, loss_fp: 0.001930, loss_freq: 0.009160
[03:31:37.254] iteration 6007: loss: 0.089007, loss_s1: 0.070025, loss_fp: 0.000444, loss_freq: 0.026041
[03:31:37.869] iteration 6008: loss: 0.186890, loss_s1: 0.187108, loss_fp: 0.001633, loss_freq: 0.057777
[03:31:38.479] iteration 6009: loss: 0.160956, loss_s1: 0.092801, loss_fp: 0.001945, loss_freq: 0.079714
[03:31:39.095] iteration 6010: loss: 0.105031, loss_s1: 0.084260, loss_fp: 0.002166, loss_freq: 0.048897
[03:31:39.718] iteration 6011: loss: 0.057828, loss_s1: 0.025860, loss_fp: 0.001212, loss_freq: 0.023486
[03:31:40.333] iteration 6012: loss: 0.102161, loss_s1: 0.048212, loss_fp: 0.006684, loss_freq: 0.051900
[03:31:40.974] iteration 6013: loss: 0.078398, loss_s1: 0.054923, loss_fp: 0.000543, loss_freq: 0.008221
[03:31:41.631] iteration 6014: loss: 0.089683, loss_s1: 0.061983, loss_fp: 0.002351, loss_freq: 0.020234
[03:31:42.297] iteration 6015: loss: 0.142960, loss_s1: 0.092770, loss_fp: 0.005880, loss_freq: 0.024103
[03:31:42.956] iteration 6016: loss: 0.095147, loss_s1: 0.065313, loss_fp: 0.005968, loss_freq: 0.040922
[03:31:43.610] iteration 6017: loss: 0.128788, loss_s1: 0.048392, loss_fp: 0.001080, loss_freq: 0.011373
[03:31:44.223] iteration 6018: loss: 0.158163, loss_s1: 0.122657, loss_fp: 0.002250, loss_freq: 0.056509
[03:31:44.832] iteration 6019: loss: 0.061931, loss_s1: 0.036663, loss_fp: 0.001695, loss_freq: 0.020267
[03:31:45.446] iteration 6020: loss: 0.082443, loss_s1: 0.054290, loss_fp: 0.015412, loss_freq: 0.027584
[03:31:46.088] iteration 6021: loss: 0.109484, loss_s1: 0.068725, loss_fp: 0.005760, loss_freq: 0.055565
[03:31:46.704] iteration 6022: loss: 0.100647, loss_s1: 0.069682, loss_fp: 0.002862, loss_freq: 0.029586
[03:31:47.314] iteration 6023: loss: 0.103790, loss_s1: 0.102134, loss_fp: 0.004557, loss_freq: 0.034533
[03:31:47.932] iteration 6024: loss: 0.132260, loss_s1: 0.116484, loss_fp: 0.001581, loss_freq: 0.034249
[03:31:48.544] iteration 6025: loss: 0.122681, loss_s1: 0.068556, loss_fp: 0.001961, loss_freq: 0.045700
[03:31:49.156] iteration 6026: loss: 0.129958, loss_s1: 0.085136, loss_fp: 0.004156, loss_freq: 0.044754
[03:31:49.766] iteration 6027: loss: 0.084553, loss_s1: 0.092134, loss_fp: 0.001271, loss_freq: 0.011809
[03:31:50.381] iteration 6028: loss: 0.146545, loss_s1: 0.107518, loss_fp: 0.002548, loss_freq: 0.046971
[03:31:51.031] iteration 6029: loss: 0.100224, loss_s1: 0.079232, loss_fp: 0.001497, loss_freq: 0.038555
[03:31:51.680] iteration 6030: loss: 0.106305, loss_s1: 0.057502, loss_fp: 0.010509, loss_freq: 0.032460
[03:31:52.315] iteration 6031: loss: 0.115595, loss_s1: 0.035608, loss_fp: 0.010583, loss_freq: 0.085060
[03:31:52.931] iteration 6032: loss: 0.062754, loss_s1: 0.026678, loss_fp: 0.005217, loss_freq: 0.014922
[03:31:53.594] iteration 6033: loss: 0.128255, loss_s1: 0.086972, loss_fp: 0.002150, loss_freq: 0.045818
[03:31:54.250] iteration 6034: loss: 0.090737, loss_s1: 0.047386, loss_fp: 0.008949, loss_freq: 0.029351
[03:31:54.906] iteration 6035: loss: 0.114661, loss_s1: 0.082801, loss_fp: 0.001677, loss_freq: 0.047846
[03:31:55.550] iteration 6036: loss: 0.085075, loss_s1: 0.028983, loss_fp: 0.002677, loss_freq: 0.064031
[03:31:56.160] iteration 6037: loss: 0.111211, loss_s1: 0.106986, loss_fp: 0.000636, loss_freq: 0.051399
[03:31:56.774] iteration 6038: loss: 0.134151, loss_s1: 0.154627, loss_fp: 0.009843, loss_freq: 0.032793
[03:31:57.387] iteration 6039: loss: 0.140117, loss_s1: 0.148708, loss_fp: 0.011278, loss_freq: 0.050688
[03:31:58.005] iteration 6040: loss: 0.095321, loss_s1: 0.062779, loss_fp: 0.015660, loss_freq: 0.021350
[03:31:58.613] iteration 6041: loss: 0.128682, loss_s1: 0.083498, loss_fp: 0.001189, loss_freq: 0.032551
[03:31:59.228] iteration 6042: loss: 0.139764, loss_s1: 0.127079, loss_fp: 0.001725, loss_freq: 0.062893
[03:31:59.837] iteration 6043: loss: 0.146082, loss_s1: 0.085739, loss_fp: 0.001563, loss_freq: 0.033088
[03:32:00.452] iteration 6044: loss: 0.107488, loss_s1: 0.071236, loss_fp: 0.000618, loss_freq: 0.010091
[03:32:01.061] iteration 6045: loss: 0.108496, loss_s1: 0.120688, loss_fp: 0.001007, loss_freq: 0.010931
[03:32:01.673] iteration 6046: loss: 0.146664, loss_s1: 0.173173, loss_fp: 0.002802, loss_freq: 0.034379
[03:32:02.283] iteration 6047: loss: 0.180309, loss_s1: 0.111268, loss_fp: 0.001871, loss_freq: 0.036690
[03:32:02.897] iteration 6048: loss: 0.069270, loss_s1: 0.029518, loss_fp: 0.002406, loss_freq: 0.014987
[03:32:03.571] iteration 6049: loss: 0.124484, loss_s1: 0.060410, loss_fp: 0.003938, loss_freq: 0.051720
[03:32:04.232] iteration 6050: loss: 0.087005, loss_s1: 0.049548, loss_fp: 0.001739, loss_freq: 0.027507
[03:32:04.892] iteration 6051: loss: 0.143226, loss_s1: 0.068825, loss_fp: 0.000985, loss_freq: 0.050732
[03:32:05.559] iteration 6052: loss: 0.105368, loss_s1: 0.043243, loss_fp: 0.000979, loss_freq: 0.044177
[03:32:06.192] iteration 6053: loss: 0.068184, loss_s1: 0.050609, loss_fp: 0.000296, loss_freq: 0.023732
[03:32:06.806] iteration 6054: loss: 0.101142, loss_s1: 0.024986, loss_fp: 0.002180, loss_freq: 0.020967
[03:32:07.417] iteration 6055: loss: 0.132104, loss_s1: 0.091413, loss_fp: 0.002958, loss_freq: 0.062415
[03:32:08.029] iteration 6056: loss: 0.135716, loss_s1: 0.081744, loss_fp: 0.002217, loss_freq: 0.041073
[03:32:08.636] iteration 6057: loss: 0.059463, loss_s1: 0.008518, loss_fp: 0.001119, loss_freq: 0.016814
[03:32:09.259] iteration 6058: loss: 0.131118, loss_s1: 0.069097, loss_fp: 0.001084, loss_freq: 0.037430
[03:32:09.870] iteration 6059: loss: 0.141467, loss_s1: 0.121561, loss_fp: 0.009857, loss_freq: 0.058287
[03:32:10.483] iteration 6060: loss: 0.082831, loss_s1: 0.026401, loss_fp: 0.001797, loss_freq: 0.023352
[03:32:11.088] iteration 6061: loss: 0.102968, loss_s1: 0.070311, loss_fp: 0.003495, loss_freq: 0.023417
[03:32:11.758] iteration 6062: loss: 0.077398, loss_s1: 0.039160, loss_fp: 0.002523, loss_freq: 0.018532
[03:32:12.418] iteration 6063: loss: 0.061368, loss_s1: 0.043001, loss_fp: 0.002099, loss_freq: 0.015314
[03:32:13.096] iteration 6064: loss: 0.085006, loss_s1: 0.069467, loss_fp: 0.002459, loss_freq: 0.028912
[03:32:13.732] iteration 6065: loss: 0.126732, loss_s1: 0.059828, loss_fp: 0.004907, loss_freq: 0.074906
[03:32:14.359] iteration 6066: loss: 0.104534, loss_s1: 0.066556, loss_fp: 0.002983, loss_freq: 0.052810
[03:32:14.970] iteration 6067: loss: 0.095291, loss_s1: 0.062780, loss_fp: 0.005566, loss_freq: 0.055718
[03:32:15.584] iteration 6068: loss: 0.072374, loss_s1: 0.037082, loss_fp: 0.002008, loss_freq: 0.024096
[03:32:16.201] iteration 6069: loss: 0.135442, loss_s1: 0.084657, loss_fp: 0.003097, loss_freq: 0.108225
[03:32:16.811] iteration 6070: loss: 0.127814, loss_s1: 0.070509, loss_fp: 0.001025, loss_freq: 0.035991
[03:32:17.424] iteration 6071: loss: 0.100688, loss_s1: 0.072872, loss_fp: 0.002375, loss_freq: 0.022969
[03:32:18.073] iteration 6072: loss: 0.088790, loss_s1: 0.067050, loss_fp: 0.007213, loss_freq: 0.037390
[03:32:18.727] iteration 6073: loss: 0.097661, loss_s1: 0.089445, loss_fp: 0.002945, loss_freq: 0.030238
[03:32:19.357] iteration 6074: loss: 0.124505, loss_s1: 0.100484, loss_fp: 0.002412, loss_freq: 0.079419
[03:32:20.011] iteration 6075: loss: 0.118684, loss_s1: 0.106632, loss_fp: 0.003036, loss_freq: 0.045184
[03:32:20.667] iteration 6076: loss: 0.119986, loss_s1: 0.136674, loss_fp: 0.003245, loss_freq: 0.032607
[03:32:21.334] iteration 6077: loss: 0.181349, loss_s1: 0.150897, loss_fp: 0.003764, loss_freq: 0.144028
[03:32:21.957] iteration 6078: loss: 0.117723, loss_s1: 0.052397, loss_fp: 0.003171, loss_freq: 0.075439
[03:32:22.605] iteration 6079: loss: 0.099583, loss_s1: 0.093948, loss_fp: 0.001332, loss_freq: 0.021454
[03:32:23.261] iteration 6080: loss: 0.063691, loss_s1: 0.047726, loss_fp: 0.005063, loss_freq: 0.015291
[03:32:23.917] iteration 6081: loss: 0.118975, loss_s1: 0.164096, loss_fp: 0.004281, loss_freq: 0.014132
[03:32:24.576] iteration 6082: loss: 0.101748, loss_s1: 0.037015, loss_fp: 0.001904, loss_freq: 0.013944
[03:32:25.203] iteration 6083: loss: 0.142154, loss_s1: 0.095409, loss_fp: 0.002673, loss_freq: 0.085829
[03:32:25.809] iteration 6084: loss: 0.152280, loss_s1: 0.119345, loss_fp: 0.001062, loss_freq: 0.068550
[03:32:26.426] iteration 6085: loss: 0.117648, loss_s1: 0.066773, loss_fp: 0.004263, loss_freq: 0.087409
[03:32:27.040] iteration 6086: loss: 0.114150, loss_s1: 0.078992, loss_fp: 0.000509, loss_freq: 0.058969
[03:32:27.664] iteration 6087: loss: 0.112508, loss_s1: 0.056211, loss_fp: 0.001648, loss_freq: 0.024279
[03:32:28.279] iteration 6088: loss: 0.123566, loss_s1: 0.082466, loss_fp: 0.009769, loss_freq: 0.037414
[03:32:28.893] iteration 6089: loss: 0.166558, loss_s1: 0.149220, loss_fp: 0.008085, loss_freq: 0.103892
[03:32:29.508] iteration 6090: loss: 0.119665, loss_s1: 0.107331, loss_fp: 0.001487, loss_freq: 0.069179
[03:32:30.200] iteration 6091: loss: 0.134900, loss_s1: 0.053690, loss_fp: 0.005727, loss_freq: 0.049690
[03:32:30.856] iteration 6092: loss: 0.090411, loss_s1: 0.046287, loss_fp: 0.000809, loss_freq: 0.037895
[03:32:31.515] iteration 6093: loss: 0.088724, loss_s1: 0.059873, loss_fp: 0.001398, loss_freq: 0.036523
[03:32:32.159] iteration 6094: loss: 0.080662, loss_s1: 0.026212, loss_fp: 0.004900, loss_freq: 0.014674
[03:32:32.773] iteration 6095: loss: 0.091382, loss_s1: 0.053802, loss_fp: 0.004776, loss_freq: 0.015820
[03:32:33.388] iteration 6096: loss: 0.096897, loss_s1: 0.069757, loss_fp: 0.001838, loss_freq: 0.038395
[03:32:34.008] iteration 6097: loss: 0.095245, loss_s1: 0.087157, loss_fp: 0.001418, loss_freq: 0.041033
[03:32:34.631] iteration 6098: loss: 0.139072, loss_s1: 0.124941, loss_fp: 0.004433, loss_freq: 0.052278
[03:32:35.240] iteration 6099: loss: 0.103507, loss_s1: 0.082596, loss_fp: 0.001987, loss_freq: 0.061838
[03:32:35.846] iteration 6100: loss: 0.124790, loss_s1: 0.057467, loss_fp: 0.006672, loss_freq: 0.027561
[03:32:36.456] iteration 6101: loss: 0.118616, loss_s1: 0.103838, loss_fp: 0.001000, loss_freq: 0.019082
[03:32:37.062] iteration 6102: loss: 0.116942, loss_s1: 0.086644, loss_fp: 0.002258, loss_freq: 0.024093
[03:32:37.676] iteration 6103: loss: 0.238773, loss_s1: 0.158702, loss_fp: 0.002579, loss_freq: 0.115569
[03:32:38.298] iteration 6104: loss: 0.107654, loss_s1: 0.077585, loss_fp: 0.005891, loss_freq: 0.039574
[03:32:38.924] iteration 6105: loss: 0.176657, loss_s1: 0.104116, loss_fp: 0.005186, loss_freq: 0.045309
[03:32:39.542] iteration 6106: loss: 0.078249, loss_s1: 0.059979, loss_fp: 0.000896, loss_freq: 0.028178
[03:32:40.154] iteration 6107: loss: 0.075956, loss_s1: 0.036881, loss_fp: 0.007490, loss_freq: 0.031095
[03:32:40.769] iteration 6108: loss: 0.098623, loss_s1: 0.052118, loss_fp: 0.001440, loss_freq: 0.032666
[03:32:41.390] iteration 6109: loss: 0.076003, loss_s1: 0.057757, loss_fp: 0.001057, loss_freq: 0.038399
[03:32:42.012] iteration 6110: loss: 0.113694, loss_s1: 0.105685, loss_fp: 0.001505, loss_freq: 0.027524
[03:32:42.632] iteration 6111: loss: 0.065278, loss_s1: 0.055707, loss_fp: 0.004556, loss_freq: 0.008501
[03:32:43.248] iteration 6112: loss: 0.111504, loss_s1: 0.063731, loss_fp: 0.001439, loss_freq: 0.022013
[03:32:43.871] iteration 6113: loss: 0.114522, loss_s1: 0.096493, loss_fp: 0.001680, loss_freq: 0.019819
[03:32:44.498] iteration 6114: loss: 0.093891, loss_s1: 0.048267, loss_fp: 0.001435, loss_freq: 0.031041
[03:32:45.134] iteration 6115: loss: 0.062951, loss_s1: 0.031565, loss_fp: 0.001332, loss_freq: 0.014148
[03:32:45.746] iteration 6116: loss: 0.188936, loss_s1: 0.202978, loss_fp: 0.002604, loss_freq: 0.032945
[03:32:46.363] iteration 6117: loss: 0.096642, loss_s1: 0.057576, loss_fp: 0.010806, loss_freq: 0.039649
[03:32:46.975] iteration 6118: loss: 0.085649, loss_s1: 0.083340, loss_fp: 0.000876, loss_freq: 0.014728
[03:32:47.587] iteration 6119: loss: 0.148126, loss_s1: 0.088418, loss_fp: 0.002916, loss_freq: 0.080624
[03:32:48.194] iteration 6120: loss: 0.128408, loss_s1: 0.097855, loss_fp: 0.002302, loss_freq: 0.069087
[03:32:49.162] iteration 6121: loss: 0.112210, loss_s1: 0.050873, loss_fp: 0.000999, loss_freq: 0.024322
[03:32:49.787] iteration 6122: loss: 0.087567, loss_s1: 0.082089, loss_fp: 0.002620, loss_freq: 0.016637
[03:32:50.410] iteration 6123: loss: 0.119579, loss_s1: 0.070770, loss_fp: 0.007000, loss_freq: 0.049045
[03:32:51.017] iteration 6124: loss: 0.077834, loss_s1: 0.032591, loss_fp: 0.000585, loss_freq: 0.033395
[03:32:51.625] iteration 6125: loss: 0.139083, loss_s1: 0.043223, loss_fp: 0.004117, loss_freq: 0.038644
[03:32:52.256] iteration 6126: loss: 0.088685, loss_s1: 0.051531, loss_fp: 0.001332, loss_freq: 0.016834
[03:32:53.012] iteration 6127: loss: 0.099150, loss_s1: 0.060506, loss_fp: 0.003223, loss_freq: 0.047786
[03:32:53.689] iteration 6128: loss: 0.073042, loss_s1: 0.046115, loss_fp: 0.002586, loss_freq: 0.025110
[03:32:54.385] iteration 6129: loss: 0.076687, loss_s1: 0.034393, loss_fp: 0.001013, loss_freq: 0.042971
[03:32:55.106] iteration 6130: loss: 0.121230, loss_s1: 0.075252, loss_fp: 0.018586, loss_freq: 0.045698
[03:32:55.768] iteration 6131: loss: 0.110338, loss_s1: 0.027747, loss_fp: 0.001749, loss_freq: 0.081008
[03:32:56.470] iteration 6132: loss: 0.155769, loss_s1: 0.134865, loss_fp: 0.000493, loss_freq: 0.072367
[03:32:57.201] iteration 6133: loss: 0.092502, loss_s1: 0.038042, loss_fp: 0.001723, loss_freq: 0.047863
[03:32:57.831] iteration 6134: loss: 0.095022, loss_s1: 0.048795, loss_fp: 0.000371, loss_freq: 0.026452
[03:32:58.575] iteration 6135: loss: 0.128077, loss_s1: 0.068254, loss_fp: 0.000910, loss_freq: 0.025473
[03:32:59.293] iteration 6136: loss: 0.114181, loss_s1: 0.067362, loss_fp: 0.007381, loss_freq: 0.045828
[03:32:59.944] iteration 6137: loss: 0.159652, loss_s1: 0.131942, loss_fp: 0.009480, loss_freq: 0.113413
[03:33:00.653] iteration 6138: loss: 0.101651, loss_s1: 0.048035, loss_fp: 0.001857, loss_freq: 0.019654
[03:33:01.334] iteration 6139: loss: 0.113921, loss_s1: 0.141755, loss_fp: 0.002754, loss_freq: 0.027987
[03:33:01.977] iteration 6140: loss: 0.096457, loss_s1: 0.054108, loss_fp: 0.002168, loss_freq: 0.020152
[03:33:02.758] iteration 6141: loss: 0.080368, loss_s1: 0.032235, loss_fp: 0.008044, loss_freq: 0.026274
[03:33:03.392] iteration 6142: loss: 0.128250, loss_s1: 0.072398, loss_fp: 0.003129, loss_freq: 0.059435
[03:33:04.143] iteration 6143: loss: 0.092261, loss_s1: 0.050060, loss_fp: 0.000626, loss_freq: 0.017506
[03:33:04.823] iteration 6144: loss: 0.077158, loss_s1: 0.036451, loss_fp: 0.005743, loss_freq: 0.049632
[03:33:05.480] iteration 6145: loss: 0.135023, loss_s1: 0.117164, loss_fp: 0.001524, loss_freq: 0.019270
[03:33:06.176] iteration 6146: loss: 0.070594, loss_s1: 0.038469, loss_fp: 0.001747, loss_freq: 0.043480
[03:33:06.933] iteration 6147: loss: 0.121037, loss_s1: 0.038291, loss_fp: 0.001870, loss_freq: 0.011393
[03:33:07.679] iteration 6148: loss: 0.151213, loss_s1: 0.107357, loss_fp: 0.003161, loss_freq: 0.070644
[03:33:08.427] iteration 6149: loss: 0.102449, loss_s1: 0.065964, loss_fp: 0.000957, loss_freq: 0.027025
[03:33:09.112] iteration 6150: loss: 0.136965, loss_s1: 0.116683, loss_fp: 0.002240, loss_freq: 0.035329
[03:33:09.848] iteration 6151: loss: 0.093870, loss_s1: 0.054106, loss_fp: 0.001507, loss_freq: 0.034865
[03:33:10.519] iteration 6152: loss: 0.115799, loss_s1: 0.045978, loss_fp: 0.001575, loss_freq: 0.034947
[03:33:11.171] iteration 6153: loss: 0.076577, loss_s1: 0.042062, loss_fp: 0.006703, loss_freq: 0.023598
[03:33:11.767] iteration 6154: loss: 0.085229, loss_s1: 0.088097, loss_fp: 0.002442, loss_freq: 0.018616
[03:33:12.366] iteration 6155: loss: 0.088896, loss_s1: 0.072021, loss_fp: 0.002874, loss_freq: 0.039851
[03:33:12.962] iteration 6156: loss: 0.094072, loss_s1: 0.054117, loss_fp: 0.001823, loss_freq: 0.020357
[03:33:13.559] iteration 6157: loss: 0.092338, loss_s1: 0.056703, loss_fp: 0.004736, loss_freq: 0.038636
[03:33:14.153] iteration 6158: loss: 0.121023, loss_s1: 0.119471, loss_fp: 0.004839, loss_freq: 0.039280
[03:33:14.746] iteration 6159: loss: 0.162914, loss_s1: 0.125316, loss_fp: 0.025957, loss_freq: 0.064496
[03:33:15.331] iteration 6160: loss: 0.084863, loss_s1: 0.050090, loss_fp: 0.004603, loss_freq: 0.043344
[03:33:15.920] iteration 6161: loss: 0.123590, loss_s1: 0.081996, loss_fp: 0.005893, loss_freq: 0.042377
[03:33:16.511] iteration 6162: loss: 0.133323, loss_s1: 0.083746, loss_fp: 0.002024, loss_freq: 0.073736
[03:33:17.104] iteration 6163: loss: 0.124561, loss_s1: 0.120545, loss_fp: 0.004480, loss_freq: 0.058377
[03:33:17.690] iteration 6164: loss: 0.175642, loss_s1: 0.159015, loss_fp: 0.011809, loss_freq: 0.095966
[03:33:18.282] iteration 6165: loss: 0.102338, loss_s1: 0.063257, loss_fp: 0.005808, loss_freq: 0.031263
[03:33:18.880] iteration 6166: loss: 0.138099, loss_s1: 0.142192, loss_fp: 0.001912, loss_freq: 0.036003
[03:33:19.470] iteration 6167: loss: 0.094658, loss_s1: 0.091238, loss_fp: 0.002366, loss_freq: 0.023054
[03:33:20.060] iteration 6168: loss: 0.100142, loss_s1: 0.041754, loss_fp: 0.002879, loss_freq: 0.066456
[03:33:20.682] iteration 6169: loss: 0.082639, loss_s1: 0.033998, loss_fp: 0.002990, loss_freq: 0.029076
[03:33:21.348] iteration 6170: loss: 0.124274, loss_s1: 0.105301, loss_fp: 0.001473, loss_freq: 0.016587
[03:33:21.976] iteration 6171: loss: 0.099866, loss_s1: 0.076597, loss_fp: 0.000580, loss_freq: 0.054328
[03:33:22.569] iteration 6172: loss: 0.091348, loss_s1: 0.078899, loss_fp: 0.004936, loss_freq: 0.039425
[03:33:23.156] iteration 6173: loss: 0.132997, loss_s1: 0.072987, loss_fp: 0.000835, loss_freq: 0.059114
[03:33:23.743] iteration 6174: loss: 0.118098, loss_s1: 0.088124, loss_fp: 0.002496, loss_freq: 0.060062
[03:33:24.333] iteration 6175: loss: 0.099624, loss_s1: 0.019819, loss_fp: 0.005278, loss_freq: 0.077936
[03:33:24.922] iteration 6176: loss: 0.090488, loss_s1: 0.072708, loss_fp: 0.008409, loss_freq: 0.025059
[03:33:25.513] iteration 6177: loss: 0.088917, loss_s1: 0.077606, loss_fp: 0.000815, loss_freq: 0.030094
[03:33:26.099] iteration 6178: loss: 0.118225, loss_s1: 0.071515, loss_fp: 0.006406, loss_freq: 0.053908
[03:33:26.746] iteration 6179: loss: 0.143079, loss_s1: 0.055752, loss_fp: 0.001184, loss_freq: 0.047708
[03:33:27.369] iteration 6180: loss: 0.106686, loss_s1: 0.072323, loss_fp: 0.002625, loss_freq: 0.078144
[03:33:28.000] iteration 6181: loss: 0.078679, loss_s1: 0.065803, loss_fp: 0.002935, loss_freq: 0.026635
[03:33:28.626] iteration 6182: loss: 0.112876, loss_s1: 0.077347, loss_fp: 0.001545, loss_freq: 0.044157
[03:33:29.261] iteration 6183: loss: 0.077259, loss_s1: 0.020980, loss_fp: 0.001308, loss_freq: 0.020581
[03:33:29.888] iteration 6184: loss: 0.066765, loss_s1: 0.046543, loss_fp: 0.004008, loss_freq: 0.007854
[03:33:30.522] iteration 6185: loss: 0.103992, loss_s1: 0.078860, loss_fp: 0.000965, loss_freq: 0.037096
[03:33:31.150] iteration 6186: loss: 0.115255, loss_s1: 0.092777, loss_fp: 0.000468, loss_freq: 0.025090
[03:33:31.749] iteration 6187: loss: 0.104248, loss_s1: 0.047674, loss_fp: 0.006062, loss_freq: 0.015926
[03:33:32.342] iteration 6188: loss: 0.149083, loss_s1: 0.106641, loss_fp: 0.010437, loss_freq: 0.055563
[03:33:32.929] iteration 6189: loss: 0.108743, loss_s1: 0.040354, loss_fp: 0.001854, loss_freq: 0.030540
[03:33:33.538] iteration 6190: loss: 0.086557, loss_s1: 0.072813, loss_fp: 0.002332, loss_freq: 0.024682
[03:33:34.138] iteration 6191: loss: 0.112202, loss_s1: 0.064310, loss_fp: 0.001609, loss_freq: 0.050299
[03:33:34.726] iteration 6192: loss: 0.079554, loss_s1: 0.059185, loss_fp: 0.002264, loss_freq: 0.020077
[03:33:35.314] iteration 6193: loss: 0.111868, loss_s1: 0.086295, loss_fp: 0.005426, loss_freq: 0.018474
[03:33:35.899] iteration 6194: loss: 0.153837, loss_s1: 0.169488, loss_fp: 0.003479, loss_freq: 0.028391
[03:33:36.518] iteration 6195: loss: 0.131838, loss_s1: 0.068675, loss_fp: 0.003517, loss_freq: 0.053719
[03:33:37.148] iteration 6196: loss: 0.131254, loss_s1: 0.060637, loss_fp: 0.006347, loss_freq: 0.041610
[03:33:37.779] iteration 6197: loss: 0.099432, loss_s1: 0.053358, loss_fp: 0.003993, loss_freq: 0.019237
[03:33:38.411] iteration 6198: loss: 0.128981, loss_s1: 0.056568, loss_fp: 0.002018, loss_freq: 0.028495
[03:33:39.048] iteration 6199: loss: 0.083633, loss_s1: 0.041458, loss_fp: 0.002556, loss_freq: 0.046718
[03:33:39.646] iteration 6200: loss: 0.091440, loss_s1: 0.042394, loss_fp: 0.001405, loss_freq: 0.029636
[03:33:43.067] iteration 6200 : mean_dice : 0.647088
[03:33:43.698] iteration 6201: loss: 0.140994, loss_s1: 0.050846, loss_fp: 0.023008, loss_freq: 0.094694
[03:33:44.290] iteration 6202: loss: 0.064791, loss_s1: 0.043173, loss_fp: 0.004693, loss_freq: 0.022888
[03:33:44.879] iteration 6203: loss: 0.114346, loss_s1: 0.092396, loss_fp: 0.003240, loss_freq: 0.029766
[03:33:45.516] iteration 6204: loss: 0.085472, loss_s1: 0.052710, loss_fp: 0.004560, loss_freq: 0.015896
[03:33:46.150] iteration 6205: loss: 0.077447, loss_s1: 0.028994, loss_fp: 0.001347, loss_freq: 0.047607
[03:33:46.779] iteration 6206: loss: 0.104326, loss_s1: 0.089757, loss_fp: 0.003115, loss_freq: 0.050742
[03:33:47.411] iteration 6207: loss: 0.100654, loss_s1: 0.072887, loss_fp: 0.002225, loss_freq: 0.054779
[03:33:48.043] iteration 6208: loss: 0.180495, loss_s1: 0.112430, loss_fp: 0.009892, loss_freq: 0.071903
[03:33:48.674] iteration 6209: loss: 0.077386, loss_s1: 0.033452, loss_fp: 0.008823, loss_freq: 0.022532
[03:33:49.284] iteration 6210: loss: 0.091164, loss_s1: 0.046632, loss_fp: 0.001129, loss_freq: 0.042313
[03:33:49.875] iteration 6211: loss: 0.109003, loss_s1: 0.087795, loss_fp: 0.001814, loss_freq: 0.038290
[03:33:50.475] iteration 6212: loss: 0.084054, loss_s1: 0.055187, loss_fp: 0.009303, loss_freq: 0.024496
[03:33:51.066] iteration 6213: loss: 0.164461, loss_s1: 0.121242, loss_fp: 0.006306, loss_freq: 0.103720
[03:33:51.698] iteration 6214: loss: 0.062449, loss_s1: 0.042467, loss_fp: 0.001635, loss_freq: 0.016517
[03:33:52.333] iteration 6215: loss: 0.057784, loss_s1: 0.037674, loss_fp: 0.000845, loss_freq: 0.019474
[03:33:52.966] iteration 6216: loss: 0.118396, loss_s1: 0.145443, loss_fp: 0.002405, loss_freq: 0.031832
[03:33:53.587] iteration 6217: loss: 0.091861, loss_s1: 0.053710, loss_fp: 0.007627, loss_freq: 0.037398
[03:33:54.176] iteration 6218: loss: 0.080483, loss_s1: 0.053978, loss_fp: 0.001036, loss_freq: 0.030786
[03:33:54.761] iteration 6219: loss: 0.098933, loss_s1: 0.064460, loss_fp: 0.001530, loss_freq: 0.033084
[03:33:55.357] iteration 6220: loss: 0.076472, loss_s1: 0.047083, loss_fp: 0.001085, loss_freq: 0.037047
[03:33:55.945] iteration 6221: loss: 0.121363, loss_s1: 0.075909, loss_fp: 0.007038, loss_freq: 0.042038
[03:33:56.535] iteration 6222: loss: 0.091152, loss_s1: 0.044754, loss_fp: 0.003885, loss_freq: 0.014100
[03:33:57.130] iteration 6223: loss: 0.106395, loss_s1: 0.033843, loss_fp: 0.000954, loss_freq: 0.044033
[03:33:57.757] iteration 6224: loss: 0.119652, loss_s1: 0.041120, loss_fp: 0.000555, loss_freq: 0.062937
[03:33:58.400] iteration 6225: loss: 0.088630, loss_s1: 0.041624, loss_fp: 0.008922, loss_freq: 0.039227
[03:33:58.998] iteration 6226: loss: 0.074631, loss_s1: 0.043910, loss_fp: 0.002982, loss_freq: 0.026303
[03:33:59.602] iteration 6227: loss: 0.117210, loss_s1: 0.086750, loss_fp: 0.003627, loss_freq: 0.049832
[03:34:00.206] iteration 6228: loss: 0.056837, loss_s1: 0.027811, loss_fp: 0.002686, loss_freq: 0.021641
[03:34:00.809] iteration 6229: loss: 0.167278, loss_s1: 0.105047, loss_fp: 0.003930, loss_freq: 0.117908
[03:34:01.407] iteration 6230: loss: 0.096320, loss_s1: 0.072728, loss_fp: 0.003674, loss_freq: 0.044017
[03:34:02.001] iteration 6231: loss: 0.107614, loss_s1: 0.063014, loss_fp: 0.002272, loss_freq: 0.048721
[03:34:02.599] iteration 6232: loss: 0.134379, loss_s1: 0.092947, loss_fp: 0.001467, loss_freq: 0.033623
[03:34:03.195] iteration 6233: loss: 0.074447, loss_s1: 0.037099, loss_fp: 0.002985, loss_freq: 0.023962
[03:34:03.791] iteration 6234: loss: 0.102788, loss_s1: 0.067769, loss_fp: 0.004323, loss_freq: 0.032213
[03:34:04.389] iteration 6235: loss: 0.135590, loss_s1: 0.109903, loss_fp: 0.001943, loss_freq: 0.055916
[03:34:04.985] iteration 6236: loss: 0.128974, loss_s1: 0.069912, loss_fp: 0.005145, loss_freq: 0.069733
[03:34:05.580] iteration 6237: loss: 0.131464, loss_s1: 0.107183, loss_fp: 0.002393, loss_freq: 0.059247
[03:34:06.176] iteration 6238: loss: 0.099205, loss_s1: 0.063548, loss_fp: 0.002078, loss_freq: 0.027666
[03:34:06.779] iteration 6239: loss: 0.098051, loss_s1: 0.065946, loss_fp: 0.001749, loss_freq: 0.066476
[03:34:07.380] iteration 6240: loss: 0.083089, loss_s1: 0.031007, loss_fp: 0.000529, loss_freq: 0.023977
[03:34:07.972] iteration 6241: loss: 0.063999, loss_s1: 0.049296, loss_fp: 0.000451, loss_freq: 0.016968
[03:34:08.568] iteration 6242: loss: 0.119614, loss_s1: 0.142238, loss_fp: 0.001374, loss_freq: 0.022242
[03:34:09.175] iteration 6243: loss: 0.083640, loss_s1: 0.050179, loss_fp: 0.015486, loss_freq: 0.028675
[03:34:09.773] iteration 6244: loss: 0.113108, loss_s1: 0.126504, loss_fp: 0.004261, loss_freq: 0.027446
[03:34:10.369] iteration 6245: loss: 0.109666, loss_s1: 0.103011, loss_fp: 0.005409, loss_freq: 0.024029
[03:34:10.960] iteration 6246: loss: 0.129381, loss_s1: 0.136134, loss_fp: 0.016023, loss_freq: 0.036923
[03:34:11.556] iteration 6247: loss: 0.141176, loss_s1: 0.088824, loss_fp: 0.000531, loss_freq: 0.127630
[03:34:12.151] iteration 6248: loss: 0.121126, loss_s1: 0.059106, loss_fp: 0.002987, loss_freq: 0.056676
[03:34:12.742] iteration 6249: loss: 0.085997, loss_s1: 0.079185, loss_fp: 0.001827, loss_freq: 0.014981
[03:34:13.335] iteration 6250: loss: 0.131115, loss_s1: 0.087561, loss_fp: 0.005357, loss_freq: 0.087415
[03:34:13.931] iteration 6251: loss: 0.120987, loss_s1: 0.099192, loss_fp: 0.001576, loss_freq: 0.012756
[03:34:14.796] iteration 6252: loss: 0.167733, loss_s1: 0.055425, loss_fp: 0.002085, loss_freq: 0.017517
[03:34:15.608] iteration 6253: loss: 0.110723, loss_s1: 0.076144, loss_fp: 0.026699, loss_freq: 0.025260
[03:34:16.337] iteration 6254: loss: 0.143527, loss_s1: 0.107607, loss_fp: 0.002237, loss_freq: 0.061920
[03:34:16.979] iteration 6255: loss: 0.166595, loss_s1: 0.143030, loss_fp: 0.006612, loss_freq: 0.105303
[03:34:17.573] iteration 6256: loss: 0.076368, loss_s1: 0.045943, loss_fp: 0.001221, loss_freq: 0.032396
[03:34:18.161] iteration 6257: loss: 0.132338, loss_s1: 0.061203, loss_fp: 0.007011, loss_freq: 0.013729
[03:34:18.753] iteration 6258: loss: 0.087858, loss_s1: 0.077485, loss_fp: 0.001048, loss_freq: 0.024732
[03:34:19.348] iteration 6259: loss: 0.190244, loss_s1: 0.181314, loss_fp: 0.013398, loss_freq: 0.090720
[03:34:19.945] iteration 6260: loss: 0.098578, loss_s1: 0.069955, loss_fp: 0.004314, loss_freq: 0.019462
[03:34:20.536] iteration 6261: loss: 0.160363, loss_s1: 0.126145, loss_fp: 0.002224, loss_freq: 0.069587
[03:34:21.127] iteration 6262: loss: 0.100271, loss_s1: 0.087834, loss_fp: 0.002990, loss_freq: 0.031230
[03:34:21.718] iteration 6263: loss: 0.073432, loss_s1: 0.035577, loss_fp: 0.003517, loss_freq: 0.037766
[03:34:22.304] iteration 6264: loss: 0.070970, loss_s1: 0.035806, loss_fp: 0.001687, loss_freq: 0.017385
[03:34:22.925] iteration 6265: loss: 0.063169, loss_s1: 0.033419, loss_fp: 0.006830, loss_freq: 0.016837
[03:34:23.535] iteration 6266: loss: 0.092977, loss_s1: 0.080044, loss_fp: 0.001054, loss_freq: 0.027587
[03:34:24.130] iteration 6267: loss: 0.082355, loss_s1: 0.062141, loss_fp: 0.006072, loss_freq: 0.027948
[03:34:24.720] iteration 6268: loss: 0.141626, loss_s1: 0.110944, loss_fp: 0.022091, loss_freq: 0.058444
[03:34:25.316] iteration 6269: loss: 0.118938, loss_s1: 0.070301, loss_fp: 0.002225, loss_freq: 0.038993
[03:34:25.907] iteration 6270: loss: 0.090226, loss_s1: 0.051837, loss_fp: 0.002783, loss_freq: 0.030649
[03:34:26.493] iteration 6271: loss: 0.071798, loss_s1: 0.032336, loss_fp: 0.001999, loss_freq: 0.023139
[03:34:27.078] iteration 6272: loss: 0.130693, loss_s1: 0.085192, loss_fp: 0.002302, loss_freq: 0.102250
[03:34:27.663] iteration 6273: loss: 0.090119, loss_s1: 0.032894, loss_fp: 0.007700, loss_freq: 0.045898
[03:34:28.256] iteration 6274: loss: 0.090311, loss_s1: 0.064082, loss_fp: 0.003857, loss_freq: 0.016140
[03:34:28.847] iteration 6275: loss: 0.214307, loss_s1: 0.172986, loss_fp: 0.005936, loss_freq: 0.052515
[03:34:29.445] iteration 6276: loss: 0.091530, loss_s1: 0.043630, loss_fp: 0.001339, loss_freq: 0.068294
[03:34:30.041] iteration 6277: loss: 0.083729, loss_s1: 0.057156, loss_fp: 0.007448, loss_freq: 0.021613
[03:34:30.633] iteration 6278: loss: 0.090995, loss_s1: 0.039157, loss_fp: 0.003835, loss_freq: 0.032115
[03:34:31.231] iteration 6279: loss: 0.073383, loss_s1: 0.031299, loss_fp: 0.002565, loss_freq: 0.033305
[03:34:31.828] iteration 6280: loss: 0.098638, loss_s1: 0.077186, loss_fp: 0.001710, loss_freq: 0.018423
[03:34:32.422] iteration 6281: loss: 0.070278, loss_s1: 0.043034, loss_fp: 0.003847, loss_freq: 0.016076
[03:34:33.015] iteration 6282: loss: 0.069355, loss_s1: 0.044728, loss_fp: 0.004539, loss_freq: 0.024301
[03:34:33.608] iteration 6283: loss: 0.088768, loss_s1: 0.034073, loss_fp: 0.003821, loss_freq: 0.041975
[03:34:34.198] iteration 6284: loss: 0.084183, loss_s1: 0.056427, loss_fp: 0.003062, loss_freq: 0.037191
[03:34:34.788] iteration 6285: loss: 0.058550, loss_s1: 0.029667, loss_fp: 0.001118, loss_freq: 0.030963
[03:34:35.386] iteration 6286: loss: 0.118542, loss_s1: 0.042334, loss_fp: 0.011087, loss_freq: 0.061122
[03:34:35.979] iteration 6287: loss: 0.119610, loss_s1: 0.067160, loss_fp: 0.000645, loss_freq: 0.059557
[03:34:36.572] iteration 6288: loss: 0.111838, loss_s1: 0.118186, loss_fp: 0.000706, loss_freq: 0.009889
[03:34:37.164] iteration 6289: loss: 0.110950, loss_s1: 0.080129, loss_fp: 0.003155, loss_freq: 0.042752
[03:34:37.752] iteration 6290: loss: 0.120741, loss_s1: 0.106181, loss_fp: 0.004458, loss_freq: 0.067311
[03:34:38.682] iteration 6291: loss: 0.076555, loss_s1: 0.045836, loss_fp: 0.007134, loss_freq: 0.011207
[03:34:39.329] iteration 6292: loss: 0.090808, loss_s1: 0.057787, loss_fp: 0.000805, loss_freq: 0.027366
[03:34:39.966] iteration 6293: loss: 0.108665, loss_s1: 0.025467, loss_fp: 0.001826, loss_freq: 0.038051
[03:34:40.605] iteration 6294: loss: 0.102800, loss_s1: 0.074150, loss_fp: 0.000921, loss_freq: 0.050686
[03:34:41.241] iteration 6295: loss: 0.122508, loss_s1: 0.087505, loss_fp: 0.004213, loss_freq: 0.054717
[03:34:41.832] iteration 6296: loss: 0.147533, loss_s1: 0.114196, loss_fp: 0.004141, loss_freq: 0.069271
[03:34:42.425] iteration 6297: loss: 0.139772, loss_s1: 0.133708, loss_fp: 0.001940, loss_freq: 0.041767
[03:34:43.023] iteration 6298: loss: 0.064661, loss_s1: 0.032733, loss_fp: 0.000667, loss_freq: 0.017931
[03:34:43.619] iteration 6299: loss: 0.105530, loss_s1: 0.049828, loss_fp: 0.003370, loss_freq: 0.062090
[03:34:44.212] iteration 6300: loss: 0.114047, loss_s1: 0.079922, loss_fp: 0.007741, loss_freq: 0.026699
[03:34:44.809] iteration 6301: loss: 0.123867, loss_s1: 0.072743, loss_fp: 0.002793, loss_freq: 0.057089
[03:34:45.406] iteration 6302: loss: 0.120605, loss_s1: 0.074048, loss_fp: 0.002962, loss_freq: 0.106947
[03:34:46.000] iteration 6303: loss: 0.087720, loss_s1: 0.031354, loss_fp: 0.002127, loss_freq: 0.037793
[03:34:46.599] iteration 6304: loss: 0.078959, loss_s1: 0.055854, loss_fp: 0.003445, loss_freq: 0.017560
[03:34:47.189] iteration 6305: loss: 0.151694, loss_s1: 0.058694, loss_fp: 0.000694, loss_freq: 0.047170
[03:34:47.786] iteration 6306: loss: 0.106647, loss_s1: 0.079225, loss_fp: 0.006127, loss_freq: 0.029243
[03:34:48.387] iteration 6307: loss: 0.153867, loss_s1: 0.122743, loss_fp: 0.005163, loss_freq: 0.037224
[03:34:48.983] iteration 6308: loss: 0.077057, loss_s1: 0.042054, loss_fp: 0.003175, loss_freq: 0.013628
[03:34:49.580] iteration 6309: loss: 0.097767, loss_s1: 0.097107, loss_fp: 0.003068, loss_freq: 0.040747
[03:34:50.176] iteration 6310: loss: 0.098316, loss_s1: 0.074011, loss_fp: 0.001443, loss_freq: 0.020486
[03:34:50.770] iteration 6311: loss: 0.130322, loss_s1: 0.069537, loss_fp: 0.003077, loss_freq: 0.023364
[03:34:51.362] iteration 6312: loss: 0.129337, loss_s1: 0.115291, loss_fp: 0.009702, loss_freq: 0.045967
[03:34:51.956] iteration 6313: loss: 0.174857, loss_s1: 0.109965, loss_fp: 0.002666, loss_freq: 0.040055
[03:34:52.552] iteration 6314: loss: 0.086100, loss_s1: 0.026413, loss_fp: 0.004301, loss_freq: 0.018911
[03:34:53.143] iteration 6315: loss: 0.109185, loss_s1: 0.093580, loss_fp: 0.003138, loss_freq: 0.033334
[03:34:53.732] iteration 6316: loss: 0.142206, loss_s1: 0.146945, loss_fp: 0.010594, loss_freq: 0.047045
[03:34:54.326] iteration 6317: loss: 0.120184, loss_s1: 0.071525, loss_fp: 0.001886, loss_freq: 0.044989
[03:34:54.924] iteration 6318: loss: 0.195592, loss_s1: 0.171287, loss_fp: 0.006622, loss_freq: 0.093015
[03:34:55.520] iteration 6319: loss: 0.109449, loss_s1: 0.043303, loss_fp: 0.002924, loss_freq: 0.023155
[03:34:56.134] iteration 6320: loss: 0.104479, loss_s1: 0.090215, loss_fp: 0.003547, loss_freq: 0.048303
[03:34:56.732] iteration 6321: loss: 0.107450, loss_s1: 0.062972, loss_fp: 0.004409, loss_freq: 0.052579
[03:34:57.327] iteration 6322: loss: 0.141586, loss_s1: 0.098829, loss_fp: 0.000761, loss_freq: 0.032768
[03:34:57.926] iteration 6323: loss: 0.095468, loss_s1: 0.085520, loss_fp: 0.004126, loss_freq: 0.029396
[03:34:58.541] iteration 6324: loss: 0.072736, loss_s1: 0.039644, loss_fp: 0.001883, loss_freq: 0.033894
[03:34:59.152] iteration 6325: loss: 0.102626, loss_s1: 0.085906, loss_fp: 0.004796, loss_freq: 0.051042
[03:34:59.816] iteration 6326: loss: 0.083524, loss_s1: 0.025548, loss_fp: 0.000688, loss_freq: 0.023566
[03:35:00.548] iteration 6327: loss: 0.104644, loss_s1: 0.074407, loss_fp: 0.000672, loss_freq: 0.043271
[03:35:01.475] iteration 6328: loss: 0.093694, loss_s1: 0.049423, loss_fp: 0.001523, loss_freq: 0.027055
[03:35:02.421] iteration 6329: loss: 0.102370, loss_s1: 0.039095, loss_fp: 0.001880, loss_freq: 0.065545
[03:35:03.360] iteration 6330: loss: 0.072331, loss_s1: 0.055461, loss_fp: 0.000774, loss_freq: 0.010383
[03:35:04.296] iteration 6331: loss: 0.123163, loss_s1: 0.129339, loss_fp: 0.000821, loss_freq: 0.033618
[03:35:05.229] iteration 6332: loss: 0.116079, loss_s1: 0.082858, loss_fp: 0.009565, loss_freq: 0.063571
[03:35:06.168] iteration 6333: loss: 0.122892, loss_s1: 0.119280, loss_fp: 0.003025, loss_freq: 0.040944
[03:35:07.102] iteration 6334: loss: 0.164969, loss_s1: 0.135505, loss_fp: 0.002982, loss_freq: 0.089425
[03:35:08.034] iteration 6335: loss: 0.080225, loss_s1: 0.063708, loss_fp: 0.001620, loss_freq: 0.011923
[03:35:08.936] iteration 6336: loss: 0.080630, loss_s1: 0.035808, loss_fp: 0.010817, loss_freq: 0.020617
[03:35:09.870] iteration 6337: loss: 0.109019, loss_s1: 0.086050, loss_fp: 0.004638, loss_freq: 0.020843
[03:35:10.614] iteration 6338: loss: 0.105840, loss_s1: 0.089646, loss_fp: 0.002619, loss_freq: 0.028914
[03:35:11.547] iteration 6339: loss: 0.082053, loss_s1: 0.036231, loss_fp: 0.002467, loss_freq: 0.023157
[03:35:12.480] iteration 6340: loss: 0.097556, loss_s1: 0.063022, loss_fp: 0.002081, loss_freq: 0.031393
[03:35:13.418] iteration 6341: loss: 0.079830, loss_s1: 0.048030, loss_fp: 0.012840, loss_freq: 0.023291
[03:35:14.338] iteration 6342: loss: 0.114393, loss_s1: 0.121242, loss_fp: 0.004954, loss_freq: 0.049040
[03:35:15.269] iteration 6343: loss: 0.118644, loss_s1: 0.085149, loss_fp: 0.000670, loss_freq: 0.056167
[03:35:16.206] iteration 6344: loss: 0.131963, loss_s1: 0.082051, loss_fp: 0.012711, loss_freq: 0.044650
[03:35:16.845] iteration 6345: loss: 0.132458, loss_s1: 0.060273, loss_fp: 0.001246, loss_freq: 0.063585
[03:35:17.536] iteration 6346: loss: 0.090112, loss_s1: 0.077939, loss_fp: 0.000671, loss_freq: 0.016211
[03:35:18.125] iteration 6347: loss: 0.089701, loss_s1: 0.073911, loss_fp: 0.003017, loss_freq: 0.042700
[03:35:18.718] iteration 6348: loss: 0.114847, loss_s1: 0.049143, loss_fp: 0.001734, loss_freq: 0.029936
[03:35:19.311] iteration 6349: loss: 0.177904, loss_s1: 0.088084, loss_fp: 0.003956, loss_freq: 0.041850
[03:35:19.905] iteration 6350: loss: 0.124111, loss_s1: 0.076733, loss_fp: 0.002349, loss_freq: 0.093707
[03:35:20.501] iteration 6351: loss: 0.086905, loss_s1: 0.076885, loss_fp: 0.001751, loss_freq: 0.030220
[03:35:21.096] iteration 6352: loss: 0.161661, loss_s1: 0.060309, loss_fp: 0.000909, loss_freq: 0.063822
[03:35:21.687] iteration 6353: loss: 0.115682, loss_s1: 0.097419, loss_fp: 0.005961, loss_freq: 0.038476
[03:35:22.279] iteration 6354: loss: 0.094554, loss_s1: 0.043603, loss_fp: 0.004376, loss_freq: 0.031874
[03:35:22.873] iteration 6355: loss: 0.071582, loss_s1: 0.035677, loss_fp: 0.003415, loss_freq: 0.030953
[03:35:23.462] iteration 6356: loss: 0.112924, loss_s1: 0.084923, loss_fp: 0.002159, loss_freq: 0.029872
[03:35:24.056] iteration 6357: loss: 0.098163, loss_s1: 0.073532, loss_fp: 0.001219, loss_freq: 0.013388
[03:35:24.645] iteration 6358: loss: 0.136965, loss_s1: 0.128623, loss_fp: 0.000591, loss_freq: 0.048528
[03:35:25.229] iteration 6359: loss: 0.136840, loss_s1: 0.068235, loss_fp: 0.002726, loss_freq: 0.027391
[03:35:25.821] iteration 6360: loss: 0.106160, loss_s1: 0.067537, loss_fp: 0.001501, loss_freq: 0.022240
[03:35:26.413] iteration 6361: loss: 0.125100, loss_s1: 0.056877, loss_fp: 0.003418, loss_freq: 0.060163
[03:35:27.008] iteration 6362: loss: 0.095363, loss_s1: 0.046131, loss_fp: 0.002497, loss_freq: 0.020887
[03:35:27.600] iteration 6363: loss: 0.104509, loss_s1: 0.101596, loss_fp: 0.002190, loss_freq: 0.048697
[03:35:28.196] iteration 6364: loss: 0.116560, loss_s1: 0.109716, loss_fp: 0.001355, loss_freq: 0.022116
[03:35:28.783] iteration 6365: loss: 0.155129, loss_s1: 0.118432, loss_fp: 0.005568, loss_freq: 0.085068
[03:35:29.374] iteration 6366: loss: 0.096823, loss_s1: 0.067609, loss_fp: 0.001776, loss_freq: 0.011407
[03:35:29.966] iteration 6367: loss: 0.089482, loss_s1: 0.053594, loss_fp: 0.001592, loss_freq: 0.022229
[03:35:30.557] iteration 6368: loss: 0.117159, loss_s1: 0.109801, loss_fp: 0.019054, loss_freq: 0.042612
[03:35:31.148] iteration 6369: loss: 0.123958, loss_s1: 0.035469, loss_fp: 0.003803, loss_freq: 0.123214
[03:35:31.737] iteration 6370: loss: 0.101859, loss_s1: 0.090362, loss_fp: 0.003618, loss_freq: 0.020641
[03:35:32.333] iteration 6371: loss: 0.128579, loss_s1: 0.074976, loss_fp: 0.001765, loss_freq: 0.053584
[03:35:32.923] iteration 6372: loss: 0.088117, loss_s1: 0.055060, loss_fp: 0.007544, loss_freq: 0.016945
[03:35:33.512] iteration 6373: loss: 0.144843, loss_s1: 0.145382, loss_fp: 0.005335, loss_freq: 0.050544
[03:35:34.146] iteration 6374: loss: 0.114231, loss_s1: 0.105003, loss_fp: 0.012517, loss_freq: 0.014000
[03:35:34.786] iteration 6375: loss: 0.076085, loss_s1: 0.059611, loss_fp: 0.001801, loss_freq: 0.015121
[03:35:35.423] iteration 6376: loss: 0.074687, loss_s1: 0.066988, loss_fp: 0.002589, loss_freq: 0.021320
[03:35:36.034] iteration 6377: loss: 0.162840, loss_s1: 0.145648, loss_fp: 0.001723, loss_freq: 0.088680
[03:35:36.624] iteration 6378: loss: 0.119726, loss_s1: 0.069513, loss_fp: 0.002719, loss_freq: 0.048882
[03:35:37.221] iteration 6379: loss: 0.083632, loss_s1: 0.065024, loss_fp: 0.003213, loss_freq: 0.029544
[03:35:37.809] iteration 6380: loss: 0.092316, loss_s1: 0.052151, loss_fp: 0.004839, loss_freq: 0.011674
[03:35:38.400] iteration 6381: loss: 0.106905, loss_s1: 0.069076, loss_fp: 0.001881, loss_freq: 0.084579
[03:35:38.994] iteration 6382: loss: 0.156665, loss_s1: 0.129786, loss_fp: 0.002098, loss_freq: 0.055613
[03:35:39.584] iteration 6383: loss: 0.149854, loss_s1: 0.122771, loss_fp: 0.004153, loss_freq: 0.077173
[03:35:40.170] iteration 6384: loss: 0.080934, loss_s1: 0.028428, loss_fp: 0.001018, loss_freq: 0.014140
[03:35:40.795] iteration 6385: loss: 0.091837, loss_s1: 0.033233, loss_fp: 0.001016, loss_freq: 0.076269
[03:35:41.408] iteration 6386: loss: 0.096287, loss_s1: 0.102686, loss_fp: 0.002242, loss_freq: 0.037704
[03:35:41.996] iteration 6387: loss: 0.085431, loss_s1: 0.030807, loss_fp: 0.001221, loss_freq: 0.047715
[03:35:42.583] iteration 6388: loss: 0.091112, loss_s1: 0.062702, loss_fp: 0.001056, loss_freq: 0.047653
[03:35:43.168] iteration 6389: loss: 0.086926, loss_s1: 0.037323, loss_fp: 0.001428, loss_freq: 0.058521
[03:35:43.751] iteration 6390: loss: 0.066652, loss_s1: 0.026084, loss_fp: 0.004007, loss_freq: 0.024367
[03:35:44.338] iteration 6391: loss: 0.086680, loss_s1: 0.056824, loss_fp: 0.000389, loss_freq: 0.035433
[03:35:44.928] iteration 6392: loss: 0.114606, loss_s1: 0.051479, loss_fp: 0.001343, loss_freq: 0.019191
[03:35:45.519] iteration 6393: loss: 0.064630, loss_s1: 0.039310, loss_fp: 0.001857, loss_freq: 0.031815
[03:35:46.112] iteration 6394: loss: 0.073215, loss_s1: 0.043201, loss_fp: 0.001396, loss_freq: 0.024228
[03:35:46.697] iteration 6395: loss: 0.079175, loss_s1: 0.025208, loss_fp: 0.002273, loss_freq: 0.050600
[03:35:47.286] iteration 6396: loss: 0.105137, loss_s1: 0.088980, loss_fp: 0.002566, loss_freq: 0.038121
[03:35:47.875] iteration 6397: loss: 0.089541, loss_s1: 0.055531, loss_fp: 0.007710, loss_freq: 0.038311
[03:35:48.466] iteration 6398: loss: 0.088611, loss_s1: 0.053689, loss_fp: 0.003525, loss_freq: 0.036514
[03:35:49.055] iteration 6399: loss: 0.133428, loss_s1: 0.086414, loss_fp: 0.009460, loss_freq: 0.084659
[03:35:49.656] iteration 6400: loss: 0.097145, loss_s1: 0.080076, loss_fp: 0.002953, loss_freq: 0.022079
[03:35:53.243] iteration 6400 : mean_dice : 0.655883
[03:35:53.890] iteration 6401: loss: 0.113402, loss_s1: 0.075700, loss_fp: 0.001638, loss_freq: 0.057980
[03:35:54.480] iteration 6402: loss: 0.087303, loss_s1: 0.060170, loss_fp: 0.004332, loss_freq: 0.033730
[03:35:55.067] iteration 6403: loss: 0.076826, loss_s1: 0.052545, loss_fp: 0.003152, loss_freq: 0.030396
[03:35:55.654] iteration 6404: loss: 0.077291, loss_s1: 0.050126, loss_fp: 0.003622, loss_freq: 0.039874
[03:35:56.242] iteration 6405: loss: 0.094052, loss_s1: 0.041043, loss_fp: 0.007608, loss_freq: 0.056110
[03:35:56.832] iteration 6406: loss: 0.103913, loss_s1: 0.069333, loss_fp: 0.004234, loss_freq: 0.043229
[03:35:57.416] iteration 6407: loss: 0.091377, loss_s1: 0.065682, loss_fp: 0.007224, loss_freq: 0.025246
[03:35:58.004] iteration 6408: loss: 0.123193, loss_s1: 0.068529, loss_fp: 0.003930, loss_freq: 0.051453
[03:35:58.584] iteration 6409: loss: 0.132806, loss_s1: 0.047437, loss_fp: 0.006824, loss_freq: 0.141652
[03:35:59.172] iteration 6410: loss: 0.121181, loss_s1: 0.040614, loss_fp: 0.002375, loss_freq: 0.020993
[03:35:59.758] iteration 6411: loss: 0.050320, loss_s1: 0.014513, loss_fp: 0.002273, loss_freq: 0.009040
[03:36:00.341] iteration 6412: loss: 0.081311, loss_s1: 0.050079, loss_fp: 0.006545, loss_freq: 0.038028
[03:36:00.928] iteration 6413: loss: 0.145387, loss_s1: 0.103914, loss_fp: 0.033531, loss_freq: 0.075409
[03:36:01.513] iteration 6414: loss: 0.132480, loss_s1: 0.065442, loss_fp: 0.072552, loss_freq: 0.061556
[03:36:02.097] iteration 6415: loss: 0.073561, loss_s1: 0.021742, loss_fp: 0.003569, loss_freq: 0.037210
[03:36:02.684] iteration 6416: loss: 0.109970, loss_s1: 0.080838, loss_fp: 0.004379, loss_freq: 0.020570
[03:36:03.269] iteration 6417: loss: 0.109525, loss_s1: 0.063802, loss_fp: 0.003486, loss_freq: 0.074875
[03:36:03.850] iteration 6418: loss: 0.195181, loss_s1: 0.057117, loss_fp: 0.005106, loss_freq: 0.146194
[03:36:04.434] iteration 6419: loss: 0.097313, loss_s1: 0.080729, loss_fp: 0.003261, loss_freq: 0.021480
[03:36:05.023] iteration 6420: loss: 0.132074, loss_s1: 0.114942, loss_fp: 0.011535, loss_freq: 0.034375
[03:36:05.605] iteration 6421: loss: 0.147755, loss_s1: 0.116149, loss_fp: 0.014051, loss_freq: 0.088016
[03:36:06.193] iteration 6422: loss: 0.074460, loss_s1: 0.026171, loss_fp: 0.001341, loss_freq: 0.015044
[03:36:06.776] iteration 6423: loss: 0.113947, loss_s1: 0.100505, loss_fp: 0.001078, loss_freq: 0.056623
[03:36:07.365] iteration 6424: loss: 0.105101, loss_s1: 0.091136, loss_fp: 0.001410, loss_freq: 0.051479
[03:36:07.954] iteration 6425: loss: 0.122956, loss_s1: 0.077510, loss_fp: 0.001933, loss_freq: 0.099042
[03:36:08.540] iteration 6426: loss: 0.075448, loss_s1: 0.029183, loss_fp: 0.001575, loss_freq: 0.028030
[03:36:09.131] iteration 6427: loss: 0.165730, loss_s1: 0.099374, loss_fp: 0.001816, loss_freq: 0.017300
[03:36:09.721] iteration 6428: loss: 0.085763, loss_s1: 0.075343, loss_fp: 0.002832, loss_freq: 0.023498
[03:36:10.304] iteration 6429: loss: 0.177025, loss_s1: 0.165502, loss_fp: 0.016956, loss_freq: 0.077981
[03:36:10.896] iteration 6430: loss: 0.117050, loss_s1: 0.120511, loss_fp: 0.001170, loss_freq: 0.052957
[03:36:11.487] iteration 6431: loss: 0.133387, loss_s1: 0.147825, loss_fp: 0.002460, loss_freq: 0.012669
[03:36:12.076] iteration 6432: loss: 0.072414, loss_s1: 0.045625, loss_fp: 0.001826, loss_freq: 0.017287
[03:36:12.666] iteration 6433: loss: 0.121321, loss_s1: 0.091274, loss_fp: 0.006481, loss_freq: 0.071350
[03:36:13.245] iteration 6434: loss: 0.112275, loss_s1: 0.065308, loss_fp: 0.004683, loss_freq: 0.011473
[03:36:13.833] iteration 6435: loss: 0.073731, loss_s1: 0.048913, loss_fp: 0.006214, loss_freq: 0.010953
[03:36:14.414] iteration 6436: loss: 0.114337, loss_s1: 0.077166, loss_fp: 0.002507, loss_freq: 0.055829
[03:36:15.000] iteration 6437: loss: 0.090249, loss_s1: 0.089744, loss_fp: 0.009631, loss_freq: 0.023457
[03:36:15.579] iteration 6438: loss: 0.131917, loss_s1: 0.149929, loss_fp: 0.002622, loss_freq: 0.041500
[03:36:16.164] iteration 6439: loss: 0.078998, loss_s1: 0.061849, loss_fp: 0.001155, loss_freq: 0.033686
[03:36:16.745] iteration 6440: loss: 0.093803, loss_s1: 0.072004, loss_fp: 0.001500, loss_freq: 0.025540
[03:36:17.330] iteration 6441: loss: 0.097607, loss_s1: 0.058897, loss_fp: 0.002015, loss_freq: 0.027433
[03:36:17.919] iteration 6442: loss: 0.083409, loss_s1: 0.049346, loss_fp: 0.000531, loss_freq: 0.043245
[03:36:18.505] iteration 6443: loss: 0.193621, loss_s1: 0.170732, loss_fp: 0.021738, loss_freq: 0.111970
[03:36:19.096] iteration 6444: loss: 0.117869, loss_s1: 0.043124, loss_fp: 0.002891, loss_freq: 0.039827
[03:36:19.681] iteration 6445: loss: 0.137352, loss_s1: 0.057517, loss_fp: 0.018109, loss_freq: 0.076068
[03:36:20.272] iteration 6446: loss: 0.095828, loss_s1: 0.071759, loss_fp: 0.005529, loss_freq: 0.028089
[03:36:20.863] iteration 6447: loss: 0.066441, loss_s1: 0.040269, loss_fp: 0.000891, loss_freq: 0.025719
[03:36:21.457] iteration 6448: loss: 0.112307, loss_s1: 0.072715, loss_fp: 0.004223, loss_freq: 0.053952
[03:36:22.044] iteration 6449: loss: 0.090023, loss_s1: 0.042942, loss_fp: 0.018229, loss_freq: 0.046759
[03:36:22.629] iteration 6450: loss: 0.099256, loss_s1: 0.062147, loss_fp: 0.003616, loss_freq: 0.043708
[03:36:23.214] iteration 6451: loss: 0.128067, loss_s1: 0.149223, loss_fp: 0.000854, loss_freq: 0.022756
[03:36:23.793] iteration 6452: loss: 0.098292, loss_s1: 0.062166, loss_fp: 0.007706, loss_freq: 0.047173
[03:36:24.425] iteration 6453: loss: 0.092458, loss_s1: 0.062039, loss_fp: 0.000568, loss_freq: 0.028190
[03:36:25.055] iteration 6454: loss: 0.102475, loss_s1: 0.067197, loss_fp: 0.001055, loss_freq: 0.019409
[03:36:25.690] iteration 6455: loss: 0.091180, loss_s1: 0.033488, loss_fp: 0.001414, loss_freq: 0.031552
[03:36:26.285] iteration 6456: loss: 0.134960, loss_s1: 0.104405, loss_fp: 0.003374, loss_freq: 0.053113
[03:36:26.874] iteration 6457: loss: 0.097312, loss_s1: 0.064884, loss_fp: 0.005516, loss_freq: 0.031388
[03:36:27.464] iteration 6458: loss: 0.123365, loss_s1: 0.098440, loss_fp: 0.002528, loss_freq: 0.061462
[03:36:28.047] iteration 6459: loss: 0.080695, loss_s1: 0.019850, loss_fp: 0.010451, loss_freq: 0.059176
[03:36:28.632] iteration 6460: loss: 0.098607, loss_s1: 0.066029, loss_fp: 0.001900, loss_freq: 0.057700
[03:36:29.536] iteration 6461: loss: 0.070604, loss_s1: 0.035267, loss_fp: 0.000896, loss_freq: 0.014577
[03:36:30.125] iteration 6462: loss: 0.103072, loss_s1: 0.090254, loss_fp: 0.000338, loss_freq: 0.052051
[03:36:30.716] iteration 6463: loss: 0.101089, loss_s1: 0.092727, loss_fp: 0.003538, loss_freq: 0.036139
[03:36:31.311] iteration 6464: loss: 0.109798, loss_s1: 0.113239, loss_fp: 0.000634, loss_freq: 0.033569
[03:36:31.901] iteration 6465: loss: 0.063752, loss_s1: 0.029422, loss_fp: 0.009741, loss_freq: 0.010022
[03:36:32.495] iteration 6466: loss: 0.093439, loss_s1: 0.066356, loss_fp: 0.001088, loss_freq: 0.048713
[03:36:33.089] iteration 6467: loss: 0.085902, loss_s1: 0.064069, loss_fp: 0.002675, loss_freq: 0.047611
[03:36:33.678] iteration 6468: loss: 0.089118, loss_s1: 0.074585, loss_fp: 0.003353, loss_freq: 0.027544
[03:36:34.327] iteration 6469: loss: 0.083837, loss_s1: 0.065512, loss_fp: 0.002328, loss_freq: 0.042439
[03:36:34.968] iteration 6470: loss: 0.138626, loss_s1: 0.091890, loss_fp: 0.015080, loss_freq: 0.074072
[03:36:35.607] iteration 6471: loss: 0.131634, loss_s1: 0.039119, loss_fp: 0.003283, loss_freq: 0.094824
[03:36:36.220] iteration 6472: loss: 0.140698, loss_s1: 0.094880, loss_fp: 0.000482, loss_freq: 0.070720
[03:36:36.827] iteration 6473: loss: 0.081692, loss_s1: 0.038410, loss_fp: 0.003981, loss_freq: 0.032503
[03:36:37.468] iteration 6474: loss: 0.114261, loss_s1: 0.099024, loss_fp: 0.003052, loss_freq: 0.041172
[03:36:38.108] iteration 6475: loss: 0.090433, loss_s1: 0.041624, loss_fp: 0.001404, loss_freq: 0.031100
[03:36:38.746] iteration 6476: loss: 0.128603, loss_s1: 0.109866, loss_fp: 0.005552, loss_freq: 0.046602
[03:36:39.368] iteration 6477: loss: 0.167821, loss_s1: 0.116149, loss_fp: 0.007624, loss_freq: 0.124069
[03:36:39.964] iteration 6478: loss: 0.078496, loss_s1: 0.041701, loss_fp: 0.003217, loss_freq: 0.017208
[03:36:40.561] iteration 6479: loss: 0.116873, loss_s1: 0.134827, loss_fp: 0.001822, loss_freq: 0.027141
[03:36:41.157] iteration 6480: loss: 0.158891, loss_s1: 0.132366, loss_fp: 0.003163, loss_freq: 0.027892
[03:36:41.756] iteration 6481: loss: 0.073969, loss_s1: 0.043401, loss_fp: 0.002731, loss_freq: 0.024212
[03:36:42.384] iteration 6482: loss: 0.099806, loss_s1: 0.079460, loss_fp: 0.007377, loss_freq: 0.046064
[03:36:42.986] iteration 6483: loss: 0.109225, loss_s1: 0.062091, loss_fp: 0.001719, loss_freq: 0.034430
[03:36:43.589] iteration 6484: loss: 0.109517, loss_s1: 0.069642, loss_fp: 0.007474, loss_freq: 0.037554
[03:36:44.186] iteration 6485: loss: 0.063268, loss_s1: 0.025642, loss_fp: 0.002639, loss_freq: 0.028486
[03:36:44.797] iteration 6486: loss: 0.097447, loss_s1: 0.065689, loss_fp: 0.004616, loss_freq: 0.041607
[03:36:45.411] iteration 6487: loss: 0.109282, loss_s1: 0.077979, loss_fp: 0.001184, loss_freq: 0.026438
[03:36:46.023] iteration 6488: loss: 0.172775, loss_s1: 0.157530, loss_fp: 0.005080, loss_freq: 0.052527
[03:36:46.622] iteration 6489: loss: 0.117809, loss_s1: 0.057323, loss_fp: 0.005830, loss_freq: 0.048085
[03:36:47.222] iteration 6490: loss: 0.090825, loss_s1: 0.060426, loss_fp: 0.001750, loss_freq: 0.044280
[03:36:47.815] iteration 6491: loss: 0.118871, loss_s1: 0.102560, loss_fp: 0.005208, loss_freq: 0.051129
[03:36:48.414] iteration 6492: loss: 0.091581, loss_s1: 0.045441, loss_fp: 0.002791, loss_freq: 0.039220
[03:36:49.009] iteration 6493: loss: 0.114771, loss_s1: 0.062042, loss_fp: 0.001221, loss_freq: 0.026532
[03:36:49.607] iteration 6494: loss: 0.090751, loss_s1: 0.060668, loss_fp: 0.003775, loss_freq: 0.044361
[03:36:50.202] iteration 6495: loss: 0.079054, loss_s1: 0.048483, loss_fp: 0.001195, loss_freq: 0.052198
[03:36:50.806] iteration 6496: loss: 0.076985, loss_s1: 0.039803, loss_fp: 0.002857, loss_freq: 0.029737
[03:36:51.397] iteration 6497: loss: 0.085695, loss_s1: 0.043142, loss_fp: 0.000837, loss_freq: 0.045946
[03:36:51.994] iteration 6498: loss: 0.106232, loss_s1: 0.124040, loss_fp: 0.001552, loss_freq: 0.017918
[03:36:52.588] iteration 6499: loss: 0.157243, loss_s1: 0.167529, loss_fp: 0.009519, loss_freq: 0.046257
[03:36:53.182] iteration 6500: loss: 0.079955, loss_s1: 0.047546, loss_fp: 0.003663, loss_freq: 0.029594
[03:36:53.780] iteration 6501: loss: 0.094592, loss_s1: 0.082876, loss_fp: 0.000331, loss_freq: 0.038460
[03:36:54.381] iteration 6502: loss: 0.126866, loss_s1: 0.123835, loss_fp: 0.002252, loss_freq: 0.059469
[03:36:54.981] iteration 6503: loss: 0.151443, loss_s1: 0.175842, loss_fp: 0.003756, loss_freq: 0.059410
[03:36:55.575] iteration 6504: loss: 0.147881, loss_s1: 0.178155, loss_fp: 0.004197, loss_freq: 0.047216
[03:36:56.172] iteration 6505: loss: 0.098376, loss_s1: 0.070610, loss_fp: 0.005426, loss_freq: 0.029722
[03:36:56.763] iteration 6506: loss: 0.130338, loss_s1: 0.124857, loss_fp: 0.000920, loss_freq: 0.034912
[03:36:57.357] iteration 6507: loss: 0.075593, loss_s1: 0.034037, loss_fp: 0.001702, loss_freq: 0.033062
[03:36:57.960] iteration 6508: loss: 0.099170, loss_s1: 0.059688, loss_fp: 0.003350, loss_freq: 0.032411
[03:36:58.555] iteration 6509: loss: 0.083601, loss_s1: 0.026631, loss_fp: 0.000984, loss_freq: 0.020454
[03:36:59.150] iteration 6510: loss: 0.075882, loss_s1: 0.048985, loss_fp: 0.002324, loss_freq: 0.020383
[03:36:59.742] iteration 6511: loss: 0.144255, loss_s1: 0.112806, loss_fp: 0.002539, loss_freq: 0.079950
[03:37:00.338] iteration 6512: loss: 0.109154, loss_s1: 0.077408, loss_fp: 0.000969, loss_freq: 0.065873
[03:37:00.943] iteration 6513: loss: 0.098334, loss_s1: 0.060682, loss_fp: 0.000934, loss_freq: 0.032934
[03:37:01.536] iteration 6514: loss: 0.176045, loss_s1: 0.137346, loss_fp: 0.010023, loss_freq: 0.083806
[03:37:02.130] iteration 6515: loss: 0.137118, loss_s1: 0.103100, loss_fp: 0.010759, loss_freq: 0.051664
[03:37:02.728] iteration 6516: loss: 0.093056, loss_s1: 0.055412, loss_fp: 0.001466, loss_freq: 0.045293
[03:37:03.328] iteration 6517: loss: 0.061668, loss_s1: 0.036505, loss_fp: 0.001481, loss_freq: 0.020672
[03:37:03.921] iteration 6518: loss: 0.124832, loss_s1: 0.034324, loss_fp: 0.001651, loss_freq: 0.040545
[03:37:04.511] iteration 6519: loss: 0.199559, loss_s1: 0.035067, loss_fp: 0.002982, loss_freq: 0.038961
[03:37:05.105] iteration 6520: loss: 0.116822, loss_s1: 0.047181, loss_fp: 0.002925, loss_freq: 0.070285
[03:37:05.698] iteration 6521: loss: 0.065488, loss_s1: 0.049933, loss_fp: 0.001036, loss_freq: 0.019372
[03:37:06.291] iteration 6522: loss: 0.101028, loss_s1: 0.050457, loss_fp: 0.001979, loss_freq: 0.056806
[03:37:06.877] iteration 6523: loss: 0.049658, loss_s1: 0.015383, loss_fp: 0.010917, loss_freq: 0.009909
[03:37:07.510] iteration 6524: loss: 0.102708, loss_s1: 0.075095, loss_fp: 0.002128, loss_freq: 0.037159
[03:37:08.106] iteration 6525: loss: 0.120286, loss_s1: 0.120643, loss_fp: 0.002097, loss_freq: 0.033802
[03:37:08.697] iteration 6526: loss: 0.090819, loss_s1: 0.080483, loss_fp: 0.002731, loss_freq: 0.025179
[03:37:09.284] iteration 6527: loss: 0.079877, loss_s1: 0.037572, loss_fp: 0.003189, loss_freq: 0.010746
[03:37:09.875] iteration 6528: loss: 0.179403, loss_s1: 0.223220, loss_fp: 0.004310, loss_freq: 0.040345
[03:37:10.470] iteration 6529: loss: 0.089788, loss_s1: 0.034235, loss_fp: 0.004629, loss_freq: 0.017851
[03:37:11.059] iteration 6530: loss: 0.078846, loss_s1: 0.053366, loss_fp: 0.006592, loss_freq: 0.036125
[03:37:11.651] iteration 6531: loss: 0.116607, loss_s1: 0.063601, loss_fp: 0.005878, loss_freq: 0.044012
[03:37:12.243] iteration 6532: loss: 0.123320, loss_s1: 0.095527, loss_fp: 0.007428, loss_freq: 0.055179
[03:37:12.836] iteration 6533: loss: 0.149554, loss_s1: 0.107868, loss_fp: 0.001727, loss_freq: 0.052948
[03:37:13.424] iteration 6534: loss: 0.136952, loss_s1: 0.106373, loss_fp: 0.002760, loss_freq: 0.054617
[03:37:14.017] iteration 6535: loss: 0.114754, loss_s1: 0.060245, loss_fp: 0.002081, loss_freq: 0.079637
[03:37:14.611] iteration 6536: loss: 0.093005, loss_s1: 0.049090, loss_fp: 0.000997, loss_freq: 0.034581
[03:37:15.213] iteration 6537: loss: 0.073301, loss_s1: 0.042616, loss_fp: 0.002673, loss_freq: 0.034274
[03:37:15.801] iteration 6538: loss: 0.108721, loss_s1: 0.068396, loss_fp: 0.007205, loss_freq: 0.051519
[03:37:16.389] iteration 6539: loss: 0.114444, loss_s1: 0.086333, loss_fp: 0.003322, loss_freq: 0.061410
[03:37:16.978] iteration 6540: loss: 0.090633, loss_s1: 0.053707, loss_fp: 0.005558, loss_freq: 0.024712
[03:37:17.570] iteration 6541: loss: 0.138479, loss_s1: 0.109497, loss_fp: 0.000632, loss_freq: 0.057652
[03:37:18.195] iteration 6542: loss: 0.072312, loss_s1: 0.053000, loss_fp: 0.002546, loss_freq: 0.024208
[03:37:18.831] iteration 6543: loss: 0.169327, loss_s1: 0.174363, loss_fp: 0.001489, loss_freq: 0.063711
[03:37:19.479] iteration 6544: loss: 0.084299, loss_s1: 0.069351, loss_fp: 0.008378, loss_freq: 0.010882
[03:37:20.087] iteration 6545: loss: 0.083890, loss_s1: 0.067087, loss_fp: 0.001100, loss_freq: 0.023042
[03:37:20.680] iteration 6546: loss: 0.065259, loss_s1: 0.038909, loss_fp: 0.004206, loss_freq: 0.022807
[03:37:21.277] iteration 6547: loss: 0.123062, loss_s1: 0.104368, loss_fp: 0.002554, loss_freq: 0.077379
[03:37:21.870] iteration 6548: loss: 0.128682, loss_s1: 0.126173, loss_fp: 0.001501, loss_freq: 0.038243
[03:37:22.467] iteration 6549: loss: 0.102985, loss_s1: 0.069230, loss_fp: 0.005523, loss_freq: 0.049736
[03:37:23.060] iteration 6550: loss: 0.090139, loss_s1: 0.084753, loss_fp: 0.003600, loss_freq: 0.019628
[03:37:23.666] iteration 6551: loss: 0.095587, loss_s1: 0.087479, loss_fp: 0.001304, loss_freq: 0.015040
[03:37:24.258] iteration 6552: loss: 0.164009, loss_s1: 0.183632, loss_fp: 0.017650, loss_freq: 0.053792
[03:37:24.861] iteration 6553: loss: 0.120091, loss_s1: 0.090636, loss_fp: 0.000939, loss_freq: 0.028176
[03:37:25.457] iteration 6554: loss: 0.092235, loss_s1: 0.069981, loss_fp: 0.001452, loss_freq: 0.011349
[03:37:26.059] iteration 6555: loss: 0.063007, loss_s1: 0.033668, loss_fp: 0.002558, loss_freq: 0.011349
[03:37:26.651] iteration 6556: loss: 0.097725, loss_s1: 0.098444, loss_fp: 0.004930, loss_freq: 0.040547
[03:37:27.245] iteration 6557: loss: 0.127615, loss_s1: 0.055368, loss_fp: 0.009030, loss_freq: 0.050382
[03:37:27.845] iteration 6558: loss: 0.110724, loss_s1: 0.069646, loss_fp: 0.009488, loss_freq: 0.049081
[03:37:28.439] iteration 6559: loss: 0.087374, loss_s1: 0.066712, loss_fp: 0.001305, loss_freq: 0.035954
[03:37:29.032] iteration 6560: loss: 0.067647, loss_s1: 0.024825, loss_fp: 0.000773, loss_freq: 0.022326
[03:37:29.626] iteration 6561: loss: 0.142744, loss_s1: 0.152219, loss_fp: 0.004225, loss_freq: 0.053118
[03:37:30.219] iteration 6562: loss: 0.097752, loss_s1: 0.048577, loss_fp: 0.003482, loss_freq: 0.032551
[03:37:30.814] iteration 6563: loss: 0.078432, loss_s1: 0.020380, loss_fp: 0.001950, loss_freq: 0.052289
[03:37:31.418] iteration 6564: loss: 0.085054, loss_s1: 0.041500, loss_fp: 0.002739, loss_freq: 0.033588
[03:37:32.012] iteration 6565: loss: 0.134694, loss_s1: 0.099864, loss_fp: 0.002934, loss_freq: 0.047552
[03:37:32.606] iteration 6566: loss: 0.105462, loss_s1: 0.060195, loss_fp: 0.005223, loss_freq: 0.048789
[03:37:33.199] iteration 6567: loss: 0.095985, loss_s1: 0.075718, loss_fp: 0.001701, loss_freq: 0.017825
[03:37:33.798] iteration 6568: loss: 0.127475, loss_s1: 0.081458, loss_fp: 0.009503, loss_freq: 0.050507
[03:37:34.394] iteration 6569: loss: 0.121402, loss_s1: 0.080946, loss_fp: 0.018047, loss_freq: 0.055052
[03:37:34.992] iteration 6570: loss: 0.095310, loss_s1: 0.049234, loss_fp: 0.003537, loss_freq: 0.039515
[03:37:35.594] iteration 6571: loss: 0.132722, loss_s1: 0.123423, loss_fp: 0.003761, loss_freq: 0.027289
[03:37:36.187] iteration 6572: loss: 0.097408, loss_s1: 0.038648, loss_fp: 0.003046, loss_freq: 0.032029
[03:37:36.774] iteration 6573: loss: 0.094731, loss_s1: 0.091166, loss_fp: 0.001568, loss_freq: 0.025228
[03:37:37.368] iteration 6574: loss: 0.094389, loss_s1: 0.055486, loss_fp: 0.010693, loss_freq: 0.043995
[03:37:37.968] iteration 6575: loss: 0.161973, loss_s1: 0.136320, loss_fp: 0.002462, loss_freq: 0.082018
[03:37:38.559] iteration 6576: loss: 0.080628, loss_s1: 0.040848, loss_fp: 0.004756, loss_freq: 0.033609
[03:37:39.164] iteration 6577: loss: 0.109128, loss_s1: 0.069400, loss_fp: 0.003671, loss_freq: 0.056847
[03:37:39.762] iteration 6578: loss: 0.076367, loss_s1: 0.033008, loss_fp: 0.005005, loss_freq: 0.041783
[03:37:40.368] iteration 6579: loss: 0.112187, loss_s1: 0.102558, loss_fp: 0.001120, loss_freq: 0.053268
[03:37:40.969] iteration 6580: loss: 0.129518, loss_s1: 0.086304, loss_fp: 0.004427, loss_freq: 0.041118
[03:37:41.580] iteration 6581: loss: 0.063566, loss_s1: 0.031581, loss_fp: 0.000920, loss_freq: 0.006573
[03:37:42.185] iteration 6582: loss: 0.103468, loss_s1: 0.096268, loss_fp: 0.000665, loss_freq: 0.048847
[03:37:42.788] iteration 6583: loss: 0.120047, loss_s1: 0.055580, loss_fp: 0.016392, loss_freq: 0.065262
[03:37:43.390] iteration 6584: loss: 0.099609, loss_s1: 0.091630, loss_fp: 0.001831, loss_freq: 0.037092
[03:37:43.983] iteration 6585: loss: 0.167701, loss_s1: 0.156901, loss_fp: 0.013490, loss_freq: 0.070685
[03:37:44.582] iteration 6586: loss: 0.109592, loss_s1: 0.092697, loss_fp: 0.014248, loss_freq: 0.018248
[03:37:45.171] iteration 6587: loss: 0.174602, loss_s1: 0.204624, loss_fp: 0.011554, loss_freq: 0.055430
[03:37:45.760] iteration 6588: loss: 0.166376, loss_s1: 0.039853, loss_fp: 0.006978, loss_freq: 0.157858
[03:37:46.405] iteration 6589: loss: 0.098561, loss_s1: 0.093355, loss_fp: 0.002426, loss_freq: 0.016899
[03:37:47.142] iteration 6590: loss: 0.155428, loss_s1: 0.126681, loss_fp: 0.017615, loss_freq: 0.083985
[03:37:47.834] iteration 6591: loss: 0.089794, loss_s1: 0.063083, loss_fp: 0.004605, loss_freq: 0.032990
[03:37:48.532] iteration 6592: loss: 0.165249, loss_s1: 0.085621, loss_fp: 0.006062, loss_freq: 0.063542
[03:37:49.276] iteration 6593: loss: 0.170277, loss_s1: 0.132273, loss_fp: 0.003524, loss_freq: 0.118426
[03:37:49.944] iteration 6594: loss: 0.117842, loss_s1: 0.095745, loss_fp: 0.001452, loss_freq: 0.063407
[03:37:50.551] iteration 6595: loss: 0.066430, loss_s1: 0.036087, loss_fp: 0.000955, loss_freq: 0.025384
[03:37:51.246] iteration 6596: loss: 0.106965, loss_s1: 0.038031, loss_fp: 0.009818, loss_freq: 0.047882
[03:37:51.922] iteration 6597: loss: 0.143968, loss_s1: 0.067222, loss_fp: 0.002481, loss_freq: 0.030806
[03:37:52.710] iteration 6598: loss: 0.082914, loss_s1: 0.058912, loss_fp: 0.003095, loss_freq: 0.033520
[03:37:53.346] iteration 6599: loss: 0.142496, loss_s1: 0.085254, loss_fp: 0.004408, loss_freq: 0.088829
[03:37:54.016] iteration 6600: loss: 0.136638, loss_s1: 0.128961, loss_fp: 0.002521, loss_freq: 0.050960
[03:37:58.191] iteration 6600 : mean_dice : 0.654514
[03:37:58.827] iteration 6601: loss: 0.124565, loss_s1: 0.109942, loss_fp: 0.006033, loss_freq: 0.038855
[03:37:59.418] iteration 6602: loss: 0.075216, loss_s1: 0.043422, loss_fp: 0.004008, loss_freq: 0.020108
[03:38:00.175] iteration 6603: loss: 0.124541, loss_s1: 0.072650, loss_fp: 0.001279, loss_freq: 0.042172
[03:38:00.790] iteration 6604: loss: 0.076537, loss_s1: 0.044809, loss_fp: 0.012766, loss_freq: 0.014262
[03:38:01.527] iteration 6605: loss: 0.095751, loss_s1: 0.056150, loss_fp: 0.016652, loss_freq: 0.041414
[03:38:02.225] iteration 6606: loss: 0.061391, loss_s1: 0.025423, loss_fp: 0.002367, loss_freq: 0.019360
[03:38:02.858] iteration 6607: loss: 0.105247, loss_s1: 0.070212, loss_fp: 0.001226, loss_freq: 0.029568
[03:38:03.583] iteration 6608: loss: 0.124264, loss_s1: 0.072452, loss_fp: 0.003178, loss_freq: 0.037368
[03:38:04.224] iteration 6609: loss: 0.136453, loss_s1: 0.096984, loss_fp: 0.004860, loss_freq: 0.045908
[03:38:04.848] iteration 6610: loss: 0.090616, loss_s1: 0.029734, loss_fp: 0.005139, loss_freq: 0.042496
[03:38:05.446] iteration 6611: loss: 0.121149, loss_s1: 0.099607, loss_fp: 0.003248, loss_freq: 0.028812
[03:38:06.034] iteration 6612: loss: 0.120605, loss_s1: 0.098552, loss_fp: 0.002455, loss_freq: 0.030657
[03:38:06.623] iteration 6613: loss: 0.159839, loss_s1: 0.115871, loss_fp: 0.004087, loss_freq: 0.063532
[03:38:07.209] iteration 6614: loss: 0.090398, loss_s1: 0.052556, loss_fp: 0.004779, loss_freq: 0.022759
[03:38:07.795] iteration 6615: loss: 0.182557, loss_s1: 0.082894, loss_fp: 0.002617, loss_freq: 0.051507
[03:38:08.387] iteration 6616: loss: 0.116141, loss_s1: 0.105189, loss_fp: 0.000751, loss_freq: 0.046193
[03:38:09.008] iteration 6617: loss: 0.095351, loss_s1: 0.054714, loss_fp: 0.003536, loss_freq: 0.028660
[03:38:09.593] iteration 6618: loss: 0.121499, loss_s1: 0.098100, loss_fp: 0.008167, loss_freq: 0.047668
[03:38:10.183] iteration 6619: loss: 0.080228, loss_s1: 0.060212, loss_fp: 0.003046, loss_freq: 0.036388
[03:38:10.777] iteration 6620: loss: 0.115318, loss_s1: 0.089662, loss_fp: 0.001997, loss_freq: 0.035480
[03:38:11.369] iteration 6621: loss: 0.091010, loss_s1: 0.094414, loss_fp: 0.001001, loss_freq: 0.019129
[03:38:11.963] iteration 6622: loss: 0.109616, loss_s1: 0.089093, loss_fp: 0.000878, loss_freq: 0.011100
[03:38:12.554] iteration 6623: loss: 0.106072, loss_s1: 0.043852, loss_fp: 0.002436, loss_freq: 0.033816
[03:38:13.142] iteration 6624: loss: 0.078959, loss_s1: 0.039421, loss_fp: 0.001176, loss_freq: 0.015570
[03:38:13.734] iteration 6625: loss: 0.061431, loss_s1: 0.056980, loss_fp: 0.000359, loss_freq: 0.009633
[03:38:14.323] iteration 6626: loss: 0.106829, loss_s1: 0.091762, loss_fp: 0.002420, loss_freq: 0.040633
[03:38:14.912] iteration 6627: loss: 0.135726, loss_s1: 0.104449, loss_fp: 0.000546, loss_freq: 0.058897
[03:38:15.501] iteration 6628: loss: 0.134231, loss_s1: 0.171107, loss_fp: 0.000813, loss_freq: 0.008511
[03:38:16.086] iteration 6629: loss: 0.118327, loss_s1: 0.073155, loss_fp: 0.004012, loss_freq: 0.070766
[03:38:16.671] iteration 6630: loss: 0.115492, loss_s1: 0.085927, loss_fp: 0.001368, loss_freq: 0.082488
[03:38:17.589] iteration 6631: loss: 0.098623, loss_s1: 0.069485, loss_fp: 0.001558, loss_freq: 0.039958
[03:38:18.177] iteration 6632: loss: 0.135191, loss_s1: 0.179632, loss_fp: 0.003521, loss_freq: 0.021259
[03:38:18.761] iteration 6633: loss: 0.109173, loss_s1: 0.103195, loss_fp: 0.002125, loss_freq: 0.046278
[03:38:19.353] iteration 6634: loss: 0.100344, loss_s1: 0.074618, loss_fp: 0.001813, loss_freq: 0.038355
[03:38:19.950] iteration 6635: loss: 0.121559, loss_s1: 0.071376, loss_fp: 0.000854, loss_freq: 0.046465
[03:38:20.543] iteration 6636: loss: 0.142059, loss_s1: 0.045977, loss_fp: 0.009857, loss_freq: 0.049693
[03:38:21.133] iteration 6637: loss: 0.120406, loss_s1: 0.053730, loss_fp: 0.003528, loss_freq: 0.051982
[03:38:21.724] iteration 6638: loss: 0.088423, loss_s1: 0.059896, loss_fp: 0.004220, loss_freq: 0.018459
[03:38:22.314] iteration 6639: loss: 0.104291, loss_s1: 0.044310, loss_fp: 0.001396, loss_freq: 0.025615
[03:38:22.920] iteration 6640: loss: 0.098460, loss_s1: 0.074977, loss_fp: 0.002965, loss_freq: 0.043722
[03:38:23.535] iteration 6641: loss: 0.095645, loss_s1: 0.029289, loss_fp: 0.001788, loss_freq: 0.055995
[03:38:24.452] iteration 6642: loss: 0.107726, loss_s1: 0.058612, loss_fp: 0.001445, loss_freq: 0.084442
[03:38:25.196] iteration 6643: loss: 0.085532, loss_s1: 0.060625, loss_fp: 0.008537, loss_freq: 0.027156
[03:38:25.783] iteration 6644: loss: 0.071427, loss_s1: 0.039225, loss_fp: 0.005504, loss_freq: 0.022548
[03:38:26.371] iteration 6645: loss: 0.116604, loss_s1: 0.102851, loss_fp: 0.002654, loss_freq: 0.030082
[03:38:26.956] iteration 6646: loss: 0.066515, loss_s1: 0.047890, loss_fp: 0.002248, loss_freq: 0.028481
[03:38:27.546] iteration 6647: loss: 0.134374, loss_s1: 0.053782, loss_fp: 0.001529, loss_freq: 0.127606
[03:38:28.135] iteration 6648: loss: 0.058701, loss_s1: 0.028493, loss_fp: 0.001538, loss_freq: 0.013807
[03:38:28.724] iteration 6649: loss: 0.106713, loss_s1: 0.133555, loss_fp: 0.003447, loss_freq: 0.014731
[03:38:29.311] iteration 6650: loss: 0.104555, loss_s1: 0.064304, loss_fp: 0.004112, loss_freq: 0.044409
[03:38:29.947] iteration 6651: loss: 0.070990, loss_s1: 0.033757, loss_fp: 0.004842, loss_freq: 0.029007
[03:38:30.569] iteration 6652: loss: 0.105607, loss_s1: 0.078138, loss_fp: 0.001699, loss_freq: 0.060501
[03:38:31.182] iteration 6653: loss: 0.128277, loss_s1: 0.088289, loss_fp: 0.012864, loss_freq: 0.026436
[03:38:31.839] iteration 6654: loss: 0.060385, loss_s1: 0.030824, loss_fp: 0.005288, loss_freq: 0.023847
[03:38:32.428] iteration 6655: loss: 0.076070, loss_s1: 0.033218, loss_fp: 0.000644, loss_freq: 0.032719
[03:38:33.015] iteration 6656: loss: 0.133879, loss_s1: 0.106253, loss_fp: 0.012871, loss_freq: 0.054860
[03:38:33.610] iteration 6657: loss: 0.078585, loss_s1: 0.060610, loss_fp: 0.000763, loss_freq: 0.019715
[03:38:34.196] iteration 6658: loss: 0.135504, loss_s1: 0.095004, loss_fp: 0.007263, loss_freq: 0.057128
[03:38:34.786] iteration 6659: loss: 0.108034, loss_s1: 0.046684, loss_fp: 0.001079, loss_freq: 0.054914
[03:38:35.381] iteration 6660: loss: 0.100806, loss_s1: 0.119421, loss_fp: 0.001685, loss_freq: 0.028360
[03:38:35.970] iteration 6661: loss: 0.113387, loss_s1: 0.105594, loss_fp: 0.004597, loss_freq: 0.052550
[03:38:36.556] iteration 6662: loss: 0.093722, loss_s1: 0.040200, loss_fp: 0.006439, loss_freq: 0.027519
[03:38:37.185] iteration 6663: loss: 0.111092, loss_s1: 0.115781, loss_fp: 0.001870, loss_freq: 0.040982
[03:38:37.811] iteration 6664: loss: 0.069746, loss_s1: 0.056061, loss_fp: 0.003577, loss_freq: 0.011177
[03:38:38.419] iteration 6665: loss: 0.067124, loss_s1: 0.045994, loss_fp: 0.002003, loss_freq: 0.026877
[03:38:39.008] iteration 6666: loss: 0.082699, loss_s1: 0.037542, loss_fp: 0.000949, loss_freq: 0.013936
[03:38:39.649] iteration 6667: loss: 0.102330, loss_s1: 0.092281, loss_fp: 0.002620, loss_freq: 0.030682
[03:38:40.281] iteration 6668: loss: 0.072330, loss_s1: 0.062663, loss_fp: 0.001722, loss_freq: 0.009732
[03:38:40.943] iteration 6669: loss: 0.149141, loss_s1: 0.138479, loss_fp: 0.006342, loss_freq: 0.054343
[03:38:41.534] iteration 6670: loss: 0.131651, loss_s1: 0.119657, loss_fp: 0.000839, loss_freq: 0.071611
[03:38:42.125] iteration 6671: loss: 0.104204, loss_s1: 0.055061, loss_fp: 0.003722, loss_freq: 0.051427
[03:38:42.750] iteration 6672: loss: 0.101330, loss_s1: 0.089882, loss_fp: 0.000926, loss_freq: 0.054206
[03:38:43.382] iteration 6673: loss: 0.121042, loss_s1: 0.091737, loss_fp: 0.007775, loss_freq: 0.077951
[03:38:44.005] iteration 6674: loss: 0.144947, loss_s1: 0.104736, loss_fp: 0.001987, loss_freq: 0.090961
[03:38:44.627] iteration 6675: loss: 0.132613, loss_s1: 0.053003, loss_fp: 0.002010, loss_freq: 0.016166
[03:38:45.273] iteration 6676: loss: 0.087898, loss_s1: 0.064462, loss_fp: 0.001285, loss_freq: 0.015451
[03:38:45.899] iteration 6677: loss: 0.059978, loss_s1: 0.037548, loss_fp: 0.003360, loss_freq: 0.017119
[03:38:46.486] iteration 6678: loss: 0.097636, loss_s1: 0.073014, loss_fp: 0.005180, loss_freq: 0.016380
[03:38:47.079] iteration 6679: loss: 0.074306, loss_s1: 0.038893, loss_fp: 0.001755, loss_freq: 0.017888
[03:38:47.672] iteration 6680: loss: 0.081752, loss_s1: 0.037830, loss_fp: 0.000988, loss_freq: 0.024871
[03:38:48.263] iteration 6681: loss: 0.137030, loss_s1: 0.113484, loss_fp: 0.001238, loss_freq: 0.054738
[03:38:48.896] iteration 6682: loss: 0.070630, loss_s1: 0.039783, loss_fp: 0.004335, loss_freq: 0.031187
[03:38:49.483] iteration 6683: loss: 0.079432, loss_s1: 0.020634, loss_fp: 0.001004, loss_freq: 0.034186
[03:38:50.069] iteration 6684: loss: 0.134861, loss_s1: 0.133577, loss_fp: 0.001723, loss_freq: 0.047144
[03:38:50.655] iteration 6685: loss: 0.082663, loss_s1: 0.014972, loss_fp: 0.003048, loss_freq: 0.047285
[03:38:51.242] iteration 6686: loss: 0.103766, loss_s1: 0.102717, loss_fp: 0.000584, loss_freq: 0.009845
[03:38:51.829] iteration 6687: loss: 0.060729, loss_s1: 0.035858, loss_fp: 0.002084, loss_freq: 0.014914
[03:38:52.424] iteration 6688: loss: 0.155109, loss_s1: 0.082466, loss_fp: 0.001365, loss_freq: 0.039550
[03:38:53.049] iteration 6689: loss: 0.131369, loss_s1: 0.121198, loss_fp: 0.001596, loss_freq: 0.050765
[03:38:53.636] iteration 6690: loss: 0.143422, loss_s1: 0.133137, loss_fp: 0.002886, loss_freq: 0.062054
[03:38:54.266] iteration 6691: loss: 0.067239, loss_s1: 0.054355, loss_fp: 0.003615, loss_freq: 0.030445
[03:38:54.901] iteration 6692: loss: 0.164926, loss_s1: 0.110804, loss_fp: 0.002344, loss_freq: 0.068571
[03:38:55.537] iteration 6693: loss: 0.075846, loss_s1: 0.066136, loss_fp: 0.002467, loss_freq: 0.014112
[03:38:56.167] iteration 6694: loss: 0.142832, loss_s1: 0.085830, loss_fp: 0.001322, loss_freq: 0.032985
[03:38:56.797] iteration 6695: loss: 0.109679, loss_s1: 0.076044, loss_fp: 0.002818, loss_freq: 0.047964
[03:38:57.424] iteration 6696: loss: 0.113029, loss_s1: 0.072581, loss_fp: 0.010618, loss_freq: 0.034954
[03:38:58.052] iteration 6697: loss: 0.083843, loss_s1: 0.057390, loss_fp: 0.003949, loss_freq: 0.010395
[03:38:58.685] iteration 6698: loss: 0.184907, loss_s1: 0.195094, loss_fp: 0.011718, loss_freq: 0.030305
[03:38:59.292] iteration 6699: loss: 0.080417, loss_s1: 0.069642, loss_fp: 0.001537, loss_freq: 0.014030
[03:38:59.893] iteration 6700: loss: 0.078078, loss_s1: 0.070705, loss_fp: 0.001615, loss_freq: 0.019407
[03:39:00.495] iteration 6701: loss: 0.109098, loss_s1: 0.076893, loss_fp: 0.007585, loss_freq: 0.040371
[03:39:01.092] iteration 6702: loss: 0.095763, loss_s1: 0.080231, loss_fp: 0.002646, loss_freq: 0.035945
[03:39:01.706] iteration 6703: loss: 0.120751, loss_s1: 0.111654, loss_fp: 0.012166, loss_freq: 0.043104
[03:39:02.302] iteration 6704: loss: 0.127583, loss_s1: 0.105597, loss_fp: 0.011427, loss_freq: 0.036439
[03:39:02.896] iteration 6705: loss: 0.107998, loss_s1: 0.078200, loss_fp: 0.012012, loss_freq: 0.038004
[03:39:03.528] iteration 6706: loss: 0.099242, loss_s1: 0.082030, loss_fp: 0.002223, loss_freq: 0.042589
[03:39:04.161] iteration 6707: loss: 0.095752, loss_s1: 0.065359, loss_fp: 0.000862, loss_freq: 0.031077
[03:39:04.792] iteration 6708: loss: 0.139684, loss_s1: 0.089145, loss_fp: 0.002555, loss_freq: 0.038957
[03:39:05.412] iteration 6709: loss: 0.110132, loss_s1: 0.078635, loss_fp: 0.002208, loss_freq: 0.041612
[03:39:06.011] iteration 6710: loss: 0.095276, loss_s1: 0.062642, loss_fp: 0.002519, loss_freq: 0.022868
[03:39:06.602] iteration 6711: loss: 0.158398, loss_s1: 0.091418, loss_fp: 0.001564, loss_freq: 0.108797
[03:39:07.215] iteration 6712: loss: 0.096669, loss_s1: 0.070522, loss_fp: 0.004882, loss_freq: 0.043873
[03:39:07.813] iteration 6713: loss: 0.169124, loss_s1: 0.190957, loss_fp: 0.001945, loss_freq: 0.052652
[03:39:08.410] iteration 6714: loss: 0.118275, loss_s1: 0.110703, loss_fp: 0.004826, loss_freq: 0.045964
[03:39:09.001] iteration 6715: loss: 0.083843, loss_s1: 0.047868, loss_fp: 0.001103, loss_freq: 0.016375
[03:39:09.593] iteration 6716: loss: 0.089414, loss_s1: 0.035253, loss_fp: 0.000800, loss_freq: 0.024259
[03:39:10.186] iteration 6717: loss: 0.125738, loss_s1: 0.146957, loss_fp: 0.001176, loss_freq: 0.057951
[03:39:10.787] iteration 6718: loss: 0.116652, loss_s1: 0.089052, loss_fp: 0.004301, loss_freq: 0.021446
[03:39:11.387] iteration 6719: loss: 0.108336, loss_s1: 0.101649, loss_fp: 0.001927, loss_freq: 0.040343
[03:39:11.974] iteration 6720: loss: 0.080949, loss_s1: 0.058213, loss_fp: 0.001017, loss_freq: 0.011394
[03:39:12.570] iteration 6721: loss: 0.061762, loss_s1: 0.040909, loss_fp: 0.002120, loss_freq: 0.018453
[03:39:13.165] iteration 6722: loss: 0.079831, loss_s1: 0.076434, loss_fp: 0.003286, loss_freq: 0.033857
[03:39:13.758] iteration 6723: loss: 0.102711, loss_s1: 0.076920, loss_fp: 0.003156, loss_freq: 0.048513
[03:39:14.348] iteration 6724: loss: 0.063645, loss_s1: 0.035871, loss_fp: 0.001094, loss_freq: 0.020199
[03:39:14.934] iteration 6725: loss: 0.118629, loss_s1: 0.108878, loss_fp: 0.004387, loss_freq: 0.038819
[03:39:15.587] iteration 6726: loss: 0.103623, loss_s1: 0.099909, loss_fp: 0.005614, loss_freq: 0.035282
[03:39:16.236] iteration 6727: loss: 0.140153, loss_s1: 0.071074, loss_fp: 0.003460, loss_freq: 0.081170
[03:39:16.871] iteration 6728: loss: 0.133589, loss_s1: 0.091653, loss_fp: 0.002127, loss_freq: 0.027116
[03:39:17.487] iteration 6729: loss: 0.134771, loss_s1: 0.080865, loss_fp: 0.001884, loss_freq: 0.070420
[03:39:18.082] iteration 6730: loss: 0.056628, loss_s1: 0.025424, loss_fp: 0.003126, loss_freq: 0.009723
[03:39:18.678] iteration 6731: loss: 0.097313, loss_s1: 0.067633, loss_fp: 0.001812, loss_freq: 0.057441
[03:39:19.305] iteration 6732: loss: 0.111100, loss_s1: 0.062464, loss_fp: 0.001501, loss_freq: 0.055260
[03:39:19.943] iteration 6733: loss: 0.073524, loss_s1: 0.065363, loss_fp: 0.000835, loss_freq: 0.024244
[03:39:20.575] iteration 6734: loss: 0.096555, loss_s1: 0.065318, loss_fp: 0.001778, loss_freq: 0.035238
[03:39:21.211] iteration 6735: loss: 0.084067, loss_s1: 0.055570, loss_fp: 0.004618, loss_freq: 0.053065
[03:39:21.826] iteration 6736: loss: 0.120578, loss_s1: 0.067043, loss_fp: 0.011606, loss_freq: 0.032554
[03:39:22.416] iteration 6737: loss: 0.092742, loss_s1: 0.069697, loss_fp: 0.002655, loss_freq: 0.036631
[03:39:23.010] iteration 6738: loss: 0.093153, loss_s1: 0.045709, loss_fp: 0.000883, loss_freq: 0.017964
[03:39:23.600] iteration 6739: loss: 0.151783, loss_s1: 0.097355, loss_fp: 0.002261, loss_freq: 0.103132
[03:39:24.208] iteration 6740: loss: 0.092848, loss_s1: 0.061825, loss_fp: 0.001434, loss_freq: 0.024288
[03:39:24.802] iteration 6741: loss: 0.103311, loss_s1: 0.113367, loss_fp: 0.001434, loss_freq: 0.015300
[03:39:25.397] iteration 6742: loss: 0.075548, loss_s1: 0.052100, loss_fp: 0.003479, loss_freq: 0.040975
[03:39:25.988] iteration 6743: loss: 0.073580, loss_s1: 0.048678, loss_fp: 0.001331, loss_freq: 0.023786
[03:39:26.581] iteration 6744: loss: 0.078665, loss_s1: 0.046876, loss_fp: 0.002630, loss_freq: 0.041651
[03:39:27.176] iteration 6745: loss: 0.135038, loss_s1: 0.096071, loss_fp: 0.002937, loss_freq: 0.077268
[03:39:27.769] iteration 6746: loss: 0.112257, loss_s1: 0.042422, loss_fp: 0.008324, loss_freq: 0.072875
[03:39:28.369] iteration 6747: loss: 0.132487, loss_s1: 0.125284, loss_fp: 0.001369, loss_freq: 0.081898
[03:39:28.959] iteration 6748: loss: 0.066487, loss_s1: 0.038381, loss_fp: 0.001888, loss_freq: 0.025061
[03:39:29.553] iteration 6749: loss: 0.141875, loss_s1: 0.083125, loss_fp: 0.005681, loss_freq: 0.115469
[03:39:30.149] iteration 6750: loss: 0.090079, loss_s1: 0.060647, loss_fp: 0.001218, loss_freq: 0.040905
[03:39:30.743] iteration 6751: loss: 0.103439, loss_s1: 0.101619, loss_fp: 0.001247, loss_freq: 0.007941
[03:39:31.331] iteration 6752: loss: 0.104084, loss_s1: 0.133382, loss_fp: 0.003203, loss_freq: 0.010514
[03:39:31.920] iteration 6753: loss: 0.097396, loss_s1: 0.075276, loss_fp: 0.005888, loss_freq: 0.026050
[03:39:32.508] iteration 6754: loss: 0.096465, loss_s1: 0.075108, loss_fp: 0.001994, loss_freq: 0.046997
[03:39:33.094] iteration 6755: loss: 0.104136, loss_s1: 0.060846, loss_fp: 0.003408, loss_freq: 0.055862
[03:39:33.691] iteration 6756: loss: 0.095320, loss_s1: 0.101390, loss_fp: 0.001926, loss_freq: 0.023883
[03:39:34.280] iteration 6757: loss: 0.176057, loss_s1: 0.112805, loss_fp: 0.010086, loss_freq: 0.161347
[03:39:34.873] iteration 6758: loss: 0.096149, loss_s1: 0.041174, loss_fp: 0.006411, loss_freq: 0.039560
[03:39:35.457] iteration 6759: loss: 0.087574, loss_s1: 0.039522, loss_fp: 0.004854, loss_freq: 0.015340
[03:39:36.078] iteration 6760: loss: 0.107656, loss_s1: 0.102772, loss_fp: 0.004410, loss_freq: 0.033872
[03:39:36.735] iteration 6761: loss: 0.111246, loss_s1: 0.095169, loss_fp: 0.020018, loss_freq: 0.041211
[03:39:37.368] iteration 6762: loss: 0.092171, loss_s1: 0.027327, loss_fp: 0.000415, loss_freq: 0.014225
[03:39:38.003] iteration 6763: loss: 0.087446, loss_s1: 0.059818, loss_fp: 0.002654, loss_freq: 0.027725
[03:39:38.633] iteration 6764: loss: 0.100143, loss_s1: 0.051706, loss_fp: 0.002179, loss_freq: 0.057693
[03:39:39.265] iteration 6765: loss: 0.101604, loss_s1: 0.069488, loss_fp: 0.002525, loss_freq: 0.069053
[03:39:39.900] iteration 6766: loss: 0.082267, loss_s1: 0.069542, loss_fp: 0.001350, loss_freq: 0.017935
[03:39:40.488] iteration 6767: loss: 0.178041, loss_s1: 0.114096, loss_fp: 0.001964, loss_freq: 0.029738
[03:39:41.071] iteration 6768: loss: 0.094050, loss_s1: 0.067761, loss_fp: 0.001695, loss_freq: 0.022775
[03:39:41.657] iteration 6769: loss: 0.112905, loss_s1: 0.099395, loss_fp: 0.003993, loss_freq: 0.066494
[03:39:42.245] iteration 6770: loss: 0.103312, loss_s1: 0.105693, loss_fp: 0.006441, loss_freq: 0.029114
[03:39:42.834] iteration 6771: loss: 0.118097, loss_s1: 0.068914, loss_fp: 0.004347, loss_freq: 0.053600
[03:39:43.421] iteration 6772: loss: 0.094600, loss_s1: 0.079891, loss_fp: 0.001706, loss_freq: 0.043973
[03:39:44.012] iteration 6773: loss: 0.127607, loss_s1: 0.122456, loss_fp: 0.006993, loss_freq: 0.044501
[03:39:44.599] iteration 6774: loss: 0.088656, loss_s1: 0.043892, loss_fp: 0.004036, loss_freq: 0.013786
[03:39:45.228] iteration 6775: loss: 0.083972, loss_s1: 0.077538, loss_fp: 0.001428, loss_freq: 0.015315
[03:39:45.861] iteration 6776: loss: 0.069506, loss_s1: 0.027035, loss_fp: 0.001503, loss_freq: 0.032065
[03:39:46.493] iteration 6777: loss: 0.095691, loss_s1: 0.069875, loss_fp: 0.001284, loss_freq: 0.027947
[03:39:47.130] iteration 6778: loss: 0.130470, loss_s1: 0.067386, loss_fp: 0.002668, loss_freq: 0.067033
[03:39:47.718] iteration 6779: loss: 0.104269, loss_s1: 0.085399, loss_fp: 0.000659, loss_freq: 0.037780
[03:39:48.308] iteration 6780: loss: 0.096459, loss_s1: 0.038503, loss_fp: 0.008182, loss_freq: 0.034880
[03:39:48.969] iteration 6781: loss: 0.079950, loss_s1: 0.043805, loss_fp: 0.005503, loss_freq: 0.019134
[03:39:49.600] iteration 6782: loss: 0.099280, loss_s1: 0.087283, loss_fp: 0.002452, loss_freq: 0.034542
[03:39:50.231] iteration 6783: loss: 0.156210, loss_s1: 0.131897, loss_fp: 0.001287, loss_freq: 0.062093
[03:39:50.825] iteration 6784: loss: 0.066751, loss_s1: 0.040136, loss_fp: 0.001918, loss_freq: 0.023681
[03:39:51.414] iteration 6785: loss: 0.103971, loss_s1: 0.072406, loss_fp: 0.006866, loss_freq: 0.042811
[03:39:52.055] iteration 6786: loss: 0.089693, loss_s1: 0.060171, loss_fp: 0.001637, loss_freq: 0.023622
[03:39:52.686] iteration 6787: loss: 0.055114, loss_s1: 0.042806, loss_fp: 0.002722, loss_freq: 0.008633
[03:39:53.309] iteration 6788: loss: 0.131355, loss_s1: 0.103222, loss_fp: 0.004905, loss_freq: 0.069532
[03:39:53.933] iteration 6789: loss: 0.119421, loss_s1: 0.105370, loss_fp: 0.002753, loss_freq: 0.062689
[03:39:54.538] iteration 6790: loss: 0.081064, loss_s1: 0.053851, loss_fp: 0.002648, loss_freq: 0.027671
[03:39:55.130] iteration 6791: loss: 0.065297, loss_s1: 0.054063, loss_fp: 0.005598, loss_freq: 0.017221
[03:39:55.726] iteration 6792: loss: 0.079492, loss_s1: 0.065779, loss_fp: 0.001629, loss_freq: 0.031548
[03:39:56.319] iteration 6793: loss: 0.082631, loss_s1: 0.040508, loss_fp: 0.002767, loss_freq: 0.026682
[03:39:56.907] iteration 6794: loss: 0.080447, loss_s1: 0.052500, loss_fp: 0.002425, loss_freq: 0.049066
[03:39:57.487] iteration 6795: loss: 0.072673, loss_s1: 0.049689, loss_fp: 0.002032, loss_freq: 0.020761
[03:39:58.074] iteration 6796: loss: 0.082635, loss_s1: 0.055927, loss_fp: 0.002579, loss_freq: 0.022312
[03:39:58.709] iteration 6797: loss: 0.089524, loss_s1: 0.045724, loss_fp: 0.002161, loss_freq: 0.050479
[03:39:59.335] iteration 6798: loss: 0.086134, loss_s1: 0.056849, loss_fp: 0.002302, loss_freq: 0.032308
[03:39:59.961] iteration 6799: loss: 0.109018, loss_s1: 0.069147, loss_fp: 0.004721, loss_freq: 0.081407
[03:40:00.586] iteration 6800: loss: 0.105349, loss_s1: 0.080823, loss_fp: 0.002489, loss_freq: 0.062219
[03:40:03.833] iteration 6800 : mean_dice : 0.655989
[03:40:04.850] iteration 6801: loss: 0.108308, loss_s1: 0.052610, loss_fp: 0.003943, loss_freq: 0.014434
[03:40:05.487] iteration 6802: loss: 0.080245, loss_s1: 0.014433, loss_fp: 0.001129, loss_freq: 0.051308
[03:40:06.122] iteration 6803: loss: 0.092273, loss_s1: 0.086383, loss_fp: 0.000806, loss_freq: 0.020671
[03:40:06.719] iteration 6804: loss: 0.066667, loss_s1: 0.037502, loss_fp: 0.001831, loss_freq: 0.022151
[03:40:07.317] iteration 6805: loss: 0.104209, loss_s1: 0.041995, loss_fp: 0.007368, loss_freq: 0.048169
[03:40:07.906] iteration 6806: loss: 0.104012, loss_s1: 0.080952, loss_fp: 0.006189, loss_freq: 0.049323
[03:40:08.494] iteration 6807: loss: 0.094714, loss_s1: 0.061476, loss_fp: 0.007743, loss_freq: 0.040552
[03:40:09.130] iteration 6808: loss: 0.088245, loss_s1: 0.080343, loss_fp: 0.001903, loss_freq: 0.034777
[03:40:09.756] iteration 6809: loss: 0.091842, loss_s1: 0.075646, loss_fp: 0.001728, loss_freq: 0.033091
[03:40:10.388] iteration 6810: loss: 0.148412, loss_s1: 0.139966, loss_fp: 0.003775, loss_freq: 0.049694
[03:40:11.001] iteration 6811: loss: 0.086904, loss_s1: 0.044610, loss_fp: 0.018363, loss_freq: 0.034379
[03:40:11.593] iteration 6812: loss: 0.078197, loss_s1: 0.042435, loss_fp: 0.003362, loss_freq: 0.055769
[03:40:12.179] iteration 6813: loss: 0.097451, loss_s1: 0.047893, loss_fp: 0.007952, loss_freq: 0.068431
[03:40:12.775] iteration 6814: loss: 0.082023, loss_s1: 0.043871, loss_fp: 0.002246, loss_freq: 0.024346
[03:40:13.365] iteration 6815: loss: 0.102587, loss_s1: 0.060736, loss_fp: 0.008603, loss_freq: 0.040706
[03:40:13.964] iteration 6816: loss: 0.095767, loss_s1: 0.050025, loss_fp: 0.005157, loss_freq: 0.036652
[03:40:14.563] iteration 6817: loss: 0.206578, loss_s1: 0.140007, loss_fp: 0.008552, loss_freq: 0.187060
[03:40:15.163] iteration 6818: loss: 0.066392, loss_s1: 0.037475, loss_fp: 0.000881, loss_freq: 0.011664
[03:40:15.763] iteration 6819: loss: 0.105479, loss_s1: 0.112160, loss_fp: 0.010217, loss_freq: 0.027469
[03:40:16.352] iteration 6820: loss: 0.083622, loss_s1: 0.065483, loss_fp: 0.003242, loss_freq: 0.021711
[03:40:16.941] iteration 6821: loss: 0.081685, loss_s1: 0.056332, loss_fp: 0.002475, loss_freq: 0.030564
[03:40:17.530] iteration 6822: loss: 0.134931, loss_s1: 0.097215, loss_fp: 0.008802, loss_freq: 0.068402
[03:40:18.124] iteration 6823: loss: 0.132491, loss_s1: 0.090813, loss_fp: 0.001880, loss_freq: 0.050180
[03:40:18.712] iteration 6824: loss: 0.090978, loss_s1: 0.074939, loss_fp: 0.000640, loss_freq: 0.035886
[03:40:19.302] iteration 6825: loss: 0.108677, loss_s1: 0.123429, loss_fp: 0.000271, loss_freq: 0.023848
[03:40:19.892] iteration 6826: loss: 0.184815, loss_s1: 0.122030, loss_fp: 0.007171, loss_freq: 0.068299
[03:40:20.482] iteration 6827: loss: 0.092855, loss_s1: 0.066606, loss_fp: 0.003667, loss_freq: 0.020051
[03:40:21.076] iteration 6828: loss: 0.154926, loss_s1: 0.074773, loss_fp: 0.001998, loss_freq: 0.091594
[03:40:21.667] iteration 6829: loss: 0.166667, loss_s1: 0.128851, loss_fp: 0.014060, loss_freq: 0.034267
[03:40:22.253] iteration 6830: loss: 0.096317, loss_s1: 0.041364, loss_fp: 0.004824, loss_freq: 0.029649
[03:40:22.843] iteration 6831: loss: 0.079508, loss_s1: 0.062884, loss_fp: 0.001209, loss_freq: 0.029434
[03:40:23.437] iteration 6832: loss: 0.148799, loss_s1: 0.071959, loss_fp: 0.004485, loss_freq: 0.063444
[03:40:24.030] iteration 6833: loss: 0.098575, loss_s1: 0.068145, loss_fp: 0.001408, loss_freq: 0.032147
[03:40:24.615] iteration 6834: loss: 0.063066, loss_s1: 0.052558, loss_fp: 0.003571, loss_freq: 0.011053
[03:40:25.205] iteration 6835: loss: 0.082719, loss_s1: 0.042629, loss_fp: 0.004106, loss_freq: 0.062462
[03:40:25.798] iteration 6836: loss: 0.086545, loss_s1: 0.034634, loss_fp: 0.001883, loss_freq: 0.044199
[03:40:26.394] iteration 6837: loss: 0.098928, loss_s1: 0.040511, loss_fp: 0.019731, loss_freq: 0.054725
[03:40:26.978] iteration 6838: loss: 0.124196, loss_s1: 0.092201, loss_fp: 0.013478, loss_freq: 0.011799
[03:40:27.891] iteration 6839: loss: 0.086737, loss_s1: 0.037715, loss_fp: 0.002491, loss_freq: 0.030604
[03:40:28.723] iteration 6840: loss: 0.129507, loss_s1: 0.133262, loss_fp: 0.017974, loss_freq: 0.038590
[03:40:29.502] iteration 6841: loss: 0.130615, loss_s1: 0.116022, loss_fp: 0.001840, loss_freq: 0.041749
[03:40:30.096] iteration 6842: loss: 0.101935, loss_s1: 0.094955, loss_fp: 0.007913, loss_freq: 0.044699
[03:40:30.680] iteration 6843: loss: 0.113011, loss_s1: 0.096786, loss_fp: 0.002647, loss_freq: 0.054398
[03:40:31.265] iteration 6844: loss: 0.120450, loss_s1: 0.135674, loss_fp: 0.003741, loss_freq: 0.044117
[03:40:31.850] iteration 6845: loss: 0.087318, loss_s1: 0.044209, loss_fp: 0.006924, loss_freq: 0.012662
[03:40:32.430] iteration 6846: loss: 0.084045, loss_s1: 0.067080, loss_fp: 0.002546, loss_freq: 0.021514
[03:40:33.013] iteration 6847: loss: 0.090049, loss_s1: 0.038815, loss_fp: 0.000807, loss_freq: 0.022642
[03:40:33.600] iteration 6848: loss: 0.090437, loss_s1: 0.051812, loss_fp: 0.003387, loss_freq: 0.034908
[03:40:34.190] iteration 6849: loss: 0.078308, loss_s1: 0.044952, loss_fp: 0.008735, loss_freq: 0.024022
[03:40:34.779] iteration 6850: loss: 0.095747, loss_s1: 0.035842, loss_fp: 0.001354, loss_freq: 0.019305
[03:40:35.363] iteration 6851: loss: 0.127344, loss_s1: 0.117674, loss_fp: 0.010241, loss_freq: 0.066283
[03:40:35.991] iteration 6852: loss: 0.098675, loss_s1: 0.101963, loss_fp: 0.003275, loss_freq: 0.037374
[03:40:36.619] iteration 6853: loss: 0.094632, loss_s1: 0.064864, loss_fp: 0.000807, loss_freq: 0.033302
[03:40:37.246] iteration 6854: loss: 0.139246, loss_s1: 0.112005, loss_fp: 0.003655, loss_freq: 0.099900
[03:40:37.886] iteration 6855: loss: 0.130387, loss_s1: 0.070626, loss_fp: 0.001373, loss_freq: 0.063026
[03:40:38.531] iteration 6856: loss: 0.081030, loss_s1: 0.051848, loss_fp: 0.000722, loss_freq: 0.015073
[03:40:39.145] iteration 6857: loss: 0.090230, loss_s1: 0.061426, loss_fp: 0.005322, loss_freq: 0.031378
[03:40:39.763] iteration 6858: loss: 0.125213, loss_s1: 0.083586, loss_fp: 0.014034, loss_freq: 0.045896
[03:40:40.358] iteration 6859: loss: 0.107558, loss_s1: 0.049335, loss_fp: 0.005547, loss_freq: 0.036944
[03:40:40.943] iteration 6860: loss: 0.113466, loss_s1: 0.095819, loss_fp: 0.001659, loss_freq: 0.059183
[03:40:41.532] iteration 6861: loss: 0.066275, loss_s1: 0.054756, loss_fp: 0.006627, loss_freq: 0.022423
[03:40:42.123] iteration 6862: loss: 0.078656, loss_s1: 0.020521, loss_fp: 0.006513, loss_freq: 0.018306
[03:40:42.729] iteration 6863: loss: 0.077639, loss_s1: 0.053322, loss_fp: 0.001097, loss_freq: 0.012407
[03:40:43.326] iteration 6864: loss: 0.119518, loss_s1: 0.067027, loss_fp: 0.002530, loss_freq: 0.031325
[03:40:43.924] iteration 6865: loss: 0.138960, loss_s1: 0.077136, loss_fp: 0.001171, loss_freq: 0.038671
[03:40:44.550] iteration 6866: loss: 0.084687, loss_s1: 0.052345, loss_fp: 0.003528, loss_freq: 0.024528
[03:40:45.176] iteration 6867: loss: 0.125922, loss_s1: 0.065003, loss_fp: 0.001799, loss_freq: 0.016885
[03:40:45.788] iteration 6868: loss: 0.132297, loss_s1: 0.144807, loss_fp: 0.006572, loss_freq: 0.036846
[03:40:46.381] iteration 6869: loss: 0.060707, loss_s1: 0.036612, loss_fp: 0.000624, loss_freq: 0.014171
[03:40:46.967] iteration 6870: loss: 0.076564, loss_s1: 0.049035, loss_fp: 0.002945, loss_freq: 0.049135
[03:40:47.552] iteration 6871: loss: 0.099384, loss_s1: 0.044077, loss_fp: 0.007244, loss_freq: 0.047609
[03:40:48.145] iteration 6872: loss: 0.084655, loss_s1: 0.049585, loss_fp: 0.005150, loss_freq: 0.012768
[03:40:48.733] iteration 6873: loss: 0.095755, loss_s1: 0.052215, loss_fp: 0.009722, loss_freq: 0.037909
[03:40:49.325] iteration 6874: loss: 0.130936, loss_s1: 0.148279, loss_fp: 0.003919, loss_freq: 0.025771
[03:40:49.910] iteration 6875: loss: 0.103440, loss_s1: 0.038974, loss_fp: 0.004341, loss_freq: 0.058549
[03:40:50.503] iteration 6876: loss: 0.117049, loss_s1: 0.089890, loss_fp: 0.002732, loss_freq: 0.045136
[03:40:51.090] iteration 6877: loss: 0.071599, loss_s1: 0.019956, loss_fp: 0.001957, loss_freq: 0.021552
[03:40:51.673] iteration 6878: loss: 0.145860, loss_s1: 0.091227, loss_fp: 0.003118, loss_freq: 0.068344
[03:40:52.263] iteration 6879: loss: 0.092131, loss_s1: 0.060046, loss_fp: 0.000725, loss_freq: 0.044038
[03:40:52.847] iteration 6880: loss: 0.092982, loss_s1: 0.058515, loss_fp: 0.001430, loss_freq: 0.051742
[03:40:53.432] iteration 6881: loss: 0.146109, loss_s1: 0.049660, loss_fp: 0.002582, loss_freq: 0.071066
[03:40:54.062] iteration 6882: loss: 0.088126, loss_s1: 0.061291, loss_fp: 0.003336, loss_freq: 0.059129
[03:40:54.694] iteration 6883: loss: 0.113117, loss_s1: 0.122784, loss_fp: 0.001923, loss_freq: 0.025014
[03:40:55.326] iteration 6884: loss: 0.075688, loss_s1: 0.047717, loss_fp: 0.001870, loss_freq: 0.031086
[03:40:55.951] iteration 6885: loss: 0.085478, loss_s1: 0.063666, loss_fp: 0.001359, loss_freq: 0.023549
[03:40:56.581] iteration 6886: loss: 0.085807, loss_s1: 0.060836, loss_fp: 0.001413, loss_freq: 0.027694
[03:40:57.167] iteration 6887: loss: 0.154176, loss_s1: 0.144093, loss_fp: 0.005426, loss_freq: 0.075878
[03:40:57.757] iteration 6888: loss: 0.094247, loss_s1: 0.056497, loss_fp: 0.007614, loss_freq: 0.055765
[03:40:58.348] iteration 6889: loss: 0.114424, loss_s1: 0.107747, loss_fp: 0.006591, loss_freq: 0.030235
[03:40:58.943] iteration 6890: loss: 0.111284, loss_s1: 0.103578, loss_fp: 0.002285, loss_freq: 0.026798
[03:40:59.534] iteration 6891: loss: 0.103028, loss_s1: 0.088375, loss_fp: 0.001210, loss_freq: 0.033271
[03:41:00.127] iteration 6892: loss: 0.100717, loss_s1: 0.039270, loss_fp: 0.001791, loss_freq: 0.042052
[03:41:00.720] iteration 6893: loss: 0.113224, loss_s1: 0.047405, loss_fp: 0.003367, loss_freq: 0.059970
[03:41:01.315] iteration 6894: loss: 0.108338, loss_s1: 0.073775, loss_fp: 0.002065, loss_freq: 0.006123
[03:41:01.905] iteration 6895: loss: 0.084589, loss_s1: 0.046031, loss_fp: 0.001929, loss_freq: 0.051145
[03:41:02.492] iteration 6896: loss: 0.074168, loss_s1: 0.049000, loss_fp: 0.002261, loss_freq: 0.031785
[03:41:03.074] iteration 6897: loss: 0.130123, loss_s1: 0.105649, loss_fp: 0.003778, loss_freq: 0.051186
[03:41:03.662] iteration 6898: loss: 0.094169, loss_s1: 0.058035, loss_fp: 0.009629, loss_freq: 0.038516
[03:41:04.254] iteration 6899: loss: 0.111942, loss_s1: 0.073726, loss_fp: 0.009774, loss_freq: 0.051421
[03:41:04.852] iteration 6900: loss: 0.076167, loss_s1: 0.033667, loss_fp: 0.007022, loss_freq: 0.028442
[03:41:05.439] iteration 6901: loss: 0.094995, loss_s1: 0.061233, loss_fp: 0.001284, loss_freq: 0.053017
[03:41:06.029] iteration 6902: loss: 0.075961, loss_s1: 0.038845, loss_fp: 0.000808, loss_freq: 0.017888
[03:41:06.619] iteration 6903: loss: 0.111372, loss_s1: 0.086813, loss_fp: 0.004078, loss_freq: 0.051143
[03:41:07.208] iteration 6904: loss: 0.099183, loss_s1: 0.059832, loss_fp: 0.004853, loss_freq: 0.034349
[03:41:07.801] iteration 6905: loss: 0.110575, loss_s1: 0.069493, loss_fp: 0.006760, loss_freq: 0.083574
[03:41:08.392] iteration 6906: loss: 0.105719, loss_s1: 0.065209, loss_fp: 0.006564, loss_freq: 0.037685
[03:41:08.985] iteration 6907: loss: 0.097489, loss_s1: 0.053001, loss_fp: 0.008641, loss_freq: 0.066394
[03:41:09.573] iteration 6908: loss: 0.085403, loss_s1: 0.061683, loss_fp: 0.006936, loss_freq: 0.030055
[03:41:10.161] iteration 6909: loss: 0.102434, loss_s1: 0.053863, loss_fp: 0.003691, loss_freq: 0.082553
[03:41:10.749] iteration 6910: loss: 0.086147, loss_s1: 0.038801, loss_fp: 0.001519, loss_freq: 0.021556
[03:41:11.341] iteration 6911: loss: 0.119917, loss_s1: 0.067892, loss_fp: 0.001233, loss_freq: 0.055778
[03:41:11.929] iteration 6912: loss: 0.092805, loss_s1: 0.063983, loss_fp: 0.002895, loss_freq: 0.046263
[03:41:12.549] iteration 6913: loss: 0.074345, loss_s1: 0.047340, loss_fp: 0.003882, loss_freq: 0.033130
[03:41:13.175] iteration 6914: loss: 0.083186, loss_s1: 0.079112, loss_fp: 0.004779, loss_freq: 0.021930
[03:41:13.799] iteration 6915: loss: 0.124470, loss_s1: 0.075049, loss_fp: 0.008081, loss_freq: 0.070705
[03:41:14.424] iteration 6916: loss: 0.109572, loss_s1: 0.078801, loss_fp: 0.002702, loss_freq: 0.056272
[03:41:15.006] iteration 6917: loss: 0.109677, loss_s1: 0.127826, loss_fp: 0.000771, loss_freq: 0.033015
[03:41:15.590] iteration 6918: loss: 0.063107, loss_s1: 0.030755, loss_fp: 0.002221, loss_freq: 0.016842
[03:41:16.174] iteration 6919: loss: 0.168826, loss_s1: 0.143476, loss_fp: 0.001094, loss_freq: 0.123715
[03:41:16.760] iteration 6920: loss: 0.075784, loss_s1: 0.041363, loss_fp: 0.001772, loss_freq: 0.018675
[03:41:17.347] iteration 6921: loss: 0.080250, loss_s1: 0.068217, loss_fp: 0.001420, loss_freq: 0.013594
[03:41:17.934] iteration 6922: loss: 0.086343, loss_s1: 0.092814, loss_fp: 0.002641, loss_freq: 0.018221
[03:41:18.525] iteration 6923: loss: 0.144784, loss_s1: 0.161189, loss_fp: 0.003912, loss_freq: 0.056817
[03:41:19.113] iteration 6924: loss: 0.098206, loss_s1: 0.031924, loss_fp: 0.003087, loss_freq: 0.090388
[03:41:19.707] iteration 6925: loss: 0.140840, loss_s1: 0.070664, loss_fp: 0.017444, loss_freq: 0.074336
[03:41:20.295] iteration 6926: loss: 0.115644, loss_s1: 0.075202, loss_fp: 0.001268, loss_freq: 0.033748
[03:41:20.889] iteration 6927: loss: 0.147716, loss_s1: 0.121537, loss_fp: 0.007131, loss_freq: 0.107796
[03:41:21.514] iteration 6928: loss: 0.095110, loss_s1: 0.049105, loss_fp: 0.001494, loss_freq: 0.042640
[03:41:22.098] iteration 6929: loss: 0.090717, loss_s1: 0.085167, loss_fp: 0.001207, loss_freq: 0.025924
[03:41:22.683] iteration 6930: loss: 0.115025, loss_s1: 0.113184, loss_fp: 0.002866, loss_freq: 0.056337
[03:41:23.272] iteration 6931: loss: 0.112790, loss_s1: 0.146269, loss_fp: 0.007904, loss_freq: 0.017031
[03:41:23.867] iteration 6932: loss: 0.087750, loss_s1: 0.021499, loss_fp: 0.002427, loss_freq: 0.010316
[03:41:24.481] iteration 6933: loss: 0.156361, loss_s1: 0.102784, loss_fp: 0.002923, loss_freq: 0.086690
[03:41:25.072] iteration 6934: loss: 0.115699, loss_s1: 0.114249, loss_fp: 0.000899, loss_freq: 0.049587
[03:41:25.663] iteration 6935: loss: 0.159924, loss_s1: 0.101137, loss_fp: 0.001756, loss_freq: 0.123542
[03:41:26.253] iteration 6936: loss: 0.089992, loss_s1: 0.054507, loss_fp: 0.005569, loss_freq: 0.034632
[03:41:26.843] iteration 6937: loss: 0.099205, loss_s1: 0.036622, loss_fp: 0.002810, loss_freq: 0.014598
[03:41:27.433] iteration 6938: loss: 0.087656, loss_s1: 0.071843, loss_fp: 0.004626, loss_freq: 0.030195
[03:41:28.024] iteration 6939: loss: 0.119570, loss_s1: 0.060774, loss_fp: 0.002539, loss_freq: 0.071670
[03:41:28.616] iteration 6940: loss: 0.117823, loss_s1: 0.115057, loss_fp: 0.001344, loss_freq: 0.040299
[03:41:29.200] iteration 6941: loss: 0.105805, loss_s1: 0.104320, loss_fp: 0.007045, loss_freq: 0.021336
[03:41:29.785] iteration 6942: loss: 0.077813, loss_s1: 0.055697, loss_fp: 0.003871, loss_freq: 0.020130
[03:41:30.413] iteration 6943: loss: 0.097954, loss_s1: 0.069240, loss_fp: 0.005777, loss_freq: 0.045421
[03:41:30.999] iteration 6944: loss: 0.097642, loss_s1: 0.077828, loss_fp: 0.003019, loss_freq: 0.035496
[03:41:31.590] iteration 6945: loss: 0.086694, loss_s1: 0.070140, loss_fp: 0.008379, loss_freq: 0.020098
[03:41:32.180] iteration 6946: loss: 0.105683, loss_s1: 0.040346, loss_fp: 0.001027, loss_freq: 0.041659
[03:41:32.769] iteration 6947: loss: 0.078625, loss_s1: 0.065887, loss_fp: 0.000836, loss_freq: 0.022227
[03:41:33.352] iteration 6948: loss: 0.116527, loss_s1: 0.111963, loss_fp: 0.002724, loss_freq: 0.049042
[03:41:33.940] iteration 6949: loss: 0.099962, loss_s1: 0.060977, loss_fp: 0.001302, loss_freq: 0.058118
[03:41:34.527] iteration 6950: loss: 0.112026, loss_s1: 0.068520, loss_fp: 0.003171, loss_freq: 0.043661
[03:41:35.110] iteration 6951: loss: 0.110706, loss_s1: 0.086834, loss_fp: 0.005552, loss_freq: 0.034028
[03:41:35.694] iteration 6952: loss: 0.108831, loss_s1: 0.098231, loss_fp: 0.003180, loss_freq: 0.039734
[03:41:36.282] iteration 6953: loss: 0.207069, loss_s1: 0.150403, loss_fp: 0.027139, loss_freq: 0.095950
[03:41:36.868] iteration 6954: loss: 0.110016, loss_s1: 0.077672, loss_fp: 0.003787, loss_freq: 0.036337
[03:41:37.452] iteration 6955: loss: 0.108969, loss_s1: 0.074206, loss_fp: 0.002026, loss_freq: 0.047872
[03:41:38.043] iteration 6956: loss: 0.119659, loss_s1: 0.082378, loss_fp: 0.006812, loss_freq: 0.030583
[03:41:38.628] iteration 6957: loss: 0.147312, loss_s1: 0.040136, loss_fp: 0.007402, loss_freq: 0.053061
[03:41:39.214] iteration 6958: loss: 0.153966, loss_s1: 0.100140, loss_fp: 0.001404, loss_freq: 0.076118
[03:41:39.806] iteration 6959: loss: 0.089011, loss_s1: 0.060847, loss_fp: 0.003577, loss_freq: 0.041953
[03:41:40.390] iteration 6960: loss: 0.102761, loss_s1: 0.066700, loss_fp: 0.005450, loss_freq: 0.024447
[03:41:40.984] iteration 6961: loss: 0.093354, loss_s1: 0.098162, loss_fp: 0.003641, loss_freq: 0.015098
[03:41:41.567] iteration 6962: loss: 0.109142, loss_s1: 0.075397, loss_fp: 0.002908, loss_freq: 0.053406
[03:41:42.148] iteration 6963: loss: 0.092408, loss_s1: 0.047938, loss_fp: 0.002352, loss_freq: 0.016489
[03:41:42.735] iteration 6964: loss: 0.049266, loss_s1: 0.025078, loss_fp: 0.001046, loss_freq: 0.013954
[03:41:43.323] iteration 6965: loss: 0.092880, loss_s1: 0.097335, loss_fp: 0.000567, loss_freq: 0.026459
[03:41:43.907] iteration 6966: loss: 0.089770, loss_s1: 0.064418, loss_fp: 0.002849, loss_freq: 0.042822
[03:41:44.496] iteration 6967: loss: 0.097382, loss_s1: 0.044820, loss_fp: 0.002082, loss_freq: 0.056432
[03:41:45.085] iteration 6968: loss: 0.090550, loss_s1: 0.068339, loss_fp: 0.002445, loss_freq: 0.010614
[03:41:45.672] iteration 6969: loss: 0.109709, loss_s1: 0.076892, loss_fp: 0.001476, loss_freq: 0.049753
[03:41:46.257] iteration 6970: loss: 0.168790, loss_s1: 0.114487, loss_fp: 0.004393, loss_freq: 0.115776
[03:41:47.148] iteration 6971: loss: 0.072913, loss_s1: 0.036968, loss_fp: 0.002514, loss_freq: 0.011967
[03:41:47.742] iteration 6972: loss: 0.094585, loss_s1: 0.069484, loss_fp: 0.002277, loss_freq: 0.038680
[03:41:48.340] iteration 6973: loss: 0.094992, loss_s1: 0.033492, loss_fp: 0.001770, loss_freq: 0.040028
[03:41:48.925] iteration 6974: loss: 0.073553, loss_s1: 0.049185, loss_fp: 0.001261, loss_freq: 0.015011
[03:41:49.517] iteration 6975: loss: 0.082002, loss_s1: 0.066274, loss_fp: 0.002527, loss_freq: 0.023924
[03:41:50.115] iteration 6976: loss: 0.160475, loss_s1: 0.086178, loss_fp: 0.001482, loss_freq: 0.040198
[03:41:50.709] iteration 6977: loss: 0.132111, loss_s1: 0.093245, loss_fp: 0.002689, loss_freq: 0.042577
[03:41:51.304] iteration 6978: loss: 0.079490, loss_s1: 0.059106, loss_fp: 0.002372, loss_freq: 0.016292
[03:41:51.895] iteration 6979: loss: 0.065353, loss_s1: 0.032335, loss_fp: 0.002860, loss_freq: 0.020971
[03:41:52.489] iteration 6980: loss: 0.098516, loss_s1: 0.056585, loss_fp: 0.003673, loss_freq: 0.065952
[03:41:53.074] iteration 6981: loss: 0.093068, loss_s1: 0.047598, loss_fp: 0.001529, loss_freq: 0.043470
[03:41:53.669] iteration 6982: loss: 0.105579, loss_s1: 0.074975, loss_fp: 0.001693, loss_freq: 0.067687
[03:41:54.257] iteration 6983: loss: 0.109444, loss_s1: 0.031745, loss_fp: 0.000975, loss_freq: 0.083685
[03:41:54.847] iteration 6984: loss: 0.099121, loss_s1: 0.064179, loss_fp: 0.009663, loss_freq: 0.048422
[03:41:55.440] iteration 6985: loss: 0.124114, loss_s1: 0.061993, loss_fp: 0.000583, loss_freq: 0.011939
[03:41:56.071] iteration 6986: loss: 0.107076, loss_s1: 0.063921, loss_fp: 0.008044, loss_freq: 0.032400
[03:41:56.699] iteration 6987: loss: 0.122091, loss_s1: 0.062218, loss_fp: 0.003390, loss_freq: 0.116670
[03:41:57.329] iteration 6988: loss: 0.062383, loss_s1: 0.021055, loss_fp: 0.001300, loss_freq: 0.019455
[03:41:57.958] iteration 6989: loss: 0.094307, loss_s1: 0.095463, loss_fp: 0.004092, loss_freq: 0.017024
[03:41:58.585] iteration 6990: loss: 0.081304, loss_s1: 0.045549, loss_fp: 0.000725, loss_freq: 0.030101
[03:41:59.179] iteration 6991: loss: 0.084495, loss_s1: 0.046928, loss_fp: 0.011259, loss_freq: 0.027991
[03:41:59.765] iteration 6992: loss: 0.121469, loss_s1: 0.083743, loss_fp: 0.003559, loss_freq: 0.044878
[03:42:00.348] iteration 6993: loss: 0.133404, loss_s1: 0.065106, loss_fp: 0.010422, loss_freq: 0.037220
[03:42:00.937] iteration 6994: loss: 0.107370, loss_s1: 0.045612, loss_fp: 0.004807, loss_freq: 0.024474
[03:42:01.529] iteration 6995: loss: 0.109787, loss_s1: 0.122763, loss_fp: 0.002680, loss_freq: 0.021447
[03:42:02.153] iteration 6996: loss: 0.145797, loss_s1: 0.151101, loss_fp: 0.001586, loss_freq: 0.051415
[03:42:02.779] iteration 6997: loss: 0.121033, loss_s1: 0.045374, loss_fp: 0.007201, loss_freq: 0.012362
[03:42:03.394] iteration 6998: loss: 0.159044, loss_s1: 0.109692, loss_fp: 0.023512, loss_freq: 0.053667
[03:42:03.984] iteration 6999: loss: 0.107509, loss_s1: 0.036390, loss_fp: 0.001652, loss_freq: 0.036233
[03:42:04.579] iteration 7000: loss: 0.132041, loss_s1: 0.164931, loss_fp: 0.001282, loss_freq: 0.029729
[03:42:07.838] iteration 7000 : mean_dice : 0.681672
[03:42:08.465] iteration 7001: loss: 0.077318, loss_s1: 0.053665, loss_fp: 0.004360, loss_freq: 0.028986
[03:42:09.057] iteration 7002: loss: 0.091604, loss_s1: 0.037219, loss_fp: 0.002963, loss_freq: 0.040578
[03:42:09.650] iteration 7003: loss: 0.088729, loss_s1: 0.096168, loss_fp: 0.002431, loss_freq: 0.020354
[03:42:10.240] iteration 7004: loss: 0.064052, loss_s1: 0.035575, loss_fp: 0.001144, loss_freq: 0.016261
[03:42:10.835] iteration 7005: loss: 0.069276, loss_s1: 0.055523, loss_fp: 0.001674, loss_freq: 0.031455
[03:42:11.424] iteration 7006: loss: 0.067527, loss_s1: 0.043066, loss_fp: 0.000734, loss_freq: 0.018389
[03:42:12.015] iteration 7007: loss: 0.070841, loss_s1: 0.028800, loss_fp: 0.004289, loss_freq: 0.022191
[03:42:12.603] iteration 7008: loss: 0.069507, loss_s1: 0.052326, loss_fp: 0.002171, loss_freq: 0.023961
[03:42:13.188] iteration 7009: loss: 0.090137, loss_s1: 0.036276, loss_fp: 0.012181, loss_freq: 0.025836
[03:42:13.771] iteration 7010: loss: 0.091846, loss_s1: 0.066900, loss_fp: 0.001054, loss_freq: 0.039616
[03:42:14.365] iteration 7011: loss: 0.097988, loss_s1: 0.056111, loss_fp: 0.006431, loss_freq: 0.016200
[03:42:14.995] iteration 7012: loss: 0.096670, loss_s1: 0.083946, loss_fp: 0.007092, loss_freq: 0.030204
[03:42:15.637] iteration 7013: loss: 0.087119, loss_s1: 0.079918, loss_fp: 0.003517, loss_freq: 0.035179
[03:42:16.230] iteration 7014: loss: 0.138714, loss_s1: 0.107980, loss_fp: 0.002229, loss_freq: 0.109524
[03:42:16.821] iteration 7015: loss: 0.100660, loss_s1: 0.037896, loss_fp: 0.008657, loss_freq: 0.035269
[03:42:17.413] iteration 7016: loss: 0.109859, loss_s1: 0.072819, loss_fp: 0.001876, loss_freq: 0.059618
[03:42:18.005] iteration 7017: loss: 0.081406, loss_s1: 0.039572, loss_fp: 0.003620, loss_freq: 0.020544
[03:42:18.609] iteration 7018: loss: 0.059429, loss_s1: 0.037407, loss_fp: 0.001240, loss_freq: 0.012011
[03:42:19.199] iteration 7019: loss: 0.089026, loss_s1: 0.066680, loss_fp: 0.002150, loss_freq: 0.013852
[03:42:19.785] iteration 7020: loss: 0.116680, loss_s1: 0.111690, loss_fp: 0.003093, loss_freq: 0.027376
[03:42:20.375] iteration 7021: loss: 0.086885, loss_s1: 0.045673, loss_fp: 0.001001, loss_freq: 0.050854
[03:42:20.961] iteration 7022: loss: 0.127509, loss_s1: 0.152580, loss_fp: 0.001706, loss_freq: 0.040045
[03:42:21.563] iteration 7023: loss: 0.092698, loss_s1: 0.016380, loss_fp: 0.003340, loss_freq: 0.064013
[03:42:22.160] iteration 7024: loss: 0.090988, loss_s1: 0.052084, loss_fp: 0.001899, loss_freq: 0.051444
[03:42:22.757] iteration 7025: loss: 0.140918, loss_s1: 0.096687, loss_fp: 0.005146, loss_freq: 0.090019
[03:42:23.348] iteration 7026: loss: 0.053074, loss_s1: 0.011409, loss_fp: 0.001557, loss_freq: 0.018149
[03:42:23.939] iteration 7027: loss: 0.084043, loss_s1: 0.044461, loss_fp: 0.001729, loss_freq: 0.024196
[03:42:24.527] iteration 7028: loss: 0.094366, loss_s1: 0.069666, loss_fp: 0.001593, loss_freq: 0.016700
[03:42:25.127] iteration 7029: loss: 0.113389, loss_s1: 0.065694, loss_fp: 0.001942, loss_freq: 0.053654
[03:42:25.781] iteration 7030: loss: 0.111428, loss_s1: 0.090584, loss_fp: 0.000764, loss_freq: 0.060492
[03:42:26.418] iteration 7031: loss: 0.052191, loss_s1: 0.032657, loss_fp: 0.002001, loss_freq: 0.022045
[03:42:27.060] iteration 7032: loss: 0.201786, loss_s1: 0.109966, loss_fp: 0.004222, loss_freq: 0.070331
[03:42:27.707] iteration 7033: loss: 0.058294, loss_s1: 0.028816, loss_fp: 0.001310, loss_freq: 0.009271
[03:42:28.317] iteration 7034: loss: 0.090668, loss_s1: 0.051784, loss_fp: 0.000688, loss_freq: 0.037168
[03:42:28.957] iteration 7035: loss: 0.139424, loss_s1: 0.149282, loss_fp: 0.001853, loss_freq: 0.038799
[03:42:29.590] iteration 7036: loss: 0.096284, loss_s1: 0.092859, loss_fp: 0.001863, loss_freq: 0.035086
[03:42:30.225] iteration 7037: loss: 0.105927, loss_s1: 0.091862, loss_fp: 0.002717, loss_freq: 0.022094
[03:42:30.859] iteration 7038: loss: 0.152071, loss_s1: 0.116602, loss_fp: 0.003788, loss_freq: 0.064833
[03:42:31.493] iteration 7039: loss: 0.102732, loss_s1: 0.085472, loss_fp: 0.003788, loss_freq: 0.051655
[03:42:32.120] iteration 7040: loss: 0.095970, loss_s1: 0.086943, loss_fp: 0.007948, loss_freq: 0.025944
[03:42:32.715] iteration 7041: loss: 0.138534, loss_s1: 0.112198, loss_fp: 0.003112, loss_freq: 0.062909
[03:42:33.310] iteration 7042: loss: 0.106117, loss_s1: 0.098617, loss_fp: 0.004701, loss_freq: 0.021512
[03:42:33.918] iteration 7043: loss: 0.073407, loss_s1: 0.045523, loss_fp: 0.006636, loss_freq: 0.031378
[03:42:34.842] iteration 7044: loss: 0.139939, loss_s1: 0.138632, loss_fp: 0.001600, loss_freq: 0.024841
[03:42:35.778] iteration 7045: loss: 0.150346, loss_s1: 0.117663, loss_fp: 0.005739, loss_freq: 0.099542
[03:42:36.373] iteration 7046: loss: 0.096415, loss_s1: 0.065866, loss_fp: 0.007610, loss_freq: 0.044279
[03:42:36.976] iteration 7047: loss: 0.072068, loss_s1: 0.045617, loss_fp: 0.001023, loss_freq: 0.019577
[03:42:37.568] iteration 7048: loss: 0.100711, loss_s1: 0.074169, loss_fp: 0.005220, loss_freq: 0.036887
[03:42:38.168] iteration 7049: loss: 0.098018, loss_s1: 0.061231, loss_fp: 0.027238, loss_freq: 0.038381
[03:42:38.771] iteration 7050: loss: 0.106054, loss_s1: 0.056597, loss_fp: 0.001748, loss_freq: 0.035296
[03:42:39.367] iteration 7051: loss: 0.162087, loss_s1: 0.099443, loss_fp: 0.008390, loss_freq: 0.081479
[03:42:39.967] iteration 7052: loss: 0.094034, loss_s1: 0.088992, loss_fp: 0.009698, loss_freq: 0.031054
[03:42:40.563] iteration 7053: loss: 0.117816, loss_s1: 0.127551, loss_fp: 0.001366, loss_freq: 0.021597
[03:42:41.156] iteration 7054: loss: 0.091083, loss_s1: 0.074516, loss_fp: 0.005901, loss_freq: 0.014247
[03:42:41.759] iteration 7055: loss: 0.082987, loss_s1: 0.057375, loss_fp: 0.001569, loss_freq: 0.044247
[03:42:42.350] iteration 7056: loss: 0.073018, loss_s1: 0.046179, loss_fp: 0.002146, loss_freq: 0.020656
[03:42:42.938] iteration 7057: loss: 0.101086, loss_s1: 0.107704, loss_fp: 0.004083, loss_freq: 0.030113
[03:42:43.606] iteration 7058: loss: 0.097834, loss_s1: 0.052467, loss_fp: 0.003030, loss_freq: 0.024994
[03:42:44.246] iteration 7059: loss: 0.135235, loss_s1: 0.090114, loss_fp: 0.000669, loss_freq: 0.109125
[03:42:44.878] iteration 7060: loss: 0.080103, loss_s1: 0.058263, loss_fp: 0.000710, loss_freq: 0.022574
[03:42:45.495] iteration 7061: loss: 0.097631, loss_s1: 0.084551, loss_fp: 0.004551, loss_freq: 0.026659
[03:42:46.086] iteration 7062: loss: 0.129574, loss_s1: 0.072271, loss_fp: 0.003333, loss_freq: 0.112662
[03:42:46.682] iteration 7063: loss: 0.160623, loss_s1: 0.148943, loss_fp: 0.002279, loss_freq: 0.041133
[03:42:47.277] iteration 7064: loss: 0.048566, loss_s1: 0.025745, loss_fp: 0.000839, loss_freq: 0.005057
[03:42:47.873] iteration 7065: loss: 0.119531, loss_s1: 0.079137, loss_fp: 0.004108, loss_freq: 0.044307
[03:42:48.474] iteration 7066: loss: 0.093766, loss_s1: 0.081010, loss_fp: 0.003898, loss_freq: 0.040082
[03:42:49.070] iteration 7067: loss: 0.124707, loss_s1: 0.035701, loss_fp: 0.003075, loss_freq: 0.071554
[03:42:49.663] iteration 7068: loss: 0.089069, loss_s1: 0.072844, loss_fp: 0.004524, loss_freq: 0.034657
[03:42:50.263] iteration 7069: loss: 0.070894, loss_s1: 0.039730, loss_fp: 0.004248, loss_freq: 0.037895
[03:42:50.863] iteration 7070: loss: 0.066438, loss_s1: 0.029705, loss_fp: 0.001781, loss_freq: 0.016609
[03:42:51.453] iteration 7071: loss: 0.059852, loss_s1: 0.036440, loss_fp: 0.000896, loss_freq: 0.016386
[03:42:52.046] iteration 7072: loss: 0.107252, loss_s1: 0.050094, loss_fp: 0.002506, loss_freq: 0.032859
[03:42:52.638] iteration 7073: loss: 0.054634, loss_s1: 0.030109, loss_fp: 0.003227, loss_freq: 0.016266
[03:42:53.228] iteration 7074: loss: 0.072397, loss_s1: 0.055637, loss_fp: 0.001875, loss_freq: 0.022760
[03:42:53.813] iteration 7075: loss: 0.091067, loss_s1: 0.052619, loss_fp: 0.001666, loss_freq: 0.058320
[03:42:54.405] iteration 7076: loss: 0.113557, loss_s1: 0.120722, loss_fp: 0.004900, loss_freq: 0.020774
[03:42:54.996] iteration 7077: loss: 0.060968, loss_s1: 0.033693, loss_fp: 0.001647, loss_freq: 0.011536
[03:42:55.596] iteration 7078: loss: 0.076372, loss_s1: 0.046221, loss_fp: 0.001359, loss_freq: 0.032455
[03:42:56.255] iteration 7079: loss: 0.124683, loss_s1: 0.079453, loss_fp: 0.006964, loss_freq: 0.065956
[03:42:56.890] iteration 7080: loss: 0.118550, loss_s1: 0.041077, loss_fp: 0.001666, loss_freq: 0.023648
[03:42:57.523] iteration 7081: loss: 0.070741, loss_s1: 0.044543, loss_fp: 0.001004, loss_freq: 0.021851
[03:42:58.161] iteration 7082: loss: 0.064409, loss_s1: 0.035527, loss_fp: 0.001203, loss_freq: 0.026217
[03:42:58.776] iteration 7083: loss: 0.108066, loss_s1: 0.084124, loss_fp: 0.002193, loss_freq: 0.037338
[03:42:59.418] iteration 7084: loss: 0.064791, loss_s1: 0.031503, loss_fp: 0.003922, loss_freq: 0.029759
[03:43:00.059] iteration 7085: loss: 0.176911, loss_s1: 0.141235, loss_fp: 0.006003, loss_freq: 0.055568
[03:43:00.683] iteration 7086: loss: 0.089298, loss_s1: 0.066558, loss_fp: 0.002161, loss_freq: 0.030602
[03:43:01.277] iteration 7087: loss: 0.091735, loss_s1: 0.054624, loss_fp: 0.004669, loss_freq: 0.040707
[03:43:01.864] iteration 7088: loss: 0.088906, loss_s1: 0.064446, loss_fp: 0.001255, loss_freq: 0.031863
[03:43:02.457] iteration 7089: loss: 0.100187, loss_s1: 0.036364, loss_fp: 0.003162, loss_freq: 0.094739
[03:43:03.050] iteration 7090: loss: 0.077486, loss_s1: 0.047638, loss_fp: 0.013275, loss_freq: 0.012510
[03:43:03.644] iteration 7091: loss: 0.099547, loss_s1: 0.101942, loss_fp: 0.001422, loss_freq: 0.021969
[03:43:04.241] iteration 7092: loss: 0.080084, loss_s1: 0.063463, loss_fp: 0.000666, loss_freq: 0.044071
[03:43:04.839] iteration 7093: loss: 0.135768, loss_s1: 0.124834, loss_fp: 0.006557, loss_freq: 0.050476
[03:43:05.427] iteration 7094: loss: 0.124217, loss_s1: 0.089352, loss_fp: 0.001840, loss_freq: 0.103228
[03:43:06.022] iteration 7095: loss: 0.120167, loss_s1: 0.095032, loss_fp: 0.007331, loss_freq: 0.056117
[03:43:06.615] iteration 7096: loss: 0.084308, loss_s1: 0.079298, loss_fp: 0.003615, loss_freq: 0.025946
[03:43:07.206] iteration 7097: loss: 0.163533, loss_s1: 0.078035, loss_fp: 0.005386, loss_freq: 0.170520
[03:43:07.801] iteration 7098: loss: 0.139919, loss_s1: 0.066633, loss_fp: 0.009906, loss_freq: 0.060505
[03:43:08.392] iteration 7099: loss: 0.099267, loss_s1: 0.066458, loss_fp: 0.004518, loss_freq: 0.034414
[03:43:08.973] iteration 7100: loss: 0.098480, loss_s1: 0.056780, loss_fp: 0.000552, loss_freq: 0.051702
[03:43:09.565] iteration 7101: loss: 0.089787, loss_s1: 0.080999, loss_fp: 0.001317, loss_freq: 0.038418
[03:43:10.157] iteration 7102: loss: 0.094500, loss_s1: 0.037608, loss_fp: 0.003029, loss_freq: 0.012263
[03:43:10.750] iteration 7103: loss: 0.061471, loss_s1: 0.034197, loss_fp: 0.000394, loss_freq: 0.020772
[03:43:11.337] iteration 7104: loss: 0.113397, loss_s1: 0.113405, loss_fp: 0.001628, loss_freq: 0.041563
[03:43:11.928] iteration 7105: loss: 0.106547, loss_s1: 0.064038, loss_fp: 0.004349, loss_freq: 0.028267
[03:43:12.515] iteration 7106: loss: 0.060967, loss_s1: 0.049782, loss_fp: 0.001878, loss_freq: 0.022032
[03:43:13.140] iteration 7107: loss: 0.110789, loss_s1: 0.068760, loss_fp: 0.004351, loss_freq: 0.012943
[03:43:13.773] iteration 7108: loss: 0.069468, loss_s1: 0.050685, loss_fp: 0.004482, loss_freq: 0.017418
[03:43:14.426] iteration 7109: loss: 0.132702, loss_s1: 0.130103, loss_fp: 0.006706, loss_freq: 0.049493
[03:43:15.022] iteration 7110: loss: 0.069808, loss_s1: 0.032356, loss_fp: 0.006589, loss_freq: 0.045788
[03:43:15.622] iteration 7111: loss: 0.083451, loss_s1: 0.064587, loss_fp: 0.004222, loss_freq: 0.018602
[03:43:16.213] iteration 7112: loss: 0.086464, loss_s1: 0.058219, loss_fp: 0.001476, loss_freq: 0.040853
[03:43:16.812] iteration 7113: loss: 0.179686, loss_s1: 0.087155, loss_fp: 0.002128, loss_freq: 0.067340
[03:43:17.405] iteration 7114: loss: 0.074119, loss_s1: 0.031362, loss_fp: 0.009838, loss_freq: 0.019305
[03:43:17.993] iteration 7115: loss: 0.064801, loss_s1: 0.039022, loss_fp: 0.002333, loss_freq: 0.018640
[03:43:18.588] iteration 7116: loss: 0.071867, loss_s1: 0.037714, loss_fp: 0.002039, loss_freq: 0.031073
[03:43:19.180] iteration 7117: loss: 0.085935, loss_s1: 0.041837, loss_fp: 0.001247, loss_freq: 0.041875
[03:43:19.768] iteration 7118: loss: 0.162297, loss_s1: 0.172460, loss_fp: 0.001694, loss_freq: 0.078223
[03:43:20.364] iteration 7119: loss: 0.127058, loss_s1: 0.111776, loss_fp: 0.005137, loss_freq: 0.047233
[03:43:20.960] iteration 7120: loss: 0.095747, loss_s1: 0.041144, loss_fp: 0.001377, loss_freq: 0.054174
[03:43:21.554] iteration 7121: loss: 0.090315, loss_s1: 0.063649, loss_fp: 0.002151, loss_freq: 0.040783
[03:43:22.145] iteration 7122: loss: 0.112699, loss_s1: 0.064975, loss_fp: 0.004046, loss_freq: 0.044044
[03:43:22.742] iteration 7123: loss: 0.124978, loss_s1: 0.109256, loss_fp: 0.002326, loss_freq: 0.073321
[03:43:23.330] iteration 7124: loss: 0.082309, loss_s1: 0.061341, loss_fp: 0.002768, loss_freq: 0.030924
[03:43:23.926] iteration 7125: loss: 0.153114, loss_s1: 0.103967, loss_fp: 0.012583, loss_freq: 0.092664
[03:43:24.517] iteration 7126: loss: 0.079295, loss_s1: 0.048083, loss_fp: 0.007639, loss_freq: 0.024098
[03:43:25.113] iteration 7127: loss: 0.081728, loss_s1: 0.039997, loss_fp: 0.002760, loss_freq: 0.058659
[03:43:25.711] iteration 7128: loss: 0.116897, loss_s1: 0.092633, loss_fp: 0.002477, loss_freq: 0.077323
[03:43:26.306] iteration 7129: loss: 0.061181, loss_s1: 0.035706, loss_fp: 0.006135, loss_freq: 0.022179
[03:43:26.903] iteration 7130: loss: 0.127122, loss_s1: 0.107307, loss_fp: 0.001381, loss_freq: 0.012614
[03:43:27.494] iteration 7131: loss: 0.063836, loss_s1: 0.049849, loss_fp: 0.001125, loss_freq: 0.006587
[03:43:28.089] iteration 7132: loss: 0.061643, loss_s1: 0.043251, loss_fp: 0.002012, loss_freq: 0.010190
[03:43:28.685] iteration 7133: loss: 0.100167, loss_s1: 0.043313, loss_fp: 0.000319, loss_freq: 0.036550
[03:43:29.276] iteration 7134: loss: 0.068308, loss_s1: 0.048971, loss_fp: 0.001077, loss_freq: 0.033738
[03:43:29.863] iteration 7135: loss: 0.097566, loss_s1: 0.083328, loss_fp: 0.006103, loss_freq: 0.021141
[03:43:30.455] iteration 7136: loss: 0.103409, loss_s1: 0.064494, loss_fp: 0.003760, loss_freq: 0.070891
[03:43:31.044] iteration 7137: loss: 0.083766, loss_s1: 0.049386, loss_fp: 0.002745, loss_freq: 0.038309
[03:43:31.636] iteration 7138: loss: 0.073572, loss_s1: 0.036286, loss_fp: 0.001526, loss_freq: 0.012151
[03:43:32.223] iteration 7139: loss: 0.138765, loss_s1: 0.124060, loss_fp: 0.003467, loss_freq: 0.080319
[03:43:32.808] iteration 7140: loss: 0.140245, loss_s1: 0.132935, loss_fp: 0.007173, loss_freq: 0.057251
[03:43:33.769] iteration 7141: loss: 0.109563, loss_s1: 0.089335, loss_fp: 0.000591, loss_freq: 0.053349
[03:43:34.363] iteration 7142: loss: 0.071990, loss_s1: 0.029885, loss_fp: 0.000779, loss_freq: 0.029993
[03:43:34.952] iteration 7143: loss: 0.083157, loss_s1: 0.060418, loss_fp: 0.001158, loss_freq: 0.038984
[03:43:35.544] iteration 7144: loss: 0.081539, loss_s1: 0.062889, loss_fp: 0.000710, loss_freq: 0.016638
[03:43:36.144] iteration 7145: loss: 0.105594, loss_s1: 0.123384, loss_fp: 0.001658, loss_freq: 0.031966
[03:43:36.735] iteration 7146: loss: 0.103429, loss_s1: 0.045143, loss_fp: 0.001735, loss_freq: 0.038211
[03:43:37.337] iteration 7147: loss: 0.102147, loss_s1: 0.110920, loss_fp: 0.003366, loss_freq: 0.035421
[03:43:37.929] iteration 7148: loss: 0.065947, loss_s1: 0.031423, loss_fp: 0.002123, loss_freq: 0.019769
[03:43:38.538] iteration 7149: loss: 0.091745, loss_s1: 0.064717, loss_fp: 0.005546, loss_freq: 0.024949
[03:43:39.255] iteration 7150: loss: 0.106644, loss_s1: 0.082459, loss_fp: 0.001380, loss_freq: 0.044077
[03:43:39.887] iteration 7151: loss: 0.117334, loss_s1: 0.060328, loss_fp: 0.004986, loss_freq: 0.090566
[03:43:40.612] iteration 7152: loss: 0.122258, loss_s1: 0.088568, loss_fp: 0.002902, loss_freq: 0.066219
[03:43:41.296] iteration 7153: loss: 0.098127, loss_s1: 0.047665, loss_fp: 0.011421, loss_freq: 0.047726
[03:43:41.996] iteration 7154: loss: 0.055166, loss_s1: 0.016448, loss_fp: 0.002331, loss_freq: 0.019520
[03:43:42.648] iteration 7155: loss: 0.080585, loss_s1: 0.040848, loss_fp: 0.007204, loss_freq: 0.020959
[03:43:43.317] iteration 7156: loss: 0.089455, loss_s1: 0.055273, loss_fp: 0.003829, loss_freq: 0.033604
[03:43:44.044] iteration 7157: loss: 0.193841, loss_s1: 0.175527, loss_fp: 0.012135, loss_freq: 0.127730
[03:43:44.656] iteration 7158: loss: 0.086040, loss_s1: 0.046878, loss_fp: 0.001703, loss_freq: 0.017956
[03:43:45.267] iteration 7159: loss: 0.091297, loss_s1: 0.103736, loss_fp: 0.002183, loss_freq: 0.012528
[03:43:45.869] iteration 7160: loss: 0.136837, loss_s1: 0.110270, loss_fp: 0.008231, loss_freq: 0.051629
[03:43:46.477] iteration 7161: loss: 0.121608, loss_s1: 0.106513, loss_fp: 0.002414, loss_freq: 0.046574
[03:43:47.123] iteration 7162: loss: 0.103707, loss_s1: 0.093518, loss_fp: 0.001373, loss_freq: 0.030929
[03:43:47.808] iteration 7163: loss: 0.147138, loss_s1: 0.056510, loss_fp: 0.001593, loss_freq: 0.041011
[03:43:48.475] iteration 7164: loss: 0.077207, loss_s1: 0.028660, loss_fp: 0.003415, loss_freq: 0.067017
[03:43:49.096] iteration 7165: loss: 0.096083, loss_s1: 0.053236, loss_fp: 0.003804, loss_freq: 0.040057
[03:43:49.818] iteration 7166: loss: 0.132828, loss_s1: 0.080827, loss_fp: 0.001907, loss_freq: 0.053991
[03:43:50.480] iteration 7167: loss: 0.092794, loss_s1: 0.047122, loss_fp: 0.000691, loss_freq: 0.024907
[03:43:51.084] iteration 7168: loss: 0.134068, loss_s1: 0.151439, loss_fp: 0.002037, loss_freq: 0.027475
[03:43:51.670] iteration 7169: loss: 0.099862, loss_s1: 0.082513, loss_fp: 0.002127, loss_freq: 0.037880
[03:43:52.263] iteration 7170: loss: 0.116357, loss_s1: 0.134478, loss_fp: 0.006761, loss_freq: 0.035056
[03:43:52.852] iteration 7171: loss: 0.094788, loss_s1: 0.075198, loss_fp: 0.002148, loss_freq: 0.034549
[03:43:53.450] iteration 7172: loss: 0.083001, loss_s1: 0.036263, loss_fp: 0.000818, loss_freq: 0.043722
[03:43:54.044] iteration 7173: loss: 0.117775, loss_s1: 0.081882, loss_fp: 0.004336, loss_freq: 0.027262
[03:43:54.637] iteration 7174: loss: 0.065506, loss_s1: 0.041035, loss_fp: 0.000740, loss_freq: 0.008305
[03:43:55.230] iteration 7175: loss: 0.054203, loss_s1: 0.027328, loss_fp: 0.002409, loss_freq: 0.026602
[03:43:55.819] iteration 7176: loss: 0.070722, loss_s1: 0.020268, loss_fp: 0.001251, loss_freq: 0.010664
[03:43:56.412] iteration 7177: loss: 0.127717, loss_s1: 0.117054, loss_fp: 0.003084, loss_freq: 0.063313
[03:43:57.010] iteration 7178: loss: 0.092082, loss_s1: 0.072737, loss_fp: 0.003376, loss_freq: 0.033040
[03:43:57.608] iteration 7179: loss: 0.100080, loss_s1: 0.052829, loss_fp: 0.001595, loss_freq: 0.050162
[03:43:58.194] iteration 7180: loss: 0.135583, loss_s1: 0.141935, loss_fp: 0.003161, loss_freq: 0.038618
[03:43:58.780] iteration 7181: loss: 0.123861, loss_s1: 0.099740, loss_fp: 0.002593, loss_freq: 0.078011
[03:43:59.369] iteration 7182: loss: 0.103121, loss_s1: 0.089930, loss_fp: 0.003235, loss_freq: 0.043559
[03:43:59.958] iteration 7183: loss: 0.139967, loss_s1: 0.085145, loss_fp: 0.002428, loss_freq: 0.120213
[03:44:00.553] iteration 7184: loss: 0.104052, loss_s1: 0.092707, loss_fp: 0.001987, loss_freq: 0.062824
[03:44:01.143] iteration 7185: loss: 0.116628, loss_s1: 0.077533, loss_fp: 0.001202, loss_freq: 0.024055
[03:44:01.733] iteration 7186: loss: 0.098827, loss_s1: 0.059602, loss_fp: 0.002556, loss_freq: 0.026688
[03:44:02.320] iteration 7187: loss: 0.095393, loss_s1: 0.090263, loss_fp: 0.002874, loss_freq: 0.011055
[03:44:02.916] iteration 7188: loss: 0.093715, loss_s1: 0.095250, loss_fp: 0.001523, loss_freq: 0.040001
[03:44:03.513] iteration 7189: loss: 0.075554, loss_s1: 0.060539, loss_fp: 0.003072, loss_freq: 0.012436
[03:44:04.113] iteration 7190: loss: 0.085559, loss_s1: 0.055943, loss_fp: 0.000325, loss_freq: 0.016560
[03:44:04.703] iteration 7191: loss: 0.061766, loss_s1: 0.037091, loss_fp: 0.001274, loss_freq: 0.025678
[03:44:05.303] iteration 7192: loss: 0.097071, loss_s1: 0.075871, loss_fp: 0.001620, loss_freq: 0.042533
[03:44:05.932] iteration 7193: loss: 0.093673, loss_s1: 0.061310, loss_fp: 0.001763, loss_freq: 0.047386
[03:44:06.588] iteration 7194: loss: 0.127556, loss_s1: 0.123127, loss_fp: 0.000922, loss_freq: 0.075813
[03:44:07.290] iteration 7195: loss: 0.109208, loss_s1: 0.028135, loss_fp: 0.003607, loss_freq: 0.089391
[03:44:08.039] iteration 7196: loss: 0.069532, loss_s1: 0.066728, loss_fp: 0.004049, loss_freq: 0.013998
[03:44:08.691] iteration 7197: loss: 0.082194, loss_s1: 0.057770, loss_fp: 0.005769, loss_freq: 0.039215
[03:44:09.287] iteration 7198: loss: 0.110687, loss_s1: 0.098822, loss_fp: 0.001605, loss_freq: 0.027927
[03:44:09.877] iteration 7199: loss: 0.069972, loss_s1: 0.058413, loss_fp: 0.001948, loss_freq: 0.026609
[03:44:10.468] iteration 7200: loss: 0.138170, loss_s1: 0.129687, loss_fp: 0.002998, loss_freq: 0.076327
[03:44:13.748] iteration 7200 : mean_dice : 0.684549
[03:44:14.379] iteration 7201: loss: 0.059270, loss_s1: 0.060910, loss_fp: 0.003295, loss_freq: 0.013334
[03:44:14.976] iteration 7202: loss: 0.148917, loss_s1: 0.071822, loss_fp: 0.007154, loss_freq: 0.043100
[03:44:15.572] iteration 7203: loss: 0.066359, loss_s1: 0.047634, loss_fp: 0.002388, loss_freq: 0.008430
[03:44:16.166] iteration 7204: loss: 0.135191, loss_s1: 0.079017, loss_fp: 0.002464, loss_freq: 0.048129
[03:44:16.758] iteration 7205: loss: 0.124743, loss_s1: 0.129966, loss_fp: 0.003089, loss_freq: 0.040895
[03:44:17.362] iteration 7206: loss: 0.083998, loss_s1: 0.046566, loss_fp: 0.003329, loss_freq: 0.053046
[03:44:17.956] iteration 7207: loss: 0.120483, loss_s1: 0.106000, loss_fp: 0.000812, loss_freq: 0.013139
[03:44:18.545] iteration 7208: loss: 0.097837, loss_s1: 0.085206, loss_fp: 0.002237, loss_freq: 0.048563
[03:44:19.134] iteration 7209: loss: 0.066936, loss_s1: 0.040665, loss_fp: 0.001803, loss_freq: 0.033335
[03:44:19.726] iteration 7210: loss: 0.089544, loss_s1: 0.078068, loss_fp: 0.001450, loss_freq: 0.038965
[03:44:20.324] iteration 7211: loss: 0.098549, loss_s1: 0.050625, loss_fp: 0.002715, loss_freq: 0.055478
[03:44:20.914] iteration 7212: loss: 0.079068, loss_s1: 0.056193, loss_fp: 0.001534, loss_freq: 0.015058
[03:44:21.508] iteration 7213: loss: 0.088051, loss_s1: 0.049777, loss_fp: 0.001231, loss_freq: 0.036826
[03:44:22.096] iteration 7214: loss: 0.088604, loss_s1: 0.102714, loss_fp: 0.002471, loss_freq: 0.012692
[03:44:22.684] iteration 7215: loss: 0.132933, loss_s1: 0.064393, loss_fp: 0.003819, loss_freq: 0.086638
[03:44:23.284] iteration 7216: loss: 0.070112, loss_s1: 0.037337, loss_fp: 0.001800, loss_freq: 0.027198
[03:44:23.877] iteration 7217: loss: 0.079567, loss_s1: 0.040986, loss_fp: 0.001841, loss_freq: 0.018686
[03:44:24.469] iteration 7218: loss: 0.122357, loss_s1: 0.071623, loss_fp: 0.001174, loss_freq: 0.069408
[03:44:25.064] iteration 7219: loss: 0.074452, loss_s1: 0.046760, loss_fp: 0.005620, loss_freq: 0.040081
[03:44:25.652] iteration 7220: loss: 0.062340, loss_s1: 0.037430, loss_fp: 0.001417, loss_freq: 0.019600
[03:44:26.244] iteration 7221: loss: 0.148854, loss_s1: 0.086180, loss_fp: 0.001888, loss_freq: 0.097681
[03:44:26.838] iteration 7222: loss: 0.090015, loss_s1: 0.080533, loss_fp: 0.004984, loss_freq: 0.040953
[03:44:27.432] iteration 7223: loss: 0.145554, loss_s1: 0.120975, loss_fp: 0.004265, loss_freq: 0.041930
[03:44:28.024] iteration 7224: loss: 0.073222, loss_s1: 0.036282, loss_fp: 0.001387, loss_freq: 0.039120
[03:44:28.616] iteration 7225: loss: 0.078895, loss_s1: 0.043914, loss_fp: 0.002913, loss_freq: 0.023595
[03:44:29.207] iteration 7226: loss: 0.061907, loss_s1: 0.037985, loss_fp: 0.004623, loss_freq: 0.028715
[03:44:29.796] iteration 7227: loss: 0.071308, loss_s1: 0.069522, loss_fp: 0.001134, loss_freq: 0.026163
[03:44:30.391] iteration 7228: loss: 0.080631, loss_s1: 0.056725, loss_fp: 0.002208, loss_freq: 0.018331
[03:44:30.991] iteration 7229: loss: 0.108643, loss_s1: 0.040398, loss_fp: 0.020800, loss_freq: 0.105864
[03:44:31.588] iteration 7230: loss: 0.081286, loss_s1: 0.038984, loss_fp: 0.003925, loss_freq: 0.007696
[03:44:32.175] iteration 7231: loss: 0.058958, loss_s1: 0.036850, loss_fp: 0.002988, loss_freq: 0.019612
[03:44:32.768] iteration 7232: loss: 0.108757, loss_s1: 0.081514, loss_fp: 0.007984, loss_freq: 0.065670
[03:44:33.363] iteration 7233: loss: 0.079302, loss_s1: 0.060965, loss_fp: 0.001234, loss_freq: 0.039142
[03:44:33.956] iteration 7234: loss: 0.082791, loss_s1: 0.049158, loss_fp: 0.002530, loss_freq: 0.012029
[03:44:34.550] iteration 7235: loss: 0.163006, loss_s1: 0.114557, loss_fp: 0.004029, loss_freq: 0.064461
[03:44:35.148] iteration 7236: loss: 0.076347, loss_s1: 0.048517, loss_fp: 0.002676, loss_freq: 0.043360
[03:44:35.744] iteration 7237: loss: 0.121612, loss_s1: 0.088263, loss_fp: 0.004194, loss_freq: 0.051320
[03:44:36.339] iteration 7238: loss: 0.077052, loss_s1: 0.074266, loss_fp: 0.002051, loss_freq: 0.019881
[03:44:36.933] iteration 7239: loss: 0.114659, loss_s1: 0.056176, loss_fp: 0.003921, loss_freq: 0.050278
[03:44:37.524] iteration 7240: loss: 0.065832, loss_s1: 0.036432, loss_fp: 0.003897, loss_freq: 0.030756
[03:44:38.108] iteration 7241: loss: 0.105897, loss_s1: 0.069311, loss_fp: 0.001546, loss_freq: 0.090504
[03:44:38.700] iteration 7242: loss: 0.096070, loss_s1: 0.071028, loss_fp: 0.003474, loss_freq: 0.017465
[03:44:39.619] iteration 7243: loss: 0.065268, loss_s1: 0.043765, loss_fp: 0.001864, loss_freq: 0.020532
[03:44:40.309] iteration 7244: loss: 0.073952, loss_s1: 0.024570, loss_fp: 0.005246, loss_freq: 0.039995
[03:44:41.248] iteration 7245: loss: 0.078857, loss_s1: 0.027443, loss_fp: 0.001823, loss_freq: 0.063515
[03:44:41.881] iteration 7246: loss: 0.070707, loss_s1: 0.044002, loss_fp: 0.009271, loss_freq: 0.026227
[03:44:42.474] iteration 7247: loss: 0.077619, loss_s1: 0.043078, loss_fp: 0.010138, loss_freq: 0.041522
[03:44:43.064] iteration 7248: loss: 0.143270, loss_s1: 0.199764, loss_fp: 0.001741, loss_freq: 0.027752
[03:44:43.667] iteration 7249: loss: 0.145322, loss_s1: 0.065413, loss_fp: 0.002261, loss_freq: 0.141725
[03:44:44.329] iteration 7250: loss: 0.075411, loss_s1: 0.018174, loss_fp: 0.002602, loss_freq: 0.018258
[03:44:44.961] iteration 7251: loss: 0.083902, loss_s1: 0.079897, loss_fp: 0.001664, loss_freq: 0.028590
[03:44:45.596] iteration 7252: loss: 0.072152, loss_s1: 0.044368, loss_fp: 0.001180, loss_freq: 0.018083
[03:44:46.232] iteration 7253: loss: 0.122140, loss_s1: 0.135883, loss_fp: 0.001170, loss_freq: 0.028826
[03:44:46.867] iteration 7254: loss: 0.087098, loss_s1: 0.034653, loss_fp: 0.000689, loss_freq: 0.030003
[03:44:47.475] iteration 7255: loss: 0.118633, loss_s1: 0.093583, loss_fp: 0.007107, loss_freq: 0.059258
[03:44:48.069] iteration 7256: loss: 0.134948, loss_s1: 0.070059, loss_fp: 0.004258, loss_freq: 0.106787
[03:44:48.671] iteration 7257: loss: 0.146964, loss_s1: 0.155470, loss_fp: 0.004210, loss_freq: 0.039358
[03:44:49.258] iteration 7258: loss: 0.070959, loss_s1: 0.017918, loss_fp: 0.001461, loss_freq: 0.027125
[03:44:49.921] iteration 7259: loss: 0.117396, loss_s1: 0.089936, loss_fp: 0.001990, loss_freq: 0.079648
[03:44:50.554] iteration 7260: loss: 0.100397, loss_s1: 0.100535, loss_fp: 0.000849, loss_freq: 0.016143
[03:44:51.187] iteration 7261: loss: 0.056819, loss_s1: 0.025244, loss_fp: 0.004389, loss_freq: 0.026202
[03:44:51.838] iteration 7262: loss: 0.089470, loss_s1: 0.078589, loss_fp: 0.002021, loss_freq: 0.040574
[03:44:52.474] iteration 7263: loss: 0.115209, loss_s1: 0.081044, loss_fp: 0.001954, loss_freq: 0.020889
[03:44:53.106] iteration 7264: loss: 0.101067, loss_s1: 0.036895, loss_fp: 0.006517, loss_freq: 0.096291
[03:44:53.737] iteration 7265: loss: 0.143761, loss_s1: 0.116619, loss_fp: 0.007580, loss_freq: 0.084226
[03:44:54.367] iteration 7266: loss: 0.116280, loss_s1: 0.125408, loss_fp: 0.002648, loss_freq: 0.029753
[03:44:54.973] iteration 7267: loss: 0.107376, loss_s1: 0.057871, loss_fp: 0.005681, loss_freq: 0.081882
[03:44:55.564] iteration 7268: loss: 0.158144, loss_s1: 0.114580, loss_fp: 0.001886, loss_freq: 0.102635
[03:44:56.221] iteration 7269: loss: 0.079268, loss_s1: 0.081832, loss_fp: 0.001712, loss_freq: 0.021261
[03:44:56.857] iteration 7270: loss: 0.143938, loss_s1: 0.152235, loss_fp: 0.001554, loss_freq: 0.034012
[03:44:57.519] iteration 7271: loss: 0.116879, loss_s1: 0.102120, loss_fp: 0.001840, loss_freq: 0.064998
[03:44:58.180] iteration 7272: loss: 0.102838, loss_s1: 0.034381, loss_fp: 0.005087, loss_freq: 0.023713
[03:44:58.851] iteration 7273: loss: 0.118381, loss_s1: 0.129716, loss_fp: 0.004606, loss_freq: 0.036494
[03:44:59.481] iteration 7274: loss: 0.081466, loss_s1: 0.064619, loss_fp: 0.001125, loss_freq: 0.040295
[03:45:00.198] iteration 7275: loss: 0.099373, loss_s1: 0.055087, loss_fp: 0.002527, loss_freq: 0.052970
[03:45:00.860] iteration 7276: loss: 0.080745, loss_s1: 0.035797, loss_fp: 0.002168, loss_freq: 0.050297
[03:45:01.594] iteration 7277: loss: 0.124805, loss_s1: 0.076770, loss_fp: 0.002411, loss_freq: 0.023810
[03:45:02.260] iteration 7278: loss: 0.069224, loss_s1: 0.066250, loss_fp: 0.004001, loss_freq: 0.017631
[03:45:02.949] iteration 7279: loss: 0.155071, loss_s1: 0.137209, loss_fp: 0.020684, loss_freq: 0.070115
[03:45:03.651] iteration 7280: loss: 0.089678, loss_s1: 0.071471, loss_fp: 0.004463, loss_freq: 0.047307
[03:45:04.309] iteration 7281: loss: 0.106757, loss_s1: 0.103141, loss_fp: 0.000799, loss_freq: 0.032985
[03:45:05.019] iteration 7282: loss: 0.080758, loss_s1: 0.057956, loss_fp: 0.002546, loss_freq: 0.032010
[03:45:05.649] iteration 7283: loss: 0.138855, loss_s1: 0.111334, loss_fp: 0.012465, loss_freq: 0.033817
[03:45:06.483] iteration 7284: loss: 0.142654, loss_s1: 0.161043, loss_fp: 0.002837, loss_freq: 0.023182
[03:45:07.154] iteration 7285: loss: 0.057077, loss_s1: 0.020252, loss_fp: 0.005861, loss_freq: 0.011351
[03:45:07.851] iteration 7286: loss: 0.098115, loss_s1: 0.075487, loss_fp: 0.003132, loss_freq: 0.039456
[03:45:08.562] iteration 7287: loss: 0.090787, loss_s1: 0.056879, loss_fp: 0.002747, loss_freq: 0.025279
[03:45:09.157] iteration 7288: loss: 0.150854, loss_s1: 0.180756, loss_fp: 0.002653, loss_freq: 0.055056
[03:45:09.750] iteration 7289: loss: 0.099917, loss_s1: 0.082384, loss_fp: 0.004896, loss_freq: 0.058928
[03:45:10.334] iteration 7290: loss: 0.080983, loss_s1: 0.039688, loss_fp: 0.006221, loss_freq: 0.023112
[03:45:10.924] iteration 7291: loss: 0.082416, loss_s1: 0.019006, loss_fp: 0.006795, loss_freq: 0.019780
[03:45:11.506] iteration 7292: loss: 0.116783, loss_s1: 0.098528, loss_fp: 0.012547, loss_freq: 0.071498
[03:45:12.094] iteration 7293: loss: 0.126072, loss_s1: 0.066087, loss_fp: 0.009319, loss_freq: 0.120520
[03:45:12.691] iteration 7294: loss: 0.078499, loss_s1: 0.056459, loss_fp: 0.002027, loss_freq: 0.040684
[03:45:13.283] iteration 7295: loss: 0.123293, loss_s1: 0.063387, loss_fp: 0.008892, loss_freq: 0.071223
[03:45:13.879] iteration 7296: loss: 0.110706, loss_s1: 0.060008, loss_fp: 0.007606, loss_freq: 0.050214
[03:45:14.475] iteration 7297: loss: 0.061371, loss_s1: 0.010761, loss_fp: 0.000804, loss_freq: 0.061299
[03:45:15.062] iteration 7298: loss: 0.137190, loss_s1: 0.091757, loss_fp: 0.003349, loss_freq: 0.072207
[03:45:15.649] iteration 7299: loss: 0.055037, loss_s1: 0.024889, loss_fp: 0.001245, loss_freq: 0.030878
[03:45:16.233] iteration 7300: loss: 0.124066, loss_s1: 0.118863, loss_fp: 0.004493, loss_freq: 0.040031
[03:45:16.821] iteration 7301: loss: 0.063914, loss_s1: 0.027857, loss_fp: 0.003552, loss_freq: 0.025421
[03:45:17.411] iteration 7302: loss: 0.053612, loss_s1: 0.040557, loss_fp: 0.003306, loss_freq: 0.006794
[03:45:17.996] iteration 7303: loss: 0.093537, loss_s1: 0.047575, loss_fp: 0.002639, loss_freq: 0.016858
[03:45:18.588] iteration 7304: loss: 0.088143, loss_s1: 0.076650, loss_fp: 0.002326, loss_freq: 0.035921
[03:45:19.179] iteration 7305: loss: 0.065550, loss_s1: 0.056854, loss_fp: 0.001020, loss_freq: 0.017894
[03:45:19.811] iteration 7306: loss: 0.089537, loss_s1: 0.073390, loss_fp: 0.005496, loss_freq: 0.027676
[03:45:20.440] iteration 7307: loss: 0.086933, loss_s1: 0.027105, loss_fp: 0.002905, loss_freq: 0.024723
[03:45:21.083] iteration 7308: loss: 0.090722, loss_s1: 0.057337, loss_fp: 0.010361, loss_freq: 0.020598
[03:45:21.670] iteration 7309: loss: 0.119684, loss_s1: 0.088723, loss_fp: 0.005441, loss_freq: 0.083765
[03:45:22.260] iteration 7310: loss: 0.129411, loss_s1: 0.117811, loss_fp: 0.001065, loss_freq: 0.066868
[03:45:23.489] iteration 7311: loss: 0.071261, loss_s1: 0.042272, loss_fp: 0.002127, loss_freq: 0.016251
[03:45:24.285] iteration 7312: loss: 0.092796, loss_s1: 0.080430, loss_fp: 0.004506, loss_freq: 0.033487
[03:45:25.091] iteration 7313: loss: 0.067156, loss_s1: 0.040760, loss_fp: 0.003428, loss_freq: 0.043846
[03:45:25.740] iteration 7314: loss: 0.065719, loss_s1: 0.043867, loss_fp: 0.000684, loss_freq: 0.017405
[03:45:26.382] iteration 7315: loss: 0.085268, loss_s1: 0.068586, loss_fp: 0.002733, loss_freq: 0.036611
[03:45:26.987] iteration 7316: loss: 0.087102, loss_s1: 0.037924, loss_fp: 0.024557, loss_freq: 0.016351
[03:45:27.582] iteration 7317: loss: 0.127218, loss_s1: 0.113035, loss_fp: 0.006686, loss_freq: 0.033020
[03:45:28.179] iteration 7318: loss: 0.088092, loss_s1: 0.028084, loss_fp: 0.000836, loss_freq: 0.024542
[03:45:28.772] iteration 7319: loss: 0.068007, loss_s1: 0.057436, loss_fp: 0.007819, loss_freq: 0.030285
[03:45:29.361] iteration 7320: loss: 0.107578, loss_s1: 0.081265, loss_fp: 0.003534, loss_freq: 0.049117
[03:45:29.945] iteration 7321: loss: 0.101955, loss_s1: 0.056157, loss_fp: 0.003052, loss_freq: 0.066988
[03:45:30.535] iteration 7322: loss: 0.103047, loss_s1: 0.060760, loss_fp: 0.001623, loss_freq: 0.092333
[03:45:31.130] iteration 7323: loss: 0.110101, loss_s1: 0.080522, loss_fp: 0.000970, loss_freq: 0.049531
[03:45:31.728] iteration 7324: loss: 0.114115, loss_s1: 0.097511, loss_fp: 0.002691, loss_freq: 0.040552
[03:45:32.321] iteration 7325: loss: 0.089817, loss_s1: 0.082469, loss_fp: 0.002196, loss_freq: 0.015254
[03:45:32.915] iteration 7326: loss: 0.121678, loss_s1: 0.089770, loss_fp: 0.004092, loss_freq: 0.078048
[03:45:33.512] iteration 7327: loss: 0.131362, loss_s1: 0.116344, loss_fp: 0.004000, loss_freq: 0.085682
[03:45:34.112] iteration 7328: loss: 0.109588, loss_s1: 0.052616, loss_fp: 0.002493, loss_freq: 0.018989
[03:45:34.703] iteration 7329: loss: 0.090295, loss_s1: 0.046557, loss_fp: 0.007195, loss_freq: 0.037258
[03:45:35.298] iteration 7330: loss: 0.131554, loss_s1: 0.128185, loss_fp: 0.001231, loss_freq: 0.042211
[03:45:35.893] iteration 7331: loss: 0.084715, loss_s1: 0.042024, loss_fp: 0.004698, loss_freq: 0.055207
[03:45:36.482] iteration 7332: loss: 0.116070, loss_s1: 0.104307, loss_fp: 0.003203, loss_freq: 0.052371
[03:45:37.075] iteration 7333: loss: 0.147926, loss_s1: 0.093285, loss_fp: 0.001260, loss_freq: 0.056865
[03:45:37.671] iteration 7334: loss: 0.102238, loss_s1: 0.094549, loss_fp: 0.000662, loss_freq: 0.037744
[03:45:38.267] iteration 7335: loss: 0.055930, loss_s1: 0.012820, loss_fp: 0.003917, loss_freq: 0.033121
[03:45:38.860] iteration 7336: loss: 0.139743, loss_s1: 0.147976, loss_fp: 0.003694, loss_freq: 0.061576
[03:45:39.452] iteration 7337: loss: 0.094140, loss_s1: 0.048249, loss_fp: 0.003683, loss_freq: 0.023838
[03:45:40.048] iteration 7338: loss: 0.110858, loss_s1: 0.097717, loss_fp: 0.003661, loss_freq: 0.045432
[03:45:40.650] iteration 7339: loss: 0.098370, loss_s1: 0.045873, loss_fp: 0.010941, loss_freq: 0.042989
[03:45:41.245] iteration 7340: loss: 0.075628, loss_s1: 0.055970, loss_fp: 0.009099, loss_freq: 0.025172
[03:45:41.845] iteration 7341: loss: 0.089599, loss_s1: 0.054767, loss_fp: 0.007133, loss_freq: 0.050792
[03:45:42.443] iteration 7342: loss: 0.115937, loss_s1: 0.095158, loss_fp: 0.002366, loss_freq: 0.037489
[03:45:43.121] iteration 7343: loss: 0.071900, loss_s1: 0.039457, loss_fp: 0.004106, loss_freq: 0.033880
[03:45:43.760] iteration 7344: loss: 0.080531, loss_s1: 0.058195, loss_fp: 0.013414, loss_freq: 0.028922
[03:45:44.393] iteration 7345: loss: 0.074395, loss_s1: 0.061300, loss_fp: 0.005029, loss_freq: 0.040350
[03:45:45.000] iteration 7346: loss: 0.054299, loss_s1: 0.033984, loss_fp: 0.001125, loss_freq: 0.008311
[03:45:45.599] iteration 7347: loss: 0.098561, loss_s1: 0.066964, loss_fp: 0.010048, loss_freq: 0.044503
[03:45:46.187] iteration 7348: loss: 0.060589, loss_s1: 0.033754, loss_fp: 0.008262, loss_freq: 0.020463
[03:45:46.777] iteration 7349: loss: 0.115273, loss_s1: 0.094415, loss_fp: 0.002264, loss_freq: 0.044271
[03:45:47.369] iteration 7350: loss: 0.138182, loss_s1: 0.157177, loss_fp: 0.000910, loss_freq: 0.052600
[03:45:47.964] iteration 7351: loss: 0.139760, loss_s1: 0.100142, loss_fp: 0.003119, loss_freq: 0.088343
[03:45:48.565] iteration 7352: loss: 0.111757, loss_s1: 0.074589, loss_fp: 0.001076, loss_freq: 0.095908
[03:45:49.157] iteration 7353: loss: 0.138994, loss_s1: 0.117123, loss_fp: 0.004857, loss_freq: 0.043196
[03:45:49.752] iteration 7354: loss: 0.163748, loss_s1: 0.120371, loss_fp: 0.001945, loss_freq: 0.119371
[03:45:50.337] iteration 7355: loss: 0.098525, loss_s1: 0.080616, loss_fp: 0.007345, loss_freq: 0.033237
[03:45:50.923] iteration 7356: loss: 0.072406, loss_s1: 0.057033, loss_fp: 0.001113, loss_freq: 0.035639
[03:45:51.513] iteration 7357: loss: 0.070712, loss_s1: 0.050199, loss_fp: 0.007456, loss_freq: 0.024800
[03:45:52.096] iteration 7358: loss: 0.086181, loss_s1: 0.067266, loss_fp: 0.001932, loss_freq: 0.033561
[03:45:52.694] iteration 7359: loss: 0.084537, loss_s1: 0.075687, loss_fp: 0.001206, loss_freq: 0.016983
[03:45:53.288] iteration 7360: loss: 0.083795, loss_s1: 0.087349, loss_fp: 0.001160, loss_freq: 0.018238
[03:45:53.883] iteration 7361: loss: 0.117578, loss_s1: 0.122933, loss_fp: 0.003033, loss_freq: 0.024715
[03:45:54.481] iteration 7362: loss: 0.092767, loss_s1: 0.082998, loss_fp: 0.016926, loss_freq: 0.044229
[03:45:55.082] iteration 7363: loss: 0.094833, loss_s1: 0.058755, loss_fp: 0.005823, loss_freq: 0.036588
[03:45:55.671] iteration 7364: loss: 0.164886, loss_s1: 0.130749, loss_fp: 0.007379, loss_freq: 0.093854
[03:45:56.255] iteration 7365: loss: 0.113989, loss_s1: 0.046733, loss_fp: 0.001404, loss_freq: 0.087249
[03:45:56.848] iteration 7366: loss: 0.061336, loss_s1: 0.052605, loss_fp: 0.001708, loss_freq: 0.017331
[03:45:57.443] iteration 7367: loss: 0.084136, loss_s1: 0.058839, loss_fp: 0.002555, loss_freq: 0.031872
[03:45:58.037] iteration 7368: loss: 0.143631, loss_s1: 0.149366, loss_fp: 0.005537, loss_freq: 0.057259
[03:45:58.622] iteration 7369: loss: 0.080493, loss_s1: 0.047398, loss_fp: 0.002162, loss_freq: 0.039689
[03:45:59.214] iteration 7370: loss: 0.118443, loss_s1: 0.084362, loss_fp: 0.002789, loss_freq: 0.066961
[03:45:59.811] iteration 7371: loss: 0.072892, loss_s1: 0.071036, loss_fp: 0.000644, loss_freq: 0.024692
[03:46:00.408] iteration 7372: loss: 0.196102, loss_s1: 0.084604, loss_fp: 0.002409, loss_freq: 0.055305
[03:46:01.002] iteration 7373: loss: 0.074720, loss_s1: 0.042706, loss_fp: 0.004534, loss_freq: 0.020036
[03:46:01.597] iteration 7374: loss: 0.080333, loss_s1: 0.058158, loss_fp: 0.002405, loss_freq: 0.044545
[03:46:02.190] iteration 7375: loss: 0.096621, loss_s1: 0.054291, loss_fp: 0.000889, loss_freq: 0.024193
[03:46:02.783] iteration 7376: loss: 0.081281, loss_s1: 0.053054, loss_fp: 0.003843, loss_freq: 0.029572
[03:46:03.377] iteration 7377: loss: 0.096580, loss_s1: 0.065176, loss_fp: 0.001867, loss_freq: 0.008221
[03:46:03.965] iteration 7378: loss: 0.163978, loss_s1: 0.149007, loss_fp: 0.003646, loss_freq: 0.068585
[03:46:04.561] iteration 7379: loss: 0.062963, loss_s1: 0.025142, loss_fp: 0.005408, loss_freq: 0.010498
[03:46:05.143] iteration 7380: loss: 0.094516, loss_s1: 0.046617, loss_fp: 0.004303, loss_freq: 0.061192
[03:46:05.737] iteration 7381: loss: 0.100246, loss_s1: 0.044213, loss_fp: 0.005578, loss_freq: 0.038265
[03:46:06.325] iteration 7382: loss: 0.078849, loss_s1: 0.056203, loss_fp: 0.001198, loss_freq: 0.019373
[03:46:06.917] iteration 7383: loss: 0.103274, loss_s1: 0.056332, loss_fp: 0.003558, loss_freq: 0.040246
[03:46:07.509] iteration 7384: loss: 0.073738, loss_s1: 0.061348, loss_fp: 0.003370, loss_freq: 0.011280
[03:46:08.103] iteration 7385: loss: 0.102270, loss_s1: 0.099844, loss_fp: 0.002871, loss_freq: 0.033618
[03:46:08.699] iteration 7386: loss: 0.074875, loss_s1: 0.043994, loss_fp: 0.006163, loss_freq: 0.032412
[03:46:09.296] iteration 7387: loss: 0.078215, loss_s1: 0.060651, loss_fp: 0.005044, loss_freq: 0.026215
[03:46:09.889] iteration 7388: loss: 0.144586, loss_s1: 0.117422, loss_fp: 0.003885, loss_freq: 0.069598
[03:46:10.485] iteration 7389: loss: 0.082103, loss_s1: 0.054561, loss_fp: 0.001202, loss_freq: 0.039788
[03:46:11.073] iteration 7390: loss: 0.091494, loss_s1: 0.065391, loss_fp: 0.001631, loss_freq: 0.021238
[03:46:11.670] iteration 7391: loss: 0.125380, loss_s1: 0.096212, loss_fp: 0.004213, loss_freq: 0.081928
[03:46:12.273] iteration 7392: loss: 0.088062, loss_s1: 0.068332, loss_fp: 0.001170, loss_freq: 0.034908
[03:46:12.870] iteration 7393: loss: 0.098417, loss_s1: 0.091868, loss_fp: 0.001578, loss_freq: 0.023568
[03:46:13.471] iteration 7394: loss: 0.098292, loss_s1: 0.080697, loss_fp: 0.003549, loss_freq: 0.017530
[03:46:14.071] iteration 7395: loss: 0.100699, loss_s1: 0.105049, loss_fp: 0.001228, loss_freq: 0.027583
[03:46:14.668] iteration 7396: loss: 0.081233, loss_s1: 0.054969, loss_fp: 0.001846, loss_freq: 0.044973
[03:46:15.254] iteration 7397: loss: 0.084684, loss_s1: 0.099552, loss_fp: 0.002412, loss_freq: 0.021435
[03:46:15.840] iteration 7398: loss: 0.114509, loss_s1: 0.070395, loss_fp: 0.006548, loss_freq: 0.034348
[03:46:16.439] iteration 7399: loss: 0.114442, loss_s1: 0.100595, loss_fp: 0.021010, loss_freq: 0.042944
[03:46:17.029] iteration 7400: loss: 0.082478, loss_s1: 0.053799, loss_fp: 0.003764, loss_freq: 0.038889
[03:46:20.509] iteration 7400 : mean_dice : 0.664860
[03:46:21.173] iteration 7401: loss: 0.103269, loss_s1: 0.122713, loss_fp: 0.000871, loss_freq: 0.015016
[03:46:21.768] iteration 7402: loss: 0.094879, loss_s1: 0.096724, loss_fp: 0.008741, loss_freq: 0.035529
[03:46:22.368] iteration 7403: loss: 0.076946, loss_s1: 0.052100, loss_fp: 0.007058, loss_freq: 0.022007
[03:46:22.971] iteration 7404: loss: 0.082694, loss_s1: 0.037555, loss_fp: 0.002826, loss_freq: 0.025821
[03:46:23.565] iteration 7405: loss: 0.137996, loss_s1: 0.123304, loss_fp: 0.007500, loss_freq: 0.062553
[03:46:24.155] iteration 7406: loss: 0.122582, loss_s1: 0.112166, loss_fp: 0.007198, loss_freq: 0.021583
[03:46:24.749] iteration 7407: loss: 0.102996, loss_s1: 0.061477, loss_fp: 0.002032, loss_freq: 0.037055
[03:46:25.345] iteration 7408: loss: 0.094131, loss_s1: 0.074565, loss_fp: 0.000690, loss_freq: 0.025825
[03:46:25.938] iteration 7409: loss: 0.073519, loss_s1: 0.047236, loss_fp: 0.002807, loss_freq: 0.030681
[03:46:26.533] iteration 7410: loss: 0.077607, loss_s1: 0.054544, loss_fp: 0.008740, loss_freq: 0.014048
[03:46:27.122] iteration 7411: loss: 0.088002, loss_s1: 0.033056, loss_fp: 0.002448, loss_freq: 0.057712
[03:46:27.720] iteration 7412: loss: 0.071026, loss_s1: 0.044549, loss_fp: 0.006751, loss_freq: 0.021941
[03:46:28.313] iteration 7413: loss: 0.072819, loss_s1: 0.046791, loss_fp: 0.001383, loss_freq: 0.021144
[03:46:28.911] iteration 7414: loss: 0.082158, loss_s1: 0.024421, loss_fp: 0.003956, loss_freq: 0.023369
[03:46:29.508] iteration 7415: loss: 0.078848, loss_s1: 0.044136, loss_fp: 0.013637, loss_freq: 0.023682
[03:46:30.101] iteration 7416: loss: 0.111660, loss_s1: 0.076784, loss_fp: 0.004282, loss_freq: 0.064443
[03:46:30.723] iteration 7417: loss: 0.087327, loss_s1: 0.038690, loss_fp: 0.006086, loss_freq: 0.043458
[03:46:31.352] iteration 7418: loss: 0.066164, loss_s1: 0.060084, loss_fp: 0.001318, loss_freq: 0.014088
[03:46:31.949] iteration 7419: loss: 0.127609, loss_s1: 0.058617, loss_fp: 0.008497, loss_freq: 0.095213
[03:46:32.548] iteration 7420: loss: 0.090813, loss_s1: 0.045011, loss_fp: 0.003121, loss_freq: 0.016390
[03:46:33.142] iteration 7421: loss: 0.066045, loss_s1: 0.027251, loss_fp: 0.000881, loss_freq: 0.021789
[03:46:33.732] iteration 7422: loss: 0.078655, loss_s1: 0.032209, loss_fp: 0.000836, loss_freq: 0.032390
[03:46:34.331] iteration 7423: loss: 0.097341, loss_s1: 0.075432, loss_fp: 0.001141, loss_freq: 0.038751
[03:46:34.928] iteration 7424: loss: 0.065895, loss_s1: 0.043410, loss_fp: 0.001924, loss_freq: 0.020765
[03:46:35.525] iteration 7425: loss: 0.187053, loss_s1: 0.117516, loss_fp: 0.008598, loss_freq: 0.152175
[03:46:36.119] iteration 7426: loss: 0.105533, loss_s1: 0.066154, loss_fp: 0.000674, loss_freq: 0.073016
[03:46:36.705] iteration 7427: loss: 0.096017, loss_s1: 0.092538, loss_fp: 0.001840, loss_freq: 0.032007
[03:46:37.294] iteration 7428: loss: 0.062820, loss_s1: 0.020865, loss_fp: 0.001776, loss_freq: 0.022618
[03:46:37.888] iteration 7429: loss: 0.115857, loss_s1: 0.062398, loss_fp: 0.001911, loss_freq: 0.085655
[03:46:38.479] iteration 7430: loss: 0.109231, loss_s1: 0.078011, loss_fp: 0.000659, loss_freq: 0.043232
[03:46:39.077] iteration 7431: loss: 0.056746, loss_s1: 0.050346, loss_fp: 0.002485, loss_freq: 0.008037
[03:46:39.667] iteration 7432: loss: 0.081388, loss_s1: 0.066448, loss_fp: 0.000698, loss_freq: 0.036938
[03:46:40.263] iteration 7433: loss: 0.094037, loss_s1: 0.047863, loss_fp: 0.003774, loss_freq: 0.035103
[03:46:40.851] iteration 7434: loss: 0.061768, loss_s1: 0.031524, loss_fp: 0.001654, loss_freq: 0.037515
[03:46:41.444] iteration 7435: loss: 0.122252, loss_s1: 0.067176, loss_fp: 0.005192, loss_freq: 0.042392
[03:46:42.039] iteration 7436: loss: 0.063348, loss_s1: 0.024932, loss_fp: 0.000916, loss_freq: 0.031123
[03:46:42.634] iteration 7437: loss: 0.088541, loss_s1: 0.061885, loss_fp: 0.023749, loss_freq: 0.039862
[03:46:43.222] iteration 7438: loss: 0.135514, loss_s1: 0.067438, loss_fp: 0.004559, loss_freq: 0.088966
[03:46:43.815] iteration 7439: loss: 0.090781, loss_s1: 0.095346, loss_fp: 0.003615, loss_freq: 0.022393
[03:46:44.530] iteration 7440: loss: 0.081715, loss_s1: 0.053373, loss_fp: 0.012064, loss_freq: 0.035729
[03:46:45.168] iteration 7441: loss: 0.076044, loss_s1: 0.069340, loss_fp: 0.002204, loss_freq: 0.030120
[03:46:45.912] iteration 7442: loss: 0.107902, loss_s1: 0.069830, loss_fp: 0.001655, loss_freq: 0.014443
[03:46:46.648] iteration 7443: loss: 0.126934, loss_s1: 0.105499, loss_fp: 0.000588, loss_freq: 0.082826
[03:46:47.242] iteration 7444: loss: 0.103807, loss_s1: 0.097674, loss_fp: 0.003563, loss_freq: 0.041525
[03:46:47.843] iteration 7445: loss: 0.092373, loss_s1: 0.079253, loss_fp: 0.003555, loss_freq: 0.049824
[03:46:48.462] iteration 7446: loss: 0.056557, loss_s1: 0.015336, loss_fp: 0.000855, loss_freq: 0.033194
[03:46:49.052] iteration 7447: loss: 0.123841, loss_s1: 0.050886, loss_fp: 0.000583, loss_freq: 0.019141
[03:46:49.702] iteration 7448: loss: 0.116977, loss_s1: 0.120881, loss_fp: 0.007236, loss_freq: 0.045971
[03:46:50.333] iteration 7449: loss: 0.120834, loss_s1: 0.098904, loss_fp: 0.005755, loss_freq: 0.067040
[03:46:50.920] iteration 7450: loss: 0.097650, loss_s1: 0.112369, loss_fp: 0.006358, loss_freq: 0.034226
[03:46:51.509] iteration 7451: loss: 0.117202, loss_s1: 0.068609, loss_fp: 0.008041, loss_freq: 0.030178
[03:46:52.102] iteration 7452: loss: 0.118774, loss_s1: 0.071212, loss_fp: 0.001068, loss_freq: 0.077632
[03:46:52.696] iteration 7453: loss: 0.075502, loss_s1: 0.032139, loss_fp: 0.004051, loss_freq: 0.043466
[03:46:53.294] iteration 7454: loss: 0.105314, loss_s1: 0.097599, loss_fp: 0.008505, loss_freq: 0.017248
[03:46:53.881] iteration 7455: loss: 0.095874, loss_s1: 0.071567, loss_fp: 0.013114, loss_freq: 0.027082
[03:46:54.469] iteration 7456: loss: 0.086241, loss_s1: 0.058347, loss_fp: 0.004193, loss_freq: 0.046475
[03:46:55.065] iteration 7457: loss: 0.098278, loss_s1: 0.071227, loss_fp: 0.009082, loss_freq: 0.034770
[03:46:55.663] iteration 7458: loss: 0.129342, loss_s1: 0.124282, loss_fp: 0.003111, loss_freq: 0.065794
[03:46:56.250] iteration 7459: loss: 0.135742, loss_s1: 0.151088, loss_fp: 0.010464, loss_freq: 0.059598
[03:46:56.843] iteration 7460: loss: 0.090337, loss_s1: 0.040510, loss_fp: 0.002121, loss_freq: 0.041524
[03:46:57.434] iteration 7461: loss: 0.095854, loss_s1: 0.072681, loss_fp: 0.008945, loss_freq: 0.028434
[03:46:58.031] iteration 7462: loss: 0.127478, loss_s1: 0.126096, loss_fp: 0.001809, loss_freq: 0.043844
[03:46:58.703] iteration 7463: loss: 0.129421, loss_s1: 0.095761, loss_fp: 0.006784, loss_freq: 0.059243
[03:46:59.335] iteration 7464: loss: 0.088886, loss_s1: 0.065548, loss_fp: 0.006935, loss_freq: 0.030543
[03:46:59.971] iteration 7465: loss: 0.140082, loss_s1: 0.104559, loss_fp: 0.012111, loss_freq: 0.050381
[03:47:00.603] iteration 7466: loss: 0.092146, loss_s1: 0.035087, loss_fp: 0.001481, loss_freq: 0.044410
[03:47:01.237] iteration 7467: loss: 0.116201, loss_s1: 0.044481, loss_fp: 0.002787, loss_freq: 0.059886
[03:47:01.864] iteration 7468: loss: 0.135439, loss_s1: 0.085006, loss_fp: 0.000952, loss_freq: 0.098409
[03:47:02.481] iteration 7469: loss: 0.064932, loss_s1: 0.035123, loss_fp: 0.004947, loss_freq: 0.026432
[03:47:03.073] iteration 7470: loss: 0.125436, loss_s1: 0.100394, loss_fp: 0.002720, loss_freq: 0.040190
[03:47:03.662] iteration 7471: loss: 0.083031, loss_s1: 0.077379, loss_fp: 0.001662, loss_freq: 0.008138
[03:47:04.257] iteration 7472: loss: 0.073677, loss_s1: 0.063129, loss_fp: 0.001911, loss_freq: 0.023930
[03:47:04.847] iteration 7473: loss: 0.077607, loss_s1: 0.019041, loss_fp: 0.005086, loss_freq: 0.021920
[03:47:05.439] iteration 7474: loss: 0.106738, loss_s1: 0.103858, loss_fp: 0.000620, loss_freq: 0.039045
[03:47:06.035] iteration 7475: loss: 0.064702, loss_s1: 0.034007, loss_fp: 0.001018, loss_freq: 0.017832
[03:47:06.656] iteration 7476: loss: 0.140382, loss_s1: 0.055543, loss_fp: 0.003612, loss_freq: 0.112114
[03:47:07.286] iteration 7477: loss: 0.113166, loss_s1: 0.051513, loss_fp: 0.001743, loss_freq: 0.071397
[03:47:07.913] iteration 7478: loss: 0.104235, loss_s1: 0.125407, loss_fp: 0.002762, loss_freq: 0.014196
[03:47:08.537] iteration 7479: loss: 0.093213, loss_s1: 0.078774, loss_fp: 0.000729, loss_freq: 0.049965
[03:47:09.160] iteration 7480: loss: 0.110019, loss_s1: 0.069657, loss_fp: 0.000848, loss_freq: 0.076320
[03:47:10.120] iteration 7481: loss: 0.085170, loss_s1: 0.059556, loss_fp: 0.002694, loss_freq: 0.014763
[03:47:10.753] iteration 7482: loss: 0.092266, loss_s1: 0.057639, loss_fp: 0.001519, loss_freq: 0.054502
[03:47:11.376] iteration 7483: loss: 0.098356, loss_s1: 0.075267, loss_fp: 0.000628, loss_freq: 0.046747
[03:47:11.968] iteration 7484: loss: 0.144446, loss_s1: 0.109389, loss_fp: 0.001285, loss_freq: 0.027863
[03:47:12.563] iteration 7485: loss: 0.065872, loss_s1: 0.044161, loss_fp: 0.002011, loss_freq: 0.026574
[03:47:13.157] iteration 7486: loss: 0.132631, loss_s1: 0.091618, loss_fp: 0.002128, loss_freq: 0.028253
[03:47:13.749] iteration 7487: loss: 0.112309, loss_s1: 0.085661, loss_fp: 0.002491, loss_freq: 0.034456
[03:47:14.347] iteration 7488: loss: 0.095456, loss_s1: 0.075100, loss_fp: 0.001699, loss_freq: 0.023618
[03:47:14.945] iteration 7489: loss: 0.081905, loss_s1: 0.054945, loss_fp: 0.006587, loss_freq: 0.050574
[03:47:15.534] iteration 7490: loss: 0.134996, loss_s1: 0.099814, loss_fp: 0.007170, loss_freq: 0.033716
[03:47:16.128] iteration 7491: loss: 0.110189, loss_s1: 0.066873, loss_fp: 0.001683, loss_freq: 0.052080
[03:47:16.801] iteration 7492: loss: 0.090631, loss_s1: 0.028457, loss_fp: 0.001047, loss_freq: 0.089613
[03:47:17.433] iteration 7493: loss: 0.074943, loss_s1: 0.036771, loss_fp: 0.004838, loss_freq: 0.032828
[03:47:18.066] iteration 7494: loss: 0.108475, loss_s1: 0.115497, loss_fp: 0.002805, loss_freq: 0.032009
[03:47:18.724] iteration 7495: loss: 0.108882, loss_s1: 0.091606, loss_fp: 0.002670, loss_freq: 0.021220
[03:47:19.329] iteration 7496: loss: 0.145155, loss_s1: 0.139942, loss_fp: 0.001780, loss_freq: 0.067035
[03:47:19.925] iteration 7497: loss: 0.157020, loss_s1: 0.179092, loss_fp: 0.002566, loss_freq: 0.066440
[03:47:20.512] iteration 7498: loss: 0.097098, loss_s1: 0.040639, loss_fp: 0.002577, loss_freq: 0.026670
[03:47:21.100] iteration 7499: loss: 0.091452, loss_s1: 0.101043, loss_fp: 0.003557, loss_freq: 0.024007
[03:47:21.691] iteration 7500: loss: 0.093579, loss_s1: 0.060373, loss_fp: 0.003282, loss_freq: 0.042784
[03:47:22.274] iteration 7501: loss: 0.068207, loss_s1: 0.053267, loss_fp: 0.003027, loss_freq: 0.015472
[03:47:22.869] iteration 7502: loss: 0.096109, loss_s1: 0.031725, loss_fp: 0.011589, loss_freq: 0.068955
[03:47:23.460] iteration 7503: loss: 0.110010, loss_s1: 0.072172, loss_fp: 0.003062, loss_freq: 0.033766
[03:47:24.051] iteration 7504: loss: 0.084264, loss_s1: 0.029801, loss_fp: 0.002764, loss_freq: 0.033935
[03:47:24.640] iteration 7505: loss: 0.078681, loss_s1: 0.038549, loss_fp: 0.001830, loss_freq: 0.036741
[03:47:25.231] iteration 7506: loss: 0.095963, loss_s1: 0.070997, loss_fp: 0.002319, loss_freq: 0.059309
[03:47:25.822] iteration 7507: loss: 0.140142, loss_s1: 0.105666, loss_fp: 0.001565, loss_freq: 0.024759
[03:47:26.413] iteration 7508: loss: 0.120360, loss_s1: 0.096728, loss_fp: 0.005721, loss_freq: 0.035323
[03:47:27.000] iteration 7509: loss: 0.094292, loss_s1: 0.063299, loss_fp: 0.001965, loss_freq: 0.046806
[03:47:27.591] iteration 7510: loss: 0.107988, loss_s1: 0.115902, loss_fp: 0.000419, loss_freq: 0.036060
[03:47:28.176] iteration 7511: loss: 0.120998, loss_s1: 0.124446, loss_fp: 0.001570, loss_freq: 0.033473
[03:47:28.767] iteration 7512: loss: 0.113250, loss_s1: 0.082716, loss_fp: 0.001770, loss_freq: 0.048620
[03:47:29.362] iteration 7513: loss: 0.120338, loss_s1: 0.107669, loss_fp: 0.000716, loss_freq: 0.038083
[03:47:29.960] iteration 7514: loss: 0.073809, loss_s1: 0.024881, loss_fp: 0.000860, loss_freq: 0.009592
[03:47:30.559] iteration 7515: loss: 0.101365, loss_s1: 0.103887, loss_fp: 0.001534, loss_freq: 0.025369
[03:47:31.193] iteration 7516: loss: 0.133929, loss_s1: 0.063778, loss_fp: 0.002285, loss_freq: 0.048329
[03:47:31.830] iteration 7517: loss: 0.099449, loss_s1: 0.086928, loss_fp: 0.001679, loss_freq: 0.034107
[03:47:32.435] iteration 7518: loss: 0.061540, loss_s1: 0.048947, loss_fp: 0.000343, loss_freq: 0.016125
[03:47:33.057] iteration 7519: loss: 0.106306, loss_s1: 0.109459, loss_fp: 0.004575, loss_freq: 0.037301
[03:47:33.654] iteration 7520: loss: 0.111649, loss_s1: 0.095469, loss_fp: 0.001961, loss_freq: 0.067088
[03:47:34.245] iteration 7521: loss: 0.179998, loss_s1: 0.106321, loss_fp: 0.010008, loss_freq: 0.158357
[03:47:34.838] iteration 7522: loss: 0.100303, loss_s1: 0.066924, loss_fp: 0.005980, loss_freq: 0.054862
[03:47:35.427] iteration 7523: loss: 0.119480, loss_s1: 0.102184, loss_fp: 0.002391, loss_freq: 0.075534
[03:47:36.018] iteration 7524: loss: 0.143308, loss_s1: 0.149951, loss_fp: 0.000965, loss_freq: 0.054792
[03:47:36.613] iteration 7525: loss: 0.084646, loss_s1: 0.067922, loss_fp: 0.008652, loss_freq: 0.015042
[03:47:37.206] iteration 7526: loss: 0.106373, loss_s1: 0.086016, loss_fp: 0.001055, loss_freq: 0.046610
[03:47:37.843] iteration 7527: loss: 0.077259, loss_s1: 0.058440, loss_fp: 0.001908, loss_freq: 0.010173
[03:47:38.437] iteration 7528: loss: 0.075726, loss_s1: 0.039793, loss_fp: 0.002565, loss_freq: 0.023404
[03:47:39.026] iteration 7529: loss: 0.099997, loss_s1: 0.083935, loss_fp: 0.001235, loss_freq: 0.018583
[03:47:39.617] iteration 7530: loss: 0.080654, loss_s1: 0.032638, loss_fp: 0.001643, loss_freq: 0.038499
[03:47:40.205] iteration 7531: loss: 0.101854, loss_s1: 0.083479, loss_fp: 0.001264, loss_freq: 0.040656
[03:47:40.788] iteration 7532: loss: 0.115513, loss_s1: 0.113191, loss_fp: 0.004646, loss_freq: 0.020858
[03:47:41.372] iteration 7533: loss: 0.104397, loss_s1: 0.099127, loss_fp: 0.000527, loss_freq: 0.027299
[03:47:41.963] iteration 7534: loss: 0.111918, loss_s1: 0.086559, loss_fp: 0.004703, loss_freq: 0.070501
[03:47:42.559] iteration 7535: loss: 0.106713, loss_s1: 0.053370, loss_fp: 0.003859, loss_freq: 0.044979
[03:47:43.154] iteration 7536: loss: 0.056681, loss_s1: 0.043727, loss_fp: 0.000364, loss_freq: 0.010789
[03:47:43.746] iteration 7537: loss: 0.085896, loss_s1: 0.060283, loss_fp: 0.001596, loss_freq: 0.044329
[03:47:44.394] iteration 7538: loss: 0.079244, loss_s1: 0.074701, loss_fp: 0.000847, loss_freq: 0.015805
[03:47:44.982] iteration 7539: loss: 0.072628, loss_s1: 0.041729, loss_fp: 0.000970, loss_freq: 0.030302
[03:47:45.570] iteration 7540: loss: 0.090213, loss_s1: 0.068859, loss_fp: 0.006450, loss_freq: 0.046622
[03:47:46.161] iteration 7541: loss: 0.065987, loss_s1: 0.066058, loss_fp: 0.000955, loss_freq: 0.018174
[03:47:46.746] iteration 7542: loss: 0.095082, loss_s1: 0.028629, loss_fp: 0.003134, loss_freq: 0.079915
[03:47:47.333] iteration 7543: loss: 0.052923, loss_s1: 0.021964, loss_fp: 0.001256, loss_freq: 0.020563
[03:47:47.918] iteration 7544: loss: 0.084779, loss_s1: 0.067277, loss_fp: 0.003590, loss_freq: 0.026962
[03:47:48.511] iteration 7545: loss: 0.170957, loss_s1: 0.196319, loss_fp: 0.008528, loss_freq: 0.013405
[03:47:49.108] iteration 7546: loss: 0.120367, loss_s1: 0.134964, loss_fp: 0.002777, loss_freq: 0.049834
[03:47:49.698] iteration 7547: loss: 0.101946, loss_s1: 0.096791, loss_fp: 0.002621, loss_freq: 0.011849
[03:47:50.287] iteration 7548: loss: 0.123028, loss_s1: 0.073363, loss_fp: 0.005400, loss_freq: 0.108612
[03:47:50.878] iteration 7549: loss: 0.068328, loss_s1: 0.040032, loss_fp: 0.001963, loss_freq: 0.031984
[03:47:51.472] iteration 7550: loss: 0.058898, loss_s1: 0.034656, loss_fp: 0.002674, loss_freq: 0.030958
[03:47:52.058] iteration 7551: loss: 0.135389, loss_s1: 0.065721, loss_fp: 0.002729, loss_freq: 0.055471
[03:47:52.649] iteration 7552: loss: 0.073504, loss_s1: 0.024692, loss_fp: 0.005468, loss_freq: 0.049448
[03:47:53.240] iteration 7553: loss: 0.104989, loss_s1: 0.054784, loss_fp: 0.023234, loss_freq: 0.052260
[03:47:53.832] iteration 7554: loss: 0.124768, loss_s1: 0.123577, loss_fp: 0.002514, loss_freq: 0.044293
[03:47:54.417] iteration 7555: loss: 0.145785, loss_s1: 0.086474, loss_fp: 0.001928, loss_freq: 0.067745
[03:47:55.008] iteration 7556: loss: 0.072375, loss_s1: 0.042984, loss_fp: 0.004647, loss_freq: 0.022140
[03:47:55.609] iteration 7557: loss: 0.083040, loss_s1: 0.082825, loss_fp: 0.005086, loss_freq: 0.021381
[03:47:56.197] iteration 7558: loss: 0.127511, loss_s1: 0.092779, loss_fp: 0.004506, loss_freq: 0.070278
[03:47:56.788] iteration 7559: loss: 0.099116, loss_s1: 0.064422, loss_fp: 0.001933, loss_freq: 0.065125
[03:47:57.378] iteration 7560: loss: 0.116314, loss_s1: 0.069280, loss_fp: 0.004428, loss_freq: 0.036741
[03:47:57.972] iteration 7561: loss: 0.151688, loss_s1: 0.132062, loss_fp: 0.003080, loss_freq: 0.061775
[03:47:58.565] iteration 7562: loss: 0.073314, loss_s1: 0.060342, loss_fp: 0.001402, loss_freq: 0.032931
[03:47:59.156] iteration 7563: loss: 0.152415, loss_s1: 0.102270, loss_fp: 0.003838, loss_freq: 0.069512
[03:47:59.744] iteration 7564: loss: 0.107616, loss_s1: 0.070662, loss_fp: 0.001211, loss_freq: 0.021733
[03:48:00.338] iteration 7565: loss: 0.107038, loss_s1: 0.083830, loss_fp: 0.000907, loss_freq: 0.063210
[03:48:00.928] iteration 7566: loss: 0.077312, loss_s1: 0.045348, loss_fp: 0.001990, loss_freq: 0.048040
[03:48:01.518] iteration 7567: loss: 0.086242, loss_s1: 0.084675, loss_fp: 0.003701, loss_freq: 0.033247
[03:48:02.165] iteration 7568: loss: 0.085695, loss_s1: 0.066454, loss_fp: 0.002462, loss_freq: 0.032184
[03:48:02.758] iteration 7569: loss: 0.081781, loss_s1: 0.046868, loss_fp: 0.002357, loss_freq: 0.046090
[03:48:03.353] iteration 7570: loss: 0.130264, loss_s1: 0.117365, loss_fp: 0.001667, loss_freq: 0.020619
[03:48:03.941] iteration 7571: loss: 0.121765, loss_s1: 0.043736, loss_fp: 0.003154, loss_freq: 0.062607
[03:48:04.528] iteration 7572: loss: 0.131575, loss_s1: 0.130409, loss_fp: 0.003259, loss_freq: 0.066838
[03:48:05.114] iteration 7573: loss: 0.197325, loss_s1: 0.129919, loss_fp: 0.004559, loss_freq: 0.106772
[03:48:05.702] iteration 7574: loss: 0.084075, loss_s1: 0.025325, loss_fp: 0.000906, loss_freq: 0.030305
[03:48:06.288] iteration 7575: loss: 0.122217, loss_s1: 0.070965, loss_fp: 0.003218, loss_freq: 0.060729
[03:48:06.874] iteration 7576: loss: 0.105723, loss_s1: 0.106828, loss_fp: 0.001994, loss_freq: 0.047233
[03:48:07.459] iteration 7577: loss: 0.120241, loss_s1: 0.065356, loss_fp: 0.017443, loss_freq: 0.059661
[03:48:08.045] iteration 7578: loss: 0.094638, loss_s1: 0.087638, loss_fp: 0.003131, loss_freq: 0.026551
[03:48:08.687] iteration 7579: loss: 0.082895, loss_s1: 0.059930, loss_fp: 0.001569, loss_freq: 0.026000
[03:48:09.302] iteration 7580: loss: 0.061938, loss_s1: 0.050959, loss_fp: 0.001449, loss_freq: 0.005694
[03:48:09.893] iteration 7581: loss: 0.087514, loss_s1: 0.056751, loss_fp: 0.006568, loss_freq: 0.024326
[03:48:10.493] iteration 7582: loss: 0.127330, loss_s1: 0.100748, loss_fp: 0.000412, loss_freq: 0.055101
[03:48:11.088] iteration 7583: loss: 0.065443, loss_s1: 0.035116, loss_fp: 0.001046, loss_freq: 0.034466
[03:48:11.684] iteration 7584: loss: 0.101327, loss_s1: 0.079656, loss_fp: 0.005532, loss_freq: 0.024071
[03:48:12.281] iteration 7585: loss: 0.085875, loss_s1: 0.061047, loss_fp: 0.004925, loss_freq: 0.050081
[03:48:12.873] iteration 7586: loss: 0.093662, loss_s1: 0.048983, loss_fp: 0.000902, loss_freq: 0.022721
[03:48:13.474] iteration 7587: loss: 0.079989, loss_s1: 0.058873, loss_fp: 0.001543, loss_freq: 0.040109
[03:48:14.067] iteration 7588: loss: 0.063072, loss_s1: 0.034834, loss_fp: 0.000521, loss_freq: 0.028146
[03:48:14.662] iteration 7589: loss: 0.223922, loss_s1: 0.165158, loss_fp: 0.006219, loss_freq: 0.194042
[03:48:15.255] iteration 7590: loss: 0.070591, loss_s1: 0.023901, loss_fp: 0.000935, loss_freq: 0.020848
[03:48:15.843] iteration 7591: loss: 0.067734, loss_s1: 0.056226, loss_fp: 0.001047, loss_freq: 0.013425
[03:48:16.434] iteration 7592: loss: 0.103927, loss_s1: 0.070142, loss_fp: 0.001365, loss_freq: 0.040303
[03:48:17.023] iteration 7593: loss: 0.062139, loss_s1: 0.041497, loss_fp: 0.000809, loss_freq: 0.031255
[03:48:17.614] iteration 7594: loss: 0.058242, loss_s1: 0.033175, loss_fp: 0.002413, loss_freq: 0.010887
[03:48:18.210] iteration 7595: loss: 0.169048, loss_s1: 0.153660, loss_fp: 0.007952, loss_freq: 0.082874
[03:48:18.803] iteration 7596: loss: 0.077104, loss_s1: 0.041033, loss_fp: 0.000505, loss_freq: 0.046520
[03:48:19.391] iteration 7597: loss: 0.109841, loss_s1: 0.064869, loss_fp: 0.001992, loss_freq: 0.070431
[03:48:20.024] iteration 7598: loss: 0.071756, loss_s1: 0.070902, loss_fp: 0.002874, loss_freq: 0.016419
[03:48:20.654] iteration 7599: loss: 0.108178, loss_s1: 0.055014, loss_fp: 0.007160, loss_freq: 0.089037
[03:48:21.292] iteration 7600: loss: 0.064950, loss_s1: 0.012617, loss_fp: 0.001444, loss_freq: 0.006634
[03:48:24.672] iteration 7600 : mean_dice : 0.657139
[03:48:25.344] iteration 7601: loss: 0.075980, loss_s1: 0.044717, loss_fp: 0.000354, loss_freq: 0.012087
[03:48:25.972] iteration 7602: loss: 0.101772, loss_s1: 0.105619, loss_fp: 0.008538, loss_freq: 0.016315
[03:48:26.603] iteration 7603: loss: 0.125580, loss_s1: 0.102148, loss_fp: 0.014108, loss_freq: 0.039850
[03:48:27.237] iteration 7604: loss: 0.086974, loss_s1: 0.063453, loss_fp: 0.007770, loss_freq: 0.049557
[03:48:27.824] iteration 7605: loss: 0.141124, loss_s1: 0.109414, loss_fp: 0.006592, loss_freq: 0.056049
[03:48:28.420] iteration 7606: loss: 0.055122, loss_s1: 0.015859, loss_fp: 0.001473, loss_freq: 0.013156
[03:48:29.009] iteration 7607: loss: 0.102839, loss_s1: 0.062605, loss_fp: 0.002936, loss_freq: 0.096386
[03:48:29.632] iteration 7608: loss: 0.140013, loss_s1: 0.123241, loss_fp: 0.003727, loss_freq: 0.073802
[03:48:30.269] iteration 7609: loss: 0.070170, loss_s1: 0.038353, loss_fp: 0.005004, loss_freq: 0.015058
[03:48:30.903] iteration 7610: loss: 0.118747, loss_s1: 0.114712, loss_fp: 0.004358, loss_freq: 0.060445
[03:48:31.523] iteration 7611: loss: 0.093750, loss_s1: 0.108751, loss_fp: 0.014373, loss_freq: 0.016796
[03:48:32.115] iteration 7612: loss: 0.095216, loss_s1: 0.025457, loss_fp: 0.000867, loss_freq: 0.029171
[03:48:32.703] iteration 7613: loss: 0.120289, loss_s1: 0.110741, loss_fp: 0.003549, loss_freq: 0.048046
[03:48:33.297] iteration 7614: loss: 0.083144, loss_s1: 0.069286, loss_fp: 0.001292, loss_freq: 0.037476
[03:48:33.890] iteration 7615: loss: 0.106502, loss_s1: 0.064723, loss_fp: 0.002507, loss_freq: 0.046866
[03:48:34.480] iteration 7616: loss: 0.081980, loss_s1: 0.057132, loss_fp: 0.004286, loss_freq: 0.051045
[03:48:35.067] iteration 7617: loss: 0.109119, loss_s1: 0.072635, loss_fp: 0.002189, loss_freq: 0.030093
[03:48:35.653] iteration 7618: loss: 0.101762, loss_s1: 0.078238, loss_fp: 0.004200, loss_freq: 0.057953
[03:48:36.242] iteration 7619: loss: 0.093680, loss_s1: 0.052807, loss_fp: 0.002620, loss_freq: 0.056338
[03:48:36.834] iteration 7620: loss: 0.112077, loss_s1: 0.096580, loss_fp: 0.011607, loss_freq: 0.042555
[03:48:37.425] iteration 7621: loss: 0.142059, loss_s1: 0.146665, loss_fp: 0.006654, loss_freq: 0.032612
[03:48:38.016] iteration 7622: loss: 0.095315, loss_s1: 0.065857, loss_fp: 0.001529, loss_freq: 0.031846
[03:48:38.605] iteration 7623: loss: 0.141721, loss_s1: 0.106799, loss_fp: 0.005898, loss_freq: 0.050592
[03:48:39.197] iteration 7624: loss: 0.121146, loss_s1: 0.112768, loss_fp: 0.005125, loss_freq: 0.021398
[03:48:39.790] iteration 7625: loss: 0.069539, loss_s1: 0.028404, loss_fp: 0.007789, loss_freq: 0.031137
[03:48:40.384] iteration 7626: loss: 0.092501, loss_s1: 0.056540, loss_fp: 0.005196, loss_freq: 0.031847
[03:48:40.987] iteration 7627: loss: 0.073272, loss_s1: 0.032438, loss_fp: 0.004025, loss_freq: 0.038594
[03:48:41.575] iteration 7628: loss: 0.145052, loss_s1: 0.131315, loss_fp: 0.004029, loss_freq: 0.089813
[03:48:42.217] iteration 7629: loss: 0.130670, loss_s1: 0.065472, loss_fp: 0.006033, loss_freq: 0.077584
[03:48:42.917] iteration 7630: loss: 0.115906, loss_s1: 0.062440, loss_fp: 0.010939, loss_freq: 0.037395
[03:48:43.605] iteration 7631: loss: 0.085507, loss_s1: 0.048182, loss_fp: 0.005920, loss_freq: 0.033158
[03:48:44.295] iteration 7632: loss: 0.090753, loss_s1: 0.074313, loss_fp: 0.007940, loss_freq: 0.034775
[03:48:45.033] iteration 7633: loss: 0.163101, loss_s1: 0.146168, loss_fp: 0.004763, loss_freq: 0.073050
[03:48:45.683] iteration 7634: loss: 0.082281, loss_s1: 0.080936, loss_fp: 0.003294, loss_freq: 0.027434
[03:48:46.373] iteration 7635: loss: 0.101832, loss_s1: 0.079706, loss_fp: 0.009049, loss_freq: 0.030300
[03:48:47.005] iteration 7636: loss: 0.134558, loss_s1: 0.091325, loss_fp: 0.002060, loss_freq: 0.037947
[03:48:47.752] iteration 7637: loss: 0.117802, loss_s1: 0.076757, loss_fp: 0.001688, loss_freq: 0.029656
[03:48:48.376] iteration 7638: loss: 0.172298, loss_s1: 0.157238, loss_fp: 0.010581, loss_freq: 0.051273
[03:48:49.285] iteration 7639: loss: 0.136626, loss_s1: 0.131130, loss_fp: 0.001161, loss_freq: 0.059006
[03:48:50.066] iteration 7640: loss: 0.118882, loss_s1: 0.099024, loss_fp: 0.002502, loss_freq: 0.026007
[03:48:50.829] iteration 7641: loss: 0.148757, loss_s1: 0.072262, loss_fp: 0.000860, loss_freq: 0.021965
[03:48:51.564] iteration 7642: loss: 0.073553, loss_s1: 0.047229, loss_fp: 0.007800, loss_freq: 0.020090
[03:48:52.397] iteration 7643: loss: 0.105598, loss_s1: 0.074521, loss_fp: 0.002080, loss_freq: 0.030551
[03:48:52.995] iteration 7644: loss: 0.053497, loss_s1: 0.026429, loss_fp: 0.000975, loss_freq: 0.018693
[03:48:53.662] iteration 7645: loss: 0.053403, loss_s1: 0.013431, loss_fp: 0.000975, loss_freq: 0.019795
[03:48:54.269] iteration 7646: loss: 0.070258, loss_s1: 0.048720, loss_fp: 0.001869, loss_freq: 0.024154
[03:48:54.877] iteration 7647: loss: 0.072509, loss_s1: 0.038747, loss_fp: 0.000644, loss_freq: 0.035199
[03:48:55.478] iteration 7648: loss: 0.076394, loss_s1: 0.045263, loss_fp: 0.004052, loss_freq: 0.031478
[03:48:56.068] iteration 7649: loss: 0.091217, loss_s1: 0.060483, loss_fp: 0.002570, loss_freq: 0.048461
[03:48:56.657] iteration 7650: loss: 0.104318, loss_s1: 0.080530, loss_fp: 0.002267, loss_freq: 0.064417
[03:48:57.597] iteration 7651: loss: 0.094716, loss_s1: 0.040136, loss_fp: 0.001790, loss_freq: 0.023500
[03:48:58.204] iteration 7652: loss: 0.071176, loss_s1: 0.040947, loss_fp: 0.000985, loss_freq: 0.025040
[03:48:58.800] iteration 7653: loss: 0.058417, loss_s1: 0.044987, loss_fp: 0.001903, loss_freq: 0.008200
[03:48:59.395] iteration 7654: loss: 0.093593, loss_s1: 0.074355, loss_fp: 0.000411, loss_freq: 0.016565
[03:48:59.992] iteration 7655: loss: 0.079564, loss_s1: 0.061720, loss_fp: 0.000917, loss_freq: 0.020534
[03:49:00.586] iteration 7656: loss: 0.103018, loss_s1: 0.060173, loss_fp: 0.001099, loss_freq: 0.036308
[03:49:01.182] iteration 7657: loss: 0.077555, loss_s1: 0.065155, loss_fp: 0.009217, loss_freq: 0.012237
[03:49:01.774] iteration 7658: loss: 0.071746, loss_s1: 0.037845, loss_fp: 0.002156, loss_freq: 0.028946
[03:49:02.367] iteration 7659: loss: 0.056615, loss_s1: 0.047083, loss_fp: 0.001340, loss_freq: 0.017367
[03:49:02.964] iteration 7660: loss: 0.096707, loss_s1: 0.084280, loss_fp: 0.004440, loss_freq: 0.024062
[03:49:03.552] iteration 7661: loss: 0.089640, loss_s1: 0.016822, loss_fp: 0.001606, loss_freq: 0.083806
[03:49:04.138] iteration 7662: loss: 0.132431, loss_s1: 0.128831, loss_fp: 0.001471, loss_freq: 0.077065
[03:49:04.734] iteration 7663: loss: 0.107922, loss_s1: 0.073097, loss_fp: 0.000569, loss_freq: 0.065474
[03:49:05.324] iteration 7664: loss: 0.064579, loss_s1: 0.033212, loss_fp: 0.001408, loss_freq: 0.022002
[03:49:05.910] iteration 7665: loss: 0.091652, loss_s1: 0.041761, loss_fp: 0.001104, loss_freq: 0.036321
[03:49:06.503] iteration 7666: loss: 0.109471, loss_s1: 0.060123, loss_fp: 0.001781, loss_freq: 0.055032
[03:49:07.089] iteration 7667: loss: 0.106510, loss_s1: 0.075817, loss_fp: 0.005331, loss_freq: 0.065399
[03:49:07.698] iteration 7668: loss: 0.105057, loss_s1: 0.069481, loss_fp: 0.001086, loss_freq: 0.020807
[03:49:08.288] iteration 7669: loss: 0.078108, loss_s1: 0.054812, loss_fp: 0.001947, loss_freq: 0.049098
[03:49:08.891] iteration 7670: loss: 0.089512, loss_s1: 0.062962, loss_fp: 0.003910, loss_freq: 0.034770
[03:49:09.531] iteration 7671: loss: 0.072494, loss_s1: 0.033064, loss_fp: 0.002688, loss_freq: 0.055414
[03:49:10.329] iteration 7672: loss: 0.065842, loss_s1: 0.055725, loss_fp: 0.003911, loss_freq: 0.016714
[03:49:11.243] iteration 7673: loss: 0.105013, loss_s1: 0.067098, loss_fp: 0.002598, loss_freq: 0.033927
[03:49:12.025] iteration 7674: loss: 0.095155, loss_s1: 0.036523, loss_fp: 0.000704, loss_freq: 0.020735
[03:49:12.767] iteration 7675: loss: 0.090246, loss_s1: 0.039353, loss_fp: 0.005114, loss_freq: 0.076299
[03:49:13.354] iteration 7676: loss: 0.072218, loss_s1: 0.053574, loss_fp: 0.001357, loss_freq: 0.049114
[03:49:13.982] iteration 7677: loss: 0.086628, loss_s1: 0.068169, loss_fp: 0.003513, loss_freq: 0.019018
[03:49:14.579] iteration 7678: loss: 0.140614, loss_s1: 0.138826, loss_fp: 0.001922, loss_freq: 0.064794
[03:49:15.180] iteration 7679: loss: 0.069405, loss_s1: 0.054708, loss_fp: 0.001720, loss_freq: 0.013692
[03:49:15.786] iteration 7680: loss: 0.081614, loss_s1: 0.061910, loss_fp: 0.005762, loss_freq: 0.032486
[03:49:16.400] iteration 7681: loss: 0.065890, loss_s1: 0.053893, loss_fp: 0.001177, loss_freq: 0.029324
[03:49:16.985] iteration 7682: loss: 0.122246, loss_s1: 0.081962, loss_fp: 0.002154, loss_freq: 0.065643
[03:49:17.571] iteration 7683: loss: 0.070921, loss_s1: 0.048035, loss_fp: 0.002592, loss_freq: 0.031050
[03:49:18.157] iteration 7684: loss: 0.079142, loss_s1: 0.062387, loss_fp: 0.005984, loss_freq: 0.012605
[03:49:18.748] iteration 7685: loss: 0.101800, loss_s1: 0.126747, loss_fp: 0.001666, loss_freq: 0.032803
[03:49:19.337] iteration 7686: loss: 0.071442, loss_s1: 0.041730, loss_fp: 0.000687, loss_freq: 0.019102
[03:49:19.924] iteration 7687: loss: 0.092974, loss_s1: 0.061528, loss_fp: 0.003200, loss_freq: 0.041238
[03:49:20.511] iteration 7688: loss: 0.104757, loss_s1: 0.089644, loss_fp: 0.000735, loss_freq: 0.019597
[03:49:21.100] iteration 7689: loss: 0.100668, loss_s1: 0.100815, loss_fp: 0.002425, loss_freq: 0.037725
[03:49:21.690] iteration 7690: loss: 0.111822, loss_s1: 0.076405, loss_fp: 0.001731, loss_freq: 0.075248
[03:49:22.281] iteration 7691: loss: 0.127037, loss_s1: 0.103190, loss_fp: 0.000692, loss_freq: 0.055880
[03:49:22.873] iteration 7692: loss: 0.094458, loss_s1: 0.088750, loss_fp: 0.006650, loss_freq: 0.039668
[03:49:23.460] iteration 7693: loss: 0.091544, loss_s1: 0.088036, loss_fp: 0.001737, loss_freq: 0.027663
[03:49:24.049] iteration 7694: loss: 0.101780, loss_s1: 0.089556, loss_fp: 0.005216, loss_freq: 0.058380
[03:49:24.636] iteration 7695: loss: 0.115851, loss_s1: 0.108572, loss_fp: 0.002365, loss_freq: 0.040160
[03:49:25.223] iteration 7696: loss: 0.114619, loss_s1: 0.128618, loss_fp: 0.002149, loss_freq: 0.041653
[03:49:25.814] iteration 7697: loss: 0.076066, loss_s1: 0.053216, loss_fp: 0.001897, loss_freq: 0.038503
[03:49:26.403] iteration 7698: loss: 0.078215, loss_s1: 0.057923, loss_fp: 0.002329, loss_freq: 0.021208
[03:49:26.990] iteration 7699: loss: 0.063437, loss_s1: 0.032681, loss_fp: 0.001502, loss_freq: 0.025063
[03:49:27.584] iteration 7700: loss: 0.076859, loss_s1: 0.065646, loss_fp: 0.003659, loss_freq: 0.019390
[03:49:28.167] iteration 7701: loss: 0.108040, loss_s1: 0.106989, loss_fp: 0.003585, loss_freq: 0.046282
[03:49:28.798] iteration 7702: loss: 0.106851, loss_s1: 0.136350, loss_fp: 0.001682, loss_freq: 0.034884
[03:49:29.395] iteration 7703: loss: 0.112187, loss_s1: 0.082631, loss_fp: 0.003496, loss_freq: 0.036397
[03:49:30.024] iteration 7704: loss: 0.110218, loss_s1: 0.099203, loss_fp: 0.003235, loss_freq: 0.048089
[03:49:30.636] iteration 7705: loss: 0.113656, loss_s1: 0.065878, loss_fp: 0.002723, loss_freq: 0.064424
[03:49:31.228] iteration 7706: loss: 0.076891, loss_s1: 0.065598, loss_fp: 0.008250, loss_freq: 0.027698
[03:49:31.822] iteration 7707: loss: 0.069558, loss_s1: 0.036522, loss_fp: 0.005005, loss_freq: 0.032406
[03:49:32.420] iteration 7708: loss: 0.085987, loss_s1: 0.051269, loss_fp: 0.000860, loss_freq: 0.027749
[03:49:33.012] iteration 7709: loss: 0.084349, loss_s1: 0.047637, loss_fp: 0.005472, loss_freq: 0.030518
[03:49:33.601] iteration 7710: loss: 0.102418, loss_s1: 0.089862, loss_fp: 0.000858, loss_freq: 0.053794
[03:49:34.194] iteration 7711: loss: 0.076761, loss_s1: 0.058726, loss_fp: 0.001433, loss_freq: 0.018209
[03:49:34.789] iteration 7712: loss: 0.085156, loss_s1: 0.050166, loss_fp: 0.008627, loss_freq: 0.046026
[03:49:35.378] iteration 7713: loss: 0.060594, loss_s1: 0.034884, loss_fp: 0.001036, loss_freq: 0.009070
[03:49:35.974] iteration 7714: loss: 0.073311, loss_s1: 0.031440, loss_fp: 0.001750, loss_freq: 0.015958
[03:49:36.595] iteration 7715: loss: 0.106721, loss_s1: 0.105983, loss_fp: 0.012149, loss_freq: 0.027768
[03:49:37.221] iteration 7716: loss: 0.075630, loss_s1: 0.067912, loss_fp: 0.000807, loss_freq: 0.013106
[03:49:37.860] iteration 7717: loss: 0.094512, loss_s1: 0.069357, loss_fp: 0.003288, loss_freq: 0.031171
[03:49:38.495] iteration 7718: loss: 0.159938, loss_s1: 0.157521, loss_fp: 0.004782, loss_freq: 0.074717
[03:49:39.163] iteration 7719: loss: 0.068877, loss_s1: 0.025771, loss_fp: 0.001676, loss_freq: 0.040560
[03:49:39.792] iteration 7720: loss: 0.073959, loss_s1: 0.059879, loss_fp: 0.001479, loss_freq: 0.049286
[03:49:40.432] iteration 7721: loss: 0.129176, loss_s1: 0.075771, loss_fp: 0.008667, loss_freq: 0.051192
[03:49:41.037] iteration 7722: loss: 0.077373, loss_s1: 0.058960, loss_fp: 0.006822, loss_freq: 0.024580
[03:49:41.635] iteration 7723: loss: 0.090691, loss_s1: 0.072356, loss_fp: 0.004255, loss_freq: 0.042512
[03:49:42.229] iteration 7724: loss: 0.122452, loss_s1: 0.070332, loss_fp: 0.012461, loss_freq: 0.099478
[03:49:42.822] iteration 7725: loss: 0.102003, loss_s1: 0.045035, loss_fp: 0.004465, loss_freq: 0.081410
[03:49:43.411] iteration 7726: loss: 0.086513, loss_s1: 0.051800, loss_fp: 0.001300, loss_freq: 0.028589
[03:49:44.005] iteration 7727: loss: 0.078854, loss_s1: 0.034349, loss_fp: 0.001683, loss_freq: 0.029273
[03:49:44.590] iteration 7728: loss: 0.152674, loss_s1: 0.095078, loss_fp: 0.011795, loss_freq: 0.087446
[03:49:45.185] iteration 7729: loss: 0.078949, loss_s1: 0.043416, loss_fp: 0.012698, loss_freq: 0.066110
[03:49:45.777] iteration 7730: loss: 0.088549, loss_s1: 0.056772, loss_fp: 0.001920, loss_freq: 0.049518
[03:49:46.363] iteration 7731: loss: 0.089276, loss_s1: 0.060191, loss_fp: 0.011645, loss_freq: 0.026835
[03:49:46.953] iteration 7732: loss: 0.100330, loss_s1: 0.058405, loss_fp: 0.013277, loss_freq: 0.061822
[03:49:47.539] iteration 7733: loss: 0.132241, loss_s1: 0.082421, loss_fp: 0.003322, loss_freq: 0.050355
[03:49:48.130] iteration 7734: loss: 0.061508, loss_s1: 0.015669, loss_fp: 0.013008, loss_freq: 0.027002
[03:49:48.723] iteration 7735: loss: 0.083715, loss_s1: 0.071717, loss_fp: 0.002184, loss_freq: 0.043554
[03:49:49.318] iteration 7736: loss: 0.077365, loss_s1: 0.064797, loss_fp: 0.006776, loss_freq: 0.024070
[03:49:49.913] iteration 7737: loss: 0.099417, loss_s1: 0.103769, loss_fp: 0.001219, loss_freq: 0.030682
[03:49:50.505] iteration 7738: loss: 0.124219, loss_s1: 0.129020, loss_fp: 0.000692, loss_freq: 0.039547
[03:49:51.100] iteration 7739: loss: 0.120887, loss_s1: 0.090069, loss_fp: 0.002643, loss_freq: 0.084948
[03:49:51.692] iteration 7740: loss: 0.102392, loss_s1: 0.093521, loss_fp: 0.001828, loss_freq: 0.019253
[03:49:52.280] iteration 7741: loss: 0.103313, loss_s1: 0.116567, loss_fp: 0.003304, loss_freq: 0.026706
[03:49:52.871] iteration 7742: loss: 0.076128, loss_s1: 0.050582, loss_fp: 0.002994, loss_freq: 0.039305
[03:49:53.469] iteration 7743: loss: 0.083963, loss_s1: 0.066452, loss_fp: 0.002106, loss_freq: 0.016044
[03:49:54.065] iteration 7744: loss: 0.062404, loss_s1: 0.065187, loss_fp: 0.001853, loss_freq: 0.006652
[03:49:54.660] iteration 7745: loss: 0.081880, loss_s1: 0.061074, loss_fp: 0.000850, loss_freq: 0.040243
[03:49:55.250] iteration 7746: loss: 0.096962, loss_s1: 0.075910, loss_fp: 0.000910, loss_freq: 0.051743
[03:49:55.836] iteration 7747: loss: 0.078952, loss_s1: 0.045943, loss_fp: 0.006174, loss_freq: 0.032275
[03:49:56.420] iteration 7748: loss: 0.113063, loss_s1: 0.120625, loss_fp: 0.001075, loss_freq: 0.031310
[03:49:57.014] iteration 7749: loss: 0.077354, loss_s1: 0.046693, loss_fp: 0.002533, loss_freq: 0.021248
[03:49:57.617] iteration 7750: loss: 0.075999, loss_s1: 0.063283, loss_fp: 0.002230, loss_freq: 0.014263
[03:49:58.206] iteration 7751: loss: 0.090809, loss_s1: 0.044276, loss_fp: 0.007951, loss_freq: 0.050925
[03:49:58.804] iteration 7752: loss: 0.094735, loss_s1: 0.076256, loss_fp: 0.002031, loss_freq: 0.039025
[03:49:59.400] iteration 7753: loss: 0.055315, loss_s1: 0.031093, loss_fp: 0.000890, loss_freq: 0.021696
[03:49:59.988] iteration 7754: loss: 0.079700, loss_s1: 0.029570, loss_fp: 0.001508, loss_freq: 0.043931
[03:50:00.578] iteration 7755: loss: 0.060042, loss_s1: 0.022309, loss_fp: 0.002639, loss_freq: 0.035866
[03:50:01.168] iteration 7756: loss: 0.124212, loss_s1: 0.102388, loss_fp: 0.003298, loss_freq: 0.046028
[03:50:01.797] iteration 7757: loss: 0.096494, loss_s1: 0.093338, loss_fp: 0.004277, loss_freq: 0.025857
[03:50:02.426] iteration 7758: loss: 0.087535, loss_s1: 0.058927, loss_fp: 0.001661, loss_freq: 0.028493
[03:50:03.055] iteration 7759: loss: 0.169607, loss_s1: 0.138472, loss_fp: 0.009494, loss_freq: 0.120072
[03:50:03.685] iteration 7760: loss: 0.074124, loss_s1: 0.062228, loss_fp: 0.003775, loss_freq: 0.022732
[03:50:04.295] iteration 7761: loss: 0.069435, loss_s1: 0.039495, loss_fp: 0.001740, loss_freq: 0.013856
[03:50:04.947] iteration 7762: loss: 0.075471, loss_s1: 0.038370, loss_fp: 0.004874, loss_freq: 0.036846
[03:50:05.573] iteration 7763: loss: 0.061301, loss_s1: 0.037934, loss_fp: 0.002434, loss_freq: 0.029583
[03:50:06.201] iteration 7764: loss: 0.090479, loss_s1: 0.041226, loss_fp: 0.002027, loss_freq: 0.039216
[03:50:06.805] iteration 7765: loss: 0.097283, loss_s1: 0.042382, loss_fp: 0.002280, loss_freq: 0.052518
[03:50:07.390] iteration 7766: loss: 0.095964, loss_s1: 0.062133, loss_fp: 0.001935, loss_freq: 0.061156
[03:50:07.987] iteration 7767: loss: 0.076100, loss_s1: 0.062126, loss_fp: 0.004285, loss_freq: 0.027638
[03:50:08.574] iteration 7768: loss: 0.080654, loss_s1: 0.041768, loss_fp: 0.003130, loss_freq: 0.052563
[03:50:09.170] iteration 7769: loss: 0.129775, loss_s1: 0.106844, loss_fp: 0.004214, loss_freq: 0.101443
[03:50:09.761] iteration 7770: loss: 0.058051, loss_s1: 0.039138, loss_fp: 0.006587, loss_freq: 0.010634
[03:50:10.352] iteration 7771: loss: 0.086095, loss_s1: 0.076708, loss_fp: 0.001734, loss_freq: 0.019381
[03:50:10.943] iteration 7772: loss: 0.067960, loss_s1: 0.062479, loss_fp: 0.002923, loss_freq: 0.029088
[03:50:11.538] iteration 7773: loss: 0.072297, loss_s1: 0.038949, loss_fp: 0.015483, loss_freq: 0.031829
[03:50:12.131] iteration 7774: loss: 0.087650, loss_s1: 0.035838, loss_fp: 0.001055, loss_freq: 0.092957
[03:50:12.739] iteration 7775: loss: 0.110012, loss_s1: 0.048572, loss_fp: 0.012775, loss_freq: 0.067708
[03:50:13.344] iteration 7776: loss: 0.078258, loss_s1: 0.048848, loss_fp: 0.006330, loss_freq: 0.020083
[03:50:13.949] iteration 7777: loss: 0.067136, loss_s1: 0.042622, loss_fp: 0.002992, loss_freq: 0.037900
[03:50:14.546] iteration 7778: loss: 0.093179, loss_s1: 0.053393, loss_fp: 0.010205, loss_freq: 0.046220
[03:50:15.154] iteration 7779: loss: 0.058542, loss_s1: 0.031677, loss_fp: 0.001843, loss_freq: 0.023117
[03:50:15.742] iteration 7780: loss: 0.071512, loss_s1: 0.052536, loss_fp: 0.003192, loss_freq: 0.019472
[03:50:16.333] iteration 7781: loss: 0.106521, loss_s1: 0.091956, loss_fp: 0.003067, loss_freq: 0.062804
[03:50:16.926] iteration 7782: loss: 0.083483, loss_s1: 0.022211, loss_fp: 0.002224, loss_freq: 0.012921
[03:50:17.516] iteration 7783: loss: 0.112412, loss_s1: 0.080736, loss_fp: 0.005892, loss_freq: 0.037840
[03:50:18.172] iteration 7784: loss: 0.081472, loss_s1: 0.049906, loss_fp: 0.001541, loss_freq: 0.049943
[03:50:18.800] iteration 7785: loss: 0.113587, loss_s1: 0.115054, loss_fp: 0.003600, loss_freq: 0.053089
[03:50:19.431] iteration 7786: loss: 0.057509, loss_s1: 0.042368, loss_fp: 0.000795, loss_freq: 0.018362
[03:50:20.060] iteration 7787: loss: 0.128997, loss_s1: 0.138732, loss_fp: 0.012832, loss_freq: 0.021682
[03:50:20.653] iteration 7788: loss: 0.099577, loss_s1: 0.089822, loss_fp: 0.007048, loss_freq: 0.053121
[03:50:21.301] iteration 7789: loss: 0.103674, loss_s1: 0.100525, loss_fp: 0.006111, loss_freq: 0.047464
[03:50:21.960] iteration 7790: loss: 0.064526, loss_s1: 0.053174, loss_fp: 0.000919, loss_freq: 0.038320
[03:50:22.594] iteration 7791: loss: 0.142332, loss_s1: 0.137615, loss_fp: 0.002707, loss_freq: 0.041254
[03:50:23.227] iteration 7792: loss: 0.079820, loss_s1: 0.048867, loss_fp: 0.003154, loss_freq: 0.029879
[03:50:23.819] iteration 7793: loss: 0.107041, loss_s1: 0.045107, loss_fp: 0.001931, loss_freq: 0.047352
[03:50:24.412] iteration 7794: loss: 0.076717, loss_s1: 0.057895, loss_fp: 0.000678, loss_freq: 0.022596
[03:50:24.997] iteration 7795: loss: 0.064594, loss_s1: 0.032548, loss_fp: 0.020026, loss_freq: 0.022205
[03:50:25.586] iteration 7796: loss: 0.074522, loss_s1: 0.024499, loss_fp: 0.002643, loss_freq: 0.029398
[03:50:26.173] iteration 7797: loss: 0.088474, loss_s1: 0.061946, loss_fp: 0.002326, loss_freq: 0.041819
[03:50:26.756] iteration 7798: loss: 0.110985, loss_s1: 0.080069, loss_fp: 0.004280, loss_freq: 0.083938
[03:50:27.347] iteration 7799: loss: 0.087448, loss_s1: 0.066127, loss_fp: 0.000773, loss_freq: 0.049405
[03:50:27.934] iteration 7800: loss: 0.104036, loss_s1: 0.067232, loss_fp: 0.013477, loss_freq: 0.045611
[03:50:31.145] iteration 7800 : mean_dice : 0.655914
[03:50:31.782] iteration 7801: loss: 0.081882, loss_s1: 0.031645, loss_fp: 0.004001, loss_freq: 0.052995
[03:50:32.375] iteration 7802: loss: 0.097607, loss_s1: 0.090727, loss_fp: 0.004169, loss_freq: 0.045705
[03:50:32.996] iteration 7803: loss: 0.126882, loss_s1: 0.117254, loss_fp: 0.005203, loss_freq: 0.049410
[03:50:33.636] iteration 7804: loss: 0.110195, loss_s1: 0.069327, loss_fp: 0.001804, loss_freq: 0.071905
[03:50:34.227] iteration 7805: loss: 0.123120, loss_s1: 0.068215, loss_fp: 0.003741, loss_freq: 0.065253
[03:50:34.823] iteration 7806: loss: 0.110180, loss_s1: 0.109597, loss_fp: 0.011760, loss_freq: 0.038966
[03:50:35.412] iteration 7807: loss: 0.072554, loss_s1: 0.062586, loss_fp: 0.006889, loss_freq: 0.031725
[03:50:36.007] iteration 7808: loss: 0.180270, loss_s1: 0.108665, loss_fp: 0.001572, loss_freq: 0.094797
[03:50:36.602] iteration 7809: loss: 0.105805, loss_s1: 0.098648, loss_fp: 0.000760, loss_freq: 0.018762
[03:50:37.188] iteration 7810: loss: 0.099077, loss_s1: 0.087893, loss_fp: 0.000716, loss_freq: 0.024651
[03:50:37.772] iteration 7811: loss: 0.066571, loss_s1: 0.044946, loss_fp: 0.002877, loss_freq: 0.017477
[03:50:38.361] iteration 7812: loss: 0.076107, loss_s1: 0.079402, loss_fp: 0.001164, loss_freq: 0.025201
[03:50:38.957] iteration 7813: loss: 0.067331, loss_s1: 0.024523, loss_fp: 0.002125, loss_freq: 0.022143
[03:50:39.547] iteration 7814: loss: 0.123657, loss_s1: 0.150688, loss_fp: 0.002609, loss_freq: 0.023750
[03:50:40.148] iteration 7815: loss: 0.042812, loss_s1: 0.016092, loss_fp: 0.005906, loss_freq: 0.018247
[03:50:40.744] iteration 7816: loss: 0.107501, loss_s1: 0.067036, loss_fp: 0.014429, loss_freq: 0.065241
[03:50:41.334] iteration 7817: loss: 0.070198, loss_s1: 0.043263, loss_fp: 0.002779, loss_freq: 0.033150
[03:50:41.923] iteration 7818: loss: 0.100280, loss_s1: 0.094942, loss_fp: 0.004693, loss_freq: 0.032409
[03:50:42.509] iteration 7819: loss: 0.126572, loss_s1: 0.123698, loss_fp: 0.001382, loss_freq: 0.067478
[03:50:43.090] iteration 7820: loss: 0.138754, loss_s1: 0.093429, loss_fp: 0.000905, loss_freq: 0.125732
[03:50:44.087] iteration 7821: loss: 0.058521, loss_s1: 0.040714, loss_fp: 0.000852, loss_freq: 0.012139
[03:50:44.719] iteration 7822: loss: 0.056533, loss_s1: 0.022802, loss_fp: 0.001569, loss_freq: 0.026369
[03:50:45.348] iteration 7823: loss: 0.071503, loss_s1: 0.045042, loss_fp: 0.003250, loss_freq: 0.028123
[03:50:45.975] iteration 7824: loss: 0.067608, loss_s1: 0.029497, loss_fp: 0.003828, loss_freq: 0.033575
[03:50:46.603] iteration 7825: loss: 0.098209, loss_s1: 0.083504, loss_fp: 0.002718, loss_freq: 0.051163
[03:50:47.239] iteration 7826: loss: 0.114749, loss_s1: 0.083976, loss_fp: 0.004274, loss_freq: 0.020405
[03:50:47.872] iteration 7827: loss: 0.105953, loss_s1: 0.092488, loss_fp: 0.002368, loss_freq: 0.039661
[03:50:48.487] iteration 7828: loss: 0.077878, loss_s1: 0.058879, loss_fp: 0.002092, loss_freq: 0.033928
[03:50:49.079] iteration 7829: loss: 0.138723, loss_s1: 0.176681, loss_fp: 0.001940, loss_freq: 0.035554
[03:50:49.670] iteration 7830: loss: 0.105258, loss_s1: 0.115156, loss_fp: 0.000768, loss_freq: 0.026373
[03:50:50.263] iteration 7831: loss: 0.105981, loss_s1: 0.038845, loss_fp: 0.000992, loss_freq: 0.047920
[03:50:50.854] iteration 7832: loss: 0.101743, loss_s1: 0.049257, loss_fp: 0.006357, loss_freq: 0.095173
[03:50:51.453] iteration 7833: loss: 0.074954, loss_s1: 0.049158, loss_fp: 0.007943, loss_freq: 0.041021
[03:50:52.054] iteration 7834: loss: 0.063943, loss_s1: 0.039467, loss_fp: 0.001360, loss_freq: 0.034036
[03:50:52.645] iteration 7835: loss: 0.091573, loss_s1: 0.087337, loss_fp: 0.001679, loss_freq: 0.026949
[03:50:53.233] iteration 7836: loss: 0.065768, loss_s1: 0.035101, loss_fp: 0.001734, loss_freq: 0.031344
[03:50:53.830] iteration 7837: loss: 0.120826, loss_s1: 0.096959, loss_fp: 0.006845, loss_freq: 0.093541
[03:50:54.422] iteration 7838: loss: 0.095974, loss_s1: 0.069909, loss_fp: 0.001384, loss_freq: 0.018086
[03:50:55.092] iteration 7839: loss: 0.060297, loss_s1: 0.026121, loss_fp: 0.005519, loss_freq: 0.021994
[03:50:55.694] iteration 7840: loss: 0.069532, loss_s1: 0.049475, loss_fp: 0.001114, loss_freq: 0.018817
[03:50:56.302] iteration 7841: loss: 0.085877, loss_s1: 0.048860, loss_fp: 0.000841, loss_freq: 0.063686
[03:50:56.898] iteration 7842: loss: 0.117794, loss_s1: 0.088463, loss_fp: 0.003751, loss_freq: 0.037302
[03:50:57.510] iteration 7843: loss: 0.103382, loss_s1: 0.077536, loss_fp: 0.004506, loss_freq: 0.027524
[03:50:58.097] iteration 7844: loss: 0.102349, loss_s1: 0.072882, loss_fp: 0.001574, loss_freq: 0.054185
[03:50:58.681] iteration 7845: loss: 0.115849, loss_s1: 0.140143, loss_fp: 0.004192, loss_freq: 0.040873
[03:50:59.272] iteration 7846: loss: 0.096735, loss_s1: 0.093367, loss_fp: 0.002044, loss_freq: 0.054716
[03:50:59.867] iteration 7847: loss: 0.061729, loss_s1: 0.029051, loss_fp: 0.007060, loss_freq: 0.020054
[03:51:00.460] iteration 7848: loss: 0.107862, loss_s1: 0.066771, loss_fp: 0.006732, loss_freq: 0.046347
[03:51:01.048] iteration 7849: loss: 0.114639, loss_s1: 0.075113, loss_fp: 0.013727, loss_freq: 0.069090
[03:51:01.638] iteration 7850: loss: 0.105037, loss_s1: 0.100229, loss_fp: 0.002249, loss_freq: 0.040152
[03:51:02.229] iteration 7851: loss: 0.076673, loss_s1: 0.016062, loss_fp: 0.008085, loss_freq: 0.043385
[03:51:02.814] iteration 7852: loss: 0.153392, loss_s1: 0.093717, loss_fp: 0.002904, loss_freq: 0.046303
[03:51:03.402] iteration 7853: loss: 0.089234, loss_s1: 0.049856, loss_fp: 0.010018, loss_freq: 0.062502
[03:51:03.987] iteration 7854: loss: 0.058564, loss_s1: 0.025220, loss_fp: 0.002130, loss_freq: 0.013945
[03:51:04.577] iteration 7855: loss: 0.042176, loss_s1: 0.019608, loss_fp: 0.004539, loss_freq: 0.022728
[03:51:05.161] iteration 7856: loss: 0.061825, loss_s1: 0.036580, loss_fp: 0.002397, loss_freq: 0.011506
[03:51:05.747] iteration 7857: loss: 0.089322, loss_s1: 0.069456, loss_fp: 0.003345, loss_freq: 0.038200
[03:51:06.333] iteration 7858: loss: 0.099468, loss_s1: 0.116787, loss_fp: 0.001029, loss_freq: 0.022566
[03:51:06.920] iteration 7859: loss: 0.115322, loss_s1: 0.082911, loss_fp: 0.006329, loss_freq: 0.051206
[03:51:07.510] iteration 7860: loss: 0.089789, loss_s1: 0.074234, loss_fp: 0.001083, loss_freq: 0.033070
[03:51:08.100] iteration 7861: loss: 0.122850, loss_s1: 0.100963, loss_fp: 0.004651, loss_freq: 0.070404
[03:51:08.695] iteration 7862: loss: 0.096880, loss_s1: 0.060312, loss_fp: 0.002946, loss_freq: 0.072819
[03:51:09.289] iteration 7863: loss: 0.093109, loss_s1: 0.073476, loss_fp: 0.002959, loss_freq: 0.061137
[03:51:09.879] iteration 7864: loss: 0.135723, loss_s1: 0.105757, loss_fp: 0.027036, loss_freq: 0.092236
[03:51:10.468] iteration 7865: loss: 0.082032, loss_s1: 0.064273, loss_fp: 0.004849, loss_freq: 0.017200
[03:51:11.060] iteration 7866: loss: 0.089976, loss_s1: 0.077041, loss_fp: 0.000873, loss_freq: 0.045471
[03:51:11.650] iteration 7867: loss: 0.085852, loss_s1: 0.081266, loss_fp: 0.003286, loss_freq: 0.038559
[03:51:12.242] iteration 7868: loss: 0.056732, loss_s1: 0.043106, loss_fp: 0.003948, loss_freq: 0.016881
[03:51:12.871] iteration 7869: loss: 0.052236, loss_s1: 0.018753, loss_fp: 0.002293, loss_freq: 0.010698
[03:51:13.501] iteration 7870: loss: 0.082122, loss_s1: 0.062413, loss_fp: 0.003914, loss_freq: 0.027147
[03:51:14.133] iteration 7871: loss: 0.098811, loss_s1: 0.067661, loss_fp: 0.003693, loss_freq: 0.048069
[03:51:14.733] iteration 7872: loss: 0.125172, loss_s1: 0.148671, loss_fp: 0.006089, loss_freq: 0.060565
[03:51:15.325] iteration 7873: loss: 0.093913, loss_s1: 0.030765, loss_fp: 0.002952, loss_freq: 0.025251
[03:51:15.910] iteration 7874: loss: 0.101488, loss_s1: 0.070617, loss_fp: 0.001657, loss_freq: 0.062241
[03:51:16.504] iteration 7875: loss: 0.097897, loss_s1: 0.031523, loss_fp: 0.001885, loss_freq: 0.067701
[03:51:17.092] iteration 7876: loss: 0.076324, loss_s1: 0.062666, loss_fp: 0.004631, loss_freq: 0.020331
[03:51:17.685] iteration 7877: loss: 0.075992, loss_s1: 0.035764, loss_fp: 0.001879, loss_freq: 0.021950
[03:51:18.284] iteration 7878: loss: 0.080590, loss_s1: 0.055832, loss_fp: 0.003186, loss_freq: 0.043294
[03:51:18.878] iteration 7879: loss: 0.093145, loss_s1: 0.068404, loss_fp: 0.001169, loss_freq: 0.041589
[03:51:19.474] iteration 7880: loss: 0.105592, loss_s1: 0.122102, loss_fp: 0.003409, loss_freq: 0.031288
[03:51:20.066] iteration 7881: loss: 0.062436, loss_s1: 0.038746, loss_fp: 0.003284, loss_freq: 0.037390
[03:51:20.657] iteration 7882: loss: 0.088899, loss_s1: 0.026422, loss_fp: 0.008857, loss_freq: 0.037946
[03:51:21.330] iteration 7883: loss: 0.071503, loss_s1: 0.052815, loss_fp: 0.000438, loss_freq: 0.022259
[03:51:21.930] iteration 7884: loss: 0.066554, loss_s1: 0.038011, loss_fp: 0.003604, loss_freq: 0.033043
[03:51:22.516] iteration 7885: loss: 0.159113, loss_s1: 0.165416, loss_fp: 0.002842, loss_freq: 0.018984
[03:51:23.103] iteration 7886: loss: 0.064485, loss_s1: 0.034868, loss_fp: 0.002904, loss_freq: 0.037870
[03:51:23.690] iteration 7887: loss: 0.074005, loss_s1: 0.045578, loss_fp: 0.009546, loss_freq: 0.017314
[03:51:24.271] iteration 7888: loss: 0.120515, loss_s1: 0.099917, loss_fp: 0.002393, loss_freq: 0.065207
[03:51:24.861] iteration 7889: loss: 0.078688, loss_s1: 0.040373, loss_fp: 0.001280, loss_freq: 0.045869
[03:51:25.451] iteration 7890: loss: 0.084789, loss_s1: 0.048564, loss_fp: 0.001945, loss_freq: 0.038984
[03:51:26.036] iteration 7891: loss: 0.098895, loss_s1: 0.081825, loss_fp: 0.003357, loss_freq: 0.055114
[03:51:26.628] iteration 7892: loss: 0.078008, loss_s1: 0.051003, loss_fp: 0.006752, loss_freq: 0.035824
[03:51:27.216] iteration 7893: loss: 0.089116, loss_s1: 0.062225, loss_fp: 0.008468, loss_freq: 0.053535
[03:51:27.813] iteration 7894: loss: 0.094191, loss_s1: 0.086991, loss_fp: 0.005634, loss_freq: 0.036692
[03:51:28.401] iteration 7895: loss: 0.121772, loss_s1: 0.057459, loss_fp: 0.001362, loss_freq: 0.083974
[03:51:28.998] iteration 7896: loss: 0.090972, loss_s1: 0.080428, loss_fp: 0.001244, loss_freq: 0.035526
[03:51:29.590] iteration 7897: loss: 0.061002, loss_s1: 0.049466, loss_fp: 0.001166, loss_freq: 0.028675
[03:51:30.210] iteration 7898: loss: 0.094773, loss_s1: 0.091377, loss_fp: 0.001687, loss_freq: 0.047058
[03:51:30.799] iteration 7899: loss: 0.098521, loss_s1: 0.104586, loss_fp: 0.001755, loss_freq: 0.039706
[03:51:31.390] iteration 7900: loss: 0.079859, loss_s1: 0.046940, loss_fp: 0.004348, loss_freq: 0.032762
[03:51:31.980] iteration 7901: loss: 0.103101, loss_s1: 0.057486, loss_fp: 0.005636, loss_freq: 0.040038
[03:51:32.567] iteration 7902: loss: 0.118436, loss_s1: 0.101030, loss_fp: 0.005330, loss_freq: 0.075536
[03:51:33.156] iteration 7903: loss: 0.100661, loss_s1: 0.098214, loss_fp: 0.005429, loss_freq: 0.029331
[03:51:33.748] iteration 7904: loss: 0.060824, loss_s1: 0.038905, loss_fp: 0.005745, loss_freq: 0.013283
[03:51:34.342] iteration 7905: loss: 0.091099, loss_s1: 0.069646, loss_fp: 0.002306, loss_freq: 0.043935
[03:51:34.935] iteration 7906: loss: 0.064937, loss_s1: 0.050264, loss_fp: 0.002773, loss_freq: 0.026031
[03:51:35.523] iteration 7907: loss: 0.124323, loss_s1: 0.139451, loss_fp: 0.003854, loss_freq: 0.048782
[03:51:36.111] iteration 7908: loss: 0.107526, loss_s1: 0.084343, loss_fp: 0.012089, loss_freq: 0.041247
[03:51:36.700] iteration 7909: loss: 0.067038, loss_s1: 0.043828, loss_fp: 0.004734, loss_freq: 0.030133
[03:51:37.287] iteration 7910: loss: 0.097555, loss_s1: 0.025796, loss_fp: 0.002809, loss_freq: 0.034315
[03:51:37.878] iteration 7911: loss: 0.112562, loss_s1: 0.118592, loss_fp: 0.001508, loss_freq: 0.044351
[03:51:38.470] iteration 7912: loss: 0.075831, loss_s1: 0.061642, loss_fp: 0.002358, loss_freq: 0.045958
[03:51:39.105] iteration 7913: loss: 0.084976, loss_s1: 0.063339, loss_fp: 0.001236, loss_freq: 0.035603
[03:51:39.694] iteration 7914: loss: 0.059245, loss_s1: 0.017082, loss_fp: 0.001267, loss_freq: 0.018166
[03:51:40.287] iteration 7915: loss: 0.060671, loss_s1: 0.033533, loss_fp: 0.003904, loss_freq: 0.025795
[03:51:40.870] iteration 7916: loss: 0.099025, loss_s1: 0.104339, loss_fp: 0.004583, loss_freq: 0.039398
[03:51:41.453] iteration 7917: loss: 0.094552, loss_s1: 0.078432, loss_fp: 0.005238, loss_freq: 0.031750
[03:51:42.035] iteration 7918: loss: 0.106776, loss_s1: 0.056786, loss_fp: 0.007287, loss_freq: 0.051439
[03:51:42.621] iteration 7919: loss: 0.055083, loss_s1: 0.026568, loss_fp: 0.001848, loss_freq: 0.029105
[03:51:43.212] iteration 7920: loss: 0.053896, loss_s1: 0.037951, loss_fp: 0.005004, loss_freq: 0.008586
[03:51:43.801] iteration 7921: loss: 0.068640, loss_s1: 0.063049, loss_fp: 0.003408, loss_freq: 0.020873
[03:51:44.385] iteration 7922: loss: 0.101845, loss_s1: 0.095643, loss_fp: 0.003151, loss_freq: 0.034412
[03:51:44.975] iteration 7923: loss: 0.065473, loss_s1: 0.028788, loss_fp: 0.001448, loss_freq: 0.033080
[03:51:45.565] iteration 7924: loss: 0.072477, loss_s1: 0.032921, loss_fp: 0.001353, loss_freq: 0.042801
[03:51:46.161] iteration 7925: loss: 0.080184, loss_s1: 0.063395, loss_fp: 0.003474, loss_freq: 0.030947
[03:51:46.750] iteration 7926: loss: 0.088286, loss_s1: 0.078319, loss_fp: 0.001652, loss_freq: 0.033556
[03:51:47.338] iteration 7927: loss: 0.064538, loss_s1: 0.037810, loss_fp: 0.006718, loss_freq: 0.030012
[03:51:47.932] iteration 7928: loss: 0.074324, loss_s1: 0.055207, loss_fp: 0.001716, loss_freq: 0.017755
[03:51:48.518] iteration 7929: loss: 0.118586, loss_s1: 0.089863, loss_fp: 0.003597, loss_freq: 0.089033
[03:51:49.105] iteration 7930: loss: 0.072304, loss_s1: 0.052919, loss_fp: 0.001064, loss_freq: 0.014410
[03:51:49.699] iteration 7931: loss: 0.099062, loss_s1: 0.087023, loss_fp: 0.002297, loss_freq: 0.046696
[03:51:50.295] iteration 7932: loss: 0.109064, loss_s1: 0.101932, loss_fp: 0.004786, loss_freq: 0.034817
[03:51:50.937] iteration 7933: loss: 0.075855, loss_s1: 0.039372, loss_fp: 0.001984, loss_freq: 0.027081
[03:51:51.573] iteration 7934: loss: 0.066094, loss_s1: 0.042255, loss_fp: 0.001305, loss_freq: 0.035789
[03:51:52.200] iteration 7935: loss: 0.117385, loss_s1: 0.090776, loss_fp: 0.004872, loss_freq: 0.058375
[03:51:52.832] iteration 7936: loss: 0.096790, loss_s1: 0.065236, loss_fp: 0.005229, loss_freq: 0.052757
[03:51:53.463] iteration 7937: loss: 0.111102, loss_s1: 0.126226, loss_fp: 0.001962, loss_freq: 0.025750
[03:51:54.115] iteration 7938: loss: 0.070055, loss_s1: 0.053750, loss_fp: 0.001338, loss_freq: 0.019071
[03:51:54.705] iteration 7939: loss: 0.094955, loss_s1: 0.053946, loss_fp: 0.002937, loss_freq: 0.086268
[03:51:55.299] iteration 7940: loss: 0.073832, loss_s1: 0.028266, loss_fp: 0.002469, loss_freq: 0.019641
[03:51:55.916] iteration 7941: loss: 0.050782, loss_s1: 0.023835, loss_fp: 0.002640, loss_freq: 0.015973
[03:51:56.539] iteration 7942: loss: 0.080037, loss_s1: 0.082387, loss_fp: 0.002348, loss_freq: 0.027094
[03:51:57.166] iteration 7943: loss: 0.088466, loss_s1: 0.048652, loss_fp: 0.002390, loss_freq: 0.053786
[03:51:57.796] iteration 7944: loss: 0.077386, loss_s1: 0.038292, loss_fp: 0.006534, loss_freq: 0.046010
[03:51:58.399] iteration 7945: loss: 0.117629, loss_s1: 0.076071, loss_fp: 0.004248, loss_freq: 0.081824
[03:51:58.994] iteration 7946: loss: 0.078291, loss_s1: 0.058544, loss_fp: 0.005434, loss_freq: 0.010383
[03:51:59.592] iteration 7947: loss: 0.131950, loss_s1: 0.133332, loss_fp: 0.003488, loss_freq: 0.071350
[03:52:00.197] iteration 7948: loss: 0.093767, loss_s1: 0.053639, loss_fp: 0.000749, loss_freq: 0.035008
[03:52:00.793] iteration 7949: loss: 0.061394, loss_s1: 0.047180, loss_fp: 0.000988, loss_freq: 0.015654
[03:52:01.390] iteration 7950: loss: 0.073250, loss_s1: 0.047342, loss_fp: 0.010536, loss_freq: 0.032866
[03:52:01.984] iteration 7951: loss: 0.057368, loss_s1: 0.018061, loss_fp: 0.006450, loss_freq: 0.050484
[03:52:02.578] iteration 7952: loss: 0.208339, loss_s1: 0.058328, loss_fp: 0.001975, loss_freq: 0.028601
[03:52:03.169] iteration 7953: loss: 0.099213, loss_s1: 0.080196, loss_fp: 0.003130, loss_freq: 0.042958
[03:52:03.754] iteration 7954: loss: 0.073655, loss_s1: 0.063786, loss_fp: 0.001757, loss_freq: 0.035323
[03:52:04.344] iteration 7955: loss: 0.070685, loss_s1: 0.051857, loss_fp: 0.001285, loss_freq: 0.007591
[03:52:04.942] iteration 7956: loss: 0.072487, loss_s1: 0.049213, loss_fp: 0.001713, loss_freq: 0.022637
[03:52:05.539] iteration 7957: loss: 0.118188, loss_s1: 0.060619, loss_fp: 0.004805, loss_freq: 0.025618
[03:52:06.146] iteration 7958: loss: 0.084892, loss_s1: 0.058476, loss_fp: 0.004474, loss_freq: 0.031387
[03:52:06.747] iteration 7959: loss: 0.135257, loss_s1: 0.101956, loss_fp: 0.002771, loss_freq: 0.100645
[03:52:07.341] iteration 7960: loss: 0.066036, loss_s1: 0.057996, loss_fp: 0.001309, loss_freq: 0.022267
[03:52:07.933] iteration 7961: loss: 0.134821, loss_s1: 0.086160, loss_fp: 0.004165, loss_freq: 0.060753
[03:52:08.580] iteration 7962: loss: 0.085503, loss_s1: 0.049867, loss_fp: 0.001031, loss_freq: 0.044525
[03:52:09.178] iteration 7963: loss: 0.141977, loss_s1: 0.134401, loss_fp: 0.001952, loss_freq: 0.048838
[03:52:09.776] iteration 7964: loss: 0.076245, loss_s1: 0.063293, loss_fp: 0.003796, loss_freq: 0.010769
[03:52:10.363] iteration 7965: loss: 0.096632, loss_s1: 0.083954, loss_fp: 0.001825, loss_freq: 0.021883
[03:52:10.969] iteration 7966: loss: 0.068810, loss_s1: 0.029545, loss_fp: 0.000838, loss_freq: 0.032125
[03:52:11.558] iteration 7967: loss: 0.071428, loss_s1: 0.054719, loss_fp: 0.001244, loss_freq: 0.030517
[03:52:12.143] iteration 7968: loss: 0.137659, loss_s1: 0.132440, loss_fp: 0.005611, loss_freq: 0.062850
[03:52:12.738] iteration 7969: loss: 0.116828, loss_s1: 0.094275, loss_fp: 0.006582, loss_freq: 0.060092
[03:52:13.354] iteration 7970: loss: 0.103649, loss_s1: 0.035694, loss_fp: 0.006308, loss_freq: 0.031368
[03:52:13.943] iteration 7971: loss: 0.102176, loss_s1: 0.079142, loss_fp: 0.015897, loss_freq: 0.035893
[03:52:14.533] iteration 7972: loss: 0.098165, loss_s1: 0.059332, loss_fp: 0.001264, loss_freq: 0.078019
[03:52:15.123] iteration 7973: loss: 0.122984, loss_s1: 0.097857, loss_fp: 0.019983, loss_freq: 0.059283
[03:52:15.718] iteration 7974: loss: 0.082650, loss_s1: 0.067270, loss_fp: 0.004509, loss_freq: 0.031902
[03:52:16.305] iteration 7975: loss: 0.177175, loss_s1: 0.114377, loss_fp: 0.015846, loss_freq: 0.072446
[03:52:16.898] iteration 7976: loss: 0.109913, loss_s1: 0.053975, loss_fp: 0.000676, loss_freq: 0.049756
[03:52:17.512] iteration 7977: loss: 0.069679, loss_s1: 0.035842, loss_fp: 0.004212, loss_freq: 0.052412
[03:52:18.104] iteration 7978: loss: 0.152270, loss_s1: 0.124998, loss_fp: 0.005114, loss_freq: 0.082590
[03:52:18.693] iteration 7979: loss: 0.058483, loss_s1: 0.032532, loss_fp: 0.006537, loss_freq: 0.027448
[03:52:19.298] iteration 7980: loss: 0.090013, loss_s1: 0.053841, loss_fp: 0.002192, loss_freq: 0.021208
[03:52:19.893] iteration 7981: loss: 0.066297, loss_s1: 0.052486, loss_fp: 0.000375, loss_freq: 0.008885
[03:52:20.489] iteration 7982: loss: 0.078935, loss_s1: 0.084725, loss_fp: 0.002861, loss_freq: 0.021726
[03:52:21.088] iteration 7983: loss: 0.066604, loss_s1: 0.024665, loss_fp: 0.001750, loss_freq: 0.022622
[03:52:21.685] iteration 7984: loss: 0.084965, loss_s1: 0.065877, loss_fp: 0.009633, loss_freq: 0.039048
[03:52:22.282] iteration 7985: loss: 0.057135, loss_s1: 0.042864, loss_fp: 0.001019, loss_freq: 0.016319
[03:52:22.881] iteration 7986: loss: 0.108742, loss_s1: 0.082838, loss_fp: 0.001472, loss_freq: 0.053030
[03:52:23.479] iteration 7987: loss: 0.097335, loss_s1: 0.076738, loss_fp: 0.001886, loss_freq: 0.040632
[03:52:24.075] iteration 7988: loss: 0.125642, loss_s1: 0.143667, loss_fp: 0.002874, loss_freq: 0.030905
[03:52:24.661] iteration 7989: loss: 0.103232, loss_s1: 0.069920, loss_fp: 0.004766, loss_freq: 0.065394
[03:52:25.248] iteration 7990: loss: 0.158923, loss_s1: 0.069473, loss_fp: 0.003969, loss_freq: 0.087730
[03:52:26.199] iteration 7991: loss: 0.068962, loss_s1: 0.041867, loss_fp: 0.000677, loss_freq: 0.017091
[03:52:26.796] iteration 7992: loss: 0.077124, loss_s1: 0.074828, loss_fp: 0.001144, loss_freq: 0.014084
[03:52:27.396] iteration 7993: loss: 0.075152, loss_s1: 0.038920, loss_fp: 0.000716, loss_freq: 0.022112
[03:52:28.000] iteration 7994: loss: 0.071746, loss_s1: 0.039802, loss_fp: 0.001032, loss_freq: 0.034565
[03:52:28.600] iteration 7995: loss: 0.065205, loss_s1: 0.051442, loss_fp: 0.001010, loss_freq: 0.018302
[03:52:29.202] iteration 7996: loss: 0.103213, loss_s1: 0.079684, loss_fp: 0.001014, loss_freq: 0.046882
[03:52:29.797] iteration 7997: loss: 0.097562, loss_s1: 0.088836, loss_fp: 0.001595, loss_freq: 0.029023
[03:52:30.435] iteration 7998: loss: 0.049867, loss_s1: 0.026145, loss_fp: 0.001179, loss_freq: 0.013029
[03:52:31.065] iteration 7999: loss: 0.079551, loss_s1: 0.038799, loss_fp: 0.001955, loss_freq: 0.027398
[03:52:31.661] iteration 8000: loss: 0.120426, loss_s1: 0.117191, loss_fp: 0.003965, loss_freq: 0.037515
[03:52:34.731] iteration 8000 : mean_dice : 0.653723
[03:52:35.357] iteration 8001: loss: 0.108343, loss_s1: 0.056316, loss_fp: 0.007033, loss_freq: 0.082963
[03:52:35.951] iteration 8002: loss: 0.100569, loss_s1: 0.082640, loss_fp: 0.001002, loss_freq: 0.058519
[03:52:36.542] iteration 8003: loss: 0.085113, loss_s1: 0.037082, loss_fp: 0.004133, loss_freq: 0.067995
[03:52:37.140] iteration 8004: loss: 0.072726, loss_s1: 0.028006, loss_fp: 0.005179, loss_freq: 0.044634
[03:52:37.737] iteration 8005: loss: 0.081689, loss_s1: 0.049478, loss_fp: 0.002742, loss_freq: 0.041681
[03:52:38.324] iteration 8006: loss: 0.055709, loss_s1: 0.039115, loss_fp: 0.000938, loss_freq: 0.023210
[03:52:38.920] iteration 8007: loss: 0.111301, loss_s1: 0.098057, loss_fp: 0.003859, loss_freq: 0.050429
[03:52:39.504] iteration 8008: loss: 0.068076, loss_s1: 0.047446, loss_fp: 0.000359, loss_freq: 0.025916
[03:52:40.096] iteration 8009: loss: 0.071471, loss_s1: 0.062826, loss_fp: 0.003685, loss_freq: 0.030587
[03:52:40.704] iteration 8010: loss: 0.112343, loss_s1: 0.073723, loss_fp: 0.000773, loss_freq: 0.026658
[03:52:41.286] iteration 8011: loss: 0.077602, loss_s1: 0.039284, loss_fp: 0.013913, loss_freq: 0.041899
[03:52:41.872] iteration 8012: loss: 0.083817, loss_s1: 0.040078, loss_fp: 0.004704, loss_freq: 0.053457
[03:52:42.461] iteration 8013: loss: 0.102578, loss_s1: 0.061474, loss_fp: 0.009548, loss_freq: 0.039339
[03:52:43.055] iteration 8014: loss: 0.096860, loss_s1: 0.093633, loss_fp: 0.003992, loss_freq: 0.025082
[03:52:43.643] iteration 8015: loss: 0.136369, loss_s1: 0.116375, loss_fp: 0.005647, loss_freq: 0.041272
[03:52:44.262] iteration 8016: loss: 0.084641, loss_s1: 0.052866, loss_fp: 0.004033, loss_freq: 0.052202
[03:52:44.857] iteration 8017: loss: 0.103802, loss_s1: 0.079417, loss_fp: 0.001875, loss_freq: 0.038321
[03:52:45.455] iteration 8018: loss: 0.145922, loss_s1: 0.111263, loss_fp: 0.000806, loss_freq: 0.038841
[03:52:46.045] iteration 8019: loss: 0.072032, loss_s1: 0.030992, loss_fp: 0.002814, loss_freq: 0.046439
[03:52:46.679] iteration 8020: loss: 0.100558, loss_s1: 0.086006, loss_fp: 0.006083, loss_freq: 0.036310
[03:52:47.334] iteration 8021: loss: 0.105187, loss_s1: 0.099009, loss_fp: 0.004779, loss_freq: 0.046957
[03:52:47.960] iteration 8022: loss: 0.080840, loss_s1: 0.037334, loss_fp: 0.002030, loss_freq: 0.040950
[03:52:48.591] iteration 8023: loss: 0.138799, loss_s1: 0.165598, loss_fp: 0.006267, loss_freq: 0.046832
[03:52:49.227] iteration 8024: loss: 0.092375, loss_s1: 0.082311, loss_fp: 0.001754, loss_freq: 0.010074
[03:52:49.864] iteration 8025: loss: 0.080508, loss_s1: 0.057566, loss_fp: 0.000960, loss_freq: 0.049287
[03:52:50.479] iteration 8026: loss: 0.071265, loss_s1: 0.038062, loss_fp: 0.001399, loss_freq: 0.018428
[03:52:51.075] iteration 8027: loss: 0.087459, loss_s1: 0.073154, loss_fp: 0.002534, loss_freq: 0.029581
[03:52:51.671] iteration 8028: loss: 0.077344, loss_s1: 0.066323, loss_fp: 0.008431, loss_freq: 0.037346
[03:52:52.265] iteration 8029: loss: 0.140130, loss_s1: 0.154397, loss_fp: 0.004053, loss_freq: 0.061477
[03:52:52.860] iteration 8030: loss: 0.140520, loss_s1: 0.123957, loss_fp: 0.002822, loss_freq: 0.040219
[03:52:53.453] iteration 8031: loss: 0.096437, loss_s1: 0.053368, loss_fp: 0.005857, loss_freq: 0.071581
[03:52:54.090] iteration 8032: loss: 0.115273, loss_s1: 0.136993, loss_fp: 0.003225, loss_freq: 0.043992
[03:52:54.717] iteration 8033: loss: 0.111831, loss_s1: 0.117345, loss_fp: 0.008928, loss_freq: 0.040537
[03:52:55.314] iteration 8034: loss: 0.106952, loss_s1: 0.091254, loss_fp: 0.007785, loss_freq: 0.045243
[03:52:55.907] iteration 8035: loss: 0.076723, loss_s1: 0.064613, loss_fp: 0.002494, loss_freq: 0.015454
[03:52:56.499] iteration 8036: loss: 0.095841, loss_s1: 0.081256, loss_fp: 0.004973, loss_freq: 0.030283
[03:52:57.092] iteration 8037: loss: 0.068001, loss_s1: 0.057759, loss_fp: 0.004781, loss_freq: 0.019854
[03:52:57.686] iteration 8038: loss: 0.067570, loss_s1: 0.050213, loss_fp: 0.001077, loss_freq: 0.014512
[03:52:58.276] iteration 8039: loss: 0.081553, loss_s1: 0.080246, loss_fp: 0.002535, loss_freq: 0.015473
[03:52:58.864] iteration 8040: loss: 0.082447, loss_s1: 0.070907, loss_fp: 0.007066, loss_freq: 0.016186
[03:52:59.553] iteration 8041: loss: 0.061411, loss_s1: 0.039607, loss_fp: 0.001158, loss_freq: 0.025053
[03:53:00.145] iteration 8042: loss: 0.101163, loss_s1: 0.093002, loss_fp: 0.003579, loss_freq: 0.056590
[03:53:00.742] iteration 8043: loss: 0.070309, loss_s1: 0.053866, loss_fp: 0.002289, loss_freq: 0.016217
[03:53:01.345] iteration 8044: loss: 0.093316, loss_s1: 0.047101, loss_fp: 0.003812, loss_freq: 0.077195
[03:53:01.938] iteration 8045: loss: 0.091908, loss_s1: 0.026084, loss_fp: 0.002848, loss_freq: 0.083865
[03:53:02.556] iteration 8046: loss: 0.061603, loss_s1: 0.038278, loss_fp: 0.001152, loss_freq: 0.033638
[03:53:03.155] iteration 8047: loss: 0.107495, loss_s1: 0.101000, loss_fp: 0.003668, loss_freq: 0.056258
[03:53:03.758] iteration 8048: loss: 0.090274, loss_s1: 0.052258, loss_fp: 0.000967, loss_freq: 0.028740
[03:53:04.346] iteration 8049: loss: 0.154003, loss_s1: 0.099456, loss_fp: 0.006036, loss_freq: 0.081813
[03:53:04.938] iteration 8050: loss: 0.168158, loss_s1: 0.208146, loss_fp: 0.003303, loss_freq: 0.063370
[03:53:05.528] iteration 8051: loss: 0.054744, loss_s1: 0.030270, loss_fp: 0.003340, loss_freq: 0.010997
[03:53:06.123] iteration 8052: loss: 0.102603, loss_s1: 0.077993, loss_fp: 0.001927, loss_freq: 0.035978
[03:53:06.714] iteration 8053: loss: 0.060664, loss_s1: 0.030428, loss_fp: 0.001385, loss_freq: 0.018283
[03:53:07.311] iteration 8054: loss: 0.082518, loss_s1: 0.069522, loss_fp: 0.003025, loss_freq: 0.024022
[03:53:07.904] iteration 8055: loss: 0.083596, loss_s1: 0.055830, loss_fp: 0.010677, loss_freq: 0.030275
[03:53:08.538] iteration 8056: loss: 0.111635, loss_s1: 0.100539, loss_fp: 0.002994, loss_freq: 0.040758
[03:53:09.174] iteration 8057: loss: 0.081737, loss_s1: 0.044545, loss_fp: 0.004364, loss_freq: 0.020656
[03:53:09.805] iteration 8058: loss: 0.100934, loss_s1: 0.071519, loss_fp: 0.007450, loss_freq: 0.073172
[03:53:10.395] iteration 8059: loss: 0.085250, loss_s1: 0.028576, loss_fp: 0.007516, loss_freq: 0.032624
[03:53:10.984] iteration 8060: loss: 0.086705, loss_s1: 0.055503, loss_fp: 0.007376, loss_freq: 0.034463
[03:53:11.574] iteration 8061: loss: 0.099488, loss_s1: 0.060652, loss_fp: 0.002783, loss_freq: 0.054181
[03:53:12.169] iteration 8062: loss: 0.068517, loss_s1: 0.065935, loss_fp: 0.001257, loss_freq: 0.012269
[03:53:12.759] iteration 8063: loss: 0.082500, loss_s1: 0.065639, loss_fp: 0.001695, loss_freq: 0.035157
[03:53:13.438] iteration 8064: loss: 0.073234, loss_s1: 0.052404, loss_fp: 0.001415, loss_freq: 0.030400
[03:53:14.034] iteration 8065: loss: 0.119875, loss_s1: 0.059410, loss_fp: 0.001618, loss_freq: 0.059144
[03:53:14.649] iteration 8066: loss: 0.090835, loss_s1: 0.058269, loss_fp: 0.008067, loss_freq: 0.039369
[03:53:15.265] iteration 8067: loss: 0.064511, loss_s1: 0.038206, loss_fp: 0.006298, loss_freq: 0.026659
[03:53:15.871] iteration 8068: loss: 0.110075, loss_s1: 0.097910, loss_fp: 0.010564, loss_freq: 0.046865
[03:53:16.481] iteration 8069: loss: 0.053628, loss_s1: 0.017393, loss_fp: 0.002033, loss_freq: 0.034908
[03:53:17.076] iteration 8070: loss: 0.063569, loss_s1: 0.029878, loss_fp: 0.003416, loss_freq: 0.012957
[03:53:17.668] iteration 8071: loss: 0.108802, loss_s1: 0.061808, loss_fp: 0.000588, loss_freq: 0.083860
[03:53:18.258] iteration 8072: loss: 0.075614, loss_s1: 0.049685, loss_fp: 0.002704, loss_freq: 0.039640
[03:53:18.845] iteration 8073: loss: 0.112057, loss_s1: 0.128468, loss_fp: 0.005009, loss_freq: 0.031319
[03:53:19.445] iteration 8074: loss: 0.089033, loss_s1: 0.049504, loss_fp: 0.004013, loss_freq: 0.015755
[03:53:20.034] iteration 8075: loss: 0.116614, loss_s1: 0.100569, loss_fp: 0.003926, loss_freq: 0.058115
[03:53:20.623] iteration 8076: loss: 0.092647, loss_s1: 0.072950, loss_fp: 0.003137, loss_freq: 0.046836
[03:53:21.213] iteration 8077: loss: 0.118769, loss_s1: 0.097038, loss_fp: 0.003764, loss_freq: 0.073342
[03:53:21.801] iteration 8078: loss: 0.076291, loss_s1: 0.048423, loss_fp: 0.001945, loss_freq: 0.023527
[03:53:22.389] iteration 8079: loss: 0.087403, loss_s1: 0.064071, loss_fp: 0.005243, loss_freq: 0.052300
[03:53:22.982] iteration 8080: loss: 0.084644, loss_s1: 0.046012, loss_fp: 0.004302, loss_freq: 0.040148
[03:53:23.574] iteration 8081: loss: 0.114644, loss_s1: 0.071350, loss_fp: 0.009753, loss_freq: 0.044479
[03:53:24.173] iteration 8082: loss: 0.115757, loss_s1: 0.068628, loss_fp: 0.003663, loss_freq: 0.089446
[03:53:24.764] iteration 8083: loss: 0.123791, loss_s1: 0.114918, loss_fp: 0.005944, loss_freq: 0.057170
[03:53:25.359] iteration 8084: loss: 0.074386, loss_s1: 0.055425, loss_fp: 0.000813, loss_freq: 0.032506
[03:53:25.955] iteration 8085: loss: 0.070470, loss_s1: 0.057822, loss_fp: 0.001251, loss_freq: 0.037091
[03:53:26.543] iteration 8086: loss: 0.059765, loss_s1: 0.043264, loss_fp: 0.002146, loss_freq: 0.023666
[03:53:27.154] iteration 8087: loss: 0.083480, loss_s1: 0.051657, loss_fp: 0.001832, loss_freq: 0.036493
[03:53:27.745] iteration 8088: loss: 0.078123, loss_s1: 0.027041, loss_fp: 0.000878, loss_freq: 0.064518
[03:53:28.337] iteration 8089: loss: 0.085097, loss_s1: 0.059659, loss_fp: 0.000574, loss_freq: 0.060825
[03:53:28.927] iteration 8090: loss: 0.063869, loss_s1: 0.047775, loss_fp: 0.001953, loss_freq: 0.021684
[03:53:29.523] iteration 8091: loss: 0.070581, loss_s1: 0.041844, loss_fp: 0.001185, loss_freq: 0.033201
[03:53:30.122] iteration 8092: loss: 0.084560, loss_s1: 0.063521, loss_fp: 0.000506, loss_freq: 0.012160
[03:53:30.714] iteration 8093: loss: 0.058509, loss_s1: 0.036690, loss_fp: 0.000924, loss_freq: 0.033002
[03:53:31.307] iteration 8094: loss: 0.090606, loss_s1: 0.041887, loss_fp: 0.005695, loss_freq: 0.031369
[03:53:31.907] iteration 8095: loss: 0.093521, loss_s1: 0.045412, loss_fp: 0.002050, loss_freq: 0.068123
[03:53:32.501] iteration 8096: loss: 0.101781, loss_s1: 0.100568, loss_fp: 0.006744, loss_freq: 0.021366
[03:53:33.096] iteration 8097: loss: 0.077254, loss_s1: 0.038482, loss_fp: 0.001602, loss_freq: 0.046341
[03:53:33.689] iteration 8098: loss: 0.073744, loss_s1: 0.051205, loss_fp: 0.005927, loss_freq: 0.023363
[03:53:34.288] iteration 8099: loss: 0.144515, loss_s1: 0.080156, loss_fp: 0.005099, loss_freq: 0.117064
[03:53:34.896] iteration 8100: loss: 0.060170, loss_s1: 0.043060, loss_fp: 0.001698, loss_freq: 0.019083
[03:53:35.489] iteration 8101: loss: 0.061411, loss_s1: 0.035445, loss_fp: 0.001785, loss_freq: 0.023830
[03:53:36.082] iteration 8102: loss: 0.072539, loss_s1: 0.048196, loss_fp: 0.003898, loss_freq: 0.044391
[03:53:36.674] iteration 8103: loss: 0.090924, loss_s1: 0.090488, loss_fp: 0.001375, loss_freq: 0.035701
[03:53:37.267] iteration 8104: loss: 0.098343, loss_s1: 0.062940, loss_fp: 0.005240, loss_freq: 0.030876
[03:53:37.853] iteration 8105: loss: 0.144263, loss_s1: 0.067710, loss_fp: 0.005836, loss_freq: 0.082872
[03:53:38.442] iteration 8106: loss: 0.075748, loss_s1: 0.029898, loss_fp: 0.001935, loss_freq: 0.054963
[03:53:39.032] iteration 8107: loss: 0.121741, loss_s1: 0.060784, loss_fp: 0.004461, loss_freq: 0.074870
[03:53:39.617] iteration 8108: loss: 0.090214, loss_s1: 0.067854, loss_fp: 0.002089, loss_freq: 0.055567
[03:53:40.207] iteration 8109: loss: 0.110212, loss_s1: 0.053669, loss_fp: 0.001610, loss_freq: 0.070936
[03:53:40.797] iteration 8110: loss: 0.055168, loss_s1: 0.027748, loss_fp: 0.001084, loss_freq: 0.009060
[03:53:41.390] iteration 8111: loss: 0.063561, loss_s1: 0.037431, loss_fp: 0.001475, loss_freq: 0.029184
[03:53:41.992] iteration 8112: loss: 0.056779, loss_s1: 0.044932, loss_fp: 0.003071, loss_freq: 0.025524
[03:53:42.600] iteration 8113: loss: 0.091428, loss_s1: 0.068360, loss_fp: 0.000656, loss_freq: 0.041544
[03:53:43.245] iteration 8114: loss: 0.106854, loss_s1: 0.095843, loss_fp: 0.001732, loss_freq: 0.032544
[03:53:43.865] iteration 8115: loss: 0.099573, loss_s1: 0.050691, loss_fp: 0.014324, loss_freq: 0.054383
[03:53:44.477] iteration 8116: loss: 0.058141, loss_s1: 0.029500, loss_fp: 0.000592, loss_freq: 0.027792
[03:53:45.174] iteration 8117: loss: 0.087667, loss_s1: 0.042032, loss_fp: 0.004115, loss_freq: 0.079309
[03:53:45.818] iteration 8118: loss: 0.098390, loss_s1: 0.058795, loss_fp: 0.006883, loss_freq: 0.025361
[03:53:46.451] iteration 8119: loss: 0.059539, loss_s1: 0.020484, loss_fp: 0.004483, loss_freq: 0.028320
[03:53:47.086] iteration 8120: loss: 0.098982, loss_s1: 0.083598, loss_fp: 0.008466, loss_freq: 0.047049
[03:53:47.722] iteration 8121: loss: 0.116154, loss_s1: 0.177725, loss_fp: 0.005482, loss_freq: 0.009115
[03:53:48.363] iteration 8122: loss: 0.110306, loss_s1: 0.045693, loss_fp: 0.002263, loss_freq: 0.023713
[03:53:49.042] iteration 8123: loss: 0.120858, loss_s1: 0.088852, loss_fp: 0.002454, loss_freq: 0.080626
[03:53:49.687] iteration 8124: loss: 0.129501, loss_s1: 0.067207, loss_fp: 0.002614, loss_freq: 0.041470
[03:53:50.282] iteration 8125: loss: 0.116174, loss_s1: 0.084835, loss_fp: 0.002537, loss_freq: 0.087390
[03:53:50.878] iteration 8126: loss: 0.063978, loss_s1: 0.053836, loss_fp: 0.000941, loss_freq: 0.023197
[03:53:51.471] iteration 8127: loss: 0.148515, loss_s1: 0.131016, loss_fp: 0.003538, loss_freq: 0.049990
[03:53:52.064] iteration 8128: loss: 0.072343, loss_s1: 0.051979, loss_fp: 0.004731, loss_freq: 0.035972
[03:53:52.705] iteration 8129: loss: 0.139244, loss_s1: 0.137170, loss_fp: 0.006100, loss_freq: 0.066870
[03:53:53.300] iteration 8130: loss: 0.082577, loss_s1: 0.065635, loss_fp: 0.003715, loss_freq: 0.044437
[03:53:53.898] iteration 8131: loss: 0.083391, loss_s1: 0.071986, loss_fp: 0.004711, loss_freq: 0.028466
[03:53:54.502] iteration 8132: loss: 0.089657, loss_s1: 0.078488, loss_fp: 0.001495, loss_freq: 0.038874
[03:53:55.098] iteration 8133: loss: 0.081408, loss_s1: 0.078740, loss_fp: 0.002526, loss_freq: 0.030229
[03:53:55.699] iteration 8134: loss: 0.106314, loss_s1: 0.074556, loss_fp: 0.003777, loss_freq: 0.026858
[03:53:56.296] iteration 8135: loss: 0.057844, loss_s1: 0.030826, loss_fp: 0.002020, loss_freq: 0.017803
[03:53:56.885] iteration 8136: loss: 0.066937, loss_s1: 0.042724, loss_fp: 0.002073, loss_freq: 0.031010
[03:53:57.476] iteration 8137: loss: 0.068870, loss_s1: 0.034186, loss_fp: 0.001664, loss_freq: 0.020251
[03:53:58.069] iteration 8138: loss: 0.154107, loss_s1: 0.102691, loss_fp: 0.004597, loss_freq: 0.057034
[03:53:58.667] iteration 8139: loss: 0.068726, loss_s1: 0.060109, loss_fp: 0.001729, loss_freq: 0.036330
[03:53:59.263] iteration 8140: loss: 0.107869, loss_s1: 0.058438, loss_fp: 0.002487, loss_freq: 0.073544
[03:53:59.853] iteration 8141: loss: 0.089696, loss_s1: 0.063905, loss_fp: 0.001499, loss_freq: 0.038124
[03:54:00.446] iteration 8142: loss: 0.094498, loss_s1: 0.091731, loss_fp: 0.005460, loss_freq: 0.038559
[03:54:01.047] iteration 8143: loss: 0.118987, loss_s1: 0.075484, loss_fp: 0.012357, loss_freq: 0.037359
[03:54:01.637] iteration 8144: loss: 0.065968, loss_s1: 0.038878, loss_fp: 0.008861, loss_freq: 0.022190
[03:54:02.274] iteration 8145: loss: 0.111996, loss_s1: 0.078328, loss_fp: 0.004600, loss_freq: 0.042670
[03:54:02.872] iteration 8146: loss: 0.087334, loss_s1: 0.095625, loss_fp: 0.003720, loss_freq: 0.020248
[03:54:03.463] iteration 8147: loss: 0.076120, loss_s1: 0.065704, loss_fp: 0.001844, loss_freq: 0.023781
[03:54:04.062] iteration 8148: loss: 0.106969, loss_s1: 0.084264, loss_fp: 0.001452, loss_freq: 0.066493
[03:54:04.655] iteration 8149: loss: 0.067204, loss_s1: 0.040688, loss_fp: 0.005294, loss_freq: 0.037024
[03:54:05.253] iteration 8150: loss: 0.088433, loss_s1: 0.086848, loss_fp: 0.003890, loss_freq: 0.017597
[03:54:05.841] iteration 8151: loss: 0.050769, loss_s1: 0.014947, loss_fp: 0.002475, loss_freq: 0.018426
[03:54:06.475] iteration 8152: loss: 0.065728, loss_s1: 0.033760, loss_fp: 0.006818, loss_freq: 0.034025
[03:54:07.108] iteration 8153: loss: 0.069723, loss_s1: 0.018014, loss_fp: 0.001627, loss_freq: 0.020772
[03:54:07.741] iteration 8154: loss: 0.062661, loss_s1: 0.019019, loss_fp: 0.004924, loss_freq: 0.030726
[03:54:08.354] iteration 8155: loss: 0.052795, loss_s1: 0.030242, loss_fp: 0.000925, loss_freq: 0.010323
[03:54:08.957] iteration 8156: loss: 0.141818, loss_s1: 0.114830, loss_fp: 0.005980, loss_freq: 0.072679
[03:54:09.554] iteration 8157: loss: 0.075784, loss_s1: 0.033147, loss_fp: 0.004606, loss_freq: 0.046314
[03:54:10.150] iteration 8158: loss: 0.072205, loss_s1: 0.041562, loss_fp: 0.000493, loss_freq: 0.023647
[03:54:10.736] iteration 8159: loss: 0.096246, loss_s1: 0.075850, loss_fp: 0.002353, loss_freq: 0.067668
[03:54:11.331] iteration 8160: loss: 0.104057, loss_s1: 0.077192, loss_fp: 0.001746, loss_freq: 0.067289
[03:54:12.240] iteration 8161: loss: 0.078258, loss_s1: 0.038974, loss_fp: 0.001616, loss_freq: 0.013823
[03:54:12.837] iteration 8162: loss: 0.150522, loss_s1: 0.189447, loss_fp: 0.000580, loss_freq: 0.051146
[03:54:13.437] iteration 8163: loss: 0.120819, loss_s1: 0.114691, loss_fp: 0.006696, loss_freq: 0.046772
[03:54:14.030] iteration 8164: loss: 0.077255, loss_s1: 0.056484, loss_fp: 0.005709, loss_freq: 0.025468
[03:54:14.631] iteration 8165: loss: 0.082910, loss_s1: 0.065933, loss_fp: 0.004247, loss_freq: 0.021199
[03:54:15.221] iteration 8166: loss: 0.141413, loss_s1: 0.103203, loss_fp: 0.002305, loss_freq: 0.042622
[03:54:15.814] iteration 8167: loss: 0.082826, loss_s1: 0.052964, loss_fp: 0.001392, loss_freq: 0.045538
[03:54:16.403] iteration 8168: loss: 0.071174, loss_s1: 0.050136, loss_fp: 0.005532, loss_freq: 0.027690
[03:54:16.993] iteration 8169: loss: 0.079189, loss_s1: 0.050492, loss_fp: 0.001340, loss_freq: 0.017296
[03:54:17.585] iteration 8170: loss: 0.115262, loss_s1: 0.116547, loss_fp: 0.005024, loss_freq: 0.048484
[03:54:18.180] iteration 8171: loss: 0.117509, loss_s1: 0.066452, loss_fp: 0.000722, loss_freq: 0.069594
[03:54:18.775] iteration 8172: loss: 0.087699, loss_s1: 0.031340, loss_fp: 0.003870, loss_freq: 0.083014
[03:54:19.375] iteration 8173: loss: 0.115372, loss_s1: 0.102897, loss_fp: 0.004405, loss_freq: 0.056538
[03:54:19.967] iteration 8174: loss: 0.073167, loss_s1: 0.034562, loss_fp: 0.001427, loss_freq: 0.046562
[03:54:20.561] iteration 8175: loss: 0.090739, loss_s1: 0.056390, loss_fp: 0.004281, loss_freq: 0.017564
[03:54:21.150] iteration 8176: loss: 0.091721, loss_s1: 0.080833, loss_fp: 0.002432, loss_freq: 0.042806
[03:54:21.744] iteration 8177: loss: 0.099870, loss_s1: 0.080877, loss_fp: 0.013881, loss_freq: 0.045812
[03:54:22.336] iteration 8178: loss: 0.064746, loss_s1: 0.032040, loss_fp: 0.001135, loss_freq: 0.023338
[03:54:22.958] iteration 8179: loss: 0.114669, loss_s1: 0.116450, loss_fp: 0.008204, loss_freq: 0.053341
[03:54:23.597] iteration 8180: loss: 0.091239, loss_s1: 0.083424, loss_fp: 0.004878, loss_freq: 0.035689
[03:54:24.216] iteration 8181: loss: 0.073699, loss_s1: 0.048563, loss_fp: 0.006736, loss_freq: 0.037782
[03:54:24.811] iteration 8182: loss: 0.074564, loss_s1: 0.071455, loss_fp: 0.002312, loss_freq: 0.038077
[03:54:25.409] iteration 8183: loss: 0.109062, loss_s1: 0.078755, loss_fp: 0.001884, loss_freq: 0.043276
[03:54:26.000] iteration 8184: loss: 0.065675, loss_s1: 0.045238, loss_fp: 0.002225, loss_freq: 0.026934
[03:54:26.602] iteration 8185: loss: 0.073273, loss_s1: 0.054131, loss_fp: 0.002828, loss_freq: 0.032515
[03:54:27.199] iteration 8186: loss: 0.097056, loss_s1: 0.064234, loss_fp: 0.004091, loss_freq: 0.048922
[03:54:27.795] iteration 8187: loss: 0.099171, loss_s1: 0.064765, loss_fp: 0.005467, loss_freq: 0.033294
[03:54:28.421] iteration 8188: loss: 0.140595, loss_s1: 0.088881, loss_fp: 0.004085, loss_freq: 0.063277
[03:54:29.017] iteration 8189: loss: 0.095113, loss_s1: 0.052445, loss_fp: 0.001102, loss_freq: 0.055613
[03:54:29.610] iteration 8190: loss: 0.130374, loss_s1: 0.133629, loss_fp: 0.005967, loss_freq: 0.067670
[03:54:30.203] iteration 8191: loss: 0.082386, loss_s1: 0.080806, loss_fp: 0.003466, loss_freq: 0.037777
[03:54:30.794] iteration 8192: loss: 0.106048, loss_s1: 0.106106, loss_fp: 0.002197, loss_freq: 0.037390
[03:54:31.389] iteration 8193: loss: 0.125095, loss_s1: 0.087873, loss_fp: 0.004299, loss_freq: 0.043869
[03:54:31.984] iteration 8194: loss: 0.061537, loss_s1: 0.024426, loss_fp: 0.017179, loss_freq: 0.019951
[03:54:32.586] iteration 8195: loss: 0.070942, loss_s1: 0.040311, loss_fp: 0.001432, loss_freq: 0.040503
[03:54:33.181] iteration 8196: loss: 0.083137, loss_s1: 0.049771, loss_fp: 0.005379, loss_freq: 0.026347
[03:54:33.774] iteration 8197: loss: 0.103566, loss_s1: 0.076723, loss_fp: 0.006325, loss_freq: 0.039097
[03:54:34.370] iteration 8198: loss: 0.067080, loss_s1: 0.014972, loss_fp: 0.001183, loss_freq: 0.022731
[03:54:34.965] iteration 8199: loss: 0.088482, loss_s1: 0.079980, loss_fp: 0.002281, loss_freq: 0.040496
[03:54:35.555] iteration 8200: loss: 0.061887, loss_s1: 0.030844, loss_fp: 0.000758, loss_freq: 0.028033
[03:54:38.869] iteration 8200 : mean_dice : 0.685760
[03:54:39.492] iteration 8201: loss: 0.092356, loss_s1: 0.058655, loss_fp: 0.005192, loss_freq: 0.060221
[03:54:40.090] iteration 8202: loss: 0.094542, loss_s1: 0.091135, loss_fp: 0.001887, loss_freq: 0.048329
[03:54:40.708] iteration 8203: loss: 0.102424, loss_s1: 0.076768, loss_fp: 0.003259, loss_freq: 0.067414
[03:54:41.299] iteration 8204: loss: 0.108615, loss_s1: 0.106965, loss_fp: 0.004318, loss_freq: 0.043690
[03:54:41.889] iteration 8205: loss: 0.099732, loss_s1: 0.050559, loss_fp: 0.002501, loss_freq: 0.036459
[03:54:42.477] iteration 8206: loss: 0.091164, loss_s1: 0.069885, loss_fp: 0.002007, loss_freq: 0.044589
[03:54:43.074] iteration 8207: loss: 0.065177, loss_s1: 0.046009, loss_fp: 0.004832, loss_freq: 0.024431
[03:54:43.665] iteration 8208: loss: 0.073694, loss_s1: 0.044169, loss_fp: 0.003940, loss_freq: 0.048717
[03:54:44.257] iteration 8209: loss: 0.054796, loss_s1: 0.037744, loss_fp: 0.001050, loss_freq: 0.015628
[03:54:44.848] iteration 8210: loss: 0.071499, loss_s1: 0.030845, loss_fp: 0.000633, loss_freq: 0.019507
[03:54:45.439] iteration 8211: loss: 0.075949, loss_s1: 0.037832, loss_fp: 0.000684, loss_freq: 0.048460
[03:54:46.031] iteration 8212: loss: 0.096656, loss_s1: 0.104998, loss_fp: 0.002780, loss_freq: 0.038088
[03:54:46.623] iteration 8213: loss: 0.055398, loss_s1: 0.013971, loss_fp: 0.002554, loss_freq: 0.043003
[03:54:47.214] iteration 8214: loss: 0.168822, loss_s1: 0.146239, loss_fp: 0.003216, loss_freq: 0.120532
[03:54:47.812] iteration 8215: loss: 0.144207, loss_s1: 0.066882, loss_fp: 0.003416, loss_freq: 0.122845
[03:54:48.405] iteration 8216: loss: 0.065041, loss_s1: 0.025467, loss_fp: 0.002214, loss_freq: 0.034330
[03:54:49.003] iteration 8217: loss: 0.086945, loss_s1: 0.047448, loss_fp: 0.003159, loss_freq: 0.065623
[03:54:49.600] iteration 8218: loss: 0.075576, loss_s1: 0.023678, loss_fp: 0.001477, loss_freq: 0.019349
[03:54:50.232] iteration 8219: loss: 0.094434, loss_s1: 0.058339, loss_fp: 0.006958, loss_freq: 0.028691
[03:54:50.822] iteration 8220: loss: 0.111178, loss_s1: 0.085319, loss_fp: 0.003891, loss_freq: 0.060697
[03:54:51.413] iteration 8221: loss: 0.051078, loss_s1: 0.043089, loss_fp: 0.000611, loss_freq: 0.011108
[03:54:52.012] iteration 8222: loss: 0.081705, loss_s1: 0.036037, loss_fp: 0.003428, loss_freq: 0.038484
[03:54:52.608] iteration 8223: loss: 0.056501, loss_s1: 0.027037, loss_fp: 0.001340, loss_freq: 0.025711
[03:54:53.204] iteration 8224: loss: 0.074618, loss_s1: 0.086133, loss_fp: 0.002219, loss_freq: 0.016538
[03:54:53.827] iteration 8225: loss: 0.127288, loss_s1: 0.163550, loss_fp: 0.002491, loss_freq: 0.032255
[03:54:54.419] iteration 8226: loss: 0.107681, loss_s1: 0.089344, loss_fp: 0.003094, loss_freq: 0.050192
[03:54:55.025] iteration 8227: loss: 0.076925, loss_s1: 0.048149, loss_fp: 0.001137, loss_freq: 0.024336
[03:54:55.628] iteration 8228: loss: 0.146586, loss_s1: 0.123426, loss_fp: 0.004558, loss_freq: 0.041579
[03:54:56.221] iteration 8229: loss: 0.061952, loss_s1: 0.030896, loss_fp: 0.004318, loss_freq: 0.019463
[03:54:56.839] iteration 8230: loss: 0.083209, loss_s1: 0.059028, loss_fp: 0.003310, loss_freq: 0.046470
[03:54:57.493] iteration 8231: loss: 0.088646, loss_s1: 0.060349, loss_fp: 0.009003, loss_freq: 0.035931
[03:54:58.106] iteration 8232: loss: 0.076871, loss_s1: 0.068212, loss_fp: 0.002930, loss_freq: 0.019880
[03:54:58.732] iteration 8233: loss: 0.054056, loss_s1: 0.029886, loss_fp: 0.003498, loss_freq: 0.033942
[03:54:59.352] iteration 8234: loss: 0.081210, loss_s1: 0.049909, loss_fp: 0.006811, loss_freq: 0.041408
[03:54:59.986] iteration 8235: loss: 0.097463, loss_s1: 0.041837, loss_fp: 0.009375, loss_freq: 0.077485
[03:55:00.580] iteration 8236: loss: 0.058002, loss_s1: 0.034419, loss_fp: 0.002788, loss_freq: 0.016610
[03:55:01.170] iteration 8237: loss: 0.063459, loss_s1: 0.053903, loss_fp: 0.002763, loss_freq: 0.020310
[03:55:01.785] iteration 8238: loss: 0.155587, loss_s1: 0.104605, loss_fp: 0.005854, loss_freq: 0.051162
[03:55:02.411] iteration 8239: loss: 0.089192, loss_s1: 0.059898, loss_fp: 0.003403, loss_freq: 0.069757
[03:55:03.005] iteration 8240: loss: 0.083098, loss_s1: 0.053023, loss_fp: 0.003756, loss_freq: 0.031064
[03:55:03.604] iteration 8241: loss: 0.089653, loss_s1: 0.025565, loss_fp: 0.003036, loss_freq: 0.060504
[03:55:04.204] iteration 8242: loss: 0.101348, loss_s1: 0.078024, loss_fp: 0.003637, loss_freq: 0.059565
[03:55:05.051] iteration 8243: loss: 0.078454, loss_s1: 0.081896, loss_fp: 0.000707, loss_freq: 0.032456
[03:55:05.984] iteration 8244: loss: 0.050684, loss_s1: 0.041121, loss_fp: 0.001052, loss_freq: 0.010095
[03:55:06.668] iteration 8245: loss: 0.090745, loss_s1: 0.049656, loss_fp: 0.001157, loss_freq: 0.069331
[03:55:07.269] iteration 8246: loss: 0.066874, loss_s1: 0.051986, loss_fp: 0.003803, loss_freq: 0.017483
[03:55:07.870] iteration 8247: loss: 0.090730, loss_s1: 0.080836, loss_fp: 0.003521, loss_freq: 0.058915
[03:55:08.465] iteration 8248: loss: 0.079017, loss_s1: 0.074789, loss_fp: 0.003873, loss_freq: 0.032418
[03:55:09.068] iteration 8249: loss: 0.106675, loss_s1: 0.074881, loss_fp: 0.016975, loss_freq: 0.074015
[03:55:09.660] iteration 8250: loss: 0.092969, loss_s1: 0.076604, loss_fp: 0.004211, loss_freq: 0.019778
[03:55:10.255] iteration 8251: loss: 0.082540, loss_s1: 0.066788, loss_fp: 0.001293, loss_freq: 0.025939
[03:55:10.852] iteration 8252: loss: 0.121253, loss_s1: 0.097269, loss_fp: 0.008682, loss_freq: 0.057219
[03:55:11.441] iteration 8253: loss: 0.121886, loss_s1: 0.060399, loss_fp: 0.002173, loss_freq: 0.103685
[03:55:12.036] iteration 8254: loss: 0.067140, loss_s1: 0.046750, loss_fp: 0.002454, loss_freq: 0.007834
[03:55:12.631] iteration 8255: loss: 0.122373, loss_s1: 0.107589, loss_fp: 0.003546, loss_freq: 0.030542
[03:55:13.226] iteration 8256: loss: 0.095279, loss_s1: 0.068269, loss_fp: 0.006841, loss_freq: 0.031983
[03:55:13.820] iteration 8257: loss: 0.131198, loss_s1: 0.105078, loss_fp: 0.001085, loss_freq: 0.041136
[03:55:14.415] iteration 8258: loss: 0.106513, loss_s1: 0.088644, loss_fp: 0.001443, loss_freq: 0.025976
[03:55:15.006] iteration 8259: loss: 0.150092, loss_s1: 0.134398, loss_fp: 0.002437, loss_freq: 0.052631
[03:55:15.599] iteration 8260: loss: 0.095624, loss_s1: 0.093536, loss_fp: 0.003502, loss_freq: 0.035818
[03:55:16.187] iteration 8261: loss: 0.110600, loss_s1: 0.100827, loss_fp: 0.001660, loss_freq: 0.054960
[03:55:16.778] iteration 8262: loss: 0.065606, loss_s1: 0.041265, loss_fp: 0.002089, loss_freq: 0.022839
[03:55:17.372] iteration 8263: loss: 0.070457, loss_s1: 0.025236, loss_fp: 0.001094, loss_freq: 0.029468
[03:55:17.961] iteration 8264: loss: 0.075460, loss_s1: 0.023263, loss_fp: 0.002870, loss_freq: 0.027053
[03:55:18.551] iteration 8265: loss: 0.057934, loss_s1: 0.038149, loss_fp: 0.003014, loss_freq: 0.030151
[03:55:19.173] iteration 8266: loss: 0.069955, loss_s1: 0.046509, loss_fp: 0.005704, loss_freq: 0.030344
[03:55:19.799] iteration 8267: loss: 0.075083, loss_s1: 0.052612, loss_fp: 0.002293, loss_freq: 0.017199
[03:55:20.424] iteration 8268: loss: 0.068898, loss_s1: 0.049636, loss_fp: 0.001443, loss_freq: 0.025813
[03:55:21.011] iteration 8269: loss: 0.104362, loss_s1: 0.088365, loss_fp: 0.008831, loss_freq: 0.054065
[03:55:21.632] iteration 8270: loss: 0.086517, loss_s1: 0.100841, loss_fp: 0.001408, loss_freq: 0.028231
[03:55:22.226] iteration 8271: loss: 0.093681, loss_s1: 0.061467, loss_fp: 0.004262, loss_freq: 0.030410
[03:55:22.819] iteration 8272: loss: 0.054120, loss_s1: 0.019987, loss_fp: 0.001758, loss_freq: 0.036514
[03:55:23.412] iteration 8273: loss: 0.065995, loss_s1: 0.032165, loss_fp: 0.001955, loss_freq: 0.023214
[03:55:24.012] iteration 8274: loss: 0.057251, loss_s1: 0.033673, loss_fp: 0.005958, loss_freq: 0.014368
[03:55:24.605] iteration 8275: loss: 0.175696, loss_s1: 0.096061, loss_fp: 0.008337, loss_freq: 0.107761
[03:55:25.197] iteration 8276: loss: 0.102222, loss_s1: 0.071605, loss_fp: 0.001784, loss_freq: 0.052654
[03:55:25.792] iteration 8277: loss: 0.096380, loss_s1: 0.087026, loss_fp: 0.001215, loss_freq: 0.034130
[03:55:26.387] iteration 8278: loss: 0.087172, loss_s1: 0.080812, loss_fp: 0.000704, loss_freq: 0.028706
[03:55:26.979] iteration 8279: loss: 0.130255, loss_s1: 0.074106, loss_fp: 0.001897, loss_freq: 0.102235
[03:55:27.594] iteration 8280: loss: 0.060824, loss_s1: 0.026604, loss_fp: 0.000490, loss_freq: 0.014243
[03:55:28.187] iteration 8281: loss: 0.090049, loss_s1: 0.112860, loss_fp: 0.002286, loss_freq: 0.011619
[03:55:28.773] iteration 8282: loss: 0.082365, loss_s1: 0.064762, loss_fp: 0.001324, loss_freq: 0.049942
[03:55:29.367] iteration 8283: loss: 0.174698, loss_s1: 0.153011, loss_fp: 0.043683, loss_freq: 0.089583
[03:55:29.961] iteration 8284: loss: 0.074895, loss_s1: 0.090604, loss_fp: 0.002434, loss_freq: 0.017339
[03:55:30.550] iteration 8285: loss: 0.100810, loss_s1: 0.067049, loss_fp: 0.004463, loss_freq: 0.028897
[03:55:31.136] iteration 8286: loss: 0.092136, loss_s1: 0.062729, loss_fp: 0.006136, loss_freq: 0.044882
[03:55:31.777] iteration 8287: loss: 0.123081, loss_s1: 0.079661, loss_fp: 0.009518, loss_freq: 0.095182
[03:55:32.419] iteration 8288: loss: 0.071693, loss_s1: 0.034314, loss_fp: 0.003104, loss_freq: 0.023016
[03:55:33.052] iteration 8289: loss: 0.069401, loss_s1: 0.039969, loss_fp: 0.000922, loss_freq: 0.048245
[03:55:33.684] iteration 8290: loss: 0.091277, loss_s1: 0.065662, loss_fp: 0.007611, loss_freq: 0.035875
[03:55:34.312] iteration 8291: loss: 0.114118, loss_s1: 0.127575, loss_fp: 0.001244, loss_freq: 0.022285
[03:55:34.901] iteration 8292: loss: 0.050643, loss_s1: 0.017238, loss_fp: 0.000688, loss_freq: 0.012980
[03:55:35.496] iteration 8293: loss: 0.125034, loss_s1: 0.125110, loss_fp: 0.001395, loss_freq: 0.032674
[03:55:36.084] iteration 8294: loss: 0.057231, loss_s1: 0.041308, loss_fp: 0.001569, loss_freq: 0.024751
[03:55:36.682] iteration 8295: loss: 0.134823, loss_s1: 0.111307, loss_fp: 0.001086, loss_freq: 0.072423
[03:55:37.270] iteration 8296: loss: 0.075487, loss_s1: 0.048901, loss_fp: 0.009761, loss_freq: 0.042527
[03:55:37.855] iteration 8297: loss: 0.137473, loss_s1: 0.066044, loss_fp: 0.008018, loss_freq: 0.025908
[03:55:38.471] iteration 8298: loss: 0.079261, loss_s1: 0.064564, loss_fp: 0.000854, loss_freq: 0.035887
[03:55:39.073] iteration 8299: loss: 0.095565, loss_s1: 0.088412, loss_fp: 0.002724, loss_freq: 0.059704
[03:55:39.670] iteration 8300: loss: 0.107130, loss_s1: 0.144047, loss_fp: 0.000711, loss_freq: 0.021736
[03:55:40.266] iteration 8301: loss: 0.072612, loss_s1: 0.050609, loss_fp: 0.003170, loss_freq: 0.019911
[03:55:40.868] iteration 8302: loss: 0.092271, loss_s1: 0.072119, loss_fp: 0.002008, loss_freq: 0.053374
[03:55:41.462] iteration 8303: loss: 0.064238, loss_s1: 0.029663, loss_fp: 0.001865, loss_freq: 0.029847
[03:55:42.055] iteration 8304: loss: 0.084875, loss_s1: 0.040911, loss_fp: 0.001424, loss_freq: 0.019448
[03:55:42.652] iteration 8305: loss: 0.047332, loss_s1: 0.024359, loss_fp: 0.002413, loss_freq: 0.012110
[03:55:43.250] iteration 8306: loss: 0.110655, loss_s1: 0.126388, loss_fp: 0.005197, loss_freq: 0.038014
[03:55:43.844] iteration 8307: loss: 0.071180, loss_s1: 0.025482, loss_fp: 0.003717, loss_freq: 0.024400
[03:55:44.437] iteration 8308: loss: 0.134469, loss_s1: 0.140283, loss_fp: 0.004441, loss_freq: 0.041207
[03:55:45.032] iteration 8309: loss: 0.104994, loss_s1: 0.097229, loss_fp: 0.002691, loss_freq: 0.063722
[03:55:45.624] iteration 8310: loss: 0.087751, loss_s1: 0.049050, loss_fp: 0.009074, loss_freq: 0.027657
[03:55:46.219] iteration 8311: loss: 0.093325, loss_s1: 0.073490, loss_fp: 0.001734, loss_freq: 0.045407
[03:55:46.809] iteration 8312: loss: 0.106437, loss_s1: 0.085270, loss_fp: 0.001971, loss_freq: 0.070964
[03:55:47.408] iteration 8313: loss: 0.145932, loss_s1: 0.114588, loss_fp: 0.007459, loss_freq: 0.065267
[03:55:47.998] iteration 8314: loss: 0.080500, loss_s1: 0.073145, loss_fp: 0.000594, loss_freq: 0.018205
[03:55:48.590] iteration 8315: loss: 0.113223, loss_s1: 0.086288, loss_fp: 0.005492, loss_freq: 0.021513
[03:55:49.187] iteration 8316: loss: 0.104625, loss_s1: 0.090341, loss_fp: 0.001740, loss_freq: 0.019667
[03:55:49.778] iteration 8317: loss: 0.083312, loss_s1: 0.048842, loss_fp: 0.000978, loss_freq: 0.029096
[03:55:50.377] iteration 8318: loss: 0.102453, loss_s1: 0.082193, loss_fp: 0.007857, loss_freq: 0.037794
[03:55:50.974] iteration 8319: loss: 0.091262, loss_s1: 0.085928, loss_fp: 0.008037, loss_freq: 0.043597
[03:55:51.573] iteration 8320: loss: 0.092339, loss_s1: 0.057894, loss_fp: 0.002108, loss_freq: 0.036631
[03:55:52.164] iteration 8321: loss: 0.076893, loss_s1: 0.072705, loss_fp: 0.001113, loss_freq: 0.030252
[03:55:52.765] iteration 8322: loss: 0.084346, loss_s1: 0.089093, loss_fp: 0.002451, loss_freq: 0.022381
[03:55:53.399] iteration 8323: loss: 0.088059, loss_s1: 0.064106, loss_fp: 0.001510, loss_freq: 0.016991
[03:55:53.997] iteration 8324: loss: 0.060435, loss_s1: 0.058758, loss_fp: 0.001104, loss_freq: 0.016717
[03:55:54.587] iteration 8325: loss: 0.092480, loss_s1: 0.094431, loss_fp: 0.000981, loss_freq: 0.011382
[03:55:55.176] iteration 8326: loss: 0.134667, loss_s1: 0.151467, loss_fp: 0.003325, loss_freq: 0.051656
[03:55:55.793] iteration 8327: loss: 0.090499, loss_s1: 0.020667, loss_fp: 0.001430, loss_freq: 0.046471
[03:55:56.384] iteration 8328: loss: 0.075089, loss_s1: 0.047068, loss_fp: 0.012023, loss_freq: 0.024824
[03:55:56.968] iteration 8329: loss: 0.142276, loss_s1: 0.143994, loss_fp: 0.006463, loss_freq: 0.092458
[03:55:57.556] iteration 8330: loss: 0.125533, loss_s1: 0.074975, loss_fp: 0.008116, loss_freq: 0.097782
[03:55:58.492] iteration 8331: loss: 0.082315, loss_s1: 0.067369, loss_fp: 0.006145, loss_freq: 0.025744
[03:55:59.101] iteration 8332: loss: 0.072329, loss_s1: 0.030260, loss_fp: 0.001890, loss_freq: 0.046470
[03:55:59.708] iteration 8333: loss: 0.111676, loss_s1: 0.088736, loss_fp: 0.005732, loss_freq: 0.062132
[03:56:00.321] iteration 8334: loss: 0.060639, loss_s1: 0.039894, loss_fp: 0.003643, loss_freq: 0.019683
[03:56:00.929] iteration 8335: loss: 0.085017, loss_s1: 0.093060, loss_fp: 0.008273, loss_freq: 0.018059
[03:56:01.544] iteration 8336: loss: 0.101884, loss_s1: 0.090201, loss_fp: 0.002705, loss_freq: 0.022443
[03:56:02.141] iteration 8337: loss: 0.080565, loss_s1: 0.056579, loss_fp: 0.001948, loss_freq: 0.043959
[03:56:02.728] iteration 8338: loss: 0.060831, loss_s1: 0.038981, loss_fp: 0.002109, loss_freq: 0.022380
[03:56:03.319] iteration 8339: loss: 0.046743, loss_s1: 0.019946, loss_fp: 0.004790, loss_freq: 0.020532
[03:56:03.908] iteration 8340: loss: 0.094695, loss_s1: 0.051552, loss_fp: 0.002891, loss_freq: 0.041296
[03:56:04.494] iteration 8341: loss: 0.065051, loss_s1: 0.022207, loss_fp: 0.000538, loss_freq: 0.037258
[03:56:05.082] iteration 8342: loss: 0.092033, loss_s1: 0.041351, loss_fp: 0.006830, loss_freq: 0.080601
[03:56:05.673] iteration 8343: loss: 0.079451, loss_s1: 0.040495, loss_fp: 0.001912, loss_freq: 0.050618
[03:56:06.262] iteration 8344: loss: 0.081034, loss_s1: 0.069460, loss_fp: 0.003967, loss_freq: 0.022899
[03:56:06.858] iteration 8345: loss: 0.072382, loss_s1: 0.057724, loss_fp: 0.001225, loss_freq: 0.035009
[03:56:07.455] iteration 8346: loss: 0.074184, loss_s1: 0.030410, loss_fp: 0.002601, loss_freq: 0.044800
[03:56:08.051] iteration 8347: loss: 0.116466, loss_s1: 0.091492, loss_fp: 0.003304, loss_freq: 0.074922
[03:56:08.646] iteration 8348: loss: 0.065139, loss_s1: 0.052478, loss_fp: 0.003156, loss_freq: 0.012955
[03:56:09.238] iteration 8349: loss: 0.062842, loss_s1: 0.057995, loss_fp: 0.002809, loss_freq: 0.020334
[03:56:09.833] iteration 8350: loss: 0.126513, loss_s1: 0.121379, loss_fp: 0.002154, loss_freq: 0.033181
[03:56:10.420] iteration 8351: loss: 0.084112, loss_s1: 0.050850, loss_fp: 0.001957, loss_freq: 0.049704
[03:56:11.012] iteration 8352: loss: 0.121018, loss_s1: 0.037364, loss_fp: 0.000521, loss_freq: 0.023311
[03:56:11.595] iteration 8353: loss: 0.113856, loss_s1: 0.065068, loss_fp: 0.002371, loss_freq: 0.045619
[03:56:12.189] iteration 8354: loss: 0.071071, loss_s1: 0.020506, loss_fp: 0.007693, loss_freq: 0.025502
[03:56:12.782] iteration 8355: loss: 0.062254, loss_s1: 0.013691, loss_fp: 0.003865, loss_freq: 0.027565
[03:56:13.367] iteration 8356: loss: 0.099949, loss_s1: 0.105489, loss_fp: 0.003294, loss_freq: 0.054962
[03:56:13.960] iteration 8357: loss: 0.087325, loss_s1: 0.040053, loss_fp: 0.002352, loss_freq: 0.036933
[03:56:14.546] iteration 8358: loss: 0.099346, loss_s1: 0.064590, loss_fp: 0.006414, loss_freq: 0.031077
[03:56:15.144] iteration 8359: loss: 0.148023, loss_s1: 0.066698, loss_fp: 0.008581, loss_freq: 0.055021
[03:56:15.737] iteration 8360: loss: 0.134053, loss_s1: 0.174095, loss_fp: 0.004892, loss_freq: 0.040721
[03:56:16.322] iteration 8361: loss: 0.083619, loss_s1: 0.081456, loss_fp: 0.001284, loss_freq: 0.029221
[03:56:16.916] iteration 8362: loss: 0.091173, loss_s1: 0.033595, loss_fp: 0.003895, loss_freq: 0.030220
[03:56:17.507] iteration 8363: loss: 0.116912, loss_s1: 0.109173, loss_fp: 0.003015, loss_freq: 0.043103
[03:56:18.104] iteration 8364: loss: 0.058960, loss_s1: 0.027780, loss_fp: 0.005611, loss_freq: 0.013140
[03:56:18.702] iteration 8365: loss: 0.063872, loss_s1: 0.031358, loss_fp: 0.001889, loss_freq: 0.041424
[03:56:19.332] iteration 8366: loss: 0.068139, loss_s1: 0.046768, loss_fp: 0.003878, loss_freq: 0.023545
[03:56:19.926] iteration 8367: loss: 0.076538, loss_s1: 0.034057, loss_fp: 0.001703, loss_freq: 0.023698
[03:56:20.531] iteration 8368: loss: 0.086546, loss_s1: 0.084155, loss_fp: 0.005025, loss_freq: 0.036853
[03:56:21.136] iteration 8369: loss: 0.129386, loss_s1: 0.115744, loss_fp: 0.003531, loss_freq: 0.064352
[03:56:21.732] iteration 8370: loss: 0.107559, loss_s1: 0.088225, loss_fp: 0.003859, loss_freq: 0.048207
[03:56:22.335] iteration 8371: loss: 0.132235, loss_s1: 0.113352, loss_fp: 0.005657, loss_freq: 0.074375
[03:56:22.946] iteration 8372: loss: 0.096587, loss_s1: 0.114469, loss_fp: 0.001200, loss_freq: 0.019683
[03:56:23.537] iteration 8373: loss: 0.089531, loss_s1: 0.040115, loss_fp: 0.001709, loss_freq: 0.072051
[03:56:24.173] iteration 8374: loss: 0.107790, loss_s1: 0.096958, loss_fp: 0.005153, loss_freq: 0.052337
[03:56:24.777] iteration 8375: loss: 0.107754, loss_s1: 0.073711, loss_fp: 0.002890, loss_freq: 0.048714
[03:56:25.373] iteration 8376: loss: 0.086837, loss_s1: 0.065579, loss_fp: 0.002977, loss_freq: 0.037943
[03:56:25.962] iteration 8377: loss: 0.090474, loss_s1: 0.036651, loss_fp: 0.007908, loss_freq: 0.049541
[03:56:26.560] iteration 8378: loss: 0.095064, loss_s1: 0.091971, loss_fp: 0.004548, loss_freq: 0.028828
[03:56:27.155] iteration 8379: loss: 0.068691, loss_s1: 0.038682, loss_fp: 0.001391, loss_freq: 0.011817
[03:56:27.753] iteration 8380: loss: 0.069543, loss_s1: 0.044475, loss_fp: 0.000773, loss_freq: 0.026320
[03:56:28.353] iteration 8381: loss: 0.074698, loss_s1: 0.055054, loss_fp: 0.004793, loss_freq: 0.027532
[03:56:28.952] iteration 8382: loss: 0.118936, loss_s1: 0.137156, loss_fp: 0.002470, loss_freq: 0.054180
[03:56:29.546] iteration 8383: loss: 0.118615, loss_s1: 0.035733, loss_fp: 0.001804, loss_freq: 0.084012
[03:56:30.136] iteration 8384: loss: 0.183993, loss_s1: 0.160456, loss_fp: 0.003860, loss_freq: 0.119554
[03:56:30.727] iteration 8385: loss: 0.140764, loss_s1: 0.056624, loss_fp: 0.002764, loss_freq: 0.120937
[03:56:31.316] iteration 8386: loss: 0.061200, loss_s1: 0.053093, loss_fp: 0.003620, loss_freq: 0.019658
[03:56:31.911] iteration 8387: loss: 0.079080, loss_s1: 0.040266, loss_fp: 0.001118, loss_freq: 0.040571
[03:56:32.501] iteration 8388: loss: 0.081345, loss_s1: 0.038763, loss_fp: 0.008546, loss_freq: 0.037278
[03:56:33.095] iteration 8389: loss: 0.074637, loss_s1: 0.030285, loss_fp: 0.002288, loss_freq: 0.051845
[03:56:33.686] iteration 8390: loss: 0.073401, loss_s1: 0.049589, loss_fp: 0.001900, loss_freq: 0.034452
[03:56:34.284] iteration 8391: loss: 0.049857, loss_s1: 0.041101, loss_fp: 0.000840, loss_freq: 0.017564
[03:56:34.871] iteration 8392: loss: 0.079844, loss_s1: 0.035702, loss_fp: 0.001988, loss_freq: 0.031736
[03:56:35.462] iteration 8393: loss: 0.058831, loss_s1: 0.031193, loss_fp: 0.000772, loss_freq: 0.021135
[03:56:36.047] iteration 8394: loss: 0.136730, loss_s1: 0.081036, loss_fp: 0.002434, loss_freq: 0.021913
[03:56:36.640] iteration 8395: loss: 0.083655, loss_s1: 0.095590, loss_fp: 0.001468, loss_freq: 0.020866
[03:56:37.239] iteration 8396: loss: 0.087984, loss_s1: 0.063160, loss_fp: 0.002068, loss_freq: 0.052772
[03:56:37.832] iteration 8397: loss: 0.082174, loss_s1: 0.059239, loss_fp: 0.001505, loss_freq: 0.008086
[03:56:38.423] iteration 8398: loss: 0.122446, loss_s1: 0.129957, loss_fp: 0.001375, loss_freq: 0.040665
[03:56:39.019] iteration 8399: loss: 0.060308, loss_s1: 0.027321, loss_fp: 0.002572, loss_freq: 0.035535
[03:56:39.615] iteration 8400: loss: 0.075256, loss_s1: 0.064513, loss_fp: 0.001658, loss_freq: 0.032251
[03:56:42.910] iteration 8400 : mean_dice : 0.680211
[03:56:43.575] iteration 8401: loss: 0.108964, loss_s1: 0.093852, loss_fp: 0.002202, loss_freq: 0.040370
[03:56:44.213] iteration 8402: loss: 0.074684, loss_s1: 0.046066, loss_fp: 0.005814, loss_freq: 0.036972
[03:56:44.886] iteration 8403: loss: 0.086276, loss_s1: 0.051880, loss_fp: 0.003473, loss_freq: 0.051082
[03:56:45.510] iteration 8404: loss: 0.110278, loss_s1: 0.098970, loss_fp: 0.002921, loss_freq: 0.055231
[03:56:46.146] iteration 8405: loss: 0.108741, loss_s1: 0.050397, loss_fp: 0.004987, loss_freq: 0.070997
[03:56:46.774] iteration 8406: loss: 0.068453, loss_s1: 0.056779, loss_fp: 0.003558, loss_freq: 0.022530
[03:56:47.415] iteration 8407: loss: 0.056106, loss_s1: 0.038687, loss_fp: 0.001599, loss_freq: 0.018334
[03:56:48.059] iteration 8408: loss: 0.105560, loss_s1: 0.076262, loss_fp: 0.002171, loss_freq: 0.045022
[03:56:48.689] iteration 8409: loss: 0.082378, loss_s1: 0.052296, loss_fp: 0.003282, loss_freq: 0.064572
[03:56:49.319] iteration 8410: loss: 0.087518, loss_s1: 0.039972, loss_fp: 0.003399, loss_freq: 0.040209
[03:56:49.950] iteration 8411: loss: 0.105329, loss_s1: 0.073704, loss_fp: 0.006858, loss_freq: 0.049483
[03:56:50.584] iteration 8412: loss: 0.075324, loss_s1: 0.043528, loss_fp: 0.005259, loss_freq: 0.044114
[03:56:51.217] iteration 8413: loss: 0.084833, loss_s1: 0.080526, loss_fp: 0.006594, loss_freq: 0.022626
[03:56:51.821] iteration 8414: loss: 0.061392, loss_s1: 0.035932, loss_fp: 0.001689, loss_freq: 0.012898
[03:56:52.431] iteration 8415: loss: 0.074204, loss_s1: 0.052375, loss_fp: 0.000940, loss_freq: 0.024274
[03:56:53.025] iteration 8416: loss: 0.045422, loss_s1: 0.022401, loss_fp: 0.002749, loss_freq: 0.010093
[03:56:53.615] iteration 8417: loss: 0.106480, loss_s1: 0.120773, loss_fp: 0.004167, loss_freq: 0.050550
[03:56:54.209] iteration 8418: loss: 0.091282, loss_s1: 0.080391, loss_fp: 0.015266, loss_freq: 0.027009
[03:56:54.836] iteration 8419: loss: 0.079874, loss_s1: 0.034798, loss_fp: 0.005478, loss_freq: 0.069097
[03:56:55.465] iteration 8420: loss: 0.072620, loss_s1: 0.056776, loss_fp: 0.001979, loss_freq: 0.012279
[03:56:56.098] iteration 8421: loss: 0.087649, loss_s1: 0.082206, loss_fp: 0.001712, loss_freq: 0.035929
[03:56:56.729] iteration 8422: loss: 0.104810, loss_s1: 0.119746, loss_fp: 0.002943, loss_freq: 0.032347
[03:56:57.341] iteration 8423: loss: 0.096292, loss_s1: 0.068233, loss_fp: 0.004117, loss_freq: 0.037996
[03:56:57.929] iteration 8424: loss: 0.058121, loss_s1: 0.054782, loss_fp: 0.001387, loss_freq: 0.012482
[03:56:58.530] iteration 8425: loss: 0.057697, loss_s1: 0.037236, loss_fp: 0.005060, loss_freq: 0.031212
[03:56:59.135] iteration 8426: loss: 0.079738, loss_s1: 0.052276, loss_fp: 0.000973, loss_freq: 0.052229
[03:56:59.734] iteration 8427: loss: 0.169191, loss_s1: 0.120003, loss_fp: 0.000538, loss_freq: 0.122236
[03:57:00.327] iteration 8428: loss: 0.083290, loss_s1: 0.056453, loss_fp: 0.005528, loss_freq: 0.034300
[03:57:00.927] iteration 8429: loss: 0.106872, loss_s1: 0.096617, loss_fp: 0.002839, loss_freq: 0.067492
[03:57:01.525] iteration 8430: loss: 0.060201, loss_s1: 0.033535, loss_fp: 0.003871, loss_freq: 0.021464
[03:57:02.121] iteration 8431: loss: 0.080015, loss_s1: 0.061087, loss_fp: 0.003409, loss_freq: 0.031161
[03:57:02.716] iteration 8432: loss: 0.060622, loss_s1: 0.030381, loss_fp: 0.002185, loss_freq: 0.027837
[03:57:03.319] iteration 8433: loss: 0.049149, loss_s1: 0.028424, loss_fp: 0.002040, loss_freq: 0.018568
[03:57:03.917] iteration 8434: loss: 0.065264, loss_s1: 0.035136, loss_fp: 0.000641, loss_freq: 0.030182
[03:57:04.515] iteration 8435: loss: 0.069539, loss_s1: 0.019049, loss_fp: 0.006127, loss_freq: 0.064543
[03:57:05.111] iteration 8436: loss: 0.094153, loss_s1: 0.087990, loss_fp: 0.011670, loss_freq: 0.022120
[03:57:05.714] iteration 8437: loss: 0.060562, loss_s1: 0.029535, loss_fp: 0.005118, loss_freq: 0.028234
[03:57:06.324] iteration 8438: loss: 0.077358, loss_s1: 0.041032, loss_fp: 0.003021, loss_freq: 0.044172
[03:57:06.916] iteration 8439: loss: 0.127448, loss_s1: 0.104802, loss_fp: 0.002129, loss_freq: 0.090730
[03:57:07.509] iteration 8440: loss: 0.058000, loss_s1: 0.023734, loss_fp: 0.004624, loss_freq: 0.029099
[03:57:08.103] iteration 8441: loss: 0.087725, loss_s1: 0.079406, loss_fp: 0.003538, loss_freq: 0.037282
[03:57:08.698] iteration 8442: loss: 0.092570, loss_s1: 0.081019, loss_fp: 0.013584, loss_freq: 0.037448
[03:57:09.448] iteration 8443: loss: 0.069740, loss_s1: 0.059573, loss_fp: 0.001475, loss_freq: 0.010322
[03:57:10.212] iteration 8444: loss: 0.078627, loss_s1: 0.039279, loss_fp: 0.005661, loss_freq: 0.025439
[03:57:10.811] iteration 8445: loss: 0.099802, loss_s1: 0.053837, loss_fp: 0.000719, loss_freq: 0.073539
[03:57:11.476] iteration 8446: loss: 0.106112, loss_s1: 0.083325, loss_fp: 0.005503, loss_freq: 0.034214
[03:57:12.060] iteration 8447: loss: 0.085375, loss_s1: 0.079036, loss_fp: 0.001570, loss_freq: 0.033337
[03:57:12.654] iteration 8448: loss: 0.076519, loss_s1: 0.067777, loss_fp: 0.006095, loss_freq: 0.022578
[03:57:13.305] iteration 8449: loss: 0.095641, loss_s1: 0.079042, loss_fp: 0.003597, loss_freq: 0.055935
[03:57:13.931] iteration 8450: loss: 0.085435, loss_s1: 0.057319, loss_fp: 0.001857, loss_freq: 0.023893
[03:57:14.536] iteration 8451: loss: 0.076772, loss_s1: 0.064998, loss_fp: 0.000410, loss_freq: 0.022037
[03:57:15.129] iteration 8452: loss: 0.081927, loss_s1: 0.081095, loss_fp: 0.001537, loss_freq: 0.044236
[03:57:15.717] iteration 8453: loss: 0.099639, loss_s1: 0.073478, loss_fp: 0.002448, loss_freq: 0.080090
[03:57:16.308] iteration 8454: loss: 0.066022, loss_s1: 0.034219, loss_fp: 0.001323, loss_freq: 0.026622
[03:57:16.908] iteration 8455: loss: 0.093231, loss_s1: 0.049474, loss_fp: 0.010252, loss_freq: 0.053869
[03:57:17.507] iteration 8456: loss: 0.065031, loss_s1: 0.034893, loss_fp: 0.001557, loss_freq: 0.043375
[03:57:18.100] iteration 8457: loss: 0.105782, loss_s1: 0.091344, loss_fp: 0.014183, loss_freq: 0.062694
[03:57:18.694] iteration 8458: loss: 0.098584, loss_s1: 0.083923, loss_fp: 0.001495, loss_freq: 0.025152
[03:57:19.290] iteration 8459: loss: 0.071955, loss_s1: 0.064738, loss_fp: 0.002399, loss_freq: 0.033290
[03:57:19.882] iteration 8460: loss: 0.060112, loss_s1: 0.045418, loss_fp: 0.001743, loss_freq: 0.015788
[03:57:20.469] iteration 8461: loss: 0.067616, loss_s1: 0.049437, loss_fp: 0.004115, loss_freq: 0.027782
[03:57:21.058] iteration 8462: loss: 0.080540, loss_s1: 0.044509, loss_fp: 0.002800, loss_freq: 0.008444
[03:57:21.651] iteration 8463: loss: 0.116875, loss_s1: 0.100200, loss_fp: 0.004047, loss_freq: 0.049667
[03:57:22.240] iteration 8464: loss: 0.087746, loss_s1: 0.059878, loss_fp: 0.001161, loss_freq: 0.050005
[03:57:22.832] iteration 8465: loss: 0.144031, loss_s1: 0.095127, loss_fp: 0.002155, loss_freq: 0.134466
[03:57:23.424] iteration 8466: loss: 0.068122, loss_s1: 0.051690, loss_fp: 0.005846, loss_freq: 0.014871
[03:57:24.012] iteration 8467: loss: 0.099203, loss_s1: 0.041255, loss_fp: 0.000751, loss_freq: 0.016930
[03:57:24.604] iteration 8468: loss: 0.087563, loss_s1: 0.077943, loss_fp: 0.005180, loss_freq: 0.038583
[03:57:25.198] iteration 8469: loss: 0.078628, loss_s1: 0.074438, loss_fp: 0.002312, loss_freq: 0.038018
[03:57:25.799] iteration 8470: loss: 0.088584, loss_s1: 0.053101, loss_fp: 0.001148, loss_freq: 0.055663
[03:57:26.390] iteration 8471: loss: 0.133148, loss_s1: 0.129920, loss_fp: 0.004739, loss_freq: 0.053356
[03:57:26.981] iteration 8472: loss: 0.071218, loss_s1: 0.028271, loss_fp: 0.003454, loss_freq: 0.048358
[03:57:27.576] iteration 8473: loss: 0.086322, loss_s1: 0.063123, loss_fp: 0.005289, loss_freq: 0.041011
[03:57:28.169] iteration 8474: loss: 0.104046, loss_s1: 0.092977, loss_fp: 0.009055, loss_freq: 0.023548
[03:57:28.755] iteration 8475: loss: 0.081639, loss_s1: 0.055682, loss_fp: 0.003591, loss_freq: 0.035924
[03:57:29.346] iteration 8476: loss: 0.082025, loss_s1: 0.038231, loss_fp: 0.003665, loss_freq: 0.054097
[03:57:29.937] iteration 8477: loss: 0.075718, loss_s1: 0.057751, loss_fp: 0.007186, loss_freq: 0.035122
[03:57:30.527] iteration 8478: loss: 0.125914, loss_s1: 0.126985, loss_fp: 0.004208, loss_freq: 0.078625
[03:57:31.119] iteration 8479: loss: 0.087303, loss_s1: 0.071050, loss_fp: 0.004642, loss_freq: 0.049889
[03:57:31.712] iteration 8480: loss: 0.102985, loss_s1: 0.080820, loss_fp: 0.009071, loss_freq: 0.047336
[03:57:32.302] iteration 8481: loss: 0.107129, loss_s1: 0.081653, loss_fp: 0.004304, loss_freq: 0.036533
[03:57:32.889] iteration 8482: loss: 0.126264, loss_s1: 0.114450, loss_fp: 0.025077, loss_freq: 0.059730
[03:57:33.477] iteration 8483: loss: 0.141293, loss_s1: 0.131636, loss_fp: 0.012514, loss_freq: 0.049546
[03:57:34.074] iteration 8484: loss: 0.110270, loss_s1: 0.062880, loss_fp: 0.003212, loss_freq: 0.057288
[03:57:34.661] iteration 8485: loss: 0.145338, loss_s1: 0.119597, loss_fp: 0.010733, loss_freq: 0.062346
[03:57:35.251] iteration 8486: loss: 0.144631, loss_s1: 0.109120, loss_fp: 0.001569, loss_freq: 0.058850
[03:57:35.845] iteration 8487: loss: 0.115783, loss_s1: 0.049042, loss_fp: 0.001847, loss_freq: 0.077533
[03:57:36.479] iteration 8488: loss: 0.155900, loss_s1: 0.138250, loss_fp: 0.008158, loss_freq: 0.074656
[03:57:37.106] iteration 8489: loss: 0.092165, loss_s1: 0.104036, loss_fp: 0.002978, loss_freq: 0.035103
[03:57:37.738] iteration 8490: loss: 0.086429, loss_s1: 0.084402, loss_fp: 0.003003, loss_freq: 0.025699
[03:57:38.345] iteration 8491: loss: 0.083099, loss_s1: 0.054950, loss_fp: 0.001267, loss_freq: 0.005818
[03:57:38.936] iteration 8492: loss: 0.054531, loss_s1: 0.037487, loss_fp: 0.006036, loss_freq: 0.030860
[03:57:39.529] iteration 8493: loss: 0.091440, loss_s1: 0.079752, loss_fp: 0.001230, loss_freq: 0.022012
[03:57:40.127] iteration 8494: loss: 0.107836, loss_s1: 0.136187, loss_fp: 0.001807, loss_freq: 0.021275
[03:57:40.720] iteration 8495: loss: 0.050151, loss_s1: 0.032190, loss_fp: 0.000764, loss_freq: 0.011228
[03:57:41.314] iteration 8496: loss: 0.112675, loss_s1: 0.132915, loss_fp: 0.002868, loss_freq: 0.038110
[03:57:41.913] iteration 8497: loss: 0.069731, loss_s1: 0.047380, loss_fp: 0.007850, loss_freq: 0.021185
[03:57:42.504] iteration 8498: loss: 0.090853, loss_s1: 0.079529, loss_fp: 0.003258, loss_freq: 0.027117
[03:57:43.092] iteration 8499: loss: 0.061091, loss_s1: 0.028658, loss_fp: 0.003479, loss_freq: 0.047666
[03:57:43.679] iteration 8500: loss: 0.108221, loss_s1: 0.066641, loss_fp: 0.003897, loss_freq: 0.073702
[03:57:44.679] iteration 8501: loss: 0.115284, loss_s1: 0.073439, loss_fp: 0.001021, loss_freq: 0.028939
[03:57:45.273] iteration 8502: loss: 0.072800, loss_s1: 0.043998, loss_fp: 0.000525, loss_freq: 0.028065
[03:57:45.864] iteration 8503: loss: 0.087818, loss_s1: 0.080142, loss_fp: 0.004233, loss_freq: 0.040141
[03:57:46.456] iteration 8504: loss: 0.079268, loss_s1: 0.055008, loss_fp: 0.000745, loss_freq: 0.024252
[03:57:47.057] iteration 8505: loss: 0.078321, loss_s1: 0.049581, loss_fp: 0.005954, loss_freq: 0.019588
[03:57:47.648] iteration 8506: loss: 0.131835, loss_s1: 0.119040, loss_fp: 0.003070, loss_freq: 0.035884
[03:57:48.239] iteration 8507: loss: 0.094661, loss_s1: 0.072482, loss_fp: 0.015393, loss_freq: 0.056509
[03:57:48.848] iteration 8508: loss: 0.061776, loss_s1: 0.035272, loss_fp: 0.000953, loss_freq: 0.012229
[03:57:49.437] iteration 8509: loss: 0.088529, loss_s1: 0.086794, loss_fp: 0.003154, loss_freq: 0.026043
[03:57:50.029] iteration 8510: loss: 0.103066, loss_s1: 0.068040, loss_fp: 0.001219, loss_freq: 0.041748
[03:57:50.625] iteration 8511: loss: 0.072942, loss_s1: 0.036013, loss_fp: 0.002282, loss_freq: 0.034622
[03:57:51.215] iteration 8512: loss: 0.092371, loss_s1: 0.066683, loss_fp: 0.000957, loss_freq: 0.066182
[03:57:51.807] iteration 8513: loss: 0.108711, loss_s1: 0.079113, loss_fp: 0.021531, loss_freq: 0.044358
[03:57:52.400] iteration 8514: loss: 0.075095, loss_s1: 0.048974, loss_fp: 0.006265, loss_freq: 0.047297
[03:57:52.988] iteration 8515: loss: 0.059696, loss_s1: 0.029888, loss_fp: 0.001076, loss_freq: 0.022102
[03:57:53.575] iteration 8516: loss: 0.055635, loss_s1: 0.045569, loss_fp: 0.001307, loss_freq: 0.013430
[03:57:54.164] iteration 8517: loss: 0.168347, loss_s1: 0.149753, loss_fp: 0.006525, loss_freq: 0.107305
[03:57:54.754] iteration 8518: loss: 0.079269, loss_s1: 0.061265, loss_fp: 0.002422, loss_freq: 0.022085
[03:57:55.340] iteration 8519: loss: 0.106547, loss_s1: 0.105684, loss_fp: 0.006244, loss_freq: 0.051681
[03:57:55.927] iteration 8520: loss: 0.108331, loss_s1: 0.090521, loss_fp: 0.001145, loss_freq: 0.029119
[03:57:56.520] iteration 8521: loss: 0.082666, loss_s1: 0.058731, loss_fp: 0.005549, loss_freq: 0.030155
[03:57:57.116] iteration 8522: loss: 0.068393, loss_s1: 0.062023, loss_fp: 0.004654, loss_freq: 0.021483
[03:57:57.710] iteration 8523: loss: 0.098193, loss_s1: 0.035832, loss_fp: 0.005148, loss_freq: 0.055884
[03:57:58.299] iteration 8524: loss: 0.069235, loss_s1: 0.040033, loss_fp: 0.004196, loss_freq: 0.022990
[03:57:58.922] iteration 8525: loss: 0.106859, loss_s1: 0.052523, loss_fp: 0.000800, loss_freq: 0.076959
[03:57:59.513] iteration 8526: loss: 0.078634, loss_s1: 0.060835, loss_fp: 0.010592, loss_freq: 0.028614
[03:58:00.106] iteration 8527: loss: 0.077536, loss_s1: 0.044917, loss_fp: 0.003348, loss_freq: 0.017152
[03:58:00.699] iteration 8528: loss: 0.119854, loss_s1: 0.063136, loss_fp: 0.002339, loss_freq: 0.055124
[03:58:01.287] iteration 8529: loss: 0.060852, loss_s1: 0.031530, loss_fp: 0.010292, loss_freq: 0.023450
[03:58:01.872] iteration 8530: loss: 0.102136, loss_s1: 0.089422, loss_fp: 0.008840, loss_freq: 0.054687
[03:58:02.461] iteration 8531: loss: 0.094061, loss_s1: 0.062789, loss_fp: 0.003734, loss_freq: 0.046096
[03:58:03.053] iteration 8532: loss: 0.116918, loss_s1: 0.094227, loss_fp: 0.001772, loss_freq: 0.046727
[03:58:03.647] iteration 8533: loss: 0.079236, loss_s1: 0.033185, loss_fp: 0.001881, loss_freq: 0.041236
[03:58:04.240] iteration 8534: loss: 0.070846, loss_s1: 0.077290, loss_fp: 0.000640, loss_freq: 0.006541
[03:58:04.829] iteration 8535: loss: 0.074425, loss_s1: 0.058672, loss_fp: 0.000713, loss_freq: 0.032321
[03:58:05.418] iteration 8536: loss: 0.076621, loss_s1: 0.055333, loss_fp: 0.001505, loss_freq: 0.022483
[03:58:06.009] iteration 8537: loss: 0.097200, loss_s1: 0.062008, loss_fp: 0.001868, loss_freq: 0.052988
[03:58:06.599] iteration 8538: loss: 0.079254, loss_s1: 0.072380, loss_fp: 0.001049, loss_freq: 0.026364
[03:58:07.191] iteration 8539: loss: 0.098590, loss_s1: 0.077245, loss_fp: 0.005906, loss_freq: 0.058216
[03:58:07.785] iteration 8540: loss: 0.115735, loss_s1: 0.108168, loss_fp: 0.001781, loss_freq: 0.062637
[03:58:08.381] iteration 8541: loss: 0.141907, loss_s1: 0.170479, loss_fp: 0.008423, loss_freq: 0.049758
[03:58:08.970] iteration 8542: loss: 0.059045, loss_s1: 0.039307, loss_fp: 0.002517, loss_freq: 0.029914
[03:58:09.561] iteration 8543: loss: 0.100838, loss_s1: 0.114339, loss_fp: 0.001985, loss_freq: 0.048884
[03:58:10.154] iteration 8544: loss: 0.167232, loss_s1: 0.167245, loss_fp: 0.011015, loss_freq: 0.103808
[03:58:10.740] iteration 8545: loss: 0.088985, loss_s1: 0.060605, loss_fp: 0.001721, loss_freq: 0.026227
[03:58:11.334] iteration 8546: loss: 0.082090, loss_s1: 0.081836, loss_fp: 0.002108, loss_freq: 0.020115
[03:58:11.923] iteration 8547: loss: 0.077901, loss_s1: 0.064500, loss_fp: 0.003232, loss_freq: 0.027925
[03:58:12.521] iteration 8548: loss: 0.082581, loss_s1: 0.063472, loss_fp: 0.002483, loss_freq: 0.040968
[03:58:13.112] iteration 8549: loss: 0.057153, loss_s1: 0.037750, loss_fp: 0.003180, loss_freq: 0.008244
[03:58:13.701] iteration 8550: loss: 0.098576, loss_s1: 0.046777, loss_fp: 0.000746, loss_freq: 0.024140
[03:58:14.293] iteration 8551: loss: 0.093057, loss_s1: 0.075066, loss_fp: 0.009378, loss_freq: 0.031162
[03:58:14.880] iteration 8552: loss: 0.136226, loss_s1: 0.143624, loss_fp: 0.021891, loss_freq: 0.053248
[03:58:15.468] iteration 8553: loss: 0.077845, loss_s1: 0.032514, loss_fp: 0.000645, loss_freq: 0.046451
[03:58:16.066] iteration 8554: loss: 0.136949, loss_s1: 0.128001, loss_fp: 0.008119, loss_freq: 0.050593
[03:58:16.656] iteration 8555: loss: 0.100116, loss_s1: 0.040455, loss_fp: 0.005790, loss_freq: 0.057047
[03:58:17.248] iteration 8556: loss: 0.048537, loss_s1: 0.025486, loss_fp: 0.004435, loss_freq: 0.018533
[03:58:17.839] iteration 8557: loss: 0.066365, loss_s1: 0.027180, loss_fp: 0.006186, loss_freq: 0.016261
[03:58:18.434] iteration 8558: loss: 0.096101, loss_s1: 0.067331, loss_fp: 0.005544, loss_freq: 0.051619
[03:58:19.027] iteration 8559: loss: 0.063689, loss_s1: 0.042440, loss_fp: 0.002482, loss_freq: 0.022121
[03:58:19.621] iteration 8560: loss: 0.110199, loss_s1: 0.096174, loss_fp: 0.002086, loss_freq: 0.070229
[03:58:20.220] iteration 8561: loss: 0.069744, loss_s1: 0.069993, loss_fp: 0.001826, loss_freq: 0.016745
[03:58:20.817] iteration 8562: loss: 0.086448, loss_s1: 0.050959, loss_fp: 0.001384, loss_freq: 0.042133
[03:58:21.414] iteration 8563: loss: 0.087191, loss_s1: 0.045374, loss_fp: 0.002841, loss_freq: 0.046875
[03:58:22.008] iteration 8564: loss: 0.088945, loss_s1: 0.068557, loss_fp: 0.003029, loss_freq: 0.041609
[03:58:22.598] iteration 8565: loss: 0.083390, loss_s1: 0.048020, loss_fp: 0.006400, loss_freq: 0.037961
[03:58:23.191] iteration 8566: loss: 0.075183, loss_s1: 0.061573, loss_fp: 0.002635, loss_freq: 0.036165
[03:58:23.788] iteration 8567: loss: 0.100226, loss_s1: 0.068211, loss_fp: 0.002641, loss_freq: 0.010121
[03:58:24.378] iteration 8568: loss: 0.133151, loss_s1: 0.095440, loss_fp: 0.019545, loss_freq: 0.048538
[03:58:24.966] iteration 8569: loss: 0.044156, loss_s1: 0.021949, loss_fp: 0.001904, loss_freq: 0.008327
[03:58:25.559] iteration 8570: loss: 0.055044, loss_s1: 0.037182, loss_fp: 0.002980, loss_freq: 0.032187
[03:58:26.147] iteration 8571: loss: 0.100855, loss_s1: 0.075361, loss_fp: 0.005958, loss_freq: 0.038931
[03:58:26.739] iteration 8572: loss: 0.092481, loss_s1: 0.044245, loss_fp: 0.003201, loss_freq: 0.062575
[03:58:27.332] iteration 8573: loss: 0.102227, loss_s1: 0.070157, loss_fp: 0.017481, loss_freq: 0.051160
[03:58:27.924] iteration 8574: loss: 0.088027, loss_s1: 0.077488, loss_fp: 0.003270, loss_freq: 0.046893
[03:58:28.513] iteration 8575: loss: 0.078063, loss_s1: 0.041610, loss_fp: 0.001756, loss_freq: 0.039931
[03:58:29.103] iteration 8576: loss: 0.073701, loss_s1: 0.039283, loss_fp: 0.001119, loss_freq: 0.024047
[03:58:29.691] iteration 8577: loss: 0.079867, loss_s1: 0.054722, loss_fp: 0.001277, loss_freq: 0.031170
[03:58:30.285] iteration 8578: loss: 0.109405, loss_s1: 0.083572, loss_fp: 0.005544, loss_freq: 0.082879
[03:58:30.878] iteration 8579: loss: 0.083814, loss_s1: 0.070629, loss_fp: 0.004282, loss_freq: 0.049655
[03:58:31.469] iteration 8580: loss: 0.118462, loss_s1: 0.072669, loss_fp: 0.005680, loss_freq: 0.046244
[03:58:32.065] iteration 8581: loss: 0.129354, loss_s1: 0.098366, loss_fp: 0.004860, loss_freq: 0.079083
[03:58:32.658] iteration 8582: loss: 0.046521, loss_s1: 0.028272, loss_fp: 0.002640, loss_freq: 0.014598
[03:58:33.248] iteration 8583: loss: 0.120216, loss_s1: 0.132875, loss_fp: 0.002250, loss_freq: 0.043110
[03:58:33.839] iteration 8584: loss: 0.088116, loss_s1: 0.083529, loss_fp: 0.006493, loss_freq: 0.022774
[03:58:34.428] iteration 8585: loss: 0.070000, loss_s1: 0.028494, loss_fp: 0.005678, loss_freq: 0.025165
[03:58:35.021] iteration 8586: loss: 0.070543, loss_s1: 0.054199, loss_fp: 0.002990, loss_freq: 0.038483
[03:58:35.625] iteration 8587: loss: 0.084157, loss_s1: 0.031030, loss_fp: 0.003004, loss_freq: 0.076521
[03:58:36.215] iteration 8588: loss: 0.094479, loss_s1: 0.070593, loss_fp: 0.002349, loss_freq: 0.051444
[03:58:36.804] iteration 8589: loss: 0.087804, loss_s1: 0.093518, loss_fp: 0.005159, loss_freq: 0.030132
[03:58:37.394] iteration 8590: loss: 0.065086, loss_s1: 0.028106, loss_fp: 0.004609, loss_freq: 0.030290
[03:58:37.985] iteration 8591: loss: 0.086014, loss_s1: 0.067318, loss_fp: 0.003633, loss_freq: 0.027638
[03:58:38.570] iteration 8592: loss: 0.094152, loss_s1: 0.065309, loss_fp: 0.004264, loss_freq: 0.073297
[03:58:39.164] iteration 8593: loss: 0.082835, loss_s1: 0.024787, loss_fp: 0.009580, loss_freq: 0.048406
[03:58:39.754] iteration 8594: loss: 0.064461, loss_s1: 0.033491, loss_fp: 0.004064, loss_freq: 0.010034
[03:58:40.341] iteration 8595: loss: 0.061832, loss_s1: 0.028019, loss_fp: 0.001282, loss_freq: 0.034412
[03:58:40.938] iteration 8596: loss: 0.118632, loss_s1: 0.120448, loss_fp: 0.001639, loss_freq: 0.052060
[03:58:41.532] iteration 8597: loss: 0.157582, loss_s1: 0.145518, loss_fp: 0.002441, loss_freq: 0.103929
[03:58:42.123] iteration 8598: loss: 0.118290, loss_s1: 0.107960, loss_fp: 0.003705, loss_freq: 0.065636
[03:58:42.713] iteration 8599: loss: 0.058892, loss_s1: 0.029579, loss_fp: 0.001540, loss_freq: 0.035202
[03:58:43.308] iteration 8600: loss: 0.055361, loss_s1: 0.021045, loss_fp: 0.001498, loss_freq: 0.033170
[03:58:46.469] iteration 8600 : mean_dice : 0.685336
[03:58:47.083] iteration 8601: loss: 0.077728, loss_s1: 0.059231, loss_fp: 0.001675, loss_freq: 0.025519
[03:58:47.678] iteration 8602: loss: 0.072634, loss_s1: 0.050195, loss_fp: 0.000787, loss_freq: 0.016338
[03:58:48.261] iteration 8603: loss: 0.081720, loss_s1: 0.029423, loss_fp: 0.002345, loss_freq: 0.017842
[03:58:48.851] iteration 8604: loss: 0.066257, loss_s1: 0.036516, loss_fp: 0.003593, loss_freq: 0.030900
[03:58:49.437] iteration 8605: loss: 0.065855, loss_s1: 0.060136, loss_fp: 0.005331, loss_freq: 0.018588
[03:58:50.061] iteration 8606: loss: 0.070687, loss_s1: 0.048575, loss_fp: 0.009036, loss_freq: 0.026254
[03:58:50.657] iteration 8607: loss: 0.094177, loss_s1: 0.076334, loss_fp: 0.008916, loss_freq: 0.027911
[03:58:51.250] iteration 8608: loss: 0.065428, loss_s1: 0.015017, loss_fp: 0.000631, loss_freq: 0.032895
[03:58:51.841] iteration 8609: loss: 0.103835, loss_s1: 0.040967, loss_fp: 0.004379, loss_freq: 0.090606
[03:58:52.435] iteration 8610: loss: 0.054905, loss_s1: 0.027374, loss_fp: 0.007097, loss_freq: 0.023539
[03:58:53.031] iteration 8611: loss: 0.073430, loss_s1: 0.053417, loss_fp: 0.001641, loss_freq: 0.032783
[03:58:53.623] iteration 8612: loss: 0.055702, loss_s1: 0.024518, loss_fp: 0.001722, loss_freq: 0.025144
[03:58:54.211] iteration 8613: loss: 0.068010, loss_s1: 0.059893, loss_fp: 0.001429, loss_freq: 0.027157
[03:58:54.807] iteration 8614: loss: 0.060027, loss_s1: 0.042251, loss_fp: 0.003385, loss_freq: 0.024675
[03:58:55.405] iteration 8615: loss: 0.124884, loss_s1: 0.119082, loss_fp: 0.002145, loss_freq: 0.058163
[03:58:55.995] iteration 8616: loss: 0.078708, loss_s1: 0.032386, loss_fp: 0.002958, loss_freq: 0.065962
[03:58:56.588] iteration 8617: loss: 0.129305, loss_s1: 0.088192, loss_fp: 0.002529, loss_freq: 0.054022
[03:58:57.181] iteration 8618: loss: 0.059159, loss_s1: 0.035726, loss_fp: 0.001469, loss_freq: 0.027922
[03:58:57.766] iteration 8619: loss: 0.158033, loss_s1: 0.120730, loss_fp: 0.011939, loss_freq: 0.130612
[03:58:58.350] iteration 8620: loss: 0.078934, loss_s1: 0.035282, loss_fp: 0.005078, loss_freq: 0.032800
[03:58:58.980] iteration 8621: loss: 0.060371, loss_s1: 0.025901, loss_fp: 0.002406, loss_freq: 0.026972
[03:58:59.611] iteration 8622: loss: 0.089228, loss_s1: 0.037651, loss_fp: 0.001749, loss_freq: 0.061159
[03:59:00.248] iteration 8623: loss: 0.113134, loss_s1: 0.044111, loss_fp: 0.002977, loss_freq: 0.106634
[03:59:00.874] iteration 8624: loss: 0.074021, loss_s1: 0.050133, loss_fp: 0.004282, loss_freq: 0.039705
[03:59:01.468] iteration 8625: loss: 0.086596, loss_s1: 0.083928, loss_fp: 0.006902, loss_freq: 0.017426
[03:59:02.092] iteration 8626: loss: 0.113370, loss_s1: 0.131601, loss_fp: 0.003017, loss_freq: 0.022802
[03:59:02.737] iteration 8627: loss: 0.118781, loss_s1: 0.093695, loss_fp: 0.004696, loss_freq: 0.071311
[03:59:03.366] iteration 8628: loss: 0.083787, loss_s1: 0.031147, loss_fp: 0.002883, loss_freq: 0.047647
[03:59:03.997] iteration 8629: loss: 0.056398, loss_s1: 0.043516, loss_fp: 0.002237, loss_freq: 0.019533
[03:59:04.592] iteration 8630: loss: 0.117847, loss_s1: 0.105516, loss_fp: 0.002366, loss_freq: 0.061170
[03:59:05.186] iteration 8631: loss: 0.094157, loss_s1: 0.112187, loss_fp: 0.002262, loss_freq: 0.030375
[03:59:05.778] iteration 8632: loss: 0.068902, loss_s1: 0.040669, loss_fp: 0.002859, loss_freq: 0.023991
[03:59:06.373] iteration 8633: loss: 0.106381, loss_s1: 0.094801, loss_fp: 0.002579, loss_freq: 0.048862
[03:59:06.962] iteration 8634: loss: 0.086115, loss_s1: 0.075277, loss_fp: 0.003386, loss_freq: 0.035474
[03:59:07.550] iteration 8635: loss: 0.104931, loss_s1: 0.076893, loss_fp: 0.001264, loss_freq: 0.082676
[03:59:08.141] iteration 8636: loss: 0.062892, loss_s1: 0.036733, loss_fp: 0.002270, loss_freq: 0.042201
[03:59:08.736] iteration 8637: loss: 0.094556, loss_s1: 0.095837, loss_fp: 0.001335, loss_freq: 0.032049
[03:59:09.327] iteration 8638: loss: 0.111528, loss_s1: 0.090252, loss_fp: 0.004329, loss_freq: 0.082805
[03:59:09.922] iteration 8639: loss: 0.103886, loss_s1: 0.075438, loss_fp: 0.002943, loss_freq: 0.061295
[03:59:10.519] iteration 8640: loss: 0.115955, loss_s1: 0.106781, loss_fp: 0.002052, loss_freq: 0.086586
[03:59:11.113] iteration 8641: loss: 0.119188, loss_s1: 0.114625, loss_fp: 0.006696, loss_freq: 0.045545
[03:59:11.704] iteration 8642: loss: 0.081280, loss_s1: 0.056977, loss_fp: 0.002138, loss_freq: 0.048798
[03:59:12.289] iteration 8643: loss: 0.064226, loss_s1: 0.045098, loss_fp: 0.005331, loss_freq: 0.026218
[03:59:12.882] iteration 8644: loss: 0.069886, loss_s1: 0.049713, loss_fp: 0.008555, loss_freq: 0.027556
[03:59:13.474] iteration 8645: loss: 0.041695, loss_s1: 0.017909, loss_fp: 0.008022, loss_freq: 0.010677
[03:59:14.104] iteration 8646: loss: 0.096476, loss_s1: 0.036304, loss_fp: 0.005844, loss_freq: 0.053610
[03:59:15.032] iteration 8647: loss: 0.081644, loss_s1: 0.069793, loss_fp: 0.005704, loss_freq: 0.039369
[03:59:15.956] iteration 8648: loss: 0.099113, loss_s1: 0.078754, loss_fp: 0.003218, loss_freq: 0.056391
[03:59:16.826] iteration 8649: loss: 0.112666, loss_s1: 0.102692, loss_fp: 0.008064, loss_freq: 0.061079
[03:59:17.450] iteration 8650: loss: 0.126822, loss_s1: 0.076334, loss_fp: 0.003553, loss_freq: 0.046902
[03:59:18.077] iteration 8651: loss: 0.111722, loss_s1: 0.098689, loss_fp: 0.002291, loss_freq: 0.043417
[03:59:18.709] iteration 8652: loss: 0.090948, loss_s1: 0.057134, loss_fp: 0.003151, loss_freq: 0.061518
[03:59:19.341] iteration 8653: loss: 0.132958, loss_s1: 0.114633, loss_fp: 0.004423, loss_freq: 0.061233
[03:59:19.968] iteration 8654: loss: 0.084899, loss_s1: 0.050803, loss_fp: 0.005360, loss_freq: 0.048652
[03:59:20.560] iteration 8655: loss: 0.118234, loss_s1: 0.068343, loss_fp: 0.005918, loss_freq: 0.103312
[03:59:21.152] iteration 8656: loss: 0.068162, loss_s1: 0.061497, loss_fp: 0.001080, loss_freq: 0.016608
[03:59:21.742] iteration 8657: loss: 0.066933, loss_s1: 0.022407, loss_fp: 0.003319, loss_freq: 0.063689
[03:59:22.371] iteration 8658: loss: 0.102963, loss_s1: 0.066502, loss_fp: 0.005461, loss_freq: 0.068329
[03:59:22.998] iteration 8659: loss: 0.096504, loss_s1: 0.082986, loss_fp: 0.003312, loss_freq: 0.058076
[03:59:23.641] iteration 8660: loss: 0.089416, loss_s1: 0.078948, loss_fp: 0.009156, loss_freq: 0.026136
[03:59:24.237] iteration 8661: loss: 0.078166, loss_s1: 0.046072, loss_fp: 0.003035, loss_freq: 0.052395
[03:59:24.831] iteration 8662: loss: 0.104131, loss_s1: 0.123444, loss_fp: 0.004463, loss_freq: 0.020963
[03:59:25.426] iteration 8663: loss: 0.117218, loss_s1: 0.059196, loss_fp: 0.003236, loss_freq: 0.040394
[03:59:26.018] iteration 8664: loss: 0.066212, loss_s1: 0.043425, loss_fp: 0.001390, loss_freq: 0.019415
[03:59:26.610] iteration 8665: loss: 0.087046, loss_s1: 0.085707, loss_fp: 0.008941, loss_freq: 0.018412
[03:59:27.212] iteration 8666: loss: 0.124642, loss_s1: 0.129171, loss_fp: 0.001765, loss_freq: 0.046087
[03:59:27.809] iteration 8667: loss: 0.108920, loss_s1: 0.065861, loss_fp: 0.004498, loss_freq: 0.067306
[03:59:28.413] iteration 8668: loss: 0.113633, loss_s1: 0.083424, loss_fp: 0.051652, loss_freq: 0.025896
[03:59:29.008] iteration 8669: loss: 0.129552, loss_s1: 0.068212, loss_fp: 0.002044, loss_freq: 0.062805
[03:59:29.600] iteration 8670: loss: 0.084738, loss_s1: 0.071725, loss_fp: 0.005801, loss_freq: 0.044832
[03:59:30.506] iteration 8671: loss: 0.102453, loss_s1: 0.085763, loss_fp: 0.005791, loss_freq: 0.023418
[03:59:31.100] iteration 8672: loss: 0.079014, loss_s1: 0.050878, loss_fp: 0.000576, loss_freq: 0.048214
[03:59:31.714] iteration 8673: loss: 0.084323, loss_s1: 0.072003, loss_fp: 0.001505, loss_freq: 0.038506
[03:59:32.365] iteration 8674: loss: 0.097455, loss_s1: 0.089405, loss_fp: 0.003920, loss_freq: 0.032783
[03:59:33.002] iteration 8675: loss: 0.070631, loss_s1: 0.070363, loss_fp: 0.001430, loss_freq: 0.019652
[03:59:33.640] iteration 8676: loss: 0.085477, loss_s1: 0.043680, loss_fp: 0.008912, loss_freq: 0.016804
[03:59:34.248] iteration 8677: loss: 0.087860, loss_s1: 0.041826, loss_fp: 0.001844, loss_freq: 0.044241
[03:59:34.847] iteration 8678: loss: 0.064924, loss_s1: 0.034723, loss_fp: 0.000679, loss_freq: 0.031894
[03:59:35.443] iteration 8679: loss: 0.083081, loss_s1: 0.040256, loss_fp: 0.002142, loss_freq: 0.031367
[03:59:36.031] iteration 8680: loss: 0.075857, loss_s1: 0.053162, loss_fp: 0.003373, loss_freq: 0.029424
[03:59:36.621] iteration 8681: loss: 0.079945, loss_s1: 0.019902, loss_fp: 0.002229, loss_freq: 0.075732
[03:59:37.220] iteration 8682: loss: 0.064354, loss_s1: 0.023717, loss_fp: 0.015995, loss_freq: 0.039841
[03:59:37.812] iteration 8683: loss: 0.098698, loss_s1: 0.098494, loss_fp: 0.001637, loss_freq: 0.041334
[03:59:38.412] iteration 8684: loss: 0.078136, loss_s1: 0.046960, loss_fp: 0.003540, loss_freq: 0.026222
[03:59:39.016] iteration 8685: loss: 0.055512, loss_s1: 0.034600, loss_fp: 0.002137, loss_freq: 0.015105
[03:59:39.622] iteration 8686: loss: 0.098105, loss_s1: 0.029415, loss_fp: 0.003389, loss_freq: 0.075417
[03:59:40.225] iteration 8687: loss: 0.098762, loss_s1: 0.066523, loss_fp: 0.010942, loss_freq: 0.058068
[03:59:40.818] iteration 8688: loss: 0.066611, loss_s1: 0.031569, loss_fp: 0.001424, loss_freq: 0.010539
[03:59:41.415] iteration 8689: loss: 0.089331, loss_s1: 0.095096, loss_fp: 0.003306, loss_freq: 0.034221
[03:59:42.007] iteration 8690: loss: 0.130541, loss_s1: 0.118929, loss_fp: 0.006651, loss_freq: 0.035283
[03:59:42.603] iteration 8691: loss: 0.083691, loss_s1: 0.055290, loss_fp: 0.000959, loss_freq: 0.049713
[03:59:43.196] iteration 8692: loss: 0.087952, loss_s1: 0.083293, loss_fp: 0.002941, loss_freq: 0.035090
[03:59:43.793] iteration 8693: loss: 0.098898, loss_s1: 0.070841, loss_fp: 0.003414, loss_freq: 0.042216
[03:59:44.394] iteration 8694: loss: 0.070612, loss_s1: 0.050445, loss_fp: 0.003702, loss_freq: 0.032338
[03:59:44.992] iteration 8695: loss: 0.097278, loss_s1: 0.096357, loss_fp: 0.009213, loss_freq: 0.034625
[03:59:45.591] iteration 8696: loss: 0.113892, loss_s1: 0.112197, loss_fp: 0.003666, loss_freq: 0.062641
[03:59:46.190] iteration 8697: loss: 0.092853, loss_s1: 0.094393, loss_fp: 0.001433, loss_freq: 0.030034
[03:59:46.785] iteration 8698: loss: 0.179773, loss_s1: 0.176332, loss_fp: 0.005876, loss_freq: 0.050069
[03:59:47.385] iteration 8699: loss: 0.083367, loss_s1: 0.059725, loss_fp: 0.008678, loss_freq: 0.042313
[03:59:47.978] iteration 8700: loss: 0.090166, loss_s1: 0.099703, loss_fp: 0.006984, loss_freq: 0.021200
[03:59:48.564] iteration 8701: loss: 0.113016, loss_s1: 0.109552, loss_fp: 0.006862, loss_freq: 0.054843
[03:59:49.160] iteration 8702: loss: 0.090803, loss_s1: 0.067468, loss_fp: 0.003539, loss_freq: 0.046865
[03:59:49.772] iteration 8703: loss: 0.076734, loss_s1: 0.060521, loss_fp: 0.008500, loss_freq: 0.028455
[03:59:50.363] iteration 8704: loss: 0.059333, loss_s1: 0.033676, loss_fp: 0.002276, loss_freq: 0.011595
[03:59:50.993] iteration 8705: loss: 0.061881, loss_s1: 0.049662, loss_fp: 0.004226, loss_freq: 0.023208
[03:59:51.623] iteration 8706: loss: 0.042968, loss_s1: 0.018265, loss_fp: 0.000595, loss_freq: 0.007608
[03:59:52.235] iteration 8707: loss: 0.098904, loss_s1: 0.077340, loss_fp: 0.000553, loss_freq: 0.056418
[03:59:52.839] iteration 8708: loss: 0.077221, loss_s1: 0.042872, loss_fp: 0.003376, loss_freq: 0.019722
[03:59:53.438] iteration 8709: loss: 0.218267, loss_s1: 0.189849, loss_fp: 0.003967, loss_freq: 0.094957
[03:59:54.043] iteration 8710: loss: 0.081264, loss_s1: 0.061864, loss_fp: 0.009885, loss_freq: 0.041989
[03:59:54.647] iteration 8711: loss: 0.093084, loss_s1: 0.056067, loss_fp: 0.001304, loss_freq: 0.062553
[03:59:55.245] iteration 8712: loss: 0.079206, loss_s1: 0.072520, loss_fp: 0.004437, loss_freq: 0.030067
[03:59:55.844] iteration 8713: loss: 0.108952, loss_s1: 0.108785, loss_fp: 0.004786, loss_freq: 0.057522
[03:59:56.466] iteration 8714: loss: 0.153216, loss_s1: 0.156139, loss_fp: 0.003695, loss_freq: 0.086778
[03:59:57.060] iteration 8715: loss: 0.071696, loss_s1: 0.053930, loss_fp: 0.002111, loss_freq: 0.026617
[03:59:57.656] iteration 8716: loss: 0.101076, loss_s1: 0.095200, loss_fp: 0.003721, loss_freq: 0.028299
[03:59:58.250] iteration 8717: loss: 0.080722, loss_s1: 0.070608, loss_fp: 0.004671, loss_freq: 0.036167
[03:59:58.854] iteration 8718: loss: 0.058047, loss_s1: 0.033396, loss_fp: 0.008318, loss_freq: 0.024176
[03:59:59.446] iteration 8719: loss: 0.093999, loss_s1: 0.066877, loss_fp: 0.013181, loss_freq: 0.018785
[04:00:00.044] iteration 8720: loss: 0.087420, loss_s1: 0.079880, loss_fp: 0.004577, loss_freq: 0.020588
[04:00:00.636] iteration 8721: loss: 0.118751, loss_s1: 0.082144, loss_fp: 0.003147, loss_freq: 0.078297
[04:00:01.238] iteration 8722: loss: 0.082284, loss_s1: 0.076315, loss_fp: 0.003300, loss_freq: 0.036165
[04:00:01.835] iteration 8723: loss: 0.070668, loss_s1: 0.038346, loss_fp: 0.002323, loss_freq: 0.027345
[04:00:02.433] iteration 8724: loss: 0.095093, loss_s1: 0.040356, loss_fp: 0.006386, loss_freq: 0.073539
[04:00:03.028] iteration 8725: loss: 0.111321, loss_s1: 0.089053, loss_fp: 0.000979, loss_freq: 0.053023
[04:00:03.622] iteration 8726: loss: 0.077457, loss_s1: 0.055858, loss_fp: 0.002798, loss_freq: 0.017079
[04:00:04.216] iteration 8727: loss: 0.088412, loss_s1: 0.086593, loss_fp: 0.001585, loss_freq: 0.035292
[04:00:04.802] iteration 8728: loss: 0.076795, loss_s1: 0.037904, loss_fp: 0.000984, loss_freq: 0.035504
[04:00:05.388] iteration 8729: loss: 0.098807, loss_s1: 0.042386, loss_fp: 0.003922, loss_freq: 0.073428
[04:00:05.980] iteration 8730: loss: 0.093470, loss_s1: 0.065295, loss_fp: 0.002462, loss_freq: 0.050983
[04:00:06.568] iteration 8731: loss: 0.052073, loss_s1: 0.035890, loss_fp: 0.002187, loss_freq: 0.021683
[04:00:07.165] iteration 8732: loss: 0.120126, loss_s1: 0.070442, loss_fp: 0.004357, loss_freq: 0.086142
[04:00:07.753] iteration 8733: loss: 0.058345, loss_s1: 0.028623, loss_fp: 0.002523, loss_freq: 0.010852
[04:00:08.341] iteration 8734: loss: 0.062572, loss_s1: 0.053839, loss_fp: 0.001894, loss_freq: 0.025361
[04:00:08.930] iteration 8735: loss: 0.142691, loss_s1: 0.179920, loss_fp: 0.001695, loss_freq: 0.047017
[04:00:09.531] iteration 8736: loss: 0.071055, loss_s1: 0.027009, loss_fp: 0.001656, loss_freq: 0.033371
[04:00:10.125] iteration 8737: loss: 0.094902, loss_s1: 0.055556, loss_fp: 0.000811, loss_freq: 0.016349
[04:00:10.721] iteration 8738: loss: 0.149737, loss_s1: 0.137930, loss_fp: 0.003133, loss_freq: 0.092531
[04:00:11.348] iteration 8739: loss: 0.090753, loss_s1: 0.036578, loss_fp: 0.006207, loss_freq: 0.029031
[04:00:11.988] iteration 8740: loss: 0.084332, loss_s1: 0.064182, loss_fp: 0.003842, loss_freq: 0.040132
[04:00:12.623] iteration 8741: loss: 0.068815, loss_s1: 0.038039, loss_fp: 0.004726, loss_freq: 0.031292
[04:00:13.217] iteration 8742: loss: 0.093467, loss_s1: 0.060315, loss_fp: 0.002745, loss_freq: 0.054065
[04:00:13.810] iteration 8743: loss: 0.081392, loss_s1: 0.059375, loss_fp: 0.008393, loss_freq: 0.038573
[04:00:14.402] iteration 8744: loss: 0.189865, loss_s1: 0.178897, loss_fp: 0.002085, loss_freq: 0.097171
[04:00:15.070] iteration 8745: loss: 0.085123, loss_s1: 0.027105, loss_fp: 0.002320, loss_freq: 0.074832
[04:00:15.706] iteration 8746: loss: 0.101909, loss_s1: 0.067547, loss_fp: 0.008079, loss_freq: 0.055231
[04:00:16.339] iteration 8747: loss: 0.073864, loss_s1: 0.084904, loss_fp: 0.001641, loss_freq: 0.020261
[04:00:16.973] iteration 8748: loss: 0.081359, loss_s1: 0.062045, loss_fp: 0.004257, loss_freq: 0.034794
[04:00:17.648] iteration 8749: loss: 0.094453, loss_s1: 0.086921, loss_fp: 0.000979, loss_freq: 0.046952
[04:00:18.291] iteration 8750: loss: 0.076110, loss_s1: 0.082461, loss_fp: 0.002521, loss_freq: 0.016772
[04:00:18.930] iteration 8751: loss: 0.075525, loss_s1: 0.046316, loss_fp: 0.005212, loss_freq: 0.047389
[04:00:19.528] iteration 8752: loss: 0.086884, loss_s1: 0.044815, loss_fp: 0.002040, loss_freq: 0.038117
[04:00:20.159] iteration 8753: loss: 0.077539, loss_s1: 0.073238, loss_fp: 0.004327, loss_freq: 0.012797
[04:00:20.806] iteration 8754: loss: 0.064561, loss_s1: 0.057617, loss_fp: 0.004508, loss_freq: 0.015953
[04:00:21.449] iteration 8755: loss: 0.106294, loss_s1: 0.098547, loss_fp: 0.001041, loss_freq: 0.048848
[04:00:22.081] iteration 8756: loss: 0.092821, loss_s1: 0.075395, loss_fp: 0.003181, loss_freq: 0.029525
[04:00:22.693] iteration 8757: loss: 0.134748, loss_s1: 0.154294, loss_fp: 0.007534, loss_freq: 0.068931
[04:00:23.304] iteration 8758: loss: 0.095991, loss_s1: 0.090214, loss_fp: 0.006224, loss_freq: 0.043301
[04:00:23.906] iteration 8759: loss: 0.065075, loss_s1: 0.059608, loss_fp: 0.004465, loss_freq: 0.021506
[04:00:24.513] iteration 8760: loss: 0.061185, loss_s1: 0.022722, loss_fp: 0.005083, loss_freq: 0.022923
[04:00:25.124] iteration 8761: loss: 0.113148, loss_s1: 0.128744, loss_fp: 0.002673, loss_freq: 0.035918
[04:00:25.725] iteration 8762: loss: 0.071929, loss_s1: 0.048359, loss_fp: 0.002156, loss_freq: 0.041978
[04:00:26.331] iteration 8763: loss: 0.105400, loss_s1: 0.087989, loss_fp: 0.003537, loss_freq: 0.037725
[04:00:26.943] iteration 8764: loss: 0.062768, loss_s1: 0.047043, loss_fp: 0.004127, loss_freq: 0.014401
[04:00:27.550] iteration 8765: loss: 0.079243, loss_s1: 0.051602, loss_fp: 0.002339, loss_freq: 0.042081
[04:00:28.155] iteration 8766: loss: 0.071426, loss_s1: 0.083556, loss_fp: 0.001974, loss_freq: 0.020380
[04:00:28.764] iteration 8767: loss: 0.132773, loss_s1: 0.074535, loss_fp: 0.003425, loss_freq: 0.078176
[04:00:29.370] iteration 8768: loss: 0.085703, loss_s1: 0.061795, loss_fp: 0.004259, loss_freq: 0.047392
[04:00:29.976] iteration 8769: loss: 0.080610, loss_s1: 0.056564, loss_fp: 0.000935, loss_freq: 0.030781
[04:00:30.568] iteration 8770: loss: 0.096235, loss_s1: 0.047146, loss_fp: 0.004271, loss_freq: 0.056241
[04:00:31.161] iteration 8771: loss: 0.078008, loss_s1: 0.046683, loss_fp: 0.001831, loss_freq: 0.023964
[04:00:31.757] iteration 8772: loss: 0.093781, loss_s1: 0.047299, loss_fp: 0.001944, loss_freq: 0.018694
[04:00:32.365] iteration 8773: loss: 0.068342, loss_s1: 0.025995, loss_fp: 0.002924, loss_freq: 0.046294
[04:00:32.960] iteration 8774: loss: 0.067799, loss_s1: 0.037642, loss_fp: 0.001352, loss_freq: 0.020542
[04:00:33.560] iteration 8775: loss: 0.106975, loss_s1: 0.080820, loss_fp: 0.002130, loss_freq: 0.085651
[04:00:34.156] iteration 8776: loss: 0.078722, loss_s1: 0.077313, loss_fp: 0.001227, loss_freq: 0.014818
[04:00:34.753] iteration 8777: loss: 0.072413, loss_s1: 0.043037, loss_fp: 0.006360, loss_freq: 0.028664
[04:00:35.347] iteration 8778: loss: 0.048805, loss_s1: 0.020491, loss_fp: 0.004223, loss_freq: 0.021851
[04:00:35.945] iteration 8779: loss: 0.127956, loss_s1: 0.101690, loss_fp: 0.006700, loss_freq: 0.084901
[04:00:36.541] iteration 8780: loss: 0.057277, loss_s1: 0.038466, loss_fp: 0.002049, loss_freq: 0.015908
[04:00:37.136] iteration 8781: loss: 0.072102, loss_s1: 0.049780, loss_fp: 0.002522, loss_freq: 0.034614
[04:00:37.736] iteration 8782: loss: 0.074193, loss_s1: 0.063909, loss_fp: 0.001880, loss_freq: 0.034046
[04:00:38.329] iteration 8783: loss: 0.077009, loss_s1: 0.063585, loss_fp: 0.001742, loss_freq: 0.033983
[04:00:38.922] iteration 8784: loss: 0.059867, loss_s1: 0.045349, loss_fp: 0.005000, loss_freq: 0.031422
[04:00:39.519] iteration 8785: loss: 0.113769, loss_s1: 0.111943, loss_fp: 0.000891, loss_freq: 0.056357
[04:00:40.116] iteration 8786: loss: 0.105615, loss_s1: 0.059725, loss_fp: 0.008944, loss_freq: 0.079915
[04:00:40.709] iteration 8787: loss: 0.088181, loss_s1: 0.094722, loss_fp: 0.004012, loss_freq: 0.025187
[04:00:41.303] iteration 8788: loss: 0.079492, loss_s1: 0.038917, loss_fp: 0.002322, loss_freq: 0.027645
[04:00:41.899] iteration 8789: loss: 0.092528, loss_s1: 0.044887, loss_fp: 0.004384, loss_freq: 0.066617
[04:00:42.537] iteration 8790: loss: 0.069011, loss_s1: 0.036053, loss_fp: 0.001764, loss_freq: 0.024981
[04:00:43.171] iteration 8791: loss: 0.076105, loss_s1: 0.080214, loss_fp: 0.000535, loss_freq: 0.011068
[04:00:43.804] iteration 8792: loss: 0.075495, loss_s1: 0.062367, loss_fp: 0.003158, loss_freq: 0.048769
[04:00:44.438] iteration 8793: loss: 0.083863, loss_s1: 0.041978, loss_fp: 0.005305, loss_freq: 0.044124
[04:00:45.070] iteration 8794: loss: 0.064841, loss_s1: 0.051677, loss_fp: 0.001395, loss_freq: 0.028773
[04:00:45.670] iteration 8795: loss: 0.102702, loss_s1: 0.073630, loss_fp: 0.004471, loss_freq: 0.059221
[04:00:46.265] iteration 8796: loss: 0.070562, loss_s1: 0.067314, loss_fp: 0.001355, loss_freq: 0.015353
[04:00:46.863] iteration 8797: loss: 0.094302, loss_s1: 0.054482, loss_fp: 0.002982, loss_freq: 0.071596
[04:00:47.452] iteration 8798: loss: 0.103768, loss_s1: 0.040822, loss_fp: 0.000825, loss_freq: 0.097178
[04:00:48.047] iteration 8799: loss: 0.048860, loss_s1: 0.028708, loss_fp: 0.006186, loss_freq: 0.017294
[04:00:48.636] iteration 8800: loss: 0.118586, loss_s1: 0.086233, loss_fp: 0.003885, loss_freq: 0.079617
[04:00:51.962] iteration 8800 : mean_dice : 0.690461
[04:00:52.587] iteration 8801: loss: 0.089610, loss_s1: 0.075834, loss_fp: 0.007417, loss_freq: 0.047027
[04:00:53.192] iteration 8802: loss: 0.088966, loss_s1: 0.076650, loss_fp: 0.003332, loss_freq: 0.020489
[04:00:53.787] iteration 8803: loss: 0.086006, loss_s1: 0.079254, loss_fp: 0.000954, loss_freq: 0.029411
[04:00:54.418] iteration 8804: loss: 0.078293, loss_s1: 0.068118, loss_fp: 0.002241, loss_freq: 0.039128
[04:00:55.049] iteration 8805: loss: 0.086388, loss_s1: 0.084144, loss_fp: 0.001914, loss_freq: 0.023525
[04:00:55.680] iteration 8806: loss: 0.050886, loss_s1: 0.023467, loss_fp: 0.002641, loss_freq: 0.010672
[04:00:56.320] iteration 8807: loss: 0.105117, loss_s1: 0.075693, loss_fp: 0.000872, loss_freq: 0.013771
[04:00:56.962] iteration 8808: loss: 0.099457, loss_s1: 0.040910, loss_fp: 0.007057, loss_freq: 0.076000
[04:00:57.587] iteration 8809: loss: 0.117993, loss_s1: 0.118863, loss_fp: 0.006223, loss_freq: 0.052946
[04:00:58.222] iteration 8810: loss: 0.051732, loss_s1: 0.024927, loss_fp: 0.001915, loss_freq: 0.028807
[04:00:58.823] iteration 8811: loss: 0.088135, loss_s1: 0.053982, loss_fp: 0.001570, loss_freq: 0.029693
[04:00:59.422] iteration 8812: loss: 0.082917, loss_s1: 0.065273, loss_fp: 0.004549, loss_freq: 0.045240
[04:01:00.012] iteration 8813: loss: 0.091588, loss_s1: 0.099956, loss_fp: 0.002317, loss_freq: 0.018195
[04:01:00.606] iteration 8814: loss: 0.059484, loss_s1: 0.023967, loss_fp: 0.003692, loss_freq: 0.014565
[04:01:01.202] iteration 8815: loss: 0.075389, loss_s1: 0.066832, loss_fp: 0.006238, loss_freq: 0.013768
[04:01:01.799] iteration 8816: loss: 0.085398, loss_s1: 0.049498, loss_fp: 0.014151, loss_freq: 0.022697
[04:01:02.395] iteration 8817: loss: 0.087437, loss_s1: 0.084959, loss_fp: 0.005493, loss_freq: 0.040234
[04:01:02.989] iteration 8818: loss: 0.112247, loss_s1: 0.106624, loss_fp: 0.005807, loss_freq: 0.049939
[04:01:03.579] iteration 8819: loss: 0.108136, loss_s1: 0.121157, loss_fp: 0.002784, loss_freq: 0.047307
[04:01:04.211] iteration 8820: loss: 0.111905, loss_s1: 0.057961, loss_fp: 0.020429, loss_freq: 0.051450
[04:01:04.803] iteration 8821: loss: 0.102393, loss_s1: 0.084702, loss_fp: 0.006232, loss_freq: 0.032532
[04:01:05.399] iteration 8822: loss: 0.106644, loss_s1: 0.058228, loss_fp: 0.001689, loss_freq: 0.091729
[04:01:05.993] iteration 8823: loss: 0.120016, loss_s1: 0.101008, loss_fp: 0.007796, loss_freq: 0.052589
[04:01:06.586] iteration 8824: loss: 0.086723, loss_s1: 0.055587, loss_fp: 0.003679, loss_freq: 0.048089
[04:01:07.179] iteration 8825: loss: 0.085914, loss_s1: 0.068902, loss_fp: 0.002432, loss_freq: 0.032638
[04:01:07.775] iteration 8826: loss: 0.065653, loss_s1: 0.043170, loss_fp: 0.001379, loss_freq: 0.036579
[04:01:08.369] iteration 8827: loss: 0.056848, loss_s1: 0.035506, loss_fp: 0.004516, loss_freq: 0.032487
[04:01:08.962] iteration 8828: loss: 0.126068, loss_s1: 0.101640, loss_fp: 0.004628, loss_freq: 0.064711
[04:01:09.557] iteration 8829: loss: 0.082660, loss_s1: 0.054657, loss_fp: 0.013751, loss_freq: 0.054796
[04:01:10.161] iteration 8830: loss: 0.073675, loss_s1: 0.038377, loss_fp: 0.011004, loss_freq: 0.027171
[04:01:10.755] iteration 8831: loss: 0.052440, loss_s1: 0.039364, loss_fp: 0.001425, loss_freq: 0.018224
[04:01:11.378] iteration 8832: loss: 0.083560, loss_s1: 0.054234, loss_fp: 0.002977, loss_freq: 0.038355
[04:01:11.974] iteration 8833: loss: 0.055535, loss_s1: 0.028473, loss_fp: 0.001171, loss_freq: 0.009712
[04:01:12.565] iteration 8834: loss: 0.107518, loss_s1: 0.118517, loss_fp: 0.001583, loss_freq: 0.026973
[04:01:13.161] iteration 8835: loss: 0.045922, loss_s1: 0.021923, loss_fp: 0.001809, loss_freq: 0.018012
[04:01:13.758] iteration 8836: loss: 0.088086, loss_s1: 0.085080, loss_fp: 0.010264, loss_freq: 0.037062
[04:01:14.352] iteration 8837: loss: 0.091970, loss_s1: 0.063937, loss_fp: 0.001559, loss_freq: 0.046431
[04:01:14.949] iteration 8838: loss: 0.082451, loss_s1: 0.065670, loss_fp: 0.002487, loss_freq: 0.021664
[04:01:15.538] iteration 8839: loss: 0.077142, loss_s1: 0.063554, loss_fp: 0.003107, loss_freq: 0.030155
[04:01:16.135] iteration 8840: loss: 0.119896, loss_s1: 0.100756, loss_fp: 0.003050, loss_freq: 0.086981
[04:01:17.108] iteration 8841: loss: 0.075888, loss_s1: 0.054809, loss_fp: 0.001460, loss_freq: 0.016330
[04:01:17.702] iteration 8842: loss: 0.086081, loss_s1: 0.092117, loss_fp: 0.002224, loss_freq: 0.023830
[04:01:18.300] iteration 8843: loss: 0.073501, loss_s1: 0.022606, loss_fp: 0.006595, loss_freq: 0.036078
[04:01:18.891] iteration 8844: loss: 0.093407, loss_s1: 0.058226, loss_fp: 0.002710, loss_freq: 0.043125
[04:01:19.536] iteration 8845: loss: 0.070522, loss_s1: 0.056373, loss_fp: 0.006275, loss_freq: 0.037644
[04:01:20.191] iteration 8846: loss: 0.082559, loss_s1: 0.050532, loss_fp: 0.002789, loss_freq: 0.039387
[04:01:20.836] iteration 8847: loss: 0.092396, loss_s1: 0.072076, loss_fp: 0.002817, loss_freq: 0.062145
[04:01:21.743] iteration 8848: loss: 0.071218, loss_s1: 0.029854, loss_fp: 0.003519, loss_freq: 0.026764
[04:01:22.380] iteration 8849: loss: 0.074226, loss_s1: 0.045066, loss_fp: 0.009047, loss_freq: 0.032828
[04:01:22.977] iteration 8850: loss: 0.076534, loss_s1: 0.064066, loss_fp: 0.003009, loss_freq: 0.015966
[04:01:23.568] iteration 8851: loss: 0.085502, loss_s1: 0.039312, loss_fp: 0.003711, loss_freq: 0.051268
[04:01:24.165] iteration 8852: loss: 0.119397, loss_s1: 0.092176, loss_fp: 0.001277, loss_freq: 0.095675
[04:01:24.757] iteration 8853: loss: 0.102851, loss_s1: 0.046486, loss_fp: 0.005013, loss_freq: 0.078842
[04:01:25.349] iteration 8854: loss: 0.056490, loss_s1: 0.051581, loss_fp: 0.002331, loss_freq: 0.008399
[04:01:25.952] iteration 8855: loss: 0.095402, loss_s1: 0.088215, loss_fp: 0.001554, loss_freq: 0.031479
[04:01:26.541] iteration 8856: loss: 0.076105, loss_s1: 0.051496, loss_fp: 0.003346, loss_freq: 0.039339
[04:01:27.181] iteration 8857: loss: 0.173917, loss_s1: 0.122239, loss_fp: 0.010216, loss_freq: 0.175307
[04:01:27.804] iteration 8858: loss: 0.057091, loss_s1: 0.029242, loss_fp: 0.000914, loss_freq: 0.024400
[04:01:28.436] iteration 8859: loss: 0.094264, loss_s1: 0.127147, loss_fp: 0.005434, loss_freq: 0.012404
[04:01:29.054] iteration 8860: loss: 0.079592, loss_s1: 0.071049, loss_fp: 0.001791, loss_freq: 0.025460
[04:01:29.646] iteration 8861: loss: 0.065428, loss_s1: 0.036819, loss_fp: 0.003748, loss_freq: 0.042784
[04:01:30.236] iteration 8862: loss: 0.075203, loss_s1: 0.051178, loss_fp: 0.020197, loss_freq: 0.033475
[04:01:30.872] iteration 8863: loss: 0.096389, loss_s1: 0.067662, loss_fp: 0.001268, loss_freq: 0.023999
[04:01:31.507] iteration 8864: loss: 0.091604, loss_s1: 0.099571, loss_fp: 0.000941, loss_freq: 0.025402
[04:01:32.146] iteration 8865: loss: 0.057258, loss_s1: 0.031830, loss_fp: 0.001960, loss_freq: 0.036584
[04:01:32.781] iteration 8866: loss: 0.085348, loss_s1: 0.072715, loss_fp: 0.001985, loss_freq: 0.051266
[04:01:33.408] iteration 8867: loss: 0.046792, loss_s1: 0.018369, loss_fp: 0.002229, loss_freq: 0.018633
[04:01:34.087] iteration 8868: loss: 0.132760, loss_s1: 0.104060, loss_fp: 0.005176, loss_freq: 0.030864
[04:01:34.718] iteration 8869: loss: 0.115881, loss_s1: 0.096115, loss_fp: 0.003684, loss_freq: 0.046688
[04:01:35.350] iteration 8870: loss: 0.109862, loss_s1: 0.105974, loss_fp: 0.000954, loss_freq: 0.048893
[04:01:35.946] iteration 8871: loss: 0.071467, loss_s1: 0.042792, loss_fp: 0.002508, loss_freq: 0.051232
[04:01:36.551] iteration 8872: loss: 0.122703, loss_s1: 0.123221, loss_fp: 0.001429, loss_freq: 0.037607
[04:01:37.144] iteration 8873: loss: 0.087163, loss_s1: 0.085896, loss_fp: 0.001556, loss_freq: 0.044159
[04:01:37.781] iteration 8874: loss: 0.046377, loss_s1: 0.018741, loss_fp: 0.000745, loss_freq: 0.020998
[04:01:38.433] iteration 8875: loss: 0.073209, loss_s1: 0.041427, loss_fp: 0.000595, loss_freq: 0.040135
[04:01:39.122] iteration 8876: loss: 0.072933, loss_s1: 0.038864, loss_fp: 0.002998, loss_freq: 0.017428
[04:01:39.890] iteration 8877: loss: 0.076283, loss_s1: 0.057633, loss_fp: 0.000824, loss_freq: 0.025864
[04:01:40.542] iteration 8878: loss: 0.113565, loss_s1: 0.084197, loss_fp: 0.013784, loss_freq: 0.062316
[04:01:41.247] iteration 8879: loss: 0.094000, loss_s1: 0.071600, loss_fp: 0.001651, loss_freq: 0.049882
[04:01:41.847] iteration 8880: loss: 0.080162, loss_s1: 0.049129, loss_fp: 0.002975, loss_freq: 0.055462
[04:01:42.452] iteration 8881: loss: 0.128910, loss_s1: 0.122727, loss_fp: 0.006035, loss_freq: 0.033470
[04:01:43.193] iteration 8882: loss: 0.070236, loss_s1: 0.055329, loss_fp: 0.005401, loss_freq: 0.035064
[04:01:43.845] iteration 8883: loss: 0.130836, loss_s1: 0.112107, loss_fp: 0.002634, loss_freq: 0.071205
[04:01:44.583] iteration 8884: loss: 0.105819, loss_s1: 0.081690, loss_fp: 0.001115, loss_freq: 0.071657
[04:01:45.248] iteration 8885: loss: 0.081880, loss_s1: 0.047655, loss_fp: 0.005931, loss_freq: 0.033137
[04:01:46.004] iteration 8886: loss: 0.081381, loss_s1: 0.073111, loss_fp: 0.005356, loss_freq: 0.023834
[04:01:46.614] iteration 8887: loss: 0.089772, loss_s1: 0.059581, loss_fp: 0.007355, loss_freq: 0.047571
[04:01:47.265] iteration 8888: loss: 0.094233, loss_s1: 0.071764, loss_fp: 0.002895, loss_freq: 0.038667
[04:01:47.960] iteration 8889: loss: 0.071818, loss_s1: 0.052353, loss_fp: 0.001638, loss_freq: 0.017756
[04:01:48.636] iteration 8890: loss: 0.067434, loss_s1: 0.033634, loss_fp: 0.002634, loss_freq: 0.046609
[04:01:49.365] iteration 8891: loss: 0.117962, loss_s1: 0.100229, loss_fp: 0.007431, loss_freq: 0.059315
[04:01:50.008] iteration 8892: loss: 0.098340, loss_s1: 0.117810, loss_fp: 0.002726, loss_freq: 0.041408
[04:01:50.607] iteration 8893: loss: 0.106494, loss_s1: 0.118514, loss_fp: 0.001411, loss_freq: 0.033993
[04:01:51.198] iteration 8894: loss: 0.121428, loss_s1: 0.098181, loss_fp: 0.008808, loss_freq: 0.072556
[04:01:51.790] iteration 8895: loss: 0.128174, loss_s1: 0.062307, loss_fp: 0.001478, loss_freq: 0.068580
[04:01:52.385] iteration 8896: loss: 0.048297, loss_s1: 0.034624, loss_fp: 0.001231, loss_freq: 0.011154
[04:01:52.975] iteration 8897: loss: 0.086286, loss_s1: 0.057041, loss_fp: 0.001762, loss_freq: 0.044684
[04:01:53.570] iteration 8898: loss: 0.074685, loss_s1: 0.045612, loss_fp: 0.001452, loss_freq: 0.034382
[04:01:54.160] iteration 8899: loss: 0.060249, loss_s1: 0.044043, loss_fp: 0.000640, loss_freq: 0.029664
[04:01:54.755] iteration 8900: loss: 0.082655, loss_s1: 0.043543, loss_fp: 0.003552, loss_freq: 0.055155
[04:01:55.349] iteration 8901: loss: 0.051449, loss_s1: 0.030880, loss_fp: 0.005017, loss_freq: 0.016041
[04:01:55.942] iteration 8902: loss: 0.119100, loss_s1: 0.054115, loss_fp: 0.004027, loss_freq: 0.048903
[04:01:56.537] iteration 8903: loss: 0.066906, loss_s1: 0.038538, loss_fp: 0.002221, loss_freq: 0.028741
[04:01:57.170] iteration 8904: loss: 0.068160, loss_s1: 0.057803, loss_fp: 0.001227, loss_freq: 0.024742
[04:01:57.800] iteration 8905: loss: 0.117878, loss_s1: 0.090775, loss_fp: 0.001033, loss_freq: 0.043017
[04:01:58.456] iteration 8906: loss: 0.113623, loss_s1: 0.134051, loss_fp: 0.000651, loss_freq: 0.047775
[04:01:59.099] iteration 8907: loss: 0.097886, loss_s1: 0.073248, loss_fp: 0.002822, loss_freq: 0.007436
[04:01:59.740] iteration 8908: loss: 0.134971, loss_s1: 0.122052, loss_fp: 0.007839, loss_freq: 0.059637
[04:02:00.377] iteration 8909: loss: 0.082409, loss_s1: 0.030356, loss_fp: 0.001311, loss_freq: 0.042369
[04:02:01.006] iteration 8910: loss: 0.088984, loss_s1: 0.075858, loss_fp: 0.008609, loss_freq: 0.047118
[04:02:01.602] iteration 8911: loss: 0.069316, loss_s1: 0.045396, loss_fp: 0.003126, loss_freq: 0.024969
[04:02:02.198] iteration 8912: loss: 0.061610, loss_s1: 0.037404, loss_fp: 0.001479, loss_freq: 0.017291
[04:02:02.797] iteration 8913: loss: 0.094778, loss_s1: 0.056456, loss_fp: 0.002679, loss_freq: 0.048221
[04:02:03.394] iteration 8914: loss: 0.113155, loss_s1: 0.065983, loss_fp: 0.028193, loss_freq: 0.065411
[04:02:03.989] iteration 8915: loss: 0.106100, loss_s1: 0.037116, loss_fp: 0.003907, loss_freq: 0.043125
[04:02:04.582] iteration 8916: loss: 0.087548, loss_s1: 0.049217, loss_fp: 0.003441, loss_freq: 0.041357
[04:02:05.410] iteration 8917: loss: 0.082121, loss_s1: 0.051980, loss_fp: 0.003125, loss_freq: 0.029080
[04:02:06.276] iteration 8918: loss: 0.114490, loss_s1: 0.093085, loss_fp: 0.003643, loss_freq: 0.062731
[04:02:07.100] iteration 8919: loss: 0.101520, loss_s1: 0.083668, loss_fp: 0.005123, loss_freq: 0.037505
[04:02:07.814] iteration 8920: loss: 0.117399, loss_s1: 0.117194, loss_fp: 0.025249, loss_freq: 0.028382
[04:02:08.441] iteration 8921: loss: 0.108984, loss_s1: 0.089936, loss_fp: 0.003689, loss_freq: 0.056416
[04:02:09.049] iteration 8922: loss: 0.096746, loss_s1: 0.086383, loss_fp: 0.001650, loss_freq: 0.057708
[04:02:09.644] iteration 8923: loss: 0.123478, loss_s1: 0.131874, loss_fp: 0.000835, loss_freq: 0.050076
[04:02:10.237] iteration 8924: loss: 0.065639, loss_s1: 0.044701, loss_fp: 0.004377, loss_freq: 0.028347
[04:02:10.831] iteration 8925: loss: 0.133479, loss_s1: 0.131283, loss_fp: 0.001340, loss_freq: 0.030850
[04:02:11.433] iteration 8926: loss: 0.084784, loss_s1: 0.080975, loss_fp: 0.001363, loss_freq: 0.039840
[04:02:12.024] iteration 8927: loss: 0.093961, loss_s1: 0.072332, loss_fp: 0.003391, loss_freq: 0.072484
[04:02:12.631] iteration 8928: loss: 0.096777, loss_s1: 0.073432, loss_fp: 0.002714, loss_freq: 0.037142
[04:02:13.227] iteration 8929: loss: 0.113917, loss_s1: 0.109317, loss_fp: 0.005625, loss_freq: 0.059128
[04:02:13.821] iteration 8930: loss: 0.084041, loss_s1: 0.044500, loss_fp: 0.001862, loss_freq: 0.033746
[04:02:14.416] iteration 8931: loss: 0.107481, loss_s1: 0.124776, loss_fp: 0.001111, loss_freq: 0.043918
[04:02:15.011] iteration 8932: loss: 0.097023, loss_s1: 0.095290, loss_fp: 0.003735, loss_freq: 0.020278
[04:02:15.607] iteration 8933: loss: 0.103483, loss_s1: 0.060086, loss_fp: 0.005433, loss_freq: 0.057105
[04:02:16.199] iteration 8934: loss: 0.089655, loss_s1: 0.055687, loss_fp: 0.002555, loss_freq: 0.024448
[04:02:16.795] iteration 8935: loss: 0.101245, loss_s1: 0.066381, loss_fp: 0.005189, loss_freq: 0.054882
[04:02:17.391] iteration 8936: loss: 0.086188, loss_s1: 0.097776, loss_fp: 0.003555, loss_freq: 0.027668
[04:02:17.980] iteration 8937: loss: 0.131767, loss_s1: 0.068189, loss_fp: 0.006277, loss_freq: 0.086090
[04:02:18.579] iteration 8938: loss: 0.080470, loss_s1: 0.078623, loss_fp: 0.002114, loss_freq: 0.021789
[04:02:19.173] iteration 8939: loss: 0.083611, loss_s1: 0.086211, loss_fp: 0.002315, loss_freq: 0.025700
[04:02:19.768] iteration 8940: loss: 0.054179, loss_s1: 0.029906, loss_fp: 0.001366, loss_freq: 0.023046
[04:02:20.368] iteration 8941: loss: 0.084555, loss_s1: 0.089622, loss_fp: 0.003559, loss_freq: 0.031115
[04:02:20.962] iteration 8942: loss: 0.072809, loss_s1: 0.048391, loss_fp: 0.008791, loss_freq: 0.014178
[04:02:21.607] iteration 8943: loss: 0.067639, loss_s1: 0.039794, loss_fp: 0.002327, loss_freq: 0.025547
[04:02:22.211] iteration 8944: loss: 0.072426, loss_s1: 0.022147, loss_fp: 0.003496, loss_freq: 0.035943
[04:02:22.812] iteration 8945: loss: 0.063170, loss_s1: 0.026529, loss_fp: 0.006744, loss_freq: 0.044746
[04:02:23.408] iteration 8946: loss: 0.094938, loss_s1: 0.076059, loss_fp: 0.003148, loss_freq: 0.046243
[04:02:24.042] iteration 8947: loss: 0.093747, loss_s1: 0.046241, loss_fp: 0.002058, loss_freq: 0.040595
[04:02:24.646] iteration 8948: loss: 0.066217, loss_s1: 0.037924, loss_fp: 0.002649, loss_freq: 0.027337
[04:02:25.252] iteration 8949: loss: 0.088160, loss_s1: 0.075667, loss_fp: 0.004230, loss_freq: 0.046905
[04:02:25.855] iteration 8950: loss: 0.054504, loss_s1: 0.028613, loss_fp: 0.002859, loss_freq: 0.022579
[04:02:26.474] iteration 8951: loss: 0.064491, loss_s1: 0.044594, loss_fp: 0.004994, loss_freq: 0.027750
[04:02:27.116] iteration 8952: loss: 0.066835, loss_s1: 0.034153, loss_fp: 0.001373, loss_freq: 0.028293
[04:02:27.762] iteration 8953: loss: 0.069947, loss_s1: 0.055739, loss_fp: 0.002682, loss_freq: 0.026680
[04:02:28.367] iteration 8954: loss: 0.059461, loss_s1: 0.031331, loss_fp: 0.001777, loss_freq: 0.047057
[04:02:28.969] iteration 8955: loss: 0.139372, loss_s1: 0.113973, loss_fp: 0.002610, loss_freq: 0.074127
[04:02:29.560] iteration 8956: loss: 0.117192, loss_s1: 0.107932, loss_fp: 0.003353, loss_freq: 0.056203
[04:02:30.162] iteration 8957: loss: 0.081542, loss_s1: 0.076935, loss_fp: 0.002573, loss_freq: 0.034234
[04:02:30.788] iteration 8958: loss: 0.081983, loss_s1: 0.068184, loss_fp: 0.003313, loss_freq: 0.031445
[04:02:31.423] iteration 8959: loss: 0.089264, loss_s1: 0.051214, loss_fp: 0.001788, loss_freq: 0.061575
[04:02:32.072] iteration 8960: loss: 0.083685, loss_s1: 0.020048, loss_fp: 0.004368, loss_freq: 0.058680
[04:02:32.712] iteration 8961: loss: 0.083606, loss_s1: 0.098061, loss_fp: 0.000221, loss_freq: 0.009809
[04:02:33.342] iteration 8962: loss: 0.069363, loss_s1: 0.078432, loss_fp: 0.002424, loss_freq: 0.024752
[04:02:33.931] iteration 8963: loss: 0.096357, loss_s1: 0.099543, loss_fp: 0.008398, loss_freq: 0.024632
[04:02:34.520] iteration 8964: loss: 0.079813, loss_s1: 0.055424, loss_fp: 0.000852, loss_freq: 0.050809
[04:02:35.119] iteration 8965: loss: 0.109876, loss_s1: 0.112656, loss_fp: 0.005962, loss_freq: 0.033833
[04:02:35.745] iteration 8966: loss: 0.087328, loss_s1: 0.097149, loss_fp: 0.002749, loss_freq: 0.017114
[04:02:36.373] iteration 8967: loss: 0.135285, loss_s1: 0.117925, loss_fp: 0.001065, loss_freq: 0.088740
[04:02:37.004] iteration 8968: loss: 0.141355, loss_s1: 0.039836, loss_fp: 0.002370, loss_freq: 0.145501
[04:02:37.641] iteration 8969: loss: 0.069818, loss_s1: 0.069239, loss_fp: 0.002710, loss_freq: 0.019243
[04:02:38.276] iteration 8970: loss: 0.110469, loss_s1: 0.062927, loss_fp: 0.001695, loss_freq: 0.084693
[04:02:38.869] iteration 8971: loss: 0.076491, loss_s1: 0.061337, loss_fp: 0.010186, loss_freq: 0.040750
[04:02:39.460] iteration 8972: loss: 0.076058, loss_s1: 0.055103, loss_fp: 0.004051, loss_freq: 0.008575
[04:02:40.064] iteration 8973: loss: 0.081354, loss_s1: 0.057205, loss_fp: 0.000447, loss_freq: 0.041129
[04:02:40.669] iteration 8974: loss: 0.106276, loss_s1: 0.090309, loss_fp: 0.009150, loss_freq: 0.058217
[04:02:41.304] iteration 8975: loss: 0.061458, loss_s1: 0.040534, loss_fp: 0.002077, loss_freq: 0.023089
[04:02:41.932] iteration 8976: loss: 0.060156, loss_s1: 0.052364, loss_fp: 0.001455, loss_freq: 0.015045
[04:02:42.563] iteration 8977: loss: 0.063247, loss_s1: 0.034277, loss_fp: 0.003348, loss_freq: 0.009942
[04:02:43.172] iteration 8978: loss: 0.093239, loss_s1: 0.043442, loss_fp: 0.009585, loss_freq: 0.031357
[04:02:43.777] iteration 8979: loss: 0.083605, loss_s1: 0.068471, loss_fp: 0.002404, loss_freq: 0.047039
[04:02:44.373] iteration 8980: loss: 0.112428, loss_s1: 0.101400, loss_fp: 0.007399, loss_freq: 0.079656
[04:02:44.972] iteration 8981: loss: 0.088957, loss_s1: 0.057857, loss_fp: 0.009208, loss_freq: 0.040628
[04:02:45.574] iteration 8982: loss: 0.077504, loss_s1: 0.054741, loss_fp: 0.006450, loss_freq: 0.036965
[04:02:46.174] iteration 8983: loss: 0.088453, loss_s1: 0.068126, loss_fp: 0.008044, loss_freq: 0.051716
[04:02:46.766] iteration 8984: loss: 0.062668, loss_s1: 0.038665, loss_fp: 0.010673, loss_freq: 0.012688
[04:02:47.364] iteration 8985: loss: 0.083133, loss_s1: 0.047624, loss_fp: 0.003951, loss_freq: 0.062829
[04:02:47.954] iteration 8986: loss: 0.085310, loss_s1: 0.070630, loss_fp: 0.002935, loss_freq: 0.023516
[04:02:48.548] iteration 8987: loss: 0.041811, loss_s1: 0.017551, loss_fp: 0.001581, loss_freq: 0.018290
[04:02:49.139] iteration 8988: loss: 0.152028, loss_s1: 0.161435, loss_fp: 0.004677, loss_freq: 0.081983
[04:02:49.727] iteration 8989: loss: 0.092962, loss_s1: 0.076913, loss_fp: 0.001212, loss_freq: 0.054578
[04:02:50.320] iteration 8990: loss: 0.116352, loss_s1: 0.101157, loss_fp: 0.004646, loss_freq: 0.029600
[04:02:50.909] iteration 8991: loss: 0.089744, loss_s1: 0.058679, loss_fp: 0.009576, loss_freq: 0.035781
[04:02:51.505] iteration 8992: loss: 0.141104, loss_s1: 0.111567, loss_fp: 0.001222, loss_freq: 0.106119
[04:02:52.103] iteration 8993: loss: 0.118562, loss_s1: 0.085497, loss_fp: 0.002764, loss_freq: 0.060867
[04:02:52.700] iteration 8994: loss: 0.091138, loss_s1: 0.058230, loss_fp: 0.001122, loss_freq: 0.014082
[04:02:53.302] iteration 8995: loss: 0.124266, loss_s1: 0.046392, loss_fp: 0.006280, loss_freq: 0.081294
[04:02:53.937] iteration 8996: loss: 0.061286, loss_s1: 0.043791, loss_fp: 0.001626, loss_freq: 0.020619
[04:02:54.537] iteration 8997: loss: 0.078601, loss_s1: 0.035395, loss_fp: 0.004744, loss_freq: 0.032667
[04:02:55.136] iteration 8998: loss: 0.149277, loss_s1: 0.063627, loss_fp: 0.002940, loss_freq: 0.109743
[04:02:55.733] iteration 8999: loss: 0.086008, loss_s1: 0.033142, loss_fp: 0.003042, loss_freq: 0.079427
[04:02:56.325] iteration 9000: loss: 0.128003, loss_s1: 0.138797, loss_fp: 0.002149, loss_freq: 0.036900
[04:02:59.774] iteration 9000 : mean_dice : 0.682765
[04:03:00.448] iteration 9001: loss: 0.056238, loss_s1: 0.044933, loss_fp: 0.004970, loss_freq: 0.008600
[04:03:01.138] iteration 9002: loss: 0.047503, loss_s1: 0.040807, loss_fp: 0.001930, loss_freq: 0.013560
[04:03:01.769] iteration 9003: loss: 0.078065, loss_s1: 0.053086, loss_fp: 0.003778, loss_freq: 0.022335
[04:03:02.397] iteration 9004: loss: 0.066572, loss_s1: 0.064922, loss_fp: 0.000951, loss_freq: 0.014833
[04:03:03.036] iteration 9005: loss: 0.047925, loss_s1: 0.021951, loss_fp: 0.001062, loss_freq: 0.023168
[04:03:03.666] iteration 9006: loss: 0.101882, loss_s1: 0.099607, loss_fp: 0.007513, loss_freq: 0.033111
[04:03:04.270] iteration 9007: loss: 0.057211, loss_s1: 0.007637, loss_fp: 0.002378, loss_freq: 0.034370
[04:03:04.867] iteration 9008: loss: 0.070170, loss_s1: 0.056925, loss_fp: 0.005274, loss_freq: 0.024028
[04:03:05.451] iteration 9009: loss: 0.092681, loss_s1: 0.065123, loss_fp: 0.003218, loss_freq: 0.059015
[04:03:06.039] iteration 9010: loss: 0.117544, loss_s1: 0.057379, loss_fp: 0.010955, loss_freq: 0.108405
[04:03:06.939] iteration 9011: loss: 0.054755, loss_s1: 0.034255, loss_fp: 0.001220, loss_freq: 0.010790
[04:03:07.574] iteration 9012: loss: 0.075609, loss_s1: 0.058054, loss_fp: 0.003042, loss_freq: 0.031933
[04:03:08.233] iteration 9013: loss: 0.061241, loss_s1: 0.043120, loss_fp: 0.003870, loss_freq: 0.028891
[04:03:08.860] iteration 9014: loss: 0.063842, loss_s1: 0.048315, loss_fp: 0.000962, loss_freq: 0.018530
[04:03:09.461] iteration 9015: loss: 0.094149, loss_s1: 0.084872, loss_fp: 0.005245, loss_freq: 0.043515
[04:03:10.050] iteration 9016: loss: 0.098567, loss_s1: 0.070347, loss_fp: 0.001192, loss_freq: 0.056558
[04:03:10.684] iteration 9017: loss: 0.083700, loss_s1: 0.065917, loss_fp: 0.001289, loss_freq: 0.024412
[04:03:11.278] iteration 9018: loss: 0.068573, loss_s1: 0.046534, loss_fp: 0.001510, loss_freq: 0.047549
[04:03:11.874] iteration 9019: loss: 0.058255, loss_s1: 0.043676, loss_fp: 0.005234, loss_freq: 0.032118
[04:03:12.476] iteration 9020: loss: 0.097377, loss_s1: 0.070221, loss_fp: 0.002025, loss_freq: 0.042831
[04:03:13.124] iteration 9021: loss: 0.086774, loss_s1: 0.059503, loss_fp: 0.002215, loss_freq: 0.053074
[04:03:13.761] iteration 9022: loss: 0.088944, loss_s1: 0.039982, loss_fp: 0.003189, loss_freq: 0.075555
[04:03:14.352] iteration 9023: loss: 0.075439, loss_s1: 0.066576, loss_fp: 0.003829, loss_freq: 0.016498
[04:03:14.949] iteration 9024: loss: 0.052476, loss_s1: 0.029407, loss_fp: 0.007450, loss_freq: 0.020124
[04:03:15.545] iteration 9025: loss: 0.070711, loss_s1: 0.045087, loss_fp: 0.000578, loss_freq: 0.026695
[04:03:16.152] iteration 9026: loss: 0.067737, loss_s1: 0.053071, loss_fp: 0.000655, loss_freq: 0.030427
[04:03:16.784] iteration 9027: loss: 0.125145, loss_s1: 0.175596, loss_fp: 0.002968, loss_freq: 0.037873
[04:03:17.416] iteration 9028: loss: 0.079666, loss_s1: 0.070263, loss_fp: 0.000998, loss_freq: 0.015391
[04:03:18.051] iteration 9029: loss: 0.064651, loss_s1: 0.052577, loss_fp: 0.002281, loss_freq: 0.033630
[04:03:18.660] iteration 9030: loss: 0.111791, loss_s1: 0.070415, loss_fp: 0.002385, loss_freq: 0.031349
[04:03:19.253] iteration 9031: loss: 0.084629, loss_s1: 0.073186, loss_fp: 0.003315, loss_freq: 0.031319
[04:03:19.852] iteration 9032: loss: 0.076346, loss_s1: 0.057130, loss_fp: 0.003661, loss_freq: 0.041264
[04:03:20.446] iteration 9033: loss: 0.094930, loss_s1: 0.086628, loss_fp: 0.003466, loss_freq: 0.030492
[04:03:21.045] iteration 9034: loss: 0.075939, loss_s1: 0.056766, loss_fp: 0.002788, loss_freq: 0.039821
[04:03:21.636] iteration 9035: loss: 0.111652, loss_s1: 0.101861, loss_fp: 0.007871, loss_freq: 0.033656
[04:03:22.247] iteration 9036: loss: 0.103218, loss_s1: 0.085884, loss_fp: 0.001621, loss_freq: 0.059027
[04:03:22.858] iteration 9037: loss: 0.069273, loss_s1: 0.025606, loss_fp: 0.004279, loss_freq: 0.025980
[04:03:23.478] iteration 9038: loss: 0.148486, loss_s1: 0.136743, loss_fp: 0.004176, loss_freq: 0.043809
[04:03:24.214] iteration 9039: loss: 0.082747, loss_s1: 0.042806, loss_fp: 0.006136, loss_freq: 0.056402
[04:03:25.089] iteration 9040: loss: 0.110926, loss_s1: 0.142033, loss_fp: 0.006528, loss_freq: 0.023447
[04:03:25.974] iteration 9041: loss: 0.072827, loss_s1: 0.057448, loss_fp: 0.002058, loss_freq: 0.048609
[04:03:26.589] iteration 9042: loss: 0.098614, loss_s1: 0.064998, loss_fp: 0.011456, loss_freq: 0.050319
[04:03:27.212] iteration 9043: loss: 0.127658, loss_s1: 0.142036, loss_fp: 0.003279, loss_freq: 0.051312
[04:03:27.985] iteration 9044: loss: 0.064088, loss_s1: 0.038373, loss_fp: 0.001722, loss_freq: 0.015662
[04:03:28.654] iteration 9045: loss: 0.059603, loss_s1: 0.063996, loss_fp: 0.000946, loss_freq: 0.012951
[04:03:29.372] iteration 9046: loss: 0.082823, loss_s1: 0.070560, loss_fp: 0.000824, loss_freq: 0.006284
[04:03:30.045] iteration 9047: loss: 0.067425, loss_s1: 0.032055, loss_fp: 0.002165, loss_freq: 0.046860
[04:03:30.784] iteration 9048: loss: 0.046943, loss_s1: 0.028574, loss_fp: 0.002805, loss_freq: 0.016837
[04:03:31.432] iteration 9049: loss: 0.114087, loss_s1: 0.099289, loss_fp: 0.001282, loss_freq: 0.055112
[04:03:32.189] iteration 9050: loss: 0.088231, loss_s1: 0.066785, loss_fp: 0.005354, loss_freq: 0.037244
[04:03:32.810] iteration 9051: loss: 0.132651, loss_s1: 0.113037, loss_fp: 0.000301, loss_freq: 0.106304
[04:03:33.564] iteration 9052: loss: 0.082832, loss_s1: 0.074260, loss_fp: 0.005022, loss_freq: 0.033140
[04:03:34.280] iteration 9053: loss: 0.110039, loss_s1: 0.121451, loss_fp: 0.007999, loss_freq: 0.041884
[04:03:34.942] iteration 9054: loss: 0.146960, loss_s1: 0.117991, loss_fp: 0.001644, loss_freq: 0.118781
[04:03:35.678] iteration 9055: loss: 0.059740, loss_s1: 0.056748, loss_fp: 0.001960, loss_freq: 0.011689
[04:03:36.299] iteration 9056: loss: 0.085033, loss_s1: 0.066719, loss_fp: 0.001991, loss_freq: 0.044571
[04:03:36.897] iteration 9057: loss: 0.083024, loss_s1: 0.070268, loss_fp: 0.001022, loss_freq: 0.032091
[04:03:37.502] iteration 9058: loss: 0.107571, loss_s1: 0.078376, loss_fp: 0.003996, loss_freq: 0.057199
[04:03:38.095] iteration 9059: loss: 0.056603, loss_s1: 0.029908, loss_fp: 0.002643, loss_freq: 0.028989
[04:03:38.691] iteration 9060: loss: 0.071432, loss_s1: 0.061066, loss_fp: 0.001262, loss_freq: 0.023159
[04:03:39.290] iteration 9061: loss: 0.095989, loss_s1: 0.080188, loss_fp: 0.006826, loss_freq: 0.037528
[04:03:39.884] iteration 9062: loss: 0.099463, loss_s1: 0.101327, loss_fp: 0.008460, loss_freq: 0.055435
[04:03:40.477] iteration 9063: loss: 0.081138, loss_s1: 0.039435, loss_fp: 0.001380, loss_freq: 0.061686
[04:03:41.073] iteration 9064: loss: 0.087017, loss_s1: 0.021704, loss_fp: 0.000662, loss_freq: 0.071794
[04:03:41.667] iteration 9065: loss: 0.093077, loss_s1: 0.056554, loss_fp: 0.005660, loss_freq: 0.062030
[04:03:42.261] iteration 9066: loss: 0.063644, loss_s1: 0.062759, loss_fp: 0.004532, loss_freq: 0.014818
[04:03:42.853] iteration 9067: loss: 0.062616, loss_s1: 0.063900, loss_fp: 0.005860, loss_freq: 0.020291
[04:03:43.452] iteration 9068: loss: 0.066656, loss_s1: 0.025331, loss_fp: 0.001696, loss_freq: 0.043572
[04:03:44.045] iteration 9069: loss: 0.087412, loss_s1: 0.045574, loss_fp: 0.001626, loss_freq: 0.051522
[04:03:44.635] iteration 9070: loss: 0.103022, loss_s1: 0.056415, loss_fp: 0.009118, loss_freq: 0.083887
[04:03:45.226] iteration 9071: loss: 0.068745, loss_s1: 0.059529, loss_fp: 0.004200, loss_freq: 0.016005
[04:03:45.816] iteration 9072: loss: 0.069350, loss_s1: 0.050328, loss_fp: 0.003084, loss_freq: 0.029821
[04:03:46.404] iteration 9073: loss: 0.071282, loss_s1: 0.071858, loss_fp: 0.001290, loss_freq: 0.006190
[04:03:46.993] iteration 9074: loss: 0.054550, loss_s1: 0.046645, loss_fp: 0.002335, loss_freq: 0.010740
[04:03:47.582] iteration 9075: loss: 0.085071, loss_s1: 0.060263, loss_fp: 0.002183, loss_freq: 0.023577
[04:03:48.170] iteration 9076: loss: 0.073916, loss_s1: 0.064948, loss_fp: 0.001796, loss_freq: 0.032287
[04:03:48.763] iteration 9077: loss: 0.065695, loss_s1: 0.058769, loss_fp: 0.001176, loss_freq: 0.013030
[04:03:49.387] iteration 9078: loss: 0.130003, loss_s1: 0.150771, loss_fp: 0.006829, loss_freq: 0.042400
[04:03:49.977] iteration 9079: loss: 0.059381, loss_s1: 0.030194, loss_fp: 0.003405, loss_freq: 0.017528
[04:03:50.567] iteration 9080: loss: 0.061303, loss_s1: 0.048134, loss_fp: 0.003171, loss_freq: 0.028241
[04:03:51.157] iteration 9081: loss: 0.104993, loss_s1: 0.085436, loss_fp: 0.004690, loss_freq: 0.049384
[04:03:51.747] iteration 9082: loss: 0.073174, loss_s1: 0.050354, loss_fp: 0.003919, loss_freq: 0.014798
[04:03:52.351] iteration 9083: loss: 0.065164, loss_s1: 0.043533, loss_fp: 0.005795, loss_freq: 0.021860
[04:03:52.949] iteration 9084: loss: 0.137041, loss_s1: 0.137233, loss_fp: 0.004646, loss_freq: 0.038312
[04:03:53.635] iteration 9085: loss: 0.114693, loss_s1: 0.035334, loss_fp: 0.005967, loss_freq: 0.077007
[04:03:54.513] iteration 9086: loss: 0.067326, loss_s1: 0.048991, loss_fp: 0.007707, loss_freq: 0.023972
[04:03:55.173] iteration 9087: loss: 0.052932, loss_s1: 0.039049, loss_fp: 0.005023, loss_freq: 0.017664
[04:03:55.821] iteration 9088: loss: 0.094458, loss_s1: 0.078557, loss_fp: 0.008533, loss_freq: 0.031204
[04:03:56.468] iteration 9089: loss: 0.095264, loss_s1: 0.105012, loss_fp: 0.003298, loss_freq: 0.044179
[04:03:57.057] iteration 9090: loss: 0.065091, loss_s1: 0.043391, loss_fp: 0.001683, loss_freq: 0.025298
[04:03:57.699] iteration 9091: loss: 0.109986, loss_s1: 0.078675, loss_fp: 0.002110, loss_freq: 0.049855
[04:03:58.330] iteration 9092: loss: 0.079353, loss_s1: 0.064150, loss_fp: 0.002376, loss_freq: 0.038906
[04:03:58.922] iteration 9093: loss: 0.092618, loss_s1: 0.110953, loss_fp: 0.002682, loss_freq: 0.021900
[04:03:59.513] iteration 9094: loss: 0.052154, loss_s1: 0.040758, loss_fp: 0.002063, loss_freq: 0.013942
[04:04:00.102] iteration 9095: loss: 0.091073, loss_s1: 0.087168, loss_fp: 0.007506, loss_freq: 0.035068
[04:04:00.696] iteration 9096: loss: 0.064296, loss_s1: 0.041753, loss_fp: 0.001382, loss_freq: 0.030285
[04:04:01.287] iteration 9097: loss: 0.107501, loss_s1: 0.092284, loss_fp: 0.002061, loss_freq: 0.077222
[04:04:01.878] iteration 9098: loss: 0.103740, loss_s1: 0.066961, loss_fp: 0.004849, loss_freq: 0.040487
[04:04:02.477] iteration 9099: loss: 0.086317, loss_s1: 0.051866, loss_fp: 0.015661, loss_freq: 0.054414
[04:04:03.072] iteration 9100: loss: 0.055455, loss_s1: 0.023404, loss_fp: 0.005668, loss_freq: 0.023813
[04:04:03.664] iteration 9101: loss: 0.072194, loss_s1: 0.065525, loss_fp: 0.009570, loss_freq: 0.023407
[04:04:04.259] iteration 9102: loss: 0.057850, loss_s1: 0.053272, loss_fp: 0.002810, loss_freq: 0.021354
[04:04:04.854] iteration 9103: loss: 0.082233, loss_s1: 0.039151, loss_fp: 0.001509, loss_freq: 0.060171
[04:04:05.451] iteration 9104: loss: 0.048412, loss_s1: 0.037873, loss_fp: 0.001870, loss_freq: 0.014986
[04:04:06.046] iteration 9105: loss: 0.055778, loss_s1: 0.037541, loss_fp: 0.001901, loss_freq: 0.029068
[04:04:06.635] iteration 9106: loss: 0.063620, loss_s1: 0.024037, loss_fp: 0.002264, loss_freq: 0.043084
[04:04:07.222] iteration 9107: loss: 0.074826, loss_s1: 0.047579, loss_fp: 0.002952, loss_freq: 0.037698
[04:04:07.814] iteration 9108: loss: 0.055024, loss_s1: 0.030928, loss_fp: 0.001749, loss_freq: 0.020183
[04:04:08.404] iteration 9109: loss: 0.081186, loss_s1: 0.039095, loss_fp: 0.002571, loss_freq: 0.050894
[04:04:09.000] iteration 9110: loss: 0.076161, loss_s1: 0.088078, loss_fp: 0.002093, loss_freq: 0.011505
[04:04:09.595] iteration 9111: loss: 0.084986, loss_s1: 0.100878, loss_fp: 0.001039, loss_freq: 0.032525
[04:04:10.194] iteration 9112: loss: 0.070500, loss_s1: 0.034627, loss_fp: 0.001666, loss_freq: 0.037564
[04:04:10.786] iteration 9113: loss: 0.076137, loss_s1: 0.069793, loss_fp: 0.001316, loss_freq: 0.032816
[04:04:11.377] iteration 9114: loss: 0.062181, loss_s1: 0.043634, loss_fp: 0.002845, loss_freq: 0.026852
[04:04:11.966] iteration 9115: loss: 0.075792, loss_s1: 0.054337, loss_fp: 0.000987, loss_freq: 0.047891
[04:04:12.567] iteration 9116: loss: 0.107144, loss_s1: 0.092628, loss_fp: 0.006458, loss_freq: 0.036281
[04:04:13.167] iteration 9117: loss: 0.095116, loss_s1: 0.056457, loss_fp: 0.011284, loss_freq: 0.068676
[04:04:13.763] iteration 9118: loss: 0.097122, loss_s1: 0.092749, loss_fp: 0.001610, loss_freq: 0.054574
[04:04:14.354] iteration 9119: loss: 0.074094, loss_s1: 0.037504, loss_fp: 0.004854, loss_freq: 0.043491
[04:04:14.949] iteration 9120: loss: 0.050044, loss_s1: 0.021676, loss_fp: 0.001533, loss_freq: 0.023946
[04:04:15.536] iteration 9121: loss: 0.062319, loss_s1: 0.039681, loss_fp: 0.001464, loss_freq: 0.017477
[04:04:16.125] iteration 9122: loss: 0.064357, loss_s1: 0.051242, loss_fp: 0.002755, loss_freq: 0.026274
[04:04:16.720] iteration 9123: loss: 0.068164, loss_s1: 0.071218, loss_fp: 0.001322, loss_freq: 0.012916
[04:04:17.309] iteration 9124: loss: 0.074290, loss_s1: 0.050421, loss_fp: 0.013351, loss_freq: 0.042101
[04:04:17.899] iteration 9125: loss: 0.075129, loss_s1: 0.040022, loss_fp: 0.001621, loss_freq: 0.041410
[04:04:18.533] iteration 9126: loss: 0.105419, loss_s1: 0.073956, loss_fp: 0.004099, loss_freq: 0.056836
[04:04:19.168] iteration 9127: loss: 0.089738, loss_s1: 0.084242, loss_fp: 0.004820, loss_freq: 0.047397
[04:04:19.801] iteration 9128: loss: 0.059478, loss_s1: 0.018691, loss_fp: 0.005571, loss_freq: 0.034090
[04:04:20.431] iteration 9129: loss: 0.117616, loss_s1: 0.056519, loss_fp: 0.001992, loss_freq: 0.128581
[04:04:21.061] iteration 9130: loss: 0.123808, loss_s1: 0.087666, loss_fp: 0.005251, loss_freq: 0.040545
[04:04:21.664] iteration 9131: loss: 0.053934, loss_s1: 0.039916, loss_fp: 0.006841, loss_freq: 0.012975
[04:04:22.262] iteration 9132: loss: 0.076385, loss_s1: 0.075826, loss_fp: 0.002431, loss_freq: 0.017576
[04:04:22.865] iteration 9133: loss: 0.092168, loss_s1: 0.068634, loss_fp: 0.002151, loss_freq: 0.060836
[04:04:23.465] iteration 9134: loss: 0.090513, loss_s1: 0.082182, loss_fp: 0.000786, loss_freq: 0.058635
[04:04:24.068] iteration 9135: loss: 0.133112, loss_s1: 0.090288, loss_fp: 0.006835, loss_freq: 0.085227
[04:04:24.663] iteration 9136: loss: 0.060708, loss_s1: 0.045127, loss_fp: 0.004131, loss_freq: 0.019735
[04:04:25.257] iteration 9137: loss: 0.105357, loss_s1: 0.070928, loss_fp: 0.006650, loss_freq: 0.072349
[04:04:25.854] iteration 9138: loss: 0.113509, loss_s1: 0.048942, loss_fp: 0.003321, loss_freq: 0.101263
[04:04:26.444] iteration 9139: loss: 0.055964, loss_s1: 0.037092, loss_fp: 0.004323, loss_freq: 0.030365
[04:04:27.043] iteration 9140: loss: 0.085548, loss_s1: 0.082786, loss_fp: 0.007944, loss_freq: 0.031415
[04:04:27.640] iteration 9141: loss: 0.067891, loss_s1: 0.050954, loss_fp: 0.002002, loss_freq: 0.018787
[04:04:28.237] iteration 9142: loss: 0.071886, loss_s1: 0.045035, loss_fp: 0.002893, loss_freq: 0.015334
[04:04:28.836] iteration 9143: loss: 0.124539, loss_s1: 0.085078, loss_fp: 0.001290, loss_freq: 0.067957
[04:04:29.430] iteration 9144: loss: 0.112140, loss_s1: 0.124374, loss_fp: 0.001563, loss_freq: 0.040112
[04:04:30.023] iteration 9145: loss: 0.100621, loss_s1: 0.072150, loss_fp: 0.003885, loss_freq: 0.077996
[04:04:30.617] iteration 9146: loss: 0.062330, loss_s1: 0.039749, loss_fp: 0.001199, loss_freq: 0.013960
[04:04:31.215] iteration 9147: loss: 0.077774, loss_s1: 0.065952, loss_fp: 0.003149, loss_freq: 0.015951
[04:04:31.808] iteration 9148: loss: 0.066882, loss_s1: 0.032716, loss_fp: 0.000991, loss_freq: 0.057458
[04:04:32.408] iteration 9149: loss: 0.113091, loss_s1: 0.098020, loss_fp: 0.008987, loss_freq: 0.058057
[04:04:33.010] iteration 9150: loss: 0.068070, loss_s1: 0.046723, loss_fp: 0.006441, loss_freq: 0.032201
[04:04:33.612] iteration 9151: loss: 0.091719, loss_s1: 0.068431, loss_fp: 0.002983, loss_freq: 0.049415
[04:04:34.227] iteration 9152: loss: 0.103073, loss_s1: 0.058372, loss_fp: 0.003875, loss_freq: 0.082488
[04:04:34.831] iteration 9153: loss: 0.089610, loss_s1: 0.081280, loss_fp: 0.003368, loss_freq: 0.044356
[04:04:35.429] iteration 9154: loss: 0.105802, loss_s1: 0.070622, loss_fp: 0.003266, loss_freq: 0.031672
[04:04:36.018] iteration 9155: loss: 0.069032, loss_s1: 0.052543, loss_fp: 0.001716, loss_freq: 0.040820
[04:04:36.651] iteration 9156: loss: 0.070778, loss_s1: 0.055279, loss_fp: 0.004982, loss_freq: 0.032095
[04:04:37.284] iteration 9157: loss: 0.070310, loss_s1: 0.056949, loss_fp: 0.006305, loss_freq: 0.031422
[04:04:37.914] iteration 9158: loss: 0.098599, loss_s1: 0.059506, loss_fp: 0.006434, loss_freq: 0.068638
[04:04:38.525] iteration 9159: loss: 0.062398, loss_s1: 0.052434, loss_fp: 0.006917, loss_freq: 0.027182
[04:04:39.122] iteration 9160: loss: 0.114992, loss_s1: 0.108660, loss_fp: 0.004228, loss_freq: 0.042030
[04:04:39.718] iteration 9161: loss: 0.065165, loss_s1: 0.039788, loss_fp: 0.007491, loss_freq: 0.021459
[04:04:40.320] iteration 9162: loss: 0.132169, loss_s1: 0.117879, loss_fp: 0.010065, loss_freq: 0.082068
[04:04:40.913] iteration 9163: loss: 0.100484, loss_s1: 0.088866, loss_fp: 0.004934, loss_freq: 0.047270
[04:04:41.514] iteration 9164: loss: 0.080772, loss_s1: 0.046544, loss_fp: 0.010771, loss_freq: 0.037896
[04:04:42.147] iteration 9165: loss: 0.091518, loss_s1: 0.065265, loss_fp: 0.003389, loss_freq: 0.060854
[04:04:42.755] iteration 9166: loss: 0.074969, loss_s1: 0.078734, loss_fp: 0.001234, loss_freq: 0.023816
[04:04:43.346] iteration 9167: loss: 0.107845, loss_s1: 0.042360, loss_fp: 0.002649, loss_freq: 0.095393
[04:04:43.940] iteration 9168: loss: 0.162192, loss_s1: 0.100734, loss_fp: 0.009496, loss_freq: 0.087709
[04:04:44.532] iteration 9169: loss: 0.091670, loss_s1: 0.100958, loss_fp: 0.003717, loss_freq: 0.029020
[04:04:45.126] iteration 9170: loss: 0.080668, loss_s1: 0.051293, loss_fp: 0.007842, loss_freq: 0.021972
[04:04:45.712] iteration 9171: loss: 0.053830, loss_s1: 0.040397, loss_fp: 0.001175, loss_freq: 0.013497
[04:04:46.377] iteration 9172: loss: 0.082636, loss_s1: 0.074586, loss_fp: 0.004291, loss_freq: 0.040800
[04:04:47.007] iteration 9173: loss: 0.073235, loss_s1: 0.044483, loss_fp: 0.002849, loss_freq: 0.033674
[04:04:47.645] iteration 9174: loss: 0.066268, loss_s1: 0.035772, loss_fp: 0.003834, loss_freq: 0.034147
[04:04:48.250] iteration 9175: loss: 0.050968, loss_s1: 0.027965, loss_fp: 0.001588, loss_freq: 0.016242
[04:04:48.842] iteration 9176: loss: 0.086782, loss_s1: 0.085591, loss_fp: 0.002898, loss_freq: 0.030662
[04:04:49.427] iteration 9177: loss: 0.075637, loss_s1: 0.025379, loss_fp: 0.000451, loss_freq: 0.031382
[04:04:50.014] iteration 9178: loss: 0.090566, loss_s1: 0.060688, loss_fp: 0.002595, loss_freq: 0.043356
[04:04:50.600] iteration 9179: loss: 0.118516, loss_s1: 0.115347, loss_fp: 0.003514, loss_freq: 0.067563
[04:04:51.186] iteration 9180: loss: 0.100526, loss_s1: 0.099061, loss_fp: 0.001212, loss_freq: 0.042206
[04:04:52.120] iteration 9181: loss: 0.078184, loss_s1: 0.086218, loss_fp: 0.001227, loss_freq: 0.013444
[04:04:52.750] iteration 9182: loss: 0.082013, loss_s1: 0.046741, loss_fp: 0.000675, loss_freq: 0.046698
[04:04:53.383] iteration 9183: loss: 0.096176, loss_s1: 0.074667, loss_fp: 0.016904, loss_freq: 0.048517
[04:04:54.005] iteration 9184: loss: 0.063759, loss_s1: 0.042284, loss_fp: 0.000827, loss_freq: 0.017107
[04:04:54.600] iteration 9185: loss: 0.081809, loss_s1: 0.098318, loss_fp: 0.002873, loss_freq: 0.018998
[04:04:55.203] iteration 9186: loss: 0.103482, loss_s1: 0.068685, loss_fp: 0.003465, loss_freq: 0.064651
[04:04:55.797] iteration 9187: loss: 0.072095, loss_s1: 0.061447, loss_fp: 0.001149, loss_freq: 0.028735
[04:04:56.453] iteration 9188: loss: 0.081921, loss_s1: 0.068176, loss_fp: 0.002404, loss_freq: 0.027481
[04:04:57.111] iteration 9189: loss: 0.053091, loss_s1: 0.027778, loss_fp: 0.002680, loss_freq: 0.027105
[04:04:57.754] iteration 9190: loss: 0.085087, loss_s1: 0.039827, loss_fp: 0.005574, loss_freq: 0.053759
[04:04:58.383] iteration 9191: loss: 0.066276, loss_s1: 0.019810, loss_fp: 0.003927, loss_freq: 0.054023
[04:04:59.020] iteration 9192: loss: 0.094572, loss_s1: 0.058145, loss_fp: 0.002906, loss_freq: 0.072617
[04:04:59.651] iteration 9193: loss: 0.089576, loss_s1: 0.087823, loss_fp: 0.005784, loss_freq: 0.031895
[04:05:00.285] iteration 9194: loss: 0.065883, loss_s1: 0.041853, loss_fp: 0.002020, loss_freq: 0.017575
[04:05:00.897] iteration 9195: loss: 0.079210, loss_s1: 0.033564, loss_fp: 0.004307, loss_freq: 0.031793
[04:05:01.494] iteration 9196: loss: 0.086735, loss_s1: 0.060255, loss_fp: 0.002510, loss_freq: 0.058059
[04:05:02.093] iteration 9197: loss: 0.152624, loss_s1: 0.145431, loss_fp: 0.004733, loss_freq: 0.104997
[04:05:02.696] iteration 9198: loss: 0.074931, loss_s1: 0.050774, loss_fp: 0.001870, loss_freq: 0.017148
[04:05:03.297] iteration 9199: loss: 0.078566, loss_s1: 0.069198, loss_fp: 0.004253, loss_freq: 0.044944
[04:05:03.887] iteration 9200: loss: 0.077844, loss_s1: 0.073037, loss_fp: 0.000484, loss_freq: 0.022194
[04:05:07.342] iteration 9200 : mean_dice : 0.708198
[04:05:07.966] iteration 9201: loss: 0.080412, loss_s1: 0.048289, loss_fp: 0.002891, loss_freq: 0.016112
[04:05:08.560] iteration 9202: loss: 0.102625, loss_s1: 0.058675, loss_fp: 0.002250, loss_freq: 0.042569
[04:05:09.152] iteration 9203: loss: 0.089256, loss_s1: 0.064711, loss_fp: 0.002969, loss_freq: 0.057246
[04:05:09.741] iteration 9204: loss: 0.083150, loss_s1: 0.039198, loss_fp: 0.001363, loss_freq: 0.049901
[04:05:10.332] iteration 9205: loss: 0.084784, loss_s1: 0.078051, loss_fp: 0.001457, loss_freq: 0.029421
[04:05:10.930] iteration 9206: loss: 0.106611, loss_s1: 0.063490, loss_fp: 0.016677, loss_freq: 0.041282
[04:05:11.528] iteration 9207: loss: 0.091318, loss_s1: 0.052712, loss_fp: 0.004592, loss_freq: 0.030780
[04:05:12.117] iteration 9208: loss: 0.108383, loss_s1: 0.119479, loss_fp: 0.003553, loss_freq: 0.016782
[04:05:12.772] iteration 9209: loss: 0.076943, loss_s1: 0.029404, loss_fp: 0.001350, loss_freq: 0.051398
[04:05:13.418] iteration 9210: loss: 0.125404, loss_s1: 0.123076, loss_fp: 0.003920, loss_freq: 0.066292
[04:05:14.069] iteration 9211: loss: 0.102278, loss_s1: 0.098699, loss_fp: 0.003326, loss_freq: 0.052285
[04:05:14.713] iteration 9212: loss: 0.081577, loss_s1: 0.068999, loss_fp: 0.001276, loss_freq: 0.033277
[04:05:15.327] iteration 9213: loss: 0.095362, loss_s1: 0.063533, loss_fp: 0.003979, loss_freq: 0.062924
[04:05:15.945] iteration 9214: loss: 0.054847, loss_s1: 0.029913, loss_fp: 0.009888, loss_freq: 0.010446
[04:05:16.537] iteration 9215: loss: 0.083250, loss_s1: 0.075190, loss_fp: 0.001259, loss_freq: 0.041672
[04:05:17.133] iteration 9216: loss: 0.065095, loss_s1: 0.026511, loss_fp: 0.001047, loss_freq: 0.022222
[04:05:17.722] iteration 9217: loss: 0.081687, loss_s1: 0.057486, loss_fp: 0.001355, loss_freq: 0.028530
[04:05:18.335] iteration 9218: loss: 0.060787, loss_s1: 0.042526, loss_fp: 0.008795, loss_freq: 0.031064
[04:05:18.947] iteration 9219: loss: 0.132369, loss_s1: 0.096095, loss_fp: 0.008594, loss_freq: 0.039054
[04:05:19.554] iteration 9220: loss: 0.082088, loss_s1: 0.055421, loss_fp: 0.001486, loss_freq: 0.039359
[04:05:20.218] iteration 9221: loss: 0.111039, loss_s1: 0.103083, loss_fp: 0.001032, loss_freq: 0.046061
[04:05:20.869] iteration 9222: loss: 0.109132, loss_s1: 0.100815, loss_fp: 0.004146, loss_freq: 0.050323
[04:05:21.520] iteration 9223: loss: 0.094640, loss_s1: 0.061781, loss_fp: 0.004270, loss_freq: 0.078060
[04:05:22.173] iteration 9224: loss: 0.121265, loss_s1: 0.126148, loss_fp: 0.003432, loss_freq: 0.060362
[04:05:22.787] iteration 9225: loss: 0.082945, loss_s1: 0.052100, loss_fp: 0.001549, loss_freq: 0.015660
[04:05:23.380] iteration 9226: loss: 0.077125, loss_s1: 0.057668, loss_fp: 0.003324, loss_freq: 0.018008
[04:05:23.970] iteration 9227: loss: 0.074395, loss_s1: 0.077858, loss_fp: 0.001183, loss_freq: 0.015361
[04:05:24.559] iteration 9228: loss: 0.070511, loss_s1: 0.055378, loss_fp: 0.004239, loss_freq: 0.044888
[04:05:25.151] iteration 9229: loss: 0.056811, loss_s1: 0.025359, loss_fp: 0.005048, loss_freq: 0.019933
[04:05:25.745] iteration 9230: loss: 0.064674, loss_s1: 0.027204, loss_fp: 0.003357, loss_freq: 0.028626
[04:05:26.339] iteration 9231: loss: 0.063634, loss_s1: 0.045567, loss_fp: 0.001384, loss_freq: 0.025982
[04:05:26.929] iteration 9232: loss: 0.092671, loss_s1: 0.086226, loss_fp: 0.002496, loss_freq: 0.054887
[04:05:27.521] iteration 9233: loss: 0.067990, loss_s1: 0.020538, loss_fp: 0.003707, loss_freq: 0.034950
[04:05:28.277] iteration 9234: loss: 0.109493, loss_s1: 0.092549, loss_fp: 0.001392, loss_freq: 0.069659
[04:05:28.884] iteration 9235: loss: 0.098786, loss_s1: 0.058268, loss_fp: 0.004365, loss_freq: 0.052186
[04:05:29.482] iteration 9236: loss: 0.108992, loss_s1: 0.053754, loss_fp: 0.008050, loss_freq: 0.019469
[04:05:30.080] iteration 9237: loss: 0.073364, loss_s1: 0.055251, loss_fp: 0.001553, loss_freq: 0.027150
[04:05:30.695] iteration 9238: loss: 0.063307, loss_s1: 0.034083, loss_fp: 0.003276, loss_freq: 0.020929
[04:05:31.284] iteration 9239: loss: 0.087638, loss_s1: 0.092404, loss_fp: 0.005240, loss_freq: 0.035656
[04:05:31.881] iteration 9240: loss: 0.095184, loss_s1: 0.056692, loss_fp: 0.010299, loss_freq: 0.073063
[04:05:32.471] iteration 9241: loss: 0.063157, loss_s1: 0.072220, loss_fp: 0.001668, loss_freq: 0.011063
[04:05:33.071] iteration 9242: loss: 0.099259, loss_s1: 0.064494, loss_fp: 0.002721, loss_freq: 0.052481
[04:05:33.661] iteration 9243: loss: 0.063057, loss_s1: 0.031529, loss_fp: 0.001365, loss_freq: 0.012235
[04:05:34.303] iteration 9244: loss: 0.049195, loss_s1: 0.022155, loss_fp: 0.001956, loss_freq: 0.027197
[04:05:34.900] iteration 9245: loss: 0.080050, loss_s1: 0.032800, loss_fp: 0.001873, loss_freq: 0.023498
[04:05:35.491] iteration 9246: loss: 0.071344, loss_s1: 0.071074, loss_fp: 0.005311, loss_freq: 0.024668
[04:05:36.089] iteration 9247: loss: 0.118843, loss_s1: 0.103268, loss_fp: 0.003434, loss_freq: 0.013531
[04:05:36.683] iteration 9248: loss: 0.099009, loss_s1: 0.085014, loss_fp: 0.010474, loss_freq: 0.033628
[04:05:37.274] iteration 9249: loss: 0.056992, loss_s1: 0.013305, loss_fp: 0.003921, loss_freq: 0.039517
[04:05:37.865] iteration 9250: loss: 0.092428, loss_s1: 0.070468, loss_fp: 0.005396, loss_freq: 0.048706
[04:05:38.460] iteration 9251: loss: 0.079159, loss_s1: 0.047455, loss_fp: 0.002066, loss_freq: 0.036590
[04:05:39.053] iteration 9252: loss: 0.061212, loss_s1: 0.034483, loss_fp: 0.003383, loss_freq: 0.021379
[04:05:39.651] iteration 9253: loss: 0.076474, loss_s1: 0.048572, loss_fp: 0.005736, loss_freq: 0.045592
[04:05:40.249] iteration 9254: loss: 0.090753, loss_s1: 0.070077, loss_fp: 0.006359, loss_freq: 0.041048
[04:05:40.846] iteration 9255: loss: 0.095906, loss_s1: 0.045285, loss_fp: 0.011376, loss_freq: 0.059188
[04:05:41.436] iteration 9256: loss: 0.071595, loss_s1: 0.035944, loss_fp: 0.005088, loss_freq: 0.035310
[04:05:42.028] iteration 9257: loss: 0.083826, loss_s1: 0.065643, loss_fp: 0.001902, loss_freq: 0.031653
[04:05:42.619] iteration 9258: loss: 0.102820, loss_s1: 0.088790, loss_fp: 0.009276, loss_freq: 0.046121
[04:05:43.209] iteration 9259: loss: 0.079843, loss_s1: 0.073914, loss_fp: 0.006138, loss_freq: 0.045063
[04:05:43.799] iteration 9260: loss: 0.081438, loss_s1: 0.058769, loss_fp: 0.002349, loss_freq: 0.030377
[04:05:44.387] iteration 9261: loss: 0.126177, loss_s1: 0.110486, loss_fp: 0.005615, loss_freq: 0.059338
[04:05:44.977] iteration 9262: loss: 0.070923, loss_s1: 0.050902, loss_fp: 0.001541, loss_freq: 0.048796
[04:05:45.566] iteration 9263: loss: 0.098649, loss_s1: 0.114307, loss_fp: 0.003301, loss_freq: 0.036760
[04:05:46.190] iteration 9264: loss: 0.080499, loss_s1: 0.071295, loss_fp: 0.009917, loss_freq: 0.017869
[04:05:46.776] iteration 9265: loss: 0.063713, loss_s1: 0.049585, loss_fp: 0.001803, loss_freq: 0.023441
[04:05:47.370] iteration 9266: loss: 0.069593, loss_s1: 0.061413, loss_fp: 0.003110, loss_freq: 0.023164
[04:05:47.959] iteration 9267: loss: 0.066876, loss_s1: 0.053364, loss_fp: 0.003983, loss_freq: 0.032464
[04:05:48.549] iteration 9268: loss: 0.078985, loss_s1: 0.053986, loss_fp: 0.001331, loss_freq: 0.019217
[04:05:49.141] iteration 9269: loss: 0.111569, loss_s1: 0.122363, loss_fp: 0.009038, loss_freq: 0.032641
[04:05:49.733] iteration 9270: loss: 0.093732, loss_s1: 0.083100, loss_fp: 0.001648, loss_freq: 0.028525
[04:05:50.321] iteration 9271: loss: 0.085744, loss_s1: 0.072668, loss_fp: 0.010935, loss_freq: 0.040765
[04:05:50.918] iteration 9272: loss: 0.079481, loss_s1: 0.062103, loss_fp: 0.014421, loss_freq: 0.035608
[04:05:51.514] iteration 9273: loss: 0.102097, loss_s1: 0.075550, loss_fp: 0.015680, loss_freq: 0.043021
[04:05:52.108] iteration 9274: loss: 0.068091, loss_s1: 0.046655, loss_fp: 0.001036, loss_freq: 0.021634
[04:05:52.700] iteration 9275: loss: 0.058530, loss_s1: 0.051065, loss_fp: 0.002866, loss_freq: 0.014796
[04:05:53.289] iteration 9276: loss: 0.086764, loss_s1: 0.081158, loss_fp: 0.001148, loss_freq: 0.034901
[04:05:53.879] iteration 9277: loss: 0.091362, loss_s1: 0.064851, loss_fp: 0.003903, loss_freq: 0.054509
[04:05:54.473] iteration 9278: loss: 0.071530, loss_s1: 0.046038, loss_fp: 0.003416, loss_freq: 0.036098
[04:05:55.068] iteration 9279: loss: 0.110805, loss_s1: 0.107693, loss_fp: 0.004815, loss_freq: 0.035621
[04:05:55.663] iteration 9280: loss: 0.074004, loss_s1: 0.068325, loss_fp: 0.001459, loss_freq: 0.022298
[04:05:56.293] iteration 9281: loss: 0.117360, loss_s1: 0.126926, loss_fp: 0.002360, loss_freq: 0.037390
[04:05:56.925] iteration 9282: loss: 0.067352, loss_s1: 0.050922, loss_fp: 0.003102, loss_freq: 0.017671
[04:05:57.552] iteration 9283: loss: 0.078766, loss_s1: 0.052205, loss_fp: 0.003461, loss_freq: 0.031789
[04:05:58.141] iteration 9284: loss: 0.070252, loss_s1: 0.025388, loss_fp: 0.001134, loss_freq: 0.025106
[04:05:58.727] iteration 9285: loss: 0.056990, loss_s1: 0.027764, loss_fp: 0.001229, loss_freq: 0.048108
[04:05:59.356] iteration 9286: loss: 0.086371, loss_s1: 0.079056, loss_fp: 0.001951, loss_freq: 0.034777
[04:05:59.985] iteration 9287: loss: 0.061238, loss_s1: 0.017753, loss_fp: 0.003920, loss_freq: 0.022648
[04:06:00.585] iteration 9288: loss: 0.065086, loss_s1: 0.035255, loss_fp: 0.001706, loss_freq: 0.031636
[04:06:01.171] iteration 9289: loss: 0.085185, loss_s1: 0.034115, loss_fp: 0.015854, loss_freq: 0.065883
[04:06:01.764] iteration 9290: loss: 0.062277, loss_s1: 0.046858, loss_fp: 0.007866, loss_freq: 0.022345
[04:06:02.361] iteration 9291: loss: 0.059972, loss_s1: 0.052177, loss_fp: 0.001392, loss_freq: 0.012748
[04:06:02.951] iteration 9292: loss: 0.115568, loss_s1: 0.038299, loss_fp: 0.004678, loss_freq: 0.037502
[04:06:03.551] iteration 9293: loss: 0.082811, loss_s1: 0.046271, loss_fp: 0.003173, loss_freq: 0.038284
[04:06:04.148] iteration 9294: loss: 0.067983, loss_s1: 0.053874, loss_fp: 0.003058, loss_freq: 0.023298
[04:06:04.745] iteration 9295: loss: 0.129729, loss_s1: 0.106642, loss_fp: 0.026074, loss_freq: 0.069747
[04:06:05.338] iteration 9296: loss: 0.072976, loss_s1: 0.071030, loss_fp: 0.003315, loss_freq: 0.020011
[04:06:05.935] iteration 9297: loss: 0.075165, loss_s1: 0.049594, loss_fp: 0.003882, loss_freq: 0.049955
[04:06:06.525] iteration 9298: loss: 0.085447, loss_s1: 0.071763, loss_fp: 0.009931, loss_freq: 0.042961
[04:06:07.114] iteration 9299: loss: 0.116837, loss_s1: 0.084322, loss_fp: 0.002968, loss_freq: 0.097475
[04:06:07.707] iteration 9300: loss: 0.059514, loss_s1: 0.045494, loss_fp: 0.001194, loss_freq: 0.017834
[04:06:08.322] iteration 9301: loss: 0.052677, loss_s1: 0.052623, loss_fp: 0.001739, loss_freq: 0.009389
[04:06:08.911] iteration 9302: loss: 0.091089, loss_s1: 0.078711, loss_fp: 0.001788, loss_freq: 0.042826
[04:06:09.499] iteration 9303: loss: 0.078223, loss_s1: 0.044777, loss_fp: 0.003871, loss_freq: 0.054540
[04:06:10.097] iteration 9304: loss: 0.051977, loss_s1: 0.018634, loss_fp: 0.002266, loss_freq: 0.040331
[04:06:10.698] iteration 9305: loss: 0.107613, loss_s1: 0.072784, loss_fp: 0.007703, loss_freq: 0.049636
[04:06:11.292] iteration 9306: loss: 0.088708, loss_s1: 0.098364, loss_fp: 0.004277, loss_freq: 0.027406
[04:06:11.972] iteration 9307: loss: 0.111862, loss_s1: 0.073026, loss_fp: 0.003853, loss_freq: 0.102299
[04:06:12.616] iteration 9308: loss: 0.093899, loss_s1: 0.031379, loss_fp: 0.004266, loss_freq: 0.041979
[04:06:13.259] iteration 9309: loss: 0.062370, loss_s1: 0.041030, loss_fp: 0.008666, loss_freq: 0.019498
[04:06:13.899] iteration 9310: loss: 0.057577, loss_s1: 0.053929, loss_fp: 0.001379, loss_freq: 0.019344
[04:06:14.548] iteration 9311: loss: 0.083713, loss_s1: 0.038429, loss_fp: 0.009895, loss_freq: 0.074370
[04:06:15.193] iteration 9312: loss: 0.084048, loss_s1: 0.037223, loss_fp: 0.004169, loss_freq: 0.012875
[04:06:15.829] iteration 9313: loss: 0.063125, loss_s1: 0.046841, loss_fp: 0.002150, loss_freq: 0.028645
[04:06:16.515] iteration 9314: loss: 0.085897, loss_s1: 0.076027, loss_fp: 0.007097, loss_freq: 0.030350
[04:06:17.162] iteration 9315: loss: 0.097293, loss_s1: 0.104846, loss_fp: 0.006966, loss_freq: 0.027545
[04:06:17.806] iteration 9316: loss: 0.060283, loss_s1: 0.049113, loss_fp: 0.002657, loss_freq: 0.017408
[04:06:18.444] iteration 9317: loss: 0.133125, loss_s1: 0.062880, loss_fp: 0.006006, loss_freq: 0.036106
[04:06:19.082] iteration 9318: loss: 0.093845, loss_s1: 0.094617, loss_fp: 0.004915, loss_freq: 0.043413
[04:06:19.724] iteration 9319: loss: 0.135531, loss_s1: 0.151066, loss_fp: 0.006327, loss_freq: 0.068276
[04:06:20.340] iteration 9320: loss: 0.067034, loss_s1: 0.047154, loss_fp: 0.005084, loss_freq: 0.026095
[04:06:20.930] iteration 9321: loss: 0.096128, loss_s1: 0.081752, loss_fp: 0.005712, loss_freq: 0.032509
[04:06:21.567] iteration 9322: loss: 0.075133, loss_s1: 0.056041, loss_fp: 0.001908, loss_freq: 0.028611
[04:06:22.194] iteration 9323: loss: 0.089866, loss_s1: 0.064844, loss_fp: 0.003453, loss_freq: 0.063323
[04:06:22.823] iteration 9324: loss: 0.087848, loss_s1: 0.085005, loss_fp: 0.001395, loss_freq: 0.029324
[04:06:23.451] iteration 9325: loss: 0.084428, loss_s1: 0.088373, loss_fp: 0.002468, loss_freq: 0.024823
[04:06:24.077] iteration 9326: loss: 0.057648, loss_s1: 0.020920, loss_fp: 0.002881, loss_freq: 0.034231
[04:06:24.705] iteration 9327: loss: 0.083087, loss_s1: 0.067168, loss_fp: 0.002185, loss_freq: 0.029999
[04:06:25.338] iteration 9328: loss: 0.104513, loss_s1: 0.102065, loss_fp: 0.005062, loss_freq: 0.035230
[04:06:25.965] iteration 9329: loss: 0.105804, loss_s1: 0.104820, loss_fp: 0.002190, loss_freq: 0.059009
[04:06:26.571] iteration 9330: loss: 0.099419, loss_s1: 0.071511, loss_fp: 0.007416, loss_freq: 0.045082
[04:06:27.169] iteration 9331: loss: 0.066070, loss_s1: 0.047297, loss_fp: 0.001707, loss_freq: 0.034570
[04:06:27.763] iteration 9332: loss: 0.072606, loss_s1: 0.047803, loss_fp: 0.007999, loss_freq: 0.040493
[04:06:28.357] iteration 9333: loss: 0.150804, loss_s1: 0.111039, loss_fp: 0.006798, loss_freq: 0.110649
[04:06:28.944] iteration 9334: loss: 0.059142, loss_s1: 0.012588, loss_fp: 0.004965, loss_freq: 0.036075
[04:06:29.533] iteration 9335: loss: 0.110971, loss_s1: 0.065130, loss_fp: 0.002685, loss_freq: 0.041310
[04:06:30.129] iteration 9336: loss: 0.082642, loss_s1: 0.021214, loss_fp: 0.003784, loss_freq: 0.019706
[04:06:30.716] iteration 9337: loss: 0.115077, loss_s1: 0.068853, loss_fp: 0.007585, loss_freq: 0.069200
[04:06:31.307] iteration 9338: loss: 0.167230, loss_s1: 0.114327, loss_fp: 0.003927, loss_freq: 0.098161
[04:06:31.906] iteration 9339: loss: 0.101496, loss_s1: 0.085493, loss_fp: 0.008043, loss_freq: 0.058472
[04:06:32.499] iteration 9340: loss: 0.095216, loss_s1: 0.066993, loss_fp: 0.002318, loss_freq: 0.029753
[04:06:33.097] iteration 9341: loss: 0.069238, loss_s1: 0.066648, loss_fp: 0.001182, loss_freq: 0.010433
[04:06:33.689] iteration 9342: loss: 0.082681, loss_s1: 0.051608, loss_fp: 0.002934, loss_freq: 0.044840
[04:06:34.283] iteration 9343: loss: 0.075891, loss_s1: 0.048319, loss_fp: 0.002212, loss_freq: 0.037106
[04:06:34.874] iteration 9344: loss: 0.114171, loss_s1: 0.124433, loss_fp: 0.002125, loss_freq: 0.018638
[04:06:35.501] iteration 9345: loss: 0.060312, loss_s1: 0.045066, loss_fp: 0.001133, loss_freq: 0.013981
[04:06:36.103] iteration 9346: loss: 0.093188, loss_s1: 0.065293, loss_fp: 0.005099, loss_freq: 0.034844
[04:06:36.700] iteration 9347: loss: 0.080335, loss_s1: 0.044280, loss_fp: 0.001644, loss_freq: 0.038994
[04:06:37.296] iteration 9348: loss: 0.104336, loss_s1: 0.112664, loss_fp: 0.003751, loss_freq: 0.045917
[04:06:37.887] iteration 9349: loss: 0.138736, loss_s1: 0.116778, loss_fp: 0.017934, loss_freq: 0.078052
[04:06:38.482] iteration 9350: loss: 0.093657, loss_s1: 0.057261, loss_fp: 0.006242, loss_freq: 0.051012
[04:06:39.391] iteration 9351: loss: 0.131264, loss_s1: 0.065576, loss_fp: 0.002938, loss_freq: 0.034488
[04:06:39.987] iteration 9352: loss: 0.076075, loss_s1: 0.050449, loss_fp: 0.002355, loss_freq: 0.036100
[04:06:40.581] iteration 9353: loss: 0.085693, loss_s1: 0.090712, loss_fp: 0.001499, loss_freq: 0.020713
[04:06:41.176] iteration 9354: loss: 0.080864, loss_s1: 0.061434, loss_fp: 0.002123, loss_freq: 0.008916
[04:06:41.809] iteration 9355: loss: 0.084663, loss_s1: 0.074935, loss_fp: 0.001213, loss_freq: 0.035241
[04:06:42.440] iteration 9356: loss: 0.062063, loss_s1: 0.033827, loss_fp: 0.005212, loss_freq: 0.022737
[04:06:43.067] iteration 9357: loss: 0.061029, loss_s1: 0.043697, loss_fp: 0.001307, loss_freq: 0.031011
[04:06:43.693] iteration 9358: loss: 0.082347, loss_s1: 0.061242, loss_fp: 0.004556, loss_freq: 0.019823
[04:06:44.309] iteration 9359: loss: 0.065304, loss_s1: 0.052065, loss_fp: 0.001188, loss_freq: 0.037699
[04:06:44.904] iteration 9360: loss: 0.147173, loss_s1: 0.188445, loss_fp: 0.003141, loss_freq: 0.035392
[04:06:45.495] iteration 9361: loss: 0.089201, loss_s1: 0.047720, loss_fp: 0.004040, loss_freq: 0.051380
[04:06:46.085] iteration 9362: loss: 0.109303, loss_s1: 0.050568, loss_fp: 0.003113, loss_freq: 0.107489
[04:06:46.675] iteration 9363: loss: 0.112174, loss_s1: 0.066273, loss_fp: 0.004258, loss_freq: 0.091581
[04:06:47.263] iteration 9364: loss: 0.073077, loss_s1: 0.061375, loss_fp: 0.002291, loss_freq: 0.019722
[04:06:47.860] iteration 9365: loss: 0.064717, loss_s1: 0.038522, loss_fp: 0.002180, loss_freq: 0.014845
[04:06:48.450] iteration 9366: loss: 0.100007, loss_s1: 0.064553, loss_fp: 0.000944, loss_freq: 0.034670
[04:06:49.039] iteration 9367: loss: 0.146099, loss_s1: 0.134897, loss_fp: 0.006620, loss_freq: 0.104667
[04:06:49.628] iteration 9368: loss: 0.063308, loss_s1: 0.043151, loss_fp: 0.001862, loss_freq: 0.012182
[04:06:50.220] iteration 9369: loss: 0.070947, loss_s1: 0.075348, loss_fp: 0.002023, loss_freq: 0.011676
[04:06:50.879] iteration 9370: loss: 0.087959, loss_s1: 0.073625, loss_fp: 0.009422, loss_freq: 0.032913
[04:06:51.510] iteration 9371: loss: 0.061381, loss_s1: 0.031265, loss_fp: 0.004348, loss_freq: 0.039659
[04:06:52.144] iteration 9372: loss: 0.070368, loss_s1: 0.036748, loss_fp: 0.001560, loss_freq: 0.039614
[04:06:52.779] iteration 9373: loss: 0.099436, loss_s1: 0.074164, loss_fp: 0.004229, loss_freq: 0.041278
[04:06:53.377] iteration 9374: loss: 0.059851, loss_s1: 0.020810, loss_fp: 0.001052, loss_freq: 0.030892
[04:06:53.968] iteration 9375: loss: 0.104296, loss_s1: 0.089621, loss_fp: 0.004925, loss_freq: 0.049628
[04:06:54.597] iteration 9376: loss: 0.059281, loss_s1: 0.037400, loss_fp: 0.004051, loss_freq: 0.038327
[04:06:55.379] iteration 9377: loss: 0.076434, loss_s1: 0.048607, loss_fp: 0.000525, loss_freq: 0.037147
[04:06:56.125] iteration 9378: loss: 0.120228, loss_s1: 0.130811, loss_fp: 0.001350, loss_freq: 0.032466
[04:06:56.799] iteration 9379: loss: 0.082463, loss_s1: 0.053360, loss_fp: 0.005214, loss_freq: 0.047950
[04:06:57.513] iteration 9380: loss: 0.104718, loss_s1: 0.107978, loss_fp: 0.006211, loss_freq: 0.047236
[04:06:58.171] iteration 9381: loss: 0.073105, loss_s1: 0.041894, loss_fp: 0.001654, loss_freq: 0.051953
[04:06:58.870] iteration 9382: loss: 0.078304, loss_s1: 0.041089, loss_fp: 0.006815, loss_freq: 0.054590
[04:06:59.525] iteration 9383: loss: 0.094794, loss_s1: 0.084666, loss_fp: 0.005680, loss_freq: 0.033592
[04:07:00.201] iteration 9384: loss: 0.061879, loss_s1: 0.063926, loss_fp: 0.001904, loss_freq: 0.014645
[04:07:00.824] iteration 9385: loss: 0.088275, loss_s1: 0.069480, loss_fp: 0.004326, loss_freq: 0.045436
[04:07:01.565] iteration 9386: loss: 0.065421, loss_s1: 0.028957, loss_fp: 0.001037, loss_freq: 0.031215
[04:07:02.253] iteration 9387: loss: 0.084256, loss_s1: 0.076156, loss_fp: 0.000947, loss_freq: 0.028125
[04:07:02.936] iteration 9388: loss: 0.077666, loss_s1: 0.050715, loss_fp: 0.003363, loss_freq: 0.019626
[04:07:03.648] iteration 9389: loss: 0.113649, loss_s1: 0.093721, loss_fp: 0.007669, loss_freq: 0.054752
[04:07:04.293] iteration 9390: loss: 0.120049, loss_s1: 0.138212, loss_fp: 0.008164, loss_freq: 0.046715
[04:07:04.966] iteration 9391: loss: 0.122168, loss_s1: 0.121673, loss_fp: 0.006889, loss_freq: 0.057460
[04:07:05.594] iteration 9392: loss: 0.103905, loss_s1: 0.124497, loss_fp: 0.003568, loss_freq: 0.028973
[04:07:06.340] iteration 9393: loss: 0.118216, loss_s1: 0.107213, loss_fp: 0.005595, loss_freq: 0.072486
[04:07:06.975] iteration 9394: loss: 0.093728, loss_s1: 0.079215, loss_fp: 0.007355, loss_freq: 0.051615
[04:07:07.575] iteration 9395: loss: 0.098417, loss_s1: 0.091230, loss_fp: 0.005317, loss_freq: 0.039267
[04:07:08.169] iteration 9396: loss: 0.089768, loss_s1: 0.086003, loss_fp: 0.003885, loss_freq: 0.041724
[04:07:08.767] iteration 9397: loss: 0.102796, loss_s1: 0.087438, loss_fp: 0.005935, loss_freq: 0.068073
[04:07:09.355] iteration 9398: loss: 0.070403, loss_s1: 0.053527, loss_fp: 0.005404, loss_freq: 0.034817
[04:07:09.941] iteration 9399: loss: 0.094374, loss_s1: 0.078262, loss_fp: 0.000688, loss_freq: 0.008168
[04:07:10.593] iteration 9400: loss: 0.085807, loss_s1: 0.038131, loss_fp: 0.001218, loss_freq: 0.033472
[04:07:13.825] iteration 9400 : mean_dice : 0.679719
[04:07:14.496] iteration 9401: loss: 0.074405, loss_s1: 0.074961, loss_fp: 0.001997, loss_freq: 0.017201
[04:07:15.124] iteration 9402: loss: 0.075739, loss_s1: 0.089925, loss_fp: 0.001739, loss_freq: 0.018469
[04:07:15.720] iteration 9403: loss: 0.086244, loss_s1: 0.019972, loss_fp: 0.001268, loss_freq: 0.056923
[04:07:16.319] iteration 9404: loss: 0.079110, loss_s1: 0.049289, loss_fp: 0.015999, loss_freq: 0.042162
[04:07:16.913] iteration 9405: loss: 0.113302, loss_s1: 0.049157, loss_fp: 0.006243, loss_freq: 0.100509
[04:07:17.524] iteration 9406: loss: 0.079063, loss_s1: 0.070963, loss_fp: 0.008104, loss_freq: 0.011138
[04:07:18.128] iteration 9407: loss: 0.071933, loss_s1: 0.039848, loss_fp: 0.002985, loss_freq: 0.046370
[04:07:18.733] iteration 9408: loss: 0.075936, loss_s1: 0.036157, loss_fp: 0.000446, loss_freq: 0.020898
[04:07:19.337] iteration 9409: loss: 0.136925, loss_s1: 0.081421, loss_fp: 0.005479, loss_freq: 0.066691
[04:07:19.940] iteration 9410: loss: 0.087016, loss_s1: 0.058881, loss_fp: 0.009795, loss_freq: 0.058786
[04:07:20.547] iteration 9411: loss: 0.069340, loss_s1: 0.046959, loss_fp: 0.003805, loss_freq: 0.019052
[04:07:21.142] iteration 9412: loss: 0.130645, loss_s1: 0.030926, loss_fp: 0.002553, loss_freq: 0.036831
[04:07:21.828] iteration 9413: loss: 0.063984, loss_s1: 0.033622, loss_fp: 0.001642, loss_freq: 0.030491
[04:07:22.727] iteration 9414: loss: 0.060557, loss_s1: 0.024806, loss_fp: 0.001668, loss_freq: 0.027426
[04:07:23.678] iteration 9415: loss: 0.083366, loss_s1: 0.100139, loss_fp: 0.003122, loss_freq: 0.019186
[04:07:24.608] iteration 9416: loss: 0.068550, loss_s1: 0.035232, loss_fp: 0.001475, loss_freq: 0.028229
[04:07:25.234] iteration 9417: loss: 0.077633, loss_s1: 0.028380, loss_fp: 0.002890, loss_freq: 0.009675
[04:07:25.878] iteration 9418: loss: 0.173350, loss_s1: 0.105929, loss_fp: 0.013521, loss_freq: 0.062153
[04:07:26.521] iteration 9419: loss: 0.090978, loss_s1: 0.025202, loss_fp: 0.003109, loss_freq: 0.031410
[04:07:27.135] iteration 9420: loss: 0.071332, loss_s1: 0.058901, loss_fp: 0.004940, loss_freq: 0.029436
[04:07:27.761] iteration 9421: loss: 0.091072, loss_s1: 0.064848, loss_fp: 0.006181, loss_freq: 0.033418
[04:07:28.360] iteration 9422: loss: 0.069984, loss_s1: 0.042325, loss_fp: 0.002734, loss_freq: 0.035542
[04:07:28.965] iteration 9423: loss: 0.075194, loss_s1: 0.066162, loss_fp: 0.006989, loss_freq: 0.020326
[04:07:29.575] iteration 9424: loss: 0.089436, loss_s1: 0.076728, loss_fp: 0.003299, loss_freq: 0.053506
[04:07:30.191] iteration 9425: loss: 0.101411, loss_s1: 0.069562, loss_fp: 0.005919, loss_freq: 0.058040
[04:07:30.819] iteration 9426: loss: 0.082867, loss_s1: 0.057681, loss_fp: 0.001253, loss_freq: 0.048285
[04:07:31.443] iteration 9427: loss: 0.089640, loss_s1: 0.058451, loss_fp: 0.001598, loss_freq: 0.041890
[04:07:32.043] iteration 9428: loss: 0.096526, loss_s1: 0.054195, loss_fp: 0.006423, loss_freq: 0.045186
[04:07:32.642] iteration 9429: loss: 0.075538, loss_s1: 0.048269, loss_fp: 0.003218, loss_freq: 0.050755
[04:07:33.242] iteration 9430: loss: 0.100014, loss_s1: 0.058438, loss_fp: 0.004927, loss_freq: 0.032918
[04:07:34.106] iteration 9431: loss: 0.104640, loss_s1: 0.048437, loss_fp: 0.001268, loss_freq: 0.051715
[04:07:34.912] iteration 9432: loss: 0.078670, loss_s1: 0.045261, loss_fp: 0.004849, loss_freq: 0.027362
[04:07:35.644] iteration 9433: loss: 0.081464, loss_s1: 0.083682, loss_fp: 0.002037, loss_freq: 0.028595
[04:07:36.280] iteration 9434: loss: 0.057483, loss_s1: 0.038583, loss_fp: 0.003174, loss_freq: 0.021984
[04:07:36.907] iteration 9435: loss: 0.057164, loss_s1: 0.020477, loss_fp: 0.000400, loss_freq: 0.021282
[04:07:37.498] iteration 9436: loss: 0.056146, loss_s1: 0.027749, loss_fp: 0.001592, loss_freq: 0.011698
[04:07:38.085] iteration 9437: loss: 0.102260, loss_s1: 0.093907, loss_fp: 0.002147, loss_freq: 0.047928
[04:07:38.680] iteration 9438: loss: 0.104033, loss_s1: 0.088237, loss_fp: 0.001542, loss_freq: 0.054171
[04:07:39.315] iteration 9439: loss: 0.050836, loss_s1: 0.037727, loss_fp: 0.008337, loss_freq: 0.013431
[04:07:39.908] iteration 9440: loss: 0.078655, loss_s1: 0.043994, loss_fp: 0.001201, loss_freq: 0.022302
[04:07:40.499] iteration 9441: loss: 0.105463, loss_s1: 0.106944, loss_fp: 0.008009, loss_freq: 0.033338
[04:07:41.092] iteration 9442: loss: 0.089123, loss_s1: 0.038275, loss_fp: 0.003455, loss_freq: 0.079450
[04:07:41.683] iteration 9443: loss: 0.093072, loss_s1: 0.068480, loss_fp: 0.001330, loss_freq: 0.024498
[04:07:42.277] iteration 9444: loss: 0.059021, loss_s1: 0.040950, loss_fp: 0.000738, loss_freq: 0.009945
[04:07:42.872] iteration 9445: loss: 0.081793, loss_s1: 0.047762, loss_fp: 0.000963, loss_freq: 0.050626
[04:07:43.466] iteration 9446: loss: 0.092503, loss_s1: 0.091897, loss_fp: 0.003040, loss_freq: 0.042194
[04:07:44.068] iteration 9447: loss: 0.087500, loss_s1: 0.049614, loss_fp: 0.002572, loss_freq: 0.049323
[04:07:44.661] iteration 9448: loss: 0.068891, loss_s1: 0.047140, loss_fp: 0.000968, loss_freq: 0.031512
[04:07:45.256] iteration 9449: loss: 0.111541, loss_s1: 0.060485, loss_fp: 0.003732, loss_freq: 0.057276
[04:07:45.876] iteration 9450: loss: 0.061580, loss_s1: 0.042462, loss_fp: 0.001483, loss_freq: 0.024000
[04:07:46.508] iteration 9451: loss: 0.065745, loss_s1: 0.063201, loss_fp: 0.002154, loss_freq: 0.022741
[04:07:47.145] iteration 9452: loss: 0.068495, loss_s1: 0.033893, loss_fp: 0.002923, loss_freq: 0.032454
[04:07:47.784] iteration 9453: loss: 0.058324, loss_s1: 0.032685, loss_fp: 0.001798, loss_freq: 0.020165
[04:07:48.406] iteration 9454: loss: 0.063943, loss_s1: 0.045664, loss_fp: 0.000376, loss_freq: 0.020299
[04:07:49.004] iteration 9455: loss: 0.060189, loss_s1: 0.036583, loss_fp: 0.001433, loss_freq: 0.028051
[04:07:49.603] iteration 9456: loss: 0.097153, loss_s1: 0.064799, loss_fp: 0.007184, loss_freq: 0.044331
[04:07:50.196] iteration 9457: loss: 0.069905, loss_s1: 0.037114, loss_fp: 0.006581, loss_freq: 0.036915
[04:07:50.797] iteration 9458: loss: 0.050193, loss_s1: 0.017594, loss_fp: 0.004098, loss_freq: 0.031311
[04:07:51.394] iteration 9459: loss: 0.140871, loss_s1: 0.077239, loss_fp: 0.004457, loss_freq: 0.104418
[04:07:51.989] iteration 9460: loss: 0.052860, loss_s1: 0.031462, loss_fp: 0.007311, loss_freq: 0.020238
[04:07:52.589] iteration 9461: loss: 0.082042, loss_s1: 0.032120, loss_fp: 0.001362, loss_freq: 0.024000
[04:07:53.187] iteration 9462: loss: 0.084991, loss_s1: 0.061492, loss_fp: 0.003375, loss_freq: 0.030203
[04:07:53.782] iteration 9463: loss: 0.080443, loss_s1: 0.089121, loss_fp: 0.001167, loss_freq: 0.011220
[04:07:54.380] iteration 9464: loss: 0.050254, loss_s1: 0.028424, loss_fp: 0.001867, loss_freq: 0.019211
[04:07:54.972] iteration 9465: loss: 0.112092, loss_s1: 0.049353, loss_fp: 0.024047, loss_freq: 0.083508
[04:07:55.570] iteration 9466: loss: 0.077958, loss_s1: 0.049793, loss_fp: 0.001780, loss_freq: 0.040665
[04:07:56.167] iteration 9467: loss: 0.108041, loss_s1: 0.084497, loss_fp: 0.004735, loss_freq: 0.042204
[04:07:56.763] iteration 9468: loss: 0.049237, loss_s1: 0.017680, loss_fp: 0.005012, loss_freq: 0.017043
[04:07:57.360] iteration 9469: loss: 0.090850, loss_s1: 0.043397, loss_fp: 0.005754, loss_freq: 0.078401
[04:07:57.957] iteration 9470: loss: 0.079948, loss_s1: 0.073623, loss_fp: 0.001034, loss_freq: 0.025146
[04:07:58.551] iteration 9471: loss: 0.055163, loss_s1: 0.041243, loss_fp: 0.002853, loss_freq: 0.015052
[04:07:59.149] iteration 9472: loss: 0.075415, loss_s1: 0.084530, loss_fp: 0.002446, loss_freq: 0.026076
[04:07:59.741] iteration 9473: loss: 0.061817, loss_s1: 0.037708, loss_fp: 0.002263, loss_freq: 0.029080
[04:08:00.340] iteration 9474: loss: 0.076449, loss_s1: 0.047212, loss_fp: 0.001958, loss_freq: 0.057241
[04:08:00.936] iteration 9475: loss: 0.074037, loss_s1: 0.045885, loss_fp: 0.008782, loss_freq: 0.036833
[04:08:01.534] iteration 9476: loss: 0.086196, loss_s1: 0.077892, loss_fp: 0.001379, loss_freq: 0.034068
[04:08:02.133] iteration 9477: loss: 0.088095, loss_s1: 0.073657, loss_fp: 0.002731, loss_freq: 0.056606
[04:08:02.727] iteration 9478: loss: 0.123562, loss_s1: 0.056567, loss_fp: 0.003321, loss_freq: 0.053732
[04:08:03.327] iteration 9479: loss: 0.060980, loss_s1: 0.035012, loss_fp: 0.006437, loss_freq: 0.040362
[04:08:03.920] iteration 9480: loss: 0.079676, loss_s1: 0.029100, loss_fp: 0.008822, loss_freq: 0.064774
[04:08:04.521] iteration 9481: loss: 0.086102, loss_s1: 0.065413, loss_fp: 0.008535, loss_freq: 0.039118
[04:08:05.113] iteration 9482: loss: 0.106037, loss_s1: 0.025418, loss_fp: 0.001490, loss_freq: 0.017758
[04:08:05.738] iteration 9483: loss: 0.126712, loss_s1: 0.150727, loss_fp: 0.001107, loss_freq: 0.038675
[04:08:06.338] iteration 9484: loss: 0.091605, loss_s1: 0.068338, loss_fp: 0.011025, loss_freq: 0.035694
[04:08:06.938] iteration 9485: loss: 0.146146, loss_s1: 0.106522, loss_fp: 0.003123, loss_freq: 0.114431
[04:08:07.534] iteration 9486: loss: 0.076631, loss_s1: 0.043585, loss_fp: 0.000768, loss_freq: 0.048365
[04:08:08.129] iteration 9487: loss: 0.099362, loss_s1: 0.077230, loss_fp: 0.002226, loss_freq: 0.023593
[04:08:08.723] iteration 9488: loss: 0.077689, loss_s1: 0.063149, loss_fp: 0.002080, loss_freq: 0.044857
[04:08:09.313] iteration 9489: loss: 0.116977, loss_s1: 0.074378, loss_fp: 0.009016, loss_freq: 0.084288
[04:08:09.900] iteration 9490: loss: 0.099449, loss_s1: 0.098248, loss_fp: 0.001744, loss_freq: 0.054466
[04:08:10.496] iteration 9491: loss: 0.120358, loss_s1: 0.084493, loss_fp: 0.003704, loss_freq: 0.067675
[04:08:11.090] iteration 9492: loss: 0.086890, loss_s1: 0.068438, loss_fp: 0.003802, loss_freq: 0.053314
[04:08:11.681] iteration 9493: loss: 0.095156, loss_s1: 0.103280, loss_fp: 0.006082, loss_freq: 0.034213
[04:08:12.272] iteration 9494: loss: 0.097711, loss_s1: 0.079735, loss_fp: 0.003013, loss_freq: 0.013573
[04:08:12.867] iteration 9495: loss: 0.078844, loss_s1: 0.074679, loss_fp: 0.005444, loss_freq: 0.018363
[04:08:13.454] iteration 9496: loss: 0.073297, loss_s1: 0.057114, loss_fp: 0.000717, loss_freq: 0.033574
[04:08:14.041] iteration 9497: loss: 0.078518, loss_s1: 0.072276, loss_fp: 0.006940, loss_freq: 0.019153
[04:08:14.629] iteration 9498: loss: 0.092347, loss_s1: 0.047559, loss_fp: 0.001726, loss_freq: 0.056295
[04:08:15.271] iteration 9499: loss: 0.089918, loss_s1: 0.054770, loss_fp: 0.002106, loss_freq: 0.084526
[04:08:15.865] iteration 9500: loss: 0.080703, loss_s1: 0.062720, loss_fp: 0.004099, loss_freq: 0.034883
[04:08:16.453] iteration 9501: loss: 0.081879, loss_s1: 0.055613, loss_fp: 0.015595, loss_freq: 0.028923
[04:08:17.050] iteration 9502: loss: 0.104911, loss_s1: 0.105873, loss_fp: 0.002415, loss_freq: 0.050339
[04:08:17.644] iteration 9503: loss: 0.107665, loss_s1: 0.072239, loss_fp: 0.005929, loss_freq: 0.049087
[04:08:18.233] iteration 9504: loss: 0.066508, loss_s1: 0.033757, loss_fp: 0.020032, loss_freq: 0.027761
[04:08:18.824] iteration 9505: loss: 0.095791, loss_s1: 0.084390, loss_fp: 0.006188, loss_freq: 0.038541
[04:08:19.420] iteration 9506: loss: 0.087036, loss_s1: 0.090067, loss_fp: 0.001797, loss_freq: 0.020097
[04:08:20.014] iteration 9507: loss: 0.046144, loss_s1: 0.024906, loss_fp: 0.001703, loss_freq: 0.020830
[04:08:20.611] iteration 9508: loss: 0.091500, loss_s1: 0.078459, loss_fp: 0.003843, loss_freq: 0.045517
[04:08:21.202] iteration 9509: loss: 0.077829, loss_s1: 0.043153, loss_fp: 0.004818, loss_freq: 0.041765
[04:08:21.795] iteration 9510: loss: 0.074430, loss_s1: 0.065383, loss_fp: 0.002735, loss_freq: 0.023732
[04:08:22.386] iteration 9511: loss: 0.067762, loss_s1: 0.064346, loss_fp: 0.001769, loss_freq: 0.009934
[04:08:22.982] iteration 9512: loss: 0.035600, loss_s1: 0.021966, loss_fp: 0.001715, loss_freq: 0.010392
[04:08:23.579] iteration 9513: loss: 0.066871, loss_s1: 0.020166, loss_fp: 0.001381, loss_freq: 0.028747
[04:08:24.174] iteration 9514: loss: 0.057169, loss_s1: 0.041727, loss_fp: 0.007185, loss_freq: 0.026048
[04:08:24.767] iteration 9515: loss: 0.042379, loss_s1: 0.021416, loss_fp: 0.001264, loss_freq: 0.017115
[04:08:25.395] iteration 9516: loss: 0.096674, loss_s1: 0.080987, loss_fp: 0.002170, loss_freq: 0.068114
[04:08:26.047] iteration 9517: loss: 0.106976, loss_s1: 0.078532, loss_fp: 0.003502, loss_freq: 0.056989
[04:08:26.678] iteration 9518: loss: 0.112444, loss_s1: 0.120347, loss_fp: 0.005568, loss_freq: 0.049194
[04:08:27.311] iteration 9519: loss: 0.101276, loss_s1: 0.078727, loss_fp: 0.005881, loss_freq: 0.064229
[04:08:27.940] iteration 9520: loss: 0.085954, loss_s1: 0.053803, loss_fp: 0.001924, loss_freq: 0.053689
[04:08:28.857] iteration 9521: loss: 0.087984, loss_s1: 0.079640, loss_fp: 0.001237, loss_freq: 0.020892
[04:08:29.469] iteration 9522: loss: 0.049612, loss_s1: 0.014450, loss_fp: 0.000747, loss_freq: 0.014706
[04:08:30.102] iteration 9523: loss: 0.053694, loss_s1: 0.032287, loss_fp: 0.001152, loss_freq: 0.031590
[04:08:30.691] iteration 9524: loss: 0.067466, loss_s1: 0.031166, loss_fp: 0.002570, loss_freq: 0.027577
[04:08:31.279] iteration 9525: loss: 0.068405, loss_s1: 0.039659, loss_fp: 0.003389, loss_freq: 0.032953
[04:08:31.915] iteration 9526: loss: 0.109101, loss_s1: 0.103983, loss_fp: 0.002705, loss_freq: 0.042540
[04:08:32.562] iteration 9527: loss: 0.065438, loss_s1: 0.044015, loss_fp: 0.005181, loss_freq: 0.025335
[04:08:33.190] iteration 9528: loss: 0.053301, loss_s1: 0.042268, loss_fp: 0.004998, loss_freq: 0.018654
[04:08:33.780] iteration 9529: loss: 0.048878, loss_s1: 0.023137, loss_fp: 0.001729, loss_freq: 0.021823
[04:08:34.378] iteration 9530: loss: 0.077331, loss_s1: 0.077292, loss_fp: 0.001416, loss_freq: 0.020689
[04:08:34.966] iteration 9531: loss: 0.114803, loss_s1: 0.062289, loss_fp: 0.011122, loss_freq: 0.049054
[04:08:35.557] iteration 9532: loss: 0.110315, loss_s1: 0.075536, loss_fp: 0.010734, loss_freq: 0.083249
[04:08:36.154] iteration 9533: loss: 0.075844, loss_s1: 0.035087, loss_fp: 0.010724, loss_freq: 0.034943
[04:08:36.753] iteration 9534: loss: 0.099525, loss_s1: 0.087282, loss_fp: 0.001520, loss_freq: 0.053980
[04:08:37.350] iteration 9535: loss: 0.077369, loss_s1: 0.063777, loss_fp: 0.008110, loss_freq: 0.017384
[04:08:37.949] iteration 9536: loss: 0.075582, loss_s1: 0.055594, loss_fp: 0.001125, loss_freq: 0.036594
[04:08:38.540] iteration 9537: loss: 0.138475, loss_s1: 0.146111, loss_fp: 0.007113, loss_freq: 0.083527
[04:08:39.137] iteration 9538: loss: 0.086839, loss_s1: 0.030738, loss_fp: 0.002116, loss_freq: 0.012009
[04:08:39.728] iteration 9539: loss: 0.069113, loss_s1: 0.052428, loss_fp: 0.003550, loss_freq: 0.038382
[04:08:40.323] iteration 9540: loss: 0.073834, loss_s1: 0.056756, loss_fp: 0.001105, loss_freq: 0.027620
[04:08:40.918] iteration 9541: loss: 0.050091, loss_s1: 0.017138, loss_fp: 0.003431, loss_freq: 0.030512
[04:08:41.505] iteration 9542: loss: 0.059982, loss_s1: 0.040707, loss_fp: 0.002132, loss_freq: 0.034043
[04:08:42.097] iteration 9543: loss: 0.145893, loss_s1: 0.094257, loss_fp: 0.004171, loss_freq: 0.056841
[04:08:42.692] iteration 9544: loss: 0.078053, loss_s1: 0.072511, loss_fp: 0.003750, loss_freq: 0.014949
[04:08:43.279] iteration 9545: loss: 0.045217, loss_s1: 0.011791, loss_fp: 0.000503, loss_freq: 0.031378
[04:08:43.871] iteration 9546: loss: 0.084044, loss_s1: 0.068247, loss_fp: 0.002204, loss_freq: 0.032547
[04:08:44.460] iteration 9547: loss: 0.091313, loss_s1: 0.087083, loss_fp: 0.003562, loss_freq: 0.024938
[04:08:45.057] iteration 9548: loss: 0.095718, loss_s1: 0.063914, loss_fp: 0.011136, loss_freq: 0.024616
[04:08:45.647] iteration 9549: loss: 0.098453, loss_s1: 0.049120, loss_fp: 0.001091, loss_freq: 0.055385
[04:08:46.239] iteration 9550: loss: 0.060761, loss_s1: 0.052317, loss_fp: 0.001666, loss_freq: 0.020970
[04:08:46.834] iteration 9551: loss: 0.071568, loss_s1: 0.039580, loss_fp: 0.000742, loss_freq: 0.056082
[04:08:47.461] iteration 9552: loss: 0.105856, loss_s1: 0.071243, loss_fp: 0.004453, loss_freq: 0.054922
[04:08:48.056] iteration 9553: loss: 0.082662, loss_s1: 0.051388, loss_fp: 0.001423, loss_freq: 0.048782
[04:08:48.644] iteration 9554: loss: 0.062607, loss_s1: 0.070962, loss_fp: 0.003971, loss_freq: 0.007662
[04:08:49.233] iteration 9555: loss: 0.069676, loss_s1: 0.049674, loss_fp: 0.001445, loss_freq: 0.028577
[04:08:49.828] iteration 9556: loss: 0.068995, loss_s1: 0.038661, loss_fp: 0.002634, loss_freq: 0.022006
[04:08:50.421] iteration 9557: loss: 0.107905, loss_s1: 0.090213, loss_fp: 0.010228, loss_freq: 0.061353
[04:08:51.009] iteration 9558: loss: 0.045635, loss_s1: 0.026330, loss_fp: 0.002051, loss_freq: 0.023495
[04:08:51.608] iteration 9559: loss: 0.110600, loss_s1: 0.085836, loss_fp: 0.005142, loss_freq: 0.057306
[04:08:52.240] iteration 9560: loss: 0.086951, loss_s1: 0.082120, loss_fp: 0.001461, loss_freq: 0.033182
[04:08:52.840] iteration 9561: loss: 0.135255, loss_s1: 0.108162, loss_fp: 0.000623, loss_freq: 0.114863
[04:08:53.427] iteration 9562: loss: 0.075216, loss_s1: 0.069534, loss_fp: 0.000789, loss_freq: 0.032919
[04:08:54.017] iteration 9563: loss: 0.089657, loss_s1: 0.053444, loss_fp: 0.002872, loss_freq: 0.064957
[04:08:54.606] iteration 9564: loss: 0.110987, loss_s1: 0.119546, loss_fp: 0.000538, loss_freq: 0.048211
[04:08:55.201] iteration 9565: loss: 0.096891, loss_s1: 0.089187, loss_fp: 0.003629, loss_freq: 0.016068
[04:08:55.848] iteration 9566: loss: 0.079516, loss_s1: 0.052752, loss_fp: 0.003693, loss_freq: 0.038994
[04:08:56.459] iteration 9567: loss: 0.081504, loss_s1: 0.063121, loss_fp: 0.001407, loss_freq: 0.048401
[04:08:57.048] iteration 9568: loss: 0.052325, loss_s1: 0.028922, loss_fp: 0.000928, loss_freq: 0.028636
[04:08:57.639] iteration 9569: loss: 0.077026, loss_s1: 0.050945, loss_fp: 0.003248, loss_freq: 0.018391
[04:08:58.228] iteration 9570: loss: 0.076671, loss_s1: 0.079396, loss_fp: 0.002169, loss_freq: 0.019061
[04:08:58.815] iteration 9571: loss: 0.083045, loss_s1: 0.055821, loss_fp: 0.003295, loss_freq: 0.051263
[04:08:59.437] iteration 9572: loss: 0.081553, loss_s1: 0.074922, loss_fp: 0.001012, loss_freq: 0.051116
[04:09:00.063] iteration 9573: loss: 0.086453, loss_s1: 0.047307, loss_fp: 0.003953, loss_freq: 0.032396
[04:09:00.658] iteration 9574: loss: 0.111148, loss_s1: 0.093234, loss_fp: 0.007832, loss_freq: 0.064356
[04:09:01.246] iteration 9575: loss: 0.072328, loss_s1: 0.034610, loss_fp: 0.007107, loss_freq: 0.031103
[04:09:01.866] iteration 9576: loss: 0.050013, loss_s1: 0.025796, loss_fp: 0.005384, loss_freq: 0.017003
[04:09:02.501] iteration 9577: loss: 0.054422, loss_s1: 0.045530, loss_fp: 0.001585, loss_freq: 0.024519
[04:09:03.132] iteration 9578: loss: 0.091911, loss_s1: 0.073387, loss_fp: 0.004547, loss_freq: 0.022466
[04:09:03.758] iteration 9579: loss: 0.079697, loss_s1: 0.048501, loss_fp: 0.002632, loss_freq: 0.028985
[04:09:04.347] iteration 9580: loss: 0.096814, loss_s1: 0.066474, loss_fp: 0.004560, loss_freq: 0.042264
[04:09:04.942] iteration 9581: loss: 0.086492, loss_s1: 0.091410, loss_fp: 0.007195, loss_freq: 0.018324
[04:09:05.539] iteration 9582: loss: 0.116910, loss_s1: 0.055646, loss_fp: 0.003412, loss_freq: 0.043959
[04:09:06.146] iteration 9583: loss: 0.082759, loss_s1: 0.070256, loss_fp: 0.002549, loss_freq: 0.024951
[04:09:06.747] iteration 9584: loss: 0.069126, loss_s1: 0.054707, loss_fp: 0.004159, loss_freq: 0.038660
[04:09:07.338] iteration 9585: loss: 0.081184, loss_s1: 0.056992, loss_fp: 0.002046, loss_freq: 0.044129
[04:09:07.924] iteration 9586: loss: 0.049131, loss_s1: 0.038535, loss_fp: 0.001257, loss_freq: 0.023003
[04:09:08.513] iteration 9587: loss: 0.062381, loss_s1: 0.043214, loss_fp: 0.001887, loss_freq: 0.014071
[04:09:09.102] iteration 9588: loss: 0.130438, loss_s1: 0.094075, loss_fp: 0.009077, loss_freq: 0.059682
[04:09:09.695] iteration 9589: loss: 0.087163, loss_s1: 0.072757, loss_fp: 0.002926, loss_freq: 0.037076
[04:09:10.286] iteration 9590: loss: 0.057657, loss_s1: 0.046952, loss_fp: 0.001618, loss_freq: 0.027250
[04:09:10.874] iteration 9591: loss: 0.072003, loss_s1: 0.050129, loss_fp: 0.011275, loss_freq: 0.029086
[04:09:11.465] iteration 9592: loss: 0.091376, loss_s1: 0.058719, loss_fp: 0.002586, loss_freq: 0.050436
[04:09:12.059] iteration 9593: loss: 0.066464, loss_s1: 0.040784, loss_fp: 0.003695, loss_freq: 0.043804
[04:09:12.649] iteration 9594: loss: 0.122762, loss_s1: 0.122208, loss_fp: 0.003925, loss_freq: 0.034321
[04:09:13.243] iteration 9595: loss: 0.126453, loss_s1: 0.063870, loss_fp: 0.002117, loss_freq: 0.074113
[04:09:13.832] iteration 9596: loss: 0.096774, loss_s1: 0.070650, loss_fp: 0.010101, loss_freq: 0.035048
[04:09:14.424] iteration 9597: loss: 0.064128, loss_s1: 0.041156, loss_fp: 0.003728, loss_freq: 0.037343
[04:09:15.012] iteration 9598: loss: 0.133464, loss_s1: 0.141434, loss_fp: 0.001908, loss_freq: 0.040576
[04:09:15.639] iteration 9599: loss: 0.072674, loss_s1: 0.042581, loss_fp: 0.003180, loss_freq: 0.056507
[04:09:16.288] iteration 9600: loss: 0.098015, loss_s1: 0.084645, loss_fp: 0.002035, loss_freq: 0.043372
[04:09:19.562] iteration 9600 : mean_dice : 0.692207
[04:09:20.192] iteration 9601: loss: 0.143222, loss_s1: 0.113963, loss_fp: 0.016014, loss_freq: 0.078984
[04:09:20.784] iteration 9602: loss: 0.081867, loss_s1: 0.069222, loss_fp: 0.003208, loss_freq: 0.024591
[04:09:21.381] iteration 9603: loss: 0.087786, loss_s1: 0.074337, loss_fp: 0.001445, loss_freq: 0.035090
[04:09:21.980] iteration 9604: loss: 0.070385, loss_s1: 0.046595, loss_fp: 0.006210, loss_freq: 0.016947
[04:09:22.574] iteration 9605: loss: 0.071307, loss_s1: 0.054061, loss_fp: 0.002471, loss_freq: 0.028345
[04:09:23.172] iteration 9606: loss: 0.096945, loss_s1: 0.088337, loss_fp: 0.003167, loss_freq: 0.053578
[04:09:23.760] iteration 9607: loss: 0.078567, loss_s1: 0.076344, loss_fp: 0.005316, loss_freq: 0.030950
[04:09:24.351] iteration 9608: loss: 0.110625, loss_s1: 0.110195, loss_fp: 0.001324, loss_freq: 0.039676
[04:09:24.937] iteration 9609: loss: 0.115059, loss_s1: 0.123915, loss_fp: 0.010989, loss_freq: 0.036520
[04:09:25.530] iteration 9610: loss: 0.088690, loss_s1: 0.090872, loss_fp: 0.001503, loss_freq: 0.026644
[04:09:26.123] iteration 9611: loss: 0.089692, loss_s1: 0.082733, loss_fp: 0.004160, loss_freq: 0.034925
[04:09:26.714] iteration 9612: loss: 0.094413, loss_s1: 0.068908, loss_fp: 0.002152, loss_freq: 0.062380
[04:09:27.308] iteration 9613: loss: 0.084395, loss_s1: 0.061342, loss_fp: 0.008625, loss_freq: 0.028036
[04:09:27.897] iteration 9614: loss: 0.067851, loss_s1: 0.026744, loss_fp: 0.002731, loss_freq: 0.050204
[04:09:28.494] iteration 9615: loss: 0.100062, loss_s1: 0.075857, loss_fp: 0.000489, loss_freq: 0.029989
[04:09:29.085] iteration 9616: loss: 0.085919, loss_s1: 0.103887, loss_fp: 0.001609, loss_freq: 0.019274
[04:09:29.673] iteration 9617: loss: 0.121955, loss_s1: 0.099518, loss_fp: 0.013215, loss_freq: 0.055684
[04:09:30.263] iteration 9618: loss: 0.090923, loss_s1: 0.092320, loss_fp: 0.001293, loss_freq: 0.038617
[04:09:30.848] iteration 9619: loss: 0.094785, loss_s1: 0.081482, loss_fp: 0.002014, loss_freq: 0.048448
[04:09:31.438] iteration 9620: loss: 0.067265, loss_s1: 0.041822, loss_fp: 0.002625, loss_freq: 0.020967
[04:09:32.025] iteration 9621: loss: 0.090505, loss_s1: 0.078235, loss_fp: 0.001709, loss_freq: 0.046835
[04:09:32.616] iteration 9622: loss: 0.064466, loss_s1: 0.058278, loss_fp: 0.001995, loss_freq: 0.010371
[04:09:33.211] iteration 9623: loss: 0.070938, loss_s1: 0.040144, loss_fp: 0.001655, loss_freq: 0.043777
[04:09:33.802] iteration 9624: loss: 0.067379, loss_s1: 0.026955, loss_fp: 0.001410, loss_freq: 0.026923
[04:09:34.398] iteration 9625: loss: 0.081167, loss_s1: 0.065456, loss_fp: 0.003864, loss_freq: 0.044999
[04:09:34.989] iteration 9626: loss: 0.089411, loss_s1: 0.073434, loss_fp: 0.004505, loss_freq: 0.048503
[04:09:35.589] iteration 9627: loss: 0.066395, loss_s1: 0.041829, loss_fp: 0.007020, loss_freq: 0.027570
[04:09:36.267] iteration 9628: loss: 0.099210, loss_s1: 0.065076, loss_fp: 0.002951, loss_freq: 0.043662
[04:09:37.064] iteration 9629: loss: 0.087105, loss_s1: 0.045867, loss_fp: 0.002556, loss_freq: 0.058425
[04:09:37.995] iteration 9630: loss: 0.079453, loss_s1: 0.049447, loss_fp: 0.001128, loss_freq: 0.050061
[04:09:38.844] iteration 9631: loss: 0.098617, loss_s1: 0.070951, loss_fp: 0.005056, loss_freq: 0.020082
[04:09:39.452] iteration 9632: loss: 0.073461, loss_s1: 0.051991, loss_fp: 0.010708, loss_freq: 0.036279
[04:09:40.054] iteration 9633: loss: 0.078655, loss_s1: 0.063886, loss_fp: 0.004896, loss_freq: 0.026463
[04:09:40.648] iteration 9634: loss: 0.042084, loss_s1: 0.026919, loss_fp: 0.007141, loss_freq: 0.017970
[04:09:41.288] iteration 9635: loss: 0.122180, loss_s1: 0.104120, loss_fp: 0.003734, loss_freq: 0.076000
[04:09:41.880] iteration 9636: loss: 0.090709, loss_s1: 0.060080, loss_fp: 0.004976, loss_freq: 0.059609
[04:09:42.505] iteration 9637: loss: 0.081785, loss_s1: 0.082515, loss_fp: 0.003747, loss_freq: 0.019483
[04:09:43.138] iteration 9638: loss: 0.074158, loss_s1: 0.076039, loss_fp: 0.004723, loss_freq: 0.018291
[04:09:43.773] iteration 9639: loss: 0.130594, loss_s1: 0.081600, loss_fp: 0.003678, loss_freq: 0.128833
[04:09:44.379] iteration 9640: loss: 0.058805, loss_s1: 0.043332, loss_fp: 0.000978, loss_freq: 0.019518
[04:09:44.970] iteration 9641: loss: 0.071392, loss_s1: 0.076073, loss_fp: 0.000823, loss_freq: 0.015006
[04:09:45.558] iteration 9642: loss: 0.100282, loss_s1: 0.112789, loss_fp: 0.002158, loss_freq: 0.049188
[04:09:46.148] iteration 9643: loss: 0.060665, loss_s1: 0.023120, loss_fp: 0.004302, loss_freq: 0.045166
[04:09:46.738] iteration 9644: loss: 0.063552, loss_s1: 0.042664, loss_fp: 0.001036, loss_freq: 0.030783
[04:09:47.320] iteration 9645: loss: 0.124849, loss_s1: 0.091074, loss_fp: 0.011993, loss_freq: 0.077328
[04:09:47.908] iteration 9646: loss: 0.103491, loss_s1: 0.123386, loss_fp: 0.001302, loss_freq: 0.037421
[04:09:48.500] iteration 9647: loss: 0.091768, loss_s1: 0.066312, loss_fp: 0.003370, loss_freq: 0.066791
[04:09:49.090] iteration 9648: loss: 0.070923, loss_s1: 0.026632, loss_fp: 0.003937, loss_freq: 0.059477
[04:09:49.682] iteration 9649: loss: 0.060355, loss_s1: 0.036443, loss_fp: 0.001994, loss_freq: 0.044448
[04:09:50.268] iteration 9650: loss: 0.116631, loss_s1: 0.086369, loss_fp: 0.009404, loss_freq: 0.060871
[04:09:50.863] iteration 9651: loss: 0.104973, loss_s1: 0.127590, loss_fp: 0.005964, loss_freq: 0.019234
[04:09:51.519] iteration 9652: loss: 0.077656, loss_s1: 0.036291, loss_fp: 0.001183, loss_freq: 0.036559
[04:09:52.134] iteration 9653: loss: 0.073137, loss_s1: 0.068740, loss_fp: 0.002099, loss_freq: 0.030739
[04:09:52.721] iteration 9654: loss: 0.119879, loss_s1: 0.157420, loss_fp: 0.003775, loss_freq: 0.030429
[04:09:53.315] iteration 9655: loss: 0.137235, loss_s1: 0.129386, loss_fp: 0.006188, loss_freq: 0.092516
[04:09:53.909] iteration 9656: loss: 0.059352, loss_s1: 0.026854, loss_fp: 0.002430, loss_freq: 0.022006
[04:09:54.500] iteration 9657: loss: 0.086967, loss_s1: 0.071791, loss_fp: 0.002541, loss_freq: 0.027085
[04:09:55.095] iteration 9658: loss: 0.076241, loss_s1: 0.072148, loss_fp: 0.013084, loss_freq: 0.028672
[04:09:55.688] iteration 9659: loss: 0.124487, loss_s1: 0.102307, loss_fp: 0.014773, loss_freq: 0.074033
[04:09:56.284] iteration 9660: loss: 0.065398, loss_s1: 0.066893, loss_fp: 0.001532, loss_freq: 0.022608
[04:09:56.881] iteration 9661: loss: 0.121481, loss_s1: 0.125379, loss_fp: 0.007901, loss_freq: 0.040089
[04:09:57.480] iteration 9662: loss: 0.076080, loss_s1: 0.043368, loss_fp: 0.003977, loss_freq: 0.042278
[04:09:58.070] iteration 9663: loss: 0.093331, loss_s1: 0.058251, loss_fp: 0.006042, loss_freq: 0.043870
[04:09:58.663] iteration 9664: loss: 0.111953, loss_s1: 0.026610, loss_fp: 0.011007, loss_freq: 0.017180
[04:09:59.259] iteration 9665: loss: 0.060078, loss_s1: 0.030410, loss_fp: 0.004372, loss_freq: 0.020970
[04:09:59.851] iteration 9666: loss: 0.063329, loss_s1: 0.042079, loss_fp: 0.004192, loss_freq: 0.025578
[04:10:00.441] iteration 9667: loss: 0.065765, loss_s1: 0.054209, loss_fp: 0.006528, loss_freq: 0.022615
[04:10:01.036] iteration 9668: loss: 0.087838, loss_s1: 0.076218, loss_fp: 0.002657, loss_freq: 0.032537
[04:10:01.629] iteration 9669: loss: 0.100713, loss_s1: 0.080711, loss_fp: 0.015897, loss_freq: 0.049623
[04:10:02.257] iteration 9670: loss: 0.101467, loss_s1: 0.053823, loss_fp: 0.004257, loss_freq: 0.040228
[04:10:02.885] iteration 9671: loss: 0.072142, loss_s1: 0.050878, loss_fp: 0.001791, loss_freq: 0.034482
[04:10:03.533] iteration 9672: loss: 0.077148, loss_s1: 0.081150, loss_fp: 0.002604, loss_freq: 0.023604
[04:10:04.157] iteration 9673: loss: 0.146681, loss_s1: 0.142305, loss_fp: 0.004885, loss_freq: 0.073455
[04:10:04.784] iteration 9674: loss: 0.076369, loss_s1: 0.043277, loss_fp: 0.005047, loss_freq: 0.039141
[04:10:05.417] iteration 9675: loss: 0.106761, loss_s1: 0.064927, loss_fp: 0.001733, loss_freq: 0.065382
[04:10:06.043] iteration 9676: loss: 0.090099, loss_s1: 0.033252, loss_fp: 0.005167, loss_freq: 0.034373
[04:10:06.674] iteration 9677: loss: 0.079000, loss_s1: 0.049522, loss_fp: 0.007771, loss_freq: 0.060015
[04:10:07.285] iteration 9678: loss: 0.149146, loss_s1: 0.143709, loss_fp: 0.006594, loss_freq: 0.070576
[04:10:07.887] iteration 9679: loss: 0.076805, loss_s1: 0.044486, loss_fp: 0.001888, loss_freq: 0.022088
[04:10:08.473] iteration 9680: loss: 0.093736, loss_s1: 0.072976, loss_fp: 0.006909, loss_freq: 0.028304
[04:10:09.064] iteration 9681: loss: 0.056204, loss_s1: 0.047545, loss_fp: 0.004458, loss_freq: 0.010606
[04:10:09.654] iteration 9682: loss: 0.064470, loss_s1: 0.029274, loss_fp: 0.003916, loss_freq: 0.027819
[04:10:10.248] iteration 9683: loss: 0.053943, loss_s1: 0.019703, loss_fp: 0.002831, loss_freq: 0.009736
[04:10:10.841] iteration 9684: loss: 0.067319, loss_s1: 0.050463, loss_fp: 0.002175, loss_freq: 0.032427
[04:10:11.436] iteration 9685: loss: 0.059712, loss_s1: 0.016425, loss_fp: 0.007878, loss_freq: 0.014828
[04:10:12.030] iteration 9686: loss: 0.102070, loss_s1: 0.101080, loss_fp: 0.008204, loss_freq: 0.032657
[04:10:12.622] iteration 9687: loss: 0.096333, loss_s1: 0.045634, loss_fp: 0.001039, loss_freq: 0.064622
[04:10:13.217] iteration 9688: loss: 0.073563, loss_s1: 0.061604, loss_fp: 0.002008, loss_freq: 0.027510
[04:10:13.803] iteration 9689: loss: 0.069470, loss_s1: 0.032403, loss_fp: 0.001207, loss_freq: 0.024193
[04:10:14.397] iteration 9690: loss: 0.083098, loss_s1: 0.059202, loss_fp: 0.006068, loss_freq: 0.052108
[04:10:15.283] iteration 9691: loss: 0.080051, loss_s1: 0.051637, loss_fp: 0.008315, loss_freq: 0.020582
[04:10:15.929] iteration 9692: loss: 0.072322, loss_s1: 0.017245, loss_fp: 0.001159, loss_freq: 0.064165
[04:10:16.569] iteration 9693: loss: 0.073895, loss_s1: 0.061641, loss_fp: 0.008241, loss_freq: 0.036126
[04:10:17.171] iteration 9694: loss: 0.057254, loss_s1: 0.040409, loss_fp: 0.004666, loss_freq: 0.015506
[04:10:17.837] iteration 9695: loss: 0.075925, loss_s1: 0.092703, loss_fp: 0.000359, loss_freq: 0.012042
[04:10:18.470] iteration 9696: loss: 0.069718, loss_s1: 0.035806, loss_fp: 0.006420, loss_freq: 0.041727
[04:10:19.103] iteration 9697: loss: 0.071059, loss_s1: 0.042588, loss_fp: 0.007139, loss_freq: 0.028793
[04:10:19.736] iteration 9698: loss: 0.058137, loss_s1: 0.041385, loss_fp: 0.004415, loss_freq: 0.022163
[04:10:20.365] iteration 9699: loss: 0.078964, loss_s1: 0.074349, loss_fp: 0.004994, loss_freq: 0.025706
[04:10:20.959] iteration 9700: loss: 0.089788, loss_s1: 0.092525, loss_fp: 0.002400, loss_freq: 0.025831
[04:10:21.552] iteration 9701: loss: 0.089404, loss_s1: 0.055806, loss_fp: 0.001902, loss_freq: 0.061496
[04:10:22.143] iteration 9702: loss: 0.079129, loss_s1: 0.050576, loss_fp: 0.001541, loss_freq: 0.041815
[04:10:22.737] iteration 9703: loss: 0.079893, loss_s1: 0.077115, loss_fp: 0.000603, loss_freq: 0.033088
[04:10:23.327] iteration 9704: loss: 0.117282, loss_s1: 0.106037, loss_fp: 0.005294, loss_freq: 0.063191
[04:10:23.921] iteration 9705: loss: 0.131563, loss_s1: 0.154234, loss_fp: 0.001030, loss_freq: 0.036794
[04:10:24.541] iteration 9706: loss: 0.064586, loss_s1: 0.045951, loss_fp: 0.003932, loss_freq: 0.030368
[04:10:25.131] iteration 9707: loss: 0.142722, loss_s1: 0.153910, loss_fp: 0.001011, loss_freq: 0.093261
[04:10:25.736] iteration 9708: loss: 0.072001, loss_s1: 0.073656, loss_fp: 0.000803, loss_freq: 0.009276
[04:10:26.326] iteration 9709: loss: 0.069739, loss_s1: 0.072369, loss_fp: 0.005988, loss_freq: 0.016208
[04:10:26.914] iteration 9710: loss: 0.108589, loss_s1: 0.098407, loss_fp: 0.002515, loss_freq: 0.024869
[04:10:27.507] iteration 9711: loss: 0.094735, loss_s1: 0.075650, loss_fp: 0.004297, loss_freq: 0.040290
[04:10:28.105] iteration 9712: loss: 0.149000, loss_s1: 0.087338, loss_fp: 0.003613, loss_freq: 0.049576
[04:10:28.696] iteration 9713: loss: 0.117416, loss_s1: 0.064588, loss_fp: 0.001345, loss_freq: 0.060208
[04:10:29.288] iteration 9714: loss: 0.084597, loss_s1: 0.057507, loss_fp: 0.001394, loss_freq: 0.044859
[04:10:29.887] iteration 9715: loss: 0.116726, loss_s1: 0.117152, loss_fp: 0.001822, loss_freq: 0.039718
[04:10:30.480] iteration 9716: loss: 0.098550, loss_s1: 0.081498, loss_fp: 0.005889, loss_freq: 0.053729
[04:10:31.110] iteration 9717: loss: 0.054931, loss_s1: 0.032503, loss_fp: 0.001977, loss_freq: 0.019314
[04:10:31.705] iteration 9718: loss: 0.109256, loss_s1: 0.106030, loss_fp: 0.002054, loss_freq: 0.033239
[04:10:32.321] iteration 9719: loss: 0.086067, loss_s1: 0.070903, loss_fp: 0.001097, loss_freq: 0.032156
[04:10:32.931] iteration 9720: loss: 0.118285, loss_s1: 0.094538, loss_fp: 0.002313, loss_freq: 0.082413
[04:10:33.619] iteration 9721: loss: 0.107613, loss_s1: 0.092299, loss_fp: 0.004262, loss_freq: 0.059909
[04:10:34.255] iteration 9722: loss: 0.086338, loss_s1: 0.058598, loss_fp: 0.002338, loss_freq: 0.052810
[04:10:34.896] iteration 9723: loss: 0.150919, loss_s1: 0.135835, loss_fp: 0.017048, loss_freq: 0.077932
[04:10:35.491] iteration 9724: loss: 0.051479, loss_s1: 0.026369, loss_fp: 0.002394, loss_freq: 0.010323
[04:10:36.079] iteration 9725: loss: 0.072669, loss_s1: 0.077257, loss_fp: 0.004886, loss_freq: 0.032167
[04:10:36.672] iteration 9726: loss: 0.068365, loss_s1: 0.042291, loss_fp: 0.000974, loss_freq: 0.040929
[04:10:37.264] iteration 9727: loss: 0.082753, loss_s1: 0.078905, loss_fp: 0.001473, loss_freq: 0.026945
[04:10:37.849] iteration 9728: loss: 0.052752, loss_s1: 0.043357, loss_fp: 0.001177, loss_freq: 0.016622
[04:10:38.439] iteration 9729: loss: 0.131723, loss_s1: 0.109456, loss_fp: 0.003778, loss_freq: 0.066960
[04:10:39.025] iteration 9730: loss: 0.108888, loss_s1: 0.098189, loss_fp: 0.002563, loss_freq: 0.034618
[04:10:39.616] iteration 9731: loss: 0.089832, loss_s1: 0.070257, loss_fp: 0.000653, loss_freq: 0.049296
[04:10:40.234] iteration 9732: loss: 0.088241, loss_s1: 0.074115, loss_fp: 0.001651, loss_freq: 0.041720
[04:10:40.830] iteration 9733: loss: 0.118737, loss_s1: 0.105986, loss_fp: 0.003273, loss_freq: 0.071731
[04:10:41.424] iteration 9734: loss: 0.116847, loss_s1: 0.103044, loss_fp: 0.006934, loss_freq: 0.077672
[04:10:42.019] iteration 9735: loss: 0.071364, loss_s1: 0.048621, loss_fp: 0.001771, loss_freq: 0.018387
[04:10:42.608] iteration 9736: loss: 0.059125, loss_s1: 0.043711, loss_fp: 0.010296, loss_freq: 0.013065
[04:10:43.204] iteration 9737: loss: 0.067446, loss_s1: 0.054200, loss_fp: 0.002560, loss_freq: 0.029615
[04:10:43.800] iteration 9738: loss: 0.061652, loss_s1: 0.025055, loss_fp: 0.008325, loss_freq: 0.013562
[04:10:44.384] iteration 9739: loss: 0.138044, loss_s1: 0.183958, loss_fp: 0.000935, loss_freq: 0.036540
[04:10:44.968] iteration 9740: loss: 0.069314, loss_s1: 0.055139, loss_fp: 0.001072, loss_freq: 0.033246
[04:10:45.600] iteration 9741: loss: 0.094064, loss_s1: 0.043545, loss_fp: 0.002085, loss_freq: 0.064086
[04:10:46.229] iteration 9742: loss: 0.072859, loss_s1: 0.072345, loss_fp: 0.003970, loss_freq: 0.032315
[04:10:46.858] iteration 9743: loss: 0.083845, loss_s1: 0.064713, loss_fp: 0.001084, loss_freq: 0.030011
[04:10:47.444] iteration 9744: loss: 0.100737, loss_s1: 0.109504, loss_fp: 0.003784, loss_freq: 0.026946
[04:10:48.038] iteration 9745: loss: 0.069698, loss_s1: 0.016234, loss_fp: 0.003447, loss_freq: 0.060156
[04:10:48.628] iteration 9746: loss: 0.074519, loss_s1: 0.067161, loss_fp: 0.000968, loss_freq: 0.026681
[04:10:49.219] iteration 9747: loss: 0.063044, loss_s1: 0.026228, loss_fp: 0.004480, loss_freq: 0.051418
[04:10:49.815] iteration 9748: loss: 0.080114, loss_s1: 0.069316, loss_fp: 0.004792, loss_freq: 0.019797
[04:10:50.406] iteration 9749: loss: 0.109856, loss_s1: 0.066940, loss_fp: 0.002215, loss_freq: 0.051535
[04:10:51.052] iteration 9750: loss: 0.087708, loss_s1: 0.054172, loss_fp: 0.005951, loss_freq: 0.060984
[04:10:51.684] iteration 9751: loss: 0.051350, loss_s1: 0.050672, loss_fp: 0.001971, loss_freq: 0.007563
[04:10:52.312] iteration 9752: loss: 0.123181, loss_s1: 0.066720, loss_fp: 0.011425, loss_freq: 0.043250
[04:10:52.941] iteration 9753: loss: 0.053589, loss_s1: 0.040701, loss_fp: 0.001816, loss_freq: 0.005279
[04:10:53.573] iteration 9754: loss: 0.065700, loss_s1: 0.056274, loss_fp: 0.002052, loss_freq: 0.018244
[04:10:54.170] iteration 9755: loss: 0.061716, loss_s1: 0.048667, loss_fp: 0.003367, loss_freq: 0.021779
[04:10:54.763] iteration 9756: loss: 0.062903, loss_s1: 0.062040, loss_fp: 0.001441, loss_freq: 0.029590
[04:10:55.395] iteration 9757: loss: 0.069146, loss_s1: 0.025218, loss_fp: 0.003963, loss_freq: 0.013277
[04:10:56.023] iteration 9758: loss: 0.122608, loss_s1: 0.103109, loss_fp: 0.009182, loss_freq: 0.079890
[04:10:56.651] iteration 9759: loss: 0.073953, loss_s1: 0.044919, loss_fp: 0.007372, loss_freq: 0.036331
[04:10:57.273] iteration 9760: loss: 0.111663, loss_s1: 0.102747, loss_fp: 0.008332, loss_freq: 0.041166
[04:10:57.868] iteration 9761: loss: 0.079036, loss_s1: 0.059389, loss_fp: 0.002412, loss_freq: 0.043295
[04:10:58.455] iteration 9762: loss: 0.058463, loss_s1: 0.022016, loss_fp: 0.007256, loss_freq: 0.029512
[04:10:59.044] iteration 9763: loss: 0.070939, loss_s1: 0.053454, loss_fp: 0.006731, loss_freq: 0.041488
[04:10:59.634] iteration 9764: loss: 0.143057, loss_s1: 0.120671, loss_fp: 0.005595, loss_freq: 0.083527
[04:11:00.227] iteration 9765: loss: 0.077877, loss_s1: 0.024604, loss_fp: 0.005908, loss_freq: 0.033839
[04:11:00.816] iteration 9766: loss: 0.086840, loss_s1: 0.058792, loss_fp: 0.002069, loss_freq: 0.041200
[04:11:01.407] iteration 9767: loss: 0.062204, loss_s1: 0.038692, loss_fp: 0.004126, loss_freq: 0.037885
[04:11:01.999] iteration 9768: loss: 0.077840, loss_s1: 0.066667, loss_fp: 0.008235, loss_freq: 0.032833
[04:11:02.591] iteration 9769: loss: 0.069987, loss_s1: 0.033975, loss_fp: 0.001901, loss_freq: 0.055203
[04:11:03.175] iteration 9770: loss: 0.064140, loss_s1: 0.039965, loss_fp: 0.004417, loss_freq: 0.017043
[04:11:03.767] iteration 9771: loss: 0.109514, loss_s1: 0.099766, loss_fp: 0.001318, loss_freq: 0.052485
[04:11:04.355] iteration 9772: loss: 0.069706, loss_s1: 0.060365, loss_fp: 0.004071, loss_freq: 0.017840
[04:11:04.947] iteration 9773: loss: 0.065366, loss_s1: 0.055739, loss_fp: 0.001839, loss_freq: 0.007334
[04:11:05.579] iteration 9774: loss: 0.101003, loss_s1: 0.080996, loss_fp: 0.004079, loss_freq: 0.040221
[04:11:06.217] iteration 9775: loss: 0.057281, loss_s1: 0.037225, loss_fp: 0.000639, loss_freq: 0.013905
[04:11:06.847] iteration 9776: loss: 0.067721, loss_s1: 0.036604, loss_fp: 0.003514, loss_freq: 0.038513
[04:11:07.465] iteration 9777: loss: 0.087683, loss_s1: 0.100040, loss_fp: 0.001459, loss_freq: 0.029094
[04:11:08.055] iteration 9778: loss: 0.086223, loss_s1: 0.062562, loss_fp: 0.001819, loss_freq: 0.038105
[04:11:08.642] iteration 9779: loss: 0.086298, loss_s1: 0.083308, loss_fp: 0.023637, loss_freq: 0.020680
[04:11:09.233] iteration 9780: loss: 0.072391, loss_s1: 0.048169, loss_fp: 0.005846, loss_freq: 0.028190
[04:11:09.823] iteration 9781: loss: 0.097471, loss_s1: 0.116621, loss_fp: 0.004039, loss_freq: 0.018104
[04:11:10.411] iteration 9782: loss: 0.081979, loss_s1: 0.055917, loss_fp: 0.002441, loss_freq: 0.060741
[04:11:11.001] iteration 9783: loss: 0.078641, loss_s1: 0.059925, loss_fp: 0.002247, loss_freq: 0.033841
[04:11:11.593] iteration 9784: loss: 0.076772, loss_s1: 0.056675, loss_fp: 0.003278, loss_freq: 0.036939
[04:11:12.188] iteration 9785: loss: 0.078402, loss_s1: 0.055709, loss_fp: 0.002116, loss_freq: 0.046704
[04:11:12.835] iteration 9786: loss: 0.079989, loss_s1: 0.090602, loss_fp: 0.002265, loss_freq: 0.029034
[04:11:13.467] iteration 9787: loss: 0.092306, loss_s1: 0.078145, loss_fp: 0.003432, loss_freq: 0.029549
[04:11:14.101] iteration 9788: loss: 0.077400, loss_s1: 0.048173, loss_fp: 0.001393, loss_freq: 0.035012
[04:11:14.717] iteration 9789: loss: 0.070550, loss_s1: 0.039028, loss_fp: 0.003530, loss_freq: 0.031677
[04:11:15.312] iteration 9790: loss: 0.058369, loss_s1: 0.037269, loss_fp: 0.003213, loss_freq: 0.031589
[04:11:15.901] iteration 9791: loss: 0.083748, loss_s1: 0.082594, loss_fp: 0.003737, loss_freq: 0.030611
[04:11:16.506] iteration 9792: loss: 0.091485, loss_s1: 0.038706, loss_fp: 0.002245, loss_freq: 0.049527
[04:11:17.101] iteration 9793: loss: 0.051491, loss_s1: 0.013062, loss_fp: 0.002920, loss_freq: 0.038722
[04:11:17.692] iteration 9794: loss: 0.064964, loss_s1: 0.046689, loss_fp: 0.002516, loss_freq: 0.015736
[04:11:18.324] iteration 9795: loss: 0.079064, loss_s1: 0.064709, loss_fp: 0.003299, loss_freq: 0.055925
[04:11:18.980] iteration 9796: loss: 0.081914, loss_s1: 0.059453, loss_fp: 0.008935, loss_freq: 0.043054
[04:11:19.610] iteration 9797: loss: 0.058121, loss_s1: 0.047354, loss_fp: 0.002695, loss_freq: 0.014955
[04:11:20.205] iteration 9798: loss: 0.062895, loss_s1: 0.043405, loss_fp: 0.001609, loss_freq: 0.030686
[04:11:20.801] iteration 9799: loss: 0.091020, loss_s1: 0.034427, loss_fp: 0.007344, loss_freq: 0.030319
[04:11:21.385] iteration 9800: loss: 0.103721, loss_s1: 0.107911, loss_fp: 0.008505, loss_freq: 0.024119
[04:11:24.637] iteration 9800 : mean_dice : 0.703653
[04:11:25.274] iteration 9801: loss: 0.077276, loss_s1: 0.063570, loss_fp: 0.008624, loss_freq: 0.028287
[04:11:25.896] iteration 9802: loss: 0.059650, loss_s1: 0.047337, loss_fp: 0.002633, loss_freq: 0.024420
[04:11:26.494] iteration 9803: loss: 0.056102, loss_s1: 0.037326, loss_fp: 0.001384, loss_freq: 0.026430
[04:11:27.088] iteration 9804: loss: 0.076074, loss_s1: 0.085321, loss_fp: 0.006331, loss_freq: 0.014968
[04:11:27.681] iteration 9805: loss: 0.136079, loss_s1: 0.131736, loss_fp: 0.004394, loss_freq: 0.079160
[04:11:28.310] iteration 9806: loss: 0.095611, loss_s1: 0.071141, loss_fp: 0.003371, loss_freq: 0.053638
[04:11:28.942] iteration 9807: loss: 0.090693, loss_s1: 0.104123, loss_fp: 0.002791, loss_freq: 0.032012
[04:11:29.577] iteration 9808: loss: 0.045299, loss_s1: 0.032972, loss_fp: 0.003264, loss_freq: 0.015529
[04:11:30.177] iteration 9809: loss: 0.080981, loss_s1: 0.035692, loss_fp: 0.002188, loss_freq: 0.068664
[04:11:30.771] iteration 9810: loss: 0.112784, loss_s1: 0.095661, loss_fp: 0.003225, loss_freq: 0.049962
[04:11:31.364] iteration 9811: loss: 0.081842, loss_s1: 0.048154, loss_fp: 0.001218, loss_freq: 0.030666
[04:11:31.960] iteration 9812: loss: 0.051125, loss_s1: 0.053983, loss_fp: 0.000985, loss_freq: 0.018063
[04:11:32.554] iteration 9813: loss: 0.112684, loss_s1: 0.098256, loss_fp: 0.017095, loss_freq: 0.062102
[04:11:33.143] iteration 9814: loss: 0.079916, loss_s1: 0.062349, loss_fp: 0.002559, loss_freq: 0.049484
[04:11:33.775] iteration 9815: loss: 0.075490, loss_s1: 0.055926, loss_fp: 0.001291, loss_freq: 0.022617
[04:11:34.402] iteration 9816: loss: 0.111418, loss_s1: 0.116804, loss_fp: 0.004275, loss_freq: 0.044665
[04:11:35.048] iteration 9817: loss: 0.073862, loss_s1: 0.064950, loss_fp: 0.002413, loss_freq: 0.045901
[04:11:35.678] iteration 9818: loss: 0.113412, loss_s1: 0.082754, loss_fp: 0.002427, loss_freq: 0.021712
[04:11:36.331] iteration 9819: loss: 0.096330, loss_s1: 0.070466, loss_fp: 0.001511, loss_freq: 0.017546
[04:11:36.969] iteration 9820: loss: 0.098316, loss_s1: 0.089974, loss_fp: 0.003776, loss_freq: 0.042543
[04:11:37.559] iteration 9821: loss: 0.050839, loss_s1: 0.047581, loss_fp: 0.003666, loss_freq: 0.016524
[04:11:38.154] iteration 9822: loss: 0.073664, loss_s1: 0.037401, loss_fp: 0.005336, loss_freq: 0.041764
[04:11:38.746] iteration 9823: loss: 0.121496, loss_s1: 0.106225, loss_fp: 0.002911, loss_freq: 0.056119
[04:11:39.333] iteration 9824: loss: 0.110547, loss_s1: 0.117332, loss_fp: 0.006670, loss_freq: 0.034343
[04:11:40.045] iteration 9825: loss: 0.100867, loss_s1: 0.113277, loss_fp: 0.006943, loss_freq: 0.030448
[04:11:40.640] iteration 9826: loss: 0.079936, loss_s1: 0.055994, loss_fp: 0.009100, loss_freq: 0.049101
[04:11:41.572] iteration 9827: loss: 0.078522, loss_s1: 0.056272, loss_fp: 0.005865, loss_freq: 0.032217
[04:11:42.174] iteration 9828: loss: 0.061492, loss_s1: 0.038389, loss_fp: 0.007512, loss_freq: 0.033947
[04:11:42.792] iteration 9829: loss: 0.092354, loss_s1: 0.072050, loss_fp: 0.010163, loss_freq: 0.053171
[04:11:43.423] iteration 9830: loss: 0.113302, loss_s1: 0.113170, loss_fp: 0.003638, loss_freq: 0.075711
[04:11:44.061] iteration 9831: loss: 0.118104, loss_s1: 0.097868, loss_fp: 0.007132, loss_freq: 0.039625
[04:11:44.661] iteration 9832: loss: 0.081984, loss_s1: 0.068796, loss_fp: 0.007131, loss_freq: 0.028143
[04:11:45.263] iteration 9833: loss: 0.107401, loss_s1: 0.073834, loss_fp: 0.007508, loss_freq: 0.031767
[04:11:45.864] iteration 9834: loss: 0.102467, loss_s1: 0.119793, loss_fp: 0.007435, loss_freq: 0.027276
[04:11:46.480] iteration 9835: loss: 0.064575, loss_s1: 0.022180, loss_fp: 0.000868, loss_freq: 0.050969
[04:11:47.075] iteration 9836: loss: 0.070733, loss_s1: 0.061951, loss_fp: 0.001257, loss_freq: 0.018087
[04:11:47.672] iteration 9837: loss: 0.087660, loss_s1: 0.070427, loss_fp: 0.015841, loss_freq: 0.042737
[04:11:48.268] iteration 9838: loss: 0.097263, loss_s1: 0.076358, loss_fp: 0.004850, loss_freq: 0.071197
[04:11:48.858] iteration 9839: loss: 0.086787, loss_s1: 0.081882, loss_fp: 0.008675, loss_freq: 0.043544
[04:11:49.452] iteration 9840: loss: 0.083638, loss_s1: 0.076452, loss_fp: 0.002578, loss_freq: 0.032450
[04:11:50.043] iteration 9841: loss: 0.093441, loss_s1: 0.090566, loss_fp: 0.002639, loss_freq: 0.031560
[04:11:50.637] iteration 9842: loss: 0.102266, loss_s1: 0.092325, loss_fp: 0.005515, loss_freq: 0.063499
[04:11:51.233] iteration 9843: loss: 0.138268, loss_s1: 0.118396, loss_fp: 0.006175, loss_freq: 0.088585
[04:11:51.832] iteration 9844: loss: 0.103395, loss_s1: 0.074326, loss_fp: 0.002484, loss_freq: 0.072633
[04:11:52.425] iteration 9845: loss: 0.119701, loss_s1: 0.089757, loss_fp: 0.006597, loss_freq: 0.069171
[04:11:53.021] iteration 9846: loss: 0.068516, loss_s1: 0.073162, loss_fp: 0.000860, loss_freq: 0.010588
[04:11:53.617] iteration 9847: loss: 0.084782, loss_s1: 0.033746, loss_fp: 0.003761, loss_freq: 0.059538
[04:11:54.208] iteration 9848: loss: 0.091339, loss_s1: 0.080590, loss_fp: 0.006570, loss_freq: 0.044563
[04:11:54.798] iteration 9849: loss: 0.074677, loss_s1: 0.077130, loss_fp: 0.002055, loss_freq: 0.019940
[04:11:55.399] iteration 9850: loss: 0.095729, loss_s1: 0.095392, loss_fp: 0.003343, loss_freq: 0.031780
[04:11:55.988] iteration 9851: loss: 0.062219, loss_s1: 0.062982, loss_fp: 0.004827, loss_freq: 0.009233
[04:11:56.586] iteration 9852: loss: 0.070203, loss_s1: 0.037153, loss_fp: 0.003881, loss_freq: 0.013881
[04:11:57.179] iteration 9853: loss: 0.058459, loss_s1: 0.015441, loss_fp: 0.001436, loss_freq: 0.031361
[04:11:57.774] iteration 9854: loss: 0.061870, loss_s1: 0.046437, loss_fp: 0.000969, loss_freq: 0.027386
[04:11:58.359] iteration 9855: loss: 0.055364, loss_s1: 0.045942, loss_fp: 0.002325, loss_freq: 0.012115
[04:11:58.948] iteration 9856: loss: 0.081921, loss_s1: 0.060855, loss_fp: 0.001924, loss_freq: 0.059630
[04:11:59.530] iteration 9857: loss: 0.084338, loss_s1: 0.042323, loss_fp: 0.005970, loss_freq: 0.049638
[04:12:00.117] iteration 9858: loss: 0.088457, loss_s1: 0.069205, loss_fp: 0.005852, loss_freq: 0.029660
[04:12:00.702] iteration 9859: loss: 0.100766, loss_s1: 0.055897, loss_fp: 0.002645, loss_freq: 0.068339
[04:12:01.291] iteration 9860: loss: 0.097596, loss_s1: 0.047829, loss_fp: 0.005549, loss_freq: 0.087249
[04:12:02.198] iteration 9861: loss: 0.089672, loss_s1: 0.083607, loss_fp: 0.008033, loss_freq: 0.022114
[04:12:02.812] iteration 9862: loss: 0.076819, loss_s1: 0.051953, loss_fp: 0.002865, loss_freq: 0.041116
[04:12:03.417] iteration 9863: loss: 0.080654, loss_s1: 0.077485, loss_fp: 0.000891, loss_freq: 0.038191
[04:12:04.025] iteration 9864: loss: 0.044704, loss_s1: 0.025001, loss_fp: 0.000400, loss_freq: 0.011373
[04:12:04.630] iteration 9865: loss: 0.055327, loss_s1: 0.023467, loss_fp: 0.005327, loss_freq: 0.026209
[04:12:05.242] iteration 9866: loss: 0.091525, loss_s1: 0.104150, loss_fp: 0.005133, loss_freq: 0.024256
[04:12:05.834] iteration 9867: loss: 0.132275, loss_s1: 0.164203, loss_fp: 0.003000, loss_freq: 0.043858
[04:12:06.427] iteration 9868: loss: 0.070600, loss_s1: 0.058558, loss_fp: 0.014087, loss_freq: 0.023035
[04:12:07.019] iteration 9869: loss: 0.080358, loss_s1: 0.046180, loss_fp: 0.001208, loss_freq: 0.051573
[04:12:07.618] iteration 9870: loss: 0.101083, loss_s1: 0.105642, loss_fp: 0.005799, loss_freq: 0.028222
[04:12:08.224] iteration 9871: loss: 0.099099, loss_s1: 0.046281, loss_fp: 0.001065, loss_freq: 0.067293
[04:12:08.821] iteration 9872: loss: 0.094683, loss_s1: 0.026361, loss_fp: 0.009563, loss_freq: 0.080720
[04:12:09.417] iteration 9873: loss: 0.075233, loss_s1: 0.053871, loss_fp: 0.003201, loss_freq: 0.038290
[04:12:10.008] iteration 9874: loss: 0.054748, loss_s1: 0.035969, loss_fp: 0.002353, loss_freq: 0.022122
[04:12:10.598] iteration 9875: loss: 0.109123, loss_s1: 0.118229, loss_fp: 0.002974, loss_freq: 0.042505
[04:12:11.185] iteration 9876: loss: 0.070740, loss_s1: 0.045635, loss_fp: 0.003345, loss_freq: 0.025209
[04:12:11.777] iteration 9877: loss: 0.134912, loss_s1: 0.146599, loss_fp: 0.009505, loss_freq: 0.063995
[04:12:12.368] iteration 9878: loss: 0.053837, loss_s1: 0.040471, loss_fp: 0.002280, loss_freq: 0.016565
[04:12:12.958] iteration 9879: loss: 0.073175, loss_s1: 0.071805, loss_fp: 0.003552, loss_freq: 0.023611
[04:12:13.550] iteration 9880: loss: 0.083515, loss_s1: 0.054545, loss_fp: 0.001416, loss_freq: 0.030510
[04:12:14.143] iteration 9881: loss: 0.061992, loss_s1: 0.031098, loss_fp: 0.003107, loss_freq: 0.043042
[04:12:14.737] iteration 9882: loss: 0.060258, loss_s1: 0.040124, loss_fp: 0.005063, loss_freq: 0.032773
[04:12:15.332] iteration 9883: loss: 0.129690, loss_s1: 0.055788, loss_fp: 0.001408, loss_freq: 0.048241
[04:12:15.965] iteration 9884: loss: 0.077559, loss_s1: 0.074430, loss_fp: 0.011565, loss_freq: 0.021952
[04:12:16.555] iteration 9885: loss: 0.141943, loss_s1: 0.208086, loss_fp: 0.001750, loss_freq: 0.029901
[04:12:17.220] iteration 9886: loss: 0.078031, loss_s1: 0.072107, loss_fp: 0.003387, loss_freq: 0.038745
[04:12:17.850] iteration 9887: loss: 0.081243, loss_s1: 0.083098, loss_fp: 0.004360, loss_freq: 0.022117
[04:12:18.441] iteration 9888: loss: 0.112328, loss_s1: 0.081251, loss_fp: 0.008545, loss_freq: 0.045862
[04:12:19.030] iteration 9889: loss: 0.131952, loss_s1: 0.062656, loss_fp: 0.008713, loss_freq: 0.037892
[04:12:19.615] iteration 9890: loss: 0.087117, loss_s1: 0.090717, loss_fp: 0.002071, loss_freq: 0.035432
[04:12:20.206] iteration 9891: loss: 0.070235, loss_s1: 0.032990, loss_fp: 0.001042, loss_freq: 0.053310
[04:12:20.797] iteration 9892: loss: 0.094054, loss_s1: 0.043105, loss_fp: 0.001036, loss_freq: 0.074284
[04:12:21.386] iteration 9893: loss: 0.120517, loss_s1: 0.095544, loss_fp: 0.003988, loss_freq: 0.091023
[04:12:21.982] iteration 9894: loss: 0.043619, loss_s1: 0.028999, loss_fp: 0.007434, loss_freq: 0.007517
[04:12:22.564] iteration 9895: loss: 0.068137, loss_s1: 0.055178, loss_fp: 0.005676, loss_freq: 0.037175
[04:12:23.179] iteration 9896: loss: 0.056290, loss_s1: 0.038490, loss_fp: 0.001348, loss_freq: 0.007129
[04:12:23.770] iteration 9897: loss: 0.097954, loss_s1: 0.098233, loss_fp: 0.000517, loss_freq: 0.022043
[04:12:24.361] iteration 9898: loss: 0.084524, loss_s1: 0.084400, loss_fp: 0.002084, loss_freq: 0.018327
[04:12:24.955] iteration 9899: loss: 0.119328, loss_s1: 0.108076, loss_fp: 0.002943, loss_freq: 0.067474
[04:12:25.544] iteration 9900: loss: 0.070709, loss_s1: 0.076180, loss_fp: 0.004514, loss_freq: 0.021197
[04:12:26.138] iteration 9901: loss: 0.125110, loss_s1: 0.122832, loss_fp: 0.001521, loss_freq: 0.059706
[04:12:26.749] iteration 9902: loss: 0.074754, loss_s1: 0.069860, loss_fp: 0.002361, loss_freq: 0.032019
[04:12:27.336] iteration 9903: loss: 0.102361, loss_s1: 0.069969, loss_fp: 0.008021, loss_freq: 0.073668
[04:12:27.929] iteration 9904: loss: 0.135566, loss_s1: 0.132919, loss_fp: 0.002232, loss_freq: 0.084472
[04:12:28.527] iteration 9905: loss: 0.087815, loss_s1: 0.068788, loss_fp: 0.005299, loss_freq: 0.026103
[04:12:29.122] iteration 9906: loss: 0.103298, loss_s1: 0.113457, loss_fp: 0.003546, loss_freq: 0.035033
[04:12:29.755] iteration 9907: loss: 0.065243, loss_s1: 0.059934, loss_fp: 0.002660, loss_freq: 0.027616
[04:12:30.392] iteration 9908: loss: 0.084204, loss_s1: 0.038821, loss_fp: 0.001271, loss_freq: 0.018617
[04:12:31.024] iteration 9909: loss: 0.087915, loss_s1: 0.091239, loss_fp: 0.002284, loss_freq: 0.024050
[04:12:31.652] iteration 9910: loss: 0.090862, loss_s1: 0.056254, loss_fp: 0.002411, loss_freq: 0.030763
[04:12:32.262] iteration 9911: loss: 0.105322, loss_s1: 0.080233, loss_fp: 0.003657, loss_freq: 0.056688
[04:12:32.851] iteration 9912: loss: 0.084285, loss_s1: 0.070983, loss_fp: 0.001610, loss_freq: 0.050632
[04:12:33.440] iteration 9913: loss: 0.089531, loss_s1: 0.072373, loss_fp: 0.001133, loss_freq: 0.049282
[04:12:34.033] iteration 9914: loss: 0.092869, loss_s1: 0.060013, loss_fp: 0.006849, loss_freq: 0.067751
[04:12:34.625] iteration 9915: loss: 0.097538, loss_s1: 0.047161, loss_fp: 0.003392, loss_freq: 0.071696
[04:12:35.215] iteration 9916: loss: 0.045821, loss_s1: 0.020303, loss_fp: 0.001624, loss_freq: 0.012987
[04:12:35.817] iteration 9917: loss: 0.087272, loss_s1: 0.104202, loss_fp: 0.005116, loss_freq: 0.029795
[04:12:36.457] iteration 9918: loss: 0.091919, loss_s1: 0.061237, loss_fp: 0.002526, loss_freq: 0.028399
[04:12:37.048] iteration 9919: loss: 0.124858, loss_s1: 0.086197, loss_fp: 0.004794, loss_freq: 0.046091
[04:12:37.638] iteration 9920: loss: 0.102863, loss_s1: 0.064996, loss_fp: 0.003233, loss_freq: 0.050708
[04:12:38.224] iteration 9921: loss: 0.049838, loss_s1: 0.036624, loss_fp: 0.002688, loss_freq: 0.022836
[04:12:38.810] iteration 9922: loss: 0.118964, loss_s1: 0.045531, loss_fp: 0.009308, loss_freq: 0.047666
[04:12:39.405] iteration 9923: loss: 0.049362, loss_s1: 0.039422, loss_fp: 0.003580, loss_freq: 0.009643
[04:12:39.993] iteration 9924: loss: 0.058911, loss_s1: 0.035736, loss_fp: 0.002464, loss_freq: 0.033961
[04:12:40.578] iteration 9925: loss: 0.112060, loss_s1: 0.110255, loss_fp: 0.006629, loss_freq: 0.038152
[04:12:41.172] iteration 9926: loss: 0.112189, loss_s1: 0.122337, loss_fp: 0.002735, loss_freq: 0.048858
[04:12:41.764] iteration 9927: loss: 0.073616, loss_s1: 0.061824, loss_fp: 0.001655, loss_freq: 0.006718
[04:12:42.351] iteration 9928: loss: 0.145582, loss_s1: 0.127548, loss_fp: 0.004697, loss_freq: 0.061901
[04:12:42.939] iteration 9929: loss: 0.054030, loss_s1: 0.024503, loss_fp: 0.000639, loss_freq: 0.017477
[04:12:43.527] iteration 9930: loss: 0.102875, loss_s1: 0.071683, loss_fp: 0.009081, loss_freq: 0.055780
[04:12:44.116] iteration 9931: loss: 0.092984, loss_s1: 0.088181, loss_fp: 0.004013, loss_freq: 0.019710
[04:12:44.704] iteration 9932: loss: 0.080750, loss_s1: 0.035204, loss_fp: 0.005566, loss_freq: 0.024745
[04:12:45.291] iteration 9933: loss: 0.081630, loss_s1: 0.044523, loss_fp: 0.002521, loss_freq: 0.056805
[04:12:45.884] iteration 9934: loss: 0.061120, loss_s1: 0.043863, loss_fp: 0.006754, loss_freq: 0.019884
[04:12:46.474] iteration 9935: loss: 0.122163, loss_s1: 0.103083, loss_fp: 0.001951, loss_freq: 0.047186
[04:12:47.059] iteration 9936: loss: 0.097047, loss_s1: 0.052067, loss_fp: 0.002416, loss_freq: 0.065405
[04:12:47.645] iteration 9937: loss: 0.085287, loss_s1: 0.063263, loss_fp: 0.010606, loss_freq: 0.020776
[04:12:48.231] iteration 9938: loss: 0.082876, loss_s1: 0.075876, loss_fp: 0.009119, loss_freq: 0.029437
[04:12:48.818] iteration 9939: loss: 0.073734, loss_s1: 0.065281, loss_fp: 0.003917, loss_freq: 0.033023
[04:12:49.408] iteration 9940: loss: 0.054938, loss_s1: 0.020507, loss_fp: 0.005040, loss_freq: 0.013712
[04:12:50.042] iteration 9941: loss: 0.094582, loss_s1: 0.094818, loss_fp: 0.001471, loss_freq: 0.030004
[04:12:50.674] iteration 9942: loss: 0.068552, loss_s1: 0.031678, loss_fp: 0.009994, loss_freq: 0.052165
[04:12:51.309] iteration 9943: loss: 0.143686, loss_s1: 0.163688, loss_fp: 0.004014, loss_freq: 0.045490
[04:12:51.938] iteration 9944: loss: 0.067284, loss_s1: 0.073471, loss_fp: 0.003196, loss_freq: 0.007583
[04:12:52.560] iteration 9945: loss: 0.073895, loss_s1: 0.062766, loss_fp: 0.002175, loss_freq: 0.038688
[04:12:53.153] iteration 9946: loss: 0.087460, loss_s1: 0.084679, loss_fp: 0.003530, loss_freq: 0.031954
[04:12:53.742] iteration 9947: loss: 0.078670, loss_s1: 0.094888, loss_fp: 0.002192, loss_freq: 0.023985
[04:12:54.331] iteration 9948: loss: 0.083199, loss_s1: 0.048537, loss_fp: 0.001462, loss_freq: 0.044550
[04:12:54.917] iteration 9949: loss: 0.106974, loss_s1: 0.044728, loss_fp: 0.006528, loss_freq: 0.107974
[04:12:55.508] iteration 9950: loss: 0.079472, loss_s1: 0.019837, loss_fp: 0.002896, loss_freq: 0.040683
[04:12:56.100] iteration 9951: loss: 0.090879, loss_s1: 0.079892, loss_fp: 0.011169, loss_freq: 0.014619
[04:12:56.711] iteration 9952: loss: 0.063325, loss_s1: 0.030918, loss_fp: 0.001230, loss_freq: 0.052555
[04:12:57.299] iteration 9953: loss: 0.078825, loss_s1: 0.069237, loss_fp: 0.003379, loss_freq: 0.024130
[04:12:57.887] iteration 9954: loss: 0.061449, loss_s1: 0.050932, loss_fp: 0.005084, loss_freq: 0.013038
[04:12:58.474] iteration 9955: loss: 0.085638, loss_s1: 0.088229, loss_fp: 0.000801, loss_freq: 0.039730
[04:12:59.064] iteration 9956: loss: 0.051010, loss_s1: 0.044716, loss_fp: 0.002101, loss_freq: 0.023733
[04:12:59.655] iteration 9957: loss: 0.090685, loss_s1: 0.048533, loss_fp: 0.002238, loss_freq: 0.070096
[04:13:00.246] iteration 9958: loss: 0.057579, loss_s1: 0.042564, loss_fp: 0.003348, loss_freq: 0.020421
[04:13:00.838] iteration 9959: loss: 0.094646, loss_s1: 0.075469, loss_fp: 0.004733, loss_freq: 0.033471
[04:13:01.427] iteration 9960: loss: 0.090182, loss_s1: 0.063219, loss_fp: 0.002939, loss_freq: 0.045405
[04:13:02.014] iteration 9961: loss: 0.076332, loss_s1: 0.078971, loss_fp: 0.002574, loss_freq: 0.026413
[04:13:02.604] iteration 9962: loss: 0.092148, loss_s1: 0.060744, loss_fp: 0.003463, loss_freq: 0.028633
[04:13:03.195] iteration 9963: loss: 0.044936, loss_s1: 0.027292, loss_fp: 0.005409, loss_freq: 0.019845
[04:13:03.782] iteration 9964: loss: 0.045394, loss_s1: 0.013271, loss_fp: 0.001561, loss_freq: 0.024459
[04:13:04.371] iteration 9965: loss: 0.079340, loss_s1: 0.037366, loss_fp: 0.004568, loss_freq: 0.067026
[04:13:04.961] iteration 9966: loss: 0.068491, loss_s1: 0.050905, loss_fp: 0.004547, loss_freq: 0.027616
[04:13:05.616] iteration 9967: loss: 0.071608, loss_s1: 0.054736, loss_fp: 0.002475, loss_freq: 0.029998
[04:13:06.255] iteration 9968: loss: 0.058105, loss_s1: 0.019471, loss_fp: 0.001277, loss_freq: 0.022781
[04:13:06.885] iteration 9969: loss: 0.133986, loss_s1: 0.096255, loss_fp: 0.005037, loss_freq: 0.118353
[04:13:07.490] iteration 9970: loss: 0.080686, loss_s1: 0.042846, loss_fp: 0.001644, loss_freq: 0.037265
[04:13:08.078] iteration 9971: loss: 0.085247, loss_s1: 0.067504, loss_fp: 0.002871, loss_freq: 0.040868
[04:13:08.696] iteration 9972: loss: 0.057032, loss_s1: 0.045893, loss_fp: 0.004117, loss_freq: 0.015856
[04:13:09.294] iteration 9973: loss: 0.059442, loss_s1: 0.051630, loss_fp: 0.001407, loss_freq: 0.029725
[04:13:09.885] iteration 9974: loss: 0.044396, loss_s1: 0.034469, loss_fp: 0.002570, loss_freq: 0.014997
[04:13:10.483] iteration 9975: loss: 0.150202, loss_s1: 0.151028, loss_fp: 0.004839, loss_freq: 0.080275
[04:13:11.086] iteration 9976: loss: 0.065777, loss_s1: 0.029812, loss_fp: 0.003748, loss_freq: 0.045897
[04:13:11.724] iteration 9977: loss: 0.069299, loss_s1: 0.055321, loss_fp: 0.002924, loss_freq: 0.017265
[04:13:12.364] iteration 9978: loss: 0.063522, loss_s1: 0.061324, loss_fp: 0.000591, loss_freq: 0.019545
[04:13:13.001] iteration 9979: loss: 0.091161, loss_s1: 0.043232, loss_fp: 0.002134, loss_freq: 0.064120
[04:13:13.637] iteration 9980: loss: 0.070448, loss_s1: 0.070607, loss_fp: 0.001659, loss_freq: 0.020166
[04:13:14.286] iteration 9981: loss: 0.062663, loss_s1: 0.046943, loss_fp: 0.000398, loss_freq: 0.015557
[04:13:14.912] iteration 9982: loss: 0.064918, loss_s1: 0.040736, loss_fp: 0.003541, loss_freq: 0.025909
[04:13:15.516] iteration 9983: loss: 0.114320, loss_s1: 0.090197, loss_fp: 0.007379, loss_freq: 0.070262
[04:13:16.110] iteration 9984: loss: 0.068165, loss_s1: 0.073583, loss_fp: 0.006515, loss_freq: 0.016134
[04:13:16.701] iteration 9985: loss: 0.065165, loss_s1: 0.028376, loss_fp: 0.002947, loss_freq: 0.037675
[04:13:17.295] iteration 9986: loss: 0.063820, loss_s1: 0.053660, loss_fp: 0.001895, loss_freq: 0.017342
[04:13:17.884] iteration 9987: loss: 0.090013, loss_s1: 0.041162, loss_fp: 0.001392, loss_freq: 0.087190
[04:13:18.478] iteration 9988: loss: 0.103040, loss_s1: 0.080881, loss_fp: 0.003253, loss_freq: 0.042979
[04:13:19.074] iteration 9989: loss: 0.068405, loss_s1: 0.061200, loss_fp: 0.004124, loss_freq: 0.030206
[04:13:19.659] iteration 9990: loss: 0.083909, loss_s1: 0.076592, loss_fp: 0.007564, loss_freq: 0.046636
[04:13:20.249] iteration 9991: loss: 0.064453, loss_s1: 0.081909, loss_fp: 0.001778, loss_freq: 0.014060
[04:13:20.868] iteration 9992: loss: 0.085041, loss_s1: 0.046185, loss_fp: 0.001148, loss_freq: 0.044972
[04:13:21.465] iteration 9993: loss: 0.129863, loss_s1: 0.163199, loss_fp: 0.002316, loss_freq: 0.042889
[04:13:22.044] iteration 9994: loss: 0.094094, loss_s1: 0.064495, loss_fp: 0.006970, loss_freq: 0.058612
[04:13:22.627] iteration 9995: loss: 0.122369, loss_s1: 0.034369, loss_fp: 0.000896, loss_freq: 0.156050
[04:13:23.252] iteration 9996: loss: 0.045621, loss_s1: 0.031569, loss_fp: 0.002981, loss_freq: 0.016640
[04:13:23.883] iteration 9997: loss: 0.072067, loss_s1: 0.039783, loss_fp: 0.002684, loss_freq: 0.015787
[04:13:24.511] iteration 9998: loss: 0.114738, loss_s1: 0.117433, loss_fp: 0.002969, loss_freq: 0.056210
[04:13:25.154] iteration 9999: loss: 0.108327, loss_s1: 0.099583, loss_fp: 0.004125, loss_freq: 0.062009
[04:13:25.739] iteration 10000: loss: 0.089084, loss_s1: 0.060493, loss_fp: 0.001066, loss_freq: 0.055675
[04:13:28.875] iteration 10000 : mean_dice : 0.697417
[04:13:29.502] iteration 10001: loss: 0.104364, loss_s1: 0.119801, loss_fp: 0.004905, loss_freq: 0.029926
[04:13:30.095] iteration 10002: loss: 0.107194, loss_s1: 0.097783, loss_fp: 0.002931, loss_freq: 0.053826
[04:13:30.684] iteration 10003: loss: 0.069378, loss_s1: 0.054720, loss_fp: 0.001942, loss_freq: 0.036820
[04:13:31.273] iteration 10004: loss: 0.079005, loss_s1: 0.062173, loss_fp: 0.000521, loss_freq: 0.031417
[04:13:31.866] iteration 10005: loss: 0.046970, loss_s1: 0.027614, loss_fp: 0.008353, loss_freq: 0.015993
[04:13:32.454] iteration 10006: loss: 0.071702, loss_s1: 0.052454, loss_fp: 0.011280, loss_freq: 0.024493
[04:13:33.041] iteration 10007: loss: 0.103828, loss_s1: 0.055307, loss_fp: 0.003771, loss_freq: 0.050618
[04:13:33.628] iteration 10008: loss: 0.140111, loss_s1: 0.139573, loss_fp: 0.017281, loss_freq: 0.057145
[04:13:34.219] iteration 10009: loss: 0.071434, loss_s1: 0.055471, loss_fp: 0.007720, loss_freq: 0.047696
[04:13:34.807] iteration 10010: loss: 0.136209, loss_s1: 0.094446, loss_fp: 0.006334, loss_freq: 0.087804
[04:13:35.393] iteration 10011: loss: 0.115348, loss_s1: 0.078134, loss_fp: 0.017218, loss_freq: 0.047477
[04:13:35.984] iteration 10012: loss: 0.093996, loss_s1: 0.061617, loss_fp: 0.002821, loss_freq: 0.076235
[04:13:36.575] iteration 10013: loss: 0.089492, loss_s1: 0.062947, loss_fp: 0.006128, loss_freq: 0.062604
[04:13:37.164] iteration 10014: loss: 0.083459, loss_s1: 0.066066, loss_fp: 0.007910, loss_freq: 0.031310
[04:13:37.753] iteration 10015: loss: 0.106780, loss_s1: 0.076142, loss_fp: 0.004325, loss_freq: 0.065517
[04:13:38.340] iteration 10016: loss: 0.058727, loss_s1: 0.030615, loss_fp: 0.004180, loss_freq: 0.021507
[04:13:38.924] iteration 10017: loss: 0.074151, loss_s1: 0.057753, loss_fp: 0.002280, loss_freq: 0.029566
[04:13:39.512] iteration 10018: loss: 0.110985, loss_s1: 0.051673, loss_fp: 0.004179, loss_freq: 0.092712
[04:13:40.106] iteration 10019: loss: 0.073725, loss_s1: 0.064054, loss_fp: 0.001490, loss_freq: 0.036591
[04:13:40.690] iteration 10020: loss: 0.102581, loss_s1: 0.078068, loss_fp: 0.004374, loss_freq: 0.050477
[04:13:41.273] iteration 10021: loss: 0.057678, loss_s1: 0.057002, loss_fp: 0.001532, loss_freq: 0.006561
[04:13:41.859] iteration 10022: loss: 0.051122, loss_s1: 0.026563, loss_fp: 0.001475, loss_freq: 0.024160
[04:13:42.518] iteration 10023: loss: 0.072003, loss_s1: 0.035486, loss_fp: 0.002003, loss_freq: 0.026789
[04:13:43.204] iteration 10024: loss: 0.062983, loss_s1: 0.058167, loss_fp: 0.003037, loss_freq: 0.033008
[04:13:43.878] iteration 10025: loss: 0.053071, loss_s1: 0.037059, loss_fp: 0.001137, loss_freq: 0.022857
[04:13:44.529] iteration 10026: loss: 0.080390, loss_s1: 0.061725, loss_fp: 0.002072, loss_freq: 0.046405
[04:13:45.134] iteration 10027: loss: 0.066163, loss_s1: 0.045692, loss_fp: 0.002206, loss_freq: 0.022992
[04:13:45.745] iteration 10028: loss: 0.121247, loss_s1: 0.142436, loss_fp: 0.009062, loss_freq: 0.034628
[04:13:46.335] iteration 10029: loss: 0.119664, loss_s1: 0.083174, loss_fp: 0.010588, loss_freq: 0.065554
[04:13:46.955] iteration 10030: loss: 0.112237, loss_s1: 0.104872, loss_fp: 0.005140, loss_freq: 0.049879
[04:13:47.907] iteration 10031: loss: 0.072894, loss_s1: 0.036426, loss_fp: 0.001603, loss_freq: 0.052685
[04:13:48.498] iteration 10032: loss: 0.062766, loss_s1: 0.043415, loss_fp: 0.000990, loss_freq: 0.025458
[04:13:49.090] iteration 10033: loss: 0.083777, loss_s1: 0.086576, loss_fp: 0.004885, loss_freq: 0.030161
[04:13:49.688] iteration 10034: loss: 0.071819, loss_s1: 0.065412, loss_fp: 0.002270, loss_freq: 0.018719
[04:13:50.282] iteration 10035: loss: 0.101958, loss_s1: 0.100246, loss_fp: 0.002550, loss_freq: 0.039286
[04:13:50.874] iteration 10036: loss: 0.069787, loss_s1: 0.056326, loss_fp: 0.004105, loss_freq: 0.017171
[04:13:51.464] iteration 10037: loss: 0.065997, loss_s1: 0.051324, loss_fp: 0.003555, loss_freq: 0.035414
[04:13:52.053] iteration 10038: loss: 0.079897, loss_s1: 0.061366, loss_fp: 0.005093, loss_freq: 0.028504
[04:13:52.656] iteration 10039: loss: 0.070209, loss_s1: 0.058094, loss_fp: 0.001806, loss_freq: 0.040086
[04:13:53.247] iteration 10040: loss: 0.094741, loss_s1: 0.077987, loss_fp: 0.003946, loss_freq: 0.042214
[04:13:53.837] iteration 10041: loss: 0.082684, loss_s1: 0.049786, loss_fp: 0.001805, loss_freq: 0.051037
[04:13:54.429] iteration 10042: loss: 0.075615, loss_s1: 0.027555, loss_fp: 0.005459, loss_freq: 0.066948
[04:13:55.020] iteration 10043: loss: 0.062625, loss_s1: 0.036336, loss_fp: 0.005935, loss_freq: 0.037814
[04:13:55.617] iteration 10044: loss: 0.062698, loss_s1: 0.035621, loss_fp: 0.002970, loss_freq: 0.040169
[04:13:56.213] iteration 10045: loss: 0.050144, loss_s1: 0.026334, loss_fp: 0.000738, loss_freq: 0.020116
[04:13:56.804] iteration 10046: loss: 0.077977, loss_s1: 0.052742, loss_fp: 0.002047, loss_freq: 0.039466
[04:13:57.394] iteration 10047: loss: 0.152330, loss_s1: 0.153558, loss_fp: 0.002486, loss_freq: 0.096726
[04:13:57.986] iteration 10048: loss: 0.089346, loss_s1: 0.068185, loss_fp: 0.001175, loss_freq: 0.020419
[04:13:58.575] iteration 10049: loss: 0.092444, loss_s1: 0.105273, loss_fp: 0.007389, loss_freq: 0.025225
[04:13:59.163] iteration 10050: loss: 0.087609, loss_s1: 0.075939, loss_fp: 0.004986, loss_freq: 0.014441
[04:13:59.749] iteration 10051: loss: 0.069356, loss_s1: 0.049553, loss_fp: 0.000656, loss_freq: 0.045823
[04:14:00.340] iteration 10052: loss: 0.078245, loss_s1: 0.080467, loss_fp: 0.002419, loss_freq: 0.031697
[04:14:00.924] iteration 10053: loss: 0.086948, loss_s1: 0.045947, loss_fp: 0.000903, loss_freq: 0.046539
[04:14:01.514] iteration 10054: loss: 0.059413, loss_s1: 0.053466, loss_fp: 0.004582, loss_freq: 0.019362
[04:14:02.105] iteration 10055: loss: 0.061835, loss_s1: 0.044995, loss_fp: 0.003458, loss_freq: 0.032582
[04:14:02.694] iteration 10056: loss: 0.093044, loss_s1: 0.073632, loss_fp: 0.003104, loss_freq: 0.074249
[04:14:03.286] iteration 10057: loss: 0.079831, loss_s1: 0.037136, loss_fp: 0.003760, loss_freq: 0.053259
[04:14:03.876] iteration 10058: loss: 0.095720, loss_s1: 0.101227, loss_fp: 0.003799, loss_freq: 0.017822
[04:14:04.474] iteration 10059: loss: 0.065427, loss_s1: 0.038084, loss_fp: 0.002689, loss_freq: 0.021739
[04:14:05.061] iteration 10060: loss: 0.089408, loss_s1: 0.080689, loss_fp: 0.009163, loss_freq: 0.038512
[04:14:05.650] iteration 10061: loss: 0.073274, loss_s1: 0.036853, loss_fp: 0.013687, loss_freq: 0.028875
[04:14:06.244] iteration 10062: loss: 0.126589, loss_s1: 0.129124, loss_fp: 0.001086, loss_freq: 0.065859
[04:14:06.836] iteration 10063: loss: 0.100008, loss_s1: 0.099606, loss_fp: 0.005900, loss_freq: 0.038776
[04:14:07.430] iteration 10064: loss: 0.055787, loss_s1: 0.043753, loss_fp: 0.006251, loss_freq: 0.014764
[04:14:08.026] iteration 10065: loss: 0.054891, loss_s1: 0.038071, loss_fp: 0.002521, loss_freq: 0.035034
[04:14:08.616] iteration 10066: loss: 0.068208, loss_s1: 0.052083, loss_fp: 0.002288, loss_freq: 0.026098
[04:14:09.210] iteration 10067: loss: 0.086528, loss_s1: 0.061279, loss_fp: 0.004720, loss_freq: 0.049524
[04:14:09.809] iteration 10068: loss: 0.083739, loss_s1: 0.070796, loss_fp: 0.011297, loss_freq: 0.039958
[04:14:10.403] iteration 10069: loss: 0.093379, loss_s1: 0.078948, loss_fp: 0.004402, loss_freq: 0.043781
[04:14:10.995] iteration 10070: loss: 0.076521, loss_s1: 0.046889, loss_fp: 0.005992, loss_freq: 0.045187
[04:14:11.591] iteration 10071: loss: 0.111924, loss_s1: 0.074288, loss_fp: 0.002684, loss_freq: 0.058679
[04:14:12.192] iteration 10072: loss: 0.093202, loss_s1: 0.058843, loss_fp: 0.004464, loss_freq: 0.041344
[04:14:12.786] iteration 10073: loss: 0.098155, loss_s1: 0.119905, loss_fp: 0.002829, loss_freq: 0.029343
[04:14:13.384] iteration 10074: loss: 0.115329, loss_s1: 0.091558, loss_fp: 0.005633, loss_freq: 0.063627
[04:14:13.979] iteration 10075: loss: 0.077058, loss_s1: 0.032597, loss_fp: 0.001398, loss_freq: 0.072704
[04:14:14.686] iteration 10076: loss: 0.063297, loss_s1: 0.039289, loss_fp: 0.001483, loss_freq: 0.029245
[04:14:15.276] iteration 10077: loss: 0.067460, loss_s1: 0.066616, loss_fp: 0.001335, loss_freq: 0.020305
[04:14:15.870] iteration 10078: loss: 0.061506, loss_s1: 0.048832, loss_fp: 0.002430, loss_freq: 0.016578
[04:14:16.462] iteration 10079: loss: 0.050196, loss_s1: 0.033271, loss_fp: 0.001815, loss_freq: 0.015822
[04:14:17.058] iteration 10080: loss: 0.093584, loss_s1: 0.055509, loss_fp: 0.001008, loss_freq: 0.056524
[04:14:17.650] iteration 10081: loss: 0.110414, loss_s1: 0.069017, loss_fp: 0.002685, loss_freq: 0.041878
[04:14:18.238] iteration 10082: loss: 0.122798, loss_s1: 0.114766, loss_fp: 0.006701, loss_freq: 0.078785
[04:14:18.829] iteration 10083: loss: 0.102089, loss_s1: 0.046162, loss_fp: 0.002044, loss_freq: 0.038824
[04:14:19.422] iteration 10084: loss: 0.121481, loss_s1: 0.078335, loss_fp: 0.005804, loss_freq: 0.103699
[04:14:20.009] iteration 10085: loss: 0.101965, loss_s1: 0.077909, loss_fp: 0.004587, loss_freq: 0.053558
[04:14:20.598] iteration 10086: loss: 0.043918, loss_s1: 0.010870, loss_fp: 0.000684, loss_freq: 0.031581
[04:14:21.189] iteration 10087: loss: 0.075017, loss_s1: 0.040495, loss_fp: 0.006690, loss_freq: 0.038847
[04:14:21.787] iteration 10088: loss: 0.065116, loss_s1: 0.048002, loss_fp: 0.003885, loss_freq: 0.021114
[04:14:22.384] iteration 10089: loss: 0.083407, loss_s1: 0.068764, loss_fp: 0.001569, loss_freq: 0.053054
[04:14:22.980] iteration 10090: loss: 0.090525, loss_s1: 0.084751, loss_fp: 0.005439, loss_freq: 0.039423
[04:14:23.578] iteration 10091: loss: 0.070215, loss_s1: 0.065562, loss_fp: 0.002192, loss_freq: 0.015110
[04:14:24.176] iteration 10092: loss: 0.089316, loss_s1: 0.075536, loss_fp: 0.003780, loss_freq: 0.040142
[04:14:24.772] iteration 10093: loss: 0.042978, loss_s1: 0.022480, loss_fp: 0.000672, loss_freq: 0.009455
[04:14:25.368] iteration 10094: loss: 0.059097, loss_s1: 0.026463, loss_fp: 0.001798, loss_freq: 0.016136
[04:14:25.961] iteration 10095: loss: 0.071346, loss_s1: 0.041539, loss_fp: 0.010123, loss_freq: 0.027800
[04:14:26.547] iteration 10096: loss: 0.060406, loss_s1: 0.040950, loss_fp: 0.001065, loss_freq: 0.033698
[04:14:27.143] iteration 10097: loss: 0.071490, loss_s1: 0.035366, loss_fp: 0.003178, loss_freq: 0.011542
[04:14:27.740] iteration 10098: loss: 0.114002, loss_s1: 0.107749, loss_fp: 0.003119, loss_freq: 0.065546
[04:14:28.361] iteration 10099: loss: 0.061560, loss_s1: 0.044949, loss_fp: 0.003592, loss_freq: 0.032507
[04:14:28.988] iteration 10100: loss: 0.090936, loss_s1: 0.090883, loss_fp: 0.010433, loss_freq: 0.039720
[04:14:29.624] iteration 10101: loss: 0.097163, loss_s1: 0.045247, loss_fp: 0.004534, loss_freq: 0.049777
[04:14:30.261] iteration 10102: loss: 0.069027, loss_s1: 0.055482, loss_fp: 0.001886, loss_freq: 0.022404
[04:14:30.898] iteration 10103: loss: 0.093786, loss_s1: 0.091517, loss_fp: 0.005820, loss_freq: 0.045213
[04:14:31.530] iteration 10104: loss: 0.112554, loss_s1: 0.129728, loss_fp: 0.005516, loss_freq: 0.028328
[04:14:32.167] iteration 10105: loss: 0.104986, loss_s1: 0.111374, loss_fp: 0.001826, loss_freq: 0.051585
[04:14:32.799] iteration 10106: loss: 0.073996, loss_s1: 0.028895, loss_fp: 0.012548, loss_freq: 0.055208
[04:14:33.404] iteration 10107: loss: 0.086111, loss_s1: 0.048049, loss_fp: 0.003428, loss_freq: 0.027249
[04:14:34.001] iteration 10108: loss: 0.069330, loss_s1: 0.052495, loss_fp: 0.003009, loss_freq: 0.037695
[04:14:34.599] iteration 10109: loss: 0.068322, loss_s1: 0.050456, loss_fp: 0.004184, loss_freq: 0.042171
[04:14:35.196] iteration 10110: loss: 0.100807, loss_s1: 0.071793, loss_fp: 0.002002, loss_freq: 0.036907
[04:14:35.797] iteration 10111: loss: 0.120671, loss_s1: 0.127000, loss_fp: 0.000364, loss_freq: 0.037110
[04:14:36.396] iteration 10112: loss: 0.046111, loss_s1: 0.031061, loss_fp: 0.003102, loss_freq: 0.017687
[04:14:36.992] iteration 10113: loss: 0.080691, loss_s1: 0.074359, loss_fp: 0.006901, loss_freq: 0.040051
[04:14:37.588] iteration 10114: loss: 0.104712, loss_s1: 0.129273, loss_fp: 0.001803, loss_freq: 0.017448
[04:14:38.181] iteration 10115: loss: 0.076198, loss_s1: 0.033957, loss_fp: 0.009545, loss_freq: 0.043564
[04:14:38.771] iteration 10116: loss: 0.046595, loss_s1: 0.029758, loss_fp: 0.003161, loss_freq: 0.019192
[04:14:39.361] iteration 10117: loss: 0.088317, loss_s1: 0.099419, loss_fp: 0.001527, loss_freq: 0.027696
[04:14:39.953] iteration 10118: loss: 0.068907, loss_s1: 0.065581, loss_fp: 0.004785, loss_freq: 0.019395
[04:14:40.546] iteration 10119: loss: 0.093345, loss_s1: 0.080487, loss_fp: 0.002464, loss_freq: 0.058479
[04:14:41.140] iteration 10120: loss: 0.084714, loss_s1: 0.074264, loss_fp: 0.001080, loss_freq: 0.036403
[04:14:41.731] iteration 10121: loss: 0.086444, loss_s1: 0.110870, loss_fp: 0.000912, loss_freq: 0.019366
[04:14:42.328] iteration 10122: loss: 0.076047, loss_s1: 0.055627, loss_fp: 0.002611, loss_freq: 0.050129
[04:14:42.926] iteration 10123: loss: 0.089971, loss_s1: 0.073588, loss_fp: 0.006960, loss_freq: 0.038950
[04:14:43.523] iteration 10124: loss: 0.043478, loss_s1: 0.024789, loss_fp: 0.002661, loss_freq: 0.015227
[04:14:44.124] iteration 10125: loss: 0.078380, loss_s1: 0.020297, loss_fp: 0.005062, loss_freq: 0.048801
[04:14:44.714] iteration 10126: loss: 0.078396, loss_s1: 0.061036, loss_fp: 0.002277, loss_freq: 0.043365
[04:14:45.314] iteration 10127: loss: 0.105354, loss_s1: 0.075209, loss_fp: 0.004486, loss_freq: 0.057131
[04:14:45.910] iteration 10128: loss: 0.090135, loss_s1: 0.065186, loss_fp: 0.005183, loss_freq: 0.055751
[04:14:46.579] iteration 10129: loss: 0.068823, loss_s1: 0.034491, loss_fp: 0.001210, loss_freq: 0.050388
[04:14:47.169] iteration 10130: loss: 0.076932, loss_s1: 0.061201, loss_fp: 0.006771, loss_freq: 0.030054
[04:14:47.804] iteration 10131: loss: 0.063947, loss_s1: 0.076686, loss_fp: 0.001369, loss_freq: 0.015735
[04:14:48.405] iteration 10132: loss: 0.063441, loss_s1: 0.046318, loss_fp: 0.001849, loss_freq: 0.016656
[04:14:48.996] iteration 10133: loss: 0.033597, loss_s1: 0.012730, loss_fp: 0.001161, loss_freq: 0.007057
[04:14:49.587] iteration 10134: loss: 0.066512, loss_s1: 0.034880, loss_fp: 0.004551, loss_freq: 0.035182
[04:14:50.180] iteration 10135: loss: 0.080960, loss_s1: 0.080798, loss_fp: 0.000765, loss_freq: 0.029698
[04:14:50.805] iteration 10136: loss: 0.086613, loss_s1: 0.055839, loss_fp: 0.007008, loss_freq: 0.046558
[04:14:51.444] iteration 10137: loss: 0.069508, loss_s1: 0.043223, loss_fp: 0.003456, loss_freq: 0.029925
[04:14:52.035] iteration 10138: loss: 0.062365, loss_s1: 0.047280, loss_fp: 0.001652, loss_freq: 0.024061
[04:14:52.625] iteration 10139: loss: 0.072699, loss_s1: 0.037567, loss_fp: 0.009383, loss_freq: 0.048339
[04:14:53.216] iteration 10140: loss: 0.043430, loss_s1: 0.011155, loss_fp: 0.002236, loss_freq: 0.014999
[04:14:53.809] iteration 10141: loss: 0.074089, loss_s1: 0.074005, loss_fp: 0.000978, loss_freq: 0.014083
[04:14:54.407] iteration 10142: loss: 0.065966, loss_s1: 0.056139, loss_fp: 0.002369, loss_freq: 0.030624
[04:14:55.038] iteration 10143: loss: 0.070965, loss_s1: 0.073533, loss_fp: 0.000839, loss_freq: 0.032699
[04:14:55.663] iteration 10144: loss: 0.085623, loss_s1: 0.081401, loss_fp: 0.001677, loss_freq: 0.054791
[04:14:56.300] iteration 10145: loss: 0.148310, loss_s1: 0.116248, loss_fp: 0.003089, loss_freq: 0.091154
[04:14:56.926] iteration 10146: loss: 0.083639, loss_s1: 0.079313, loss_fp: 0.002604, loss_freq: 0.034664
[04:14:57.557] iteration 10147: loss: 0.048983, loss_s1: 0.040335, loss_fp: 0.002298, loss_freq: 0.005768
[04:14:58.182] iteration 10148: loss: 0.079328, loss_s1: 0.070592, loss_fp: 0.007544, loss_freq: 0.018606
[04:14:58.789] iteration 10149: loss: 0.149757, loss_s1: 0.126363, loss_fp: 0.019735, loss_freq: 0.118321
[04:14:59.384] iteration 10150: loss: 0.083421, loss_s1: 0.058138, loss_fp: 0.006564, loss_freq: 0.046013
[04:14:59.985] iteration 10151: loss: 0.049655, loss_s1: 0.032079, loss_fp: 0.000448, loss_freq: 0.015539
[04:15:00.618] iteration 10152: loss: 0.092707, loss_s1: 0.091209, loss_fp: 0.001222, loss_freq: 0.036225
[04:15:01.300] iteration 10153: loss: 0.079068, loss_s1: 0.077293, loss_fp: 0.004098, loss_freq: 0.022887
[04:15:01.937] iteration 10154: loss: 0.050911, loss_s1: 0.030515, loss_fp: 0.002967, loss_freq: 0.022968
[04:15:02.570] iteration 10155: loss: 0.083486, loss_s1: 0.071776, loss_fp: 0.003404, loss_freq: 0.038561
[04:15:03.162] iteration 10156: loss: 0.071229, loss_s1: 0.052468, loss_fp: 0.000850, loss_freq: 0.037266
[04:15:03.754] iteration 10157: loss: 0.090543, loss_s1: 0.068364, loss_fp: 0.002743, loss_freq: 0.069051
[04:15:04.345] iteration 10158: loss: 0.079913, loss_s1: 0.064806, loss_fp: 0.004481, loss_freq: 0.017526
[04:15:04.937] iteration 10159: loss: 0.102066, loss_s1: 0.078153, loss_fp: 0.003776, loss_freq: 0.045188
[04:15:05.527] iteration 10160: loss: 0.073968, loss_s1: 0.055865, loss_fp: 0.002852, loss_freq: 0.048691
[04:15:06.122] iteration 10161: loss: 0.088879, loss_s1: 0.061571, loss_fp: 0.002412, loss_freq: 0.057257
[04:15:06.724] iteration 10162: loss: 0.080005, loss_s1: 0.070803, loss_fp: 0.002330, loss_freq: 0.028327
[04:15:07.322] iteration 10163: loss: 0.090939, loss_s1: 0.082485, loss_fp: 0.002746, loss_freq: 0.047002
[04:15:07.920] iteration 10164: loss: 0.098654, loss_s1: 0.074554, loss_fp: 0.008954, loss_freq: 0.051075
[04:15:08.524] iteration 10165: loss: 0.097208, loss_s1: 0.091636, loss_fp: 0.002463, loss_freq: 0.052256
[04:15:09.130] iteration 10166: loss: 0.043218, loss_s1: 0.023810, loss_fp: 0.001994, loss_freq: 0.021621
[04:15:09.736] iteration 10167: loss: 0.120533, loss_s1: 0.104463, loss_fp: 0.002454, loss_freq: 0.027740
[04:15:10.333] iteration 10168: loss: 0.079628, loss_s1: 0.057158, loss_fp: 0.002335, loss_freq: 0.053367
[04:15:10.927] iteration 10169: loss: 0.105946, loss_s1: 0.110437, loss_fp: 0.006878, loss_freq: 0.042832
[04:15:11.523] iteration 10170: loss: 0.081390, loss_s1: 0.087802, loss_fp: 0.001830, loss_freq: 0.038931
[04:15:12.118] iteration 10171: loss: 0.080055, loss_s1: 0.061463, loss_fp: 0.002786, loss_freq: 0.039075
[04:15:12.708] iteration 10172: loss: 0.071746, loss_s1: 0.065110, loss_fp: 0.001934, loss_freq: 0.016046
[04:15:13.298] iteration 10173: loss: 0.072695, loss_s1: 0.062365, loss_fp: 0.007187, loss_freq: 0.033030
[04:15:13.881] iteration 10174: loss: 0.070825, loss_s1: 0.040535, loss_fp: 0.007030, loss_freq: 0.044293
[04:15:14.498] iteration 10175: loss: 0.082637, loss_s1: 0.061755, loss_fp: 0.000972, loss_freq: 0.062171
[04:15:15.092] iteration 10176: loss: 0.053018, loss_s1: 0.028900, loss_fp: 0.001121, loss_freq: 0.015985
[04:15:15.679] iteration 10177: loss: 0.081299, loss_s1: 0.056574, loss_fp: 0.003024, loss_freq: 0.024099
[04:15:16.269] iteration 10178: loss: 0.115379, loss_s1: 0.126339, loss_fp: 0.001442, loss_freq: 0.042301
[04:15:16.867] iteration 10179: loss: 0.097610, loss_s1: 0.104500, loss_fp: 0.004706, loss_freq: 0.048209
[04:15:17.462] iteration 10180: loss: 0.076317, loss_s1: 0.048022, loss_fp: 0.002893, loss_freq: 0.039792
[04:15:18.056] iteration 10181: loss: 0.096284, loss_s1: 0.082413, loss_fp: 0.010676, loss_freq: 0.035868
[04:15:18.689] iteration 10182: loss: 0.091009, loss_s1: 0.069828, loss_fp: 0.009329, loss_freq: 0.058331
[04:15:19.285] iteration 10183: loss: 0.163817, loss_s1: 0.123908, loss_fp: 0.004851, loss_freq: 0.078250
[04:15:19.887] iteration 10184: loss: 0.078973, loss_s1: 0.077947, loss_fp: 0.002577, loss_freq: 0.022016
[04:15:20.478] iteration 10185: loss: 0.088742, loss_s1: 0.062632, loss_fp: 0.001577, loss_freq: 0.054667
[04:15:21.063] iteration 10186: loss: 0.064214, loss_s1: 0.034145, loss_fp: 0.000894, loss_freq: 0.016434
[04:15:21.657] iteration 10187: loss: 0.064427, loss_s1: 0.029588, loss_fp: 0.003162, loss_freq: 0.043845
[04:15:22.254] iteration 10188: loss: 0.100875, loss_s1: 0.088854, loss_fp: 0.002371, loss_freq: 0.045438
[04:15:22.843] iteration 10189: loss: 0.057594, loss_s1: 0.067436, loss_fp: 0.001428, loss_freq: 0.012141
[04:15:23.435] iteration 10190: loss: 0.106250, loss_s1: 0.112289, loss_fp: 0.004617, loss_freq: 0.048153
[04:15:24.025] iteration 10191: loss: 0.067066, loss_s1: 0.031642, loss_fp: 0.002604, loss_freq: 0.020060
[04:15:24.615] iteration 10192: loss: 0.048899, loss_s1: 0.045929, loss_fp: 0.002405, loss_freq: 0.013897
[04:15:25.208] iteration 10193: loss: 0.044087, loss_s1: 0.019544, loss_fp: 0.000491, loss_freq: 0.012500
[04:15:25.803] iteration 10194: loss: 0.075253, loss_s1: 0.053268, loss_fp: 0.000894, loss_freq: 0.018836
[04:15:26.391] iteration 10195: loss: 0.042951, loss_s1: 0.023078, loss_fp: 0.002217, loss_freq: 0.020553
[04:15:26.977] iteration 10196: loss: 0.104589, loss_s1: 0.081792, loss_fp: 0.001283, loss_freq: 0.045429
[04:15:27.572] iteration 10197: loss: 0.061517, loss_s1: 0.041475, loss_fp: 0.004081, loss_freq: 0.026874
[04:15:28.169] iteration 10198: loss: 0.049400, loss_s1: 0.020940, loss_fp: 0.001395, loss_freq: 0.025350
[04:15:28.755] iteration 10199: loss: 0.079774, loss_s1: 0.041357, loss_fp: 0.002696, loss_freq: 0.081509
[04:15:29.343] iteration 10200: loss: 0.085779, loss_s1: 0.087936, loss_fp: 0.000766, loss_freq: 0.025920
[04:15:32.506] iteration 10200 : mean_dice : 0.696448
[04:15:33.484] iteration 10201: loss: 0.080619, loss_s1: 0.058469, loss_fp: 0.001609, loss_freq: 0.028076
[04:15:34.127] iteration 10202: loss: 0.062250, loss_s1: 0.038934, loss_fp: 0.002097, loss_freq: 0.027766
[04:15:34.792] iteration 10203: loss: 0.091164, loss_s1: 0.101473, loss_fp: 0.003886, loss_freq: 0.031124
[04:15:35.424] iteration 10204: loss: 0.062402, loss_s1: 0.044114, loss_fp: 0.001621, loss_freq: 0.021293
[04:15:36.054] iteration 10205: loss: 0.067079, loss_s1: 0.086031, loss_fp: 0.001880, loss_freq: 0.011908
[04:15:36.748] iteration 10206: loss: 0.069274, loss_s1: 0.066679, loss_fp: 0.003369, loss_freq: 0.024332
[04:15:37.356] iteration 10207: loss: 0.075297, loss_s1: 0.083219, loss_fp: 0.002822, loss_freq: 0.023753
[04:15:37.951] iteration 10208: loss: 0.055189, loss_s1: 0.035845, loss_fp: 0.004203, loss_freq: 0.025478
[04:15:38.546] iteration 10209: loss: 0.062203, loss_s1: 0.038748, loss_fp: 0.002760, loss_freq: 0.028876
[04:15:39.139] iteration 10210: loss: 0.072234, loss_s1: 0.059732, loss_fp: 0.003876, loss_freq: 0.026812
[04:15:39.783] iteration 10211: loss: 0.070036, loss_s1: 0.051000, loss_fp: 0.001503, loss_freq: 0.046282
[04:15:40.370] iteration 10212: loss: 0.097357, loss_s1: 0.089420, loss_fp: 0.001955, loss_freq: 0.048864
[04:15:40.965] iteration 10213: loss: 0.067131, loss_s1: 0.049067, loss_fp: 0.000907, loss_freq: 0.029008
[04:15:41.557] iteration 10214: loss: 0.053715, loss_s1: 0.041272, loss_fp: 0.006268, loss_freq: 0.010945
[04:15:42.188] iteration 10215: loss: 0.084490, loss_s1: 0.066669, loss_fp: 0.001023, loss_freq: 0.018823
[04:15:42.787] iteration 10216: loss: 0.054025, loss_s1: 0.038811, loss_fp: 0.001468, loss_freq: 0.021406
[04:15:43.444] iteration 10217: loss: 0.165378, loss_s1: 0.149527, loss_fp: 0.002798, loss_freq: 0.137225
[04:15:44.094] iteration 10218: loss: 0.072315, loss_s1: 0.084910, loss_fp: 0.001504, loss_freq: 0.011747
[04:15:44.722] iteration 10219: loss: 0.081806, loss_s1: 0.066700, loss_fp: 0.012422, loss_freq: 0.027126
[04:15:45.352] iteration 10220: loss: 0.048001, loss_s1: 0.021460, loss_fp: 0.004016, loss_freq: 0.018321
[04:15:45.979] iteration 10221: loss: 0.064875, loss_s1: 0.040202, loss_fp: 0.003518, loss_freq: 0.022224
[04:15:46.616] iteration 10222: loss: 0.069083, loss_s1: 0.062485, loss_fp: 0.003947, loss_freq: 0.028460
[04:15:47.261] iteration 10223: loss: 0.090052, loss_s1: 0.074005, loss_fp: 0.001882, loss_freq: 0.047560
[04:15:47.858] iteration 10224: loss: 0.060041, loss_s1: 0.044820, loss_fp: 0.001149, loss_freq: 0.017839
[04:15:48.525] iteration 10225: loss: 0.082489, loss_s1: 0.060003, loss_fp: 0.001756, loss_freq: 0.047523
[04:15:49.176] iteration 10226: loss: 0.110201, loss_s1: 0.096246, loss_fp: 0.001592, loss_freq: 0.055304
[04:15:49.819] iteration 10227: loss: 0.091334, loss_s1: 0.078518, loss_fp: 0.003937, loss_freq: 0.034237
[04:15:50.429] iteration 10228: loss: 0.129259, loss_s1: 0.121574, loss_fp: 0.003068, loss_freq: 0.057051
[04:15:51.064] iteration 10229: loss: 0.086851, loss_s1: 0.035787, loss_fp: 0.002575, loss_freq: 0.032686
[04:15:51.684] iteration 10230: loss: 0.097686, loss_s1: 0.089113, loss_fp: 0.011869, loss_freq: 0.046436
[04:15:52.281] iteration 10231: loss: 0.067558, loss_s1: 0.036477, loss_fp: 0.000580, loss_freq: 0.054359
[04:15:52.868] iteration 10232: loss: 0.099042, loss_s1: 0.093990, loss_fp: 0.007709, loss_freq: 0.040694
[04:15:53.465] iteration 10233: loss: 0.133693, loss_s1: 0.141256, loss_fp: 0.003201, loss_freq: 0.079416
[04:15:54.061] iteration 10234: loss: 0.063890, loss_s1: 0.065272, loss_fp: 0.009985, loss_freq: 0.006792
[04:15:54.664] iteration 10235: loss: 0.055888, loss_s1: 0.048204, loss_fp: 0.001411, loss_freq: 0.032787
[04:15:55.248] iteration 10236: loss: 0.052755, loss_s1: 0.044412, loss_fp: 0.000778, loss_freq: 0.007316
[04:15:55.839] iteration 10237: loss: 0.076496, loss_s1: 0.060621, loss_fp: 0.002363, loss_freq: 0.026606
[04:15:56.432] iteration 10238: loss: 0.096624, loss_s1: 0.115578, loss_fp: 0.003884, loss_freq: 0.022210
[04:15:57.026] iteration 10239: loss: 0.146796, loss_s1: 0.108982, loss_fp: 0.004642, loss_freq: 0.122519
[04:15:57.619] iteration 10240: loss: 0.120426, loss_s1: 0.139034, loss_fp: 0.001353, loss_freq: 0.030252
[04:15:58.209] iteration 10241: loss: 0.129598, loss_s1: 0.125929, loss_fp: 0.012255, loss_freq: 0.066592
[04:15:58.817] iteration 10242: loss: 0.071872, loss_s1: 0.070124, loss_fp: 0.003072, loss_freq: 0.029197
[04:15:59.406] iteration 10243: loss: 0.110625, loss_s1: 0.083164, loss_fp: 0.002071, loss_freq: 0.083873
[04:15:59.995] iteration 10244: loss: 0.072098, loss_s1: 0.047843, loss_fp: 0.001546, loss_freq: 0.057970
[04:16:00.589] iteration 10245: loss: 0.077892, loss_s1: 0.054688, loss_fp: 0.002859, loss_freq: 0.044721
[04:16:01.179] iteration 10246: loss: 0.094623, loss_s1: 0.057586, loss_fp: 0.005160, loss_freq: 0.069733
[04:16:01.769] iteration 10247: loss: 0.062694, loss_s1: 0.044356, loss_fp: 0.004625, loss_freq: 0.034589
[04:16:02.364] iteration 10248: loss: 0.080269, loss_s1: 0.093146, loss_fp: 0.001662, loss_freq: 0.027925
[04:16:02.959] iteration 10249: loss: 0.063823, loss_s1: 0.065664, loss_fp: 0.000372, loss_freq: 0.012618
[04:16:03.551] iteration 10250: loss: 0.066432, loss_s1: 0.041730, loss_fp: 0.000910, loss_freq: 0.026118
[04:16:04.150] iteration 10251: loss: 0.074888, loss_s1: 0.055875, loss_fp: 0.006258, loss_freq: 0.023366
[04:16:04.740] iteration 10252: loss: 0.096635, loss_s1: 0.101774, loss_fp: 0.006495, loss_freq: 0.050378
[04:16:05.328] iteration 10253: loss: 0.073516, loss_s1: 0.049557, loss_fp: 0.002632, loss_freq: 0.041141
[04:16:05.916] iteration 10254: loss: 0.091507, loss_s1: 0.085015, loss_fp: 0.003607, loss_freq: 0.040929
[04:16:06.507] iteration 10255: loss: 0.081790, loss_s1: 0.063967, loss_fp: 0.005939, loss_freq: 0.040045
[04:16:07.097] iteration 10256: loss: 0.068567, loss_s1: 0.054958, loss_fp: 0.001111, loss_freq: 0.029836
[04:16:07.691] iteration 10257: loss: 0.088692, loss_s1: 0.085858, loss_fp: 0.001981, loss_freq: 0.038128
[04:16:08.288] iteration 10258: loss: 0.070891, loss_s1: 0.050470, loss_fp: 0.002281, loss_freq: 0.033678
[04:16:08.875] iteration 10259: loss: 0.090386, loss_s1: 0.066301, loss_fp: 0.004808, loss_freq: 0.062924
[04:16:09.473] iteration 10260: loss: 0.087744, loss_s1: 0.051494, loss_fp: 0.003782, loss_freq: 0.070636
[04:16:10.068] iteration 10261: loss: 0.048615, loss_s1: 0.028185, loss_fp: 0.000883, loss_freq: 0.013408
[04:16:10.666] iteration 10262: loss: 0.070927, loss_s1: 0.037742, loss_fp: 0.002222, loss_freq: 0.031058
[04:16:11.254] iteration 10263: loss: 0.049046, loss_s1: 0.020340, loss_fp: 0.003603, loss_freq: 0.015081
[04:16:11.848] iteration 10264: loss: 0.035945, loss_s1: 0.016423, loss_fp: 0.004308, loss_freq: 0.016428
[04:16:12.435] iteration 10265: loss: 0.089932, loss_s1: 0.070559, loss_fp: 0.001417, loss_freq: 0.027336
[04:16:13.025] iteration 10266: loss: 0.089726, loss_s1: 0.074374, loss_fp: 0.005607, loss_freq: 0.057136
[04:16:13.650] iteration 10267: loss: 0.095149, loss_s1: 0.072216, loss_fp: 0.001455, loss_freq: 0.015286
[04:16:14.237] iteration 10268: loss: 0.139527, loss_s1: 0.140253, loss_fp: 0.004579, loss_freq: 0.090965
[04:16:14.825] iteration 10269: loss: 0.049503, loss_s1: 0.033392, loss_fp: 0.003650, loss_freq: 0.014048
[04:16:15.412] iteration 10270: loss: 0.061135, loss_s1: 0.038901, loss_fp: 0.012019, loss_freq: 0.032497
[04:16:15.998] iteration 10271: loss: 0.084879, loss_s1: 0.078513, loss_fp: 0.002604, loss_freq: 0.037451
[04:16:16.588] iteration 10272: loss: 0.084947, loss_s1: 0.059676, loss_fp: 0.003960, loss_freq: 0.045204
[04:16:17.175] iteration 10273: loss: 0.070585, loss_s1: 0.054079, loss_fp: 0.005985, loss_freq: 0.039694
[04:16:17.804] iteration 10274: loss: 0.072003, loss_s1: 0.047501, loss_fp: 0.002754, loss_freq: 0.035513
[04:16:18.396] iteration 10275: loss: 0.107631, loss_s1: 0.102042, loss_fp: 0.002179, loss_freq: 0.068841
[04:16:18.991] iteration 10276: loss: 0.082714, loss_s1: 0.049289, loss_fp: 0.003513, loss_freq: 0.050018
[04:16:19.587] iteration 10277: loss: 0.083566, loss_s1: 0.070574, loss_fp: 0.004678, loss_freq: 0.040031
[04:16:20.177] iteration 10278: loss: 0.093739, loss_s1: 0.079883, loss_fp: 0.002598, loss_freq: 0.036389
[04:16:20.771] iteration 10279: loss: 0.071766, loss_s1: 0.048527, loss_fp: 0.003870, loss_freq: 0.049370
[04:16:21.373] iteration 10280: loss: 0.104485, loss_s1: 0.110247, loss_fp: 0.001344, loss_freq: 0.020962
[04:16:21.963] iteration 10281: loss: 0.074848, loss_s1: 0.046528, loss_fp: 0.004127, loss_freq: 0.031438
[04:16:22.553] iteration 10282: loss: 0.106330, loss_s1: 0.117658, loss_fp: 0.006173, loss_freq: 0.047804
[04:16:23.146] iteration 10283: loss: 0.063407, loss_s1: 0.035494, loss_fp: 0.009797, loss_freq: 0.034878
[04:16:23.743] iteration 10284: loss: 0.064339, loss_s1: 0.061861, loss_fp: 0.008422, loss_freq: 0.011052
[04:16:24.334] iteration 10285: loss: 0.082879, loss_s1: 0.082689, loss_fp: 0.005680, loss_freq: 0.027790
[04:16:24.918] iteration 10286: loss: 0.075191, loss_s1: 0.048346, loss_fp: 0.006296, loss_freq: 0.030031
[04:16:25.503] iteration 10287: loss: 0.081127, loss_s1: 0.107942, loss_fp: 0.005213, loss_freq: 0.015533
[04:16:26.091] iteration 10288: loss: 0.068800, loss_s1: 0.048905, loss_fp: 0.001162, loss_freq: 0.013585
[04:16:26.680] iteration 10289: loss: 0.081244, loss_s1: 0.054750, loss_fp: 0.004327, loss_freq: 0.057788
[04:16:27.275] iteration 10290: loss: 0.111224, loss_s1: 0.119735, loss_fp: 0.001330, loss_freq: 0.011725
[04:16:27.861] iteration 10291: loss: 0.058331, loss_s1: 0.061263, loss_fp: 0.000890, loss_freq: 0.009704
[04:16:28.454] iteration 10292: loss: 0.077342, loss_s1: 0.059267, loss_fp: 0.001542, loss_freq: 0.050305
[04:16:29.054] iteration 10293: loss: 0.084769, loss_s1: 0.041980, loss_fp: 0.006688, loss_freq: 0.038721
[04:16:29.651] iteration 10294: loss: 0.040803, loss_s1: 0.026827, loss_fp: 0.001714, loss_freq: 0.009077
[04:16:30.244] iteration 10295: loss: 0.079728, loss_s1: 0.054716, loss_fp: 0.000981, loss_freq: 0.044484
[04:16:30.835] iteration 10296: loss: 0.075847, loss_s1: 0.079218, loss_fp: 0.002285, loss_freq: 0.026336
[04:16:31.423] iteration 10297: loss: 0.100409, loss_s1: 0.070165, loss_fp: 0.001482, loss_freq: 0.064943
[04:16:32.008] iteration 10298: loss: 0.074035, loss_s1: 0.040632, loss_fp: 0.002895, loss_freq: 0.049148
[04:16:32.599] iteration 10299: loss: 0.084402, loss_s1: 0.064080, loss_fp: 0.003232, loss_freq: 0.057725
[04:16:33.189] iteration 10300: loss: 0.064205, loss_s1: 0.027181, loss_fp: 0.006541, loss_freq: 0.048309
[04:16:33.869] iteration 10301: loss: 0.049882, loss_s1: 0.039130, loss_fp: 0.002930, loss_freq: 0.017619
[04:16:34.504] iteration 10302: loss: 0.068133, loss_s1: 0.049094, loss_fp: 0.004083, loss_freq: 0.027782
[04:16:35.141] iteration 10303: loss: 0.056041, loss_s1: 0.014977, loss_fp: 0.000532, loss_freq: 0.023890
[04:16:35.764] iteration 10304: loss: 0.058112, loss_s1: 0.026172, loss_fp: 0.002017, loss_freq: 0.027073
[04:16:36.371] iteration 10305: loss: 0.044480, loss_s1: 0.032163, loss_fp: 0.001900, loss_freq: 0.018640
[04:16:36.971] iteration 10306: loss: 0.119179, loss_s1: 0.103694, loss_fp: 0.004566, loss_freq: 0.058657
[04:16:37.564] iteration 10307: loss: 0.075355, loss_s1: 0.085277, loss_fp: 0.003045, loss_freq: 0.020353
[04:16:38.162] iteration 10308: loss: 0.056320, loss_s1: 0.049094, loss_fp: 0.001675, loss_freq: 0.017883
[04:16:38.756] iteration 10309: loss: 0.060533, loss_s1: 0.047054, loss_fp: 0.002751, loss_freq: 0.025042
[04:16:39.345] iteration 10310: loss: 0.067110, loss_s1: 0.047947, loss_fp: 0.001863, loss_freq: 0.035970
[04:16:39.939] iteration 10311: loss: 0.065238, loss_s1: 0.056427, loss_fp: 0.003036, loss_freq: 0.011765
[04:16:40.533] iteration 10312: loss: 0.068108, loss_s1: 0.061729, loss_fp: 0.003433, loss_freq: 0.019970
[04:16:41.130] iteration 10313: loss: 0.073906, loss_s1: 0.063351, loss_fp: 0.003819, loss_freq: 0.040741
[04:16:41.727] iteration 10314: loss: 0.041238, loss_s1: 0.009325, loss_fp: 0.007095, loss_freq: 0.020008
[04:16:42.339] iteration 10315: loss: 0.097823, loss_s1: 0.036711, loss_fp: 0.006426, loss_freq: 0.058849
[04:16:42.961] iteration 10316: loss: 0.097175, loss_s1: 0.062353, loss_fp: 0.007405, loss_freq: 0.059356
[04:16:43.545] iteration 10317: loss: 0.097884, loss_s1: 0.102700, loss_fp: 0.001216, loss_freq: 0.033250
[04:16:44.131] iteration 10318: loss: 0.066749, loss_s1: 0.050128, loss_fp: 0.001366, loss_freq: 0.037160
[04:16:44.720] iteration 10319: loss: 0.082915, loss_s1: 0.033146, loss_fp: 0.002797, loss_freq: 0.081527
[04:16:45.307] iteration 10320: loss: 0.048689, loss_s1: 0.033621, loss_fp: 0.001443, loss_freq: 0.013007
[04:16:45.894] iteration 10321: loss: 0.070438, loss_s1: 0.048059, loss_fp: 0.001323, loss_freq: 0.020790
[04:16:46.475] iteration 10322: loss: 0.053021, loss_s1: 0.042966, loss_fp: 0.003301, loss_freq: 0.023378
[04:16:47.077] iteration 10323: loss: 0.095103, loss_s1: 0.085815, loss_fp: 0.004039, loss_freq: 0.056318
[04:16:47.669] iteration 10324: loss: 0.059687, loss_s1: 0.053981, loss_fp: 0.005995, loss_freq: 0.026344
[04:16:48.261] iteration 10325: loss: 0.120091, loss_s1: 0.079283, loss_fp: 0.024274, loss_freq: 0.059352
[04:16:48.886] iteration 10326: loss: 0.069312, loss_s1: 0.053758, loss_fp: 0.000965, loss_freq: 0.038316
[04:16:49.481] iteration 10327: loss: 0.099587, loss_s1: 0.081480, loss_fp: 0.004335, loss_freq: 0.076574
[04:16:50.084] iteration 10328: loss: 0.099267, loss_s1: 0.102280, loss_fp: 0.007370, loss_freq: 0.014938
[04:16:50.677] iteration 10329: loss: 0.052339, loss_s1: 0.023601, loss_fp: 0.004812, loss_freq: 0.019568
[04:16:51.269] iteration 10330: loss: 0.084793, loss_s1: 0.059482, loss_fp: 0.004029, loss_freq: 0.044210
[04:16:51.860] iteration 10331: loss: 0.099281, loss_s1: 0.141848, loss_fp: 0.000888, loss_freq: 0.016296
[04:16:52.455] iteration 10332: loss: 0.078421, loss_s1: 0.063942, loss_fp: 0.004732, loss_freq: 0.026179
[04:16:53.049] iteration 10333: loss: 0.108069, loss_s1: 0.127363, loss_fp: 0.001339, loss_freq: 0.037884
[04:16:53.675] iteration 10334: loss: 0.121216, loss_s1: 0.120731, loss_fp: 0.001866, loss_freq: 0.071516
[04:16:54.303] iteration 10335: loss: 0.166688, loss_s1: 0.141539, loss_fp: 0.029436, loss_freq: 0.115075
[04:16:54.932] iteration 10336: loss: 0.047201, loss_s1: 0.046872, loss_fp: 0.002094, loss_freq: 0.012361
[04:16:55.564] iteration 10337: loss: 0.089993, loss_s1: 0.053959, loss_fp: 0.002193, loss_freq: 0.027523
[04:16:56.194] iteration 10338: loss: 0.091967, loss_s1: 0.072493, loss_fp: 0.003779, loss_freq: 0.069666
[04:16:56.823] iteration 10339: loss: 0.118812, loss_s1: 0.118782, loss_fp: 0.002674, loss_freq: 0.049532
[04:16:57.409] iteration 10340: loss: 0.067171, loss_s1: 0.066945, loss_fp: 0.001261, loss_freq: 0.032091
[04:16:58.003] iteration 10341: loss: 0.092934, loss_s1: 0.073013, loss_fp: 0.003748, loss_freq: 0.038983
[04:16:58.595] iteration 10342: loss: 0.085841, loss_s1: 0.068454, loss_fp: 0.001607, loss_freq: 0.040087
[04:16:59.191] iteration 10343: loss: 0.110747, loss_s1: 0.089651, loss_fp: 0.006795, loss_freq: 0.069485
[04:16:59.789] iteration 10344: loss: 0.072545, loss_s1: 0.055487, loss_fp: 0.002549, loss_freq: 0.031517
[04:17:00.388] iteration 10345: loss: 0.053430, loss_s1: 0.039429, loss_fp: 0.004329, loss_freq: 0.021358
[04:17:00.976] iteration 10346: loss: 0.071040, loss_s1: 0.033056, loss_fp: 0.009059, loss_freq: 0.047182
[04:17:01.567] iteration 10347: loss: 0.078661, loss_s1: 0.061873, loss_fp: 0.002676, loss_freq: 0.034224
[04:17:02.170] iteration 10348: loss: 0.118828, loss_s1: 0.108128, loss_fp: 0.009206, loss_freq: 0.057093
[04:17:02.760] iteration 10349: loss: 0.077733, loss_s1: 0.066018, loss_fp: 0.000963, loss_freq: 0.043370
[04:17:03.407] iteration 10350: loss: 0.097143, loss_s1: 0.056801, loss_fp: 0.001680, loss_freq: 0.061647
[04:17:03.996] iteration 10351: loss: 0.067486, loss_s1: 0.026313, loss_fp: 0.002632, loss_freq: 0.032824
[04:17:04.587] iteration 10352: loss: 0.057661, loss_s1: 0.032509, loss_fp: 0.005015, loss_freq: 0.028963
[04:17:05.227] iteration 10353: loss: 0.124970, loss_s1: 0.062001, loss_fp: 0.025172, loss_freq: 0.051108
[04:17:05.814] iteration 10354: loss: 0.052382, loss_s1: 0.030126, loss_fp: 0.001870, loss_freq: 0.025805
[04:17:06.406] iteration 10355: loss: 0.095662, loss_s1: 0.095241, loss_fp: 0.002850, loss_freq: 0.036617
[04:17:07.003] iteration 10356: loss: 0.051512, loss_s1: 0.048743, loss_fp: 0.000905, loss_freq: 0.008018
[04:17:07.604] iteration 10357: loss: 0.033856, loss_s1: 0.024097, loss_fp: 0.001077, loss_freq: 0.009173
[04:17:08.195] iteration 10358: loss: 0.080321, loss_s1: 0.046263, loss_fp: 0.000997, loss_freq: 0.056986
[04:17:08.793] iteration 10359: loss: 0.070475, loss_s1: 0.071291, loss_fp: 0.002385, loss_freq: 0.029072
[04:17:09.390] iteration 10360: loss: 0.115696, loss_s1: 0.089464, loss_fp: 0.005123, loss_freq: 0.044876
[04:17:09.979] iteration 10361: loss: 0.040888, loss_s1: 0.023921, loss_fp: 0.003121, loss_freq: 0.007654
[04:17:10.578] iteration 10362: loss: 0.070321, loss_s1: 0.059659, loss_fp: 0.005471, loss_freq: 0.043746
[04:17:11.172] iteration 10363: loss: 0.089436, loss_s1: 0.065438, loss_fp: 0.000996, loss_freq: 0.017418
[04:17:11.765] iteration 10364: loss: 0.073026, loss_s1: 0.043731, loss_fp: 0.003402, loss_freq: 0.021430
[04:17:12.357] iteration 10365: loss: 0.041072, loss_s1: 0.027979, loss_fp: 0.001938, loss_freq: 0.012340
[04:17:12.952] iteration 10366: loss: 0.113545, loss_s1: 0.120053, loss_fp: 0.003736, loss_freq: 0.048921
[04:17:13.537] iteration 10367: loss: 0.080244, loss_s1: 0.055950, loss_fp: 0.002523, loss_freq: 0.042609
[04:17:14.128] iteration 10368: loss: 0.090162, loss_s1: 0.070872, loss_fp: 0.011488, loss_freq: 0.025742
[04:17:14.716] iteration 10369: loss: 0.084580, loss_s1: 0.078199, loss_fp: 0.006460, loss_freq: 0.039781
[04:17:15.309] iteration 10370: loss: 0.103739, loss_s1: 0.080710, loss_fp: 0.005088, loss_freq: 0.078753
[04:17:16.200] iteration 10371: loss: 0.057141, loss_s1: 0.027203, loss_fp: 0.002302, loss_freq: 0.033799
[04:17:16.811] iteration 10372: loss: 0.051694, loss_s1: 0.029362, loss_fp: 0.003642, loss_freq: 0.021153
[04:17:17.417] iteration 10373: loss: 0.066158, loss_s1: 0.045493, loss_fp: 0.010276, loss_freq: 0.036311
[04:17:18.023] iteration 10374: loss: 0.051149, loss_s1: 0.031305, loss_fp: 0.005495, loss_freq: 0.015244
[04:17:18.618] iteration 10375: loss: 0.065621, loss_s1: 0.046090, loss_fp: 0.005538, loss_freq: 0.042632
[04:17:19.205] iteration 10376: loss: 0.081194, loss_s1: 0.047532, loss_fp: 0.003528, loss_freq: 0.029284
[04:17:19.800] iteration 10377: loss: 0.101024, loss_s1: 0.082298, loss_fp: 0.010808, loss_freq: 0.028703
[04:17:20.390] iteration 10378: loss: 0.060951, loss_s1: 0.049382, loss_fp: 0.003734, loss_freq: 0.018631
[04:17:20.979] iteration 10379: loss: 0.065544, loss_s1: 0.030949, loss_fp: 0.001837, loss_freq: 0.031829
[04:17:21.573] iteration 10380: loss: 0.099705, loss_s1: 0.088478, loss_fp: 0.010965, loss_freq: 0.051526
[04:17:22.169] iteration 10381: loss: 0.059757, loss_s1: 0.017177, loss_fp: 0.001243, loss_freq: 0.038567
[04:17:22.767] iteration 10382: loss: 0.107965, loss_s1: 0.069420, loss_fp: 0.008247, loss_freq: 0.096013
[04:17:23.416] iteration 10383: loss: 0.084309, loss_s1: 0.063657, loss_fp: 0.009587, loss_freq: 0.044966
[04:17:24.044] iteration 10384: loss: 0.058457, loss_s1: 0.035590, loss_fp: 0.004434, loss_freq: 0.022348
[04:17:24.669] iteration 10385: loss: 0.060778, loss_s1: 0.036985, loss_fp: 0.006443, loss_freq: 0.014034
[04:17:25.298] iteration 10386: loss: 0.054609, loss_s1: 0.011010, loss_fp: 0.004970, loss_freq: 0.023944
[04:17:25.926] iteration 10387: loss: 0.150789, loss_s1: 0.088338, loss_fp: 0.002204, loss_freq: 0.147756
[04:17:26.517] iteration 10388: loss: 0.055491, loss_s1: 0.041850, loss_fp: 0.002119, loss_freq: 0.018675
[04:17:27.175] iteration 10389: loss: 0.053608, loss_s1: 0.045873, loss_fp: 0.004489, loss_freq: 0.014337
[04:17:27.768] iteration 10390: loss: 0.069176, loss_s1: 0.047378, loss_fp: 0.003455, loss_freq: 0.018992
[04:17:28.361] iteration 10391: loss: 0.052449, loss_s1: 0.037203, loss_fp: 0.001473, loss_freq: 0.019308
[04:17:28.958] iteration 10392: loss: 0.077717, loss_s1: 0.029903, loss_fp: 0.002208, loss_freq: 0.052595
[04:17:29.544] iteration 10393: loss: 0.114576, loss_s1: 0.096012, loss_fp: 0.001134, loss_freq: 0.032947
[04:17:30.141] iteration 10394: loss: 0.076792, loss_s1: 0.067665, loss_fp: 0.002935, loss_freq: 0.035389
[04:17:30.732] iteration 10395: loss: 0.102071, loss_s1: 0.118401, loss_fp: 0.001544, loss_freq: 0.034845
[04:17:31.325] iteration 10396: loss: 0.069216, loss_s1: 0.030214, loss_fp: 0.002209, loss_freq: 0.039508
[04:17:31.921] iteration 10397: loss: 0.058350, loss_s1: 0.043826, loss_fp: 0.003434, loss_freq: 0.008726
[04:17:32.511] iteration 10398: loss: 0.114631, loss_s1: 0.123118, loss_fp: 0.000776, loss_freq: 0.031005
[04:17:33.102] iteration 10399: loss: 0.141748, loss_s1: 0.118801, loss_fp: 0.002695, loss_freq: 0.055026
[04:17:33.695] iteration 10400: loss: 0.092620, loss_s1: 0.090837, loss_fp: 0.010193, loss_freq: 0.039440
[04:17:37.000] iteration 10400 : mean_dice : 0.696486
[04:17:37.620] iteration 10401: loss: 0.059550, loss_s1: 0.033869, loss_fp: 0.001951, loss_freq: 0.046966
[04:17:38.217] iteration 10402: loss: 0.083441, loss_s1: 0.046510, loss_fp: 0.001442, loss_freq: 0.047737
[04:17:38.816] iteration 10403: loss: 0.067062, loss_s1: 0.037213, loss_fp: 0.005000, loss_freq: 0.047253
[04:17:39.424] iteration 10404: loss: 0.050880, loss_s1: 0.027557, loss_fp: 0.003632, loss_freq: 0.024194
[04:17:40.019] iteration 10405: loss: 0.063468, loss_s1: 0.051212, loss_fp: 0.001290, loss_freq: 0.041005
[04:17:40.615] iteration 10406: loss: 0.062353, loss_s1: 0.043286, loss_fp: 0.002296, loss_freq: 0.028796
[04:17:41.266] iteration 10407: loss: 0.065441, loss_s1: 0.044650, loss_fp: 0.002241, loss_freq: 0.029551
[04:17:41.924] iteration 10408: loss: 0.070070, loss_s1: 0.076738, loss_fp: 0.001265, loss_freq: 0.020271
[04:17:42.578] iteration 10409: loss: 0.073019, loss_s1: 0.041010, loss_fp: 0.002910, loss_freq: 0.039915
[04:17:43.185] iteration 10410: loss: 0.089318, loss_s1: 0.094007, loss_fp: 0.002912, loss_freq: 0.032552
[04:17:43.806] iteration 10411: loss: 0.100383, loss_s1: 0.090156, loss_fp: 0.002120, loss_freq: 0.039329
[04:17:44.441] iteration 10412: loss: 0.115470, loss_s1: 0.104426, loss_fp: 0.002696, loss_freq: 0.053637
[04:17:45.070] iteration 10413: loss: 0.094881, loss_s1: 0.085287, loss_fp: 0.001706, loss_freq: 0.064391
[04:17:45.691] iteration 10414: loss: 0.100111, loss_s1: 0.102456, loss_fp: 0.001379, loss_freq: 0.055824
[04:17:46.288] iteration 10415: loss: 0.079601, loss_s1: 0.083985, loss_fp: 0.001954, loss_freq: 0.019180
[04:17:46.879] iteration 10416: loss: 0.091798, loss_s1: 0.102856, loss_fp: 0.008548, loss_freq: 0.022474
[04:17:47.480] iteration 10417: loss: 0.073624, loss_s1: 0.070620, loss_fp: 0.003209, loss_freq: 0.016195
[04:17:48.073] iteration 10418: loss: 0.094892, loss_s1: 0.048169, loss_fp: 0.009069, loss_freq: 0.055857
[04:17:48.668] iteration 10419: loss: 0.056238, loss_s1: 0.052224, loss_fp: 0.001415, loss_freq: 0.021947
[04:17:49.259] iteration 10420: loss: 0.084345, loss_s1: 0.072851, loss_fp: 0.003335, loss_freq: 0.040429
[04:17:49.848] iteration 10421: loss: 0.088553, loss_s1: 0.043427, loss_fp: 0.004008, loss_freq: 0.069946
[04:17:50.436] iteration 10422: loss: 0.071661, loss_s1: 0.071872, loss_fp: 0.006533, loss_freq: 0.030628
[04:17:51.019] iteration 10423: loss: 0.081571, loss_s1: 0.039955, loss_fp: 0.010933, loss_freq: 0.042896
[04:17:51.612] iteration 10424: loss: 0.084117, loss_s1: 0.054089, loss_fp: 0.010331, loss_freq: 0.038659
[04:17:52.202] iteration 10425: loss: 0.079521, loss_s1: 0.039935, loss_fp: 0.008168, loss_freq: 0.040443
[04:17:52.789] iteration 10426: loss: 0.057329, loss_s1: 0.044093, loss_fp: 0.003984, loss_freq: 0.018086
[04:17:53.419] iteration 10427: loss: 0.052843, loss_s1: 0.034919, loss_fp: 0.004344, loss_freq: 0.023266
[04:17:54.085] iteration 10428: loss: 0.061331, loss_s1: 0.036050, loss_fp: 0.003148, loss_freq: 0.018555
[04:17:54.976] iteration 10429: loss: 0.075026, loss_s1: 0.023423, loss_fp: 0.001071, loss_freq: 0.031920
[04:17:55.749] iteration 10430: loss: 0.086726, loss_s1: 0.074005, loss_fp: 0.004581, loss_freq: 0.043696
[04:17:56.483] iteration 10431: loss: 0.052354, loss_s1: 0.052945, loss_fp: 0.000630, loss_freq: 0.011175
[04:17:57.111] iteration 10432: loss: 0.090063, loss_s1: 0.061884, loss_fp: 0.004659, loss_freq: 0.045112
[04:17:57.705] iteration 10433: loss: 0.061156, loss_s1: 0.052955, loss_fp: 0.007127, loss_freq: 0.006358
[04:17:58.301] iteration 10434: loss: 0.064968, loss_s1: 0.045414, loss_fp: 0.001332, loss_freq: 0.019131
[04:17:58.892] iteration 10435: loss: 0.070612, loss_s1: 0.058194, loss_fp: 0.002048, loss_freq: 0.024902
[04:17:59.480] iteration 10436: loss: 0.075660, loss_s1: 0.074687, loss_fp: 0.003388, loss_freq: 0.035209
[04:18:00.068] iteration 10437: loss: 0.053133, loss_s1: 0.023681, loss_fp: 0.002150, loss_freq: 0.029365
[04:18:00.661] iteration 10438: loss: 0.119314, loss_s1: 0.145754, loss_fp: 0.005877, loss_freq: 0.040359
[04:18:01.254] iteration 10439: loss: 0.064900, loss_s1: 0.029571, loss_fp: 0.001302, loss_freq: 0.030774
[04:18:01.851] iteration 10440: loss: 0.061659, loss_s1: 0.046060, loss_fp: 0.005999, loss_freq: 0.031815
[04:18:02.442] iteration 10441: loss: 0.077208, loss_s1: 0.057238, loss_fp: 0.009061, loss_freq: 0.045530
[04:18:03.031] iteration 10442: loss: 0.065573, loss_s1: 0.024317, loss_fp: 0.005815, loss_freq: 0.043963
[04:18:03.622] iteration 10443: loss: 0.085139, loss_s1: 0.083603, loss_fp: 0.003568, loss_freq: 0.043787
[04:18:04.216] iteration 10444: loss: 0.084920, loss_s1: 0.105749, loss_fp: 0.003558, loss_freq: 0.016472
[04:18:04.809] iteration 10445: loss: 0.107797, loss_s1: 0.085529, loss_fp: 0.002858, loss_freq: 0.076873
[04:18:05.397] iteration 10446: loss: 0.062832, loss_s1: 0.039005, loss_fp: 0.007456, loss_freq: 0.023076
[04:18:05.987] iteration 10447: loss: 0.070423, loss_s1: 0.038015, loss_fp: 0.003566, loss_freq: 0.047342
[04:18:06.581] iteration 10448: loss: 0.126963, loss_s1: 0.120133, loss_fp: 0.003002, loss_freq: 0.058695
[04:18:07.170] iteration 10449: loss: 0.050482, loss_s1: 0.032434, loss_fp: 0.008891, loss_freq: 0.025447
[04:18:07.762] iteration 10450: loss: 0.072965, loss_s1: 0.056970, loss_fp: 0.001914, loss_freq: 0.030701
[04:18:08.353] iteration 10451: loss: 0.094086, loss_s1: 0.050205, loss_fp: 0.004798, loss_freq: 0.045934
[04:18:08.940] iteration 10452: loss: 0.103626, loss_s1: 0.100360, loss_fp: 0.002469, loss_freq: 0.061195
[04:18:09.542] iteration 10453: loss: 0.090283, loss_s1: 0.092331, loss_fp: 0.001533, loss_freq: 0.030183
[04:18:10.176] iteration 10454: loss: 0.084649, loss_s1: 0.075194, loss_fp: 0.011366, loss_freq: 0.021609
[04:18:10.770] iteration 10455: loss: 0.087842, loss_s1: 0.077762, loss_fp: 0.003651, loss_freq: 0.028511
[04:18:11.365] iteration 10456: loss: 0.046958, loss_s1: 0.039368, loss_fp: 0.003497, loss_freq: 0.010032
[04:18:11.960] iteration 10457: loss: 0.086351, loss_s1: 0.105191, loss_fp: 0.001107, loss_freq: 0.033040
[04:18:12.550] iteration 10458: loss: 0.074881, loss_s1: 0.072001, loss_fp: 0.002237, loss_freq: 0.026536
[04:18:13.138] iteration 10459: loss: 0.052814, loss_s1: 0.027671, loss_fp: 0.007193, loss_freq: 0.026517
[04:18:13.729] iteration 10460: loss: 0.062931, loss_s1: 0.034980, loss_fp: 0.001976, loss_freq: 0.015292
[04:18:14.321] iteration 10461: loss: 0.097655, loss_s1: 0.073879, loss_fp: 0.001350, loss_freq: 0.057442
[04:18:14.914] iteration 10462: loss: 0.063575, loss_s1: 0.066253, loss_fp: 0.002627, loss_freq: 0.023379
[04:18:15.508] iteration 10463: loss: 0.105580, loss_s1: 0.071553, loss_fp: 0.011916, loss_freq: 0.039745
[04:18:16.098] iteration 10464: loss: 0.061171, loss_s1: 0.053569, loss_fp: 0.001337, loss_freq: 0.017473
[04:18:16.691] iteration 10465: loss: 0.129602, loss_s1: 0.081592, loss_fp: 0.002089, loss_freq: 0.054689
[04:18:17.280] iteration 10466: loss: 0.084310, loss_s1: 0.060740, loss_fp: 0.002662, loss_freq: 0.047670
[04:18:17.866] iteration 10467: loss: 0.097753, loss_s1: 0.091529, loss_fp: 0.007172, loss_freq: 0.042186
[04:18:18.457] iteration 10468: loss: 0.079142, loss_s1: 0.057965, loss_fp: 0.001437, loss_freq: 0.050483
[04:18:19.047] iteration 10469: loss: 0.122817, loss_s1: 0.134156, loss_fp: 0.004223, loss_freq: 0.062879
[04:18:19.643] iteration 10470: loss: 0.063291, loss_s1: 0.054261, loss_fp: 0.001428, loss_freq: 0.024501
[04:18:20.239] iteration 10471: loss: 0.070504, loss_s1: 0.075179, loss_fp: 0.002427, loss_freq: 0.021392
[04:18:20.830] iteration 10472: loss: 0.065084, loss_s1: 0.053022, loss_fp: 0.000780, loss_freq: 0.019011
[04:18:21.421] iteration 10473: loss: 0.063998, loss_s1: 0.028060, loss_fp: 0.003603, loss_freq: 0.020177
[04:18:22.010] iteration 10474: loss: 0.087113, loss_s1: 0.027331, loss_fp: 0.003313, loss_freq: 0.031827
[04:18:22.599] iteration 10475: loss: 0.082282, loss_s1: 0.054996, loss_fp: 0.002591, loss_freq: 0.052118
[04:18:23.187] iteration 10476: loss: 0.095284, loss_s1: 0.080272, loss_fp: 0.003448, loss_freq: 0.027901
[04:18:23.774] iteration 10477: loss: 0.085689, loss_s1: 0.061395, loss_fp: 0.006187, loss_freq: 0.039109
[04:18:24.364] iteration 10478: loss: 0.074941, loss_s1: 0.059044, loss_fp: 0.002514, loss_freq: 0.029880
[04:18:24.957] iteration 10479: loss: 0.106166, loss_s1: 0.049241, loss_fp: 0.002416, loss_freq: 0.109947
[04:18:25.549] iteration 10480: loss: 0.058358, loss_s1: 0.049192, loss_fp: 0.001159, loss_freq: 0.025098
[04:18:26.138] iteration 10481: loss: 0.065063, loss_s1: 0.016974, loss_fp: 0.008277, loss_freq: 0.060886
[04:18:26.729] iteration 10482: loss: 0.082367, loss_s1: 0.072559, loss_fp: 0.006889, loss_freq: 0.030897
[04:18:27.317] iteration 10483: loss: 0.053364, loss_s1: 0.048007, loss_fp: 0.000771, loss_freq: 0.016403
[04:18:27.914] iteration 10484: loss: 0.078037, loss_s1: 0.077024, loss_fp: 0.003192, loss_freq: 0.038006
[04:18:28.506] iteration 10485: loss: 0.093452, loss_s1: 0.072366, loss_fp: 0.004785, loss_freq: 0.069104
[04:18:29.100] iteration 10486: loss: 0.088245, loss_s1: 0.054278, loss_fp: 0.003792, loss_freq: 0.059048
[04:18:29.693] iteration 10487: loss: 0.107911, loss_s1: 0.128536, loss_fp: 0.001299, loss_freq: 0.021074
[04:18:30.289] iteration 10488: loss: 0.086589, loss_s1: 0.041034, loss_fp: 0.006935, loss_freq: 0.028802
[04:18:30.882] iteration 10489: loss: 0.130236, loss_s1: 0.069833, loss_fp: 0.006341, loss_freq: 0.114562
[04:18:31.471] iteration 10490: loss: 0.071936, loss_s1: 0.040821, loss_fp: 0.005203, loss_freq: 0.033070
[04:18:32.058] iteration 10491: loss: 0.070480, loss_s1: 0.044687, loss_fp: 0.000978, loss_freq: 0.014231
[04:18:32.644] iteration 10492: loss: 0.058503, loss_s1: 0.037402, loss_fp: 0.004529, loss_freq: 0.031485
[04:18:33.234] iteration 10493: loss: 0.091314, loss_s1: 0.073182, loss_fp: 0.002534, loss_freq: 0.037198
[04:18:33.824] iteration 10494: loss: 0.052007, loss_s1: 0.032099, loss_fp: 0.002388, loss_freq: 0.032841
[04:18:34.413] iteration 10495: loss: 0.092622, loss_s1: 0.064909, loss_fp: 0.004594, loss_freq: 0.053216
[04:18:35.007] iteration 10496: loss: 0.095233, loss_s1: 0.103080, loss_fp: 0.003504, loss_freq: 0.034532
[04:18:35.603] iteration 10497: loss: 0.131874, loss_s1: 0.098882, loss_fp: 0.001812, loss_freq: 0.098810
[04:18:36.199] iteration 10498: loss: 0.171759, loss_s1: 0.178359, loss_fp: 0.002619, loss_freq: 0.039628
[04:18:36.792] iteration 10499: loss: 0.057443, loss_s1: 0.049133, loss_fp: 0.002795, loss_freq: 0.022429
[04:18:37.384] iteration 10500: loss: 0.077203, loss_s1: 0.088493, loss_fp: 0.004290, loss_freq: 0.018305
[04:18:37.975] iteration 10501: loss: 0.072949, loss_s1: 0.052371, loss_fp: 0.001449, loss_freq: 0.031497
[04:18:38.564] iteration 10502: loss: 0.062478, loss_s1: 0.030818, loss_fp: 0.002302, loss_freq: 0.012929
[04:18:39.150] iteration 10503: loss: 0.063225, loss_s1: 0.029284, loss_fp: 0.002439, loss_freq: 0.045361
[04:18:39.739] iteration 10504: loss: 0.081729, loss_s1: 0.072430, loss_fp: 0.003633, loss_freq: 0.033526
[04:18:40.335] iteration 10505: loss: 0.050918, loss_s1: 0.024476, loss_fp: 0.001327, loss_freq: 0.033673
[04:18:40.928] iteration 10506: loss: 0.058744, loss_s1: 0.050612, loss_fp: 0.005517, loss_freq: 0.016807
[04:18:41.598] iteration 10507: loss: 0.096501, loss_s1: 0.079990, loss_fp: 0.000874, loss_freq: 0.025534
[04:18:42.192] iteration 10508: loss: 0.072047, loss_s1: 0.061414, loss_fp: 0.003875, loss_freq: 0.034220
[04:18:42.826] iteration 10509: loss: 0.095702, loss_s1: 0.097777, loss_fp: 0.013438, loss_freq: 0.034627
[04:18:43.453] iteration 10510: loss: 0.085932, loss_s1: 0.097992, loss_fp: 0.003613, loss_freq: 0.029444
[04:18:44.080] iteration 10511: loss: 0.094007, loss_s1: 0.091693, loss_fp: 0.007444, loss_freq: 0.046053
[04:18:44.683] iteration 10512: loss: 0.082409, loss_s1: 0.073016, loss_fp: 0.003184, loss_freq: 0.034990
[04:18:45.339] iteration 10513: loss: 0.078146, loss_s1: 0.026270, loss_fp: 0.006785, loss_freq: 0.032238
[04:18:45.973] iteration 10514: loss: 0.068511, loss_s1: 0.039938, loss_fp: 0.007764, loss_freq: 0.018882
[04:18:46.618] iteration 10515: loss: 0.054845, loss_s1: 0.044372, loss_fp: 0.002119, loss_freq: 0.017196
[04:18:47.244] iteration 10516: loss: 0.065714, loss_s1: 0.039320, loss_fp: 0.003533, loss_freq: 0.030136
[04:18:47.840] iteration 10517: loss: 0.056641, loss_s1: 0.031380, loss_fp: 0.001661, loss_freq: 0.031990
[04:18:48.436] iteration 10518: loss: 0.124296, loss_s1: 0.120394, loss_fp: 0.005114, loss_freq: 0.076497
[04:18:49.025] iteration 10519: loss: 0.076919, loss_s1: 0.082531, loss_fp: 0.002561, loss_freq: 0.037423
[04:18:49.619] iteration 10520: loss: 0.086742, loss_s1: 0.070980, loss_fp: 0.003993, loss_freq: 0.050217
[04:18:50.208] iteration 10521: loss: 0.078760, loss_s1: 0.033435, loss_fp: 0.002069, loss_freq: 0.047927
[04:18:50.804] iteration 10522: loss: 0.082469, loss_s1: 0.064433, loss_fp: 0.003574, loss_freq: 0.058797
[04:18:51.393] iteration 10523: loss: 0.134091, loss_s1: 0.079104, loss_fp: 0.017339, loss_freq: 0.049945
[04:18:51.981] iteration 10524: loss: 0.091892, loss_s1: 0.070232, loss_fp: 0.005729, loss_freq: 0.061985
[04:18:52.577] iteration 10525: loss: 0.112360, loss_s1: 0.068341, loss_fp: 0.001721, loss_freq: 0.081102
[04:18:53.172] iteration 10526: loss: 0.050640, loss_s1: 0.041749, loss_fp: 0.000796, loss_freq: 0.013392
[04:18:53.763] iteration 10527: loss: 0.050877, loss_s1: 0.044288, loss_fp: 0.002561, loss_freq: 0.023489
[04:18:54.356] iteration 10528: loss: 0.140510, loss_s1: 0.076516, loss_fp: 0.001692, loss_freq: 0.114389
[04:18:54.959] iteration 10529: loss: 0.084416, loss_s1: 0.077422, loss_fp: 0.002929, loss_freq: 0.051117
[04:18:55.563] iteration 10530: loss: 0.083253, loss_s1: 0.055461, loss_fp: 0.002967, loss_freq: 0.052723
[04:18:56.165] iteration 10531: loss: 0.035605, loss_s1: 0.015021, loss_fp: 0.002083, loss_freq: 0.009502
[04:18:56.756] iteration 10532: loss: 0.061441, loss_s1: 0.050984, loss_fp: 0.013463, loss_freq: 0.028782
[04:18:57.351] iteration 10533: loss: 0.041731, loss_s1: 0.021971, loss_fp: 0.000897, loss_freq: 0.012683
[04:18:57.941] iteration 10534: loss: 0.063613, loss_s1: 0.047093, loss_fp: 0.001026, loss_freq: 0.018984
[04:18:58.531] iteration 10535: loss: 0.041254, loss_s1: 0.018581, loss_fp: 0.002039, loss_freq: 0.016876
[04:18:59.121] iteration 10536: loss: 0.092272, loss_s1: 0.041739, loss_fp: 0.001671, loss_freq: 0.039369
[04:18:59.710] iteration 10537: loss: 0.084431, loss_s1: 0.053846, loss_fp: 0.008600, loss_freq: 0.052702
[04:19:00.304] iteration 10538: loss: 0.102422, loss_s1: 0.110900, loss_fp: 0.002143, loss_freq: 0.016276
[04:19:00.937] iteration 10539: loss: 0.096266, loss_s1: 0.050117, loss_fp: 0.003279, loss_freq: 0.040160
[04:19:01.566] iteration 10540: loss: 0.059669, loss_s1: 0.049413, loss_fp: 0.003332, loss_freq: 0.024721
[04:19:02.488] iteration 10541: loss: 0.066921, loss_s1: 0.059255, loss_fp: 0.003596, loss_freq: 0.023460
[04:19:03.082] iteration 10542: loss: 0.099868, loss_s1: 0.094052, loss_fp: 0.000781, loss_freq: 0.059185
[04:19:03.672] iteration 10543: loss: 0.078465, loss_s1: 0.085178, loss_fp: 0.002758, loss_freq: 0.013445
[04:19:04.261] iteration 10544: loss: 0.044796, loss_s1: 0.026072, loss_fp: 0.002413, loss_freq: 0.015211
[04:19:04.858] iteration 10545: loss: 0.076383, loss_s1: 0.061860, loss_fp: 0.003106, loss_freq: 0.033604
[04:19:05.458] iteration 10546: loss: 0.085912, loss_s1: 0.073866, loss_fp: 0.003798, loss_freq: 0.034780
[04:19:06.048] iteration 10547: loss: 0.073299, loss_s1: 0.058196, loss_fp: 0.011580, loss_freq: 0.031807
[04:19:06.673] iteration 10548: loss: 0.051492, loss_s1: 0.056413, loss_fp: 0.001372, loss_freq: 0.009860
[04:19:07.271] iteration 10549: loss: 0.054686, loss_s1: 0.039115, loss_fp: 0.003854, loss_freq: 0.015764
[04:19:07.875] iteration 10550: loss: 0.106998, loss_s1: 0.115598, loss_fp: 0.005994, loss_freq: 0.042703
[04:19:08.468] iteration 10551: loss: 0.087665, loss_s1: 0.088335, loss_fp: 0.001812, loss_freq: 0.026345
[04:19:09.063] iteration 10552: loss: 0.087270, loss_s1: 0.079322, loss_fp: 0.001693, loss_freq: 0.045547
[04:19:09.653] iteration 10553: loss: 0.073243, loss_s1: 0.061413, loss_fp: 0.001829, loss_freq: 0.038282
[04:19:10.244] iteration 10554: loss: 0.088708, loss_s1: 0.063729, loss_fp: 0.001188, loss_freq: 0.060777
[04:19:10.833] iteration 10555: loss: 0.089387, loss_s1: 0.096371, loss_fp: 0.002295, loss_freq: 0.022595
[04:19:11.423] iteration 10556: loss: 0.070849, loss_s1: 0.050186, loss_fp: 0.002205, loss_freq: 0.022817
[04:19:12.014] iteration 10557: loss: 0.114110, loss_s1: 0.095537, loss_fp: 0.016637, loss_freq: 0.077833
[04:19:12.607] iteration 10558: loss: 0.044351, loss_s1: 0.030213, loss_fp: 0.001965, loss_freq: 0.010141
[04:19:13.206] iteration 10559: loss: 0.054962, loss_s1: 0.051109, loss_fp: 0.009070, loss_freq: 0.015711
[04:19:13.800] iteration 10560: loss: 0.079375, loss_s1: 0.054881, loss_fp: 0.004780, loss_freq: 0.021985
[04:19:14.391] iteration 10561: loss: 0.059927, loss_s1: 0.041643, loss_fp: 0.006836, loss_freq: 0.022436
[04:19:15.032] iteration 10562: loss: 0.076451, loss_s1: 0.042361, loss_fp: 0.002958, loss_freq: 0.060330
[04:19:15.668] iteration 10563: loss: 0.077984, loss_s1: 0.045760, loss_fp: 0.001641, loss_freq: 0.039780
[04:19:16.311] iteration 10564: loss: 0.076264, loss_s1: 0.064658, loss_fp: 0.005157, loss_freq: 0.028676
[04:19:16.945] iteration 10565: loss: 0.056244, loss_s1: 0.018266, loss_fp: 0.002391, loss_freq: 0.045876
[04:19:17.592] iteration 10566: loss: 0.097483, loss_s1: 0.080980, loss_fp: 0.002191, loss_freq: 0.055107
[04:19:18.220] iteration 10567: loss: 0.081636, loss_s1: 0.065275, loss_fp: 0.001415, loss_freq: 0.017571
[04:19:18.817] iteration 10568: loss: 0.106648, loss_s1: 0.079749, loss_fp: 0.010006, loss_freq: 0.045583
[04:19:19.410] iteration 10569: loss: 0.070556, loss_s1: 0.029323, loss_fp: 0.001513, loss_freq: 0.059053
[04:19:20.005] iteration 10570: loss: 0.085070, loss_s1: 0.090229, loss_fp: 0.003352, loss_freq: 0.026805
[04:19:20.603] iteration 10571: loss: 0.068352, loss_s1: 0.042548, loss_fp: 0.004372, loss_freq: 0.036488
[04:19:21.196] iteration 10572: loss: 0.123984, loss_s1: 0.083133, loss_fp: 0.007898, loss_freq: 0.087109
[04:19:21.791] iteration 10573: loss: 0.115762, loss_s1: 0.118388, loss_fp: 0.010881, loss_freq: 0.050574
[04:19:22.388] iteration 10574: loss: 0.061087, loss_s1: 0.049187, loss_fp: 0.002330, loss_freq: 0.010207
[04:19:22.978] iteration 10575: loss: 0.088057, loss_s1: 0.078487, loss_fp: 0.003487, loss_freq: 0.038128
[04:19:23.579] iteration 10576: loss: 0.048062, loss_s1: 0.018979, loss_fp: 0.001112, loss_freq: 0.013583
[04:19:24.181] iteration 10577: loss: 0.105156, loss_s1: 0.100704, loss_fp: 0.002441, loss_freq: 0.054327
[04:19:24.772] iteration 10578: loss: 0.063406, loss_s1: 0.060863, loss_fp: 0.004985, loss_freq: 0.015002
[04:19:25.362] iteration 10579: loss: 0.087108, loss_s1: 0.070150, loss_fp: 0.007995, loss_freq: 0.035221
[04:19:25.958] iteration 10580: loss: 0.069911, loss_s1: 0.059425, loss_fp: 0.005177, loss_freq: 0.036759
[04:19:26.554] iteration 10581: loss: 0.068298, loss_s1: 0.025023, loss_fp: 0.001556, loss_freq: 0.032243
[04:19:27.169] iteration 10582: loss: 0.074690, loss_s1: 0.073614, loss_fp: 0.002007, loss_freq: 0.026455
[04:19:27.760] iteration 10583: loss: 0.081582, loss_s1: 0.075532, loss_fp: 0.002172, loss_freq: 0.051589
[04:19:28.349] iteration 10584: loss: 0.158014, loss_s1: 0.219951, loss_fp: 0.000883, loss_freq: 0.043078
[04:19:28.962] iteration 10585: loss: 0.085165, loss_s1: 0.070728, loss_fp: 0.011474, loss_freq: 0.028969
[04:19:29.550] iteration 10586: loss: 0.109137, loss_s1: 0.123965, loss_fp: 0.002175, loss_freq: 0.030949
[04:19:30.142] iteration 10587: loss: 0.057548, loss_s1: 0.058314, loss_fp: 0.000937, loss_freq: 0.015873
[04:19:30.733] iteration 10588: loss: 0.099665, loss_s1: 0.066248, loss_fp: 0.002840, loss_freq: 0.049661
[04:19:31.325] iteration 10589: loss: 0.075164, loss_s1: 0.047661, loss_fp: 0.002794, loss_freq: 0.021196
[04:19:31.924] iteration 10590: loss: 0.058429, loss_s1: 0.022569, loss_fp: 0.003348, loss_freq: 0.037107
[04:19:32.519] iteration 10591: loss: 0.084530, loss_s1: 0.042546, loss_fp: 0.001960, loss_freq: 0.020236
[04:19:33.112] iteration 10592: loss: 0.065772, loss_s1: 0.076372, loss_fp: 0.002156, loss_freq: 0.021371
[04:19:33.706] iteration 10593: loss: 0.094192, loss_s1: 0.043459, loss_fp: 0.000863, loss_freq: 0.035159
[04:19:34.303] iteration 10594: loss: 0.084466, loss_s1: 0.062519, loss_fp: 0.002247, loss_freq: 0.045595
[04:19:34.896] iteration 10595: loss: 0.081235, loss_s1: 0.050848, loss_fp: 0.001348, loss_freq: 0.050633
[04:19:35.534] iteration 10596: loss: 0.066431, loss_s1: 0.060782, loss_fp: 0.000770, loss_freq: 0.026152
[04:19:36.177] iteration 10597: loss: 0.072364, loss_s1: 0.052993, loss_fp: 0.002961, loss_freq: 0.048257
[04:19:36.809] iteration 10598: loss: 0.053686, loss_s1: 0.027993, loss_fp: 0.001278, loss_freq: 0.012239
[04:19:37.443] iteration 10599: loss: 0.064217, loss_s1: 0.037331, loss_fp: 0.003336, loss_freq: 0.033464
[04:19:38.086] iteration 10600: loss: 0.071049, loss_s1: 0.063896, loss_fp: 0.003124, loss_freq: 0.039663
[04:19:42.076] iteration 10600 : mean_dice : 0.711790
[04:19:42.719] iteration 10601: loss: 0.044438, loss_s1: 0.031339, loss_fp: 0.002258, loss_freq: 0.013122
[04:19:43.374] iteration 10602: loss: 0.137084, loss_s1: 0.049692, loss_fp: 0.003910, loss_freq: 0.046477
[04:19:44.093] iteration 10603: loss: 0.050308, loss_s1: 0.043473, loss_fp: 0.001305, loss_freq: 0.005117
[04:19:44.809] iteration 10604: loss: 0.052675, loss_s1: 0.037336, loss_fp: 0.004683, loss_freq: 0.026493
[04:19:45.418] iteration 10605: loss: 0.123054, loss_s1: 0.158260, loss_fp: 0.008542, loss_freq: 0.034316
[04:19:46.104] iteration 10606: loss: 0.068636, loss_s1: 0.032182, loss_fp: 0.003170, loss_freq: 0.050757
[04:19:46.742] iteration 10607: loss: 0.059669, loss_s1: 0.017090, loss_fp: 0.006406, loss_freq: 0.016437
[04:19:47.397] iteration 10608: loss: 0.146057, loss_s1: 0.105473, loss_fp: 0.002427, loss_freq: 0.080421
[04:19:48.149] iteration 10609: loss: 0.068955, loss_s1: 0.015411, loss_fp: 0.004092, loss_freq: 0.030214
[04:19:48.788] iteration 10610: loss: 0.063915, loss_s1: 0.040901, loss_fp: 0.004848, loss_freq: 0.030803
[04:19:49.487] iteration 10611: loss: 0.074801, loss_s1: 0.037075, loss_fp: 0.003961, loss_freq: 0.045389
[04:19:50.127] iteration 10612: loss: 0.079361, loss_s1: 0.050575, loss_fp: 0.003178, loss_freq: 0.040938
[04:19:50.766] iteration 10613: loss: 0.062820, loss_s1: 0.044524, loss_fp: 0.003606, loss_freq: 0.036068
[04:19:51.357] iteration 10614: loss: 0.095145, loss_s1: 0.109167, loss_fp: 0.002942, loss_freq: 0.025567
[04:19:51.955] iteration 10615: loss: 0.094986, loss_s1: 0.053410, loss_fp: 0.003959, loss_freq: 0.058228
[04:19:52.565] iteration 10616: loss: 0.094943, loss_s1: 0.037059, loss_fp: 0.007078, loss_freq: 0.035517
[04:19:53.154] iteration 10617: loss: 0.059318, loss_s1: 0.039802, loss_fp: 0.002246, loss_freq: 0.023389
[04:19:53.745] iteration 10618: loss: 0.104515, loss_s1: 0.077983, loss_fp: 0.002281, loss_freq: 0.064488
[04:19:54.339] iteration 10619: loss: 0.052989, loss_s1: 0.037857, loss_fp: 0.008952, loss_freq: 0.027222
[04:19:54.936] iteration 10620: loss: 0.067438, loss_s1: 0.056880, loss_fp: 0.001635, loss_freq: 0.011249
[04:19:55.528] iteration 10621: loss: 0.074771, loss_s1: 0.047568, loss_fp: 0.008157, loss_freq: 0.040977
[04:19:56.117] iteration 10622: loss: 0.066986, loss_s1: 0.044947, loss_fp: 0.007248, loss_freq: 0.044154
[04:19:56.706] iteration 10623: loss: 0.082888, loss_s1: 0.066346, loss_fp: 0.003120, loss_freq: 0.021760
[04:19:57.301] iteration 10624: loss: 0.065308, loss_s1: 0.053188, loss_fp: 0.006842, loss_freq: 0.018174
[04:19:57.893] iteration 10625: loss: 0.110604, loss_s1: 0.112225, loss_fp: 0.002404, loss_freq: 0.025093
[04:19:58.511] iteration 10626: loss: 0.052192, loss_s1: 0.037688, loss_fp: 0.002321, loss_freq: 0.022276
[04:19:59.140] iteration 10627: loss: 0.103388, loss_s1: 0.145723, loss_fp: 0.000871, loss_freq: 0.024887
[04:20:00.205] iteration 10628: loss: 0.080266, loss_s1: 0.085644, loss_fp: 0.000716, loss_freq: 0.014005
[04:20:00.937] iteration 10629: loss: 0.081632, loss_s1: 0.064719, loss_fp: 0.011277, loss_freq: 0.036194
[04:20:01.723] iteration 10630: loss: 0.060039, loss_s1: 0.037425, loss_fp: 0.004393, loss_freq: 0.017513
[04:20:02.398] iteration 10631: loss: 0.091100, loss_s1: 0.073799, loss_fp: 0.001388, loss_freq: 0.026666
[04:20:03.043] iteration 10632: loss: 0.075094, loss_s1: 0.050236, loss_fp: 0.002448, loss_freq: 0.044958
[04:20:03.675] iteration 10633: loss: 0.099895, loss_s1: 0.041534, loss_fp: 0.003263, loss_freq: 0.069389
[04:20:04.313] iteration 10634: loss: 0.055544, loss_s1: 0.048999, loss_fp: 0.001760, loss_freq: 0.011172
[04:20:04.950] iteration 10635: loss: 0.090580, loss_s1: 0.072382, loss_fp: 0.005494, loss_freq: 0.036115
[04:20:05.609] iteration 10636: loss: 0.100722, loss_s1: 0.082701, loss_fp: 0.003431, loss_freq: 0.058170
[04:20:06.474] iteration 10637: loss: 0.077035, loss_s1: 0.041093, loss_fp: 0.001486, loss_freq: 0.041489
[04:20:07.238] iteration 10638: loss: 0.090708, loss_s1: 0.053206, loss_fp: 0.000974, loss_freq: 0.080641
[04:20:08.073] iteration 10639: loss: 0.090959, loss_s1: 0.060707, loss_fp: 0.003615, loss_freq: 0.071755
[04:20:08.803] iteration 10640: loss: 0.058647, loss_s1: 0.033137, loss_fp: 0.003393, loss_freq: 0.022495
[04:20:09.436] iteration 10641: loss: 0.047372, loss_s1: 0.038010, loss_fp: 0.001347, loss_freq: 0.022133
[04:20:10.074] iteration 10642: loss: 0.057842, loss_s1: 0.030113, loss_fp: 0.003079, loss_freq: 0.015181
[04:20:10.757] iteration 10643: loss: 0.077540, loss_s1: 0.043334, loss_fp: 0.001104, loss_freq: 0.043783
[04:20:11.378] iteration 10644: loss: 0.068527, loss_s1: 0.038719, loss_fp: 0.003419, loss_freq: 0.030408
[04:20:12.003] iteration 10645: loss: 0.066748, loss_s1: 0.054557, loss_fp: 0.007901, loss_freq: 0.027021
[04:20:12.646] iteration 10646: loss: 0.079256, loss_s1: 0.076844, loss_fp: 0.003967, loss_freq: 0.021295
[04:20:13.301] iteration 10647: loss: 0.059766, loss_s1: 0.028850, loss_fp: 0.004305, loss_freq: 0.021570
[04:20:13.929] iteration 10648: loss: 0.069996, loss_s1: 0.052010, loss_fp: 0.004032, loss_freq: 0.029489
[04:20:14.559] iteration 10649: loss: 0.068366, loss_s1: 0.014304, loss_fp: 0.003159, loss_freq: 0.063731
[04:20:15.185] iteration 10650: loss: 0.069749, loss_s1: 0.041774, loss_fp: 0.004264, loss_freq: 0.037680
[04:20:15.843] iteration 10651: loss: 0.101160, loss_s1: 0.071882, loss_fp: 0.004712, loss_freq: 0.051907
[04:20:16.494] iteration 10652: loss: 0.098611, loss_s1: 0.080823, loss_fp: 0.003878, loss_freq: 0.035394
[04:20:17.134] iteration 10653: loss: 0.058232, loss_s1: 0.052996, loss_fp: 0.000875, loss_freq: 0.030680
[04:20:17.789] iteration 10654: loss: 0.075308, loss_s1: 0.031095, loss_fp: 0.005761, loss_freq: 0.055826
[04:20:18.453] iteration 10655: loss: 0.088599, loss_s1: 0.041092, loss_fp: 0.006386, loss_freq: 0.062743
[04:20:19.084] iteration 10656: loss: 0.097031, loss_s1: 0.066925, loss_fp: 0.003468, loss_freq: 0.036394
[04:20:19.715] iteration 10657: loss: 0.068698, loss_s1: 0.059187, loss_fp: 0.001576, loss_freq: 0.027424
[04:20:20.342] iteration 10658: loss: 0.061057, loss_s1: 0.042502, loss_fp: 0.002090, loss_freq: 0.027196
[04:20:20.993] iteration 10659: loss: 0.125584, loss_s1: 0.074125, loss_fp: 0.001266, loss_freq: 0.107758
[04:20:21.632] iteration 10660: loss: 0.135356, loss_s1: 0.177331, loss_fp: 0.003598, loss_freq: 0.035537
[04:20:22.269] iteration 10661: loss: 0.050660, loss_s1: 0.025653, loss_fp: 0.009330, loss_freq: 0.011792
[04:20:22.970] iteration 10662: loss: 0.067967, loss_s1: 0.061213, loss_fp: 0.003046, loss_freq: 0.034086
[04:20:23.658] iteration 10663: loss: 0.098287, loss_s1: 0.105813, loss_fp: 0.002214, loss_freq: 0.030845
[04:20:24.322] iteration 10664: loss: 0.059210, loss_s1: 0.043280, loss_fp: 0.002349, loss_freq: 0.031966
[04:20:24.952] iteration 10665: loss: 0.065679, loss_s1: 0.044031, loss_fp: 0.001030, loss_freq: 0.026483
[04:20:25.581] iteration 10666: loss: 0.084390, loss_s1: 0.093129, loss_fp: 0.002065, loss_freq: 0.016468
[04:20:26.203] iteration 10667: loss: 0.112948, loss_s1: 0.085229, loss_fp: 0.002917, loss_freq: 0.103965
[04:20:26.831] iteration 10668: loss: 0.082893, loss_s1: 0.059977, loss_fp: 0.003102, loss_freq: 0.036105
[04:20:27.463] iteration 10669: loss: 0.061128, loss_s1: 0.049959, loss_fp: 0.002564, loss_freq: 0.036014
[04:20:28.101] iteration 10670: loss: 0.093548, loss_s1: 0.084297, loss_fp: 0.000975, loss_freq: 0.046427
[04:20:28.747] iteration 10671: loss: 0.082046, loss_s1: 0.104146, loss_fp: 0.003558, loss_freq: 0.017715
[04:20:29.379] iteration 10672: loss: 0.094234, loss_s1: 0.090129, loss_fp: 0.001866, loss_freq: 0.029592
[04:20:30.008] iteration 10673: loss: 0.070851, loss_s1: 0.066459, loss_fp: 0.007494, loss_freq: 0.027698
[04:20:30.717] iteration 10674: loss: 0.077157, loss_s1: 0.054385, loss_fp: 0.001927, loss_freq: 0.031488
[04:20:31.415] iteration 10675: loss: 0.092471, loss_s1: 0.023613, loss_fp: 0.011353, loss_freq: 0.084254
[04:20:32.084] iteration 10676: loss: 0.083696, loss_s1: 0.069503, loss_fp: 0.004376, loss_freq: 0.038078
[04:20:32.807] iteration 10677: loss: 0.085217, loss_s1: 0.052392, loss_fp: 0.003853, loss_freq: 0.033241
[04:20:33.518] iteration 10678: loss: 0.100946, loss_s1: 0.091355, loss_fp: 0.002023, loss_freq: 0.070291
[04:20:34.157] iteration 10679: loss: 0.125718, loss_s1: 0.128335, loss_fp: 0.012395, loss_freq: 0.068952
[04:20:34.797] iteration 10680: loss: 0.079501, loss_s1: 0.095081, loss_fp: 0.003462, loss_freq: 0.029031
[04:20:35.425] iteration 10681: loss: 0.065133, loss_s1: 0.034683, loss_fp: 0.009620, loss_freq: 0.037061
[04:20:36.051] iteration 10682: loss: 0.100333, loss_s1: 0.085766, loss_fp: 0.014607, loss_freq: 0.043039
[04:20:36.711] iteration 10683: loss: 0.063229, loss_s1: 0.029097, loss_fp: 0.005811, loss_freq: 0.042808
[04:20:37.335] iteration 10684: loss: 0.064785, loss_s1: 0.033918, loss_fp: 0.005191, loss_freq: 0.029556
[04:20:37.960] iteration 10685: loss: 0.055193, loss_s1: 0.036428, loss_fp: 0.002421, loss_freq: 0.015867
[04:20:38.593] iteration 10686: loss: 0.079155, loss_s1: 0.058497, loss_fp: 0.003645, loss_freq: 0.037291
[04:20:39.253] iteration 10687: loss: 0.067456, loss_s1: 0.044823, loss_fp: 0.004068, loss_freq: 0.034283
[04:20:39.890] iteration 10688: loss: 0.112538, loss_s1: 0.100539, loss_fp: 0.003381, loss_freq: 0.067960
[04:20:40.539] iteration 10689: loss: 0.126363, loss_s1: 0.138566, loss_fp: 0.004396, loss_freq: 0.057607
[04:20:41.170] iteration 10690: loss: 0.096243, loss_s1: 0.076777, loss_fp: 0.004370, loss_freq: 0.050811
[04:20:41.826] iteration 10691: loss: 0.114823, loss_s1: 0.113611, loss_fp: 0.004021, loss_freq: 0.043550
[04:20:42.453] iteration 10692: loss: 0.099804, loss_s1: 0.099050, loss_fp: 0.003447, loss_freq: 0.054727
[04:20:43.095] iteration 10693: loss: 0.137759, loss_s1: 0.134298, loss_fp: 0.014829, loss_freq: 0.079581
[04:20:43.727] iteration 10694: loss: 0.060434, loss_s1: 0.029384, loss_fp: 0.003354, loss_freq: 0.024825
[04:20:44.373] iteration 10695: loss: 0.089964, loss_s1: 0.069062, loss_fp: 0.002387, loss_freq: 0.058601
[04:20:44.996] iteration 10696: loss: 0.049359, loss_s1: 0.034624, loss_fp: 0.002012, loss_freq: 0.008122
[04:20:45.640] iteration 10697: loss: 0.037449, loss_s1: 0.016590, loss_fp: 0.001850, loss_freq: 0.027152
[04:20:46.290] iteration 10698: loss: 0.116130, loss_s1: 0.090208, loss_fp: 0.003531, loss_freq: 0.087764
[04:20:46.935] iteration 10699: loss: 0.087133, loss_s1: 0.043823, loss_fp: 0.003156, loss_freq: 0.051311
[04:20:47.567] iteration 10700: loss: 0.081298, loss_s1: 0.052044, loss_fp: 0.005179, loss_freq: 0.025889
[04:20:48.209] iteration 10701: loss: 0.057475, loss_s1: 0.050094, loss_fp: 0.001576, loss_freq: 0.005523
[04:20:48.852] iteration 10702: loss: 0.052554, loss_s1: 0.030241, loss_fp: 0.005078, loss_freq: 0.034320
[04:20:49.491] iteration 10703: loss: 0.049811, loss_s1: 0.017506, loss_fp: 0.001809, loss_freq: 0.015278
[04:20:50.132] iteration 10704: loss: 0.052046, loss_s1: 0.033766, loss_fp: 0.001901, loss_freq: 0.033794
[04:20:50.760] iteration 10705: loss: 0.049129, loss_s1: 0.038914, loss_fp: 0.001299, loss_freq: 0.011898
[04:20:51.387] iteration 10706: loss: 0.113120, loss_s1: 0.138197, loss_fp: 0.001424, loss_freq: 0.032043
[04:20:52.015] iteration 10707: loss: 0.098081, loss_s1: 0.073166, loss_fp: 0.002053, loss_freq: 0.062049
[04:20:52.657] iteration 10708: loss: 0.055599, loss_s1: 0.036542, loss_fp: 0.005535, loss_freq: 0.020879
[04:20:53.279] iteration 10709: loss: 0.102234, loss_s1: 0.086393, loss_fp: 0.013084, loss_freq: 0.065011
[04:20:53.899] iteration 10710: loss: 0.096005, loss_s1: 0.078786, loss_fp: 0.002676, loss_freq: 0.053756
[04:20:54.907] iteration 10711: loss: 0.051082, loss_s1: 0.033584, loss_fp: 0.000860, loss_freq: 0.017221
[04:20:55.584] iteration 10712: loss: 0.053913, loss_s1: 0.039028, loss_fp: 0.000853, loss_freq: 0.017116
[04:20:56.294] iteration 10713: loss: 0.060499, loss_s1: 0.048473, loss_fp: 0.001308, loss_freq: 0.034151
[04:20:56.930] iteration 10714: loss: 0.055266, loss_s1: 0.050436, loss_fp: 0.000790, loss_freq: 0.013079
[04:20:57.582] iteration 10715: loss: 0.083631, loss_s1: 0.055859, loss_fp: 0.001033, loss_freq: 0.060005
[04:20:58.211] iteration 10716: loss: 0.052218, loss_s1: 0.033236, loss_fp: 0.002118, loss_freq: 0.016770
[04:20:58.843] iteration 10717: loss: 0.087636, loss_s1: 0.062173, loss_fp: 0.003646, loss_freq: 0.055707
[04:20:59.481] iteration 10718: loss: 0.072439, loss_s1: 0.042605, loss_fp: 0.004437, loss_freq: 0.052160
[04:21:00.133] iteration 10719: loss: 0.035089, loss_s1: 0.016399, loss_fp: 0.001903, loss_freq: 0.010789
[04:21:00.822] iteration 10720: loss: 0.089338, loss_s1: 0.063233, loss_fp: 0.004074, loss_freq: 0.055943
[04:21:01.486] iteration 10721: loss: 0.077486, loss_s1: 0.043976, loss_fp: 0.000559, loss_freq: 0.053405
[04:21:02.171] iteration 10722: loss: 0.111805, loss_s1: 0.079747, loss_fp: 0.001723, loss_freq: 0.088735
[04:21:02.837] iteration 10723: loss: 0.078431, loss_s1: 0.042579, loss_fp: 0.003189, loss_freq: 0.065895
[04:21:03.492] iteration 10724: loss: 0.082427, loss_s1: 0.055241, loss_fp: 0.002277, loss_freq: 0.018214
[04:21:04.125] iteration 10725: loss: 0.099513, loss_s1: 0.097830, loss_fp: 0.006627, loss_freq: 0.020465
[04:21:04.748] iteration 10726: loss: 0.085330, loss_s1: 0.056249, loss_fp: 0.001550, loss_freq: 0.062254
[04:21:05.380] iteration 10727: loss: 0.148543, loss_s1: 0.128718, loss_fp: 0.009080, loss_freq: 0.126131
[04:21:06.009] iteration 10728: loss: 0.057628, loss_s1: 0.036567, loss_fp: 0.000980, loss_freq: 0.030289
[04:21:06.675] iteration 10729: loss: 0.097949, loss_s1: 0.106617, loss_fp: 0.004018, loss_freq: 0.031974
[04:21:07.336] iteration 10730: loss: 0.122912, loss_s1: 0.148972, loss_fp: 0.003700, loss_freq: 0.026905
[04:21:07.967] iteration 10731: loss: 0.072561, loss_s1: 0.062449, loss_fp: 0.001983, loss_freq: 0.035887
[04:21:08.612] iteration 10732: loss: 0.076322, loss_s1: 0.064990, loss_fp: 0.002854, loss_freq: 0.042002
[04:21:09.274] iteration 10733: loss: 0.155419, loss_s1: 0.066376, loss_fp: 0.001432, loss_freq: 0.038353
[04:21:09.909] iteration 10734: loss: 0.068286, loss_s1: 0.054825, loss_fp: 0.002004, loss_freq: 0.033039
[04:21:10.540] iteration 10735: loss: 0.094690, loss_s1: 0.089196, loss_fp: 0.003024, loss_freq: 0.046577
[04:21:11.181] iteration 10736: loss: 0.078194, loss_s1: 0.072901, loss_fp: 0.004713, loss_freq: 0.046092
[04:21:11.821] iteration 10737: loss: 0.098690, loss_s1: 0.057152, loss_fp: 0.003772, loss_freq: 0.029495
[04:21:12.450] iteration 10738: loss: 0.119829, loss_s1: 0.121636, loss_fp: 0.006397, loss_freq: 0.019145
[04:21:13.094] iteration 10739: loss: 0.090061, loss_s1: 0.098626, loss_fp: 0.001423, loss_freq: 0.018130
[04:21:13.773] iteration 10740: loss: 0.081541, loss_s1: 0.072224, loss_fp: 0.007185, loss_freq: 0.031141
[04:21:14.400] iteration 10741: loss: 0.102547, loss_s1: 0.083800, loss_fp: 0.004607, loss_freq: 0.063479
[04:21:15.032] iteration 10742: loss: 0.113307, loss_s1: 0.124984, loss_fp: 0.007844, loss_freq: 0.039862
[04:21:15.666] iteration 10743: loss: 0.095320, loss_s1: 0.059968, loss_fp: 0.001484, loss_freq: 0.041541
[04:21:16.290] iteration 10744: loss: 0.081899, loss_s1: 0.055780, loss_fp: 0.007276, loss_freq: 0.030519
[04:21:16.923] iteration 10745: loss: 0.113482, loss_s1: 0.074410, loss_fp: 0.003364, loss_freq: 0.043213
[04:21:17.569] iteration 10746: loss: 0.060048, loss_s1: 0.020925, loss_fp: 0.000837, loss_freq: 0.015076
[04:21:18.239] iteration 10747: loss: 0.066456, loss_s1: 0.040584, loss_fp: 0.004017, loss_freq: 0.036051
[04:21:18.868] iteration 10748: loss: 0.048164, loss_s1: 0.014332, loss_fp: 0.002772, loss_freq: 0.012714
[04:21:19.523] iteration 10749: loss: 0.121848, loss_s1: 0.127917, loss_fp: 0.003256, loss_freq: 0.058964
[04:21:20.255] iteration 10750: loss: 0.096723, loss_s1: 0.091385, loss_fp: 0.002238, loss_freq: 0.044359
[04:21:20.923] iteration 10751: loss: 0.108154, loss_s1: 0.061837, loss_fp: 0.002591, loss_freq: 0.092476
[04:21:21.561] iteration 10752: loss: 0.067649, loss_s1: 0.049370, loss_fp: 0.000759, loss_freq: 0.047613
[04:21:22.184] iteration 10753: loss: 0.098406, loss_s1: 0.083842, loss_fp: 0.001804, loss_freq: 0.054593
[04:21:22.823] iteration 10754: loss: 0.115398, loss_s1: 0.096741, loss_fp: 0.010317, loss_freq: 0.082690
[04:21:23.459] iteration 10755: loss: 0.100060, loss_s1: 0.091358, loss_fp: 0.008863, loss_freq: 0.031226
[04:21:24.097] iteration 10756: loss: 0.114263, loss_s1: 0.127809, loss_fp: 0.002081, loss_freq: 0.042052
[04:21:24.724] iteration 10757: loss: 0.050317, loss_s1: 0.028358, loss_fp: 0.005871, loss_freq: 0.014809
[04:21:25.351] iteration 10758: loss: 0.082768, loss_s1: 0.073074, loss_fp: 0.005338, loss_freq: 0.038715
[04:21:26.008] iteration 10759: loss: 0.065128, loss_s1: 0.070123, loss_fp: 0.001380, loss_freq: 0.006833
[04:21:26.652] iteration 10760: loss: 0.072524, loss_s1: 0.061752, loss_fp: 0.001061, loss_freq: 0.032756
[04:21:27.278] iteration 10761: loss: 0.062766, loss_s1: 0.051871, loss_fp: 0.000878, loss_freq: 0.025242
[04:21:27.914] iteration 10762: loss: 0.081059, loss_s1: 0.085171, loss_fp: 0.002785, loss_freq: 0.033295
[04:21:28.533] iteration 10763: loss: 0.063356, loss_s1: 0.034711, loss_fp: 0.001359, loss_freq: 0.039588
[04:21:29.157] iteration 10764: loss: 0.110259, loss_s1: 0.130147, loss_fp: 0.009630, loss_freq: 0.035823
[04:21:29.796] iteration 10765: loss: 0.067241, loss_s1: 0.029171, loss_fp: 0.003017, loss_freq: 0.050808
[04:21:30.420] iteration 10766: loss: 0.051715, loss_s1: 0.035247, loss_fp: 0.004475, loss_freq: 0.018010
[04:21:31.038] iteration 10767: loss: 0.056643, loss_s1: 0.033110, loss_fp: 0.002339, loss_freq: 0.028889
[04:21:31.669] iteration 10768: loss: 0.065950, loss_s1: 0.041911, loss_fp: 0.001403, loss_freq: 0.022442
[04:21:32.304] iteration 10769: loss: 0.065723, loss_s1: 0.029470, loss_fp: 0.003719, loss_freq: 0.025586
[04:21:32.943] iteration 10770: loss: 0.092207, loss_s1: 0.070855, loss_fp: 0.003878, loss_freq: 0.052997
[04:21:33.585] iteration 10771: loss: 0.061407, loss_s1: 0.042987, loss_fp: 0.004164, loss_freq: 0.016329
[04:21:34.232] iteration 10772: loss: 0.095542, loss_s1: 0.080531, loss_fp: 0.003537, loss_freq: 0.050686
[04:21:34.858] iteration 10773: loss: 0.049257, loss_s1: 0.030796, loss_fp: 0.001394, loss_freq: 0.013034
[04:21:35.491] iteration 10774: loss: 0.049453, loss_s1: 0.032921, loss_fp: 0.003160, loss_freq: 0.024033
[04:21:36.124] iteration 10775: loss: 0.095046, loss_s1: 0.118861, loss_fp: 0.006083, loss_freq: 0.016203
[04:21:36.765] iteration 10776: loss: 0.064703, loss_s1: 0.034437, loss_fp: 0.003016, loss_freq: 0.041967
[04:21:37.420] iteration 10777: loss: 0.078843, loss_s1: 0.085881, loss_fp: 0.001788, loss_freq: 0.013103
[04:21:38.078] iteration 10778: loss: 0.129678, loss_s1: 0.129723, loss_fp: 0.006318, loss_freq: 0.063279
[04:21:38.729] iteration 10779: loss: 0.059336, loss_s1: 0.035659, loss_fp: 0.003396, loss_freq: 0.028761
[04:21:39.366] iteration 10780: loss: 0.071144, loss_s1: 0.048176, loss_fp: 0.005850, loss_freq: 0.049773
[04:21:39.995] iteration 10781: loss: 0.073651, loss_s1: 0.044336, loss_fp: 0.004554, loss_freq: 0.043804
[04:21:40.657] iteration 10782: loss: 0.057328, loss_s1: 0.028064, loss_fp: 0.003046, loss_freq: 0.033508
[04:21:41.293] iteration 10783: loss: 0.086068, loss_s1: 0.092016, loss_fp: 0.002530, loss_freq: 0.041662
[04:21:41.931] iteration 10784: loss: 0.102997, loss_s1: 0.131217, loss_fp: 0.001846, loss_freq: 0.024148
[04:21:42.551] iteration 10785: loss: 0.102226, loss_s1: 0.094840, loss_fp: 0.004265, loss_freq: 0.058962
[04:21:43.196] iteration 10786: loss: 0.091174, loss_s1: 0.064242, loss_fp: 0.005664, loss_freq: 0.064296
[04:21:43.863] iteration 10787: loss: 0.103271, loss_s1: 0.078785, loss_fp: 0.002661, loss_freq: 0.031598
[04:21:44.493] iteration 10788: loss: 0.076265, loss_s1: 0.078299, loss_fp: 0.002806, loss_freq: 0.016877
[04:21:45.142] iteration 10789: loss: 0.079496, loss_s1: 0.072826, loss_fp: 0.003147, loss_freq: 0.023656
[04:21:45.770] iteration 10790: loss: 0.067932, loss_s1: 0.054594, loss_fp: 0.005378, loss_freq: 0.023391
[04:21:46.421] iteration 10791: loss: 0.097784, loss_s1: 0.057853, loss_fp: 0.000747, loss_freq: 0.054246
[04:21:47.042] iteration 10792: loss: 0.069542, loss_s1: 0.042232, loss_fp: 0.008111, loss_freq: 0.042039
[04:21:47.680] iteration 10793: loss: 0.065619, loss_s1: 0.056243, loss_fp: 0.002016, loss_freq: 0.012745
[04:21:48.313] iteration 10794: loss: 0.104099, loss_s1: 0.132866, loss_fp: 0.004732, loss_freq: 0.024413
[04:21:48.992] iteration 10795: loss: 0.082712, loss_s1: 0.081517, loss_fp: 0.004312, loss_freq: 0.027376
[04:21:49.641] iteration 10796: loss: 0.059987, loss_s1: 0.052357, loss_fp: 0.001041, loss_freq: 0.022342
[04:21:50.308] iteration 10797: loss: 0.088853, loss_s1: 0.112262, loss_fp: 0.011744, loss_freq: 0.027281
[04:21:50.968] iteration 10798: loss: 0.083431, loss_s1: 0.051710, loss_fp: 0.001493, loss_freq: 0.032873
[04:21:51.613] iteration 10799: loss: 0.106816, loss_s1: 0.094381, loss_fp: 0.004731, loss_freq: 0.074818
[04:21:52.251] iteration 10800: loss: 0.097842, loss_s1: 0.093779, loss_fp: 0.001702, loss_freq: 0.034469
[04:21:55.698] iteration 10800 : mean_dice : 0.695131
[04:21:56.367] iteration 10801: loss: 0.085310, loss_s1: 0.085656, loss_fp: 0.002809, loss_freq: 0.033758
[04:21:57.001] iteration 10802: loss: 0.110001, loss_s1: 0.061001, loss_fp: 0.004308, loss_freq: 0.114204
[04:21:57.618] iteration 10803: loss: 0.122326, loss_s1: 0.159578, loss_fp: 0.004227, loss_freq: 0.023554
[04:21:58.243] iteration 10804: loss: 0.042550, loss_s1: 0.020114, loss_fp: 0.001095, loss_freq: 0.019581
[04:21:58.874] iteration 10805: loss: 0.080555, loss_s1: 0.066134, loss_fp: 0.002585, loss_freq: 0.035576
[04:21:59.507] iteration 10806: loss: 0.074233, loss_s1: 0.044284, loss_fp: 0.002896, loss_freq: 0.047289
[04:22:00.136] iteration 10807: loss: 0.082320, loss_s1: 0.035812, loss_fp: 0.001249, loss_freq: 0.040649
[04:22:00.762] iteration 10808: loss: 0.074624, loss_s1: 0.061729, loss_fp: 0.002471, loss_freq: 0.023499
[04:22:01.412] iteration 10809: loss: 0.054882, loss_s1: 0.035973, loss_fp: 0.001323, loss_freq: 0.032031
[04:22:02.108] iteration 10810: loss: 0.059763, loss_s1: 0.037983, loss_fp: 0.002303, loss_freq: 0.034421
[04:22:02.744] iteration 10811: loss: 0.060842, loss_s1: 0.055847, loss_fp: 0.001580, loss_freq: 0.018241
[04:22:03.386] iteration 10812: loss: 0.055417, loss_s1: 0.037913, loss_fp: 0.000994, loss_freq: 0.011701
[04:22:04.020] iteration 10813: loss: 0.068363, loss_s1: 0.058439, loss_fp: 0.002450, loss_freq: 0.029852
[04:22:04.941] iteration 10814: loss: 0.050582, loss_s1: 0.022205, loss_fp: 0.002462, loss_freq: 0.023415
[04:22:05.956] iteration 10815: loss: 0.066531, loss_s1: 0.033850, loss_fp: 0.011632, loss_freq: 0.048621
[04:22:06.779] iteration 10816: loss: 0.156783, loss_s1: 0.052609, loss_fp: 0.003988, loss_freq: 0.024712
[04:22:07.495] iteration 10817: loss: 0.095253, loss_s1: 0.110852, loss_fp: 0.002160, loss_freq: 0.028853
[04:22:08.249] iteration 10818: loss: 0.053313, loss_s1: 0.035001, loss_fp: 0.002535, loss_freq: 0.027622
[04:22:08.971] iteration 10819: loss: 0.081047, loss_s1: 0.022905, loss_fp: 0.001349, loss_freq: 0.064018
[04:22:09.711] iteration 10820: loss: 0.057454, loss_s1: 0.051759, loss_fp: 0.000963, loss_freq: 0.019971
[04:22:10.482] iteration 10821: loss: 0.069129, loss_s1: 0.030344, loss_fp: 0.002326, loss_freq: 0.052846
[04:22:11.179] iteration 10822: loss: 0.064210, loss_s1: 0.041497, loss_fp: 0.004650, loss_freq: 0.025393
[04:22:11.906] iteration 10823: loss: 0.059224, loss_s1: 0.042060, loss_fp: 0.002061, loss_freq: 0.026507
[04:22:12.589] iteration 10824: loss: 0.060548, loss_s1: 0.048040, loss_fp: 0.003846, loss_freq: 0.015884
[04:22:13.311] iteration 10825: loss: 0.146981, loss_s1: 0.135761, loss_fp: 0.002660, loss_freq: 0.097222
[04:22:14.057] iteration 10826: loss: 0.073584, loss_s1: 0.051476, loss_fp: 0.003680, loss_freq: 0.039043
[04:22:14.747] iteration 10827: loss: 0.107328, loss_s1: 0.087366, loss_fp: 0.004351, loss_freq: 0.048826
[04:22:15.490] iteration 10828: loss: 0.063055, loss_s1: 0.043955, loss_fp: 0.001538, loss_freq: 0.041501
[04:22:16.212] iteration 10829: loss: 0.101807, loss_s1: 0.057808, loss_fp: 0.002043, loss_freq: 0.093112
[04:22:16.977] iteration 10830: loss: 0.051745, loss_s1: 0.024064, loss_fp: 0.004439, loss_freq: 0.032269
[04:22:17.691] iteration 10831: loss: 0.059920, loss_s1: 0.051151, loss_fp: 0.004119, loss_freq: 0.018623
[04:22:18.320] iteration 10832: loss: 0.097921, loss_s1: 0.103756, loss_fp: 0.007797, loss_freq: 0.024323
[04:22:18.944] iteration 10833: loss: 0.090571, loss_s1: 0.076663, loss_fp: 0.005744, loss_freq: 0.050480
[04:22:19.584] iteration 10834: loss: 0.058204, loss_s1: 0.047639, loss_fp: 0.000988, loss_freq: 0.025169
[04:22:20.217] iteration 10835: loss: 0.140536, loss_s1: 0.092009, loss_fp: 0.013422, loss_freq: 0.091623
[04:22:20.841] iteration 10836: loss: 0.056380, loss_s1: 0.045925, loss_fp: 0.000907, loss_freq: 0.017373
[04:22:21.566] iteration 10837: loss: 0.109188, loss_s1: 0.047609, loss_fp: 0.002591, loss_freq: 0.111086
[04:22:22.252] iteration 10838: loss: 0.074641, loss_s1: 0.051559, loss_fp: 0.005088, loss_freq: 0.040092
[04:22:22.946] iteration 10839: loss: 0.053335, loss_s1: 0.044520, loss_fp: 0.001917, loss_freq: 0.015869
[04:22:23.629] iteration 10840: loss: 0.127556, loss_s1: 0.079620, loss_fp: 0.016140, loss_freq: 0.057821
[04:22:24.258] iteration 10841: loss: 0.089505, loss_s1: 0.071674, loss_fp: 0.003376, loss_freq: 0.039163
[04:22:24.902] iteration 10842: loss: 0.070546, loss_s1: 0.047407, loss_fp: 0.005392, loss_freq: 0.025587
[04:22:25.545] iteration 10843: loss: 0.106331, loss_s1: 0.088580, loss_fp: 0.002792, loss_freq: 0.065044
[04:22:26.177] iteration 10844: loss: 0.096737, loss_s1: 0.115073, loss_fp: 0.003480, loss_freq: 0.026325
[04:22:26.836] iteration 10845: loss: 0.060418, loss_s1: 0.031508, loss_fp: 0.002332, loss_freq: 0.030595
[04:22:27.477] iteration 10846: loss: 0.044523, loss_s1: 0.017636, loss_fp: 0.001303, loss_freq: 0.017076
[04:22:28.106] iteration 10847: loss: 0.081960, loss_s1: 0.071968, loss_fp: 0.003565, loss_freq: 0.024204
[04:22:28.755] iteration 10848: loss: 0.090365, loss_s1: 0.054858, loss_fp: 0.002432, loss_freq: 0.086645
[04:22:29.396] iteration 10849: loss: 0.094043, loss_s1: 0.067708, loss_fp: 0.006461, loss_freq: 0.059551
[04:22:30.366] iteration 10850: loss: 0.059279, loss_s1: 0.043492, loss_fp: 0.004329, loss_freq: 0.031935
[04:22:31.266] iteration 10851: loss: 0.121130, loss_s1: 0.091579, loss_fp: 0.010115, loss_freq: 0.070648
[04:22:32.114] iteration 10852: loss: 0.077764, loss_s1: 0.046639, loss_fp: 0.007892, loss_freq: 0.041738
[04:22:32.791] iteration 10853: loss: 0.121869, loss_s1: 0.101734, loss_fp: 0.008808, loss_freq: 0.086022
[04:22:33.460] iteration 10854: loss: 0.098420, loss_s1: 0.069600, loss_fp: 0.008404, loss_freq: 0.042594
[04:22:34.086] iteration 10855: loss: 0.040055, loss_s1: 0.027704, loss_fp: 0.005012, loss_freq: 0.004300
[04:22:34.711] iteration 10856: loss: 0.062140, loss_s1: 0.024223, loss_fp: 0.002101, loss_freq: 0.028552
[04:22:35.412] iteration 10857: loss: 0.097667, loss_s1: 0.106264, loss_fp: 0.002838, loss_freq: 0.026737
[04:22:36.037] iteration 10858: loss: 0.105302, loss_s1: 0.104320, loss_fp: 0.002873, loss_freq: 0.052178
[04:22:36.682] iteration 10859: loss: 0.085670, loss_s1: 0.061422, loss_fp: 0.003392, loss_freq: 0.071388
[04:22:37.332] iteration 10860: loss: 0.089776, loss_s1: 0.078687, loss_fp: 0.005710, loss_freq: 0.026737
[04:22:37.998] iteration 10861: loss: 0.079638, loss_s1: 0.052189, loss_fp: 0.005165, loss_freq: 0.045683
[04:22:38.630] iteration 10862: loss: 0.105191, loss_s1: 0.125148, loss_fp: 0.002073, loss_freq: 0.035427
[04:22:39.302] iteration 10863: loss: 0.126038, loss_s1: 0.124514, loss_fp: 0.008538, loss_freq: 0.030378
[04:22:39.977] iteration 10864: loss: 0.082435, loss_s1: 0.050703, loss_fp: 0.014481, loss_freq: 0.041882
[04:22:40.648] iteration 10865: loss: 0.075762, loss_s1: 0.056502, loss_fp: 0.004476, loss_freq: 0.024056
[04:22:41.319] iteration 10866: loss: 0.081510, loss_s1: 0.077412, loss_fp: 0.002344, loss_freq: 0.035971
[04:22:41.993] iteration 10867: loss: 0.057603, loss_s1: 0.035874, loss_fp: 0.000968, loss_freq: 0.019016
[04:22:42.659] iteration 10868: loss: 0.082296, loss_s1: 0.057102, loss_fp: 0.001071, loss_freq: 0.064379
[04:22:43.368] iteration 10869: loss: 0.059087, loss_s1: 0.041096, loss_fp: 0.001396, loss_freq: 0.036495
[04:22:44.070] iteration 10870: loss: 0.069897, loss_s1: 0.049677, loss_fp: 0.005550, loss_freq: 0.025545
[04:22:44.767] iteration 10871: loss: 0.094906, loss_s1: 0.105428, loss_fp: 0.003342, loss_freq: 0.013104
[04:22:45.485] iteration 10872: loss: 0.065421, loss_s1: 0.044543, loss_fp: 0.005789, loss_freq: 0.029486
[04:22:46.163] iteration 10873: loss: 0.061027, loss_s1: 0.015693, loss_fp: 0.000511, loss_freq: 0.021628
[04:22:46.844] iteration 10874: loss: 0.057706, loss_s1: 0.039616, loss_fp: 0.001822, loss_freq: 0.022221
[04:22:47.518] iteration 10875: loss: 0.048820, loss_s1: 0.039275, loss_fp: 0.003853, loss_freq: 0.014888
[04:22:48.217] iteration 10876: loss: 0.075334, loss_s1: 0.090937, loss_fp: 0.000804, loss_freq: 0.017932
[04:22:48.860] iteration 10877: loss: 0.075114, loss_s1: 0.049235, loss_fp: 0.001235, loss_freq: 0.044823
[04:22:49.499] iteration 10878: loss: 0.064812, loss_s1: 0.036780, loss_fp: 0.002300, loss_freq: 0.033286
[04:22:50.133] iteration 10879: loss: 0.066572, loss_s1: 0.047508, loss_fp: 0.006523, loss_freq: 0.040111
[04:22:50.761] iteration 10880: loss: 0.092150, loss_s1: 0.083153, loss_fp: 0.003926, loss_freq: 0.041248
[04:22:51.774] iteration 10881: loss: 0.099635, loss_s1: 0.099059, loss_fp: 0.002086, loss_freq: 0.024615
[04:22:52.463] iteration 10882: loss: 0.058312, loss_s1: 0.028424, loss_fp: 0.002219, loss_freq: 0.028661
[04:22:53.154] iteration 10883: loss: 0.078479, loss_s1: 0.070365, loss_fp: 0.004384, loss_freq: 0.034507
[04:22:53.821] iteration 10884: loss: 0.075949, loss_s1: 0.086853, loss_fp: 0.004106, loss_freq: 0.016909
[04:22:54.446] iteration 10885: loss: 0.086556, loss_s1: 0.070332, loss_fp: 0.004863, loss_freq: 0.049255
[04:22:55.148] iteration 10886: loss: 0.062166, loss_s1: 0.056681, loss_fp: 0.003418, loss_freq: 0.018735
[04:22:55.774] iteration 10887: loss: 0.064814, loss_s1: 0.030623, loss_fp: 0.002076, loss_freq: 0.027300
[04:22:56.423] iteration 10888: loss: 0.086277, loss_s1: 0.078189, loss_fp: 0.003741, loss_freq: 0.043313
[04:22:57.055] iteration 10889: loss: 0.046447, loss_s1: 0.037144, loss_fp: 0.002304, loss_freq: 0.020916
[04:22:57.692] iteration 10890: loss: 0.072777, loss_s1: 0.048972, loss_fp: 0.005308, loss_freq: 0.030016
[04:22:58.329] iteration 10891: loss: 0.065423, loss_s1: 0.026316, loss_fp: 0.000732, loss_freq: 0.048855
[04:22:58.967] iteration 10892: loss: 0.096049, loss_s1: 0.056857, loss_fp: 0.003099, loss_freq: 0.087171
[04:22:59.589] iteration 10893: loss: 0.068655, loss_s1: 0.048110, loss_fp: 0.003217, loss_freq: 0.022164
[04:23:00.238] iteration 10894: loss: 0.058915, loss_s1: 0.025872, loss_fp: 0.001213, loss_freq: 0.036443
[04:23:00.895] iteration 10895: loss: 0.078221, loss_s1: 0.078933, loss_fp: 0.001279, loss_freq: 0.033571
[04:23:01.527] iteration 10896: loss: 0.061876, loss_s1: 0.050513, loss_fp: 0.001733, loss_freq: 0.032513
[04:23:02.169] iteration 10897: loss: 0.129541, loss_s1: 0.124572, loss_fp: 0.003162, loss_freq: 0.095190
[04:23:02.804] iteration 10898: loss: 0.064111, loss_s1: 0.042048, loss_fp: 0.004255, loss_freq: 0.018119
[04:23:03.440] iteration 10899: loss: 0.092526, loss_s1: 0.104543, loss_fp: 0.005853, loss_freq: 0.030238
[04:23:04.072] iteration 10900: loss: 0.093184, loss_s1: 0.091724, loss_fp: 0.001459, loss_freq: 0.036073
[04:23:04.718] iteration 10901: loss: 0.085656, loss_s1: 0.037510, loss_fp: 0.001224, loss_freq: 0.025690
[04:23:05.351] iteration 10902: loss: 0.068421, loss_s1: 0.047864, loss_fp: 0.004332, loss_freq: 0.048010
[04:23:05.978] iteration 10903: loss: 0.091455, loss_s1: 0.049529, loss_fp: 0.002346, loss_freq: 0.032374
[04:23:06.638] iteration 10904: loss: 0.063142, loss_s1: 0.066633, loss_fp: 0.001124, loss_freq: 0.020989
[04:23:07.277] iteration 10905: loss: 0.076645, loss_s1: 0.056612, loss_fp: 0.001193, loss_freq: 0.045661
[04:23:07.912] iteration 10906: loss: 0.096945, loss_s1: 0.072822, loss_fp: 0.001980, loss_freq: 0.050034
[04:23:08.559] iteration 10907: loss: 0.076464, loss_s1: 0.044916, loss_fp: 0.004663, loss_freq: 0.026333
[04:23:09.204] iteration 10908: loss: 0.152150, loss_s1: 0.182902, loss_fp: 0.002489, loss_freq: 0.027553
[04:23:09.828] iteration 10909: loss: 0.090811, loss_s1: 0.036823, loss_fp: 0.009372, loss_freq: 0.030152
[04:23:10.476] iteration 10910: loss: 0.106363, loss_s1: 0.086264, loss_fp: 0.000804, loss_freq: 0.055782
[04:23:11.100] iteration 10911: loss: 0.071452, loss_s1: 0.067868, loss_fp: 0.002330, loss_freq: 0.039063
[04:23:11.743] iteration 10912: loss: 0.086537, loss_s1: 0.084766, loss_fp: 0.002885, loss_freq: 0.042709
[04:23:12.395] iteration 10913: loss: 0.069577, loss_s1: 0.061994, loss_fp: 0.002625, loss_freq: 0.030161
[04:23:13.036] iteration 10914: loss: 0.049574, loss_s1: 0.042649, loss_fp: 0.005144, loss_freq: 0.012717
[04:23:13.672] iteration 10915: loss: 0.063519, loss_s1: 0.047617, loss_fp: 0.001051, loss_freq: 0.039161
[04:23:14.302] iteration 10916: loss: 0.070236, loss_s1: 0.042140, loss_fp: 0.005075, loss_freq: 0.031498
[04:23:14.931] iteration 10917: loss: 0.056880, loss_s1: 0.036589, loss_fp: 0.008698, loss_freq: 0.018057
[04:23:15.568] iteration 10918: loss: 0.074811, loss_s1: 0.056025, loss_fp: 0.004329, loss_freq: 0.042288
[04:23:16.195] iteration 10919: loss: 0.096061, loss_s1: 0.075271, loss_fp: 0.002808, loss_freq: 0.021750
[04:23:16.824] iteration 10920: loss: 0.103182, loss_s1: 0.083483, loss_fp: 0.005175, loss_freq: 0.067508
[04:23:17.448] iteration 10921: loss: 0.086946, loss_s1: 0.087171, loss_fp: 0.003396, loss_freq: 0.038819
[04:23:18.079] iteration 10922: loss: 0.098983, loss_s1: 0.119414, loss_fp: 0.003251, loss_freq: 0.021059
[04:23:18.704] iteration 10923: loss: 0.086590, loss_s1: 0.044427, loss_fp: 0.005785, loss_freq: 0.068456
[04:23:19.329] iteration 10924: loss: 0.095958, loss_s1: 0.089717, loss_fp: 0.005757, loss_freq: 0.051818
[04:23:19.958] iteration 10925: loss: 0.076156, loss_s1: 0.046280, loss_fp: 0.002852, loss_freq: 0.044206
[04:23:20.607] iteration 10926: loss: 0.081577, loss_s1: 0.072101, loss_fp: 0.012508, loss_freq: 0.029880
[04:23:21.245] iteration 10927: loss: 0.075375, loss_s1: 0.057435, loss_fp: 0.005966, loss_freq: 0.019039
[04:23:21.878] iteration 10928: loss: 0.071175, loss_s1: 0.053478, loss_fp: 0.001203, loss_freq: 0.042765
[04:23:22.514] iteration 10929: loss: 0.058609, loss_s1: 0.059522, loss_fp: 0.001343, loss_freq: 0.019562
[04:23:23.150] iteration 10930: loss: 0.056561, loss_s1: 0.035508, loss_fp: 0.002088, loss_freq: 0.025291
[04:23:23.801] iteration 10931: loss: 0.063601, loss_s1: 0.033675, loss_fp: 0.001542, loss_freq: 0.033815
[04:23:24.477] iteration 10932: loss: 0.091218, loss_s1: 0.097288, loss_fp: 0.006326, loss_freq: 0.053607
[04:23:25.161] iteration 10933: loss: 0.101974, loss_s1: 0.032109, loss_fp: 0.001765, loss_freq: 0.082561
[04:23:25.802] iteration 10934: loss: 0.105512, loss_s1: 0.102146, loss_fp: 0.006625, loss_freq: 0.037068
[04:23:26.480] iteration 10935: loss: 0.084420, loss_s1: 0.030286, loss_fp: 0.004238, loss_freq: 0.056976
[04:23:27.113] iteration 10936: loss: 0.066687, loss_s1: 0.034467, loss_fp: 0.001471, loss_freq: 0.031580
[04:23:27.737] iteration 10937: loss: 0.066189, loss_s1: 0.057828, loss_fp: 0.005780, loss_freq: 0.024916
[04:23:28.362] iteration 10938: loss: 0.079365, loss_s1: 0.071286, loss_fp: 0.002402, loss_freq: 0.031364
[04:23:28.996] iteration 10939: loss: 0.092702, loss_s1: 0.031052, loss_fp: 0.000726, loss_freq: 0.037967
[04:23:29.634] iteration 10940: loss: 0.085957, loss_s1: 0.041581, loss_fp: 0.000669, loss_freq: 0.081123
[04:23:30.296] iteration 10941: loss: 0.046020, loss_s1: 0.038971, loss_fp: 0.002103, loss_freq: 0.016446
[04:23:30.928] iteration 10942: loss: 0.084577, loss_s1: 0.041995, loss_fp: 0.001653, loss_freq: 0.046905
[04:23:31.562] iteration 10943: loss: 0.047220, loss_s1: 0.031735, loss_fp: 0.000839, loss_freq: 0.008483
[04:23:32.198] iteration 10944: loss: 0.041755, loss_s1: 0.024093, loss_fp: 0.001059, loss_freq: 0.017296
[04:23:32.840] iteration 10945: loss: 0.084530, loss_s1: 0.090634, loss_fp: 0.001398, loss_freq: 0.013809
[04:23:33.474] iteration 10946: loss: 0.051707, loss_s1: 0.046040, loss_fp: 0.000889, loss_freq: 0.020793
[04:23:34.119] iteration 10947: loss: 0.073680, loss_s1: 0.062110, loss_fp: 0.002112, loss_freq: 0.011202
[04:23:34.737] iteration 10948: loss: 0.098700, loss_s1: 0.112136, loss_fp: 0.002378, loss_freq: 0.046018
[04:23:35.357] iteration 10949: loss: 0.046511, loss_s1: 0.022501, loss_fp: 0.004297, loss_freq: 0.024561
[04:23:36.003] iteration 10950: loss: 0.062501, loss_s1: 0.039213, loss_fp: 0.004668, loss_freq: 0.039400
[04:23:36.657] iteration 10951: loss: 0.083016, loss_s1: 0.076076, loss_fp: 0.000905, loss_freq: 0.035795
[04:23:37.316] iteration 10952: loss: 0.056842, loss_s1: 0.020524, loss_fp: 0.005086, loss_freq: 0.042360
[04:23:37.946] iteration 10953: loss: 0.079410, loss_s1: 0.070516, loss_fp: 0.007990, loss_freq: 0.028644
[04:23:38.601] iteration 10954: loss: 0.113198, loss_s1: 0.135638, loss_fp: 0.006190, loss_freq: 0.033221
[04:23:39.226] iteration 10955: loss: 0.094568, loss_s1: 0.080750, loss_fp: 0.001027, loss_freq: 0.058525
[04:23:39.875] iteration 10956: loss: 0.062911, loss_s1: 0.026557, loss_fp: 0.003459, loss_freq: 0.023538
[04:23:40.524] iteration 10957: loss: 0.062228, loss_s1: 0.029696, loss_fp: 0.001387, loss_freq: 0.048939
[04:23:41.163] iteration 10958: loss: 0.094446, loss_s1: 0.087263, loss_fp: 0.011974, loss_freq: 0.034075
[04:23:41.814] iteration 10959: loss: 0.084380, loss_s1: 0.070736, loss_fp: 0.004527, loss_freq: 0.044602
[04:23:42.453] iteration 10960: loss: 0.113628, loss_s1: 0.081408, loss_fp: 0.006360, loss_freq: 0.075620
[04:23:43.098] iteration 10961: loss: 0.126779, loss_s1: 0.129463, loss_fp: 0.003872, loss_freq: 0.045482
[04:23:43.740] iteration 10962: loss: 0.065214, loss_s1: 0.054768, loss_fp: 0.003611, loss_freq: 0.035038
[04:23:44.418] iteration 10963: loss: 0.119576, loss_s1: 0.120093, loss_fp: 0.004988, loss_freq: 0.023993
[04:23:45.096] iteration 10964: loss: 0.064487, loss_s1: 0.036349, loss_fp: 0.001721, loss_freq: 0.039633
[04:23:45.739] iteration 10965: loss: 0.093765, loss_s1: 0.104269, loss_fp: 0.000723, loss_freq: 0.036663
[04:23:46.408] iteration 10966: loss: 0.069162, loss_s1: 0.035276, loss_fp: 0.001724, loss_freq: 0.022385
[04:23:47.040] iteration 10967: loss: 0.092409, loss_s1: 0.083407, loss_fp: 0.003301, loss_freq: 0.054263
[04:23:47.695] iteration 10968: loss: 0.070284, loss_s1: 0.051602, loss_fp: 0.002837, loss_freq: 0.031036
[04:23:48.337] iteration 10969: loss: 0.072152, loss_s1: 0.055671, loss_fp: 0.002517, loss_freq: 0.039478
[04:23:48.988] iteration 10970: loss: 0.053807, loss_s1: 0.019691, loss_fp: 0.005608, loss_freq: 0.017779
[04:23:49.627] iteration 10971: loss: 0.075556, loss_s1: 0.070612, loss_fp: 0.000986, loss_freq: 0.035896
[04:23:50.263] iteration 10972: loss: 0.078246, loss_s1: 0.079968, loss_fp: 0.001245, loss_freq: 0.033027
[04:23:50.897] iteration 10973: loss: 0.123180, loss_s1: 0.141019, loss_fp: 0.003391, loss_freq: 0.042783
[04:23:51.528] iteration 10974: loss: 0.058926, loss_s1: 0.047758, loss_fp: 0.002424, loss_freq: 0.019435
[04:23:52.220] iteration 10975: loss: 0.079585, loss_s1: 0.085525, loss_fp: 0.002394, loss_freq: 0.034060
[04:23:52.905] iteration 10976: loss: 0.078203, loss_s1: 0.066378, loss_fp: 0.000875, loss_freq: 0.045780
[04:23:53.581] iteration 10977: loss: 0.112052, loss_s1: 0.066017, loss_fp: 0.006314, loss_freq: 0.081753
[04:23:54.216] iteration 10978: loss: 0.078098, loss_s1: 0.068679, loss_fp: 0.003203, loss_freq: 0.026567
[04:23:54.866] iteration 10979: loss: 0.053168, loss_s1: 0.047874, loss_fp: 0.000993, loss_freq: 0.019532
[04:23:55.515] iteration 10980: loss: 0.085643, loss_s1: 0.086348, loss_fp: 0.000651, loss_freq: 0.044130
[04:23:56.155] iteration 10981: loss: 0.060528, loss_s1: 0.045578, loss_fp: 0.002688, loss_freq: 0.031566
[04:23:56.786] iteration 10982: loss: 0.061993, loss_s1: 0.044045, loss_fp: 0.001209, loss_freq: 0.019232
[04:23:57.416] iteration 10983: loss: 0.040360, loss_s1: 0.019364, loss_fp: 0.001334, loss_freq: 0.022251
[04:23:58.046] iteration 10984: loss: 0.076243, loss_s1: 0.047390, loss_fp: 0.001425, loss_freq: 0.029021
[04:23:58.695] iteration 10985: loss: 0.053209, loss_s1: 0.055558, loss_fp: 0.003994, loss_freq: 0.015282
[04:23:59.332] iteration 10986: loss: 0.060644, loss_s1: 0.053654, loss_fp: 0.002749, loss_freq: 0.014034
[04:23:59.966] iteration 10987: loss: 0.067627, loss_s1: 0.053994, loss_fp: 0.003578, loss_freq: 0.030065
[04:24:00.608] iteration 10988: loss: 0.048593, loss_s1: 0.036062, loss_fp: 0.002189, loss_freq: 0.016794
[04:24:01.239] iteration 10989: loss: 0.075162, loss_s1: 0.012493, loss_fp: 0.002624, loss_freq: 0.090801
[04:24:01.884] iteration 10990: loss: 0.079043, loss_s1: 0.044140, loss_fp: 0.009004, loss_freq: 0.032248
[04:24:02.510] iteration 10991: loss: 0.047493, loss_s1: 0.031494, loss_fp: 0.001649, loss_freq: 0.012444
[04:24:03.141] iteration 10992: loss: 0.058019, loss_s1: 0.033437, loss_fp: 0.003289, loss_freq: 0.038422
[04:24:03.779] iteration 10993: loss: 0.063712, loss_s1: 0.045908, loss_fp: 0.002707, loss_freq: 0.038491
[04:24:04.401] iteration 10994: loss: 0.065106, loss_s1: 0.048378, loss_fp: 0.006986, loss_freq: 0.037497
[04:24:05.067] iteration 10995: loss: 0.081578, loss_s1: 0.040830, loss_fp: 0.010511, loss_freq: 0.059868
[04:24:05.722] iteration 10996: loss: 0.091438, loss_s1: 0.064596, loss_fp: 0.011204, loss_freq: 0.050235
[04:24:06.370] iteration 10997: loss: 0.065128, loss_s1: 0.040031, loss_fp: 0.003991, loss_freq: 0.046738
[04:24:07.006] iteration 10998: loss: 0.062285, loss_s1: 0.036717, loss_fp: 0.001708, loss_freq: 0.042190
[04:24:07.656] iteration 10999: loss: 0.129053, loss_s1: 0.111294, loss_fp: 0.002436, loss_freq: 0.103815
[04:24:08.295] iteration 11000: loss: 0.056019, loss_s1: 0.030347, loss_fp: 0.008115, loss_freq: 0.025733
[04:24:12.198] iteration 11000 : mean_dice : 0.702447
[04:24:12.864] iteration 11001: loss: 0.065798, loss_s1: 0.044980, loss_fp: 0.002316, loss_freq: 0.027350
[04:24:13.490] iteration 11002: loss: 0.089936, loss_s1: 0.093202, loss_fp: 0.004361, loss_freq: 0.032776
[04:24:14.138] iteration 11003: loss: 0.104397, loss_s1: 0.092846, loss_fp: 0.002910, loss_freq: 0.061704
[04:24:14.758] iteration 11004: loss: 0.043006, loss_s1: 0.028370, loss_fp: 0.002419, loss_freq: 0.015520
[04:24:15.389] iteration 11005: loss: 0.122883, loss_s1: 0.101682, loss_fp: 0.006436, loss_freq: 0.086865
[04:24:16.022] iteration 11006: loss: 0.057114, loss_s1: 0.043074, loss_fp: 0.001108, loss_freq: 0.029548
[04:24:16.660] iteration 11007: loss: 0.106444, loss_s1: 0.090936, loss_fp: 0.005305, loss_freq: 0.071391
[04:24:17.278] iteration 11008: loss: 0.083449, loss_s1: 0.018161, loss_fp: 0.003542, loss_freq: 0.060332
[04:24:17.904] iteration 11009: loss: 0.076387, loss_s1: 0.052781, loss_fp: 0.004510, loss_freq: 0.027737
[04:24:18.572] iteration 11010: loss: 0.103790, loss_s1: 0.088356, loss_fp: 0.009342, loss_freq: 0.042353
[04:24:19.217] iteration 11011: loss: 0.140815, loss_s1: 0.186475, loss_fp: 0.035233, loss_freq: 0.013220
[04:24:19.856] iteration 11012: loss: 0.058088, loss_s1: 0.019109, loss_fp: 0.006395, loss_freq: 0.032368
[04:24:20.482] iteration 11013: loss: 0.081713, loss_s1: 0.081467, loss_fp: 0.001682, loss_freq: 0.031931
[04:24:21.106] iteration 11014: loss: 0.080274, loss_s1: 0.078658, loss_fp: 0.002480, loss_freq: 0.030582
[04:24:21.728] iteration 11015: loss: 0.106303, loss_s1: 0.069292, loss_fp: 0.003297, loss_freq: 0.093375
[04:24:22.352] iteration 11016: loss: 0.036637, loss_s1: 0.025114, loss_fp: 0.002173, loss_freq: 0.015110
[04:24:23.041] iteration 11017: loss: 0.096685, loss_s1: 0.104513, loss_fp: 0.002269, loss_freq: 0.018068
[04:24:23.770] iteration 11018: loss: 0.074016, loss_s1: 0.028807, loss_fp: 0.007713, loss_freq: 0.063426
[04:24:24.462] iteration 11019: loss: 0.118304, loss_s1: 0.125970, loss_fp: 0.013620, loss_freq: 0.060581
[04:24:25.142] iteration 11020: loss: 0.084587, loss_s1: 0.072966, loss_fp: 0.004575, loss_freq: 0.049833
[04:24:25.759] iteration 11021: loss: 0.069991, loss_s1: 0.046408, loss_fp: 0.002165, loss_freq: 0.039527
[04:24:26.376] iteration 11022: loss: 0.070454, loss_s1: 0.057526, loss_fp: 0.003087, loss_freq: 0.029055
[04:24:27.008] iteration 11023: loss: 0.066245, loss_s1: 0.067137, loss_fp: 0.003989, loss_freq: 0.019567
[04:24:27.643] iteration 11024: loss: 0.087782, loss_s1: 0.092405, loss_fp: 0.004549, loss_freq: 0.018959
[04:24:28.274] iteration 11025: loss: 0.053052, loss_s1: 0.050815, loss_fp: 0.003841, loss_freq: 0.011831
[04:24:28.941] iteration 11026: loss: 0.091038, loss_s1: 0.059687, loss_fp: 0.004045, loss_freq: 0.043868
[04:24:29.588] iteration 11027: loss: 0.071458, loss_s1: 0.039606, loss_fp: 0.006575, loss_freq: 0.030255
[04:24:30.243] iteration 11028: loss: 0.132200, loss_s1: 0.120664, loss_fp: 0.007688, loss_freq: 0.044774
[04:24:30.884] iteration 11029: loss: 0.091424, loss_s1: 0.061625, loss_fp: 0.002386, loss_freq: 0.035575
[04:24:31.562] iteration 11030: loss: 0.092440, loss_s1: 0.063974, loss_fp: 0.004019, loss_freq: 0.054152
[04:24:32.254] iteration 11031: loss: 0.091578, loss_s1: 0.092401, loss_fp: 0.010904, loss_freq: 0.028658
[04:24:32.896] iteration 11032: loss: 0.109683, loss_s1: 0.093939, loss_fp: 0.003705, loss_freq: 0.055747
[04:24:33.536] iteration 11033: loss: 0.151139, loss_s1: 0.121427, loss_fp: 0.010048, loss_freq: 0.072744
[04:24:34.163] iteration 11034: loss: 0.086083, loss_s1: 0.069878, loss_fp: 0.001764, loss_freq: 0.035886
[04:24:34.811] iteration 11035: loss: 0.106418, loss_s1: 0.083499, loss_fp: 0.004843, loss_freq: 0.054360
[04:24:35.600] iteration 11036: loss: 0.105907, loss_s1: 0.109727, loss_fp: 0.001984, loss_freq: 0.030998
[04:24:36.270] iteration 11037: loss: 0.051834, loss_s1: 0.034584, loss_fp: 0.002719, loss_freq: 0.028233
[04:24:36.923] iteration 11038: loss: 0.096586, loss_s1: 0.061716, loss_fp: 0.001885, loss_freq: 0.055155
[04:24:37.560] iteration 11039: loss: 0.073445, loss_s1: 0.044169, loss_fp: 0.012548, loss_freq: 0.043432
[04:24:38.190] iteration 11040: loss: 0.100897, loss_s1: 0.090565, loss_fp: 0.005525, loss_freq: 0.045529
[04:24:38.807] iteration 11041: loss: 0.074428, loss_s1: 0.037618, loss_fp: 0.003063, loss_freq: 0.030650
[04:24:39.420] iteration 11042: loss: 0.060182, loss_s1: 0.059570, loss_fp: 0.006261, loss_freq: 0.022774
[04:24:40.044] iteration 11043: loss: 0.045203, loss_s1: 0.023950, loss_fp: 0.000620, loss_freq: 0.019792
[04:24:40.670] iteration 11044: loss: 0.088561, loss_s1: 0.116521, loss_fp: 0.003331, loss_freq: 0.017841
[04:24:41.293] iteration 11045: loss: 0.053422, loss_s1: 0.045153, loss_fp: 0.002576, loss_freq: 0.018871
[04:24:41.926] iteration 11046: loss: 0.098843, loss_s1: 0.094745, loss_fp: 0.004439, loss_freq: 0.047173
[04:24:42.571] iteration 11047: loss: 0.068007, loss_s1: 0.034651, loss_fp: 0.000874, loss_freq: 0.044737
[04:24:43.190] iteration 11048: loss: 0.102429, loss_s1: 0.096821, loss_fp: 0.007305, loss_freq: 0.042195
[04:24:43.835] iteration 11049: loss: 0.124366, loss_s1: 0.117140, loss_fp: 0.005568, loss_freq: 0.089372
[04:24:44.456] iteration 11050: loss: 0.116124, loss_s1: 0.089212, loss_fp: 0.005014, loss_freq: 0.079608
[04:24:45.502] iteration 11051: loss: 0.057702, loss_s1: 0.039234, loss_fp: 0.002291, loss_freq: 0.013169
[04:24:46.169] iteration 11052: loss: 0.072300, loss_s1: 0.049750, loss_fp: 0.008787, loss_freq: 0.043312
[04:24:46.861] iteration 11053: loss: 0.085810, loss_s1: 0.084434, loss_fp: 0.001923, loss_freq: 0.042513
[04:24:47.530] iteration 11054: loss: 0.095472, loss_s1: 0.087310, loss_fp: 0.001975, loss_freq: 0.050875
[04:24:48.197] iteration 11055: loss: 0.103819, loss_s1: 0.121671, loss_fp: 0.000720, loss_freq: 0.037168
[04:24:48.818] iteration 11056: loss: 0.089533, loss_s1: 0.092811, loss_fp: 0.005014, loss_freq: 0.032537
[04:24:49.462] iteration 11057: loss: 0.074561, loss_s1: 0.066132, loss_fp: 0.005568, loss_freq: 0.025264
[04:24:50.087] iteration 11058: loss: 0.099868, loss_s1: 0.089443, loss_fp: 0.005105, loss_freq: 0.031610
[04:24:50.725] iteration 11059: loss: 0.079839, loss_s1: 0.071048, loss_fp: 0.001292, loss_freq: 0.023070
[04:24:51.346] iteration 11060: loss: 0.100012, loss_s1: 0.102759, loss_fp: 0.001920, loss_freq: 0.041290
[04:24:51.965] iteration 11061: loss: 0.052441, loss_s1: 0.023500, loss_fp: 0.004817, loss_freq: 0.025440
[04:24:52.588] iteration 11062: loss: 0.077049, loss_s1: 0.059189, loss_fp: 0.005743, loss_freq: 0.045534
[04:24:53.244] iteration 11063: loss: 0.090471, loss_s1: 0.071685, loss_fp: 0.003229, loss_freq: 0.056640
[04:24:53.884] iteration 11064: loss: 0.086019, loss_s1: 0.054068, loss_fp: 0.001890, loss_freq: 0.050380
[04:24:54.622] iteration 11065: loss: 0.056813, loss_s1: 0.033339, loss_fp: 0.000535, loss_freq: 0.021748
[04:24:55.324] iteration 11066: loss: 0.078146, loss_s1: 0.067154, loss_fp: 0.001740, loss_freq: 0.037714
[04:24:56.017] iteration 11067: loss: 0.115374, loss_s1: 0.081956, loss_fp: 0.004346, loss_freq: 0.106767
[04:24:56.658] iteration 11068: loss: 0.066968, loss_s1: 0.035599, loss_fp: 0.001161, loss_freq: 0.021952
[04:24:57.298] iteration 11069: loss: 0.062351, loss_s1: 0.067737, loss_fp: 0.002415, loss_freq: 0.017906
[04:24:57.942] iteration 11070: loss: 0.090962, loss_s1: 0.091884, loss_fp: 0.002413, loss_freq: 0.037020
[04:24:58.599] iteration 11071: loss: 0.045566, loss_s1: 0.012670, loss_fp: 0.002686, loss_freq: 0.032681
[04:24:59.252] iteration 11072: loss: 0.068444, loss_s1: 0.046961, loss_fp: 0.004452, loss_freq: 0.043140
[04:24:59.877] iteration 11073: loss: 0.074206, loss_s1: 0.048867, loss_fp: 0.000590, loss_freq: 0.030141
[04:25:00.522] iteration 11074: loss: 0.071737, loss_s1: 0.048795, loss_fp: 0.002253, loss_freq: 0.022129
[04:25:01.157] iteration 11075: loss: 0.090345, loss_s1: 0.079285, loss_fp: 0.002088, loss_freq: 0.029559
[04:25:01.795] iteration 11076: loss: 0.082844, loss_s1: 0.072908, loss_fp: 0.002227, loss_freq: 0.051532
[04:25:02.432] iteration 11077: loss: 0.096009, loss_s1: 0.069886, loss_fp: 0.003021, loss_freq: 0.031752
[04:25:03.064] iteration 11078: loss: 0.097323, loss_s1: 0.083976, loss_fp: 0.001826, loss_freq: 0.016868
[04:25:03.694] iteration 11079: loss: 0.111488, loss_s1: 0.063680, loss_fp: 0.005872, loss_freq: 0.072517
[04:25:04.330] iteration 11080: loss: 0.110814, loss_s1: 0.124204, loss_fp: 0.004216, loss_freq: 0.051576
[04:25:04.975] iteration 11081: loss: 0.066159, loss_s1: 0.037897, loss_fp: 0.002523, loss_freq: 0.035364
[04:25:05.609] iteration 11082: loss: 0.120237, loss_s1: 0.089357, loss_fp: 0.002392, loss_freq: 0.072797
[04:25:06.268] iteration 11083: loss: 0.109793, loss_s1: 0.090731, loss_fp: 0.010927, loss_freq: 0.068650
[04:25:06.890] iteration 11084: loss: 0.042111, loss_s1: 0.021906, loss_fp: 0.002027, loss_freq: 0.005320
[04:25:07.595] iteration 11085: loss: 0.070964, loss_s1: 0.053123, loss_fp: 0.001111, loss_freq: 0.052380
[04:25:08.296] iteration 11086: loss: 0.056303, loss_s1: 0.022121, loss_fp: 0.001634, loss_freq: 0.022789
[04:25:08.997] iteration 11087: loss: 0.082243, loss_s1: 0.075960, loss_fp: 0.000502, loss_freq: 0.042273
[04:25:09.714] iteration 11088: loss: 0.059917, loss_s1: 0.046759, loss_fp: 0.000926, loss_freq: 0.027726
[04:25:10.512] iteration 11089: loss: 0.077555, loss_s1: 0.067201, loss_fp: 0.002374, loss_freq: 0.029571
[04:25:11.169] iteration 11090: loss: 0.074146, loss_s1: 0.067183, loss_fp: 0.005136, loss_freq: 0.029781
[04:25:11.874] iteration 11091: loss: 0.117801, loss_s1: 0.134503, loss_fp: 0.002415, loss_freq: 0.040799
[04:25:12.621] iteration 11092: loss: 0.072880, loss_s1: 0.055017, loss_fp: 0.002295, loss_freq: 0.033564
[04:25:13.339] iteration 11093: loss: 0.113693, loss_s1: 0.050114, loss_fp: 0.003776, loss_freq: 0.111550
[04:25:14.069] iteration 11094: loss: 0.137503, loss_s1: 0.129046, loss_fp: 0.010862, loss_freq: 0.089442
[04:25:14.749] iteration 11095: loss: 0.060846, loss_s1: 0.025055, loss_fp: 0.001069, loss_freq: 0.022416
[04:25:15.457] iteration 11096: loss: 0.090069, loss_s1: 0.101361, loss_fp: 0.003426, loss_freq: 0.037609
[04:25:16.098] iteration 11097: loss: 0.062732, loss_s1: 0.044251, loss_fp: 0.003732, loss_freq: 0.029090
[04:25:16.830] iteration 11098: loss: 0.070861, loss_s1: 0.055120, loss_fp: 0.002335, loss_freq: 0.042813
[04:25:17.614] iteration 11099: loss: 0.040414, loss_s1: 0.017315, loss_fp: 0.002540, loss_freq: 0.006290
[04:25:18.287] iteration 11100: loss: 0.039742, loss_s1: 0.010273, loss_fp: 0.001342, loss_freq: 0.010027
[04:25:19.043] iteration 11101: loss: 0.093436, loss_s1: 0.099536, loss_fp: 0.002173, loss_freq: 0.034194
[04:25:19.722] iteration 11102: loss: 0.079119, loss_s1: 0.084448, loss_fp: 0.002867, loss_freq: 0.044029
[04:25:20.351] iteration 11103: loss: 0.064589, loss_s1: 0.026114, loss_fp: 0.002919, loss_freq: 0.035060
[04:25:20.980] iteration 11104: loss: 0.077239, loss_s1: 0.056188, loss_fp: 0.007555, loss_freq: 0.048166
[04:25:21.644] iteration 11105: loss: 0.076756, loss_s1: 0.039854, loss_fp: 0.002501, loss_freq: 0.049534
[04:25:22.294] iteration 11106: loss: 0.057545, loss_s1: 0.025974, loss_fp: 0.001304, loss_freq: 0.009726
[04:25:22.929] iteration 11107: loss: 0.067879, loss_s1: 0.044253, loss_fp: 0.003804, loss_freq: 0.051410
[04:25:23.573] iteration 11108: loss: 0.070675, loss_s1: 0.050460, loss_fp: 0.004859, loss_freq: 0.032860
[04:25:24.224] iteration 11109: loss: 0.081689, loss_s1: 0.046681, loss_fp: 0.002710, loss_freq: 0.032662
[04:25:24.862] iteration 11110: loss: 0.076824, loss_s1: 0.052321, loss_fp: 0.004400, loss_freq: 0.053801
[04:25:25.501] iteration 11111: loss: 0.048298, loss_s1: 0.037894, loss_fp: 0.005281, loss_freq: 0.009784
[04:25:26.159] iteration 11112: loss: 0.060382, loss_s1: 0.029021, loss_fp: 0.004504, loss_freq: 0.043321
[04:25:26.802] iteration 11113: loss: 0.057395, loss_s1: 0.039173, loss_fp: 0.004701, loss_freq: 0.020882
[04:25:27.457] iteration 11114: loss: 0.052720, loss_s1: 0.050159, loss_fp: 0.004425, loss_freq: 0.014108
[04:25:28.090] iteration 11115: loss: 0.134063, loss_s1: 0.185595, loss_fp: 0.002595, loss_freq: 0.030128
[04:25:28.726] iteration 11116: loss: 0.053892, loss_s1: 0.040671, loss_fp: 0.003690, loss_freq: 0.024593
[04:25:29.358] iteration 11117: loss: 0.055374, loss_s1: 0.037537, loss_fp: 0.002508, loss_freq: 0.025544
[04:25:29.988] iteration 11118: loss: 0.104102, loss_s1: 0.110635, loss_fp: 0.005847, loss_freq: 0.053037
[04:25:30.617] iteration 11119: loss: 0.070803, loss_s1: 0.021587, loss_fp: 0.001394, loss_freq: 0.041831
[04:25:31.251] iteration 11120: loss: 0.069672, loss_s1: 0.042478, loss_fp: 0.007702, loss_freq: 0.058243
[04:25:31.890] iteration 11121: loss: 0.060017, loss_s1: 0.040848, loss_fp: 0.004898, loss_freq: 0.035586
[04:25:32.533] iteration 11122: loss: 0.071504, loss_s1: 0.053682, loss_fp: 0.008424, loss_freq: 0.025578
[04:25:33.407] iteration 11123: loss: 0.072514, loss_s1: 0.043224, loss_fp: 0.011866, loss_freq: 0.052500
[04:25:34.259] iteration 11124: loss: 0.104685, loss_s1: 0.119388, loss_fp: 0.005413, loss_freq: 0.036332
[04:25:35.120] iteration 11125: loss: 0.069515, loss_s1: 0.037548, loss_fp: 0.002738, loss_freq: 0.049472
[04:25:35.742] iteration 11126: loss: 0.053736, loss_s1: 0.026054, loss_fp: 0.003811, loss_freq: 0.018861
[04:25:36.408] iteration 11127: loss: 0.066053, loss_s1: 0.053818, loss_fp: 0.001537, loss_freq: 0.030562
[04:25:37.054] iteration 11128: loss: 0.116724, loss_s1: 0.117920, loss_fp: 0.005818, loss_freq: 0.032285
[04:25:37.690] iteration 11129: loss: 0.076931, loss_s1: 0.054833, loss_fp: 0.001832, loss_freq: 0.070668
[04:25:38.324] iteration 11130: loss: 0.061025, loss_s1: 0.041995, loss_fp: 0.002705, loss_freq: 0.033287
[04:25:38.992] iteration 11131: loss: 0.101681, loss_s1: 0.073133, loss_fp: 0.007169, loss_freq: 0.061642
[04:25:39.643] iteration 11132: loss: 0.077962, loss_s1: 0.065988, loss_fp: 0.011248, loss_freq: 0.036392
[04:25:40.279] iteration 11133: loss: 0.071067, loss_s1: 0.069539, loss_fp: 0.005357, loss_freq: 0.024019
[04:25:40.916] iteration 11134: loss: 0.074178, loss_s1: 0.089533, loss_fp: 0.004416, loss_freq: 0.009956
[04:25:41.551] iteration 11135: loss: 0.076461, loss_s1: 0.051938, loss_fp: 0.002539, loss_freq: 0.034502
[04:25:42.185] iteration 11136: loss: 0.066334, loss_s1: 0.066755, loss_fp: 0.004076, loss_freq: 0.021521
[04:25:42.837] iteration 11137: loss: 0.091961, loss_s1: 0.099337, loss_fp: 0.001941, loss_freq: 0.045954
[04:25:43.464] iteration 11138: loss: 0.107005, loss_s1: 0.086003, loss_fp: 0.003855, loss_freq: 0.052150
[04:25:44.101] iteration 11139: loss: 0.070252, loss_s1: 0.041866, loss_fp: 0.008654, loss_freq: 0.053381
[04:25:44.740] iteration 11140: loss: 0.066517, loss_s1: 0.034829, loss_fp: 0.002294, loss_freq: 0.036957
[04:25:45.382] iteration 11141: loss: 0.071382, loss_s1: 0.060064, loss_fp: 0.002682, loss_freq: 0.031048
[04:25:46.010] iteration 11142: loss: 0.092108, loss_s1: 0.047984, loss_fp: 0.003376, loss_freq: 0.054588
[04:25:46.681] iteration 11143: loss: 0.059775, loss_s1: 0.039174, loss_fp: 0.004341, loss_freq: 0.010758
[04:25:47.372] iteration 11144: loss: 0.047094, loss_s1: 0.030440, loss_fp: 0.002532, loss_freq: 0.006831
[04:25:48.000] iteration 11145: loss: 0.100783, loss_s1: 0.077194, loss_fp: 0.006413, loss_freq: 0.050678
[04:25:48.652] iteration 11146: loss: 0.076741, loss_s1: 0.031947, loss_fp: 0.001637, loss_freq: 0.075677
[04:25:49.282] iteration 11147: loss: 0.076426, loss_s1: 0.042701, loss_fp: 0.005298, loss_freq: 0.052288
[04:25:49.908] iteration 11148: loss: 0.083936, loss_s1: 0.052119, loss_fp: 0.001430, loss_freq: 0.066809
[04:25:50.558] iteration 11149: loss: 0.096493, loss_s1: 0.097555, loss_fp: 0.002089, loss_freq: 0.058168
[04:25:51.235] iteration 11150: loss: 0.067074, loss_s1: 0.035733, loss_fp: 0.004773, loss_freq: 0.043242
[04:25:51.907] iteration 11151: loss: 0.130437, loss_s1: 0.126166, loss_fp: 0.005910, loss_freq: 0.080812
[04:25:52.594] iteration 11152: loss: 0.079899, loss_s1: 0.050060, loss_fp: 0.004152, loss_freq: 0.019071
[04:25:53.269] iteration 11153: loss: 0.053701, loss_s1: 0.032480, loss_fp: 0.001926, loss_freq: 0.024175
[04:25:53.917] iteration 11154: loss: 0.055710, loss_s1: 0.015808, loss_fp: 0.003075, loss_freq: 0.029117
[04:25:54.553] iteration 11155: loss: 0.076731, loss_s1: 0.031311, loss_fp: 0.002318, loss_freq: 0.046259
[04:25:55.213] iteration 11156: loss: 0.104844, loss_s1: 0.095256, loss_fp: 0.011740, loss_freq: 0.041144
[04:25:55.846] iteration 11157: loss: 0.073932, loss_s1: 0.044329, loss_fp: 0.009934, loss_freq: 0.035235
[04:25:56.521] iteration 11158: loss: 0.057707, loss_s1: 0.028574, loss_fp: 0.004787, loss_freq: 0.020456
[04:25:57.158] iteration 11159: loss: 0.108127, loss_s1: 0.049841, loss_fp: 0.013631, loss_freq: 0.092248
[04:25:57.782] iteration 11160: loss: 0.069621, loss_s1: 0.038394, loss_fp: 0.010505, loss_freq: 0.039663
[04:25:58.519] iteration 11161: loss: 0.094588, loss_s1: 0.094319, loss_fp: 0.008347, loss_freq: 0.045782
[04:25:59.188] iteration 11162: loss: 0.096580, loss_s1: 0.088454, loss_fp: 0.003566, loss_freq: 0.033612
[04:25:59.866] iteration 11163: loss: 0.047834, loss_s1: 0.032581, loss_fp: 0.001223, loss_freq: 0.029449
[04:26:00.567] iteration 11164: loss: 0.060312, loss_s1: 0.040127, loss_fp: 0.003501, loss_freq: 0.032834
[04:26:01.247] iteration 11165: loss: 0.118975, loss_s1: 0.072898, loss_fp: 0.006492, loss_freq: 0.100452
[04:26:01.923] iteration 11166: loss: 0.097832, loss_s1: 0.059847, loss_fp: 0.002765, loss_freq: 0.070663
[04:26:02.550] iteration 11167: loss: 0.096822, loss_s1: 0.052577, loss_fp: 0.002415, loss_freq: 0.072721
[04:26:03.188] iteration 11168: loss: 0.079651, loss_s1: 0.096023, loss_fp: 0.004041, loss_freq: 0.019901
[04:26:03.817] iteration 11169: loss: 0.117998, loss_s1: 0.090837, loss_fp: 0.000748, loss_freq: 0.106977
[04:26:04.456] iteration 11170: loss: 0.075175, loss_s1: 0.058349, loss_fp: 0.002591, loss_freq: 0.032777
[04:26:05.100] iteration 11171: loss: 0.066355, loss_s1: 0.055338, loss_fp: 0.001637, loss_freq: 0.019879
[04:26:05.736] iteration 11172: loss: 0.083137, loss_s1: 0.082228, loss_fp: 0.003982, loss_freq: 0.030012
[04:26:06.361] iteration 11173: loss: 0.105024, loss_s1: 0.118493, loss_fp: 0.021508, loss_freq: 0.022615
[04:26:06.988] iteration 11174: loss: 0.060882, loss_s1: 0.035329, loss_fp: 0.011718, loss_freq: 0.033708
[04:26:07.628] iteration 11175: loss: 0.133987, loss_s1: 0.143546, loss_fp: 0.003009, loss_freq: 0.052532
[04:26:08.273] iteration 11176: loss: 0.066119, loss_s1: 0.038842, loss_fp: 0.002061, loss_freq: 0.042471
[04:26:08.937] iteration 11177: loss: 0.088697, loss_s1: 0.059965, loss_fp: 0.003604, loss_freq: 0.055833
[04:26:09.605] iteration 11178: loss: 0.055060, loss_s1: 0.035941, loss_fp: 0.003305, loss_freq: 0.011710
[04:26:10.278] iteration 11179: loss: 0.061849, loss_s1: 0.029824, loss_fp: 0.001404, loss_freq: 0.020881
[04:26:10.958] iteration 11180: loss: 0.086961, loss_s1: 0.106209, loss_fp: 0.003084, loss_freq: 0.024080
[04:26:11.615] iteration 11181: loss: 0.110064, loss_s1: 0.096079, loss_fp: 0.006497, loss_freq: 0.060858
[04:26:12.272] iteration 11182: loss: 0.083913, loss_s1: 0.040131, loss_fp: 0.001186, loss_freq: 0.013621
[04:26:12.893] iteration 11183: loss: 0.098746, loss_s1: 0.101007, loss_fp: 0.001833, loss_freq: 0.033810
[04:26:13.515] iteration 11184: loss: 0.070304, loss_s1: 0.064602, loss_fp: 0.004701, loss_freq: 0.025217
[04:26:14.159] iteration 11185: loss: 0.113278, loss_s1: 0.076017, loss_fp: 0.002436, loss_freq: 0.100584
[04:26:14.923] iteration 11186: loss: 0.054884, loss_s1: 0.038203, loss_fp: 0.001946, loss_freq: 0.028300
[04:26:15.704] iteration 11187: loss: 0.053498, loss_s1: 0.029466, loss_fp: 0.002255, loss_freq: 0.013316
[04:26:16.496] iteration 11188: loss: 0.094661, loss_s1: 0.069828, loss_fp: 0.005701, loss_freq: 0.067981
[04:26:17.133] iteration 11189: loss: 0.116206, loss_s1: 0.135290, loss_fp: 0.005239, loss_freq: 0.045963
[04:26:17.839] iteration 11190: loss: 0.061896, loss_s1: 0.067974, loss_fp: 0.001041, loss_freq: 0.020978
[04:26:18.535] iteration 11191: loss: 0.080867, loss_s1: 0.066032, loss_fp: 0.002738, loss_freq: 0.033511
[04:26:19.167] iteration 11192: loss: 0.099338, loss_s1: 0.091814, loss_fp: 0.004392, loss_freq: 0.051002
[04:26:19.791] iteration 11193: loss: 0.086428, loss_s1: 0.062633, loss_fp: 0.004509, loss_freq: 0.041424
[04:26:20.431] iteration 11194: loss: 0.074114, loss_s1: 0.065448, loss_fp: 0.007536, loss_freq: 0.017912
[04:26:21.071] iteration 11195: loss: 0.043224, loss_s1: 0.031997, loss_fp: 0.001889, loss_freq: 0.012536
[04:26:21.699] iteration 11196: loss: 0.057667, loss_s1: 0.038875, loss_fp: 0.002620, loss_freq: 0.023910
[04:26:22.333] iteration 11197: loss: 0.088173, loss_s1: 0.080391, loss_fp: 0.006077, loss_freq: 0.037938
[04:26:23.038] iteration 11198: loss: 0.121604, loss_s1: 0.161578, loss_fp: 0.001958, loss_freq: 0.041155
[04:26:23.709] iteration 11199: loss: 0.083370, loss_s1: 0.089985, loss_fp: 0.004319, loss_freq: 0.034177
[04:26:24.368] iteration 11200: loss: 0.088981, loss_s1: 0.065299, loss_fp: 0.010181, loss_freq: 0.028956
[04:26:27.622] iteration 11200 : mean_dice : 0.708830
[04:26:28.358] iteration 11201: loss: 0.084100, loss_s1: 0.050355, loss_fp: 0.008131, loss_freq: 0.058205
[04:26:29.033] iteration 11202: loss: 0.106763, loss_s1: 0.069850, loss_fp: 0.006066, loss_freq: 0.094949
[04:26:29.724] iteration 11203: loss: 0.130978, loss_s1: 0.059384, loss_fp: 0.013861, loss_freq: 0.093650
[04:26:30.427] iteration 11204: loss: 0.097094, loss_s1: 0.084244, loss_fp: 0.005611, loss_freq: 0.058975
[04:26:31.079] iteration 11205: loss: 0.138531, loss_s1: 0.080904, loss_fp: 0.002121, loss_freq: 0.084596
[04:26:31.763] iteration 11206: loss: 0.041732, loss_s1: 0.011902, loss_fp: 0.001925, loss_freq: 0.020157
[04:26:32.389] iteration 11207: loss: 0.054622, loss_s1: 0.035032, loss_fp: 0.004727, loss_freq: 0.030048
[04:26:33.039] iteration 11208: loss: 0.136082, loss_s1: 0.114500, loss_fp: 0.007766, loss_freq: 0.097081
[04:26:33.666] iteration 11209: loss: 0.093149, loss_s1: 0.079747, loss_fp: 0.003457, loss_freq: 0.060281
[04:26:34.299] iteration 11210: loss: 0.096848, loss_s1: 0.078713, loss_fp: 0.003161, loss_freq: 0.045118
[04:26:34.929] iteration 11211: loss: 0.058211, loss_s1: 0.040937, loss_fp: 0.003342, loss_freq: 0.019381
[04:26:35.591] iteration 11212: loss: 0.065198, loss_s1: 0.065375, loss_fp: 0.006870, loss_freq: 0.015425
[04:26:36.286] iteration 11213: loss: 0.063882, loss_s1: 0.036385, loss_fp: 0.000778, loss_freq: 0.012975
[04:26:36.956] iteration 11214: loss: 0.089689, loss_s1: 0.092637, loss_fp: 0.001303, loss_freq: 0.039076
[04:26:37.640] iteration 11215: loss: 0.040962, loss_s1: 0.024314, loss_fp: 0.003181, loss_freq: 0.008975
[04:26:38.280] iteration 11216: loss: 0.084754, loss_s1: 0.088142, loss_fp: 0.004671, loss_freq: 0.037460
[04:26:38.908] iteration 11217: loss: 0.067350, loss_s1: 0.058851, loss_fp: 0.001220, loss_freq: 0.027483
[04:26:39.601] iteration 11218: loss: 0.080774, loss_s1: 0.043544, loss_fp: 0.004566, loss_freq: 0.062150
[04:26:40.294] iteration 11219: loss: 0.065407, loss_s1: 0.030131, loss_fp: 0.009135, loss_freq: 0.037936
[04:26:40.991] iteration 11220: loss: 0.100652, loss_s1: 0.059294, loss_fp: 0.006413, loss_freq: 0.060516
[04:26:41.991] iteration 11221: loss: 0.060786, loss_s1: 0.052085, loss_fp: 0.003353, loss_freq: 0.016925
[04:26:42.686] iteration 11222: loss: 0.060694, loss_s1: 0.025034, loss_fp: 0.000742, loss_freq: 0.039158
[04:26:43.359] iteration 11223: loss: 0.047920, loss_s1: 0.025174, loss_fp: 0.002749, loss_freq: 0.023792
[04:26:43.993] iteration 11224: loss: 0.076530, loss_s1: 0.049840, loss_fp: 0.004941, loss_freq: 0.039065
[04:26:44.616] iteration 11225: loss: 0.125578, loss_s1: 0.158430, loss_fp: 0.004309, loss_freq: 0.047888
[04:26:45.249] iteration 11226: loss: 0.095982, loss_s1: 0.088275, loss_fp: 0.010831, loss_freq: 0.020530
[04:26:45.874] iteration 11227: loss: 0.107147, loss_s1: 0.093725, loss_fp: 0.008045, loss_freq: 0.038166
[04:26:46.496] iteration 11228: loss: 0.073365, loss_s1: 0.058068, loss_fp: 0.001353, loss_freq: 0.026786
[04:26:47.135] iteration 11229: loss: 0.073114, loss_s1: 0.060499, loss_fp: 0.003446, loss_freq: 0.029666
[04:26:47.757] iteration 11230: loss: 0.084329, loss_s1: 0.082495, loss_fp: 0.006962, loss_freq: 0.024970
[04:26:48.426] iteration 11231: loss: 0.098200, loss_s1: 0.074334, loss_fp: 0.003179, loss_freq: 0.060454
[04:26:49.045] iteration 11232: loss: 0.106677, loss_s1: 0.105587, loss_fp: 0.004117, loss_freq: 0.059204
[04:26:49.698] iteration 11233: loss: 0.075333, loss_s1: 0.025509, loss_fp: 0.002428, loss_freq: 0.074042
[04:26:50.323] iteration 11234: loss: 0.065298, loss_s1: 0.057559, loss_fp: 0.002826, loss_freq: 0.024862
[04:26:50.985] iteration 11235: loss: 0.082039, loss_s1: 0.088276, loss_fp: 0.000821, loss_freq: 0.023596
[04:26:51.621] iteration 11236: loss: 0.067508, loss_s1: 0.048507, loss_fp: 0.002862, loss_freq: 0.028588
[04:26:52.245] iteration 11237: loss: 0.123602, loss_s1: 0.121753, loss_fp: 0.005635, loss_freq: 0.077622
[04:26:52.889] iteration 11238: loss: 0.054105, loss_s1: 0.042305, loss_fp: 0.006226, loss_freq: 0.012806
[04:26:53.556] iteration 11239: loss: 0.089710, loss_s1: 0.092210, loss_fp: 0.004470, loss_freq: 0.045967
[04:26:54.213] iteration 11240: loss: 0.084026, loss_s1: 0.061268, loss_fp: 0.000949, loss_freq: 0.022881
[04:26:54.838] iteration 11241: loss: 0.059292, loss_s1: 0.045883, loss_fp: 0.008920, loss_freq: 0.021774
[04:26:55.475] iteration 11242: loss: 0.092777, loss_s1: 0.047662, loss_fp: 0.004215, loss_freq: 0.051410
[04:26:56.110] iteration 11243: loss: 0.089537, loss_s1: 0.063900, loss_fp: 0.002326, loss_freq: 0.038842
[04:26:56.751] iteration 11244: loss: 0.067019, loss_s1: 0.044389, loss_fp: 0.001580, loss_freq: 0.027822
[04:26:57.380] iteration 11245: loss: 0.089586, loss_s1: 0.029780, loss_fp: 0.001317, loss_freq: 0.101244
[04:26:57.995] iteration 11246: loss: 0.112878, loss_s1: 0.142841, loss_fp: 0.002923, loss_freq: 0.043887
[04:26:58.636] iteration 11247: loss: 0.075744, loss_s1: 0.033822, loss_fp: 0.012027, loss_freq: 0.021096
[04:26:59.267] iteration 11248: loss: 0.080257, loss_s1: 0.060570, loss_fp: 0.004314, loss_freq: 0.023123
[04:26:59.904] iteration 11249: loss: 0.063155, loss_s1: 0.044372, loss_fp: 0.014188, loss_freq: 0.029449
[04:27:00.526] iteration 11250: loss: 0.080482, loss_s1: 0.081792, loss_fp: 0.002317, loss_freq: 0.032200
[04:27:01.153] iteration 11251: loss: 0.110785, loss_s1: 0.135241, loss_fp: 0.003822, loss_freq: 0.046858
[04:27:01.782] iteration 11252: loss: 0.105636, loss_s1: 0.091663, loss_fp: 0.002702, loss_freq: 0.057981
[04:27:02.426] iteration 11253: loss: 0.071390, loss_s1: 0.075153, loss_fp: 0.001002, loss_freq: 0.021990
[04:27:03.044] iteration 11254: loss: 0.060421, loss_s1: 0.047478, loss_fp: 0.004780, loss_freq: 0.030174
[04:27:03.714] iteration 11255: loss: 0.051729, loss_s1: 0.039987, loss_fp: 0.001121, loss_freq: 0.031937
[04:27:04.341] iteration 11256: loss: 0.057680, loss_s1: 0.022003, loss_fp: 0.002448, loss_freq: 0.010760
[04:27:04.970] iteration 11257: loss: 0.095513, loss_s1: 0.106358, loss_fp: 0.000640, loss_freq: 0.031238
[04:27:05.593] iteration 11258: loss: 0.061955, loss_s1: 0.067406, loss_fp: 0.000740, loss_freq: 0.021531
[04:27:06.233] iteration 11259: loss: 0.102322, loss_s1: 0.106023, loss_fp: 0.005519, loss_freq: 0.046750
[04:27:06.861] iteration 11260: loss: 0.096865, loss_s1: 0.089526, loss_fp: 0.006052, loss_freq: 0.038363
[04:27:07.503] iteration 11261: loss: 0.105223, loss_s1: 0.101991, loss_fp: 0.003151, loss_freq: 0.040367
[04:27:08.144] iteration 11262: loss: 0.063393, loss_s1: 0.029056, loss_fp: 0.003633, loss_freq: 0.038034
[04:27:08.764] iteration 11263: loss: 0.083516, loss_s1: 0.061770, loss_fp: 0.006629, loss_freq: 0.059586
[04:27:09.399] iteration 11264: loss: 0.134401, loss_s1: 0.163524, loss_fp: 0.004486, loss_freq: 0.064634
[04:27:10.031] iteration 11265: loss: 0.078471, loss_s1: 0.047940, loss_fp: 0.001465, loss_freq: 0.038952
[04:27:10.670] iteration 11266: loss: 0.064270, loss_s1: 0.036063, loss_fp: 0.001858, loss_freq: 0.037259
[04:27:11.311] iteration 11267: loss: 0.046120, loss_s1: 0.012647, loss_fp: 0.001010, loss_freq: 0.018973
[04:27:11.965] iteration 11268: loss: 0.058650, loss_s1: 0.039091, loss_fp: 0.001470, loss_freq: 0.018054
[04:27:12.600] iteration 11269: loss: 0.039753, loss_s1: 0.024904, loss_fp: 0.001679, loss_freq: 0.007790
[04:27:13.250] iteration 11270: loss: 0.050780, loss_s1: 0.026096, loss_fp: 0.005674, loss_freq: 0.015555
[04:27:13.922] iteration 11271: loss: 0.056094, loss_s1: 0.026319, loss_fp: 0.002317, loss_freq: 0.020358
[04:27:14.552] iteration 11272: loss: 0.092520, loss_s1: 0.090493, loss_fp: 0.004602, loss_freq: 0.050355
[04:27:15.179] iteration 11273: loss: 0.064422, loss_s1: 0.021868, loss_fp: 0.001016, loss_freq: 0.050722
[04:27:15.811] iteration 11274: loss: 0.091568, loss_s1: 0.054947, loss_fp: 0.006541, loss_freq: 0.080566
[04:27:16.439] iteration 11275: loss: 0.073609, loss_s1: 0.042469, loss_fp: 0.001760, loss_freq: 0.054628
[04:27:17.061] iteration 11276: loss: 0.061211, loss_s1: 0.051363, loss_fp: 0.003146, loss_freq: 0.020138
[04:27:17.719] iteration 11277: loss: 0.083434, loss_s1: 0.077290, loss_fp: 0.007435, loss_freq: 0.047670
[04:27:18.373] iteration 11278: loss: 0.060073, loss_s1: 0.034368, loss_fp: 0.005737, loss_freq: 0.024048
[04:27:19.006] iteration 11279: loss: 0.095277, loss_s1: 0.061370, loss_fp: 0.005114, loss_freq: 0.039980
[04:27:19.668] iteration 11280: loss: 0.080025, loss_s1: 0.054005, loss_fp: 0.002551, loss_freq: 0.065914
[04:27:20.297] iteration 11281: loss: 0.052863, loss_s1: 0.037836, loss_fp: 0.003317, loss_freq: 0.008567
[04:27:21.012] iteration 11282: loss: 0.111503, loss_s1: 0.050639, loss_fp: 0.005170, loss_freq: 0.060930
[04:27:21.699] iteration 11283: loss: 0.063821, loss_s1: 0.058410, loss_fp: 0.002523, loss_freq: 0.009467
[04:27:22.380] iteration 11284: loss: 0.060640, loss_s1: 0.034555, loss_fp: 0.005140, loss_freq: 0.044152
[04:27:23.055] iteration 11285: loss: 0.099581, loss_s1: 0.109503, loss_fp: 0.003010, loss_freq: 0.022604
[04:27:23.757] iteration 11286: loss: 0.095525, loss_s1: 0.062564, loss_fp: 0.004161, loss_freq: 0.060054
[04:27:24.441] iteration 11287: loss: 0.057431, loss_s1: 0.036147, loss_fp: 0.001143, loss_freq: 0.017247
[04:27:25.075] iteration 11288: loss: 0.138304, loss_s1: 0.125941, loss_fp: 0.010102, loss_freq: 0.073727
[04:27:25.719] iteration 11289: loss: 0.062390, loss_s1: 0.029470, loss_fp: 0.015440, loss_freq: 0.020271
[04:27:26.357] iteration 11290: loss: 0.075262, loss_s1: 0.065688, loss_fp: 0.002655, loss_freq: 0.048276
[04:27:26.980] iteration 11291: loss: 0.071372, loss_s1: 0.047898, loss_fp: 0.004427, loss_freq: 0.029969
[04:27:27.601] iteration 11292: loss: 0.071718, loss_s1: 0.061587, loss_fp: 0.002677, loss_freq: 0.024952
[04:27:28.226] iteration 11293: loss: 0.081451, loss_s1: 0.064933, loss_fp: 0.029988, loss_freq: 0.031926
[04:27:28.854] iteration 11294: loss: 0.086748, loss_s1: 0.091011, loss_fp: 0.006356, loss_freq: 0.026626
[04:27:29.487] iteration 11295: loss: 0.079792, loss_s1: 0.067539, loss_fp: 0.006638, loss_freq: 0.028710
[04:27:30.120] iteration 11296: loss: 0.075604, loss_s1: 0.045341, loss_fp: 0.006629, loss_freq: 0.045199
[04:27:30.748] iteration 11297: loss: 0.086148, loss_s1: 0.096160, loss_fp: 0.002399, loss_freq: 0.024039
[04:27:31.387] iteration 11298: loss: 0.069511, loss_s1: 0.056271, loss_fp: 0.004042, loss_freq: 0.036033
[04:27:32.042] iteration 11299: loss: 0.064050, loss_s1: 0.025918, loss_fp: 0.004018, loss_freq: 0.063197
[04:27:32.671] iteration 11300: loss: 0.080114, loss_s1: 0.059799, loss_fp: 0.002719, loss_freq: 0.027086
[04:27:33.380] iteration 11301: loss: 0.115464, loss_s1: 0.098670, loss_fp: 0.008235, loss_freq: 0.068097
[04:27:34.056] iteration 11302: loss: 0.077253, loss_s1: 0.050960, loss_fp: 0.004483, loss_freq: 0.025473
[04:27:34.738] iteration 11303: loss: 0.133685, loss_s1: 0.131894, loss_fp: 0.002355, loss_freq: 0.033860
[04:27:35.419] iteration 11304: loss: 0.095451, loss_s1: 0.034437, loss_fp: 0.025235, loss_freq: 0.055923
[04:27:36.098] iteration 11305: loss: 0.081061, loss_s1: 0.051652, loss_fp: 0.005860, loss_freq: 0.049273
[04:27:36.753] iteration 11306: loss: 0.044152, loss_s1: 0.027751, loss_fp: 0.005593, loss_freq: 0.013138
[04:27:37.426] iteration 11307: loss: 0.080967, loss_s1: 0.095996, loss_fp: 0.005061, loss_freq: 0.025504
[04:27:38.057] iteration 11308: loss: 0.108550, loss_s1: 0.108690, loss_fp: 0.002985, loss_freq: 0.043567
[04:27:38.684] iteration 11309: loss: 0.101566, loss_s1: 0.089076, loss_fp: 0.003022, loss_freq: 0.071955
[04:27:39.310] iteration 11310: loss: 0.080080, loss_s1: 0.048195, loss_fp: 0.005405, loss_freq: 0.027127
[04:27:39.939] iteration 11311: loss: 0.069055, loss_s1: 0.061125, loss_fp: 0.001875, loss_freq: 0.020435
[04:27:40.564] iteration 11312: loss: 0.086160, loss_s1: 0.074723, loss_fp: 0.001052, loss_freq: 0.039969
[04:27:41.214] iteration 11313: loss: 0.145361, loss_s1: 0.188882, loss_fp: 0.001065, loss_freq: 0.037028
[04:27:41.847] iteration 11314: loss: 0.067648, loss_s1: 0.042062, loss_fp: 0.002263, loss_freq: 0.043261
[04:27:42.489] iteration 11315: loss: 0.080201, loss_s1: 0.050989, loss_fp: 0.003966, loss_freq: 0.018840
[04:27:43.111] iteration 11316: loss: 0.101811, loss_s1: 0.111419, loss_fp: 0.006767, loss_freq: 0.043742
[04:27:43.763] iteration 11317: loss: 0.087644, loss_s1: 0.042711, loss_fp: 0.003471, loss_freq: 0.067428
[04:27:44.402] iteration 11318: loss: 0.136731, loss_s1: 0.165105, loss_fp: 0.001457, loss_freq: 0.044157
[04:27:45.029] iteration 11319: loss: 0.093145, loss_s1: 0.075988, loss_fp: 0.004857, loss_freq: 0.069033
[04:27:45.658] iteration 11320: loss: 0.090788, loss_s1: 0.070374, loss_fp: 0.002963, loss_freq: 0.051766
[04:27:46.282] iteration 11321: loss: 0.093072, loss_s1: 0.098404, loss_fp: 0.003534, loss_freq: 0.049271
[04:27:46.952] iteration 11322: loss: 0.075200, loss_s1: 0.067976, loss_fp: 0.001768, loss_freq: 0.034924
[04:27:47.595] iteration 11323: loss: 0.069690, loss_s1: 0.045889, loss_fp: 0.002399, loss_freq: 0.031662
[04:27:48.225] iteration 11324: loss: 0.061935, loss_s1: 0.030587, loss_fp: 0.001220, loss_freq: 0.028380
[04:27:48.884] iteration 11325: loss: 0.052501, loss_s1: 0.017941, loss_fp: 0.002395, loss_freq: 0.020922
[04:27:49.564] iteration 11326: loss: 0.070519, loss_s1: 0.039803, loss_fp: 0.014066, loss_freq: 0.036903
[04:27:50.225] iteration 11327: loss: 0.090285, loss_s1: 0.082397, loss_fp: 0.004680, loss_freq: 0.030013
[04:27:50.868] iteration 11328: loss: 0.058070, loss_s1: 0.027549, loss_fp: 0.004254, loss_freq: 0.042469
[04:27:51.513] iteration 11329: loss: 0.077856, loss_s1: 0.037999, loss_fp: 0.002376, loss_freq: 0.066583
[04:27:52.168] iteration 11330: loss: 0.064949, loss_s1: 0.034191, loss_fp: 0.003479, loss_freq: 0.034517
[04:27:52.818] iteration 11331: loss: 0.062457, loss_s1: 0.036703, loss_fp: 0.001728, loss_freq: 0.039527
[04:27:53.495] iteration 11332: loss: 0.078319, loss_s1: 0.047580, loss_fp: 0.003886, loss_freq: 0.045172
[04:27:54.168] iteration 11333: loss: 0.069972, loss_s1: 0.054264, loss_fp: 0.002717, loss_freq: 0.023496
[04:27:54.841] iteration 11334: loss: 0.041321, loss_s1: 0.023183, loss_fp: 0.002028, loss_freq: 0.021616
[04:27:55.570] iteration 11335: loss: 0.113236, loss_s1: 0.080094, loss_fp: 0.004581, loss_freq: 0.075133
[04:27:56.265] iteration 11336: loss: 0.110800, loss_s1: 0.030920, loss_fp: 0.008943, loss_freq: 0.089095
[04:27:56.936] iteration 11337: loss: 0.090929, loss_s1: 0.120105, loss_fp: 0.003519, loss_freq: 0.020895
[04:27:57.596] iteration 11338: loss: 0.072987, loss_s1: 0.067039, loss_fp: 0.003710, loss_freq: 0.015930
[04:27:58.246] iteration 11339: loss: 0.088472, loss_s1: 0.053391, loss_fp: 0.004727, loss_freq: 0.072704
[04:27:58.888] iteration 11340: loss: 0.061982, loss_s1: 0.042051, loss_fp: 0.000990, loss_freq: 0.015407
[04:27:59.532] iteration 11341: loss: 0.045493, loss_s1: 0.030865, loss_fp: 0.001119, loss_freq: 0.013526
[04:28:00.263] iteration 11342: loss: 0.057266, loss_s1: 0.046771, loss_fp: 0.005480, loss_freq: 0.025878
[04:28:00.961] iteration 11343: loss: 0.089208, loss_s1: 0.065273, loss_fp: 0.001046, loss_freq: 0.035315
[04:28:01.606] iteration 11344: loss: 0.065794, loss_s1: 0.026536, loss_fp: 0.002371, loss_freq: 0.055023
[04:28:02.249] iteration 11345: loss: 0.107172, loss_s1: 0.049644, loss_fp: 0.001843, loss_freq: 0.078990
[04:28:02.897] iteration 11346: loss: 0.049621, loss_s1: 0.017301, loss_fp: 0.001612, loss_freq: 0.016494
[04:28:03.524] iteration 11347: loss: 0.078874, loss_s1: 0.060686, loss_fp: 0.006552, loss_freq: 0.045628
[04:28:04.168] iteration 11348: loss: 0.108089, loss_s1: 0.104681, loss_fp: 0.003434, loss_freq: 0.042418
[04:28:04.796] iteration 11349: loss: 0.040661, loss_s1: 0.039213, loss_fp: 0.000993, loss_freq: 0.010023
[04:28:05.432] iteration 11350: loss: 0.086369, loss_s1: 0.071836, loss_fp: 0.008717, loss_freq: 0.047480
[04:28:06.064] iteration 11351: loss: 0.109624, loss_s1: 0.158427, loss_fp: 0.001017, loss_freq: 0.025931
[04:28:06.688] iteration 11352: loss: 0.062328, loss_s1: 0.046045, loss_fp: 0.002111, loss_freq: 0.012347
[04:28:07.325] iteration 11353: loss: 0.131797, loss_s1: 0.128401, loss_fp: 0.004450, loss_freq: 0.078614
[04:28:07.999] iteration 11354: loss: 0.086572, loss_s1: 0.079255, loss_fp: 0.002554, loss_freq: 0.055181
[04:28:08.655] iteration 11355: loss: 0.071398, loss_s1: 0.053078, loss_fp: 0.004881, loss_freq: 0.042022
[04:28:09.286] iteration 11356: loss: 0.057508, loss_s1: 0.050332, loss_fp: 0.001063, loss_freq: 0.021620
[04:28:09.928] iteration 11357: loss: 0.092426, loss_s1: 0.073830, loss_fp: 0.003136, loss_freq: 0.011734
[04:28:10.557] iteration 11358: loss: 0.088082, loss_s1: 0.091918, loss_fp: 0.002683, loss_freq: 0.044521
[04:28:11.177] iteration 11359: loss: 0.097918, loss_s1: 0.079697, loss_fp: 0.006295, loss_freq: 0.055883
[04:28:11.805] iteration 11360: loss: 0.069611, loss_s1: 0.067754, loss_fp: 0.005068, loss_freq: 0.028951
[04:28:12.441] iteration 11361: loss: 0.094076, loss_s1: 0.100432, loss_fp: 0.006389, loss_freq: 0.032687
[04:28:13.070] iteration 11362: loss: 0.062663, loss_s1: 0.039649, loss_fp: 0.002185, loss_freq: 0.027174
[04:28:13.722] iteration 11363: loss: 0.071136, loss_s1: 0.058264, loss_fp: 0.003659, loss_freq: 0.040774
[04:28:14.360] iteration 11364: loss: 0.073733, loss_s1: 0.065769, loss_fp: 0.013759, loss_freq: 0.014688
[04:28:14.984] iteration 11365: loss: 0.053959, loss_s1: 0.045549, loss_fp: 0.003504, loss_freq: 0.023868
[04:28:15.633] iteration 11366: loss: 0.066647, loss_s1: 0.060936, loss_fp: 0.002725, loss_freq: 0.018172
[04:28:16.263] iteration 11367: loss: 0.064693, loss_s1: 0.044899, loss_fp: 0.003466, loss_freq: 0.022512
[04:28:16.884] iteration 11368: loss: 0.140385, loss_s1: 0.138147, loss_fp: 0.011518, loss_freq: 0.079359
[04:28:17.509] iteration 11369: loss: 0.086172, loss_s1: 0.068255, loss_fp: 0.004936, loss_freq: 0.068747
[04:28:18.131] iteration 11370: loss: 0.091073, loss_s1: 0.078327, loss_fp: 0.005605, loss_freq: 0.046180
[04:28:18.754] iteration 11371: loss: 0.090324, loss_s1: 0.111521, loss_fp: 0.008742, loss_freq: 0.013596
[04:28:19.388] iteration 11372: loss: 0.100080, loss_s1: 0.108693, loss_fp: 0.002594, loss_freq: 0.049693
[04:28:20.026] iteration 11373: loss: 0.105725, loss_s1: 0.061370, loss_fp: 0.001909, loss_freq: 0.068742
[04:28:20.744] iteration 11374: loss: 0.086716, loss_s1: 0.074109, loss_fp: 0.008124, loss_freq: 0.048208
[04:28:21.496] iteration 11375: loss: 0.095632, loss_s1: 0.064250, loss_fp: 0.005013, loss_freq: 0.055507
[04:28:22.155] iteration 11376: loss: 0.067816, loss_s1: 0.075208, loss_fp: 0.002009, loss_freq: 0.011692
[04:28:22.790] iteration 11377: loss: 0.068933, loss_s1: 0.043490, loss_fp: 0.002715, loss_freq: 0.032329
[04:28:23.411] iteration 11378: loss: 0.110067, loss_s1: 0.109826, loss_fp: 0.003679, loss_freq: 0.062716
[04:28:24.046] iteration 11379: loss: 0.069443, loss_s1: 0.052896, loss_fp: 0.005171, loss_freq: 0.030583
[04:28:24.684] iteration 11380: loss: 0.109978, loss_s1: 0.099186, loss_fp: 0.006137, loss_freq: 0.050370
[04:28:25.303] iteration 11381: loss: 0.067385, loss_s1: 0.047788, loss_fp: 0.003366, loss_freq: 0.038944
[04:28:25.939] iteration 11382: loss: 0.069677, loss_s1: 0.069843, loss_fp: 0.001378, loss_freq: 0.021850
[04:28:26.572] iteration 11383: loss: 0.050216, loss_s1: 0.032879, loss_fp: 0.001884, loss_freq: 0.011565
[04:28:27.221] iteration 11384: loss: 0.061343, loss_s1: 0.048691, loss_fp: 0.001667, loss_freq: 0.029593
[04:28:27.860] iteration 11385: loss: 0.056526, loss_s1: 0.017892, loss_fp: 0.003884, loss_freq: 0.024162
[04:28:28.497] iteration 11386: loss: 0.083480, loss_s1: 0.054306, loss_fp: 0.004703, loss_freq: 0.072575
[04:28:29.134] iteration 11387: loss: 0.055266, loss_s1: 0.024172, loss_fp: 0.001805, loss_freq: 0.014830
[04:28:29.758] iteration 11388: loss: 0.069264, loss_s1: 0.065943, loss_fp: 0.003866, loss_freq: 0.020565
[04:28:30.375] iteration 11389: loss: 0.086844, loss_s1: 0.071733, loss_fp: 0.003966, loss_freq: 0.056219
[04:28:30.997] iteration 11390: loss: 0.086893, loss_s1: 0.071244, loss_fp: 0.003502, loss_freq: 0.043533
[04:28:32.007] iteration 11391: loss: 0.059248, loss_s1: 0.055242, loss_fp: 0.002953, loss_freq: 0.014485
[04:28:32.685] iteration 11392: loss: 0.062292, loss_s1: 0.031675, loss_fp: 0.002749, loss_freq: 0.031997
[04:28:33.323] iteration 11393: loss: 0.083858, loss_s1: 0.090181, loss_fp: 0.006551, loss_freq: 0.031136
[04:28:34.026] iteration 11394: loss: 0.063051, loss_s1: 0.066017, loss_fp: 0.002357, loss_freq: 0.019591
[04:28:34.700] iteration 11395: loss: 0.075005, loss_s1: 0.069093, loss_fp: 0.003886, loss_freq: 0.027275
[04:28:35.343] iteration 11396: loss: 0.062467, loss_s1: 0.035877, loss_fp: 0.002039, loss_freq: 0.039174
[04:28:35.994] iteration 11397: loss: 0.085460, loss_s1: 0.078490, loss_fp: 0.005401, loss_freq: 0.039215
[04:28:36.666] iteration 11398: loss: 0.054427, loss_s1: 0.033475, loss_fp: 0.002664, loss_freq: 0.016745
[04:28:37.331] iteration 11399: loss: 0.086063, loss_s1: 0.043267, loss_fp: 0.001658, loss_freq: 0.046992
[04:28:37.989] iteration 11400: loss: 0.088744, loss_s1: 0.089436, loss_fp: 0.007554, loss_freq: 0.034487
[04:28:41.410] iteration 11400 : mean_dice : 0.706626
[04:28:42.065] iteration 11401: loss: 0.071448, loss_s1: 0.044399, loss_fp: 0.004375, loss_freq: 0.043173
[04:28:42.706] iteration 11402: loss: 0.080424, loss_s1: 0.040264, loss_fp: 0.007509, loss_freq: 0.038294
[04:28:43.338] iteration 11403: loss: 0.092394, loss_s1: 0.059788, loss_fp: 0.004458, loss_freq: 0.048582
[04:28:43.971] iteration 11404: loss: 0.086263, loss_s1: 0.094463, loss_fp: 0.002648, loss_freq: 0.018443
[04:28:44.609] iteration 11405: loss: 0.060566, loss_s1: 0.051531, loss_fp: 0.000866, loss_freq: 0.021868
[04:28:45.269] iteration 11406: loss: 0.062813, loss_s1: 0.043292, loss_fp: 0.004325, loss_freq: 0.031480
[04:28:45.917] iteration 11407: loss: 0.169174, loss_s1: 0.169025, loss_fp: 0.003597, loss_freq: 0.124517
[04:28:46.554] iteration 11408: loss: 0.052594, loss_s1: 0.046830, loss_fp: 0.002159, loss_freq: 0.010737
[04:28:47.192] iteration 11409: loss: 0.113266, loss_s1: 0.155073, loss_fp: 0.004250, loss_freq: 0.030452
[04:28:47.833] iteration 11410: loss: 0.074861, loss_s1: 0.067665, loss_fp: 0.001384, loss_freq: 0.030283
[04:28:48.457] iteration 11411: loss: 0.072811, loss_s1: 0.063672, loss_fp: 0.003718, loss_freq: 0.030184
[04:28:49.095] iteration 11412: loss: 0.104137, loss_s1: 0.048754, loss_fp: 0.001720, loss_freq: 0.045460
[04:28:49.709] iteration 11413: loss: 0.098399, loss_s1: 0.070641, loss_fp: 0.002387, loss_freq: 0.052105
[04:28:50.334] iteration 11414: loss: 0.061998, loss_s1: 0.048333, loss_fp: 0.003927, loss_freq: 0.018012
[04:28:50.958] iteration 11415: loss: 0.093134, loss_s1: 0.088605, loss_fp: 0.010653, loss_freq: 0.032317
[04:28:51.576] iteration 11416: loss: 0.113707, loss_s1: 0.128215, loss_fp: 0.004339, loss_freq: 0.041127
[04:28:52.218] iteration 11417: loss: 0.064323, loss_s1: 0.034731, loss_fp: 0.002757, loss_freq: 0.018796
[04:28:52.837] iteration 11418: loss: 0.105460, loss_s1: 0.133947, loss_fp: 0.005110, loss_freq: 0.018578
[04:28:53.459] iteration 11419: loss: 0.070498, loss_s1: 0.048347, loss_fp: 0.005160, loss_freq: 0.037796
[04:28:54.086] iteration 11420: loss: 0.113872, loss_s1: 0.141222, loss_fp: 0.000926, loss_freq: 0.034789
[04:28:54.713] iteration 11421: loss: 0.052797, loss_s1: 0.024109, loss_fp: 0.000362, loss_freq: 0.037146
[04:28:55.355] iteration 11422: loss: 0.078828, loss_s1: 0.060783, loss_fp: 0.008990, loss_freq: 0.028531
[04:28:55.993] iteration 11423: loss: 0.087724, loss_s1: 0.074211, loss_fp: 0.001780, loss_freq: 0.053707
[04:28:56.633] iteration 11424: loss: 0.053591, loss_s1: 0.022581, loss_fp: 0.016306, loss_freq: 0.024573
[04:28:57.258] iteration 11425: loss: 0.053515, loss_s1: 0.047206, loss_fp: 0.003612, loss_freq: 0.031241
[04:28:57.892] iteration 11426: loss: 0.052445, loss_s1: 0.024248, loss_fp: 0.001965, loss_freq: 0.029265
[04:28:58.516] iteration 11427: loss: 0.085412, loss_s1: 0.095916, loss_fp: 0.000925, loss_freq: 0.022802
[04:28:59.155] iteration 11428: loss: 0.074864, loss_s1: 0.081338, loss_fp: 0.002913, loss_freq: 0.029276
[04:28:59.775] iteration 11429: loss: 0.106944, loss_s1: 0.075643, loss_fp: 0.003221, loss_freq: 0.073895
[04:29:00.400] iteration 11430: loss: 0.047487, loss_s1: 0.032158, loss_fp: 0.002779, loss_freq: 0.027069
[04:29:01.029] iteration 11431: loss: 0.096422, loss_s1: 0.100556, loss_fp: 0.001308, loss_freq: 0.045058
[04:29:01.656] iteration 11432: loss: 0.072565, loss_s1: 0.054788, loss_fp: 0.000809, loss_freq: 0.034941
[04:29:02.282] iteration 11433: loss: 0.076695, loss_s1: 0.057613, loss_fp: 0.004289, loss_freq: 0.055284
[04:29:02.908] iteration 11434: loss: 0.110436, loss_s1: 0.127805, loss_fp: 0.005411, loss_freq: 0.051996
[04:29:03.530] iteration 11435: loss: 0.063174, loss_s1: 0.051571, loss_fp: 0.002832, loss_freq: 0.019101
[04:29:04.167] iteration 11436: loss: 0.099015, loss_s1: 0.072159, loss_fp: 0.004307, loss_freq: 0.069777
[04:29:04.809] iteration 11437: loss: 0.049210, loss_s1: 0.035852, loss_fp: 0.001727, loss_freq: 0.016180
[04:29:05.435] iteration 11438: loss: 0.078665, loss_s1: 0.065314, loss_fp: 0.002377, loss_freq: 0.049316
[04:29:06.080] iteration 11439: loss: 0.060247, loss_s1: 0.040092, loss_fp: 0.002178, loss_freq: 0.014677
[04:29:06.704] iteration 11440: loss: 0.055017, loss_s1: 0.040575, loss_fp: 0.000950, loss_freq: 0.026676
[04:29:07.326] iteration 11441: loss: 0.093607, loss_s1: 0.105275, loss_fp: 0.003095, loss_freq: 0.032457
[04:29:07.953] iteration 11442: loss: 0.087031, loss_s1: 0.094854, loss_fp: 0.003127, loss_freq: 0.049375
[04:29:08.585] iteration 11443: loss: 0.092884, loss_s1: 0.035607, loss_fp: 0.002895, loss_freq: 0.056174
[04:29:09.211] iteration 11444: loss: 0.076069, loss_s1: 0.047121, loss_fp: 0.001739, loss_freq: 0.061955
[04:29:09.842] iteration 11445: loss: 0.099010, loss_s1: 0.044092, loss_fp: 0.001815, loss_freq: 0.062661
[04:29:10.480] iteration 11446: loss: 0.053760, loss_s1: 0.034019, loss_fp: 0.002038, loss_freq: 0.025036
[04:29:11.107] iteration 11447: loss: 0.061818, loss_s1: 0.044439, loss_fp: 0.002301, loss_freq: 0.045577
[04:29:11.741] iteration 11448: loss: 0.058685, loss_s1: 0.043308, loss_fp: 0.002058, loss_freq: 0.024063
[04:29:12.366] iteration 11449: loss: 0.059072, loss_s1: 0.046452, loss_fp: 0.002660, loss_freq: 0.023961
[04:29:12.983] iteration 11450: loss: 0.070975, loss_s1: 0.045606, loss_fp: 0.001335, loss_freq: 0.044827
[04:29:13.612] iteration 11451: loss: 0.036183, loss_s1: 0.022834, loss_fp: 0.001550, loss_freq: 0.016988
[04:29:14.269] iteration 11452: loss: 0.080240, loss_s1: 0.051145, loss_fp: 0.007199, loss_freq: 0.035178
[04:29:14.889] iteration 11453: loss: 0.045080, loss_s1: 0.030301, loss_fp: 0.003355, loss_freq: 0.008394
[04:29:15.578] iteration 11454: loss: 0.064224, loss_s1: 0.050952, loss_fp: 0.006490, loss_freq: 0.013763
[04:29:16.252] iteration 11455: loss: 0.113675, loss_s1: 0.121532, loss_fp: 0.001437, loss_freq: 0.039130
[04:29:16.884] iteration 11456: loss: 0.053650, loss_s1: 0.032636, loss_fp: 0.004305, loss_freq: 0.034110
[04:29:17.582] iteration 11457: loss: 0.063549, loss_s1: 0.032018, loss_fp: 0.003513, loss_freq: 0.023077
[04:29:18.272] iteration 11458: loss: 0.139336, loss_s1: 0.153835, loss_fp: 0.017242, loss_freq: 0.072160
[04:29:18.904] iteration 11459: loss: 0.051638, loss_s1: 0.016667, loss_fp: 0.003919, loss_freq: 0.037339
[04:29:19.558] iteration 11460: loss: 0.058240, loss_s1: 0.037719, loss_fp: 0.001443, loss_freq: 0.034251
[04:29:20.201] iteration 11461: loss: 0.082215, loss_s1: 0.070556, loss_fp: 0.004780, loss_freq: 0.028539
[04:29:20.845] iteration 11462: loss: 0.059790, loss_s1: 0.044700, loss_fp: 0.005317, loss_freq: 0.029998
[04:29:21.480] iteration 11463: loss: 0.073153, loss_s1: 0.076325, loss_fp: 0.008110, loss_freq: 0.025568
[04:29:22.121] iteration 11464: loss: 0.064575, loss_s1: 0.040887, loss_fp: 0.003814, loss_freq: 0.041533
[04:29:22.771] iteration 11465: loss: 0.078480, loss_s1: 0.074399, loss_fp: 0.005935, loss_freq: 0.036655
[04:29:23.434] iteration 11466: loss: 0.088650, loss_s1: 0.053277, loss_fp: 0.014500, loss_freq: 0.047429
[04:29:24.089] iteration 11467: loss: 0.066087, loss_s1: 0.062232, loss_fp: 0.009457, loss_freq: 0.022925
[04:29:24.749] iteration 11468: loss: 0.083141, loss_s1: 0.058006, loss_fp: 0.004671, loss_freq: 0.057528
[04:29:25.396] iteration 11469: loss: 0.061384, loss_s1: 0.046085, loss_fp: 0.006036, loss_freq: 0.038646
[04:29:26.020] iteration 11470: loss: 0.060355, loss_s1: 0.031703, loss_fp: 0.002033, loss_freq: 0.029468
[04:29:26.663] iteration 11471: loss: 0.103040, loss_s1: 0.053042, loss_fp: 0.007274, loss_freq: 0.079778
[04:29:27.322] iteration 11472: loss: 0.094155, loss_s1: 0.046904, loss_fp: 0.008828, loss_freq: 0.032484
[04:29:27.966] iteration 11473: loss: 0.113865, loss_s1: 0.132289, loss_fp: 0.003159, loss_freq: 0.041009
[04:29:28.618] iteration 11474: loss: 0.075680, loss_s1: 0.073744, loss_fp: 0.003822, loss_freq: 0.018416
[04:29:29.258] iteration 11475: loss: 0.087061, loss_s1: 0.070031, loss_fp: 0.002100, loss_freq: 0.042892
[04:29:29.917] iteration 11476: loss: 0.073383, loss_s1: 0.084167, loss_fp: 0.004523, loss_freq: 0.022662
[04:29:30.614] iteration 11477: loss: 0.085159, loss_s1: 0.089592, loss_fp: 0.003495, loss_freq: 0.042230
[04:29:31.292] iteration 11478: loss: 0.091139, loss_s1: 0.087269, loss_fp: 0.001895, loss_freq: 0.030549
[04:29:31.961] iteration 11479: loss: 0.070017, loss_s1: 0.059026, loss_fp: 0.002542, loss_freq: 0.029302
[04:29:32.631] iteration 11480: loss: 0.051733, loss_s1: 0.040958, loss_fp: 0.003202, loss_freq: 0.007289
[04:29:33.324] iteration 11481: loss: 0.106548, loss_s1: 0.104924, loss_fp: 0.001914, loss_freq: 0.047828
[04:29:33.958] iteration 11482: loss: 0.061369, loss_s1: 0.054420, loss_fp: 0.007048, loss_freq: 0.010377
[04:29:34.583] iteration 11483: loss: 0.084223, loss_s1: 0.054752, loss_fp: 0.008857, loss_freq: 0.034439
[04:29:35.216] iteration 11484: loss: 0.056094, loss_s1: 0.056176, loss_fp: 0.001592, loss_freq: 0.012778
[04:29:35.837] iteration 11485: loss: 0.073072, loss_s1: 0.035233, loss_fp: 0.002857, loss_freq: 0.047594
[04:29:36.471] iteration 11486: loss: 0.086724, loss_s1: 0.083989, loss_fp: 0.007069, loss_freq: 0.034411
[04:29:37.103] iteration 11487: loss: 0.111927, loss_s1: 0.136288, loss_fp: 0.003163, loss_freq: 0.030173
[04:29:37.752] iteration 11488: loss: 0.060203, loss_s1: 0.041361, loss_fp: 0.001403, loss_freq: 0.019981
[04:29:38.421] iteration 11489: loss: 0.054692, loss_s1: 0.038373, loss_fp: 0.002027, loss_freq: 0.024110
[04:29:39.080] iteration 11490: loss: 0.069791, loss_s1: 0.045736, loss_fp: 0.001944, loss_freq: 0.044210
[04:29:39.715] iteration 11491: loss: 0.044377, loss_s1: 0.036557, loss_fp: 0.001951, loss_freq: 0.020576
[04:29:40.368] iteration 11492: loss: 0.068235, loss_s1: 0.026012, loss_fp: 0.003252, loss_freq: 0.026324
[04:29:41.007] iteration 11493: loss: 0.045351, loss_s1: 0.035729, loss_fp: 0.001333, loss_freq: 0.014493
[04:29:41.651] iteration 11494: loss: 0.054284, loss_s1: 0.021841, loss_fp: 0.003289, loss_freq: 0.024717
[04:29:42.285] iteration 11495: loss: 0.082638, loss_s1: 0.071264, loss_fp: 0.006104, loss_freq: 0.047010
[04:29:42.923] iteration 11496: loss: 0.087891, loss_s1: 0.058240, loss_fp: 0.005122, loss_freq: 0.039961
[04:29:43.560] iteration 11497: loss: 0.055799, loss_s1: 0.038314, loss_fp: 0.003164, loss_freq: 0.020880
[04:29:44.186] iteration 11498: loss: 0.071691, loss_s1: 0.045499, loss_fp: 0.002370, loss_freq: 0.046294
[04:29:44.860] iteration 11499: loss: 0.089936, loss_s1: 0.025974, loss_fp: 0.005264, loss_freq: 0.086464
[04:29:45.488] iteration 11500: loss: 0.060686, loss_s1: 0.031155, loss_fp: 0.003033, loss_freq: 0.033534
[04:29:46.150] iteration 11501: loss: 0.063802, loss_s1: 0.043330, loss_fp: 0.005682, loss_freq: 0.031737
[04:29:46.767] iteration 11502: loss: 0.086787, loss_s1: 0.086168, loss_fp: 0.007460, loss_freq: 0.031712
[04:29:47.406] iteration 11503: loss: 0.083678, loss_s1: 0.070211, loss_fp: 0.003094, loss_freq: 0.032692
[04:29:48.060] iteration 11504: loss: 0.047056, loss_s1: 0.025765, loss_fp: 0.005495, loss_freq: 0.026379
[04:29:48.745] iteration 11505: loss: 0.089827, loss_s1: 0.045213, loss_fp: 0.003205, loss_freq: 0.079802
[04:29:49.435] iteration 11506: loss: 0.070330, loss_s1: 0.055194, loss_fp: 0.004821, loss_freq: 0.035978
[04:29:50.087] iteration 11507: loss: 0.087228, loss_s1: 0.085808, loss_fp: 0.002200, loss_freq: 0.035628
[04:29:50.744] iteration 11508: loss: 0.043142, loss_s1: 0.009650, loss_fp: 0.000684, loss_freq: 0.026906
[04:29:51.432] iteration 11509: loss: 0.155508, loss_s1: 0.074107, loss_fp: 0.008507, loss_freq: 0.182963
[04:29:52.101] iteration 11510: loss: 0.096867, loss_s1: 0.052559, loss_fp: 0.001778, loss_freq: 0.043711
[04:29:52.760] iteration 11511: loss: 0.058435, loss_s1: 0.044503, loss_fp: 0.001347, loss_freq: 0.015355
[04:29:53.389] iteration 11512: loss: 0.081299, loss_s1: 0.077503, loss_fp: 0.000702, loss_freq: 0.046212
[04:29:54.011] iteration 11513: loss: 0.095890, loss_s1: 0.088295, loss_fp: 0.008594, loss_freq: 0.033388
[04:29:54.646] iteration 11514: loss: 0.072232, loss_s1: 0.016215, loss_fp: 0.000277, loss_freq: 0.086292
[04:29:55.282] iteration 11515: loss: 0.101768, loss_s1: 0.080445, loss_fp: 0.006370, loss_freq: 0.054965
[04:29:55.905] iteration 11516: loss: 0.096417, loss_s1: 0.114437, loss_fp: 0.002803, loss_freq: 0.023229
[04:29:56.528] iteration 11517: loss: 0.103075, loss_s1: 0.093613, loss_fp: 0.001414, loss_freq: 0.078004
[04:29:57.157] iteration 11518: loss: 0.080400, loss_s1: 0.051412, loss_fp: 0.004355, loss_freq: 0.050243
[04:29:57.794] iteration 11519: loss: 0.054689, loss_s1: 0.043044, loss_fp: 0.011272, loss_freq: 0.024598
[04:29:58.433] iteration 11520: loss: 0.058643, loss_s1: 0.049305, loss_fp: 0.003822, loss_freq: 0.024736
[04:29:59.097] iteration 11521: loss: 0.062981, loss_s1: 0.057024, loss_fp: 0.005544, loss_freq: 0.030970
[04:29:59.732] iteration 11522: loss: 0.074346, loss_s1: 0.066065, loss_fp: 0.000841, loss_freq: 0.031443
[04:30:00.360] iteration 11523: loss: 0.085575, loss_s1: 0.073847, loss_fp: 0.001670, loss_freq: 0.056369
[04:30:00.981] iteration 11524: loss: 0.063374, loss_s1: 0.042755, loss_fp: 0.003642, loss_freq: 0.029139
[04:30:01.602] iteration 11525: loss: 0.130628, loss_s1: 0.078180, loss_fp: 0.004977, loss_freq: 0.129648
[04:30:02.232] iteration 11526: loss: 0.057102, loss_s1: 0.051561, loss_fp: 0.009917, loss_freq: 0.021201
[04:30:02.864] iteration 11527: loss: 0.100477, loss_s1: 0.081780, loss_fp: 0.001373, loss_freq: 0.026573
[04:30:03.496] iteration 11528: loss: 0.070890, loss_s1: 0.061201, loss_fp: 0.002496, loss_freq: 0.043944
[04:30:04.130] iteration 11529: loss: 0.131791, loss_s1: 0.149750, loss_fp: 0.005852, loss_freq: 0.056592
[04:30:04.761] iteration 11530: loss: 0.064213, loss_s1: 0.057160, loss_fp: 0.002994, loss_freq: 0.032233
[04:30:05.383] iteration 11531: loss: 0.079359, loss_s1: 0.058712, loss_fp: 0.005763, loss_freq: 0.040929
[04:30:06.003] iteration 11532: loss: 0.073913, loss_s1: 0.058976, loss_fp: 0.004179, loss_freq: 0.030419
[04:30:06.634] iteration 11533: loss: 0.085224, loss_s1: 0.098506, loss_fp: 0.000786, loss_freq: 0.020633
[04:30:07.267] iteration 11534: loss: 0.048902, loss_s1: 0.031214, loss_fp: 0.005954, loss_freq: 0.014500
[04:30:07.898] iteration 11535: loss: 0.061484, loss_s1: 0.055939, loss_fp: 0.001293, loss_freq: 0.029088
[04:30:08.532] iteration 11536: loss: 0.037389, loss_s1: 0.006589, loss_fp: 0.000695, loss_freq: 0.017081
[04:30:09.196] iteration 11537: loss: 0.051655, loss_s1: 0.028449, loss_fp: 0.008262, loss_freq: 0.022243
[04:30:09.867] iteration 11538: loss: 0.107057, loss_s1: 0.093540, loss_fp: 0.010284, loss_freq: 0.080139
[04:30:10.502] iteration 11539: loss: 0.085968, loss_s1: 0.118178, loss_fp: 0.001345, loss_freq: 0.011023
[04:30:11.130] iteration 11540: loss: 0.069061, loss_s1: 0.035919, loss_fp: 0.006235, loss_freq: 0.021985
[04:30:11.774] iteration 11541: loss: 0.072585, loss_s1: 0.063744, loss_fp: 0.002084, loss_freq: 0.013595
[04:30:12.412] iteration 11542: loss: 0.078124, loss_s1: 0.043378, loss_fp: 0.004242, loss_freq: 0.064951
[04:30:13.050] iteration 11543: loss: 0.074757, loss_s1: 0.057350, loss_fp: 0.002540, loss_freq: 0.042047
[04:30:13.700] iteration 11544: loss: 0.060231, loss_s1: 0.039632, loss_fp: 0.003155, loss_freq: 0.035727
[04:30:14.342] iteration 11545: loss: 0.092875, loss_s1: 0.060044, loss_fp: 0.002551, loss_freq: 0.064262
[04:30:14.992] iteration 11546: loss: 0.060574, loss_s1: 0.035329, loss_fp: 0.004608, loss_freq: 0.022740
[04:30:15.629] iteration 11547: loss: 0.064762, loss_s1: 0.039196, loss_fp: 0.001849, loss_freq: 0.041300
[04:30:16.261] iteration 11548: loss: 0.101428, loss_s1: 0.078472, loss_fp: 0.011793, loss_freq: 0.058640
[04:30:16.883] iteration 11549: loss: 0.061205, loss_s1: 0.051795, loss_fp: 0.004029, loss_freq: 0.023427
[04:30:17.525] iteration 11550: loss: 0.090028, loss_s1: 0.059880, loss_fp: 0.004068, loss_freq: 0.051435
[04:30:18.167] iteration 11551: loss: 0.055395, loss_s1: 0.060733, loss_fp: 0.002924, loss_freq: 0.003307
[04:30:18.802] iteration 11552: loss: 0.054694, loss_s1: 0.053357, loss_fp: 0.004359, loss_freq: 0.016766
[04:30:19.519] iteration 11553: loss: 0.068193, loss_s1: 0.022704, loss_fp: 0.001449, loss_freq: 0.038843
[04:30:20.193] iteration 11554: loss: 0.061098, loss_s1: 0.046980, loss_fp: 0.004071, loss_freq: 0.031515
[04:30:20.872] iteration 11555: loss: 0.050650, loss_s1: 0.035693, loss_fp: 0.006705, loss_freq: 0.013353
[04:30:21.565] iteration 11556: loss: 0.077783, loss_s1: 0.068521, loss_fp: 0.006899, loss_freq: 0.043157
[04:30:22.255] iteration 11557: loss: 0.064749, loss_s1: 0.054973, loss_fp: 0.007898, loss_freq: 0.020610
[04:30:22.938] iteration 11558: loss: 0.100310, loss_s1: 0.117446, loss_fp: 0.004665, loss_freq: 0.025902
[04:30:23.590] iteration 11559: loss: 0.065870, loss_s1: 0.049116, loss_fp: 0.001495, loss_freq: 0.046018
[04:30:24.260] iteration 11560: loss: 0.089875, loss_s1: 0.072525, loss_fp: 0.012887, loss_freq: 0.049331
[04:30:25.313] iteration 11561: loss: 0.087760, loss_s1: 0.077322, loss_fp: 0.002125, loss_freq: 0.043739
[04:30:25.998] iteration 11562: loss: 0.053114, loss_s1: 0.033598, loss_fp: 0.002256, loss_freq: 0.030187
[04:30:26.671] iteration 11563: loss: 0.054441, loss_s1: 0.032335, loss_fp: 0.002666, loss_freq: 0.019837
[04:30:27.352] iteration 11564: loss: 0.034101, loss_s1: 0.014095, loss_fp: 0.003382, loss_freq: 0.008757
[04:30:28.029] iteration 11565: loss: 0.084815, loss_s1: 0.088743, loss_fp: 0.001033, loss_freq: 0.040957
[04:30:28.694] iteration 11566: loss: 0.074014, loss_s1: 0.078952, loss_fp: 0.003342, loss_freq: 0.023904
[04:30:29.340] iteration 11567: loss: 0.095932, loss_s1: 0.060587, loss_fp: 0.008215, loss_freq: 0.056334
[04:30:29.984] iteration 11568: loss: 0.077849, loss_s1: 0.074029, loss_fp: 0.003429, loss_freq: 0.042815
[04:30:30.618] iteration 11569: loss: 0.074637, loss_s1: 0.061543, loss_fp: 0.006460, loss_freq: 0.029374
[04:30:31.248] iteration 11570: loss: 0.079482, loss_s1: 0.047205, loss_fp: 0.007862, loss_freq: 0.039156
[04:30:31.884] iteration 11571: loss: 0.089936, loss_s1: 0.021712, loss_fp: 0.007509, loss_freq: 0.046765
[04:30:32.522] iteration 11572: loss: 0.094137, loss_s1: 0.076145, loss_fp: 0.002265, loss_freq: 0.072247
[04:30:33.185] iteration 11573: loss: 0.085998, loss_s1: 0.068245, loss_fp: 0.003398, loss_freq: 0.061655
[04:30:33.856] iteration 11574: loss: 0.045760, loss_s1: 0.038942, loss_fp: 0.002934, loss_freq: 0.015727
[04:30:34.484] iteration 11575: loss: 0.065606, loss_s1: 0.061376, loss_fp: 0.002376, loss_freq: 0.011925
[04:30:35.116] iteration 11576: loss: 0.053570, loss_s1: 0.025602, loss_fp: 0.002530, loss_freq: 0.031348
[04:30:35.750] iteration 11577: loss: 0.120054, loss_s1: 0.098161, loss_fp: 0.009945, loss_freq: 0.101826
[04:30:36.377] iteration 11578: loss: 0.060691, loss_s1: 0.052119, loss_fp: 0.001165, loss_freq: 0.017082
[04:30:37.007] iteration 11579: loss: 0.092955, loss_s1: 0.094099, loss_fp: 0.004797, loss_freq: 0.029268
[04:30:37.638] iteration 11580: loss: 0.092568, loss_s1: 0.078153, loss_fp: 0.001090, loss_freq: 0.027226
[04:30:38.269] iteration 11581: loss: 0.064070, loss_s1: 0.035942, loss_fp: 0.001693, loss_freq: 0.033871
[04:30:38.905] iteration 11582: loss: 0.099759, loss_s1: 0.058397, loss_fp: 0.008860, loss_freq: 0.041564
[04:30:39.536] iteration 11583: loss: 0.084107, loss_s1: 0.052120, loss_fp: 0.001199, loss_freq: 0.049944
[04:30:40.193] iteration 11584: loss: 0.078425, loss_s1: 0.066439, loss_fp: 0.002111, loss_freq: 0.021978
[04:30:40.840] iteration 11585: loss: 0.079076, loss_s1: 0.090550, loss_fp: 0.001689, loss_freq: 0.020579
[04:30:41.474] iteration 11586: loss: 0.089064, loss_s1: 0.072579, loss_fp: 0.004878, loss_freq: 0.039170
[04:30:42.106] iteration 11587: loss: 0.078779, loss_s1: 0.051762, loss_fp: 0.004459, loss_freq: 0.035016
[04:30:42.736] iteration 11588: loss: 0.107116, loss_s1: 0.066655, loss_fp: 0.001495, loss_freq: 0.030629
[04:30:43.364] iteration 11589: loss: 0.057898, loss_s1: 0.034459, loss_fp: 0.004799, loss_freq: 0.038498
[04:30:44.002] iteration 11590: loss: 0.078525, loss_s1: 0.068080, loss_fp: 0.010152, loss_freq: 0.029974
[04:30:44.633] iteration 11591: loss: 0.098979, loss_s1: 0.116498, loss_fp: 0.000888, loss_freq: 0.040802
[04:30:45.282] iteration 11592: loss: 0.096111, loss_s1: 0.081483, loss_fp: 0.001680, loss_freq: 0.054956
[04:30:45.912] iteration 11593: loss: 0.099179, loss_s1: 0.102453, loss_fp: 0.002414, loss_freq: 0.048905
[04:30:46.542] iteration 11594: loss: 0.038052, loss_s1: 0.023033, loss_fp: 0.001692, loss_freq: 0.010563
[04:30:47.178] iteration 11595: loss: 0.071902, loss_s1: 0.055869, loss_fp: 0.006991, loss_freq: 0.043834
[04:30:47.816] iteration 11596: loss: 0.053906, loss_s1: 0.038109, loss_fp: 0.001888, loss_freq: 0.013137
[04:30:48.445] iteration 11597: loss: 0.065347, loss_s1: 0.036382, loss_fp: 0.006441, loss_freq: 0.030184
[04:30:49.076] iteration 11598: loss: 0.094343, loss_s1: 0.082747, loss_fp: 0.002128, loss_freq: 0.024123
[04:30:49.711] iteration 11599: loss: 0.097494, loss_s1: 0.073992, loss_fp: 0.005650, loss_freq: 0.066805
[04:30:50.368] iteration 11600: loss: 0.068750, loss_s1: 0.052603, loss_fp: 0.006315, loss_freq: 0.043720
[04:30:53.779] iteration 11600 : mean_dice : 0.718612
[04:30:54.428] iteration 11601: loss: 0.104330, loss_s1: 0.090670, loss_fp: 0.000778, loss_freq: 0.053226
[04:30:55.086] iteration 11602: loss: 0.089952, loss_s1: 0.087094, loss_fp: 0.001707, loss_freq: 0.039105
[04:30:55.766] iteration 11603: loss: 0.083656, loss_s1: 0.064598, loss_fp: 0.006570, loss_freq: 0.042574
[04:30:56.445] iteration 11604: loss: 0.107649, loss_s1: 0.134664, loss_fp: 0.003780, loss_freq: 0.033486
[04:30:57.159] iteration 11605: loss: 0.089390, loss_s1: 0.059963, loss_fp: 0.000875, loss_freq: 0.044756
[04:30:57.783] iteration 11606: loss: 0.075396, loss_s1: 0.064981, loss_fp: 0.006407, loss_freq: 0.018680
[04:30:58.432] iteration 11607: loss: 0.059816, loss_s1: 0.026954, loss_fp: 0.005942, loss_freq: 0.031197
[04:30:59.061] iteration 11608: loss: 0.063712, loss_s1: 0.054022, loss_fp: 0.002118, loss_freq: 0.028247
[04:30:59.702] iteration 11609: loss: 0.072115, loss_s1: 0.047086, loss_fp: 0.001164, loss_freq: 0.006482
[04:31:00.341] iteration 11610: loss: 0.085669, loss_s1: 0.059907, loss_fp: 0.002192, loss_freq: 0.024274
[04:31:00.966] iteration 11611: loss: 0.057606, loss_s1: 0.023124, loss_fp: 0.002670, loss_freq: 0.019061
[04:31:01.622] iteration 11612: loss: 0.079845, loss_s1: 0.075147, loss_fp: 0.003989, loss_freq: 0.053510
[04:31:02.274] iteration 11613: loss: 0.063841, loss_s1: 0.039750, loss_fp: 0.004681, loss_freq: 0.013387
[04:31:02.912] iteration 11614: loss: 0.104390, loss_s1: 0.079941, loss_fp: 0.001649, loss_freq: 0.078279
[04:31:03.559] iteration 11615: loss: 0.092132, loss_s1: 0.074628, loss_fp: 0.003840, loss_freq: 0.057211
[04:31:04.187] iteration 11616: loss: 0.056167, loss_s1: 0.048015, loss_fp: 0.003165, loss_freq: 0.023408
[04:31:04.827] iteration 11617: loss: 0.062259, loss_s1: 0.062376, loss_fp: 0.001513, loss_freq: 0.028445
[04:31:05.448] iteration 11618: loss: 0.063825, loss_s1: 0.018950, loss_fp: 0.002902, loss_freq: 0.033527
[04:31:06.089] iteration 11619: loss: 0.109553, loss_s1: 0.071695, loss_fp: 0.008667, loss_freq: 0.063462
[04:31:06.713] iteration 11620: loss: 0.082961, loss_s1: 0.061119, loss_fp: 0.007220, loss_freq: 0.048245
[04:31:07.346] iteration 11621: loss: 0.066865, loss_s1: 0.061541, loss_fp: 0.001341, loss_freq: 0.013614
[04:31:07.977] iteration 11622: loss: 0.074873, loss_s1: 0.071043, loss_fp: 0.005630, loss_freq: 0.038648
[04:31:08.629] iteration 11623: loss: 0.051045, loss_s1: 0.039598, loss_fp: 0.003433, loss_freq: 0.012290
[04:31:09.258] iteration 11624: loss: 0.039780, loss_s1: 0.021736, loss_fp: 0.002682, loss_freq: 0.014986
[04:31:09.878] iteration 11625: loss: 0.074084, loss_s1: 0.054467, loss_fp: 0.015284, loss_freq: 0.023662
[04:31:10.511] iteration 11626: loss: 0.092627, loss_s1: 0.093273, loss_fp: 0.002184, loss_freq: 0.042425
[04:31:11.156] iteration 11627: loss: 0.058902, loss_s1: 0.032710, loss_fp: 0.002143, loss_freq: 0.014043
[04:31:11.788] iteration 11628: loss: 0.147808, loss_s1: 0.124691, loss_fp: 0.008877, loss_freq: 0.103270
[04:31:12.429] iteration 11629: loss: 0.051308, loss_s1: 0.011532, loss_fp: 0.005388, loss_freq: 0.038668
[04:31:13.056] iteration 11630: loss: 0.082556, loss_s1: 0.080205, loss_fp: 0.001404, loss_freq: 0.054874
[04:31:13.682] iteration 11631: loss: 0.086011, loss_s1: 0.090886, loss_fp: 0.004985, loss_freq: 0.027147
[04:31:14.306] iteration 11632: loss: 0.064131, loss_s1: 0.039702, loss_fp: 0.001563, loss_freq: 0.035653
[04:31:14.954] iteration 11633: loss: 0.101293, loss_s1: 0.068937, loss_fp: 0.007067, loss_freq: 0.041472
[04:31:15.577] iteration 11634: loss: 0.088710, loss_s1: 0.060064, loss_fp: 0.008211, loss_freq: 0.037718
[04:31:16.199] iteration 11635: loss: 0.069133, loss_s1: 0.039028, loss_fp: 0.005757, loss_freq: 0.056741
[04:31:16.834] iteration 11636: loss: 0.073963, loss_s1: 0.055292, loss_fp: 0.006640, loss_freq: 0.046409
[04:31:17.460] iteration 11637: loss: 0.044438, loss_s1: 0.025924, loss_fp: 0.002874, loss_freq: 0.022572
[04:31:18.117] iteration 11638: loss: 0.090012, loss_s1: 0.109985, loss_fp: 0.007025, loss_freq: 0.028598
[04:31:18.792] iteration 11639: loss: 0.068663, loss_s1: 0.066165, loss_fp: 0.003282, loss_freq: 0.031493
[04:31:19.465] iteration 11640: loss: 0.082563, loss_s1: 0.091941, loss_fp: 0.002023, loss_freq: 0.017107
[04:31:20.149] iteration 11641: loss: 0.057910, loss_s1: 0.029365, loss_fp: 0.004296, loss_freq: 0.041102
[04:31:20.826] iteration 11642: loss: 0.100444, loss_s1: 0.080666, loss_fp: 0.003724, loss_freq: 0.047218
[04:31:21.490] iteration 11643: loss: 0.072041, loss_s1: 0.056682, loss_fp: 0.002363, loss_freq: 0.022528
[04:31:22.127] iteration 11644: loss: 0.064826, loss_s1: 0.058536, loss_fp: 0.004326, loss_freq: 0.025714
[04:31:22.803] iteration 11645: loss: 0.082002, loss_s1: 0.045697, loss_fp: 0.005919, loss_freq: 0.057406
[04:31:23.429] iteration 11646: loss: 0.041507, loss_s1: 0.009047, loss_fp: 0.002562, loss_freq: 0.023602
[04:31:24.058] iteration 11647: loss: 0.072127, loss_s1: 0.084030, loss_fp: 0.005432, loss_freq: 0.018323
[04:31:24.691] iteration 11648: loss: 0.105128, loss_s1: 0.079616, loss_fp: 0.010197, loss_freq: 0.078595
[04:31:25.315] iteration 11649: loss: 0.128897, loss_s1: 0.121304, loss_fp: 0.009265, loss_freq: 0.078607
[04:31:25.961] iteration 11650: loss: 0.067264, loss_s1: 0.071111, loss_fp: 0.002130, loss_freq: 0.013385
[04:31:26.600] iteration 11651: loss: 0.120296, loss_s1: 0.118650, loss_fp: 0.003604, loss_freq: 0.037371
[04:31:27.222] iteration 11652: loss: 0.051839, loss_s1: 0.035235, loss_fp: 0.003351, loss_freq: 0.027537
[04:31:27.842] iteration 11653: loss: 0.066943, loss_s1: 0.038470, loss_fp: 0.004088, loss_freq: 0.024321
[04:31:28.479] iteration 11654: loss: 0.050660, loss_s1: 0.046694, loss_fp: 0.003488, loss_freq: 0.013196
[04:31:29.095] iteration 11655: loss: 0.090477, loss_s1: 0.087175, loss_fp: 0.007009, loss_freq: 0.037828
[04:31:29.719] iteration 11656: loss: 0.053271, loss_s1: 0.036427, loss_fp: 0.003134, loss_freq: 0.030362
[04:31:30.337] iteration 11657: loss: 0.087630, loss_s1: 0.054375, loss_fp: 0.010051, loss_freq: 0.047367
[04:31:30.971] iteration 11658: loss: 0.062441, loss_s1: 0.027441, loss_fp: 0.010834, loss_freq: 0.034839
[04:31:31.612] iteration 11659: loss: 0.064535, loss_s1: 0.042002, loss_fp: 0.007324, loss_freq: 0.038710
[04:31:32.270] iteration 11660: loss: 0.045006, loss_s1: 0.029896, loss_fp: 0.001205, loss_freq: 0.015479
[04:31:32.911] iteration 11661: loss: 0.047655, loss_s1: 0.034247, loss_fp: 0.005250, loss_freq: 0.017566
[04:31:33.617] iteration 11662: loss: 0.056794, loss_s1: 0.038519, loss_fp: 0.001098, loss_freq: 0.024236
[04:31:34.302] iteration 11663: loss: 0.043561, loss_s1: 0.024645, loss_fp: 0.003992, loss_freq: 0.017972
[04:31:34.981] iteration 11664: loss: 0.059866, loss_s1: 0.023685, loss_fp: 0.009211, loss_freq: 0.028758
[04:31:35.657] iteration 11665: loss: 0.057748, loss_s1: 0.033410, loss_fp: 0.003686, loss_freq: 0.040351
[04:31:36.302] iteration 11666: loss: 0.078696, loss_s1: 0.052194, loss_fp: 0.007418, loss_freq: 0.046203
[04:31:36.972] iteration 11667: loss: 0.078763, loss_s1: 0.076603, loss_fp: 0.006526, loss_freq: 0.021387
[04:31:37.626] iteration 11668: loss: 0.068329, loss_s1: 0.040052, loss_fp: 0.005595, loss_freq: 0.033455
[04:31:38.331] iteration 11669: loss: 0.095667, loss_s1: 0.047324, loss_fp: 0.009594, loss_freq: 0.080707
[04:31:39.011] iteration 11670: loss: 0.061518, loss_s1: 0.045034, loss_fp: 0.000605, loss_freq: 0.031191
[04:31:39.656] iteration 11671: loss: 0.085690, loss_s1: 0.088879, loss_fp: 0.002317, loss_freq: 0.033241
[04:31:40.307] iteration 11672: loss: 0.063151, loss_s1: 0.031522, loss_fp: 0.002320, loss_freq: 0.031760
[04:31:41.007] iteration 11673: loss: 0.061090, loss_s1: 0.049833, loss_fp: 0.001751, loss_freq: 0.037377
[04:31:41.677] iteration 11674: loss: 0.033148, loss_s1: 0.024109, loss_fp: 0.001840, loss_freq: 0.012671
[04:31:42.358] iteration 11675: loss: 0.104175, loss_s1: 0.048591, loss_fp: 0.004108, loss_freq: 0.109397
[04:31:43.025] iteration 11676: loss: 0.074838, loss_s1: 0.042069, loss_fp: 0.003657, loss_freq: 0.042921
[04:31:43.659] iteration 11677: loss: 0.059804, loss_s1: 0.059601, loss_fp: 0.001777, loss_freq: 0.022328
[04:31:44.280] iteration 11678: loss: 0.059845, loss_s1: 0.061075, loss_fp: 0.001546, loss_freq: 0.015738
[04:31:44.904] iteration 11679: loss: 0.102602, loss_s1: 0.045106, loss_fp: 0.001683, loss_freq: 0.106108
[04:31:45.527] iteration 11680: loss: 0.065027, loss_s1: 0.059247, loss_fp: 0.002151, loss_freq: 0.011264
[04:31:46.156] iteration 11681: loss: 0.050620, loss_s1: 0.041413, loss_fp: 0.000934, loss_freq: 0.011507
[04:31:46.805] iteration 11682: loss: 0.073772, loss_s1: 0.054997, loss_fp: 0.005665, loss_freq: 0.032200
[04:31:47.429] iteration 11683: loss: 0.095835, loss_s1: 0.080592, loss_fp: 0.006752, loss_freq: 0.064783
[04:31:48.048] iteration 11684: loss: 0.082953, loss_s1: 0.102658, loss_fp: 0.003511, loss_freq: 0.023687
[04:31:48.688] iteration 11685: loss: 0.109280, loss_s1: 0.123824, loss_fp: 0.001316, loss_freq: 0.049311
[04:31:49.326] iteration 11686: loss: 0.060236, loss_s1: 0.050641, loss_fp: 0.005352, loss_freq: 0.025150
[04:31:49.963] iteration 11687: loss: 0.090324, loss_s1: 0.064289, loss_fp: 0.001082, loss_freq: 0.080923
[04:31:50.586] iteration 11688: loss: 0.072371, loss_s1: 0.068961, loss_fp: 0.001929, loss_freq: 0.012336
[04:31:51.227] iteration 11689: loss: 0.060907, loss_s1: 0.042018, loss_fp: 0.009919, loss_freq: 0.030586
[04:31:51.869] iteration 11690: loss: 0.076639, loss_s1: 0.068039, loss_fp: 0.005671, loss_freq: 0.028701
[04:31:52.488] iteration 11691: loss: 0.082942, loss_s1: 0.085750, loss_fp: 0.003133, loss_freq: 0.027672
[04:31:53.127] iteration 11692: loss: 0.067526, loss_s1: 0.048908, loss_fp: 0.004194, loss_freq: 0.040746
[04:31:53.752] iteration 11693: loss: 0.112267, loss_s1: 0.143283, loss_fp: 0.003952, loss_freq: 0.036216
[04:31:54.391] iteration 11694: loss: 0.085525, loss_s1: 0.072358, loss_fp: 0.005292, loss_freq: 0.025771
[04:31:55.028] iteration 11695: loss: 0.159665, loss_s1: 0.126517, loss_fp: 0.008237, loss_freq: 0.124740
[04:31:55.657] iteration 11696: loss: 0.037639, loss_s1: 0.023149, loss_fp: 0.002880, loss_freq: 0.014398
[04:31:56.284] iteration 11697: loss: 0.071036, loss_s1: 0.039063, loss_fp: 0.007914, loss_freq: 0.033830
[04:31:56.935] iteration 11698: loss: 0.082604, loss_s1: 0.043380, loss_fp: 0.012673, loss_freq: 0.069892
[04:31:57.661] iteration 11699: loss: 0.133777, loss_s1: 0.145492, loss_fp: 0.009327, loss_freq: 0.074745
[04:31:58.347] iteration 11700: loss: 0.071618, loss_s1: 0.066017, loss_fp: 0.002104, loss_freq: 0.039074
[04:31:59.033] iteration 11701: loss: 0.129649, loss_s1: 0.057187, loss_fp: 0.002096, loss_freq: 0.035342
[04:31:59.705] iteration 11702: loss: 0.064506, loss_s1: 0.047475, loss_fp: 0.001851, loss_freq: 0.030214
[04:32:00.405] iteration 11703: loss: 0.083455, loss_s1: 0.076571, loss_fp: 0.004104, loss_freq: 0.053581
[04:32:01.082] iteration 11704: loss: 0.063837, loss_s1: 0.052686, loss_fp: 0.001778, loss_freq: 0.025883
[04:32:01.705] iteration 11705: loss: 0.061835, loss_s1: 0.049778, loss_fp: 0.004035, loss_freq: 0.020664
[04:32:02.377] iteration 11706: loss: 0.077045, loss_s1: 0.056134, loss_fp: 0.002756, loss_freq: 0.026778
[04:32:03.046] iteration 11707: loss: 0.081663, loss_s1: 0.058602, loss_fp: 0.002606, loss_freq: 0.026822
[04:32:03.715] iteration 11708: loss: 0.092054, loss_s1: 0.070747, loss_fp: 0.002468, loss_freq: 0.054686
[04:32:04.398] iteration 11709: loss: 0.074577, loss_s1: 0.063923, loss_fp: 0.002399, loss_freq: 0.045405
[04:32:05.079] iteration 11710: loss: 0.081409, loss_s1: 0.034869, loss_fp: 0.010187, loss_freq: 0.042925
[04:32:05.712] iteration 11711: loss: 0.087831, loss_s1: 0.057513, loss_fp: 0.009528, loss_freq: 0.043398
[04:32:06.348] iteration 11712: loss: 0.087284, loss_s1: 0.041767, loss_fp: 0.006338, loss_freq: 0.076444
[04:32:06.971] iteration 11713: loss: 0.079123, loss_s1: 0.054530, loss_fp: 0.002334, loss_freq: 0.052541
[04:32:07.660] iteration 11714: loss: 0.088564, loss_s1: 0.078236, loss_fp: 0.007439, loss_freq: 0.030450
[04:32:08.336] iteration 11715: loss: 0.068136, loss_s1: 0.056717, loss_fp: 0.002713, loss_freq: 0.031163
[04:32:08.951] iteration 11716: loss: 0.062595, loss_s1: 0.056596, loss_fp: 0.002801, loss_freq: 0.025145
[04:32:09.571] iteration 11717: loss: 0.065758, loss_s1: 0.054651, loss_fp: 0.008797, loss_freq: 0.036860
[04:32:10.221] iteration 11718: loss: 0.101760, loss_s1: 0.073051, loss_fp: 0.006039, loss_freq: 0.089616
[04:32:10.846] iteration 11719: loss: 0.069718, loss_s1: 0.069680, loss_fp: 0.008255, loss_freq: 0.022782
[04:32:11.464] iteration 11720: loss: 0.089214, loss_s1: 0.080734, loss_fp: 0.006625, loss_freq: 0.044006
[04:32:12.089] iteration 11721: loss: 0.072658, loss_s1: 0.083778, loss_fp: 0.002061, loss_freq: 0.004175
[04:32:12.725] iteration 11722: loss: 0.072111, loss_s1: 0.079523, loss_fp: 0.001469, loss_freq: 0.025361
[04:32:13.373] iteration 11723: loss: 0.050205, loss_s1: 0.020905, loss_fp: 0.000887, loss_freq: 0.019254
[04:32:14.108] iteration 11724: loss: 0.057999, loss_s1: 0.050931, loss_fp: 0.002414, loss_freq: 0.030985
[04:32:14.767] iteration 11725: loss: 0.039608, loss_s1: 0.022155, loss_fp: 0.002181, loss_freq: 0.012836
[04:32:15.413] iteration 11726: loss: 0.138265, loss_s1: 0.151500, loss_fp: 0.002321, loss_freq: 0.022789
[04:32:16.046] iteration 11727: loss: 0.096676, loss_s1: 0.057652, loss_fp: 0.001076, loss_freq: 0.062536
[04:32:16.665] iteration 11728: loss: 0.092823, loss_s1: 0.073944, loss_fp: 0.013159, loss_freq: 0.055350
[04:32:17.278] iteration 11729: loss: 0.083146, loss_s1: 0.072960, loss_fp: 0.001371, loss_freq: 0.054068
[04:32:17.894] iteration 11730: loss: 0.053163, loss_s1: 0.034258, loss_fp: 0.000898, loss_freq: 0.023268
[04:32:18.859] iteration 11731: loss: 0.106846, loss_s1: 0.051067, loss_fp: 0.001796, loss_freq: 0.016759
[04:32:19.546] iteration 11732: loss: 0.062159, loss_s1: 0.041821, loss_fp: 0.002905, loss_freq: 0.036883
[04:32:20.176] iteration 11733: loss: 0.102142, loss_s1: 0.086558, loss_fp: 0.003309, loss_freq: 0.032948
[04:32:20.816] iteration 11734: loss: 0.065451, loss_s1: 0.070985, loss_fp: 0.002255, loss_freq: 0.010269
[04:32:21.446] iteration 11735: loss: 0.088329, loss_s1: 0.079702, loss_fp: 0.005028, loss_freq: 0.024758
[04:32:22.077] iteration 11736: loss: 0.081068, loss_s1: 0.058513, loss_fp: 0.003251, loss_freq: 0.042613
[04:32:22.694] iteration 11737: loss: 0.077701, loss_s1: 0.078729, loss_fp: 0.002964, loss_freq: 0.022829
[04:32:23.312] iteration 11738: loss: 0.049020, loss_s1: 0.039183, loss_fp: 0.003770, loss_freq: 0.012673
[04:32:23.935] iteration 11739: loss: 0.073324, loss_s1: 0.061831, loss_fp: 0.002353, loss_freq: 0.013736
[04:32:24.572] iteration 11740: loss: 0.105713, loss_s1: 0.055593, loss_fp: 0.014810, loss_freq: 0.039120
[04:32:25.193] iteration 11741: loss: 0.090884, loss_s1: 0.029445, loss_fp: 0.003667, loss_freq: 0.040279
[04:32:25.839] iteration 11742: loss: 0.106653, loss_s1: 0.103834, loss_fp: 0.005797, loss_freq: 0.053408
[04:32:26.492] iteration 11743: loss: 0.104110, loss_s1: 0.053908, loss_fp: 0.005903, loss_freq: 0.069144
[04:32:27.136] iteration 11744: loss: 0.084605, loss_s1: 0.068106, loss_fp: 0.002211, loss_freq: 0.050237
[04:32:27.808] iteration 11745: loss: 0.078394, loss_s1: 0.066368, loss_fp: 0.006039, loss_freq: 0.032935
[04:32:28.482] iteration 11746: loss: 0.085716, loss_s1: 0.083682, loss_fp: 0.008361, loss_freq: 0.026732
[04:32:29.109] iteration 11747: loss: 0.140401, loss_s1: 0.138757, loss_fp: 0.001316, loss_freq: 0.101034
[04:32:29.736] iteration 11748: loss: 0.078333, loss_s1: 0.078967, loss_fp: 0.002194, loss_freq: 0.025371
[04:32:30.380] iteration 11749: loss: 0.073677, loss_s1: 0.085304, loss_fp: 0.006189, loss_freq: 0.015306
[04:32:31.009] iteration 11750: loss: 0.074110, loss_s1: 0.047701, loss_fp: 0.002258, loss_freq: 0.018017
[04:32:31.638] iteration 11751: loss: 0.061644, loss_s1: 0.043428, loss_fp: 0.002628, loss_freq: 0.014718
[04:32:32.260] iteration 11752: loss: 0.101524, loss_s1: 0.106092, loss_fp: 0.007044, loss_freq: 0.052369
[04:32:32.911] iteration 11753: loss: 0.079853, loss_s1: 0.031488, loss_fp: 0.002067, loss_freq: 0.036351
[04:32:33.539] iteration 11754: loss: 0.064291, loss_s1: 0.050219, loss_fp: 0.002844, loss_freq: 0.036459
[04:32:34.163] iteration 11755: loss: 0.122804, loss_s1: 0.130255, loss_fp: 0.001343, loss_freq: 0.042703
[04:32:34.785] iteration 11756: loss: 0.081779, loss_s1: 0.057098, loss_fp: 0.001631, loss_freq: 0.035573
[04:32:35.404] iteration 11757: loss: 0.069557, loss_s1: 0.032897, loss_fp: 0.000778, loss_freq: 0.023462
[04:32:36.045] iteration 11758: loss: 0.126236, loss_s1: 0.140417, loss_fp: 0.003213, loss_freq: 0.038358
[04:32:36.664] iteration 11759: loss: 0.078350, loss_s1: 0.070869, loss_fp: 0.002450, loss_freq: 0.046764
[04:32:37.296] iteration 11760: loss: 0.078979, loss_s1: 0.068814, loss_fp: 0.001237, loss_freq: 0.047519
[04:32:37.922] iteration 11761: loss: 0.081286, loss_s1: 0.055592, loss_fp: 0.001399, loss_freq: 0.065741
[04:32:38.542] iteration 11762: loss: 0.124010, loss_s1: 0.092360, loss_fp: 0.001767, loss_freq: 0.071872
[04:32:39.165] iteration 11763: loss: 0.099608, loss_s1: 0.122072, loss_fp: 0.003019, loss_freq: 0.038243
[04:32:39.789] iteration 11764: loss: 0.040346, loss_s1: 0.028283, loss_fp: 0.004271, loss_freq: 0.006512
[04:32:40.424] iteration 11765: loss: 0.084173, loss_s1: 0.089630, loss_fp: 0.000895, loss_freq: 0.048397
[04:32:41.081] iteration 11766: loss: 0.068315, loss_s1: 0.054472, loss_fp: 0.001274, loss_freq: 0.017028
[04:32:41.708] iteration 11767: loss: 0.052954, loss_s1: 0.025397, loss_fp: 0.001493, loss_freq: 0.028136
[04:32:42.378] iteration 11768: loss: 0.076296, loss_s1: 0.080593, loss_fp: 0.003305, loss_freq: 0.028327
[04:32:43.054] iteration 11769: loss: 0.098318, loss_s1: 0.084472, loss_fp: 0.004900, loss_freq: 0.041756
[04:32:43.728] iteration 11770: loss: 0.071747, loss_s1: 0.051956, loss_fp: 0.001135, loss_freq: 0.051520
[04:32:44.394] iteration 11771: loss: 0.093942, loss_s1: 0.074041, loss_fp: 0.005520, loss_freq: 0.044822
[04:32:45.059] iteration 11772: loss: 0.063263, loss_s1: 0.046302, loss_fp: 0.002162, loss_freq: 0.035705
[04:32:45.692] iteration 11773: loss: 0.100049, loss_s1: 0.095577, loss_fp: 0.007126, loss_freq: 0.061620
[04:32:46.394] iteration 11774: loss: 0.099934, loss_s1: 0.099231, loss_fp: 0.006333, loss_freq: 0.052985
[04:32:47.071] iteration 11775: loss: 0.080186, loss_s1: 0.069034, loss_fp: 0.001987, loss_freq: 0.040185
[04:32:47.764] iteration 11776: loss: 0.065700, loss_s1: 0.043339, loss_fp: 0.005910, loss_freq: 0.036076
[04:32:48.446] iteration 11777: loss: 0.065057, loss_s1: 0.047070, loss_fp: 0.003759, loss_freq: 0.038890
[04:32:49.117] iteration 11778: loss: 0.069589, loss_s1: 0.045898, loss_fp: 0.005187, loss_freq: 0.029916
[04:32:49.755] iteration 11779: loss: 0.059408, loss_s1: 0.031830, loss_fp: 0.000526, loss_freq: 0.006258
[04:32:50.393] iteration 11780: loss: 0.047079, loss_s1: 0.019717, loss_fp: 0.001583, loss_freq: 0.015342
[04:32:51.033] iteration 11781: loss: 0.099865, loss_s1: 0.127189, loss_fp: 0.003413, loss_freq: 0.031813
[04:32:51.660] iteration 11782: loss: 0.111105, loss_s1: 0.112995, loss_fp: 0.003967, loss_freq: 0.073066
[04:32:52.299] iteration 11783: loss: 0.049567, loss_s1: 0.019788, loss_fp: 0.001994, loss_freq: 0.031805
[04:32:52.927] iteration 11784: loss: 0.086096, loss_s1: 0.085565, loss_fp: 0.007526, loss_freq: 0.023816
[04:32:53.556] iteration 11785: loss: 0.109124, loss_s1: 0.051843, loss_fp: 0.008546, loss_freq: 0.046309
[04:32:54.207] iteration 11786: loss: 0.048483, loss_s1: 0.031065, loss_fp: 0.000975, loss_freq: 0.027612
[04:32:54.840] iteration 11787: loss: 0.086556, loss_s1: 0.059492, loss_fp: 0.006773, loss_freq: 0.059900
[04:32:55.481] iteration 11788: loss: 0.065368, loss_s1: 0.042778, loss_fp: 0.003223, loss_freq: 0.036933
[04:32:56.119] iteration 11789: loss: 0.059830, loss_s1: 0.032814, loss_fp: 0.001668, loss_freq: 0.040413
[04:32:56.741] iteration 11790: loss: 0.072871, loss_s1: 0.046873, loss_fp: 0.008605, loss_freq: 0.047565
[04:32:57.376] iteration 11791: loss: 0.045108, loss_s1: 0.041237, loss_fp: 0.001125, loss_freq: 0.014690
[04:32:58.007] iteration 11792: loss: 0.080653, loss_s1: 0.031863, loss_fp: 0.004702, loss_freq: 0.070008
[04:32:58.624] iteration 11793: loss: 0.042931, loss_s1: 0.030971, loss_fp: 0.001369, loss_freq: 0.009297
[04:32:59.275] iteration 11794: loss: 0.055447, loss_s1: 0.045234, loss_fp: 0.000964, loss_freq: 0.021569
[04:32:59.919] iteration 11795: loss: 0.102994, loss_s1: 0.136908, loss_fp: 0.001299, loss_freq: 0.019421
[04:33:00.542] iteration 11796: loss: 0.071974, loss_s1: 0.063282, loss_fp: 0.002597, loss_freq: 0.037143
[04:33:01.170] iteration 11797: loss: 0.086498, loss_s1: 0.041151, loss_fp: 0.003212, loss_freq: 0.033250
[04:33:01.817] iteration 11798: loss: 0.118610, loss_s1: 0.110508, loss_fp: 0.010810, loss_freq: 0.076699
[04:33:02.452] iteration 11799: loss: 0.056899, loss_s1: 0.046445, loss_fp: 0.003460, loss_freq: 0.015417
[04:33:03.073] iteration 11800: loss: 0.078971, loss_s1: 0.074960, loss_fp: 0.004828, loss_freq: 0.041182
[04:33:06.333] iteration 11800 : mean_dice : 0.698520
[04:33:06.989] iteration 11801: loss: 0.100270, loss_s1: 0.053187, loss_fp: 0.004492, loss_freq: 0.044728
[04:33:07.623] iteration 11802: loss: 0.096593, loss_s1: 0.081059, loss_fp: 0.001595, loss_freq: 0.052818
[04:33:08.251] iteration 11803: loss: 0.060477, loss_s1: 0.048305, loss_fp: 0.003021, loss_freq: 0.034706
[04:33:08.893] iteration 11804: loss: 0.101463, loss_s1: 0.086521, loss_fp: 0.003422, loss_freq: 0.067379
[04:33:09.528] iteration 11805: loss: 0.080772, loss_s1: 0.053365, loss_fp: 0.002952, loss_freq: 0.048507
[04:33:10.148] iteration 11806: loss: 0.078403, loss_s1: 0.069204, loss_fp: 0.003746, loss_freq: 0.038916
[04:33:10.770] iteration 11807: loss: 0.054353, loss_s1: 0.046830, loss_fp: 0.004640, loss_freq: 0.015196
[04:33:11.498] iteration 11808: loss: 0.113386, loss_s1: 0.105926, loss_fp: 0.008709, loss_freq: 0.044170
[04:33:12.171] iteration 11809: loss: 0.062710, loss_s1: 0.047622, loss_fp: 0.007104, loss_freq: 0.033276
[04:33:12.850] iteration 11810: loss: 0.060243, loss_s1: 0.048974, loss_fp: 0.002322, loss_freq: 0.022281
[04:33:13.529] iteration 11811: loss: 0.084187, loss_s1: 0.070104, loss_fp: 0.006022, loss_freq: 0.034904
[04:33:14.207] iteration 11812: loss: 0.091360, loss_s1: 0.074885, loss_fp: 0.008792, loss_freq: 0.033967
[04:33:14.866] iteration 11813: loss: 0.052799, loss_s1: 0.042276, loss_fp: 0.000524, loss_freq: 0.019869
[04:33:15.489] iteration 11814: loss: 0.083016, loss_s1: 0.070465, loss_fp: 0.007673, loss_freq: 0.020774
[04:33:16.110] iteration 11815: loss: 0.061082, loss_s1: 0.039402, loss_fp: 0.003361, loss_freq: 0.031709
[04:33:16.735] iteration 11816: loss: 0.061193, loss_s1: 0.049514, loss_fp: 0.003319, loss_freq: 0.019975
[04:33:17.397] iteration 11817: loss: 0.064327, loss_s1: 0.069319, loss_fp: 0.001794, loss_freq: 0.032840
[04:33:18.051] iteration 11818: loss: 0.084082, loss_s1: 0.083151, loss_fp: 0.002836, loss_freq: 0.017685
[04:33:18.677] iteration 11819: loss: 0.123911, loss_s1: 0.152819, loss_fp: 0.004928, loss_freq: 0.048947
[04:33:19.314] iteration 11820: loss: 0.058458, loss_s1: 0.037059, loss_fp: 0.001619, loss_freq: 0.030921
[04:33:19.946] iteration 11821: loss: 0.076100, loss_s1: 0.070187, loss_fp: 0.000799, loss_freq: 0.022723
[04:33:20.565] iteration 11822: loss: 0.052815, loss_s1: 0.038831, loss_fp: 0.002263, loss_freq: 0.027933
[04:33:21.182] iteration 11823: loss: 0.096020, loss_s1: 0.072993, loss_fp: 0.004905, loss_freq: 0.067055
[04:33:21.820] iteration 11824: loss: 0.079301, loss_s1: 0.077911, loss_fp: 0.003939, loss_freq: 0.030450
[04:33:22.462] iteration 11825: loss: 0.083731, loss_s1: 0.055484, loss_fp: 0.001806, loss_freq: 0.060479
[04:33:23.087] iteration 11826: loss: 0.083724, loss_s1: 0.099198, loss_fp: 0.001747, loss_freq: 0.027941
[04:33:23.727] iteration 11827: loss: 0.116415, loss_s1: 0.080868, loss_fp: 0.012196, loss_freq: 0.059867
[04:33:24.362] iteration 11828: loss: 0.067910, loss_s1: 0.048592, loss_fp: 0.005460, loss_freq: 0.033093
[04:33:24.988] iteration 11829: loss: 0.075783, loss_s1: 0.069399, loss_fp: 0.002675, loss_freq: 0.037855
[04:33:25.623] iteration 11830: loss: 0.066995, loss_s1: 0.039044, loss_fp: 0.001494, loss_freq: 0.035774
[04:33:26.244] iteration 11831: loss: 0.064797, loss_s1: 0.040528, loss_fp: 0.004159, loss_freq: 0.051054
[04:33:26.863] iteration 11832: loss: 0.070922, loss_s1: 0.044874, loss_fp: 0.003285, loss_freq: 0.012093
[04:33:27.479] iteration 11833: loss: 0.058278, loss_s1: 0.050874, loss_fp: 0.002344, loss_freq: 0.016193
[04:33:28.152] iteration 11834: loss: 0.064197, loss_s1: 0.040583, loss_fp: 0.005106, loss_freq: 0.028171
[04:33:28.782] iteration 11835: loss: 0.076902, loss_s1: 0.068395, loss_fp: 0.002178, loss_freq: 0.043181
[04:33:29.414] iteration 11836: loss: 0.056741, loss_s1: 0.025579, loss_fp: 0.007412, loss_freq: 0.029244
[04:33:30.071] iteration 11837: loss: 0.059060, loss_s1: 0.045184, loss_fp: 0.002788, loss_freq: 0.026410
[04:33:30.698] iteration 11838: loss: 0.078382, loss_s1: 0.051817, loss_fp: 0.003339, loss_freq: 0.045235
[04:33:31.325] iteration 11839: loss: 0.099384, loss_s1: 0.076220, loss_fp: 0.008569, loss_freq: 0.054703
[04:33:31.966] iteration 11840: loss: 0.069998, loss_s1: 0.018169, loss_fp: 0.001577, loss_freq: 0.022425
[04:33:32.600] iteration 11841: loss: 0.084769, loss_s1: 0.050281, loss_fp: 0.010738, loss_freq: 0.046211
[04:33:33.263] iteration 11842: loss: 0.057117, loss_s1: 0.032168, loss_fp: 0.012527, loss_freq: 0.025264
[04:33:33.895] iteration 11843: loss: 0.093859, loss_s1: 0.061380, loss_fp: 0.006383, loss_freq: 0.039157
[04:33:34.548] iteration 11844: loss: 0.045062, loss_s1: 0.027056, loss_fp: 0.004147, loss_freq: 0.014453
[04:33:35.171] iteration 11845: loss: 0.097059, loss_s1: 0.050227, loss_fp: 0.017954, loss_freq: 0.078071
[04:33:35.811] iteration 11846: loss: 0.095784, loss_s1: 0.068803, loss_fp: 0.002268, loss_freq: 0.056158
[04:33:36.436] iteration 11847: loss: 0.078594, loss_s1: 0.088332, loss_fp: 0.008849, loss_freq: 0.018048
[04:33:37.074] iteration 11848: loss: 0.080438, loss_s1: 0.065987, loss_fp: 0.003101, loss_freq: 0.033194
[04:33:37.701] iteration 11849: loss: 0.086992, loss_s1: 0.056832, loss_fp: 0.003304, loss_freq: 0.063016
[04:33:38.329] iteration 11850: loss: 0.050953, loss_s1: 0.028660, loss_fp: 0.001323, loss_freq: 0.023945
[04:33:38.978] iteration 11851: loss: 0.050561, loss_s1: 0.035944, loss_fp: 0.002138, loss_freq: 0.015279
[04:33:39.662] iteration 11852: loss: 0.077740, loss_s1: 0.087407, loss_fp: 0.002258, loss_freq: 0.026564
[04:33:40.288] iteration 11853: loss: 0.101967, loss_s1: 0.057946, loss_fp: 0.002250, loss_freq: 0.100767
[04:33:40.911] iteration 11854: loss: 0.056597, loss_s1: 0.035302, loss_fp: 0.002336, loss_freq: 0.026771
[04:33:41.551] iteration 11855: loss: 0.114448, loss_s1: 0.089557, loss_fp: 0.002780, loss_freq: 0.068127
[04:33:42.180] iteration 11856: loss: 0.042632, loss_s1: 0.029193, loss_fp: 0.002503, loss_freq: 0.011376
[04:33:42.824] iteration 11857: loss: 0.092105, loss_s1: 0.102222, loss_fp: 0.002200, loss_freq: 0.044817
[04:33:43.461] iteration 11858: loss: 0.081616, loss_s1: 0.033771, loss_fp: 0.003195, loss_freq: 0.034076
[04:33:44.102] iteration 11859: loss: 0.060936, loss_s1: 0.037616, loss_fp: 0.002324, loss_freq: 0.029169
[04:33:44.732] iteration 11860: loss: 0.085260, loss_s1: 0.045019, loss_fp: 0.018157, loss_freq: 0.039253
[04:33:45.384] iteration 11861: loss: 0.100997, loss_s1: 0.129848, loss_fp: 0.003065, loss_freq: 0.027107
[04:33:46.017] iteration 11862: loss: 0.084440, loss_s1: 0.043570, loss_fp: 0.002546, loss_freq: 0.017702
[04:33:46.660] iteration 11863: loss: 0.086324, loss_s1: 0.065539, loss_fp: 0.002411, loss_freq: 0.040732
[04:33:47.290] iteration 11864: loss: 0.082611, loss_s1: 0.072157, loss_fp: 0.005093, loss_freq: 0.041774
[04:33:47.907] iteration 11865: loss: 0.086652, loss_s1: 0.060976, loss_fp: 0.002805, loss_freq: 0.065773
[04:33:48.569] iteration 11866: loss: 0.074501, loss_s1: 0.071485, loss_fp: 0.002078, loss_freq: 0.024126
[04:33:49.241] iteration 11867: loss: 0.048783, loss_s1: 0.022303, loss_fp: 0.001306, loss_freq: 0.019277
[04:33:49.948] iteration 11868: loss: 0.077922, loss_s1: 0.067509, loss_fp: 0.003112, loss_freq: 0.051052
[04:33:50.607] iteration 11869: loss: 0.112944, loss_s1: 0.105088, loss_fp: 0.004294, loss_freq: 0.067608
[04:33:51.244] iteration 11870: loss: 0.074942, loss_s1: 0.062262, loss_fp: 0.012210, loss_freq: 0.030613
[04:33:51.879] iteration 11871: loss: 0.091898, loss_s1: 0.078871, loss_fp: 0.004141, loss_freq: 0.030809
[04:33:52.550] iteration 11872: loss: 0.049481, loss_s1: 0.016162, loss_fp: 0.005830, loss_freq: 0.028048
[04:33:53.255] iteration 11873: loss: 0.061014, loss_s1: 0.037617, loss_fp: 0.005038, loss_freq: 0.043445
[04:33:53.955] iteration 11874: loss: 0.077883, loss_s1: 0.059069, loss_fp: 0.003605, loss_freq: 0.027734
[04:33:54.647] iteration 11875: loss: 0.065258, loss_s1: 0.069213, loss_fp: 0.008919, loss_freq: 0.016997
[04:33:55.335] iteration 11876: loss: 0.064829, loss_s1: 0.027421, loss_fp: 0.010107, loss_freq: 0.031924
[04:33:55.980] iteration 11877: loss: 0.064836, loss_s1: 0.056857, loss_fp: 0.004650, loss_freq: 0.029483
[04:33:56.617] iteration 11878: loss: 0.114984, loss_s1: 0.143873, loss_fp: 0.002362, loss_freq: 0.030367
[04:33:57.254] iteration 11879: loss: 0.064549, loss_s1: 0.055980, loss_fp: 0.004748, loss_freq: 0.039548
[04:33:57.883] iteration 11880: loss: 0.056159, loss_s1: 0.036315, loss_fp: 0.003974, loss_freq: 0.017277
[04:33:58.535] iteration 11881: loss: 0.081701, loss_s1: 0.046426, loss_fp: 0.005739, loss_freq: 0.059122
[04:33:59.232] iteration 11882: loss: 0.064794, loss_s1: 0.051294, loss_fp: 0.002468, loss_freq: 0.035864
[04:33:59.879] iteration 11883: loss: 0.081509, loss_s1: 0.056123, loss_fp: 0.001583, loss_freq: 0.039262
[04:34:00.514] iteration 11884: loss: 0.079432, loss_s1: 0.056440, loss_fp: 0.008481, loss_freq: 0.032820
[04:34:01.153] iteration 11885: loss: 0.079125, loss_s1: 0.035576, loss_fp: 0.003953, loss_freq: 0.062559
[04:34:01.777] iteration 11886: loss: 0.063753, loss_s1: 0.064985, loss_fp: 0.001575, loss_freq: 0.013383
[04:34:02.393] iteration 11887: loss: 0.047721, loss_s1: 0.041352, loss_fp: 0.002470, loss_freq: 0.021055
[04:34:03.025] iteration 11888: loss: 0.113774, loss_s1: 0.083550, loss_fp: 0.004556, loss_freq: 0.093562
[04:34:03.652] iteration 11889: loss: 0.045994, loss_s1: 0.033182, loss_fp: 0.002595, loss_freq: 0.017429
[04:34:04.268] iteration 11890: loss: 0.083034, loss_s1: 0.058685, loss_fp: 0.002432, loss_freq: 0.036860
[04:34:04.905] iteration 11891: loss: 0.044800, loss_s1: 0.036703, loss_fp: 0.000884, loss_freq: 0.008540
[04:34:05.527] iteration 11892: loss: 0.036440, loss_s1: 0.026797, loss_fp: 0.002162, loss_freq: 0.009611
[04:34:06.149] iteration 11893: loss: 0.049507, loss_s1: 0.023405, loss_fp: 0.001256, loss_freq: 0.008747
[04:34:06.776] iteration 11894: loss: 0.069550, loss_s1: 0.079290, loss_fp: 0.000985, loss_freq: 0.025764
[04:34:07.416] iteration 11895: loss: 0.054653, loss_s1: 0.047705, loss_fp: 0.007905, loss_freq: 0.012104
[04:34:08.043] iteration 11896: loss: 0.074913, loss_s1: 0.078950, loss_fp: 0.001129, loss_freq: 0.036730
[04:34:08.683] iteration 11897: loss: 0.074613, loss_s1: 0.060955, loss_fp: 0.005979, loss_freq: 0.034844
[04:34:09.350] iteration 11898: loss: 0.062457, loss_s1: 0.042314, loss_fp: 0.008342, loss_freq: 0.029950
[04:34:09.978] iteration 11899: loss: 0.079692, loss_s1: 0.075169, loss_fp: 0.004531, loss_freq: 0.031537
[04:34:10.616] iteration 11900: loss: 0.081419, loss_s1: 0.072341, loss_fp: 0.001127, loss_freq: 0.036678
[04:34:11.615] iteration 11901: loss: 0.068152, loss_s1: 0.047845, loss_fp: 0.005092, loss_freq: 0.023500
[04:34:12.238] iteration 11902: loss: 0.057014, loss_s1: 0.026929, loss_fp: 0.008570, loss_freq: 0.027447
[04:34:12.860] iteration 11903: loss: 0.051640, loss_s1: 0.041952, loss_fp: 0.002689, loss_freq: 0.028945
[04:34:13.492] iteration 11904: loss: 0.050115, loss_s1: 0.036512, loss_fp: 0.001537, loss_freq: 0.013598
[04:34:14.170] iteration 11905: loss: 0.096622, loss_s1: 0.088405, loss_fp: 0.003344, loss_freq: 0.069266
[04:34:14.794] iteration 11906: loss: 0.094608, loss_s1: 0.094050, loss_fp: 0.004084, loss_freq: 0.033458
[04:34:15.422] iteration 11907: loss: 0.102796, loss_s1: 0.094537, loss_fp: 0.002417, loss_freq: 0.068940
[04:34:16.065] iteration 11908: loss: 0.064092, loss_s1: 0.041221, loss_fp: 0.004623, loss_freq: 0.033531
[04:34:16.685] iteration 11909: loss: 0.065228, loss_s1: 0.042320, loss_fp: 0.005442, loss_freq: 0.047783
[04:34:17.341] iteration 11910: loss: 0.105472, loss_s1: 0.101534, loss_fp: 0.008535, loss_freq: 0.039922
[04:34:17.983] iteration 11911: loss: 0.110192, loss_s1: 0.067892, loss_fp: 0.020459, loss_freq: 0.074593
[04:34:18.682] iteration 11912: loss: 0.078269, loss_s1: 0.060725, loss_fp: 0.001066, loss_freq: 0.051167
[04:34:19.333] iteration 11913: loss: 0.088052, loss_s1: 0.053415, loss_fp: 0.004424, loss_freq: 0.079545
[04:34:19.952] iteration 11914: loss: 0.070237, loss_s1: 0.054034, loss_fp: 0.003330, loss_freq: 0.048789
[04:34:20.595] iteration 11915: loss: 0.059959, loss_s1: 0.041110, loss_fp: 0.002822, loss_freq: 0.023074
[04:34:21.242] iteration 11916: loss: 0.109530, loss_s1: 0.117671, loss_fp: 0.002588, loss_freq: 0.041535
[04:34:21.883] iteration 11917: loss: 0.118774, loss_s1: 0.096563, loss_fp: 0.002134, loss_freq: 0.107004
[04:34:22.516] iteration 11918: loss: 0.070714, loss_s1: 0.061272, loss_fp: 0.002121, loss_freq: 0.028021
[04:34:23.140] iteration 11919: loss: 0.104456, loss_s1: 0.103903, loss_fp: 0.012638, loss_freq: 0.044818
[04:34:23.813] iteration 11920: loss: 0.096148, loss_s1: 0.104867, loss_fp: 0.005975, loss_freq: 0.011767
[04:34:24.480] iteration 11921: loss: 0.057256, loss_s1: 0.041732, loss_fp: 0.004491, loss_freq: 0.022581
[04:34:25.163] iteration 11922: loss: 0.062874, loss_s1: 0.041378, loss_fp: 0.012497, loss_freq: 0.033270
[04:34:25.828] iteration 11923: loss: 0.105790, loss_s1: 0.056984, loss_fp: 0.001727, loss_freq: 0.041762
[04:34:26.466] iteration 11924: loss: 0.099743, loss_s1: 0.104736, loss_fp: 0.000877, loss_freq: 0.049488
[04:34:27.112] iteration 11925: loss: 0.072964, loss_s1: 0.068690, loss_fp: 0.002881, loss_freq: 0.030638
[04:34:27.730] iteration 11926: loss: 0.071600, loss_s1: 0.056031, loss_fp: 0.002183, loss_freq: 0.042998
[04:34:28.417] iteration 11927: loss: 0.074252, loss_s1: 0.060597, loss_fp: 0.002930, loss_freq: 0.018793
[04:34:29.052] iteration 11928: loss: 0.095056, loss_s1: 0.058689, loss_fp: 0.005050, loss_freq: 0.041791
[04:34:29.919] iteration 11929: loss: 0.081762, loss_s1: 0.054682, loss_fp: 0.005434, loss_freq: 0.033476
[04:34:30.900] iteration 11930: loss: 0.078341, loss_s1: 0.065195, loss_fp: 0.002528, loss_freq: 0.044563
[04:34:31.619] iteration 11931: loss: 0.080580, loss_s1: 0.046831, loss_fp: 0.007583, loss_freq: 0.065432
[04:34:32.256] iteration 11932: loss: 0.134972, loss_s1: 0.141568, loss_fp: 0.003530, loss_freq: 0.073418
[04:34:32.911] iteration 11933: loss: 0.078066, loss_s1: 0.073060, loss_fp: 0.005213, loss_freq: 0.039071
[04:34:33.563] iteration 11934: loss: 0.070737, loss_s1: 0.062682, loss_fp: 0.011996, loss_freq: 0.017191
[04:34:34.204] iteration 11935: loss: 0.045938, loss_s1: 0.031458, loss_fp: 0.001536, loss_freq: 0.028553
[04:34:34.835] iteration 11936: loss: 0.054088, loss_s1: 0.028648, loss_fp: 0.001720, loss_freq: 0.025987
[04:34:35.474] iteration 11937: loss: 0.076463, loss_s1: 0.059931, loss_fp: 0.002667, loss_freq: 0.043390
[04:34:36.110] iteration 11938: loss: 0.048550, loss_s1: 0.043547, loss_fp: 0.001999, loss_freq: 0.015354
[04:34:36.801] iteration 11939: loss: 0.113795, loss_s1: 0.085799, loss_fp: 0.003683, loss_freq: 0.063299
[04:34:37.432] iteration 11940: loss: 0.106854, loss_s1: 0.080371, loss_fp: 0.005141, loss_freq: 0.082943
[04:34:38.062] iteration 11941: loss: 0.077037, loss_s1: 0.036144, loss_fp: 0.006848, loss_freq: 0.059179
[04:34:38.681] iteration 11942: loss: 0.064767, loss_s1: 0.062007, loss_fp: 0.004996, loss_freq: 0.019526
[04:34:39.363] iteration 11943: loss: 0.133424, loss_s1: 0.139726, loss_fp: 0.004564, loss_freq: 0.065265
[04:34:40.052] iteration 11944: loss: 0.107534, loss_s1: 0.092326, loss_fp: 0.003004, loss_freq: 0.078017
[04:34:40.700] iteration 11945: loss: 0.069737, loss_s1: 0.060272, loss_fp: 0.001640, loss_freq: 0.024063
[04:34:41.338] iteration 11946: loss: 0.065329, loss_s1: 0.041804, loss_fp: 0.002816, loss_freq: 0.047150
[04:34:41.977] iteration 11947: loss: 0.045679, loss_s1: 0.016589, loss_fp: 0.004450, loss_freq: 0.024769
[04:34:42.618] iteration 11948: loss: 0.086373, loss_s1: 0.047955, loss_fp: 0.007078, loss_freq: 0.047656
[04:34:43.263] iteration 11949: loss: 0.058166, loss_s1: 0.042196, loss_fp: 0.000815, loss_freq: 0.025978
[04:34:43.902] iteration 11950: loss: 0.080045, loss_s1: 0.066211, loss_fp: 0.000741, loss_freq: 0.016002
[04:34:44.544] iteration 11951: loss: 0.080185, loss_s1: 0.091116, loss_fp: 0.001681, loss_freq: 0.023613
[04:34:45.187] iteration 11952: loss: 0.048644, loss_s1: 0.048662, loss_fp: 0.002362, loss_freq: 0.012695
[04:34:45.847] iteration 11953: loss: 0.046930, loss_s1: 0.013218, loss_fp: 0.005237, loss_freq: 0.029114
[04:34:46.494] iteration 11954: loss: 0.075282, loss_s1: 0.058215, loss_fp: 0.006944, loss_freq: 0.035054
[04:34:47.140] iteration 11955: loss: 0.059256, loss_s1: 0.034856, loss_fp: 0.003108, loss_freq: 0.030946
[04:34:47.783] iteration 11956: loss: 0.049846, loss_s1: 0.027830, loss_fp: 0.001415, loss_freq: 0.030176
[04:34:48.422] iteration 11957: loss: 0.066709, loss_s1: 0.043679, loss_fp: 0.005370, loss_freq: 0.040387
[04:34:49.065] iteration 11958: loss: 0.051226, loss_s1: 0.019176, loss_fp: 0.000762, loss_freq: 0.015099
[04:34:49.699] iteration 11959: loss: 0.069447, loss_s1: 0.062242, loss_fp: 0.001598, loss_freq: 0.024481
[04:34:50.370] iteration 11960: loss: 0.066144, loss_s1: 0.047746, loss_fp: 0.004163, loss_freq: 0.034252
[04:34:51.056] iteration 11961: loss: 0.033981, loss_s1: 0.024967, loss_fp: 0.002464, loss_freq: 0.010144
[04:34:51.757] iteration 11962: loss: 0.101924, loss_s1: 0.066374, loss_fp: 0.002123, loss_freq: 0.051495
[04:34:52.454] iteration 11963: loss: 0.049729, loss_s1: 0.033054, loss_fp: 0.002064, loss_freq: 0.008689
[04:34:53.116] iteration 11964: loss: 0.056460, loss_s1: 0.033854, loss_fp: 0.001370, loss_freq: 0.030088
[04:34:53.766] iteration 11965: loss: 0.089277, loss_s1: 0.087091, loss_fp: 0.004660, loss_freq: 0.037645
[04:34:54.403] iteration 11966: loss: 0.080308, loss_s1: 0.050411, loss_fp: 0.000746, loss_freq: 0.061151
[04:34:55.046] iteration 11967: loss: 0.062799, loss_s1: 0.033772, loss_fp: 0.003824, loss_freq: 0.012716
[04:34:55.681] iteration 11968: loss: 0.131510, loss_s1: 0.107411, loss_fp: 0.027015, loss_freq: 0.052340
[04:34:56.327] iteration 11969: loss: 0.069584, loss_s1: 0.037315, loss_fp: 0.003337, loss_freq: 0.034506
[04:34:56.963] iteration 11970: loss: 0.074049, loss_s1: 0.039921, loss_fp: 0.011472, loss_freq: 0.059947
[04:34:57.684] iteration 11971: loss: 0.080153, loss_s1: 0.074842, loss_fp: 0.005496, loss_freq: 0.026085
[04:34:58.355] iteration 11972: loss: 0.056118, loss_s1: 0.040723, loss_fp: 0.007214, loss_freq: 0.024498
[04:34:59.040] iteration 11973: loss: 0.060060, loss_s1: 0.040033, loss_fp: 0.005926, loss_freq: 0.039577
[04:34:59.715] iteration 11974: loss: 0.087835, loss_s1: 0.102968, loss_fp: 0.009442, loss_freq: 0.017761
[04:35:00.341] iteration 11975: loss: 0.117733, loss_s1: 0.077792, loss_fp: 0.001942, loss_freq: 0.093312
[04:35:01.060] iteration 11976: loss: 0.077797, loss_s1: 0.049253, loss_fp: 0.006095, loss_freq: 0.039350
[04:35:01.706] iteration 11977: loss: 0.067957, loss_s1: 0.049817, loss_fp: 0.003921, loss_freq: 0.033468
[04:35:02.394] iteration 11978: loss: 0.067720, loss_s1: 0.045010, loss_fp: 0.008538, loss_freq: 0.042573
[04:35:03.130] iteration 11979: loss: 0.096983, loss_s1: 0.100724, loss_fp: 0.007666, loss_freq: 0.050307
[04:35:03.788] iteration 11980: loss: 0.081155, loss_s1: 0.059167, loss_fp: 0.001450, loss_freq: 0.018775
[04:35:04.405] iteration 11981: loss: 0.111807, loss_s1: 0.057706, loss_fp: 0.001599, loss_freq: 0.088436
[04:35:05.025] iteration 11982: loss: 0.060772, loss_s1: 0.056311, loss_fp: 0.003712, loss_freq: 0.024429
[04:35:05.663] iteration 11983: loss: 0.073017, loss_s1: 0.072928, loss_fp: 0.003155, loss_freq: 0.012099
[04:35:06.288] iteration 11984: loss: 0.087358, loss_s1: 0.104361, loss_fp: 0.005249, loss_freq: 0.019668
[04:35:06.914] iteration 11985: loss: 0.081535, loss_s1: 0.055522, loss_fp: 0.002840, loss_freq: 0.046875
[04:35:07.557] iteration 11986: loss: 0.068453, loss_s1: 0.048903, loss_fp: 0.001865, loss_freq: 0.024657
[04:35:08.180] iteration 11987: loss: 0.087819, loss_s1: 0.097956, loss_fp: 0.003986, loss_freq: 0.043157
[04:35:08.823] iteration 11988: loss: 0.058555, loss_s1: 0.049210, loss_fp: 0.003079, loss_freq: 0.018156
[04:35:09.473] iteration 11989: loss: 0.128154, loss_s1: 0.072555, loss_fp: 0.025826, loss_freq: 0.103159
[04:35:10.096] iteration 11990: loss: 0.052640, loss_s1: 0.022906, loss_fp: 0.002323, loss_freq: 0.008255
[04:35:10.713] iteration 11991: loss: 0.063638, loss_s1: 0.037901, loss_fp: 0.002091, loss_freq: 0.025230
[04:35:11.336] iteration 11992: loss: 0.124734, loss_s1: 0.154010, loss_fp: 0.003563, loss_freq: 0.060135
[04:35:12.024] iteration 11993: loss: 0.121219, loss_s1: 0.122026, loss_fp: 0.007244, loss_freq: 0.029363
[04:35:12.660] iteration 11994: loss: 0.059294, loss_s1: 0.035489, loss_fp: 0.002171, loss_freq: 0.020085
[04:35:13.285] iteration 11995: loss: 0.068718, loss_s1: 0.041593, loss_fp: 0.008986, loss_freq: 0.039542
[04:35:13.929] iteration 11996: loss: 0.072084, loss_s1: 0.067487, loss_fp: 0.001214, loss_freq: 0.032228
[04:35:14.550] iteration 11997: loss: 0.076727, loss_s1: 0.051342, loss_fp: 0.001523, loss_freq: 0.037730
[04:35:15.192] iteration 11998: loss: 0.076711, loss_s1: 0.049816, loss_fp: 0.003291, loss_freq: 0.045791
[04:35:15.818] iteration 11999: loss: 0.065235, loss_s1: 0.031742, loss_fp: 0.001807, loss_freq: 0.063730
[04:35:16.461] iteration 12000: loss: 0.055997, loss_s1: 0.034678, loss_fp: 0.002152, loss_freq: 0.026447
[04:35:19.876] iteration 12000 : mean_dice : 0.726567
[04:35:20.536] iteration 12001: loss: 0.092625, loss_s1: 0.082257, loss_fp: 0.007393, loss_freq: 0.057737
[04:35:21.177] iteration 12002: loss: 0.076233, loss_s1: 0.061477, loss_fp: 0.001644, loss_freq: 0.016064
[04:35:21.809] iteration 12003: loss: 0.041131, loss_s1: 0.011200, loss_fp: 0.001325, loss_freq: 0.024141
[04:35:22.448] iteration 12004: loss: 0.070674, loss_s1: 0.043391, loss_fp: 0.001483, loss_freq: 0.029848
[04:35:23.090] iteration 12005: loss: 0.050283, loss_s1: 0.031524, loss_fp: 0.014319, loss_freq: 0.019215
[04:35:23.724] iteration 12006: loss: 0.076312, loss_s1: 0.074807, loss_fp: 0.005883, loss_freq: 0.026762
[04:35:24.366] iteration 12007: loss: 0.064349, loss_s1: 0.051536, loss_fp: 0.001693, loss_freq: 0.020059
[04:35:24.998] iteration 12008: loss: 0.050600, loss_s1: 0.034620, loss_fp: 0.001300, loss_freq: 0.024586
[04:35:25.647] iteration 12009: loss: 0.103174, loss_s1: 0.042350, loss_fp: 0.002548, loss_freq: 0.114667
[04:35:26.282] iteration 12010: loss: 0.055269, loss_s1: 0.029458, loss_fp: 0.001922, loss_freq: 0.035748
[04:35:26.907] iteration 12011: loss: 0.079364, loss_s1: 0.067486, loss_fp: 0.003685, loss_freq: 0.037374
[04:35:27.533] iteration 12012: loss: 0.056668, loss_s1: 0.026073, loss_fp: 0.004304, loss_freq: 0.027995
[04:35:28.161] iteration 12013: loss: 0.067740, loss_s1: 0.060678, loss_fp: 0.006504, loss_freq: 0.019920
[04:35:28.799] iteration 12014: loss: 0.046724, loss_s1: 0.031361, loss_fp: 0.006198, loss_freq: 0.022587
[04:35:29.455] iteration 12015: loss: 0.080709, loss_s1: 0.027537, loss_fp: 0.001732, loss_freq: 0.082046
[04:35:30.124] iteration 12016: loss: 0.063179, loss_s1: 0.042340, loss_fp: 0.001862, loss_freq: 0.038907
[04:35:30.777] iteration 12017: loss: 0.068449, loss_s1: 0.063251, loss_fp: 0.005364, loss_freq: 0.027088
[04:35:31.437] iteration 12018: loss: 0.050635, loss_s1: 0.044526, loss_fp: 0.004832, loss_freq: 0.010247
[04:35:32.081] iteration 12019: loss: 0.107858, loss_s1: 0.051661, loss_fp: 0.001705, loss_freq: 0.116060
[04:35:32.758] iteration 12020: loss: 0.052207, loss_s1: 0.039863, loss_fp: 0.001990, loss_freq: 0.014811
[04:35:33.436] iteration 12021: loss: 0.093311, loss_s1: 0.096145, loss_fp: 0.001594, loss_freq: 0.016995
[04:35:34.075] iteration 12022: loss: 0.066666, loss_s1: 0.052858, loss_fp: 0.001206, loss_freq: 0.034159
[04:35:34.725] iteration 12023: loss: 0.116311, loss_s1: 0.087513, loss_fp: 0.003071, loss_freq: 0.095185
[04:35:35.383] iteration 12024: loss: 0.063746, loss_s1: 0.070746, loss_fp: 0.001933, loss_freq: 0.021053
[04:35:36.003] iteration 12025: loss: 0.094003, loss_s1: 0.072808, loss_fp: 0.009472, loss_freq: 0.030537
[04:35:36.698] iteration 12026: loss: 0.068013, loss_s1: 0.032735, loss_fp: 0.007181, loss_freq: 0.042396
[04:35:37.394] iteration 12027: loss: 0.114660, loss_s1: 0.095009, loss_fp: 0.002233, loss_freq: 0.098543
[04:35:38.062] iteration 12028: loss: 0.125933, loss_s1: 0.113112, loss_fp: 0.001581, loss_freq: 0.063008
[04:35:38.689] iteration 12029: loss: 0.046663, loss_s1: 0.020194, loss_fp: 0.008717, loss_freq: 0.025742
[04:35:39.322] iteration 12030: loss: 0.054375, loss_s1: 0.043052, loss_fp: 0.002203, loss_freq: 0.020589
[04:35:40.012] iteration 12031: loss: 0.059198, loss_s1: 0.049765, loss_fp: 0.005035, loss_freq: 0.031327
[04:35:40.655] iteration 12032: loss: 0.094432, loss_s1: 0.043211, loss_fp: 0.004511, loss_freq: 0.026845
[04:35:41.304] iteration 12033: loss: 0.068623, loss_s1: 0.035027, loss_fp: 0.001350, loss_freq: 0.029959
[04:35:41.961] iteration 12034: loss: 0.083395, loss_s1: 0.084362, loss_fp: 0.006154, loss_freq: 0.035577
[04:35:42.587] iteration 12035: loss: 0.135667, loss_s1: 0.071295, loss_fp: 0.008178, loss_freq: 0.140514
[04:35:43.230] iteration 12036: loss: 0.055300, loss_s1: 0.044578, loss_fp: 0.002919, loss_freq: 0.009685
[04:35:43.870] iteration 12037: loss: 0.081365, loss_s1: 0.057697, loss_fp: 0.007230, loss_freq: 0.025979
[04:35:44.502] iteration 12038: loss: 0.058922, loss_s1: 0.040622, loss_fp: 0.004108, loss_freq: 0.034327
[04:35:45.152] iteration 12039: loss: 0.092871, loss_s1: 0.073257, loss_fp: 0.004732, loss_freq: 0.059792
[04:35:45.797] iteration 12040: loss: 0.101281, loss_s1: 0.110575, loss_fp: 0.001346, loss_freq: 0.062623
[04:35:46.439] iteration 12041: loss: 0.081498, loss_s1: 0.056042, loss_fp: 0.003791, loss_freq: 0.041173
[04:35:47.066] iteration 12042: loss: 0.074075, loss_s1: 0.034177, loss_fp: 0.002571, loss_freq: 0.064770
[04:35:47.701] iteration 12043: loss: 0.073181, loss_s1: 0.068494, loss_fp: 0.004407, loss_freq: 0.029793
[04:35:48.336] iteration 12044: loss: 0.088582, loss_s1: 0.052835, loss_fp: 0.003466, loss_freq: 0.051100
[04:35:48.973] iteration 12045: loss: 0.060011, loss_s1: 0.063883, loss_fp: 0.001242, loss_freq: 0.019648
[04:35:49.636] iteration 12046: loss: 0.076656, loss_s1: 0.097047, loss_fp: 0.002834, loss_freq: 0.013410
[04:35:50.262] iteration 12047: loss: 0.052021, loss_s1: 0.028097, loss_fp: 0.007729, loss_freq: 0.022282
[04:35:50.904] iteration 12048: loss: 0.093982, loss_s1: 0.083200, loss_fp: 0.005799, loss_freq: 0.047825
[04:35:51.533] iteration 12049: loss: 0.061896, loss_s1: 0.054492, loss_fp: 0.000991, loss_freq: 0.022634
[04:35:52.168] iteration 12050: loss: 0.080422, loss_s1: 0.053126, loss_fp: 0.010643, loss_freq: 0.042778
[04:35:52.791] iteration 12051: loss: 0.071897, loss_s1: 0.072227, loss_fp: 0.009941, loss_freq: 0.023333
[04:35:53.433] iteration 12052: loss: 0.094277, loss_s1: 0.078483, loss_fp: 0.002736, loss_freq: 0.056022
[04:35:54.056] iteration 12053: loss: 0.107262, loss_s1: 0.118714, loss_fp: 0.002492, loss_freq: 0.045232
[04:35:54.702] iteration 12054: loss: 0.089365, loss_s1: 0.047496, loss_fp: 0.020886, loss_freq: 0.047477
[04:35:55.337] iteration 12055: loss: 0.081068, loss_s1: 0.048229, loss_fp: 0.003302, loss_freq: 0.047110
[04:35:55.967] iteration 12056: loss: 0.039666, loss_s1: 0.014949, loss_fp: 0.001720, loss_freq: 0.009870
[04:35:56.597] iteration 12057: loss: 0.057568, loss_s1: 0.042699, loss_fp: 0.004798, loss_freq: 0.032743
[04:35:57.232] iteration 12058: loss: 0.109335, loss_s1: 0.112778, loss_fp: 0.010202, loss_freq: 0.049801
[04:35:57.870] iteration 12059: loss: 0.055456, loss_s1: 0.048426, loss_fp: 0.002893, loss_freq: 0.022588
[04:35:58.509] iteration 12060: loss: 0.080276, loss_s1: 0.061312, loss_fp: 0.007956, loss_freq: 0.029413
[04:35:59.143] iteration 12061: loss: 0.070683, loss_s1: 0.084664, loss_fp: 0.000445, loss_freq: 0.007294
[04:35:59.788] iteration 12062: loss: 0.068913, loss_s1: 0.071298, loss_fp: 0.002415, loss_freq: 0.018344
[04:36:00.420] iteration 12063: loss: 0.050467, loss_s1: 0.040441, loss_fp: 0.000640, loss_freq: 0.008503
[04:36:01.061] iteration 12064: loss: 0.072981, loss_s1: 0.075178, loss_fp: 0.003778, loss_freq: 0.019751
[04:36:01.689] iteration 12065: loss: 0.061548, loss_s1: 0.051739, loss_fp: 0.001566, loss_freq: 0.013967
[04:36:02.336] iteration 12066: loss: 0.106233, loss_s1: 0.115629, loss_fp: 0.007479, loss_freq: 0.040744
[04:36:02.972] iteration 12067: loss: 0.068404, loss_s1: 0.045835, loss_fp: 0.003740, loss_freq: 0.034997
[04:36:03.612] iteration 12068: loss: 0.081132, loss_s1: 0.063206, loss_fp: 0.004944, loss_freq: 0.032560
[04:36:04.254] iteration 12069: loss: 0.083755, loss_s1: 0.071441, loss_fp: 0.002309, loss_freq: 0.046855
[04:36:04.891] iteration 12070: loss: 0.088384, loss_s1: 0.082057, loss_fp: 0.005789, loss_freq: 0.037116
[04:36:05.856] iteration 12071: loss: 0.104200, loss_s1: 0.070601, loss_fp: 0.007761, loss_freq: 0.048410
[04:36:06.533] iteration 12072: loss: 0.076543, loss_s1: 0.050596, loss_fp: 0.001315, loss_freq: 0.044023
[04:36:07.209] iteration 12073: loss: 0.057041, loss_s1: 0.042617, loss_fp: 0.003893, loss_freq: 0.026930
[04:36:07.889] iteration 12074: loss: 0.075141, loss_s1: 0.078677, loss_fp: 0.002416, loss_freq: 0.015159
[04:36:08.571] iteration 12075: loss: 0.055964, loss_s1: 0.026159, loss_fp: 0.001445, loss_freq: 0.038941
[04:36:09.240] iteration 12076: loss: 0.058833, loss_s1: 0.049305, loss_fp: 0.003440, loss_freq: 0.020190
[04:36:09.896] iteration 12077: loss: 0.116609, loss_s1: 0.111864, loss_fp: 0.010574, loss_freq: 0.055901
[04:36:10.517] iteration 12078: loss: 0.082655, loss_s1: 0.069959, loss_fp: 0.004537, loss_freq: 0.021075
[04:36:11.148] iteration 12079: loss: 0.083018, loss_s1: 0.076170, loss_fp: 0.002071, loss_freq: 0.053562
[04:36:11.788] iteration 12080: loss: 0.076016, loss_s1: 0.072786, loss_fp: 0.002431, loss_freq: 0.026071
[04:36:12.425] iteration 12081: loss: 0.087654, loss_s1: 0.066566, loss_fp: 0.001195, loss_freq: 0.066119
[04:36:13.068] iteration 12082: loss: 0.113796, loss_s1: 0.101172, loss_fp: 0.006618, loss_freq: 0.073086
[04:36:13.716] iteration 12083: loss: 0.091465, loss_s1: 0.065840, loss_fp: 0.002564, loss_freq: 0.065922
[04:36:14.360] iteration 12084: loss: 0.069007, loss_s1: 0.045792, loss_fp: 0.006650, loss_freq: 0.021481
[04:36:15.015] iteration 12085: loss: 0.051726, loss_s1: 0.030459, loss_fp: 0.000832, loss_freq: 0.019454
[04:36:15.649] iteration 12086: loss: 0.075525, loss_s1: 0.065007, loss_fp: 0.002269, loss_freq: 0.032144
[04:36:16.279] iteration 12087: loss: 0.102240, loss_s1: 0.092077, loss_fp: 0.003526, loss_freq: 0.069074
[04:36:16.910] iteration 12088: loss: 0.098818, loss_s1: 0.046789, loss_fp: 0.001489, loss_freq: 0.011629
[04:36:17.551] iteration 12089: loss: 0.098961, loss_s1: 0.073949, loss_fp: 0.006427, loss_freq: 0.048224
[04:36:18.179] iteration 12090: loss: 0.076037, loss_s1: 0.064955, loss_fp: 0.000997, loss_freq: 0.011438
[04:36:18.814] iteration 12091: loss: 0.077497, loss_s1: 0.068961, loss_fp: 0.009826, loss_freq: 0.019919
[04:36:19.490] iteration 12092: loss: 0.070219, loss_s1: 0.068092, loss_fp: 0.002170, loss_freq: 0.040370
[04:36:20.119] iteration 12093: loss: 0.107440, loss_s1: 0.075713, loss_fp: 0.001543, loss_freq: 0.023053
[04:36:20.750] iteration 12094: loss: 0.081635, loss_s1: 0.085376, loss_fp: 0.001532, loss_freq: 0.023143
[04:36:21.372] iteration 12095: loss: 0.114006, loss_s1: 0.049614, loss_fp: 0.008991, loss_freq: 0.043549
[04:36:22.017] iteration 12096: loss: 0.091461, loss_s1: 0.091045, loss_fp: 0.002027, loss_freq: 0.047591
[04:36:22.649] iteration 12097: loss: 0.089873, loss_s1: 0.048737, loss_fp: 0.005372, loss_freq: 0.044033
[04:36:23.289] iteration 12098: loss: 0.089166, loss_s1: 0.076884, loss_fp: 0.003012, loss_freq: 0.033305
[04:36:23.921] iteration 12099: loss: 0.102196, loss_s1: 0.046302, loss_fp: 0.004239, loss_freq: 0.081284
[04:36:24.545] iteration 12100: loss: 0.107435, loss_s1: 0.125340, loss_fp: 0.003540, loss_freq: 0.044067
[04:36:25.182] iteration 12101: loss: 0.067083, loss_s1: 0.043200, loss_fp: 0.001326, loss_freq: 0.030114
[04:36:25.810] iteration 12102: loss: 0.111578, loss_s1: 0.099175, loss_fp: 0.003044, loss_freq: 0.057404
[04:36:26.438] iteration 12103: loss: 0.079121, loss_s1: 0.064834, loss_fp: 0.003524, loss_freq: 0.044035
[04:36:27.079] iteration 12104: loss: 0.068166, loss_s1: 0.068319, loss_fp: 0.004179, loss_freq: 0.008069
[04:36:27.717] iteration 12105: loss: 0.065381, loss_s1: 0.059827, loss_fp: 0.004412, loss_freq: 0.029647
[04:36:28.351] iteration 12106: loss: 0.084073, loss_s1: 0.079345, loss_fp: 0.002584, loss_freq: 0.031902
[04:36:28.992] iteration 12107: loss: 0.061804, loss_s1: 0.029377, loss_fp: 0.007891, loss_freq: 0.035894
[04:36:29.620] iteration 12108: loss: 0.059750, loss_s1: 0.032117, loss_fp: 0.009649, loss_freq: 0.030943
[04:36:30.326] iteration 12109: loss: 0.074218, loss_s1: 0.057611, loss_fp: 0.004433, loss_freq: 0.023529
[04:36:30.998] iteration 12110: loss: 0.062263, loss_s1: 0.037674, loss_fp: 0.001851, loss_freq: 0.043095
[04:36:31.683] iteration 12111: loss: 0.110382, loss_s1: 0.114759, loss_fp: 0.001285, loss_freq: 0.045659
[04:36:32.365] iteration 12112: loss: 0.074649, loss_s1: 0.059643, loss_fp: 0.018329, loss_freq: 0.026963
[04:36:33.004] iteration 12113: loss: 0.123955, loss_s1: 0.139120, loss_fp: 0.005646, loss_freq: 0.054031
[04:36:33.647] iteration 12114: loss: 0.110493, loss_s1: 0.079373, loss_fp: 0.002494, loss_freq: 0.083187
[04:36:34.542] iteration 12115: loss: 0.047660, loss_s1: 0.028162, loss_fp: 0.003773, loss_freq: 0.021675
[04:36:35.437] iteration 12116: loss: 0.102612, loss_s1: 0.106951, loss_fp: 0.009916, loss_freq: 0.037039
[04:36:36.139] iteration 12117: loss: 0.058199, loss_s1: 0.047451, loss_fp: 0.002425, loss_freq: 0.020587
[04:36:36.764] iteration 12118: loss: 0.060448, loss_s1: 0.024974, loss_fp: 0.006148, loss_freq: 0.042528
[04:36:37.393] iteration 12119: loss: 0.070254, loss_s1: 0.064658, loss_fp: 0.004463, loss_freq: 0.021511
[04:36:38.018] iteration 12120: loss: 0.060145, loss_s1: 0.051832, loss_fp: 0.002833, loss_freq: 0.013565
[04:36:38.642] iteration 12121: loss: 0.083626, loss_s1: 0.046600, loss_fp: 0.008578, loss_freq: 0.059962
[04:36:39.269] iteration 12122: loss: 0.072980, loss_s1: 0.088379, loss_fp: 0.003392, loss_freq: 0.020710
[04:36:39.945] iteration 12123: loss: 0.058784, loss_s1: 0.016250, loss_fp: 0.002672, loss_freq: 0.027654
[04:36:40.578] iteration 12124: loss: 0.096868, loss_s1: 0.095271, loss_fp: 0.003457, loss_freq: 0.030771
[04:36:41.194] iteration 12125: loss: 0.070695, loss_s1: 0.041056, loss_fp: 0.001738, loss_freq: 0.041858
[04:36:41.866] iteration 12126: loss: 0.067529, loss_s1: 0.052461, loss_fp: 0.008075, loss_freq: 0.022011
[04:36:42.492] iteration 12127: loss: 0.079223, loss_s1: 0.062599, loss_fp: 0.001203, loss_freq: 0.060833
[04:36:43.107] iteration 12128: loss: 0.065304, loss_s1: 0.048459, loss_fp: 0.002725, loss_freq: 0.026685
[04:36:43.808] iteration 12129: loss: 0.088375, loss_s1: 0.086888, loss_fp: 0.007798, loss_freq: 0.035417
[04:36:44.488] iteration 12130: loss: 0.075648, loss_s1: 0.046371, loss_fp: 0.002379, loss_freq: 0.044581
[04:36:45.163] iteration 12131: loss: 0.026888, loss_s1: 0.016208, loss_fp: 0.001234, loss_freq: 0.004926
[04:36:45.789] iteration 12132: loss: 0.074074, loss_s1: 0.040368, loss_fp: 0.005831, loss_freq: 0.056648
[04:36:46.491] iteration 12133: loss: 0.041010, loss_s1: 0.022211, loss_fp: 0.003080, loss_freq: 0.004203
[04:36:47.186] iteration 12134: loss: 0.084924, loss_s1: 0.068923, loss_fp: 0.001596, loss_freq: 0.032651
[04:36:47.843] iteration 12135: loss: 0.064581, loss_s1: 0.044152, loss_fp: 0.003017, loss_freq: 0.013450
[04:36:48.548] iteration 12136: loss: 0.068715, loss_s1: 0.053243, loss_fp: 0.003296, loss_freq: 0.015938
[04:36:49.223] iteration 12137: loss: 0.074716, loss_s1: 0.026023, loss_fp: 0.001957, loss_freq: 0.018687
[04:36:49.902] iteration 12138: loss: 0.138648, loss_s1: 0.113889, loss_fp: 0.013422, loss_freq: 0.093023
[04:36:50.577] iteration 12139: loss: 0.065648, loss_s1: 0.042968, loss_fp: 0.001741, loss_freq: 0.038734
[04:36:51.291] iteration 12140: loss: 0.064453, loss_s1: 0.062491, loss_fp: 0.012118, loss_freq: 0.021995
[04:36:51.975] iteration 12141: loss: 0.071969, loss_s1: 0.040092, loss_fp: 0.002438, loss_freq: 0.028535
[04:36:52.651] iteration 12142: loss: 0.074036, loss_s1: 0.078846, loss_fp: 0.004106, loss_freq: 0.012460
[04:36:53.294] iteration 12143: loss: 0.058855, loss_s1: 0.041534, loss_fp: 0.004019, loss_freq: 0.038392
[04:36:53.938] iteration 12144: loss: 0.111267, loss_s1: 0.127175, loss_fp: 0.008132, loss_freq: 0.049159
[04:36:54.574] iteration 12145: loss: 0.082198, loss_s1: 0.069569, loss_fp: 0.004603, loss_freq: 0.041940
[04:36:55.223] iteration 12146: loss: 0.059403, loss_s1: 0.037844, loss_fp: 0.005350, loss_freq: 0.027324
[04:36:55.848] iteration 12147: loss: 0.069731, loss_s1: 0.057708, loss_fp: 0.006583, loss_freq: 0.030900
[04:36:56.470] iteration 12148: loss: 0.097921, loss_s1: 0.080927, loss_fp: 0.007610, loss_freq: 0.051923
[04:36:57.116] iteration 12149: loss: 0.090144, loss_s1: 0.067543, loss_fp: 0.005655, loss_freq: 0.048293
[04:36:57.741] iteration 12150: loss: 0.083717, loss_s1: 0.058536, loss_fp: 0.003800, loss_freq: 0.054829
[04:36:58.370] iteration 12151: loss: 0.091676, loss_s1: 0.106987, loss_fp: 0.004849, loss_freq: 0.028549
[04:36:59.016] iteration 12152: loss: 0.049602, loss_s1: 0.033026, loss_fp: 0.004983, loss_freq: 0.018932
[04:36:59.642] iteration 12153: loss: 0.060995, loss_s1: 0.043099, loss_fp: 0.001846, loss_freq: 0.024576
[04:37:00.292] iteration 12154: loss: 0.044772, loss_s1: 0.033603, loss_fp: 0.001969, loss_freq: 0.019411
[04:37:00.969] iteration 12155: loss: 0.091378, loss_s1: 0.069953, loss_fp: 0.004535, loss_freq: 0.021825
[04:37:01.616] iteration 12156: loss: 0.054574, loss_s1: 0.033810, loss_fp: 0.000912, loss_freq: 0.021494
[04:37:02.258] iteration 12157: loss: 0.115674, loss_s1: 0.161336, loss_fp: 0.003651, loss_freq: 0.036919
[04:37:02.922] iteration 12158: loss: 0.062232, loss_s1: 0.050230, loss_fp: 0.001879, loss_freq: 0.005892
[04:37:03.556] iteration 12159: loss: 0.066736, loss_s1: 0.070326, loss_fp: 0.002015, loss_freq: 0.020147
[04:37:04.205] iteration 12160: loss: 0.050757, loss_s1: 0.029152, loss_fp: 0.000735, loss_freq: 0.013449
[04:37:04.849] iteration 12161: loss: 0.048800, loss_s1: 0.034197, loss_fp: 0.003462, loss_freq: 0.012797
[04:37:05.493] iteration 12162: loss: 0.077494, loss_s1: 0.075794, loss_fp: 0.002714, loss_freq: 0.040950
[04:37:06.132] iteration 12163: loss: 0.123350, loss_s1: 0.125392, loss_fp: 0.001331, loss_freq: 0.022060
[04:37:06.798] iteration 12164: loss: 0.057674, loss_s1: 0.058386, loss_fp: 0.002513, loss_freq: 0.011077
[04:37:07.433] iteration 12165: loss: 0.101192, loss_s1: 0.093217, loss_fp: 0.000628, loss_freq: 0.062704
[04:37:08.063] iteration 12166: loss: 0.080338, loss_s1: 0.080809, loss_fp: 0.002487, loss_freq: 0.045435
[04:37:08.709] iteration 12167: loss: 0.105411, loss_s1: 0.099221, loss_fp: 0.001462, loss_freq: 0.052756
[04:37:09.357] iteration 12168: loss: 0.054043, loss_s1: 0.036744, loss_fp: 0.001349, loss_freq: 0.025533
[04:37:10.012] iteration 12169: loss: 0.063615, loss_s1: 0.077891, loss_fp: 0.001540, loss_freq: 0.016624
[04:37:10.708] iteration 12170: loss: 0.068843, loss_s1: 0.063089, loss_fp: 0.002215, loss_freq: 0.025650
[04:37:11.392] iteration 12171: loss: 0.069679, loss_s1: 0.060053, loss_fp: 0.003000, loss_freq: 0.026447
[04:37:12.068] iteration 12172: loss: 0.053514, loss_s1: 0.031142, loss_fp: 0.001685, loss_freq: 0.012488
[04:37:12.751] iteration 12173: loss: 0.051201, loss_s1: 0.038424, loss_fp: 0.001739, loss_freq: 0.017635
[04:37:13.424] iteration 12174: loss: 0.041782, loss_s1: 0.016341, loss_fp: 0.001226, loss_freq: 0.025878
[04:37:14.095] iteration 12175: loss: 0.064801, loss_s1: 0.050807, loss_fp: 0.002802, loss_freq: 0.041697
[04:37:14.745] iteration 12176: loss: 0.075858, loss_s1: 0.063505, loss_fp: 0.001266, loss_freq: 0.045380
[04:37:15.380] iteration 12177: loss: 0.059609, loss_s1: 0.027599, loss_fp: 0.005141, loss_freq: 0.041645
[04:37:16.002] iteration 12178: loss: 0.059722, loss_s1: 0.061158, loss_fp: 0.002104, loss_freq: 0.019178
[04:37:16.644] iteration 12179: loss: 0.077824, loss_s1: 0.044987, loss_fp: 0.001887, loss_freq: 0.062856
[04:37:17.280] iteration 12180: loss: 0.047192, loss_s1: 0.036521, loss_fp: 0.001909, loss_freq: 0.011701
[04:37:17.909] iteration 12181: loss: 0.078994, loss_s1: 0.059869, loss_fp: 0.001490, loss_freq: 0.022320
[04:37:18.561] iteration 12182: loss: 0.062821, loss_s1: 0.032115, loss_fp: 0.001951, loss_freq: 0.050623
[04:37:19.191] iteration 12183: loss: 0.070876, loss_s1: 0.066350, loss_fp: 0.002763, loss_freq: 0.032767
[04:37:19.829] iteration 12184: loss: 0.051028, loss_s1: 0.031565, loss_fp: 0.002849, loss_freq: 0.022587
[04:37:20.464] iteration 12185: loss: 0.118842, loss_s1: 0.106468, loss_fp: 0.009393, loss_freq: 0.060297
[04:37:21.115] iteration 12186: loss: 0.080330, loss_s1: 0.035962, loss_fp: 0.003561, loss_freq: 0.063475
[04:37:21.759] iteration 12187: loss: 0.063379, loss_s1: 0.045734, loss_fp: 0.005838, loss_freq: 0.036329
[04:37:22.388] iteration 12188: loss: 0.058602, loss_s1: 0.055632, loss_fp: 0.002029, loss_freq: 0.020831
[04:37:23.025] iteration 12189: loss: 0.098785, loss_s1: 0.048808, loss_fp: 0.007123, loss_freq: 0.091375
[04:37:23.649] iteration 12190: loss: 0.070052, loss_s1: 0.040009, loss_fp: 0.000460, loss_freq: 0.045500
[04:37:24.299] iteration 12191: loss: 0.064535, loss_s1: 0.053210, loss_fp: 0.001584, loss_freq: 0.019193
[04:37:24.932] iteration 12192: loss: 0.054192, loss_s1: 0.044086, loss_fp: 0.003638, loss_freq: 0.036400
[04:37:25.558] iteration 12193: loss: 0.100388, loss_s1: 0.097715, loss_fp: 0.002686, loss_freq: 0.047372
[04:37:26.194] iteration 12194: loss: 0.052580, loss_s1: 0.033035, loss_fp: 0.003168, loss_freq: 0.034611
[04:37:26.838] iteration 12195: loss: 0.094595, loss_s1: 0.065077, loss_fp: 0.005390, loss_freq: 0.064478
[04:37:27.469] iteration 12196: loss: 0.052609, loss_s1: 0.023068, loss_fp: 0.004722, loss_freq: 0.035893
[04:37:28.096] iteration 12197: loss: 0.094343, loss_s1: 0.064970, loss_fp: 0.002820, loss_freq: 0.085730
[04:37:28.728] iteration 12198: loss: 0.083207, loss_s1: 0.028741, loss_fp: 0.002231, loss_freq: 0.083301
[04:37:29.356] iteration 12199: loss: 0.044188, loss_s1: 0.030202, loss_fp: 0.003099, loss_freq: 0.018864
[04:37:29.998] iteration 12200: loss: 0.097645, loss_s1: 0.077549, loss_fp: 0.016605, loss_freq: 0.056309
[04:37:33.338] iteration 12200 : mean_dice : 0.709332
[04:37:33.990] iteration 12201: loss: 0.075408, loss_s1: 0.090905, loss_fp: 0.001314, loss_freq: 0.026412
[04:37:34.631] iteration 12202: loss: 0.083054, loss_s1: 0.070611, loss_fp: 0.009957, loss_freq: 0.013144
[04:37:35.251] iteration 12203: loss: 0.149705, loss_s1: 0.147532, loss_fp: 0.003209, loss_freq: 0.079819
[04:37:35.890] iteration 12204: loss: 0.066400, loss_s1: 0.057559, loss_fp: 0.001201, loss_freq: 0.030776
[04:37:36.517] iteration 12205: loss: 0.085318, loss_s1: 0.087663, loss_fp: 0.007488, loss_freq: 0.028527
[04:37:37.149] iteration 12206: loss: 0.074176, loss_s1: 0.057890, loss_fp: 0.005537, loss_freq: 0.033083
[04:37:37.780] iteration 12207: loss: 0.081640, loss_s1: 0.059223, loss_fp: 0.001885, loss_freq: 0.022726
[04:37:38.422] iteration 12208: loss: 0.085857, loss_s1: 0.041585, loss_fp: 0.001859, loss_freq: 0.093471
[04:37:39.174] iteration 12209: loss: 0.091687, loss_s1: 0.087978, loss_fp: 0.006408, loss_freq: 0.041734
[04:37:39.906] iteration 12210: loss: 0.090923, loss_s1: 0.103971, loss_fp: 0.003683, loss_freq: 0.037243
[04:37:40.617] iteration 12211: loss: 0.087777, loss_s1: 0.067148, loss_fp: 0.001985, loss_freq: 0.033051
[04:37:41.386] iteration 12212: loss: 0.068984, loss_s1: 0.048382, loss_fp: 0.006089, loss_freq: 0.025753
[04:37:42.048] iteration 12213: loss: 0.079537, loss_s1: 0.037545, loss_fp: 0.001268, loss_freq: 0.059084
[04:37:42.822] iteration 12214: loss: 0.062051, loss_s1: 0.043281, loss_fp: 0.002109, loss_freq: 0.026672
[04:37:43.568] iteration 12215: loss: 0.064059, loss_s1: 0.049742, loss_fp: 0.015743, loss_freq: 0.014092
[04:37:44.279] iteration 12216: loss: 0.054517, loss_s1: 0.040187, loss_fp: 0.000671, loss_freq: 0.028727
[04:37:45.033] iteration 12217: loss: 0.059447, loss_s1: 0.026157, loss_fp: 0.002413, loss_freq: 0.029640
[04:37:45.705] iteration 12218: loss: 0.104577, loss_s1: 0.115286, loss_fp: 0.002775, loss_freq: 0.037110
[04:37:46.452] iteration 12219: loss: 0.074954, loss_s1: 0.052713, loss_fp: 0.002952, loss_freq: 0.045493
[04:37:47.116] iteration 12220: loss: 0.061775, loss_s1: 0.054701, loss_fp: 0.003460, loss_freq: 0.017053
[04:37:47.796] iteration 12221: loss: 0.072023, loss_s1: 0.063562, loss_fp: 0.011242, loss_freq: 0.015663
[04:37:48.657] iteration 12222: loss: 0.062694, loss_s1: 0.043456, loss_fp: 0.009530, loss_freq: 0.034771
[04:37:49.388] iteration 12223: loss: 0.076762, loss_s1: 0.030901, loss_fp: 0.004453, loss_freq: 0.055979
[04:37:50.230] iteration 12224: loss: 0.075940, loss_s1: 0.064491, loss_fp: 0.010211, loss_freq: 0.022138
[04:37:50.875] iteration 12225: loss: 0.089653, loss_s1: 0.073891, loss_fp: 0.002179, loss_freq: 0.048359
[04:37:51.570] iteration 12226: loss: 0.055219, loss_s1: 0.045423, loss_fp: 0.001429, loss_freq: 0.020100
[04:37:52.273] iteration 12227: loss: 0.034113, loss_s1: 0.012771, loss_fp: 0.002576, loss_freq: 0.022757
[04:37:52.933] iteration 12228: loss: 0.090735, loss_s1: 0.055921, loss_fp: 0.003553, loss_freq: 0.068329
[04:37:53.572] iteration 12229: loss: 0.075444, loss_s1: 0.060425, loss_fp: 0.009058, loss_freq: 0.039009
[04:37:54.214] iteration 12230: loss: 0.096047, loss_s1: 0.103698, loss_fp: 0.010105, loss_freq: 0.026057
[04:37:54.835] iteration 12231: loss: 0.035234, loss_s1: 0.015226, loss_fp: 0.001570, loss_freq: 0.008108
[04:37:55.508] iteration 12232: loss: 0.047613, loss_s1: 0.038527, loss_fp: 0.002056, loss_freq: 0.018075
[04:37:56.131] iteration 12233: loss: 0.046128, loss_s1: 0.021213, loss_fp: 0.001353, loss_freq: 0.016490
[04:37:56.760] iteration 12234: loss: 0.061280, loss_s1: 0.063408, loss_fp: 0.002536, loss_freq: 0.023958
[04:37:57.390] iteration 12235: loss: 0.035930, loss_s1: 0.021166, loss_fp: 0.003268, loss_freq: 0.013247
[04:37:58.019] iteration 12236: loss: 0.088690, loss_s1: 0.071112, loss_fp: 0.003755, loss_freq: 0.062253
[04:37:58.644] iteration 12237: loss: 0.104048, loss_s1: 0.094374, loss_fp: 0.003320, loss_freq: 0.060742
[04:37:59.293] iteration 12238: loss: 0.114695, loss_s1: 0.121866, loss_fp: 0.008207, loss_freq: 0.060201
[04:37:59.915] iteration 12239: loss: 0.076668, loss_s1: 0.048992, loss_fp: 0.006112, loss_freq: 0.060712
[04:38:00.535] iteration 12240: loss: 0.105187, loss_s1: 0.109272, loss_fp: 0.003802, loss_freq: 0.052659
[04:38:01.542] iteration 12241: loss: 0.087263, loss_s1: 0.070904, loss_fp: 0.007869, loss_freq: 0.028347
[04:38:02.185] iteration 12242: loss: 0.091006, loss_s1: 0.062416, loss_fp: 0.001623, loss_freq: 0.058839
[04:38:02.814] iteration 12243: loss: 0.053592, loss_s1: 0.029066, loss_fp: 0.005142, loss_freq: 0.033989
[04:38:03.459] iteration 12244: loss: 0.063019, loss_s1: 0.057399, loss_fp: 0.003508, loss_freq: 0.020053
[04:38:04.118] iteration 12245: loss: 0.071936, loss_s1: 0.056115, loss_fp: 0.004465, loss_freq: 0.027384
[04:38:04.747] iteration 12246: loss: 0.107252, loss_s1: 0.120472, loss_fp: 0.004176, loss_freq: 0.046590
[04:38:05.388] iteration 12247: loss: 0.097991, loss_s1: 0.069045, loss_fp: 0.001229, loss_freq: 0.045827
[04:38:06.032] iteration 12248: loss: 0.064866, loss_s1: 0.067726, loss_fp: 0.002165, loss_freq: 0.019607
[04:38:06.735] iteration 12249: loss: 0.072356, loss_s1: 0.044465, loss_fp: 0.005005, loss_freq: 0.052862
[04:38:07.606] iteration 12250: loss: 0.073540, loss_s1: 0.051638, loss_fp: 0.004784, loss_freq: 0.033030
[04:38:08.414] iteration 12251: loss: 0.073440, loss_s1: 0.043845, loss_fp: 0.000828, loss_freq: 0.061058
[04:38:09.089] iteration 12252: loss: 0.087045, loss_s1: 0.044077, loss_fp: 0.002047, loss_freq: 0.087769
[04:38:09.779] iteration 12253: loss: 0.064637, loss_s1: 0.056222, loss_fp: 0.005604, loss_freq: 0.024291
[04:38:10.409] iteration 12254: loss: 0.050421, loss_s1: 0.036200, loss_fp: 0.000884, loss_freq: 0.025934
[04:38:11.041] iteration 12255: loss: 0.059040, loss_s1: 0.051422, loss_fp: 0.004046, loss_freq: 0.016895
[04:38:11.709] iteration 12256: loss: 0.076384, loss_s1: 0.034071, loss_fp: 0.011844, loss_freq: 0.034366
[04:38:12.399] iteration 12257: loss: 0.115567, loss_s1: 0.095358, loss_fp: 0.005641, loss_freq: 0.095978
[04:38:13.071] iteration 12258: loss: 0.042039, loss_s1: 0.024600, loss_fp: 0.002218, loss_freq: 0.011013
[04:38:13.703] iteration 12259: loss: 0.079299, loss_s1: 0.042785, loss_fp: 0.012411, loss_freq: 0.061743
[04:38:14.381] iteration 12260: loss: 0.082895, loss_s1: 0.063863, loss_fp: 0.003899, loss_freq: 0.025768
[04:38:15.065] iteration 12261: loss: 0.056182, loss_s1: 0.035119, loss_fp: 0.004073, loss_freq: 0.029097
[04:38:15.744] iteration 12262: loss: 0.073381, loss_s1: 0.060054, loss_fp: 0.002269, loss_freq: 0.046526
[04:38:16.398] iteration 12263: loss: 0.058405, loss_s1: 0.023055, loss_fp: 0.001672, loss_freq: 0.035044
[04:38:17.065] iteration 12264: loss: 0.054802, loss_s1: 0.046375, loss_fp: 0.001303, loss_freq: 0.020398
[04:38:17.703] iteration 12265: loss: 0.077107, loss_s1: 0.087314, loss_fp: 0.004078, loss_freq: 0.030646
[04:38:18.330] iteration 12266: loss: 0.096740, loss_s1: 0.091408, loss_fp: 0.001571, loss_freq: 0.060486
[04:38:18.992] iteration 12267: loss: 0.084960, loss_s1: 0.083305, loss_fp: 0.003252, loss_freq: 0.033083
[04:38:19.620] iteration 12268: loss: 0.081822, loss_s1: 0.087554, loss_fp: 0.007116, loss_freq: 0.011512
[04:38:20.254] iteration 12269: loss: 0.076738, loss_s1: 0.067520, loss_fp: 0.003286, loss_freq: 0.032205
[04:38:20.887] iteration 12270: loss: 0.087221, loss_s1: 0.084173, loss_fp: 0.003934, loss_freq: 0.044053
[04:38:21.516] iteration 12271: loss: 0.071146, loss_s1: 0.045067, loss_fp: 0.002064, loss_freq: 0.057824
[04:38:22.157] iteration 12272: loss: 0.125795, loss_s1: 0.092850, loss_fp: 0.003453, loss_freq: 0.074916
[04:38:22.806] iteration 12273: loss: 0.080372, loss_s1: 0.054449, loss_fp: 0.003480, loss_freq: 0.060269
[04:38:23.445] iteration 12274: loss: 0.066518, loss_s1: 0.069730, loss_fp: 0.002480, loss_freq: 0.011020
[04:38:24.089] iteration 12275: loss: 0.060611, loss_s1: 0.037722, loss_fp: 0.002501, loss_freq: 0.052296
[04:38:24.715] iteration 12276: loss: 0.065699, loss_s1: 0.046479, loss_fp: 0.001551, loss_freq: 0.021487
[04:38:25.343] iteration 12277: loss: 0.070687, loss_s1: 0.052334, loss_fp: 0.001083, loss_freq: 0.037542
[04:38:25.971] iteration 12278: loss: 0.085889, loss_s1: 0.084638, loss_fp: 0.005839, loss_freq: 0.042429
[04:38:26.610] iteration 12279: loss: 0.100655, loss_s1: 0.114174, loss_fp: 0.001564, loss_freq: 0.043372
[04:38:27.241] iteration 12280: loss: 0.087223, loss_s1: 0.041786, loss_fp: 0.007758, loss_freq: 0.060119
[04:38:27.868] iteration 12281: loss: 0.091411, loss_s1: 0.080111, loss_fp: 0.001392, loss_freq: 0.038086
[04:38:28.504] iteration 12282: loss: 0.062942, loss_s1: 0.066076, loss_fp: 0.002504, loss_freq: 0.012039
[04:38:29.136] iteration 12283: loss: 0.107842, loss_s1: 0.126069, loss_fp: 0.001459, loss_freq: 0.052648
[04:38:29.762] iteration 12284: loss: 0.110261, loss_s1: 0.103030, loss_fp: 0.006300, loss_freq: 0.078111
[04:38:30.390] iteration 12285: loss: 0.074521, loss_s1: 0.053529, loss_fp: 0.001192, loss_freq: 0.041970
[04:38:31.072] iteration 12286: loss: 0.086247, loss_s1: 0.058760, loss_fp: 0.004279, loss_freq: 0.070761
[04:38:31.703] iteration 12287: loss: 0.050717, loss_s1: 0.014527, loss_fp: 0.004965, loss_freq: 0.043300
[04:38:32.335] iteration 12288: loss: 0.064480, loss_s1: 0.038405, loss_fp: 0.005156, loss_freq: 0.049628
[04:38:32.994] iteration 12289: loss: 0.051033, loss_s1: 0.055397, loss_fp: 0.001364, loss_freq: 0.009377
[04:38:33.623] iteration 12290: loss: 0.044530, loss_s1: 0.021024, loss_fp: 0.003187, loss_freq: 0.010642
[04:38:34.249] iteration 12291: loss: 0.075376, loss_s1: 0.061595, loss_fp: 0.003141, loss_freq: 0.031694
[04:38:34.875] iteration 12292: loss: 0.080316, loss_s1: 0.077957, loss_fp: 0.001858, loss_freq: 0.052831
[04:38:35.512] iteration 12293: loss: 0.076941, loss_s1: 0.009894, loss_fp: 0.002447, loss_freq: 0.025505
[04:38:36.138] iteration 12294: loss: 0.074767, loss_s1: 0.045461, loss_fp: 0.004326, loss_freq: 0.026538
[04:38:36.762] iteration 12295: loss: 0.077758, loss_s1: 0.042682, loss_fp: 0.002721, loss_freq: 0.055966
[04:38:37.414] iteration 12296: loss: 0.064642, loss_s1: 0.027158, loss_fp: 0.002874, loss_freq: 0.022269
[04:38:38.138] iteration 12297: loss: 0.080533, loss_s1: 0.078079, loss_fp: 0.002035, loss_freq: 0.038789
[04:38:38.781] iteration 12298: loss: 0.076254, loss_s1: 0.057558, loss_fp: 0.001462, loss_freq: 0.015845
[04:38:39.440] iteration 12299: loss: 0.064194, loss_s1: 0.037590, loss_fp: 0.001226, loss_freq: 0.017715
[04:38:40.115] iteration 12300: loss: 0.071876, loss_s1: 0.036797, loss_fp: 0.010558, loss_freq: 0.045164
[04:38:40.746] iteration 12301: loss: 0.062570, loss_s1: 0.077880, loss_fp: 0.002380, loss_freq: 0.010920
[04:38:41.377] iteration 12302: loss: 0.059775, loss_s1: 0.035840, loss_fp: 0.001341, loss_freq: 0.031420
[04:38:42.007] iteration 12303: loss: 0.040941, loss_s1: 0.020092, loss_fp: 0.001935, loss_freq: 0.016324
[04:38:42.635] iteration 12304: loss: 0.063805, loss_s1: 0.042777, loss_fp: 0.003993, loss_freq: 0.031751
[04:38:43.266] iteration 12305: loss: 0.085773, loss_s1: 0.083519, loss_fp: 0.004094, loss_freq: 0.026780
[04:38:43.899] iteration 12306: loss: 0.085883, loss_s1: 0.086042, loss_fp: 0.005560, loss_freq: 0.040777
[04:38:44.576] iteration 12307: loss: 0.051170, loss_s1: 0.028434, loss_fp: 0.000885, loss_freq: 0.021867
[04:38:45.203] iteration 12308: loss: 0.188647, loss_s1: 0.199709, loss_fp: 0.005910, loss_freq: 0.101595
[04:38:45.827] iteration 12309: loss: 0.051281, loss_s1: 0.040902, loss_fp: 0.007546, loss_freq: 0.009229
[04:38:46.463] iteration 12310: loss: 0.072061, loss_s1: 0.064398, loss_fp: 0.012029, loss_freq: 0.019849
[04:38:47.098] iteration 12311: loss: 0.090330, loss_s1: 0.042126, loss_fp: 0.014966, loss_freq: 0.057281
[04:38:47.745] iteration 12312: loss: 0.059480, loss_s1: 0.010852, loss_fp: 0.007469, loss_freq: 0.058804
[04:38:48.384] iteration 12313: loss: 0.064819, loss_s1: 0.051985, loss_fp: 0.009828, loss_freq: 0.031849
[04:38:49.073] iteration 12314: loss: 0.082938, loss_s1: 0.069998, loss_fp: 0.008774, loss_freq: 0.040067
[04:38:49.740] iteration 12315: loss: 0.058442, loss_s1: 0.016302, loss_fp: 0.002713, loss_freq: 0.047207
[04:38:50.420] iteration 12316: loss: 0.082910, loss_s1: 0.050416, loss_fp: 0.004978, loss_freq: 0.044201
[04:38:51.093] iteration 12317: loss: 0.046994, loss_s1: 0.028049, loss_fp: 0.002214, loss_freq: 0.018068
[04:38:51.760] iteration 12318: loss: 0.080509, loss_s1: 0.057220, loss_fp: 0.005240, loss_freq: 0.044365
[04:38:52.444] iteration 12319: loss: 0.081217, loss_s1: 0.084526, loss_fp: 0.002003, loss_freq: 0.049369
[04:38:53.066] iteration 12320: loss: 0.076760, loss_s1: 0.045304, loss_fp: 0.008350, loss_freq: 0.048576
[04:38:53.689] iteration 12321: loss: 0.071767, loss_s1: 0.035621, loss_fp: 0.001195, loss_freq: 0.041634
[04:38:54.312] iteration 12322: loss: 0.053125, loss_s1: 0.038406, loss_fp: 0.003102, loss_freq: 0.023551
[04:38:54.928] iteration 12323: loss: 0.081250, loss_s1: 0.081362, loss_fp: 0.000850, loss_freq: 0.031987
[04:38:55.559] iteration 12324: loss: 0.070459, loss_s1: 0.074956, loss_fp: 0.005122, loss_freq: 0.014246
[04:38:56.186] iteration 12325: loss: 0.050889, loss_s1: 0.040678, loss_fp: 0.000797, loss_freq: 0.015059
[04:38:56.836] iteration 12326: loss: 0.048133, loss_s1: 0.028829, loss_fp: 0.001200, loss_freq: 0.024105
[04:38:57.473] iteration 12327: loss: 0.062266, loss_s1: 0.051955, loss_fp: 0.007553, loss_freq: 0.025921
[04:38:58.097] iteration 12328: loss: 0.077439, loss_s1: 0.067708, loss_fp: 0.001083, loss_freq: 0.028116
[04:38:58.714] iteration 12329: loss: 0.076258, loss_s1: 0.049640, loss_fp: 0.017611, loss_freq: 0.047061
[04:38:59.370] iteration 12330: loss: 0.047656, loss_s1: 0.028317, loss_fp: 0.001656, loss_freq: 0.020168
[04:39:00.029] iteration 12331: loss: 0.083719, loss_s1: 0.091483, loss_fp: 0.001131, loss_freq: 0.027342
[04:39:00.692] iteration 12332: loss: 0.075989, loss_s1: 0.064005, loss_fp: 0.002759, loss_freq: 0.037971
[04:39:01.393] iteration 12333: loss: 0.087173, loss_s1: 0.097468, loss_fp: 0.001032, loss_freq: 0.021956
[04:39:02.062] iteration 12334: loss: 0.055165, loss_s1: 0.040015, loss_fp: 0.001772, loss_freq: 0.008289
[04:39:02.754] iteration 12335: loss: 0.066885, loss_s1: 0.060368, loss_fp: 0.000880, loss_freq: 0.030121
[04:39:03.383] iteration 12336: loss: 0.070749, loss_s1: 0.060145, loss_fp: 0.004464, loss_freq: 0.045635
[04:39:04.048] iteration 12337: loss: 0.084656, loss_s1: 0.062743, loss_fp: 0.001823, loss_freq: 0.049365
[04:39:04.680] iteration 12338: loss: 0.065083, loss_s1: 0.031128, loss_fp: 0.002509, loss_freq: 0.038819
[04:39:05.302] iteration 12339: loss: 0.057928, loss_s1: 0.059312, loss_fp: 0.000642, loss_freq: 0.021517
[04:39:05.926] iteration 12340: loss: 0.057183, loss_s1: 0.039539, loss_fp: 0.002504, loss_freq: 0.027201
[04:39:06.551] iteration 12341: loss: 0.051761, loss_s1: 0.020316, loss_fp: 0.006878, loss_freq: 0.029381
[04:39:07.189] iteration 12342: loss: 0.067363, loss_s1: 0.025892, loss_fp: 0.003600, loss_freq: 0.029852
[04:39:07.821] iteration 12343: loss: 0.072517, loss_s1: 0.045303, loss_fp: 0.004453, loss_freq: 0.041571
[04:39:08.453] iteration 12344: loss: 0.056201, loss_s1: 0.031087, loss_fp: 0.005615, loss_freq: 0.034083
[04:39:09.107] iteration 12345: loss: 0.086483, loss_s1: 0.046233, loss_fp: 0.010298, loss_freq: 0.068932
[04:39:09.744] iteration 12346: loss: 0.072271, loss_s1: 0.051939, loss_fp: 0.004993, loss_freq: 0.027633
[04:39:10.376] iteration 12347: loss: 0.052104, loss_s1: 0.035009, loss_fp: 0.002919, loss_freq: 0.013691
[04:39:11.029] iteration 12348: loss: 0.055627, loss_s1: 0.034363, loss_fp: 0.003151, loss_freq: 0.033190
[04:39:11.651] iteration 12349: loss: 0.084984, loss_s1: 0.033941, loss_fp: 0.005535, loss_freq: 0.080859
[04:39:12.289] iteration 12350: loss: 0.073018, loss_s1: 0.059754, loss_fp: 0.003522, loss_freq: 0.028706
[04:39:12.909] iteration 12351: loss: 0.068570, loss_s1: 0.038384, loss_fp: 0.006185, loss_freq: 0.038626
[04:39:13.538] iteration 12352: loss: 0.062442, loss_s1: 0.032598, loss_fp: 0.005268, loss_freq: 0.041515
[04:39:14.193] iteration 12353: loss: 0.059173, loss_s1: 0.039445, loss_fp: 0.001433, loss_freq: 0.025885
[04:39:14.860] iteration 12354: loss: 0.040757, loss_s1: 0.027583, loss_fp: 0.004443, loss_freq: 0.022594
[04:39:15.521] iteration 12355: loss: 0.093092, loss_s1: 0.055901, loss_fp: 0.007330, loss_freq: 0.077624
[04:39:16.153] iteration 12356: loss: 0.077051, loss_s1: 0.058084, loss_fp: 0.003711, loss_freq: 0.033458
[04:39:16.821] iteration 12357: loss: 0.072684, loss_s1: 0.052317, loss_fp: 0.009803, loss_freq: 0.043805
[04:39:17.505] iteration 12358: loss: 0.047664, loss_s1: 0.037084, loss_fp: 0.004539, loss_freq: 0.020221
[04:39:18.166] iteration 12359: loss: 0.098659, loss_s1: 0.059609, loss_fp: 0.007792, loss_freq: 0.085367
[04:39:18.805] iteration 12360: loss: 0.045995, loss_s1: 0.017407, loss_fp: 0.007371, loss_freq: 0.012760
[04:39:19.426] iteration 12361: loss: 0.035876, loss_s1: 0.009016, loss_fp: 0.002422, loss_freq: 0.008399
[04:39:20.053] iteration 12362: loss: 0.059020, loss_s1: 0.056306, loss_fp: 0.002928, loss_freq: 0.025997
[04:39:20.688] iteration 12363: loss: 0.073871, loss_s1: 0.060407, loss_fp: 0.011960, loss_freq: 0.036448
[04:39:21.314] iteration 12364: loss: 0.058648, loss_s1: 0.049044, loss_fp: 0.003734, loss_freq: 0.024769
[04:39:21.952] iteration 12365: loss: 0.110038, loss_s1: 0.124852, loss_fp: 0.006099, loss_freq: 0.042504
[04:39:22.589] iteration 12366: loss: 0.116435, loss_s1: 0.107052, loss_fp: 0.010730, loss_freq: 0.036952
[04:39:23.216] iteration 12367: loss: 0.095936, loss_s1: 0.057897, loss_fp: 0.001474, loss_freq: 0.088480
[04:39:23.870] iteration 12368: loss: 0.056916, loss_s1: 0.031928, loss_fp: 0.005796, loss_freq: 0.027765
[04:39:24.505] iteration 12369: loss: 0.053658, loss_s1: 0.030762, loss_fp: 0.004556, loss_freq: 0.026181
[04:39:25.129] iteration 12370: loss: 0.068404, loss_s1: 0.047377, loss_fp: 0.003179, loss_freq: 0.031951
[04:39:25.785] iteration 12371: loss: 0.071172, loss_s1: 0.081285, loss_fp: 0.001389, loss_freq: 0.023047
[04:39:26.412] iteration 12372: loss: 0.062743, loss_s1: 0.038285, loss_fp: 0.003594, loss_freq: 0.012381
[04:39:27.057] iteration 12373: loss: 0.076105, loss_s1: 0.029500, loss_fp: 0.006050, loss_freq: 0.039190
[04:39:27.687] iteration 12374: loss: 0.063768, loss_s1: 0.062983, loss_fp: 0.003124, loss_freq: 0.017017
[04:39:28.312] iteration 12375: loss: 0.147551, loss_s1: 0.077760, loss_fp: 0.005189, loss_freq: 0.163255
[04:39:28.940] iteration 12376: loss: 0.035405, loss_s1: 0.026952, loss_fp: 0.001548, loss_freq: 0.008950
[04:39:29.611] iteration 12377: loss: 0.069530, loss_s1: 0.050221, loss_fp: 0.006141, loss_freq: 0.020489
[04:39:30.305] iteration 12378: loss: 0.093191, loss_s1: 0.114436, loss_fp: 0.003160, loss_freq: 0.036515
[04:39:30.978] iteration 12379: loss: 0.107043, loss_s1: 0.116788, loss_fp: 0.002976, loss_freq: 0.054925
[04:39:31.643] iteration 12380: loss: 0.071803, loss_s1: 0.054736, loss_fp: 0.003720, loss_freq: 0.054727
[04:39:32.312] iteration 12381: loss: 0.083208, loss_s1: 0.071198, loss_fp: 0.002675, loss_freq: 0.037205
[04:39:32.985] iteration 12382: loss: 0.089335, loss_s1: 0.105541, loss_fp: 0.001930, loss_freq: 0.029743
[04:39:33.647] iteration 12383: loss: 0.068073, loss_s1: 0.071860, loss_fp: 0.007201, loss_freq: 0.017024
[04:39:34.282] iteration 12384: loss: 0.065112, loss_s1: 0.041054, loss_fp: 0.001382, loss_freq: 0.023686
[04:39:34.917] iteration 12385: loss: 0.063102, loss_s1: 0.054870, loss_fp: 0.005083, loss_freq: 0.008725
[04:39:35.543] iteration 12386: loss: 0.044327, loss_s1: 0.016860, loss_fp: 0.001941, loss_freq: 0.026877
[04:39:36.194] iteration 12387: loss: 0.049075, loss_s1: 0.033910, loss_fp: 0.002275, loss_freq: 0.018952
[04:39:36.838] iteration 12388: loss: 0.114023, loss_s1: 0.106532, loss_fp: 0.008093, loss_freq: 0.071481
[04:39:37.462] iteration 12389: loss: 0.061669, loss_s1: 0.043082, loss_fp: 0.005864, loss_freq: 0.041707
[04:39:38.135] iteration 12390: loss: 0.071654, loss_s1: 0.032801, loss_fp: 0.005790, loss_freq: 0.050576
[04:39:38.806] iteration 12391: loss: 0.088003, loss_s1: 0.046998, loss_fp: 0.015368, loss_freq: 0.065478
[04:39:39.496] iteration 12392: loss: 0.066273, loss_s1: 0.040726, loss_fp: 0.004134, loss_freq: 0.047286
[04:39:40.171] iteration 12393: loss: 0.138285, loss_s1: 0.097671, loss_fp: 0.002864, loss_freq: 0.055479
[04:39:40.848] iteration 12394: loss: 0.085091, loss_s1: 0.075160, loss_fp: 0.013293, loss_freq: 0.024530
[04:39:41.488] iteration 12395: loss: 0.087382, loss_s1: 0.086734, loss_fp: 0.009293, loss_freq: 0.024537
[04:39:42.132] iteration 12396: loss: 0.048188, loss_s1: 0.033588, loss_fp: 0.001510, loss_freq: 0.015392
[04:39:42.767] iteration 12397: loss: 0.073050, loss_s1: 0.060173, loss_fp: 0.005358, loss_freq: 0.038563
[04:39:43.412] iteration 12398: loss: 0.122550, loss_s1: 0.109813, loss_fp: 0.002473, loss_freq: 0.070831
[04:39:44.041] iteration 12399: loss: 0.083326, loss_s1: 0.076128, loss_fp: 0.005976, loss_freq: 0.045244
[04:39:44.681] iteration 12400: loss: 0.066411, loss_s1: 0.060334, loss_fp: 0.003100, loss_freq: 0.024835
[04:39:48.131] iteration 12400 : mean_dice : 0.705944
[04:39:48.814] iteration 12401: loss: 0.045655, loss_s1: 0.042858, loss_fp: 0.003052, loss_freq: 0.007333
[04:39:49.463] iteration 12402: loss: 0.073761, loss_s1: 0.060295, loss_fp: 0.011966, loss_freq: 0.033859
[04:39:50.152] iteration 12403: loss: 0.059041, loss_s1: 0.026764, loss_fp: 0.003897, loss_freq: 0.019772
[04:39:50.769] iteration 12404: loss: 0.061564, loss_s1: 0.055876, loss_fp: 0.001455, loss_freq: 0.021976
[04:39:51.402] iteration 12405: loss: 0.050131, loss_s1: 0.032858, loss_fp: 0.001560, loss_freq: 0.016031
[04:39:52.059] iteration 12406: loss: 0.103053, loss_s1: 0.101585, loss_fp: 0.004719, loss_freq: 0.054065
[04:39:52.688] iteration 12407: loss: 0.073130, loss_s1: 0.025889, loss_fp: 0.001774, loss_freq: 0.032422
[04:39:53.310] iteration 12408: loss: 0.137003, loss_s1: 0.152635, loss_fp: 0.011947, loss_freq: 0.068704
[04:39:53.934] iteration 12409: loss: 0.085205, loss_s1: 0.073096, loss_fp: 0.001793, loss_freq: 0.049804
[04:39:54.550] iteration 12410: loss: 0.126158, loss_s1: 0.120828, loss_fp: 0.008879, loss_freq: 0.080552
[04:39:55.569] iteration 12411: loss: 0.074555, loss_s1: 0.086901, loss_fp: 0.001732, loss_freq: 0.014999
[04:39:56.216] iteration 12412: loss: 0.074330, loss_s1: 0.049871, loss_fp: 0.004025, loss_freq: 0.042915
[04:39:56.874] iteration 12413: loss: 0.051049, loss_s1: 0.038003, loss_fp: 0.001069, loss_freq: 0.030276
[04:39:57.498] iteration 12414: loss: 0.053368, loss_s1: 0.049601, loss_fp: 0.002458, loss_freq: 0.015165
[04:39:58.123] iteration 12415: loss: 0.074092, loss_s1: 0.053444, loss_fp: 0.002421, loss_freq: 0.051581
[04:39:58.750] iteration 12416: loss: 0.078584, loss_s1: 0.084366, loss_fp: 0.001763, loss_freq: 0.015823
[04:39:59.410] iteration 12417: loss: 0.069568, loss_s1: 0.036172, loss_fp: 0.002430, loss_freq: 0.059411
[04:40:00.031] iteration 12418: loss: 0.062537, loss_s1: 0.058061, loss_fp: 0.002364, loss_freq: 0.022422
[04:40:00.652] iteration 12419: loss: 0.051181, loss_s1: 0.049645, loss_fp: 0.002314, loss_freq: 0.010960
[04:40:01.287] iteration 12420: loss: 0.093895, loss_s1: 0.071617, loss_fp: 0.001834, loss_freq: 0.059936
[04:40:01.943] iteration 12421: loss: 0.081137, loss_s1: 0.058698, loss_fp: 0.006383, loss_freq: 0.048456
[04:40:02.581] iteration 12422: loss: 0.080312, loss_s1: 0.064867, loss_fp: 0.005182, loss_freq: 0.051462
[04:40:03.208] iteration 12423: loss: 0.099272, loss_s1: 0.057518, loss_fp: 0.001746, loss_freq: 0.052878
[04:40:03.898] iteration 12424: loss: 0.062020, loss_s1: 0.063622, loss_fp: 0.001556, loss_freq: 0.021399
[04:40:04.561] iteration 12425: loss: 0.116732, loss_s1: 0.139154, loss_fp: 0.000920, loss_freq: 0.025671
[04:40:05.197] iteration 12426: loss: 0.054475, loss_s1: 0.042999, loss_fp: 0.008287, loss_freq: 0.022622
[04:40:05.823] iteration 12427: loss: 0.108626, loss_s1: 0.083440, loss_fp: 0.008200, loss_freq: 0.098169
[04:40:06.502] iteration 12428: loss: 0.050685, loss_s1: 0.042738, loss_fp: 0.000847, loss_freq: 0.010271
[04:40:07.187] iteration 12429: loss: 0.066274, loss_s1: 0.044971, loss_fp: 0.003708, loss_freq: 0.035408
[04:40:07.864] iteration 12430: loss: 0.103361, loss_s1: 0.103519, loss_fp: 0.002058, loss_freq: 0.032125
[04:40:08.534] iteration 12431: loss: 0.059390, loss_s1: 0.055754, loss_fp: 0.001587, loss_freq: 0.019903
[04:40:09.203] iteration 12432: loss: 0.041224, loss_s1: 0.032518, loss_fp: 0.002649, loss_freq: 0.017664
[04:40:09.830] iteration 12433: loss: 0.075001, loss_s1: 0.044004, loss_fp: 0.006576, loss_freq: 0.026150
[04:40:10.471] iteration 12434: loss: 0.049856, loss_s1: 0.040833, loss_fp: 0.003073, loss_freq: 0.017795
[04:40:11.134] iteration 12435: loss: 0.079145, loss_s1: 0.069125, loss_fp: 0.003243, loss_freq: 0.050359
[04:40:11.800] iteration 12436: loss: 0.061944, loss_s1: 0.056217, loss_fp: 0.001460, loss_freq: 0.033963
[04:40:12.470] iteration 12437: loss: 0.064549, loss_s1: 0.043667, loss_fp: 0.002322, loss_freq: 0.032407
[04:40:13.139] iteration 12438: loss: 0.118660, loss_s1: 0.091397, loss_fp: 0.009119, loss_freq: 0.064892
[04:40:13.789] iteration 12439: loss: 0.073759, loss_s1: 0.062584, loss_fp: 0.003652, loss_freq: 0.031481
[04:40:14.478] iteration 12440: loss: 0.073436, loss_s1: 0.073665, loss_fp: 0.009013, loss_freq: 0.027311
[04:40:15.140] iteration 12441: loss: 0.100174, loss_s1: 0.065264, loss_fp: 0.003159, loss_freq: 0.061433
[04:40:15.830] iteration 12442: loss: 0.097581, loss_s1: 0.089420, loss_fp: 0.001943, loss_freq: 0.022794
[04:40:16.493] iteration 12443: loss: 0.106487, loss_s1: 0.116499, loss_fp: 0.003891, loss_freq: 0.055771
[04:40:17.227] iteration 12444: loss: 0.090014, loss_s1: 0.066561, loss_fp: 0.011340, loss_freq: 0.010704
[04:40:17.996] iteration 12445: loss: 0.069298, loss_s1: 0.053091, loss_fp: 0.002870, loss_freq: 0.051457
[04:40:18.637] iteration 12446: loss: 0.058858, loss_s1: 0.024849, loss_fp: 0.003769, loss_freq: 0.017927
[04:40:19.286] iteration 12447: loss: 0.079426, loss_s1: 0.066963, loss_fp: 0.002723, loss_freq: 0.043489
[04:40:20.005] iteration 12448: loss: 0.064060, loss_s1: 0.034831, loss_fp: 0.002964, loss_freq: 0.054029
[04:40:20.706] iteration 12449: loss: 0.090896, loss_s1: 0.077841, loss_fp: 0.018592, loss_freq: 0.039024
[04:40:21.493] iteration 12450: loss: 0.079884, loss_s1: 0.075441, loss_fp: 0.003143, loss_freq: 0.035904
[04:40:22.157] iteration 12451: loss: 0.149004, loss_s1: 0.107641, loss_fp: 0.000851, loss_freq: 0.136948
[04:40:22.829] iteration 12452: loss: 0.074389, loss_s1: 0.069336, loss_fp: 0.003573, loss_freq: 0.016603
[04:40:23.476] iteration 12453: loss: 0.106194, loss_s1: 0.117076, loss_fp: 0.003025, loss_freq: 0.055369
[04:40:24.267] iteration 12454: loss: 0.122571, loss_s1: 0.148806, loss_fp: 0.002316, loss_freq: 0.052982
[04:40:25.064] iteration 12455: loss: 0.064484, loss_s1: 0.040113, loss_fp: 0.007590, loss_freq: 0.038648
[04:40:25.729] iteration 12456: loss: 0.095060, loss_s1: 0.105753, loss_fp: 0.001820, loss_freq: 0.025803
[04:40:26.498] iteration 12457: loss: 0.078383, loss_s1: 0.067339, loss_fp: 0.001750, loss_freq: 0.034195
[04:40:27.223] iteration 12458: loss: 0.071232, loss_s1: 0.076861, loss_fp: 0.001554, loss_freq: 0.031150
[04:40:27.935] iteration 12459: loss: 0.058022, loss_s1: 0.061410, loss_fp: 0.003338, loss_freq: 0.008626
[04:40:28.667] iteration 12460: loss: 0.065173, loss_s1: 0.046876, loss_fp: 0.001837, loss_freq: 0.038535
[04:40:29.324] iteration 12461: loss: 0.051324, loss_s1: 0.030371, loss_fp: 0.005313, loss_freq: 0.026316
[04:40:29.957] iteration 12462: loss: 0.085662, loss_s1: 0.093326, loss_fp: 0.007365, loss_freq: 0.036730
[04:40:30.592] iteration 12463: loss: 0.054653, loss_s1: 0.043143, loss_fp: 0.001331, loss_freq: 0.026098
[04:40:31.232] iteration 12464: loss: 0.126563, loss_s1: 0.112418, loss_fp: 0.006672, loss_freq: 0.085813
[04:40:31.871] iteration 12465: loss: 0.079587, loss_s1: 0.068037, loss_fp: 0.003495, loss_freq: 0.030918
[04:40:32.500] iteration 12466: loss: 0.055849, loss_s1: 0.028391, loss_fp: 0.002570, loss_freq: 0.036129
[04:40:33.146] iteration 12467: loss: 0.066359, loss_s1: 0.052008, loss_fp: 0.006342, loss_freq: 0.035902
[04:40:33.783] iteration 12468: loss: 0.112597, loss_s1: 0.067954, loss_fp: 0.009722, loss_freq: 0.074477
[04:40:34.410] iteration 12469: loss: 0.051849, loss_s1: 0.028737, loss_fp: 0.003441, loss_freq: 0.032734
[04:40:35.038] iteration 12470: loss: 0.089898, loss_s1: 0.044233, loss_fp: 0.003851, loss_freq: 0.077030
[04:40:35.675] iteration 12471: loss: 0.043769, loss_s1: 0.024589, loss_fp: 0.001673, loss_freq: 0.008005
[04:40:36.311] iteration 12472: loss: 0.053923, loss_s1: 0.020317, loss_fp: 0.002693, loss_freq: 0.038315
[04:40:36.953] iteration 12473: loss: 0.050348, loss_s1: 0.037214, loss_fp: 0.001289, loss_freq: 0.010788
[04:40:37.579] iteration 12474: loss: 0.058612, loss_s1: 0.051644, loss_fp: 0.001742, loss_freq: 0.026096
[04:40:38.209] iteration 12475: loss: 0.086356, loss_s1: 0.081592, loss_fp: 0.004510, loss_freq: 0.034714
[04:40:38.865] iteration 12476: loss: 0.069275, loss_s1: 0.071252, loss_fp: 0.001881, loss_freq: 0.030621
[04:40:39.508] iteration 12477: loss: 0.076784, loss_s1: 0.079217, loss_fp: 0.002285, loss_freq: 0.015527
[04:40:40.128] iteration 12478: loss: 0.120791, loss_s1: 0.100325, loss_fp: 0.004608, loss_freq: 0.088448
[04:40:40.764] iteration 12479: loss: 0.064163, loss_s1: 0.056491, loss_fp: 0.001397, loss_freq: 0.029854
[04:40:41.469] iteration 12480: loss: 0.073062, loss_s1: 0.059804, loss_fp: 0.002301, loss_freq: 0.035810
[04:40:42.362] iteration 12481: loss: 0.076838, loss_s1: 0.062400, loss_fp: 0.002194, loss_freq: 0.047500
[04:40:43.215] iteration 12482: loss: 0.053247, loss_s1: 0.020028, loss_fp: 0.002173, loss_freq: 0.016139
[04:40:43.997] iteration 12483: loss: 0.084801, loss_s1: 0.069250, loss_fp: 0.007490, loss_freq: 0.038536
[04:40:44.777] iteration 12484: loss: 0.115091, loss_s1: 0.123363, loss_fp: 0.003986, loss_freq: 0.021446
[04:40:45.444] iteration 12485: loss: 0.112322, loss_s1: 0.101269, loss_fp: 0.001797, loss_freq: 0.052816
[04:40:46.286] iteration 12486: loss: 0.085302, loss_s1: 0.062758, loss_fp: 0.004730, loss_freq: 0.030558
[04:40:47.102] iteration 12487: loss: 0.054764, loss_s1: 0.036186, loss_fp: 0.003103, loss_freq: 0.024125
[04:40:47.731] iteration 12488: loss: 0.054870, loss_s1: 0.033195, loss_fp: 0.003414, loss_freq: 0.025768
[04:40:48.368] iteration 12489: loss: 0.084397, loss_s1: 0.080624, loss_fp: 0.001785, loss_freq: 0.035945
[04:40:48.988] iteration 12490: loss: 0.090238, loss_s1: 0.086615, loss_fp: 0.000957, loss_freq: 0.030146
[04:40:49.619] iteration 12491: loss: 0.087851, loss_s1: 0.064949, loss_fp: 0.001364, loss_freq: 0.046035
[04:40:50.234] iteration 12492: loss: 0.062981, loss_s1: 0.059014, loss_fp: 0.006967, loss_freq: 0.021527
[04:40:50.854] iteration 12493: loss: 0.095708, loss_s1: 0.100359, loss_fp: 0.002905, loss_freq: 0.033623
[04:40:51.475] iteration 12494: loss: 0.054916, loss_s1: 0.053792, loss_fp: 0.003484, loss_freq: 0.010199
[04:40:52.112] iteration 12495: loss: 0.053174, loss_s1: 0.030601, loss_fp: 0.000782, loss_freq: 0.026500
[04:40:52.731] iteration 12496: loss: 0.070800, loss_s1: 0.056901, loss_fp: 0.006119, loss_freq: 0.023133
[04:40:53.373] iteration 12497: loss: 0.063900, loss_s1: 0.065302, loss_fp: 0.005829, loss_freq: 0.019480
[04:40:54.005] iteration 12498: loss: 0.049355, loss_s1: 0.044409, loss_fp: 0.000736, loss_freq: 0.008430
[04:40:54.660] iteration 12499: loss: 0.069024, loss_s1: 0.069957, loss_fp: 0.002417, loss_freq: 0.013762
[04:40:55.292] iteration 12500: loss: 0.043045, loss_s1: 0.031893, loss_fp: 0.000716, loss_freq: 0.004718
[04:40:55.927] iteration 12501: loss: 0.110609, loss_s1: 0.083439, loss_fp: 0.008180, loss_freq: 0.031814
[04:40:56.563] iteration 12502: loss: 0.076017, loss_s1: 0.054112, loss_fp: 0.001410, loss_freq: 0.054840
[04:40:57.210] iteration 12503: loss: 0.081905, loss_s1: 0.062310, loss_fp: 0.010829, loss_freq: 0.035159
[04:40:57.853] iteration 12504: loss: 0.039094, loss_s1: 0.026192, loss_fp: 0.003048, loss_freq: 0.011522
[04:40:58.485] iteration 12505: loss: 0.084490, loss_s1: 0.051748, loss_fp: 0.006044, loss_freq: 0.060249
[04:40:59.133] iteration 12506: loss: 0.085540, loss_s1: 0.070688, loss_fp: 0.003909, loss_freq: 0.043024
[04:40:59.770] iteration 12507: loss: 0.090452, loss_s1: 0.048956, loss_fp: 0.003987, loss_freq: 0.052335
[04:41:00.445] iteration 12508: loss: 0.092635, loss_s1: 0.070534, loss_fp: 0.007108, loss_freq: 0.063019
[04:41:01.073] iteration 12509: loss: 0.064015, loss_s1: 0.073962, loss_fp: 0.002295, loss_freq: 0.023221
[04:41:01.701] iteration 12510: loss: 0.051156, loss_s1: 0.030639, loss_fp: 0.001865, loss_freq: 0.028502
[04:41:02.350] iteration 12511: loss: 0.089461, loss_s1: 0.088794, loss_fp: 0.009495, loss_freq: 0.046373
[04:41:02.996] iteration 12512: loss: 0.045879, loss_s1: 0.027048, loss_fp: 0.005235, loss_freq: 0.009242
[04:41:03.656] iteration 12513: loss: 0.047011, loss_s1: 0.038475, loss_fp: 0.001240, loss_freq: 0.014313
[04:41:04.284] iteration 12514: loss: 0.050075, loss_s1: 0.011970, loss_fp: 0.006723, loss_freq: 0.028295
[04:41:04.910] iteration 12515: loss: 0.036066, loss_s1: 0.018359, loss_fp: 0.004330, loss_freq: 0.018561
[04:41:05.538] iteration 12516: loss: 0.077828, loss_s1: 0.070473, loss_fp: 0.005084, loss_freq: 0.023209
[04:41:06.165] iteration 12517: loss: 0.078710, loss_s1: 0.061883, loss_fp: 0.004946, loss_freq: 0.044609
[04:41:06.803] iteration 12518: loss: 0.079097, loss_s1: 0.033413, loss_fp: 0.003795, loss_freq: 0.035973
[04:41:07.422] iteration 12519: loss: 0.074554, loss_s1: 0.047986, loss_fp: 0.008715, loss_freq: 0.046253
[04:41:08.047] iteration 12520: loss: 0.077439, loss_s1: 0.043333, loss_fp: 0.007495, loss_freq: 0.044986
[04:41:08.694] iteration 12521: loss: 0.069729, loss_s1: 0.075414, loss_fp: 0.002059, loss_freq: 0.018852
[04:41:09.343] iteration 12522: loss: 0.092434, loss_s1: 0.071703, loss_fp: 0.003264, loss_freq: 0.045189
[04:41:09.970] iteration 12523: loss: 0.081327, loss_s1: 0.067329, loss_fp: 0.002672, loss_freq: 0.033082
[04:41:10.609] iteration 12524: loss: 0.052427, loss_s1: 0.036956, loss_fp: 0.001049, loss_freq: 0.030716
[04:41:11.235] iteration 12525: loss: 0.102278, loss_s1: 0.080716, loss_fp: 0.001507, loss_freq: 0.077057
[04:41:11.862] iteration 12526: loss: 0.067699, loss_s1: 0.042584, loss_fp: 0.002917, loss_freq: 0.043394
[04:41:12.488] iteration 12527: loss: 0.052390, loss_s1: 0.048853, loss_fp: 0.003176, loss_freq: 0.015054
[04:41:13.137] iteration 12528: loss: 0.065306, loss_s1: 0.048916, loss_fp: 0.002588, loss_freq: 0.032706
[04:41:13.755] iteration 12529: loss: 0.083813, loss_s1: 0.032241, loss_fp: 0.011337, loss_freq: 0.086304
[04:41:14.377] iteration 12530: loss: 0.038786, loss_s1: 0.020774, loss_fp: 0.000985, loss_freq: 0.009242
[04:41:15.047] iteration 12531: loss: 0.072343, loss_s1: 0.073876, loss_fp: 0.000852, loss_freq: 0.010745
[04:41:15.716] iteration 12532: loss: 0.069702, loss_s1: 0.064319, loss_fp: 0.006292, loss_freq: 0.033574
[04:41:16.411] iteration 12533: loss: 0.108262, loss_s1: 0.099570, loss_fp: 0.003799, loss_freq: 0.059806
[04:41:17.061] iteration 12534: loss: 0.099605, loss_s1: 0.121996, loss_fp: 0.001722, loss_freq: 0.041053
[04:41:17.695] iteration 12535: loss: 0.073859, loss_s1: 0.029432, loss_fp: 0.008441, loss_freq: 0.061804
[04:41:18.328] iteration 12536: loss: 0.050341, loss_s1: 0.017390, loss_fp: 0.006265, loss_freq: 0.037618
[04:41:18.959] iteration 12537: loss: 0.073470, loss_s1: 0.034020, loss_fp: 0.000535, loss_freq: 0.065542
[04:41:19.584] iteration 12538: loss: 0.070455, loss_s1: 0.058111, loss_fp: 0.004036, loss_freq: 0.026700
[04:41:20.210] iteration 12539: loss: 0.070278, loss_s1: 0.048066, loss_fp: 0.009561, loss_freq: 0.026796
[04:41:20.847] iteration 12540: loss: 0.050536, loss_s1: 0.023653, loss_fp: 0.009640, loss_freq: 0.022282
[04:41:21.496] iteration 12541: loss: 0.082381, loss_s1: 0.104150, loss_fp: 0.007534, loss_freq: 0.019068
[04:41:22.135] iteration 12542: loss: 0.048220, loss_s1: 0.026788, loss_fp: 0.001832, loss_freq: 0.021134
[04:41:22.769] iteration 12543: loss: 0.085440, loss_s1: 0.051496, loss_fp: 0.007912, loss_freq: 0.054142
[04:41:23.396] iteration 12544: loss: 0.085571, loss_s1: 0.085670, loss_fp: 0.003044, loss_freq: 0.043791
[04:41:24.043] iteration 12545: loss: 0.073615, loss_s1: 0.083750, loss_fp: 0.000994, loss_freq: 0.024853
[04:41:24.692] iteration 12546: loss: 0.045802, loss_s1: 0.035447, loss_fp: 0.008011, loss_freq: 0.013508
[04:41:25.335] iteration 12547: loss: 0.130573, loss_s1: 0.124968, loss_fp: 0.001494, loss_freq: 0.023335
[04:41:25.975] iteration 12548: loss: 0.087908, loss_s1: 0.063267, loss_fp: 0.003511, loss_freq: 0.071422
[04:41:26.630] iteration 12549: loss: 0.107477, loss_s1: 0.090997, loss_fp: 0.009133, loss_freq: 0.072216
[04:41:27.286] iteration 12550: loss: 0.079077, loss_s1: 0.101353, loss_fp: 0.002042, loss_freq: 0.025035
[04:41:27.915] iteration 12551: loss: 0.060909, loss_s1: 0.038350, loss_fp: 0.006123, loss_freq: 0.029612
[04:41:28.564] iteration 12552: loss: 0.042012, loss_s1: 0.022056, loss_fp: 0.002475, loss_freq: 0.016490
[04:41:29.231] iteration 12553: loss: 0.055434, loss_s1: 0.024624, loss_fp: 0.011253, loss_freq: 0.033697
[04:41:29.902] iteration 12554: loss: 0.070987, loss_s1: 0.047103, loss_fp: 0.002438, loss_freq: 0.030401
[04:41:30.559] iteration 12555: loss: 0.036406, loss_s1: 0.018747, loss_fp: 0.005157, loss_freq: 0.003735
[04:41:31.240] iteration 12556: loss: 0.057886, loss_s1: 0.036744, loss_fp: 0.010179, loss_freq: 0.015597
[04:41:31.926] iteration 12557: loss: 0.050686, loss_s1: 0.024831, loss_fp: 0.007953, loss_freq: 0.029057
[04:41:32.570] iteration 12558: loss: 0.091852, loss_s1: 0.102504, loss_fp: 0.001407, loss_freq: 0.045695
[04:41:33.200] iteration 12559: loss: 0.091770, loss_s1: 0.108068, loss_fp: 0.007174, loss_freq: 0.030847
[04:41:33.839] iteration 12560: loss: 0.068943, loss_s1: 0.031710, loss_fp: 0.003350, loss_freq: 0.036497
[04:41:34.482] iteration 12561: loss: 0.056260, loss_s1: 0.027477, loss_fp: 0.009470, loss_freq: 0.025252
[04:41:35.134] iteration 12562: loss: 0.071215, loss_s1: 0.038352, loss_fp: 0.002835, loss_freq: 0.055722
[04:41:35.795] iteration 12563: loss: 0.110552, loss_s1: 0.104724, loss_fp: 0.025540, loss_freq: 0.031313
[04:41:36.468] iteration 12564: loss: 0.087091, loss_s1: 0.071492, loss_fp: 0.002694, loss_freq: 0.056033
[04:41:37.152] iteration 12565: loss: 0.088073, loss_s1: 0.070334, loss_fp: 0.002226, loss_freq: 0.056475
[04:41:37.871] iteration 12566: loss: 0.044689, loss_s1: 0.024701, loss_fp: 0.003971, loss_freq: 0.020652
[04:41:38.547] iteration 12567: loss: 0.042884, loss_s1: 0.028060, loss_fp: 0.004756, loss_freq: 0.018128
[04:41:39.249] iteration 12568: loss: 0.088954, loss_s1: 0.056305, loss_fp: 0.003230, loss_freq: 0.060453
[04:41:39.931] iteration 12569: loss: 0.066124, loss_s1: 0.052117, loss_fp: 0.004334, loss_freq: 0.030443
[04:41:40.565] iteration 12570: loss: 0.096646, loss_s1: 0.070965, loss_fp: 0.002253, loss_freq: 0.046921
[04:41:41.264] iteration 12571: loss: 0.052380, loss_s1: 0.054394, loss_fp: 0.001699, loss_freq: 0.006713
[04:41:41.949] iteration 12572: loss: 0.070610, loss_s1: 0.050454, loss_fp: 0.002852, loss_freq: 0.040954
[04:41:42.618] iteration 12573: loss: 0.045320, loss_s1: 0.019615, loss_fp: 0.000806, loss_freq: 0.013917
[04:41:43.331] iteration 12574: loss: 0.059140, loss_s1: 0.036488, loss_fp: 0.005644, loss_freq: 0.044424
[04:41:43.998] iteration 12575: loss: 0.040862, loss_s1: 0.022717, loss_fp: 0.001877, loss_freq: 0.015631
[04:41:44.660] iteration 12576: loss: 0.042794, loss_s1: 0.026586, loss_fp: 0.000894, loss_freq: 0.024688
[04:41:45.283] iteration 12577: loss: 0.093899, loss_s1: 0.082566, loss_fp: 0.001026, loss_freq: 0.043328
[04:41:45.906] iteration 12578: loss: 0.061408, loss_s1: 0.062345, loss_fp: 0.007912, loss_freq: 0.011342
[04:41:46.568] iteration 12579: loss: 0.069399, loss_s1: 0.058590, loss_fp: 0.002922, loss_freq: 0.038598
[04:41:47.230] iteration 12580: loss: 0.066205, loss_s1: 0.044734, loss_fp: 0.000885, loss_freq: 0.037540
[04:41:48.284] iteration 12581: loss: 0.107461, loss_s1: 0.075183, loss_fp: 0.002211, loss_freq: 0.017678
[04:41:48.960] iteration 12582: loss: 0.075659, loss_s1: 0.079708, loss_fp: 0.001344, loss_freq: 0.033138
[04:41:49.666] iteration 12583: loss: 0.068991, loss_s1: 0.071822, loss_fp: 0.005446, loss_freq: 0.028715
[04:41:50.334] iteration 12584: loss: 0.057794, loss_s1: 0.053033, loss_fp: 0.002403, loss_freq: 0.010161
[04:41:51.011] iteration 12585: loss: 0.056677, loss_s1: 0.043572, loss_fp: 0.006504, loss_freq: 0.012215
[04:41:51.686] iteration 12586: loss: 0.097851, loss_s1: 0.111982, loss_fp: 0.011031, loss_freq: 0.026403
[04:41:52.382] iteration 12587: loss: 0.067870, loss_s1: 0.051400, loss_fp: 0.004084, loss_freq: 0.030735
[04:41:53.021] iteration 12588: loss: 0.058754, loss_s1: 0.053479, loss_fp: 0.004352, loss_freq: 0.013260
[04:41:53.651] iteration 12589: loss: 0.084313, loss_s1: 0.062595, loss_fp: 0.001720, loss_freq: 0.077645
[04:41:54.291] iteration 12590: loss: 0.099635, loss_s1: 0.110733, loss_fp: 0.003259, loss_freq: 0.027601
[04:41:54.932] iteration 12591: loss: 0.073948, loss_s1: 0.040216, loss_fp: 0.004192, loss_freq: 0.045538
[04:41:55.580] iteration 12592: loss: 0.086967, loss_s1: 0.053197, loss_fp: 0.003826, loss_freq: 0.077199
[04:41:56.225] iteration 12593: loss: 0.058804, loss_s1: 0.031579, loss_fp: 0.002465, loss_freq: 0.027190
[04:41:56.862] iteration 12594: loss: 0.066910, loss_s1: 0.069140, loss_fp: 0.001231, loss_freq: 0.015856
[04:41:57.489] iteration 12595: loss: 0.097154, loss_s1: 0.117795, loss_fp: 0.005490, loss_freq: 0.023226
[04:41:58.131] iteration 12596: loss: 0.077126, loss_s1: 0.071408, loss_fp: 0.002963, loss_freq: 0.042370
[04:41:58.764] iteration 12597: loss: 0.099842, loss_s1: 0.102825, loss_fp: 0.003355, loss_freq: 0.057422
[04:41:59.446] iteration 12598: loss: 0.038797, loss_s1: 0.032282, loss_fp: 0.000691, loss_freq: 0.005160
[04:42:00.107] iteration 12599: loss: 0.065948, loss_s1: 0.046498, loss_fp: 0.014658, loss_freq: 0.034197
[04:42:00.745] iteration 12600: loss: 0.072041, loss_s1: 0.061952, loss_fp: 0.002731, loss_freq: 0.022375
[04:42:03.996] iteration 12600 : mean_dice : 0.688011
[04:42:04.654] iteration 12601: loss: 0.053946, loss_s1: 0.036935, loss_fp: 0.002238, loss_freq: 0.021464
[04:42:05.323] iteration 12602: loss: 0.068469, loss_s1: 0.064237, loss_fp: 0.003597, loss_freq: 0.032309
[04:42:05.992] iteration 12603: loss: 0.087372, loss_s1: 0.053430, loss_fp: 0.000836, loss_freq: 0.031949
[04:42:06.669] iteration 12604: loss: 0.069785, loss_s1: 0.060497, loss_fp: 0.003272, loss_freq: 0.018793
[04:42:07.350] iteration 12605: loss: 0.092192, loss_s1: 0.092621, loss_fp: 0.005294, loss_freq: 0.050337
[04:42:08.039] iteration 12606: loss: 0.067826, loss_s1: 0.060526, loss_fp: 0.004721, loss_freq: 0.035250
[04:42:08.690] iteration 12607: loss: 0.077346, loss_s1: 0.071515, loss_fp: 0.003534, loss_freq: 0.026258
[04:42:09.323] iteration 12608: loss: 0.135201, loss_s1: 0.148852, loss_fp: 0.013861, loss_freq: 0.054175
[04:42:09.948] iteration 12609: loss: 0.068135, loss_s1: 0.014855, loss_fp: 0.001915, loss_freq: 0.025416
[04:42:10.586] iteration 12610: loss: 0.088309, loss_s1: 0.103277, loss_fp: 0.005116, loss_freq: 0.027094
[04:42:11.209] iteration 12611: loss: 0.083378, loss_s1: 0.073076, loss_fp: 0.001344, loss_freq: 0.048676
[04:42:11.841] iteration 12612: loss: 0.112925, loss_s1: 0.097658, loss_fp: 0.010118, loss_freq: 0.043774
[04:42:12.461] iteration 12613: loss: 0.074350, loss_s1: 0.061230, loss_fp: 0.003972, loss_freq: 0.048669
[04:42:13.105] iteration 12614: loss: 0.034666, loss_s1: 0.013031, loss_fp: 0.001417, loss_freq: 0.012393
[04:42:13.754] iteration 12615: loss: 0.049659, loss_s1: 0.029329, loss_fp: 0.003370, loss_freq: 0.028817
[04:42:14.378] iteration 12616: loss: 0.039953, loss_s1: 0.019248, loss_fp: 0.001528, loss_freq: 0.011472
[04:42:15.003] iteration 12617: loss: 0.075277, loss_s1: 0.057072, loss_fp: 0.000908, loss_freq: 0.051586
[04:42:15.634] iteration 12618: loss: 0.043858, loss_s1: 0.017983, loss_fp: 0.011697, loss_freq: 0.026139
[04:42:16.300] iteration 12619: loss: 0.081667, loss_s1: 0.072135, loss_fp: 0.006514, loss_freq: 0.022209
[04:42:16.919] iteration 12620: loss: 0.090265, loss_s1: 0.084711, loss_fp: 0.006671, loss_freq: 0.042891
[04:42:17.626] iteration 12621: loss: 0.088457, loss_s1: 0.082659, loss_fp: 0.004697, loss_freq: 0.015749
[04:42:18.257] iteration 12622: loss: 0.072823, loss_s1: 0.069967, loss_fp: 0.001243, loss_freq: 0.033607
[04:42:18.883] iteration 12623: loss: 0.112989, loss_s1: 0.141153, loss_fp: 0.004590, loss_freq: 0.039673
[04:42:19.552] iteration 12624: loss: 0.121946, loss_s1: 0.120371, loss_fp: 0.004279, loss_freq: 0.065410
[04:42:20.185] iteration 12625: loss: 0.074958, loss_s1: 0.040476, loss_fp: 0.001306, loss_freq: 0.036156
[04:42:20.809] iteration 12626: loss: 0.078497, loss_s1: 0.088553, loss_fp: 0.004718, loss_freq: 0.013749
[04:42:21.441] iteration 12627: loss: 0.078119, loss_s1: 0.061558, loss_fp: 0.002979, loss_freq: 0.052322
[04:42:22.078] iteration 12628: loss: 0.076355, loss_s1: 0.045012, loss_fp: 0.003036, loss_freq: 0.061075
[04:42:22.705] iteration 12629: loss: 0.057443, loss_s1: 0.061328, loss_fp: 0.001679, loss_freq: 0.010006
[04:42:23.361] iteration 12630: loss: 0.065072, loss_s1: 0.053145, loss_fp: 0.002561, loss_freq: 0.014073
[04:42:23.993] iteration 12631: loss: 0.087681, loss_s1: 0.056999, loss_fp: 0.001108, loss_freq: 0.029680
[04:42:24.677] iteration 12632: loss: 0.072336, loss_s1: 0.066532, loss_fp: 0.001963, loss_freq: 0.045871
[04:42:25.359] iteration 12633: loss: 0.104325, loss_s1: 0.062117, loss_fp: 0.000989, loss_freq: 0.077107
[04:42:26.038] iteration 12634: loss: 0.085153, loss_s1: 0.064207, loss_fp: 0.009938, loss_freq: 0.034748
[04:42:26.714] iteration 12635: loss: 0.072838, loss_s1: 0.031801, loss_fp: 0.001835, loss_freq: 0.053971
[04:42:27.337] iteration 12636: loss: 0.048564, loss_s1: 0.034601, loss_fp: 0.000271, loss_freq: 0.018504
[04:42:27.964] iteration 12637: loss: 0.051087, loss_s1: 0.029174, loss_fp: 0.005231, loss_freq: 0.032833
[04:42:28.605] iteration 12638: loss: 0.071176, loss_s1: 0.049391, loss_fp: 0.000876, loss_freq: 0.036828
[04:42:29.247] iteration 12639: loss: 0.050869, loss_s1: 0.027851, loss_fp: 0.000956, loss_freq: 0.034365
[04:42:29.898] iteration 12640: loss: 0.116789, loss_s1: 0.080746, loss_fp: 0.010642, loss_freq: 0.089615
[04:42:30.534] iteration 12641: loss: 0.041821, loss_s1: 0.026944, loss_fp: 0.003898, loss_freq: 0.016276
[04:42:31.168] iteration 12642: loss: 0.067177, loss_s1: 0.019800, loss_fp: 0.000510, loss_freq: 0.040686
[04:42:31.845] iteration 12643: loss: 0.055233, loss_s1: 0.042223, loss_fp: 0.000961, loss_freq: 0.019805
[04:42:32.475] iteration 12644: loss: 0.042465, loss_s1: 0.023429, loss_fp: 0.002058, loss_freq: 0.018878
[04:42:33.094] iteration 12645: loss: 0.127278, loss_s1: 0.171293, loss_fp: 0.004915, loss_freq: 0.028789
[04:42:33.716] iteration 12646: loss: 0.057624, loss_s1: 0.044110, loss_fp: 0.000826, loss_freq: 0.040503
[04:42:34.375] iteration 12647: loss: 0.069114, loss_s1: 0.073070, loss_fp: 0.002138, loss_freq: 0.016434
[04:42:35.012] iteration 12648: loss: 0.108431, loss_s1: 0.121570, loss_fp: 0.005983, loss_freq: 0.038288
[04:42:35.723] iteration 12649: loss: 0.057259, loss_s1: 0.041123, loss_fp: 0.002399, loss_freq: 0.025009
[04:42:36.417] iteration 12650: loss: 0.064196, loss_s1: 0.049697, loss_fp: 0.003588, loss_freq: 0.032888
[04:42:37.105] iteration 12651: loss: 0.090209, loss_s1: 0.097179, loss_fp: 0.007423, loss_freq: 0.028870
[04:42:37.793] iteration 12652: loss: 0.068652, loss_s1: 0.054738, loss_fp: 0.007970, loss_freq: 0.025138
[04:42:38.482] iteration 12653: loss: 0.062282, loss_s1: 0.037846, loss_fp: 0.008869, loss_freq: 0.041236
[04:42:39.118] iteration 12654: loss: 0.058115, loss_s1: 0.039915, loss_fp: 0.005028, loss_freq: 0.028300
[04:42:39.769] iteration 12655: loss: 0.080565, loss_s1: 0.073073, loss_fp: 0.002197, loss_freq: 0.032522
[04:42:40.423] iteration 12656: loss: 0.078802, loss_s1: 0.060473, loss_fp: 0.008703, loss_freq: 0.047444
[04:42:41.072] iteration 12657: loss: 0.056827, loss_s1: 0.048995, loss_fp: 0.004289, loss_freq: 0.022713
[04:42:41.723] iteration 12658: loss: 0.095756, loss_s1: 0.108949, loss_fp: 0.007819, loss_freq: 0.033910
[04:42:42.372] iteration 12659: loss: 0.065192, loss_s1: 0.059028, loss_fp: 0.003947, loss_freq: 0.038031
[04:42:43.015] iteration 12660: loss: 0.059770, loss_s1: 0.041120, loss_fp: 0.002035, loss_freq: 0.025301
[04:42:43.646] iteration 12661: loss: 0.113663, loss_s1: 0.086774, loss_fp: 0.020342, loss_freq: 0.049272
[04:42:44.301] iteration 12662: loss: 0.059796, loss_s1: 0.042468, loss_fp: 0.003984, loss_freq: 0.032544
[04:42:44.944] iteration 12663: loss: 0.054070, loss_s1: 0.038756, loss_fp: 0.005457, loss_freq: 0.020237
[04:42:45.587] iteration 12664: loss: 0.069029, loss_s1: 0.049981, loss_fp: 0.012889, loss_freq: 0.019192
[04:42:46.224] iteration 12665: loss: 0.068143, loss_s1: 0.058360, loss_fp: 0.005607, loss_freq: 0.025398
[04:42:46.870] iteration 12666: loss: 0.063273, loss_s1: 0.034445, loss_fp: 0.003526, loss_freq: 0.046669
[04:42:47.514] iteration 12667: loss: 0.096697, loss_s1: 0.133156, loss_fp: 0.005709, loss_freq: 0.017828
[04:42:48.170] iteration 12668: loss: 0.104639, loss_s1: 0.131024, loss_fp: 0.002862, loss_freq: 0.028449
[04:42:48.852] iteration 12669: loss: 0.103919, loss_s1: 0.130478, loss_fp: 0.006855, loss_freq: 0.025639
[04:42:49.502] iteration 12670: loss: 0.094402, loss_s1: 0.058855, loss_fp: 0.001085, loss_freq: 0.035454
[04:42:50.148] iteration 12671: loss: 0.112428, loss_s1: 0.121173, loss_fp: 0.006973, loss_freq: 0.030481
[04:42:50.819] iteration 12672: loss: 0.089890, loss_s1: 0.041472, loss_fp: 0.025464, loss_freq: 0.065793
[04:42:51.508] iteration 12673: loss: 0.075351, loss_s1: 0.046722, loss_fp: 0.001918, loss_freq: 0.034595
[04:42:52.168] iteration 12674: loss: 0.094216, loss_s1: 0.129888, loss_fp: 0.001636, loss_freq: 0.013940
[04:42:52.852] iteration 12675: loss: 0.093029, loss_s1: 0.073144, loss_fp: 0.003904, loss_freq: 0.041646
[04:42:53.496] iteration 12676: loss: 0.079126, loss_s1: 0.073474, loss_fp: 0.002287, loss_freq: 0.045115
[04:42:54.130] iteration 12677: loss: 0.104622, loss_s1: 0.089839, loss_fp: 0.001550, loss_freq: 0.069189
[04:42:54.766] iteration 12678: loss: 0.050005, loss_s1: 0.042365, loss_fp: 0.000575, loss_freq: 0.014644
[04:42:55.422] iteration 12679: loss: 0.069300, loss_s1: 0.065224, loss_fp: 0.000894, loss_freq: 0.031041
[04:42:56.063] iteration 12680: loss: 0.077413, loss_s1: 0.050123, loss_fp: 0.005480, loss_freq: 0.053655
[04:42:56.710] iteration 12681: loss: 0.077063, loss_s1: 0.080440, loss_fp: 0.003479, loss_freq: 0.030413
[04:42:57.346] iteration 12682: loss: 0.056183, loss_s1: 0.036489, loss_fp: 0.000569, loss_freq: 0.020376
[04:42:57.988] iteration 12683: loss: 0.044004, loss_s1: 0.012281, loss_fp: 0.000755, loss_freq: 0.032076
[04:42:58.610] iteration 12684: loss: 0.069131, loss_s1: 0.025689, loss_fp: 0.001814, loss_freq: 0.039290
[04:42:59.242] iteration 12685: loss: 0.050010, loss_s1: 0.025273, loss_fp: 0.000282, loss_freq: 0.022951
[04:42:59.870] iteration 12686: loss: 0.100638, loss_s1: 0.083264, loss_fp: 0.020617, loss_freq: 0.036233
[04:43:00.494] iteration 12687: loss: 0.082729, loss_s1: 0.079087, loss_fp: 0.002780, loss_freq: 0.038504
[04:43:01.120] iteration 12688: loss: 0.060384, loss_s1: 0.045096, loss_fp: 0.006687, loss_freq: 0.022464
[04:43:01.772] iteration 12689: loss: 0.100502, loss_s1: 0.050769, loss_fp: 0.006964, loss_freq: 0.077287
[04:43:02.406] iteration 12690: loss: 0.061176, loss_s1: 0.026952, loss_fp: 0.001273, loss_freq: 0.035891
[04:43:03.045] iteration 12691: loss: 0.056148, loss_s1: 0.041149, loss_fp: 0.004160, loss_freq: 0.014817
[04:43:03.678] iteration 12692: loss: 0.054956, loss_s1: 0.042135, loss_fp: 0.004416, loss_freq: 0.027635
[04:43:04.322] iteration 12693: loss: 0.072240, loss_s1: 0.072092, loss_fp: 0.001776, loss_freq: 0.032054
[04:43:04.955] iteration 12694: loss: 0.064319, loss_s1: 0.053716, loss_fp: 0.008590, loss_freq: 0.033822
[04:43:05.606] iteration 12695: loss: 0.100834, loss_s1: 0.072277, loss_fp: 0.007585, loss_freq: 0.054642
[04:43:06.278] iteration 12696: loss: 0.078873, loss_s1: 0.061221, loss_fp: 0.005202, loss_freq: 0.051828
[04:43:06.948] iteration 12697: loss: 0.064688, loss_s1: 0.044405, loss_fp: 0.001182, loss_freq: 0.048226
[04:43:07.605] iteration 12698: loss: 0.064623, loss_s1: 0.048481, loss_fp: 0.004389, loss_freq: 0.011827
[04:43:08.262] iteration 12699: loss: 0.124192, loss_s1: 0.069484, loss_fp: 0.002825, loss_freq: 0.113866
[04:43:08.937] iteration 12700: loss: 0.043355, loss_s1: 0.029069, loss_fp: 0.002610, loss_freq: 0.007962
[04:43:09.603] iteration 12701: loss: 0.051386, loss_s1: 0.042572, loss_fp: 0.001296, loss_freq: 0.014271
[04:43:10.251] iteration 12702: loss: 0.091618, loss_s1: 0.088138, loss_fp: 0.000672, loss_freq: 0.052909
[04:43:10.902] iteration 12703: loss: 0.087089, loss_s1: 0.069015, loss_fp: 0.002106, loss_freq: 0.052358
[04:43:11.550] iteration 12704: loss: 0.050807, loss_s1: 0.049822, loss_fp: 0.002381, loss_freq: 0.011523
[04:43:12.197] iteration 12705: loss: 0.093425, loss_s1: 0.058913, loss_fp: 0.006758, loss_freq: 0.055566
[04:43:12.843] iteration 12706: loss: 0.058883, loss_s1: 0.061385, loss_fp: 0.001875, loss_freq: 0.014538
[04:43:13.483] iteration 12707: loss: 0.080489, loss_s1: 0.080726, loss_fp: 0.003507, loss_freq: 0.045373
[04:43:14.190] iteration 12708: loss: 0.069708, loss_s1: 0.040480, loss_fp: 0.002140, loss_freq: 0.035446
[04:43:14.879] iteration 12709: loss: 0.043623, loss_s1: 0.019052, loss_fp: 0.003967, loss_freq: 0.017540
[04:43:15.517] iteration 12710: loss: 0.083172, loss_s1: 0.046931, loss_fp: 0.005651, loss_freq: 0.070007
[04:43:16.156] iteration 12711: loss: 0.054119, loss_s1: 0.042745, loss_fp: 0.011709, loss_freq: 0.008508
[04:43:16.849] iteration 12712: loss: 0.056246, loss_s1: 0.018905, loss_fp: 0.001265, loss_freq: 0.035787
[04:43:17.544] iteration 12713: loss: 0.111547, loss_s1: 0.120383, loss_fp: 0.002338, loss_freq: 0.050497
[04:43:18.262] iteration 12714: loss: 0.059564, loss_s1: 0.045843, loss_fp: 0.003867, loss_freq: 0.027570
[04:43:18.944] iteration 12715: loss: 0.060983, loss_s1: 0.045760, loss_fp: 0.001983, loss_freq: 0.024880
[04:43:19.640] iteration 12716: loss: 0.051486, loss_s1: 0.048621, loss_fp: 0.005065, loss_freq: 0.019130
[04:43:20.288] iteration 12717: loss: 0.064664, loss_s1: 0.035289, loss_fp: 0.002291, loss_freq: 0.030007
[04:43:20.930] iteration 12718: loss: 0.085797, loss_s1: 0.066500, loss_fp: 0.009705, loss_freq: 0.055368
[04:43:21.573] iteration 12719: loss: 0.105771, loss_s1: 0.099338, loss_fp: 0.009850, loss_freq: 0.063059
[04:43:22.247] iteration 12720: loss: 0.066620, loss_s1: 0.064754, loss_fp: 0.004954, loss_freq: 0.029207
[04:43:22.868] iteration 12721: loss: 0.091116, loss_s1: 0.106252, loss_fp: 0.004697, loss_freq: 0.018196
[04:43:23.493] iteration 12722: loss: 0.104799, loss_s1: 0.121748, loss_fp: 0.006968, loss_freq: 0.030011
[04:43:24.131] iteration 12723: loss: 0.054415, loss_s1: 0.030572, loss_fp: 0.001917, loss_freq: 0.036376
[04:43:24.762] iteration 12724: loss: 0.067251, loss_s1: 0.055221, loss_fp: 0.003313, loss_freq: 0.023654
[04:43:25.429] iteration 12725: loss: 0.052483, loss_s1: 0.032658, loss_fp: 0.003887, loss_freq: 0.024805
[04:43:26.246] iteration 12726: loss: 0.057702, loss_s1: 0.055613, loss_fp: 0.004393, loss_freq: 0.011440
[04:43:27.077] iteration 12727: loss: 0.054365, loss_s1: 0.041513, loss_fp: 0.001148, loss_freq: 0.020482
[04:43:27.787] iteration 12728: loss: 0.089545, loss_s1: 0.078738, loss_fp: 0.007155, loss_freq: 0.053048
[04:43:28.563] iteration 12729: loss: 0.089874, loss_s1: 0.094621, loss_fp: 0.001358, loss_freq: 0.054232
[04:43:29.258] iteration 12730: loss: 0.057706, loss_s1: 0.034603, loss_fp: 0.004508, loss_freq: 0.021297
[04:43:30.002] iteration 12731: loss: 0.070683, loss_s1: 0.053604, loss_fp: 0.001160, loss_freq: 0.033317
[04:43:30.767] iteration 12732: loss: 0.064224, loss_s1: 0.056533, loss_fp: 0.007727, loss_freq: 0.022201
[04:43:31.492] iteration 12733: loss: 0.054070, loss_s1: 0.034621, loss_fp: 0.006663, loss_freq: 0.034987
[04:43:32.320] iteration 12734: loss: 0.061496, loss_s1: 0.048074, loss_fp: 0.004349, loss_freq: 0.032550
[04:43:33.024] iteration 12735: loss: 0.099534, loss_s1: 0.073860, loss_fp: 0.002845, loss_freq: 0.076387
[04:43:33.933] iteration 12736: loss: 0.046069, loss_s1: 0.040384, loss_fp: 0.000703, loss_freq: 0.015516
[04:43:34.684] iteration 12737: loss: 0.058377, loss_s1: 0.038149, loss_fp: 0.004434, loss_freq: 0.030854
[04:43:35.355] iteration 12738: loss: 0.089749, loss_s1: 0.043442, loss_fp: 0.001987, loss_freq: 0.067843
[04:43:36.142] iteration 12739: loss: 0.069819, loss_s1: 0.046669, loss_fp: 0.005987, loss_freq: 0.038058
[04:43:36.851] iteration 12740: loss: 0.073147, loss_s1: 0.053699, loss_fp: 0.005658, loss_freq: 0.035120
[04:43:37.585] iteration 12741: loss: 0.037981, loss_s1: 0.021767, loss_fp: 0.002705, loss_freq: 0.012525
[04:43:38.234] iteration 12742: loss: 0.053223, loss_s1: 0.026436, loss_fp: 0.004116, loss_freq: 0.035028
[04:43:38.847] iteration 12743: loss: 0.050418, loss_s1: 0.035531, loss_fp: 0.001983, loss_freq: 0.010697
[04:43:39.457] iteration 12744: loss: 0.057595, loss_s1: 0.040299, loss_fp: 0.002822, loss_freq: 0.027789
[04:43:40.066] iteration 12745: loss: 0.040194, loss_s1: 0.022667, loss_fp: 0.000477, loss_freq: 0.018658
[04:43:40.672] iteration 12746: loss: 0.067324, loss_s1: 0.079135, loss_fp: 0.002071, loss_freq: 0.027143
[04:43:41.289] iteration 12747: loss: 0.059384, loss_s1: 0.038880, loss_fp: 0.000977, loss_freq: 0.024761
[04:43:41.895] iteration 12748: loss: 0.097646, loss_s1: 0.051010, loss_fp: 0.020858, loss_freq: 0.072413
[04:43:42.500] iteration 12749: loss: 0.049950, loss_s1: 0.040937, loss_fp: 0.003625, loss_freq: 0.015564
[04:43:43.106] iteration 12750: loss: 0.061528, loss_s1: 0.037225, loss_fp: 0.000850, loss_freq: 0.038535
[04:43:44.054] iteration 12751: loss: 0.084158, loss_s1: 0.057106, loss_fp: 0.001033, loss_freq: 0.029542
[04:43:44.660] iteration 12752: loss: 0.065589, loss_s1: 0.054064, loss_fp: 0.002637, loss_freq: 0.022789
[04:43:45.271] iteration 12753: loss: 0.065622, loss_s1: 0.068033, loss_fp: 0.001263, loss_freq: 0.025359
[04:43:45.893] iteration 12754: loss: 0.054393, loss_s1: 0.055723, loss_fp: 0.002604, loss_freq: 0.010908
[04:43:46.504] iteration 12755: loss: 0.060804, loss_s1: 0.069452, loss_fp: 0.004725, loss_freq: 0.011685
[04:43:47.133] iteration 12756: loss: 0.069581, loss_s1: 0.049884, loss_fp: 0.002066, loss_freq: 0.030783
[04:43:47.759] iteration 12757: loss: 0.093898, loss_s1: 0.083133, loss_fp: 0.019056, loss_freq: 0.042801
[04:43:48.385] iteration 12758: loss: 0.059542, loss_s1: 0.041624, loss_fp: 0.004027, loss_freq: 0.016873
[04:43:48.998] iteration 12759: loss: 0.059729, loss_s1: 0.045140, loss_fp: 0.001982, loss_freq: 0.019819
[04:43:49.623] iteration 12760: loss: 0.085095, loss_s1: 0.067038, loss_fp: 0.004409, loss_freq: 0.034033
[04:43:50.247] iteration 12761: loss: 0.121887, loss_s1: 0.070034, loss_fp: 0.003954, loss_freq: 0.045763
[04:43:50.855] iteration 12762: loss: 0.123150, loss_s1: 0.102358, loss_fp: 0.001601, loss_freq: 0.103331
[04:43:51.487] iteration 12763: loss: 0.041807, loss_s1: 0.019287, loss_fp: 0.001545, loss_freq: 0.016037
[04:43:52.110] iteration 12764: loss: 0.066410, loss_s1: 0.025267, loss_fp: 0.003718, loss_freq: 0.052575
[04:43:52.732] iteration 12765: loss: 0.068137, loss_s1: 0.034280, loss_fp: 0.001806, loss_freq: 0.037393
[04:43:53.346] iteration 12766: loss: 0.058677, loss_s1: 0.035049, loss_fp: 0.001886, loss_freq: 0.043868
[04:43:53.951] iteration 12767: loss: 0.145748, loss_s1: 0.088610, loss_fp: 0.003023, loss_freq: 0.163487
[04:43:54.868] iteration 12768: loss: 0.043686, loss_s1: 0.031458, loss_fp: 0.001477, loss_freq: 0.009402
[04:43:55.834] iteration 12769: loss: 0.089029, loss_s1: 0.110848, loss_fp: 0.006173, loss_freq: 0.027240
[04:43:56.767] iteration 12770: loss: 0.074935, loss_s1: 0.060992, loss_fp: 0.001163, loss_freq: 0.036437
[04:43:57.442] iteration 12771: loss: 0.034859, loss_s1: 0.012534, loss_fp: 0.002859, loss_freq: 0.014642
[04:43:58.072] iteration 12772: loss: 0.085568, loss_s1: 0.064043, loss_fp: 0.004438, loss_freq: 0.066111
[04:43:58.690] iteration 12773: loss: 0.083053, loss_s1: 0.034053, loss_fp: 0.002285, loss_freq: 0.028677
[04:43:59.307] iteration 12774: loss: 0.061180, loss_s1: 0.055481, loss_fp: 0.003180, loss_freq: 0.021871
[04:43:59.917] iteration 12775: loss: 0.096461, loss_s1: 0.050734, loss_fp: 0.000641, loss_freq: 0.057643
[04:44:00.549] iteration 12776: loss: 0.068549, loss_s1: 0.037294, loss_fp: 0.004146, loss_freq: 0.040719
[04:44:01.160] iteration 12777: loss: 0.102666, loss_s1: 0.102416, loss_fp: 0.007716, loss_freq: 0.053060
[04:44:01.798] iteration 12778: loss: 0.109062, loss_s1: 0.082536, loss_fp: 0.008605, loss_freq: 0.074976
[04:44:02.431] iteration 12779: loss: 0.074015, loss_s1: 0.056205, loss_fp: 0.004267, loss_freq: 0.034070
[04:44:03.061] iteration 12780: loss: 0.093034, loss_s1: 0.098995, loss_fp: 0.003751, loss_freq: 0.043775
[04:44:03.692] iteration 12781: loss: 0.064017, loss_s1: 0.036786, loss_fp: 0.001654, loss_freq: 0.047416
[04:44:04.319] iteration 12782: loss: 0.072879, loss_s1: 0.042590, loss_fp: 0.002296, loss_freq: 0.042556
[04:44:04.952] iteration 12783: loss: 0.085795, loss_s1: 0.074933, loss_fp: 0.002500, loss_freq: 0.050730
[04:44:05.565] iteration 12784: loss: 0.047157, loss_s1: 0.035410, loss_fp: 0.001624, loss_freq: 0.019255
[04:44:06.190] iteration 12785: loss: 0.069275, loss_s1: 0.048089, loss_fp: 0.001855, loss_freq: 0.045931
[04:44:06.807] iteration 12786: loss: 0.064255, loss_s1: 0.033032, loss_fp: 0.003559, loss_freq: 0.029012
[04:44:07.421] iteration 12787: loss: 0.057234, loss_s1: 0.044461, loss_fp: 0.002386, loss_freq: 0.020272
[04:44:08.041] iteration 12788: loss: 0.048798, loss_s1: 0.045713, loss_fp: 0.003713, loss_freq: 0.011823
[04:44:08.658] iteration 12789: loss: 0.152142, loss_s1: 0.168555, loss_fp: 0.005829, loss_freq: 0.078171
[04:44:09.271] iteration 12790: loss: 0.073104, loss_s1: 0.061059, loss_fp: 0.009892, loss_freq: 0.035810
[04:44:09.887] iteration 12791: loss: 0.079449, loss_s1: 0.059334, loss_fp: 0.003116, loss_freq: 0.047532
[04:44:10.504] iteration 12792: loss: 0.083628, loss_s1: 0.096474, loss_fp: 0.001970, loss_freq: 0.028967
[04:44:11.121] iteration 12793: loss: 0.092709, loss_s1: 0.099525, loss_fp: 0.001387, loss_freq: 0.050640
[04:44:11.735] iteration 12794: loss: 0.132029, loss_s1: 0.127351, loss_fp: 0.002843, loss_freq: 0.094546
[04:44:12.357] iteration 12795: loss: 0.079762, loss_s1: 0.066939, loss_fp: 0.004403, loss_freq: 0.025906
[04:44:12.973] iteration 12796: loss: 0.079330, loss_s1: 0.045177, loss_fp: 0.014105, loss_freq: 0.051441
[04:44:13.624] iteration 12797: loss: 0.057308, loss_s1: 0.023283, loss_fp: 0.001348, loss_freq: 0.046818
[04:44:14.244] iteration 12798: loss: 0.080353, loss_s1: 0.052438, loss_fp: 0.004929, loss_freq: 0.059465
[04:44:14.851] iteration 12799: loss: 0.074406, loss_s1: 0.086322, loss_fp: 0.000985, loss_freq: 0.018297
[04:44:15.457] iteration 12800: loss: 0.041977, loss_s1: 0.025388, loss_fp: 0.003482, loss_freq: 0.010357
[04:44:18.852] iteration 12800 : mean_dice : 0.717903
[04:44:19.510] iteration 12801: loss: 0.047302, loss_s1: 0.027241, loss_fp: 0.002078, loss_freq: 0.015104
[04:44:20.124] iteration 12802: loss: 0.085626, loss_s1: 0.070526, loss_fp: 0.005266, loss_freq: 0.054464
[04:44:20.759] iteration 12803: loss: 0.069457, loss_s1: 0.040892, loss_fp: 0.003756, loss_freq: 0.035053
[04:44:21.388] iteration 12804: loss: 0.080169, loss_s1: 0.055618, loss_fp: 0.003813, loss_freq: 0.054445
[04:44:22.007] iteration 12805: loss: 0.079776, loss_s1: 0.050729, loss_fp: 0.001906, loss_freq: 0.053393
[04:44:22.624] iteration 12806: loss: 0.079221, loss_s1: 0.057022, loss_fp: 0.001792, loss_freq: 0.020963
[04:44:23.280] iteration 12807: loss: 0.064660, loss_s1: 0.052544, loss_fp: 0.005758, loss_freq: 0.040800
[04:44:23.929] iteration 12808: loss: 0.078804, loss_s1: 0.060820, loss_fp: 0.000730, loss_freq: 0.041251
[04:44:24.549] iteration 12809: loss: 0.039838, loss_s1: 0.017629, loss_fp: 0.001850, loss_freq: 0.025018
[04:44:25.167] iteration 12810: loss: 0.106481, loss_s1: 0.079691, loss_fp: 0.004655, loss_freq: 0.064988
[04:44:25.784] iteration 12811: loss: 0.038674, loss_s1: 0.033694, loss_fp: 0.001376, loss_freq: 0.010166
[04:44:26.407] iteration 12812: loss: 0.104737, loss_s1: 0.093827, loss_fp: 0.003787, loss_freq: 0.048517
[04:44:27.019] iteration 12813: loss: 0.045186, loss_s1: 0.024370, loss_fp: 0.001524, loss_freq: 0.014776
[04:44:27.629] iteration 12814: loss: 0.051793, loss_s1: 0.036816, loss_fp: 0.002768, loss_freq: 0.016356
[04:44:28.248] iteration 12815: loss: 0.179230, loss_s1: 0.241383, loss_fp: 0.005296, loss_freq: 0.011994
[04:44:28.862] iteration 12816: loss: 0.075467, loss_s1: 0.043481, loss_fp: 0.004463, loss_freq: 0.068865
[04:44:29.475] iteration 12817: loss: 0.049617, loss_s1: 0.021247, loss_fp: 0.000985, loss_freq: 0.010418
[04:44:30.100] iteration 12818: loss: 0.105291, loss_s1: 0.083910, loss_fp: 0.005336, loss_freq: 0.065960
[04:44:30.723] iteration 12819: loss: 0.058640, loss_s1: 0.038964, loss_fp: 0.001086, loss_freq: 0.028138
[04:44:31.365] iteration 12820: loss: 0.071554, loss_s1: 0.088364, loss_fp: 0.001430, loss_freq: 0.022374
[04:44:31.979] iteration 12821: loss: 0.067421, loss_s1: 0.062807, loss_fp: 0.002670, loss_freq: 0.031662
[04:44:32.592] iteration 12822: loss: 0.056906, loss_s1: 0.037827, loss_fp: 0.003720, loss_freq: 0.029713
[04:44:33.207] iteration 12823: loss: 0.054466, loss_s1: 0.043235, loss_fp: 0.001948, loss_freq: 0.030975
[04:44:33.819] iteration 12824: loss: 0.086897, loss_s1: 0.094741, loss_fp: 0.004829, loss_freq: 0.023606
[04:44:34.430] iteration 12825: loss: 0.058478, loss_s1: 0.030188, loss_fp: 0.001029, loss_freq: 0.051144
[04:44:35.077] iteration 12826: loss: 0.079992, loss_s1: 0.045304, loss_fp: 0.008279, loss_freq: 0.058563
[04:44:35.742] iteration 12827: loss: 0.067573, loss_s1: 0.057059, loss_fp: 0.004543, loss_freq: 0.024055
[04:44:36.404] iteration 12828: loss: 0.089036, loss_s1: 0.080020, loss_fp: 0.001638, loss_freq: 0.033464
[04:44:37.059] iteration 12829: loss: 0.057789, loss_s1: 0.055750, loss_fp: 0.002319, loss_freq: 0.023011
[04:44:37.718] iteration 12830: loss: 0.067907, loss_s1: 0.045285, loss_fp: 0.003697, loss_freq: 0.030172
[04:44:38.339] iteration 12831: loss: 0.084579, loss_s1: 0.091297, loss_fp: 0.004434, loss_freq: 0.021404
[04:44:38.956] iteration 12832: loss: 0.056452, loss_s1: 0.031303, loss_fp: 0.003975, loss_freq: 0.036693
[04:44:39.558] iteration 12833: loss: 0.067888, loss_s1: 0.066292, loss_fp: 0.004333, loss_freq: 0.018345
[04:44:40.164] iteration 12834: loss: 0.073535, loss_s1: 0.069466, loss_fp: 0.004528, loss_freq: 0.016689
[04:44:40.777] iteration 12835: loss: 0.090868, loss_s1: 0.113384, loss_fp: 0.002434, loss_freq: 0.021939
[04:44:41.385] iteration 12836: loss: 0.053436, loss_s1: 0.035908, loss_fp: 0.000845, loss_freq: 0.015274
[04:44:41.993] iteration 12837: loss: 0.070566, loss_s1: 0.072098, loss_fp: 0.005697, loss_freq: 0.036369
[04:44:42.636] iteration 12838: loss: 0.070210, loss_s1: 0.057473, loss_fp: 0.002822, loss_freq: 0.029319
[04:44:43.248] iteration 12839: loss: 0.071079, loss_s1: 0.058155, loss_fp: 0.004580, loss_freq: 0.045783
[04:44:43.858] iteration 12840: loss: 0.072763, loss_s1: 0.057568, loss_fp: 0.004186, loss_freq: 0.028550
[04:44:44.467] iteration 12841: loss: 0.090749, loss_s1: 0.087805, loss_fp: 0.003789, loss_freq: 0.048826
[04:44:45.079] iteration 12842: loss: 0.067527, loss_s1: 0.052530, loss_fp: 0.001677, loss_freq: 0.039268
[04:44:45.694] iteration 12843: loss: 0.079658, loss_s1: 0.075742, loss_fp: 0.003096, loss_freq: 0.024610
[04:44:46.316] iteration 12844: loss: 0.044684, loss_s1: 0.033410, loss_fp: 0.001965, loss_freq: 0.015975
[04:44:46.928] iteration 12845: loss: 0.078084, loss_s1: 0.072145, loss_fp: 0.003356, loss_freq: 0.027636
[04:44:47.545] iteration 12846: loss: 0.077158, loss_s1: 0.064607, loss_fp: 0.000775, loss_freq: 0.054253
[04:44:48.161] iteration 12847: loss: 0.110639, loss_s1: 0.083472, loss_fp: 0.005497, loss_freq: 0.064773
[04:44:48.779] iteration 12848: loss: 0.069185, loss_s1: 0.049350, loss_fp: 0.001949, loss_freq: 0.037135
[04:44:49.389] iteration 12849: loss: 0.107599, loss_s1: 0.060595, loss_fp: 0.001039, loss_freq: 0.111065
[04:44:50.013] iteration 12850: loss: 0.077085, loss_s1: 0.049513, loss_fp: 0.003330, loss_freq: 0.050967
[04:44:50.626] iteration 12851: loss: 0.062701, loss_s1: 0.049388, loss_fp: 0.003037, loss_freq: 0.040472
[04:44:51.313] iteration 12852: loss: 0.074436, loss_s1: 0.056026, loss_fp: 0.003800, loss_freq: 0.036557
[04:44:51.928] iteration 12853: loss: 0.059484, loss_s1: 0.042575, loss_fp: 0.000939, loss_freq: 0.028608
[04:44:52.543] iteration 12854: loss: 0.046720, loss_s1: 0.030088, loss_fp: 0.001503, loss_freq: 0.023684
[04:44:53.155] iteration 12855: loss: 0.072683, loss_s1: 0.078835, loss_fp: 0.002370, loss_freq: 0.019214
[04:44:53.774] iteration 12856: loss: 0.075360, loss_s1: 0.062472, loss_fp: 0.005371, loss_freq: 0.028042
[04:44:54.390] iteration 12857: loss: 0.067707, loss_s1: 0.061129, loss_fp: 0.002443, loss_freq: 0.027662
[04:44:55.050] iteration 12858: loss: 0.065458, loss_s1: 0.054347, loss_fp: 0.010583, loss_freq: 0.023054
[04:44:55.773] iteration 12859: loss: 0.087150, loss_s1: 0.033624, loss_fp: 0.007834, loss_freq: 0.079870
[04:44:56.537] iteration 12860: loss: 0.073078, loss_s1: 0.050749, loss_fp: 0.002033, loss_freq: 0.050454
[04:44:57.158] iteration 12861: loss: 0.077304, loss_s1: 0.016718, loss_fp: 0.005342, loss_freq: 0.094173
[04:44:57.783] iteration 12862: loss: 0.097878, loss_s1: 0.034107, loss_fp: 0.002622, loss_freq: 0.044488
[04:44:58.411] iteration 12863: loss: 0.081745, loss_s1: 0.063071, loss_fp: 0.008952, loss_freq: 0.036845
[04:44:59.031] iteration 12864: loss: 0.068937, loss_s1: 0.058901, loss_fp: 0.013957, loss_freq: 0.029745
[04:44:59.652] iteration 12865: loss: 0.086123, loss_s1: 0.051936, loss_fp: 0.007505, loss_freq: 0.058724
[04:45:00.273] iteration 12866: loss: 0.096639, loss_s1: 0.046106, loss_fp: 0.002160, loss_freq: 0.084708
[04:45:00.896] iteration 12867: loss: 0.099409, loss_s1: 0.110825, loss_fp: 0.002973, loss_freq: 0.035444
[04:45:01.527] iteration 12868: loss: 0.080716, loss_s1: 0.085431, loss_fp: 0.003914, loss_freq: 0.019878
[04:45:02.155] iteration 12869: loss: 0.115545, loss_s1: 0.085959, loss_fp: 0.002341, loss_freq: 0.098079
[04:45:02.779] iteration 12870: loss: 0.061647, loss_s1: 0.052099, loss_fp: 0.001076, loss_freq: 0.014738
[04:45:03.400] iteration 12871: loss: 0.044591, loss_s1: 0.029401, loss_fp: 0.001636, loss_freq: 0.008629
[04:45:04.024] iteration 12872: loss: 0.094583, loss_s1: 0.120878, loss_fp: 0.002335, loss_freq: 0.037771
[04:45:04.674] iteration 12873: loss: 0.079665, loss_s1: 0.034073, loss_fp: 0.009095, loss_freq: 0.063810
[04:45:05.303] iteration 12874: loss: 0.043183, loss_s1: 0.030371, loss_fp: 0.000677, loss_freq: 0.020455
[04:45:05.929] iteration 12875: loss: 0.069480, loss_s1: 0.038342, loss_fp: 0.005779, loss_freq: 0.049665
[04:45:06.558] iteration 12876: loss: 0.068339, loss_s1: 0.061064, loss_fp: 0.002640, loss_freq: 0.027550
[04:45:07.187] iteration 12877: loss: 0.089331, loss_s1: 0.042258, loss_fp: 0.002095, loss_freq: 0.103705
[04:45:07.843] iteration 12878: loss: 0.067554, loss_s1: 0.055524, loss_fp: 0.001636, loss_freq: 0.017181
[04:45:08.470] iteration 12879: loss: 0.082106, loss_s1: 0.072406, loss_fp: 0.002600, loss_freq: 0.023982
[04:45:09.168] iteration 12880: loss: 0.059497, loss_s1: 0.056687, loss_fp: 0.004041, loss_freq: 0.020250
[04:45:09.857] iteration 12881: loss: 0.059843, loss_s1: 0.063709, loss_fp: 0.001765, loss_freq: 0.012486
[04:45:10.526] iteration 12882: loss: 0.088434, loss_s1: 0.048018, loss_fp: 0.000553, loss_freq: 0.021839
[04:45:11.155] iteration 12883: loss: 0.075310, loss_s1: 0.057691, loss_fp: 0.003870, loss_freq: 0.034773
[04:45:11.785] iteration 12884: loss: 0.065850, loss_s1: 0.070379, loss_fp: 0.001316, loss_freq: 0.017181
[04:45:12.428] iteration 12885: loss: 0.136598, loss_s1: 0.125052, loss_fp: 0.006855, loss_freq: 0.104342
[04:45:13.070] iteration 12886: loss: 0.046801, loss_s1: 0.036718, loss_fp: 0.000544, loss_freq: 0.020366
[04:45:13.685] iteration 12887: loss: 0.084214, loss_s1: 0.068511, loss_fp: 0.001038, loss_freq: 0.019757
[04:45:14.334] iteration 12888: loss: 0.090906, loss_s1: 0.058472, loss_fp: 0.006749, loss_freq: 0.081943
[04:45:14.988] iteration 12889: loss: 0.141954, loss_s1: 0.200623, loss_fp: 0.006514, loss_freq: 0.043126
[04:45:15.656] iteration 12890: loss: 0.059209, loss_s1: 0.056676, loss_fp: 0.006413, loss_freq: 0.022852
[04:45:16.316] iteration 12891: loss: 0.055176, loss_s1: 0.040163, loss_fp: 0.004744, loss_freq: 0.010329
[04:45:16.955] iteration 12892: loss: 0.073725, loss_s1: 0.064353, loss_fp: 0.003038, loss_freq: 0.035464
[04:45:17.560] iteration 12893: loss: 0.072204, loss_s1: 0.063183, loss_fp: 0.003165, loss_freq: 0.037617
[04:45:18.167] iteration 12894: loss: 0.064829, loss_s1: 0.063544, loss_fp: 0.003610, loss_freq: 0.015771
[04:45:18.775] iteration 12895: loss: 0.067755, loss_s1: 0.059783, loss_fp: 0.002109, loss_freq: 0.038074
[04:45:19.378] iteration 12896: loss: 0.062978, loss_s1: 0.051435, loss_fp: 0.005190, loss_freq: 0.021052
[04:45:19.985] iteration 12897: loss: 0.065572, loss_s1: 0.038031, loss_fp: 0.004817, loss_freq: 0.029472
[04:45:20.594] iteration 12898: loss: 0.093075, loss_s1: 0.113808, loss_fp: 0.003779, loss_freq: 0.026162
[04:45:21.197] iteration 12899: loss: 0.082494, loss_s1: 0.061822, loss_fp: 0.003116, loss_freq: 0.039740
[04:45:21.806] iteration 12900: loss: 0.074511, loss_s1: 0.036199, loss_fp: 0.008252, loss_freq: 0.048810
[04:45:22.414] iteration 12901: loss: 0.088089, loss_s1: 0.078806, loss_fp: 0.004478, loss_freq: 0.037034
[04:45:23.019] iteration 12902: loss: 0.071148, loss_s1: 0.073713, loss_fp: 0.001776, loss_freq: 0.025720
[04:45:23.625] iteration 12903: loss: 0.097101, loss_s1: 0.075207, loss_fp: 0.010095, loss_freq: 0.044698
[04:45:24.235] iteration 12904: loss: 0.061075, loss_s1: 0.057194, loss_fp: 0.003392, loss_freq: 0.025107
[04:45:24.841] iteration 12905: loss: 0.095191, loss_s1: 0.081051, loss_fp: 0.005455, loss_freq: 0.050865
[04:45:25.448] iteration 12906: loss: 0.072491, loss_s1: 0.036395, loss_fp: 0.002056, loss_freq: 0.055272
[04:45:26.060] iteration 12907: loss: 0.069618, loss_s1: 0.033473, loss_fp: 0.003957, loss_freq: 0.027375
[04:45:26.673] iteration 12908: loss: 0.107014, loss_s1: 0.127132, loss_fp: 0.005839, loss_freq: 0.046975
[04:45:27.284] iteration 12909: loss: 0.089535, loss_s1: 0.088161, loss_fp: 0.004726, loss_freq: 0.037792
[04:45:27.898] iteration 12910: loss: 0.082179, loss_s1: 0.071011, loss_fp: 0.004467, loss_freq: 0.043887
[04:45:28.520] iteration 12911: loss: 0.043951, loss_s1: 0.026379, loss_fp: 0.002138, loss_freq: 0.007399
[04:45:29.179] iteration 12912: loss: 0.060732, loss_s1: 0.062336, loss_fp: 0.003745, loss_freq: 0.021392
[04:45:29.833] iteration 12913: loss: 0.050262, loss_s1: 0.022725, loss_fp: 0.001404, loss_freq: 0.028118
[04:45:30.485] iteration 12914: loss: 0.052767, loss_s1: 0.032893, loss_fp: 0.001607, loss_freq: 0.027214
[04:45:31.117] iteration 12915: loss: 0.039148, loss_s1: 0.024228, loss_fp: 0.002159, loss_freq: 0.010109
[04:45:31.726] iteration 12916: loss: 0.068430, loss_s1: 0.058726, loss_fp: 0.010798, loss_freq: 0.034919
[04:45:32.344] iteration 12917: loss: 0.120645, loss_s1: 0.096449, loss_fp: 0.001112, loss_freq: 0.050204
[04:45:32.957] iteration 12918: loss: 0.115767, loss_s1: 0.135504, loss_fp: 0.005499, loss_freq: 0.047498
[04:45:33.565] iteration 12919: loss: 0.109958, loss_s1: 0.107983, loss_fp: 0.004144, loss_freq: 0.067012
[04:45:34.167] iteration 12920: loss: 0.090350, loss_s1: 0.087130, loss_fp: 0.007575, loss_freq: 0.044967
[04:45:35.111] iteration 12921: loss: 0.069874, loss_s1: 0.056117, loss_fp: 0.003557, loss_freq: 0.024226
[04:45:35.739] iteration 12922: loss: 0.061666, loss_s1: 0.015663, loss_fp: 0.002183, loss_freq: 0.060339
[04:45:36.360] iteration 12923: loss: 0.049781, loss_s1: 0.026301, loss_fp: 0.004523, loss_freq: 0.033803
[04:45:36.968] iteration 12924: loss: 0.057777, loss_s1: 0.045045, loss_fp: 0.002801, loss_freq: 0.020878
[04:45:37.573] iteration 12925: loss: 0.053181, loss_s1: 0.042982, loss_fp: 0.002479, loss_freq: 0.026749
[04:45:38.187] iteration 12926: loss: 0.081080, loss_s1: 0.089762, loss_fp: 0.001362, loss_freq: 0.023900
[04:45:38.807] iteration 12927: loss: 0.094857, loss_s1: 0.100015, loss_fp: 0.001791, loss_freq: 0.047171
[04:45:39.411] iteration 12928: loss: 0.070804, loss_s1: 0.066226, loss_fp: 0.001362, loss_freq: 0.037651
[04:45:40.019] iteration 12929: loss: 0.061855, loss_s1: 0.051278, loss_fp: 0.003668, loss_freq: 0.029644
[04:45:40.626] iteration 12930: loss: 0.089431, loss_s1: 0.082937, loss_fp: 0.002716, loss_freq: 0.036085
[04:45:41.239] iteration 12931: loss: 0.084253, loss_s1: 0.058039, loss_fp: 0.001158, loss_freq: 0.060362
[04:45:41.851] iteration 12932: loss: 0.119922, loss_s1: 0.097848, loss_fp: 0.018267, loss_freq: 0.084852
[04:45:42.460] iteration 12933: loss: 0.123373, loss_s1: 0.046983, loss_fp: 0.004548, loss_freq: 0.089659
[04:45:43.085] iteration 12934: loss: 0.068007, loss_s1: 0.031695, loss_fp: 0.011568, loss_freq: 0.036903
[04:45:43.704] iteration 12935: loss: 0.096691, loss_s1: 0.108697, loss_fp: 0.003576, loss_freq: 0.040323
[04:45:44.313] iteration 12936: loss: 0.095449, loss_s1: 0.089724, loss_fp: 0.003357, loss_freq: 0.041641
[04:45:44.926] iteration 12937: loss: 0.128214, loss_s1: 0.105812, loss_fp: 0.007474, loss_freq: 0.108692
[04:45:45.536] iteration 12938: loss: 0.049337, loss_s1: 0.027210, loss_fp: 0.002737, loss_freq: 0.011469
[04:45:46.143] iteration 12939: loss: 0.071391, loss_s1: 0.055708, loss_fp: 0.008133, loss_freq: 0.036152
[04:45:46.757] iteration 12940: loss: 0.074727, loss_s1: 0.058276, loss_fp: 0.002777, loss_freq: 0.029120
[04:45:47.371] iteration 12941: loss: 0.083657, loss_s1: 0.060307, loss_fp: 0.002187, loss_freq: 0.045035
[04:45:47.980] iteration 12942: loss: 0.055368, loss_s1: 0.044706, loss_fp: 0.004085, loss_freq: 0.031336
[04:45:48.587] iteration 12943: loss: 0.103711, loss_s1: 0.074086, loss_fp: 0.001857, loss_freq: 0.046773
[04:45:49.194] iteration 12944: loss: 0.065406, loss_s1: 0.061102, loss_fp: 0.001433, loss_freq: 0.022022
[04:45:49.800] iteration 12945: loss: 0.070851, loss_s1: 0.044956, loss_fp: 0.001780, loss_freq: 0.032288
[04:45:50.410] iteration 12946: loss: 0.063015, loss_s1: 0.052141, loss_fp: 0.002133, loss_freq: 0.038977
[04:45:51.017] iteration 12947: loss: 0.079916, loss_s1: 0.085756, loss_fp: 0.006625, loss_freq: 0.018072
[04:45:51.632] iteration 12948: loss: 0.097906, loss_s1: 0.102184, loss_fp: 0.002475, loss_freq: 0.030879
[04:45:52.243] iteration 12949: loss: 0.068164, loss_s1: 0.036550, loss_fp: 0.003443, loss_freq: 0.052139
[04:45:52.852] iteration 12950: loss: 0.063187, loss_s1: 0.050462, loss_fp: 0.006434, loss_freq: 0.026207
[04:45:53.461] iteration 12951: loss: 0.083533, loss_s1: 0.066257, loss_fp: 0.001675, loss_freq: 0.057895
[04:45:54.106] iteration 12952: loss: 0.126058, loss_s1: 0.110905, loss_fp: 0.006908, loss_freq: 0.072245
[04:45:54.729] iteration 12953: loss: 0.065796, loss_s1: 0.035056, loss_fp: 0.005659, loss_freq: 0.038525
[04:45:55.340] iteration 12954: loss: 0.054886, loss_s1: 0.038713, loss_fp: 0.003724, loss_freq: 0.012861
[04:45:55.963] iteration 12955: loss: 0.072581, loss_s1: 0.074228, loss_fp: 0.001462, loss_freq: 0.042561
[04:45:56.577] iteration 12956: loss: 0.046869, loss_s1: 0.020462, loss_fp: 0.002374, loss_freq: 0.009692
[04:45:57.189] iteration 12957: loss: 0.057345, loss_s1: 0.044130, loss_fp: 0.010211, loss_freq: 0.017920
[04:45:57.805] iteration 12958: loss: 0.057636, loss_s1: 0.055383, loss_fp: 0.007773, loss_freq: 0.016415
[04:45:58.413] iteration 12959: loss: 0.083355, loss_s1: 0.077138, loss_fp: 0.005826, loss_freq: 0.035152
[04:45:59.019] iteration 12960: loss: 0.081930, loss_s1: 0.092960, loss_fp: 0.004046, loss_freq: 0.024629
[04:45:59.624] iteration 12961: loss: 0.101703, loss_s1: 0.100140, loss_fp: 0.002498, loss_freq: 0.024701
[04:46:00.229] iteration 12962: loss: 0.064504, loss_s1: 0.051346, loss_fp: 0.002772, loss_freq: 0.036428
[04:46:00.853] iteration 12963: loss: 0.097486, loss_s1: 0.113938, loss_fp: 0.002047, loss_freq: 0.045134
[04:46:01.493] iteration 12964: loss: 0.132132, loss_s1: 0.117886, loss_fp: 0.002440, loss_freq: 0.102548
[04:46:02.162] iteration 12965: loss: 0.061703, loss_s1: 0.038615, loss_fp: 0.005171, loss_freq: 0.038327
[04:46:02.807] iteration 12966: loss: 0.052005, loss_s1: 0.040200, loss_fp: 0.004974, loss_freq: 0.013527
[04:46:03.483] iteration 12967: loss: 0.062569, loss_s1: 0.014942, loss_fp: 0.002897, loss_freq: 0.034575
[04:46:04.146] iteration 12968: loss: 0.063532, loss_s1: 0.052608, loss_fp: 0.003440, loss_freq: 0.037418
[04:46:04.803] iteration 12969: loss: 0.051503, loss_s1: 0.044254, loss_fp: 0.000968, loss_freq: 0.009608
[04:46:05.472] iteration 12970: loss: 0.058904, loss_s1: 0.063983, loss_fp: 0.000741, loss_freq: 0.009836
[04:46:06.129] iteration 12971: loss: 0.061472, loss_s1: 0.031143, loss_fp: 0.004059, loss_freq: 0.048216
[04:46:06.787] iteration 12972: loss: 0.089628, loss_s1: 0.083400, loss_fp: 0.002108, loss_freq: 0.054983
[04:46:07.441] iteration 12973: loss: 0.040779, loss_s1: 0.019902, loss_fp: 0.001369, loss_freq: 0.021760
[04:46:08.091] iteration 12974: loss: 0.073238, loss_s1: 0.048520, loss_fp: 0.006867, loss_freq: 0.049964
[04:46:08.706] iteration 12975: loss: 0.064173, loss_s1: 0.027942, loss_fp: 0.003967, loss_freq: 0.031048
[04:46:09.321] iteration 12976: loss: 0.041046, loss_s1: 0.026685, loss_fp: 0.000787, loss_freq: 0.016950
[04:46:09.932] iteration 12977: loss: 0.094593, loss_s1: 0.055178, loss_fp: 0.002011, loss_freq: 0.054423
[04:46:10.546] iteration 12978: loss: 0.054673, loss_s1: 0.033693, loss_fp: 0.001389, loss_freq: 0.021989
[04:46:11.163] iteration 12979: loss: 0.067225, loss_s1: 0.032901, loss_fp: 0.001477, loss_freq: 0.060512
[04:46:11.781] iteration 12980: loss: 0.049957, loss_s1: 0.019915, loss_fp: 0.003943, loss_freq: 0.032288
[04:46:12.390] iteration 12981: loss: 0.047914, loss_s1: 0.051094, loss_fp: 0.004339, loss_freq: 0.009435
[04:46:12.998] iteration 12982: loss: 0.072818, loss_s1: 0.045461, loss_fp: 0.006556, loss_freq: 0.039845
[04:46:13.608] iteration 12983: loss: 0.047297, loss_s1: 0.030253, loss_fp: 0.001471, loss_freq: 0.015124
[04:46:14.214] iteration 12984: loss: 0.056343, loss_s1: 0.044762, loss_fp: 0.002423, loss_freq: 0.025370
[04:46:14.825] iteration 12985: loss: 0.116833, loss_s1: 0.152474, loss_fp: 0.009446, loss_freq: 0.019065
[04:46:15.442] iteration 12986: loss: 0.083075, loss_s1: 0.066118, loss_fp: 0.003781, loss_freq: 0.042679
[04:46:16.051] iteration 12987: loss: 0.045468, loss_s1: 0.032492, loss_fp: 0.002545, loss_freq: 0.012105
[04:46:16.653] iteration 12988: loss: 0.099031, loss_s1: 0.102271, loss_fp: 0.009159, loss_freq: 0.043657
[04:46:17.262] iteration 12989: loss: 0.055488, loss_s1: 0.032821, loss_fp: 0.003681, loss_freq: 0.032263
[04:46:17.880] iteration 12990: loss: 0.078329, loss_s1: 0.077355, loss_fp: 0.007180, loss_freq: 0.033138
[04:46:18.491] iteration 12991: loss: 0.082954, loss_s1: 0.068192, loss_fp: 0.004692, loss_freq: 0.050926
[04:46:19.099] iteration 12992: loss: 0.052741, loss_s1: 0.024818, loss_fp: 0.003120, loss_freq: 0.027244
[04:46:19.713] iteration 12993: loss: 0.067808, loss_s1: 0.058113, loss_fp: 0.003821, loss_freq: 0.030340
[04:46:20.324] iteration 12994: loss: 0.118848, loss_s1: 0.136904, loss_fp: 0.005679, loss_freq: 0.049399
[04:46:20.949] iteration 12995: loss: 0.095926, loss_s1: 0.046842, loss_fp: 0.009946, loss_freq: 0.053226
[04:46:21.562] iteration 12996: loss: 0.067590, loss_s1: 0.043015, loss_fp: 0.013297, loss_freq: 0.035134
[04:46:22.179] iteration 12997: loss: 0.059378, loss_s1: 0.039647, loss_fp: 0.001638, loss_freq: 0.039750
[04:46:22.795] iteration 12998: loss: 0.074752, loss_s1: 0.035997, loss_fp: 0.017724, loss_freq: 0.042115
[04:46:23.403] iteration 12999: loss: 0.066346, loss_s1: 0.054093, loss_fp: 0.002833, loss_freq: 0.040918
[04:46:24.014] iteration 13000: loss: 0.071404, loss_s1: 0.060248, loss_fp: 0.001574, loss_freq: 0.039009
[04:46:27.344] iteration 13000 : mean_dice : 0.707278
[04:46:27.989] iteration 13001: loss: 0.066442, loss_s1: 0.060161, loss_fp: 0.002321, loss_freq: 0.023722
[04:46:28.603] iteration 13002: loss: 0.063363, loss_s1: 0.046938, loss_fp: 0.002596, loss_freq: 0.040932
[04:46:29.211] iteration 13003: loss: 0.085181, loss_s1: 0.068323, loss_fp: 0.002557, loss_freq: 0.031002
[04:46:29.820] iteration 13004: loss: 0.071026, loss_s1: 0.057444, loss_fp: 0.003668, loss_freq: 0.013097
[04:46:30.430] iteration 13005: loss: 0.081005, loss_s1: 0.061605, loss_fp: 0.005740, loss_freq: 0.035657
[04:46:31.035] iteration 13006: loss: 0.057129, loss_s1: 0.036202, loss_fp: 0.012466, loss_freq: 0.022708
[04:46:31.642] iteration 13007: loss: 0.079056, loss_s1: 0.067189, loss_fp: 0.005804, loss_freq: 0.047430
[04:46:32.254] iteration 13008: loss: 0.084809, loss_s1: 0.096175, loss_fp: 0.001603, loss_freq: 0.019830
[04:46:32.859] iteration 13009: loss: 0.046590, loss_s1: 0.026246, loss_fp: 0.002341, loss_freq: 0.027688
[04:46:33.465] iteration 13010: loss: 0.061870, loss_s1: 0.039425, loss_fp: 0.003440, loss_freq: 0.019986
[04:46:34.071] iteration 13011: loss: 0.066868, loss_s1: 0.072442, loss_fp: 0.001581, loss_freq: 0.019260
[04:46:34.684] iteration 13012: loss: 0.083371, loss_s1: 0.071712, loss_fp: 0.004386, loss_freq: 0.053847
[04:46:35.301] iteration 13013: loss: 0.084953, loss_s1: 0.076461, loss_fp: 0.003778, loss_freq: 0.028764
[04:46:35.919] iteration 13014: loss: 0.068640, loss_s1: 0.050961, loss_fp: 0.002031, loss_freq: 0.054078
[04:46:36.521] iteration 13015: loss: 0.063299, loss_s1: 0.048120, loss_fp: 0.001379, loss_freq: 0.028612
[04:46:37.121] iteration 13016: loss: 0.079984, loss_s1: 0.071344, loss_fp: 0.002710, loss_freq: 0.046492
[04:46:37.721] iteration 13017: loss: 0.098412, loss_s1: 0.076141, loss_fp: 0.004406, loss_freq: 0.054179
[04:46:38.324] iteration 13018: loss: 0.095348, loss_s1: 0.087793, loss_fp: 0.002074, loss_freq: 0.044910
[04:46:38.927] iteration 13019: loss: 0.067638, loss_s1: 0.069212, loss_fp: 0.001662, loss_freq: 0.030267
[04:46:39.531] iteration 13020: loss: 0.055541, loss_s1: 0.032217, loss_fp: 0.003310, loss_freq: 0.038323
[04:46:40.134] iteration 13021: loss: 0.083501, loss_s1: 0.078370, loss_fp: 0.010076, loss_freq: 0.036673
[04:46:40.738] iteration 13022: loss: 0.046195, loss_s1: 0.022965, loss_fp: 0.003620, loss_freq: 0.012860
[04:46:41.345] iteration 13023: loss: 0.045993, loss_s1: 0.020652, loss_fp: 0.000889, loss_freq: 0.015451
[04:46:41.949] iteration 13024: loss: 0.058696, loss_s1: 0.029930, loss_fp: 0.004137, loss_freq: 0.031371
[04:46:42.556] iteration 13025: loss: 0.042107, loss_s1: 0.015641, loss_fp: 0.005471, loss_freq: 0.031087
[04:46:43.159] iteration 13026: loss: 0.083319, loss_s1: 0.060001, loss_fp: 0.004021, loss_freq: 0.040782
[04:46:43.771] iteration 13027: loss: 0.065455, loss_s1: 0.042325, loss_fp: 0.007117, loss_freq: 0.028167
[04:46:44.381] iteration 13028: loss: 0.069182, loss_s1: 0.064950, loss_fp: 0.003381, loss_freq: 0.033159
[04:46:44.987] iteration 13029: loss: 0.101879, loss_s1: 0.098761, loss_fp: 0.007683, loss_freq: 0.052457
[04:46:45.592] iteration 13030: loss: 0.060172, loss_s1: 0.047371, loss_fp: 0.005492, loss_freq: 0.030246
[04:46:46.203] iteration 13031: loss: 0.091410, loss_s1: 0.036884, loss_fp: 0.007129, loss_freq: 0.036246
[04:46:46.818] iteration 13032: loss: 0.052302, loss_s1: 0.032212, loss_fp: 0.006051, loss_freq: 0.024319
[04:46:47.425] iteration 13033: loss: 0.060136, loss_s1: 0.055634, loss_fp: 0.001425, loss_freq: 0.029475
[04:46:48.076] iteration 13034: loss: 0.064017, loss_s1: 0.055665, loss_fp: 0.003324, loss_freq: 0.017449
[04:46:48.690] iteration 13035: loss: 0.086052, loss_s1: 0.043973, loss_fp: 0.001986, loss_freq: 0.083043
[04:46:49.301] iteration 13036: loss: 0.094491, loss_s1: 0.051837, loss_fp: 0.004093, loss_freq: 0.062807
[04:46:49.924] iteration 13037: loss: 0.073332, loss_s1: 0.054630, loss_fp: 0.007557, loss_freq: 0.046565
[04:46:50.536] iteration 13038: loss: 0.046303, loss_s1: 0.022277, loss_fp: 0.002377, loss_freq: 0.028162
[04:46:51.144] iteration 13039: loss: 0.119868, loss_s1: 0.074308, loss_fp: 0.003819, loss_freq: 0.122038
[04:46:51.752] iteration 13040: loss: 0.061522, loss_s1: 0.050472, loss_fp: 0.002456, loss_freq: 0.029150
[04:46:52.363] iteration 13041: loss: 0.055725, loss_s1: 0.050891, loss_fp: 0.001761, loss_freq: 0.012062
[04:46:52.965] iteration 13042: loss: 0.049287, loss_s1: 0.053385, loss_fp: 0.000356, loss_freq: 0.017522
[04:46:53.577] iteration 13043: loss: 0.089320, loss_s1: 0.051098, loss_fp: 0.008840, loss_freq: 0.052652
[04:46:54.187] iteration 13044: loss: 0.063511, loss_s1: 0.059101, loss_fp: 0.005007, loss_freq: 0.023120
[04:46:54.798] iteration 13045: loss: 0.100870, loss_s1: 0.085791, loss_fp: 0.002821, loss_freq: 0.049784
[04:46:55.416] iteration 13046: loss: 0.058770, loss_s1: 0.051589, loss_fp: 0.003767, loss_freq: 0.015557
[04:46:56.027] iteration 13047: loss: 0.076183, loss_s1: 0.042554, loss_fp: 0.001334, loss_freq: 0.050438
[04:46:56.643] iteration 13048: loss: 0.080492, loss_s1: 0.021328, loss_fp: 0.003337, loss_freq: 0.053232
[04:46:57.322] iteration 13049: loss: 0.048507, loss_s1: 0.030266, loss_fp: 0.007351, loss_freq: 0.020529
[04:46:58.040] iteration 13050: loss: 0.060798, loss_s1: 0.037589, loss_fp: 0.000648, loss_freq: 0.040098
[04:46:58.667] iteration 13051: loss: 0.067556, loss_s1: 0.073308, loss_fp: 0.001639, loss_freq: 0.031823
[04:46:59.325] iteration 13052: loss: 0.066351, loss_s1: 0.038985, loss_fp: 0.002808, loss_freq: 0.019999
[04:46:59.945] iteration 13053: loss: 0.107651, loss_s1: 0.093082, loss_fp: 0.002224, loss_freq: 0.081545
[04:47:00.553] iteration 13054: loss: 0.071665, loss_s1: 0.075696, loss_fp: 0.001896, loss_freq: 0.031635
[04:47:01.164] iteration 13055: loss: 0.090124, loss_s1: 0.043610, loss_fp: 0.002991, loss_freq: 0.094291
[04:47:01.844] iteration 13056: loss: 0.047780, loss_s1: 0.035975, loss_fp: 0.005919, loss_freq: 0.021121
[04:47:02.499] iteration 13057: loss: 0.063639, loss_s1: 0.049323, loss_fp: 0.001644, loss_freq: 0.012626
[04:47:03.154] iteration 13058: loss: 0.069877, loss_s1: 0.050721, loss_fp: 0.018943, loss_freq: 0.033227
[04:47:03.807] iteration 13059: loss: 0.065438, loss_s1: 0.052694, loss_fp: 0.002626, loss_freq: 0.030550
[04:47:04.455] iteration 13060: loss: 0.069430, loss_s1: 0.079470, loss_fp: 0.007132, loss_freq: 0.021384
[04:47:05.088] iteration 13061: loss: 0.066638, loss_s1: 0.054310, loss_fp: 0.005124, loss_freq: 0.023758
[04:47:05.694] iteration 13062: loss: 0.089427, loss_s1: 0.053962, loss_fp: 0.003157, loss_freq: 0.067424
[04:47:06.301] iteration 13063: loss: 0.059788, loss_s1: 0.041667, loss_fp: 0.008283, loss_freq: 0.021469
[04:47:06.908] iteration 13064: loss: 0.040780, loss_s1: 0.016304, loss_fp: 0.001033, loss_freq: 0.019143
[04:47:07.531] iteration 13065: loss: 0.039963, loss_s1: 0.026241, loss_fp: 0.003713, loss_freq: 0.011053
[04:47:08.184] iteration 13066: loss: 0.060956, loss_s1: 0.039484, loss_fp: 0.004795, loss_freq: 0.035407
[04:47:08.795] iteration 13067: loss: 0.043985, loss_s1: 0.016428, loss_fp: 0.005286, loss_freq: 0.025495
[04:47:09.409] iteration 13068: loss: 0.092327, loss_s1: 0.086275, loss_fp: 0.011345, loss_freq: 0.044863
[04:47:10.025] iteration 13069: loss: 0.056463, loss_s1: 0.062328, loss_fp: 0.002709, loss_freq: 0.016425
[04:47:10.688] iteration 13070: loss: 0.060514, loss_s1: 0.041410, loss_fp: 0.008299, loss_freq: 0.021432
[04:47:11.349] iteration 13071: loss: 0.080439, loss_s1: 0.074971, loss_fp: 0.009735, loss_freq: 0.037727
[04:47:12.048] iteration 13072: loss: 0.086191, loss_s1: 0.113381, loss_fp: 0.004221, loss_freq: 0.016753
[04:47:12.704] iteration 13073: loss: 0.088694, loss_s1: 0.064264, loss_fp: 0.005978, loss_freq: 0.064768
[04:47:13.320] iteration 13074: loss: 0.092947, loss_s1: 0.067094, loss_fp: 0.003666, loss_freq: 0.050330
[04:47:13.936] iteration 13075: loss: 0.102898, loss_s1: 0.062907, loss_fp: 0.009866, loss_freq: 0.087673
[04:47:14.551] iteration 13076: loss: 0.039961, loss_s1: 0.028325, loss_fp: 0.002692, loss_freq: 0.008850
[04:47:15.166] iteration 13077: loss: 0.050150, loss_s1: 0.035491, loss_fp: 0.001416, loss_freq: 0.030076
[04:47:15.781] iteration 13078: loss: 0.111163, loss_s1: 0.113521, loss_fp: 0.001230, loss_freq: 0.068018
[04:47:16.389] iteration 13079: loss: 0.059857, loss_s1: 0.043291, loss_fp: 0.002297, loss_freq: 0.027059
[04:47:16.990] iteration 13080: loss: 0.087087, loss_s1: 0.082972, loss_fp: 0.002140, loss_freq: 0.027419
[04:47:17.595] iteration 13081: loss: 0.054644, loss_s1: 0.049544, loss_fp: 0.003341, loss_freq: 0.018812
[04:47:18.212] iteration 13082: loss: 0.071809, loss_s1: 0.075954, loss_fp: 0.003472, loss_freq: 0.033998
[04:47:18.816] iteration 13083: loss: 0.054198, loss_s1: 0.020604, loss_fp: 0.002401, loss_freq: 0.018740
[04:47:19.445] iteration 13084: loss: 0.064943, loss_s1: 0.065409, loss_fp: 0.004083, loss_freq: 0.021658
[04:47:20.059] iteration 13085: loss: 0.043550, loss_s1: 0.032698, loss_fp: 0.001586, loss_freq: 0.011563
[04:47:20.681] iteration 13086: loss: 0.084594, loss_s1: 0.105591, loss_fp: 0.003258, loss_freq: 0.023296
[04:47:21.300] iteration 13087: loss: 0.102479, loss_s1: 0.040192, loss_fp: 0.002056, loss_freq: 0.040493
[04:47:21.915] iteration 13088: loss: 0.087626, loss_s1: 0.092822, loss_fp: 0.016191, loss_freq: 0.026425
[04:47:22.521] iteration 13089: loss: 0.090765, loss_s1: 0.094735, loss_fp: 0.004256, loss_freq: 0.049535
[04:47:23.131] iteration 13090: loss: 0.086449, loss_s1: 0.082001, loss_fp: 0.005139, loss_freq: 0.044439
[04:47:24.129] iteration 13091: loss: 0.106161, loss_s1: 0.082119, loss_fp: 0.011796, loss_freq: 0.063580
[04:47:24.754] iteration 13092: loss: 0.068373, loss_s1: 0.065070, loss_fp: 0.001881, loss_freq: 0.026990
[04:47:25.374] iteration 13093: loss: 0.084399, loss_s1: 0.073285, loss_fp: 0.001365, loss_freq: 0.027689
[04:47:25.996] iteration 13094: loss: 0.072864, loss_s1: 0.064634, loss_fp: 0.003474, loss_freq: 0.022036
[04:47:26.637] iteration 13095: loss: 0.072567, loss_s1: 0.073039, loss_fp: 0.002873, loss_freq: 0.020534
[04:47:27.251] iteration 13096: loss: 0.102743, loss_s1: 0.093475, loss_fp: 0.005296, loss_freq: 0.041785
[04:47:27.866] iteration 13097: loss: 0.111002, loss_s1: 0.135350, loss_fp: 0.003752, loss_freq: 0.041241
[04:47:28.486] iteration 13098: loss: 0.053394, loss_s1: 0.047601, loss_fp: 0.004177, loss_freq: 0.022217
[04:47:29.105] iteration 13099: loss: 0.072509, loss_s1: 0.072686, loss_fp: 0.004574, loss_freq: 0.042987
[04:47:29.718] iteration 13100: loss: 0.094941, loss_s1: 0.063251, loss_fp: 0.002480, loss_freq: 0.061951
[04:47:30.335] iteration 13101: loss: 0.094233, loss_s1: 0.045587, loss_fp: 0.000854, loss_freq: 0.071092
[04:47:30.939] iteration 13102: loss: 0.097145, loss_s1: 0.075795, loss_fp: 0.002011, loss_freq: 0.077293
[04:47:31.552] iteration 13103: loss: 0.066329, loss_s1: 0.065303, loss_fp: 0.002846, loss_freq: 0.026069
[04:47:32.171] iteration 13104: loss: 0.090133, loss_s1: 0.080607, loss_fp: 0.002487, loss_freq: 0.049423
[04:47:32.789] iteration 13105: loss: 0.109449, loss_s1: 0.156524, loss_fp: 0.000828, loss_freq: 0.023144
[04:47:33.397] iteration 13106: loss: 0.055821, loss_s1: 0.029671, loss_fp: 0.001515, loss_freq: 0.028945
[04:47:34.005] iteration 13107: loss: 0.099797, loss_s1: 0.082089, loss_fp: 0.001131, loss_freq: 0.081468
[04:47:34.614] iteration 13108: loss: 0.062848, loss_s1: 0.054496, loss_fp: 0.000295, loss_freq: 0.007486
[04:47:35.215] iteration 13109: loss: 0.073209, loss_s1: 0.091319, loss_fp: 0.006477, loss_freq: 0.015683
[04:47:35.823] iteration 13110: loss: 0.066936, loss_s1: 0.062154, loss_fp: 0.003349, loss_freq: 0.014828
[04:47:36.438] iteration 13111: loss: 0.047548, loss_s1: 0.027075, loss_fp: 0.006464, loss_freq: 0.025447
[04:47:37.047] iteration 13112: loss: 0.044460, loss_s1: 0.027914, loss_fp: 0.003064, loss_freq: 0.031465
[04:47:37.673] iteration 13113: loss: 0.053904, loss_s1: 0.012693, loss_fp: 0.002995, loss_freq: 0.033644
[04:47:38.326] iteration 13114: loss: 0.050860, loss_s1: 0.031867, loss_fp: 0.003616, loss_freq: 0.019874
[04:47:38.984] iteration 13115: loss: 0.075746, loss_s1: 0.064373, loss_fp: 0.001802, loss_freq: 0.047669
[04:47:39.682] iteration 13116: loss: 0.067978, loss_s1: 0.077189, loss_fp: 0.003847, loss_freq: 0.023605
[04:47:40.340] iteration 13117: loss: 0.085877, loss_s1: 0.060819, loss_fp: 0.001885, loss_freq: 0.030645
[04:47:41.000] iteration 13118: loss: 0.110906, loss_s1: 0.099520, loss_fp: 0.005473, loss_freq: 0.072102
[04:47:41.657] iteration 13119: loss: 0.056030, loss_s1: 0.040857, loss_fp: 0.002175, loss_freq: 0.030854
[04:47:42.284] iteration 13120: loss: 0.076813, loss_s1: 0.068066, loss_fp: 0.002470, loss_freq: 0.043179
[04:47:42.897] iteration 13121: loss: 0.077082, loss_s1: 0.037092, loss_fp: 0.005356, loss_freq: 0.077478
[04:47:43.512] iteration 13122: loss: 0.075126, loss_s1: 0.054094, loss_fp: 0.000992, loss_freq: 0.038919
[04:47:44.127] iteration 13123: loss: 0.070811, loss_s1: 0.057795, loss_fp: 0.001020, loss_freq: 0.047764
[04:47:44.736] iteration 13124: loss: 0.044584, loss_s1: 0.031884, loss_fp: 0.003811, loss_freq: 0.014214
[04:47:45.345] iteration 13125: loss: 0.045742, loss_s1: 0.027608, loss_fp: 0.001959, loss_freq: 0.035923
[04:47:45.956] iteration 13126: loss: 0.054512, loss_s1: 0.043385, loss_fp: 0.000694, loss_freq: 0.014384
[04:47:46.572] iteration 13127: loss: 0.058167, loss_s1: 0.045338, loss_fp: 0.002234, loss_freq: 0.025467
[04:47:47.179] iteration 13128: loss: 0.064795, loss_s1: 0.072066, loss_fp: 0.002537, loss_freq: 0.024066
[04:47:47.803] iteration 13129: loss: 0.102990, loss_s1: 0.078244, loss_fp: 0.000739, loss_freq: 0.084161
[04:47:48.422] iteration 13130: loss: 0.066220, loss_s1: 0.048270, loss_fp: 0.003697, loss_freq: 0.037675
[04:47:49.034] iteration 13131: loss: 0.109323, loss_s1: 0.109694, loss_fp: 0.002946, loss_freq: 0.051988
[04:47:49.665] iteration 13132: loss: 0.074305, loss_s1: 0.055750, loss_fp: 0.001350, loss_freq: 0.029981
[04:47:50.275] iteration 13133: loss: 0.082568, loss_s1: 0.075264, loss_fp: 0.002438, loss_freq: 0.055586
[04:47:50.892] iteration 13134: loss: 0.130044, loss_s1: 0.126346, loss_fp: 0.007300, loss_freq: 0.079814
[04:47:51.570] iteration 13135: loss: 0.092458, loss_s1: 0.067539, loss_fp: 0.002469, loss_freq: 0.051201
[04:47:52.223] iteration 13136: loss: 0.118258, loss_s1: 0.108774, loss_fp: 0.006230, loss_freq: 0.068979
[04:47:52.876] iteration 13137: loss: 0.058589, loss_s1: 0.030433, loss_fp: 0.006729, loss_freq: 0.042363
[04:47:53.484] iteration 13138: loss: 0.063754, loss_s1: 0.063143, loss_fp: 0.002250, loss_freq: 0.030744
[04:47:54.090] iteration 13139: loss: 0.093780, loss_s1: 0.113567, loss_fp: 0.004031, loss_freq: 0.015533
[04:47:54.693] iteration 13140: loss: 0.057385, loss_s1: 0.035073, loss_fp: 0.004209, loss_freq: 0.029252
[04:47:55.299] iteration 13141: loss: 0.087710, loss_s1: 0.062988, loss_fp: 0.002908, loss_freq: 0.049997
[04:47:55.902] iteration 13142: loss: 0.097346, loss_s1: 0.095261, loss_fp: 0.003270, loss_freq: 0.054361
[04:47:56.506] iteration 13143: loss: 0.072312, loss_s1: 0.050636, loss_fp: 0.002073, loss_freq: 0.029616
[04:47:57.113] iteration 13144: loss: 0.061867, loss_s1: 0.028381, loss_fp: 0.009078, loss_freq: 0.038182
[04:47:57.717] iteration 13145: loss: 0.061830, loss_s1: 0.038673, loss_fp: 0.001127, loss_freq: 0.044298
[04:47:58.319] iteration 13146: loss: 0.042593, loss_s1: 0.023915, loss_fp: 0.001607, loss_freq: 0.018354
[04:47:58.924] iteration 13147: loss: 0.059774, loss_s1: 0.065789, loss_fp: 0.003698, loss_freq: 0.022423
[04:47:59.529] iteration 13148: loss: 0.077692, loss_s1: 0.055146, loss_fp: 0.001243, loss_freq: 0.049206
[04:48:00.204] iteration 13149: loss: 0.094979, loss_s1: 0.104930, loss_fp: 0.003501, loss_freq: 0.041709
[04:48:00.818] iteration 13150: loss: 0.056890, loss_s1: 0.038806, loss_fp: 0.002591, loss_freq: 0.033367
[04:48:01.428] iteration 13151: loss: 0.043189, loss_s1: 0.039214, loss_fp: 0.001732, loss_freq: 0.011669
[04:48:02.036] iteration 13152: loss: 0.108978, loss_s1: 0.070964, loss_fp: 0.002479, loss_freq: 0.066880
[04:48:02.645] iteration 13153: loss: 0.059989, loss_s1: 0.055327, loss_fp: 0.002826, loss_freq: 0.010968
[04:48:03.252] iteration 13154: loss: 0.050530, loss_s1: 0.040231, loss_fp: 0.006965, loss_freq: 0.021671
[04:48:03.856] iteration 13155: loss: 0.081331, loss_s1: 0.104838, loss_fp: 0.002595, loss_freq: 0.014290
[04:48:04.521] iteration 13156: loss: 0.061102, loss_s1: 0.049464, loss_fp: 0.001542, loss_freq: 0.028695
[04:48:05.141] iteration 13157: loss: 0.065554, loss_s1: 0.025784, loss_fp: 0.007000, loss_freq: 0.026523
[04:48:05.755] iteration 13158: loss: 0.122257, loss_s1: 0.090959, loss_fp: 0.007377, loss_freq: 0.093496
[04:48:06.361] iteration 13159: loss: 0.063746, loss_s1: 0.043694, loss_fp: 0.004003, loss_freq: 0.039658
[04:48:06.971] iteration 13160: loss: 0.054583, loss_s1: 0.046288, loss_fp: 0.005560, loss_freq: 0.019393
[04:48:07.579] iteration 13161: loss: 0.089985, loss_s1: 0.061744, loss_fp: 0.003021, loss_freq: 0.037946
[04:48:08.193] iteration 13162: loss: 0.076288, loss_s1: 0.054858, loss_fp: 0.005329, loss_freq: 0.046134
[04:48:08.803] iteration 13163: loss: 0.093209, loss_s1: 0.068116, loss_fp: 0.016369, loss_freq: 0.062296
[04:48:09.414] iteration 13164: loss: 0.103682, loss_s1: 0.124677, loss_fp: 0.007568, loss_freq: 0.015458
[04:48:10.020] iteration 13165: loss: 0.095289, loss_s1: 0.054434, loss_fp: 0.002851, loss_freq: 0.078026
[04:48:10.636] iteration 13166: loss: 0.071168, loss_s1: 0.030003, loss_fp: 0.006343, loss_freq: 0.047597
[04:48:11.245] iteration 13167: loss: 0.049353, loss_s1: 0.035417, loss_fp: 0.005192, loss_freq: 0.018157
[04:48:11.857] iteration 13168: loss: 0.120706, loss_s1: 0.088160, loss_fp: 0.001958, loss_freq: 0.025956
[04:48:12.474] iteration 13169: loss: 0.067970, loss_s1: 0.035558, loss_fp: 0.001884, loss_freq: 0.045080
[04:48:13.114] iteration 13170: loss: 0.077487, loss_s1: 0.057001, loss_fp: 0.003748, loss_freq: 0.034215
[04:48:13.767] iteration 13171: loss: 0.074624, loss_s1: 0.059482, loss_fp: 0.001856, loss_freq: 0.033890
[04:48:14.420] iteration 13172: loss: 0.071761, loss_s1: 0.047412, loss_fp: 0.004486, loss_freq: 0.048259
[04:48:15.079] iteration 13173: loss: 0.060254, loss_s1: 0.058411, loss_fp: 0.001616, loss_freq: 0.018575
[04:48:15.731] iteration 13174: loss: 0.079300, loss_s1: 0.086156, loss_fp: 0.003399, loss_freq: 0.022678
[04:48:16.382] iteration 13175: loss: 0.060129, loss_s1: 0.046903, loss_fp: 0.003461, loss_freq: 0.021370
[04:48:17.020] iteration 13176: loss: 0.079475, loss_s1: 0.057809, loss_fp: 0.002337, loss_freq: 0.035597
[04:48:17.636] iteration 13177: loss: 0.101856, loss_s1: 0.117722, loss_fp: 0.004735, loss_freq: 0.053395
[04:48:18.249] iteration 13178: loss: 0.084681, loss_s1: 0.080637, loss_fp: 0.003322, loss_freq: 0.018678
[04:48:18.861] iteration 13179: loss: 0.075825, loss_s1: 0.051044, loss_fp: 0.007703, loss_freq: 0.048261
[04:48:19.484] iteration 13180: loss: 0.101337, loss_s1: 0.131610, loss_fp: 0.003616, loss_freq: 0.014601
[04:48:20.092] iteration 13181: loss: 0.069741, loss_s1: 0.069724, loss_fp: 0.001291, loss_freq: 0.016264
[04:48:20.708] iteration 13182: loss: 0.060734, loss_s1: 0.026722, loss_fp: 0.002024, loss_freq: 0.046353
[04:48:21.330] iteration 13183: loss: 0.077246, loss_s1: 0.033424, loss_fp: 0.009296, loss_freq: 0.038691
[04:48:21.935] iteration 13184: loss: 0.087156, loss_s1: 0.048732, loss_fp: 0.002844, loss_freq: 0.071113
[04:48:22.542] iteration 13185: loss: 0.062577, loss_s1: 0.069023, loss_fp: 0.001287, loss_freq: 0.017370
[04:48:23.151] iteration 13186: loss: 0.072210, loss_s1: 0.070486, loss_fp: 0.000891, loss_freq: 0.038160
[04:48:23.758] iteration 13187: loss: 0.097249, loss_s1: 0.067812, loss_fp: 0.002349, loss_freq: 0.057924
[04:48:24.360] iteration 13188: loss: 0.062733, loss_s1: 0.049213, loss_fp: 0.001891, loss_freq: 0.032701
[04:48:24.971] iteration 13189: loss: 0.090471, loss_s1: 0.079293, loss_fp: 0.004626, loss_freq: 0.055527
[04:48:25.585] iteration 13190: loss: 0.062537, loss_s1: 0.054018, loss_fp: 0.001367, loss_freq: 0.028600
[04:48:26.196] iteration 13191: loss: 0.069953, loss_s1: 0.060078, loss_fp: 0.003159, loss_freq: 0.028215
[04:48:26.803] iteration 13192: loss: 0.051946, loss_s1: 0.021822, loss_fp: 0.003454, loss_freq: 0.023913
[04:48:27.413] iteration 13193: loss: 0.039525, loss_s1: 0.016644, loss_fp: 0.001581, loss_freq: 0.027811
[04:48:28.025] iteration 13194: loss: 0.065669, loss_s1: 0.043762, loss_fp: 0.003242, loss_freq: 0.037271
[04:48:28.636] iteration 13195: loss: 0.079038, loss_s1: 0.051612, loss_fp: 0.004584, loss_freq: 0.063046
[04:48:29.261] iteration 13196: loss: 0.074124, loss_s1: 0.057088, loss_fp: 0.001776, loss_freq: 0.033192
[04:48:29.880] iteration 13197: loss: 0.048797, loss_s1: 0.033287, loss_fp: 0.004052, loss_freq: 0.017786
[04:48:30.588] iteration 13198: loss: 0.067375, loss_s1: 0.026154, loss_fp: 0.002172, loss_freq: 0.033708
[04:48:31.247] iteration 13199: loss: 0.094771, loss_s1: 0.043110, loss_fp: 0.006262, loss_freq: 0.091499
[04:48:31.918] iteration 13200: loss: 0.053107, loss_s1: 0.031079, loss_fp: 0.003633, loss_freq: 0.021927
[04:48:35.225] iteration 13200 : mean_dice : 0.713837
[04:48:35.864] iteration 13201: loss: 0.093550, loss_s1: 0.093595, loss_fp: 0.003004, loss_freq: 0.034341
[04:48:36.467] iteration 13202: loss: 0.059845, loss_s1: 0.029027, loss_fp: 0.003598, loss_freq: 0.037124
[04:48:37.079] iteration 13203: loss: 0.068390, loss_s1: 0.041474, loss_fp: 0.002954, loss_freq: 0.037513
[04:48:37.689] iteration 13204: loss: 0.044337, loss_s1: 0.044342, loss_fp: 0.003975, loss_freq: 0.009440
[04:48:38.303] iteration 13205: loss: 0.097563, loss_s1: 0.060563, loss_fp: 0.003983, loss_freq: 0.065259
[04:48:38.908] iteration 13206: loss: 0.056735, loss_s1: 0.032262, loss_fp: 0.006791, loss_freq: 0.032233
[04:48:39.527] iteration 13207: loss: 0.049843, loss_s1: 0.038360, loss_fp: 0.003161, loss_freq: 0.016749
[04:48:40.139] iteration 13208: loss: 0.062621, loss_s1: 0.072010, loss_fp: 0.005327, loss_freq: 0.015642
[04:48:40.802] iteration 13209: loss: 0.095961, loss_s1: 0.037834, loss_fp: 0.002597, loss_freq: 0.113751
[04:48:41.473] iteration 13210: loss: 0.060010, loss_s1: 0.037467, loss_fp: 0.001781, loss_freq: 0.033527
[04:48:42.134] iteration 13211: loss: 0.062687, loss_s1: 0.042944, loss_fp: 0.001273, loss_freq: 0.015887
[04:48:42.788] iteration 13212: loss: 0.061845, loss_s1: 0.061163, loss_fp: 0.004681, loss_freq: 0.028905
[04:48:43.398] iteration 13213: loss: 0.105917, loss_s1: 0.075279, loss_fp: 0.005295, loss_freq: 0.085438
[04:48:44.007] iteration 13214: loss: 0.081522, loss_s1: 0.032219, loss_fp: 0.003169, loss_freq: 0.090271
[04:48:44.620] iteration 13215: loss: 0.077433, loss_s1: 0.055156, loss_fp: 0.001298, loss_freq: 0.052107
[04:48:45.247] iteration 13216: loss: 0.051492, loss_s1: 0.028512, loss_fp: 0.005826, loss_freq: 0.021401
[04:48:45.862] iteration 13217: loss: 0.095772, loss_s1: 0.079814, loss_fp: 0.003200, loss_freq: 0.074313
[04:48:46.469] iteration 13218: loss: 0.064066, loss_s1: 0.042598, loss_fp: 0.002871, loss_freq: 0.023015
[04:48:47.076] iteration 13219: loss: 0.065541, loss_s1: 0.056676, loss_fp: 0.005507, loss_freq: 0.014461
[04:48:47.692] iteration 13220: loss: 0.091295, loss_s1: 0.070528, loss_fp: 0.005537, loss_freq: 0.053643
[04:48:48.305] iteration 13221: loss: 0.061734, loss_s1: 0.062552, loss_fp: 0.006148, loss_freq: 0.021853
[04:48:48.918] iteration 13222: loss: 0.063532, loss_s1: 0.054198, loss_fp: 0.002703, loss_freq: 0.012554
[04:48:49.533] iteration 13223: loss: 0.102774, loss_s1: 0.114328, loss_fp: 0.002962, loss_freq: 0.037304
[04:48:50.148] iteration 13224: loss: 0.094598, loss_s1: 0.089348, loss_fp: 0.006312, loss_freq: 0.034466
[04:48:50.760] iteration 13225: loss: 0.085705, loss_s1: 0.096721, loss_fp: 0.001349, loss_freq: 0.033344
[04:48:51.370] iteration 13226: loss: 0.049534, loss_s1: 0.036243, loss_fp: 0.000812, loss_freq: 0.018405
[04:48:51.977] iteration 13227: loss: 0.053629, loss_s1: 0.029539, loss_fp: 0.003866, loss_freq: 0.021275
[04:48:52.612] iteration 13228: loss: 0.054308, loss_s1: 0.043810, loss_fp: 0.001091, loss_freq: 0.026623
[04:48:53.218] iteration 13229: loss: 0.133284, loss_s1: 0.135523, loss_fp: 0.008201, loss_freq: 0.072515
[04:48:53.905] iteration 13230: loss: 0.050321, loss_s1: 0.037241, loss_fp: 0.003505, loss_freq: 0.030363
[04:48:54.568] iteration 13231: loss: 0.087371, loss_s1: 0.098954, loss_fp: 0.005668, loss_freq: 0.018506
[04:48:55.232] iteration 13232: loss: 0.068554, loss_s1: 0.064511, loss_fp: 0.002852, loss_freq: 0.026591
[04:48:55.883] iteration 13233: loss: 0.078536, loss_s1: 0.056217, loss_fp: 0.002871, loss_freq: 0.041940
[04:48:56.504] iteration 13234: loss: 0.063423, loss_s1: 0.049986, loss_fp: 0.002319, loss_freq: 0.027303
[04:48:57.123] iteration 13235: loss: 0.035214, loss_s1: 0.021550, loss_fp: 0.002458, loss_freq: 0.010852
[04:48:57.746] iteration 13236: loss: 0.061691, loss_s1: 0.022682, loss_fp: 0.006452, loss_freq: 0.035806
[04:48:58.369] iteration 13237: loss: 0.066660, loss_s1: 0.061696, loss_fp: 0.003933, loss_freq: 0.031458
[04:48:58.993] iteration 13238: loss: 0.132304, loss_s1: 0.144075, loss_fp: 0.005682, loss_freq: 0.073184
[04:48:59.615] iteration 13239: loss: 0.091675, loss_s1: 0.098628, loss_fp: 0.001427, loss_freq: 0.047223
[04:49:00.235] iteration 13240: loss: 0.086240, loss_s1: 0.063357, loss_fp: 0.007942, loss_freq: 0.046827
[04:49:00.863] iteration 13241: loss: 0.067947, loss_s1: 0.050363, loss_fp: 0.007403, loss_freq: 0.024813
[04:49:01.570] iteration 13242: loss: 0.067317, loss_s1: 0.066687, loss_fp: 0.001238, loss_freq: 0.025930
[04:49:02.358] iteration 13243: loss: 0.073049, loss_s1: 0.063852, loss_fp: 0.006972, loss_freq: 0.040810
[04:49:03.231] iteration 13244: loss: 0.093370, loss_s1: 0.096098, loss_fp: 0.004073, loss_freq: 0.052277
[04:49:03.911] iteration 13245: loss: 0.141263, loss_s1: 0.115309, loss_fp: 0.011733, loss_freq: 0.098420
[04:49:04.562] iteration 13246: loss: 0.041442, loss_s1: 0.013436, loss_fp: 0.001758, loss_freq: 0.023891
[04:49:05.179] iteration 13247: loss: 0.051038, loss_s1: 0.032596, loss_fp: 0.003524, loss_freq: 0.026996
[04:49:05.785] iteration 13248: loss: 0.096273, loss_s1: 0.054199, loss_fp: 0.010662, loss_freq: 0.078961
[04:49:06.395] iteration 13249: loss: 0.052179, loss_s1: 0.038371, loss_fp: 0.001770, loss_freq: 0.030624
[04:49:07.009] iteration 13250: loss: 0.072573, loss_s1: 0.056853, loss_fp: 0.005183, loss_freq: 0.033651
[04:49:07.615] iteration 13251: loss: 0.041904, loss_s1: 0.031559, loss_fp: 0.002503, loss_freq: 0.006733
[04:49:08.300] iteration 13252: loss: 0.093912, loss_s1: 0.077460, loss_fp: 0.007522, loss_freq: 0.062343
[04:49:08.976] iteration 13253: loss: 0.056687, loss_s1: 0.024424, loss_fp: 0.001690, loss_freq: 0.013687
[04:49:09.675] iteration 13254: loss: 0.047216, loss_s1: 0.036004, loss_fp: 0.001311, loss_freq: 0.022879
[04:49:10.339] iteration 13255: loss: 0.051669, loss_s1: 0.041006, loss_fp: 0.000967, loss_freq: 0.012850
[04:49:11.016] iteration 13256: loss: 0.071054, loss_s1: 0.060827, loss_fp: 0.006147, loss_freq: 0.035831
[04:49:11.684] iteration 13257: loss: 0.056917, loss_s1: 0.029256, loss_fp: 0.002326, loss_freq: 0.025906
[04:49:12.356] iteration 13258: loss: 0.116256, loss_s1: 0.108558, loss_fp: 0.013897, loss_freq: 0.047890
[04:49:12.974] iteration 13259: loss: 0.065907, loss_s1: 0.051167, loss_fp: 0.003905, loss_freq: 0.045308
[04:49:13.581] iteration 13260: loss: 0.086381, loss_s1: 0.066838, loss_fp: 0.002988, loss_freq: 0.031577
[04:49:14.500] iteration 13261: loss: 0.066910, loss_s1: 0.050765, loss_fp: 0.003680, loss_freq: 0.022667
[04:49:15.177] iteration 13262: loss: 0.055462, loss_s1: 0.029057, loss_fp: 0.004072, loss_freq: 0.031042
[04:49:15.831] iteration 13263: loss: 0.087730, loss_s1: 0.088609, loss_fp: 0.003875, loss_freq: 0.045177
[04:49:16.489] iteration 13264: loss: 0.041019, loss_s1: 0.020789, loss_fp: 0.001441, loss_freq: 0.015056
[04:49:17.145] iteration 13265: loss: 0.069238, loss_s1: 0.055855, loss_fp: 0.006539, loss_freq: 0.033836
[04:49:17.754] iteration 13266: loss: 0.084721, loss_s1: 0.074336, loss_fp: 0.006203, loss_freq: 0.045409
[04:49:18.367] iteration 13267: loss: 0.090056, loss_s1: 0.060096, loss_fp: 0.008665, loss_freq: 0.063993
[04:49:19.010] iteration 13268: loss: 0.079413, loss_s1: 0.086377, loss_fp: 0.003182, loss_freq: 0.038247
[04:49:19.622] iteration 13269: loss: 0.056471, loss_s1: 0.029300, loss_fp: 0.003710, loss_freq: 0.023877
[04:49:20.258] iteration 13270: loss: 0.117887, loss_s1: 0.140647, loss_fp: 0.003950, loss_freq: 0.042949
[04:49:20.871] iteration 13271: loss: 0.073555, loss_s1: 0.061239, loss_fp: 0.001224, loss_freq: 0.032238
[04:49:21.484] iteration 13272: loss: 0.093700, loss_s1: 0.064282, loss_fp: 0.003122, loss_freq: 0.070342
[04:49:22.096] iteration 13273: loss: 0.061536, loss_s1: 0.036572, loss_fp: 0.003129, loss_freq: 0.036265
[04:49:22.703] iteration 13274: loss: 0.091147, loss_s1: 0.063957, loss_fp: 0.002819, loss_freq: 0.043829
[04:49:23.318] iteration 13275: loss: 0.098439, loss_s1: 0.071111, loss_fp: 0.010386, loss_freq: 0.057896
[04:49:23.932] iteration 13276: loss: 0.071902, loss_s1: 0.063424, loss_fp: 0.003967, loss_freq: 0.032626
[04:49:24.540] iteration 13277: loss: 0.116139, loss_s1: 0.098784, loss_fp: 0.002515, loss_freq: 0.098180
[04:49:25.154] iteration 13278: loss: 0.046115, loss_s1: 0.038833, loss_fp: 0.003478, loss_freq: 0.013789
[04:49:25.827] iteration 13279: loss: 0.048859, loss_s1: 0.052289, loss_fp: 0.001985, loss_freq: 0.012291
[04:49:26.510] iteration 13280: loss: 0.105073, loss_s1: 0.132939, loss_fp: 0.001007, loss_freq: 0.020488
[04:49:27.181] iteration 13281: loss: 0.059095, loss_s1: 0.048500, loss_fp: 0.002517, loss_freq: 0.025588
[04:49:27.791] iteration 13282: loss: 0.063044, loss_s1: 0.047884, loss_fp: 0.004567, loss_freq: 0.038665
[04:49:28.444] iteration 13283: loss: 0.066929, loss_s1: 0.043225, loss_fp: 0.002436, loss_freq: 0.032285
[04:49:29.056] iteration 13284: loss: 0.073391, loss_s1: 0.038889, loss_fp: 0.000514, loss_freq: 0.030407
[04:49:29.664] iteration 13285: loss: 0.118325, loss_s1: 0.098329, loss_fp: 0.001181, loss_freq: 0.043555
[04:49:30.268] iteration 13286: loss: 0.059176, loss_s1: 0.043590, loss_fp: 0.001184, loss_freq: 0.046655
[04:49:30.869] iteration 13287: loss: 0.046249, loss_s1: 0.020991, loss_fp: 0.000947, loss_freq: 0.031394
[04:49:31.468] iteration 13288: loss: 0.097498, loss_s1: 0.107404, loss_fp: 0.002888, loss_freq: 0.033955
[04:49:32.069] iteration 13289: loss: 0.061848, loss_s1: 0.052078, loss_fp: 0.004857, loss_freq: 0.026297
[04:49:32.671] iteration 13290: loss: 0.130944, loss_s1: 0.149074, loss_fp: 0.001183, loss_freq: 0.070297
[04:49:33.333] iteration 13291: loss: 0.069851, loss_s1: 0.030861, loss_fp: 0.003367, loss_freq: 0.048957
[04:49:33.939] iteration 13292: loss: 0.076099, loss_s1: 0.045640, loss_fp: 0.001514, loss_freq: 0.057239
[04:49:34.574] iteration 13293: loss: 0.093370, loss_s1: 0.057455, loss_fp: 0.005312, loss_freq: 0.045200
[04:49:35.180] iteration 13294: loss: 0.041186, loss_s1: 0.015821, loss_fp: 0.002279, loss_freq: 0.012460
[04:49:35.781] iteration 13295: loss: 0.069313, loss_s1: 0.067754, loss_fp: 0.001183, loss_freq: 0.037847
[04:49:36.387] iteration 13296: loss: 0.059540, loss_s1: 0.035506, loss_fp: 0.004267, loss_freq: 0.024967
[04:49:36.995] iteration 13297: loss: 0.070683, loss_s1: 0.056232, loss_fp: 0.004547, loss_freq: 0.033926
[04:49:37.602] iteration 13298: loss: 0.083008, loss_s1: 0.071717, loss_fp: 0.002371, loss_freq: 0.015235
[04:49:38.222] iteration 13299: loss: 0.112352, loss_s1: 0.113508, loss_fp: 0.009172, loss_freq: 0.056967
[04:49:38.830] iteration 13300: loss: 0.066998, loss_s1: 0.051155, loss_fp: 0.005600, loss_freq: 0.043424
[04:49:39.438] iteration 13301: loss: 0.083417, loss_s1: 0.101440, loss_fp: 0.001353, loss_freq: 0.023175
[04:49:40.044] iteration 13302: loss: 0.072513, loss_s1: 0.074896, loss_fp: 0.001986, loss_freq: 0.032789
[04:49:40.661] iteration 13303: loss: 0.102711, loss_s1: 0.106192, loss_fp: 0.011624, loss_freq: 0.053978
[04:49:41.268] iteration 13304: loss: 0.100083, loss_s1: 0.114083, loss_fp: 0.006360, loss_freq: 0.036616
[04:49:41.878] iteration 13305: loss: 0.060451, loss_s1: 0.038716, loss_fp: 0.003218, loss_freq: 0.019247
[04:49:42.532] iteration 13306: loss: 0.083301, loss_s1: 0.066272, loss_fp: 0.010030, loss_freq: 0.038001
[04:49:43.198] iteration 13307: loss: 0.047564, loss_s1: 0.020694, loss_fp: 0.003080, loss_freq: 0.030967
[04:49:43.852] iteration 13308: loss: 0.085033, loss_s1: 0.039677, loss_fp: 0.002637, loss_freq: 0.089549
[04:49:44.510] iteration 13309: loss: 0.061052, loss_s1: 0.049483, loss_fp: 0.001928, loss_freq: 0.018394
[04:49:45.133] iteration 13310: loss: 0.057814, loss_s1: 0.029934, loss_fp: 0.003179, loss_freq: 0.033764
[04:49:45.748] iteration 13311: loss: 0.098036, loss_s1: 0.072483, loss_fp: 0.003920, loss_freq: 0.053171
[04:49:46.358] iteration 13312: loss: 0.079752, loss_s1: 0.082301, loss_fp: 0.002355, loss_freq: 0.040642
[04:49:46.967] iteration 13313: loss: 0.073756, loss_s1: 0.032808, loss_fp: 0.001539, loss_freq: 0.045530
[04:49:47.574] iteration 13314: loss: 0.090051, loss_s1: 0.096742, loss_fp: 0.004478, loss_freq: 0.033443
[04:49:48.184] iteration 13315: loss: 0.075515, loss_s1: 0.048681, loss_fp: 0.002563, loss_freq: 0.057984
[04:49:48.800] iteration 13316: loss: 0.046630, loss_s1: 0.029326, loss_fp: 0.000809, loss_freq: 0.022235
[04:49:49.410] iteration 13317: loss: 0.079506, loss_s1: 0.061839, loss_fp: 0.005095, loss_freq: 0.061654
[04:49:50.019] iteration 13318: loss: 0.068047, loss_s1: 0.053705, loss_fp: 0.002379, loss_freq: 0.029248
[04:49:50.628] iteration 13319: loss: 0.049908, loss_s1: 0.015380, loss_fp: 0.001375, loss_freq: 0.020371
[04:49:51.232] iteration 13320: loss: 0.068719, loss_s1: 0.035385, loss_fp: 0.008335, loss_freq: 0.048583
[04:49:51.837] iteration 13321: loss: 0.043110, loss_s1: 0.045693, loss_fp: 0.003900, loss_freq: 0.005707
[04:49:52.495] iteration 13322: loss: 0.087673, loss_s1: 0.073793, loss_fp: 0.001499, loss_freq: 0.034616
[04:49:53.152] iteration 13323: loss: 0.044072, loss_s1: 0.023097, loss_fp: 0.000389, loss_freq: 0.005526
[04:49:53.803] iteration 13324: loss: 0.055020, loss_s1: 0.051347, loss_fp: 0.001564, loss_freq: 0.017467
[04:49:54.414] iteration 13325: loss: 0.051501, loss_s1: 0.009920, loss_fp: 0.002038, loss_freq: 0.022905
[04:49:55.077] iteration 13326: loss: 0.085029, loss_s1: 0.082535, loss_fp: 0.003101, loss_freq: 0.049111
[04:49:55.713] iteration 13327: loss: 0.053744, loss_s1: 0.021065, loss_fp: 0.002405, loss_freq: 0.009383
[04:49:56.407] iteration 13328: loss: 0.127914, loss_s1: 0.144371, loss_fp: 0.022504, loss_freq: 0.051030
[04:49:57.063] iteration 13329: loss: 0.049306, loss_s1: 0.021172, loss_fp: 0.006627, loss_freq: 0.027438
[04:49:57.755] iteration 13330: loss: 0.050503, loss_s1: 0.032663, loss_fp: 0.004458, loss_freq: 0.031792
[04:49:58.384] iteration 13331: loss: 0.083248, loss_s1: 0.086059, loss_fp: 0.002986, loss_freq: 0.034007
[04:49:58.988] iteration 13332: loss: 0.058535, loss_s1: 0.019529, loss_fp: 0.011593, loss_freq: 0.032278
[04:49:59.593] iteration 13333: loss: 0.072909, loss_s1: 0.052267, loss_fp: 0.006365, loss_freq: 0.044224
[04:50:00.201] iteration 13334: loss: 0.066231, loss_s1: 0.049582, loss_fp: 0.004099, loss_freq: 0.037901
[04:50:00.810] iteration 13335: loss: 0.069214, loss_s1: 0.020779, loss_fp: 0.001735, loss_freq: 0.072354
[04:50:01.416] iteration 13336: loss: 0.074578, loss_s1: 0.035671, loss_fp: 0.004517, loss_freq: 0.047552
[04:50:02.025] iteration 13337: loss: 0.064201, loss_s1: 0.049515, loss_fp: 0.003348, loss_freq: 0.036767
[04:50:02.638] iteration 13338: loss: 0.070937, loss_s1: 0.040422, loss_fp: 0.006630, loss_freq: 0.052332
[04:50:03.256] iteration 13339: loss: 0.076738, loss_s1: 0.057565, loss_fp: 0.003322, loss_freq: 0.061991
[04:50:03.863] iteration 13340: loss: 0.077961, loss_s1: 0.050885, loss_fp: 0.001627, loss_freq: 0.046972
[04:50:04.472] iteration 13341: loss: 0.067879, loss_s1: 0.031624, loss_fp: 0.001749, loss_freq: 0.036182
[04:50:05.080] iteration 13342: loss: 0.055609, loss_s1: 0.035538, loss_fp: 0.006703, loss_freq: 0.029997
[04:50:05.704] iteration 13343: loss: 0.063189, loss_s1: 0.051112, loss_fp: 0.003026, loss_freq: 0.024740
[04:50:06.328] iteration 13344: loss: 0.068934, loss_s1: 0.072934, loss_fp: 0.003696, loss_freq: 0.018624
[04:50:06.950] iteration 13345: loss: 0.074117, loss_s1: 0.065584, loss_fp: 0.001970, loss_freq: 0.033956
[04:50:07.606] iteration 13346: loss: 0.050302, loss_s1: 0.036922, loss_fp: 0.001649, loss_freq: 0.023778
[04:50:08.220] iteration 13347: loss: 0.079567, loss_s1: 0.102480, loss_fp: 0.001833, loss_freq: 0.021473
[04:50:08.829] iteration 13348: loss: 0.098036, loss_s1: 0.135148, loss_fp: 0.003858, loss_freq: 0.011270
[04:50:09.434] iteration 13349: loss: 0.084650, loss_s1: 0.102018, loss_fp: 0.001383, loss_freq: 0.024697
[04:50:10.038] iteration 13350: loss: 0.068594, loss_s1: 0.047776, loss_fp: 0.001009, loss_freq: 0.035786
[04:50:10.646] iteration 13351: loss: 0.072631, loss_s1: 0.072276, loss_fp: 0.001417, loss_freq: 0.033026
[04:50:11.254] iteration 13352: loss: 0.074961, loss_s1: 0.069048, loss_fp: 0.002366, loss_freq: 0.039998
[04:50:11.862] iteration 13353: loss: 0.096969, loss_s1: 0.081108, loss_fp: 0.004846, loss_freq: 0.048770
[04:50:12.466] iteration 13354: loss: 0.045891, loss_s1: 0.036299, loss_fp: 0.003336, loss_freq: 0.012356
[04:50:13.066] iteration 13355: loss: 0.071921, loss_s1: 0.043774, loss_fp: 0.003508, loss_freq: 0.050009
[04:50:13.674] iteration 13356: loss: 0.062831, loss_s1: 0.054764, loss_fp: 0.001488, loss_freq: 0.038152
[04:50:14.282] iteration 13357: loss: 0.113876, loss_s1: 0.075434, loss_fp: 0.003995, loss_freq: 0.063253
[04:50:14.892] iteration 13358: loss: 0.066987, loss_s1: 0.053961, loss_fp: 0.003026, loss_freq: 0.026150
[04:50:15.511] iteration 13359: loss: 0.047848, loss_s1: 0.030860, loss_fp: 0.002843, loss_freq: 0.021055
[04:50:16.132] iteration 13360: loss: 0.062531, loss_s1: 0.029740, loss_fp: 0.001109, loss_freq: 0.048678
[04:50:16.753] iteration 13361: loss: 0.038467, loss_s1: 0.027666, loss_fp: 0.001955, loss_freq: 0.017964
[04:50:17.364] iteration 13362: loss: 0.068178, loss_s1: 0.050348, loss_fp: 0.004632, loss_freq: 0.017497
[04:50:17.974] iteration 13363: loss: 0.042659, loss_s1: 0.016456, loss_fp: 0.001325, loss_freq: 0.021798
[04:50:18.585] iteration 13364: loss: 0.058224, loss_s1: 0.031435, loss_fp: 0.009153, loss_freq: 0.028690
[04:50:19.198] iteration 13365: loss: 0.053796, loss_s1: 0.011612, loss_fp: 0.005209, loss_freq: 0.047522
[04:50:19.808] iteration 13366: loss: 0.069206, loss_s1: 0.062311, loss_fp: 0.006016, loss_freq: 0.030091
[04:50:20.421] iteration 13367: loss: 0.077630, loss_s1: 0.073269, loss_fp: 0.003050, loss_freq: 0.030979
[04:50:21.031] iteration 13368: loss: 0.052528, loss_s1: 0.045119, loss_fp: 0.000840, loss_freq: 0.026024
[04:50:21.641] iteration 13369: loss: 0.087625, loss_s1: 0.048944, loss_fp: 0.009177, loss_freq: 0.077358
[04:50:22.265] iteration 13370: loss: 0.062236, loss_s1: 0.041124, loss_fp: 0.010860, loss_freq: 0.034772
[04:50:22.885] iteration 13371: loss: 0.107862, loss_s1: 0.087876, loss_fp: 0.002196, loss_freq: 0.040896
[04:50:23.497] iteration 13372: loss: 0.069663, loss_s1: 0.059221, loss_fp: 0.002397, loss_freq: 0.040717
[04:50:24.113] iteration 13373: loss: 0.062089, loss_s1: 0.045404, loss_fp: 0.006288, loss_freq: 0.036357
[04:50:24.725] iteration 13374: loss: 0.044897, loss_s1: 0.033793, loss_fp: 0.005324, loss_freq: 0.018623
[04:50:25.332] iteration 13375: loss: 0.114885, loss_s1: 0.117696, loss_fp: 0.003064, loss_freq: 0.055636
[04:50:25.940] iteration 13376: loss: 0.072990, loss_s1: 0.041315, loss_fp: 0.013701, loss_freq: 0.049668
[04:50:26.550] iteration 13377: loss: 0.066368, loss_s1: 0.047488, loss_fp: 0.007159, loss_freq: 0.041283
[04:50:27.173] iteration 13378: loss: 0.066058, loss_s1: 0.045449, loss_fp: 0.002788, loss_freq: 0.048059
[04:50:27.779] iteration 13379: loss: 0.061473, loss_s1: 0.027231, loss_fp: 0.004956, loss_freq: 0.053955
[04:50:28.381] iteration 13380: loss: 0.058944, loss_s1: 0.033169, loss_fp: 0.006780, loss_freq: 0.019291
[04:50:28.984] iteration 13381: loss: 0.054143, loss_s1: 0.057628, loss_fp: 0.001470, loss_freq: 0.013526
[04:50:29.587] iteration 13382: loss: 0.068091, loss_s1: 0.065420, loss_fp: 0.007659, loss_freq: 0.033999
[04:50:30.196] iteration 13383: loss: 0.091084, loss_s1: 0.065613, loss_fp: 0.013852, loss_freq: 0.066925
[04:50:30.798] iteration 13384: loss: 0.056661, loss_s1: 0.039296, loss_fp: 0.002300, loss_freq: 0.037332
[04:50:31.402] iteration 13385: loss: 0.123422, loss_s1: 0.081051, loss_fp: 0.005383, loss_freq: 0.111767
[04:50:32.006] iteration 13386: loss: 0.052841, loss_s1: 0.021089, loss_fp: 0.005597, loss_freq: 0.036178
[04:50:32.610] iteration 13387: loss: 0.056879, loss_s1: 0.051344, loss_fp: 0.001902, loss_freq: 0.029797
[04:50:33.224] iteration 13388: loss: 0.049782, loss_s1: 0.012301, loss_fp: 0.004404, loss_freq: 0.027414
[04:50:33.831] iteration 13389: loss: 0.054399, loss_s1: 0.038863, loss_fp: 0.002208, loss_freq: 0.020756
[04:50:34.443] iteration 13390: loss: 0.065373, loss_s1: 0.027760, loss_fp: 0.012054, loss_freq: 0.042601
[04:50:35.055] iteration 13391: loss: 0.102621, loss_s1: 0.104009, loss_fp: 0.003871, loss_freq: 0.065031
[04:50:35.662] iteration 13392: loss: 0.058208, loss_s1: 0.027901, loss_fp: 0.001226, loss_freq: 0.017846
[04:50:36.271] iteration 13393: loss: 0.110134, loss_s1: 0.119040, loss_fp: 0.005963, loss_freq: 0.046754
[04:50:36.878] iteration 13394: loss: 0.061453, loss_s1: 0.040995, loss_fp: 0.002924, loss_freq: 0.039353
[04:50:37.546] iteration 13395: loss: 0.081566, loss_s1: 0.065747, loss_fp: 0.003087, loss_freq: 0.051643
[04:50:38.200] iteration 13396: loss: 0.048829, loss_s1: 0.045292, loss_fp: 0.001446, loss_freq: 0.009647
[04:50:38.854] iteration 13397: loss: 0.112086, loss_s1: 0.079993, loss_fp: 0.004620, loss_freq: 0.036784
[04:50:39.477] iteration 13398: loss: 0.080232, loss_s1: 0.079942, loss_fp: 0.003365, loss_freq: 0.047121
[04:50:40.087] iteration 13399: loss: 0.127710, loss_s1: 0.139730, loss_fp: 0.011885, loss_freq: 0.064965
[04:50:40.699] iteration 13400: loss: 0.075394, loss_s1: 0.101656, loss_fp: 0.006449, loss_freq: 0.014966
[04:50:43.996] iteration 13400 : mean_dice : 0.719187
[04:50:44.629] iteration 13401: loss: 0.084600, loss_s1: 0.061248, loss_fp: 0.002152, loss_freq: 0.043928
[04:50:45.243] iteration 13402: loss: 0.059190, loss_s1: 0.038375, loss_fp: 0.003458, loss_freq: 0.029522
[04:50:45.850] iteration 13403: loss: 0.081106, loss_s1: 0.049032, loss_fp: 0.003375, loss_freq: 0.074702
[04:50:46.461] iteration 13404: loss: 0.074111, loss_s1: 0.052098, loss_fp: 0.003855, loss_freq: 0.048387
[04:50:47.070] iteration 13405: loss: 0.053795, loss_s1: 0.037781, loss_fp: 0.003287, loss_freq: 0.027501
[04:50:47.674] iteration 13406: loss: 0.059166, loss_s1: 0.037351, loss_fp: 0.001573, loss_freq: 0.012378
[04:50:48.286] iteration 13407: loss: 0.061432, loss_s1: 0.051515, loss_fp: 0.001875, loss_freq: 0.032537
[04:50:48.889] iteration 13408: loss: 0.123414, loss_s1: 0.119731, loss_fp: 0.005171, loss_freq: 0.078769
[04:50:49.496] iteration 13409: loss: 0.069508, loss_s1: 0.052370, loss_fp: 0.012736, loss_freq: 0.039340
[04:50:50.103] iteration 13410: loss: 0.076070, loss_s1: 0.047242, loss_fp: 0.005869, loss_freq: 0.027295
[04:50:50.713] iteration 13411: loss: 0.062908, loss_s1: 0.039253, loss_fp: 0.003364, loss_freq: 0.037378
[04:50:51.316] iteration 13412: loss: 0.086314, loss_s1: 0.069716, loss_fp: 0.004522, loss_freq: 0.058909
[04:50:51.919] iteration 13413: loss: 0.116195, loss_s1: 0.111500, loss_fp: 0.004929, loss_freq: 0.068572
[04:50:52.529] iteration 13414: loss: 0.116629, loss_s1: 0.057888, loss_fp: 0.003918, loss_freq: 0.132907
[04:50:53.137] iteration 13415: loss: 0.074696, loss_s1: 0.032030, loss_fp: 0.004826, loss_freq: 0.033234
[04:50:53.743] iteration 13416: loss: 0.068859, loss_s1: 0.058314, loss_fp: 0.001643, loss_freq: 0.008920
[04:50:54.353] iteration 13417: loss: 0.052301, loss_s1: 0.038512, loss_fp: 0.004060, loss_freq: 0.030094
[04:50:54.960] iteration 13418: loss: 0.071785, loss_s1: 0.039392, loss_fp: 0.003208, loss_freq: 0.063398
[04:50:55.567] iteration 13419: loss: 0.064209, loss_s1: 0.065440, loss_fp: 0.002185, loss_freq: 0.023372
[04:50:56.174] iteration 13420: loss: 0.083085, loss_s1: 0.083133, loss_fp: 0.003901, loss_freq: 0.034932
[04:50:56.789] iteration 13421: loss: 0.063331, loss_s1: 0.067462, loss_fp: 0.001646, loss_freq: 0.017937
[04:50:57.395] iteration 13422: loss: 0.100342, loss_s1: 0.086153, loss_fp: 0.002584, loss_freq: 0.070008
[04:50:58.001] iteration 13423: loss: 0.051932, loss_s1: 0.019861, loss_fp: 0.000659, loss_freq: 0.017323
[04:50:58.619] iteration 13424: loss: 0.049500, loss_s1: 0.043375, loss_fp: 0.002089, loss_freq: 0.022847
[04:50:59.228] iteration 13425: loss: 0.056723, loss_s1: 0.053545, loss_fp: 0.000546, loss_freq: 0.017125
[04:50:59.837] iteration 13426: loss: 0.085172, loss_s1: 0.098702, loss_fp: 0.002551, loss_freq: 0.032960
[04:51:00.440] iteration 13427: loss: 0.055191, loss_s1: 0.035892, loss_fp: 0.001381, loss_freq: 0.030115
[04:51:01.051] iteration 13428: loss: 0.083155, loss_s1: 0.061347, loss_fp: 0.009675, loss_freq: 0.055591
[04:51:01.651] iteration 13429: loss: 0.095220, loss_s1: 0.067398, loss_fp: 0.004748, loss_freq: 0.082378
[04:51:02.256] iteration 13430: loss: 0.097080, loss_s1: 0.094929, loss_fp: 0.010329, loss_freq: 0.039277
[04:51:03.258] iteration 13431: loss: 0.088344, loss_s1: 0.089315, loss_fp: 0.001437, loss_freq: 0.036847
[04:51:03.890] iteration 13432: loss: 0.066632, loss_s1: 0.042336, loss_fp: 0.004406, loss_freq: 0.040420
[04:51:04.510] iteration 13433: loss: 0.074392, loss_s1: 0.058949, loss_fp: 0.008515, loss_freq: 0.030442
[04:51:05.143] iteration 13434: loss: 0.048501, loss_s1: 0.042474, loss_fp: 0.002829, loss_freq: 0.008596
[04:51:05.998] iteration 13435: loss: 0.064289, loss_s1: 0.044769, loss_fp: 0.009181, loss_freq: 0.027179
[04:51:06.667] iteration 13436: loss: 0.100666, loss_s1: 0.087323, loss_fp: 0.001634, loss_freq: 0.054286
[04:51:07.322] iteration 13437: loss: 0.084081, loss_s1: 0.066749, loss_fp: 0.001478, loss_freq: 0.049194
[04:51:08.014] iteration 13438: loss: 0.089252, loss_s1: 0.068808, loss_fp: 0.007996, loss_freq: 0.059292
[04:51:08.638] iteration 13439: loss: 0.088841, loss_s1: 0.088387, loss_fp: 0.002246, loss_freq: 0.047653
[04:51:09.263] iteration 13440: loss: 0.084593, loss_s1: 0.056643, loss_fp: 0.005456, loss_freq: 0.054948
[04:51:09.865] iteration 13441: loss: 0.125761, loss_s1: 0.070526, loss_fp: 0.003372, loss_freq: 0.087094
[04:51:10.473] iteration 13442: loss: 0.109035, loss_s1: 0.108362, loss_fp: 0.003717, loss_freq: 0.060882
[04:51:11.081] iteration 13443: loss: 0.067429, loss_s1: 0.040248, loss_fp: 0.002953, loss_freq: 0.043523
[04:51:11.695] iteration 13444: loss: 0.075275, loss_s1: 0.069266, loss_fp: 0.002494, loss_freq: 0.035893
[04:51:12.309] iteration 13445: loss: 0.065974, loss_s1: 0.057784, loss_fp: 0.002708, loss_freq: 0.011605
[04:51:12.925] iteration 13446: loss: 0.084234, loss_s1: 0.073100, loss_fp: 0.010616, loss_freq: 0.032861
[04:51:13.547] iteration 13447: loss: 0.104711, loss_s1: 0.094890, loss_fp: 0.000883, loss_freq: 0.079754
[04:51:14.174] iteration 13448: loss: 0.048088, loss_s1: 0.036778, loss_fp: 0.001206, loss_freq: 0.006273
[04:51:14.796] iteration 13449: loss: 0.080456, loss_s1: 0.092436, loss_fp: 0.002493, loss_freq: 0.031356
[04:51:15.418] iteration 13450: loss: 0.069614, loss_s1: 0.065031, loss_fp: 0.002690, loss_freq: 0.027019
[04:51:16.042] iteration 13451: loss: 0.076479, loss_s1: 0.070846, loss_fp: 0.001988, loss_freq: 0.033463
[04:51:16.657] iteration 13452: loss: 0.096589, loss_s1: 0.089871, loss_fp: 0.004819, loss_freq: 0.062221
[04:51:17.261] iteration 13453: loss: 0.064791, loss_s1: 0.050511, loss_fp: 0.001990, loss_freq: 0.029311
[04:51:17.906] iteration 13454: loss: 0.060485, loss_s1: 0.035371, loss_fp: 0.005942, loss_freq: 0.031117
[04:51:18.532] iteration 13455: loss: 0.076339, loss_s1: 0.053884, loss_fp: 0.004938, loss_freq: 0.056454
[04:51:19.141] iteration 13456: loss: 0.111055, loss_s1: 0.143097, loss_fp: 0.002338, loss_freq: 0.039935
[04:51:19.769] iteration 13457: loss: 0.080125, loss_s1: 0.065066, loss_fp: 0.001377, loss_freq: 0.034987
[04:51:20.379] iteration 13458: loss: 0.125218, loss_s1: 0.101645, loss_fp: 0.007908, loss_freq: 0.072012
[04:51:20.985] iteration 13459: loss: 0.056555, loss_s1: 0.027882, loss_fp: 0.002858, loss_freq: 0.038319
[04:51:21.598] iteration 13460: loss: 0.060622, loss_s1: 0.049289, loss_fp: 0.002324, loss_freq: 0.026695
[04:51:22.252] iteration 13461: loss: 0.082819, loss_s1: 0.072007, loss_fp: 0.004249, loss_freq: 0.049379
[04:51:22.906] iteration 13462: loss: 0.079431, loss_s1: 0.050461, loss_fp: 0.002915, loss_freq: 0.049310
[04:51:23.561] iteration 13463: loss: 0.065630, loss_s1: 0.060309, loss_fp: 0.003048, loss_freq: 0.030044
[04:51:24.213] iteration 13464: loss: 0.045526, loss_s1: 0.022206, loss_fp: 0.002440, loss_freq: 0.023968
[04:51:24.823] iteration 13465: loss: 0.075870, loss_s1: 0.033261, loss_fp: 0.005338, loss_freq: 0.034550
[04:51:25.435] iteration 13466: loss: 0.058414, loss_s1: 0.031582, loss_fp: 0.002363, loss_freq: 0.026863
[04:51:26.041] iteration 13467: loss: 0.069528, loss_s1: 0.060954, loss_fp: 0.004300, loss_freq: 0.030780
[04:51:26.651] iteration 13468: loss: 0.052604, loss_s1: 0.055154, loss_fp: 0.003862, loss_freq: 0.013524
[04:51:27.252] iteration 13469: loss: 0.074268, loss_s1: 0.076856, loss_fp: 0.005585, loss_freq: 0.022847
[04:51:27.855] iteration 13470: loss: 0.086995, loss_s1: 0.096120, loss_fp: 0.003147, loss_freq: 0.024501
[04:51:28.462] iteration 13471: loss: 0.116825, loss_s1: 0.130449, loss_fp: 0.001052, loss_freq: 0.046787
[04:51:29.063] iteration 13472: loss: 0.062569, loss_s1: 0.050149, loss_fp: 0.005200, loss_freq: 0.032788
[04:51:29.669] iteration 13473: loss: 0.072073, loss_s1: 0.071181, loss_fp: 0.006002, loss_freq: 0.032958
[04:51:30.283] iteration 13474: loss: 0.081526, loss_s1: 0.074126, loss_fp: 0.004044, loss_freq: 0.049952
[04:51:30.889] iteration 13475: loss: 0.073425, loss_s1: 0.072774, loss_fp: 0.001361, loss_freq: 0.025380
[04:51:31.495] iteration 13476: loss: 0.078273, loss_s1: 0.082199, loss_fp: 0.001842, loss_freq: 0.037043
[04:51:32.100] iteration 13477: loss: 0.061053, loss_s1: 0.035994, loss_fp: 0.002332, loss_freq: 0.042721
[04:51:32.711] iteration 13478: loss: 0.089476, loss_s1: 0.074331, loss_fp: 0.003217, loss_freq: 0.061367
[04:51:33.318] iteration 13479: loss: 0.095306, loss_s1: 0.100171, loss_fp: 0.001142, loss_freq: 0.053009
[04:51:33.921] iteration 13480: loss: 0.056870, loss_s1: 0.053868, loss_fp: 0.000787, loss_freq: 0.017230
[04:51:34.521] iteration 13481: loss: 0.089795, loss_s1: 0.102891, loss_fp: 0.000692, loss_freq: 0.033245
[04:51:35.126] iteration 13482: loss: 0.087114, loss_s1: 0.104954, loss_fp: 0.006601, loss_freq: 0.031272
[04:51:35.730] iteration 13483: loss: 0.047420, loss_s1: 0.038517, loss_fp: 0.001383, loss_freq: 0.009082
[04:51:36.332] iteration 13484: loss: 0.047262, loss_s1: 0.018694, loss_fp: 0.002393, loss_freq: 0.037297
[04:51:36.940] iteration 13485: loss: 0.058160, loss_s1: 0.030395, loss_fp: 0.002083, loss_freq: 0.037561
[04:51:37.549] iteration 13486: loss: 0.061369, loss_s1: 0.034228, loss_fp: 0.000974, loss_freq: 0.038854
[04:51:38.158] iteration 13487: loss: 0.053912, loss_s1: 0.027613, loss_fp: 0.001888, loss_freq: 0.046052
[04:51:38.765] iteration 13488: loss: 0.046544, loss_s1: 0.023382, loss_fp: 0.000810, loss_freq: 0.013280
[04:51:39.371] iteration 13489: loss: 0.058819, loss_s1: 0.045640, loss_fp: 0.002764, loss_freq: 0.021955
[04:51:40.023] iteration 13490: loss: 0.082604, loss_s1: 0.053456, loss_fp: 0.002769, loss_freq: 0.066207
[04:51:40.713] iteration 13491: loss: 0.043724, loss_s1: 0.031446, loss_fp: 0.001460, loss_freq: 0.017877
[04:51:41.319] iteration 13492: loss: 0.076975, loss_s1: 0.050760, loss_fp: 0.001035, loss_freq: 0.051561
[04:51:41.924] iteration 13493: loss: 0.056454, loss_s1: 0.050290, loss_fp: 0.000892, loss_freq: 0.017367
[04:51:42.543] iteration 13494: loss: 0.059405, loss_s1: 0.020064, loss_fp: 0.000762, loss_freq: 0.019525
[04:51:43.186] iteration 13495: loss: 0.101827, loss_s1: 0.078685, loss_fp: 0.001821, loss_freq: 0.057424
[04:51:43.802] iteration 13496: loss: 0.041696, loss_s1: 0.027318, loss_fp: 0.001835, loss_freq: 0.021147
[04:51:44.424] iteration 13497: loss: 0.054046, loss_s1: 0.039470, loss_fp: 0.001590, loss_freq: 0.011989
[04:51:45.066] iteration 13498: loss: 0.087132, loss_s1: 0.073508, loss_fp: 0.004998, loss_freq: 0.053576
[04:51:45.676] iteration 13499: loss: 0.049030, loss_s1: 0.023756, loss_fp: 0.001213, loss_freq: 0.022805
[04:51:46.277] iteration 13500: loss: 0.078305, loss_s1: 0.046835, loss_fp: 0.005217, loss_freq: 0.070907
[04:51:46.885] iteration 13501: loss: 0.074064, loss_s1: 0.049970, loss_fp: 0.004074, loss_freq: 0.042415
[04:51:47.495] iteration 13502: loss: 0.047772, loss_s1: 0.016875, loss_fp: 0.003800, loss_freq: 0.027024
[04:51:48.100] iteration 13503: loss: 0.088963, loss_s1: 0.052214, loss_fp: 0.006726, loss_freq: 0.063294
[04:51:48.705] iteration 13504: loss: 0.083824, loss_s1: 0.090311, loss_fp: 0.010539, loss_freq: 0.013378
[04:51:49.309] iteration 13505: loss: 0.072883, loss_s1: 0.035735, loss_fp: 0.006807, loss_freq: 0.049116
[04:51:49.924] iteration 13506: loss: 0.072766, loss_s1: 0.031534, loss_fp: 0.001385, loss_freq: 0.064256
[04:51:50.541] iteration 13507: loss: 0.052507, loss_s1: 0.031826, loss_fp: 0.001901, loss_freq: 0.033115
[04:51:51.159] iteration 13508: loss: 0.071928, loss_s1: 0.057246, loss_fp: 0.004732, loss_freq: 0.032249
[04:51:51.771] iteration 13509: loss: 0.069952, loss_s1: 0.045777, loss_fp: 0.005296, loss_freq: 0.053303
[04:51:52.380] iteration 13510: loss: 0.085528, loss_s1: 0.086643, loss_fp: 0.002458, loss_freq: 0.023677
[04:51:52.990] iteration 13511: loss: 0.089807, loss_s1: 0.041984, loss_fp: 0.002980, loss_freq: 0.056646
[04:51:53.604] iteration 13512: loss: 0.058329, loss_s1: 0.030516, loss_fp: 0.003545, loss_freq: 0.036919
[04:51:54.216] iteration 13513: loss: 0.058916, loss_s1: 0.061628, loss_fp: 0.001595, loss_freq: 0.015764
[04:51:54.830] iteration 13514: loss: 0.066823, loss_s1: 0.072262, loss_fp: 0.010224, loss_freq: 0.009556
[04:51:55.443] iteration 13515: loss: 0.058411, loss_s1: 0.044048, loss_fp: 0.019094, loss_freq: 0.011510
[04:51:56.058] iteration 13516: loss: 0.061936, loss_s1: 0.051733, loss_fp: 0.001417, loss_freq: 0.027588
[04:51:56.674] iteration 13517: loss: 0.085417, loss_s1: 0.088351, loss_fp: 0.004600, loss_freq: 0.047257
[04:51:57.299] iteration 13518: loss: 0.098441, loss_s1: 0.106132, loss_fp: 0.005265, loss_freq: 0.035746
[04:51:57.939] iteration 13519: loss: 0.059306, loss_s1: 0.056553, loss_fp: 0.003656, loss_freq: 0.023991
[04:51:58.548] iteration 13520: loss: 0.097783, loss_s1: 0.082685, loss_fp: 0.038475, loss_freq: 0.030340
[04:51:59.154] iteration 13521: loss: 0.077774, loss_s1: 0.058790, loss_fp: 0.001881, loss_freq: 0.034050
[04:51:59.765] iteration 13522: loss: 0.082334, loss_s1: 0.071472, loss_fp: 0.005555, loss_freq: 0.043220
[04:52:00.374] iteration 13523: loss: 0.054282, loss_s1: 0.040187, loss_fp: 0.001152, loss_freq: 0.020316
[04:52:00.981] iteration 13524: loss: 0.052690, loss_s1: 0.047482, loss_fp: 0.001816, loss_freq: 0.018014
[04:52:01.659] iteration 13525: loss: 0.090391, loss_s1: 0.086481, loss_fp: 0.002647, loss_freq: 0.032002
[04:52:02.341] iteration 13526: loss: 0.059189, loss_s1: 0.054401, loss_fp: 0.005122, loss_freq: 0.029276
[04:52:03.001] iteration 13527: loss: 0.146812, loss_s1: 0.139030, loss_fp: 0.015340, loss_freq: 0.085873
[04:52:03.615] iteration 13528: loss: 0.094170, loss_s1: 0.100233, loss_fp: 0.001453, loss_freq: 0.043598
[04:52:04.228] iteration 13529: loss: 0.078126, loss_s1: 0.058626, loss_fp: 0.006862, loss_freq: 0.052173
[04:52:04.840] iteration 13530: loss: 0.054567, loss_s1: 0.042765, loss_fp: 0.001883, loss_freq: 0.025426
[04:52:05.446] iteration 13531: loss: 0.040407, loss_s1: 0.030167, loss_fp: 0.003005, loss_freq: 0.015232
[04:52:06.050] iteration 13532: loss: 0.044337, loss_s1: 0.024229, loss_fp: 0.002368, loss_freq: 0.014938
[04:52:06.657] iteration 13533: loss: 0.045423, loss_s1: 0.019112, loss_fp: 0.005069, loss_freq: 0.028517
[04:52:07.262] iteration 13534: loss: 0.052969, loss_s1: 0.020473, loss_fp: 0.002441, loss_freq: 0.020143
[04:52:07.870] iteration 13535: loss: 0.059960, loss_s1: 0.053642, loss_fp: 0.002210, loss_freq: 0.031709
[04:52:08.474] iteration 13536: loss: 0.083625, loss_s1: 0.063663, loss_fp: 0.003366, loss_freq: 0.019992
[04:52:09.082] iteration 13537: loss: 0.069008, loss_s1: 0.056696, loss_fp: 0.003035, loss_freq: 0.032674
[04:52:09.689] iteration 13538: loss: 0.094581, loss_s1: 0.065199, loss_fp: 0.001211, loss_freq: 0.037021
[04:52:10.301] iteration 13539: loss: 0.068427, loss_s1: 0.011735, loss_fp: 0.005602, loss_freq: 0.078915
[04:52:10.915] iteration 13540: loss: 0.059407, loss_s1: 0.046368, loss_fp: 0.005072, loss_freq: 0.030374
[04:52:11.527] iteration 13541: loss: 0.068105, loss_s1: 0.040446, loss_fp: 0.001155, loss_freq: 0.028181
[04:52:12.144] iteration 13542: loss: 0.083792, loss_s1: 0.082914, loss_fp: 0.002681, loss_freq: 0.042481
[04:52:12.757] iteration 13543: loss: 0.048208, loss_s1: 0.032557, loss_fp: 0.003831, loss_freq: 0.024184
[04:52:13.369] iteration 13544: loss: 0.030045, loss_s1: 0.012708, loss_fp: 0.001823, loss_freq: 0.009303
[04:52:13.974] iteration 13545: loss: 0.105200, loss_s1: 0.083209, loss_fp: 0.002476, loss_freq: 0.087217
[04:52:14.587] iteration 13546: loss: 0.081556, loss_s1: 0.065484, loss_fp: 0.004165, loss_freq: 0.044304
[04:52:15.197] iteration 13547: loss: 0.087144, loss_s1: 0.109224, loss_fp: 0.003200, loss_freq: 0.018405
[04:52:15.805] iteration 13548: loss: 0.083667, loss_s1: 0.078512, loss_fp: 0.002823, loss_freq: 0.032025
[04:52:16.412] iteration 13549: loss: 0.076887, loss_s1: 0.049418, loss_fp: 0.002592, loss_freq: 0.064189
[04:52:17.020] iteration 13550: loss: 0.084292, loss_s1: 0.103406, loss_fp: 0.001634, loss_freq: 0.013925
[04:52:17.629] iteration 13551: loss: 0.045854, loss_s1: 0.037048, loss_fp: 0.001471, loss_freq: 0.014033
[04:52:18.236] iteration 13552: loss: 0.074448, loss_s1: 0.075520, loss_fp: 0.003991, loss_freq: 0.038939
[04:52:18.841] iteration 13553: loss: 0.091915, loss_s1: 0.084769, loss_fp: 0.003023, loss_freq: 0.056794
[04:52:19.448] iteration 13554: loss: 0.053799, loss_s1: 0.025337, loss_fp: 0.003929, loss_freq: 0.044709
[04:52:20.053] iteration 13555: loss: 0.118563, loss_s1: 0.102633, loss_fp: 0.006953, loss_freq: 0.085577
[04:52:20.660] iteration 13556: loss: 0.038198, loss_s1: 0.021114, loss_fp: 0.001422, loss_freq: 0.017039
[04:52:21.268] iteration 13557: loss: 0.080482, loss_s1: 0.052981, loss_fp: 0.001487, loss_freq: 0.071867
[04:52:21.878] iteration 13558: loss: 0.037672, loss_s1: 0.010743, loss_fp: 0.008745, loss_freq: 0.011706
[04:52:22.495] iteration 13559: loss: 0.067126, loss_s1: 0.034285, loss_fp: 0.010635, loss_freq: 0.048003
[04:52:23.096] iteration 13560: loss: 0.128632, loss_s1: 0.163457, loss_fp: 0.001598, loss_freq: 0.057160
[04:52:23.706] iteration 13561: loss: 0.086757, loss_s1: 0.067207, loss_fp: 0.009857, loss_freq: 0.035789
[04:52:24.311] iteration 13562: loss: 0.079119, loss_s1: 0.068151, loss_fp: 0.007458, loss_freq: 0.030314
[04:52:24.916] iteration 13563: loss: 0.079479, loss_s1: 0.077629, loss_fp: 0.000582, loss_freq: 0.033091
[04:52:25.524] iteration 13564: loss: 0.068724, loss_s1: 0.042175, loss_fp: 0.004808, loss_freq: 0.026253
[04:52:26.128] iteration 13565: loss: 0.077049, loss_s1: 0.028105, loss_fp: 0.007601, loss_freq: 0.074534
[04:52:26.736] iteration 13566: loss: 0.052875, loss_s1: 0.049816, loss_fp: 0.005652, loss_freq: 0.010886
[04:52:27.340] iteration 13567: loss: 0.068085, loss_s1: 0.043803, loss_fp: 0.001751, loss_freq: 0.017723
[04:52:27.948] iteration 13568: loss: 0.074700, loss_s1: 0.082296, loss_fp: 0.003287, loss_freq: 0.031054
[04:52:28.559] iteration 13569: loss: 0.137725, loss_s1: 0.176797, loss_fp: 0.008116, loss_freq: 0.043908
[04:52:29.166] iteration 13570: loss: 0.095462, loss_s1: 0.069582, loss_fp: 0.001794, loss_freq: 0.080674
[04:52:29.774] iteration 13571: loss: 0.089606, loss_s1: 0.060042, loss_fp: 0.003765, loss_freq: 0.071031
[04:52:30.381] iteration 13572: loss: 0.071771, loss_s1: 0.065590, loss_fp: 0.002776, loss_freq: 0.030946
[04:52:30.989] iteration 13573: loss: 0.070815, loss_s1: 0.057204, loss_fp: 0.004930, loss_freq: 0.043423
[04:52:31.596] iteration 13574: loss: 0.072274, loss_s1: 0.078112, loss_fp: 0.002727, loss_freq: 0.018636
[04:52:32.201] iteration 13575: loss: 0.067987, loss_s1: 0.049879, loss_fp: 0.002641, loss_freq: 0.034406
[04:52:32.812] iteration 13576: loss: 0.063282, loss_s1: 0.053510, loss_fp: 0.002870, loss_freq: 0.011263
[04:52:33.423] iteration 13577: loss: 0.055481, loss_s1: 0.029844, loss_fp: 0.003780, loss_freq: 0.027884
[04:52:34.030] iteration 13578: loss: 0.098898, loss_s1: 0.120809, loss_fp: 0.002528, loss_freq: 0.030026
[04:52:34.638] iteration 13579: loss: 0.079386, loss_s1: 0.066526, loss_fp: 0.003674, loss_freq: 0.060162
[04:52:35.263] iteration 13580: loss: 0.058688, loss_s1: 0.042227, loss_fp: 0.010557, loss_freq: 0.014086
[04:52:35.865] iteration 13581: loss: 0.070941, loss_s1: 0.051391, loss_fp: 0.001225, loss_freq: 0.036999
[04:52:36.560] iteration 13582: loss: 0.122759, loss_s1: 0.143954, loss_fp: 0.000659, loss_freq: 0.064660
[04:52:37.219] iteration 13583: loss: 0.075333, loss_s1: 0.072825, loss_fp: 0.009210, loss_freq: 0.028666
[04:52:37.872] iteration 13584: loss: 0.058084, loss_s1: 0.024610, loss_fp: 0.002625, loss_freq: 0.046836
[04:52:38.528] iteration 13585: loss: 0.126957, loss_s1: 0.099547, loss_fp: 0.011042, loss_freq: 0.078453
[04:52:39.185] iteration 13586: loss: 0.075060, loss_s1: 0.050584, loss_fp: 0.003093, loss_freq: 0.025685
[04:52:39.833] iteration 13587: loss: 0.049626, loss_s1: 0.050789, loss_fp: 0.001865, loss_freq: 0.017615
[04:52:40.453] iteration 13588: loss: 0.075277, loss_s1: 0.062738, loss_fp: 0.005096, loss_freq: 0.042515
[04:52:41.083] iteration 13589: loss: 0.072097, loss_s1: 0.089831, loss_fp: 0.001990, loss_freq: 0.020417
[04:52:41.698] iteration 13590: loss: 0.089728, loss_s1: 0.079060, loss_fp: 0.010055, loss_freq: 0.041490
[04:52:42.332] iteration 13591: loss: 0.040303, loss_s1: 0.022858, loss_fp: 0.002584, loss_freq: 0.008374
[04:52:42.982] iteration 13592: loss: 0.049959, loss_s1: 0.031265, loss_fp: 0.005611, loss_freq: 0.031712
[04:52:43.638] iteration 13593: loss: 0.058127, loss_s1: 0.023349, loss_fp: 0.001855, loss_freq: 0.024982
[04:52:44.243] iteration 13594: loss: 0.049825, loss_s1: 0.044341, loss_fp: 0.001839, loss_freq: 0.022437
[04:52:44.842] iteration 13595: loss: 0.035825, loss_s1: 0.021561, loss_fp: 0.003251, loss_freq: 0.009229
[04:52:45.444] iteration 13596: loss: 0.081840, loss_s1: 0.076659, loss_fp: 0.006568, loss_freq: 0.044719
[04:52:46.047] iteration 13597: loss: 0.070470, loss_s1: 0.044347, loss_fp: 0.002632, loss_freq: 0.046774
[04:52:46.650] iteration 13598: loss: 0.107381, loss_s1: 0.134067, loss_fp: 0.006608, loss_freq: 0.031475
[04:52:47.249] iteration 13599: loss: 0.096725, loss_s1: 0.102250, loss_fp: 0.006644, loss_freq: 0.052837
[04:52:47.862] iteration 13600: loss: 0.082035, loss_s1: 0.085039, loss_fp: 0.005446, loss_freq: 0.031368
[04:52:51.304] iteration 13600 : mean_dice : 0.701704
[04:52:52.303] iteration 13601: loss: 0.059633, loss_s1: 0.055072, loss_fp: 0.003929, loss_freq: 0.012936
[04:52:52.920] iteration 13602: loss: 0.051597, loss_s1: 0.026330, loss_fp: 0.003399, loss_freq: 0.033127
[04:52:53.533] iteration 13603: loss: 0.076039, loss_s1: 0.085443, loss_fp: 0.003951, loss_freq: 0.019450
[04:52:54.160] iteration 13604: loss: 0.072378, loss_s1: 0.079738, loss_fp: 0.004495, loss_freq: 0.018310
[04:52:54.769] iteration 13605: loss: 0.064120, loss_s1: 0.049108, loss_fp: 0.009669, loss_freq: 0.028580
[04:52:55.389] iteration 13606: loss: 0.079085, loss_s1: 0.073790, loss_fp: 0.003405, loss_freq: 0.036566
[04:52:56.010] iteration 13607: loss: 0.090096, loss_s1: 0.065791, loss_fp: 0.005597, loss_freq: 0.065590
[04:52:56.635] iteration 13608: loss: 0.080195, loss_s1: 0.054857, loss_fp: 0.010832, loss_freq: 0.050063
[04:52:57.247] iteration 13609: loss: 0.079191, loss_s1: 0.068511, loss_fp: 0.021715, loss_freq: 0.025345
[04:52:57.860] iteration 13610: loss: 0.108564, loss_s1: 0.123138, loss_fp: 0.005376, loss_freq: 0.046945
[04:52:58.471] iteration 13611: loss: 0.074954, loss_s1: 0.035396, loss_fp: 0.003317, loss_freq: 0.065619
[04:52:59.079] iteration 13612: loss: 0.082983, loss_s1: 0.085892, loss_fp: 0.001944, loss_freq: 0.043165
[04:52:59.688] iteration 13613: loss: 0.076225, loss_s1: 0.060496, loss_fp: 0.001656, loss_freq: 0.037188
[04:53:00.305] iteration 13614: loss: 0.064674, loss_s1: 0.060053, loss_fp: 0.003229, loss_freq: 0.029374
[04:53:00.963] iteration 13615: loss: 0.082620, loss_s1: 0.070967, loss_fp: 0.002364, loss_freq: 0.027854
[04:53:01.645] iteration 13616: loss: 0.069362, loss_s1: 0.066452, loss_fp: 0.006220, loss_freq: 0.026233
[04:53:02.300] iteration 13617: loss: 0.139996, loss_s1: 0.128875, loss_fp: 0.002808, loss_freq: 0.115959
[04:53:02.911] iteration 13618: loss: 0.045233, loss_s1: 0.034771, loss_fp: 0.001222, loss_freq: 0.010585
[04:53:03.526] iteration 13619: loss: 0.115862, loss_s1: 0.111382, loss_fp: 0.011259, loss_freq: 0.063333
[04:53:04.145] iteration 13620: loss: 0.056385, loss_s1: 0.042397, loss_fp: 0.001543, loss_freq: 0.028263
[04:53:04.788] iteration 13621: loss: 0.049396, loss_s1: 0.037128, loss_fp: 0.002279, loss_freq: 0.018696
[04:53:05.431] iteration 13622: loss: 0.083442, loss_s1: 0.078634, loss_fp: 0.002648, loss_freq: 0.032346
[04:53:06.056] iteration 13623: loss: 0.075814, loss_s1: 0.060259, loss_fp: 0.002956, loss_freq: 0.042585
[04:53:06.679] iteration 13624: loss: 0.066589, loss_s1: 0.046080, loss_fp: 0.002306, loss_freq: 0.033372
[04:53:07.306] iteration 13625: loss: 0.107704, loss_s1: 0.101052, loss_fp: 0.001474, loss_freq: 0.053794
[04:53:07.920] iteration 13626: loss: 0.080022, loss_s1: 0.064682, loss_fp: 0.010957, loss_freq: 0.050317
[04:53:08.728] iteration 13627: loss: 0.090650, loss_s1: 0.073816, loss_fp: 0.004296, loss_freq: 0.032888
[04:53:09.448] iteration 13628: loss: 0.096991, loss_s1: 0.095404, loss_fp: 0.001483, loss_freq: 0.009291
[04:53:10.091] iteration 13629: loss: 0.044675, loss_s1: 0.023294, loss_fp: 0.005133, loss_freq: 0.018029
[04:53:10.840] iteration 13630: loss: 0.085288, loss_s1: 0.060185, loss_fp: 0.002503, loss_freq: 0.049993
[04:53:11.501] iteration 13631: loss: 0.087000, loss_s1: 0.062171, loss_fp: 0.008940, loss_freq: 0.067239
[04:53:12.148] iteration 13632: loss: 0.080921, loss_s1: 0.047877, loss_fp: 0.001691, loss_freq: 0.024985
[04:53:12.764] iteration 13633: loss: 0.062153, loss_s1: 0.063704, loss_fp: 0.002951, loss_freq: 0.022980
[04:53:13.375] iteration 13634: loss: 0.047002, loss_s1: 0.043697, loss_fp: 0.002264, loss_freq: 0.008037
[04:53:13.990] iteration 13635: loss: 0.063985, loss_s1: 0.033189, loss_fp: 0.002721, loss_freq: 0.061896
[04:53:14.601] iteration 13636: loss: 0.059324, loss_s1: 0.041380, loss_fp: 0.003352, loss_freq: 0.021543
[04:53:15.222] iteration 13637: loss: 0.060188, loss_s1: 0.052382, loss_fp: 0.000942, loss_freq: 0.023610
[04:53:15.840] iteration 13638: loss: 0.081853, loss_s1: 0.087570, loss_fp: 0.001147, loss_freq: 0.028969
[04:53:16.448] iteration 13639: loss: 0.095856, loss_s1: 0.068324, loss_fp: 0.007499, loss_freq: 0.057067
[04:53:17.063] iteration 13640: loss: 0.076067, loss_s1: 0.069867, loss_fp: 0.006141, loss_freq: 0.041305
[04:53:17.682] iteration 13641: loss: 0.071662, loss_s1: 0.051345, loss_fp: 0.004267, loss_freq: 0.045328
[04:53:18.329] iteration 13642: loss: 0.071567, loss_s1: 0.066785, loss_fp: 0.000634, loss_freq: 0.028124
[04:53:18.951] iteration 13643: loss: 0.086625, loss_s1: 0.098922, loss_fp: 0.004056, loss_freq: 0.035178
[04:53:19.561] iteration 13644: loss: 0.125345, loss_s1: 0.139708, loss_fp: 0.008136, loss_freq: 0.063912
[04:53:20.174] iteration 13645: loss: 0.073087, loss_s1: 0.066899, loss_fp: 0.002461, loss_freq: 0.028394
[04:53:20.787] iteration 13646: loss: 0.075736, loss_s1: 0.053352, loss_fp: 0.007486, loss_freq: 0.045675
[04:53:21.399] iteration 13647: loss: 0.052176, loss_s1: 0.035522, loss_fp: 0.002542, loss_freq: 0.028207
[04:53:22.029] iteration 13648: loss: 0.055458, loss_s1: 0.038865, loss_fp: 0.002034, loss_freq: 0.028180
[04:53:22.644] iteration 13649: loss: 0.042666, loss_s1: 0.029551, loss_fp: 0.002848, loss_freq: 0.009273
[04:53:23.260] iteration 13650: loss: 0.055508, loss_s1: 0.037343, loss_fp: 0.003645, loss_freq: 0.026421
[04:53:23.866] iteration 13651: loss: 0.060745, loss_s1: 0.033870, loss_fp: 0.001511, loss_freq: 0.024569
[04:53:24.483] iteration 13652: loss: 0.056974, loss_s1: 0.051653, loss_fp: 0.005282, loss_freq: 0.025997
[04:53:25.093] iteration 13653: loss: 0.057821, loss_s1: 0.044022, loss_fp: 0.001342, loss_freq: 0.012548
[04:53:25.703] iteration 13654: loss: 0.076129, loss_s1: 0.060346, loss_fp: 0.006619, loss_freq: 0.040533
[04:53:26.320] iteration 13655: loss: 0.071364, loss_s1: 0.046935, loss_fp: 0.003436, loss_freq: 0.045511
[04:53:26.936] iteration 13656: loss: 0.055291, loss_s1: 0.032677, loss_fp: 0.003555, loss_freq: 0.023705
[04:53:27.547] iteration 13657: loss: 0.076211, loss_s1: 0.053868, loss_fp: 0.003232, loss_freq: 0.051011
[04:53:28.160] iteration 13658: loss: 0.074395, loss_s1: 0.036523, loss_fp: 0.010284, loss_freq: 0.026818
[04:53:28.779] iteration 13659: loss: 0.084254, loss_s1: 0.030079, loss_fp: 0.002109, loss_freq: 0.066884
[04:53:29.397] iteration 13660: loss: 0.081680, loss_s1: 0.050199, loss_fp: 0.009496, loss_freq: 0.053400
[04:53:30.004] iteration 13661: loss: 0.056312, loss_s1: 0.062185, loss_fp: 0.001918, loss_freq: 0.011227
[04:53:30.612] iteration 13662: loss: 0.106129, loss_s1: 0.041080, loss_fp: 0.007302, loss_freq: 0.059009
[04:53:31.229] iteration 13663: loss: 0.051191, loss_s1: 0.034159, loss_fp: 0.003215, loss_freq: 0.018207
[04:53:31.876] iteration 13664: loss: 0.047627, loss_s1: 0.025803, loss_fp: 0.001772, loss_freq: 0.027718
[04:53:32.542] iteration 13665: loss: 0.121258, loss_s1: 0.150748, loss_fp: 0.003930, loss_freq: 0.036614
[04:53:33.232] iteration 13666: loss: 0.071589, loss_s1: 0.057098, loss_fp: 0.002472, loss_freq: 0.050261
[04:53:33.891] iteration 13667: loss: 0.051537, loss_s1: 0.026853, loss_fp: 0.001043, loss_freq: 0.014490
[04:53:34.524] iteration 13668: loss: 0.111687, loss_s1: 0.104023, loss_fp: 0.009241, loss_freq: 0.070733
[04:53:35.137] iteration 13669: loss: 0.056371, loss_s1: 0.034813, loss_fp: 0.002339, loss_freq: 0.023353
[04:53:35.746] iteration 13670: loss: 0.056614, loss_s1: 0.035947, loss_fp: 0.002183, loss_freq: 0.039276
[04:53:36.359] iteration 13671: loss: 0.076348, loss_s1: 0.061817, loss_fp: 0.003714, loss_freq: 0.031261
[04:53:36.971] iteration 13672: loss: 0.059937, loss_s1: 0.044550, loss_fp: 0.004351, loss_freq: 0.029821
[04:53:37.583] iteration 13673: loss: 0.068089, loss_s1: 0.060701, loss_fp: 0.007767, loss_freq: 0.027780
[04:53:38.196] iteration 13674: loss: 0.058100, loss_s1: 0.058515, loss_fp: 0.000953, loss_freq: 0.012579
[04:53:38.802] iteration 13675: loss: 0.050895, loss_s1: 0.020064, loss_fp: 0.002278, loss_freq: 0.047010
[04:53:39.416] iteration 13676: loss: 0.071222, loss_s1: 0.038315, loss_fp: 0.005043, loss_freq: 0.060873
[04:53:40.099] iteration 13677: loss: 0.066655, loss_s1: 0.064508, loss_fp: 0.005268, loss_freq: 0.028113
[04:53:40.750] iteration 13678: loss: 0.082727, loss_s1: 0.075959, loss_fp: 0.007640, loss_freq: 0.033958
[04:53:41.396] iteration 13679: loss: 0.062262, loss_s1: 0.031806, loss_fp: 0.008240, loss_freq: 0.048429
[04:53:42.035] iteration 13680: loss: 0.071060, loss_s1: 0.050249, loss_fp: 0.003103, loss_freq: 0.042685
[04:53:42.656] iteration 13681: loss: 0.067159, loss_s1: 0.048588, loss_fp: 0.003733, loss_freq: 0.032494
[04:53:43.265] iteration 13682: loss: 0.067616, loss_s1: 0.040277, loss_fp: 0.003725, loss_freq: 0.056033
[04:53:43.876] iteration 13683: loss: 0.113047, loss_s1: 0.121625, loss_fp: 0.008949, loss_freq: 0.032306
[04:53:44.481] iteration 13684: loss: 0.081783, loss_s1: 0.042162, loss_fp: 0.001562, loss_freq: 0.028587
[04:53:45.091] iteration 13685: loss: 0.064968, loss_s1: 0.044535, loss_fp: 0.005764, loss_freq: 0.021116
[04:53:45.699] iteration 13686: loss: 0.059901, loss_s1: 0.045087, loss_fp: 0.006636, loss_freq: 0.027580
[04:53:46.310] iteration 13687: loss: 0.075056, loss_s1: 0.094669, loss_fp: 0.003545, loss_freq: 0.026770
[04:53:46.926] iteration 13688: loss: 0.077429, loss_s1: 0.100566, loss_fp: 0.003359, loss_freq: 0.010934
[04:53:47.538] iteration 13689: loss: 0.097196, loss_s1: 0.083392, loss_fp: 0.016721, loss_freq: 0.056671
[04:53:48.149] iteration 13690: loss: 0.068789, loss_s1: 0.054136, loss_fp: 0.009839, loss_freq: 0.020222
[04:53:48.762] iteration 13691: loss: 0.080797, loss_s1: 0.068302, loss_fp: 0.007456, loss_freq: 0.035346
[04:53:49.374] iteration 13692: loss: 0.068713, loss_s1: 0.043689, loss_fp: 0.001647, loss_freq: 0.041531
[04:53:49.987] iteration 13693: loss: 0.049723, loss_s1: 0.024459, loss_fp: 0.004515, loss_freq: 0.024100
[04:53:50.618] iteration 13694: loss: 0.064950, loss_s1: 0.072406, loss_fp: 0.004332, loss_freq: 0.007472
[04:53:51.343] iteration 13695: loss: 0.090978, loss_s1: 0.056846, loss_fp: 0.007918, loss_freq: 0.067745
[04:53:52.045] iteration 13696: loss: 0.066204, loss_s1: 0.058196, loss_fp: 0.005687, loss_freq: 0.040367
[04:53:52.716] iteration 13697: loss: 0.077236, loss_s1: 0.064648, loss_fp: 0.002995, loss_freq: 0.026580
[04:53:53.373] iteration 13698: loss: 0.073910, loss_s1: 0.065716, loss_fp: 0.001843, loss_freq: 0.032996
[04:53:54.032] iteration 13699: loss: 0.056675, loss_s1: 0.040160, loss_fp: 0.004668, loss_freq: 0.032808
[04:53:54.690] iteration 13700: loss: 0.049242, loss_s1: 0.029102, loss_fp: 0.001159, loss_freq: 0.021082
[04:53:55.323] iteration 13701: loss: 0.078656, loss_s1: 0.092081, loss_fp: 0.002230, loss_freq: 0.033623
[04:53:55.925] iteration 13702: loss: 0.067876, loss_s1: 0.038187, loss_fp: 0.008131, loss_freq: 0.018088
[04:53:56.533] iteration 13703: loss: 0.057010, loss_s1: 0.029248, loss_fp: 0.001864, loss_freq: 0.025560
[04:53:57.154] iteration 13704: loss: 0.039815, loss_s1: 0.011656, loss_fp: 0.002825, loss_freq: 0.021757
[04:53:57.767] iteration 13705: loss: 0.068926, loss_s1: 0.043310, loss_fp: 0.006498, loss_freq: 0.058659
[04:53:58.374] iteration 13706: loss: 0.088222, loss_s1: 0.110180, loss_fp: 0.005378, loss_freq: 0.019188
[04:53:58.984] iteration 13707: loss: 0.081497, loss_s1: 0.093436, loss_fp: 0.001858, loss_freq: 0.026972
[04:53:59.590] iteration 13708: loss: 0.054083, loss_s1: 0.035127, loss_fp: 0.002866, loss_freq: 0.032370
[04:54:00.202] iteration 13709: loss: 0.086953, loss_s1: 0.058241, loss_fp: 0.003676, loss_freq: 0.073969
[04:54:00.814] iteration 13710: loss: 0.067907, loss_s1: 0.052558, loss_fp: 0.005332, loss_freq: 0.041311
[04:54:01.421] iteration 13711: loss: 0.079946, loss_s1: 0.055506, loss_fp: 0.002778, loss_freq: 0.044451
[04:54:02.025] iteration 13712: loss: 0.075870, loss_s1: 0.070352, loss_fp: 0.004795, loss_freq: 0.030924
[04:54:02.631] iteration 13713: loss: 0.066360, loss_s1: 0.066383, loss_fp: 0.004643, loss_freq: 0.029900
[04:54:03.236] iteration 13714: loss: 0.030766, loss_s1: 0.017928, loss_fp: 0.001420, loss_freq: 0.010421
[04:54:03.843] iteration 13715: loss: 0.083490, loss_s1: 0.061342, loss_fp: 0.009329, loss_freq: 0.047503
[04:54:04.451] iteration 13716: loss: 0.075720, loss_s1: 0.035752, loss_fp: 0.002670, loss_freq: 0.041697
[04:54:05.060] iteration 13717: loss: 0.081549, loss_s1: 0.081486, loss_fp: 0.004175, loss_freq: 0.035828
[04:54:05.668] iteration 13718: loss: 0.063240, loss_s1: 0.044416, loss_fp: 0.004621, loss_freq: 0.033299
[04:54:06.284] iteration 13719: loss: 0.076382, loss_s1: 0.033624, loss_fp: 0.003324, loss_freq: 0.080153
[04:54:06.897] iteration 13720: loss: 0.050450, loss_s1: 0.033884, loss_fp: 0.000421, loss_freq: 0.005801
[04:54:07.518] iteration 13721: loss: 0.060408, loss_s1: 0.060485, loss_fp: 0.010027, loss_freq: 0.009879
[04:54:08.124] iteration 13722: loss: 0.068053, loss_s1: 0.063868, loss_fp: 0.004354, loss_freq: 0.033979
[04:54:08.729] iteration 13723: loss: 0.081394, loss_s1: 0.069231, loss_fp: 0.004314, loss_freq: 0.037225
[04:54:09.332] iteration 13724: loss: 0.045500, loss_s1: 0.026264, loss_fp: 0.003842, loss_freq: 0.027296
[04:54:09.933] iteration 13725: loss: 0.086523, loss_s1: 0.077126, loss_fp: 0.001583, loss_freq: 0.034123
[04:54:10.548] iteration 13726: loss: 0.043013, loss_s1: 0.017287, loss_fp: 0.003087, loss_freq: 0.017948
[04:54:11.152] iteration 13727: loss: 0.064362, loss_s1: 0.030380, loss_fp: 0.001367, loss_freq: 0.055301
[04:54:11.807] iteration 13728: loss: 0.080040, loss_s1: 0.062959, loss_fp: 0.008899, loss_freq: 0.032461
[04:54:12.467] iteration 13729: loss: 0.053945, loss_s1: 0.049065, loss_fp: 0.004492, loss_freq: 0.019331
[04:54:13.123] iteration 13730: loss: 0.079300, loss_s1: 0.044225, loss_fp: 0.005600, loss_freq: 0.068315
[04:54:13.778] iteration 13731: loss: 0.055594, loss_s1: 0.042838, loss_fp: 0.003109, loss_freq: 0.018023
[04:54:14.444] iteration 13732: loss: 0.074875, loss_s1: 0.066711, loss_fp: 0.001630, loss_freq: 0.023278
[04:54:15.099] iteration 13733: loss: 0.073335, loss_s1: 0.070929, loss_fp: 0.003019, loss_freq: 0.024214
[04:54:15.752] iteration 13734: loss: 0.083000, loss_s1: 0.102120, loss_fp: 0.005735, loss_freq: 0.024938
[04:54:16.402] iteration 13735: loss: 0.137826, loss_s1: 0.069895, loss_fp: 0.001414, loss_freq: 0.158124
[04:54:17.012] iteration 13736: loss: 0.074535, loss_s1: 0.092720, loss_fp: 0.006121, loss_freq: 0.018951
[04:54:17.624] iteration 13737: loss: 0.078147, loss_s1: 0.054964, loss_fp: 0.005183, loss_freq: 0.030800
[04:54:18.243] iteration 13738: loss: 0.064023, loss_s1: 0.050059, loss_fp: 0.002513, loss_freq: 0.043670
[04:54:18.856] iteration 13739: loss: 0.083474, loss_s1: 0.082959, loss_fp: 0.001983, loss_freq: 0.037552
[04:54:19.516] iteration 13740: loss: 0.084965, loss_s1: 0.104816, loss_fp: 0.001108, loss_freq: 0.038685
[04:54:20.181] iteration 13741: loss: 0.082615, loss_s1: 0.071429, loss_fp: 0.004395, loss_freq: 0.046896
[04:54:20.839] iteration 13742: loss: 0.050943, loss_s1: 0.031566, loss_fp: 0.004950, loss_freq: 0.022019
[04:54:21.503] iteration 13743: loss: 0.064897, loss_s1: 0.047365, loss_fp: 0.001226, loss_freq: 0.038054
[04:54:22.113] iteration 13744: loss: 0.056425, loss_s1: 0.023752, loss_fp: 0.010708, loss_freq: 0.031221
[04:54:22.729] iteration 13745: loss: 0.051175, loss_s1: 0.042990, loss_fp: 0.005573, loss_freq: 0.006507
[04:54:23.339] iteration 13746: loss: 0.069427, loss_s1: 0.048017, loss_fp: 0.003961, loss_freq: 0.037091
[04:54:23.944] iteration 13747: loss: 0.064677, loss_s1: 0.060308, loss_fp: 0.002195, loss_freq: 0.017851
[04:54:24.547] iteration 13748: loss: 0.099184, loss_s1: 0.100747, loss_fp: 0.003517, loss_freq: 0.049064
[04:54:25.158] iteration 13749: loss: 0.067804, loss_s1: 0.067514, loss_fp: 0.010280, loss_freq: 0.033105
[04:54:25.773] iteration 13750: loss: 0.093343, loss_s1: 0.044662, loss_fp: 0.009886, loss_freq: 0.060989
[04:54:26.387] iteration 13751: loss: 0.106205, loss_s1: 0.137907, loss_fp: 0.010051, loss_freq: 0.020625
[04:54:26.999] iteration 13752: loss: 0.078828, loss_s1: 0.060656, loss_fp: 0.013050, loss_freq: 0.047724
[04:54:27.604] iteration 13753: loss: 0.125676, loss_s1: 0.090434, loss_fp: 0.006029, loss_freq: 0.110417
[04:54:28.220] iteration 13754: loss: 0.097364, loss_s1: 0.096441, loss_fp: 0.004555, loss_freq: 0.059609
[04:54:28.891] iteration 13755: loss: 0.082811, loss_s1: 0.067939, loss_fp: 0.006252, loss_freq: 0.033439
[04:54:29.501] iteration 13756: loss: 0.053351, loss_s1: 0.012350, loss_fp: 0.001430, loss_freq: 0.040272
[04:54:30.115] iteration 13757: loss: 0.076581, loss_s1: 0.055890, loss_fp: 0.005464, loss_freq: 0.031598
[04:54:30.734] iteration 13758: loss: 0.108193, loss_s1: 0.116300, loss_fp: 0.004310, loss_freq: 0.047520
[04:54:31.396] iteration 13759: loss: 0.099313, loss_s1: 0.110300, loss_fp: 0.007280, loss_freq: 0.039769
[04:54:32.051] iteration 13760: loss: 0.071438, loss_s1: 0.063386, loss_fp: 0.001338, loss_freq: 0.034799
[04:54:32.704] iteration 13761: loss: 0.048746, loss_s1: 0.028426, loss_fp: 0.002718, loss_freq: 0.017059
[04:54:33.355] iteration 13762: loss: 0.054736, loss_s1: 0.042808, loss_fp: 0.005181, loss_freq: 0.012757
[04:54:33.969] iteration 13763: loss: 0.064815, loss_s1: 0.029209, loss_fp: 0.004257, loss_freq: 0.039232
[04:54:34.571] iteration 13764: loss: 0.067219, loss_s1: 0.070187, loss_fp: 0.005247, loss_freq: 0.025034
[04:54:35.180] iteration 13765: loss: 0.056824, loss_s1: 0.028199, loss_fp: 0.004642, loss_freq: 0.017648
[04:54:35.793] iteration 13766: loss: 0.058253, loss_s1: 0.047224, loss_fp: 0.001689, loss_freq: 0.039092
[04:54:36.405] iteration 13767: loss: 0.070798, loss_s1: 0.054775, loss_fp: 0.004741, loss_freq: 0.035898
[04:54:37.018] iteration 13768: loss: 0.085427, loss_s1: 0.072780, loss_fp: 0.001580, loss_freq: 0.054444
[04:54:37.615] iteration 13769: loss: 0.109203, loss_s1: 0.113623, loss_fp: 0.007205, loss_freq: 0.063779
[04:54:38.225] iteration 13770: loss: 0.077477, loss_s1: 0.068864, loss_fp: 0.002812, loss_freq: 0.033256
[04:54:39.183] iteration 13771: loss: 0.078321, loss_s1: 0.090864, loss_fp: 0.002692, loss_freq: 0.017249
[04:54:39.856] iteration 13772: loss: 0.079190, loss_s1: 0.062311, loss_fp: 0.001194, loss_freq: 0.053370
[04:54:40.494] iteration 13773: loss: 0.067393, loss_s1: 0.075299, loss_fp: 0.005364, loss_freq: 0.019539
[04:54:41.109] iteration 13774: loss: 0.065751, loss_s1: 0.055178, loss_fp: 0.003167, loss_freq: 0.018575
[04:54:41.736] iteration 13775: loss: 0.063768, loss_s1: 0.066343, loss_fp: 0.006571, loss_freq: 0.018165
[04:54:42.350] iteration 13776: loss: 0.057472, loss_s1: 0.035605, loss_fp: 0.004321, loss_freq: 0.030254
[04:54:43.011] iteration 13777: loss: 0.056511, loss_s1: 0.030783, loss_fp: 0.003300, loss_freq: 0.032619
[04:54:43.687] iteration 13778: loss: 0.051729, loss_s1: 0.038972, loss_fp: 0.001549, loss_freq: 0.032086
[04:54:44.326] iteration 13779: loss: 0.056848, loss_s1: 0.046372, loss_fp: 0.004360, loss_freq: 0.034183
[04:54:44.934] iteration 13780: loss: 0.060341, loss_s1: 0.035853, loss_fp: 0.006307, loss_freq: 0.033975
[04:54:45.542] iteration 13781: loss: 0.054853, loss_s1: 0.025308, loss_fp: 0.000332, loss_freq: 0.036076
[04:54:46.156] iteration 13782: loss: 0.099749, loss_s1: 0.102588, loss_fp: 0.003348, loss_freq: 0.052306
[04:54:46.766] iteration 13783: loss: 0.060401, loss_s1: 0.051931, loss_fp: 0.003789, loss_freq: 0.022493
[04:54:47.376] iteration 13784: loss: 0.067918, loss_s1: 0.038227, loss_fp: 0.004051, loss_freq: 0.044057
[04:54:47.984] iteration 13785: loss: 0.065547, loss_s1: 0.050453, loss_fp: 0.001174, loss_freq: 0.033433
[04:54:48.596] iteration 13786: loss: 0.058464, loss_s1: 0.042206, loss_fp: 0.006018, loss_freq: 0.015907
[04:54:49.211] iteration 13787: loss: 0.101575, loss_s1: 0.101812, loss_fp: 0.001065, loss_freq: 0.074309
[04:54:49.835] iteration 13788: loss: 0.043172, loss_s1: 0.013975, loss_fp: 0.002754, loss_freq: 0.014283
[04:54:50.446] iteration 13789: loss: 0.102210, loss_s1: 0.116949, loss_fp: 0.003121, loss_freq: 0.052857
[04:54:51.062] iteration 13790: loss: 0.071862, loss_s1: 0.071286, loss_fp: 0.003355, loss_freq: 0.022975
[04:54:51.677] iteration 13791: loss: 0.073249, loss_s1: 0.063677, loss_fp: 0.002692, loss_freq: 0.031036
[04:54:52.283] iteration 13792: loss: 0.082410, loss_s1: 0.092240, loss_fp: 0.002582, loss_freq: 0.031147
[04:54:52.892] iteration 13793: loss: 0.086484, loss_s1: 0.046021, loss_fp: 0.002916, loss_freq: 0.071370
[04:54:53.499] iteration 13794: loss: 0.075994, loss_s1: 0.089538, loss_fp: 0.001394, loss_freq: 0.025555
[04:54:54.104] iteration 13795: loss: 0.059207, loss_s1: 0.030926, loss_fp: 0.002513, loss_freq: 0.036235
[04:54:54.707] iteration 13796: loss: 0.045866, loss_s1: 0.034147, loss_fp: 0.003767, loss_freq: 0.024506
[04:54:55.317] iteration 13797: loss: 0.081661, loss_s1: 0.084287, loss_fp: 0.012006, loss_freq: 0.024640
[04:54:55.932] iteration 13798: loss: 0.129770, loss_s1: 0.140761, loss_fp: 0.008433, loss_freq: 0.036707
[04:54:56.549] iteration 13799: loss: 0.081173, loss_s1: 0.091596, loss_fp: 0.001347, loss_freq: 0.029957
[04:54:57.160] iteration 13800: loss: 0.119967, loss_s1: 0.157120, loss_fp: 0.004762, loss_freq: 0.030495
[04:55:00.817] iteration 13800 : mean_dice : 0.711396
[04:55:01.492] iteration 13801: loss: 0.066307, loss_s1: 0.052087, loss_fp: 0.002030, loss_freq: 0.051320
[04:55:02.140] iteration 13802: loss: 0.107418, loss_s1: 0.115038, loss_fp: 0.003571, loss_freq: 0.042391
[04:55:02.760] iteration 13803: loss: 0.097703, loss_s1: 0.074375, loss_fp: 0.003486, loss_freq: 0.055377
[04:55:03.366] iteration 13804: loss: 0.062852, loss_s1: 0.040792, loss_fp: 0.005477, loss_freq: 0.023409
[04:55:03.975] iteration 13805: loss: 0.086909, loss_s1: 0.101797, loss_fp: 0.005434, loss_freq: 0.034970
[04:55:04.587] iteration 13806: loss: 0.043729, loss_s1: 0.029599, loss_fp: 0.001293, loss_freq: 0.015223
[04:55:05.200] iteration 13807: loss: 0.062630, loss_s1: 0.040165, loss_fp: 0.003618, loss_freq: 0.032156
[04:55:05.810] iteration 13808: loss: 0.083314, loss_s1: 0.060483, loss_fp: 0.002426, loss_freq: 0.060332
[04:55:06.427] iteration 13809: loss: 0.091657, loss_s1: 0.066776, loss_fp: 0.008299, loss_freq: 0.065466
[04:55:07.037] iteration 13810: loss: 0.090194, loss_s1: 0.088389, loss_fp: 0.001438, loss_freq: 0.045716
[04:55:07.663] iteration 13811: loss: 0.090473, loss_s1: 0.126489, loss_fp: 0.000313, loss_freq: 0.007464
[04:55:08.286] iteration 13812: loss: 0.073642, loss_s1: 0.058835, loss_fp: 0.005148, loss_freq: 0.032646
[04:55:08.899] iteration 13813: loss: 0.082409, loss_s1: 0.091613, loss_fp: 0.001963, loss_freq: 0.030168
[04:55:09.510] iteration 13814: loss: 0.104173, loss_s1: 0.097519, loss_fp: 0.004157, loss_freq: 0.067091
[04:55:10.188] iteration 13815: loss: 0.086765, loss_s1: 0.054755, loss_fp: 0.004598, loss_freq: 0.040776
[04:55:10.853] iteration 13816: loss: 0.065338, loss_s1: 0.059083, loss_fp: 0.004282, loss_freq: 0.031384
[04:55:11.507] iteration 13817: loss: 0.046442, loss_s1: 0.025603, loss_fp: 0.005165, loss_freq: 0.017781
[04:55:12.148] iteration 13818: loss: 0.052733, loss_s1: 0.039855, loss_fp: 0.006745, loss_freq: 0.018789
[04:55:12.785] iteration 13819: loss: 0.073540, loss_s1: 0.067635, loss_fp: 0.002554, loss_freq: 0.011905
[04:55:13.585] iteration 13820: loss: 0.041607, loss_s1: 0.015969, loss_fp: 0.001350, loss_freq: 0.017356
[04:55:14.347] iteration 13821: loss: 0.051822, loss_s1: 0.029005, loss_fp: 0.002155, loss_freq: 0.032395
[04:55:14.987] iteration 13822: loss: 0.049512, loss_s1: 0.054551, loss_fp: 0.003441, loss_freq: 0.016653
[04:55:15.601] iteration 13823: loss: 0.086294, loss_s1: 0.046527, loss_fp: 0.002066, loss_freq: 0.085261
[04:55:16.208] iteration 13824: loss: 0.066629, loss_s1: 0.056159, loss_fp: 0.003474, loss_freq: 0.031714
[04:55:16.819] iteration 13825: loss: 0.064041, loss_s1: 0.017552, loss_fp: 0.000885, loss_freq: 0.062980
[04:55:17.425] iteration 13826: loss: 0.067371, loss_s1: 0.060341, loss_fp: 0.001654, loss_freq: 0.031486
[04:55:18.035] iteration 13827: loss: 0.074785, loss_s1: 0.067377, loss_fp: 0.003454, loss_freq: 0.037561
[04:55:18.642] iteration 13828: loss: 0.056035, loss_s1: 0.018569, loss_fp: 0.005488, loss_freq: 0.025811
[04:55:19.253] iteration 13829: loss: 0.053687, loss_s1: 0.052160, loss_fp: 0.001170, loss_freq: 0.025431
[04:55:19.865] iteration 13830: loss: 0.087389, loss_s1: 0.063140, loss_fp: 0.002876, loss_freq: 0.049330
[04:55:20.477] iteration 13831: loss: 0.046577, loss_s1: 0.045033, loss_fp: 0.004010, loss_freq: 0.011684
[04:55:21.132] iteration 13832: loss: 0.068207, loss_s1: 0.052159, loss_fp: 0.000994, loss_freq: 0.028277
[04:55:21.798] iteration 13833: loss: 0.069548, loss_s1: 0.072609, loss_fp: 0.001435, loss_freq: 0.019213
[04:55:22.418] iteration 13834: loss: 0.052643, loss_s1: 0.032298, loss_fp: 0.008601, loss_freq: 0.025016
[04:55:23.046] iteration 13835: loss: 0.138120, loss_s1: 0.195050, loss_fp: 0.007871, loss_freq: 0.020995
[04:55:23.676] iteration 13836: loss: 0.065651, loss_s1: 0.062653, loss_fp: 0.002022, loss_freq: 0.034370
[04:55:24.299] iteration 13837: loss: 0.050948, loss_s1: 0.023324, loss_fp: 0.001304, loss_freq: 0.025717
[04:55:24.931] iteration 13838: loss: 0.083553, loss_s1: 0.070976, loss_fp: 0.002386, loss_freq: 0.049446
[04:55:25.552] iteration 13839: loss: 0.100563, loss_s1: 0.107672, loss_fp: 0.005522, loss_freq: 0.043259
[04:55:26.160] iteration 13840: loss: 0.048773, loss_s1: 0.042523, loss_fp: 0.004794, loss_freq: 0.022096
[04:55:26.767] iteration 13841: loss: 0.076136, loss_s1: 0.053177, loss_fp: 0.001365, loss_freq: 0.045733
[04:55:27.387] iteration 13842: loss: 0.078042, loss_s1: 0.034070, loss_fp: 0.011292, loss_freq: 0.061454
[04:55:28.009] iteration 13843: loss: 0.060789, loss_s1: 0.046129, loss_fp: 0.006800, loss_freq: 0.035933
[04:55:28.632] iteration 13844: loss: 0.078684, loss_s1: 0.068272, loss_fp: 0.006412, loss_freq: 0.039083
[04:55:29.265] iteration 13845: loss: 0.071472, loss_s1: 0.041819, loss_fp: 0.002513, loss_freq: 0.053340
[04:55:29.888] iteration 13846: loss: 0.099161, loss_s1: 0.092381, loss_fp: 0.005121, loss_freq: 0.043463
[04:55:30.508] iteration 13847: loss: 0.065599, loss_s1: 0.050208, loss_fp: 0.007957, loss_freq: 0.025684
[04:55:31.122] iteration 13848: loss: 0.076565, loss_s1: 0.053039, loss_fp: 0.008054, loss_freq: 0.034005
[04:55:31.793] iteration 13849: loss: 0.045224, loss_s1: 0.027528, loss_fp: 0.006263, loss_freq: 0.032933
[04:55:32.447] iteration 13850: loss: 0.061569, loss_s1: 0.035967, loss_fp: 0.004350, loss_freq: 0.031918
[04:55:33.099] iteration 13851: loss: 0.110349, loss_s1: 0.126049, loss_fp: 0.001129, loss_freq: 0.039302
[04:55:33.755] iteration 13852: loss: 0.066504, loss_s1: 0.034612, loss_fp: 0.004444, loss_freq: 0.055205
[04:55:34.365] iteration 13853: loss: 0.055841, loss_s1: 0.050543, loss_fp: 0.004255, loss_freq: 0.024259
[04:55:34.979] iteration 13854: loss: 0.072121, loss_s1: 0.076691, loss_fp: 0.006053, loss_freq: 0.017905
[04:55:35.588] iteration 13855: loss: 0.046549, loss_s1: 0.016929, loss_fp: 0.002632, loss_freq: 0.029840
[04:55:36.200] iteration 13856: loss: 0.056257, loss_s1: 0.043074, loss_fp: 0.005438, loss_freq: 0.016539
[04:55:36.814] iteration 13857: loss: 0.091325, loss_s1: 0.115703, loss_fp: 0.002881, loss_freq: 0.038869
[04:55:37.425] iteration 13858: loss: 0.076899, loss_s1: 0.065337, loss_fp: 0.003515, loss_freq: 0.038775
[04:55:38.033] iteration 13859: loss: 0.114110, loss_s1: 0.088954, loss_fp: 0.003558, loss_freq: 0.076505
[04:55:38.640] iteration 13860: loss: 0.082314, loss_s1: 0.086355, loss_fp: 0.001686, loss_freq: 0.033025
[04:55:39.257] iteration 13861: loss: 0.078107, loss_s1: 0.077899, loss_fp: 0.004992, loss_freq: 0.031804
[04:55:39.871] iteration 13862: loss: 0.066225, loss_s1: 0.071334, loss_fp: 0.003602, loss_freq: 0.024680
[04:55:40.478] iteration 13863: loss: 0.136524, loss_s1: 0.137122, loss_fp: 0.002699, loss_freq: 0.077276
[04:55:41.085] iteration 13864: loss: 0.041140, loss_s1: 0.028971, loss_fp: 0.005495, loss_freq: 0.012713
[04:55:41.693] iteration 13865: loss: 0.055739, loss_s1: 0.035661, loss_fp: 0.001932, loss_freq: 0.019011
[04:55:42.376] iteration 13866: loss: 0.069899, loss_s1: 0.034865, loss_fp: 0.002584, loss_freq: 0.061795
[04:55:43.015] iteration 13867: loss: 0.100945, loss_s1: 0.059328, loss_fp: 0.002835, loss_freq: 0.097183
[04:55:43.643] iteration 13868: loss: 0.085919, loss_s1: 0.065345, loss_fp: 0.004177, loss_freq: 0.055327
[04:55:44.363] iteration 13869: loss: 0.051809, loss_s1: 0.036115, loss_fp: 0.001739, loss_freq: 0.036944
[04:55:45.002] iteration 13870: loss: 0.051700, loss_s1: 0.036467, loss_fp: 0.001063, loss_freq: 0.013186
[04:55:45.684] iteration 13871: loss: 0.071895, loss_s1: 0.083462, loss_fp: 0.003040, loss_freq: 0.025265
[04:55:46.334] iteration 13872: loss: 0.054114, loss_s1: 0.037245, loss_fp: 0.003261, loss_freq: 0.012764
[04:55:47.025] iteration 13873: loss: 0.033270, loss_s1: 0.011632, loss_fp: 0.001277, loss_freq: 0.017136
[04:55:47.676] iteration 13874: loss: 0.053924, loss_s1: 0.037172, loss_fp: 0.001140, loss_freq: 0.023800
[04:55:48.330] iteration 13875: loss: 0.031190, loss_s1: 0.012197, loss_fp: 0.001725, loss_freq: 0.012901
[04:55:49.014] iteration 13876: loss: 0.078424, loss_s1: 0.076404, loss_fp: 0.005317, loss_freq: 0.028263
[04:55:49.666] iteration 13877: loss: 0.085707, loss_s1: 0.085018, loss_fp: 0.003445, loss_freq: 0.036764
[04:55:50.444] iteration 13878: loss: 0.050570, loss_s1: 0.027995, loss_fp: 0.008827, loss_freq: 0.021072
[04:55:51.169] iteration 13879: loss: 0.091214, loss_s1: 0.040534, loss_fp: 0.008872, loss_freq: 0.079393
[04:55:51.866] iteration 13880: loss: 0.070249, loss_s1: 0.047491, loss_fp: 0.006735, loss_freq: 0.034610
[04:55:52.616] iteration 13881: loss: 0.058607, loss_s1: 0.049812, loss_fp: 0.004285, loss_freq: 0.016130
[04:55:53.272] iteration 13882: loss: 0.048611, loss_s1: 0.025201, loss_fp: 0.002444, loss_freq: 0.024188
[04:55:54.040] iteration 13883: loss: 0.054776, loss_s1: 0.048766, loss_fp: 0.004136, loss_freq: 0.015873
[04:55:54.741] iteration 13884: loss: 0.061485, loss_s1: 0.034279, loss_fp: 0.007346, loss_freq: 0.042954
[04:55:55.462] iteration 13885: loss: 0.093826, loss_s1: 0.055674, loss_fp: 0.001916, loss_freq: 0.048823
[04:55:56.101] iteration 13886: loss: 0.070435, loss_s1: 0.045390, loss_fp: 0.008553, loss_freq: 0.046030
[04:55:56.739] iteration 13887: loss: 0.087057, loss_s1: 0.072967, loss_fp: 0.004491, loss_freq: 0.051520
[04:55:57.352] iteration 13888: loss: 0.047165, loss_s1: 0.032397, loss_fp: 0.002093, loss_freq: 0.025762
[04:55:57.964] iteration 13889: loss: 0.103112, loss_s1: 0.067574, loss_fp: 0.006093, loss_freq: 0.092424
[04:55:58.575] iteration 13890: loss: 0.092167, loss_s1: 0.099982, loss_fp: 0.003437, loss_freq: 0.039980
[04:55:59.183] iteration 13891: loss: 0.053677, loss_s1: 0.050920, loss_fp: 0.001004, loss_freq: 0.014262
[04:55:59.791] iteration 13892: loss: 0.063968, loss_s1: 0.062894, loss_fp: 0.001325, loss_freq: 0.035924
[04:56:00.399] iteration 13893: loss: 0.101631, loss_s1: 0.073531, loss_fp: 0.005701, loss_freq: 0.083876
[04:56:01.011] iteration 13894: loss: 0.061579, loss_s1: 0.051214, loss_fp: 0.000592, loss_freq: 0.035115
[04:56:01.619] iteration 13895: loss: 0.102076, loss_s1: 0.066010, loss_fp: 0.007296, loss_freq: 0.078850
[04:56:02.223] iteration 13896: loss: 0.066840, loss_s1: 0.068799, loss_fp: 0.004222, loss_freq: 0.019721
[04:56:02.834] iteration 13897: loss: 0.079341, loss_s1: 0.053325, loss_fp: 0.002882, loss_freq: 0.069008
[04:56:03.458] iteration 13898: loss: 0.083854, loss_s1: 0.032967, loss_fp: 0.012153, loss_freq: 0.052955
[04:56:04.067] iteration 13899: loss: 0.072256, loss_s1: 0.059456, loss_fp: 0.001506, loss_freq: 0.036941
[04:56:04.680] iteration 13900: loss: 0.082951, loss_s1: 0.043641, loss_fp: 0.012688, loss_freq: 0.064514
[04:56:05.294] iteration 13901: loss: 0.080545, loss_s1: 0.087420, loss_fp: 0.002033, loss_freq: 0.035109
[04:56:05.902] iteration 13902: loss: 0.089747, loss_s1: 0.021108, loss_fp: 0.007351, loss_freq: 0.025725
[04:56:06.600] iteration 13903: loss: 0.085579, loss_s1: 0.081167, loss_fp: 0.006900, loss_freq: 0.039150
[04:56:07.300] iteration 13904: loss: 0.087622, loss_s1: 0.043905, loss_fp: 0.003006, loss_freq: 0.050234
[04:56:08.051] iteration 13905: loss: 0.071838, loss_s1: 0.028800, loss_fp: 0.004239, loss_freq: 0.073156
[04:56:08.867] iteration 13906: loss: 0.045932, loss_s1: 0.050903, loss_fp: 0.001572, loss_freq: 0.007403
[04:56:09.520] iteration 13907: loss: 0.085464, loss_s1: 0.070783, loss_fp: 0.000817, loss_freq: 0.010528
[04:56:10.185] iteration 13908: loss: 0.063727, loss_s1: 0.044447, loss_fp: 0.003398, loss_freq: 0.048620
[04:56:10.819] iteration 13909: loss: 0.100925, loss_s1: 0.116406, loss_fp: 0.004272, loss_freq: 0.050492
[04:56:11.431] iteration 13910: loss: 0.047522, loss_s1: 0.035442, loss_fp: 0.002120, loss_freq: 0.028944
[04:56:12.070] iteration 13911: loss: 0.070724, loss_s1: 0.040580, loss_fp: 0.001934, loss_freq: 0.033781
[04:56:12.683] iteration 13912: loss: 0.047159, loss_s1: 0.025526, loss_fp: 0.001407, loss_freq: 0.019554
[04:56:13.293] iteration 13913: loss: 0.074641, loss_s1: 0.057024, loss_fp: 0.002523, loss_freq: 0.026500
[04:56:13.912] iteration 13914: loss: 0.061872, loss_s1: 0.044261, loss_fp: 0.001653, loss_freq: 0.030073
[04:56:14.524] iteration 13915: loss: 0.050529, loss_s1: 0.038764, loss_fp: 0.003074, loss_freq: 0.022225
[04:56:15.135] iteration 13916: loss: 0.066050, loss_s1: 0.056548, loss_fp: 0.001292, loss_freq: 0.024254
[04:56:15.744] iteration 13917: loss: 0.054652, loss_s1: 0.029340, loss_fp: 0.004826, loss_freq: 0.019230
[04:56:16.359] iteration 13918: loss: 0.081228, loss_s1: 0.075394, loss_fp: 0.004543, loss_freq: 0.044901
[04:56:16.976] iteration 13919: loss: 0.089960, loss_s1: 0.070345, loss_fp: 0.003573, loss_freq: 0.065636
[04:56:17.593] iteration 13920: loss: 0.064817, loss_s1: 0.054148, loss_fp: 0.006292, loss_freq: 0.015605
[04:56:18.213] iteration 13921: loss: 0.066675, loss_s1: 0.042080, loss_fp: 0.003644, loss_freq: 0.029065
[04:56:18.832] iteration 13922: loss: 0.073181, loss_s1: 0.046808, loss_fp: 0.002339, loss_freq: 0.037576
[04:56:19.459] iteration 13923: loss: 0.108984, loss_s1: 0.117197, loss_fp: 0.013557, loss_freq: 0.024447
[04:56:20.093] iteration 13924: loss: 0.070391, loss_s1: 0.046758, loss_fp: 0.020196, loss_freq: 0.038099
[04:56:20.738] iteration 13925: loss: 0.103760, loss_s1: 0.053054, loss_fp: 0.006141, loss_freq: 0.104072
[04:56:21.368] iteration 13926: loss: 0.046805, loss_s1: 0.026821, loss_fp: 0.006070, loss_freq: 0.026128
[04:56:21.996] iteration 13927: loss: 0.062593, loss_s1: 0.043229, loss_fp: 0.002345, loss_freq: 0.023581
[04:56:22.661] iteration 13928: loss: 0.087455, loss_s1: 0.071853, loss_fp: 0.002412, loss_freq: 0.064754
[04:56:23.310] iteration 13929: loss: 0.054106, loss_s1: 0.030881, loss_fp: 0.007570, loss_freq: 0.032490
[04:56:23.967] iteration 13930: loss: 0.070160, loss_s1: 0.067835, loss_fp: 0.002578, loss_freq: 0.019655
[04:56:24.625] iteration 13931: loss: 0.063422, loss_s1: 0.075707, loss_fp: 0.001608, loss_freq: 0.009197
[04:56:25.248] iteration 13932: loss: 0.045402, loss_s1: 0.031292, loss_fp: 0.002922, loss_freq: 0.026548
[04:56:25.856] iteration 13933: loss: 0.048836, loss_s1: 0.011153, loss_fp: 0.002153, loss_freq: 0.017221
[04:56:26.468] iteration 13934: loss: 0.052410, loss_s1: 0.034548, loss_fp: 0.002146, loss_freq: 0.017886
[04:56:27.079] iteration 13935: loss: 0.050817, loss_s1: 0.044747, loss_fp: 0.000831, loss_freq: 0.017875
[04:56:27.686] iteration 13936: loss: 0.098984, loss_s1: 0.113252, loss_fp: 0.003366, loss_freq: 0.051892
[04:56:28.314] iteration 13937: loss: 0.073873, loss_s1: 0.045064, loss_fp: 0.003572, loss_freq: 0.055932
[04:56:28.929] iteration 13938: loss: 0.065184, loss_s1: 0.044664, loss_fp: 0.002694, loss_freq: 0.045271
[04:56:29.539] iteration 13939: loss: 0.095659, loss_s1: 0.074845, loss_fp: 0.001970, loss_freq: 0.076358
[04:56:30.155] iteration 13940: loss: 0.101714, loss_s1: 0.095707, loss_fp: 0.001133, loss_freq: 0.065465
[04:56:31.139] iteration 13941: loss: 0.098999, loss_s1: 0.098937, loss_fp: 0.002995, loss_freq: 0.041608
[04:56:31.751] iteration 13942: loss: 0.065311, loss_s1: 0.027584, loss_fp: 0.005769, loss_freq: 0.054126
[04:56:32.363] iteration 13943: loss: 0.066081, loss_s1: 0.056735, loss_fp: 0.007329, loss_freq: 0.029898
[04:56:32.973] iteration 13944: loss: 0.051092, loss_s1: 0.018403, loss_fp: 0.004176, loss_freq: 0.023500
[04:56:33.578] iteration 13945: loss: 0.056369, loss_s1: 0.061475, loss_fp: 0.004792, loss_freq: 0.015187
[04:56:34.184] iteration 13946: loss: 0.061923, loss_s1: 0.051976, loss_fp: 0.004511, loss_freq: 0.024091
[04:56:34.794] iteration 13947: loss: 0.077644, loss_s1: 0.068852, loss_fp: 0.009376, loss_freq: 0.035079
[04:56:35.401] iteration 13948: loss: 0.090157, loss_s1: 0.097591, loss_fp: 0.004432, loss_freq: 0.043077
[04:56:36.004] iteration 13949: loss: 0.048902, loss_s1: 0.046566, loss_fp: 0.002535, loss_freq: 0.010191
[04:56:36.615] iteration 13950: loss: 0.078678, loss_s1: 0.088647, loss_fp: 0.006651, loss_freq: 0.021982
[04:56:37.236] iteration 13951: loss: 0.084500, loss_s1: 0.047168, loss_fp: 0.006842, loss_freq: 0.073499
[04:56:37.845] iteration 13952: loss: 0.116909, loss_s1: 0.077830, loss_fp: 0.007202, loss_freq: 0.107922
[04:56:38.452] iteration 13953: loss: 0.106857, loss_s1: 0.062327, loss_fp: 0.008259, loss_freq: 0.106242
[04:56:39.067] iteration 13954: loss: 0.080374, loss_s1: 0.086123, loss_fp: 0.005885, loss_freq: 0.030261
[04:56:39.683] iteration 13955: loss: 0.059744, loss_s1: 0.044140, loss_fp: 0.000760, loss_freq: 0.032214
[04:56:40.297] iteration 13956: loss: 0.064577, loss_s1: 0.051934, loss_fp: 0.008658, loss_freq: 0.019381
[04:56:40.914] iteration 13957: loss: 0.095615, loss_s1: 0.045655, loss_fp: 0.005396, loss_freq: 0.101843
[04:56:41.531] iteration 13958: loss: 0.041795, loss_s1: 0.023053, loss_fp: 0.003387, loss_freq: 0.014743
[04:56:42.151] iteration 13959: loss: 0.071555, loss_s1: 0.061048, loss_fp: 0.009258, loss_freq: 0.033031
[04:56:42.762] iteration 13960: loss: 0.067271, loss_s1: 0.069601, loss_fp: 0.001540, loss_freq: 0.013374
[04:56:43.373] iteration 13961: loss: 0.060563, loss_s1: 0.045075, loss_fp: 0.002198, loss_freq: 0.028898
[04:56:43.989] iteration 13962: loss: 0.072527, loss_s1: 0.054005, loss_fp: 0.002530, loss_freq: 0.057925
[04:56:44.614] iteration 13963: loss: 0.086982, loss_s1: 0.069878, loss_fp: 0.002880, loss_freq: 0.046031
[04:56:45.236] iteration 13964: loss: 0.075044, loss_s1: 0.065632, loss_fp: 0.003822, loss_freq: 0.040597
[04:56:45.854] iteration 13965: loss: 0.075392, loss_s1: 0.042965, loss_fp: 0.001487, loss_freq: 0.036544
[04:56:46.477] iteration 13966: loss: 0.056599, loss_s1: 0.045184, loss_fp: 0.002639, loss_freq: 0.040084
[04:56:47.085] iteration 13967: loss: 0.051791, loss_s1: 0.049233, loss_fp: 0.001124, loss_freq: 0.015770
[04:56:47.700] iteration 13968: loss: 0.069097, loss_s1: 0.066244, loss_fp: 0.002119, loss_freq: 0.020106
[04:56:48.315] iteration 13969: loss: 0.043229, loss_s1: 0.028819, loss_fp: 0.004165, loss_freq: 0.010616
[04:56:48.928] iteration 13970: loss: 0.103493, loss_s1: 0.126773, loss_fp: 0.002139, loss_freq: 0.034284
[04:56:49.538] iteration 13971: loss: 0.072713, loss_s1: 0.050820, loss_fp: 0.007272, loss_freq: 0.046913
[04:56:50.152] iteration 13972: loss: 0.123295, loss_s1: 0.076316, loss_fp: 0.003449, loss_freq: 0.054863
[04:56:50.766] iteration 13973: loss: 0.085757, loss_s1: 0.054214, loss_fp: 0.005005, loss_freq: 0.039854
[04:56:51.382] iteration 13974: loss: 0.032257, loss_s1: 0.015359, loss_fp: 0.002386, loss_freq: 0.007925
[04:56:51.999] iteration 13975: loss: 0.046145, loss_s1: 0.035015, loss_fp: 0.003158, loss_freq: 0.028380
[04:56:52.667] iteration 13976: loss: 0.073440, loss_s1: 0.050721, loss_fp: 0.001669, loss_freq: 0.039800
[04:56:53.276] iteration 13977: loss: 0.070017, loss_s1: 0.060909, loss_fp: 0.004902, loss_freq: 0.035509
[04:56:53.889] iteration 13978: loss: 0.061105, loss_s1: 0.053127, loss_fp: 0.001525, loss_freq: 0.031475
[04:56:54.575] iteration 13979: loss: 0.082142, loss_s1: 0.072581, loss_fp: 0.003412, loss_freq: 0.045498
[04:56:55.222] iteration 13980: loss: 0.085730, loss_s1: 0.072865, loss_fp: 0.004724, loss_freq: 0.037156
[04:56:55.851] iteration 13981: loss: 0.075977, loss_s1: 0.070092, loss_fp: 0.002344, loss_freq: 0.038270
[04:56:56.480] iteration 13982: loss: 0.049535, loss_s1: 0.025519, loss_fp: 0.005150, loss_freq: 0.029539
[04:56:57.103] iteration 13983: loss: 0.117949, loss_s1: 0.124284, loss_fp: 0.003653, loss_freq: 0.079628
[04:56:57.731] iteration 13984: loss: 0.077915, loss_s1: 0.101842, loss_fp: 0.003336, loss_freq: 0.023558
[04:56:58.377] iteration 13985: loss: 0.080146, loss_s1: 0.077398, loss_fp: 0.003219, loss_freq: 0.039141
[04:56:59.027] iteration 13986: loss: 0.057506, loss_s1: 0.043765, loss_fp: 0.002843, loss_freq: 0.012395
[04:56:59.640] iteration 13987: loss: 0.067299, loss_s1: 0.028174, loss_fp: 0.026064, loss_freq: 0.043179
[04:57:00.257] iteration 13988: loss: 0.052776, loss_s1: 0.041282, loss_fp: 0.002067, loss_freq: 0.032861
[04:57:00.879] iteration 13989: loss: 0.060398, loss_s1: 0.051667, loss_fp: 0.004652, loss_freq: 0.029723
[04:57:01.496] iteration 13990: loss: 0.048622, loss_s1: 0.022363, loss_fp: 0.002447, loss_freq: 0.019515
[04:57:02.106] iteration 13991: loss: 0.098895, loss_s1: 0.071112, loss_fp: 0.002806, loss_freq: 0.032256
[04:57:02.712] iteration 13992: loss: 0.079270, loss_s1: 0.096824, loss_fp: 0.003464, loss_freq: 0.030255
[04:57:03.385] iteration 13993: loss: 0.042993, loss_s1: 0.014752, loss_fp: 0.003137, loss_freq: 0.014853
[04:57:04.005] iteration 13994: loss: 0.083407, loss_s1: 0.084217, loss_fp: 0.010211, loss_freq: 0.034937
[04:57:04.626] iteration 13995: loss: 0.072607, loss_s1: 0.027719, loss_fp: 0.003914, loss_freq: 0.072043
[04:57:05.240] iteration 13996: loss: 0.060644, loss_s1: 0.057714, loss_fp: 0.003796, loss_freq: 0.020105
[04:57:05.861] iteration 13997: loss: 0.075575, loss_s1: 0.052160, loss_fp: 0.004322, loss_freq: 0.064225
[04:57:06.480] iteration 13998: loss: 0.065992, loss_s1: 0.052508, loss_fp: 0.012240, loss_freq: 0.018549
[04:57:07.102] iteration 13999: loss: 0.049650, loss_s1: 0.022683, loss_fp: 0.005071, loss_freq: 0.030512
[04:57:07.727] iteration 14000: loss: 0.054511, loss_s1: 0.029780, loss_fp: 0.005006, loss_freq: 0.041888
[04:57:11.102] iteration 14000 : mean_dice : 0.724636
[04:57:11.752] iteration 14001: loss: 0.037694, loss_s1: 0.035144, loss_fp: 0.003639, loss_freq: 0.008807
[04:57:12.367] iteration 14002: loss: 0.068607, loss_s1: 0.027482, loss_fp: 0.006223, loss_freq: 0.052217
[04:57:13.029] iteration 14003: loss: 0.063084, loss_s1: 0.060794, loss_fp: 0.000683, loss_freq: 0.022072
[04:57:13.692] iteration 14004: loss: 0.048832, loss_s1: 0.044943, loss_fp: 0.002786, loss_freq: 0.020128
[04:57:14.353] iteration 14005: loss: 0.066671, loss_s1: 0.054276, loss_fp: 0.007446, loss_freq: 0.028616
[04:57:15.014] iteration 14006: loss: 0.055237, loss_s1: 0.032776, loss_fp: 0.000963, loss_freq: 0.040394
[04:57:15.680] iteration 14007: loss: 0.066683, loss_s1: 0.050386, loss_fp: 0.004256, loss_freq: 0.016573
[04:57:16.347] iteration 14008: loss: 0.121097, loss_s1: 0.098171, loss_fp: 0.009005, loss_freq: 0.061201
[04:57:16.970] iteration 14009: loss: 0.050281, loss_s1: 0.022773, loss_fp: 0.001859, loss_freq: 0.028027
[04:57:17.923] iteration 14010: loss: 0.046310, loss_s1: 0.043554, loss_fp: 0.003700, loss_freq: 0.019928
[04:57:18.890] iteration 14011: loss: 0.053098, loss_s1: 0.030548, loss_fp: 0.008194, loss_freq: 0.025507
[04:57:19.654] iteration 14012: loss: 0.045710, loss_s1: 0.013356, loss_fp: 0.000810, loss_freq: 0.023077
[04:57:20.269] iteration 14013: loss: 0.065341, loss_s1: 0.048980, loss_fp: 0.001961, loss_freq: 0.052056
[04:57:20.879] iteration 14014: loss: 0.091405, loss_s1: 0.092201, loss_fp: 0.008038, loss_freq: 0.044547
[04:57:21.498] iteration 14015: loss: 0.083177, loss_s1: 0.075532, loss_fp: 0.000970, loss_freq: 0.054774
[04:57:22.105] iteration 14016: loss: 0.090456, loss_s1: 0.057303, loss_fp: 0.004868, loss_freq: 0.066436
[04:57:22.709] iteration 14017: loss: 0.069195, loss_s1: 0.047902, loss_fp: 0.006210, loss_freq: 0.039719
[04:57:23.319] iteration 14018: loss: 0.101029, loss_s1: 0.048979, loss_fp: 0.005356, loss_freq: 0.105947
[04:57:23.932] iteration 14019: loss: 0.093162, loss_s1: 0.061935, loss_fp: 0.003905, loss_freq: 0.061566
[04:57:24.542] iteration 14020: loss: 0.066590, loss_s1: 0.052072, loss_fp: 0.003490, loss_freq: 0.030224
[04:57:25.161] iteration 14021: loss: 0.104952, loss_s1: 0.096387, loss_fp: 0.006080, loss_freq: 0.059968
[04:57:25.797] iteration 14022: loss: 0.060750, loss_s1: 0.043340, loss_fp: 0.006594, loss_freq: 0.034358
[04:57:26.416] iteration 14023: loss: 0.065247, loss_s1: 0.051281, loss_fp: 0.002645, loss_freq: 0.038718
[04:57:27.035] iteration 14024: loss: 0.047727, loss_s1: 0.035423, loss_fp: 0.004104, loss_freq: 0.018926
[04:57:27.697] iteration 14025: loss: 0.075391, loss_s1: 0.087487, loss_fp: 0.003697, loss_freq: 0.018656
[04:57:28.314] iteration 14026: loss: 0.081517, loss_s1: 0.073646, loss_fp: 0.010999, loss_freq: 0.034257
[04:57:28.927] iteration 14027: loss: 0.071693, loss_s1: 0.072644, loss_fp: 0.006492, loss_freq: 0.027497
[04:57:29.544] iteration 14028: loss: 0.080803, loss_s1: 0.076072, loss_fp: 0.003734, loss_freq: 0.021286
[04:57:30.169] iteration 14029: loss: 0.081342, loss_s1: 0.085741, loss_fp: 0.006210, loss_freq: 0.030821
[04:57:30.790] iteration 14030: loss: 0.067454, loss_s1: 0.052859, loss_fp: 0.001838, loss_freq: 0.030245
[04:57:31.404] iteration 14031: loss: 0.081146, loss_s1: 0.098767, loss_fp: 0.003797, loss_freq: 0.017681
[04:57:32.022] iteration 14032: loss: 0.071745, loss_s1: 0.057036, loss_fp: 0.002065, loss_freq: 0.047767
[04:57:32.624] iteration 14033: loss: 0.061965, loss_s1: 0.054064, loss_fp: 0.002296, loss_freq: 0.018511
[04:57:33.231] iteration 14034: loss: 0.068851, loss_s1: 0.065058, loss_fp: 0.003805, loss_freq: 0.021825
[04:57:33.837] iteration 14035: loss: 0.065880, loss_s1: 0.059022, loss_fp: 0.001757, loss_freq: 0.027109
[04:57:34.470] iteration 14036: loss: 0.054605, loss_s1: 0.044159, loss_fp: 0.002899, loss_freq: 0.022576
[04:57:35.083] iteration 14037: loss: 0.097215, loss_s1: 0.072627, loss_fp: 0.002992, loss_freq: 0.072978
[04:57:35.694] iteration 14038: loss: 0.077920, loss_s1: 0.045506, loss_fp: 0.005497, loss_freq: 0.041722
[04:57:36.299] iteration 14039: loss: 0.072503, loss_s1: 0.050563, loss_fp: 0.005444, loss_freq: 0.057621
[04:57:36.903] iteration 14040: loss: 0.050808, loss_s1: 0.046430, loss_fp: 0.003707, loss_freq: 0.007726
[04:57:37.519] iteration 14041: loss: 0.105390, loss_s1: 0.145184, loss_fp: 0.004354, loss_freq: 0.030602
[04:57:38.177] iteration 14042: loss: 0.068457, loss_s1: 0.053192, loss_fp: 0.001867, loss_freq: 0.030711
[04:57:38.827] iteration 14043: loss: 0.035533, loss_s1: 0.010310, loss_fp: 0.001483, loss_freq: 0.023480
[04:57:39.484] iteration 14044: loss: 0.042496, loss_s1: 0.023927, loss_fp: 0.002493, loss_freq: 0.022794
[04:57:40.140] iteration 14045: loss: 0.057439, loss_s1: 0.045659, loss_fp: 0.002562, loss_freq: 0.036729
[04:57:40.752] iteration 14046: loss: 0.079453, loss_s1: 0.063309, loss_fp: 0.003424, loss_freq: 0.037787
[04:57:41.370] iteration 14047: loss: 0.081635, loss_s1: 0.082004, loss_fp: 0.002938, loss_freq: 0.031887
[04:57:41.991] iteration 14048: loss: 0.058440, loss_s1: 0.057715, loss_fp: 0.002253, loss_freq: 0.022291
[04:57:42.610] iteration 14049: loss: 0.055444, loss_s1: 0.014847, loss_fp: 0.007892, loss_freq: 0.045859
[04:57:43.223] iteration 14050: loss: 0.053787, loss_s1: 0.044380, loss_fp: 0.004514, loss_freq: 0.021547
[04:57:43.849] iteration 14051: loss: 0.070427, loss_s1: 0.063339, loss_fp: 0.004507, loss_freq: 0.027161
[04:57:44.482] iteration 14052: loss: 0.071116, loss_s1: 0.061214, loss_fp: 0.003236, loss_freq: 0.035631
[04:57:45.111] iteration 14053: loss: 0.066302, loss_s1: 0.050403, loss_fp: 0.002982, loss_freq: 0.047302
[04:57:45.760] iteration 14054: loss: 0.038969, loss_s1: 0.029214, loss_fp: 0.002417, loss_freq: 0.011605
[04:57:46.387] iteration 14055: loss: 0.101433, loss_s1: 0.064703, loss_fp: 0.007943, loss_freq: 0.081549
[04:57:47.015] iteration 14056: loss: 0.091259, loss_s1: 0.055035, loss_fp: 0.002762, loss_freq: 0.074045
[04:57:47.658] iteration 14057: loss: 0.071950, loss_s1: 0.069194, loss_fp: 0.006398, loss_freq: 0.026226
[04:57:48.318] iteration 14058: loss: 0.053450, loss_s1: 0.050221, loss_fp: 0.004505, loss_freq: 0.017263
[04:57:48.966] iteration 14059: loss: 0.091191, loss_s1: 0.049479, loss_fp: 0.002889, loss_freq: 0.088821
[04:57:49.607] iteration 14060: loss: 0.043096, loss_s1: 0.030867, loss_fp: 0.002113, loss_freq: 0.009967
[04:57:50.240] iteration 14061: loss: 0.045975, loss_s1: 0.036883, loss_fp: 0.002760, loss_freq: 0.010942
[04:57:50.871] iteration 14062: loss: 0.099450, loss_s1: 0.131558, loss_fp: 0.005198, loss_freq: 0.030969
[04:57:51.497] iteration 14063: loss: 0.079772, loss_s1: 0.054753, loss_fp: 0.008836, loss_freq: 0.045315
[04:57:52.126] iteration 14064: loss: 0.053065, loss_s1: 0.033221, loss_fp: 0.000820, loss_freq: 0.016954
[04:57:52.763] iteration 14065: loss: 0.081534, loss_s1: 0.034871, loss_fp: 0.006707, loss_freq: 0.061617
[04:57:53.439] iteration 14066: loss: 0.050924, loss_s1: 0.029085, loss_fp: 0.002758, loss_freq: 0.020200
[04:57:54.108] iteration 14067: loss: 0.083836, loss_s1: 0.074789, loss_fp: 0.004957, loss_freq: 0.049356
[04:57:54.789] iteration 14068: loss: 0.107427, loss_s1: 0.086608, loss_fp: 0.006527, loss_freq: 0.059975
[04:57:55.444] iteration 14069: loss: 0.088917, loss_s1: 0.085940, loss_fp: 0.004797, loss_freq: 0.057013
[04:57:56.094] iteration 14070: loss: 0.073972, loss_s1: 0.045240, loss_fp: 0.007778, loss_freq: 0.042945
[04:57:56.726] iteration 14071: loss: 0.047969, loss_s1: 0.046133, loss_fp: 0.008540, loss_freq: 0.010121
[04:57:57.361] iteration 14072: loss: 0.077036, loss_s1: 0.034992, loss_fp: 0.002194, loss_freq: 0.011327
[04:57:58.004] iteration 14073: loss: 0.077351, loss_s1: 0.048436, loss_fp: 0.007004, loss_freq: 0.043204
[04:57:58.660] iteration 14074: loss: 0.079145, loss_s1: 0.105882, loss_fp: 0.001496, loss_freq: 0.017728
[04:57:59.313] iteration 14075: loss: 0.085697, loss_s1: 0.044691, loss_fp: 0.000713, loss_freq: 0.075685
[04:57:59.944] iteration 14076: loss: 0.051206, loss_s1: 0.039895, loss_fp: 0.001481, loss_freq: 0.019808
[04:58:00.575] iteration 14077: loss: 0.077939, loss_s1: 0.077542, loss_fp: 0.001928, loss_freq: 0.015578
[04:58:01.208] iteration 14078: loss: 0.071936, loss_s1: 0.040820, loss_fp: 0.007192, loss_freq: 0.051708
[04:58:01.846] iteration 14079: loss: 0.127328, loss_s1: 0.175524, loss_fp: 0.004696, loss_freq: 0.029291
[04:58:02.497] iteration 14080: loss: 0.048434, loss_s1: 0.038805, loss_fp: 0.004741, loss_freq: 0.019196
[04:58:03.130] iteration 14081: loss: 0.061367, loss_s1: 0.042317, loss_fp: 0.006626, loss_freq: 0.025024
[04:58:03.766] iteration 14082: loss: 0.072966, loss_s1: 0.060411, loss_fp: 0.005256, loss_freq: 0.034998
[04:58:04.404] iteration 14083: loss: 0.072668, loss_s1: 0.057071, loss_fp: 0.001596, loss_freq: 0.052795
[04:58:05.053] iteration 14084: loss: 0.049158, loss_s1: 0.038241, loss_fp: 0.001100, loss_freq: 0.019998
[04:58:05.681] iteration 14085: loss: 0.065740, loss_s1: 0.041423, loss_fp: 0.002182, loss_freq: 0.006473
[04:58:06.312] iteration 14086: loss: 0.070781, loss_s1: 0.035421, loss_fp: 0.007126, loss_freq: 0.055068
[04:58:06.951] iteration 14087: loss: 0.061574, loss_s1: 0.044871, loss_fp: 0.004225, loss_freq: 0.027621
[04:58:07.611] iteration 14088: loss: 0.091817, loss_s1: 0.081846, loss_fp: 0.007105, loss_freq: 0.051465
[04:58:08.252] iteration 14089: loss: 0.066584, loss_s1: 0.055112, loss_fp: 0.009951, loss_freq: 0.035219
[04:58:08.888] iteration 14090: loss: 0.077616, loss_s1: 0.059632, loss_fp: 0.007933, loss_freq: 0.043933
[04:58:09.558] iteration 14091: loss: 0.114902, loss_s1: 0.129984, loss_fp: 0.003767, loss_freq: 0.043895
[04:58:10.188] iteration 14092: loss: 0.081099, loss_s1: 0.071579, loss_fp: 0.009598, loss_freq: 0.031042
[04:58:10.820] iteration 14093: loss: 0.150239, loss_s1: 0.189383, loss_fp: 0.007419, loss_freq: 0.069190
[04:58:11.458] iteration 14094: loss: 0.102022, loss_s1: 0.101813, loss_fp: 0.010762, loss_freq: 0.018630
[04:58:12.089] iteration 14095: loss: 0.060683, loss_s1: 0.032375, loss_fp: 0.005978, loss_freq: 0.028183
[04:58:12.719] iteration 14096: loss: 0.082125, loss_s1: 0.050872, loss_fp: 0.014138, loss_freq: 0.038844
[04:58:13.357] iteration 14097: loss: 0.094184, loss_s1: 0.050476, loss_fp: 0.011350, loss_freq: 0.043373
[04:58:14.011] iteration 14098: loss: 0.122495, loss_s1: 0.102537, loss_fp: 0.006067, loss_freq: 0.084264
[04:58:14.638] iteration 14099: loss: 0.056887, loss_s1: 0.022949, loss_fp: 0.003924, loss_freq: 0.049847
[04:58:15.301] iteration 14100: loss: 0.078870, loss_s1: 0.075081, loss_fp: 0.005242, loss_freq: 0.035440
[04:58:15.927] iteration 14101: loss: 0.042614, loss_s1: 0.034116, loss_fp: 0.005299, loss_freq: 0.006737
[04:58:16.644] iteration 14102: loss: 0.051758, loss_s1: 0.046020, loss_fp: 0.002657, loss_freq: 0.025381
[04:58:17.405] iteration 14103: loss: 0.042561, loss_s1: 0.023218, loss_fp: 0.000900, loss_freq: 0.013131
[04:58:18.179] iteration 14104: loss: 0.042312, loss_s1: 0.030993, loss_fp: 0.001071, loss_freq: 0.017961
[04:58:18.831] iteration 14105: loss: 0.032300, loss_s1: 0.008633, loss_fp: 0.000871, loss_freq: 0.011904
[04:58:19.603] iteration 14106: loss: 0.046495, loss_s1: 0.048706, loss_fp: 0.007356, loss_freq: 0.013151
[04:58:20.260] iteration 14107: loss: 0.077952, loss_s1: 0.044712, loss_fp: 0.000892, loss_freq: 0.052054
[04:58:20.949] iteration 14108: loss: 0.095805, loss_s1: 0.110948, loss_fp: 0.008509, loss_freq: 0.029904
[04:58:21.597] iteration 14109: loss: 0.086880, loss_s1: 0.100068, loss_fp: 0.005071, loss_freq: 0.037400
[04:58:22.284] iteration 14110: loss: 0.077011, loss_s1: 0.063854, loss_fp: 0.004847, loss_freq: 0.033211
[04:58:23.317] iteration 14111: loss: 0.080078, loss_s1: 0.089873, loss_fp: 0.004005, loss_freq: 0.019580
[04:58:24.018] iteration 14112: loss: 0.055485, loss_s1: 0.036238, loss_fp: 0.003053, loss_freq: 0.033472
[04:58:24.758] iteration 14113: loss: 0.081924, loss_s1: 0.072626, loss_fp: 0.004227, loss_freq: 0.046306
[04:58:25.514] iteration 14114: loss: 0.047110, loss_s1: 0.032707, loss_fp: 0.001304, loss_freq: 0.013905
[04:58:26.182] iteration 14115: loss: 0.066546, loss_s1: 0.071752, loss_fp: 0.003421, loss_freq: 0.028079
[04:58:26.928] iteration 14116: loss: 0.076650, loss_s1: 0.055228, loss_fp: 0.004977, loss_freq: 0.031349
[04:58:27.661] iteration 14117: loss: 0.054867, loss_s1: 0.029180, loss_fp: 0.006327, loss_freq: 0.035734
[04:58:28.345] iteration 14118: loss: 0.068697, loss_s1: 0.065280, loss_fp: 0.001305, loss_freq: 0.035670
[04:58:28.978] iteration 14119: loss: 0.053482, loss_s1: 0.049519, loss_fp: 0.003859, loss_freq: 0.019761
[04:58:29.607] iteration 14120: loss: 0.082339, loss_s1: 0.072811, loss_fp: 0.013808, loss_freq: 0.040974
[04:58:30.255] iteration 14121: loss: 0.094109, loss_s1: 0.095065, loss_fp: 0.002378, loss_freq: 0.045506
[04:58:30.891] iteration 14122: loss: 0.079228, loss_s1: 0.037110, loss_fp: 0.008110, loss_freq: 0.057953
[04:58:31.508] iteration 14123: loss: 0.081501, loss_s1: 0.082316, loss_fp: 0.003158, loss_freq: 0.026623
[04:58:32.151] iteration 14124: loss: 0.044419, loss_s1: 0.021504, loss_fp: 0.003700, loss_freq: 0.023678
[04:58:32.769] iteration 14125: loss: 0.059411, loss_s1: 0.048729, loss_fp: 0.002969, loss_freq: 0.024749
[04:58:33.389] iteration 14126: loss: 0.065035, loss_s1: 0.056523, loss_fp: 0.001727, loss_freq: 0.034818
[04:58:34.024] iteration 14127: loss: 0.129171, loss_s1: 0.075256, loss_fp: 0.003270, loss_freq: 0.149447
[04:58:34.643] iteration 14128: loss: 0.039476, loss_s1: 0.031647, loss_fp: 0.000936, loss_freq: 0.009263
[04:58:35.267] iteration 14129: loss: 0.086077, loss_s1: 0.093569, loss_fp: 0.009976, loss_freq: 0.019304
[04:58:35.900] iteration 14130: loss: 0.065247, loss_s1: 0.046387, loss_fp: 0.001934, loss_freq: 0.026528
[04:58:36.525] iteration 14131: loss: 0.059527, loss_s1: 0.044581, loss_fp: 0.004248, loss_freq: 0.031376
[04:58:37.157] iteration 14132: loss: 0.074164, loss_s1: 0.072254, loss_fp: 0.001285, loss_freq: 0.036104
[04:58:37.796] iteration 14133: loss: 0.087442, loss_s1: 0.054112, loss_fp: 0.005782, loss_freq: 0.040644
[04:58:38.420] iteration 14134: loss: 0.054751, loss_s1: 0.041019, loss_fp: 0.001197, loss_freq: 0.014711
[04:58:39.054] iteration 14135: loss: 0.107282, loss_s1: 0.127583, loss_fp: 0.002261, loss_freq: 0.027964
[04:58:39.673] iteration 14136: loss: 0.042660, loss_s1: 0.033193, loss_fp: 0.003363, loss_freq: 0.024714
[04:58:40.332] iteration 14137: loss: 0.076183, loss_s1: 0.079867, loss_fp: 0.002319, loss_freq: 0.020805
[04:58:41.330] iteration 14138: loss: 0.106031, loss_s1: 0.102050, loss_fp: 0.004808, loss_freq: 0.052149
[04:58:42.315] iteration 14139: loss: 0.055524, loss_s1: 0.023110, loss_fp: 0.003596, loss_freq: 0.032548
[04:58:42.970] iteration 14140: loss: 0.084760, loss_s1: 0.084833, loss_fp: 0.001202, loss_freq: 0.041621
[04:58:43.588] iteration 14141: loss: 0.090137, loss_s1: 0.073420, loss_fp: 0.004102, loss_freq: 0.067004
[04:58:44.225] iteration 14142: loss: 0.088576, loss_s1: 0.056896, loss_fp: 0.004375, loss_freq: 0.050171
[04:58:44.858] iteration 14143: loss: 0.085103, loss_s1: 0.090339, loss_fp: 0.003970, loss_freq: 0.046233
[04:58:45.479] iteration 14144: loss: 0.065097, loss_s1: 0.057344, loss_fp: 0.007629, loss_freq: 0.015965
[04:58:46.101] iteration 14145: loss: 0.043693, loss_s1: 0.035743, loss_fp: 0.002159, loss_freq: 0.023675
[04:58:46.744] iteration 14146: loss: 0.052845, loss_s1: 0.036996, loss_fp: 0.001268, loss_freq: 0.026450
[04:58:47.366] iteration 14147: loss: 0.051160, loss_s1: 0.045448, loss_fp: 0.002056, loss_freq: 0.013659
[04:58:47.993] iteration 14148: loss: 0.059751, loss_s1: 0.038780, loss_fp: 0.000960, loss_freq: 0.040773
[04:58:48.632] iteration 14149: loss: 0.078400, loss_s1: 0.089325, loss_fp: 0.002231, loss_freq: 0.021121
[04:58:49.270] iteration 14150: loss: 0.055767, loss_s1: 0.042000, loss_fp: 0.008094, loss_freq: 0.027308
[04:58:49.888] iteration 14151: loss: 0.035258, loss_s1: 0.020955, loss_fp: 0.000636, loss_freq: 0.012813
[04:58:50.514] iteration 14152: loss: 0.075247, loss_s1: 0.088351, loss_fp: 0.003878, loss_freq: 0.018394
[04:58:51.178] iteration 14153: loss: 0.085355, loss_s1: 0.104159, loss_fp: 0.002356, loss_freq: 0.032252
[04:58:51.796] iteration 14154: loss: 0.116176, loss_s1: 0.105199, loss_fp: 0.004756, loss_freq: 0.063816
[04:58:52.481] iteration 14155: loss: 0.064439, loss_s1: 0.059132, loss_fp: 0.002822, loss_freq: 0.021739
[04:58:53.124] iteration 14156: loss: 0.094650, loss_s1: 0.077735, loss_fp: 0.008949, loss_freq: 0.058365
[04:58:53.753] iteration 14157: loss: 0.053898, loss_s1: 0.028466, loss_fp: 0.006360, loss_freq: 0.027777
[04:58:54.376] iteration 14158: loss: 0.072088, loss_s1: 0.049877, loss_fp: 0.000914, loss_freq: 0.050506
[04:58:54.997] iteration 14159: loss: 0.064127, loss_s1: 0.075609, loss_fp: 0.001579, loss_freq: 0.009903
[04:58:55.633] iteration 14160: loss: 0.087428, loss_s1: 0.063019, loss_fp: 0.001761, loss_freq: 0.035956
[04:58:56.262] iteration 14161: loss: 0.056604, loss_s1: 0.034338, loss_fp: 0.002546, loss_freq: 0.027957
[04:58:56.896] iteration 14162: loss: 0.091710, loss_s1: 0.077650, loss_fp: 0.002867, loss_freq: 0.068323
[04:58:57.516] iteration 14163: loss: 0.053477, loss_s1: 0.024664, loss_fp: 0.002490, loss_freq: 0.015217
[04:58:58.142] iteration 14164: loss: 0.087195, loss_s1: 0.077438, loss_fp: 0.002497, loss_freq: 0.059533
[04:58:58.776] iteration 14165: loss: 0.061194, loss_s1: 0.031312, loss_fp: 0.001039, loss_freq: 0.037835
[04:58:59.461] iteration 14166: loss: 0.050895, loss_s1: 0.024363, loss_fp: 0.005576, loss_freq: 0.022521
[04:59:00.138] iteration 14167: loss: 0.059663, loss_s1: 0.040995, loss_fp: 0.002779, loss_freq: 0.041167
[04:59:00.844] iteration 14168: loss: 0.051236, loss_s1: 0.035869, loss_fp: 0.002480, loss_freq: 0.013714
[04:59:01.537] iteration 14169: loss: 0.058575, loss_s1: 0.028297, loss_fp: 0.001767, loss_freq: 0.042598
[04:59:02.203] iteration 14170: loss: 0.075920, loss_s1: 0.032796, loss_fp: 0.002439, loss_freq: 0.063685
[04:59:02.879] iteration 14171: loss: 0.041804, loss_s1: 0.033003, loss_fp: 0.002914, loss_freq: 0.007842
[04:59:03.558] iteration 14172: loss: 0.094609, loss_s1: 0.076448, loss_fp: 0.004302, loss_freq: 0.055209
[04:59:04.233] iteration 14173: loss: 0.049395, loss_s1: 0.035582, loss_fp: 0.001979, loss_freq: 0.015826
[04:59:04.945] iteration 14174: loss: 0.048283, loss_s1: 0.034931, loss_fp: 0.000676, loss_freq: 0.023823
[04:59:05.615] iteration 14175: loss: 0.054410, loss_s1: 0.044967, loss_fp: 0.001318, loss_freq: 0.020276
[04:59:06.291] iteration 14176: loss: 0.065002, loss_s1: 0.056878, loss_fp: 0.005249, loss_freq: 0.039872
[04:59:06.962] iteration 14177: loss: 0.074533, loss_s1: 0.065306, loss_fp: 0.002904, loss_freq: 0.010766
[04:59:07.637] iteration 14178: loss: 0.093147, loss_s1: 0.093062, loss_fp: 0.007276, loss_freq: 0.044810
[04:59:08.306] iteration 14179: loss: 0.040042, loss_s1: 0.018240, loss_fp: 0.002286, loss_freq: 0.012517
[04:59:08.959] iteration 14180: loss: 0.052654, loss_s1: 0.044348, loss_fp: 0.002797, loss_freq: 0.026368
[04:59:09.604] iteration 14181: loss: 0.069727, loss_s1: 0.067233, loss_fp: 0.005159, loss_freq: 0.026788
[04:59:10.228] iteration 14182: loss: 0.058749, loss_s1: 0.036484, loss_fp: 0.003511, loss_freq: 0.029500
[04:59:10.881] iteration 14183: loss: 0.073070, loss_s1: 0.048841, loss_fp: 0.014760, loss_freq: 0.035068
[04:59:11.506] iteration 14184: loss: 0.096097, loss_s1: 0.102676, loss_fp: 0.007579, loss_freq: 0.036180
[04:59:12.179] iteration 14185: loss: 0.063848, loss_s1: 0.054841, loss_fp: 0.003118, loss_freq: 0.035381
[04:59:12.802] iteration 14186: loss: 0.077169, loss_s1: 0.063422, loss_fp: 0.003894, loss_freq: 0.047662
[04:59:13.464] iteration 14187: loss: 0.072899, loss_s1: 0.061099, loss_fp: 0.006412, loss_freq: 0.032753
[04:59:14.087] iteration 14188: loss: 0.079765, loss_s1: 0.075163, loss_fp: 0.007726, loss_freq: 0.018214
[04:59:14.731] iteration 14189: loss: 0.067811, loss_s1: 0.041058, loss_fp: 0.005064, loss_freq: 0.031850
[04:59:15.376] iteration 14190: loss: 0.057991, loss_s1: 0.036331, loss_fp: 0.002648, loss_freq: 0.026235
[04:59:16.009] iteration 14191: loss: 0.057149, loss_s1: 0.036694, loss_fp: 0.002197, loss_freq: 0.028880
[04:59:16.636] iteration 14192: loss: 0.055943, loss_s1: 0.028941, loss_fp: 0.015185, loss_freq: 0.028668
[04:59:17.281] iteration 14193: loss: 0.049165, loss_s1: 0.032921, loss_fp: 0.002278, loss_freq: 0.026007
[04:59:17.925] iteration 14194: loss: 0.054247, loss_s1: 0.032269, loss_fp: 0.002454, loss_freq: 0.033860
[04:59:18.562] iteration 14195: loss: 0.095463, loss_s1: 0.113673, loss_fp: 0.004634, loss_freq: 0.029630
[04:59:19.197] iteration 14196: loss: 0.060440, loss_s1: 0.039378, loss_fp: 0.004752, loss_freq: 0.027860
[04:59:19.833] iteration 14197: loss: 0.076747, loss_s1: 0.092714, loss_fp: 0.002076, loss_freq: 0.027339
[04:59:20.460] iteration 14198: loss: 0.071648, loss_s1: 0.081105, loss_fp: 0.007349, loss_freq: 0.016241
[04:59:21.084] iteration 14199: loss: 0.055120, loss_s1: 0.036308, loss_fp: 0.005164, loss_freq: 0.030629
[04:59:21.720] iteration 14200: loss: 0.060961, loss_s1: 0.047373, loss_fp: 0.006493, loss_freq: 0.018827
[04:59:25.207] iteration 14200 : mean_dice : 0.713102
[04:59:25.872] iteration 14201: loss: 0.096620, loss_s1: 0.096979, loss_fp: 0.006534, loss_freq: 0.044257
[04:59:26.531] iteration 14202: loss: 0.051114, loss_s1: 0.032888, loss_fp: 0.002914, loss_freq: 0.034233
[04:59:27.163] iteration 14203: loss: 0.052117, loss_s1: 0.020413, loss_fp: 0.006636, loss_freq: 0.016971
[04:59:27.803] iteration 14204: loss: 0.058416, loss_s1: 0.048497, loss_fp: 0.003023, loss_freq: 0.026105
[04:59:28.459] iteration 14205: loss: 0.064327, loss_s1: 0.060666, loss_fp: 0.002688, loss_freq: 0.025453
[04:59:29.082] iteration 14206: loss: 0.072062, loss_s1: 0.061636, loss_fp: 0.003239, loss_freq: 0.039531
[04:59:29.720] iteration 14207: loss: 0.082209, loss_s1: 0.034590, loss_fp: 0.004478, loss_freq: 0.081911
[04:59:30.358] iteration 14208: loss: 0.068689, loss_s1: 0.035043, loss_fp: 0.001900, loss_freq: 0.042938
[04:59:30.984] iteration 14209: loss: 0.048146, loss_s1: 0.039225, loss_fp: 0.002068, loss_freq: 0.024718
[04:59:31.615] iteration 14210: loss: 0.059304, loss_s1: 0.053080, loss_fp: 0.000951, loss_freq: 0.015454
[04:59:32.251] iteration 14211: loss: 0.091992, loss_s1: 0.089225, loss_fp: 0.002866, loss_freq: 0.047100
[04:59:32.893] iteration 14212: loss: 0.055222, loss_s1: 0.036524, loss_fp: 0.001566, loss_freq: 0.014621
[04:59:33.526] iteration 14213: loss: 0.045488, loss_s1: 0.034864, loss_fp: 0.003488, loss_freq: 0.012126
[04:59:34.177] iteration 14214: loss: 0.043631, loss_s1: 0.021419, loss_fp: 0.003409, loss_freq: 0.022718
[04:59:34.809] iteration 14215: loss: 0.029720, loss_s1: 0.015127, loss_fp: 0.001120, loss_freq: 0.014215
[04:59:35.446] iteration 14216: loss: 0.072642, loss_s1: 0.048796, loss_fp: 0.007207, loss_freq: 0.041654
[04:59:36.097] iteration 14217: loss: 0.074093, loss_s1: 0.068822, loss_fp: 0.001879, loss_freq: 0.039002
[04:59:36.725] iteration 14218: loss: 0.073761, loss_s1: 0.068448, loss_fp: 0.008608, loss_freq: 0.032541
[04:59:37.360] iteration 14219: loss: 0.073362, loss_s1: 0.027564, loss_fp: 0.004672, loss_freq: 0.072221
[04:59:37.988] iteration 14220: loss: 0.051065, loss_s1: 0.040313, loss_fp: 0.002410, loss_freq: 0.021446
[04:59:38.629] iteration 14221: loss: 0.058782, loss_s1: 0.047275, loss_fp: 0.003388, loss_freq: 0.019348
[04:59:39.256] iteration 14222: loss: 0.071768, loss_s1: 0.059752, loss_fp: 0.002608, loss_freq: 0.040499
[04:59:39.884] iteration 14223: loss: 0.072455, loss_s1: 0.066546, loss_fp: 0.002443, loss_freq: 0.040048
[04:59:40.527] iteration 14224: loss: 0.033364, loss_s1: 0.013372, loss_fp: 0.008302, loss_freq: 0.009516
[04:59:41.162] iteration 14225: loss: 0.086978, loss_s1: 0.049573, loss_fp: 0.001387, loss_freq: 0.074158
[04:59:41.800] iteration 14226: loss: 0.116641, loss_s1: 0.101970, loss_fp: 0.008392, loss_freq: 0.078633
[04:59:42.437] iteration 14227: loss: 0.063757, loss_s1: 0.038900, loss_fp: 0.003817, loss_freq: 0.047193
[04:59:43.118] iteration 14228: loss: 0.043611, loss_s1: 0.030037, loss_fp: 0.001549, loss_freq: 0.015557
[04:59:43.805] iteration 14229: loss: 0.076664, loss_s1: 0.049145, loss_fp: 0.003990, loss_freq: 0.057594
[04:59:44.474] iteration 14230: loss: 0.078372, loss_s1: 0.064836, loss_fp: 0.008288, loss_freq: 0.044413
[04:59:45.194] iteration 14231: loss: 0.069572, loss_s1: 0.060098, loss_fp: 0.002370, loss_freq: 0.012322
[04:59:45.815] iteration 14232: loss: 0.046946, loss_s1: 0.031488, loss_fp: 0.001947, loss_freq: 0.031270
[04:59:46.445] iteration 14233: loss: 0.091648, loss_s1: 0.071700, loss_fp: 0.009112, loss_freq: 0.060218
[04:59:47.153] iteration 14234: loss: 0.055600, loss_s1: 0.033700, loss_fp: 0.001809, loss_freq: 0.025212
[04:59:47.798] iteration 14235: loss: 0.069408, loss_s1: 0.054873, loss_fp: 0.004476, loss_freq: 0.038080
[04:59:48.425] iteration 14236: loss: 0.089051, loss_s1: 0.058872, loss_fp: 0.001549, loss_freq: 0.064031
[04:59:49.060] iteration 14237: loss: 0.108005, loss_s1: 0.094814, loss_fp: 0.002765, loss_freq: 0.090405
[04:59:49.700] iteration 14238: loss: 0.078645, loss_s1: 0.055581, loss_fp: 0.020414, loss_freq: 0.038630
[04:59:50.348] iteration 14239: loss: 0.052916, loss_s1: 0.043563, loss_fp: 0.011638, loss_freq: 0.014301
[04:59:50.976] iteration 14240: loss: 0.092289, loss_s1: 0.075109, loss_fp: 0.005618, loss_freq: 0.063496
[04:59:51.611] iteration 14241: loss: 0.049730, loss_s1: 0.047044, loss_fp: 0.002371, loss_freq: 0.021337
[04:59:52.253] iteration 14242: loss: 0.071826, loss_s1: 0.025328, loss_fp: 0.002632, loss_freq: 0.051976
[04:59:52.870] iteration 14243: loss: 0.086642, loss_s1: 0.090485, loss_fp: 0.001968, loss_freq: 0.027734
[04:59:53.498] iteration 14244: loss: 0.077939, loss_s1: 0.046815, loss_fp: 0.009091, loss_freq: 0.064683
[04:59:54.148] iteration 14245: loss: 0.054886, loss_s1: 0.029198, loss_fp: 0.001936, loss_freq: 0.033941
[04:59:54.778] iteration 14246: loss: 0.046680, loss_s1: 0.039597, loss_fp: 0.002719, loss_freq: 0.016530
[04:59:55.413] iteration 14247: loss: 0.115846, loss_s1: 0.140519, loss_fp: 0.002671, loss_freq: 0.029573
[04:59:56.035] iteration 14248: loss: 0.093701, loss_s1: 0.085691, loss_fp: 0.011618, loss_freq: 0.055853
[04:59:56.660] iteration 14249: loss: 0.111565, loss_s1: 0.126186, loss_fp: 0.006449, loss_freq: 0.050399
[04:59:57.286] iteration 14250: loss: 0.071047, loss_s1: 0.086461, loss_fp: 0.002371, loss_freq: 0.026011
[04:59:57.931] iteration 14251: loss: 0.091944, loss_s1: 0.073659, loss_fp: 0.009232, loss_freq: 0.059641
[04:59:58.570] iteration 14252: loss: 0.053016, loss_s1: 0.029331, loss_fp: 0.003637, loss_freq: 0.020794
[04:59:59.201] iteration 14253: loss: 0.102252, loss_s1: 0.113776, loss_fp: 0.005587, loss_freq: 0.043644
[04:59:59.882] iteration 14254: loss: 0.043869, loss_s1: 0.023768, loss_fp: 0.002017, loss_freq: 0.018525
[05:00:00.556] iteration 14255: loss: 0.053992, loss_s1: 0.029367, loss_fp: 0.004819, loss_freq: 0.026132
[05:00:01.233] iteration 14256: loss: 0.058958, loss_s1: 0.036883, loss_fp: 0.001670, loss_freq: 0.036275
[05:00:01.896] iteration 14257: loss: 0.036571, loss_s1: 0.010954, loss_fp: 0.001902, loss_freq: 0.019878
[05:00:02.565] iteration 14258: loss: 0.103603, loss_s1: 0.097998, loss_fp: 0.003324, loss_freq: 0.061409
[05:00:03.250] iteration 14259: loss: 0.049689, loss_s1: 0.037920, loss_fp: 0.006811, loss_freq: 0.016520
[05:00:03.888] iteration 14260: loss: 0.081759, loss_s1: 0.084644, loss_fp: 0.010961, loss_freq: 0.028400
[05:00:04.545] iteration 14261: loss: 0.064860, loss_s1: 0.033332, loss_fp: 0.004405, loss_freq: 0.036951
[05:00:05.174] iteration 14262: loss: 0.069924, loss_s1: 0.050713, loss_fp: 0.005628, loss_freq: 0.046225
[05:00:05.799] iteration 14263: loss: 0.065219, loss_s1: 0.057270, loss_fp: 0.006578, loss_freq: 0.027861
[05:00:06.415] iteration 14264: loss: 0.079584, loss_s1: 0.054660, loss_fp: 0.002214, loss_freq: 0.061823
[05:00:07.053] iteration 14265: loss: 0.084396, loss_s1: 0.050394, loss_fp: 0.001971, loss_freq: 0.045280
[05:00:07.671] iteration 14266: loss: 0.051706, loss_s1: 0.054543, loss_fp: 0.000938, loss_freq: 0.008335
[05:00:08.285] iteration 14267: loss: 0.047370, loss_s1: 0.038464, loss_fp: 0.006990, loss_freq: 0.020089
[05:00:08.904] iteration 14268: loss: 0.134089, loss_s1: 0.135481, loss_fp: 0.003470, loss_freq: 0.074917
[05:00:09.524] iteration 14269: loss: 0.094339, loss_s1: 0.095334, loss_fp: 0.004357, loss_freq: 0.053307
[05:00:10.156] iteration 14270: loss: 0.058466, loss_s1: 0.041511, loss_fp: 0.005522, loss_freq: 0.020987
[05:00:10.775] iteration 14271: loss: 0.064191, loss_s1: 0.079418, loss_fp: 0.001560, loss_freq: 0.009887
[05:00:11.395] iteration 14272: loss: 0.052228, loss_s1: 0.041043, loss_fp: 0.002571, loss_freq: 0.029285
[05:00:12.030] iteration 14273: loss: 0.043337, loss_s1: 0.016849, loss_fp: 0.000967, loss_freq: 0.006758
[05:00:12.658] iteration 14274: loss: 0.039415, loss_s1: 0.035703, loss_fp: 0.000781, loss_freq: 0.013310
[05:00:13.284] iteration 14275: loss: 0.056450, loss_s1: 0.040844, loss_fp: 0.002788, loss_freq: 0.016606
[05:00:13.916] iteration 14276: loss: 0.045664, loss_s1: 0.036186, loss_fp: 0.003707, loss_freq: 0.016574
[05:00:14.582] iteration 14277: loss: 0.075254, loss_s1: 0.030459, loss_fp: 0.001588, loss_freq: 0.050569
[05:00:15.283] iteration 14278: loss: 0.055748, loss_s1: 0.049914, loss_fp: 0.001447, loss_freq: 0.018092
[05:00:15.958] iteration 14279: loss: 0.091913, loss_s1: 0.076387, loss_fp: 0.002631, loss_freq: 0.075116
[05:00:16.617] iteration 14280: loss: 0.083901, loss_s1: 0.100625, loss_fp: 0.004732, loss_freq: 0.024142
[05:00:17.611] iteration 14281: loss: 0.066697, loss_s1: 0.059518, loss_fp: 0.000917, loss_freq: 0.027353
[05:00:18.284] iteration 14282: loss: 0.085006, loss_s1: 0.088864, loss_fp: 0.002092, loss_freq: 0.041096
[05:00:18.977] iteration 14283: loss: 0.067319, loss_s1: 0.075759, loss_fp: 0.007448, loss_freq: 0.019556
[05:00:19.648] iteration 14284: loss: 0.035933, loss_s1: 0.020839, loss_fp: 0.002768, loss_freq: 0.016030
[05:00:20.317] iteration 14285: loss: 0.079633, loss_s1: 0.105430, loss_fp: 0.001198, loss_freq: 0.014246
[05:00:20.987] iteration 14286: loss: 0.091257, loss_s1: 0.063687, loss_fp: 0.008305, loss_freq: 0.026197
[05:00:21.688] iteration 14287: loss: 0.059480, loss_s1: 0.041514, loss_fp: 0.003430, loss_freq: 0.040608
[05:00:22.358] iteration 14288: loss: 0.037840, loss_s1: 0.026126, loss_fp: 0.001767, loss_freq: 0.015378
[05:00:23.045] iteration 14289: loss: 0.050367, loss_s1: 0.049389, loss_fp: 0.003046, loss_freq: 0.015889
[05:00:23.689] iteration 14290: loss: 0.076614, loss_s1: 0.053909, loss_fp: 0.007037, loss_freq: 0.027009
[05:00:24.304] iteration 14291: loss: 0.086083, loss_s1: 0.029605, loss_fp: 0.028854, loss_freq: 0.058820
[05:00:24.926] iteration 14292: loss: 0.082604, loss_s1: 0.092406, loss_fp: 0.002766, loss_freq: 0.034505
[05:00:25.560] iteration 14293: loss: 0.073796, loss_s1: 0.037015, loss_fp: 0.001320, loss_freq: 0.065271
[05:00:26.224] iteration 14294: loss: 0.074116, loss_s1: 0.046702, loss_fp: 0.008364, loss_freq: 0.062828
[05:00:26.875] iteration 14295: loss: 0.053085, loss_s1: 0.029468, loss_fp: 0.008700, loss_freq: 0.024227
[05:00:27.510] iteration 14296: loss: 0.078716, loss_s1: 0.099645, loss_fp: 0.002081, loss_freq: 0.018628
[05:00:28.148] iteration 14297: loss: 0.089170, loss_s1: 0.063016, loss_fp: 0.004644, loss_freq: 0.062374
[05:00:28.787] iteration 14298: loss: 0.058349, loss_s1: 0.057802, loss_fp: 0.003931, loss_freq: 0.008143
[05:00:29.423] iteration 14299: loss: 0.069361, loss_s1: 0.053920, loss_fp: 0.011253, loss_freq: 0.037109
[05:00:30.044] iteration 14300: loss: 0.073989, loss_s1: 0.056768, loss_fp: 0.003530, loss_freq: 0.015814
[05:00:30.668] iteration 14301: loss: 0.073321, loss_s1: 0.055195, loss_fp: 0.001228, loss_freq: 0.040248
[05:00:31.302] iteration 14302: loss: 0.054727, loss_s1: 0.032462, loss_fp: 0.003137, loss_freq: 0.043801
[05:00:31.973] iteration 14303: loss: 0.103251, loss_s1: 0.090884, loss_fp: 0.003448, loss_freq: 0.046278
[05:00:32.601] iteration 14304: loss: 0.059973, loss_s1: 0.061148, loss_fp: 0.005648, loss_freq: 0.018287
[05:00:33.225] iteration 14305: loss: 0.126005, loss_s1: 0.167950, loss_fp: 0.002206, loss_freq: 0.041801
[05:00:33.887] iteration 14306: loss: 0.071315, loss_s1: 0.050214, loss_fp: 0.003737, loss_freq: 0.061166
[05:00:34.520] iteration 14307: loss: 0.100236, loss_s1: 0.089177, loss_fp: 0.009717, loss_freq: 0.044372
[05:00:35.154] iteration 14308: loss: 0.118738, loss_s1: 0.154645, loss_fp: 0.002390, loss_freq: 0.026028
[05:00:35.771] iteration 14309: loss: 0.053413, loss_s1: 0.046035, loss_fp: 0.001832, loss_freq: 0.027631
[05:00:36.402] iteration 14310: loss: 0.118609, loss_s1: 0.067231, loss_fp: 0.004647, loss_freq: 0.089799
[05:00:37.029] iteration 14311: loss: 0.047954, loss_s1: 0.028645, loss_fp: 0.001894, loss_freq: 0.034353
[05:00:37.651] iteration 14312: loss: 0.069638, loss_s1: 0.041635, loss_fp: 0.006148, loss_freq: 0.036557
[05:00:38.284] iteration 14313: loss: 0.073317, loss_s1: 0.057309, loss_fp: 0.007570, loss_freq: 0.038658
[05:00:38.924] iteration 14314: loss: 0.061439, loss_s1: 0.050642, loss_fp: 0.004648, loss_freq: 0.010820
[05:00:39.552] iteration 14315: loss: 0.069306, loss_s1: 0.075632, loss_fp: 0.001590, loss_freq: 0.030656
[05:00:40.170] iteration 14316: loss: 0.055501, loss_s1: 0.036211, loss_fp: 0.002849, loss_freq: 0.020327
[05:00:40.915] iteration 14317: loss: 0.076725, loss_s1: 0.075242, loss_fp: 0.002822, loss_freq: 0.029549
[05:00:41.545] iteration 14318: loss: 0.037286, loss_s1: 0.022792, loss_fp: 0.001779, loss_freq: 0.018783
[05:00:42.163] iteration 14319: loss: 0.079353, loss_s1: 0.092186, loss_fp: 0.007124, loss_freq: 0.015023
[05:00:42.799] iteration 14320: loss: 0.081664, loss_s1: 0.083479, loss_fp: 0.004852, loss_freq: 0.029744
[05:00:43.443] iteration 14321: loss: 0.095567, loss_s1: 0.088515, loss_fp: 0.000662, loss_freq: 0.050083
[05:00:44.064] iteration 14322: loss: 0.099724, loss_s1: 0.143806, loss_fp: 0.003796, loss_freq: 0.014014
[05:00:44.702] iteration 14323: loss: 0.098943, loss_s1: 0.104586, loss_fp: 0.004538, loss_freq: 0.056747
[05:00:45.333] iteration 14324: loss: 0.131735, loss_s1: 0.182947, loss_fp: 0.004208, loss_freq: 0.044587
[05:00:45.960] iteration 14325: loss: 0.075079, loss_s1: 0.053833, loss_fp: 0.003111, loss_freq: 0.030635
[05:00:46.619] iteration 14326: loss: 0.062523, loss_s1: 0.052426, loss_fp: 0.003589, loss_freq: 0.022428
[05:00:47.243] iteration 14327: loss: 0.079733, loss_s1: 0.066969, loss_fp: 0.003024, loss_freq: 0.054408
[05:00:47.876] iteration 14328: loss: 0.057047, loss_s1: 0.034340, loss_fp: 0.003184, loss_freq: 0.039959
[05:00:48.504] iteration 14329: loss: 0.059576, loss_s1: 0.062731, loss_fp: 0.003110, loss_freq: 0.010564
[05:00:49.128] iteration 14330: loss: 0.046012, loss_s1: 0.024868, loss_fp: 0.006097, loss_freq: 0.020044
[05:00:49.764] iteration 14331: loss: 0.053285, loss_s1: 0.023695, loss_fp: 0.003919, loss_freq: 0.031444
[05:00:50.392] iteration 14332: loss: 0.061950, loss_s1: 0.060645, loss_fp: 0.002526, loss_freq: 0.031902
[05:00:51.015] iteration 14333: loss: 0.079954, loss_s1: 0.061612, loss_fp: 0.002591, loss_freq: 0.033735
[05:00:51.654] iteration 14334: loss: 0.065361, loss_s1: 0.041302, loss_fp: 0.007052, loss_freq: 0.039225
[05:00:52.295] iteration 14335: loss: 0.056541, loss_s1: 0.016583, loss_fp: 0.007319, loss_freq: 0.042678
[05:00:53.007] iteration 14336: loss: 0.038745, loss_s1: 0.021288, loss_fp: 0.001170, loss_freq: 0.017373
[05:00:53.683] iteration 14337: loss: 0.067308, loss_s1: 0.056122, loss_fp: 0.002659, loss_freq: 0.051255
[05:00:54.389] iteration 14338: loss: 0.063732, loss_s1: 0.030295, loss_fp: 0.003649, loss_freq: 0.044150
[05:00:55.101] iteration 14339: loss: 0.045087, loss_s1: 0.039329, loss_fp: 0.002937, loss_freq: 0.020985
[05:00:55.759] iteration 14340: loss: 0.081302, loss_s1: 0.080075, loss_fp: 0.002917, loss_freq: 0.041010
[05:00:56.387] iteration 14341: loss: 0.044190, loss_s1: 0.028520, loss_fp: 0.009464, loss_freq: 0.013757
[05:00:57.035] iteration 14342: loss: 0.106283, loss_s1: 0.103853, loss_fp: 0.001570, loss_freq: 0.051610
[05:00:57.709] iteration 14343: loss: 0.050448, loss_s1: 0.026605, loss_fp: 0.002093, loss_freq: 0.020904
[05:00:58.381] iteration 14344: loss: 0.042676, loss_s1: 0.037998, loss_fp: 0.001795, loss_freq: 0.015409
[05:00:59.056] iteration 14345: loss: 0.095640, loss_s1: 0.120713, loss_fp: 0.006094, loss_freq: 0.018535
[05:00:59.721] iteration 14346: loss: 0.050638, loss_s1: 0.042987, loss_fp: 0.001424, loss_freq: 0.025168
[05:01:00.376] iteration 14347: loss: 0.066908, loss_s1: 0.068690, loss_fp: 0.003257, loss_freq: 0.013008
[05:01:01.059] iteration 14348: loss: 0.127612, loss_s1: 0.106590, loss_fp: 0.006572, loss_freq: 0.099663
[05:01:01.741] iteration 14349: loss: 0.048369, loss_s1: 0.022104, loss_fp: 0.004095, loss_freq: 0.030980
[05:01:02.435] iteration 14350: loss: 0.058786, loss_s1: 0.034710, loss_fp: 0.001539, loss_freq: 0.039663
[05:01:03.116] iteration 14351: loss: 0.071511, loss_s1: 0.047542, loss_fp: 0.003264, loss_freq: 0.053325
[05:01:03.784] iteration 14352: loss: 0.053899, loss_s1: 0.029479, loss_fp: 0.004582, loss_freq: 0.037728
[05:01:04.427] iteration 14353: loss: 0.052928, loss_s1: 0.028817, loss_fp: 0.010761, loss_freq: 0.028784
[05:01:05.110] iteration 14354: loss: 0.104001, loss_s1: 0.082707, loss_fp: 0.004604, loss_freq: 0.056340
[05:01:05.733] iteration 14355: loss: 0.082498, loss_s1: 0.043575, loss_fp: 0.015391, loss_freq: 0.057253
[05:01:06.357] iteration 14356: loss: 0.085761, loss_s1: 0.068723, loss_fp: 0.006151, loss_freq: 0.060124
[05:01:06.975] iteration 14357: loss: 0.064784, loss_s1: 0.060273, loss_fp: 0.006585, loss_freq: 0.028818
[05:01:07.640] iteration 14358: loss: 0.098523, loss_s1: 0.078369, loss_fp: 0.005547, loss_freq: 0.068428
[05:01:08.276] iteration 14359: loss: 0.078043, loss_s1: 0.051778, loss_fp: 0.015511, loss_freq: 0.056386
[05:01:08.902] iteration 14360: loss: 0.068909, loss_s1: 0.058916, loss_fp: 0.004622, loss_freq: 0.034161
[05:01:09.531] iteration 14361: loss: 0.073719, loss_s1: 0.062211, loss_fp: 0.004235, loss_freq: 0.038342
[05:01:10.167] iteration 14362: loss: 0.049717, loss_s1: 0.031118, loss_fp: 0.002201, loss_freq: 0.031761
[05:01:10.805] iteration 14363: loss: 0.064455, loss_s1: 0.047307, loss_fp: 0.004030, loss_freq: 0.039722
[05:01:11.436] iteration 14364: loss: 0.046533, loss_s1: 0.032943, loss_fp: 0.002758, loss_freq: 0.025199
[05:01:12.065] iteration 14365: loss: 0.087275, loss_s1: 0.100592, loss_fp: 0.001494, loss_freq: 0.026095
[05:01:12.692] iteration 14366: loss: 0.059657, loss_s1: 0.043299, loss_fp: 0.003124, loss_freq: 0.017924
[05:01:13.328] iteration 14367: loss: 0.081402, loss_s1: 0.097871, loss_fp: 0.001971, loss_freq: 0.033702
[05:01:13.975] iteration 14368: loss: 0.072242, loss_s1: 0.068951, loss_fp: 0.002745, loss_freq: 0.040602
[05:01:14.597] iteration 14369: loss: 0.050904, loss_s1: 0.031005, loss_fp: 0.005065, loss_freq: 0.020299
[05:01:15.220] iteration 14370: loss: 0.051727, loss_s1: 0.028897, loss_fp: 0.002297, loss_freq: 0.029629
[05:01:15.846] iteration 14371: loss: 0.095187, loss_s1: 0.100352, loss_fp: 0.002780, loss_freq: 0.042093
[05:01:16.526] iteration 14372: loss: 0.064022, loss_s1: 0.044852, loss_fp: 0.002293, loss_freq: 0.050577
[05:01:17.151] iteration 14373: loss: 0.075524, loss_s1: 0.070935, loss_fp: 0.003083, loss_freq: 0.022584
[05:01:17.769] iteration 14374: loss: 0.065146, loss_s1: 0.049192, loss_fp: 0.001171, loss_freq: 0.036983
[05:01:18.405] iteration 14375: loss: 0.090224, loss_s1: 0.091649, loss_fp: 0.001852, loss_freq: 0.045328
[05:01:19.038] iteration 14376: loss: 0.095617, loss_s1: 0.133581, loss_fp: 0.002481, loss_freq: 0.024499
[05:01:19.681] iteration 14377: loss: 0.134563, loss_s1: 0.091613, loss_fp: 0.007513, loss_freq: 0.122053
[05:01:20.328] iteration 14378: loss: 0.089468, loss_s1: 0.049038, loss_fp: 0.002291, loss_freq: 0.091151
[05:01:20.958] iteration 14379: loss: 0.066487, loss_s1: 0.069286, loss_fp: 0.002289, loss_freq: 0.031011
[05:01:21.605] iteration 14380: loss: 0.041838, loss_s1: 0.027752, loss_fp: 0.002604, loss_freq: 0.016207
[05:01:22.235] iteration 14381: loss: 0.066401, loss_s1: 0.064824, loss_fp: 0.004993, loss_freq: 0.021270
[05:01:22.904] iteration 14382: loss: 0.059429, loss_s1: 0.065226, loss_fp: 0.001676, loss_freq: 0.009239
[05:01:23.576] iteration 14383: loss: 0.049786, loss_s1: 0.037267, loss_fp: 0.001757, loss_freq: 0.022696
[05:01:24.258] iteration 14384: loss: 0.057950, loss_s1: 0.023382, loss_fp: 0.001857, loss_freq: 0.053583
[05:01:24.889] iteration 14385: loss: 0.030643, loss_s1: 0.020136, loss_fp: 0.004186, loss_freq: 0.012612
[05:01:25.517] iteration 14386: loss: 0.066371, loss_s1: 0.042617, loss_fp: 0.004627, loss_freq: 0.027589
[05:01:26.156] iteration 14387: loss: 0.072332, loss_s1: 0.049692, loss_fp: 0.004617, loss_freq: 0.046665
[05:01:26.781] iteration 14388: loss: 0.072334, loss_s1: 0.055782, loss_fp: 0.005442, loss_freq: 0.031917
[05:01:27.432] iteration 14389: loss: 0.076313, loss_s1: 0.042174, loss_fp: 0.005983, loss_freq: 0.054746
[05:01:28.110] iteration 14390: loss: 0.073709, loss_s1: 0.079992, loss_fp: 0.002202, loss_freq: 0.031026
[05:01:28.857] iteration 14391: loss: 0.056497, loss_s1: 0.023075, loss_fp: 0.005298, loss_freq: 0.019742
[05:01:29.602] iteration 14392: loss: 0.085332, loss_s1: 0.089551, loss_fp: 0.002199, loss_freq: 0.033225
[05:01:30.361] iteration 14393: loss: 0.066246, loss_s1: 0.049618, loss_fp: 0.003329, loss_freq: 0.046149
[05:01:31.056] iteration 14394: loss: 0.042759, loss_s1: 0.025242, loss_fp: 0.006319, loss_freq: 0.017819
[05:01:31.708] iteration 14395: loss: 0.090401, loss_s1: 0.059325, loss_fp: 0.001594, loss_freq: 0.076114
[05:01:32.335] iteration 14396: loss: 0.093006, loss_s1: 0.078552, loss_fp: 0.009183, loss_freq: 0.063512
[05:01:32.962] iteration 14397: loss: 0.065070, loss_s1: 0.070093, loss_fp: 0.005737, loss_freq: 0.017801
[05:01:33.608] iteration 14398: loss: 0.046438, loss_s1: 0.031997, loss_fp: 0.002900, loss_freq: 0.025242
[05:01:34.231] iteration 14399: loss: 0.099765, loss_s1: 0.049442, loss_fp: 0.007070, loss_freq: 0.109570
[05:01:34.866] iteration 14400: loss: 0.070552, loss_s1: 0.077955, loss_fp: 0.004558, loss_freq: 0.018075
[05:01:38.251] iteration 14400 : mean_dice : 0.729299
[05:01:38.904] iteration 14401: loss: 0.051021, loss_s1: 0.053905, loss_fp: 0.001687, loss_freq: 0.008513
[05:01:39.546] iteration 14402: loss: 0.060817, loss_s1: 0.060409, loss_fp: 0.004043, loss_freq: 0.032239
[05:01:40.177] iteration 14403: loss: 0.116466, loss_s1: 0.126698, loss_fp: 0.001667, loss_freq: 0.069290
[05:01:40.813] iteration 14404: loss: 0.059723, loss_s1: 0.018379, loss_fp: 0.002037, loss_freq: 0.059442
[05:01:41.439] iteration 14405: loss: 0.137590, loss_s1: 0.159925, loss_fp: 0.004549, loss_freq: 0.067310
[05:01:42.135] iteration 14406: loss: 0.069620, loss_s1: 0.076615, loss_fp: 0.001400, loss_freq: 0.014412
[05:01:42.886] iteration 14407: loss: 0.063747, loss_s1: 0.028515, loss_fp: 0.007349, loss_freq: 0.062352
[05:01:43.603] iteration 14408: loss: 0.065596, loss_s1: 0.058380, loss_fp: 0.001588, loss_freq: 0.016872
[05:01:44.284] iteration 14409: loss: 0.064256, loss_s1: 0.040431, loss_fp: 0.004040, loss_freq: 0.027027
[05:01:44.986] iteration 14410: loss: 0.059164, loss_s1: 0.036020, loss_fp: 0.001915, loss_freq: 0.022038
[05:01:45.699] iteration 14411: loss: 0.069003, loss_s1: 0.074900, loss_fp: 0.003882, loss_freq: 0.031524
[05:01:46.426] iteration 14412: loss: 0.075671, loss_s1: 0.046681, loss_fp: 0.005128, loss_freq: 0.021222
[05:01:47.069] iteration 14413: loss: 0.099131, loss_s1: 0.104969, loss_fp: 0.008146, loss_freq: 0.039484
[05:01:47.803] iteration 14414: loss: 0.059431, loss_s1: 0.067890, loss_fp: 0.002363, loss_freq: 0.018591
[05:01:48.562] iteration 14415: loss: 0.069244, loss_s1: 0.067800, loss_fp: 0.002865, loss_freq: 0.028308
[05:01:49.304] iteration 14416: loss: 0.033617, loss_s1: 0.019061, loss_fp: 0.002154, loss_freq: 0.009311
[05:01:50.074] iteration 14417: loss: 0.066856, loss_s1: 0.034259, loss_fp: 0.001175, loss_freq: 0.025960
[05:01:50.753] iteration 14418: loss: 0.066992, loss_s1: 0.037378, loss_fp: 0.005829, loss_freq: 0.046769
[05:01:51.475] iteration 14419: loss: 0.098469, loss_s1: 0.088038, loss_fp: 0.007794, loss_freq: 0.049555
[05:01:52.263] iteration 14420: loss: 0.062104, loss_s1: 0.062607, loss_fp: 0.009070, loss_freq: 0.024802
[05:01:52.950] iteration 14421: loss: 0.076586, loss_s1: 0.061665, loss_fp: 0.004190, loss_freq: 0.037305
[05:01:53.670] iteration 14422: loss: 0.072399, loss_s1: 0.073557, loss_fp: 0.001995, loss_freq: 0.023788
[05:01:54.326] iteration 14423: loss: 0.065675, loss_s1: 0.058549, loss_fp: 0.004718, loss_freq: 0.029068
[05:01:54.961] iteration 14424: loss: 0.059936, loss_s1: 0.056600, loss_fp: 0.006807, loss_freq: 0.013210
[05:01:55.592] iteration 14425: loss: 0.047993, loss_s1: 0.032504, loss_fp: 0.003277, loss_freq: 0.021000
[05:01:56.218] iteration 14426: loss: 0.049130, loss_s1: 0.038107, loss_fp: 0.000654, loss_freq: 0.020449
[05:01:56.864] iteration 14427: loss: 0.063178, loss_s1: 0.033980, loss_fp: 0.007239, loss_freq: 0.038535
[05:01:57.490] iteration 14428: loss: 0.085307, loss_s1: 0.093596, loss_fp: 0.003814, loss_freq: 0.032144
[05:01:58.109] iteration 14429: loss: 0.078780, loss_s1: 0.091803, loss_fp: 0.005257, loss_freq: 0.024448
[05:01:58.740] iteration 14430: loss: 0.063741, loss_s1: 0.049772, loss_fp: 0.007395, loss_freq: 0.023832
[05:01:59.361] iteration 14431: loss: 0.076970, loss_s1: 0.088649, loss_fp: 0.004491, loss_freq: 0.022417
[05:02:00.018] iteration 14432: loss: 0.077318, loss_s1: 0.052352, loss_fp: 0.006990, loss_freq: 0.049753
[05:02:00.638] iteration 14433: loss: 0.063836, loss_s1: 0.048115, loss_fp: 0.001207, loss_freq: 0.045008
[05:02:01.289] iteration 14434: loss: 0.095747, loss_s1: 0.081095, loss_fp: 0.003132, loss_freq: 0.069875
[05:02:01.926] iteration 14435: loss: 0.085763, loss_s1: 0.034878, loss_fp: 0.002285, loss_freq: 0.093560
[05:02:02.582] iteration 14436: loss: 0.050722, loss_s1: 0.036642, loss_fp: 0.002161, loss_freq: 0.010078
[05:02:03.250] iteration 14437: loss: 0.049747, loss_s1: 0.038156, loss_fp: 0.003820, loss_freq: 0.020090
[05:02:04.112] iteration 14438: loss: 0.110456, loss_s1: 0.102084, loss_fp: 0.003270, loss_freq: 0.078742
[05:02:04.829] iteration 14439: loss: 0.050370, loss_s1: 0.035702, loss_fp: 0.010141, loss_freq: 0.021362
[05:02:05.704] iteration 14440: loss: 0.114017, loss_s1: 0.122830, loss_fp: 0.004123, loss_freq: 0.036274
[05:02:06.331] iteration 14441: loss: 0.057246, loss_s1: 0.039473, loss_fp: 0.006169, loss_freq: 0.020520
[05:02:06.999] iteration 14442: loss: 0.052782, loss_s1: 0.023888, loss_fp: 0.003191, loss_freq: 0.035189
[05:02:07.644] iteration 14443: loss: 0.066415, loss_s1: 0.034567, loss_fp: 0.000969, loss_freq: 0.031993
[05:02:08.275] iteration 14444: loss: 0.040393, loss_s1: 0.025141, loss_fp: 0.001263, loss_freq: 0.019423
[05:02:08.902] iteration 14445: loss: 0.040711, loss_s1: 0.037931, loss_fp: 0.001779, loss_freq: 0.008379
[05:02:09.538] iteration 14446: loss: 0.095156, loss_s1: 0.126790, loss_fp: 0.001063, loss_freq: 0.037773
[05:02:10.198] iteration 14447: loss: 0.075969, loss_s1: 0.034358, loss_fp: 0.002230, loss_freq: 0.063148
[05:02:10.833] iteration 14448: loss: 0.080036, loss_s1: 0.067839, loss_fp: 0.002377, loss_freq: 0.043537
[05:02:11.461] iteration 14449: loss: 0.105710, loss_s1: 0.094402, loss_fp: 0.002188, loss_freq: 0.052584
[05:02:12.097] iteration 14450: loss: 0.080895, loss_s1: 0.077828, loss_fp: 0.002441, loss_freq: 0.043658
[05:02:13.116] iteration 14451: loss: 0.063985, loss_s1: 0.065355, loss_fp: 0.003914, loss_freq: 0.012241
[05:02:13.781] iteration 14452: loss: 0.094587, loss_s1: 0.090956, loss_fp: 0.003639, loss_freq: 0.054691
[05:02:14.410] iteration 14453: loss: 0.067128, loss_s1: 0.063743, loss_fp: 0.001123, loss_freq: 0.035068
[05:02:15.039] iteration 14454: loss: 0.058952, loss_s1: 0.052456, loss_fp: 0.003915, loss_freq: 0.022098
[05:02:15.703] iteration 14455: loss: 0.062480, loss_s1: 0.058281, loss_fp: 0.001429, loss_freq: 0.025788
[05:02:16.345] iteration 14456: loss: 0.083193, loss_s1: 0.081355, loss_fp: 0.006841, loss_freq: 0.040444
[05:02:16.979] iteration 14457: loss: 0.061387, loss_s1: 0.043629, loss_fp: 0.002877, loss_freq: 0.030733
[05:02:17.608] iteration 14458: loss: 0.041663, loss_s1: 0.029670, loss_fp: 0.004406, loss_freq: 0.016436
[05:02:18.261] iteration 14459: loss: 0.054644, loss_s1: 0.044615, loss_fp: 0.001962, loss_freq: 0.027913
[05:02:18.884] iteration 14460: loss: 0.066082, loss_s1: 0.048094, loss_fp: 0.005263, loss_freq: 0.038736
[05:02:19.510] iteration 14461: loss: 0.073549, loss_s1: 0.024084, loss_fp: 0.002976, loss_freq: 0.056154
[05:02:20.138] iteration 14462: loss: 0.066204, loss_s1: 0.040200, loss_fp: 0.002660, loss_freq: 0.049896
[05:02:20.772] iteration 14463: loss: 0.066497, loss_s1: 0.045356, loss_fp: 0.005139, loss_freq: 0.033251
[05:02:21.415] iteration 14464: loss: 0.062024, loss_s1: 0.036407, loss_fp: 0.007537, loss_freq: 0.049404
[05:02:22.055] iteration 14465: loss: 0.057949, loss_s1: 0.042662, loss_fp: 0.001433, loss_freq: 0.027199
[05:02:22.678] iteration 14466: loss: 0.064131, loss_s1: 0.046202, loss_fp: 0.002743, loss_freq: 0.040181
[05:02:23.305] iteration 14467: loss: 0.121261, loss_s1: 0.082105, loss_fp: 0.006691, loss_freq: 0.127459
[05:02:23.931] iteration 14468: loss: 0.062189, loss_s1: 0.045502, loss_fp: 0.004100, loss_freq: 0.015707
[05:02:24.609] iteration 14469: loss: 0.096937, loss_s1: 0.129288, loss_fp: 0.002295, loss_freq: 0.026592
[05:02:25.280] iteration 14470: loss: 0.084972, loss_s1: 0.101830, loss_fp: 0.006923, loss_freq: 0.017333
[05:02:25.951] iteration 14471: loss: 0.055243, loss_s1: 0.027442, loss_fp: 0.004831, loss_freq: 0.032451
[05:02:26.644] iteration 14472: loss: 0.092025, loss_s1: 0.085829, loss_fp: 0.003041, loss_freq: 0.051050
[05:02:27.306] iteration 14473: loss: 0.096097, loss_s1: 0.048254, loss_fp: 0.004169, loss_freq: 0.059993
[05:02:27.993] iteration 14474: loss: 0.055462, loss_s1: 0.035755, loss_fp: 0.003158, loss_freq: 0.028570
[05:02:28.671] iteration 14475: loss: 0.072360, loss_s1: 0.036429, loss_fp: 0.005008, loss_freq: 0.064700
[05:02:29.325] iteration 14476: loss: 0.076754, loss_s1: 0.078772, loss_fp: 0.001204, loss_freq: 0.042947
[05:02:29.956] iteration 14477: loss: 0.084973, loss_s1: 0.057958, loss_fp: 0.002768, loss_freq: 0.022648
[05:02:30.587] iteration 14478: loss: 0.134884, loss_s1: 0.180183, loss_fp: 0.008585, loss_freq: 0.035280
[05:02:31.217] iteration 14479: loss: 0.083911, loss_s1: 0.046628, loss_fp: 0.002618, loss_freq: 0.033940
[05:02:31.847] iteration 14480: loss: 0.126806, loss_s1: 0.151805, loss_fp: 0.001278, loss_freq: 0.058897
[05:02:32.481] iteration 14481: loss: 0.061030, loss_s1: 0.048622, loss_fp: 0.003264, loss_freq: 0.043419
[05:02:33.132] iteration 14482: loss: 0.083050, loss_s1: 0.062469, loss_fp: 0.009087, loss_freq: 0.041078
[05:02:33.824] iteration 14483: loss: 0.135139, loss_s1: 0.156839, loss_fp: 0.003699, loss_freq: 0.055353
[05:02:34.477] iteration 14484: loss: 0.042533, loss_s1: 0.022130, loss_fp: 0.001632, loss_freq: 0.024063
[05:02:35.102] iteration 14485: loss: 0.057098, loss_s1: 0.046823, loss_fp: 0.001833, loss_freq: 0.036368
[05:02:35.797] iteration 14486: loss: 0.064882, loss_s1: 0.043391, loss_fp: 0.000665, loss_freq: 0.017529
[05:02:36.469] iteration 14487: loss: 0.071572, loss_s1: 0.065356, loss_fp: 0.000396, loss_freq: 0.034367
[05:02:37.141] iteration 14488: loss: 0.050795, loss_s1: 0.050517, loss_fp: 0.001588, loss_freq: 0.015341
[05:02:37.759] iteration 14489: loss: 0.080468, loss_s1: 0.045507, loss_fp: 0.002968, loss_freq: 0.046753
[05:02:38.388] iteration 14490: loss: 0.060227, loss_s1: 0.050780, loss_fp: 0.003376, loss_freq: 0.030684
[05:02:39.019] iteration 14491: loss: 0.069258, loss_s1: 0.060423, loss_fp: 0.000518, loss_freq: 0.034014
[05:02:39.645] iteration 14492: loss: 0.065964, loss_s1: 0.055804, loss_fp: 0.005379, loss_freq: 0.024884
[05:02:40.272] iteration 14493: loss: 0.070470, loss_s1: 0.069961, loss_fp: 0.002414, loss_freq: 0.036727
[05:02:40.909] iteration 14494: loss: 0.075959, loss_s1: 0.057879, loss_fp: 0.002086, loss_freq: 0.058012
[05:02:41.539] iteration 14495: loss: 0.060862, loss_s1: 0.046346, loss_fp: 0.004510, loss_freq: 0.032962
[05:02:42.175] iteration 14496: loss: 0.068382, loss_s1: 0.053373, loss_fp: 0.006088, loss_freq: 0.016514
[05:02:42.844] iteration 14497: loss: 0.044578, loss_s1: 0.018115, loss_fp: 0.002325, loss_freq: 0.026995
[05:02:43.474] iteration 14498: loss: 0.064235, loss_s1: 0.053614, loss_fp: 0.001042, loss_freq: 0.033852
[05:02:44.111] iteration 14499: loss: 0.034561, loss_s1: 0.019762, loss_fp: 0.002111, loss_freq: 0.014469
[05:02:44.748] iteration 14500: loss: 0.058668, loss_s1: 0.054520, loss_fp: 0.001144, loss_freq: 0.017040
[05:02:45.371] iteration 14501: loss: 0.051558, loss_s1: 0.039541, loss_fp: 0.002493, loss_freq: 0.022342
[05:02:46.008] iteration 14502: loss: 0.061338, loss_s1: 0.061376, loss_fp: 0.003821, loss_freq: 0.032492
[05:02:46.646] iteration 14503: loss: 0.059357, loss_s1: 0.050882, loss_fp: 0.000675, loss_freq: 0.028530
[05:02:47.310] iteration 14504: loss: 0.078717, loss_s1: 0.048390, loss_fp: 0.001497, loss_freq: 0.065069
[05:02:47.990] iteration 14505: loss: 0.069711, loss_s1: 0.039852, loss_fp: 0.001837, loss_freq: 0.036315
[05:02:48.658] iteration 14506: loss: 0.055569, loss_s1: 0.045983, loss_fp: 0.002329, loss_freq: 0.025086
[05:02:49.313] iteration 14507: loss: 0.095590, loss_s1: 0.089705, loss_fp: 0.001116, loss_freq: 0.065135
[05:02:49.946] iteration 14508: loss: 0.062074, loss_s1: 0.053392, loss_fp: 0.001372, loss_freq: 0.024093
[05:02:50.575] iteration 14509: loss: 0.064184, loss_s1: 0.039502, loss_fp: 0.002622, loss_freq: 0.038875
[05:02:51.197] iteration 14510: loss: 0.082620, loss_s1: 0.052570, loss_fp: 0.004380, loss_freq: 0.039097
[05:02:51.818] iteration 14511: loss: 0.047253, loss_s1: 0.060031, loss_fp: 0.002784, loss_freq: 0.004452
[05:02:52.448] iteration 14512: loss: 0.072212, loss_s1: 0.046586, loss_fp: 0.002499, loss_freq: 0.025989
[05:02:53.076] iteration 14513: loss: 0.042885, loss_s1: 0.026330, loss_fp: 0.002621, loss_freq: 0.010385
[05:02:53.697] iteration 14514: loss: 0.054070, loss_s1: 0.051898, loss_fp: 0.003220, loss_freq: 0.023524
[05:02:54.331] iteration 14515: loss: 0.062004, loss_s1: 0.038381, loss_fp: 0.001491, loss_freq: 0.027147
[05:02:54.953] iteration 14516: loss: 0.078325, loss_s1: 0.084398, loss_fp: 0.001937, loss_freq: 0.034746
[05:02:55.581] iteration 14517: loss: 0.044631, loss_s1: 0.029873, loss_fp: 0.002283, loss_freq: 0.017620
[05:02:56.235] iteration 14518: loss: 0.104064, loss_s1: 0.082593, loss_fp: 0.006941, loss_freq: 0.078915
[05:02:56.854] iteration 14519: loss: 0.047734, loss_s1: 0.016009, loss_fp: 0.002080, loss_freq: 0.031867
[05:02:57.481] iteration 14520: loss: 0.054382, loss_s1: 0.041885, loss_fp: 0.005665, loss_freq: 0.031658
[05:02:58.106] iteration 14521: loss: 0.079844, loss_s1: 0.043642, loss_fp: 0.004972, loss_freq: 0.052983
[05:02:58.740] iteration 14522: loss: 0.056541, loss_s1: 0.031046, loss_fp: 0.005297, loss_freq: 0.040714
[05:02:59.357] iteration 14523: loss: 0.060294, loss_s1: 0.033847, loss_fp: 0.005123, loss_freq: 0.053542
[05:02:59.966] iteration 14524: loss: 0.107998, loss_s1: 0.138129, loss_fp: 0.005622, loss_freq: 0.025154
[05:03:00.592] iteration 14525: loss: 0.069323, loss_s1: 0.045406, loss_fp: 0.005083, loss_freq: 0.056602
[05:03:01.256] iteration 14526: loss: 0.091280, loss_s1: 0.084566, loss_fp: 0.004836, loss_freq: 0.050884
[05:03:01.891] iteration 14527: loss: 0.067373, loss_s1: 0.062409, loss_fp: 0.004765, loss_freq: 0.029167
[05:03:02.515] iteration 14528: loss: 0.099843, loss_s1: 0.072966, loss_fp: 0.009443, loss_freq: 0.034582
[05:03:03.197] iteration 14529: loss: 0.061330, loss_s1: 0.057681, loss_fp: 0.012445, loss_freq: 0.027692
[05:03:03.879] iteration 14530: loss: 0.049616, loss_s1: 0.016076, loss_fp: 0.001507, loss_freq: 0.038544
[05:03:04.504] iteration 14531: loss: 0.082454, loss_s1: 0.056124, loss_fp: 0.003318, loss_freq: 0.062275
[05:03:05.167] iteration 14532: loss: 0.076609, loss_s1: 0.049155, loss_fp: 0.002576, loss_freq: 0.038013
[05:03:05.841] iteration 14533: loss: 0.059501, loss_s1: 0.023386, loss_fp: 0.000562, loss_freq: 0.046133
[05:03:06.503] iteration 14534: loss: 0.060377, loss_s1: 0.034973, loss_fp: 0.012006, loss_freq: 0.020984
[05:03:07.169] iteration 14535: loss: 0.078962, loss_s1: 0.086976, loss_fp: 0.000962, loss_freq: 0.021975
[05:03:07.842] iteration 14536: loss: 0.068233, loss_s1: 0.054601, loss_fp: 0.002853, loss_freq: 0.043461
[05:03:08.515] iteration 14537: loss: 0.074060, loss_s1: 0.071122, loss_fp: 0.001229, loss_freq: 0.039182
[05:03:09.186] iteration 14538: loss: 0.075423, loss_s1: 0.052295, loss_fp: 0.002049, loss_freq: 0.029328
[05:03:09.804] iteration 14539: loss: 0.111258, loss_s1: 0.083006, loss_fp: 0.002779, loss_freq: 0.080507
[05:03:10.415] iteration 14540: loss: 0.050491, loss_s1: 0.025977, loss_fp: 0.003979, loss_freq: 0.013783
[05:03:11.036] iteration 14541: loss: 0.082847, loss_s1: 0.047821, loss_fp: 0.003578, loss_freq: 0.047132
[05:03:11.651] iteration 14542: loss: 0.071621, loss_s1: 0.058690, loss_fp: 0.010453, loss_freq: 0.034923
[05:03:12.264] iteration 14543: loss: 0.082102, loss_s1: 0.058180, loss_fp: 0.003748, loss_freq: 0.040197
[05:03:12.964] iteration 14544: loss: 0.077686, loss_s1: 0.067361, loss_fp: 0.003255, loss_freq: 0.029062
[05:03:13.687] iteration 14545: loss: 0.069818, loss_s1: 0.061398, loss_fp: 0.007133, loss_freq: 0.032765
[05:03:14.376] iteration 14546: loss: 0.094356, loss_s1: 0.110277, loss_fp: 0.002092, loss_freq: 0.043294
[05:03:15.055] iteration 14547: loss: 0.080446, loss_s1: 0.060703, loss_fp: 0.002850, loss_freq: 0.055607
[05:03:15.709] iteration 14548: loss: 0.097643, loss_s1: 0.070746, loss_fp: 0.003478, loss_freq: 0.071280
[05:03:16.418] iteration 14549: loss: 0.061128, loss_s1: 0.033779, loss_fp: 0.003118, loss_freq: 0.054531
[05:03:17.121] iteration 14550: loss: 0.048503, loss_s1: 0.036385, loss_fp: 0.001594, loss_freq: 0.019081
[05:03:17.792] iteration 14551: loss: 0.078076, loss_s1: 0.075800, loss_fp: 0.005731, loss_freq: 0.038029
[05:03:18.472] iteration 14552: loss: 0.046534, loss_s1: 0.025292, loss_fp: 0.001463, loss_freq: 0.018445
[05:03:19.148] iteration 14553: loss: 0.034685, loss_s1: 0.021602, loss_fp: 0.001159, loss_freq: 0.011879
[05:03:19.776] iteration 14554: loss: 0.057133, loss_s1: 0.032594, loss_fp: 0.002327, loss_freq: 0.025956
[05:03:20.429] iteration 14555: loss: 0.060792, loss_s1: 0.063007, loss_fp: 0.001197, loss_freq: 0.024607
[05:03:21.060] iteration 14556: loss: 0.078325, loss_s1: 0.092490, loss_fp: 0.002091, loss_freq: 0.018076
[05:03:21.714] iteration 14557: loss: 0.065315, loss_s1: 0.053166, loss_fp: 0.004806, loss_freq: 0.034298
[05:03:22.356] iteration 14558: loss: 0.041211, loss_s1: 0.021645, loss_fp: 0.003484, loss_freq: 0.019961
[05:03:22.993] iteration 14559: loss: 0.064853, loss_s1: 0.033995, loss_fp: 0.010633, loss_freq: 0.042581
[05:03:23.621] iteration 14560: loss: 0.055888, loss_s1: 0.046039, loss_fp: 0.002986, loss_freq: 0.030528
[05:03:24.265] iteration 14561: loss: 0.057602, loss_s1: 0.046561, loss_fp: 0.002393, loss_freq: 0.026293
[05:03:24.891] iteration 14562: loss: 0.049407, loss_s1: 0.034367, loss_fp: 0.001306, loss_freq: 0.026261
[05:03:25.528] iteration 14563: loss: 0.059169, loss_s1: 0.059327, loss_fp: 0.003307, loss_freq: 0.023180
[05:03:26.161] iteration 14564: loss: 0.042310, loss_s1: 0.025816, loss_fp: 0.002823, loss_freq: 0.026509
[05:03:26.778] iteration 14565: loss: 0.094592, loss_s1: 0.074924, loss_fp: 0.005932, loss_freq: 0.071125
[05:03:27.409] iteration 14566: loss: 0.094232, loss_s1: 0.094013, loss_fp: 0.005765, loss_freq: 0.050961
[05:03:28.032] iteration 14567: loss: 0.116615, loss_s1: 0.138068, loss_fp: 0.012308, loss_freq: 0.044132
[05:03:28.665] iteration 14568: loss: 0.085756, loss_s1: 0.081857, loss_fp: 0.006763, loss_freq: 0.045372
[05:03:29.287] iteration 14569: loss: 0.132942, loss_s1: 0.069976, loss_fp: 0.036704, loss_freq: 0.101792
[05:03:29.923] iteration 14570: loss: 0.086488, loss_s1: 0.052183, loss_fp: 0.005648, loss_freq: 0.074760
[05:03:30.602] iteration 14571: loss: 0.042934, loss_s1: 0.025276, loss_fp: 0.004884, loss_freq: 0.007344
[05:03:31.228] iteration 14572: loss: 0.052083, loss_s1: 0.037359, loss_fp: 0.003106, loss_freq: 0.017267
[05:03:31.884] iteration 14573: loss: 0.126605, loss_s1: 0.169352, loss_fp: 0.006051, loss_freq: 0.028483
[05:03:32.568] iteration 14574: loss: 0.069722, loss_s1: 0.038541, loss_fp: 0.010459, loss_freq: 0.054604
[05:03:33.225] iteration 14575: loss: 0.074693, loss_s1: 0.039270, loss_fp: 0.003831, loss_freq: 0.061709
[05:03:33.879] iteration 14576: loss: 0.069131, loss_s1: 0.030198, loss_fp: 0.000654, loss_freq: 0.034114
[05:03:34.527] iteration 14577: loss: 0.072689, loss_s1: 0.054222, loss_fp: 0.003921, loss_freq: 0.044337
[05:03:35.175] iteration 14578: loss: 0.044350, loss_s1: 0.016743, loss_fp: 0.002837, loss_freq: 0.014805
[05:03:35.813] iteration 14579: loss: 0.051927, loss_s1: 0.038936, loss_fp: 0.004544, loss_freq: 0.030867
[05:03:36.462] iteration 14580: loss: 0.069523, loss_s1: 0.078193, loss_fp: 0.001060, loss_freq: 0.021455
[05:03:37.090] iteration 14581: loss: 0.045077, loss_s1: 0.025647, loss_fp: 0.001617, loss_freq: 0.020657
[05:03:37.715] iteration 14582: loss: 0.063563, loss_s1: 0.046333, loss_fp: 0.003363, loss_freq: 0.015190
[05:03:38.358] iteration 14583: loss: 0.086527, loss_s1: 0.096044, loss_fp: 0.002369, loss_freq: 0.034565
[05:03:38.983] iteration 14584: loss: 0.071697, loss_s1: 0.071257, loss_fp: 0.007231, loss_freq: 0.019822
[05:03:39.609] iteration 14585: loss: 0.100663, loss_s1: 0.050935, loss_fp: 0.002386, loss_freq: 0.102498
[05:03:40.233] iteration 14586: loss: 0.060753, loss_s1: 0.062130, loss_fp: 0.003330, loss_freq: 0.014188
[05:03:40.866] iteration 14587: loss: 0.087970, loss_s1: 0.101795, loss_fp: 0.002907, loss_freq: 0.015398
[05:03:41.490] iteration 14588: loss: 0.075571, loss_s1: 0.057260, loss_fp: 0.008643, loss_freq: 0.050769
[05:03:42.120] iteration 14589: loss: 0.128836, loss_s1: 0.123975, loss_fp: 0.009505, loss_freq: 0.068150
[05:03:42.779] iteration 14590: loss: 0.042917, loss_s1: 0.030659, loss_fp: 0.001446, loss_freq: 0.028376
[05:03:43.451] iteration 14591: loss: 0.069328, loss_s1: 0.053525, loss_fp: 0.003531, loss_freq: 0.020416
[05:03:44.109] iteration 14592: loss: 0.049437, loss_s1: 0.033596, loss_fp: 0.001976, loss_freq: 0.017175
[05:03:44.735] iteration 14593: loss: 0.050247, loss_s1: 0.029066, loss_fp: 0.006209, loss_freq: 0.035931
[05:03:45.387] iteration 14594: loss: 0.041750, loss_s1: 0.017890, loss_fp: 0.005509, loss_freq: 0.014346
[05:03:46.022] iteration 14595: loss: 0.036383, loss_s1: 0.022467, loss_fp: 0.006537, loss_freq: 0.006494
[05:03:46.655] iteration 14596: loss: 0.062929, loss_s1: 0.051679, loss_fp: 0.001834, loss_freq: 0.029468
[05:03:47.326] iteration 14597: loss: 0.042137, loss_s1: 0.032545, loss_fp: 0.002145, loss_freq: 0.014074
[05:03:47.975] iteration 14598: loss: 0.126431, loss_s1: 0.154679, loss_fp: 0.004902, loss_freq: 0.052294
[05:03:48.618] iteration 14599: loss: 0.091887, loss_s1: 0.084343, loss_fp: 0.006577, loss_freq: 0.063754
[05:03:49.247] iteration 14600: loss: 0.081550, loss_s1: 0.037639, loss_fp: 0.019133, loss_freq: 0.064429
[05:03:52.588] iteration 14600 : mean_dice : 0.715024
[05:03:53.278] iteration 14601: loss: 0.091313, loss_s1: 0.089122, loss_fp: 0.009133, loss_freq: 0.029303
[05:03:53.904] iteration 14602: loss: 0.083594, loss_s1: 0.057668, loss_fp: 0.005267, loss_freq: 0.068636
[05:03:54.535] iteration 14603: loss: 0.112065, loss_s1: 0.096213, loss_fp: 0.009153, loss_freq: 0.047314
[05:03:55.179] iteration 14604: loss: 0.082864, loss_s1: 0.033638, loss_fp: 0.006617, loss_freq: 0.048861
[05:03:55.856] iteration 14605: loss: 0.096303, loss_s1: 0.057357, loss_fp: 0.003124, loss_freq: 0.046532
[05:03:56.533] iteration 14606: loss: 0.047919, loss_s1: 0.040475, loss_fp: 0.002939, loss_freq: 0.012763
[05:03:57.157] iteration 14607: loss: 0.036759, loss_s1: 0.018329, loss_fp: 0.003015, loss_freq: 0.025445
[05:03:57.808] iteration 14608: loss: 0.106645, loss_s1: 0.078095, loss_fp: 0.005412, loss_freq: 0.069961
[05:03:58.452] iteration 14609: loss: 0.080581, loss_s1: 0.054102, loss_fp: 0.005426, loss_freq: 0.068156
[05:03:59.099] iteration 14610: loss: 0.065361, loss_s1: 0.067788, loss_fp: 0.003043, loss_freq: 0.022654
[05:03:59.725] iteration 14611: loss: 0.037811, loss_s1: 0.031842, loss_fp: 0.001831, loss_freq: 0.005664
[05:04:00.351] iteration 14612: loss: 0.062446, loss_s1: 0.052792, loss_fp: 0.002792, loss_freq: 0.029176
[05:04:00.985] iteration 14613: loss: 0.056625, loss_s1: 0.030369, loss_fp: 0.003363, loss_freq: 0.022231
[05:04:01.617] iteration 14614: loss: 0.065721, loss_s1: 0.066384, loss_fp: 0.001557, loss_freq: 0.033669
[05:04:02.243] iteration 14615: loss: 0.044399, loss_s1: 0.023013, loss_fp: 0.003402, loss_freq: 0.017826
[05:04:02.868] iteration 14616: loss: 0.065813, loss_s1: 0.053447, loss_fp: 0.005158, loss_freq: 0.035530
[05:04:03.510] iteration 14617: loss: 0.104824, loss_s1: 0.114632, loss_fp: 0.001216, loss_freq: 0.053184
[05:04:04.136] iteration 14618: loss: 0.131552, loss_s1: 0.167173, loss_fp: 0.002679, loss_freq: 0.051699
[05:04:04.767] iteration 14619: loss: 0.113682, loss_s1: 0.080009, loss_fp: 0.002214, loss_freq: 0.078860
[05:04:05.392] iteration 14620: loss: 0.100805, loss_s1: 0.075432, loss_fp: 0.001788, loss_freq: 0.087289
[05:04:06.364] iteration 14621: loss: 0.059017, loss_s1: 0.057559, loss_fp: 0.003264, loss_freq: 0.016124
[05:04:07.037] iteration 14622: loss: 0.073098, loss_s1: 0.041843, loss_fp: 0.002243, loss_freq: 0.039765
[05:04:07.656] iteration 14623: loss: 0.072229, loss_s1: 0.075689, loss_fp: 0.002128, loss_freq: 0.030492
[05:04:08.285] iteration 14624: loss: 0.056029, loss_s1: 0.045431, loss_fp: 0.004303, loss_freq: 0.028513
[05:04:08.910] iteration 14625: loss: 0.063671, loss_s1: 0.057541, loss_fp: 0.001617, loss_freq: 0.038436
[05:04:09.550] iteration 14626: loss: 0.080420, loss_s1: 0.068229, loss_fp: 0.002618, loss_freq: 0.049686
[05:04:10.192] iteration 14627: loss: 0.074259, loss_s1: 0.056684, loss_fp: 0.003929, loss_freq: 0.030699
[05:04:10.857] iteration 14628: loss: 0.060158, loss_s1: 0.066757, loss_fp: 0.002711, loss_freq: 0.011266
[05:04:11.489] iteration 14629: loss: 0.056056, loss_s1: 0.062709, loss_fp: 0.007001, loss_freq: 0.013658
[05:04:12.129] iteration 14630: loss: 0.099568, loss_s1: 0.094527, loss_fp: 0.004461, loss_freq: 0.056178
[05:04:12.760] iteration 14631: loss: 0.052989, loss_s1: 0.041094, loss_fp: 0.002575, loss_freq: 0.019646
[05:04:13.399] iteration 14632: loss: 0.047545, loss_s1: 0.018280, loss_fp: 0.005135, loss_freq: 0.028228
[05:04:14.029] iteration 14633: loss: 0.054204, loss_s1: 0.012663, loss_fp: 0.001821, loss_freq: 0.052801
[05:04:14.659] iteration 14634: loss: 0.063454, loss_s1: 0.030934, loss_fp: 0.002380, loss_freq: 0.025831
[05:04:15.305] iteration 14635: loss: 0.049891, loss_s1: 0.021299, loss_fp: 0.001741, loss_freq: 0.033738
[05:04:15.934] iteration 14636: loss: 0.078800, loss_s1: 0.105643, loss_fp: 0.007391, loss_freq: 0.008934
[05:04:16.592] iteration 14637: loss: 0.095162, loss_s1: 0.069941, loss_fp: 0.003047, loss_freq: 0.081996
[05:04:17.242] iteration 14638: loss: 0.058972, loss_s1: 0.053189, loss_fp: 0.001288, loss_freq: 0.020363
[05:04:17.882] iteration 14639: loss: 0.084013, loss_s1: 0.069057, loss_fp: 0.007531, loss_freq: 0.047001
[05:04:18.521] iteration 14640: loss: 0.050220, loss_s1: 0.033042, loss_fp: 0.002270, loss_freq: 0.018091
[05:04:19.151] iteration 14641: loss: 0.063607, loss_s1: 0.051226, loss_fp: 0.001019, loss_freq: 0.038513
[05:04:19.820] iteration 14642: loss: 0.057895, loss_s1: 0.057357, loss_fp: 0.003451, loss_freq: 0.029540
[05:04:20.447] iteration 14643: loss: 0.085309, loss_s1: 0.066707, loss_fp: 0.002466, loss_freq: 0.053789
[05:04:21.078] iteration 14644: loss: 0.074108, loss_s1: 0.091536, loss_fp: 0.005366, loss_freq: 0.017670
[05:04:21.723] iteration 14645: loss: 0.092750, loss_s1: 0.100321, loss_fp: 0.002483, loss_freq: 0.035925
[05:04:22.419] iteration 14646: loss: 0.064673, loss_s1: 0.056475, loss_fp: 0.001968, loss_freq: 0.036050
[05:04:23.096] iteration 14647: loss: 0.076005, loss_s1: 0.072037, loss_fp: 0.004037, loss_freq: 0.035234
[05:04:23.765] iteration 14648: loss: 0.091914, loss_s1: 0.099546, loss_fp: 0.008136, loss_freq: 0.028962
[05:04:24.434] iteration 14649: loss: 0.054300, loss_s1: 0.038062, loss_fp: 0.001192, loss_freq: 0.036379
[05:04:25.107] iteration 14650: loss: 0.087069, loss_s1: 0.080338, loss_fp: 0.003529, loss_freq: 0.046962
[05:04:25.776] iteration 14651: loss: 0.086355, loss_s1: 0.081764, loss_fp: 0.003761, loss_freq: 0.041275
[05:04:26.408] iteration 14652: loss: 0.092707, loss_s1: 0.072613, loss_fp: 0.009527, loss_freq: 0.058901
[05:04:27.044] iteration 14653: loss: 0.086457, loss_s1: 0.056859, loss_fp: 0.003019, loss_freq: 0.065234
[05:04:27.677] iteration 14654: loss: 0.046374, loss_s1: 0.039355, loss_fp: 0.003620, loss_freq: 0.012570
[05:04:28.349] iteration 14655: loss: 0.053911, loss_s1: 0.041853, loss_fp: 0.001472, loss_freq: 0.035416
[05:04:29.032] iteration 14656: loss: 0.057644, loss_s1: 0.033258, loss_fp: 0.001285, loss_freq: 0.019026
[05:04:29.706] iteration 14657: loss: 0.090145, loss_s1: 0.095973, loss_fp: 0.002564, loss_freq: 0.036156
[05:04:30.387] iteration 14658: loss: 0.049412, loss_s1: 0.037235, loss_fp: 0.002582, loss_freq: 0.022049
[05:04:31.058] iteration 14659: loss: 0.091648, loss_s1: 0.067743, loss_fp: 0.003307, loss_freq: 0.050671
[05:04:31.731] iteration 14660: loss: 0.056761, loss_s1: 0.021635, loss_fp: 0.005822, loss_freq: 0.033564
[05:04:32.460] iteration 14661: loss: 0.067669, loss_s1: 0.047359, loss_fp: 0.004091, loss_freq: 0.039142
[05:04:33.107] iteration 14662: loss: 0.073935, loss_s1: 0.065683, loss_fp: 0.002875, loss_freq: 0.031426
[05:04:33.780] iteration 14663: loss: 0.104970, loss_s1: 0.104774, loss_fp: 0.003214, loss_freq: 0.068024
[05:04:34.453] iteration 14664: loss: 0.082290, loss_s1: 0.074843, loss_fp: 0.004693, loss_freq: 0.024916
[05:04:35.132] iteration 14665: loss: 0.064130, loss_s1: 0.043354, loss_fp: 0.003461, loss_freq: 0.046618
[05:04:35.803] iteration 14666: loss: 0.083219, loss_s1: 0.074587, loss_fp: 0.000880, loss_freq: 0.030415
[05:04:36.424] iteration 14667: loss: 0.051849, loss_s1: 0.011847, loss_fp: 0.003377, loss_freq: 0.043497
[05:04:37.043] iteration 14668: loss: 0.059774, loss_s1: 0.034708, loss_fp: 0.003091, loss_freq: 0.036218
[05:04:37.695] iteration 14669: loss: 0.054502, loss_s1: 0.048533, loss_fp: 0.002247, loss_freq: 0.016376
[05:04:38.344] iteration 14670: loss: 0.061226, loss_s1: 0.041088, loss_fp: 0.001387, loss_freq: 0.019881
[05:04:39.041] iteration 14671: loss: 0.073090, loss_s1: 0.054282, loss_fp: 0.001106, loss_freq: 0.025401
[05:04:39.727] iteration 14672: loss: 0.079089, loss_s1: 0.070041, loss_fp: 0.003101, loss_freq: 0.051708
[05:04:40.395] iteration 14673: loss: 0.052782, loss_s1: 0.039621, loss_fp: 0.000804, loss_freq: 0.018251
[05:04:41.031] iteration 14674: loss: 0.075388, loss_s1: 0.067319, loss_fp: 0.002806, loss_freq: 0.040859
[05:04:41.692] iteration 14675: loss: 0.082845, loss_s1: 0.037500, loss_fp: 0.004361, loss_freq: 0.074461
[05:04:42.323] iteration 14676: loss: 0.052100, loss_s1: 0.053046, loss_fp: 0.000880, loss_freq: 0.011366
[05:04:42.947] iteration 14677: loss: 0.066371, loss_s1: 0.033860, loss_fp: 0.004457, loss_freq: 0.066447
[05:04:43.583] iteration 14678: loss: 0.082499, loss_s1: 0.072802, loss_fp: 0.002161, loss_freq: 0.020610
[05:04:44.210] iteration 14679: loss: 0.073278, loss_s1: 0.083590, loss_fp: 0.001766, loss_freq: 0.028270
[05:04:44.843] iteration 14680: loss: 0.079549, loss_s1: 0.058492, loss_fp: 0.002511, loss_freq: 0.041981
[05:04:45.467] iteration 14681: loss: 0.032658, loss_s1: 0.017361, loss_fp: 0.004767, loss_freq: 0.011096
[05:04:46.093] iteration 14682: loss: 0.101134, loss_s1: 0.058684, loss_fp: 0.005222, loss_freq: 0.071248
[05:04:46.713] iteration 14683: loss: 0.043272, loss_s1: 0.036077, loss_fp: 0.000874, loss_freq: 0.005999
[05:04:47.331] iteration 14684: loss: 0.044944, loss_s1: 0.026598, loss_fp: 0.001216, loss_freq: 0.025658
[05:04:47.984] iteration 14685: loss: 0.075664, loss_s1: 0.082453, loss_fp: 0.007243, loss_freq: 0.013046
[05:04:48.598] iteration 14686: loss: 0.046083, loss_s1: 0.020720, loss_fp: 0.005102, loss_freq: 0.033648
[05:04:49.225] iteration 14687: loss: 0.049634, loss_s1: 0.036212, loss_fp: 0.000669, loss_freq: 0.017302
[05:04:49.839] iteration 14688: loss: 0.128463, loss_s1: 0.136982, loss_fp: 0.012254, loss_freq: 0.041256
[05:04:50.477] iteration 14689: loss: 0.053565, loss_s1: 0.031025, loss_fp: 0.002875, loss_freq: 0.037541
[05:04:51.108] iteration 14690: loss: 0.053282, loss_s1: 0.029258, loss_fp: 0.005717, loss_freq: 0.040622
[05:04:51.729] iteration 14691: loss: 0.077556, loss_s1: 0.060910, loss_fp: 0.006649, loss_freq: 0.036976
[05:04:52.356] iteration 14692: loss: 0.068964, loss_s1: 0.032164, loss_fp: 0.003980, loss_freq: 0.055155
[05:04:52.974] iteration 14693: loss: 0.074581, loss_s1: 0.060292, loss_fp: 0.013239, loss_freq: 0.047471
[05:04:53.595] iteration 14694: loss: 0.104401, loss_s1: 0.118242, loss_fp: 0.007811, loss_freq: 0.040718
[05:04:54.222] iteration 14695: loss: 0.082212, loss_s1: 0.036248, loss_fp: 0.002641, loss_freq: 0.054471
[05:04:54.910] iteration 14696: loss: 0.075156, loss_s1: 0.046268, loss_fp: 0.004196, loss_freq: 0.037815
[05:04:55.595] iteration 14697: loss: 0.067736, loss_s1: 0.035713, loss_fp: 0.002208, loss_freq: 0.034857
[05:04:56.279] iteration 14698: loss: 0.109061, loss_s1: 0.081601, loss_fp: 0.009993, loss_freq: 0.054926
[05:04:56.948] iteration 14699: loss: 0.079976, loss_s1: 0.090961, loss_fp: 0.003917, loss_freq: 0.033029
[05:04:57.579] iteration 14700: loss: 0.066072, loss_s1: 0.046804, loss_fp: 0.003991, loss_freq: 0.032078
[05:04:58.216] iteration 14701: loss: 0.096347, loss_s1: 0.103287, loss_fp: 0.002389, loss_freq: 0.032528
[05:04:58.875] iteration 14702: loss: 0.058924, loss_s1: 0.040490, loss_fp: 0.010029, loss_freq: 0.031828
[05:04:59.517] iteration 14703: loss: 0.056054, loss_s1: 0.050588, loss_fp: 0.001052, loss_freq: 0.019466
[05:05:00.168] iteration 14704: loss: 0.034094, loss_s1: 0.021070, loss_fp: 0.001924, loss_freq: 0.009530
[05:05:00.793] iteration 14705: loss: 0.077181, loss_s1: 0.078054, loss_fp: 0.002560, loss_freq: 0.021123
[05:05:01.420] iteration 14706: loss: 0.059126, loss_s1: 0.036015, loss_fp: 0.002659, loss_freq: 0.035375
[05:05:02.051] iteration 14707: loss: 0.067964, loss_s1: 0.061048, loss_fp: 0.002035, loss_freq: 0.042079
[05:05:02.687] iteration 14708: loss: 0.058210, loss_s1: 0.061504, loss_fp: 0.001046, loss_freq: 0.015697
[05:05:03.313] iteration 14709: loss: 0.080700, loss_s1: 0.065349, loss_fp: 0.002047, loss_freq: 0.052186
[05:05:03.937] iteration 14710: loss: 0.097797, loss_s1: 0.096679, loss_fp: 0.003535, loss_freq: 0.047760
[05:05:04.556] iteration 14711: loss: 0.077489, loss_s1: 0.089498, loss_fp: 0.009033, loss_freq: 0.015310
[05:05:05.211] iteration 14712: loss: 0.049968, loss_s1: 0.037949, loss_fp: 0.006612, loss_freq: 0.023838
[05:05:05.832] iteration 14713: loss: 0.061199, loss_s1: 0.034686, loss_fp: 0.002966, loss_freq: 0.036103
[05:05:06.453] iteration 14714: loss: 0.039493, loss_s1: 0.025361, loss_fp: 0.003801, loss_freq: 0.010770
[05:05:07.085] iteration 14715: loss: 0.076411, loss_s1: 0.038753, loss_fp: 0.002316, loss_freq: 0.064368
[05:05:07.720] iteration 14716: loss: 0.087245, loss_s1: 0.089014, loss_fp: 0.002199, loss_freq: 0.049881
[05:05:08.357] iteration 14717: loss: 0.092331, loss_s1: 0.085957, loss_fp: 0.001588, loss_freq: 0.048736
[05:05:08.992] iteration 14718: loss: 0.058742, loss_s1: 0.028845, loss_fp: 0.002024, loss_freq: 0.028949
[05:05:09.626] iteration 14719: loss: 0.054971, loss_s1: 0.027908, loss_fp: 0.002371, loss_freq: 0.016237
[05:05:10.253] iteration 14720: loss: 0.051987, loss_s1: 0.032091, loss_fp: 0.005628, loss_freq: 0.029099
[05:05:10.889] iteration 14721: loss: 0.097367, loss_s1: 0.058935, loss_fp: 0.011826, loss_freq: 0.032235
[05:05:11.532] iteration 14722: loss: 0.040828, loss_s1: 0.035764, loss_fp: 0.001530, loss_freq: 0.005191
[05:05:12.152] iteration 14723: loss: 0.049080, loss_s1: 0.022026, loss_fp: 0.001918, loss_freq: 0.019506
[05:05:12.783] iteration 14724: loss: 0.055029, loss_s1: 0.035151, loss_fp: 0.003682, loss_freq: 0.027614
[05:05:13.409] iteration 14725: loss: 0.027634, loss_s1: 0.015971, loss_fp: 0.001047, loss_freq: 0.013583
[05:05:14.047] iteration 14726: loss: 0.065119, loss_s1: 0.052875, loss_fp: 0.001851, loss_freq: 0.038293
[05:05:14.723] iteration 14727: loss: 0.043146, loss_s1: 0.021290, loss_fp: 0.004125, loss_freq: 0.025763
[05:05:15.372] iteration 14728: loss: 0.047497, loss_s1: 0.021509, loss_fp: 0.003905, loss_freq: 0.029032
[05:05:15.995] iteration 14729: loss: 0.116680, loss_s1: 0.057929, loss_fp: 0.005359, loss_freq: 0.125029
[05:05:16.636] iteration 14730: loss: 0.061365, loss_s1: 0.032506, loss_fp: 0.006729, loss_freq: 0.038498
[05:05:17.265] iteration 14731: loss: 0.058711, loss_s1: 0.049272, loss_fp: 0.003004, loss_freq: 0.025137
[05:05:17.895] iteration 14732: loss: 0.057095, loss_s1: 0.037916, loss_fp: 0.004943, loss_freq: 0.026359
[05:05:18.529] iteration 14733: loss: 0.072898, loss_s1: 0.069169, loss_fp: 0.002660, loss_freq: 0.028793
[05:05:19.197] iteration 14734: loss: 0.038040, loss_s1: 0.028222, loss_fp: 0.005841, loss_freq: 0.016392
[05:05:19.877] iteration 14735: loss: 0.132300, loss_s1: 0.071391, loss_fp: 0.005059, loss_freq: 0.113967
[05:05:20.539] iteration 14736: loss: 0.075548, loss_s1: 0.048318, loss_fp: 0.004261, loss_freq: 0.048627
[05:05:21.215] iteration 14737: loss: 0.053718, loss_s1: 0.045633, loss_fp: 0.004207, loss_freq: 0.022682
[05:05:21.855] iteration 14738: loss: 0.058529, loss_s1: 0.056362, loss_fp: 0.004174, loss_freq: 0.019444
[05:05:22.508] iteration 14739: loss: 0.104381, loss_s1: 0.084191, loss_fp: 0.002509, loss_freq: 0.083331
[05:05:23.126] iteration 14740: loss: 0.077299, loss_s1: 0.057119, loss_fp: 0.003174, loss_freq: 0.053845
[05:05:23.745] iteration 14741: loss: 0.039470, loss_s1: 0.022811, loss_fp: 0.004031, loss_freq: 0.005856
[05:05:24.361] iteration 14742: loss: 0.079154, loss_s1: 0.063956, loss_fp: 0.003543, loss_freq: 0.057524
[05:05:24.981] iteration 14743: loss: 0.115594, loss_s1: 0.094644, loss_fp: 0.008149, loss_freq: 0.081805
[05:05:25.603] iteration 14744: loss: 0.043345, loss_s1: 0.032147, loss_fp: 0.001938, loss_freq: 0.013350
[05:05:26.217] iteration 14745: loss: 0.065245, loss_s1: 0.036160, loss_fp: 0.006027, loss_freq: 0.042200
[05:05:26.836] iteration 14746: loss: 0.059969, loss_s1: 0.059100, loss_fp: 0.001026, loss_freq: 0.016786
[05:05:27.462] iteration 14747: loss: 0.097468, loss_s1: 0.084981, loss_fp: 0.003132, loss_freq: 0.063595
[05:05:28.087] iteration 14748: loss: 0.070635, loss_s1: 0.076072, loss_fp: 0.002909, loss_freq: 0.010516
[05:05:28.741] iteration 14749: loss: 0.049948, loss_s1: 0.037002, loss_fp: 0.005340, loss_freq: 0.021941
[05:05:29.373] iteration 14750: loss: 0.095203, loss_s1: 0.105063, loss_fp: 0.003627, loss_freq: 0.040139
[05:05:30.115] iteration 14751: loss: 0.080894, loss_s1: 0.101094, loss_fp: 0.002489, loss_freq: 0.022411
[05:05:30.776] iteration 14752: loss: 0.073736, loss_s1: 0.057042, loss_fp: 0.006107, loss_freq: 0.015483
[05:05:31.426] iteration 14753: loss: 0.122121, loss_s1: 0.119209, loss_fp: 0.003156, loss_freq: 0.068255
[05:05:32.071] iteration 14754: loss: 0.070859, loss_s1: 0.069443, loss_fp: 0.002536, loss_freq: 0.033368
[05:05:32.806] iteration 14755: loss: 0.108307, loss_s1: 0.140295, loss_fp: 0.002611, loss_freq: 0.037494
[05:05:33.482] iteration 14756: loss: 0.062749, loss_s1: 0.050941, loss_fp: 0.004819, loss_freq: 0.023015
[05:05:34.160] iteration 14757: loss: 0.070843, loss_s1: 0.057169, loss_fp: 0.000401, loss_freq: 0.018501
[05:05:34.842] iteration 14758: loss: 0.087847, loss_s1: 0.069600, loss_fp: 0.006578, loss_freq: 0.063146
[05:05:35.494] iteration 14759: loss: 0.107828, loss_s1: 0.123954, loss_fp: 0.005254, loss_freq: 0.047307
[05:05:36.167] iteration 14760: loss: 0.097405, loss_s1: 0.118143, loss_fp: 0.003560, loss_freq: 0.044738
[05:05:36.834] iteration 14761: loss: 0.061154, loss_s1: 0.054670, loss_fp: 0.004630, loss_freq: 0.016948
[05:05:37.530] iteration 14762: loss: 0.055709, loss_s1: 0.019344, loss_fp: 0.002508, loss_freq: 0.031318
[05:05:38.193] iteration 14763: loss: 0.048836, loss_s1: 0.026620, loss_fp: 0.002260, loss_freq: 0.033261
[05:05:38.829] iteration 14764: loss: 0.049280, loss_s1: 0.033513, loss_fp: 0.003226, loss_freq: 0.022106
[05:05:39.483] iteration 14765: loss: 0.033201, loss_s1: 0.016211, loss_fp: 0.003097, loss_freq: 0.012190
[05:05:40.170] iteration 14766: loss: 0.075911, loss_s1: 0.058862, loss_fp: 0.003511, loss_freq: 0.037695
[05:05:40.901] iteration 14767: loss: 0.038435, loss_s1: 0.027504, loss_fp: 0.002268, loss_freq: 0.014497
[05:05:41.546] iteration 14768: loss: 0.091831, loss_s1: 0.102435, loss_fp: 0.004129, loss_freq: 0.030840
[05:05:42.194] iteration 14769: loss: 0.089345, loss_s1: 0.086992, loss_fp: 0.008371, loss_freq: 0.050751
[05:05:42.843] iteration 14770: loss: 0.091914, loss_s1: 0.079214, loss_fp: 0.008511, loss_freq: 0.026798
[05:05:43.502] iteration 14771: loss: 0.064074, loss_s1: 0.064891, loss_fp: 0.007146, loss_freq: 0.022263
[05:05:44.150] iteration 14772: loss: 0.059882, loss_s1: 0.050034, loss_fp: 0.010009, loss_freq: 0.022584
[05:05:44.800] iteration 14773: loss: 0.096121, loss_s1: 0.084466, loss_fp: 0.006333, loss_freq: 0.061788
[05:05:45.436] iteration 14774: loss: 0.081577, loss_s1: 0.081006, loss_fp: 0.007466, loss_freq: 0.035033
[05:05:46.059] iteration 14775: loss: 0.085541, loss_s1: 0.087191, loss_fp: 0.003166, loss_freq: 0.031318
[05:05:46.677] iteration 14776: loss: 0.071404, loss_s1: 0.067908, loss_fp: 0.001495, loss_freq: 0.014922
[05:05:47.332] iteration 14777: loss: 0.076571, loss_s1: 0.038542, loss_fp: 0.005718, loss_freq: 0.018471
[05:05:47.957] iteration 14778: loss: 0.139084, loss_s1: 0.118185, loss_fp: 0.002850, loss_freq: 0.105867
[05:05:48.597] iteration 14779: loss: 0.084443, loss_s1: 0.068214, loss_fp: 0.008369, loss_freq: 0.057193
[05:05:49.234] iteration 14780: loss: 0.070750, loss_s1: 0.048926, loss_fp: 0.010246, loss_freq: 0.030048
[05:05:49.931] iteration 14781: loss: 0.038098, loss_s1: 0.024366, loss_fp: 0.001641, loss_freq: 0.008806
[05:05:50.608] iteration 14782: loss: 0.059325, loss_s1: 0.056072, loss_fp: 0.002984, loss_freq: 0.030045
[05:05:51.279] iteration 14783: loss: 0.055778, loss_s1: 0.019221, loss_fp: 0.001486, loss_freq: 0.015848
[05:05:51.945] iteration 14784: loss: 0.044983, loss_s1: 0.033656, loss_fp: 0.001017, loss_freq: 0.016967
[05:05:52.612] iteration 14785: loss: 0.047278, loss_s1: 0.026758, loss_fp: 0.003542, loss_freq: 0.018562
[05:05:53.243] iteration 14786: loss: 0.063041, loss_s1: 0.047219, loss_fp: 0.001144, loss_freq: 0.051877
[05:05:53.871] iteration 14787: loss: 0.046639, loss_s1: 0.031467, loss_fp: 0.001999, loss_freq: 0.019193
[05:05:54.507] iteration 14788: loss: 0.116943, loss_s1: 0.173540, loss_fp: 0.001747, loss_freq: 0.017442
[05:05:55.134] iteration 14789: loss: 0.070818, loss_s1: 0.060468, loss_fp: 0.002297, loss_freq: 0.045973
[05:05:55.776] iteration 14790: loss: 0.088887, loss_s1: 0.101735, loss_fp: 0.004639, loss_freq: 0.033354
[05:05:56.831] iteration 14791: loss: 0.056273, loss_s1: 0.033819, loss_fp: 0.004912, loss_freq: 0.035216
[05:05:57.468] iteration 14792: loss: 0.093656, loss_s1: 0.105218, loss_fp: 0.003566, loss_freq: 0.034999
[05:05:58.091] iteration 14793: loss: 0.059553, loss_s1: 0.050850, loss_fp: 0.003285, loss_freq: 0.034567
[05:05:58.709] iteration 14794: loss: 0.057043, loss_s1: 0.049180, loss_fp: 0.001515, loss_freq: 0.018587
[05:05:59.380] iteration 14795: loss: 0.079002, loss_s1: 0.070971, loss_fp: 0.005565, loss_freq: 0.026900
[05:06:00.057] iteration 14796: loss: 0.069241, loss_s1: 0.048321, loss_fp: 0.005947, loss_freq: 0.035133
[05:06:00.729] iteration 14797: loss: 0.078314, loss_s1: 0.047903, loss_fp: 0.012072, loss_freq: 0.052471
[05:06:01.406] iteration 14798: loss: 0.069784, loss_s1: 0.069510, loss_fp: 0.009938, loss_freq: 0.025138
[05:06:02.064] iteration 14799: loss: 0.077599, loss_s1: 0.082435, loss_fp: 0.006450, loss_freq: 0.034791
[05:06:02.687] iteration 14800: loss: 0.089014, loss_s1: 0.049896, loss_fp: 0.012244, loss_freq: 0.059567
[05:06:05.917] iteration 14800 : mean_dice : 0.716680
[05:06:06.594] iteration 14801: loss: 0.081929, loss_s1: 0.044028, loss_fp: 0.002977, loss_freq: 0.079614
[05:06:07.221] iteration 14802: loss: 0.076941, loss_s1: 0.060771, loss_fp: 0.003157, loss_freq: 0.048532
[05:06:07.855] iteration 14803: loss: 0.063775, loss_s1: 0.046260, loss_fp: 0.001203, loss_freq: 0.041794
[05:06:08.485] iteration 14804: loss: 0.059946, loss_s1: 0.055166, loss_fp: 0.005682, loss_freq: 0.015860
[05:06:09.177] iteration 14805: loss: 0.073875, loss_s1: 0.083184, loss_fp: 0.003844, loss_freq: 0.016171
[05:06:09.878] iteration 14806: loss: 0.102381, loss_s1: 0.101914, loss_fp: 0.008237, loss_freq: 0.048594
[05:06:10.508] iteration 14807: loss: 0.112921, loss_s1: 0.079518, loss_fp: 0.003105, loss_freq: 0.090706
[05:06:11.143] iteration 14808: loss: 0.045985, loss_s1: 0.032513, loss_fp: 0.002435, loss_freq: 0.013729
[05:06:11.770] iteration 14809: loss: 0.087906, loss_s1: 0.107540, loss_fp: 0.006109, loss_freq: 0.026507
[05:06:12.414] iteration 14810: loss: 0.044860, loss_s1: 0.022335, loss_fp: 0.005324, loss_freq: 0.016802
[05:06:13.048] iteration 14811: loss: 0.054557, loss_s1: 0.042098, loss_fp: 0.004363, loss_freq: 0.022103
[05:06:13.672] iteration 14812: loss: 0.036606, loss_s1: 0.022628, loss_fp: 0.004209, loss_freq: 0.019424
[05:06:14.306] iteration 14813: loss: 0.057587, loss_s1: 0.035771, loss_fp: 0.001336, loss_freq: 0.024559
[05:06:14.972] iteration 14814: loss: 0.077241, loss_s1: 0.090711, loss_fp: 0.001263, loss_freq: 0.021705
[05:06:15.661] iteration 14815: loss: 0.088630, loss_s1: 0.074785, loss_fp: 0.002416, loss_freq: 0.032300
[05:06:16.328] iteration 14816: loss: 0.049692, loss_s1: 0.031813, loss_fp: 0.005078, loss_freq: 0.034487
[05:06:16.983] iteration 14817: loss: 0.041174, loss_s1: 0.014093, loss_fp: 0.006693, loss_freq: 0.016101
[05:06:17.595] iteration 14818: loss: 0.078748, loss_s1: 0.064808, loss_fp: 0.005566, loss_freq: 0.024025
[05:06:18.228] iteration 14819: loss: 0.070958, loss_s1: 0.067283, loss_fp: 0.007903, loss_freq: 0.028916
[05:06:18.882] iteration 14820: loss: 0.060287, loss_s1: 0.037448, loss_fp: 0.002337, loss_freq: 0.040978
[05:06:19.557] iteration 14821: loss: 0.088019, loss_s1: 0.061172, loss_fp: 0.002385, loss_freq: 0.085682
[05:06:20.232] iteration 14822: loss: 0.096900, loss_s1: 0.061185, loss_fp: 0.003481, loss_freq: 0.075997
[05:06:20.912] iteration 14823: loss: 0.060167, loss_s1: 0.051689, loss_fp: 0.001440, loss_freq: 0.033742
[05:06:21.569] iteration 14824: loss: 0.044836, loss_s1: 0.027647, loss_fp: 0.003898, loss_freq: 0.012524
[05:06:22.195] iteration 14825: loss: 0.062566, loss_s1: 0.064216, loss_fp: 0.005166, loss_freq: 0.021740
[05:06:22.831] iteration 14826: loss: 0.058176, loss_s1: 0.056603, loss_fp: 0.002887, loss_freq: 0.008078
[05:06:23.452] iteration 14827: loss: 0.075401, loss_s1: 0.081192, loss_fp: 0.001277, loss_freq: 0.029404
[05:06:24.075] iteration 14828: loss: 0.076545, loss_s1: 0.086034, loss_fp: 0.003103, loss_freq: 0.020047
[05:06:24.701] iteration 14829: loss: 0.104683, loss_s1: 0.125951, loss_fp: 0.005057, loss_freq: 0.031244
[05:06:25.349] iteration 14830: loss: 0.069540, loss_s1: 0.061145, loss_fp: 0.006853, loss_freq: 0.035961
[05:06:25.975] iteration 14831: loss: 0.068210, loss_s1: 0.053983, loss_fp: 0.016994, loss_freq: 0.021291
[05:06:26.612] iteration 14832: loss: 0.071197, loss_s1: 0.056111, loss_fp: 0.005539, loss_freq: 0.027686
[05:06:27.248] iteration 14833: loss: 0.080839, loss_s1: 0.107251, loss_fp: 0.002241, loss_freq: 0.024274
[05:06:27.865] iteration 14834: loss: 0.120140, loss_s1: 0.099658, loss_fp: 0.002657, loss_freq: 0.100000
[05:06:28.494] iteration 14835: loss: 0.056015, loss_s1: 0.031426, loss_fp: 0.002035, loss_freq: 0.033919
[05:06:29.122] iteration 14836: loss: 0.090518, loss_s1: 0.112992, loss_fp: 0.002337, loss_freq: 0.026846
[05:06:29.752] iteration 14837: loss: 0.049451, loss_s1: 0.034288, loss_fp: 0.006165, loss_freq: 0.020390
[05:06:30.397] iteration 14838: loss: 0.061261, loss_s1: 0.053233, loss_fp: 0.004822, loss_freq: 0.020202
[05:06:31.077] iteration 14839: loss: 0.043920, loss_s1: 0.048106, loss_fp: 0.001244, loss_freq: 0.004904
[05:06:31.759] iteration 14840: loss: 0.053781, loss_s1: 0.032762, loss_fp: 0.000476, loss_freq: 0.012711
[05:06:32.468] iteration 14841: loss: 0.047574, loss_s1: 0.030446, loss_fp: 0.002835, loss_freq: 0.018996
[05:06:33.180] iteration 14842: loss: 0.081735, loss_s1: 0.075342, loss_fp: 0.010413, loss_freq: 0.047973
[05:06:33.868] iteration 14843: loss: 0.050826, loss_s1: 0.027050, loss_fp: 0.002208, loss_freq: 0.016314
[05:06:34.551] iteration 14844: loss: 0.077922, loss_s1: 0.066833, loss_fp: 0.011630, loss_freq: 0.032668
[05:06:35.246] iteration 14845: loss: 0.068444, loss_s1: 0.029192, loss_fp: 0.008116, loss_freq: 0.050231
[05:06:35.938] iteration 14846: loss: 0.059598, loss_s1: 0.051327, loss_fp: 0.002606, loss_freq: 0.026968
[05:06:36.629] iteration 14847: loss: 0.081079, loss_s1: 0.061461, loss_fp: 0.009024, loss_freq: 0.064179
[05:06:37.317] iteration 14848: loss: 0.079721, loss_s1: 0.048883, loss_fp: 0.007802, loss_freq: 0.044169
[05:06:37.994] iteration 14849: loss: 0.059874, loss_s1: 0.024900, loss_fp: 0.003449, loss_freq: 0.061087
[05:06:38.677] iteration 14850: loss: 0.099053, loss_s1: 0.064322, loss_fp: 0.007779, loss_freq: 0.052451
[05:06:39.363] iteration 14851: loss: 0.034394, loss_s1: 0.015368, loss_fp: 0.003584, loss_freq: 0.010459
[05:06:40.045] iteration 14852: loss: 0.077119, loss_s1: 0.058551, loss_fp: 0.005063, loss_freq: 0.042953
[05:06:40.683] iteration 14853: loss: 0.052549, loss_s1: 0.038234, loss_fp: 0.002753, loss_freq: 0.027506
[05:06:41.355] iteration 14854: loss: 0.038348, loss_s1: 0.019232, loss_fp: 0.001288, loss_freq: 0.016947
[05:06:41.984] iteration 14855: loss: 0.067374, loss_s1: 0.053284, loss_fp: 0.006843, loss_freq: 0.019692
[05:06:42.612] iteration 14856: loss: 0.052375, loss_s1: 0.037712, loss_fp: 0.002969, loss_freq: 0.034154
[05:06:43.246] iteration 14857: loss: 0.058599, loss_s1: 0.044529, loss_fp: 0.002198, loss_freq: 0.016524
[05:06:43.883] iteration 14858: loss: 0.106444, loss_s1: 0.090001, loss_fp: 0.003221, loss_freq: 0.071994
[05:06:44.511] iteration 14859: loss: 0.053074, loss_s1: 0.039519, loss_fp: 0.000731, loss_freq: 0.026386
[05:06:45.140] iteration 14860: loss: 0.050052, loss_s1: 0.046921, loss_fp: 0.002142, loss_freq: 0.026669
[05:06:45.766] iteration 14861: loss: 0.077695, loss_s1: 0.044472, loss_fp: 0.004573, loss_freq: 0.033375
[05:06:46.402] iteration 14862: loss: 0.060192, loss_s1: 0.048657, loss_fp: 0.001705, loss_freq: 0.025193
[05:06:47.026] iteration 14863: loss: 0.068810, loss_s1: 0.069849, loss_fp: 0.002189, loss_freq: 0.031347
[05:06:47.661] iteration 14864: loss: 0.063874, loss_s1: 0.062379, loss_fp: 0.003435, loss_freq: 0.017770
[05:06:48.341] iteration 14865: loss: 0.079236, loss_s1: 0.031146, loss_fp: 0.001791, loss_freq: 0.063438
[05:06:48.969] iteration 14866: loss: 0.082779, loss_s1: 0.039044, loss_fp: 0.005660, loss_freq: 0.071267
[05:06:49.597] iteration 14867: loss: 0.065784, loss_s1: 0.063751, loss_fp: 0.002309, loss_freq: 0.030615
[05:06:50.262] iteration 14868: loss: 0.098452, loss_s1: 0.083793, loss_fp: 0.012923, loss_freq: 0.047013
[05:06:50.892] iteration 14869: loss: 0.078684, loss_s1: 0.082080, loss_fp: 0.006323, loss_freq: 0.042314
[05:06:51.530] iteration 14870: loss: 0.051217, loss_s1: 0.035674, loss_fp: 0.002292, loss_freq: 0.023085
[05:06:52.164] iteration 14871: loss: 0.064396, loss_s1: 0.032276, loss_fp: 0.005947, loss_freq: 0.038648
[05:06:52.794] iteration 14872: loss: 0.047941, loss_s1: 0.035256, loss_fp: 0.004758, loss_freq: 0.017889
[05:06:53.445] iteration 14873: loss: 0.046816, loss_s1: 0.032561, loss_fp: 0.001595, loss_freq: 0.020852
[05:06:54.099] iteration 14874: loss: 0.070440, loss_s1: 0.029442, loss_fp: 0.004578, loss_freq: 0.052243
[05:06:54.737] iteration 14875: loss: 0.062426, loss_s1: 0.019753, loss_fp: 0.004729, loss_freq: 0.040830
[05:06:55.385] iteration 14876: loss: 0.057375, loss_s1: 0.046549, loss_fp: 0.001366, loss_freq: 0.026027
[05:06:56.003] iteration 14877: loss: 0.078704, loss_s1: 0.071480, loss_fp: 0.001793, loss_freq: 0.052577
[05:06:56.632] iteration 14878: loss: 0.065663, loss_s1: 0.061031, loss_fp: 0.006878, loss_freq: 0.021410
[05:06:57.261] iteration 14879: loss: 0.073551, loss_s1: 0.060108, loss_fp: 0.017787, loss_freq: 0.035285
[05:06:57.888] iteration 14880: loss: 0.049266, loss_s1: 0.019173, loss_fp: 0.005291, loss_freq: 0.030366
[05:06:58.511] iteration 14881: loss: 0.056941, loss_s1: 0.037477, loss_fp: 0.004007, loss_freq: 0.033577
[05:06:59.153] iteration 14882: loss: 0.086716, loss_s1: 0.045691, loss_fp: 0.014252, loss_freq: 0.080183
[05:06:59.776] iteration 14883: loss: 0.120865, loss_s1: 0.106937, loss_fp: 0.005745, loss_freq: 0.067325
[05:07:00.415] iteration 14884: loss: 0.064925, loss_s1: 0.041189, loss_fp: 0.000581, loss_freq: 0.050474
[05:07:01.072] iteration 14885: loss: 0.075283, loss_s1: 0.043025, loss_fp: 0.000890, loss_freq: 0.049718
[05:07:01.699] iteration 14886: loss: 0.062862, loss_s1: 0.036710, loss_fp: 0.010981, loss_freq: 0.047227
[05:07:02.324] iteration 14887: loss: 0.110638, loss_s1: 0.073270, loss_fp: 0.003654, loss_freq: 0.069780
[05:07:02.949] iteration 14888: loss: 0.062569, loss_s1: 0.050382, loss_fp: 0.001856, loss_freq: 0.024588
[05:07:03.568] iteration 14889: loss: 0.084196, loss_s1: 0.036463, loss_fp: 0.008621, loss_freq: 0.069530
[05:07:04.210] iteration 14890: loss: 0.055060, loss_s1: 0.034273, loss_fp: 0.000598, loss_freq: 0.029468
[05:07:04.852] iteration 14891: loss: 0.065386, loss_s1: 0.073809, loss_fp: 0.006628, loss_freq: 0.012955
[05:07:05.483] iteration 14892: loss: 0.042040, loss_s1: 0.013605, loss_fp: 0.002127, loss_freq: 0.009296
[05:07:06.113] iteration 14893: loss: 0.048320, loss_s1: 0.037395, loss_fp: 0.002314, loss_freq: 0.024793
[05:07:06.744] iteration 14894: loss: 0.042263, loss_s1: 0.026739, loss_fp: 0.002261, loss_freq: 0.015962
[05:07:07.372] iteration 14895: loss: 0.057685, loss_s1: 0.038369, loss_fp: 0.006456, loss_freq: 0.037664
[05:07:08.015] iteration 14896: loss: 0.069379, loss_s1: 0.049247, loss_fp: 0.002571, loss_freq: 0.036220
[05:07:08.640] iteration 14897: loss: 0.056461, loss_s1: 0.054158, loss_fp: 0.002609, loss_freq: 0.017711
[05:07:09.281] iteration 14898: loss: 0.051064, loss_s1: 0.028656, loss_fp: 0.006225, loss_freq: 0.029586
[05:07:09.914] iteration 14899: loss: 0.070396, loss_s1: 0.059884, loss_fp: 0.006166, loss_freq: 0.036750
[05:07:10.548] iteration 14900: loss: 0.062460, loss_s1: 0.051644, loss_fp: 0.009523, loss_freq: 0.034343
[05:07:11.185] iteration 14901: loss: 0.073060, loss_s1: 0.058320, loss_fp: 0.003348, loss_freq: 0.030076
[05:07:11.820] iteration 14902: loss: 0.058768, loss_s1: 0.036194, loss_fp: 0.004657, loss_freq: 0.032369
[05:07:12.444] iteration 14903: loss: 0.069245, loss_s1: 0.063989, loss_fp: 0.002781, loss_freq: 0.026523
[05:07:13.168] iteration 14904: loss: 0.034525, loss_s1: 0.024521, loss_fp: 0.001640, loss_freq: 0.008336
[05:07:13.840] iteration 14905: loss: 0.125035, loss_s1: 0.098274, loss_fp: 0.014300, loss_freq: 0.086912
[05:07:14.478] iteration 14906: loss: 0.055887, loss_s1: 0.027046, loss_fp: 0.006533, loss_freq: 0.035886
[05:07:15.123] iteration 14907: loss: 0.118118, loss_s1: 0.122346, loss_fp: 0.021256, loss_freq: 0.053005
[05:07:15.751] iteration 14908: loss: 0.056298, loss_s1: 0.045384, loss_fp: 0.004974, loss_freq: 0.028567
[05:07:16.381] iteration 14909: loss: 0.082676, loss_s1: 0.042549, loss_fp: 0.002340, loss_freq: 0.072552
[05:07:17.029] iteration 14910: loss: 0.064430, loss_s1: 0.045392, loss_fp: 0.004999, loss_freq: 0.036579
[05:07:17.662] iteration 14911: loss: 0.043738, loss_s1: 0.042434, loss_fp: 0.001481, loss_freq: 0.009709
[05:07:18.293] iteration 14912: loss: 0.053665, loss_s1: 0.055360, loss_fp: 0.001199, loss_freq: 0.026765
[05:07:18.924] iteration 14913: loss: 0.116831, loss_s1: 0.106479, loss_fp: 0.008216, loss_freq: 0.074274
[05:07:19.566] iteration 14914: loss: 0.046192, loss_s1: 0.037044, loss_fp: 0.005634, loss_freq: 0.016486
[05:07:20.204] iteration 14915: loss: 0.067219, loss_s1: 0.035134, loss_fp: 0.006111, loss_freq: 0.037221
[05:07:20.834] iteration 14916: loss: 0.087365, loss_s1: 0.113146, loss_fp: 0.001892, loss_freq: 0.022924
[05:07:21.479] iteration 14917: loss: 0.078183, loss_s1: 0.061909, loss_fp: 0.006588, loss_freq: 0.061727
[05:07:22.117] iteration 14918: loss: 0.067218, loss_s1: 0.051227, loss_fp: 0.005101, loss_freq: 0.035121
[05:07:22.754] iteration 14919: loss: 0.075217, loss_s1: 0.053417, loss_fp: 0.004807, loss_freq: 0.053334
[05:07:23.396] iteration 14920: loss: 0.105081, loss_s1: 0.098791, loss_fp: 0.016525, loss_freq: 0.046911
[05:07:24.024] iteration 14921: loss: 0.072720, loss_s1: 0.049133, loss_fp: 0.005895, loss_freq: 0.041851
[05:07:24.653] iteration 14922: loss: 0.044366, loss_s1: 0.017894, loss_fp: 0.002659, loss_freq: 0.024023
[05:07:25.297] iteration 14923: loss: 0.093492, loss_s1: 0.109010, loss_fp: 0.002142, loss_freq: 0.029017
[05:07:25.990] iteration 14924: loss: 0.050573, loss_s1: 0.038838, loss_fp: 0.003658, loss_freq: 0.026094
[05:07:26.696] iteration 14925: loss: 0.100425, loss_s1: 0.074627, loss_fp: 0.004869, loss_freq: 0.072031
[05:07:27.380] iteration 14926: loss: 0.029801, loss_s1: 0.023660, loss_fp: 0.003421, loss_freq: 0.007612
[05:07:28.062] iteration 14927: loss: 0.078511, loss_s1: 0.036693, loss_fp: 0.002056, loss_freq: 0.046088
[05:07:28.746] iteration 14928: loss: 0.076185, loss_s1: 0.045858, loss_fp: 0.003912, loss_freq: 0.037319
[05:07:29.437] iteration 14929: loss: 0.135943, loss_s1: 0.150066, loss_fp: 0.007198, loss_freq: 0.074286
[05:07:30.113] iteration 14930: loss: 0.053403, loss_s1: 0.050822, loss_fp: 0.000457, loss_freq: 0.030038
[05:07:30.793] iteration 14931: loss: 0.074452, loss_s1: 0.052828, loss_fp: 0.000775, loss_freq: 0.034463
[05:07:31.486] iteration 14932: loss: 0.074463, loss_s1: 0.054748, loss_fp: 0.005109, loss_freq: 0.023348
[05:07:32.163] iteration 14933: loss: 0.075816, loss_s1: 0.064852, loss_fp: 0.005329, loss_freq: 0.032017
[05:07:32.849] iteration 14934: loss: 0.087885, loss_s1: 0.047475, loss_fp: 0.004476, loss_freq: 0.029577
[05:07:33.529] iteration 14935: loss: 0.050791, loss_s1: 0.051738, loss_fp: 0.003937, loss_freq: 0.007065
[05:07:34.198] iteration 14936: loss: 0.074843, loss_s1: 0.039260, loss_fp: 0.002901, loss_freq: 0.046645
[05:07:34.822] iteration 14937: loss: 0.048571, loss_s1: 0.022538, loss_fp: 0.003320, loss_freq: 0.037731
[05:07:35.447] iteration 14938: loss: 0.097902, loss_s1: 0.091570, loss_fp: 0.015201, loss_freq: 0.061454
[05:07:36.101] iteration 14939: loss: 0.086457, loss_s1: 0.092999, loss_fp: 0.005743, loss_freq: 0.047666
[05:07:36.750] iteration 14940: loss: 0.079670, loss_s1: 0.053644, loss_fp: 0.002883, loss_freq: 0.054479
[05:07:37.367] iteration 14941: loss: 0.079587, loss_s1: 0.041273, loss_fp: 0.004143, loss_freq: 0.062974
[05:07:37.991] iteration 14942: loss: 0.055622, loss_s1: 0.038536, loss_fp: 0.004456, loss_freq: 0.032076
[05:07:38.616] iteration 14943: loss: 0.073325, loss_s1: 0.071606, loss_fp: 0.012313, loss_freq: 0.026098
[05:07:39.235] iteration 14944: loss: 0.071075, loss_s1: 0.057910, loss_fp: 0.004159, loss_freq: 0.041576
[05:07:39.852] iteration 14945: loss: 0.105428, loss_s1: 0.065939, loss_fp: 0.003191, loss_freq: 0.067610
[05:07:40.470] iteration 14946: loss: 0.040474, loss_s1: 0.023602, loss_fp: 0.001737, loss_freq: 0.014339
[05:07:41.085] iteration 14947: loss: 0.046259, loss_s1: 0.027934, loss_fp: 0.006842, loss_freq: 0.030391
[05:07:41.740] iteration 14948: loss: 0.114240, loss_s1: 0.107416, loss_fp: 0.005308, loss_freq: 0.070363
[05:07:42.371] iteration 14949: loss: 0.056471, loss_s1: 0.043515, loss_fp: 0.001437, loss_freq: 0.032617
[05:07:43.018] iteration 14950: loss: 0.085745, loss_s1: 0.061972, loss_fp: 0.009488, loss_freq: 0.036862
[05:07:43.693] iteration 14951: loss: 0.042591, loss_s1: 0.040357, loss_fp: 0.001429, loss_freq: 0.010991
[05:07:44.371] iteration 14952: loss: 0.068954, loss_s1: 0.080084, loss_fp: 0.006194, loss_freq: 0.022314
[05:07:45.081] iteration 14953: loss: 0.075938, loss_s1: 0.063620, loss_fp: 0.006081, loss_freq: 0.027780
[05:07:45.794] iteration 14954: loss: 0.039657, loss_s1: 0.014410, loss_fp: 0.001462, loss_freq: 0.024730
[05:07:46.528] iteration 14955: loss: 0.054053, loss_s1: 0.053972, loss_fp: 0.001611, loss_freq: 0.014165
[05:07:47.182] iteration 14956: loss: 0.096656, loss_s1: 0.121716, loss_fp: 0.004286, loss_freq: 0.041157
[05:07:47.809] iteration 14957: loss: 0.076685, loss_s1: 0.064755, loss_fp: 0.001267, loss_freq: 0.033454
[05:07:48.435] iteration 14958: loss: 0.073186, loss_s1: 0.058368, loss_fp: 0.009899, loss_freq: 0.040252
[05:07:49.056] iteration 14959: loss: 0.076286, loss_s1: 0.064124, loss_fp: 0.008306, loss_freq: 0.036701
[05:07:49.685] iteration 14960: loss: 0.071050, loss_s1: 0.046911, loss_fp: 0.006787, loss_freq: 0.052133
[05:07:50.744] iteration 14961: loss: 0.068482, loss_s1: 0.041331, loss_fp: 0.009249, loss_freq: 0.031054
[05:07:51.377] iteration 14962: loss: 0.083829, loss_s1: 0.055117, loss_fp: 0.005145, loss_freq: 0.053776
[05:07:52.009] iteration 14963: loss: 0.063363, loss_s1: 0.045831, loss_fp: 0.004628, loss_freq: 0.026696
[05:07:52.629] iteration 14964: loss: 0.053165, loss_s1: 0.051925, loss_fp: 0.001641, loss_freq: 0.014226
[05:07:53.291] iteration 14965: loss: 0.059264, loss_s1: 0.051061, loss_fp: 0.002260, loss_freq: 0.032101
[05:07:53.914] iteration 14966: loss: 0.069078, loss_s1: 0.053848, loss_fp: 0.002432, loss_freq: 0.021885
[05:07:54.536] iteration 14967: loss: 0.071059, loss_s1: 0.047384, loss_fp: 0.003313, loss_freq: 0.036501
[05:07:55.159] iteration 14968: loss: 0.088482, loss_s1: 0.082000, loss_fp: 0.019794, loss_freq: 0.038815
[05:07:55.809] iteration 14969: loss: 0.082956, loss_s1: 0.059055, loss_fp: 0.006228, loss_freq: 0.038241
[05:07:56.469] iteration 14970: loss: 0.068338, loss_s1: 0.055486, loss_fp: 0.001358, loss_freq: 0.032318
[05:07:57.114] iteration 14971: loss: 0.072462, loss_s1: 0.054697, loss_fp: 0.005715, loss_freq: 0.040468
[05:07:57.737] iteration 14972: loss: 0.088470, loss_s1: 0.063558, loss_fp: 0.004789, loss_freq: 0.049582
[05:07:58.453] iteration 14973: loss: 0.088477, loss_s1: 0.069732, loss_fp: 0.004765, loss_freq: 0.043997
[05:07:59.096] iteration 14974: loss: 0.089346, loss_s1: 0.072201, loss_fp: 0.006920, loss_freq: 0.059703
[05:07:59.730] iteration 14975: loss: 0.098244, loss_s1: 0.078475, loss_fp: 0.001708, loss_freq: 0.048852
[05:08:00.355] iteration 14976: loss: 0.056989, loss_s1: 0.052258, loss_fp: 0.002543, loss_freq: 0.019562
[05:08:00.978] iteration 14977: loss: 0.093398, loss_s1: 0.068888, loss_fp: 0.016754, loss_freq: 0.078508
[05:08:01.627] iteration 14978: loss: 0.042797, loss_s1: 0.024063, loss_fp: 0.003776, loss_freq: 0.020695
[05:08:02.280] iteration 14979: loss: 0.085844, loss_s1: 0.072436, loss_fp: 0.027364, loss_freq: 0.030516
[05:08:02.905] iteration 14980: loss: 0.068811, loss_s1: 0.051854, loss_fp: 0.002221, loss_freq: 0.013080
[05:08:03.524] iteration 14981: loss: 0.069220, loss_s1: 0.069698, loss_fp: 0.006468, loss_freq: 0.022871
[05:08:04.172] iteration 14982: loss: 0.084456, loss_s1: 0.093301, loss_fp: 0.003395, loss_freq: 0.037000
[05:08:04.792] iteration 14983: loss: 0.058670, loss_s1: 0.029098, loss_fp: 0.000548, loss_freq: 0.025702
[05:08:05.420] iteration 14984: loss: 0.086147, loss_s1: 0.087801, loss_fp: 0.007423, loss_freq: 0.037084
[05:08:06.044] iteration 14985: loss: 0.060785, loss_s1: 0.042316, loss_fp: 0.005499, loss_freq: 0.037804
[05:08:06.678] iteration 14986: loss: 0.079984, loss_s1: 0.078527, loss_fp: 0.004503, loss_freq: 0.033733
[05:08:07.331] iteration 14987: loss: 0.068476, loss_s1: 0.059548, loss_fp: 0.001451, loss_freq: 0.035589
[05:08:07.981] iteration 14988: loss: 0.097940, loss_s1: 0.095924, loss_fp: 0.008442, loss_freq: 0.037761
[05:08:08.598] iteration 14989: loss: 0.049176, loss_s1: 0.018323, loss_fp: 0.004160, loss_freq: 0.018283
[05:08:09.231] iteration 14990: loss: 0.084963, loss_s1: 0.083700, loss_fp: 0.004638, loss_freq: 0.038764
[05:08:09.903] iteration 14991: loss: 0.074294, loss_s1: 0.069917, loss_fp: 0.002497, loss_freq: 0.034130
[05:08:10.579] iteration 14992: loss: 0.116961, loss_s1: 0.117071, loss_fp: 0.009716, loss_freq: 0.050631
[05:08:11.268] iteration 14993: loss: 0.071307, loss_s1: 0.065486, loss_fp: 0.005272, loss_freq: 0.040228
[05:08:11.940] iteration 14994: loss: 0.080138, loss_s1: 0.042825, loss_fp: 0.003537, loss_freq: 0.026519
[05:08:12.579] iteration 14995: loss: 0.046597, loss_s1: 0.023183, loss_fp: 0.002398, loss_freq: 0.044718
[05:08:13.210] iteration 14996: loss: 0.043930, loss_s1: 0.022234, loss_fp: 0.002002, loss_freq: 0.024550
[05:08:13.861] iteration 14997: loss: 0.085121, loss_s1: 0.082047, loss_fp: 0.002502, loss_freq: 0.041255
[05:08:14.483] iteration 14998: loss: 0.065249, loss_s1: 0.046304, loss_fp: 0.003618, loss_freq: 0.026545
[05:08:15.115] iteration 14999: loss: 0.128749, loss_s1: 0.142719, loss_fp: 0.002628, loss_freq: 0.068489
[05:08:15.754] iteration 15000: loss: 0.083034, loss_s1: 0.092828, loss_fp: 0.009646, loss_freq: 0.033346
[05:08:19.145] iteration 15000 : mean_dice : 0.726352
[05:08:19.825] iteration 15001: loss: 0.080453, loss_s1: 0.068720, loss_fp: 0.001193, loss_freq: 0.041951
[05:08:20.481] iteration 15002: loss: 0.069590, loss_s1: 0.051429, loss_fp: 0.008230, loss_freq: 0.035255
[05:08:21.130] iteration 15003: loss: 0.117533, loss_s1: 0.149712, loss_fp: 0.003312, loss_freq: 0.050876
[05:08:21.782] iteration 15004: loss: 0.086024, loss_s1: 0.059889, loss_fp: 0.014553, loss_freq: 0.050772
[05:08:22.429] iteration 15005: loss: 0.087531, loss_s1: 0.059975, loss_fp: 0.001332, loss_freq: 0.057643
[05:08:23.072] iteration 15006: loss: 0.067225, loss_s1: 0.059126, loss_fp: 0.004041, loss_freq: 0.020628
[05:08:23.711] iteration 15007: loss: 0.057535, loss_s1: 0.043518, loss_fp: 0.004216, loss_freq: 0.024863
[05:08:24.329] iteration 15008: loss: 0.058164, loss_s1: 0.053176, loss_fp: 0.000917, loss_freq: 0.030860
[05:08:24.973] iteration 15009: loss: 0.046287, loss_s1: 0.036632, loss_fp: 0.002255, loss_freq: 0.022143
[05:08:25.615] iteration 15010: loss: 0.047499, loss_s1: 0.028887, loss_fp: 0.002044, loss_freq: 0.017618
[05:08:26.248] iteration 15011: loss: 0.063269, loss_s1: 0.041805, loss_fp: 0.005693, loss_freq: 0.035603
[05:08:26.892] iteration 15012: loss: 0.059534, loss_s1: 0.063857, loss_fp: 0.001998, loss_freq: 0.024649
[05:08:27.523] iteration 15013: loss: 0.065696, loss_s1: 0.031840, loss_fp: 0.001797, loss_freq: 0.037999
[05:08:28.155] iteration 15014: loss: 0.083562, loss_s1: 0.073074, loss_fp: 0.002865, loss_freq: 0.055421
[05:08:28.875] iteration 15015: loss: 0.063797, loss_s1: 0.036148, loss_fp: 0.001736, loss_freq: 0.038330
[05:08:29.524] iteration 15016: loss: 0.047462, loss_s1: 0.027598, loss_fp: 0.000586, loss_freq: 0.018188
[05:08:30.195] iteration 15017: loss: 0.087585, loss_s1: 0.074880, loss_fp: 0.012372, loss_freq: 0.046528
[05:08:30.841] iteration 15018: loss: 0.065611, loss_s1: 0.046324, loss_fp: 0.006927, loss_freq: 0.033162
[05:08:31.483] iteration 15019: loss: 0.044164, loss_s1: 0.016078, loss_fp: 0.002539, loss_freq: 0.038919
[05:08:32.127] iteration 15020: loss: 0.089642, loss_s1: 0.093409, loss_fp: 0.000910, loss_freq: 0.039978
[05:08:32.753] iteration 15021: loss: 0.029535, loss_s1: 0.007923, loss_fp: 0.008552, loss_freq: 0.012588
[05:08:33.402] iteration 15022: loss: 0.079756, loss_s1: 0.051743, loss_fp: 0.001471, loss_freq: 0.038801
[05:08:34.042] iteration 15023: loss: 0.033872, loss_s1: 0.016784, loss_fp: 0.002158, loss_freq: 0.007193
[05:08:34.692] iteration 15024: loss: 0.053335, loss_s1: 0.059917, loss_fp: 0.001331, loss_freq: 0.011983
[05:08:35.344] iteration 15025: loss: 0.102189, loss_s1: 0.144255, loss_fp: 0.002834, loss_freq: 0.016312
[05:08:35.979] iteration 15026: loss: 0.053041, loss_s1: 0.049896, loss_fp: 0.002354, loss_freq: 0.023743
[05:08:36.609] iteration 15027: loss: 0.043604, loss_s1: 0.017522, loss_fp: 0.005065, loss_freq: 0.010888
[05:08:37.244] iteration 15028: loss: 0.071270, loss_s1: 0.062439, loss_fp: 0.003548, loss_freq: 0.036791
[05:08:37.884] iteration 15029: loss: 0.056919, loss_s1: 0.027485, loss_fp: 0.007795, loss_freq: 0.039675
[05:08:38.516] iteration 15030: loss: 0.044238, loss_s1: 0.025446, loss_fp: 0.006818, loss_freq: 0.021041
[05:08:39.167] iteration 15031: loss: 0.074898, loss_s1: 0.043720, loss_fp: 0.003113, loss_freq: 0.021085
[05:08:39.796] iteration 15032: loss: 0.045079, loss_s1: 0.021702, loss_fp: 0.004526, loss_freq: 0.012712
[05:08:40.430] iteration 15033: loss: 0.053258, loss_s1: 0.036899, loss_fp: 0.003890, loss_freq: 0.031360
[05:08:41.067] iteration 15034: loss: 0.073298, loss_s1: 0.078202, loss_fp: 0.005168, loss_freq: 0.022432
[05:08:41.707] iteration 15035: loss: 0.057660, loss_s1: 0.036498, loss_fp: 0.004398, loss_freq: 0.045642
[05:08:42.336] iteration 15036: loss: 0.081274, loss_s1: 0.059651, loss_fp: 0.003233, loss_freq: 0.056259
[05:08:43.020] iteration 15037: loss: 0.065445, loss_s1: 0.051543, loss_fp: 0.005602, loss_freq: 0.034995
[05:08:43.685] iteration 15038: loss: 0.075564, loss_s1: 0.056623, loss_fp: 0.009071, loss_freq: 0.047048
[05:08:44.332] iteration 15039: loss: 0.077923, loss_s1: 0.066405, loss_fp: 0.004905, loss_freq: 0.044658
[05:08:44.968] iteration 15040: loss: 0.091867, loss_s1: 0.069993, loss_fp: 0.003079, loss_freq: 0.030789
[05:08:45.599] iteration 15041: loss: 0.112033, loss_s1: 0.135697, loss_fp: 0.013061, loss_freq: 0.018634
[05:08:46.229] iteration 15042: loss: 0.069465, loss_s1: 0.073909, loss_fp: 0.005762, loss_freq: 0.022992
[05:08:46.871] iteration 15043: loss: 0.088711, loss_s1: 0.097151, loss_fp: 0.006109, loss_freq: 0.028392
[05:08:47.519] iteration 15044: loss: 0.074561, loss_s1: 0.083008, loss_fp: 0.001603, loss_freq: 0.027081
[05:08:48.150] iteration 15045: loss: 0.073235, loss_s1: 0.074529, loss_fp: 0.003719, loss_freq: 0.017569
[05:08:48.785] iteration 15046: loss: 0.056479, loss_s1: 0.037419, loss_fp: 0.001384, loss_freq: 0.037358
[05:08:49.447] iteration 15047: loss: 0.081908, loss_s1: 0.115877, loss_fp: 0.006502, loss_freq: 0.014800
[05:08:50.084] iteration 15048: loss: 0.068425, loss_s1: 0.059871, loss_fp: 0.003418, loss_freq: 0.042714
[05:08:50.724] iteration 15049: loss: 0.049678, loss_s1: 0.040182, loss_fp: 0.006384, loss_freq: 0.018266
[05:08:51.354] iteration 15050: loss: 0.065250, loss_s1: 0.046921, loss_fp: 0.016055, loss_freq: 0.019353
[05:08:51.984] iteration 15051: loss: 0.067635, loss_s1: 0.068658, loss_fp: 0.006998, loss_freq: 0.020051
[05:08:52.615] iteration 15052: loss: 0.084764, loss_s1: 0.088113, loss_fp: 0.000570, loss_freq: 0.046703
[05:08:53.258] iteration 15053: loss: 0.100773, loss_s1: 0.108690, loss_fp: 0.003558, loss_freq: 0.042443
[05:08:53.914] iteration 15054: loss: 0.043606, loss_s1: 0.026910, loss_fp: 0.000880, loss_freq: 0.029300
[05:08:54.558] iteration 15055: loss: 0.067597, loss_s1: 0.056153, loss_fp: 0.003017, loss_freq: 0.035179
[05:08:55.232] iteration 15056: loss: 0.064596, loss_s1: 0.059190, loss_fp: 0.000944, loss_freq: 0.038265
[05:08:55.876] iteration 15057: loss: 0.100270, loss_s1: 0.066689, loss_fp: 0.001561, loss_freq: 0.092712
[05:08:56.518] iteration 15058: loss: 0.058307, loss_s1: 0.050496, loss_fp: 0.000673, loss_freq: 0.024341
[05:08:57.157] iteration 15059: loss: 0.055820, loss_s1: 0.038050, loss_fp: 0.004548, loss_freq: 0.035021
[05:08:57.785] iteration 15060: loss: 0.067710, loss_s1: 0.053923, loss_fp: 0.002034, loss_freq: 0.032792
[05:08:58.412] iteration 15061: loss: 0.046527, loss_s1: 0.039574, loss_fp: 0.001435, loss_freq: 0.011848
[05:08:59.061] iteration 15062: loss: 0.046536, loss_s1: 0.026438, loss_fp: 0.002759, loss_freq: 0.009151
[05:08:59.723] iteration 15063: loss: 0.039752, loss_s1: 0.016284, loss_fp: 0.001335, loss_freq: 0.028895
[05:09:00.351] iteration 15064: loss: 0.034426, loss_s1: 0.013281, loss_fp: 0.000771, loss_freq: 0.021965
[05:09:00.978] iteration 15065: loss: 0.032021, loss_s1: 0.023560, loss_fp: 0.001754, loss_freq: 0.011213
[05:09:01.619] iteration 15066: loss: 0.074986, loss_s1: 0.065954, loss_fp: 0.003134, loss_freq: 0.036073
[05:09:02.249] iteration 15067: loss: 0.076762, loss_s1: 0.070761, loss_fp: 0.011405, loss_freq: 0.027775
[05:09:02.894] iteration 15068: loss: 0.062752, loss_s1: 0.047091, loss_fp: 0.004448, loss_freq: 0.038473
[05:09:03.525] iteration 15069: loss: 0.090792, loss_s1: 0.082474, loss_fp: 0.006241, loss_freq: 0.056288
[05:09:04.164] iteration 15070: loss: 0.049265, loss_s1: 0.026517, loss_fp: 0.003409, loss_freq: 0.037594
[05:09:04.795] iteration 15071: loss: 0.049418, loss_s1: 0.032776, loss_fp: 0.003476, loss_freq: 0.022297
[05:09:05.433] iteration 15072: loss: 0.060050, loss_s1: 0.046010, loss_fp: 0.004207, loss_freq: 0.022540
[05:09:06.059] iteration 15073: loss: 0.054979, loss_s1: 0.038911, loss_fp: 0.005045, loss_freq: 0.023218
[05:09:06.681] iteration 15074: loss: 0.037302, loss_s1: 0.027531, loss_fp: 0.005945, loss_freq: 0.015003
[05:09:07.308] iteration 15075: loss: 0.100434, loss_s1: 0.066341, loss_fp: 0.003308, loss_freq: 0.078218
[05:09:07.943] iteration 15076: loss: 0.077788, loss_s1: 0.053146, loss_fp: 0.002924, loss_freq: 0.053699
[05:09:08.569] iteration 15077: loss: 0.050742, loss_s1: 0.035946, loss_fp: 0.001788, loss_freq: 0.028907
[05:09:09.198] iteration 15078: loss: 0.047696, loss_s1: 0.051675, loss_fp: 0.002225, loss_freq: 0.008502
[05:09:09.842] iteration 15079: loss: 0.088608, loss_s1: 0.042940, loss_fp: 0.003094, loss_freq: 0.085910
[05:09:10.478] iteration 15080: loss: 0.038286, loss_s1: 0.029008, loss_fp: 0.002480, loss_freq: 0.005284
[05:09:11.114] iteration 15081: loss: 0.056603, loss_s1: 0.049909, loss_fp: 0.009822, loss_freq: 0.013608
[05:09:11.746] iteration 15082: loss: 0.069428, loss_s1: 0.041748, loss_fp: 0.005991, loss_freq: 0.057136
[05:09:12.391] iteration 15083: loss: 0.086355, loss_s1: 0.063700, loss_fp: 0.007233, loss_freq: 0.061373
[05:09:13.081] iteration 15084: loss: 0.042701, loss_s1: 0.033873, loss_fp: 0.002056, loss_freq: 0.018495
[05:09:13.773] iteration 15085: loss: 0.076076, loss_s1: 0.047300, loss_fp: 0.009298, loss_freq: 0.057196
[05:09:14.445] iteration 15086: loss: 0.073106, loss_s1: 0.081711, loss_fp: 0.007421, loss_freq: 0.025399
[05:09:15.130] iteration 15087: loss: 0.074517, loss_s1: 0.030093, loss_fp: 0.020020, loss_freq: 0.054522
[05:09:15.816] iteration 15088: loss: 0.042881, loss_s1: 0.025906, loss_fp: 0.003908, loss_freq: 0.014547
[05:09:16.495] iteration 15089: loss: 0.066838, loss_s1: 0.057937, loss_fp: 0.006776, loss_freq: 0.026152
[05:09:17.138] iteration 15090: loss: 0.065631, loss_s1: 0.054825, loss_fp: 0.004064, loss_freq: 0.033185
[05:09:17.781] iteration 15091: loss: 0.066352, loss_s1: 0.078362, loss_fp: 0.004738, loss_freq: 0.022412
[05:09:18.426] iteration 15092: loss: 0.060807, loss_s1: 0.045635, loss_fp: 0.001852, loss_freq: 0.015777
[05:09:19.058] iteration 15093: loss: 0.102785, loss_s1: 0.098780, loss_fp: 0.003166, loss_freq: 0.060814
[05:09:19.681] iteration 15094: loss: 0.058654, loss_s1: 0.039141, loss_fp: 0.004306, loss_freq: 0.035692
[05:09:20.339] iteration 15095: loss: 0.074513, loss_s1: 0.078514, loss_fp: 0.002683, loss_freq: 0.026334
[05:09:20.984] iteration 15096: loss: 0.027306, loss_s1: 0.011902, loss_fp: 0.001452, loss_freq: 0.007268
[05:09:21.614] iteration 15097: loss: 0.067124, loss_s1: 0.049985, loss_fp: 0.003384, loss_freq: 0.031593
[05:09:22.241] iteration 15098: loss: 0.064233, loss_s1: 0.050399, loss_fp: 0.001619, loss_freq: 0.039190
[05:09:22.873] iteration 15099: loss: 0.115506, loss_s1: 0.132092, loss_fp: 0.003794, loss_freq: 0.046374
[05:09:23.517] iteration 15100: loss: 0.060416, loss_s1: 0.046079, loss_fp: 0.004570, loss_freq: 0.044390
[05:09:24.141] iteration 15101: loss: 0.079331, loss_s1: 0.077154, loss_fp: 0.003613, loss_freq: 0.040374
[05:09:24.782] iteration 15102: loss: 0.057060, loss_s1: 0.036873, loss_fp: 0.004609, loss_freq: 0.024275
[05:09:25.425] iteration 15103: loss: 0.063626, loss_s1: 0.034823, loss_fp: 0.004305, loss_freq: 0.044872
[05:09:26.055] iteration 15104: loss: 0.069699, loss_s1: 0.067683, loss_fp: 0.002723, loss_freq: 0.028746
[05:09:26.691] iteration 15105: loss: 0.028734, loss_s1: 0.014997, loss_fp: 0.000881, loss_freq: 0.006820
[05:09:27.282] iteration 15106: loss: 0.073824, loss_s1: 0.061850, loss_fp: 0.001747, loss_freq: 0.039305
[05:09:27.881] iteration 15107: loss: 0.070767, loss_s1: 0.065482, loss_fp: 0.004936, loss_freq: 0.033105
[05:09:28.490] iteration 15108: loss: 0.089534, loss_s1: 0.095107, loss_fp: 0.005387, loss_freq: 0.037882
[05:09:29.132] iteration 15109: loss: 0.115129, loss_s1: 0.103633, loss_fp: 0.005187, loss_freq: 0.093124
[05:09:29.850] iteration 15110: loss: 0.069991, loss_s1: 0.041954, loss_fp: 0.004002, loss_freq: 0.040734
[05:09:30.539] iteration 15111: loss: 0.076954, loss_s1: 0.063996, loss_fp: 0.009308, loss_freq: 0.042964
[05:09:31.237] iteration 15112: loss: 0.071101, loss_s1: 0.059746, loss_fp: 0.007933, loss_freq: 0.040233
[05:09:31.915] iteration 15113: loss: 0.117471, loss_s1: 0.084010, loss_fp: 0.010383, loss_freq: 0.052009
[05:09:32.629] iteration 15114: loss: 0.068971, loss_s1: 0.071245, loss_fp: 0.003861, loss_freq: 0.029185
[05:09:33.321] iteration 15115: loss: 0.069478, loss_s1: 0.053634, loss_fp: 0.004043, loss_freq: 0.030279
[05:09:33.991] iteration 15116: loss: 0.037206, loss_s1: 0.008403, loss_fp: 0.002910, loss_freq: 0.026223
[05:09:34.675] iteration 15117: loss: 0.055590, loss_s1: 0.053773, loss_fp: 0.007426, loss_freq: 0.022057
[05:09:35.368] iteration 15118: loss: 0.086995, loss_s1: 0.037018, loss_fp: 0.002814, loss_freq: 0.086056
[05:09:35.992] iteration 15119: loss: 0.034417, loss_s1: 0.015735, loss_fp: 0.005717, loss_freq: 0.014826
[05:09:36.618] iteration 15120: loss: 0.071509, loss_s1: 0.062072, loss_fp: 0.003071, loss_freq: 0.043927
[05:09:37.299] iteration 15121: loss: 0.043016, loss_s1: 0.027831, loss_fp: 0.002386, loss_freq: 0.015487
[05:09:38.019] iteration 15122: loss: 0.059656, loss_s1: 0.059138, loss_fp: 0.005342, loss_freq: 0.026520
[05:09:38.708] iteration 15123: loss: 0.039428, loss_s1: 0.013706, loss_fp: 0.005486, loss_freq: 0.013567
[05:09:39.403] iteration 15124: loss: 0.069278, loss_s1: 0.058609, loss_fp: 0.001767, loss_freq: 0.029222
[05:09:40.086] iteration 15125: loss: 0.033487, loss_s1: 0.014522, loss_fp: 0.002121, loss_freq: 0.020103
[05:09:40.735] iteration 15126: loss: 0.054518, loss_s1: 0.031250, loss_fp: 0.002950, loss_freq: 0.044462
[05:09:41.380] iteration 15127: loss: 0.088590, loss_s1: 0.027516, loss_fp: 0.001300, loss_freq: 0.057738
[05:09:42.017] iteration 15128: loss: 0.118808, loss_s1: 0.109379, loss_fp: 0.004980, loss_freq: 0.077853
[05:09:42.655] iteration 15129: loss: 0.076241, loss_s1: 0.055468, loss_fp: 0.002683, loss_freq: 0.058308
[05:09:43.285] iteration 15130: loss: 0.065407, loss_s1: 0.055220, loss_fp: 0.003709, loss_freq: 0.028252
[05:09:44.315] iteration 15131: loss: 0.087427, loss_s1: 0.098455, loss_fp: 0.004054, loss_freq: 0.034136
[05:09:45.003] iteration 15132: loss: 0.063090, loss_s1: 0.046465, loss_fp: 0.003121, loss_freq: 0.031643
[05:09:45.682] iteration 15133: loss: 0.060092, loss_s1: 0.050574, loss_fp: 0.006844, loss_freq: 0.028288
[05:09:46.352] iteration 15134: loss: 0.043278, loss_s1: 0.018046, loss_fp: 0.004091, loss_freq: 0.029343
[05:09:47.045] iteration 15135: loss: 0.061571, loss_s1: 0.055593, loss_fp: 0.008710, loss_freq: 0.024620
[05:09:47.740] iteration 15136: loss: 0.059192, loss_s1: 0.038736, loss_fp: 0.005611, loss_freq: 0.031146
[05:09:48.377] iteration 15137: loss: 0.061575, loss_s1: 0.063550, loss_fp: 0.004465, loss_freq: 0.020625
[05:09:49.000] iteration 15138: loss: 0.050411, loss_s1: 0.028122, loss_fp: 0.004972, loss_freq: 0.026064
[05:09:49.646] iteration 15139: loss: 0.040412, loss_s1: 0.029369, loss_fp: 0.003743, loss_freq: 0.018190
[05:09:50.639] iteration 15140: loss: 0.057831, loss_s1: 0.032297, loss_fp: 0.004514, loss_freq: 0.039319
[05:09:51.644] iteration 15141: loss: 0.085584, loss_s1: 0.068128, loss_fp: 0.008374, loss_freq: 0.024495
[05:09:52.298] iteration 15142: loss: 0.100492, loss_s1: 0.087507, loss_fp: 0.003092, loss_freq: 0.072811
[05:09:52.928] iteration 15143: loss: 0.057277, loss_s1: 0.036241, loss_fp: 0.002276, loss_freq: 0.019214
[05:09:53.546] iteration 15144: loss: 0.043355, loss_s1: 0.031357, loss_fp: 0.003390, loss_freq: 0.015961
[05:09:54.165] iteration 15145: loss: 0.069190, loss_s1: 0.040813, loss_fp: 0.001699, loss_freq: 0.036162
[05:09:54.780] iteration 15146: loss: 0.043760, loss_s1: 0.034886, loss_fp: 0.001357, loss_freq: 0.016354
[05:09:55.400] iteration 15147: loss: 0.088676, loss_s1: 0.087972, loss_fp: 0.005925, loss_freq: 0.059781
[05:09:56.033] iteration 15148: loss: 0.042742, loss_s1: 0.029173, loss_fp: 0.000789, loss_freq: 0.010790
[05:09:56.657] iteration 15149: loss: 0.071109, loss_s1: 0.034832, loss_fp: 0.011475, loss_freq: 0.061541
[05:09:57.311] iteration 15150: loss: 0.068867, loss_s1: 0.064566, loss_fp: 0.005174, loss_freq: 0.017467
[05:09:57.934] iteration 15151: loss: 0.069547, loss_s1: 0.050877, loss_fp: 0.001933, loss_freq: 0.023550
[05:09:58.571] iteration 15152: loss: 0.045038, loss_s1: 0.028638, loss_fp: 0.002502, loss_freq: 0.037553
[05:09:59.219] iteration 15153: loss: 0.069781, loss_s1: 0.040727, loss_fp: 0.001335, loss_freq: 0.039040
[05:09:59.846] iteration 15154: loss: 0.046647, loss_s1: 0.035611, loss_fp: 0.004488, loss_freq: 0.013247
[05:10:00.476] iteration 15155: loss: 0.082839, loss_s1: 0.046236, loss_fp: 0.008927, loss_freq: 0.041872
[05:10:01.102] iteration 15156: loss: 0.088496, loss_s1: 0.093917, loss_fp: 0.005652, loss_freq: 0.049675
[05:10:01.738] iteration 15157: loss: 0.062556, loss_s1: 0.039711, loss_fp: 0.003972, loss_freq: 0.033491
[05:10:02.360] iteration 15158: loss: 0.128977, loss_s1: 0.153454, loss_fp: 0.004607, loss_freq: 0.018258
[05:10:03.023] iteration 15159: loss: 0.067322, loss_s1: 0.020511, loss_fp: 0.006679, loss_freq: 0.021118
[05:10:03.652] iteration 15160: loss: 0.069661, loss_s1: 0.061441, loss_fp: 0.001763, loss_freq: 0.035701
[05:10:04.277] iteration 15161: loss: 0.072644, loss_s1: 0.073031, loss_fp: 0.006053, loss_freq: 0.036713
[05:10:05.010] iteration 15162: loss: 0.084759, loss_s1: 0.046919, loss_fp: 0.004604, loss_freq: 0.074693
[05:10:05.699] iteration 15163: loss: 0.058007, loss_s1: 0.053937, loss_fp: 0.003331, loss_freq: 0.027224
[05:10:06.379] iteration 15164: loss: 0.043217, loss_s1: 0.026821, loss_fp: 0.006527, loss_freq: 0.011032
[05:10:07.068] iteration 15165: loss: 0.064327, loss_s1: 0.058589, loss_fp: 0.005743, loss_freq: 0.029389
[05:10:07.764] iteration 15166: loss: 0.054848, loss_s1: 0.045741, loss_fp: 0.003006, loss_freq: 0.014844
[05:10:08.475] iteration 15167: loss: 0.064455, loss_s1: 0.051533, loss_fp: 0.001936, loss_freq: 0.034377
[05:10:09.131] iteration 15168: loss: 0.047992, loss_s1: 0.041963, loss_fp: 0.002908, loss_freq: 0.015149
[05:10:09.764] iteration 15169: loss: 0.097367, loss_s1: 0.111738, loss_fp: 0.005078, loss_freq: 0.025568
[05:10:10.449] iteration 15170: loss: 0.058606, loss_s1: 0.054252, loss_fp: 0.003235, loss_freq: 0.030538
[05:10:11.152] iteration 15171: loss: 0.098046, loss_s1: 0.101187, loss_fp: 0.001107, loss_freq: 0.055066
[05:10:11.843] iteration 15172: loss: 0.079822, loss_s1: 0.091329, loss_fp: 0.003578, loss_freq: 0.023545
[05:10:12.504] iteration 15173: loss: 0.069721, loss_s1: 0.070117, loss_fp: 0.003017, loss_freq: 0.033899
[05:10:13.151] iteration 15174: loss: 0.115646, loss_s1: 0.123488, loss_fp: 0.011705, loss_freq: 0.066565
[05:10:13.798] iteration 15175: loss: 0.069271, loss_s1: 0.036166, loss_fp: 0.003467, loss_freq: 0.057139
[05:10:14.423] iteration 15176: loss: 0.056429, loss_s1: 0.044178, loss_fp: 0.009550, loss_freq: 0.021371
[05:10:15.046] iteration 15177: loss: 0.056434, loss_s1: 0.043572, loss_fp: 0.002280, loss_freq: 0.027715
[05:10:15.676] iteration 15178: loss: 0.086820, loss_s1: 0.095110, loss_fp: 0.001816, loss_freq: 0.029716
[05:10:16.328] iteration 15179: loss: 0.061505, loss_s1: 0.066428, loss_fp: 0.002515, loss_freq: 0.020645
[05:10:16.972] iteration 15180: loss: 0.063523, loss_s1: 0.048695, loss_fp: 0.003234, loss_freq: 0.021213
[05:10:17.603] iteration 15181: loss: 0.081783, loss_s1: 0.041663, loss_fp: 0.005226, loss_freq: 0.073005
[05:10:18.240] iteration 15182: loss: 0.096079, loss_s1: 0.089128, loss_fp: 0.002550, loss_freq: 0.068558
[05:10:18.879] iteration 15183: loss: 0.044279, loss_s1: 0.019945, loss_fp: 0.001055, loss_freq: 0.022517
[05:10:19.507] iteration 15184: loss: 0.066470, loss_s1: 0.062514, loss_fp: 0.003159, loss_freq: 0.027342
[05:10:20.133] iteration 15185: loss: 0.054332, loss_s1: 0.011319, loss_fp: 0.000949, loss_freq: 0.046803
[05:10:20.760] iteration 15186: loss: 0.052184, loss_s1: 0.029675, loss_fp: 0.002623, loss_freq: 0.021689
[05:10:21.389] iteration 15187: loss: 0.089407, loss_s1: 0.061163, loss_fp: 0.003649, loss_freq: 0.071733
[05:10:22.025] iteration 15188: loss: 0.059066, loss_s1: 0.057351, loss_fp: 0.002687, loss_freq: 0.015758
[05:10:22.676] iteration 15189: loss: 0.040843, loss_s1: 0.026855, loss_fp: 0.004060, loss_freq: 0.011983
[05:10:23.314] iteration 15190: loss: 0.055990, loss_s1: 0.030017, loss_fp: 0.001770, loss_freq: 0.044846
[05:10:23.957] iteration 15191: loss: 0.040654, loss_s1: 0.032837, loss_fp: 0.011284, loss_freq: 0.008431
[05:10:24.604] iteration 15192: loss: 0.066139, loss_s1: 0.048445, loss_fp: 0.001621, loss_freq: 0.035476
[05:10:25.233] iteration 15193: loss: 0.039561, loss_s1: 0.033197, loss_fp: 0.000828, loss_freq: 0.007171
[05:10:25.863] iteration 15194: loss: 0.038825, loss_s1: 0.022462, loss_fp: 0.001694, loss_freq: 0.022789
[05:10:26.513] iteration 15195: loss: 0.064804, loss_s1: 0.064942, loss_fp: 0.001807, loss_freq: 0.018852
[05:10:27.205] iteration 15196: loss: 0.085338, loss_s1: 0.087371, loss_fp: 0.002504, loss_freq: 0.054414
[05:10:27.843] iteration 15197: loss: 0.049667, loss_s1: 0.047186, loss_fp: 0.001446, loss_freq: 0.011377
[05:10:28.486] iteration 15198: loss: 0.092420, loss_s1: 0.081437, loss_fp: 0.005929, loss_freq: 0.055700
[05:10:29.141] iteration 15199: loss: 0.057753, loss_s1: 0.053502, loss_fp: 0.004218, loss_freq: 0.026041
[05:10:29.784] iteration 15200: loss: 0.058522, loss_s1: 0.064367, loss_fp: 0.002134, loss_freq: 0.024255
[05:10:33.127] iteration 15200 : mean_dice : 0.726068
[05:10:33.822] iteration 15201: loss: 0.092051, loss_s1: 0.053720, loss_fp: 0.007259, loss_freq: 0.049011
[05:10:34.515] iteration 15202: loss: 0.051448, loss_s1: 0.024814, loss_fp: 0.002936, loss_freq: 0.018663
[05:10:35.233] iteration 15203: loss: 0.045873, loss_s1: 0.024404, loss_fp: 0.004863, loss_freq: 0.026854
[05:10:35.885] iteration 15204: loss: 0.082047, loss_s1: 0.079692, loss_fp: 0.003923, loss_freq: 0.035441
[05:10:36.515] iteration 15205: loss: 0.070606, loss_s1: 0.043328, loss_fp: 0.001452, loss_freq: 0.054484
[05:10:37.185] iteration 15206: loss: 0.077245, loss_s1: 0.065188, loss_fp: 0.003222, loss_freq: 0.041597
[05:10:37.811] iteration 15207: loss: 0.064906, loss_s1: 0.072584, loss_fp: 0.004299, loss_freq: 0.015903
[05:10:38.452] iteration 15208: loss: 0.072809, loss_s1: 0.082236, loss_fp: 0.003800, loss_freq: 0.029697
[05:10:39.074] iteration 15209: loss: 0.078840, loss_s1: 0.084206, loss_fp: 0.002410, loss_freq: 0.040756
[05:10:39.701] iteration 15210: loss: 0.078002, loss_s1: 0.069230, loss_fp: 0.001263, loss_freq: 0.036801
[05:10:40.339] iteration 15211: loss: 0.082216, loss_s1: 0.086956, loss_fp: 0.004163, loss_freq: 0.031841
[05:10:40.988] iteration 15212: loss: 0.070067, loss_s1: 0.050955, loss_fp: 0.004096, loss_freq: 0.052788
[05:10:41.631] iteration 15213: loss: 0.060501, loss_s1: 0.045786, loss_fp: 0.001576, loss_freq: 0.030275
[05:10:42.283] iteration 15214: loss: 0.067706, loss_s1: 0.051949, loss_fp: 0.005373, loss_freq: 0.032516
[05:10:42.911] iteration 15215: loss: 0.051633, loss_s1: 0.014887, loss_fp: 0.003396, loss_freq: 0.047607
[05:10:43.540] iteration 15216: loss: 0.066374, loss_s1: 0.028801, loss_fp: 0.004349, loss_freq: 0.024102
[05:10:44.202] iteration 15217: loss: 0.077148, loss_s1: 0.086193, loss_fp: 0.002934, loss_freq: 0.038654
[05:10:44.911] iteration 15218: loss: 0.062401, loss_s1: 0.064219, loss_fp: 0.009478, loss_freq: 0.014019
[05:10:45.614] iteration 15219: loss: 0.084301, loss_s1: 0.040992, loss_fp: 0.029057, loss_freq: 0.067461
[05:10:46.307] iteration 15220: loss: 0.051196, loss_s1: 0.042229, loss_fp: 0.003176, loss_freq: 0.011691
[05:10:46.995] iteration 15221: loss: 0.109437, loss_s1: 0.132248, loss_fp: 0.002398, loss_freq: 0.031675
[05:10:47.671] iteration 15222: loss: 0.115999, loss_s1: 0.087564, loss_fp: 0.011633, loss_freq: 0.098445
[05:10:48.321] iteration 15223: loss: 0.090541, loss_s1: 0.051594, loss_fp: 0.009047, loss_freq: 0.068638
[05:10:48.946] iteration 15224: loss: 0.069252, loss_s1: 0.077396, loss_fp: 0.000876, loss_freq: 0.021354
[05:10:49.575] iteration 15225: loss: 0.079652, loss_s1: 0.060858, loss_fp: 0.003221, loss_freq: 0.033321
[05:10:50.205] iteration 15226: loss: 0.079042, loss_s1: 0.053839, loss_fp: 0.001726, loss_freq: 0.070905
[05:10:50.880] iteration 15227: loss: 0.074523, loss_s1: 0.066991, loss_fp: 0.001705, loss_freq: 0.034653
[05:10:51.555] iteration 15228: loss: 0.099227, loss_s1: 0.106098, loss_fp: 0.002524, loss_freq: 0.032414
[05:10:52.236] iteration 15229: loss: 0.065335, loss_s1: 0.059562, loss_fp: 0.000667, loss_freq: 0.030177
[05:10:52.936] iteration 15230: loss: 0.065276, loss_s1: 0.034372, loss_fp: 0.003652, loss_freq: 0.045353
[05:10:53.570] iteration 15231: loss: 0.068094, loss_s1: 0.082204, loss_fp: 0.006424, loss_freq: 0.020693
[05:10:54.214] iteration 15232: loss: 0.057502, loss_s1: 0.046254, loss_fp: 0.000993, loss_freq: 0.012892
[05:10:54.847] iteration 15233: loss: 0.037837, loss_s1: 0.016556, loss_fp: 0.001385, loss_freq: 0.023824
[05:10:55.501] iteration 15234: loss: 0.054665, loss_s1: 0.027161, loss_fp: 0.001656, loss_freq: 0.037531
[05:10:56.145] iteration 15235: loss: 0.030499, loss_s1: 0.015328, loss_fp: 0.001371, loss_freq: 0.011523
[05:10:56.777] iteration 15236: loss: 0.074003, loss_s1: 0.063503, loss_fp: 0.002804, loss_freq: 0.034823
[05:10:57.434] iteration 15237: loss: 0.079912, loss_s1: 0.074865, loss_fp: 0.004262, loss_freq: 0.042185
[05:10:58.065] iteration 15238: loss: 0.036439, loss_s1: 0.013430, loss_fp: 0.008718, loss_freq: 0.013245
[05:10:58.709] iteration 15239: loss: 0.093446, loss_s1: 0.030775, loss_fp: 0.008991, loss_freq: 0.104813
[05:10:59.340] iteration 15240: loss: 0.070231, loss_s1: 0.039700, loss_fp: 0.007580, loss_freq: 0.043644
[05:11:00.029] iteration 15241: loss: 0.062592, loss_s1: 0.061959, loss_fp: 0.005941, loss_freq: 0.015326
[05:11:00.760] iteration 15242: loss: 0.052267, loss_s1: 0.040938, loss_fp: 0.004334, loss_freq: 0.020450
[05:11:01.411] iteration 15243: loss: 0.074351, loss_s1: 0.071576, loss_fp: 0.007771, loss_freq: 0.034827
[05:11:02.085] iteration 15244: loss: 0.116874, loss_s1: 0.084627, loss_fp: 0.006092, loss_freq: 0.063264
[05:11:02.717] iteration 15245: loss: 0.109394, loss_s1: 0.082692, loss_fp: 0.006807, loss_freq: 0.044940
[05:11:03.351] iteration 15246: loss: 0.070802, loss_s1: 0.034149, loss_fp: 0.013362, loss_freq: 0.050219
[05:11:03.987] iteration 15247: loss: 0.061620, loss_s1: 0.035719, loss_fp: 0.009069, loss_freq: 0.038119
[05:11:04.619] iteration 15248: loss: 0.057341, loss_s1: 0.050440, loss_fp: 0.011119, loss_freq: 0.020015
[05:11:05.314] iteration 15249: loss: 0.108701, loss_s1: 0.078248, loss_fp: 0.004970, loss_freq: 0.095686
[05:11:06.004] iteration 15250: loss: 0.078909, loss_s1: 0.058404, loss_fp: 0.003763, loss_freq: 0.039257
[05:11:06.677] iteration 15251: loss: 0.045396, loss_s1: 0.025661, loss_fp: 0.001598, loss_freq: 0.017484
[05:11:07.316] iteration 15252: loss: 0.067448, loss_s1: 0.062230, loss_fp: 0.002591, loss_freq: 0.043185
[05:11:07.948] iteration 15253: loss: 0.088855, loss_s1: 0.094978, loss_fp: 0.004871, loss_freq: 0.038235
[05:11:08.627] iteration 15254: loss: 0.072698, loss_s1: 0.045406, loss_fp: 0.003520, loss_freq: 0.051455
[05:11:09.319] iteration 15255: loss: 0.096498, loss_s1: 0.071671, loss_fp: 0.002558, loss_freq: 0.058127
[05:11:10.008] iteration 15256: loss: 0.058152, loss_s1: 0.023105, loss_fp: 0.001397, loss_freq: 0.027490
[05:11:10.694] iteration 15257: loss: 0.099925, loss_s1: 0.063094, loss_fp: 0.003587, loss_freq: 0.101880
[05:11:11.388] iteration 15258: loss: 0.086849, loss_s1: 0.061846, loss_fp: 0.009725, loss_freq: 0.045556
[05:11:12.070] iteration 15259: loss: 0.066301, loss_s1: 0.036593, loss_fp: 0.004520, loss_freq: 0.041829
[05:11:12.757] iteration 15260: loss: 0.099648, loss_s1: 0.092682, loss_fp: 0.004416, loss_freq: 0.033299
[05:11:13.447] iteration 15261: loss: 0.044041, loss_s1: 0.037692, loss_fp: 0.005001, loss_freq: 0.010509
[05:11:14.080] iteration 15262: loss: 0.114897, loss_s1: 0.083567, loss_fp: 0.001458, loss_freq: 0.006444
[05:11:14.711] iteration 15263: loss: 0.081324, loss_s1: 0.045035, loss_fp: 0.025547, loss_freq: 0.036629
[05:11:15.364] iteration 15264: loss: 0.043859, loss_s1: 0.024711, loss_fp: 0.000921, loss_freq: 0.026624
[05:11:15.996] iteration 15265: loss: 0.043397, loss_s1: 0.013781, loss_fp: 0.003604, loss_freq: 0.026306
[05:11:16.656] iteration 15266: loss: 0.041995, loss_s1: 0.011160, loss_fp: 0.000374, loss_freq: 0.007614
[05:11:17.279] iteration 15267: loss: 0.085928, loss_s1: 0.047053, loss_fp: 0.003198, loss_freq: 0.016342
[05:11:17.902] iteration 15268: loss: 0.077009, loss_s1: 0.054560, loss_fp: 0.000992, loss_freq: 0.033830
[05:11:18.528] iteration 15269: loss: 0.098264, loss_s1: 0.097340, loss_fp: 0.009317, loss_freq: 0.048955
[05:11:19.205] iteration 15270: loss: 0.072812, loss_s1: 0.092496, loss_fp: 0.002588, loss_freq: 0.022628
[05:11:19.834] iteration 15271: loss: 0.080896, loss_s1: 0.079437, loss_fp: 0.004909, loss_freq: 0.027069
[05:11:20.459] iteration 15272: loss: 0.070732, loss_s1: 0.058940, loss_fp: 0.002773, loss_freq: 0.038843
[05:11:21.086] iteration 15273: loss: 0.071393, loss_s1: 0.053503, loss_fp: 0.004465, loss_freq: 0.034736
[05:11:21.712] iteration 15274: loss: 0.067034, loss_s1: 0.060674, loss_fp: 0.002507, loss_freq: 0.022233
[05:11:22.337] iteration 15275: loss: 0.060566, loss_s1: 0.062393, loss_fp: 0.003936, loss_freq: 0.019776
[05:11:22.976] iteration 15276: loss: 0.079658, loss_s1: 0.087230, loss_fp: 0.007540, loss_freq: 0.018670
[05:11:23.612] iteration 15277: loss: 0.076480, loss_s1: 0.050915, loss_fp: 0.004193, loss_freq: 0.060598
[05:11:24.253] iteration 15278: loss: 0.100644, loss_s1: 0.081774, loss_fp: 0.008981, loss_freq: 0.065801
[05:11:24.902] iteration 15279: loss: 0.062740, loss_s1: 0.043277, loss_fp: 0.002425, loss_freq: 0.051471
[05:11:25.577] iteration 15280: loss: 0.092720, loss_s1: 0.067181, loss_fp: 0.007764, loss_freq: 0.048305
[05:11:26.261] iteration 15281: loss: 0.070836, loss_s1: 0.060375, loss_fp: 0.003025, loss_freq: 0.033649
[05:11:26.942] iteration 15282: loss: 0.077411, loss_s1: 0.064695, loss_fp: 0.008999, loss_freq: 0.043314
[05:11:27.615] iteration 15283: loss: 0.078415, loss_s1: 0.074384, loss_fp: 0.003509, loss_freq: 0.035033
[05:11:28.286] iteration 15284: loss: 0.070522, loss_s1: 0.054827, loss_fp: 0.003232, loss_freq: 0.034793
[05:11:28.967] iteration 15285: loss: 0.093085, loss_s1: 0.085192, loss_fp: 0.003985, loss_freq: 0.052299
[05:11:29.609] iteration 15286: loss: 0.074768, loss_s1: 0.068722, loss_fp: 0.002965, loss_freq: 0.042373
[05:11:30.249] iteration 15287: loss: 0.052389, loss_s1: 0.020926, loss_fp: 0.002710, loss_freq: 0.053045
[05:11:30.887] iteration 15288: loss: 0.129602, loss_s1: 0.066111, loss_fp: 0.002901, loss_freq: 0.128927
[05:11:31.511] iteration 15289: loss: 0.072067, loss_s1: 0.056494, loss_fp: 0.003658, loss_freq: 0.049277
[05:11:32.147] iteration 15290: loss: 0.074493, loss_s1: 0.056227, loss_fp: 0.004290, loss_freq: 0.037768
[05:11:32.778] iteration 15291: loss: 0.053874, loss_s1: 0.062728, loss_fp: 0.001965, loss_freq: 0.003803
[05:11:33.405] iteration 15292: loss: 0.059794, loss_s1: 0.053334, loss_fp: 0.008141, loss_freq: 0.022107
[05:11:34.032] iteration 15293: loss: 0.055913, loss_s1: 0.038818, loss_fp: 0.001962, loss_freq: 0.013841
[05:11:34.670] iteration 15294: loss: 0.042218, loss_s1: 0.017516, loss_fp: 0.002620, loss_freq: 0.030321
[05:11:35.293] iteration 15295: loss: 0.041665, loss_s1: 0.023501, loss_fp: 0.000565, loss_freq: 0.009727
[05:11:35.935] iteration 15296: loss: 0.056836, loss_s1: 0.049846, loss_fp: 0.001405, loss_freq: 0.022402
[05:11:36.581] iteration 15297: loss: 0.052543, loss_s1: 0.032080, loss_fp: 0.002251, loss_freq: 0.020189
[05:11:37.226] iteration 15298: loss: 0.080259, loss_s1: 0.063917, loss_fp: 0.001223, loss_freq: 0.050355
[05:11:37.845] iteration 15299: loss: 0.098568, loss_s1: 0.094698, loss_fp: 0.004893, loss_freq: 0.068031
[05:11:38.470] iteration 15300: loss: 0.070741, loss_s1: 0.041558, loss_fp: 0.009335, loss_freq: 0.053160
[05:11:39.434] iteration 15301: loss: 0.070149, loss_s1: 0.062825, loss_fp: 0.004701, loss_freq: 0.029414
[05:11:40.061] iteration 15302: loss: 0.091031, loss_s1: 0.096334, loss_fp: 0.006525, loss_freq: 0.037169
[05:11:40.684] iteration 15303: loss: 0.062153, loss_s1: 0.057215, loss_fp: 0.008317, loss_freq: 0.027814
[05:11:41.310] iteration 15304: loss: 0.040040, loss_s1: 0.028745, loss_fp: 0.004285, loss_freq: 0.011275
[05:11:41.956] iteration 15305: loss: 0.068197, loss_s1: 0.048003, loss_fp: 0.004089, loss_freq: 0.037511
[05:11:42.617] iteration 15306: loss: 0.072129, loss_s1: 0.061950, loss_fp: 0.003368, loss_freq: 0.034417
[05:11:43.241] iteration 15307: loss: 0.075997, loss_s1: 0.049724, loss_fp: 0.006502, loss_freq: 0.039858
[05:11:43.872] iteration 15308: loss: 0.070424, loss_s1: 0.072874, loss_fp: 0.002240, loss_freq: 0.032703
[05:11:44.497] iteration 15309: loss: 0.052276, loss_s1: 0.033782, loss_fp: 0.002489, loss_freq: 0.041364
[05:11:45.120] iteration 15310: loss: 0.073464, loss_s1: 0.055405, loss_fp: 0.007592, loss_freq: 0.028926
[05:11:45.754] iteration 15311: loss: 0.078795, loss_s1: 0.047492, loss_fp: 0.001077, loss_freq: 0.061541
[05:11:46.381] iteration 15312: loss: 0.092392, loss_s1: 0.088894, loss_fp: 0.001908, loss_freq: 0.059280
[05:11:47.008] iteration 15313: loss: 0.071686, loss_s1: 0.053040, loss_fp: 0.002504, loss_freq: 0.042742
[05:11:47.654] iteration 15314: loss: 0.090033, loss_s1: 0.091082, loss_fp: 0.006677, loss_freq: 0.043977
[05:11:48.301] iteration 15315: loss: 0.047648, loss_s1: 0.044560, loss_fp: 0.001251, loss_freq: 0.011226
[05:11:49.005] iteration 15316: loss: 0.096457, loss_s1: 0.089771, loss_fp: 0.003899, loss_freq: 0.052234
[05:11:49.671] iteration 15317: loss: 0.083316, loss_s1: 0.063011, loss_fp: 0.006846, loss_freq: 0.069730
[05:11:50.303] iteration 15318: loss: 0.053244, loss_s1: 0.037686, loss_fp: 0.001091, loss_freq: 0.015270
[05:11:50.936] iteration 15319: loss: 0.074571, loss_s1: 0.055696, loss_fp: 0.005952, loss_freq: 0.051359
[05:11:51.583] iteration 15320: loss: 0.073974, loss_s1: 0.073923, loss_fp: 0.002241, loss_freq: 0.015292
[05:11:52.217] iteration 15321: loss: 0.051118, loss_s1: 0.027055, loss_fp: 0.005917, loss_freq: 0.010964
[05:11:52.834] iteration 15322: loss: 0.051159, loss_s1: 0.034900, loss_fp: 0.001644, loss_freq: 0.036561
[05:11:53.511] iteration 15323: loss: 0.065282, loss_s1: 0.055179, loss_fp: 0.001017, loss_freq: 0.026670
[05:11:54.227] iteration 15324: loss: 0.054206, loss_s1: 0.045643, loss_fp: 0.004508, loss_freq: 0.018294
[05:11:54.988] iteration 15325: loss: 0.078719, loss_s1: 0.068767, loss_fp: 0.003516, loss_freq: 0.049082
[05:11:55.647] iteration 15326: loss: 0.047458, loss_s1: 0.036989, loss_fp: 0.005803, loss_freq: 0.026247
[05:11:56.326] iteration 15327: loss: 0.057745, loss_s1: 0.051433, loss_fp: 0.001514, loss_freq: 0.008516
[05:11:56.974] iteration 15328: loss: 0.056232, loss_s1: 0.040566, loss_fp: 0.004812, loss_freq: 0.013976
[05:11:57.600] iteration 15329: loss: 0.043024, loss_s1: 0.030144, loss_fp: 0.002251, loss_freq: 0.019836
[05:11:58.230] iteration 15330: loss: 0.103447, loss_s1: 0.131673, loss_fp: 0.004240, loss_freq: 0.029745
[05:11:58.878] iteration 15331: loss: 0.055333, loss_s1: 0.023271, loss_fp: 0.009659, loss_freq: 0.041650
[05:11:59.513] iteration 15332: loss: 0.088292, loss_s1: 0.084999, loss_fp: 0.004702, loss_freq: 0.039406
[05:12:00.158] iteration 15333: loss: 0.108613, loss_s1: 0.080942, loss_fp: 0.013294, loss_freq: 0.059896
[05:12:00.794] iteration 15334: loss: 0.054833, loss_s1: 0.039533, loss_fp: 0.007131, loss_freq: 0.013057
[05:12:01.416] iteration 15335: loss: 0.050159, loss_s1: 0.049743, loss_fp: 0.002349, loss_freq: 0.024823
[05:12:02.039] iteration 15336: loss: 0.091390, loss_s1: 0.060409, loss_fp: 0.003032, loss_freq: 0.019075
[05:12:02.667] iteration 15337: loss: 0.071352, loss_s1: 0.059237, loss_fp: 0.001687, loss_freq: 0.044890
[05:12:03.290] iteration 15338: loss: 0.071937, loss_s1: 0.072970, loss_fp: 0.004792, loss_freq: 0.036579
[05:12:03.916] iteration 15339: loss: 0.102398, loss_s1: 0.110169, loss_fp: 0.006908, loss_freq: 0.051448
[05:12:04.563] iteration 15340: loss: 0.068810, loss_s1: 0.059071, loss_fp: 0.011768, loss_freq: 0.033000
[05:12:05.233] iteration 15341: loss: 0.099203, loss_s1: 0.101002, loss_fp: 0.005428, loss_freq: 0.046430
[05:12:05.923] iteration 15342: loss: 0.085111, loss_s1: 0.076328, loss_fp: 0.002357, loss_freq: 0.031773
[05:12:06.587] iteration 15343: loss: 0.120753, loss_s1: 0.142240, loss_fp: 0.004597, loss_freq: 0.060423
[05:12:07.250] iteration 15344: loss: 0.083522, loss_s1: 0.066652, loss_fp: 0.006571, loss_freq: 0.060675
[05:12:07.882] iteration 15345: loss: 0.077944, loss_s1: 0.056442, loss_fp: 0.004443, loss_freq: 0.042717
[05:12:08.498] iteration 15346: loss: 0.058259, loss_s1: 0.044732, loss_fp: 0.005802, loss_freq: 0.024007
[05:12:09.128] iteration 15347: loss: 0.059158, loss_s1: 0.043525, loss_fp: 0.009375, loss_freq: 0.021431
[05:12:09.766] iteration 15348: loss: 0.065901, loss_s1: 0.061541, loss_fp: 0.000879, loss_freq: 0.032434
[05:12:10.388] iteration 15349: loss: 0.039765, loss_s1: 0.018581, loss_fp: 0.006043, loss_freq: 0.009571
[05:12:11.022] iteration 15350: loss: 0.064451, loss_s1: 0.054603, loss_fp: 0.000820, loss_freq: 0.030445
[05:12:11.654] iteration 15351: loss: 0.062549, loss_s1: 0.054391, loss_fp: 0.006424, loss_freq: 0.026681
[05:12:12.302] iteration 15352: loss: 0.070799, loss_s1: 0.069520, loss_fp: 0.005570, loss_freq: 0.042581
[05:12:12.937] iteration 15353: loss: 0.052523, loss_s1: 0.021616, loss_fp: 0.001491, loss_freq: 0.032227
[05:12:13.574] iteration 15354: loss: 0.095589, loss_s1: 0.097890, loss_fp: 0.004593, loss_freq: 0.052021
[05:12:14.205] iteration 15355: loss: 0.049179, loss_s1: 0.031230, loss_fp: 0.004597, loss_freq: 0.026540
[05:12:14.840] iteration 15356: loss: 0.057268, loss_s1: 0.052485, loss_fp: 0.002239, loss_freq: 0.021496
[05:12:15.532] iteration 15357: loss: 0.056744, loss_s1: 0.046312, loss_fp: 0.001836, loss_freq: 0.037222
[05:12:16.209] iteration 15358: loss: 0.075905, loss_s1: 0.074269, loss_fp: 0.005133, loss_freq: 0.014827
[05:12:16.889] iteration 15359: loss: 0.057344, loss_s1: 0.026881, loss_fp: 0.002762, loss_freq: 0.037473
[05:12:17.611] iteration 15360: loss: 0.055936, loss_s1: 0.052593, loss_fp: 0.003009, loss_freq: 0.022474
[05:12:18.314] iteration 15361: loss: 0.051668, loss_s1: 0.060743, loss_fp: 0.002530, loss_freq: 0.007708
[05:12:18.948] iteration 15362: loss: 0.082271, loss_s1: 0.053348, loss_fp: 0.002347, loss_freq: 0.045731
[05:12:19.580] iteration 15363: loss: 0.040379, loss_s1: 0.024051, loss_fp: 0.001474, loss_freq: 0.007875
[05:12:20.232] iteration 15364: loss: 0.047780, loss_s1: 0.022634, loss_fp: 0.001194, loss_freq: 0.028576
[05:12:20.866] iteration 15365: loss: 0.041515, loss_s1: 0.028136, loss_fp: 0.002206, loss_freq: 0.014279
[05:12:21.506] iteration 15366: loss: 0.077258, loss_s1: 0.074040, loss_fp: 0.005489, loss_freq: 0.047399
[05:12:22.136] iteration 15367: loss: 0.067426, loss_s1: 0.040836, loss_fp: 0.001740, loss_freq: 0.036847
[05:12:22.769] iteration 15368: loss: 0.142548, loss_s1: 0.097810, loss_fp: 0.015822, loss_freq: 0.127603
[05:12:23.421] iteration 15369: loss: 0.056689, loss_s1: 0.026532, loss_fp: 0.004231, loss_freq: 0.043009
[05:12:24.088] iteration 15370: loss: 0.048208, loss_s1: 0.044000, loss_fp: 0.002502, loss_freq: 0.020875
[05:12:24.750] iteration 15371: loss: 0.099983, loss_s1: 0.067435, loss_fp: 0.018161, loss_freq: 0.065264
[05:12:25.430] iteration 15372: loss: 0.039129, loss_s1: 0.020669, loss_fp: 0.001812, loss_freq: 0.022887
[05:12:26.055] iteration 15373: loss: 0.053841, loss_s1: 0.033053, loss_fp: 0.005946, loss_freq: 0.033385
[05:12:26.683] iteration 15374: loss: 0.061249, loss_s1: 0.048076, loss_fp: 0.004057, loss_freq: 0.026619
[05:12:27.310] iteration 15375: loss: 0.090162, loss_s1: 0.058766, loss_fp: 0.002303, loss_freq: 0.066256
[05:12:27.940] iteration 15376: loss: 0.080009, loss_s1: 0.047488, loss_fp: 0.005644, loss_freq: 0.062801
[05:12:28.567] iteration 15377: loss: 0.056281, loss_s1: 0.026853, loss_fp: 0.004367, loss_freq: 0.044807
[05:12:29.213] iteration 15378: loss: 0.115998, loss_s1: 0.072108, loss_fp: 0.006160, loss_freq: 0.083910
[05:12:29.901] iteration 15379: loss: 0.053163, loss_s1: 0.026993, loss_fp: 0.003598, loss_freq: 0.045321
[05:12:30.536] iteration 15380: loss: 0.065850, loss_s1: 0.035201, loss_fp: 0.001662, loss_freq: 0.033060
[05:12:31.192] iteration 15381: loss: 0.051565, loss_s1: 0.050465, loss_fp: 0.001581, loss_freq: 0.009883
[05:12:31.868] iteration 15382: loss: 0.071216, loss_s1: 0.062508, loss_fp: 0.014455, loss_freq: 0.030247
[05:12:32.545] iteration 15383: loss: 0.079405, loss_s1: 0.087178, loss_fp: 0.005060, loss_freq: 0.029750
[05:12:33.220] iteration 15384: loss: 0.042858, loss_s1: 0.037223, loss_fp: 0.001263, loss_freq: 0.009840
[05:12:33.870] iteration 15385: loss: 0.051102, loss_s1: 0.028190, loss_fp: 0.005382, loss_freq: 0.026651
[05:12:34.511] iteration 15386: loss: 0.058958, loss_s1: 0.042240, loss_fp: 0.005166, loss_freq: 0.014098
[05:12:35.148] iteration 15387: loss: 0.067778, loss_s1: 0.080122, loss_fp: 0.004008, loss_freq: 0.028492
[05:12:35.808] iteration 15388: loss: 0.063708, loss_s1: 0.052034, loss_fp: 0.005660, loss_freq: 0.021492
[05:12:36.455] iteration 15389: loss: 0.074888, loss_s1: 0.078844, loss_fp: 0.015950, loss_freq: 0.019839
[05:12:37.102] iteration 15390: loss: 0.056298, loss_s1: 0.045065, loss_fp: 0.002567, loss_freq: 0.011294
[05:12:37.726] iteration 15391: loss: 0.106949, loss_s1: 0.106889, loss_fp: 0.014462, loss_freq: 0.040092
[05:12:38.350] iteration 15392: loss: 0.038060, loss_s1: 0.016330, loss_fp: 0.002034, loss_freq: 0.024190
[05:12:38.973] iteration 15393: loss: 0.057200, loss_s1: 0.040611, loss_fp: 0.003581, loss_freq: 0.024042
[05:12:39.590] iteration 15394: loss: 0.035288, loss_s1: 0.014006, loss_fp: 0.001766, loss_freq: 0.024630
[05:12:40.222] iteration 15395: loss: 0.070374, loss_s1: 0.067173, loss_fp: 0.004073, loss_freq: 0.031515
[05:12:40.844] iteration 15396: loss: 0.090350, loss_s1: 0.106531, loss_fp: 0.010815, loss_freq: 0.027726
[05:12:41.475] iteration 15397: loss: 0.094475, loss_s1: 0.072711, loss_fp: 0.002375, loss_freq: 0.067337
[05:12:42.100] iteration 15398: loss: 0.080743, loss_s1: 0.056881, loss_fp: 0.005455, loss_freq: 0.046684
[05:12:42.757] iteration 15399: loss: 0.052481, loss_s1: 0.032363, loss_fp: 0.001141, loss_freq: 0.030411
[05:12:43.437] iteration 15400: loss: 0.058231, loss_s1: 0.030657, loss_fp: 0.001851, loss_freq: 0.022454
[05:12:46.819] iteration 15400 : mean_dice : 0.715944
[05:12:47.481] iteration 15401: loss: 0.066539, loss_s1: 0.065636, loss_fp: 0.002275, loss_freq: 0.028441
[05:12:48.135] iteration 15402: loss: 0.064205, loss_s1: 0.047644, loss_fp: 0.000556, loss_freq: 0.037264
[05:12:48.796] iteration 15403: loss: 0.047090, loss_s1: 0.032133, loss_fp: 0.005663, loss_freq: 0.020981
[05:12:49.433] iteration 15404: loss: 0.062382, loss_s1: 0.051503, loss_fp: 0.004079, loss_freq: 0.035018
[05:12:50.067] iteration 15405: loss: 0.035091, loss_s1: 0.020123, loss_fp: 0.001486, loss_freq: 0.020017
[05:12:50.754] iteration 15406: loss: 0.090304, loss_s1: 0.057580, loss_fp: 0.004042, loss_freq: 0.038239
[05:12:51.400] iteration 15407: loss: 0.046955, loss_s1: 0.042847, loss_fp: 0.002624, loss_freq: 0.012395
[05:12:52.033] iteration 15408: loss: 0.055366, loss_s1: 0.043183, loss_fp: 0.002358, loss_freq: 0.030578
[05:12:52.659] iteration 15409: loss: 0.052702, loss_s1: 0.024246, loss_fp: 0.006325, loss_freq: 0.022744
[05:12:53.288] iteration 15410: loss: 0.057242, loss_s1: 0.038125, loss_fp: 0.005780, loss_freq: 0.032101
[05:12:53.948] iteration 15411: loss: 0.053752, loss_s1: 0.040137, loss_fp: 0.002560, loss_freq: 0.025222
[05:12:54.590] iteration 15412: loss: 0.087949, loss_s1: 0.080945, loss_fp: 0.002935, loss_freq: 0.046782
[05:12:55.220] iteration 15413: loss: 0.063090, loss_s1: 0.042707, loss_fp: 0.008285, loss_freq: 0.030887
[05:12:55.850] iteration 15414: loss: 0.050815, loss_s1: 0.040645, loss_fp: 0.002984, loss_freq: 0.024147
[05:12:56.480] iteration 15415: loss: 0.082507, loss_s1: 0.055074, loss_fp: 0.007972, loss_freq: 0.055671
[05:12:57.104] iteration 15416: loss: 0.079150, loss_s1: 0.049097, loss_fp: 0.002742, loss_freq: 0.064210
[05:12:57.725] iteration 15417: loss: 0.082583, loss_s1: 0.059346, loss_fp: 0.010355, loss_freq: 0.055403
[05:12:58.352] iteration 15418: loss: 0.066579, loss_s1: 0.043819, loss_fp: 0.006310, loss_freq: 0.044936
[05:12:58.998] iteration 15419: loss: 0.100521, loss_s1: 0.077436, loss_fp: 0.006170, loss_freq: 0.082214
[05:12:59.617] iteration 15420: loss: 0.035834, loss_s1: 0.019377, loss_fp: 0.002409, loss_freq: 0.010510
[05:13:00.258] iteration 15421: loss: 0.048490, loss_s1: 0.036218, loss_fp: 0.001832, loss_freq: 0.006407
[05:13:00.891] iteration 15422: loss: 0.077331, loss_s1: 0.070061, loss_fp: 0.008350, loss_freq: 0.039825
[05:13:01.525] iteration 15423: loss: 0.067197, loss_s1: 0.024973, loss_fp: 0.011160, loss_freq: 0.048593
[05:13:02.153] iteration 15424: loss: 0.046452, loss_s1: 0.032413, loss_fp: 0.001216, loss_freq: 0.019938
[05:13:02.795] iteration 15425: loss: 0.065959, loss_s1: 0.046654, loss_fp: 0.007411, loss_freq: 0.020673
[05:13:03.420] iteration 15426: loss: 0.097391, loss_s1: 0.102561, loss_fp: 0.004697, loss_freq: 0.050994
[05:13:04.050] iteration 15427: loss: 0.080550, loss_s1: 0.037901, loss_fp: 0.001515, loss_freq: 0.090203
[05:13:04.677] iteration 15428: loss: 0.053023, loss_s1: 0.021278, loss_fp: 0.005666, loss_freq: 0.023053
[05:13:05.376] iteration 15429: loss: 0.048365, loss_s1: 0.032798, loss_fp: 0.002542, loss_freq: 0.015257
[05:13:06.002] iteration 15430: loss: 0.047800, loss_s1: 0.036067, loss_fp: 0.002520, loss_freq: 0.023986
[05:13:06.640] iteration 15431: loss: 0.064489, loss_s1: 0.053777, loss_fp: 0.006049, loss_freq: 0.043894
[05:13:07.260] iteration 15432: loss: 0.063286, loss_s1: 0.054595, loss_fp: 0.004202, loss_freq: 0.019002
[05:13:07.871] iteration 15433: loss: 0.107158, loss_s1: 0.103654, loss_fp: 0.003671, loss_freq: 0.056727
[05:13:08.483] iteration 15434: loss: 0.091675, loss_s1: 0.108601, loss_fp: 0.003283, loss_freq: 0.038558
[05:13:09.097] iteration 15435: loss: 0.120967, loss_s1: 0.104088, loss_fp: 0.004550, loss_freq: 0.089518
[05:13:09.707] iteration 15436: loss: 0.062721, loss_s1: 0.069075, loss_fp: 0.001618, loss_freq: 0.021037
[05:13:10.328] iteration 15437: loss: 0.082999, loss_s1: 0.069746, loss_fp: 0.007029, loss_freq: 0.047395
[05:13:10.944] iteration 15438: loss: 0.061383, loss_s1: 0.041615, loss_fp: 0.001737, loss_freq: 0.041755
[05:13:11.565] iteration 15439: loss: 0.073954, loss_s1: 0.082996, loss_fp: 0.006226, loss_freq: 0.027925
[05:13:12.185] iteration 15440: loss: 0.049214, loss_s1: 0.046180, loss_fp: 0.007778, loss_freq: 0.013628
[05:13:12.796] iteration 15441: loss: 0.078208, loss_s1: 0.069857, loss_fp: 0.005292, loss_freq: 0.036540
[05:13:13.410] iteration 15442: loss: 0.076123, loss_s1: 0.066348, loss_fp: 0.002126, loss_freq: 0.041318
[05:13:14.029] iteration 15443: loss: 0.065533, loss_s1: 0.039409, loss_fp: 0.007032, loss_freq: 0.050712
[05:13:14.643] iteration 15444: loss: 0.032150, loss_s1: 0.012448, loss_fp: 0.008112, loss_freq: 0.010081
[05:13:15.275] iteration 15445: loss: 0.031436, loss_s1: 0.021622, loss_fp: 0.002941, loss_freq: 0.007928
[05:13:15.883] iteration 15446: loss: 0.071277, loss_s1: 0.048951, loss_fp: 0.001333, loss_freq: 0.031718
[05:13:16.492] iteration 15447: loss: 0.060710, loss_s1: 0.042735, loss_fp: 0.007020, loss_freq: 0.029639
[05:13:17.109] iteration 15448: loss: 0.081432, loss_s1: 0.058533, loss_fp: 0.003485, loss_freq: 0.056060
[05:13:17.733] iteration 15449: loss: 0.070552, loss_s1: 0.061527, loss_fp: 0.002261, loss_freq: 0.047949
[05:13:18.341] iteration 15450: loss: 0.060778, loss_s1: 0.034941, loss_fp: 0.005459, loss_freq: 0.022005
[05:13:18.954] iteration 15451: loss: 0.065114, loss_s1: 0.069565, loss_fp: 0.005096, loss_freq: 0.013733
[05:13:19.566] iteration 15452: loss: 0.072613, loss_s1: 0.077272, loss_fp: 0.000915, loss_freq: 0.030375
[05:13:20.183] iteration 15453: loss: 0.067354, loss_s1: 0.036476, loss_fp: 0.003804, loss_freq: 0.052541
[05:13:20.789] iteration 15454: loss: 0.072769, loss_s1: 0.055816, loss_fp: 0.015480, loss_freq: 0.037568
[05:13:21.397] iteration 15455: loss: 0.102776, loss_s1: 0.102289, loss_fp: 0.002844, loss_freq: 0.060626
[05:13:22.011] iteration 15456: loss: 0.063769, loss_s1: 0.028305, loss_fp: 0.002040, loss_freq: 0.031800
[05:13:22.622] iteration 15457: loss: 0.060018, loss_s1: 0.032417, loss_fp: 0.002083, loss_freq: 0.023926
[05:13:23.232] iteration 15458: loss: 0.104483, loss_s1: 0.078897, loss_fp: 0.002059, loss_freq: 0.077995
[05:13:23.839] iteration 15459: loss: 0.064193, loss_s1: 0.052007, loss_fp: 0.003292, loss_freq: 0.038974
[05:13:24.447] iteration 15460: loss: 0.091586, loss_s1: 0.077738, loss_fp: 0.003372, loss_freq: 0.048594
[05:13:25.063] iteration 15461: loss: 0.038005, loss_s1: 0.028093, loss_fp: 0.005516, loss_freq: 0.006218
[05:13:25.676] iteration 15462: loss: 0.060416, loss_s1: 0.068389, loss_fp: 0.004542, loss_freq: 0.024079
[05:13:26.287] iteration 15463: loss: 0.048943, loss_s1: 0.017092, loss_fp: 0.003561, loss_freq: 0.020666
[05:13:26.896] iteration 15464: loss: 0.075077, loss_s1: 0.066092, loss_fp: 0.004526, loss_freq: 0.028885
[05:13:27.500] iteration 15465: loss: 0.036270, loss_s1: 0.027997, loss_fp: 0.002845, loss_freq: 0.010645
[05:13:28.103] iteration 15466: loss: 0.114948, loss_s1: 0.125245, loss_fp: 0.020762, loss_freq: 0.052376
[05:13:28.715] iteration 15467: loss: 0.068878, loss_s1: 0.055278, loss_fp: 0.003469, loss_freq: 0.041537
[05:13:29.330] iteration 15468: loss: 0.110802, loss_s1: 0.133858, loss_fp: 0.003800, loss_freq: 0.040945
[05:13:29.933] iteration 15469: loss: 0.114831, loss_s1: 0.062913, loss_fp: 0.005724, loss_freq: 0.109202
[05:13:30.540] iteration 15470: loss: 0.105251, loss_s1: 0.101007, loss_fp: 0.002412, loss_freq: 0.072282
[05:13:31.462] iteration 15471: loss: 0.080607, loss_s1: 0.079676, loss_fp: 0.003618, loss_freq: 0.041236
[05:13:32.079] iteration 15472: loss: 0.067900, loss_s1: 0.055918, loss_fp: 0.004566, loss_freq: 0.041426
[05:13:32.696] iteration 15473: loss: 0.092249, loss_s1: 0.117076, loss_fp: 0.008309, loss_freq: 0.024078
[05:13:33.312] iteration 15474: loss: 0.066869, loss_s1: 0.064460, loss_fp: 0.001895, loss_freq: 0.030874
[05:13:33.922] iteration 15475: loss: 0.063574, loss_s1: 0.061614, loss_fp: 0.004091, loss_freq: 0.023453
[05:13:34.536] iteration 15476: loss: 0.070824, loss_s1: 0.059380, loss_fp: 0.010279, loss_freq: 0.036982
[05:13:35.148] iteration 15477: loss: 0.080729, loss_s1: 0.074697, loss_fp: 0.006476, loss_freq: 0.044223
[05:13:35.767] iteration 15478: loss: 0.076994, loss_s1: 0.075837, loss_fp: 0.004891, loss_freq: 0.019758
[05:13:36.385] iteration 15479: loss: 0.044596, loss_s1: 0.031587, loss_fp: 0.002441, loss_freq: 0.028631
[05:13:36.997] iteration 15480: loss: 0.090937, loss_s1: 0.108900, loss_fp: 0.002709, loss_freq: 0.035425
[05:13:37.607] iteration 15481: loss: 0.060251, loss_s1: 0.034247, loss_fp: 0.004020, loss_freq: 0.036528
[05:13:38.221] iteration 15482: loss: 0.086546, loss_s1: 0.025389, loss_fp: 0.003195, loss_freq: 0.089636
[05:13:38.836] iteration 15483: loss: 0.043869, loss_s1: 0.032094, loss_fp: 0.000761, loss_freq: 0.018483
[05:13:39.460] iteration 15484: loss: 0.057522, loss_s1: 0.045788, loss_fp: 0.002176, loss_freq: 0.037272
[05:13:40.077] iteration 15485: loss: 0.082949, loss_s1: 0.048422, loss_fp: 0.002357, loss_freq: 0.042290
[05:13:40.696] iteration 15486: loss: 0.029843, loss_s1: 0.012485, loss_fp: 0.001875, loss_freq: 0.012343
[05:13:41.313] iteration 15487: loss: 0.081595, loss_s1: 0.060146, loss_fp: 0.000756, loss_freq: 0.074250
[05:13:41.932] iteration 15488: loss: 0.057637, loss_s1: 0.057100, loss_fp: 0.005326, loss_freq: 0.017846
[05:13:42.557] iteration 15489: loss: 0.065943, loss_s1: 0.063021, loss_fp: 0.005568, loss_freq: 0.026230
[05:13:43.184] iteration 15490: loss: 0.110824, loss_s1: 0.054854, loss_fp: 0.000946, loss_freq: 0.062464
[05:13:43.797] iteration 15491: loss: 0.059202, loss_s1: 0.037079, loss_fp: 0.002333, loss_freq: 0.037475
[05:13:44.409] iteration 15492: loss: 0.083226, loss_s1: 0.088145, loss_fp: 0.007029, loss_freq: 0.045888
[05:13:45.024] iteration 15493: loss: 0.076735, loss_s1: 0.048975, loss_fp: 0.003352, loss_freq: 0.033573
[05:13:45.636] iteration 15494: loss: 0.099338, loss_s1: 0.080984, loss_fp: 0.003764, loss_freq: 0.051703
[05:13:46.242] iteration 15495: loss: 0.070693, loss_s1: 0.048700, loss_fp: 0.003155, loss_freq: 0.054421
[05:13:46.855] iteration 15496: loss: 0.088926, loss_s1: 0.068065, loss_fp: 0.004039, loss_freq: 0.066958
[05:13:47.485] iteration 15497: loss: 0.063064, loss_s1: 0.028193, loss_fp: 0.003667, loss_freq: 0.029303
[05:13:48.094] iteration 15498: loss: 0.120172, loss_s1: 0.098315, loss_fp: 0.013523, loss_freq: 0.041319
[05:13:48.748] iteration 15499: loss: 0.113288, loss_s1: 0.035537, loss_fp: 0.002656, loss_freq: 0.034727
[05:13:49.375] iteration 15500: loss: 0.062507, loss_s1: 0.065469, loss_fp: 0.002700, loss_freq: 0.017465
[05:13:49.980] iteration 15501: loss: 0.076966, loss_s1: 0.057566, loss_fp: 0.003079, loss_freq: 0.060545
[05:13:50.633] iteration 15502: loss: 0.118632, loss_s1: 0.097429, loss_fp: 0.004518, loss_freq: 0.065756
[05:13:51.301] iteration 15503: loss: 0.075487, loss_s1: 0.047662, loss_fp: 0.005856, loss_freq: 0.045295
[05:13:51.965] iteration 15504: loss: 0.058515, loss_s1: 0.057307, loss_fp: 0.001811, loss_freq: 0.016541
[05:13:52.597] iteration 15505: loss: 0.093284, loss_s1: 0.071546, loss_fp: 0.002209, loss_freq: 0.080890
[05:13:53.215] iteration 15506: loss: 0.047112, loss_s1: 0.034428, loss_fp: 0.006621, loss_freq: 0.016721
[05:13:53.845] iteration 15507: loss: 0.075561, loss_s1: 0.072636, loss_fp: 0.000537, loss_freq: 0.025825
[05:13:54.455] iteration 15508: loss: 0.063240, loss_s1: 0.047138, loss_fp: 0.001593, loss_freq: 0.038801
[05:13:55.067] iteration 15509: loss: 0.062590, loss_s1: 0.034227, loss_fp: 0.003613, loss_freq: 0.042127
[05:13:55.683] iteration 15510: loss: 0.090593, loss_s1: 0.089333, loss_fp: 0.005672, loss_freq: 0.039196
[05:13:56.297] iteration 15511: loss: 0.084473, loss_s1: 0.068988, loss_fp: 0.005254, loss_freq: 0.045999
[05:13:56.911] iteration 15512: loss: 0.053194, loss_s1: 0.048284, loss_fp: 0.002361, loss_freq: 0.014623
[05:13:57.527] iteration 15513: loss: 0.064204, loss_s1: 0.048416, loss_fp: 0.005273, loss_freq: 0.040220
[05:13:58.141] iteration 15514: loss: 0.086554, loss_s1: 0.085831, loss_fp: 0.004056, loss_freq: 0.053596
[05:13:58.783] iteration 15515: loss: 0.068522, loss_s1: 0.068854, loss_fp: 0.003967, loss_freq: 0.031036
[05:13:59.566] iteration 15516: loss: 0.095387, loss_s1: 0.085215, loss_fp: 0.004103, loss_freq: 0.060479
[05:14:00.354] iteration 15517: loss: 0.049244, loss_s1: 0.033969, loss_fp: 0.002726, loss_freq: 0.027433
[05:14:01.055] iteration 15518: loss: 0.063423, loss_s1: 0.053685, loss_fp: 0.001922, loss_freq: 0.036164
[05:14:01.674] iteration 15519: loss: 0.051571, loss_s1: 0.042798, loss_fp: 0.004444, loss_freq: 0.014966
[05:14:02.296] iteration 15520: loss: 0.055081, loss_s1: 0.034650, loss_fp: 0.004400, loss_freq: 0.020621
[05:14:02.916] iteration 15521: loss: 0.051358, loss_s1: 0.027951, loss_fp: 0.000632, loss_freq: 0.029463
[05:14:03.532] iteration 15522: loss: 0.048593, loss_s1: 0.035274, loss_fp: 0.001257, loss_freq: 0.029409
[05:14:04.157] iteration 15523: loss: 0.042721, loss_s1: 0.015039, loss_fp: 0.003029, loss_freq: 0.026803
[05:14:04.778] iteration 15524: loss: 0.064873, loss_s1: 0.060106, loss_fp: 0.001475, loss_freq: 0.031379
[05:14:05.393] iteration 15525: loss: 0.065648, loss_s1: 0.048816, loss_fp: 0.005350, loss_freq: 0.026279
[05:14:06.003] iteration 15526: loss: 0.043220, loss_s1: 0.027188, loss_fp: 0.001356, loss_freq: 0.015009
[05:14:06.618] iteration 15527: loss: 0.064951, loss_s1: 0.043621, loss_fp: 0.006860, loss_freq: 0.047521
[05:14:07.231] iteration 15528: loss: 0.050993, loss_s1: 0.038466, loss_fp: 0.001274, loss_freq: 0.014503
[05:14:07.845] iteration 15529: loss: 0.047813, loss_s1: 0.030717, loss_fp: 0.001840, loss_freq: 0.027210
[05:14:08.456] iteration 15530: loss: 0.092704, loss_s1: 0.066956, loss_fp: 0.006220, loss_freq: 0.051645
[05:14:09.064] iteration 15531: loss: 0.059246, loss_s1: 0.037734, loss_fp: 0.000815, loss_freq: 0.012492
[05:14:09.677] iteration 15532: loss: 0.078078, loss_s1: 0.048813, loss_fp: 0.002381, loss_freq: 0.059509
[05:14:10.286] iteration 15533: loss: 0.042685, loss_s1: 0.026418, loss_fp: 0.002404, loss_freq: 0.013332
[05:14:10.893] iteration 15534: loss: 0.034042, loss_s1: 0.014344, loss_fp: 0.006011, loss_freq: 0.015699
[05:14:11.504] iteration 15535: loss: 0.074309, loss_s1: 0.081378, loss_fp: 0.002569, loss_freq: 0.018977
[05:14:12.116] iteration 15536: loss: 0.047930, loss_s1: 0.029876, loss_fp: 0.005304, loss_freq: 0.034636
[05:14:12.730] iteration 15537: loss: 0.055861, loss_s1: 0.028183, loss_fp: 0.000912, loss_freq: 0.019555
[05:14:13.340] iteration 15538: loss: 0.119202, loss_s1: 0.117769, loss_fp: 0.018303, loss_freq: 0.068710
[05:14:13.951] iteration 15539: loss: 0.054537, loss_s1: 0.034727, loss_fp: 0.001476, loss_freq: 0.043133
[05:14:14.561] iteration 15540: loss: 0.068383, loss_s1: 0.060452, loss_fp: 0.005424, loss_freq: 0.049152
[05:14:15.179] iteration 15541: loss: 0.073109, loss_s1: 0.059335, loss_fp: 0.015415, loss_freq: 0.027794
[05:14:15.789] iteration 15542: loss: 0.068351, loss_s1: 0.052031, loss_fp: 0.004922, loss_freq: 0.043437
[05:14:16.401] iteration 15543: loss: 0.063372, loss_s1: 0.052843, loss_fp: 0.007074, loss_freq: 0.032609
[05:14:17.013] iteration 15544: loss: 0.086375, loss_s1: 0.047684, loss_fp: 0.007302, loss_freq: 0.078178
[05:14:17.619] iteration 15545: loss: 0.066256, loss_s1: 0.020612, loss_fp: 0.003726, loss_freq: 0.067570
[05:14:18.232] iteration 15546: loss: 0.090424, loss_s1: 0.062557, loss_fp: 0.011598, loss_freq: 0.059290
[05:14:18.842] iteration 15547: loss: 0.047617, loss_s1: 0.033773, loss_fp: 0.003158, loss_freq: 0.024297
[05:14:19.460] iteration 15548: loss: 0.083813, loss_s1: 0.057952, loss_fp: 0.005039, loss_freq: 0.065837
[05:14:20.073] iteration 15549: loss: 0.045537, loss_s1: 0.019851, loss_fp: 0.011277, loss_freq: 0.033226
[05:14:20.731] iteration 15550: loss: 0.066984, loss_s1: 0.046516, loss_fp: 0.002307, loss_freq: 0.041517
[05:14:21.341] iteration 15551: loss: 0.101657, loss_s1: 0.088829, loss_fp: 0.001745, loss_freq: 0.064143
[05:14:21.961] iteration 15552: loss: 0.066577, loss_s1: 0.042957, loss_fp: 0.007127, loss_freq: 0.035512
[05:14:22.575] iteration 15553: loss: 0.080884, loss_s1: 0.084352, loss_fp: 0.007580, loss_freq: 0.035129
[05:14:23.187] iteration 15554: loss: 0.052725, loss_s1: 0.038889, loss_fp: 0.007759, loss_freq: 0.019643
[05:14:23.803] iteration 15555: loss: 0.065091, loss_s1: 0.067757, loss_fp: 0.001564, loss_freq: 0.022172
[05:14:24.420] iteration 15556: loss: 0.065785, loss_s1: 0.041617, loss_fp: 0.007836, loss_freq: 0.031335
[05:14:25.033] iteration 15557: loss: 0.069342, loss_s1: 0.067156, loss_fp: 0.002531, loss_freq: 0.039254
[05:14:25.652] iteration 15558: loss: 0.067588, loss_s1: 0.070482, loss_fp: 0.004624, loss_freq: 0.012193
[05:14:26.267] iteration 15559: loss: 0.065757, loss_s1: 0.067311, loss_fp: 0.008981, loss_freq: 0.020889
[05:14:26.880] iteration 15560: loss: 0.064259, loss_s1: 0.066022, loss_fp: 0.004396, loss_freq: 0.018020
[05:14:27.489] iteration 15561: loss: 0.088947, loss_s1: 0.081220, loss_fp: 0.003101, loss_freq: 0.055596
[05:14:28.104] iteration 15562: loss: 0.056594, loss_s1: 0.051208, loss_fp: 0.003991, loss_freq: 0.028823
[05:14:28.720] iteration 15563: loss: 0.048950, loss_s1: 0.023001, loss_fp: 0.004025, loss_freq: 0.017313
[05:14:29.341] iteration 15564: loss: 0.051137, loss_s1: 0.036356, loss_fp: 0.001740, loss_freq: 0.014787
[05:14:29.951] iteration 15565: loss: 0.085086, loss_s1: 0.082187, loss_fp: 0.005655, loss_freq: 0.043251
[05:14:30.564] iteration 15566: loss: 0.060340, loss_s1: 0.045819, loss_fp: 0.005230, loss_freq: 0.042799
[05:14:31.225] iteration 15567: loss: 0.063481, loss_s1: 0.031118, loss_fp: 0.001430, loss_freq: 0.051331
[05:14:31.880] iteration 15568: loss: 0.114935, loss_s1: 0.085912, loss_fp: 0.013862, loss_freq: 0.082423
[05:14:32.537] iteration 15569: loss: 0.057811, loss_s1: 0.022611, loss_fp: 0.009906, loss_freq: 0.049080
[05:14:33.194] iteration 15570: loss: 0.043001, loss_s1: 0.026637, loss_fp: 0.006173, loss_freq: 0.016363
[05:14:33.812] iteration 15571: loss: 0.049827, loss_s1: 0.044711, loss_fp: 0.004793, loss_freq: 0.020636
[05:14:34.422] iteration 15572: loss: 0.048355, loss_s1: 0.022790, loss_fp: 0.009703, loss_freq: 0.010539
[05:14:35.034] iteration 15573: loss: 0.048629, loss_s1: 0.041407, loss_fp: 0.000862, loss_freq: 0.017591
[05:14:35.647] iteration 15574: loss: 0.040575, loss_s1: 0.021877, loss_fp: 0.001432, loss_freq: 0.024583
[05:14:36.260] iteration 15575: loss: 0.053413, loss_s1: 0.035741, loss_fp: 0.003248, loss_freq: 0.037456
[05:14:36.869] iteration 15576: loss: 0.089062, loss_s1: 0.079465, loss_fp: 0.003044, loss_freq: 0.054141
[05:14:37.481] iteration 15577: loss: 0.055128, loss_s1: 0.051728, loss_fp: 0.008472, loss_freq: 0.010474
[05:14:38.092] iteration 15578: loss: 0.055133, loss_s1: 0.043160, loss_fp: 0.002569, loss_freq: 0.032784
[05:14:38.705] iteration 15579: loss: 0.071540, loss_s1: 0.014031, loss_fp: 0.003340, loss_freq: 0.082612
[05:14:39.314] iteration 15580: loss: 0.073277, loss_s1: 0.060004, loss_fp: 0.005738, loss_freq: 0.032523
[05:14:39.924] iteration 15581: loss: 0.073735, loss_s1: 0.046546, loss_fp: 0.003554, loss_freq: 0.027206
[05:14:40.564] iteration 15582: loss: 0.047902, loss_s1: 0.027632, loss_fp: 0.004136, loss_freq: 0.028780
[05:14:41.221] iteration 15583: loss: 0.044682, loss_s1: 0.032636, loss_fp: 0.004087, loss_freq: 0.018339
[05:14:41.840] iteration 15584: loss: 0.057871, loss_s1: 0.036010, loss_fp: 0.003321, loss_freq: 0.039652
[05:14:42.452] iteration 15585: loss: 0.059353, loss_s1: 0.038169, loss_fp: 0.003969, loss_freq: 0.029162
[05:14:43.086] iteration 15586: loss: 0.070036, loss_s1: 0.041851, loss_fp: 0.002406, loss_freq: 0.050303
[05:14:43.697] iteration 15587: loss: 0.051916, loss_s1: 0.041841, loss_fp: 0.005364, loss_freq: 0.016751
[05:14:44.319] iteration 15588: loss: 0.055609, loss_s1: 0.055241, loss_fp: 0.001612, loss_freq: 0.021801
[05:14:44.942] iteration 15589: loss: 0.099518, loss_s1: 0.051735, loss_fp: 0.005945, loss_freq: 0.105005
[05:14:45.567] iteration 15590: loss: 0.049819, loss_s1: 0.026448, loss_fp: 0.001771, loss_freq: 0.015147
[05:14:46.179] iteration 15591: loss: 0.033223, loss_s1: 0.018938, loss_fp: 0.001238, loss_freq: 0.009689
[05:14:46.803] iteration 15592: loss: 0.043914, loss_s1: 0.031842, loss_fp: 0.002956, loss_freq: 0.023585
[05:14:47.435] iteration 15593: loss: 0.079734, loss_s1: 0.079613, loss_fp: 0.010357, loss_freq: 0.029380
[05:14:48.042] iteration 15594: loss: 0.047028, loss_s1: 0.024520, loss_fp: 0.003804, loss_freq: 0.030518
[05:14:48.657] iteration 15595: loss: 0.074912, loss_s1: 0.051069, loss_fp: 0.004756, loss_freq: 0.046400
[05:14:49.271] iteration 15596: loss: 0.084512, loss_s1: 0.079849, loss_fp: 0.001232, loss_freq: 0.044203
[05:14:49.886] iteration 15597: loss: 0.079075, loss_s1: 0.069719, loss_fp: 0.006646, loss_freq: 0.054053
[05:14:50.500] iteration 15598: loss: 0.078120, loss_s1: 0.031478, loss_fp: 0.003300, loss_freq: 0.067696
[05:14:51.113] iteration 15599: loss: 0.066040, loss_s1: 0.036588, loss_fp: 0.006322, loss_freq: 0.023204
[05:14:51.729] iteration 15600: loss: 0.075612, loss_s1: 0.075086, loss_fp: 0.015374, loss_freq: 0.022249
[05:14:55.127] iteration 15600 : mean_dice : 0.726925
[05:14:55.769] iteration 15601: loss: 0.093577, loss_s1: 0.098553, loss_fp: 0.006797, loss_freq: 0.050571
[05:14:56.404] iteration 15602: loss: 0.105994, loss_s1: 0.064125, loss_fp: 0.003065, loss_freq: 0.030913
[05:14:57.080] iteration 15603: loss: 0.081307, loss_s1: 0.068223, loss_fp: 0.006804, loss_freq: 0.044894
[05:14:57.740] iteration 15604: loss: 0.072085, loss_s1: 0.077932, loss_fp: 0.004304, loss_freq: 0.028460
[05:14:58.401] iteration 15605: loss: 0.088650, loss_s1: 0.053057, loss_fp: 0.003013, loss_freq: 0.054034
[05:14:59.036] iteration 15606: loss: 0.038155, loss_s1: 0.026310, loss_fp: 0.001347, loss_freq: 0.017694
[05:14:59.650] iteration 15607: loss: 0.056753, loss_s1: 0.049968, loss_fp: 0.001017, loss_freq: 0.013466
[05:15:00.261] iteration 15608: loss: 0.086595, loss_s1: 0.039260, loss_fp: 0.002296, loss_freq: 0.099141
[05:15:00.879] iteration 15609: loss: 0.068997, loss_s1: 0.050236, loss_fp: 0.004368, loss_freq: 0.051378
[05:15:01.491] iteration 15610: loss: 0.067916, loss_s1: 0.047494, loss_fp: 0.004390, loss_freq: 0.058677
[05:15:02.128] iteration 15611: loss: 0.090460, loss_s1: 0.088739, loss_fp: 0.005835, loss_freq: 0.049527
[05:15:02.749] iteration 15612: loss: 0.071174, loss_s1: 0.054266, loss_fp: 0.004422, loss_freq: 0.040743
[05:15:03.358] iteration 15613: loss: 0.066549, loss_s1: 0.068112, loss_fp: 0.003426, loss_freq: 0.029902
[05:15:03.969] iteration 15614: loss: 0.078827, loss_s1: 0.085932, loss_fp: 0.005449, loss_freq: 0.007743
[05:15:04.577] iteration 15615: loss: 0.037059, loss_s1: 0.020619, loss_fp: 0.004798, loss_freq: 0.006087
[05:15:05.188] iteration 15616: loss: 0.064622, loss_s1: 0.049821, loss_fp: 0.001869, loss_freq: 0.031965
[05:15:05.799] iteration 15617: loss: 0.055077, loss_s1: 0.045125, loss_fp: 0.006931, loss_freq: 0.018358
[05:15:06.417] iteration 15618: loss: 0.105369, loss_s1: 0.126450, loss_fp: 0.005645, loss_freq: 0.046391
[05:15:07.027] iteration 15619: loss: 0.095298, loss_s1: 0.078046, loss_fp: 0.003703, loss_freq: 0.069770
[05:15:07.690] iteration 15620: loss: 0.069312, loss_s1: 0.036551, loss_fp: 0.007920, loss_freq: 0.041850
[05:15:08.366] iteration 15621: loss: 0.065581, loss_s1: 0.043146, loss_fp: 0.005239, loss_freq: 0.037998
[05:15:09.043] iteration 15622: loss: 0.061365, loss_s1: 0.044568, loss_fp: 0.004838, loss_freq: 0.028443
[05:15:09.723] iteration 15623: loss: 0.092292, loss_s1: 0.050517, loss_fp: 0.012054, loss_freq: 0.033772
[05:15:10.400] iteration 15624: loss: 0.071009, loss_s1: 0.076794, loss_fp: 0.006401, loss_freq: 0.018327
[05:15:11.079] iteration 15625: loss: 0.095288, loss_s1: 0.099559, loss_fp: 0.018072, loss_freq: 0.025746
[05:15:11.704] iteration 15626: loss: 0.068009, loss_s1: 0.059599, loss_fp: 0.001880, loss_freq: 0.022347
[05:15:12.317] iteration 15627: loss: 0.058849, loss_s1: 0.047016, loss_fp: 0.004205, loss_freq: 0.025506
[05:15:12.930] iteration 15628: loss: 0.101938, loss_s1: 0.045105, loss_fp: 0.006697, loss_freq: 0.091817
[05:15:13.542] iteration 15629: loss: 0.076242, loss_s1: 0.081200, loss_fp: 0.011320, loss_freq: 0.019904
[05:15:14.158] iteration 15630: loss: 0.057706, loss_s1: 0.045190, loss_fp: 0.001948, loss_freq: 0.025331
[05:15:14.783] iteration 15631: loss: 0.035639, loss_s1: 0.018078, loss_fp: 0.002567, loss_freq: 0.008910
[05:15:15.405] iteration 15632: loss: 0.063756, loss_s1: 0.064071, loss_fp: 0.004204, loss_freq: 0.032855
[05:15:16.034] iteration 15633: loss: 0.044342, loss_s1: 0.016197, loss_fp: 0.002433, loss_freq: 0.014496
[05:15:16.694] iteration 15634: loss: 0.054139, loss_s1: 0.046159, loss_fp: 0.001890, loss_freq: 0.019357
[05:15:17.319] iteration 15635: loss: 0.050573, loss_s1: 0.035365, loss_fp: 0.001542, loss_freq: 0.018181
[05:15:17.944] iteration 15636: loss: 0.082134, loss_s1: 0.094457, loss_fp: 0.006890, loss_freq: 0.036246
[05:15:18.557] iteration 15637: loss: 0.088308, loss_s1: 0.080982, loss_fp: 0.001249, loss_freq: 0.045583
[05:15:19.171] iteration 15638: loss: 0.110015, loss_s1: 0.111448, loss_fp: 0.009964, loss_freq: 0.060848
[05:15:19.779] iteration 15639: loss: 0.072250, loss_s1: 0.058411, loss_fp: 0.005879, loss_freq: 0.045616
[05:15:20.391] iteration 15640: loss: 0.089424, loss_s1: 0.118496, loss_fp: 0.001597, loss_freq: 0.019105
[05:15:21.316] iteration 15641: loss: 0.079736, loss_s1: 0.065810, loss_fp: 0.001529, loss_freq: 0.047504
[05:15:21.942] iteration 15642: loss: 0.055254, loss_s1: 0.040243, loss_fp: 0.002270, loss_freq: 0.026024
[05:15:22.556] iteration 15643: loss: 0.048025, loss_s1: 0.034741, loss_fp: 0.003317, loss_freq: 0.028223
[05:15:23.188] iteration 15644: loss: 0.050566, loss_s1: 0.040567, loss_fp: 0.002227, loss_freq: 0.016619
[05:15:23.804] iteration 15645: loss: 0.086546, loss_s1: 0.111259, loss_fp: 0.003040, loss_freq: 0.028379
[05:15:24.418] iteration 15646: loss: 0.069485, loss_s1: 0.064935, loss_fp: 0.005028, loss_freq: 0.024080
[05:15:25.035] iteration 15647: loss: 0.058223, loss_s1: 0.036302, loss_fp: 0.003312, loss_freq: 0.038900
[05:15:25.680] iteration 15648: loss: 0.046981, loss_s1: 0.041663, loss_fp: 0.001951, loss_freq: 0.017415
[05:15:26.343] iteration 15649: loss: 0.081922, loss_s1: 0.061294, loss_fp: 0.003499, loss_freq: 0.046056
[05:15:27.001] iteration 15650: loss: 0.079588, loss_s1: 0.067930, loss_fp: 0.003844, loss_freq: 0.047811
[05:15:27.656] iteration 15651: loss: 0.059663, loss_s1: 0.020146, loss_fp: 0.000820, loss_freq: 0.028556
[05:15:28.319] iteration 15652: loss: 0.079733, loss_s1: 0.043221, loss_fp: 0.000306, loss_freq: 0.082211
[05:15:28.946] iteration 15653: loss: 0.053333, loss_s1: 0.039058, loss_fp: 0.002134, loss_freq: 0.022644
[05:15:29.555] iteration 15654: loss: 0.096958, loss_s1: 0.085983, loss_fp: 0.005237, loss_freq: 0.065277
[05:15:30.159] iteration 15655: loss: 0.070535, loss_s1: 0.072019, loss_fp: 0.001769, loss_freq: 0.023776
[05:15:30.817] iteration 15656: loss: 0.050117, loss_s1: 0.037411, loss_fp: 0.007798, loss_freq: 0.013805
[05:15:31.520] iteration 15657: loss: 0.130618, loss_s1: 0.161768, loss_fp: 0.002239, loss_freq: 0.068373
[05:15:32.187] iteration 15658: loss: 0.076925, loss_s1: 0.072788, loss_fp: 0.001743, loss_freq: 0.029634
[05:15:32.811] iteration 15659: loss: 0.071090, loss_s1: 0.079292, loss_fp: 0.003421, loss_freq: 0.027535
[05:15:33.430] iteration 15660: loss: 0.068212, loss_s1: 0.070049, loss_fp: 0.007365, loss_freq: 0.020484
[05:15:34.040] iteration 15661: loss: 0.081554, loss_s1: 0.083111, loss_fp: 0.002353, loss_freq: 0.029821
[05:15:34.667] iteration 15662: loss: 0.052284, loss_s1: 0.027986, loss_fp: 0.001417, loss_freq: 0.044908
[05:15:35.295] iteration 15663: loss: 0.076868, loss_s1: 0.064856, loss_fp: 0.003249, loss_freq: 0.034033
[05:15:35.921] iteration 15664: loss: 0.078269, loss_s1: 0.093416, loss_fp: 0.001411, loss_freq: 0.024641
[05:15:36.552] iteration 15665: loss: 0.081256, loss_s1: 0.059188, loss_fp: 0.001242, loss_freq: 0.047911
[05:15:37.161] iteration 15666: loss: 0.087567, loss_s1: 0.092687, loss_fp: 0.003060, loss_freq: 0.039940
[05:15:37.790] iteration 15667: loss: 0.058929, loss_s1: 0.040950, loss_fp: 0.002027, loss_freq: 0.033544
[05:15:38.471] iteration 15668: loss: 0.085160, loss_s1: 0.062874, loss_fp: 0.003023, loss_freq: 0.017590
[05:15:39.147] iteration 15669: loss: 0.049903, loss_s1: 0.022709, loss_fp: 0.001265, loss_freq: 0.031266
[05:15:39.751] iteration 15670: loss: 0.069324, loss_s1: 0.067285, loss_fp: 0.001665, loss_freq: 0.028681
[05:15:40.356] iteration 15671: loss: 0.067134, loss_s1: 0.043364, loss_fp: 0.005086, loss_freq: 0.043350
[05:15:40.963] iteration 15672: loss: 0.131743, loss_s1: 0.083327, loss_fp: 0.002179, loss_freq: 0.125323
[05:15:41.578] iteration 15673: loss: 0.072683, loss_s1: 0.066516, loss_fp: 0.000869, loss_freq: 0.047425
[05:15:42.208] iteration 15674: loss: 0.038849, loss_s1: 0.016744, loss_fp: 0.007216, loss_freq: 0.011964
[05:15:42.847] iteration 15675: loss: 0.050714, loss_s1: 0.057158, loss_fp: 0.001012, loss_freq: 0.020322
[05:15:43.475] iteration 15676: loss: 0.075125, loss_s1: 0.074423, loss_fp: 0.001731, loss_freq: 0.033071
[05:15:44.104] iteration 15677: loss: 0.042410, loss_s1: 0.013965, loss_fp: 0.003374, loss_freq: 0.026154
[05:15:44.744] iteration 15678: loss: 0.087227, loss_s1: 0.088464, loss_fp: 0.004395, loss_freq: 0.037096
[05:15:45.368] iteration 15679: loss: 0.083650, loss_s1: 0.074424, loss_fp: 0.005259, loss_freq: 0.041454
[05:15:46.002] iteration 15680: loss: 0.090719, loss_s1: 0.089128, loss_fp: 0.001579, loss_freq: 0.037581
[05:15:46.631] iteration 15681: loss: 0.062852, loss_s1: 0.074512, loss_fp: 0.002169, loss_freq: 0.008625
[05:15:47.258] iteration 15682: loss: 0.074940, loss_s1: 0.064707, loss_fp: 0.004998, loss_freq: 0.036965
[05:15:47.869] iteration 15683: loss: 0.084373, loss_s1: 0.092021, loss_fp: 0.001725, loss_freq: 0.040648
[05:15:48.522] iteration 15684: loss: 0.119179, loss_s1: 0.126395, loss_fp: 0.005982, loss_freq: 0.074944
[05:15:49.200] iteration 15685: loss: 0.064173, loss_s1: 0.035720, loss_fp: 0.002868, loss_freq: 0.021703
[05:15:49.819] iteration 15686: loss: 0.055958, loss_s1: 0.039828, loss_fp: 0.002842, loss_freq: 0.033526
[05:15:50.428] iteration 15687: loss: 0.050652, loss_s1: 0.039861, loss_fp: 0.001491, loss_freq: 0.022744
[05:15:51.036] iteration 15688: loss: 0.062070, loss_s1: 0.039830, loss_fp: 0.004244, loss_freq: 0.045157
[05:15:51.645] iteration 15689: loss: 0.040019, loss_s1: 0.031263, loss_fp: 0.001030, loss_freq: 0.016022
[05:15:52.254] iteration 15690: loss: 0.056927, loss_s1: 0.025826, loss_fp: 0.003976, loss_freq: 0.040905
[05:15:52.872] iteration 15691: loss: 0.083783, loss_s1: 0.066136, loss_fp: 0.004360, loss_freq: 0.047651
[05:15:53.484] iteration 15692: loss: 0.082334, loss_s1: 0.086899, loss_fp: 0.007222, loss_freq: 0.046809
[05:15:54.098] iteration 15693: loss: 0.057433, loss_s1: 0.039426, loss_fp: 0.004837, loss_freq: 0.033889
[05:15:54.781] iteration 15694: loss: 0.111652, loss_s1: 0.141049, loss_fp: 0.002802, loss_freq: 0.037612
[05:15:55.436] iteration 15695: loss: 0.085100, loss_s1: 0.040946, loss_fp: 0.002694, loss_freq: 0.081789
[05:15:56.087] iteration 15696: loss: 0.054681, loss_s1: 0.038563, loss_fp: 0.001962, loss_freq: 0.027923
[05:15:56.743] iteration 15697: loss: 0.076195, loss_s1: 0.042631, loss_fp: 0.003637, loss_freq: 0.069580
[05:15:57.365] iteration 15698: loss: 0.068948, loss_s1: 0.031947, loss_fp: 0.003013, loss_freq: 0.040902
[05:15:58.007] iteration 15699: loss: 0.046067, loss_s1: 0.019014, loss_fp: 0.001145, loss_freq: 0.025387
[05:15:58.616] iteration 15700: loss: 0.076633, loss_s1: 0.050196, loss_fp: 0.005553, loss_freq: 0.037806
[05:15:59.245] iteration 15701: loss: 0.035079, loss_s1: 0.028117, loss_fp: 0.001489, loss_freq: 0.006444
[05:15:59.914] iteration 15702: loss: 0.082467, loss_s1: 0.066329, loss_fp: 0.001148, loss_freq: 0.035955
[05:16:00.569] iteration 15703: loss: 0.040580, loss_s1: 0.022073, loss_fp: 0.002108, loss_freq: 0.010419
[05:16:01.225] iteration 15704: loss: 0.041050, loss_s1: 0.021877, loss_fp: 0.000506, loss_freq: 0.016206
[05:16:01.883] iteration 15705: loss: 0.071731, loss_s1: 0.082929, loss_fp: 0.004057, loss_freq: 0.019489
[05:16:02.510] iteration 15706: loss: 0.075110, loss_s1: 0.056474, loss_fp: 0.002183, loss_freq: 0.060619
[05:16:03.118] iteration 15707: loss: 0.056797, loss_s1: 0.038165, loss_fp: 0.002805, loss_freq: 0.017052
[05:16:03.731] iteration 15708: loss: 0.104552, loss_s1: 0.095341, loss_fp: 0.010520, loss_freq: 0.062806
[05:16:04.352] iteration 15709: loss: 0.066885, loss_s1: 0.030677, loss_fp: 0.003923, loss_freq: 0.069160
[05:16:05.016] iteration 15710: loss: 0.041910, loss_s1: 0.034926, loss_fp: 0.001711, loss_freq: 0.016659
[05:16:05.638] iteration 15711: loss: 0.064370, loss_s1: 0.040521, loss_fp: 0.003095, loss_freq: 0.042503
[05:16:06.306] iteration 15712: loss: 0.033401, loss_s1: 0.015573, loss_fp: 0.001612, loss_freq: 0.012491
[05:16:06.969] iteration 15713: loss: 0.064790, loss_s1: 0.031377, loss_fp: 0.003575, loss_freq: 0.054157
[05:16:07.604] iteration 15714: loss: 0.064204, loss_s1: 0.073568, loss_fp: 0.001702, loss_freq: 0.018183
[05:16:08.250] iteration 15715: loss: 0.086870, loss_s1: 0.045752, loss_fp: 0.001586, loss_freq: 0.087151
[05:16:08.854] iteration 15716: loss: 0.086958, loss_s1: 0.054023, loss_fp: 0.011608, loss_freq: 0.057718
[05:16:09.460] iteration 15717: loss: 0.059299, loss_s1: 0.053162, loss_fp: 0.002197, loss_freq: 0.023061
[05:16:10.067] iteration 15718: loss: 0.066611, loss_s1: 0.055273, loss_fp: 0.004055, loss_freq: 0.031498
[05:16:10.687] iteration 15719: loss: 0.068577, loss_s1: 0.029044, loss_fp: 0.004893, loss_freq: 0.060298
[05:16:11.309] iteration 15720: loss: 0.067809, loss_s1: 0.040435, loss_fp: 0.002529, loss_freq: 0.044406
[05:16:11.919] iteration 15721: loss: 0.067414, loss_s1: 0.064760, loss_fp: 0.005543, loss_freq: 0.018201
[05:16:12.533] iteration 15722: loss: 0.058591, loss_s1: 0.059985, loss_fp: 0.007439, loss_freq: 0.014467
[05:16:13.143] iteration 15723: loss: 0.089558, loss_s1: 0.077543, loss_fp: 0.006779, loss_freq: 0.020841
[05:16:13.753] iteration 15724: loss: 0.058250, loss_s1: 0.034596, loss_fp: 0.007898, loss_freq: 0.021864
[05:16:14.394] iteration 15725: loss: 0.058848, loss_s1: 0.035137, loss_fp: 0.010136, loss_freq: 0.023429
[05:16:15.043] iteration 15726: loss: 0.057804, loss_s1: 0.035831, loss_fp: 0.003947, loss_freq: 0.015768
[05:16:15.694] iteration 15727: loss: 0.061941, loss_s1: 0.056966, loss_fp: 0.003016, loss_freq: 0.038407
[05:16:16.349] iteration 15728: loss: 0.053356, loss_s1: 0.035251, loss_fp: 0.006086, loss_freq: 0.021902
[05:16:16.999] iteration 15729: loss: 0.073706, loss_s1: 0.037113, loss_fp: 0.006347, loss_freq: 0.062244
[05:16:17.647] iteration 15730: loss: 0.048700, loss_s1: 0.015764, loss_fp: 0.001899, loss_freq: 0.025987
[05:16:18.274] iteration 15731: loss: 0.077636, loss_s1: 0.043052, loss_fp: 0.002562, loss_freq: 0.027751
[05:16:18.889] iteration 15732: loss: 0.050330, loss_s1: 0.032490, loss_fp: 0.001918, loss_freq: 0.031176
[05:16:19.504] iteration 15733: loss: 0.099916, loss_s1: 0.108903, loss_fp: 0.004389, loss_freq: 0.040367
[05:16:20.111] iteration 15734: loss: 0.059837, loss_s1: 0.053532, loss_fp: 0.000659, loss_freq: 0.033973
[05:16:20.720] iteration 15735: loss: 0.061659, loss_s1: 0.052494, loss_fp: 0.003657, loss_freq: 0.026391
[05:16:21.327] iteration 15736: loss: 0.102227, loss_s1: 0.113207, loss_fp: 0.003630, loss_freq: 0.054625
[05:16:21.936] iteration 15737: loss: 0.088170, loss_s1: 0.083385, loss_fp: 0.003752, loss_freq: 0.041608
[05:16:22.542] iteration 15738: loss: 0.063806, loss_s1: 0.023730, loss_fp: 0.002110, loss_freq: 0.050840
[05:16:23.148] iteration 15739: loss: 0.037977, loss_s1: 0.017532, loss_fp: 0.000995, loss_freq: 0.028229
[05:16:23.757] iteration 15740: loss: 0.053259, loss_s1: 0.046127, loss_fp: 0.002008, loss_freq: 0.017745
[05:16:24.369] iteration 15741: loss: 0.066356, loss_s1: 0.060884, loss_fp: 0.004280, loss_freq: 0.036499
[05:16:24.978] iteration 15742: loss: 0.056518, loss_s1: 0.036881, loss_fp: 0.001233, loss_freq: 0.017214
[05:16:25.585] iteration 15743: loss: 0.037013, loss_s1: 0.025887, loss_fp: 0.001004, loss_freq: 0.017968
[05:16:26.191] iteration 15744: loss: 0.046034, loss_s1: 0.013442, loss_fp: 0.003723, loss_freq: 0.023709
[05:16:26.799] iteration 15745: loss: 0.035412, loss_s1: 0.016271, loss_fp: 0.004101, loss_freq: 0.021908
[05:16:27.405] iteration 15746: loss: 0.061645, loss_s1: 0.047353, loss_fp: 0.011846, loss_freq: 0.029184
[05:16:28.011] iteration 15747: loss: 0.074492, loss_s1: 0.090066, loss_fp: 0.006261, loss_freq: 0.016104
[05:16:28.611] iteration 15748: loss: 0.065372, loss_s1: 0.052504, loss_fp: 0.002911, loss_freq: 0.031760
[05:16:29.215] iteration 15749: loss: 0.047330, loss_s1: 0.025479, loss_fp: 0.004674, loss_freq: 0.029478
[05:16:29.828] iteration 15750: loss: 0.061991, loss_s1: 0.058322, loss_fp: 0.002403, loss_freq: 0.026568
[05:16:30.443] iteration 15751: loss: 0.063689, loss_s1: 0.038764, loss_fp: 0.003502, loss_freq: 0.027569
[05:16:31.056] iteration 15752: loss: 0.067675, loss_s1: 0.063304, loss_fp: 0.006491, loss_freq: 0.024110
[05:16:31.667] iteration 15753: loss: 0.052307, loss_s1: 0.018903, loss_fp: 0.004587, loss_freq: 0.047930
[05:16:32.287] iteration 15754: loss: 0.060437, loss_s1: 0.058484, loss_fp: 0.002270, loss_freq: 0.015288
[05:16:32.909] iteration 15755: loss: 0.076214, loss_s1: 0.059834, loss_fp: 0.002250, loss_freq: 0.032498
[05:16:33.524] iteration 15756: loss: 0.068259, loss_s1: 0.051894, loss_fp: 0.010294, loss_freq: 0.028937
[05:16:34.136] iteration 15757: loss: 0.089748, loss_s1: 0.089561, loss_fp: 0.011928, loss_freq: 0.028432
[05:16:34.742] iteration 15758: loss: 0.055408, loss_s1: 0.032692, loss_fp: 0.006447, loss_freq: 0.036854
[05:16:35.354] iteration 15759: loss: 0.090142, loss_s1: 0.061005, loss_fp: 0.002507, loss_freq: 0.077603
[05:16:35.961] iteration 15760: loss: 0.045181, loss_s1: 0.031538, loss_fp: 0.001882, loss_freq: 0.011361
[05:16:36.564] iteration 15761: loss: 0.052962, loss_s1: 0.042903, loss_fp: 0.001066, loss_freq: 0.015816
[05:16:37.174] iteration 15762: loss: 0.044736, loss_s1: 0.039117, loss_fp: 0.002297, loss_freq: 0.017920
[05:16:37.782] iteration 15763: loss: 0.131117, loss_s1: 0.091047, loss_fp: 0.002472, loss_freq: 0.077383
[05:16:38.392] iteration 15764: loss: 0.066944, loss_s1: 0.043469, loss_fp: 0.006253, loss_freq: 0.040749
[05:16:38.998] iteration 15765: loss: 0.075816, loss_s1: 0.052683, loss_fp: 0.004754, loss_freq: 0.037976
[05:16:39.607] iteration 15766: loss: 0.063783, loss_s1: 0.063038, loss_fp: 0.002029, loss_freq: 0.025725
[05:16:40.215] iteration 15767: loss: 0.098601, loss_s1: 0.080714, loss_fp: 0.002304, loss_freq: 0.069344
[05:16:40.834] iteration 15768: loss: 0.052901, loss_s1: 0.037470, loss_fp: 0.004230, loss_freq: 0.017158
[05:16:41.442] iteration 15769: loss: 0.048511, loss_s1: 0.029900, loss_fp: 0.018964, loss_freq: 0.013945
[05:16:42.056] iteration 15770: loss: 0.056389, loss_s1: 0.049856, loss_fp: 0.006241, loss_freq: 0.019872
[05:16:42.663] iteration 15771: loss: 0.047343, loss_s1: 0.041717, loss_fp: 0.002655, loss_freq: 0.017736
[05:16:43.275] iteration 15772: loss: 0.071985, loss_s1: 0.020604, loss_fp: 0.015716, loss_freq: 0.036126
[05:16:43.884] iteration 15773: loss: 0.095265, loss_s1: 0.094304, loss_fp: 0.003302, loss_freq: 0.048685
[05:16:44.492] iteration 15774: loss: 0.076214, loss_s1: 0.084889, loss_fp: 0.004249, loss_freq: 0.029169
[05:16:45.098] iteration 15775: loss: 0.069754, loss_s1: 0.030868, loss_fp: 0.004430, loss_freq: 0.062931
[05:16:45.709] iteration 15776: loss: 0.028069, loss_s1: 0.017066, loss_fp: 0.004675, loss_freq: 0.006810
[05:16:46.318] iteration 15777: loss: 0.086570, loss_s1: 0.055415, loss_fp: 0.003531, loss_freq: 0.027652
[05:16:46.925] iteration 15778: loss: 0.078059, loss_s1: 0.083489, loss_fp: 0.002130, loss_freq: 0.034331
[05:16:47.531] iteration 15779: loss: 0.115652, loss_s1: 0.153783, loss_fp: 0.004628, loss_freq: 0.038016
[05:16:48.137] iteration 15780: loss: 0.062035, loss_s1: 0.057164, loss_fp: 0.004085, loss_freq: 0.033679
[05:16:48.743] iteration 15781: loss: 0.091797, loss_s1: 0.068927, loss_fp: 0.016758, loss_freq: 0.056417
[05:16:49.355] iteration 15782: loss: 0.055307, loss_s1: 0.038862, loss_fp: 0.008591, loss_freq: 0.022926
[05:16:49.968] iteration 15783: loss: 0.079650, loss_s1: 0.055295, loss_fp: 0.011755, loss_freq: 0.053563
[05:16:50.584] iteration 15784: loss: 0.071885, loss_s1: 0.061545, loss_fp: 0.003113, loss_freq: 0.037562
[05:16:51.197] iteration 15785: loss: 0.037375, loss_s1: 0.018520, loss_fp: 0.005978, loss_freq: 0.008923
[05:16:51.805] iteration 15786: loss: 0.052473, loss_s1: 0.031564, loss_fp: 0.002757, loss_freq: 0.009492
[05:16:52.436] iteration 15787: loss: 0.052714, loss_s1: 0.046768, loss_fp: 0.004166, loss_freq: 0.017925
[05:16:53.043] iteration 15788: loss: 0.100652, loss_s1: 0.078654, loss_fp: 0.005944, loss_freq: 0.072825
[05:16:53.661] iteration 15789: loss: 0.087592, loss_s1: 0.063133, loss_fp: 0.002324, loss_freq: 0.074820
[05:16:54.285] iteration 15790: loss: 0.062287, loss_s1: 0.042264, loss_fp: 0.004917, loss_freq: 0.025733
[05:16:54.903] iteration 15791: loss: 0.059974, loss_s1: 0.034957, loss_fp: 0.009063, loss_freq: 0.036457
[05:16:55.519] iteration 15792: loss: 0.065719, loss_s1: 0.041121, loss_fp: 0.004892, loss_freq: 0.037548
[05:16:56.132] iteration 15793: loss: 0.104857, loss_s1: 0.078018, loss_fp: 0.018318, loss_freq: 0.059878
[05:16:56.749] iteration 15794: loss: 0.091752, loss_s1: 0.072559, loss_fp: 0.005847, loss_freq: 0.063506
[05:16:57.362] iteration 15795: loss: 0.114546, loss_s1: 0.104130, loss_fp: 0.002679, loss_freq: 0.042768
[05:16:57.978] iteration 15796: loss: 0.049212, loss_s1: 0.042104, loss_fp: 0.001956, loss_freq: 0.016977
[05:16:58.591] iteration 15797: loss: 0.047515, loss_s1: 0.048766, loss_fp: 0.004037, loss_freq: 0.019351
[05:16:59.200] iteration 15798: loss: 0.119552, loss_s1: 0.095505, loss_fp: 0.005914, loss_freq: 0.086471
[05:16:59.824] iteration 15799: loss: 0.090384, loss_s1: 0.098704, loss_fp: 0.005327, loss_freq: 0.041847
[05:17:00.440] iteration 15800: loss: 0.064305, loss_s1: 0.048846, loss_fp: 0.006704, loss_freq: 0.034210
[05:17:03.851] iteration 15800 : mean_dice : 0.711301
[05:17:04.540] iteration 15801: loss: 0.071143, loss_s1: 0.079538, loss_fp: 0.002365, loss_freq: 0.023446
[05:17:05.205] iteration 15802: loss: 0.050910, loss_s1: 0.046492, loss_fp: 0.004428, loss_freq: 0.020826
[05:17:05.858] iteration 15803: loss: 0.039280, loss_s1: 0.008785, loss_fp: 0.001511, loss_freq: 0.012380
[05:17:06.510] iteration 15804: loss: 0.054689, loss_s1: 0.036722, loss_fp: 0.001504, loss_freq: 0.033508
[05:17:07.161] iteration 15805: loss: 0.063991, loss_s1: 0.076311, loss_fp: 0.002331, loss_freq: 0.011403
[05:17:07.797] iteration 15806: loss: 0.085146, loss_s1: 0.086010, loss_fp: 0.004495, loss_freq: 0.049280
[05:17:08.404] iteration 15807: loss: 0.069005, loss_s1: 0.060012, loss_fp: 0.001369, loss_freq: 0.025661
[05:17:09.014] iteration 15808: loss: 0.064010, loss_s1: 0.029518, loss_fp: 0.003920, loss_freq: 0.057770
[05:17:09.622] iteration 15809: loss: 0.079573, loss_s1: 0.080465, loss_fp: 0.003230, loss_freq: 0.044611
[05:17:10.233] iteration 15810: loss: 0.061132, loss_s1: 0.060119, loss_fp: 0.002380, loss_freq: 0.018254
[05:17:11.140] iteration 15811: loss: 0.060106, loss_s1: 0.061676, loss_fp: 0.004032, loss_freq: 0.014320
[05:17:11.807] iteration 15812: loss: 0.047574, loss_s1: 0.012054, loss_fp: 0.003501, loss_freq: 0.027481
[05:17:12.484] iteration 15813: loss: 0.074050, loss_s1: 0.080837, loss_fp: 0.006373, loss_freq: 0.028588
[05:17:13.113] iteration 15814: loss: 0.059401, loss_s1: 0.044376, loss_fp: 0.001161, loss_freq: 0.027053
[05:17:13.720] iteration 15815: loss: 0.037214, loss_s1: 0.023038, loss_fp: 0.000736, loss_freq: 0.013453
[05:17:14.327] iteration 15816: loss: 0.071763, loss_s1: 0.051913, loss_fp: 0.002189, loss_freq: 0.033554
[05:17:14.932] iteration 15817: loss: 0.056574, loss_s1: 0.033612, loss_fp: 0.002213, loss_freq: 0.029603
[05:17:15.536] iteration 15818: loss: 0.053438, loss_s1: 0.038041, loss_fp: 0.002994, loss_freq: 0.024696
[05:17:16.142] iteration 15819: loss: 0.083055, loss_s1: 0.092998, loss_fp: 0.002320, loss_freq: 0.029831
[05:17:16.752] iteration 15820: loss: 0.063646, loss_s1: 0.062441, loss_fp: 0.004233, loss_freq: 0.021511
[05:17:17.364] iteration 15821: loss: 0.080081, loss_s1: 0.040617, loss_fp: 0.003477, loss_freq: 0.064866
[05:17:18.040] iteration 15822: loss: 0.085901, loss_s1: 0.083447, loss_fp: 0.006150, loss_freq: 0.039126
[05:17:18.713] iteration 15823: loss: 0.061908, loss_s1: 0.039340, loss_fp: 0.003902, loss_freq: 0.035810
[05:17:19.369] iteration 15824: loss: 0.057169, loss_s1: 0.041371, loss_fp: 0.004149, loss_freq: 0.022321
[05:17:20.002] iteration 15825: loss: 0.079528, loss_s1: 0.075982, loss_fp: 0.001918, loss_freq: 0.031812
[05:17:20.610] iteration 15826: loss: 0.080173, loss_s1: 0.067276, loss_fp: 0.007704, loss_freq: 0.028711
[05:17:21.218] iteration 15827: loss: 0.148317, loss_s1: 0.145766, loss_fp: 0.003039, loss_freq: 0.116218
[05:17:21.828] iteration 15828: loss: 0.040949, loss_s1: 0.026137, loss_fp: 0.003029, loss_freq: 0.012816
[05:17:22.440] iteration 15829: loss: 0.064404, loss_s1: 0.039032, loss_fp: 0.003417, loss_freq: 0.055631
[05:17:23.107] iteration 15830: loss: 0.062861, loss_s1: 0.040425, loss_fp: 0.004252, loss_freq: 0.019941
[05:17:23.770] iteration 15831: loss: 0.048621, loss_s1: 0.026812, loss_fp: 0.001502, loss_freq: 0.031502
[05:17:24.432] iteration 15832: loss: 0.049752, loss_s1: 0.031453, loss_fp: 0.013724, loss_freq: 0.021311
[05:17:25.096] iteration 15833: loss: 0.069860, loss_s1: 0.048559, loss_fp: 0.005656, loss_freq: 0.034994
[05:17:25.760] iteration 15834: loss: 0.077878, loss_s1: 0.062418, loss_fp: 0.012351, loss_freq: 0.048478
[05:17:26.408] iteration 15835: loss: 0.070513, loss_s1: 0.054667, loss_fp: 0.004763, loss_freq: 0.025446
[05:17:27.029] iteration 15836: loss: 0.061205, loss_s1: 0.057771, loss_fp: 0.004445, loss_freq: 0.031710
[05:17:27.644] iteration 15837: loss: 0.048717, loss_s1: 0.025795, loss_fp: 0.001150, loss_freq: 0.029313
[05:17:28.259] iteration 15838: loss: 0.069444, loss_s1: 0.066288, loss_fp: 0.008671, loss_freq: 0.018628
[05:17:28.871] iteration 15839: loss: 0.054737, loss_s1: 0.045403, loss_fp: 0.003581, loss_freq: 0.020773
[05:17:29.482] iteration 15840: loss: 0.105874, loss_s1: 0.126779, loss_fp: 0.003971, loss_freq: 0.036565
[05:17:30.099] iteration 15841: loss: 0.062176, loss_s1: 0.048032, loss_fp: 0.002538, loss_freq: 0.050437
[05:17:30.714] iteration 15842: loss: 0.098913, loss_s1: 0.098547, loss_fp: 0.011045, loss_freq: 0.045888
[05:17:31.326] iteration 15843: loss: 0.080308, loss_s1: 0.080604, loss_fp: 0.003756, loss_freq: 0.044930
[05:17:31.943] iteration 15844: loss: 0.058926, loss_s1: 0.055085, loss_fp: 0.006561, loss_freq: 0.022045
[05:17:32.560] iteration 15845: loss: 0.062696, loss_s1: 0.053841, loss_fp: 0.000785, loss_freq: 0.033298
[05:17:33.175] iteration 15846: loss: 0.054861, loss_s1: 0.038982, loss_fp: 0.000816, loss_freq: 0.014634
[05:17:33.824] iteration 15847: loss: 0.056470, loss_s1: 0.028064, loss_fp: 0.002593, loss_freq: 0.022163
[05:17:34.442] iteration 15848: loss: 0.043209, loss_s1: 0.021459, loss_fp: 0.004005, loss_freq: 0.032946
[05:17:35.049] iteration 15849: loss: 0.078265, loss_s1: 0.087617, loss_fp: 0.006620, loss_freq: 0.022642
[05:17:35.661] iteration 15850: loss: 0.062410, loss_s1: 0.052896, loss_fp: 0.004015, loss_freq: 0.027576
[05:17:36.270] iteration 15851: loss: 0.092324, loss_s1: 0.071023, loss_fp: 0.007683, loss_freq: 0.060188
[05:17:36.879] iteration 15852: loss: 0.066643, loss_s1: 0.073054, loss_fp: 0.001160, loss_freq: 0.020122
[05:17:37.488] iteration 15853: loss: 0.107910, loss_s1: 0.126474, loss_fp: 0.003343, loss_freq: 0.046218
[05:17:38.104] iteration 15854: loss: 0.075135, loss_s1: 0.060301, loss_fp: 0.011521, loss_freq: 0.046872
[05:17:38.724] iteration 15855: loss: 0.088946, loss_s1: 0.076327, loss_fp: 0.000937, loss_freq: 0.053586
[05:17:39.337] iteration 15856: loss: 0.104575, loss_s1: 0.081680, loss_fp: 0.005026, loss_freq: 0.067141
[05:17:39.948] iteration 15857: loss: 0.057065, loss_s1: 0.032065, loss_fp: 0.006354, loss_freq: 0.036540
[05:17:40.563] iteration 15858: loss: 0.061570, loss_s1: 0.040081, loss_fp: 0.002107, loss_freq: 0.046384
[05:17:41.179] iteration 15859: loss: 0.052053, loss_s1: 0.054970, loss_fp: 0.001510, loss_freq: 0.013372
[05:17:41.790] iteration 15860: loss: 0.061521, loss_s1: 0.049250, loss_fp: 0.001376, loss_freq: 0.020788
[05:17:42.400] iteration 15861: loss: 0.046596, loss_s1: 0.032817, loss_fp: 0.000742, loss_freq: 0.024384
[05:17:43.011] iteration 15862: loss: 0.048851, loss_s1: 0.044644, loss_fp: 0.004106, loss_freq: 0.028977
[05:17:43.623] iteration 15863: loss: 0.056947, loss_s1: 0.039634, loss_fp: 0.002902, loss_freq: 0.037275
[05:17:44.236] iteration 15864: loss: 0.113505, loss_s1: 0.097199, loss_fp: 0.021193, loss_freq: 0.075179
[05:17:44.856] iteration 15865: loss: 0.084083, loss_s1: 0.057001, loss_fp: 0.004564, loss_freq: 0.066681
[05:17:45.468] iteration 15866: loss: 0.054222, loss_s1: 0.044226, loss_fp: 0.002100, loss_freq: 0.021903
[05:17:46.086] iteration 15867: loss: 0.089514, loss_s1: 0.074914, loss_fp: 0.003493, loss_freq: 0.070387
[05:17:46.701] iteration 15868: loss: 0.054469, loss_s1: 0.035553, loss_fp: 0.005082, loss_freq: 0.014883
[05:17:47.318] iteration 15869: loss: 0.070015, loss_s1: 0.023470, loss_fp: 0.004489, loss_freq: 0.029614
[05:17:47.929] iteration 15870: loss: 0.068657, loss_s1: 0.037119, loss_fp: 0.003215, loss_freq: 0.056029
[05:17:48.539] iteration 15871: loss: 0.047472, loss_s1: 0.039891, loss_fp: 0.004092, loss_freq: 0.005211
[05:17:49.150] iteration 15872: loss: 0.077995, loss_s1: 0.063521, loss_fp: 0.003464, loss_freq: 0.037815
[05:17:49.765] iteration 15873: loss: 0.038640, loss_s1: 0.019897, loss_fp: 0.001515, loss_freq: 0.006165
[05:17:50.421] iteration 15874: loss: 0.051385, loss_s1: 0.051523, loss_fp: 0.001804, loss_freq: 0.015429
[05:17:51.080] iteration 15875: loss: 0.082188, loss_s1: 0.090529, loss_fp: 0.001725, loss_freq: 0.032075
[05:17:51.738] iteration 15876: loss: 0.058184, loss_s1: 0.041126, loss_fp: 0.004483, loss_freq: 0.034106
[05:17:52.350] iteration 15877: loss: 0.041627, loss_s1: 0.020599, loss_fp: 0.002102, loss_freq: 0.014132
[05:17:52.998] iteration 15878: loss: 0.109380, loss_s1: 0.110457, loss_fp: 0.012523, loss_freq: 0.062343
[05:17:53.649] iteration 15879: loss: 0.048570, loss_s1: 0.017443, loss_fp: 0.013924, loss_freq: 0.022526
[05:17:54.296] iteration 15880: loss: 0.061627, loss_s1: 0.052142, loss_fp: 0.005961, loss_freq: 0.030801
[05:17:54.947] iteration 15881: loss: 0.063292, loss_s1: 0.032408, loss_fp: 0.003574, loss_freq: 0.038993
[05:17:55.600] iteration 15882: loss: 0.043315, loss_s1: 0.026818, loss_fp: 0.005389, loss_freq: 0.016188
[05:17:56.264] iteration 15883: loss: 0.052253, loss_s1: 0.035914, loss_fp: 0.006227, loss_freq: 0.027183
[05:17:56.891] iteration 15884: loss: 0.072539, loss_s1: 0.051279, loss_fp: 0.014697, loss_freq: 0.042909
[05:17:57.511] iteration 15885: loss: 0.079458, loss_s1: 0.062342, loss_fp: 0.001708, loss_freq: 0.059727
[05:17:58.126] iteration 15886: loss: 0.075098, loss_s1: 0.044809, loss_fp: 0.006182, loss_freq: 0.053272
[05:17:58.735] iteration 15887: loss: 0.075001, loss_s1: 0.072665, loss_fp: 0.003946, loss_freq: 0.029324
[05:17:59.374] iteration 15888: loss: 0.103683, loss_s1: 0.111612, loss_fp: 0.010039, loss_freq: 0.046438
[05:18:00.018] iteration 15889: loss: 0.050085, loss_s1: 0.042381, loss_fp: 0.000667, loss_freq: 0.035019
[05:18:00.659] iteration 15890: loss: 0.069575, loss_s1: 0.046674, loss_fp: 0.000806, loss_freq: 0.037727
[05:18:01.271] iteration 15891: loss: 0.108081, loss_s1: 0.118033, loss_fp: 0.001535, loss_freq: 0.037253
[05:18:01.887] iteration 15892: loss: 0.077017, loss_s1: 0.089913, loss_fp: 0.006608, loss_freq: 0.022932
[05:18:02.539] iteration 15893: loss: 0.047559, loss_s1: 0.030873, loss_fp: 0.002596, loss_freq: 0.025916
[05:18:03.216] iteration 15894: loss: 0.044023, loss_s1: 0.028045, loss_fp: 0.006016, loss_freq: 0.010880
[05:18:03.874] iteration 15895: loss: 0.059647, loss_s1: 0.041132, loss_fp: 0.002530, loss_freq: 0.029717
[05:18:04.527] iteration 15896: loss: 0.047153, loss_s1: 0.028081, loss_fp: 0.005814, loss_freq: 0.024073
[05:18:05.135] iteration 15897: loss: 0.056443, loss_s1: 0.042676, loss_fp: 0.003896, loss_freq: 0.042019
[05:18:05.746] iteration 15898: loss: 0.082409, loss_s1: 0.098074, loss_fp: 0.001811, loss_freq: 0.014510
[05:18:06.351] iteration 15899: loss: 0.084650, loss_s1: 0.067511, loss_fp: 0.005780, loss_freq: 0.055527
[05:18:06.958] iteration 15900: loss: 0.050214, loss_s1: 0.021142, loss_fp: 0.005583, loss_freq: 0.026429
[05:18:07.576] iteration 15901: loss: 0.077907, loss_s1: 0.081382, loss_fp: 0.001679, loss_freq: 0.033361
[05:18:08.187] iteration 15902: loss: 0.069022, loss_s1: 0.039269, loss_fp: 0.005377, loss_freq: 0.046252
[05:18:08.794] iteration 15903: loss: 0.091687, loss_s1: 0.054402, loss_fp: 0.004433, loss_freq: 0.034150
[05:18:09.411] iteration 15904: loss: 0.056640, loss_s1: 0.046722, loss_fp: 0.005306, loss_freq: 0.028527
[05:18:10.042] iteration 15905: loss: 0.063803, loss_s1: 0.054619, loss_fp: 0.006217, loss_freq: 0.021676
[05:18:10.854] iteration 15906: loss: 0.067407, loss_s1: 0.059475, loss_fp: 0.007673, loss_freq: 0.040533
[05:18:11.595] iteration 15907: loss: 0.071432, loss_s1: 0.035084, loss_fp: 0.001370, loss_freq: 0.067876
[05:18:12.218] iteration 15908: loss: 0.071437, loss_s1: 0.049504, loss_fp: 0.001198, loss_freq: 0.048837
[05:18:12.831] iteration 15909: loss: 0.059332, loss_s1: 0.049829, loss_fp: 0.007592, loss_freq: 0.028790
[05:18:13.494] iteration 15910: loss: 0.048092, loss_s1: 0.046365, loss_fp: 0.001422, loss_freq: 0.015076
[05:18:14.163] iteration 15911: loss: 0.074304, loss_s1: 0.089672, loss_fp: 0.008203, loss_freq: 0.018555
[05:18:14.839] iteration 15912: loss: 0.037617, loss_s1: 0.019254, loss_fp: 0.004575, loss_freq: 0.012404
[05:18:15.508] iteration 15913: loss: 0.039098, loss_s1: 0.022289, loss_fp: 0.002002, loss_freq: 0.020349
[05:18:16.122] iteration 15914: loss: 0.068799, loss_s1: 0.045243, loss_fp: 0.000987, loss_freq: 0.049108
[05:18:16.755] iteration 15915: loss: 0.043027, loss_s1: 0.034088, loss_fp: 0.010077, loss_freq: 0.013502
[05:18:17.376] iteration 15916: loss: 0.073474, loss_s1: 0.058286, loss_fp: 0.005279, loss_freq: 0.032679
[05:18:18.053] iteration 15917: loss: 0.043840, loss_s1: 0.023940, loss_fp: 0.006407, loss_freq: 0.017886
[05:18:18.763] iteration 15918: loss: 0.037422, loss_s1: 0.019234, loss_fp: 0.001434, loss_freq: 0.020984
[05:18:19.378] iteration 15919: loss: 0.081582, loss_s1: 0.055403, loss_fp: 0.009118, loss_freq: 0.058967
[05:18:19.993] iteration 15920: loss: 0.069037, loss_s1: 0.072465, loss_fp: 0.001698, loss_freq: 0.029395
[05:18:20.649] iteration 15921: loss: 0.048443, loss_s1: 0.038337, loss_fp: 0.002901, loss_freq: 0.014970
[05:18:21.317] iteration 15922: loss: 0.091681, loss_s1: 0.086745, loss_fp: 0.005050, loss_freq: 0.043890
[05:18:21.959] iteration 15923: loss: 0.054747, loss_s1: 0.041056, loss_fp: 0.002870, loss_freq: 0.032778
[05:18:22.594] iteration 15924: loss: 0.033892, loss_s1: 0.014603, loss_fp: 0.001757, loss_freq: 0.014952
[05:18:23.242] iteration 15925: loss: 0.064268, loss_s1: 0.027226, loss_fp: 0.004241, loss_freq: 0.053533
[05:18:23.902] iteration 15926: loss: 0.074951, loss_s1: 0.032040, loss_fp: 0.001864, loss_freq: 0.074710
[05:18:24.604] iteration 15927: loss: 0.090660, loss_s1: 0.097257, loss_fp: 0.012319, loss_freq: 0.034577
[05:18:25.217] iteration 15928: loss: 0.065994, loss_s1: 0.057418, loss_fp: 0.009177, loss_freq: 0.030461
[05:18:25.834] iteration 15929: loss: 0.049311, loss_s1: 0.021937, loss_fp: 0.001175, loss_freq: 0.038805
[05:18:26.456] iteration 15930: loss: 0.059510, loss_s1: 0.041295, loss_fp: 0.006651, loss_freq: 0.029202
[05:18:27.087] iteration 15931: loss: 0.041189, loss_s1: 0.038656, loss_fp: 0.001336, loss_freq: 0.008485
[05:18:27.706] iteration 15932: loss: 0.050112, loss_s1: 0.049134, loss_fp: 0.000835, loss_freq: 0.015446
[05:18:28.335] iteration 15933: loss: 0.082424, loss_s1: 0.062545, loss_fp: 0.003725, loss_freq: 0.035274
[05:18:28.980] iteration 15934: loss: 0.047909, loss_s1: 0.045109, loss_fp: 0.002654, loss_freq: 0.017848
[05:18:29.620] iteration 15935: loss: 0.081913, loss_s1: 0.027834, loss_fp: 0.009892, loss_freq: 0.081072
[05:18:30.249] iteration 15936: loss: 0.043589, loss_s1: 0.022725, loss_fp: 0.003307, loss_freq: 0.016858
[05:18:30.905] iteration 15937: loss: 0.055101, loss_s1: 0.037718, loss_fp: 0.000548, loss_freq: 0.043655
[05:18:31.528] iteration 15938: loss: 0.058566, loss_s1: 0.019029, loss_fp: 0.005837, loss_freq: 0.047989
[05:18:32.159] iteration 15939: loss: 0.062270, loss_s1: 0.043855, loss_fp: 0.004352, loss_freq: 0.042882
[05:18:32.774] iteration 15940: loss: 0.072228, loss_s1: 0.056473, loss_fp: 0.010094, loss_freq: 0.032967
[05:18:33.393] iteration 15941: loss: 0.066743, loss_s1: 0.084334, loss_fp: 0.008309, loss_freq: 0.012862
[05:18:34.017] iteration 15942: loss: 0.065091, loss_s1: 0.038284, loss_fp: 0.006415, loss_freq: 0.020823
[05:18:34.645] iteration 15943: loss: 0.085786, loss_s1: 0.095407, loss_fp: 0.003461, loss_freq: 0.032755
[05:18:35.267] iteration 15944: loss: 0.041774, loss_s1: 0.034479, loss_fp: 0.003943, loss_freq: 0.017309
[05:18:35.885] iteration 15945: loss: 0.083014, loss_s1: 0.041754, loss_fp: 0.006994, loss_freq: 0.078584
[05:18:36.504] iteration 15946: loss: 0.024282, loss_s1: 0.014241, loss_fp: 0.001643, loss_freq: 0.008000
[05:18:37.130] iteration 15947: loss: 0.062964, loss_s1: 0.043632, loss_fp: 0.006506, loss_freq: 0.028224
[05:18:37.742] iteration 15948: loss: 0.058186, loss_s1: 0.019937, loss_fp: 0.014281, loss_freq: 0.047252
[05:18:38.353] iteration 15949: loss: 0.074170, loss_s1: 0.066204, loss_fp: 0.006655, loss_freq: 0.042725
[05:18:38.965] iteration 15950: loss: 0.061298, loss_s1: 0.050062, loss_fp: 0.005218, loss_freq: 0.037456
[05:18:39.576] iteration 15951: loss: 0.070834, loss_s1: 0.066737, loss_fp: 0.004093, loss_freq: 0.033930
[05:18:40.193] iteration 15952: loss: 0.042780, loss_s1: 0.022192, loss_fp: 0.005065, loss_freq: 0.022629
[05:18:40.818] iteration 15953: loss: 0.051804, loss_s1: 0.028279, loss_fp: 0.008488, loss_freq: 0.036609
[05:18:41.441] iteration 15954: loss: 0.073045, loss_s1: 0.081841, loss_fp: 0.011695, loss_freq: 0.012456
[05:18:42.056] iteration 15955: loss: 0.036736, loss_s1: 0.032090, loss_fp: 0.001443, loss_freq: 0.011220
[05:18:42.668] iteration 15956: loss: 0.053454, loss_s1: 0.035983, loss_fp: 0.007405, loss_freq: 0.028045
[05:18:43.317] iteration 15957: loss: 0.063391, loss_s1: 0.025476, loss_fp: 0.012530, loss_freq: 0.036509
[05:18:43.941] iteration 15958: loss: 0.068373, loss_s1: 0.078045, loss_fp: 0.002600, loss_freq: 0.024046
[05:18:44.556] iteration 15959: loss: 0.107750, loss_s1: 0.085710, loss_fp: 0.006512, loss_freq: 0.068780
[05:18:45.163] iteration 15960: loss: 0.058609, loss_s1: 0.036998, loss_fp: 0.005295, loss_freq: 0.032984
[05:18:45.790] iteration 15961: loss: 0.080502, loss_s1: 0.073626, loss_fp: 0.005638, loss_freq: 0.039536
[05:18:46.413] iteration 15962: loss: 0.072663, loss_s1: 0.035192, loss_fp: 0.003107, loss_freq: 0.069558
[05:18:47.058] iteration 15963: loss: 0.092263, loss_s1: 0.099115, loss_fp: 0.007953, loss_freq: 0.033622
[05:18:47.705] iteration 15964: loss: 0.080578, loss_s1: 0.077217, loss_fp: 0.001981, loss_freq: 0.040156
[05:18:48.408] iteration 15965: loss: 0.080098, loss_s1: 0.041114, loss_fp: 0.008486, loss_freq: 0.036957
[05:18:49.031] iteration 15966: loss: 0.068107, loss_s1: 0.068171, loss_fp: 0.000807, loss_freq: 0.024378
[05:18:49.711] iteration 15967: loss: 0.059091, loss_s1: 0.033048, loss_fp: 0.005968, loss_freq: 0.040628
[05:18:50.376] iteration 15968: loss: 0.134894, loss_s1: 0.124416, loss_fp: 0.004140, loss_freq: 0.095529
[05:18:51.023] iteration 15969: loss: 0.053783, loss_s1: 0.027444, loss_fp: 0.003336, loss_freq: 0.033707
[05:18:51.662] iteration 15970: loss: 0.067201, loss_s1: 0.049885, loss_fp: 0.008526, loss_freq: 0.029590
[05:18:52.281] iteration 15971: loss: 0.037927, loss_s1: 0.026126, loss_fp: 0.004285, loss_freq: 0.007713
[05:18:52.887] iteration 15972: loss: 0.080968, loss_s1: 0.082447, loss_fp: 0.007683, loss_freq: 0.046599
[05:18:53.491] iteration 15973: loss: 0.041778, loss_s1: 0.018915, loss_fp: 0.002653, loss_freq: 0.009467
[05:18:54.101] iteration 15974: loss: 0.060541, loss_s1: 0.046539, loss_fp: 0.002762, loss_freq: 0.038306
[05:18:54.705] iteration 15975: loss: 0.036661, loss_s1: 0.016336, loss_fp: 0.001382, loss_freq: 0.008223
[05:18:55.311] iteration 15976: loss: 0.070610, loss_s1: 0.081957, loss_fp: 0.006085, loss_freq: 0.022639
[05:18:55.920] iteration 15977: loss: 0.071405, loss_s1: 0.030746, loss_fp: 0.004439, loss_freq: 0.032654
[05:18:56.530] iteration 15978: loss: 0.102895, loss_s1: 0.111547, loss_fp: 0.004417, loss_freq: 0.044077
[05:18:57.132] iteration 15979: loss: 0.054784, loss_s1: 0.050615, loss_fp: 0.001954, loss_freq: 0.024277
[05:18:57.734] iteration 15980: loss: 0.057252, loss_s1: 0.031029, loss_fp: 0.005668, loss_freq: 0.021975
[05:18:58.653] iteration 15981: loss: 0.073931, loss_s1: 0.065754, loss_fp: 0.002475, loss_freq: 0.031478
[05:18:59.250] iteration 15982: loss: 0.064471, loss_s1: 0.059955, loss_fp: 0.003323, loss_freq: 0.025136
[05:18:59.906] iteration 15983: loss: 0.059842, loss_s1: 0.057364, loss_fp: 0.004015, loss_freq: 0.027170
[05:19:00.558] iteration 15984: loss: 0.049598, loss_s1: 0.027126, loss_fp: 0.000615, loss_freq: 0.013544
[05:19:01.210] iteration 15985: loss: 0.074930, loss_s1: 0.082095, loss_fp: 0.005322, loss_freq: 0.026598
[05:19:01.834] iteration 15986: loss: 0.093770, loss_s1: 0.104583, loss_fp: 0.006212, loss_freq: 0.038651
[05:19:02.436] iteration 15987: loss: 0.073327, loss_s1: 0.069332, loss_fp: 0.001914, loss_freq: 0.032208
[05:19:03.042] iteration 15988: loss: 0.059628, loss_s1: 0.062724, loss_fp: 0.005422, loss_freq: 0.018378
[05:19:03.646] iteration 15989: loss: 0.064509, loss_s1: 0.044827, loss_fp: 0.003881, loss_freq: 0.045756
[05:19:04.267] iteration 15990: loss: 0.088399, loss_s1: 0.090686, loss_fp: 0.007233, loss_freq: 0.041166
[05:19:04.872] iteration 15991: loss: 0.067339, loss_s1: 0.023224, loss_fp: 0.006513, loss_freq: 0.063362
[05:19:05.529] iteration 15992: loss: 0.103854, loss_s1: 0.087853, loss_fp: 0.006164, loss_freq: 0.074309
[05:19:06.188] iteration 15993: loss: 0.066264, loss_s1: 0.062576, loss_fp: 0.002729, loss_freq: 0.033191
[05:19:06.823] iteration 15994: loss: 0.067767, loss_s1: 0.070608, loss_fp: 0.006915, loss_freq: 0.026764
[05:19:07.427] iteration 15995: loss: 0.071422, loss_s1: 0.053086, loss_fp: 0.005124, loss_freq: 0.033381
[05:19:08.033] iteration 15996: loss: 0.048936, loss_s1: 0.024564, loss_fp: 0.009001, loss_freq: 0.025313
[05:19:08.636] iteration 15997: loss: 0.134323, loss_s1: 0.138480, loss_fp: 0.003456, loss_freq: 0.095422
[05:19:09.259] iteration 15998: loss: 0.048172, loss_s1: 0.033905, loss_fp: 0.001971, loss_freq: 0.021694
[05:19:09.868] iteration 15999: loss: 0.076748, loss_s1: 0.051477, loss_fp: 0.009317, loss_freq: 0.058816
[05:19:10.476] iteration 16000: loss: 0.059418, loss_s1: 0.053028, loss_fp: 0.003088, loss_freq: 0.020089
[05:19:13.521] iteration 16000 : mean_dice : 0.706872
[05:19:14.156] iteration 16001: loss: 0.063659, loss_s1: 0.036575, loss_fp: 0.003379, loss_freq: 0.041014
[05:19:14.759] iteration 16002: loss: 0.100342, loss_s1: 0.066362, loss_fp: 0.006747, loss_freq: 0.066383
[05:19:15.361] iteration 16003: loss: 0.059911, loss_s1: 0.032260, loss_fp: 0.003458, loss_freq: 0.032110
[05:19:15.961] iteration 16004: loss: 0.058593, loss_s1: 0.032041, loss_fp: 0.006708, loss_freq: 0.042127
[05:19:16.566] iteration 16005: loss: 0.063281, loss_s1: 0.051154, loss_fp: 0.006582, loss_freq: 0.031163
[05:19:17.170] iteration 16006: loss: 0.073161, loss_s1: 0.080985, loss_fp: 0.001090, loss_freq: 0.034231
[05:19:17.772] iteration 16007: loss: 0.043430, loss_s1: 0.032633, loss_fp: 0.004888, loss_freq: 0.011326
[05:19:18.374] iteration 16008: loss: 0.079803, loss_s1: 0.072178, loss_fp: 0.003751, loss_freq: 0.009226
[05:19:18.980] iteration 16009: loss: 0.052217, loss_s1: 0.047365, loss_fp: 0.003502, loss_freq: 0.016182
[05:19:19.599] iteration 16010: loss: 0.080974, loss_s1: 0.048703, loss_fp: 0.000968, loss_freq: 0.056475
[05:19:20.206] iteration 16011: loss: 0.056238, loss_s1: 0.036938, loss_fp: 0.002809, loss_freq: 0.044135
[05:19:20.807] iteration 16012: loss: 0.085273, loss_s1: 0.063688, loss_fp: 0.007884, loss_freq: 0.050358
[05:19:21.413] iteration 16013: loss: 0.059974, loss_s1: 0.042734, loss_fp: 0.002119, loss_freq: 0.037888
[05:19:22.020] iteration 16014: loss: 0.041529, loss_s1: 0.014073, loss_fp: 0.002951, loss_freq: 0.014462
[05:19:22.627] iteration 16015: loss: 0.051369, loss_s1: 0.020458, loss_fp: 0.005711, loss_freq: 0.048449
[05:19:23.235] iteration 16016: loss: 0.055867, loss_s1: 0.040693, loss_fp: 0.004073, loss_freq: 0.021607
[05:19:23.841] iteration 16017: loss: 0.053824, loss_s1: 0.042923, loss_fp: 0.001246, loss_freq: 0.022149
[05:19:24.442] iteration 16018: loss: 0.048054, loss_s1: 0.031148, loss_fp: 0.002489, loss_freq: 0.016015
[05:19:25.046] iteration 16019: loss: 0.071511, loss_s1: 0.054349, loss_fp: 0.004488, loss_freq: 0.052098
[05:19:25.656] iteration 16020: loss: 0.069690, loss_s1: 0.057543, loss_fp: 0.005777, loss_freq: 0.034649
[05:19:26.266] iteration 16021: loss: 0.094229, loss_s1: 0.117951, loss_fp: 0.003224, loss_freq: 0.013725
[05:19:26.874] iteration 16022: loss: 0.053256, loss_s1: 0.041810, loss_fp: 0.001301, loss_freq: 0.022160
[05:19:27.479] iteration 16023: loss: 0.074624, loss_s1: 0.088922, loss_fp: 0.002118, loss_freq: 0.026021
[05:19:28.083] iteration 16024: loss: 0.076218, loss_s1: 0.080205, loss_fp: 0.001439, loss_freq: 0.039043
[05:19:28.693] iteration 16025: loss: 0.063894, loss_s1: 0.053345, loss_fp: 0.002073, loss_freq: 0.017023
[05:19:29.301] iteration 16026: loss: 0.084911, loss_s1: 0.109000, loss_fp: 0.003810, loss_freq: 0.013088
[05:19:29.920] iteration 16027: loss: 0.058164, loss_s1: 0.057123, loss_fp: 0.003151, loss_freq: 0.022069
[05:19:30.526] iteration 16028: loss: 0.064686, loss_s1: 0.048990, loss_fp: 0.008405, loss_freq: 0.037047
[05:19:31.142] iteration 16029: loss: 0.058764, loss_s1: 0.037580, loss_fp: 0.000858, loss_freq: 0.019090
[05:19:31.749] iteration 16030: loss: 0.049934, loss_s1: 0.040669, loss_fp: 0.003173, loss_freq: 0.012172
[05:19:32.351] iteration 16031: loss: 0.030391, loss_s1: 0.010946, loss_fp: 0.001670, loss_freq: 0.013704
[05:19:32.954] iteration 16032: loss: 0.095143, loss_s1: 0.086791, loss_fp: 0.001737, loss_freq: 0.067082
[05:19:33.562] iteration 16033: loss: 0.056617, loss_s1: 0.032267, loss_fp: 0.002818, loss_freq: 0.046510
[05:19:34.165] iteration 16034: loss: 0.076613, loss_s1: 0.067559, loss_fp: 0.003063, loss_freq: 0.043930
[05:19:34.770] iteration 16035: loss: 0.056763, loss_s1: 0.018717, loss_fp: 0.003109, loss_freq: 0.056567
[05:19:35.381] iteration 16036: loss: 0.056629, loss_s1: 0.047160, loss_fp: 0.001696, loss_freq: 0.026886
[05:19:35.996] iteration 16037: loss: 0.097518, loss_s1: 0.090544, loss_fp: 0.002157, loss_freq: 0.069105
[05:19:36.604] iteration 16038: loss: 0.052867, loss_s1: 0.026810, loss_fp: 0.003023, loss_freq: 0.018394
[05:19:37.220] iteration 16039: loss: 0.056907, loss_s1: 0.034413, loss_fp: 0.004873, loss_freq: 0.034743
[05:19:37.829] iteration 16040: loss: 0.064474, loss_s1: 0.022451, loss_fp: 0.002640, loss_freq: 0.043541
[05:19:38.440] iteration 16041: loss: 0.040259, loss_s1: 0.033444, loss_fp: 0.005537, loss_freq: 0.008402
[05:19:39.125] iteration 16042: loss: 0.061333, loss_s1: 0.040488, loss_fp: 0.002767, loss_freq: 0.025995
[05:19:39.784] iteration 16043: loss: 0.045331, loss_s1: 0.022785, loss_fp: 0.003984, loss_freq: 0.015111
[05:19:40.455] iteration 16044: loss: 0.039902, loss_s1: 0.029449, loss_fp: 0.002321, loss_freq: 0.016001
[05:19:41.111] iteration 16045: loss: 0.063041, loss_s1: 0.065438, loss_fp: 0.002559, loss_freq: 0.013031
[05:19:41.725] iteration 16046: loss: 0.033698, loss_s1: 0.013845, loss_fp: 0.002484, loss_freq: 0.022596
[05:19:42.356] iteration 16047: loss: 0.066722, loss_s1: 0.063914, loss_fp: 0.001669, loss_freq: 0.020863
[05:19:42.991] iteration 16048: loss: 0.110015, loss_s1: 0.123190, loss_fp: 0.003940, loss_freq: 0.046970
[05:19:43.620] iteration 16049: loss: 0.032437, loss_s1: 0.017112, loss_fp: 0.000815, loss_freq: 0.015470
[05:19:44.246] iteration 16050: loss: 0.066187, loss_s1: 0.062896, loss_fp: 0.003597, loss_freq: 0.041158
[05:19:44.873] iteration 16051: loss: 0.061083, loss_s1: 0.030517, loss_fp: 0.012122, loss_freq: 0.046909
[05:19:45.497] iteration 16052: loss: 0.049733, loss_s1: 0.034633, loss_fp: 0.004613, loss_freq: 0.026933
[05:19:46.122] iteration 16053: loss: 0.054697, loss_s1: 0.048427, loss_fp: 0.006345, loss_freq: 0.028161
[05:19:46.741] iteration 16054: loss: 0.078439, loss_s1: 0.097666, loss_fp: 0.006696, loss_freq: 0.022521
[05:19:47.403] iteration 16055: loss: 0.076703, loss_s1: 0.035359, loss_fp: 0.001573, loss_freq: 0.079139
[05:19:48.024] iteration 16056: loss: 0.084098, loss_s1: 0.041075, loss_fp: 0.008311, loss_freq: 0.052355
[05:19:48.649] iteration 16057: loss: 0.063579, loss_s1: 0.043403, loss_fp: 0.007182, loss_freq: 0.027205
[05:19:49.347] iteration 16058: loss: 0.068079, loss_s1: 0.054687, loss_fp: 0.011717, loss_freq: 0.023571
[05:19:49.980] iteration 16059: loss: 0.047192, loss_s1: 0.032126, loss_fp: 0.002422, loss_freq: 0.031238
[05:19:50.652] iteration 16060: loss: 0.075197, loss_s1: 0.082632, loss_fp: 0.002830, loss_freq: 0.024190
[05:19:51.294] iteration 16061: loss: 0.084112, loss_s1: 0.056100, loss_fp: 0.013869, loss_freq: 0.047366
[05:19:51.913] iteration 16062: loss: 0.061035, loss_s1: 0.045598, loss_fp: 0.004261, loss_freq: 0.038821
[05:19:52.535] iteration 16063: loss: 0.052103, loss_s1: 0.047166, loss_fp: 0.006812, loss_freq: 0.023249
[05:19:53.208] iteration 16064: loss: 0.049408, loss_s1: 0.032224, loss_fp: 0.006603, loss_freq: 0.015890
[05:19:53.889] iteration 16065: loss: 0.046260, loss_s1: 0.028431, loss_fp: 0.003485, loss_freq: 0.021205
[05:19:54.544] iteration 16066: loss: 0.078733, loss_s1: 0.063496, loss_fp: 0.002469, loss_freq: 0.038182
[05:19:55.189] iteration 16067: loss: 0.076350, loss_s1: 0.101255, loss_fp: 0.001025, loss_freq: 0.029136
[05:19:55.828] iteration 16068: loss: 0.041874, loss_s1: 0.023817, loss_fp: 0.002671, loss_freq: 0.018833
[05:19:56.468] iteration 16069: loss: 0.091150, loss_s1: 0.126227, loss_fp: 0.002283, loss_freq: 0.025091
[05:19:57.120] iteration 16070: loss: 0.050358, loss_s1: 0.039791, loss_fp: 0.002010, loss_freq: 0.013423
[05:19:57.829] iteration 16071: loss: 0.089947, loss_s1: 0.114969, loss_fp: 0.009135, loss_freq: 0.020931
[05:19:58.503] iteration 16072: loss: 0.054135, loss_s1: 0.053276, loss_fp: 0.002450, loss_freq: 0.025980
[05:19:59.143] iteration 16073: loss: 0.075706, loss_s1: 0.052091, loss_fp: 0.005281, loss_freq: 0.050837
[05:19:59.787] iteration 16074: loss: 0.047503, loss_s1: 0.021329, loss_fp: 0.001289, loss_freq: 0.039631
[05:20:00.423] iteration 16075: loss: 0.085041, loss_s1: 0.089786, loss_fp: 0.006425, loss_freq: 0.043108
[05:20:01.064] iteration 16076: loss: 0.051787, loss_s1: 0.032416, loss_fp: 0.001400, loss_freq: 0.025715
[05:20:01.694] iteration 16077: loss: 0.104352, loss_s1: 0.097103, loss_fp: 0.002890, loss_freq: 0.049178
[05:20:02.337] iteration 16078: loss: 0.090144, loss_s1: 0.091470, loss_fp: 0.003134, loss_freq: 0.045522
[05:20:02.975] iteration 16079: loss: 0.079627, loss_s1: 0.067567, loss_fp: 0.002695, loss_freq: 0.061873
[05:20:03.609] iteration 16080: loss: 0.060927, loss_s1: 0.023257, loss_fp: 0.005250, loss_freq: 0.046264
[05:20:04.284] iteration 16081: loss: 0.071169, loss_s1: 0.083941, loss_fp: 0.005596, loss_freq: 0.023151
[05:20:04.947] iteration 16082: loss: 0.059655, loss_s1: 0.026851, loss_fp: 0.004157, loss_freq: 0.023179
[05:20:05.611] iteration 16083: loss: 0.041608, loss_s1: 0.026026, loss_fp: 0.009212, loss_freq: 0.014095
[05:20:06.281] iteration 16084: loss: 0.035701, loss_s1: 0.016337, loss_fp: 0.001999, loss_freq: 0.017455
[05:20:06.954] iteration 16085: loss: 0.043206, loss_s1: 0.026734, loss_fp: 0.001574, loss_freq: 0.024710
[05:20:07.619] iteration 16086: loss: 0.081750, loss_s1: 0.093933, loss_fp: 0.003025, loss_freq: 0.024554
[05:20:08.285] iteration 16087: loss: 0.056695, loss_s1: 0.028835, loss_fp: 0.010097, loss_freq: 0.018846
[05:20:08.917] iteration 16088: loss: 0.049251, loss_s1: 0.041930, loss_fp: 0.004274, loss_freq: 0.021163
[05:20:09.564] iteration 16089: loss: 0.064701, loss_s1: 0.051734, loss_fp: 0.009261, loss_freq: 0.027663
[05:20:10.187] iteration 16090: loss: 0.077245, loss_s1: 0.071992, loss_fp: 0.002553, loss_freq: 0.025188
[05:20:10.809] iteration 16091: loss: 0.064019, loss_s1: 0.047598, loss_fp: 0.004191, loss_freq: 0.022320
[05:20:11.427] iteration 16092: loss: 0.057626, loss_s1: 0.059098, loss_fp: 0.002916, loss_freq: 0.020363
[05:20:12.076] iteration 16093: loss: 0.046700, loss_s1: 0.037724, loss_fp: 0.001178, loss_freq: 0.029353
[05:20:12.721] iteration 16094: loss: 0.048321, loss_s1: 0.032130, loss_fp: 0.005716, loss_freq: 0.032429
[05:20:13.362] iteration 16095: loss: 0.084794, loss_s1: 0.072571, loss_fp: 0.003925, loss_freq: 0.055887
[05:20:14.364] iteration 16096: loss: 0.074743, loss_s1: 0.046082, loss_fp: 0.007126, loss_freq: 0.039775
[05:20:15.089] iteration 16097: loss: 0.086041, loss_s1: 0.085666, loss_fp: 0.014912, loss_freq: 0.037847
[05:20:15.723] iteration 16098: loss: 0.059408, loss_s1: 0.052496, loss_fp: 0.006275, loss_freq: 0.025804
[05:20:16.377] iteration 16099: loss: 0.117347, loss_s1: 0.074903, loss_fp: 0.002795, loss_freq: 0.099606
[05:20:17.003] iteration 16100: loss: 0.055665, loss_s1: 0.043533, loss_fp: 0.005802, loss_freq: 0.009053
[05:20:17.656] iteration 16101: loss: 0.047094, loss_s1: 0.036663, loss_fp: 0.003785, loss_freq: 0.011570
[05:20:18.286] iteration 16102: loss: 0.051433, loss_s1: 0.055997, loss_fp: 0.002218, loss_freq: 0.021951
[05:20:18.930] iteration 16103: loss: 0.058864, loss_s1: 0.035635, loss_fp: 0.003861, loss_freq: 0.040401
[05:20:19.581] iteration 16104: loss: 0.046108, loss_s1: 0.020353, loss_fp: 0.005249, loss_freq: 0.032507
[05:20:20.210] iteration 16105: loss: 0.072941, loss_s1: 0.051717, loss_fp: 0.006854, loss_freq: 0.039859
[05:20:20.831] iteration 16106: loss: 0.034883, loss_s1: 0.017010, loss_fp: 0.001309, loss_freq: 0.011669
[05:20:21.482] iteration 16107: loss: 0.114659, loss_s1: 0.117926, loss_fp: 0.003151, loss_freq: 0.075410
[05:20:22.149] iteration 16108: loss: 0.070429, loss_s1: 0.063882, loss_fp: 0.006769, loss_freq: 0.014010
[05:20:22.801] iteration 16109: loss: 0.057550, loss_s1: 0.031911, loss_fp: 0.008382, loss_freq: 0.032792
[05:20:23.433] iteration 16110: loss: 0.096350, loss_s1: 0.115079, loss_fp: 0.009152, loss_freq: 0.036650
[05:20:24.083] iteration 16111: loss: 0.099242, loss_s1: 0.071771, loss_fp: 0.022550, loss_freq: 0.074840
[05:20:24.755] iteration 16112: loss: 0.121329, loss_s1: 0.058532, loss_fp: 0.001987, loss_freq: 0.017527
[05:20:25.426] iteration 16113: loss: 0.099167, loss_s1: 0.112018, loss_fp: 0.004148, loss_freq: 0.041476
[05:20:26.097] iteration 16114: loss: 0.042236, loss_s1: 0.026369, loss_fp: 0.001218, loss_freq: 0.025361
[05:20:26.770] iteration 16115: loss: 0.088257, loss_s1: 0.053181, loss_fp: 0.000543, loss_freq: 0.087700
[05:20:27.450] iteration 16116: loss: 0.046164, loss_s1: 0.049662, loss_fp: 0.001504, loss_freq: 0.010864
[05:20:28.141] iteration 16117: loss: 0.064505, loss_s1: 0.060707, loss_fp: 0.001365, loss_freq: 0.020037
[05:20:28.815] iteration 16118: loss: 0.067806, loss_s1: 0.056846, loss_fp: 0.002116, loss_freq: 0.034682
[05:20:29.498] iteration 16119: loss: 0.106618, loss_s1: 0.117770, loss_fp: 0.009654, loss_freq: 0.054147
[05:20:30.140] iteration 16120: loss: 0.047068, loss_s1: 0.046391, loss_fp: 0.000905, loss_freq: 0.022050
[05:20:30.770] iteration 16121: loss: 0.072668, loss_s1: 0.066385, loss_fp: 0.002699, loss_freq: 0.036024
[05:20:31.403] iteration 16122: loss: 0.056123, loss_s1: 0.048046, loss_fp: 0.006205, loss_freq: 0.017031
[05:20:32.019] iteration 16123: loss: 0.044932, loss_s1: 0.030497, loss_fp: 0.002811, loss_freq: 0.025543
[05:20:32.636] iteration 16124: loss: 0.083246, loss_s1: 0.080776, loss_fp: 0.005939, loss_freq: 0.026698
[05:20:33.272] iteration 16125: loss: 0.048276, loss_s1: 0.052147, loss_fp: 0.001575, loss_freq: 0.010565
[05:20:33.919] iteration 16126: loss: 0.068728, loss_s1: 0.043171, loss_fp: 0.002669, loss_freq: 0.056156
[05:20:34.566] iteration 16127: loss: 0.060839, loss_s1: 0.049810, loss_fp: 0.003899, loss_freq: 0.017677
[05:20:35.202] iteration 16128: loss: 0.092105, loss_s1: 0.117062, loss_fp: 0.002275, loss_freq: 0.033242
[05:20:35.836] iteration 16129: loss: 0.051346, loss_s1: 0.042363, loss_fp: 0.003183, loss_freq: 0.027957
[05:20:36.475] iteration 16130: loss: 0.070243, loss_s1: 0.043766, loss_fp: 0.002707, loss_freq: 0.035880
[05:20:37.105] iteration 16131: loss: 0.102198, loss_s1: 0.101546, loss_fp: 0.008628, loss_freq: 0.054602
[05:20:37.746] iteration 16132: loss: 0.095533, loss_s1: 0.051099, loss_fp: 0.003291, loss_freq: 0.097368
[05:20:38.376] iteration 16133: loss: 0.058879, loss_s1: 0.050771, loss_fp: 0.001918, loss_freq: 0.028865
[05:20:39.004] iteration 16134: loss: 0.079777, loss_s1: 0.062651, loss_fp: 0.002124, loss_freq: 0.044014
[05:20:39.636] iteration 16135: loss: 0.089060, loss_s1: 0.086332, loss_fp: 0.002264, loss_freq: 0.046693
[05:20:40.277] iteration 16136: loss: 0.054128, loss_s1: 0.043179, loss_fp: 0.003530, loss_freq: 0.020310
[05:20:40.899] iteration 16137: loss: 0.057943, loss_s1: 0.049687, loss_fp: 0.003414, loss_freq: 0.039460
[05:20:41.558] iteration 16138: loss: 0.092421, loss_s1: 0.092897, loss_fp: 0.003936, loss_freq: 0.043238
[05:20:42.212] iteration 16139: loss: 0.063197, loss_s1: 0.042708, loss_fp: 0.006914, loss_freq: 0.033731
[05:20:42.859] iteration 16140: loss: 0.066918, loss_s1: 0.055533, loss_fp: 0.007730, loss_freq: 0.022535
[05:20:43.491] iteration 16141: loss: 0.060795, loss_s1: 0.068222, loss_fp: 0.001570, loss_freq: 0.008952
[05:20:44.182] iteration 16142: loss: 0.050327, loss_s1: 0.035496, loss_fp: 0.003912, loss_freq: 0.027074
[05:20:44.851] iteration 16143: loss: 0.086769, loss_s1: 0.050719, loss_fp: 0.005716, loss_freq: 0.061256
[05:20:45.499] iteration 16144: loss: 0.043856, loss_s1: 0.020653, loss_fp: 0.002819, loss_freq: 0.023345
[05:20:46.147] iteration 16145: loss: 0.046287, loss_s1: 0.028825, loss_fp: 0.002422, loss_freq: 0.023932
[05:20:46.778] iteration 16146: loss: 0.071422, loss_s1: 0.068459, loss_fp: 0.008640, loss_freq: 0.037815
[05:20:47.480] iteration 16147: loss: 0.075910, loss_s1: 0.044464, loss_fp: 0.013135, loss_freq: 0.051549
[05:20:48.149] iteration 16148: loss: 0.058632, loss_s1: 0.036238, loss_fp: 0.007586, loss_freq: 0.031378
[05:20:48.824] iteration 16149: loss: 0.079421, loss_s1: 0.051030, loss_fp: 0.001620, loss_freq: 0.075812
[05:20:49.472] iteration 16150: loss: 0.072158, loss_s1: 0.069853, loss_fp: 0.004519, loss_freq: 0.027534
[05:20:50.434] iteration 16151: loss: 0.083726, loss_s1: 0.085959, loss_fp: 0.005922, loss_freq: 0.031435
[05:20:51.147] iteration 16152: loss: 0.056099, loss_s1: 0.036603, loss_fp: 0.004967, loss_freq: 0.030509
[05:20:51.813] iteration 16153: loss: 0.052728, loss_s1: 0.034157, loss_fp: 0.005454, loss_freq: 0.023839
[05:20:52.479] iteration 16154: loss: 0.041357, loss_s1: 0.022759, loss_fp: 0.002466, loss_freq: 0.023153
[05:20:53.154] iteration 16155: loss: 0.053460, loss_s1: 0.047159, loss_fp: 0.002706, loss_freq: 0.023974
[05:20:53.798] iteration 16156: loss: 0.091488, loss_s1: 0.082976, loss_fp: 0.004676, loss_freq: 0.046548
[05:20:54.429] iteration 16157: loss: 0.064130, loss_s1: 0.025125, loss_fp: 0.004502, loss_freq: 0.045589
[05:20:55.063] iteration 16158: loss: 0.052501, loss_s1: 0.035976, loss_fp: 0.003080, loss_freq: 0.021955
[05:20:55.776] iteration 16159: loss: 0.051975, loss_s1: 0.041698, loss_fp: 0.003501, loss_freq: 0.025448
[05:20:56.448] iteration 16160: loss: 0.080910, loss_s1: 0.058087, loss_fp: 0.007070, loss_freq: 0.037731
[05:20:57.118] iteration 16161: loss: 0.054564, loss_s1: 0.020604, loss_fp: 0.005313, loss_freq: 0.039552
[05:20:57.791] iteration 16162: loss: 0.116736, loss_s1: 0.151177, loss_fp: 0.004377, loss_freq: 0.034556
[05:20:58.485] iteration 16163: loss: 0.076609, loss_s1: 0.060252, loss_fp: 0.005838, loss_freq: 0.050996
[05:20:59.118] iteration 16164: loss: 0.091735, loss_s1: 0.083202, loss_fp: 0.006278, loss_freq: 0.058621
[05:20:59.749] iteration 16165: loss: 0.071633, loss_s1: 0.053412, loss_fp: 0.001979, loss_freq: 0.054560
[05:21:00.382] iteration 16166: loss: 0.045550, loss_s1: 0.048774, loss_fp: 0.001841, loss_freq: 0.005528
[05:21:01.005] iteration 16167: loss: 0.129683, loss_s1: 0.087017, loss_fp: 0.005053, loss_freq: 0.143263
[05:21:01.637] iteration 16168: loss: 0.028819, loss_s1: 0.012469, loss_fp: 0.003426, loss_freq: 0.013557
[05:21:02.270] iteration 16169: loss: 0.068084, loss_s1: 0.052135, loss_fp: 0.005046, loss_freq: 0.032834
[05:21:02.903] iteration 16170: loss: 0.041134, loss_s1: 0.022203, loss_fp: 0.005600, loss_freq: 0.016017
[05:21:03.539] iteration 16171: loss: 0.065687, loss_s1: 0.037816, loss_fp: 0.009804, loss_freq: 0.026817
[05:21:04.185] iteration 16172: loss: 0.061273, loss_s1: 0.063005, loss_fp: 0.001870, loss_freq: 0.032375
[05:21:04.831] iteration 16173: loss: 0.079862, loss_s1: 0.068632, loss_fp: 0.002544, loss_freq: 0.040257
[05:21:05.458] iteration 16174: loss: 0.065478, loss_s1: 0.054716, loss_fp: 0.012810, loss_freq: 0.023573
[05:21:06.084] iteration 16175: loss: 0.092866, loss_s1: 0.097889, loss_fp: 0.003743, loss_freq: 0.025870
[05:21:06.711] iteration 16176: loss: 0.076640, loss_s1: 0.066708, loss_fp: 0.005493, loss_freq: 0.046396
[05:21:07.352] iteration 16177: loss: 0.085890, loss_s1: 0.057628, loss_fp: 0.003052, loss_freq: 0.070280
[05:21:07.975] iteration 16178: loss: 0.095422, loss_s1: 0.067424, loss_fp: 0.004465, loss_freq: 0.050644
[05:21:08.595] iteration 16179: loss: 0.075758, loss_s1: 0.056728, loss_fp: 0.002078, loss_freq: 0.038382
[05:21:09.220] iteration 16180: loss: 0.107972, loss_s1: 0.099340, loss_fp: 0.004085, loss_freq: 0.067235
[05:21:09.853] iteration 16181: loss: 0.054490, loss_s1: 0.036402, loss_fp: 0.002786, loss_freq: 0.041210
[05:21:10.485] iteration 16182: loss: 0.093837, loss_s1: 0.076532, loss_fp: 0.003243, loss_freq: 0.049551
[05:21:11.131] iteration 16183: loss: 0.079869, loss_s1: 0.078831, loss_fp: 0.003670, loss_freq: 0.046981
[05:21:11.762] iteration 16184: loss: 0.045590, loss_s1: 0.046852, loss_fp: 0.002135, loss_freq: 0.005206
[05:21:12.388] iteration 16185: loss: 0.070067, loss_s1: 0.081669, loss_fp: 0.001711, loss_freq: 0.031212
[05:21:13.036] iteration 16186: loss: 0.047868, loss_s1: 0.026756, loss_fp: 0.002874, loss_freq: 0.023619
[05:21:13.664] iteration 16187: loss: 0.065841, loss_s1: 0.049553, loss_fp: 0.001629, loss_freq: 0.034144
[05:21:14.300] iteration 16188: loss: 0.059174, loss_s1: 0.035960, loss_fp: 0.005134, loss_freq: 0.026971
[05:21:14.950] iteration 16189: loss: 0.139782, loss_s1: 0.158452, loss_fp: 0.009084, loss_freq: 0.065493
[05:21:15.617] iteration 16190: loss: 0.068429, loss_s1: 0.035808, loss_fp: 0.003661, loss_freq: 0.049073
[05:21:16.315] iteration 16191: loss: 0.059876, loss_s1: 0.042083, loss_fp: 0.001513, loss_freq: 0.037198
[05:21:16.989] iteration 16192: loss: 0.080485, loss_s1: 0.082054, loss_fp: 0.004926, loss_freq: 0.032002
[05:21:17.662] iteration 16193: loss: 0.111271, loss_s1: 0.123239, loss_fp: 0.001846, loss_freq: 0.061597
[05:21:18.305] iteration 16194: loss: 0.128106, loss_s1: 0.141350, loss_fp: 0.002778, loss_freq: 0.081456
[05:21:18.937] iteration 16195: loss: 0.056189, loss_s1: 0.049519, loss_fp: 0.002594, loss_freq: 0.020371
[05:21:19.558] iteration 16196: loss: 0.042029, loss_s1: 0.025115, loss_fp: 0.007060, loss_freq: 0.015709
[05:21:20.185] iteration 16197: loss: 0.041726, loss_s1: 0.019746, loss_fp: 0.004272, loss_freq: 0.022543
[05:21:20.805] iteration 16198: loss: 0.074959, loss_s1: 0.063291, loss_fp: 0.002898, loss_freq: 0.030260
[05:21:21.435] iteration 16199: loss: 0.035478, loss_s1: 0.013831, loss_fp: 0.007010, loss_freq: 0.015811
[05:21:22.075] iteration 16200: loss: 0.043857, loss_s1: 0.030761, loss_fp: 0.001666, loss_freq: 0.010230
[05:21:25.426] iteration 16200 : mean_dice : 0.724161
[05:21:26.080] iteration 16201: loss: 0.067248, loss_s1: 0.048933, loss_fp: 0.003054, loss_freq: 0.034460
[05:21:26.708] iteration 16202: loss: 0.057096, loss_s1: 0.043592, loss_fp: 0.003108, loss_freq: 0.034598
[05:21:27.329] iteration 16203: loss: 0.040717, loss_s1: 0.013455, loss_fp: 0.000491, loss_freq: 0.021289
[05:21:27.966] iteration 16204: loss: 0.097752, loss_s1: 0.110190, loss_fp: 0.009357, loss_freq: 0.035407
[05:21:28.610] iteration 16205: loss: 0.066585, loss_s1: 0.052560, loss_fp: 0.001638, loss_freq: 0.034427
[05:21:29.255] iteration 16206: loss: 0.060273, loss_s1: 0.029283, loss_fp: 0.008153, loss_freq: 0.038462
[05:21:29.890] iteration 16207: loss: 0.061431, loss_s1: 0.060349, loss_fp: 0.003197, loss_freq: 0.030262
[05:21:30.526] iteration 16208: loss: 0.060524, loss_s1: 0.035797, loss_fp: 0.004828, loss_freq: 0.022840
[05:21:31.155] iteration 16209: loss: 0.046477, loss_s1: 0.027886, loss_fp: 0.002043, loss_freq: 0.023168
[05:21:31.786] iteration 16210: loss: 0.065441, loss_s1: 0.057198, loss_fp: 0.007137, loss_freq: 0.038246
[05:21:32.419] iteration 16211: loss: 0.042263, loss_s1: 0.048297, loss_fp: 0.000742, loss_freq: 0.007050
[05:21:33.058] iteration 16212: loss: 0.071783, loss_s1: 0.077249, loss_fp: 0.001202, loss_freq: 0.019561
[05:21:33.692] iteration 16213: loss: 0.034577, loss_s1: 0.022499, loss_fp: 0.000609, loss_freq: 0.005656
[05:21:34.327] iteration 16214: loss: 0.063048, loss_s1: 0.057521, loss_fp: 0.005105, loss_freq: 0.030517
[05:21:34.984] iteration 16215: loss: 0.046684, loss_s1: 0.020533, loss_fp: 0.004125, loss_freq: 0.027368
[05:21:35.631] iteration 16216: loss: 0.046808, loss_s1: 0.033167, loss_fp: 0.003303, loss_freq: 0.027821
[05:21:36.277] iteration 16217: loss: 0.043349, loss_s1: 0.020944, loss_fp: 0.002154, loss_freq: 0.014432
[05:21:36.905] iteration 16218: loss: 0.098935, loss_s1: 0.076273, loss_fp: 0.006763, loss_freq: 0.068230
[05:21:37.532] iteration 16219: loss: 0.053206, loss_s1: 0.021324, loss_fp: 0.001653, loss_freq: 0.022946
[05:21:38.202] iteration 16220: loss: 0.060812, loss_s1: 0.050795, loss_fp: 0.001523, loss_freq: 0.044149
[05:21:38.873] iteration 16221: loss: 0.089502, loss_s1: 0.100225, loss_fp: 0.001400, loss_freq: 0.038423
[05:21:39.540] iteration 16222: loss: 0.049522, loss_s1: 0.037629, loss_fp: 0.002111, loss_freq: 0.021205
[05:21:40.218] iteration 16223: loss: 0.061914, loss_s1: 0.051876, loss_fp: 0.008884, loss_freq: 0.032924
[05:21:40.909] iteration 16224: loss: 0.091814, loss_s1: 0.104130, loss_fp: 0.009882, loss_freq: 0.024972
[05:21:41.579] iteration 16225: loss: 0.085729, loss_s1: 0.078462, loss_fp: 0.003923, loss_freq: 0.037083
[05:21:42.219] iteration 16226: loss: 0.102157, loss_s1: 0.093497, loss_fp: 0.008900, loss_freq: 0.065680
[05:21:42.873] iteration 16227: loss: 0.058029, loss_s1: 0.050925, loss_fp: 0.002624, loss_freq: 0.023908
[05:21:43.523] iteration 16228: loss: 0.086892, loss_s1: 0.087927, loss_fp: 0.009418, loss_freq: 0.040829
[05:21:44.156] iteration 16229: loss: 0.071613, loss_s1: 0.066932, loss_fp: 0.005662, loss_freq: 0.040482
[05:21:44.797] iteration 16230: loss: 0.085902, loss_s1: 0.052965, loss_fp: 0.009078, loss_freq: 0.049662
[05:21:45.437] iteration 16231: loss: 0.055684, loss_s1: 0.058824, loss_fp: 0.001749, loss_freq: 0.013849
[05:21:46.109] iteration 16232: loss: 0.094310, loss_s1: 0.107658, loss_fp: 0.003850, loss_freq: 0.041900
[05:21:46.767] iteration 16233: loss: 0.063177, loss_s1: 0.047702, loss_fp: 0.000575, loss_freq: 0.026776
[05:21:47.423] iteration 16234: loss: 0.049258, loss_s1: 0.035101, loss_fp: 0.011426, loss_freq: 0.012093
[05:21:48.066] iteration 16235: loss: 0.086598, loss_s1: 0.098103, loss_fp: 0.004795, loss_freq: 0.028981
[05:21:48.696] iteration 16236: loss: 0.082726, loss_s1: 0.100599, loss_fp: 0.005640, loss_freq: 0.016524
[05:21:49.316] iteration 16237: loss: 0.091258, loss_s1: 0.093272, loss_fp: 0.006481, loss_freq: 0.050095
[05:21:49.948] iteration 16238: loss: 0.064245, loss_s1: 0.050582, loss_fp: 0.005441, loss_freq: 0.028340
[05:21:50.576] iteration 16239: loss: 0.081086, loss_s1: 0.092818, loss_fp: 0.005200, loss_freq: 0.031454
[05:21:51.267] iteration 16240: loss: 0.066581, loss_s1: 0.061010, loss_fp: 0.007769, loss_freq: 0.017084
[05:21:51.957] iteration 16241: loss: 0.084540, loss_s1: 0.068078, loss_fp: 0.004006, loss_freq: 0.044216
[05:21:52.591] iteration 16242: loss: 0.046605, loss_s1: 0.040516, loss_fp: 0.002831, loss_freq: 0.021089
[05:21:53.242] iteration 16243: loss: 0.073272, loss_s1: 0.070592, loss_fp: 0.005859, loss_freq: 0.018189
[05:21:53.877] iteration 16244: loss: 0.079437, loss_s1: 0.086964, loss_fp: 0.010381, loss_freq: 0.029585
[05:21:54.508] iteration 16245: loss: 0.067920, loss_s1: 0.059468, loss_fp: 0.005730, loss_freq: 0.030022
[05:21:55.141] iteration 16246: loss: 0.064149, loss_s1: 0.064118, loss_fp: 0.002904, loss_freq: 0.030324
[05:21:55.779] iteration 16247: loss: 0.094009, loss_s1: 0.048439, loss_fp: 0.002846, loss_freq: 0.083392
[05:21:56.404] iteration 16248: loss: 0.078698, loss_s1: 0.016733, loss_fp: 0.005455, loss_freq: 0.083494
[05:21:57.054] iteration 16249: loss: 0.051248, loss_s1: 0.024820, loss_fp: 0.000697, loss_freq: 0.046987
[05:21:57.695] iteration 16250: loss: 0.054767, loss_s1: 0.045159, loss_fp: 0.004837, loss_freq: 0.019722
[05:21:58.319] iteration 16251: loss: 0.083617, loss_s1: 0.087768, loss_fp: 0.005568, loss_freq: 0.036985
[05:21:58.937] iteration 16252: loss: 0.065718, loss_s1: 0.059821, loss_fp: 0.004391, loss_freq: 0.019679
[05:21:59.561] iteration 16253: loss: 0.042237, loss_s1: 0.015562, loss_fp: 0.002527, loss_freq: 0.038008
[05:22:00.187] iteration 16254: loss: 0.049538, loss_s1: 0.029834, loss_fp: 0.002178, loss_freq: 0.032528
[05:22:00.850] iteration 16255: loss: 0.039108, loss_s1: 0.039514, loss_fp: 0.000957, loss_freq: 0.013611
[05:22:01.529] iteration 16256: loss: 0.092030, loss_s1: 0.085965, loss_fp: 0.005093, loss_freq: 0.042844
[05:22:02.243] iteration 16257: loss: 0.070417, loss_s1: 0.069669, loss_fp: 0.002170, loss_freq: 0.032439
[05:22:02.948] iteration 16258: loss: 0.062287, loss_s1: 0.061511, loss_fp: 0.002824, loss_freq: 0.021744
[05:22:03.619] iteration 16259: loss: 0.075827, loss_s1: 0.070485, loss_fp: 0.008527, loss_freq: 0.036935
[05:22:04.253] iteration 16260: loss: 0.059388, loss_s1: 0.047189, loss_fp: 0.005552, loss_freq: 0.033706
[05:22:04.868] iteration 16261: loss: 0.049963, loss_s1: 0.021803, loss_fp: 0.003118, loss_freq: 0.017952
[05:22:05.498] iteration 16262: loss: 0.070618, loss_s1: 0.070091, loss_fp: 0.005210, loss_freq: 0.026198
[05:22:06.134] iteration 16263: loss: 0.048628, loss_s1: 0.028786, loss_fp: 0.002491, loss_freq: 0.031061
[05:22:06.757] iteration 16264: loss: 0.061457, loss_s1: 0.052474, loss_fp: 0.002452, loss_freq: 0.033371
[05:22:07.406] iteration 16265: loss: 0.082662, loss_s1: 0.064601, loss_fp: 0.002536, loss_freq: 0.052637
[05:22:08.032] iteration 16266: loss: 0.073172, loss_s1: 0.036652, loss_fp: 0.008530, loss_freq: 0.060481
[05:22:08.656] iteration 16267: loss: 0.055389, loss_s1: 0.049307, loss_fp: 0.006117, loss_freq: 0.020995
[05:22:09.292] iteration 16268: loss: 0.092451, loss_s1: 0.094482, loss_fp: 0.002737, loss_freq: 0.053634
[05:22:09.933] iteration 16269: loss: 0.095257, loss_s1: 0.064453, loss_fp: 0.001684, loss_freq: 0.082918
[05:22:10.574] iteration 16270: loss: 0.076496, loss_s1: 0.092069, loss_fp: 0.007968, loss_freq: 0.009106
[05:22:11.201] iteration 16271: loss: 0.042920, loss_s1: 0.034792, loss_fp: 0.001580, loss_freq: 0.009535
[05:22:11.837] iteration 16272: loss: 0.059816, loss_s1: 0.069041, loss_fp: 0.003446, loss_freq: 0.019980
[05:22:12.521] iteration 16273: loss: 0.091952, loss_s1: 0.079697, loss_fp: 0.016320, loss_freq: 0.055538
[05:22:13.202] iteration 16274: loss: 0.051870, loss_s1: 0.040492, loss_fp: 0.002670, loss_freq: 0.020631
[05:22:13.886] iteration 16275: loss: 0.072419, loss_s1: 0.037012, loss_fp: 0.001721, loss_freq: 0.067284
[05:22:14.514] iteration 16276: loss: 0.055219, loss_s1: 0.041048, loss_fp: 0.002228, loss_freq: 0.030240
[05:22:15.143] iteration 16277: loss: 0.063621, loss_s1: 0.042341, loss_fp: 0.001645, loss_freq: 0.044274
[05:22:15.768] iteration 16278: loss: 0.109767, loss_s1: 0.147611, loss_fp: 0.005129, loss_freq: 0.026420
[05:22:16.405] iteration 16279: loss: 0.082390, loss_s1: 0.079248, loss_fp: 0.001558, loss_freq: 0.052853
[05:22:17.032] iteration 16280: loss: 0.074081, loss_s1: 0.050732, loss_fp: 0.003225, loss_freq: 0.049232
[05:22:17.680] iteration 16281: loss: 0.067373, loss_s1: 0.074988, loss_fp: 0.004511, loss_freq: 0.027598
[05:22:18.660] iteration 16282: loss: 0.075608, loss_s1: 0.056339, loss_fp: 0.003412, loss_freq: 0.030817
[05:22:19.563] iteration 16283: loss: 0.067755, loss_s1: 0.065520, loss_fp: 0.002563, loss_freq: 0.026614
[05:22:20.201] iteration 16284: loss: 0.072256, loss_s1: 0.083585, loss_fp: 0.004928, loss_freq: 0.021481
[05:22:20.828] iteration 16285: loss: 0.064392, loss_s1: 0.050496, loss_fp: 0.011311, loss_freq: 0.013861
[05:22:21.444] iteration 16286: loss: 0.052913, loss_s1: 0.049140, loss_fp: 0.010593, loss_freq: 0.013358
[05:22:22.089] iteration 16287: loss: 0.084687, loss_s1: 0.067799, loss_fp: 0.002692, loss_freq: 0.018730
[05:22:22.719] iteration 16288: loss: 0.055609, loss_s1: 0.031615, loss_fp: 0.005587, loss_freq: 0.030154
[05:22:23.355] iteration 16289: loss: 0.106503, loss_s1: 0.112342, loss_fp: 0.005262, loss_freq: 0.066058
[05:22:23.976] iteration 16290: loss: 0.046942, loss_s1: 0.042627, loss_fp: 0.001035, loss_freq: 0.019573
[05:22:24.605] iteration 16291: loss: 0.049280, loss_s1: 0.038290, loss_fp: 0.000846, loss_freq: 0.018636
[05:22:25.230] iteration 16292: loss: 0.072971, loss_s1: 0.059999, loss_fp: 0.001689, loss_freq: 0.039322
[05:22:25.844] iteration 16293: loss: 0.043719, loss_s1: 0.022508, loss_fp: 0.003009, loss_freq: 0.027603
[05:22:26.470] iteration 16294: loss: 0.048501, loss_s1: 0.032125, loss_fp: 0.002247, loss_freq: 0.017231
[05:22:27.098] iteration 16295: loss: 0.053536, loss_s1: 0.025614, loss_fp: 0.002997, loss_freq: 0.012982
[05:22:27.717] iteration 16296: loss: 0.055054, loss_s1: 0.028433, loss_fp: 0.013616, loss_freq: 0.024251
[05:22:28.352] iteration 16297: loss: 0.049205, loss_s1: 0.034990, loss_fp: 0.006887, loss_freq: 0.022356
[05:22:28.971] iteration 16298: loss: 0.103475, loss_s1: 0.112344, loss_fp: 0.005509, loss_freq: 0.049068
[05:22:29.596] iteration 16299: loss: 0.060183, loss_s1: 0.033337, loss_fp: 0.003275, loss_freq: 0.047269
[05:22:30.227] iteration 16300: loss: 0.083413, loss_s1: 0.059538, loss_fp: 0.005158, loss_freq: 0.046468
[05:22:30.848] iteration 16301: loss: 0.076368, loss_s1: 0.076018, loss_fp: 0.006021, loss_freq: 0.024744
[05:22:31.468] iteration 16302: loss: 0.093943, loss_s1: 0.101822, loss_fp: 0.010378, loss_freq: 0.042567
[05:22:32.085] iteration 16303: loss: 0.101174, loss_s1: 0.123785, loss_fp: 0.002399, loss_freq: 0.044914
[05:22:32.708] iteration 16304: loss: 0.083846, loss_s1: 0.079285, loss_fp: 0.003653, loss_freq: 0.041529
[05:22:33.337] iteration 16305: loss: 0.076306, loss_s1: 0.055044, loss_fp: 0.002738, loss_freq: 0.020171
[05:22:33.966] iteration 16306: loss: 0.046160, loss_s1: 0.043012, loss_fp: 0.000863, loss_freq: 0.011585
[05:22:34.589] iteration 16307: loss: 0.049994, loss_s1: 0.021864, loss_fp: 0.006569, loss_freq: 0.042742
[05:22:35.215] iteration 16308: loss: 0.108231, loss_s1: 0.079052, loss_fp: 0.002052, loss_freq: 0.097155
[05:22:35.855] iteration 16309: loss: 0.069488, loss_s1: 0.053359, loss_fp: 0.002403, loss_freq: 0.048409
[05:22:36.472] iteration 16310: loss: 0.072143, loss_s1: 0.064830, loss_fp: 0.004373, loss_freq: 0.036085
[05:22:37.098] iteration 16311: loss: 0.071126, loss_s1: 0.053981, loss_fp: 0.003661, loss_freq: 0.033931
[05:22:37.717] iteration 16312: loss: 0.076296, loss_s1: 0.066641, loss_fp: 0.002245, loss_freq: 0.040778
[05:22:38.346] iteration 16313: loss: 0.086470, loss_s1: 0.036245, loss_fp: 0.006362, loss_freq: 0.017656
[05:22:38.988] iteration 16314: loss: 0.048187, loss_s1: 0.040369, loss_fp: 0.001795, loss_freq: 0.023724
[05:22:39.605] iteration 16315: loss: 0.035767, loss_s1: 0.022017, loss_fp: 0.000985, loss_freq: 0.008116
[05:22:40.228] iteration 16316: loss: 0.054185, loss_s1: 0.024580, loss_fp: 0.000903, loss_freq: 0.050374
[05:22:40.851] iteration 16317: loss: 0.054273, loss_s1: 0.027608, loss_fp: 0.003354, loss_freq: 0.033290
[05:22:41.488] iteration 16318: loss: 0.112108, loss_s1: 0.117132, loss_fp: 0.005680, loss_freq: 0.060232
[05:22:42.106] iteration 16319: loss: 0.055808, loss_s1: 0.029060, loss_fp: 0.000869, loss_freq: 0.053518
[05:22:42.720] iteration 16320: loss: 0.058496, loss_s1: 0.043610, loss_fp: 0.002537, loss_freq: 0.032931
[05:22:43.750] iteration 16321: loss: 0.062085, loss_s1: 0.054993, loss_fp: 0.001714, loss_freq: 0.017123
[05:22:44.432] iteration 16322: loss: 0.052946, loss_s1: 0.037372, loss_fp: 0.000409, loss_freq: 0.031783
[05:22:45.124] iteration 16323: loss: 0.072457, loss_s1: 0.085928, loss_fp: 0.001477, loss_freq: 0.023729
[05:22:45.796] iteration 16324: loss: 0.046988, loss_s1: 0.035250, loss_fp: 0.002339, loss_freq: 0.017271
[05:22:46.434] iteration 16325: loss: 0.049314, loss_s1: 0.041525, loss_fp: 0.001478, loss_freq: 0.019811
[05:22:47.113] iteration 16326: loss: 0.065877, loss_s1: 0.042144, loss_fp: 0.002867, loss_freq: 0.027264
[05:22:47.743] iteration 16327: loss: 0.066257, loss_s1: 0.053386, loss_fp: 0.001987, loss_freq: 0.044542
[05:22:48.379] iteration 16328: loss: 0.053650, loss_s1: 0.045964, loss_fp: 0.003590, loss_freq: 0.017525
[05:22:49.003] iteration 16329: loss: 0.069976, loss_s1: 0.088086, loss_fp: 0.002890, loss_freq: 0.020103
[05:22:49.699] iteration 16330: loss: 0.088562, loss_s1: 0.111261, loss_fp: 0.007775, loss_freq: 0.018501
[05:22:50.388] iteration 16331: loss: 0.073991, loss_s1: 0.056097, loss_fp: 0.001966, loss_freq: 0.040870
[05:22:51.052] iteration 16332: loss: 0.077183, loss_s1: 0.063830, loss_fp: 0.001065, loss_freq: 0.049477
[05:22:51.715] iteration 16333: loss: 0.093158, loss_s1: 0.053355, loss_fp: 0.000954, loss_freq: 0.031216
[05:22:52.377] iteration 16334: loss: 0.033884, loss_s1: 0.021321, loss_fp: 0.001454, loss_freq: 0.017083
[05:22:53.040] iteration 16335: loss: 0.051163, loss_s1: 0.051647, loss_fp: 0.002120, loss_freq: 0.013588
[05:22:53.732] iteration 16336: loss: 0.046031, loss_s1: 0.027495, loss_fp: 0.002241, loss_freq: 0.025450
[05:22:54.351] iteration 16337: loss: 0.093274, loss_s1: 0.110945, loss_fp: 0.004720, loss_freq: 0.049204
[05:22:54.968] iteration 16338: loss: 0.041841, loss_s1: 0.022433, loss_fp: 0.000897, loss_freq: 0.010815
[05:22:55.600] iteration 16339: loss: 0.063314, loss_s1: 0.056988, loss_fp: 0.004328, loss_freq: 0.023145
[05:22:56.247] iteration 16340: loss: 0.075225, loss_s1: 0.082165, loss_fp: 0.002096, loss_freq: 0.021187
[05:22:56.866] iteration 16341: loss: 0.046881, loss_s1: 0.027657, loss_fp: 0.004121, loss_freq: 0.021692
[05:22:57.486] iteration 16342: loss: 0.066912, loss_s1: 0.065504, loss_fp: 0.003261, loss_freq: 0.041218
[05:22:58.134] iteration 16343: loss: 0.072206, loss_s1: 0.025571, loss_fp: 0.002033, loss_freq: 0.054247
[05:22:58.757] iteration 16344: loss: 0.057249, loss_s1: 0.041925, loss_fp: 0.001448, loss_freq: 0.031235
[05:22:59.393] iteration 16345: loss: 0.071482, loss_s1: 0.065543, loss_fp: 0.001251, loss_freq: 0.040173
[05:23:00.033] iteration 16346: loss: 0.066739, loss_s1: 0.051852, loss_fp: 0.001973, loss_freq: 0.046785
[05:23:00.664] iteration 16347: loss: 0.080220, loss_s1: 0.085723, loss_fp: 0.005415, loss_freq: 0.032684
[05:23:01.288] iteration 16348: loss: 0.082992, loss_s1: 0.073399, loss_fp: 0.002798, loss_freq: 0.039866
[05:23:01.915] iteration 16349: loss: 0.042845, loss_s1: 0.017516, loss_fp: 0.002649, loss_freq: 0.035346
[05:23:02.556] iteration 16350: loss: 0.168803, loss_s1: 0.249015, loss_fp: 0.005427, loss_freq: 0.043594
[05:23:03.186] iteration 16351: loss: 0.065145, loss_s1: 0.052765, loss_fp: 0.003436, loss_freq: 0.043978
[05:23:03.804] iteration 16352: loss: 0.105089, loss_s1: 0.097417, loss_fp: 0.003938, loss_freq: 0.061020
[05:23:04.422] iteration 16353: loss: 0.070799, loss_s1: 0.039603, loss_fp: 0.002633, loss_freq: 0.045083
[05:23:05.045] iteration 16354: loss: 0.057435, loss_s1: 0.024300, loss_fp: 0.008477, loss_freq: 0.008915
[05:23:05.674] iteration 16355: loss: 0.061034, loss_s1: 0.057560, loss_fp: 0.001301, loss_freq: 0.031215
[05:23:06.291] iteration 16356: loss: 0.065239, loss_s1: 0.030178, loss_fp: 0.000557, loss_freq: 0.025387
[05:23:06.907] iteration 16357: loss: 0.055926, loss_s1: 0.038767, loss_fp: 0.003673, loss_freq: 0.034855
[05:23:07.542] iteration 16358: loss: 0.047846, loss_s1: 0.058845, loss_fp: 0.001588, loss_freq: 0.005507
[05:23:08.177] iteration 16359: loss: 0.094979, loss_s1: 0.097588, loss_fp: 0.005284, loss_freq: 0.039869
[05:23:08.802] iteration 16360: loss: 0.077521, loss_s1: 0.060763, loss_fp: 0.001760, loss_freq: 0.044914
[05:23:09.434] iteration 16361: loss: 0.082005, loss_s1: 0.084366, loss_fp: 0.002334, loss_freq: 0.038757
[05:23:10.063] iteration 16362: loss: 0.066907, loss_s1: 0.081212, loss_fp: 0.001112, loss_freq: 0.014692
[05:23:10.695] iteration 16363: loss: 0.098926, loss_s1: 0.135148, loss_fp: 0.004942, loss_freq: 0.025768
[05:23:11.346] iteration 16364: loss: 0.093922, loss_s1: 0.074291, loss_fp: 0.007153, loss_freq: 0.081167
[05:23:11.987] iteration 16365: loss: 0.058233, loss_s1: 0.036861, loss_fp: 0.007774, loss_freq: 0.031894
[05:23:12.619] iteration 16366: loss: 0.097301, loss_s1: 0.106146, loss_fp: 0.008108, loss_freq: 0.033564
[05:23:13.286] iteration 16367: loss: 0.071638, loss_s1: 0.065785, loss_fp: 0.006579, loss_freq: 0.036634
[05:23:13.918] iteration 16368: loss: 0.052286, loss_s1: 0.051223, loss_fp: 0.002228, loss_freq: 0.018085
[05:23:14.553] iteration 16369: loss: 0.036237, loss_s1: 0.027201, loss_fp: 0.001207, loss_freq: 0.007922
[05:23:15.175] iteration 16370: loss: 0.039842, loss_s1: 0.025923, loss_fp: 0.001978, loss_freq: 0.014472
[05:23:15.812] iteration 16371: loss: 0.072685, loss_s1: 0.057545, loss_fp: 0.002311, loss_freq: 0.049190
[05:23:16.468] iteration 16372: loss: 0.067377, loss_s1: 0.085251, loss_fp: 0.000648, loss_freq: 0.024944
[05:23:17.126] iteration 16373: loss: 0.045030, loss_s1: 0.031754, loss_fp: 0.002780, loss_freq: 0.025700
[05:23:17.780] iteration 16374: loss: 0.064810, loss_s1: 0.045991, loss_fp: 0.002492, loss_freq: 0.044586
[05:23:18.440] iteration 16375: loss: 0.057730, loss_s1: 0.014286, loss_fp: 0.005594, loss_freq: 0.050502
[05:23:19.092] iteration 16376: loss: 0.045088, loss_s1: 0.020545, loss_fp: 0.004226, loss_freq: 0.022539
[05:23:19.741] iteration 16377: loss: 0.060877, loss_s1: 0.061085, loss_fp: 0.003144, loss_freq: 0.028223
[05:23:20.361] iteration 16378: loss: 0.062003, loss_s1: 0.071048, loss_fp: 0.002095, loss_freq: 0.011881
[05:23:20.988] iteration 16379: loss: 0.046358, loss_s1: 0.040710, loss_fp: 0.002313, loss_freq: 0.022459
[05:23:21.610] iteration 16380: loss: 0.072319, loss_s1: 0.063799, loss_fp: 0.003729, loss_freq: 0.035820
[05:23:22.225] iteration 16381: loss: 0.074172, loss_s1: 0.103705, loss_fp: 0.002074, loss_freq: 0.010954
[05:23:22.846] iteration 16382: loss: 0.058959, loss_s1: 0.042144, loss_fp: 0.001348, loss_freq: 0.035273
[05:23:23.491] iteration 16383: loss: 0.052265, loss_s1: 0.040205, loss_fp: 0.001574, loss_freq: 0.017070
[05:23:24.124] iteration 16384: loss: 0.035731, loss_s1: 0.030664, loss_fp: 0.001017, loss_freq: 0.009289
[05:23:24.744] iteration 16385: loss: 0.056699, loss_s1: 0.063710, loss_fp: 0.001918, loss_freq: 0.011967
[05:23:25.368] iteration 16386: loss: 0.043127, loss_s1: 0.027980, loss_fp: 0.001691, loss_freq: 0.023177
[05:23:25.999] iteration 16387: loss: 0.061509, loss_s1: 0.058900, loss_fp: 0.002939, loss_freq: 0.015567
[05:23:26.622] iteration 16388: loss: 0.103808, loss_s1: 0.114483, loss_fp: 0.004978, loss_freq: 0.057858
[05:23:27.246] iteration 16389: loss: 0.037259, loss_s1: 0.019275, loss_fp: 0.001919, loss_freq: 0.013449
[05:23:27.864] iteration 16390: loss: 0.051257, loss_s1: 0.033690, loss_fp: 0.002728, loss_freq: 0.034247
[05:23:28.483] iteration 16391: loss: 0.077284, loss_s1: 0.068771, loss_fp: 0.007387, loss_freq: 0.020499
[05:23:29.112] iteration 16392: loss: 0.069366, loss_s1: 0.054822, loss_fp: 0.003961, loss_freq: 0.033873
[05:23:29.742] iteration 16393: loss: 0.061251, loss_s1: 0.056993, loss_fp: 0.005766, loss_freq: 0.031196
[05:23:30.379] iteration 16394: loss: 0.058456, loss_s1: 0.060577, loss_fp: 0.003410, loss_freq: 0.016409
[05:23:31.002] iteration 16395: loss: 0.086527, loss_s1: 0.079030, loss_fp: 0.003965, loss_freq: 0.054440
[05:23:31.706] iteration 16396: loss: 0.066446, loss_s1: 0.033450, loss_fp: 0.008703, loss_freq: 0.047505
[05:23:32.376] iteration 16397: loss: 0.062408, loss_s1: 0.062604, loss_fp: 0.003915, loss_freq: 0.025664
[05:23:33.069] iteration 16398: loss: 0.085350, loss_s1: 0.065334, loss_fp: 0.002970, loss_freq: 0.055324
[05:23:33.717] iteration 16399: loss: 0.057474, loss_s1: 0.038927, loss_fp: 0.009121, loss_freq: 0.023655
[05:23:34.421] iteration 16400: loss: 0.073924, loss_s1: 0.063914, loss_fp: 0.003552, loss_freq: 0.029366
[05:23:38.019] iteration 16400 : mean_dice : 0.733710
[05:23:38.658] iteration 16401: loss: 0.071707, loss_s1: 0.068873, loss_fp: 0.003344, loss_freq: 0.019621
[05:23:39.283] iteration 16402: loss: 0.065823, loss_s1: 0.033741, loss_fp: 0.002778, loss_freq: 0.058935
[05:23:39.900] iteration 16403: loss: 0.069677, loss_s1: 0.054392, loss_fp: 0.003225, loss_freq: 0.023053
[05:23:40.526] iteration 16404: loss: 0.084811, loss_s1: 0.119470, loss_fp: 0.007526, loss_freq: 0.014128
[05:23:41.148] iteration 16405: loss: 0.064186, loss_s1: 0.062003, loss_fp: 0.001576, loss_freq: 0.024602
[05:23:41.792] iteration 16406: loss: 0.040455, loss_s1: 0.026599, loss_fp: 0.002196, loss_freq: 0.017212
[05:23:42.410] iteration 16407: loss: 0.065362, loss_s1: 0.066181, loss_fp: 0.005493, loss_freq: 0.021142
[05:23:43.092] iteration 16408: loss: 0.055889, loss_s1: 0.066903, loss_fp: 0.002101, loss_freq: 0.009664
[05:23:43.767] iteration 16409: loss: 0.070610, loss_s1: 0.062490, loss_fp: 0.006179, loss_freq: 0.036490
[05:23:44.435] iteration 16410: loss: 0.066123, loss_s1: 0.081042, loss_fp: 0.002390, loss_freq: 0.008443
[05:23:45.104] iteration 16411: loss: 0.064659, loss_s1: 0.064057, loss_fp: 0.002703, loss_freq: 0.017962
[05:23:45.772] iteration 16412: loss: 0.045708, loss_s1: 0.051682, loss_fp: 0.002042, loss_freq: 0.013010
[05:23:46.442] iteration 16413: loss: 0.055146, loss_s1: 0.039166, loss_fp: 0.001742, loss_freq: 0.022742
[05:23:47.102] iteration 16414: loss: 0.060922, loss_s1: 0.064312, loss_fp: 0.002216, loss_freq: 0.016525
[05:23:47.720] iteration 16415: loss: 0.061131, loss_s1: 0.057572, loss_fp: 0.006886, loss_freq: 0.018504
[05:23:48.357] iteration 16416: loss: 0.067970, loss_s1: 0.053465, loss_fp: 0.002238, loss_freq: 0.048947
[05:23:48.991] iteration 16417: loss: 0.090023, loss_s1: 0.080614, loss_fp: 0.001408, loss_freq: 0.051023
[05:23:49.619] iteration 16418: loss: 0.061843, loss_s1: 0.035440, loss_fp: 0.002434, loss_freq: 0.037352
[05:23:50.247] iteration 16419: loss: 0.065368, loss_s1: 0.057323, loss_fp: 0.001984, loss_freq: 0.041498
[05:23:50.881] iteration 16420: loss: 0.060101, loss_s1: 0.045650, loss_fp: 0.006963, loss_freq: 0.029501
[05:23:51.499] iteration 16421: loss: 0.076647, loss_s1: 0.095161, loss_fp: 0.003015, loss_freq: 0.028205
[05:23:52.142] iteration 16422: loss: 0.059023, loss_s1: 0.032278, loss_fp: 0.008189, loss_freq: 0.034959
[05:23:52.776] iteration 16423: loss: 0.042025, loss_s1: 0.022010, loss_fp: 0.002251, loss_freq: 0.024561
[05:23:53.405] iteration 16424: loss: 0.046922, loss_s1: 0.023764, loss_fp: 0.002668, loss_freq: 0.022110
[05:23:54.036] iteration 16425: loss: 0.036437, loss_s1: 0.013479, loss_fp: 0.001480, loss_freq: 0.029201
[05:23:54.680] iteration 16426: loss: 0.076659, loss_s1: 0.065959, loss_fp: 0.001744, loss_freq: 0.021207
[05:23:55.324] iteration 16427: loss: 0.085448, loss_s1: 0.095826, loss_fp: 0.003248, loss_freq: 0.027212
[05:23:55.945] iteration 16428: loss: 0.060558, loss_s1: 0.042075, loss_fp: 0.002494, loss_freq: 0.042132
[05:23:56.572] iteration 16429: loss: 0.108570, loss_s1: 0.066661, loss_fp: 0.004585, loss_freq: 0.110443
[05:23:57.207] iteration 16430: loss: 0.042566, loss_s1: 0.026480, loss_fp: 0.003082, loss_freq: 0.022294
[05:23:57.837] iteration 16431: loss: 0.070876, loss_s1: 0.059045, loss_fp: 0.005166, loss_freq: 0.024275
[05:23:58.473] iteration 16432: loss: 0.053407, loss_s1: 0.034148, loss_fp: 0.006100, loss_freq: 0.018290
[05:23:59.100] iteration 16433: loss: 0.050952, loss_s1: 0.039681, loss_fp: 0.003849, loss_freq: 0.027810
[05:23:59.721] iteration 16434: loss: 0.047366, loss_s1: 0.026553, loss_fp: 0.024526, loss_freq: 0.012439
[05:24:00.347] iteration 16435: loss: 0.088644, loss_s1: 0.062461, loss_fp: 0.009911, loss_freq: 0.045517
[05:24:00.981] iteration 16436: loss: 0.084560, loss_s1: 0.047434, loss_fp: 0.006917, loss_freq: 0.049890
[05:24:01.619] iteration 16437: loss: 0.050930, loss_s1: 0.047234, loss_fp: 0.002074, loss_freq: 0.016322
[05:24:02.241] iteration 16438: loss: 0.052261, loss_s1: 0.024157, loss_fp: 0.007563, loss_freq: 0.038640
[05:24:02.879] iteration 16439: loss: 0.094543, loss_s1: 0.088004, loss_fp: 0.004513, loss_freq: 0.063848
[05:24:03.533] iteration 16440: loss: 0.061435, loss_s1: 0.051823, loss_fp: 0.000840, loss_freq: 0.034086
[05:24:04.164] iteration 16441: loss: 0.043881, loss_s1: 0.037148, loss_fp: 0.002733, loss_freq: 0.012115
[05:24:04.786] iteration 16442: loss: 0.070215, loss_s1: 0.090316, loss_fp: 0.000981, loss_freq: 0.022590
[05:24:05.408] iteration 16443: loss: 0.098268, loss_s1: 0.089814, loss_fp: 0.002537, loss_freq: 0.062906
[05:24:06.028] iteration 16444: loss: 0.063450, loss_s1: 0.077362, loss_fp: 0.002057, loss_freq: 0.012730
[05:24:06.658] iteration 16445: loss: 0.055845, loss_s1: 0.031710, loss_fp: 0.001958, loss_freq: 0.040378
[05:24:07.344] iteration 16446: loss: 0.051404, loss_s1: 0.041614, loss_fp: 0.001021, loss_freq: 0.023536
[05:24:08.016] iteration 16447: loss: 0.071444, loss_s1: 0.042288, loss_fp: 0.002177, loss_freq: 0.068884
[05:24:08.687] iteration 16448: loss: 0.061198, loss_s1: 0.025427, loss_fp: 0.001447, loss_freq: 0.049992
[05:24:09.327] iteration 16449: loss: 0.044246, loss_s1: 0.026247, loss_fp: 0.006888, loss_freq: 0.025202
[05:24:09.955] iteration 16450: loss: 0.063331, loss_s1: 0.035108, loss_fp: 0.002427, loss_freq: 0.057292
[05:24:10.582] iteration 16451: loss: 0.036522, loss_s1: 0.030871, loss_fp: 0.002802, loss_freq: 0.014374
[05:24:11.202] iteration 16452: loss: 0.049700, loss_s1: 0.028631, loss_fp: 0.001709, loss_freq: 0.017089
[05:24:11.830] iteration 16453: loss: 0.068735, loss_s1: 0.045559, loss_fp: 0.001943, loss_freq: 0.040297
[05:24:12.458] iteration 16454: loss: 0.048441, loss_s1: 0.044228, loss_fp: 0.005998, loss_freq: 0.014007
[05:24:13.164] iteration 16455: loss: 0.103619, loss_s1: 0.071701, loss_fp: 0.001655, loss_freq: 0.099247
[05:24:13.849] iteration 16456: loss: 0.044875, loss_s1: 0.022681, loss_fp: 0.005298, loss_freq: 0.029901
[05:24:14.532] iteration 16457: loss: 0.057544, loss_s1: 0.052331, loss_fp: 0.002130, loss_freq: 0.017739
[05:24:15.202] iteration 16458: loss: 0.055319, loss_s1: 0.038892, loss_fp: 0.012854, loss_freq: 0.023416
[05:24:15.883] iteration 16459: loss: 0.100782, loss_s1: 0.078342, loss_fp: 0.004119, loss_freq: 0.072852
[05:24:16.557] iteration 16460: loss: 0.054966, loss_s1: 0.059213, loss_fp: 0.002306, loss_freq: 0.023552
[05:24:17.188] iteration 16461: loss: 0.047813, loss_s1: 0.038579, loss_fp: 0.005824, loss_freq: 0.010814
[05:24:17.810] iteration 16462: loss: 0.063896, loss_s1: 0.038257, loss_fp: 0.002281, loss_freq: 0.030275
[05:24:18.429] iteration 16463: loss: 0.047320, loss_s1: 0.037881, loss_fp: 0.002932, loss_freq: 0.021670
[05:24:19.070] iteration 16464: loss: 0.069279, loss_s1: 0.066968, loss_fp: 0.004113, loss_freq: 0.026602
[05:24:19.682] iteration 16465: loss: 0.047524, loss_s1: 0.031897, loss_fp: 0.002128, loss_freq: 0.018100
[05:24:20.305] iteration 16466: loss: 0.053685, loss_s1: 0.031048, loss_fp: 0.006374, loss_freq: 0.016598
[05:24:20.946] iteration 16467: loss: 0.060515, loss_s1: 0.051056, loss_fp: 0.007829, loss_freq: 0.021540
[05:24:21.567] iteration 16468: loss: 0.098129, loss_s1: 0.120391, loss_fp: 0.005723, loss_freq: 0.034644
[05:24:22.192] iteration 16469: loss: 0.061664, loss_s1: 0.064913, loss_fp: 0.002909, loss_freq: 0.032323
[05:24:22.835] iteration 16470: loss: 0.069169, loss_s1: 0.064637, loss_fp: 0.002753, loss_freq: 0.027957
[05:24:23.759] iteration 16471: loss: 0.067974, loss_s1: 0.057029, loss_fp: 0.010985, loss_freq: 0.021164
[05:24:24.491] iteration 16472: loss: 0.101166, loss_s1: 0.082231, loss_fp: 0.010666, loss_freq: 0.064125
[05:24:25.276] iteration 16473: loss: 0.069764, loss_s1: 0.053866, loss_fp: 0.005815, loss_freq: 0.037416
[05:24:25.963] iteration 16474: loss: 0.089263, loss_s1: 0.079237, loss_fp: 0.004933, loss_freq: 0.052281
[05:24:26.645] iteration 16475: loss: 0.080106, loss_s1: 0.070651, loss_fp: 0.003017, loss_freq: 0.045781
[05:24:27.323] iteration 16476: loss: 0.070981, loss_s1: 0.071844, loss_fp: 0.002524, loss_freq: 0.009860
[05:24:28.007] iteration 16477: loss: 0.035887, loss_s1: 0.030356, loss_fp: 0.003559, loss_freq: 0.017147
[05:24:28.701] iteration 16478: loss: 0.100830, loss_s1: 0.071262, loss_fp: 0.003367, loss_freq: 0.092773
[05:24:29.345] iteration 16479: loss: 0.057667, loss_s1: 0.049812, loss_fp: 0.005085, loss_freq: 0.024073
[05:24:29.983] iteration 16480: loss: 0.088848, loss_s1: 0.086761, loss_fp: 0.005314, loss_freq: 0.043004
[05:24:30.635] iteration 16481: loss: 0.044057, loss_s1: 0.044886, loss_fp: 0.001377, loss_freq: 0.010256
[05:24:31.281] iteration 16482: loss: 0.065858, loss_s1: 0.049139, loss_fp: 0.003906, loss_freq: 0.049783
[05:24:31.983] iteration 16483: loss: 0.041271, loss_s1: 0.024455, loss_fp: 0.000757, loss_freq: 0.004955
[05:24:32.692] iteration 16484: loss: 0.050123, loss_s1: 0.044283, loss_fp: 0.002155, loss_freq: 0.023700
[05:24:33.371] iteration 16485: loss: 0.041990, loss_s1: 0.033883, loss_fp: 0.001744, loss_freq: 0.014342
[05:24:34.011] iteration 16486: loss: 0.093983, loss_s1: 0.099958, loss_fp: 0.004892, loss_freq: 0.052121
[05:24:34.648] iteration 16487: loss: 0.072256, loss_s1: 0.056354, loss_fp: 0.001844, loss_freq: 0.038952
[05:24:35.306] iteration 16488: loss: 0.073705, loss_s1: 0.066852, loss_fp: 0.005688, loss_freq: 0.037492
[05:24:35.943] iteration 16489: loss: 0.119655, loss_s1: 0.107133, loss_fp: 0.007007, loss_freq: 0.062593
[05:24:36.564] iteration 16490: loss: 0.061495, loss_s1: 0.048067, loss_fp: 0.006087, loss_freq: 0.028770
[05:24:37.578] iteration 16491: loss: 0.082857, loss_s1: 0.082462, loss_fp: 0.006381, loss_freq: 0.033233
[05:24:38.257] iteration 16492: loss: 0.047654, loss_s1: 0.010641, loss_fp: 0.002830, loss_freq: 0.037408
[05:24:38.936] iteration 16493: loss: 0.063337, loss_s1: 0.046802, loss_fp: 0.004473, loss_freq: 0.034430
[05:24:39.616] iteration 16494: loss: 0.046994, loss_s1: 0.030881, loss_fp: 0.002335, loss_freq: 0.019611
[05:24:40.306] iteration 16495: loss: 0.062210, loss_s1: 0.068645, loss_fp: 0.009735, loss_freq: 0.015196
[05:24:40.997] iteration 16496: loss: 0.081999, loss_s1: 0.055819, loss_fp: 0.006607, loss_freq: 0.058515
[05:24:41.629] iteration 16497: loss: 0.056044, loss_s1: 0.026916, loss_fp: 0.004088, loss_freq: 0.045171
[05:24:42.270] iteration 16498: loss: 0.044251, loss_s1: 0.028940, loss_fp: 0.002474, loss_freq: 0.015567
[05:24:42.914] iteration 16499: loss: 0.035029, loss_s1: 0.023988, loss_fp: 0.001835, loss_freq: 0.014617
[05:24:43.545] iteration 16500: loss: 0.081244, loss_s1: 0.057249, loss_fp: 0.009653, loss_freq: 0.051037
[05:24:44.219] iteration 16501: loss: 0.079948, loss_s1: 0.060890, loss_fp: 0.004345, loss_freq: 0.046444
[05:24:44.911] iteration 16502: loss: 0.100393, loss_s1: 0.108046, loss_fp: 0.003982, loss_freq: 0.049877
[05:24:45.574] iteration 16503: loss: 0.076213, loss_s1: 0.062460, loss_fp: 0.002626, loss_freq: 0.045808
[05:24:46.282] iteration 16504: loss: 0.067599, loss_s1: 0.031386, loss_fp: 0.006982, loss_freq: 0.062979
[05:24:47.000] iteration 16505: loss: 0.065048, loss_s1: 0.067610, loss_fp: 0.008151, loss_freq: 0.015658
[05:24:47.627] iteration 16506: loss: 0.050044, loss_s1: 0.039796, loss_fp: 0.002826, loss_freq: 0.024663
[05:24:48.255] iteration 16507: loss: 0.146171, loss_s1: 0.174415, loss_fp: 0.004366, loss_freq: 0.091020
[05:24:48.898] iteration 16508: loss: 0.047776, loss_s1: 0.050063, loss_fp: 0.002551, loss_freq: 0.004850
[05:24:49.526] iteration 16509: loss: 0.079062, loss_s1: 0.094651, loss_fp: 0.003980, loss_freq: 0.025158
[05:24:50.160] iteration 16510: loss: 0.084984, loss_s1: 0.081995, loss_fp: 0.002486, loss_freq: 0.023444
[05:24:50.797] iteration 16511: loss: 0.073644, loss_s1: 0.064173, loss_fp: 0.002551, loss_freq: 0.034755
[05:24:51.416] iteration 16512: loss: 0.062788, loss_s1: 0.068911, loss_fp: 0.002092, loss_freq: 0.032141
[05:24:52.038] iteration 16513: loss: 0.063810, loss_s1: 0.030974, loss_fp: 0.005060, loss_freq: 0.041503
[05:24:52.664] iteration 16514: loss: 0.040391, loss_s1: 0.028473, loss_fp: 0.001144, loss_freq: 0.020547
[05:24:53.302] iteration 16515: loss: 0.056115, loss_s1: 0.044983, loss_fp: 0.002406, loss_freq: 0.021149
[05:24:53.933] iteration 16516: loss: 0.072720, loss_s1: 0.057511, loss_fp: 0.004346, loss_freq: 0.026455
[05:24:54.580] iteration 16517: loss: 0.065413, loss_s1: 0.047540, loss_fp: 0.004047, loss_freq: 0.024143
[05:24:55.226] iteration 16518: loss: 0.088525, loss_s1: 0.050727, loss_fp: 0.006323, loss_freq: 0.075152
[05:24:55.851] iteration 16519: loss: 0.068328, loss_s1: 0.057280, loss_fp: 0.002626, loss_freq: 0.018745
[05:24:56.480] iteration 16520: loss: 0.107080, loss_s1: 0.116264, loss_fp: 0.003871, loss_freq: 0.050337
[05:24:57.099] iteration 16521: loss: 0.077750, loss_s1: 0.074451, loss_fp: 0.002932, loss_freq: 0.039420
[05:24:57.719] iteration 16522: loss: 0.057991, loss_s1: 0.028146, loss_fp: 0.008341, loss_freq: 0.038610
[05:24:58.350] iteration 16523: loss: 0.071432, loss_s1: 0.041759, loss_fp: 0.002507, loss_freq: 0.061209
[05:24:58.972] iteration 16524: loss: 0.048267, loss_s1: 0.035307, loss_fp: 0.004425, loss_freq: 0.017413
[05:24:59.593] iteration 16525: loss: 0.057597, loss_s1: 0.050517, loss_fp: 0.003874, loss_freq: 0.028331
[05:25:00.230] iteration 16526: loss: 0.044687, loss_s1: 0.021658, loss_fp: 0.001343, loss_freq: 0.020209
[05:25:00.863] iteration 16527: loss: 0.057702, loss_s1: 0.041195, loss_fp: 0.002933, loss_freq: 0.025129
[05:25:01.480] iteration 16528: loss: 0.052812, loss_s1: 0.036671, loss_fp: 0.004070, loss_freq: 0.019975
[05:25:02.103] iteration 16529: loss: 0.076786, loss_s1: 0.085170, loss_fp: 0.003543, loss_freq: 0.025185
[05:25:02.734] iteration 16530: loss: 0.068095, loss_s1: 0.051958, loss_fp: 0.007217, loss_freq: 0.039490
[05:25:03.356] iteration 16531: loss: 0.070140, loss_s1: 0.062757, loss_fp: 0.007224, loss_freq: 0.021637
[05:25:03.979] iteration 16532: loss: 0.057926, loss_s1: 0.047147, loss_fp: 0.003260, loss_freq: 0.025972
[05:25:04.624] iteration 16533: loss: 0.082055, loss_s1: 0.094977, loss_fp: 0.005102, loss_freq: 0.037203
[05:25:05.265] iteration 16534: loss: 0.098500, loss_s1: 0.111526, loss_fp: 0.010895, loss_freq: 0.042590
[05:25:05.923] iteration 16535: loss: 0.074780, loss_s1: 0.047835, loss_fp: 0.004225, loss_freq: 0.054595
[05:25:06.570] iteration 16536: loss: 0.070546, loss_s1: 0.073337, loss_fp: 0.005538, loss_freq: 0.026526
[05:25:07.212] iteration 16537: loss: 0.058247, loss_s1: 0.045408, loss_fp: 0.004876, loss_freq: 0.030277
[05:25:07.853] iteration 16538: loss: 0.075263, loss_s1: 0.083952, loss_fp: 0.001577, loss_freq: 0.036729
[05:25:08.497] iteration 16539: loss: 0.031990, loss_s1: 0.019359, loss_fp: 0.006026, loss_freq: 0.005741
[05:25:09.135] iteration 16540: loss: 0.050128, loss_s1: 0.034198, loss_fp: 0.001151, loss_freq: 0.022363
[05:25:09.805] iteration 16541: loss: 0.037366, loss_s1: 0.014155, loss_fp: 0.002180, loss_freq: 0.019343
[05:25:10.447] iteration 16542: loss: 0.040074, loss_s1: 0.039949, loss_fp: 0.003107, loss_freq: 0.013108
[05:25:11.080] iteration 16543: loss: 0.066464, loss_s1: 0.057615, loss_fp: 0.004403, loss_freq: 0.037089
[05:25:11.714] iteration 16544: loss: 0.095127, loss_s1: 0.074508, loss_fp: 0.003450, loss_freq: 0.045398
[05:25:12.344] iteration 16545: loss: 0.059032, loss_s1: 0.061359, loss_fp: 0.003567, loss_freq: 0.010680
[05:25:12.966] iteration 16546: loss: 0.057055, loss_s1: 0.037452, loss_fp: 0.001127, loss_freq: 0.035140
[05:25:13.611] iteration 16547: loss: 0.059982, loss_s1: 0.040010, loss_fp: 0.002255, loss_freq: 0.041921
[05:25:14.306] iteration 16548: loss: 0.060409, loss_s1: 0.032567, loss_fp: 0.003502, loss_freq: 0.043816
[05:25:14.926] iteration 16549: loss: 0.059399, loss_s1: 0.044913, loss_fp: 0.002208, loss_freq: 0.030191
[05:25:15.606] iteration 16550: loss: 0.061289, loss_s1: 0.035199, loss_fp: 0.005232, loss_freq: 0.038600
[05:25:16.297] iteration 16551: loss: 0.042225, loss_s1: 0.034523, loss_fp: 0.004260, loss_freq: 0.015412
[05:25:16.931] iteration 16552: loss: 0.083827, loss_s1: 0.052018, loss_fp: 0.002063, loss_freq: 0.042385
[05:25:17.556] iteration 16553: loss: 0.049847, loss_s1: 0.028708, loss_fp: 0.001222, loss_freq: 0.019562
[05:25:18.223] iteration 16554: loss: 0.049481, loss_s1: 0.046492, loss_fp: 0.002392, loss_freq: 0.021771
[05:25:18.883] iteration 16555: loss: 0.093577, loss_s1: 0.085299, loss_fp: 0.001571, loss_freq: 0.014861
[05:25:19.546] iteration 16556: loss: 0.052254, loss_s1: 0.048634, loss_fp: 0.001884, loss_freq: 0.029033
[05:25:20.211] iteration 16557: loss: 0.046399, loss_s1: 0.025370, loss_fp: 0.000815, loss_freq: 0.024881
[05:25:20.880] iteration 16558: loss: 0.118293, loss_s1: 0.111379, loss_fp: 0.005879, loss_freq: 0.060207
[05:25:21.498] iteration 16559: loss: 0.061588, loss_s1: 0.027128, loss_fp: 0.006256, loss_freq: 0.027954
[05:25:22.125] iteration 16560: loss: 0.052188, loss_s1: 0.051245, loss_fp: 0.009160, loss_freq: 0.014263
[05:25:22.743] iteration 16561: loss: 0.085070, loss_s1: 0.069232, loss_fp: 0.004643, loss_freq: 0.047719
[05:25:23.411] iteration 16562: loss: 0.059482, loss_s1: 0.056637, loss_fp: 0.002483, loss_freq: 0.014817
[05:25:24.084] iteration 16563: loss: 0.056739, loss_s1: 0.048804, loss_fp: 0.004173, loss_freq: 0.028469
[05:25:24.735] iteration 16564: loss: 0.076449, loss_s1: 0.071082, loss_fp: 0.005807, loss_freq: 0.037331
[05:25:25.354] iteration 16565: loss: 0.091071, loss_s1: 0.059630, loss_fp: 0.003216, loss_freq: 0.047428
[05:25:25.976] iteration 16566: loss: 0.090111, loss_s1: 0.082552, loss_fp: 0.005110, loss_freq: 0.042789
[05:25:26.604] iteration 16567: loss: 0.064628, loss_s1: 0.041184, loss_fp: 0.001476, loss_freq: 0.032131
[05:25:27.232] iteration 16568: loss: 0.093900, loss_s1: 0.071788, loss_fp: 0.006684, loss_freq: 0.056536
[05:25:27.895] iteration 16569: loss: 0.062465, loss_s1: 0.041449, loss_fp: 0.015775, loss_freq: 0.037575
[05:25:28.521] iteration 16570: loss: 0.069982, loss_s1: 0.043350, loss_fp: 0.004084, loss_freq: 0.042177
[05:25:29.152] iteration 16571: loss: 0.072242, loss_s1: 0.079437, loss_fp: 0.011346, loss_freq: 0.009244
[05:25:29.794] iteration 16572: loss: 0.061295, loss_s1: 0.043725, loss_fp: 0.002539, loss_freq: 0.045266
[05:25:30.422] iteration 16573: loss: 0.046756, loss_s1: 0.036647, loss_fp: 0.002608, loss_freq: 0.018869
[05:25:31.051] iteration 16574: loss: 0.054152, loss_s1: 0.045845, loss_fp: 0.002059, loss_freq: 0.023343
[05:25:31.696] iteration 16575: loss: 0.064081, loss_s1: 0.065099, loss_fp: 0.003262, loss_freq: 0.014916
[05:25:32.311] iteration 16576: loss: 0.045304, loss_s1: 0.037852, loss_fp: 0.003414, loss_freq: 0.014190
[05:25:32.943] iteration 16577: loss: 0.061936, loss_s1: 0.071137, loss_fp: 0.002262, loss_freq: 0.018254
[05:25:33.571] iteration 16578: loss: 0.085140, loss_s1: 0.070109, loss_fp: 0.006103, loss_freq: 0.029693
[05:25:34.206] iteration 16579: loss: 0.061610, loss_s1: 0.045466, loss_fp: 0.002674, loss_freq: 0.031059
[05:25:34.827] iteration 16580: loss: 0.053163, loss_s1: 0.022388, loss_fp: 0.002881, loss_freq: 0.022254
[05:25:35.454] iteration 16581: loss: 0.076896, loss_s1: 0.058943, loss_fp: 0.005787, loss_freq: 0.046861
[05:25:36.077] iteration 16582: loss: 0.095348, loss_s1: 0.101860, loss_fp: 0.002520, loss_freq: 0.039693
[05:25:36.713] iteration 16583: loss: 0.069279, loss_s1: 0.061401, loss_fp: 0.018551, loss_freq: 0.020886
[05:25:37.361] iteration 16584: loss: 0.085996, loss_s1: 0.092938, loss_fp: 0.001389, loss_freq: 0.028442
[05:25:37.985] iteration 16585: loss: 0.056585, loss_s1: 0.031030, loss_fp: 0.003054, loss_freq: 0.043361
[05:25:38.613] iteration 16586: loss: 0.087817, loss_s1: 0.114672, loss_fp: 0.002440, loss_freq: 0.030471
[05:25:39.234] iteration 16587: loss: 0.108782, loss_s1: 0.098572, loss_fp: 0.011389, loss_freq: 0.069040
[05:25:39.860] iteration 16588: loss: 0.080264, loss_s1: 0.043520, loss_fp: 0.005061, loss_freq: 0.063746
[05:25:40.486] iteration 16589: loss: 0.076603, loss_s1: 0.071874, loss_fp: 0.004175, loss_freq: 0.036686
[05:25:41.113] iteration 16590: loss: 0.050117, loss_s1: 0.027641, loss_fp: 0.003555, loss_freq: 0.028230
[05:25:41.738] iteration 16591: loss: 0.058525, loss_s1: 0.057849, loss_fp: 0.001567, loss_freq: 0.024623
[05:25:42.360] iteration 16592: loss: 0.045368, loss_s1: 0.026728, loss_fp: 0.003933, loss_freq: 0.005790
[05:25:43.008] iteration 16593: loss: 0.047861, loss_s1: 0.023264, loss_fp: 0.003475, loss_freq: 0.028819
[05:25:43.631] iteration 16594: loss: 0.052102, loss_s1: 0.033093, loss_fp: 0.001438, loss_freq: 0.020919
[05:25:44.253] iteration 16595: loss: 0.042384, loss_s1: 0.032903, loss_fp: 0.002882, loss_freq: 0.016211
[05:25:44.875] iteration 16596: loss: 0.069726, loss_s1: 0.055399, loss_fp: 0.002481, loss_freq: 0.023060
[05:25:45.501] iteration 16597: loss: 0.049357, loss_s1: 0.039926, loss_fp: 0.002733, loss_freq: 0.019245
[05:25:46.123] iteration 16598: loss: 0.040044, loss_s1: 0.027907, loss_fp: 0.002957, loss_freq: 0.020729
[05:25:46.761] iteration 16599: loss: 0.116029, loss_s1: 0.097659, loss_fp: 0.006030, loss_freq: 0.095739
[05:25:47.385] iteration 16600: loss: 0.058541, loss_s1: 0.057003, loss_fp: 0.000614, loss_freq: 0.021039
[05:25:50.680] iteration 16600 : mean_dice : 0.724532
[05:25:51.337] iteration 16601: loss: 0.068650, loss_s1: 0.060796, loss_fp: 0.001523, loss_freq: 0.023578
[05:25:51.982] iteration 16602: loss: 0.068625, loss_s1: 0.043419, loss_fp: 0.004956, loss_freq: 0.046527
[05:25:52.604] iteration 16603: loss: 0.081869, loss_s1: 0.069711, loss_fp: 0.002923, loss_freq: 0.035129
[05:25:53.231] iteration 16604: loss: 0.039725, loss_s1: 0.032633, loss_fp: 0.003795, loss_freq: 0.012932
[05:25:53.853] iteration 16605: loss: 0.066446, loss_s1: 0.040894, loss_fp: 0.004644, loss_freq: 0.043423
[05:25:54.485] iteration 16606: loss: 0.067739, loss_s1: 0.047663, loss_fp: 0.002471, loss_freq: 0.036996
[05:25:55.109] iteration 16607: loss: 0.076583, loss_s1: 0.064037, loss_fp: 0.002386, loss_freq: 0.028396
[05:25:55.743] iteration 16608: loss: 0.073075, loss_s1: 0.057419, loss_fp: 0.004001, loss_freq: 0.050075
[05:25:56.360] iteration 16609: loss: 0.074694, loss_s1: 0.053651, loss_fp: 0.003562, loss_freq: 0.045330
[05:25:56.988] iteration 16610: loss: 0.093481, loss_s1: 0.118910, loss_fp: 0.004315, loss_freq: 0.019185
[05:25:57.612] iteration 16611: loss: 0.047552, loss_s1: 0.040378, loss_fp: 0.001339, loss_freq: 0.013643
[05:25:58.243] iteration 16612: loss: 0.041881, loss_s1: 0.030326, loss_fp: 0.001392, loss_freq: 0.031293
[05:25:58.920] iteration 16613: loss: 0.065997, loss_s1: 0.025338, loss_fp: 0.002005, loss_freq: 0.066474
[05:25:59.570] iteration 16614: loss: 0.046592, loss_s1: 0.039034, loss_fp: 0.002777, loss_freq: 0.016133
[05:26:00.195] iteration 16615: loss: 0.055799, loss_s1: 0.031270, loss_fp: 0.002064, loss_freq: 0.037340
[05:26:00.829] iteration 16616: loss: 0.091468, loss_s1: 0.088208, loss_fp: 0.002649, loss_freq: 0.055946
[05:26:01.461] iteration 16617: loss: 0.088745, loss_s1: 0.084070, loss_fp: 0.002115, loss_freq: 0.059056
[05:26:02.080] iteration 16618: loss: 0.045258, loss_s1: 0.028009, loss_fp: 0.007590, loss_freq: 0.010132
[05:26:02.701] iteration 16619: loss: 0.058436, loss_s1: 0.040534, loss_fp: 0.008426, loss_freq: 0.040959
[05:26:03.368] iteration 16620: loss: 0.081085, loss_s1: 0.057747, loss_fp: 0.000682, loss_freq: 0.072273
[05:26:03.984] iteration 16621: loss: 0.039432, loss_s1: 0.029077, loss_fp: 0.003609, loss_freq: 0.022053
[05:26:04.605] iteration 16622: loss: 0.067398, loss_s1: 0.066320, loss_fp: 0.002553, loss_freq: 0.024489
[05:26:05.246] iteration 16623: loss: 0.124110, loss_s1: 0.129591, loss_fp: 0.022534, loss_freq: 0.057726
[05:26:05.891] iteration 16624: loss: 0.084633, loss_s1: 0.106491, loss_fp: 0.004133, loss_freq: 0.029645
[05:26:06.536] iteration 16625: loss: 0.094819, loss_s1: 0.102026, loss_fp: 0.001839, loss_freq: 0.050045
[05:26:07.171] iteration 16626: loss: 0.039731, loss_s1: 0.026527, loss_fp: 0.005355, loss_freq: 0.013999
[05:26:07.801] iteration 16627: loss: 0.088023, loss_s1: 0.086548, loss_fp: 0.001934, loss_freq: 0.027615
[05:26:08.442] iteration 16628: loss: 0.089602, loss_s1: 0.093135, loss_fp: 0.001424, loss_freq: 0.049226
[05:26:09.074] iteration 16629: loss: 0.119993, loss_s1: 0.128894, loss_fp: 0.007521, loss_freq: 0.062007
[05:26:09.700] iteration 16630: loss: 0.057575, loss_s1: 0.060214, loss_fp: 0.005414, loss_freq: 0.027405
[05:26:10.327] iteration 16631: loss: 0.080333, loss_s1: 0.069168, loss_fp: 0.002721, loss_freq: 0.042170
[05:26:10.942] iteration 16632: loss: 0.060163, loss_s1: 0.053356, loss_fp: 0.003981, loss_freq: 0.021621
[05:26:11.580] iteration 16633: loss: 0.061257, loss_s1: 0.063934, loss_fp: 0.002550, loss_freq: 0.026592
[05:26:12.206] iteration 16634: loss: 0.067359, loss_s1: 0.053060, loss_fp: 0.004678, loss_freq: 0.034245
[05:26:12.839] iteration 16635: loss: 0.025437, loss_s1: 0.010421, loss_fp: 0.002892, loss_freq: 0.007243
[05:26:13.466] iteration 16636: loss: 0.080166, loss_s1: 0.072492, loss_fp: 0.007255, loss_freq: 0.038850
[05:26:14.097] iteration 16637: loss: 0.064212, loss_s1: 0.041015, loss_fp: 0.002424, loss_freq: 0.038462
[05:26:14.742] iteration 16638: loss: 0.085945, loss_s1: 0.056602, loss_fp: 0.013944, loss_freq: 0.071312
[05:26:15.365] iteration 16639: loss: 0.121606, loss_s1: 0.171947, loss_fp: 0.003924, loss_freq: 0.039867
[05:26:16.000] iteration 16640: loss: 0.054763, loss_s1: 0.042186, loss_fp: 0.003225, loss_freq: 0.021410
[05:26:16.637] iteration 16641: loss: 0.103091, loss_s1: 0.100493, loss_fp: 0.012553, loss_freq: 0.049111
[05:26:17.267] iteration 16642: loss: 0.091054, loss_s1: 0.073291, loss_fp: 0.008674, loss_freq: 0.059275
[05:26:17.896] iteration 16643: loss: 0.087936, loss_s1: 0.054641, loss_fp: 0.002629, loss_freq: 0.073458
[05:26:18.528] iteration 16644: loss: 0.070987, loss_s1: 0.054091, loss_fp: 0.005404, loss_freq: 0.037376
[05:26:19.154] iteration 16645: loss: 0.070505, loss_s1: 0.057778, loss_fp: 0.004169, loss_freq: 0.026381
[05:26:19.766] iteration 16646: loss: 0.066913, loss_s1: 0.056271, loss_fp: 0.002190, loss_freq: 0.024082
[05:26:20.386] iteration 16647: loss: 0.075643, loss_s1: 0.046573, loss_fp: 0.006096, loss_freq: 0.053245
[05:26:21.009] iteration 16648: loss: 0.110482, loss_s1: 0.101019, loss_fp: 0.002043, loss_freq: 0.061019
[05:26:21.667] iteration 16649: loss: 0.089818, loss_s1: 0.070691, loss_fp: 0.007556, loss_freq: 0.066481
[05:26:22.285] iteration 16650: loss: 0.067033, loss_s1: 0.060211, loss_fp: 0.004774, loss_freq: 0.026021
[05:26:22.922] iteration 16651: loss: 0.039751, loss_s1: 0.028277, loss_fp: 0.001854, loss_freq: 0.018200
[05:26:23.550] iteration 16652: loss: 0.053056, loss_s1: 0.048359, loss_fp: 0.003798, loss_freq: 0.028907
[05:26:24.174] iteration 16653: loss: 0.039904, loss_s1: 0.018178, loss_fp: 0.001174, loss_freq: 0.016804
[05:26:24.797] iteration 16654: loss: 0.061112, loss_s1: 0.049419, loss_fp: 0.001266, loss_freq: 0.026102
[05:26:25.426] iteration 16655: loss: 0.036909, loss_s1: 0.023750, loss_fp: 0.001105, loss_freq: 0.013214
[05:26:26.059] iteration 16656: loss: 0.054952, loss_s1: 0.037253, loss_fp: 0.002186, loss_freq: 0.044993
[05:26:26.692] iteration 16657: loss: 0.068929, loss_s1: 0.067604, loss_fp: 0.003456, loss_freq: 0.016779
[05:26:27.312] iteration 16658: loss: 0.118656, loss_s1: 0.153224, loss_fp: 0.002897, loss_freq: 0.039667
[05:26:27.942] iteration 16659: loss: 0.065333, loss_s1: 0.039184, loss_fp: 0.002130, loss_freq: 0.047396
[05:26:28.571] iteration 16660: loss: 0.057451, loss_s1: 0.032755, loss_fp: 0.004789, loss_freq: 0.033087
[05:26:29.658] iteration 16661: loss: 0.055386, loss_s1: 0.051795, loss_fp: 0.001604, loss_freq: 0.013574
[05:26:30.407] iteration 16662: loss: 0.044375, loss_s1: 0.028557, loss_fp: 0.002617, loss_freq: 0.018980
[05:26:31.116] iteration 16663: loss: 0.082947, loss_s1: 0.115564, loss_fp: 0.000594, loss_freq: 0.020971
[05:26:31.765] iteration 16664: loss: 0.040407, loss_s1: 0.029529, loss_fp: 0.001044, loss_freq: 0.018156
[05:26:32.393] iteration 16665: loss: 0.063258, loss_s1: 0.063723, loss_fp: 0.001514, loss_freq: 0.032719
[05:26:33.032] iteration 16666: loss: 0.067920, loss_s1: 0.045275, loss_fp: 0.008651, loss_freq: 0.045626
[05:26:33.662] iteration 16667: loss: 0.060950, loss_s1: 0.032601, loss_fp: 0.004369, loss_freq: 0.038118
[05:26:34.302] iteration 16668: loss: 0.036350, loss_s1: 0.031845, loss_fp: 0.001672, loss_freq: 0.013146
[05:26:34.926] iteration 16669: loss: 0.075546, loss_s1: 0.069782, loss_fp: 0.003087, loss_freq: 0.041856
[05:26:35.553] iteration 16670: loss: 0.081587, loss_s1: 0.097327, loss_fp: 0.001078, loss_freq: 0.024593
[05:26:36.192] iteration 16671: loss: 0.072502, loss_s1: 0.069728, loss_fp: 0.002149, loss_freq: 0.035310
[05:26:36.815] iteration 16672: loss: 0.068328, loss_s1: 0.047692, loss_fp: 0.002272, loss_freq: 0.043429
[05:26:37.441] iteration 16673: loss: 0.044745, loss_s1: 0.030553, loss_fp: 0.002202, loss_freq: 0.017778
[05:26:38.078] iteration 16674: loss: 0.046328, loss_s1: 0.035344, loss_fp: 0.004951, loss_freq: 0.021720
[05:26:38.758] iteration 16675: loss: 0.060472, loss_s1: 0.050132, loss_fp: 0.003661, loss_freq: 0.029468
[05:26:39.386] iteration 16676: loss: 0.049818, loss_s1: 0.031560, loss_fp: 0.002956, loss_freq: 0.014144
[05:26:40.018] iteration 16677: loss: 0.094137, loss_s1: 0.042922, loss_fp: 0.002084, loss_freq: 0.112153
[05:26:40.648] iteration 16678: loss: 0.040788, loss_s1: 0.038226, loss_fp: 0.002420, loss_freq: 0.010473
[05:26:41.271] iteration 16679: loss: 0.062231, loss_s1: 0.041382, loss_fp: 0.011721, loss_freq: 0.032264
[05:26:41.907] iteration 16680: loss: 0.077089, loss_s1: 0.066428, loss_fp: 0.002286, loss_freq: 0.030807
[05:26:42.531] iteration 16681: loss: 0.039526, loss_s1: 0.020187, loss_fp: 0.001336, loss_freq: 0.018572
[05:26:43.149] iteration 16682: loss: 0.081639, loss_s1: 0.066461, loss_fp: 0.005069, loss_freq: 0.063336
[05:26:43.772] iteration 16683: loss: 0.078463, loss_s1: 0.058527, loss_fp: 0.003823, loss_freq: 0.023347
[05:26:44.400] iteration 16684: loss: 0.075535, loss_s1: 0.064857, loss_fp: 0.009522, loss_freq: 0.036930
[05:26:45.033] iteration 16685: loss: 0.074243, loss_s1: 0.056328, loss_fp: 0.005611, loss_freq: 0.037841
[05:26:45.680] iteration 16686: loss: 0.092814, loss_s1: 0.103470, loss_fp: 0.006919, loss_freq: 0.049927
[05:26:46.316] iteration 16687: loss: 0.056153, loss_s1: 0.038391, loss_fp: 0.001087, loss_freq: 0.008687
[05:26:46.945] iteration 16688: loss: 0.066454, loss_s1: 0.053189, loss_fp: 0.009137, loss_freq: 0.027867
[05:26:47.585] iteration 16689: loss: 0.047502, loss_s1: 0.036247, loss_fp: 0.006369, loss_freq: 0.015706
[05:26:48.215] iteration 16690: loss: 0.110428, loss_s1: 0.087067, loss_fp: 0.005533, loss_freq: 0.089583
[05:26:48.843] iteration 16691: loss: 0.043844, loss_s1: 0.028978, loss_fp: 0.002787, loss_freq: 0.030177
[05:26:49.518] iteration 16692: loss: 0.111683, loss_s1: 0.086786, loss_fp: 0.003488, loss_freq: 0.085876
[05:26:50.152] iteration 16693: loss: 0.065998, loss_s1: 0.055761, loss_fp: 0.001153, loss_freq: 0.043657
[05:26:50.785] iteration 16694: loss: 0.041066, loss_s1: 0.029499, loss_fp: 0.001430, loss_freq: 0.009109
[05:26:51.413] iteration 16695: loss: 0.062480, loss_s1: 0.055585, loss_fp: 0.002782, loss_freq: 0.038916
[05:26:52.048] iteration 16696: loss: 0.040884, loss_s1: 0.026531, loss_fp: 0.003793, loss_freq: 0.011162
[05:26:52.686] iteration 16697: loss: 0.066093, loss_s1: 0.056223, loss_fp: 0.004736, loss_freq: 0.036530
[05:26:53.316] iteration 16698: loss: 0.052358, loss_s1: 0.054454, loss_fp: 0.000951, loss_freq: 0.022531
[05:26:54.013] iteration 16699: loss: 0.123275, loss_s1: 0.125696, loss_fp: 0.002500, loss_freq: 0.079142
[05:26:54.635] iteration 16700: loss: 0.076896, loss_s1: 0.097084, loss_fp: 0.002469, loss_freq: 0.019309
[05:26:55.269] iteration 16701: loss: 0.086090, loss_s1: 0.080126, loss_fp: 0.000837, loss_freq: 0.057919
[05:26:55.902] iteration 16702: loss: 0.045680, loss_s1: 0.028234, loss_fp: 0.001028, loss_freq: 0.016047
[05:26:56.529] iteration 16703: loss: 0.085989, loss_s1: 0.097145, loss_fp: 0.003040, loss_freq: 0.038835
[05:26:57.152] iteration 16704: loss: 0.075860, loss_s1: 0.048687, loss_fp: 0.006487, loss_freq: 0.064334
[05:26:57.782] iteration 16705: loss: 0.066252, loss_s1: 0.054733, loss_fp: 0.002179, loss_freq: 0.030598
[05:26:58.445] iteration 16706: loss: 0.090201, loss_s1: 0.113963, loss_fp: 0.002807, loss_freq: 0.022256
[05:26:59.070] iteration 16707: loss: 0.051561, loss_s1: 0.034814, loss_fp: 0.007398, loss_freq: 0.026867
[05:26:59.706] iteration 16708: loss: 0.060637, loss_s1: 0.034753, loss_fp: 0.002686, loss_freq: 0.054417
[05:27:00.337] iteration 16709: loss: 0.047540, loss_s1: 0.027294, loss_fp: 0.002797, loss_freq: 0.024112
[05:27:00.968] iteration 16710: loss: 0.057193, loss_s1: 0.042045, loss_fp: 0.005955, loss_freq: 0.032198
[05:27:01.603] iteration 16711: loss: 0.102403, loss_s1: 0.132267, loss_fp: 0.003530, loss_freq: 0.029932
[05:27:02.225] iteration 16712: loss: 0.064366, loss_s1: 0.069036, loss_fp: 0.006794, loss_freq: 0.028648
[05:27:02.873] iteration 16713: loss: 0.060420, loss_s1: 0.035045, loss_fp: 0.003405, loss_freq: 0.047948
[05:27:03.559] iteration 16714: loss: 0.091649, loss_s1: 0.069758, loss_fp: 0.002434, loss_freq: 0.079074
[05:27:04.229] iteration 16715: loss: 0.057226, loss_s1: 0.024564, loss_fp: 0.007245, loss_freq: 0.029320
[05:27:04.897] iteration 16716: loss: 0.062415, loss_s1: 0.050776, loss_fp: 0.002870, loss_freq: 0.029802
[05:27:05.575] iteration 16717: loss: 0.060452, loss_s1: 0.050998, loss_fp: 0.007014, loss_freq: 0.030890
[05:27:06.211] iteration 16718: loss: 0.070277, loss_s1: 0.034468, loss_fp: 0.003531, loss_freq: 0.054369
[05:27:06.835] iteration 16719: loss: 0.049191, loss_s1: 0.023931, loss_fp: 0.002114, loss_freq: 0.037081
[05:27:07.497] iteration 16720: loss: 0.051296, loss_s1: 0.030518, loss_fp: 0.003915, loss_freq: 0.035580
[05:27:08.173] iteration 16721: loss: 0.039371, loss_s1: 0.034296, loss_fp: 0.000638, loss_freq: 0.013847
[05:27:08.843] iteration 16722: loss: 0.077396, loss_s1: 0.038401, loss_fp: 0.000937, loss_freq: 0.034137
[05:27:09.516] iteration 16723: loss: 0.042240, loss_s1: 0.038155, loss_fp: 0.001896, loss_freq: 0.005098
[05:27:10.171] iteration 16724: loss: 0.045192, loss_s1: 0.017125, loss_fp: 0.001228, loss_freq: 0.013549
[05:27:10.826] iteration 16725: loss: 0.089021, loss_s1: 0.121647, loss_fp: 0.003239, loss_freq: 0.013971
[05:27:11.455] iteration 16726: loss: 0.051077, loss_s1: 0.044544, loss_fp: 0.003478, loss_freq: 0.027829
[05:27:12.099] iteration 16727: loss: 0.059380, loss_s1: 0.052790, loss_fp: 0.001067, loss_freq: 0.015267
[05:27:12.728] iteration 16728: loss: 0.076854, loss_s1: 0.048742, loss_fp: 0.007383, loss_freq: 0.051742
[05:27:13.355] iteration 16729: loss: 0.059232, loss_s1: 0.036950, loss_fp: 0.001583, loss_freq: 0.043115
[05:27:13.994] iteration 16730: loss: 0.052667, loss_s1: 0.041715, loss_fp: 0.003296, loss_freq: 0.030839
[05:27:14.615] iteration 16731: loss: 0.062320, loss_s1: 0.031621, loss_fp: 0.002588, loss_freq: 0.052198
[05:27:15.241] iteration 16732: loss: 0.051814, loss_s1: 0.017658, loss_fp: 0.007764, loss_freq: 0.036417
[05:27:15.879] iteration 16733: loss: 0.068339, loss_s1: 0.066124, loss_fp: 0.006320, loss_freq: 0.032710
[05:27:16.511] iteration 16734: loss: 0.088065, loss_s1: 0.093133, loss_fp: 0.002279, loss_freq: 0.037762
[05:27:17.132] iteration 16735: loss: 0.073626, loss_s1: 0.032674, loss_fp: 0.004564, loss_freq: 0.055530
[05:27:17.768] iteration 16736: loss: 0.060320, loss_s1: 0.036429, loss_fp: 0.006217, loss_freq: 0.034426
[05:27:18.397] iteration 16737: loss: 0.072911, loss_s1: 0.054128, loss_fp: 0.002765, loss_freq: 0.032567
[05:27:19.017] iteration 16738: loss: 0.092225, loss_s1: 0.054878, loss_fp: 0.005523, loss_freq: 0.058981
[05:27:19.646] iteration 16739: loss: 0.071051, loss_s1: 0.055214, loss_fp: 0.006302, loss_freq: 0.044490
[05:27:20.278] iteration 16740: loss: 0.055131, loss_s1: 0.040812, loss_fp: 0.002298, loss_freq: 0.030211
[05:27:20.903] iteration 16741: loss: 0.082292, loss_s1: 0.077688, loss_fp: 0.002895, loss_freq: 0.039281
[05:27:21.548] iteration 16742: loss: 0.068556, loss_s1: 0.045589, loss_fp: 0.006038, loss_freq: 0.033991
[05:27:22.263] iteration 16743: loss: 0.053711, loss_s1: 0.049451, loss_fp: 0.001738, loss_freq: 0.023661
[05:27:22.953] iteration 16744: loss: 0.040598, loss_s1: 0.018454, loss_fp: 0.005346, loss_freq: 0.023140
[05:27:23.621] iteration 16745: loss: 0.062920, loss_s1: 0.059124, loss_fp: 0.001940, loss_freq: 0.027801
[05:27:24.291] iteration 16746: loss: 0.056867, loss_s1: 0.049513, loss_fp: 0.002564, loss_freq: 0.016604
[05:27:24.913] iteration 16747: loss: 0.066589, loss_s1: 0.068400, loss_fp: 0.003744, loss_freq: 0.033382
[05:27:25.530] iteration 16748: loss: 0.058982, loss_s1: 0.043824, loss_fp: 0.014773, loss_freq: 0.013835
[05:27:26.152] iteration 16749: loss: 0.070853, loss_s1: 0.062291, loss_fp: 0.004101, loss_freq: 0.037726
[05:27:26.786] iteration 16750: loss: 0.059368, loss_s1: 0.045468, loss_fp: 0.000566, loss_freq: 0.018398
[05:27:27.416] iteration 16751: loss: 0.080224, loss_s1: 0.066019, loss_fp: 0.004189, loss_freq: 0.038728
[05:27:28.032] iteration 16752: loss: 0.063618, loss_s1: 0.050357, loss_fp: 0.009784, loss_freq: 0.025157
[05:27:28.664] iteration 16753: loss: 0.068955, loss_s1: 0.058598, loss_fp: 0.004900, loss_freq: 0.021280
[05:27:29.362] iteration 16754: loss: 0.055680, loss_s1: 0.044470, loss_fp: 0.003145, loss_freq: 0.033881
[05:27:30.001] iteration 16755: loss: 0.086347, loss_s1: 0.064986, loss_fp: 0.001349, loss_freq: 0.047993
[05:27:30.630] iteration 16756: loss: 0.045176, loss_s1: 0.026552, loss_fp: 0.005702, loss_freq: 0.028092
[05:27:31.259] iteration 16757: loss: 0.117949, loss_s1: 0.114380, loss_fp: 0.002762, loss_freq: 0.068813
[05:27:31.875] iteration 16758: loss: 0.057514, loss_s1: 0.026925, loss_fp: 0.006264, loss_freq: 0.044739
[05:27:32.497] iteration 16759: loss: 0.096514, loss_s1: 0.052301, loss_fp: 0.002727, loss_freq: 0.085583
[05:27:33.130] iteration 16760: loss: 0.065142, loss_s1: 0.065561, loss_fp: 0.003551, loss_freq: 0.017142
[05:27:33.742] iteration 16761: loss: 0.094840, loss_s1: 0.105569, loss_fp: 0.008142, loss_freq: 0.041087
[05:27:34.373] iteration 16762: loss: 0.054868, loss_s1: 0.030840, loss_fp: 0.010012, loss_freq: 0.022843
[05:27:35.014] iteration 16763: loss: 0.041108, loss_s1: 0.040677, loss_fp: 0.002329, loss_freq: 0.012833
[05:27:35.639] iteration 16764: loss: 0.060946, loss_s1: 0.033749, loss_fp: 0.002595, loss_freq: 0.039603
[05:27:36.277] iteration 16765: loss: 0.031439, loss_s1: 0.016868, loss_fp: 0.007371, loss_freq: 0.016805
[05:27:36.904] iteration 16766: loss: 0.082654, loss_s1: 0.097360, loss_fp: 0.009763, loss_freq: 0.021241
[05:27:37.539] iteration 16767: loss: 0.063192, loss_s1: 0.043176, loss_fp: 0.004091, loss_freq: 0.031633
[05:27:38.160] iteration 16768: loss: 0.050449, loss_s1: 0.034143, loss_fp: 0.000914, loss_freq: 0.026082
[05:27:38.783] iteration 16769: loss: 0.052464, loss_s1: 0.030130, loss_fp: 0.006035, loss_freq: 0.033879
[05:27:39.414] iteration 16770: loss: 0.057004, loss_s1: 0.040344, loss_fp: 0.005352, loss_freq: 0.036041
[05:27:40.046] iteration 16771: loss: 0.082316, loss_s1: 0.074748, loss_fp: 0.006859, loss_freq: 0.042929
[05:27:40.721] iteration 16772: loss: 0.074426, loss_s1: 0.055989, loss_fp: 0.002329, loss_freq: 0.029343
[05:27:41.448] iteration 16773: loss: 0.065218, loss_s1: 0.055009, loss_fp: 0.001110, loss_freq: 0.026565
[05:27:42.119] iteration 16774: loss: 0.030201, loss_s1: 0.015709, loss_fp: 0.003773, loss_freq: 0.010023
[05:27:42.753] iteration 16775: loss: 0.111581, loss_s1: 0.074383, loss_fp: 0.002678, loss_freq: 0.088184
[05:27:43.395] iteration 16776: loss: 0.108417, loss_s1: 0.068515, loss_fp: 0.009044, loss_freq: 0.083196
[05:27:44.033] iteration 16777: loss: 0.082159, loss_s1: 0.079534, loss_fp: 0.004460, loss_freq: 0.045369
[05:27:44.664] iteration 16778: loss: 0.055690, loss_s1: 0.047256, loss_fp: 0.001049, loss_freq: 0.025747
[05:27:45.292] iteration 16779: loss: 0.091337, loss_s1: 0.042467, loss_fp: 0.014392, loss_freq: 0.088274
[05:27:45.932] iteration 16780: loss: 0.071398, loss_s1: 0.050105, loss_fp: 0.002612, loss_freq: 0.043083
[05:27:46.574] iteration 16781: loss: 0.048480, loss_s1: 0.043461, loss_fp: 0.000476, loss_freq: 0.014480
[05:27:47.198] iteration 16782: loss: 0.064331, loss_s1: 0.054346, loss_fp: 0.003298, loss_freq: 0.044864
[05:27:47.845] iteration 16783: loss: 0.084606, loss_s1: 0.079757, loss_fp: 0.004251, loss_freq: 0.041740
[05:27:48.487] iteration 16784: loss: 0.053946, loss_s1: 0.054268, loss_fp: 0.002063, loss_freq: 0.016922
[05:27:49.121] iteration 16785: loss: 0.078251, loss_s1: 0.047400, loss_fp: 0.005230, loss_freq: 0.058046
[05:27:49.754] iteration 16786: loss: 0.057449, loss_s1: 0.035119, loss_fp: 0.004139, loss_freq: 0.028050
[05:27:50.376] iteration 16787: loss: 0.095299, loss_s1: 0.072047, loss_fp: 0.001954, loss_freq: 0.082652
[05:27:51.010] iteration 16788: loss: 0.079855, loss_s1: 0.094347, loss_fp: 0.001078, loss_freq: 0.017355
[05:27:51.651] iteration 16789: loss: 0.048047, loss_s1: 0.038804, loss_fp: 0.002393, loss_freq: 0.020515
[05:27:52.301] iteration 16790: loss: 0.076785, loss_s1: 0.053923, loss_fp: 0.005029, loss_freq: 0.053117
[05:27:52.928] iteration 16791: loss: 0.052020, loss_s1: 0.042886, loss_fp: 0.007639, loss_freq: 0.025093
[05:27:53.583] iteration 16792: loss: 0.066538, loss_s1: 0.060817, loss_fp: 0.003580, loss_freq: 0.011955
[05:27:54.223] iteration 16793: loss: 0.084022, loss_s1: 0.060449, loss_fp: 0.017993, loss_freq: 0.038665
[05:27:54.912] iteration 16794: loss: 0.073552, loss_s1: 0.066184, loss_fp: 0.006841, loss_freq: 0.047646
[05:27:55.576] iteration 16795: loss: 0.070413, loss_s1: 0.037580, loss_fp: 0.001312, loss_freq: 0.062059
[05:27:56.200] iteration 16796: loss: 0.032710, loss_s1: 0.009808, loss_fp: 0.001683, loss_freq: 0.023467
[05:27:56.842] iteration 16797: loss: 0.077770, loss_s1: 0.062992, loss_fp: 0.004745, loss_freq: 0.020489
[05:27:57.485] iteration 16798: loss: 0.076396, loss_s1: 0.035130, loss_fp: 0.008553, loss_freq: 0.082005
[05:27:58.123] iteration 16799: loss: 0.099536, loss_s1: 0.088707, loss_fp: 0.006551, loss_freq: 0.065479
[05:27:58.750] iteration 16800: loss: 0.075756, loss_s1: 0.086378, loss_fp: 0.003659, loss_freq: 0.040593
[05:28:01.938] iteration 16800 : mean_dice : 0.729198
[05:28:02.579] iteration 16801: loss: 0.080252, loss_s1: 0.079303, loss_fp: 0.004827, loss_freq: 0.032634
[05:28:03.197] iteration 16802: loss: 0.083641, loss_s1: 0.081465, loss_fp: 0.003446, loss_freq: 0.034967
[05:28:03.834] iteration 16803: loss: 0.057067, loss_s1: 0.035703, loss_fp: 0.009891, loss_freq: 0.034267
[05:28:04.495] iteration 16804: loss: 0.040993, loss_s1: 0.030191, loss_fp: 0.005172, loss_freq: 0.006486
[05:28:05.135] iteration 16805: loss: 0.041994, loss_s1: 0.034202, loss_fp: 0.003561, loss_freq: 0.015815
[05:28:05.767] iteration 16806: loss: 0.046661, loss_s1: 0.028986, loss_fp: 0.002009, loss_freq: 0.022572
[05:28:06.440] iteration 16807: loss: 0.060842, loss_s1: 0.032833, loss_fp: 0.001896, loss_freq: 0.036027
[05:28:07.129] iteration 16808: loss: 0.073046, loss_s1: 0.089566, loss_fp: 0.005441, loss_freq: 0.023572
[05:28:07.814] iteration 16809: loss: 0.074786, loss_s1: 0.081294, loss_fp: 0.004268, loss_freq: 0.037246
[05:28:08.458] iteration 16810: loss: 0.052999, loss_s1: 0.039419, loss_fp: 0.003753, loss_freq: 0.020531
[05:28:09.090] iteration 16811: loss: 0.061580, loss_s1: 0.040467, loss_fp: 0.015738, loss_freq: 0.031035
[05:28:09.716] iteration 16812: loss: 0.086743, loss_s1: 0.077241, loss_fp: 0.002611, loss_freq: 0.047314
[05:28:10.340] iteration 16813: loss: 0.069164, loss_s1: 0.062855, loss_fp: 0.006941, loss_freq: 0.032117
[05:28:10.969] iteration 16814: loss: 0.105347, loss_s1: 0.093885, loss_fp: 0.009089, loss_freq: 0.057150
[05:28:11.619] iteration 16815: loss: 0.089450, loss_s1: 0.077814, loss_fp: 0.007258, loss_freq: 0.035075
[05:28:12.252] iteration 16816: loss: 0.060208, loss_s1: 0.049623, loss_fp: 0.002177, loss_freq: 0.032469
[05:28:12.883] iteration 16817: loss: 0.073326, loss_s1: 0.047914, loss_fp: 0.009646, loss_freq: 0.055948
[05:28:13.509] iteration 16818: loss: 0.122212, loss_s1: 0.126645, loss_fp: 0.006161, loss_freq: 0.070760
[05:28:14.138] iteration 16819: loss: 0.093870, loss_s1: 0.087879, loss_fp: 0.005453, loss_freq: 0.064238
[05:28:14.774] iteration 16820: loss: 0.088448, loss_s1: 0.076652, loss_fp: 0.003351, loss_freq: 0.055469
[05:28:15.403] iteration 16821: loss: 0.036447, loss_s1: 0.021192, loss_fp: 0.003324, loss_freq: 0.013848
[05:28:16.038] iteration 16822: loss: 0.058053, loss_s1: 0.053498, loss_fp: 0.003341, loss_freq: 0.034161
[05:28:16.676] iteration 16823: loss: 0.054635, loss_s1: 0.034639, loss_fp: 0.001560, loss_freq: 0.021280
[05:28:17.297] iteration 16824: loss: 0.031627, loss_s1: 0.021696, loss_fp: 0.001312, loss_freq: 0.012875
[05:28:17.944] iteration 16825: loss: 0.051619, loss_s1: 0.042098, loss_fp: 0.002820, loss_freq: 0.016786
[05:28:18.568] iteration 16826: loss: 0.080527, loss_s1: 0.091737, loss_fp: 0.009191, loss_freq: 0.031150
[05:28:19.195] iteration 16827: loss: 0.077273, loss_s1: 0.060915, loss_fp: 0.001673, loss_freq: 0.033064
[05:28:19.813] iteration 16828: loss: 0.087924, loss_s1: 0.093952, loss_fp: 0.010367, loss_freq: 0.030895
[05:28:20.430] iteration 16829: loss: 0.078743, loss_s1: 0.080199, loss_fp: 0.001787, loss_freq: 0.042943
[05:28:21.048] iteration 16830: loss: 0.057549, loss_s1: 0.040798, loss_fp: 0.001254, loss_freq: 0.033727
[05:28:22.031] iteration 16831: loss: 0.052433, loss_s1: 0.042421, loss_fp: 0.002798, loss_freq: 0.017840
[05:28:22.655] iteration 16832: loss: 0.054189, loss_s1: 0.023979, loss_fp: 0.003180, loss_freq: 0.044439
[05:28:23.287] iteration 16833: loss: 0.058804, loss_s1: 0.056289, loss_fp: 0.006211, loss_freq: 0.028481
[05:28:23.980] iteration 16834: loss: 0.053657, loss_s1: 0.038398, loss_fp: 0.000433, loss_freq: 0.028867
[05:28:24.665] iteration 16835: loss: 0.074919, loss_s1: 0.065586, loss_fp: 0.003428, loss_freq: 0.040370
[05:28:25.351] iteration 16836: loss: 0.069346, loss_s1: 0.067629, loss_fp: 0.010241, loss_freq: 0.025868
[05:28:25.982] iteration 16837: loss: 0.041949, loss_s1: 0.013153, loss_fp: 0.001879, loss_freq: 0.033181
[05:28:26.650] iteration 16838: loss: 0.054537, loss_s1: 0.034938, loss_fp: 0.012263, loss_freq: 0.031665
[05:28:27.314] iteration 16839: loss: 0.055984, loss_s1: 0.053169, loss_fp: 0.003386, loss_freq: 0.014367
[05:28:27.951] iteration 16840: loss: 0.082867, loss_s1: 0.076856, loss_fp: 0.006219, loss_freq: 0.038600
[05:28:28.588] iteration 16841: loss: 0.089928, loss_s1: 0.090558, loss_fp: 0.007324, loss_freq: 0.017434
[05:28:29.229] iteration 16842: loss: 0.066698, loss_s1: 0.051138, loss_fp: 0.000894, loss_freq: 0.042443
[05:28:29.862] iteration 16843: loss: 0.059567, loss_s1: 0.045167, loss_fp: 0.003190, loss_freq: 0.036455
[05:28:30.540] iteration 16844: loss: 0.077642, loss_s1: 0.080692, loss_fp: 0.007160, loss_freq: 0.040033
[05:28:31.167] iteration 16845: loss: 0.062683, loss_s1: 0.046544, loss_fp: 0.003428, loss_freq: 0.038366
[05:28:31.789] iteration 16846: loss: 0.099644, loss_s1: 0.096727, loss_fp: 0.017604, loss_freq: 0.045645
[05:28:32.411] iteration 16847: loss: 0.096510, loss_s1: 0.056857, loss_fp: 0.002196, loss_freq: 0.107613
[05:28:33.038] iteration 16848: loss: 0.037941, loss_s1: 0.020716, loss_fp: 0.002341, loss_freq: 0.021321
[05:28:33.666] iteration 16849: loss: 0.084674, loss_s1: 0.091335, loss_fp: 0.004431, loss_freq: 0.041379
[05:28:34.311] iteration 16850: loss: 0.059917, loss_s1: 0.071227, loss_fp: 0.002419, loss_freq: 0.010409
[05:28:35.078] iteration 16851: loss: 0.071320, loss_s1: 0.049281, loss_fp: 0.000897, loss_freq: 0.029563
[05:28:35.932] iteration 16852: loss: 0.050533, loss_s1: 0.028205, loss_fp: 0.004595, loss_freq: 0.036632
[05:28:36.576] iteration 16853: loss: 0.062441, loss_s1: 0.043552, loss_fp: 0.002123, loss_freq: 0.020855
[05:28:37.207] iteration 16854: loss: 0.077457, loss_s1: 0.078110, loss_fp: 0.001162, loss_freq: 0.038009
[05:28:37.828] iteration 16855: loss: 0.054100, loss_s1: 0.030810, loss_fp: 0.005426, loss_freq: 0.041627
[05:28:38.451] iteration 16856: loss: 0.065973, loss_s1: 0.075192, loss_fp: 0.002864, loss_freq: 0.031126
[05:28:39.070] iteration 16857: loss: 0.040597, loss_s1: 0.022973, loss_fp: 0.005761, loss_freq: 0.014288
[05:28:39.707] iteration 16858: loss: 0.082845, loss_s1: 0.061410, loss_fp: 0.004707, loss_freq: 0.040805
[05:28:40.346] iteration 16859: loss: 0.062166, loss_s1: 0.047988, loss_fp: 0.004229, loss_freq: 0.033027
[05:28:40.977] iteration 16860: loss: 0.090020, loss_s1: 0.084375, loss_fp: 0.011362, loss_freq: 0.048075
[05:28:41.606] iteration 16861: loss: 0.056369, loss_s1: 0.037776, loss_fp: 0.001025, loss_freq: 0.040999
[05:28:42.238] iteration 16862: loss: 0.078836, loss_s1: 0.057955, loss_fp: 0.002481, loss_freq: 0.054869
[05:28:42.867] iteration 16863: loss: 0.078352, loss_s1: 0.079221, loss_fp: 0.002908, loss_freq: 0.037473
[05:28:43.501] iteration 16864: loss: 0.047366, loss_s1: 0.033513, loss_fp: 0.001066, loss_freq: 0.022763
[05:28:44.118] iteration 16865: loss: 0.043199, loss_s1: 0.030322, loss_fp: 0.004388, loss_freq: 0.026958
[05:28:44.750] iteration 16866: loss: 0.048497, loss_s1: 0.040713, loss_fp: 0.002384, loss_freq: 0.012768
[05:28:45.372] iteration 16867: loss: 0.052739, loss_s1: 0.050871, loss_fp: 0.001270, loss_freq: 0.014114
[05:28:45.990] iteration 16868: loss: 0.052905, loss_s1: 0.052279, loss_fp: 0.006448, loss_freq: 0.015113
[05:28:46.624] iteration 16869: loss: 0.082296, loss_s1: 0.069347, loss_fp: 0.005256, loss_freq: 0.051109
[05:28:47.247] iteration 16870: loss: 0.074068, loss_s1: 0.076994, loss_fp: 0.002371, loss_freq: 0.027502
[05:28:47.871] iteration 16871: loss: 0.109215, loss_s1: 0.144209, loss_fp: 0.001820, loss_freq: 0.028742
[05:28:48.523] iteration 16872: loss: 0.071504, loss_s1: 0.057072, loss_fp: 0.005938, loss_freq: 0.022910
[05:28:49.162] iteration 16873: loss: 0.086046, loss_s1: 0.093477, loss_fp: 0.007262, loss_freq: 0.040841
[05:28:49.794] iteration 16874: loss: 0.089594, loss_s1: 0.078737, loss_fp: 0.008803, loss_freq: 0.064052
[05:28:50.427] iteration 16875: loss: 0.051024, loss_s1: 0.032903, loss_fp: 0.008824, loss_freq: 0.023616
[05:28:51.052] iteration 16876: loss: 0.064108, loss_s1: 0.053750, loss_fp: 0.008978, loss_freq: 0.031668
[05:28:51.675] iteration 16877: loss: 0.042906, loss_s1: 0.026248, loss_fp: 0.001974, loss_freq: 0.022156
[05:28:52.298] iteration 16878: loss: 0.075251, loss_s1: 0.081777, loss_fp: 0.003960, loss_freq: 0.028132
[05:28:52.924] iteration 16879: loss: 0.039942, loss_s1: 0.029430, loss_fp: 0.006254, loss_freq: 0.005501
[05:28:53.542] iteration 16880: loss: 0.039611, loss_s1: 0.020137, loss_fp: 0.006376, loss_freq: 0.016377
[05:28:54.157] iteration 16881: loss: 0.046722, loss_s1: 0.024245, loss_fp: 0.002429, loss_freq: 0.027762
[05:28:54.801] iteration 16882: loss: 0.060710, loss_s1: 0.066891, loss_fp: 0.003632, loss_freq: 0.029739
[05:28:55.443] iteration 16883: loss: 0.052408, loss_s1: 0.029226, loss_fp: 0.002840, loss_freq: 0.008395
[05:28:56.074] iteration 16884: loss: 0.062041, loss_s1: 0.045812, loss_fp: 0.011865, loss_freq: 0.034109
[05:28:56.699] iteration 16885: loss: 0.061001, loss_s1: 0.033695, loss_fp: 0.002337, loss_freq: 0.047558
[05:28:57.320] iteration 16886: loss: 0.056446, loss_s1: 0.026486, loss_fp: 0.001911, loss_freq: 0.049260
[05:28:57.938] iteration 16887: loss: 0.049693, loss_s1: 0.030404, loss_fp: 0.002125, loss_freq: 0.039629
[05:28:58.557] iteration 16888: loss: 0.051871, loss_s1: 0.029745, loss_fp: 0.011683, loss_freq: 0.013455
[05:28:59.174] iteration 16889: loss: 0.038602, loss_s1: 0.025279, loss_fp: 0.001885, loss_freq: 0.021355
[05:28:59.793] iteration 16890: loss: 0.040410, loss_s1: 0.017954, loss_fp: 0.002384, loss_freq: 0.024264
[05:29:00.441] iteration 16891: loss: 0.038504, loss_s1: 0.040481, loss_fp: 0.001575, loss_freq: 0.009283
[05:29:01.063] iteration 16892: loss: 0.055641, loss_s1: 0.043411, loss_fp: 0.006770, loss_freq: 0.025811
[05:29:01.691] iteration 16893: loss: 0.043578, loss_s1: 0.036065, loss_fp: 0.000801, loss_freq: 0.006768
[05:29:02.319] iteration 16894: loss: 0.039876, loss_s1: 0.021161, loss_fp: 0.004287, loss_freq: 0.024551
[05:29:02.938] iteration 16895: loss: 0.071375, loss_s1: 0.049596, loss_fp: 0.004288, loss_freq: 0.018733
[05:29:03.568] iteration 16896: loss: 0.061779, loss_s1: 0.059022, loss_fp: 0.004858, loss_freq: 0.035787
[05:29:04.188] iteration 16897: loss: 0.064321, loss_s1: 0.054241, loss_fp: 0.003511, loss_freq: 0.024573
[05:29:04.812] iteration 16898: loss: 0.100197, loss_s1: 0.108972, loss_fp: 0.006496, loss_freq: 0.046724
[05:29:05.434] iteration 16899: loss: 0.038418, loss_s1: 0.014938, loss_fp: 0.004831, loss_freq: 0.015647
[05:29:06.078] iteration 16900: loss: 0.061544, loss_s1: 0.045374, loss_fp: 0.001077, loss_freq: 0.044531
[05:29:06.700] iteration 16901: loss: 0.061792, loss_s1: 0.041655, loss_fp: 0.004104, loss_freq: 0.037349
[05:29:07.362] iteration 16902: loss: 0.039415, loss_s1: 0.026042, loss_fp: 0.004017, loss_freq: 0.008070
[05:29:07.985] iteration 16903: loss: 0.068688, loss_s1: 0.051375, loss_fp: 0.009639, loss_freq: 0.037483
[05:29:08.611] iteration 16904: loss: 0.061088, loss_s1: 0.063395, loss_fp: 0.006973, loss_freq: 0.016391
[05:29:09.304] iteration 16905: loss: 0.090268, loss_s1: 0.047130, loss_fp: 0.004978, loss_freq: 0.080045
[05:29:10.046] iteration 16906: loss: 0.083884, loss_s1: 0.057774, loss_fp: 0.014606, loss_freq: 0.060604
[05:29:10.672] iteration 16907: loss: 0.045138, loss_s1: 0.029317, loss_fp: 0.004421, loss_freq: 0.021861
[05:29:11.347] iteration 16908: loss: 0.068036, loss_s1: 0.050077, loss_fp: 0.007554, loss_freq: 0.042106
[05:29:12.039] iteration 16909: loss: 0.048289, loss_s1: 0.038237, loss_fp: 0.006835, loss_freq: 0.023337
[05:29:12.710] iteration 16910: loss: 0.070053, loss_s1: 0.039931, loss_fp: 0.002688, loss_freq: 0.019010
[05:29:13.398] iteration 16911: loss: 0.054158, loss_s1: 0.040672, loss_fp: 0.011339, loss_freq: 0.018760
[05:29:14.015] iteration 16912: loss: 0.065381, loss_s1: 0.052850, loss_fp: 0.007259, loss_freq: 0.031173
[05:29:14.650] iteration 16913: loss: 0.069486, loss_s1: 0.067572, loss_fp: 0.003950, loss_freq: 0.032030
[05:29:15.289] iteration 16914: loss: 0.039728, loss_s1: 0.026426, loss_fp: 0.005920, loss_freq: 0.019698
[05:29:15.917] iteration 16915: loss: 0.067299, loss_s1: 0.045339, loss_fp: 0.005424, loss_freq: 0.031804
[05:29:16.580] iteration 16916: loss: 0.056301, loss_s1: 0.038289, loss_fp: 0.005804, loss_freq: 0.011478
[05:29:17.434] iteration 16917: loss: 0.065236, loss_s1: 0.072174, loss_fp: 0.011250, loss_freq: 0.014837
[05:29:18.188] iteration 16918: loss: 0.084882, loss_s1: 0.103193, loss_fp: 0.004303, loss_freq: 0.028879
[05:29:18.884] iteration 16919: loss: 0.073741, loss_s1: 0.067207, loss_fp: 0.003664, loss_freq: 0.034705
[05:29:19.623] iteration 16920: loss: 0.041344, loss_s1: 0.022114, loss_fp: 0.005913, loss_freq: 0.013848
[05:29:20.255] iteration 16921: loss: 0.069446, loss_s1: 0.080059, loss_fp: 0.001010, loss_freq: 0.022373
[05:29:21.045] iteration 16922: loss: 0.052084, loss_s1: 0.025631, loss_fp: 0.001057, loss_freq: 0.040197
[05:29:21.783] iteration 16923: loss: 0.084586, loss_s1: 0.067544, loss_fp: 0.017293, loss_freq: 0.029870
[05:29:22.505] iteration 16924: loss: 0.070784, loss_s1: 0.069427, loss_fp: 0.001495, loss_freq: 0.039447
[05:29:23.269] iteration 16925: loss: 0.067423, loss_s1: 0.061506, loss_fp: 0.006885, loss_freq: 0.029373
[05:29:23.936] iteration 16926: loss: 0.092545, loss_s1: 0.078090, loss_fp: 0.002948, loss_freq: 0.077295
[05:29:24.746] iteration 16927: loss: 0.060789, loss_s1: 0.057423, loss_fp: 0.004370, loss_freq: 0.023190
[05:29:25.455] iteration 16928: loss: 0.071052, loss_s1: 0.059450, loss_fp: 0.001015, loss_freq: 0.029691
[05:29:26.090] iteration 16929: loss: 0.056922, loss_s1: 0.032602, loss_fp: 0.006498, loss_freq: 0.049024
[05:29:26.904] iteration 16930: loss: 0.043849, loss_s1: 0.027241, loss_fp: 0.004489, loss_freq: 0.016994
[05:29:27.628] iteration 16931: loss: 0.064507, loss_s1: 0.060993, loss_fp: 0.002920, loss_freq: 0.038861
[05:29:28.380] iteration 16932: loss: 0.065803, loss_s1: 0.041225, loss_fp: 0.004235, loss_freq: 0.029837
[05:29:29.053] iteration 16933: loss: 0.034753, loss_s1: 0.013406, loss_fp: 0.001568, loss_freq: 0.011842
[05:29:29.709] iteration 16934: loss: 0.043875, loss_s1: 0.026522, loss_fp: 0.000945, loss_freq: 0.028853
[05:29:30.427] iteration 16935: loss: 0.034702, loss_s1: 0.028223, loss_fp: 0.001928, loss_freq: 0.012029
[05:29:31.108] iteration 16936: loss: 0.089647, loss_s1: 0.098394, loss_fp: 0.005533, loss_freq: 0.033672
[05:29:31.842] iteration 16937: loss: 0.054616, loss_s1: 0.047311, loss_fp: 0.003373, loss_freq: 0.014896
[05:29:32.596] iteration 16938: loss: 0.051114, loss_s1: 0.049201, loss_fp: 0.002576, loss_freq: 0.022080
[05:29:33.367] iteration 16939: loss: 0.049430, loss_s1: 0.022699, loss_fp: 0.006202, loss_freq: 0.029190
[05:29:34.089] iteration 16940: loss: 0.079117, loss_s1: 0.070514, loss_fp: 0.007045, loss_freq: 0.040563
[05:29:34.758] iteration 16941: loss: 0.057684, loss_s1: 0.029983, loss_fp: 0.001234, loss_freq: 0.028675
[05:29:35.391] iteration 16942: loss: 0.075963, loss_s1: 0.069741, loss_fp: 0.011129, loss_freq: 0.034330
[05:29:36.025] iteration 16943: loss: 0.050961, loss_s1: 0.035357, loss_fp: 0.002542, loss_freq: 0.036048
[05:29:36.646] iteration 16944: loss: 0.047131, loss_s1: 0.038296, loss_fp: 0.014345, loss_freq: 0.012965
[05:29:37.272] iteration 16945: loss: 0.086587, loss_s1: 0.088306, loss_fp: 0.005938, loss_freq: 0.036409
[05:29:37.904] iteration 16946: loss: 0.084859, loss_s1: 0.065178, loss_fp: 0.005971, loss_freq: 0.058074
[05:29:38.536] iteration 16947: loss: 0.073481, loss_s1: 0.078112, loss_fp: 0.004358, loss_freq: 0.028688
[05:29:39.172] iteration 16948: loss: 0.064573, loss_s1: 0.041501, loss_fp: 0.023381, loss_freq: 0.022364
[05:29:39.805] iteration 16949: loss: 0.115401, loss_s1: 0.119085, loss_fp: 0.004432, loss_freq: 0.073975
[05:29:40.436] iteration 16950: loss: 0.052598, loss_s1: 0.031651, loss_fp: 0.000920, loss_freq: 0.014809
[05:29:41.066] iteration 16951: loss: 0.040943, loss_s1: 0.029240, loss_fp: 0.002312, loss_freq: 0.010251
[05:29:41.697] iteration 16952: loss: 0.039152, loss_s1: 0.029860, loss_fp: 0.006796, loss_freq: 0.016003
[05:29:42.317] iteration 16953: loss: 0.076042, loss_s1: 0.056367, loss_fp: 0.017195, loss_freq: 0.026533
[05:29:42.946] iteration 16954: loss: 0.053485, loss_s1: 0.043875, loss_fp: 0.004193, loss_freq: 0.028293
[05:29:43.567] iteration 16955: loss: 0.108411, loss_s1: 0.113881, loss_fp: 0.005906, loss_freq: 0.063835
[05:29:44.186] iteration 16956: loss: 0.049513, loss_s1: 0.012627, loss_fp: 0.004695, loss_freq: 0.042035
[05:29:44.820] iteration 16957: loss: 0.061388, loss_s1: 0.011027, loss_fp: 0.002939, loss_freq: 0.082818
[05:29:45.444] iteration 16958: loss: 0.058483, loss_s1: 0.048363, loss_fp: 0.001327, loss_freq: 0.013540
[05:29:46.072] iteration 16959: loss: 0.052960, loss_s1: 0.034167, loss_fp: 0.003128, loss_freq: 0.041517
[05:29:46.770] iteration 16960: loss: 0.077029, loss_s1: 0.039740, loss_fp: 0.004068, loss_freq: 0.072521
[05:29:47.434] iteration 16961: loss: 0.068914, loss_s1: 0.086725, loss_fp: 0.005956, loss_freq: 0.019183
[05:29:48.090] iteration 16962: loss: 0.103672, loss_s1: 0.097739, loss_fp: 0.009022, loss_freq: 0.052573
[05:29:48.703] iteration 16963: loss: 0.067700, loss_s1: 0.051425, loss_fp: 0.007260, loss_freq: 0.036578
[05:29:49.335] iteration 16964: loss: 0.060289, loss_s1: 0.066258, loss_fp: 0.003170, loss_freq: 0.024368
[05:29:49.952] iteration 16965: loss: 0.071602, loss_s1: 0.055289, loss_fp: 0.006967, loss_freq: 0.038012
[05:29:50.597] iteration 16966: loss: 0.045316, loss_s1: 0.031217, loss_fp: 0.001771, loss_freq: 0.007531
[05:29:51.277] iteration 16967: loss: 0.089481, loss_s1: 0.088669, loss_fp: 0.002201, loss_freq: 0.035586
[05:29:51.945] iteration 16968: loss: 0.052291, loss_s1: 0.043063, loss_fp: 0.003169, loss_freq: 0.028516
[05:29:52.609] iteration 16969: loss: 0.103174, loss_s1: 0.095683, loss_fp: 0.006362, loss_freq: 0.064723
[05:29:53.290] iteration 16970: loss: 0.044546, loss_s1: 0.052475, loss_fp: 0.003063, loss_freq: 0.011952
[05:29:54.089] iteration 16971: loss: 0.077953, loss_s1: 0.067030, loss_fp: 0.008895, loss_freq: 0.038642
[05:29:54.945] iteration 16972: loss: 0.046992, loss_s1: 0.028804, loss_fp: 0.004464, loss_freq: 0.023438
[05:29:55.642] iteration 16973: loss: 0.051134, loss_s1: 0.032689, loss_fp: 0.003592, loss_freq: 0.035327
[05:29:56.387] iteration 16974: loss: 0.043042, loss_s1: 0.025221, loss_fp: 0.004774, loss_freq: 0.014791
[05:29:57.034] iteration 16975: loss: 0.050273, loss_s1: 0.054733, loss_fp: 0.006288, loss_freq: 0.007752
[05:29:57.656] iteration 16976: loss: 0.072361, loss_s1: 0.072511, loss_fp: 0.001678, loss_freq: 0.035033
[05:29:58.283] iteration 16977: loss: 0.038216, loss_s1: 0.025486, loss_fp: 0.003486, loss_freq: 0.011022
[05:29:58.907] iteration 16978: loss: 0.100397, loss_s1: 0.085433, loss_fp: 0.004798, loss_freq: 0.078360
[05:29:59.555] iteration 16979: loss: 0.066936, loss_s1: 0.069341, loss_fp: 0.003819, loss_freq: 0.030393
[05:30:00.258] iteration 16980: loss: 0.073089, loss_s1: 0.056812, loss_fp: 0.002416, loss_freq: 0.047709
[05:30:00.938] iteration 16981: loss: 0.081553, loss_s1: 0.077619, loss_fp: 0.000911, loss_freq: 0.046185
[05:30:01.618] iteration 16982: loss: 0.095057, loss_s1: 0.063391, loss_fp: 0.003901, loss_freq: 0.085219
[05:30:02.309] iteration 16983: loss: 0.071620, loss_s1: 0.064189, loss_fp: 0.004221, loss_freq: 0.029798
[05:30:02.987] iteration 16984: loss: 0.102618, loss_s1: 0.074619, loss_fp: 0.005462, loss_freq: 0.077235
[05:30:03.614] iteration 16985: loss: 0.081432, loss_s1: 0.058271, loss_fp: 0.003868, loss_freq: 0.057627
[05:30:04.250] iteration 16986: loss: 0.037310, loss_s1: 0.029264, loss_fp: 0.000906, loss_freq: 0.007681
[05:30:04.895] iteration 16987: loss: 0.047505, loss_s1: 0.023253, loss_fp: 0.003862, loss_freq: 0.038534
[05:30:05.535] iteration 16988: loss: 0.093982, loss_s1: 0.075168, loss_fp: 0.002640, loss_freq: 0.071827
[05:30:06.168] iteration 16989: loss: 0.050598, loss_s1: 0.026206, loss_fp: 0.007057, loss_freq: 0.030083
[05:30:06.795] iteration 16990: loss: 0.071982, loss_s1: 0.051178, loss_fp: 0.006238, loss_freq: 0.043056
[05:30:07.424] iteration 16991: loss: 0.040609, loss_s1: 0.033851, loss_fp: 0.002842, loss_freq: 0.007909
[05:30:08.056] iteration 16992: loss: 0.062097, loss_s1: 0.076174, loss_fp: 0.006092, loss_freq: 0.016498
[05:30:08.676] iteration 16993: loss: 0.044273, loss_s1: 0.023159, loss_fp: 0.002172, loss_freq: 0.012657
[05:30:09.305] iteration 16994: loss: 0.078329, loss_s1: 0.087409, loss_fp: 0.001035, loss_freq: 0.040819
[05:30:09.944] iteration 16995: loss: 0.035787, loss_s1: 0.018140, loss_fp: 0.000686, loss_freq: 0.012254
[05:30:10.581] iteration 16996: loss: 0.089845, loss_s1: 0.084429, loss_fp: 0.008858, loss_freq: 0.059282
[05:30:11.217] iteration 16997: loss: 0.071548, loss_s1: 0.045345, loss_fp: 0.007337, loss_freq: 0.047863
[05:30:11.853] iteration 16998: loss: 0.062271, loss_s1: 0.039502, loss_fp: 0.002700, loss_freq: 0.038663
[05:30:12.482] iteration 16999: loss: 0.084228, loss_s1: 0.072235, loss_fp: 0.006436, loss_freq: 0.058518
[05:30:13.111] iteration 17000: loss: 0.096846, loss_s1: 0.111549, loss_fp: 0.020330, loss_freq: 0.024747
[05:30:16.513] iteration 17000 : mean_dice : 0.716526
[05:30:17.478] iteration 17001: loss: 0.078908, loss_s1: 0.072535, loss_fp: 0.002580, loss_freq: 0.038364
[05:30:18.108] iteration 17002: loss: 0.047166, loss_s1: 0.027804, loss_fp: 0.002792, loss_freq: 0.025974
[05:30:18.744] iteration 17003: loss: 0.063230, loss_s1: 0.065388, loss_fp: 0.002430, loss_freq: 0.027405
[05:30:19.363] iteration 17004: loss: 0.059056, loss_s1: 0.056587, loss_fp: 0.002245, loss_freq: 0.015312
[05:30:19.981] iteration 17005: loss: 0.050780, loss_s1: 0.029893, loss_fp: 0.012345, loss_freq: 0.014870
[05:30:20.616] iteration 17006: loss: 0.069384, loss_s1: 0.061583, loss_fp: 0.002076, loss_freq: 0.041953
[05:30:21.246] iteration 17007: loss: 0.063963, loss_s1: 0.029230, loss_fp: 0.005395, loss_freq: 0.041780
[05:30:21.868] iteration 17008: loss: 0.059386, loss_s1: 0.039398, loss_fp: 0.008590, loss_freq: 0.039117
[05:30:22.490] iteration 17009: loss: 0.061896, loss_s1: 0.053102, loss_fp: 0.008935, loss_freq: 0.024822
[05:30:23.110] iteration 17010: loss: 0.104932, loss_s1: 0.122717, loss_fp: 0.005439, loss_freq: 0.043162
[05:30:23.748] iteration 17011: loss: 0.076739, loss_s1: 0.035186, loss_fp: 0.013601, loss_freq: 0.069724
[05:30:24.395] iteration 17012: loss: 0.119104, loss_s1: 0.099744, loss_fp: 0.002841, loss_freq: 0.097916
[05:30:25.026] iteration 17013: loss: 0.087933, loss_s1: 0.076322, loss_fp: 0.003650, loss_freq: 0.055103
[05:30:25.657] iteration 17014: loss: 0.087323, loss_s1: 0.056777, loss_fp: 0.006937, loss_freq: 0.066530
[05:30:26.299] iteration 17015: loss: 0.053066, loss_s1: 0.048245, loss_fp: 0.001381, loss_freq: 0.021284
[05:30:26.925] iteration 17016: loss: 0.064687, loss_s1: 0.040763, loss_fp: 0.004231, loss_freq: 0.042774
[05:30:27.545] iteration 17017: loss: 0.079740, loss_s1: 0.045798, loss_fp: 0.008629, loss_freq: 0.079010
[05:30:28.168] iteration 17018: loss: 0.046816, loss_s1: 0.036307, loss_fp: 0.000950, loss_freq: 0.017361
[05:30:28.790] iteration 17019: loss: 0.091148, loss_s1: 0.103474, loss_fp: 0.007537, loss_freq: 0.037924
[05:30:29.485] iteration 17020: loss: 0.058372, loss_s1: 0.042536, loss_fp: 0.002467, loss_freq: 0.012124
[05:30:30.193] iteration 17021: loss: 0.047278, loss_s1: 0.021533, loss_fp: 0.005703, loss_freq: 0.016474
[05:30:30.875] iteration 17022: loss: 0.054295, loss_s1: 0.059652, loss_fp: 0.000987, loss_freq: 0.018748
[05:30:31.575] iteration 17023: loss: 0.045703, loss_s1: 0.028029, loss_fp: 0.001822, loss_freq: 0.017430
[05:30:32.270] iteration 17024: loss: 0.051206, loss_s1: 0.046238, loss_fp: 0.001375, loss_freq: 0.026434
[05:30:32.938] iteration 17025: loss: 0.087158, loss_s1: 0.092505, loss_fp: 0.001500, loss_freq: 0.051346
[05:30:33.634] iteration 17026: loss: 0.056762, loss_s1: 0.050690, loss_fp: 0.001843, loss_freq: 0.035422
[05:30:34.315] iteration 17027: loss: 0.046563, loss_s1: 0.039892, loss_fp: 0.001645, loss_freq: 0.010852
[05:30:34.963] iteration 17028: loss: 0.066276, loss_s1: 0.036921, loss_fp: 0.009641, loss_freq: 0.042344
[05:30:35.605] iteration 17029: loss: 0.059312, loss_s1: 0.049922, loss_fp: 0.001353, loss_freq: 0.018429
[05:30:36.252] iteration 17030: loss: 0.083302, loss_s1: 0.092383, loss_fp: 0.006377, loss_freq: 0.033146
[05:30:36.879] iteration 17031: loss: 0.058437, loss_s1: 0.052328, loss_fp: 0.002606, loss_freq: 0.032058
[05:30:37.521] iteration 17032: loss: 0.075736, loss_s1: 0.060967, loss_fp: 0.004978, loss_freq: 0.047440
[05:30:38.158] iteration 17033: loss: 0.058595, loss_s1: 0.022202, loss_fp: 0.010850, loss_freq: 0.045886
[05:30:38.789] iteration 17034: loss: 0.032856, loss_s1: 0.021826, loss_fp: 0.002377, loss_freq: 0.006075
[05:30:39.436] iteration 17035: loss: 0.058559, loss_s1: 0.050096, loss_fp: 0.003186, loss_freq: 0.043005
[05:30:40.081] iteration 17036: loss: 0.050604, loss_s1: 0.037022, loss_fp: 0.002326, loss_freq: 0.011452
[05:30:40.746] iteration 17037: loss: 0.062562, loss_s1: 0.048346, loss_fp: 0.000959, loss_freq: 0.037316
[05:30:41.423] iteration 17038: loss: 0.039694, loss_s1: 0.036237, loss_fp: 0.002942, loss_freq: 0.010460
[05:30:42.074] iteration 17039: loss: 0.082961, loss_s1: 0.088090, loss_fp: 0.007100, loss_freq: 0.027803
[05:30:42.724] iteration 17040: loss: 0.094106, loss_s1: 0.085075, loss_fp: 0.003362, loss_freq: 0.039901
[05:30:43.343] iteration 17041: loss: 0.093281, loss_s1: 0.092393, loss_fp: 0.002555, loss_freq: 0.050419
[05:30:44.015] iteration 17042: loss: 0.062798, loss_s1: 0.037085, loss_fp: 0.004034, loss_freq: 0.043089
[05:30:44.711] iteration 17043: loss: 0.115170, loss_s1: 0.111506, loss_fp: 0.011008, loss_freq: 0.070055
[05:30:45.374] iteration 17044: loss: 0.107498, loss_s1: 0.132245, loss_fp: 0.010978, loss_freq: 0.032983
[05:30:46.074] iteration 17045: loss: 0.086846, loss_s1: 0.075805, loss_fp: 0.001242, loss_freq: 0.035434
[05:30:46.702] iteration 17046: loss: 0.073350, loss_s1: 0.052565, loss_fp: 0.003786, loss_freq: 0.042179
[05:30:47.320] iteration 17047: loss: 0.069452, loss_s1: 0.054617, loss_fp: 0.003611, loss_freq: 0.043744
[05:30:47.950] iteration 17048: loss: 0.069293, loss_s1: 0.039512, loss_fp: 0.005093, loss_freq: 0.025644
[05:30:48.600] iteration 17049: loss: 0.060637, loss_s1: 0.047997, loss_fp: 0.002627, loss_freq: 0.017621
[05:30:49.226] iteration 17050: loss: 0.048271, loss_s1: 0.048238, loss_fp: 0.000932, loss_freq: 0.010320
[05:30:49.859] iteration 17051: loss: 0.062762, loss_s1: 0.042744, loss_fp: 0.002140, loss_freq: 0.044773
[05:30:50.488] iteration 17052: loss: 0.057665, loss_s1: 0.068637, loss_fp: 0.002222, loss_freq: 0.014961
[05:30:51.118] iteration 17053: loss: 0.050518, loss_s1: 0.014557, loss_fp: 0.001404, loss_freq: 0.014475
[05:30:51.740] iteration 17054: loss: 0.065887, loss_s1: 0.045606, loss_fp: 0.006257, loss_freq: 0.047454
[05:30:52.390] iteration 17055: loss: 0.056124, loss_s1: 0.018410, loss_fp: 0.010366, loss_freq: 0.030402
[05:30:53.030] iteration 17056: loss: 0.057138, loss_s1: 0.049519, loss_fp: 0.004665, loss_freq: 0.023054
[05:30:53.654] iteration 17057: loss: 0.062114, loss_s1: 0.054892, loss_fp: 0.003817, loss_freq: 0.030915
[05:30:54.290] iteration 17058: loss: 0.047949, loss_s1: 0.027461, loss_fp: 0.002782, loss_freq: 0.020166
[05:30:54.923] iteration 17059: loss: 0.051479, loss_s1: 0.025861, loss_fp: 0.003475, loss_freq: 0.038882
[05:30:55.548] iteration 17060: loss: 0.057064, loss_s1: 0.031890, loss_fp: 0.004597, loss_freq: 0.040914
[05:30:56.172] iteration 17061: loss: 0.039124, loss_s1: 0.034988, loss_fp: 0.000383, loss_freq: 0.006554
[05:30:56.797] iteration 17062: loss: 0.063849, loss_s1: 0.036316, loss_fp: 0.007411, loss_freq: 0.046204
[05:30:57.425] iteration 17063: loss: 0.035862, loss_s1: 0.022607, loss_fp: 0.001490, loss_freq: 0.010472
[05:30:58.057] iteration 17064: loss: 0.035124, loss_s1: 0.014639, loss_fp: 0.004104, loss_freq: 0.016190
[05:30:58.687] iteration 17065: loss: 0.071141, loss_s1: 0.052867, loss_fp: 0.007129, loss_freq: 0.031004
[05:30:59.321] iteration 17066: loss: 0.057520, loss_s1: 0.028316, loss_fp: 0.009474, loss_freq: 0.051598
[05:30:59.951] iteration 17067: loss: 0.047512, loss_s1: 0.026212, loss_fp: 0.002601, loss_freq: 0.015609
[05:31:00.580] iteration 17068: loss: 0.084856, loss_s1: 0.037477, loss_fp: 0.010427, loss_freq: 0.084577
[05:31:01.209] iteration 17069: loss: 0.049258, loss_s1: 0.021768, loss_fp: 0.001695, loss_freq: 0.025524
[05:31:01.856] iteration 17070: loss: 0.046727, loss_s1: 0.034495, loss_fp: 0.003136, loss_freq: 0.024288
[05:31:02.547] iteration 17071: loss: 0.073169, loss_s1: 0.054844, loss_fp: 0.008136, loss_freq: 0.033196
[05:31:03.217] iteration 17072: loss: 0.067776, loss_s1: 0.047229, loss_fp: 0.001774, loss_freq: 0.029231
[05:31:03.893] iteration 17073: loss: 0.069883, loss_s1: 0.068328, loss_fp: 0.005312, loss_freq: 0.020684
[05:31:04.595] iteration 17074: loss: 0.082741, loss_s1: 0.069288, loss_fp: 0.003588, loss_freq: 0.052400
[05:31:05.267] iteration 17075: loss: 0.089286, loss_s1: 0.040436, loss_fp: 0.001001, loss_freq: 0.075688
[05:31:05.929] iteration 17076: loss: 0.080865, loss_s1: 0.061278, loss_fp: 0.007967, loss_freq: 0.039558
[05:31:06.561] iteration 17077: loss: 0.067993, loss_s1: 0.059315, loss_fp: 0.002537, loss_freq: 0.035583
[05:31:07.179] iteration 17078: loss: 0.089600, loss_s1: 0.093165, loss_fp: 0.005092, loss_freq: 0.028787
[05:31:07.802] iteration 17079: loss: 0.047821, loss_s1: 0.022796, loss_fp: 0.003483, loss_freq: 0.036426
[05:31:08.440] iteration 17080: loss: 0.068548, loss_s1: 0.059407, loss_fp: 0.007276, loss_freq: 0.023677
[05:31:09.069] iteration 17081: loss: 0.080493, loss_s1: 0.084485, loss_fp: 0.010603, loss_freq: 0.012485
[05:31:09.705] iteration 17082: loss: 0.067943, loss_s1: 0.056086, loss_fp: 0.009529, loss_freq: 0.027308
[05:31:10.333] iteration 17083: loss: 0.094953, loss_s1: 0.118140, loss_fp: 0.010960, loss_freq: 0.029932
[05:31:10.966] iteration 17084: loss: 0.037061, loss_s1: 0.026197, loss_fp: 0.003875, loss_freq: 0.012062
[05:31:11.624] iteration 17085: loss: 0.055244, loss_s1: 0.051666, loss_fp: 0.001419, loss_freq: 0.017220
[05:31:12.252] iteration 17086: loss: 0.056897, loss_s1: 0.051025, loss_fp: 0.002970, loss_freq: 0.016778
[05:31:12.870] iteration 17087: loss: 0.065024, loss_s1: 0.058417, loss_fp: 0.002701, loss_freq: 0.043902
[05:31:13.508] iteration 17088: loss: 0.061582, loss_s1: 0.046191, loss_fp: 0.002726, loss_freq: 0.032027
[05:31:14.133] iteration 17089: loss: 0.089537, loss_s1: 0.080057, loss_fp: 0.012000, loss_freq: 0.051386
[05:31:14.764] iteration 17090: loss: 0.046135, loss_s1: 0.026819, loss_fp: 0.001698, loss_freq: 0.018423
[05:31:15.472] iteration 17091: loss: 0.083268, loss_s1: 0.057100, loss_fp: 0.002107, loss_freq: 0.021168
[05:31:16.152] iteration 17092: loss: 0.059136, loss_s1: 0.070719, loss_fp: 0.006877, loss_freq: 0.014043
[05:31:16.800] iteration 17093: loss: 0.055751, loss_s1: 0.035645, loss_fp: 0.002778, loss_freq: 0.021600
[05:31:17.435] iteration 17094: loss: 0.035283, loss_s1: 0.023917, loss_fp: 0.000900, loss_freq: 0.013094
[05:31:18.056] iteration 17095: loss: 0.059187, loss_s1: 0.046105, loss_fp: 0.004764, loss_freq: 0.029040
[05:31:18.677] iteration 17096: loss: 0.055514, loss_s1: 0.049305, loss_fp: 0.003286, loss_freq: 0.032734
[05:31:19.306] iteration 17097: loss: 0.077760, loss_s1: 0.046162, loss_fp: 0.000568, loss_freq: 0.070821
[05:31:19.936] iteration 17098: loss: 0.048238, loss_s1: 0.023644, loss_fp: 0.005188, loss_freq: 0.020629
[05:31:20.565] iteration 17099: loss: 0.101062, loss_s1: 0.090700, loss_fp: 0.004731, loss_freq: 0.064007
[05:31:21.206] iteration 17100: loss: 0.064927, loss_s1: 0.039178, loss_fp: 0.017637, loss_freq: 0.032793
[05:31:21.825] iteration 17101: loss: 0.093085, loss_s1: 0.117859, loss_fp: 0.006834, loss_freq: 0.029683
[05:31:22.465] iteration 17102: loss: 0.057414, loss_s1: 0.054582, loss_fp: 0.002516, loss_freq: 0.012574
[05:31:23.090] iteration 17103: loss: 0.041659, loss_s1: 0.023380, loss_fp: 0.001877, loss_freq: 0.027219
[05:31:23.712] iteration 17104: loss: 0.054604, loss_s1: 0.043127, loss_fp: 0.003591, loss_freq: 0.023569
[05:31:24.331] iteration 17105: loss: 0.037223, loss_s1: 0.023055, loss_fp: 0.001805, loss_freq: 0.023352
[05:31:24.942] iteration 17106: loss: 0.085499, loss_s1: 0.072442, loss_fp: 0.005299, loss_freq: 0.055559
[05:31:25.580] iteration 17107: loss: 0.069789, loss_s1: 0.057978, loss_fp: 0.009658, loss_freq: 0.032892
[05:31:26.237] iteration 17108: loss: 0.051228, loss_s1: 0.033207, loss_fp: 0.005782, loss_freq: 0.024979
[05:31:26.906] iteration 17109: loss: 0.058017, loss_s1: 0.030475, loss_fp: 0.008048, loss_freq: 0.038476
[05:31:27.581] iteration 17110: loss: 0.035664, loss_s1: 0.026621, loss_fp: 0.000894, loss_freq: 0.014908
[05:31:28.256] iteration 17111: loss: 0.070197, loss_s1: 0.042253, loss_fp: 0.002484, loss_freq: 0.033989
[05:31:28.939] iteration 17112: loss: 0.045871, loss_s1: 0.025093, loss_fp: 0.001384, loss_freq: 0.020549
[05:31:29.582] iteration 17113: loss: 0.036382, loss_s1: 0.021847, loss_fp: 0.001641, loss_freq: 0.018392
[05:31:30.220] iteration 17114: loss: 0.036212, loss_s1: 0.034245, loss_fp: 0.002042, loss_freq: 0.009373
[05:31:30.842] iteration 17115: loss: 0.104914, loss_s1: 0.096274, loss_fp: 0.005021, loss_freq: 0.052444
[05:31:31.513] iteration 17116: loss: 0.078236, loss_s1: 0.037696, loss_fp: 0.005351, loss_freq: 0.063591
[05:31:32.194] iteration 17117: loss: 0.084825, loss_s1: 0.061101, loss_fp: 0.008140, loss_freq: 0.058354
[05:31:32.828] iteration 17118: loss: 0.054766, loss_s1: 0.051590, loss_fp: 0.012052, loss_freq: 0.016985
[05:31:33.467] iteration 17119: loss: 0.089654, loss_s1: 0.061484, loss_fp: 0.005955, loss_freq: 0.084002
[05:31:34.115] iteration 17120: loss: 0.050422, loss_s1: 0.045410, loss_fp: 0.002827, loss_freq: 0.012257
[05:31:34.754] iteration 17121: loss: 0.041973, loss_s1: 0.036781, loss_fp: 0.002035, loss_freq: 0.013692
[05:31:35.393] iteration 17122: loss: 0.076995, loss_s1: 0.080848, loss_fp: 0.006957, loss_freq: 0.035530
[05:31:36.029] iteration 17123: loss: 0.097105, loss_s1: 0.101315, loss_fp: 0.009290, loss_freq: 0.048720
[05:31:36.664] iteration 17124: loss: 0.052471, loss_s1: 0.043071, loss_fp: 0.004266, loss_freq: 0.025098
[05:31:37.326] iteration 17125: loss: 0.073247, loss_s1: 0.052796, loss_fp: 0.003393, loss_freq: 0.045625
[05:31:38.063] iteration 17126: loss: 0.045920, loss_s1: 0.025934, loss_fp: 0.004293, loss_freq: 0.022133
[05:31:38.737] iteration 17127: loss: 0.082413, loss_s1: 0.092335, loss_fp: 0.005267, loss_freq: 0.032881
[05:31:39.410] iteration 17128: loss: 0.073743, loss_s1: 0.042601, loss_fp: 0.002216, loss_freq: 0.052728
[05:31:40.129] iteration 17129: loss: 0.060626, loss_s1: 0.064216, loss_fp: 0.004183, loss_freq: 0.022034
[05:31:40.814] iteration 17130: loss: 0.070867, loss_s1: 0.041394, loss_fp: 0.002460, loss_freq: 0.055361
[05:31:41.478] iteration 17131: loss: 0.101431, loss_s1: 0.145456, loss_fp: 0.007428, loss_freq: 0.013269
[05:31:42.111] iteration 17132: loss: 0.067935, loss_s1: 0.065483, loss_fp: 0.005014, loss_freq: 0.018043
[05:31:42.758] iteration 17133: loss: 0.080648, loss_s1: 0.070903, loss_fp: 0.005633, loss_freq: 0.044769
[05:31:43.383] iteration 17134: loss: 0.062347, loss_s1: 0.078576, loss_fp: 0.003138, loss_freq: 0.014579
[05:31:44.006] iteration 17135: loss: 0.085596, loss_s1: 0.112123, loss_fp: 0.001299, loss_freq: 0.018439
[05:31:44.643] iteration 17136: loss: 0.038153, loss_s1: 0.028528, loss_fp: 0.004529, loss_freq: 0.008555
[05:31:45.264] iteration 17137: loss: 0.099161, loss_s1: 0.084381, loss_fp: 0.012148, loss_freq: 0.021662
[05:31:45.930] iteration 17138: loss: 0.051704, loss_s1: 0.027941, loss_fp: 0.002808, loss_freq: 0.037417
[05:31:46.564] iteration 17139: loss: 0.104038, loss_s1: 0.136169, loss_fp: 0.001997, loss_freq: 0.037448
[05:31:47.202] iteration 17140: loss: 0.068589, loss_s1: 0.058556, loss_fp: 0.009115, loss_freq: 0.048001
[05:31:47.841] iteration 17141: loss: 0.074880, loss_s1: 0.081561, loss_fp: 0.005140, loss_freq: 0.026496
[05:31:48.477] iteration 17142: loss: 0.060056, loss_s1: 0.044118, loss_fp: 0.004114, loss_freq: 0.028446
[05:31:49.145] iteration 17143: loss: 0.064406, loss_s1: 0.070651, loss_fp: 0.001735, loss_freq: 0.019356
[05:31:49.800] iteration 17144: loss: 0.057125, loss_s1: 0.058834, loss_fp: 0.003188, loss_freq: 0.015777
[05:31:50.440] iteration 17145: loss: 0.043202, loss_s1: 0.038690, loss_fp: 0.004571, loss_freq: 0.009889
[05:31:51.068] iteration 17146: loss: 0.050438, loss_s1: 0.021226, loss_fp: 0.003710, loss_freq: 0.037869
[05:31:51.723] iteration 17147: loss: 0.077848, loss_s1: 0.016632, loss_fp: 0.007830, loss_freq: 0.023739
[05:31:52.355] iteration 17148: loss: 0.087013, loss_s1: 0.072534, loss_fp: 0.003829, loss_freq: 0.054872
[05:31:52.986] iteration 17149: loss: 0.100786, loss_s1: 0.127134, loss_fp: 0.007929, loss_freq: 0.041121
[05:31:53.613] iteration 17150: loss: 0.071188, loss_s1: 0.044004, loss_fp: 0.009946, loss_freq: 0.039487
[05:31:54.245] iteration 17151: loss: 0.066054, loss_s1: 0.082133, loss_fp: 0.004104, loss_freq: 0.008491
[05:31:54.880] iteration 17152: loss: 0.092749, loss_s1: 0.108071, loss_fp: 0.001321, loss_freq: 0.044383
[05:31:55.536] iteration 17153: loss: 0.092540, loss_s1: 0.065539, loss_fp: 0.004066, loss_freq: 0.067102
[05:31:56.167] iteration 17154: loss: 0.096438, loss_s1: 0.084185, loss_fp: 0.011306, loss_freq: 0.058562
[05:31:56.838] iteration 17155: loss: 0.059154, loss_s1: 0.046591, loss_fp: 0.010307, loss_freq: 0.022058
[05:31:57.477] iteration 17156: loss: 0.057373, loss_s1: 0.038256, loss_fp: 0.001744, loss_freq: 0.032047
[05:31:58.111] iteration 17157: loss: 0.051138, loss_s1: 0.026767, loss_fp: 0.007990, loss_freq: 0.026296
[05:31:58.764] iteration 17158: loss: 0.059135, loss_s1: 0.029328, loss_fp: 0.004667, loss_freq: 0.044654
[05:31:59.390] iteration 17159: loss: 0.053785, loss_s1: 0.056057, loss_fp: 0.003424, loss_freq: 0.018350
[05:32:00.013] iteration 17160: loss: 0.057059, loss_s1: 0.045898, loss_fp: 0.003935, loss_freq: 0.024363
[05:32:00.657] iteration 17161: loss: 0.056230, loss_s1: 0.052902, loss_fp: 0.002638, loss_freq: 0.008941
[05:32:01.303] iteration 17162: loss: 0.073179, loss_s1: 0.062336, loss_fp: 0.003520, loss_freq: 0.058213
[05:32:01.935] iteration 17163: loss: 0.042340, loss_s1: 0.028922, loss_fp: 0.004547, loss_freq: 0.011373
[05:32:02.566] iteration 17164: loss: 0.058628, loss_s1: 0.056754, loss_fp: 0.001815, loss_freq: 0.027820
[05:32:03.227] iteration 17165: loss: 0.041279, loss_s1: 0.016199, loss_fp: 0.006232, loss_freq: 0.011645
[05:32:03.852] iteration 17166: loss: 0.086238, loss_s1: 0.087270, loss_fp: 0.006196, loss_freq: 0.047949
[05:32:04.478] iteration 17167: loss: 0.057233, loss_s1: 0.047907, loss_fp: 0.009798, loss_freq: 0.016263
[05:32:05.142] iteration 17168: loss: 0.086462, loss_s1: 0.096058, loss_fp: 0.005162, loss_freq: 0.034374
[05:32:05.789] iteration 17169: loss: 0.052098, loss_s1: 0.039960, loss_fp: 0.003591, loss_freq: 0.031596
[05:32:06.417] iteration 17170: loss: 0.066496, loss_s1: 0.053435, loss_fp: 0.003492, loss_freq: 0.039797
[05:32:07.551] iteration 17171: loss: 0.051848, loss_s1: 0.048451, loss_fp: 0.002763, loss_freq: 0.014302
[05:32:08.364] iteration 17172: loss: 0.050746, loss_s1: 0.034468, loss_fp: 0.002072, loss_freq: 0.027930
[05:32:09.086] iteration 17173: loss: 0.046292, loss_s1: 0.033510, loss_fp: 0.002774, loss_freq: 0.027355
[05:32:09.802] iteration 17174: loss: 0.036009, loss_s1: 0.022025, loss_fp: 0.001658, loss_freq: 0.014276
[05:32:10.491] iteration 17175: loss: 0.045984, loss_s1: 0.041518, loss_fp: 0.001421, loss_freq: 0.018376
[05:32:11.321] iteration 17176: loss: 0.085030, loss_s1: 0.104901, loss_fp: 0.003101, loss_freq: 0.018232
[05:32:11.991] iteration 17177: loss: 0.045016, loss_s1: 0.019121, loss_fp: 0.003177, loss_freq: 0.031274
[05:32:12.662] iteration 17178: loss: 0.058187, loss_s1: 0.058992, loss_fp: 0.006320, loss_freq: 0.024721
[05:32:13.442] iteration 17179: loss: 0.036785, loss_s1: 0.031642, loss_fp: 0.001860, loss_freq: 0.015636
[05:32:14.106] iteration 17180: loss: 0.071555, loss_s1: 0.052488, loss_fp: 0.003601, loss_freq: 0.040180
[05:32:14.879] iteration 17181: loss: 0.076675, loss_s1: 0.058565, loss_fp: 0.008494, loss_freq: 0.015003
[05:32:15.628] iteration 17182: loss: 0.082552, loss_s1: 0.093295, loss_fp: 0.001260, loss_freq: 0.038066
[05:32:16.374] iteration 17183: loss: 0.064896, loss_s1: 0.043952, loss_fp: 0.002938, loss_freq: 0.035542
[05:32:17.184] iteration 17184: loss: 0.079818, loss_s1: 0.086432, loss_fp: 0.002423, loss_freq: 0.043543
[05:32:17.850] iteration 17185: loss: 0.056945, loss_s1: 0.055999, loss_fp: 0.005289, loss_freq: 0.016594
[05:32:18.634] iteration 17186: loss: 0.065080, loss_s1: 0.060964, loss_fp: 0.001718, loss_freq: 0.029228
[05:32:19.363] iteration 17187: loss: 0.113111, loss_s1: 0.140391, loss_fp: 0.002860, loss_freq: 0.060515
[05:32:20.068] iteration 17188: loss: 0.042985, loss_s1: 0.035755, loss_fp: 0.001677, loss_freq: 0.017692
[05:32:20.846] iteration 17189: loss: 0.079641, loss_s1: 0.078853, loss_fp: 0.005337, loss_freq: 0.045806
[05:32:21.502] iteration 17190: loss: 0.054052, loss_s1: 0.045793, loss_fp: 0.003837, loss_freq: 0.019864
[05:32:22.171] iteration 17191: loss: 0.067691, loss_s1: 0.045928, loss_fp: 0.006029, loss_freq: 0.041618
[05:32:22.879] iteration 17192: loss: 0.068587, loss_s1: 0.065065, loss_fp: 0.001657, loss_freq: 0.030067
[05:32:23.602] iteration 17193: loss: 0.076489, loss_s1: 0.074726, loss_fp: 0.003436, loss_freq: 0.033701
[05:32:24.247] iteration 17194: loss: 0.052895, loss_s1: 0.040553, loss_fp: 0.001659, loss_freq: 0.029052
[05:32:24.888] iteration 17195: loss: 0.073153, loss_s1: 0.041887, loss_fp: 0.002048, loss_freq: 0.032445
[05:32:25.525] iteration 17196: loss: 0.053164, loss_s1: 0.049606, loss_fp: 0.003298, loss_freq: 0.023539
[05:32:26.157] iteration 17197: loss: 0.071633, loss_s1: 0.072928, loss_fp: 0.003946, loss_freq: 0.029670
[05:32:26.805] iteration 17198: loss: 0.104460, loss_s1: 0.057795, loss_fp: 0.006652, loss_freq: 0.093077
[05:32:27.444] iteration 17199: loss: 0.066534, loss_s1: 0.038430, loss_fp: 0.005188, loss_freq: 0.022200
[05:32:28.075] iteration 17200: loss: 0.110989, loss_s1: 0.104503, loss_fp: 0.008543, loss_freq: 0.076795
[05:32:31.585] iteration 17200 : mean_dice : 0.727206
[05:32:32.292] iteration 17201: loss: 0.079939, loss_s1: 0.076721, loss_fp: 0.004015, loss_freq: 0.055553
[05:32:32.967] iteration 17202: loss: 0.090599, loss_s1: 0.067883, loss_fp: 0.008550, loss_freq: 0.062167
[05:32:33.639] iteration 17203: loss: 0.090289, loss_s1: 0.111465, loss_fp: 0.007368, loss_freq: 0.033336
[05:32:34.323] iteration 17204: loss: 0.030007, loss_s1: 0.012265, loss_fp: 0.007301, loss_freq: 0.012094
[05:32:34.995] iteration 17205: loss: 0.073828, loss_s1: 0.073199, loss_fp: 0.003310, loss_freq: 0.043135
[05:32:35.687] iteration 17206: loss: 0.054410, loss_s1: 0.031431, loss_fp: 0.003274, loss_freq: 0.024877
[05:32:36.367] iteration 17207: loss: 0.057612, loss_s1: 0.045817, loss_fp: 0.003778, loss_freq: 0.023970
[05:32:37.043] iteration 17208: loss: 0.090596, loss_s1: 0.094095, loss_fp: 0.004284, loss_freq: 0.052499
[05:32:37.728] iteration 17209: loss: 0.075864, loss_s1: 0.064591, loss_fp: 0.002296, loss_freq: 0.043984
[05:32:38.415] iteration 17210: loss: 0.070849, loss_s1: 0.048652, loss_fp: 0.006293, loss_freq: 0.047928
[05:32:39.085] iteration 17211: loss: 0.123997, loss_s1: 0.140717, loss_fp: 0.010473, loss_freq: 0.061280
[05:32:39.752] iteration 17212: loss: 0.068293, loss_s1: 0.059909, loss_fp: 0.006218, loss_freq: 0.035156
[05:32:40.423] iteration 17213: loss: 0.124314, loss_s1: 0.133834, loss_fp: 0.002185, loss_freq: 0.082438
[05:32:41.104] iteration 17214: loss: 0.114069, loss_s1: 0.096543, loss_fp: 0.003962, loss_freq: 0.064505
[05:32:41.762] iteration 17215: loss: 0.055078, loss_s1: 0.023352, loss_fp: 0.005948, loss_freq: 0.031020
[05:32:42.406] iteration 17216: loss: 0.054915, loss_s1: 0.046022, loss_fp: 0.004982, loss_freq: 0.021458
[05:32:43.043] iteration 17217: loss: 0.054687, loss_s1: 0.035761, loss_fp: 0.002973, loss_freq: 0.039110
[05:32:43.945] iteration 17218: loss: 0.057553, loss_s1: 0.027761, loss_fp: 0.003540, loss_freq: 0.040716
[05:32:44.804] iteration 17219: loss: 0.042122, loss_s1: 0.044702, loss_fp: 0.001646, loss_freq: 0.006416
[05:32:45.700] iteration 17220: loss: 0.031291, loss_s1: 0.008224, loss_fp: 0.002442, loss_freq: 0.010932
[05:32:46.549] iteration 17221: loss: 0.057965, loss_s1: 0.038622, loss_fp: 0.003111, loss_freq: 0.034689
[05:32:47.466] iteration 17222: loss: 0.033186, loss_s1: 0.023637, loss_fp: 0.003787, loss_freq: 0.014275
[05:32:48.439] iteration 17223: loss: 0.034660, loss_s1: 0.016863, loss_fp: 0.003299, loss_freq: 0.012575
[05:32:49.111] iteration 17224: loss: 0.119688, loss_s1: 0.139226, loss_fp: 0.004444, loss_freq: 0.064100
[05:32:49.795] iteration 17225: loss: 0.029204, loss_s1: 0.010292, loss_fp: 0.001902, loss_freq: 0.011856
[05:32:50.456] iteration 17226: loss: 0.028770, loss_s1: 0.012039, loss_fp: 0.001548, loss_freq: 0.007202
[05:32:51.108] iteration 17227: loss: 0.067524, loss_s1: 0.043105, loss_fp: 0.006495, loss_freq: 0.045649
[05:32:51.770] iteration 17228: loss: 0.051910, loss_s1: 0.039039, loss_fp: 0.000672, loss_freq: 0.010488
[05:32:52.412] iteration 17229: loss: 0.049744, loss_s1: 0.032245, loss_fp: 0.002561, loss_freq: 0.034757
[05:32:53.054] iteration 17230: loss: 0.064858, loss_s1: 0.046305, loss_fp: 0.004648, loss_freq: 0.041014
[05:32:53.688] iteration 17231: loss: 0.052565, loss_s1: 0.057010, loss_fp: 0.002855, loss_freq: 0.016617
[05:32:54.324] iteration 17232: loss: 0.081327, loss_s1: 0.059391, loss_fp: 0.003547, loss_freq: 0.039427
[05:32:54.979] iteration 17233: loss: 0.055043, loss_s1: 0.061438, loss_fp: 0.000828, loss_freq: 0.008162
[05:32:55.620] iteration 17234: loss: 0.053936, loss_s1: 0.063891, loss_fp: 0.001389, loss_freq: 0.013845
[05:32:56.279] iteration 17235: loss: 0.056306, loss_s1: 0.053533, loss_fp: 0.009274, loss_freq: 0.014825
[05:32:56.915] iteration 17236: loss: 0.063560, loss_s1: 0.051276, loss_fp: 0.002349, loss_freq: 0.047298
[05:32:57.547] iteration 17237: loss: 0.055208, loss_s1: 0.048671, loss_fp: 0.001980, loss_freq: 0.009232
[05:32:58.182] iteration 17238: loss: 0.122701, loss_s1: 0.139938, loss_fp: 0.011509, loss_freq: 0.059360
[05:32:58.821] iteration 17239: loss: 0.041426, loss_s1: 0.020509, loss_fp: 0.002262, loss_freq: 0.022863
[05:32:59.457] iteration 17240: loss: 0.056880, loss_s1: 0.043018, loss_fp: 0.002034, loss_freq: 0.038077
[05:33:00.089] iteration 17241: loss: 0.079253, loss_s1: 0.058999, loss_fp: 0.004310, loss_freq: 0.044378
[05:33:00.729] iteration 17242: loss: 0.062259, loss_s1: 0.049793, loss_fp: 0.002634, loss_freq: 0.034731
[05:33:01.372] iteration 17243: loss: 0.060707, loss_s1: 0.046337, loss_fp: 0.002924, loss_freq: 0.040662
[05:33:02.013] iteration 17244: loss: 0.090414, loss_s1: 0.098127, loss_fp: 0.016308, loss_freq: 0.027123
[05:33:02.677] iteration 17245: loss: 0.053174, loss_s1: 0.039132, loss_fp: 0.001713, loss_freq: 0.034954
[05:33:03.313] iteration 17246: loss: 0.079926, loss_s1: 0.031095, loss_fp: 0.009464, loss_freq: 0.061031
[05:33:03.952] iteration 17247: loss: 0.062193, loss_s1: 0.036187, loss_fp: 0.004222, loss_freq: 0.027194
[05:33:04.588] iteration 17248: loss: 0.058281, loss_s1: 0.046267, loss_fp: 0.004412, loss_freq: 0.029777
[05:33:05.222] iteration 17249: loss: 0.045077, loss_s1: 0.016550, loss_fp: 0.006167, loss_freq: 0.035469
[05:33:05.877] iteration 17250: loss: 0.049000, loss_s1: 0.031515, loss_fp: 0.003287, loss_freq: 0.018441
[05:33:06.528] iteration 17251: loss: 0.083318, loss_s1: 0.077231, loss_fp: 0.003457, loss_freq: 0.030386
[05:33:07.167] iteration 17252: loss: 0.046439, loss_s1: 0.036586, loss_fp: 0.004674, loss_freq: 0.013315
[05:33:07.817] iteration 17253: loss: 0.069066, loss_s1: 0.068576, loss_fp: 0.001159, loss_freq: 0.033513
[05:33:08.455] iteration 17254: loss: 0.051327, loss_s1: 0.036481, loss_fp: 0.007909, loss_freq: 0.017411
[05:33:09.105] iteration 17255: loss: 0.055545, loss_s1: 0.049031, loss_fp: 0.002962, loss_freq: 0.015270
[05:33:09.744] iteration 17256: loss: 0.052549, loss_s1: 0.043858, loss_fp: 0.001388, loss_freq: 0.029268
[05:33:10.384] iteration 17257: loss: 0.069308, loss_s1: 0.055707, loss_fp: 0.001768, loss_freq: 0.038906
[05:33:11.012] iteration 17258: loss: 0.091020, loss_s1: 0.103580, loss_fp: 0.001340, loss_freq: 0.034485
[05:33:11.641] iteration 17259: loss: 0.056575, loss_s1: 0.052363, loss_fp: 0.002763, loss_freq: 0.023352
[05:33:12.273] iteration 17260: loss: 0.062396, loss_s1: 0.029535, loss_fp: 0.000816, loss_freq: 0.053093
[05:33:12.904] iteration 17261: loss: 0.082340, loss_s1: 0.069820, loss_fp: 0.004828, loss_freq: 0.052269
[05:33:13.548] iteration 17262: loss: 0.074034, loss_s1: 0.084681, loss_fp: 0.005509, loss_freq: 0.027265
[05:33:14.201] iteration 17263: loss: 0.107904, loss_s1: 0.052773, loss_fp: 0.003672, loss_freq: 0.069036
[05:33:14.828] iteration 17264: loss: 0.040539, loss_s1: 0.018427, loss_fp: 0.001166, loss_freq: 0.031872
[05:33:15.470] iteration 17265: loss: 0.055900, loss_s1: 0.030284, loss_fp: 0.004899, loss_freq: 0.041984
[05:33:16.104] iteration 17266: loss: 0.061619, loss_s1: 0.048488, loss_fp: 0.003216, loss_freq: 0.037972
[05:33:16.735] iteration 17267: loss: 0.072512, loss_s1: 0.060273, loss_fp: 0.004098, loss_freq: 0.033073
[05:33:17.384] iteration 17268: loss: 0.049236, loss_s1: 0.035716, loss_fp: 0.000819, loss_freq: 0.022503
[05:33:18.033] iteration 17269: loss: 0.058611, loss_s1: 0.031944, loss_fp: 0.002626, loss_freq: 0.051560
[05:33:18.672] iteration 17270: loss: 0.048615, loss_s1: 0.030178, loss_fp: 0.000979, loss_freq: 0.026123
[05:33:19.310] iteration 17271: loss: 0.064554, loss_s1: 0.078095, loss_fp: 0.002892, loss_freq: 0.023626
[05:33:19.947] iteration 17272: loss: 0.064632, loss_s1: 0.040190, loss_fp: 0.001852, loss_freq: 0.020822
[05:33:20.589] iteration 17273: loss: 0.029324, loss_s1: 0.013652, loss_fp: 0.004230, loss_freq: 0.012257
[05:33:21.229] iteration 17274: loss: 0.052681, loss_s1: 0.040272, loss_fp: 0.003849, loss_freq: 0.018116
[05:33:21.871] iteration 17275: loss: 0.039036, loss_s1: 0.021605, loss_fp: 0.002611, loss_freq: 0.023561
[05:33:22.505] iteration 17276: loss: 0.078253, loss_s1: 0.054142, loss_fp: 0.003668, loss_freq: 0.026898
[05:33:23.152] iteration 17277: loss: 0.061005, loss_s1: 0.035344, loss_fp: 0.009245, loss_freq: 0.040326
[05:33:23.790] iteration 17278: loss: 0.048075, loss_s1: 0.044438, loss_fp: 0.002405, loss_freq: 0.015335
[05:33:24.438] iteration 17279: loss: 0.065959, loss_s1: 0.051167, loss_fp: 0.008187, loss_freq: 0.032639
[05:33:25.084] iteration 17280: loss: 0.043651, loss_s1: 0.029768, loss_fp: 0.005209, loss_freq: 0.021571
[05:33:25.740] iteration 17281: loss: 0.051975, loss_s1: 0.033433, loss_fp: 0.001433, loss_freq: 0.020395
[05:33:26.369] iteration 17282: loss: 0.063706, loss_s1: 0.063731, loss_fp: 0.012450, loss_freq: 0.020458
[05:33:27.014] iteration 17283: loss: 0.061337, loss_s1: 0.059293, loss_fp: 0.003132, loss_freq: 0.021494
[05:33:27.650] iteration 17284: loss: 0.042416, loss_s1: 0.016300, loss_fp: 0.001881, loss_freq: 0.009891
[05:33:28.283] iteration 17285: loss: 0.103222, loss_s1: 0.054178, loss_fp: 0.004104, loss_freq: 0.092181
[05:33:28.916] iteration 17286: loss: 0.063386, loss_s1: 0.049447, loss_fp: 0.007303, loss_freq: 0.034246
[05:33:29.546] iteration 17287: loss: 0.050561, loss_s1: 0.045843, loss_fp: 0.001255, loss_freq: 0.019180
[05:33:30.206] iteration 17288: loss: 0.056141, loss_s1: 0.048637, loss_fp: 0.011124, loss_freq: 0.019639
[05:33:30.833] iteration 17289: loss: 0.070427, loss_s1: 0.053577, loss_fp: 0.005022, loss_freq: 0.048180
[05:33:31.482] iteration 17290: loss: 0.069017, loss_s1: 0.075272, loss_fp: 0.001104, loss_freq: 0.021237
[05:33:32.106] iteration 17291: loss: 0.036950, loss_s1: 0.025820, loss_fp: 0.003436, loss_freq: 0.007815
[05:33:32.734] iteration 17292: loss: 0.077224, loss_s1: 0.079774, loss_fp: 0.002772, loss_freq: 0.046692
[05:33:33.372] iteration 17293: loss: 0.109101, loss_s1: 0.048436, loss_fp: 0.006286, loss_freq: 0.115347
[05:33:34.025] iteration 17294: loss: 0.060683, loss_s1: 0.045598, loss_fp: 0.007084, loss_freq: 0.032044
[05:33:34.650] iteration 17295: loss: 0.073008, loss_s1: 0.048821, loss_fp: 0.002104, loss_freq: 0.049653
[05:33:35.275] iteration 17296: loss: 0.041692, loss_s1: 0.022534, loss_fp: 0.001566, loss_freq: 0.023107
[05:33:35.916] iteration 17297: loss: 0.063799, loss_s1: 0.044769, loss_fp: 0.000959, loss_freq: 0.058151
[05:33:36.546] iteration 17298: loss: 0.064027, loss_s1: 0.061597, loss_fp: 0.005779, loss_freq: 0.013344
[05:33:37.173] iteration 17299: loss: 0.050722, loss_s1: 0.042746, loss_fp: 0.006004, loss_freq: 0.023458
[05:33:37.813] iteration 17300: loss: 0.072874, loss_s1: 0.062080, loss_fp: 0.005528, loss_freq: 0.041040
[05:33:38.466] iteration 17301: loss: 0.098953, loss_s1: 0.139373, loss_fp: 0.003041, loss_freq: 0.027304
[05:33:39.204] iteration 17302: loss: 0.096654, loss_s1: 0.061556, loss_fp: 0.008493, loss_freq: 0.033319
[05:33:39.928] iteration 17303: loss: 0.064429, loss_s1: 0.057721, loss_fp: 0.001432, loss_freq: 0.031949
[05:33:40.624] iteration 17304: loss: 0.068396, loss_s1: 0.050993, loss_fp: 0.016246, loss_freq: 0.040893
[05:33:41.300] iteration 17305: loss: 0.126649, loss_s1: 0.094572, loss_fp: 0.001439, loss_freq: 0.118624
[05:33:41.987] iteration 17306: loss: 0.037407, loss_s1: 0.020980, loss_fp: 0.004673, loss_freq: 0.015354
[05:33:42.631] iteration 17307: loss: 0.077782, loss_s1: 0.069511, loss_fp: 0.003711, loss_freq: 0.030823
[05:33:43.263] iteration 17308: loss: 0.059753, loss_s1: 0.029902, loss_fp: 0.002513, loss_freq: 0.054878
[05:33:43.904] iteration 17309: loss: 0.104743, loss_s1: 0.119716, loss_fp: 0.006423, loss_freq: 0.055210
[05:33:44.542] iteration 17310: loss: 0.046343, loss_s1: 0.057646, loss_fp: 0.002333, loss_freq: 0.010686
[05:33:45.171] iteration 17311: loss: 0.069986, loss_s1: 0.046714, loss_fp: 0.005076, loss_freq: 0.032858
[05:33:45.807] iteration 17312: loss: 0.066492, loss_s1: 0.068304, loss_fp: 0.003420, loss_freq: 0.022068
[05:33:46.435] iteration 17313: loss: 0.067519, loss_s1: 0.072750, loss_fp: 0.000973, loss_freq: 0.027872
[05:33:47.077] iteration 17314: loss: 0.082702, loss_s1: 0.102817, loss_fp: 0.003997, loss_freq: 0.013369
[05:33:47.719] iteration 17315: loss: 0.073524, loss_s1: 0.073457, loss_fp: 0.003038, loss_freq: 0.028694
[05:33:48.351] iteration 17316: loss: 0.066376, loss_s1: 0.056096, loss_fp: 0.003703, loss_freq: 0.031547
[05:33:49.039] iteration 17317: loss: 0.099953, loss_s1: 0.034612, loss_fp: 0.002738, loss_freq: 0.067629
[05:33:49.717] iteration 17318: loss: 0.083224, loss_s1: 0.088516, loss_fp: 0.002664, loss_freq: 0.038753
[05:33:50.394] iteration 17319: loss: 0.093565, loss_s1: 0.100440, loss_fp: 0.001116, loss_freq: 0.041447
[05:33:51.066] iteration 17320: loss: 0.056913, loss_s1: 0.033442, loss_fp: 0.005270, loss_freq: 0.033544
[05:33:51.707] iteration 17321: loss: 0.064469, loss_s1: 0.040443, loss_fp: 0.001128, loss_freq: 0.037258
[05:33:52.346] iteration 17322: loss: 0.067226, loss_s1: 0.052742, loss_fp: 0.006573, loss_freq: 0.036305
[05:33:52.988] iteration 17323: loss: 0.105110, loss_s1: 0.098537, loss_fp: 0.002822, loss_freq: 0.067533
[05:33:53.626] iteration 17324: loss: 0.071052, loss_s1: 0.049453, loss_fp: 0.004434, loss_freq: 0.051885
[05:33:54.298] iteration 17325: loss: 0.087064, loss_s1: 0.041928, loss_fp: 0.004481, loss_freq: 0.069502
[05:33:54.941] iteration 17326: loss: 0.047675, loss_s1: 0.033226, loss_fp: 0.000825, loss_freq: 0.017288
[05:33:55.575] iteration 17327: loss: 0.055475, loss_s1: 0.023747, loss_fp: 0.002445, loss_freq: 0.044143
[05:33:56.200] iteration 17328: loss: 0.065094, loss_s1: 0.026762, loss_fp: 0.001792, loss_freq: 0.066449
[05:33:56.842] iteration 17329: loss: 0.064734, loss_s1: 0.049036, loss_fp: 0.005932, loss_freq: 0.037262
[05:33:57.500] iteration 17330: loss: 0.077504, loss_s1: 0.079185, loss_fp: 0.010632, loss_freq: 0.029283
[05:33:58.142] iteration 17331: loss: 0.057590, loss_s1: 0.062539, loss_fp: 0.002163, loss_freq: 0.012843
[05:33:58.789] iteration 17332: loss: 0.052638, loss_s1: 0.035491, loss_fp: 0.005958, loss_freq: 0.036578
[05:33:59.429] iteration 17333: loss: 0.043956, loss_s1: 0.019340, loss_fp: 0.008280, loss_freq: 0.015955
[05:34:00.094] iteration 17334: loss: 0.056999, loss_s1: 0.046206, loss_fp: 0.003890, loss_freq: 0.035702
[05:34:00.732] iteration 17335: loss: 0.042950, loss_s1: 0.021016, loss_fp: 0.003538, loss_freq: 0.014429
[05:34:01.379] iteration 17336: loss: 0.089252, loss_s1: 0.099834, loss_fp: 0.002168, loss_freq: 0.043439
[05:34:02.015] iteration 17337: loss: 0.068044, loss_s1: 0.063124, loss_fp: 0.001465, loss_freq: 0.033844
[05:34:02.648] iteration 17338: loss: 0.041924, loss_s1: 0.027364, loss_fp: 0.006682, loss_freq: 0.007893
[05:34:03.291] iteration 17339: loss: 0.080589, loss_s1: 0.069551, loss_fp: 0.006679, loss_freq: 0.041350
[05:34:03.914] iteration 17340: loss: 0.066558, loss_s1: 0.051361, loss_fp: 0.008516, loss_freq: 0.030289
[05:34:04.885] iteration 17341: loss: 0.063331, loss_s1: 0.055584, loss_fp: 0.002065, loss_freq: 0.029169
[05:34:05.530] iteration 17342: loss: 0.063415, loss_s1: 0.040260, loss_fp: 0.004201, loss_freq: 0.045210
[05:34:06.187] iteration 17343: loss: 0.075807, loss_s1: 0.071740, loss_fp: 0.006081, loss_freq: 0.038323
[05:34:06.813] iteration 17344: loss: 0.051859, loss_s1: 0.047040, loss_fp: 0.005670, loss_freq: 0.014295
[05:34:07.439] iteration 17345: loss: 0.047380, loss_s1: 0.037022, loss_fp: 0.002018, loss_freq: 0.016587
[05:34:08.056] iteration 17346: loss: 0.076104, loss_s1: 0.069276, loss_fp: 0.016018, loss_freq: 0.031001
[05:34:08.680] iteration 17347: loss: 0.056258, loss_s1: 0.048186, loss_fp: 0.001624, loss_freq: 0.027119
[05:34:09.342] iteration 17348: loss: 0.030147, loss_s1: 0.021219, loss_fp: 0.003015, loss_freq: 0.007678
[05:34:10.059] iteration 17349: loss: 0.038361, loss_s1: 0.030737, loss_fp: 0.001794, loss_freq: 0.014760
[05:34:10.791] iteration 17350: loss: 0.053903, loss_s1: 0.036535, loss_fp: 0.004986, loss_freq: 0.026210
[05:34:11.481] iteration 17351: loss: 0.063932, loss_s1: 0.031682, loss_fp: 0.002905, loss_freq: 0.048883
[05:34:12.195] iteration 17352: loss: 0.070711, loss_s1: 0.044122, loss_fp: 0.006324, loss_freq: 0.059386
[05:34:12.876] iteration 17353: loss: 0.087245, loss_s1: 0.087566, loss_fp: 0.005982, loss_freq: 0.036157
[05:34:13.612] iteration 17354: loss: 0.089123, loss_s1: 0.077037, loss_fp: 0.006784, loss_freq: 0.060149
[05:34:14.286] iteration 17355: loss: 0.043470, loss_s1: 0.020954, loss_fp: 0.006162, loss_freq: 0.020789
[05:34:14.938] iteration 17356: loss: 0.073927, loss_s1: 0.046744, loss_fp: 0.005355, loss_freq: 0.045035
[05:34:15.599] iteration 17357: loss: 0.122249, loss_s1: 0.052412, loss_fp: 0.001822, loss_freq: 0.164663
[05:34:16.226] iteration 17358: loss: 0.041417, loss_s1: 0.026076, loss_fp: 0.001245, loss_freq: 0.014386
[05:34:16.867] iteration 17359: loss: 0.074034, loss_s1: 0.070668, loss_fp: 0.004051, loss_freq: 0.040172
[05:34:17.505] iteration 17360: loss: 0.057210, loss_s1: 0.042379, loss_fp: 0.004119, loss_freq: 0.020202
[05:34:18.282] iteration 17361: loss: 0.050611, loss_s1: 0.035898, loss_fp: 0.003926, loss_freq: 0.028913
[05:34:19.180] iteration 17362: loss: 0.094717, loss_s1: 0.074940, loss_fp: 0.006327, loss_freq: 0.060492
[05:34:20.041] iteration 17363: loss: 0.087771, loss_s1: 0.070162, loss_fp: 0.008478, loss_freq: 0.045055
[05:34:20.850] iteration 17364: loss: 0.059203, loss_s1: 0.030558, loss_fp: 0.005005, loss_freq: 0.042002
[05:34:21.537] iteration 17365: loss: 0.084272, loss_s1: 0.090057, loss_fp: 0.001575, loss_freq: 0.038813
[05:34:22.187] iteration 17366: loss: 0.052687, loss_s1: 0.042316, loss_fp: 0.002159, loss_freq: 0.033537
[05:34:22.808] iteration 17367: loss: 0.064328, loss_s1: 0.046746, loss_fp: 0.006632, loss_freq: 0.016091
[05:34:23.430] iteration 17368: loss: 0.124041, loss_s1: 0.099758, loss_fp: 0.006667, loss_freq: 0.056911
[05:34:24.048] iteration 17369: loss: 0.043448, loss_s1: 0.025848, loss_fp: 0.001021, loss_freq: 0.023260
[05:34:24.667] iteration 17370: loss: 0.087683, loss_s1: 0.081815, loss_fp: 0.007034, loss_freq: 0.046349
[05:34:25.283] iteration 17371: loss: 0.064482, loss_s1: 0.033545, loss_fp: 0.004893, loss_freq: 0.042095
[05:34:25.907] iteration 17372: loss: 0.099927, loss_s1: 0.074085, loss_fp: 0.005456, loss_freq: 0.077649
[05:34:26.544] iteration 17373: loss: 0.084572, loss_s1: 0.066813, loss_fp: 0.006881, loss_freq: 0.038568
[05:34:27.177] iteration 17374: loss: 0.067936, loss_s1: 0.026757, loss_fp: 0.014660, loss_freq: 0.036589
[05:34:27.828] iteration 17375: loss: 0.061427, loss_s1: 0.079184, loss_fp: 0.004260, loss_freq: 0.017384
[05:34:28.457] iteration 17376: loss: 0.064229, loss_s1: 0.047790, loss_fp: 0.002492, loss_freq: 0.019399
[05:34:29.088] iteration 17377: loss: 0.060452, loss_s1: 0.046524, loss_fp: 0.004761, loss_freq: 0.024286
[05:34:29.734] iteration 17378: loss: 0.048918, loss_s1: 0.051523, loss_fp: 0.001149, loss_freq: 0.011585
[05:34:30.361] iteration 17379: loss: 0.075960, loss_s1: 0.048610, loss_fp: 0.002807, loss_freq: 0.060456
[05:34:30.992] iteration 17380: loss: 0.055966, loss_s1: 0.043600, loss_fp: 0.002403, loss_freq: 0.025394
[05:34:31.631] iteration 17381: loss: 0.100847, loss_s1: 0.093438, loss_fp: 0.002599, loss_freq: 0.046297
[05:34:32.323] iteration 17382: loss: 0.050272, loss_s1: 0.041584, loss_fp: 0.005378, loss_freq: 0.019305
[05:34:33.008] iteration 17383: loss: 0.148272, loss_s1: 0.118967, loss_fp: 0.003081, loss_freq: 0.143523
[05:34:33.657] iteration 17384: loss: 0.087699, loss_s1: 0.086744, loss_fp: 0.003166, loss_freq: 0.055038
[05:34:34.305] iteration 17385: loss: 0.067141, loss_s1: 0.055850, loss_fp: 0.002542, loss_freq: 0.026412
[05:34:34.960] iteration 17386: loss: 0.050743, loss_s1: 0.044351, loss_fp: 0.004107, loss_freq: 0.018117
[05:34:35.610] iteration 17387: loss: 0.045114, loss_s1: 0.017014, loss_fp: 0.004958, loss_freq: 0.028924
[05:34:36.291] iteration 17388: loss: 0.060881, loss_s1: 0.040125, loss_fp: 0.006743, loss_freq: 0.039071
[05:34:36.953] iteration 17389: loss: 0.045983, loss_s1: 0.028711, loss_fp: 0.002181, loss_freq: 0.012041
[05:34:37.592] iteration 17390: loss: 0.038454, loss_s1: 0.009974, loss_fp: 0.000662, loss_freq: 0.020746
[05:34:38.227] iteration 17391: loss: 0.056766, loss_s1: 0.058348, loss_fp: 0.001966, loss_freq: 0.017076
[05:34:38.872] iteration 17392: loss: 0.035203, loss_s1: 0.017080, loss_fp: 0.004246, loss_freq: 0.018041
[05:34:39.510] iteration 17393: loss: 0.053676, loss_s1: 0.038403, loss_fp: 0.001302, loss_freq: 0.022492
[05:34:40.147] iteration 17394: loss: 0.066427, loss_s1: 0.048054, loss_fp: 0.002828, loss_freq: 0.033787
[05:34:40.785] iteration 17395: loss: 0.047893, loss_s1: 0.024523, loss_fp: 0.002795, loss_freq: 0.031599
[05:34:41.431] iteration 17396: loss: 0.051440, loss_s1: 0.054372, loss_fp: 0.001229, loss_freq: 0.012808
[05:34:42.055] iteration 17397: loss: 0.048916, loss_s1: 0.029805, loss_fp: 0.003662, loss_freq: 0.036748
[05:34:42.692] iteration 17398: loss: 0.070495, loss_s1: 0.062536, loss_fp: 0.001013, loss_freq: 0.012199
[05:34:43.332] iteration 17399: loss: 0.055576, loss_s1: 0.032271, loss_fp: 0.001807, loss_freq: 0.043511
[05:34:43.978] iteration 17400: loss: 0.063657, loss_s1: 0.048763, loss_fp: 0.003501, loss_freq: 0.040705
[05:34:47.640] iteration 17400 : mean_dice : 0.720166
[05:34:48.332] iteration 17401: loss: 0.040587, loss_s1: 0.037327, loss_fp: 0.000769, loss_freq: 0.004666
[05:34:48.967] iteration 17402: loss: 0.071534, loss_s1: 0.043928, loss_fp: 0.001896, loss_freq: 0.040661
[05:34:49.713] iteration 17403: loss: 0.042628, loss_s1: 0.025127, loss_fp: 0.002046, loss_freq: 0.011147
[05:34:50.608] iteration 17404: loss: 0.046927, loss_s1: 0.029703, loss_fp: 0.003461, loss_freq: 0.028026
[05:34:51.414] iteration 17405: loss: 0.100104, loss_s1: 0.110140, loss_fp: 0.002799, loss_freq: 0.039903
[05:34:52.115] iteration 17406: loss: 0.055871, loss_s1: 0.056548, loss_fp: 0.002357, loss_freq: 0.023315
[05:34:52.751] iteration 17407: loss: 0.052072, loss_s1: 0.041091, loss_fp: 0.002320, loss_freq: 0.011338
[05:34:53.374] iteration 17408: loss: 0.098483, loss_s1: 0.071585, loss_fp: 0.009466, loss_freq: 0.072280
[05:34:54.047] iteration 17409: loss: 0.077652, loss_s1: 0.037900, loss_fp: 0.004402, loss_freq: 0.019742
[05:34:54.677] iteration 17410: loss: 0.034398, loss_s1: 0.026690, loss_fp: 0.002030, loss_freq: 0.010304
[05:34:55.308] iteration 17411: loss: 0.075985, loss_s1: 0.048180, loss_fp: 0.003959, loss_freq: 0.037815
[05:34:55.936] iteration 17412: loss: 0.059255, loss_s1: 0.016479, loss_fp: 0.002271, loss_freq: 0.058932
[05:34:56.593] iteration 17413: loss: 0.059756, loss_s1: 0.053258, loss_fp: 0.008688, loss_freq: 0.023396
[05:34:57.233] iteration 17414: loss: 0.076871, loss_s1: 0.051129, loss_fp: 0.006676, loss_freq: 0.060539
[05:34:57.871] iteration 17415: loss: 0.066990, loss_s1: 0.033808, loss_fp: 0.007693, loss_freq: 0.062999
[05:34:58.565] iteration 17416: loss: 0.077323, loss_s1: 0.050223, loss_fp: 0.015235, loss_freq: 0.051596
[05:34:59.227] iteration 17417: loss: 0.050757, loss_s1: 0.031553, loss_fp: 0.003064, loss_freq: 0.031761
[05:34:59.868] iteration 17418: loss: 0.112432, loss_s1: 0.113713, loss_fp: 0.006612, loss_freq: 0.051652
[05:35:00.503] iteration 17419: loss: 0.053236, loss_s1: 0.047516, loss_fp: 0.007911, loss_freq: 0.012091
[05:35:01.149] iteration 17420: loss: 0.058329, loss_s1: 0.046927, loss_fp: 0.002947, loss_freq: 0.012995
[05:35:01.785] iteration 17421: loss: 0.077764, loss_s1: 0.085519, loss_fp: 0.003142, loss_freq: 0.031455
[05:35:02.457] iteration 17422: loss: 0.059802, loss_s1: 0.043187, loss_fp: 0.010218, loss_freq: 0.032770
[05:35:03.098] iteration 17423: loss: 0.057686, loss_s1: 0.048999, loss_fp: 0.005932, loss_freq: 0.027132
[05:35:03.744] iteration 17424: loss: 0.049119, loss_s1: 0.044938, loss_fp: 0.002241, loss_freq: 0.018812
[05:35:04.397] iteration 17425: loss: 0.065674, loss_s1: 0.062613, loss_fp: 0.001996, loss_freq: 0.023712
[05:35:05.041] iteration 17426: loss: 0.072307, loss_s1: 0.067577, loss_fp: 0.008797, loss_freq: 0.029478
[05:35:05.685] iteration 17427: loss: 0.094263, loss_s1: 0.128821, loss_fp: 0.002548, loss_freq: 0.024830
[05:35:06.345] iteration 17428: loss: 0.063787, loss_s1: 0.056323, loss_fp: 0.001031, loss_freq: 0.036605
[05:35:06.971] iteration 17429: loss: 0.069588, loss_s1: 0.069523, loss_fp: 0.005941, loss_freq: 0.032328
[05:35:07.634] iteration 17430: loss: 0.052077, loss_s1: 0.037800, loss_fp: 0.002823, loss_freq: 0.017009
[05:35:08.312] iteration 17431: loss: 0.050460, loss_s1: 0.037151, loss_fp: 0.003192, loss_freq: 0.015741
[05:35:08.954] iteration 17432: loss: 0.076265, loss_s1: 0.059995, loss_fp: 0.003584, loss_freq: 0.064525
[05:35:09.598] iteration 17433: loss: 0.094075, loss_s1: 0.107138, loss_fp: 0.004848, loss_freq: 0.030089
[05:35:10.282] iteration 17434: loss: 0.065378, loss_s1: 0.066060, loss_fp: 0.003724, loss_freq: 0.030943
[05:35:10.909] iteration 17435: loss: 0.054171, loss_s1: 0.028510, loss_fp: 0.002088, loss_freq: 0.030178
[05:35:11.548] iteration 17436: loss: 0.069088, loss_s1: 0.074759, loss_fp: 0.001961, loss_freq: 0.031869
[05:35:12.179] iteration 17437: loss: 0.080494, loss_s1: 0.070530, loss_fp: 0.005560, loss_freq: 0.047398
[05:35:12.818] iteration 17438: loss: 0.073974, loss_s1: 0.028576, loss_fp: 0.001831, loss_freq: 0.082941
[05:35:13.476] iteration 17439: loss: 0.042951, loss_s1: 0.019641, loss_fp: 0.007699, loss_freq: 0.027199
[05:35:14.111] iteration 17440: loss: 0.056403, loss_s1: 0.035934, loss_fp: 0.002307, loss_freq: 0.029570
[05:35:14.747] iteration 17441: loss: 0.062265, loss_s1: 0.051537, loss_fp: 0.005631, loss_freq: 0.042558
[05:35:15.391] iteration 17442: loss: 0.060452, loss_s1: 0.051497, loss_fp: 0.004005, loss_freq: 0.020922
[05:35:16.019] iteration 17443: loss: 0.042467, loss_s1: 0.026272, loss_fp: 0.003422, loss_freq: 0.025392
[05:35:16.662] iteration 17444: loss: 0.047168, loss_s1: 0.042185, loss_fp: 0.001694, loss_freq: 0.018601
[05:35:17.300] iteration 17445: loss: 0.029866, loss_s1: 0.023186, loss_fp: 0.002056, loss_freq: 0.009838
[05:35:17.947] iteration 17446: loss: 0.077574, loss_s1: 0.061942, loss_fp: 0.002103, loss_freq: 0.051608
[05:35:18.585] iteration 17447: loss: 0.060776, loss_s1: 0.034778, loss_fp: 0.007845, loss_freq: 0.040578
[05:35:19.215] iteration 17448: loss: 0.066301, loss_s1: 0.067043, loss_fp: 0.001734, loss_freq: 0.034083
[05:35:19.843] iteration 17449: loss: 0.059981, loss_s1: 0.031201, loss_fp: 0.002870, loss_freq: 0.042458
[05:35:20.469] iteration 17450: loss: 0.068221, loss_s1: 0.075842, loss_fp: 0.001007, loss_freq: 0.031533
[05:35:21.104] iteration 17451: loss: 0.094958, loss_s1: 0.103415, loss_fp: 0.004490, loss_freq: 0.034604
[05:35:21.740] iteration 17452: loss: 0.082332, loss_s1: 0.094405, loss_fp: 0.010130, loss_freq: 0.019543
[05:35:22.385] iteration 17453: loss: 0.059030, loss_s1: 0.045828, loss_fp: 0.001635, loss_freq: 0.031005
[05:35:23.019] iteration 17454: loss: 0.037058, loss_s1: 0.025564, loss_fp: 0.001955, loss_freq: 0.018490
[05:35:23.656] iteration 17455: loss: 0.053390, loss_s1: 0.024635, loss_fp: 0.006949, loss_freq: 0.035745
[05:35:24.306] iteration 17456: loss: 0.072844, loss_s1: 0.045519, loss_fp: 0.005132, loss_freq: 0.054298
[05:35:24.951] iteration 17457: loss: 0.069523, loss_s1: 0.028751, loss_fp: 0.005140, loss_freq: 0.033578
[05:35:25.628] iteration 17458: loss: 0.061897, loss_s1: 0.060410, loss_fp: 0.002237, loss_freq: 0.029728
[05:35:26.276] iteration 17459: loss: 0.052967, loss_s1: 0.036416, loss_fp: 0.002167, loss_freq: 0.030411
[05:35:26.917] iteration 17460: loss: 0.038991, loss_s1: 0.013621, loss_fp: 0.003457, loss_freq: 0.023462
[05:35:27.544] iteration 17461: loss: 0.056437, loss_s1: 0.058186, loss_fp: 0.001713, loss_freq: 0.015889
[05:35:28.199] iteration 17462: loss: 0.060814, loss_s1: 0.070756, loss_fp: 0.003044, loss_freq: 0.027810
[05:35:28.827] iteration 17463: loss: 0.110857, loss_s1: 0.085064, loss_fp: 0.007840, loss_freq: 0.083819
[05:35:29.452] iteration 17464: loss: 0.071154, loss_s1: 0.076224, loss_fp: 0.001736, loss_freq: 0.031648
[05:35:30.095] iteration 17465: loss: 0.098060, loss_s1: 0.069571, loss_fp: 0.002202, loss_freq: 0.084863
[05:35:30.740] iteration 17466: loss: 0.086029, loss_s1: 0.089494, loss_fp: 0.002299, loss_freq: 0.040732
[05:35:31.377] iteration 17467: loss: 0.081712, loss_s1: 0.042419, loss_fp: 0.002832, loss_freq: 0.082879
[05:35:32.023] iteration 17468: loss: 0.049279, loss_s1: 0.034261, loss_fp: 0.002197, loss_freq: 0.020745
[05:35:32.652] iteration 17469: loss: 0.110327, loss_s1: 0.104753, loss_fp: 0.004917, loss_freq: 0.041126
[05:35:33.303] iteration 17470: loss: 0.062364, loss_s1: 0.031675, loss_fp: 0.006997, loss_freq: 0.044376
[05:35:33.937] iteration 17471: loss: 0.064492, loss_s1: 0.075312, loss_fp: 0.005055, loss_freq: 0.019196
[05:35:34.575] iteration 17472: loss: 0.093331, loss_s1: 0.109039, loss_fp: 0.006251, loss_freq: 0.021264
[05:35:35.217] iteration 17473: loss: 0.095657, loss_s1: 0.111332, loss_fp: 0.006214, loss_freq: 0.032889
[05:35:35.870] iteration 17474: loss: 0.057809, loss_s1: 0.054542, loss_fp: 0.005659, loss_freq: 0.026086
[05:35:36.501] iteration 17475: loss: 0.073395, loss_s1: 0.049856, loss_fp: 0.005366, loss_freq: 0.051064
[05:35:37.163] iteration 17476: loss: 0.044729, loss_s1: 0.041412, loss_fp: 0.008454, loss_freq: 0.013388
[05:35:37.781] iteration 17477: loss: 0.081783, loss_s1: 0.062346, loss_fp: 0.003690, loss_freq: 0.045104
[05:35:38.407] iteration 17478: loss: 0.057060, loss_s1: 0.028007, loss_fp: 0.005405, loss_freq: 0.042863
[05:35:39.084] iteration 17479: loss: 0.092910, loss_s1: 0.106312, loss_fp: 0.004662, loss_freq: 0.037006
[05:35:39.761] iteration 17480: loss: 0.059503, loss_s1: 0.062252, loss_fp: 0.002829, loss_freq: 0.028920
[05:35:40.407] iteration 17481: loss: 0.053132, loss_s1: 0.039409, loss_fp: 0.007851, loss_freq: 0.016757
[05:35:41.041] iteration 17482: loss: 0.053456, loss_s1: 0.039407, loss_fp: 0.007076, loss_freq: 0.015325
[05:35:41.680] iteration 17483: loss: 0.080663, loss_s1: 0.077364, loss_fp: 0.003455, loss_freq: 0.035236
[05:35:42.377] iteration 17484: loss: 0.038264, loss_s1: 0.017681, loss_fp: 0.002713, loss_freq: 0.022725
[05:35:43.060] iteration 17485: loss: 0.035314, loss_s1: 0.030397, loss_fp: 0.004538, loss_freq: 0.003988
[05:35:43.743] iteration 17486: loss: 0.063316, loss_s1: 0.044893, loss_fp: 0.003954, loss_freq: 0.036261
[05:35:44.430] iteration 17487: loss: 0.072578, loss_s1: 0.068461, loss_fp: 0.001996, loss_freq: 0.027117
[05:35:45.099] iteration 17488: loss: 0.070403, loss_s1: 0.072720, loss_fp: 0.004615, loss_freq: 0.035013
[05:35:45.735] iteration 17489: loss: 0.070792, loss_s1: 0.056783, loss_fp: 0.002506, loss_freq: 0.046415
[05:35:46.391] iteration 17490: loss: 0.071416, loss_s1: 0.054420, loss_fp: 0.006466, loss_freq: 0.048782
[05:35:47.015] iteration 17491: loss: 0.079923, loss_s1: 0.060682, loss_fp: 0.004796, loss_freq: 0.057321
[05:35:47.655] iteration 17492: loss: 0.066999, loss_s1: 0.067484, loss_fp: 0.001951, loss_freq: 0.030977
[05:35:48.290] iteration 17493: loss: 0.100350, loss_s1: 0.099712, loss_fp: 0.005328, loss_freq: 0.061944
[05:35:48.917] iteration 17494: loss: 0.063527, loss_s1: 0.051868, loss_fp: 0.003918, loss_freq: 0.025374
[05:35:49.642] iteration 17495: loss: 0.103400, loss_s1: 0.073904, loss_fp: 0.004086, loss_freq: 0.074498
[05:35:50.341] iteration 17496: loss: 0.069290, loss_s1: 0.050657, loss_fp: 0.003952, loss_freq: 0.044272
[05:35:51.032] iteration 17497: loss: 0.050525, loss_s1: 0.032199, loss_fp: 0.001352, loss_freq: 0.024423
[05:35:51.729] iteration 17498: loss: 0.060598, loss_s1: 0.039542, loss_fp: 0.003473, loss_freq: 0.041098
[05:35:52.401] iteration 17499: loss: 0.069838, loss_s1: 0.063155, loss_fp: 0.004849, loss_freq: 0.038171
[05:35:53.082] iteration 17500: loss: 0.065346, loss_s1: 0.047712, loss_fp: 0.003159, loss_freq: 0.036159
[05:35:53.732] iteration 17501: loss: 0.059047, loss_s1: 0.060712, loss_fp: 0.002831, loss_freq: 0.011991
[05:35:54.365] iteration 17502: loss: 0.094343, loss_s1: 0.109364, loss_fp: 0.005445, loss_freq: 0.040241
[05:35:54.996] iteration 17503: loss: 0.053872, loss_s1: 0.025562, loss_fp: 0.008278, loss_freq: 0.011090
[05:35:55.651] iteration 17504: loss: 0.052630, loss_s1: 0.036580, loss_fp: 0.003048, loss_freq: 0.023190
[05:35:56.307] iteration 17505: loss: 0.049408, loss_s1: 0.046389, loss_fp: 0.005225, loss_freq: 0.015068
[05:35:56.968] iteration 17506: loss: 0.073255, loss_s1: 0.082891, loss_fp: 0.004447, loss_freq: 0.031398
[05:35:57.620] iteration 17507: loss: 0.073044, loss_s1: 0.054047, loss_fp: 0.008673, loss_freq: 0.038677
[05:35:58.269] iteration 17508: loss: 0.078779, loss_s1: 0.064021, loss_fp: 0.006013, loss_freq: 0.042176
[05:35:58.897] iteration 17509: loss: 0.060685, loss_s1: 0.040926, loss_fp: 0.008277, loss_freq: 0.041648
[05:35:59.537] iteration 17510: loss: 0.055234, loss_s1: 0.052403, loss_fp: 0.003348, loss_freq: 0.018664
[05:36:00.531] iteration 17511: loss: 0.101095, loss_s1: 0.098731, loss_fp: 0.005299, loss_freq: 0.064289
[05:36:01.156] iteration 17512: loss: 0.064409, loss_s1: 0.050827, loss_fp: 0.003864, loss_freq: 0.039033
[05:36:01.805] iteration 17513: loss: 0.055101, loss_s1: 0.048779, loss_fp: 0.002490, loss_freq: 0.032794
[05:36:02.476] iteration 17514: loss: 0.061853, loss_s1: 0.051043, loss_fp: 0.002422, loss_freq: 0.021327
[05:36:03.101] iteration 17515: loss: 0.088276, loss_s1: 0.110747, loss_fp: 0.001658, loss_freq: 0.021871
[05:36:03.731] iteration 17516: loss: 0.060961, loss_s1: 0.047935, loss_fp: 0.004995, loss_freq: 0.031835
[05:36:04.373] iteration 17517: loss: 0.089037, loss_s1: 0.087455, loss_fp: 0.002553, loss_freq: 0.049984
[05:36:05.001] iteration 17518: loss: 0.072851, loss_s1: 0.074386, loss_fp: 0.001903, loss_freq: 0.025842
[05:36:05.628] iteration 17519: loss: 0.063752, loss_s1: 0.047524, loss_fp: 0.004693, loss_freq: 0.045586
[05:36:06.256] iteration 17520: loss: 0.107513, loss_s1: 0.114854, loss_fp: 0.004223, loss_freq: 0.047127
[05:36:06.914] iteration 17521: loss: 0.057440, loss_s1: 0.048061, loss_fp: 0.002667, loss_freq: 0.022772
[05:36:07.562] iteration 17522: loss: 0.096248, loss_s1: 0.102989, loss_fp: 0.012017, loss_freq: 0.042375
[05:36:08.189] iteration 17523: loss: 0.060616, loss_s1: 0.048797, loss_fp: 0.010925, loss_freq: 0.029728
[05:36:08.826] iteration 17524: loss: 0.070614, loss_s1: 0.048534, loss_fp: 0.016515, loss_freq: 0.044218
[05:36:09.455] iteration 17525: loss: 0.068908, loss_s1: 0.037473, loss_fp: 0.010883, loss_freq: 0.048439
[05:36:10.096] iteration 17526: loss: 0.072658, loss_s1: 0.071897, loss_fp: 0.009279, loss_freq: 0.029366
[05:36:10.726] iteration 17527: loss: 0.088716, loss_s1: 0.048402, loss_fp: 0.002397, loss_freq: 0.097391
[05:36:11.418] iteration 17528: loss: 0.041418, loss_s1: 0.035225, loss_fp: 0.000953, loss_freq: 0.006650
[05:36:12.095] iteration 17529: loss: 0.098675, loss_s1: 0.131004, loss_fp: 0.002165, loss_freq: 0.027713
[05:36:12.778] iteration 17530: loss: 0.055066, loss_s1: 0.050000, loss_fp: 0.000921, loss_freq: 0.019582
[05:36:13.451] iteration 17531: loss: 0.038733, loss_s1: 0.020313, loss_fp: 0.004799, loss_freq: 0.014997
[05:36:14.089] iteration 17532: loss: 0.065548, loss_s1: 0.059525, loss_fp: 0.003558, loss_freq: 0.040877
[05:36:14.720] iteration 17533: loss: 0.056388, loss_s1: 0.025484, loss_fp: 0.001476, loss_freq: 0.041401
[05:36:15.355] iteration 17534: loss: 0.066202, loss_s1: 0.069941, loss_fp: 0.001476, loss_freq: 0.022343
[05:36:16.027] iteration 17535: loss: 0.061602, loss_s1: 0.052194, loss_fp: 0.000860, loss_freq: 0.037698
[05:36:16.712] iteration 17536: loss: 0.039522, loss_s1: 0.025591, loss_fp: 0.001924, loss_freq: 0.022790
[05:36:17.400] iteration 17537: loss: 0.052430, loss_s1: 0.047159, loss_fp: 0.002246, loss_freq: 0.024450
[05:36:18.084] iteration 17538: loss: 0.085372, loss_s1: 0.092620, loss_fp: 0.005538, loss_freq: 0.028263
[05:36:18.778] iteration 17539: loss: 0.084353, loss_s1: 0.067991, loss_fp: 0.005977, loss_freq: 0.023382
[05:36:19.428] iteration 17540: loss: 0.106955, loss_s1: 0.107324, loss_fp: 0.004388, loss_freq: 0.058506
[05:36:20.064] iteration 17541: loss: 0.063776, loss_s1: 0.041946, loss_fp: 0.005974, loss_freq: 0.052176
[05:36:20.697] iteration 17542: loss: 0.111617, loss_s1: 0.090023, loss_fp: 0.007249, loss_freq: 0.085192
[05:36:21.333] iteration 17543: loss: 0.059077, loss_s1: 0.044364, loss_fp: 0.010687, loss_freq: 0.021913
[05:36:21.970] iteration 17544: loss: 0.056712, loss_s1: 0.044515, loss_fp: 0.001493, loss_freq: 0.010972
[05:36:22.602] iteration 17545: loss: 0.074465, loss_s1: 0.085802, loss_fp: 0.004532, loss_freq: 0.033548
[05:36:23.246] iteration 17546: loss: 0.059707, loss_s1: 0.016361, loss_fp: 0.004268, loss_freq: 0.029240
[05:36:23.885] iteration 17547: loss: 0.060554, loss_s1: 0.047892, loss_fp: 0.004532, loss_freq: 0.030721
[05:36:24.560] iteration 17548: loss: 0.048344, loss_s1: 0.051739, loss_fp: 0.002459, loss_freq: 0.009727
[05:36:25.256] iteration 17549: loss: 0.082012, loss_s1: 0.080634, loss_fp: 0.004421, loss_freq: 0.045863
[05:36:25.936] iteration 17550: loss: 0.090552, loss_s1: 0.075015, loss_fp: 0.010821, loss_freq: 0.046783
[05:36:26.627] iteration 17551: loss: 0.090569, loss_s1: 0.094543, loss_fp: 0.003560, loss_freq: 0.036577
[05:36:27.329] iteration 17552: loss: 0.065046, loss_s1: 0.064904, loss_fp: 0.003349, loss_freq: 0.029724
[05:36:28.021] iteration 17553: loss: 0.120063, loss_s1: 0.091482, loss_fp: 0.001291, loss_freq: 0.102519
[05:36:28.702] iteration 17554: loss: 0.080520, loss_s1: 0.070506, loss_fp: 0.005164, loss_freq: 0.053660
[05:36:29.354] iteration 17555: loss: 0.060751, loss_s1: 0.053832, loss_fp: 0.003316, loss_freq: 0.022928
[05:36:29.996] iteration 17556: loss: 0.079705, loss_s1: 0.047084, loss_fp: 0.003083, loss_freq: 0.041782
[05:36:30.652] iteration 17557: loss: 0.075403, loss_s1: 0.080674, loss_fp: 0.004792, loss_freq: 0.027897
[05:36:31.303] iteration 17558: loss: 0.053599, loss_s1: 0.055254, loss_fp: 0.003493, loss_freq: 0.015702
[05:36:31.971] iteration 17559: loss: 0.042863, loss_s1: 0.028493, loss_fp: 0.001517, loss_freq: 0.008258
[05:36:32.611] iteration 17560: loss: 0.034231, loss_s1: 0.022987, loss_fp: 0.000996, loss_freq: 0.008533
[05:36:33.242] iteration 17561: loss: 0.047204, loss_s1: 0.042329, loss_fp: 0.000487, loss_freq: 0.014628
[05:36:33.917] iteration 17562: loss: 0.067512, loss_s1: 0.064827, loss_fp: 0.001435, loss_freq: 0.038225
[05:36:34.759] iteration 17563: loss: 0.058854, loss_s1: 0.026875, loss_fp: 0.000976, loss_freq: 0.038597
[05:36:35.471] iteration 17564: loss: 0.041018, loss_s1: 0.025575, loss_fp: 0.001893, loss_freq: 0.022401
[05:36:36.142] iteration 17565: loss: 0.045279, loss_s1: 0.012081, loss_fp: 0.005017, loss_freq: 0.032219
[05:36:36.823] iteration 17566: loss: 0.053711, loss_s1: 0.043873, loss_fp: 0.007123, loss_freq: 0.022339
[05:36:37.584] iteration 17567: loss: 0.050951, loss_s1: 0.044328, loss_fp: 0.001663, loss_freq: 0.019328
[05:36:38.344] iteration 17568: loss: 0.082210, loss_s1: 0.064454, loss_fp: 0.001307, loss_freq: 0.051465
[05:36:39.092] iteration 17569: loss: 0.043963, loss_s1: 0.026360, loss_fp: 0.005903, loss_freq: 0.029823
[05:36:39.717] iteration 17570: loss: 0.062699, loss_s1: 0.040913, loss_fp: 0.003507, loss_freq: 0.037915
[05:36:40.438] iteration 17571: loss: 0.042310, loss_s1: 0.046546, loss_fp: 0.001549, loss_freq: 0.006027
[05:36:41.160] iteration 17572: loss: 0.081236, loss_s1: 0.081847, loss_fp: 0.001481, loss_freq: 0.041993
[05:36:41.885] iteration 17573: loss: 0.047358, loss_s1: 0.028221, loss_fp: 0.001079, loss_freq: 0.021026
[05:36:42.638] iteration 17574: loss: 0.046096, loss_s1: 0.035364, loss_fp: 0.004121, loss_freq: 0.020072
[05:36:43.322] iteration 17575: loss: 0.077003, loss_s1: 0.094309, loss_fp: 0.003923, loss_freq: 0.020899
[05:36:44.164] iteration 17576: loss: 0.060178, loss_s1: 0.047601, loss_fp: 0.005422, loss_freq: 0.040113
[05:36:44.918] iteration 17577: loss: 0.057552, loss_s1: 0.040073, loss_fp: 0.002209, loss_freq: 0.025902
[05:36:45.676] iteration 17578: loss: 0.122865, loss_s1: 0.154297, loss_fp: 0.004282, loss_freq: 0.049057
[05:36:46.398] iteration 17579: loss: 0.062156, loss_s1: 0.048941, loss_fp: 0.001805, loss_freq: 0.032123
[05:36:47.065] iteration 17580: loss: 0.058485, loss_s1: 0.042523, loss_fp: 0.005077, loss_freq: 0.040805
[05:36:47.823] iteration 17581: loss: 0.079103, loss_s1: 0.076415, loss_fp: 0.005210, loss_freq: 0.044563
[05:36:48.549] iteration 17582: loss: 0.062825, loss_s1: 0.047534, loss_fp: 0.011549, loss_freq: 0.027969
[05:36:49.278] iteration 17583: loss: 0.048773, loss_s1: 0.034461, loss_fp: 0.005083, loss_freq: 0.027782
[05:36:50.024] iteration 17584: loss: 0.072034, loss_s1: 0.078582, loss_fp: 0.013886, loss_freq: 0.019387
[05:36:50.659] iteration 17585: loss: 0.067557, loss_s1: 0.039754, loss_fp: 0.001923, loss_freq: 0.056190
[05:36:51.278] iteration 17586: loss: 0.100035, loss_s1: 0.071147, loss_fp: 0.007812, loss_freq: 0.082789
[05:36:51.968] iteration 17587: loss: 0.058638, loss_s1: 0.057497, loss_fp: 0.002893, loss_freq: 0.020425
[05:36:52.601] iteration 17588: loss: 0.089410, loss_s1: 0.073366, loss_fp: 0.011692, loss_freq: 0.059456
[05:36:53.206] iteration 17589: loss: 0.053078, loss_s1: 0.046864, loss_fp: 0.007181, loss_freq: 0.026343
[05:36:53.824] iteration 17590: loss: 0.074383, loss_s1: 0.077244, loss_fp: 0.003368, loss_freq: 0.028974
[05:36:54.451] iteration 17591: loss: 0.067761, loss_s1: 0.064415, loss_fp: 0.003189, loss_freq: 0.020033
[05:36:55.329] iteration 17592: loss: 0.050212, loss_s1: 0.035259, loss_fp: 0.006575, loss_freq: 0.024134
[05:36:56.033] iteration 17593: loss: 0.067553, loss_s1: 0.048806, loss_fp: 0.000834, loss_freq: 0.053848
[05:36:56.711] iteration 17594: loss: 0.049093, loss_s1: 0.041675, loss_fp: 0.002304, loss_freq: 0.011541
[05:36:57.341] iteration 17595: loss: 0.061413, loss_s1: 0.040560, loss_fp: 0.004146, loss_freq: 0.025254
[05:36:57.949] iteration 17596: loss: 0.077790, loss_s1: 0.076480, loss_fp: 0.001292, loss_freq: 0.027829
[05:36:58.556] iteration 17597: loss: 0.092766, loss_s1: 0.118600, loss_fp: 0.002052, loss_freq: 0.037054
[05:36:59.163] iteration 17598: loss: 0.054815, loss_s1: 0.058454, loss_fp: 0.002252, loss_freq: 0.016463
[05:36:59.778] iteration 17599: loss: 0.064337, loss_s1: 0.059848, loss_fp: 0.007206, loss_freq: 0.029049
[05:37:00.386] iteration 17600: loss: 0.055486, loss_s1: 0.043912, loss_fp: 0.001656, loss_freq: 0.024206
[05:37:03.776] iteration 17600 : mean_dice : 0.718785
[05:37:04.409] iteration 17601: loss: 0.071956, loss_s1: 0.069391, loss_fp: 0.004784, loss_freq: 0.035393
[05:37:05.019] iteration 17602: loss: 0.050266, loss_s1: 0.040812, loss_fp: 0.000897, loss_freq: 0.029329
[05:37:05.624] iteration 17603: loss: 0.102941, loss_s1: 0.086497, loss_fp: 0.001169, loss_freq: 0.076706
[05:37:06.237] iteration 17604: loss: 0.054388, loss_s1: 0.031158, loss_fp: 0.002819, loss_freq: 0.031052
[05:37:06.857] iteration 17605: loss: 0.058153, loss_s1: 0.032733, loss_fp: 0.007333, loss_freq: 0.037861
[05:37:07.467] iteration 17606: loss: 0.077658, loss_s1: 0.068383, loss_fp: 0.004045, loss_freq: 0.045798
[05:37:08.082] iteration 17607: loss: 0.063015, loss_s1: 0.030881, loss_fp: 0.001465, loss_freq: 0.048020
[05:37:08.688] iteration 17608: loss: 0.099154, loss_s1: 0.108073, loss_fp: 0.005547, loss_freq: 0.042334
[05:37:09.298] iteration 17609: loss: 0.064501, loss_s1: 0.046587, loss_fp: 0.003188, loss_freq: 0.045948
[05:37:09.907] iteration 17610: loss: 0.059928, loss_s1: 0.046069, loss_fp: 0.004471, loss_freq: 0.031013
[05:37:10.520] iteration 17611: loss: 0.076558, loss_s1: 0.093102, loss_fp: 0.003838, loss_freq: 0.029914
[05:37:11.143] iteration 17612: loss: 0.049449, loss_s1: 0.019133, loss_fp: 0.001242, loss_freq: 0.011127
[05:37:11.770] iteration 17613: loss: 0.047566, loss_s1: 0.037729, loss_fp: 0.008478, loss_freq: 0.015862
[05:37:12.522] iteration 17614: loss: 0.042751, loss_s1: 0.018827, loss_fp: 0.002765, loss_freq: 0.020310
[05:37:13.497] iteration 17615: loss: 0.041556, loss_s1: 0.039069, loss_fp: 0.004377, loss_freq: 0.007645
[05:37:14.473] iteration 17616: loss: 0.061100, loss_s1: 0.056135, loss_fp: 0.004904, loss_freq: 0.023001
[05:37:15.446] iteration 17617: loss: 0.070813, loss_s1: 0.071831, loss_fp: 0.006978, loss_freq: 0.021835
[05:37:16.210] iteration 17618: loss: 0.069407, loss_s1: 0.041054, loss_fp: 0.004763, loss_freq: 0.026206
[05:37:16.967] iteration 17619: loss: 0.127169, loss_s1: 0.108721, loss_fp: 0.004149, loss_freq: 0.104670
[05:37:17.631] iteration 17620: loss: 0.068373, loss_s1: 0.062109, loss_fp: 0.008154, loss_freq: 0.038492
[05:37:18.243] iteration 17621: loss: 0.090265, loss_s1: 0.051101, loss_fp: 0.005511, loss_freq: 0.082174
[05:37:18.849] iteration 17622: loss: 0.043595, loss_s1: 0.029152, loss_fp: 0.003524, loss_freq: 0.019518
[05:37:19.499] iteration 17623: loss: 0.065507, loss_s1: 0.062108, loss_fp: 0.004114, loss_freq: 0.025409
[05:37:20.176] iteration 17624: loss: 0.028279, loss_s1: 0.009079, loss_fp: 0.004650, loss_freq: 0.016401
[05:37:20.793] iteration 17625: loss: 0.110232, loss_s1: 0.046907, loss_fp: 0.011047, loss_freq: 0.092934
[05:37:21.409] iteration 17626: loss: 0.101313, loss_s1: 0.036131, loss_fp: 0.005592, loss_freq: 0.077267
[05:37:22.030] iteration 17627: loss: 0.092949, loss_s1: 0.111099, loss_fp: 0.001576, loss_freq: 0.035920
[05:37:22.649] iteration 17628: loss: 0.054845, loss_s1: 0.054192, loss_fp: 0.000743, loss_freq: 0.023876
[05:37:23.578] iteration 17629: loss: 0.108692, loss_s1: 0.077315, loss_fp: 0.003167, loss_freq: 0.098217
[05:37:24.392] iteration 17630: loss: 0.056894, loss_s1: 0.067502, loss_fp: 0.003544, loss_freq: 0.006468
[05:37:25.063] iteration 17631: loss: 0.049419, loss_s1: 0.038764, loss_fp: 0.001227, loss_freq: 0.017584
[05:37:25.702] iteration 17632: loss: 0.081677, loss_s1: 0.058268, loss_fp: 0.006260, loss_freq: 0.067359
[05:37:26.329] iteration 17633: loss: 0.086539, loss_s1: 0.063843, loss_fp: 0.028200, loss_freq: 0.049048
[05:37:26.940] iteration 17634: loss: 0.069625, loss_s1: 0.073210, loss_fp: 0.006314, loss_freq: 0.025634
[05:37:27.588] iteration 17635: loss: 0.099010, loss_s1: 0.064769, loss_fp: 0.006216, loss_freq: 0.063475
[05:37:28.211] iteration 17636: loss: 0.045966, loss_s1: 0.021617, loss_fp: 0.002453, loss_freq: 0.027549
[05:37:28.821] iteration 17637: loss: 0.080316, loss_s1: 0.076815, loss_fp: 0.001812, loss_freq: 0.057548
[05:37:29.443] iteration 17638: loss: 0.082971, loss_s1: 0.095221, loss_fp: 0.004978, loss_freq: 0.007833
[05:37:30.054] iteration 17639: loss: 0.071696, loss_s1: 0.062780, loss_fp: 0.006181, loss_freq: 0.032489
[05:37:30.663] iteration 17640: loss: 0.072518, loss_s1: 0.069741, loss_fp: 0.003372, loss_freq: 0.030688
[05:37:31.277] iteration 17641: loss: 0.059264, loss_s1: 0.057308, loss_fp: 0.003920, loss_freq: 0.026022
[05:37:31.915] iteration 17642: loss: 0.076859, loss_s1: 0.056012, loss_fp: 0.003445, loss_freq: 0.022235
[05:37:32.527] iteration 17643: loss: 0.076757, loss_s1: 0.064936, loss_fp: 0.004212, loss_freq: 0.044399
[05:37:33.132] iteration 17644: loss: 0.077436, loss_s1: 0.074448, loss_fp: 0.003621, loss_freq: 0.017818
[05:37:33.745] iteration 17645: loss: 0.064129, loss_s1: 0.059106, loss_fp: 0.001104, loss_freq: 0.034608
[05:37:34.358] iteration 17646: loss: 0.047651, loss_s1: 0.042628, loss_fp: 0.003703, loss_freq: 0.019486
[05:37:34.980] iteration 17647: loss: 0.094633, loss_s1: 0.066066, loss_fp: 0.003085, loss_freq: 0.031000
[05:37:35.593] iteration 17648: loss: 0.062074, loss_s1: 0.044481, loss_fp: 0.003376, loss_freq: 0.046591
[05:37:36.217] iteration 17649: loss: 0.092967, loss_s1: 0.098844, loss_fp: 0.004881, loss_freq: 0.035080
[05:37:36.860] iteration 17650: loss: 0.062947, loss_s1: 0.058970, loss_fp: 0.005360, loss_freq: 0.037452
[05:37:37.472] iteration 17651: loss: 0.055900, loss_s1: 0.049377, loss_fp: 0.002759, loss_freq: 0.023698
[05:37:38.077] iteration 17652: loss: 0.074553, loss_s1: 0.079641, loss_fp: 0.002267, loss_freq: 0.028492
[05:37:38.763] iteration 17653: loss: 0.063006, loss_s1: 0.048803, loss_fp: 0.010291, loss_freq: 0.035778
[05:37:39.420] iteration 17654: loss: 0.062087, loss_s1: 0.062608, loss_fp: 0.003196, loss_freq: 0.020867
[05:37:40.090] iteration 17655: loss: 0.040503, loss_s1: 0.026351, loss_fp: 0.002897, loss_freq: 0.005974
[05:37:40.748] iteration 17656: loss: 0.051090, loss_s1: 0.039764, loss_fp: 0.003647, loss_freq: 0.017845
[05:37:41.406] iteration 17657: loss: 0.085667, loss_s1: 0.093987, loss_fp: 0.006195, loss_freq: 0.032978
[05:37:42.045] iteration 17658: loss: 0.076844, loss_s1: 0.066345, loss_fp: 0.003194, loss_freq: 0.052691
[05:37:42.659] iteration 17659: loss: 0.045082, loss_s1: 0.026275, loss_fp: 0.003722, loss_freq: 0.034252
[05:37:43.268] iteration 17660: loss: 0.054161, loss_s1: 0.030247, loss_fp: 0.004561, loss_freq: 0.035589
[05:37:43.879] iteration 17661: loss: 0.065764, loss_s1: 0.063543, loss_fp: 0.006896, loss_freq: 0.021750
[05:37:44.582] iteration 17662: loss: 0.093977, loss_s1: 0.082498, loss_fp: 0.007106, loss_freq: 0.064660
[05:37:45.272] iteration 17663: loss: 0.096471, loss_s1: 0.062398, loss_fp: 0.005541, loss_freq: 0.056161
[05:37:45.909] iteration 17664: loss: 0.084321, loss_s1: 0.074819, loss_fp: 0.006148, loss_freq: 0.046104
[05:37:46.533] iteration 17665: loss: 0.071378, loss_s1: 0.065932, loss_fp: 0.003929, loss_freq: 0.036313
[05:37:47.146] iteration 17666: loss: 0.045944, loss_s1: 0.031389, loss_fp: 0.001494, loss_freq: 0.018876
[05:37:47.757] iteration 17667: loss: 0.047970, loss_s1: 0.023209, loss_fp: 0.002070, loss_freq: 0.016455
[05:37:48.367] iteration 17668: loss: 0.095535, loss_s1: 0.082084, loss_fp: 0.003297, loss_freq: 0.068163
[05:37:48.978] iteration 17669: loss: 0.053356, loss_s1: 0.046001, loss_fp: 0.002948, loss_freq: 0.019288
[05:37:49.584] iteration 17670: loss: 0.072008, loss_s1: 0.056850, loss_fp: 0.005320, loss_freq: 0.044520
[05:37:50.198] iteration 17671: loss: 0.080126, loss_s1: 0.107721, loss_fp: 0.003830, loss_freq: 0.012012
[05:37:50.811] iteration 17672: loss: 0.066141, loss_s1: 0.061568, loss_fp: 0.001882, loss_freq: 0.036806
[05:37:51.419] iteration 17673: loss: 0.039787, loss_s1: 0.015531, loss_fp: 0.003563, loss_freq: 0.019684
[05:37:52.031] iteration 17674: loss: 0.074321, loss_s1: 0.083445, loss_fp: 0.002568, loss_freq: 0.026771
[05:37:52.700] iteration 17675: loss: 0.032150, loss_s1: 0.017406, loss_fp: 0.001439, loss_freq: 0.012045
[05:37:53.362] iteration 17676: loss: 0.049883, loss_s1: 0.048309, loss_fp: 0.005708, loss_freq: 0.020545
[05:37:54.029] iteration 17677: loss: 0.074451, loss_s1: 0.042448, loss_fp: 0.002226, loss_freq: 0.041492
[05:37:54.683] iteration 17678: loss: 0.075693, loss_s1: 0.071820, loss_fp: 0.003698, loss_freq: 0.041332
[05:37:55.333] iteration 17679: loss: 0.066109, loss_s1: 0.049435, loss_fp: 0.003529, loss_freq: 0.053564
[05:37:55.991] iteration 17680: loss: 0.053173, loss_s1: 0.036580, loss_fp: 0.002665, loss_freq: 0.028620
[05:37:56.984] iteration 17681: loss: 0.052315, loss_s1: 0.041631, loss_fp: 0.003268, loss_freq: 0.021398
[05:37:57.637] iteration 17682: loss: 0.059953, loss_s1: 0.054303, loss_fp: 0.007191, loss_freq: 0.025724
[05:37:58.286] iteration 17683: loss: 0.073615, loss_s1: 0.087853, loss_fp: 0.003364, loss_freq: 0.029129
[05:37:58.959] iteration 17684: loss: 0.047997, loss_s1: 0.030496, loss_fp: 0.003850, loss_freq: 0.022142
[05:37:59.625] iteration 17685: loss: 0.046347, loss_s1: 0.028740, loss_fp: 0.000826, loss_freq: 0.031806
[05:38:00.297] iteration 17686: loss: 0.088089, loss_s1: 0.087617, loss_fp: 0.007142, loss_freq: 0.039178
[05:38:00.952] iteration 17687: loss: 0.101006, loss_s1: 0.103974, loss_fp: 0.001657, loss_freq: 0.036250
[05:38:01.576] iteration 17688: loss: 0.058542, loss_s1: 0.052461, loss_fp: 0.006686, loss_freq: 0.027141
[05:38:02.189] iteration 17689: loss: 0.055611, loss_s1: 0.045660, loss_fp: 0.007726, loss_freq: 0.023179
[05:38:02.817] iteration 17690: loss: 0.085284, loss_s1: 0.082112, loss_fp: 0.008653, loss_freq: 0.016836
[05:38:03.474] iteration 17691: loss: 0.049568, loss_s1: 0.015565, loss_fp: 0.003017, loss_freq: 0.026704
[05:38:04.132] iteration 17692: loss: 0.132217, loss_s1: 0.132787, loss_fp: 0.008937, loss_freq: 0.092668
[05:38:04.790] iteration 17693: loss: 0.068490, loss_s1: 0.062486, loss_fp: 0.011435, loss_freq: 0.021073
[05:38:05.444] iteration 17694: loss: 0.093759, loss_s1: 0.077368, loss_fp: 0.008679, loss_freq: 0.067289
[05:38:06.089] iteration 17695: loss: 0.051899, loss_s1: 0.043651, loss_fp: 0.003364, loss_freq: 0.021002
[05:38:06.697] iteration 17696: loss: 0.099337, loss_s1: 0.075653, loss_fp: 0.013582, loss_freq: 0.068463
[05:38:07.303] iteration 17697: loss: 0.100979, loss_s1: 0.062158, loss_fp: 0.007426, loss_freq: 0.104079
[05:38:07.915] iteration 17698: loss: 0.045818, loss_s1: 0.035199, loss_fp: 0.000793, loss_freq: 0.020276
[05:38:08.524] iteration 17699: loss: 0.105162, loss_s1: 0.113003, loss_fp: 0.009982, loss_freq: 0.057297
[05:38:09.132] iteration 17700: loss: 0.075792, loss_s1: 0.083390, loss_fp: 0.008222, loss_freq: 0.018543
[05:38:09.739] iteration 17701: loss: 0.082841, loss_s1: 0.060062, loss_fp: 0.003326, loss_freq: 0.030993
[05:38:10.351] iteration 17702: loss: 0.059206, loss_s1: 0.056615, loss_fp: 0.002450, loss_freq: 0.036045
[05:38:11.008] iteration 17703: loss: 0.058211, loss_s1: 0.041982, loss_fp: 0.000849, loss_freq: 0.027653
[05:38:11.671] iteration 17704: loss: 0.050370, loss_s1: 0.036795, loss_fp: 0.001549, loss_freq: 0.027362
[05:38:12.331] iteration 17705: loss: 0.094103, loss_s1: 0.095056, loss_fp: 0.001314, loss_freq: 0.055464
[05:38:12.994] iteration 17706: loss: 0.061021, loss_s1: 0.056568, loss_fp: 0.004264, loss_freq: 0.036486
[05:38:13.666] iteration 17707: loss: 0.055388, loss_s1: 0.046251, loss_fp: 0.002137, loss_freq: 0.021342
[05:38:14.327] iteration 17708: loss: 0.076363, loss_s1: 0.062545, loss_fp: 0.022278, loss_freq: 0.028417
[05:38:14.937] iteration 17709: loss: 0.044625, loss_s1: 0.028176, loss_fp: 0.002100, loss_freq: 0.031406
[05:38:15.551] iteration 17710: loss: 0.105449, loss_s1: 0.128135, loss_fp: 0.003622, loss_freq: 0.043599
[05:38:16.157] iteration 17711: loss: 0.070094, loss_s1: 0.045947, loss_fp: 0.007630, loss_freq: 0.049311
[05:38:16.767] iteration 17712: loss: 0.061956, loss_s1: 0.036337, loss_fp: 0.002427, loss_freq: 0.035646
[05:38:17.373] iteration 17713: loss: 0.082907, loss_s1: 0.079834, loss_fp: 0.002968, loss_freq: 0.049108
[05:38:17.980] iteration 17714: loss: 0.050422, loss_s1: 0.042858, loss_fp: 0.002805, loss_freq: 0.010436
[05:38:18.596] iteration 17715: loss: 0.059027, loss_s1: 0.051813, loss_fp: 0.002722, loss_freq: 0.042557
[05:38:19.206] iteration 17716: loss: 0.055876, loss_s1: 0.027830, loss_fp: 0.002585, loss_freq: 0.025724
[05:38:19.821] iteration 17717: loss: 0.047712, loss_s1: 0.035370, loss_fp: 0.003418, loss_freq: 0.020065
[05:38:20.438] iteration 17718: loss: 0.057798, loss_s1: 0.044196, loss_fp: 0.004720, loss_freq: 0.022045
[05:38:21.050] iteration 17719: loss: 0.083207, loss_s1: 0.068382, loss_fp: 0.003126, loss_freq: 0.041898
[05:38:21.675] iteration 17720: loss: 0.076360, loss_s1: 0.082465, loss_fp: 0.002771, loss_freq: 0.038150
[05:38:22.298] iteration 17721: loss: 0.048746, loss_s1: 0.036469, loss_fp: 0.003118, loss_freq: 0.007574
[05:38:22.903] iteration 17722: loss: 0.071128, loss_s1: 0.078317, loss_fp: 0.001644, loss_freq: 0.028825
[05:38:23.595] iteration 17723: loss: 0.079435, loss_s1: 0.073824, loss_fp: 0.008620, loss_freq: 0.029392
[05:38:24.260] iteration 17724: loss: 0.090055, loss_s1: 0.103192, loss_fp: 0.007264, loss_freq: 0.046638
[05:38:24.930] iteration 17725: loss: 0.066401, loss_s1: 0.039503, loss_fp: 0.003900, loss_freq: 0.039335
[05:38:25.576] iteration 17726: loss: 0.087562, loss_s1: 0.075900, loss_fp: 0.002296, loss_freq: 0.058405
[05:38:26.228] iteration 17727: loss: 0.058429, loss_s1: 0.057536, loss_fp: 0.002721, loss_freq: 0.019506
[05:38:26.879] iteration 17728: loss: 0.065122, loss_s1: 0.042230, loss_fp: 0.002254, loss_freq: 0.045128
[05:38:27.515] iteration 17729: loss: 0.039838, loss_s1: 0.033504, loss_fp: 0.001835, loss_freq: 0.012638
[05:38:28.120] iteration 17730: loss: 0.039604, loss_s1: 0.023239, loss_fp: 0.002364, loss_freq: 0.013835
[05:38:28.734] iteration 17731: loss: 0.062009, loss_s1: 0.053139, loss_fp: 0.005794, loss_freq: 0.026476
[05:38:29.349] iteration 17732: loss: 0.061529, loss_s1: 0.057792, loss_fp: 0.001645, loss_freq: 0.017495
[05:38:29.962] iteration 17733: loss: 0.048871, loss_s1: 0.016564, loss_fp: 0.001173, loss_freq: 0.032539
[05:38:30.576] iteration 17734: loss: 0.047111, loss_s1: 0.026159, loss_fp: 0.005505, loss_freq: 0.027494
[05:38:31.187] iteration 17735: loss: 0.056861, loss_s1: 0.025638, loss_fp: 0.001851, loss_freq: 0.032431
[05:38:31.800] iteration 17736: loss: 0.045298, loss_s1: 0.035918, loss_fp: 0.001427, loss_freq: 0.020448
[05:38:32.412] iteration 17737: loss: 0.071832, loss_s1: 0.047342, loss_fp: 0.006519, loss_freq: 0.060057
[05:38:33.023] iteration 17738: loss: 0.044284, loss_s1: 0.023097, loss_fp: 0.003559, loss_freq: 0.023420
[05:38:33.634] iteration 17739: loss: 0.049646, loss_s1: 0.034144, loss_fp: 0.003933, loss_freq: 0.031335
[05:38:34.259] iteration 17740: loss: 0.058421, loss_s1: 0.054655, loss_fp: 0.003203, loss_freq: 0.029153
[05:38:34.882] iteration 17741: loss: 0.060617, loss_s1: 0.069263, loss_fp: 0.002456, loss_freq: 0.009781
[05:38:35.501] iteration 17742: loss: 0.094198, loss_s1: 0.047758, loss_fp: 0.003742, loss_freq: 0.035590
[05:38:36.105] iteration 17743: loss: 0.045999, loss_s1: 0.046486, loss_fp: 0.000844, loss_freq: 0.006454
[05:38:36.758] iteration 17744: loss: 0.055426, loss_s1: 0.030579, loss_fp: 0.005022, loss_freq: 0.017791
[05:38:37.402] iteration 17745: loss: 0.087328, loss_s1: 0.110968, loss_fp: 0.003224, loss_freq: 0.017785
[05:38:38.033] iteration 17746: loss: 0.052832, loss_s1: 0.060222, loss_fp: 0.001290, loss_freq: 0.023156
[05:38:38.653] iteration 17747: loss: 0.058734, loss_s1: 0.011924, loss_fp: 0.001552, loss_freq: 0.028419
[05:38:39.276] iteration 17748: loss: 0.061443, loss_s1: 0.034297, loss_fp: 0.003576, loss_freq: 0.054031
[05:38:39.889] iteration 17749: loss: 0.060253, loss_s1: 0.030365, loss_fp: 0.001679, loss_freq: 0.045979
[05:38:40.551] iteration 17750: loss: 0.046958, loss_s1: 0.037562, loss_fp: 0.003491, loss_freq: 0.020173
[05:38:41.207] iteration 17751: loss: 0.066855, loss_s1: 0.045388, loss_fp: 0.003282, loss_freq: 0.038039
[05:38:41.859] iteration 17752: loss: 0.039323, loss_s1: 0.013564, loss_fp: 0.006088, loss_freq: 0.025280
[05:38:42.519] iteration 17753: loss: 0.057056, loss_s1: 0.036862, loss_fp: 0.004866, loss_freq: 0.045135
[05:38:43.182] iteration 17754: loss: 0.077956, loss_s1: 0.079367, loss_fp: 0.011050, loss_freq: 0.027432
[05:38:43.834] iteration 17755: loss: 0.060038, loss_s1: 0.031026, loss_fp: 0.002372, loss_freq: 0.050446
[05:38:44.495] iteration 17756: loss: 0.065477, loss_s1: 0.059089, loss_fp: 0.005125, loss_freq: 0.029980
[05:38:45.150] iteration 17757: loss: 0.058886, loss_s1: 0.046005, loss_fp: 0.002404, loss_freq: 0.036430
[05:38:45.763] iteration 17758: loss: 0.071279, loss_s1: 0.079950, loss_fp: 0.005838, loss_freq: 0.015734
[05:38:46.380] iteration 17759: loss: 0.055309, loss_s1: 0.042978, loss_fp: 0.001914, loss_freq: 0.036557
[05:38:46.995] iteration 17760: loss: 0.056892, loss_s1: 0.048826, loss_fp: 0.001789, loss_freq: 0.015968
[05:38:47.609] iteration 17761: loss: 0.119427, loss_s1: 0.063293, loss_fp: 0.008985, loss_freq: 0.096477
[05:38:48.256] iteration 17762: loss: 0.056388, loss_s1: 0.047764, loss_fp: 0.012290, loss_freq: 0.018147
[05:38:48.882] iteration 17763: loss: 0.077281, loss_s1: 0.093383, loss_fp: 0.000691, loss_freq: 0.023834
[05:38:49.496] iteration 17764: loss: 0.049301, loss_s1: 0.043220, loss_fp: 0.001065, loss_freq: 0.016605
[05:38:50.103] iteration 17765: loss: 0.075877, loss_s1: 0.080898, loss_fp: 0.002716, loss_freq: 0.026308
[05:38:50.711] iteration 17766: loss: 0.057291, loss_s1: 0.043406, loss_fp: 0.002215, loss_freq: 0.030088
[05:38:51.324] iteration 17767: loss: 0.062683, loss_s1: 0.061296, loss_fp: 0.002953, loss_freq: 0.038231
[05:38:51.937] iteration 17768: loss: 0.068933, loss_s1: 0.077220, loss_fp: 0.001337, loss_freq: 0.016382
[05:38:52.563] iteration 17769: loss: 0.065750, loss_s1: 0.056838, loss_fp: 0.003281, loss_freq: 0.040064
[05:38:53.171] iteration 17770: loss: 0.041473, loss_s1: 0.026376, loss_fp: 0.004084, loss_freq: 0.015112
[05:38:53.779] iteration 17771: loss: 0.075296, loss_s1: 0.070992, loss_fp: 0.005196, loss_freq: 0.029151
[05:38:54.387] iteration 17772: loss: 0.045803, loss_s1: 0.029836, loss_fp: 0.001951, loss_freq: 0.027425
[05:38:54.999] iteration 17773: loss: 0.071076, loss_s1: 0.043565, loss_fp: 0.003911, loss_freq: 0.047808
[05:38:55.611] iteration 17774: loss: 0.070013, loss_s1: 0.075440, loss_fp: 0.002003, loss_freq: 0.018202
[05:38:56.223] iteration 17775: loss: 0.047261, loss_s1: 0.032373, loss_fp: 0.004190, loss_freq: 0.017412
[05:38:56.833] iteration 17776: loss: 0.053998, loss_s1: 0.036395, loss_fp: 0.002233, loss_freq: 0.039786
[05:38:57.443] iteration 17777: loss: 0.079996, loss_s1: 0.066087, loss_fp: 0.001228, loss_freq: 0.033119
[05:38:58.055] iteration 17778: loss: 0.115527, loss_s1: 0.112752, loss_fp: 0.002962, loss_freq: 0.080508
[05:38:58.670] iteration 17779: loss: 0.059154, loss_s1: 0.066331, loss_fp: 0.004114, loss_freq: 0.020398
[05:38:59.574] iteration 17780: loss: 0.047745, loss_s1: 0.027866, loss_fp: 0.004837, loss_freq: 0.030330
[05:39:00.341] iteration 17781: loss: 0.044027, loss_s1: 0.040947, loss_fp: 0.006080, loss_freq: 0.016658
[05:39:01.107] iteration 17782: loss: 0.058624, loss_s1: 0.043349, loss_fp: 0.003445, loss_freq: 0.019364
[05:39:01.767] iteration 17783: loss: 0.053848, loss_s1: 0.048865, loss_fp: 0.002115, loss_freq: 0.024438
[05:39:02.403] iteration 17784: loss: 0.054165, loss_s1: 0.028376, loss_fp: 0.003947, loss_freq: 0.028220
[05:39:03.010] iteration 17785: loss: 0.028755, loss_s1: 0.018774, loss_fp: 0.001998, loss_freq: 0.008885
[05:39:03.620] iteration 17786: loss: 0.046583, loss_s1: 0.036041, loss_fp: 0.001716, loss_freq: 0.014909
[05:39:04.229] iteration 17787: loss: 0.050618, loss_s1: 0.045131, loss_fp: 0.001303, loss_freq: 0.020190
[05:39:04.883] iteration 17788: loss: 0.073548, loss_s1: 0.085447, loss_fp: 0.002967, loss_freq: 0.022268
[05:39:05.491] iteration 17789: loss: 0.100591, loss_s1: 0.071677, loss_fp: 0.008137, loss_freq: 0.086194
[05:39:06.114] iteration 17790: loss: 0.059067, loss_s1: 0.057052, loss_fp: 0.005611, loss_freq: 0.022073
[05:39:06.735] iteration 17791: loss: 0.089908, loss_s1: 0.066023, loss_fp: 0.002096, loss_freq: 0.058960
[05:39:07.346] iteration 17792: loss: 0.061554, loss_s1: 0.042385, loss_fp: 0.001955, loss_freq: 0.030320
[05:39:07.947] iteration 17793: loss: 0.052352, loss_s1: 0.044711, loss_fp: 0.003791, loss_freq: 0.031305
[05:39:08.551] iteration 17794: loss: 0.028241, loss_s1: 0.015017, loss_fp: 0.003659, loss_freq: 0.013527
[05:39:09.160] iteration 17795: loss: 0.087433, loss_s1: 0.058684, loss_fp: 0.006430, loss_freq: 0.070070
[05:39:09.769] iteration 17796: loss: 0.052340, loss_s1: 0.033492, loss_fp: 0.003640, loss_freq: 0.030640
[05:39:10.422] iteration 17797: loss: 0.072155, loss_s1: 0.075185, loss_fp: 0.006219, loss_freq: 0.024167
[05:39:11.079] iteration 17798: loss: 0.054013, loss_s1: 0.045005, loss_fp: 0.004596, loss_freq: 0.028379
[05:39:11.752] iteration 17799: loss: 0.056787, loss_s1: 0.029840, loss_fp: 0.002497, loss_freq: 0.043128
[05:39:12.363] iteration 17800: loss: 0.055027, loss_s1: 0.042960, loss_fp: 0.005940, loss_freq: 0.020763
[05:39:15.919] iteration 17800 : mean_dice : 0.737830
[05:39:16.557] iteration 17801: loss: 0.043813, loss_s1: 0.037002, loss_fp: 0.002073, loss_freq: 0.011452
[05:39:17.169] iteration 17802: loss: 0.058481, loss_s1: 0.059360, loss_fp: 0.005230, loss_freq: 0.029763
[05:39:17.786] iteration 17803: loss: 0.118587, loss_s1: 0.082986, loss_fp: 0.001723, loss_freq: 0.083344
[05:39:18.403] iteration 17804: loss: 0.047239, loss_s1: 0.028513, loss_fp: 0.002993, loss_freq: 0.029907
[05:39:19.016] iteration 17805: loss: 0.088419, loss_s1: 0.064516, loss_fp: 0.000955, loss_freq: 0.061354
[05:39:19.631] iteration 17806: loss: 0.047253, loss_s1: 0.022358, loss_fp: 0.007206, loss_freq: 0.030495
[05:39:20.321] iteration 17807: loss: 0.077108, loss_s1: 0.057279, loss_fp: 0.001179, loss_freq: 0.069084
[05:39:20.929] iteration 17808: loss: 0.066340, loss_s1: 0.071628, loss_fp: 0.001774, loss_freq: 0.019952
[05:39:21.538] iteration 17809: loss: 0.049240, loss_s1: 0.033814, loss_fp: 0.006434, loss_freq: 0.023892
[05:39:22.146] iteration 17810: loss: 0.042580, loss_s1: 0.025458, loss_fp: 0.002857, loss_freq: 0.026741
[05:39:22.753] iteration 17811: loss: 0.064261, loss_s1: 0.042539, loss_fp: 0.001452, loss_freq: 0.052498
[05:39:23.366] iteration 17812: loss: 0.067164, loss_s1: 0.044781, loss_fp: 0.003197, loss_freq: 0.027052
[05:39:23.977] iteration 17813: loss: 0.064061, loss_s1: 0.039530, loss_fp: 0.012101, loss_freq: 0.044429
[05:39:24.589] iteration 17814: loss: 0.046865, loss_s1: 0.052881, loss_fp: 0.002324, loss_freq: 0.012965
[05:39:25.198] iteration 17815: loss: 0.090970, loss_s1: 0.049259, loss_fp: 0.005933, loss_freq: 0.088276
[05:39:25.807] iteration 17816: loss: 0.036701, loss_s1: 0.031521, loss_fp: 0.002423, loss_freq: 0.004716
[05:39:26.417] iteration 17817: loss: 0.071172, loss_s1: 0.072698, loss_fp: 0.004385, loss_freq: 0.017917
[05:39:27.042] iteration 17818: loss: 0.044181, loss_s1: 0.026122, loss_fp: 0.003473, loss_freq: 0.023265
[05:39:27.648] iteration 17819: loss: 0.084090, loss_s1: 0.083661, loss_fp: 0.004515, loss_freq: 0.043590
[05:39:28.255] iteration 17820: loss: 0.056448, loss_s1: 0.072603, loss_fp: 0.002298, loss_freq: 0.013916
[05:39:28.871] iteration 17821: loss: 0.074123, loss_s1: 0.055513, loss_fp: 0.008529, loss_freq: 0.026864
[05:39:29.508] iteration 17822: loss: 0.074830, loss_s1: 0.057399, loss_fp: 0.013892, loss_freq: 0.037663
[05:39:30.123] iteration 17823: loss: 0.072272, loss_s1: 0.055713, loss_fp: 0.004228, loss_freq: 0.032312
[05:39:30.739] iteration 17824: loss: 0.053054, loss_s1: 0.042035, loss_fp: 0.001947, loss_freq: 0.021552
[05:39:31.357] iteration 17825: loss: 0.042788, loss_s1: 0.018308, loss_fp: 0.003122, loss_freq: 0.022274
[05:39:31.973] iteration 17826: loss: 0.063300, loss_s1: 0.049931, loss_fp: 0.004682, loss_freq: 0.031035
[05:39:32.591] iteration 17827: loss: 0.059787, loss_s1: 0.056294, loss_fp: 0.003163, loss_freq: 0.024906
[05:39:33.202] iteration 17828: loss: 0.071108, loss_s1: 0.054707, loss_fp: 0.012843, loss_freq: 0.050367
[05:39:33.814] iteration 17829: loss: 0.056791, loss_s1: 0.054721, loss_fp: 0.005013, loss_freq: 0.029187
[05:39:34.429] iteration 17830: loss: 0.072665, loss_s1: 0.032712, loss_fp: 0.003260, loss_freq: 0.053154
[05:39:35.038] iteration 17831: loss: 0.076714, loss_s1: 0.073962, loss_fp: 0.012035, loss_freq: 0.019680
[05:39:35.653] iteration 17832: loss: 0.073710, loss_s1: 0.058312, loss_fp: 0.006284, loss_freq: 0.048275
[05:39:36.264] iteration 17833: loss: 0.079197, loss_s1: 0.076010, loss_fp: 0.005835, loss_freq: 0.036905
[05:39:36.877] iteration 17834: loss: 0.071192, loss_s1: 0.060828, loss_fp: 0.006205, loss_freq: 0.038744
[05:39:37.514] iteration 17835: loss: 0.058600, loss_s1: 0.040627, loss_fp: 0.006058, loss_freq: 0.013243
[05:39:38.124] iteration 17836: loss: 0.054785, loss_s1: 0.050609, loss_fp: 0.003298, loss_freq: 0.008736
[05:39:38.737] iteration 17837: loss: 0.058276, loss_s1: 0.036740, loss_fp: 0.007161, loss_freq: 0.047079
[05:39:39.360] iteration 17838: loss: 0.136707, loss_s1: 0.120847, loss_fp: 0.003492, loss_freq: 0.091639
[05:39:39.974] iteration 17839: loss: 0.058388, loss_s1: 0.057471, loss_fp: 0.003810, loss_freq: 0.022018
[05:39:40.595] iteration 17840: loss: 0.091135, loss_s1: 0.105749, loss_fp: 0.007325, loss_freq: 0.034178
[05:39:41.298] iteration 17841: loss: 0.073359, loss_s1: 0.087250, loss_fp: 0.002913, loss_freq: 0.015692
[05:39:41.969] iteration 17842: loss: 0.070452, loss_s1: 0.068156, loss_fp: 0.003272, loss_freq: 0.041399
[05:39:42.654] iteration 17843: loss: 0.058040, loss_s1: 0.041709, loss_fp: 0.002495, loss_freq: 0.028407
[05:39:43.333] iteration 17844: loss: 0.084271, loss_s1: 0.100839, loss_fp: 0.001644, loss_freq: 0.034410
[05:39:44.012] iteration 17845: loss: 0.042790, loss_s1: 0.028379, loss_fp: 0.002018, loss_freq: 0.009612
[05:39:44.688] iteration 17846: loss: 0.052164, loss_s1: 0.044236, loss_fp: 0.009766, loss_freq: 0.028428
[05:39:45.365] iteration 17847: loss: 0.105457, loss_s1: 0.090300, loss_fp: 0.001110, loss_freq: 0.074590
[05:39:46.024] iteration 17848: loss: 0.078674, loss_s1: 0.097111, loss_fp: 0.002366, loss_freq: 0.027090
[05:39:46.685] iteration 17849: loss: 0.090646, loss_s1: 0.077252, loss_fp: 0.001505, loss_freq: 0.076655
[05:39:47.335] iteration 17850: loss: 0.132324, loss_s1: 0.187800, loss_fp: 0.004632, loss_freq: 0.033982
[05:39:48.328] iteration 17851: loss: 0.070514, loss_s1: 0.075307, loss_fp: 0.001956, loss_freq: 0.025817
[05:39:49.004] iteration 17852: loss: 0.042431, loss_s1: 0.020546, loss_fp: 0.001451, loss_freq: 0.026377
[05:39:49.662] iteration 17853: loss: 0.067680, loss_s1: 0.069056, loss_fp: 0.003083, loss_freq: 0.029183
[05:39:50.290] iteration 17854: loss: 0.055616, loss_s1: 0.034481, loss_fp: 0.002432, loss_freq: 0.022259
[05:39:50.978] iteration 17855: loss: 0.072204, loss_s1: 0.055194, loss_fp: 0.001540, loss_freq: 0.031572
[05:39:51.633] iteration 17856: loss: 0.092105, loss_s1: 0.110150, loss_fp: 0.005184, loss_freq: 0.028967
[05:39:52.281] iteration 17857: loss: 0.047423, loss_s1: 0.025141, loss_fp: 0.003487, loss_freq: 0.027940
[05:39:52.882] iteration 17858: loss: 0.041795, loss_s1: 0.030685, loss_fp: 0.003340, loss_freq: 0.021018
[05:39:53.498] iteration 17859: loss: 0.046680, loss_s1: 0.032173, loss_fp: 0.004947, loss_freq: 0.029754
[05:39:54.111] iteration 17860: loss: 0.094119, loss_s1: 0.073146, loss_fp: 0.006819, loss_freq: 0.059112
[05:39:54.719] iteration 17861: loss: 0.075316, loss_s1: 0.054357, loss_fp: 0.002381, loss_freq: 0.037599
[05:39:55.341] iteration 17862: loss: 0.108305, loss_s1: 0.112955, loss_fp: 0.005486, loss_freq: 0.061958
[05:39:55.955] iteration 17863: loss: 0.071720, loss_s1: 0.050046, loss_fp: 0.003219, loss_freq: 0.053101
[05:39:56.566] iteration 17864: loss: 0.071676, loss_s1: 0.081802, loss_fp: 0.006743, loss_freq: 0.018564
[05:39:57.175] iteration 17865: loss: 0.058106, loss_s1: 0.035292, loss_fp: 0.001332, loss_freq: 0.038489
[05:39:57.784] iteration 17866: loss: 0.055923, loss_s1: 0.042162, loss_fp: 0.013623, loss_freq: 0.017976
[05:39:58.409] iteration 17867: loss: 0.102083, loss_s1: 0.103158, loss_fp: 0.000944, loss_freq: 0.076763
[05:39:59.017] iteration 17868: loss: 0.028853, loss_s1: 0.012400, loss_fp: 0.000618, loss_freq: 0.008784
[05:39:59.621] iteration 17869: loss: 0.106311, loss_s1: 0.143577, loss_fp: 0.003686, loss_freq: 0.027510
[05:40:00.231] iteration 17870: loss: 0.053826, loss_s1: 0.029765, loss_fp: 0.002477, loss_freq: 0.016771
[05:40:00.834] iteration 17871: loss: 0.078960, loss_s1: 0.047042, loss_fp: 0.001761, loss_freq: 0.052137
[05:40:01.456] iteration 17872: loss: 0.075070, loss_s1: 0.060103, loss_fp: 0.002028, loss_freq: 0.063589
[05:40:02.082] iteration 17873: loss: 0.074272, loss_s1: 0.060839, loss_fp: 0.003758, loss_freq: 0.032100
[05:40:02.708] iteration 17874: loss: 0.045900, loss_s1: 0.042594, loss_fp: 0.001915, loss_freq: 0.016443
[05:40:03.334] iteration 17875: loss: 0.062006, loss_s1: 0.049438, loss_fp: 0.000584, loss_freq: 0.042944
[05:40:03.942] iteration 17876: loss: 0.070116, loss_s1: 0.068586, loss_fp: 0.002812, loss_freq: 0.041247
[05:40:04.556] iteration 17877: loss: 0.064848, loss_s1: 0.071149, loss_fp: 0.001314, loss_freq: 0.012362
[05:40:05.164] iteration 17878: loss: 0.075111, loss_s1: 0.048536, loss_fp: 0.004009, loss_freq: 0.018231
[05:40:05.770] iteration 17879: loss: 0.102136, loss_s1: 0.069110, loss_fp: 0.005353, loss_freq: 0.055470
[05:40:06.374] iteration 17880: loss: 0.103053, loss_s1: 0.118696, loss_fp: 0.005481, loss_freq: 0.040712
[05:40:06.983] iteration 17881: loss: 0.057393, loss_s1: 0.037290, loss_fp: 0.005346, loss_freq: 0.046886
[05:40:07.585] iteration 17882: loss: 0.120433, loss_s1: 0.141097, loss_fp: 0.015435, loss_freq: 0.033549
[05:40:08.196] iteration 17883: loss: 0.086673, loss_s1: 0.094942, loss_fp: 0.001027, loss_freq: 0.046594
[05:40:08.812] iteration 17884: loss: 0.059308, loss_s1: 0.062970, loss_fp: 0.001138, loss_freq: 0.017971
[05:40:09.424] iteration 17885: loss: 0.043305, loss_s1: 0.047476, loss_fp: 0.002324, loss_freq: 0.015563
[05:40:10.037] iteration 17886: loss: 0.055674, loss_s1: 0.030185, loss_fp: 0.005887, loss_freq: 0.018155
[05:40:10.646] iteration 17887: loss: 0.048972, loss_s1: 0.032640, loss_fp: 0.001037, loss_freq: 0.019563
[05:40:11.256] iteration 17888: loss: 0.043322, loss_s1: 0.032203, loss_fp: 0.008376, loss_freq: 0.018845
[05:40:11.857] iteration 17889: loss: 0.086873, loss_s1: 0.106783, loss_fp: 0.001192, loss_freq: 0.028040
[05:40:12.471] iteration 17890: loss: 0.099269, loss_s1: 0.105550, loss_fp: 0.004584, loss_freq: 0.048372
[05:40:13.075] iteration 17891: loss: 0.074441, loss_s1: 0.060926, loss_fp: 0.001361, loss_freq: 0.051105
[05:40:13.684] iteration 17892: loss: 0.068361, loss_s1: 0.038665, loss_fp: 0.006241, loss_freq: 0.054542
[05:40:14.296] iteration 17893: loss: 0.079886, loss_s1: 0.058608, loss_fp: 0.002599, loss_freq: 0.064072
[05:40:14.905] iteration 17894: loss: 0.108981, loss_s1: 0.126713, loss_fp: 0.002234, loss_freq: 0.059216
[05:40:15.516] iteration 17895: loss: 0.068751, loss_s1: 0.055792, loss_fp: 0.002704, loss_freq: 0.022717
[05:40:16.126] iteration 17896: loss: 0.052873, loss_s1: 0.052462, loss_fp: 0.006574, loss_freq: 0.011274
[05:40:16.741] iteration 17897: loss: 0.052294, loss_s1: 0.039062, loss_fp: 0.003404, loss_freq: 0.026362
[05:40:17.350] iteration 17898: loss: 0.080537, loss_s1: 0.079111, loss_fp: 0.001569, loss_freq: 0.025234
[05:40:17.959] iteration 17899: loss: 0.049680, loss_s1: 0.052206, loss_fp: 0.002350, loss_freq: 0.007078
[05:40:18.566] iteration 17900: loss: 0.043940, loss_s1: 0.035438, loss_fp: 0.001014, loss_freq: 0.017622
[05:40:19.180] iteration 17901: loss: 0.044586, loss_s1: 0.031848, loss_fp: 0.002614, loss_freq: 0.015293
[05:40:19.785] iteration 17902: loss: 0.058236, loss_s1: 0.074995, loss_fp: 0.004742, loss_freq: 0.013805
[05:40:20.392] iteration 17903: loss: 0.064229, loss_s1: 0.045220, loss_fp: 0.001891, loss_freq: 0.019051
[05:40:21.013] iteration 17904: loss: 0.080481, loss_s1: 0.083689, loss_fp: 0.001499, loss_freq: 0.040319
[05:40:21.623] iteration 17905: loss: 0.064861, loss_s1: 0.042742, loss_fp: 0.002861, loss_freq: 0.042034
[05:40:22.229] iteration 17906: loss: 0.071899, loss_s1: 0.075337, loss_fp: 0.002225, loss_freq: 0.029450
[05:40:22.833] iteration 17907: loss: 0.060275, loss_s1: 0.045512, loss_fp: 0.004386, loss_freq: 0.040152
[05:40:23.448] iteration 17908: loss: 0.053317, loss_s1: 0.039881, loss_fp: 0.000540, loss_freq: 0.020020
[05:40:24.064] iteration 17909: loss: 0.046386, loss_s1: 0.034303, loss_fp: 0.003928, loss_freq: 0.019414
[05:40:24.666] iteration 17910: loss: 0.087455, loss_s1: 0.091472, loss_fp: 0.001878, loss_freq: 0.042604
[05:40:25.270] iteration 17911: loss: 0.054428, loss_s1: 0.057751, loss_fp: 0.004674, loss_freq: 0.009731
[05:40:25.880] iteration 17912: loss: 0.064437, loss_s1: 0.021801, loss_fp: 0.002975, loss_freq: 0.044970
[05:40:26.489] iteration 17913: loss: 0.040021, loss_s1: 0.022932, loss_fp: 0.001236, loss_freq: 0.004938
[05:40:27.106] iteration 17914: loss: 0.054257, loss_s1: 0.041273, loss_fp: 0.003802, loss_freq: 0.018693
[05:40:27.715] iteration 17915: loss: 0.046495, loss_s1: 0.028828, loss_fp: 0.011729, loss_freq: 0.015708
[05:40:28.368] iteration 17916: loss: 0.043818, loss_s1: 0.041491, loss_fp: 0.003098, loss_freq: 0.019227
[05:40:29.026] iteration 17917: loss: 0.055094, loss_s1: 0.040967, loss_fp: 0.001338, loss_freq: 0.007470
[05:40:29.688] iteration 17918: loss: 0.095494, loss_s1: 0.101878, loss_fp: 0.009692, loss_freq: 0.040748
[05:40:30.345] iteration 17919: loss: 0.034078, loss_s1: 0.015268, loss_fp: 0.002263, loss_freq: 0.020734
[05:40:31.008] iteration 17920: loss: 0.048885, loss_s1: 0.024875, loss_fp: 0.002006, loss_freq: 0.044311
[05:40:31.644] iteration 17921: loss: 0.073356, loss_s1: 0.034434, loss_fp: 0.008805, loss_freq: 0.042020
[05:40:32.250] iteration 17922: loss: 0.058505, loss_s1: 0.032553, loss_fp: 0.004124, loss_freq: 0.045506
[05:40:32.855] iteration 17923: loss: 0.054028, loss_s1: 0.041584, loss_fp: 0.005010, loss_freq: 0.030767
[05:40:33.530] iteration 17924: loss: 0.068626, loss_s1: 0.070236, loss_fp: 0.005653, loss_freq: 0.031274
[05:40:34.191] iteration 17925: loss: 0.068686, loss_s1: 0.045212, loss_fp: 0.001260, loss_freq: 0.057898
[05:40:34.852] iteration 17926: loss: 0.046998, loss_s1: 0.027873, loss_fp: 0.008380, loss_freq: 0.015347
[05:40:35.526] iteration 17927: loss: 0.077143, loss_s1: 0.075559, loss_fp: 0.001603, loss_freq: 0.044856
[05:40:36.135] iteration 17928: loss: 0.087751, loss_s1: 0.100176, loss_fp: 0.002907, loss_freq: 0.039040
[05:40:36.747] iteration 17929: loss: 0.035663, loss_s1: 0.023394, loss_fp: 0.005718, loss_freq: 0.015339
[05:40:37.353] iteration 17930: loss: 0.059084, loss_s1: 0.043903, loss_fp: 0.002780, loss_freq: 0.036601
[05:40:37.958] iteration 17931: loss: 0.069879, loss_s1: 0.034800, loss_fp: 0.000358, loss_freq: 0.014366
[05:40:38.559] iteration 17932: loss: 0.070019, loss_s1: 0.049463, loss_fp: 0.003964, loss_freq: 0.047060
[05:40:39.161] iteration 17933: loss: 0.069881, loss_s1: 0.085699, loss_fp: 0.007874, loss_freq: 0.012888
[05:40:39.770] iteration 17934: loss: 0.124226, loss_s1: 0.126275, loss_fp: 0.003153, loss_freq: 0.077004
[05:40:40.392] iteration 17935: loss: 0.069822, loss_s1: 0.067186, loss_fp: 0.005580, loss_freq: 0.031718
[05:40:40.997] iteration 17936: loss: 0.064660, loss_s1: 0.065817, loss_fp: 0.000727, loss_freq: 0.014373
[05:40:41.608] iteration 17937: loss: 0.069471, loss_s1: 0.071911, loss_fp: 0.005229, loss_freq: 0.032026
[05:40:42.210] iteration 17938: loss: 0.057819, loss_s1: 0.066297, loss_fp: 0.005947, loss_freq: 0.014297
[05:40:42.814] iteration 17939: loss: 0.075257, loss_s1: 0.051444, loss_fp: 0.007463, loss_freq: 0.036906
[05:40:43.422] iteration 17940: loss: 0.045820, loss_s1: 0.020044, loss_fp: 0.002128, loss_freq: 0.033161
[05:40:44.025] iteration 17941: loss: 0.092661, loss_s1: 0.112492, loss_fp: 0.001945, loss_freq: 0.023231
[05:40:44.626] iteration 17942: loss: 0.087801, loss_s1: 0.097417, loss_fp: 0.005075, loss_freq: 0.049097
[05:40:45.237] iteration 17943: loss: 0.098243, loss_s1: 0.124506, loss_fp: 0.002431, loss_freq: 0.032670
[05:40:45.855] iteration 17944: loss: 0.076234, loss_s1: 0.057319, loss_fp: 0.003132, loss_freq: 0.041343
[05:40:46.478] iteration 17945: loss: 0.044986, loss_s1: 0.032804, loss_fp: 0.001949, loss_freq: 0.028386
[05:40:47.084] iteration 17946: loss: 0.062708, loss_s1: 0.075718, loss_fp: 0.002740, loss_freq: 0.019470
[05:40:47.692] iteration 17947: loss: 0.102790, loss_s1: 0.094149, loss_fp: 0.003166, loss_freq: 0.068639
[05:40:48.296] iteration 17948: loss: 0.081721, loss_s1: 0.063765, loss_fp: 0.003252, loss_freq: 0.060366
[05:40:48.907] iteration 17949: loss: 0.093488, loss_s1: 0.092310, loss_fp: 0.003940, loss_freq: 0.063469
[05:40:49.522] iteration 17950: loss: 0.031053, loss_s1: 0.009400, loss_fp: 0.004355, loss_freq: 0.014010
[05:40:50.134] iteration 17951: loss: 0.067928, loss_s1: 0.058463, loss_fp: 0.002291, loss_freq: 0.025866
[05:40:50.754] iteration 17952: loss: 0.051728, loss_s1: 0.030498, loss_fp: 0.001992, loss_freq: 0.023536
[05:40:51.360] iteration 17953: loss: 0.047338, loss_s1: 0.025767, loss_fp: 0.000909, loss_freq: 0.023503
[05:40:51.967] iteration 17954: loss: 0.046933, loss_s1: 0.043806, loss_fp: 0.003393, loss_freq: 0.013098
[05:40:52.574] iteration 17955: loss: 0.045000, loss_s1: 0.019511, loss_fp: 0.002241, loss_freq: 0.036995
[05:40:53.184] iteration 17956: loss: 0.078425, loss_s1: 0.089449, loss_fp: 0.001702, loss_freq: 0.027582
[05:40:53.787] iteration 17957: loss: 0.057428, loss_s1: 0.063992, loss_fp: 0.001451, loss_freq: 0.012559
[05:40:54.399] iteration 17958: loss: 0.054694, loss_s1: 0.051814, loss_fp: 0.003589, loss_freq: 0.024529
[05:40:55.012] iteration 17959: loss: 0.067822, loss_s1: 0.044006, loss_fp: 0.002446, loss_freq: 0.055147
[05:40:55.619] iteration 17960: loss: 0.048672, loss_s1: 0.049252, loss_fp: 0.001669, loss_freq: 0.020788
[05:40:56.230] iteration 17961: loss: 0.054304, loss_s1: 0.046771, loss_fp: 0.002168, loss_freq: 0.016444
[05:40:56.838] iteration 17962: loss: 0.062486, loss_s1: 0.054035, loss_fp: 0.004488, loss_freq: 0.030260
[05:40:57.451] iteration 17963: loss: 0.079620, loss_s1: 0.086697, loss_fp: 0.006750, loss_freq: 0.026053
[05:40:58.111] iteration 17964: loss: 0.045271, loss_s1: 0.035420, loss_fp: 0.002334, loss_freq: 0.022758
[05:40:58.723] iteration 17965: loss: 0.081277, loss_s1: 0.071960, loss_fp: 0.002679, loss_freq: 0.053338
[05:40:59.338] iteration 17966: loss: 0.089646, loss_s1: 0.044315, loss_fp: 0.004716, loss_freq: 0.080503
[05:40:59.946] iteration 17967: loss: 0.038458, loss_s1: 0.031690, loss_fp: 0.002328, loss_freq: 0.012040
[05:41:00.557] iteration 17968: loss: 0.041780, loss_s1: 0.024222, loss_fp: 0.001428, loss_freq: 0.028991
[05:41:01.167] iteration 17969: loss: 0.073189, loss_s1: 0.062260, loss_fp: 0.002053, loss_freq: 0.052808
[05:41:01.836] iteration 17970: loss: 0.051801, loss_s1: 0.046263, loss_fp: 0.014159, loss_freq: 0.005540
[05:41:02.459] iteration 17971: loss: 0.047005, loss_s1: 0.045702, loss_fp: 0.000783, loss_freq: 0.005090
[05:41:03.084] iteration 17972: loss: 0.046553, loss_s1: 0.043039, loss_fp: 0.004128, loss_freq: 0.020230
[05:41:04.022] iteration 17973: loss: 0.076575, loss_s1: 0.039149, loss_fp: 0.004195, loss_freq: 0.065132
[05:41:04.647] iteration 17974: loss: 0.070985, loss_s1: 0.046990, loss_fp: 0.009560, loss_freq: 0.054335
[05:41:05.259] iteration 17975: loss: 0.092271, loss_s1: 0.075475, loss_fp: 0.010307, loss_freq: 0.058375
[05:41:05.875] iteration 17976: loss: 0.055032, loss_s1: 0.029292, loss_fp: 0.001959, loss_freq: 0.040551
[05:41:06.490] iteration 17977: loss: 0.082445, loss_s1: 0.087604, loss_fp: 0.003642, loss_freq: 0.041267
[05:41:07.120] iteration 17978: loss: 0.064615, loss_s1: 0.042322, loss_fp: 0.003217, loss_freq: 0.033305
[05:41:07.728] iteration 17979: loss: 0.067069, loss_s1: 0.087427, loss_fp: 0.002451, loss_freq: 0.015192
[05:41:08.337] iteration 17980: loss: 0.084104, loss_s1: 0.038265, loss_fp: 0.008392, loss_freq: 0.084720
[05:41:08.947] iteration 17981: loss: 0.077467, loss_s1: 0.098402, loss_fp: 0.004313, loss_freq: 0.024447
[05:41:09.555] iteration 17982: loss: 0.060407, loss_s1: 0.038883, loss_fp: 0.004320, loss_freq: 0.027846
[05:41:10.167] iteration 17983: loss: 0.063301, loss_s1: 0.050452, loss_fp: 0.002570, loss_freq: 0.035182
[05:41:10.772] iteration 17984: loss: 0.050006, loss_s1: 0.038872, loss_fp: 0.003117, loss_freq: 0.026042
[05:41:11.375] iteration 17985: loss: 0.134724, loss_s1: 0.077071, loss_fp: 0.004171, loss_freq: 0.152976
[05:41:11.987] iteration 17986: loss: 0.034764, loss_s1: 0.024027, loss_fp: 0.003535, loss_freq: 0.010119
[05:41:12.593] iteration 17987: loss: 0.069799, loss_s1: 0.054707, loss_fp: 0.001442, loss_freq: 0.013015
[05:41:13.197] iteration 17988: loss: 0.064046, loss_s1: 0.057167, loss_fp: 0.010675, loss_freq: 0.024871
[05:41:13.803] iteration 17989: loss: 0.120291, loss_s1: 0.106692, loss_fp: 0.003449, loss_freq: 0.084927
[05:41:14.416] iteration 17990: loss: 0.073432, loss_s1: 0.066097, loss_fp: 0.007552, loss_freq: 0.050773
[05:41:15.029] iteration 17991: loss: 0.101604, loss_s1: 0.100170, loss_fp: 0.001928, loss_freq: 0.053635
[05:41:15.643] iteration 17992: loss: 0.081196, loss_s1: 0.053337, loss_fp: 0.001481, loss_freq: 0.070281
[05:41:16.266] iteration 17993: loss: 0.061875, loss_s1: 0.069982, loss_fp: 0.005872, loss_freq: 0.016617
[05:41:16.877] iteration 17994: loss: 0.056751, loss_s1: 0.052162, loss_fp: 0.006395, loss_freq: 0.021618
[05:41:17.494] iteration 17995: loss: 0.031656, loss_s1: 0.017217, loss_fp: 0.006822, loss_freq: 0.012565
[05:41:18.109] iteration 17996: loss: 0.050289, loss_s1: 0.036860, loss_fp: 0.003680, loss_freq: 0.013335
[05:41:18.715] iteration 17997: loss: 0.067159, loss_s1: 0.051832, loss_fp: 0.004487, loss_freq: 0.043748
[05:41:19.335] iteration 17998: loss: 0.100765, loss_s1: 0.122120, loss_fp: 0.004762, loss_freq: 0.041473
[05:41:19.939] iteration 17999: loss: 0.082726, loss_s1: 0.092741, loss_fp: 0.006078, loss_freq: 0.044717
[05:41:20.544] iteration 18000: loss: 0.082572, loss_s1: 0.082192, loss_fp: 0.003153, loss_freq: 0.025426
[05:41:24.050] iteration 18000 : mean_dice : 0.709790
[05:41:24.695] iteration 18001: loss: 0.053347, loss_s1: 0.030866, loss_fp: 0.009458, loss_freq: 0.028814
[05:41:25.305] iteration 18002: loss: 0.091874, loss_s1: 0.085543, loss_fp: 0.014634, loss_freq: 0.035852
[05:41:25.921] iteration 18003: loss: 0.072635, loss_s1: 0.043461, loss_fp: 0.006787, loss_freq: 0.060867
[05:41:26.529] iteration 18004: loss: 0.086306, loss_s1: 0.095235, loss_fp: 0.011996, loss_freq: 0.028636
[05:41:27.137] iteration 18005: loss: 0.085610, loss_s1: 0.078007, loss_fp: 0.005800, loss_freq: 0.039400
[05:41:27.745] iteration 18006: loss: 0.066153, loss_s1: 0.070018, loss_fp: 0.002253, loss_freq: 0.027790
[05:41:28.443] iteration 18007: loss: 0.050473, loss_s1: 0.026501, loss_fp: 0.004606, loss_freq: 0.037669
[05:41:29.099] iteration 18008: loss: 0.120377, loss_s1: 0.125030, loss_fp: 0.007227, loss_freq: 0.054409
[05:41:29.757] iteration 18009: loss: 0.082936, loss_s1: 0.090550, loss_fp: 0.005921, loss_freq: 0.039719
[05:41:30.408] iteration 18010: loss: 0.058909, loss_s1: 0.045840, loss_fp: 0.004609, loss_freq: 0.035788
[05:41:31.064] iteration 18011: loss: 0.046415, loss_s1: 0.044385, loss_fp: 0.002728, loss_freq: 0.008174
[05:41:31.719] iteration 18012: loss: 0.055192, loss_s1: 0.033711, loss_fp: 0.002402, loss_freq: 0.038032
[05:41:32.387] iteration 18013: loss: 0.056545, loss_s1: 0.037553, loss_fp: 0.002314, loss_freq: 0.026841
[05:41:33.015] iteration 18014: loss: 0.076405, loss_s1: 0.088459, loss_fp: 0.003505, loss_freq: 0.027614
[05:41:33.630] iteration 18015: loss: 0.041564, loss_s1: 0.030847, loss_fp: 0.002684, loss_freq: 0.014212
[05:41:34.246] iteration 18016: loss: 0.054735, loss_s1: 0.065504, loss_fp: 0.003000, loss_freq: 0.008892
[05:41:34.867] iteration 18017: loss: 0.062284, loss_s1: 0.033865, loss_fp: 0.001070, loss_freq: 0.053396
[05:41:35.482] iteration 18018: loss: 0.058968, loss_s1: 0.035433, loss_fp: 0.001578, loss_freq: 0.045692
[05:41:36.095] iteration 18019: loss: 0.062650, loss_s1: 0.062394, loss_fp: 0.003751, loss_freq: 0.030553
[05:41:36.707] iteration 18020: loss: 0.051383, loss_s1: 0.040338, loss_fp: 0.001064, loss_freq: 0.018750
[05:41:37.661] iteration 18021: loss: 0.060170, loss_s1: 0.071881, loss_fp: 0.001683, loss_freq: 0.010114
[05:41:38.286] iteration 18022: loss: 0.039964, loss_s1: 0.027350, loss_fp: 0.001665, loss_freq: 0.016171
[05:41:39.045] iteration 18023: loss: 0.054924, loss_s1: 0.048372, loss_fp: 0.004098, loss_freq: 0.016910
[05:41:39.749] iteration 18024: loss: 0.048236, loss_s1: 0.033876, loss_fp: 0.001339, loss_freq: 0.023999
[05:41:40.356] iteration 18025: loss: 0.042348, loss_s1: 0.025380, loss_fp: 0.001791, loss_freq: 0.027390
[05:41:40.981] iteration 18026: loss: 0.069933, loss_s1: 0.053802, loss_fp: 0.002879, loss_freq: 0.041286
[05:41:41.658] iteration 18027: loss: 0.042972, loss_s1: 0.025213, loss_fp: 0.001880, loss_freq: 0.029166
[05:41:42.262] iteration 18028: loss: 0.058326, loss_s1: 0.037603, loss_fp: 0.013795, loss_freq: 0.029009
[05:41:42.904] iteration 18029: loss: 0.052672, loss_s1: 0.048336, loss_fp: 0.005416, loss_freq: 0.025496
[05:41:43.544] iteration 18030: loss: 0.071942, loss_s1: 0.065978, loss_fp: 0.005459, loss_freq: 0.030728
[05:41:44.210] iteration 18031: loss: 0.082983, loss_s1: 0.082100, loss_fp: 0.003319, loss_freq: 0.028760
[05:41:44.864] iteration 18032: loss: 0.128311, loss_s1: 0.123708, loss_fp: 0.002466, loss_freq: 0.093050
[05:41:45.517] iteration 18033: loss: 0.047261, loss_s1: 0.027212, loss_fp: 0.000972, loss_freq: 0.037123
[05:41:46.183] iteration 18034: loss: 0.047888, loss_s1: 0.033807, loss_fp: 0.005525, loss_freq: 0.022581
[05:41:46.815] iteration 18035: loss: 0.070401, loss_s1: 0.082225, loss_fp: 0.004429, loss_freq: 0.017497
[05:41:47.434] iteration 18036: loss: 0.050329, loss_s1: 0.032328, loss_fp: 0.002166, loss_freq: 0.026814
[05:41:48.287] iteration 18037: loss: 0.119171, loss_s1: 0.121182, loss_fp: 0.003053, loss_freq: 0.084015
[05:41:49.129] iteration 18038: loss: 0.041232, loss_s1: 0.041211, loss_fp: 0.001364, loss_freq: 0.008561
[05:41:49.791] iteration 18039: loss: 0.066301, loss_s1: 0.059718, loss_fp: 0.006303, loss_freq: 0.031823
[05:41:50.456] iteration 18040: loss: 0.054444, loss_s1: 0.038872, loss_fp: 0.003690, loss_freq: 0.016200
[05:41:51.152] iteration 18041: loss: 0.043937, loss_s1: 0.028832, loss_fp: 0.003080, loss_freq: 0.017421
[05:41:51.804] iteration 18042: loss: 0.075359, loss_s1: 0.066963, loss_fp: 0.006131, loss_freq: 0.048714
[05:41:52.456] iteration 18043: loss: 0.075721, loss_s1: 0.056734, loss_fp: 0.002269, loss_freq: 0.029182
[05:41:53.102] iteration 18044: loss: 0.051978, loss_s1: 0.039014, loss_fp: 0.002511, loss_freq: 0.024006
[05:41:53.771] iteration 18045: loss: 0.051290, loss_s1: 0.026348, loss_fp: 0.003010, loss_freq: 0.034108
[05:41:54.405] iteration 18046: loss: 0.066334, loss_s1: 0.068232, loss_fp: 0.000999, loss_freq: 0.037301
[05:41:55.011] iteration 18047: loss: 0.070212, loss_s1: 0.057902, loss_fp: 0.002149, loss_freq: 0.040772
[05:41:55.723] iteration 18048: loss: 0.066138, loss_s1: 0.082553, loss_fp: 0.002516, loss_freq: 0.007506
[05:41:56.401] iteration 18049: loss: 0.049353, loss_s1: 0.033305, loss_fp: 0.001179, loss_freq: 0.025645
[05:41:57.107] iteration 18050: loss: 0.095759, loss_s1: 0.098201, loss_fp: 0.005728, loss_freq: 0.046190
[05:41:57.779] iteration 18051: loss: 0.070456, loss_s1: 0.078804, loss_fp: 0.004470, loss_freq: 0.025382
[05:41:58.457] iteration 18052: loss: 0.106576, loss_s1: 0.101125, loss_fp: 0.002788, loss_freq: 0.068675
[05:41:59.088] iteration 18053: loss: 0.064158, loss_s1: 0.059128, loss_fp: 0.007168, loss_freq: 0.030583
[05:41:59.747] iteration 18054: loss: 0.064653, loss_s1: 0.063494, loss_fp: 0.003731, loss_freq: 0.030084
[05:42:00.352] iteration 18055: loss: 0.055412, loss_s1: 0.049980, loss_fp: 0.004265, loss_freq: 0.029880
[05:42:00.959] iteration 18056: loss: 0.055002, loss_s1: 0.028837, loss_fp: 0.001952, loss_freq: 0.018612
[05:42:01.570] iteration 18057: loss: 0.059058, loss_s1: 0.038278, loss_fp: 0.002235, loss_freq: 0.033177
[05:42:02.180] iteration 18058: loss: 0.043021, loss_s1: 0.034281, loss_fp: 0.003031, loss_freq: 0.022762
[05:42:02.803] iteration 18059: loss: 0.102759, loss_s1: 0.075521, loss_fp: 0.002099, loss_freq: 0.092091
[05:42:03.428] iteration 18060: loss: 0.076755, loss_s1: 0.081739, loss_fp: 0.005198, loss_freq: 0.033404
[05:42:04.050] iteration 18061: loss: 0.072389, loss_s1: 0.077736, loss_fp: 0.006156, loss_freq: 0.021942
[05:42:04.696] iteration 18062: loss: 0.042443, loss_s1: 0.025688, loss_fp: 0.002956, loss_freq: 0.018892
[05:42:05.354] iteration 18063: loss: 0.096161, loss_s1: 0.106761, loss_fp: 0.004171, loss_freq: 0.050520
[05:42:05.977] iteration 18064: loss: 0.107836, loss_s1: 0.103898, loss_fp: 0.006512, loss_freq: 0.075887
[05:42:06.590] iteration 18065: loss: 0.090951, loss_s1: 0.064200, loss_fp: 0.005139, loss_freq: 0.054718
[05:42:07.200] iteration 18066: loss: 0.069500, loss_s1: 0.070384, loss_fp: 0.003455, loss_freq: 0.026194
[05:42:07.865] iteration 18067: loss: 0.039007, loss_s1: 0.025943, loss_fp: 0.003590, loss_freq: 0.017169
[05:42:08.530] iteration 18068: loss: 0.064656, loss_s1: 0.046096, loss_fp: 0.001810, loss_freq: 0.032947
[05:42:09.196] iteration 18069: loss: 0.032147, loss_s1: 0.028810, loss_fp: 0.001203, loss_freq: 0.008179
[05:42:09.856] iteration 18070: loss: 0.052215, loss_s1: 0.037503, loss_fp: 0.000619, loss_freq: 0.011970
[05:42:10.493] iteration 18071: loss: 0.054547, loss_s1: 0.040440, loss_fp: 0.003061, loss_freq: 0.028951
[05:42:11.105] iteration 18072: loss: 0.044868, loss_s1: 0.045246, loss_fp: 0.004841, loss_freq: 0.018773
[05:42:11.726] iteration 18073: loss: 0.073919, loss_s1: 0.031284, loss_fp: 0.007730, loss_freq: 0.059139
[05:42:12.357] iteration 18074: loss: 0.050823, loss_s1: 0.041459, loss_fp: 0.012703, loss_freq: 0.015410
[05:42:12.982] iteration 18075: loss: 0.041431, loss_s1: 0.017306, loss_fp: 0.001102, loss_freq: 0.031881
[05:42:13.596] iteration 18076: loss: 0.051217, loss_s1: 0.043189, loss_fp: 0.002306, loss_freq: 0.024170
[05:42:14.207] iteration 18077: loss: 0.067728, loss_s1: 0.056516, loss_fp: 0.002839, loss_freq: 0.044206
[05:42:14.827] iteration 18078: loss: 0.065502, loss_s1: 0.063039, loss_fp: 0.002795, loss_freq: 0.021211
[05:42:15.440] iteration 18079: loss: 0.052661, loss_s1: 0.048975, loss_fp: 0.001763, loss_freq: 0.026285
[05:42:16.055] iteration 18080: loss: 0.064047, loss_s1: 0.040159, loss_fp: 0.010228, loss_freq: 0.033418
[05:42:16.673] iteration 18081: loss: 0.038562, loss_s1: 0.038774, loss_fp: 0.002348, loss_freq: 0.009897
[05:42:17.286] iteration 18082: loss: 0.074282, loss_s1: 0.049993, loss_fp: 0.003087, loss_freq: 0.048581
[05:42:17.899] iteration 18083: loss: 0.041771, loss_s1: 0.027886, loss_fp: 0.003841, loss_freq: 0.012964
[05:42:18.570] iteration 18084: loss: 0.054957, loss_s1: 0.057872, loss_fp: 0.003134, loss_freq: 0.016418
[05:42:19.243] iteration 18085: loss: 0.085296, loss_s1: 0.087669, loss_fp: 0.018138, loss_freq: 0.026138
[05:42:19.883] iteration 18086: loss: 0.053665, loss_s1: 0.022784, loss_fp: 0.003560, loss_freq: 0.038212
[05:42:20.490] iteration 18087: loss: 0.040588, loss_s1: 0.020809, loss_fp: 0.001176, loss_freq: 0.016037
[05:42:21.097] iteration 18088: loss: 0.092462, loss_s1: 0.055485, loss_fp: 0.012763, loss_freq: 0.086351
[05:42:21.715] iteration 18089: loss: 0.037042, loss_s1: 0.008732, loss_fp: 0.000526, loss_freq: 0.022720
[05:42:22.333] iteration 18090: loss: 0.061367, loss_s1: 0.063007, loss_fp: 0.002987, loss_freq: 0.031680
[05:42:22.945] iteration 18091: loss: 0.052202, loss_s1: 0.040572, loss_fp: 0.002418, loss_freq: 0.028271
[05:42:23.560] iteration 18092: loss: 0.069700, loss_s1: 0.049253, loss_fp: 0.005778, loss_freq: 0.050649
[05:42:24.177] iteration 18093: loss: 0.047755, loss_s1: 0.030437, loss_fp: 0.004039, loss_freq: 0.033158
[05:42:24.782] iteration 18094: loss: 0.078755, loss_s1: 0.086809, loss_fp: 0.004637, loss_freq: 0.018473
[05:42:25.400] iteration 18095: loss: 0.083912, loss_s1: 0.039215, loss_fp: 0.003286, loss_freq: 0.088145
[05:42:26.006] iteration 18096: loss: 0.074852, loss_s1: 0.058316, loss_fp: 0.008505, loss_freq: 0.036703
[05:42:26.614] iteration 18097: loss: 0.054418, loss_s1: 0.033629, loss_fp: 0.001251, loss_freq: 0.032402
[05:42:27.224] iteration 18098: loss: 0.090493, loss_s1: 0.096576, loss_fp: 0.008259, loss_freq: 0.041423
[05:42:27.830] iteration 18099: loss: 0.063221, loss_s1: 0.055456, loss_fp: 0.009236, loss_freq: 0.029238
[05:42:28.441] iteration 18100: loss: 0.069631, loss_s1: 0.043706, loss_fp: 0.002707, loss_freq: 0.051710
[05:42:29.056] iteration 18101: loss: 0.047849, loss_s1: 0.019764, loss_fp: 0.002859, loss_freq: 0.023652
[05:42:29.682] iteration 18102: loss: 0.079456, loss_s1: 0.069672, loss_fp: 0.011070, loss_freq: 0.042286
[05:42:30.307] iteration 18103: loss: 0.054602, loss_s1: 0.044389, loss_fp: 0.002935, loss_freq: 0.026395
[05:42:30.914] iteration 18104: loss: 0.068038, loss_s1: 0.067678, loss_fp: 0.010094, loss_freq: 0.025675
[05:42:31.525] iteration 18105: loss: 0.064245, loss_s1: 0.071958, loss_fp: 0.003049, loss_freq: 0.017155
[05:42:32.141] iteration 18106: loss: 0.058092, loss_s1: 0.051959, loss_fp: 0.003725, loss_freq: 0.023485
[05:42:32.752] iteration 18107: loss: 0.071554, loss_s1: 0.068585, loss_fp: 0.003433, loss_freq: 0.042881
[05:42:33.368] iteration 18108: loss: 0.050553, loss_s1: 0.036369, loss_fp: 0.004825, loss_freq: 0.028555
[05:42:33.984] iteration 18109: loss: 0.061429, loss_s1: 0.048954, loss_fp: 0.005627, loss_freq: 0.038014
[05:42:34.596] iteration 18110: loss: 0.054394, loss_s1: 0.051136, loss_fp: 0.001242, loss_freq: 0.012385
[05:42:35.211] iteration 18111: loss: 0.062975, loss_s1: 0.060973, loss_fp: 0.001650, loss_freq: 0.026119
[05:42:35.878] iteration 18112: loss: 0.052561, loss_s1: 0.041174, loss_fp: 0.005065, loss_freq: 0.027996
[05:42:36.534] iteration 18113: loss: 0.075784, loss_s1: 0.073054, loss_fp: 0.008621, loss_freq: 0.024425
[05:42:37.208] iteration 18114: loss: 0.051687, loss_s1: 0.039096, loss_fp: 0.001023, loss_freq: 0.027800
[05:42:37.849] iteration 18115: loss: 0.067930, loss_s1: 0.058005, loss_fp: 0.003258, loss_freq: 0.038444
[05:42:38.476] iteration 18116: loss: 0.108790, loss_s1: 0.135133, loss_fp: 0.001368, loss_freq: 0.043969
[05:42:39.097] iteration 18117: loss: 0.093121, loss_s1: 0.065096, loss_fp: 0.001766, loss_freq: 0.036669
[05:42:39.719] iteration 18118: loss: 0.056318, loss_s1: 0.024320, loss_fp: 0.003235, loss_freq: 0.035353
[05:42:40.341] iteration 18119: loss: 0.060204, loss_s1: 0.053123, loss_fp: 0.002633, loss_freq: 0.033757
[05:42:40.960] iteration 18120: loss: 0.044910, loss_s1: 0.024710, loss_fp: 0.003277, loss_freq: 0.024989
[05:42:41.580] iteration 18121: loss: 0.053725, loss_s1: 0.051499, loss_fp: 0.006428, loss_freq: 0.019450
[05:42:42.193] iteration 18122: loss: 0.049881, loss_s1: 0.030759, loss_fp: 0.002363, loss_freq: 0.017887
[05:42:42.874] iteration 18123: loss: 0.036259, loss_s1: 0.024686, loss_fp: 0.003132, loss_freq: 0.013651
[05:42:43.541] iteration 18124: loss: 0.054119, loss_s1: 0.044517, loss_fp: 0.002803, loss_freq: 0.029808
[05:42:44.193] iteration 18125: loss: 0.032097, loss_s1: 0.011010, loss_fp: 0.001747, loss_freq: 0.026314
[05:42:44.844] iteration 18126: loss: 0.067520, loss_s1: 0.058404, loss_fp: 0.011542, loss_freq: 0.022386
[05:42:45.501] iteration 18127: loss: 0.052454, loss_s1: 0.046225, loss_fp: 0.002703, loss_freq: 0.021954
[05:42:46.155] iteration 18128: loss: 0.067480, loss_s1: 0.050251, loss_fp: 0.005168, loss_freq: 0.039409
[05:42:46.813] iteration 18129: loss: 0.069909, loss_s1: 0.058383, loss_fp: 0.005920, loss_freq: 0.042850
[05:42:47.471] iteration 18130: loss: 0.067675, loss_s1: 0.055520, loss_fp: 0.007141, loss_freq: 0.028529
[05:42:48.082] iteration 18131: loss: 0.071943, loss_s1: 0.043945, loss_fp: 0.016233, loss_freq: 0.047054
[05:42:48.692] iteration 18132: loss: 0.056729, loss_s1: 0.037578, loss_fp: 0.003330, loss_freq: 0.037309
[05:42:49.306] iteration 18133: loss: 0.043516, loss_s1: 0.037245, loss_fp: 0.003693, loss_freq: 0.016627
[05:42:49.915] iteration 18134: loss: 0.037659, loss_s1: 0.035905, loss_fp: 0.000999, loss_freq: 0.011390
[05:42:50.528] iteration 18135: loss: 0.083876, loss_s1: 0.071172, loss_fp: 0.005631, loss_freq: 0.047646
[05:42:51.138] iteration 18136: loss: 0.059747, loss_s1: 0.028370, loss_fp: 0.003046, loss_freq: 0.050066
[05:42:51.749] iteration 18137: loss: 0.053023, loss_s1: 0.030165, loss_fp: 0.006277, loss_freq: 0.036618
[05:42:52.404] iteration 18138: loss: 0.045610, loss_s1: 0.031377, loss_fp: 0.003549, loss_freq: 0.022395
[05:42:53.019] iteration 18139: loss: 0.073689, loss_s1: 0.072116, loss_fp: 0.006276, loss_freq: 0.034773
[05:42:53.637] iteration 18140: loss: 0.055947, loss_s1: 0.060575, loss_fp: 0.002466, loss_freq: 0.011409
[05:42:54.371] iteration 18141: loss: 0.037209, loss_s1: 0.025054, loss_fp: 0.004504, loss_freq: 0.009217
[05:42:55.032] iteration 18142: loss: 0.068902, loss_s1: 0.057584, loss_fp: 0.003632, loss_freq: 0.054820
[05:42:55.664] iteration 18143: loss: 0.136647, loss_s1: 0.104232, loss_fp: 0.007660, loss_freq: 0.118284
[05:42:56.298] iteration 18144: loss: 0.050657, loss_s1: 0.025060, loss_fp: 0.006428, loss_freq: 0.037535
[05:42:56.946] iteration 18145: loss: 0.126347, loss_s1: 0.144815, loss_fp: 0.009238, loss_freq: 0.058293
[05:42:57.590] iteration 18146: loss: 0.050263, loss_s1: 0.030515, loss_fp: 0.001879, loss_freq: 0.024812
[05:42:58.234] iteration 18147: loss: 0.048061, loss_s1: 0.032823, loss_fp: 0.002716, loss_freq: 0.040639
[05:42:58.884] iteration 18148: loss: 0.087849, loss_s1: 0.077628, loss_fp: 0.002348, loss_freq: 0.051983
[05:42:59.500] iteration 18149: loss: 0.073691, loss_s1: 0.058267, loss_fp: 0.005179, loss_freq: 0.052807
[05:43:00.123] iteration 18150: loss: 0.078726, loss_s1: 0.030702, loss_fp: 0.018462, loss_freq: 0.074347
[05:43:00.737] iteration 18151: loss: 0.063776, loss_s1: 0.059707, loss_fp: 0.009209, loss_freq: 0.025414
[05:43:01.358] iteration 18152: loss: 0.068009, loss_s1: 0.029160, loss_fp: 0.002675, loss_freq: 0.032618
[05:43:01.967] iteration 18153: loss: 0.088482, loss_s1: 0.092964, loss_fp: 0.005988, loss_freq: 0.039365
[05:43:02.577] iteration 18154: loss: 0.083972, loss_s1: 0.076986, loss_fp: 0.014935, loss_freq: 0.049314
[05:43:03.186] iteration 18155: loss: 0.125489, loss_s1: 0.108705, loss_fp: 0.003521, loss_freq: 0.100843
[05:43:03.794] iteration 18156: loss: 0.047857, loss_s1: 0.051448, loss_fp: 0.004080, loss_freq: 0.010691
[05:43:04.403] iteration 18157: loss: 0.066500, loss_s1: 0.052638, loss_fp: 0.000996, loss_freq: 0.018945
[05:43:05.016] iteration 18158: loss: 0.057191, loss_s1: 0.045032, loss_fp: 0.002518, loss_freq: 0.039865
[05:43:05.624] iteration 18159: loss: 0.107120, loss_s1: 0.118730, loss_fp: 0.010609, loss_freq: 0.046361
[05:43:06.234] iteration 18160: loss: 0.071222, loss_s1: 0.059692, loss_fp: 0.002758, loss_freq: 0.048880
[05:43:07.100] iteration 18161: loss: 0.069605, loss_s1: 0.056068, loss_fp: 0.005888, loss_freq: 0.043399
[05:43:07.895] iteration 18162: loss: 0.060591, loss_s1: 0.043838, loss_fp: 0.002565, loss_freq: 0.036716
[05:43:08.837] iteration 18163: loss: 0.043974, loss_s1: 0.035741, loss_fp: 0.003383, loss_freq: 0.018041
[05:43:09.439] iteration 18164: loss: 0.039099, loss_s1: 0.025722, loss_fp: 0.002477, loss_freq: 0.011309
[05:43:10.045] iteration 18165: loss: 0.048610, loss_s1: 0.051982, loss_fp: 0.004112, loss_freq: 0.010222
[05:43:10.714] iteration 18166: loss: 0.047887, loss_s1: 0.022659, loss_fp: 0.005084, loss_freq: 0.029659
[05:43:11.385] iteration 18167: loss: 0.052679, loss_s1: 0.044885, loss_fp: 0.005000, loss_freq: 0.021401
[05:43:12.014] iteration 18168: loss: 0.085682, loss_s1: 0.063832, loss_fp: 0.007180, loss_freq: 0.067910
[05:43:12.632] iteration 18169: loss: 0.062571, loss_s1: 0.049517, loss_fp: 0.004390, loss_freq: 0.042267
[05:43:13.282] iteration 18170: loss: 0.061769, loss_s1: 0.038102, loss_fp: 0.007835, loss_freq: 0.034185
[05:43:13.934] iteration 18171: loss: 0.074135, loss_s1: 0.074196, loss_fp: 0.006735, loss_freq: 0.026599
[05:43:14.596] iteration 18172: loss: 0.080717, loss_s1: 0.071093, loss_fp: 0.002878, loss_freq: 0.048804
[05:43:15.258] iteration 18173: loss: 0.082458, loss_s1: 0.083380, loss_fp: 0.001235, loss_freq: 0.037143
[05:43:15.919] iteration 18174: loss: 0.087324, loss_s1: 0.074044, loss_fp: 0.005109, loss_freq: 0.051298
[05:43:16.547] iteration 18175: loss: 0.085836, loss_s1: 0.067019, loss_fp: 0.004708, loss_freq: 0.037236
[05:43:17.156] iteration 18176: loss: 0.049270, loss_s1: 0.040770, loss_fp: 0.001677, loss_freq: 0.011988
[05:43:17.776] iteration 18177: loss: 0.065450, loss_s1: 0.032519, loss_fp: 0.003556, loss_freq: 0.039998
[05:43:18.386] iteration 18178: loss: 0.084932, loss_s1: 0.072512, loss_fp: 0.004787, loss_freq: 0.058683
[05:43:18.992] iteration 18179: loss: 0.038651, loss_s1: 0.020927, loss_fp: 0.002244, loss_freq: 0.017576
[05:43:19.601] iteration 18180: loss: 0.070381, loss_s1: 0.065178, loss_fp: 0.002558, loss_freq: 0.040634
[05:43:20.217] iteration 18181: loss: 0.047563, loss_s1: 0.047087, loss_fp: 0.000768, loss_freq: 0.006611
[05:43:20.832] iteration 18182: loss: 0.059670, loss_s1: 0.049889, loss_fp: 0.006195, loss_freq: 0.027607
[05:43:21.440] iteration 18183: loss: 0.036058, loss_s1: 0.016625, loss_fp: 0.001805, loss_freq: 0.010417
[05:43:22.052] iteration 18184: loss: 0.053585, loss_s1: 0.045586, loss_fp: 0.001718, loss_freq: 0.031934
[05:43:22.669] iteration 18185: loss: 0.048638, loss_s1: 0.037065, loss_fp: 0.000598, loss_freq: 0.010060
[05:43:23.284] iteration 18186: loss: 0.038795, loss_s1: 0.023977, loss_fp: 0.008107, loss_freq: 0.016154
[05:43:23.889] iteration 18187: loss: 0.046234, loss_s1: 0.027126, loss_fp: 0.000825, loss_freq: 0.023266
[05:43:24.499] iteration 18188: loss: 0.083578, loss_s1: 0.092334, loss_fp: 0.002459, loss_freq: 0.035056
[05:43:25.105] iteration 18189: loss: 0.058671, loss_s1: 0.050167, loss_fp: 0.003974, loss_freq: 0.033918
[05:43:25.719] iteration 18190: loss: 0.073340, loss_s1: 0.053802, loss_fp: 0.012801, loss_freq: 0.040326
[05:43:26.720] iteration 18191: loss: 0.061418, loss_s1: 0.041113, loss_fp: 0.006275, loss_freq: 0.040159
[05:43:27.366] iteration 18192: loss: 0.054744, loss_s1: 0.041392, loss_fp: 0.002368, loss_freq: 0.030210
[05:43:27.987] iteration 18193: loss: 0.063128, loss_s1: 0.061799, loss_fp: 0.003070, loss_freq: 0.032542
[05:43:28.604] iteration 18194: loss: 0.043298, loss_s1: 0.022919, loss_fp: 0.006886, loss_freq: 0.022638
[05:43:29.213] iteration 18195: loss: 0.073080, loss_s1: 0.085568, loss_fp: 0.006685, loss_freq: 0.030509
[05:43:29.822] iteration 18196: loss: 0.098447, loss_s1: 0.083804, loss_fp: 0.002394, loss_freq: 0.073178
[05:43:30.434] iteration 18197: loss: 0.113213, loss_s1: 0.139331, loss_fp: 0.007231, loss_freq: 0.039917
[05:43:31.052] iteration 18198: loss: 0.060676, loss_s1: 0.059494, loss_fp: 0.005680, loss_freq: 0.013577
[05:43:31.669] iteration 18199: loss: 0.046776, loss_s1: 0.044844, loss_fp: 0.005330, loss_freq: 0.017984
[05:43:32.297] iteration 18200: loss: 0.078157, loss_s1: 0.080100, loss_fp: 0.004094, loss_freq: 0.032889
[05:43:36.034] iteration 18200 : mean_dice : 0.724141
[05:43:36.693] iteration 18201: loss: 0.071458, loss_s1: 0.061557, loss_fp: 0.002352, loss_freq: 0.044735
[05:43:37.299] iteration 18202: loss: 0.081307, loss_s1: 0.068932, loss_fp: 0.004329, loss_freq: 0.045219
[05:43:37.905] iteration 18203: loss: 0.077276, loss_s1: 0.061576, loss_fp: 0.005827, loss_freq: 0.052605
[05:43:38.517] iteration 18204: loss: 0.076963, loss_s1: 0.074400, loss_fp: 0.005138, loss_freq: 0.039881
[05:43:39.138] iteration 18205: loss: 0.066281, loss_s1: 0.036974, loss_fp: 0.001421, loss_freq: 0.048823
[05:43:39.745] iteration 18206: loss: 0.054645, loss_s1: 0.036334, loss_fp: 0.020755, loss_freq: 0.006226
[05:43:40.367] iteration 18207: loss: 0.090119, loss_s1: 0.079754, loss_fp: 0.001074, loss_freq: 0.077250
[05:43:40.989] iteration 18208: loss: 0.048834, loss_s1: 0.036653, loss_fp: 0.002266, loss_freq: 0.009307
[05:43:41.618] iteration 18209: loss: 0.103776, loss_s1: 0.080137, loss_fp: 0.007093, loss_freq: 0.085096
[05:43:42.233] iteration 18210: loss: 0.068532, loss_s1: 0.072578, loss_fp: 0.002711, loss_freq: 0.018174
[05:43:42.848] iteration 18211: loss: 0.037610, loss_s1: 0.016297, loss_fp: 0.003119, loss_freq: 0.019403
[05:43:43.466] iteration 18212: loss: 0.042887, loss_s1: 0.035531, loss_fp: 0.005062, loss_freq: 0.022401
[05:43:44.084] iteration 18213: loss: 0.067374, loss_s1: 0.034903, loss_fp: 0.002189, loss_freq: 0.047486
[05:43:44.703] iteration 18214: loss: 0.056880, loss_s1: 0.049379, loss_fp: 0.001676, loss_freq: 0.030457
[05:43:45.316] iteration 18215: loss: 0.049840, loss_s1: 0.027304, loss_fp: 0.004138, loss_freq: 0.032378
[05:43:45.936] iteration 18216: loss: 0.059945, loss_s1: 0.036359, loss_fp: 0.003093, loss_freq: 0.056136
[05:43:46.550] iteration 18217: loss: 0.055347, loss_s1: 0.029874, loss_fp: 0.006206, loss_freq: 0.032308
[05:43:47.165] iteration 18218: loss: 0.108250, loss_s1: 0.145500, loss_fp: 0.001277, loss_freq: 0.021287
[05:43:47.779] iteration 18219: loss: 0.059509, loss_s1: 0.053307, loss_fp: 0.005510, loss_freq: 0.016775
[05:43:48.395] iteration 18220: loss: 0.108259, loss_s1: 0.112025, loss_fp: 0.006383, loss_freq: 0.059169
[05:43:49.012] iteration 18221: loss: 0.089953, loss_s1: 0.105634, loss_fp: 0.004444, loss_freq: 0.039256
[05:43:49.659] iteration 18222: loss: 0.078579, loss_s1: 0.076353, loss_fp: 0.008163, loss_freq: 0.040029
[05:43:50.274] iteration 18223: loss: 0.089533, loss_s1: 0.097204, loss_fp: 0.002967, loss_freq: 0.049224
[05:43:50.883] iteration 18224: loss: 0.062654, loss_s1: 0.033337, loss_fp: 0.004007, loss_freq: 0.028783
[05:43:51.544] iteration 18225: loss: 0.050966, loss_s1: 0.056358, loss_fp: 0.000686, loss_freq: 0.017216
[05:43:52.205] iteration 18226: loss: 0.060231, loss_s1: 0.044327, loss_fp: 0.002577, loss_freq: 0.017212
[05:43:52.868] iteration 18227: loss: 0.108561, loss_s1: 0.120542, loss_fp: 0.002318, loss_freq: 0.044101
[05:43:53.519] iteration 18228: loss: 0.052439, loss_s1: 0.062201, loss_fp: 0.001754, loss_freq: 0.011638
[05:43:54.162] iteration 18229: loss: 0.097853, loss_s1: 0.053985, loss_fp: 0.003145, loss_freq: 0.097062
[05:43:54.822] iteration 18230: loss: 0.058475, loss_s1: 0.061842, loss_fp: 0.002815, loss_freq: 0.019941
[05:43:55.475] iteration 18231: loss: 0.133892, loss_s1: 0.196895, loss_fp: 0.005892, loss_freq: 0.024738
[05:43:56.132] iteration 18232: loss: 0.051338, loss_s1: 0.045591, loss_fp: 0.001559, loss_freq: 0.022300
[05:43:56.748] iteration 18233: loss: 0.102748, loss_s1: 0.146180, loss_fp: 0.002688, loss_freq: 0.022290
[05:43:57.359] iteration 18234: loss: 0.089528, loss_s1: 0.089183, loss_fp: 0.003999, loss_freq: 0.044102
[05:43:57.971] iteration 18235: loss: 0.056347, loss_s1: 0.045877, loss_fp: 0.009499, loss_freq: 0.023474
[05:43:58.580] iteration 18236: loss: 0.057598, loss_s1: 0.050823, loss_fp: 0.006257, loss_freq: 0.023653
[05:43:59.198] iteration 18237: loss: 0.053335, loss_s1: 0.041690, loss_fp: 0.002011, loss_freq: 0.028715
[05:43:59.822] iteration 18238: loss: 0.055632, loss_s1: 0.032900, loss_fp: 0.001409, loss_freq: 0.044676
[05:44:00.435] iteration 18239: loss: 0.045648, loss_s1: 0.044983, loss_fp: 0.001513, loss_freq: 0.006129
[05:44:01.052] iteration 18240: loss: 0.062458, loss_s1: 0.050498, loss_fp: 0.002285, loss_freq: 0.034760
[05:44:01.710] iteration 18241: loss: 0.044256, loss_s1: 0.018576, loss_fp: 0.005673, loss_freq: 0.028379
[05:44:02.390] iteration 18242: loss: 0.067418, loss_s1: 0.079384, loss_fp: 0.005419, loss_freq: 0.028164
[05:44:03.062] iteration 18243: loss: 0.045622, loss_s1: 0.039843, loss_fp: 0.000693, loss_freq: 0.017455
[05:44:03.714] iteration 18244: loss: 0.048306, loss_s1: 0.026593, loss_fp: 0.002957, loss_freq: 0.030439
[05:44:04.380] iteration 18245: loss: 0.051612, loss_s1: 0.034968, loss_fp: 0.003875, loss_freq: 0.023398
[05:44:05.042] iteration 18246: loss: 0.049578, loss_s1: 0.039483, loss_fp: 0.004562, loss_freq: 0.019897
[05:44:05.665] iteration 18247: loss: 0.059089, loss_s1: 0.024385, loss_fp: 0.008299, loss_freq: 0.060067
[05:44:06.274] iteration 18248: loss: 0.051164, loss_s1: 0.028980, loss_fp: 0.000441, loss_freq: 0.023141
[05:44:06.885] iteration 18249: loss: 0.038983, loss_s1: 0.021986, loss_fp: 0.001107, loss_freq: 0.018620
[05:44:07.508] iteration 18250: loss: 0.055587, loss_s1: 0.031594, loss_fp: 0.006937, loss_freq: 0.037675
[05:44:08.125] iteration 18251: loss: 0.026091, loss_s1: 0.015563, loss_fp: 0.003007, loss_freq: 0.008169
[05:44:08.732] iteration 18252: loss: 0.081705, loss_s1: 0.062220, loss_fp: 0.000875, loss_freq: 0.036398
[05:44:09.352] iteration 18253: loss: 0.047631, loss_s1: 0.029425, loss_fp: 0.002879, loss_freq: 0.022110
[05:44:09.977] iteration 18254: loss: 0.046196, loss_s1: 0.034101, loss_fp: 0.001193, loss_freq: 0.009597
[05:44:10.659] iteration 18255: loss: 0.039475, loss_s1: 0.018127, loss_fp: 0.003658, loss_freq: 0.018606
[05:44:11.272] iteration 18256: loss: 0.055355, loss_s1: 0.039880, loss_fp: 0.002933, loss_freq: 0.040264
[05:44:11.887] iteration 18257: loss: 0.052343, loss_s1: 0.036602, loss_fp: 0.004163, loss_freq: 0.011033
[05:44:12.501] iteration 18258: loss: 0.105786, loss_s1: 0.088970, loss_fp: 0.003924, loss_freq: 0.086502
[05:44:13.117] iteration 18259: loss: 0.050071, loss_s1: 0.029050, loss_fp: 0.008117, loss_freq: 0.014623
[05:44:13.786] iteration 18260: loss: 0.067811, loss_s1: 0.055027, loss_fp: 0.002269, loss_freq: 0.049998
[05:44:14.412] iteration 18261: loss: 0.074788, loss_s1: 0.057618, loss_fp: 0.008435, loss_freq: 0.039005
[05:44:15.031] iteration 18262: loss: 0.048038, loss_s1: 0.016654, loss_fp: 0.003648, loss_freq: 0.036353
[05:44:15.654] iteration 18263: loss: 0.058398, loss_s1: 0.044131, loss_fp: 0.004706, loss_freq: 0.037813
[05:44:16.270] iteration 18264: loss: 0.080392, loss_s1: 0.092049, loss_fp: 0.002702, loss_freq: 0.030248
[05:44:16.888] iteration 18265: loss: 0.067414, loss_s1: 0.059672, loss_fp: 0.002076, loss_freq: 0.035325
[05:44:17.499] iteration 18266: loss: 0.080870, loss_s1: 0.029499, loss_fp: 0.010005, loss_freq: 0.075549
[05:44:18.113] iteration 18267: loss: 0.053291, loss_s1: 0.028064, loss_fp: 0.004557, loss_freq: 0.040299
[05:44:18.726] iteration 18268: loss: 0.067320, loss_s1: 0.058613, loss_fp: 0.004536, loss_freq: 0.028733
[05:44:19.341] iteration 18269: loss: 0.056129, loss_s1: 0.033500, loss_fp: 0.007372, loss_freq: 0.047136
[05:44:19.947] iteration 18270: loss: 0.063021, loss_s1: 0.042378, loss_fp: 0.004534, loss_freq: 0.033854
[05:44:20.553] iteration 18271: loss: 0.072368, loss_s1: 0.090026, loss_fp: 0.001900, loss_freq: 0.012274
[05:44:21.172] iteration 18272: loss: 0.050801, loss_s1: 0.031673, loss_fp: 0.005831, loss_freq: 0.027449
[05:44:21.785] iteration 18273: loss: 0.057112, loss_s1: 0.057367, loss_fp: 0.002040, loss_freq: 0.020374
[05:44:22.399] iteration 18274: loss: 0.051269, loss_s1: 0.044598, loss_fp: 0.002101, loss_freq: 0.023346
[05:44:23.013] iteration 18275: loss: 0.062325, loss_s1: 0.050956, loss_fp: 0.001716, loss_freq: 0.019804
[05:44:23.621] iteration 18276: loss: 0.068572, loss_s1: 0.035599, loss_fp: 0.006294, loss_freq: 0.046724
[05:44:24.243] iteration 18277: loss: 0.065067, loss_s1: 0.080678, loss_fp: 0.005356, loss_freq: 0.018202
[05:44:24.855] iteration 18278: loss: 0.089266, loss_s1: 0.093149, loss_fp: 0.002338, loss_freq: 0.028443
[05:44:25.466] iteration 18279: loss: 0.054199, loss_s1: 0.042386, loss_fp: 0.016903, loss_freq: 0.011287
[05:44:26.067] iteration 18280: loss: 0.065621, loss_s1: 0.036375, loss_fp: 0.001794, loss_freq: 0.023268
[05:44:26.670] iteration 18281: loss: 0.071202, loss_s1: 0.071878, loss_fp: 0.007313, loss_freq: 0.029908
[05:44:27.318] iteration 18282: loss: 0.091578, loss_s1: 0.088644, loss_fp: 0.001307, loss_freq: 0.063919
[05:44:27.931] iteration 18283: loss: 0.048234, loss_s1: 0.035802, loss_fp: 0.007233, loss_freq: 0.012253
[05:44:28.549] iteration 18284: loss: 0.053474, loss_s1: 0.026621, loss_fp: 0.002398, loss_freq: 0.038294
[05:44:29.161] iteration 18285: loss: 0.082095, loss_s1: 0.074432, loss_fp: 0.004268, loss_freq: 0.039770
[05:44:29.767] iteration 18286: loss: 0.064474, loss_s1: 0.047929, loss_fp: 0.003765, loss_freq: 0.049624
[05:44:30.375] iteration 18287: loss: 0.080001, loss_s1: 0.058507, loss_fp: 0.002725, loss_freq: 0.036519
[05:44:30.986] iteration 18288: loss: 0.105777, loss_s1: 0.055251, loss_fp: 0.013662, loss_freq: 0.096714
[05:44:31.610] iteration 18289: loss: 0.075069, loss_s1: 0.059411, loss_fp: 0.008806, loss_freq: 0.041409
[05:44:32.216] iteration 18290: loss: 0.056008, loss_s1: 0.026456, loss_fp: 0.005141, loss_freq: 0.035128
[05:44:32.827] iteration 18291: loss: 0.078567, loss_s1: 0.083719, loss_fp: 0.008364, loss_freq: 0.030549
[05:44:33.437] iteration 18292: loss: 0.053879, loss_s1: 0.034646, loss_fp: 0.004588, loss_freq: 0.021459
[05:44:34.041] iteration 18293: loss: 0.053001, loss_s1: 0.024508, loss_fp: 0.003243, loss_freq: 0.031746
[05:44:34.647] iteration 18294: loss: 0.039189, loss_s1: 0.024117, loss_fp: 0.002197, loss_freq: 0.021312
[05:44:35.260] iteration 18295: loss: 0.053810, loss_s1: 0.036403, loss_fp: 0.005360, loss_freq: 0.039316
[05:44:35.881] iteration 18296: loss: 0.076680, loss_s1: 0.065592, loss_fp: 0.007149, loss_freq: 0.026132
[05:44:36.492] iteration 18297: loss: 0.048896, loss_s1: 0.038722, loss_fp: 0.003078, loss_freq: 0.017762
[05:44:37.097] iteration 18298: loss: 0.063648, loss_s1: 0.055878, loss_fp: 0.002648, loss_freq: 0.034624
[05:44:37.704] iteration 18299: loss: 0.054582, loss_s1: 0.051567, loss_fp: 0.004659, loss_freq: 0.016998
[05:44:38.320] iteration 18300: loss: 0.053186, loss_s1: 0.028980, loss_fp: 0.003511, loss_freq: 0.037859
[05:44:38.933] iteration 18301: loss: 0.044519, loss_s1: 0.024370, loss_fp: 0.003274, loss_freq: 0.017557
[05:44:39.547] iteration 18302: loss: 0.057194, loss_s1: 0.042424, loss_fp: 0.005917, loss_freq: 0.021365
[05:44:40.159] iteration 18303: loss: 0.048764, loss_s1: 0.023746, loss_fp: 0.002059, loss_freq: 0.031497
[05:44:40.790] iteration 18304: loss: 0.031225, loss_s1: 0.021288, loss_fp: 0.007314, loss_freq: 0.007548
[05:44:41.405] iteration 18305: loss: 0.083757, loss_s1: 0.078449, loss_fp: 0.004756, loss_freq: 0.035758
[05:44:42.032] iteration 18306: loss: 0.076114, loss_s1: 0.069954, loss_fp: 0.005222, loss_freq: 0.038846
[05:44:42.663] iteration 18307: loss: 0.086144, loss_s1: 0.085013, loss_fp: 0.003799, loss_freq: 0.050971
[05:44:43.269] iteration 18308: loss: 0.052987, loss_s1: 0.035258, loss_fp: 0.002332, loss_freq: 0.028837
[05:44:43.881] iteration 18309: loss: 0.074636, loss_s1: 0.030754, loss_fp: 0.001145, loss_freq: 0.084418
[05:44:44.490] iteration 18310: loss: 0.035138, loss_s1: 0.023145, loss_fp: 0.005095, loss_freq: 0.005465
[05:44:45.098] iteration 18311: loss: 0.046507, loss_s1: 0.045657, loss_fp: 0.002928, loss_freq: 0.005246
[05:44:45.710] iteration 18312: loss: 0.067298, loss_s1: 0.049306, loss_fp: 0.001005, loss_freq: 0.057547
[05:44:46.317] iteration 18313: loss: 0.101173, loss_s1: 0.116471, loss_fp: 0.012593, loss_freq: 0.039996
[05:44:46.925] iteration 18314: loss: 0.043979, loss_s1: 0.016407, loss_fp: 0.002747, loss_freq: 0.028052
[05:44:47.565] iteration 18315: loss: 0.079946, loss_s1: 0.078728, loss_fp: 0.004515, loss_freq: 0.032790
[05:44:48.175] iteration 18316: loss: 0.075020, loss_s1: 0.103691, loss_fp: 0.001555, loss_freq: 0.010225
[05:44:48.851] iteration 18317: loss: 0.080402, loss_s1: 0.060408, loss_fp: 0.001835, loss_freq: 0.071936
[05:44:49.508] iteration 18318: loss: 0.040823, loss_s1: 0.013457, loss_fp: 0.003787, loss_freq: 0.005401
[05:44:50.176] iteration 18319: loss: 0.062337, loss_s1: 0.060356, loss_fp: 0.002615, loss_freq: 0.023708
[05:44:50.838] iteration 18320: loss: 0.044927, loss_s1: 0.029305, loss_fp: 0.000631, loss_freq: 0.027562
[05:44:51.460] iteration 18321: loss: 0.069011, loss_s1: 0.077049, loss_fp: 0.001126, loss_freq: 0.031863
[05:44:52.128] iteration 18322: loss: 0.070563, loss_s1: 0.052580, loss_fp: 0.005225, loss_freq: 0.026747
[05:44:52.817] iteration 18323: loss: 0.082258, loss_s1: 0.063878, loss_fp: 0.003482, loss_freq: 0.051312
[05:44:53.511] iteration 18324: loss: 0.054211, loss_s1: 0.050865, loss_fp: 0.004774, loss_freq: 0.014917
[05:44:54.172] iteration 18325: loss: 0.109998, loss_s1: 0.081266, loss_fp: 0.003514, loss_freq: 0.098126
[05:44:54.837] iteration 18326: loss: 0.047902, loss_s1: 0.058438, loss_fp: 0.001879, loss_freq: 0.008142
[05:44:55.483] iteration 18327: loss: 0.075112, loss_s1: 0.078554, loss_fp: 0.002728, loss_freq: 0.022848
[05:44:56.093] iteration 18328: loss: 0.064453, loss_s1: 0.048439, loss_fp: 0.007532, loss_freq: 0.029983
[05:44:56.702] iteration 18329: loss: 0.050249, loss_s1: 0.036218, loss_fp: 0.006926, loss_freq: 0.030861
[05:44:57.319] iteration 18330: loss: 0.051763, loss_s1: 0.041209, loss_fp: 0.004062, loss_freq: 0.029261
[05:44:57.962] iteration 18331: loss: 0.081703, loss_s1: 0.088915, loss_fp: 0.004781, loss_freq: 0.023491
[05:44:58.577] iteration 18332: loss: 0.056762, loss_s1: 0.050307, loss_fp: 0.003051, loss_freq: 0.024204
[05:44:59.194] iteration 18333: loss: 0.056870, loss_s1: 0.059071, loss_fp: 0.002772, loss_freq: 0.018982
[05:44:59.838] iteration 18334: loss: 0.040615, loss_s1: 0.010986, loss_fp: 0.003177, loss_freq: 0.021236
[05:45:00.445] iteration 18335: loss: 0.067439, loss_s1: 0.063889, loss_fp: 0.005509, loss_freq: 0.020000
[05:45:01.055] iteration 18336: loss: 0.053359, loss_s1: 0.032617, loss_fp: 0.001620, loss_freq: 0.027103
[05:45:01.679] iteration 18337: loss: 0.083176, loss_s1: 0.096811, loss_fp: 0.003366, loss_freq: 0.034058
[05:45:02.294] iteration 18338: loss: 0.059867, loss_s1: 0.041301, loss_fp: 0.003326, loss_freq: 0.046284
[05:45:02.924] iteration 18339: loss: 0.071571, loss_s1: 0.056954, loss_fp: 0.012627, loss_freq: 0.014940
[05:45:03.535] iteration 18340: loss: 0.073335, loss_s1: 0.063207, loss_fp: 0.006455, loss_freq: 0.027242
[05:45:04.149] iteration 18341: loss: 0.065737, loss_s1: 0.059281, loss_fp: 0.004537, loss_freq: 0.032079
[05:45:04.766] iteration 18342: loss: 0.064863, loss_s1: 0.045302, loss_fp: 0.001291, loss_freq: 0.043312
[05:45:05.380] iteration 18343: loss: 0.090131, loss_s1: 0.100050, loss_fp: 0.005488, loss_freq: 0.041429
[05:45:05.995] iteration 18344: loss: 0.078542, loss_s1: 0.052275, loss_fp: 0.012804, loss_freq: 0.060400
[05:45:06.605] iteration 18345: loss: 0.074235, loss_s1: 0.065470, loss_fp: 0.002437, loss_freq: 0.031519
[05:45:07.217] iteration 18346: loss: 0.043850, loss_s1: 0.037049, loss_fp: 0.004470, loss_freq: 0.012564
[05:45:07.832] iteration 18347: loss: 0.042659, loss_s1: 0.028111, loss_fp: 0.007784, loss_freq: 0.023440
[05:45:08.438] iteration 18348: loss: 0.116557, loss_s1: 0.108664, loss_fp: 0.003033, loss_freq: 0.079379
[05:45:09.057] iteration 18349: loss: 0.053731, loss_s1: 0.048585, loss_fp: 0.005006, loss_freq: 0.022103
[05:45:09.709] iteration 18350: loss: 0.092472, loss_s1: 0.086807, loss_fp: 0.005442, loss_freq: 0.055875
[05:45:10.554] iteration 18351: loss: 0.042470, loss_s1: 0.043305, loss_fp: 0.002612, loss_freq: 0.006035
[05:45:11.324] iteration 18352: loss: 0.068482, loss_s1: 0.055977, loss_fp: 0.003930, loss_freq: 0.049294
[05:45:12.038] iteration 18353: loss: 0.046088, loss_s1: 0.023883, loss_fp: 0.001797, loss_freq: 0.017682
[05:45:12.646] iteration 18354: loss: 0.054424, loss_s1: 0.032649, loss_fp: 0.003038, loss_freq: 0.037943
[05:45:13.264] iteration 18355: loss: 0.033125, loss_s1: 0.018506, loss_fp: 0.002759, loss_freq: 0.012301
[05:45:13.877] iteration 18356: loss: 0.090403, loss_s1: 0.087563, loss_fp: 0.003637, loss_freq: 0.041021
[05:45:14.532] iteration 18357: loss: 0.062087, loss_s1: 0.032515, loss_fp: 0.005003, loss_freq: 0.046023
[05:45:15.188] iteration 18358: loss: 0.076069, loss_s1: 0.045510, loss_fp: 0.004291, loss_freq: 0.066994
[05:45:15.842] iteration 18359: loss: 0.097257, loss_s1: 0.085182, loss_fp: 0.003188, loss_freq: 0.070920
[05:45:16.491] iteration 18360: loss: 0.051766, loss_s1: 0.032129, loss_fp: 0.007652, loss_freq: 0.024422
[05:45:17.432] iteration 18361: loss: 0.054951, loss_s1: 0.038214, loss_fp: 0.000680, loss_freq: 0.015551
[05:45:18.062] iteration 18362: loss: 0.063744, loss_s1: 0.069484, loss_fp: 0.000773, loss_freq: 0.024805
[05:45:18.714] iteration 18363: loss: 0.048906, loss_s1: 0.049154, loss_fp: 0.004926, loss_freq: 0.016891
[05:45:19.350] iteration 18364: loss: 0.038952, loss_s1: 0.018820, loss_fp: 0.001640, loss_freq: 0.019681
[05:45:19.967] iteration 18365: loss: 0.047433, loss_s1: 0.032408, loss_fp: 0.001130, loss_freq: 0.030489
[05:45:20.588] iteration 18366: loss: 0.071774, loss_s1: 0.076779, loss_fp: 0.004484, loss_freq: 0.022762
[05:45:21.218] iteration 18367: loss: 0.078126, loss_s1: 0.089751, loss_fp: 0.002020, loss_freq: 0.031641
[05:45:21.875] iteration 18368: loss: 0.057386, loss_s1: 0.060635, loss_fp: 0.002779, loss_freq: 0.024480
[05:45:22.540] iteration 18369: loss: 0.054316, loss_s1: 0.034155, loss_fp: 0.001721, loss_freq: 0.016139
[05:45:23.185] iteration 18370: loss: 0.073002, loss_s1: 0.076592, loss_fp: 0.005609, loss_freq: 0.028681
[05:45:23.876] iteration 18371: loss: 0.055967, loss_s1: 0.040983, loss_fp: 0.004262, loss_freq: 0.025927
[05:45:24.531] iteration 18372: loss: 0.062548, loss_s1: 0.062752, loss_fp: 0.001974, loss_freq: 0.025096
[05:45:25.187] iteration 18373: loss: 0.054979, loss_s1: 0.051416, loss_fp: 0.001136, loss_freq: 0.025109
[05:45:25.845] iteration 18374: loss: 0.096436, loss_s1: 0.081259, loss_fp: 0.007205, loss_freq: 0.061560
[05:45:26.487] iteration 18375: loss: 0.054523, loss_s1: 0.052375, loss_fp: 0.001847, loss_freq: 0.017856
[05:45:27.142] iteration 18376: loss: 0.056019, loss_s1: 0.056604, loss_fp: 0.003620, loss_freq: 0.010134
[05:45:27.753] iteration 18377: loss: 0.093671, loss_s1: 0.078778, loss_fp: 0.006392, loss_freq: 0.072438
[05:45:28.404] iteration 18378: loss: 0.039002, loss_s1: 0.034907, loss_fp: 0.001329, loss_freq: 0.011473
[05:45:29.013] iteration 18379: loss: 0.084046, loss_s1: 0.071871, loss_fp: 0.012877, loss_freq: 0.047391
[05:45:29.621] iteration 18380: loss: 0.086625, loss_s1: 0.112523, loss_fp: 0.003672, loss_freq: 0.012811
[05:45:30.229] iteration 18381: loss: 0.045250, loss_s1: 0.034130, loss_fp: 0.001325, loss_freq: 0.022791
[05:45:30.836] iteration 18382: loss: 0.060661, loss_s1: 0.039799, loss_fp: 0.015482, loss_freq: 0.033211
[05:45:31.438] iteration 18383: loss: 0.063622, loss_s1: 0.019468, loss_fp: 0.003641, loss_freq: 0.027803
[05:45:32.043] iteration 18384: loss: 0.066093, loss_s1: 0.066707, loss_fp: 0.006106, loss_freq: 0.029785
[05:45:32.652] iteration 18385: loss: 0.076188, loss_s1: 0.067549, loss_fp: 0.002543, loss_freq: 0.045871
[05:45:33.262] iteration 18386: loss: 0.060687, loss_s1: 0.048884, loss_fp: 0.002969, loss_freq: 0.036412
[05:45:33.868] iteration 18387: loss: 0.058237, loss_s1: 0.039342, loss_fp: 0.007831, loss_freq: 0.012395
[05:45:34.479] iteration 18388: loss: 0.128628, loss_s1: 0.138448, loss_fp: 0.001327, loss_freq: 0.075335
[05:45:35.087] iteration 18389: loss: 0.036415, loss_s1: 0.021824, loss_fp: 0.003843, loss_freq: 0.014647
[05:45:35.699] iteration 18390: loss: 0.100669, loss_s1: 0.111858, loss_fp: 0.005352, loss_freq: 0.033994
[05:45:36.323] iteration 18391: loss: 0.110125, loss_s1: 0.094310, loss_fp: 0.002049, loss_freq: 0.094070
[05:45:36.933] iteration 18392: loss: 0.085109, loss_s1: 0.066511, loss_fp: 0.010122, loss_freq: 0.054485
[05:45:37.545] iteration 18393: loss: 0.052364, loss_s1: 0.046886, loss_fp: 0.002462, loss_freq: 0.025919
[05:45:38.155] iteration 18394: loss: 0.036174, loss_s1: 0.030342, loss_fp: 0.002825, loss_freq: 0.008859
[05:45:38.761] iteration 18395: loss: 0.081229, loss_s1: 0.103422, loss_fp: 0.002151, loss_freq: 0.031809
[05:45:39.370] iteration 18396: loss: 0.042561, loss_s1: 0.016149, loss_fp: 0.003924, loss_freq: 0.016186
[05:45:39.977] iteration 18397: loss: 0.061691, loss_s1: 0.049772, loss_fp: 0.003657, loss_freq: 0.029847
[05:45:40.589] iteration 18398: loss: 0.052187, loss_s1: 0.055728, loss_fp: 0.002932, loss_freq: 0.015551
[05:45:41.205] iteration 18399: loss: 0.115334, loss_s1: 0.114203, loss_fp: 0.007605, loss_freq: 0.067515
[05:45:41.824] iteration 18400: loss: 0.075275, loss_s1: 0.073985, loss_fp: 0.003753, loss_freq: 0.027070
[05:45:45.084] iteration 18400 : mean_dice : 0.730120
[05:45:45.728] iteration 18401: loss: 0.063000, loss_s1: 0.046667, loss_fp: 0.004458, loss_freq: 0.034238
[05:45:46.341] iteration 18402: loss: 0.059377, loss_s1: 0.048665, loss_fp: 0.003448, loss_freq: 0.026974
[05:45:46.952] iteration 18403: loss: 0.115919, loss_s1: 0.154081, loss_fp: 0.002151, loss_freq: 0.045773
[05:45:47.566] iteration 18404: loss: 0.099351, loss_s1: 0.100319, loss_fp: 0.004964, loss_freq: 0.068435
[05:45:48.178] iteration 18405: loss: 0.052437, loss_s1: 0.025982, loss_fp: 0.003134, loss_freq: 0.028865
[05:45:48.791] iteration 18406: loss: 0.072282, loss_s1: 0.070090, loss_fp: 0.003228, loss_freq: 0.021700
[05:45:49.403] iteration 18407: loss: 0.062220, loss_s1: 0.054389, loss_fp: 0.006271, loss_freq: 0.029876
[05:45:50.019] iteration 18408: loss: 0.056333, loss_s1: 0.046856, loss_fp: 0.001695, loss_freq: 0.022989
[05:45:50.635] iteration 18409: loss: 0.043657, loss_s1: 0.052823, loss_fp: 0.001038, loss_freq: 0.004942
[05:45:51.244] iteration 18410: loss: 0.054258, loss_s1: 0.036858, loss_fp: 0.003353, loss_freq: 0.021969
[05:45:51.858] iteration 18411: loss: 0.035375, loss_s1: 0.018702, loss_fp: 0.001174, loss_freq: 0.018664
[05:45:52.475] iteration 18412: loss: 0.050573, loss_s1: 0.049802, loss_fp: 0.003285, loss_freq: 0.022465
[05:45:53.084] iteration 18413: loss: 0.052083, loss_s1: 0.023494, loss_fp: 0.001958, loss_freq: 0.027338
[05:45:53.718] iteration 18414: loss: 0.082556, loss_s1: 0.092623, loss_fp: 0.002729, loss_freq: 0.030334
[05:45:54.376] iteration 18415: loss: 0.044920, loss_s1: 0.016986, loss_fp: 0.002412, loss_freq: 0.034582
[05:45:55.033] iteration 18416: loss: 0.047889, loss_s1: 0.036595, loss_fp: 0.004280, loss_freq: 0.019170
[05:45:55.653] iteration 18417: loss: 0.086989, loss_s1: 0.073363, loss_fp: 0.007146, loss_freq: 0.067094
[05:45:56.297] iteration 18418: loss: 0.077376, loss_s1: 0.070792, loss_fp: 0.003639, loss_freq: 0.028080
[05:45:56.906] iteration 18419: loss: 0.036362, loss_s1: 0.014298, loss_fp: 0.002241, loss_freq: 0.025061
[05:45:57.521] iteration 18420: loss: 0.068078, loss_s1: 0.036431, loss_fp: 0.007970, loss_freq: 0.045217
[05:45:58.129] iteration 18421: loss: 0.044617, loss_s1: 0.040693, loss_fp: 0.002093, loss_freq: 0.013116
[05:45:58.742] iteration 18422: loss: 0.064768, loss_s1: 0.037260, loss_fp: 0.003081, loss_freq: 0.028410
[05:45:59.361] iteration 18423: loss: 0.041762, loss_s1: 0.027887, loss_fp: 0.001245, loss_freq: 0.016366
[05:45:59.978] iteration 18424: loss: 0.044545, loss_s1: 0.035387, loss_fp: 0.002022, loss_freq: 0.021314
[05:46:00.629] iteration 18425: loss: 0.071066, loss_s1: 0.078029, loss_fp: 0.006452, loss_freq: 0.012507
[05:46:01.246] iteration 18426: loss: 0.044946, loss_s1: 0.024264, loss_fp: 0.004079, loss_freq: 0.034194
[05:46:01.866] iteration 18427: loss: 0.056753, loss_s1: 0.022933, loss_fp: 0.008775, loss_freq: 0.012698
[05:46:02.475] iteration 18428: loss: 0.125115, loss_s1: 0.133247, loss_fp: 0.016596, loss_freq: 0.056634
[05:46:03.092] iteration 18429: loss: 0.026781, loss_s1: 0.010447, loss_fp: 0.001768, loss_freq: 0.010697
[05:46:03.744] iteration 18430: loss: 0.068297, loss_s1: 0.056017, loss_fp: 0.007514, loss_freq: 0.047455
[05:46:04.402] iteration 18431: loss: 0.090176, loss_s1: 0.052646, loss_fp: 0.007414, loss_freq: 0.049545
[05:46:05.063] iteration 18432: loss: 0.056874, loss_s1: 0.050429, loss_fp: 0.001706, loss_freq: 0.027040
[05:46:05.688] iteration 18433: loss: 0.056959, loss_s1: 0.054255, loss_fp: 0.013694, loss_freq: 0.015149
[05:46:06.303] iteration 18434: loss: 0.084516, loss_s1: 0.087852, loss_fp: 0.008832, loss_freq: 0.036944
[05:46:06.918] iteration 18435: loss: 0.063572, loss_s1: 0.029097, loss_fp: 0.002090, loss_freq: 0.051528
[05:46:07.530] iteration 18436: loss: 0.080801, loss_s1: 0.053303, loss_fp: 0.006759, loss_freq: 0.048559
[05:46:08.188] iteration 18437: loss: 0.056407, loss_s1: 0.056985, loss_fp: 0.001358, loss_freq: 0.018621
[05:46:08.864] iteration 18438: loss: 0.067608, loss_s1: 0.048687, loss_fp: 0.008942, loss_freq: 0.045443
[05:46:09.545] iteration 18439: loss: 0.068199, loss_s1: 0.058524, loss_fp: 0.007538, loss_freq: 0.042877
[05:46:10.198] iteration 18440: loss: 0.074874, loss_s1: 0.058529, loss_fp: 0.003424, loss_freq: 0.046612
[05:46:10.861] iteration 18441: loss: 0.080393, loss_s1: 0.052609, loss_fp: 0.002295, loss_freq: 0.047065
[05:46:11.520] iteration 18442: loss: 0.050816, loss_s1: 0.035275, loss_fp: 0.006924, loss_freq: 0.026048
[05:46:12.127] iteration 18443: loss: 0.077414, loss_s1: 0.084958, loss_fp: 0.001089, loss_freq: 0.025954
[05:46:12.739] iteration 18444: loss: 0.081763, loss_s1: 0.109907, loss_fp: 0.006075, loss_freq: 0.012256
[05:46:13.347] iteration 18445: loss: 0.063365, loss_s1: 0.062000, loss_fp: 0.001746, loss_freq: 0.023454
[05:46:13.958] iteration 18446: loss: 0.065728, loss_s1: 0.043914, loss_fp: 0.008756, loss_freq: 0.041382
[05:46:14.571] iteration 18447: loss: 0.065109, loss_s1: 0.072714, loss_fp: 0.003169, loss_freq: 0.030111
[05:46:15.179] iteration 18448: loss: 0.082373, loss_s1: 0.086057, loss_fp: 0.002618, loss_freq: 0.043104
[05:46:15.791] iteration 18449: loss: 0.071728, loss_s1: 0.030159, loss_fp: 0.003472, loss_freq: 0.077245
[05:46:16.404] iteration 18450: loss: 0.047170, loss_s1: 0.047930, loss_fp: 0.001371, loss_freq: 0.005863
[05:46:17.017] iteration 18451: loss: 0.054886, loss_s1: 0.045280, loss_fp: 0.002670, loss_freq: 0.021562
[05:46:17.628] iteration 18452: loss: 0.070297, loss_s1: 0.073507, loss_fp: 0.003413, loss_freq: 0.037044
[05:46:18.240] iteration 18453: loss: 0.055471, loss_s1: 0.042162, loss_fp: 0.003441, loss_freq: 0.013608
[05:46:18.855] iteration 18454: loss: 0.046708, loss_s1: 0.042744, loss_fp: 0.005811, loss_freq: 0.011595
[05:46:19.463] iteration 18455: loss: 0.080978, loss_s1: 0.060189, loss_fp: 0.002103, loss_freq: 0.063723
[05:46:20.076] iteration 18456: loss: 0.074105, loss_s1: 0.088354, loss_fp: 0.004998, loss_freq: 0.028464
[05:46:20.689] iteration 18457: loss: 0.081146, loss_s1: 0.052158, loss_fp: 0.001607, loss_freq: 0.059564
[05:46:21.296] iteration 18458: loss: 0.080501, loss_s1: 0.081874, loss_fp: 0.004739, loss_freq: 0.037569
[05:46:21.917] iteration 18459: loss: 0.064265, loss_s1: 0.043667, loss_fp: 0.011276, loss_freq: 0.034775
[05:46:22.525] iteration 18460: loss: 0.052238, loss_s1: 0.041698, loss_fp: 0.006365, loss_freq: 0.019641
[05:46:23.131] iteration 18461: loss: 0.038184, loss_s1: 0.030438, loss_fp: 0.004929, loss_freq: 0.014049
[05:46:23.746] iteration 18462: loss: 0.072068, loss_s1: 0.076557, loss_fp: 0.009439, loss_freq: 0.015177
[05:46:24.392] iteration 18463: loss: 0.048579, loss_s1: 0.013847, loss_fp: 0.005784, loss_freq: 0.033576
[05:46:25.082] iteration 18464: loss: 0.053909, loss_s1: 0.026932, loss_fp: 0.004955, loss_freq: 0.040506
[05:46:25.751] iteration 18465: loss: 0.044490, loss_s1: 0.026615, loss_fp: 0.002444, loss_freq: 0.031451
[05:46:26.417] iteration 18466: loss: 0.071920, loss_s1: 0.069217, loss_fp: 0.008857, loss_freq: 0.025698
[05:46:27.089] iteration 18467: loss: 0.065807, loss_s1: 0.062317, loss_fp: 0.003596, loss_freq: 0.027833
[05:46:27.744] iteration 18468: loss: 0.069643, loss_s1: 0.057474, loss_fp: 0.003877, loss_freq: 0.052111
[05:46:28.379] iteration 18469: loss: 0.050098, loss_s1: 0.027393, loss_fp: 0.009903, loss_freq: 0.027808
[05:46:29.006] iteration 18470: loss: 0.050787, loss_s1: 0.042000, loss_fp: 0.002961, loss_freq: 0.027706
[05:46:29.632] iteration 18471: loss: 0.049145, loss_s1: 0.037066, loss_fp: 0.001530, loss_freq: 0.020676
[05:46:30.261] iteration 18472: loss: 0.066022, loss_s1: 0.056556, loss_fp: 0.005019, loss_freq: 0.029394
[05:46:30.888] iteration 18473: loss: 0.059846, loss_s1: 0.056748, loss_fp: 0.003163, loss_freq: 0.030331
[05:46:31.517] iteration 18474: loss: 0.039465, loss_s1: 0.023756, loss_fp: 0.002891, loss_freq: 0.011290
[05:46:32.131] iteration 18475: loss: 0.101000, loss_s1: 0.103482, loss_fp: 0.004609, loss_freq: 0.056016
[05:46:32.746] iteration 18476: loss: 0.064898, loss_s1: 0.046439, loss_fp: 0.006148, loss_freq: 0.035196
[05:46:33.360] iteration 18477: loss: 0.082044, loss_s1: 0.074327, loss_fp: 0.013019, loss_freq: 0.040723
[05:46:33.973] iteration 18478: loss: 0.059997, loss_s1: 0.061995, loss_fp: 0.009913, loss_freq: 0.019675
[05:46:34.582] iteration 18479: loss: 0.092379, loss_s1: 0.068433, loss_fp: 0.003571, loss_freq: 0.077259
[05:46:35.194] iteration 18480: loss: 0.066393, loss_s1: 0.064454, loss_fp: 0.004901, loss_freq: 0.021750
[05:46:35.806] iteration 18481: loss: 0.049307, loss_s1: 0.034032, loss_fp: 0.003963, loss_freq: 0.015852
[05:46:36.421] iteration 18482: loss: 0.072256, loss_s1: 0.081784, loss_fp: 0.004612, loss_freq: 0.036548
[05:46:37.031] iteration 18483: loss: 0.051195, loss_s1: 0.040956, loss_fp: 0.007312, loss_freq: 0.023666
[05:46:37.648] iteration 18484: loss: 0.046120, loss_s1: 0.039963, loss_fp: 0.001828, loss_freq: 0.018263
[05:46:38.252] iteration 18485: loss: 0.055452, loss_s1: 0.038231, loss_fp: 0.001004, loss_freq: 0.032434
[05:46:38.863] iteration 18486: loss: 0.041812, loss_s1: 0.019990, loss_fp: 0.002123, loss_freq: 0.029891
[05:46:39.490] iteration 18487: loss: 0.068026, loss_s1: 0.047098, loss_fp: 0.001523, loss_freq: 0.058999
[05:46:40.100] iteration 18488: loss: 0.069978, loss_s1: 0.056386, loss_fp: 0.022202, loss_freq: 0.009566
[05:46:40.711] iteration 18489: loss: 0.075454, loss_s1: 0.063126, loss_fp: 0.002496, loss_freq: 0.038463
[05:46:41.318] iteration 18490: loss: 0.057174, loss_s1: 0.039241, loss_fp: 0.011789, loss_freq: 0.028403
[05:46:41.924] iteration 18491: loss: 0.056308, loss_s1: 0.067255, loss_fp: 0.010948, loss_freq: 0.009022
[05:46:42.533] iteration 18492: loss: 0.050926, loss_s1: 0.043335, loss_fp: 0.001415, loss_freq: 0.021172
[05:46:43.144] iteration 18493: loss: 0.078313, loss_s1: 0.077604, loss_fp: 0.014619, loss_freq: 0.029330
[05:46:43.771] iteration 18494: loss: 0.060504, loss_s1: 0.062778, loss_fp: 0.008127, loss_freq: 0.018045
[05:46:44.393] iteration 18495: loss: 0.131952, loss_s1: 0.093632, loss_fp: 0.003963, loss_freq: 0.127539
[05:46:45.066] iteration 18496: loss: 0.055228, loss_s1: 0.054958, loss_fp: 0.011153, loss_freq: 0.017383
[05:46:45.720] iteration 18497: loss: 0.077394, loss_s1: 0.080041, loss_fp: 0.002344, loss_freq: 0.022255
[05:46:46.377] iteration 18498: loss: 0.058316, loss_s1: 0.029003, loss_fp: 0.001954, loss_freq: 0.054140
[05:46:46.993] iteration 18499: loss: 0.100457, loss_s1: 0.109362, loss_fp: 0.004464, loss_freq: 0.059195
[05:46:47.610] iteration 18500: loss: 0.051107, loss_s1: 0.043821, loss_fp: 0.006852, loss_freq: 0.026320
[05:46:48.224] iteration 18501: loss: 0.097963, loss_s1: 0.125136, loss_fp: 0.004075, loss_freq: 0.026177
[05:46:48.834] iteration 18502: loss: 0.066061, loss_s1: 0.028690, loss_fp: 0.014670, loss_freq: 0.050878
[05:46:49.450] iteration 18503: loss: 0.062045, loss_s1: 0.052975, loss_fp: 0.006438, loss_freq: 0.028151
[05:46:50.056] iteration 18504: loss: 0.043548, loss_s1: 0.039930, loss_fp: 0.004276, loss_freq: 0.009904
[05:46:50.662] iteration 18505: loss: 0.034634, loss_s1: 0.025001, loss_fp: 0.004603, loss_freq: 0.008694
[05:46:51.274] iteration 18506: loss: 0.054052, loss_s1: 0.040240, loss_fp: 0.003380, loss_freq: 0.026845
[05:46:51.880] iteration 18507: loss: 0.062755, loss_s1: 0.049048, loss_fp: 0.002091, loss_freq: 0.028432
[05:46:52.491] iteration 18508: loss: 0.078769, loss_s1: 0.097995, loss_fp: 0.004533, loss_freq: 0.026051
[05:46:53.128] iteration 18509: loss: 0.062716, loss_s1: 0.065285, loss_fp: 0.001304, loss_freq: 0.027166
[05:46:53.749] iteration 18510: loss: 0.055061, loss_s1: 0.042221, loss_fp: 0.003984, loss_freq: 0.024470
[05:46:54.368] iteration 18511: loss: 0.093724, loss_s1: 0.088076, loss_fp: 0.017258, loss_freq: 0.045303
[05:46:54.988] iteration 18512: loss: 0.089726, loss_s1: 0.079285, loss_fp: 0.004943, loss_freq: 0.054716
[05:46:55.611] iteration 18513: loss: 0.079691, loss_s1: 0.066001, loss_fp: 0.002764, loss_freq: 0.040056
[05:46:56.222] iteration 18514: loss: 0.075688, loss_s1: 0.085000, loss_fp: 0.007347, loss_freq: 0.029767
[05:46:56.839] iteration 18515: loss: 0.086787, loss_s1: 0.051548, loss_fp: 0.005935, loss_freq: 0.083064
[05:46:57.454] iteration 18516: loss: 0.040507, loss_s1: 0.019516, loss_fp: 0.001749, loss_freq: 0.009580
[05:46:58.073] iteration 18517: loss: 0.045868, loss_s1: 0.036312, loss_fp: 0.004112, loss_freq: 0.025203
[05:46:58.712] iteration 18518: loss: 0.092062, loss_s1: 0.047710, loss_fp: 0.001853, loss_freq: 0.084368
[05:46:59.323] iteration 18519: loss: 0.069513, loss_s1: 0.081072, loss_fp: 0.003447, loss_freq: 0.025596
[05:46:59.935] iteration 18520: loss: 0.081691, loss_s1: 0.055389, loss_fp: 0.005687, loss_freq: 0.030021
[05:47:00.551] iteration 18521: loss: 0.048869, loss_s1: 0.038426, loss_fp: 0.002201, loss_freq: 0.020229
[05:47:01.160] iteration 18522: loss: 0.073692, loss_s1: 0.079754, loss_fp: 0.001899, loss_freq: 0.033105
[05:47:01.768] iteration 18523: loss: 0.043787, loss_s1: 0.018150, loss_fp: 0.004544, loss_freq: 0.014966
[05:47:02.392] iteration 18524: loss: 0.054049, loss_s1: 0.043698, loss_fp: 0.001087, loss_freq: 0.034469
[05:47:03.025] iteration 18525: loss: 0.047115, loss_s1: 0.041687, loss_fp: 0.001243, loss_freq: 0.013471
[05:47:03.656] iteration 18526: loss: 0.071231, loss_s1: 0.041733, loss_fp: 0.011574, loss_freq: 0.034759
[05:47:04.284] iteration 18527: loss: 0.061229, loss_s1: 0.039912, loss_fp: 0.004127, loss_freq: 0.037748
[05:47:04.909] iteration 18528: loss: 0.081389, loss_s1: 0.069947, loss_fp: 0.005152, loss_freq: 0.047691
[05:47:05.532] iteration 18529: loss: 0.072510, loss_s1: 0.063605, loss_fp: 0.001408, loss_freq: 0.052298
[05:47:06.148] iteration 18530: loss: 0.072267, loss_s1: 0.064302, loss_fp: 0.005615, loss_freq: 0.039106
[05:47:07.163] iteration 18531: loss: 0.072931, loss_s1: 0.072299, loss_fp: 0.004912, loss_freq: 0.026210
[05:47:07.825] iteration 18532: loss: 0.058736, loss_s1: 0.043422, loss_fp: 0.002033, loss_freq: 0.037338
[05:47:08.513] iteration 18533: loss: 0.047103, loss_s1: 0.036188, loss_fp: 0.004665, loss_freq: 0.026912
[05:47:09.170] iteration 18534: loss: 0.039857, loss_s1: 0.028350, loss_fp: 0.001470, loss_freq: 0.018468
[05:47:09.841] iteration 18535: loss: 0.049525, loss_s1: 0.046504, loss_fp: 0.003936, loss_freq: 0.016620
[05:47:10.508] iteration 18536: loss: 0.053038, loss_s1: 0.032408, loss_fp: 0.002628, loss_freq: 0.031569
[05:47:11.176] iteration 18537: loss: 0.066939, loss_s1: 0.048983, loss_fp: 0.007544, loss_freq: 0.038852
[05:47:11.832] iteration 18538: loss: 0.050356, loss_s1: 0.034306, loss_fp: 0.009744, loss_freq: 0.024881
[05:47:12.470] iteration 18539: loss: 0.036731, loss_s1: 0.017841, loss_fp: 0.007319, loss_freq: 0.021795
[05:47:13.145] iteration 18540: loss: 0.092342, loss_s1: 0.085451, loss_fp: 0.007831, loss_freq: 0.044197
[05:47:13.822] iteration 18541: loss: 0.060936, loss_s1: 0.031715, loss_fp: 0.001978, loss_freq: 0.046397
[05:47:14.480] iteration 18542: loss: 0.126511, loss_s1: 0.155130, loss_fp: 0.006925, loss_freq: 0.050558
[05:47:15.264] iteration 18543: loss: 0.053106, loss_s1: 0.029145, loss_fp: 0.004997, loss_freq: 0.022099
[05:47:16.063] iteration 18544: loss: 0.089601, loss_s1: 0.073465, loss_fp: 0.006600, loss_freq: 0.065004
[05:47:16.807] iteration 18545: loss: 0.064312, loss_s1: 0.063921, loss_fp: 0.008653, loss_freq: 0.022763
[05:47:17.415] iteration 18546: loss: 0.041420, loss_s1: 0.024192, loss_fp: 0.002304, loss_freq: 0.021871
[05:47:18.028] iteration 18547: loss: 0.117207, loss_s1: 0.122664, loss_fp: 0.001954, loss_freq: 0.082645
[05:47:18.645] iteration 18548: loss: 0.034703, loss_s1: 0.018604, loss_fp: 0.001466, loss_freq: 0.022513
[05:47:19.265] iteration 18549: loss: 0.068926, loss_s1: 0.044376, loss_fp: 0.005162, loss_freq: 0.041341
[05:47:19.914] iteration 18550: loss: 0.049102, loss_s1: 0.036459, loss_fp: 0.008093, loss_freq: 0.019321
[05:47:20.529] iteration 18551: loss: 0.034298, loss_s1: 0.012356, loss_fp: 0.002149, loss_freq: 0.014250
[05:47:21.138] iteration 18552: loss: 0.057847, loss_s1: 0.064600, loss_fp: 0.002548, loss_freq: 0.024770
[05:47:21.750] iteration 18553: loss: 0.055874, loss_s1: 0.022585, loss_fp: 0.004333, loss_freq: 0.034508
[05:47:22.363] iteration 18554: loss: 0.067225, loss_s1: 0.071479, loss_fp: 0.002595, loss_freq: 0.021433
[05:47:22.974] iteration 18555: loss: 0.093986, loss_s1: 0.089857, loss_fp: 0.003579, loss_freq: 0.049900
[05:47:23.609] iteration 18556: loss: 0.059152, loss_s1: 0.054976, loss_fp: 0.003828, loss_freq: 0.034902
[05:47:24.222] iteration 18557: loss: 0.082481, loss_s1: 0.059810, loss_fp: 0.002399, loss_freq: 0.051397
[05:47:24.833] iteration 18558: loss: 0.085437, loss_s1: 0.072640, loss_fp: 0.006200, loss_freq: 0.048813
[05:47:25.446] iteration 18559: loss: 0.044437, loss_s1: 0.024980, loss_fp: 0.001377, loss_freq: 0.013738
[05:47:26.062] iteration 18560: loss: 0.057484, loss_s1: 0.026320, loss_fp: 0.013105, loss_freq: 0.044409
[05:47:26.676] iteration 18561: loss: 0.070099, loss_s1: 0.059374, loss_fp: 0.004174, loss_freq: 0.051244
[05:47:27.285] iteration 18562: loss: 0.085023, loss_s1: 0.087436, loss_fp: 0.001787, loss_freq: 0.025580
[05:47:27.900] iteration 18563: loss: 0.117022, loss_s1: 0.096933, loss_fp: 0.007416, loss_freq: 0.065722
[05:47:28.516] iteration 18564: loss: 0.056255, loss_s1: 0.054346, loss_fp: 0.002472, loss_freq: 0.013715
[05:47:29.124] iteration 18565: loss: 0.041635, loss_s1: 0.026581, loss_fp: 0.002089, loss_freq: 0.025751
[05:47:29.738] iteration 18566: loss: 0.062529, loss_s1: 0.059299, loss_fp: 0.002789, loss_freq: 0.022462
[05:47:30.346] iteration 18567: loss: 0.057526, loss_s1: 0.046369, loss_fp: 0.006909, loss_freq: 0.028060
[05:47:30.956] iteration 18568: loss: 0.046796, loss_s1: 0.046341, loss_fp: 0.002267, loss_freq: 0.017502
[05:47:31.561] iteration 18569: loss: 0.102580, loss_s1: 0.098584, loss_fp: 0.004852, loss_freq: 0.060784
[05:47:32.211] iteration 18570: loss: 0.058745, loss_s1: 0.036909, loss_fp: 0.004843, loss_freq: 0.042829
[05:47:32.820] iteration 18571: loss: 0.107015, loss_s1: 0.119787, loss_fp: 0.007732, loss_freq: 0.042249
[05:47:33.427] iteration 18572: loss: 0.050450, loss_s1: 0.024051, loss_fp: 0.001586, loss_freq: 0.038586
[05:47:34.030] iteration 18573: loss: 0.069566, loss_s1: 0.073334, loss_fp: 0.002152, loss_freq: 0.034940
[05:47:34.639] iteration 18574: loss: 0.067303, loss_s1: 0.048289, loss_fp: 0.002921, loss_freq: 0.052264
[05:47:35.251] iteration 18575: loss: 0.040621, loss_s1: 0.028777, loss_fp: 0.001276, loss_freq: 0.017879
[05:47:35.865] iteration 18576: loss: 0.053923, loss_s1: 0.038650, loss_fp: 0.003874, loss_freq: 0.028890
[05:47:36.503] iteration 18577: loss: 0.056685, loss_s1: 0.029829, loss_fp: 0.002028, loss_freq: 0.026079
[05:47:37.118] iteration 18578: loss: 0.067986, loss_s1: 0.070706, loss_fp: 0.002261, loss_freq: 0.032584
[05:47:37.732] iteration 18579: loss: 0.058897, loss_s1: 0.068880, loss_fp: 0.004072, loss_freq: 0.005210
[05:47:38.350] iteration 18580: loss: 0.066362, loss_s1: 0.063274, loss_fp: 0.002433, loss_freq: 0.028594
[05:47:38.966] iteration 18581: loss: 0.059377, loss_s1: 0.032327, loss_fp: 0.002020, loss_freq: 0.041325
[05:47:39.576] iteration 18582: loss: 0.084006, loss_s1: 0.076932, loss_fp: 0.004263, loss_freq: 0.057928
[05:47:40.189] iteration 18583: loss: 0.034992, loss_s1: 0.012987, loss_fp: 0.004684, loss_freq: 0.018651
[05:47:40.869] iteration 18584: loss: 0.088404, loss_s1: 0.098436, loss_fp: 0.004523, loss_freq: 0.040471
[05:47:41.522] iteration 18585: loss: 0.046139, loss_s1: 0.010040, loss_fp: 0.002187, loss_freq: 0.036942
[05:47:42.175] iteration 18586: loss: 0.049076, loss_s1: 0.037843, loss_fp: 0.003044, loss_freq: 0.019361
[05:47:42.832] iteration 18587: loss: 0.063531, loss_s1: 0.047739, loss_fp: 0.004074, loss_freq: 0.041492
[05:47:43.496] iteration 18588: loss: 0.038953, loss_s1: 0.015208, loss_fp: 0.004215, loss_freq: 0.018724
[05:47:44.109] iteration 18589: loss: 0.044839, loss_s1: 0.017040, loss_fp: 0.002547, loss_freq: 0.035375
[05:47:44.773] iteration 18590: loss: 0.072789, loss_s1: 0.068763, loss_fp: 0.001462, loss_freq: 0.040623
[05:47:45.446] iteration 18591: loss: 0.039835, loss_s1: 0.025612, loss_fp: 0.003446, loss_freq: 0.012529
[05:47:46.112] iteration 18592: loss: 0.079092, loss_s1: 0.052616, loss_fp: 0.001314, loss_freq: 0.051657
[05:47:46.736] iteration 18593: loss: 0.035731, loss_s1: 0.025227, loss_fp: 0.002009, loss_freq: 0.009392
[05:47:47.406] iteration 18594: loss: 0.043841, loss_s1: 0.020666, loss_fp: 0.001239, loss_freq: 0.011008
[05:47:48.021] iteration 18595: loss: 0.047151, loss_s1: 0.046142, loss_fp: 0.001543, loss_freq: 0.010720
[05:47:48.626] iteration 18596: loss: 0.042899, loss_s1: 0.029073, loss_fp: 0.005269, loss_freq: 0.025337
[05:47:49.232] iteration 18597: loss: 0.051052, loss_s1: 0.039931, loss_fp: 0.000859, loss_freq: 0.021423
[05:47:49.838] iteration 18598: loss: 0.147359, loss_s1: 0.184738, loss_fp: 0.003106, loss_freq: 0.076946
[05:47:50.445] iteration 18599: loss: 0.042417, loss_s1: 0.020071, loss_fp: 0.002645, loss_freq: 0.025510
[05:47:51.060] iteration 18600: loss: 0.039322, loss_s1: 0.046681, loss_fp: 0.002947, loss_freq: 0.008367
[05:47:54.378] iteration 18600 : mean_dice : 0.739901
[05:47:55.008] iteration 18601: loss: 0.069163, loss_s1: 0.058865, loss_fp: 0.015229, loss_freq: 0.023594
[05:47:55.616] iteration 18602: loss: 0.058566, loss_s1: 0.027797, loss_fp: 0.011641, loss_freq: 0.033475
[05:47:56.226] iteration 18603: loss: 0.059693, loss_s1: 0.038224, loss_fp: 0.005233, loss_freq: 0.046431
[05:47:56.838] iteration 18604: loss: 0.067949, loss_s1: 0.062009, loss_fp: 0.012678, loss_freq: 0.023479
[05:47:57.447] iteration 18605: loss: 0.052264, loss_s1: 0.034700, loss_fp: 0.000565, loss_freq: 0.043857
[05:47:58.123] iteration 18606: loss: 0.067920, loss_s1: 0.045624, loss_fp: 0.009882, loss_freq: 0.039197
[05:47:58.828] iteration 18607: loss: 0.056474, loss_s1: 0.038008, loss_fp: 0.007161, loss_freq: 0.031064
[05:47:59.478] iteration 18608: loss: 0.087327, loss_s1: 0.079621, loss_fp: 0.005118, loss_freq: 0.047209
[05:48:00.105] iteration 18609: loss: 0.062628, loss_s1: 0.048214, loss_fp: 0.008940, loss_freq: 0.033582
[05:48:00.732] iteration 18610: loss: 0.063128, loss_s1: 0.046898, loss_fp: 0.005397, loss_freq: 0.031540
[05:48:01.354] iteration 18611: loss: 0.078187, loss_s1: 0.078440, loss_fp: 0.000304, loss_freq: 0.040865
[05:48:01.967] iteration 18612: loss: 0.052409, loss_s1: 0.025152, loss_fp: 0.009594, loss_freq: 0.033641
[05:48:02.590] iteration 18613: loss: 0.058803, loss_s1: 0.056781, loss_fp: 0.001044, loss_freq: 0.027776
[05:48:03.197] iteration 18614: loss: 0.039845, loss_s1: 0.024190, loss_fp: 0.004424, loss_freq: 0.013597
[05:48:03.805] iteration 18615: loss: 0.043161, loss_s1: 0.015745, loss_fp: 0.001408, loss_freq: 0.022177
[05:48:04.412] iteration 18616: loss: 0.056524, loss_s1: 0.048905, loss_fp: 0.006636, loss_freq: 0.024207
[05:48:05.021] iteration 18617: loss: 0.062828, loss_s1: 0.055659, loss_fp: 0.002164, loss_freq: 0.045066
[05:48:05.627] iteration 18618: loss: 0.072767, loss_s1: 0.056770, loss_fp: 0.002386, loss_freq: 0.030417
[05:48:06.233] iteration 18619: loss: 0.066037, loss_s1: 0.064925, loss_fp: 0.005705, loss_freq: 0.029738
[05:48:06.846] iteration 18620: loss: 0.075049, loss_s1: 0.069037, loss_fp: 0.001336, loss_freq: 0.034286
[05:48:07.455] iteration 18621: loss: 0.079455, loss_s1: 0.094545, loss_fp: 0.003133, loss_freq: 0.025462
[05:48:08.066] iteration 18622: loss: 0.067294, loss_s1: 0.039586, loss_fp: 0.003613, loss_freq: 0.062014
[05:48:08.668] iteration 18623: loss: 0.099409, loss_s1: 0.087698, loss_fp: 0.007291, loss_freq: 0.058814
[05:48:09.271] iteration 18624: loss: 0.086345, loss_s1: 0.077085, loss_fp: 0.003959, loss_freq: 0.061633
[05:48:09.880] iteration 18625: loss: 0.067669, loss_s1: 0.064257, loss_fp: 0.004844, loss_freq: 0.036843
[05:48:10.488] iteration 18626: loss: 0.062303, loss_s1: 0.051572, loss_fp: 0.002771, loss_freq: 0.044599
[05:48:11.093] iteration 18627: loss: 0.095010, loss_s1: 0.077711, loss_fp: 0.001667, loss_freq: 0.071130
[05:48:11.705] iteration 18628: loss: 0.046679, loss_s1: 0.028941, loss_fp: 0.003196, loss_freq: 0.023232
[05:48:12.310] iteration 18629: loss: 0.093438, loss_s1: 0.102939, loss_fp: 0.002756, loss_freq: 0.052152
[05:48:12.917] iteration 18630: loss: 0.053748, loss_s1: 0.052088, loss_fp: 0.001542, loss_freq: 0.014485
[05:48:13.525] iteration 18631: loss: 0.064260, loss_s1: 0.067460, loss_fp: 0.002583, loss_freq: 0.031724
[05:48:14.144] iteration 18632: loss: 0.045411, loss_s1: 0.019900, loss_fp: 0.003445, loss_freq: 0.029182
[05:48:14.755] iteration 18633: loss: 0.038328, loss_s1: 0.018741, loss_fp: 0.002316, loss_freq: 0.024066
[05:48:15.365] iteration 18634: loss: 0.039036, loss_s1: 0.019435, loss_fp: 0.003107, loss_freq: 0.018775
[05:48:15.978] iteration 18635: loss: 0.047965, loss_s1: 0.048647, loss_fp: 0.001304, loss_freq: 0.018788
[05:48:16.588] iteration 18636: loss: 0.070670, loss_s1: 0.067434, loss_fp: 0.005000, loss_freq: 0.027272
[05:48:17.253] iteration 18637: loss: 0.072610, loss_s1: 0.078992, loss_fp: 0.003340, loss_freq: 0.029519
[05:48:17.873] iteration 18638: loss: 0.061447, loss_s1: 0.052457, loss_fp: 0.005044, loss_freq: 0.040431
[05:48:18.475] iteration 18639: loss: 0.078829, loss_s1: 0.058745, loss_fp: 0.004890, loss_freq: 0.061255
[05:48:19.084] iteration 18640: loss: 0.038665, loss_s1: 0.021598, loss_fp: 0.003262, loss_freq: 0.027332
[05:48:19.690] iteration 18641: loss: 0.041358, loss_s1: 0.021346, loss_fp: 0.002076, loss_freq: 0.014337
[05:48:20.328] iteration 18642: loss: 0.047310, loss_s1: 0.022899, loss_fp: 0.004879, loss_freq: 0.019274
[05:48:20.935] iteration 18643: loss: 0.044589, loss_s1: 0.027745, loss_fp: 0.001977, loss_freq: 0.027743
[05:48:21.543] iteration 18644: loss: 0.041395, loss_s1: 0.027972, loss_fp: 0.005073, loss_freq: 0.011016
[05:48:22.152] iteration 18645: loss: 0.068869, loss_s1: 0.046563, loss_fp: 0.006493, loss_freq: 0.050667
[05:48:22.783] iteration 18646: loss: 0.052456, loss_s1: 0.040220, loss_fp: 0.003749, loss_freq: 0.023731
[05:48:23.395] iteration 18647: loss: 0.061343, loss_s1: 0.039854, loss_fp: 0.003534, loss_freq: 0.041450
[05:48:24.004] iteration 18648: loss: 0.062699, loss_s1: 0.045661, loss_fp: 0.010920, loss_freq: 0.036604
[05:48:24.611] iteration 18649: loss: 0.112365, loss_s1: 0.068425, loss_fp: 0.005353, loss_freq: 0.094123
[05:48:25.223] iteration 18650: loss: 0.066649, loss_s1: 0.046509, loss_fp: 0.002595, loss_freq: 0.037479
[05:48:25.833] iteration 18651: loss: 0.050739, loss_s1: 0.053590, loss_fp: 0.000899, loss_freq: 0.011360
[05:48:26.443] iteration 18652: loss: 0.040560, loss_s1: 0.029854, loss_fp: 0.005890, loss_freq: 0.017022
[05:48:27.053] iteration 18653: loss: 0.066069, loss_s1: 0.044749, loss_fp: 0.002315, loss_freq: 0.052986
[05:48:27.657] iteration 18654: loss: 0.042781, loss_s1: 0.032284, loss_fp: 0.001143, loss_freq: 0.020926
[05:48:28.261] iteration 18655: loss: 0.096308, loss_s1: 0.089059, loss_fp: 0.006386, loss_freq: 0.056141
[05:48:28.907] iteration 18656: loss: 0.043851, loss_s1: 0.028669, loss_fp: 0.004138, loss_freq: 0.017571
[05:48:29.523] iteration 18657: loss: 0.051443, loss_s1: 0.035347, loss_fp: 0.003884, loss_freq: 0.038829
[05:48:30.137] iteration 18658: loss: 0.068549, loss_s1: 0.066874, loss_fp: 0.006450, loss_freq: 0.014428
[05:48:30.748] iteration 18659: loss: 0.059325, loss_s1: 0.042329, loss_fp: 0.006703, loss_freq: 0.038139
[05:48:31.356] iteration 18660: loss: 0.086874, loss_s1: 0.102436, loss_fp: 0.010268, loss_freq: 0.029818
[05:48:31.966] iteration 18661: loss: 0.074452, loss_s1: 0.100496, loss_fp: 0.004063, loss_freq: 0.021580
[05:48:32.577] iteration 18662: loss: 0.087464, loss_s1: 0.062323, loss_fp: 0.013074, loss_freq: 0.061672
[05:48:33.203] iteration 18663: loss: 0.087442, loss_s1: 0.110429, loss_fp: 0.003391, loss_freq: 0.026823
[05:48:33.817] iteration 18664: loss: 0.088391, loss_s1: 0.096638, loss_fp: 0.006289, loss_freq: 0.041920
[05:48:34.431] iteration 18665: loss: 0.082879, loss_s1: 0.078484, loss_fp: 0.002030, loss_freq: 0.050019
[05:48:35.046] iteration 18666: loss: 0.039503, loss_s1: 0.041213, loss_fp: 0.007467, loss_freq: 0.006297
[05:48:35.661] iteration 18667: loss: 0.078001, loss_s1: 0.075181, loss_fp: 0.003132, loss_freq: 0.016228
[05:48:36.274] iteration 18668: loss: 0.093655, loss_s1: 0.072061, loss_fp: 0.003088, loss_freq: 0.073937
[05:48:36.888] iteration 18669: loss: 0.123486, loss_s1: 0.164040, loss_fp: 0.005213, loss_freq: 0.044259
[05:48:37.547] iteration 18670: loss: 0.087720, loss_s1: 0.122782, loss_fp: 0.004550, loss_freq: 0.025299
[05:48:38.200] iteration 18671: loss: 0.066260, loss_s1: 0.054288, loss_fp: 0.006790, loss_freq: 0.032130
[05:48:38.850] iteration 18672: loss: 0.062718, loss_s1: 0.032898, loss_fp: 0.003834, loss_freq: 0.041944
[05:48:39.459] iteration 18673: loss: 0.029582, loss_s1: 0.012268, loss_fp: 0.002226, loss_freq: 0.013033
[05:48:40.066] iteration 18674: loss: 0.053276, loss_s1: 0.050680, loss_fp: 0.002447, loss_freq: 0.014082
[05:48:40.675] iteration 18675: loss: 0.057485, loss_s1: 0.072324, loss_fp: 0.002647, loss_freq: 0.014921
[05:48:41.279] iteration 18676: loss: 0.068269, loss_s1: 0.061077, loss_fp: 0.004261, loss_freq: 0.029738
[05:48:41.883] iteration 18677: loss: 0.045180, loss_s1: 0.034753, loss_fp: 0.004097, loss_freq: 0.016772
[05:48:42.491] iteration 18678: loss: 0.076744, loss_s1: 0.083788, loss_fp: 0.005967, loss_freq: 0.036026
[05:48:43.102] iteration 18679: loss: 0.052551, loss_s1: 0.042755, loss_fp: 0.002697, loss_freq: 0.032623
[05:48:43.719] iteration 18680: loss: 0.087103, loss_s1: 0.062764, loss_fp: 0.014016, loss_freq: 0.049961
[05:48:44.334] iteration 18681: loss: 0.079598, loss_s1: 0.044312, loss_fp: 0.021083, loss_freq: 0.055807
[05:48:44.942] iteration 18682: loss: 0.091162, loss_s1: 0.070192, loss_fp: 0.002753, loss_freq: 0.077442
[05:48:45.547] iteration 18683: loss: 0.095206, loss_s1: 0.064816, loss_fp: 0.005622, loss_freq: 0.089666
[05:48:46.156] iteration 18684: loss: 0.073677, loss_s1: 0.066088, loss_fp: 0.006679, loss_freq: 0.036803
[05:48:46.761] iteration 18685: loss: 0.091710, loss_s1: 0.071652, loss_fp: 0.009777, loss_freq: 0.033515
[05:48:47.363] iteration 18686: loss: 0.042478, loss_s1: 0.031261, loss_fp: 0.002525, loss_freq: 0.015594
[05:48:47.965] iteration 18687: loss: 0.034549, loss_s1: 0.024457, loss_fp: 0.004648, loss_freq: 0.015556
[05:48:48.572] iteration 18688: loss: 0.129571, loss_s1: 0.130441, loss_fp: 0.018799, loss_freq: 0.071205
[05:48:49.181] iteration 18689: loss: 0.056276, loss_s1: 0.036792, loss_fp: 0.010293, loss_freq: 0.030982
[05:48:49.789] iteration 18690: loss: 0.094713, loss_s1: 0.069117, loss_fp: 0.003033, loss_freq: 0.075196
[05:48:50.393] iteration 18691: loss: 0.049137, loss_s1: 0.030126, loss_fp: 0.004011, loss_freq: 0.027702
[05:48:50.994] iteration 18692: loss: 0.082365, loss_s1: 0.071710, loss_fp: 0.013690, loss_freq: 0.042508
[05:48:51.598] iteration 18693: loss: 0.047961, loss_s1: 0.012132, loss_fp: 0.003319, loss_freq: 0.016048
[05:48:52.206] iteration 18694: loss: 0.043176, loss_s1: 0.029685, loss_fp: 0.002294, loss_freq: 0.020371
[05:48:52.810] iteration 18695: loss: 0.071293, loss_s1: 0.020897, loss_fp: 0.001281, loss_freq: 0.028151
[05:48:53.488] iteration 18696: loss: 0.060172, loss_s1: 0.055427, loss_fp: 0.016214, loss_freq: 0.023757
[05:48:54.192] iteration 18697: loss: 0.072295, loss_s1: 0.057759, loss_fp: 0.001597, loss_freq: 0.029739
[05:48:54.834] iteration 18698: loss: 0.098668, loss_s1: 0.078011, loss_fp: 0.001885, loss_freq: 0.080595
[05:48:55.446] iteration 18699: loss: 0.076103, loss_s1: 0.060386, loss_fp: 0.012837, loss_freq: 0.034352
[05:48:56.050] iteration 18700: loss: 0.071794, loss_s1: 0.071815, loss_fp: 0.004884, loss_freq: 0.012272
[05:48:57.004] iteration 18701: loss: 0.060745, loss_s1: 0.052429, loss_fp: 0.004298, loss_freq: 0.020923
[05:48:57.669] iteration 18702: loss: 0.045381, loss_s1: 0.023602, loss_fp: 0.001750, loss_freq: 0.031555
[05:48:58.319] iteration 18703: loss: 0.068687, loss_s1: 0.068925, loss_fp: 0.005636, loss_freq: 0.036352
[05:48:58.988] iteration 18704: loss: 0.045254, loss_s1: 0.031019, loss_fp: 0.001437, loss_freq: 0.014351
[05:48:59.619] iteration 18705: loss: 0.042894, loss_s1: 0.028186, loss_fp: 0.003665, loss_freq: 0.026927
[05:49:00.221] iteration 18706: loss: 0.071440, loss_s1: 0.075010, loss_fp: 0.002748, loss_freq: 0.022997
[05:49:00.828] iteration 18707: loss: 0.053572, loss_s1: 0.052059, loss_fp: 0.003933, loss_freq: 0.023273
[05:49:01.436] iteration 18708: loss: 0.037582, loss_s1: 0.028724, loss_fp: 0.000852, loss_freq: 0.013517
[05:49:02.051] iteration 18709: loss: 0.042191, loss_s1: 0.028442, loss_fp: 0.002024, loss_freq: 0.022046
[05:49:02.661] iteration 18710: loss: 0.054750, loss_s1: 0.051190, loss_fp: 0.002560, loss_freq: 0.015887
[05:49:03.272] iteration 18711: loss: 0.087150, loss_s1: 0.075326, loss_fp: 0.008881, loss_freq: 0.051178
[05:49:03.878] iteration 18712: loss: 0.065026, loss_s1: 0.049467, loss_fp: 0.001867, loss_freq: 0.042302
[05:49:04.545] iteration 18713: loss: 0.060020, loss_s1: 0.027195, loss_fp: 0.002194, loss_freq: 0.055267
[05:49:05.219] iteration 18714: loss: 0.064533, loss_s1: 0.058371, loss_fp: 0.005694, loss_freq: 0.027610
[05:49:05.874] iteration 18715: loss: 0.059462, loss_s1: 0.050530, loss_fp: 0.001616, loss_freq: 0.020849
[05:49:06.491] iteration 18716: loss: 0.062961, loss_s1: 0.055328, loss_fp: 0.002644, loss_freq: 0.031863
[05:49:07.098] iteration 18717: loss: 0.076973, loss_s1: 0.035580, loss_fp: 0.001789, loss_freq: 0.086064
[05:49:07.696] iteration 18718: loss: 0.036781, loss_s1: 0.026300, loss_fp: 0.002053, loss_freq: 0.013325
[05:49:08.300] iteration 18719: loss: 0.068781, loss_s1: 0.066282, loss_fp: 0.008333, loss_freq: 0.030701
[05:49:08.911] iteration 18720: loss: 0.046180, loss_s1: 0.023052, loss_fp: 0.002713, loss_freq: 0.017151
[05:49:09.532] iteration 18721: loss: 0.045416, loss_s1: 0.020862, loss_fp: 0.004621, loss_freq: 0.027242
[05:49:10.144] iteration 18722: loss: 0.050431, loss_s1: 0.047275, loss_fp: 0.004383, loss_freq: 0.022640
[05:49:10.747] iteration 18723: loss: 0.049722, loss_s1: 0.023850, loss_fp: 0.002306, loss_freq: 0.026951
[05:49:11.356] iteration 18724: loss: 0.045747, loss_s1: 0.033367, loss_fp: 0.003820, loss_freq: 0.018607
[05:49:11.972] iteration 18725: loss: 0.080509, loss_s1: 0.074657, loss_fp: 0.003023, loss_freq: 0.047608
[05:49:12.588] iteration 18726: loss: 0.053462, loss_s1: 0.048585, loss_fp: 0.003997, loss_freq: 0.027396
[05:49:13.203] iteration 18727: loss: 0.047168, loss_s1: 0.023934, loss_fp: 0.001054, loss_freq: 0.032283
[05:49:13.815] iteration 18728: loss: 0.125291, loss_s1: 0.094355, loss_fp: 0.008074, loss_freq: 0.096338
[05:49:14.447] iteration 18729: loss: 0.066219, loss_s1: 0.054019, loss_fp: 0.002249, loss_freq: 0.039348
[05:49:15.063] iteration 18730: loss: 0.099404, loss_s1: 0.117484, loss_fp: 0.012520, loss_freq: 0.032386
[05:49:15.672] iteration 18731: loss: 0.061123, loss_s1: 0.045967, loss_fp: 0.004509, loss_freq: 0.045425
[05:49:16.279] iteration 18732: loss: 0.135638, loss_s1: 0.146416, loss_fp: 0.008305, loss_freq: 0.074358
[05:49:16.902] iteration 18733: loss: 0.052970, loss_s1: 0.044285, loss_fp: 0.003687, loss_freq: 0.030661
[05:49:17.578] iteration 18734: loss: 0.050180, loss_s1: 0.044724, loss_fp: 0.002396, loss_freq: 0.014674
[05:49:18.546] iteration 18735: loss: 0.057284, loss_s1: 0.049393, loss_fp: 0.002582, loss_freq: 0.037820
[05:49:19.303] iteration 18736: loss: 0.059470, loss_s1: 0.055536, loss_fp: 0.002504, loss_freq: 0.016068
[05:49:20.006] iteration 18737: loss: 0.061003, loss_s1: 0.039950, loss_fp: 0.002630, loss_freq: 0.035596
[05:49:20.680] iteration 18738: loss: 0.087320, loss_s1: 0.118622, loss_fp: 0.005223, loss_freq: 0.014542
[05:49:21.351] iteration 18739: loss: 0.087935, loss_s1: 0.080487, loss_fp: 0.004125, loss_freq: 0.054107
[05:49:21.969] iteration 18740: loss: 0.059834, loss_s1: 0.040855, loss_fp: 0.003314, loss_freq: 0.044194
[05:49:22.602] iteration 18741: loss: 0.072826, loss_s1: 0.080400, loss_fp: 0.009398, loss_freq: 0.017444
[05:49:23.212] iteration 18742: loss: 0.071767, loss_s1: 0.060826, loss_fp: 0.004022, loss_freq: 0.041684
[05:49:23.820] iteration 18743: loss: 0.074181, loss_s1: 0.068362, loss_fp: 0.009968, loss_freq: 0.042304
[05:49:24.427] iteration 18744: loss: 0.099413, loss_s1: 0.094262, loss_fp: 0.008352, loss_freq: 0.066639
[05:49:25.034] iteration 18745: loss: 0.058022, loss_s1: 0.030866, loss_fp: 0.009420, loss_freq: 0.026856
[05:49:25.652] iteration 18746: loss: 0.072715, loss_s1: 0.079387, loss_fp: 0.013325, loss_freq: 0.023856
[05:49:26.253] iteration 18747: loss: 0.068013, loss_s1: 0.058654, loss_fp: 0.003133, loss_freq: 0.039680
[05:49:26.857] iteration 18748: loss: 0.068085, loss_s1: 0.034790, loss_fp: 0.010687, loss_freq: 0.059480
[05:49:27.461] iteration 18749: loss: 0.070504, loss_s1: 0.058250, loss_fp: 0.003899, loss_freq: 0.043418
[05:49:28.066] iteration 18750: loss: 0.046712, loss_s1: 0.046583, loss_fp: 0.001026, loss_freq: 0.007696
[05:49:28.678] iteration 18751: loss: 0.063761, loss_s1: 0.052985, loss_fp: 0.002654, loss_freq: 0.040397
[05:49:29.286] iteration 18752: loss: 0.068891, loss_s1: 0.074720, loss_fp: 0.004036, loss_freq: 0.039566
[05:49:29.931] iteration 18753: loss: 0.034079, loss_s1: 0.015723, loss_fp: 0.001525, loss_freq: 0.014198
[05:49:30.548] iteration 18754: loss: 0.072682, loss_s1: 0.056749, loss_fp: 0.012995, loss_freq: 0.041431
[05:49:31.160] iteration 18755: loss: 0.039014, loss_s1: 0.022128, loss_fp: 0.001934, loss_freq: 0.011031
[05:49:31.764] iteration 18756: loss: 0.038995, loss_s1: 0.023331, loss_fp: 0.002220, loss_freq: 0.017687
[05:49:32.374] iteration 18757: loss: 0.068007, loss_s1: 0.053230, loss_fp: 0.002493, loss_freq: 0.052998
[05:49:32.990] iteration 18758: loss: 0.056352, loss_s1: 0.025857, loss_fp: 0.006286, loss_freq: 0.035417
[05:49:33.604] iteration 18759: loss: 0.048589, loss_s1: 0.037743, loss_fp: 0.004036, loss_freq: 0.024455
[05:49:34.218] iteration 18760: loss: 0.095623, loss_s1: 0.074853, loss_fp: 0.004016, loss_freq: 0.077163
[05:49:34.850] iteration 18761: loss: 0.039658, loss_s1: 0.029406, loss_fp: 0.001918, loss_freq: 0.007890
[05:49:35.462] iteration 18762: loss: 0.074997, loss_s1: 0.041714, loss_fp: 0.006449, loss_freq: 0.060818
[05:49:36.125] iteration 18763: loss: 0.046698, loss_s1: 0.019307, loss_fp: 0.001773, loss_freq: 0.013819
[05:49:36.778] iteration 18764: loss: 0.056359, loss_s1: 0.036030, loss_fp: 0.003060, loss_freq: 0.027267
[05:49:37.396] iteration 18765: loss: 0.081820, loss_s1: 0.108104, loss_fp: 0.002536, loss_freq: 0.017132
[05:49:38.005] iteration 18766: loss: 0.043947, loss_s1: 0.032342, loss_fp: 0.006190, loss_freq: 0.026870
[05:49:38.676] iteration 18767: loss: 0.046307, loss_s1: 0.028688, loss_fp: 0.001542, loss_freq: 0.008380
[05:49:39.334] iteration 18768: loss: 0.092695, loss_s1: 0.083019, loss_fp: 0.006860, loss_freq: 0.056978
[05:49:39.993] iteration 18769: loss: 0.033943, loss_s1: 0.020077, loss_fp: 0.001907, loss_freq: 0.017001
[05:49:40.650] iteration 18770: loss: 0.046910, loss_s1: 0.026362, loss_fp: 0.010283, loss_freq: 0.032270
[05:49:41.309] iteration 18771: loss: 0.064701, loss_s1: 0.042685, loss_fp: 0.006005, loss_freq: 0.038334
[05:49:41.948] iteration 18772: loss: 0.051360, loss_s1: 0.055955, loss_fp: 0.002072, loss_freq: 0.012955
[05:49:42.636] iteration 18773: loss: 0.061700, loss_s1: 0.057256, loss_fp: 0.005252, loss_freq: 0.033471
[05:49:43.246] iteration 18774: loss: 0.085788, loss_s1: 0.102687, loss_fp: 0.004451, loss_freq: 0.031074
[05:49:43.864] iteration 18775: loss: 0.085401, loss_s1: 0.065843, loss_fp: 0.005763, loss_freq: 0.050214
[05:49:44.477] iteration 18776: loss: 0.069774, loss_s1: 0.048474, loss_fp: 0.006163, loss_freq: 0.050303
[05:49:45.084] iteration 18777: loss: 0.067104, loss_s1: 0.042529, loss_fp: 0.006626, loss_freq: 0.046728
[05:49:45.691] iteration 18778: loss: 0.061839, loss_s1: 0.042743, loss_fp: 0.006036, loss_freq: 0.041057
[05:49:46.309] iteration 18779: loss: 0.046779, loss_s1: 0.042216, loss_fp: 0.006816, loss_freq: 0.021852
[05:49:46.911] iteration 18780: loss: 0.053026, loss_s1: 0.037421, loss_fp: 0.005817, loss_freq: 0.027933
[05:49:47.524] iteration 18781: loss: 0.073751, loss_s1: 0.043353, loss_fp: 0.002998, loss_freq: 0.037240
[05:49:48.135] iteration 18782: loss: 0.064845, loss_s1: 0.049072, loss_fp: 0.004224, loss_freq: 0.044742
[05:49:48.754] iteration 18783: loss: 0.063993, loss_s1: 0.072492, loss_fp: 0.003330, loss_freq: 0.025731
[05:49:49.373] iteration 18784: loss: 0.041039, loss_s1: 0.025595, loss_fp: 0.001247, loss_freq: 0.019082
[05:49:49.989] iteration 18785: loss: 0.058120, loss_s1: 0.049476, loss_fp: 0.004680, loss_freq: 0.027691
[05:49:50.600] iteration 18786: loss: 0.063744, loss_s1: 0.041320, loss_fp: 0.011108, loss_freq: 0.034382
[05:49:51.213] iteration 18787: loss: 0.074997, loss_s1: 0.089318, loss_fp: 0.003123, loss_freq: 0.034354
[05:49:51.829] iteration 18788: loss: 0.052685, loss_s1: 0.045780, loss_fp: 0.004935, loss_freq: 0.018165
[05:49:52.448] iteration 18789: loss: 0.042433, loss_s1: 0.029160, loss_fp: 0.002857, loss_freq: 0.021846
[05:49:53.071] iteration 18790: loss: 0.046387, loss_s1: 0.032573, loss_fp: 0.010123, loss_freq: 0.011213
[05:49:53.704] iteration 18791: loss: 0.073484, loss_s1: 0.057353, loss_fp: 0.005112, loss_freq: 0.048825
[05:49:54.360] iteration 18792: loss: 0.102097, loss_s1: 0.142408, loss_fp: 0.000970, loss_freq: 0.034887
[05:49:54.986] iteration 18793: loss: 0.092313, loss_s1: 0.097680, loss_fp: 0.016036, loss_freq: 0.030007
[05:49:55.614] iteration 18794: loss: 0.040886, loss_s1: 0.029518, loss_fp: 0.001575, loss_freq: 0.019199
[05:49:56.229] iteration 18795: loss: 0.055357, loss_s1: 0.037117, loss_fp: 0.005593, loss_freq: 0.031137
[05:49:56.854] iteration 18796: loss: 0.068084, loss_s1: 0.052445, loss_fp: 0.001187, loss_freq: 0.045285
[05:49:57.465] iteration 18797: loss: 0.082522, loss_s1: 0.068820, loss_fp: 0.004109, loss_freq: 0.049333
[05:49:58.112] iteration 18798: loss: 0.046382, loss_s1: 0.013690, loss_fp: 0.003687, loss_freq: 0.030640
[05:49:58.723] iteration 18799: loss: 0.067952, loss_s1: 0.047439, loss_fp: 0.001431, loss_freq: 0.051138
[05:49:59.337] iteration 18800: loss: 0.048275, loss_s1: 0.021529, loss_fp: 0.001852, loss_freq: 0.031544
[05:50:02.577] iteration 18800 : mean_dice : 0.732256
[05:50:03.235] iteration 18801: loss: 0.061430, loss_s1: 0.059218, loss_fp: 0.004198, loss_freq: 0.026596
[05:50:03.844] iteration 18802: loss: 0.056281, loss_s1: 0.024663, loss_fp: 0.001692, loss_freq: 0.026525
[05:50:04.453] iteration 18803: loss: 0.037012, loss_s1: 0.028440, loss_fp: 0.002516, loss_freq: 0.015483
[05:50:05.100] iteration 18804: loss: 0.041455, loss_s1: 0.019600, loss_fp: 0.001487, loss_freq: 0.017994
[05:50:05.763] iteration 18805: loss: 0.029462, loss_s1: 0.021030, loss_fp: 0.001491, loss_freq: 0.009531
[05:50:06.368] iteration 18806: loss: 0.052935, loss_s1: 0.053124, loss_fp: 0.004034, loss_freq: 0.013839
[05:50:06.995] iteration 18807: loss: 0.078883, loss_s1: 0.067716, loss_fp: 0.003891, loss_freq: 0.045678
[05:50:07.609] iteration 18808: loss: 0.046825, loss_s1: 0.048004, loss_fp: 0.002309, loss_freq: 0.017335
[05:50:08.211] iteration 18809: loss: 0.045619, loss_s1: 0.017637, loss_fp: 0.010377, loss_freq: 0.025787
[05:50:08.828] iteration 18810: loss: 0.063469, loss_s1: 0.058289, loss_fp: 0.002681, loss_freq: 0.034370
[05:50:09.475] iteration 18811: loss: 0.066896, loss_s1: 0.042203, loss_fp: 0.001930, loss_freq: 0.044023
[05:50:10.092] iteration 18812: loss: 0.064024, loss_s1: 0.053714, loss_fp: 0.003128, loss_freq: 0.031741
[05:50:10.707] iteration 18813: loss: 0.069951, loss_s1: 0.076435, loss_fp: 0.003807, loss_freq: 0.035403
[05:50:11.322] iteration 18814: loss: 0.039510, loss_s1: 0.020858, loss_fp: 0.004092, loss_freq: 0.011611
[05:50:11.946] iteration 18815: loss: 0.060791, loss_s1: 0.038942, loss_fp: 0.006821, loss_freq: 0.040517
[05:50:12.560] iteration 18816: loss: 0.061377, loss_s1: 0.042639, loss_fp: 0.007070, loss_freq: 0.032169
[05:50:13.186] iteration 18817: loss: 0.062147, loss_s1: 0.048542, loss_fp: 0.005134, loss_freq: 0.033347
[05:50:13.844] iteration 18818: loss: 0.051589, loss_s1: 0.045770, loss_fp: 0.006448, loss_freq: 0.022198
[05:50:14.450] iteration 18819: loss: 0.066608, loss_s1: 0.056478, loss_fp: 0.005975, loss_freq: 0.040758
[05:50:15.057] iteration 18820: loss: 0.072267, loss_s1: 0.093227, loss_fp: 0.002857, loss_freq: 0.012129
[05:50:15.665] iteration 18821: loss: 0.065653, loss_s1: 0.088061, loss_fp: 0.001980, loss_freq: 0.008263
[05:50:16.269] iteration 18822: loss: 0.060003, loss_s1: 0.068694, loss_fp: 0.003106, loss_freq: 0.025960
[05:50:16.874] iteration 18823: loss: 0.119539, loss_s1: 0.124914, loss_fp: 0.002634, loss_freq: 0.075243
[05:50:17.479] iteration 18824: loss: 0.074069, loss_s1: 0.085126, loss_fp: 0.002562, loss_freq: 0.029075
[05:50:18.121] iteration 18825: loss: 0.137724, loss_s1: 0.164203, loss_fp: 0.015691, loss_freq: 0.057373
[05:50:18.735] iteration 18826: loss: 0.058699, loss_s1: 0.040031, loss_fp: 0.002687, loss_freq: 0.039646
[05:50:19.347] iteration 18827: loss: 0.067246, loss_s1: 0.071366, loss_fp: 0.002103, loss_freq: 0.037258
[05:50:19.957] iteration 18828: loss: 0.054688, loss_s1: 0.044425, loss_fp: 0.002025, loss_freq: 0.013500
[05:50:20.569] iteration 18829: loss: 0.051888, loss_s1: 0.053731, loss_fp: 0.005580, loss_freq: 0.017166
[05:50:21.178] iteration 18830: loss: 0.063942, loss_s1: 0.042136, loss_fp: 0.005270, loss_freq: 0.045775
[05:50:21.790] iteration 18831: loss: 0.054363, loss_s1: 0.041718, loss_fp: 0.003926, loss_freq: 0.034443
[05:50:22.402] iteration 18832: loss: 0.047009, loss_s1: 0.030061, loss_fp: 0.001140, loss_freq: 0.019788
[05:50:23.022] iteration 18833: loss: 0.057072, loss_s1: 0.043706, loss_fp: 0.004056, loss_freq: 0.034307
[05:50:23.636] iteration 18834: loss: 0.075234, loss_s1: 0.061623, loss_fp: 0.003827, loss_freq: 0.044112
[05:50:24.254] iteration 18835: loss: 0.041516, loss_s1: 0.020024, loss_fp: 0.005797, loss_freq: 0.019125
[05:50:24.886] iteration 18836: loss: 0.066319, loss_s1: 0.087885, loss_fp: 0.003737, loss_freq: 0.010389
[05:50:25.492] iteration 18837: loss: 0.088383, loss_s1: 0.096636, loss_fp: 0.001464, loss_freq: 0.016204
[05:50:26.101] iteration 18838: loss: 0.051912, loss_s1: 0.018113, loss_fp: 0.002947, loss_freq: 0.038872
[05:50:26.714] iteration 18839: loss: 0.113893, loss_s1: 0.136431, loss_fp: 0.006586, loss_freq: 0.054228
[05:50:27.318] iteration 18840: loss: 0.044570, loss_s1: 0.036990, loss_fp: 0.005536, loss_freq: 0.024465
[05:50:27.926] iteration 18841: loss: 0.044179, loss_s1: 0.024285, loss_fp: 0.006425, loss_freq: 0.024566
[05:50:28.540] iteration 18842: loss: 0.052803, loss_s1: 0.042897, loss_fp: 0.009852, loss_freq: 0.016300
[05:50:29.152] iteration 18843: loss: 0.054670, loss_s1: 0.051987, loss_fp: 0.002239, loss_freq: 0.024602
[05:50:29.765] iteration 18844: loss: 0.050852, loss_s1: 0.034650, loss_fp: 0.003451, loss_freq: 0.022979
[05:50:30.449] iteration 18845: loss: 0.050275, loss_s1: 0.048743, loss_fp: 0.000967, loss_freq: 0.017821
[05:50:31.108] iteration 18846: loss: 0.046137, loss_s1: 0.023868, loss_fp: 0.004462, loss_freq: 0.024646
[05:50:31.770] iteration 18847: loss: 0.043631, loss_s1: 0.026919, loss_fp: 0.002001, loss_freq: 0.019775
[05:50:32.432] iteration 18848: loss: 0.108559, loss_s1: 0.117281, loss_fp: 0.003611, loss_freq: 0.047138
[05:50:33.091] iteration 18849: loss: 0.074546, loss_s1: 0.071724, loss_fp: 0.013254, loss_freq: 0.036031
[05:50:33.753] iteration 18850: loss: 0.064477, loss_s1: 0.036913, loss_fp: 0.007547, loss_freq: 0.043209
[05:50:34.374] iteration 18851: loss: 0.076475, loss_s1: 0.065488, loss_fp: 0.015485, loss_freq: 0.032709
[05:50:35.033] iteration 18852: loss: 0.074566, loss_s1: 0.069369, loss_fp: 0.004604, loss_freq: 0.040848
[05:50:35.677] iteration 18853: loss: 0.072059, loss_s1: 0.054421, loss_fp: 0.007611, loss_freq: 0.050268
[05:50:36.287] iteration 18854: loss: 0.088387, loss_s1: 0.078382, loss_fp: 0.014642, loss_freq: 0.050651
[05:50:36.892] iteration 18855: loss: 0.084607, loss_s1: 0.065749, loss_fp: 0.003819, loss_freq: 0.055263
[05:50:37.507] iteration 18856: loss: 0.052770, loss_s1: 0.048314, loss_fp: 0.001483, loss_freq: 0.014595
[05:50:38.119] iteration 18857: loss: 0.044958, loss_s1: 0.028568, loss_fp: 0.004156, loss_freq: 0.016039
[05:50:38.736] iteration 18858: loss: 0.086354, loss_s1: 0.062062, loss_fp: 0.001965, loss_freq: 0.052731
[05:50:39.381] iteration 18859: loss: 0.067902, loss_s1: 0.036445, loss_fp: 0.006842, loss_freq: 0.062456
[05:50:39.997] iteration 18860: loss: 0.069983, loss_s1: 0.065250, loss_fp: 0.006020, loss_freq: 0.028591
[05:50:40.611] iteration 18861: loss: 0.047389, loss_s1: 0.033871, loss_fp: 0.003083, loss_freq: 0.018267
[05:50:41.218] iteration 18862: loss: 0.076103, loss_s1: 0.050292, loss_fp: 0.001382, loss_freq: 0.057198
[05:50:41.839] iteration 18863: loss: 0.043377, loss_s1: 0.016463, loss_fp: 0.000823, loss_freq: 0.017804
[05:50:42.462] iteration 18864: loss: 0.074969, loss_s1: 0.088974, loss_fp: 0.001158, loss_freq: 0.023532
[05:50:43.124] iteration 18865: loss: 0.048210, loss_s1: 0.041475, loss_fp: 0.002904, loss_freq: 0.010118
[05:50:43.785] iteration 18866: loss: 0.081261, loss_s1: 0.076445, loss_fp: 0.010325, loss_freq: 0.043496
[05:50:44.474] iteration 18867: loss: 0.064087, loss_s1: 0.037913, loss_fp: 0.003047, loss_freq: 0.041839
[05:50:45.127] iteration 18868: loss: 0.107875, loss_s1: 0.121891, loss_fp: 0.006787, loss_freq: 0.043791
[05:50:45.776] iteration 18869: loss: 0.115097, loss_s1: 0.122696, loss_fp: 0.002764, loss_freq: 0.072951
[05:50:46.424] iteration 18870: loss: 0.077996, loss_s1: 0.057352, loss_fp: 0.002574, loss_freq: 0.055489
[05:50:47.387] iteration 18871: loss: 0.051678, loss_s1: 0.032299, loss_fp: 0.002174, loss_freq: 0.035513
[05:50:47.995] iteration 18872: loss: 0.062024, loss_s1: 0.054195, loss_fp: 0.007391, loss_freq: 0.025781
[05:50:48.604] iteration 18873: loss: 0.074183, loss_s1: 0.100897, loss_fp: 0.004512, loss_freq: 0.016959
[05:50:49.216] iteration 18874: loss: 0.053426, loss_s1: 0.043088, loss_fp: 0.001755, loss_freq: 0.024883
[05:50:49.830] iteration 18875: loss: 0.053466, loss_s1: 0.038171, loss_fp: 0.002874, loss_freq: 0.027113
[05:50:50.444] iteration 18876: loss: 0.063277, loss_s1: 0.051460, loss_fp: 0.004684, loss_freq: 0.031006
[05:50:51.068] iteration 18877: loss: 0.040986, loss_s1: 0.021738, loss_fp: 0.001826, loss_freq: 0.024053
[05:50:51.726] iteration 18878: loss: 0.066741, loss_s1: 0.059142, loss_fp: 0.008524, loss_freq: 0.028845
[05:50:52.385] iteration 18879: loss: 0.049862, loss_s1: 0.038089, loss_fp: 0.003584, loss_freq: 0.011018
[05:50:53.066] iteration 18880: loss: 0.069174, loss_s1: 0.063912, loss_fp: 0.008129, loss_freq: 0.030876
[05:50:53.689] iteration 18881: loss: 0.069141, loss_s1: 0.053976, loss_fp: 0.001256, loss_freq: 0.020308
[05:50:54.296] iteration 18882: loss: 0.076430, loss_s1: 0.058827, loss_fp: 0.002756, loss_freq: 0.054709
[05:50:54.901] iteration 18883: loss: 0.060262, loss_s1: 0.063330, loss_fp: 0.002166, loss_freq: 0.023469
[05:50:55.504] iteration 18884: loss: 0.079893, loss_s1: 0.070951, loss_fp: 0.006730, loss_freq: 0.054878
[05:50:56.112] iteration 18885: loss: 0.081791, loss_s1: 0.069675, loss_fp: 0.007624, loss_freq: 0.050191
[05:50:56.726] iteration 18886: loss: 0.073169, loss_s1: 0.063813, loss_fp: 0.006858, loss_freq: 0.040648
[05:50:57.359] iteration 18887: loss: 0.137683, loss_s1: 0.083084, loss_fp: 0.010806, loss_freq: 0.149786
[05:50:57.996] iteration 18888: loss: 0.085655, loss_s1: 0.020935, loss_fp: 0.001144, loss_freq: 0.011153
[05:50:58.602] iteration 18889: loss: 0.080716, loss_s1: 0.078139, loss_fp: 0.004628, loss_freq: 0.047769
[05:50:59.219] iteration 18890: loss: 0.051692, loss_s1: 0.042988, loss_fp: 0.001468, loss_freq: 0.015804
[05:50:59.840] iteration 18891: loss: 0.065333, loss_s1: 0.048231, loss_fp: 0.005309, loss_freq: 0.046365
[05:51:00.501] iteration 18892: loss: 0.056161, loss_s1: 0.048912, loss_fp: 0.002438, loss_freq: 0.036319
[05:51:01.128] iteration 18893: loss: 0.055863, loss_s1: 0.038590, loss_fp: 0.001839, loss_freq: 0.031684
[05:51:01.739] iteration 18894: loss: 0.051342, loss_s1: 0.029634, loss_fp: 0.003630, loss_freq: 0.026174
[05:51:02.349] iteration 18895: loss: 0.054682, loss_s1: 0.032962, loss_fp: 0.005378, loss_freq: 0.033316
[05:51:02.963] iteration 18896: loss: 0.077996, loss_s1: 0.072756, loss_fp: 0.001812, loss_freq: 0.041025
[05:51:03.574] iteration 18897: loss: 0.052081, loss_s1: 0.040727, loss_fp: 0.009163, loss_freq: 0.021094
[05:51:04.181] iteration 18898: loss: 0.074719, loss_s1: 0.054270, loss_fp: 0.002174, loss_freq: 0.049687
[05:51:04.786] iteration 18899: loss: 0.085142, loss_s1: 0.016892, loss_fp: 0.006289, loss_freq: 0.018432
[05:51:05.392] iteration 18900: loss: 0.134731, loss_s1: 0.162038, loss_fp: 0.003210, loss_freq: 0.065930
[05:51:05.994] iteration 18901: loss: 0.099515, loss_s1: 0.108467, loss_fp: 0.006701, loss_freq: 0.059365
[05:51:06.703] iteration 18902: loss: 0.070874, loss_s1: 0.054673, loss_fp: 0.003804, loss_freq: 0.041469
[05:51:07.371] iteration 18903: loss: 0.056569, loss_s1: 0.054816, loss_fp: 0.002689, loss_freq: 0.026816
[05:51:08.034] iteration 18904: loss: 0.051723, loss_s1: 0.034855, loss_fp: 0.006694, loss_freq: 0.018581
[05:51:08.693] iteration 18905: loss: 0.047723, loss_s1: 0.032163, loss_fp: 0.001412, loss_freq: 0.033313
[05:51:09.353] iteration 18906: loss: 0.061480, loss_s1: 0.031076, loss_fp: 0.005568, loss_freq: 0.013242
[05:51:10.016] iteration 18907: loss: 0.072012, loss_s1: 0.065473, loss_fp: 0.006241, loss_freq: 0.033085
[05:51:10.627] iteration 18908: loss: 0.096494, loss_s1: 0.106765, loss_fp: 0.004785, loss_freq: 0.052400
[05:51:11.239] iteration 18909: loss: 0.096836, loss_s1: 0.103101, loss_fp: 0.001581, loss_freq: 0.047784
[05:51:11.871] iteration 18910: loss: 0.064722, loss_s1: 0.061247, loss_fp: 0.003131, loss_freq: 0.031275
[05:51:12.476] iteration 18911: loss: 0.044719, loss_s1: 0.038242, loss_fp: 0.003106, loss_freq: 0.010319
[05:51:13.093] iteration 18912: loss: 0.080863, loss_s1: 0.093466, loss_fp: 0.005577, loss_freq: 0.028913
[05:51:13.701] iteration 18913: loss: 0.070691, loss_s1: 0.051807, loss_fp: 0.012618, loss_freq: 0.035644
[05:51:14.307] iteration 18914: loss: 0.099705, loss_s1: 0.114670, loss_fp: 0.007628, loss_freq: 0.041396
[05:51:14.911] iteration 18915: loss: 0.069002, loss_s1: 0.047677, loss_fp: 0.001792, loss_freq: 0.023612
[05:51:15.521] iteration 18916: loss: 0.074581, loss_s1: 0.056932, loss_fp: 0.009096, loss_freq: 0.033112
[05:51:16.128] iteration 18917: loss: 0.060709, loss_s1: 0.045862, loss_fp: 0.001540, loss_freq: 0.033087
[05:51:16.739] iteration 18918: loss: 0.055755, loss_s1: 0.039780, loss_fp: 0.002486, loss_freq: 0.032856
[05:51:17.348] iteration 18919: loss: 0.031281, loss_s1: 0.020356, loss_fp: 0.001665, loss_freq: 0.008600
[05:51:17.957] iteration 18920: loss: 0.032260, loss_s1: 0.016584, loss_fp: 0.001350, loss_freq: 0.013878
[05:51:18.562] iteration 18921: loss: 0.047892, loss_s1: 0.020925, loss_fp: 0.001063, loss_freq: 0.025505
[05:51:19.170] iteration 18922: loss: 0.062074, loss_s1: 0.049089, loss_fp: 0.005313, loss_freq: 0.037824
[05:51:19.791] iteration 18923: loss: 0.045855, loss_s1: 0.022866, loss_fp: 0.001828, loss_freq: 0.035155
[05:51:20.402] iteration 18924: loss: 0.081718, loss_s1: 0.056284, loss_fp: 0.002698, loss_freq: 0.068227
[05:51:21.068] iteration 18925: loss: 0.063644, loss_s1: 0.053783, loss_fp: 0.012953, loss_freq: 0.014143
[05:51:21.735] iteration 18926: loss: 0.044444, loss_s1: 0.035607, loss_fp: 0.002029, loss_freq: 0.017785
[05:51:22.405] iteration 18927: loss: 0.060328, loss_s1: 0.043047, loss_fp: 0.003777, loss_freq: 0.050170
[05:51:23.074] iteration 18928: loss: 0.052496, loss_s1: 0.035585, loss_fp: 0.001961, loss_freq: 0.024843
[05:51:23.746] iteration 18929: loss: 0.053995, loss_s1: 0.037697, loss_fp: 0.006134, loss_freq: 0.033072
[05:51:24.399] iteration 18930: loss: 0.075314, loss_s1: 0.053243, loss_fp: 0.002650, loss_freq: 0.052961
[05:51:25.047] iteration 18931: loss: 0.026458, loss_s1: 0.013716, loss_fp: 0.001836, loss_freq: 0.006568
[05:51:25.696] iteration 18932: loss: 0.091178, loss_s1: 0.066327, loss_fp: 0.001487, loss_freq: 0.036243
[05:51:26.309] iteration 18933: loss: 0.050669, loss_s1: 0.049529, loss_fp: 0.001893, loss_freq: 0.008276
[05:51:26.926] iteration 18934: loss: 0.039736, loss_s1: 0.021872, loss_fp: 0.001256, loss_freq: 0.023007
[05:51:27.544] iteration 18935: loss: 0.056871, loss_s1: 0.055933, loss_fp: 0.002330, loss_freq: 0.016168
[05:51:28.154] iteration 18936: loss: 0.041364, loss_s1: 0.031703, loss_fp: 0.002155, loss_freq: 0.022926
[05:51:28.767] iteration 18937: loss: 0.045156, loss_s1: 0.015708, loss_fp: 0.002809, loss_freq: 0.024808
[05:51:29.378] iteration 18938: loss: 0.131660, loss_s1: 0.146788, loss_fp: 0.012917, loss_freq: 0.051780
[05:51:30.060] iteration 18939: loss: 0.048211, loss_s1: 0.031118, loss_fp: 0.004225, loss_freq: 0.031178
[05:51:30.795] iteration 18940: loss: 0.042619, loss_s1: 0.028412, loss_fp: 0.004421, loss_freq: 0.024250
[05:51:31.579] iteration 18941: loss: 0.083683, loss_s1: 0.042452, loss_fp: 0.003185, loss_freq: 0.035215
[05:51:32.263] iteration 18942: loss: 0.063154, loss_s1: 0.052267, loss_fp: 0.005599, loss_freq: 0.033302
[05:51:33.014] iteration 18943: loss: 0.055691, loss_s1: 0.046118, loss_fp: 0.007915, loss_freq: 0.032352
[05:51:33.774] iteration 18944: loss: 0.082332, loss_s1: 0.094005, loss_fp: 0.003384, loss_freq: 0.029820
[05:51:34.407] iteration 18945: loss: 0.066976, loss_s1: 0.050927, loss_fp: 0.003261, loss_freq: 0.045727
[05:51:35.127] iteration 18946: loss: 0.077836, loss_s1: 0.090412, loss_fp: 0.003232, loss_freq: 0.021678
[05:51:35.747] iteration 18947: loss: 0.062744, loss_s1: 0.057087, loss_fp: 0.005286, loss_freq: 0.031763
[05:51:36.407] iteration 18948: loss: 0.089672, loss_s1: 0.094405, loss_fp: 0.004668, loss_freq: 0.055080
[05:51:37.042] iteration 18949: loss: 0.063488, loss_s1: 0.055095, loss_fp: 0.003233, loss_freq: 0.043387
[05:51:37.791] iteration 18950: loss: 0.069410, loss_s1: 0.060416, loss_fp: 0.004492, loss_freq: 0.022471
[05:51:38.477] iteration 18951: loss: 0.100567, loss_s1: 0.066802, loss_fp: 0.005676, loss_freq: 0.031122
[05:51:39.185] iteration 18952: loss: 0.067582, loss_s1: 0.024544, loss_fp: 0.010953, loss_freq: 0.066284
[05:51:39.899] iteration 18953: loss: 0.051338, loss_s1: 0.039748, loss_fp: 0.005470, loss_freq: 0.021145
[05:51:40.536] iteration 18954: loss: 0.050280, loss_s1: 0.044925, loss_fp: 0.002044, loss_freq: 0.022801
[05:51:41.174] iteration 18955: loss: 0.095195, loss_s1: 0.094829, loss_fp: 0.010578, loss_freq: 0.040697
[05:51:41.828] iteration 18956: loss: 0.050025, loss_s1: 0.042609, loss_fp: 0.001776, loss_freq: 0.014648
[05:51:42.458] iteration 18957: loss: 0.075395, loss_s1: 0.084103, loss_fp: 0.001007, loss_freq: 0.039387
[05:51:43.084] iteration 18958: loss: 0.088030, loss_s1: 0.102316, loss_fp: 0.008344, loss_freq: 0.032647
[05:51:43.707] iteration 18959: loss: 0.050153, loss_s1: 0.042980, loss_fp: 0.009703, loss_freq: 0.013551
[05:51:44.332] iteration 18960: loss: 0.046877, loss_s1: 0.018017, loss_fp: 0.001689, loss_freq: 0.023773
[05:51:44.955] iteration 18961: loss: 0.083609, loss_s1: 0.096158, loss_fp: 0.004144, loss_freq: 0.032095
[05:51:45.563] iteration 18962: loss: 0.054816, loss_s1: 0.026542, loss_fp: 0.001373, loss_freq: 0.054996
[05:51:46.216] iteration 18963: loss: 0.069912, loss_s1: 0.070114, loss_fp: 0.004617, loss_freq: 0.022350
[05:51:46.840] iteration 18964: loss: 0.064414, loss_s1: 0.052542, loss_fp: 0.006003, loss_freq: 0.037363
[05:51:47.466] iteration 18965: loss: 0.070144, loss_s1: 0.049845, loss_fp: 0.003166, loss_freq: 0.042311
[05:51:48.089] iteration 18966: loss: 0.058188, loss_s1: 0.051399, loss_fp: 0.001481, loss_freq: 0.041914
[05:51:48.729] iteration 18967: loss: 0.058714, loss_s1: 0.027281, loss_fp: 0.003274, loss_freq: 0.046247
[05:51:49.498] iteration 18968: loss: 0.084620, loss_s1: 0.109862, loss_fp: 0.001730, loss_freq: 0.023709
[05:51:50.275] iteration 18969: loss: 0.073737, loss_s1: 0.063742, loss_fp: 0.004094, loss_freq: 0.047565
[05:51:51.243] iteration 18970: loss: 0.038582, loss_s1: 0.022477, loss_fp: 0.001301, loss_freq: 0.012465
[05:51:51.888] iteration 18971: loss: 0.072337, loss_s1: 0.072728, loss_fp: 0.011020, loss_freq: 0.035233
[05:51:52.587] iteration 18972: loss: 0.049470, loss_s1: 0.028561, loss_fp: 0.004066, loss_freq: 0.021496
[05:51:53.205] iteration 18973: loss: 0.058131, loss_s1: 0.023118, loss_fp: 0.002745, loss_freq: 0.023505
[05:51:53.819] iteration 18974: loss: 0.033817, loss_s1: 0.024159, loss_fp: 0.001464, loss_freq: 0.014683
[05:51:54.430] iteration 18975: loss: 0.031434, loss_s1: 0.017336, loss_fp: 0.004362, loss_freq: 0.015974
[05:51:55.039] iteration 18976: loss: 0.074361, loss_s1: 0.069375, loss_fp: 0.002728, loss_freq: 0.035496
[05:51:55.652] iteration 18977: loss: 0.055903, loss_s1: 0.045568, loss_fp: 0.003437, loss_freq: 0.020494
[05:51:56.260] iteration 18978: loss: 0.043081, loss_s1: 0.025972, loss_fp: 0.001578, loss_freq: 0.030757
[05:51:56.870] iteration 18979: loss: 0.062597, loss_s1: 0.042823, loss_fp: 0.008742, loss_freq: 0.039968
[05:51:57.484] iteration 18980: loss: 0.065975, loss_s1: 0.083646, loss_fp: 0.003628, loss_freq: 0.011525
[05:51:58.093] iteration 18981: loss: 0.061333, loss_s1: 0.042204, loss_fp: 0.007290, loss_freq: 0.018404
[05:51:58.701] iteration 18982: loss: 0.045755, loss_s1: 0.022112, loss_fp: 0.004150, loss_freq: 0.026404
[05:51:59.312] iteration 18983: loss: 0.042810, loss_s1: 0.030929, loss_fp: 0.002329, loss_freq: 0.020859
[05:51:59.923] iteration 18984: loss: 0.047801, loss_s1: 0.038611, loss_fp: 0.009341, loss_freq: 0.024264
[05:52:00.531] iteration 18985: loss: 0.062237, loss_s1: 0.049182, loss_fp: 0.005388, loss_freq: 0.026283
[05:52:01.140] iteration 18986: loss: 0.058948, loss_s1: 0.033975, loss_fp: 0.007410, loss_freq: 0.045431
[05:52:01.749] iteration 18987: loss: 0.040152, loss_s1: 0.021721, loss_fp: 0.004362, loss_freq: 0.018287
[05:52:02.390] iteration 18988: loss: 0.064029, loss_s1: 0.032532, loss_fp: 0.007197, loss_freq: 0.054284
[05:52:03.014] iteration 18989: loss: 0.079880, loss_s1: 0.056377, loss_fp: 0.004460, loss_freq: 0.069287
[05:52:03.623] iteration 18990: loss: 0.044414, loss_s1: 0.019036, loss_fp: 0.001902, loss_freq: 0.015455
[05:52:04.237] iteration 18991: loss: 0.048702, loss_s1: 0.052019, loss_fp: 0.001057, loss_freq: 0.012268
[05:52:04.855] iteration 18992: loss: 0.064257, loss_s1: 0.071273, loss_fp: 0.004206, loss_freq: 0.031872
[05:52:05.466] iteration 18993: loss: 0.096314, loss_s1: 0.090355, loss_fp: 0.006973, loss_freq: 0.064864
[05:52:06.082] iteration 18994: loss: 0.046569, loss_s1: 0.035540, loss_fp: 0.001959, loss_freq: 0.021780
[05:52:06.694] iteration 18995: loss: 0.059355, loss_s1: 0.033931, loss_fp: 0.027504, loss_freq: 0.020682
[05:52:07.303] iteration 18996: loss: 0.054868, loss_s1: 0.041511, loss_fp: 0.004318, loss_freq: 0.027527
[05:52:07.914] iteration 18997: loss: 0.049386, loss_s1: 0.017130, loss_fp: 0.002390, loss_freq: 0.054885
[05:52:08.525] iteration 18998: loss: 0.056371, loss_s1: 0.017561, loss_fp: 0.030211, loss_freq: 0.004942
[05:52:09.137] iteration 18999: loss: 0.074855, loss_s1: 0.076102, loss_fp: 0.005162, loss_freq: 0.033467
[05:52:09.785] iteration 19000: loss: 0.047468, loss_s1: 0.026001, loss_fp: 0.004096, loss_freq: 0.034228
[05:52:13.284] iteration 19000 : mean_dice : 0.732230
[05:52:13.956] iteration 19001: loss: 0.052682, loss_s1: 0.044227, loss_fp: 0.002733, loss_freq: 0.028702
[05:52:14.571] iteration 19002: loss: 0.099742, loss_s1: 0.035208, loss_fp: 0.006367, loss_freq: 0.035153
[05:52:15.185] iteration 19003: loss: 0.052586, loss_s1: 0.023034, loss_fp: 0.015234, loss_freq: 0.032324
[05:52:15.795] iteration 19004: loss: 0.068953, loss_s1: 0.063846, loss_fp: 0.001704, loss_freq: 0.037780
[05:52:16.416] iteration 19005: loss: 0.074866, loss_s1: 0.060833, loss_fp: 0.004138, loss_freq: 0.034368
[05:52:17.031] iteration 19006: loss: 0.041617, loss_s1: 0.038795, loss_fp: 0.002045, loss_freq: 0.013540
[05:52:17.644] iteration 19007: loss: 0.064941, loss_s1: 0.069439, loss_fp: 0.002142, loss_freq: 0.016862
[05:52:18.254] iteration 19008: loss: 0.062661, loss_s1: 0.050800, loss_fp: 0.003243, loss_freq: 0.039218
[05:52:18.869] iteration 19009: loss: 0.100247, loss_s1: 0.085065, loss_fp: 0.014930, loss_freq: 0.071396
[05:52:19.491] iteration 19010: loss: 0.055508, loss_s1: 0.045720, loss_fp: 0.002777, loss_freq: 0.032603
[05:52:20.104] iteration 19011: loss: 0.047862, loss_s1: 0.041846, loss_fp: 0.002591, loss_freq: 0.014596
[05:52:20.717] iteration 19012: loss: 0.056005, loss_s1: 0.052729, loss_fp: 0.003863, loss_freq: 0.020217
[05:52:21.328] iteration 19013: loss: 0.045487, loss_s1: 0.034411, loss_fp: 0.004337, loss_freq: 0.019433
[05:52:21.944] iteration 19014: loss: 0.060202, loss_s1: 0.068831, loss_fp: 0.005459, loss_freq: 0.012438
[05:52:22.569] iteration 19015: loss: 0.053990, loss_s1: 0.031380, loss_fp: 0.002324, loss_freq: 0.022096
[05:52:23.191] iteration 19016: loss: 0.064114, loss_s1: 0.073263, loss_fp: 0.005603, loss_freq: 0.011506
[05:52:23.813] iteration 19017: loss: 0.057408, loss_s1: 0.037031, loss_fp: 0.002915, loss_freq: 0.037319
[05:52:24.426] iteration 19018: loss: 0.058657, loss_s1: 0.055945, loss_fp: 0.004589, loss_freq: 0.030942
[05:52:25.040] iteration 19019: loss: 0.081199, loss_s1: 0.061707, loss_fp: 0.006520, loss_freq: 0.045990
[05:52:25.652] iteration 19020: loss: 0.067849, loss_s1: 0.059978, loss_fp: 0.003487, loss_freq: 0.020540
[05:52:26.264] iteration 19021: loss: 0.057883, loss_s1: 0.043488, loss_fp: 0.005147, loss_freq: 0.028994
[05:52:26.871] iteration 19022: loss: 0.088432, loss_s1: 0.087930, loss_fp: 0.005333, loss_freq: 0.046261
[05:52:27.479] iteration 19023: loss: 0.081806, loss_s1: 0.080865, loss_fp: 0.002523, loss_freq: 0.049576
[05:52:28.093] iteration 19024: loss: 0.070137, loss_s1: 0.044074, loss_fp: 0.002574, loss_freq: 0.059617
[05:52:28.703] iteration 19025: loss: 0.082506, loss_s1: 0.087993, loss_fp: 0.001481, loss_freq: 0.028333
[05:52:29.317] iteration 19026: loss: 0.041039, loss_s1: 0.021635, loss_fp: 0.002017, loss_freq: 0.015623
[05:52:29.934] iteration 19027: loss: 0.054426, loss_s1: 0.053415, loss_fp: 0.009453, loss_freq: 0.017517
[05:52:30.547] iteration 19028: loss: 0.097932, loss_s1: 0.080622, loss_fp: 0.000528, loss_freq: 0.079793
[05:52:31.160] iteration 19029: loss: 0.057425, loss_s1: 0.043715, loss_fp: 0.002513, loss_freq: 0.035887
[05:52:31.775] iteration 19030: loss: 0.066579, loss_s1: 0.055806, loss_fp: 0.009388, loss_freq: 0.031666
[05:52:32.390] iteration 19031: loss: 0.051210, loss_s1: 0.049713, loss_fp: 0.001378, loss_freq: 0.012231
[05:52:33.007] iteration 19032: loss: 0.042801, loss_s1: 0.031539, loss_fp: 0.003150, loss_freq: 0.027626
[05:52:33.618] iteration 19033: loss: 0.038883, loss_s1: 0.015069, loss_fp: 0.005046, loss_freq: 0.018827
[05:52:34.236] iteration 19034: loss: 0.059710, loss_s1: 0.065602, loss_fp: 0.001170, loss_freq: 0.026084
[05:52:34.846] iteration 19035: loss: 0.038213, loss_s1: 0.021987, loss_fp: 0.001379, loss_freq: 0.016412
[05:52:35.452] iteration 19036: loss: 0.046178, loss_s1: 0.022564, loss_fp: 0.006742, loss_freq: 0.027133
[05:52:36.062] iteration 19037: loss: 0.056727, loss_s1: 0.055188, loss_fp: 0.005565, loss_freq: 0.016635
[05:52:36.674] iteration 19038: loss: 0.076860, loss_s1: 0.052205, loss_fp: 0.006930, loss_freq: 0.053764
[05:52:37.281] iteration 19039: loss: 0.115818, loss_s1: 0.121161, loss_fp: 0.002853, loss_freq: 0.077398
[05:52:37.885] iteration 19040: loss: 0.050903, loss_s1: 0.030662, loss_fp: 0.003896, loss_freq: 0.030385
[05:52:38.864] iteration 19041: loss: 0.073318, loss_s1: 0.050721, loss_fp: 0.005338, loss_freq: 0.046129
[05:52:39.516] iteration 19042: loss: 0.046347, loss_s1: 0.037581, loss_fp: 0.002368, loss_freq: 0.017147
[05:52:40.126] iteration 19043: loss: 0.043632, loss_s1: 0.031201, loss_fp: 0.001909, loss_freq: 0.025810
[05:52:40.739] iteration 19044: loss: 0.047982, loss_s1: 0.024411, loss_fp: 0.001532, loss_freq: 0.016481
[05:52:41.357] iteration 19045: loss: 0.080448, loss_s1: 0.072293, loss_fp: 0.005072, loss_freq: 0.050944
[05:52:41.984] iteration 19046: loss: 0.069512, loss_s1: 0.056841, loss_fp: 0.004991, loss_freq: 0.033513
[05:52:42.604] iteration 19047: loss: 0.092593, loss_s1: 0.100894, loss_fp: 0.004291, loss_freq: 0.036012
[05:52:43.217] iteration 19048: loss: 0.045180, loss_s1: 0.027635, loss_fp: 0.009745, loss_freq: 0.024550
[05:52:43.831] iteration 19049: loss: 0.065757, loss_s1: 0.048366, loss_fp: 0.004853, loss_freq: 0.044990
[05:52:44.443] iteration 19050: loss: 0.089874, loss_s1: 0.114771, loss_fp: 0.005753, loss_freq: 0.018545
[05:52:45.056] iteration 19051: loss: 0.120594, loss_s1: 0.082097, loss_fp: 0.003717, loss_freq: 0.064593
[05:52:45.666] iteration 19052: loss: 0.075982, loss_s1: 0.052888, loss_fp: 0.006451, loss_freq: 0.053246
[05:52:46.273] iteration 19053: loss: 0.071717, loss_s1: 0.071250, loss_fp: 0.002736, loss_freq: 0.026193
[05:52:46.887] iteration 19054: loss: 0.064791, loss_s1: 0.051397, loss_fp: 0.009872, loss_freq: 0.035338
[05:52:47.523] iteration 19055: loss: 0.050310, loss_s1: 0.021703, loss_fp: 0.004158, loss_freq: 0.023375
[05:52:48.165] iteration 19056: loss: 0.053040, loss_s1: 0.052188, loss_fp: 0.002029, loss_freq: 0.016688
[05:52:48.770] iteration 19057: loss: 0.074784, loss_s1: 0.052789, loss_fp: 0.001410, loss_freq: 0.069613
[05:52:49.384] iteration 19058: loss: 0.053031, loss_s1: 0.052361, loss_fp: 0.002240, loss_freq: 0.011745
[05:52:49.998] iteration 19059: loss: 0.099614, loss_s1: 0.111390, loss_fp: 0.006407, loss_freq: 0.052194
[05:52:50.611] iteration 19060: loss: 0.033417, loss_s1: 0.020075, loss_fp: 0.001835, loss_freq: 0.009010
[05:52:51.227] iteration 19061: loss: 0.048425, loss_s1: 0.017340, loss_fp: 0.002890, loss_freq: 0.036632
[05:52:51.845] iteration 19062: loss: 0.062057, loss_s1: 0.050765, loss_fp: 0.004497, loss_freq: 0.039094
[05:52:52.456] iteration 19063: loss: 0.049466, loss_s1: 0.034017, loss_fp: 0.005210, loss_freq: 0.020211
[05:52:53.072] iteration 19064: loss: 0.077946, loss_s1: 0.078886, loss_fp: 0.002194, loss_freq: 0.041997
[05:52:53.683] iteration 19065: loss: 0.079873, loss_s1: 0.076273, loss_fp: 0.004276, loss_freq: 0.025665
[05:52:54.301] iteration 19066: loss: 0.056829, loss_s1: 0.033419, loss_fp: 0.005275, loss_freq: 0.048211
[05:52:54.904] iteration 19067: loss: 0.065337, loss_s1: 0.070425, loss_fp: 0.002140, loss_freq: 0.019953
[05:52:55.519] iteration 19068: loss: 0.096888, loss_s1: 0.126040, loss_fp: 0.001816, loss_freq: 0.016810
[05:52:56.179] iteration 19069: loss: 0.062468, loss_s1: 0.067264, loss_fp: 0.002451, loss_freq: 0.018759
[05:52:56.794] iteration 19070: loss: 0.081625, loss_s1: 0.068273, loss_fp: 0.005052, loss_freq: 0.054154
[05:52:57.410] iteration 19071: loss: 0.066683, loss_s1: 0.029625, loss_fp: 0.006411, loss_freq: 0.062166
[05:52:58.013] iteration 19072: loss: 0.096258, loss_s1: 0.085576, loss_fp: 0.003282, loss_freq: 0.057463
[05:52:58.620] iteration 19073: loss: 0.079427, loss_s1: 0.058439, loss_fp: 0.005392, loss_freq: 0.059359
[05:52:59.231] iteration 19074: loss: 0.039460, loss_s1: 0.042666, loss_fp: 0.003174, loss_freq: 0.005732
[05:52:59.884] iteration 19075: loss: 0.062517, loss_s1: 0.072767, loss_fp: 0.008048, loss_freq: 0.016155
[05:53:00.541] iteration 19076: loss: 0.070978, loss_s1: 0.089759, loss_fp: 0.003722, loss_freq: 0.005657
[05:53:01.204] iteration 19077: loss: 0.053945, loss_s1: 0.032979, loss_fp: 0.002115, loss_freq: 0.037771
[05:53:01.819] iteration 19078: loss: 0.035435, loss_s1: 0.023341, loss_fp: 0.005515, loss_freq: 0.010303
[05:53:02.431] iteration 19079: loss: 0.056043, loss_s1: 0.050133, loss_fp: 0.005626, loss_freq: 0.018059
[05:53:03.046] iteration 19080: loss: 0.063402, loss_s1: 0.063095, loss_fp: 0.004763, loss_freq: 0.033856
[05:53:03.660] iteration 19081: loss: 0.089453, loss_s1: 0.057608, loss_fp: 0.003614, loss_freq: 0.075454
[05:53:04.270] iteration 19082: loss: 0.043986, loss_s1: 0.025034, loss_fp: 0.003675, loss_freq: 0.021006
[05:53:04.884] iteration 19083: loss: 0.122955, loss_s1: 0.124289, loss_fp: 0.006171, loss_freq: 0.091223
[05:53:05.501] iteration 19084: loss: 0.081939, loss_s1: 0.082846, loss_fp: 0.003796, loss_freq: 0.048958
[05:53:06.121] iteration 19085: loss: 0.059383, loss_s1: 0.039076, loss_fp: 0.010262, loss_freq: 0.018568
[05:53:06.733] iteration 19086: loss: 0.074562, loss_s1: 0.080071, loss_fp: 0.001847, loss_freq: 0.033991
[05:53:07.367] iteration 19087: loss: 0.066249, loss_s1: 0.076744, loss_fp: 0.003364, loss_freq: 0.017241
[05:53:07.975] iteration 19088: loss: 0.044176, loss_s1: 0.014627, loss_fp: 0.002613, loss_freq: 0.038591
[05:53:08.589] iteration 19089: loss: 0.063262, loss_s1: 0.043535, loss_fp: 0.001285, loss_freq: 0.009783
[05:53:09.202] iteration 19090: loss: 0.050440, loss_s1: 0.053126, loss_fp: 0.001502, loss_freq: 0.009125
[05:53:09.818] iteration 19091: loss: 0.041520, loss_s1: 0.011580, loss_fp: 0.002686, loss_freq: 0.016615
[05:53:10.430] iteration 19092: loss: 0.071976, loss_s1: 0.074466, loss_fp: 0.004549, loss_freq: 0.037654
[05:53:11.040] iteration 19093: loss: 0.047362, loss_s1: 0.022057, loss_fp: 0.002933, loss_freq: 0.018389
[05:53:11.650] iteration 19094: loss: 0.074682, loss_s1: 0.087200, loss_fp: 0.001341, loss_freq: 0.031127
[05:53:12.263] iteration 19095: loss: 0.068201, loss_s1: 0.050001, loss_fp: 0.006558, loss_freq: 0.041805
[05:53:12.874] iteration 19096: loss: 0.036176, loss_s1: 0.020663, loss_fp: 0.002606, loss_freq: 0.016173
[05:53:13.485] iteration 19097: loss: 0.054943, loss_s1: 0.045431, loss_fp: 0.001642, loss_freq: 0.042853
[05:53:14.094] iteration 19098: loss: 0.071588, loss_s1: 0.034051, loss_fp: 0.004319, loss_freq: 0.040191
[05:53:14.697] iteration 19099: loss: 0.040358, loss_s1: 0.024850, loss_fp: 0.001946, loss_freq: 0.021850
[05:53:15.299] iteration 19100: loss: 0.087098, loss_s1: 0.075059, loss_fp: 0.004074, loss_freq: 0.066798
[05:53:15.910] iteration 19101: loss: 0.041590, loss_s1: 0.033538, loss_fp: 0.003994, loss_freq: 0.017335
[05:53:16.529] iteration 19102: loss: 0.052405, loss_s1: 0.021014, loss_fp: 0.004726, loss_freq: 0.042816
[05:53:17.141] iteration 19103: loss: 0.055640, loss_s1: 0.050165, loss_fp: 0.002576, loss_freq: 0.018396
[05:53:17.741] iteration 19104: loss: 0.041732, loss_s1: 0.040266, loss_fp: 0.004154, loss_freq: 0.008516
[05:53:18.347] iteration 19105: loss: 0.094061, loss_s1: 0.116804, loss_fp: 0.001778, loss_freq: 0.022749
[05:53:18.951] iteration 19106: loss: 0.042124, loss_s1: 0.032422, loss_fp: 0.001229, loss_freq: 0.022948
[05:53:19.560] iteration 19107: loss: 0.047495, loss_s1: 0.026273, loss_fp: 0.001377, loss_freq: 0.022322
[05:53:20.168] iteration 19108: loss: 0.108608, loss_s1: 0.115812, loss_fp: 0.009285, loss_freq: 0.045523
[05:53:20.777] iteration 19109: loss: 0.059342, loss_s1: 0.032732, loss_fp: 0.003173, loss_freq: 0.034369
[05:53:21.387] iteration 19110: loss: 0.071618, loss_s1: 0.047890, loss_fp: 0.005810, loss_freq: 0.066325
[05:53:22.000] iteration 19111: loss: 0.116368, loss_s1: 0.131025, loss_fp: 0.005139, loss_freq: 0.029337
[05:53:22.610] iteration 19112: loss: 0.047142, loss_s1: 0.012358, loss_fp: 0.004486, loss_freq: 0.040044
[05:53:23.226] iteration 19113: loss: 0.046468, loss_s1: 0.029121, loss_fp: 0.004509, loss_freq: 0.033525
[05:53:23.840] iteration 19114: loss: 0.064031, loss_s1: 0.060162, loss_fp: 0.003989, loss_freq: 0.026302
[05:53:24.614] iteration 19115: loss: 0.044482, loss_s1: 0.026853, loss_fp: 0.002858, loss_freq: 0.025091
[05:53:25.235] iteration 19116: loss: 0.077021, loss_s1: 0.060837, loss_fp: 0.004232, loss_freq: 0.049238
[05:53:25.878] iteration 19117: loss: 0.061786, loss_s1: 0.042213, loss_fp: 0.000761, loss_freq: 0.039603
[05:53:26.520] iteration 19118: loss: 0.066554, loss_s1: 0.054049, loss_fp: 0.005366, loss_freq: 0.039468
[05:53:27.273] iteration 19119: loss: 0.070514, loss_s1: 0.083212, loss_fp: 0.011739, loss_freq: 0.020407
[05:53:27.922] iteration 19120: loss: 0.060884, loss_s1: 0.046290, loss_fp: 0.005191, loss_freq: 0.013729
[05:53:28.573] iteration 19121: loss: 0.056021, loss_s1: 0.044274, loss_fp: 0.004556, loss_freq: 0.021651
[05:53:29.190] iteration 19122: loss: 0.050759, loss_s1: 0.035965, loss_fp: 0.002483, loss_freq: 0.024531
[05:53:29.815] iteration 19123: loss: 0.085736, loss_s1: 0.093728, loss_fp: 0.005111, loss_freq: 0.036523
[05:53:30.432] iteration 19124: loss: 0.045923, loss_s1: 0.029108, loss_fp: 0.002541, loss_freq: 0.015597
[05:53:31.047] iteration 19125: loss: 0.075010, loss_s1: 0.089083, loss_fp: 0.004776, loss_freq: 0.015441
[05:53:31.665] iteration 19126: loss: 0.067699, loss_s1: 0.048669, loss_fp: 0.008969, loss_freq: 0.040165
[05:53:32.280] iteration 19127: loss: 0.086071, loss_s1: 0.080048, loss_fp: 0.002233, loss_freq: 0.055967
[05:53:32.900] iteration 19128: loss: 0.077267, loss_s1: 0.075453, loss_fp: 0.001755, loss_freq: 0.020727
[05:53:33.531] iteration 19129: loss: 0.066917, loss_s1: 0.071109, loss_fp: 0.005486, loss_freq: 0.023673
[05:53:34.157] iteration 19130: loss: 0.039243, loss_s1: 0.031547, loss_fp: 0.002359, loss_freq: 0.009357
[05:53:34.796] iteration 19131: loss: 0.061177, loss_s1: 0.061387, loss_fp: 0.003837, loss_freq: 0.023213
[05:53:35.418] iteration 19132: loss: 0.066333, loss_s1: 0.044628, loss_fp: 0.004585, loss_freq: 0.050895
[05:53:36.028] iteration 19133: loss: 0.081628, loss_s1: 0.052345, loss_fp: 0.007693, loss_freq: 0.050787
[05:53:36.643] iteration 19134: loss: 0.041384, loss_s1: 0.023824, loss_fp: 0.003244, loss_freq: 0.021364
[05:53:37.256] iteration 19135: loss: 0.057123, loss_s1: 0.040789, loss_fp: 0.005057, loss_freq: 0.034218
[05:53:37.859] iteration 19136: loss: 0.067099, loss_s1: 0.068603, loss_fp: 0.001792, loss_freq: 0.033264
[05:53:38.464] iteration 19137: loss: 0.087309, loss_s1: 0.107213, loss_fp: 0.002973, loss_freq: 0.023515
[05:53:39.071] iteration 19138: loss: 0.072438, loss_s1: 0.050253, loss_fp: 0.001871, loss_freq: 0.049521
[05:53:39.683] iteration 19139: loss: 0.070997, loss_s1: 0.083567, loss_fp: 0.003893, loss_freq: 0.029281
[05:53:40.334] iteration 19140: loss: 0.053032, loss_s1: 0.041331, loss_fp: 0.004575, loss_freq: 0.021529
[05:53:40.995] iteration 19141: loss: 0.075548, loss_s1: 0.078745, loss_fp: 0.002207, loss_freq: 0.030581
[05:53:41.642] iteration 19142: loss: 0.050968, loss_s1: 0.041025, loss_fp: 0.002621, loss_freq: 0.019529
[05:53:42.251] iteration 19143: loss: 0.043415, loss_s1: 0.022599, loss_fp: 0.004007, loss_freq: 0.033893
[05:53:42.935] iteration 19144: loss: 0.032164, loss_s1: 0.019214, loss_fp: 0.003754, loss_freq: 0.012105
[05:53:43.564] iteration 19145: loss: 0.041419, loss_s1: 0.049164, loss_fp: 0.000941, loss_freq: 0.007987
[05:53:44.181] iteration 19146: loss: 0.071769, loss_s1: 0.077041, loss_fp: 0.006105, loss_freq: 0.020790
[05:53:44.787] iteration 19147: loss: 0.053301, loss_s1: 0.037617, loss_fp: 0.004950, loss_freq: 0.022205
[05:53:45.401] iteration 19148: loss: 0.056275, loss_s1: 0.040522, loss_fp: 0.001601, loss_freq: 0.038557
[05:53:46.016] iteration 19149: loss: 0.070074, loss_s1: 0.042630, loss_fp: 0.007874, loss_freq: 0.057489
[05:53:46.627] iteration 19150: loss: 0.060956, loss_s1: 0.030683, loss_fp: 0.010879, loss_freq: 0.050694
[05:53:47.240] iteration 19151: loss: 0.070759, loss_s1: 0.058833, loss_fp: 0.003855, loss_freq: 0.040483
[05:53:47.857] iteration 19152: loss: 0.056109, loss_s1: 0.047885, loss_fp: 0.003315, loss_freq: 0.024548
[05:53:48.508] iteration 19153: loss: 0.049523, loss_s1: 0.033743, loss_fp: 0.003753, loss_freq: 0.023594
[05:53:49.168] iteration 19154: loss: 0.023882, loss_s1: 0.011535, loss_fp: 0.001791, loss_freq: 0.011066
[05:53:49.824] iteration 19155: loss: 0.115840, loss_s1: 0.085335, loss_fp: 0.008863, loss_freq: 0.099658
[05:53:50.480] iteration 19156: loss: 0.083579, loss_s1: 0.058542, loss_fp: 0.017538, loss_freq: 0.043021
[05:53:51.135] iteration 19157: loss: 0.071959, loss_s1: 0.083547, loss_fp: 0.003922, loss_freq: 0.022613
[05:53:51.745] iteration 19158: loss: 0.045214, loss_s1: 0.049330, loss_fp: 0.003248, loss_freq: 0.011861
[05:53:52.356] iteration 19159: loss: 0.073298, loss_s1: 0.032593, loss_fp: 0.003147, loss_freq: 0.081424
[05:53:52.973] iteration 19160: loss: 0.084958, loss_s1: 0.090041, loss_fp: 0.000844, loss_freq: 0.034758
[05:53:53.583] iteration 19161: loss: 0.057914, loss_s1: 0.061172, loss_fp: 0.002301, loss_freq: 0.011778
[05:53:54.192] iteration 19162: loss: 0.077223, loss_s1: 0.087576, loss_fp: 0.002291, loss_freq: 0.037903
[05:53:54.831] iteration 19163: loss: 0.046082, loss_s1: 0.037836, loss_fp: 0.002707, loss_freq: 0.019067
[05:53:55.448] iteration 19164: loss: 0.048064, loss_s1: 0.030860, loss_fp: 0.005974, loss_freq: 0.016276
[05:53:56.067] iteration 19165: loss: 0.089387, loss_s1: 0.074767, loss_fp: 0.008380, loss_freq: 0.061240
[05:53:56.710] iteration 19166: loss: 0.061965, loss_s1: 0.051371, loss_fp: 0.002738, loss_freq: 0.023052
[05:53:57.369] iteration 19167: loss: 0.097607, loss_s1: 0.105655, loss_fp: 0.002742, loss_freq: 0.059954
[05:53:57.980] iteration 19168: loss: 0.055642, loss_s1: 0.033599, loss_fp: 0.003404, loss_freq: 0.027586
[05:53:58.603] iteration 19169: loss: 0.056918, loss_s1: 0.036898, loss_fp: 0.005814, loss_freq: 0.018372
[05:53:59.213] iteration 19170: loss: 0.052561, loss_s1: 0.051035, loss_fp: 0.008539, loss_freq: 0.016299
[05:53:59.826] iteration 19171: loss: 0.078285, loss_s1: 0.076510, loss_fp: 0.005402, loss_freq: 0.028715
[05:54:00.434] iteration 19172: loss: 0.056951, loss_s1: 0.054179, loss_fp: 0.003260, loss_freq: 0.022130
[05:54:01.051] iteration 19173: loss: 0.078225, loss_s1: 0.089043, loss_fp: 0.006842, loss_freq: 0.029538
[05:54:01.665] iteration 19174: loss: 0.041153, loss_s1: 0.032181, loss_fp: 0.003505, loss_freq: 0.021479
[05:54:02.286] iteration 19175: loss: 0.047905, loss_s1: 0.034634, loss_fp: 0.006318, loss_freq: 0.012600
[05:54:02.902] iteration 19176: loss: 0.028569, loss_s1: 0.024571, loss_fp: 0.002040, loss_freq: 0.006076
[05:54:03.518] iteration 19177: loss: 0.119522, loss_s1: 0.129173, loss_fp: 0.005333, loss_freq: 0.030361
[05:54:04.125] iteration 19178: loss: 0.055415, loss_s1: 0.044294, loss_fp: 0.003148, loss_freq: 0.031961
[05:54:04.736] iteration 19179: loss: 0.087022, loss_s1: 0.081554, loss_fp: 0.005611, loss_freq: 0.056985
[05:54:05.352] iteration 19180: loss: 0.049070, loss_s1: 0.047496, loss_fp: 0.001188, loss_freq: 0.019394
[05:54:05.957] iteration 19181: loss: 0.057436, loss_s1: 0.055420, loss_fp: 0.005681, loss_freq: 0.016300
[05:54:06.565] iteration 19182: loss: 0.051409, loss_s1: 0.028299, loss_fp: 0.002881, loss_freq: 0.040350
[05:54:07.180] iteration 19183: loss: 0.053620, loss_s1: 0.062379, loss_fp: 0.003679, loss_freq: 0.013701
[05:54:07.790] iteration 19184: loss: 0.043279, loss_s1: 0.035315, loss_fp: 0.005086, loss_freq: 0.010027
[05:54:08.402] iteration 19185: loss: 0.049396, loss_s1: 0.044360, loss_fp: 0.003054, loss_freq: 0.017034
[05:54:09.023] iteration 19186: loss: 0.047103, loss_s1: 0.028372, loss_fp: 0.004639, loss_freq: 0.027874
[05:54:09.631] iteration 19187: loss: 0.045342, loss_s1: 0.036235, loss_fp: 0.004452, loss_freq: 0.019059
[05:54:10.243] iteration 19188: loss: 0.081737, loss_s1: 0.101257, loss_fp: 0.004837, loss_freq: 0.029232
[05:54:10.852] iteration 19189: loss: 0.053415, loss_s1: 0.065716, loss_fp: 0.002835, loss_freq: 0.016826
[05:54:11.463] iteration 19190: loss: 0.046248, loss_s1: 0.046920, loss_fp: 0.001645, loss_freq: 0.011942
[05:54:12.078] iteration 19191: loss: 0.065752, loss_s1: 0.056407, loss_fp: 0.006588, loss_freq: 0.020577
[05:54:12.693] iteration 19192: loss: 0.084824, loss_s1: 0.087546, loss_fp: 0.003825, loss_freq: 0.047409
[05:54:13.308] iteration 19193: loss: 0.078169, loss_s1: 0.084905, loss_fp: 0.003891, loss_freq: 0.032698
[05:54:13.917] iteration 19194: loss: 0.083383, loss_s1: 0.072812, loss_fp: 0.004782, loss_freq: 0.053382
[05:54:14.614] iteration 19195: loss: 0.077702, loss_s1: 0.063459, loss_fp: 0.019406, loss_freq: 0.028021
[05:54:15.218] iteration 19196: loss: 0.042794, loss_s1: 0.043224, loss_fp: 0.001967, loss_freq: 0.010500
[05:54:15.822] iteration 19197: loss: 0.032756, loss_s1: 0.022492, loss_fp: 0.003038, loss_freq: 0.015286
[05:54:16.426] iteration 19198: loss: 0.127548, loss_s1: 0.138033, loss_fp: 0.006109, loss_freq: 0.074384
[05:54:17.032] iteration 19199: loss: 0.078044, loss_s1: 0.054770, loss_fp: 0.004425, loss_freq: 0.067198
[05:54:17.647] iteration 19200: loss: 0.075457, loss_s1: 0.068667, loss_fp: 0.010735, loss_freq: 0.035404
[05:54:21.235] iteration 19200 : mean_dice : 0.723872
[05:54:21.928] iteration 19201: loss: 0.038674, loss_s1: 0.035791, loss_fp: 0.003529, loss_freq: 0.007792
[05:54:22.558] iteration 19202: loss: 0.087361, loss_s1: 0.079205, loss_fp: 0.007403, loss_freq: 0.060714
[05:54:23.190] iteration 19203: loss: 0.033123, loss_s1: 0.017541, loss_fp: 0.000549, loss_freq: 0.008171
[05:54:23.805] iteration 19204: loss: 0.042292, loss_s1: 0.034160, loss_fp: 0.004212, loss_freq: 0.018214
[05:54:24.421] iteration 19205: loss: 0.032340, loss_s1: 0.016643, loss_fp: 0.001419, loss_freq: 0.014941
[05:54:25.032] iteration 19206: loss: 0.116791, loss_s1: 0.164018, loss_fp: 0.003602, loss_freq: 0.035825
[05:54:25.641] iteration 19207: loss: 0.066606, loss_s1: 0.045250, loss_fp: 0.001442, loss_freq: 0.040195
[05:54:26.251] iteration 19208: loss: 0.083866, loss_s1: 0.097904, loss_fp: 0.009263, loss_freq: 0.024763
[05:54:26.859] iteration 19209: loss: 0.075130, loss_s1: 0.065790, loss_fp: 0.004308, loss_freq: 0.050478
[05:54:27.467] iteration 19210: loss: 0.074990, loss_s1: 0.080202, loss_fp: 0.012118, loss_freq: 0.021225
[05:54:28.470] iteration 19211: loss: 0.075134, loss_s1: 0.070543, loss_fp: 0.006748, loss_freq: 0.040703
[05:54:29.134] iteration 19212: loss: 0.054271, loss_s1: 0.036324, loss_fp: 0.006498, loss_freq: 0.029428
[05:54:29.801] iteration 19213: loss: 0.057129, loss_s1: 0.058196, loss_fp: 0.006235, loss_freq: 0.017619
[05:54:30.468] iteration 19214: loss: 0.037406, loss_s1: 0.017158, loss_fp: 0.002007, loss_freq: 0.019998
[05:54:31.106] iteration 19215: loss: 0.045345, loss_s1: 0.018791, loss_fp: 0.005504, loss_freq: 0.036598
[05:54:31.721] iteration 19216: loss: 0.066812, loss_s1: 0.065622, loss_fp: 0.003049, loss_freq: 0.031798
[05:54:32.336] iteration 19217: loss: 0.062004, loss_s1: 0.066537, loss_fp: 0.004845, loss_freq: 0.016159
[05:54:32.950] iteration 19218: loss: 0.067641, loss_s1: 0.057774, loss_fp: 0.005257, loss_freq: 0.033675
[05:54:33.563] iteration 19219: loss: 0.061056, loss_s1: 0.056620, loss_fp: 0.003443, loss_freq: 0.023759
[05:54:34.171] iteration 19220: loss: 0.083918, loss_s1: 0.076255, loss_fp: 0.002812, loss_freq: 0.049772
[05:54:34.779] iteration 19221: loss: 0.069023, loss_s1: 0.055972, loss_fp: 0.003265, loss_freq: 0.037533
[05:54:35.384] iteration 19222: loss: 0.079684, loss_s1: 0.073339, loss_fp: 0.007826, loss_freq: 0.040851
[05:54:35.991] iteration 19223: loss: 0.053548, loss_s1: 0.034934, loss_fp: 0.002179, loss_freq: 0.040344
[05:54:36.596] iteration 19224: loss: 0.071650, loss_s1: 0.054495, loss_fp: 0.012545, loss_freq: 0.041337
[05:54:37.206] iteration 19225: loss: 0.079763, loss_s1: 0.090939, loss_fp: 0.003509, loss_freq: 0.026456
[05:54:37.823] iteration 19226: loss: 0.058131, loss_s1: 0.043156, loss_fp: 0.001545, loss_freq: 0.030376
[05:54:38.446] iteration 19227: loss: 0.107727, loss_s1: 0.079831, loss_fp: 0.002512, loss_freq: 0.111554
[05:54:39.054] iteration 19228: loss: 0.028814, loss_s1: 0.015883, loss_fp: 0.002281, loss_freq: 0.010226
[05:54:39.680] iteration 19229: loss: 0.100812, loss_s1: 0.093682, loss_fp: 0.006430, loss_freq: 0.064379
[05:54:40.313] iteration 19230: loss: 0.056346, loss_s1: 0.024476, loss_fp: 0.001492, loss_freq: 0.019655
[05:54:40.929] iteration 19231: loss: 0.062133, loss_s1: 0.061022, loss_fp: 0.002641, loss_freq: 0.025435
[05:54:41.602] iteration 19232: loss: 0.076281, loss_s1: 0.035643, loss_fp: 0.014759, loss_freq: 0.061724
[05:54:42.279] iteration 19233: loss: 0.072171, loss_s1: 0.056173, loss_fp: 0.005162, loss_freq: 0.042163
[05:54:42.960] iteration 19234: loss: 0.043544, loss_s1: 0.026922, loss_fp: 0.001448, loss_freq: 0.017177
[05:54:43.641] iteration 19235: loss: 0.077212, loss_s1: 0.095546, loss_fp: 0.001499, loss_freq: 0.024067
[05:54:44.261] iteration 19236: loss: 0.072773, loss_s1: 0.074681, loss_fp: 0.005695, loss_freq: 0.035569
[05:54:44.874] iteration 19237: loss: 0.080275, loss_s1: 0.065402, loss_fp: 0.004910, loss_freq: 0.053034
[05:54:45.484] iteration 19238: loss: 0.085656, loss_s1: 0.089516, loss_fp: 0.008113, loss_freq: 0.029260
[05:54:46.093] iteration 19239: loss: 0.073012, loss_s1: 0.054142, loss_fp: 0.002107, loss_freq: 0.021594
[05:54:46.702] iteration 19240: loss: 0.079519, loss_s1: 0.065724, loss_fp: 0.006422, loss_freq: 0.052686
[05:54:47.317] iteration 19241: loss: 0.059789, loss_s1: 0.036415, loss_fp: 0.004424, loss_freq: 0.048946
[05:54:47.930] iteration 19242: loss: 0.105656, loss_s1: 0.117545, loss_fp: 0.004181, loss_freq: 0.045696
[05:54:48.537] iteration 19243: loss: 0.077767, loss_s1: 0.062226, loss_fp: 0.002789, loss_freq: 0.059395
[05:54:49.149] iteration 19244: loss: 0.052145, loss_s1: 0.046258, loss_fp: 0.001486, loss_freq: 0.016044
[05:54:49.765] iteration 19245: loss: 0.046014, loss_s1: 0.047957, loss_fp: 0.001058, loss_freq: 0.023357
[05:54:50.387] iteration 19246: loss: 0.053633, loss_s1: 0.047437, loss_fp: 0.004462, loss_freq: 0.008606
[05:54:51.089] iteration 19247: loss: 0.082439, loss_s1: 0.078808, loss_fp: 0.001458, loss_freq: 0.048084
[05:54:51.703] iteration 19248: loss: 0.050906, loss_s1: 0.039920, loss_fp: 0.002569, loss_freq: 0.022550
[05:54:52.319] iteration 19249: loss: 0.103057, loss_s1: 0.133692, loss_fp: 0.002110, loss_freq: 0.037787
[05:54:52.932] iteration 19250: loss: 0.061483, loss_s1: 0.054780, loss_fp: 0.005308, loss_freq: 0.031413
[05:54:53.542] iteration 19251: loss: 0.106922, loss_s1: 0.104785, loss_fp: 0.004525, loss_freq: 0.058189
[05:54:54.149] iteration 19252: loss: 0.046943, loss_s1: 0.034974, loss_fp: 0.007017, loss_freq: 0.015917
[05:54:54.757] iteration 19253: loss: 0.118589, loss_s1: 0.126649, loss_fp: 0.006440, loss_freq: 0.071052
[05:54:55.366] iteration 19254: loss: 0.105130, loss_s1: 0.080278, loss_fp: 0.003476, loss_freq: 0.085534
[05:54:55.973] iteration 19255: loss: 0.068860, loss_s1: 0.056337, loss_fp: 0.001855, loss_freq: 0.040609
[05:54:56.579] iteration 19256: loss: 0.090727, loss_s1: 0.104503, loss_fp: 0.004095, loss_freq: 0.040661
[05:54:57.189] iteration 19257: loss: 0.052958, loss_s1: 0.048909, loss_fp: 0.003657, loss_freq: 0.021467
[05:54:57.802] iteration 19258: loss: 0.051870, loss_s1: 0.033447, loss_fp: 0.005743, loss_freq: 0.033841
[05:54:58.414] iteration 19259: loss: 0.045866, loss_s1: 0.042393, loss_fp: 0.001572, loss_freq: 0.012539
[05:54:59.032] iteration 19260: loss: 0.039206, loss_s1: 0.023029, loss_fp: 0.000830, loss_freq: 0.015571
[05:54:59.642] iteration 19261: loss: 0.048134, loss_s1: 0.038071, loss_fp: 0.003229, loss_freq: 0.014885
[05:55:00.263] iteration 19262: loss: 0.045149, loss_s1: 0.031561, loss_fp: 0.001691, loss_freq: 0.033620
[05:55:00.935] iteration 19263: loss: 0.044607, loss_s1: 0.028602, loss_fp: 0.000978, loss_freq: 0.018453
[05:55:01.586] iteration 19264: loss: 0.083466, loss_s1: 0.079666, loss_fp: 0.005240, loss_freq: 0.046725
[05:55:02.200] iteration 19265: loss: 0.064300, loss_s1: 0.039714, loss_fp: 0.001819, loss_freq: 0.043779
[05:55:02.815] iteration 19266: loss: 0.035420, loss_s1: 0.016692, loss_fp: 0.002027, loss_freq: 0.017157
[05:55:03.551] iteration 19267: loss: 0.070354, loss_s1: 0.052491, loss_fp: 0.001096, loss_freq: 0.061947
[05:55:04.257] iteration 19268: loss: 0.046025, loss_s1: 0.021291, loss_fp: 0.002969, loss_freq: 0.022273
[05:55:04.929] iteration 19269: loss: 0.047398, loss_s1: 0.024629, loss_fp: 0.001773, loss_freq: 0.037588
[05:55:05.682] iteration 19270: loss: 0.062985, loss_s1: 0.053932, loss_fp: 0.011946, loss_freq: 0.024671
[05:55:06.392] iteration 19271: loss: 0.053806, loss_s1: 0.046319, loss_fp: 0.001684, loss_freq: 0.021415
[05:55:07.128] iteration 19272: loss: 0.048864, loss_s1: 0.028565, loss_fp: 0.001552, loss_freq: 0.031418
[05:55:07.833] iteration 19273: loss: 0.042711, loss_s1: 0.029173, loss_fp: 0.001535, loss_freq: 0.007758
[05:55:08.594] iteration 19274: loss: 0.045833, loss_s1: 0.027742, loss_fp: 0.002258, loss_freq: 0.031559
[05:55:09.339] iteration 19275: loss: 0.046814, loss_s1: 0.040143, loss_fp: 0.006532, loss_freq: 0.013986
[05:55:10.013] iteration 19276: loss: 0.055702, loss_s1: 0.060422, loss_fp: 0.004456, loss_freq: 0.023216
[05:55:10.765] iteration 19277: loss: 0.060962, loss_s1: 0.032274, loss_fp: 0.001557, loss_freq: 0.028333
[05:55:11.479] iteration 19278: loss: 0.081084, loss_s1: 0.054176, loss_fp: 0.006065, loss_freq: 0.062563
[05:55:12.170] iteration 19279: loss: 0.042157, loss_s1: 0.032807, loss_fp: 0.001313, loss_freq: 0.020473
[05:55:12.894] iteration 19280: loss: 0.051954, loss_s1: 0.026157, loss_fp: 0.016574, loss_freq: 0.038434
[05:55:13.551] iteration 19281: loss: 0.053730, loss_s1: 0.027803, loss_fp: 0.004732, loss_freq: 0.037904
[05:55:14.318] iteration 19282: loss: 0.057752, loss_s1: 0.038413, loss_fp: 0.002425, loss_freq: 0.035465
[05:55:14.964] iteration 19283: loss: 0.061796, loss_s1: 0.044641, loss_fp: 0.009831, loss_freq: 0.040316
[05:55:15.585] iteration 19284: loss: 0.095962, loss_s1: 0.107269, loss_fp: 0.011541, loss_freq: 0.038994
[05:55:16.194] iteration 19285: loss: 0.075690, loss_s1: 0.021585, loss_fp: 0.003811, loss_freq: 0.087493
[05:55:16.806] iteration 19286: loss: 0.047662, loss_s1: 0.032530, loss_fp: 0.008367, loss_freq: 0.020845
[05:55:17.414] iteration 19287: loss: 0.057065, loss_s1: 0.036295, loss_fp: 0.003422, loss_freq: 0.033135
[05:55:18.022] iteration 19288: loss: 0.091764, loss_s1: 0.103742, loss_fp: 0.007654, loss_freq: 0.044083
[05:55:18.633] iteration 19289: loss: 0.054580, loss_s1: 0.049700, loss_fp: 0.005197, loss_freq: 0.025119
[05:55:19.249] iteration 19290: loss: 0.062839, loss_s1: 0.056882, loss_fp: 0.002920, loss_freq: 0.025481
[05:55:19.863] iteration 19291: loss: 0.069652, loss_s1: 0.050862, loss_fp: 0.002915, loss_freq: 0.045256
[05:55:20.479] iteration 19292: loss: 0.074982, loss_s1: 0.065729, loss_fp: 0.006900, loss_freq: 0.043722
[05:55:21.094] iteration 19293: loss: 0.062921, loss_s1: 0.054061, loss_fp: 0.003437, loss_freq: 0.038603
[05:55:21.910] iteration 19294: loss: 0.047434, loss_s1: 0.022302, loss_fp: 0.002520, loss_freq: 0.026721
[05:55:22.765] iteration 19295: loss: 0.064122, loss_s1: 0.055414, loss_fp: 0.006337, loss_freq: 0.023084
[05:55:23.597] iteration 19296: loss: 0.067140, loss_s1: 0.068297, loss_fp: 0.005762, loss_freq: 0.028613
[05:55:24.231] iteration 19297: loss: 0.058155, loss_s1: 0.075043, loss_fp: 0.002870, loss_freq: 0.018377
[05:55:24.851] iteration 19298: loss: 0.080334, loss_s1: 0.100789, loss_fp: 0.007263, loss_freq: 0.020350
[05:55:25.460] iteration 19299: loss: 0.051666, loss_s1: 0.051228, loss_fp: 0.003236, loss_freq: 0.011087
[05:55:26.064] iteration 19300: loss: 0.056345, loss_s1: 0.040841, loss_fp: 0.003106, loss_freq: 0.020651
[05:55:26.679] iteration 19301: loss: 0.063376, loss_s1: 0.061317, loss_fp: 0.011335, loss_freq: 0.021118
[05:55:27.287] iteration 19302: loss: 0.063175, loss_s1: 0.052227, loss_fp: 0.002359, loss_freq: 0.042587
[05:55:27.934] iteration 19303: loss: 0.080760, loss_s1: 0.088390, loss_fp: 0.013573, loss_freq: 0.017348
[05:55:28.679] iteration 19304: loss: 0.038298, loss_s1: 0.025164, loss_fp: 0.001790, loss_freq: 0.014076
[05:55:29.471] iteration 19305: loss: 0.057075, loss_s1: 0.053306, loss_fp: 0.002466, loss_freq: 0.017759
[05:55:30.261] iteration 19306: loss: 0.052065, loss_s1: 0.049993, loss_fp: 0.002325, loss_freq: 0.025863
[05:55:31.050] iteration 19307: loss: 0.041504, loss_s1: 0.028332, loss_fp: 0.002363, loss_freq: 0.012814
[05:55:31.694] iteration 19308: loss: 0.056906, loss_s1: 0.042495, loss_fp: 0.002155, loss_freq: 0.027041
[05:55:32.306] iteration 19309: loss: 0.064929, loss_s1: 0.036846, loss_fp: 0.007071, loss_freq: 0.034236
[05:55:32.928] iteration 19310: loss: 0.047260, loss_s1: 0.041619, loss_fp: 0.001636, loss_freq: 0.015772
[05:55:33.543] iteration 19311: loss: 0.062536, loss_s1: 0.064749, loss_fp: 0.007875, loss_freq: 0.022930
[05:55:34.153] iteration 19312: loss: 0.053422, loss_s1: 0.032644, loss_fp: 0.003468, loss_freq: 0.008370
[05:55:34.768] iteration 19313: loss: 0.041393, loss_s1: 0.029030, loss_fp: 0.003079, loss_freq: 0.021751
[05:55:35.377] iteration 19314: loss: 0.040629, loss_s1: 0.028818, loss_fp: 0.004655, loss_freq: 0.015236
[05:55:35.988] iteration 19315: loss: 0.042151, loss_s1: 0.037301, loss_fp: 0.001634, loss_freq: 0.018851
[05:55:36.601] iteration 19316: loss: 0.071231, loss_s1: 0.050908, loss_fp: 0.003880, loss_freq: 0.024008
[05:55:37.213] iteration 19317: loss: 0.069060, loss_s1: 0.074764, loss_fp: 0.001908, loss_freq: 0.025641
[05:55:37.827] iteration 19318: loss: 0.052165, loss_s1: 0.048657, loss_fp: 0.002631, loss_freq: 0.011372
[05:55:38.441] iteration 19319: loss: 0.061597, loss_s1: 0.045164, loss_fp: 0.014679, loss_freq: 0.027456
[05:55:39.051] iteration 19320: loss: 0.045172, loss_s1: 0.030404, loss_fp: 0.004049, loss_freq: 0.027070
[05:55:39.654] iteration 19321: loss: 0.053104, loss_s1: 0.048533, loss_fp: 0.005821, loss_freq: 0.015042
[05:55:40.280] iteration 19322: loss: 0.053851, loss_s1: 0.045836, loss_fp: 0.003848, loss_freq: 0.020748
[05:55:40.890] iteration 19323: loss: 0.042503, loss_s1: 0.028814, loss_fp: 0.003110, loss_freq: 0.025811
[05:55:41.500] iteration 19324: loss: 0.029666, loss_s1: 0.012404, loss_fp: 0.005557, loss_freq: 0.016589
[05:55:42.104] iteration 19325: loss: 0.106264, loss_s1: 0.087068, loss_fp: 0.003341, loss_freq: 0.087298
[05:55:42.716] iteration 19326: loss: 0.064176, loss_s1: 0.043099, loss_fp: 0.004074, loss_freq: 0.043884
[05:55:43.332] iteration 19327: loss: 0.059125, loss_s1: 0.047156, loss_fp: 0.005229, loss_freq: 0.028813
[05:55:43.944] iteration 19328: loss: 0.040788, loss_s1: 0.013766, loss_fp: 0.004621, loss_freq: 0.021737
[05:55:44.551] iteration 19329: loss: 0.074885, loss_s1: 0.065387, loss_fp: 0.002539, loss_freq: 0.048623
[05:55:45.163] iteration 19330: loss: 0.040778, loss_s1: 0.037478, loss_fp: 0.001658, loss_freq: 0.004369
[05:55:45.771] iteration 19331: loss: 0.042204, loss_s1: 0.028733, loss_fp: 0.004363, loss_freq: 0.016833
[05:55:46.388] iteration 19332: loss: 0.061380, loss_s1: 0.051556, loss_fp: 0.013154, loss_freq: 0.035421
[05:55:47.002] iteration 19333: loss: 0.082090, loss_s1: 0.038857, loss_fp: 0.007411, loss_freq: 0.030794
[05:55:47.612] iteration 19334: loss: 0.088699, loss_s1: 0.085108, loss_fp: 0.008659, loss_freq: 0.050840
[05:55:48.225] iteration 19335: loss: 0.094660, loss_s1: 0.093672, loss_fp: 0.018082, loss_freq: 0.037367
[05:55:48.829] iteration 19336: loss: 0.054096, loss_s1: 0.035363, loss_fp: 0.005117, loss_freq: 0.029376
[05:55:49.439] iteration 19337: loss: 0.059511, loss_s1: 0.040434, loss_fp: 0.002029, loss_freq: 0.054893
[05:55:50.045] iteration 19338: loss: 0.045842, loss_s1: 0.032435, loss_fp: 0.001122, loss_freq: 0.011457
[05:55:50.659] iteration 19339: loss: 0.053080, loss_s1: 0.049714, loss_fp: 0.009157, loss_freq: 0.015499
[05:55:51.276] iteration 19340: loss: 0.058654, loss_s1: 0.043473, loss_fp: 0.003350, loss_freq: 0.037788
[05:55:51.893] iteration 19341: loss: 0.069922, loss_s1: 0.074627, loss_fp: 0.003783, loss_freq: 0.029857
[05:55:52.507] iteration 19342: loss: 0.082728, loss_s1: 0.024172, loss_fp: 0.001700, loss_freq: 0.027119
[05:55:53.121] iteration 19343: loss: 0.080548, loss_s1: 0.058130, loss_fp: 0.005398, loss_freq: 0.061629
[05:55:53.745] iteration 19344: loss: 0.074760, loss_s1: 0.066504, loss_fp: 0.006839, loss_freq: 0.038584
[05:55:54.353] iteration 19345: loss: 0.073559, loss_s1: 0.084348, loss_fp: 0.001714, loss_freq: 0.028809
[05:55:54.956] iteration 19346: loss: 0.029586, loss_s1: 0.025392, loss_fp: 0.002883, loss_freq: 0.007650
[05:55:55.561] iteration 19347: loss: 0.085643, loss_s1: 0.051732, loss_fp: 0.004183, loss_freq: 0.017411
[05:55:56.167] iteration 19348: loss: 0.069865, loss_s1: 0.052991, loss_fp: 0.004285, loss_freq: 0.054791
[05:55:56.771] iteration 19349: loss: 0.112118, loss_s1: 0.138352, loss_fp: 0.002613, loss_freq: 0.050848
[05:55:57.381] iteration 19350: loss: 0.058707, loss_s1: 0.076459, loss_fp: 0.003239, loss_freq: 0.017610
[05:55:57.988] iteration 19351: loss: 0.077223, loss_s1: 0.059866, loss_fp: 0.004848, loss_freq: 0.037362
[05:55:58.603] iteration 19352: loss: 0.062708, loss_s1: 0.056928, loss_fp: 0.002295, loss_freq: 0.025365
[05:55:59.210] iteration 19353: loss: 0.065026, loss_s1: 0.060718, loss_fp: 0.006121, loss_freq: 0.027160
[05:55:59.816] iteration 19354: loss: 0.081343, loss_s1: 0.072466, loss_fp: 0.002689, loss_freq: 0.051024
[05:56:00.435] iteration 19355: loss: 0.064370, loss_s1: 0.062960, loss_fp: 0.009277, loss_freq: 0.025889
[05:56:01.045] iteration 19356: loss: 0.053130, loss_s1: 0.034308, loss_fp: 0.003131, loss_freq: 0.022109
[05:56:01.653] iteration 19357: loss: 0.066392, loss_s1: 0.051772, loss_fp: 0.004432, loss_freq: 0.032856
[05:56:02.263] iteration 19358: loss: 0.093474, loss_s1: 0.108012, loss_fp: 0.008768, loss_freq: 0.035349
[05:56:02.869] iteration 19359: loss: 0.056635, loss_s1: 0.059722, loss_fp: 0.002264, loss_freq: 0.027279
[05:56:03.484] iteration 19360: loss: 0.110397, loss_s1: 0.108649, loss_fp: 0.003260, loss_freq: 0.035413
[05:56:04.093] iteration 19361: loss: 0.061958, loss_s1: 0.042267, loss_fp: 0.011352, loss_freq: 0.032063
[05:56:04.727] iteration 19362: loss: 0.105484, loss_s1: 0.104025, loss_fp: 0.015681, loss_freq: 0.058647
[05:56:05.336] iteration 19363: loss: 0.125581, loss_s1: 0.136752, loss_fp: 0.004613, loss_freq: 0.057516
[05:56:05.947] iteration 19364: loss: 0.080234, loss_s1: 0.060611, loss_fp: 0.006277, loss_freq: 0.045554
[05:56:06.558] iteration 19365: loss: 0.076172, loss_s1: 0.065302, loss_fp: 0.002413, loss_freq: 0.045652
[05:56:07.168] iteration 19366: loss: 0.042523, loss_s1: 0.037877, loss_fp: 0.005569, loss_freq: 0.006852
[05:56:07.784] iteration 19367: loss: 0.051126, loss_s1: 0.034426, loss_fp: 0.004096, loss_freq: 0.023951
[05:56:08.392] iteration 19368: loss: 0.117208, loss_s1: 0.112931, loss_fp: 0.005628, loss_freq: 0.078057
[05:56:09.002] iteration 19369: loss: 0.070590, loss_s1: 0.068669, loss_fp: 0.004492, loss_freq: 0.034828
[05:56:09.609] iteration 19370: loss: 0.070977, loss_s1: 0.069305, loss_fp: 0.008592, loss_freq: 0.027268
[05:56:10.223] iteration 19371: loss: 0.049408, loss_s1: 0.039407, loss_fp: 0.002242, loss_freq: 0.015328
[05:56:10.832] iteration 19372: loss: 0.054470, loss_s1: 0.058663, loss_fp: 0.006528, loss_freq: 0.023075
[05:56:11.442] iteration 19373: loss: 0.059909, loss_s1: 0.035889, loss_fp: 0.004046, loss_freq: 0.024517
[05:56:12.056] iteration 19374: loss: 0.052592, loss_s1: 0.030938, loss_fp: 0.003349, loss_freq: 0.036317
[05:56:12.669] iteration 19375: loss: 0.039364, loss_s1: 0.028985, loss_fp: 0.001865, loss_freq: 0.014273
[05:56:13.276] iteration 19376: loss: 0.110486, loss_s1: 0.148197, loss_fp: 0.003740, loss_freq: 0.043369
[05:56:13.883] iteration 19377: loss: 0.057580, loss_s1: 0.057500, loss_fp: 0.001231, loss_freq: 0.013253
[05:56:14.492] iteration 19378: loss: 0.087664, loss_s1: 0.102541, loss_fp: 0.005556, loss_freq: 0.016157
[05:56:15.105] iteration 19379: loss: 0.077107, loss_s1: 0.092963, loss_fp: 0.002238, loss_freq: 0.033408
[05:56:15.745] iteration 19380: loss: 0.075004, loss_s1: 0.059140, loss_fp: 0.004901, loss_freq: 0.052002
[05:56:16.704] iteration 19381: loss: 0.068038, loss_s1: 0.046933, loss_fp: 0.001527, loss_freq: 0.049135
[05:56:17.318] iteration 19382: loss: 0.056805, loss_s1: 0.044619, loss_fp: 0.002402, loss_freq: 0.028487
[05:56:17.929] iteration 19383: loss: 0.082902, loss_s1: 0.092355, loss_fp: 0.003555, loss_freq: 0.038229
[05:56:18.585] iteration 19384: loss: 0.044519, loss_s1: 0.038008, loss_fp: 0.003212, loss_freq: 0.012661
[05:56:19.205] iteration 19385: loss: 0.034549, loss_s1: 0.018364, loss_fp: 0.002403, loss_freq: 0.025858
[05:56:19.817] iteration 19386: loss: 0.056630, loss_s1: 0.052813, loss_fp: 0.001394, loss_freq: 0.023234
[05:56:20.426] iteration 19387: loss: 0.069487, loss_s1: 0.061912, loss_fp: 0.000991, loss_freq: 0.043745
[05:56:21.040] iteration 19388: loss: 0.040807, loss_s1: 0.030133, loss_fp: 0.004523, loss_freq: 0.014556
[05:56:21.650] iteration 19389: loss: 0.054969, loss_s1: 0.045667, loss_fp: 0.004472, loss_freq: 0.034183
[05:56:22.261] iteration 19390: loss: 0.073196, loss_s1: 0.073269, loss_fp: 0.003518, loss_freq: 0.034012
[05:56:22.873] iteration 19391: loss: 0.062130, loss_s1: 0.038764, loss_fp: 0.001493, loss_freq: 0.036711
[05:56:23.504] iteration 19392: loss: 0.090311, loss_s1: 0.073830, loss_fp: 0.004477, loss_freq: 0.064375
[05:56:24.119] iteration 19393: loss: 0.047368, loss_s1: 0.024149, loss_fp: 0.001209, loss_freq: 0.025761
[05:56:24.728] iteration 19394: loss: 0.063511, loss_s1: 0.072647, loss_fp: 0.003257, loss_freq: 0.020875
[05:56:25.366] iteration 19395: loss: 0.062981, loss_s1: 0.068071, loss_fp: 0.002602, loss_freq: 0.021035
[05:56:25.978] iteration 19396: loss: 0.058976, loss_s1: 0.068699, loss_fp: 0.003534, loss_freq: 0.009983
[05:56:26.590] iteration 19397: loss: 0.106440, loss_s1: 0.116515, loss_fp: 0.003928, loss_freq: 0.068060
[05:56:27.201] iteration 19398: loss: 0.032985, loss_s1: 0.019949, loss_fp: 0.000854, loss_freq: 0.013463
[05:56:27.815] iteration 19399: loss: 0.084074, loss_s1: 0.101007, loss_fp: 0.006646, loss_freq: 0.033221
[05:56:28.430] iteration 19400: loss: 0.056039, loss_s1: 0.049838, loss_fp: 0.007538, loss_freq: 0.019210
[05:56:31.921] iteration 19400 : mean_dice : 0.725628
[05:56:32.608] iteration 19401: loss: 0.052713, loss_s1: 0.051256, loss_fp: 0.003252, loss_freq: 0.018919
[05:56:33.268] iteration 19402: loss: 0.048136, loss_s1: 0.041883, loss_fp: 0.002632, loss_freq: 0.030523
[05:56:33.920] iteration 19403: loss: 0.059954, loss_s1: 0.046142, loss_fp: 0.001992, loss_freq: 0.019257
[05:56:34.572] iteration 19404: loss: 0.060430, loss_s1: 0.051981, loss_fp: 0.004197, loss_freq: 0.026265
[05:56:35.187] iteration 19405: loss: 0.081020, loss_s1: 0.080556, loss_fp: 0.004176, loss_freq: 0.043098
[05:56:35.806] iteration 19406: loss: 0.067924, loss_s1: 0.051653, loss_fp: 0.004589, loss_freq: 0.051380
[05:56:36.416] iteration 19407: loss: 0.043968, loss_s1: 0.020986, loss_fp: 0.003576, loss_freq: 0.017265
[05:56:37.031] iteration 19408: loss: 0.128427, loss_s1: 0.114939, loss_fp: 0.024949, loss_freq: 0.081723
[05:56:37.643] iteration 19409: loss: 0.048571, loss_s1: 0.032421, loss_fp: 0.003010, loss_freq: 0.028808
[05:56:38.261] iteration 19410: loss: 0.071074, loss_s1: 0.064538, loss_fp: 0.004663, loss_freq: 0.028247
[05:56:38.880] iteration 19411: loss: 0.051732, loss_s1: 0.031227, loss_fp: 0.003828, loss_freq: 0.040878
[05:56:39.493] iteration 19412: loss: 0.085666, loss_s1: 0.077666, loss_fp: 0.004170, loss_freq: 0.050102
[05:56:40.107] iteration 19413: loss: 0.058391, loss_s1: 0.060999, loss_fp: 0.006959, loss_freq: 0.020935
[05:56:40.720] iteration 19414: loss: 0.039077, loss_s1: 0.019447, loss_fp: 0.003129, loss_freq: 0.007009
[05:56:41.321] iteration 19415: loss: 0.054780, loss_s1: 0.045217, loss_fp: 0.001766, loss_freq: 0.033802
[05:56:41.926] iteration 19416: loss: 0.059952, loss_s1: 0.050271, loss_fp: 0.001412, loss_freq: 0.015802
[05:56:42.540] iteration 19417: loss: 0.076591, loss_s1: 0.080268, loss_fp: 0.005739, loss_freq: 0.036673
[05:56:43.149] iteration 19418: loss: 0.043174, loss_s1: 0.037511, loss_fp: 0.005843, loss_freq: 0.018262
[05:56:43.764] iteration 19419: loss: 0.087679, loss_s1: 0.097616, loss_fp: 0.002882, loss_freq: 0.033829
[05:56:44.375] iteration 19420: loss: 0.104822, loss_s1: 0.104299, loss_fp: 0.003666, loss_freq: 0.054863
[05:56:44.992] iteration 19421: loss: 0.056886, loss_s1: 0.052386, loss_fp: 0.002051, loss_freq: 0.009842
[05:56:45.601] iteration 19422: loss: 0.061199, loss_s1: 0.049888, loss_fp: 0.009963, loss_freq: 0.023200
[05:56:46.273] iteration 19423: loss: 0.082132, loss_s1: 0.100896, loss_fp: 0.001824, loss_freq: 0.036592
[05:56:46.915] iteration 19424: loss: 0.085814, loss_s1: 0.103304, loss_fp: 0.002791, loss_freq: 0.041827
[05:56:47.545] iteration 19425: loss: 0.067333, loss_s1: 0.049522, loss_fp: 0.003538, loss_freq: 0.043282
[05:56:48.158] iteration 19426: loss: 0.085010, loss_s1: 0.059730, loss_fp: 0.005177, loss_freq: 0.070707
[05:56:48.767] iteration 19427: loss: 0.053079, loss_s1: 0.033430, loss_fp: 0.002005, loss_freq: 0.034096
[05:56:49.375] iteration 19428: loss: 0.065737, loss_s1: 0.065512, loss_fp: 0.003791, loss_freq: 0.030403
[05:56:49.981] iteration 19429: loss: 0.043819, loss_s1: 0.047145, loss_fp: 0.002055, loss_freq: 0.009826
[05:56:50.658] iteration 19430: loss: 0.041100, loss_s1: 0.029338, loss_fp: 0.002436, loss_freq: 0.015969
[05:56:51.343] iteration 19431: loss: 0.038223, loss_s1: 0.021361, loss_fp: 0.001975, loss_freq: 0.015600
[05:56:52.072] iteration 19432: loss: 0.046059, loss_s1: 0.051611, loss_fp: 0.003752, loss_freq: 0.017417
[05:56:52.728] iteration 19433: loss: 0.065440, loss_s1: 0.028431, loss_fp: 0.002933, loss_freq: 0.019077
[05:56:53.368] iteration 19434: loss: 0.075891, loss_s1: 0.083072, loss_fp: 0.004690, loss_freq: 0.029221
[05:56:53.970] iteration 19435: loss: 0.056323, loss_s1: 0.032187, loss_fp: 0.003521, loss_freq: 0.037051
[05:56:54.577] iteration 19436: loss: 0.033933, loss_s1: 0.015295, loss_fp: 0.002513, loss_freq: 0.017116
[05:56:55.192] iteration 19437: loss: 0.052891, loss_s1: 0.052176, loss_fp: 0.003402, loss_freq: 0.027024
[05:56:55.809] iteration 19438: loss: 0.061362, loss_s1: 0.040703, loss_fp: 0.020097, loss_freq: 0.016460
[05:56:56.418] iteration 19439: loss: 0.038854, loss_s1: 0.022193, loss_fp: 0.001823, loss_freq: 0.023669
[05:56:57.031] iteration 19440: loss: 0.050588, loss_s1: 0.047379, loss_fp: 0.003318, loss_freq: 0.022577
[05:56:57.640] iteration 19441: loss: 0.057995, loss_s1: 0.068380, loss_fp: 0.001799, loss_freq: 0.020104
[05:56:58.248] iteration 19442: loss: 0.075026, loss_s1: 0.028240, loss_fp: 0.001628, loss_freq: 0.038296
[05:56:58.859] iteration 19443: loss: 0.042714, loss_s1: 0.029166, loss_fp: 0.002686, loss_freq: 0.017860
[05:56:59.466] iteration 19444: loss: 0.046149, loss_s1: 0.035439, loss_fp: 0.003657, loss_freq: 0.022197
[05:57:00.073] iteration 19445: loss: 0.052301, loss_s1: 0.044467, loss_fp: 0.002180, loss_freq: 0.022745
[05:57:00.682] iteration 19446: loss: 0.040609, loss_s1: 0.033909, loss_fp: 0.002783, loss_freq: 0.020425
[05:57:01.291] iteration 19447: loss: 0.047277, loss_s1: 0.034502, loss_fp: 0.001780, loss_freq: 0.015000
[05:57:01.899] iteration 19448: loss: 0.120397, loss_s1: 0.091916, loss_fp: 0.011613, loss_freq: 0.109499
[05:57:02.519] iteration 19449: loss: 0.049079, loss_s1: 0.031190, loss_fp: 0.002240, loss_freq: 0.027818
[05:57:03.127] iteration 19450: loss: 0.053478, loss_s1: 0.055624, loss_fp: 0.000535, loss_freq: 0.026795
[05:57:03.736] iteration 19451: loss: 0.065586, loss_s1: 0.048385, loss_fp: 0.005467, loss_freq: 0.037503
[05:57:04.350] iteration 19452: loss: 0.058712, loss_s1: 0.047217, loss_fp: 0.003773, loss_freq: 0.032601
[05:57:05.007] iteration 19453: loss: 0.061581, loss_s1: 0.040759, loss_fp: 0.005258, loss_freq: 0.049335
[05:57:05.624] iteration 19454: loss: 0.061576, loss_s1: 0.043682, loss_fp: 0.004553, loss_freq: 0.016131
[05:57:06.237] iteration 19455: loss: 0.066656, loss_s1: 0.049445, loss_fp: 0.005410, loss_freq: 0.039052
[05:57:06.849] iteration 19456: loss: 0.065985, loss_s1: 0.050076, loss_fp: 0.004691, loss_freq: 0.027692
[05:57:07.468] iteration 19457: loss: 0.044057, loss_s1: 0.034401, loss_fp: 0.004912, loss_freq: 0.016798
[05:57:08.082] iteration 19458: loss: 0.060443, loss_s1: 0.034844, loss_fp: 0.003401, loss_freq: 0.035042
[05:57:08.691] iteration 19459: loss: 0.058286, loss_s1: 0.052914, loss_fp: 0.006542, loss_freq: 0.029085
[05:57:09.360] iteration 19460: loss: 0.072088, loss_s1: 0.061800, loss_fp: 0.005074, loss_freq: 0.020014
[05:57:09.977] iteration 19461: loss: 0.047391, loss_s1: 0.034529, loss_fp: 0.002023, loss_freq: 0.018982
[05:57:10.586] iteration 19462: loss: 0.072178, loss_s1: 0.066601, loss_fp: 0.004238, loss_freq: 0.043992
[05:57:11.202] iteration 19463: loss: 0.051930, loss_s1: 0.053308, loss_fp: 0.002816, loss_freq: 0.018001
[05:57:11.822] iteration 19464: loss: 0.110835, loss_s1: 0.137676, loss_fp: 0.006769, loss_freq: 0.039859
[05:57:12.430] iteration 19465: loss: 0.053610, loss_s1: 0.039572, loss_fp: 0.003908, loss_freq: 0.027462
[05:57:13.043] iteration 19466: loss: 0.061975, loss_s1: 0.025439, loss_fp: 0.006764, loss_freq: 0.040920
[05:57:13.651] iteration 19467: loss: 0.094583, loss_s1: 0.113063, loss_fp: 0.002870, loss_freq: 0.048664
[05:57:14.272] iteration 19468: loss: 0.075489, loss_s1: 0.079825, loss_fp: 0.008180, loss_freq: 0.030082
[05:57:14.887] iteration 19469: loss: 0.058201, loss_s1: 0.046926, loss_fp: 0.006352, loss_freq: 0.025912
[05:57:15.505] iteration 19470: loss: 0.044390, loss_s1: 0.022158, loss_fp: 0.008409, loss_freq: 0.020641
[05:57:16.120] iteration 19471: loss: 0.077270, loss_s1: 0.093778, loss_fp: 0.002684, loss_freq: 0.017550
[05:57:16.736] iteration 19472: loss: 0.079526, loss_s1: 0.076618, loss_fp: 0.006704, loss_freq: 0.046551
[05:57:17.353] iteration 19473: loss: 0.048507, loss_s1: 0.025941, loss_fp: 0.003363, loss_freq: 0.027509
[05:57:17.979] iteration 19474: loss: 0.074345, loss_s1: 0.068670, loss_fp: 0.002941, loss_freq: 0.047130
[05:57:18.592] iteration 19475: loss: 0.076246, loss_s1: 0.059892, loss_fp: 0.006093, loss_freq: 0.048731
[05:57:19.211] iteration 19476: loss: 0.059729, loss_s1: 0.044150, loss_fp: 0.005704, loss_freq: 0.031757
[05:57:19.840] iteration 19477: loss: 0.112019, loss_s1: 0.124362, loss_fp: 0.001647, loss_freq: 0.042598
[05:57:20.445] iteration 19478: loss: 0.077097, loss_s1: 0.050571, loss_fp: 0.008209, loss_freq: 0.051641
[05:57:21.051] iteration 19479: loss: 0.090326, loss_s1: 0.085624, loss_fp: 0.002064, loss_freq: 0.061287
[05:57:21.663] iteration 19480: loss: 0.050439, loss_s1: 0.046190, loss_fp: 0.002757, loss_freq: 0.012479
[05:57:22.275] iteration 19481: loss: 0.080701, loss_s1: 0.089782, loss_fp: 0.008650, loss_freq: 0.022791
[05:57:22.884] iteration 19482: loss: 0.064108, loss_s1: 0.045659, loss_fp: 0.003648, loss_freq: 0.022665
[05:57:23.498] iteration 19483: loss: 0.032448, loss_s1: 0.015571, loss_fp: 0.002606, loss_freq: 0.013764
[05:57:24.111] iteration 19484: loss: 0.062548, loss_s1: 0.025788, loss_fp: 0.002695, loss_freq: 0.050991
[05:57:24.734] iteration 19485: loss: 0.049102, loss_s1: 0.038689, loss_fp: 0.014516, loss_freq: 0.021214
[05:57:25.348] iteration 19486: loss: 0.065650, loss_s1: 0.049463, loss_fp: 0.001929, loss_freq: 0.042574
[05:57:25.964] iteration 19487: loss: 0.043461, loss_s1: 0.024045, loss_fp: 0.003149, loss_freq: 0.020986
[05:57:26.580] iteration 19488: loss: 0.078287, loss_s1: 0.082293, loss_fp: 0.002993, loss_freq: 0.038078
[05:57:27.190] iteration 19489: loss: 0.057454, loss_s1: 0.023756, loss_fp: 0.005782, loss_freq: 0.038719
[05:57:27.832] iteration 19490: loss: 0.038736, loss_s1: 0.019858, loss_fp: 0.004008, loss_freq: 0.022871
[05:57:28.450] iteration 19491: loss: 0.059837, loss_s1: 0.061067, loss_fp: 0.002232, loss_freq: 0.020482
[05:57:29.060] iteration 19492: loss: 0.056244, loss_s1: 0.037826, loss_fp: 0.006349, loss_freq: 0.028517
[05:57:29.669] iteration 19493: loss: 0.043254, loss_s1: 0.024006, loss_fp: 0.003726, loss_freq: 0.026186
[05:57:30.287] iteration 19494: loss: 0.053583, loss_s1: 0.060992, loss_fp: 0.003202, loss_freq: 0.020064
[05:57:30.896] iteration 19495: loss: 0.122097, loss_s1: 0.102122, loss_fp: 0.003947, loss_freq: 0.086893
[05:57:31.502] iteration 19496: loss: 0.067053, loss_s1: 0.069549, loss_fp: 0.002623, loss_freq: 0.028437
[05:57:32.104] iteration 19497: loss: 0.048200, loss_s1: 0.029333, loss_fp: 0.002623, loss_freq: 0.020514
[05:57:32.717] iteration 19498: loss: 0.039383, loss_s1: 0.025332, loss_fp: 0.010427, loss_freq: 0.013802
[05:57:33.323] iteration 19499: loss: 0.084629, loss_s1: 0.075306, loss_fp: 0.005016, loss_freq: 0.057627
[05:57:33.932] iteration 19500: loss: 0.056034, loss_s1: 0.031613, loss_fp: 0.001547, loss_freq: 0.032481
[05:57:34.587] iteration 19501: loss: 0.037186, loss_s1: 0.029294, loss_fp: 0.006134, loss_freq: 0.005049
[05:57:35.248] iteration 19502: loss: 0.053425, loss_s1: 0.056437, loss_fp: 0.001028, loss_freq: 0.023684
[05:57:36.020] iteration 19503: loss: 0.079166, loss_s1: 0.038945, loss_fp: 0.002508, loss_freq: 0.066324
[05:57:36.736] iteration 19504: loss: 0.046286, loss_s1: 0.038547, loss_fp: 0.005674, loss_freq: 0.015360
[05:57:37.349] iteration 19505: loss: 0.072856, loss_s1: 0.045605, loss_fp: 0.005086, loss_freq: 0.049011
[05:57:37.961] iteration 19506: loss: 0.052293, loss_s1: 0.036645, loss_fp: 0.003007, loss_freq: 0.022174
[05:57:38.584] iteration 19507: loss: 0.038704, loss_s1: 0.028350, loss_fp: 0.002392, loss_freq: 0.020702
[05:57:39.198] iteration 19508: loss: 0.046829, loss_s1: 0.033228, loss_fp: 0.001265, loss_freq: 0.008909
[05:57:39.812] iteration 19509: loss: 0.059895, loss_s1: 0.050205, loss_fp: 0.005615, loss_freq: 0.030189
[05:57:40.422] iteration 19510: loss: 0.074526, loss_s1: 0.057521, loss_fp: 0.010454, loss_freq: 0.047136
[05:57:41.035] iteration 19511: loss: 0.054804, loss_s1: 0.066945, loss_fp: 0.003823, loss_freq: 0.014114
[05:57:41.652] iteration 19512: loss: 0.067890, loss_s1: 0.054356, loss_fp: 0.002576, loss_freq: 0.018820
[05:57:42.273] iteration 19513: loss: 0.057996, loss_s1: 0.037829, loss_fp: 0.004553, loss_freq: 0.041421
[05:57:42.888] iteration 19514: loss: 0.053716, loss_s1: 0.050502, loss_fp: 0.002282, loss_freq: 0.024725
[05:57:43.518] iteration 19515: loss: 0.119038, loss_s1: 0.083445, loss_fp: 0.002686, loss_freq: 0.112663
[05:57:44.145] iteration 19516: loss: 0.032767, loss_s1: 0.029083, loss_fp: 0.002481, loss_freq: 0.010076
[05:57:44.757] iteration 19517: loss: 0.065940, loss_s1: 0.064039, loss_fp: 0.001631, loss_freq: 0.022400
[05:57:45.372] iteration 19518: loss: 0.041521, loss_s1: 0.024726, loss_fp: 0.001661, loss_freq: 0.027764
[05:57:45.986] iteration 19519: loss: 0.106031, loss_s1: 0.128050, loss_fp: 0.003041, loss_freq: 0.045527
[05:57:46.601] iteration 19520: loss: 0.053836, loss_s1: 0.056960, loss_fp: 0.005095, loss_freq: 0.019414
[05:57:47.211] iteration 19521: loss: 0.062783, loss_s1: 0.049504, loss_fp: 0.004062, loss_freq: 0.029474
[05:57:47.820] iteration 19522: loss: 0.076353, loss_s1: 0.068832, loss_fp: 0.002670, loss_freq: 0.035815
[05:57:48.476] iteration 19523: loss: 0.044792, loss_s1: 0.033531, loss_fp: 0.005341, loss_freq: 0.017501
[05:57:49.087] iteration 19524: loss: 0.047548, loss_s1: 0.029664, loss_fp: 0.002723, loss_freq: 0.028708
[05:57:49.709] iteration 19525: loss: 0.030469, loss_s1: 0.021049, loss_fp: 0.002604, loss_freq: 0.011354
[05:57:50.325] iteration 19526: loss: 0.055708, loss_s1: 0.032604, loss_fp: 0.004172, loss_freq: 0.036948
[05:57:50.938] iteration 19527: loss: 0.046561, loss_s1: 0.028814, loss_fp: 0.008287, loss_freq: 0.022522
[05:57:51.545] iteration 19528: loss: 0.046013, loss_s1: 0.033168, loss_fp: 0.002142, loss_freq: 0.030214
[05:57:52.154] iteration 19529: loss: 0.061029, loss_s1: 0.073503, loss_fp: 0.004325, loss_freq: 0.021260
[05:57:52.761] iteration 19530: loss: 0.058609, loss_s1: 0.051309, loss_fp: 0.004222, loss_freq: 0.023540
[05:57:53.372] iteration 19531: loss: 0.062111, loss_s1: 0.057176, loss_fp: 0.011199, loss_freq: 0.021044
[05:57:53.988] iteration 19532: loss: 0.056698, loss_s1: 0.040122, loss_fp: 0.003246, loss_freq: 0.036367
[05:57:54.591] iteration 19533: loss: 0.096872, loss_s1: 0.091775, loss_fp: 0.004508, loss_freq: 0.059404
[05:57:55.227] iteration 19534: loss: 0.085712, loss_s1: 0.087710, loss_fp: 0.007744, loss_freq: 0.035821
[05:57:55.845] iteration 19535: loss: 0.090463, loss_s1: 0.092846, loss_fp: 0.002902, loss_freq: 0.036727
[05:57:56.458] iteration 19536: loss: 0.065711, loss_s1: 0.056357, loss_fp: 0.002454, loss_freq: 0.035259
[05:57:57.068] iteration 19537: loss: 0.034256, loss_s1: 0.025778, loss_fp: 0.002685, loss_freq: 0.017459
[05:57:57.678] iteration 19538: loss: 0.085714, loss_s1: 0.062366, loss_fp: 0.014311, loss_freq: 0.045050
[05:57:58.287] iteration 19539: loss: 0.080085, loss_s1: 0.060762, loss_fp: 0.005244, loss_freq: 0.061265
[05:57:58.898] iteration 19540: loss: 0.076554, loss_s1: 0.060059, loss_fp: 0.006786, loss_freq: 0.052303
[05:57:59.503] iteration 19541: loss: 0.040392, loss_s1: 0.030009, loss_fp: 0.004466, loss_freq: 0.008589
[05:58:00.115] iteration 19542: loss: 0.054393, loss_s1: 0.050987, loss_fp: 0.006539, loss_freq: 0.030890
[05:58:00.719] iteration 19543: loss: 0.043886, loss_s1: 0.014409, loss_fp: 0.001488, loss_freq: 0.012202
[05:58:01.414] iteration 19544: loss: 0.052300, loss_s1: 0.040713, loss_fp: 0.003000, loss_freq: 0.030066
[05:58:02.069] iteration 19545: loss: 0.026367, loss_s1: 0.011739, loss_fp: 0.001458, loss_freq: 0.011532
[05:58:02.726] iteration 19546: loss: 0.039717, loss_s1: 0.023127, loss_fp: 0.006754, loss_freq: 0.018745
[05:58:03.418] iteration 19547: loss: 0.056751, loss_s1: 0.044530, loss_fp: 0.002974, loss_freq: 0.026690
[05:58:04.074] iteration 19548: loss: 0.055521, loss_s1: 0.042050, loss_fp: 0.003191, loss_freq: 0.023993
[05:58:04.726] iteration 19549: loss: 0.101118, loss_s1: 0.121572, loss_fp: 0.002586, loss_freq: 0.048575
[05:58:05.376] iteration 19550: loss: 0.073429, loss_s1: 0.078628, loss_fp: 0.001335, loss_freq: 0.028772
[05:58:06.322] iteration 19551: loss: 0.079219, loss_s1: 0.078337, loss_fp: 0.001138, loss_freq: 0.042541
[05:58:06.943] iteration 19552: loss: 0.056906, loss_s1: 0.040109, loss_fp: 0.002836, loss_freq: 0.039027
[05:58:07.565] iteration 19553: loss: 0.050859, loss_s1: 0.050990, loss_fp: 0.002945, loss_freq: 0.019818
[05:58:08.182] iteration 19554: loss: 0.078756, loss_s1: 0.084478, loss_fp: 0.002636, loss_freq: 0.030949
[05:58:08.797] iteration 19555: loss: 0.050687, loss_s1: 0.052857, loss_fp: 0.006546, loss_freq: 0.013667
[05:58:09.410] iteration 19556: loss: 0.069435, loss_s1: 0.060537, loss_fp: 0.002142, loss_freq: 0.035561
[05:58:10.025] iteration 19557: loss: 0.046573, loss_s1: 0.029743, loss_fp: 0.004981, loss_freq: 0.010535
[05:58:10.641] iteration 19558: loss: 0.054908, loss_s1: 0.036409, loss_fp: 0.004603, loss_freq: 0.029888
[05:58:11.250] iteration 19559: loss: 0.068206, loss_s1: 0.070642, loss_fp: 0.002226, loss_freq: 0.025995
[05:58:11.859] iteration 19560: loss: 0.073448, loss_s1: 0.077123, loss_fp: 0.004976, loss_freq: 0.025772
[05:58:12.469] iteration 19561: loss: 0.091774, loss_s1: 0.078988, loss_fp: 0.003038, loss_freq: 0.060257
[05:58:13.082] iteration 19562: loss: 0.071721, loss_s1: 0.055678, loss_fp: 0.001067, loss_freq: 0.048023
[05:58:13.724] iteration 19563: loss: 0.073361, loss_s1: 0.059454, loss_fp: 0.007247, loss_freq: 0.037890
[05:58:14.346] iteration 19564: loss: 0.084272, loss_s1: 0.060410, loss_fp: 0.009483, loss_freq: 0.065125
[05:58:14.963] iteration 19565: loss: 0.089104, loss_s1: 0.110706, loss_fp: 0.005130, loss_freq: 0.013715
[05:58:15.573] iteration 19566: loss: 0.074013, loss_s1: 0.060965, loss_fp: 0.004237, loss_freq: 0.025672
[05:58:16.180] iteration 19567: loss: 0.093649, loss_s1: 0.103018, loss_fp: 0.003059, loss_freq: 0.050465
[05:58:16.798] iteration 19568: loss: 0.044331, loss_s1: 0.028942, loss_fp: 0.005516, loss_freq: 0.019039
[05:58:17.418] iteration 19569: loss: 0.123116, loss_s1: 0.122707, loss_fp: 0.029096, loss_freq: 0.060776
[05:58:18.034] iteration 19570: loss: 0.046892, loss_s1: 0.045259, loss_fp: 0.003809, loss_freq: 0.013872
[05:58:18.646] iteration 19571: loss: 0.080894, loss_s1: 0.063449, loss_fp: 0.004200, loss_freq: 0.036037
[05:58:19.261] iteration 19572: loss: 0.078952, loss_s1: 0.097433, loss_fp: 0.002102, loss_freq: 0.035497
[05:58:19.875] iteration 19573: loss: 0.072488, loss_s1: 0.073986, loss_fp: 0.001270, loss_freq: 0.025488
[05:58:20.489] iteration 19574: loss: 0.061085, loss_s1: 0.054802, loss_fp: 0.003402, loss_freq: 0.025987
[05:58:21.140] iteration 19575: loss: 0.065310, loss_s1: 0.058585, loss_fp: 0.004343, loss_freq: 0.031607
[05:58:21.753] iteration 19576: loss: 0.076791, loss_s1: 0.077589, loss_fp: 0.003962, loss_freq: 0.039928
[05:58:22.361] iteration 19577: loss: 0.079041, loss_s1: 0.067797, loss_fp: 0.003363, loss_freq: 0.022020
[05:58:22.975] iteration 19578: loss: 0.059676, loss_s1: 0.062335, loss_fp: 0.002343, loss_freq: 0.017610
[05:58:23.588] iteration 19579: loss: 0.042872, loss_s1: 0.032239, loss_fp: 0.000486, loss_freq: 0.022087
[05:58:24.208] iteration 19580: loss: 0.066157, loss_s1: 0.047687, loss_fp: 0.006635, loss_freq: 0.039876
[05:58:24.821] iteration 19581: loss: 0.082087, loss_s1: 0.102369, loss_fp: 0.004172, loss_freq: 0.034235
[05:58:25.439] iteration 19582: loss: 0.088231, loss_s1: 0.086145, loss_fp: 0.001998, loss_freq: 0.042038
[05:58:26.064] iteration 19583: loss: 0.051671, loss_s1: 0.037919, loss_fp: 0.003057, loss_freq: 0.033309
[05:58:26.686] iteration 19584: loss: 0.042486, loss_s1: 0.030022, loss_fp: 0.006721, loss_freq: 0.006217
[05:58:27.304] iteration 19585: loss: 0.053262, loss_s1: 0.052801, loss_fp: 0.002569, loss_freq: 0.026911
[05:58:27.964] iteration 19586: loss: 0.044143, loss_s1: 0.021687, loss_fp: 0.002723, loss_freq: 0.016749
[05:58:28.575] iteration 19587: loss: 0.076163, loss_s1: 0.081208, loss_fp: 0.004588, loss_freq: 0.028684
[05:58:29.190] iteration 19588: loss: 0.080331, loss_s1: 0.110058, loss_fp: 0.005574, loss_freq: 0.016259
[05:58:29.805] iteration 19589: loss: 0.107021, loss_s1: 0.103563, loss_fp: 0.007317, loss_freq: 0.068749
[05:58:30.435] iteration 19590: loss: 0.060926, loss_s1: 0.057878, loss_fp: 0.010489, loss_freq: 0.026304
[05:58:31.041] iteration 19591: loss: 0.098992, loss_s1: 0.072915, loss_fp: 0.002639, loss_freq: 0.077535
[05:58:31.655] iteration 19592: loss: 0.068049, loss_s1: 0.064433, loss_fp: 0.002268, loss_freq: 0.037025
[05:58:32.263] iteration 19593: loss: 0.073983, loss_s1: 0.049126, loss_fp: 0.006497, loss_freq: 0.058378
[05:58:32.880] iteration 19594: loss: 0.120164, loss_s1: 0.117957, loss_fp: 0.003038, loss_freq: 0.083881
[05:58:33.488] iteration 19595: loss: 0.051410, loss_s1: 0.038017, loss_fp: 0.003532, loss_freq: 0.017503
[05:58:34.099] iteration 19596: loss: 0.079411, loss_s1: 0.081123, loss_fp: 0.005232, loss_freq: 0.042561
[05:58:34.759] iteration 19597: loss: 0.046354, loss_s1: 0.036618, loss_fp: 0.004581, loss_freq: 0.023280
[05:58:35.416] iteration 19598: loss: 0.058937, loss_s1: 0.036357, loss_fp: 0.004280, loss_freq: 0.045043
[05:58:36.047] iteration 19599: loss: 0.037165, loss_s1: 0.029812, loss_fp: 0.001400, loss_freq: 0.006169
[05:58:36.664] iteration 19600: loss: 0.056051, loss_s1: 0.047168, loss_fp: 0.003271, loss_freq: 0.017718
[05:58:40.129] iteration 19600 : mean_dice : 0.725439
[05:58:40.773] iteration 19601: loss: 0.052936, loss_s1: 0.033215, loss_fp: 0.001437, loss_freq: 0.033881
[05:58:41.382] iteration 19602: loss: 0.034472, loss_s1: 0.031501, loss_fp: 0.003573, loss_freq: 0.012814
[05:58:41.999] iteration 19603: loss: 0.068800, loss_s1: 0.073967, loss_fp: 0.001571, loss_freq: 0.027122
[05:58:42.640] iteration 19604: loss: 0.058768, loss_s1: 0.036389, loss_fp: 0.010792, loss_freq: 0.027046
[05:58:43.323] iteration 19605: loss: 0.061904, loss_s1: 0.047966, loss_fp: 0.003235, loss_freq: 0.034930
[05:58:43.985] iteration 19606: loss: 0.040871, loss_s1: 0.019188, loss_fp: 0.004426, loss_freq: 0.025943
[05:58:44.640] iteration 19607: loss: 0.073826, loss_s1: 0.065347, loss_fp: 0.004753, loss_freq: 0.054413
[05:58:45.258] iteration 19608: loss: 0.040962, loss_s1: 0.012562, loss_fp: 0.003588, loss_freq: 0.023875
[05:58:45.873] iteration 19609: loss: 0.042600, loss_s1: 0.028475, loss_fp: 0.004183, loss_freq: 0.024648
[05:58:46.484] iteration 19610: loss: 0.066339, loss_s1: 0.048232, loss_fp: 0.004277, loss_freq: 0.044941
[05:58:47.091] iteration 19611: loss: 0.039502, loss_s1: 0.021915, loss_fp: 0.004806, loss_freq: 0.016232
[05:58:47.699] iteration 19612: loss: 0.075976, loss_s1: 0.071352, loss_fp: 0.003879, loss_freq: 0.026668
[05:58:48.305] iteration 19613: loss: 0.045807, loss_s1: 0.035158, loss_fp: 0.001777, loss_freq: 0.015492
[05:58:48.910] iteration 19614: loss: 0.035076, loss_s1: 0.023840, loss_fp: 0.001578, loss_freq: 0.011832
[05:58:49.517] iteration 19615: loss: 0.096448, loss_s1: 0.110443, loss_fp: 0.012504, loss_freq: 0.032269
[05:58:50.123] iteration 19616: loss: 0.053222, loss_s1: 0.039588, loss_fp: 0.001003, loss_freq: 0.037267
[05:58:50.729] iteration 19617: loss: 0.072766, loss_s1: 0.035140, loss_fp: 0.001632, loss_freq: 0.029486
[05:58:51.340] iteration 19618: loss: 0.096411, loss_s1: 0.089976, loss_fp: 0.007771, loss_freq: 0.048008
[05:58:51.951] iteration 19619: loss: 0.041603, loss_s1: 0.029601, loss_fp: 0.001756, loss_freq: 0.014174
[05:58:52.567] iteration 19620: loss: 0.054955, loss_s1: 0.055998, loss_fp: 0.002985, loss_freq: 0.021490
[05:58:53.180] iteration 19621: loss: 0.060784, loss_s1: 0.063435, loss_fp: 0.005494, loss_freq: 0.017644
[05:58:53.786] iteration 19622: loss: 0.047876, loss_s1: 0.029293, loss_fp: 0.005332, loss_freq: 0.022720
[05:58:54.395] iteration 19623: loss: 0.049212, loss_s1: 0.032893, loss_fp: 0.009379, loss_freq: 0.031752
[05:58:55.008] iteration 19624: loss: 0.054131, loss_s1: 0.042237, loss_fp: 0.010247, loss_freq: 0.024502
[05:58:55.618] iteration 19625: loss: 0.055167, loss_s1: 0.031267, loss_fp: 0.006305, loss_freq: 0.039909
[05:58:56.223] iteration 19626: loss: 0.077821, loss_s1: 0.062419, loss_fp: 0.007115, loss_freq: 0.055173
[05:58:56.830] iteration 19627: loss: 0.047062, loss_s1: 0.031682, loss_fp: 0.003503, loss_freq: 0.026534
[05:58:57.439] iteration 19628: loss: 0.084986, loss_s1: 0.091464, loss_fp: 0.004948, loss_freq: 0.032579
[05:58:58.043] iteration 19629: loss: 0.052552, loss_s1: 0.042092, loss_fp: 0.003406, loss_freq: 0.022277
[05:58:58.652] iteration 19630: loss: 0.054430, loss_s1: 0.041919, loss_fp: 0.003986, loss_freq: 0.017737
[05:58:59.266] iteration 19631: loss: 0.068980, loss_s1: 0.059589, loss_fp: 0.004567, loss_freq: 0.024718
[05:58:59.920] iteration 19632: loss: 0.054562, loss_s1: 0.030770, loss_fp: 0.004740, loss_freq: 0.042966
[05:59:00.578] iteration 19633: loss: 0.057315, loss_s1: 0.033419, loss_fp: 0.002263, loss_freq: 0.040253
[05:59:01.231] iteration 19634: loss: 0.077680, loss_s1: 0.077032, loss_fp: 0.005737, loss_freq: 0.030216
[05:59:01.862] iteration 19635: loss: 0.055128, loss_s1: 0.034644, loss_fp: 0.003909, loss_freq: 0.020799
[05:59:02.475] iteration 19636: loss: 0.068863, loss_s1: 0.063763, loss_fp: 0.002473, loss_freq: 0.035877
[05:59:03.097] iteration 19637: loss: 0.081452, loss_s1: 0.100223, loss_fp: 0.007213, loss_freq: 0.034023
[05:59:03.746] iteration 19638: loss: 0.063343, loss_s1: 0.056565, loss_fp: 0.006146, loss_freq: 0.029492
[05:59:04.358] iteration 19639: loss: 0.063466, loss_s1: 0.068165, loss_fp: 0.002245, loss_freq: 0.025882
[05:59:04.969] iteration 19640: loss: 0.039303, loss_s1: 0.024437, loss_fp: 0.008043, loss_freq: 0.010066
[05:59:05.576] iteration 19641: loss: 0.055642, loss_s1: 0.049848, loss_fp: 0.001080, loss_freq: 0.023805
[05:59:06.180] iteration 19642: loss: 0.057196, loss_s1: 0.076999, loss_fp: 0.005077, loss_freq: 0.008428
[05:59:06.787] iteration 19643: loss: 0.071514, loss_s1: 0.087438, loss_fp: 0.002648, loss_freq: 0.015154
[05:59:07.395] iteration 19644: loss: 0.069758, loss_s1: 0.080152, loss_fp: 0.002599, loss_freq: 0.028424
[05:59:08.003] iteration 19645: loss: 0.112483, loss_s1: 0.128742, loss_fp: 0.002186, loss_freq: 0.059496
[05:59:08.610] iteration 19646: loss: 0.048010, loss_s1: 0.047355, loss_fp: 0.001863, loss_freq: 0.022169
[05:59:09.218] iteration 19647: loss: 0.087155, loss_s1: 0.099698, loss_fp: 0.006755, loss_freq: 0.025230
[05:59:09.821] iteration 19648: loss: 0.079388, loss_s1: 0.046992, loss_fp: 0.001243, loss_freq: 0.062304
[05:59:10.422] iteration 19649: loss: 0.069696, loss_s1: 0.051766, loss_fp: 0.001244, loss_freq: 0.055865
[05:59:11.038] iteration 19650: loss: 0.059430, loss_s1: 0.049546, loss_fp: 0.003150, loss_freq: 0.030711
[05:59:11.720] iteration 19651: loss: 0.064116, loss_s1: 0.063710, loss_fp: 0.004518, loss_freq: 0.029227
[05:59:12.394] iteration 19652: loss: 0.056326, loss_s1: 0.048830, loss_fp: 0.003910, loss_freq: 0.015279
[05:59:13.055] iteration 19653: loss: 0.047548, loss_s1: 0.022935, loss_fp: 0.003601, loss_freq: 0.036581
[05:59:13.693] iteration 19654: loss: 0.038694, loss_s1: 0.019322, loss_fp: 0.003345, loss_freq: 0.016388
[05:59:14.325] iteration 19655: loss: 0.035410, loss_s1: 0.020992, loss_fp: 0.004469, loss_freq: 0.024504
[05:59:14.954] iteration 19656: loss: 0.065266, loss_s1: 0.064673, loss_fp: 0.003368, loss_freq: 0.025904
[05:59:15.585] iteration 19657: loss: 0.056424, loss_s1: 0.050731, loss_fp: 0.002715, loss_freq: 0.019937
[05:59:16.209] iteration 19658: loss: 0.045527, loss_s1: 0.037105, loss_fp: 0.005184, loss_freq: 0.021682
[05:59:16.832] iteration 19659: loss: 0.088129, loss_s1: 0.050275, loss_fp: 0.016588, loss_freq: 0.070061
[05:59:17.450] iteration 19660: loss: 0.072083, loss_s1: 0.073247, loss_fp: 0.003945, loss_freq: 0.032972
[05:59:18.118] iteration 19661: loss: 0.041481, loss_s1: 0.026672, loss_fp: 0.003172, loss_freq: 0.016533
[05:59:18.773] iteration 19662: loss: 0.044832, loss_s1: 0.033437, loss_fp: 0.004602, loss_freq: 0.018443
[05:59:19.424] iteration 19663: loss: 0.050570, loss_s1: 0.041921, loss_fp: 0.004687, loss_freq: 0.026116
[05:59:20.055] iteration 19664: loss: 0.029173, loss_s1: 0.014045, loss_fp: 0.002824, loss_freq: 0.009356
[05:59:20.712] iteration 19665: loss: 0.076758, loss_s1: 0.037650, loss_fp: 0.005625, loss_freq: 0.065502
[05:59:21.367] iteration 19666: loss: 0.068487, loss_s1: 0.036096, loss_fp: 0.010122, loss_freq: 0.048028
[05:59:21.991] iteration 19667: loss: 0.066497, loss_s1: 0.055284, loss_fp: 0.006076, loss_freq: 0.037611
[05:59:22.603] iteration 19668: loss: 0.047807, loss_s1: 0.023823, loss_fp: 0.004136, loss_freq: 0.034919
[05:59:23.253] iteration 19669: loss: 0.073120, loss_s1: 0.034912, loss_fp: 0.001647, loss_freq: 0.078375
[05:59:23.868] iteration 19670: loss: 0.050693, loss_s1: 0.038567, loss_fp: 0.001773, loss_freq: 0.017352
[05:59:24.481] iteration 19671: loss: 0.032974, loss_s1: 0.023340, loss_fp: 0.003191, loss_freq: 0.005548
[05:59:25.136] iteration 19672: loss: 0.070494, loss_s1: 0.081615, loss_fp: 0.001940, loss_freq: 0.035920
[05:59:25.799] iteration 19673: loss: 0.060756, loss_s1: 0.035199, loss_fp: 0.005593, loss_freq: 0.038461
[05:59:26.466] iteration 19674: loss: 0.043386, loss_s1: 0.028620, loss_fp: 0.000990, loss_freq: 0.026277
[05:59:27.152] iteration 19675: loss: 0.066559, loss_s1: 0.048131, loss_fp: 0.002652, loss_freq: 0.046158
[05:59:27.820] iteration 19676: loss: 0.047456, loss_s1: 0.025962, loss_fp: 0.013410, loss_freq: 0.021623
[05:59:28.432] iteration 19677: loss: 0.050417, loss_s1: 0.027264, loss_fp: 0.005774, loss_freq: 0.042042
[05:59:29.215] iteration 19678: loss: 0.065531, loss_s1: 0.045739, loss_fp: 0.004642, loss_freq: 0.033441
[05:59:29.936] iteration 19679: loss: 0.042988, loss_s1: 0.038731, loss_fp: 0.003094, loss_freq: 0.019957
[05:59:30.734] iteration 19680: loss: 0.059297, loss_s1: 0.044309, loss_fp: 0.000885, loss_freq: 0.036936
[05:59:31.456] iteration 19681: loss: 0.058259, loss_s1: 0.068094, loss_fp: 0.009145, loss_freq: 0.016104
[05:59:32.125] iteration 19682: loss: 0.068514, loss_s1: 0.057777, loss_fp: 0.002171, loss_freq: 0.028813
[05:59:32.889] iteration 19683: loss: 0.073835, loss_s1: 0.080930, loss_fp: 0.007132, loss_freq: 0.024402
[05:59:33.527] iteration 19684: loss: 0.075013, loss_s1: 0.062222, loss_fp: 0.007635, loss_freq: 0.053011
[05:59:34.266] iteration 19685: loss: 0.120940, loss_s1: 0.104894, loss_fp: 0.004149, loss_freq: 0.094466
[05:59:34.926] iteration 19686: loss: 0.040351, loss_s1: 0.032895, loss_fp: 0.002205, loss_freq: 0.016765
[05:59:35.566] iteration 19687: loss: 0.075345, loss_s1: 0.075541, loss_fp: 0.001321, loss_freq: 0.024563
[05:59:36.202] iteration 19688: loss: 0.077193, loss_s1: 0.034752, loss_fp: 0.003952, loss_freq: 0.050513
[05:59:36.849] iteration 19689: loss: 0.105766, loss_s1: 0.113535, loss_fp: 0.003037, loss_freq: 0.066597
[05:59:37.487] iteration 19690: loss: 0.050446, loss_s1: 0.028163, loss_fp: 0.007273, loss_freq: 0.041140
[05:59:38.105] iteration 19691: loss: 0.077596, loss_s1: 0.032880, loss_fp: 0.002879, loss_freq: 0.022206
[05:59:38.871] iteration 19692: loss: 0.046527, loss_s1: 0.039847, loss_fp: 0.001932, loss_freq: 0.017524
[05:59:39.635] iteration 19693: loss: 0.043199, loss_s1: 0.034013, loss_fp: 0.003144, loss_freq: 0.021860
[05:59:40.384] iteration 19694: loss: 0.048592, loss_s1: 0.044153, loss_fp: 0.004212, loss_freq: 0.011819
[05:59:41.087] iteration 19695: loss: 0.065895, loss_s1: 0.070965, loss_fp: 0.003036, loss_freq: 0.017953
[05:59:41.755] iteration 19696: loss: 0.072804, loss_s1: 0.052723, loss_fp: 0.002918, loss_freq: 0.017337
[05:59:42.370] iteration 19697: loss: 0.040379, loss_s1: 0.018254, loss_fp: 0.002867, loss_freq: 0.016552
[05:59:42.979] iteration 19698: loss: 0.068183, loss_s1: 0.069615, loss_fp: 0.001454, loss_freq: 0.039843
[05:59:43.588] iteration 19699: loss: 0.096300, loss_s1: 0.101631, loss_fp: 0.002197, loss_freq: 0.063133
[05:59:44.203] iteration 19700: loss: 0.069774, loss_s1: 0.038092, loss_fp: 0.007383, loss_freq: 0.028839
[05:59:44.812] iteration 19701: loss: 0.077204, loss_s1: 0.037506, loss_fp: 0.010913, loss_freq: 0.058038
[05:59:45.422] iteration 19702: loss: 0.060764, loss_s1: 0.062097, loss_fp: 0.003612, loss_freq: 0.020746
[05:59:46.031] iteration 19703: loss: 0.073701, loss_s1: 0.053905, loss_fp: 0.015151, loss_freq: 0.019790
[05:59:46.647] iteration 19704: loss: 0.063062, loss_s1: 0.040869, loss_fp: 0.010486, loss_freq: 0.043365
[05:59:47.261] iteration 19705: loss: 0.094544, loss_s1: 0.070738, loss_fp: 0.004304, loss_freq: 0.065412
[05:59:47.872] iteration 19706: loss: 0.037304, loss_s1: 0.021155, loss_fp: 0.000690, loss_freq: 0.010848
[05:59:48.602] iteration 19707: loss: 0.032243, loss_s1: 0.017753, loss_fp: 0.001752, loss_freq: 0.019993
[05:59:49.484] iteration 19708: loss: 0.106308, loss_s1: 0.104756, loss_fp: 0.004890, loss_freq: 0.069128
[05:59:50.310] iteration 19709: loss: 0.055269, loss_s1: 0.033377, loss_fp: 0.004839, loss_freq: 0.043700
[05:59:51.040] iteration 19710: loss: 0.067969, loss_s1: 0.057093, loss_fp: 0.006865, loss_freq: 0.034365
[05:59:51.655] iteration 19711: loss: 0.059474, loss_s1: 0.058608, loss_fp: 0.001758, loss_freq: 0.022097
[05:59:52.274] iteration 19712: loss: 0.051449, loss_s1: 0.040744, loss_fp: 0.007257, loss_freq: 0.030365
[05:59:52.880] iteration 19713: loss: 0.044074, loss_s1: 0.022175, loss_fp: 0.005846, loss_freq: 0.013639
[05:59:53.490] iteration 19714: loss: 0.047694, loss_s1: 0.025064, loss_fp: 0.009496, loss_freq: 0.030013
[05:59:54.105] iteration 19715: loss: 0.034972, loss_s1: 0.021760, loss_fp: 0.001304, loss_freq: 0.014871
[05:59:54.717] iteration 19716: loss: 0.064561, loss_s1: 0.071604, loss_fp: 0.004490, loss_freq: 0.021757
[05:59:55.334] iteration 19717: loss: 0.050332, loss_s1: 0.022168, loss_fp: 0.001660, loss_freq: 0.025715
[05:59:55.947] iteration 19718: loss: 0.058497, loss_s1: 0.042800, loss_fp: 0.006427, loss_freq: 0.030287
[05:59:56.553] iteration 19719: loss: 0.081631, loss_s1: 0.055725, loss_fp: 0.002909, loss_freq: 0.073429
[05:59:57.160] iteration 19720: loss: 0.063743, loss_s1: 0.056548, loss_fp: 0.007400, loss_freq: 0.030162
[05:59:58.112] iteration 19721: loss: 0.073302, loss_s1: 0.078263, loss_fp: 0.002216, loss_freq: 0.031705
[05:59:58.757] iteration 19722: loss: 0.058493, loss_s1: 0.025295, loss_fp: 0.002888, loss_freq: 0.047658
[05:59:59.399] iteration 19723: loss: 0.048462, loss_s1: 0.048529, loss_fp: 0.004254, loss_freq: 0.015908
[06:00:00.021] iteration 19724: loss: 0.052032, loss_s1: 0.040914, loss_fp: 0.002339, loss_freq: 0.023348
[06:00:00.701] iteration 19725: loss: 0.054553, loss_s1: 0.061320, loss_fp: 0.005793, loss_freq: 0.019185
[06:00:01.312] iteration 19726: loss: 0.054303, loss_s1: 0.038038, loss_fp: 0.005648, loss_freq: 0.032026
[06:00:01.922] iteration 19727: loss: 0.073701, loss_s1: 0.037024, loss_fp: 0.003749, loss_freq: 0.063163
[06:00:02.540] iteration 19728: loss: 0.064365, loss_s1: 0.063281, loss_fp: 0.004630, loss_freq: 0.035296
[06:00:03.151] iteration 19729: loss: 0.053256, loss_s1: 0.026030, loss_fp: 0.003524, loss_freq: 0.050241
[06:00:03.850] iteration 19730: loss: 0.061502, loss_s1: 0.059503, loss_fp: 0.005145, loss_freq: 0.022854
[06:00:04.514] iteration 19731: loss: 0.050744, loss_s1: 0.023878, loss_fp: 0.003265, loss_freq: 0.034806
[06:00:05.174] iteration 19732: loss: 0.049999, loss_s1: 0.030274, loss_fp: 0.001429, loss_freq: 0.032728
[06:00:05.837] iteration 19733: loss: 0.068547, loss_s1: 0.059927, loss_fp: 0.001472, loss_freq: 0.046322
[06:00:06.450] iteration 19734: loss: 0.056849, loss_s1: 0.049742, loss_fp: 0.004067, loss_freq: 0.026837
[06:00:07.059] iteration 19735: loss: 0.051644, loss_s1: 0.042726, loss_fp: 0.001717, loss_freq: 0.016484
[06:00:07.666] iteration 19736: loss: 0.081789, loss_s1: 0.090613, loss_fp: 0.006125, loss_freq: 0.027651
[06:00:08.300] iteration 19737: loss: 0.077683, loss_s1: 0.050776, loss_fp: 0.005977, loss_freq: 0.077810
[06:00:08.912] iteration 19738: loss: 0.046002, loss_s1: 0.046720, loss_fp: 0.002339, loss_freq: 0.011133
[06:00:09.523] iteration 19739: loss: 0.059740, loss_s1: 0.056728, loss_fp: 0.005995, loss_freq: 0.026696
[06:00:10.128] iteration 19740: loss: 0.051326, loss_s1: 0.048259, loss_fp: 0.003580, loss_freq: 0.014377
[06:00:10.736] iteration 19741: loss: 0.043908, loss_s1: 0.025461, loss_fp: 0.001783, loss_freq: 0.020042
[06:00:11.348] iteration 19742: loss: 0.060324, loss_s1: 0.061255, loss_fp: 0.007491, loss_freq: 0.026799
[06:00:12.008] iteration 19743: loss: 0.071573, loss_s1: 0.054245, loss_fp: 0.001786, loss_freq: 0.037435
[06:00:12.663] iteration 19744: loss: 0.056669, loss_s1: 0.049561, loss_fp: 0.003568, loss_freq: 0.028600
[06:00:13.325] iteration 19745: loss: 0.071511, loss_s1: 0.049711, loss_fp: 0.006916, loss_freq: 0.050400
[06:00:13.985] iteration 19746: loss: 0.107991, loss_s1: 0.152390, loss_fp: 0.001527, loss_freq: 0.035159
[06:00:14.639] iteration 19747: loss: 0.045143, loss_s1: 0.024133, loss_fp: 0.001702, loss_freq: 0.025547
[06:00:15.300] iteration 19748: loss: 0.072932, loss_s1: 0.060168, loss_fp: 0.002931, loss_freq: 0.028873
[06:00:15.956] iteration 19749: loss: 0.053704, loss_s1: 0.029886, loss_fp: 0.009088, loss_freq: 0.029124
[06:00:16.593] iteration 19750: loss: 0.088452, loss_s1: 0.098475, loss_fp: 0.005895, loss_freq: 0.040490
[06:00:17.202] iteration 19751: loss: 0.079301, loss_s1: 0.045118, loss_fp: 0.001033, loss_freq: 0.058200
[06:00:17.812] iteration 19752: loss: 0.077715, loss_s1: 0.075402, loss_fp: 0.006684, loss_freq: 0.034463
[06:00:18.421] iteration 19753: loss: 0.081828, loss_s1: 0.050593, loss_fp: 0.025206, loss_freq: 0.047651
[06:00:19.024] iteration 19754: loss: 0.057218, loss_s1: 0.055467, loss_fp: 0.005057, loss_freq: 0.017285
[06:00:19.632] iteration 19755: loss: 0.081595, loss_s1: 0.105345, loss_fp: 0.004321, loss_freq: 0.032557
[06:00:20.245] iteration 19756: loss: 0.045705, loss_s1: 0.026939, loss_fp: 0.004512, loss_freq: 0.020824
[06:00:20.910] iteration 19757: loss: 0.047347, loss_s1: 0.033584, loss_fp: 0.003223, loss_freq: 0.023717
[06:00:21.562] iteration 19758: loss: 0.055347, loss_s1: 0.036703, loss_fp: 0.012596, loss_freq: 0.032723
[06:00:22.218] iteration 19759: loss: 0.083793, loss_s1: 0.069295, loss_fp: 0.008152, loss_freq: 0.051206
[06:00:22.853] iteration 19760: loss: 0.084843, loss_s1: 0.099163, loss_fp: 0.003287, loss_freq: 0.035012
[06:00:23.479] iteration 19761: loss: 0.077805, loss_s1: 0.052044, loss_fp: 0.003169, loss_freq: 0.059893
[06:00:24.117] iteration 19762: loss: 0.088982, loss_s1: 0.095127, loss_fp: 0.005182, loss_freq: 0.038241
[06:00:24.728] iteration 19763: loss: 0.067573, loss_s1: 0.088547, loss_fp: 0.003863, loss_freq: 0.020045
[06:00:25.344] iteration 19764: loss: 0.093450, loss_s1: 0.104724, loss_fp: 0.002666, loss_freq: 0.048045
[06:00:25.954] iteration 19765: loss: 0.078832, loss_s1: 0.079769, loss_fp: 0.003305, loss_freq: 0.032220
[06:00:26.572] iteration 19766: loss: 0.079087, loss_s1: 0.102698, loss_fp: 0.002874, loss_freq: 0.023952
[06:00:27.195] iteration 19767: loss: 0.065370, loss_s1: 0.063747, loss_fp: 0.005443, loss_freq: 0.027793
[06:00:27.799] iteration 19768: loss: 0.058608, loss_s1: 0.038395, loss_fp: 0.002935, loss_freq: 0.045102
[06:00:28.415] iteration 19769: loss: 0.049123, loss_s1: 0.036976, loss_fp: 0.008116, loss_freq: 0.014449
[06:00:29.026] iteration 19770: loss: 0.050066, loss_s1: 0.048080, loss_fp: 0.000837, loss_freq: 0.011173
[06:00:29.639] iteration 19771: loss: 0.067495, loss_s1: 0.061996, loss_fp: 0.007033, loss_freq: 0.035763
[06:00:30.245] iteration 19772: loss: 0.047176, loss_s1: 0.039792, loss_fp: 0.001759, loss_freq: 0.023430
[06:00:30.857] iteration 19773: loss: 0.033478, loss_s1: 0.017774, loss_fp: 0.001016, loss_freq: 0.012085
[06:00:31.465] iteration 19774: loss: 0.076472, loss_s1: 0.059859, loss_fp: 0.009501, loss_freq: 0.055682
[06:00:32.071] iteration 19775: loss: 0.060863, loss_s1: 0.023080, loss_fp: 0.007296, loss_freq: 0.058026
[06:00:32.701] iteration 19776: loss: 0.041777, loss_s1: 0.022950, loss_fp: 0.002080, loss_freq: 0.026575
[06:00:33.307] iteration 19777: loss: 0.075625, loss_s1: 0.051455, loss_fp: 0.005043, loss_freq: 0.072057
[06:00:33.917] iteration 19778: loss: 0.049612, loss_s1: 0.025837, loss_fp: 0.005091, loss_freq: 0.022807
[06:00:34.529] iteration 19779: loss: 0.039716, loss_s1: 0.031112, loss_fp: 0.003786, loss_freq: 0.018776
[06:00:35.138] iteration 19780: loss: 0.072158, loss_s1: 0.076577, loss_fp: 0.005887, loss_freq: 0.033692
[06:00:35.751] iteration 19781: loss: 0.027743, loss_s1: 0.021038, loss_fp: 0.002488, loss_freq: 0.006279
[06:00:36.366] iteration 19782: loss: 0.060822, loss_s1: 0.052312, loss_fp: 0.001744, loss_freq: 0.028877
[06:00:36.979] iteration 19783: loss: 0.052762, loss_s1: 0.034448, loss_fp: 0.002569, loss_freq: 0.029224
[06:00:37.604] iteration 19784: loss: 0.059868, loss_s1: 0.068770, loss_fp: 0.002324, loss_freq: 0.016196
[06:00:38.212] iteration 19785: loss: 0.038325, loss_s1: 0.024544, loss_fp: 0.004446, loss_freq: 0.013601
[06:00:38.820] iteration 19786: loss: 0.075587, loss_s1: 0.084233, loss_fp: 0.008468, loss_freq: 0.034332
[06:00:39.431] iteration 19787: loss: 0.045586, loss_s1: 0.024635, loss_fp: 0.002628, loss_freq: 0.017650
[06:00:40.040] iteration 19788: loss: 0.079176, loss_s1: 0.073632, loss_fp: 0.007061, loss_freq: 0.043386
[06:00:40.651] iteration 19789: loss: 0.036343, loss_s1: 0.017896, loss_fp: 0.003414, loss_freq: 0.011438
[06:00:41.271] iteration 19790: loss: 0.049070, loss_s1: 0.044156, loss_fp: 0.002872, loss_freq: 0.027484
[06:00:41.892] iteration 19791: loss: 0.070198, loss_s1: 0.057062, loss_fp: 0.002681, loss_freq: 0.049663
[06:00:42.505] iteration 19792: loss: 0.059272, loss_s1: 0.061483, loss_fp: 0.002270, loss_freq: 0.017495
[06:00:43.124] iteration 19793: loss: 0.057602, loss_s1: 0.060400, loss_fp: 0.006683, loss_freq: 0.020285
[06:00:43.741] iteration 19794: loss: 0.057234, loss_s1: 0.054096, loss_fp: 0.006060, loss_freq: 0.017214
[06:00:44.356] iteration 19795: loss: 0.088051, loss_s1: 0.075051, loss_fp: 0.001967, loss_freq: 0.047466
[06:00:44.968] iteration 19796: loss: 0.077682, loss_s1: 0.048256, loss_fp: 0.016793, loss_freq: 0.045239
[06:00:45.580] iteration 19797: loss: 0.062116, loss_s1: 0.034264, loss_fp: 0.004909, loss_freq: 0.033511
[06:00:46.202] iteration 19798: loss: 0.055160, loss_s1: 0.024571, loss_fp: 0.008246, loss_freq: 0.035693
[06:00:46.814] iteration 19799: loss: 0.052162, loss_s1: 0.035100, loss_fp: 0.007147, loss_freq: 0.037165
[06:00:47.421] iteration 19800: loss: 0.068873, loss_s1: 0.065203, loss_fp: 0.002928, loss_freq: 0.037399
[06:00:50.879] iteration 19800 : mean_dice : 0.729700
[06:00:51.540] iteration 19801: loss: 0.055716, loss_s1: 0.052578, loss_fp: 0.006354, loss_freq: 0.017677
[06:00:52.147] iteration 19802: loss: 0.052338, loss_s1: 0.040877, loss_fp: 0.006086, loss_freq: 0.024311
[06:00:52.765] iteration 19803: loss: 0.071670, loss_s1: 0.057268, loss_fp: 0.004127, loss_freq: 0.041417
[06:00:53.379] iteration 19804: loss: 0.064038, loss_s1: 0.069231, loss_fp: 0.004563, loss_freq: 0.019484
[06:00:53.995] iteration 19805: loss: 0.061197, loss_s1: 0.039088, loss_fp: 0.004418, loss_freq: 0.034257
[06:00:54.604] iteration 19806: loss: 0.066534, loss_s1: 0.057841, loss_fp: 0.003392, loss_freq: 0.025184
[06:00:55.214] iteration 19807: loss: 0.057287, loss_s1: 0.060201, loss_fp: 0.006587, loss_freq: 0.027810
[06:00:55.846] iteration 19808: loss: 0.074570, loss_s1: 0.075837, loss_fp: 0.007460, loss_freq: 0.028037
[06:00:56.460] iteration 19809: loss: 0.070217, loss_s1: 0.072168, loss_fp: 0.005149, loss_freq: 0.031911
[06:00:57.072] iteration 19810: loss: 0.051313, loss_s1: 0.048464, loss_fp: 0.002537, loss_freq: 0.009964
[06:00:57.679] iteration 19811: loss: 0.074710, loss_s1: 0.075394, loss_fp: 0.002764, loss_freq: 0.029456
[06:00:58.292] iteration 19812: loss: 0.041166, loss_s1: 0.037961, loss_fp: 0.003392, loss_freq: 0.012063
[06:00:58.897] iteration 19813: loss: 0.068996, loss_s1: 0.058441, loss_fp: 0.005106, loss_freq: 0.027941
[06:00:59.506] iteration 19814: loss: 0.036530, loss_s1: 0.021935, loss_fp: 0.000590, loss_freq: 0.021355
[06:01:00.113] iteration 19815: loss: 0.049265, loss_s1: 0.043600, loss_fp: 0.001616, loss_freq: 0.016673
[06:01:00.741] iteration 19816: loss: 0.053469, loss_s1: 0.030438, loss_fp: 0.004507, loss_freq: 0.041184
[06:01:01.352] iteration 19817: loss: 0.098895, loss_s1: 0.129132, loss_fp: 0.002971, loss_freq: 0.020417
[06:01:01.967] iteration 19818: loss: 0.071260, loss_s1: 0.028141, loss_fp: 0.002171, loss_freq: 0.072311
[06:01:02.576] iteration 19819: loss: 0.054035, loss_s1: 0.034056, loss_fp: 0.002217, loss_freq: 0.034039
[06:01:03.186] iteration 19820: loss: 0.050497, loss_s1: 0.025438, loss_fp: 0.002884, loss_freq: 0.032958
[06:01:03.843] iteration 19821: loss: 0.065531, loss_s1: 0.071401, loss_fp: 0.005590, loss_freq: 0.032898
[06:01:04.508] iteration 19822: loss: 0.049547, loss_s1: 0.035436, loss_fp: 0.009146, loss_freq: 0.016044
[06:01:05.167] iteration 19823: loss: 0.047708, loss_s1: 0.017448, loss_fp: 0.001973, loss_freq: 0.038749
[06:01:05.786] iteration 19824: loss: 0.044930, loss_s1: 0.026066, loss_fp: 0.003974, loss_freq: 0.027098
[06:01:06.407] iteration 19825: loss: 0.035605, loss_s1: 0.032695, loss_fp: 0.004112, loss_freq: 0.012526
[06:01:07.022] iteration 19826: loss: 0.059993, loss_s1: 0.046254, loss_fp: 0.003799, loss_freq: 0.028821
[06:01:07.631] iteration 19827: loss: 0.040844, loss_s1: 0.026885, loss_fp: 0.006472, loss_freq: 0.012584
[06:01:08.243] iteration 19828: loss: 0.050587, loss_s1: 0.027478, loss_fp: 0.002079, loss_freq: 0.036079
[06:01:08.864] iteration 19829: loss: 0.081714, loss_s1: 0.080170, loss_fp: 0.003791, loss_freq: 0.050475
[06:01:09.472] iteration 19830: loss: 0.059947, loss_s1: 0.036743, loss_fp: 0.002357, loss_freq: 0.050359
[06:01:10.108] iteration 19831: loss: 0.061179, loss_s1: 0.064159, loss_fp: 0.010467, loss_freq: 0.013320
[06:01:10.766] iteration 19832: loss: 0.076191, loss_s1: 0.082337, loss_fp: 0.009024, loss_freq: 0.024879
[06:01:11.453] iteration 19833: loss: 0.061225, loss_s1: 0.070461, loss_fp: 0.000810, loss_freq: 0.024723
[06:01:12.107] iteration 19834: loss: 0.037076, loss_s1: 0.019698, loss_fp: 0.002693, loss_freq: 0.029154
[06:01:12.761] iteration 19835: loss: 0.092599, loss_s1: 0.075360, loss_fp: 0.008597, loss_freq: 0.065880
[06:01:13.415] iteration 19836: loss: 0.055901, loss_s1: 0.042457, loss_fp: 0.005328, loss_freq: 0.035776
[06:01:14.071] iteration 19837: loss: 0.082536, loss_s1: 0.076548, loss_fp: 0.007051, loss_freq: 0.047763
[06:01:14.729] iteration 19838: loss: 0.061972, loss_s1: 0.048266, loss_fp: 0.003834, loss_freq: 0.041403
[06:01:15.356] iteration 19839: loss: 0.065839, loss_s1: 0.042047, loss_fp: 0.005934, loss_freq: 0.052019
[06:01:15.960] iteration 19840: loss: 0.059771, loss_s1: 0.050166, loss_fp: 0.001940, loss_freq: 0.028271
[06:01:16.564] iteration 19841: loss: 0.042220, loss_s1: 0.035925, loss_fp: 0.004095, loss_freq: 0.011777
[06:01:17.215] iteration 19842: loss: 0.053028, loss_s1: 0.050923, loss_fp: 0.003979, loss_freq: 0.029125
[06:01:17.867] iteration 19843: loss: 0.072757, loss_s1: 0.064969, loss_fp: 0.005909, loss_freq: 0.046029
[06:01:18.518] iteration 19844: loss: 0.059670, loss_s1: 0.047884, loss_fp: 0.010674, loss_freq: 0.030882
[06:01:19.118] iteration 19845: loss: 0.093989, loss_s1: 0.089512, loss_fp: 0.002884, loss_freq: 0.054701
[06:01:19.737] iteration 19846: loss: 0.058711, loss_s1: 0.047529, loss_fp: 0.004741, loss_freq: 0.026019
[06:01:20.366] iteration 19847: loss: 0.119907, loss_s1: 0.088301, loss_fp: 0.007422, loss_freq: 0.107694
[06:01:20.970] iteration 19848: loss: 0.059692, loss_s1: 0.042751, loss_fp: 0.007399, loss_freq: 0.023599
[06:01:21.576] iteration 19849: loss: 0.047732, loss_s1: 0.033114, loss_fp: 0.005444, loss_freq: 0.027960
[06:01:22.215] iteration 19850: loss: 0.057185, loss_s1: 0.044542, loss_fp: 0.003274, loss_freq: 0.029649
[06:01:22.824] iteration 19851: loss: 0.065841, loss_s1: 0.089438, loss_fp: 0.005092, loss_freq: 0.010797
[06:01:23.433] iteration 19852: loss: 0.072108, loss_s1: 0.061529, loss_fp: 0.004954, loss_freq: 0.013535
[06:01:24.047] iteration 19853: loss: 0.070604, loss_s1: 0.071800, loss_fp: 0.001499, loss_freq: 0.024765
[06:01:24.729] iteration 19854: loss: 0.051901, loss_s1: 0.054442, loss_fp: 0.001700, loss_freq: 0.020770
[06:01:25.344] iteration 19855: loss: 0.073967, loss_s1: 0.052270, loss_fp: 0.004663, loss_freq: 0.058923
[06:01:25.962] iteration 19856: loss: 0.046137, loss_s1: 0.056160, loss_fp: 0.003868, loss_freq: 0.008869
[06:01:26.572] iteration 19857: loss: 0.061493, loss_s1: 0.039453, loss_fp: 0.008359, loss_freq: 0.017110
[06:01:27.188] iteration 19858: loss: 0.046730, loss_s1: 0.036558, loss_fp: 0.007758, loss_freq: 0.020678
[06:01:27.800] iteration 19859: loss: 0.140661, loss_s1: 0.169279, loss_fp: 0.006809, loss_freq: 0.070023
[06:01:28.418] iteration 19860: loss: 0.101500, loss_s1: 0.124413, loss_fp: 0.004088, loss_freq: 0.050868
[06:01:29.035] iteration 19861: loss: 0.097955, loss_s1: 0.121782, loss_fp: 0.007252, loss_freq: 0.029088
[06:01:29.661] iteration 19862: loss: 0.059397, loss_s1: 0.055463, loss_fp: 0.005418, loss_freq: 0.023688
[06:01:30.278] iteration 19863: loss: 0.052161, loss_s1: 0.051892, loss_fp: 0.007136, loss_freq: 0.015717
[06:01:30.927] iteration 19864: loss: 0.044611, loss_s1: 0.027252, loss_fp: 0.003225, loss_freq: 0.021378
[06:01:31.583] iteration 19865: loss: 0.029647, loss_s1: 0.014829, loss_fp: 0.002342, loss_freq: 0.014362
[06:01:32.222] iteration 19866: loss: 0.065152, loss_s1: 0.060509, loss_fp: 0.009973, loss_freq: 0.024525
[06:01:32.863] iteration 19867: loss: 0.052206, loss_s1: 0.045370, loss_fp: 0.002868, loss_freq: 0.023752
[06:01:33.475] iteration 19868: loss: 0.081426, loss_s1: 0.083482, loss_fp: 0.005194, loss_freq: 0.044462
[06:01:34.091] iteration 19869: loss: 0.058994, loss_s1: 0.030052, loss_fp: 0.002206, loss_freq: 0.063203
[06:01:34.706] iteration 19870: loss: 0.088060, loss_s1: 0.057308, loss_fp: 0.005827, loss_freq: 0.060178
[06:01:35.393] iteration 19871: loss: 0.110216, loss_s1: 0.067726, loss_fp: 0.005915, loss_freq: 0.054022
[06:01:36.060] iteration 19872: loss: 0.089754, loss_s1: 0.098093, loss_fp: 0.005972, loss_freq: 0.042910
[06:01:36.711] iteration 19873: loss: 0.079444, loss_s1: 0.051811, loss_fp: 0.007143, loss_freq: 0.058604
[06:01:37.361] iteration 19874: loss: 0.081028, loss_s1: 0.046903, loss_fp: 0.005669, loss_freq: 0.065491
[06:01:38.036] iteration 19875: loss: 0.075462, loss_s1: 0.087092, loss_fp: 0.004221, loss_freq: 0.024570
[06:01:38.683] iteration 19876: loss: 0.044609, loss_s1: 0.033557, loss_fp: 0.001703, loss_freq: 0.017698
[06:01:39.335] iteration 19877: loss: 0.061463, loss_s1: 0.043558, loss_fp: 0.006864, loss_freq: 0.040350
[06:01:39.987] iteration 19878: loss: 0.080046, loss_s1: 0.074627, loss_fp: 0.001499, loss_freq: 0.049519
[06:01:40.693] iteration 19879: loss: 0.084378, loss_s1: 0.087605, loss_fp: 0.006335, loss_freq: 0.043429
[06:01:41.315] iteration 19880: loss: 0.093609, loss_s1: 0.083729, loss_fp: 0.003998, loss_freq: 0.063281
[06:01:41.918] iteration 19881: loss: 0.036975, loss_s1: 0.022073, loss_fp: 0.005925, loss_freq: 0.017006
[06:01:42.533] iteration 19882: loss: 0.080489, loss_s1: 0.095050, loss_fp: 0.003355, loss_freq: 0.039317
[06:01:43.138] iteration 19883: loss: 0.056601, loss_s1: 0.031724, loss_fp: 0.004240, loss_freq: 0.021059
[06:01:43.746] iteration 19884: loss: 0.088624, loss_s1: 0.082065, loss_fp: 0.001712, loss_freq: 0.060520
[06:01:44.360] iteration 19885: loss: 0.061792, loss_s1: 0.050073, loss_fp: 0.002704, loss_freq: 0.012511
[06:01:45.076] iteration 19886: loss: 0.063857, loss_s1: 0.077057, loss_fp: 0.001692, loss_freq: 0.015224
[06:01:45.775] iteration 19887: loss: 0.080983, loss_s1: 0.059569, loss_fp: 0.011213, loss_freq: 0.030421
[06:01:46.394] iteration 19888: loss: 0.086850, loss_s1: 0.077665, loss_fp: 0.003062, loss_freq: 0.048833
[06:01:46.998] iteration 19889: loss: 0.064576, loss_s1: 0.060837, loss_fp: 0.002538, loss_freq: 0.035032
[06:01:47.605] iteration 19890: loss: 0.061059, loss_s1: 0.047734, loss_fp: 0.002269, loss_freq: 0.024590
[06:01:48.561] iteration 19891: loss: 0.039743, loss_s1: 0.022014, loss_fp: 0.000594, loss_freq: 0.010280
[06:01:49.166] iteration 19892: loss: 0.052230, loss_s1: 0.028574, loss_fp: 0.004327, loss_freq: 0.029930
[06:01:49.770] iteration 19893: loss: 0.051502, loss_s1: 0.055016, loss_fp: 0.002579, loss_freq: 0.014951
[06:01:50.381] iteration 19894: loss: 0.049346, loss_s1: 0.032179, loss_fp: 0.001512, loss_freq: 0.023070
[06:01:50.998] iteration 19895: loss: 0.068740, loss_s1: 0.051911, loss_fp: 0.005346, loss_freq: 0.051582
[06:01:51.605] iteration 19896: loss: 0.085341, loss_s1: 0.088369, loss_fp: 0.002822, loss_freq: 0.034632
[06:01:52.219] iteration 19897: loss: 0.057898, loss_s1: 0.020740, loss_fp: 0.004457, loss_freq: 0.056774
[06:01:52.834] iteration 19898: loss: 0.043348, loss_s1: 0.034691, loss_fp: 0.002324, loss_freq: 0.017914
[06:01:53.495] iteration 19899: loss: 0.034910, loss_s1: 0.024132, loss_fp: 0.002784, loss_freq: 0.021335
[06:01:54.109] iteration 19900: loss: 0.081804, loss_s1: 0.074818, loss_fp: 0.003878, loss_freq: 0.046269
[06:01:54.721] iteration 19901: loss: 0.055121, loss_s1: 0.026375, loss_fp: 0.004680, loss_freq: 0.043355
[06:01:55.332] iteration 19902: loss: 0.058040, loss_s1: 0.027705, loss_fp: 0.006366, loss_freq: 0.041932
[06:01:55.944] iteration 19903: loss: 0.035703, loss_s1: 0.013778, loss_fp: 0.002415, loss_freq: 0.020341
[06:01:56.550] iteration 19904: loss: 0.077957, loss_s1: 0.069586, loss_fp: 0.002103, loss_freq: 0.045825
[06:01:57.156] iteration 19905: loss: 0.073224, loss_s1: 0.086914, loss_fp: 0.002968, loss_freq: 0.017143
[06:01:57.764] iteration 19906: loss: 0.045040, loss_s1: 0.040833, loss_fp: 0.001170, loss_freq: 0.013484
[06:01:58.376] iteration 19907: loss: 0.083366, loss_s1: 0.049649, loss_fp: 0.001864, loss_freq: 0.093564
[06:01:59.062] iteration 19908: loss: 0.041950, loss_s1: 0.023624, loss_fp: 0.001134, loss_freq: 0.012244
[06:01:59.725] iteration 19909: loss: 0.071323, loss_s1: 0.092044, loss_fp: 0.006690, loss_freq: 0.012641
[06:02:00.380] iteration 19910: loss: 0.076654, loss_s1: 0.093028, loss_fp: 0.002471, loss_freq: 0.017333
[06:02:01.037] iteration 19911: loss: 0.040200, loss_s1: 0.021282, loss_fp: 0.002676, loss_freq: 0.019917
[06:02:01.722] iteration 19912: loss: 0.053817, loss_s1: 0.041187, loss_fp: 0.001797, loss_freq: 0.031287
[06:02:02.333] iteration 19913: loss: 0.053796, loss_s1: 0.031526, loss_fp: 0.002297, loss_freq: 0.029774
[06:02:02.944] iteration 19914: loss: 0.066395, loss_s1: 0.085447, loss_fp: 0.004140, loss_freq: 0.015412
[06:02:03.553] iteration 19915: loss: 0.038859, loss_s1: 0.019258, loss_fp: 0.001574, loss_freq: 0.026651
[06:02:04.163] iteration 19916: loss: 0.066976, loss_s1: 0.060825, loss_fp: 0.006000, loss_freq: 0.033771
[06:02:04.772] iteration 19917: loss: 0.056900, loss_s1: 0.056148, loss_fp: 0.002011, loss_freq: 0.021641
[06:02:05.376] iteration 19918: loss: 0.074402, loss_s1: 0.075907, loss_fp: 0.001135, loss_freq: 0.028532
[06:02:05.981] iteration 19919: loss: 0.049297, loss_s1: 0.034308, loss_fp: 0.002477, loss_freq: 0.026462
[06:02:06.591] iteration 19920: loss: 0.094914, loss_s1: 0.095855, loss_fp: 0.003117, loss_freq: 0.040659
[06:02:07.198] iteration 19921: loss: 0.095365, loss_s1: 0.055605, loss_fp: 0.005712, loss_freq: 0.076996
[06:02:07.802] iteration 19922: loss: 0.063732, loss_s1: 0.026767, loss_fp: 0.002754, loss_freq: 0.060838
[06:02:08.410] iteration 19923: loss: 0.082689, loss_s1: 0.087578, loss_fp: 0.007156, loss_freq: 0.037148
[06:02:09.014] iteration 19924: loss: 0.053263, loss_s1: 0.032389, loss_fp: 0.004815, loss_freq: 0.026349
[06:02:09.618] iteration 19925: loss: 0.046362, loss_s1: 0.043812, loss_fp: 0.001552, loss_freq: 0.027791
[06:02:10.229] iteration 19926: loss: 0.074616, loss_s1: 0.039317, loss_fp: 0.001614, loss_freq: 0.021619
[06:02:10.842] iteration 19927: loss: 0.066673, loss_s1: 0.059859, loss_fp: 0.003708, loss_freq: 0.029461
[06:02:11.461] iteration 19928: loss: 0.046454, loss_s1: 0.030667, loss_fp: 0.002869, loss_freq: 0.028981
[06:02:12.080] iteration 19929: loss: 0.081496, loss_s1: 0.082788, loss_fp: 0.002792, loss_freq: 0.026819
[06:02:12.692] iteration 19930: loss: 0.059560, loss_s1: 0.061274, loss_fp: 0.003498, loss_freq: 0.028819
[06:02:13.303] iteration 19931: loss: 0.097898, loss_s1: 0.134078, loss_fp: 0.002546, loss_freq: 0.016440
[06:02:13.959] iteration 19932: loss: 0.066451, loss_s1: 0.046432, loss_fp: 0.002897, loss_freq: 0.041425
[06:02:14.614] iteration 19933: loss: 0.092722, loss_s1: 0.087277, loss_fp: 0.001969, loss_freq: 0.069083
[06:02:15.249] iteration 19934: loss: 0.094490, loss_s1: 0.102857, loss_fp: 0.001976, loss_freq: 0.056805
[06:02:15.851] iteration 19935: loss: 0.065748, loss_s1: 0.050096, loss_fp: 0.004487, loss_freq: 0.039576
[06:02:16.459] iteration 19936: loss: 0.045442, loss_s1: 0.040664, loss_fp: 0.002544, loss_freq: 0.013386
[06:02:17.071] iteration 19937: loss: 0.063565, loss_s1: 0.058707, loss_fp: 0.002287, loss_freq: 0.033611
[06:02:17.680] iteration 19938: loss: 0.066119, loss_s1: 0.055666, loss_fp: 0.002818, loss_freq: 0.040901
[06:02:18.293] iteration 19939: loss: 0.040710, loss_s1: 0.033403, loss_fp: 0.000689, loss_freq: 0.008780
[06:02:18.898] iteration 19940: loss: 0.041426, loss_s1: 0.033438, loss_fp: 0.000597, loss_freq: 0.012155
[06:02:19.504] iteration 19941: loss: 0.051467, loss_s1: 0.044067, loss_fp: 0.004581, loss_freq: 0.018133
[06:02:20.151] iteration 19942: loss: 0.040404, loss_s1: 0.037724, loss_fp: 0.001373, loss_freq: 0.017325
[06:02:20.763] iteration 19943: loss: 0.038459, loss_s1: 0.011658, loss_fp: 0.002767, loss_freq: 0.030539
[06:02:21.377] iteration 19944: loss: 0.081088, loss_s1: 0.061710, loss_fp: 0.025071, loss_freq: 0.038501
[06:02:21.985] iteration 19945: loss: 0.070076, loss_s1: 0.051398, loss_fp: 0.003130, loss_freq: 0.049017
[06:02:22.598] iteration 19946: loss: 0.031676, loss_s1: 0.009218, loss_fp: 0.001399, loss_freq: 0.017665
[06:02:23.212] iteration 19947: loss: 0.043721, loss_s1: 0.040218, loss_fp: 0.001544, loss_freq: 0.024481
[06:02:23.822] iteration 19948: loss: 0.049565, loss_s1: 0.032637, loss_fp: 0.002049, loss_freq: 0.020784
[06:02:24.460] iteration 19949: loss: 0.053959, loss_s1: 0.025332, loss_fp: 0.001565, loss_freq: 0.034861
[06:02:25.068] iteration 19950: loss: 0.068332, loss_s1: 0.055140, loss_fp: 0.003576, loss_freq: 0.046332
[06:02:25.678] iteration 19951: loss: 0.027457, loss_s1: 0.025763, loss_fp: 0.001123, loss_freq: 0.004909
[06:02:26.421] iteration 19952: loss: 0.117036, loss_s1: 0.073715, loss_fp: 0.001762, loss_freq: 0.061049
[06:02:27.077] iteration 19953: loss: 0.051322, loss_s1: 0.041137, loss_fp: 0.002578, loss_freq: 0.017861
[06:02:27.731] iteration 19954: loss: 0.050326, loss_s1: 0.035904, loss_fp: 0.002772, loss_freq: 0.017271
[06:02:28.385] iteration 19955: loss: 0.052105, loss_s1: 0.039133, loss_fp: 0.004218, loss_freq: 0.020349
[06:02:29.018] iteration 19956: loss: 0.034282, loss_s1: 0.020232, loss_fp: 0.003032, loss_freq: 0.020233
[06:02:29.627] iteration 19957: loss: 0.062525, loss_s1: 0.060059, loss_fp: 0.003193, loss_freq: 0.027206
[06:02:30.240] iteration 19958: loss: 0.118932, loss_s1: 0.050849, loss_fp: 0.004826, loss_freq: 0.089536
[06:02:30.861] iteration 19959: loss: 0.043467, loss_s1: 0.014808, loss_fp: 0.002684, loss_freq: 0.034982
[06:02:31.473] iteration 19960: loss: 0.082189, loss_s1: 0.074137, loss_fp: 0.010134, loss_freq: 0.054249
[06:02:32.079] iteration 19961: loss: 0.063748, loss_s1: 0.045747, loss_fp: 0.011608, loss_freq: 0.036883
[06:02:32.696] iteration 19962: loss: 0.059414, loss_s1: 0.051042, loss_fp: 0.004464, loss_freq: 0.028982
[06:02:33.307] iteration 19963: loss: 0.056724, loss_s1: 0.050088, loss_fp: 0.005775, loss_freq: 0.030782
[06:02:33.916] iteration 19964: loss: 0.055681, loss_s1: 0.037269, loss_fp: 0.013312, loss_freq: 0.024627
[06:02:34.520] iteration 19965: loss: 0.042377, loss_s1: 0.025635, loss_fp: 0.001845, loss_freq: 0.028044
[06:02:35.122] iteration 19966: loss: 0.069744, loss_s1: 0.049796, loss_fp: 0.002809, loss_freq: 0.046386
[06:02:35.728] iteration 19967: loss: 0.076253, loss_s1: 0.052706, loss_fp: 0.009771, loss_freq: 0.049897
[06:02:36.333] iteration 19968: loss: 0.085391, loss_s1: 0.101778, loss_fp: 0.010812, loss_freq: 0.022538
[06:02:36.937] iteration 19969: loss: 0.042136, loss_s1: 0.029462, loss_fp: 0.006249, loss_freq: 0.027311
[06:02:37.538] iteration 19970: loss: 0.065908, loss_s1: 0.030319, loss_fp: 0.005896, loss_freq: 0.035733
[06:02:38.139] iteration 19971: loss: 0.058683, loss_s1: 0.018501, loss_fp: 0.005755, loss_freq: 0.029675
[06:02:38.742] iteration 19972: loss: 0.046948, loss_s1: 0.033717, loss_fp: 0.006959, loss_freq: 0.020135
[06:02:39.353] iteration 19973: loss: 0.058082, loss_s1: 0.052388, loss_fp: 0.006962, loss_freq: 0.017119
[06:02:40.048] iteration 19974: loss: 0.044722, loss_s1: 0.032466, loss_fp: 0.003643, loss_freq: 0.009435
[06:02:40.717] iteration 19975: loss: 0.068240, loss_s1: 0.058796, loss_fp: 0.011734, loss_freq: 0.028537
[06:02:41.393] iteration 19976: loss: 0.074224, loss_s1: 0.063541, loss_fp: 0.008190, loss_freq: 0.020899
[06:02:42.068] iteration 19977: loss: 0.073761, loss_s1: 0.076861, loss_fp: 0.003640, loss_freq: 0.045197
[06:02:42.742] iteration 19978: loss: 0.066474, loss_s1: 0.078968, loss_fp: 0.001428, loss_freq: 0.012179
[06:02:43.388] iteration 19979: loss: 0.060160, loss_s1: 0.054812, loss_fp: 0.010909, loss_freq: 0.021736
[06:02:44.008] iteration 19980: loss: 0.078575, loss_s1: 0.098418, loss_fp: 0.003805, loss_freq: 0.012819
[06:02:44.632] iteration 19981: loss: 0.063437, loss_s1: 0.071391, loss_fp: 0.001345, loss_freq: 0.022873
[06:02:45.245] iteration 19982: loss: 0.049243, loss_s1: 0.030251, loss_fp: 0.003952, loss_freq: 0.035102
[06:02:45.856] iteration 19983: loss: 0.052621, loss_s1: 0.027906, loss_fp: 0.002234, loss_freq: 0.029766
[06:02:46.464] iteration 19984: loss: 0.052450, loss_s1: 0.044498, loss_fp: 0.001386, loss_freq: 0.034166
[06:02:47.069] iteration 19985: loss: 0.052062, loss_s1: 0.039171, loss_fp: 0.002924, loss_freq: 0.028937
[06:02:47.679] iteration 19986: loss: 0.049946, loss_s1: 0.030771, loss_fp: 0.002297, loss_freq: 0.026218
[06:02:48.354] iteration 19987: loss: 0.067521, loss_s1: 0.041339, loss_fp: 0.002863, loss_freq: 0.053663
[06:02:48.976] iteration 19988: loss: 0.086428, loss_s1: 0.049629, loss_fp: 0.009769, loss_freq: 0.062737
[06:02:49.584] iteration 19989: loss: 0.056271, loss_s1: 0.042772, loss_fp: 0.005767, loss_freq: 0.023694
[06:02:50.195] iteration 19990: loss: 0.065930, loss_s1: 0.057316, loss_fp: 0.001766, loss_freq: 0.032662
[06:02:50.805] iteration 19991: loss: 0.046120, loss_s1: 0.028946, loss_fp: 0.006544, loss_freq: 0.028658
[06:02:51.411] iteration 19992: loss: 0.043428, loss_s1: 0.027267, loss_fp: 0.002186, loss_freq: 0.015086
[06:02:52.026] iteration 19993: loss: 0.041680, loss_s1: 0.027072, loss_fp: 0.001617, loss_freq: 0.026738
[06:02:52.637] iteration 19994: loss: 0.046026, loss_s1: 0.026066, loss_fp: 0.006498, loss_freq: 0.022046
[06:02:53.253] iteration 19995: loss: 0.029029, loss_s1: 0.016662, loss_fp: 0.001549, loss_freq: 0.015220
[06:02:53.898] iteration 19996: loss: 0.069107, loss_s1: 0.062245, loss_fp: 0.002294, loss_freq: 0.026513
[06:02:54.545] iteration 19997: loss: 0.043301, loss_s1: 0.036800, loss_fp: 0.003954, loss_freq: 0.016218
[06:02:55.152] iteration 19998: loss: 0.052075, loss_s1: 0.048353, loss_fp: 0.003271, loss_freq: 0.024868
[06:02:55.763] iteration 19999: loss: 0.062049, loss_s1: 0.031207, loss_fp: 0.006426, loss_freq: 0.054120
[06:02:56.401] iteration 20000: loss: 0.043816, loss_s1: 0.022518, loss_fp: 0.004961, loss_freq: 0.028223
[06:02:59.842] iteration 20000 : mean_dice : 0.746055
[06:03:00.507] iteration 20001: loss: 0.048134, loss_s1: 0.038198, loss_fp: 0.002935, loss_freq: 0.019253
[06:03:01.110] iteration 20002: loss: 0.052822, loss_s1: 0.036578, loss_fp: 0.002442, loss_freq: 0.030014
[06:03:01.719] iteration 20003: loss: 0.048313, loss_s1: 0.045833, loss_fp: 0.005017, loss_freq: 0.015064
[06:03:02.320] iteration 20004: loss: 0.031240, loss_s1: 0.019838, loss_fp: 0.002389, loss_freq: 0.011423
[06:03:02.918] iteration 20005: loss: 0.083599, loss_s1: 0.065593, loss_fp: 0.006768, loss_freq: 0.058454
[06:03:03.519] iteration 20006: loss: 0.068709, loss_s1: 0.055495, loss_fp: 0.009928, loss_freq: 0.036929
[06:03:04.125] iteration 20007: loss: 0.046454, loss_s1: 0.034713, loss_fp: 0.001959, loss_freq: 0.021986
[06:03:04.732] iteration 20008: loss: 0.071827, loss_s1: 0.060238, loss_fp: 0.013420, loss_freq: 0.038699
[06:03:05.339] iteration 20009: loss: 0.075254, loss_s1: 0.061549, loss_fp: 0.007392, loss_freq: 0.042814
[06:03:05.941] iteration 20010: loss: 0.054699, loss_s1: 0.061391, loss_fp: 0.006609, loss_freq: 0.008098
[06:03:06.547] iteration 20011: loss: 0.055752, loss_s1: 0.064630, loss_fp: 0.001940, loss_freq: 0.008852
[06:03:07.165] iteration 20012: loss: 0.080266, loss_s1: 0.083586, loss_fp: 0.003336, loss_freq: 0.039066
[06:03:07.819] iteration 20013: loss: 0.097620, loss_s1: 0.104731, loss_fp: 0.025982, loss_freq: 0.027992
[06:03:08.481] iteration 20014: loss: 0.057543, loss_s1: 0.033768, loss_fp: 0.007045, loss_freq: 0.040380
[06:03:09.145] iteration 20015: loss: 0.074677, loss_s1: 0.075698, loss_fp: 0.006641, loss_freq: 0.030940
[06:03:09.802] iteration 20016: loss: 0.073690, loss_s1: 0.032717, loss_fp: 0.003102, loss_freq: 0.033187
[06:03:10.474] iteration 20017: loss: 0.065718, loss_s1: 0.069656, loss_fp: 0.005332, loss_freq: 0.026442
[06:03:11.141] iteration 20018: loss: 0.047999, loss_s1: 0.036736, loss_fp: 0.003702, loss_freq: 0.011383
[06:03:11.784] iteration 20019: loss: 0.058761, loss_s1: 0.052578, loss_fp: 0.003491, loss_freq: 0.025394
[06:03:12.401] iteration 20020: loss: 0.145766, loss_s1: 0.121655, loss_fp: 0.038442, loss_freq: 0.090529
[06:03:13.014] iteration 20021: loss: 0.045856, loss_s1: 0.033224, loss_fp: 0.006683, loss_freq: 0.016992
[06:03:13.628] iteration 20022: loss: 0.079557, loss_s1: 0.078274, loss_fp: 0.002317, loss_freq: 0.009855
[06:03:14.236] iteration 20023: loss: 0.088242, loss_s1: 0.099292, loss_fp: 0.005831, loss_freq: 0.034122
[06:03:14.856] iteration 20024: loss: 0.068978, loss_s1: 0.078698, loss_fp: 0.005470, loss_freq: 0.027422
[06:03:15.470] iteration 20025: loss: 0.040090, loss_s1: 0.017792, loss_fp: 0.002153, loss_freq: 0.026000
[06:03:16.083] iteration 20026: loss: 0.024961, loss_s1: 0.014605, loss_fp: 0.003932, loss_freq: 0.005697
[06:03:16.701] iteration 20027: loss: 0.072011, loss_s1: 0.075811, loss_fp: 0.003660, loss_freq: 0.022795
[06:03:17.313] iteration 20028: loss: 0.063503, loss_s1: 0.039583, loss_fp: 0.003903, loss_freq: 0.058086
[06:03:17.931] iteration 20029: loss: 0.114091, loss_s1: 0.120568, loss_fp: 0.009389, loss_freq: 0.065601
[06:03:18.549] iteration 20030: loss: 0.065672, loss_s1: 0.082720, loss_fp: 0.009826, loss_freq: 0.018642
[06:03:19.163] iteration 20031: loss: 0.089986, loss_s1: 0.079668, loss_fp: 0.004796, loss_freq: 0.055506
[06:03:19.778] iteration 20032: loss: 0.050449, loss_s1: 0.023881, loss_fp: 0.006280, loss_freq: 0.033278
[06:03:20.393] iteration 20033: loss: 0.054211, loss_s1: 0.048305, loss_fp: 0.004104, loss_freq: 0.021896
[06:03:21.007] iteration 20034: loss: 0.054040, loss_s1: 0.058231, loss_fp: 0.002260, loss_freq: 0.011990
[06:03:21.670] iteration 20035: loss: 0.058245, loss_s1: 0.059831, loss_fp: 0.006146, loss_freq: 0.018429
[06:03:22.347] iteration 20036: loss: 0.063617, loss_s1: 0.061573, loss_fp: 0.005311, loss_freq: 0.020337
[06:03:23.006] iteration 20037: loss: 0.073680, loss_s1: 0.063376, loss_fp: 0.006729, loss_freq: 0.043067
[06:03:23.663] iteration 20038: loss: 0.062894, loss_s1: 0.066344, loss_fp: 0.004327, loss_freq: 0.025262
[06:03:24.320] iteration 20039: loss: 0.059358, loss_s1: 0.059588, loss_fp: 0.003358, loss_freq: 0.032549
[06:03:24.976] iteration 20040: loss: 0.068383, loss_s1: 0.046949, loss_fp: 0.004262, loss_freq: 0.029948
[06:03:25.603] iteration 20041: loss: 0.086262, loss_s1: 0.065995, loss_fp: 0.022449, loss_freq: 0.044741
[06:03:26.208] iteration 20042: loss: 0.094039, loss_s1: 0.103051, loss_fp: 0.006895, loss_freq: 0.045933
[06:03:26.856] iteration 20043: loss: 0.074118, loss_s1: 0.049174, loss_fp: 0.015891, loss_freq: 0.054695
[06:03:27.510] iteration 20044: loss: 0.061245, loss_s1: 0.043877, loss_fp: 0.012520, loss_freq: 0.032010
[06:03:28.194] iteration 20045: loss: 0.058260, loss_s1: 0.036064, loss_fp: 0.003051, loss_freq: 0.036030
[06:03:28.827] iteration 20046: loss: 0.036161, loss_s1: 0.016849, loss_fp: 0.001964, loss_freq: 0.019619
[06:03:29.463] iteration 20047: loss: 0.038600, loss_s1: 0.020741, loss_fp: 0.001928, loss_freq: 0.028197
[06:03:30.096] iteration 20048: loss: 0.070480, loss_s1: 0.054767, loss_fp: 0.007242, loss_freq: 0.044248
[06:03:30.727] iteration 20049: loss: 0.077798, loss_s1: 0.091737, loss_fp: 0.002304, loss_freq: 0.031333
[06:03:31.353] iteration 20050: loss: 0.086034, loss_s1: 0.089793, loss_fp: 0.004741, loss_freq: 0.038529
[06:03:31.985] iteration 20051: loss: 0.055800, loss_s1: 0.054966, loss_fp: 0.003454, loss_freq: 0.015568
[06:03:32.691] iteration 20052: loss: 0.048813, loss_s1: 0.025573, loss_fp: 0.008957, loss_freq: 0.036481
[06:03:33.387] iteration 20053: loss: 0.054379, loss_s1: 0.019756, loss_fp: 0.014231, loss_freq: 0.030781
[06:03:34.047] iteration 20054: loss: 0.046252, loss_s1: 0.042308, loss_fp: 0.002434, loss_freq: 0.017940
[06:03:34.706] iteration 20055: loss: 0.033043, loss_s1: 0.026210, loss_fp: 0.000759, loss_freq: 0.006004
[06:03:35.367] iteration 20056: loss: 0.082971, loss_s1: 0.073195, loss_fp: 0.002670, loss_freq: 0.064286
[06:03:36.002] iteration 20057: loss: 0.047280, loss_s1: 0.033380, loss_fp: 0.002088, loss_freq: 0.021627
[06:03:36.614] iteration 20058: loss: 0.116271, loss_s1: 0.123526, loss_fp: 0.005440, loss_freq: 0.056925
[06:03:37.221] iteration 20059: loss: 0.065365, loss_s1: 0.062585, loss_fp: 0.003892, loss_freq: 0.037631
[06:03:37.832] iteration 20060: loss: 0.054442, loss_s1: 0.057291, loss_fp: 0.003967, loss_freq: 0.014448
[06:03:38.762] iteration 20061: loss: 0.044510, loss_s1: 0.028548, loss_fp: 0.001423, loss_freq: 0.019384
[06:03:39.380] iteration 20062: loss: 0.056776, loss_s1: 0.042693, loss_fp: 0.002619, loss_freq: 0.025071
[06:03:39.994] iteration 20063: loss: 0.042425, loss_s1: 0.039919, loss_fp: 0.004855, loss_freq: 0.011816
[06:03:40.604] iteration 20064: loss: 0.039645, loss_s1: 0.034633, loss_fp: 0.003015, loss_freq: 0.010036
[06:03:41.210] iteration 20065: loss: 0.064094, loss_s1: 0.040295, loss_fp: 0.007043, loss_freq: 0.043806
[06:03:41.824] iteration 20066: loss: 0.059898, loss_s1: 0.058215, loss_fp: 0.002503, loss_freq: 0.025931
[06:03:42.436] iteration 20067: loss: 0.052194, loss_s1: 0.024972, loss_fp: 0.004673, loss_freq: 0.042995
[06:03:43.052] iteration 20068: loss: 0.054983, loss_s1: 0.029521, loss_fp: 0.008783, loss_freq: 0.041803
[06:03:43.666] iteration 20069: loss: 0.035983, loss_s1: 0.028384, loss_fp: 0.003334, loss_freq: 0.016452
[06:03:44.345] iteration 20070: loss: 0.073760, loss_s1: 0.072699, loss_fp: 0.005399, loss_freq: 0.025619
[06:03:44.989] iteration 20071: loss: 0.047873, loss_s1: 0.036811, loss_fp: 0.004715, loss_freq: 0.016325
[06:03:45.636] iteration 20072: loss: 0.102095, loss_s1: 0.093380, loss_fp: 0.000675, loss_freq: 0.077610
[06:03:46.308] iteration 20073: loss: 0.046355, loss_s1: 0.033817, loss_fp: 0.003526, loss_freq: 0.021530
[06:03:46.974] iteration 20074: loss: 0.065871, loss_s1: 0.060218, loss_fp: 0.010603, loss_freq: 0.030574
[06:03:47.637] iteration 20075: loss: 0.051815, loss_s1: 0.033190, loss_fp: 0.001343, loss_freq: 0.027346
[06:03:48.294] iteration 20076: loss: 0.063087, loss_s1: 0.076662, loss_fp: 0.002303, loss_freq: 0.011004
[06:03:48.909] iteration 20077: loss: 0.083680, loss_s1: 0.086867, loss_fp: 0.003901, loss_freq: 0.054268
[06:03:49.572] iteration 20078: loss: 0.029329, loss_s1: 0.023547, loss_fp: 0.001777, loss_freq: 0.007504
[06:03:50.500] iteration 20079: loss: 0.058713, loss_s1: 0.051962, loss_fp: 0.010285, loss_freq: 0.023948
[06:03:51.322] iteration 20080: loss: 0.071972, loss_s1: 0.086078, loss_fp: 0.002065, loss_freq: 0.012401
[06:03:52.043] iteration 20081: loss: 0.080886, loss_s1: 0.058933, loss_fp: 0.002828, loss_freq: 0.052996
[06:03:52.695] iteration 20082: loss: 0.059016, loss_s1: 0.035317, loss_fp: 0.008168, loss_freq: 0.046697
[06:03:53.347] iteration 20083: loss: 0.073299, loss_s1: 0.051641, loss_fp: 0.004427, loss_freq: 0.027608
[06:03:53.991] iteration 20084: loss: 0.043445, loss_s1: 0.043533, loss_fp: 0.004022, loss_freq: 0.012291
[06:03:54.599] iteration 20085: loss: 0.103568, loss_s1: 0.136456, loss_fp: 0.002139, loss_freq: 0.028898
[06:03:55.205] iteration 20086: loss: 0.059961, loss_s1: 0.059843, loss_fp: 0.004768, loss_freq: 0.028379
[06:03:55.813] iteration 20087: loss: 0.040939, loss_s1: 0.013298, loss_fp: 0.003854, loss_freq: 0.029223
[06:03:56.420] iteration 20088: loss: 0.117808, loss_s1: 0.116283, loss_fp: 0.004132, loss_freq: 0.057172
[06:03:57.037] iteration 20089: loss: 0.043760, loss_s1: 0.039026, loss_fp: 0.004579, loss_freq: 0.015837
[06:03:57.644] iteration 20090: loss: 0.080699, loss_s1: 0.066185, loss_fp: 0.003293, loss_freq: 0.058327
[06:03:58.251] iteration 20091: loss: 0.069798, loss_s1: 0.038278, loss_fp: 0.007481, loss_freq: 0.052124
[06:03:58.858] iteration 20092: loss: 0.093859, loss_s1: 0.084519, loss_fp: 0.004227, loss_freq: 0.061390
[06:03:59.463] iteration 20093: loss: 0.056690, loss_s1: 0.045856, loss_fp: 0.003467, loss_freq: 0.031063
[06:04:00.073] iteration 20094: loss: 0.037352, loss_s1: 0.032382, loss_fp: 0.002527, loss_freq: 0.013764
[06:04:00.678] iteration 20095: loss: 0.043434, loss_s1: 0.055063, loss_fp: 0.001061, loss_freq: 0.012647
[06:04:01.327] iteration 20096: loss: 0.063160, loss_s1: 0.042658, loss_fp: 0.004216, loss_freq: 0.021560
[06:04:01.977] iteration 20097: loss: 0.058193, loss_s1: 0.048484, loss_fp: 0.003074, loss_freq: 0.028375
[06:04:02.644] iteration 20098: loss: 0.056659, loss_s1: 0.061639, loss_fp: 0.005551, loss_freq: 0.018139
[06:04:03.295] iteration 20099: loss: 0.113906, loss_s1: 0.086451, loss_fp: 0.005408, loss_freq: 0.101073
[06:04:03.942] iteration 20100: loss: 0.058102, loss_s1: 0.055222, loss_fp: 0.004934, loss_freq: 0.025948
[06:04:04.594] iteration 20101: loss: 0.138666, loss_s1: 0.156694, loss_fp: 0.002512, loss_freq: 0.085370
[06:04:05.240] iteration 20102: loss: 0.052085, loss_s1: 0.045641, loss_fp: 0.002059, loss_freq: 0.021990
[06:04:05.847] iteration 20103: loss: 0.097253, loss_s1: 0.090841, loss_fp: 0.009571, loss_freq: 0.065710
[06:04:06.456] iteration 20104: loss: 0.095421, loss_s1: 0.133894, loss_fp: 0.001517, loss_freq: 0.029057
[06:04:07.065] iteration 20105: loss: 0.052843, loss_s1: 0.026813, loss_fp: 0.002806, loss_freq: 0.030293
[06:04:07.714] iteration 20106: loss: 0.065884, loss_s1: 0.065689, loss_fp: 0.004387, loss_freq: 0.028491
[06:04:08.353] iteration 20107: loss: 0.053485, loss_s1: 0.039272, loss_fp: 0.004557, loss_freq: 0.026843
[06:04:08.963] iteration 20108: loss: 0.050735, loss_s1: 0.046167, loss_fp: 0.003230, loss_freq: 0.017956
[06:04:09.571] iteration 20109: loss: 0.030247, loss_s1: 0.014595, loss_fp: 0.003115, loss_freq: 0.008111
[06:04:10.180] iteration 20110: loss: 0.048246, loss_s1: 0.035882, loss_fp: 0.001050, loss_freq: 0.016592
[06:04:10.791] iteration 20111: loss: 0.066632, loss_s1: 0.049817, loss_fp: 0.004887, loss_freq: 0.038204
[06:04:11.393] iteration 20112: loss: 0.068714, loss_s1: 0.064958, loss_fp: 0.002205, loss_freq: 0.042791
[06:04:12.047] iteration 20113: loss: 0.039399, loss_s1: 0.020598, loss_fp: 0.001577, loss_freq: 0.009109
[06:04:12.691] iteration 20114: loss: 0.082296, loss_s1: 0.089068, loss_fp: 0.007809, loss_freq: 0.038989
[06:04:13.300] iteration 20115: loss: 0.085514, loss_s1: 0.043169, loss_fp: 0.006077, loss_freq: 0.055525
[06:04:13.903] iteration 20116: loss: 0.048078, loss_s1: 0.036414, loss_fp: 0.002588, loss_freq: 0.019474
[06:04:14.510] iteration 20117: loss: 0.057998, loss_s1: 0.052051, loss_fp: 0.001781, loss_freq: 0.038401
[06:04:15.121] iteration 20118: loss: 0.043156, loss_s1: 0.024965, loss_fp: 0.003131, loss_freq: 0.015337
[06:04:15.730] iteration 20119: loss: 0.043609, loss_s1: 0.020309, loss_fp: 0.001966, loss_freq: 0.036320
[06:04:16.337] iteration 20120: loss: 0.037134, loss_s1: 0.015735, loss_fp: 0.001536, loss_freq: 0.016577
[06:04:16.944] iteration 20121: loss: 0.048983, loss_s1: 0.044852, loss_fp: 0.004077, loss_freq: 0.007264
[06:04:17.553] iteration 20122: loss: 0.073882, loss_s1: 0.051864, loss_fp: 0.005505, loss_freq: 0.053908
[06:04:18.172] iteration 20123: loss: 0.036917, loss_s1: 0.022079, loss_fp: 0.004650, loss_freq: 0.010321
[06:04:18.783] iteration 20124: loss: 0.042271, loss_s1: 0.029532, loss_fp: 0.001625, loss_freq: 0.023979
[06:04:19.387] iteration 20125: loss: 0.034012, loss_s1: 0.015706, loss_fp: 0.003762, loss_freq: 0.007302
[06:04:19.992] iteration 20126: loss: 0.073230, loss_s1: 0.093319, loss_fp: 0.003680, loss_freq: 0.022703
[06:04:20.607] iteration 20127: loss: 0.042530, loss_s1: 0.028538, loss_fp: 0.002979, loss_freq: 0.011804
[06:04:21.209] iteration 20128: loss: 0.111614, loss_s1: 0.116660, loss_fp: 0.023934, loss_freq: 0.043660
[06:04:21.812] iteration 20129: loss: 0.041620, loss_s1: 0.028338, loss_fp: 0.001267, loss_freq: 0.024225
[06:04:22.412] iteration 20130: loss: 0.055098, loss_s1: 0.044046, loss_fp: 0.006067, loss_freq: 0.020583
[06:04:23.017] iteration 20131: loss: 0.055552, loss_s1: 0.034064, loss_fp: 0.003644, loss_freq: 0.035774
[06:04:23.620] iteration 20132: loss: 0.070252, loss_s1: 0.043644, loss_fp: 0.005789, loss_freq: 0.055351
[06:04:24.224] iteration 20133: loss: 0.049387, loss_s1: 0.045793, loss_fp: 0.002640, loss_freq: 0.022819
[06:04:24.824] iteration 20134: loss: 0.055897, loss_s1: 0.048665, loss_fp: 0.005417, loss_freq: 0.024826
[06:04:25.425] iteration 20135: loss: 0.078561, loss_s1: 0.060685, loss_fp: 0.007753, loss_freq: 0.056113
[06:04:26.030] iteration 20136: loss: 0.077105, loss_s1: 0.043594, loss_fp: 0.013557, loss_freq: 0.054064
[06:04:26.649] iteration 20137: loss: 0.063482, loss_s1: 0.063479, loss_fp: 0.010779, loss_freq: 0.021170
[06:04:27.256] iteration 20138: loss: 0.089507, loss_s1: 0.069412, loss_fp: 0.005518, loss_freq: 0.050415
[06:04:27.954] iteration 20139: loss: 0.047697, loss_s1: 0.050530, loss_fp: 0.001591, loss_freq: 0.020994
[06:04:28.587] iteration 20140: loss: 0.047268, loss_s1: 0.028494, loss_fp: 0.004155, loss_freq: 0.021688
[06:04:29.201] iteration 20141: loss: 0.057567, loss_s1: 0.038011, loss_fp: 0.003532, loss_freq: 0.015011
[06:04:29.817] iteration 20142: loss: 0.082806, loss_s1: 0.063104, loss_fp: 0.005643, loss_freq: 0.046378
[06:04:30.424] iteration 20143: loss: 0.073129, loss_s1: 0.059775, loss_fp: 0.001118, loss_freq: 0.028105
[06:04:31.029] iteration 20144: loss: 0.051397, loss_s1: 0.046172, loss_fp: 0.004306, loss_freq: 0.013252
[06:04:31.633] iteration 20145: loss: 0.058688, loss_s1: 0.044038, loss_fp: 0.008114, loss_freq: 0.018986
[06:04:32.239] iteration 20146: loss: 0.063720, loss_s1: 0.059620, loss_fp: 0.004162, loss_freq: 0.023829
[06:04:32.846] iteration 20147: loss: 0.079210, loss_s1: 0.092404, loss_fp: 0.001827, loss_freq: 0.042775
[06:04:33.452] iteration 20148: loss: 0.062841, loss_s1: 0.063536, loss_fp: 0.003691, loss_freq: 0.022472
[06:04:34.059] iteration 20149: loss: 0.028673, loss_s1: 0.017231, loss_fp: 0.001409, loss_freq: 0.008169
[06:04:34.672] iteration 20150: loss: 0.048436, loss_s1: 0.037766, loss_fp: 0.002043, loss_freq: 0.008335
[06:04:35.285] iteration 20151: loss: 0.077140, loss_s1: 0.071119, loss_fp: 0.002894, loss_freq: 0.044000
[06:04:35.912] iteration 20152: loss: 0.086891, loss_s1: 0.101240, loss_fp: 0.005157, loss_freq: 0.037354
[06:04:36.516] iteration 20153: loss: 0.066810, loss_s1: 0.050833, loss_fp: 0.002625, loss_freq: 0.033297
[06:04:37.125] iteration 20154: loss: 0.058154, loss_s1: 0.037012, loss_fp: 0.001277, loss_freq: 0.030897
[06:04:37.745] iteration 20155: loss: 0.072663, loss_s1: 0.060145, loss_fp: 0.008181, loss_freq: 0.028714
[06:04:38.374] iteration 20156: loss: 0.066082, loss_s1: 0.066444, loss_fp: 0.004354, loss_freq: 0.034499
[06:04:39.011] iteration 20157: loss: 0.079575, loss_s1: 0.078150, loss_fp: 0.004984, loss_freq: 0.035380
[06:04:39.647] iteration 20158: loss: 0.066575, loss_s1: 0.064231, loss_fp: 0.004215, loss_freq: 0.028541
[06:04:40.310] iteration 20159: loss: 0.037728, loss_s1: 0.030001, loss_fp: 0.002800, loss_freq: 0.018243
[06:04:40.924] iteration 20160: loss: 0.059451, loss_s1: 0.064397, loss_fp: 0.004597, loss_freq: 0.008292
[06:04:41.535] iteration 20161: loss: 0.056403, loss_s1: 0.024220, loss_fp: 0.003378, loss_freq: 0.053413
[06:04:42.145] iteration 20162: loss: 0.052542, loss_s1: 0.039459, loss_fp: 0.001412, loss_freq: 0.014367
[06:04:42.760] iteration 20163: loss: 0.035351, loss_s1: 0.015712, loss_fp: 0.005572, loss_freq: 0.018272
[06:04:43.367] iteration 20164: loss: 0.044520, loss_s1: 0.048361, loss_fp: 0.003845, loss_freq: 0.009383
[06:04:43.976] iteration 20165: loss: 0.040820, loss_s1: 0.050367, loss_fp: 0.003271, loss_freq: 0.004328
[06:04:44.583] iteration 20166: loss: 0.051620, loss_s1: 0.035271, loss_fp: 0.004385, loss_freq: 0.028540
[06:04:45.195] iteration 20167: loss: 0.055226, loss_s1: 0.047844, loss_fp: 0.011396, loss_freq: 0.017109
[06:04:45.800] iteration 20168: loss: 0.050533, loss_s1: 0.034326, loss_fp: 0.004819, loss_freq: 0.035095
[06:04:46.482] iteration 20169: loss: 0.048788, loss_s1: 0.020121, loss_fp: 0.008263, loss_freq: 0.029990
[06:04:47.097] iteration 20170: loss: 0.061859, loss_s1: 0.068812, loss_fp: 0.002750, loss_freq: 0.026084
[06:04:47.707] iteration 20171: loss: 0.069735, loss_s1: 0.053511, loss_fp: 0.011497, loss_freq: 0.038850
[06:04:48.310] iteration 20172: loss: 0.051817, loss_s1: 0.033726, loss_fp: 0.004665, loss_freq: 0.026280
[06:04:48.924] iteration 20173: loss: 0.063818, loss_s1: 0.063835, loss_fp: 0.004302, loss_freq: 0.025679
[06:04:49.540] iteration 20174: loss: 0.034092, loss_s1: 0.020855, loss_fp: 0.002462, loss_freq: 0.016479
[06:04:50.143] iteration 20175: loss: 0.070432, loss_s1: 0.058498, loss_fp: 0.011498, loss_freq: 0.026228
[06:04:50.751] iteration 20176: loss: 0.062197, loss_s1: 0.037901, loss_fp: 0.003637, loss_freq: 0.047153
[06:04:51.355] iteration 20177: loss: 0.051191, loss_s1: 0.054263, loss_fp: 0.001849, loss_freq: 0.012937
[06:04:51.963] iteration 20178: loss: 0.048432, loss_s1: 0.042895, loss_fp: 0.002008, loss_freq: 0.021813
[06:04:52.593] iteration 20179: loss: 0.048937, loss_s1: 0.050060, loss_fp: 0.002609, loss_freq: 0.016998
[06:04:53.199] iteration 20180: loss: 0.084536, loss_s1: 0.118504, loss_fp: 0.002674, loss_freq: 0.013735
[06:04:53.806] iteration 20181: loss: 0.057364, loss_s1: 0.055221, loss_fp: 0.002544, loss_freq: 0.012831
[06:04:54.446] iteration 20182: loss: 0.061774, loss_s1: 0.086422, loss_fp: 0.004056, loss_freq: 0.010450
[06:04:55.104] iteration 20183: loss: 0.072283, loss_s1: 0.058943, loss_fp: 0.008651, loss_freq: 0.041045
[06:04:55.760] iteration 20184: loss: 0.056140, loss_s1: 0.049018, loss_fp: 0.002639, loss_freq: 0.028633
[06:04:56.421] iteration 20185: loss: 0.040007, loss_s1: 0.027295, loss_fp: 0.001707, loss_freq: 0.016430
[06:04:57.082] iteration 20186: loss: 0.046358, loss_s1: 0.020975, loss_fp: 0.001365, loss_freq: 0.035471
[06:04:57.740] iteration 20187: loss: 0.040656, loss_s1: 0.027940, loss_fp: 0.002161, loss_freq: 0.029918
[06:04:58.398] iteration 20188: loss: 0.045904, loss_s1: 0.034461, loss_fp: 0.001507, loss_freq: 0.016179
[06:04:59.057] iteration 20189: loss: 0.072595, loss_s1: 0.056502, loss_fp: 0.005896, loss_freq: 0.051529
[06:04:59.718] iteration 20190: loss: 0.068070, loss_s1: 0.033950, loss_fp: 0.010419, loss_freq: 0.053965
[06:05:00.401] iteration 20191: loss: 0.073311, loss_s1: 0.050518, loss_fp: 0.005534, loss_freq: 0.069181
[06:05:01.056] iteration 20192: loss: 0.070834, loss_s1: 0.059046, loss_fp: 0.004994, loss_freq: 0.039091
[06:05:01.730] iteration 20193: loss: 0.057341, loss_s1: 0.062533, loss_fp: 0.006446, loss_freq: 0.014408
[06:05:02.354] iteration 20194: loss: 0.052738, loss_s1: 0.060207, loss_fp: 0.004591, loss_freq: 0.014567
[06:05:02.968] iteration 20195: loss: 0.078295, loss_s1: 0.082636, loss_fp: 0.003133, loss_freq: 0.037013
[06:05:03.578] iteration 20196: loss: 0.042769, loss_s1: 0.024520, loss_fp: 0.002102, loss_freq: 0.034223
[06:05:04.191] iteration 20197: loss: 0.056495, loss_s1: 0.054804, loss_fp: 0.005154, loss_freq: 0.012948
[06:05:04.804] iteration 20198: loss: 0.068716, loss_s1: 0.043860, loss_fp: 0.008714, loss_freq: 0.049299
[06:05:05.439] iteration 20199: loss: 0.095902, loss_s1: 0.099794, loss_fp: 0.006822, loss_freq: 0.056618
[06:05:06.047] iteration 20200: loss: 0.052492, loss_s1: 0.064877, loss_fp: 0.001861, loss_freq: 0.018253
[06:05:09.532] iteration 20200 : mean_dice : 0.733623
[06:05:10.187] iteration 20201: loss: 0.059347, loss_s1: 0.032389, loss_fp: 0.009068, loss_freq: 0.041378
[06:05:10.853] iteration 20202: loss: 0.054808, loss_s1: 0.056150, loss_fp: 0.002503, loss_freq: 0.017446
[06:05:11.507] iteration 20203: loss: 0.042654, loss_s1: 0.038941, loss_fp: 0.005539, loss_freq: 0.013364
[06:05:12.162] iteration 20204: loss: 0.033698, loss_s1: 0.015253, loss_fp: 0.006931, loss_freq: 0.010725
[06:05:12.814] iteration 20205: loss: 0.052253, loss_s1: 0.055851, loss_fp: 0.003154, loss_freq: 0.014501
[06:05:13.422] iteration 20206: loss: 0.064330, loss_s1: 0.034687, loss_fp: 0.001911, loss_freq: 0.058295
[06:05:14.030] iteration 20207: loss: 0.071788, loss_s1: 0.082028, loss_fp: 0.000991, loss_freq: 0.028673
[06:05:14.642] iteration 20208: loss: 0.088498, loss_s1: 0.090932, loss_fp: 0.004510, loss_freq: 0.041767
[06:05:15.253] iteration 20209: loss: 0.075387, loss_s1: 0.066071, loss_fp: 0.003312, loss_freq: 0.056745
[06:05:15.897] iteration 20210: loss: 0.050668, loss_s1: 0.035434, loss_fp: 0.001121, loss_freq: 0.028146
[06:05:16.507] iteration 20211: loss: 0.074912, loss_s1: 0.066794, loss_fp: 0.010322, loss_freq: 0.034084
[06:05:17.112] iteration 20212: loss: 0.099431, loss_s1: 0.087697, loss_fp: 0.004695, loss_freq: 0.070405
[06:05:17.744] iteration 20213: loss: 0.115847, loss_s1: 0.145507, loss_fp: 0.008941, loss_freq: 0.046444
[06:05:18.408] iteration 20214: loss: 0.073502, loss_s1: 0.058790, loss_fp: 0.011056, loss_freq: 0.041311
[06:05:19.015] iteration 20215: loss: 0.073914, loss_s1: 0.058223, loss_fp: 0.006072, loss_freq: 0.042380
[06:05:19.626] iteration 20216: loss: 0.047487, loss_s1: 0.046975, loss_fp: 0.007922, loss_freq: 0.007616
[06:05:20.244] iteration 20217: loss: 0.022851, loss_s1: 0.010642, loss_fp: 0.004452, loss_freq: 0.005825
[06:05:20.862] iteration 20218: loss: 0.085236, loss_s1: 0.072316, loss_fp: 0.004051, loss_freq: 0.057965
[06:05:21.465] iteration 20219: loss: 0.061612, loss_s1: 0.046794, loss_fp: 0.003881, loss_freq: 0.042882
[06:05:22.071] iteration 20220: loss: 0.072488, loss_s1: 0.057127, loss_fp: 0.006564, loss_freq: 0.046765
[06:05:22.685] iteration 20221: loss: 0.031036, loss_s1: 0.019403, loss_fp: 0.002793, loss_freq: 0.008568
[06:05:23.296] iteration 20222: loss: 0.063281, loss_s1: 0.057774, loss_fp: 0.008386, loss_freq: 0.038378
[06:05:23.904] iteration 20223: loss: 0.045681, loss_s1: 0.014839, loss_fp: 0.003241, loss_freq: 0.032661
[06:05:24.517] iteration 20224: loss: 0.053683, loss_s1: 0.039415, loss_fp: 0.004404, loss_freq: 0.032290
[06:05:25.126] iteration 20225: loss: 0.038607, loss_s1: 0.029184, loss_fp: 0.001930, loss_freq: 0.010817
[06:05:25.788] iteration 20226: loss: 0.058189, loss_s1: 0.061200, loss_fp: 0.006009, loss_freq: 0.023393
[06:05:26.441] iteration 20227: loss: 0.063372, loss_s1: 0.054091, loss_fp: 0.001730, loss_freq: 0.030980
[06:05:27.098] iteration 20228: loss: 0.079788, loss_s1: 0.056330, loss_fp: 0.011513, loss_freq: 0.044537
[06:05:27.746] iteration 20229: loss: 0.091771, loss_s1: 0.085937, loss_fp: 0.011224, loss_freq: 0.057123
[06:05:28.355] iteration 20230: loss: 0.073556, loss_s1: 0.071416, loss_fp: 0.006614, loss_freq: 0.038581
[06:05:29.395] iteration 20231: loss: 0.084239, loss_s1: 0.086393, loss_fp: 0.001968, loss_freq: 0.038857
[06:05:30.057] iteration 20232: loss: 0.054020, loss_s1: 0.035266, loss_fp: 0.007781, loss_freq: 0.031910
[06:05:30.719] iteration 20233: loss: 0.066023, loss_s1: 0.076667, loss_fp: 0.007338, loss_freq: 0.019307
[06:05:31.398] iteration 20234: loss: 0.053272, loss_s1: 0.031373, loss_fp: 0.002632, loss_freq: 0.032415
[06:05:32.095] iteration 20235: loss: 0.048628, loss_s1: 0.043976, loss_fp: 0.001734, loss_freq: 0.020611
[06:05:32.752] iteration 20236: loss: 0.070772, loss_s1: 0.063664, loss_fp: 0.003019, loss_freq: 0.041772
[06:05:33.412] iteration 20237: loss: 0.049134, loss_s1: 0.023134, loss_fp: 0.003986, loss_freq: 0.031847
[06:05:34.080] iteration 20238: loss: 0.048268, loss_s1: 0.049859, loss_fp: 0.005514, loss_freq: 0.013131
[06:05:34.747] iteration 20239: loss: 0.050057, loss_s1: 0.040763, loss_fp: 0.002014, loss_freq: 0.031404
[06:05:35.368] iteration 20240: loss: 0.065198, loss_s1: 0.056982, loss_fp: 0.003535, loss_freq: 0.032061
[06:05:36.010] iteration 20241: loss: 0.047849, loss_s1: 0.042358, loss_fp: 0.002750, loss_freq: 0.014677
[06:05:36.620] iteration 20242: loss: 0.048518, loss_s1: 0.033079, loss_fp: 0.000410, loss_freq: 0.032268
[06:05:37.233] iteration 20243: loss: 0.048498, loss_s1: 0.035753, loss_fp: 0.003900, loss_freq: 0.021082
[06:05:37.850] iteration 20244: loss: 0.067566, loss_s1: 0.066227, loss_fp: 0.008255, loss_freq: 0.013648
[06:05:38.467] iteration 20245: loss: 0.081965, loss_s1: 0.064240, loss_fp: 0.006692, loss_freq: 0.022796
[06:05:39.094] iteration 20246: loss: 0.044035, loss_s1: 0.022773, loss_fp: 0.003216, loss_freq: 0.021748
[06:05:39.708] iteration 20247: loss: 0.121205, loss_s1: 0.129899, loss_fp: 0.007543, loss_freq: 0.078125
[06:05:40.319] iteration 20248: loss: 0.033353, loss_s1: 0.031658, loss_fp: 0.001374, loss_freq: 0.004414
[06:05:40.928] iteration 20249: loss: 0.089659, loss_s1: 0.074542, loss_fp: 0.009599, loss_freq: 0.060450
[06:05:41.537] iteration 20250: loss: 0.054527, loss_s1: 0.048796, loss_fp: 0.004367, loss_freq: 0.014735
[06:05:42.152] iteration 20251: loss: 0.061200, loss_s1: 0.058649, loss_fp: 0.001871, loss_freq: 0.027631
[06:05:42.771] iteration 20252: loss: 0.052206, loss_s1: 0.040711, loss_fp: 0.003756, loss_freq: 0.035639
[06:05:43.383] iteration 20253: loss: 0.069112, loss_s1: 0.065965, loss_fp: 0.002225, loss_freq: 0.026058
[06:05:43.996] iteration 20254: loss: 0.038512, loss_s1: 0.022569, loss_fp: 0.003293, loss_freq: 0.022981
[06:05:44.608] iteration 20255: loss: 0.055436, loss_s1: 0.040455, loss_fp: 0.005819, loss_freq: 0.024042
[06:05:45.224] iteration 20256: loss: 0.087215, loss_s1: 0.084614, loss_fp: 0.006825, loss_freq: 0.050396
[06:05:45.838] iteration 20257: loss: 0.056002, loss_s1: 0.036409, loss_fp: 0.005778, loss_freq: 0.020212
[06:05:46.446] iteration 20258: loss: 0.083302, loss_s1: 0.047300, loss_fp: 0.009000, loss_freq: 0.025229
[06:05:47.064] iteration 20259: loss: 0.037356, loss_s1: 0.018827, loss_fp: 0.001182, loss_freq: 0.020736
[06:05:47.676] iteration 20260: loss: 0.085556, loss_s1: 0.080446, loss_fp: 0.005622, loss_freq: 0.054090
[06:05:48.284] iteration 20261: loss: 0.047935, loss_s1: 0.021207, loss_fp: 0.002245, loss_freq: 0.043860
[06:05:48.893] iteration 20262: loss: 0.095376, loss_s1: 0.086917, loss_fp: 0.008880, loss_freq: 0.056897
[06:05:49.499] iteration 20263: loss: 0.084323, loss_s1: 0.088782, loss_fp: 0.006846, loss_freq: 0.040127
[06:05:50.107] iteration 20264: loss: 0.046774, loss_s1: 0.040831, loss_fp: 0.004766, loss_freq: 0.014911
[06:05:50.715] iteration 20265: loss: 0.070902, loss_s1: 0.066444, loss_fp: 0.003313, loss_freq: 0.049636
[06:05:51.323] iteration 20266: loss: 0.049252, loss_s1: 0.023859, loss_fp: 0.005562, loss_freq: 0.029634
[06:05:51.938] iteration 20267: loss: 0.065677, loss_s1: 0.065001, loss_fp: 0.002411, loss_freq: 0.030082
[06:05:52.559] iteration 20268: loss: 0.038622, loss_s1: 0.027314, loss_fp: 0.002573, loss_freq: 0.011878
[06:05:53.213] iteration 20269: loss: 0.098905, loss_s1: 0.080012, loss_fp: 0.008078, loss_freq: 0.066137
[06:05:53.884] iteration 20270: loss: 0.063151, loss_s1: 0.063659, loss_fp: 0.002188, loss_freq: 0.030555
[06:05:54.558] iteration 20271: loss: 0.042543, loss_s1: 0.036036, loss_fp: 0.000776, loss_freq: 0.014945
[06:05:55.218] iteration 20272: loss: 0.086808, loss_s1: 0.084745, loss_fp: 0.017964, loss_freq: 0.024598
[06:05:55.856] iteration 20273: loss: 0.087805, loss_s1: 0.089093, loss_fp: 0.003290, loss_freq: 0.041079
[06:05:56.513] iteration 20274: loss: 0.122556, loss_s1: 0.152903, loss_fp: 0.004224, loss_freq: 0.055551
[06:05:57.143] iteration 20275: loss: 0.057747, loss_s1: 0.051527, loss_fp: 0.001112, loss_freq: 0.031433
[06:05:57.752] iteration 20276: loss: 0.066319, loss_s1: 0.071885, loss_fp: 0.003760, loss_freq: 0.026480
[06:05:58.362] iteration 20277: loss: 0.053305, loss_s1: 0.037897, loss_fp: 0.006362, loss_freq: 0.028152
[06:05:58.975] iteration 20278: loss: 0.050100, loss_s1: 0.042152, loss_fp: 0.002592, loss_freq: 0.026206
[06:05:59.587] iteration 20279: loss: 0.040893, loss_s1: 0.030607, loss_fp: 0.002896, loss_freq: 0.018731
[06:06:00.200] iteration 20280: loss: 0.039875, loss_s1: 0.034461, loss_fp: 0.001857, loss_freq: 0.004212
[06:06:00.824] iteration 20281: loss: 0.060914, loss_s1: 0.030850, loss_fp: 0.003631, loss_freq: 0.045402
[06:06:01.435] iteration 20282: loss: 0.054663, loss_s1: 0.075815, loss_fp: 0.003634, loss_freq: 0.010288
[06:06:02.042] iteration 20283: loss: 0.032737, loss_s1: 0.011601, loss_fp: 0.002166, loss_freq: 0.016113
[06:06:02.652] iteration 20284: loss: 0.092120, loss_s1: 0.085914, loss_fp: 0.003119, loss_freq: 0.066237
[06:06:03.279] iteration 20285: loss: 0.070224, loss_s1: 0.022649, loss_fp: 0.002521, loss_freq: 0.073482
[06:06:03.924] iteration 20286: loss: 0.038392, loss_s1: 0.014694, loss_fp: 0.001874, loss_freq: 0.023772
[06:06:04.531] iteration 20287: loss: 0.044042, loss_s1: 0.035789, loss_fp: 0.004783, loss_freq: 0.026187
[06:06:05.141] iteration 20288: loss: 0.054760, loss_s1: 0.052446, loss_fp: 0.001395, loss_freq: 0.015664
[06:06:05.754] iteration 20289: loss: 0.057744, loss_s1: 0.016095, loss_fp: 0.005045, loss_freq: 0.017775
[06:06:06.362] iteration 20290: loss: 0.047363, loss_s1: 0.034578, loss_fp: 0.002648, loss_freq: 0.022274
[06:06:06.969] iteration 20291: loss: 0.027779, loss_s1: 0.018508, loss_fp: 0.002882, loss_freq: 0.004334
[06:06:07.575] iteration 20292: loss: 0.060403, loss_s1: 0.032393, loss_fp: 0.002860, loss_freq: 0.043562
[06:06:08.177] iteration 20293: loss: 0.037256, loss_s1: 0.021699, loss_fp: 0.003250, loss_freq: 0.011639
[06:06:08.783] iteration 20294: loss: 0.042647, loss_s1: 0.030709, loss_fp: 0.003202, loss_freq: 0.020573
[06:06:09.400] iteration 20295: loss: 0.051702, loss_s1: 0.044982, loss_fp: 0.004108, loss_freq: 0.017765
[06:06:10.007] iteration 20296: loss: 0.063196, loss_s1: 0.056476, loss_fp: 0.003950, loss_freq: 0.034730
[06:06:10.618] iteration 20297: loss: 0.038958, loss_s1: 0.031156, loss_fp: 0.001774, loss_freq: 0.009535
[06:06:11.222] iteration 20298: loss: 0.126643, loss_s1: 0.125433, loss_fp: 0.014648, loss_freq: 0.067054
[06:06:11.833] iteration 20299: loss: 0.037659, loss_s1: 0.023617, loss_fp: 0.006010, loss_freq: 0.017149
[06:06:12.440] iteration 20300: loss: 0.051374, loss_s1: 0.044489, loss_fp: 0.007556, loss_freq: 0.025590
[06:06:13.047] iteration 20301: loss: 0.074003, loss_s1: 0.054615, loss_fp: 0.003156, loss_freq: 0.052943
[06:06:13.720] iteration 20302: loss: 0.059806, loss_s1: 0.045007, loss_fp: 0.003863, loss_freq: 0.033957
[06:06:14.375] iteration 20303: loss: 0.059255, loss_s1: 0.052724, loss_fp: 0.005550, loss_freq: 0.034642
[06:06:15.035] iteration 20304: loss: 0.058376, loss_s1: 0.063449, loss_fp: 0.001331, loss_freq: 0.017160
[06:06:15.687] iteration 20305: loss: 0.046615, loss_s1: 0.038920, loss_fp: 0.002949, loss_freq: 0.025925
[06:06:16.349] iteration 20306: loss: 0.077258, loss_s1: 0.039384, loss_fp: 0.011211, loss_freq: 0.068673
[06:06:17.004] iteration 20307: loss: 0.067010, loss_s1: 0.058744, loss_fp: 0.001997, loss_freq: 0.043043
[06:06:17.658] iteration 20308: loss: 0.103512, loss_s1: 0.104365, loss_fp: 0.010889, loss_freq: 0.063680
[06:06:18.266] iteration 20309: loss: 0.057407, loss_s1: 0.051544, loss_fp: 0.005957, loss_freq: 0.033018
[06:06:18.878] iteration 20310: loss: 0.079730, loss_s1: 0.068431, loss_fp: 0.005820, loss_freq: 0.032735
[06:06:19.489] iteration 20311: loss: 0.038817, loss_s1: 0.020815, loss_fp: 0.005430, loss_freq: 0.005585
[06:06:20.091] iteration 20312: loss: 0.058531, loss_s1: 0.035705, loss_fp: 0.003034, loss_freq: 0.040451
[06:06:20.696] iteration 20313: loss: 0.045675, loss_s1: 0.032493, loss_fp: 0.005563, loss_freq: 0.024229
[06:06:21.305] iteration 20314: loss: 0.047661, loss_s1: 0.034492, loss_fp: 0.002015, loss_freq: 0.017338
[06:06:21.913] iteration 20315: loss: 0.048047, loss_s1: 0.029491, loss_fp: 0.005972, loss_freq: 0.027364
[06:06:22.518] iteration 20316: loss: 0.054791, loss_s1: 0.042078, loss_fp: 0.005525, loss_freq: 0.030506
[06:06:23.128] iteration 20317: loss: 0.067757, loss_s1: 0.078801, loss_fp: 0.001653, loss_freq: 0.033179
[06:06:23.748] iteration 20318: loss: 0.048330, loss_s1: 0.052266, loss_fp: 0.001379, loss_freq: 0.013264
[06:06:24.360] iteration 20319: loss: 0.082690, loss_s1: 0.043524, loss_fp: 0.005747, loss_freq: 0.077278
[06:06:24.968] iteration 20320: loss: 0.057009, loss_s1: 0.061105, loss_fp: 0.002448, loss_freq: 0.010714
[06:06:25.573] iteration 20321: loss: 0.076555, loss_s1: 0.060101, loss_fp: 0.002463, loss_freq: 0.056669
[06:06:26.180] iteration 20322: loss: 0.058705, loss_s1: 0.040242, loss_fp: 0.005073, loss_freq: 0.041991
[06:06:26.788] iteration 20323: loss: 0.056994, loss_s1: 0.025213, loss_fp: 0.003290, loss_freq: 0.036892
[06:06:27.392] iteration 20324: loss: 0.044096, loss_s1: 0.027555, loss_fp: 0.002700, loss_freq: 0.025606
[06:06:27.996] iteration 20325: loss: 0.088043, loss_s1: 0.098768, loss_fp: 0.002644, loss_freq: 0.044838
[06:06:28.598] iteration 20326: loss: 0.059645, loss_s1: 0.043899, loss_fp: 0.003471, loss_freq: 0.048128
[06:06:29.213] iteration 20327: loss: 0.076831, loss_s1: 0.047266, loss_fp: 0.004860, loss_freq: 0.060984
[06:06:29.864] iteration 20328: loss: 0.059279, loss_s1: 0.046917, loss_fp: 0.007469, loss_freq: 0.024710
[06:06:30.514] iteration 20329: loss: 0.050871, loss_s1: 0.040055, loss_fp: 0.009719, loss_freq: 0.023304
[06:06:31.167] iteration 20330: loss: 0.053618, loss_s1: 0.042319, loss_fp: 0.001462, loss_freq: 0.028464
[06:06:31.812] iteration 20331: loss: 0.066597, loss_s1: 0.048824, loss_fp: 0.008643, loss_freq: 0.043261
[06:06:32.419] iteration 20332: loss: 0.085604, loss_s1: 0.096326, loss_fp: 0.006927, loss_freq: 0.031769
[06:06:33.032] iteration 20333: loss: 0.047959, loss_s1: 0.031567, loss_fp: 0.002013, loss_freq: 0.030301
[06:06:33.640] iteration 20334: loss: 0.043879, loss_s1: 0.027082, loss_fp: 0.003525, loss_freq: 0.018468
[06:06:34.258] iteration 20335: loss: 0.031650, loss_s1: 0.023608, loss_fp: 0.001290, loss_freq: 0.015165
[06:06:34.865] iteration 20336: loss: 0.061292, loss_s1: 0.055052, loss_fp: 0.002756, loss_freq: 0.026425
[06:06:35.479] iteration 20337: loss: 0.051925, loss_s1: 0.038006, loss_fp: 0.004087, loss_freq: 0.022765
[06:06:36.093] iteration 20338: loss: 0.071977, loss_s1: 0.083181, loss_fp: 0.004098, loss_freq: 0.025240
[06:06:36.699] iteration 20339: loss: 0.062130, loss_s1: 0.045474, loss_fp: 0.005579, loss_freq: 0.040393
[06:06:37.362] iteration 20340: loss: 0.071551, loss_s1: 0.063466, loss_fp: 0.003085, loss_freq: 0.039034
[06:06:37.973] iteration 20341: loss: 0.059656, loss_s1: 0.041967, loss_fp: 0.005436, loss_freq: 0.023923
[06:06:38.582] iteration 20342: loss: 0.054138, loss_s1: 0.044418, loss_fp: 0.002394, loss_freq: 0.024498
[06:06:39.184] iteration 20343: loss: 0.047475, loss_s1: 0.031728, loss_fp: 0.002741, loss_freq: 0.031309
[06:06:39.784] iteration 20344: loss: 0.023487, loss_s1: 0.012843, loss_fp: 0.000742, loss_freq: 0.008829
[06:06:40.391] iteration 20345: loss: 0.104284, loss_s1: 0.094228, loss_fp: 0.004746, loss_freq: 0.064086
[06:06:40.999] iteration 20346: loss: 0.079704, loss_s1: 0.057281, loss_fp: 0.008702, loss_freq: 0.060588
[06:06:41.606] iteration 20347: loss: 0.058941, loss_s1: 0.047107, loss_fp: 0.002974, loss_freq: 0.029833
[06:06:42.285] iteration 20348: loss: 0.055767, loss_s1: 0.053428, loss_fp: 0.005439, loss_freq: 0.023272
[06:06:42.953] iteration 20349: loss: 0.071973, loss_s1: 0.059283, loss_fp: 0.001542, loss_freq: 0.052618
[06:06:43.617] iteration 20350: loss: 0.056775, loss_s1: 0.046385, loss_fp: 0.005292, loss_freq: 0.021877
[06:06:44.285] iteration 20351: loss: 0.046555, loss_s1: 0.043524, loss_fp: 0.001102, loss_freq: 0.012598
[06:06:44.911] iteration 20352: loss: 0.070523, loss_s1: 0.079487, loss_fp: 0.011208, loss_freq: 0.025621
[06:06:45.527] iteration 20353: loss: 0.104207, loss_s1: 0.100168, loss_fp: 0.008422, loss_freq: 0.068439
[06:06:46.182] iteration 20354: loss: 0.037554, loss_s1: 0.025317, loss_fp: 0.004492, loss_freq: 0.015698
[06:06:46.834] iteration 20355: loss: 0.058342, loss_s1: 0.046719, loss_fp: 0.007868, loss_freq: 0.026553
[06:06:47.505] iteration 20356: loss: 0.042213, loss_s1: 0.020099, loss_fp: 0.002278, loss_freq: 0.029093
[06:06:48.172] iteration 20357: loss: 0.084057, loss_s1: 0.072232, loss_fp: 0.010998, loss_freq: 0.046298
[06:06:48.837] iteration 20358: loss: 0.056257, loss_s1: 0.014880, loss_fp: 0.015608, loss_freq: 0.047235
[06:06:49.497] iteration 20359: loss: 0.051745, loss_s1: 0.044224, loss_fp: 0.005172, loss_freq: 0.026963
[06:06:50.154] iteration 20360: loss: 0.072052, loss_s1: 0.068005, loss_fp: 0.010394, loss_freq: 0.024858
[06:06:50.768] iteration 20361: loss: 0.045426, loss_s1: 0.055811, loss_fp: 0.001192, loss_freq: 0.009110
[06:06:51.380] iteration 20362: loss: 0.059129, loss_s1: 0.050453, loss_fp: 0.007257, loss_freq: 0.011794
[06:06:51.994] iteration 20363: loss: 0.085451, loss_s1: 0.080356, loss_fp: 0.004017, loss_freq: 0.042852
[06:06:52.608] iteration 20364: loss: 0.053340, loss_s1: 0.047760, loss_fp: 0.004953, loss_freq: 0.025268
[06:06:53.220] iteration 20365: loss: 0.068342, loss_s1: 0.057542, loss_fp: 0.004326, loss_freq: 0.037414
[06:06:53.832] iteration 20366: loss: 0.036537, loss_s1: 0.030148, loss_fp: 0.002232, loss_freq: 0.013243
[06:06:54.449] iteration 20367: loss: 0.055062, loss_s1: 0.044222, loss_fp: 0.005652, loss_freq: 0.022977
[06:06:55.062] iteration 20368: loss: 0.054724, loss_s1: 0.037759, loss_fp: 0.005577, loss_freq: 0.041170
[06:06:55.680] iteration 20369: loss: 0.097919, loss_s1: 0.115641, loss_fp: 0.003411, loss_freq: 0.040089
[06:06:56.288] iteration 20370: loss: 0.046215, loss_s1: 0.033609, loss_fp: 0.000927, loss_freq: 0.032928
[06:06:56.897] iteration 20371: loss: 0.084629, loss_s1: 0.064804, loss_fp: 0.002546, loss_freq: 0.065879
[06:06:57.512] iteration 20372: loss: 0.075400, loss_s1: 0.092328, loss_fp: 0.003399, loss_freq: 0.022494
[06:06:58.116] iteration 20373: loss: 0.040913, loss_s1: 0.019250, loss_fp: 0.009008, loss_freq: 0.027622
[06:06:58.726] iteration 20374: loss: 0.028356, loss_s1: 0.007920, loss_fp: 0.002922, loss_freq: 0.009311
[06:06:59.338] iteration 20375: loss: 0.029926, loss_s1: 0.022491, loss_fp: 0.001597, loss_freq: 0.008340
[06:06:59.947] iteration 20376: loss: 0.049790, loss_s1: 0.029688, loss_fp: 0.004353, loss_freq: 0.032085
[06:07:00.560] iteration 20377: loss: 0.044552, loss_s1: 0.031137, loss_fp: 0.005414, loss_freq: 0.020815
[06:07:01.175] iteration 20378: loss: 0.062493, loss_s1: 0.078211, loss_fp: 0.005412, loss_freq: 0.016388
[06:07:01.787] iteration 20379: loss: 0.057655, loss_s1: 0.029174, loss_fp: 0.004892, loss_freq: 0.051861
[06:07:02.420] iteration 20380: loss: 0.061941, loss_s1: 0.048129, loss_fp: 0.004696, loss_freq: 0.035885
[06:07:03.031] iteration 20381: loss: 0.057861, loss_s1: 0.048490, loss_fp: 0.006794, loss_freq: 0.031083
[06:07:03.641] iteration 20382: loss: 0.061055, loss_s1: 0.056652, loss_fp: 0.002828, loss_freq: 0.029281
[06:07:04.250] iteration 20383: loss: 0.051534, loss_s1: 0.032633, loss_fp: 0.007109, loss_freq: 0.028578
[06:07:04.909] iteration 20384: loss: 0.048679, loss_s1: 0.020714, loss_fp: 0.010719, loss_freq: 0.030947
[06:07:05.563] iteration 20385: loss: 0.085114, loss_s1: 0.058337, loss_fp: 0.003277, loss_freq: 0.046278
[06:07:06.174] iteration 20386: loss: 0.056201, loss_s1: 0.057677, loss_fp: 0.003463, loss_freq: 0.016574
[06:07:06.783] iteration 20387: loss: 0.049916, loss_s1: 0.051315, loss_fp: 0.004760, loss_freq: 0.019797
[06:07:07.395] iteration 20388: loss: 0.098956, loss_s1: 0.097007, loss_fp: 0.008588, loss_freq: 0.055063
[06:07:08.005] iteration 20389: loss: 0.083789, loss_s1: 0.072941, loss_fp: 0.008186, loss_freq: 0.056684
[06:07:08.616] iteration 20390: loss: 0.066907, loss_s1: 0.053702, loss_fp: 0.004303, loss_freq: 0.045035
[06:07:09.223] iteration 20391: loss: 0.030773, loss_s1: 0.014952, loss_fp: 0.001333, loss_freq: 0.010940
[06:07:09.823] iteration 20392: loss: 0.048672, loss_s1: 0.036228, loss_fp: 0.004897, loss_freq: 0.027415
[06:07:10.436] iteration 20393: loss: 0.042139, loss_s1: 0.033483, loss_fp: 0.002608, loss_freq: 0.008667
[06:07:11.047] iteration 20394: loss: 0.043587, loss_s1: 0.025801, loss_fp: 0.003902, loss_freq: 0.030018
[06:07:11.701] iteration 20395: loss: 0.035302, loss_s1: 0.012222, loss_fp: 0.001411, loss_freq: 0.028497
[06:07:12.361] iteration 20396: loss: 0.054510, loss_s1: 0.051361, loss_fp: 0.002380, loss_freq: 0.029512
[06:07:13.018] iteration 20397: loss: 0.042091, loss_s1: 0.028754, loss_fp: 0.007860, loss_freq: 0.014881
[06:07:13.695] iteration 20398: loss: 0.049273, loss_s1: 0.034252, loss_fp: 0.002330, loss_freq: 0.024788
[06:07:14.349] iteration 20399: loss: 0.095326, loss_s1: 0.081183, loss_fp: 0.003522, loss_freq: 0.077409
[06:07:14.999] iteration 20400: loss: 0.055139, loss_s1: 0.055696, loss_fp: 0.006443, loss_freq: 0.013289
[06:07:18.373] iteration 20400 : mean_dice : 0.721136
[06:07:19.403] iteration 20401: loss: 0.058550, loss_s1: 0.042616, loss_fp: 0.003438, loss_freq: 0.015439
[06:07:20.059] iteration 20402: loss: 0.047418, loss_s1: 0.024932, loss_fp: 0.005007, loss_freq: 0.023341
[06:07:20.722] iteration 20403: loss: 0.056313, loss_s1: 0.067689, loss_fp: 0.001894, loss_freq: 0.017057
[06:07:21.380] iteration 20404: loss: 0.044697, loss_s1: 0.032482, loss_fp: 0.001290, loss_freq: 0.021682
[06:07:22.033] iteration 20405: loss: 0.057750, loss_s1: 0.047164, loss_fp: 0.001205, loss_freq: 0.034269
[06:07:22.643] iteration 20406: loss: 0.064942, loss_s1: 0.060687, loss_fp: 0.010187, loss_freq: 0.021644
[06:07:23.256] iteration 20407: loss: 0.105263, loss_s1: 0.127687, loss_fp: 0.002281, loss_freq: 0.040103
[06:07:23.860] iteration 20408: loss: 0.058620, loss_s1: 0.050214, loss_fp: 0.002203, loss_freq: 0.027316
[06:07:24.473] iteration 20409: loss: 0.068141, loss_s1: 0.054111, loss_fp: 0.004405, loss_freq: 0.034775
[06:07:25.080] iteration 20410: loss: 0.053135, loss_s1: 0.031630, loss_fp: 0.005740, loss_freq: 0.029291
[06:07:25.688] iteration 20411: loss: 0.056653, loss_s1: 0.043067, loss_fp: 0.007802, loss_freq: 0.027764
[06:07:26.291] iteration 20412: loss: 0.088312, loss_s1: 0.092697, loss_fp: 0.012618, loss_freq: 0.036653
[06:07:26.906] iteration 20413: loss: 0.055345, loss_s1: 0.046449, loss_fp: 0.001370, loss_freq: 0.025375
[06:07:27.511] iteration 20414: loss: 0.068099, loss_s1: 0.063385, loss_fp: 0.009309, loss_freq: 0.033173
[06:07:28.118] iteration 20415: loss: 0.047267, loss_s1: 0.036062, loss_fp: 0.006413, loss_freq: 0.013063
[06:07:28.723] iteration 20416: loss: 0.063413, loss_s1: 0.046646, loss_fp: 0.003896, loss_freq: 0.040020
[06:07:29.331] iteration 20417: loss: 0.110767, loss_s1: 0.114452, loss_fp: 0.006492, loss_freq: 0.073627
[06:07:29.941] iteration 20418: loss: 0.041752, loss_s1: 0.027591, loss_fp: 0.001356, loss_freq: 0.015326
[06:07:30.549] iteration 20419: loss: 0.076425, loss_s1: 0.062245, loss_fp: 0.004136, loss_freq: 0.034412
[06:07:31.216] iteration 20420: loss: 0.043599, loss_s1: 0.029600, loss_fp: 0.003956, loss_freq: 0.023483
[06:07:31.866] iteration 20421: loss: 0.055058, loss_s1: 0.024754, loss_fp: 0.002332, loss_freq: 0.043775
[06:07:32.489] iteration 20422: loss: 0.042987, loss_s1: 0.016381, loss_fp: 0.006239, loss_freq: 0.036608
[06:07:33.118] iteration 20423: loss: 0.066309, loss_s1: 0.053153, loss_fp: 0.003207, loss_freq: 0.032357
[06:07:33.740] iteration 20424: loss: 0.075118, loss_s1: 0.050637, loss_fp: 0.004576, loss_freq: 0.065758
[06:07:34.368] iteration 20425: loss: 0.073978, loss_s1: 0.069495, loss_fp: 0.004531, loss_freq: 0.039360
[06:07:34.996] iteration 20426: loss: 0.066581, loss_s1: 0.066500, loss_fp: 0.007475, loss_freq: 0.029907
[06:07:35.624] iteration 20427: loss: 0.049069, loss_s1: 0.021665, loss_fp: 0.008916, loss_freq: 0.033769
[06:07:36.248] iteration 20428: loss: 0.088974, loss_s1: 0.094695, loss_fp: 0.003275, loss_freq: 0.047196
[06:07:36.874] iteration 20429: loss: 0.050628, loss_s1: 0.050191, loss_fp: 0.004093, loss_freq: 0.015012
[06:07:37.501] iteration 20430: loss: 0.076149, loss_s1: 0.069985, loss_fp: 0.003202, loss_freq: 0.044722
[06:07:38.122] iteration 20431: loss: 0.060253, loss_s1: 0.039795, loss_fp: 0.007049, loss_freq: 0.042895
[06:07:38.754] iteration 20432: loss: 0.071751, loss_s1: 0.072013, loss_fp: 0.006064, loss_freq: 0.020621
[06:07:39.393] iteration 20433: loss: 0.102651, loss_s1: 0.127014, loss_fp: 0.007457, loss_freq: 0.037242
[06:07:40.020] iteration 20434: loss: 0.035106, loss_s1: 0.023541, loss_fp: 0.003048, loss_freq: 0.010565
[06:07:40.641] iteration 20435: loss: 0.056897, loss_s1: 0.058637, loss_fp: 0.001056, loss_freq: 0.028347
[06:07:41.269] iteration 20436: loss: 0.045629, loss_s1: 0.025860, loss_fp: 0.002057, loss_freq: 0.020441
[06:07:41.901] iteration 20437: loss: 0.053813, loss_s1: 0.038869, loss_fp: 0.002050, loss_freq: 0.031728
[06:07:42.527] iteration 20438: loss: 0.033824, loss_s1: 0.016939, loss_fp: 0.003259, loss_freq: 0.017620
[06:07:43.148] iteration 20439: loss: 0.085909, loss_s1: 0.061514, loss_fp: 0.003218, loss_freq: 0.065070
[06:07:43.772] iteration 20440: loss: 0.079244, loss_s1: 0.077069, loss_fp: 0.003910, loss_freq: 0.032862
[06:07:44.401] iteration 20441: loss: 0.046178, loss_s1: 0.039903, loss_fp: 0.000749, loss_freq: 0.011287
[06:07:45.021] iteration 20442: loss: 0.036520, loss_s1: 0.023396, loss_fp: 0.000681, loss_freq: 0.017083
[06:07:45.690] iteration 20443: loss: 0.102468, loss_s1: 0.113436, loss_fp: 0.001304, loss_freq: 0.060900
[06:07:46.352] iteration 20444: loss: 0.128291, loss_s1: 0.160481, loss_fp: 0.005547, loss_freq: 0.058217
[06:07:46.959] iteration 20445: loss: 0.056133, loss_s1: 0.052684, loss_fp: 0.004346, loss_freq: 0.014888
[06:07:47.571] iteration 20446: loss: 0.060626, loss_s1: 0.057801, loss_fp: 0.004140, loss_freq: 0.028369
[06:07:48.179] iteration 20447: loss: 0.053053, loss_s1: 0.034663, loss_fp: 0.004213, loss_freq: 0.035329
[06:07:48.789] iteration 20448: loss: 0.067846, loss_s1: 0.047466, loss_fp: 0.005536, loss_freq: 0.049239
[06:07:49.444] iteration 20449: loss: 0.044741, loss_s1: 0.053680, loss_fp: 0.000980, loss_freq: 0.006498
[06:07:50.052] iteration 20450: loss: 0.043372, loss_s1: 0.012164, loss_fp: 0.000585, loss_freq: 0.009802
[06:07:50.667] iteration 20451: loss: 0.036796, loss_s1: 0.023901, loss_fp: 0.004951, loss_freq: 0.012676
[06:07:51.280] iteration 20452: loss: 0.052748, loss_s1: 0.049235, loss_fp: 0.001314, loss_freq: 0.025089
[06:07:51.893] iteration 20453: loss: 0.049427, loss_s1: 0.043568, loss_fp: 0.001033, loss_freq: 0.018544
[06:07:52.520] iteration 20454: loss: 0.076763, loss_s1: 0.077371, loss_fp: 0.007887, loss_freq: 0.027425
[06:07:53.142] iteration 20455: loss: 0.058088, loss_s1: 0.031699, loss_fp: 0.006264, loss_freq: 0.018476
[06:07:53.756] iteration 20456: loss: 0.041756, loss_s1: 0.022783, loss_fp: 0.006020, loss_freq: 0.017452
[06:07:54.371] iteration 20457: loss: 0.055626, loss_s1: 0.047181, loss_fp: 0.001017, loss_freq: 0.038456
[06:07:54.977] iteration 20458: loss: 0.064804, loss_s1: 0.042439, loss_fp: 0.010448, loss_freq: 0.032298
[06:07:55.588] iteration 20459: loss: 0.065269, loss_s1: 0.048164, loss_fp: 0.003440, loss_freq: 0.038632
[06:07:56.207] iteration 20460: loss: 0.064309, loss_s1: 0.048917, loss_fp: 0.001368, loss_freq: 0.038216
[06:07:56.970] iteration 20461: loss: 0.035567, loss_s1: 0.022291, loss_fp: 0.001221, loss_freq: 0.005268
[06:07:57.592] iteration 20462: loss: 0.050781, loss_s1: 0.031013, loss_fp: 0.001217, loss_freq: 0.030449
[06:07:58.237] iteration 20463: loss: 0.040005, loss_s1: 0.034886, loss_fp: 0.001534, loss_freq: 0.010106
[06:07:58.872] iteration 20464: loss: 0.034436, loss_s1: 0.015148, loss_fp: 0.003496, loss_freq: 0.027364
[06:07:59.482] iteration 20465: loss: 0.107220, loss_s1: 0.158293, loss_fp: 0.002567, loss_freq: 0.011643
[06:08:00.098] iteration 20466: loss: 0.050342, loss_s1: 0.028536, loss_fp: 0.002401, loss_freq: 0.049341
[06:08:00.706] iteration 20467: loss: 0.048721, loss_s1: 0.043501, loss_fp: 0.004222, loss_freq: 0.010104
[06:08:01.309] iteration 20468: loss: 0.092116, loss_s1: 0.092597, loss_fp: 0.003734, loss_freq: 0.051366
[06:08:01.918] iteration 20469: loss: 0.033693, loss_s1: 0.008465, loss_fp: 0.002376, loss_freq: 0.027657
[06:08:02.527] iteration 20470: loss: 0.053098, loss_s1: 0.044037, loss_fp: 0.002320, loss_freq: 0.032236
[06:08:03.134] iteration 20471: loss: 0.068173, loss_s1: 0.048773, loss_fp: 0.004491, loss_freq: 0.042151
[06:08:03.742] iteration 20472: loss: 0.039737, loss_s1: 0.023043, loss_fp: 0.002411, loss_freq: 0.018954
[06:08:04.351] iteration 20473: loss: 0.079901, loss_s1: 0.080830, loss_fp: 0.004516, loss_freq: 0.033687
[06:08:04.953] iteration 20474: loss: 0.060897, loss_s1: 0.057453, loss_fp: 0.002577, loss_freq: 0.031442
[06:08:05.556] iteration 20475: loss: 0.044619, loss_s1: 0.023687, loss_fp: 0.002280, loss_freq: 0.036478
[06:08:06.167] iteration 20476: loss: 0.065409, loss_s1: 0.032742, loss_fp: 0.004483, loss_freq: 0.043515
[06:08:06.777] iteration 20477: loss: 0.064403, loss_s1: 0.060129, loss_fp: 0.008964, loss_freq: 0.030456
[06:08:07.383] iteration 20478: loss: 0.098934, loss_s1: 0.108876, loss_fp: 0.006022, loss_freq: 0.040167
[06:08:07.987] iteration 20479: loss: 0.044475, loss_s1: 0.033846, loss_fp: 0.003602, loss_freq: 0.028570
[06:08:08.593] iteration 20480: loss: 0.077454, loss_s1: 0.084192, loss_fp: 0.003849, loss_freq: 0.027729
[06:08:09.209] iteration 20481: loss: 0.042032, loss_s1: 0.031544, loss_fp: 0.004093, loss_freq: 0.011864
[06:08:09.884] iteration 20482: loss: 0.049822, loss_s1: 0.034518, loss_fp: 0.004497, loss_freq: 0.029152
[06:08:10.539] iteration 20483: loss: 0.050276, loss_s1: 0.030434, loss_fp: 0.013957, loss_freq: 0.023282
[06:08:11.180] iteration 20484: loss: 0.045772, loss_s1: 0.037674, loss_fp: 0.012179, loss_freq: 0.009868
[06:08:11.794] iteration 20485: loss: 0.055406, loss_s1: 0.040144, loss_fp: 0.003675, loss_freq: 0.024698
[06:08:12.400] iteration 20486: loss: 0.049616, loss_s1: 0.019042, loss_fp: 0.003324, loss_freq: 0.036769
[06:08:13.010] iteration 20487: loss: 0.063483, loss_s1: 0.060469, loss_fp: 0.001372, loss_freq: 0.041879
[06:08:13.619] iteration 20488: loss: 0.064443, loss_s1: 0.050460, loss_fp: 0.004601, loss_freq: 0.037268
[06:08:14.234] iteration 20489: loss: 0.104740, loss_s1: 0.077633, loss_fp: 0.008403, loss_freq: 0.090246
[06:08:14.882] iteration 20490: loss: 0.039465, loss_s1: 0.020194, loss_fp: 0.002396, loss_freq: 0.011480
[06:08:15.543] iteration 20491: loss: 0.058466, loss_s1: 0.028758, loss_fp: 0.009357, loss_freq: 0.045631
[06:08:16.172] iteration 20492: loss: 0.039444, loss_s1: 0.039966, loss_fp: 0.004546, loss_freq: 0.011743
[06:08:16.784] iteration 20493: loss: 0.065977, loss_s1: 0.035756, loss_fp: 0.007194, loss_freq: 0.041850
[06:08:17.389] iteration 20494: loss: 0.044333, loss_s1: 0.023007, loss_fp: 0.002791, loss_freq: 0.029059
[06:08:17.992] iteration 20495: loss: 0.038429, loss_s1: 0.034057, loss_fp: 0.001868, loss_freq: 0.013752
[06:08:18.599] iteration 20496: loss: 0.091828, loss_s1: 0.094543, loss_fp: 0.001810, loss_freq: 0.057666
[06:08:19.209] iteration 20497: loss: 0.068829, loss_s1: 0.036527, loss_fp: 0.005244, loss_freq: 0.027764
[06:08:19.818] iteration 20498: loss: 0.057536, loss_s1: 0.036971, loss_fp: 0.002863, loss_freq: 0.030886
[06:08:20.424] iteration 20499: loss: 0.053947, loss_s1: 0.048023, loss_fp: 0.005199, loss_freq: 0.026808
[06:08:21.038] iteration 20500: loss: 0.052156, loss_s1: 0.033700, loss_fp: 0.004535, loss_freq: 0.012426
[06:08:21.647] iteration 20501: loss: 0.056658, loss_s1: 0.050124, loss_fp: 0.001221, loss_freq: 0.030900
[06:08:22.264] iteration 20502: loss: 0.031547, loss_s1: 0.019577, loss_fp: 0.002825, loss_freq: 0.006352
[06:08:22.870] iteration 20503: loss: 0.046438, loss_s1: 0.026226, loss_fp: 0.004021, loss_freq: 0.015528
[06:08:23.476] iteration 20504: loss: 0.051877, loss_s1: 0.034396, loss_fp: 0.007652, loss_freq: 0.021309
[06:08:24.085] iteration 20505: loss: 0.033265, loss_s1: 0.025513, loss_fp: 0.003591, loss_freq: 0.012905
[06:08:24.695] iteration 20506: loss: 0.058445, loss_s1: 0.061835, loss_fp: 0.003637, loss_freq: 0.016848
[06:08:25.307] iteration 20507: loss: 0.054346, loss_s1: 0.051647, loss_fp: 0.000735, loss_freq: 0.020586
[06:08:25.919] iteration 20508: loss: 0.050680, loss_s1: 0.047532, loss_fp: 0.002961, loss_freq: 0.022547
[06:08:26.524] iteration 20509: loss: 0.075250, loss_s1: 0.071506, loss_fp: 0.002312, loss_freq: 0.043361
[06:08:27.130] iteration 20510: loss: 0.056535, loss_s1: 0.066124, loss_fp: 0.003720, loss_freq: 0.016079
[06:08:27.770] iteration 20511: loss: 0.052425, loss_s1: 0.041131, loss_fp: 0.004196, loss_freq: 0.018429
[06:08:28.380] iteration 20512: loss: 0.069375, loss_s1: 0.068661, loss_fp: 0.004736, loss_freq: 0.027630
[06:08:28.993] iteration 20513: loss: 0.053449, loss_s1: 0.043040, loss_fp: 0.008374, loss_freq: 0.031966
[06:08:29.602] iteration 20514: loss: 0.050532, loss_s1: 0.047746, loss_fp: 0.003867, loss_freq: 0.005786
[06:08:30.257] iteration 20515: loss: 0.088630, loss_s1: 0.087651, loss_fp: 0.005098, loss_freq: 0.052673
[06:08:30.887] iteration 20516: loss: 0.080681, loss_s1: 0.050043, loss_fp: 0.017486, loss_freq: 0.049292
[06:08:31.495] iteration 20517: loss: 0.049184, loss_s1: 0.050790, loss_fp: 0.002661, loss_freq: 0.011164
[06:08:32.100] iteration 20518: loss: 0.050344, loss_s1: 0.047540, loss_fp: 0.004747, loss_freq: 0.015517
[06:08:32.711] iteration 20519: loss: 0.059976, loss_s1: 0.042673, loss_fp: 0.007619, loss_freq: 0.038569
[06:08:33.324] iteration 20520: loss: 0.075537, loss_s1: 0.042684, loss_fp: 0.014629, loss_freq: 0.055327
[06:08:33.936] iteration 20521: loss: 0.059841, loss_s1: 0.053440, loss_fp: 0.003292, loss_freq: 0.012842
[06:08:34.548] iteration 20522: loss: 0.077325, loss_s1: 0.080080, loss_fp: 0.006367, loss_freq: 0.034795
[06:08:35.165] iteration 20523: loss: 0.056734, loss_s1: 0.033147, loss_fp: 0.005673, loss_freq: 0.042786
[06:08:35.794] iteration 20524: loss: 0.057340, loss_s1: 0.049072, loss_fp: 0.002437, loss_freq: 0.023284
[06:08:36.406] iteration 20525: loss: 0.052267, loss_s1: 0.029825, loss_fp: 0.004534, loss_freq: 0.037991
[06:08:37.019] iteration 20526: loss: 0.063513, loss_s1: 0.057759, loss_fp: 0.003933, loss_freq: 0.022148
[06:08:37.663] iteration 20527: loss: 0.080600, loss_s1: 0.061167, loss_fp: 0.017482, loss_freq: 0.059197
[06:08:38.274] iteration 20528: loss: 0.057196, loss_s1: 0.044890, loss_fp: 0.004207, loss_freq: 0.022578
[06:08:38.891] iteration 20529: loss: 0.066209, loss_s1: 0.064627, loss_fp: 0.003321, loss_freq: 0.028324
[06:08:39.500] iteration 20530: loss: 0.058576, loss_s1: 0.029404, loss_fp: 0.011421, loss_freq: 0.044121
[06:08:40.132] iteration 20531: loss: 0.063778, loss_s1: 0.081803, loss_fp: 0.004436, loss_freq: 0.013767
[06:08:40.753] iteration 20532: loss: 0.061608, loss_s1: 0.061367, loss_fp: 0.005698, loss_freq: 0.021304
[06:08:41.369] iteration 20533: loss: 0.062308, loss_s1: 0.040400, loss_fp: 0.017337, loss_freq: 0.032888
[06:08:41.983] iteration 20534: loss: 0.068919, loss_s1: 0.058953, loss_fp: 0.004348, loss_freq: 0.039390
[06:08:42.605] iteration 20535: loss: 0.093928, loss_s1: 0.092048, loss_fp: 0.006000, loss_freq: 0.041393
[06:08:43.221] iteration 20536: loss: 0.048776, loss_s1: 0.037396, loss_fp: 0.004860, loss_freq: 0.030431
[06:08:43.847] iteration 20537: loss: 0.074901, loss_s1: 0.053695, loss_fp: 0.002136, loss_freq: 0.033642
[06:08:44.459] iteration 20538: loss: 0.057642, loss_s1: 0.029348, loss_fp: 0.005034, loss_freq: 0.048867
[06:08:45.073] iteration 20539: loss: 0.101193, loss_s1: 0.133976, loss_fp: 0.003167, loss_freq: 0.036929
[06:08:45.680] iteration 20540: loss: 0.062583, loss_s1: 0.053755, loss_fp: 0.001689, loss_freq: 0.046222
[06:08:46.290] iteration 20541: loss: 0.094150, loss_s1: 0.088966, loss_fp: 0.003752, loss_freq: 0.044305
[06:08:46.896] iteration 20542: loss: 0.048206, loss_s1: 0.040982, loss_fp: 0.001822, loss_freq: 0.023567
[06:08:47.501] iteration 20543: loss: 0.048984, loss_s1: 0.041768, loss_fp: 0.000860, loss_freq: 0.021509
[06:08:48.110] iteration 20544: loss: 0.048904, loss_s1: 0.037044, loss_fp: 0.008314, loss_freq: 0.016383
[06:08:48.728] iteration 20545: loss: 0.051543, loss_s1: 0.054946, loss_fp: 0.003432, loss_freq: 0.010760
[06:08:49.345] iteration 20546: loss: 0.039143, loss_s1: 0.016058, loss_fp: 0.003108, loss_freq: 0.022722
[06:08:49.961] iteration 20547: loss: 0.049640, loss_s1: 0.024891, loss_fp: 0.007821, loss_freq: 0.032229
[06:08:50.590] iteration 20548: loss: 0.083749, loss_s1: 0.102893, loss_fp: 0.002760, loss_freq: 0.039242
[06:08:51.207] iteration 20549: loss: 0.058540, loss_s1: 0.054830, loss_fp: 0.004245, loss_freq: 0.032983
[06:08:51.836] iteration 20550: loss: 0.066746, loss_s1: 0.043125, loss_fp: 0.003765, loss_freq: 0.039928
[06:08:52.453] iteration 20551: loss: 0.051250, loss_s1: 0.038394, loss_fp: 0.003693, loss_freq: 0.025193
[06:08:53.075] iteration 20552: loss: 0.078391, loss_s1: 0.086810, loss_fp: 0.020115, loss_freq: 0.017444
[06:08:53.693] iteration 20553: loss: 0.106261, loss_s1: 0.120683, loss_fp: 0.003391, loss_freq: 0.053566
[06:08:54.314] iteration 20554: loss: 0.084663, loss_s1: 0.086459, loss_fp: 0.006684, loss_freq: 0.039432
[06:08:54.937] iteration 20555: loss: 0.077012, loss_s1: 0.062501, loss_fp: 0.013334, loss_freq: 0.042870
[06:08:55.610] iteration 20556: loss: 0.061572, loss_s1: 0.059564, loss_fp: 0.001673, loss_freq: 0.007510
[06:08:56.224] iteration 20557: loss: 0.043030, loss_s1: 0.031835, loss_fp: 0.002528, loss_freq: 0.026724
[06:08:56.832] iteration 20558: loss: 0.113411, loss_s1: 0.087630, loss_fp: 0.002150, loss_freq: 0.041910
[06:08:57.437] iteration 20559: loss: 0.052396, loss_s1: 0.044258, loss_fp: 0.004142, loss_freq: 0.026494
[06:08:58.049] iteration 20560: loss: 0.082062, loss_s1: 0.081806, loss_fp: 0.004816, loss_freq: 0.040153
[06:08:58.662] iteration 20561: loss: 0.057668, loss_s1: 0.064092, loss_fp: 0.005068, loss_freq: 0.010977
[06:08:59.284] iteration 20562: loss: 0.082473, loss_s1: 0.046630, loss_fp: 0.010424, loss_freq: 0.077839
[06:08:59.893] iteration 20563: loss: 0.045870, loss_s1: 0.009781, loss_fp: 0.002786, loss_freq: 0.035493
[06:09:00.511] iteration 20564: loss: 0.038485, loss_s1: 0.029681, loss_fp: 0.001987, loss_freq: 0.018002
[06:09:01.142] iteration 20565: loss: 0.043112, loss_s1: 0.031723, loss_fp: 0.002652, loss_freq: 0.015685
[06:09:01.769] iteration 20566: loss: 0.058133, loss_s1: 0.072977, loss_fp: 0.003780, loss_freq: 0.015610
[06:09:02.380] iteration 20567: loss: 0.051203, loss_s1: 0.044461, loss_fp: 0.002289, loss_freq: 0.025877
[06:09:02.997] iteration 20568: loss: 0.108111, loss_s1: 0.116535, loss_fp: 0.004655, loss_freq: 0.046369
[06:09:03.609] iteration 20569: loss: 0.055977, loss_s1: 0.059130, loss_fp: 0.002540, loss_freq: 0.024522
[06:09:04.220] iteration 20570: loss: 0.045859, loss_s1: 0.021275, loss_fp: 0.004389, loss_freq: 0.032004
[06:09:05.197] iteration 20571: loss: 0.069852, loss_s1: 0.076203, loss_fp: 0.004331, loss_freq: 0.027142
[06:09:05.806] iteration 20572: loss: 0.042076, loss_s1: 0.018138, loss_fp: 0.007538, loss_freq: 0.025191
[06:09:06.413] iteration 20573: loss: 0.047306, loss_s1: 0.042537, loss_fp: 0.002961, loss_freq: 0.018095
[06:09:07.020] iteration 20574: loss: 0.049739, loss_s1: 0.041878, loss_fp: 0.001126, loss_freq: 0.023902
[06:09:07.630] iteration 20575: loss: 0.044104, loss_s1: 0.046992, loss_fp: 0.003093, loss_freq: 0.011769
[06:09:08.243] iteration 20576: loss: 0.095362, loss_s1: 0.089371, loss_fp: 0.002980, loss_freq: 0.052554
[06:09:08.853] iteration 20577: loss: 0.069199, loss_s1: 0.078721, loss_fp: 0.007738, loss_freq: 0.017267
[06:09:09.466] iteration 20578: loss: 0.043739, loss_s1: 0.030711, loss_fp: 0.008678, loss_freq: 0.021485
[06:09:10.109] iteration 20579: loss: 0.041623, loss_s1: 0.038528, loss_fp: 0.002522, loss_freq: 0.014763
[06:09:10.787] iteration 20580: loss: 0.104338, loss_s1: 0.099674, loss_fp: 0.009042, loss_freq: 0.049874
[06:09:11.410] iteration 20581: loss: 0.062689, loss_s1: 0.052693, loss_fp: 0.003858, loss_freq: 0.032501
[06:09:12.030] iteration 20582: loss: 0.068029, loss_s1: 0.051983, loss_fp: 0.002306, loss_freq: 0.045454
[06:09:12.714] iteration 20583: loss: 0.048716, loss_s1: 0.035150, loss_fp: 0.001313, loss_freq: 0.032805
[06:09:13.421] iteration 20584: loss: 0.057401, loss_s1: 0.038062, loss_fp: 0.009909, loss_freq: 0.022215
[06:09:14.158] iteration 20585: loss: 0.044341, loss_s1: 0.022034, loss_fp: 0.007518, loss_freq: 0.013154
[06:09:14.853] iteration 20586: loss: 0.054239, loss_s1: 0.041128, loss_fp: 0.005786, loss_freq: 0.026252
[06:09:15.596] iteration 20587: loss: 0.092342, loss_s1: 0.079686, loss_fp: 0.001135, loss_freq: 0.080657
[06:09:16.236] iteration 20588: loss: 0.036000, loss_s1: 0.025970, loss_fp: 0.003437, loss_freq: 0.014717
[06:09:17.109] iteration 20589: loss: 0.112200, loss_s1: 0.100424, loss_fp: 0.014701, loss_freq: 0.073330
[06:09:17.813] iteration 20590: loss: 0.055289, loss_s1: 0.036462, loss_fp: 0.003005, loss_freq: 0.023468
[06:09:18.515] iteration 20591: loss: 0.043012, loss_s1: 0.028207, loss_fp: 0.005164, loss_freq: 0.021112
[06:09:19.258] iteration 20592: loss: 0.046687, loss_s1: 0.029632, loss_fp: 0.003166, loss_freq: 0.034813
[06:09:19.896] iteration 20593: loss: 0.060369, loss_s1: 0.041197, loss_fp: 0.008357, loss_freq: 0.034094
[06:09:20.684] iteration 20594: loss: 0.034639, loss_s1: 0.021235, loss_fp: 0.002915, loss_freq: 0.017401
[06:09:21.320] iteration 20595: loss: 0.081958, loss_s1: 0.066683, loss_fp: 0.001720, loss_freq: 0.054683
[06:09:21.968] iteration 20596: loss: 0.063464, loss_s1: 0.043329, loss_fp: 0.002746, loss_freq: 0.056703
[06:09:22.704] iteration 20597: loss: 0.064894, loss_s1: 0.071620, loss_fp: 0.004728, loss_freq: 0.007622
[06:09:23.385] iteration 20598: loss: 0.090326, loss_s1: 0.054503, loss_fp: 0.004546, loss_freq: 0.054480
[06:09:24.154] iteration 20599: loss: 0.039565, loss_s1: 0.028028, loss_fp: 0.001177, loss_freq: 0.020816
[06:09:24.806] iteration 20600: loss: 0.113522, loss_s1: 0.121544, loss_fp: 0.001456, loss_freq: 0.056109
[06:09:27.995] iteration 20600 : mean_dice : 0.736780
[06:09:28.646] iteration 20601: loss: 0.043610, loss_s1: 0.027012, loss_fp: 0.001768, loss_freq: 0.034451
[06:09:29.256] iteration 20602: loss: 0.080993, loss_s1: 0.071906, loss_fp: 0.006104, loss_freq: 0.034401
[06:09:29.915] iteration 20603: loss: 0.079846, loss_s1: 0.075545, loss_fp: 0.003163, loss_freq: 0.050629
[06:09:30.573] iteration 20604: loss: 0.051213, loss_s1: 0.060453, loss_fp: 0.000985, loss_freq: 0.008128
[06:09:31.235] iteration 20605: loss: 0.054828, loss_s1: 0.055560, loss_fp: 0.002735, loss_freq: 0.030439
[06:09:31.894] iteration 20606: loss: 0.060706, loss_s1: 0.043086, loss_fp: 0.004076, loss_freq: 0.018119
[06:09:32.526] iteration 20607: loss: 0.056189, loss_s1: 0.059113, loss_fp: 0.001739, loss_freq: 0.018889
[06:09:33.160] iteration 20608: loss: 0.057718, loss_s1: 0.051318, loss_fp: 0.002973, loss_freq: 0.031972
[06:09:33.769] iteration 20609: loss: 0.078716, loss_s1: 0.061450, loss_fp: 0.002696, loss_freq: 0.051223
[06:09:34.387] iteration 20610: loss: 0.044370, loss_s1: 0.030069, loss_fp: 0.002766, loss_freq: 0.026909
[06:09:35.003] iteration 20611: loss: 0.060366, loss_s1: 0.056574, loss_fp: 0.003055, loss_freq: 0.028969
[06:09:35.612] iteration 20612: loss: 0.052897, loss_s1: 0.045182, loss_fp: 0.005768, loss_freq: 0.022698
[06:09:36.212] iteration 20613: loss: 0.106979, loss_s1: 0.078756, loss_fp: 0.006840, loss_freq: 0.101761
[06:09:36.885] iteration 20614: loss: 0.080264, loss_s1: 0.070978, loss_fp: 0.007719, loss_freq: 0.059252
[06:09:37.535] iteration 20615: loss: 0.074274, loss_s1: 0.047994, loss_fp: 0.002004, loss_freq: 0.055473
[06:09:38.193] iteration 20616: loss: 0.090237, loss_s1: 0.096279, loss_fp: 0.007364, loss_freq: 0.032341
[06:09:38.883] iteration 20617: loss: 0.050234, loss_s1: 0.028887, loss_fp: 0.007165, loss_freq: 0.032094
[06:09:39.519] iteration 20618: loss: 0.056070, loss_s1: 0.042773, loss_fp: 0.010479, loss_freq: 0.025871
[06:09:40.137] iteration 20619: loss: 0.041771, loss_s1: 0.043211, loss_fp: 0.001242, loss_freq: 0.007723
[06:09:41.003] iteration 20620: loss: 0.042146, loss_s1: 0.020599, loss_fp: 0.004934, loss_freq: 0.018762
[06:09:41.761] iteration 20621: loss: 0.058733, loss_s1: 0.059331, loss_fp: 0.002580, loss_freq: 0.018799
[06:09:42.570] iteration 20622: loss: 0.036650, loss_s1: 0.026352, loss_fp: 0.003121, loss_freq: 0.021812
[06:09:43.233] iteration 20623: loss: 0.041605, loss_s1: 0.022575, loss_fp: 0.000784, loss_freq: 0.017916
[06:09:43.862] iteration 20624: loss: 0.059769, loss_s1: 0.054197, loss_fp: 0.003585, loss_freq: 0.028929
[06:09:44.475] iteration 20625: loss: 0.048406, loss_s1: 0.017514, loss_fp: 0.008191, loss_freq: 0.034948
[06:09:45.103] iteration 20626: loss: 0.038249, loss_s1: 0.016177, loss_fp: 0.003099, loss_freq: 0.020409
[06:09:45.723] iteration 20627: loss: 0.055662, loss_s1: 0.055376, loss_fp: 0.001954, loss_freq: 0.024658
[06:09:46.337] iteration 20628: loss: 0.056288, loss_s1: 0.051699, loss_fp: 0.002122, loss_freq: 0.014907
[06:09:46.945] iteration 20629: loss: 0.029092, loss_s1: 0.015412, loss_fp: 0.001860, loss_freq: 0.017033
[06:09:47.554] iteration 20630: loss: 0.050676, loss_s1: 0.034490, loss_fp: 0.002658, loss_freq: 0.030791
[06:09:48.164] iteration 20631: loss: 0.042251, loss_s1: 0.034088, loss_fp: 0.004700, loss_freq: 0.018207
[06:09:48.768] iteration 20632: loss: 0.085701, loss_s1: 0.072764, loss_fp: 0.001544, loss_freq: 0.036251
[06:09:49.380] iteration 20633: loss: 0.050487, loss_s1: 0.047707, loss_fp: 0.003309, loss_freq: 0.010512
[06:09:49.991] iteration 20634: loss: 0.038745, loss_s1: 0.029882, loss_fp: 0.002987, loss_freq: 0.018237
[06:09:50.622] iteration 20635: loss: 0.037343, loss_s1: 0.014546, loss_fp: 0.009402, loss_freq: 0.010899
[06:09:51.236] iteration 20636: loss: 0.054573, loss_s1: 0.052058, loss_fp: 0.003463, loss_freq: 0.028980
[06:09:51.845] iteration 20637: loss: 0.052815, loss_s1: 0.042621, loss_fp: 0.003213, loss_freq: 0.017909
[06:09:52.457] iteration 20638: loss: 0.113390, loss_s1: 0.095331, loss_fp: 0.006411, loss_freq: 0.088618
[06:09:53.068] iteration 20639: loss: 0.044663, loss_s1: 0.025153, loss_fp: 0.004965, loss_freq: 0.028715
[06:09:53.677] iteration 20640: loss: 0.034803, loss_s1: 0.023906, loss_fp: 0.002167, loss_freq: 0.018619
[06:09:54.285] iteration 20641: loss: 0.063087, loss_s1: 0.052305, loss_fp: 0.004173, loss_freq: 0.032406
[06:09:54.902] iteration 20642: loss: 0.042066, loss_s1: 0.021145, loss_fp: 0.001160, loss_freq: 0.026018
[06:09:55.518] iteration 20643: loss: 0.051155, loss_s1: 0.024775, loss_fp: 0.005567, loss_freq: 0.042935
[06:09:56.131] iteration 20644: loss: 0.055862, loss_s1: 0.057653, loss_fp: 0.002814, loss_freq: 0.018221
[06:09:56.745] iteration 20645: loss: 0.058522, loss_s1: 0.024952, loss_fp: 0.004852, loss_freq: 0.054890
[06:09:57.356] iteration 20646: loss: 0.045700, loss_s1: 0.033044, loss_fp: 0.006602, loss_freq: 0.014187
[06:09:57.965] iteration 20647: loss: 0.064823, loss_s1: 0.068549, loss_fp: 0.001933, loss_freq: 0.022024
[06:09:58.574] iteration 20648: loss: 0.069691, loss_s1: 0.054456, loss_fp: 0.003355, loss_freq: 0.046762
[06:09:59.186] iteration 20649: loss: 0.058253, loss_s1: 0.058716, loss_fp: 0.008056, loss_freq: 0.027883
[06:09:59.818] iteration 20650: loss: 0.069430, loss_s1: 0.044639, loss_fp: 0.003754, loss_freq: 0.051037
[06:10:00.435] iteration 20651: loss: 0.097833, loss_s1: 0.060053, loss_fp: 0.010249, loss_freq: 0.077558
[06:10:01.077] iteration 20652: loss: 0.071760, loss_s1: 0.053923, loss_fp: 0.005742, loss_freq: 0.053511
[06:10:01.705] iteration 20653: loss: 0.046981, loss_s1: 0.023873, loss_fp: 0.007978, loss_freq: 0.030590
[06:10:02.323] iteration 20654: loss: 0.051220, loss_s1: 0.050471, loss_fp: 0.003185, loss_freq: 0.018447
[06:10:02.949] iteration 20655: loss: 0.054356, loss_s1: 0.052533, loss_fp: 0.002750, loss_freq: 0.019455
[06:10:03.570] iteration 20656: loss: 0.058494, loss_s1: 0.063672, loss_fp: 0.002050, loss_freq: 0.018515
[06:10:04.188] iteration 20657: loss: 0.053346, loss_s1: 0.050687, loss_fp: 0.002550, loss_freq: 0.026184
[06:10:04.800] iteration 20658: loss: 0.045801, loss_s1: 0.041606, loss_fp: 0.004603, loss_freq: 0.017557
[06:10:05.420] iteration 20659: loss: 0.095769, loss_s1: 0.105597, loss_fp: 0.005413, loss_freq: 0.048973
[06:10:06.026] iteration 20660: loss: 0.044636, loss_s1: 0.014000, loss_fp: 0.003700, loss_freq: 0.019930
[06:10:06.638] iteration 20661: loss: 0.055266, loss_s1: 0.054716, loss_fp: 0.002530, loss_freq: 0.023643
[06:10:07.246] iteration 20662: loss: 0.055116, loss_s1: 0.044420, loss_fp: 0.001880, loss_freq: 0.043461
[06:10:07.851] iteration 20663: loss: 0.074530, loss_s1: 0.071288, loss_fp: 0.009999, loss_freq: 0.033579
[06:10:08.467] iteration 20664: loss: 0.064720, loss_s1: 0.077567, loss_fp: 0.002411, loss_freq: 0.023692
[06:10:09.124] iteration 20665: loss: 0.068616, loss_s1: 0.066346, loss_fp: 0.008242, loss_freq: 0.028037
[06:10:09.740] iteration 20666: loss: 0.072884, loss_s1: 0.087177, loss_fp: 0.002168, loss_freq: 0.030177
[06:10:10.349] iteration 20667: loss: 0.094350, loss_s1: 0.102793, loss_fp: 0.006315, loss_freq: 0.039605
[06:10:10.958] iteration 20668: loss: 0.079895, loss_s1: 0.061337, loss_fp: 0.003543, loss_freq: 0.052903
[06:10:11.567] iteration 20669: loss: 0.063387, loss_s1: 0.046850, loss_fp: 0.002143, loss_freq: 0.047161
[06:10:12.179] iteration 20670: loss: 0.038401, loss_s1: 0.020504, loss_fp: 0.002064, loss_freq: 0.016113
[06:10:12.786] iteration 20671: loss: 0.059221, loss_s1: 0.049572, loss_fp: 0.003628, loss_freq: 0.034477
[06:10:13.456] iteration 20672: loss: 0.054214, loss_s1: 0.055577, loss_fp: 0.003842, loss_freq: 0.012813
[06:10:14.076] iteration 20673: loss: 0.055624, loss_s1: 0.042993, loss_fp: 0.005714, loss_freq: 0.031224
[06:10:14.690] iteration 20674: loss: 0.042596, loss_s1: 0.037642, loss_fp: 0.002941, loss_freq: 0.016233
[06:10:15.307] iteration 20675: loss: 0.041725, loss_s1: 0.039891, loss_fp: 0.000141, loss_freq: 0.017174
[06:10:15.920] iteration 20676: loss: 0.069701, loss_s1: 0.079830, loss_fp: 0.002567, loss_freq: 0.021188
[06:10:16.528] iteration 20677: loss: 0.057725, loss_s1: 0.052181, loss_fp: 0.001672, loss_freq: 0.029021
[06:10:17.136] iteration 20678: loss: 0.043847, loss_s1: 0.015365, loss_fp: 0.004690, loss_freq: 0.037707
[06:10:17.747] iteration 20679: loss: 0.052183, loss_s1: 0.035229, loss_fp: 0.003463, loss_freq: 0.027538
[06:10:18.357] iteration 20680: loss: 0.048823, loss_s1: 0.032840, loss_fp: 0.001491, loss_freq: 0.035668
[06:10:18.965] iteration 20681: loss: 0.050586, loss_s1: 0.035750, loss_fp: 0.006148, loss_freq: 0.026286
[06:10:19.569] iteration 20682: loss: 0.043989, loss_s1: 0.033075, loss_fp: 0.005209, loss_freq: 0.016452
[06:10:20.174] iteration 20683: loss: 0.050706, loss_s1: 0.045015, loss_fp: 0.004767, loss_freq: 0.021809
[06:10:20.853] iteration 20684: loss: 0.035647, loss_s1: 0.026449, loss_fp: 0.004447, loss_freq: 0.013785
[06:10:21.512] iteration 20685: loss: 0.107567, loss_s1: 0.081115, loss_fp: 0.002846, loss_freq: 0.095990
[06:10:22.165] iteration 20686: loss: 0.073152, loss_s1: 0.051506, loss_fp: 0.012852, loss_freq: 0.044831
[06:10:22.828] iteration 20687: loss: 0.052537, loss_s1: 0.047568, loss_fp: 0.002498, loss_freq: 0.018295
[06:10:23.485] iteration 20688: loss: 0.089366, loss_s1: 0.075116, loss_fp: 0.017434, loss_freq: 0.055909
[06:10:24.153] iteration 20689: loss: 0.110673, loss_s1: 0.079861, loss_fp: 0.004267, loss_freq: 0.091775
[06:10:24.809] iteration 20690: loss: 0.037066, loss_s1: 0.035262, loss_fp: 0.000727, loss_freq: 0.004660
[06:10:25.481] iteration 20691: loss: 0.043818, loss_s1: 0.018508, loss_fp: 0.006884, loss_freq: 0.009655
[06:10:26.155] iteration 20692: loss: 0.048436, loss_s1: 0.038487, loss_fp: 0.003575, loss_freq: 0.029879
[06:10:26.811] iteration 20693: loss: 0.082699, loss_s1: 0.059778, loss_fp: 0.004382, loss_freq: 0.053773
[06:10:27.463] iteration 20694: loss: 0.049888, loss_s1: 0.031593, loss_fp: 0.004135, loss_freq: 0.027541
[06:10:28.121] iteration 20695: loss: 0.060865, loss_s1: 0.034490, loss_fp: 0.008631, loss_freq: 0.048545
[06:10:28.775] iteration 20696: loss: 0.094148, loss_s1: 0.108915, loss_fp: 0.002248, loss_freq: 0.046524
[06:10:29.426] iteration 20697: loss: 0.067754, loss_s1: 0.039528, loss_fp: 0.003504, loss_freq: 0.067956
[06:10:30.042] iteration 20698: loss: 0.079191, loss_s1: 0.100616, loss_fp: 0.001510, loss_freq: 0.015196
[06:10:30.649] iteration 20699: loss: 0.066033, loss_s1: 0.036865, loss_fp: 0.004327, loss_freq: 0.027082
[06:10:31.264] iteration 20700: loss: 0.059787, loss_s1: 0.026366, loss_fp: 0.002782, loss_freq: 0.045045
[06:10:31.912] iteration 20701: loss: 0.057197, loss_s1: 0.066508, loss_fp: 0.005095, loss_freq: 0.012886
[06:10:32.565] iteration 20702: loss: 0.084412, loss_s1: 0.052460, loss_fp: 0.003022, loss_freq: 0.049274
[06:10:33.220] iteration 20703: loss: 0.088755, loss_s1: 0.097193, loss_fp: 0.003240, loss_freq: 0.041193
[06:10:33.872] iteration 20704: loss: 0.068871, loss_s1: 0.084991, loss_fp: 0.002167, loss_freq: 0.020269
[06:10:34.483] iteration 20705: loss: 0.092660, loss_s1: 0.042419, loss_fp: 0.009733, loss_freq: 0.098044
[06:10:35.122] iteration 20706: loss: 0.041648, loss_s1: 0.043153, loss_fp: 0.001933, loss_freq: 0.008574
[06:10:35.737] iteration 20707: loss: 0.065421, loss_s1: 0.065683, loss_fp: 0.001502, loss_freq: 0.011713
[06:10:36.346] iteration 20708: loss: 0.052308, loss_s1: 0.047307, loss_fp: 0.004280, loss_freq: 0.027659
[06:10:36.953] iteration 20709: loss: 0.084464, loss_s1: 0.072733, loss_fp: 0.003418, loss_freq: 0.059508
[06:10:37.562] iteration 20710: loss: 0.061457, loss_s1: 0.035936, loss_fp: 0.006618, loss_freq: 0.055935
[06:10:38.172] iteration 20711: loss: 0.035467, loss_s1: 0.018725, loss_fp: 0.003455, loss_freq: 0.013394
[06:10:38.803] iteration 20712: loss: 0.046884, loss_s1: 0.032641, loss_fp: 0.001843, loss_freq: 0.019301
[06:10:39.413] iteration 20713: loss: 0.050235, loss_s1: 0.032806, loss_fp: 0.005583, loss_freq: 0.027624
[06:10:40.067] iteration 20714: loss: 0.070665, loss_s1: 0.081691, loss_fp: 0.009743, loss_freq: 0.009855
[06:10:40.725] iteration 20715: loss: 0.026134, loss_s1: 0.012236, loss_fp: 0.002715, loss_freq: 0.011189
[06:10:41.386] iteration 20716: loss: 0.050364, loss_s1: 0.025429, loss_fp: 0.004753, loss_freq: 0.028295
[06:10:42.043] iteration 20717: loss: 0.065683, loss_s1: 0.063113, loss_fp: 0.004983, loss_freq: 0.026830
[06:10:42.659] iteration 20718: loss: 0.075892, loss_s1: 0.078355, loss_fp: 0.003401, loss_freq: 0.044025
[06:10:43.278] iteration 20719: loss: 0.046189, loss_s1: 0.037609, loss_fp: 0.006107, loss_freq: 0.025750
[06:10:43.900] iteration 20720: loss: 0.072964, loss_s1: 0.054422, loss_fp: 0.002637, loss_freq: 0.033129
[06:10:44.523] iteration 20721: loss: 0.068307, loss_s1: 0.044108, loss_fp: 0.016510, loss_freq: 0.033078
[06:10:45.135] iteration 20722: loss: 0.099967, loss_s1: 0.078979, loss_fp: 0.007878, loss_freq: 0.070754
[06:10:45.814] iteration 20723: loss: 0.088768, loss_s1: 0.097525, loss_fp: 0.002693, loss_freq: 0.043626
[06:10:46.435] iteration 20724: loss: 0.102198, loss_s1: 0.112683, loss_fp: 0.007291, loss_freq: 0.038809
[06:10:47.044] iteration 20725: loss: 0.084824, loss_s1: 0.071186, loss_fp: 0.008273, loss_freq: 0.047425
[06:10:47.655] iteration 20726: loss: 0.052199, loss_s1: 0.051366, loss_fp: 0.000729, loss_freq: 0.009301
[06:10:48.263] iteration 20727: loss: 0.030234, loss_s1: 0.016788, loss_fp: 0.005120, loss_freq: 0.018469
[06:10:48.876] iteration 20728: loss: 0.105136, loss_s1: 0.129006, loss_fp: 0.001934, loss_freq: 0.047801
[06:10:49.487] iteration 20729: loss: 0.045729, loss_s1: 0.028439, loss_fp: 0.003005, loss_freq: 0.025418
[06:10:50.139] iteration 20730: loss: 0.077640, loss_s1: 0.057899, loss_fp: 0.008176, loss_freq: 0.022150
[06:10:50.759] iteration 20731: loss: 0.033443, loss_s1: 0.026053, loss_fp: 0.002366, loss_freq: 0.006015
[06:10:51.372] iteration 20732: loss: 0.057214, loss_s1: 0.044194, loss_fp: 0.013609, loss_freq: 0.032798
[06:10:51.988] iteration 20733: loss: 0.048641, loss_s1: 0.034512, loss_fp: 0.006557, loss_freq: 0.009664
[06:10:52.603] iteration 20734: loss: 0.099993, loss_s1: 0.060414, loss_fp: 0.004011, loss_freq: 0.092423
[06:10:53.218] iteration 20735: loss: 0.032961, loss_s1: 0.010694, loss_fp: 0.001370, loss_freq: 0.011547
[06:10:53.833] iteration 20736: loss: 0.108159, loss_s1: 0.120407, loss_fp: 0.008980, loss_freq: 0.042769
[06:10:54.453] iteration 20737: loss: 0.040735, loss_s1: 0.022614, loss_fp: 0.001595, loss_freq: 0.021862
[06:10:55.063] iteration 20738: loss: 0.061267, loss_s1: 0.059452, loss_fp: 0.002192, loss_freq: 0.020163
[06:10:55.666] iteration 20739: loss: 0.077254, loss_s1: 0.068556, loss_fp: 0.005290, loss_freq: 0.048782
[06:10:56.272] iteration 20740: loss: 0.066359, loss_s1: 0.071001, loss_fp: 0.003114, loss_freq: 0.023736
[06:10:57.281] iteration 20741: loss: 0.058928, loss_s1: 0.058110, loss_fp: 0.002477, loss_freq: 0.023357
[06:10:57.931] iteration 20742: loss: 0.066833, loss_s1: 0.069793, loss_fp: 0.003691, loss_freq: 0.019561
[06:10:58.588] iteration 20743: loss: 0.059847, loss_s1: 0.057641, loss_fp: 0.002983, loss_freq: 0.024961
[06:10:59.248] iteration 20744: loss: 0.061654, loss_s1: 0.041496, loss_fp: 0.001448, loss_freq: 0.015261
[06:10:59.893] iteration 20745: loss: 0.053397, loss_s1: 0.027698, loss_fp: 0.007803, loss_freq: 0.013559
[06:11:00.510] iteration 20746: loss: 0.059506, loss_s1: 0.056791, loss_fp: 0.002435, loss_freq: 0.017223
[06:11:01.121] iteration 20747: loss: 0.073784, loss_s1: 0.069098, loss_fp: 0.008465, loss_freq: 0.038744
[06:11:01.728] iteration 20748: loss: 0.048269, loss_s1: 0.039378, loss_fp: 0.007542, loss_freq: 0.017396
[06:11:02.337] iteration 20749: loss: 0.046413, loss_s1: 0.056990, loss_fp: 0.002477, loss_freq: 0.013162
[06:11:02.949] iteration 20750: loss: 0.067953, loss_s1: 0.051361, loss_fp: 0.008130, loss_freq: 0.032653
[06:11:03.565] iteration 20751: loss: 0.056024, loss_s1: 0.028627, loss_fp: 0.001453, loss_freq: 0.044092
[06:11:04.170] iteration 20752: loss: 0.090976, loss_s1: 0.100958, loss_fp: 0.001863, loss_freq: 0.043028
[06:11:04.815] iteration 20753: loss: 0.065587, loss_s1: 0.055569, loss_fp: 0.005032, loss_freq: 0.039731
[06:11:05.421] iteration 20754: loss: 0.064912, loss_s1: 0.063172, loss_fp: 0.008727, loss_freq: 0.023837
[06:11:06.031] iteration 20755: loss: 0.077162, loss_s1: 0.047395, loss_fp: 0.005324, loss_freq: 0.044562
[06:11:06.633] iteration 20756: loss: 0.058034, loss_s1: 0.072110, loss_fp: 0.001798, loss_freq: 0.011572
[06:11:07.245] iteration 20757: loss: 0.089361, loss_s1: 0.082085, loss_fp: 0.002535, loss_freq: 0.073947
[06:11:07.856] iteration 20758: loss: 0.044110, loss_s1: 0.024788, loss_fp: 0.007911, loss_freq: 0.017650
[06:11:08.470] iteration 20759: loss: 0.088571, loss_s1: 0.098093, loss_fp: 0.007535, loss_freq: 0.044230
[06:11:09.081] iteration 20760: loss: 0.066250, loss_s1: 0.066860, loss_fp: 0.006759, loss_freq: 0.024760
[06:11:09.688] iteration 20761: loss: 0.075149, loss_s1: 0.047778, loss_fp: 0.009830, loss_freq: 0.057589
[06:11:10.298] iteration 20762: loss: 0.058994, loss_s1: 0.041992, loss_fp: 0.002357, loss_freq: 0.051773
[06:11:10.909] iteration 20763: loss: 0.053208, loss_s1: 0.035985, loss_fp: 0.000814, loss_freq: 0.020924
[06:11:11.521] iteration 20764: loss: 0.062379, loss_s1: 0.073029, loss_fp: 0.001875, loss_freq: 0.020283
[06:11:12.164] iteration 20765: loss: 0.052440, loss_s1: 0.036654, loss_fp: 0.005498, loss_freq: 0.029148
[06:11:12.770] iteration 20766: loss: 0.060924, loss_s1: 0.039243, loss_fp: 0.002598, loss_freq: 0.054859
[06:11:13.380] iteration 20767: loss: 0.051944, loss_s1: 0.025944, loss_fp: 0.002893, loss_freq: 0.028318
[06:11:13.991] iteration 20768: loss: 0.111025, loss_s1: 0.097701, loss_fp: 0.016729, loss_freq: 0.061516
[06:11:14.603] iteration 20769: loss: 0.061083, loss_s1: 0.035259, loss_fp: 0.009203, loss_freq: 0.038747
[06:11:15.210] iteration 20770: loss: 0.101289, loss_s1: 0.078778, loss_fp: 0.009591, loss_freq: 0.077846
[06:11:15.817] iteration 20771: loss: 0.057210, loss_s1: 0.033412, loss_fp: 0.002034, loss_freq: 0.040498
[06:11:16.423] iteration 20772: loss: 0.074923, loss_s1: 0.018864, loss_fp: 0.001364, loss_freq: 0.085804
[06:11:17.026] iteration 20773: loss: 0.048110, loss_s1: 0.040491, loss_fp: 0.005645, loss_freq: 0.025560
[06:11:17.630] iteration 20774: loss: 0.039771, loss_s1: 0.034190, loss_fp: 0.001217, loss_freq: 0.009681
[06:11:18.238] iteration 20775: loss: 0.055136, loss_s1: 0.057421, loss_fp: 0.002291, loss_freq: 0.025393
[06:11:18.846] iteration 20776: loss: 0.051846, loss_s1: 0.030730, loss_fp: 0.002494, loss_freq: 0.018985
[06:11:19.459] iteration 20777: loss: 0.076000, loss_s1: 0.076697, loss_fp: 0.002927, loss_freq: 0.039153
[06:11:20.062] iteration 20778: loss: 0.056870, loss_s1: 0.037829, loss_fp: 0.004302, loss_freq: 0.044617
[06:11:20.748] iteration 20779: loss: 0.095707, loss_s1: 0.117316, loss_fp: 0.005470, loss_freq: 0.034930
[06:11:21.425] iteration 20780: loss: 0.066661, loss_s1: 0.066101, loss_fp: 0.005417, loss_freq: 0.025605
[06:11:22.035] iteration 20781: loss: 0.052295, loss_s1: 0.040945, loss_fp: 0.006475, loss_freq: 0.008924
[06:11:22.640] iteration 20782: loss: 0.049719, loss_s1: 0.035799, loss_fp: 0.001496, loss_freq: 0.029020
[06:11:23.248] iteration 20783: loss: 0.077777, loss_s1: 0.082632, loss_fp: 0.005036, loss_freq: 0.040010
[06:11:23.862] iteration 20784: loss: 0.127130, loss_s1: 0.134800, loss_fp: 0.002213, loss_freq: 0.089778
[06:11:24.488] iteration 20785: loss: 0.064658, loss_s1: 0.046728, loss_fp: 0.008448, loss_freq: 0.020554
[06:11:25.117] iteration 20786: loss: 0.085763, loss_s1: 0.093150, loss_fp: 0.004935, loss_freq: 0.034918
[06:11:25.741] iteration 20787: loss: 0.050788, loss_s1: 0.043004, loss_fp: 0.005096, loss_freq: 0.020672
[06:11:26.364] iteration 20788: loss: 0.065654, loss_s1: 0.054281, loss_fp: 0.005129, loss_freq: 0.024133
[06:11:26.994] iteration 20789: loss: 0.040571, loss_s1: 0.017183, loss_fp: 0.003694, loss_freq: 0.015329
[06:11:27.620] iteration 20790: loss: 0.055916, loss_s1: 0.039148, loss_fp: 0.005361, loss_freq: 0.016920
[06:11:28.280] iteration 20791: loss: 0.040317, loss_s1: 0.030089, loss_fp: 0.003354, loss_freq: 0.017648
[06:11:28.904] iteration 20792: loss: 0.059595, loss_s1: 0.070421, loss_fp: 0.001505, loss_freq: 0.025530
[06:11:29.527] iteration 20793: loss: 0.037544, loss_s1: 0.016032, loss_fp: 0.001608, loss_freq: 0.018382
[06:11:30.144] iteration 20794: loss: 0.072065, loss_s1: 0.067071, loss_fp: 0.009147, loss_freq: 0.036256
[06:11:30.764] iteration 20795: loss: 0.035731, loss_s1: 0.007630, loss_fp: 0.001632, loss_freq: 0.027579
[06:11:31.394] iteration 20796: loss: 0.041109, loss_s1: 0.018719, loss_fp: 0.001948, loss_freq: 0.024890
[06:11:32.100] iteration 20797: loss: 0.045696, loss_s1: 0.027200, loss_fp: 0.002839, loss_freq: 0.027959
[06:11:32.790] iteration 20798: loss: 0.062370, loss_s1: 0.044186, loss_fp: 0.001043, loss_freq: 0.022623
[06:11:33.459] iteration 20799: loss: 0.043307, loss_s1: 0.019325, loss_fp: 0.002689, loss_freq: 0.017065
[06:11:34.121] iteration 20800: loss: 0.052925, loss_s1: 0.030003, loss_fp: 0.003761, loss_freq: 0.035671
[06:11:37.430] iteration 20800 : mean_dice : 0.740819
[06:11:38.063] iteration 20801: loss: 0.034543, loss_s1: 0.031921, loss_fp: 0.003184, loss_freq: 0.010238
[06:11:38.683] iteration 20802: loss: 0.063548, loss_s1: 0.045092, loss_fp: 0.001894, loss_freq: 0.045118
[06:11:39.300] iteration 20803: loss: 0.035663, loss_s1: 0.029134, loss_fp: 0.000607, loss_freq: 0.004632
[06:11:39.913] iteration 20804: loss: 0.028972, loss_s1: 0.015713, loss_fp: 0.001949, loss_freq: 0.013651
[06:11:40.524] iteration 20805: loss: 0.038662, loss_s1: 0.022120, loss_fp: 0.006646, loss_freq: 0.011436
[06:11:41.134] iteration 20806: loss: 0.068174, loss_s1: 0.061845, loss_fp: 0.005008, loss_freq: 0.046956
[06:11:41.761] iteration 20807: loss: 0.045926, loss_s1: 0.034236, loss_fp: 0.004800, loss_freq: 0.019893
[06:11:42.373] iteration 20808: loss: 0.133675, loss_s1: 0.109775, loss_fp: 0.022992, loss_freq: 0.082189
[06:11:43.040] iteration 20809: loss: 0.045212, loss_s1: 0.015822, loss_fp: 0.005084, loss_freq: 0.032655
[06:11:43.701] iteration 20810: loss: 0.057578, loss_s1: 0.034957, loss_fp: 0.001574, loss_freq: 0.059023
[06:11:44.360] iteration 20811: loss: 0.068450, loss_s1: 0.069268, loss_fp: 0.001088, loss_freq: 0.021819
[06:11:45.014] iteration 20812: loss: 0.047516, loss_s1: 0.039654, loss_fp: 0.002744, loss_freq: 0.018895
[06:11:45.669] iteration 20813: loss: 0.053447, loss_s1: 0.048116, loss_fp: 0.004469, loss_freq: 0.030015
[06:11:46.321] iteration 20814: loss: 0.064410, loss_s1: 0.077083, loss_fp: 0.002761, loss_freq: 0.009726
[06:11:46.987] iteration 20815: loss: 0.071379, loss_s1: 0.022916, loss_fp: 0.002302, loss_freq: 0.056032
[06:11:47.648] iteration 20816: loss: 0.058025, loss_s1: 0.029735, loss_fp: 0.015467, loss_freq: 0.036130
[06:11:48.305] iteration 20817: loss: 0.058555, loss_s1: 0.053358, loss_fp: 0.003450, loss_freq: 0.026175
[06:11:48.929] iteration 20818: loss: 0.133953, loss_s1: 0.084987, loss_fp: 0.004574, loss_freq: 0.068497
[06:11:49.583] iteration 20819: loss: 0.060092, loss_s1: 0.043755, loss_fp: 0.004419, loss_freq: 0.042060
[06:11:50.191] iteration 20820: loss: 0.041562, loss_s1: 0.025031, loss_fp: 0.004458, loss_freq: 0.016265
[06:11:50.794] iteration 20821: loss: 0.130158, loss_s1: 0.122405, loss_fp: 0.004027, loss_freq: 0.046312
[06:11:51.401] iteration 20822: loss: 0.066597, loss_s1: 0.050851, loss_fp: 0.007748, loss_freq: 0.043687
[06:11:52.012] iteration 20823: loss: 0.056983, loss_s1: 0.039223, loss_fp: 0.011505, loss_freq: 0.023725
[06:11:52.619] iteration 20824: loss: 0.070137, loss_s1: 0.056779, loss_fp: 0.011026, loss_freq: 0.015165
[06:11:53.229] iteration 20825: loss: 0.051185, loss_s1: 0.049617, loss_fp: 0.003484, loss_freq: 0.017530
[06:11:53.841] iteration 20826: loss: 0.058054, loss_s1: 0.057304, loss_fp: 0.002254, loss_freq: 0.023016
[06:11:54.451] iteration 20827: loss: 0.067256, loss_s1: 0.055294, loss_fp: 0.005073, loss_freq: 0.051919
[06:11:55.055] iteration 20828: loss: 0.086474, loss_s1: 0.078947, loss_fp: 0.013849, loss_freq: 0.028387
[06:11:55.663] iteration 20829: loss: 0.055274, loss_s1: 0.052929, loss_fp: 0.001447, loss_freq: 0.021795
[06:11:56.266] iteration 20830: loss: 0.037028, loss_s1: 0.026015, loss_fp: 0.001452, loss_freq: 0.010337
[06:11:56.881] iteration 20831: loss: 0.074781, loss_s1: 0.088201, loss_fp: 0.003602, loss_freq: 0.016350
[06:11:57.496] iteration 20832: loss: 0.056214, loss_s1: 0.049776, loss_fp: 0.003350, loss_freq: 0.023908
[06:11:58.105] iteration 20833: loss: 0.057134, loss_s1: 0.037056, loss_fp: 0.002316, loss_freq: 0.026001
[06:11:58.711] iteration 20834: loss: 0.043123, loss_s1: 0.039289, loss_fp: 0.001951, loss_freq: 0.013418
[06:11:59.322] iteration 20835: loss: 0.059339, loss_s1: 0.060874, loss_fp: 0.000573, loss_freq: 0.020446
[06:11:59.939] iteration 20836: loss: 0.044631, loss_s1: 0.021872, loss_fp: 0.000942, loss_freq: 0.020392
[06:12:00.552] iteration 20837: loss: 0.057153, loss_s1: 0.041418, loss_fp: 0.003229, loss_freq: 0.031195
[06:12:01.164] iteration 20838: loss: 0.111497, loss_s1: 0.126645, loss_fp: 0.003540, loss_freq: 0.056823
[06:12:01.774] iteration 20839: loss: 0.046035, loss_s1: 0.045370, loss_fp: 0.001239, loss_freq: 0.016171
[06:12:02.386] iteration 20840: loss: 0.042285, loss_s1: 0.022172, loss_fp: 0.001992, loss_freq: 0.020856
[06:12:02.994] iteration 20841: loss: 0.058245, loss_s1: 0.057398, loss_fp: 0.003304, loss_freq: 0.030630
[06:12:03.602] iteration 20842: loss: 0.053916, loss_s1: 0.043936, loss_fp: 0.002596, loss_freq: 0.011969
[06:12:04.234] iteration 20843: loss: 0.039380, loss_s1: 0.031658, loss_fp: 0.003197, loss_freq: 0.015546
[06:12:04.934] iteration 20844: loss: 0.041934, loss_s1: 0.016046, loss_fp: 0.002731, loss_freq: 0.012982
[06:12:05.547] iteration 20845: loss: 0.040389, loss_s1: 0.027728, loss_fp: 0.002007, loss_freq: 0.026855
[06:12:06.304] iteration 20846: loss: 0.044675, loss_s1: 0.026206, loss_fp: 0.006088, loss_freq: 0.020420
[06:12:06.992] iteration 20847: loss: 0.046668, loss_s1: 0.028925, loss_fp: 0.003568, loss_freq: 0.020239
[06:12:07.601] iteration 20848: loss: 0.079334, loss_s1: 0.073073, loss_fp: 0.007020, loss_freq: 0.044828
[06:12:08.212] iteration 20849: loss: 0.057710, loss_s1: 0.027574, loss_fp: 0.003801, loss_freq: 0.042700
[06:12:08.871] iteration 20850: loss: 0.056277, loss_s1: 0.057968, loss_fp: 0.002763, loss_freq: 0.020954
[06:12:09.492] iteration 20851: loss: 0.060203, loss_s1: 0.070199, loss_fp: 0.002083, loss_freq: 0.013289
[06:12:10.113] iteration 20852: loss: 0.046373, loss_s1: 0.028011, loss_fp: 0.003012, loss_freq: 0.022055
[06:12:10.725] iteration 20853: loss: 0.052658, loss_s1: 0.041301, loss_fp: 0.002513, loss_freq: 0.035259
[06:12:11.331] iteration 20854: loss: 0.056717, loss_s1: 0.053712, loss_fp: 0.001825, loss_freq: 0.015757
[06:12:11.946] iteration 20855: loss: 0.063224, loss_s1: 0.029087, loss_fp: 0.005107, loss_freq: 0.048368
[06:12:12.571] iteration 20856: loss: 0.093947, loss_s1: 0.045161, loss_fp: 0.005734, loss_freq: 0.097921
[06:12:13.267] iteration 20857: loss: 0.083908, loss_s1: 0.113987, loss_fp: 0.004371, loss_freq: 0.017081
[06:12:13.923] iteration 20858: loss: 0.043304, loss_s1: 0.035856, loss_fp: 0.002570, loss_freq: 0.021057
[06:12:14.568] iteration 20859: loss: 0.097685, loss_s1: 0.072037, loss_fp: 0.005571, loss_freq: 0.085010
[06:12:15.215] iteration 20860: loss: 0.071701, loss_s1: 0.063631, loss_fp: 0.007600, loss_freq: 0.032302
[06:12:15.864] iteration 20861: loss: 0.055040, loss_s1: 0.060868, loss_fp: 0.005378, loss_freq: 0.009549
[06:12:16.517] iteration 20862: loss: 0.082313, loss_s1: 0.091906, loss_fp: 0.001050, loss_freq: 0.046481
[06:12:17.124] iteration 20863: loss: 0.090547, loss_s1: 0.081923, loss_fp: 0.009803, loss_freq: 0.057200
[06:12:17.729] iteration 20864: loss: 0.040842, loss_s1: 0.031046, loss_fp: 0.002877, loss_freq: 0.019430
[06:12:18.346] iteration 20865: loss: 0.058035, loss_s1: 0.045722, loss_fp: 0.002499, loss_freq: 0.030698
[06:12:19.051] iteration 20866: loss: 0.067166, loss_s1: 0.073362, loss_fp: 0.002282, loss_freq: 0.025335
[06:12:19.713] iteration 20867: loss: 0.079660, loss_s1: 0.081368, loss_fp: 0.003341, loss_freq: 0.051399
[06:12:20.375] iteration 20868: loss: 0.057403, loss_s1: 0.050721, loss_fp: 0.006923, loss_freq: 0.012037
[06:12:21.014] iteration 20869: loss: 0.051363, loss_s1: 0.053810, loss_fp: 0.007951, loss_freq: 0.015305
[06:12:21.627] iteration 20870: loss: 0.076318, loss_s1: 0.053262, loss_fp: 0.005830, loss_freq: 0.058058
[06:12:22.239] iteration 20871: loss: 0.060422, loss_s1: 0.067535, loss_fp: 0.003270, loss_freq: 0.025031
[06:12:22.848] iteration 20872: loss: 0.088457, loss_s1: 0.045667, loss_fp: 0.005860, loss_freq: 0.057921
[06:12:23.455] iteration 20873: loss: 0.076983, loss_s1: 0.070065, loss_fp: 0.007014, loss_freq: 0.044604
[06:12:24.058] iteration 20874: loss: 0.047328, loss_s1: 0.028485, loss_fp: 0.006067, loss_freq: 0.034301
[06:12:24.659] iteration 20875: loss: 0.043615, loss_s1: 0.018927, loss_fp: 0.009162, loss_freq: 0.025596
[06:12:25.260] iteration 20876: loss: 0.024641, loss_s1: 0.006597, loss_fp: 0.006851, loss_freq: 0.008216
[06:12:25.861] iteration 20877: loss: 0.066300, loss_s1: 0.067979, loss_fp: 0.001397, loss_freq: 0.016260
[06:12:26.475] iteration 20878: loss: 0.061714, loss_s1: 0.049125, loss_fp: 0.001849, loss_freq: 0.035305
[06:12:27.084] iteration 20879: loss: 0.105654, loss_s1: 0.086788, loss_fp: 0.002742, loss_freq: 0.084529
[06:12:27.690] iteration 20880: loss: 0.025796, loss_s1: 0.021285, loss_fp: 0.001318, loss_freq: 0.007937
[06:12:28.294] iteration 20881: loss: 0.093704, loss_s1: 0.077563, loss_fp: 0.010723, loss_freq: 0.059372
[06:12:28.939] iteration 20882: loss: 0.061005, loss_s1: 0.054296, loss_fp: 0.003366, loss_freq: 0.026321
[06:12:29.600] iteration 20883: loss: 0.059504, loss_s1: 0.047327, loss_fp: 0.002486, loss_freq: 0.038656
[06:12:30.258] iteration 20884: loss: 0.048776, loss_s1: 0.031986, loss_fp: 0.003056, loss_freq: 0.028578
[06:12:30.902] iteration 20885: loss: 0.038904, loss_s1: 0.031884, loss_fp: 0.001504, loss_freq: 0.015200
[06:12:31.524] iteration 20886: loss: 0.063506, loss_s1: 0.049681, loss_fp: 0.003914, loss_freq: 0.036293
[06:12:32.149] iteration 20887: loss: 0.046931, loss_s1: 0.037865, loss_fp: 0.002442, loss_freq: 0.022431
[06:12:32.765] iteration 20888: loss: 0.067865, loss_s1: 0.060771, loss_fp: 0.005755, loss_freq: 0.035808
[06:12:33.383] iteration 20889: loss: 0.077368, loss_s1: 0.061345, loss_fp: 0.006043, loss_freq: 0.064679
[06:12:33.994] iteration 20890: loss: 0.055285, loss_s1: 0.031962, loss_fp: 0.006405, loss_freq: 0.024936
[06:12:34.603] iteration 20891: loss: 0.074510, loss_s1: 0.069985, loss_fp: 0.003782, loss_freq: 0.030042
[06:12:35.214] iteration 20892: loss: 0.117555, loss_s1: 0.127577, loss_fp: 0.006019, loss_freq: 0.060648
[06:12:35.828] iteration 20893: loss: 0.084778, loss_s1: 0.104850, loss_fp: 0.004013, loss_freq: 0.026877
[06:12:36.439] iteration 20894: loss: 0.093719, loss_s1: 0.114250, loss_fp: 0.003745, loss_freq: 0.039823
[06:12:37.044] iteration 20895: loss: 0.060976, loss_s1: 0.059567, loss_fp: 0.006189, loss_freq: 0.017721
[06:12:37.664] iteration 20896: loss: 0.038182, loss_s1: 0.014116, loss_fp: 0.001658, loss_freq: 0.014054
[06:12:38.277] iteration 20897: loss: 0.049550, loss_s1: 0.045302, loss_fp: 0.003746, loss_freq: 0.029419
[06:12:38.887] iteration 20898: loss: 0.147134, loss_s1: 0.120855, loss_fp: 0.003530, loss_freq: 0.104448
[06:12:39.495] iteration 20899: loss: 0.050889, loss_s1: 0.034239, loss_fp: 0.004428, loss_freq: 0.028442
[06:12:40.106] iteration 20900: loss: 0.092992, loss_s1: 0.091701, loss_fp: 0.004510, loss_freq: 0.041807
[06:12:40.712] iteration 20901: loss: 0.032318, loss_s1: 0.015644, loss_fp: 0.001420, loss_freq: 0.012838
[06:12:41.326] iteration 20902: loss: 0.075931, loss_s1: 0.077500, loss_fp: 0.006272, loss_freq: 0.047561
[06:12:41.942] iteration 20903: loss: 0.058678, loss_s1: 0.050660, loss_fp: 0.008991, loss_freq: 0.021443
[06:12:42.625] iteration 20904: loss: 0.051549, loss_s1: 0.045110, loss_fp: 0.003083, loss_freq: 0.029770
[06:12:43.277] iteration 20905: loss: 0.032113, loss_s1: 0.022034, loss_fp: 0.001143, loss_freq: 0.011960
[06:12:43.926] iteration 20906: loss: 0.059645, loss_s1: 0.045324, loss_fp: 0.002763, loss_freq: 0.044874
[06:12:44.550] iteration 20907: loss: 0.053231, loss_s1: 0.044725, loss_fp: 0.002149, loss_freq: 0.018641
[06:12:45.170] iteration 20908: loss: 0.073229, loss_s1: 0.052951, loss_fp: 0.009668, loss_freq: 0.042680
[06:12:45.776] iteration 20909: loss: 0.106421, loss_s1: 0.137228, loss_fp: 0.002593, loss_freq: 0.047403
[06:12:46.382] iteration 20910: loss: 0.063998, loss_s1: 0.058382, loss_fp: 0.002130, loss_freq: 0.023806
[06:12:47.316] iteration 20911: loss: 0.070567, loss_s1: 0.057103, loss_fp: 0.001422, loss_freq: 0.046335
[06:12:47.929] iteration 20912: loss: 0.046916, loss_s1: 0.022768, loss_fp: 0.003001, loss_freq: 0.032225
[06:12:48.544] iteration 20913: loss: 0.045881, loss_s1: 0.032706, loss_fp: 0.005180, loss_freq: 0.022534
[06:12:49.245] iteration 20914: loss: 0.033122, loss_s1: 0.016403, loss_fp: 0.000758, loss_freq: 0.014305
[06:12:49.919] iteration 20915: loss: 0.052947, loss_s1: 0.053357, loss_fp: 0.000989, loss_freq: 0.018658
[06:12:50.597] iteration 20916: loss: 0.063838, loss_s1: 0.056603, loss_fp: 0.001804, loss_freq: 0.027741
[06:12:51.210] iteration 20917: loss: 0.077810, loss_s1: 0.091089, loss_fp: 0.001281, loss_freq: 0.032304
[06:12:51.819] iteration 20918: loss: 0.052995, loss_s1: 0.055666, loss_fp: 0.005424, loss_freq: 0.015955
[06:12:52.438] iteration 20919: loss: 0.031654, loss_s1: 0.025957, loss_fp: 0.001383, loss_freq: 0.009127
[06:12:53.053] iteration 20920: loss: 0.095103, loss_s1: 0.106952, loss_fp: 0.014457, loss_freq: 0.034346
[06:12:53.659] iteration 20921: loss: 0.049834, loss_s1: 0.035912, loss_fp: 0.005879, loss_freq: 0.023303
[06:12:54.271] iteration 20922: loss: 0.053742, loss_s1: 0.035383, loss_fp: 0.006568, loss_freq: 0.032116
[06:12:54.880] iteration 20923: loss: 0.085895, loss_s1: 0.061385, loss_fp: 0.006617, loss_freq: 0.069354
[06:12:55.492] iteration 20924: loss: 0.054442, loss_s1: 0.062182, loss_fp: 0.001501, loss_freq: 0.014190
[06:12:56.114] iteration 20925: loss: 0.062048, loss_s1: 0.069392, loss_fp: 0.000839, loss_freq: 0.017571
[06:12:56.723] iteration 20926: loss: 0.073055, loss_s1: 0.070140, loss_fp: 0.009477, loss_freq: 0.028621
[06:12:57.360] iteration 20927: loss: 0.072859, loss_s1: 0.047341, loss_fp: 0.017315, loss_freq: 0.060340
[06:12:58.099] iteration 20928: loss: 0.037714, loss_s1: 0.030320, loss_fp: 0.002706, loss_freq: 0.010933
[06:12:58.791] iteration 20929: loss: 0.067404, loss_s1: 0.052276, loss_fp: 0.008404, loss_freq: 0.039546
[06:12:59.495] iteration 20930: loss: 0.071969, loss_s1: 0.075726, loss_fp: 0.002179, loss_freq: 0.017139
[06:13:00.152] iteration 20931: loss: 0.049143, loss_s1: 0.027323, loss_fp: 0.004900, loss_freq: 0.029506
[06:13:00.853] iteration 20932: loss: 0.055416, loss_s1: 0.032862, loss_fp: 0.008521, loss_freq: 0.044231
[06:13:01.494] iteration 20933: loss: 0.067546, loss_s1: 0.044964, loss_fp: 0.000945, loss_freq: 0.028892
[06:13:02.165] iteration 20934: loss: 0.061336, loss_s1: 0.047762, loss_fp: 0.001553, loss_freq: 0.035399
[06:13:02.821] iteration 20935: loss: 0.130701, loss_s1: 0.149480, loss_fp: 0.003170, loss_freq: 0.061939
[06:13:03.455] iteration 20936: loss: 0.057046, loss_s1: 0.048553, loss_fp: 0.007163, loss_freq: 0.030868
[06:13:04.238] iteration 20937: loss: 0.064465, loss_s1: 0.037517, loss_fp: 0.001878, loss_freq: 0.032667
[06:13:04.927] iteration 20938: loss: 0.120496, loss_s1: 0.090275, loss_fp: 0.007913, loss_freq: 0.095392
[06:13:05.627] iteration 20939: loss: 0.045693, loss_s1: 0.034683, loss_fp: 0.005294, loss_freq: 0.025262
[06:13:06.323] iteration 20940: loss: 0.099095, loss_s1: 0.125207, loss_fp: 0.010285, loss_freq: 0.021262
[06:13:06.999] iteration 20941: loss: 0.075495, loss_s1: 0.076251, loss_fp: 0.003911, loss_freq: 0.046293
[06:13:07.742] iteration 20942: loss: 0.106507, loss_s1: 0.123611, loss_fp: 0.007829, loss_freq: 0.040147
[06:13:08.380] iteration 20943: loss: 0.081952, loss_s1: 0.066850, loss_fp: 0.002082, loss_freq: 0.060596
[06:13:09.214] iteration 20944: loss: 0.053312, loss_s1: 0.059621, loss_fp: 0.004575, loss_freq: 0.010497
[06:13:09.851] iteration 20945: loss: 0.056413, loss_s1: 0.061267, loss_fp: 0.002559, loss_freq: 0.028240
[06:13:10.460] iteration 20946: loss: 0.045018, loss_s1: 0.026924, loss_fp: 0.002812, loss_freq: 0.017773
[06:13:11.083] iteration 20947: loss: 0.046696, loss_s1: 0.037065, loss_fp: 0.001050, loss_freq: 0.019055
[06:13:11.699] iteration 20948: loss: 0.045266, loss_s1: 0.036740, loss_fp: 0.006174, loss_freq: 0.020749
[06:13:12.315] iteration 20949: loss: 0.062503, loss_s1: 0.055729, loss_fp: 0.005507, loss_freq: 0.018697
[06:13:12.932] iteration 20950: loss: 0.077058, loss_s1: 0.069311, loss_fp: 0.003668, loss_freq: 0.049415
[06:13:13.552] iteration 20951: loss: 0.075744, loss_s1: 0.076103, loss_fp: 0.004096, loss_freq: 0.031289
[06:13:14.157] iteration 20952: loss: 0.062294, loss_s1: 0.061239, loss_fp: 0.011286, loss_freq: 0.021125
[06:13:14.764] iteration 20953: loss: 0.103506, loss_s1: 0.142733, loss_fp: 0.002198, loss_freq: 0.033244
[06:13:15.381] iteration 20954: loss: 0.090805, loss_s1: 0.094689, loss_fp: 0.005191, loss_freq: 0.058960
[06:13:15.996] iteration 20955: loss: 0.046906, loss_s1: 0.039916, loss_fp: 0.004312, loss_freq: 0.014703
[06:13:16.611] iteration 20956: loss: 0.079205, loss_s1: 0.079713, loss_fp: 0.007019, loss_freq: 0.027114
[06:13:17.222] iteration 20957: loss: 0.064750, loss_s1: 0.044387, loss_fp: 0.004624, loss_freq: 0.038128
[06:13:17.841] iteration 20958: loss: 0.060646, loss_s1: 0.018075, loss_fp: 0.005643, loss_freq: 0.065850
[06:13:18.455] iteration 20959: loss: 0.064276, loss_s1: 0.070730, loss_fp: 0.006265, loss_freq: 0.018323
[06:13:19.064] iteration 20960: loss: 0.049623, loss_s1: 0.045254, loss_fp: 0.004002, loss_freq: 0.011724
[06:13:19.675] iteration 20961: loss: 0.050554, loss_s1: 0.042318, loss_fp: 0.002159, loss_freq: 0.018051
[06:13:20.287] iteration 20962: loss: 0.055219, loss_s1: 0.049849, loss_fp: 0.001362, loss_freq: 0.034889
[06:13:20.896] iteration 20963: loss: 0.045668, loss_s1: 0.030368, loss_fp: 0.002028, loss_freq: 0.012294
[06:13:21.503] iteration 20964: loss: 0.061272, loss_s1: 0.045943, loss_fp: 0.016400, loss_freq: 0.026374
[06:13:22.123] iteration 20965: loss: 0.049547, loss_s1: 0.021715, loss_fp: 0.001212, loss_freq: 0.039667
[06:13:22.730] iteration 20966: loss: 0.048173, loss_s1: 0.023499, loss_fp: 0.002750, loss_freq: 0.036854
[06:13:23.337] iteration 20967: loss: 0.053546, loss_s1: 0.033986, loss_fp: 0.004376, loss_freq: 0.037427
[06:13:23.956] iteration 20968: loss: 0.049408, loss_s1: 0.030618, loss_fp: 0.002512, loss_freq: 0.020950
[06:13:24.625] iteration 20969: loss: 0.044538, loss_s1: 0.025201, loss_fp: 0.003052, loss_freq: 0.020342
[06:13:25.293] iteration 20970: loss: 0.063936, loss_s1: 0.048746, loss_fp: 0.003734, loss_freq: 0.039965
[06:13:26.132] iteration 20971: loss: 0.031058, loss_s1: 0.023755, loss_fp: 0.001224, loss_freq: 0.005989
[06:13:27.006] iteration 20972: loss: 0.054336, loss_s1: 0.031820, loss_fp: 0.005378, loss_freq: 0.021415
[06:13:27.801] iteration 20973: loss: 0.036989, loss_s1: 0.026259, loss_fp: 0.002527, loss_freq: 0.010855
[06:13:28.403] iteration 20974: loss: 0.044523, loss_s1: 0.032630, loss_fp: 0.003486, loss_freq: 0.022109
[06:13:29.031] iteration 20975: loss: 0.037463, loss_s1: 0.029423, loss_fp: 0.001278, loss_freq: 0.007572
[06:13:29.641] iteration 20976: loss: 0.065188, loss_s1: 0.073051, loss_fp: 0.001248, loss_freq: 0.031645
[06:13:30.274] iteration 20977: loss: 0.038843, loss_s1: 0.024873, loss_fp: 0.001420, loss_freq: 0.010571
[06:13:30.894] iteration 20978: loss: 0.082831, loss_s1: 0.066309, loss_fp: 0.012944, loss_freq: 0.062573
[06:13:31.509] iteration 20979: loss: 0.053427, loss_s1: 0.029415, loss_fp: 0.006022, loss_freq: 0.032513
[06:13:32.115] iteration 20980: loss: 0.043271, loss_s1: 0.026763, loss_fp: 0.005507, loss_freq: 0.031468
[06:13:32.724] iteration 20981: loss: 0.070970, loss_s1: 0.057663, loss_fp: 0.002719, loss_freq: 0.046110
[06:13:33.341] iteration 20982: loss: 0.039244, loss_s1: 0.020592, loss_fp: 0.003903, loss_freq: 0.022099
[06:13:33.957] iteration 20983: loss: 0.046491, loss_s1: 0.029943, loss_fp: 0.003973, loss_freq: 0.030209
[06:13:34.567] iteration 20984: loss: 0.053352, loss_s1: 0.046817, loss_fp: 0.008266, loss_freq: 0.013060
[06:13:35.179] iteration 20985: loss: 0.058209, loss_s1: 0.030113, loss_fp: 0.003936, loss_freq: 0.051326
[06:13:35.807] iteration 20986: loss: 0.084553, loss_s1: 0.050898, loss_fp: 0.016404, loss_freq: 0.065503
[06:13:36.415] iteration 20987: loss: 0.058739, loss_s1: 0.044869, loss_fp: 0.003930, loss_freq: 0.030848
[06:13:37.027] iteration 20988: loss: 0.092224, loss_s1: 0.075845, loss_fp: 0.007612, loss_freq: 0.051856
[06:13:37.634] iteration 20989: loss: 0.055275, loss_s1: 0.032424, loss_fp: 0.002821, loss_freq: 0.046298
[06:13:38.241] iteration 20990: loss: 0.052101, loss_s1: 0.040784, loss_fp: 0.001877, loss_freq: 0.016388
[06:13:38.854] iteration 20991: loss: 0.060034, loss_s1: 0.037059, loss_fp: 0.002382, loss_freq: 0.027547
[06:13:39.463] iteration 20992: loss: 0.058179, loss_s1: 0.042859, loss_fp: 0.016034, loss_freq: 0.025956
[06:13:40.072] iteration 20993: loss: 0.053972, loss_s1: 0.054096, loss_fp: 0.002671, loss_freq: 0.017484
[06:13:40.677] iteration 20994: loss: 0.046566, loss_s1: 0.030636, loss_fp: 0.003630, loss_freq: 0.024715
[06:13:41.286] iteration 20995: loss: 0.064627, loss_s1: 0.061586, loss_fp: 0.007253, loss_freq: 0.027710
[06:13:41.898] iteration 20996: loss: 0.055573, loss_s1: 0.042543, loss_fp: 0.004395, loss_freq: 0.025079
[06:13:42.505] iteration 20997: loss: 0.047876, loss_s1: 0.025915, loss_fp: 0.003225, loss_freq: 0.020346
[06:13:43.108] iteration 20998: loss: 0.059613, loss_s1: 0.043131, loss_fp: 0.001891, loss_freq: 0.023837
[06:13:43.715] iteration 20999: loss: 0.062648, loss_s1: 0.048414, loss_fp: 0.011115, loss_freq: 0.031634
[06:13:44.356] iteration 21000: loss: 0.034784, loss_s1: 0.010254, loss_fp: 0.002179, loss_freq: 0.014735
[06:13:47.917] iteration 21000 : mean_dice : 0.732790
[06:13:48.566] iteration 21001: loss: 0.051022, loss_s1: 0.049515, loss_fp: 0.002488, loss_freq: 0.015018
[06:13:49.181] iteration 21002: loss: 0.045285, loss_s1: 0.018541, loss_fp: 0.001087, loss_freq: 0.038201
[06:13:49.792] iteration 21003: loss: 0.082690, loss_s1: 0.080969, loss_fp: 0.003515, loss_freq: 0.039366
[06:13:50.413] iteration 21004: loss: 0.066556, loss_s1: 0.080971, loss_fp: 0.003635, loss_freq: 0.023598
[06:13:51.025] iteration 21005: loss: 0.044898, loss_s1: 0.038118, loss_fp: 0.001869, loss_freq: 0.021328
[06:13:51.640] iteration 21006: loss: 0.057478, loss_s1: 0.047279, loss_fp: 0.001605, loss_freq: 0.039572
[06:13:52.288] iteration 21007: loss: 0.069013, loss_s1: 0.075947, loss_fp: 0.004578, loss_freq: 0.013775
[06:13:52.900] iteration 21008: loss: 0.044532, loss_s1: 0.014195, loss_fp: 0.001380, loss_freq: 0.031163
[06:13:53.503] iteration 21009: loss: 0.057480, loss_s1: 0.035058, loss_fp: 0.013968, loss_freq: 0.031842
[06:13:54.112] iteration 21010: loss: 0.056388, loss_s1: 0.039708, loss_fp: 0.004641, loss_freq: 0.027443
[06:13:54.719] iteration 21011: loss: 0.042004, loss_s1: 0.034196, loss_fp: 0.003176, loss_freq: 0.014326
[06:13:55.343] iteration 21012: loss: 0.064324, loss_s1: 0.049993, loss_fp: 0.005210, loss_freq: 0.020874
[06:13:55.955] iteration 21013: loss: 0.051439, loss_s1: 0.048085, loss_fp: 0.004987, loss_freq: 0.023473
[06:13:56.566] iteration 21014: loss: 0.051154, loss_s1: 0.048982, loss_fp: 0.003895, loss_freq: 0.020794
[06:13:57.177] iteration 21015: loss: 0.037684, loss_s1: 0.025721, loss_fp: 0.003356, loss_freq: 0.014454
[06:13:57.790] iteration 21016: loss: 0.061406, loss_s1: 0.054806, loss_fp: 0.009313, loss_freq: 0.024612
[06:13:58.404] iteration 21017: loss: 0.041548, loss_s1: 0.030837, loss_fp: 0.002848, loss_freq: 0.014606
[06:13:59.016] iteration 21018: loss: 0.039635, loss_s1: 0.023559, loss_fp: 0.004854, loss_freq: 0.019654
[06:13:59.630] iteration 21019: loss: 0.051718, loss_s1: 0.041295, loss_fp: 0.004189, loss_freq: 0.017256
[06:14:00.235] iteration 21020: loss: 0.058205, loss_s1: 0.047307, loss_fp: 0.001569, loss_freq: 0.031346
[06:14:00.853] iteration 21021: loss: 0.046861, loss_s1: 0.037664, loss_fp: 0.004144, loss_freq: 0.007214
[06:14:01.462] iteration 21022: loss: 0.060336, loss_s1: 0.062946, loss_fp: 0.002125, loss_freq: 0.014109
[06:14:02.065] iteration 21023: loss: 0.055710, loss_s1: 0.054082, loss_fp: 0.003208, loss_freq: 0.023295
[06:14:02.678] iteration 21024: loss: 0.040506, loss_s1: 0.021603, loss_fp: 0.008684, loss_freq: 0.025849
[06:14:03.282] iteration 21025: loss: 0.120040, loss_s1: 0.055107, loss_fp: 0.004961, loss_freq: 0.126774
[06:14:03.884] iteration 21026: loss: 0.061291, loss_s1: 0.037654, loss_fp: 0.017552, loss_freq: 0.029526
[06:14:04.491] iteration 21027: loss: 0.052640, loss_s1: 0.036925, loss_fp: 0.007130, loss_freq: 0.026916
[06:14:05.097] iteration 21028: loss: 0.040520, loss_s1: 0.035276, loss_fp: 0.003017, loss_freq: 0.011125
[06:14:05.729] iteration 21029: loss: 0.068170, loss_s1: 0.045984, loss_fp: 0.003705, loss_freq: 0.046137
[06:14:06.411] iteration 21030: loss: 0.049724, loss_s1: 0.031649, loss_fp: 0.007225, loss_freq: 0.025471
[06:14:07.085] iteration 21031: loss: 0.044376, loss_s1: 0.023136, loss_fp: 0.002961, loss_freq: 0.005770
[06:14:07.770] iteration 21032: loss: 0.057873, loss_s1: 0.056790, loss_fp: 0.002981, loss_freq: 0.028804
[06:14:08.545] iteration 21033: loss: 0.046211, loss_s1: 0.032563, loss_fp: 0.004778, loss_freq: 0.025512
[06:14:09.368] iteration 21034: loss: 0.083404, loss_s1: 0.084478, loss_fp: 0.004686, loss_freq: 0.043693
[06:14:10.037] iteration 21035: loss: 0.070556, loss_s1: 0.054239, loss_fp: 0.003764, loss_freq: 0.036084
[06:14:10.648] iteration 21036: loss: 0.077816, loss_s1: 0.072110, loss_fp: 0.001562, loss_freq: 0.042176
[06:14:11.260] iteration 21037: loss: 0.082096, loss_s1: 0.066729, loss_fp: 0.003517, loss_freq: 0.063823
[06:14:11.872] iteration 21038: loss: 0.042162, loss_s1: 0.035716, loss_fp: 0.002909, loss_freq: 0.006733
[06:14:12.534] iteration 21039: loss: 0.052635, loss_s1: 0.041087, loss_fp: 0.003850, loss_freq: 0.013214
[06:14:13.149] iteration 21040: loss: 0.097595, loss_s1: 0.087238, loss_fp: 0.009598, loss_freq: 0.064653
[06:14:13.761] iteration 21041: loss: 0.068327, loss_s1: 0.085663, loss_fp: 0.003035, loss_freq: 0.019370
[06:14:14.385] iteration 21042: loss: 0.060613, loss_s1: 0.068654, loss_fp: 0.001706, loss_freq: 0.011652
[06:14:14.999] iteration 21043: loss: 0.074230, loss_s1: 0.081068, loss_fp: 0.001747, loss_freq: 0.034882
[06:14:15.610] iteration 21044: loss: 0.090645, loss_s1: 0.114275, loss_fp: 0.004403, loss_freq: 0.033244
[06:14:16.247] iteration 21045: loss: 0.103669, loss_s1: 0.121430, loss_fp: 0.004704, loss_freq: 0.049362
[06:14:16.908] iteration 21046: loss: 0.040315, loss_s1: 0.036362, loss_fp: 0.002564, loss_freq: 0.009401
[06:14:17.581] iteration 21047: loss: 0.052613, loss_s1: 0.043277, loss_fp: 0.002259, loss_freq: 0.010234
[06:14:18.241] iteration 21048: loss: 0.096683, loss_s1: 0.111694, loss_fp: 0.006040, loss_freq: 0.045035
[06:14:18.870] iteration 21049: loss: 0.123701, loss_s1: 0.138204, loss_fp: 0.001817, loss_freq: 0.070175
[06:14:19.500] iteration 21050: loss: 0.078794, loss_s1: 0.097504, loss_fp: 0.001831, loss_freq: 0.035820
[06:14:20.122] iteration 21051: loss: 0.071513, loss_s1: 0.041306, loss_fp: 0.002630, loss_freq: 0.049195
[06:14:20.746] iteration 21052: loss: 0.049285, loss_s1: 0.037029, loss_fp: 0.002218, loss_freq: 0.024229
[06:14:21.372] iteration 21053: loss: 0.037435, loss_s1: 0.027035, loss_fp: 0.002099, loss_freq: 0.015567
[06:14:21.981] iteration 21054: loss: 0.073396, loss_s1: 0.080467, loss_fp: 0.001590, loss_freq: 0.029138
[06:14:22.585] iteration 21055: loss: 0.049487, loss_s1: 0.030182, loss_fp: 0.005023, loss_freq: 0.027565
[06:14:23.192] iteration 21056: loss: 0.056358, loss_s1: 0.038010, loss_fp: 0.004127, loss_freq: 0.034136
[06:14:23.797] iteration 21057: loss: 0.057489, loss_s1: 0.056142, loss_fp: 0.003576, loss_freq: 0.015006
[06:14:24.411] iteration 21058: loss: 0.104088, loss_s1: 0.124891, loss_fp: 0.010968, loss_freq: 0.043317
[06:14:25.020] iteration 21059: loss: 0.069109, loss_s1: 0.077344, loss_fp: 0.002960, loss_freq: 0.034126
[06:14:25.625] iteration 21060: loss: 0.072221, loss_s1: 0.062768, loss_fp: 0.009338, loss_freq: 0.029921
[06:14:26.236] iteration 21061: loss: 0.076064, loss_s1: 0.063744, loss_fp: 0.013158, loss_freq: 0.041768
[06:14:26.862] iteration 21062: loss: 0.069211, loss_s1: 0.078325, loss_fp: 0.002032, loss_freq: 0.024364
[06:14:27.477] iteration 21063: loss: 0.069175, loss_s1: 0.080816, loss_fp: 0.005000, loss_freq: 0.020096
[06:14:28.114] iteration 21064: loss: 0.071752, loss_s1: 0.058574, loss_fp: 0.002906, loss_freq: 0.037458
[06:14:28.727] iteration 21065: loss: 0.072648, loss_s1: 0.079109, loss_fp: 0.003507, loss_freq: 0.018272
[06:14:29.348] iteration 21066: loss: 0.066807, loss_s1: 0.050816, loss_fp: 0.002433, loss_freq: 0.026678
[06:14:29.962] iteration 21067: loss: 0.059270, loss_s1: 0.032053, loss_fp: 0.001410, loss_freq: 0.061052
[06:14:30.628] iteration 21068: loss: 0.100516, loss_s1: 0.089389, loss_fp: 0.007457, loss_freq: 0.060206
[06:14:31.280] iteration 21069: loss: 0.051849, loss_s1: 0.025339, loss_fp: 0.003563, loss_freq: 0.047042
[06:14:31.947] iteration 21070: loss: 0.082540, loss_s1: 0.084894, loss_fp: 0.004087, loss_freq: 0.037533
[06:14:32.611] iteration 21071: loss: 0.048067, loss_s1: 0.036274, loss_fp: 0.004013, loss_freq: 0.008876
[06:14:33.222] iteration 21072: loss: 0.046643, loss_s1: 0.037682, loss_fp: 0.003381, loss_freq: 0.030069
[06:14:33.835] iteration 21073: loss: 0.053316, loss_s1: 0.020655, loss_fp: 0.002960, loss_freq: 0.042442
[06:14:34.502] iteration 21074: loss: 0.054338, loss_s1: 0.064766, loss_fp: 0.005021, loss_freq: 0.012499
[06:14:35.163] iteration 21075: loss: 0.035338, loss_s1: 0.019058, loss_fp: 0.001990, loss_freq: 0.016357
[06:14:35.787] iteration 21076: loss: 0.062630, loss_s1: 0.064070, loss_fp: 0.004735, loss_freq: 0.031807
[06:14:36.399] iteration 21077: loss: 0.058577, loss_s1: 0.049821, loss_fp: 0.001471, loss_freq: 0.019057
[06:14:37.010] iteration 21078: loss: 0.075005, loss_s1: 0.054822, loss_fp: 0.001925, loss_freq: 0.059459
[06:14:37.627] iteration 21079: loss: 0.078847, loss_s1: 0.086572, loss_fp: 0.004564, loss_freq: 0.039896
[06:14:38.262] iteration 21080: loss: 0.073991, loss_s1: 0.069048, loss_fp: 0.001958, loss_freq: 0.041022
[06:14:39.203] iteration 21081: loss: 0.098901, loss_s1: 0.111064, loss_fp: 0.002343, loss_freq: 0.047127
[06:14:39.821] iteration 21082: loss: 0.063488, loss_s1: 0.044742, loss_fp: 0.001963, loss_freq: 0.041691
[06:14:40.483] iteration 21083: loss: 0.044224, loss_s1: 0.046288, loss_fp: 0.002598, loss_freq: 0.014396
[06:14:41.092] iteration 21084: loss: 0.030125, loss_s1: 0.016061, loss_fp: 0.000888, loss_freq: 0.015842
[06:14:41.701] iteration 21085: loss: 0.064624, loss_s1: 0.081191, loss_fp: 0.004348, loss_freq: 0.015034
[06:14:42.308] iteration 21086: loss: 0.075366, loss_s1: 0.056449, loss_fp: 0.003434, loss_freq: 0.047177
[06:14:42.917] iteration 21087: loss: 0.057747, loss_s1: 0.044110, loss_fp: 0.004615, loss_freq: 0.032994
[06:14:43.525] iteration 21088: loss: 0.040136, loss_s1: 0.024261, loss_fp: 0.005725, loss_freq: 0.024485
[06:14:44.136] iteration 21089: loss: 0.049508, loss_s1: 0.050814, loss_fp: 0.006200, loss_freq: 0.014068
[06:14:44.741] iteration 21090: loss: 0.056692, loss_s1: 0.034002, loss_fp: 0.005449, loss_freq: 0.033498
[06:14:45.349] iteration 21091: loss: 0.061067, loss_s1: 0.042048, loss_fp: 0.003075, loss_freq: 0.043565
[06:14:46.005] iteration 21092: loss: 0.057428, loss_s1: 0.030116, loss_fp: 0.003046, loss_freq: 0.034002
[06:14:46.661] iteration 21093: loss: 0.055253, loss_s1: 0.039144, loss_fp: 0.004015, loss_freq: 0.038619
[06:14:47.316] iteration 21094: loss: 0.049983, loss_s1: 0.036335, loss_fp: 0.004675, loss_freq: 0.032523
[06:14:47.948] iteration 21095: loss: 0.059910, loss_s1: 0.042365, loss_fp: 0.003761, loss_freq: 0.041398
[06:14:48.553] iteration 21096: loss: 0.052165, loss_s1: 0.028306, loss_fp: 0.004098, loss_freq: 0.037671
[06:14:49.210] iteration 21097: loss: 0.128300, loss_s1: 0.142050, loss_fp: 0.006773, loss_freq: 0.082713
[06:14:49.865] iteration 21098: loss: 0.032023, loss_s1: 0.007782, loss_fp: 0.001641, loss_freq: 0.025343
[06:14:50.553] iteration 21099: loss: 0.100576, loss_s1: 0.107423, loss_fp: 0.008314, loss_freq: 0.055805
[06:14:51.227] iteration 21100: loss: 0.076032, loss_s1: 0.084050, loss_fp: 0.005165, loss_freq: 0.027257
[06:14:51.870] iteration 21101: loss: 0.079496, loss_s1: 0.091592, loss_fp: 0.004984, loss_freq: 0.028741
[06:14:52.543] iteration 21102: loss: 0.038549, loss_s1: 0.011726, loss_fp: 0.004984, loss_freq: 0.031802
[06:14:53.200] iteration 21103: loss: 0.075872, loss_s1: 0.064815, loss_fp: 0.003849, loss_freq: 0.022999
[06:14:53.896] iteration 21104: loss: 0.034083, loss_s1: 0.014355, loss_fp: 0.003237, loss_freq: 0.020611
[06:14:54.554] iteration 21105: loss: 0.063743, loss_s1: 0.057489, loss_fp: 0.003043, loss_freq: 0.027178
[06:14:55.212] iteration 21106: loss: 0.063866, loss_s1: 0.055281, loss_fp: 0.002478, loss_freq: 0.041057
[06:14:55.866] iteration 21107: loss: 0.055092, loss_s1: 0.036956, loss_fp: 0.003091, loss_freq: 0.028904
[06:14:56.487] iteration 21108: loss: 0.121595, loss_s1: 0.093591, loss_fp: 0.010856, loss_freq: 0.095353
[06:14:57.090] iteration 21109: loss: 0.054033, loss_s1: 0.029975, loss_fp: 0.006347, loss_freq: 0.033896
[06:14:57.697] iteration 21110: loss: 0.081251, loss_s1: 0.073559, loss_fp: 0.003495, loss_freq: 0.048398
[06:14:58.314] iteration 21111: loss: 0.066207, loss_s1: 0.063047, loss_fp: 0.004343, loss_freq: 0.036805
[06:14:58.925] iteration 21112: loss: 0.108075, loss_s1: 0.125224, loss_fp: 0.004571, loss_freq: 0.041980
[06:14:59.533] iteration 21113: loss: 0.084189, loss_s1: 0.101944, loss_fp: 0.004172, loss_freq: 0.028810
[06:15:00.139] iteration 21114: loss: 0.036085, loss_s1: 0.028175, loss_fp: 0.002693, loss_freq: 0.003789
[06:15:00.741] iteration 21115: loss: 0.066531, loss_s1: 0.063537, loss_fp: 0.001315, loss_freq: 0.044195
[06:15:01.348] iteration 21116: loss: 0.058025, loss_s1: 0.029783, loss_fp: 0.003030, loss_freq: 0.016094
[06:15:01.956] iteration 21117: loss: 0.063003, loss_s1: 0.055732, loss_fp: 0.001682, loss_freq: 0.037336
[06:15:02.562] iteration 21118: loss: 0.046958, loss_s1: 0.041474, loss_fp: 0.002595, loss_freq: 0.021476
[06:15:03.168] iteration 21119: loss: 0.117878, loss_s1: 0.114954, loss_fp: 0.004311, loss_freq: 0.061456
[06:15:03.777] iteration 21120: loss: 0.048046, loss_s1: 0.037766, loss_fp: 0.003134, loss_freq: 0.016844
[06:15:04.384] iteration 21121: loss: 0.091915, loss_s1: 0.104220, loss_fp: 0.001393, loss_freq: 0.041500
[06:15:04.990] iteration 21122: loss: 0.042950, loss_s1: 0.034728, loss_fp: 0.002192, loss_freq: 0.016757
[06:15:05.602] iteration 21123: loss: 0.073649, loss_s1: 0.080783, loss_fp: 0.000809, loss_freq: 0.030129
[06:15:06.211] iteration 21124: loss: 0.081631, loss_s1: 0.068164, loss_fp: 0.002393, loss_freq: 0.064617
[06:15:06.826] iteration 21125: loss: 0.057422, loss_s1: 0.041288, loss_fp: 0.006288, loss_freq: 0.025705
[06:15:07.437] iteration 21126: loss: 0.068710, loss_s1: 0.067939, loss_fp: 0.005354, loss_freq: 0.024727
[06:15:08.046] iteration 21127: loss: 0.069964, loss_s1: 0.057792, loss_fp: 0.003025, loss_freq: 0.046030
[06:15:08.654] iteration 21128: loss: 0.058708, loss_s1: 0.047126, loss_fp: 0.001531, loss_freq: 0.024017
[06:15:09.282] iteration 21129: loss: 0.057980, loss_s1: 0.076348, loss_fp: 0.001445, loss_freq: 0.004535
[06:15:09.890] iteration 21130: loss: 0.042118, loss_s1: 0.036789, loss_fp: 0.002631, loss_freq: 0.007944
[06:15:10.504] iteration 21131: loss: 0.052057, loss_s1: 0.046638, loss_fp: 0.002676, loss_freq: 0.022786
[06:15:11.119] iteration 21132: loss: 0.050239, loss_s1: 0.045347, loss_fp: 0.003040, loss_freq: 0.028109
[06:15:11.729] iteration 21133: loss: 0.034786, loss_s1: 0.015840, loss_fp: 0.001216, loss_freq: 0.016469
[06:15:12.344] iteration 21134: loss: 0.091762, loss_s1: 0.088565, loss_fp: 0.012573, loss_freq: 0.053984
[06:15:12.970] iteration 21135: loss: 0.048437, loss_s1: 0.021386, loss_fp: 0.001915, loss_freq: 0.033555
[06:15:13.581] iteration 21136: loss: 0.046192, loss_s1: 0.027403, loss_fp: 0.002930, loss_freq: 0.022687
[06:15:14.191] iteration 21137: loss: 0.057398, loss_s1: 0.036492, loss_fp: 0.004773, loss_freq: 0.048634
[06:15:14.809] iteration 21138: loss: 0.053005, loss_s1: 0.035602, loss_fp: 0.005758, loss_freq: 0.018412
[06:15:15.421] iteration 21139: loss: 0.035007, loss_s1: 0.019142, loss_fp: 0.001810, loss_freq: 0.021486
[06:15:16.033] iteration 21140: loss: 0.048658, loss_s1: 0.027270, loss_fp: 0.006525, loss_freq: 0.027111
[06:15:16.645] iteration 21141: loss: 0.024531, loss_s1: 0.014895, loss_fp: 0.002653, loss_freq: 0.005214
[06:15:17.253] iteration 21142: loss: 0.049080, loss_s1: 0.028915, loss_fp: 0.002511, loss_freq: 0.022867
[06:15:17.867] iteration 21143: loss: 0.040206, loss_s1: 0.023355, loss_fp: 0.001698, loss_freq: 0.015012
[06:15:18.484] iteration 21144: loss: 0.034525, loss_s1: 0.017037, loss_fp: 0.001514, loss_freq: 0.016944
[06:15:19.096] iteration 21145: loss: 0.086304, loss_s1: 0.121721, loss_fp: 0.001696, loss_freq: 0.012614
[06:15:19.706] iteration 21146: loss: 0.053187, loss_s1: 0.045440, loss_fp: 0.003989, loss_freq: 0.031705
[06:15:20.315] iteration 21147: loss: 0.052819, loss_s1: 0.037179, loss_fp: 0.001551, loss_freq: 0.012330
[06:15:20.920] iteration 21148: loss: 0.107089, loss_s1: 0.087868, loss_fp: 0.010863, loss_freq: 0.062575
[06:15:21.528] iteration 21149: loss: 0.038399, loss_s1: 0.021789, loss_fp: 0.002213, loss_freq: 0.015928
[06:15:22.137] iteration 21150: loss: 0.045046, loss_s1: 0.036017, loss_fp: 0.003426, loss_freq: 0.023612
[06:15:22.745] iteration 21151: loss: 0.065010, loss_s1: 0.048889, loss_fp: 0.004708, loss_freq: 0.039993
[06:15:23.353] iteration 21152: loss: 0.064730, loss_s1: 0.063902, loss_fp: 0.002295, loss_freq: 0.028261
[06:15:23.960] iteration 21153: loss: 0.047189, loss_s1: 0.021994, loss_fp: 0.003549, loss_freq: 0.040292
[06:15:24.567] iteration 21154: loss: 0.074711, loss_s1: 0.080164, loss_fp: 0.004040, loss_freq: 0.033118
[06:15:25.180] iteration 21155: loss: 0.071452, loss_s1: 0.028004, loss_fp: 0.010133, loss_freq: 0.075605
[06:15:25.792] iteration 21156: loss: 0.079427, loss_s1: 0.036912, loss_fp: 0.015336, loss_freq: 0.066971
[06:15:26.402] iteration 21157: loss: 0.037879, loss_s1: 0.019371, loss_fp: 0.002695, loss_freq: 0.017791
[06:15:27.016] iteration 21158: loss: 0.077198, loss_s1: 0.083977, loss_fp: 0.002544, loss_freq: 0.041185
[06:15:27.628] iteration 21159: loss: 0.030976, loss_s1: 0.017903, loss_fp: 0.002387, loss_freq: 0.022223
[06:15:28.238] iteration 21160: loss: 0.077931, loss_s1: 0.063886, loss_fp: 0.004626, loss_freq: 0.055584
[06:15:28.843] iteration 21161: loss: 0.065456, loss_s1: 0.050140, loss_fp: 0.001791, loss_freq: 0.015757
[06:15:29.451] iteration 21162: loss: 0.065236, loss_s1: 0.051132, loss_fp: 0.003943, loss_freq: 0.039562
[06:15:30.064] iteration 21163: loss: 0.063041, loss_s1: 0.072518, loss_fp: 0.001732, loss_freq: 0.021149
[06:15:30.673] iteration 21164: loss: 0.050803, loss_s1: 0.036235, loss_fp: 0.007480, loss_freq: 0.018101
[06:15:31.282] iteration 21165: loss: 0.064656, loss_s1: 0.054295, loss_fp: 0.003567, loss_freq: 0.031684
[06:15:31.890] iteration 21166: loss: 0.065705, loss_s1: 0.064939, loss_fp: 0.003135, loss_freq: 0.020357
[06:15:32.501] iteration 21167: loss: 0.061853, loss_s1: 0.067274, loss_fp: 0.002891, loss_freq: 0.028965
[06:15:33.110] iteration 21168: loss: 0.066032, loss_s1: 0.054110, loss_fp: 0.005737, loss_freq: 0.028240
[06:15:33.723] iteration 21169: loss: 0.067377, loss_s1: 0.052450, loss_fp: 0.016859, loss_freq: 0.033001
[06:15:34.333] iteration 21170: loss: 0.048705, loss_s1: 0.036677, loss_fp: 0.004465, loss_freq: 0.018597
[06:15:34.947] iteration 21171: loss: 0.076118, loss_s1: 0.078673, loss_fp: 0.001471, loss_freq: 0.036370
[06:15:35.575] iteration 21172: loss: 0.053306, loss_s1: 0.040192, loss_fp: 0.003063, loss_freq: 0.037717
[06:15:36.190] iteration 21173: loss: 0.093905, loss_s1: 0.117267, loss_fp: 0.001593, loss_freq: 0.026777
[06:15:36.806] iteration 21174: loss: 0.032808, loss_s1: 0.023329, loss_fp: 0.003094, loss_freq: 0.010687
[06:15:37.420] iteration 21175: loss: 0.055098, loss_s1: 0.047367, loss_fp: 0.005933, loss_freq: 0.021916
[06:15:38.075] iteration 21176: loss: 0.065216, loss_s1: 0.055735, loss_fp: 0.002424, loss_freq: 0.042864
[06:15:38.683] iteration 21177: loss: 0.099033, loss_s1: 0.079536, loss_fp: 0.002119, loss_freq: 0.074378
[06:15:39.289] iteration 21178: loss: 0.074757, loss_s1: 0.061268, loss_fp: 0.003029, loss_freq: 0.044343
[06:15:39.897] iteration 21179: loss: 0.098665, loss_s1: 0.141527, loss_fp: 0.001985, loss_freq: 0.022792
[06:15:40.563] iteration 21180: loss: 0.059755, loss_s1: 0.042974, loss_fp: 0.001673, loss_freq: 0.034763
[06:15:41.200] iteration 21181: loss: 0.065586, loss_s1: 0.077967, loss_fp: 0.003048, loss_freq: 0.024567
[06:15:41.805] iteration 21182: loss: 0.059596, loss_s1: 0.047332, loss_fp: 0.006956, loss_freq: 0.020960
[06:15:42.411] iteration 21183: loss: 0.060318, loss_s1: 0.050071, loss_fp: 0.000872, loss_freq: 0.035859
[06:15:43.015] iteration 21184: loss: 0.047659, loss_s1: 0.042605, loss_fp: 0.002090, loss_freq: 0.018444
[06:15:43.624] iteration 21185: loss: 0.022707, loss_s1: 0.013822, loss_fp: 0.000587, loss_freq: 0.009614
[06:15:44.230] iteration 21186: loss: 0.061746, loss_s1: 0.037477, loss_fp: 0.021788, loss_freq: 0.027838
[06:15:44.841] iteration 21187: loss: 0.057845, loss_s1: 0.056976, loss_fp: 0.004479, loss_freq: 0.017370
[06:15:45.451] iteration 21188: loss: 0.050515, loss_s1: 0.038235, loss_fp: 0.003283, loss_freq: 0.027729
[06:15:46.111] iteration 21189: loss: 0.053907, loss_s1: 0.035278, loss_fp: 0.008774, loss_freq: 0.031282
[06:15:46.774] iteration 21190: loss: 0.052327, loss_s1: 0.019331, loss_fp: 0.007963, loss_freq: 0.046359
[06:15:47.424] iteration 21191: loss: 0.083237, loss_s1: 0.086452, loss_fp: 0.005621, loss_freq: 0.021277
[06:15:48.037] iteration 21192: loss: 0.061163, loss_s1: 0.047060, loss_fp: 0.004634, loss_freq: 0.029068
[06:15:48.656] iteration 21193: loss: 0.046280, loss_s1: 0.047514, loss_fp: 0.001922, loss_freq: 0.014146
[06:15:49.283] iteration 21194: loss: 0.033315, loss_s1: 0.019079, loss_fp: 0.001412, loss_freq: 0.018441
[06:15:49.902] iteration 21195: loss: 0.070575, loss_s1: 0.047331, loss_fp: 0.002312, loss_freq: 0.042351
[06:15:50.517] iteration 21196: loss: 0.065672, loss_s1: 0.035733, loss_fp: 0.012921, loss_freq: 0.051894
[06:15:51.199] iteration 21197: loss: 0.076604, loss_s1: 0.064320, loss_fp: 0.003269, loss_freq: 0.042774
[06:15:51.862] iteration 21198: loss: 0.047723, loss_s1: 0.029869, loss_fp: 0.003272, loss_freq: 0.028696
[06:15:52.541] iteration 21199: loss: 0.081040, loss_s1: 0.064025, loss_fp: 0.002246, loss_freq: 0.062912
[06:15:53.159] iteration 21200: loss: 0.050610, loss_s1: 0.037843, loss_fp: 0.006474, loss_freq: 0.019779
[06:15:56.461] iteration 21200 : mean_dice : 0.744768
[06:15:57.158] iteration 21201: loss: 0.027204, loss_s1: 0.012118, loss_fp: 0.003340, loss_freq: 0.008319
[06:15:57.828] iteration 21202: loss: 0.078238, loss_s1: 0.079494, loss_fp: 0.005111, loss_freq: 0.032683
[06:15:58.488] iteration 21203: loss: 0.060846, loss_s1: 0.038330, loss_fp: 0.005047, loss_freq: 0.035425
[06:15:59.103] iteration 21204: loss: 0.036701, loss_s1: 0.025089, loss_fp: 0.002283, loss_freq: 0.012551
[06:15:59.713] iteration 21205: loss: 0.055434, loss_s1: 0.028830, loss_fp: 0.001751, loss_freq: 0.038909
[06:16:00.322] iteration 21206: loss: 0.042840, loss_s1: 0.036655, loss_fp: 0.001272, loss_freq: 0.016928
[06:16:00.930] iteration 21207: loss: 0.078075, loss_s1: 0.081651, loss_fp: 0.003253, loss_freq: 0.042369
[06:16:01.557] iteration 21208: loss: 0.062783, loss_s1: 0.049451, loss_fp: 0.007410, loss_freq: 0.021544
[06:16:02.173] iteration 21209: loss: 0.068191, loss_s1: 0.067235, loss_fp: 0.006075, loss_freq: 0.026920
[06:16:02.778] iteration 21210: loss: 0.095547, loss_s1: 0.091071, loss_fp: 0.014365, loss_freq: 0.055071
[06:16:03.391] iteration 21211: loss: 0.064203, loss_s1: 0.087539, loss_fp: 0.001943, loss_freq: 0.013110
[06:16:04.003] iteration 21212: loss: 0.067011, loss_s1: 0.045515, loss_fp: 0.002858, loss_freq: 0.015426
[06:16:04.617] iteration 21213: loss: 0.094282, loss_s1: 0.107150, loss_fp: 0.003336, loss_freq: 0.039820
[06:16:05.285] iteration 21214: loss: 0.072841, loss_s1: 0.091294, loss_fp: 0.002765, loss_freq: 0.017261
[06:16:05.949] iteration 21215: loss: 0.033993, loss_s1: 0.011778, loss_fp: 0.001972, loss_freq: 0.012824
[06:16:06.607] iteration 21216: loss: 0.033655, loss_s1: 0.025092, loss_fp: 0.003770, loss_freq: 0.010843
[06:16:07.264] iteration 21217: loss: 0.045142, loss_s1: 0.038393, loss_fp: 0.000861, loss_freq: 0.011904
[06:16:07.923] iteration 21218: loss: 0.058812, loss_s1: 0.025775, loss_fp: 0.007221, loss_freq: 0.044444
[06:16:08.579] iteration 21219: loss: 0.089499, loss_s1: 0.093373, loss_fp: 0.007885, loss_freq: 0.049411
[06:16:09.239] iteration 21220: loss: 0.067729, loss_s1: 0.066460, loss_fp: 0.016907, loss_freq: 0.026195
[06:16:09.890] iteration 21221: loss: 0.083221, loss_s1: 0.087387, loss_fp: 0.003680, loss_freq: 0.037409
[06:16:10.587] iteration 21222: loss: 0.048973, loss_s1: 0.034518, loss_fp: 0.005248, loss_freq: 0.029238
[06:16:11.283] iteration 21223: loss: 0.042249, loss_s1: 0.032503, loss_fp: 0.002821, loss_freq: 0.020504
[06:16:12.124] iteration 21224: loss: 0.035662, loss_s1: 0.015399, loss_fp: 0.005297, loss_freq: 0.019672
[06:16:13.042] iteration 21225: loss: 0.032514, loss_s1: 0.020473, loss_fp: 0.005665, loss_freq: 0.009771
[06:16:13.810] iteration 21226: loss: 0.045877, loss_s1: 0.034547, loss_fp: 0.002642, loss_freq: 0.023522
[06:16:14.509] iteration 21227: loss: 0.052334, loss_s1: 0.029820, loss_fp: 0.006423, loss_freq: 0.030522
[06:16:15.122] iteration 21228: loss: 0.061968, loss_s1: 0.068968, loss_fp: 0.003317, loss_freq: 0.023404
[06:16:15.733] iteration 21229: loss: 0.092278, loss_s1: 0.099268, loss_fp: 0.008342, loss_freq: 0.057940
[06:16:16.343] iteration 21230: loss: 0.063254, loss_s1: 0.057916, loss_fp: 0.014457, loss_freq: 0.020613
[06:16:16.950] iteration 21231: loss: 0.086003, loss_s1: 0.089162, loss_fp: 0.006898, loss_freq: 0.039104
[06:16:17.557] iteration 21232: loss: 0.066365, loss_s1: 0.059481, loss_fp: 0.002532, loss_freq: 0.035914
[06:16:18.173] iteration 21233: loss: 0.107794, loss_s1: 0.101462, loss_fp: 0.018981, loss_freq: 0.060709
[06:16:18.776] iteration 21234: loss: 0.101754, loss_s1: 0.084825, loss_fp: 0.007186, loss_freq: 0.083740
[06:16:19.384] iteration 21235: loss: 0.071710, loss_s1: 0.060848, loss_fp: 0.003287, loss_freq: 0.034532
[06:16:19.986] iteration 21236: loss: 0.034979, loss_s1: 0.021903, loss_fp: 0.001786, loss_freq: 0.009277
[06:16:20.588] iteration 21237: loss: 0.030684, loss_s1: 0.019307, loss_fp: 0.004185, loss_freq: 0.013354
[06:16:21.195] iteration 21238: loss: 0.097848, loss_s1: 0.093133, loss_fp: 0.002395, loss_freq: 0.070661
[06:16:21.802] iteration 21239: loss: 0.064556, loss_s1: 0.060259, loss_fp: 0.002831, loss_freq: 0.032072
[06:16:22.420] iteration 21240: loss: 0.082204, loss_s1: 0.080152, loss_fp: 0.008892, loss_freq: 0.039640
[06:16:23.026] iteration 21241: loss: 0.060945, loss_s1: 0.067575, loss_fp: 0.003641, loss_freq: 0.014732
[06:16:23.639] iteration 21242: loss: 0.056828, loss_s1: 0.060142, loss_fp: 0.003821, loss_freq: 0.026572
[06:16:24.256] iteration 21243: loss: 0.047461, loss_s1: 0.010327, loss_fp: 0.010561, loss_freq: 0.025000
[06:16:24.865] iteration 21244: loss: 0.057501, loss_s1: 0.045604, loss_fp: 0.002585, loss_freq: 0.033351
[06:16:25.485] iteration 21245: loss: 0.056907, loss_s1: 0.072224, loss_fp: 0.001134, loss_freq: 0.008551
[06:16:26.151] iteration 21246: loss: 0.097093, loss_s1: 0.121767, loss_fp: 0.006972, loss_freq: 0.031108
[06:16:26.817] iteration 21247: loss: 0.071053, loss_s1: 0.053505, loss_fp: 0.002337, loss_freq: 0.049409
[06:16:27.486] iteration 21248: loss: 0.077065, loss_s1: 0.059053, loss_fp: 0.001656, loss_freq: 0.057142
[06:16:28.109] iteration 21249: loss: 0.064045, loss_s1: 0.055101, loss_fp: 0.003298, loss_freq: 0.042620
[06:16:28.720] iteration 21250: loss: 0.061442, loss_s1: 0.052010, loss_fp: 0.004728, loss_freq: 0.030259
[06:16:29.698] iteration 21251: loss: 0.073645, loss_s1: 0.070943, loss_fp: 0.004388, loss_freq: 0.036312
[06:16:30.361] iteration 21252: loss: 0.046415, loss_s1: 0.034054, loss_fp: 0.002675, loss_freq: 0.022266
[06:16:31.022] iteration 21253: loss: 0.052248, loss_s1: 0.051932, loss_fp: 0.004245, loss_freq: 0.019388
[06:16:31.673] iteration 21254: loss: 0.047938, loss_s1: 0.029665, loss_fp: 0.003107, loss_freq: 0.018333
[06:16:32.286] iteration 21255: loss: 0.048092, loss_s1: 0.037027, loss_fp: 0.001854, loss_freq: 0.024571
[06:16:32.911] iteration 21256: loss: 0.070130, loss_s1: 0.061327, loss_fp: 0.005197, loss_freq: 0.038004
[06:16:33.525] iteration 21257: loss: 0.040680, loss_s1: 0.019644, loss_fp: 0.001803, loss_freq: 0.031426
[06:16:34.144] iteration 21258: loss: 0.041284, loss_s1: 0.027607, loss_fp: 0.004036, loss_freq: 0.016121
[06:16:34.754] iteration 21259: loss: 0.048962, loss_s1: 0.061904, loss_fp: 0.001783, loss_freq: 0.013796
[06:16:35.364] iteration 21260: loss: 0.077100, loss_s1: 0.086680, loss_fp: 0.006870, loss_freq: 0.025129
[06:16:35.986] iteration 21261: loss: 0.044933, loss_s1: 0.027158, loss_fp: 0.004278, loss_freq: 0.023494
[06:16:36.598] iteration 21262: loss: 0.084808, loss_s1: 0.064406, loss_fp: 0.002584, loss_freq: 0.054141
[06:16:37.213] iteration 21263: loss: 0.056700, loss_s1: 0.053692, loss_fp: 0.004642, loss_freq: 0.020994
[06:16:37.820] iteration 21264: loss: 0.064487, loss_s1: 0.044463, loss_fp: 0.013142, loss_freq: 0.025646
[06:16:38.479] iteration 21265: loss: 0.057027, loss_s1: 0.048753, loss_fp: 0.007954, loss_freq: 0.019342
[06:16:39.133] iteration 21266: loss: 0.059282, loss_s1: 0.037476, loss_fp: 0.003921, loss_freq: 0.041625
[06:16:39.783] iteration 21267: loss: 0.085092, loss_s1: 0.076336, loss_fp: 0.007337, loss_freq: 0.059993
[06:16:40.445] iteration 21268: loss: 0.052257, loss_s1: 0.050320, loss_fp: 0.002903, loss_freq: 0.018061
[06:16:41.100] iteration 21269: loss: 0.067002, loss_s1: 0.049844, loss_fp: 0.005830, loss_freq: 0.046816
[06:16:41.708] iteration 21270: loss: 0.044715, loss_s1: 0.036648, loss_fp: 0.002989, loss_freq: 0.015787
[06:16:42.324] iteration 21271: loss: 0.058321, loss_s1: 0.034654, loss_fp: 0.002470, loss_freq: 0.035096
[06:16:42.941] iteration 21272: loss: 0.047383, loss_s1: 0.034612, loss_fp: 0.003779, loss_freq: 0.030816
[06:16:43.561] iteration 21273: loss: 0.084598, loss_s1: 0.072462, loss_fp: 0.004490, loss_freq: 0.030289
[06:16:44.196] iteration 21274: loss: 0.054073, loss_s1: 0.043001, loss_fp: 0.001932, loss_freq: 0.026335
[06:16:44.863] iteration 21275: loss: 0.117109, loss_s1: 0.155568, loss_fp: 0.003410, loss_freq: 0.034170
[06:16:45.477] iteration 21276: loss: 0.050499, loss_s1: 0.047168, loss_fp: 0.003158, loss_freq: 0.028977
[06:16:46.090] iteration 21277: loss: 0.057380, loss_s1: 0.050931, loss_fp: 0.003023, loss_freq: 0.029700
[06:16:46.705] iteration 21278: loss: 0.075043, loss_s1: 0.087933, loss_fp: 0.011498, loss_freq: 0.012059
[06:16:47.318] iteration 21279: loss: 0.056787, loss_s1: 0.040711, loss_fp: 0.002467, loss_freq: 0.039321
[06:16:47.933] iteration 21280: loss: 0.099365, loss_s1: 0.127790, loss_fp: 0.007850, loss_freq: 0.028543
[06:16:48.547] iteration 21281: loss: 0.072275, loss_s1: 0.051763, loss_fp: 0.003510, loss_freq: 0.062922
[06:16:49.161] iteration 21282: loss: 0.091111, loss_s1: 0.046914, loss_fp: 0.022169, loss_freq: 0.062178
[06:16:49.771] iteration 21283: loss: 0.091786, loss_s1: 0.055793, loss_fp: 0.004970, loss_freq: 0.079873
[06:16:50.385] iteration 21284: loss: 0.063190, loss_s1: 0.046755, loss_fp: 0.003374, loss_freq: 0.022429
[06:16:50.998] iteration 21285: loss: 0.059178, loss_s1: 0.059073, loss_fp: 0.002532, loss_freq: 0.033756
[06:16:51.607] iteration 21286: loss: 0.069963, loss_s1: 0.049161, loss_fp: 0.005063, loss_freq: 0.022388
[06:16:52.219] iteration 21287: loss: 0.062389, loss_s1: 0.047801, loss_fp: 0.001447, loss_freq: 0.040654
[06:16:52.829] iteration 21288: loss: 0.063049, loss_s1: 0.044044, loss_fp: 0.001512, loss_freq: 0.021206
[06:16:53.441] iteration 21289: loss: 0.087420, loss_s1: 0.082693, loss_fp: 0.007022, loss_freq: 0.047558
[06:16:54.053] iteration 21290: loss: 0.067606, loss_s1: 0.067473, loss_fp: 0.003670, loss_freq: 0.027234
[06:16:54.662] iteration 21291: loss: 0.090579, loss_s1: 0.107598, loss_fp: 0.000526, loss_freq: 0.038471
[06:16:55.271] iteration 21292: loss: 0.058062, loss_s1: 0.050907, loss_fp: 0.008771, loss_freq: 0.020702
[06:16:55.880] iteration 21293: loss: 0.095591, loss_s1: 0.116746, loss_fp: 0.005993, loss_freq: 0.036843
[06:16:56.494] iteration 21294: loss: 0.109616, loss_s1: 0.132916, loss_fp: 0.004405, loss_freq: 0.056010
[06:16:57.107] iteration 21295: loss: 0.064069, loss_s1: 0.057339, loss_fp: 0.005956, loss_freq: 0.019352
[06:16:57.713] iteration 21296: loss: 0.109392, loss_s1: 0.089828, loss_fp: 0.003250, loss_freq: 0.087302
[06:16:58.328] iteration 21297: loss: 0.057893, loss_s1: 0.030891, loss_fp: 0.007352, loss_freq: 0.028383
[06:16:58.933] iteration 21298: loss: 0.079093, loss_s1: 0.089892, loss_fp: 0.001375, loss_freq: 0.032100
[06:16:59.544] iteration 21299: loss: 0.044368, loss_s1: 0.036169, loss_fp: 0.001582, loss_freq: 0.011253
[06:17:00.149] iteration 21300: loss: 0.030812, loss_s1: 0.015470, loss_fp: 0.001135, loss_freq: 0.012530
[06:17:00.758] iteration 21301: loss: 0.045981, loss_s1: 0.041273, loss_fp: 0.001285, loss_freq: 0.016748
[06:17:01.367] iteration 21302: loss: 0.050695, loss_s1: 0.064657, loss_fp: 0.001680, loss_freq: 0.014782
[06:17:01.979] iteration 21303: loss: 0.034836, loss_s1: 0.012273, loss_fp: 0.007113, loss_freq: 0.016406
[06:17:02.592] iteration 21304: loss: 0.106332, loss_s1: 0.116274, loss_fp: 0.004880, loss_freq: 0.057840
[06:17:03.203] iteration 21305: loss: 0.051498, loss_s1: 0.015196, loss_fp: 0.004188, loss_freq: 0.049949
[06:17:03.819] iteration 21306: loss: 0.057963, loss_s1: 0.045863, loss_fp: 0.003876, loss_freq: 0.031203
[06:17:04.440] iteration 21307: loss: 0.061472, loss_s1: 0.045808, loss_fp: 0.004868, loss_freq: 0.040265
[06:17:05.051] iteration 21308: loss: 0.043612, loss_s1: 0.032597, loss_fp: 0.000598, loss_freq: 0.019698
[06:17:05.672] iteration 21309: loss: 0.064334, loss_s1: 0.046470, loss_fp: 0.005091, loss_freq: 0.029756
[06:17:06.278] iteration 21310: loss: 0.052590, loss_s1: 0.044996, loss_fp: 0.006574, loss_freq: 0.018893
[06:17:06.886] iteration 21311: loss: 0.030352, loss_s1: 0.018431, loss_fp: 0.004423, loss_freq: 0.006291
[06:17:07.500] iteration 21312: loss: 0.069019, loss_s1: 0.057237, loss_fp: 0.001763, loss_freq: 0.040842
[06:17:08.106] iteration 21313: loss: 0.053624, loss_s1: 0.056750, loss_fp: 0.001496, loss_freq: 0.005583
[06:17:08.714] iteration 21314: loss: 0.037059, loss_s1: 0.025252, loss_fp: 0.002480, loss_freq: 0.014836
[06:17:09.329] iteration 21315: loss: 0.037263, loss_s1: 0.017978, loss_fp: 0.010832, loss_freq: 0.013045
[06:17:09.944] iteration 21316: loss: 0.054945, loss_s1: 0.053873, loss_fp: 0.006376, loss_freq: 0.027596
[06:17:10.553] iteration 21317: loss: 0.068172, loss_s1: 0.068715, loss_fp: 0.005837, loss_freq: 0.021098
[06:17:11.167] iteration 21318: loss: 0.097397, loss_s1: 0.085638, loss_fp: 0.008044, loss_freq: 0.065780
[06:17:11.781] iteration 21319: loss: 0.040717, loss_s1: 0.020479, loss_fp: 0.003521, loss_freq: 0.018599
[06:17:12.394] iteration 21320: loss: 0.052880, loss_s1: 0.040372, loss_fp: 0.002894, loss_freq: 0.027474
[06:17:13.000] iteration 21321: loss: 0.051345, loss_s1: 0.022928, loss_fp: 0.003770, loss_freq: 0.041336
[06:17:13.602] iteration 21322: loss: 0.047600, loss_s1: 0.030107, loss_fp: 0.004201, loss_freq: 0.022752
[06:17:14.213] iteration 21323: loss: 0.068516, loss_s1: 0.049132, loss_fp: 0.008815, loss_freq: 0.045482
[06:17:14.833] iteration 21324: loss: 0.063737, loss_s1: 0.071287, loss_fp: 0.008238, loss_freq: 0.013154
[06:17:15.444] iteration 21325: loss: 0.063356, loss_s1: 0.049963, loss_fp: 0.003706, loss_freq: 0.045490
[06:17:16.058] iteration 21326: loss: 0.073868, loss_s1: 0.048705, loss_fp: 0.011679, loss_freq: 0.051007
[06:17:16.666] iteration 21327: loss: 0.036787, loss_s1: 0.023093, loss_fp: 0.001204, loss_freq: 0.018621
[06:17:17.277] iteration 21328: loss: 0.057891, loss_s1: 0.044565, loss_fp: 0.005573, loss_freq: 0.033015
[06:17:17.885] iteration 21329: loss: 0.038312, loss_s1: 0.022084, loss_fp: 0.003983, loss_freq: 0.026780
[06:17:18.494] iteration 21330: loss: 0.049326, loss_s1: 0.038981, loss_fp: 0.001678, loss_freq: 0.025963
[06:17:19.099] iteration 21331: loss: 0.055627, loss_s1: 0.031671, loss_fp: 0.003499, loss_freq: 0.040239
[06:17:19.703] iteration 21332: loss: 0.048748, loss_s1: 0.038367, loss_fp: 0.003493, loss_freq: 0.023296
[06:17:20.312] iteration 21333: loss: 0.063255, loss_s1: 0.064437, loss_fp: 0.005818, loss_freq: 0.016699
[06:17:20.936] iteration 21334: loss: 0.045120, loss_s1: 0.039600, loss_fp: 0.001740, loss_freq: 0.014705
[06:17:21.547] iteration 21335: loss: 0.077957, loss_s1: 0.070261, loss_fp: 0.002990, loss_freq: 0.044183
[06:17:22.156] iteration 21336: loss: 0.058173, loss_s1: 0.042052, loss_fp: 0.006215, loss_freq: 0.028563
[06:17:22.781] iteration 21337: loss: 0.066920, loss_s1: 0.054500, loss_fp: 0.005744, loss_freq: 0.052602
[06:17:23.391] iteration 21338: loss: 0.115102, loss_s1: 0.148538, loss_fp: 0.002637, loss_freq: 0.050262
[06:17:23.996] iteration 21339: loss: 0.056880, loss_s1: 0.048519, loss_fp: 0.008832, loss_freq: 0.026058
[06:17:24.607] iteration 21340: loss: 0.061374, loss_s1: 0.021287, loss_fp: 0.002481, loss_freq: 0.033147
[06:17:25.220] iteration 21341: loss: 0.062775, loss_s1: 0.061251, loss_fp: 0.004821, loss_freq: 0.024119
[06:17:25.835] iteration 21342: loss: 0.063144, loss_s1: 0.075622, loss_fp: 0.004267, loss_freq: 0.024677
[06:17:26.446] iteration 21343: loss: 0.075818, loss_s1: 0.065281, loss_fp: 0.004889, loss_freq: 0.029040
[06:17:27.058] iteration 21344: loss: 0.045655, loss_s1: 0.039286, loss_fp: 0.001110, loss_freq: 0.024461
[06:17:27.671] iteration 21345: loss: 0.073386, loss_s1: 0.071542, loss_fp: 0.004108, loss_freq: 0.021570
[06:17:28.333] iteration 21346: loss: 0.077474, loss_s1: 0.074497, loss_fp: 0.003465, loss_freq: 0.048017
[06:17:28.998] iteration 21347: loss: 0.085502, loss_s1: 0.088261, loss_fp: 0.008868, loss_freq: 0.031589
[06:17:29.618] iteration 21348: loss: 0.058610, loss_s1: 0.037175, loss_fp: 0.001402, loss_freq: 0.040591
[06:17:30.245] iteration 21349: loss: 0.071461, loss_s1: 0.080255, loss_fp: 0.002061, loss_freq: 0.027642
[06:17:30.867] iteration 21350: loss: 0.054919, loss_s1: 0.052088, loss_fp: 0.003784, loss_freq: 0.020342
[06:17:31.480] iteration 21351: loss: 0.051972, loss_s1: 0.063033, loss_fp: 0.001152, loss_freq: 0.009812
[06:17:32.091] iteration 21352: loss: 0.040941, loss_s1: 0.027190, loss_fp: 0.004233, loss_freq: 0.012462
[06:17:32.707] iteration 21353: loss: 0.036933, loss_s1: 0.022025, loss_fp: 0.000939, loss_freq: 0.019103
[06:17:33.320] iteration 21354: loss: 0.049283, loss_s1: 0.032016, loss_fp: 0.006735, loss_freq: 0.024520
[06:17:33.961] iteration 21355: loss: 0.037531, loss_s1: 0.030362, loss_fp: 0.001139, loss_freq: 0.018105
[06:17:34.576] iteration 21356: loss: 0.070753, loss_s1: 0.084259, loss_fp: 0.003907, loss_freq: 0.018526
[06:17:35.196] iteration 21357: loss: 0.051353, loss_s1: 0.040270, loss_fp: 0.002174, loss_freq: 0.027266
[06:17:35.818] iteration 21358: loss: 0.045765, loss_s1: 0.041685, loss_fp: 0.001820, loss_freq: 0.021074
[06:17:36.432] iteration 21359: loss: 0.081283, loss_s1: 0.060895, loss_fp: 0.003461, loss_freq: 0.061136
[06:17:37.044] iteration 21360: loss: 0.050550, loss_s1: 0.024889, loss_fp: 0.003932, loss_freq: 0.046041
[06:17:37.653] iteration 21361: loss: 0.054467, loss_s1: 0.034372, loss_fp: 0.003518, loss_freq: 0.033566
[06:17:38.260] iteration 21362: loss: 0.057579, loss_s1: 0.040421, loss_fp: 0.004704, loss_freq: 0.016418
[06:17:38.866] iteration 21363: loss: 0.056422, loss_s1: 0.047169, loss_fp: 0.004070, loss_freq: 0.031143
[06:17:39.476] iteration 21364: loss: 0.035925, loss_s1: 0.021187, loss_fp: 0.005664, loss_freq: 0.017372
[06:17:40.081] iteration 21365: loss: 0.077056, loss_s1: 0.044164, loss_fp: 0.009087, loss_freq: 0.043449
[06:17:40.690] iteration 21366: loss: 0.058868, loss_s1: 0.048998, loss_fp: 0.002632, loss_freq: 0.032615
[06:17:41.300] iteration 21367: loss: 0.050613, loss_s1: 0.038880, loss_fp: 0.006129, loss_freq: 0.025446
[06:17:41.914] iteration 21368: loss: 0.060562, loss_s1: 0.052676, loss_fp: 0.004389, loss_freq: 0.030076
[06:17:42.543] iteration 21369: loss: 0.080676, loss_s1: 0.043783, loss_fp: 0.001848, loss_freq: 0.084702
[06:17:43.162] iteration 21370: loss: 0.064124, loss_s1: 0.044852, loss_fp: 0.003607, loss_freq: 0.043089
[06:17:43.796] iteration 21371: loss: 0.044191, loss_s1: 0.030750, loss_fp: 0.002963, loss_freq: 0.013795
[06:17:44.576] iteration 21372: loss: 0.078774, loss_s1: 0.099447, loss_fp: 0.002642, loss_freq: 0.035616
[06:17:45.270] iteration 21373: loss: 0.061523, loss_s1: 0.036424, loss_fp: 0.001889, loss_freq: 0.048450
[06:17:45.974] iteration 21374: loss: 0.056096, loss_s1: 0.034945, loss_fp: 0.009255, loss_freq: 0.032556
[06:17:46.704] iteration 21375: loss: 0.098486, loss_s1: 0.071324, loss_fp: 0.026634, loss_freq: 0.061509
[06:17:47.386] iteration 21376: loss: 0.034249, loss_s1: 0.016252, loss_fp: 0.003464, loss_freq: 0.015232
[06:17:48.094] iteration 21377: loss: 0.065534, loss_s1: 0.047180, loss_fp: 0.004108, loss_freq: 0.055149
[06:17:48.755] iteration 21378: loss: 0.040901, loss_s1: 0.028525, loss_fp: 0.006421, loss_freq: 0.011520
[06:17:49.486] iteration 21379: loss: 0.073194, loss_s1: 0.077713, loss_fp: 0.003931, loss_freq: 0.039994
[06:17:50.123] iteration 21380: loss: 0.057591, loss_s1: 0.043727, loss_fp: 0.007102, loss_freq: 0.031638
[06:17:50.846] iteration 21381: loss: 0.042833, loss_s1: 0.046955, loss_fp: 0.001236, loss_freq: 0.011797
[06:17:51.475] iteration 21382: loss: 0.046887, loss_s1: 0.025415, loss_fp: 0.004504, loss_freq: 0.021294
[06:17:52.237] iteration 21383: loss: 0.099037, loss_s1: 0.085286, loss_fp: 0.011864, loss_freq: 0.063681
[06:17:52.867] iteration 21384: loss: 0.044894, loss_s1: 0.028758, loss_fp: 0.002360, loss_freq: 0.019866
[06:17:53.497] iteration 21385: loss: 0.091269, loss_s1: 0.073001, loss_fp: 0.004121, loss_freq: 0.064033
[06:17:54.155] iteration 21386: loss: 0.035902, loss_s1: 0.030750, loss_fp: 0.005071, loss_freq: 0.011156
[06:17:54.786] iteration 21387: loss: 0.073327, loss_s1: 0.071610, loss_fp: 0.007967, loss_freq: 0.027241
[06:17:55.500] iteration 21388: loss: 0.034040, loss_s1: 0.029499, loss_fp: 0.001325, loss_freq: 0.011182
[06:17:56.353] iteration 21389: loss: 0.064771, loss_s1: 0.070602, loss_fp: 0.003794, loss_freq: 0.025276
[06:17:56.986] iteration 21390: loss: 0.069192, loss_s1: 0.060084, loss_fp: 0.003623, loss_freq: 0.053642
[06:17:57.604] iteration 21391: loss: 0.064676, loss_s1: 0.042222, loss_fp: 0.007426, loss_freq: 0.014409
[06:17:58.227] iteration 21392: loss: 0.057930, loss_s1: 0.054935, loss_fp: 0.002228, loss_freq: 0.021725
[06:17:58.841] iteration 21393: loss: 0.044185, loss_s1: 0.036900, loss_fp: 0.002780, loss_freq: 0.011751
[06:17:59.452] iteration 21394: loss: 0.054603, loss_s1: 0.058824, loss_fp: 0.004503, loss_freq: 0.013263
[06:18:00.064] iteration 21395: loss: 0.029008, loss_s1: 0.010978, loss_fp: 0.003146, loss_freq: 0.009389
[06:18:00.674] iteration 21396: loss: 0.070942, loss_s1: 0.045176, loss_fp: 0.009631, loss_freq: 0.047369
[06:18:01.288] iteration 21397: loss: 0.053670, loss_s1: 0.047152, loss_fp: 0.004214, loss_freq: 0.027328
[06:18:01.898] iteration 21398: loss: 0.051448, loss_s1: 0.033944, loss_fp: 0.003776, loss_freq: 0.040307
[06:18:02.512] iteration 21399: loss: 0.069417, loss_s1: 0.070553, loss_fp: 0.003021, loss_freq: 0.045018
[06:18:03.131] iteration 21400: loss: 0.044690, loss_s1: 0.021644, loss_fp: 0.005745, loss_freq: 0.027505
[06:18:06.690] iteration 21400 : mean_dice : 0.727182
[06:18:07.372] iteration 21401: loss: 0.070902, loss_s1: 0.046840, loss_fp: 0.018821, loss_freq: 0.041151
[06:18:07.983] iteration 21402: loss: 0.108621, loss_s1: 0.127208, loss_fp: 0.005596, loss_freq: 0.049359
[06:18:08.627] iteration 21403: loss: 0.072141, loss_s1: 0.073269, loss_fp: 0.005993, loss_freq: 0.022112
[06:18:09.304] iteration 21404: loss: 0.064945, loss_s1: 0.037537, loss_fp: 0.007413, loss_freq: 0.042267
[06:18:09.915] iteration 21405: loss: 0.079526, loss_s1: 0.057796, loss_fp: 0.005195, loss_freq: 0.046547
[06:18:10.522] iteration 21406: loss: 0.032017, loss_s1: 0.015361, loss_fp: 0.001431, loss_freq: 0.010253
[06:18:11.135] iteration 21407: loss: 0.037781, loss_s1: 0.029286, loss_fp: 0.003920, loss_freq: 0.019400
[06:18:11.878] iteration 21408: loss: 0.102185, loss_s1: 0.072058, loss_fp: 0.006461, loss_freq: 0.068834
[06:18:12.743] iteration 21409: loss: 0.076641, loss_s1: 0.071618, loss_fp: 0.004989, loss_freq: 0.048130
[06:18:13.572] iteration 21410: loss: 0.095421, loss_s1: 0.094715, loss_fp: 0.004012, loss_freq: 0.051171
[06:18:14.205] iteration 21411: loss: 0.060394, loss_s1: 0.069783, loss_fp: 0.003693, loss_freq: 0.013892
[06:18:14.819] iteration 21412: loss: 0.072654, loss_s1: 0.064710, loss_fp: 0.009011, loss_freq: 0.046819
[06:18:15.425] iteration 21413: loss: 0.049104, loss_s1: 0.020329, loss_fp: 0.010424, loss_freq: 0.024547
[06:18:16.056] iteration 21414: loss: 0.040659, loss_s1: 0.030392, loss_fp: 0.002259, loss_freq: 0.019590
[06:18:16.664] iteration 21415: loss: 0.044053, loss_s1: 0.038296, loss_fp: 0.001668, loss_freq: 0.017211
[06:18:17.268] iteration 21416: loss: 0.081498, loss_s1: 0.080551, loss_fp: 0.005174, loss_freq: 0.050890
[06:18:17.950] iteration 21417: loss: 0.062498, loss_s1: 0.040067, loss_fp: 0.002301, loss_freq: 0.045296
[06:18:18.586] iteration 21418: loss: 0.071121, loss_s1: 0.079901, loss_fp: 0.001396, loss_freq: 0.026161
[06:18:19.293] iteration 21419: loss: 0.095870, loss_s1: 0.126172, loss_fp: 0.002476, loss_freq: 0.036851
[06:18:20.046] iteration 21420: loss: 0.062680, loss_s1: 0.054518, loss_fp: 0.004773, loss_freq: 0.031630
[06:18:21.041] iteration 21421: loss: 0.067399, loss_s1: 0.045685, loss_fp: 0.003657, loss_freq: 0.028452
[06:18:21.649] iteration 21422: loss: 0.054349, loss_s1: 0.055925, loss_fp: 0.002141, loss_freq: 0.018571
[06:18:22.268] iteration 21423: loss: 0.052455, loss_s1: 0.059217, loss_fp: 0.001291, loss_freq: 0.015750
[06:18:22.876] iteration 21424: loss: 0.054469, loss_s1: 0.057842, loss_fp: 0.001419, loss_freq: 0.019806
[06:18:23.501] iteration 21425: loss: 0.046735, loss_s1: 0.040215, loss_fp: 0.009517, loss_freq: 0.022016
[06:18:24.109] iteration 21426: loss: 0.070912, loss_s1: 0.079028, loss_fp: 0.004234, loss_freq: 0.020921
[06:18:24.718] iteration 21427: loss: 0.055540, loss_s1: 0.036598, loss_fp: 0.004472, loss_freq: 0.037481
[06:18:25.331] iteration 21428: loss: 0.045661, loss_s1: 0.037583, loss_fp: 0.003315, loss_freq: 0.022195
[06:18:25.957] iteration 21429: loss: 0.055117, loss_s1: 0.051862, loss_fp: 0.003239, loss_freq: 0.015913
[06:18:26.567] iteration 21430: loss: 0.074933, loss_s1: 0.064653, loss_fp: 0.008127, loss_freq: 0.029883
[06:18:27.174] iteration 21431: loss: 0.074907, loss_s1: 0.061778, loss_fp: 0.004403, loss_freq: 0.030788
[06:18:27.840] iteration 21432: loss: 0.088099, loss_s1: 0.115637, loss_fp: 0.002031, loss_freq: 0.024380
[06:18:28.517] iteration 21433: loss: 0.072063, loss_s1: 0.061244, loss_fp: 0.008112, loss_freq: 0.039077
[06:18:29.159] iteration 21434: loss: 0.087787, loss_s1: 0.094217, loss_fp: 0.007369, loss_freq: 0.041474
[06:18:29.768] iteration 21435: loss: 0.045494, loss_s1: 0.033826, loss_fp: 0.005102, loss_freq: 0.019284
[06:18:30.383] iteration 21436: loss: 0.082981, loss_s1: 0.113981, loss_fp: 0.001359, loss_freq: 0.016427
[06:18:30.994] iteration 21437: loss: 0.083793, loss_s1: 0.072989, loss_fp: 0.012071, loss_freq: 0.058963
[06:18:31.606] iteration 21438: loss: 0.043266, loss_s1: 0.038570, loss_fp: 0.002958, loss_freq: 0.016017
[06:18:32.216] iteration 21439: loss: 0.071771, loss_s1: 0.078539, loss_fp: 0.003486, loss_freq: 0.032464
[06:18:32.832] iteration 21440: loss: 0.064426, loss_s1: 0.072928, loss_fp: 0.001451, loss_freq: 0.018587
[06:18:33.445] iteration 21441: loss: 0.044799, loss_s1: 0.017708, loss_fp: 0.001269, loss_freq: 0.039149
[06:18:34.055] iteration 21442: loss: 0.069437, loss_s1: 0.050133, loss_fp: 0.003079, loss_freq: 0.058133
[06:18:34.664] iteration 21443: loss: 0.072029, loss_s1: 0.069145, loss_fp: 0.002990, loss_freq: 0.026819
[06:18:35.271] iteration 21444: loss: 0.054692, loss_s1: 0.042235, loss_fp: 0.003846, loss_freq: 0.020142
[06:18:35.877] iteration 21445: loss: 0.061961, loss_s1: 0.042793, loss_fp: 0.005871, loss_freq: 0.041139
[06:18:36.484] iteration 21446: loss: 0.057538, loss_s1: 0.042107, loss_fp: 0.005097, loss_freq: 0.043170
[06:18:37.094] iteration 21447: loss: 0.060268, loss_s1: 0.056784, loss_fp: 0.003961, loss_freq: 0.011501
[06:18:37.707] iteration 21448: loss: 0.120314, loss_s1: 0.148733, loss_fp: 0.010199, loss_freq: 0.034719
[06:18:38.315] iteration 21449: loss: 0.036314, loss_s1: 0.018035, loss_fp: 0.001447, loss_freq: 0.025566
[06:18:38.933] iteration 21450: loss: 0.052604, loss_s1: 0.035178, loss_fp: 0.009405, loss_freq: 0.025715
[06:18:39.542] iteration 21451: loss: 0.072703, loss_s1: 0.043419, loss_fp: 0.004428, loss_freq: 0.072491
[06:18:40.145] iteration 21452: loss: 0.087875, loss_s1: 0.099613, loss_fp: 0.007085, loss_freq: 0.027288
[06:18:40.754] iteration 21453: loss: 0.048340, loss_s1: 0.045576, loss_fp: 0.002748, loss_freq: 0.020103
[06:18:41.360] iteration 21454: loss: 0.028210, loss_s1: 0.009878, loss_fp: 0.001064, loss_freq: 0.009856
[06:18:41.968] iteration 21455: loss: 0.076589, loss_s1: 0.081654, loss_fp: 0.000860, loss_freq: 0.044593
[06:18:42.582] iteration 21456: loss: 0.049948, loss_s1: 0.036740, loss_fp: 0.001983, loss_freq: 0.014846
[06:18:43.194] iteration 21457: loss: 0.064462, loss_s1: 0.062924, loss_fp: 0.003085, loss_freq: 0.029470
[06:18:43.807] iteration 21458: loss: 0.042817, loss_s1: 0.043553, loss_fp: 0.001945, loss_freq: 0.014615
[06:18:44.421] iteration 21459: loss: 0.091558, loss_s1: 0.098329, loss_fp: 0.005793, loss_freq: 0.046011
[06:18:45.032] iteration 21460: loss: 0.065420, loss_s1: 0.077154, loss_fp: 0.004265, loss_freq: 0.020361
[06:18:45.639] iteration 21461: loss: 0.040852, loss_s1: 0.030520, loss_fp: 0.004779, loss_freq: 0.007922
[06:18:46.250] iteration 21462: loss: 0.091567, loss_s1: 0.121500, loss_fp: 0.001835, loss_freq: 0.018777
[06:18:46.861] iteration 21463: loss: 0.104185, loss_s1: 0.128385, loss_fp: 0.003455, loss_freq: 0.047523
[06:18:47.472] iteration 21464: loss: 0.128641, loss_s1: 0.173781, loss_fp: 0.001674, loss_freq: 0.057977
[06:18:48.081] iteration 21465: loss: 0.065786, loss_s1: 0.060482, loss_fp: 0.005679, loss_freq: 0.016556
[06:18:48.688] iteration 21466: loss: 0.096924, loss_s1: 0.115414, loss_fp: 0.001712, loss_freq: 0.045031
[06:18:49.309] iteration 21467: loss: 0.044794, loss_s1: 0.029748, loss_fp: 0.002018, loss_freq: 0.021500
[06:18:49.917] iteration 21468: loss: 0.045899, loss_s1: 0.037377, loss_fp: 0.003760, loss_freq: 0.020874
[06:18:50.525] iteration 21469: loss: 0.061652, loss_s1: 0.066741, loss_fp: 0.001489, loss_freq: 0.011681
[06:18:51.140] iteration 21470: loss: 0.039075, loss_s1: 0.034979, loss_fp: 0.003078, loss_freq: 0.008438
[06:18:51.752] iteration 21471: loss: 0.044167, loss_s1: 0.044838, loss_fp: 0.001317, loss_freq: 0.009511
[06:18:52.361] iteration 21472: loss: 0.066294, loss_s1: 0.074840, loss_fp: 0.002576, loss_freq: 0.030360
[06:18:52.967] iteration 21473: loss: 0.064980, loss_s1: 0.066499, loss_fp: 0.002105, loss_freq: 0.017213
[06:18:53.572] iteration 21474: loss: 0.058835, loss_s1: 0.046961, loss_fp: 0.002876, loss_freq: 0.035571
[06:18:54.177] iteration 21475: loss: 0.042626, loss_s1: 0.019395, loss_fp: 0.005931, loss_freq: 0.021221
[06:18:54.779] iteration 21476: loss: 0.048810, loss_s1: 0.029858, loss_fp: 0.002674, loss_freq: 0.029299
[06:18:55.382] iteration 21477: loss: 0.069730, loss_s1: 0.075356, loss_fp: 0.001890, loss_freq: 0.030385
[06:18:55.990] iteration 21478: loss: 0.038435, loss_s1: 0.024972, loss_fp: 0.000996, loss_freq: 0.014615
[06:18:56.659] iteration 21479: loss: 0.034903, loss_s1: 0.019634, loss_fp: 0.004336, loss_freq: 0.022114
[06:18:57.341] iteration 21480: loss: 0.066070, loss_s1: 0.054090, loss_fp: 0.002587, loss_freq: 0.038387
[06:18:58.007] iteration 21481: loss: 0.028028, loss_s1: 0.021914, loss_fp: 0.001695, loss_freq: 0.008063
[06:18:58.622] iteration 21482: loss: 0.051286, loss_s1: 0.016579, loss_fp: 0.001668, loss_freq: 0.033694
[06:18:59.227] iteration 21483: loss: 0.040730, loss_s1: 0.029195, loss_fp: 0.003971, loss_freq: 0.014343
[06:18:59.840] iteration 21484: loss: 0.032808, loss_s1: 0.028293, loss_fp: 0.001818, loss_freq: 0.005960
[06:19:00.445] iteration 21485: loss: 0.079829, loss_s1: 0.099032, loss_fp: 0.002136, loss_freq: 0.017088
[06:19:01.049] iteration 21486: loss: 0.047030, loss_s1: 0.031166, loss_fp: 0.003626, loss_freq: 0.035304
[06:19:01.655] iteration 21487: loss: 0.051484, loss_s1: 0.033838, loss_fp: 0.002022, loss_freq: 0.015498
[06:19:02.262] iteration 21488: loss: 0.099210, loss_s1: 0.087018, loss_fp: 0.006204, loss_freq: 0.076460
[06:19:02.890] iteration 21489: loss: 0.034670, loss_s1: 0.022488, loss_fp: 0.003774, loss_freq: 0.012146
[06:19:03.508] iteration 21490: loss: 0.046977, loss_s1: 0.030235, loss_fp: 0.007092, loss_freq: 0.030967
[06:19:04.113] iteration 21491: loss: 0.084839, loss_s1: 0.065593, loss_fp: 0.007943, loss_freq: 0.057161
[06:19:04.723] iteration 21492: loss: 0.064408, loss_s1: 0.060599, loss_fp: 0.003642, loss_freq: 0.029605
[06:19:05.335] iteration 21493: loss: 0.054238, loss_s1: 0.039673, loss_fp: 0.006181, loss_freq: 0.037017
[06:19:05.949] iteration 21494: loss: 0.076040, loss_s1: 0.092029, loss_fp: 0.005754, loss_freq: 0.023212
[06:19:06.560] iteration 21495: loss: 0.060006, loss_s1: 0.039426, loss_fp: 0.003976, loss_freq: 0.045142
[06:19:07.168] iteration 21496: loss: 0.058415, loss_s1: 0.050033, loss_fp: 0.007251, loss_freq: 0.026311
[06:19:07.777] iteration 21497: loss: 0.058833, loss_s1: 0.043819, loss_fp: 0.003625, loss_freq: 0.037878
[06:19:08.389] iteration 21498: loss: 0.122836, loss_s1: 0.131039, loss_fp: 0.004411, loss_freq: 0.076069
[06:19:09.000] iteration 21499: loss: 0.062268, loss_s1: 0.045764, loss_fp: 0.006167, loss_freq: 0.045038
[06:19:09.621] iteration 21500: loss: 0.060334, loss_s1: 0.060223, loss_fp: 0.006546, loss_freq: 0.015875
[06:19:10.245] iteration 21501: loss: 0.067487, loss_s1: 0.073913, loss_fp: 0.003038, loss_freq: 0.018917
[06:19:10.854] iteration 21502: loss: 0.048966, loss_s1: 0.035781, loss_fp: 0.004875, loss_freq: 0.029716
[06:19:11.463] iteration 21503: loss: 0.043197, loss_s1: 0.035771, loss_fp: 0.003566, loss_freq: 0.020794
[06:19:12.077] iteration 21504: loss: 0.061110, loss_s1: 0.054587, loss_fp: 0.006195, loss_freq: 0.015949
[06:19:12.680] iteration 21505: loss: 0.055522, loss_s1: 0.053423, loss_fp: 0.003147, loss_freq: 0.024013
[06:19:13.282] iteration 21506: loss: 0.050983, loss_s1: 0.022593, loss_fp: 0.004798, loss_freq: 0.030406
[06:19:13.887] iteration 21507: loss: 0.056663, loss_s1: 0.051515, loss_fp: 0.004575, loss_freq: 0.032674
[06:19:14.492] iteration 21508: loss: 0.064284, loss_s1: 0.069821, loss_fp: 0.003885, loss_freq: 0.015344
[06:19:15.103] iteration 21509: loss: 0.086610, loss_s1: 0.071880, loss_fp: 0.004142, loss_freq: 0.068953
[06:19:15.716] iteration 21510: loss: 0.050647, loss_s1: 0.049770, loss_fp: 0.003049, loss_freq: 0.010819
[06:19:16.327] iteration 21511: loss: 0.077831, loss_s1: 0.069673, loss_fp: 0.002358, loss_freq: 0.052423
[06:19:16.935] iteration 21512: loss: 0.031738, loss_s1: 0.019896, loss_fp: 0.000500, loss_freq: 0.020141
[06:19:17.547] iteration 21513: loss: 0.061687, loss_s1: 0.052810, loss_fp: 0.002698, loss_freq: 0.027719
[06:19:18.157] iteration 21514: loss: 0.050020, loss_s1: 0.039021, loss_fp: 0.001594, loss_freq: 0.032665
[06:19:18.765] iteration 21515: loss: 0.055783, loss_s1: 0.033689, loss_fp: 0.003631, loss_freq: 0.046687
[06:19:19.370] iteration 21516: loss: 0.061581, loss_s1: 0.061086, loss_fp: 0.004046, loss_freq: 0.035711
[06:19:19.974] iteration 21517: loss: 0.069200, loss_s1: 0.065779, loss_fp: 0.003021, loss_freq: 0.023724
[06:19:20.582] iteration 21518: loss: 0.050461, loss_s1: 0.030485, loss_fp: 0.001487, loss_freq: 0.028081
[06:19:21.197] iteration 21519: loss: 0.060723, loss_s1: 0.072229, loss_fp: 0.001805, loss_freq: 0.017683
[06:19:21.820] iteration 21520: loss: 0.051753, loss_s1: 0.034358, loss_fp: 0.003050, loss_freq: 0.025435
[06:19:22.461] iteration 21521: loss: 0.069712, loss_s1: 0.087166, loss_fp: 0.005230, loss_freq: 0.019356
[06:19:23.070] iteration 21522: loss: 0.040255, loss_s1: 0.025864, loss_fp: 0.009276, loss_freq: 0.006237
[06:19:23.681] iteration 21523: loss: 0.048169, loss_s1: 0.031999, loss_fp: 0.002122, loss_freq: 0.016109
[06:19:24.292] iteration 21524: loss: 0.039668, loss_s1: 0.022025, loss_fp: 0.001781, loss_freq: 0.019628
[06:19:24.908] iteration 21525: loss: 0.041186, loss_s1: 0.034638, loss_fp: 0.004641, loss_freq: 0.017945
[06:19:25.518] iteration 21526: loss: 0.061199, loss_s1: 0.054954, loss_fp: 0.003366, loss_freq: 0.030188
[06:19:26.127] iteration 21527: loss: 0.061106, loss_s1: 0.063898, loss_fp: 0.003630, loss_freq: 0.020798
[06:19:26.736] iteration 21528: loss: 0.036390, loss_s1: 0.015187, loss_fp: 0.001689, loss_freq: 0.023410
[06:19:27.352] iteration 21529: loss: 0.051765, loss_s1: 0.032205, loss_fp: 0.009281, loss_freq: 0.026677
[06:19:27.963] iteration 21530: loss: 0.041978, loss_s1: 0.032063, loss_fp: 0.001059, loss_freq: 0.023675
[06:19:28.576] iteration 21531: loss: 0.039488, loss_s1: 0.023602, loss_fp: 0.004808, loss_freq: 0.014471
[06:19:29.195] iteration 21532: loss: 0.058078, loss_s1: 0.049594, loss_fp: 0.003161, loss_freq: 0.028403
[06:19:29.806] iteration 21533: loss: 0.051115, loss_s1: 0.046159, loss_fp: 0.002049, loss_freq: 0.025898
[06:19:30.426] iteration 21534: loss: 0.042576, loss_s1: 0.034749, loss_fp: 0.009043, loss_freq: 0.020124
[06:19:31.041] iteration 21535: loss: 0.097546, loss_s1: 0.037519, loss_fp: 0.003069, loss_freq: 0.114215
[06:19:31.655] iteration 21536: loss: 0.080066, loss_s1: 0.061207, loss_fp: 0.006139, loss_freq: 0.041103
[06:19:32.259] iteration 21537: loss: 0.067962, loss_s1: 0.073811, loss_fp: 0.003406, loss_freq: 0.020747
[06:19:32.863] iteration 21538: loss: 0.056952, loss_s1: 0.046188, loss_fp: 0.004212, loss_freq: 0.037687
[06:19:33.472] iteration 21539: loss: 0.074955, loss_s1: 0.047754, loss_fp: 0.004913, loss_freq: 0.070622
[06:19:34.076] iteration 21540: loss: 0.052558, loss_s1: 0.054250, loss_fp: 0.003278, loss_freq: 0.016180
[06:19:34.683] iteration 21541: loss: 0.062126, loss_s1: 0.067737, loss_fp: 0.002328, loss_freq: 0.010105
[06:19:35.297] iteration 21542: loss: 0.066945, loss_s1: 0.073875, loss_fp: 0.007971, loss_freq: 0.026046
[06:19:35.898] iteration 21543: loss: 0.070786, loss_s1: 0.077437, loss_fp: 0.003914, loss_freq: 0.028220
[06:19:36.510] iteration 21544: loss: 0.049514, loss_s1: 0.033776, loss_fp: 0.001643, loss_freq: 0.031954
[06:19:37.115] iteration 21545: loss: 0.061638, loss_s1: 0.047035, loss_fp: 0.015567, loss_freq: 0.025215
[06:19:37.728] iteration 21546: loss: 0.056596, loss_s1: 0.034447, loss_fp: 0.000842, loss_freq: 0.040249
[06:19:38.338] iteration 21547: loss: 0.080574, loss_s1: 0.076744, loss_fp: 0.004184, loss_freq: 0.055558
[06:19:38.946] iteration 21548: loss: 0.073814, loss_s1: 0.076825, loss_fp: 0.001649, loss_freq: 0.029990
[06:19:39.551] iteration 21549: loss: 0.096582, loss_s1: 0.096517, loss_fp: 0.002150, loss_freq: 0.066530
[06:19:40.156] iteration 21550: loss: 0.070290, loss_s1: 0.046706, loss_fp: 0.008178, loss_freq: 0.046900
[06:19:40.770] iteration 21551: loss: 0.058237, loss_s1: 0.059327, loss_fp: 0.002854, loss_freq: 0.027318
[06:19:41.379] iteration 21552: loss: 0.084159, loss_s1: 0.040054, loss_fp: 0.002598, loss_freq: 0.037389
[06:19:42.035] iteration 21553: loss: 0.064203, loss_s1: 0.061902, loss_fp: 0.002206, loss_freq: 0.032328
[06:19:42.687] iteration 21554: loss: 0.056997, loss_s1: 0.053946, loss_fp: 0.004537, loss_freq: 0.026722
[06:19:43.344] iteration 21555: loss: 0.070665, loss_s1: 0.045385, loss_fp: 0.001831, loss_freq: 0.059258
[06:19:43.990] iteration 21556: loss: 0.031422, loss_s1: 0.024259, loss_fp: 0.001819, loss_freq: 0.010750
[06:19:44.663] iteration 21557: loss: 0.083805, loss_s1: 0.099842, loss_fp: 0.001786, loss_freq: 0.010936
[06:19:45.273] iteration 21558: loss: 0.087043, loss_s1: 0.080160, loss_fp: 0.001716, loss_freq: 0.061278
[06:19:45.916] iteration 21559: loss: 0.105361, loss_s1: 0.129934, loss_fp: 0.008503, loss_freq: 0.043608
[06:19:46.573] iteration 21560: loss: 0.066632, loss_s1: 0.054217, loss_fp: 0.002446, loss_freq: 0.054270
[06:19:47.227] iteration 21561: loss: 0.073052, loss_s1: 0.047246, loss_fp: 0.004737, loss_freq: 0.061974
[06:19:47.879] iteration 21562: loss: 0.054053, loss_s1: 0.028315, loss_fp: 0.006319, loss_freq: 0.031087
[06:19:48.535] iteration 21563: loss: 0.056220, loss_s1: 0.059171, loss_fp: 0.001974, loss_freq: 0.025246
[06:19:49.183] iteration 21564: loss: 0.056185, loss_s1: 0.059734, loss_fp: 0.007866, loss_freq: 0.012001
[06:19:49.790] iteration 21565: loss: 0.046708, loss_s1: 0.028475, loss_fp: 0.014438, loss_freq: 0.009313
[06:19:50.410] iteration 21566: loss: 0.044783, loss_s1: 0.035092, loss_fp: 0.006629, loss_freq: 0.012494
[06:19:51.016] iteration 21567: loss: 0.046893, loss_s1: 0.042614, loss_fp: 0.002444, loss_freq: 0.020860
[06:19:51.620] iteration 21568: loss: 0.067738, loss_s1: 0.071879, loss_fp: 0.006745, loss_freq: 0.020446
[06:19:52.226] iteration 21569: loss: 0.064462, loss_s1: 0.049702, loss_fp: 0.003174, loss_freq: 0.053862
[06:19:52.827] iteration 21570: loss: 0.055650, loss_s1: 0.032430, loss_fp: 0.002730, loss_freq: 0.025099
[06:19:53.429] iteration 21571: loss: 0.071967, loss_s1: 0.041790, loss_fp: 0.014951, loss_freq: 0.032589
[06:19:54.029] iteration 21572: loss: 0.051596, loss_s1: 0.026198, loss_fp: 0.003234, loss_freq: 0.040418
[06:19:54.633] iteration 21573: loss: 0.087687, loss_s1: 0.092718, loss_fp: 0.003007, loss_freq: 0.045086
[06:19:55.239] iteration 21574: loss: 0.088427, loss_s1: 0.093024, loss_fp: 0.004087, loss_freq: 0.041201
[06:19:55.847] iteration 21575: loss: 0.060411, loss_s1: 0.046982, loss_fp: 0.004127, loss_freq: 0.032026
[06:19:56.452] iteration 21576: loss: 0.041240, loss_s1: 0.024222, loss_fp: 0.001234, loss_freq: 0.020140
[06:19:57.058] iteration 21577: loss: 0.024757, loss_s1: 0.014925, loss_fp: 0.001482, loss_freq: 0.008016
[06:19:57.663] iteration 21578: loss: 0.105646, loss_s1: 0.095057, loss_fp: 0.002654, loss_freq: 0.071289
[06:19:58.268] iteration 21579: loss: 0.073567, loss_s1: 0.045080, loss_fp: 0.003200, loss_freq: 0.066713
[06:19:58.868] iteration 21580: loss: 0.068217, loss_s1: 0.059455, loss_fp: 0.002881, loss_freq: 0.033644
[06:19:59.472] iteration 21581: loss: 0.040053, loss_s1: 0.035276, loss_fp: 0.001870, loss_freq: 0.008388
[06:20:00.083] iteration 21582: loss: 0.068993, loss_s1: 0.080431, loss_fp: 0.003841, loss_freq: 0.029159
[06:20:00.694] iteration 21583: loss: 0.045732, loss_s1: 0.026277, loss_fp: 0.002181, loss_freq: 0.013833
[06:20:01.307] iteration 21584: loss: 0.041187, loss_s1: 0.033523, loss_fp: 0.002987, loss_freq: 0.019877
[06:20:01.910] iteration 21585: loss: 0.034064, loss_s1: 0.017662, loss_fp: 0.001869, loss_freq: 0.010120
[06:20:02.517] iteration 21586: loss: 0.072116, loss_s1: 0.082508, loss_fp: 0.005872, loss_freq: 0.027146
[06:20:03.133] iteration 21587: loss: 0.055433, loss_s1: 0.028108, loss_fp: 0.006936, loss_freq: 0.036079
[06:20:03.739] iteration 21588: loss: 0.058215, loss_s1: 0.051130, loss_fp: 0.004163, loss_freq: 0.023074
[06:20:04.344] iteration 21589: loss: 0.081164, loss_s1: 0.061142, loss_fp: 0.003425, loss_freq: 0.059123
[06:20:04.948] iteration 21590: loss: 0.070911, loss_s1: 0.050858, loss_fp: 0.009597, loss_freq: 0.042551
[06:20:05.861] iteration 21591: loss: 0.062137, loss_s1: 0.074521, loss_fp: 0.001119, loss_freq: 0.011947
[06:20:06.475] iteration 21592: loss: 0.062723, loss_s1: 0.037214, loss_fp: 0.002459, loss_freq: 0.050470
[06:20:07.089] iteration 21593: loss: 0.081497, loss_s1: 0.109122, loss_fp: 0.003267, loss_freq: 0.024020
[06:20:07.706] iteration 21594: loss: 0.050806, loss_s1: 0.034489, loss_fp: 0.002802, loss_freq: 0.017256
[06:20:08.325] iteration 21595: loss: 0.040154, loss_s1: 0.035175, loss_fp: 0.003857, loss_freq: 0.015511
[06:20:08.990] iteration 21596: loss: 0.076547, loss_s1: 0.045488, loss_fp: 0.002975, loss_freq: 0.055909
[06:20:09.609] iteration 21597: loss: 0.080863, loss_s1: 0.092459, loss_fp: 0.002195, loss_freq: 0.029438
[06:20:10.227] iteration 21598: loss: 0.047453, loss_s1: 0.045648, loss_fp: 0.001845, loss_freq: 0.013624
[06:20:10.836] iteration 21599: loss: 0.036488, loss_s1: 0.024292, loss_fp: 0.003143, loss_freq: 0.015374
[06:20:11.439] iteration 21600: loss: 0.099290, loss_s1: 0.121414, loss_fp: 0.011349, loss_freq: 0.021127
[06:20:14.947] iteration 21600 : mean_dice : 0.728586
[06:20:15.607] iteration 21601: loss: 0.064768, loss_s1: 0.039500, loss_fp: 0.001620, loss_freq: 0.050049
[06:20:16.212] iteration 21602: loss: 0.055894, loss_s1: 0.019284, loss_fp: 0.004721, loss_freq: 0.046293
[06:20:16.820] iteration 21603: loss: 0.070459, loss_s1: 0.043064, loss_fp: 0.016393, loss_freq: 0.045091
[06:20:17.425] iteration 21604: loss: 0.053634, loss_s1: 0.049146, loss_fp: 0.009866, loss_freq: 0.025607
[06:20:18.030] iteration 21605: loss: 0.050774, loss_s1: 0.049281, loss_fp: 0.001026, loss_freq: 0.013614
[06:20:18.639] iteration 21606: loss: 0.042367, loss_s1: 0.023440, loss_fp: 0.003137, loss_freq: 0.017083
[06:20:19.256] iteration 21607: loss: 0.067072, loss_s1: 0.073584, loss_fp: 0.002565, loss_freq: 0.031520
[06:20:19.863] iteration 21608: loss: 0.035341, loss_s1: 0.019867, loss_fp: 0.001754, loss_freq: 0.013618
[06:20:20.466] iteration 21609: loss: 0.062027, loss_s1: 0.058375, loss_fp: 0.004156, loss_freq: 0.026507
[06:20:21.067] iteration 21610: loss: 0.068592, loss_s1: 0.079043, loss_fp: 0.001385, loss_freq: 0.021351
[06:20:21.678] iteration 21611: loss: 0.048264, loss_s1: 0.017871, loss_fp: 0.009055, loss_freq: 0.033861
[06:20:22.282] iteration 21612: loss: 0.050286, loss_s1: 0.038778, loss_fp: 0.003658, loss_freq: 0.034587
[06:20:22.947] iteration 21613: loss: 0.046102, loss_s1: 0.033220, loss_fp: 0.002865, loss_freq: 0.020022
[06:20:23.609] iteration 21614: loss: 0.056489, loss_s1: 0.060748, loss_fp: 0.002914, loss_freq: 0.021755
[06:20:24.344] iteration 21615: loss: 0.062185, loss_s1: 0.046592, loss_fp: 0.007379, loss_freq: 0.037202
[06:20:25.146] iteration 21616: loss: 0.059200, loss_s1: 0.051923, loss_fp: 0.002465, loss_freq: 0.037922
[06:20:25.907] iteration 21617: loss: 0.044910, loss_s1: 0.027231, loss_fp: 0.001521, loss_freq: 0.022304
[06:20:26.514] iteration 21618: loss: 0.059141, loss_s1: 0.042002, loss_fp: 0.004562, loss_freq: 0.029880
[06:20:27.124] iteration 21619: loss: 0.046550, loss_s1: 0.021693, loss_fp: 0.003259, loss_freq: 0.035691
[06:20:27.733] iteration 21620: loss: 0.073455, loss_s1: 0.077261, loss_fp: 0.001881, loss_freq: 0.031231
[06:20:28.340] iteration 21621: loss: 0.062886, loss_s1: 0.044078, loss_fp: 0.002590, loss_freq: 0.051380
[06:20:28.946] iteration 21622: loss: 0.077836, loss_s1: 0.073883, loss_fp: 0.002229, loss_freq: 0.035707
[06:20:29.563] iteration 21623: loss: 0.062303, loss_s1: 0.046250, loss_fp: 0.006423, loss_freq: 0.046873
[06:20:30.171] iteration 21624: loss: 0.031828, loss_s1: 0.025350, loss_fp: 0.000958, loss_freq: 0.009390
[06:20:30.776] iteration 21625: loss: 0.047161, loss_s1: 0.031385, loss_fp: 0.003674, loss_freq: 0.036877
[06:20:31.383] iteration 21626: loss: 0.045290, loss_s1: 0.032466, loss_fp: 0.003505, loss_freq: 0.016062
[06:20:31.990] iteration 21627: loss: 0.049319, loss_s1: 0.030960, loss_fp: 0.006332, loss_freq: 0.028212
[06:20:32.596] iteration 21628: loss: 0.032735, loss_s1: 0.022749, loss_fp: 0.004687, loss_freq: 0.008086
[06:20:33.202] iteration 21629: loss: 0.079085, loss_s1: 0.083086, loss_fp: 0.002128, loss_freq: 0.027427
[06:20:33.825] iteration 21630: loss: 0.067634, loss_s1: 0.058696, loss_fp: 0.010463, loss_freq: 0.036696
[06:20:34.445] iteration 21631: loss: 0.063749, loss_s1: 0.066183, loss_fp: 0.000932, loss_freq: 0.029100
[06:20:35.059] iteration 21632: loss: 0.076185, loss_s1: 0.069946, loss_fp: 0.003124, loss_freq: 0.045864
[06:20:35.671] iteration 21633: loss: 0.124421, loss_s1: 0.167728, loss_fp: 0.003821, loss_freq: 0.049735
[06:20:36.283] iteration 21634: loss: 0.083746, loss_s1: 0.088772, loss_fp: 0.012632, loss_freq: 0.038217
[06:20:36.884] iteration 21635: loss: 0.058243, loss_s1: 0.036305, loss_fp: 0.002113, loss_freq: 0.035433
[06:20:37.494] iteration 21636: loss: 0.064988, loss_s1: 0.064454, loss_fp: 0.006258, loss_freq: 0.030917
[06:20:38.108] iteration 21637: loss: 0.067858, loss_s1: 0.054614, loss_fp: 0.006353, loss_freq: 0.033834
[06:20:38.716] iteration 21638: loss: 0.046942, loss_s1: 0.041244, loss_fp: 0.001769, loss_freq: 0.024861
[06:20:39.389] iteration 21639: loss: 0.041222, loss_s1: 0.036029, loss_fp: 0.002550, loss_freq: 0.012593
[06:20:40.041] iteration 21640: loss: 0.051390, loss_s1: 0.051720, loss_fp: 0.001389, loss_freq: 0.009850
[06:20:40.654] iteration 21641: loss: 0.048996, loss_s1: 0.018970, loss_fp: 0.003144, loss_freq: 0.034789
[06:20:41.263] iteration 21642: loss: 0.050576, loss_s1: 0.044456, loss_fp: 0.002300, loss_freq: 0.024630
[06:20:41.871] iteration 21643: loss: 0.045948, loss_s1: 0.011600, loss_fp: 0.011043, loss_freq: 0.029186
[06:20:42.476] iteration 21644: loss: 0.069432, loss_s1: 0.074176, loss_fp: 0.002814, loss_freq: 0.033415
[06:20:43.086] iteration 21645: loss: 0.069569, loss_s1: 0.033453, loss_fp: 0.013026, loss_freq: 0.056296
[06:20:43.700] iteration 21646: loss: 0.033795, loss_s1: 0.011337, loss_fp: 0.001451, loss_freq: 0.019969
[06:20:44.310] iteration 21647: loss: 0.059858, loss_s1: 0.053195, loss_fp: 0.003647, loss_freq: 0.039284
[06:20:44.940] iteration 21648: loss: 0.032423, loss_s1: 0.013483, loss_fp: 0.000821, loss_freq: 0.014513
[06:20:45.545] iteration 21649: loss: 0.055262, loss_s1: 0.033069, loss_fp: 0.002525, loss_freq: 0.044653
[06:20:46.158] iteration 21650: loss: 0.041838, loss_s1: 0.016226, loss_fp: 0.002529, loss_freq: 0.034291
[06:20:46.771] iteration 21651: loss: 0.027263, loss_s1: 0.019331, loss_fp: 0.003192, loss_freq: 0.006220
[06:20:47.394] iteration 21652: loss: 0.060751, loss_s1: 0.065595, loss_fp: 0.001220, loss_freq: 0.020247
[06:20:48.005] iteration 21653: loss: 0.042333, loss_s1: 0.024200, loss_fp: 0.003024, loss_freq: 0.019720
[06:20:48.613] iteration 21654: loss: 0.050810, loss_s1: 0.045214, loss_fp: 0.005526, loss_freq: 0.026580
[06:20:49.253] iteration 21655: loss: 0.047150, loss_s1: 0.038165, loss_fp: 0.003979, loss_freq: 0.011247
[06:20:49.861] iteration 21656: loss: 0.048119, loss_s1: 0.038612, loss_fp: 0.002163, loss_freq: 0.030993
[06:20:50.465] iteration 21657: loss: 0.066072, loss_s1: 0.065908, loss_fp: 0.002548, loss_freq: 0.029104
[06:20:51.083] iteration 21658: loss: 0.100099, loss_s1: 0.088307, loss_fp: 0.007137, loss_freq: 0.075579
[06:20:51.690] iteration 21659: loss: 0.062642, loss_s1: 0.066009, loss_fp: 0.009751, loss_freq: 0.021028
[06:20:52.292] iteration 21660: loss: 0.047194, loss_s1: 0.037769, loss_fp: 0.004014, loss_freq: 0.027870
[06:20:52.899] iteration 21661: loss: 0.056957, loss_s1: 0.037221, loss_fp: 0.005991, loss_freq: 0.030781
[06:20:53.510] iteration 21662: loss: 0.061431, loss_s1: 0.053371, loss_fp: 0.003880, loss_freq: 0.031736
[06:20:54.120] iteration 21663: loss: 0.068405, loss_s1: 0.065025, loss_fp: 0.008403, loss_freq: 0.038587
[06:20:54.724] iteration 21664: loss: 0.065999, loss_s1: 0.081367, loss_fp: 0.002531, loss_freq: 0.013747
[06:20:55.347] iteration 21665: loss: 0.065508, loss_s1: 0.059002, loss_fp: 0.003316, loss_freq: 0.040875
[06:20:55.950] iteration 21666: loss: 0.087388, loss_s1: 0.089747, loss_fp: 0.015477, loss_freq: 0.033612
[06:20:56.608] iteration 21667: loss: 0.045235, loss_s1: 0.023850, loss_fp: 0.008113, loss_freq: 0.024921
[06:20:57.258] iteration 21668: loss: 0.079920, loss_s1: 0.077441, loss_fp: 0.005792, loss_freq: 0.040652
[06:20:57.869] iteration 21669: loss: 0.047655, loss_s1: 0.032380, loss_fp: 0.003784, loss_freq: 0.039004
[06:20:58.474] iteration 21670: loss: 0.049790, loss_s1: 0.038434, loss_fp: 0.002414, loss_freq: 0.015743
[06:20:59.081] iteration 21671: loss: 0.046546, loss_s1: 0.030543, loss_fp: 0.002325, loss_freq: 0.026561
[06:20:59.760] iteration 21672: loss: 0.050074, loss_s1: 0.036519, loss_fp: 0.007514, loss_freq: 0.022555
[06:21:00.435] iteration 21673: loss: 0.077050, loss_s1: 0.077760, loss_fp: 0.003376, loss_freq: 0.036008
[06:21:01.051] iteration 21674: loss: 0.031919, loss_s1: 0.014272, loss_fp: 0.002319, loss_freq: 0.010672
[06:21:01.660] iteration 21675: loss: 0.046470, loss_s1: 0.026602, loss_fp: 0.003440, loss_freq: 0.015628
[06:21:02.267] iteration 21676: loss: 0.052581, loss_s1: 0.039178, loss_fp: 0.006122, loss_freq: 0.023661
[06:21:02.914] iteration 21677: loss: 0.056655, loss_s1: 0.053647, loss_fp: 0.006201, loss_freq: 0.030034
[06:21:03.522] iteration 21678: loss: 0.078662, loss_s1: 0.074872, loss_fp: 0.004363, loss_freq: 0.032525
[06:21:04.127] iteration 21679: loss: 0.073393, loss_s1: 0.063276, loss_fp: 0.008786, loss_freq: 0.041485
[06:21:04.732] iteration 21680: loss: 0.039987, loss_s1: 0.024217, loss_fp: 0.007221, loss_freq: 0.013469
[06:21:05.337] iteration 21681: loss: 0.070286, loss_s1: 0.057125, loss_fp: 0.004163, loss_freq: 0.036646
[06:21:05.954] iteration 21682: loss: 0.074341, loss_s1: 0.073339, loss_fp: 0.005528, loss_freq: 0.047896
[06:21:06.563] iteration 21683: loss: 0.067631, loss_s1: 0.066567, loss_fp: 0.006393, loss_freq: 0.024850
[06:21:07.166] iteration 21684: loss: 0.039723, loss_s1: 0.035253, loss_fp: 0.002371, loss_freq: 0.015838
[06:21:07.777] iteration 21685: loss: 0.058195, loss_s1: 0.046471, loss_fp: 0.003956, loss_freq: 0.025015
[06:21:08.385] iteration 21686: loss: 0.050393, loss_s1: 0.045342, loss_fp: 0.004196, loss_freq: 0.028611
[06:21:08.990] iteration 21687: loss: 0.062127, loss_s1: 0.053796, loss_fp: 0.002692, loss_freq: 0.031967
[06:21:09.591] iteration 21688: loss: 0.080929, loss_s1: 0.049908, loss_fp: 0.001095, loss_freq: 0.065902
[06:21:10.195] iteration 21689: loss: 0.049657, loss_s1: 0.031482, loss_fp: 0.001155, loss_freq: 0.031434
[06:21:10.851] iteration 21690: loss: 0.042087, loss_s1: 0.026416, loss_fp: 0.000907, loss_freq: 0.014119
[06:21:11.526] iteration 21691: loss: 0.045267, loss_s1: 0.035735, loss_fp: 0.002296, loss_freq: 0.027280
[06:21:12.201] iteration 21692: loss: 0.056267, loss_s1: 0.030044, loss_fp: 0.008813, loss_freq: 0.024953
[06:21:12.822] iteration 21693: loss: 0.042803, loss_s1: 0.031672, loss_fp: 0.007605, loss_freq: 0.017461
[06:21:13.440] iteration 21694: loss: 0.039336, loss_s1: 0.028149, loss_fp: 0.002276, loss_freq: 0.020515
[06:21:14.056] iteration 21695: loss: 0.065504, loss_s1: 0.064243, loss_fp: 0.002867, loss_freq: 0.041416
[06:21:14.662] iteration 21696: loss: 0.054647, loss_s1: 0.037486, loss_fp: 0.001081, loss_freq: 0.034258
[06:21:15.272] iteration 21697: loss: 0.052093, loss_s1: 0.051763, loss_fp: 0.004530, loss_freq: 0.015598
[06:21:15.938] iteration 21698: loss: 0.048694, loss_s1: 0.049445, loss_fp: 0.004287, loss_freq: 0.015356
[06:21:16.605] iteration 21699: loss: 0.051911, loss_s1: 0.022108, loss_fp: 0.007766, loss_freq: 0.039502
[06:21:17.269] iteration 21700: loss: 0.053093, loss_s1: 0.036268, loss_fp: 0.003928, loss_freq: 0.037960
[06:21:17.964] iteration 21701: loss: 0.072757, loss_s1: 0.060922, loss_fp: 0.017921, loss_freq: 0.027359
[06:21:18.622] iteration 21702: loss: 0.056859, loss_s1: 0.058676, loss_fp: 0.001651, loss_freq: 0.023619
[06:21:19.237] iteration 21703: loss: 0.055280, loss_s1: 0.050861, loss_fp: 0.003472, loss_freq: 0.027790
[06:21:19.854] iteration 21704: loss: 0.038318, loss_s1: 0.037362, loss_fp: 0.003601, loss_freq: 0.010209
[06:21:20.470] iteration 21705: loss: 0.052300, loss_s1: 0.033169, loss_fp: 0.005739, loss_freq: 0.025646
[06:21:21.079] iteration 21706: loss: 0.056987, loss_s1: 0.028928, loss_fp: 0.005159, loss_freq: 0.043166
[06:21:21.696] iteration 21707: loss: 0.048183, loss_s1: 0.034537, loss_fp: 0.003200, loss_freq: 0.022145
[06:21:22.309] iteration 21708: loss: 0.057364, loss_s1: 0.053692, loss_fp: 0.005957, loss_freq: 0.021838
[06:21:22.924] iteration 21709: loss: 0.111780, loss_s1: 0.101797, loss_fp: 0.005970, loss_freq: 0.080750
[06:21:23.534] iteration 21710: loss: 0.040513, loss_s1: 0.021314, loss_fp: 0.001241, loss_freq: 0.003651
[06:21:24.143] iteration 21711: loss: 0.053576, loss_s1: 0.051279, loss_fp: 0.004800, loss_freq: 0.009239
[06:21:24.758] iteration 21712: loss: 0.049029, loss_s1: 0.031660, loss_fp: 0.001997, loss_freq: 0.044884
[06:21:25.371] iteration 21713: loss: 0.089767, loss_s1: 0.104602, loss_fp: 0.008510, loss_freq: 0.038939
[06:21:25.978] iteration 21714: loss: 0.060743, loss_s1: 0.047645, loss_fp: 0.006572, loss_freq: 0.036812
[06:21:26.588] iteration 21715: loss: 0.076057, loss_s1: 0.059796, loss_fp: 0.005651, loss_freq: 0.049122
[06:21:27.201] iteration 21716: loss: 0.059334, loss_s1: 0.054774, loss_fp: 0.004399, loss_freq: 0.025528
[06:21:27.817] iteration 21717: loss: 0.048599, loss_s1: 0.023948, loss_fp: 0.004993, loss_freq: 0.037489
[06:21:28.428] iteration 21718: loss: 0.039957, loss_s1: 0.026037, loss_fp: 0.005801, loss_freq: 0.009498
[06:21:29.037] iteration 21719: loss: 0.043595, loss_s1: 0.026947, loss_fp: 0.005335, loss_freq: 0.023907
[06:21:29.644] iteration 21720: loss: 0.076268, loss_s1: 0.070529, loss_fp: 0.010078, loss_freq: 0.038130
[06:21:30.247] iteration 21721: loss: 0.031772, loss_s1: 0.027500, loss_fp: 0.001537, loss_freq: 0.006135
[06:21:30.850] iteration 21722: loss: 0.056077, loss_s1: 0.030591, loss_fp: 0.001953, loss_freq: 0.027019
[06:21:31.459] iteration 21723: loss: 0.077389, loss_s1: 0.074675, loss_fp: 0.005411, loss_freq: 0.036956
[06:21:32.065] iteration 21724: loss: 0.072249, loss_s1: 0.070857, loss_fp: 0.003877, loss_freq: 0.038077
[06:21:32.673] iteration 21725: loss: 0.049173, loss_s1: 0.036699, loss_fp: 0.001749, loss_freq: 0.028188
[06:21:33.282] iteration 21726: loss: 0.043950, loss_s1: 0.047634, loss_fp: 0.003771, loss_freq: 0.008949
[06:21:33.888] iteration 21727: loss: 0.091871, loss_s1: 0.114579, loss_fp: 0.005384, loss_freq: 0.010844
[06:21:34.491] iteration 21728: loss: 0.089727, loss_s1: 0.058465, loss_fp: 0.018422, loss_freq: 0.073352
[06:21:35.099] iteration 21729: loss: 0.089616, loss_s1: 0.086110, loss_fp: 0.014140, loss_freq: 0.046043
[06:21:35.705] iteration 21730: loss: 0.063605, loss_s1: 0.047849, loss_fp: 0.000713, loss_freq: 0.052803
[06:21:36.307] iteration 21731: loss: 0.068040, loss_s1: 0.067627, loss_fp: 0.002392, loss_freq: 0.029081
[06:21:36.916] iteration 21732: loss: 0.060423, loss_s1: 0.051938, loss_fp: 0.005773, loss_freq: 0.032197
[06:21:37.531] iteration 21733: loss: 0.061168, loss_s1: 0.051342, loss_fp: 0.005259, loss_freq: 0.032701
[06:21:38.144] iteration 21734: loss: 0.063884, loss_s1: 0.067662, loss_fp: 0.008368, loss_freq: 0.015117
[06:21:38.755] iteration 21735: loss: 0.066171, loss_s1: 0.086190, loss_fp: 0.003467, loss_freq: 0.015603
[06:21:39.364] iteration 21736: loss: 0.035939, loss_s1: 0.016636, loss_fp: 0.005408, loss_freq: 0.015709
[06:21:39.971] iteration 21737: loss: 0.053015, loss_s1: 0.032229, loss_fp: 0.006836, loss_freq: 0.025901
[06:21:40.615] iteration 21738: loss: 0.084149, loss_s1: 0.107674, loss_fp: 0.004082, loss_freq: 0.028656
[06:21:41.276] iteration 21739: loss: 0.062660, loss_s1: 0.067899, loss_fp: 0.004150, loss_freq: 0.031876
[06:21:41.934] iteration 21740: loss: 0.071524, loss_s1: 0.051932, loss_fp: 0.014480, loss_freq: 0.033841
[06:21:42.590] iteration 21741: loss: 0.078857, loss_s1: 0.070175, loss_fp: 0.009685, loss_freq: 0.042978
[06:21:43.235] iteration 21742: loss: 0.081206, loss_s1: 0.089615, loss_fp: 0.006829, loss_freq: 0.030788
[06:21:43.842] iteration 21743: loss: 0.083992, loss_s1: 0.100281, loss_fp: 0.002985, loss_freq: 0.032143
[06:21:44.452] iteration 21744: loss: 0.063166, loss_s1: 0.035760, loss_fp: 0.005691, loss_freq: 0.048832
[06:21:45.102] iteration 21745: loss: 0.069134, loss_s1: 0.049951, loss_fp: 0.010487, loss_freq: 0.046377
[06:21:45.708] iteration 21746: loss: 0.045841, loss_s1: 0.028704, loss_fp: 0.001716, loss_freq: 0.032847
[06:21:46.317] iteration 21747: loss: 0.045015, loss_s1: 0.033189, loss_fp: 0.007718, loss_freq: 0.022960
[06:21:46.924] iteration 21748: loss: 0.083624, loss_s1: 0.046500, loss_fp: 0.012614, loss_freq: 0.066382
[06:21:47.531] iteration 21749: loss: 0.069220, loss_s1: 0.073842, loss_fp: 0.003271, loss_freq: 0.028681
[06:21:48.142] iteration 21750: loss: 0.077055, loss_s1: 0.066671, loss_fp: 0.007247, loss_freq: 0.039523
[06:21:48.747] iteration 21751: loss: 0.045412, loss_s1: 0.046846, loss_fp: 0.006414, loss_freq: 0.005257
[06:21:49.354] iteration 21752: loss: 0.050185, loss_s1: 0.043627, loss_fp: 0.006290, loss_freq: 0.025512
[06:21:49.957] iteration 21753: loss: 0.047117, loss_s1: 0.018886, loss_fp: 0.004087, loss_freq: 0.019887
[06:21:50.563] iteration 21754: loss: 0.053761, loss_s1: 0.055739, loss_fp: 0.002621, loss_freq: 0.021410
[06:21:51.175] iteration 21755: loss: 0.034682, loss_s1: 0.020743, loss_fp: 0.001444, loss_freq: 0.010406
[06:21:51.789] iteration 21756: loss: 0.072688, loss_s1: 0.089167, loss_fp: 0.009227, loss_freq: 0.024483
[06:21:52.396] iteration 21757: loss: 0.055717, loss_s1: 0.041248, loss_fp: 0.004588, loss_freq: 0.020383
[06:21:53.007] iteration 21758: loss: 0.066518, loss_s1: 0.038573, loss_fp: 0.019381, loss_freq: 0.042905
[06:21:53.609] iteration 21759: loss: 0.106931, loss_s1: 0.118016, loss_fp: 0.012174, loss_freq: 0.054225
[06:21:54.215] iteration 21760: loss: 0.078940, loss_s1: 0.070989, loss_fp: 0.031484, loss_freq: 0.019964
[06:21:55.221] iteration 21761: loss: 0.084432, loss_s1: 0.051930, loss_fp: 0.005074, loss_freq: 0.074707
[06:21:55.876] iteration 21762: loss: 0.062028, loss_s1: 0.060434, loss_fp: 0.006626, loss_freq: 0.021965
[06:21:56.538] iteration 21763: loss: 0.075310, loss_s1: 0.085736, loss_fp: 0.005362, loss_freq: 0.030638
[06:21:57.260] iteration 21764: loss: 0.036303, loss_s1: 0.027662, loss_fp: 0.001612, loss_freq: 0.008277
[06:21:57.918] iteration 21765: loss: 0.043031, loss_s1: 0.025707, loss_fp: 0.003758, loss_freq: 0.025072
[06:21:58.580] iteration 21766: loss: 0.046615, loss_s1: 0.021527, loss_fp: 0.004623, loss_freq: 0.032896
[06:21:59.230] iteration 21767: loss: 0.066049, loss_s1: 0.058439, loss_fp: 0.002226, loss_freq: 0.035882
[06:21:59.880] iteration 21768: loss: 0.039764, loss_s1: 0.019394, loss_fp: 0.006374, loss_freq: 0.029576
[06:22:00.537] iteration 21769: loss: 0.048231, loss_s1: 0.051244, loss_fp: 0.002158, loss_freq: 0.014753
[06:22:01.194] iteration 21770: loss: 0.058817, loss_s1: 0.033685, loss_fp: 0.002251, loss_freq: 0.029219
[06:22:01.852] iteration 21771: loss: 0.065079, loss_s1: 0.040068, loss_fp: 0.004330, loss_freq: 0.042749
[06:22:02.504] iteration 21772: loss: 0.119646, loss_s1: 0.084769, loss_fp: 0.011528, loss_freq: 0.109323
[06:22:03.154] iteration 21773: loss: 0.066597, loss_s1: 0.072959, loss_fp: 0.001370, loss_freq: 0.026940
[06:22:03.773] iteration 21774: loss: 0.054596, loss_s1: 0.043969, loss_fp: 0.002119, loss_freq: 0.035813
[06:22:04.385] iteration 21775: loss: 0.060108, loss_s1: 0.068664, loss_fp: 0.006281, loss_freq: 0.009377
[06:22:04.998] iteration 21776: loss: 0.072143, loss_s1: 0.046352, loss_fp: 0.011516, loss_freq: 0.049317
[06:22:05.604] iteration 21777: loss: 0.131447, loss_s1: 0.120420, loss_fp: 0.008503, loss_freq: 0.114184
[06:22:06.213] iteration 21778: loss: 0.034511, loss_s1: 0.017309, loss_fp: 0.001083, loss_freq: 0.011406
[06:22:06.851] iteration 21779: loss: 0.090215, loss_s1: 0.107122, loss_fp: 0.011685, loss_freq: 0.030656
[06:22:07.506] iteration 21780: loss: 0.057027, loss_s1: 0.067432, loss_fp: 0.002057, loss_freq: 0.006894
[06:22:08.161] iteration 21781: loss: 0.052773, loss_s1: 0.039592, loss_fp: 0.004604, loss_freq: 0.029667
[06:22:08.824] iteration 21782: loss: 0.047999, loss_s1: 0.034824, loss_fp: 0.005108, loss_freq: 0.028655
[06:22:09.479] iteration 21783: loss: 0.055159, loss_s1: 0.030773, loss_fp: 0.003579, loss_freq: 0.032712
[06:22:10.131] iteration 21784: loss: 0.057859, loss_s1: 0.052022, loss_fp: 0.002785, loss_freq: 0.023465
[06:22:10.742] iteration 21785: loss: 0.090556, loss_s1: 0.097489, loss_fp: 0.003717, loss_freq: 0.038407
[06:22:11.353] iteration 21786: loss: 0.053257, loss_s1: 0.044037, loss_fp: 0.001397, loss_freq: 0.039704
[06:22:11.962] iteration 21787: loss: 0.034882, loss_s1: 0.015723, loss_fp: 0.002201, loss_freq: 0.005492
[06:22:12.563] iteration 21788: loss: 0.103290, loss_s1: 0.128530, loss_fp: 0.002538, loss_freq: 0.038934
[06:22:13.167] iteration 21789: loss: 0.077252, loss_s1: 0.071175, loss_fp: 0.001624, loss_freq: 0.034456
[06:22:13.775] iteration 21790: loss: 0.095996, loss_s1: 0.096473, loss_fp: 0.008655, loss_freq: 0.051065
[06:22:14.385] iteration 21791: loss: 0.068720, loss_s1: 0.039626, loss_fp: 0.004448, loss_freq: 0.066577
[06:22:14.990] iteration 21792: loss: 0.079820, loss_s1: 0.075818, loss_fp: 0.001933, loss_freq: 0.049162
[06:22:15.592] iteration 21793: loss: 0.051040, loss_s1: 0.040882, loss_fp: 0.003079, loss_freq: 0.028855
[06:22:16.196] iteration 21794: loss: 0.043706, loss_s1: 0.032989, loss_fp: 0.001127, loss_freq: 0.025816
[06:22:16.806] iteration 21795: loss: 0.073101, loss_s1: 0.066933, loss_fp: 0.004249, loss_freq: 0.048816
[06:22:17.410] iteration 21796: loss: 0.048883, loss_s1: 0.036858, loss_fp: 0.004302, loss_freq: 0.016216
[06:22:18.015] iteration 21797: loss: 0.059073, loss_s1: 0.040554, loss_fp: 0.003110, loss_freq: 0.030312
[06:22:18.619] iteration 21798: loss: 0.053435, loss_s1: 0.054505, loss_fp: 0.003150, loss_freq: 0.022041
[06:22:19.229] iteration 21799: loss: 0.110702, loss_s1: 0.107194, loss_fp: 0.012587, loss_freq: 0.069630
[06:22:19.836] iteration 21800: loss: 0.063628, loss_s1: 0.064738, loss_fp: 0.002483, loss_freq: 0.029540
[06:22:22.992] iteration 21800 : mean_dice : 0.733883
[06:22:23.623] iteration 21801: loss: 0.074585, loss_s1: 0.089352, loss_fp: 0.003683, loss_freq: 0.024638
[06:22:24.228] iteration 21802: loss: 0.042004, loss_s1: 0.031730, loss_fp: 0.001142, loss_freq: 0.021909
[06:22:24.831] iteration 21803: loss: 0.108409, loss_s1: 0.161336, loss_fp: 0.004690, loss_freq: 0.025595
[06:22:25.437] iteration 21804: loss: 0.081229, loss_s1: 0.087165, loss_fp: 0.003425, loss_freq: 0.043175
[06:22:26.040] iteration 21805: loss: 0.062334, loss_s1: 0.049948, loss_fp: 0.002537, loss_freq: 0.019801
[06:22:26.640] iteration 21806: loss: 0.057498, loss_s1: 0.039634, loss_fp: 0.010437, loss_freq: 0.019046
[06:22:27.239] iteration 21807: loss: 0.063017, loss_s1: 0.050904, loss_fp: 0.001890, loss_freq: 0.026422
[06:22:27.838] iteration 21808: loss: 0.045700, loss_s1: 0.038769, loss_fp: 0.002296, loss_freq: 0.016682
[06:22:28.438] iteration 21809: loss: 0.047749, loss_s1: 0.046925, loss_fp: 0.002460, loss_freq: 0.012730
[06:22:29.133] iteration 21810: loss: 0.054915, loss_s1: 0.036146, loss_fp: 0.001428, loss_freq: 0.033184
[06:22:29.862] iteration 21811: loss: 0.066249, loss_s1: 0.061979, loss_fp: 0.004912, loss_freq: 0.028575
[06:22:30.485] iteration 21812: loss: 0.047693, loss_s1: 0.046724, loss_fp: 0.004303, loss_freq: 0.024322
[06:22:31.111] iteration 21813: loss: 0.051223, loss_s1: 0.043816, loss_fp: 0.001145, loss_freq: 0.016765
[06:22:31.721] iteration 21814: loss: 0.080733, loss_s1: 0.080341, loss_fp: 0.018007, loss_freq: 0.032805
[06:22:32.424] iteration 21815: loss: 0.050114, loss_s1: 0.028693, loss_fp: 0.002662, loss_freq: 0.036186
[06:22:33.071] iteration 21816: loss: 0.047542, loss_s1: 0.030081, loss_fp: 0.002427, loss_freq: 0.027661
[06:22:33.707] iteration 21817: loss: 0.051486, loss_s1: 0.052354, loss_fp: 0.004339, loss_freq: 0.014283
[06:22:34.314] iteration 21818: loss: 0.034638, loss_s1: 0.017639, loss_fp: 0.003047, loss_freq: 0.013112
[06:22:34.918] iteration 21819: loss: 0.031419, loss_s1: 0.016245, loss_fp: 0.002090, loss_freq: 0.020490
[06:22:35.523] iteration 21820: loss: 0.037033, loss_s1: 0.020728, loss_fp: 0.003633, loss_freq: 0.021269
[06:22:36.124] iteration 21821: loss: 0.028658, loss_s1: 0.018926, loss_fp: 0.003256, loss_freq: 0.011483
[06:22:36.731] iteration 21822: loss: 0.052224, loss_s1: 0.016804, loss_fp: 0.002024, loss_freq: 0.035932
[06:22:37.336] iteration 21823: loss: 0.060094, loss_s1: 0.053682, loss_fp: 0.006693, loss_freq: 0.022874
[06:22:37.965] iteration 21824: loss: 0.035006, loss_s1: 0.021425, loss_fp: 0.001451, loss_freq: 0.019174
[06:22:38.604] iteration 21825: loss: 0.033354, loss_s1: 0.019693, loss_fp: 0.003225, loss_freq: 0.010164
[06:22:39.231] iteration 21826: loss: 0.033429, loss_s1: 0.024698, loss_fp: 0.002275, loss_freq: 0.015394
[06:22:39.838] iteration 21827: loss: 0.038441, loss_s1: 0.026223, loss_fp: 0.001674, loss_freq: 0.010232
[06:22:40.451] iteration 21828: loss: 0.076864, loss_s1: 0.075493, loss_fp: 0.009640, loss_freq: 0.038264
[06:22:41.056] iteration 21829: loss: 0.047758, loss_s1: 0.025243, loss_fp: 0.003633, loss_freq: 0.030626
[06:22:41.664] iteration 21830: loss: 0.039338, loss_s1: 0.030362, loss_fp: 0.002295, loss_freq: 0.016004
[06:22:42.267] iteration 21831: loss: 0.077661, loss_s1: 0.071024, loss_fp: 0.004549, loss_freq: 0.043597
[06:22:42.872] iteration 21832: loss: 0.042252, loss_s1: 0.017231, loss_fp: 0.005008, loss_freq: 0.029887
[06:22:43.478] iteration 21833: loss: 0.054929, loss_s1: 0.043707, loss_fp: 0.004246, loss_freq: 0.030582
[06:22:44.081] iteration 21834: loss: 0.053074, loss_s1: 0.044955, loss_fp: 0.001244, loss_freq: 0.028747
[06:22:44.689] iteration 21835: loss: 0.055684, loss_s1: 0.044849, loss_fp: 0.002482, loss_freq: 0.031728
[06:22:45.296] iteration 21836: loss: 0.055278, loss_s1: 0.035292, loss_fp: 0.004444, loss_freq: 0.037885
[06:22:45.901] iteration 21837: loss: 0.040497, loss_s1: 0.024384, loss_fp: 0.003895, loss_freq: 0.023973
[06:22:46.514] iteration 21838: loss: 0.077088, loss_s1: 0.068638, loss_fp: 0.012492, loss_freq: 0.040975
[06:22:47.117] iteration 21839: loss: 0.057946, loss_s1: 0.044232, loss_fp: 0.004306, loss_freq: 0.043413
[06:22:47.721] iteration 21840: loss: 0.041112, loss_s1: 0.024693, loss_fp: 0.002574, loss_freq: 0.010086
[06:22:48.324] iteration 21841: loss: 0.060049, loss_s1: 0.039218, loss_fp: 0.003794, loss_freq: 0.036501
[06:22:48.925] iteration 21842: loss: 0.058667, loss_s1: 0.050397, loss_fp: 0.006036, loss_freq: 0.026390
[06:22:49.532] iteration 21843: loss: 0.068520, loss_s1: 0.034942, loss_fp: 0.001731, loss_freq: 0.024124
[06:22:50.138] iteration 21844: loss: 0.053181, loss_s1: 0.054270, loss_fp: 0.006881, loss_freq: 0.017231
[06:22:50.750] iteration 21845: loss: 0.052422, loss_s1: 0.034540, loss_fp: 0.005538, loss_freq: 0.026568
[06:22:51.357] iteration 21846: loss: 0.060698, loss_s1: 0.017245, loss_fp: 0.005334, loss_freq: 0.041021
[06:22:51.963] iteration 21847: loss: 0.043834, loss_s1: 0.053199, loss_fp: 0.001778, loss_freq: 0.011576
[06:22:52.565] iteration 21848: loss: 0.080418, loss_s1: 0.066110, loss_fp: 0.004834, loss_freq: 0.031764
[06:22:53.167] iteration 21849: loss: 0.075604, loss_s1: 0.061023, loss_fp: 0.010153, loss_freq: 0.049411
[06:22:53.773] iteration 21850: loss: 0.063086, loss_s1: 0.063934, loss_fp: 0.001599, loss_freq: 0.020140
[06:22:54.431] iteration 21851: loss: 0.065998, loss_s1: 0.066906, loss_fp: 0.005693, loss_freq: 0.026581
[06:22:55.092] iteration 21852: loss: 0.029696, loss_s1: 0.015173, loss_fp: 0.006104, loss_freq: 0.008100
[06:22:55.754] iteration 21853: loss: 0.092163, loss_s1: 0.090072, loss_fp: 0.006055, loss_freq: 0.049555
[06:22:56.410] iteration 21854: loss: 0.081727, loss_s1: 0.070317, loss_fp: 0.003413, loss_freq: 0.040634
[06:22:57.020] iteration 21855: loss: 0.059217, loss_s1: 0.050852, loss_fp: 0.002258, loss_freq: 0.030678
[06:22:57.625] iteration 21856: loss: 0.067713, loss_s1: 0.059553, loss_fp: 0.004952, loss_freq: 0.040484
[06:22:58.231] iteration 21857: loss: 0.078193, loss_s1: 0.078298, loss_fp: 0.003206, loss_freq: 0.034761
[06:22:58.839] iteration 21858: loss: 0.063470, loss_s1: 0.060488, loss_fp: 0.003579, loss_freq: 0.027045
[06:22:59.444] iteration 21859: loss: 0.039255, loss_s1: 0.020720, loss_fp: 0.003674, loss_freq: 0.024912
[06:23:00.067] iteration 21860: loss: 0.046585, loss_s1: 0.026365, loss_fp: 0.002305, loss_freq: 0.024988
[06:23:00.684] iteration 21861: loss: 0.034412, loss_s1: 0.026251, loss_fp: 0.003505, loss_freq: 0.014212
[06:23:01.319] iteration 21862: loss: 0.053560, loss_s1: 0.033715, loss_fp: 0.003360, loss_freq: 0.016711
[06:23:01.925] iteration 21863: loss: 0.034221, loss_s1: 0.015870, loss_fp: 0.007585, loss_freq: 0.014882
[06:23:02.594] iteration 21864: loss: 0.034566, loss_s1: 0.024556, loss_fp: 0.002965, loss_freq: 0.011879
[06:23:03.262] iteration 21865: loss: 0.027395, loss_s1: 0.012769, loss_fp: 0.005406, loss_freq: 0.013925
[06:23:03.920] iteration 21866: loss: 0.063572, loss_s1: 0.055169, loss_fp: 0.007133, loss_freq: 0.023811
[06:23:04.546] iteration 21867: loss: 0.053973, loss_s1: 0.051396, loss_fp: 0.009296, loss_freq: 0.010858
[06:23:05.150] iteration 21868: loss: 0.046956, loss_s1: 0.022815, loss_fp: 0.001798, loss_freq: 0.023865
[06:23:05.763] iteration 21869: loss: 0.049805, loss_s1: 0.031597, loss_fp: 0.004561, loss_freq: 0.031664
[06:23:06.367] iteration 21870: loss: 0.064720, loss_s1: 0.068940, loss_fp: 0.005030, loss_freq: 0.025957
[06:23:06.999] iteration 21871: loss: 0.048925, loss_s1: 0.029818, loss_fp: 0.009749, loss_freq: 0.015813
[06:23:07.603] iteration 21872: loss: 0.036783, loss_s1: 0.018194, loss_fp: 0.006407, loss_freq: 0.020769
[06:23:08.206] iteration 21873: loss: 0.057642, loss_s1: 0.032608, loss_fp: 0.004634, loss_freq: 0.038195
[06:23:08.813] iteration 21874: loss: 0.041299, loss_s1: 0.036159, loss_fp: 0.007170, loss_freq: 0.019877
[06:23:09.424] iteration 21875: loss: 0.074227, loss_s1: 0.027824, loss_fp: 0.002995, loss_freq: 0.069082
[06:23:10.031] iteration 21876: loss: 0.072879, loss_s1: 0.058409, loss_fp: 0.013765, loss_freq: 0.030337
[06:23:10.646] iteration 21877: loss: 0.070227, loss_s1: 0.061212, loss_fp: 0.004953, loss_freq: 0.040925
[06:23:11.257] iteration 21878: loss: 0.065593, loss_s1: 0.066335, loss_fp: 0.003304, loss_freq: 0.033996
[06:23:11.871] iteration 21879: loss: 0.083776, loss_s1: 0.043570, loss_fp: 0.007467, loss_freq: 0.072361
[06:23:12.480] iteration 21880: loss: 0.059096, loss_s1: 0.045644, loss_fp: 0.003414, loss_freq: 0.014388
[06:23:13.091] iteration 21881: loss: 0.041697, loss_s1: 0.039935, loss_fp: 0.000856, loss_freq: 0.005394
[06:23:13.706] iteration 21882: loss: 0.069822, loss_s1: 0.047715, loss_fp: 0.004495, loss_freq: 0.061984
[06:23:14.348] iteration 21883: loss: 0.053409, loss_s1: 0.018665, loss_fp: 0.007725, loss_freq: 0.035534
[06:23:14.964] iteration 21884: loss: 0.073159, loss_s1: 0.061514, loss_fp: 0.015097, loss_freq: 0.039734
[06:23:15.586] iteration 21885: loss: 0.093558, loss_s1: 0.051858, loss_fp: 0.008066, loss_freq: 0.081012
[06:23:16.196] iteration 21886: loss: 0.058168, loss_s1: 0.059088, loss_fp: 0.001841, loss_freq: 0.016078
[06:23:16.812] iteration 21887: loss: 0.053381, loss_s1: 0.053939, loss_fp: 0.005177, loss_freq: 0.029039
[06:23:17.425] iteration 21888: loss: 0.057172, loss_s1: 0.056453, loss_fp: 0.001495, loss_freq: 0.014610
[06:23:18.036] iteration 21889: loss: 0.063134, loss_s1: 0.040170, loss_fp: 0.002014, loss_freq: 0.057503
[06:23:18.649] iteration 21890: loss: 0.047319, loss_s1: 0.032021, loss_fp: 0.000711, loss_freq: 0.033012
[06:23:19.258] iteration 21891: loss: 0.053314, loss_s1: 0.030511, loss_fp: 0.005612, loss_freq: 0.046259
[06:23:19.864] iteration 21892: loss: 0.085396, loss_s1: 0.052046, loss_fp: 0.006719, loss_freq: 0.011880
[06:23:20.486] iteration 21893: loss: 0.073086, loss_s1: 0.064747, loss_fp: 0.004672, loss_freq: 0.032838
[06:23:21.092] iteration 21894: loss: 0.070905, loss_s1: 0.065912, loss_fp: 0.007814, loss_freq: 0.040207
[06:23:21.707] iteration 21895: loss: 0.033711, loss_s1: 0.022910, loss_fp: 0.001114, loss_freq: 0.009569
[06:23:22.319] iteration 21896: loss: 0.029494, loss_s1: 0.020610, loss_fp: 0.003522, loss_freq: 0.007364
[06:23:22.926] iteration 21897: loss: 0.061480, loss_s1: 0.057009, loss_fp: 0.002398, loss_freq: 0.023346
[06:23:23.537] iteration 21898: loss: 0.058737, loss_s1: 0.052073, loss_fp: 0.002901, loss_freq: 0.028349
[06:23:24.144] iteration 21899: loss: 0.085406, loss_s1: 0.081796, loss_fp: 0.005002, loss_freq: 0.042819
[06:23:24.749] iteration 21900: loss: 0.099288, loss_s1: 0.116013, loss_fp: 0.010023, loss_freq: 0.049016
[06:23:25.354] iteration 21901: loss: 0.067621, loss_s1: 0.077250, loss_fp: 0.003811, loss_freq: 0.022884
[06:23:25.955] iteration 21902: loss: 0.038662, loss_s1: 0.017289, loss_fp: 0.003995, loss_freq: 0.023627
[06:23:26.596] iteration 21903: loss: 0.041925, loss_s1: 0.031264, loss_fp: 0.001330, loss_freq: 0.019352
[06:23:27.271] iteration 21904: loss: 0.038991, loss_s1: 0.029616, loss_fp: 0.004396, loss_freq: 0.012371
[06:23:27.877] iteration 21905: loss: 0.034253, loss_s1: 0.025271, loss_fp: 0.003007, loss_freq: 0.007271
[06:23:28.489] iteration 21906: loss: 0.047516, loss_s1: 0.029465, loss_fp: 0.004939, loss_freq: 0.025766
[06:23:29.106] iteration 21907: loss: 0.046106, loss_s1: 0.031795, loss_fp: 0.008586, loss_freq: 0.015894
[06:23:29.715] iteration 21908: loss: 0.095484, loss_s1: 0.122664, loss_fp: 0.004264, loss_freq: 0.033681
[06:23:30.328] iteration 21909: loss: 0.046889, loss_s1: 0.031622, loss_fp: 0.001502, loss_freq: 0.034997
[06:23:30.934] iteration 21910: loss: 0.077836, loss_s1: 0.049645, loss_fp: 0.005073, loss_freq: 0.064120
[06:23:31.541] iteration 21911: loss: 0.067740, loss_s1: 0.057492, loss_fp: 0.011663, loss_freq: 0.036717
[06:23:32.144] iteration 21912: loss: 0.073413, loss_s1: 0.057078, loss_fp: 0.005466, loss_freq: 0.051372
[06:23:32.768] iteration 21913: loss: 0.052331, loss_s1: 0.053582, loss_fp: 0.002418, loss_freq: 0.014434
[06:23:33.385] iteration 21914: loss: 0.076798, loss_s1: 0.079441, loss_fp: 0.005617, loss_freq: 0.035798
[06:23:34.002] iteration 21915: loss: 0.043517, loss_s1: 0.029970, loss_fp: 0.004584, loss_freq: 0.018739
[06:23:34.607] iteration 21916: loss: 0.042675, loss_s1: 0.027411, loss_fp: 0.002068, loss_freq: 0.015556
[06:23:35.210] iteration 21917: loss: 0.038081, loss_s1: 0.023612, loss_fp: 0.007065, loss_freq: 0.024043
[06:23:35.830] iteration 21918: loss: 0.101414, loss_s1: 0.087604, loss_fp: 0.005702, loss_freq: 0.059936
[06:23:36.445] iteration 21919: loss: 0.072605, loss_s1: 0.050559, loss_fp: 0.004388, loss_freq: 0.057250
[06:23:37.059] iteration 21920: loss: 0.060132, loss_s1: 0.028010, loss_fp: 0.003750, loss_freq: 0.045714
[06:23:37.675] iteration 21921: loss: 0.040803, loss_s1: 0.029814, loss_fp: 0.004828, loss_freq: 0.009499
[06:23:38.288] iteration 21922: loss: 0.051799, loss_s1: 0.046911, loss_fp: 0.005664, loss_freq: 0.029753
[06:23:38.898] iteration 21923: loss: 0.041110, loss_s1: 0.026069, loss_fp: 0.002083, loss_freq: 0.013860
[06:23:39.508] iteration 21924: loss: 0.061981, loss_s1: 0.035900, loss_fp: 0.002617, loss_freq: 0.053033
[06:23:40.112] iteration 21925: loss: 0.046396, loss_s1: 0.043475, loss_fp: 0.001731, loss_freq: 0.013415
[06:23:40.721] iteration 21926: loss: 0.120282, loss_s1: 0.145908, loss_fp: 0.004260, loss_freq: 0.061740
[06:23:41.333] iteration 21927: loss: 0.061204, loss_s1: 0.048638, loss_fp: 0.003581, loss_freq: 0.031942
[06:23:41.937] iteration 21928: loss: 0.095338, loss_s1: 0.124992, loss_fp: 0.004949, loss_freq: 0.030186
[06:23:42.546] iteration 21929: loss: 0.070388, loss_s1: 0.066009, loss_fp: 0.004800, loss_freq: 0.041554
[06:23:43.152] iteration 21930: loss: 0.055221, loss_s1: 0.058875, loss_fp: 0.001278, loss_freq: 0.020278
[06:23:44.093] iteration 21931: loss: 0.080336, loss_s1: 0.069897, loss_fp: 0.001114, loss_freq: 0.050357
[06:23:44.691] iteration 21932: loss: 0.044447, loss_s1: 0.022336, loss_fp: 0.001649, loss_freq: 0.030180
[06:23:45.298] iteration 21933: loss: 0.084945, loss_s1: 0.113558, loss_fp: 0.002245, loss_freq: 0.026209
[06:23:45.897] iteration 21934: loss: 0.038877, loss_s1: 0.030104, loss_fp: 0.002119, loss_freq: 0.014982
[06:23:46.505] iteration 21935: loss: 0.054375, loss_s1: 0.048997, loss_fp: 0.002372, loss_freq: 0.024725
[06:23:47.112] iteration 21936: loss: 0.082617, loss_s1: 0.090744, loss_fp: 0.003154, loss_freq: 0.041409
[06:23:47.716] iteration 21937: loss: 0.081690, loss_s1: 0.079321, loss_fp: 0.001014, loss_freq: 0.043359
[06:23:48.333] iteration 21938: loss: 0.076361, loss_s1: 0.065406, loss_fp: 0.006121, loss_freq: 0.019807
[06:23:48.942] iteration 21939: loss: 0.054058, loss_s1: 0.037698, loss_fp: 0.004463, loss_freq: 0.042239
[06:23:49.551] iteration 21940: loss: 0.057037, loss_s1: 0.045216, loss_fp: 0.004046, loss_freq: 0.020486
[06:23:50.240] iteration 21941: loss: 0.073483, loss_s1: 0.079744, loss_fp: 0.005391, loss_freq: 0.025813
[06:23:50.919] iteration 21942: loss: 0.090309, loss_s1: 0.075239, loss_fp: 0.002756, loss_freq: 0.069772
[06:23:51.592] iteration 21943: loss: 0.068282, loss_s1: 0.045482, loss_fp: 0.011394, loss_freq: 0.043659
[06:23:52.230] iteration 21944: loss: 0.058108, loss_s1: 0.040148, loss_fp: 0.004767, loss_freq: 0.034479
[06:23:52.840] iteration 21945: loss: 0.064539, loss_s1: 0.071908, loss_fp: 0.004956, loss_freq: 0.013471
[06:23:53.451] iteration 21946: loss: 0.088631, loss_s1: 0.098888, loss_fp: 0.005871, loss_freq: 0.040941
[06:23:54.066] iteration 21947: loss: 0.086121, loss_s1: 0.103809, loss_fp: 0.005476, loss_freq: 0.043550
[06:23:54.671] iteration 21948: loss: 0.046215, loss_s1: 0.044038, loss_fp: 0.002548, loss_freq: 0.010727
[06:23:55.279] iteration 21949: loss: 0.078911, loss_s1: 0.081246, loss_fp: 0.010192, loss_freq: 0.031001
[06:23:55.911] iteration 21950: loss: 0.066778, loss_s1: 0.066469, loss_fp: 0.000864, loss_freq: 0.029383
[06:23:56.520] iteration 21951: loss: 0.038652, loss_s1: 0.022613, loss_fp: 0.002326, loss_freq: 0.020036
[06:23:57.127] iteration 21952: loss: 0.055902, loss_s1: 0.055097, loss_fp: 0.006904, loss_freq: 0.030966
[06:23:57.739] iteration 21953: loss: 0.078153, loss_s1: 0.070678, loss_fp: 0.002946, loss_freq: 0.038323
[06:23:58.347] iteration 21954: loss: 0.050961, loss_s1: 0.028343, loss_fp: 0.002284, loss_freq: 0.034627
[06:23:58.952] iteration 21955: loss: 0.056885, loss_s1: 0.046404, loss_fp: 0.002057, loss_freq: 0.021076
[06:23:59.556] iteration 21956: loss: 0.057172, loss_s1: 0.058747, loss_fp: 0.005031, loss_freq: 0.030256
[06:24:00.166] iteration 21957: loss: 0.050264, loss_s1: 0.037738, loss_fp: 0.002804, loss_freq: 0.014742
[06:24:00.775] iteration 21958: loss: 0.102980, loss_s1: 0.084884, loss_fp: 0.002549, loss_freq: 0.049372
[06:24:01.387] iteration 21959: loss: 0.059894, loss_s1: 0.037430, loss_fp: 0.003213, loss_freq: 0.038434
[06:24:01.996] iteration 21960: loss: 0.080775, loss_s1: 0.075099, loss_fp: 0.007537, loss_freq: 0.045927
[06:24:02.609] iteration 21961: loss: 0.074700, loss_s1: 0.043543, loss_fp: 0.001584, loss_freq: 0.074938
[06:24:03.215] iteration 21962: loss: 0.078341, loss_s1: 0.042381, loss_fp: 0.003783, loss_freq: 0.063471
[06:24:03.819] iteration 21963: loss: 0.084203, loss_s1: 0.061169, loss_fp: 0.011830, loss_freq: 0.061551
[06:24:04.435] iteration 21964: loss: 0.029130, loss_s1: 0.018181, loss_fp: 0.000828, loss_freq: 0.008385
[06:24:05.033] iteration 21965: loss: 0.046465, loss_s1: 0.034922, loss_fp: 0.001144, loss_freq: 0.028338
[06:24:05.638] iteration 21966: loss: 0.082762, loss_s1: 0.074114, loss_fp: 0.008733, loss_freq: 0.040382
[06:24:06.237] iteration 21967: loss: 0.080084, loss_s1: 0.084504, loss_fp: 0.003354, loss_freq: 0.038509
[06:24:06.847] iteration 21968: loss: 0.038178, loss_s1: 0.036555, loss_fp: 0.002529, loss_freq: 0.011513
[06:24:07.458] iteration 21969: loss: 0.064006, loss_s1: 0.030951, loss_fp: 0.007285, loss_freq: 0.059134
[06:24:08.153] iteration 21970: loss: 0.062631, loss_s1: 0.050976, loss_fp: 0.004501, loss_freq: 0.043928
[06:24:08.779] iteration 21971: loss: 0.087790, loss_s1: 0.080736, loss_fp: 0.002762, loss_freq: 0.055733
[06:24:09.385] iteration 21972: loss: 0.050626, loss_s1: 0.043645, loss_fp: 0.003522, loss_freq: 0.013219
[06:24:09.991] iteration 21973: loss: 0.093397, loss_s1: 0.109384, loss_fp: 0.004695, loss_freq: 0.043963
[06:24:10.604] iteration 21974: loss: 0.104514, loss_s1: 0.101203, loss_fp: 0.003988, loss_freq: 0.057921
[06:24:11.219] iteration 21975: loss: 0.052525, loss_s1: 0.039449, loss_fp: 0.000943, loss_freq: 0.024047
[06:24:11.830] iteration 21976: loss: 0.098914, loss_s1: 0.106137, loss_fp: 0.010055, loss_freq: 0.043727
[06:24:12.459] iteration 21977: loss: 0.066299, loss_s1: 0.040970, loss_fp: 0.005161, loss_freq: 0.039171
[06:24:13.066] iteration 21978: loss: 0.046954, loss_s1: 0.040985, loss_fp: 0.006420, loss_freq: 0.020841
[06:24:13.677] iteration 21979: loss: 0.045236, loss_s1: 0.031568, loss_fp: 0.002512, loss_freq: 0.021030
[06:24:14.288] iteration 21980: loss: 0.034189, loss_s1: 0.017778, loss_fp: 0.002405, loss_freq: 0.009113
[06:24:14.942] iteration 21981: loss: 0.036151, loss_s1: 0.020376, loss_fp: 0.002205, loss_freq: 0.013137
[06:24:15.560] iteration 21982: loss: 0.067747, loss_s1: 0.038138, loss_fp: 0.003581, loss_freq: 0.016738
[06:24:16.178] iteration 21983: loss: 0.039311, loss_s1: 0.026463, loss_fp: 0.000327, loss_freq: 0.020083
[06:24:16.802] iteration 21984: loss: 0.062272, loss_s1: 0.056461, loss_fp: 0.009148, loss_freq: 0.030947
[06:24:17.432] iteration 21985: loss: 0.056280, loss_s1: 0.027812, loss_fp: 0.002700, loss_freq: 0.045360
[06:24:18.060] iteration 21986: loss: 0.047557, loss_s1: 0.032444, loss_fp: 0.005316, loss_freq: 0.024203
[06:24:18.684] iteration 21987: loss: 0.056331, loss_s1: 0.055618, loss_fp: 0.001829, loss_freq: 0.029859
[06:24:19.315] iteration 21988: loss: 0.044735, loss_s1: 0.022115, loss_fp: 0.004293, loss_freq: 0.019228
[06:24:19.929] iteration 21989: loss: 0.060311, loss_s1: 0.055184, loss_fp: 0.001599, loss_freq: 0.021048
[06:24:20.552] iteration 21990: loss: 0.056991, loss_s1: 0.045381, loss_fp: 0.003306, loss_freq: 0.028707
[06:24:21.167] iteration 21991: loss: 0.032687, loss_s1: 0.029753, loss_fp: 0.002115, loss_freq: 0.009216
[06:24:21.784] iteration 21992: loss: 0.059825, loss_s1: 0.039974, loss_fp: 0.002216, loss_freq: 0.025009
[06:24:22.395] iteration 21993: loss: 0.049666, loss_s1: 0.040323, loss_fp: 0.001309, loss_freq: 0.013005
[06:24:23.020] iteration 21994: loss: 0.046034, loss_s1: 0.036082, loss_fp: 0.000773, loss_freq: 0.025529
[06:24:23.645] iteration 21995: loss: 0.062277, loss_s1: 0.067651, loss_fp: 0.007778, loss_freq: 0.015965
[06:24:24.269] iteration 21996: loss: 0.039660, loss_s1: 0.022832, loss_fp: 0.006129, loss_freq: 0.025381
[06:24:24.895] iteration 21997: loss: 0.053560, loss_s1: 0.040357, loss_fp: 0.003352, loss_freq: 0.015765
[06:24:25.536] iteration 21998: loss: 0.139510, loss_s1: 0.162400, loss_fp: 0.006483, loss_freq: 0.078722
[06:24:26.151] iteration 21999: loss: 0.039915, loss_s1: 0.021603, loss_fp: 0.001786, loss_freq: 0.023509
[06:24:26.764] iteration 22000: loss: 0.047316, loss_s1: 0.037318, loss_fp: 0.006435, loss_freq: 0.032555
[06:24:30.059] iteration 22000 : mean_dice : 0.745007
[06:24:30.700] iteration 22001: loss: 0.065595, loss_s1: 0.064196, loss_fp: 0.004206, loss_freq: 0.024505
[06:24:31.306] iteration 22002: loss: 0.059278, loss_s1: 0.039819, loss_fp: 0.002700, loss_freq: 0.044559
[06:24:31.981] iteration 22003: loss: 0.062436, loss_s1: 0.042880, loss_fp: 0.009189, loss_freq: 0.044387
[06:24:32.637] iteration 22004: loss: 0.065592, loss_s1: 0.081687, loss_fp: 0.003578, loss_freq: 0.015204
[06:24:33.257] iteration 22005: loss: 0.052036, loss_s1: 0.036791, loss_fp: 0.002464, loss_freq: 0.036305
[06:24:33.878] iteration 22006: loss: 0.074562, loss_s1: 0.058035, loss_fp: 0.013619, loss_freq: 0.041627
[06:24:34.507] iteration 22007: loss: 0.051245, loss_s1: 0.054251, loss_fp: 0.003181, loss_freq: 0.016901
[06:24:35.139] iteration 22008: loss: 0.072174, loss_s1: 0.076137, loss_fp: 0.003149, loss_freq: 0.036002
[06:24:35.795] iteration 22009: loss: 0.049821, loss_s1: 0.050768, loss_fp: 0.004929, loss_freq: 0.021329
[06:24:36.441] iteration 22010: loss: 0.049902, loss_s1: 0.028805, loss_fp: 0.006229, loss_freq: 0.028027
[06:24:37.064] iteration 22011: loss: 0.045575, loss_s1: 0.034673, loss_fp: 0.001763, loss_freq: 0.016195
[06:24:37.680] iteration 22012: loss: 0.062778, loss_s1: 0.048284, loss_fp: 0.007493, loss_freq: 0.039157
[06:24:38.303] iteration 22013: loss: 0.053262, loss_s1: 0.057940, loss_fp: 0.004037, loss_freq: 0.012293
[06:24:38.919] iteration 22014: loss: 0.040244, loss_s1: 0.025925, loss_fp: 0.003802, loss_freq: 0.015175
[06:24:39.537] iteration 22015: loss: 0.039613, loss_s1: 0.014491, loss_fp: 0.005178, loss_freq: 0.027930
[06:24:40.157] iteration 22016: loss: 0.073414, loss_s1: 0.080660, loss_fp: 0.004671, loss_freq: 0.023802
[06:24:40.786] iteration 22017: loss: 0.050682, loss_s1: 0.050911, loss_fp: 0.005568, loss_freq: 0.024247
[06:24:41.404] iteration 22018: loss: 0.064466, loss_s1: 0.053214, loss_fp: 0.003095, loss_freq: 0.019077
[06:24:42.021] iteration 22019: loss: 0.072497, loss_s1: 0.079552, loss_fp: 0.013022, loss_freq: 0.021497
[06:24:42.641] iteration 22020: loss: 0.037992, loss_s1: 0.019589, loss_fp: 0.002036, loss_freq: 0.014431
[06:24:43.252] iteration 22021: loss: 0.063386, loss_s1: 0.062765, loss_fp: 0.003351, loss_freq: 0.022542
[06:24:43.864] iteration 22022: loss: 0.094248, loss_s1: 0.078943, loss_fp: 0.007299, loss_freq: 0.078811
[06:24:44.482] iteration 22023: loss: 0.072645, loss_s1: 0.062148, loss_fp: 0.010210, loss_freq: 0.031032
[06:24:45.096] iteration 22024: loss: 0.052222, loss_s1: 0.042923, loss_fp: 0.005350, loss_freq: 0.029095
[06:24:45.712] iteration 22025: loss: 0.063081, loss_s1: 0.072297, loss_fp: 0.003854, loss_freq: 0.019118
[06:24:46.334] iteration 22026: loss: 0.058940, loss_s1: 0.068932, loss_fp: 0.001758, loss_freq: 0.024725
[06:24:46.948] iteration 22027: loss: 0.082340, loss_s1: 0.054575, loss_fp: 0.003527, loss_freq: 0.057111
[06:24:47.563] iteration 22028: loss: 0.059929, loss_s1: 0.054316, loss_fp: 0.001075, loss_freq: 0.027152
[06:24:48.173] iteration 22029: loss: 0.052904, loss_s1: 0.031146, loss_fp: 0.005938, loss_freq: 0.041252
[06:24:48.782] iteration 22030: loss: 0.045972, loss_s1: 0.042135, loss_fp: 0.003943, loss_freq: 0.014543
[06:24:49.399] iteration 22031: loss: 0.083019, loss_s1: 0.102968, loss_fp: 0.002852, loss_freq: 0.032192
[06:24:50.005] iteration 22032: loss: 0.056466, loss_s1: 0.049865, loss_fp: 0.001881, loss_freq: 0.024215
[06:24:50.615] iteration 22033: loss: 0.036647, loss_s1: 0.015398, loss_fp: 0.002868, loss_freq: 0.022691
[06:24:51.227] iteration 22034: loss: 0.043139, loss_s1: 0.038587, loss_fp: 0.000712, loss_freq: 0.015303
[06:24:51.840] iteration 22035: loss: 0.039225, loss_s1: 0.021611, loss_fp: 0.000951, loss_freq: 0.029847
[06:24:52.541] iteration 22036: loss: 0.060577, loss_s1: 0.066598, loss_fp: 0.003693, loss_freq: 0.016616
[06:24:53.217] iteration 22037: loss: 0.055505, loss_s1: 0.048127, loss_fp: 0.003324, loss_freq: 0.024459
[06:24:53.874] iteration 22038: loss: 0.044555, loss_s1: 0.044328, loss_fp: 0.002033, loss_freq: 0.016361
[06:24:54.519] iteration 22039: loss: 0.064519, loss_s1: 0.036796, loss_fp: 0.001697, loss_freq: 0.048801
[06:24:55.132] iteration 22040: loss: 0.066083, loss_s1: 0.040736, loss_fp: 0.001439, loss_freq: 0.058937
[06:24:55.762] iteration 22041: loss: 0.060066, loss_s1: 0.054455, loss_fp: 0.002189, loss_freq: 0.020022
[06:24:56.379] iteration 22042: loss: 0.055931, loss_s1: 0.054930, loss_fp: 0.008757, loss_freq: 0.013360
[06:24:57.000] iteration 22043: loss: 0.055650, loss_s1: 0.040697, loss_fp: 0.001692, loss_freq: 0.041075
[06:24:57.613] iteration 22044: loss: 0.037122, loss_s1: 0.030791, loss_fp: 0.004172, loss_freq: 0.016781
[06:24:58.228] iteration 22045: loss: 0.092203, loss_s1: 0.100499, loss_fp: 0.004997, loss_freq: 0.042957
[06:24:58.840] iteration 22046: loss: 0.054151, loss_s1: 0.038746, loss_fp: 0.004260, loss_freq: 0.031518
[06:24:59.496] iteration 22047: loss: 0.041834, loss_s1: 0.027416, loss_fp: 0.001249, loss_freq: 0.013538
[06:25:00.153] iteration 22048: loss: 0.058121, loss_s1: 0.043406, loss_fp: 0.003734, loss_freq: 0.037627
[06:25:00.829] iteration 22049: loss: 0.100906, loss_s1: 0.061739, loss_fp: 0.005012, loss_freq: 0.099561
[06:25:01.444] iteration 22050: loss: 0.044421, loss_s1: 0.023165, loss_fp: 0.001303, loss_freq: 0.027277
[06:25:02.092] iteration 22051: loss: 0.036060, loss_s1: 0.032128, loss_fp: 0.000630, loss_freq: 0.007000
[06:25:02.698] iteration 22052: loss: 0.040189, loss_s1: 0.033253, loss_fp: 0.011753, loss_freq: 0.013455
[06:25:03.303] iteration 22053: loss: 0.115786, loss_s1: 0.133480, loss_fp: 0.020722, loss_freq: 0.044575
[06:25:03.910] iteration 22054: loss: 0.038023, loss_s1: 0.029102, loss_fp: 0.003886, loss_freq: 0.012542
[06:25:04.519] iteration 22055: loss: 0.056794, loss_s1: 0.043494, loss_fp: 0.005230, loss_freq: 0.032891
[06:25:05.130] iteration 22056: loss: 0.041447, loss_s1: 0.011887, loss_fp: 0.003723, loss_freq: 0.033040
[06:25:05.749] iteration 22057: loss: 0.044524, loss_s1: 0.037044, loss_fp: 0.005105, loss_freq: 0.022752
[06:25:06.356] iteration 22058: loss: 0.088140, loss_s1: 0.077072, loss_fp: 0.005299, loss_freq: 0.054105
[06:25:06.967] iteration 22059: loss: 0.052379, loss_s1: 0.045758, loss_fp: 0.003633, loss_freq: 0.024777
[06:25:07.616] iteration 22060: loss: 0.093204, loss_s1: 0.060803, loss_fp: 0.007009, loss_freq: 0.086912
[06:25:08.265] iteration 22061: loss: 0.048133, loss_s1: 0.044382, loss_fp: 0.006250, loss_freq: 0.020284
[06:25:08.915] iteration 22062: loss: 0.073082, loss_s1: 0.036087, loss_fp: 0.005416, loss_freq: 0.034933
[06:25:09.564] iteration 22063: loss: 0.076577, loss_s1: 0.061056, loss_fp: 0.014087, loss_freq: 0.045882
[06:25:10.244] iteration 22064: loss: 0.045289, loss_s1: 0.043652, loss_fp: 0.004515, loss_freq: 0.014085
[06:25:10.869] iteration 22065: loss: 0.063998, loss_s1: 0.049914, loss_fp: 0.001992, loss_freq: 0.039902
[06:25:11.533] iteration 22066: loss: 0.048810, loss_s1: 0.049848, loss_fp: 0.003143, loss_freq: 0.021424
[06:25:12.151] iteration 22067: loss: 0.056046, loss_s1: 0.039609, loss_fp: 0.004124, loss_freq: 0.015209
[06:25:12.771] iteration 22068: loss: 0.079259, loss_s1: 0.087810, loss_fp: 0.004750, loss_freq: 0.033279
[06:25:13.394] iteration 22069: loss: 0.117313, loss_s1: 0.124107, loss_fp: 0.006173, loss_freq: 0.059574
[06:25:14.016] iteration 22070: loss: 0.103078, loss_s1: 0.122663, loss_fp: 0.002963, loss_freq: 0.058939
[06:25:14.641] iteration 22071: loss: 0.057343, loss_s1: 0.067277, loss_fp: 0.002163, loss_freq: 0.008243
[06:25:15.260] iteration 22072: loss: 0.064987, loss_s1: 0.063971, loss_fp: 0.003232, loss_freq: 0.023516
[06:25:15.882] iteration 22073: loss: 0.048929, loss_s1: 0.053612, loss_fp: 0.001072, loss_freq: 0.015085
[06:25:16.504] iteration 22074: loss: 0.058255, loss_s1: 0.066281, loss_fp: 0.004523, loss_freq: 0.016441
[06:25:17.128] iteration 22075: loss: 0.032850, loss_s1: 0.023422, loss_fp: 0.002637, loss_freq: 0.015897
[06:25:17.764] iteration 22076: loss: 0.058996, loss_s1: 0.047693, loss_fp: 0.003698, loss_freq: 0.025096
[06:25:18.388] iteration 22077: loss: 0.045560, loss_s1: 0.031707, loss_fp: 0.001885, loss_freq: 0.020663
[06:25:19.006] iteration 22078: loss: 0.087529, loss_s1: 0.083687, loss_fp: 0.011628, loss_freq: 0.055061
[06:25:19.628] iteration 22079: loss: 0.053027, loss_s1: 0.053934, loss_fp: 0.006886, loss_freq: 0.021447
[06:25:20.251] iteration 22080: loss: 0.057284, loss_s1: 0.045715, loss_fp: 0.003274, loss_freq: 0.018758
[06:25:20.873] iteration 22081: loss: 0.071314, loss_s1: 0.073163, loss_fp: 0.015810, loss_freq: 0.011398
[06:25:21.493] iteration 22082: loss: 0.088247, loss_s1: 0.107707, loss_fp: 0.007313, loss_freq: 0.028969
[06:25:22.113] iteration 22083: loss: 0.076715, loss_s1: 0.073155, loss_fp: 0.006532, loss_freq: 0.045143
[06:25:22.733] iteration 22084: loss: 0.080697, loss_s1: 0.057649, loss_fp: 0.004739, loss_freq: 0.065043
[06:25:23.382] iteration 22085: loss: 0.065668, loss_s1: 0.064364, loss_fp: 0.002765, loss_freq: 0.024290
[06:25:24.043] iteration 22086: loss: 0.049312, loss_s1: 0.039978, loss_fp: 0.002146, loss_freq: 0.018617
[06:25:24.733] iteration 22087: loss: 0.040003, loss_s1: 0.031850, loss_fp: 0.004591, loss_freq: 0.015911
[06:25:25.410] iteration 22088: loss: 0.059485, loss_s1: 0.033071, loss_fp: 0.003316, loss_freq: 0.050713
[06:25:26.021] iteration 22089: loss: 0.067235, loss_s1: 0.041850, loss_fp: 0.013429, loss_freq: 0.046436
[06:25:26.633] iteration 22090: loss: 0.067271, loss_s1: 0.053725, loss_fp: 0.006430, loss_freq: 0.038748
[06:25:27.242] iteration 22091: loss: 0.038616, loss_s1: 0.031910, loss_fp: 0.003976, loss_freq: 0.009762
[06:25:27.853] iteration 22092: loss: 0.061415, loss_s1: 0.049301, loss_fp: 0.005531, loss_freq: 0.045481
[06:25:28.471] iteration 22093: loss: 0.043811, loss_s1: 0.021027, loss_fp: 0.002001, loss_freq: 0.018078
[06:25:29.080] iteration 22094: loss: 0.052201, loss_s1: 0.044251, loss_fp: 0.003997, loss_freq: 0.026849
[06:25:29.691] iteration 22095: loss: 0.032043, loss_s1: 0.022815, loss_fp: 0.004237, loss_freq: 0.009512
[06:25:30.303] iteration 22096: loss: 0.072225, loss_s1: 0.083829, loss_fp: 0.002704, loss_freq: 0.035744
[06:25:30.919] iteration 22097: loss: 0.065282, loss_s1: 0.064238, loss_fp: 0.002797, loss_freq: 0.029230
[06:25:31.533] iteration 22098: loss: 0.061702, loss_s1: 0.051381, loss_fp: 0.003543, loss_freq: 0.034082
[06:25:32.145] iteration 22099: loss: 0.076483, loss_s1: 0.079994, loss_fp: 0.004096, loss_freq: 0.038742
[06:25:32.764] iteration 22100: loss: 0.053727, loss_s1: 0.050503, loss_fp: 0.002048, loss_freq: 0.014701
[06:25:33.715] iteration 22101: loss: 0.076041, loss_s1: 0.073257, loss_fp: 0.002903, loss_freq: 0.034872
[06:25:34.334] iteration 22102: loss: 0.060511, loss_s1: 0.039691, loss_fp: 0.001948, loss_freq: 0.036472
[06:25:34.949] iteration 22103: loss: 0.067308, loss_s1: 0.069337, loss_fp: 0.007371, loss_freq: 0.026440
[06:25:35.564] iteration 22104: loss: 0.036841, loss_s1: 0.027669, loss_fp: 0.004089, loss_freq: 0.010831
[06:25:36.176] iteration 22105: loss: 0.074231, loss_s1: 0.072155, loss_fp: 0.004569, loss_freq: 0.049331
[06:25:36.792] iteration 22106: loss: 0.092794, loss_s1: 0.047890, loss_fp: 0.001171, loss_freq: 0.060262
[06:25:37.405] iteration 22107: loss: 0.045415, loss_s1: 0.033581, loss_fp: 0.001175, loss_freq: 0.018854
[06:25:38.016] iteration 22108: loss: 0.042261, loss_s1: 0.044171, loss_fp: 0.001585, loss_freq: 0.014246
[06:25:38.648] iteration 22109: loss: 0.057608, loss_s1: 0.054459, loss_fp: 0.002792, loss_freq: 0.036883
[06:25:39.264] iteration 22110: loss: 0.095305, loss_s1: 0.094338, loss_fp: 0.004108, loss_freq: 0.049506
[06:25:39.873] iteration 22111: loss: 0.072451, loss_s1: 0.090189, loss_fp: 0.002188, loss_freq: 0.018866
[06:25:40.486] iteration 22112: loss: 0.069825, loss_s1: 0.049129, loss_fp: 0.001277, loss_freq: 0.054836
[06:25:41.133] iteration 22113: loss: 0.059382, loss_s1: 0.054096, loss_fp: 0.004823, loss_freq: 0.025065
[06:25:41.787] iteration 22114: loss: 0.060844, loss_s1: 0.045187, loss_fp: 0.008311, loss_freq: 0.032687
[06:25:42.438] iteration 22115: loss: 0.100779, loss_s1: 0.115113, loss_fp: 0.008014, loss_freq: 0.035672
[06:25:43.090] iteration 22116: loss: 0.042568, loss_s1: 0.034397, loss_fp: 0.002227, loss_freq: 0.016323
[06:25:43.743] iteration 22117: loss: 0.104977, loss_s1: 0.080936, loss_fp: 0.005279, loss_freq: 0.096226
[06:25:44.361] iteration 22118: loss: 0.045266, loss_s1: 0.030843, loss_fp: 0.006337, loss_freq: 0.019036
[06:25:44.984] iteration 22119: loss: 0.076056, loss_s1: 0.072677, loss_fp: 0.004362, loss_freq: 0.032955
[06:25:45.597] iteration 22120: loss: 0.065311, loss_s1: 0.071641, loss_fp: 0.003238, loss_freq: 0.017908
[06:25:46.210] iteration 22121: loss: 0.054224, loss_s1: 0.022702, loss_fp: 0.007237, loss_freq: 0.044617
[06:25:46.820] iteration 22122: loss: 0.064305, loss_s1: 0.070677, loss_fp: 0.006043, loss_freq: 0.023743
[06:25:47.434] iteration 22123: loss: 0.061542, loss_s1: 0.046803, loss_fp: 0.002815, loss_freq: 0.028001
[06:25:48.043] iteration 22124: loss: 0.054111, loss_s1: 0.041835, loss_fp: 0.006057, loss_freq: 0.029767
[06:25:48.653] iteration 22125: loss: 0.062013, loss_s1: 0.048800, loss_fp: 0.002250, loss_freq: 0.039217
[06:25:49.270] iteration 22126: loss: 0.060940, loss_s1: 0.045820, loss_fp: 0.005186, loss_freq: 0.041374
[06:25:49.873] iteration 22127: loss: 0.049847, loss_s1: 0.047275, loss_fp: 0.001563, loss_freq: 0.011920
[06:25:50.486] iteration 22128: loss: 0.070577, loss_s1: 0.044669, loss_fp: 0.003215, loss_freq: 0.019606
[06:25:51.102] iteration 22129: loss: 0.075048, loss_s1: 0.089248, loss_fp: 0.003622, loss_freq: 0.029073
[06:25:51.713] iteration 22130: loss: 0.099962, loss_s1: 0.127862, loss_fp: 0.003460, loss_freq: 0.031333
[06:25:52.344] iteration 22131: loss: 0.057517, loss_s1: 0.054809, loss_fp: 0.008046, loss_freq: 0.028872
[06:25:52.956] iteration 22132: loss: 0.106368, loss_s1: 0.110909, loss_fp: 0.003836, loss_freq: 0.055869
[06:25:53.566] iteration 22133: loss: 0.047921, loss_s1: 0.031834, loss_fp: 0.002368, loss_freq: 0.029666
[06:25:54.173] iteration 22134: loss: 0.062785, loss_s1: 0.071382, loss_fp: 0.005117, loss_freq: 0.011144
[06:25:54.800] iteration 22135: loss: 0.048624, loss_s1: 0.043639, loss_fp: 0.001155, loss_freq: 0.030019
[06:25:55.431] iteration 22136: loss: 0.058107, loss_s1: 0.058280, loss_fp: 0.000572, loss_freq: 0.011307
[06:25:56.056] iteration 22137: loss: 0.070217, loss_s1: 0.063706, loss_fp: 0.004130, loss_freq: 0.035286
[06:25:56.729] iteration 22138: loss: 0.057468, loss_s1: 0.050393, loss_fp: 0.007927, loss_freq: 0.029568
[06:25:57.384] iteration 22139: loss: 0.063975, loss_s1: 0.057227, loss_fp: 0.007455, loss_freq: 0.033676
[06:25:58.051] iteration 22140: loss: 0.069579, loss_s1: 0.048874, loss_fp: 0.006663, loss_freq: 0.037230
[06:25:58.712] iteration 22141: loss: 0.068665, loss_s1: 0.062698, loss_fp: 0.003720, loss_freq: 0.036285
[06:25:59.369] iteration 22142: loss: 0.041309, loss_s1: 0.024441, loss_fp: 0.003293, loss_freq: 0.014841
[06:25:59.992] iteration 22143: loss: 0.115823, loss_s1: 0.145816, loss_fp: 0.002171, loss_freq: 0.060394
[06:26:00.606] iteration 22144: loss: 0.071721, loss_s1: 0.067385, loss_fp: 0.003049, loss_freq: 0.046261
[06:26:01.213] iteration 22145: loss: 0.063084, loss_s1: 0.065770, loss_fp: 0.002355, loss_freq: 0.022803
[06:26:01.825] iteration 22146: loss: 0.072308, loss_s1: 0.080621, loss_fp: 0.004152, loss_freq: 0.025763
[06:26:02.433] iteration 22147: loss: 0.053065, loss_s1: 0.032174, loss_fp: 0.002833, loss_freq: 0.037203
[06:26:03.087] iteration 22148: loss: 0.054541, loss_s1: 0.056859, loss_fp: 0.003021, loss_freq: 0.025113
[06:26:03.707] iteration 22149: loss: 0.033763, loss_s1: 0.018481, loss_fp: 0.005099, loss_freq: 0.006122
[06:26:04.323] iteration 22150: loss: 0.029459, loss_s1: 0.021306, loss_fp: 0.001568, loss_freq: 0.007779
[06:26:04.938] iteration 22151: loss: 0.055393, loss_s1: 0.046169, loss_fp: 0.004718, loss_freq: 0.018622
[06:26:05.553] iteration 22152: loss: 0.053225, loss_s1: 0.050975, loss_fp: 0.002019, loss_freq: 0.031088
[06:26:06.160] iteration 22153: loss: 0.031290, loss_s1: 0.015335, loss_fp: 0.000774, loss_freq: 0.014168
[06:26:06.773] iteration 22154: loss: 0.074422, loss_s1: 0.062463, loss_fp: 0.008570, loss_freq: 0.051013
[06:26:07.424] iteration 22155: loss: 0.059412, loss_s1: 0.031882, loss_fp: 0.008228, loss_freq: 0.047803
[06:26:08.039] iteration 22156: loss: 0.064587, loss_s1: 0.062526, loss_fp: 0.004770, loss_freq: 0.031907
[06:26:08.646] iteration 22157: loss: 0.072531, loss_s1: 0.044864, loss_fp: 0.002299, loss_freq: 0.067818
[06:26:09.264] iteration 22158: loss: 0.043198, loss_s1: 0.029571, loss_fp: 0.001996, loss_freq: 0.014833
[06:26:09.879] iteration 22159: loss: 0.059838, loss_s1: 0.043855, loss_fp: 0.001868, loss_freq: 0.048493
[06:26:10.536] iteration 22160: loss: 0.047391, loss_s1: 0.026968, loss_fp: 0.004290, loss_freq: 0.028717
[06:26:11.232] iteration 22161: loss: 0.042216, loss_s1: 0.030196, loss_fp: 0.002411, loss_freq: 0.010143
[06:26:11.897] iteration 22162: loss: 0.102862, loss_s1: 0.080035, loss_fp: 0.007753, loss_freq: 0.071326
[06:26:12.570] iteration 22163: loss: 0.053610, loss_s1: 0.035107, loss_fp: 0.003276, loss_freq: 0.031889
[06:26:13.234] iteration 22164: loss: 0.046652, loss_s1: 0.039680, loss_fp: 0.007761, loss_freq: 0.020780
[06:26:13.842] iteration 22165: loss: 0.053339, loss_s1: 0.046727, loss_fp: 0.004179, loss_freq: 0.011020
[06:26:14.455] iteration 22166: loss: 0.029723, loss_s1: 0.012892, loss_fp: 0.002838, loss_freq: 0.019040
[06:26:15.099] iteration 22167: loss: 0.048059, loss_s1: 0.036330, loss_fp: 0.001217, loss_freq: 0.016083
[06:26:15.708] iteration 22168: loss: 0.087429, loss_s1: 0.088275, loss_fp: 0.010954, loss_freq: 0.047011
[06:26:16.311] iteration 22169: loss: 0.032086, loss_s1: 0.013491, loss_fp: 0.002315, loss_freq: 0.019567
[06:26:16.918] iteration 22170: loss: 0.055726, loss_s1: 0.034131, loss_fp: 0.009360, loss_freq: 0.043079
[06:26:17.523] iteration 22171: loss: 0.061136, loss_s1: 0.057643, loss_fp: 0.002803, loss_freq: 0.028250
[06:26:18.137] iteration 22172: loss: 0.047696, loss_s1: 0.018455, loss_fp: 0.010134, loss_freq: 0.024269
[06:26:18.743] iteration 22173: loss: 0.060658, loss_s1: 0.031332, loss_fp: 0.008048, loss_freq: 0.044377
[06:26:19.386] iteration 22174: loss: 0.055623, loss_s1: 0.046731, loss_fp: 0.014935, loss_freq: 0.020764
[06:26:20.044] iteration 22175: loss: 0.048146, loss_s1: 0.030720, loss_fp: 0.000992, loss_freq: 0.037416
[06:26:20.708] iteration 22176: loss: 0.065640, loss_s1: 0.042587, loss_fp: 0.007158, loss_freq: 0.049444
[06:26:21.361] iteration 22177: loss: 0.065050, loss_s1: 0.057218, loss_fp: 0.003276, loss_freq: 0.039633
[06:26:21.988] iteration 22178: loss: 0.072693, loss_s1: 0.042219, loss_fp: 0.011069, loss_freq: 0.021844
[06:26:22.601] iteration 22179: loss: 0.058537, loss_s1: 0.063482, loss_fp: 0.006416, loss_freq: 0.025292
[06:26:23.281] iteration 22180: loss: 0.054013, loss_s1: 0.042677, loss_fp: 0.002553, loss_freq: 0.018331
[06:26:23.896] iteration 22181: loss: 0.092587, loss_s1: 0.104948, loss_fp: 0.001861, loss_freq: 0.031623
[06:26:24.513] iteration 22182: loss: 0.059331, loss_s1: 0.054463, loss_fp: 0.008632, loss_freq: 0.026694
[06:26:25.125] iteration 22183: loss: 0.049419, loss_s1: 0.043629, loss_fp: 0.001494, loss_freq: 0.018079
[06:26:25.734] iteration 22184: loss: 0.061468, loss_s1: 0.061403, loss_fp: 0.010977, loss_freq: 0.022933
[06:26:26.342] iteration 22185: loss: 0.058497, loss_s1: 0.066390, loss_fp: 0.001901, loss_freq: 0.016916
[06:26:26.950] iteration 22186: loss: 0.059237, loss_s1: 0.049627, loss_fp: 0.004731, loss_freq: 0.025308
[06:26:27.556] iteration 22187: loss: 0.067857, loss_s1: 0.065461, loss_fp: 0.002731, loss_freq: 0.040465
[06:26:28.165] iteration 22188: loss: 0.059259, loss_s1: 0.068794, loss_fp: 0.001996, loss_freq: 0.023316
[06:26:28.775] iteration 22189: loss: 0.063344, loss_s1: 0.053145, loss_fp: 0.006044, loss_freq: 0.037878
[06:26:29.390] iteration 22190: loss: 0.040385, loss_s1: 0.013211, loss_fp: 0.000816, loss_freq: 0.022417
[06:26:30.000] iteration 22191: loss: 0.072123, loss_s1: 0.087625, loss_fp: 0.003900, loss_freq: 0.021616
[06:26:30.666] iteration 22192: loss: 0.072773, loss_s1: 0.078095, loss_fp: 0.006859, loss_freq: 0.035447
[06:26:31.292] iteration 22193: loss: 0.056383, loss_s1: 0.051039, loss_fp: 0.003644, loss_freq: 0.021887
[06:26:31.905] iteration 22194: loss: 0.065213, loss_s1: 0.053768, loss_fp: 0.002523, loss_freq: 0.039168
[06:26:32.523] iteration 22195: loss: 0.047821, loss_s1: 0.018601, loss_fp: 0.006192, loss_freq: 0.037523
[06:26:33.143] iteration 22196: loss: 0.061735, loss_s1: 0.040685, loss_fp: 0.004705, loss_freq: 0.054561
[06:26:33.763] iteration 22197: loss: 0.088409, loss_s1: 0.085471, loss_fp: 0.007064, loss_freq: 0.041647
[06:26:34.386] iteration 22198: loss: 0.059510, loss_s1: 0.039756, loss_fp: 0.002635, loss_freq: 0.040839
[06:26:35.007] iteration 22199: loss: 0.069796, loss_s1: 0.057802, loss_fp: 0.003992, loss_freq: 0.048307
[06:26:35.627] iteration 22200: loss: 0.061560, loss_s1: 0.033339, loss_fp: 0.005012, loss_freq: 0.043700
[06:26:39.000] iteration 22200 : mean_dice : 0.726437
[06:26:39.690] iteration 22201: loss: 0.036581, loss_s1: 0.031076, loss_fp: 0.002562, loss_freq: 0.014467
[06:26:40.363] iteration 22202: loss: 0.043600, loss_s1: 0.031174, loss_fp: 0.002790, loss_freq: 0.008340
[06:26:40.991] iteration 22203: loss: 0.036400, loss_s1: 0.022602, loss_fp: 0.000609, loss_freq: 0.021225
[06:26:41.617] iteration 22204: loss: 0.029752, loss_s1: 0.015604, loss_fp: 0.002051, loss_freq: 0.012942
[06:26:42.247] iteration 22205: loss: 0.022207, loss_s1: 0.007594, loss_fp: 0.002278, loss_freq: 0.009813
[06:26:42.860] iteration 22206: loss: 0.061861, loss_s1: 0.051921, loss_fp: 0.006681, loss_freq: 0.031046
[06:26:43.538] iteration 22207: loss: 0.041181, loss_s1: 0.024639, loss_fp: 0.000793, loss_freq: 0.021866
[06:26:44.197] iteration 22208: loss: 0.058282, loss_s1: 0.048666, loss_fp: 0.004609, loss_freq: 0.022679
[06:26:44.860] iteration 22209: loss: 0.029582, loss_s1: 0.011058, loss_fp: 0.000976, loss_freq: 0.014688
[06:26:45.520] iteration 22210: loss: 0.051122, loss_s1: 0.042443, loss_fp: 0.001925, loss_freq: 0.022033
[06:26:46.127] iteration 22211: loss: 0.040488, loss_s1: 0.027431, loss_fp: 0.005381, loss_freq: 0.009149
[06:26:46.732] iteration 22212: loss: 0.035014, loss_s1: 0.012504, loss_fp: 0.001850, loss_freq: 0.023366
[06:26:47.337] iteration 22213: loss: 0.049269, loss_s1: 0.046789, loss_fp: 0.001728, loss_freq: 0.021793
[06:26:47.941] iteration 22214: loss: 0.041362, loss_s1: 0.032203, loss_fp: 0.004726, loss_freq: 0.015492
[06:26:48.548] iteration 22215: loss: 0.080846, loss_s1: 0.062100, loss_fp: 0.001583, loss_freq: 0.042801
[06:26:49.151] iteration 22216: loss: 0.076213, loss_s1: 0.053939, loss_fp: 0.005933, loss_freq: 0.049845
[06:26:49.777] iteration 22217: loss: 0.050322, loss_s1: 0.027356, loss_fp: 0.002307, loss_freq: 0.037419
[06:26:50.394] iteration 22218: loss: 0.045657, loss_s1: 0.046864, loss_fp: 0.001622, loss_freq: 0.012965
[06:26:51.010] iteration 22219: loss: 0.070271, loss_s1: 0.058421, loss_fp: 0.001700, loss_freq: 0.052165
[06:26:51.622] iteration 22220: loss: 0.058325, loss_s1: 0.067298, loss_fp: 0.008460, loss_freq: 0.010744
[06:26:52.239] iteration 22221: loss: 0.028819, loss_s1: 0.014028, loss_fp: 0.002387, loss_freq: 0.007166
[06:26:52.897] iteration 22222: loss: 0.046810, loss_s1: 0.049134, loss_fp: 0.004126, loss_freq: 0.020917
[06:26:53.512] iteration 22223: loss: 0.081056, loss_s1: 0.056915, loss_fp: 0.017482, loss_freq: 0.052492
[06:26:54.187] iteration 22224: loss: 0.035832, loss_s1: 0.019079, loss_fp: 0.004401, loss_freq: 0.019153
[06:26:54.815] iteration 22225: loss: 0.083071, loss_s1: 0.040644, loss_fp: 0.002437, loss_freq: 0.081010
[06:26:55.469] iteration 22226: loss: 0.091478, loss_s1: 0.123551, loss_fp: 0.004093, loss_freq: 0.024704
[06:26:56.102] iteration 22227: loss: 0.045635, loss_s1: 0.020512, loss_fp: 0.001163, loss_freq: 0.039070
[06:26:56.748] iteration 22228: loss: 0.114129, loss_s1: 0.060270, loss_fp: 0.005387, loss_freq: 0.104092
[06:26:57.377] iteration 22229: loss: 0.053777, loss_s1: 0.040506, loss_fp: 0.007086, loss_freq: 0.031291
[06:26:58.004] iteration 22230: loss: 0.055764, loss_s1: 0.039891, loss_fp: 0.001609, loss_freq: 0.039047
[06:26:58.619] iteration 22231: loss: 0.046254, loss_s1: 0.052603, loss_fp: 0.002557, loss_freq: 0.011388
[06:26:59.244] iteration 22232: loss: 0.067302, loss_s1: 0.040455, loss_fp: 0.011889, loss_freq: 0.036792
[06:26:59.856] iteration 22233: loss: 0.080084, loss_s1: 0.074216, loss_fp: 0.001891, loss_freq: 0.047714
[06:27:00.466] iteration 22234: loss: 0.057515, loss_s1: 0.041096, loss_fp: 0.002189, loss_freq: 0.042553
[06:27:01.078] iteration 22235: loss: 0.065379, loss_s1: 0.023702, loss_fp: 0.004549, loss_freq: 0.059413
[06:27:01.683] iteration 22236: loss: 0.036805, loss_s1: 0.032578, loss_fp: 0.000937, loss_freq: 0.008525
[06:27:02.297] iteration 22237: loss: 0.067861, loss_s1: 0.085015, loss_fp: 0.001310, loss_freq: 0.015157
[06:27:02.932] iteration 22238: loss: 0.054200, loss_s1: 0.038886, loss_fp: 0.005952, loss_freq: 0.035613
[06:27:03.560] iteration 22239: loss: 0.113344, loss_s1: 0.125996, loss_fp: 0.007696, loss_freq: 0.056569
[06:27:04.193] iteration 22240: loss: 0.044499, loss_s1: 0.042348, loss_fp: 0.002905, loss_freq: 0.015353
[06:27:04.812] iteration 22241: loss: 0.061566, loss_s1: 0.059553, loss_fp: 0.002174, loss_freq: 0.028374
[06:27:05.426] iteration 22242: loss: 0.049693, loss_s1: 0.032741, loss_fp: 0.001835, loss_freq: 0.031988
[06:27:06.043] iteration 22243: loss: 0.053500, loss_s1: 0.054188, loss_fp: 0.002503, loss_freq: 0.016492
[06:27:06.651] iteration 22244: loss: 0.066209, loss_s1: 0.077527, loss_fp: 0.002317, loss_freq: 0.013155
[06:27:07.304] iteration 22245: loss: 0.036030, loss_s1: 0.023581, loss_fp: 0.006762, loss_freq: 0.014720
[06:27:08.116] iteration 22246: loss: 0.076922, loss_s1: 0.033071, loss_fp: 0.003408, loss_freq: 0.082263
[06:27:08.821] iteration 22247: loss: 0.048346, loss_s1: 0.038686, loss_fp: 0.003291, loss_freq: 0.022441
[06:27:09.476] iteration 22248: loss: 0.078831, loss_s1: 0.077018, loss_fp: 0.004880, loss_freq: 0.046568
[06:27:10.104] iteration 22249: loss: 0.046104, loss_s1: 0.042521, loss_fp: 0.002597, loss_freq: 0.019302
[06:27:10.762] iteration 22250: loss: 0.053034, loss_s1: 0.037907, loss_fp: 0.011128, loss_freq: 0.025620
[06:27:11.482] iteration 22251: loss: 0.066171, loss_s1: 0.057383, loss_fp: 0.003656, loss_freq: 0.031408
[06:27:12.144] iteration 22252: loss: 0.082310, loss_s1: 0.058417, loss_fp: 0.001551, loss_freq: 0.067414
[06:27:12.998] iteration 22253: loss: 0.071070, loss_s1: 0.085162, loss_fp: 0.005362, loss_freq: 0.025666
[06:27:13.665] iteration 22254: loss: 0.066114, loss_s1: 0.056116, loss_fp: 0.004194, loss_freq: 0.036181
[06:27:14.326] iteration 22255: loss: 0.061823, loss_s1: 0.046857, loss_fp: 0.004693, loss_freq: 0.034291
[06:27:14.968] iteration 22256: loss: 0.049791, loss_s1: 0.047553, loss_fp: 0.002973, loss_freq: 0.011352
[06:27:15.640] iteration 22257: loss: 0.042270, loss_s1: 0.033189, loss_fp: 0.004844, loss_freq: 0.024491
[06:27:16.401] iteration 22258: loss: 0.096387, loss_s1: 0.102460, loss_fp: 0.002979, loss_freq: 0.053617
[06:27:17.046] iteration 22259: loss: 0.054168, loss_s1: 0.035563, loss_fp: 0.006244, loss_freq: 0.034694
[06:27:17.788] iteration 22260: loss: 0.073260, loss_s1: 0.048790, loss_fp: 0.002050, loss_freq: 0.060373
[06:27:18.461] iteration 22261: loss: 0.039905, loss_s1: 0.035598, loss_fp: 0.003707, loss_freq: 0.008397
[06:27:19.089] iteration 22262: loss: 0.069462, loss_s1: 0.050145, loss_fp: 0.002586, loss_freq: 0.059256
[06:27:19.779] iteration 22263: loss: 0.054077, loss_s1: 0.022445, loss_fp: 0.006358, loss_freq: 0.029586
[06:27:20.403] iteration 22264: loss: 0.038673, loss_s1: 0.020232, loss_fp: 0.002230, loss_freq: 0.032318
[06:27:21.020] iteration 22265: loss: 0.045974, loss_s1: 0.038037, loss_fp: 0.002885, loss_freq: 0.021720
[06:27:21.633] iteration 22266: loss: 0.097035, loss_s1: 0.131677, loss_fp: 0.006731, loss_freq: 0.032120
[06:27:22.243] iteration 22267: loss: 0.041407, loss_s1: 0.032877, loss_fp: 0.001542, loss_freq: 0.020423
[06:27:22.856] iteration 22268: loss: 0.099590, loss_s1: 0.098892, loss_fp: 0.003336, loss_freq: 0.065119
[06:27:23.464] iteration 22269: loss: 0.091399, loss_s1: 0.072786, loss_fp: 0.014988, loss_freq: 0.059900
[06:27:24.108] iteration 22270: loss: 0.057022, loss_s1: 0.048376, loss_fp: 0.002185, loss_freq: 0.025572
[06:27:25.058] iteration 22271: loss: 0.092484, loss_s1: 0.086039, loss_fp: 0.005085, loss_freq: 0.053497
[06:27:25.674] iteration 22272: loss: 0.059284, loss_s1: 0.031680, loss_fp: 0.002796, loss_freq: 0.053493
[06:27:26.317] iteration 22273: loss: 0.069506, loss_s1: 0.077039, loss_fp: 0.005840, loss_freq: 0.029314
[06:27:26.931] iteration 22274: loss: 0.044590, loss_s1: 0.028977, loss_fp: 0.004239, loss_freq: 0.016875
[06:27:27.535] iteration 22275: loss: 0.054672, loss_s1: 0.058901, loss_fp: 0.001380, loss_freq: 0.022585
[06:27:28.145] iteration 22276: loss: 0.075348, loss_s1: 0.048973, loss_fp: 0.012421, loss_freq: 0.054220
[06:27:28.751] iteration 22277: loss: 0.051555, loss_s1: 0.043338, loss_fp: 0.001211, loss_freq: 0.028178
[06:27:29.357] iteration 22278: loss: 0.059510, loss_s1: 0.059818, loss_fp: 0.009179, loss_freq: 0.023384
[06:27:29.965] iteration 22279: loss: 0.043901, loss_s1: 0.045917, loss_fp: 0.005176, loss_freq: 0.012049
[06:27:30.575] iteration 22280: loss: 0.082139, loss_s1: 0.087761, loss_fp: 0.008102, loss_freq: 0.035761
[06:27:31.184] iteration 22281: loss: 0.056749, loss_s1: 0.038827, loss_fp: 0.005771, loss_freq: 0.030474
[06:27:31.799] iteration 22282: loss: 0.058502, loss_s1: 0.059744, loss_fp: 0.003011, loss_freq: 0.013849
[06:27:32.410] iteration 22283: loss: 0.058053, loss_s1: 0.042199, loss_fp: 0.003391, loss_freq: 0.032250
[06:27:33.076] iteration 22284: loss: 0.049577, loss_s1: 0.041943, loss_fp: 0.008460, loss_freq: 0.022274
[06:27:33.743] iteration 22285: loss: 0.090158, loss_s1: 0.110307, loss_fp: 0.009226, loss_freq: 0.025241
[06:27:34.377] iteration 22286: loss: 0.053408, loss_s1: 0.040515, loss_fp: 0.005224, loss_freq: 0.024135
[06:27:34.991] iteration 22287: loss: 0.056550, loss_s1: 0.037814, loss_fp: 0.002833, loss_freq: 0.050201
[06:27:35.604] iteration 22288: loss: 0.043700, loss_s1: 0.024104, loss_fp: 0.003444, loss_freq: 0.025468
[06:27:36.377] iteration 22289: loss: 0.064069, loss_s1: 0.059313, loss_fp: 0.011812, loss_freq: 0.029816
[06:27:37.068] iteration 22290: loss: 0.046728, loss_s1: 0.037375, loss_fp: 0.003042, loss_freq: 0.016259
[06:27:37.731] iteration 22291: loss: 0.056090, loss_s1: 0.046757, loss_fp: 0.003171, loss_freq: 0.028518
[06:27:38.380] iteration 22292: loss: 0.065853, loss_s1: 0.055910, loss_fp: 0.006836, loss_freq: 0.046257
[06:27:39.094] iteration 22293: loss: 0.058270, loss_s1: 0.047393, loss_fp: 0.004007, loss_freq: 0.025395
[06:27:39.725] iteration 22294: loss: 0.070139, loss_s1: 0.061600, loss_fp: 0.003665, loss_freq: 0.035387
[06:27:40.331] iteration 22295: loss: 0.062637, loss_s1: 0.043786, loss_fp: 0.006412, loss_freq: 0.033262
[06:27:40.951] iteration 22296: loss: 0.056687, loss_s1: 0.042327, loss_fp: 0.002888, loss_freq: 0.033732
[06:27:41.568] iteration 22297: loss: 0.044181, loss_s1: 0.032373, loss_fp: 0.004150, loss_freq: 0.019638
[06:27:42.225] iteration 22298: loss: 0.078193, loss_s1: 0.077309, loss_fp: 0.006889, loss_freq: 0.040114
[06:27:42.837] iteration 22299: loss: 0.036036, loss_s1: 0.022325, loss_fp: 0.006476, loss_freq: 0.018950
[06:27:43.444] iteration 22300: loss: 0.109051, loss_s1: 0.142466, loss_fp: 0.005197, loss_freq: 0.038304
[06:27:44.050] iteration 22301: loss: 0.057402, loss_s1: 0.055939, loss_fp: 0.002170, loss_freq: 0.034515
[06:27:44.663] iteration 22302: loss: 0.087438, loss_s1: 0.067636, loss_fp: 0.002371, loss_freq: 0.059868
[06:27:45.274] iteration 22303: loss: 0.084061, loss_s1: 0.061401, loss_fp: 0.003596, loss_freq: 0.073912
[06:27:45.952] iteration 22304: loss: 0.042420, loss_s1: 0.038206, loss_fp: 0.005587, loss_freq: 0.014891
[06:27:46.614] iteration 22305: loss: 0.041754, loss_s1: 0.031317, loss_fp: 0.001698, loss_freq: 0.024209
[06:27:47.275] iteration 22306: loss: 0.062781, loss_s1: 0.061785, loss_fp: 0.003507, loss_freq: 0.013944
[06:27:47.931] iteration 22307: loss: 0.058174, loss_s1: 0.028606, loss_fp: 0.001787, loss_freq: 0.047055
[06:27:48.542] iteration 22308: loss: 0.047870, loss_s1: 0.043664, loss_fp: 0.004142, loss_freq: 0.014697
[06:27:49.151] iteration 22309: loss: 0.124880, loss_s1: 0.132009, loss_fp: 0.005521, loss_freq: 0.069087
[06:27:49.757] iteration 22310: loss: 0.057233, loss_s1: 0.047730, loss_fp: 0.008055, loss_freq: 0.028068
[06:27:50.378] iteration 22311: loss: 0.036170, loss_s1: 0.021142, loss_fp: 0.000648, loss_freq: 0.012777
[06:27:50.997] iteration 22312: loss: 0.046804, loss_s1: 0.027097, loss_fp: 0.002943, loss_freq: 0.033899
[06:27:51.615] iteration 22313: loss: 0.060029, loss_s1: 0.049645, loss_fp: 0.005065, loss_freq: 0.036543
[06:27:52.275] iteration 22314: loss: 0.076783, loss_s1: 0.067845, loss_fp: 0.006945, loss_freq: 0.057662
[06:27:52.946] iteration 22315: loss: 0.078214, loss_s1: 0.052613, loss_fp: 0.005270, loss_freq: 0.054230
[06:27:53.608] iteration 22316: loss: 0.046386, loss_s1: 0.025791, loss_fp: 0.006436, loss_freq: 0.021710
[06:27:54.241] iteration 22317: loss: 0.042031, loss_s1: 0.027312, loss_fp: 0.003853, loss_freq: 0.022064
[06:27:54.876] iteration 22318: loss: 0.073801, loss_s1: 0.052660, loss_fp: 0.006674, loss_freq: 0.051525
[06:27:55.500] iteration 22319: loss: 0.046478, loss_s1: 0.045172, loss_fp: 0.001459, loss_freq: 0.014586
[06:27:56.113] iteration 22320: loss: 0.060056, loss_s1: 0.059273, loss_fp: 0.003641, loss_freq: 0.020631
[06:27:56.727] iteration 22321: loss: 0.033087, loss_s1: 0.015121, loss_fp: 0.002634, loss_freq: 0.013835
[06:27:57.336] iteration 22322: loss: 0.053125, loss_s1: 0.066611, loss_fp: 0.002479, loss_freq: 0.019523
[06:27:57.946] iteration 22323: loss: 0.036824, loss_s1: 0.010346, loss_fp: 0.001475, loss_freq: 0.025906
[06:27:58.557] iteration 22324: loss: 0.063344, loss_s1: 0.054034, loss_fp: 0.003956, loss_freq: 0.036988
[06:27:59.171] iteration 22325: loss: 0.047512, loss_s1: 0.014039, loss_fp: 0.005096, loss_freq: 0.041078
[06:27:59.785] iteration 22326: loss: 0.040578, loss_s1: 0.020042, loss_fp: 0.004181, loss_freq: 0.026927
[06:28:00.397] iteration 22327: loss: 0.076942, loss_s1: 0.060354, loss_fp: 0.007473, loss_freq: 0.064138
[06:28:01.012] iteration 22328: loss: 0.056001, loss_s1: 0.029221, loss_fp: 0.005522, loss_freq: 0.036862
[06:28:01.618] iteration 22329: loss: 0.049876, loss_s1: 0.032064, loss_fp: 0.017404, loss_freq: 0.025149
[06:28:02.225] iteration 22330: loss: 0.074685, loss_s1: 0.069380, loss_fp: 0.006326, loss_freq: 0.038900
[06:28:02.832] iteration 22331: loss: 0.031723, loss_s1: 0.030248, loss_fp: 0.002118, loss_freq: 0.007341
[06:28:03.437] iteration 22332: loss: 0.070600, loss_s1: 0.064726, loss_fp: 0.002962, loss_freq: 0.034896
[06:28:04.045] iteration 22333: loss: 0.033403, loss_s1: 0.013073, loss_fp: 0.002063, loss_freq: 0.017535
[06:28:04.660] iteration 22334: loss: 0.039052, loss_s1: 0.031592, loss_fp: 0.001896, loss_freq: 0.016429
[06:28:05.276] iteration 22335: loss: 0.087673, loss_s1: 0.125578, loss_fp: 0.002954, loss_freq: 0.011688
[06:28:05.908] iteration 22336: loss: 0.062833, loss_s1: 0.080075, loss_fp: 0.001240, loss_freq: 0.021005
[06:28:06.630] iteration 22337: loss: 0.055291, loss_s1: 0.043266, loss_fp: 0.002543, loss_freq: 0.019050
[06:28:07.282] iteration 22338: loss: 0.079574, loss_s1: 0.087729, loss_fp: 0.003355, loss_freq: 0.035531
[06:28:07.935] iteration 22339: loss: 0.049856, loss_s1: 0.043049, loss_fp: 0.000852, loss_freq: 0.025083
[06:28:08.590] iteration 22340: loss: 0.050164, loss_s1: 0.048401, loss_fp: 0.007481, loss_freq: 0.021833
[06:28:09.212] iteration 22341: loss: 0.049523, loss_s1: 0.039373, loss_fp: 0.003655, loss_freq: 0.020307
[06:28:09.852] iteration 22342: loss: 0.048899, loss_s1: 0.045326, loss_fp: 0.004397, loss_freq: 0.017787
[06:28:10.461] iteration 22343: loss: 0.064629, loss_s1: 0.047048, loss_fp: 0.007647, loss_freq: 0.038983
[06:28:11.147] iteration 22344: loss: 0.056227, loss_s1: 0.055804, loss_fp: 0.003865, loss_freq: 0.015897
[06:28:11.811] iteration 22345: loss: 0.047332, loss_s1: 0.020764, loss_fp: 0.002183, loss_freq: 0.047434
[06:28:12.469] iteration 22346: loss: 0.086510, loss_s1: 0.100682, loss_fp: 0.012058, loss_freq: 0.028351
[06:28:13.135] iteration 22347: loss: 0.047052, loss_s1: 0.044962, loss_fp: 0.002196, loss_freq: 0.017609
[06:28:13.802] iteration 22348: loss: 0.065106, loss_s1: 0.062027, loss_fp: 0.007862, loss_freq: 0.031880
[06:28:14.464] iteration 22349: loss: 0.042918, loss_s1: 0.029471, loss_fp: 0.002312, loss_freq: 0.032209
[06:28:15.079] iteration 22350: loss: 0.060668, loss_s1: 0.065292, loss_fp: 0.002581, loss_freq: 0.019852
[06:28:15.693] iteration 22351: loss: 0.082975, loss_s1: 0.027401, loss_fp: 0.003767, loss_freq: 0.053113
[06:28:16.319] iteration 22352: loss: 0.055074, loss_s1: 0.033357, loss_fp: 0.002793, loss_freq: 0.042739
[06:28:16.942] iteration 22353: loss: 0.054125, loss_s1: 0.044374, loss_fp: 0.003916, loss_freq: 0.029817
[06:28:17.554] iteration 22354: loss: 0.043160, loss_s1: 0.033572, loss_fp: 0.009084, loss_freq: 0.014231
[06:28:18.171] iteration 22355: loss: 0.057001, loss_s1: 0.042788, loss_fp: 0.007536, loss_freq: 0.025490
[06:28:18.784] iteration 22356: loss: 0.053645, loss_s1: 0.041415, loss_fp: 0.005378, loss_freq: 0.027232
[06:28:19.399] iteration 22357: loss: 0.048696, loss_s1: 0.054042, loss_fp: 0.001559, loss_freq: 0.020671
[06:28:20.022] iteration 22358: loss: 0.075981, loss_s1: 0.070002, loss_fp: 0.004251, loss_freq: 0.045880
[06:28:20.637] iteration 22359: loss: 0.046904, loss_s1: 0.035952, loss_fp: 0.013774, loss_freq: 0.014728
[06:28:21.247] iteration 22360: loss: 0.033816, loss_s1: 0.022842, loss_fp: 0.002675, loss_freq: 0.008449
[06:28:21.856] iteration 22361: loss: 0.054884, loss_s1: 0.035032, loss_fp: 0.002795, loss_freq: 0.037891
[06:28:22.468] iteration 22362: loss: 0.038358, loss_s1: 0.033755, loss_fp: 0.006454, loss_freq: 0.017408
[06:28:23.078] iteration 22363: loss: 0.094160, loss_s1: 0.107748, loss_fp: 0.009792, loss_freq: 0.024013
[06:28:23.690] iteration 22364: loss: 0.044255, loss_s1: 0.015854, loss_fp: 0.002373, loss_freq: 0.040841
[06:28:24.301] iteration 22365: loss: 0.065874, loss_s1: 0.047587, loss_fp: 0.005455, loss_freq: 0.032684
[06:28:24.923] iteration 22366: loss: 0.070300, loss_s1: 0.073973, loss_fp: 0.004866, loss_freq: 0.034465
[06:28:25.575] iteration 22367: loss: 0.062023, loss_s1: 0.050387, loss_fp: 0.003840, loss_freq: 0.027136
[06:28:26.194] iteration 22368: loss: 0.060871, loss_s1: 0.037757, loss_fp: 0.003215, loss_freq: 0.040072
[06:28:26.817] iteration 22369: loss: 0.090289, loss_s1: 0.089075, loss_fp: 0.001751, loss_freq: 0.054409
[06:28:27.423] iteration 22370: loss: 0.067042, loss_s1: 0.053760, loss_fp: 0.002934, loss_freq: 0.033146
[06:28:28.029] iteration 22371: loss: 0.045323, loss_s1: 0.046478, loss_fp: 0.002211, loss_freq: 0.018376
[06:28:28.642] iteration 22372: loss: 0.056593, loss_s1: 0.041525, loss_fp: 0.001942, loss_freq: 0.020852
[06:28:29.248] iteration 22373: loss: 0.043948, loss_s1: 0.025854, loss_fp: 0.002871, loss_freq: 0.030932
[06:28:29.854] iteration 22374: loss: 0.035520, loss_s1: 0.018853, loss_fp: 0.003325, loss_freq: 0.020205
[06:28:30.503] iteration 22375: loss: 0.022494, loss_s1: 0.012686, loss_fp: 0.002683, loss_freq: 0.005303
[06:28:31.117] iteration 22376: loss: 0.057102, loss_s1: 0.060458, loss_fp: 0.004749, loss_freq: 0.017424
[06:28:31.735] iteration 22377: loss: 0.055009, loss_s1: 0.040275, loss_fp: 0.004047, loss_freq: 0.031048
[06:28:32.346] iteration 22378: loss: 0.051553, loss_s1: 0.059778, loss_fp: 0.001790, loss_freq: 0.011229
[06:28:32.955] iteration 22379: loss: 0.053720, loss_s1: 0.025383, loss_fp: 0.006069, loss_freq: 0.041106
[06:28:33.570] iteration 22380: loss: 0.041173, loss_s1: 0.012897, loss_fp: 0.004609, loss_freq: 0.039115
[06:28:34.189] iteration 22381: loss: 0.049819, loss_s1: 0.029745, loss_fp: 0.005931, loss_freq: 0.025464
[06:28:34.804] iteration 22382: loss: 0.049153, loss_s1: 0.040292, loss_fp: 0.002933, loss_freq: 0.021197
[06:28:35.425] iteration 22383: loss: 0.043283, loss_s1: 0.037808, loss_fp: 0.004255, loss_freq: 0.015652
[06:28:36.036] iteration 22384: loss: 0.040788, loss_s1: 0.027417, loss_fp: 0.010018, loss_freq: 0.020876
[06:28:36.647] iteration 22385: loss: 0.066757, loss_s1: 0.039548, loss_fp: 0.003995, loss_freq: 0.047679
[06:28:37.269] iteration 22386: loss: 0.082316, loss_s1: 0.046194, loss_fp: 0.005121, loss_freq: 0.073166
[06:28:37.879] iteration 22387: loss: 0.066386, loss_s1: 0.072807, loss_fp: 0.004515, loss_freq: 0.024634
[06:28:38.496] iteration 22388: loss: 0.048510, loss_s1: 0.029409, loss_fp: 0.006546, loss_freq: 0.024639
[06:28:39.110] iteration 22389: loss: 0.071167, loss_s1: 0.025941, loss_fp: 0.005559, loss_freq: 0.077908
[06:28:39.725] iteration 22390: loss: 0.080226, loss_s1: 0.098958, loss_fp: 0.008020, loss_freq: 0.014639
[06:28:40.337] iteration 22391: loss: 0.043665, loss_s1: 0.045958, loss_fp: 0.002761, loss_freq: 0.008490
[06:28:40.988] iteration 22392: loss: 0.044993, loss_s1: 0.016999, loss_fp: 0.008454, loss_freq: 0.034060
[06:28:41.645] iteration 22393: loss: 0.041944, loss_s1: 0.033436, loss_fp: 0.006383, loss_freq: 0.016052
[06:28:42.300] iteration 22394: loss: 0.058684, loss_s1: 0.038276, loss_fp: 0.005357, loss_freq: 0.041098
[06:28:43.045] iteration 22395: loss: 0.076266, loss_s1: 0.032088, loss_fp: 0.001540, loss_freq: 0.068170
[06:28:43.681] iteration 22396: loss: 0.051151, loss_s1: 0.021834, loss_fp: 0.007265, loss_freq: 0.039915
[06:28:44.320] iteration 22397: loss: 0.045435, loss_s1: 0.019274, loss_fp: 0.002430, loss_freq: 0.045166
[06:28:45.151] iteration 22398: loss: 0.077894, loss_s1: 0.009212, loss_fp: 0.001067, loss_freq: 0.013672
[06:28:45.780] iteration 22399: loss: 0.065490, loss_s1: 0.042130, loss_fp: 0.009713, loss_freq: 0.028451
[06:28:46.406] iteration 22400: loss: 0.061147, loss_s1: 0.048640, loss_fp: 0.009215, loss_freq: 0.030404
[06:28:49.738] iteration 22400 : mean_dice : 0.746316
[06:28:50.375] iteration 22401: loss: 0.061085, loss_s1: 0.071981, loss_fp: 0.004691, loss_freq: 0.022732
[06:28:50.985] iteration 22402: loss: 0.070468, loss_s1: 0.059490, loss_fp: 0.008778, loss_freq: 0.026840
[06:28:51.602] iteration 22403: loss: 0.078733, loss_s1: 0.075108, loss_fp: 0.003817, loss_freq: 0.030710
[06:28:52.259] iteration 22404: loss: 0.069538, loss_s1: 0.071684, loss_fp: 0.001609, loss_freq: 0.040568
[06:28:52.869] iteration 22405: loss: 0.077366, loss_s1: 0.064166, loss_fp: 0.004338, loss_freq: 0.049964
[06:28:53.478] iteration 22406: loss: 0.037505, loss_s1: 0.033935, loss_fp: 0.000961, loss_freq: 0.011716
[06:28:54.092] iteration 22407: loss: 0.050930, loss_s1: 0.052949, loss_fp: 0.000921, loss_freq: 0.013879
[06:28:54.706] iteration 22408: loss: 0.049157, loss_s1: 0.040093, loss_fp: 0.010007, loss_freq: 0.026984
[06:28:55.321] iteration 22409: loss: 0.107098, loss_s1: 0.104805, loss_fp: 0.003813, loss_freq: 0.071911
[06:28:55.947] iteration 22410: loss: 0.058923, loss_s1: 0.055757, loss_fp: 0.003780, loss_freq: 0.035904
[06:28:56.564] iteration 22411: loss: 0.059914, loss_s1: 0.036995, loss_fp: 0.008898, loss_freq: 0.036478
[06:28:57.177] iteration 22412: loss: 0.049931, loss_s1: 0.038002, loss_fp: 0.003850, loss_freq: 0.022709
[06:28:57.800] iteration 22413: loss: 0.049616, loss_s1: 0.030673, loss_fp: 0.003290, loss_freq: 0.026316
[06:28:58.429] iteration 22414: loss: 0.036964, loss_s1: 0.025369, loss_fp: 0.002567, loss_freq: 0.011180
[06:28:59.046] iteration 22415: loss: 0.070871, loss_s1: 0.072761, loss_fp: 0.003998, loss_freq: 0.031284
[06:28:59.660] iteration 22416: loss: 0.079405, loss_s1: 0.055687, loss_fp: 0.003024, loss_freq: 0.064717
[06:29:00.271] iteration 22417: loss: 0.059542, loss_s1: 0.049509, loss_fp: 0.005808, loss_freq: 0.031636
[06:29:00.891] iteration 22418: loss: 0.124757, loss_s1: 0.188180, loss_fp: 0.007522, loss_freq: 0.023631
[06:29:01.504] iteration 22419: loss: 0.046002, loss_s1: 0.034869, loss_fp: 0.002950, loss_freq: 0.028399
[06:29:02.112] iteration 22420: loss: 0.066499, loss_s1: 0.037487, loss_fp: 0.010053, loss_freq: 0.030012
[06:29:02.715] iteration 22421: loss: 0.088757, loss_s1: 0.075476, loss_fp: 0.024790, loss_freq: 0.046006
[06:29:03.329] iteration 22422: loss: 0.068264, loss_s1: 0.060624, loss_fp: 0.002527, loss_freq: 0.039026
[06:29:03.936] iteration 22423: loss: 0.077915, loss_s1: 0.103888, loss_fp: 0.005108, loss_freq: 0.016769
[06:29:04.543] iteration 22424: loss: 0.077269, loss_s1: 0.066878, loss_fp: 0.006961, loss_freq: 0.049856
[06:29:05.153] iteration 22425: loss: 0.082606, loss_s1: 0.080632, loss_fp: 0.009137, loss_freq: 0.039251
[06:29:05.766] iteration 22426: loss: 0.038972, loss_s1: 0.021207, loss_fp: 0.006162, loss_freq: 0.017784
[06:29:06.367] iteration 22427: loss: 0.036441, loss_s1: 0.026498, loss_fp: 0.003953, loss_freq: 0.018005
[06:29:06.969] iteration 22428: loss: 0.096426, loss_s1: 0.087455, loss_fp: 0.001678, loss_freq: 0.064299
[06:29:07.572] iteration 22429: loss: 0.073176, loss_s1: 0.066141, loss_fp: 0.005035, loss_freq: 0.045220
[06:29:08.184] iteration 22430: loss: 0.066192, loss_s1: 0.037019, loss_fp: 0.010701, loss_freq: 0.046844
[06:29:08.798] iteration 22431: loss: 0.051851, loss_s1: 0.067430, loss_fp: 0.004087, loss_freq: 0.005418
[06:29:09.405] iteration 22432: loss: 0.061037, loss_s1: 0.049188, loss_fp: 0.006153, loss_freq: 0.047453
[06:29:10.016] iteration 22433: loss: 0.048994, loss_s1: 0.032532, loss_fp: 0.004221, loss_freq: 0.023547
[06:29:10.626] iteration 22434: loss: 0.054823, loss_s1: 0.049196, loss_fp: 0.001778, loss_freq: 0.032354
[06:29:11.237] iteration 22435: loss: 0.032857, loss_s1: 0.018060, loss_fp: 0.003757, loss_freq: 0.016169
[06:29:11.849] iteration 22436: loss: 0.064463, loss_s1: 0.066319, loss_fp: 0.002494, loss_freq: 0.033912
[06:29:12.457] iteration 22437: loss: 0.095192, loss_s1: 0.057148, loss_fp: 0.009481, loss_freq: 0.082432
[06:29:13.072] iteration 22438: loss: 0.056727, loss_s1: 0.047476, loss_fp: 0.005658, loss_freq: 0.029026
[06:29:13.679] iteration 22439: loss: 0.074800, loss_s1: 0.064908, loss_fp: 0.002022, loss_freq: 0.053128
[06:29:14.285] iteration 22440: loss: 0.036130, loss_s1: 0.015564, loss_fp: 0.000806, loss_freq: 0.021611
[06:29:15.225] iteration 22441: loss: 0.072297, loss_s1: 0.058110, loss_fp: 0.002507, loss_freq: 0.049440
[06:29:15.835] iteration 22442: loss: 0.074136, loss_s1: 0.065306, loss_fp: 0.006529, loss_freq: 0.043818
[06:29:16.453] iteration 22443: loss: 0.042566, loss_s1: 0.043840, loss_fp: 0.002274, loss_freq: 0.013290
[06:29:17.074] iteration 22444: loss: 0.045067, loss_s1: 0.030810, loss_fp: 0.004041, loss_freq: 0.019717
[06:29:17.734] iteration 22445: loss: 0.050222, loss_s1: 0.046467, loss_fp: 0.008643, loss_freq: 0.009914
[06:29:18.355] iteration 22446: loss: 0.045206, loss_s1: 0.021273, loss_fp: 0.003802, loss_freq: 0.023408
[06:29:18.970] iteration 22447: loss: 0.030534, loss_s1: 0.010040, loss_fp: 0.002873, loss_freq: 0.017343
[06:29:19.585] iteration 22448: loss: 0.043065, loss_s1: 0.037911, loss_fp: 0.001701, loss_freq: 0.015111
[06:29:20.202] iteration 22449: loss: 0.058180, loss_s1: 0.058095, loss_fp: 0.002512, loss_freq: 0.030225
[06:29:20.836] iteration 22450: loss: 0.066408, loss_s1: 0.073171, loss_fp: 0.007110, loss_freq: 0.015466
[06:29:21.447] iteration 22451: loss: 0.050897, loss_s1: 0.041748, loss_fp: 0.001682, loss_freq: 0.027139
[06:29:22.068] iteration 22452: loss: 0.078173, loss_s1: 0.082969, loss_fp: 0.006920, loss_freq: 0.033085
[06:29:22.681] iteration 22453: loss: 0.057939, loss_s1: 0.039212, loss_fp: 0.003171, loss_freq: 0.029327
[06:29:23.293] iteration 22454: loss: 0.067924, loss_s1: 0.047694, loss_fp: 0.004380, loss_freq: 0.057264
[06:29:23.902] iteration 22455: loss: 0.045848, loss_s1: 0.028385, loss_fp: 0.006035, loss_freq: 0.011029
[06:29:24.518] iteration 22456: loss: 0.059673, loss_s1: 0.071028, loss_fp: 0.006326, loss_freq: 0.011585
[06:29:25.131] iteration 22457: loss: 0.106071, loss_s1: 0.090834, loss_fp: 0.016973, loss_freq: 0.081701
[06:29:25.742] iteration 22458: loss: 0.033356, loss_s1: 0.016301, loss_fp: 0.003289, loss_freq: 0.009219
[06:29:26.353] iteration 22459: loss: 0.074824, loss_s1: 0.060362, loss_fp: 0.006650, loss_freq: 0.049748
[06:29:26.962] iteration 22460: loss: 0.057073, loss_s1: 0.034883, loss_fp: 0.001455, loss_freq: 0.013574
[06:29:27.570] iteration 22461: loss: 0.053272, loss_s1: 0.029416, loss_fp: 0.002495, loss_freq: 0.035090
[06:29:28.178] iteration 22462: loss: 0.042590, loss_s1: 0.019366, loss_fp: 0.005409, loss_freq: 0.041431
[06:29:28.787] iteration 22463: loss: 0.053338, loss_s1: 0.050163, loss_fp: 0.002478, loss_freq: 0.017612
[06:29:29.401] iteration 22464: loss: 0.028344, loss_s1: 0.014301, loss_fp: 0.001484, loss_freq: 0.011597
[06:29:30.027] iteration 22465: loss: 0.048644, loss_s1: 0.035472, loss_fp: 0.005164, loss_freq: 0.025038
[06:29:30.639] iteration 22466: loss: 0.064934, loss_s1: 0.051870, loss_fp: 0.005767, loss_freq: 0.045208
[06:29:31.252] iteration 22467: loss: 0.047022, loss_s1: 0.042971, loss_fp: 0.003983, loss_freq: 0.016746
[06:29:31.868] iteration 22468: loss: 0.088261, loss_s1: 0.092066, loss_fp: 0.011631, loss_freq: 0.038685
[06:29:32.486] iteration 22469: loss: 0.054764, loss_s1: 0.048870, loss_fp: 0.003005, loss_freq: 0.030546
[06:29:33.098] iteration 22470: loss: 0.046332, loss_s1: 0.040989, loss_fp: 0.004506, loss_freq: 0.016451
[06:29:33.751] iteration 22471: loss: 0.074236, loss_s1: 0.065277, loss_fp: 0.003662, loss_freq: 0.056904
[06:29:34.359] iteration 22472: loss: 0.062426, loss_s1: 0.030499, loss_fp: 0.005549, loss_freq: 0.036302
[06:29:34.975] iteration 22473: loss: 0.116224, loss_s1: 0.134328, loss_fp: 0.004841, loss_freq: 0.062972
[06:29:35.590] iteration 22474: loss: 0.064293, loss_s1: 0.067378, loss_fp: 0.005208, loss_freq: 0.016047
[06:29:36.204] iteration 22475: loss: 0.047846, loss_s1: 0.044653, loss_fp: 0.005113, loss_freq: 0.026168
[06:29:36.831] iteration 22476: loss: 0.077947, loss_s1: 0.070744, loss_fp: 0.002332, loss_freq: 0.013302
[06:29:37.443] iteration 22477: loss: 0.056228, loss_s1: 0.035410, loss_fp: 0.002772, loss_freq: 0.033616
[06:29:38.058] iteration 22478: loss: 0.068185, loss_s1: 0.066159, loss_fp: 0.008670, loss_freq: 0.033977
[06:29:38.671] iteration 22479: loss: 0.109603, loss_s1: 0.148130, loss_fp: 0.004176, loss_freq: 0.029420
[06:29:39.285] iteration 22480: loss: 0.051271, loss_s1: 0.039490, loss_fp: 0.005055, loss_freq: 0.033971
[06:29:39.902] iteration 22481: loss: 0.149051, loss_s1: 0.191285, loss_fp: 0.001452, loss_freq: 0.060435
[06:29:40.521] iteration 22482: loss: 0.055826, loss_s1: 0.046987, loss_fp: 0.003602, loss_freq: 0.030496
[06:29:41.130] iteration 22483: loss: 0.080620, loss_s1: 0.086734, loss_fp: 0.009640, loss_freq: 0.027532
[06:29:41.742] iteration 22484: loss: 0.084445, loss_s1: 0.087427, loss_fp: 0.003561, loss_freq: 0.047573
[06:29:42.352] iteration 22485: loss: 0.057474, loss_s1: 0.055343, loss_fp: 0.004209, loss_freq: 0.010198
[06:29:42.958] iteration 22486: loss: 0.096332, loss_s1: 0.119187, loss_fp: 0.008502, loss_freq: 0.027888
[06:29:43.578] iteration 22487: loss: 0.047258, loss_s1: 0.025824, loss_fp: 0.003177, loss_freq: 0.034511
[06:29:44.182] iteration 22488: loss: 0.061336, loss_s1: 0.056337, loss_fp: 0.001848, loss_freq: 0.035460
[06:29:44.791] iteration 22489: loss: 0.049481, loss_s1: 0.054335, loss_fp: 0.002379, loss_freq: 0.009467
[06:29:45.399] iteration 22490: loss: 0.046543, loss_s1: 0.035693, loss_fp: 0.001014, loss_freq: 0.014691
[06:29:46.013] iteration 22491: loss: 0.053637, loss_s1: 0.045951, loss_fp: 0.003583, loss_freq: 0.026603
[06:29:46.632] iteration 22492: loss: 0.053246, loss_s1: 0.052835, loss_fp: 0.002614, loss_freq: 0.027901
[06:29:47.241] iteration 22493: loss: 0.041572, loss_s1: 0.017258, loss_fp: 0.002355, loss_freq: 0.021201
[06:29:47.859] iteration 22494: loss: 0.061422, loss_s1: 0.040259, loss_fp: 0.006363, loss_freq: 0.041608
[06:29:48.475] iteration 22495: loss: 0.050020, loss_s1: 0.036817, loss_fp: 0.005862, loss_freq: 0.013667
[06:29:49.084] iteration 22496: loss: 0.037303, loss_s1: 0.011982, loss_fp: 0.001936, loss_freq: 0.020313
[06:29:49.697] iteration 22497: loss: 0.059528, loss_s1: 0.057574, loss_fp: 0.003163, loss_freq: 0.032680
[06:29:50.308] iteration 22498: loss: 0.037880, loss_s1: 0.024303, loss_fp: 0.003039, loss_freq: 0.015805
[06:29:50.932] iteration 22499: loss: 0.051522, loss_s1: 0.020695, loss_fp: 0.002777, loss_freq: 0.045527
[06:29:51.542] iteration 22500: loss: 0.064096, loss_s1: 0.060091, loss_fp: 0.000692, loss_freq: 0.034368
[06:29:52.154] iteration 22501: loss: 0.048875, loss_s1: 0.061538, loss_fp: 0.002404, loss_freq: 0.006701
[06:29:52.768] iteration 22502: loss: 0.059656, loss_s1: 0.054113, loss_fp: 0.001888, loss_freq: 0.025189
[06:29:53.379] iteration 22503: loss: 0.038503, loss_s1: 0.022942, loss_fp: 0.002498, loss_freq: 0.014515
[06:29:53.991] iteration 22504: loss: 0.037731, loss_s1: 0.021800, loss_fp: 0.003995, loss_freq: 0.021043
[06:29:54.605] iteration 22505: loss: 0.055346, loss_s1: 0.051792, loss_fp: 0.007085, loss_freq: 0.014953
[06:29:55.215] iteration 22506: loss: 0.066364, loss_s1: 0.076416, loss_fp: 0.001217, loss_freq: 0.035050
[06:29:55.823] iteration 22507: loss: 0.042082, loss_s1: 0.029501, loss_fp: 0.001340, loss_freq: 0.015207
[06:29:56.431] iteration 22508: loss: 0.093861, loss_s1: 0.101763, loss_fp: 0.007155, loss_freq: 0.052062
[06:29:57.037] iteration 22509: loss: 0.049169, loss_s1: 0.025941, loss_fp: 0.002814, loss_freq: 0.033031
[06:29:57.645] iteration 22510: loss: 0.044639, loss_s1: 0.044561, loss_fp: 0.003212, loss_freq: 0.015753
[06:29:58.260] iteration 22511: loss: 0.061133, loss_s1: 0.056377, loss_fp: 0.006185, loss_freq: 0.023005
[06:29:58.882] iteration 22512: loss: 0.055047, loss_s1: 0.039483, loss_fp: 0.005699, loss_freq: 0.019540
[06:29:59.500] iteration 22513: loss: 0.075500, loss_s1: 0.075349, loss_fp: 0.005729, loss_freq: 0.041463
[06:30:00.117] iteration 22514: loss: 0.083390, loss_s1: 0.073646, loss_fp: 0.019068, loss_freq: 0.036830
[06:30:00.777] iteration 22515: loss: 0.051039, loss_s1: 0.043834, loss_fp: 0.001948, loss_freq: 0.026818
[06:30:01.396] iteration 22516: loss: 0.065659, loss_s1: 0.061711, loss_fp: 0.007388, loss_freq: 0.027557
[06:30:02.008] iteration 22517: loss: 0.061600, loss_s1: 0.062438, loss_fp: 0.002020, loss_freq: 0.029872
[06:30:02.615] iteration 22518: loss: 0.067861, loss_s1: 0.055120, loss_fp: 0.006080, loss_freq: 0.045768
[06:30:03.219] iteration 22519: loss: 0.057664, loss_s1: 0.051972, loss_fp: 0.005989, loss_freq: 0.035507
[06:30:03.824] iteration 22520: loss: 0.047534, loss_s1: 0.035192, loss_fp: 0.001351, loss_freq: 0.017678
[06:30:04.428] iteration 22521: loss: 0.065057, loss_s1: 0.049616, loss_fp: 0.001707, loss_freq: 0.038107
[06:30:05.038] iteration 22522: loss: 0.052379, loss_s1: 0.052688, loss_fp: 0.003597, loss_freq: 0.016273
[06:30:05.640] iteration 22523: loss: 0.042403, loss_s1: 0.038330, loss_fp: 0.003373, loss_freq: 0.012361
[06:30:06.245] iteration 22524: loss: 0.038698, loss_s1: 0.027241, loss_fp: 0.007793, loss_freq: 0.011059
[06:30:06.855] iteration 22525: loss: 0.080465, loss_s1: 0.083261, loss_fp: 0.006974, loss_freq: 0.019734
[06:30:07.461] iteration 22526: loss: 0.068376, loss_s1: 0.060808, loss_fp: 0.006308, loss_freq: 0.036144
[06:30:08.071] iteration 22527: loss: 0.086403, loss_s1: 0.105743, loss_fp: 0.003978, loss_freq: 0.042505
[06:30:08.678] iteration 22528: loss: 0.060527, loss_s1: 0.060610, loss_fp: 0.004524, loss_freq: 0.017377
[06:30:09.285] iteration 22529: loss: 0.060006, loss_s1: 0.056511, loss_fp: 0.015891, loss_freq: 0.016587
[06:30:09.896] iteration 22530: loss: 0.048491, loss_s1: 0.046178, loss_fp: 0.001842, loss_freq: 0.010267
[06:30:10.510] iteration 22531: loss: 0.068112, loss_s1: 0.071838, loss_fp: 0.005717, loss_freq: 0.028075
[06:30:11.120] iteration 22532: loss: 0.035826, loss_s1: 0.020884, loss_fp: 0.003631, loss_freq: 0.023460
[06:30:11.741] iteration 22533: loss: 0.054630, loss_s1: 0.051840, loss_fp: 0.004080, loss_freq: 0.010117
[06:30:12.359] iteration 22534: loss: 0.059306, loss_s1: 0.029219, loss_fp: 0.030871, loss_freq: 0.034676
[06:30:13.015] iteration 22535: loss: 0.103133, loss_s1: 0.095441, loss_fp: 0.013029, loss_freq: 0.058075
[06:30:13.620] iteration 22536: loss: 0.057087, loss_s1: 0.041912, loss_fp: 0.001794, loss_freq: 0.044834
[06:30:14.236] iteration 22537: loss: 0.063996, loss_s1: 0.028277, loss_fp: 0.003261, loss_freq: 0.057521
[06:30:14.853] iteration 22538: loss: 0.055212, loss_s1: 0.040116, loss_fp: 0.009118, loss_freq: 0.017446
[06:30:15.463] iteration 22539: loss: 0.056531, loss_s1: 0.050560, loss_fp: 0.002987, loss_freq: 0.028588
[06:30:16.071] iteration 22540: loss: 0.052267, loss_s1: 0.045466, loss_fp: 0.006045, loss_freq: 0.019792
[06:30:16.678] iteration 22541: loss: 0.061370, loss_s1: 0.071519, loss_fp: 0.009580, loss_freq: 0.017440
[06:30:17.293] iteration 22542: loss: 0.033982, loss_s1: 0.016361, loss_fp: 0.005937, loss_freq: 0.012738
[06:30:17.903] iteration 22543: loss: 0.047462, loss_s1: 0.044050, loss_fp: 0.006773, loss_freq: 0.019507
[06:30:18.533] iteration 22544: loss: 0.045145, loss_s1: 0.026437, loss_fp: 0.000965, loss_freq: 0.016728
[06:30:19.137] iteration 22545: loss: 0.045905, loss_s1: 0.028023, loss_fp: 0.004337, loss_freq: 0.023446
[06:30:19.747] iteration 22546: loss: 0.081717, loss_s1: 0.076907, loss_fp: 0.006751, loss_freq: 0.042254
[06:30:20.356] iteration 22547: loss: 0.067833, loss_s1: 0.081398, loss_fp: 0.001308, loss_freq: 0.019642
[06:30:20.964] iteration 22548: loss: 0.050972, loss_s1: 0.038543, loss_fp: 0.002826, loss_freq: 0.029926
[06:30:21.569] iteration 22549: loss: 0.060657, loss_s1: 0.034440, loss_fp: 0.004138, loss_freq: 0.048987
[06:30:22.185] iteration 22550: loss: 0.050709, loss_s1: 0.051503, loss_fp: 0.002105, loss_freq: 0.021178
[06:30:22.790] iteration 22551: loss: 0.038593, loss_s1: 0.022361, loss_fp: 0.002302, loss_freq: 0.016587
[06:30:23.396] iteration 22552: loss: 0.043102, loss_s1: 0.025569, loss_fp: 0.001141, loss_freq: 0.019127
[06:30:24.002] iteration 22553: loss: 0.060137, loss_s1: 0.051199, loss_fp: 0.003713, loss_freq: 0.038493
[06:30:24.609] iteration 22554: loss: 0.039096, loss_s1: 0.035694, loss_fp: 0.000978, loss_freq: 0.017640
[06:30:25.215] iteration 22555: loss: 0.086843, loss_s1: 0.039798, loss_fp: 0.003313, loss_freq: 0.093388
[06:30:25.825] iteration 22556: loss: 0.054166, loss_s1: 0.046864, loss_fp: 0.001530, loss_freq: 0.023366
[06:30:26.447] iteration 22557: loss: 0.079931, loss_s1: 0.070522, loss_fp: 0.007049, loss_freq: 0.050412
[06:30:27.056] iteration 22558: loss: 0.075395, loss_s1: 0.069429, loss_fp: 0.003325, loss_freq: 0.046945
[06:30:27.657] iteration 22559: loss: 0.076939, loss_s1: 0.039560, loss_fp: 0.007793, loss_freq: 0.077890
[06:30:28.269] iteration 22560: loss: 0.040579, loss_s1: 0.037983, loss_fp: 0.001168, loss_freq: 0.005889
[06:30:28.878] iteration 22561: loss: 0.051847, loss_s1: 0.050196, loss_fp: 0.000924, loss_freq: 0.017625
[06:30:29.485] iteration 22562: loss: 0.050008, loss_s1: 0.039685, loss_fp: 0.005343, loss_freq: 0.033798
[06:30:30.100] iteration 22563: loss: 0.078493, loss_s1: 0.095139, loss_fp: 0.005395, loss_freq: 0.022696
[06:30:30.707] iteration 22564: loss: 0.063356, loss_s1: 0.056550, loss_fp: 0.025280, loss_freq: 0.013997
[06:30:31.315] iteration 22565: loss: 0.065500, loss_s1: 0.058301, loss_fp: 0.009569, loss_freq: 0.021912
[06:30:31.926] iteration 22566: loss: 0.078152, loss_s1: 0.090359, loss_fp: 0.002870, loss_freq: 0.025941
[06:30:32.539] iteration 22567: loss: 0.056559, loss_s1: 0.050595, loss_fp: 0.004623, loss_freq: 0.035020
[06:30:33.154] iteration 22568: loss: 0.042703, loss_s1: 0.027126, loss_fp: 0.005026, loss_freq: 0.015032
[06:30:33.764] iteration 22569: loss: 0.065855, loss_s1: 0.069787, loss_fp: 0.015496, loss_freq: 0.020666
[06:30:34.377] iteration 22570: loss: 0.065016, loss_s1: 0.049994, loss_fp: 0.008592, loss_freq: 0.035357
[06:30:34.988] iteration 22571: loss: 0.055653, loss_s1: 0.075078, loss_fp: 0.001414, loss_freq: 0.009901
[06:30:35.600] iteration 22572: loss: 0.049950, loss_s1: 0.041290, loss_fp: 0.001913, loss_freq: 0.016073
[06:30:36.211] iteration 22573: loss: 0.074613, loss_s1: 0.062714, loss_fp: 0.005226, loss_freq: 0.033545
[06:30:36.823] iteration 22574: loss: 0.064268, loss_s1: 0.068044, loss_fp: 0.005076, loss_freq: 0.022695
[06:30:37.430] iteration 22575: loss: 0.094919, loss_s1: 0.073730, loss_fp: 0.002265, loss_freq: 0.068249
[06:30:38.033] iteration 22576: loss: 0.049101, loss_s1: 0.042158, loss_fp: 0.008140, loss_freq: 0.019206
[06:30:38.646] iteration 22577: loss: 0.059818, loss_s1: 0.053965, loss_fp: 0.002819, loss_freq: 0.016066
[06:30:39.257] iteration 22578: loss: 0.057742, loss_s1: 0.051514, loss_fp: 0.007341, loss_freq: 0.029612
[06:30:39.870] iteration 22579: loss: 0.097285, loss_s1: 0.084433, loss_fp: 0.004549, loss_freq: 0.065947
[06:30:40.476] iteration 22580: loss: 0.071784, loss_s1: 0.080610, loss_fp: 0.001043, loss_freq: 0.036202
[06:30:41.084] iteration 22581: loss: 0.044977, loss_s1: 0.032187, loss_fp: 0.003123, loss_freq: 0.007559
[06:30:41.688] iteration 22582: loss: 0.053960, loss_s1: 0.041613, loss_fp: 0.002763, loss_freq: 0.026246
[06:30:42.299] iteration 22583: loss: 0.046254, loss_s1: 0.031097, loss_fp: 0.001364, loss_freq: 0.020591
[06:30:42.907] iteration 22584: loss: 0.060086, loss_s1: 0.069527, loss_fp: 0.005098, loss_freq: 0.011536
[06:30:43.548] iteration 22585: loss: 0.030844, loss_s1: 0.015635, loss_fp: 0.002578, loss_freq: 0.012459
[06:30:44.199] iteration 22586: loss: 0.061306, loss_s1: 0.030478, loss_fp: 0.002066, loss_freq: 0.050843
[06:30:44.852] iteration 22587: loss: 0.083497, loss_s1: 0.065797, loss_fp: 0.005327, loss_freq: 0.029408
[06:30:45.508] iteration 22588: loss: 0.084846, loss_s1: 0.104127, loss_fp: 0.004851, loss_freq: 0.031442
[06:30:46.161] iteration 22589: loss: 0.055268, loss_s1: 0.041988, loss_fp: 0.002268, loss_freq: 0.044739
[06:30:46.785] iteration 22590: loss: 0.059912, loss_s1: 0.045197, loss_fp: 0.002664, loss_freq: 0.027186
[06:30:47.393] iteration 22591: loss: 0.080723, loss_s1: 0.081589, loss_fp: 0.007385, loss_freq: 0.040459
[06:30:48.009] iteration 22592: loss: 0.086304, loss_s1: 0.084131, loss_fp: 0.005485, loss_freq: 0.049541
[06:30:48.697] iteration 22593: loss: 0.076736, loss_s1: 0.067654, loss_fp: 0.004360, loss_freq: 0.050826
[06:30:49.357] iteration 22594: loss: 0.103027, loss_s1: 0.078350, loss_fp: 0.016325, loss_freq: 0.082483
[06:30:49.981] iteration 22595: loss: 0.099432, loss_s1: 0.077809, loss_fp: 0.004572, loss_freq: 0.041318
[06:30:50.619] iteration 22596: loss: 0.047086, loss_s1: 0.040017, loss_fp: 0.001426, loss_freq: 0.020134
[06:30:51.265] iteration 22597: loss: 0.031078, loss_s1: 0.014465, loss_fp: 0.004129, loss_freq: 0.022513
[06:30:51.880] iteration 22598: loss: 0.078014, loss_s1: 0.054349, loss_fp: 0.001783, loss_freq: 0.061944
[06:30:52.494] iteration 22599: loss: 0.077090, loss_s1: 0.082287, loss_fp: 0.005793, loss_freq: 0.035188
[06:30:53.112] iteration 22600: loss: 0.067550, loss_s1: 0.037353, loss_fp: 0.012891, loss_freq: 0.048113
[06:30:57.016] iteration 22600 : mean_dice : 0.729031
[06:30:57.763] iteration 22601: loss: 0.048361, loss_s1: 0.054247, loss_fp: 0.001402, loss_freq: 0.006635
[06:30:58.450] iteration 22602: loss: 0.055674, loss_s1: 0.053849, loss_fp: 0.004451, loss_freq: 0.029112
[06:30:59.144] iteration 22603: loss: 0.040848, loss_s1: 0.038143, loss_fp: 0.001121, loss_freq: 0.007509
[06:30:59.854] iteration 22604: loss: 0.050609, loss_s1: 0.034429, loss_fp: 0.001676, loss_freq: 0.038859
[06:31:00.559] iteration 22605: loss: 0.032174, loss_s1: 0.022937, loss_fp: 0.003340, loss_freq: 0.008776
[06:31:01.362] iteration 22606: loss: 0.060709, loss_s1: 0.065595, loss_fp: 0.005865, loss_freq: 0.021506
[06:31:02.007] iteration 22607: loss: 0.063658, loss_s1: 0.046912, loss_fp: 0.004432, loss_freq: 0.035690
[06:31:02.721] iteration 22608: loss: 0.064732, loss_s1: 0.048039, loss_fp: 0.003222, loss_freq: 0.036416
[06:31:03.427] iteration 22609: loss: 0.072587, loss_s1: 0.067216, loss_fp: 0.003652, loss_freq: 0.020353
[06:31:04.110] iteration 22610: loss: 0.090803, loss_s1: 0.121760, loss_fp: 0.006881, loss_freq: 0.019153
[06:31:05.181] iteration 22611: loss: 0.078454, loss_s1: 0.080199, loss_fp: 0.003270, loss_freq: 0.035880
[06:31:05.881] iteration 22612: loss: 0.064310, loss_s1: 0.047553, loss_fp: 0.002630, loss_freq: 0.043253
[06:31:06.551] iteration 22613: loss: 0.065840, loss_s1: 0.071172, loss_fp: 0.003348, loss_freq: 0.025204
[06:31:07.304] iteration 22614: loss: 0.037659, loss_s1: 0.025134, loss_fp: 0.004030, loss_freq: 0.013315
[06:31:07.939] iteration 22615: loss: 0.062300, loss_s1: 0.069591, loss_fp: 0.005525, loss_freq: 0.023316
[06:31:08.549] iteration 22616: loss: 0.077661, loss_s1: 0.059044, loss_fp: 0.003515, loss_freq: 0.055367
[06:31:09.156] iteration 22617: loss: 0.034312, loss_s1: 0.012594, loss_fp: 0.006916, loss_freq: 0.013560
[06:31:09.764] iteration 22618: loss: 0.047947, loss_s1: 0.053194, loss_fp: 0.002126, loss_freq: 0.018102
[06:31:10.377] iteration 22619: loss: 0.042791, loss_s1: 0.021137, loss_fp: 0.001301, loss_freq: 0.013541
[06:31:10.984] iteration 22620: loss: 0.064385, loss_s1: 0.051844, loss_fp: 0.003884, loss_freq: 0.029970
[06:31:11.593] iteration 22621: loss: 0.051941, loss_s1: 0.041520, loss_fp: 0.004703, loss_freq: 0.028231
[06:31:12.211] iteration 22622: loss: 0.068038, loss_s1: 0.055229, loss_fp: 0.002141, loss_freq: 0.047197
[06:31:12.826] iteration 22623: loss: 0.077816, loss_s1: 0.044520, loss_fp: 0.003463, loss_freq: 0.027682
[06:31:13.446] iteration 22624: loss: 0.085016, loss_s1: 0.058097, loss_fp: 0.006574, loss_freq: 0.079340
[06:31:14.063] iteration 22625: loss: 0.060475, loss_s1: 0.049182, loss_fp: 0.007069, loss_freq: 0.023743
[06:31:14.690] iteration 22626: loss: 0.065393, loss_s1: 0.071764, loss_fp: 0.014050, loss_freq: 0.009666
[06:31:15.303] iteration 22627: loss: 0.085626, loss_s1: 0.096651, loss_fp: 0.005039, loss_freq: 0.050511
[06:31:15.928] iteration 22628: loss: 0.037861, loss_s1: 0.035514, loss_fp: 0.003223, loss_freq: 0.009554
[06:31:16.547] iteration 22629: loss: 0.062379, loss_s1: 0.061138, loss_fp: 0.005673, loss_freq: 0.025989
[06:31:17.167] iteration 22630: loss: 0.075551, loss_s1: 0.094880, loss_fp: 0.004858, loss_freq: 0.015272
[06:31:17.785] iteration 22631: loss: 0.051590, loss_s1: 0.043174, loss_fp: 0.003008, loss_freq: 0.021310
[06:31:18.400] iteration 22632: loss: 0.059405, loss_s1: 0.032997, loss_fp: 0.005946, loss_freq: 0.044511
[06:31:19.010] iteration 22633: loss: 0.073829, loss_s1: 0.061935, loss_fp: 0.001567, loss_freq: 0.028402
[06:31:19.620] iteration 22634: loss: 0.055654, loss_s1: 0.050376, loss_fp: 0.002232, loss_freq: 0.021075
[06:31:20.226] iteration 22635: loss: 0.070589, loss_s1: 0.069250, loss_fp: 0.002349, loss_freq: 0.025768
[06:31:20.848] iteration 22636: loss: 0.044360, loss_s1: 0.040185, loss_fp: 0.004105, loss_freq: 0.024515
[06:31:21.460] iteration 22637: loss: 0.059247, loss_s1: 0.066308, loss_fp: 0.003685, loss_freq: 0.010281
[06:31:22.065] iteration 22638: loss: 0.100771, loss_s1: 0.067870, loss_fp: 0.006272, loss_freq: 0.031750
[06:31:22.672] iteration 22639: loss: 0.048217, loss_s1: 0.040571, loss_fp: 0.003805, loss_freq: 0.016408
[06:31:23.287] iteration 22640: loss: 0.098807, loss_s1: 0.094364, loss_fp: 0.003663, loss_freq: 0.067085
[06:31:23.982] iteration 22641: loss: 0.081650, loss_s1: 0.067574, loss_fp: 0.004472, loss_freq: 0.066570
[06:31:24.962] iteration 22642: loss: 0.052448, loss_s1: 0.032557, loss_fp: 0.003529, loss_freq: 0.027159
[06:31:25.798] iteration 22643: loss: 0.066082, loss_s1: 0.043034, loss_fp: 0.004428, loss_freq: 0.036229
[06:31:26.477] iteration 22644: loss: 0.054281, loss_s1: 0.065160, loss_fp: 0.001280, loss_freq: 0.016081
[06:31:27.085] iteration 22645: loss: 0.059301, loss_s1: 0.063635, loss_fp: 0.001610, loss_freq: 0.029287
[06:31:27.691] iteration 22646: loss: 0.040009, loss_s1: 0.020898, loss_fp: 0.005003, loss_freq: 0.015062
[06:31:28.304] iteration 22647: loss: 0.066325, loss_s1: 0.060261, loss_fp: 0.004232, loss_freq: 0.031267
[06:31:28.916] iteration 22648: loss: 0.042808, loss_s1: 0.035982, loss_fp: 0.003419, loss_freq: 0.015082
[06:31:29.531] iteration 22649: loss: 0.076129, loss_s1: 0.077992, loss_fp: 0.005753, loss_freq: 0.027125
[06:31:30.205] iteration 22650: loss: 0.063447, loss_s1: 0.057893, loss_fp: 0.008832, loss_freq: 0.031127
[06:31:30.846] iteration 22651: loss: 0.083648, loss_s1: 0.093627, loss_fp: 0.001518, loss_freq: 0.037186
[06:31:31.460] iteration 22652: loss: 0.063618, loss_s1: 0.055365, loss_fp: 0.002256, loss_freq: 0.016315
[06:31:32.110] iteration 22653: loss: 0.097716, loss_s1: 0.113973, loss_fp: 0.010190, loss_freq: 0.038947
[06:31:32.764] iteration 22654: loss: 0.118398, loss_s1: 0.138829, loss_fp: 0.008610, loss_freq: 0.053707
[06:31:33.423] iteration 22655: loss: 0.045577, loss_s1: 0.033417, loss_fp: 0.003766, loss_freq: 0.017895
[06:31:34.115] iteration 22656: loss: 0.082999, loss_s1: 0.100282, loss_fp: 0.004950, loss_freq: 0.025403
[06:31:34.748] iteration 22657: loss: 0.047246, loss_s1: 0.042077, loss_fp: 0.002109, loss_freq: 0.018090
[06:31:35.370] iteration 22658: loss: 0.058684, loss_s1: 0.032766, loss_fp: 0.002202, loss_freq: 0.038198
[06:31:35.995] iteration 22659: loss: 0.046489, loss_s1: 0.039350, loss_fp: 0.003780, loss_freq: 0.017093
[06:31:36.604] iteration 22660: loss: 0.050433, loss_s1: 0.050528, loss_fp: 0.002849, loss_freq: 0.014843
[06:31:37.214] iteration 22661: loss: 0.060281, loss_s1: 0.057826, loss_fp: 0.002809, loss_freq: 0.030345
[06:31:37.823] iteration 22662: loss: 0.032964, loss_s1: 0.027723, loss_fp: 0.004378, loss_freq: 0.013932
[06:31:38.452] iteration 22663: loss: 0.044880, loss_s1: 0.030515, loss_fp: 0.000755, loss_freq: 0.013262
[06:31:39.060] iteration 22664: loss: 0.046793, loss_s1: 0.032868, loss_fp: 0.002621, loss_freq: 0.029811
[06:31:39.669] iteration 22665: loss: 0.054764, loss_s1: 0.011169, loss_fp: 0.003891, loss_freq: 0.060019
[06:31:40.284] iteration 22666: loss: 0.035733, loss_s1: 0.007802, loss_fp: 0.005583, loss_freq: 0.027609
[06:31:40.935] iteration 22667: loss: 0.051759, loss_s1: 0.038344, loss_fp: 0.003789, loss_freq: 0.041188
[06:31:41.550] iteration 22668: loss: 0.055280, loss_s1: 0.034019, loss_fp: 0.002164, loss_freq: 0.024778
[06:31:42.163] iteration 22669: loss: 0.046550, loss_s1: 0.035771, loss_fp: 0.003495, loss_freq: 0.023448
[06:31:42.776] iteration 22670: loss: 0.062377, loss_s1: 0.043666, loss_fp: 0.003408, loss_freq: 0.046583
[06:31:43.390] iteration 22671: loss: 0.029181, loss_s1: 0.013401, loss_fp: 0.001739, loss_freq: 0.004533
[06:31:44.002] iteration 22672: loss: 0.042350, loss_s1: 0.018030, loss_fp: 0.001704, loss_freq: 0.024904
[06:31:44.616] iteration 22673: loss: 0.047236, loss_s1: 0.048541, loss_fp: 0.000779, loss_freq: 0.012463
[06:31:45.231] iteration 22674: loss: 0.039633, loss_s1: 0.030628, loss_fp: 0.002425, loss_freq: 0.017365
[06:31:45.840] iteration 22675: loss: 0.062263, loss_s1: 0.061150, loss_fp: 0.011734, loss_freq: 0.015655
[06:31:46.506] iteration 22676: loss: 0.046906, loss_s1: 0.038730, loss_fp: 0.004574, loss_freq: 0.021398
[06:31:47.162] iteration 22677: loss: 0.047261, loss_s1: 0.037804, loss_fp: 0.002935, loss_freq: 0.014369
[06:31:47.826] iteration 22678: loss: 0.085608, loss_s1: 0.071267, loss_fp: 0.010951, loss_freq: 0.056809
[06:31:48.489] iteration 22679: loss: 0.052896, loss_s1: 0.022137, loss_fp: 0.010519, loss_freq: 0.044773
[06:31:49.189] iteration 22680: loss: 0.049487, loss_s1: 0.052089, loss_fp: 0.001818, loss_freq: 0.025232
[06:31:49.854] iteration 22681: loss: 0.063093, loss_s1: 0.047302, loss_fp: 0.001263, loss_freq: 0.036586
[06:31:50.511] iteration 22682: loss: 0.050183, loss_s1: 0.032926, loss_fp: 0.003525, loss_freq: 0.029979
[06:31:51.160] iteration 22683: loss: 0.064158, loss_s1: 0.066117, loss_fp: 0.004332, loss_freq: 0.033187
[06:31:51.772] iteration 22684: loss: 0.066752, loss_s1: 0.077875, loss_fp: 0.005358, loss_freq: 0.019133
[06:31:52.388] iteration 22685: loss: 0.045578, loss_s1: 0.015449, loss_fp: 0.007770, loss_freq: 0.036308
[06:31:53.003] iteration 22686: loss: 0.057937, loss_s1: 0.042637, loss_fp: 0.013456, loss_freq: 0.024492
[06:31:53.612] iteration 22687: loss: 0.048197, loss_s1: 0.029847, loss_fp: 0.001331, loss_freq: 0.031051
[06:31:54.224] iteration 22688: loss: 0.099667, loss_s1: 0.093966, loss_fp: 0.008377, loss_freq: 0.061595
[06:31:54.878] iteration 22689: loss: 0.036946, loss_s1: 0.014748, loss_fp: 0.006726, loss_freq: 0.028592
[06:31:55.493] iteration 22690: loss: 0.036090, loss_s1: 0.022905, loss_fp: 0.001549, loss_freq: 0.016553
[06:31:56.104] iteration 22691: loss: 0.060274, loss_s1: 0.063321, loss_fp: 0.002360, loss_freq: 0.015769
[06:31:56.722] iteration 22692: loss: 0.058732, loss_s1: 0.037500, loss_fp: 0.003339, loss_freq: 0.042276
[06:31:57.370] iteration 22693: loss: 0.054839, loss_s1: 0.053929, loss_fp: 0.006126, loss_freq: 0.012549
[06:31:58.023] iteration 22694: loss: 0.040783, loss_s1: 0.025645, loss_fp: 0.004984, loss_freq: 0.025286
[06:31:58.708] iteration 22695: loss: 0.037683, loss_s1: 0.016766, loss_fp: 0.002502, loss_freq: 0.017774
[06:31:59.364] iteration 22696: loss: 0.060322, loss_s1: 0.042130, loss_fp: 0.005042, loss_freq: 0.041771
[06:32:00.022] iteration 22697: loss: 0.088064, loss_s1: 0.099597, loss_fp: 0.002126, loss_freq: 0.056121
[06:32:00.682] iteration 22698: loss: 0.067456, loss_s1: 0.074735, loss_fp: 0.005397, loss_freq: 0.016886
[06:32:01.331] iteration 22699: loss: 0.068379, loss_s1: 0.055008, loss_fp: 0.013412, loss_freq: 0.037265
[06:32:01.986] iteration 22700: loss: 0.043931, loss_s1: 0.028716, loss_fp: 0.008045, loss_freq: 0.012639
[06:32:02.617] iteration 22701: loss: 0.076346, loss_s1: 0.088091, loss_fp: 0.006761, loss_freq: 0.023866
[06:32:03.223] iteration 22702: loss: 0.055107, loss_s1: 0.050264, loss_fp: 0.005422, loss_freq: 0.034345
[06:32:03.845] iteration 22703: loss: 0.090044, loss_s1: 0.082538, loss_fp: 0.014301, loss_freq: 0.041333
[06:32:04.460] iteration 22704: loss: 0.051584, loss_s1: 0.050597, loss_fp: 0.001404, loss_freq: 0.028037
[06:32:05.072] iteration 22705: loss: 0.104022, loss_s1: 0.135393, loss_fp: 0.004688, loss_freq: 0.040073
[06:32:05.679] iteration 22706: loss: 0.055926, loss_s1: 0.063592, loss_fp: 0.001239, loss_freq: 0.022421
[06:32:06.284] iteration 22707: loss: 0.092102, loss_s1: 0.107141, loss_fp: 0.002876, loss_freq: 0.031949
[06:32:06.888] iteration 22708: loss: 0.057260, loss_s1: 0.040641, loss_fp: 0.003218, loss_freq: 0.034226
[06:32:07.503] iteration 22709: loss: 0.055329, loss_s1: 0.026600, loss_fp: 0.008320, loss_freq: 0.049047
[06:32:08.116] iteration 22710: loss: 0.085780, loss_s1: 0.118701, loss_fp: 0.002215, loss_freq: 0.014587
[06:32:08.730] iteration 22711: loss: 0.068902, loss_s1: 0.079219, loss_fp: 0.007724, loss_freq: 0.025325
[06:32:09.340] iteration 22712: loss: 0.069505, loss_s1: 0.050792, loss_fp: 0.007691, loss_freq: 0.016147
[06:32:09.950] iteration 22713: loss: 0.036243, loss_s1: 0.016146, loss_fp: 0.004492, loss_freq: 0.023376
[06:32:10.560] iteration 22714: loss: 0.040636, loss_s1: 0.017809, loss_fp: 0.003563, loss_freq: 0.029121
[06:32:11.171] iteration 22715: loss: 0.022807, loss_s1: 0.014369, loss_fp: 0.000401, loss_freq: 0.005745
[06:32:11.782] iteration 22716: loss: 0.070114, loss_s1: 0.070911, loss_fp: 0.007477, loss_freq: 0.020643
[06:32:12.397] iteration 22717: loss: 0.101476, loss_s1: 0.123360, loss_fp: 0.001494, loss_freq: 0.047094
[06:32:13.012] iteration 22718: loss: 0.040277, loss_s1: 0.029423, loss_fp: 0.002452, loss_freq: 0.023245
[06:32:13.619] iteration 22719: loss: 0.061511, loss_s1: 0.025752, loss_fp: 0.011267, loss_freq: 0.049512
[06:32:14.226] iteration 22720: loss: 0.056625, loss_s1: 0.052344, loss_fp: 0.004694, loss_freq: 0.027871
[06:32:14.835] iteration 22721: loss: 0.069644, loss_s1: 0.076784, loss_fp: 0.013628, loss_freq: 0.006843
[06:32:15.443] iteration 22722: loss: 0.051982, loss_s1: 0.047578, loss_fp: 0.001074, loss_freq: 0.018958
[06:32:16.078] iteration 22723: loss: 0.042839, loss_s1: 0.034964, loss_fp: 0.005015, loss_freq: 0.016662
[06:32:16.689] iteration 22724: loss: 0.033715, loss_s1: 0.021346, loss_fp: 0.001235, loss_freq: 0.015260
[06:32:17.305] iteration 22725: loss: 0.071165, loss_s1: 0.041300, loss_fp: 0.004867, loss_freq: 0.054324
[06:32:17.942] iteration 22726: loss: 0.062261, loss_s1: 0.028620, loss_fp: 0.009211, loss_freq: 0.054847
[06:32:18.549] iteration 22727: loss: 0.063481, loss_s1: 0.065200, loss_fp: 0.004348, loss_freq: 0.021259
[06:32:19.163] iteration 22728: loss: 0.058625, loss_s1: 0.025117, loss_fp: 0.008678, loss_freq: 0.051269
[06:32:19.772] iteration 22729: loss: 0.082282, loss_s1: 0.059174, loss_fp: 0.005625, loss_freq: 0.071414
[06:32:20.377] iteration 22730: loss: 0.056423, loss_s1: 0.030549, loss_fp: 0.009242, loss_freq: 0.024488
[06:32:20.982] iteration 22731: loss: 0.041972, loss_s1: 0.037277, loss_fp: 0.001475, loss_freq: 0.004362
[06:32:21.590] iteration 22732: loss: 0.050646, loss_s1: 0.056390, loss_fp: 0.005159, loss_freq: 0.020103
[06:32:22.215] iteration 22733: loss: 0.061761, loss_s1: 0.050296, loss_fp: 0.005740, loss_freq: 0.033699
[06:32:22.843] iteration 22734: loss: 0.042702, loss_s1: 0.029335, loss_fp: 0.005658, loss_freq: 0.020448
[06:32:23.465] iteration 22735: loss: 0.052295, loss_s1: 0.049521, loss_fp: 0.003892, loss_freq: 0.016904
[06:32:24.078] iteration 22736: loss: 0.079098, loss_s1: 0.070363, loss_fp: 0.003512, loss_freq: 0.047050
[06:32:24.687] iteration 22737: loss: 0.063823, loss_s1: 0.035794, loss_fp: 0.002452, loss_freq: 0.063101
[06:32:25.296] iteration 22738: loss: 0.057410, loss_s1: 0.029763, loss_fp: 0.008072, loss_freq: 0.033938
[06:32:25.910] iteration 22739: loss: 0.047534, loss_s1: 0.036977, loss_fp: 0.008330, loss_freq: 0.025790
[06:32:26.517] iteration 22740: loss: 0.073099, loss_s1: 0.023531, loss_fp: 0.020261, loss_freq: 0.068387
[06:32:27.124] iteration 22741: loss: 0.027231, loss_s1: 0.018282, loss_fp: 0.003304, loss_freq: 0.010255
[06:32:27.737] iteration 22742: loss: 0.051788, loss_s1: 0.025804, loss_fp: 0.002784, loss_freq: 0.021558
[06:32:28.360] iteration 22743: loss: 0.053055, loss_s1: 0.035713, loss_fp: 0.003395, loss_freq: 0.033301
[06:32:28.971] iteration 22744: loss: 0.060936, loss_s1: 0.073233, loss_fp: 0.005013, loss_freq: 0.017002
[06:32:29.587] iteration 22745: loss: 0.084218, loss_s1: 0.086732, loss_fp: 0.006260, loss_freq: 0.039916
[06:32:30.234] iteration 22746: loss: 0.036442, loss_s1: 0.027779, loss_fp: 0.008521, loss_freq: 0.009674
[06:32:30.888] iteration 22747: loss: 0.048942, loss_s1: 0.025395, loss_fp: 0.003039, loss_freq: 0.027977
[06:32:31.543] iteration 22748: loss: 0.057624, loss_s1: 0.028197, loss_fp: 0.004688, loss_freq: 0.054633
[06:32:32.152] iteration 22749: loss: 0.077716, loss_s1: 0.086627, loss_fp: 0.005369, loss_freq: 0.038352
[06:32:32.774] iteration 22750: loss: 0.065070, loss_s1: 0.061076, loss_fp: 0.007972, loss_freq: 0.036594
[06:32:33.398] iteration 22751: loss: 0.061220, loss_s1: 0.035085, loss_fp: 0.001483, loss_freq: 0.050004
[06:32:34.019] iteration 22752: loss: 0.053014, loss_s1: 0.052742, loss_fp: 0.001480, loss_freq: 0.019841
[06:32:34.627] iteration 22753: loss: 0.036398, loss_s1: 0.013936, loss_fp: 0.006588, loss_freq: 0.023163
[06:32:35.242] iteration 22754: loss: 0.044233, loss_s1: 0.029683, loss_fp: 0.010523, loss_freq: 0.017569
[06:32:35.863] iteration 22755: loss: 0.034126, loss_s1: 0.019815, loss_fp: 0.003620, loss_freq: 0.013370
[06:32:36.480] iteration 22756: loss: 0.074577, loss_s1: 0.042080, loss_fp: 0.003003, loss_freq: 0.066275
[06:32:37.096] iteration 22757: loss: 0.058802, loss_s1: 0.040215, loss_fp: 0.003136, loss_freq: 0.032349
[06:32:37.718] iteration 22758: loss: 0.045827, loss_s1: 0.044371, loss_fp: 0.002390, loss_freq: 0.021047
[06:32:38.333] iteration 22759: loss: 0.056902, loss_s1: 0.043350, loss_fp: 0.002272, loss_freq: 0.044783
[06:32:38.957] iteration 22760: loss: 0.055028, loss_s1: 0.054955, loss_fp: 0.003283, loss_freq: 0.018437
[06:32:39.569] iteration 22761: loss: 0.078440, loss_s1: 0.078342, loss_fp: 0.015303, loss_freq: 0.023784
[06:32:40.180] iteration 22762: loss: 0.040405, loss_s1: 0.030843, loss_fp: 0.002607, loss_freq: 0.014333
[06:32:40.786] iteration 22763: loss: 0.096990, loss_s1: 0.114206, loss_fp: 0.002851, loss_freq: 0.053505
[06:32:41.395] iteration 22764: loss: 0.084311, loss_s1: 0.070715, loss_fp: 0.012249, loss_freq: 0.055337
[06:32:42.003] iteration 22765: loss: 0.069754, loss_s1: 0.065883, loss_fp: 0.002121, loss_freq: 0.032663
[06:32:42.612] iteration 22766: loss: 0.043581, loss_s1: 0.046767, loss_fp: 0.002122, loss_freq: 0.005353
[06:32:43.225] iteration 22767: loss: 0.037858, loss_s1: 0.018882, loss_fp: 0.002955, loss_freq: 0.032647
[06:32:43.830] iteration 22768: loss: 0.055198, loss_s1: 0.034121, loss_fp: 0.003257, loss_freq: 0.037884
[06:32:44.436] iteration 22769: loss: 0.058294, loss_s1: 0.043897, loss_fp: 0.006735, loss_freq: 0.033792
[06:32:45.043] iteration 22770: loss: 0.062777, loss_s1: 0.055720, loss_fp: 0.005290, loss_freq: 0.030694
[06:32:45.651] iteration 22771: loss: 0.041179, loss_s1: 0.032630, loss_fp: 0.002884, loss_freq: 0.012499
[06:32:46.264] iteration 22772: loss: 0.039241, loss_s1: 0.028650, loss_fp: 0.003267, loss_freq: 0.023596
[06:32:46.921] iteration 22773: loss: 0.052442, loss_s1: 0.036485, loss_fp: 0.008373, loss_freq: 0.026327
[06:32:47.581] iteration 22774: loss: 0.047399, loss_s1: 0.035679, loss_fp: 0.015774, loss_freq: 0.017561
[06:32:48.238] iteration 22775: loss: 0.044179, loss_s1: 0.033080, loss_fp: 0.003407, loss_freq: 0.022702
[06:32:48.893] iteration 22776: loss: 0.112654, loss_s1: 0.166637, loss_fp: 0.002315, loss_freq: 0.026134
[06:32:49.556] iteration 22777: loss: 0.057832, loss_s1: 0.038518, loss_fp: 0.001145, loss_freq: 0.036713
[06:32:50.166] iteration 22778: loss: 0.076215, loss_s1: 0.080249, loss_fp: 0.001432, loss_freq: 0.037046
[06:32:50.792] iteration 22779: loss: 0.067824, loss_s1: 0.058501, loss_fp: 0.004281, loss_freq: 0.041166
[06:32:51.395] iteration 22780: loss: 0.069938, loss_s1: 0.081137, loss_fp: 0.002631, loss_freq: 0.020714
[06:32:52.331] iteration 22781: loss: 0.089184, loss_s1: 0.074279, loss_fp: 0.003842, loss_freq: 0.057694
[06:32:52.947] iteration 22782: loss: 0.050119, loss_s1: 0.040589, loss_fp: 0.005905, loss_freq: 0.022362
[06:32:53.561] iteration 22783: loss: 0.042386, loss_s1: 0.019472, loss_fp: 0.003645, loss_freq: 0.033576
[06:32:54.175] iteration 22784: loss: 0.048055, loss_s1: 0.043694, loss_fp: 0.003209, loss_freq: 0.019040
[06:32:54.792] iteration 22785: loss: 0.037435, loss_s1: 0.032157, loss_fp: 0.001371, loss_freq: 0.016205
[06:32:55.502] iteration 22786: loss: 0.053677, loss_s1: 0.032457, loss_fp: 0.002556, loss_freq: 0.037116
[06:32:56.261] iteration 22787: loss: 0.078312, loss_s1: 0.096287, loss_fp: 0.002445, loss_freq: 0.023501
[06:32:56.971] iteration 22788: loss: 0.070094, loss_s1: 0.073266, loss_fp: 0.006567, loss_freq: 0.033325
[06:32:57.588] iteration 22789: loss: 0.074390, loss_s1: 0.073725, loss_fp: 0.001292, loss_freq: 0.026914
[06:32:58.190] iteration 22790: loss: 0.087250, loss_s1: 0.071367, loss_fp: 0.006163, loss_freq: 0.058666
[06:32:58.798] iteration 22791: loss: 0.070487, loss_s1: 0.067931, loss_fp: 0.001729, loss_freq: 0.039686
[06:32:59.404] iteration 22792: loss: 0.055163, loss_s1: 0.033836, loss_fp: 0.006565, loss_freq: 0.037011
[06:33:00.012] iteration 22793: loss: 0.053167, loss_s1: 0.051499, loss_fp: 0.005156, loss_freq: 0.015817
[06:33:00.613] iteration 22794: loss: 0.073291, loss_s1: 0.083407, loss_fp: 0.007219, loss_freq: 0.022721
[06:33:01.216] iteration 22795: loss: 0.048872, loss_s1: 0.037435, loss_fp: 0.001741, loss_freq: 0.024684
[06:33:01.820] iteration 22796: loss: 0.057041, loss_s1: 0.058907, loss_fp: 0.001856, loss_freq: 0.025023
[06:33:02.424] iteration 22797: loss: 0.126239, loss_s1: 0.149068, loss_fp: 0.002688, loss_freq: 0.076242
[06:33:03.039] iteration 22798: loss: 0.033357, loss_s1: 0.017180, loss_fp: 0.003421, loss_freq: 0.013070
[06:33:03.644] iteration 22799: loss: 0.055055, loss_s1: 0.050129, loss_fp: 0.007009, loss_freq: 0.022108
[06:33:04.250] iteration 22800: loss: 0.038522, loss_s1: 0.032338, loss_fp: 0.001943, loss_freq: 0.011713
[06:33:07.490] iteration 22800 : mean_dice : 0.734753
[06:33:08.118] iteration 22801: loss: 0.046415, loss_s1: 0.030032, loss_fp: 0.003067, loss_freq: 0.027748
[06:33:08.726] iteration 22802: loss: 0.063150, loss_s1: 0.037720, loss_fp: 0.008279, loss_freq: 0.059223
[06:33:09.333] iteration 22803: loss: 0.085355, loss_s1: 0.066529, loss_fp: 0.003549, loss_freq: 0.049850
[06:33:09.936] iteration 22804: loss: 0.065388, loss_s1: 0.051073, loss_fp: 0.008193, loss_freq: 0.047015
[06:33:10.553] iteration 22805: loss: 0.054763, loss_s1: 0.044149, loss_fp: 0.006296, loss_freq: 0.025272
[06:33:11.162] iteration 22806: loss: 0.063325, loss_s1: 0.045295, loss_fp: 0.006358, loss_freq: 0.045825
[06:33:11.771] iteration 22807: loss: 0.039120, loss_s1: 0.025058, loss_fp: 0.004780, loss_freq: 0.010736
[06:33:12.380] iteration 22808: loss: 0.083677, loss_s1: 0.100884, loss_fp: 0.012913, loss_freq: 0.009170
[06:33:12.997] iteration 22809: loss: 0.035263, loss_s1: 0.013991, loss_fp: 0.001390, loss_freq: 0.028745
[06:33:13.605] iteration 22810: loss: 0.071385, loss_s1: 0.080971, loss_fp: 0.004372, loss_freq: 0.024496
[06:33:14.208] iteration 22811: loss: 0.069131, loss_s1: 0.038020, loss_fp: 0.001776, loss_freq: 0.066985
[06:33:14.839] iteration 22812: loss: 0.070729, loss_s1: 0.038061, loss_fp: 0.002864, loss_freq: 0.063168
[06:33:15.444] iteration 22813: loss: 0.076289, loss_s1: 0.058328, loss_fp: 0.011016, loss_freq: 0.056623
[06:33:16.051] iteration 22814: loss: 0.060288, loss_s1: 0.038649, loss_fp: 0.004396, loss_freq: 0.043520
[06:33:16.659] iteration 22815: loss: 0.059073, loss_s1: 0.053522, loss_fp: 0.005359, loss_freq: 0.039721
[06:33:17.316] iteration 22816: loss: 0.044375, loss_s1: 0.022401, loss_fp: 0.003651, loss_freq: 0.022350
[06:33:17.936] iteration 22817: loss: 0.052584, loss_s1: 0.042946, loss_fp: 0.001088, loss_freq: 0.020974
[06:33:18.545] iteration 22818: loss: 0.071101, loss_s1: 0.077671, loss_fp: 0.002532, loss_freq: 0.031340
[06:33:19.149] iteration 22819: loss: 0.088447, loss_s1: 0.061106, loss_fp: 0.007174, loss_freq: 0.072307
[06:33:19.753] iteration 22820: loss: 0.064813, loss_s1: 0.049766, loss_fp: 0.007975, loss_freq: 0.026677
[06:33:20.360] iteration 22821: loss: 0.058558, loss_s1: 0.040385, loss_fp: 0.005567, loss_freq: 0.024020
[06:33:20.977] iteration 22822: loss: 0.077954, loss_s1: 0.053506, loss_fp: 0.007476, loss_freq: 0.057718
[06:33:21.583] iteration 22823: loss: 0.077435, loss_s1: 0.078746, loss_fp: 0.004061, loss_freq: 0.044881
[06:33:22.192] iteration 22824: loss: 0.125199, loss_s1: 0.147979, loss_fp: 0.007158, loss_freq: 0.069391
[06:33:22.804] iteration 22825: loss: 0.064357, loss_s1: 0.055239, loss_fp: 0.002968, loss_freq: 0.037859
[06:33:23.413] iteration 22826: loss: 0.060378, loss_s1: 0.065517, loss_fp: 0.002199, loss_freq: 0.023012
[06:33:24.021] iteration 22827: loss: 0.064126, loss_s1: 0.057859, loss_fp: 0.005268, loss_freq: 0.031416
[06:33:24.631] iteration 22828: loss: 0.066486, loss_s1: 0.039885, loss_fp: 0.003866, loss_freq: 0.056717
[06:33:25.261] iteration 22829: loss: 0.047617, loss_s1: 0.039001, loss_fp: 0.003702, loss_freq: 0.012139
[06:33:25.872] iteration 22830: loss: 0.033355, loss_s1: 0.015116, loss_fp: 0.002728, loss_freq: 0.011679
[06:33:26.486] iteration 22831: loss: 0.036527, loss_s1: 0.022688, loss_fp: 0.002069, loss_freq: 0.018196
[06:33:27.094] iteration 22832: loss: 0.096613, loss_s1: 0.108133, loss_fp: 0.008464, loss_freq: 0.055245
[06:33:27.698] iteration 22833: loss: 0.034527, loss_s1: 0.016008, loss_fp: 0.002425, loss_freq: 0.014487
[06:33:28.307] iteration 22834: loss: 0.051319, loss_s1: 0.037231, loss_fp: 0.007758, loss_freq: 0.024828
[06:33:28.917] iteration 22835: loss: 0.063667, loss_s1: 0.047792, loss_fp: 0.006512, loss_freq: 0.036430
[06:33:29.531] iteration 22836: loss: 0.043781, loss_s1: 0.028666, loss_fp: 0.001336, loss_freq: 0.025423
[06:33:30.142] iteration 22837: loss: 0.062940, loss_s1: 0.045786, loss_fp: 0.004804, loss_freq: 0.049985
[06:33:30.756] iteration 22838: loss: 0.056100, loss_s1: 0.035051, loss_fp: 0.002345, loss_freq: 0.011563
[06:33:31.378] iteration 22839: loss: 0.049314, loss_s1: 0.021403, loss_fp: 0.003427, loss_freq: 0.040490
[06:33:32.024] iteration 22840: loss: 0.056051, loss_s1: 0.054825, loss_fp: 0.002175, loss_freq: 0.020632
[06:33:32.632] iteration 22841: loss: 0.025367, loss_s1: 0.015434, loss_fp: 0.002358, loss_freq: 0.007044
[06:33:33.254] iteration 22842: loss: 0.079257, loss_s1: 0.068168, loss_fp: 0.003082, loss_freq: 0.053281
[06:33:33.862] iteration 22843: loss: 0.053510, loss_s1: 0.037417, loss_fp: 0.003432, loss_freq: 0.033320
[06:33:34.473] iteration 22844: loss: 0.042554, loss_s1: 0.029162, loss_fp: 0.001611, loss_freq: 0.015827
[06:33:35.084] iteration 22845: loss: 0.039765, loss_s1: 0.035884, loss_fp: 0.001654, loss_freq: 0.009645
[06:33:35.694] iteration 22846: loss: 0.045787, loss_s1: 0.040401, loss_fp: 0.002623, loss_freq: 0.023648
[06:33:36.307] iteration 22847: loss: 0.047087, loss_s1: 0.019567, loss_fp: 0.003655, loss_freq: 0.019245
[06:33:36.919] iteration 22848: loss: 0.085065, loss_s1: 0.102585, loss_fp: 0.009637, loss_freq: 0.032518
[06:33:37.532] iteration 22849: loss: 0.037972, loss_s1: 0.030002, loss_fp: 0.002051, loss_freq: 0.013559
[06:33:38.204] iteration 22850: loss: 0.060556, loss_s1: 0.055767, loss_fp: 0.002102, loss_freq: 0.040484
[06:33:38.879] iteration 22851: loss: 0.076677, loss_s1: 0.054981, loss_fp: 0.003950, loss_freq: 0.057195
[06:33:39.532] iteration 22852: loss: 0.043774, loss_s1: 0.024174, loss_fp: 0.009857, loss_freq: 0.019141
[06:33:40.165] iteration 22853: loss: 0.044283, loss_s1: 0.020356, loss_fp: 0.004941, loss_freq: 0.035354
[06:33:40.771] iteration 22854: loss: 0.052762, loss_s1: 0.046217, loss_fp: 0.006098, loss_freq: 0.023352
[06:33:41.388] iteration 22855: loss: 0.073291, loss_s1: 0.024953, loss_fp: 0.004575, loss_freq: 0.085460
[06:33:42.002] iteration 22856: loss: 0.090426, loss_s1: 0.065478, loss_fp: 0.011837, loss_freq: 0.074738
[06:33:42.686] iteration 22857: loss: 0.055549, loss_s1: 0.037915, loss_fp: 0.001444, loss_freq: 0.025754
[06:33:43.347] iteration 22858: loss: 0.070021, loss_s1: 0.060998, loss_fp: 0.005226, loss_freq: 0.039747
[06:33:44.012] iteration 22859: loss: 0.031207, loss_s1: 0.014143, loss_fp: 0.005101, loss_freq: 0.010790
[06:33:44.679] iteration 22860: loss: 0.048073, loss_s1: 0.036942, loss_fp: 0.003970, loss_freq: 0.018351
[06:33:45.338] iteration 22861: loss: 0.067636, loss_s1: 0.071218, loss_fp: 0.004688, loss_freq: 0.022749
[06:33:45.975] iteration 22862: loss: 0.044332, loss_s1: 0.040177, loss_fp: 0.004132, loss_freq: 0.011684
[06:33:46.585] iteration 22863: loss: 0.044878, loss_s1: 0.036892, loss_fp: 0.000789, loss_freq: 0.024928
[06:33:47.195] iteration 22864: loss: 0.030640, loss_s1: 0.013496, loss_fp: 0.002167, loss_freq: 0.015446
[06:33:47.856] iteration 22865: loss: 0.058929, loss_s1: 0.026045, loss_fp: 0.003564, loss_freq: 0.028276
[06:33:48.483] iteration 22866: loss: 0.045413, loss_s1: 0.035757, loss_fp: 0.003595, loss_freq: 0.018029
[06:33:49.092] iteration 22867: loss: 0.035253, loss_s1: 0.034885, loss_fp: 0.002574, loss_freq: 0.010513
[06:33:49.700] iteration 22868: loss: 0.132118, loss_s1: 0.194533, loss_fp: 0.007034, loss_freq: 0.023221
[06:33:50.315] iteration 22869: loss: 0.075245, loss_s1: 0.064702, loss_fp: 0.008276, loss_freq: 0.047876
[06:33:50.951] iteration 22870: loss: 0.057282, loss_s1: 0.032623, loss_fp: 0.004120, loss_freq: 0.026818
[06:33:51.558] iteration 22871: loss: 0.059386, loss_s1: 0.061349, loss_fp: 0.003287, loss_freq: 0.023687
[06:33:52.171] iteration 22872: loss: 0.066259, loss_s1: 0.059750, loss_fp: 0.003031, loss_freq: 0.046839
[06:33:52.783] iteration 22873: loss: 0.056373, loss_s1: 0.052764, loss_fp: 0.005051, loss_freq: 0.019464
[06:33:53.411] iteration 22874: loss: 0.064933, loss_s1: 0.049473, loss_fp: 0.001148, loss_freq: 0.040721
[06:33:54.031] iteration 22875: loss: 0.059112, loss_s1: 0.032825, loss_fp: 0.005692, loss_freq: 0.049844
[06:33:54.653] iteration 22876: loss: 0.047189, loss_s1: 0.040775, loss_fp: 0.002240, loss_freq: 0.023034
[06:33:55.293] iteration 22877: loss: 0.125721, loss_s1: 0.132436, loss_fp: 0.001709, loss_freq: 0.064879
[06:33:55.906] iteration 22878: loss: 0.066520, loss_s1: 0.050519, loss_fp: 0.001870, loss_freq: 0.048218
[06:33:56.517] iteration 22879: loss: 0.081084, loss_s1: 0.065780, loss_fp: 0.004487, loss_freq: 0.064667
[06:33:57.122] iteration 22880: loss: 0.051872, loss_s1: 0.044765, loss_fp: 0.001621, loss_freq: 0.010968
[06:33:57.727] iteration 22881: loss: 0.068882, loss_s1: 0.073057, loss_fp: 0.012968, loss_freq: 0.031167
[06:33:58.331] iteration 22882: loss: 0.057187, loss_s1: 0.045399, loss_fp: 0.004629, loss_freq: 0.019684
[06:33:58.938] iteration 22883: loss: 0.036952, loss_s1: 0.024738, loss_fp: 0.003655, loss_freq: 0.016803
[06:33:59.543] iteration 22884: loss: 0.046052, loss_s1: 0.032613, loss_fp: 0.001998, loss_freq: 0.028710
[06:34:00.147] iteration 22885: loss: 0.053563, loss_s1: 0.061599, loss_fp: 0.001283, loss_freq: 0.021670
[06:34:00.757] iteration 22886: loss: 0.068081, loss_s1: 0.037589, loss_fp: 0.004251, loss_freq: 0.014366
[06:34:01.367] iteration 22887: loss: 0.078433, loss_s1: 0.061190, loss_fp: 0.009216, loss_freq: 0.033024
[06:34:01.975] iteration 22888: loss: 0.038530, loss_s1: 0.026548, loss_fp: 0.002941, loss_freq: 0.021494
[06:34:02.579] iteration 22889: loss: 0.062248, loss_s1: 0.056259, loss_fp: 0.006052, loss_freq: 0.024916
[06:34:03.192] iteration 22890: loss: 0.048614, loss_s1: 0.046685, loss_fp: 0.004754, loss_freq: 0.022872
[06:34:03.849] iteration 22891: loss: 0.061818, loss_s1: 0.065291, loss_fp: 0.003508, loss_freq: 0.018443
[06:34:04.506] iteration 22892: loss: 0.072896, loss_s1: 0.084546, loss_fp: 0.004268, loss_freq: 0.025802
[06:34:05.152] iteration 22893: loss: 0.038294, loss_s1: 0.020777, loss_fp: 0.003277, loss_freq: 0.022549
[06:34:05.764] iteration 22894: loss: 0.028523, loss_s1: 0.018999, loss_fp: 0.004533, loss_freq: 0.007743
[06:34:06.373] iteration 22895: loss: 0.057673, loss_s1: 0.032791, loss_fp: 0.011042, loss_freq: 0.038482
[06:34:06.984] iteration 22896: loss: 0.055607, loss_s1: 0.039710, loss_fp: 0.007174, loss_freq: 0.030541
[06:34:07.631] iteration 22897: loss: 0.042430, loss_s1: 0.034701, loss_fp: 0.003826, loss_freq: 0.013814
[06:34:08.237] iteration 22898: loss: 0.083801, loss_s1: 0.082851, loss_fp: 0.016092, loss_freq: 0.041392
[06:34:08.851] iteration 22899: loss: 0.081704, loss_s1: 0.067050, loss_fp: 0.004049, loss_freq: 0.060207
[06:34:09.464] iteration 22900: loss: 0.030589, loss_s1: 0.020015, loss_fp: 0.000441, loss_freq: 0.007080
[06:34:10.071] iteration 22901: loss: 0.057850, loss_s1: 0.066784, loss_fp: 0.002897, loss_freq: 0.014468
[06:34:10.678] iteration 22902: loss: 0.096883, loss_s1: 0.129286, loss_fp: 0.001562, loss_freq: 0.040417
[06:34:11.288] iteration 22903: loss: 0.062558, loss_s1: 0.057447, loss_fp: 0.018885, loss_freq: 0.020564
[06:34:11.904] iteration 22904: loss: 0.038414, loss_s1: 0.017726, loss_fp: 0.010254, loss_freq: 0.013558
[06:34:12.525] iteration 22905: loss: 0.053779, loss_s1: 0.047479, loss_fp: 0.006445, loss_freq: 0.018252
[06:34:13.135] iteration 22906: loss: 0.077067, loss_s1: 0.102008, loss_fp: 0.001923, loss_freq: 0.021791
[06:34:13.756] iteration 22907: loss: 0.063839, loss_s1: 0.031613, loss_fp: 0.006623, loss_freq: 0.058593
[06:34:14.372] iteration 22908: loss: 0.050233, loss_s1: 0.022410, loss_fp: 0.002031, loss_freq: 0.036690
[06:34:14.983] iteration 22909: loss: 0.057636, loss_s1: 0.050157, loss_fp: 0.011441, loss_freq: 0.030747
[06:34:15.591] iteration 22910: loss: 0.059379, loss_s1: 0.020877, loss_fp: 0.002728, loss_freq: 0.053311
[06:34:16.195] iteration 22911: loss: 0.073522, loss_s1: 0.093157, loss_fp: 0.002336, loss_freq: 0.025662
[06:34:16.803] iteration 22912: loss: 0.052840, loss_s1: 0.039186, loss_fp: 0.003439, loss_freq: 0.013838
[06:34:17.407] iteration 22913: loss: 0.092968, loss_s1: 0.071890, loss_fp: 0.006664, loss_freq: 0.054084
[06:34:18.009] iteration 22914: loss: 0.040604, loss_s1: 0.037301, loss_fp: 0.004316, loss_freq: 0.012503
[06:34:18.616] iteration 22915: loss: 0.062799, loss_s1: 0.065672, loss_fp: 0.001571, loss_freq: 0.014711
[06:34:19.224] iteration 22916: loss: 0.042850, loss_s1: 0.042544, loss_fp: 0.009290, loss_freq: 0.011473
[06:34:19.832] iteration 22917: loss: 0.074203, loss_s1: 0.038369, loss_fp: 0.002218, loss_freq: 0.020254
[06:34:20.438] iteration 22918: loss: 0.065418, loss_s1: 0.049822, loss_fp: 0.012685, loss_freq: 0.044699
[06:34:21.047] iteration 22919: loss: 0.106197, loss_s1: 0.119902, loss_fp: 0.011009, loss_freq: 0.049219
[06:34:21.655] iteration 22920: loss: 0.073199, loss_s1: 0.080587, loss_fp: 0.004976, loss_freq: 0.038836
[06:34:22.277] iteration 22921: loss: 0.050256, loss_s1: 0.043225, loss_fp: 0.002420, loss_freq: 0.024054
[06:34:22.885] iteration 22922: loss: 0.055610, loss_s1: 0.049212, loss_fp: 0.002761, loss_freq: 0.025397
[06:34:23.492] iteration 22923: loss: 0.033720, loss_s1: 0.015236, loss_fp: 0.002647, loss_freq: 0.024356
[06:34:24.104] iteration 22924: loss: 0.051131, loss_s1: 0.049128, loss_fp: 0.009102, loss_freq: 0.011598
[06:34:24.722] iteration 22925: loss: 0.025966, loss_s1: 0.007095, loss_fp: 0.003692, loss_freq: 0.010694
[06:34:25.336] iteration 22926: loss: 0.041496, loss_s1: 0.022333, loss_fp: 0.002498, loss_freq: 0.019352
[06:34:25.949] iteration 22927: loss: 0.048207, loss_s1: 0.040434, loss_fp: 0.003900, loss_freq: 0.023529
[06:34:26.557] iteration 22928: loss: 0.063256, loss_s1: 0.067542, loss_fp: 0.003045, loss_freq: 0.027305
[06:34:27.164] iteration 22929: loss: 0.083309, loss_s1: 0.096852, loss_fp: 0.005263, loss_freq: 0.044916
[06:34:27.769] iteration 22930: loss: 0.068408, loss_s1: 0.049053, loss_fp: 0.003469, loss_freq: 0.052450
[06:34:28.384] iteration 22931: loss: 0.063625, loss_s1: 0.047112, loss_fp: 0.003357, loss_freq: 0.041116
[06:34:28.989] iteration 22932: loss: 0.089183, loss_s1: 0.092895, loss_fp: 0.001335, loss_freq: 0.050053
[06:34:29.598] iteration 22933: loss: 0.083321, loss_s1: 0.088868, loss_fp: 0.011807, loss_freq: 0.039666
[06:34:30.211] iteration 22934: loss: 0.088497, loss_s1: 0.067198, loss_fp: 0.006912, loss_freq: 0.057196
[06:34:30.821] iteration 22935: loss: 0.071372, loss_s1: 0.059257, loss_fp: 0.002926, loss_freq: 0.040994
[06:34:31.432] iteration 22936: loss: 0.033035, loss_s1: 0.014284, loss_fp: 0.001033, loss_freq: 0.010292
[06:34:32.039] iteration 22937: loss: 0.038646, loss_s1: 0.023204, loss_fp: 0.008390, loss_freq: 0.022424
[06:34:32.649] iteration 22938: loss: 0.091621, loss_s1: 0.097103, loss_fp: 0.003546, loss_freq: 0.045319
[06:34:33.262] iteration 22939: loss: 0.069236, loss_s1: 0.083844, loss_fp: 0.003434, loss_freq: 0.020743
[06:34:33.871] iteration 22940: loss: 0.122728, loss_s1: 0.154702, loss_fp: 0.002522, loss_freq: 0.059491
[06:34:34.491] iteration 22941: loss: 0.076451, loss_s1: 0.104035, loss_fp: 0.005615, loss_freq: 0.013613
[06:34:35.100] iteration 22942: loss: 0.067086, loss_s1: 0.064978, loss_fp: 0.003733, loss_freq: 0.041670
[06:34:35.706] iteration 22943: loss: 0.055918, loss_s1: 0.025139, loss_fp: 0.007742, loss_freq: 0.027925
[06:34:36.312] iteration 22944: loss: 0.042572, loss_s1: 0.035859, loss_fp: 0.006079, loss_freq: 0.013384
[06:34:36.920] iteration 22945: loss: 0.034738, loss_s1: 0.021606, loss_fp: 0.001725, loss_freq: 0.012798
[06:34:37.524] iteration 22946: loss: 0.102506, loss_s1: 0.115376, loss_fp: 0.001150, loss_freq: 0.044646
[06:34:38.127] iteration 22947: loss: 0.056914, loss_s1: 0.023695, loss_fp: 0.003211, loss_freq: 0.053267
[06:34:38.736] iteration 22948: loss: 0.067300, loss_s1: 0.058405, loss_fp: 0.001843, loss_freq: 0.038934
[06:34:39.337] iteration 22949: loss: 0.102723, loss_s1: 0.086753, loss_fp: 0.014242, loss_freq: 0.079567
[06:34:39.939] iteration 22950: loss: 0.047007, loss_s1: 0.034641, loss_fp: 0.010185, loss_freq: 0.007751
[06:34:40.935] iteration 22951: loss: 0.055468, loss_s1: 0.055221, loss_fp: 0.000919, loss_freq: 0.021758
[06:34:41.590] iteration 22952: loss: 0.046733, loss_s1: 0.032269, loss_fp: 0.001933, loss_freq: 0.018933
[06:34:42.245] iteration 22953: loss: 0.047832, loss_s1: 0.035848, loss_fp: 0.003704, loss_freq: 0.027737
[06:34:42.905] iteration 22954: loss: 0.043772, loss_s1: 0.038424, loss_fp: 0.002100, loss_freq: 0.012187
[06:34:43.559] iteration 22955: loss: 0.029720, loss_s1: 0.014501, loss_fp: 0.001384, loss_freq: 0.013745
[06:34:44.174] iteration 22956: loss: 0.057162, loss_s1: 0.050540, loss_fp: 0.001167, loss_freq: 0.016162
[06:34:44.847] iteration 22957: loss: 0.053482, loss_s1: 0.029967, loss_fp: 0.005410, loss_freq: 0.037314
[06:34:45.504] iteration 22958: loss: 0.033428, loss_s1: 0.024589, loss_fp: 0.003786, loss_freq: 0.016083
[06:34:46.163] iteration 22959: loss: 0.039895, loss_s1: 0.031358, loss_fp: 0.003807, loss_freq: 0.010446
[06:34:46.844] iteration 22960: loss: 0.062837, loss_s1: 0.052853, loss_fp: 0.004098, loss_freq: 0.018395
[06:34:47.504] iteration 22961: loss: 0.055112, loss_s1: 0.043039, loss_fp: 0.002999, loss_freq: 0.034202
[06:34:48.163] iteration 22962: loss: 0.061818, loss_s1: 0.046468, loss_fp: 0.009757, loss_freq: 0.035964
[06:34:48.824] iteration 22963: loss: 0.074305, loss_s1: 0.067044, loss_fp: 0.001763, loss_freq: 0.051735
[06:34:49.498] iteration 22964: loss: 0.078843, loss_s1: 0.094215, loss_fp: 0.008633, loss_freq: 0.031025
[06:34:50.151] iteration 22965: loss: 0.051624, loss_s1: 0.050642, loss_fp: 0.002182, loss_freq: 0.015173
[06:34:50.832] iteration 22966: loss: 0.080088, loss_s1: 0.058229, loss_fp: 0.003690, loss_freq: 0.045521
[06:34:51.490] iteration 22967: loss: 0.095224, loss_s1: 0.055336, loss_fp: 0.001361, loss_freq: 0.113829
[06:34:52.109] iteration 22968: loss: 0.039738, loss_s1: 0.039353, loss_fp: 0.001707, loss_freq: 0.009304
[06:34:52.737] iteration 22969: loss: 0.080728, loss_s1: 0.075663, loss_fp: 0.013312, loss_freq: 0.037367
[06:34:53.350] iteration 22970: loss: 0.042552, loss_s1: 0.024553, loss_fp: 0.009112, loss_freq: 0.015059
[06:34:53.967] iteration 22971: loss: 0.051220, loss_s1: 0.043190, loss_fp: 0.008236, loss_freq: 0.017925
[06:34:54.597] iteration 22972: loss: 0.037686, loss_s1: 0.030274, loss_fp: 0.002803, loss_freq: 0.021930
[06:34:55.217] iteration 22973: loss: 0.069478, loss_s1: 0.054537, loss_fp: 0.005366, loss_freq: 0.038786
[06:34:55.825] iteration 22974: loss: 0.050841, loss_s1: 0.043013, loss_fp: 0.002290, loss_freq: 0.018125
[06:34:56.432] iteration 22975: loss: 0.080737, loss_s1: 0.078155, loss_fp: 0.012913, loss_freq: 0.042013
[06:34:57.042] iteration 22976: loss: 0.050917, loss_s1: 0.032346, loss_fp: 0.002540, loss_freq: 0.041546
[06:34:57.652] iteration 22977: loss: 0.053989, loss_s1: 0.033449, loss_fp: 0.005658, loss_freq: 0.029103
[06:34:58.259] iteration 22978: loss: 0.104351, loss_s1: 0.117191, loss_fp: 0.002901, loss_freq: 0.055994
[06:34:58.873] iteration 22979: loss: 0.047579, loss_s1: 0.028425, loss_fp: 0.002731, loss_freq: 0.008301
[06:34:59.497] iteration 22980: loss: 0.055377, loss_s1: 0.056154, loss_fp: 0.003585, loss_freq: 0.021120
[06:35:00.138] iteration 22981: loss: 0.055581, loss_s1: 0.024148, loss_fp: 0.003650, loss_freq: 0.058428
[06:35:01.093] iteration 22982: loss: 0.069420, loss_s1: 0.054518, loss_fp: 0.001071, loss_freq: 0.032330
[06:35:01.948] iteration 22983: loss: 0.048098, loss_s1: 0.036136, loss_fp: 0.004853, loss_freq: 0.025416
[06:35:02.563] iteration 22984: loss: 0.047609, loss_s1: 0.052752, loss_fp: 0.005255, loss_freq: 0.004707
[06:35:03.180] iteration 22985: loss: 0.052527, loss_s1: 0.033859, loss_fp: 0.001464, loss_freq: 0.042954
[06:35:03.792] iteration 22986: loss: 0.055833, loss_s1: 0.042422, loss_fp: 0.004139, loss_freq: 0.019670
[06:35:04.403] iteration 22987: loss: 0.058866, loss_s1: 0.037506, loss_fp: 0.002680, loss_freq: 0.047822
[06:35:05.015] iteration 22988: loss: 0.066570, loss_s1: 0.082170, loss_fp: 0.003368, loss_freq: 0.017353
[06:35:05.629] iteration 22989: loss: 0.077378, loss_s1: 0.077140, loss_fp: 0.007476, loss_freq: 0.031292
[06:35:06.296] iteration 22990: loss: 0.062558, loss_s1: 0.028486, loss_fp: 0.005318, loss_freq: 0.049558
[06:35:06.955] iteration 22991: loss: 0.082011, loss_s1: 0.092790, loss_fp: 0.002091, loss_freq: 0.029450
[06:35:07.612] iteration 22992: loss: 0.088661, loss_s1: 0.097136, loss_fp: 0.002952, loss_freq: 0.033783
[06:35:08.298] iteration 22993: loss: 0.083364, loss_s1: 0.109410, loss_fp: 0.001762, loss_freq: 0.027335
[06:35:08.928] iteration 22994: loss: 0.083231, loss_s1: 0.095781, loss_fp: 0.003941, loss_freq: 0.041848
[06:35:09.534] iteration 22995: loss: 0.060633, loss_s1: 0.057969, loss_fp: 0.005181, loss_freq: 0.025418
[06:35:10.141] iteration 22996: loss: 0.068455, loss_s1: 0.075098, loss_fp: 0.009904, loss_freq: 0.019455
[06:35:10.758] iteration 22997: loss: 0.058063, loss_s1: 0.046252, loss_fp: 0.003730, loss_freq: 0.034316
[06:35:11.371] iteration 22998: loss: 0.052795, loss_s1: 0.035749, loss_fp: 0.004961, loss_freq: 0.036788
[06:35:11.980] iteration 22999: loss: 0.042893, loss_s1: 0.038529, loss_fp: 0.004053, loss_freq: 0.005866
[06:35:12.591] iteration 23000: loss: 0.059354, loss_s1: 0.063853, loss_fp: 0.001829, loss_freq: 0.017877
[06:35:15.862] iteration 23000 : mean_dice : 0.732778
[06:35:16.534] iteration 23001: loss: 0.046844, loss_s1: 0.029599, loss_fp: 0.001085, loss_freq: 0.025821
[06:35:17.147] iteration 23002: loss: 0.042603, loss_s1: 0.034489, loss_fp: 0.004099, loss_freq: 0.025464
[06:35:17.751] iteration 23003: loss: 0.035855, loss_s1: 0.015879, loss_fp: 0.007246, loss_freq: 0.021204
[06:35:18.364] iteration 23004: loss: 0.070090, loss_s1: 0.083424, loss_fp: 0.009485, loss_freq: 0.017140
[06:35:19.000] iteration 23005: loss: 0.072707, loss_s1: 0.056773, loss_fp: 0.005206, loss_freq: 0.045796
[06:35:19.612] iteration 23006: loss: 0.048705, loss_s1: 0.032119, loss_fp: 0.003469, loss_freq: 0.028913
[06:35:20.240] iteration 23007: loss: 0.053919, loss_s1: 0.050630, loss_fp: 0.004767, loss_freq: 0.030545
[06:35:20.860] iteration 23008: loss: 0.038037, loss_s1: 0.016225, loss_fp: 0.001147, loss_freq: 0.022445
[06:35:21.483] iteration 23009: loss: 0.043163, loss_s1: 0.027537, loss_fp: 0.002000, loss_freq: 0.026918
[06:35:22.098] iteration 23010: loss: 0.060526, loss_s1: 0.062153, loss_fp: 0.008284, loss_freq: 0.023483
[06:35:22.765] iteration 23011: loss: 0.030779, loss_s1: 0.028497, loss_fp: 0.002789, loss_freq: 0.005871
[06:35:23.425] iteration 23012: loss: 0.046103, loss_s1: 0.020700, loss_fp: 0.003221, loss_freq: 0.033875
[06:35:24.082] iteration 23013: loss: 0.053537, loss_s1: 0.045297, loss_fp: 0.002613, loss_freq: 0.024942
[06:35:24.749] iteration 23014: loss: 0.030425, loss_s1: 0.014970, loss_fp: 0.000743, loss_freq: 0.010221
[06:35:25.404] iteration 23015: loss: 0.046260, loss_s1: 0.036055, loss_fp: 0.004111, loss_freq: 0.010592
[06:35:26.052] iteration 23016: loss: 0.055963, loss_s1: 0.052898, loss_fp: 0.001689, loss_freq: 0.029834
[06:35:26.669] iteration 23017: loss: 0.046901, loss_s1: 0.047253, loss_fp: 0.001734, loss_freq: 0.010821
[06:35:27.284] iteration 23018: loss: 0.093799, loss_s1: 0.090739, loss_fp: 0.007027, loss_freq: 0.051948
[06:35:27.892] iteration 23019: loss: 0.025007, loss_s1: 0.007217, loss_fp: 0.000986, loss_freq: 0.006670
[06:35:28.504] iteration 23020: loss: 0.041072, loss_s1: 0.031552, loss_fp: 0.004711, loss_freq: 0.023950
[06:35:29.110] iteration 23021: loss: 0.072610, loss_s1: 0.042344, loss_fp: 0.008189, loss_freq: 0.056372
[06:35:29.716] iteration 23022: loss: 0.033974, loss_s1: 0.017349, loss_fp: 0.001266, loss_freq: 0.017186
[06:35:30.323] iteration 23023: loss: 0.066035, loss_s1: 0.053718, loss_fp: 0.006952, loss_freq: 0.043583
[06:35:30.929] iteration 23024: loss: 0.070874, loss_s1: 0.091901, loss_fp: 0.004339, loss_freq: 0.008636
[06:35:31.543] iteration 23025: loss: 0.037546, loss_s1: 0.020356, loss_fp: 0.004909, loss_freq: 0.021523
[06:35:32.174] iteration 23026: loss: 0.067510, loss_s1: 0.042020, loss_fp: 0.006551, loss_freq: 0.053120
[06:35:32.785] iteration 23027: loss: 0.054489, loss_s1: 0.049561, loss_fp: 0.001216, loss_freq: 0.030416
[06:35:33.397] iteration 23028: loss: 0.073242, loss_s1: 0.059485, loss_fp: 0.005930, loss_freq: 0.033382
[06:35:34.004] iteration 23029: loss: 0.067066, loss_s1: 0.065163, loss_fp: 0.006584, loss_freq: 0.034427
[06:35:34.614] iteration 23030: loss: 0.077344, loss_s1: 0.070299, loss_fp: 0.002208, loss_freq: 0.040052
[06:35:35.222] iteration 23031: loss: 0.070849, loss_s1: 0.088971, loss_fp: 0.004605, loss_freq: 0.006093
[06:35:35.825] iteration 23032: loss: 0.056729, loss_s1: 0.032811, loss_fp: 0.008290, loss_freq: 0.041296
[06:35:36.429] iteration 23033: loss: 0.045405, loss_s1: 0.017295, loss_fp: 0.003673, loss_freq: 0.033233
[06:35:37.032] iteration 23034: loss: 0.038820, loss_s1: 0.026636, loss_fp: 0.011729, loss_freq: 0.008582
[06:35:37.641] iteration 23035: loss: 0.068716, loss_s1: 0.043922, loss_fp: 0.004573, loss_freq: 0.042722
[06:35:38.247] iteration 23036: loss: 0.046400, loss_s1: 0.028720, loss_fp: 0.002525, loss_freq: 0.028813
[06:35:38.856] iteration 23037: loss: 0.052542, loss_s1: 0.053740, loss_fp: 0.003029, loss_freq: 0.028428
[06:35:39.467] iteration 23038: loss: 0.055560, loss_s1: 0.060752, loss_fp: 0.004637, loss_freq: 0.012128
[06:35:40.078] iteration 23039: loss: 0.055732, loss_s1: 0.057441, loss_fp: 0.003183, loss_freq: 0.021225
[06:35:40.693] iteration 23040: loss: 0.043394, loss_s1: 0.032717, loss_fp: 0.008019, loss_freq: 0.008785
[06:35:41.308] iteration 23041: loss: 0.073754, loss_s1: 0.066319, loss_fp: 0.001867, loss_freq: 0.048446
[06:35:41.918] iteration 23042: loss: 0.046826, loss_s1: 0.028347, loss_fp: 0.001952, loss_freq: 0.033971
[06:35:42.531] iteration 23043: loss: 0.052910, loss_s1: 0.038771, loss_fp: 0.008040, loss_freq: 0.025088
[06:35:43.144] iteration 23044: loss: 0.051437, loss_s1: 0.047599, loss_fp: 0.002027, loss_freq: 0.019407
[06:35:43.755] iteration 23045: loss: 0.055130, loss_s1: 0.036409, loss_fp: 0.006820, loss_freq: 0.040700
[06:35:44.364] iteration 23046: loss: 0.052486, loss_s1: 0.053850, loss_fp: 0.002486, loss_freq: 0.026020
[06:35:44.975] iteration 23047: loss: 0.061686, loss_s1: 0.032871, loss_fp: 0.003324, loss_freq: 0.043301
[06:35:45.585] iteration 23048: loss: 0.058942, loss_s1: 0.022337, loss_fp: 0.002555, loss_freq: 0.025929
[06:35:46.199] iteration 23049: loss: 0.067557, loss_s1: 0.056445, loss_fp: 0.002719, loss_freq: 0.038893
[06:35:46.814] iteration 23050: loss: 0.034540, loss_s1: 0.020154, loss_fp: 0.004685, loss_freq: 0.007847
[06:35:47.426] iteration 23051: loss: 0.075460, loss_s1: 0.071079, loss_fp: 0.003786, loss_freq: 0.045372
[06:35:48.100] iteration 23052: loss: 0.051300, loss_s1: 0.042210, loss_fp: 0.004314, loss_freq: 0.016758
[06:35:48.751] iteration 23053: loss: 0.029833, loss_s1: 0.016976, loss_fp: 0.003938, loss_freq: 0.011843
[06:35:49.406] iteration 23054: loss: 0.051424, loss_s1: 0.035171, loss_fp: 0.000808, loss_freq: 0.034241
[06:35:50.065] iteration 23055: loss: 0.039925, loss_s1: 0.025407, loss_fp: 0.004761, loss_freq: 0.022768
[06:35:50.733] iteration 23056: loss: 0.085407, loss_s1: 0.087901, loss_fp: 0.003136, loss_freq: 0.047689
[06:35:51.354] iteration 23057: loss: 0.065473, loss_s1: 0.048953, loss_fp: 0.010836, loss_freq: 0.029967
[06:35:51.982] iteration 23058: loss: 0.049187, loss_s1: 0.042220, loss_fp: 0.003568, loss_freq: 0.020057
[06:35:52.602] iteration 23059: loss: 0.038434, loss_s1: 0.013208, loss_fp: 0.004522, loss_freq: 0.029442
[06:35:53.326] iteration 23060: loss: 0.064374, loss_s1: 0.066351, loss_fp: 0.002259, loss_freq: 0.038012
[06:35:54.084] iteration 23061: loss: 0.054819, loss_s1: 0.045281, loss_fp: 0.001164, loss_freq: 0.021490
[06:35:54.819] iteration 23062: loss: 0.048617, loss_s1: 0.047836, loss_fp: 0.004852, loss_freq: 0.017349
[06:35:55.480] iteration 23063: loss: 0.038665, loss_s1: 0.022901, loss_fp: 0.002227, loss_freq: 0.023411
[06:35:56.223] iteration 23064: loss: 0.036002, loss_s1: 0.035831, loss_fp: 0.009733, loss_freq: 0.005852
[06:35:56.862] iteration 23065: loss: 0.051768, loss_s1: 0.021621, loss_fp: 0.004767, loss_freq: 0.039099
[06:35:57.604] iteration 23066: loss: 0.059833, loss_s1: 0.057858, loss_fp: 0.004805, loss_freq: 0.020421
[06:35:58.321] iteration 23067: loss: 0.059404, loss_s1: 0.065053, loss_fp: 0.002940, loss_freq: 0.016101
[06:35:59.001] iteration 23068: loss: 0.053390, loss_s1: 0.045006, loss_fp: 0.008784, loss_freq: 0.015189
[06:35:59.735] iteration 23069: loss: 0.072756, loss_s1: 0.034931, loss_fp: 0.007807, loss_freq: 0.077901
[06:36:00.427] iteration 23070: loss: 0.045372, loss_s1: 0.028209, loss_fp: 0.008039, loss_freq: 0.023959
[06:36:01.193] iteration 23071: loss: 0.029524, loss_s1: 0.019365, loss_fp: 0.001110, loss_freq: 0.005706
[06:36:01.870] iteration 23072: loss: 0.038994, loss_s1: 0.032961, loss_fp: 0.002298, loss_freq: 0.021291
[06:36:02.540] iteration 23073: loss: 0.068984, loss_s1: 0.077394, loss_fp: 0.004029, loss_freq: 0.018606
[06:36:03.320] iteration 23074: loss: 0.047745, loss_s1: 0.032667, loss_fp: 0.004199, loss_freq: 0.031612
[06:36:03.982] iteration 23075: loss: 0.088873, loss_s1: 0.083025, loss_fp: 0.006794, loss_freq: 0.039654
[06:36:04.674] iteration 23076: loss: 0.061941, loss_s1: 0.039376, loss_fp: 0.001699, loss_freq: 0.048223
[06:36:05.317] iteration 23077: loss: 0.080897, loss_s1: 0.116535, loss_fp: 0.001075, loss_freq: 0.023877
[06:36:05.983] iteration 23078: loss: 0.044130, loss_s1: 0.018498, loss_fp: 0.002922, loss_freq: 0.020901
[06:36:06.668] iteration 23079: loss: 0.061510, loss_s1: 0.065756, loss_fp: 0.005057, loss_freq: 0.027003
[06:36:07.289] iteration 23080: loss: 0.061929, loss_s1: 0.050681, loss_fp: 0.006795, loss_freq: 0.037133
[06:36:07.897] iteration 23081: loss: 0.038828, loss_s1: 0.035401, loss_fp: 0.003002, loss_freq: 0.014066
[06:36:08.503] iteration 23082: loss: 0.057062, loss_s1: 0.045558, loss_fp: 0.005135, loss_freq: 0.027232
[06:36:09.169] iteration 23083: loss: 0.079421, loss_s1: 0.076332, loss_fp: 0.007284, loss_freq: 0.039760
[06:36:09.772] iteration 23084: loss: 0.040330, loss_s1: 0.031485, loss_fp: 0.005225, loss_freq: 0.015463
[06:36:10.375] iteration 23085: loss: 0.140941, loss_s1: 0.112542, loss_fp: 0.003495, loss_freq: 0.133505
[06:36:10.977] iteration 23086: loss: 0.029703, loss_s1: 0.028549, loss_fp: 0.001909, loss_freq: 0.009153
[06:36:11.586] iteration 23087: loss: 0.063327, loss_s1: 0.057591, loss_fp: 0.005564, loss_freq: 0.023418
[06:36:12.243] iteration 23088: loss: 0.058369, loss_s1: 0.045546, loss_fp: 0.003803, loss_freq: 0.025686
[06:36:12.897] iteration 23089: loss: 0.085742, loss_s1: 0.079445, loss_fp: 0.007926, loss_freq: 0.056272
[06:36:13.553] iteration 23090: loss: 0.042335, loss_s1: 0.048599, loss_fp: 0.003441, loss_freq: 0.012910
[06:36:14.164] iteration 23091: loss: 0.046768, loss_s1: 0.027485, loss_fp: 0.003366, loss_freq: 0.030066
[06:36:14.769] iteration 23092: loss: 0.050945, loss_s1: 0.045524, loss_fp: 0.001689, loss_freq: 0.021009
[06:36:15.375] iteration 23093: loss: 0.040623, loss_s1: 0.026342, loss_fp: 0.006205, loss_freq: 0.019993
[06:36:15.984] iteration 23094: loss: 0.026749, loss_s1: 0.013337, loss_fp: 0.004920, loss_freq: 0.008001
[06:36:16.590] iteration 23095: loss: 0.027559, loss_s1: 0.017515, loss_fp: 0.004384, loss_freq: 0.009224
[06:36:17.189] iteration 23096: loss: 0.059468, loss_s1: 0.037903, loss_fp: 0.002659, loss_freq: 0.042330
[06:36:17.789] iteration 23097: loss: 0.059642, loss_s1: 0.044788, loss_fp: 0.004352, loss_freq: 0.027181
[06:36:18.397] iteration 23098: loss: 0.071058, loss_s1: 0.091671, loss_fp: 0.004971, loss_freq: 0.022203
[06:36:19.000] iteration 23099: loss: 0.049443, loss_s1: 0.028409, loss_fp: 0.003852, loss_freq: 0.041508
[06:36:19.610] iteration 23100: loss: 0.065811, loss_s1: 0.052371, loss_fp: 0.004359, loss_freq: 0.035809
[06:36:20.220] iteration 23101: loss: 0.062177, loss_s1: 0.064191, loss_fp: 0.005058, loss_freq: 0.021108
[06:36:20.828] iteration 23102: loss: 0.068429, loss_s1: 0.043908, loss_fp: 0.003990, loss_freq: 0.059326
[06:36:21.738] iteration 23103: loss: 0.051692, loss_s1: 0.026326, loss_fp: 0.013584, loss_freq: 0.027785
[06:36:22.548] iteration 23104: loss: 0.062026, loss_s1: 0.053041, loss_fp: 0.004473, loss_freq: 0.030249
[06:36:23.351] iteration 23105: loss: 0.094700, loss_s1: 0.107299, loss_fp: 0.004360, loss_freq: 0.039826
[06:36:23.960] iteration 23106: loss: 0.043420, loss_s1: 0.033532, loss_fp: 0.002524, loss_freq: 0.008021
[06:36:24.577] iteration 23107: loss: 0.038108, loss_s1: 0.039623, loss_fp: 0.003082, loss_freq: 0.012520
[06:36:25.186] iteration 23108: loss: 0.056487, loss_s1: 0.041916, loss_fp: 0.003289, loss_freq: 0.038414
[06:36:25.794] iteration 23109: loss: 0.061757, loss_s1: 0.032480, loss_fp: 0.005462, loss_freq: 0.057713
[06:36:26.401] iteration 23110: loss: 0.060450, loss_s1: 0.055275, loss_fp: 0.004698, loss_freq: 0.030891
[06:36:27.005] iteration 23111: loss: 0.061904, loss_s1: 0.078677, loss_fp: 0.000964, loss_freq: 0.009263
[06:36:27.609] iteration 23112: loss: 0.058549, loss_s1: 0.048531, loss_fp: 0.004543, loss_freq: 0.022814
[06:36:28.220] iteration 23113: loss: 0.034073, loss_s1: 0.017093, loss_fp: 0.003757, loss_freq: 0.007211
[06:36:28.830] iteration 23114: loss: 0.051033, loss_s1: 0.054343, loss_fp: 0.004223, loss_freq: 0.017516
[06:36:29.438] iteration 23115: loss: 0.040239, loss_s1: 0.039209, loss_fp: 0.001859, loss_freq: 0.004936
[06:36:30.056] iteration 23116: loss: 0.076764, loss_s1: 0.092096, loss_fp: 0.005731, loss_freq: 0.027871
[06:36:30.661] iteration 23117: loss: 0.063858, loss_s1: 0.039163, loss_fp: 0.005914, loss_freq: 0.046194
[06:36:31.268] iteration 23118: loss: 0.057337, loss_s1: 0.060487, loss_fp: 0.006868, loss_freq: 0.017539
[06:36:31.872] iteration 23119: loss: 0.094931, loss_s1: 0.079411, loss_fp: 0.012613, loss_freq: 0.068510
[06:36:32.476] iteration 23120: loss: 0.094861, loss_s1: 0.102965, loss_fp: 0.001949, loss_freq: 0.049533
[06:36:33.397] iteration 23121: loss: 0.059905, loss_s1: 0.043382, loss_fp: 0.006798, loss_freq: 0.039314
[06:36:34.007] iteration 23122: loss: 0.056361, loss_s1: 0.056480, loss_fp: 0.004079, loss_freq: 0.019206
[06:36:34.618] iteration 23123: loss: 0.059162, loss_s1: 0.060028, loss_fp: 0.003018, loss_freq: 0.029547
[06:36:35.232] iteration 23124: loss: 0.045709, loss_s1: 0.037054, loss_fp: 0.004852, loss_freq: 0.022082
[06:36:35.843] iteration 23125: loss: 0.044143, loss_s1: 0.044231, loss_fp: 0.002619, loss_freq: 0.016809
[06:36:36.457] iteration 23126: loss: 0.071239, loss_s1: 0.054693, loss_fp: 0.004958, loss_freq: 0.035703
[06:36:37.069] iteration 23127: loss: 0.056420, loss_s1: 0.040345, loss_fp: 0.006076, loss_freq: 0.029571
[06:36:37.677] iteration 23128: loss: 0.034131, loss_s1: 0.034969, loss_fp: 0.001311, loss_freq: 0.008362
[06:36:38.282] iteration 23129: loss: 0.045564, loss_s1: 0.047744, loss_fp: 0.001375, loss_freq: 0.011879
[06:36:38.890] iteration 23130: loss: 0.081332, loss_s1: 0.101306, loss_fp: 0.004922, loss_freq: 0.024644
[06:36:39.505] iteration 23131: loss: 0.067725, loss_s1: 0.037411, loss_fp: 0.004436, loss_freq: 0.062085
[06:36:40.116] iteration 23132: loss: 0.052743, loss_s1: 0.018647, loss_fp: 0.000867, loss_freq: 0.051232
[06:36:40.728] iteration 23133: loss: 0.051668, loss_s1: 0.045373, loss_fp: 0.001506, loss_freq: 0.025307
[06:36:41.343] iteration 23134: loss: 0.040889, loss_s1: 0.023370, loss_fp: 0.004477, loss_freq: 0.016830
[06:36:41.952] iteration 23135: loss: 0.062450, loss_s1: 0.053879, loss_fp: 0.009880, loss_freq: 0.026211
[06:36:42.567] iteration 23136: loss: 0.057516, loss_s1: 0.056136, loss_fp: 0.004917, loss_freq: 0.025829
[06:36:43.182] iteration 23137: loss: 0.103733, loss_s1: 0.100853, loss_fp: 0.003883, loss_freq: 0.074611
[06:36:43.787] iteration 23138: loss: 0.043300, loss_s1: 0.041960, loss_fp: 0.001551, loss_freq: 0.013571
[06:36:44.399] iteration 23139: loss: 0.069178, loss_s1: 0.066643, loss_fp: 0.008518, loss_freq: 0.030829
[06:36:45.014] iteration 23140: loss: 0.064158, loss_s1: 0.067869, loss_fp: 0.003738, loss_freq: 0.023532
[06:36:45.625] iteration 23141: loss: 0.044054, loss_s1: 0.016443, loss_fp: 0.001921, loss_freq: 0.032320
[06:36:46.233] iteration 23142: loss: 0.060403, loss_s1: 0.056869, loss_fp: 0.009395, loss_freq: 0.028099
[06:36:46.849] iteration 23143: loss: 0.071037, loss_s1: 0.054424, loss_fp: 0.004886, loss_freq: 0.024856
[06:36:47.457] iteration 23144: loss: 0.066820, loss_s1: 0.069703, loss_fp: 0.003407, loss_freq: 0.021679
[06:36:48.080] iteration 23145: loss: 0.082120, loss_s1: 0.083476, loss_fp: 0.006508, loss_freq: 0.038143
[06:36:48.691] iteration 23146: loss: 0.057361, loss_s1: 0.062685, loss_fp: 0.003041, loss_freq: 0.014933
[06:36:49.349] iteration 23147: loss: 0.073151, loss_s1: 0.047943, loss_fp: 0.006752, loss_freq: 0.057700
[06:36:50.010] iteration 23148: loss: 0.107085, loss_s1: 0.108731, loss_fp: 0.006785, loss_freq: 0.041873
[06:36:50.664] iteration 23149: loss: 0.059356, loss_s1: 0.043709, loss_fp: 0.005859, loss_freq: 0.030613
[06:36:51.315] iteration 23150: loss: 0.081867, loss_s1: 0.090727, loss_fp: 0.002275, loss_freq: 0.034789
[06:36:51.945] iteration 23151: loss: 0.055997, loss_s1: 0.046869, loss_fp: 0.005667, loss_freq: 0.038346
[06:36:52.559] iteration 23152: loss: 0.094129, loss_s1: 0.076438, loss_fp: 0.005311, loss_freq: 0.060829
[06:36:53.161] iteration 23153: loss: 0.093807, loss_s1: 0.102362, loss_fp: 0.009349, loss_freq: 0.048875
[06:36:53.775] iteration 23154: loss: 0.042552, loss_s1: 0.037975, loss_fp: 0.006327, loss_freq: 0.014200
[06:36:54.391] iteration 23155: loss: 0.062444, loss_s1: 0.066831, loss_fp: 0.002041, loss_freq: 0.032161
[06:36:54.997] iteration 23156: loss: 0.053799, loss_s1: 0.033430, loss_fp: 0.007251, loss_freq: 0.019717
[06:36:55.608] iteration 23157: loss: 0.060064, loss_s1: 0.056153, loss_fp: 0.002102, loss_freq: 0.029863
[06:36:56.215] iteration 23158: loss: 0.045528, loss_s1: 0.036237, loss_fp: 0.005946, loss_freq: 0.012279
[06:36:56.840] iteration 23159: loss: 0.072318, loss_s1: 0.063201, loss_fp: 0.007192, loss_freq: 0.041119
[06:36:57.452] iteration 23160: loss: 0.099823, loss_s1: 0.142645, loss_fp: 0.004367, loss_freq: 0.026608
[06:36:58.055] iteration 23161: loss: 0.074491, loss_s1: 0.064482, loss_fp: 0.006305, loss_freq: 0.028404
[06:36:58.660] iteration 23162: loss: 0.051105, loss_s1: 0.051570, loss_fp: 0.002138, loss_freq: 0.016940
[06:36:59.263] iteration 23163: loss: 0.058311, loss_s1: 0.047115, loss_fp: 0.002223, loss_freq: 0.041166
[06:36:59.875] iteration 23164: loss: 0.046988, loss_s1: 0.033661, loss_fp: 0.002387, loss_freq: 0.024847
[06:37:00.486] iteration 23165: loss: 0.059957, loss_s1: 0.046956, loss_fp: 0.003015, loss_freq: 0.031059
[06:37:01.088] iteration 23166: loss: 0.065319, loss_s1: 0.039742, loss_fp: 0.005153, loss_freq: 0.049050
[06:37:01.713] iteration 23167: loss: 0.047278, loss_s1: 0.035805, loss_fp: 0.003208, loss_freq: 0.025862
[06:37:02.339] iteration 23168: loss: 0.047263, loss_s1: 0.046696, loss_fp: 0.002319, loss_freq: 0.019471
[06:37:02.968] iteration 23169: loss: 0.045031, loss_s1: 0.040531, loss_fp: 0.004213, loss_freq: 0.013883
[06:37:03.629] iteration 23170: loss: 0.037238, loss_s1: 0.021024, loss_fp: 0.002696, loss_freq: 0.010387
[06:37:04.247] iteration 23171: loss: 0.063931, loss_s1: 0.068508, loss_fp: 0.001916, loss_freq: 0.023363
[06:37:04.908] iteration 23172: loss: 0.042634, loss_s1: 0.038957, loss_fp: 0.006150, loss_freq: 0.017688
[06:37:05.529] iteration 23173: loss: 0.037034, loss_s1: 0.019889, loss_fp: 0.001194, loss_freq: 0.014644
[06:37:06.158] iteration 23174: loss: 0.053001, loss_s1: 0.035789, loss_fp: 0.008728, loss_freq: 0.033311
[06:37:06.912] iteration 23175: loss: 0.062223, loss_s1: 0.050013, loss_fp: 0.005304, loss_freq: 0.029236
[06:37:07.583] iteration 23176: loss: 0.048015, loss_s1: 0.039977, loss_fp: 0.001593, loss_freq: 0.017033
[06:37:08.247] iteration 23177: loss: 0.049031, loss_s1: 0.035313, loss_fp: 0.005204, loss_freq: 0.037615
[06:37:08.913] iteration 23178: loss: 0.044797, loss_s1: 0.024488, loss_fp: 0.004595, loss_freq: 0.020321
[06:37:09.586] iteration 23179: loss: 0.047392, loss_s1: 0.017814, loss_fp: 0.001929, loss_freq: 0.037440
[06:37:10.205] iteration 23180: loss: 0.052839, loss_s1: 0.041865, loss_fp: 0.002718, loss_freq: 0.025021
[06:37:10.822] iteration 23181: loss: 0.032922, loss_s1: 0.033003, loss_fp: 0.001672, loss_freq: 0.006150
[06:37:11.436] iteration 23182: loss: 0.051204, loss_s1: 0.045501, loss_fp: 0.004910, loss_freq: 0.018751
[06:37:12.062] iteration 23183: loss: 0.033490, loss_s1: 0.021187, loss_fp: 0.003402, loss_freq: 0.010640
[06:37:12.733] iteration 23184: loss: 0.031160, loss_s1: 0.019381, loss_fp: 0.001559, loss_freq: 0.013318
[06:37:13.377] iteration 23185: loss: 0.058748, loss_s1: 0.060546, loss_fp: 0.001602, loss_freq: 0.020263
[06:37:14.020] iteration 23186: loss: 0.036595, loss_s1: 0.026231, loss_fp: 0.002104, loss_freq: 0.024198
[06:37:14.638] iteration 23187: loss: 0.047198, loss_s1: 0.022413, loss_fp: 0.005302, loss_freq: 0.017741
[06:37:15.256] iteration 23188: loss: 0.093509, loss_s1: 0.081569, loss_fp: 0.010169, loss_freq: 0.067032
[06:37:15.879] iteration 23189: loss: 0.042007, loss_s1: 0.029581, loss_fp: 0.003313, loss_freq: 0.020832
[06:37:16.497] iteration 23190: loss: 0.045003, loss_s1: 0.023164, loss_fp: 0.011886, loss_freq: 0.029187
[06:37:17.110] iteration 23191: loss: 0.065441, loss_s1: 0.051145, loss_fp: 0.004124, loss_freq: 0.041250
[06:37:17.724] iteration 23192: loss: 0.049466, loss_s1: 0.044687, loss_fp: 0.001703, loss_freq: 0.016668
[06:37:18.331] iteration 23193: loss: 0.050266, loss_s1: 0.040672, loss_fp: 0.007377, loss_freq: 0.027192
[06:37:18.944] iteration 23194: loss: 0.049477, loss_s1: 0.042828, loss_fp: 0.001699, loss_freq: 0.022122
[06:37:19.554] iteration 23195: loss: 0.046317, loss_s1: 0.035632, loss_fp: 0.004535, loss_freq: 0.025484
[06:37:20.157] iteration 23196: loss: 0.063187, loss_s1: 0.036918, loss_fp: 0.002216, loss_freq: 0.053243
[06:37:20.763] iteration 23197: loss: 0.060019, loss_s1: 0.035004, loss_fp: 0.001922, loss_freq: 0.042945
[06:37:21.374] iteration 23198: loss: 0.061437, loss_s1: 0.056951, loss_fp: 0.001709, loss_freq: 0.037620
[06:37:21.985] iteration 23199: loss: 0.060404, loss_s1: 0.049504, loss_fp: 0.007936, loss_freq: 0.034681
[06:37:22.599] iteration 23200: loss: 0.051179, loss_s1: 0.046002, loss_fp: 0.001419, loss_freq: 0.017957
[06:37:26.052] iteration 23200 : mean_dice : 0.747025
[06:37:26.688] iteration 23201: loss: 0.082367, loss_s1: 0.092532, loss_fp: 0.002098, loss_freq: 0.012485
[06:37:27.294] iteration 23202: loss: 0.048846, loss_s1: 0.038037, loss_fp: 0.004913, loss_freq: 0.020508
[06:37:27.910] iteration 23203: loss: 0.056311, loss_s1: 0.055562, loss_fp: 0.001686, loss_freq: 0.018055
[06:37:28.525] iteration 23204: loss: 0.038489, loss_s1: 0.025682, loss_fp: 0.005627, loss_freq: 0.011166
[06:37:29.134] iteration 23205: loss: 0.083047, loss_s1: 0.079124, loss_fp: 0.002980, loss_freq: 0.044504
[06:37:29.747] iteration 23206: loss: 0.041739, loss_s1: 0.033802, loss_fp: 0.005252, loss_freq: 0.012156
[06:37:30.359] iteration 23207: loss: 0.053803, loss_s1: 0.059079, loss_fp: 0.006756, loss_freq: 0.021417
[06:37:30.967] iteration 23208: loss: 0.044860, loss_s1: 0.031631, loss_fp: 0.007021, loss_freq: 0.013559
[06:37:31.582] iteration 23209: loss: 0.058935, loss_s1: 0.038143, loss_fp: 0.002833, loss_freq: 0.045785
[06:37:32.192] iteration 23210: loss: 0.048540, loss_s1: 0.027653, loss_fp: 0.003404, loss_freq: 0.028340
[06:37:32.808] iteration 23211: loss: 0.081815, loss_s1: 0.085597, loss_fp: 0.006792, loss_freq: 0.033387
[06:37:33.422] iteration 23212: loss: 0.065762, loss_s1: 0.031434, loss_fp: 0.021074, loss_freq: 0.049912
[06:37:34.033] iteration 23213: loss: 0.079010, loss_s1: 0.074345, loss_fp: 0.007896, loss_freq: 0.029421
[06:37:34.646] iteration 23214: loss: 0.048792, loss_s1: 0.053683, loss_fp: 0.003895, loss_freq: 0.011351
[06:37:35.257] iteration 23215: loss: 0.031903, loss_s1: 0.021172, loss_fp: 0.001416, loss_freq: 0.011377
[06:37:35.867] iteration 23216: loss: 0.041358, loss_s1: 0.029309, loss_fp: 0.004333, loss_freq: 0.026391
[06:37:36.474] iteration 23217: loss: 0.055170, loss_s1: 0.038569, loss_fp: 0.004028, loss_freq: 0.023797
[06:37:37.084] iteration 23218: loss: 0.069405, loss_s1: 0.074997, loss_fp: 0.004641, loss_freq: 0.022663
[06:37:37.691] iteration 23219: loss: 0.048424, loss_s1: 0.043709, loss_fp: 0.002274, loss_freq: 0.027537
[06:37:38.295] iteration 23220: loss: 0.073072, loss_s1: 0.076320, loss_fp: 0.003454, loss_freq: 0.032886
[06:37:38.916] iteration 23221: loss: 0.045617, loss_s1: 0.028519, loss_fp: 0.003442, loss_freq: 0.038487
[06:37:39.531] iteration 23222: loss: 0.040865, loss_s1: 0.022973, loss_fp: 0.003886, loss_freq: 0.019003
[06:37:40.139] iteration 23223: loss: 0.036411, loss_s1: 0.021135, loss_fp: 0.004138, loss_freq: 0.019641
[06:37:40.755] iteration 23224: loss: 0.036482, loss_s1: 0.021307, loss_fp: 0.004157, loss_freq: 0.017777
[06:37:41.365] iteration 23225: loss: 0.036705, loss_s1: 0.031755, loss_fp: 0.002167, loss_freq: 0.016515
[06:37:41.984] iteration 23226: loss: 0.076725, loss_s1: 0.061737, loss_fp: 0.005727, loss_freq: 0.054099
[06:37:42.601] iteration 23227: loss: 0.053501, loss_s1: 0.045717, loss_fp: 0.010682, loss_freq: 0.014420
[06:37:43.209] iteration 23228: loss: 0.037262, loss_s1: 0.015587, loss_fp: 0.003307, loss_freq: 0.029717
[06:37:43.819] iteration 23229: loss: 0.112543, loss_s1: 0.054810, loss_fp: 0.023403, loss_freq: 0.116585
[06:37:44.431] iteration 23230: loss: 0.045391, loss_s1: 0.039794, loss_fp: 0.004286, loss_freq: 0.016931
[06:37:45.100] iteration 23231: loss: 0.050602, loss_s1: 0.016090, loss_fp: 0.004727, loss_freq: 0.035376
[06:37:45.774] iteration 23232: loss: 0.052277, loss_s1: 0.051896, loss_fp: 0.002753, loss_freq: 0.017228
[06:37:46.432] iteration 23233: loss: 0.042840, loss_s1: 0.029790, loss_fp: 0.005570, loss_freq: 0.014590
[06:37:47.059] iteration 23234: loss: 0.040971, loss_s1: 0.042369, loss_fp: 0.001660, loss_freq: 0.016020
[06:37:47.670] iteration 23235: loss: 0.081156, loss_s1: 0.064597, loss_fp: 0.003299, loss_freq: 0.047510
[06:37:48.276] iteration 23236: loss: 0.058545, loss_s1: 0.027563, loss_fp: 0.009026, loss_freq: 0.051314
[06:37:48.882] iteration 23237: loss: 0.050363, loss_s1: 0.047286, loss_fp: 0.001347, loss_freq: 0.013695
[06:37:49.490] iteration 23238: loss: 0.057652, loss_s1: 0.064592, loss_fp: 0.002913, loss_freq: 0.019490
[06:37:50.108] iteration 23239: loss: 0.087117, loss_s1: 0.069706, loss_fp: 0.004381, loss_freq: 0.062445
[06:37:50.723] iteration 23240: loss: 0.049056, loss_s1: 0.043511, loss_fp: 0.004503, loss_freq: 0.016583
[06:37:51.336] iteration 23241: loss: 0.036705, loss_s1: 0.029082, loss_fp: 0.003046, loss_freq: 0.005361
[06:37:51.946] iteration 23242: loss: 0.056046, loss_s1: 0.047339, loss_fp: 0.006555, loss_freq: 0.036097
[06:37:52.565] iteration 23243: loss: 0.064394, loss_s1: 0.061943, loss_fp: 0.008947, loss_freq: 0.024039
[06:37:53.176] iteration 23244: loss: 0.044797, loss_s1: 0.027444, loss_fp: 0.006941, loss_freq: 0.024689
[06:37:53.802] iteration 23245: loss: 0.056760, loss_s1: 0.041925, loss_fp: 0.003450, loss_freq: 0.036502
[06:37:54.418] iteration 23246: loss: 0.040304, loss_s1: 0.026144, loss_fp: 0.001866, loss_freq: 0.021726
[06:37:55.024] iteration 23247: loss: 0.042904, loss_s1: 0.020934, loss_fp: 0.002618, loss_freq: 0.041938
[06:37:55.632] iteration 23248: loss: 0.056287, loss_s1: 0.024519, loss_fp: 0.004873, loss_freq: 0.045235
[06:37:56.236] iteration 23249: loss: 0.068801, loss_s1: 0.064376, loss_fp: 0.008145, loss_freq: 0.040203
[06:37:56.851] iteration 23250: loss: 0.055542, loss_s1: 0.040091, loss_fp: 0.015580, loss_freq: 0.026368
[06:37:57.506] iteration 23251: loss: 0.039270, loss_s1: 0.034990, loss_fp: 0.002465, loss_freq: 0.018130
[06:37:58.183] iteration 23252: loss: 0.073045, loss_s1: 0.069133, loss_fp: 0.006597, loss_freq: 0.033102
[06:37:58.854] iteration 23253: loss: 0.070132, loss_s1: 0.068601, loss_fp: 0.004447, loss_freq: 0.035135
[06:37:59.463] iteration 23254: loss: 0.047641, loss_s1: 0.048078, loss_fp: 0.003265, loss_freq: 0.018363
[06:38:00.069] iteration 23255: loss: 0.065877, loss_s1: 0.044869, loss_fp: 0.001489, loss_freq: 0.045143
[06:38:00.676] iteration 23256: loss: 0.034670, loss_s1: 0.034818, loss_fp: 0.003367, loss_freq: 0.009435
[06:38:01.283] iteration 23257: loss: 0.061149, loss_s1: 0.052704, loss_fp: 0.012832, loss_freq: 0.018675
[06:38:01.891] iteration 23258: loss: 0.042787, loss_s1: 0.022396, loss_fp: 0.004786, loss_freq: 0.036462
[06:38:02.512] iteration 23259: loss: 0.110029, loss_s1: 0.115866, loss_fp: 0.006418, loss_freq: 0.072032
[06:38:03.126] iteration 23260: loss: 0.054262, loss_s1: 0.059273, loss_fp: 0.001297, loss_freq: 0.027769
[06:38:03.737] iteration 23261: loss: 0.071668, loss_s1: 0.030157, loss_fp: 0.011605, loss_freq: 0.043993
[06:38:04.353] iteration 23262: loss: 0.052511, loss_s1: 0.052521, loss_fp: 0.001995, loss_freq: 0.018522
[06:38:04.963] iteration 23263: loss: 0.051013, loss_s1: 0.048793, loss_fp: 0.008698, loss_freq: 0.019262
[06:38:05.568] iteration 23264: loss: 0.050164, loss_s1: 0.061164, loss_fp: 0.003191, loss_freq: 0.007636
[06:38:06.179] iteration 23265: loss: 0.033800, loss_s1: 0.023706, loss_fp: 0.002414, loss_freq: 0.008526
[06:38:06.790] iteration 23266: loss: 0.053788, loss_s1: 0.048138, loss_fp: 0.005948, loss_freq: 0.023541
[06:38:07.401] iteration 23267: loss: 0.045787, loss_s1: 0.037083, loss_fp: 0.002708, loss_freq: 0.020641
[06:38:08.009] iteration 23268: loss: 0.064772, loss_s1: 0.070612, loss_fp: 0.001917, loss_freq: 0.029131
[06:38:08.633] iteration 23269: loss: 0.089274, loss_s1: 0.087933, loss_fp: 0.003179, loss_freq: 0.053775
[06:38:09.242] iteration 23270: loss: 0.066643, loss_s1: 0.049283, loss_fp: 0.007977, loss_freq: 0.035872
[06:38:09.851] iteration 23271: loss: 0.071192, loss_s1: 0.084129, loss_fp: 0.006267, loss_freq: 0.019544
[06:38:10.464] iteration 23272: loss: 0.115412, loss_s1: 0.115977, loss_fp: 0.006583, loss_freq: 0.071626
[06:38:11.083] iteration 23273: loss: 0.064226, loss_s1: 0.062037, loss_fp: 0.005872, loss_freq: 0.034301
[06:38:11.692] iteration 23274: loss: 0.063086, loss_s1: 0.045139, loss_fp: 0.003168, loss_freq: 0.045470
[06:38:12.317] iteration 23275: loss: 0.074434, loss_s1: 0.068552, loss_fp: 0.008799, loss_freq: 0.043366
[06:38:12.935] iteration 23276: loss: 0.033606, loss_s1: 0.021525, loss_fp: 0.002227, loss_freq: 0.008042
[06:38:13.549] iteration 23277: loss: 0.032737, loss_s1: 0.033006, loss_fp: 0.003116, loss_freq: 0.009549
[06:38:14.160] iteration 23278: loss: 0.073655, loss_s1: 0.077694, loss_fp: 0.001941, loss_freq: 0.043175
[06:38:14.777] iteration 23279: loss: 0.065905, loss_s1: 0.044727, loss_fp: 0.012875, loss_freq: 0.038383
[06:38:15.384] iteration 23280: loss: 0.072041, loss_s1: 0.058594, loss_fp: 0.005397, loss_freq: 0.048177
[06:38:15.988] iteration 23281: loss: 0.037581, loss_s1: 0.026921, loss_fp: 0.004139, loss_freq: 0.012256
[06:38:16.589] iteration 23282: loss: 0.077127, loss_s1: 0.056748, loss_fp: 0.005863, loss_freq: 0.071785
[06:38:17.200] iteration 23283: loss: 0.049835, loss_s1: 0.028168, loss_fp: 0.005015, loss_freq: 0.018867
[06:38:17.809] iteration 23284: loss: 0.060132, loss_s1: 0.041887, loss_fp: 0.002914, loss_freq: 0.044647
[06:38:18.418] iteration 23285: loss: 0.047036, loss_s1: 0.041138, loss_fp: 0.004384, loss_freq: 0.011080
[06:38:19.028] iteration 23286: loss: 0.102295, loss_s1: 0.115862, loss_fp: 0.006032, loss_freq: 0.059194
[06:38:19.635] iteration 23287: loss: 0.058757, loss_s1: 0.031537, loss_fp: 0.009116, loss_freq: 0.048026
[06:38:20.242] iteration 23288: loss: 0.066649, loss_s1: 0.079153, loss_fp: 0.004438, loss_freq: 0.015209
[06:38:20.844] iteration 23289: loss: 0.087885, loss_s1: 0.105771, loss_fp: 0.006203, loss_freq: 0.039137
[06:38:21.446] iteration 23290: loss: 0.058463, loss_s1: 0.030971, loss_fp: 0.013247, loss_freq: 0.037593
[06:38:22.442] iteration 23291: loss: 0.075720, loss_s1: 0.054939, loss_fp: 0.001830, loss_freq: 0.060877
[06:38:23.095] iteration 23292: loss: 0.051011, loss_s1: 0.034846, loss_fp: 0.004540, loss_freq: 0.029633
[06:38:23.729] iteration 23293: loss: 0.077129, loss_s1: 0.102160, loss_fp: 0.005191, loss_freq: 0.022195
[06:38:24.336] iteration 23294: loss: 0.036281, loss_s1: 0.025827, loss_fp: 0.002620, loss_freq: 0.014623
[06:38:24.942] iteration 23295: loss: 0.087439, loss_s1: 0.077602, loss_fp: 0.007025, loss_freq: 0.054697
[06:38:25.605] iteration 23296: loss: 0.062489, loss_s1: 0.052555, loss_fp: 0.001565, loss_freq: 0.025455
[06:38:26.232] iteration 23297: loss: 0.044905, loss_s1: 0.036197, loss_fp: 0.001535, loss_freq: 0.019058
[06:38:26.843] iteration 23298: loss: 0.051246, loss_s1: 0.044712, loss_fp: 0.005637, loss_freq: 0.028477
[06:38:27.453] iteration 23299: loss: 0.043830, loss_s1: 0.046266, loss_fp: 0.000878, loss_freq: 0.011903
[06:38:28.062] iteration 23300: loss: 0.058216, loss_s1: 0.039557, loss_fp: 0.006858, loss_freq: 0.033113
[06:38:28.680] iteration 23301: loss: 0.056083, loss_s1: 0.040489, loss_fp: 0.002871, loss_freq: 0.034862
[06:38:29.288] iteration 23302: loss: 0.054497, loss_s1: 0.033897, loss_fp: 0.004494, loss_freq: 0.039568
[06:38:29.954] iteration 23303: loss: 0.036663, loss_s1: 0.023081, loss_fp: 0.006528, loss_freq: 0.017426
[06:38:30.573] iteration 23304: loss: 0.045271, loss_s1: 0.024109, loss_fp: 0.003644, loss_freq: 0.027972
[06:38:31.198] iteration 23305: loss: 0.061855, loss_s1: 0.062054, loss_fp: 0.001363, loss_freq: 0.012856
[06:38:31.838] iteration 23306: loss: 0.071454, loss_s1: 0.086846, loss_fp: 0.003314, loss_freq: 0.017447
[06:38:32.441] iteration 23307: loss: 0.092753, loss_s1: 0.092870, loss_fp: 0.003340, loss_freq: 0.069171
[06:38:33.050] iteration 23308: loss: 0.031731, loss_s1: 0.021269, loss_fp: 0.001656, loss_freq: 0.011415
[06:38:33.665] iteration 23309: loss: 0.066323, loss_s1: 0.061558, loss_fp: 0.005380, loss_freq: 0.036604
[06:38:34.280] iteration 23310: loss: 0.067571, loss_s1: 0.069897, loss_fp: 0.002174, loss_freq: 0.032863
[06:38:34.886] iteration 23311: loss: 0.044105, loss_s1: 0.020924, loss_fp: 0.002698, loss_freq: 0.035005
[06:38:35.489] iteration 23312: loss: 0.057904, loss_s1: 0.051183, loss_fp: 0.003651, loss_freq: 0.038612
[06:38:36.140] iteration 23313: loss: 0.067216, loss_s1: 0.053201, loss_fp: 0.004366, loss_freq: 0.041016
[06:38:36.794] iteration 23314: loss: 0.038497, loss_s1: 0.026930, loss_fp: 0.003035, loss_freq: 0.018750
[06:38:37.446] iteration 23315: loss: 0.082834, loss_s1: 0.074311, loss_fp: 0.006315, loss_freq: 0.052223
[06:38:38.100] iteration 23316: loss: 0.056577, loss_s1: 0.050933, loss_fp: 0.005265, loss_freq: 0.030295
[06:38:38.721] iteration 23317: loss: 0.032560, loss_s1: 0.020333, loss_fp: 0.001925, loss_freq: 0.008080
[06:38:39.325] iteration 23318: loss: 0.119613, loss_s1: 0.101012, loss_fp: 0.008703, loss_freq: 0.085082
[06:38:39.928] iteration 23319: loss: 0.051584, loss_s1: 0.028499, loss_fp: 0.004043, loss_freq: 0.038287
[06:38:40.564] iteration 23320: loss: 0.058289, loss_s1: 0.048786, loss_fp: 0.002544, loss_freq: 0.025262
[06:38:41.170] iteration 23321: loss: 0.076185, loss_s1: 0.064457, loss_fp: 0.007059, loss_freq: 0.056598
[06:38:41.781] iteration 23322: loss: 0.056540, loss_s1: 0.035328, loss_fp: 0.003620, loss_freq: 0.035392
[06:38:42.391] iteration 23323: loss: 0.087472, loss_s1: 0.101606, loss_fp: 0.008001, loss_freq: 0.033901
[06:38:43.000] iteration 23324: loss: 0.049262, loss_s1: 0.030874, loss_fp: 0.003842, loss_freq: 0.027997
[06:38:43.605] iteration 23325: loss: 0.056040, loss_s1: 0.068515, loss_fp: 0.002106, loss_freq: 0.019551
[06:38:44.217] iteration 23326: loss: 0.045416, loss_s1: 0.012741, loss_fp: 0.003845, loss_freq: 0.023442
[06:38:44.827] iteration 23327: loss: 0.062360, loss_s1: 0.046671, loss_fp: 0.007421, loss_freq: 0.035967
[06:38:45.436] iteration 23328: loss: 0.063404, loss_s1: 0.083896, loss_fp: 0.003331, loss_freq: 0.012831
[06:38:46.044] iteration 23329: loss: 0.061133, loss_s1: 0.051306, loss_fp: 0.004413, loss_freq: 0.028001
[06:38:46.662] iteration 23330: loss: 0.071457, loss_s1: 0.053785, loss_fp: 0.008425, loss_freq: 0.044700
[06:38:47.266] iteration 23331: loss: 0.084003, loss_s1: 0.063298, loss_fp: 0.001564, loss_freq: 0.069257
[06:38:47.877] iteration 23332: loss: 0.050588, loss_s1: 0.033429, loss_fp: 0.002783, loss_freq: 0.035288
[06:38:48.480] iteration 23333: loss: 0.070892, loss_s1: 0.079024, loss_fp: 0.004610, loss_freq: 0.035974
[06:38:49.140] iteration 23334: loss: 0.081897, loss_s1: 0.088057, loss_fp: 0.004180, loss_freq: 0.048507
[06:38:49.800] iteration 23335: loss: 0.069994, loss_s1: 0.067714, loss_fp: 0.004134, loss_freq: 0.032181
[06:38:50.409] iteration 23336: loss: 0.075398, loss_s1: 0.069286, loss_fp: 0.004946, loss_freq: 0.040332
[06:38:51.028] iteration 23337: loss: 0.043365, loss_s1: 0.011830, loss_fp: 0.009586, loss_freq: 0.029681
[06:38:51.632] iteration 23338: loss: 0.063085, loss_s1: 0.037943, loss_fp: 0.008059, loss_freq: 0.045736
[06:38:52.243] iteration 23339: loss: 0.042307, loss_s1: 0.028700, loss_fp: 0.000762, loss_freq: 0.015236
[06:38:52.848] iteration 23340: loss: 0.045596, loss_s1: 0.042071, loss_fp: 0.000955, loss_freq: 0.013477
[06:38:53.459] iteration 23341: loss: 0.044908, loss_s1: 0.037017, loss_fp: 0.002597, loss_freq: 0.019453
[06:38:54.067] iteration 23342: loss: 0.053927, loss_s1: 0.062423, loss_fp: 0.002949, loss_freq: 0.022286
[06:38:54.671] iteration 23343: loss: 0.040148, loss_s1: 0.014314, loss_fp: 0.000916, loss_freq: 0.015405
[06:38:55.288] iteration 23344: loss: 0.118366, loss_s1: 0.126436, loss_fp: 0.016232, loss_freq: 0.058092
[06:38:55.894] iteration 23345: loss: 0.043240, loss_s1: 0.031293, loss_fp: 0.003047, loss_freq: 0.018852
[06:38:56.500] iteration 23346: loss: 0.052128, loss_s1: 0.031904, loss_fp: 0.005830, loss_freq: 0.032267
[06:38:57.108] iteration 23347: loss: 0.064330, loss_s1: 0.070606, loss_fp: 0.002444, loss_freq: 0.030317
[06:38:57.713] iteration 23348: loss: 0.045438, loss_s1: 0.025324, loss_fp: 0.001833, loss_freq: 0.025170
[06:38:58.319] iteration 23349: loss: 0.040968, loss_s1: 0.027365, loss_fp: 0.002876, loss_freq: 0.024984
[06:38:58.924] iteration 23350: loss: 0.061054, loss_s1: 0.048942, loss_fp: 0.008627, loss_freq: 0.031166
[06:38:59.530] iteration 23351: loss: 0.022810, loss_s1: 0.010035, loss_fp: 0.002299, loss_freq: 0.004281
[06:39:00.138] iteration 23352: loss: 0.059266, loss_s1: 0.030851, loss_fp: 0.007067, loss_freq: 0.045728
[06:39:00.749] iteration 23353: loss: 0.039531, loss_s1: 0.042909, loss_fp: 0.000808, loss_freq: 0.005688
[06:39:01.408] iteration 23354: loss: 0.028930, loss_s1: 0.013601, loss_fp: 0.001601, loss_freq: 0.015107
[06:39:02.066] iteration 23355: loss: 0.039224, loss_s1: 0.027345, loss_fp: 0.004450, loss_freq: 0.012974
[06:39:02.709] iteration 23356: loss: 0.038570, loss_s1: 0.019206, loss_fp: 0.002678, loss_freq: 0.037420
[06:39:03.322] iteration 23357: loss: 0.041871, loss_s1: 0.021036, loss_fp: 0.001070, loss_freq: 0.007311
[06:39:03.936] iteration 23358: loss: 0.086583, loss_s1: 0.087900, loss_fp: 0.004182, loss_freq: 0.054745
[06:39:04.548] iteration 23359: loss: 0.042893, loss_s1: 0.027515, loss_fp: 0.002113, loss_freq: 0.023887
[06:39:05.163] iteration 23360: loss: 0.047475, loss_s1: 0.041166, loss_fp: 0.005503, loss_freq: 0.027177
[06:39:05.779] iteration 23361: loss: 0.053817, loss_s1: 0.036765, loss_fp: 0.005399, loss_freq: 0.029289
[06:39:06.392] iteration 23362: loss: 0.055209, loss_s1: 0.058910, loss_fp: 0.002050, loss_freq: 0.017129
[06:39:07.006] iteration 23363: loss: 0.078313, loss_s1: 0.074109, loss_fp: 0.010545, loss_freq: 0.045117
[06:39:07.634] iteration 23364: loss: 0.061949, loss_s1: 0.075037, loss_fp: 0.005214, loss_freq: 0.016460
[06:39:08.246] iteration 23365: loss: 0.053866, loss_s1: 0.024183, loss_fp: 0.001546, loss_freq: 0.055905
[06:39:08.888] iteration 23366: loss: 0.075730, loss_s1: 0.054179, loss_fp: 0.004050, loss_freq: 0.055855
[06:39:09.540] iteration 23367: loss: 0.073947, loss_s1: 0.065292, loss_fp: 0.004148, loss_freq: 0.049433
[06:39:10.326] iteration 23368: loss: 0.076122, loss_s1: 0.070764, loss_fp: 0.007276, loss_freq: 0.041400
[06:39:10.948] iteration 23369: loss: 0.041577, loss_s1: 0.024417, loss_fp: 0.002055, loss_freq: 0.029237
[06:39:11.573] iteration 23370: loss: 0.049840, loss_s1: 0.031690, loss_fp: 0.003974, loss_freq: 0.030916
[06:39:12.185] iteration 23371: loss: 0.045087, loss_s1: 0.024783, loss_fp: 0.003899, loss_freq: 0.023838
[06:39:12.792] iteration 23372: loss: 0.044935, loss_s1: 0.031114, loss_fp: 0.008034, loss_freq: 0.022796
[06:39:13.403] iteration 23373: loss: 0.054983, loss_s1: 0.046697, loss_fp: 0.003089, loss_freq: 0.022180
[06:39:14.011] iteration 23374: loss: 0.046697, loss_s1: 0.035115, loss_fp: 0.001643, loss_freq: 0.011957
[06:39:14.637] iteration 23375: loss: 0.057881, loss_s1: 0.049526, loss_fp: 0.004436, loss_freq: 0.019506
[06:39:15.298] iteration 23376: loss: 0.054810, loss_s1: 0.040568, loss_fp: 0.003466, loss_freq: 0.025043
[06:39:15.907] iteration 23377: loss: 0.054761, loss_s1: 0.067600, loss_fp: 0.002038, loss_freq: 0.021661
[06:39:16.512] iteration 23378: loss: 0.080717, loss_s1: 0.085432, loss_fp: 0.002755, loss_freq: 0.032959
[06:39:17.116] iteration 23379: loss: 0.047430, loss_s1: 0.028124, loss_fp: 0.011558, loss_freq: 0.022495
[06:39:17.724] iteration 23380: loss: 0.032840, loss_s1: 0.015264, loss_fp: 0.003606, loss_freq: 0.008333
[06:39:18.329] iteration 23381: loss: 0.052078, loss_s1: 0.037748, loss_fp: 0.002795, loss_freq: 0.032825
[06:39:18.940] iteration 23382: loss: 0.042024, loss_s1: 0.028109, loss_fp: 0.002579, loss_freq: 0.034463
[06:39:19.546] iteration 23383: loss: 0.085579, loss_s1: 0.062709, loss_fp: 0.010278, loss_freq: 0.058533
[06:39:20.168] iteration 23384: loss: 0.043146, loss_s1: 0.034820, loss_fp: 0.004315, loss_freq: 0.018872
[06:39:20.791] iteration 23385: loss: 0.050123, loss_s1: 0.039467, loss_fp: 0.003186, loss_freq: 0.028004
[06:39:21.413] iteration 23386: loss: 0.045781, loss_s1: 0.028510, loss_fp: 0.002138, loss_freq: 0.032741
[06:39:22.037] iteration 23387: loss: 0.080986, loss_s1: 0.075296, loss_fp: 0.005261, loss_freq: 0.044961
[06:39:22.658] iteration 23388: loss: 0.047996, loss_s1: 0.031162, loss_fp: 0.001927, loss_freq: 0.022388
[06:39:23.282] iteration 23389: loss: 0.033872, loss_s1: 0.015784, loss_fp: 0.002230, loss_freq: 0.018325
[06:39:23.907] iteration 23390: loss: 0.042661, loss_s1: 0.023362, loss_fp: 0.005864, loss_freq: 0.016266
[06:39:24.572] iteration 23391: loss: 0.056625, loss_s1: 0.054656, loss_fp: 0.002936, loss_freq: 0.028960
[06:39:25.182] iteration 23392: loss: 0.042137, loss_s1: 0.026486, loss_fp: 0.001986, loss_freq: 0.008282
[06:39:25.834] iteration 23393: loss: 0.043015, loss_s1: 0.040763, loss_fp: 0.001049, loss_freq: 0.018873
[06:39:26.486] iteration 23394: loss: 0.045024, loss_s1: 0.030012, loss_fp: 0.007720, loss_freq: 0.022348
[06:39:27.139] iteration 23395: loss: 0.026618, loss_s1: 0.009312, loss_fp: 0.001031, loss_freq: 0.013241
[06:39:27.747] iteration 23396: loss: 0.075057, loss_s1: 0.072340, loss_fp: 0.003520, loss_freq: 0.036941
[06:39:28.365] iteration 23397: loss: 0.064213, loss_s1: 0.056496, loss_fp: 0.008956, loss_freq: 0.024191
[06:39:28.971] iteration 23398: loss: 0.049394, loss_s1: 0.050931, loss_fp: 0.002927, loss_freq: 0.018571
[06:39:29.579] iteration 23399: loss: 0.059323, loss_s1: 0.030740, loss_fp: 0.008203, loss_freq: 0.043728
[06:39:30.268] iteration 23400: loss: 0.039097, loss_s1: 0.026482, loss_fp: 0.003595, loss_freq: 0.023562
[06:39:33.906] iteration 23400 : mean_dice : 0.751610
[06:39:34.555] iteration 23401: loss: 0.073548, loss_s1: 0.075993, loss_fp: 0.005269, loss_freq: 0.035176
[06:39:35.164] iteration 23402: loss: 0.058565, loss_s1: 0.039767, loss_fp: 0.005286, loss_freq: 0.039744
[06:39:35.767] iteration 23403: loss: 0.053808, loss_s1: 0.039968, loss_fp: 0.003368, loss_freq: 0.030301
[06:39:36.373] iteration 23404: loss: 0.027667, loss_s1: 0.019123, loss_fp: 0.003609, loss_freq: 0.012189
[06:39:36.987] iteration 23405: loss: 0.060590, loss_s1: 0.043362, loss_fp: 0.005079, loss_freq: 0.041398
[06:39:37.591] iteration 23406: loss: 0.070673, loss_s1: 0.057832, loss_fp: 0.006243, loss_freq: 0.047839
[06:39:38.198] iteration 23407: loss: 0.043592, loss_s1: 0.027954, loss_fp: 0.011110, loss_freq: 0.018062
[06:39:38.807] iteration 23408: loss: 0.055359, loss_s1: 0.034734, loss_fp: 0.007760, loss_freq: 0.041209
[06:39:39.453] iteration 23409: loss: 0.077798, loss_s1: 0.076323, loss_fp: 0.003022, loss_freq: 0.042460
[06:39:40.077] iteration 23410: loss: 0.044076, loss_s1: 0.041163, loss_fp: 0.005111, loss_freq: 0.005021
[06:39:40.682] iteration 23411: loss: 0.064878, loss_s1: 0.074526, loss_fp: 0.005699, loss_freq: 0.008141
[06:39:41.288] iteration 23412: loss: 0.076604, loss_s1: 0.078321, loss_fp: 0.008059, loss_freq: 0.040470
[06:39:41.943] iteration 23413: loss: 0.050659, loss_s1: 0.024355, loss_fp: 0.009141, loss_freq: 0.038221
[06:39:42.547] iteration 23414: loss: 0.040867, loss_s1: 0.027084, loss_fp: 0.010629, loss_freq: 0.017375
[06:39:43.163] iteration 23415: loss: 0.049430, loss_s1: 0.025565, loss_fp: 0.005445, loss_freq: 0.031025
[06:39:43.776] iteration 23416: loss: 0.083539, loss_s1: 0.103421, loss_fp: 0.003114, loss_freq: 0.027977
[06:39:44.387] iteration 23417: loss: 0.082958, loss_s1: 0.077171, loss_fp: 0.002890, loss_freq: 0.065449
[06:39:44.999] iteration 23418: loss: 0.042249, loss_s1: 0.018055, loss_fp: 0.014828, loss_freq: 0.018241
[06:39:45.611] iteration 23419: loss: 0.054944, loss_s1: 0.050861, loss_fp: 0.007894, loss_freq: 0.023469
[06:39:46.228] iteration 23420: loss: 0.055545, loss_s1: 0.033647, loss_fp: 0.004992, loss_freq: 0.043963
[06:39:46.871] iteration 23421: loss: 0.030327, loss_s1: 0.023493, loss_fp: 0.002309, loss_freq: 0.012630
[06:39:47.474] iteration 23422: loss: 0.053345, loss_s1: 0.054266, loss_fp: 0.008666, loss_freq: 0.009948
[06:39:48.086] iteration 23423: loss: 0.079129, loss_s1: 0.061072, loss_fp: 0.009850, loss_freq: 0.038644
[06:39:48.695] iteration 23424: loss: 0.037485, loss_s1: 0.026293, loss_fp: 0.004752, loss_freq: 0.011989
[06:39:49.378] iteration 23425: loss: 0.039883, loss_s1: 0.031261, loss_fp: 0.001339, loss_freq: 0.016698
[06:39:50.051] iteration 23426: loss: 0.032779, loss_s1: 0.029260, loss_fp: 0.003143, loss_freq: 0.010062
[06:39:50.722] iteration 23427: loss: 0.075770, loss_s1: 0.104004, loss_fp: 0.002746, loss_freq: 0.008111
[06:39:51.392] iteration 23428: loss: 0.045266, loss_s1: 0.018676, loss_fp: 0.014957, loss_freq: 0.033827
[06:39:52.028] iteration 23429: loss: 0.093372, loss_s1: 0.103683, loss_fp: 0.004858, loss_freq: 0.049073
[06:39:52.649] iteration 23430: loss: 0.062055, loss_s1: 0.065613, loss_fp: 0.003558, loss_freq: 0.033884
[06:39:53.264] iteration 23431: loss: 0.060436, loss_s1: 0.054590, loss_fp: 0.001466, loss_freq: 0.025965
[06:39:53.885] iteration 23432: loss: 0.046771, loss_s1: 0.038457, loss_fp: 0.004401, loss_freq: 0.017448
[06:39:54.507] iteration 23433: loss: 0.080628, loss_s1: 0.103575, loss_fp: 0.006079, loss_freq: 0.018656
[06:39:55.133] iteration 23434: loss: 0.049207, loss_s1: 0.036155, loss_fp: 0.003472, loss_freq: 0.013186
[06:39:55.755] iteration 23435: loss: 0.030718, loss_s1: 0.020752, loss_fp: 0.002521, loss_freq: 0.008100
[06:39:56.373] iteration 23436: loss: 0.057872, loss_s1: 0.044606, loss_fp: 0.005264, loss_freq: 0.029936
[06:39:56.997] iteration 23437: loss: 0.045520, loss_s1: 0.031400, loss_fp: 0.004346, loss_freq: 0.021360
[06:39:57.616] iteration 23438: loss: 0.057933, loss_s1: 0.053468, loss_fp: 0.009297, loss_freq: 0.027565
[06:39:58.238] iteration 23439: loss: 0.070679, loss_s1: 0.086292, loss_fp: 0.002550, loss_freq: 0.031819
[06:39:58.855] iteration 23440: loss: 0.050536, loss_s1: 0.045615, loss_fp: 0.003042, loss_freq: 0.021398
[06:39:59.485] iteration 23441: loss: 0.060135, loss_s1: 0.054947, loss_fp: 0.007922, loss_freq: 0.025223
[06:40:00.120] iteration 23442: loss: 0.060593, loss_s1: 0.041980, loss_fp: 0.005516, loss_freq: 0.040919
[06:40:00.747] iteration 23443: loss: 0.073745, loss_s1: 0.061524, loss_fp: 0.008149, loss_freq: 0.047287
[06:40:01.370] iteration 23444: loss: 0.072649, loss_s1: 0.055427, loss_fp: 0.004241, loss_freq: 0.042457
[06:40:02.044] iteration 23445: loss: 0.071489, loss_s1: 0.051723, loss_fp: 0.005327, loss_freq: 0.048332
[06:40:02.699] iteration 23446: loss: 0.031733, loss_s1: 0.024469, loss_fp: 0.001022, loss_freq: 0.005938
[06:40:03.355] iteration 23447: loss: 0.034146, loss_s1: 0.035815, loss_fp: 0.004421, loss_freq: 0.007953
[06:40:03.993] iteration 23448: loss: 0.072444, loss_s1: 0.057499, loss_fp: 0.004877, loss_freq: 0.051006
[06:40:04.603] iteration 23449: loss: 0.072122, loss_s1: 0.055496, loss_fp: 0.017785, loss_freq: 0.042269
[06:40:05.225] iteration 23450: loss: 0.057264, loss_s1: 0.045668, loss_fp: 0.003867, loss_freq: 0.019699
[06:40:05.839] iteration 23451: loss: 0.035368, loss_s1: 0.030275, loss_fp: 0.002809, loss_freq: 0.005066
[06:40:06.448] iteration 23452: loss: 0.056623, loss_s1: 0.052296, loss_fp: 0.007397, loss_freq: 0.031666
[06:40:07.057] iteration 23453: loss: 0.034618, loss_s1: 0.022379, loss_fp: 0.000760, loss_freq: 0.010635
[06:40:07.665] iteration 23454: loss: 0.073850, loss_s1: 0.074394, loss_fp: 0.004706, loss_freq: 0.025412
[06:40:08.269] iteration 23455: loss: 0.045266, loss_s1: 0.033985, loss_fp: 0.005045, loss_freq: 0.006222
[06:40:08.875] iteration 23456: loss: 0.073470, loss_s1: 0.080554, loss_fp: 0.004166, loss_freq: 0.026836
[06:40:09.477] iteration 23457: loss: 0.070281, loss_s1: 0.060898, loss_fp: 0.006351, loss_freq: 0.030086
[06:40:10.083] iteration 23458: loss: 0.071906, loss_s1: 0.065851, loss_fp: 0.008319, loss_freq: 0.037101
[06:40:10.691] iteration 23459: loss: 0.057419, loss_s1: 0.067006, loss_fp: 0.003199, loss_freq: 0.021086
[06:40:11.292] iteration 23460: loss: 0.071200, loss_s1: 0.076703, loss_fp: 0.003788, loss_freq: 0.030295
[06:40:12.221] iteration 23461: loss: 0.083271, loss_s1: 0.092131, loss_fp: 0.008755, loss_freq: 0.024074
[06:40:12.825] iteration 23462: loss: 0.039497, loss_s1: 0.024177, loss_fp: 0.002936, loss_freq: 0.019595
[06:40:13.434] iteration 23463: loss: 0.043572, loss_s1: 0.035014, loss_fp: 0.005261, loss_freq: 0.020008
[06:40:14.044] iteration 23464: loss: 0.043477, loss_s1: 0.037817, loss_fp: 0.003399, loss_freq: 0.012874
[06:40:14.652] iteration 23465: loss: 0.059176, loss_s1: 0.063286, loss_fp: 0.007649, loss_freq: 0.021288
[06:40:15.263] iteration 23466: loss: 0.053256, loss_s1: 0.028444, loss_fp: 0.002241, loss_freq: 0.042892
[06:40:15.870] iteration 23467: loss: 0.032620, loss_s1: 0.018694, loss_fp: 0.000892, loss_freq: 0.015247
[06:40:16.476] iteration 23468: loss: 0.049521, loss_s1: 0.042038, loss_fp: 0.004672, loss_freq: 0.024427
[06:40:17.077] iteration 23469: loss: 0.046815, loss_s1: 0.021760, loss_fp: 0.004477, loss_freq: 0.036926
[06:40:17.682] iteration 23470: loss: 0.058830, loss_s1: 0.041439, loss_fp: 0.006816, loss_freq: 0.030763
[06:40:18.283] iteration 23471: loss: 0.044056, loss_s1: 0.022993, loss_fp: 0.002020, loss_freq: 0.027726
[06:40:18.946] iteration 23472: loss: 0.085470, loss_s1: 0.095503, loss_fp: 0.001671, loss_freq: 0.042792
[06:40:19.607] iteration 23473: loss: 0.060516, loss_s1: 0.049298, loss_fp: 0.003322, loss_freq: 0.036657
[06:40:20.266] iteration 23474: loss: 0.076144, loss_s1: 0.089124, loss_fp: 0.011095, loss_freq: 0.026580
[06:40:20.889] iteration 23475: loss: 0.047771, loss_s1: 0.045717, loss_fp: 0.003537, loss_freq: 0.012445
[06:40:21.504] iteration 23476: loss: 0.038073, loss_s1: 0.023869, loss_fp: 0.003930, loss_freq: 0.012628
[06:40:22.121] iteration 23477: loss: 0.101714, loss_s1: 0.099582, loss_fp: 0.010672, loss_freq: 0.072799
[06:40:22.732] iteration 23478: loss: 0.036001, loss_s1: 0.028760, loss_fp: 0.001552, loss_freq: 0.012903
[06:40:23.347] iteration 23479: loss: 0.037819, loss_s1: 0.027595, loss_fp: 0.005195, loss_freq: 0.012315
[06:40:23.957] iteration 23480: loss: 0.059280, loss_s1: 0.057553, loss_fp: 0.004244, loss_freq: 0.011385
[06:40:24.570] iteration 23481: loss: 0.051671, loss_s1: 0.034848, loss_fp: 0.002555, loss_freq: 0.023360
[06:40:25.179] iteration 23482: loss: 0.042412, loss_s1: 0.033321, loss_fp: 0.003534, loss_freq: 0.023484
[06:40:25.798] iteration 23483: loss: 0.054994, loss_s1: 0.040377, loss_fp: 0.003227, loss_freq: 0.025484
[06:40:26.404] iteration 23484: loss: 0.054183, loss_s1: 0.037044, loss_fp: 0.002514, loss_freq: 0.029790
[06:40:27.046] iteration 23485: loss: 0.093171, loss_s1: 0.057924, loss_fp: 0.008298, loss_freq: 0.045690
[06:40:27.652] iteration 23486: loss: 0.060060, loss_s1: 0.069664, loss_fp: 0.003351, loss_freq: 0.026440
[06:40:28.262] iteration 23487: loss: 0.053186, loss_s1: 0.044622, loss_fp: 0.009036, loss_freq: 0.015122
[06:40:28.872] iteration 23488: loss: 0.084937, loss_s1: 0.092686, loss_fp: 0.002100, loss_freq: 0.031992
[06:40:29.488] iteration 23489: loss: 0.070098, loss_s1: 0.058531, loss_fp: 0.001820, loss_freq: 0.040167
[06:40:30.119] iteration 23490: loss: 0.081616, loss_s1: 0.070079, loss_fp: 0.006617, loss_freq: 0.053329
[06:40:30.734] iteration 23491: loss: 0.065076, loss_s1: 0.052398, loss_fp: 0.006184, loss_freq: 0.048577
[06:40:31.358] iteration 23492: loss: 0.083195, loss_s1: 0.043408, loss_fp: 0.007072, loss_freq: 0.046695
[06:40:31.980] iteration 23493: loss: 0.072023, loss_s1: 0.062478, loss_fp: 0.008770, loss_freq: 0.042355
[06:40:32.591] iteration 23494: loss: 0.038588, loss_s1: 0.032314, loss_fp: 0.003639, loss_freq: 0.006983
[06:40:33.206] iteration 23495: loss: 0.049677, loss_s1: 0.027229, loss_fp: 0.003631, loss_freq: 0.046711
[06:40:33.878] iteration 23496: loss: 0.064800, loss_s1: 0.042361, loss_fp: 0.004458, loss_freq: 0.025705
[06:40:34.532] iteration 23497: loss: 0.093012, loss_s1: 0.093770, loss_fp: 0.002783, loss_freq: 0.054449
[06:40:35.190] iteration 23498: loss: 0.054743, loss_s1: 0.063409, loss_fp: 0.008372, loss_freq: 0.006809
[06:40:35.844] iteration 23499: loss: 0.071779, loss_s1: 0.070418, loss_fp: 0.003506, loss_freq: 0.029171
[06:40:36.496] iteration 23500: loss: 0.093290, loss_s1: 0.128128, loss_fp: 0.004666, loss_freq: 0.024963
[06:40:37.145] iteration 23501: loss: 0.120836, loss_s1: 0.150093, loss_fp: 0.005611, loss_freq: 0.048372
[06:40:37.795] iteration 23502: loss: 0.096526, loss_s1: 0.119941, loss_fp: 0.005394, loss_freq: 0.031187
[06:40:38.444] iteration 23503: loss: 0.090909, loss_s1: 0.048917, loss_fp: 0.010505, loss_freq: 0.096150
[06:40:39.055] iteration 23504: loss: 0.099810, loss_s1: 0.118643, loss_fp: 0.005767, loss_freq: 0.047443
[06:40:39.682] iteration 23505: loss: 0.063105, loss_s1: 0.068188, loss_fp: 0.000994, loss_freq: 0.017577
[06:40:40.328] iteration 23506: loss: 0.067807, loss_s1: 0.065870, loss_fp: 0.007370, loss_freq: 0.028131
[06:40:40.984] iteration 23507: loss: 0.047988, loss_s1: 0.041645, loss_fp: 0.006834, loss_freq: 0.016737
[06:40:41.659] iteration 23508: loss: 0.044887, loss_s1: 0.043642, loss_fp: 0.005164, loss_freq: 0.012976
[06:40:42.287] iteration 23509: loss: 0.040875, loss_s1: 0.022539, loss_fp: 0.002256, loss_freq: 0.015311
[06:40:42.901] iteration 23510: loss: 0.032189, loss_s1: 0.018718, loss_fp: 0.000644, loss_freq: 0.009844
[06:40:43.506] iteration 23511: loss: 0.054714, loss_s1: 0.054068, loss_fp: 0.000915, loss_freq: 0.026191
[06:40:44.112] iteration 23512: loss: 0.090117, loss_s1: 0.115069, loss_fp: 0.001192, loss_freq: 0.033478
[06:40:44.721] iteration 23513: loss: 0.034073, loss_s1: 0.017511, loss_fp: 0.002086, loss_freq: 0.015699
[06:40:45.335] iteration 23514: loss: 0.121595, loss_s1: 0.095823, loss_fp: 0.010462, loss_freq: 0.104572
[06:40:45.965] iteration 23515: loss: 0.049314, loss_s1: 0.035932, loss_fp: 0.001643, loss_freq: 0.027363
[06:40:46.572] iteration 23516: loss: 0.041725, loss_s1: 0.025558, loss_fp: 0.007138, loss_freq: 0.014649
[06:40:47.232] iteration 23517: loss: 0.071662, loss_s1: 0.036211, loss_fp: 0.001780, loss_freq: 0.079578
[06:40:47.889] iteration 23518: loss: 0.047212, loss_s1: 0.029051, loss_fp: 0.008879, loss_freq: 0.016114
[06:40:48.544] iteration 23519: loss: 0.044303, loss_s1: 0.028886, loss_fp: 0.001435, loss_freq: 0.026818
[06:40:49.199] iteration 23520: loss: 0.042735, loss_s1: 0.025874, loss_fp: 0.003500, loss_freq: 0.027786
[06:40:49.847] iteration 23521: loss: 0.032995, loss_s1: 0.033866, loss_fp: 0.001287, loss_freq: 0.006204
[06:40:50.455] iteration 23522: loss: 0.054976, loss_s1: 0.048101, loss_fp: 0.001650, loss_freq: 0.027519
[06:40:51.062] iteration 23523: loss: 0.034261, loss_s1: 0.012819, loss_fp: 0.001814, loss_freq: 0.019340
[06:40:51.672] iteration 23524: loss: 0.042764, loss_s1: 0.035711, loss_fp: 0.001441, loss_freq: 0.017182
[06:40:52.300] iteration 23525: loss: 0.041237, loss_s1: 0.024058, loss_fp: 0.003402, loss_freq: 0.017045
[06:40:52.907] iteration 23526: loss: 0.045020, loss_s1: 0.035638, loss_fp: 0.002211, loss_freq: 0.024005
[06:40:53.520] iteration 23527: loss: 0.053906, loss_s1: 0.045567, loss_fp: 0.000777, loss_freq: 0.025997
[06:40:54.125] iteration 23528: loss: 0.096058, loss_s1: 0.103535, loss_fp: 0.010366, loss_freq: 0.044578
[06:40:54.731] iteration 23529: loss: 0.040684, loss_s1: 0.017213, loss_fp: 0.004859, loss_freq: 0.029244
[06:40:55.334] iteration 23530: loss: 0.043927, loss_s1: 0.046505, loss_fp: 0.004430, loss_freq: 0.015057
[06:40:55.946] iteration 23531: loss: 0.057464, loss_s1: 0.037907, loss_fp: 0.003267, loss_freq: 0.038429
[06:40:56.555] iteration 23532: loss: 0.041595, loss_s1: 0.022018, loss_fp: 0.001612, loss_freq: 0.027554
[06:40:57.165] iteration 23533: loss: 0.052165, loss_s1: 0.053244, loss_fp: 0.006291, loss_freq: 0.018380
[06:40:57.818] iteration 23534: loss: 0.058765, loss_s1: 0.069245, loss_fp: 0.002561, loss_freq: 0.018359
[06:40:58.426] iteration 23535: loss: 0.059053, loss_s1: 0.049345, loss_fp: 0.001355, loss_freq: 0.031413
[06:40:59.034] iteration 23536: loss: 0.056885, loss_s1: 0.049119, loss_fp: 0.002380, loss_freq: 0.028722
[06:40:59.646] iteration 23537: loss: 0.046337, loss_s1: 0.035245, loss_fp: 0.001070, loss_freq: 0.026655
[06:41:00.256] iteration 23538: loss: 0.064712, loss_s1: 0.061897, loss_fp: 0.003997, loss_freq: 0.028886
[06:41:00.870] iteration 23539: loss: 0.035272, loss_s1: 0.020627, loss_fp: 0.008748, loss_freq: 0.019362
[06:41:01.482] iteration 23540: loss: 0.056182, loss_s1: 0.034045, loss_fp: 0.003295, loss_freq: 0.020054
[06:41:02.091] iteration 23541: loss: 0.041716, loss_s1: 0.022065, loss_fp: 0.003546, loss_freq: 0.020265
[06:41:02.721] iteration 23542: loss: 0.057490, loss_s1: 0.035420, loss_fp: 0.002722, loss_freq: 0.043314
[06:41:03.337] iteration 23543: loss: 0.070488, loss_s1: 0.084112, loss_fp: 0.002298, loss_freq: 0.025132
[06:41:03.951] iteration 23544: loss: 0.060094, loss_s1: 0.065511, loss_fp: 0.002838, loss_freq: 0.022015
[06:41:04.560] iteration 23545: loss: 0.053341, loss_s1: 0.037474, loss_fp: 0.003615, loss_freq: 0.031503
[06:41:05.171] iteration 23546: loss: 0.079031, loss_s1: 0.042022, loss_fp: 0.009203, loss_freq: 0.048676
[06:41:05.781] iteration 23547: loss: 0.051004, loss_s1: 0.065491, loss_fp: 0.003406, loss_freq: 0.011441
[06:41:06.394] iteration 23548: loss: 0.063195, loss_s1: 0.066645, loss_fp: 0.003320, loss_freq: 0.029973
[06:41:07.005] iteration 23549: loss: 0.044285, loss_s1: 0.035498, loss_fp: 0.002041, loss_freq: 0.021203
[06:41:07.614] iteration 23550: loss: 0.067680, loss_s1: 0.082626, loss_fp: 0.001097, loss_freq: 0.003563
[06:41:08.221] iteration 23551: loss: 0.069552, loss_s1: 0.073425, loss_fp: 0.001876, loss_freq: 0.034002
[06:41:08.833] iteration 23552: loss: 0.051647, loss_s1: 0.036940, loss_fp: 0.002735, loss_freq: 0.046069
[06:41:09.458] iteration 23553: loss: 0.063895, loss_s1: 0.049775, loss_fp: 0.005269, loss_freq: 0.032010
[06:41:10.120] iteration 23554: loss: 0.062051, loss_s1: 0.061345, loss_fp: 0.005362, loss_freq: 0.028957
[06:41:10.774] iteration 23555: loss: 0.070985, loss_s1: 0.092165, loss_fp: 0.004791, loss_freq: 0.012567
[06:41:11.427] iteration 23556: loss: 0.054047, loss_s1: 0.033149, loss_fp: 0.004531, loss_freq: 0.041786
[06:41:12.093] iteration 23557: loss: 0.060327, loss_s1: 0.046732, loss_fp: 0.003050, loss_freq: 0.034024
[06:41:12.980] iteration 23558: loss: 0.055555, loss_s1: 0.029527, loss_fp: 0.006811, loss_freq: 0.041895
[06:41:13.785] iteration 23559: loss: 0.092333, loss_s1: 0.064083, loss_fp: 0.003535, loss_freq: 0.056399
[06:41:14.549] iteration 23560: loss: 0.047542, loss_s1: 0.034945, loss_fp: 0.004067, loss_freq: 0.014043
[06:41:15.187] iteration 23561: loss: 0.066677, loss_s1: 0.071871, loss_fp: 0.002462, loss_freq: 0.040033
[06:41:15.788] iteration 23562: loss: 0.054545, loss_s1: 0.032251, loss_fp: 0.001583, loss_freq: 0.035251
[06:41:16.396] iteration 23563: loss: 0.032535, loss_s1: 0.019471, loss_fp: 0.002277, loss_freq: 0.019661
[06:41:17.000] iteration 23564: loss: 0.033040, loss_s1: 0.023078, loss_fp: 0.002311, loss_freq: 0.015600
[06:41:17.609] iteration 23565: loss: 0.029754, loss_s1: 0.027763, loss_fp: 0.003660, loss_freq: 0.007021
[06:41:18.223] iteration 23566: loss: 0.070271, loss_s1: 0.079681, loss_fp: 0.002529, loss_freq: 0.022314
[06:41:18.827] iteration 23567: loss: 0.059294, loss_s1: 0.056387, loss_fp: 0.003956, loss_freq: 0.016756
[06:41:19.435] iteration 23568: loss: 0.033923, loss_s1: 0.022287, loss_fp: 0.001670, loss_freq: 0.020121
[06:41:20.064] iteration 23569: loss: 0.044560, loss_s1: 0.018256, loss_fp: 0.006441, loss_freq: 0.032718
[06:41:20.671] iteration 23570: loss: 0.046729, loss_s1: 0.026731, loss_fp: 0.014306, loss_freq: 0.027055
[06:41:21.276] iteration 23571: loss: 0.037176, loss_s1: 0.018870, loss_fp: 0.003656, loss_freq: 0.020545
[06:41:21.974] iteration 23572: loss: 0.040745, loss_s1: 0.029939, loss_fp: 0.005238, loss_freq: 0.015659
[06:41:22.589] iteration 23573: loss: 0.054283, loss_s1: 0.057498, loss_fp: 0.002372, loss_freq: 0.024178
[06:41:23.198] iteration 23574: loss: 0.046015, loss_s1: 0.032882, loss_fp: 0.005144, loss_freq: 0.031473
[06:41:23.817] iteration 23575: loss: 0.067807, loss_s1: 0.031766, loss_fp: 0.005558, loss_freq: 0.044542
[06:41:24.425] iteration 23576: loss: 0.070796, loss_s1: 0.057489, loss_fp: 0.008930, loss_freq: 0.041719
[06:41:25.028] iteration 23577: loss: 0.049399, loss_s1: 0.034358, loss_fp: 0.004418, loss_freq: 0.027359
[06:41:25.634] iteration 23578: loss: 0.044071, loss_s1: 0.032863, loss_fp: 0.009382, loss_freq: 0.020495
[06:41:26.241] iteration 23579: loss: 0.053706, loss_s1: 0.040812, loss_fp: 0.003264, loss_freq: 0.034160
[06:41:26.850] iteration 23580: loss: 0.051277, loss_s1: 0.043769, loss_fp: 0.005883, loss_freq: 0.016265
[06:41:27.463] iteration 23581: loss: 0.028474, loss_s1: 0.011423, loss_fp: 0.000828, loss_freq: 0.002775
[06:41:28.074] iteration 23582: loss: 0.050304, loss_s1: 0.037523, loss_fp: 0.004243, loss_freq: 0.039204
[06:41:28.679] iteration 23583: loss: 0.068248, loss_s1: 0.050057, loss_fp: 0.008220, loss_freq: 0.044571
[06:41:29.283] iteration 23584: loss: 0.052070, loss_s1: 0.052868, loss_fp: 0.002205, loss_freq: 0.016778
[06:41:29.889] iteration 23585: loss: 0.058786, loss_s1: 0.028393, loss_fp: 0.012592, loss_freq: 0.037253
[06:41:30.495] iteration 23586: loss: 0.044437, loss_s1: 0.026958, loss_fp: 0.002100, loss_freq: 0.025937
[06:41:31.103] iteration 23587: loss: 0.050586, loss_s1: 0.038826, loss_fp: 0.004040, loss_freq: 0.038388
[06:41:31.707] iteration 23588: loss: 0.059423, loss_s1: 0.059163, loss_fp: 0.004218, loss_freq: 0.019910
[06:41:32.308] iteration 23589: loss: 0.047610, loss_s1: 0.047673, loss_fp: 0.004978, loss_freq: 0.014691
[06:41:32.910] iteration 23590: loss: 0.061426, loss_s1: 0.059856, loss_fp: 0.007876, loss_freq: 0.025934
[06:41:33.522] iteration 23591: loss: 0.049276, loss_s1: 0.032210, loss_fp: 0.002227, loss_freq: 0.031320
[06:41:34.130] iteration 23592: loss: 0.097769, loss_s1: 0.075477, loss_fp: 0.002918, loss_freq: 0.024766
[06:41:34.790] iteration 23593: loss: 0.058109, loss_s1: 0.046955, loss_fp: 0.002030, loss_freq: 0.033483
[06:41:35.447] iteration 23594: loss: 0.069297, loss_s1: 0.088724, loss_fp: 0.001931, loss_freq: 0.016439
[06:41:36.103] iteration 23595: loss: 0.054010, loss_s1: 0.035101, loss_fp: 0.005347, loss_freq: 0.026138
[06:41:36.722] iteration 23596: loss: 0.035291, loss_s1: 0.025078, loss_fp: 0.004658, loss_freq: 0.013947
[06:41:37.330] iteration 23597: loss: 0.078029, loss_s1: 0.051753, loss_fp: 0.001234, loss_freq: 0.039679
[06:41:37.944] iteration 23598: loss: 0.064658, loss_s1: 0.050786, loss_fp: 0.002647, loss_freq: 0.044223
[06:41:38.567] iteration 23599: loss: 0.061610, loss_s1: 0.055617, loss_fp: 0.004159, loss_freq: 0.033687
[06:41:39.173] iteration 23600: loss: 0.076392, loss_s1: 0.070573, loss_fp: 0.005329, loss_freq: 0.051784
[06:41:42.639] iteration 23600 : mean_dice : 0.745621
[06:41:43.361] iteration 23601: loss: 0.061047, loss_s1: 0.048559, loss_fp: 0.004922, loss_freq: 0.027730
[06:41:44.057] iteration 23602: loss: 0.064912, loss_s1: 0.041787, loss_fp: 0.002481, loss_freq: 0.048657
[06:41:44.733] iteration 23603: loss: 0.034820, loss_s1: 0.021822, loss_fp: 0.003207, loss_freq: 0.011953
[06:41:45.398] iteration 23604: loss: 0.039717, loss_s1: 0.019251, loss_fp: 0.002516, loss_freq: 0.026497
[06:41:46.064] iteration 23605: loss: 0.052332, loss_s1: 0.059128, loss_fp: 0.004312, loss_freq: 0.013311
[06:41:46.749] iteration 23606: loss: 0.066741, loss_s1: 0.057353, loss_fp: 0.003055, loss_freq: 0.020997
[06:41:47.389] iteration 23607: loss: 0.037238, loss_s1: 0.020125, loss_fp: 0.004837, loss_freq: 0.020716
[06:41:47.987] iteration 23608: loss: 0.072453, loss_s1: 0.078986, loss_fp: 0.003175, loss_freq: 0.035112
[06:41:48.589] iteration 23609: loss: 0.083867, loss_s1: 0.077778, loss_fp: 0.002404, loss_freq: 0.067670
[06:41:49.191] iteration 23610: loss: 0.086538, loss_s1: 0.076247, loss_fp: 0.010009, loss_freq: 0.043012
[06:41:49.795] iteration 23611: loss: 0.073811, loss_s1: 0.057134, loss_fp: 0.018447, loss_freq: 0.038126
[06:41:50.399] iteration 23612: loss: 0.086370, loss_s1: 0.107327, loss_fp: 0.004014, loss_freq: 0.026070
[06:41:50.999] iteration 23613: loss: 0.087013, loss_s1: 0.079962, loss_fp: 0.008305, loss_freq: 0.031235
[06:41:51.602] iteration 23614: loss: 0.070577, loss_s1: 0.061197, loss_fp: 0.003683, loss_freq: 0.041576
[06:41:52.208] iteration 23615: loss: 0.049240, loss_s1: 0.041681, loss_fp: 0.005345, loss_freq: 0.019408
[06:41:52.810] iteration 23616: loss: 0.035331, loss_s1: 0.013319, loss_fp: 0.001179, loss_freq: 0.014825
[06:41:53.413] iteration 23617: loss: 0.034747, loss_s1: 0.028623, loss_fp: 0.001860, loss_freq: 0.019394
[06:41:54.016] iteration 23618: loss: 0.064146, loss_s1: 0.057006, loss_fp: 0.008439, loss_freq: 0.028293
[06:41:54.622] iteration 23619: loss: 0.061058, loss_s1: 0.061833, loss_fp: 0.004422, loss_freq: 0.025986
[06:41:55.237] iteration 23620: loss: 0.089655, loss_s1: 0.088850, loss_fp: 0.009583, loss_freq: 0.025991
[06:41:55.882] iteration 23621: loss: 0.063160, loss_s1: 0.077019, loss_fp: 0.001457, loss_freq: 0.012037
[06:41:56.529] iteration 23622: loss: 0.049353, loss_s1: 0.037579, loss_fp: 0.003482, loss_freq: 0.037183
[06:41:57.140] iteration 23623: loss: 0.037542, loss_s1: 0.013191, loss_fp: 0.006237, loss_freq: 0.013847
[06:41:57.745] iteration 23624: loss: 0.052615, loss_s1: 0.042161, loss_fp: 0.004030, loss_freq: 0.029072
[06:41:58.353] iteration 23625: loss: 0.041931, loss_s1: 0.019950, loss_fp: 0.004331, loss_freq: 0.024101
[06:41:58.964] iteration 23626: loss: 0.090076, loss_s1: 0.066775, loss_fp: 0.002814, loss_freq: 0.089282
[06:41:59.575] iteration 23627: loss: 0.060039, loss_s1: 0.034851, loss_fp: 0.009117, loss_freq: 0.041549
[06:42:00.187] iteration 23628: loss: 0.048865, loss_s1: 0.032631, loss_fp: 0.003735, loss_freq: 0.027531
[06:42:00.798] iteration 23629: loss: 0.085370, loss_s1: 0.071967, loss_fp: 0.003455, loss_freq: 0.069532
[06:42:01.407] iteration 23630: loss: 0.062218, loss_s1: 0.066784, loss_fp: 0.001488, loss_freq: 0.022961
[06:42:02.340] iteration 23631: loss: 0.045315, loss_s1: 0.036874, loss_fp: 0.002748, loss_freq: 0.018324
[06:42:02.982] iteration 23632: loss: 0.051528, loss_s1: 0.035252, loss_fp: 0.002975, loss_freq: 0.033238
[06:42:03.601] iteration 23633: loss: 0.081207, loss_s1: 0.087204, loss_fp: 0.009161, loss_freq: 0.036713
[06:42:04.235] iteration 23634: loss: 0.042039, loss_s1: 0.033878, loss_fp: 0.000936, loss_freq: 0.013436
[06:42:04.859] iteration 23635: loss: 0.046770, loss_s1: 0.035923, loss_fp: 0.002956, loss_freq: 0.028746
[06:42:05.481] iteration 23636: loss: 0.059617, loss_s1: 0.049564, loss_fp: 0.008318, loss_freq: 0.022896
[06:42:06.140] iteration 23637: loss: 0.043665, loss_s1: 0.022535, loss_fp: 0.002529, loss_freq: 0.034871
[06:42:06.766] iteration 23638: loss: 0.046807, loss_s1: 0.034129, loss_fp: 0.004934, loss_freq: 0.028493
[06:42:07.372] iteration 23639: loss: 0.051020, loss_s1: 0.042631, loss_fp: 0.001845, loss_freq: 0.035354
[06:42:07.981] iteration 23640: loss: 0.062742, loss_s1: 0.070092, loss_fp: 0.003491, loss_freq: 0.017611
[06:42:08.588] iteration 23641: loss: 0.053076, loss_s1: 0.030005, loss_fp: 0.001907, loss_freq: 0.039483
[06:42:09.198] iteration 23642: loss: 0.056595, loss_s1: 0.045844, loss_fp: 0.001161, loss_freq: 0.037105
[06:42:09.798] iteration 23643: loss: 0.046900, loss_s1: 0.026883, loss_fp: 0.010206, loss_freq: 0.025139
[06:42:10.396] iteration 23644: loss: 0.077764, loss_s1: 0.048484, loss_fp: 0.009033, loss_freq: 0.064307
[06:42:11.001] iteration 23645: loss: 0.044854, loss_s1: 0.039286, loss_fp: 0.001321, loss_freq: 0.019556
[06:42:11.639] iteration 23646: loss: 0.037204, loss_s1: 0.024605, loss_fp: 0.005833, loss_freq: 0.009281
[06:42:12.242] iteration 23647: loss: 0.090677, loss_s1: 0.110582, loss_fp: 0.007436, loss_freq: 0.042258
[06:42:12.850] iteration 23648: loss: 0.037400, loss_s1: 0.029539, loss_fp: 0.004588, loss_freq: 0.014153
[06:42:13.456] iteration 23649: loss: 0.056849, loss_s1: 0.048827, loss_fp: 0.006211, loss_freq: 0.028948
[06:42:14.064] iteration 23650: loss: 0.071725, loss_s1: 0.062719, loss_fp: 0.003503, loss_freq: 0.027707
[06:42:14.671] iteration 23651: loss: 0.053144, loss_s1: 0.045606, loss_fp: 0.003048, loss_freq: 0.023969
[06:42:15.283] iteration 23652: loss: 0.067663, loss_s1: 0.064043, loss_fp: 0.003506, loss_freq: 0.043448
[06:42:15.895] iteration 23653: loss: 0.062029, loss_s1: 0.037247, loss_fp: 0.003783, loss_freq: 0.041285
[06:42:16.515] iteration 23654: loss: 0.050158, loss_s1: 0.051609, loss_fp: 0.000748, loss_freq: 0.015131
[06:42:17.125] iteration 23655: loss: 0.055953, loss_s1: 0.041569, loss_fp: 0.005958, loss_freq: 0.035522
[06:42:17.733] iteration 23656: loss: 0.050901, loss_s1: 0.052468, loss_fp: 0.002942, loss_freq: 0.023884
[06:42:18.339] iteration 23657: loss: 0.046058, loss_s1: 0.034038, loss_fp: 0.004109, loss_freq: 0.024903
[06:42:18.942] iteration 23658: loss: 0.090174, loss_s1: 0.099376, loss_fp: 0.004005, loss_freq: 0.032208
[06:42:19.555] iteration 23659: loss: 0.078246, loss_s1: 0.103815, loss_fp: 0.003213, loss_freq: 0.023279
[06:42:20.167] iteration 23660: loss: 0.096480, loss_s1: 0.101637, loss_fp: 0.004884, loss_freq: 0.046718
[06:42:20.847] iteration 23661: loss: 0.048825, loss_s1: 0.031051, loss_fp: 0.007240, loss_freq: 0.035616
[06:42:21.489] iteration 23662: loss: 0.047458, loss_s1: 0.020138, loss_fp: 0.003252, loss_freq: 0.037452
[06:42:22.136] iteration 23663: loss: 0.054704, loss_s1: 0.057527, loss_fp: 0.001859, loss_freq: 0.019601
[06:42:22.794] iteration 23664: loss: 0.040298, loss_s1: 0.022478, loss_fp: 0.003822, loss_freq: 0.007401
[06:42:23.445] iteration 23665: loss: 0.070990, loss_s1: 0.096346, loss_fp: 0.002443, loss_freq: 0.023287
[06:42:24.066] iteration 23666: loss: 0.048921, loss_s1: 0.021293, loss_fp: 0.006933, loss_freq: 0.022448
[06:42:24.712] iteration 23667: loss: 0.065972, loss_s1: 0.065913, loss_fp: 0.002524, loss_freq: 0.029935
[06:42:25.339] iteration 23668: loss: 0.120570, loss_s1: 0.166422, loss_fp: 0.009637, loss_freq: 0.038433
[06:42:25.950] iteration 23669: loss: 0.046046, loss_s1: 0.025136, loss_fp: 0.006177, loss_freq: 0.026528
[06:42:26.559] iteration 23670: loss: 0.074107, loss_s1: 0.079153, loss_fp: 0.003003, loss_freq: 0.035995
[06:42:27.176] iteration 23671: loss: 0.071904, loss_s1: 0.094484, loss_fp: 0.007919, loss_freq: 0.008734
[06:42:27.782] iteration 23672: loss: 0.056365, loss_s1: 0.052946, loss_fp: 0.002779, loss_freq: 0.027212
[06:42:28.397] iteration 23673: loss: 0.082120, loss_s1: 0.104757, loss_fp: 0.005590, loss_freq: 0.029331
[06:42:28.998] iteration 23674: loss: 0.080332, loss_s1: 0.071695, loss_fp: 0.001445, loss_freq: 0.063854
[06:42:29.602] iteration 23675: loss: 0.045373, loss_s1: 0.027864, loss_fp: 0.003465, loss_freq: 0.026745
[06:42:30.211] iteration 23676: loss: 0.080619, loss_s1: 0.089164, loss_fp: 0.004797, loss_freq: 0.036165
[06:42:30.819] iteration 23677: loss: 0.056339, loss_s1: 0.046191, loss_fp: 0.002593, loss_freq: 0.033856
[06:42:31.420] iteration 23678: loss: 0.082048, loss_s1: 0.077963, loss_fp: 0.005562, loss_freq: 0.052484
[06:42:32.040] iteration 23679: loss: 0.061847, loss_s1: 0.066324, loss_fp: 0.002686, loss_freq: 0.019183
[06:42:32.648] iteration 23680: loss: 0.052741, loss_s1: 0.038142, loss_fp: 0.001801, loss_freq: 0.010257
[06:42:33.255] iteration 23681: loss: 0.043608, loss_s1: 0.031497, loss_fp: 0.001996, loss_freq: 0.020461
[06:42:33.861] iteration 23682: loss: 0.054008, loss_s1: 0.047064, loss_fp: 0.004835, loss_freq: 0.023030
[06:42:34.470] iteration 23683: loss: 0.046145, loss_s1: 0.034684, loss_fp: 0.002198, loss_freq: 0.020860
[06:42:35.094] iteration 23684: loss: 0.046401, loss_s1: 0.032715, loss_fp: 0.003386, loss_freq: 0.027981
[06:42:35.719] iteration 23685: loss: 0.052092, loss_s1: 0.023769, loss_fp: 0.002261, loss_freq: 0.043495
[06:42:36.342] iteration 23686: loss: 0.051219, loss_s1: 0.044908, loss_fp: 0.001671, loss_freq: 0.021640
[06:42:36.966] iteration 23687: loss: 0.060109, loss_s1: 0.062807, loss_fp: 0.003678, loss_freq: 0.031299
[06:42:37.594] iteration 23688: loss: 0.073536, loss_s1: 0.032034, loss_fp: 0.003328, loss_freq: 0.061434
[06:42:38.229] iteration 23689: loss: 0.036559, loss_s1: 0.018734, loss_fp: 0.001624, loss_freq: 0.029671
[06:42:38.858] iteration 23690: loss: 0.070114, loss_s1: 0.064449, loss_fp: 0.005093, loss_freq: 0.027706
[06:42:39.484] iteration 23691: loss: 0.030050, loss_s1: 0.024766, loss_fp: 0.002948, loss_freq: 0.010336
[06:42:40.110] iteration 23692: loss: 0.064798, loss_s1: 0.034114, loss_fp: 0.001377, loss_freq: 0.052721
[06:42:40.773] iteration 23693: loss: 0.049395, loss_s1: 0.038512, loss_fp: 0.002240, loss_freq: 0.027052
[06:42:41.436] iteration 23694: loss: 0.040510, loss_s1: 0.032584, loss_fp: 0.001313, loss_freq: 0.020016
[06:42:42.097] iteration 23695: loss: 0.066465, loss_s1: 0.077483, loss_fp: 0.006200, loss_freq: 0.019531
[06:42:42.740] iteration 23696: loss: 0.046016, loss_s1: 0.041638, loss_fp: 0.002979, loss_freq: 0.024532
[06:42:43.415] iteration 23697: loss: 0.044383, loss_s1: 0.030256, loss_fp: 0.003186, loss_freq: 0.011874
[06:42:44.113] iteration 23698: loss: 0.083601, loss_s1: 0.084172, loss_fp: 0.007977, loss_freq: 0.046604
[06:42:44.769] iteration 23699: loss: 0.032048, loss_s1: 0.015867, loss_fp: 0.002559, loss_freq: 0.010550
[06:42:45.425] iteration 23700: loss: 0.043368, loss_s1: 0.030070, loss_fp: 0.004525, loss_freq: 0.032688
[06:42:46.080] iteration 23701: loss: 0.065559, loss_s1: 0.054260, loss_fp: 0.002271, loss_freq: 0.036079
[06:42:46.697] iteration 23702: loss: 0.032378, loss_s1: 0.015377, loss_fp: 0.004112, loss_freq: 0.012701
[06:42:47.303] iteration 23703: loss: 0.052232, loss_s1: 0.041424, loss_fp: 0.003531, loss_freq: 0.031810
[06:42:47.926] iteration 23704: loss: 0.052835, loss_s1: 0.060605, loss_fp: 0.001732, loss_freq: 0.014496
[06:42:48.536] iteration 23705: loss: 0.044540, loss_s1: 0.038604, loss_fp: 0.002183, loss_freq: 0.024655
[06:42:49.146] iteration 23706: loss: 0.066229, loss_s1: 0.070779, loss_fp: 0.005943, loss_freq: 0.023108
[06:42:49.754] iteration 23707: loss: 0.068590, loss_s1: 0.065060, loss_fp: 0.001797, loss_freq: 0.039857
[06:42:50.360] iteration 23708: loss: 0.061100, loss_s1: 0.059434, loss_fp: 0.005269, loss_freq: 0.026867
[06:42:50.965] iteration 23709: loss: 0.044949, loss_s1: 0.040464, loss_fp: 0.004472, loss_freq: 0.025789
[06:42:51.570] iteration 23710: loss: 0.069334, loss_s1: 0.036685, loss_fp: 0.004077, loss_freq: 0.042363
[06:42:52.177] iteration 23711: loss: 0.077628, loss_s1: 0.101240, loss_fp: 0.002413, loss_freq: 0.009572
[06:42:52.807] iteration 23712: loss: 0.047588, loss_s1: 0.032670, loss_fp: 0.002797, loss_freq: 0.026453
[06:42:53.429] iteration 23713: loss: 0.048897, loss_s1: 0.042359, loss_fp: 0.002827, loss_freq: 0.028224
[06:42:54.051] iteration 23714: loss: 0.036265, loss_s1: 0.019009, loss_fp: 0.004122, loss_freq: 0.013765
[06:42:54.678] iteration 23715: loss: 0.063104, loss_s1: 0.069783, loss_fp: 0.001946, loss_freq: 0.024235
[06:42:55.307] iteration 23716: loss: 0.063628, loss_s1: 0.066680, loss_fp: 0.002496, loss_freq: 0.028827
[06:42:55.915] iteration 23717: loss: 0.061390, loss_s1: 0.076579, loss_fp: 0.007667, loss_freq: 0.017114
[06:42:56.527] iteration 23718: loss: 0.058567, loss_s1: 0.062750, loss_fp: 0.004992, loss_freq: 0.021857
[06:42:57.139] iteration 23719: loss: 0.059011, loss_s1: 0.072773, loss_fp: 0.006510, loss_freq: 0.011677
[06:42:57.748] iteration 23720: loss: 0.041178, loss_s1: 0.010845, loss_fp: 0.002879, loss_freq: 0.017647
[06:42:58.363] iteration 23721: loss: 0.090218, loss_s1: 0.099981, loss_fp: 0.002413, loss_freq: 0.042454
[06:42:58.976] iteration 23722: loss: 0.061609, loss_s1: 0.027182, loss_fp: 0.003371, loss_freq: 0.065294
[06:42:59.587] iteration 23723: loss: 0.073556, loss_s1: 0.057539, loss_fp: 0.008743, loss_freq: 0.048555
[06:43:00.199] iteration 23724: loss: 0.032344, loss_s1: 0.026233, loss_fp: 0.002157, loss_freq: 0.013273
[06:43:00.808] iteration 23725: loss: 0.072859, loss_s1: 0.076091, loss_fp: 0.005559, loss_freq: 0.027345
[06:43:01.417] iteration 23726: loss: 0.038189, loss_s1: 0.020310, loss_fp: 0.005565, loss_freq: 0.026159
[06:43:02.032] iteration 23727: loss: 0.084031, loss_s1: 0.078904, loss_fp: 0.007112, loss_freq: 0.035545
[06:43:02.639] iteration 23728: loss: 0.049116, loss_s1: 0.037884, loss_fp: 0.001962, loss_freq: 0.021591
[06:43:03.246] iteration 23729: loss: 0.051601, loss_s1: 0.052800, loss_fp: 0.003422, loss_freq: 0.020997
[06:43:03.864] iteration 23730: loss: 0.043978, loss_s1: 0.035985, loss_fp: 0.002012, loss_freq: 0.015711
[06:43:04.479] iteration 23731: loss: 0.073359, loss_s1: 0.075590, loss_fp: 0.003055, loss_freq: 0.037483
[06:43:05.090] iteration 23732: loss: 0.052106, loss_s1: 0.047969, loss_fp: 0.004364, loss_freq: 0.009030
[06:43:05.702] iteration 23733: loss: 0.041799, loss_s1: 0.023615, loss_fp: 0.003647, loss_freq: 0.026802
[06:43:06.314] iteration 23734: loss: 0.044178, loss_s1: 0.031176, loss_fp: 0.007867, loss_freq: 0.016972
[06:43:06.923] iteration 23735: loss: 0.033542, loss_s1: 0.022736, loss_fp: 0.006579, loss_freq: 0.015247
[06:43:07.568] iteration 23736: loss: 0.071455, loss_s1: 0.067225, loss_fp: 0.004393, loss_freq: 0.031862
[06:43:08.257] iteration 23737: loss: 0.061716, loss_s1: 0.048960, loss_fp: 0.002875, loss_freq: 0.032282
[06:43:08.928] iteration 23738: loss: 0.037038, loss_s1: 0.022212, loss_fp: 0.002163, loss_freq: 0.022262
[06:43:09.531] iteration 23739: loss: 0.039694, loss_s1: 0.021089, loss_fp: 0.008671, loss_freq: 0.017967
[06:43:10.136] iteration 23740: loss: 0.059283, loss_s1: 0.035564, loss_fp: 0.005477, loss_freq: 0.025708
[06:43:10.740] iteration 23741: loss: 0.047409, loss_s1: 0.043840, loss_fp: 0.005094, loss_freq: 0.011451
[06:43:11.346] iteration 23742: loss: 0.046477, loss_s1: 0.033850, loss_fp: 0.006181, loss_freq: 0.017980
[06:43:11.951] iteration 23743: loss: 0.047524, loss_s1: 0.029669, loss_fp: 0.003391, loss_freq: 0.034971
[06:43:12.563] iteration 23744: loss: 0.034273, loss_s1: 0.033275, loss_fp: 0.001456, loss_freq: 0.010108
[06:43:13.175] iteration 23745: loss: 0.068839, loss_s1: 0.039568, loss_fp: 0.003529, loss_freq: 0.043866
[06:43:13.794] iteration 23746: loss: 0.060337, loss_s1: 0.027254, loss_fp: 0.012952, loss_freq: 0.046251
[06:43:14.410] iteration 23747: loss: 0.039800, loss_s1: 0.028056, loss_fp: 0.005866, loss_freq: 0.013025
[06:43:15.023] iteration 23748: loss: 0.079654, loss_s1: 0.091747, loss_fp: 0.001800, loss_freq: 0.037885
[06:43:15.635] iteration 23749: loss: 0.072850, loss_s1: 0.039009, loss_fp: 0.006466, loss_freq: 0.071134
[06:43:16.244] iteration 23750: loss: 0.067221, loss_s1: 0.067786, loss_fp: 0.014079, loss_freq: 0.007167
[06:43:16.852] iteration 23751: loss: 0.050549, loss_s1: 0.044213, loss_fp: 0.003446, loss_freq: 0.015324
[06:43:17.459] iteration 23752: loss: 0.059526, loss_s1: 0.060860, loss_fp: 0.003971, loss_freq: 0.030585
[06:43:18.114] iteration 23753: loss: 0.116569, loss_s1: 0.072999, loss_fp: 0.003332, loss_freq: 0.117883
[06:43:18.739] iteration 23754: loss: 0.054110, loss_s1: 0.046557, loss_fp: 0.009501, loss_freq: 0.015880
[06:43:19.424] iteration 23755: loss: 0.072845, loss_s1: 0.040679, loss_fp: 0.021951, loss_freq: 0.042484
[06:43:20.057] iteration 23756: loss: 0.051049, loss_s1: 0.040459, loss_fp: 0.001636, loss_freq: 0.022820
[06:43:20.677] iteration 23757: loss: 0.077570, loss_s1: 0.064399, loss_fp: 0.007848, loss_freq: 0.063069
[06:43:21.288] iteration 23758: loss: 0.053951, loss_s1: 0.047258, loss_fp: 0.007226, loss_freq: 0.014643
[06:43:21.896] iteration 23759: loss: 0.041234, loss_s1: 0.032038, loss_fp: 0.002333, loss_freq: 0.021902
[06:43:22.509] iteration 23760: loss: 0.091173, loss_s1: 0.081089, loss_fp: 0.006903, loss_freq: 0.060115
[06:43:23.115] iteration 23761: loss: 0.061309, loss_s1: 0.075264, loss_fp: 0.003884, loss_freq: 0.012126
[06:43:23.729] iteration 23762: loss: 0.070589, loss_s1: 0.061567, loss_fp: 0.004587, loss_freq: 0.026385
[06:43:24.341] iteration 23763: loss: 0.059769, loss_s1: 0.043395, loss_fp: 0.005251, loss_freq: 0.041057
[06:43:24.957] iteration 23764: loss: 0.059215, loss_s1: 0.073623, loss_fp: 0.002054, loss_freq: 0.012432
[06:43:25.652] iteration 23765: loss: 0.083397, loss_s1: 0.087433, loss_fp: 0.002261, loss_freq: 0.045501
[06:43:26.281] iteration 23766: loss: 0.044810, loss_s1: 0.044758, loss_fp: 0.003058, loss_freq: 0.008052
[06:43:26.894] iteration 23767: loss: 0.059090, loss_s1: 0.055465, loss_fp: 0.004836, loss_freq: 0.020647
[06:43:27.509] iteration 23768: loss: 0.065219, loss_s1: 0.032304, loss_fp: 0.003795, loss_freq: 0.063766
[06:43:28.114] iteration 23769: loss: 0.115307, loss_s1: 0.138282, loss_fp: 0.012151, loss_freq: 0.053842
[06:43:28.737] iteration 23770: loss: 0.054975, loss_s1: 0.041154, loss_fp: 0.003725, loss_freq: 0.044727
[06:43:29.356] iteration 23771: loss: 0.055230, loss_s1: 0.044670, loss_fp: 0.015908, loss_freq: 0.017486
[06:43:29.992] iteration 23772: loss: 0.046898, loss_s1: 0.036859, loss_fp: 0.003639, loss_freq: 0.015399
[06:43:30.613] iteration 23773: loss: 0.033273, loss_s1: 0.019737, loss_fp: 0.002739, loss_freq: 0.019661
[06:43:31.220] iteration 23774: loss: 0.059005, loss_s1: 0.033076, loss_fp: 0.009008, loss_freq: 0.028911
[06:43:31.828] iteration 23775: loss: 0.039679, loss_s1: 0.036120, loss_fp: 0.001874, loss_freq: 0.010544
[06:43:32.430] iteration 23776: loss: 0.067541, loss_s1: 0.048914, loss_fp: 0.004410, loss_freq: 0.037870
[06:43:33.035] iteration 23777: loss: 0.046299, loss_s1: 0.031788, loss_fp: 0.005092, loss_freq: 0.026692
[06:43:33.644] iteration 23778: loss: 0.067867, loss_s1: 0.083251, loss_fp: 0.004446, loss_freq: 0.024660
[06:43:34.271] iteration 23779: loss: 0.050802, loss_s1: 0.033423, loss_fp: 0.006845, loss_freq: 0.037422
[06:43:34.934] iteration 23780: loss: 0.062188, loss_s1: 0.055213, loss_fp: 0.001214, loss_freq: 0.028926
[06:43:35.545] iteration 23781: loss: 0.071699, loss_s1: 0.061649, loss_fp: 0.007832, loss_freq: 0.045202
[06:43:36.161] iteration 23782: loss: 0.058375, loss_s1: 0.054811, loss_fp: 0.002268, loss_freq: 0.028696
[06:43:36.770] iteration 23783: loss: 0.061357, loss_s1: 0.048910, loss_fp: 0.004420, loss_freq: 0.043747
[06:43:37.380] iteration 23784: loss: 0.086051, loss_s1: 0.083982, loss_fp: 0.011476, loss_freq: 0.049754
[06:43:37.993] iteration 23785: loss: 0.073592, loss_s1: 0.065524, loss_fp: 0.003204, loss_freq: 0.038649
[06:43:38.607] iteration 23786: loss: 0.043325, loss_s1: 0.029576, loss_fp: 0.001361, loss_freq: 0.014795
[06:43:39.221] iteration 23787: loss: 0.037195, loss_s1: 0.030407, loss_fp: 0.002040, loss_freq: 0.015413
[06:43:39.828] iteration 23788: loss: 0.117196, loss_s1: 0.096201, loss_fp: 0.004800, loss_freq: 0.089133
[06:43:40.445] iteration 23789: loss: 0.062937, loss_s1: 0.056838, loss_fp: 0.002704, loss_freq: 0.034790
[06:43:41.061] iteration 23790: loss: 0.065625, loss_s1: 0.052359, loss_fp: 0.012625, loss_freq: 0.036283
[06:43:41.669] iteration 23791: loss: 0.034874, loss_s1: 0.022490, loss_fp: 0.004482, loss_freq: 0.010565
[06:43:42.287] iteration 23792: loss: 0.083825, loss_s1: 0.108286, loss_fp: 0.012097, loss_freq: 0.021217
[06:43:42.908] iteration 23793: loss: 0.049395, loss_s1: 0.039987, loss_fp: 0.005146, loss_freq: 0.015141
[06:43:43.517] iteration 23794: loss: 0.056436, loss_s1: 0.062039, loss_fp: 0.001923, loss_freq: 0.019464
[06:43:44.132] iteration 23795: loss: 0.036538, loss_s1: 0.028498, loss_fp: 0.003129, loss_freq: 0.009893
[06:43:44.747] iteration 23796: loss: 0.098725, loss_s1: 0.127245, loss_fp: 0.003558, loss_freq: 0.044865
[06:43:45.360] iteration 23797: loss: 0.085441, loss_s1: 0.098783, loss_fp: 0.007305, loss_freq: 0.030882
[06:43:45.967] iteration 23798: loss: 0.058238, loss_s1: 0.058239, loss_fp: 0.007057, loss_freq: 0.019856
[06:43:46.578] iteration 23799: loss: 0.052345, loss_s1: 0.031242, loss_fp: 0.007859, loss_freq: 0.039441
[06:43:47.182] iteration 23800: loss: 0.039660, loss_s1: 0.031549, loss_fp: 0.002293, loss_freq: 0.012496
[06:43:50.673] iteration 23800 : mean_dice : 0.739039
[06:43:51.651] iteration 23801: loss: 0.088715, loss_s1: 0.049070, loss_fp: 0.002052, loss_freq: 0.038999
[06:43:52.257] iteration 23802: loss: 0.064650, loss_s1: 0.046478, loss_fp: 0.002379, loss_freq: 0.043353
[06:43:52.859] iteration 23803: loss: 0.060097, loss_s1: 0.068898, loss_fp: 0.003109, loss_freq: 0.024343
[06:43:53.471] iteration 23804: loss: 0.040214, loss_s1: 0.025861, loss_fp: 0.002362, loss_freq: 0.023964
[06:43:54.075] iteration 23805: loss: 0.029828, loss_s1: 0.013974, loss_fp: 0.003646, loss_freq: 0.017835
[06:43:54.681] iteration 23806: loss: 0.044721, loss_s1: 0.024385, loss_fp: 0.001724, loss_freq: 0.020292
[06:43:55.289] iteration 23807: loss: 0.057623, loss_s1: 0.034286, loss_fp: 0.003969, loss_freq: 0.040834
[06:43:55.897] iteration 23808: loss: 0.042011, loss_s1: 0.031394, loss_fp: 0.012067, loss_freq: 0.014505
[06:43:56.505] iteration 23809: loss: 0.045411, loss_s1: 0.046126, loss_fp: 0.001188, loss_freq: 0.016276
[06:43:57.114] iteration 23810: loss: 0.053170, loss_s1: 0.044975, loss_fp: 0.005207, loss_freq: 0.010271
[06:43:57.728] iteration 23811: loss: 0.068680, loss_s1: 0.056207, loss_fp: 0.001915, loss_freq: 0.030984
[06:43:58.338] iteration 23812: loss: 0.042896, loss_s1: 0.027967, loss_fp: 0.001816, loss_freq: 0.024055
[06:43:58.948] iteration 23813: loss: 0.073696, loss_s1: 0.059037, loss_fp: 0.003835, loss_freq: 0.057189
[06:43:59.557] iteration 23814: loss: 0.039399, loss_s1: 0.031988, loss_fp: 0.004443, loss_freq: 0.013298
[06:44:00.169] iteration 23815: loss: 0.068319, loss_s1: 0.067862, loss_fp: 0.001273, loss_freq: 0.027056
[06:44:00.791] iteration 23816: loss: 0.047902, loss_s1: 0.027590, loss_fp: 0.004605, loss_freq: 0.024872
[06:44:01.415] iteration 23817: loss: 0.129980, loss_s1: 0.185906, loss_fp: 0.004310, loss_freq: 0.050965
[06:44:02.032] iteration 23818: loss: 0.056013, loss_s1: 0.054282, loss_fp: 0.005251, loss_freq: 0.025115
[06:44:02.648] iteration 23819: loss: 0.087187, loss_s1: 0.083091, loss_fp: 0.009014, loss_freq: 0.049624
[06:44:03.266] iteration 23820: loss: 0.078838, loss_s1: 0.083757, loss_fp: 0.004492, loss_freq: 0.036847
[06:44:03.883] iteration 23821: loss: 0.030755, loss_s1: 0.010653, loss_fp: 0.003580, loss_freq: 0.010737
[06:44:04.495] iteration 23822: loss: 0.064224, loss_s1: 0.050543, loss_fp: 0.004754, loss_freq: 0.051490
[06:44:05.114] iteration 23823: loss: 0.054840, loss_s1: 0.034216, loss_fp: 0.004474, loss_freq: 0.032793
[06:44:05.733] iteration 23824: loss: 0.059308, loss_s1: 0.036360, loss_fp: 0.006755, loss_freq: 0.035202
[06:44:06.344] iteration 23825: loss: 0.102903, loss_s1: 0.140507, loss_fp: 0.003349, loss_freq: 0.031825
[06:44:06.953] iteration 23826: loss: 0.068707, loss_s1: 0.061050, loss_fp: 0.002428, loss_freq: 0.050931
[06:44:07.556] iteration 23827: loss: 0.073683, loss_s1: 0.057641, loss_fp: 0.004760, loss_freq: 0.039530
[06:44:08.161] iteration 23828: loss: 0.116893, loss_s1: 0.101362, loss_fp: 0.012442, loss_freq: 0.052212
[06:44:08.768] iteration 23829: loss: 0.042311, loss_s1: 0.032426, loss_fp: 0.002691, loss_freq: 0.017793
[06:44:09.380] iteration 23830: loss: 0.100538, loss_s1: 0.125369, loss_fp: 0.004462, loss_freq: 0.034451
[06:44:09.988] iteration 23831: loss: 0.060978, loss_s1: 0.042086, loss_fp: 0.004321, loss_freq: 0.053687
[06:44:10.592] iteration 23832: loss: 0.067035, loss_s1: 0.046833, loss_fp: 0.003035, loss_freq: 0.030915
[06:44:11.196] iteration 23833: loss: 0.081848, loss_s1: 0.072023, loss_fp: 0.002670, loss_freq: 0.054475
[06:44:11.824] iteration 23834: loss: 0.067753, loss_s1: 0.073357, loss_fp: 0.005823, loss_freq: 0.024916
[06:44:12.430] iteration 23835: loss: 0.057469, loss_s1: 0.063000, loss_fp: 0.002925, loss_freq: 0.026685
[06:44:13.041] iteration 23836: loss: 0.038628, loss_s1: 0.016724, loss_fp: 0.003120, loss_freq: 0.023906
[06:44:13.687] iteration 23837: loss: 0.058775, loss_s1: 0.037047, loss_fp: 0.002538, loss_freq: 0.040161
[06:44:14.395] iteration 23838: loss: 0.103076, loss_s1: 0.143738, loss_fp: 0.003860, loss_freq: 0.026734
[06:44:15.061] iteration 23839: loss: 0.070104, loss_s1: 0.069701, loss_fp: 0.007722, loss_freq: 0.032131
[06:44:15.668] iteration 23840: loss: 0.057608, loss_s1: 0.054704, loss_fp: 0.006147, loss_freq: 0.031158
[06:44:16.295] iteration 23841: loss: 0.098992, loss_s1: 0.077632, loss_fp: 0.002184, loss_freq: 0.079260
[06:44:16.909] iteration 23842: loss: 0.087871, loss_s1: 0.097430, loss_fp: 0.003269, loss_freq: 0.043417
[06:44:17.542] iteration 23843: loss: 0.129076, loss_s1: 0.162004, loss_fp: 0.007356, loss_freq: 0.061246
[06:44:18.152] iteration 23844: loss: 0.054047, loss_s1: 0.029508, loss_fp: 0.001922, loss_freq: 0.050036
[06:44:18.760] iteration 23845: loss: 0.089218, loss_s1: 0.077785, loss_fp: 0.003360, loss_freq: 0.033918
[06:44:19.370] iteration 23846: loss: 0.079168, loss_s1: 0.105479, loss_fp: 0.001100, loss_freq: 0.019538
[06:44:19.982] iteration 23847: loss: 0.067652, loss_s1: 0.045640, loss_fp: 0.002549, loss_freq: 0.052774
[06:44:20.595] iteration 23848: loss: 0.064100, loss_s1: 0.062175, loss_fp: 0.004662, loss_freq: 0.037740
[06:44:21.207] iteration 23849: loss: 0.065094, loss_s1: 0.068473, loss_fp: 0.001187, loss_freq: 0.031844
[06:44:21.825] iteration 23850: loss: 0.041891, loss_s1: 0.041364, loss_fp: 0.000717, loss_freq: 0.005974
[06:44:22.451] iteration 23851: loss: 0.041075, loss_s1: 0.032561, loss_fp: 0.004792, loss_freq: 0.012894
[06:44:23.059] iteration 23852: loss: 0.034796, loss_s1: 0.022218, loss_fp: 0.001422, loss_freq: 0.018245
[06:44:23.666] iteration 23853: loss: 0.040856, loss_s1: 0.037013, loss_fp: 0.004738, loss_freq: 0.009464
[06:44:24.293] iteration 23854: loss: 0.063953, loss_s1: 0.065569, loss_fp: 0.004749, loss_freq: 0.027802
[06:44:24.909] iteration 23855: loss: 0.061464, loss_s1: 0.027569, loss_fp: 0.004235, loss_freq: 0.056510
[06:44:25.535] iteration 23856: loss: 0.050565, loss_s1: 0.039465, loss_fp: 0.000373, loss_freq: 0.029480
[06:44:26.145] iteration 23857: loss: 0.050954, loss_s1: 0.042624, loss_fp: 0.000867, loss_freq: 0.029128
[06:44:26.756] iteration 23858: loss: 0.049097, loss_s1: 0.035410, loss_fp: 0.002056, loss_freq: 0.019455
[06:44:27.361] iteration 23859: loss: 0.055626, loss_s1: 0.027020, loss_fp: 0.005350, loss_freq: 0.037667
[06:44:27.967] iteration 23860: loss: 0.039431, loss_s1: 0.017439, loss_fp: 0.001191, loss_freq: 0.029779
[06:44:28.569] iteration 23861: loss: 0.026812, loss_s1: 0.025633, loss_fp: 0.001109, loss_freq: 0.005913
[06:44:29.180] iteration 23862: loss: 0.063792, loss_s1: 0.053865, loss_fp: 0.002683, loss_freq: 0.030649
[06:44:29.780] iteration 23863: loss: 0.043169, loss_s1: 0.029079, loss_fp: 0.001708, loss_freq: 0.024070
[06:44:30.385] iteration 23864: loss: 0.048112, loss_s1: 0.048764, loss_fp: 0.003109, loss_freq: 0.018320
[06:44:30.989] iteration 23865: loss: 0.026504, loss_s1: 0.010431, loss_fp: 0.003064, loss_freq: 0.008240
[06:44:31.593] iteration 23866: loss: 0.064593, loss_s1: 0.070344, loss_fp: 0.003942, loss_freq: 0.031257
[06:44:32.204] iteration 23867: loss: 0.041801, loss_s1: 0.015421, loss_fp: 0.002775, loss_freq: 0.014344
[06:44:32.872] iteration 23868: loss: 0.087335, loss_s1: 0.089230, loss_fp: 0.003075, loss_freq: 0.051222
[06:44:33.536] iteration 23869: loss: 0.045555, loss_s1: 0.023069, loss_fp: 0.000612, loss_freq: 0.036612
[06:44:34.200] iteration 23870: loss: 0.040299, loss_s1: 0.028991, loss_fp: 0.003540, loss_freq: 0.021424
[06:44:34.859] iteration 23871: loss: 0.072191, loss_s1: 0.050257, loss_fp: 0.002255, loss_freq: 0.041416
[06:44:35.518] iteration 23872: loss: 0.054827, loss_s1: 0.039414, loss_fp: 0.007008, loss_freq: 0.030148
[06:44:36.134] iteration 23873: loss: 0.053260, loss_s1: 0.038604, loss_fp: 0.004799, loss_freq: 0.030686
[06:44:36.749] iteration 23874: loss: 0.065196, loss_s1: 0.080516, loss_fp: 0.004764, loss_freq: 0.016991
[06:44:37.384] iteration 23875: loss: 0.053244, loss_s1: 0.036011, loss_fp: 0.003084, loss_freq: 0.036134
[06:44:38.004] iteration 23876: loss: 0.064779, loss_s1: 0.052831, loss_fp: 0.013781, loss_freq: 0.029564
[06:44:38.617] iteration 23877: loss: 0.050409, loss_s1: 0.037354, loss_fp: 0.005277, loss_freq: 0.029767
[06:44:39.267] iteration 23878: loss: 0.088853, loss_s1: 0.098255, loss_fp: 0.003869, loss_freq: 0.042208
[06:44:39.903] iteration 23879: loss: 0.066866, loss_s1: 0.066982, loss_fp: 0.006220, loss_freq: 0.032841
[06:44:40.517] iteration 23880: loss: 0.064447, loss_s1: 0.059214, loss_fp: 0.005228, loss_freq: 0.021728
[06:44:41.134] iteration 23881: loss: 0.075279, loss_s1: 0.060763, loss_fp: 0.003201, loss_freq: 0.042946
[06:44:41.755] iteration 23882: loss: 0.050256, loss_s1: 0.036086, loss_fp: 0.004394, loss_freq: 0.027473
[06:44:42.383] iteration 23883: loss: 0.050462, loss_s1: 0.030764, loss_fp: 0.001675, loss_freq: 0.024580
[06:44:43.006] iteration 23884: loss: 0.041187, loss_s1: 0.031552, loss_fp: 0.006692, loss_freq: 0.012168
[06:44:43.627] iteration 23885: loss: 0.072242, loss_s1: 0.053444, loss_fp: 0.004854, loss_freq: 0.035394
[06:44:44.245] iteration 23886: loss: 0.076946, loss_s1: 0.053545, loss_fp: 0.007707, loss_freq: 0.022348
[06:44:44.863] iteration 23887: loss: 0.049152, loss_s1: 0.051830, loss_fp: 0.008733, loss_freq: 0.016430
[06:44:45.477] iteration 23888: loss: 0.079173, loss_s1: 0.073365, loss_fp: 0.007572, loss_freq: 0.041759
[06:44:46.131] iteration 23889: loss: 0.057615, loss_s1: 0.047001, loss_fp: 0.003732, loss_freq: 0.032629
[06:44:46.790] iteration 23890: loss: 0.068145, loss_s1: 0.037058, loss_fp: 0.003445, loss_freq: 0.025820
[06:44:47.447] iteration 23891: loss: 0.066476, loss_s1: 0.053166, loss_fp: 0.003354, loss_freq: 0.047428
[06:44:48.096] iteration 23892: loss: 0.057255, loss_s1: 0.030207, loss_fp: 0.001240, loss_freq: 0.058215
[06:44:48.708] iteration 23893: loss: 0.074563, loss_s1: 0.051353, loss_fp: 0.013090, loss_freq: 0.040380
[06:44:49.321] iteration 23894: loss: 0.061068, loss_s1: 0.043190, loss_fp: 0.015615, loss_freq: 0.030255
[06:44:49.936] iteration 23895: loss: 0.055643, loss_s1: 0.055014, loss_fp: 0.007444, loss_freq: 0.017601
[06:44:50.550] iteration 23896: loss: 0.046086, loss_s1: 0.038596, loss_fp: 0.001713, loss_freq: 0.022362
[06:44:51.164] iteration 23897: loss: 0.116004, loss_s1: 0.118087, loss_fp: 0.006201, loss_freq: 0.075237
[06:44:51.781] iteration 23898: loss: 0.105813, loss_s1: 0.084380, loss_fp: 0.006071, loss_freq: 0.071052
[06:44:52.398] iteration 23899: loss: 0.068134, loss_s1: 0.062927, loss_fp: 0.003033, loss_freq: 0.039087
[06:44:53.018] iteration 23900: loss: 0.050756, loss_s1: 0.032979, loss_fp: 0.004739, loss_freq: 0.017885
[06:44:53.646] iteration 23901: loss: 0.051137, loss_s1: 0.038169, loss_fp: 0.008409, loss_freq: 0.026044
[06:44:54.265] iteration 23902: loss: 0.052497, loss_s1: 0.042948, loss_fp: 0.002108, loss_freq: 0.016124
[06:44:54.883] iteration 23903: loss: 0.049688, loss_s1: 0.014922, loss_fp: 0.005590, loss_freq: 0.031386
[06:44:55.498] iteration 23904: loss: 0.035871, loss_s1: 0.021067, loss_fp: 0.002030, loss_freq: 0.017884
[06:44:56.151] iteration 23905: loss: 0.058013, loss_s1: 0.045468, loss_fp: 0.002175, loss_freq: 0.028271
[06:44:56.823] iteration 23906: loss: 0.074208, loss_s1: 0.058508, loss_fp: 0.019219, loss_freq: 0.034419
[06:44:57.493] iteration 23907: loss: 0.050774, loss_s1: 0.045320, loss_fp: 0.001854, loss_freq: 0.021020
[06:44:58.174] iteration 23908: loss: 0.038296, loss_s1: 0.031092, loss_fp: 0.001935, loss_freq: 0.018699
[06:44:58.809] iteration 23909: loss: 0.055684, loss_s1: 0.016645, loss_fp: 0.005036, loss_freq: 0.061799
[06:44:59.432] iteration 23910: loss: 0.053722, loss_s1: 0.041308, loss_fp: 0.005621, loss_freq: 0.035016
[06:45:00.044] iteration 23911: loss: 0.049264, loss_s1: 0.044481, loss_fp: 0.004115, loss_freq: 0.013865
[06:45:00.654] iteration 23912: loss: 0.062129, loss_s1: 0.035160, loss_fp: 0.002803, loss_freq: 0.028866
[06:45:01.265] iteration 23913: loss: 0.042598, loss_s1: 0.031133, loss_fp: 0.003743, loss_freq: 0.018019
[06:45:01.883] iteration 23914: loss: 0.028709, loss_s1: 0.019741, loss_fp: 0.002070, loss_freq: 0.015416
[06:45:02.512] iteration 23915: loss: 0.115555, loss_s1: 0.049820, loss_fp: 0.003508, loss_freq: 0.122401
[06:45:03.127] iteration 23916: loss: 0.057078, loss_s1: 0.039424, loss_fp: 0.010749, loss_freq: 0.032035
[06:45:03.740] iteration 23917: loss: 0.068942, loss_s1: 0.056025, loss_fp: 0.002572, loss_freq: 0.048801
[06:45:04.361] iteration 23918: loss: 0.051662, loss_s1: 0.052870, loss_fp: 0.005788, loss_freq: 0.021200
[06:45:04.973] iteration 23919: loss: 0.050424, loss_s1: 0.030717, loss_fp: 0.002615, loss_freq: 0.031402
[06:45:05.587] iteration 23920: loss: 0.033510, loss_s1: 0.020235, loss_fp: 0.003587, loss_freq: 0.008367
[06:45:06.196] iteration 23921: loss: 0.037861, loss_s1: 0.030023, loss_fp: 0.001051, loss_freq: 0.014040
[06:45:06.806] iteration 23922: loss: 0.044024, loss_s1: 0.049605, loss_fp: 0.002064, loss_freq: 0.015573
[06:45:07.420] iteration 23923: loss: 0.076641, loss_s1: 0.064012, loss_fp: 0.005447, loss_freq: 0.041096
[06:45:08.059] iteration 23924: loss: 0.034347, loss_s1: 0.012935, loss_fp: 0.002974, loss_freq: 0.019624
[06:45:08.710] iteration 23925: loss: 0.064777, loss_s1: 0.036862, loss_fp: 0.002806, loss_freq: 0.054198
[06:45:09.361] iteration 23926: loss: 0.047436, loss_s1: 0.037146, loss_fp: 0.004511, loss_freq: 0.019056
[06:45:09.973] iteration 23927: loss: 0.066806, loss_s1: 0.046139, loss_fp: 0.004753, loss_freq: 0.061756
[06:45:10.634] iteration 23928: loss: 0.049803, loss_s1: 0.050205, loss_fp: 0.007453, loss_freq: 0.007000
[06:45:11.297] iteration 23929: loss: 0.035032, loss_s1: 0.015936, loss_fp: 0.005161, loss_freq: 0.024549
[06:45:12.075] iteration 23930: loss: 0.099629, loss_s1: 0.109839, loss_fp: 0.005848, loss_freq: 0.039054
[06:45:12.811] iteration 23931: loss: 0.040604, loss_s1: 0.030685, loss_fp: 0.002604, loss_freq: 0.023973
[06:45:13.627] iteration 23932: loss: 0.044243, loss_s1: 0.024111, loss_fp: 0.004005, loss_freq: 0.012955
[06:45:14.314] iteration 23933: loss: 0.069652, loss_s1: 0.066565, loss_fp: 0.001632, loss_freq: 0.035418
[06:45:15.106] iteration 23934: loss: 0.048572, loss_s1: 0.039962, loss_fp: 0.007793, loss_freq: 0.023353
[06:45:15.774] iteration 23935: loss: 0.032865, loss_s1: 0.027151, loss_fp: 0.002092, loss_freq: 0.006483
[06:45:16.487] iteration 23936: loss: 0.044065, loss_s1: 0.058544, loss_fp: 0.001439, loss_freq: 0.004397
[06:45:17.162] iteration 23937: loss: 0.064105, loss_s1: 0.062067, loss_fp: 0.006689, loss_freq: 0.016747
[06:45:17.814] iteration 23938: loss: 0.066945, loss_s1: 0.083048, loss_fp: 0.005887, loss_freq: 0.020239
[06:45:18.542] iteration 23939: loss: 0.081037, loss_s1: 0.100409, loss_fp: 0.009790, loss_freq: 0.026917
[06:45:19.232] iteration 23940: loss: 0.058822, loss_s1: 0.051599, loss_fp: 0.000906, loss_freq: 0.042980
[06:45:19.969] iteration 23941: loss: 0.068849, loss_s1: 0.043506, loss_fp: 0.004942, loss_freq: 0.029758
[06:45:20.715] iteration 23942: loss: 0.062165, loss_s1: 0.055725, loss_fp: 0.001360, loss_freq: 0.028007
[06:45:21.402] iteration 23943: loss: 0.041738, loss_s1: 0.034332, loss_fp: 0.001599, loss_freq: 0.017261
[06:45:22.139] iteration 23944: loss: 0.049818, loss_s1: 0.046374, loss_fp: 0.008090, loss_freq: 0.012127
[06:45:22.793] iteration 23945: loss: 0.039739, loss_s1: 0.025062, loss_fp: 0.004559, loss_freq: 0.013050
[06:45:23.661] iteration 23946: loss: 0.067124, loss_s1: 0.051844, loss_fp: 0.003669, loss_freq: 0.044268
[06:45:24.298] iteration 23947: loss: 0.044506, loss_s1: 0.013870, loss_fp: 0.009817, loss_freq: 0.028423
[06:45:25.072] iteration 23948: loss: 0.071882, loss_s1: 0.069808, loss_fp: 0.008499, loss_freq: 0.038890
[06:45:25.784] iteration 23949: loss: 0.067913, loss_s1: 0.049758, loss_fp: 0.006741, loss_freq: 0.054375
[06:45:26.393] iteration 23950: loss: 0.061973, loss_s1: 0.051097, loss_fp: 0.005264, loss_freq: 0.032979
[06:45:26.999] iteration 23951: loss: 0.072112, loss_s1: 0.062826, loss_fp: 0.010328, loss_freq: 0.035942
[06:45:27.604] iteration 23952: loss: 0.045898, loss_s1: 0.037933, loss_fp: 0.003780, loss_freq: 0.020362
[06:45:28.212] iteration 23953: loss: 0.081825, loss_s1: 0.068005, loss_fp: 0.001180, loss_freq: 0.067374
[06:45:28.826] iteration 23954: loss: 0.078920, loss_s1: 0.077211, loss_fp: 0.009965, loss_freq: 0.041148
[06:45:29.430] iteration 23955: loss: 0.059914, loss_s1: 0.043045, loss_fp: 0.002253, loss_freq: 0.039437
[06:45:30.037] iteration 23956: loss: 0.031882, loss_s1: 0.022102, loss_fp: 0.002283, loss_freq: 0.007021
[06:45:30.639] iteration 23957: loss: 0.031293, loss_s1: 0.019378, loss_fp: 0.002722, loss_freq: 0.017366
[06:45:31.242] iteration 23958: loss: 0.063943, loss_s1: 0.044829, loss_fp: 0.002923, loss_freq: 0.050876
[06:45:31.848] iteration 23959: loss: 0.066131, loss_s1: 0.074781, loss_fp: 0.006021, loss_freq: 0.021399
[06:45:32.451] iteration 23960: loss: 0.092554, loss_s1: 0.088403, loss_fp: 0.001930, loss_freq: 0.059830
[06:45:33.063] iteration 23961: loss: 0.053222, loss_s1: 0.054867, loss_fp: 0.002347, loss_freq: 0.016471
[06:45:33.673] iteration 23962: loss: 0.043734, loss_s1: 0.020175, loss_fp: 0.009457, loss_freq: 0.035302
[06:45:34.284] iteration 23963: loss: 0.043458, loss_s1: 0.017795, loss_fp: 0.007851, loss_freq: 0.027320
[06:45:34.892] iteration 23964: loss: 0.062736, loss_s1: 0.039568, loss_fp: 0.005468, loss_freq: 0.040386
[06:45:35.504] iteration 23965: loss: 0.033019, loss_s1: 0.020329, loss_fp: 0.002332, loss_freq: 0.006577
[06:45:36.121] iteration 23966: loss: 0.086591, loss_s1: 0.095451, loss_fp: 0.005328, loss_freq: 0.047192
[06:45:36.731] iteration 23967: loss: 0.052493, loss_s1: 0.039847, loss_fp: 0.003600, loss_freq: 0.028122
[06:45:37.342] iteration 23968: loss: 0.094869, loss_s1: 0.114827, loss_fp: 0.003211, loss_freq: 0.027742
[06:45:37.951] iteration 23969: loss: 0.048542, loss_s1: 0.026542, loss_fp: 0.003175, loss_freq: 0.038323
[06:45:38.563] iteration 23970: loss: 0.040916, loss_s1: 0.028588, loss_fp: 0.002199, loss_freq: 0.017066
[06:45:39.505] iteration 23971: loss: 0.090853, loss_s1: 0.074860, loss_fp: 0.003625, loss_freq: 0.067167
[06:45:40.124] iteration 23972: loss: 0.049169, loss_s1: 0.024777, loss_fp: 0.003281, loss_freq: 0.035276
[06:45:40.734] iteration 23973: loss: 0.048836, loss_s1: 0.043963, loss_fp: 0.011076, loss_freq: 0.018810
[06:45:41.648] iteration 23974: loss: 0.054242, loss_s1: 0.042054, loss_fp: 0.008579, loss_freq: 0.020192
[06:45:42.390] iteration 23975: loss: 0.049198, loss_s1: 0.027079, loss_fp: 0.002009, loss_freq: 0.030239
[06:45:43.092] iteration 23976: loss: 0.052014, loss_s1: 0.020919, loss_fp: 0.003035, loss_freq: 0.044762
[06:45:43.698] iteration 23977: loss: 0.058509, loss_s1: 0.050448, loss_fp: 0.001993, loss_freq: 0.027006
[06:45:44.326] iteration 23978: loss: 0.067229, loss_s1: 0.039985, loss_fp: 0.003112, loss_freq: 0.025675
[06:45:44.942] iteration 23979: loss: 0.035335, loss_s1: 0.032651, loss_fp: 0.002403, loss_freq: 0.011557
[06:45:45.609] iteration 23980: loss: 0.069815, loss_s1: 0.063787, loss_fp: 0.006596, loss_freq: 0.030872
[06:45:46.309] iteration 23981: loss: 0.041114, loss_s1: 0.020640, loss_fp: 0.004234, loss_freq: 0.021354
[06:45:46.980] iteration 23982: loss: 0.067642, loss_s1: 0.081899, loss_fp: 0.005609, loss_freq: 0.018260
[06:45:47.600] iteration 23983: loss: 0.046674, loss_s1: 0.039443, loss_fp: 0.001272, loss_freq: 0.026354
[06:45:48.216] iteration 23984: loss: 0.049408, loss_s1: 0.040823, loss_fp: 0.003637, loss_freq: 0.030188
[06:45:48.872] iteration 23985: loss: 0.049563, loss_s1: 0.045141, loss_fp: 0.004940, loss_freq: 0.013171
[06:45:49.548] iteration 23986: loss: 0.047599, loss_s1: 0.044577, loss_fp: 0.003530, loss_freq: 0.012706
[06:45:50.191] iteration 23987: loss: 0.085533, loss_s1: 0.045833, loss_fp: 0.001067, loss_freq: 0.099079
[06:45:50.799] iteration 23988: loss: 0.045140, loss_s1: 0.051521, loss_fp: 0.001448, loss_freq: 0.009483
[06:45:51.426] iteration 23989: loss: 0.081199, loss_s1: 0.098565, loss_fp: 0.007689, loss_freq: 0.027492
[06:45:52.031] iteration 23990: loss: 0.053343, loss_s1: 0.039103, loss_fp: 0.003424, loss_freq: 0.021608
[06:45:52.635] iteration 23991: loss: 0.038406, loss_s1: 0.017720, loss_fp: 0.002058, loss_freq: 0.022638
[06:45:53.244] iteration 23992: loss: 0.043939, loss_s1: 0.021582, loss_fp: 0.001514, loss_freq: 0.043882
[06:45:53.851] iteration 23993: loss: 0.050954, loss_s1: 0.018152, loss_fp: 0.003432, loss_freq: 0.028473
[06:45:54.471] iteration 23994: loss: 0.047782, loss_s1: 0.037749, loss_fp: 0.004331, loss_freq: 0.018450
[06:45:55.140] iteration 23995: loss: 0.050107, loss_s1: 0.028048, loss_fp: 0.004059, loss_freq: 0.030794
[06:45:55.811] iteration 23996: loss: 0.076616, loss_s1: 0.079978, loss_fp: 0.002899, loss_freq: 0.032060
[06:45:56.490] iteration 23997: loss: 0.044645, loss_s1: 0.035324, loss_fp: 0.002758, loss_freq: 0.011852
[06:45:57.175] iteration 23998: loss: 0.089629, loss_s1: 0.095225, loss_fp: 0.002549, loss_freq: 0.035984
[06:45:57.849] iteration 23999: loss: 0.077246, loss_s1: 0.044297, loss_fp: 0.015485, loss_freq: 0.043852
[06:45:58.481] iteration 24000: loss: 0.065289, loss_s1: 0.069517, loss_fp: 0.004641, loss_freq: 0.025092
[06:46:01.882] iteration 24000 : mean_dice : 0.737641
[06:46:02.571] iteration 24001: loss: 0.063838, loss_s1: 0.065222, loss_fp: 0.002601, loss_freq: 0.038623
[06:46:03.228] iteration 24002: loss: 0.074479, loss_s1: 0.053336, loss_fp: 0.007102, loss_freq: 0.056980
[06:46:03.847] iteration 24003: loss: 0.065512, loss_s1: 0.057301, loss_fp: 0.003384, loss_freq: 0.032729
[06:46:04.457] iteration 24004: loss: 0.060126, loss_s1: 0.046280, loss_fp: 0.002307, loss_freq: 0.023406
[06:46:05.060] iteration 24005: loss: 0.085082, loss_s1: 0.118416, loss_fp: 0.001540, loss_freq: 0.027442
[06:46:05.672] iteration 24006: loss: 0.054540, loss_s1: 0.049908, loss_fp: 0.001829, loss_freq: 0.017325
[06:46:06.275] iteration 24007: loss: 0.056489, loss_s1: 0.034158, loss_fp: 0.004073, loss_freq: 0.040755
[06:46:06.882] iteration 24008: loss: 0.043616, loss_s1: 0.044775, loss_fp: 0.007019, loss_freq: 0.009977
[06:46:07.504] iteration 24009: loss: 0.080060, loss_s1: 0.056197, loss_fp: 0.007708, loss_freq: 0.062001
[06:46:08.120] iteration 24010: loss: 0.103537, loss_s1: 0.136256, loss_fp: 0.006671, loss_freq: 0.032314
[06:46:08.733] iteration 24011: loss: 0.082990, loss_s1: 0.093624, loss_fp: 0.001881, loss_freq: 0.024930
[06:46:09.346] iteration 24012: loss: 0.050686, loss_s1: 0.038016, loss_fp: 0.002242, loss_freq: 0.018461
[06:46:09.951] iteration 24013: loss: 0.080680, loss_s1: 0.085013, loss_fp: 0.010384, loss_freq: 0.039725
[06:46:10.558] iteration 24014: loss: 0.067119, loss_s1: 0.063435, loss_fp: 0.007452, loss_freq: 0.038135
[06:46:11.163] iteration 24015: loss: 0.054489, loss_s1: 0.029953, loss_fp: 0.002646, loss_freq: 0.041916
[06:46:11.772] iteration 24016: loss: 0.075467, loss_s1: 0.079293, loss_fp: 0.007165, loss_freq: 0.032164
[06:46:12.378] iteration 24017: loss: 0.043661, loss_s1: 0.029409, loss_fp: 0.005674, loss_freq: 0.020194
[06:46:13.025] iteration 24018: loss: 0.058173, loss_s1: 0.061567, loss_fp: 0.003341, loss_freq: 0.025278
[06:46:13.640] iteration 24019: loss: 0.031018, loss_s1: 0.010440, loss_fp: 0.005535, loss_freq: 0.014688
[06:46:14.251] iteration 24020: loss: 0.043087, loss_s1: 0.035393, loss_fp: 0.000476, loss_freq: 0.007447
[06:46:14.860] iteration 24021: loss: 0.049572, loss_s1: 0.037007, loss_fp: 0.002791, loss_freq: 0.025370
[06:46:15.466] iteration 24022: loss: 0.060010, loss_s1: 0.055128, loss_fp: 0.005289, loss_freq: 0.043424
[06:46:16.076] iteration 24023: loss: 0.052060, loss_s1: 0.041724, loss_fp: 0.000831, loss_freq: 0.029484
[06:46:16.684] iteration 24024: loss: 0.052686, loss_s1: 0.033562, loss_fp: 0.003839, loss_freq: 0.035718
[06:46:17.298] iteration 24025: loss: 0.045088, loss_s1: 0.020523, loss_fp: 0.002205, loss_freq: 0.033262
[06:46:17.915] iteration 24026: loss: 0.043368, loss_s1: 0.025051, loss_fp: 0.004406, loss_freq: 0.020991
[06:46:18.524] iteration 24027: loss: 0.056634, loss_s1: 0.056465, loss_fp: 0.005295, loss_freq: 0.022925
[06:46:19.130] iteration 24028: loss: 0.048030, loss_s1: 0.035958, loss_fp: 0.002402, loss_freq: 0.019912
[06:46:19.739] iteration 24029: loss: 0.032506, loss_s1: 0.015108, loss_fp: 0.003528, loss_freq: 0.021558
[06:46:20.371] iteration 24030: loss: 0.043828, loss_s1: 0.026951, loss_fp: 0.001839, loss_freq: 0.029201
[06:46:20.987] iteration 24031: loss: 0.034713, loss_s1: 0.035288, loss_fp: 0.001834, loss_freq: 0.006709
[06:46:21.597] iteration 24032: loss: 0.051055, loss_s1: 0.033759, loss_fp: 0.001872, loss_freq: 0.025965
[06:46:22.214] iteration 24033: loss: 0.060952, loss_s1: 0.061243, loss_fp: 0.001523, loss_freq: 0.016260
[06:46:22.827] iteration 24034: loss: 0.043725, loss_s1: 0.050036, loss_fp: 0.001516, loss_freq: 0.011487
[06:46:23.448] iteration 24035: loss: 0.053052, loss_s1: 0.056290, loss_fp: 0.006755, loss_freq: 0.011513
[06:46:24.062] iteration 24036: loss: 0.044794, loss_s1: 0.022771, loss_fp: 0.002809, loss_freq: 0.038790
[06:46:24.670] iteration 24037: loss: 0.038316, loss_s1: 0.027201, loss_fp: 0.000963, loss_freq: 0.015073
[06:46:25.278] iteration 24038: loss: 0.090134, loss_s1: 0.091951, loss_fp: 0.007249, loss_freq: 0.055701
[06:46:25.884] iteration 24039: loss: 0.031009, loss_s1: 0.017058, loss_fp: 0.002841, loss_freq: 0.013170
[06:46:26.489] iteration 24040: loss: 0.041958, loss_s1: 0.035567, loss_fp: 0.003446, loss_freq: 0.022249
[06:46:27.104] iteration 24041: loss: 0.052820, loss_s1: 0.048612, loss_fp: 0.003945, loss_freq: 0.021185
[06:46:27.712] iteration 24042: loss: 0.044142, loss_s1: 0.041201, loss_fp: 0.005104, loss_freq: 0.010439
[06:46:28.330] iteration 24043: loss: 0.054106, loss_s1: 0.038285, loss_fp: 0.006067, loss_freq: 0.037060
[06:46:28.933] iteration 24044: loss: 0.071364, loss_s1: 0.062442, loss_fp: 0.006404, loss_freq: 0.016180
[06:46:29.542] iteration 24045: loss: 0.061342, loss_s1: 0.041148, loss_fp: 0.007405, loss_freq: 0.045167
[06:46:30.147] iteration 24046: loss: 0.064390, loss_s1: 0.035926, loss_fp: 0.012163, loss_freq: 0.046245
[06:46:30.757] iteration 24047: loss: 0.064443, loss_s1: 0.063543, loss_fp: 0.002841, loss_freq: 0.032477
[06:46:31.375] iteration 24048: loss: 0.063254, loss_s1: 0.058498, loss_fp: 0.004097, loss_freq: 0.036712
[06:46:31.992] iteration 24049: loss: 0.036791, loss_s1: 0.024144, loss_fp: 0.004960, loss_freq: 0.024675
[06:46:32.611] iteration 24050: loss: 0.040815, loss_s1: 0.030364, loss_fp: 0.002278, loss_freq: 0.015287
[06:46:33.241] iteration 24051: loss: 0.076316, loss_s1: 0.076863, loss_fp: 0.005560, loss_freq: 0.020374
[06:46:33.860] iteration 24052: loss: 0.043800, loss_s1: 0.037151, loss_fp: 0.003175, loss_freq: 0.017618
[06:46:34.479] iteration 24053: loss: 0.068325, loss_s1: 0.070123, loss_fp: 0.005699, loss_freq: 0.033707
[06:46:35.109] iteration 24054: loss: 0.047176, loss_s1: 0.029788, loss_fp: 0.006902, loss_freq: 0.023172
[06:46:35.763] iteration 24055: loss: 0.053995, loss_s1: 0.046959, loss_fp: 0.003931, loss_freq: 0.028031
[06:46:36.422] iteration 24056: loss: 0.063008, loss_s1: 0.050352, loss_fp: 0.002764, loss_freq: 0.027375
[06:46:37.076] iteration 24057: loss: 0.075168, loss_s1: 0.095439, loss_fp: 0.004655, loss_freq: 0.031284
[06:46:37.727] iteration 24058: loss: 0.091181, loss_s1: 0.081261, loss_fp: 0.017622, loss_freq: 0.032955
[06:46:38.342] iteration 24059: loss: 0.097943, loss_s1: 0.074729, loss_fp: 0.004594, loss_freq: 0.086566
[06:46:38.958] iteration 24060: loss: 0.039644, loss_s1: 0.014146, loss_fp: 0.001575, loss_freq: 0.015579
[06:46:39.565] iteration 24061: loss: 0.066481, loss_s1: 0.064589, loss_fp: 0.004236, loss_freq: 0.034458
[06:46:40.254] iteration 24062: loss: 0.069437, loss_s1: 0.054353, loss_fp: 0.004428, loss_freq: 0.041972
[06:46:40.870] iteration 24063: loss: 0.100980, loss_s1: 0.048644, loss_fp: 0.012253, loss_freq: 0.102757
[06:46:41.483] iteration 24064: loss: 0.066072, loss_s1: 0.067223, loss_fp: 0.003414, loss_freq: 0.034835
[06:46:42.092] iteration 24065: loss: 0.066465, loss_s1: 0.065535, loss_fp: 0.004227, loss_freq: 0.030853
[06:46:42.718] iteration 24066: loss: 0.046991, loss_s1: 0.035124, loss_fp: 0.003480, loss_freq: 0.028211
[06:46:43.358] iteration 24067: loss: 0.067077, loss_s1: 0.077816, loss_fp: 0.002613, loss_freq: 0.015783
[06:46:43.970] iteration 24068: loss: 0.057541, loss_s1: 0.039636, loss_fp: 0.008238, loss_freq: 0.035325
[06:46:44.584] iteration 24069: loss: 0.058112, loss_s1: 0.044928, loss_fp: 0.002350, loss_freq: 0.043063
[06:46:45.192] iteration 24070: loss: 0.056193, loss_s1: 0.051483, loss_fp: 0.004867, loss_freq: 0.016431
[06:46:45.802] iteration 24071: loss: 0.049560, loss_s1: 0.050088, loss_fp: 0.005719, loss_freq: 0.021881
[06:46:46.414] iteration 24072: loss: 0.042203, loss_s1: 0.022524, loss_fp: 0.001902, loss_freq: 0.020374
[06:46:47.024] iteration 24073: loss: 0.034930, loss_s1: 0.030362, loss_fp: 0.001029, loss_freq: 0.014660
[06:46:47.634] iteration 24074: loss: 0.032560, loss_s1: 0.016498, loss_fp: 0.003878, loss_freq: 0.014815
[06:46:48.239] iteration 24075: loss: 0.030040, loss_s1: 0.018200, loss_fp: 0.001532, loss_freq: 0.012399
[06:46:48.843] iteration 24076: loss: 0.082267, loss_s1: 0.095776, loss_fp: 0.005548, loss_freq: 0.030149
[06:46:49.463] iteration 24077: loss: 0.061582, loss_s1: 0.059457, loss_fp: 0.004306, loss_freq: 0.025403
[06:46:50.069] iteration 24078: loss: 0.042718, loss_s1: 0.038072, loss_fp: 0.006870, loss_freq: 0.015184
[06:46:50.678] iteration 24079: loss: 0.044980, loss_s1: 0.012221, loss_fp: 0.012393, loss_freq: 0.033361
[06:46:51.294] iteration 24080: loss: 0.058090, loss_s1: 0.047248, loss_fp: 0.001611, loss_freq: 0.043347
[06:46:51.901] iteration 24081: loss: 0.051862, loss_s1: 0.047171, loss_fp: 0.004338, loss_freq: 0.019904
[06:46:52.517] iteration 24082: loss: 0.066978, loss_s1: 0.071207, loss_fp: 0.002573, loss_freq: 0.026761
[06:46:53.128] iteration 24083: loss: 0.051487, loss_s1: 0.050374, loss_fp: 0.004581, loss_freq: 0.025085
[06:46:53.738] iteration 24084: loss: 0.035767, loss_s1: 0.028147, loss_fp: 0.004700, loss_freq: 0.014812
[06:46:54.352] iteration 24085: loss: 0.061370, loss_s1: 0.016264, loss_fp: 0.017941, loss_freq: 0.028373
[06:46:54.963] iteration 24086: loss: 0.047546, loss_s1: 0.028300, loss_fp: 0.003438, loss_freq: 0.032520
[06:46:55.573] iteration 24087: loss: 0.058758, loss_s1: 0.062906, loss_fp: 0.001068, loss_freq: 0.018001
[06:46:56.184] iteration 24088: loss: 0.065884, loss_s1: 0.084207, loss_fp: 0.001890, loss_freq: 0.017199
[06:46:56.865] iteration 24089: loss: 0.090713, loss_s1: 0.105433, loss_fp: 0.006541, loss_freq: 0.037514
[06:46:57.523] iteration 24090: loss: 0.072995, loss_s1: 0.049558, loss_fp: 0.004692, loss_freq: 0.054959
[06:46:58.179] iteration 24091: loss: 0.053956, loss_s1: 0.055696, loss_fp: 0.002389, loss_freq: 0.009409
[06:46:58.833] iteration 24092: loss: 0.071324, loss_s1: 0.094022, loss_fp: 0.002671, loss_freq: 0.026347
[06:46:59.495] iteration 24093: loss: 0.074093, loss_s1: 0.076082, loss_fp: 0.002772, loss_freq: 0.030887
[06:47:00.138] iteration 24094: loss: 0.052258, loss_s1: 0.030599, loss_fp: 0.008185, loss_freq: 0.037126
[06:47:00.748] iteration 24095: loss: 0.085182, loss_s1: 0.063900, loss_fp: 0.009123, loss_freq: 0.060695
[06:47:01.356] iteration 24096: loss: 0.088629, loss_s1: 0.119482, loss_fp: 0.001457, loss_freq: 0.021135
[06:47:01.967] iteration 24097: loss: 0.066078, loss_s1: 0.049597, loss_fp: 0.004527, loss_freq: 0.060217
[06:47:02.578] iteration 24098: loss: 0.040988, loss_s1: 0.021093, loss_fp: 0.001136, loss_freq: 0.017456
[06:47:03.191] iteration 24099: loss: 0.051933, loss_s1: 0.054617, loss_fp: 0.007052, loss_freq: 0.018263
[06:47:03.804] iteration 24100: loss: 0.059364, loss_s1: 0.039115, loss_fp: 0.011743, loss_freq: 0.038928
[06:47:04.412] iteration 24101: loss: 0.055187, loss_s1: 0.064146, loss_fp: 0.003504, loss_freq: 0.020304
[06:47:05.023] iteration 24102: loss: 0.052171, loss_s1: 0.041247, loss_fp: 0.004462, loss_freq: 0.021432
[06:47:05.631] iteration 24103: loss: 0.071684, loss_s1: 0.080718, loss_fp: 0.004866, loss_freq: 0.025488
[06:47:06.248] iteration 24104: loss: 0.041168, loss_s1: 0.033836, loss_fp: 0.006947, loss_freq: 0.016153
[06:47:06.873] iteration 24105: loss: 0.136441, loss_s1: 0.092092, loss_fp: 0.000642, loss_freq: 0.146754
[06:47:07.491] iteration 24106: loss: 0.034899, loss_s1: 0.024350, loss_fp: 0.004052, loss_freq: 0.015755
[06:47:08.096] iteration 24107: loss: 0.074721, loss_s1: 0.083464, loss_fp: 0.001390, loss_freq: 0.009433
[06:47:08.706] iteration 24108: loss: 0.049157, loss_s1: 0.044158, loss_fp: 0.004404, loss_freq: 0.023615
[06:47:09.312] iteration 24109: loss: 0.108680, loss_s1: 0.123999, loss_fp: 0.005945, loss_freq: 0.056741
[06:47:09.955] iteration 24110: loss: 0.064245, loss_s1: 0.077194, loss_fp: 0.003169, loss_freq: 0.023365
[06:47:10.618] iteration 24111: loss: 0.089770, loss_s1: 0.054698, loss_fp: 0.001876, loss_freq: 0.024512
[06:47:11.281] iteration 24112: loss: 0.056465, loss_s1: 0.049585, loss_fp: 0.003720, loss_freq: 0.026847
[06:47:11.950] iteration 24113: loss: 0.057728, loss_s1: 0.045698, loss_fp: 0.014680, loss_freq: 0.021984
[06:47:12.580] iteration 24114: loss: 0.040286, loss_s1: 0.026189, loss_fp: 0.003031, loss_freq: 0.020216
[06:47:13.191] iteration 24115: loss: 0.032832, loss_s1: 0.016057, loss_fp: 0.005178, loss_freq: 0.011046
[06:47:13.804] iteration 24116: loss: 0.056752, loss_s1: 0.056739, loss_fp: 0.004290, loss_freq: 0.019333
[06:47:14.425] iteration 24117: loss: 0.052919, loss_s1: 0.045954, loss_fp: 0.003308, loss_freq: 0.023652
[06:47:15.042] iteration 24118: loss: 0.064265, loss_s1: 0.079748, loss_fp: 0.002448, loss_freq: 0.021161
[06:47:15.658] iteration 24119: loss: 0.062205, loss_s1: 0.059543, loss_fp: 0.003729, loss_freq: 0.038368
[06:47:16.295] iteration 24120: loss: 0.089980, loss_s1: 0.086271, loss_fp: 0.013441, loss_freq: 0.039141
[06:47:16.911] iteration 24121: loss: 0.051590, loss_s1: 0.023989, loss_fp: 0.005171, loss_freq: 0.039902
[06:47:17.526] iteration 24122: loss: 0.081544, loss_s1: 0.092889, loss_fp: 0.003916, loss_freq: 0.033522
[06:47:18.140] iteration 24123: loss: 0.069310, loss_s1: 0.070907, loss_fp: 0.002412, loss_freq: 0.031521
[06:47:18.808] iteration 24124: loss: 0.076028, loss_s1: 0.085886, loss_fp: 0.006522, loss_freq: 0.025607
[06:47:19.426] iteration 24125: loss: 0.054913, loss_s1: 0.041375, loss_fp: 0.003688, loss_freq: 0.031038
[06:47:20.043] iteration 24126: loss: 0.046521, loss_s1: 0.027543, loss_fp: 0.006192, loss_freq: 0.018842
[06:47:20.722] iteration 24127: loss: 0.037283, loss_s1: 0.034558, loss_fp: 0.004678, loss_freq: 0.015661
[06:47:21.350] iteration 24128: loss: 0.087154, loss_s1: 0.063656, loss_fp: 0.007979, loss_freq: 0.046196
[06:47:22.004] iteration 24129: loss: 0.047127, loss_s1: 0.038342, loss_fp: 0.003873, loss_freq: 0.020546
[06:47:22.631] iteration 24130: loss: 0.069593, loss_s1: 0.059786, loss_fp: 0.007060, loss_freq: 0.035455
[06:47:23.243] iteration 24131: loss: 0.060479, loss_s1: 0.064198, loss_fp: 0.005272, loss_freq: 0.011276
[06:47:23.861] iteration 24132: loss: 0.067054, loss_s1: 0.053714, loss_fp: 0.010866, loss_freq: 0.044245
[06:47:24.501] iteration 24133: loss: 0.042587, loss_s1: 0.031027, loss_fp: 0.009057, loss_freq: 0.009049
[06:47:25.164] iteration 24134: loss: 0.041171, loss_s1: 0.029719, loss_fp: 0.003031, loss_freq: 0.028203
[06:47:25.829] iteration 24135: loss: 0.036334, loss_s1: 0.022455, loss_fp: 0.002293, loss_freq: 0.018506
[06:47:26.474] iteration 24136: loss: 0.071921, loss_s1: 0.079919, loss_fp: 0.001661, loss_freq: 0.041417
[06:47:27.082] iteration 24137: loss: 0.044967, loss_s1: 0.025519, loss_fp: 0.005856, loss_freq: 0.018192
[06:47:27.690] iteration 24138: loss: 0.077202, loss_s1: 0.066780, loss_fp: 0.001717, loss_freq: 0.050965
[06:47:28.291] iteration 24139: loss: 0.070649, loss_s1: 0.058571, loss_fp: 0.003688, loss_freq: 0.052929
[06:47:28.904] iteration 24140: loss: 0.061359, loss_s1: 0.056130, loss_fp: 0.002422, loss_freq: 0.025758
[06:47:29.939] iteration 24141: loss: 0.074578, loss_s1: 0.061102, loss_fp: 0.006308, loss_freq: 0.046403
[06:47:30.608] iteration 24142: loss: 0.055380, loss_s1: 0.034760, loss_fp: 0.010528, loss_freq: 0.026667
[06:47:31.252] iteration 24143: loss: 0.054564, loss_s1: 0.051231, loss_fp: 0.005513, loss_freq: 0.023992
[06:47:31.864] iteration 24144: loss: 0.043172, loss_s1: 0.027636, loss_fp: 0.002033, loss_freq: 0.022674
[06:47:32.470] iteration 24145: loss: 0.046295, loss_s1: 0.043007, loss_fp: 0.002098, loss_freq: 0.020199
[06:47:33.084] iteration 24146: loss: 0.090283, loss_s1: 0.074337, loss_fp: 0.001923, loss_freq: 0.059336
[06:47:33.697] iteration 24147: loss: 0.065633, loss_s1: 0.061447, loss_fp: 0.001472, loss_freq: 0.019556
[06:47:34.311] iteration 24148: loss: 0.052875, loss_s1: 0.044807, loss_fp: 0.003839, loss_freq: 0.026969
[06:47:34.933] iteration 24149: loss: 0.061352, loss_s1: 0.039538, loss_fp: 0.002936, loss_freq: 0.028549
[06:47:35.548] iteration 24150: loss: 0.059395, loss_s1: 0.038114, loss_fp: 0.003212, loss_freq: 0.045417
[06:47:36.168] iteration 24151: loss: 0.053289, loss_s1: 0.036549, loss_fp: 0.006128, loss_freq: 0.023423
[06:47:36.815] iteration 24152: loss: 0.082186, loss_s1: 0.083873, loss_fp: 0.003162, loss_freq: 0.043017
[06:47:37.425] iteration 24153: loss: 0.062630, loss_s1: 0.064218, loss_fp: 0.005882, loss_freq: 0.021343
[06:47:38.036] iteration 24154: loss: 0.053112, loss_s1: 0.054499, loss_fp: 0.004557, loss_freq: 0.021965
[06:47:38.655] iteration 24155: loss: 0.073921, loss_s1: 0.075345, loss_fp: 0.001751, loss_freq: 0.025724
[06:47:39.275] iteration 24156: loss: 0.048400, loss_s1: 0.050928, loss_fp: 0.002736, loss_freq: 0.012699
[06:47:39.884] iteration 24157: loss: 0.133504, loss_s1: 0.118048, loss_fp: 0.013180, loss_freq: 0.112716
[06:47:40.503] iteration 24158: loss: 0.051192, loss_s1: 0.047321, loss_fp: 0.001182, loss_freq: 0.011709
[06:47:41.116] iteration 24159: loss: 0.057922, loss_s1: 0.063844, loss_fp: 0.007672, loss_freq: 0.019858
[06:47:41.729] iteration 24160: loss: 0.051917, loss_s1: 0.046653, loss_fp: 0.006575, loss_freq: 0.017476
[06:47:42.350] iteration 24161: loss: 0.065110, loss_s1: 0.059567, loss_fp: 0.005656, loss_freq: 0.030414
[06:47:42.966] iteration 24162: loss: 0.066570, loss_s1: 0.072182, loss_fp: 0.006230, loss_freq: 0.029781
[06:47:43.586] iteration 24163: loss: 0.065125, loss_s1: 0.059059, loss_fp: 0.002916, loss_freq: 0.028349
[06:47:44.195] iteration 24164: loss: 0.038432, loss_s1: 0.022253, loss_fp: 0.002044, loss_freq: 0.016416
[06:47:44.803] iteration 24165: loss: 0.070002, loss_s1: 0.050868, loss_fp: 0.009999, loss_freq: 0.034884
[06:47:45.418] iteration 24166: loss: 0.055545, loss_s1: 0.052800, loss_fp: 0.006849, loss_freq: 0.026258
[06:47:46.030] iteration 24167: loss: 0.057359, loss_s1: 0.057577, loss_fp: 0.004560, loss_freq: 0.021027
[06:47:46.639] iteration 24168: loss: 0.054946, loss_s1: 0.051097, loss_fp: 0.005904, loss_freq: 0.013768
[06:47:47.251] iteration 24169: loss: 0.045031, loss_s1: 0.041201, loss_fp: 0.002829, loss_freq: 0.015128
[06:47:47.858] iteration 24170: loss: 0.087360, loss_s1: 0.101037, loss_fp: 0.003916, loss_freq: 0.032268
[06:47:48.462] iteration 24171: loss: 0.073797, loss_s1: 0.073920, loss_fp: 0.003691, loss_freq: 0.048829
[06:47:49.068] iteration 24172: loss: 0.069679, loss_s1: 0.056411, loss_fp: 0.010322, loss_freq: 0.031335
[06:47:49.677] iteration 24173: loss: 0.058562, loss_s1: 0.046016, loss_fp: 0.001579, loss_freq: 0.037146
[06:47:50.298] iteration 24174: loss: 0.057453, loss_s1: 0.043421, loss_fp: 0.004865, loss_freq: 0.009261
[06:47:50.919] iteration 24175: loss: 0.056209, loss_s1: 0.055411, loss_fp: 0.001107, loss_freq: 0.033863
[06:47:51.541] iteration 24176: loss: 0.063138, loss_s1: 0.033296, loss_fp: 0.004269, loss_freq: 0.024270
[06:47:52.163] iteration 24177: loss: 0.051803, loss_s1: 0.034197, loss_fp: 0.001956, loss_freq: 0.036433
[06:47:52.777] iteration 24178: loss: 0.055970, loss_s1: 0.058371, loss_fp: 0.005656, loss_freq: 0.018900
[06:47:53.387] iteration 24179: loss: 0.063301, loss_s1: 0.041833, loss_fp: 0.006279, loss_freq: 0.045906
[06:47:53.999] iteration 24180: loss: 0.061450, loss_s1: 0.052718, loss_fp: 0.019318, loss_freq: 0.025503
[06:47:54.659] iteration 24181: loss: 0.094493, loss_s1: 0.127084, loss_fp: 0.001722, loss_freq: 0.023183
[06:47:55.280] iteration 24182: loss: 0.078468, loss_s1: 0.067817, loss_fp: 0.004368, loss_freq: 0.048379
[06:47:55.890] iteration 24183: loss: 0.092287, loss_s1: 0.105984, loss_fp: 0.016642, loss_freq: 0.030887
[06:47:56.504] iteration 24184: loss: 0.071028, loss_s1: 0.047821, loss_fp: 0.008313, loss_freq: 0.059289
[06:47:57.200] iteration 24185: loss: 0.060632, loss_s1: 0.040213, loss_fp: 0.012835, loss_freq: 0.029331
[06:47:57.864] iteration 24186: loss: 0.054971, loss_s1: 0.042598, loss_fp: 0.007284, loss_freq: 0.017126
[06:47:58.549] iteration 24187: loss: 0.045326, loss_s1: 0.040391, loss_fp: 0.003600, loss_freq: 0.015665
[06:47:59.223] iteration 24188: loss: 0.057596, loss_s1: 0.037553, loss_fp: 0.003808, loss_freq: 0.044070
[06:47:59.870] iteration 24189: loss: 0.037676, loss_s1: 0.037016, loss_fp: 0.000828, loss_freq: 0.007205
[06:48:00.525] iteration 24190: loss: 0.040741, loss_s1: 0.020544, loss_fp: 0.002856, loss_freq: 0.009309
[06:48:01.140] iteration 24191: loss: 0.068660, loss_s1: 0.036883, loss_fp: 0.002500, loss_freq: 0.067297
[06:48:01.751] iteration 24192: loss: 0.056701, loss_s1: 0.042340, loss_fp: 0.003837, loss_freq: 0.043798
[06:48:02.363] iteration 24193: loss: 0.064848, loss_s1: 0.050165, loss_fp: 0.000339, loss_freq: 0.016961
[06:48:02.976] iteration 24194: loss: 0.070419, loss_s1: 0.064078, loss_fp: 0.004673, loss_freq: 0.044205
[06:48:03.583] iteration 24195: loss: 0.067338, loss_s1: 0.029605, loss_fp: 0.014290, loss_freq: 0.051848
[06:48:04.189] iteration 24196: loss: 0.041896, loss_s1: 0.014266, loss_fp: 0.002270, loss_freq: 0.033105
[06:48:04.803] iteration 24197: loss: 0.061361, loss_s1: 0.035704, loss_fp: 0.001745, loss_freq: 0.062836
[06:48:05.411] iteration 24198: loss: 0.065701, loss_s1: 0.022723, loss_fp: 0.002735, loss_freq: 0.023840
[06:48:06.018] iteration 24199: loss: 0.047811, loss_s1: 0.016159, loss_fp: 0.002510, loss_freq: 0.048428
[06:48:06.626] iteration 24200: loss: 0.053536, loss_s1: 0.035243, loss_fp: 0.002287, loss_freq: 0.039749
[06:48:09.883] iteration 24200 : mean_dice : 0.745413
[06:48:10.518] iteration 24201: loss: 0.029011, loss_s1: 0.015737, loss_fp: 0.002710, loss_freq: 0.008474
[06:48:11.125] iteration 24202: loss: 0.067054, loss_s1: 0.063439, loss_fp: 0.001711, loss_freq: 0.027418
[06:48:11.743] iteration 24203: loss: 0.042490, loss_s1: 0.034077, loss_fp: 0.002486, loss_freq: 0.013336
[06:48:12.347] iteration 24204: loss: 0.037725, loss_s1: 0.023927, loss_fp: 0.001248, loss_freq: 0.026549
[06:48:12.960] iteration 24205: loss: 0.036699, loss_s1: 0.020473, loss_fp: 0.000798, loss_freq: 0.013014
[06:48:13.575] iteration 24206: loss: 0.057525, loss_s1: 0.044215, loss_fp: 0.005642, loss_freq: 0.039865
[06:48:14.188] iteration 24207: loss: 0.050312, loss_s1: 0.027654, loss_fp: 0.001175, loss_freq: 0.010484
[06:48:14.800] iteration 24208: loss: 0.085385, loss_s1: 0.073261, loss_fp: 0.003118, loss_freq: 0.056994
[06:48:15.408] iteration 24209: loss: 0.038898, loss_s1: 0.027561, loss_fp: 0.002692, loss_freq: 0.015419
[06:48:16.018] iteration 24210: loss: 0.052233, loss_s1: 0.057963, loss_fp: 0.001752, loss_freq: 0.021654
[06:48:16.630] iteration 24211: loss: 0.063040, loss_s1: 0.062412, loss_fp: 0.002231, loss_freq: 0.029450
[06:48:17.245] iteration 24212: loss: 0.040628, loss_s1: 0.026626, loss_fp: 0.002082, loss_freq: 0.021685
[06:48:17.859] iteration 24213: loss: 0.061528, loss_s1: 0.036346, loss_fp: 0.009226, loss_freq: 0.048622
[06:48:18.470] iteration 24214: loss: 0.060577, loss_s1: 0.062637, loss_fp: 0.008015, loss_freq: 0.016824
[06:48:19.077] iteration 24215: loss: 0.053212, loss_s1: 0.013991, loss_fp: 0.001914, loss_freq: 0.063180
[06:48:19.695] iteration 24216: loss: 0.057692, loss_s1: 0.042218, loss_fp: 0.005839, loss_freq: 0.034076
[06:48:20.302] iteration 24217: loss: 0.072828, loss_s1: 0.057816, loss_fp: 0.003628, loss_freq: 0.045911
[06:48:20.915] iteration 24218: loss: 0.093554, loss_s1: 0.097483, loss_fp: 0.007096, loss_freq: 0.053153
[06:48:21.526] iteration 24219: loss: 0.070898, loss_s1: 0.071418, loss_fp: 0.012713, loss_freq: 0.020931
[06:48:22.136] iteration 24220: loss: 0.061071, loss_s1: 0.065010, loss_fp: 0.001877, loss_freq: 0.017984
[06:48:22.756] iteration 24221: loss: 0.052761, loss_s1: 0.043146, loss_fp: 0.002644, loss_freq: 0.022966
[06:48:23.362] iteration 24222: loss: 0.060909, loss_s1: 0.048970, loss_fp: 0.005492, loss_freq: 0.037503
[06:48:23.990] iteration 24223: loss: 0.058188, loss_s1: 0.056207, loss_fp: 0.002105, loss_freq: 0.024892
[06:48:24.593] iteration 24224: loss: 0.039570, loss_s1: 0.032539, loss_fp: 0.004883, loss_freq: 0.011011
[06:48:25.194] iteration 24225: loss: 0.053503, loss_s1: 0.042912, loss_fp: 0.002257, loss_freq: 0.026499
[06:48:25.805] iteration 24226: loss: 0.087701, loss_s1: 0.080492, loss_fp: 0.016523, loss_freq: 0.028481
[06:48:26.409] iteration 24227: loss: 0.067497, loss_s1: 0.074791, loss_fp: 0.012133, loss_freq: 0.029170
[06:48:27.013] iteration 24228: loss: 0.056004, loss_s1: 0.034597, loss_fp: 0.004227, loss_freq: 0.024480
[06:48:27.619] iteration 24229: loss: 0.062861, loss_s1: 0.043766, loss_fp: 0.004212, loss_freq: 0.049221
[06:48:28.234] iteration 24230: loss: 0.048664, loss_s1: 0.024641, loss_fp: 0.000716, loss_freq: 0.022349
[06:48:28.848] iteration 24231: loss: 0.081418, loss_s1: 0.068876, loss_fp: 0.007620, loss_freq: 0.044093
[06:48:29.469] iteration 24232: loss: 0.045398, loss_s1: 0.037084, loss_fp: 0.007748, loss_freq: 0.024484
[06:48:30.084] iteration 24233: loss: 0.048881, loss_s1: 0.036287, loss_fp: 0.002714, loss_freq: 0.014897
[06:48:30.695] iteration 24234: loss: 0.054931, loss_s1: 0.046519, loss_fp: 0.006066, loss_freq: 0.032270
[06:48:31.303] iteration 24235: loss: 0.068583, loss_s1: 0.080196, loss_fp: 0.011451, loss_freq: 0.019001
[06:48:31.919] iteration 24236: loss: 0.050728, loss_s1: 0.052935, loss_fp: 0.001035, loss_freq: 0.025372
[06:48:32.528] iteration 24237: loss: 0.083807, loss_s1: 0.076148, loss_fp: 0.009399, loss_freq: 0.036404
[06:48:33.147] iteration 24238: loss: 0.092804, loss_s1: 0.042183, loss_fp: 0.011884, loss_freq: 0.091365
[06:48:33.761] iteration 24239: loss: 0.078279, loss_s1: 0.084266, loss_fp: 0.005678, loss_freq: 0.042066
[06:48:34.382] iteration 24240: loss: 0.063575, loss_s1: 0.055139, loss_fp: 0.017382, loss_freq: 0.016406
[06:48:35.034] iteration 24241: loss: 0.055523, loss_s1: 0.056895, loss_fp: 0.007811, loss_freq: 0.016873
[06:48:35.647] iteration 24242: loss: 0.047504, loss_s1: 0.026497, loss_fp: 0.012285, loss_freq: 0.012910
[06:48:36.342] iteration 24243: loss: 0.034269, loss_s1: 0.020282, loss_fp: 0.004501, loss_freq: 0.012184
[06:48:36.954] iteration 24244: loss: 0.034758, loss_s1: 0.019950, loss_fp: 0.000959, loss_freq: 0.017551
[06:48:37.561] iteration 24245: loss: 0.033776, loss_s1: 0.017786, loss_fp: 0.001914, loss_freq: 0.021334
[06:48:38.189] iteration 24246: loss: 0.048022, loss_s1: 0.031208, loss_fp: 0.006450, loss_freq: 0.027174
[06:48:38.795] iteration 24247: loss: 0.051026, loss_s1: 0.046463, loss_fp: 0.003751, loss_freq: 0.022141
[06:48:39.408] iteration 24248: loss: 0.044906, loss_s1: 0.029876, loss_fp: 0.000939, loss_freq: 0.027595
[06:48:40.024] iteration 24249: loss: 0.053012, loss_s1: 0.030695, loss_fp: 0.006740, loss_freq: 0.039941
[06:48:40.633] iteration 24250: loss: 0.058092, loss_s1: 0.054581, loss_fp: 0.006595, loss_freq: 0.026855
[06:48:41.245] iteration 24251: loss: 0.048712, loss_s1: 0.046243, loss_fp: 0.004090, loss_freq: 0.014067
[06:48:41.854] iteration 24252: loss: 0.046562, loss_s1: 0.021628, loss_fp: 0.004101, loss_freq: 0.031287
[06:48:42.476] iteration 24253: loss: 0.076181, loss_s1: 0.068289, loss_fp: 0.003104, loss_freq: 0.053196
[06:48:43.096] iteration 24254: loss: 0.034475, loss_s1: 0.019554, loss_fp: 0.012104, loss_freq: 0.014588
[06:48:43.699] iteration 24255: loss: 0.059523, loss_s1: 0.049286, loss_fp: 0.002602, loss_freq: 0.031621
[06:48:44.338] iteration 24256: loss: 0.088464, loss_s1: 0.038774, loss_fp: 0.004262, loss_freq: 0.093596
[06:48:44.948] iteration 24257: loss: 0.046116, loss_s1: 0.037245, loss_fp: 0.007732, loss_freq: 0.015399
[06:48:45.554] iteration 24258: loss: 0.052335, loss_s1: 0.025277, loss_fp: 0.007834, loss_freq: 0.045446
[06:48:46.155] iteration 24259: loss: 0.037034, loss_s1: 0.015836, loss_fp: 0.003492, loss_freq: 0.022071
[06:48:46.762] iteration 24260: loss: 0.061463, loss_s1: 0.043108, loss_fp: 0.006675, loss_freq: 0.042920
[06:48:47.367] iteration 24261: loss: 0.034651, loss_s1: 0.021170, loss_fp: 0.005391, loss_freq: 0.008313
[06:48:47.971] iteration 24262: loss: 0.070569, loss_s1: 0.079344, loss_fp: 0.007665, loss_freq: 0.033548
[06:48:48.579] iteration 24263: loss: 0.066014, loss_s1: 0.041169, loss_fp: 0.003198, loss_freq: 0.048956
[06:48:49.189] iteration 24264: loss: 0.042965, loss_s1: 0.024374, loss_fp: 0.003219, loss_freq: 0.030419
[06:48:49.802] iteration 24265: loss: 0.062789, loss_s1: 0.056303, loss_fp: 0.003903, loss_freq: 0.034143
[06:48:50.415] iteration 24266: loss: 0.037072, loss_s1: 0.006916, loss_fp: 0.010878, loss_freq: 0.021945
[06:48:51.027] iteration 24267: loss: 0.039639, loss_s1: 0.021511, loss_fp: 0.003467, loss_freq: 0.028938
[06:48:51.638] iteration 24268: loss: 0.051167, loss_s1: 0.042368, loss_fp: 0.004767, loss_freq: 0.016813
[06:48:52.260] iteration 24269: loss: 0.058578, loss_s1: 0.048028, loss_fp: 0.016559, loss_freq: 0.025746
[06:48:52.872] iteration 24270: loss: 0.053032, loss_s1: 0.037574, loss_fp: 0.002616, loss_freq: 0.033453
[06:48:53.508] iteration 24271: loss: 0.047734, loss_s1: 0.049638, loss_fp: 0.004427, loss_freq: 0.018091
[06:48:54.204] iteration 24272: loss: 0.052149, loss_s1: 0.035288, loss_fp: 0.004282, loss_freq: 0.016762
[06:48:54.845] iteration 24273: loss: 0.104379, loss_s1: 0.127572, loss_fp: 0.012329, loss_freq: 0.038063
[06:48:55.582] iteration 24274: loss: 0.036436, loss_s1: 0.036753, loss_fp: 0.003503, loss_freq: 0.008003
[06:48:56.269] iteration 24275: loss: 0.058565, loss_s1: 0.063557, loss_fp: 0.008434, loss_freq: 0.013423
[06:48:57.021] iteration 24276: loss: 0.028364, loss_s1: 0.022175, loss_fp: 0.001282, loss_freq: 0.009832
[06:48:57.726] iteration 24277: loss: 0.038651, loss_s1: 0.017404, loss_fp: 0.005551, loss_freq: 0.013793
[06:48:58.425] iteration 24278: loss: 0.049441, loss_s1: 0.027505, loss_fp: 0.002218, loss_freq: 0.041191
[06:48:59.065] iteration 24279: loss: 0.116277, loss_s1: 0.140886, loss_fp: 0.006560, loss_freq: 0.050952
[06:48:59.695] iteration 24280: loss: 0.067415, loss_s1: 0.065141, loss_fp: 0.006498, loss_freq: 0.044082
[06:49:00.422] iteration 24281: loss: 0.049547, loss_s1: 0.029466, loss_fp: 0.007455, loss_freq: 0.029082
[06:49:01.067] iteration 24282: loss: 0.056529, loss_s1: 0.036951, loss_fp: 0.002160, loss_freq: 0.035630
[06:49:01.780] iteration 24283: loss: 0.053345, loss_s1: 0.058181, loss_fp: 0.003651, loss_freq: 0.018558
[06:49:02.445] iteration 24284: loss: 0.041954, loss_s1: 0.031027, loss_fp: 0.002197, loss_freq: 0.021400
[06:49:03.135] iteration 24285: loss: 0.029975, loss_s1: 0.015897, loss_fp: 0.002378, loss_freq: 0.012179
[06:49:03.807] iteration 24286: loss: 0.048036, loss_s1: 0.042058, loss_fp: 0.003744, loss_freq: 0.017274
[06:49:04.486] iteration 24287: loss: 0.046192, loss_s1: 0.035445, loss_fp: 0.002872, loss_freq: 0.022710
[06:49:05.230] iteration 24288: loss: 0.064487, loss_s1: 0.074923, loss_fp: 0.003551, loss_freq: 0.018854
[06:49:05.877] iteration 24289: loss: 0.099061, loss_s1: 0.113270, loss_fp: 0.003510, loss_freq: 0.044363
[06:49:06.496] iteration 24290: loss: 0.049460, loss_s1: 0.041701, loss_fp: 0.005802, loss_freq: 0.018904
[06:49:07.110] iteration 24291: loss: 0.052771, loss_s1: 0.039432, loss_fp: 0.011411, loss_freq: 0.020494
[06:49:07.723] iteration 24292: loss: 0.081812, loss_s1: 0.075128, loss_fp: 0.002032, loss_freq: 0.039359
[06:49:08.342] iteration 24293: loss: 0.079662, loss_s1: 0.068553, loss_fp: 0.008787, loss_freq: 0.054211
[06:49:08.960] iteration 24294: loss: 0.061582, loss_s1: 0.032704, loss_fp: 0.003634, loss_freq: 0.061018
[06:49:09.580] iteration 24295: loss: 0.057862, loss_s1: 0.064020, loss_fp: 0.004273, loss_freq: 0.014264
[06:49:10.196] iteration 24296: loss: 0.036785, loss_s1: 0.024767, loss_fp: 0.005048, loss_freq: 0.014687
[06:49:10.814] iteration 24297: loss: 0.028609, loss_s1: 0.023697, loss_fp: 0.001084, loss_freq: 0.009821
[06:49:11.425] iteration 24298: loss: 0.072900, loss_s1: 0.051990, loss_fp: 0.003716, loss_freq: 0.063019
[06:49:12.035] iteration 24299: loss: 0.072697, loss_s1: 0.054680, loss_fp: 0.015889, loss_freq: 0.039951
[06:49:12.654] iteration 24300: loss: 0.075877, loss_s1: 0.092538, loss_fp: 0.002979, loss_freq: 0.019714
[06:49:13.270] iteration 24301: loss: 0.040269, loss_s1: 0.038743, loss_fp: 0.001357, loss_freq: 0.007904
[06:49:13.880] iteration 24302: loss: 0.078767, loss_s1: 0.078470, loss_fp: 0.005202, loss_freq: 0.038785
[06:49:14.491] iteration 24303: loss: 0.058196, loss_s1: 0.060054, loss_fp: 0.006556, loss_freq: 0.014608
[06:49:15.102] iteration 24304: loss: 0.048903, loss_s1: 0.033140, loss_fp: 0.001119, loss_freq: 0.033814
[06:49:15.718] iteration 24305: loss: 0.052220, loss_s1: 0.039455, loss_fp: 0.007599, loss_freq: 0.020440
[06:49:16.340] iteration 24306: loss: 0.077238, loss_s1: 0.069339, loss_fp: 0.010168, loss_freq: 0.051837
[06:49:16.942] iteration 24307: loss: 0.076519, loss_s1: 0.050467, loss_fp: 0.003212, loss_freq: 0.068673
[06:49:17.549] iteration 24308: loss: 0.071218, loss_s1: 0.093502, loss_fp: 0.005443, loss_freq: 0.011661
[06:49:18.157] iteration 24309: loss: 0.079370, loss_s1: 0.067728, loss_fp: 0.010144, loss_freq: 0.051054
[06:49:18.761] iteration 24310: loss: 0.059190, loss_s1: 0.058386, loss_fp: 0.006271, loss_freq: 0.015496
[06:49:19.713] iteration 24311: loss: 0.086796, loss_s1: 0.067392, loss_fp: 0.000676, loss_freq: 0.057926
[06:49:20.328] iteration 24312: loss: 0.048904, loss_s1: 0.024301, loss_fp: 0.004131, loss_freq: 0.025030
[06:49:20.944] iteration 24313: loss: 0.050362, loss_s1: 0.033977, loss_fp: 0.003261, loss_freq: 0.034609
[06:49:21.560] iteration 24314: loss: 0.056023, loss_s1: 0.051423, loss_fp: 0.001085, loss_freq: 0.017380
[06:49:22.350] iteration 24315: loss: 0.053507, loss_s1: 0.049504, loss_fp: 0.002897, loss_freq: 0.031725
[06:49:23.212] iteration 24316: loss: 0.065621, loss_s1: 0.051379, loss_fp: 0.002038, loss_freq: 0.041545
[06:49:24.031] iteration 24317: loss: 0.036798, loss_s1: 0.023397, loss_fp: 0.002382, loss_freq: 0.014016
[06:49:24.674] iteration 24318: loss: 0.048747, loss_s1: 0.044442, loss_fp: 0.005238, loss_freq: 0.016343
[06:49:25.293] iteration 24319: loss: 0.056465, loss_s1: 0.040745, loss_fp: 0.002926, loss_freq: 0.044452
[06:49:25.906] iteration 24320: loss: 0.079649, loss_s1: 0.086608, loss_fp: 0.007094, loss_freq: 0.019386
[06:49:26.521] iteration 24321: loss: 0.059391, loss_s1: 0.060820, loss_fp: 0.002436, loss_freq: 0.022603
[06:49:27.141] iteration 24322: loss: 0.096335, loss_s1: 0.099085, loss_fp: 0.001648, loss_freq: 0.059931
[06:49:27.780] iteration 24323: loss: 0.041086, loss_s1: 0.022002, loss_fp: 0.012854, loss_freq: 0.016674
[06:49:28.388] iteration 24324: loss: 0.062827, loss_s1: 0.052377, loss_fp: 0.003753, loss_freq: 0.044658
[06:49:28.993] iteration 24325: loss: 0.051471, loss_s1: 0.037954, loss_fp: 0.001636, loss_freq: 0.024996
[06:49:29.608] iteration 24326: loss: 0.053106, loss_s1: 0.038389, loss_fp: 0.009401, loss_freq: 0.029330
[06:49:30.225] iteration 24327: loss: 0.104569, loss_s1: 0.106829, loss_fp: 0.004401, loss_freq: 0.076411
[06:49:30.870] iteration 24328: loss: 0.039953, loss_s1: 0.018163, loss_fp: 0.004080, loss_freq: 0.013062
[06:49:31.480] iteration 24329: loss: 0.079354, loss_s1: 0.087035, loss_fp: 0.007506, loss_freq: 0.036443
[06:49:32.089] iteration 24330: loss: 0.042613, loss_s1: 0.030000, loss_fp: 0.001945, loss_freq: 0.017492
[06:49:32.696] iteration 24331: loss: 0.055176, loss_s1: 0.033714, loss_fp: 0.004345, loss_freq: 0.037405
[06:49:33.308] iteration 24332: loss: 0.051488, loss_s1: 0.033177, loss_fp: 0.004115, loss_freq: 0.040855
[06:49:33.921] iteration 24333: loss: 0.077790, loss_s1: 0.063604, loss_fp: 0.005651, loss_freq: 0.045018
[06:49:34.672] iteration 24334: loss: 0.056081, loss_s1: 0.044219, loss_fp: 0.004869, loss_freq: 0.033070
[06:49:35.411] iteration 24335: loss: 0.064669, loss_s1: 0.056559, loss_fp: 0.002286, loss_freq: 0.044376
[06:49:36.039] iteration 24336: loss: 0.048995, loss_s1: 0.041311, loss_fp: 0.004181, loss_freq: 0.028975
[06:49:36.756] iteration 24337: loss: 0.051081, loss_s1: 0.032734, loss_fp: 0.002991, loss_freq: 0.022510
[06:49:37.388] iteration 24338: loss: 0.145744, loss_s1: 0.116560, loss_fp: 0.006908, loss_freq: 0.101244
[06:49:38.003] iteration 24339: loss: 0.073574, loss_s1: 0.083025, loss_fp: 0.005697, loss_freq: 0.031233
[06:49:38.656] iteration 24340: loss: 0.078655, loss_s1: 0.103054, loss_fp: 0.002773, loss_freq: 0.019884
[06:49:39.268] iteration 24341: loss: 0.083855, loss_s1: 0.086204, loss_fp: 0.007732, loss_freq: 0.042818
[06:49:39.878] iteration 24342: loss: 0.058825, loss_s1: 0.032407, loss_fp: 0.003578, loss_freq: 0.042500
[06:49:40.490] iteration 24343: loss: 0.059979, loss_s1: 0.046849, loss_fp: 0.002674, loss_freq: 0.042693
[06:49:41.100] iteration 24344: loss: 0.039003, loss_s1: 0.028069, loss_fp: 0.003930, loss_freq: 0.014220
[06:49:41.710] iteration 24345: loss: 0.067144, loss_s1: 0.059011, loss_fp: 0.003035, loss_freq: 0.047050
[06:49:42.324] iteration 24346: loss: 0.042814, loss_s1: 0.017550, loss_fp: 0.002221, loss_freq: 0.021066
[06:49:42.977] iteration 24347: loss: 0.074422, loss_s1: 0.076229, loss_fp: 0.005265, loss_freq: 0.031489
[06:49:43.634] iteration 24348: loss: 0.042877, loss_s1: 0.036344, loss_fp: 0.002997, loss_freq: 0.019730
[06:49:44.257] iteration 24349: loss: 0.086140, loss_s1: 0.093655, loss_fp: 0.008153, loss_freq: 0.040566
[06:49:44.862] iteration 24350: loss: 0.068081, loss_s1: 0.073355, loss_fp: 0.003170, loss_freq: 0.030900
[06:49:45.469] iteration 24351: loss: 0.059906, loss_s1: 0.045237, loss_fp: 0.003025, loss_freq: 0.032650
[06:49:46.077] iteration 24352: loss: 0.051878, loss_s1: 0.047428, loss_fp: 0.001138, loss_freq: 0.015921
[06:49:46.684] iteration 24353: loss: 0.082883, loss_s1: 0.121176, loss_fp: 0.004200, loss_freq: 0.012879
[06:49:47.292] iteration 24354: loss: 0.084056, loss_s1: 0.092533, loss_fp: 0.001544, loss_freq: 0.052669
[06:49:47.916] iteration 24355: loss: 0.068273, loss_s1: 0.068469, loss_fp: 0.002780, loss_freq: 0.027171
[06:49:48.526] iteration 24356: loss: 0.060010, loss_s1: 0.044832, loss_fp: 0.004548, loss_freq: 0.035880
[06:49:49.133] iteration 24357: loss: 0.059140, loss_s1: 0.047914, loss_fp: 0.009629, loss_freq: 0.031853
[06:49:49.741] iteration 24358: loss: 0.076816, loss_s1: 0.080596, loss_fp: 0.006278, loss_freq: 0.037328
[06:49:50.352] iteration 24359: loss: 0.048042, loss_s1: 0.049923, loss_fp: 0.001213, loss_freq: 0.014950
[06:49:50.958] iteration 24360: loss: 0.034696, loss_s1: 0.022014, loss_fp: 0.000818, loss_freq: 0.008120
[06:49:51.566] iteration 24361: loss: 0.032883, loss_s1: 0.024961, loss_fp: 0.001107, loss_freq: 0.010926
[06:49:52.227] iteration 24362: loss: 0.055478, loss_s1: 0.063939, loss_fp: 0.002288, loss_freq: 0.023066
[06:49:52.884] iteration 24363: loss: 0.048762, loss_s1: 0.043502, loss_fp: 0.002837, loss_freq: 0.016996
[06:49:53.539] iteration 24364: loss: 0.066477, loss_s1: 0.068098, loss_fp: 0.005650, loss_freq: 0.029069
[06:49:54.196] iteration 24365: loss: 0.057131, loss_s1: 0.047529, loss_fp: 0.006552, loss_freq: 0.031099
[06:49:54.842] iteration 24366: loss: 0.055710, loss_s1: 0.044388, loss_fp: 0.003705, loss_freq: 0.033691
[06:49:55.483] iteration 24367: loss: 0.056023, loss_s1: 0.044378, loss_fp: 0.003743, loss_freq: 0.037090
[06:49:56.085] iteration 24368: loss: 0.052001, loss_s1: 0.045054, loss_fp: 0.003234, loss_freq: 0.022052
[06:49:56.691] iteration 24369: loss: 0.056116, loss_s1: 0.029968, loss_fp: 0.006074, loss_freq: 0.044963
[06:49:57.299] iteration 24370: loss: 0.055273, loss_s1: 0.057450, loss_fp: 0.004024, loss_freq: 0.021118
[06:49:57.933] iteration 24371: loss: 0.032290, loss_s1: 0.019991, loss_fp: 0.005454, loss_freq: 0.011436
[06:49:58.553] iteration 24372: loss: 0.046889, loss_s1: 0.037153, loss_fp: 0.004618, loss_freq: 0.017538
[06:49:59.161] iteration 24373: loss: 0.038265, loss_s1: 0.022990, loss_fp: 0.006819, loss_freq: 0.014235
[06:49:59.779] iteration 24374: loss: 0.031568, loss_s1: 0.016806, loss_fp: 0.003905, loss_freq: 0.017033
[06:50:00.392] iteration 24375: loss: 0.050297, loss_s1: 0.047882, loss_fp: 0.004068, loss_freq: 0.011371
[06:50:01.004] iteration 24376: loss: 0.055761, loss_s1: 0.064319, loss_fp: 0.003687, loss_freq: 0.020118
[06:50:01.611] iteration 24377: loss: 0.052847, loss_s1: 0.034531, loss_fp: 0.007759, loss_freq: 0.021652
[06:50:02.212] iteration 24378: loss: 0.084585, loss_s1: 0.081387, loss_fp: 0.010017, loss_freq: 0.047760
[06:50:02.816] iteration 24379: loss: 0.043165, loss_s1: 0.026766, loss_fp: 0.002961, loss_freq: 0.026647
[06:50:03.424] iteration 24380: loss: 0.051478, loss_s1: 0.043173, loss_fp: 0.003989, loss_freq: 0.030535
[06:50:04.032] iteration 24381: loss: 0.071534, loss_s1: 0.047763, loss_fp: 0.003989, loss_freq: 0.053697
[06:50:04.636] iteration 24382: loss: 0.037074, loss_s1: 0.013192, loss_fp: 0.002001, loss_freq: 0.028279
[06:50:05.237] iteration 24383: loss: 0.078353, loss_s1: 0.088378, loss_fp: 0.004634, loss_freq: 0.034568
[06:50:05.840] iteration 24384: loss: 0.061522, loss_s1: 0.059782, loss_fp: 0.010725, loss_freq: 0.019764
[06:50:06.446] iteration 24385: loss: 0.080077, loss_s1: 0.042684, loss_fp: 0.006596, loss_freq: 0.077598
[06:50:07.053] iteration 24386: loss: 0.059742, loss_s1: 0.049344, loss_fp: 0.002666, loss_freq: 0.031015
[06:50:07.658] iteration 24387: loss: 0.055632, loss_s1: 0.038250, loss_fp: 0.010695, loss_freq: 0.028622
[06:50:08.261] iteration 24388: loss: 0.089848, loss_s1: 0.096646, loss_fp: 0.007373, loss_freq: 0.042266
[06:50:08.882] iteration 24389: loss: 0.049359, loss_s1: 0.028939, loss_fp: 0.006976, loss_freq: 0.040615
[06:50:09.525] iteration 24390: loss: 0.057176, loss_s1: 0.040333, loss_fp: 0.004086, loss_freq: 0.030913
[06:50:10.195] iteration 24391: loss: 0.099490, loss_s1: 0.110917, loss_fp: 0.001797, loss_freq: 0.028386
[06:50:10.844] iteration 24392: loss: 0.054622, loss_s1: 0.043634, loss_fp: 0.003950, loss_freq: 0.029735
[06:50:11.523] iteration 24393: loss: 0.071742, loss_s1: 0.072137, loss_fp: 0.006785, loss_freq: 0.035381
[06:50:12.130] iteration 24394: loss: 0.060919, loss_s1: 0.068116, loss_fp: 0.002435, loss_freq: 0.015990
[06:50:12.738] iteration 24395: loss: 0.060310, loss_s1: 0.069845, loss_fp: 0.003191, loss_freq: 0.016820
[06:50:13.345] iteration 24396: loss: 0.054542, loss_s1: 0.040362, loss_fp: 0.006917, loss_freq: 0.030444
[06:50:13.956] iteration 24397: loss: 0.087652, loss_s1: 0.121247, loss_fp: 0.003732, loss_freq: 0.030200
[06:50:14.567] iteration 24398: loss: 0.067253, loss_s1: 0.084934, loss_fp: 0.002281, loss_freq: 0.020271
[06:50:15.177] iteration 24399: loss: 0.071397, loss_s1: 0.068552, loss_fp: 0.002244, loss_freq: 0.043115
[06:50:15.787] iteration 24400: loss: 0.041677, loss_s1: 0.035678, loss_fp: 0.001636, loss_freq: 0.012605
[06:50:19.118] iteration 24400 : mean_dice : 0.741278
[06:50:19.769] iteration 24401: loss: 0.061593, loss_s1: 0.046146, loss_fp: 0.004059, loss_freq: 0.035041
[06:50:20.406] iteration 24402: loss: 0.040921, loss_s1: 0.038360, loss_fp: 0.001402, loss_freq: 0.015218
[06:50:21.023] iteration 24403: loss: 0.055816, loss_s1: 0.056680, loss_fp: 0.005219, loss_freq: 0.013380
[06:50:21.634] iteration 24404: loss: 0.042329, loss_s1: 0.032182, loss_fp: 0.005574, loss_freq: 0.022673
[06:50:22.250] iteration 24405: loss: 0.070023, loss_s1: 0.059678, loss_fp: 0.004046, loss_freq: 0.044263
[06:50:22.865] iteration 24406: loss: 0.069806, loss_s1: 0.071879, loss_fp: 0.005658, loss_freq: 0.034839
[06:50:23.475] iteration 24407: loss: 0.080579, loss_s1: 0.070113, loss_fp: 0.001994, loss_freq: 0.049309
[06:50:24.082] iteration 24408: loss: 0.043095, loss_s1: 0.027762, loss_fp: 0.002200, loss_freq: 0.022313
[06:50:24.689] iteration 24409: loss: 0.049523, loss_s1: 0.046581, loss_fp: 0.001770, loss_freq: 0.023559
[06:50:25.297] iteration 24410: loss: 0.043158, loss_s1: 0.038783, loss_fp: 0.001427, loss_freq: 0.010049
[06:50:25.904] iteration 24411: loss: 0.072548, loss_s1: 0.071387, loss_fp: 0.002524, loss_freq: 0.043810
[06:50:26.518] iteration 24412: loss: 0.041045, loss_s1: 0.027556, loss_fp: 0.001325, loss_freq: 0.011461
[06:50:27.130] iteration 24413: loss: 0.038243, loss_s1: 0.019683, loss_fp: 0.001487, loss_freq: 0.021483
[06:50:27.744] iteration 24414: loss: 0.029041, loss_s1: 0.011204, loss_fp: 0.002105, loss_freq: 0.017241
[06:50:28.360] iteration 24415: loss: 0.026021, loss_s1: 0.014807, loss_fp: 0.002692, loss_freq: 0.006661
[06:50:28.979] iteration 24416: loss: 0.072455, loss_s1: 0.078436, loss_fp: 0.003136, loss_freq: 0.029440
[06:50:29.597] iteration 24417: loss: 0.054771, loss_s1: 0.052302, loss_fp: 0.001113, loss_freq: 0.024494
[06:50:30.213] iteration 24418: loss: 0.040215, loss_s1: 0.024558, loss_fp: 0.006488, loss_freq: 0.020241
[06:50:30.834] iteration 24419: loss: 0.055807, loss_s1: 0.028836, loss_fp: 0.011293, loss_freq: 0.040161
[06:50:31.445] iteration 24420: loss: 0.048113, loss_s1: 0.029568, loss_fp: 0.008907, loss_freq: 0.034053
[06:50:32.086] iteration 24421: loss: 0.065265, loss_s1: 0.028327, loss_fp: 0.010205, loss_freq: 0.054068
[06:50:32.792] iteration 24422: loss: 0.057701, loss_s1: 0.057754, loss_fp: 0.006109, loss_freq: 0.019266
[06:50:33.409] iteration 24423: loss: 0.055611, loss_s1: 0.048997, loss_fp: 0.004143, loss_freq: 0.032284
[06:50:34.023] iteration 24424: loss: 0.026216, loss_s1: 0.021400, loss_fp: 0.003333, loss_freq: 0.006290
[06:50:34.637] iteration 24425: loss: 0.063940, loss_s1: 0.051102, loss_fp: 0.003843, loss_freq: 0.041685
[06:50:35.274] iteration 24426: loss: 0.055339, loss_s1: 0.034165, loss_fp: 0.005338, loss_freq: 0.039900
[06:50:35.883] iteration 24427: loss: 0.088026, loss_s1: 0.100814, loss_fp: 0.004778, loss_freq: 0.038551
[06:50:36.488] iteration 24428: loss: 0.059568, loss_s1: 0.032748, loss_fp: 0.014043, loss_freq: 0.048619
[06:50:37.094] iteration 24429: loss: 0.081916, loss_s1: 0.064937, loss_fp: 0.003443, loss_freq: 0.062810
[06:50:37.718] iteration 24430: loss: 0.043451, loss_s1: 0.039672, loss_fp: 0.004205, loss_freq: 0.009158
[06:50:38.341] iteration 24431: loss: 0.042484, loss_s1: 0.042407, loss_fp: 0.001583, loss_freq: 0.008564
[06:50:38.981] iteration 24432: loss: 0.049858, loss_s1: 0.050603, loss_fp: 0.001855, loss_freq: 0.027587
[06:50:39.591] iteration 24433: loss: 0.087178, loss_s1: 0.074587, loss_fp: 0.009287, loss_freq: 0.058519
[06:50:40.205] iteration 24434: loss: 0.052975, loss_s1: 0.025834, loss_fp: 0.011984, loss_freq: 0.041633
[06:50:40.827] iteration 24435: loss: 0.063648, loss_s1: 0.065314, loss_fp: 0.000897, loss_freq: 0.016807
[06:50:41.436] iteration 24436: loss: 0.065903, loss_s1: 0.075493, loss_fp: 0.002413, loss_freq: 0.025510
[06:50:42.045] iteration 24437: loss: 0.084132, loss_s1: 0.113212, loss_fp: 0.003370, loss_freq: 0.030373
[06:50:42.656] iteration 24438: loss: 0.057187, loss_s1: 0.042550, loss_fp: 0.005516, loss_freq: 0.025005
[06:50:43.264] iteration 24439: loss: 0.034798, loss_s1: 0.029914, loss_fp: 0.003835, loss_freq: 0.008059
[06:50:43.877] iteration 24440: loss: 0.068993, loss_s1: 0.062169, loss_fp: 0.005298, loss_freq: 0.041003
[06:50:44.486] iteration 24441: loss: 0.052772, loss_s1: 0.048872, loss_fp: 0.002709, loss_freq: 0.028975
[06:50:45.106] iteration 24442: loss: 0.073416, loss_s1: 0.068672, loss_fp: 0.013738, loss_freq: 0.020101
[06:50:45.716] iteration 24443: loss: 0.074756, loss_s1: 0.085329, loss_fp: 0.003150, loss_freq: 0.025509
[06:50:46.325] iteration 24444: loss: 0.053206, loss_s1: 0.046688, loss_fp: 0.006701, loss_freq: 0.026683
[06:50:46.938] iteration 24445: loss: 0.041697, loss_s1: 0.036479, loss_fp: 0.003379, loss_freq: 0.010792
[06:50:47.550] iteration 24446: loss: 0.043103, loss_s1: 0.047292, loss_fp: 0.004048, loss_freq: 0.011203
[06:50:48.159] iteration 24447: loss: 0.072493, loss_s1: 0.067598, loss_fp: 0.009668, loss_freq: 0.016046
[06:50:48.766] iteration 24448: loss: 0.058784, loss_s1: 0.061085, loss_fp: 0.004800, loss_freq: 0.014998
[06:50:49.383] iteration 24449: loss: 0.080265, loss_s1: 0.064558, loss_fp: 0.002979, loss_freq: 0.064023
[06:50:49.992] iteration 24450: loss: 0.041827, loss_s1: 0.034922, loss_fp: 0.003687, loss_freq: 0.026119
[06:50:50.601] iteration 24451: loss: 0.066035, loss_s1: 0.071829, loss_fp: 0.004504, loss_freq: 0.020830
[06:50:51.219] iteration 24452: loss: 0.039276, loss_s1: 0.022972, loss_fp: 0.005999, loss_freq: 0.015477
[06:50:51.843] iteration 24453: loss: 0.049808, loss_s1: 0.044947, loss_fp: 0.001960, loss_freq: 0.020140
[06:50:52.476] iteration 24454: loss: 0.059230, loss_s1: 0.065629, loss_fp: 0.002545, loss_freq: 0.017682
[06:50:53.096] iteration 24455: loss: 0.032100, loss_s1: 0.024034, loss_fp: 0.002919, loss_freq: 0.007429
[06:50:53.706] iteration 24456: loss: 0.064302, loss_s1: 0.037260, loss_fp: 0.003318, loss_freq: 0.051938
[06:50:54.319] iteration 24457: loss: 0.040989, loss_s1: 0.024686, loss_fp: 0.004426, loss_freq: 0.021645
[06:50:54.974] iteration 24458: loss: 0.089318, loss_s1: 0.086826, loss_fp: 0.005557, loss_freq: 0.055936
[06:50:55.582] iteration 24459: loss: 0.057817, loss_s1: 0.065982, loss_fp: 0.003145, loss_freq: 0.026512
[06:50:56.192] iteration 24460: loss: 0.049213, loss_s1: 0.034042, loss_fp: 0.002554, loss_freq: 0.031524
[06:50:56.801] iteration 24461: loss: 0.054950, loss_s1: 0.039099, loss_fp: 0.011306, loss_freq: 0.029496
[06:50:57.406] iteration 24462: loss: 0.099610, loss_s1: 0.099574, loss_fp: 0.010622, loss_freq: 0.055479
[06:50:58.012] iteration 24463: loss: 0.051508, loss_s1: 0.041344, loss_fp: 0.009613, loss_freq: 0.024769
[06:50:58.656] iteration 24464: loss: 0.079152, loss_s1: 0.069914, loss_fp: 0.009130, loss_freq: 0.051351
[06:50:59.297] iteration 24465: loss: 0.045495, loss_s1: 0.042159, loss_fp: 0.003409, loss_freq: 0.014311
[06:50:59.902] iteration 24466: loss: 0.024154, loss_s1: 0.011171, loss_fp: 0.001598, loss_freq: 0.005521
[06:51:00.512] iteration 24467: loss: 0.043827, loss_s1: 0.028527, loss_fp: 0.011039, loss_freq: 0.027314
[06:51:01.118] iteration 24468: loss: 0.072582, loss_s1: 0.041571, loss_fp: 0.008893, loss_freq: 0.065630
[06:51:01.729] iteration 24469: loss: 0.069661, loss_s1: 0.072286, loss_fp: 0.007836, loss_freq: 0.027949
[06:51:02.336] iteration 24470: loss: 0.066032, loss_s1: 0.045539, loss_fp: 0.004518, loss_freq: 0.047309
[06:51:02.940] iteration 24471: loss: 0.033679, loss_s1: 0.021961, loss_fp: 0.002575, loss_freq: 0.010358
[06:51:03.548] iteration 24472: loss: 0.061919, loss_s1: 0.056337, loss_fp: 0.003713, loss_freq: 0.040816
[06:51:04.151] iteration 24473: loss: 0.042871, loss_s1: 0.026625, loss_fp: 0.005502, loss_freq: 0.011803
[06:51:04.753] iteration 24474: loss: 0.045729, loss_s1: 0.028017, loss_fp: 0.002939, loss_freq: 0.036683
[06:51:05.356] iteration 24475: loss: 0.049938, loss_s1: 0.041633, loss_fp: 0.001703, loss_freq: 0.023489
[06:51:05.957] iteration 24476: loss: 0.042575, loss_s1: 0.042102, loss_fp: 0.006573, loss_freq: 0.011913
[06:51:06.652] iteration 24477: loss: 0.065268, loss_s1: 0.036265, loss_fp: 0.004094, loss_freq: 0.057635
[06:51:07.334] iteration 24478: loss: 0.077072, loss_s1: 0.059697, loss_fp: 0.015167, loss_freq: 0.048361
[06:51:07.940] iteration 24479: loss: 0.092151, loss_s1: 0.094353, loss_fp: 0.001114, loss_freq: 0.052925
[06:51:08.546] iteration 24480: loss: 0.055536, loss_s1: 0.056821, loss_fp: 0.002009, loss_freq: 0.016609
[06:51:09.462] iteration 24481: loss: 0.101532, loss_s1: 0.108941, loss_fp: 0.002020, loss_freq: 0.059267
[06:51:10.070] iteration 24482: loss: 0.054231, loss_s1: 0.043636, loss_fp: 0.004505, loss_freq: 0.027165
[06:51:10.689] iteration 24483: loss: 0.058589, loss_s1: 0.053644, loss_fp: 0.002654, loss_freq: 0.034959
[06:51:11.308] iteration 24484: loss: 0.039218, loss_s1: 0.033303, loss_fp: 0.003590, loss_freq: 0.014126
[06:51:11.929] iteration 24485: loss: 0.044334, loss_s1: 0.024213, loss_fp: 0.006079, loss_freq: 0.022085
[06:51:12.557] iteration 24486: loss: 0.073999, loss_s1: 0.079942, loss_fp: 0.013813, loss_freq: 0.020206
[06:51:13.169] iteration 24487: loss: 0.045276, loss_s1: 0.032201, loss_fp: 0.002213, loss_freq: 0.025541
[06:51:13.788] iteration 24488: loss: 0.036159, loss_s1: 0.026627, loss_fp: 0.002618, loss_freq: 0.017282
[06:51:14.405] iteration 24489: loss: 0.031796, loss_s1: 0.022526, loss_fp: 0.001566, loss_freq: 0.017091
[06:51:15.012] iteration 24490: loss: 0.097313, loss_s1: 0.130944, loss_fp: 0.006526, loss_freq: 0.027025
[06:51:15.624] iteration 24491: loss: 0.045357, loss_s1: 0.033170, loss_fp: 0.003310, loss_freq: 0.024456
[06:51:16.281] iteration 24492: loss: 0.093200, loss_s1: 0.090484, loss_fp: 0.004555, loss_freq: 0.061274
[06:51:16.967] iteration 24493: loss: 0.043517, loss_s1: 0.033726, loss_fp: 0.002406, loss_freq: 0.021430
[06:51:17.631] iteration 24494: loss: 0.094209, loss_s1: 0.120036, loss_fp: 0.005162, loss_freq: 0.021310
[06:51:18.334] iteration 24495: loss: 0.045605, loss_s1: 0.024406, loss_fp: 0.002167, loss_freq: 0.033206
[06:51:19.014] iteration 24496: loss: 0.067262, loss_s1: 0.040751, loss_fp: 0.009610, loss_freq: 0.048085
[06:51:19.687] iteration 24497: loss: 0.062208, loss_s1: 0.066111, loss_fp: 0.003181, loss_freq: 0.035326
[06:51:20.353] iteration 24498: loss: 0.050872, loss_s1: 0.048939, loss_fp: 0.002701, loss_freq: 0.018847
[06:51:21.013] iteration 24499: loss: 0.107043, loss_s1: 0.131089, loss_fp: 0.014400, loss_freq: 0.042332
[06:51:21.688] iteration 24500: loss: 0.051658, loss_s1: 0.041847, loss_fp: 0.001414, loss_freq: 0.026582
[06:51:22.322] iteration 24501: loss: 0.036310, loss_s1: 0.015787, loss_fp: 0.006743, loss_freq: 0.018028
[06:51:22.980] iteration 24502: loss: 0.064181, loss_s1: 0.055593, loss_fp: 0.006153, loss_freq: 0.041018
[06:51:23.589] iteration 24503: loss: 0.074274, loss_s1: 0.050857, loss_fp: 0.003393, loss_freq: 0.040554
[06:51:24.208] iteration 24504: loss: 0.055204, loss_s1: 0.041526, loss_fp: 0.001989, loss_freq: 0.034660
[06:51:24.820] iteration 24505: loss: 0.074673, loss_s1: 0.041278, loss_fp: 0.009391, loss_freq: 0.067732
[06:51:25.440] iteration 24506: loss: 0.085614, loss_s1: 0.103458, loss_fp: 0.006859, loss_freq: 0.037334
[06:51:26.053] iteration 24507: loss: 0.048908, loss_s1: 0.017088, loss_fp: 0.004921, loss_freq: 0.017078
[06:51:26.662] iteration 24508: loss: 0.077786, loss_s1: 0.074952, loss_fp: 0.008875, loss_freq: 0.023428
[06:51:27.271] iteration 24509: loss: 0.047424, loss_s1: 0.037388, loss_fp: 0.005786, loss_freq: 0.019969
[06:51:27.885] iteration 24510: loss: 0.099742, loss_s1: 0.100462, loss_fp: 0.010146, loss_freq: 0.049712
[06:51:28.502] iteration 24511: loss: 0.064889, loss_s1: 0.042960, loss_fp: 0.002708, loss_freq: 0.062734
[06:51:29.122] iteration 24512: loss: 0.089687, loss_s1: 0.083226, loss_fp: 0.013156, loss_freq: 0.041867
[06:51:29.735] iteration 24513: loss: 0.071463, loss_s1: 0.078303, loss_fp: 0.005444, loss_freq: 0.023073
[06:51:30.344] iteration 24514: loss: 0.044313, loss_s1: 0.028303, loss_fp: 0.004106, loss_freq: 0.021710
[06:51:30.962] iteration 24515: loss: 0.049224, loss_s1: 0.052382, loss_fp: 0.006142, loss_freq: 0.018351
[06:51:31.576] iteration 24516: loss: 0.049886, loss_s1: 0.035418, loss_fp: 0.008797, loss_freq: 0.015060
[06:51:32.250] iteration 24517: loss: 0.069973, loss_s1: 0.047412, loss_fp: 0.003289, loss_freq: 0.052918
[06:51:32.924] iteration 24518: loss: 0.044512, loss_s1: 0.028559, loss_fp: 0.005062, loss_freq: 0.022429
[06:51:33.573] iteration 24519: loss: 0.069079, loss_s1: 0.047312, loss_fp: 0.004131, loss_freq: 0.053479
[06:51:34.205] iteration 24520: loss: 0.057453, loss_s1: 0.057931, loss_fp: 0.005445, loss_freq: 0.028026
[06:51:34.820] iteration 24521: loss: 0.049225, loss_s1: 0.042126, loss_fp: 0.002615, loss_freq: 0.010579
[06:51:35.431] iteration 24522: loss: 0.057634, loss_s1: 0.052290, loss_fp: 0.004880, loss_freq: 0.028545
[06:51:36.052] iteration 24523: loss: 0.061007, loss_s1: 0.071145, loss_fp: 0.003107, loss_freq: 0.024986
[06:51:36.673] iteration 24524: loss: 0.068917, loss_s1: 0.080643, loss_fp: 0.003509, loss_freq: 0.033615
[06:51:37.296] iteration 24525: loss: 0.057016, loss_s1: 0.036087, loss_fp: 0.005788, loss_freq: 0.037473
[06:51:37.911] iteration 24526: loss: 0.057460, loss_s1: 0.058527, loss_fp: 0.004978, loss_freq: 0.018448
[06:51:38.521] iteration 24527: loss: 0.043022, loss_s1: 0.030923, loss_fp: 0.002066, loss_freq: 0.023202
[06:51:39.145] iteration 24528: loss: 0.063130, loss_s1: 0.033438, loss_fp: 0.004553, loss_freq: 0.061395
[06:51:39.780] iteration 24529: loss: 0.063437, loss_s1: 0.072094, loss_fp: 0.001887, loss_freq: 0.014566
[06:51:40.403] iteration 24530: loss: 0.051002, loss_s1: 0.041701, loss_fp: 0.000996, loss_freq: 0.009391
[06:51:41.335] iteration 24531: loss: 0.059499, loss_s1: 0.046477, loss_fp: 0.011802, loss_freq: 0.024729
[06:51:42.092] iteration 24532: loss: 0.065874, loss_s1: 0.080211, loss_fp: 0.004037, loss_freq: 0.021672
[06:51:42.713] iteration 24533: loss: 0.065905, loss_s1: 0.072992, loss_fp: 0.001097, loss_freq: 0.015822
[06:51:43.352] iteration 24534: loss: 0.054213, loss_s1: 0.045861, loss_fp: 0.007573, loss_freq: 0.025653
[06:51:43.956] iteration 24535: loss: 0.043364, loss_s1: 0.016544, loss_fp: 0.009422, loss_freq: 0.019050
[06:51:44.600] iteration 24536: loss: 0.042383, loss_s1: 0.029950, loss_fp: 0.003877, loss_freq: 0.019933
[06:51:45.204] iteration 24537: loss: 0.076052, loss_s1: 0.050772, loss_fp: 0.005540, loss_freq: 0.072131
[06:51:45.815] iteration 24538: loss: 0.047262, loss_s1: 0.019574, loss_fp: 0.006981, loss_freq: 0.028142
[06:51:46.423] iteration 24539: loss: 0.051305, loss_s1: 0.030483, loss_fp: 0.000882, loss_freq: 0.041160
[06:51:47.035] iteration 24540: loss: 0.058592, loss_s1: 0.056318, loss_fp: 0.001788, loss_freq: 0.030798
[06:51:47.652] iteration 24541: loss: 0.026203, loss_s1: 0.016658, loss_fp: 0.002621, loss_freq: 0.011182
[06:51:48.278] iteration 24542: loss: 0.081541, loss_s1: 0.048886, loss_fp: 0.002343, loss_freq: 0.050111
[06:51:48.893] iteration 24543: loss: 0.051655, loss_s1: 0.039666, loss_fp: 0.001440, loss_freq: 0.029592
[06:51:49.506] iteration 24544: loss: 0.048860, loss_s1: 0.047674, loss_fp: 0.001083, loss_freq: 0.019963
[06:51:50.117] iteration 24545: loss: 0.047540, loss_s1: 0.042878, loss_fp: 0.002663, loss_freq: 0.013481
[06:51:50.730] iteration 24546: loss: 0.043510, loss_s1: 0.027357, loss_fp: 0.001635, loss_freq: 0.034295
[06:51:51.346] iteration 24547: loss: 0.046324, loss_s1: 0.029474, loss_fp: 0.002966, loss_freq: 0.006296
[06:51:51.959] iteration 24548: loss: 0.099495, loss_s1: 0.089211, loss_fp: 0.016832, loss_freq: 0.064484
[06:51:52.574] iteration 24549: loss: 0.036505, loss_s1: 0.017565, loss_fp: 0.004360, loss_freq: 0.024164
[06:51:53.190] iteration 24550: loss: 0.043895, loss_s1: 0.030770, loss_fp: 0.003618, loss_freq: 0.029302
[06:51:53.817] iteration 24551: loss: 0.055993, loss_s1: 0.046426, loss_fp: 0.003468, loss_freq: 0.027538
[06:51:54.435] iteration 24552: loss: 0.061655, loss_s1: 0.047726, loss_fp: 0.002415, loss_freq: 0.044177
[06:51:55.044] iteration 24553: loss: 0.074021, loss_s1: 0.068976, loss_fp: 0.009267, loss_freq: 0.042378
[06:51:55.664] iteration 24554: loss: 0.079478, loss_s1: 0.098601, loss_fp: 0.005291, loss_freq: 0.025732
[06:51:56.278] iteration 24555: loss: 0.047966, loss_s1: 0.030295, loss_fp: 0.003589, loss_freq: 0.035985
[06:51:56.890] iteration 24556: loss: 0.075741, loss_s1: 0.066777, loss_fp: 0.004973, loss_freq: 0.037982
[06:51:57.503] iteration 24557: loss: 0.055495, loss_s1: 0.050364, loss_fp: 0.003135, loss_freq: 0.020188
[06:51:58.115] iteration 24558: loss: 0.083793, loss_s1: 0.085548, loss_fp: 0.006165, loss_freq: 0.040413
[06:51:58.724] iteration 24559: loss: 0.048400, loss_s1: 0.047287, loss_fp: 0.006574, loss_freq: 0.017594
[06:51:59.331] iteration 24560: loss: 0.040903, loss_s1: 0.030964, loss_fp: 0.001312, loss_freq: 0.015939
[06:51:59.938] iteration 24561: loss: 0.063526, loss_s1: 0.073310, loss_fp: 0.003392, loss_freq: 0.006780
[06:52:00.571] iteration 24562: loss: 0.058453, loss_s1: 0.039184, loss_fp: 0.003257, loss_freq: 0.037107
[06:52:01.222] iteration 24563: loss: 0.053774, loss_s1: 0.048905, loss_fp: 0.001984, loss_freq: 0.027088
[06:52:01.870] iteration 24564: loss: 0.039003, loss_s1: 0.023781, loss_fp: 0.007275, loss_freq: 0.017744
[06:52:02.529] iteration 24565: loss: 0.053844, loss_s1: 0.050410, loss_fp: 0.004222, loss_freq: 0.022294
[06:52:03.175] iteration 24566: loss: 0.065276, loss_s1: 0.050554, loss_fp: 0.003037, loss_freq: 0.035046
[06:52:03.778] iteration 24567: loss: 0.037807, loss_s1: 0.028652, loss_fp: 0.007275, loss_freq: 0.013634
[06:52:04.439] iteration 24568: loss: 0.069256, loss_s1: 0.050661, loss_fp: 0.006921, loss_freq: 0.025925
[06:52:05.078] iteration 24569: loss: 0.052728, loss_s1: 0.036074, loss_fp: 0.001992, loss_freq: 0.036541
[06:52:05.765] iteration 24570: loss: 0.036819, loss_s1: 0.026223, loss_fp: 0.002374, loss_freq: 0.006111
[06:52:06.418] iteration 24571: loss: 0.063124, loss_s1: 0.047279, loss_fp: 0.010922, loss_freq: 0.038961
[06:52:07.053] iteration 24572: loss: 0.049792, loss_s1: 0.037064, loss_fp: 0.002400, loss_freq: 0.038160
[06:52:07.671] iteration 24573: loss: 0.050867, loss_s1: 0.037587, loss_fp: 0.001190, loss_freq: 0.022914
[06:52:08.290] iteration 24574: loss: 0.048369, loss_s1: 0.045204, loss_fp: 0.001414, loss_freq: 0.022341
[06:52:08.915] iteration 24575: loss: 0.049486, loss_s1: 0.046418, loss_fp: 0.006513, loss_freq: 0.015056
[06:52:09.528] iteration 24576: loss: 0.038647, loss_s1: 0.024984, loss_fp: 0.001524, loss_freq: 0.026002
[06:52:10.138] iteration 24577: loss: 0.058630, loss_s1: 0.058424, loss_fp: 0.004166, loss_freq: 0.026244
[06:52:10.759] iteration 24578: loss: 0.059163, loss_s1: 0.044094, loss_fp: 0.004041, loss_freq: 0.038772
[06:52:11.365] iteration 24579: loss: 0.048785, loss_s1: 0.051993, loss_fp: 0.002470, loss_freq: 0.018980
[06:52:11.979] iteration 24580: loss: 0.039167, loss_s1: 0.033044, loss_fp: 0.001126, loss_freq: 0.011469
[06:52:12.583] iteration 24581: loss: 0.056712, loss_s1: 0.059996, loss_fp: 0.003482, loss_freq: 0.023875
[06:52:13.197] iteration 24582: loss: 0.038183, loss_s1: 0.021516, loss_fp: 0.001466, loss_freq: 0.018971
[06:52:13.803] iteration 24583: loss: 0.029722, loss_s1: 0.013327, loss_fp: 0.002969, loss_freq: 0.016920
[06:52:14.416] iteration 24584: loss: 0.032989, loss_s1: 0.023638, loss_fp: 0.002612, loss_freq: 0.012592
[06:52:15.043] iteration 24585: loss: 0.040596, loss_s1: 0.023955, loss_fp: 0.004284, loss_freq: 0.029864
[06:52:15.659] iteration 24586: loss: 0.047806, loss_s1: 0.034967, loss_fp: 0.002716, loss_freq: 0.022338
[06:52:16.269] iteration 24587: loss: 0.050454, loss_s1: 0.023464, loss_fp: 0.008090, loss_freq: 0.019750
[06:52:16.899] iteration 24588: loss: 0.043410, loss_s1: 0.028960, loss_fp: 0.003312, loss_freq: 0.025026
[06:52:17.532] iteration 24589: loss: 0.039638, loss_s1: 0.022006, loss_fp: 0.003763, loss_freq: 0.019189
[06:52:18.142] iteration 24590: loss: 0.047569, loss_s1: 0.035190, loss_fp: 0.003420, loss_freq: 0.027309
[06:52:18.751] iteration 24591: loss: 0.036588, loss_s1: 0.020688, loss_fp: 0.002764, loss_freq: 0.017030
[06:52:19.359] iteration 24592: loss: 0.057110, loss_s1: 0.043791, loss_fp: 0.006555, loss_freq: 0.028908
[06:52:19.972] iteration 24593: loss: 0.042726, loss_s1: 0.026265, loss_fp: 0.004917, loss_freq: 0.031488
[06:52:20.652] iteration 24594: loss: 0.026932, loss_s1: 0.008840, loss_fp: 0.002039, loss_freq: 0.021571
[06:52:21.318] iteration 24595: loss: 0.077864, loss_s1: 0.086489, loss_fp: 0.007358, loss_freq: 0.031171
[06:52:21.937] iteration 24596: loss: 0.085350, loss_s1: 0.038279, loss_fp: 0.009122, loss_freq: 0.080290
[06:52:22.552] iteration 24597: loss: 0.069878, loss_s1: 0.087895, loss_fp: 0.001836, loss_freq: 0.017922
[06:52:23.177] iteration 24598: loss: 0.067640, loss_s1: 0.056825, loss_fp: 0.009828, loss_freq: 0.040380
[06:52:23.798] iteration 24599: loss: 0.058601, loss_s1: 0.050039, loss_fp: 0.002524, loss_freq: 0.035792
[06:52:24.418] iteration 24600: loss: 0.044778, loss_s1: 0.033964, loss_fp: 0.004653, loss_freq: 0.016199
[06:52:28.011] iteration 24600 : mean_dice : 0.749334
[06:52:28.680] iteration 24601: loss: 0.047521, loss_s1: 0.045520, loss_fp: 0.004221, loss_freq: 0.009882
[06:52:29.341] iteration 24602: loss: 0.063058, loss_s1: 0.047672, loss_fp: 0.007429, loss_freq: 0.050163
[06:52:30.010] iteration 24603: loss: 0.119228, loss_s1: 0.086816, loss_fp: 0.008737, loss_freq: 0.109439
[06:52:30.670] iteration 24604: loss: 0.077590, loss_s1: 0.062533, loss_fp: 0.001880, loss_freq: 0.058392
[06:52:31.334] iteration 24605: loss: 0.066002, loss_s1: 0.059181, loss_fp: 0.001357, loss_freq: 0.028758
[06:52:31.975] iteration 24606: loss: 0.044322, loss_s1: 0.031011, loss_fp: 0.008299, loss_freq: 0.017190
[06:52:32.586] iteration 24607: loss: 0.044363, loss_s1: 0.024096, loss_fp: 0.005027, loss_freq: 0.036165
[06:52:33.196] iteration 24608: loss: 0.041258, loss_s1: 0.019063, loss_fp: 0.004764, loss_freq: 0.013197
[06:52:33.839] iteration 24609: loss: 0.049471, loss_s1: 0.029128, loss_fp: 0.003099, loss_freq: 0.036347
[06:52:34.456] iteration 24610: loss: 0.047815, loss_s1: 0.039023, loss_fp: 0.002682, loss_freq: 0.022284
[06:52:35.070] iteration 24611: loss: 0.050000, loss_s1: 0.067503, loss_fp: 0.003125, loss_freq: 0.008199
[06:52:35.697] iteration 24612: loss: 0.069817, loss_s1: 0.077946, loss_fp: 0.004597, loss_freq: 0.018834
[06:52:36.311] iteration 24613: loss: 0.066041, loss_s1: 0.041216, loss_fp: 0.006647, loss_freq: 0.052875
[06:52:36.930] iteration 24614: loss: 0.066899, loss_s1: 0.061190, loss_fp: 0.006047, loss_freq: 0.038029
[06:52:37.542] iteration 24615: loss: 0.045287, loss_s1: 0.041573, loss_fp: 0.000649, loss_freq: 0.015284
[06:52:38.152] iteration 24616: loss: 0.034934, loss_s1: 0.031925, loss_fp: 0.002662, loss_freq: 0.010275
[06:52:38.763] iteration 24617: loss: 0.045550, loss_s1: 0.027801, loss_fp: 0.002551, loss_freq: 0.016552
[06:52:39.376] iteration 24618: loss: 0.059221, loss_s1: 0.040472, loss_fp: 0.006531, loss_freq: 0.048392
[06:52:39.996] iteration 24619: loss: 0.137387, loss_s1: 0.140661, loss_fp: 0.003375, loss_freq: 0.088145
[06:52:40.609] iteration 24620: loss: 0.062164, loss_s1: 0.067035, loss_fp: 0.009460, loss_freq: 0.025868
[06:52:41.221] iteration 24621: loss: 0.060701, loss_s1: 0.050457, loss_fp: 0.002986, loss_freq: 0.035413
[06:52:41.834] iteration 24622: loss: 0.054169, loss_s1: 0.038426, loss_fp: 0.006028, loss_freq: 0.022067
[06:52:42.446] iteration 24623: loss: 0.053850, loss_s1: 0.048371, loss_fp: 0.007426, loss_freq: 0.020302
[06:52:43.061] iteration 24624: loss: 0.059758, loss_s1: 0.054108, loss_fp: 0.000977, loss_freq: 0.033471
[06:52:43.673] iteration 24625: loss: 0.048933, loss_s1: 0.050413, loss_fp: 0.007941, loss_freq: 0.012280
[06:52:44.290] iteration 24626: loss: 0.053715, loss_s1: 0.026441, loss_fp: 0.002294, loss_freq: 0.041541
[06:52:44.903] iteration 24627: loss: 0.050393, loss_s1: 0.037004, loss_fp: 0.005672, loss_freq: 0.014310
[06:52:45.518] iteration 24628: loss: 0.062427, loss_s1: 0.073583, loss_fp: 0.003214, loss_freq: 0.022013
[06:52:46.128] iteration 24629: loss: 0.051960, loss_s1: 0.026763, loss_fp: 0.012416, loss_freq: 0.041451
[06:52:46.747] iteration 24630: loss: 0.055514, loss_s1: 0.046480, loss_fp: 0.006096, loss_freq: 0.027365
[06:52:47.359] iteration 24631: loss: 0.067935, loss_s1: 0.060560, loss_fp: 0.006441, loss_freq: 0.035179
[06:52:47.970] iteration 24632: loss: 0.064152, loss_s1: 0.062872, loss_fp: 0.015779, loss_freq: 0.020309
[06:52:48.592] iteration 24633: loss: 0.073143, loss_s1: 0.076226, loss_fp: 0.003643, loss_freq: 0.035284
[06:52:49.200] iteration 24634: loss: 0.063038, loss_s1: 0.038457, loss_fp: 0.005258, loss_freq: 0.055601
[06:52:49.810] iteration 24635: loss: 0.067458, loss_s1: 0.047146, loss_fp: 0.005871, loss_freq: 0.040033
[06:52:50.420] iteration 24636: loss: 0.054939, loss_s1: 0.058745, loss_fp: 0.001057, loss_freq: 0.018316
[06:52:51.046] iteration 24637: loss: 0.039644, loss_s1: 0.030254, loss_fp: 0.001052, loss_freq: 0.014515
[06:52:51.650] iteration 24638: loss: 0.085297, loss_s1: 0.052470, loss_fp: 0.002932, loss_freq: 0.085899
[06:52:52.258] iteration 24639: loss: 0.046933, loss_s1: 0.031393, loss_fp: 0.006072, loss_freq: 0.023030
[06:52:52.861] iteration 24640: loss: 0.072290, loss_s1: 0.069325, loss_fp: 0.005363, loss_freq: 0.031129
[06:52:53.466] iteration 24641: loss: 0.046172, loss_s1: 0.051410, loss_fp: 0.000896, loss_freq: 0.008522
[06:52:54.072] iteration 24642: loss: 0.039095, loss_s1: 0.023482, loss_fp: 0.003872, loss_freq: 0.028651
[06:52:54.684] iteration 24643: loss: 0.040820, loss_s1: 0.025505, loss_fp: 0.000476, loss_freq: 0.011383
[06:52:55.311] iteration 24644: loss: 0.035230, loss_s1: 0.024255, loss_fp: 0.001435, loss_freq: 0.019181
[06:52:55.923] iteration 24645: loss: 0.038470, loss_s1: 0.023251, loss_fp: 0.001169, loss_freq: 0.018037
[06:52:56.584] iteration 24646: loss: 0.040564, loss_s1: 0.030853, loss_fp: 0.002311, loss_freq: 0.018396
[06:52:57.240] iteration 24647: loss: 0.045245, loss_s1: 0.037004, loss_fp: 0.003026, loss_freq: 0.020667
[06:52:57.896] iteration 24648: loss: 0.088188, loss_s1: 0.093439, loss_fp: 0.005732, loss_freq: 0.042026
[06:52:58.551] iteration 24649: loss: 0.078776, loss_s1: 0.080801, loss_fp: 0.005872, loss_freq: 0.045779
[06:52:59.203] iteration 24650: loss: 0.073645, loss_s1: 0.088792, loss_fp: 0.003135, loss_freq: 0.024157
[06:53:00.198] iteration 24651: loss: 0.057473, loss_s1: 0.064835, loss_fp: 0.000572, loss_freq: 0.020119
[06:53:00.807] iteration 24652: loss: 0.050866, loss_s1: 0.032246, loss_fp: 0.004759, loss_freq: 0.034941
[06:53:01.423] iteration 24653: loss: 0.060496, loss_s1: 0.069382, loss_fp: 0.004130, loss_freq: 0.020044
[06:53:02.033] iteration 24654: loss: 0.040888, loss_s1: 0.032455, loss_fp: 0.001730, loss_freq: 0.013083
[06:53:02.649] iteration 24655: loss: 0.051541, loss_s1: 0.051507, loss_fp: 0.006892, loss_freq: 0.013590
[06:53:03.268] iteration 24656: loss: 0.049043, loss_s1: 0.043778, loss_fp: 0.006846, loss_freq: 0.017179
[06:53:03.884] iteration 24657: loss: 0.050828, loss_s1: 0.051595, loss_fp: 0.005049, loss_freq: 0.018616
[06:53:04.505] iteration 24658: loss: 0.051563, loss_s1: 0.045408, loss_fp: 0.005136, loss_freq: 0.026448
[06:53:05.123] iteration 24659: loss: 0.040681, loss_s1: 0.029714, loss_fp: 0.001578, loss_freq: 0.010510
[06:53:05.738] iteration 24660: loss: 0.064611, loss_s1: 0.055266, loss_fp: 0.002144, loss_freq: 0.030808
[06:53:06.350] iteration 24661: loss: 0.073174, loss_s1: 0.082839, loss_fp: 0.010385, loss_freq: 0.021504
[06:53:07.041] iteration 24662: loss: 0.073930, loss_s1: 0.070131, loss_fp: 0.001706, loss_freq: 0.044951
[06:53:07.700] iteration 24663: loss: 0.057282, loss_s1: 0.044083, loss_fp: 0.006008, loss_freq: 0.035254
[06:53:08.359] iteration 24664: loss: 0.055825, loss_s1: 0.044242, loss_fp: 0.003640, loss_freq: 0.034079
[06:53:08.987] iteration 24665: loss: 0.054588, loss_s1: 0.049611, loss_fp: 0.004372, loss_freq: 0.023173
[06:53:09.602] iteration 24666: loss: 0.047303, loss_s1: 0.042680, loss_fp: 0.002361, loss_freq: 0.021922
[06:53:10.210] iteration 24667: loss: 0.085317, loss_s1: 0.067770, loss_fp: 0.012880, loss_freq: 0.065638
[06:53:10.821] iteration 24668: loss: 0.031925, loss_s1: 0.012773, loss_fp: 0.001824, loss_freq: 0.019201
[06:53:11.428] iteration 24669: loss: 0.068141, loss_s1: 0.062167, loss_fp: 0.007071, loss_freq: 0.034971
[06:53:12.038] iteration 24670: loss: 0.051069, loss_s1: 0.055494, loss_fp: 0.004101, loss_freq: 0.009995
[06:53:12.650] iteration 24671: loss: 0.054796, loss_s1: 0.029471, loss_fp: 0.001601, loss_freq: 0.047619
[06:53:13.258] iteration 24672: loss: 0.052778, loss_s1: 0.027509, loss_fp: 0.003811, loss_freq: 0.044742
[06:53:13.875] iteration 24673: loss: 0.055024, loss_s1: 0.028733, loss_fp: 0.004434, loss_freq: 0.036964
[06:53:14.490] iteration 24674: loss: 0.052246, loss_s1: 0.057467, loss_fp: 0.002588, loss_freq: 0.022226
[06:53:15.109] iteration 24675: loss: 0.052718, loss_s1: 0.043369, loss_fp: 0.010080, loss_freq: 0.025521
[06:53:15.728] iteration 24676: loss: 0.063171, loss_s1: 0.071982, loss_fp: 0.004383, loss_freq: 0.022987
[06:53:16.345] iteration 24677: loss: 0.052891, loss_s1: 0.026459, loss_fp: 0.002215, loss_freq: 0.017691
[06:53:16.961] iteration 24678: loss: 0.063622, loss_s1: 0.036205, loss_fp: 0.005364, loss_freq: 0.050857
[06:53:17.573] iteration 24679: loss: 0.058009, loss_s1: 0.011258, loss_fp: 0.003795, loss_freq: 0.043436
[06:53:18.232] iteration 24680: loss: 0.076178, loss_s1: 0.083189, loss_fp: 0.005763, loss_freq: 0.030656
[06:53:18.897] iteration 24681: loss: 0.066025, loss_s1: 0.033709, loss_fp: 0.003525, loss_freq: 0.071773
[06:53:19.518] iteration 24682: loss: 0.066277, loss_s1: 0.037087, loss_fp: 0.004399, loss_freq: 0.052659
[06:53:20.122] iteration 24683: loss: 0.050365, loss_s1: 0.038276, loss_fp: 0.004275, loss_freq: 0.028371
[06:53:20.729] iteration 24684: loss: 0.049852, loss_s1: 0.030803, loss_fp: 0.004831, loss_freq: 0.027784
[06:53:21.342] iteration 24685: loss: 0.046290, loss_s1: 0.034719, loss_fp: 0.004395, loss_freq: 0.030310
[06:53:21.998] iteration 24686: loss: 0.066663, loss_s1: 0.066107, loss_fp: 0.001231, loss_freq: 0.030756
[06:53:22.656] iteration 24687: loss: 0.049039, loss_s1: 0.029023, loss_fp: 0.008224, loss_freq: 0.030337
[06:53:23.319] iteration 24688: loss: 0.057317, loss_s1: 0.068836, loss_fp: 0.002181, loss_freq: 0.017166
[06:53:23.948] iteration 24689: loss: 0.074480, loss_s1: 0.074328, loss_fp: 0.005045, loss_freq: 0.036498
[06:53:24.559] iteration 24690: loss: 0.097881, loss_s1: 0.108945, loss_fp: 0.002077, loss_freq: 0.047181
[06:53:25.167] iteration 24691: loss: 0.072833, loss_s1: 0.088140, loss_fp: 0.002202, loss_freq: 0.023450
[06:53:25.774] iteration 24692: loss: 0.048461, loss_s1: 0.040501, loss_fp: 0.002387, loss_freq: 0.018346
[06:53:26.385] iteration 24693: loss: 0.095813, loss_s1: 0.123384, loss_fp: 0.002052, loss_freq: 0.041789
[06:53:26.996] iteration 24694: loss: 0.077983, loss_s1: 0.066553, loss_fp: 0.005165, loss_freq: 0.060259
[06:53:27.606] iteration 24695: loss: 0.051024, loss_s1: 0.030728, loss_fp: 0.002849, loss_freq: 0.031872
[06:53:28.235] iteration 24696: loss: 0.054246, loss_s1: 0.035678, loss_fp: 0.004028, loss_freq: 0.027514
[06:53:28.875] iteration 24697: loss: 0.053352, loss_s1: 0.052172, loss_fp: 0.003542, loss_freq: 0.016490
[06:53:29.479] iteration 24698: loss: 0.063172, loss_s1: 0.053650, loss_fp: 0.002584, loss_freq: 0.040187
[06:53:30.081] iteration 24699: loss: 0.059884, loss_s1: 0.073538, loss_fp: 0.004525, loss_freq: 0.010378
[06:53:30.687] iteration 24700: loss: 0.036152, loss_s1: 0.028457, loss_fp: 0.001236, loss_freq: 0.012219
[06:53:31.293] iteration 24701: loss: 0.039775, loss_s1: 0.022672, loss_fp: 0.000904, loss_freq: 0.012438
[06:53:31.898] iteration 24702: loss: 0.058630, loss_s1: 0.044869, loss_fp: 0.006373, loss_freq: 0.044861
[06:53:32.501] iteration 24703: loss: 0.030391, loss_s1: 0.008577, loss_fp: 0.004017, loss_freq: 0.014222
[06:53:33.113] iteration 24704: loss: 0.053346, loss_s1: 0.040144, loss_fp: 0.009296, loss_freq: 0.029482
[06:53:33.722] iteration 24705: loss: 0.061332, loss_s1: 0.050335, loss_fp: 0.005325, loss_freq: 0.033644
[06:53:34.341] iteration 24706: loss: 0.063463, loss_s1: 0.069360, loss_fp: 0.006123, loss_freq: 0.021941
[06:53:34.951] iteration 24707: loss: 0.062180, loss_s1: 0.063780, loss_fp: 0.010184, loss_freq: 0.027537
[06:53:35.566] iteration 24708: loss: 0.041865, loss_s1: 0.016587, loss_fp: 0.001877, loss_freq: 0.017186
[06:53:36.173] iteration 24709: loss: 0.045524, loss_s1: 0.022182, loss_fp: 0.001660, loss_freq: 0.039327
[06:53:36.788] iteration 24710: loss: 0.048556, loss_s1: 0.027532, loss_fp: 0.000909, loss_freq: 0.040856
[06:53:37.404] iteration 24711: loss: 0.026813, loss_s1: 0.022687, loss_fp: 0.004967, loss_freq: 0.003144
[06:53:38.016] iteration 24712: loss: 0.065741, loss_s1: 0.059105, loss_fp: 0.007746, loss_freq: 0.032510
[06:53:38.635] iteration 24713: loss: 0.040175, loss_s1: 0.032038, loss_fp: 0.002434, loss_freq: 0.011166
[06:53:39.250] iteration 24714: loss: 0.035476, loss_s1: 0.024529, loss_fp: 0.001949, loss_freq: 0.011256
[06:53:39.860] iteration 24715: loss: 0.083445, loss_s1: 0.115238, loss_fp: 0.003684, loss_freq: 0.013532
[06:53:40.465] iteration 24716: loss: 0.059663, loss_s1: 0.060000, loss_fp: 0.004466, loss_freq: 0.032529
[06:53:41.072] iteration 24717: loss: 0.039123, loss_s1: 0.012856, loss_fp: 0.005807, loss_freq: 0.023339
[06:53:41.691] iteration 24718: loss: 0.107123, loss_s1: 0.145635, loss_fp: 0.011802, loss_freq: 0.032072
[06:53:42.308] iteration 24719: loss: 0.042106, loss_s1: 0.038549, loss_fp: 0.001521, loss_freq: 0.016678
[06:53:42.935] iteration 24720: loss: 0.039274, loss_s1: 0.037062, loss_fp: 0.002026, loss_freq: 0.009325
[06:53:43.767] iteration 24721: loss: 0.072823, loss_s1: 0.039445, loss_fp: 0.006704, loss_freq: 0.056388
[06:53:44.672] iteration 24722: loss: 0.071022, loss_s1: 0.063993, loss_fp: 0.004953, loss_freq: 0.040992
[06:53:45.439] iteration 24723: loss: 0.065537, loss_s1: 0.058344, loss_fp: 0.013073, loss_freq: 0.030344
[06:53:46.159] iteration 24724: loss: 0.062035, loss_s1: 0.069453, loss_fp: 0.005936, loss_freq: 0.015982
[06:53:46.769] iteration 24725: loss: 0.058969, loss_s1: 0.033118, loss_fp: 0.002994, loss_freq: 0.050194
[06:53:47.379] iteration 24726: loss: 0.044370, loss_s1: 0.024870, loss_fp: 0.005234, loss_freq: 0.025276
[06:53:47.988] iteration 24727: loss: 0.049683, loss_s1: 0.048248, loss_fp: 0.003096, loss_freq: 0.016272
[06:53:48.601] iteration 24728: loss: 0.079861, loss_s1: 0.069482, loss_fp: 0.004490, loss_freq: 0.033304
[06:53:49.215] iteration 24729: loss: 0.067680, loss_s1: 0.061908, loss_fp: 0.010801, loss_freq: 0.040887
[06:53:49.820] iteration 24730: loss: 0.049792, loss_s1: 0.037372, loss_fp: 0.004098, loss_freq: 0.016134
[06:53:50.431] iteration 24731: loss: 0.058252, loss_s1: 0.060126, loss_fp: 0.003941, loss_freq: 0.014225
[06:53:51.051] iteration 24732: loss: 0.049889, loss_s1: 0.037106, loss_fp: 0.004828, loss_freq: 0.028141
[06:53:51.656] iteration 24733: loss: 0.081765, loss_s1: 0.108391, loss_fp: 0.003922, loss_freq: 0.023418
[06:53:52.268] iteration 24734: loss: 0.056485, loss_s1: 0.052960, loss_fp: 0.007499, loss_freq: 0.015308
[06:53:52.876] iteration 24735: loss: 0.040760, loss_s1: 0.019712, loss_fp: 0.002756, loss_freq: 0.017805
[06:53:53.486] iteration 24736: loss: 0.045444, loss_s1: 0.025660, loss_fp: 0.002545, loss_freq: 0.024213
[06:53:54.104] iteration 24737: loss: 0.063459, loss_s1: 0.059317, loss_fp: 0.007751, loss_freq: 0.026244
[06:53:54.771] iteration 24738: loss: 0.063422, loss_s1: 0.051991, loss_fp: 0.007350, loss_freq: 0.030816
[06:53:55.383] iteration 24739: loss: 0.074189, loss_s1: 0.058508, loss_fp: 0.006874, loss_freq: 0.055949
[06:53:56.013] iteration 24740: loss: 0.061705, loss_s1: 0.065737, loss_fp: 0.003076, loss_freq: 0.019424
[06:53:56.625] iteration 24741: loss: 0.044854, loss_s1: 0.038521, loss_fp: 0.003489, loss_freq: 0.018220
[06:53:57.235] iteration 24742: loss: 0.061288, loss_s1: 0.060695, loss_fp: 0.006882, loss_freq: 0.026885
[06:53:57.844] iteration 24743: loss: 0.071122, loss_s1: 0.078202, loss_fp: 0.003139, loss_freq: 0.026639
[06:53:58.482] iteration 24744: loss: 0.048862, loss_s1: 0.033452, loss_fp: 0.002812, loss_freq: 0.037503
[06:53:59.093] iteration 24745: loss: 0.065789, loss_s1: 0.081406, loss_fp: 0.006768, loss_freq: 0.016761
[06:53:59.703] iteration 24746: loss: 0.048286, loss_s1: 0.042568, loss_fp: 0.003508, loss_freq: 0.029593
[06:54:00.315] iteration 24747: loss: 0.061450, loss_s1: 0.056081, loss_fp: 0.001660, loss_freq: 0.027955
[06:54:00.933] iteration 24748: loss: 0.054723, loss_s1: 0.045297, loss_fp: 0.004964, loss_freq: 0.023633
[06:54:01.550] iteration 24749: loss: 0.076837, loss_s1: 0.047119, loss_fp: 0.002796, loss_freq: 0.068543
[06:54:02.164] iteration 24750: loss: 0.054234, loss_s1: 0.042681, loss_fp: 0.002078, loss_freq: 0.023096
[06:54:02.780] iteration 24751: loss: 0.078586, loss_s1: 0.071142, loss_fp: 0.002738, loss_freq: 0.049703
[06:54:03.395] iteration 24752: loss: 0.045142, loss_s1: 0.021083, loss_fp: 0.001878, loss_freq: 0.012355
[06:54:04.018] iteration 24753: loss: 0.036216, loss_s1: 0.026383, loss_fp: 0.001331, loss_freq: 0.015136
[06:54:04.623] iteration 24754: loss: 0.044942, loss_s1: 0.044015, loss_fp: 0.002186, loss_freq: 0.015513
[06:54:05.324] iteration 24755: loss: 0.036929, loss_s1: 0.019385, loss_fp: 0.008342, loss_freq: 0.022501
[06:54:06.029] iteration 24756: loss: 0.076960, loss_s1: 0.078824, loss_fp: 0.007190, loss_freq: 0.031689
[06:54:06.749] iteration 24757: loss: 0.050986, loss_s1: 0.042008, loss_fp: 0.003007, loss_freq: 0.022435
[06:54:07.423] iteration 24758: loss: 0.038960, loss_s1: 0.029302, loss_fp: 0.003554, loss_freq: 0.017608
[06:54:08.101] iteration 24759: loss: 0.058459, loss_s1: 0.035362, loss_fp: 0.007939, loss_freq: 0.041407
[06:54:08.750] iteration 24760: loss: 0.049569, loss_s1: 0.032340, loss_fp: 0.004609, loss_freq: 0.032492
[06:54:09.378] iteration 24761: loss: 0.082919, loss_s1: 0.106032, loss_fp: 0.003377, loss_freq: 0.015882
[06:54:10.023] iteration 24762: loss: 0.058104, loss_s1: 0.060629, loss_fp: 0.001544, loss_freq: 0.023101
[06:54:10.900] iteration 24763: loss: 0.047527, loss_s1: 0.036605, loss_fp: 0.004637, loss_freq: 0.027716
[06:54:11.518] iteration 24764: loss: 0.031011, loss_s1: 0.022332, loss_fp: 0.005229, loss_freq: 0.012552
[06:54:12.259] iteration 24765: loss: 0.049701, loss_s1: 0.019744, loss_fp: 0.001140, loss_freq: 0.046665
[06:54:12.974] iteration 24766: loss: 0.082432, loss_s1: 0.043012, loss_fp: 0.007180, loss_freq: 0.075047
[06:54:13.647] iteration 24767: loss: 0.055801, loss_s1: 0.049938, loss_fp: 0.004829, loss_freq: 0.026854
[06:54:14.335] iteration 24768: loss: 0.057960, loss_s1: 0.053109, loss_fp: 0.004481, loss_freq: 0.031563
[06:54:14.986] iteration 24769: loss: 0.047766, loss_s1: 0.027324, loss_fp: 0.008808, loss_freq: 0.032761
[06:54:15.761] iteration 24770: loss: 0.058842, loss_s1: 0.029837, loss_fp: 0.003398, loss_freq: 0.044106
[06:54:16.519] iteration 24771: loss: 0.031427, loss_s1: 0.016496, loss_fp: 0.004002, loss_freq: 0.010300
[06:54:17.216] iteration 24772: loss: 0.069322, loss_s1: 0.079133, loss_fp: 0.004552, loss_freq: 0.037268
[06:54:17.875] iteration 24773: loss: 0.074871, loss_s1: 0.056404, loss_fp: 0.012831, loss_freq: 0.053501
[06:54:18.485] iteration 24774: loss: 0.034422, loss_s1: 0.013456, loss_fp: 0.001419, loss_freq: 0.027691
[06:54:19.099] iteration 24775: loss: 0.048904, loss_s1: 0.015271, loss_fp: 0.013879, loss_freq: 0.036005
[06:54:19.723] iteration 24776: loss: 0.051010, loss_s1: 0.040887, loss_fp: 0.003403, loss_freq: 0.029588
[06:54:20.352] iteration 24777: loss: 0.055168, loss_s1: 0.065573, loss_fp: 0.002850, loss_freq: 0.022554
[06:54:21.046] iteration 24778: loss: 0.043213, loss_s1: 0.019675, loss_fp: 0.000619, loss_freq: 0.032973
[06:54:21.688] iteration 24779: loss: 0.051443, loss_s1: 0.053339, loss_fp: 0.002467, loss_freq: 0.022873
[06:54:22.295] iteration 24780: loss: 0.062876, loss_s1: 0.044762, loss_fp: 0.003193, loss_freq: 0.044485
[06:54:22.902] iteration 24781: loss: 0.076696, loss_s1: 0.115134, loss_fp: 0.003058, loss_freq: 0.006458
[06:54:23.538] iteration 24782: loss: 0.050792, loss_s1: 0.041370, loss_fp: 0.001455, loss_freq: 0.012204
[06:54:24.144] iteration 24783: loss: 0.059134, loss_s1: 0.054670, loss_fp: 0.007175, loss_freq: 0.024155
[06:54:24.752] iteration 24784: loss: 0.051376, loss_s1: 0.050009, loss_fp: 0.005994, loss_freq: 0.018708
[06:54:25.363] iteration 24785: loss: 0.041049, loss_s1: 0.019306, loss_fp: 0.004768, loss_freq: 0.025926
[06:54:25.973] iteration 24786: loss: 0.040877, loss_s1: 0.026045, loss_fp: 0.003127, loss_freq: 0.021841
[06:54:26.584] iteration 24787: loss: 0.081307, loss_s1: 0.085301, loss_fp: 0.005498, loss_freq: 0.023643
[06:54:27.193] iteration 24788: loss: 0.041822, loss_s1: 0.033510, loss_fp: 0.004382, loss_freq: 0.018769
[06:54:27.804] iteration 24789: loss: 0.075386, loss_s1: 0.078608, loss_fp: 0.005566, loss_freq: 0.037532
[06:54:28.420] iteration 24790: loss: 0.049754, loss_s1: 0.041092, loss_fp: 0.002278, loss_freq: 0.029969
[06:54:29.028] iteration 24791: loss: 0.061185, loss_s1: 0.056389, loss_fp: 0.004814, loss_freq: 0.025148
[06:54:29.630] iteration 24792: loss: 0.051513, loss_s1: 0.056195, loss_fp: 0.001433, loss_freq: 0.014676
[06:54:30.235] iteration 24793: loss: 0.076022, loss_s1: 0.058521, loss_fp: 0.005903, loss_freq: 0.035441
[06:54:30.838] iteration 24794: loss: 0.054462, loss_s1: 0.051736, loss_fp: 0.002599, loss_freq: 0.019618
[06:54:31.448] iteration 24795: loss: 0.061093, loss_s1: 0.053775, loss_fp: 0.020867, loss_freq: 0.021644
[06:54:32.052] iteration 24796: loss: 0.067028, loss_s1: 0.051682, loss_fp: 0.002459, loss_freq: 0.048644
[06:54:32.791] iteration 24797: loss: 0.056181, loss_s1: 0.049583, loss_fp: 0.001945, loss_freq: 0.024155
[06:54:33.690] iteration 24798: loss: 0.101314, loss_s1: 0.158412, loss_fp: 0.002333, loss_freq: 0.013080
[06:54:34.548] iteration 24799: loss: 0.067354, loss_s1: 0.085865, loss_fp: 0.003259, loss_freq: 0.023308
[06:54:35.194] iteration 24800: loss: 0.064338, loss_s1: 0.059973, loss_fp: 0.003302, loss_freq: 0.029547
[06:54:38.560] iteration 24800 : mean_dice : 0.745292
[06:54:39.205] iteration 24801: loss: 0.075000, loss_s1: 0.037855, loss_fp: 0.015719, loss_freq: 0.065300
[06:54:39.821] iteration 24802: loss: 0.067413, loss_s1: 0.069081, loss_fp: 0.003190, loss_freq: 0.034143
[06:54:40.432] iteration 24803: loss: 0.088594, loss_s1: 0.046477, loss_fp: 0.011932, loss_freq: 0.082087
[06:54:41.043] iteration 24804: loss: 0.059940, loss_s1: 0.052336, loss_fp: 0.003467, loss_freq: 0.037147
[06:54:41.651] iteration 24805: loss: 0.085601, loss_s1: 0.076315, loss_fp: 0.003307, loss_freq: 0.050472
[06:54:42.267] iteration 24806: loss: 0.073326, loss_s1: 0.086365, loss_fp: 0.004693, loss_freq: 0.020722
[06:54:42.874] iteration 24807: loss: 0.028972, loss_s1: 0.016949, loss_fp: 0.002982, loss_freq: 0.010982
[06:54:43.482] iteration 24808: loss: 0.073626, loss_s1: 0.064892, loss_fp: 0.004585, loss_freq: 0.051988
[06:54:44.090] iteration 24809: loss: 0.051450, loss_s1: 0.046011, loss_fp: 0.004287, loss_freq: 0.025414
[06:54:44.701] iteration 24810: loss: 0.063163, loss_s1: 0.038512, loss_fp: 0.007108, loss_freq: 0.044004
[06:54:45.347] iteration 24811: loss: 0.036185, loss_s1: 0.029311, loss_fp: 0.004425, loss_freq: 0.005995
[06:54:46.006] iteration 24812: loss: 0.051426, loss_s1: 0.047961, loss_fp: 0.003473, loss_freq: 0.025780
[06:54:46.679] iteration 24813: loss: 0.038637, loss_s1: 0.025257, loss_fp: 0.001929, loss_freq: 0.015982
[06:54:47.363] iteration 24814: loss: 0.067459, loss_s1: 0.062950, loss_fp: 0.004168, loss_freq: 0.043796
[06:54:47.983] iteration 24815: loss: 0.037400, loss_s1: 0.024389, loss_fp: 0.000988, loss_freq: 0.018854
[06:54:48.600] iteration 24816: loss: 0.051221, loss_s1: 0.036550, loss_fp: 0.006997, loss_freq: 0.038047
[06:54:49.221] iteration 24817: loss: 0.085607, loss_s1: 0.066734, loss_fp: 0.008059, loss_freq: 0.049281
[06:54:49.838] iteration 24818: loss: 0.075152, loss_s1: 0.094461, loss_fp: 0.001162, loss_freq: 0.024447
[06:54:50.446] iteration 24819: loss: 0.070155, loss_s1: 0.060415, loss_fp: 0.008971, loss_freq: 0.043575
[06:54:51.054] iteration 24820: loss: 0.057384, loss_s1: 0.059675, loss_fp: 0.008394, loss_freq: 0.016024
[06:54:52.047] iteration 24821: loss: 0.070306, loss_s1: 0.049271, loss_fp: 0.008149, loss_freq: 0.048038
[06:54:52.663] iteration 24822: loss: 0.058131, loss_s1: 0.052145, loss_fp: 0.002525, loss_freq: 0.030217
[06:54:53.301] iteration 24823: loss: 0.075577, loss_s1: 0.089678, loss_fp: 0.007044, loss_freq: 0.029863
[06:54:53.916] iteration 24824: loss: 0.050269, loss_s1: 0.049886, loss_fp: 0.005813, loss_freq: 0.013437
[06:54:54.531] iteration 24825: loss: 0.049123, loss_s1: 0.045917, loss_fp: 0.002240, loss_freq: 0.020403
[06:54:55.151] iteration 24826: loss: 0.050519, loss_s1: 0.052285, loss_fp: 0.003821, loss_freq: 0.017070
[06:54:55.767] iteration 24827: loss: 0.044589, loss_s1: 0.026575, loss_fp: 0.003463, loss_freq: 0.024523
[06:54:56.426] iteration 24828: loss: 0.062795, loss_s1: 0.070556, loss_fp: 0.005115, loss_freq: 0.023436
[06:54:57.089] iteration 24829: loss: 0.028989, loss_s1: 0.022124, loss_fp: 0.003510, loss_freq: 0.009947
[06:54:57.708] iteration 24830: loss: 0.047453, loss_s1: 0.030971, loss_fp: 0.003903, loss_freq: 0.025119
[06:54:58.324] iteration 24831: loss: 0.050619, loss_s1: 0.058921, loss_fp: 0.003807, loss_freq: 0.009218
[06:54:58.937] iteration 24832: loss: 0.083962, loss_s1: 0.092652, loss_fp: 0.008144, loss_freq: 0.039099
[06:54:59.556] iteration 24833: loss: 0.046595, loss_s1: 0.041835, loss_fp: 0.004479, loss_freq: 0.019485
[06:55:00.171] iteration 24834: loss: 0.040985, loss_s1: 0.029184, loss_fp: 0.003374, loss_freq: 0.019685
[06:55:00.783] iteration 24835: loss: 0.048685, loss_s1: 0.040621, loss_fp: 0.002055, loss_freq: 0.009273
[06:55:01.395] iteration 24836: loss: 0.067647, loss_s1: 0.055297, loss_fp: 0.003403, loss_freq: 0.043093
[06:55:02.014] iteration 24837: loss: 0.093999, loss_s1: 0.109008, loss_fp: 0.002251, loss_freq: 0.057798
[06:55:02.627] iteration 24838: loss: 0.053004, loss_s1: 0.050992, loss_fp: 0.001244, loss_freq: 0.008497
[06:55:03.272] iteration 24839: loss: 0.079529, loss_s1: 0.101792, loss_fp: 0.004326, loss_freq: 0.023449
[06:55:03.890] iteration 24840: loss: 0.050497, loss_s1: 0.042232, loss_fp: 0.005047, loss_freq: 0.019909
[06:55:04.510] iteration 24841: loss: 0.051930, loss_s1: 0.048264, loss_fp: 0.004624, loss_freq: 0.019254
[06:55:05.161] iteration 24842: loss: 0.062160, loss_s1: 0.024350, loss_fp: 0.009712, loss_freq: 0.067663
[06:55:05.774] iteration 24843: loss: 0.035436, loss_s1: 0.011694, loss_fp: 0.004860, loss_freq: 0.019158
[06:55:06.385] iteration 24844: loss: 0.047168, loss_s1: 0.030546, loss_fp: 0.001562, loss_freq: 0.021036
[06:55:07.001] iteration 24845: loss: 0.061599, loss_s1: 0.068385, loss_fp: 0.003210, loss_freq: 0.019685
[06:55:07.625] iteration 24846: loss: 0.066079, loss_s1: 0.059162, loss_fp: 0.003022, loss_freq: 0.034899
[06:55:08.253] iteration 24847: loss: 0.072957, loss_s1: 0.055295, loss_fp: 0.004103, loss_freq: 0.051628
[06:55:08.864] iteration 24848: loss: 0.088978, loss_s1: 0.080655, loss_fp: 0.012372, loss_freq: 0.050126
[06:55:09.520] iteration 24849: loss: 0.038809, loss_s1: 0.021089, loss_fp: 0.003632, loss_freq: 0.028411
[06:55:10.127] iteration 24850: loss: 0.074368, loss_s1: 0.087827, loss_fp: 0.007267, loss_freq: 0.019811
[06:55:10.736] iteration 24851: loss: 0.050682, loss_s1: 0.029692, loss_fp: 0.006064, loss_freq: 0.039365
[06:55:11.359] iteration 24852: loss: 0.082246, loss_s1: 0.069098, loss_fp: 0.003721, loss_freq: 0.039274
[06:55:11.973] iteration 24853: loss: 0.085572, loss_s1: 0.101266, loss_fp: 0.006418, loss_freq: 0.033135
[06:55:12.599] iteration 24854: loss: 0.034498, loss_s1: 0.020302, loss_fp: 0.004155, loss_freq: 0.008667
[06:55:13.209] iteration 24855: loss: 0.042516, loss_s1: 0.036046, loss_fp: 0.000775, loss_freq: 0.029676
[06:55:13.820] iteration 24856: loss: 0.044536, loss_s1: 0.029413, loss_fp: 0.002269, loss_freq: 0.016361
[06:55:14.433] iteration 24857: loss: 0.060360, loss_s1: 0.044941, loss_fp: 0.005958, loss_freq: 0.040734
[06:55:15.049] iteration 24858: loss: 0.099815, loss_s1: 0.141274, loss_fp: 0.008693, loss_freq: 0.022493
[06:55:15.656] iteration 24859: loss: 0.091148, loss_s1: 0.103696, loss_fp: 0.006093, loss_freq: 0.037697
[06:55:16.264] iteration 24860: loss: 0.064007, loss_s1: 0.042878, loss_fp: 0.016924, loss_freq: 0.032584
[06:55:16.872] iteration 24861: loss: 0.072169, loss_s1: 0.075926, loss_fp: 0.004058, loss_freq: 0.026996
[06:55:17.490] iteration 24862: loss: 0.087402, loss_s1: 0.096939, loss_fp: 0.004057, loss_freq: 0.036702
[06:55:18.100] iteration 24863: loss: 0.076268, loss_s1: 0.071645, loss_fp: 0.006030, loss_freq: 0.042280
[06:55:18.710] iteration 24864: loss: 0.155179, loss_s1: 0.200024, loss_fp: 0.011580, loss_freq: 0.076607
[06:55:19.389] iteration 24865: loss: 0.064039, loss_s1: 0.058282, loss_fp: 0.002061, loss_freq: 0.032719
[06:55:20.052] iteration 24866: loss: 0.064236, loss_s1: 0.062313, loss_fp: 0.003504, loss_freq: 0.034622
[06:55:20.707] iteration 24867: loss: 0.040720, loss_s1: 0.028762, loss_fp: 0.003331, loss_freq: 0.017517
[06:55:21.358] iteration 24868: loss: 0.064815, loss_s1: 0.040627, loss_fp: 0.005370, loss_freq: 0.056660
[06:55:22.010] iteration 24869: loss: 0.035566, loss_s1: 0.023330, loss_fp: 0.000985, loss_freq: 0.013544
[06:55:22.670] iteration 24870: loss: 0.044634, loss_s1: 0.022104, loss_fp: 0.007476, loss_freq: 0.020613
[06:55:23.292] iteration 24871: loss: 0.048565, loss_s1: 0.044163, loss_fp: 0.002817, loss_freq: 0.019883
[06:55:23.914] iteration 24872: loss: 0.074652, loss_s1: 0.061245, loss_fp: 0.002634, loss_freq: 0.064001
[06:55:24.531] iteration 24873: loss: 0.049519, loss_s1: 0.024760, loss_fp: 0.002640, loss_freq: 0.034964
[06:55:25.149] iteration 24874: loss: 0.083058, loss_s1: 0.114906, loss_fp: 0.001281, loss_freq: 0.019403
[06:55:25.762] iteration 24875: loss: 0.050117, loss_s1: 0.033874, loss_fp: 0.006520, loss_freq: 0.030419
[06:55:26.375] iteration 24876: loss: 0.059409, loss_s1: 0.053472, loss_fp: 0.001012, loss_freq: 0.032116
[06:55:27.017] iteration 24877: loss: 0.055301, loss_s1: 0.038354, loss_fp: 0.003502, loss_freq: 0.041865
[06:55:27.637] iteration 24878: loss: 0.034614, loss_s1: 0.008238, loss_fp: 0.001728, loss_freq: 0.017739
[06:55:28.262] iteration 24879: loss: 0.039169, loss_s1: 0.021612, loss_fp: 0.001069, loss_freq: 0.032468
[06:55:28.878] iteration 24880: loss: 0.056039, loss_s1: 0.050652, loss_fp: 0.002550, loss_freq: 0.027517
[06:55:29.491] iteration 24881: loss: 0.032901, loss_s1: 0.033025, loss_fp: 0.000921, loss_freq: 0.006487
[06:55:30.103] iteration 24882: loss: 0.058807, loss_s1: 0.028184, loss_fp: 0.003196, loss_freq: 0.052408
[06:55:30.710] iteration 24883: loss: 0.060610, loss_s1: 0.060715, loss_fp: 0.003333, loss_freq: 0.023204
[06:55:31.318] iteration 24884: loss: 0.033515, loss_s1: 0.016778, loss_fp: 0.001487, loss_freq: 0.025257
[06:55:31.925] iteration 24885: loss: 0.079473, loss_s1: 0.123248, loss_fp: 0.000494, loss_freq: 0.007680
[06:55:32.531] iteration 24886: loss: 0.039813, loss_s1: 0.024927, loss_fp: 0.001921, loss_freq: 0.028682
[06:55:33.135] iteration 24887: loss: 0.037931, loss_s1: 0.017403, loss_fp: 0.000583, loss_freq: 0.010867
[06:55:33.740] iteration 24888: loss: 0.070862, loss_s1: 0.057960, loss_fp: 0.006256, loss_freq: 0.050868
[06:55:34.374] iteration 24889: loss: 0.044767, loss_s1: 0.025538, loss_fp: 0.003772, loss_freq: 0.027730
[06:55:34.992] iteration 24890: loss: 0.032779, loss_s1: 0.021666, loss_fp: 0.001285, loss_freq: 0.018582
[06:55:35.606] iteration 24891: loss: 0.078624, loss_s1: 0.055177, loss_fp: 0.011995, loss_freq: 0.060704
[06:55:36.219] iteration 24892: loss: 0.060927, loss_s1: 0.046516, loss_fp: 0.001418, loss_freq: 0.039323
[06:55:36.830] iteration 24893: loss: 0.055686, loss_s1: 0.047324, loss_fp: 0.010585, loss_freq: 0.021253
[06:55:37.468] iteration 24894: loss: 0.043605, loss_s1: 0.026228, loss_fp: 0.003971, loss_freq: 0.017989
[06:55:38.132] iteration 24895: loss: 0.049895, loss_s1: 0.024440, loss_fp: 0.003731, loss_freq: 0.046173
[06:55:38.756] iteration 24896: loss: 0.059404, loss_s1: 0.055868, loss_fp: 0.008284, loss_freq: 0.022772
[06:55:39.369] iteration 24897: loss: 0.058069, loss_s1: 0.044249, loss_fp: 0.005751, loss_freq: 0.035197
[06:55:39.980] iteration 24898: loss: 0.057712, loss_s1: 0.046335, loss_fp: 0.002673, loss_freq: 0.038261
[06:55:40.596] iteration 24899: loss: 0.048835, loss_s1: 0.044932, loss_fp: 0.005166, loss_freq: 0.023542
[06:55:41.218] iteration 24900: loss: 0.062455, loss_s1: 0.035897, loss_fp: 0.001740, loss_freq: 0.034117
[06:55:41.839] iteration 24901: loss: 0.051378, loss_s1: 0.048814, loss_fp: 0.002116, loss_freq: 0.014258
[06:55:42.461] iteration 24902: loss: 0.054937, loss_s1: 0.038653, loss_fp: 0.005418, loss_freq: 0.033037
[06:55:43.080] iteration 24903: loss: 0.051970, loss_s1: 0.043447, loss_fp: 0.003358, loss_freq: 0.031590
[06:55:43.694] iteration 24904: loss: 0.038473, loss_s1: 0.032210, loss_fp: 0.007066, loss_freq: 0.009350
[06:55:44.309] iteration 24905: loss: 0.069507, loss_s1: 0.062663, loss_fp: 0.004950, loss_freq: 0.025889
[06:55:44.933] iteration 24906: loss: 0.069969, loss_s1: 0.045466, loss_fp: 0.004281, loss_freq: 0.038942
[06:55:45.551] iteration 24907: loss: 0.086280, loss_s1: 0.123462, loss_fp: 0.002890, loss_freq: 0.025027
[06:55:46.171] iteration 24908: loss: 0.047041, loss_s1: 0.036409, loss_fp: 0.003696, loss_freq: 0.023215
[06:55:46.792] iteration 24909: loss: 0.067381, loss_s1: 0.076350, loss_fp: 0.002519, loss_freq: 0.025792
[06:55:47.405] iteration 24910: loss: 0.034987, loss_s1: 0.021611, loss_fp: 0.006394, loss_freq: 0.007364
[06:55:48.021] iteration 24911: loss: 0.059010, loss_s1: 0.049060, loss_fp: 0.005202, loss_freq: 0.028048
[06:55:48.652] iteration 24912: loss: 0.061166, loss_s1: 0.069439, loss_fp: 0.003810, loss_freq: 0.024431
[06:55:49.321] iteration 24913: loss: 0.074082, loss_s1: 0.076812, loss_fp: 0.003790, loss_freq: 0.029223
[06:55:50.031] iteration 24914: loss: 0.063983, loss_s1: 0.050803, loss_fp: 0.003467, loss_freq: 0.032139
[06:55:50.767] iteration 24915: loss: 0.082919, loss_s1: 0.086337, loss_fp: 0.008775, loss_freq: 0.037302
[06:55:51.464] iteration 24916: loss: 0.041703, loss_s1: 0.026661, loss_fp: 0.001506, loss_freq: 0.028452
[06:55:52.108] iteration 24917: loss: 0.077795, loss_s1: 0.056654, loss_fp: 0.006315, loss_freq: 0.061144
[06:55:52.724] iteration 24918: loss: 0.062977, loss_s1: 0.017812, loss_fp: 0.004916, loss_freq: 0.059897
[06:55:53.335] iteration 24919: loss: 0.074216, loss_s1: 0.058231, loss_fp: 0.004161, loss_freq: 0.050691
[06:55:53.943] iteration 24920: loss: 0.054171, loss_s1: 0.033146, loss_fp: 0.003787, loss_freq: 0.032704
[06:55:54.555] iteration 24921: loss: 0.063774, loss_s1: 0.060945, loss_fp: 0.003429, loss_freq: 0.034938
[06:55:55.165] iteration 24922: loss: 0.060259, loss_s1: 0.028872, loss_fp: 0.007703, loss_freq: 0.044861
[06:55:55.781] iteration 24923: loss: 0.035451, loss_s1: 0.016833, loss_fp: 0.002460, loss_freq: 0.025326
[06:55:56.390] iteration 24924: loss: 0.040899, loss_s1: 0.036146, loss_fp: 0.005487, loss_freq: 0.015459
[06:55:57.047] iteration 24925: loss: 0.043432, loss_s1: 0.044183, loss_fp: 0.006328, loss_freq: 0.016141
[06:55:57.702] iteration 24926: loss: 0.057753, loss_s1: 0.041107, loss_fp: 0.003174, loss_freq: 0.019570
[06:55:58.303] iteration 24927: loss: 0.038544, loss_s1: 0.022195, loss_fp: 0.003105, loss_freq: 0.021072
[06:55:58.955] iteration 24928: loss: 0.044322, loss_s1: 0.046724, loss_fp: 0.000634, loss_freq: 0.013768
[06:55:59.572] iteration 24929: loss: 0.065530, loss_s1: 0.032072, loss_fp: 0.004931, loss_freq: 0.065918
[06:56:00.207] iteration 24930: loss: 0.077952, loss_s1: 0.056805, loss_fp: 0.010703, loss_freq: 0.057900
[06:56:00.814] iteration 24931: loss: 0.062799, loss_s1: 0.071298, loss_fp: 0.004163, loss_freq: 0.022362
[06:56:01.426] iteration 24932: loss: 0.063628, loss_s1: 0.075356, loss_fp: 0.002500, loss_freq: 0.021305
[06:56:02.040] iteration 24933: loss: 0.067809, loss_s1: 0.073199, loss_fp: 0.003112, loss_freq: 0.036689
[06:56:02.653] iteration 24934: loss: 0.030415, loss_s1: 0.019748, loss_fp: 0.002870, loss_freq: 0.015727
[06:56:03.265] iteration 24935: loss: 0.072087, loss_s1: 0.057804, loss_fp: 0.004886, loss_freq: 0.049446
[06:56:03.878] iteration 24936: loss: 0.082797, loss_s1: 0.053961, loss_fp: 0.008219, loss_freq: 0.066701
[06:56:04.514] iteration 24937: loss: 0.105558, loss_s1: 0.116636, loss_fp: 0.009547, loss_freq: 0.026918
[06:56:05.123] iteration 24938: loss: 0.045213, loss_s1: 0.041698, loss_fp: 0.005543, loss_freq: 0.015404
[06:56:05.743] iteration 24939: loss: 0.067775, loss_s1: 0.049009, loss_fp: 0.002736, loss_freq: 0.035553
[06:56:06.350] iteration 24940: loss: 0.047927, loss_s1: 0.043738, loss_fp: 0.002098, loss_freq: 0.016985
[06:56:06.981] iteration 24941: loss: 0.039166, loss_s1: 0.016251, loss_fp: 0.002299, loss_freq: 0.024921
[06:56:07.601] iteration 24942: loss: 0.053034, loss_s1: 0.050823, loss_fp: 0.006799, loss_freq: 0.028331
[06:56:08.212] iteration 24943: loss: 0.051547, loss_s1: 0.028005, loss_fp: 0.002907, loss_freq: 0.030668
[06:56:08.830] iteration 24944: loss: 0.037469, loss_s1: 0.009132, loss_fp: 0.007461, loss_freq: 0.021579
[06:56:09.435] iteration 24945: loss: 0.071416, loss_s1: 0.044520, loss_fp: 0.002822, loss_freq: 0.058037
[06:56:10.040] iteration 24946: loss: 0.063730, loss_s1: 0.069957, loss_fp: 0.002636, loss_freq: 0.021683
[06:56:10.653] iteration 24947: loss: 0.044585, loss_s1: 0.047931, loss_fp: 0.003061, loss_freq: 0.018000
[06:56:11.260] iteration 24948: loss: 0.062808, loss_s1: 0.039133, loss_fp: 0.009119, loss_freq: 0.043759
[06:56:11.865] iteration 24949: loss: 0.090567, loss_s1: 0.071210, loss_fp: 0.018003, loss_freq: 0.059155
[06:56:12.471] iteration 24950: loss: 0.067219, loss_s1: 0.048129, loss_fp: 0.009648, loss_freq: 0.043821
[06:56:13.086] iteration 24951: loss: 0.052005, loss_s1: 0.035953, loss_fp: 0.008298, loss_freq: 0.036655
[06:56:13.746] iteration 24952: loss: 0.061904, loss_s1: 0.070728, loss_fp: 0.002823, loss_freq: 0.018551
[06:56:14.417] iteration 24953: loss: 0.082496, loss_s1: 0.079134, loss_fp: 0.011496, loss_freq: 0.029658
[06:56:15.086] iteration 24954: loss: 0.063898, loss_s1: 0.080928, loss_fp: 0.004438, loss_freq: 0.014357
[06:56:15.743] iteration 24955: loss: 0.044905, loss_s1: 0.025055, loss_fp: 0.001925, loss_freq: 0.028369
[06:56:16.406] iteration 24956: loss: 0.045447, loss_s1: 0.048296, loss_fp: 0.003809, loss_freq: 0.014369
[06:56:17.061] iteration 24957: loss: 0.081401, loss_s1: 0.099490, loss_fp: 0.000766, loss_freq: 0.025043
[06:56:17.716] iteration 24958: loss: 0.031323, loss_s1: 0.025195, loss_fp: 0.001643, loss_freq: 0.013427
[06:56:18.374] iteration 24959: loss: 0.093172, loss_s1: 0.124490, loss_fp: 0.005156, loss_freq: 0.029270
[06:56:19.003] iteration 24960: loss: 0.039892, loss_s1: 0.028722, loss_fp: 0.002556, loss_freq: 0.029117
[06:56:19.609] iteration 24961: loss: 0.070955, loss_s1: 0.071684, loss_fp: 0.001434, loss_freq: 0.024352
[06:56:20.217] iteration 24962: loss: 0.062779, loss_s1: 0.064137, loss_fp: 0.002756, loss_freq: 0.026180
[06:56:20.831] iteration 24963: loss: 0.037697, loss_s1: 0.024797, loss_fp: 0.004297, loss_freq: 0.015722
[06:56:21.466] iteration 24964: loss: 0.066348, loss_s1: 0.067416, loss_fp: 0.003411, loss_freq: 0.031507
[06:56:22.131] iteration 24965: loss: 0.024892, loss_s1: 0.018015, loss_fp: 0.001933, loss_freq: 0.005692
[06:56:22.793] iteration 24966: loss: 0.072289, loss_s1: 0.048159, loss_fp: 0.004323, loss_freq: 0.047320
[06:56:23.455] iteration 24967: loss: 0.044781, loss_s1: 0.045886, loss_fp: 0.001672, loss_freq: 0.011936
[06:56:24.105] iteration 24968: loss: 0.089378, loss_s1: 0.103511, loss_fp: 0.005895, loss_freq: 0.042068
[06:56:24.717] iteration 24969: loss: 0.041146, loss_s1: 0.034437, loss_fp: 0.002274, loss_freq: 0.023123
[06:56:25.335] iteration 24970: loss: 0.061405, loss_s1: 0.053876, loss_fp: 0.006921, loss_freq: 0.031407
[06:56:25.953] iteration 24971: loss: 0.039852, loss_s1: 0.019813, loss_fp: 0.006878, loss_freq: 0.020048
[06:56:26.574] iteration 24972: loss: 0.033457, loss_s1: 0.020555, loss_fp: 0.000865, loss_freq: 0.015810
[06:56:27.242] iteration 24973: loss: 0.086277, loss_s1: 0.087852, loss_fp: 0.002918, loss_freq: 0.052658
[06:56:27.900] iteration 24974: loss: 0.061108, loss_s1: 0.049379, loss_fp: 0.006747, loss_freq: 0.042309
[06:56:28.529] iteration 24975: loss: 0.066544, loss_s1: 0.054122, loss_fp: 0.007306, loss_freq: 0.035409
[06:56:29.144] iteration 24976: loss: 0.052360, loss_s1: 0.056238, loss_fp: 0.000947, loss_freq: 0.011584
[06:56:29.759] iteration 24977: loss: 0.049069, loss_s1: 0.039404, loss_fp: 0.004312, loss_freq: 0.030648
[06:56:30.380] iteration 24978: loss: 0.060861, loss_s1: 0.052807, loss_fp: 0.005413, loss_freq: 0.028816
[06:56:31.031] iteration 24979: loss: 0.050402, loss_s1: 0.039107, loss_fp: 0.007673, loss_freq: 0.023876
[06:56:31.639] iteration 24980: loss: 0.121399, loss_s1: 0.146652, loss_fp: 0.015979, loss_freq: 0.036040
[06:56:32.246] iteration 24981: loss: 0.051595, loss_s1: 0.060906, loss_fp: 0.003862, loss_freq: 0.006381
[06:56:32.862] iteration 24982: loss: 0.078944, loss_s1: 0.088564, loss_fp: 0.013067, loss_freq: 0.036146
[06:56:33.478] iteration 24983: loss: 0.031065, loss_s1: 0.017081, loss_fp: 0.002329, loss_freq: 0.008912
[06:56:34.094] iteration 24984: loss: 0.057709, loss_s1: 0.074250, loss_fp: 0.003189, loss_freq: 0.012848
[06:56:34.710] iteration 24985: loss: 0.046967, loss_s1: 0.051950, loss_fp: 0.003682, loss_freq: 0.008190
[06:56:35.321] iteration 24986: loss: 0.095279, loss_s1: 0.083846, loss_fp: 0.004124, loss_freq: 0.082151
[06:56:35.933] iteration 24987: loss: 0.061923, loss_s1: 0.069244, loss_fp: 0.002982, loss_freq: 0.021256
[06:56:36.548] iteration 24988: loss: 0.070153, loss_s1: 0.054077, loss_fp: 0.017289, loss_freq: 0.022555
[06:56:37.159] iteration 24989: loss: 0.052925, loss_s1: 0.034962, loss_fp: 0.007030, loss_freq: 0.039103
[06:56:37.763] iteration 24990: loss: 0.046442, loss_s1: 0.013556, loss_fp: 0.009817, loss_freq: 0.035462
[06:56:38.729] iteration 24991: loss: 0.036995, loss_s1: 0.028464, loss_fp: 0.004783, loss_freq: 0.010429
[06:56:39.341] iteration 24992: loss: 0.055380, loss_s1: 0.056177, loss_fp: 0.002600, loss_freq: 0.019025
[06:56:39.946] iteration 24993: loss: 0.048265, loss_s1: 0.054701, loss_fp: 0.005579, loss_freq: 0.012806
[06:56:40.572] iteration 24994: loss: 0.043473, loss_s1: 0.037937, loss_fp: 0.002714, loss_freq: 0.009277
[06:56:41.189] iteration 24995: loss: 0.074667, loss_s1: 0.086643, loss_fp: 0.003929, loss_freq: 0.025787
[06:56:41.810] iteration 24996: loss: 0.058280, loss_s1: 0.042405, loss_fp: 0.004425, loss_freq: 0.036931
[06:56:42.442] iteration 24997: loss: 0.052223, loss_s1: 0.048671, loss_fp: 0.002668, loss_freq: 0.019535
[06:56:43.066] iteration 24998: loss: 0.046867, loss_s1: 0.029439, loss_fp: 0.002174, loss_freq: 0.010907
[06:56:43.682] iteration 24999: loss: 0.038216, loss_s1: 0.021024, loss_fp: 0.004967, loss_freq: 0.007370
[06:56:44.288] iteration 25000: loss: 0.076543, loss_s1: 0.073970, loss_fp: 0.006719, loss_freq: 0.028163
[06:56:47.566] iteration 25000 : mean_dice : 0.732114
[06:56:48.205] iteration 25001: loss: 0.064583, loss_s1: 0.052359, loss_fp: 0.001695, loss_freq: 0.036918
[06:56:48.812] iteration 25002: loss: 0.072418, loss_s1: 0.058623, loss_fp: 0.005178, loss_freq: 0.048916
[06:56:49.419] iteration 25003: loss: 0.035728, loss_s1: 0.022609, loss_fp: 0.002067, loss_freq: 0.014646
[06:56:50.021] iteration 25004: loss: 0.052151, loss_s1: 0.052137, loss_fp: 0.006846, loss_freq: 0.021714
[06:56:50.629] iteration 25005: loss: 0.065061, loss_s1: 0.057524, loss_fp: 0.004004, loss_freq: 0.016866
[06:56:51.232] iteration 25006: loss: 0.058481, loss_s1: 0.060853, loss_fp: 0.003560, loss_freq: 0.015814
[06:56:51.842] iteration 25007: loss: 0.143696, loss_s1: 0.186158, loss_fp: 0.002862, loss_freq: 0.079383
[06:56:52.451] iteration 25008: loss: 0.028861, loss_s1: 0.010073, loss_fp: 0.002873, loss_freq: 0.010887
[06:56:53.064] iteration 25009: loss: 0.067242, loss_s1: 0.054657, loss_fp: 0.008608, loss_freq: 0.045116
[06:56:53.673] iteration 25010: loss: 0.057527, loss_s1: 0.057861, loss_fp: 0.001658, loss_freq: 0.020346
[06:56:54.289] iteration 25011: loss: 0.062844, loss_s1: 0.056190, loss_fp: 0.001551, loss_freq: 0.035788
[06:56:54.901] iteration 25012: loss: 0.046947, loss_s1: 0.035744, loss_fp: 0.004760, loss_freq: 0.035431
[06:56:55.508] iteration 25013: loss: 0.042884, loss_s1: 0.033201, loss_fp: 0.002498, loss_freq: 0.015778
[06:56:56.121] iteration 25014: loss: 0.045215, loss_s1: 0.041471, loss_fp: 0.003173, loss_freq: 0.022027
[06:56:56.730] iteration 25015: loss: 0.053234, loss_s1: 0.035583, loss_fp: 0.006287, loss_freq: 0.034708
[06:56:57.343] iteration 25016: loss: 0.064565, loss_s1: 0.053680, loss_fp: 0.003099, loss_freq: 0.048880
[06:56:57.954] iteration 25017: loss: 0.045203, loss_s1: 0.028554, loss_fp: 0.003398, loss_freq: 0.025783
[06:56:58.571] iteration 25018: loss: 0.081340, loss_s1: 0.093651, loss_fp: 0.006820, loss_freq: 0.029855
[06:56:59.172] iteration 25019: loss: 0.059229, loss_s1: 0.050791, loss_fp: 0.004780, loss_freq: 0.035224
[06:56:59.782] iteration 25020: loss: 0.072514, loss_s1: 0.053794, loss_fp: 0.002578, loss_freq: 0.054410
[06:57:00.395] iteration 25021: loss: 0.062933, loss_s1: 0.054262, loss_fp: 0.008043, loss_freq: 0.040120
[06:57:01.009] iteration 25022: loss: 0.080859, loss_s1: 0.060639, loss_fp: 0.002458, loss_freq: 0.059891
[06:57:01.621] iteration 25023: loss: 0.074166, loss_s1: 0.068213, loss_fp: 0.006306, loss_freq: 0.037722
[06:57:02.236] iteration 25024: loss: 0.053335, loss_s1: 0.048438, loss_fp: 0.002267, loss_freq: 0.024912
[06:57:02.844] iteration 25025: loss: 0.057468, loss_s1: 0.055767, loss_fp: 0.003109, loss_freq: 0.035580
[06:57:03.457] iteration 25026: loss: 0.069163, loss_s1: 0.058663, loss_fp: 0.008840, loss_freq: 0.021919
[06:57:04.063] iteration 25027: loss: 0.060859, loss_s1: 0.039642, loss_fp: 0.003146, loss_freq: 0.045828
[06:57:04.700] iteration 25028: loss: 0.036304, loss_s1: 0.036112, loss_fp: 0.002829, loss_freq: 0.007931
[06:57:05.308] iteration 25029: loss: 0.097384, loss_s1: 0.098105, loss_fp: 0.016596, loss_freq: 0.041613
[06:57:05.949] iteration 25030: loss: 0.046435, loss_s1: 0.035446, loss_fp: 0.004618, loss_freq: 0.026524
[06:57:06.590] iteration 25031: loss: 0.089053, loss_s1: 0.098724, loss_fp: 0.003372, loss_freq: 0.041479
[06:57:07.244] iteration 25032: loss: 0.063681, loss_s1: 0.070249, loss_fp: 0.004684, loss_freq: 0.023223
[06:57:07.892] iteration 25033: loss: 0.089875, loss_s1: 0.107656, loss_fp: 0.009966, loss_freq: 0.035466
[06:57:08.537] iteration 25034: loss: 0.095147, loss_s1: 0.111728, loss_fp: 0.003399, loss_freq: 0.052582
[06:57:09.159] iteration 25035: loss: 0.045600, loss_s1: 0.033610, loss_fp: 0.005610, loss_freq: 0.017989
[06:57:09.762] iteration 25036: loss: 0.092106, loss_s1: 0.113390, loss_fp: 0.015762, loss_freq: 0.020885
[06:57:10.372] iteration 25037: loss: 0.032789, loss_s1: 0.013780, loss_fp: 0.003463, loss_freq: 0.014027
[06:57:10.995] iteration 25038: loss: 0.060843, loss_s1: 0.058543, loss_fp: 0.001036, loss_freq: 0.037228
[06:57:11.606] iteration 25039: loss: 0.041237, loss_s1: 0.035713, loss_fp: 0.001983, loss_freq: 0.015625
[06:57:12.221] iteration 25040: loss: 0.044609, loss_s1: 0.043192, loss_fp: 0.000658, loss_freq: 0.009682
[06:57:12.829] iteration 25041: loss: 0.034012, loss_s1: 0.022797, loss_fp: 0.001547, loss_freq: 0.015600
[06:57:13.444] iteration 25042: loss: 0.057579, loss_s1: 0.055624, loss_fp: 0.003842, loss_freq: 0.027448
[06:57:14.056] iteration 25043: loss: 0.034848, loss_s1: 0.019102, loss_fp: 0.001377, loss_freq: 0.016852
[06:57:14.667] iteration 25044: loss: 0.066747, loss_s1: 0.078046, loss_fp: 0.003618, loss_freq: 0.019773
[06:57:15.286] iteration 25045: loss: 0.058531, loss_s1: 0.029117, loss_fp: 0.003325, loss_freq: 0.051411
[06:57:15.894] iteration 25046: loss: 0.041511, loss_s1: 0.025771, loss_fp: 0.002913, loss_freq: 0.017970
[06:57:16.568] iteration 25047: loss: 0.056618, loss_s1: 0.044138, loss_fp: 0.007914, loss_freq: 0.041880
[06:57:17.199] iteration 25048: loss: 0.044834, loss_s1: 0.038282, loss_fp: 0.001416, loss_freq: 0.010919
[06:57:17.809] iteration 25049: loss: 0.062044, loss_s1: 0.068928, loss_fp: 0.006001, loss_freq: 0.022966
[06:57:18.420] iteration 25050: loss: 0.068567, loss_s1: 0.048673, loss_fp: 0.004654, loss_freq: 0.054625
[06:57:19.032] iteration 25051: loss: 0.030211, loss_s1: 0.024131, loss_fp: 0.004937, loss_freq: 0.005870
[06:57:19.659] iteration 25052: loss: 0.063912, loss_s1: 0.061841, loss_fp: 0.002293, loss_freq: 0.022158
[06:57:20.269] iteration 25053: loss: 0.051074, loss_s1: 0.043165, loss_fp: 0.003562, loss_freq: 0.024674
[06:57:20.883] iteration 25054: loss: 0.037733, loss_s1: 0.027981, loss_fp: 0.002734, loss_freq: 0.018383
[06:57:21.498] iteration 25055: loss: 0.063982, loss_s1: 0.077893, loss_fp: 0.005407, loss_freq: 0.013383
[06:57:22.112] iteration 25056: loss: 0.043835, loss_s1: 0.027025, loss_fp: 0.007174, loss_freq: 0.031278
[06:57:22.730] iteration 25057: loss: 0.040044, loss_s1: 0.018152, loss_fp: 0.001705, loss_freq: 0.024512
[06:57:23.350] iteration 25058: loss: 0.099869, loss_s1: 0.105276, loss_fp: 0.006843, loss_freq: 0.044863
[06:57:23.969] iteration 25059: loss: 0.050287, loss_s1: 0.037956, loss_fp: 0.001401, loss_freq: 0.031448
[06:57:24.588] iteration 25060: loss: 0.038802, loss_s1: 0.028482, loss_fp: 0.001395, loss_freq: 0.022722
[06:57:25.250] iteration 25061: loss: 0.064161, loss_s1: 0.042063, loss_fp: 0.005540, loss_freq: 0.048925
[06:57:25.913] iteration 25062: loss: 0.053586, loss_s1: 0.047195, loss_fp: 0.003269, loss_freq: 0.024526
[06:57:26.571] iteration 25063: loss: 0.069666, loss_s1: 0.067906, loss_fp: 0.004320, loss_freq: 0.039081
[06:57:27.220] iteration 25064: loss: 0.067213, loss_s1: 0.053979, loss_fp: 0.008848, loss_freq: 0.036543
[06:57:27.877] iteration 25065: loss: 0.063006, loss_s1: 0.037548, loss_fp: 0.008501, loss_freq: 0.047432
[06:57:28.534] iteration 25066: loss: 0.063823, loss_s1: 0.059089, loss_fp: 0.003987, loss_freq: 0.033632
[06:57:29.154] iteration 25067: loss: 0.049014, loss_s1: 0.042319, loss_fp: 0.004886, loss_freq: 0.018207
[06:57:29.775] iteration 25068: loss: 0.073084, loss_s1: 0.092991, loss_fp: 0.003236, loss_freq: 0.021440
[06:57:30.387] iteration 25069: loss: 0.076064, loss_s1: 0.063701, loss_fp: 0.011574, loss_freq: 0.046220
[06:57:30.994] iteration 25070: loss: 0.057943, loss_s1: 0.052305, loss_fp: 0.005227, loss_freq: 0.026074
[06:57:31.602] iteration 25071: loss: 0.047453, loss_s1: 0.045675, loss_fp: 0.005213, loss_freq: 0.012394
[06:57:32.208] iteration 25072: loss: 0.054662, loss_s1: 0.029570, loss_fp: 0.005610, loss_freq: 0.042586
[06:57:32.820] iteration 25073: loss: 0.069444, loss_s1: 0.077006, loss_fp: 0.004993, loss_freq: 0.027509
[06:57:33.427] iteration 25074: loss: 0.035298, loss_s1: 0.021166, loss_fp: 0.002934, loss_freq: 0.012900
[06:57:34.034] iteration 25075: loss: 0.045501, loss_s1: 0.034957, loss_fp: 0.002163, loss_freq: 0.020991
[06:57:34.640] iteration 25076: loss: 0.050424, loss_s1: 0.048132, loss_fp: 0.002951, loss_freq: 0.019894
[06:57:35.241] iteration 25077: loss: 0.050185, loss_s1: 0.056678, loss_fp: 0.002273, loss_freq: 0.021335
[06:57:35.852] iteration 25078: loss: 0.050476, loss_s1: 0.046892, loss_fp: 0.008142, loss_freq: 0.015365
[06:57:36.532] iteration 25079: loss: 0.062467, loss_s1: 0.073673, loss_fp: 0.003390, loss_freq: 0.019641
[06:57:37.138] iteration 25080: loss: 0.051840, loss_s1: 0.037509, loss_fp: 0.003654, loss_freq: 0.011237
[06:57:37.740] iteration 25081: loss: 0.103287, loss_s1: 0.115903, loss_fp: 0.007504, loss_freq: 0.043332
[06:57:38.347] iteration 25082: loss: 0.053088, loss_s1: 0.051231, loss_fp: 0.008799, loss_freq: 0.021937
[06:57:38.982] iteration 25083: loss: 0.056603, loss_s1: 0.047325, loss_fp: 0.004831, loss_freq: 0.026478
[06:57:39.589] iteration 25084: loss: 0.048147, loss_s1: 0.054222, loss_fp: 0.001542, loss_freq: 0.017287
[06:57:40.215] iteration 25085: loss: 0.064556, loss_s1: 0.053821, loss_fp: 0.013964, loss_freq: 0.031484
[06:57:40.823] iteration 25086: loss: 0.051161, loss_s1: 0.036490, loss_fp: 0.007149, loss_freq: 0.035343
[06:57:41.435] iteration 25087: loss: 0.083850, loss_s1: 0.109967, loss_fp: 0.001595, loss_freq: 0.024172
[06:57:42.039] iteration 25088: loss: 0.056822, loss_s1: 0.043255, loss_fp: 0.004522, loss_freq: 0.034108
[06:57:42.646] iteration 25089: loss: 0.043993, loss_s1: 0.024627, loss_fp: 0.009517, loss_freq: 0.025637
[06:57:43.273] iteration 25090: loss: 0.045714, loss_s1: 0.030744, loss_fp: 0.003168, loss_freq: 0.020018
[06:57:43.935] iteration 25091: loss: 0.056570, loss_s1: 0.041926, loss_fp: 0.005420, loss_freq: 0.041438
[06:57:44.542] iteration 25092: loss: 0.063161, loss_s1: 0.047552, loss_fp: 0.009943, loss_freq: 0.016318
[06:57:45.151] iteration 25093: loss: 0.056534, loss_s1: 0.025718, loss_fp: 0.004287, loss_freq: 0.051255
[06:57:45.762] iteration 25094: loss: 0.044895, loss_s1: 0.043496, loss_fp: 0.008052, loss_freq: 0.012116
[06:57:46.366] iteration 25095: loss: 0.036895, loss_s1: 0.036111, loss_fp: 0.001159, loss_freq: 0.015738
[06:57:46.970] iteration 25096: loss: 0.074811, loss_s1: 0.084324, loss_fp: 0.006953, loss_freq: 0.017288
[06:57:47.578] iteration 25097: loss: 0.048811, loss_s1: 0.034083, loss_fp: 0.002550, loss_freq: 0.025547
[06:57:48.180] iteration 25098: loss: 0.064239, loss_s1: 0.089116, loss_fp: 0.008309, loss_freq: 0.006952
[06:57:48.796] iteration 25099: loss: 0.066106, loss_s1: 0.025808, loss_fp: 0.017079, loss_freq: 0.061996
[06:57:49.405] iteration 25100: loss: 0.053399, loss_s1: 0.058771, loss_fp: 0.001188, loss_freq: 0.016200
[06:57:50.029] iteration 25101: loss: 0.047154, loss_s1: 0.025098, loss_fp: 0.006498, loss_freq: 0.017920
[06:57:50.650] iteration 25102: loss: 0.067629, loss_s1: 0.071445, loss_fp: 0.003858, loss_freq: 0.018604
[06:57:51.267] iteration 25103: loss: 0.069060, loss_s1: 0.082925, loss_fp: 0.002861, loss_freq: 0.030415
[06:57:51.880] iteration 25104: loss: 0.035466, loss_s1: 0.018312, loss_fp: 0.007299, loss_freq: 0.023363
[06:57:52.492] iteration 25105: loss: 0.048719, loss_s1: 0.022302, loss_fp: 0.002864, loss_freq: 0.033528
[06:57:53.107] iteration 25106: loss: 0.070238, loss_s1: 0.050076, loss_fp: 0.008297, loss_freq: 0.048215
[06:57:53.714] iteration 25107: loss: 0.076262, loss_s1: 0.100378, loss_fp: 0.002117, loss_freq: 0.021899
[06:57:54.511] iteration 25108: loss: 0.046649, loss_s1: 0.025748, loss_fp: 0.007510, loss_freq: 0.031647
[06:57:55.405] iteration 25109: loss: 0.049817, loss_s1: 0.054529, loss_fp: 0.004013, loss_freq: 0.016237
[06:57:56.168] iteration 25110: loss: 0.035091, loss_s1: 0.025593, loss_fp: 0.001008, loss_freq: 0.004469
[06:57:56.895] iteration 25111: loss: 0.035274, loss_s1: 0.029843, loss_fp: 0.002264, loss_freq: 0.007281
[06:57:57.505] iteration 25112: loss: 0.083756, loss_s1: 0.094464, loss_fp: 0.002461, loss_freq: 0.051063
[06:57:58.157] iteration 25113: loss: 0.078581, loss_s1: 0.063916, loss_fp: 0.005198, loss_freq: 0.053443
[06:57:58.769] iteration 25114: loss: 0.068028, loss_s1: 0.050530, loss_fp: 0.012686, loss_freq: 0.043428
[06:57:59.383] iteration 25115: loss: 0.076547, loss_s1: 0.082230, loss_fp: 0.006268, loss_freq: 0.032023
[06:57:59.992] iteration 25116: loss: 0.040277, loss_s1: 0.023427, loss_fp: 0.003043, loss_freq: 0.023168
[06:58:00.598] iteration 25117: loss: 0.052130, loss_s1: 0.035987, loss_fp: 0.001778, loss_freq: 0.044719
[06:58:01.293] iteration 25118: loss: 0.055764, loss_s1: 0.054570, loss_fp: 0.002833, loss_freq: 0.016034
[06:58:01.904] iteration 25119: loss: 0.062438, loss_s1: 0.060723, loss_fp: 0.006982, loss_freq: 0.026687
[06:58:02.513] iteration 25120: loss: 0.068428, loss_s1: 0.037096, loss_fp: 0.010100, loss_freq: 0.058994
[06:58:03.123] iteration 25121: loss: 0.042536, loss_s1: 0.041208, loss_fp: 0.002068, loss_freq: 0.017300
[06:58:03.737] iteration 25122: loss: 0.060480, loss_s1: 0.055108, loss_fp: 0.004761, loss_freq: 0.026039
[06:58:04.348] iteration 25123: loss: 0.051507, loss_s1: 0.031283, loss_fp: 0.007966, loss_freq: 0.022508
[06:58:04.961] iteration 25124: loss: 0.052786, loss_s1: 0.054688, loss_fp: 0.002611, loss_freq: 0.023286
[06:58:05.568] iteration 25125: loss: 0.068214, loss_s1: 0.085030, loss_fp: 0.002048, loss_freq: 0.018674
[06:58:06.168] iteration 25126: loss: 0.042279, loss_s1: 0.050522, loss_fp: 0.004378, loss_freq: 0.010298
[06:58:06.775] iteration 25127: loss: 0.050567, loss_s1: 0.033981, loss_fp: 0.002781, loss_freq: 0.020240
[06:58:07.381] iteration 25128: loss: 0.068497, loss_s1: 0.048607, loss_fp: 0.002649, loss_freq: 0.060724
[06:58:07.988] iteration 25129: loss: 0.084803, loss_s1: 0.094814, loss_fp: 0.004315, loss_freq: 0.043858
[06:58:08.593] iteration 25130: loss: 0.043013, loss_s1: 0.047218, loss_fp: 0.002916, loss_freq: 0.016351
[06:58:09.198] iteration 25131: loss: 0.051989, loss_s1: 0.039567, loss_fp: 0.004514, loss_freq: 0.030458
[06:58:09.806] iteration 25132: loss: 0.051368, loss_s1: 0.044566, loss_fp: 0.002610, loss_freq: 0.018205
[06:58:10.411] iteration 25133: loss: 0.065180, loss_s1: 0.069757, loss_fp: 0.003706, loss_freq: 0.032885
[06:58:11.015] iteration 25134: loss: 0.046660, loss_s1: 0.039006, loss_fp: 0.008889, loss_freq: 0.011221
[06:58:11.625] iteration 25135: loss: 0.044481, loss_s1: 0.038375, loss_fp: 0.002424, loss_freq: 0.014431
[06:58:12.254] iteration 25136: loss: 0.041099, loss_s1: 0.027024, loss_fp: 0.002079, loss_freq: 0.021737
[06:58:12.859] iteration 25137: loss: 0.042511, loss_s1: 0.025171, loss_fp: 0.005415, loss_freq: 0.018893
[06:58:13.462] iteration 25138: loss: 0.070810, loss_s1: 0.069170, loss_fp: 0.004302, loss_freq: 0.032567
[06:58:14.062] iteration 25139: loss: 0.071221, loss_s1: 0.079203, loss_fp: 0.003417, loss_freq: 0.040432
[06:58:14.666] iteration 25140: loss: 0.047847, loss_s1: 0.033404, loss_fp: 0.004821, loss_freq: 0.019958
[06:58:15.270] iteration 25141: loss: 0.066640, loss_s1: 0.050414, loss_fp: 0.010817, loss_freq: 0.041261
[06:58:15.877] iteration 25142: loss: 0.058861, loss_s1: 0.037800, loss_fp: 0.005005, loss_freq: 0.040636
[06:58:16.489] iteration 25143: loss: 0.065963, loss_s1: 0.075402, loss_fp: 0.011620, loss_freq: 0.013381
[06:58:17.092] iteration 25144: loss: 0.077774, loss_s1: 0.076752, loss_fp: 0.008812, loss_freq: 0.025737
[06:58:17.697] iteration 25145: loss: 0.065441, loss_s1: 0.058399, loss_fp: 0.004039, loss_freq: 0.028224
[06:58:18.306] iteration 25146: loss: 0.041154, loss_s1: 0.024965, loss_fp: 0.002890, loss_freq: 0.013028
[06:58:18.917] iteration 25147: loss: 0.054363, loss_s1: 0.047240, loss_fp: 0.001352, loss_freq: 0.036224
[06:58:19.528] iteration 25148: loss: 0.096527, loss_s1: 0.111711, loss_fp: 0.002464, loss_freq: 0.046853
[06:58:20.134] iteration 25149: loss: 0.050038, loss_s1: 0.037029, loss_fp: 0.002444, loss_freq: 0.032076
[06:58:20.742] iteration 25150: loss: 0.058308, loss_s1: 0.057742, loss_fp: 0.002837, loss_freq: 0.025903
[06:58:21.352] iteration 25151: loss: 0.045053, loss_s1: 0.039359, loss_fp: 0.004716, loss_freq: 0.009108
[06:58:21.957] iteration 25152: loss: 0.068207, loss_s1: 0.058359, loss_fp: 0.005321, loss_freq: 0.052724
[06:58:22.572] iteration 25153: loss: 0.036752, loss_s1: 0.023709, loss_fp: 0.005481, loss_freq: 0.008502
[06:58:23.177] iteration 25154: loss: 0.056162, loss_s1: 0.038894, loss_fp: 0.011164, loss_freq: 0.027083
[06:58:23.785] iteration 25155: loss: 0.031642, loss_s1: 0.019653, loss_fp: 0.004484, loss_freq: 0.006582
[06:58:24.393] iteration 25156: loss: 0.062783, loss_s1: 0.064027, loss_fp: 0.007023, loss_freq: 0.024827
[06:58:24.997] iteration 25157: loss: 0.058418, loss_s1: 0.040256, loss_fp: 0.005255, loss_freq: 0.032538
[06:58:25.605] iteration 25158: loss: 0.065208, loss_s1: 0.035449, loss_fp: 0.005011, loss_freq: 0.049612
[06:58:26.206] iteration 25159: loss: 0.063245, loss_s1: 0.056880, loss_fp: 0.002247, loss_freq: 0.042778
[06:58:26.809] iteration 25160: loss: 0.075236, loss_s1: 0.085674, loss_fp: 0.004348, loss_freq: 0.027632
[06:58:27.832] iteration 25161: loss: 0.068802, loss_s1: 0.057390, loss_fp: 0.006275, loss_freq: 0.041803
[06:58:28.489] iteration 25162: loss: 0.055851, loss_s1: 0.039094, loss_fp: 0.004219, loss_freq: 0.035396
[06:58:29.142] iteration 25163: loss: 0.050266, loss_s1: 0.034059, loss_fp: 0.003341, loss_freq: 0.031045
[06:58:29.785] iteration 25164: loss: 0.037895, loss_s1: 0.021145, loss_fp: 0.003549, loss_freq: 0.023265
[06:58:30.397] iteration 25165: loss: 0.033730, loss_s1: 0.033066, loss_fp: 0.002253, loss_freq: 0.006360
[06:58:31.004] iteration 25166: loss: 0.053884, loss_s1: 0.043597, loss_fp: 0.004981, loss_freq: 0.024974
[06:58:31.618] iteration 25167: loss: 0.066804, loss_s1: 0.053493, loss_fp: 0.001294, loss_freq: 0.045207
[06:58:32.224] iteration 25168: loss: 0.052287, loss_s1: 0.043277, loss_fp: 0.007599, loss_freq: 0.027984
[06:58:32.832] iteration 25169: loss: 0.040305, loss_s1: 0.030713, loss_fp: 0.006613, loss_freq: 0.014832
[06:58:33.439] iteration 25170: loss: 0.066796, loss_s1: 0.054652, loss_fp: 0.008687, loss_freq: 0.026861
[06:58:34.044] iteration 25171: loss: 0.066803, loss_s1: 0.051901, loss_fp: 0.007605, loss_freq: 0.042585
[06:58:34.652] iteration 25172: loss: 0.037688, loss_s1: 0.015976, loss_fp: 0.002710, loss_freq: 0.026058
[06:58:35.258] iteration 25173: loss: 0.047830, loss_s1: 0.027958, loss_fp: 0.004934, loss_freq: 0.033961
[06:58:35.864] iteration 25174: loss: 0.054807, loss_s1: 0.063024, loss_fp: 0.005684, loss_freq: 0.012712
[06:58:36.463] iteration 25175: loss: 0.045264, loss_s1: 0.039683, loss_fp: 0.005259, loss_freq: 0.012466
[06:58:37.069] iteration 25176: loss: 0.072112, loss_s1: 0.079116, loss_fp: 0.003544, loss_freq: 0.034015
[06:58:37.674] iteration 25177: loss: 0.139588, loss_s1: 0.136383, loss_fp: 0.018979, loss_freq: 0.101851
[06:58:38.291] iteration 25178: loss: 0.051267, loss_s1: 0.060381, loss_fp: 0.001231, loss_freq: 0.010762
[06:58:38.917] iteration 25179: loss: 0.094890, loss_s1: 0.108165, loss_fp: 0.012755, loss_freq: 0.040396
[06:58:39.533] iteration 25180: loss: 0.072470, loss_s1: 0.081323, loss_fp: 0.003309, loss_freq: 0.024555
[06:58:40.141] iteration 25181: loss: 0.058352, loss_s1: 0.054855, loss_fp: 0.001812, loss_freq: 0.029766
[06:58:40.749] iteration 25182: loss: 0.064156, loss_s1: 0.038766, loss_fp: 0.007470, loss_freq: 0.052971
[06:58:41.358] iteration 25183: loss: 0.068262, loss_s1: 0.052653, loss_fp: 0.001826, loss_freq: 0.030923
[06:58:41.964] iteration 25184: loss: 0.046865, loss_s1: 0.033710, loss_fp: 0.004655, loss_freq: 0.025296
[06:58:42.575] iteration 25185: loss: 0.058547, loss_s1: 0.056436, loss_fp: 0.003297, loss_freq: 0.028166
[06:58:43.198] iteration 25186: loss: 0.049871, loss_s1: 0.044607, loss_fp: 0.008142, loss_freq: 0.025258
[06:58:43.848] iteration 25187: loss: 0.067792, loss_s1: 0.053167, loss_fp: 0.005462, loss_freq: 0.045334
[06:58:44.464] iteration 25188: loss: 0.065488, loss_s1: 0.053679, loss_fp: 0.002530, loss_freq: 0.032051
[06:58:45.071] iteration 25189: loss: 0.035534, loss_s1: 0.019251, loss_fp: 0.007789, loss_freq: 0.016204
[06:58:45.676] iteration 25190: loss: 0.076680, loss_s1: 0.078937, loss_fp: 0.002807, loss_freq: 0.035398
[06:58:46.281] iteration 25191: loss: 0.086221, loss_s1: 0.105359, loss_fp: 0.005929, loss_freq: 0.039158
[06:58:46.888] iteration 25192: loss: 0.085512, loss_s1: 0.073789, loss_fp: 0.008604, loss_freq: 0.051631
[06:58:47.492] iteration 25193: loss: 0.074237, loss_s1: 0.087212, loss_fp: 0.008492, loss_freq: 0.023830
[06:58:48.096] iteration 25194: loss: 0.052729, loss_s1: 0.038770, loss_fp: 0.002390, loss_freq: 0.016696
[06:58:48.705] iteration 25195: loss: 0.052101, loss_s1: 0.056714, loss_fp: 0.004444, loss_freq: 0.022007
[06:58:49.317] iteration 25196: loss: 0.060816, loss_s1: 0.033958, loss_fp: 0.003464, loss_freq: 0.025718
[06:58:49.921] iteration 25197: loss: 0.047039, loss_s1: 0.024686, loss_fp: 0.001413, loss_freq: 0.030792
[06:58:50.532] iteration 25198: loss: 0.049539, loss_s1: 0.033858, loss_fp: 0.002346, loss_freq: 0.033558
[06:58:51.137] iteration 25199: loss: 0.105407, loss_s1: 0.081331, loss_fp: 0.005077, loss_freq: 0.093513
[06:58:51.750] iteration 25200: loss: 0.053317, loss_s1: 0.048925, loss_fp: 0.005443, loss_freq: 0.021581
[06:58:54.944] iteration 25200 : mean_dice : 0.736851
[06:58:55.574] iteration 25201: loss: 0.071078, loss_s1: 0.082805, loss_fp: 0.004297, loss_freq: 0.011431
[06:58:56.177] iteration 25202: loss: 0.086733, loss_s1: 0.071171, loss_fp: 0.017318, loss_freq: 0.052769
[06:58:56.791] iteration 25203: loss: 0.076845, loss_s1: 0.086102, loss_fp: 0.002671, loss_freq: 0.031230
[06:58:57.399] iteration 25204: loss: 0.093953, loss_s1: 0.128187, loss_fp: 0.006478, loss_freq: 0.030762
[06:58:58.008] iteration 25205: loss: 0.074306, loss_s1: 0.060892, loss_fp: 0.006655, loss_freq: 0.034351
[06:58:58.617] iteration 25206: loss: 0.053145, loss_s1: 0.052285, loss_fp: 0.003414, loss_freq: 0.022294
[06:58:59.232] iteration 25207: loss: 0.045308, loss_s1: 0.025475, loss_fp: 0.003376, loss_freq: 0.026989
[06:58:59.856] iteration 25208: loss: 0.061589, loss_s1: 0.056339, loss_fp: 0.006451, loss_freq: 0.026630
[06:59:00.463] iteration 25209: loss: 0.054961, loss_s1: 0.064022, loss_fp: 0.000845, loss_freq: 0.007301
[06:59:01.068] iteration 25210: loss: 0.033745, loss_s1: 0.023334, loss_fp: 0.000856, loss_freq: 0.010068
[06:59:01.680] iteration 25211: loss: 0.042014, loss_s1: 0.014885, loss_fp: 0.003802, loss_freq: 0.033119
[06:59:02.289] iteration 25212: loss: 0.056674, loss_s1: 0.066712, loss_fp: 0.000595, loss_freq: 0.024620
[06:59:02.895] iteration 25213: loss: 0.045530, loss_s1: 0.043990, loss_fp: 0.001354, loss_freq: 0.015644
[06:59:03.504] iteration 25214: loss: 0.058056, loss_s1: 0.042714, loss_fp: 0.006182, loss_freq: 0.040127
[06:59:04.106] iteration 25215: loss: 0.042281, loss_s1: 0.017789, loss_fp: 0.007642, loss_freq: 0.027553
[06:59:04.715] iteration 25216: loss: 0.032276, loss_s1: 0.020197, loss_fp: 0.001439, loss_freq: 0.013150
[06:59:05.332] iteration 25217: loss: 0.054741, loss_s1: 0.058113, loss_fp: 0.006040, loss_freq: 0.019008
[06:59:05.993] iteration 25218: loss: 0.058070, loss_s1: 0.051415, loss_fp: 0.006745, loss_freq: 0.020467
[06:59:06.655] iteration 25219: loss: 0.051141, loss_s1: 0.028996, loss_fp: 0.002647, loss_freq: 0.025128
[06:59:07.311] iteration 25220: loss: 0.055569, loss_s1: 0.040712, loss_fp: 0.003434, loss_freq: 0.038331
[06:59:07.968] iteration 25221: loss: 0.036433, loss_s1: 0.035627, loss_fp: 0.007000, loss_freq: 0.009440
[06:59:08.597] iteration 25222: loss: 0.071406, loss_s1: 0.073837, loss_fp: 0.002988, loss_freq: 0.032647
[06:59:09.269] iteration 25223: loss: 0.036334, loss_s1: 0.022454, loss_fp: 0.003380, loss_freq: 0.014068
[06:59:09.939] iteration 25224: loss: 0.047151, loss_s1: 0.042497, loss_fp: 0.002665, loss_freq: 0.017619
[06:59:10.596] iteration 25225: loss: 0.037255, loss_s1: 0.018814, loss_fp: 0.003001, loss_freq: 0.006170
[06:59:11.250] iteration 25226: loss: 0.048881, loss_s1: 0.032381, loss_fp: 0.004395, loss_freq: 0.039548
[06:59:11.905] iteration 25227: loss: 0.039854, loss_s1: 0.033377, loss_fp: 0.002216, loss_freq: 0.010280
[06:59:12.557] iteration 25228: loss: 0.092792, loss_s1: 0.087204, loss_fp: 0.009261, loss_freq: 0.062740
[06:59:13.212] iteration 25229: loss: 0.067254, loss_s1: 0.042137, loss_fp: 0.002153, loss_freq: 0.042774
[06:59:13.828] iteration 25230: loss: 0.046430, loss_s1: 0.039073, loss_fp: 0.001088, loss_freq: 0.024661
[06:59:14.472] iteration 25231: loss: 0.053261, loss_s1: 0.033088, loss_fp: 0.001944, loss_freq: 0.034133
[06:59:15.145] iteration 25232: loss: 0.047232, loss_s1: 0.032140, loss_fp: 0.001845, loss_freq: 0.026554
[06:59:15.799] iteration 25233: loss: 0.059355, loss_s1: 0.061368, loss_fp: 0.004042, loss_freq: 0.028811
[06:59:16.410] iteration 25234: loss: 0.079761, loss_s1: 0.101211, loss_fp: 0.012391, loss_freq: 0.018527
[06:59:17.022] iteration 25235: loss: 0.044502, loss_s1: 0.020383, loss_fp: 0.002312, loss_freq: 0.041896
[06:59:17.632] iteration 25236: loss: 0.063812, loss_s1: 0.062953, loss_fp: 0.007509, loss_freq: 0.023405
[06:59:18.246] iteration 25237: loss: 0.055085, loss_s1: 0.030366, loss_fp: 0.006198, loss_freq: 0.037873
[06:59:18.856] iteration 25238: loss: 0.085579, loss_s1: 0.083800, loss_fp: 0.010925, loss_freq: 0.045708
[06:59:19.477] iteration 25239: loss: 0.053781, loss_s1: 0.044270, loss_fp: 0.001887, loss_freq: 0.038890
[06:59:20.097] iteration 25240: loss: 0.041208, loss_s1: 0.030341, loss_fp: 0.001771, loss_freq: 0.012040
[06:59:20.706] iteration 25241: loss: 0.066591, loss_s1: 0.070436, loss_fp: 0.009700, loss_freq: 0.012786
[06:59:21.321] iteration 25242: loss: 0.071220, loss_s1: 0.055717, loss_fp: 0.004276, loss_freq: 0.052741
[06:59:21.928] iteration 25243: loss: 0.057874, loss_s1: 0.049716, loss_fp: 0.002816, loss_freq: 0.023790
[06:59:22.546] iteration 25244: loss: 0.052118, loss_s1: 0.056395, loss_fp: 0.004049, loss_freq: 0.009642
[06:59:23.163] iteration 25245: loss: 0.052093, loss_s1: 0.049457, loss_fp: 0.001778, loss_freq: 0.017049
[06:59:23.769] iteration 25246: loss: 0.054140, loss_s1: 0.050448, loss_fp: 0.003717, loss_freq: 0.021452
[06:59:24.371] iteration 25247: loss: 0.046688, loss_s1: 0.051637, loss_fp: 0.002840, loss_freq: 0.017078
[06:59:24.978] iteration 25248: loss: 0.048032, loss_s1: 0.035497, loss_fp: 0.003698, loss_freq: 0.023280
[06:59:25.593] iteration 25249: loss: 0.064315, loss_s1: 0.079343, loss_fp: 0.002014, loss_freq: 0.018977
[06:59:26.201] iteration 25250: loss: 0.043832, loss_s1: 0.038420, loss_fp: 0.004234, loss_freq: 0.014350
[06:59:26.810] iteration 25251: loss: 0.077450, loss_s1: 0.085281, loss_fp: 0.005715, loss_freq: 0.034436
[06:59:27.419] iteration 25252: loss: 0.103964, loss_s1: 0.088295, loss_fp: 0.002248, loss_freq: 0.094942
[06:59:28.035] iteration 25253: loss: 0.075376, loss_s1: 0.077649, loss_fp: 0.003876, loss_freq: 0.025672
[06:59:28.656] iteration 25254: loss: 0.061280, loss_s1: 0.044186, loss_fp: 0.001620, loss_freq: 0.049482
[06:59:29.271] iteration 25255: loss: 0.093319, loss_s1: 0.105398, loss_fp: 0.010379, loss_freq: 0.022699
[06:59:29.891] iteration 25256: loss: 0.044261, loss_s1: 0.034564, loss_fp: 0.003717, loss_freq: 0.029167
[06:59:30.503] iteration 25257: loss: 0.089182, loss_s1: 0.073487, loss_fp: 0.009471, loss_freq: 0.063382
[06:59:31.118] iteration 25258: loss: 0.052043, loss_s1: 0.024362, loss_fp: 0.000981, loss_freq: 0.047361
[06:59:31.723] iteration 25259: loss: 0.038424, loss_s1: 0.029911, loss_fp: 0.004862, loss_freq: 0.017683
[06:59:32.364] iteration 25260: loss: 0.044127, loss_s1: 0.024608, loss_fp: 0.001690, loss_freq: 0.026424
[06:59:33.026] iteration 25261: loss: 0.066097, loss_s1: 0.066071, loss_fp: 0.003848, loss_freq: 0.041257
[06:59:33.689] iteration 25262: loss: 0.032699, loss_s1: 0.014059, loss_fp: 0.006590, loss_freq: 0.008810
[06:59:34.348] iteration 25263: loss: 0.039892, loss_s1: 0.021875, loss_fp: 0.005105, loss_freq: 0.019096
[06:59:35.006] iteration 25264: loss: 0.039937, loss_s1: 0.025627, loss_fp: 0.001599, loss_freq: 0.023069
[06:59:35.667] iteration 25265: loss: 0.023757, loss_s1: 0.009899, loss_fp: 0.003306, loss_freq: 0.008788
[06:59:36.326] iteration 25266: loss: 0.044009, loss_s1: 0.027017, loss_fp: 0.002747, loss_freq: 0.018287
[06:59:36.985] iteration 25267: loss: 0.064214, loss_s1: 0.052055, loss_fp: 0.004825, loss_freq: 0.035530
[06:59:37.645] iteration 25268: loss: 0.041861, loss_s1: 0.033571, loss_fp: 0.003400, loss_freq: 0.019900
[06:59:38.273] iteration 25269: loss: 0.029781, loss_s1: 0.018791, loss_fp: 0.003003, loss_freq: 0.008966
[06:59:38.896] iteration 25270: loss: 0.049759, loss_s1: 0.031381, loss_fp: 0.005129, loss_freq: 0.030909
[06:59:39.515] iteration 25271: loss: 0.055953, loss_s1: 0.033059, loss_fp: 0.009934, loss_freq: 0.022508
[06:59:40.127] iteration 25272: loss: 0.047459, loss_s1: 0.031835, loss_fp: 0.004267, loss_freq: 0.019343
[06:59:40.740] iteration 25273: loss: 0.057298, loss_s1: 0.052919, loss_fp: 0.005100, loss_freq: 0.032771
[06:59:41.354] iteration 25274: loss: 0.036495, loss_s1: 0.026390, loss_fp: 0.001767, loss_freq: 0.024105
[06:59:41.970] iteration 25275: loss: 0.055523, loss_s1: 0.041975, loss_fp: 0.007228, loss_freq: 0.031288
[06:59:42.581] iteration 25276: loss: 0.046273, loss_s1: 0.020031, loss_fp: 0.005636, loss_freq: 0.030871
[06:59:43.197] iteration 25277: loss: 0.061187, loss_s1: 0.065938, loss_fp: 0.007466, loss_freq: 0.018424
[06:59:43.808] iteration 25278: loss: 0.052135, loss_s1: 0.045517, loss_fp: 0.005451, loss_freq: 0.024696
[06:59:44.418] iteration 25279: loss: 0.081914, loss_s1: 0.081062, loss_fp: 0.003948, loss_freq: 0.049225
[06:59:45.030] iteration 25280: loss: 0.060144, loss_s1: 0.051868, loss_fp: 0.002432, loss_freq: 0.018248
[06:59:45.642] iteration 25281: loss: 0.044090, loss_s1: 0.038859, loss_fp: 0.003415, loss_freq: 0.009640
[06:59:46.264] iteration 25282: loss: 0.075504, loss_s1: 0.093079, loss_fp: 0.007092, loss_freq: 0.031057
[06:59:46.884] iteration 25283: loss: 0.066238, loss_s1: 0.048407, loss_fp: 0.001786, loss_freq: 0.039936
[06:59:47.495] iteration 25284: loss: 0.048676, loss_s1: 0.020618, loss_fp: 0.004373, loss_freq: 0.040273
[06:59:48.106] iteration 25285: loss: 0.067093, loss_s1: 0.067200, loss_fp: 0.008178, loss_freq: 0.020065
[06:59:48.718] iteration 25286: loss: 0.054824, loss_s1: 0.039923, loss_fp: 0.005643, loss_freq: 0.027845
[06:59:49.334] iteration 25287: loss: 0.054085, loss_s1: 0.037468, loss_fp: 0.010464, loss_freq: 0.034943
[06:59:49.952] iteration 25288: loss: 0.055279, loss_s1: 0.062447, loss_fp: 0.001001, loss_freq: 0.009525
[06:59:50.559] iteration 25289: loss: 0.059025, loss_s1: 0.065245, loss_fp: 0.006617, loss_freq: 0.024165
[06:59:51.209] iteration 25290: loss: 0.102622, loss_s1: 0.097656, loss_fp: 0.012933, loss_freq: 0.062275
[06:59:51.814] iteration 25291: loss: 0.040386, loss_s1: 0.042509, loss_fp: 0.006267, loss_freq: 0.009230
[06:59:52.423] iteration 25292: loss: 0.065791, loss_s1: 0.058251, loss_fp: 0.002802, loss_freq: 0.032653
[06:59:53.050] iteration 25293: loss: 0.067838, loss_s1: 0.062467, loss_fp: 0.008588, loss_freq: 0.033436
[06:59:53.671] iteration 25294: loss: 0.031031, loss_s1: 0.022054, loss_fp: 0.001662, loss_freq: 0.015245
[06:59:54.300] iteration 25295: loss: 0.055393, loss_s1: 0.065815, loss_fp: 0.001445, loss_freq: 0.012662
[06:59:54.929] iteration 25296: loss: 0.042149, loss_s1: 0.041764, loss_fp: 0.002293, loss_freq: 0.014588
[06:59:55.542] iteration 25297: loss: 0.055976, loss_s1: 0.049455, loss_fp: 0.000847, loss_freq: 0.011654
[06:59:56.150] iteration 25298: loss: 0.066702, loss_s1: 0.042705, loss_fp: 0.004966, loss_freq: 0.057828
[06:59:56.791] iteration 25299: loss: 0.092896, loss_s1: 0.112865, loss_fp: 0.005677, loss_freq: 0.041491
[06:59:57.707] iteration 25300: loss: 0.076496, loss_s1: 0.063595, loss_fp: 0.003270, loss_freq: 0.065008
[06:59:58.678] iteration 25301: loss: 0.054790, loss_s1: 0.048639, loss_fp: 0.006545, loss_freq: 0.021504
[06:59:59.558] iteration 25302: loss: 0.053723, loss_s1: 0.043186, loss_fp: 0.003680, loss_freq: 0.024440
[07:00:00.193] iteration 25303: loss: 0.040133, loss_s1: 0.027848, loss_fp: 0.002782, loss_freq: 0.024565
[07:00:00.803] iteration 25304: loss: 0.034795, loss_s1: 0.030295, loss_fp: 0.002108, loss_freq: 0.006799
[07:00:01.420] iteration 25305: loss: 0.027566, loss_s1: 0.016254, loss_fp: 0.001604, loss_freq: 0.009360
[07:00:02.031] iteration 25306: loss: 0.049951, loss_s1: 0.038096, loss_fp: 0.006295, loss_freq: 0.024105
[07:00:02.639] iteration 25307: loss: 0.044894, loss_s1: 0.023950, loss_fp: 0.002951, loss_freq: 0.020160
[07:00:03.243] iteration 25308: loss: 0.090944, loss_s1: 0.120780, loss_fp: 0.004471, loss_freq: 0.028565
[07:00:03.849] iteration 25309: loss: 0.036920, loss_s1: 0.026726, loss_fp: 0.001423, loss_freq: 0.022230
[07:00:04.460] iteration 25310: loss: 0.055292, loss_s1: 0.051355, loss_fp: 0.006222, loss_freq: 0.019925
[07:00:05.073] iteration 25311: loss: 0.073791, loss_s1: 0.040317, loss_fp: 0.006448, loss_freq: 0.064418
[07:00:05.684] iteration 25312: loss: 0.063544, loss_s1: 0.039955, loss_fp: 0.003625, loss_freq: 0.046918
[07:00:06.298] iteration 25313: loss: 0.094043, loss_s1: 0.103069, loss_fp: 0.008432, loss_freq: 0.040249
[07:00:06.910] iteration 25314: loss: 0.068957, loss_s1: 0.071673, loss_fp: 0.004487, loss_freq: 0.025258
[07:00:07.542] iteration 25315: loss: 0.056491, loss_s1: 0.046309, loss_fp: 0.001750, loss_freq: 0.031778
[07:00:08.151] iteration 25316: loss: 0.039221, loss_s1: 0.020024, loss_fp: 0.005902, loss_freq: 0.016710
[07:00:08.761] iteration 25317: loss: 0.023443, loss_s1: 0.014522, loss_fp: 0.001724, loss_freq: 0.010064
[07:00:09.373] iteration 25318: loss: 0.084192, loss_s1: 0.093320, loss_fp: 0.001296, loss_freq: 0.045579
[07:00:09.982] iteration 25319: loss: 0.059206, loss_s1: 0.061692, loss_fp: 0.008848, loss_freq: 0.016259
[07:00:10.584] iteration 25320: loss: 0.099279, loss_s1: 0.092788, loss_fp: 0.012056, loss_freq: 0.060851
[07:00:11.194] iteration 25321: loss: 0.048454, loss_s1: 0.044195, loss_fp: 0.001527, loss_freq: 0.015130
[07:00:11.846] iteration 25322: loss: 0.084621, loss_s1: 0.077020, loss_fp: 0.012700, loss_freq: 0.058121
[07:00:12.504] iteration 25323: loss: 0.034757, loss_s1: 0.019575, loss_fp: 0.004363, loss_freq: 0.008384
[07:00:13.156] iteration 25324: loss: 0.044771, loss_s1: 0.035355, loss_fp: 0.004671, loss_freq: 0.021437
[07:00:13.810] iteration 25325: loss: 0.031642, loss_s1: 0.013102, loss_fp: 0.002239, loss_freq: 0.020162
[07:00:14.460] iteration 25326: loss: 0.069369, loss_s1: 0.058704, loss_fp: 0.011478, loss_freq: 0.046983
[07:00:15.185] iteration 25327: loss: 0.067463, loss_s1: 0.036780, loss_fp: 0.008840, loss_freq: 0.056400
[07:00:15.840] iteration 25328: loss: 0.071133, loss_s1: 0.069963, loss_fp: 0.002641, loss_freq: 0.040183
[07:00:16.490] iteration 25329: loss: 0.069104, loss_s1: 0.065728, loss_fp: 0.005481, loss_freq: 0.039061
[07:00:17.144] iteration 25330: loss: 0.041278, loss_s1: 0.025153, loss_fp: 0.006054, loss_freq: 0.013257
[07:00:18.124] iteration 25331: loss: 0.071264, loss_s1: 0.058217, loss_fp: 0.006105, loss_freq: 0.048932
[07:00:18.736] iteration 25332: loss: 0.059766, loss_s1: 0.055330, loss_fp: 0.006835, loss_freq: 0.024896
[07:00:19.347] iteration 25333: loss: 0.043787, loss_s1: 0.029448, loss_fp: 0.001304, loss_freq: 0.031286
[07:00:19.953] iteration 25334: loss: 0.040617, loss_s1: 0.026305, loss_fp: 0.002843, loss_freq: 0.020518
[07:00:20.561] iteration 25335: loss: 0.055219, loss_s1: 0.063713, loss_fp: 0.009232, loss_freq: 0.015725
[07:00:21.165] iteration 25336: loss: 0.055472, loss_s1: 0.039563, loss_fp: 0.001714, loss_freq: 0.038789
[07:00:21.824] iteration 25337: loss: 0.042579, loss_s1: 0.027534, loss_fp: 0.002706, loss_freq: 0.017251
[07:00:22.472] iteration 25338: loss: 0.032520, loss_s1: 0.016289, loss_fp: 0.003677, loss_freq: 0.021328
[07:00:23.121] iteration 25339: loss: 0.034516, loss_s1: 0.026644, loss_fp: 0.001101, loss_freq: 0.022066
[07:00:23.777] iteration 25340: loss: 0.062961, loss_s1: 0.066289, loss_fp: 0.001719, loss_freq: 0.026513
[07:00:24.425] iteration 25341: loss: 0.092019, loss_s1: 0.098035, loss_fp: 0.003887, loss_freq: 0.043836
[07:00:25.032] iteration 25342: loss: 0.046974, loss_s1: 0.030511, loss_fp: 0.001730, loss_freq: 0.030138
[07:00:25.674] iteration 25343: loss: 0.036858, loss_s1: 0.020276, loss_fp: 0.000686, loss_freq: 0.022444
[07:00:26.287] iteration 25344: loss: 0.070468, loss_s1: 0.044598, loss_fp: 0.006211, loss_freq: 0.063343
[07:00:26.894] iteration 25345: loss: 0.068890, loss_s1: 0.079644, loss_fp: 0.003081, loss_freq: 0.019807
[07:00:27.508] iteration 25346: loss: 0.042942, loss_s1: 0.035130, loss_fp: 0.001952, loss_freq: 0.020973
[07:00:28.115] iteration 25347: loss: 0.074469, loss_s1: 0.039272, loss_fp: 0.008030, loss_freq: 0.081917
[07:00:28.731] iteration 25348: loss: 0.037888, loss_s1: 0.017692, loss_fp: 0.004145, loss_freq: 0.019119
[07:00:29.337] iteration 25349: loss: 0.097241, loss_s1: 0.100090, loss_fp: 0.009428, loss_freq: 0.054920
[07:00:29.940] iteration 25350: loss: 0.058733, loss_s1: 0.055591, loss_fp: 0.004126, loss_freq: 0.024349
[07:00:30.549] iteration 25351: loss: 0.043173, loss_s1: 0.030683, loss_fp: 0.001955, loss_freq: 0.026369
[07:00:31.159] iteration 25352: loss: 0.054918, loss_s1: 0.051862, loss_fp: 0.001634, loss_freq: 0.034882
[07:00:31.766] iteration 25353: loss: 0.053784, loss_s1: 0.020352, loss_fp: 0.005459, loss_freq: 0.030606
[07:00:32.368] iteration 25354: loss: 0.035358, loss_s1: 0.030888, loss_fp: 0.001889, loss_freq: 0.012369
[07:00:32.969] iteration 25355: loss: 0.063934, loss_s1: 0.048478, loss_fp: 0.005585, loss_freq: 0.043505
[07:00:33.576] iteration 25356: loss: 0.056069, loss_s1: 0.052395, loss_fp: 0.002918, loss_freq: 0.035430
[07:00:34.192] iteration 25357: loss: 0.044732, loss_s1: 0.029238, loss_fp: 0.001064, loss_freq: 0.029468
[07:00:34.801] iteration 25358: loss: 0.097810, loss_s1: 0.085041, loss_fp: 0.004122, loss_freq: 0.043763
[07:00:35.421] iteration 25359: loss: 0.045548, loss_s1: 0.035632, loss_fp: 0.003239, loss_freq: 0.025616
[07:00:36.037] iteration 25360: loss: 0.062888, loss_s1: 0.033673, loss_fp: 0.006256, loss_freq: 0.051656
[07:00:36.653] iteration 25361: loss: 0.057077, loss_s1: 0.042734, loss_fp: 0.003593, loss_freq: 0.044884
[07:00:37.265] iteration 25362: loss: 0.059524, loss_s1: 0.036126, loss_fp: 0.006274, loss_freq: 0.034576
[07:00:37.868] iteration 25363: loss: 0.064438, loss_s1: 0.078600, loss_fp: 0.002505, loss_freq: 0.019815
[07:00:38.478] iteration 25364: loss: 0.043682, loss_s1: 0.026093, loss_fp: 0.004600, loss_freq: 0.018917
[07:00:39.090] iteration 25365: loss: 0.043894, loss_s1: 0.043514, loss_fp: 0.003609, loss_freq: 0.019450
[07:00:39.704] iteration 25366: loss: 0.056541, loss_s1: 0.054265, loss_fp: 0.005649, loss_freq: 0.014775
[07:00:40.313] iteration 25367: loss: 0.074904, loss_s1: 0.064807, loss_fp: 0.003548, loss_freq: 0.052315
[07:00:40.925] iteration 25368: loss: 0.046233, loss_s1: 0.049478, loss_fp: 0.003999, loss_freq: 0.012367
[07:00:41.534] iteration 25369: loss: 0.089688, loss_s1: 0.123162, loss_fp: 0.001938, loss_freq: 0.023764
[07:00:42.143] iteration 25370: loss: 0.069341, loss_s1: 0.055700, loss_fp: 0.007533, loss_freq: 0.050260
[07:00:42.749] iteration 25371: loss: 0.074839, loss_s1: 0.086545, loss_fp: 0.006621, loss_freq: 0.016906
[07:00:43.364] iteration 25372: loss: 0.054431, loss_s1: 0.046776, loss_fp: 0.008726, loss_freq: 0.020131
[07:00:43.973] iteration 25373: loss: 0.070491, loss_s1: 0.058993, loss_fp: 0.004128, loss_freq: 0.052434
[07:00:44.625] iteration 25374: loss: 0.099053, loss_s1: 0.117746, loss_fp: 0.007896, loss_freq: 0.048052
[07:00:45.275] iteration 25375: loss: 0.084032, loss_s1: 0.050049, loss_fp: 0.009620, loss_freq: 0.051824
[07:00:45.931] iteration 25376: loss: 0.084703, loss_s1: 0.103391, loss_fp: 0.005329, loss_freq: 0.028320
[07:00:46.592] iteration 25377: loss: 0.048771, loss_s1: 0.036466, loss_fp: 0.004596, loss_freq: 0.026009
[07:00:47.286] iteration 25378: loss: 0.061040, loss_s1: 0.051627, loss_fp: 0.002099, loss_freq: 0.041369
[07:00:47.944] iteration 25379: loss: 0.043944, loss_s1: 0.041304, loss_fp: 0.001355, loss_freq: 0.016241
[07:00:48.607] iteration 25380: loss: 0.030444, loss_s1: 0.015106, loss_fp: 0.000396, loss_freq: 0.008678
[07:00:49.283] iteration 25381: loss: 0.045487, loss_s1: 0.018936, loss_fp: 0.002988, loss_freq: 0.031422
[07:00:49.946] iteration 25382: loss: 0.059407, loss_s1: 0.064090, loss_fp: 0.005018, loss_freq: 0.025097
[07:00:50.600] iteration 25383: loss: 0.034864, loss_s1: 0.020770, loss_fp: 0.001144, loss_freq: 0.019729
[07:00:51.258] iteration 25384: loss: 0.045321, loss_s1: 0.033327, loss_fp: 0.003035, loss_freq: 0.025388
[07:00:51.914] iteration 25385: loss: 0.075052, loss_s1: 0.057542, loss_fp: 0.001512, loss_freq: 0.060570
[07:00:52.567] iteration 25386: loss: 0.037925, loss_s1: 0.017722, loss_fp: 0.003378, loss_freq: 0.021899
[07:00:53.178] iteration 25387: loss: 0.054104, loss_s1: 0.035657, loss_fp: 0.002046, loss_freq: 0.044804
[07:00:53.785] iteration 25388: loss: 0.043988, loss_s1: 0.029599, loss_fp: 0.001012, loss_freq: 0.023325
[07:00:54.398] iteration 25389: loss: 0.047565, loss_s1: 0.026233, loss_fp: 0.004368, loss_freq: 0.037527
[07:00:55.012] iteration 25390: loss: 0.048128, loss_s1: 0.040065, loss_fp: 0.004111, loss_freq: 0.024369
[07:00:55.628] iteration 25391: loss: 0.033942, loss_s1: 0.036445, loss_fp: 0.003565, loss_freq: 0.005300
[07:00:56.240] iteration 25392: loss: 0.052009, loss_s1: 0.038882, loss_fp: 0.002135, loss_freq: 0.022371
[07:00:56.852] iteration 25393: loss: 0.041882, loss_s1: 0.033547, loss_fp: 0.002356, loss_freq: 0.011427
[07:00:57.461] iteration 25394: loss: 0.036344, loss_s1: 0.030831, loss_fp: 0.002382, loss_freq: 0.011726
[07:00:58.074] iteration 25395: loss: 0.137608, loss_s1: 0.229505, loss_fp: 0.001832, loss_freq: 0.009469
[07:00:58.688] iteration 25396: loss: 0.047878, loss_s1: 0.025083, loss_fp: 0.002023, loss_freq: 0.039589
[07:00:59.300] iteration 25397: loss: 0.042646, loss_s1: 0.027825, loss_fp: 0.005775, loss_freq: 0.019130
[07:00:59.928] iteration 25398: loss: 0.065506, loss_s1: 0.055362, loss_fp: 0.001814, loss_freq: 0.041149
[07:01:00.545] iteration 25399: loss: 0.040665, loss_s1: 0.026090, loss_fp: 0.002410, loss_freq: 0.018305
[07:01:01.158] iteration 25400: loss: 0.034852, loss_s1: 0.020326, loss_fp: 0.010112, loss_freq: 0.019292
[07:01:04.454] iteration 25400 : mean_dice : 0.750717
[07:01:05.098] iteration 25401: loss: 0.066587, loss_s1: 0.052091, loss_fp: 0.007786, loss_freq: 0.035143
[07:01:05.737] iteration 25402: loss: 0.059389, loss_s1: 0.041971, loss_fp: 0.010053, loss_freq: 0.022761
[07:01:06.386] iteration 25403: loss: 0.050792, loss_s1: 0.046295, loss_fp: 0.002959, loss_freq: 0.027128
[07:01:07.003] iteration 25404: loss: 0.063420, loss_s1: 0.083586, loss_fp: 0.003480, loss_freq: 0.012017
[07:01:07.621] iteration 25405: loss: 0.060046, loss_s1: 0.072203, loss_fp: 0.004056, loss_freq: 0.018097
[07:01:08.224] iteration 25406: loss: 0.073974, loss_s1: 0.052039, loss_fp: 0.014437, loss_freq: 0.052720
[07:01:08.826] iteration 25407: loss: 0.041574, loss_s1: 0.031495, loss_fp: 0.002634, loss_freq: 0.015199
[07:01:09.436] iteration 25408: loss: 0.076130, loss_s1: 0.058745, loss_fp: 0.004151, loss_freq: 0.051622
[07:01:10.042] iteration 25409: loss: 0.043583, loss_s1: 0.027811, loss_fp: 0.003410, loss_freq: 0.030100
[07:01:10.653] iteration 25410: loss: 0.081573, loss_s1: 0.074013, loss_fp: 0.003776, loss_freq: 0.042737
[07:01:11.260] iteration 25411: loss: 0.033857, loss_s1: 0.023046, loss_fp: 0.005230, loss_freq: 0.006986
[07:01:11.865] iteration 25412: loss: 0.060326, loss_s1: 0.038279, loss_fp: 0.005282, loss_freq: 0.041765
[07:01:12.473] iteration 25413: loss: 0.049221, loss_s1: 0.048442, loss_fp: 0.001034, loss_freq: 0.020721
[07:01:13.078] iteration 25414: loss: 0.039233, loss_s1: 0.029226, loss_fp: 0.002215, loss_freq: 0.013235
[07:01:13.690] iteration 25415: loss: 0.065673, loss_s1: 0.055554, loss_fp: 0.003238, loss_freq: 0.023134
[07:01:14.312] iteration 25416: loss: 0.057361, loss_s1: 0.041427, loss_fp: 0.002357, loss_freq: 0.036294
[07:01:14.972] iteration 25417: loss: 0.041075, loss_s1: 0.025442, loss_fp: 0.007469, loss_freq: 0.028128
[07:01:15.633] iteration 25418: loss: 0.089127, loss_s1: 0.112999, loss_fp: 0.004802, loss_freq: 0.022979
[07:01:16.294] iteration 25419: loss: 0.052878, loss_s1: 0.050406, loss_fp: 0.006949, loss_freq: 0.019177
[07:01:16.952] iteration 25420: loss: 0.051754, loss_s1: 0.033045, loss_fp: 0.004080, loss_freq: 0.033549
[07:01:17.616] iteration 25421: loss: 0.064470, loss_s1: 0.055750, loss_fp: 0.004835, loss_freq: 0.036736
[07:01:18.288] iteration 25422: loss: 0.034778, loss_s1: 0.020476, loss_fp: 0.001573, loss_freq: 0.021032
[07:01:18.936] iteration 25423: loss: 0.064886, loss_s1: 0.046950, loss_fp: 0.004155, loss_freq: 0.032903
[07:01:19.568] iteration 25424: loss: 0.057841, loss_s1: 0.065644, loss_fp: 0.001732, loss_freq: 0.024928
[07:01:20.190] iteration 25425: loss: 0.038449, loss_s1: 0.021997, loss_fp: 0.012071, loss_freq: 0.014150
[07:01:20.834] iteration 25426: loss: 0.065626, loss_s1: 0.054396, loss_fp: 0.003466, loss_freq: 0.042082
[07:01:21.451] iteration 25427: loss: 0.072367, loss_s1: 0.076811, loss_fp: 0.005131, loss_freq: 0.031377
[07:01:22.087] iteration 25428: loss: 0.064136, loss_s1: 0.043768, loss_fp: 0.005212, loss_freq: 0.042384
[07:01:22.718] iteration 25429: loss: 0.069215, loss_s1: 0.075448, loss_fp: 0.008533, loss_freq: 0.031434
[07:01:23.340] iteration 25430: loss: 0.043024, loss_s1: 0.016670, loss_fp: 0.005648, loss_freq: 0.029214
[07:01:23.952] iteration 25431: loss: 0.048909, loss_s1: 0.056954, loss_fp: 0.001134, loss_freq: 0.016231
[07:01:24.603] iteration 25432: loss: 0.051776, loss_s1: 0.041279, loss_fp: 0.002573, loss_freq: 0.021058
[07:01:25.258] iteration 25433: loss: 0.049970, loss_s1: 0.031974, loss_fp: 0.010166, loss_freq: 0.030120
[07:01:25.914] iteration 25434: loss: 0.042329, loss_s1: 0.031342, loss_fp: 0.001698, loss_freq: 0.020324
[07:01:26.568] iteration 25435: loss: 0.028219, loss_s1: 0.017510, loss_fp: 0.003854, loss_freq: 0.009676
[07:01:27.187] iteration 25436: loss: 0.059521, loss_s1: 0.057764, loss_fp: 0.004712, loss_freq: 0.027170
[07:01:27.793] iteration 25437: loss: 0.044271, loss_s1: 0.026870, loss_fp: 0.007551, loss_freq: 0.021047
[07:01:28.397] iteration 25438: loss: 0.035936, loss_s1: 0.019656, loss_fp: 0.001452, loss_freq: 0.025983
[07:01:29.006] iteration 25439: loss: 0.065880, loss_s1: 0.024833, loss_fp: 0.013993, loss_freq: 0.052719
[07:01:29.623] iteration 25440: loss: 0.047537, loss_s1: 0.028837, loss_fp: 0.002924, loss_freq: 0.031417
[07:01:30.229] iteration 25441: loss: 0.042975, loss_s1: 0.036097, loss_fp: 0.005328, loss_freq: 0.010930
[07:01:30.842] iteration 25442: loss: 0.037914, loss_s1: 0.033604, loss_fp: 0.003027, loss_freq: 0.010150
[07:01:31.499] iteration 25443: loss: 0.060815, loss_s1: 0.046379, loss_fp: 0.014309, loss_freq: 0.036032
[07:01:32.157] iteration 25444: loss: 0.029170, loss_s1: 0.028114, loss_fp: 0.003624, loss_freq: 0.006302
[07:01:32.807] iteration 25445: loss: 0.103828, loss_s1: 0.069140, loss_fp: 0.009834, loss_freq: 0.094613
[07:01:33.421] iteration 25446: loss: 0.054847, loss_s1: 0.046506, loss_fp: 0.004477, loss_freq: 0.029738
[07:01:34.100] iteration 25447: loss: 0.065903, loss_s1: 0.045218, loss_fp: 0.003019, loss_freq: 0.036167
[07:01:34.761] iteration 25448: loss: 0.053490, loss_s1: 0.035716, loss_fp: 0.008316, loss_freq: 0.031790
[07:01:35.432] iteration 25449: loss: 0.034221, loss_s1: 0.020934, loss_fp: 0.007163, loss_freq: 0.011659
[07:01:36.109] iteration 25450: loss: 0.039259, loss_s1: 0.028975, loss_fp: 0.001416, loss_freq: 0.005914
[07:01:36.790] iteration 25451: loss: 0.035413, loss_s1: 0.032719, loss_fp: 0.001539, loss_freq: 0.006975
[07:01:37.721] iteration 25452: loss: 0.048729, loss_s1: 0.057242, loss_fp: 0.005190, loss_freq: 0.015305
[07:01:38.338] iteration 25453: loss: 0.052637, loss_s1: 0.029556, loss_fp: 0.002317, loss_freq: 0.038290
[07:01:38.950] iteration 25454: loss: 0.043978, loss_s1: 0.023550, loss_fp: 0.004530, loss_freq: 0.032294
[07:01:39.789] iteration 25455: loss: 0.047040, loss_s1: 0.012185, loss_fp: 0.005232, loss_freq: 0.042881
[07:01:40.653] iteration 25456: loss: 0.056318, loss_s1: 0.037375, loss_fp: 0.005276, loss_freq: 0.037890
[07:01:41.270] iteration 25457: loss: 0.083624, loss_s1: 0.082998, loss_fp: 0.002580, loss_freq: 0.062221
[07:01:42.127] iteration 25458: loss: 0.040127, loss_s1: 0.016410, loss_fp: 0.002420, loss_freq: 0.016291
[07:01:43.098] iteration 25459: loss: 0.036760, loss_s1: 0.031354, loss_fp: 0.003765, loss_freq: 0.015305
[07:01:44.041] iteration 25460: loss: 0.065801, loss_s1: 0.054422, loss_fp: 0.015824, loss_freq: 0.035993
[07:01:45.013] iteration 25461: loss: 0.034540, loss_s1: 0.038532, loss_fp: 0.001139, loss_freq: 0.008649
[07:01:45.683] iteration 25462: loss: 0.051169, loss_s1: 0.026174, loss_fp: 0.005078, loss_freq: 0.019213
[07:01:46.299] iteration 25463: loss: 0.090957, loss_s1: 0.110548, loss_fp: 0.006271, loss_freq: 0.030145
[07:01:46.914] iteration 25464: loss: 0.054095, loss_s1: 0.062158, loss_fp: 0.004117, loss_freq: 0.015457
[07:01:47.523] iteration 25465: loss: 0.077489, loss_s1: 0.086723, loss_fp: 0.007073, loss_freq: 0.028149
[07:01:48.139] iteration 25466: loss: 0.035724, loss_s1: 0.028678, loss_fp: 0.005194, loss_freq: 0.016204
[07:01:48.760] iteration 25467: loss: 0.064862, loss_s1: 0.061334, loss_fp: 0.004498, loss_freq: 0.024597
[07:01:49.375] iteration 25468: loss: 0.045693, loss_s1: 0.028517, loss_fp: 0.002144, loss_freq: 0.030604
[07:01:49.992] iteration 25469: loss: 0.091964, loss_s1: 0.094738, loss_fp: 0.004645, loss_freq: 0.053906
[07:01:50.605] iteration 25470: loss: 0.051298, loss_s1: 0.047116, loss_fp: 0.003732, loss_freq: 0.030766
[07:01:51.231] iteration 25471: loss: 0.044795, loss_s1: 0.022786, loss_fp: 0.008785, loss_freq: 0.026833
[07:01:52.045] iteration 25472: loss: 0.058185, loss_s1: 0.043381, loss_fp: 0.002259, loss_freq: 0.031080
[07:01:52.706] iteration 25473: loss: 0.047609, loss_s1: 0.037337, loss_fp: 0.003730, loss_freq: 0.018141
[07:01:53.372] iteration 25474: loss: 0.046715, loss_s1: 0.051576, loss_fp: 0.002638, loss_freq: 0.009409
[07:01:54.032] iteration 25475: loss: 0.030754, loss_s1: 0.018289, loss_fp: 0.001618, loss_freq: 0.017052
[07:01:54.654] iteration 25476: loss: 0.050332, loss_s1: 0.044129, loss_fp: 0.004044, loss_freq: 0.022697
[07:01:55.322] iteration 25477: loss: 0.045078, loss_s1: 0.033296, loss_fp: 0.004882, loss_freq: 0.015196
[07:01:55.931] iteration 25478: loss: 0.087143, loss_s1: 0.097999, loss_fp: 0.002911, loss_freq: 0.045571
[07:01:56.542] iteration 25479: loss: 0.053263, loss_s1: 0.027453, loss_fp: 0.003528, loss_freq: 0.045927
[07:01:57.150] iteration 25480: loss: 0.056667, loss_s1: 0.044975, loss_fp: 0.007846, loss_freq: 0.026095
[07:01:57.761] iteration 25481: loss: 0.051150, loss_s1: 0.032870, loss_fp: 0.006253, loss_freq: 0.027645
[07:01:58.373] iteration 25482: loss: 0.059317, loss_s1: 0.066091, loss_fp: 0.002447, loss_freq: 0.016242
[07:01:59.013] iteration 25483: loss: 0.049168, loss_s1: 0.037295, loss_fp: 0.007548, loss_freq: 0.029692
[07:01:59.623] iteration 25484: loss: 0.057196, loss_s1: 0.039354, loss_fp: 0.014059, loss_freq: 0.031093
[07:02:00.237] iteration 25485: loss: 0.070930, loss_s1: 0.064912, loss_fp: 0.003132, loss_freq: 0.038764
[07:02:00.847] iteration 25486: loss: 0.032550, loss_s1: 0.022337, loss_fp: 0.002670, loss_freq: 0.012351
[07:02:01.501] iteration 25487: loss: 0.032329, loss_s1: 0.022362, loss_fp: 0.004855, loss_freq: 0.014524
[07:02:02.471] iteration 25488: loss: 0.083454, loss_s1: 0.072265, loss_fp: 0.005183, loss_freq: 0.055098
[07:02:03.452] iteration 25489: loss: 0.080396, loss_s1: 0.061850, loss_fp: 0.009793, loss_freq: 0.060613
[07:02:04.276] iteration 25490: loss: 0.101573, loss_s1: 0.102332, loss_fp: 0.008626, loss_freq: 0.057703
[07:02:04.889] iteration 25491: loss: 0.071215, loss_s1: 0.089331, loss_fp: 0.004267, loss_freq: 0.016760
[07:02:05.501] iteration 25492: loss: 0.060657, loss_s1: 0.051853, loss_fp: 0.007469, loss_freq: 0.041931
[07:02:06.107] iteration 25493: loss: 0.042856, loss_s1: 0.029323, loss_fp: 0.001629, loss_freq: 0.014447
[07:02:06.717] iteration 25494: loss: 0.067510, loss_s1: 0.076893, loss_fp: 0.009137, loss_freq: 0.022216
[07:02:07.321] iteration 25495: loss: 0.039131, loss_s1: 0.017048, loss_fp: 0.005041, loss_freq: 0.026381
[07:02:07.929] iteration 25496: loss: 0.075341, loss_s1: 0.095595, loss_fp: 0.003147, loss_freq: 0.024429
[07:02:08.528] iteration 25497: loss: 0.061256, loss_s1: 0.046763, loss_fp: 0.003578, loss_freq: 0.043875
[07:02:09.131] iteration 25498: loss: 0.086918, loss_s1: 0.110610, loss_fp: 0.006619, loss_freq: 0.024043
[07:02:09.734] iteration 25499: loss: 0.093844, loss_s1: 0.106575, loss_fp: 0.003273, loss_freq: 0.044150
[07:02:10.335] iteration 25500: loss: 0.049809, loss_s1: 0.053408, loss_fp: 0.003108, loss_freq: 0.015579
[07:02:11.291] iteration 25501: loss: 0.064881, loss_s1: 0.061282, loss_fp: 0.002530, loss_freq: 0.022004
[07:02:11.892] iteration 25502: loss: 0.082462, loss_s1: 0.087422, loss_fp: 0.008292, loss_freq: 0.036312
[07:02:12.501] iteration 25503: loss: 0.056700, loss_s1: 0.058980, loss_fp: 0.004019, loss_freq: 0.021929
[07:02:13.106] iteration 25504: loss: 0.055908, loss_s1: 0.066543, loss_fp: 0.001847, loss_freq: 0.015060
[07:02:13.726] iteration 25505: loss: 0.068203, loss_s1: 0.074303, loss_fp: 0.006668, loss_freq: 0.019870
[07:02:14.331] iteration 25506: loss: 0.065949, loss_s1: 0.067952, loss_fp: 0.001547, loss_freq: 0.031132
[07:02:14.932] iteration 25507: loss: 0.070636, loss_s1: 0.072323, loss_fp: 0.002780, loss_freq: 0.022205
[07:02:15.536] iteration 25508: loss: 0.048228, loss_s1: 0.048486, loss_fp: 0.004832, loss_freq: 0.009368
[07:02:16.140] iteration 25509: loss: 0.032554, loss_s1: 0.028921, loss_fp: 0.003392, loss_freq: 0.010356
[07:02:16.747] iteration 25510: loss: 0.050120, loss_s1: 0.040043, loss_fp: 0.006872, loss_freq: 0.017008
[07:02:17.354] iteration 25511: loss: 0.054546, loss_s1: 0.031301, loss_fp: 0.001857, loss_freq: 0.034830
[07:02:17.957] iteration 25512: loss: 0.059937, loss_s1: 0.060980, loss_fp: 0.001975, loss_freq: 0.027532
[07:02:18.570] iteration 25513: loss: 0.056152, loss_s1: 0.052240, loss_fp: 0.003802, loss_freq: 0.028117
[07:02:19.176] iteration 25514: loss: 0.051239, loss_s1: 0.040586, loss_fp: 0.005374, loss_freq: 0.030032
[07:02:19.773] iteration 25515: loss: 0.058076, loss_s1: 0.068222, loss_fp: 0.002469, loss_freq: 0.010070
[07:02:20.373] iteration 25516: loss: 0.056974, loss_s1: 0.044762, loss_fp: 0.003133, loss_freq: 0.037198
[07:02:20.972] iteration 25517: loss: 0.106439, loss_s1: 0.133646, loss_fp: 0.004270, loss_freq: 0.053293
[07:02:21.576] iteration 25518: loss: 0.034859, loss_s1: 0.018803, loss_fp: 0.002868, loss_freq: 0.018568
[07:02:22.179] iteration 25519: loss: 0.086031, loss_s1: 0.092580, loss_fp: 0.005899, loss_freq: 0.043040
[07:02:22.785] iteration 25520: loss: 0.067298, loss_s1: 0.077799, loss_fp: 0.001780, loss_freq: 0.017515
[07:02:23.390] iteration 25521: loss: 0.037904, loss_s1: 0.019092, loss_fp: 0.001744, loss_freq: 0.022769
[07:02:24.007] iteration 25522: loss: 0.041972, loss_s1: 0.028189, loss_fp: 0.004496, loss_freq: 0.031595
[07:02:24.607] iteration 25523: loss: 0.060914, loss_s1: 0.045001, loss_fp: 0.003474, loss_freq: 0.025409
[07:02:25.208] iteration 25524: loss: 0.036222, loss_s1: 0.032426, loss_fp: 0.001509, loss_freq: 0.012135
[07:02:25.810] iteration 25525: loss: 0.059937, loss_s1: 0.023376, loss_fp: 0.007297, loss_freq: 0.054834
[07:02:26.416] iteration 25526: loss: 0.071353, loss_s1: 0.090461, loss_fp: 0.002875, loss_freq: 0.026274
[07:02:27.016] iteration 25527: loss: 0.059435, loss_s1: 0.048536, loss_fp: 0.001449, loss_freq: 0.017913
[07:02:27.616] iteration 25528: loss: 0.057646, loss_s1: 0.036305, loss_fp: 0.008452, loss_freq: 0.037040
[07:02:28.214] iteration 25529: loss: 0.041999, loss_s1: 0.020039, loss_fp: 0.005750, loss_freq: 0.032785
[07:02:28.821] iteration 25530: loss: 0.085073, loss_s1: 0.097435, loss_fp: 0.001230, loss_freq: 0.040073
[07:02:29.426] iteration 25531: loss: 0.075126, loss_s1: 0.065261, loss_fp: 0.004516, loss_freq: 0.061513
[07:02:30.022] iteration 25532: loss: 0.084748, loss_s1: 0.062097, loss_fp: 0.006994, loss_freq: 0.065318
[07:02:30.621] iteration 25533: loss: 0.044052, loss_s1: 0.030129, loss_fp: 0.002966, loss_freq: 0.024470
[07:02:31.222] iteration 25534: loss: 0.044648, loss_s1: 0.047516, loss_fp: 0.001441, loss_freq: 0.007054
[07:02:31.822] iteration 25535: loss: 0.050625, loss_s1: 0.048167, loss_fp: 0.001759, loss_freq: 0.031183
[07:02:32.416] iteration 25536: loss: 0.045232, loss_s1: 0.019085, loss_fp: 0.003676, loss_freq: 0.015599
[07:02:33.013] iteration 25537: loss: 0.046953, loss_s1: 0.027402, loss_fp: 0.003068, loss_freq: 0.026742
[07:02:33.614] iteration 25538: loss: 0.043334, loss_s1: 0.035968, loss_fp: 0.002721, loss_freq: 0.011460
[07:02:34.222] iteration 25539: loss: 0.074055, loss_s1: 0.077689, loss_fp: 0.007290, loss_freq: 0.030552
[07:02:34.816] iteration 25540: loss: 0.107234, loss_s1: 0.119089, loss_fp: 0.006429, loss_freq: 0.050716
[07:02:35.416] iteration 25541: loss: 0.057643, loss_s1: 0.040275, loss_fp: 0.002193, loss_freq: 0.029005
[07:02:36.011] iteration 25542: loss: 0.062559, loss_s1: 0.054182, loss_fp: 0.005480, loss_freq: 0.032833
[07:02:36.606] iteration 25543: loss: 0.082507, loss_s1: 0.086196, loss_fp: 0.005349, loss_freq: 0.050486
[07:02:37.208] iteration 25544: loss: 0.084055, loss_s1: 0.065205, loss_fp: 0.002903, loss_freq: 0.078535
[07:02:37.811] iteration 25545: loss: 0.054116, loss_s1: 0.033576, loss_fp: 0.006704, loss_freq: 0.035177
[07:02:38.407] iteration 25546: loss: 0.086989, loss_s1: 0.086915, loss_fp: 0.005884, loss_freq: 0.053331
[07:02:39.007] iteration 25547: loss: 0.066530, loss_s1: 0.050099, loss_fp: 0.004916, loss_freq: 0.041609
[07:02:39.606] iteration 25548: loss: 0.046070, loss_s1: 0.031724, loss_fp: 0.005693, loss_freq: 0.023379
[07:02:40.202] iteration 25549: loss: 0.031699, loss_s1: 0.026715, loss_fp: 0.004609, loss_freq: 0.006720
[07:02:40.803] iteration 25550: loss: 0.034089, loss_s1: 0.022945, loss_fp: 0.002167, loss_freq: 0.010129
[07:02:41.398] iteration 25551: loss: 0.039950, loss_s1: 0.022566, loss_fp: 0.003065, loss_freq: 0.021582
[07:02:41.995] iteration 25552: loss: 0.056009, loss_s1: 0.056045, loss_fp: 0.005855, loss_freq: 0.026204
[07:02:42.591] iteration 25553: loss: 0.063312, loss_s1: 0.075028, loss_fp: 0.001327, loss_freq: 0.018307
[07:02:43.193] iteration 25554: loss: 0.057015, loss_s1: 0.047483, loss_fp: 0.010804, loss_freq: 0.024165
[07:02:43.792] iteration 25555: loss: 0.058547, loss_s1: 0.033109, loss_fp: 0.008946, loss_freq: 0.039575
[07:02:44.391] iteration 25556: loss: 0.043679, loss_s1: 0.024229, loss_fp: 0.002491, loss_freq: 0.028859
[07:02:45.003] iteration 25557: loss: 0.073884, loss_s1: 0.047288, loss_fp: 0.017956, loss_freq: 0.052264
[07:02:45.606] iteration 25558: loss: 0.043421, loss_s1: 0.028691, loss_fp: 0.000509, loss_freq: 0.019929
[07:02:46.214] iteration 25559: loss: 0.045497, loss_s1: 0.035222, loss_fp: 0.002056, loss_freq: 0.023032
[07:02:46.822] iteration 25560: loss: 0.047223, loss_s1: 0.033797, loss_fp: 0.003557, loss_freq: 0.030071
[07:02:47.423] iteration 25561: loss: 0.019250, loss_s1: 0.006248, loss_fp: 0.002238, loss_freq: 0.005442
[07:02:48.022] iteration 25562: loss: 0.046335, loss_s1: 0.025200, loss_fp: 0.001326, loss_freq: 0.026560
[07:02:48.627] iteration 25563: loss: 0.056202, loss_s1: 0.055623, loss_fp: 0.003539, loss_freq: 0.019111
[07:02:49.223] iteration 25564: loss: 0.032644, loss_s1: 0.020129, loss_fp: 0.002458, loss_freq: 0.015224
[07:02:49.825] iteration 25565: loss: 0.035981, loss_s1: 0.026593, loss_fp: 0.003236, loss_freq: 0.009178
[07:02:50.431] iteration 25566: loss: 0.053674, loss_s1: 0.064898, loss_fp: 0.001195, loss_freq: 0.013642
[07:02:51.032] iteration 25567: loss: 0.039103, loss_s1: 0.017559, loss_fp: 0.002062, loss_freq: 0.018574
[07:02:51.631] iteration 25568: loss: 0.115495, loss_s1: 0.094186, loss_fp: 0.012610, loss_freq: 0.098715
[07:02:52.238] iteration 25569: loss: 0.044671, loss_s1: 0.045999, loss_fp: 0.002236, loss_freq: 0.013312
[07:02:52.840] iteration 25570: loss: 0.053016, loss_s1: 0.054027, loss_fp: 0.003506, loss_freq: 0.027085
[07:02:53.450] iteration 25571: loss: 0.068251, loss_s1: 0.073181, loss_fp: 0.002969, loss_freq: 0.026013
[07:02:54.059] iteration 25572: loss: 0.051751, loss_s1: 0.034942, loss_fp: 0.001690, loss_freq: 0.036953
[07:02:54.659] iteration 25573: loss: 0.042473, loss_s1: 0.038818, loss_fp: 0.001916, loss_freq: 0.018293
[07:02:55.278] iteration 25574: loss: 0.054750, loss_s1: 0.050963, loss_fp: 0.002472, loss_freq: 0.028561
[07:02:55.877] iteration 25575: loss: 0.068473, loss_s1: 0.034286, loss_fp: 0.003291, loss_freq: 0.067357
[07:02:56.485] iteration 25576: loss: 0.061717, loss_s1: 0.033203, loss_fp: 0.002855, loss_freq: 0.052878
[07:02:57.084] iteration 25577: loss: 0.035765, loss_s1: 0.021500, loss_fp: 0.001695, loss_freq: 0.018677
[07:02:57.682] iteration 25578: loss: 0.078948, loss_s1: 0.057657, loss_fp: 0.010777, loss_freq: 0.052618
[07:02:58.280] iteration 25579: loss: 0.055134, loss_s1: 0.031718, loss_fp: 0.013295, loss_freq: 0.040599
[07:02:58.877] iteration 25580: loss: 0.073652, loss_s1: 0.064134, loss_fp: 0.003659, loss_freq: 0.038469
[07:02:59.476] iteration 25581: loss: 0.049388, loss_s1: 0.047317, loss_fp: 0.008629, loss_freq: 0.005081
[07:03:00.074] iteration 25582: loss: 0.051070, loss_s1: 0.037008, loss_fp: 0.005728, loss_freq: 0.030276
[07:03:00.670] iteration 25583: loss: 0.049599, loss_s1: 0.044557, loss_fp: 0.001275, loss_freq: 0.021562
[07:03:01.276] iteration 25584: loss: 0.042605, loss_s1: 0.037843, loss_fp: 0.005759, loss_freq: 0.010581
[07:03:01.876] iteration 25585: loss: 0.067624, loss_s1: 0.056942, loss_fp: 0.005974, loss_freq: 0.038559
[07:03:02.479] iteration 25586: loss: 0.051540, loss_s1: 0.034365, loss_fp: 0.002131, loss_freq: 0.029875
[07:03:03.082] iteration 25587: loss: 0.081391, loss_s1: 0.111844, loss_fp: 0.002471, loss_freq: 0.028789
[07:03:03.683] iteration 25588: loss: 0.042343, loss_s1: 0.023956, loss_fp: 0.013785, loss_freq: 0.013907
[07:03:04.283] iteration 25589: loss: 0.034531, loss_s1: 0.019601, loss_fp: 0.005526, loss_freq: 0.014943
[07:03:04.886] iteration 25590: loss: 0.034259, loss_s1: 0.024939, loss_fp: 0.002004, loss_freq: 0.010855
[07:03:05.491] iteration 25591: loss: 0.077194, loss_s1: 0.060307, loss_fp: 0.005092, loss_freq: 0.044637
[07:03:06.103] iteration 25592: loss: 0.043321, loss_s1: 0.037763, loss_fp: 0.002036, loss_freq: 0.028875
[07:03:06.707] iteration 25593: loss: 0.046570, loss_s1: 0.041177, loss_fp: 0.003659, loss_freq: 0.011784
[07:03:07.310] iteration 25594: loss: 0.043853, loss_s1: 0.041915, loss_fp: 0.003050, loss_freq: 0.020812
[07:03:07.923] iteration 25595: loss: 0.060370, loss_s1: 0.051621, loss_fp: 0.006123, loss_freq: 0.035945
[07:03:08.527] iteration 25596: loss: 0.060377, loss_s1: 0.069077, loss_fp: 0.005413, loss_freq: 0.024122
[07:03:09.149] iteration 25597: loss: 0.077657, loss_s1: 0.071277, loss_fp: 0.002240, loss_freq: 0.046674
[07:03:09.764] iteration 25598: loss: 0.042074, loss_s1: 0.023090, loss_fp: 0.002581, loss_freq: 0.024679
[07:03:10.377] iteration 25599: loss: 0.059436, loss_s1: 0.045658, loss_fp: 0.016488, loss_freq: 0.028877
[07:03:10.988] iteration 25600: loss: 0.042622, loss_s1: 0.031045, loss_fp: 0.004990, loss_freq: 0.013745
[07:03:14.863] iteration 25600 : mean_dice : 0.744518
[07:03:15.606] iteration 25601: loss: 0.055226, loss_s1: 0.057483, loss_fp: 0.005147, loss_freq: 0.025915
[07:03:16.347] iteration 25602: loss: 0.050375, loss_s1: 0.034846, loss_fp: 0.001381, loss_freq: 0.021988
[07:03:17.016] iteration 25603: loss: 0.046280, loss_s1: 0.024337, loss_fp: 0.005092, loss_freq: 0.026946
[07:03:17.842] iteration 25604: loss: 0.049968, loss_s1: 0.040779, loss_fp: 0.002563, loss_freq: 0.028623
[07:03:18.602] iteration 25605: loss: 0.028124, loss_s1: 0.020847, loss_fp: 0.004330, loss_freq: 0.012581
[07:03:19.353] iteration 25606: loss: 0.056017, loss_s1: 0.043541, loss_fp: 0.005681, loss_freq: 0.032447
[07:03:20.051] iteration 25607: loss: 0.043208, loss_s1: 0.038210, loss_fp: 0.001323, loss_freq: 0.012446
[07:03:20.771] iteration 25608: loss: 0.037360, loss_s1: 0.030779, loss_fp: 0.002364, loss_freq: 0.015591
[07:03:21.444] iteration 25609: loss: 0.041154, loss_s1: 0.027712, loss_fp: 0.005232, loss_freq: 0.019177
[07:03:22.126] iteration 25610: loss: 0.063746, loss_s1: 0.053611, loss_fp: 0.002735, loss_freq: 0.041954
[07:03:22.918] iteration 25611: loss: 0.069600, loss_s1: 0.066074, loss_fp: 0.014659, loss_freq: 0.024618
[07:03:23.571] iteration 25612: loss: 0.045514, loss_s1: 0.036941, loss_fp: 0.003912, loss_freq: 0.015603
[07:03:24.307] iteration 25613: loss: 0.054150, loss_s1: 0.030436, loss_fp: 0.018246, loss_freq: 0.036377
[07:03:25.021] iteration 25614: loss: 0.032674, loss_s1: 0.025837, loss_fp: 0.004398, loss_freq: 0.006710
[07:03:25.708] iteration 25615: loss: 0.063350, loss_s1: 0.043028, loss_fp: 0.009062, loss_freq: 0.037067
[07:03:26.359] iteration 25616: loss: 0.067747, loss_s1: 0.057990, loss_fp: 0.005976, loss_freq: 0.044512
[07:03:26.992] iteration 25617: loss: 0.042514, loss_s1: 0.043389, loss_fp: 0.003403, loss_freq: 0.008428
[07:03:27.602] iteration 25618: loss: 0.039083, loss_s1: 0.026942, loss_fp: 0.003296, loss_freq: 0.019930
[07:03:28.211] iteration 25619: loss: 0.038802, loss_s1: 0.029895, loss_fp: 0.002625, loss_freq: 0.016125
[07:03:28.824] iteration 25620: loss: 0.049750, loss_s1: 0.044776, loss_fp: 0.001874, loss_freq: 0.021478
[07:03:29.445] iteration 25621: loss: 0.053628, loss_s1: 0.055799, loss_fp: 0.004804, loss_freq: 0.012150
[07:03:30.059] iteration 25622: loss: 0.053718, loss_s1: 0.062993, loss_fp: 0.002994, loss_freq: 0.023781
[07:03:30.675] iteration 25623: loss: 0.102043, loss_s1: 0.098621, loss_fp: 0.011722, loss_freq: 0.061228
[07:03:31.321] iteration 25624: loss: 0.049785, loss_s1: 0.055011, loss_fp: 0.006342, loss_freq: 0.012799
[07:03:31.940] iteration 25625: loss: 0.084533, loss_s1: 0.077393, loss_fp: 0.006158, loss_freq: 0.052537
[07:03:32.549] iteration 25626: loss: 0.056917, loss_s1: 0.042417, loss_fp: 0.004162, loss_freq: 0.034434
[07:03:33.167] iteration 25627: loss: 0.072636, loss_s1: 0.091561, loss_fp: 0.001487, loss_freq: 0.030658
[07:03:33.784] iteration 25628: loss: 0.040965, loss_s1: 0.029981, loss_fp: 0.004676, loss_freq: 0.012347
[07:03:34.401] iteration 25629: loss: 0.038451, loss_s1: 0.022998, loss_fp: 0.009351, loss_freq: 0.021255
[07:03:35.013] iteration 25630: loss: 0.041522, loss_s1: 0.032554, loss_fp: 0.004442, loss_freq: 0.015285
[07:03:35.627] iteration 25631: loss: 0.055640, loss_s1: 0.056952, loss_fp: 0.005843, loss_freq: 0.023771
[07:03:36.245] iteration 25632: loss: 0.077868, loss_s1: 0.054182, loss_fp: 0.004160, loss_freq: 0.033034
[07:03:36.861] iteration 25633: loss: 0.061216, loss_s1: 0.040897, loss_fp: 0.003123, loss_freq: 0.048044
[07:03:37.482] iteration 25634: loss: 0.070788, loss_s1: 0.062329, loss_fp: 0.001588, loss_freq: 0.052545
[07:03:38.093] iteration 25635: loss: 0.064874, loss_s1: 0.067210, loss_fp: 0.002302, loss_freq: 0.022589
[07:03:38.704] iteration 25636: loss: 0.039662, loss_s1: 0.042218, loss_fp: 0.001880, loss_freq: 0.006841
[07:03:39.324] iteration 25637: loss: 0.055729, loss_s1: 0.047650, loss_fp: 0.001125, loss_freq: 0.014445
[07:03:39.933] iteration 25638: loss: 0.059073, loss_s1: 0.028121, loss_fp: 0.006557, loss_freq: 0.050363
[07:03:40.547] iteration 25639: loss: 0.079436, loss_s1: 0.084840, loss_fp: 0.003544, loss_freq: 0.041714
[07:03:41.340] iteration 25640: loss: 0.051465, loss_s1: 0.039513, loss_fp: 0.006000, loss_freq: 0.038318
[07:03:42.206] iteration 25641: loss: 0.053594, loss_s1: 0.030644, loss_fp: 0.004301, loss_freq: 0.039808
[07:03:43.066] iteration 25642: loss: 0.085566, loss_s1: 0.100982, loss_fp: 0.006557, loss_freq: 0.025113
[07:03:43.718] iteration 25643: loss: 0.032325, loss_s1: 0.012940, loss_fp: 0.000854, loss_freq: 0.023388
[07:03:44.359] iteration 25644: loss: 0.034536, loss_s1: 0.027055, loss_fp: 0.003102, loss_freq: 0.009148
[07:03:44.974] iteration 25645: loss: 0.023990, loss_s1: 0.012094, loss_fp: 0.002476, loss_freq: 0.008213
[07:03:45.599] iteration 25646: loss: 0.045522, loss_s1: 0.036434, loss_fp: 0.002113, loss_freq: 0.017962
[07:03:46.206] iteration 25647: loss: 0.041206, loss_s1: 0.027479, loss_fp: 0.002694, loss_freq: 0.018988
[07:03:46.819] iteration 25648: loss: 0.068409, loss_s1: 0.055793, loss_fp: 0.006550, loss_freq: 0.048238
[07:03:47.430] iteration 25649: loss: 0.066153, loss_s1: 0.053234, loss_fp: 0.004609, loss_freq: 0.050723
[07:03:48.043] iteration 25650: loss: 0.061700, loss_s1: 0.049315, loss_fp: 0.007642, loss_freq: 0.030228
[07:03:48.654] iteration 25651: loss: 0.084369, loss_s1: 0.095423, loss_fp: 0.011781, loss_freq: 0.029170
[07:03:49.268] iteration 25652: loss: 0.050465, loss_s1: 0.045805, loss_fp: 0.002564, loss_freq: 0.019965
[07:03:49.877] iteration 25653: loss: 0.068672, loss_s1: 0.070770, loss_fp: 0.003645, loss_freq: 0.029711
[07:03:50.489] iteration 25654: loss: 0.086765, loss_s1: 0.094148, loss_fp: 0.009285, loss_freq: 0.044488
[07:03:51.097] iteration 25655: loss: 0.060898, loss_s1: 0.035760, loss_fp: 0.005031, loss_freq: 0.039659
[07:03:51.711] iteration 25656: loss: 0.028422, loss_s1: 0.017634, loss_fp: 0.002112, loss_freq: 0.011317
[07:03:52.320] iteration 25657: loss: 0.029954, loss_s1: 0.028828, loss_fp: 0.003016, loss_freq: 0.008171
[07:03:52.969] iteration 25658: loss: 0.081910, loss_s1: 0.086407, loss_fp: 0.001902, loss_freq: 0.047465
[07:03:53.628] iteration 25659: loss: 0.062470, loss_s1: 0.044434, loss_fp: 0.010131, loss_freq: 0.039501
[07:03:54.288] iteration 25660: loss: 0.077620, loss_s1: 0.067411, loss_fp: 0.007943, loss_freq: 0.047555
[07:03:54.955] iteration 25661: loss: 0.036723, loss_s1: 0.028808, loss_fp: 0.002889, loss_freq: 0.008685
[07:03:55.613] iteration 25662: loss: 0.053552, loss_s1: 0.052536, loss_fp: 0.008443, loss_freq: 0.022681
[07:03:56.268] iteration 25663: loss: 0.036727, loss_s1: 0.023964, loss_fp: 0.002223, loss_freq: 0.004790
[07:03:56.874] iteration 25664: loss: 0.055248, loss_s1: 0.052588, loss_fp: 0.003526, loss_freq: 0.025131
[07:03:57.536] iteration 25665: loss: 0.027260, loss_s1: 0.014126, loss_fp: 0.002952, loss_freq: 0.010123
[07:03:58.137] iteration 25666: loss: 0.083737, loss_s1: 0.103385, loss_fp: 0.010132, loss_freq: 0.033338
[07:03:58.744] iteration 25667: loss: 0.074078, loss_s1: 0.081402, loss_fp: 0.001667, loss_freq: 0.037219
[07:03:59.395] iteration 25668: loss: 0.067058, loss_s1: 0.071285, loss_fp: 0.005705, loss_freq: 0.028310
[07:04:00.050] iteration 25669: loss: 0.085864, loss_s1: 0.069774, loss_fp: 0.004918, loss_freq: 0.063540
[07:04:00.664] iteration 25670: loss: 0.059055, loss_s1: 0.029656, loss_fp: 0.005710, loss_freq: 0.049112
[07:04:01.714] iteration 25671: loss: 0.059865, loss_s1: 0.031698, loss_fp: 0.002564, loss_freq: 0.051222
[07:04:02.321] iteration 25672: loss: 0.045179, loss_s1: 0.033026, loss_fp: 0.006579, loss_freq: 0.016845
[07:04:02.926] iteration 25673: loss: 0.072249, loss_s1: 0.077036, loss_fp: 0.004752, loss_freq: 0.035213
[07:04:03.551] iteration 25674: loss: 0.040609, loss_s1: 0.037628, loss_fp: 0.001741, loss_freq: 0.012465
[07:04:04.159] iteration 25675: loss: 0.069100, loss_s1: 0.089306, loss_fp: 0.001887, loss_freq: 0.021871
[07:04:04.778] iteration 25676: loss: 0.058855, loss_s1: 0.027276, loss_fp: 0.001341, loss_freq: 0.055663
[07:04:05.433] iteration 25677: loss: 0.043536, loss_s1: 0.030008, loss_fp: 0.001339, loss_freq: 0.025288
[07:04:06.237] iteration 25678: loss: 0.058179, loss_s1: 0.042929, loss_fp: 0.004641, loss_freq: 0.027669
[07:04:06.911] iteration 25679: loss: 0.048627, loss_s1: 0.034086, loss_fp: 0.003763, loss_freq: 0.030950
[07:04:07.621] iteration 25680: loss: 0.058779, loss_s1: 0.055428, loss_fp: 0.003416, loss_freq: 0.025190
[07:04:08.299] iteration 25681: loss: 0.063944, loss_s1: 0.053927, loss_fp: 0.002086, loss_freq: 0.039727
[07:04:08.910] iteration 25682: loss: 0.086936, loss_s1: 0.071946, loss_fp: 0.001701, loss_freq: 0.073770
[07:04:09.516] iteration 25683: loss: 0.037732, loss_s1: 0.015682, loss_fp: 0.003515, loss_freq: 0.030221
[07:04:10.198] iteration 25684: loss: 0.059945, loss_s1: 0.044266, loss_fp: 0.008574, loss_freq: 0.030901
[07:04:10.858] iteration 25685: loss: 0.053850, loss_s1: 0.053096, loss_fp: 0.003129, loss_freq: 0.015746
[07:04:11.512] iteration 25686: loss: 0.047489, loss_s1: 0.028539, loss_fp: 0.026640, loss_freq: 0.012674
[07:04:12.167] iteration 25687: loss: 0.127374, loss_s1: 0.123640, loss_fp: 0.002911, loss_freq: 0.109294
[07:04:12.794] iteration 25688: loss: 0.035667, loss_s1: 0.029916, loss_fp: 0.001555, loss_freq: 0.013590
[07:04:13.414] iteration 25689: loss: 0.079066, loss_s1: 0.095568, loss_fp: 0.004410, loss_freq: 0.032619
[07:04:14.026] iteration 25690: loss: 0.065309, loss_s1: 0.061028, loss_fp: 0.002188, loss_freq: 0.027969
[07:04:14.635] iteration 25691: loss: 0.054439, loss_s1: 0.024978, loss_fp: 0.002395, loss_freq: 0.043098
[07:04:15.245] iteration 25692: loss: 0.040365, loss_s1: 0.032647, loss_fp: 0.007113, loss_freq: 0.021565
[07:04:15.862] iteration 25693: loss: 0.046675, loss_s1: 0.030325, loss_fp: 0.003339, loss_freq: 0.026015
[07:04:16.468] iteration 25694: loss: 0.045551, loss_s1: 0.038766, loss_fp: 0.002145, loss_freq: 0.025716
[07:04:17.075] iteration 25695: loss: 0.077439, loss_s1: 0.071996, loss_fp: 0.003136, loss_freq: 0.052900
[07:04:17.677] iteration 25696: loss: 0.045572, loss_s1: 0.039425, loss_fp: 0.001452, loss_freq: 0.029386
[07:04:18.279] iteration 25697: loss: 0.038589, loss_s1: 0.024970, loss_fp: 0.001836, loss_freq: 0.019745
[07:04:18.883] iteration 25698: loss: 0.092432, loss_s1: 0.101844, loss_fp: 0.002300, loss_freq: 0.049122
[07:04:19.496] iteration 25699: loss: 0.051458, loss_s1: 0.048057, loss_fp: 0.005538, loss_freq: 0.023960
[07:04:20.100] iteration 25700: loss: 0.091369, loss_s1: 0.123379, loss_fp: 0.005641, loss_freq: 0.022832
[07:04:20.706] iteration 25701: loss: 0.066552, loss_s1: 0.058442, loss_fp: 0.003049, loss_freq: 0.050776
[07:04:21.362] iteration 25702: loss: 0.078639, loss_s1: 0.072118, loss_fp: 0.005015, loss_freq: 0.043858
[07:04:22.038] iteration 25703: loss: 0.101394, loss_s1: 0.114598, loss_fp: 0.010499, loss_freq: 0.048977
[07:04:22.691] iteration 25704: loss: 0.048868, loss_s1: 0.039736, loss_fp: 0.001556, loss_freq: 0.018039
[07:04:23.324] iteration 25705: loss: 0.051468, loss_s1: 0.052735, loss_fp: 0.001990, loss_freq: 0.029209
[07:04:23.932] iteration 25706: loss: 0.040908, loss_s1: 0.019681, loss_fp: 0.001751, loss_freq: 0.013512
[07:04:24.540] iteration 25707: loss: 0.046073, loss_s1: 0.029973, loss_fp: 0.002105, loss_freq: 0.030452
[07:04:25.231] iteration 25708: loss: 0.059037, loss_s1: 0.072044, loss_fp: 0.003040, loss_freq: 0.015818
[07:04:25.890] iteration 25709: loss: 0.068940, loss_s1: 0.077588, loss_fp: 0.003635, loss_freq: 0.027249
[07:04:26.547] iteration 25710: loss: 0.054041, loss_s1: 0.040347, loss_fp: 0.003614, loss_freq: 0.028445
[07:04:27.205] iteration 25711: loss: 0.091392, loss_s1: 0.072629, loss_fp: 0.004048, loss_freq: 0.066161
[07:04:27.875] iteration 25712: loss: 0.064275, loss_s1: 0.061398, loss_fp: 0.010932, loss_freq: 0.024309
[07:04:28.496] iteration 25713: loss: 0.095408, loss_s1: 0.100434, loss_fp: 0.006622, loss_freq: 0.053695
[07:04:29.115] iteration 25714: loss: 0.067078, loss_s1: 0.054506, loss_fp: 0.003312, loss_freq: 0.049590
[07:04:29.748] iteration 25715: loss: 0.068242, loss_s1: 0.058217, loss_fp: 0.002888, loss_freq: 0.036826
[07:04:30.368] iteration 25716: loss: 0.069318, loss_s1: 0.063222, loss_fp: 0.010271, loss_freq: 0.032686
[07:04:30.982] iteration 25717: loss: 0.043702, loss_s1: 0.038900, loss_fp: 0.003846, loss_freq: 0.017748
[07:04:31.598] iteration 25718: loss: 0.057562, loss_s1: 0.033700, loss_fp: 0.003516, loss_freq: 0.048554
[07:04:32.208] iteration 25719: loss: 0.059316, loss_s1: 0.058812, loss_fp: 0.002328, loss_freq: 0.020201
[07:04:32.828] iteration 25720: loss: 0.046891, loss_s1: 0.046906, loss_fp: 0.000802, loss_freq: 0.009030
[07:04:33.443] iteration 25721: loss: 0.035946, loss_s1: 0.018456, loss_fp: 0.001018, loss_freq: 0.022141
[07:04:34.055] iteration 25722: loss: 0.067387, loss_s1: 0.091649, loss_fp: 0.003719, loss_freq: 0.015775
[07:04:34.705] iteration 25723: loss: 0.036323, loss_s1: 0.024992, loss_fp: 0.005549, loss_freq: 0.014315
[07:04:35.317] iteration 25724: loss: 0.084872, loss_s1: 0.071942, loss_fp: 0.012429, loss_freq: 0.055813
[07:04:35.934] iteration 25725: loss: 0.054526, loss_s1: 0.052063, loss_fp: 0.003183, loss_freq: 0.021435
[07:04:36.546] iteration 25726: loss: 0.034257, loss_s1: 0.024890, loss_fp: 0.002259, loss_freq: 0.011092
[07:04:37.160] iteration 25727: loss: 0.037784, loss_s1: 0.020958, loss_fp: 0.002343, loss_freq: 0.028292
[07:04:37.769] iteration 25728: loss: 0.058972, loss_s1: 0.058160, loss_fp: 0.000344, loss_freq: 0.017261
[07:04:38.376] iteration 25729: loss: 0.037213, loss_s1: 0.015665, loss_fp: 0.002503, loss_freq: 0.030816
[07:04:38.983] iteration 25730: loss: 0.083308, loss_s1: 0.098340, loss_fp: 0.004679, loss_freq: 0.037476
[07:04:39.593] iteration 25731: loss: 0.032143, loss_s1: 0.033982, loss_fp: 0.001783, loss_freq: 0.005555
[07:04:40.203] iteration 25732: loss: 0.066526, loss_s1: 0.050592, loss_fp: 0.003541, loss_freq: 0.035859
[07:04:40.816] iteration 25733: loss: 0.040990, loss_s1: 0.030697, loss_fp: 0.003540, loss_freq: 0.007902
[07:04:41.421] iteration 25734: loss: 0.032961, loss_s1: 0.019039, loss_fp: 0.002306, loss_freq: 0.019917
[07:04:42.028] iteration 25735: loss: 0.070121, loss_s1: 0.080375, loss_fp: 0.004362, loss_freq: 0.021933
[07:04:42.632] iteration 25736: loss: 0.042335, loss_s1: 0.029986, loss_fp: 0.002705, loss_freq: 0.032973
[07:04:43.237] iteration 25737: loss: 0.035690, loss_s1: 0.014992, loss_fp: 0.002081, loss_freq: 0.013592
[07:04:43.848] iteration 25738: loss: 0.080330, loss_s1: 0.066699, loss_fp: 0.007020, loss_freq: 0.057470
[07:04:44.459] iteration 25739: loss: 0.050541, loss_s1: 0.031052, loss_fp: 0.002028, loss_freq: 0.041151
[07:04:45.094] iteration 25740: loss: 0.044877, loss_s1: 0.036358, loss_fp: 0.001209, loss_freq: 0.024637
[07:04:45.770] iteration 25741: loss: 0.082273, loss_s1: 0.071104, loss_fp: 0.003096, loss_freq: 0.031701
[07:04:46.441] iteration 25742: loss: 0.042222, loss_s1: 0.028418, loss_fp: 0.003791, loss_freq: 0.021740
[07:04:47.097] iteration 25743: loss: 0.067074, loss_s1: 0.068645, loss_fp: 0.008876, loss_freq: 0.030304
[07:04:47.780] iteration 25744: loss: 0.039915, loss_s1: 0.029752, loss_fp: 0.001707, loss_freq: 0.019069
[07:04:48.411] iteration 25745: loss: 0.067036, loss_s1: 0.032257, loss_fp: 0.002211, loss_freq: 0.065773
[07:04:49.071] iteration 25746: loss: 0.083360, loss_s1: 0.080053, loss_fp: 0.003408, loss_freq: 0.051147
[07:04:49.729] iteration 25747: loss: 0.038937, loss_s1: 0.017548, loss_fp: 0.002603, loss_freq: 0.020945
[07:04:50.382] iteration 25748: loss: 0.066365, loss_s1: 0.068837, loss_fp: 0.002982, loss_freq: 0.029165
[07:04:51.049] iteration 25749: loss: 0.044055, loss_s1: 0.031833, loss_fp: 0.007710, loss_freq: 0.022830
[07:04:51.657] iteration 25750: loss: 0.077239, loss_s1: 0.084534, loss_fp: 0.002629, loss_freq: 0.031370
[07:04:52.272] iteration 25751: loss: 0.056512, loss_s1: 0.041390, loss_fp: 0.005417, loss_freq: 0.017766
[07:04:52.900] iteration 25752: loss: 0.048190, loss_s1: 0.025078, loss_fp: 0.005143, loss_freq: 0.035810
[07:04:53.528] iteration 25753: loss: 0.052222, loss_s1: 0.046725, loss_fp: 0.011126, loss_freq: 0.015636
[07:04:54.151] iteration 25754: loss: 0.035283, loss_s1: 0.018446, loss_fp: 0.002342, loss_freq: 0.016370
[07:04:54.780] iteration 25755: loss: 0.053533, loss_s1: 0.046635, loss_fp: 0.008639, loss_freq: 0.019236
[07:04:55.408] iteration 25756: loss: 0.047755, loss_s1: 0.025733, loss_fp: 0.001866, loss_freq: 0.032631
[07:04:56.048] iteration 25757: loss: 0.054442, loss_s1: 0.067900, loss_fp: 0.003167, loss_freq: 0.017225
[07:04:56.675] iteration 25758: loss: 0.071436, loss_s1: 0.086057, loss_fp: 0.005177, loss_freq: 0.022711
[07:04:57.297] iteration 25759: loss: 0.067309, loss_s1: 0.069442, loss_fp: 0.001995, loss_freq: 0.037006
[07:04:57.932] iteration 25760: loss: 0.039937, loss_s1: 0.024939, loss_fp: 0.004464, loss_freq: 0.011372
[07:04:58.566] iteration 25761: loss: 0.081494, loss_s1: 0.091852, loss_fp: 0.002554, loss_freq: 0.041057
[07:04:59.190] iteration 25762: loss: 0.037842, loss_s1: 0.033275, loss_fp: 0.001158, loss_freq: 0.021011
[07:04:59.821] iteration 25763: loss: 0.077255, loss_s1: 0.055081, loss_fp: 0.020136, loss_freq: 0.038347
[07:05:00.451] iteration 25764: loss: 0.055065, loss_s1: 0.047397, loss_fp: 0.007636, loss_freq: 0.023761
[07:05:01.078] iteration 25765: loss: 0.079937, loss_s1: 0.085794, loss_fp: 0.004880, loss_freq: 0.031262
[07:05:01.714] iteration 25766: loss: 0.053610, loss_s1: 0.054865, loss_fp: 0.002499, loss_freq: 0.023556
[07:05:02.339] iteration 25767: loss: 0.061534, loss_s1: 0.052498, loss_fp: 0.001506, loss_freq: 0.033667
[07:05:02.963] iteration 25768: loss: 0.048799, loss_s1: 0.022245, loss_fp: 0.003016, loss_freq: 0.031404
[07:05:03.594] iteration 25769: loss: 0.052036, loss_s1: 0.051879, loss_fp: 0.003469, loss_freq: 0.020317
[07:05:04.212] iteration 25770: loss: 0.048471, loss_s1: 0.037878, loss_fp: 0.009034, loss_freq: 0.018835
[07:05:04.822] iteration 25771: loss: 0.050527, loss_s1: 0.049751, loss_fp: 0.007121, loss_freq: 0.022311
[07:05:05.435] iteration 25772: loss: 0.047524, loss_s1: 0.047098, loss_fp: 0.001931, loss_freq: 0.010982
[07:05:06.059] iteration 25773: loss: 0.033500, loss_s1: 0.014116, loss_fp: 0.006642, loss_freq: 0.015233
[07:05:06.675] iteration 25774: loss: 0.048656, loss_s1: 0.041556, loss_fp: 0.006461, loss_freq: 0.010887
[07:05:07.287] iteration 25775: loss: 0.040420, loss_s1: 0.023204, loss_fp: 0.000852, loss_freq: 0.030633
[07:05:07.945] iteration 25776: loss: 0.045668, loss_s1: 0.036668, loss_fp: 0.004135, loss_freq: 0.018515
[07:05:08.606] iteration 25777: loss: 0.056575, loss_s1: 0.041432, loss_fp: 0.005774, loss_freq: 0.033506
[07:05:09.265] iteration 25778: loss: 0.061839, loss_s1: 0.068823, loss_fp: 0.008181, loss_freq: 0.022087
[07:05:09.919] iteration 25779: loss: 0.052575, loss_s1: 0.031751, loss_fp: 0.020238, loss_freq: 0.019693
[07:05:10.528] iteration 25780: loss: 0.041731, loss_s1: 0.038171, loss_fp: 0.005029, loss_freq: 0.019570
[07:05:11.134] iteration 25781: loss: 0.050465, loss_s1: 0.043678, loss_fp: 0.002561, loss_freq: 0.022430
[07:05:11.766] iteration 25782: loss: 0.053524, loss_s1: 0.044560, loss_fp: 0.004090, loss_freq: 0.029900
[07:05:12.373] iteration 25783: loss: 0.055961, loss_s1: 0.055613, loss_fp: 0.004827, loss_freq: 0.025745
[07:05:12.982] iteration 25784: loss: 0.035561, loss_s1: 0.015457, loss_fp: 0.003686, loss_freq: 0.033377
[07:05:13.590] iteration 25785: loss: 0.058702, loss_s1: 0.050785, loss_fp: 0.004045, loss_freq: 0.029315
[07:05:14.206] iteration 25786: loss: 0.075836, loss_s1: 0.065511, loss_fp: 0.004928, loss_freq: 0.044311
[07:05:14.813] iteration 25787: loss: 0.051236, loss_s1: 0.051068, loss_fp: 0.006575, loss_freq: 0.013768
[07:05:15.429] iteration 25788: loss: 0.061007, loss_s1: 0.063216, loss_fp: 0.002263, loss_freq: 0.032178
[07:05:16.042] iteration 25789: loss: 0.066124, loss_s1: 0.059984, loss_fp: 0.002489, loss_freq: 0.044464
[07:05:16.651] iteration 25790: loss: 0.047428, loss_s1: 0.032622, loss_fp: 0.003240, loss_freq: 0.026163
[07:05:17.254] iteration 25791: loss: 0.038794, loss_s1: 0.035004, loss_fp: 0.002302, loss_freq: 0.013022
[07:05:17.854] iteration 25792: loss: 0.069894, loss_s1: 0.070048, loss_fp: 0.004786, loss_freq: 0.042138
[07:05:18.459] iteration 25793: loss: 0.078632, loss_s1: 0.062970, loss_fp: 0.003888, loss_freq: 0.065405
[07:05:19.113] iteration 25794: loss: 0.057063, loss_s1: 0.068743, loss_fp: 0.001484, loss_freq: 0.015082
[07:05:19.723] iteration 25795: loss: 0.074327, loss_s1: 0.068470, loss_fp: 0.006406, loss_freq: 0.034512
[07:05:20.332] iteration 25796: loss: 0.107775, loss_s1: 0.147257, loss_fp: 0.004034, loss_freq: 0.028937
[07:05:20.948] iteration 25797: loss: 0.049440, loss_s1: 0.038343, loss_fp: 0.003217, loss_freq: 0.035335
[07:05:21.556] iteration 25798: loss: 0.064934, loss_s1: 0.051940, loss_fp: 0.009259, loss_freq: 0.036100
[07:05:22.165] iteration 25799: loss: 0.048171, loss_s1: 0.037789, loss_fp: 0.011445, loss_freq: 0.022516
[07:05:22.785] iteration 25800: loss: 0.047056, loss_s1: 0.029351, loss_fp: 0.021312, loss_freq: 0.016823
[07:05:26.255] iteration 25800 : mean_dice : 0.749492
[07:05:26.921] iteration 25801: loss: 0.038981, loss_s1: 0.037114, loss_fp: 0.005243, loss_freq: 0.011467
[07:05:27.579] iteration 25802: loss: 0.048438, loss_s1: 0.050960, loss_fp: 0.001721, loss_freq: 0.014275
[07:05:28.234] iteration 25803: loss: 0.066581, loss_s1: 0.066435, loss_fp: 0.004498, loss_freq: 0.022897
[07:05:28.850] iteration 25804: loss: 0.058748, loss_s1: 0.046917, loss_fp: 0.004973, loss_freq: 0.024992
[07:05:29.467] iteration 25805: loss: 0.059591, loss_s1: 0.065882, loss_fp: 0.002676, loss_freq: 0.015083
[07:05:30.081] iteration 25806: loss: 0.032103, loss_s1: 0.028904, loss_fp: 0.002894, loss_freq: 0.008281
[07:05:30.692] iteration 25807: loss: 0.070049, loss_s1: 0.068116, loss_fp: 0.003351, loss_freq: 0.026961
[07:05:31.304] iteration 25808: loss: 0.039157, loss_s1: 0.024616, loss_fp: 0.001304, loss_freq: 0.023756
[07:05:31.920] iteration 25809: loss: 0.085213, loss_s1: 0.090420, loss_fp: 0.005394, loss_freq: 0.042555
[07:05:32.530] iteration 25810: loss: 0.075419, loss_s1: 0.058944, loss_fp: 0.012416, loss_freq: 0.058188
[07:05:33.146] iteration 25811: loss: 0.061504, loss_s1: 0.060865, loss_fp: 0.005277, loss_freq: 0.027417
[07:05:33.758] iteration 25812: loss: 0.057252, loss_s1: 0.041138, loss_fp: 0.001707, loss_freq: 0.037647
[07:05:34.372] iteration 25813: loss: 0.046471, loss_s1: 0.049139, loss_fp: 0.004109, loss_freq: 0.008880
[07:05:34.981] iteration 25814: loss: 0.033829, loss_s1: 0.015696, loss_fp: 0.013163, loss_freq: 0.005461
[07:05:35.590] iteration 25815: loss: 0.024476, loss_s1: 0.011592, loss_fp: 0.001385, loss_freq: 0.008664
[07:05:36.197] iteration 25816: loss: 0.056140, loss_s1: 0.037850, loss_fp: 0.003910, loss_freq: 0.036120
[07:05:36.807] iteration 25817: loss: 0.052687, loss_s1: 0.041565, loss_fp: 0.002097, loss_freq: 0.027247
[07:05:37.412] iteration 25818: loss: 0.060601, loss_s1: 0.067815, loss_fp: 0.003733, loss_freq: 0.025205
[07:05:38.017] iteration 25819: loss: 0.036471, loss_s1: 0.026605, loss_fp: 0.001815, loss_freq: 0.024178
[07:05:38.624] iteration 25820: loss: 0.034060, loss_s1: 0.016265, loss_fp: 0.001229, loss_freq: 0.020603
[07:05:39.233] iteration 25821: loss: 0.077357, loss_s1: 0.062762, loss_fp: 0.017731, loss_freq: 0.042168
[07:05:39.837] iteration 25822: loss: 0.044886, loss_s1: 0.033049, loss_fp: 0.004762, loss_freq: 0.021772
[07:05:40.439] iteration 25823: loss: 0.066469, loss_s1: 0.056692, loss_fp: 0.005352, loss_freq: 0.048757
[07:05:41.040] iteration 25824: loss: 0.067434, loss_s1: 0.056036, loss_fp: 0.011194, loss_freq: 0.041079
[07:05:41.644] iteration 25825: loss: 0.061315, loss_s1: 0.058888, loss_fp: 0.003954, loss_freq: 0.020448
[07:05:42.255] iteration 25826: loss: 0.049223, loss_s1: 0.043049, loss_fp: 0.002288, loss_freq: 0.018669
[07:05:42.867] iteration 25827: loss: 0.037407, loss_s1: 0.038010, loss_fp: 0.001265, loss_freq: 0.017423
[07:05:43.489] iteration 25828: loss: 0.099314, loss_s1: 0.114890, loss_fp: 0.002750, loss_freq: 0.054976
[07:05:44.092] iteration 25829: loss: 0.057874, loss_s1: 0.038836, loss_fp: 0.004494, loss_freq: 0.038865
[07:05:44.702] iteration 25830: loss: 0.081203, loss_s1: 0.077436, loss_fp: 0.005320, loss_freq: 0.041978
[07:05:45.316] iteration 25831: loss: 0.031865, loss_s1: 0.015436, loss_fp: 0.002170, loss_freq: 0.011703
[07:05:45.930] iteration 25832: loss: 0.040370, loss_s1: 0.041075, loss_fp: 0.002914, loss_freq: 0.017566
[07:05:46.582] iteration 25833: loss: 0.036163, loss_s1: 0.020795, loss_fp: 0.003097, loss_freq: 0.009641
[07:05:47.242] iteration 25834: loss: 0.048521, loss_s1: 0.038110, loss_fp: 0.002414, loss_freq: 0.032791
[07:05:47.901] iteration 25835: loss: 0.031014, loss_s1: 0.023566, loss_fp: 0.002819, loss_freq: 0.010273
[07:05:48.560] iteration 25836: loss: 0.070523, loss_s1: 0.076835, loss_fp: 0.001169, loss_freq: 0.042955
[07:05:49.221] iteration 25837: loss: 0.056365, loss_s1: 0.027131, loss_fp: 0.003738, loss_freq: 0.049777
[07:05:49.881] iteration 25838: loss: 0.054427, loss_s1: 0.046248, loss_fp: 0.002704, loss_freq: 0.028150
[07:05:50.523] iteration 25839: loss: 0.053821, loss_s1: 0.039295, loss_fp: 0.002365, loss_freq: 0.040747
[07:05:51.128] iteration 25840: loss: 0.059610, loss_s1: 0.060319, loss_fp: 0.000972, loss_freq: 0.023169
[07:05:52.062] iteration 25841: loss: 0.044037, loss_s1: 0.036219, loss_fp: 0.001938, loss_freq: 0.015202
[07:05:52.683] iteration 25842: loss: 0.057684, loss_s1: 0.049840, loss_fp: 0.003369, loss_freq: 0.031202
[07:05:53.293] iteration 25843: loss: 0.052796, loss_s1: 0.045638, loss_fp: 0.004233, loss_freq: 0.028546
[07:05:53.911] iteration 25844: loss: 0.040024, loss_s1: 0.038514, loss_fp: 0.001834, loss_freq: 0.013013
[07:05:54.520] iteration 25845: loss: 0.040014, loss_s1: 0.039627, loss_fp: 0.005288, loss_freq: 0.011636
[07:05:55.156] iteration 25846: loss: 0.054075, loss_s1: 0.038599, loss_fp: 0.003304, loss_freq: 0.030729
[07:05:55.766] iteration 25847: loss: 0.054251, loss_s1: 0.033481, loss_fp: 0.003519, loss_freq: 0.029774
[07:05:56.374] iteration 25848: loss: 0.050659, loss_s1: 0.043047, loss_fp: 0.001851, loss_freq: 0.031092
[07:05:56.975] iteration 25849: loss: 0.036407, loss_s1: 0.029342, loss_fp: 0.001685, loss_freq: 0.019402
[07:05:57.580] iteration 25850: loss: 0.074422, loss_s1: 0.081938, loss_fp: 0.002506, loss_freq: 0.029492
[07:05:58.185] iteration 25851: loss: 0.034399, loss_s1: 0.021378, loss_fp: 0.002174, loss_freq: 0.013929
[07:05:58.789] iteration 25852: loss: 0.052835, loss_s1: 0.048670, loss_fp: 0.001712, loss_freq: 0.024394
[07:05:59.397] iteration 25853: loss: 0.065730, loss_s1: 0.070769, loss_fp: 0.002520, loss_freq: 0.031153
[07:05:59.998] iteration 25854: loss: 0.071682, loss_s1: 0.070043, loss_fp: 0.008292, loss_freq: 0.041487
[07:06:00.604] iteration 25855: loss: 0.057678, loss_s1: 0.062532, loss_fp: 0.002049, loss_freq: 0.013395
[07:06:01.206] iteration 25856: loss: 0.051720, loss_s1: 0.039217, loss_fp: 0.001128, loss_freq: 0.033496
[07:06:01.816] iteration 25857: loss: 0.097280, loss_s1: 0.115269, loss_fp: 0.007473, loss_freq: 0.053558
[07:06:02.425] iteration 25858: loss: 0.031691, loss_s1: 0.017076, loss_fp: 0.003144, loss_freq: 0.016354
[07:06:03.029] iteration 25859: loss: 0.101922, loss_s1: 0.118746, loss_fp: 0.008599, loss_freq: 0.047684
[07:06:03.632] iteration 25860: loss: 0.069303, loss_s1: 0.080634, loss_fp: 0.005737, loss_freq: 0.019506
[07:06:04.238] iteration 25861: loss: 0.063867, loss_s1: 0.060320, loss_fp: 0.005584, loss_freq: 0.029150
[07:06:04.867] iteration 25862: loss: 0.085115, loss_s1: 0.096187, loss_fp: 0.002495, loss_freq: 0.049627
[07:06:05.476] iteration 25863: loss: 0.075269, loss_s1: 0.056360, loss_fp: 0.003131, loss_freq: 0.040252
[07:06:06.087] iteration 25864: loss: 0.044170, loss_s1: 0.039437, loss_fp: 0.002128, loss_freq: 0.011868
[07:06:06.700] iteration 25865: loss: 0.072718, loss_s1: 0.046345, loss_fp: 0.011581, loss_freq: 0.053556
[07:06:07.324] iteration 25866: loss: 0.061131, loss_s1: 0.063661, loss_fp: 0.003168, loss_freq: 0.033373
[07:06:07.937] iteration 25867: loss: 0.049751, loss_s1: 0.036824, loss_fp: 0.004112, loss_freq: 0.024102
[07:06:08.549] iteration 25868: loss: 0.095898, loss_s1: 0.095802, loss_fp: 0.003355, loss_freq: 0.061689
[07:06:09.188] iteration 25869: loss: 0.042150, loss_s1: 0.031538, loss_fp: 0.003445, loss_freq: 0.019070
[07:06:09.840] iteration 25870: loss: 0.117736, loss_s1: 0.118200, loss_fp: 0.004813, loss_freq: 0.077440
[07:06:10.693] iteration 25871: loss: 0.066647, loss_s1: 0.071383, loss_fp: 0.002779, loss_freq: 0.034119
[07:06:11.663] iteration 25872: loss: 0.087726, loss_s1: 0.067160, loss_fp: 0.012876, loss_freq: 0.058153
[07:06:12.299] iteration 25873: loss: 0.061219, loss_s1: 0.062023, loss_fp: 0.002905, loss_freq: 0.026837
[07:06:12.910] iteration 25874: loss: 0.048435, loss_s1: 0.038345, loss_fp: 0.002237, loss_freq: 0.023599
[07:06:13.515] iteration 25875: loss: 0.070613, loss_s1: 0.076510, loss_fp: 0.002297, loss_freq: 0.043188
[07:06:14.193] iteration 25876: loss: 0.039936, loss_s1: 0.021678, loss_fp: 0.001558, loss_freq: 0.010793
[07:06:14.811] iteration 25877: loss: 0.050624, loss_s1: 0.038061, loss_fp: 0.005170, loss_freq: 0.027573
[07:06:15.421] iteration 25878: loss: 0.056695, loss_s1: 0.064005, loss_fp: 0.003573, loss_freq: 0.022719
[07:06:16.026] iteration 25879: loss: 0.073500, loss_s1: 0.082450, loss_fp: 0.004019, loss_freq: 0.031777
[07:06:16.631] iteration 25880: loss: 0.062301, loss_s1: 0.064458, loss_fp: 0.004967, loss_freq: 0.033091
[07:06:17.241] iteration 25881: loss: 0.062642, loss_s1: 0.046282, loss_fp: 0.005240, loss_freq: 0.023900
[07:06:17.865] iteration 25882: loss: 0.066514, loss_s1: 0.073577, loss_fp: 0.005080, loss_freq: 0.024373
[07:06:18.495] iteration 25883: loss: 0.103123, loss_s1: 0.128880, loss_fp: 0.002160, loss_freq: 0.049713
[07:06:19.102] iteration 25884: loss: 0.108898, loss_s1: 0.121437, loss_fp: 0.006889, loss_freq: 0.057546
[07:06:19.716] iteration 25885: loss: 0.060356, loss_s1: 0.050143, loss_fp: 0.002724, loss_freq: 0.034214
[07:06:20.326] iteration 25886: loss: 0.098732, loss_s1: 0.099576, loss_fp: 0.009836, loss_freq: 0.054152
[07:06:20.931] iteration 25887: loss: 0.065000, loss_s1: 0.055747, loss_fp: 0.006116, loss_freq: 0.037235
[07:06:21.540] iteration 25888: loss: 0.087129, loss_s1: 0.107166, loss_fp: 0.005878, loss_freq: 0.032483
[07:06:22.152] iteration 25889: loss: 0.044215, loss_s1: 0.045907, loss_fp: 0.001847, loss_freq: 0.008460
[07:06:22.766] iteration 25890: loss: 0.032554, loss_s1: 0.023856, loss_fp: 0.001740, loss_freq: 0.007136
[07:06:23.422] iteration 25891: loss: 0.059621, loss_s1: 0.060117, loss_fp: 0.004921, loss_freq: 0.027320
[07:06:24.076] iteration 25892: loss: 0.046237, loss_s1: 0.031778, loss_fp: 0.009801, loss_freq: 0.022851
[07:06:24.730] iteration 25893: loss: 0.070566, loss_s1: 0.071880, loss_fp: 0.001096, loss_freq: 0.014631
[07:06:25.397] iteration 25894: loss: 0.064764, loss_s1: 0.055107, loss_fp: 0.004002, loss_freq: 0.041528
[07:06:26.027] iteration 25895: loss: 0.057548, loss_s1: 0.053242, loss_fp: 0.003966, loss_freq: 0.024622
[07:06:26.639] iteration 25896: loss: 0.037879, loss_s1: 0.021534, loss_fp: 0.001881, loss_freq: 0.024040
[07:06:27.254] iteration 25897: loss: 0.047607, loss_s1: 0.036490, loss_fp: 0.006249, loss_freq: 0.035712
[07:06:27.865] iteration 25898: loss: 0.054299, loss_s1: 0.048382, loss_fp: 0.002085, loss_freq: 0.024104
[07:06:28.478] iteration 25899: loss: 0.036063, loss_s1: 0.020043, loss_fp: 0.000894, loss_freq: 0.028998
[07:06:29.098] iteration 25900: loss: 0.053098, loss_s1: 0.028924, loss_fp: 0.006931, loss_freq: 0.039227
[07:06:29.714] iteration 25901: loss: 0.024151, loss_s1: 0.022814, loss_fp: 0.001108, loss_freq: 0.004319
[07:06:30.328] iteration 25902: loss: 0.066719, loss_s1: 0.037069, loss_fp: 0.003526, loss_freq: 0.038780
[07:06:30.938] iteration 25903: loss: 0.047664, loss_s1: 0.045597, loss_fp: 0.001112, loss_freq: 0.011442
[07:06:31.550] iteration 25904: loss: 0.052562, loss_s1: 0.047855, loss_fp: 0.005479, loss_freq: 0.025869
[07:06:32.168] iteration 25905: loss: 0.033408, loss_s1: 0.018726, loss_fp: 0.001697, loss_freq: 0.010838
[07:06:32.781] iteration 25906: loss: 0.045713, loss_s1: 0.041133, loss_fp: 0.004808, loss_freq: 0.025904
[07:06:33.393] iteration 25907: loss: 0.040388, loss_s1: 0.028892, loss_fp: 0.001105, loss_freq: 0.018569
[07:06:33.999] iteration 25908: loss: 0.072872, loss_s1: 0.069821, loss_fp: 0.015043, loss_freq: 0.038701
[07:06:34.606] iteration 25909: loss: 0.036239, loss_s1: 0.016107, loss_fp: 0.003276, loss_freq: 0.024748
[07:06:35.214] iteration 25910: loss: 0.053387, loss_s1: 0.062500, loss_fp: 0.002276, loss_freq: 0.022424
[07:06:35.837] iteration 25911: loss: 0.046666, loss_s1: 0.030477, loss_fp: 0.002569, loss_freq: 0.030526
[07:06:36.445] iteration 25912: loss: 0.040157, loss_s1: 0.021150, loss_fp: 0.004872, loss_freq: 0.022270
[07:06:37.058] iteration 25913: loss: 0.059370, loss_s1: 0.036166, loss_fp: 0.020270, loss_freq: 0.038252
[07:06:37.663] iteration 25914: loss: 0.056792, loss_s1: 0.055548, loss_fp: 0.003449, loss_freq: 0.026482
[07:06:38.265] iteration 25915: loss: 0.083787, loss_s1: 0.059526, loss_fp: 0.001892, loss_freq: 0.075316
[07:06:38.869] iteration 25916: loss: 0.088863, loss_s1: 0.086673, loss_fp: 0.005609, loss_freq: 0.045934
[07:06:39.479] iteration 25917: loss: 0.060983, loss_s1: 0.064616, loss_fp: 0.004659, loss_freq: 0.019705
[07:06:40.084] iteration 25918: loss: 0.093962, loss_s1: 0.069533, loss_fp: 0.013146, loss_freq: 0.075778
[07:06:40.684] iteration 25919: loss: 0.053888, loss_s1: 0.048881, loss_fp: 0.010101, loss_freq: 0.020952
[07:06:41.292] iteration 25920: loss: 0.043061, loss_s1: 0.030242, loss_fp: 0.006352, loss_freq: 0.012791
[07:06:41.903] iteration 25921: loss: 0.089407, loss_s1: 0.123053, loss_fp: 0.001520, loss_freq: 0.017540
[07:06:42.511] iteration 25922: loss: 0.051530, loss_s1: 0.033798, loss_fp: 0.007060, loss_freq: 0.029092
[07:06:43.121] iteration 25923: loss: 0.074500, loss_s1: 0.080302, loss_fp: 0.001865, loss_freq: 0.033524
[07:06:43.735] iteration 25924: loss: 0.054151, loss_s1: 0.043131, loss_fp: 0.015875, loss_freq: 0.008801
[07:06:44.361] iteration 25925: loss: 0.043765, loss_s1: 0.032354, loss_fp: 0.001676, loss_freq: 0.017473
[07:06:44.977] iteration 25926: loss: 0.067540, loss_s1: 0.051820, loss_fp: 0.005842, loss_freq: 0.034034
[07:06:45.590] iteration 25927: loss: 0.050717, loss_s1: 0.049882, loss_fp: 0.002273, loss_freq: 0.030942
[07:06:46.244] iteration 25928: loss: 0.064247, loss_s1: 0.069673, loss_fp: 0.001217, loss_freq: 0.016911
[07:06:46.855] iteration 25929: loss: 0.047260, loss_s1: 0.041108, loss_fp: 0.001884, loss_freq: 0.025058
[07:06:47.466] iteration 25930: loss: 0.050099, loss_s1: 0.032773, loss_fp: 0.005074, loss_freq: 0.020711
[07:06:48.076] iteration 25931: loss: 0.085534, loss_s1: 0.116284, loss_fp: 0.003274, loss_freq: 0.016067
[07:06:48.684] iteration 25932: loss: 0.051934, loss_s1: 0.029883, loss_fp: 0.004318, loss_freq: 0.042950
[07:06:49.296] iteration 25933: loss: 0.061879, loss_s1: 0.063782, loss_fp: 0.009529, loss_freq: 0.015078
[07:06:49.915] iteration 25934: loss: 0.056438, loss_s1: 0.052189, loss_fp: 0.009888, loss_freq: 0.015825
[07:06:50.525] iteration 25935: loss: 0.059698, loss_s1: 0.038163, loss_fp: 0.004136, loss_freq: 0.039345
[07:06:51.142] iteration 25936: loss: 0.034709, loss_s1: 0.026740, loss_fp: 0.000910, loss_freq: 0.018882
[07:06:51.764] iteration 25937: loss: 0.055952, loss_s1: 0.057278, loss_fp: 0.008299, loss_freq: 0.016978
[07:06:52.379] iteration 25938: loss: 0.063844, loss_s1: 0.065866, loss_fp: 0.002508, loss_freq: 0.024044
[07:06:52.992] iteration 25939: loss: 0.031588, loss_s1: 0.015374, loss_fp: 0.001936, loss_freq: 0.021708
[07:06:53.619] iteration 25940: loss: 0.039150, loss_s1: 0.023518, loss_fp: 0.001977, loss_freq: 0.021404
[07:06:54.370] iteration 25941: loss: 0.042790, loss_s1: 0.050538, loss_fp: 0.006823, loss_freq: 0.010249
[07:06:55.050] iteration 25942: loss: 0.035154, loss_s1: 0.011434, loss_fp: 0.003196, loss_freq: 0.006476
[07:06:55.765] iteration 25943: loss: 0.049132, loss_s1: 0.038539, loss_fp: 0.003060, loss_freq: 0.019381
[07:06:56.453] iteration 25944: loss: 0.050699, loss_s1: 0.054975, loss_fp: 0.003286, loss_freq: 0.012146
[07:06:57.118] iteration 25945: loss: 0.026370, loss_s1: 0.017969, loss_fp: 0.002821, loss_freq: 0.007105
[07:06:57.823] iteration 25946: loss: 0.052138, loss_s1: 0.043157, loss_fp: 0.013544, loss_freq: 0.016480
[07:06:58.484] iteration 25947: loss: 0.050627, loss_s1: 0.035097, loss_fp: 0.002913, loss_freq: 0.018403
[07:06:59.216] iteration 25948: loss: 0.047665, loss_s1: 0.035104, loss_fp: 0.002384, loss_freq: 0.026074
[07:06:59.852] iteration 25949: loss: 0.090659, loss_s1: 0.065899, loss_fp: 0.021882, loss_freq: 0.058595
[07:07:00.614] iteration 25950: loss: 0.047434, loss_s1: 0.036740, loss_fp: 0.004465, loss_freq: 0.027940
[07:07:01.286] iteration 25951: loss: 0.048236, loss_s1: 0.033433, loss_fp: 0.004718, loss_freq: 0.017034
[07:07:01.968] iteration 25952: loss: 0.077852, loss_s1: 0.087388, loss_fp: 0.003045, loss_freq: 0.030831
[07:07:02.633] iteration 25953: loss: 0.057216, loss_s1: 0.047748, loss_fp: 0.005632, loss_freq: 0.037389
[07:07:03.309] iteration 25954: loss: 0.030699, loss_s1: 0.024327, loss_fp: 0.004395, loss_freq: 0.014714
[07:07:03.998] iteration 25955: loss: 0.057314, loss_s1: 0.052380, loss_fp: 0.004683, loss_freq: 0.025752
[07:07:04.650] iteration 25956: loss: 0.088971, loss_s1: 0.062534, loss_fp: 0.007524, loss_freq: 0.072745
[07:07:05.485] iteration 25957: loss: 0.053519, loss_s1: 0.048808, loss_fp: 0.006171, loss_freq: 0.016658
[07:07:06.126] iteration 25958: loss: 0.060412, loss_s1: 0.051386, loss_fp: 0.008099, loss_freq: 0.036042
[07:07:06.739] iteration 25959: loss: 0.042552, loss_s1: 0.031931, loss_fp: 0.003111, loss_freq: 0.023485
[07:07:07.358] iteration 25960: loss: 0.055101, loss_s1: 0.044088, loss_fp: 0.001855, loss_freq: 0.021323
[07:07:08.001] iteration 25961: loss: 0.034977, loss_s1: 0.020394, loss_fp: 0.001345, loss_freq: 0.017113
[07:07:08.649] iteration 25962: loss: 0.074805, loss_s1: 0.069855, loss_fp: 0.005048, loss_freq: 0.053296
[07:07:09.292] iteration 25963: loss: 0.041423, loss_s1: 0.025989, loss_fp: 0.003934, loss_freq: 0.023414
[07:07:09.903] iteration 25964: loss: 0.049109, loss_s1: 0.044940, loss_fp: 0.011742, loss_freq: 0.015358
[07:07:10.509] iteration 25965: loss: 0.046631, loss_s1: 0.031313, loss_fp: 0.003498, loss_freq: 0.017322
[07:07:11.120] iteration 25966: loss: 0.035422, loss_s1: 0.016404, loss_fp: 0.005536, loss_freq: 0.014731
[07:07:11.730] iteration 25967: loss: 0.073121, loss_s1: 0.078506, loss_fp: 0.006443, loss_freq: 0.042075
[07:07:12.344] iteration 25968: loss: 0.047077, loss_s1: 0.012995, loss_fp: 0.002709, loss_freq: 0.037854
[07:07:12.957] iteration 25969: loss: 0.055870, loss_s1: 0.056224, loss_fp: 0.004014, loss_freq: 0.022570
[07:07:13.593] iteration 25970: loss: 0.070197, loss_s1: 0.043345, loss_fp: 0.019475, loss_freq: 0.045198
[07:07:14.207] iteration 25971: loss: 0.038886, loss_s1: 0.032701, loss_fp: 0.005524, loss_freq: 0.012770
[07:07:14.823] iteration 25972: loss: 0.060475, loss_s1: 0.037569, loss_fp: 0.002842, loss_freq: 0.022113
[07:07:15.434] iteration 25973: loss: 0.065393, loss_s1: 0.060651, loss_fp: 0.003630, loss_freq: 0.032729
[07:07:16.076] iteration 25974: loss: 0.057946, loss_s1: 0.076979, loss_fp: 0.002121, loss_freq: 0.008370
[07:07:16.690] iteration 25975: loss: 0.074342, loss_s1: 0.072263, loss_fp: 0.004715, loss_freq: 0.041670
[07:07:17.294] iteration 25976: loss: 0.038753, loss_s1: 0.042441, loss_fp: 0.006047, loss_freq: 0.007992
[07:07:17.913] iteration 25977: loss: 0.062824, loss_s1: 0.046523, loss_fp: 0.003626, loss_freq: 0.020761
[07:07:18.523] iteration 25978: loss: 0.045183, loss_s1: 0.034240, loss_fp: 0.004820, loss_freq: 0.026443
[07:07:19.132] iteration 25979: loss: 0.138477, loss_s1: 0.157937, loss_fp: 0.006066, loss_freq: 0.084861
[07:07:19.741] iteration 25980: loss: 0.058456, loss_s1: 0.072445, loss_fp: 0.001814, loss_freq: 0.024033
[07:07:20.353] iteration 25981: loss: 0.053753, loss_s1: 0.040058, loss_fp: 0.002362, loss_freq: 0.021394
[07:07:20.980] iteration 25982: loss: 0.039110, loss_s1: 0.013780, loss_fp: 0.003708, loss_freq: 0.031518
[07:07:21.803] iteration 25983: loss: 0.057644, loss_s1: 0.064512, loss_fp: 0.001081, loss_freq: 0.024981
[07:07:22.619] iteration 25984: loss: 0.049952, loss_s1: 0.035401, loss_fp: 0.004778, loss_freq: 0.028652
[07:07:23.403] iteration 25985: loss: 0.022802, loss_s1: 0.016568, loss_fp: 0.001525, loss_freq: 0.004901
[07:07:24.061] iteration 25986: loss: 0.076450, loss_s1: 0.058748, loss_fp: 0.009866, loss_freq: 0.050349
[07:07:24.711] iteration 25987: loss: 0.035636, loss_s1: 0.019261, loss_fp: 0.001963, loss_freq: 0.016247
[07:07:25.324] iteration 25988: loss: 0.105088, loss_s1: 0.142732, loss_fp: 0.004055, loss_freq: 0.037357
[07:07:25.938] iteration 25989: loss: 0.057752, loss_s1: 0.047491, loss_fp: 0.003883, loss_freq: 0.045508
[07:07:26.551] iteration 25990: loss: 0.048166, loss_s1: 0.033172, loss_fp: 0.007019, loss_freq: 0.016771
[07:07:27.164] iteration 25991: loss: 0.075717, loss_s1: 0.057428, loss_fp: 0.013845, loss_freq: 0.044845
[07:07:27.776] iteration 25992: loss: 0.054433, loss_s1: 0.057159, loss_fp: 0.006025, loss_freq: 0.013324
[07:07:28.412] iteration 25993: loss: 0.065055, loss_s1: 0.045928, loss_fp: 0.003165, loss_freq: 0.045927
[07:07:29.031] iteration 25994: loss: 0.078103, loss_s1: 0.041397, loss_fp: 0.006365, loss_freq: 0.066815
[07:07:29.643] iteration 25995: loss: 0.070637, loss_s1: 0.053900, loss_fp: 0.002648, loss_freq: 0.053327
[07:07:30.287] iteration 25996: loss: 0.042089, loss_s1: 0.037292, loss_fp: 0.001011, loss_freq: 0.014741
[07:07:30.905] iteration 25997: loss: 0.035277, loss_s1: 0.027506, loss_fp: 0.006172, loss_freq: 0.013386
[07:07:31.526] iteration 25998: loss: 0.079818, loss_s1: 0.078346, loss_fp: 0.001809, loss_freq: 0.049681
[07:07:32.138] iteration 25999: loss: 0.074668, loss_s1: 0.065437, loss_fp: 0.007525, loss_freq: 0.045871
[07:07:32.745] iteration 26000: loss: 0.065680, loss_s1: 0.052253, loss_fp: 0.004624, loss_freq: 0.043671
[07:07:36.074] iteration 26000 : mean_dice : 0.743464
[07:07:36.714] iteration 26001: loss: 0.045967, loss_s1: 0.035225, loss_fp: 0.002590, loss_freq: 0.019250
[07:07:37.326] iteration 26002: loss: 0.073653, loss_s1: 0.066725, loss_fp: 0.010926, loss_freq: 0.036152
[07:07:37.926] iteration 26003: loss: 0.035662, loss_s1: 0.023235, loss_fp: 0.001775, loss_freq: 0.007778
[07:07:38.540] iteration 26004: loss: 0.057618, loss_s1: 0.062155, loss_fp: 0.003430, loss_freq: 0.022078
[07:07:39.178] iteration 26005: loss: 0.044305, loss_s1: 0.040802, loss_fp: 0.001769, loss_freq: 0.013759
[07:07:39.781] iteration 26006: loss: 0.072350, loss_s1: 0.068292, loss_fp: 0.006197, loss_freq: 0.047686
[07:07:40.399] iteration 26007: loss: 0.060565, loss_s1: 0.039319, loss_fp: 0.002812, loss_freq: 0.035872
[07:07:41.011] iteration 26008: loss: 0.087744, loss_s1: 0.101647, loss_fp: 0.009964, loss_freq: 0.031604
[07:07:41.626] iteration 26009: loss: 0.056731, loss_s1: 0.038036, loss_fp: 0.006064, loss_freq: 0.040876
[07:07:42.235] iteration 26010: loss: 0.052136, loss_s1: 0.040782, loss_fp: 0.003236, loss_freq: 0.027742
[07:07:43.157] iteration 26011: loss: 0.078214, loss_s1: 0.068834, loss_fp: 0.002927, loss_freq: 0.051840
[07:07:43.777] iteration 26012: loss: 0.051867, loss_s1: 0.033221, loss_fp: 0.007343, loss_freq: 0.027866
[07:07:44.388] iteration 26013: loss: 0.041685, loss_s1: 0.036912, loss_fp: 0.001855, loss_freq: 0.019911
[07:07:44.992] iteration 26014: loss: 0.041133, loss_s1: 0.038189, loss_fp: 0.002367, loss_freq: 0.012599
[07:07:45.601] iteration 26015: loss: 0.034823, loss_s1: 0.029010, loss_fp: 0.002364, loss_freq: 0.013698
[07:07:46.214] iteration 26016: loss: 0.051353, loss_s1: 0.045924, loss_fp: 0.002485, loss_freq: 0.019615
[07:07:46.826] iteration 26017: loss: 0.053550, loss_s1: 0.049680, loss_fp: 0.006767, loss_freq: 0.013681
[07:07:47.439] iteration 26018: loss: 0.039848, loss_s1: 0.028977, loss_fp: 0.006993, loss_freq: 0.014679
[07:07:48.054] iteration 26019: loss: 0.035801, loss_s1: 0.030545, loss_fp: 0.000716, loss_freq: 0.014826
[07:07:48.710] iteration 26020: loss: 0.043541, loss_s1: 0.035064, loss_fp: 0.004491, loss_freq: 0.017788
[07:07:49.410] iteration 26021: loss: 0.048937, loss_s1: 0.026620, loss_fp: 0.005263, loss_freq: 0.032302
[07:07:50.067] iteration 26022: loss: 0.044930, loss_s1: 0.033913, loss_fp: 0.005866, loss_freq: 0.022010
[07:07:50.725] iteration 26023: loss: 0.045418, loss_s1: 0.041373, loss_fp: 0.001202, loss_freq: 0.018631
[07:07:51.345] iteration 26024: loss: 0.048312, loss_s1: 0.017195, loss_fp: 0.005350, loss_freq: 0.046932
[07:07:51.958] iteration 26025: loss: 0.072389, loss_s1: 0.082620, loss_fp: 0.008660, loss_freq: 0.019424
[07:07:52.568] iteration 26026: loss: 0.048421, loss_s1: 0.046477, loss_fp: 0.003916, loss_freq: 0.016010
[07:07:53.177] iteration 26027: loss: 0.111161, loss_s1: 0.147898, loss_fp: 0.007261, loss_freq: 0.047885
[07:07:53.785] iteration 26028: loss: 0.029089, loss_s1: 0.012488, loss_fp: 0.004358, loss_freq: 0.006096
[07:07:54.399] iteration 26029: loss: 0.125795, loss_s1: 0.161112, loss_fp: 0.012434, loss_freq: 0.053082
[07:07:55.009] iteration 26030: loss: 0.041926, loss_s1: 0.033799, loss_fp: 0.002402, loss_freq: 0.018438
[07:07:55.698] iteration 26031: loss: 0.044405, loss_s1: 0.032818, loss_fp: 0.002706, loss_freq: 0.023230
[07:07:56.366] iteration 26032: loss: 0.067945, loss_s1: 0.062682, loss_fp: 0.002266, loss_freq: 0.046899
[07:07:57.030] iteration 26033: loss: 0.061538, loss_s1: 0.039080, loss_fp: 0.003943, loss_freq: 0.046078
[07:07:57.654] iteration 26034: loss: 0.040187, loss_s1: 0.026278, loss_fp: 0.001144, loss_freq: 0.019501
[07:07:58.264] iteration 26035: loss: 0.075572, loss_s1: 0.083467, loss_fp: 0.005618, loss_freq: 0.031437
[07:07:58.878] iteration 26036: loss: 0.053903, loss_s1: 0.044698, loss_fp: 0.003379, loss_freq: 0.029390
[07:07:59.488] iteration 26037: loss: 0.034497, loss_s1: 0.023356, loss_fp: 0.003338, loss_freq: 0.012645
[07:08:00.155] iteration 26038: loss: 0.058896, loss_s1: 0.048623, loss_fp: 0.006066, loss_freq: 0.030712
[07:08:00.816] iteration 26039: loss: 0.036881, loss_s1: 0.023471, loss_fp: 0.001864, loss_freq: 0.020167
[07:08:01.469] iteration 26040: loss: 0.077163, loss_s1: 0.075589, loss_fp: 0.004418, loss_freq: 0.041716
[07:08:02.121] iteration 26041: loss: 0.055472, loss_s1: 0.053614, loss_fp: 0.003462, loss_freq: 0.033044
[07:08:02.812] iteration 26042: loss: 0.065329, loss_s1: 0.034017, loss_fp: 0.008065, loss_freq: 0.037253
[07:08:03.492] iteration 26043: loss: 0.071456, loss_s1: 0.067741, loss_fp: 0.003064, loss_freq: 0.040243
[07:08:04.142] iteration 26044: loss: 0.032307, loss_s1: 0.021712, loss_fp: 0.004062, loss_freq: 0.009287
[07:08:04.763] iteration 26045: loss: 0.037111, loss_s1: 0.033951, loss_fp: 0.001880, loss_freq: 0.018025
[07:08:05.433] iteration 26046: loss: 0.053051, loss_s1: 0.036556, loss_fp: 0.004639, loss_freq: 0.017151
[07:08:06.052] iteration 26047: loss: 0.085640, loss_s1: 0.078810, loss_fp: 0.003674, loss_freq: 0.048316
[07:08:06.662] iteration 26048: loss: 0.044082, loss_s1: 0.038848, loss_fp: 0.005303, loss_freq: 0.015160
[07:08:07.274] iteration 26049: loss: 0.089257, loss_s1: 0.096381, loss_fp: 0.003875, loss_freq: 0.045851
[07:08:07.887] iteration 26050: loss: 0.067386, loss_s1: 0.077744, loss_fp: 0.007324, loss_freq: 0.027106
[07:08:08.505] iteration 26051: loss: 0.074093, loss_s1: 0.049089, loss_fp: 0.002745, loss_freq: 0.056830
[07:08:09.133] iteration 26052: loss: 0.082530, loss_s1: 0.100664, loss_fp: 0.003330, loss_freq: 0.026344
[07:08:09.742] iteration 26053: loss: 0.072161, loss_s1: 0.068600, loss_fp: 0.004070, loss_freq: 0.043069
[07:08:10.364] iteration 26054: loss: 0.096884, loss_s1: 0.104974, loss_fp: 0.005387, loss_freq: 0.058092
[07:08:10.979] iteration 26055: loss: 0.060712, loss_s1: 0.062838, loss_fp: 0.002657, loss_freq: 0.022680
[07:08:11.584] iteration 26056: loss: 0.066358, loss_s1: 0.060404, loss_fp: 0.004020, loss_freq: 0.034370
[07:08:12.199] iteration 26057: loss: 0.045666, loss_s1: 0.037782, loss_fp: 0.004752, loss_freq: 0.018366
[07:08:12.846] iteration 26058: loss: 0.055254, loss_s1: 0.055165, loss_fp: 0.002677, loss_freq: 0.027023
[07:08:13.462] iteration 26059: loss: 0.058064, loss_s1: 0.062353, loss_fp: 0.001946, loss_freq: 0.020305
[07:08:14.223] iteration 26060: loss: 0.047615, loss_s1: 0.039710, loss_fp: 0.001601, loss_freq: 0.024020
[07:08:14.941] iteration 26061: loss: 0.044691, loss_s1: 0.023433, loss_fp: 0.002944, loss_freq: 0.023088
[07:08:15.552] iteration 26062: loss: 0.068437, loss_s1: 0.079513, loss_fp: 0.003943, loss_freq: 0.033074
[07:08:16.168] iteration 26063: loss: 0.037172, loss_s1: 0.017503, loss_fp: 0.000750, loss_freq: 0.020652
[07:08:16.772] iteration 26064: loss: 0.045566, loss_s1: 0.043116, loss_fp: 0.003910, loss_freq: 0.015304
[07:08:17.376] iteration 26065: loss: 0.055623, loss_s1: 0.032268, loss_fp: 0.002984, loss_freq: 0.045481
[07:08:17.977] iteration 26066: loss: 0.031718, loss_s1: 0.015232, loss_fp: 0.003069, loss_freq: 0.015571
[07:08:18.583] iteration 26067: loss: 0.061844, loss_s1: 0.060049, loss_fp: 0.003003, loss_freq: 0.039376
[07:08:19.191] iteration 26068: loss: 0.045667, loss_s1: 0.037223, loss_fp: 0.006396, loss_freq: 0.011602
[07:08:19.797] iteration 26069: loss: 0.042839, loss_s1: 0.025349, loss_fp: 0.003024, loss_freq: 0.033130
[07:08:20.400] iteration 26070: loss: 0.063937, loss_s1: 0.051641, loss_fp: 0.003494, loss_freq: 0.043163
[07:08:21.055] iteration 26071: loss: 0.028172, loss_s1: 0.025598, loss_fp: 0.003385, loss_freq: 0.005185
[07:08:21.706] iteration 26072: loss: 0.061345, loss_s1: 0.039732, loss_fp: 0.001415, loss_freq: 0.029932
[07:08:22.362] iteration 26073: loss: 0.039038, loss_s1: 0.035273, loss_fp: 0.001762, loss_freq: 0.010228
[07:08:23.014] iteration 26074: loss: 0.029161, loss_s1: 0.017032, loss_fp: 0.000987, loss_freq: 0.012986
[07:08:23.668] iteration 26075: loss: 0.031779, loss_s1: 0.017562, loss_fp: 0.001321, loss_freq: 0.008362
[07:08:24.295] iteration 26076: loss: 0.051163, loss_s1: 0.044342, loss_fp: 0.002451, loss_freq: 0.034776
[07:08:24.899] iteration 26077: loss: 0.036199, loss_s1: 0.023440, loss_fp: 0.000968, loss_freq: 0.016351
[07:08:25.511] iteration 26078: loss: 0.109319, loss_s1: 0.130755, loss_fp: 0.006947, loss_freq: 0.054416
[07:08:26.121] iteration 26079: loss: 0.034326, loss_s1: 0.024498, loss_fp: 0.002069, loss_freq: 0.012932
[07:08:26.730] iteration 26080: loss: 0.035641, loss_s1: 0.031503, loss_fp: 0.004007, loss_freq: 0.013727
[07:08:27.340] iteration 26081: loss: 0.066821, loss_s1: 0.040163, loss_fp: 0.002396, loss_freq: 0.046711
[07:08:27.952] iteration 26082: loss: 0.042136, loss_s1: 0.021075, loss_fp: 0.002328, loss_freq: 0.024771
[07:08:28.563] iteration 26083: loss: 0.066877, loss_s1: 0.061407, loss_fp: 0.002594, loss_freq: 0.031674
[07:08:29.169] iteration 26084: loss: 0.039484, loss_s1: 0.039355, loss_fp: 0.002411, loss_freq: 0.011527
[07:08:29.779] iteration 26085: loss: 0.054580, loss_s1: 0.027527, loss_fp: 0.003687, loss_freq: 0.053687
[07:08:30.395] iteration 26086: loss: 0.060622, loss_s1: 0.042814, loss_fp: 0.007975, loss_freq: 0.039769
[07:08:31.010] iteration 26087: loss: 0.042389, loss_s1: 0.034202, loss_fp: 0.001305, loss_freq: 0.013934
[07:08:31.635] iteration 26088: loss: 0.104615, loss_s1: 0.093592, loss_fp: 0.011763, loss_freq: 0.065104
[07:08:32.292] iteration 26089: loss: 0.053976, loss_s1: 0.046374, loss_fp: 0.012139, loss_freq: 0.028807
[07:08:32.955] iteration 26090: loss: 0.065095, loss_s1: 0.062596, loss_fp: 0.003308, loss_freq: 0.033312
[07:08:33.617] iteration 26091: loss: 0.039561, loss_s1: 0.032166, loss_fp: 0.004223, loss_freq: 0.012268
[07:08:34.277] iteration 26092: loss: 0.050954, loss_s1: 0.022612, loss_fp: 0.009386, loss_freq: 0.040682
[07:08:34.931] iteration 26093: loss: 0.063904, loss_s1: 0.049993, loss_fp: 0.002819, loss_freq: 0.025912
[07:08:35.589] iteration 26094: loss: 0.040283, loss_s1: 0.035185, loss_fp: 0.003245, loss_freq: 0.011355
[07:08:36.216] iteration 26095: loss: 0.050757, loss_s1: 0.031539, loss_fp: 0.005812, loss_freq: 0.030018
[07:08:36.824] iteration 26096: loss: 0.049830, loss_s1: 0.030595, loss_fp: 0.006509, loss_freq: 0.031108
[07:08:37.435] iteration 26097: loss: 0.064106, loss_s1: 0.070012, loss_fp: 0.002477, loss_freq: 0.033223
[07:08:38.048] iteration 26098: loss: 0.047964, loss_s1: 0.048279, loss_fp: 0.008337, loss_freq: 0.013535
[07:08:38.666] iteration 26099: loss: 0.052527, loss_s1: 0.044322, loss_fp: 0.005573, loss_freq: 0.021196
[07:08:39.345] iteration 26100: loss: 0.041471, loss_s1: 0.024891, loss_fp: 0.003009, loss_freq: 0.018905
[07:08:40.023] iteration 26101: loss: 0.061724, loss_s1: 0.065109, loss_fp: 0.003707, loss_freq: 0.024501
[07:08:40.682] iteration 26102: loss: 0.063448, loss_s1: 0.073017, loss_fp: 0.002151, loss_freq: 0.030795
[07:08:41.351] iteration 26103: loss: 0.068160, loss_s1: 0.073601, loss_fp: 0.002718, loss_freq: 0.021872
[07:08:41.986] iteration 26104: loss: 0.052118, loss_s1: 0.049260, loss_fp: 0.006098, loss_freq: 0.021580
[07:08:42.597] iteration 26105: loss: 0.056010, loss_s1: 0.046467, loss_fp: 0.005664, loss_freq: 0.030360
[07:08:43.204] iteration 26106: loss: 0.042728, loss_s1: 0.037149, loss_fp: 0.001246, loss_freq: 0.024303
[07:08:43.805] iteration 26107: loss: 0.053074, loss_s1: 0.057006, loss_fp: 0.001785, loss_freq: 0.016553
[07:08:44.407] iteration 26108: loss: 0.046418, loss_s1: 0.027210, loss_fp: 0.008802, loss_freq: 0.021423
[07:08:45.013] iteration 26109: loss: 0.054328, loss_s1: 0.050669, loss_fp: 0.000708, loss_freq: 0.032659
[07:08:45.621] iteration 26110: loss: 0.058960, loss_s1: 0.041217, loss_fp: 0.002908, loss_freq: 0.041406
[07:08:46.226] iteration 26111: loss: 0.054832, loss_s1: 0.056916, loss_fp: 0.004907, loss_freq: 0.024958
[07:08:46.832] iteration 26112: loss: 0.050305, loss_s1: 0.040542, loss_fp: 0.002184, loss_freq: 0.012285
[07:08:47.441] iteration 26113: loss: 0.047972, loss_s1: 0.020564, loss_fp: 0.003653, loss_freq: 0.024922
[07:08:48.050] iteration 26114: loss: 0.053268, loss_s1: 0.057876, loss_fp: 0.004675, loss_freq: 0.010534
[07:08:48.656] iteration 26115: loss: 0.023671, loss_s1: 0.016879, loss_fp: 0.001777, loss_freq: 0.005405
[07:08:49.270] iteration 26116: loss: 0.062068, loss_s1: 0.064173, loss_fp: 0.003456, loss_freq: 0.020528
[07:08:49.879] iteration 26117: loss: 0.056582, loss_s1: 0.056662, loss_fp: 0.002841, loss_freq: 0.021319
[07:08:50.551] iteration 26118: loss: 0.054327, loss_s1: 0.039384, loss_fp: 0.003431, loss_freq: 0.024829
[07:08:51.193] iteration 26119: loss: 0.062554, loss_s1: 0.037420, loss_fp: 0.008733, loss_freq: 0.044021
[07:08:51.839] iteration 26120: loss: 0.045774, loss_s1: 0.033723, loss_fp: 0.003591, loss_freq: 0.032753
[07:08:52.464] iteration 26121: loss: 0.055770, loss_s1: 0.043724, loss_fp: 0.009602, loss_freq: 0.019037
[07:08:53.079] iteration 26122: loss: 0.031677, loss_s1: 0.016526, loss_fp: 0.003681, loss_freq: 0.015155
[07:08:53.691] iteration 26123: loss: 0.053604, loss_s1: 0.038002, loss_fp: 0.004229, loss_freq: 0.041816
[07:08:54.304] iteration 26124: loss: 0.027062, loss_s1: 0.018540, loss_fp: 0.007960, loss_freq: 0.004383
[07:08:54.918] iteration 26125: loss: 0.059195, loss_s1: 0.039997, loss_fp: 0.004387, loss_freq: 0.041290
[07:08:55.526] iteration 26126: loss: 0.061132, loss_s1: 0.063451, loss_fp: 0.005513, loss_freq: 0.025485
[07:08:56.162] iteration 26127: loss: 0.080124, loss_s1: 0.080610, loss_fp: 0.003252, loss_freq: 0.042140
[07:08:56.771] iteration 26128: loss: 0.063137, loss_s1: 0.063990, loss_fp: 0.004408, loss_freq: 0.023224
[07:08:57.450] iteration 26129: loss: 0.066501, loss_s1: 0.076174, loss_fp: 0.001777, loss_freq: 0.029612
[07:08:58.125] iteration 26130: loss: 0.047168, loss_s1: 0.020676, loss_fp: 0.008674, loss_freq: 0.033973
[07:08:58.798] iteration 26131: loss: 0.044897, loss_s1: 0.043590, loss_fp: 0.002155, loss_freq: 0.010590
[07:08:59.452] iteration 26132: loss: 0.045501, loss_s1: 0.031655, loss_fp: 0.010709, loss_freq: 0.027280
[07:09:00.075] iteration 26133: loss: 0.045685, loss_s1: 0.023082, loss_fp: 0.004960, loss_freq: 0.037573
[07:09:00.696] iteration 26134: loss: 0.039681, loss_s1: 0.028304, loss_fp: 0.011060, loss_freq: 0.012355
[07:09:01.315] iteration 26135: loss: 0.074094, loss_s1: 0.049481, loss_fp: 0.005344, loss_freq: 0.056482
[07:09:01.938] iteration 26136: loss: 0.044641, loss_s1: 0.023290, loss_fp: 0.004549, loss_freq: 0.023046
[07:09:02.579] iteration 26137: loss: 0.067067, loss_s1: 0.066064, loss_fp: 0.003412, loss_freq: 0.043660
[07:09:03.225] iteration 26138: loss: 0.044294, loss_s1: 0.040513, loss_fp: 0.004880, loss_freq: 0.006625
[07:09:03.853] iteration 26139: loss: 0.054501, loss_s1: 0.058986, loss_fp: 0.003794, loss_freq: 0.019920
[07:09:04.485] iteration 26140: loss: 0.047891, loss_s1: 0.024745, loss_fp: 0.008310, loss_freq: 0.026446
[07:09:05.128] iteration 26141: loss: 0.067160, loss_s1: 0.083417, loss_fp: 0.001511, loss_freq: 0.023984
[07:09:05.736] iteration 26142: loss: 0.056964, loss_s1: 0.046267, loss_fp: 0.006973, loss_freq: 0.020048
[07:09:06.343] iteration 26143: loss: 0.059267, loss_s1: 0.053663, loss_fp: 0.004922, loss_freq: 0.028166
[07:09:06.954] iteration 26144: loss: 0.036270, loss_s1: 0.037981, loss_fp: 0.002808, loss_freq: 0.007242
[07:09:07.564] iteration 26145: loss: 0.061720, loss_s1: 0.037274, loss_fp: 0.025598, loss_freq: 0.028391
[07:09:08.169] iteration 26146: loss: 0.039911, loss_s1: 0.044334, loss_fp: 0.007726, loss_freq: 0.009007
[07:09:08.778] iteration 26147: loss: 0.097424, loss_s1: 0.045543, loss_fp: 0.006058, loss_freq: 0.035675
[07:09:09.383] iteration 26148: loss: 0.051297, loss_s1: 0.029080, loss_fp: 0.014560, loss_freq: 0.032648
[07:09:09.992] iteration 26149: loss: 0.111731, loss_s1: 0.146533, loss_fp: 0.004916, loss_freq: 0.045297
[07:09:10.603] iteration 26150: loss: 0.067435, loss_s1: 0.043109, loss_fp: 0.002640, loss_freq: 0.068954
[07:09:11.209] iteration 26151: loss: 0.048067, loss_s1: 0.043336, loss_fp: 0.002945, loss_freq: 0.017452
[07:09:11.817] iteration 26152: loss: 0.051128, loss_s1: 0.044936, loss_fp: 0.005414, loss_freq: 0.019369
[07:09:12.423] iteration 26153: loss: 0.038004, loss_s1: 0.029189, loss_fp: 0.001902, loss_freq: 0.016937
[07:09:13.035] iteration 26154: loss: 0.051115, loss_s1: 0.044892, loss_fp: 0.005486, loss_freq: 0.017024
[07:09:13.701] iteration 26155: loss: 0.030403, loss_s1: 0.016452, loss_fp: 0.006331, loss_freq: 0.014509
[07:09:14.361] iteration 26156: loss: 0.058425, loss_s1: 0.035384, loss_fp: 0.003856, loss_freq: 0.044887
[07:09:15.024] iteration 26157: loss: 0.055907, loss_s1: 0.048830, loss_fp: 0.004895, loss_freq: 0.028860
[07:09:15.680] iteration 26158: loss: 0.099530, loss_s1: 0.108236, loss_fp: 0.020052, loss_freq: 0.047024
[07:09:16.338] iteration 26159: loss: 0.074164, loss_s1: 0.069711, loss_fp: 0.005434, loss_freq: 0.055241
[07:09:17.006] iteration 26160: loss: 0.061569, loss_s1: 0.051693, loss_fp: 0.004666, loss_freq: 0.030700
[07:09:17.627] iteration 26161: loss: 0.052681, loss_s1: 0.043429, loss_fp: 0.004431, loss_freq: 0.026305
[07:09:18.243] iteration 26162: loss: 0.079530, loss_s1: 0.086675, loss_fp: 0.005538, loss_freq: 0.035902
[07:09:18.849] iteration 26163: loss: 0.058748, loss_s1: 0.042421, loss_fp: 0.003368, loss_freq: 0.047969
[07:09:19.461] iteration 26164: loss: 0.076979, loss_s1: 0.054433, loss_fp: 0.005410, loss_freq: 0.068328
[07:09:20.067] iteration 26165: loss: 0.061886, loss_s1: 0.054171, loss_fp: 0.004626, loss_freq: 0.026175
[07:09:20.681] iteration 26166: loss: 0.034319, loss_s1: 0.026752, loss_fp: 0.001620, loss_freq: 0.008678
[07:09:21.298] iteration 26167: loss: 0.033395, loss_s1: 0.032634, loss_fp: 0.003962, loss_freq: 0.010549
[07:09:21.942] iteration 26168: loss: 0.060217, loss_s1: 0.053094, loss_fp: 0.003457, loss_freq: 0.034900
[07:09:22.576] iteration 26169: loss: 0.061200, loss_s1: 0.053289, loss_fp: 0.006639, loss_freq: 0.030635
[07:09:23.188] iteration 26170: loss: 0.087095, loss_s1: 0.084139, loss_fp: 0.012620, loss_freq: 0.036498
[07:09:23.814] iteration 26171: loss: 0.041572, loss_s1: 0.039101, loss_fp: 0.004183, loss_freq: 0.009684
[07:09:24.425] iteration 26172: loss: 0.053745, loss_s1: 0.054794, loss_fp: 0.007221, loss_freq: 0.025067
[07:09:25.038] iteration 26173: loss: 0.052069, loss_s1: 0.022389, loss_fp: 0.013431, loss_freq: 0.033360
[07:09:25.653] iteration 26174: loss: 0.051111, loss_s1: 0.051694, loss_fp: 0.005660, loss_freq: 0.020804
[07:09:26.273] iteration 26175: loss: 0.041209, loss_s1: 0.044274, loss_fp: 0.002831, loss_freq: 0.009935
[07:09:26.893] iteration 26176: loss: 0.068805, loss_s1: 0.067887, loss_fp: 0.008574, loss_freq: 0.037808
[07:09:27.509] iteration 26177: loss: 0.077008, loss_s1: 0.082883, loss_fp: 0.003192, loss_freq: 0.032099
[07:09:28.116] iteration 26178: loss: 0.057532, loss_s1: 0.055307, loss_fp: 0.006184, loss_freq: 0.024005
[07:09:28.733] iteration 26179: loss: 0.063425, loss_s1: 0.063763, loss_fp: 0.004829, loss_freq: 0.030838
[07:09:29.343] iteration 26180: loss: 0.042772, loss_s1: 0.027564, loss_fp: 0.003207, loss_freq: 0.021561
[07:09:30.381] iteration 26181: loss: 0.093192, loss_s1: 0.095610, loss_fp: 0.003141, loss_freq: 0.045276
[07:09:31.038] iteration 26182: loss: 0.043030, loss_s1: 0.025735, loss_fp: 0.002804, loss_freq: 0.027245
[07:09:31.696] iteration 26183: loss: 0.041607, loss_s1: 0.033333, loss_fp: 0.002492, loss_freq: 0.020712
[07:09:32.356] iteration 26184: loss: 0.045184, loss_s1: 0.040352, loss_fp: 0.002742, loss_freq: 0.015166
[07:09:32.981] iteration 26185: loss: 0.042563, loss_s1: 0.030249, loss_fp: 0.001925, loss_freq: 0.023164
[07:09:33.592] iteration 26186: loss: 0.063797, loss_s1: 0.060547, loss_fp: 0.002669, loss_freq: 0.035147
[07:09:34.219] iteration 26187: loss: 0.078676, loss_s1: 0.103487, loss_fp: 0.004025, loss_freq: 0.019854
[07:09:34.826] iteration 26188: loss: 0.045790, loss_s1: 0.039478, loss_fp: 0.005973, loss_freq: 0.015598
[07:09:35.432] iteration 26189: loss: 0.034646, loss_s1: 0.018548, loss_fp: 0.004119, loss_freq: 0.025016
[07:09:36.037] iteration 26190: loss: 0.083503, loss_s1: 0.073997, loss_fp: 0.004838, loss_freq: 0.031247
[07:09:36.643] iteration 26191: loss: 0.040954, loss_s1: 0.030495, loss_fp: 0.005072, loss_freq: 0.014619
[07:09:37.259] iteration 26192: loss: 0.057375, loss_s1: 0.052862, loss_fp: 0.005700, loss_freq: 0.025915
[07:09:37.875] iteration 26193: loss: 0.068887, loss_s1: 0.047754, loss_fp: 0.002366, loss_freq: 0.063014
[07:09:38.522] iteration 26194: loss: 0.055843, loss_s1: 0.054568, loss_fp: 0.002479, loss_freq: 0.027087
[07:09:39.174] iteration 26195: loss: 0.035828, loss_s1: 0.026300, loss_fp: 0.003132, loss_freq: 0.013560
[07:09:39.820] iteration 26196: loss: 0.061546, loss_s1: 0.069161, loss_fp: 0.006646, loss_freq: 0.017061
[07:09:40.430] iteration 26197: loss: 0.080220, loss_s1: 0.079176, loss_fp: 0.006957, loss_freq: 0.052260
[07:09:41.038] iteration 26198: loss: 0.041588, loss_s1: 0.033063, loss_fp: 0.002504, loss_freq: 0.016113
[07:09:41.658] iteration 26199: loss: 0.054314, loss_s1: 0.045489, loss_fp: 0.012461, loss_freq: 0.023326
[07:09:42.268] iteration 26200: loss: 0.076729, loss_s1: 0.075124, loss_fp: 0.008020, loss_freq: 0.030698
[07:09:45.937] iteration 26200 : mean_dice : 0.740409
[07:09:46.621] iteration 26201: loss: 0.053250, loss_s1: 0.030052, loss_fp: 0.006963, loss_freq: 0.035995
[07:09:47.288] iteration 26202: loss: 0.067724, loss_s1: 0.043767, loss_fp: 0.015000, loss_freq: 0.054326
[07:09:47.953] iteration 26203: loss: 0.056880, loss_s1: 0.029768, loss_fp: 0.002691, loss_freq: 0.029882
[07:09:48.568] iteration 26204: loss: 0.071276, loss_s1: 0.062858, loss_fp: 0.002815, loss_freq: 0.053738
[07:09:49.182] iteration 26205: loss: 0.053475, loss_s1: 0.035285, loss_fp: 0.010756, loss_freq: 0.034916
[07:09:49.792] iteration 26206: loss: 0.053329, loss_s1: 0.024035, loss_fp: 0.008129, loss_freq: 0.048476
[07:09:50.408] iteration 26207: loss: 0.054232, loss_s1: 0.044791, loss_fp: 0.002774, loss_freq: 0.021781
[07:09:51.020] iteration 26208: loss: 0.098160, loss_s1: 0.086593, loss_fp: 0.007152, loss_freq: 0.065025
[07:09:51.642] iteration 26209: loss: 0.037975, loss_s1: 0.021224, loss_fp: 0.005080, loss_freq: 0.025684
[07:09:52.254] iteration 26210: loss: 0.059282, loss_s1: 0.057529, loss_fp: 0.003417, loss_freq: 0.028756
[07:09:52.868] iteration 26211: loss: 0.046038, loss_s1: 0.019389, loss_fp: 0.004208, loss_freq: 0.043553
[07:09:53.487] iteration 26212: loss: 0.062620, loss_s1: 0.051956, loss_fp: 0.007861, loss_freq: 0.033171
[07:09:54.104] iteration 26213: loss: 0.060530, loss_s1: 0.048380, loss_fp: 0.006652, loss_freq: 0.039226
[07:09:54.728] iteration 26214: loss: 0.046873, loss_s1: 0.017909, loss_fp: 0.010535, loss_freq: 0.037896
[07:09:55.348] iteration 26215: loss: 0.031940, loss_s1: 0.017887, loss_fp: 0.001449, loss_freq: 0.027171
[07:09:55.974] iteration 26216: loss: 0.044047, loss_s1: 0.031006, loss_fp: 0.007767, loss_freq: 0.015356
[07:09:56.591] iteration 26217: loss: 0.099198, loss_s1: 0.088646, loss_fp: 0.006694, loss_freq: 0.071944
[07:09:57.249] iteration 26218: loss: 0.073265, loss_s1: 0.108762, loss_fp: 0.004538, loss_freq: 0.009142
[07:09:57.906] iteration 26219: loss: 0.086440, loss_s1: 0.069080, loss_fp: 0.003439, loss_freq: 0.068907
[07:09:58.554] iteration 26220: loss: 0.061976, loss_s1: 0.055315, loss_fp: 0.004115, loss_freq: 0.034594
[07:09:59.168] iteration 26221: loss: 0.047442, loss_s1: 0.034542, loss_fp: 0.003653, loss_freq: 0.022213
[07:09:59.785] iteration 26222: loss: 0.100068, loss_s1: 0.080371, loss_fp: 0.003046, loss_freq: 0.082740
[07:10:00.392] iteration 26223: loss: 0.086342, loss_s1: 0.089687, loss_fp: 0.007935, loss_freq: 0.047407
[07:10:01.006] iteration 26224: loss: 0.097087, loss_s1: 0.120595, loss_fp: 0.006571, loss_freq: 0.045776
[07:10:01.616] iteration 26225: loss: 0.054650, loss_s1: 0.037421, loss_fp: 0.003086, loss_freq: 0.034701
[07:10:02.231] iteration 26226: loss: 0.109100, loss_s1: 0.140870, loss_fp: 0.011700, loss_freq: 0.036826
[07:10:02.844] iteration 26227: loss: 0.060990, loss_s1: 0.036493, loss_fp: 0.005324, loss_freq: 0.047308
[07:10:03.454] iteration 26228: loss: 0.045094, loss_s1: 0.032898, loss_fp: 0.009126, loss_freq: 0.025939
[07:10:04.076] iteration 26229: loss: 0.033218, loss_s1: 0.020417, loss_fp: 0.001836, loss_freq: 0.012951
[07:10:04.683] iteration 26230: loss: 0.038400, loss_s1: 0.027594, loss_fp: 0.001371, loss_freq: 0.006288
[07:10:05.299] iteration 26231: loss: 0.064390, loss_s1: 0.066608, loss_fp: 0.001921, loss_freq: 0.026658
[07:10:05.926] iteration 26232: loss: 0.055762, loss_s1: 0.042697, loss_fp: 0.006556, loss_freq: 0.040697
[07:10:06.550] iteration 26233: loss: 0.036039, loss_s1: 0.023182, loss_fp: 0.007542, loss_freq: 0.015936
[07:10:07.169] iteration 26234: loss: 0.071113, loss_s1: 0.082585, loss_fp: 0.006176, loss_freq: 0.024704
[07:10:07.786] iteration 26235: loss: 0.034576, loss_s1: 0.026561, loss_fp: 0.001170, loss_freq: 0.008191
[07:10:08.400] iteration 26236: loss: 0.048414, loss_s1: 0.034880, loss_fp: 0.003056, loss_freq: 0.023382
[07:10:09.010] iteration 26237: loss: 0.090508, loss_s1: 0.106448, loss_fp: 0.005643, loss_freq: 0.048812
[07:10:09.619] iteration 26238: loss: 0.043308, loss_s1: 0.033158, loss_fp: 0.001145, loss_freq: 0.017351
[07:10:10.243] iteration 26239: loss: 0.046122, loss_s1: 0.024477, loss_fp: 0.008230, loss_freq: 0.031631
[07:10:10.859] iteration 26240: loss: 0.043138, loss_s1: 0.022326, loss_fp: 0.005299, loss_freq: 0.027746
[07:10:11.479] iteration 26241: loss: 0.032618, loss_s1: 0.028633, loss_fp: 0.000661, loss_freq: 0.007736
[07:10:12.176] iteration 26242: loss: 0.051322, loss_s1: 0.036908, loss_fp: 0.001145, loss_freq: 0.034441
[07:10:12.818] iteration 26243: loss: 0.047026, loss_s1: 0.043631, loss_fp: 0.001047, loss_freq: 0.014738
[07:10:13.432] iteration 26244: loss: 0.048020, loss_s1: 0.045081, loss_fp: 0.002639, loss_freq: 0.020508
[07:10:14.044] iteration 26245: loss: 0.042040, loss_s1: 0.035936, loss_fp: 0.000698, loss_freq: 0.012132
[07:10:14.654] iteration 26246: loss: 0.047276, loss_s1: 0.037477, loss_fp: 0.001601, loss_freq: 0.032425
[07:10:15.258] iteration 26247: loss: 0.036928, loss_s1: 0.029405, loss_fp: 0.003211, loss_freq: 0.008658
[07:10:15.870] iteration 26248: loss: 0.107973, loss_s1: 0.116691, loss_fp: 0.009406, loss_freq: 0.059601
[07:10:16.479] iteration 26249: loss: 0.039578, loss_s1: 0.026428, loss_fp: 0.002900, loss_freq: 0.016106
[07:10:17.165] iteration 26250: loss: 0.059119, loss_s1: 0.047354, loss_fp: 0.002723, loss_freq: 0.044337
[07:10:18.006] iteration 26251: loss: 0.088708, loss_s1: 0.067500, loss_fp: 0.004354, loss_freq: 0.053586
[07:10:18.725] iteration 26252: loss: 0.051485, loss_s1: 0.036465, loss_fp: 0.007476, loss_freq: 0.025239
[07:10:19.352] iteration 26253: loss: 0.047667, loss_s1: 0.039896, loss_fp: 0.003424, loss_freq: 0.026256
[07:10:19.960] iteration 26254: loss: 0.042696, loss_s1: 0.033973, loss_fp: 0.003929, loss_freq: 0.017361
[07:10:20.574] iteration 26255: loss: 0.054565, loss_s1: 0.027453, loss_fp: 0.001207, loss_freq: 0.053099
[07:10:21.246] iteration 26256: loss: 0.060191, loss_s1: 0.044781, loss_fp: 0.003020, loss_freq: 0.038982
[07:10:21.856] iteration 26257: loss: 0.037595, loss_s1: 0.026717, loss_fp: 0.003009, loss_freq: 0.019657
[07:10:22.470] iteration 26258: loss: 0.045557, loss_s1: 0.032361, loss_fp: 0.004267, loss_freq: 0.028967
[07:10:23.089] iteration 26259: loss: 0.029948, loss_s1: 0.018875, loss_fp: 0.002191, loss_freq: 0.017037
[07:10:23.696] iteration 26260: loss: 0.059156, loss_s1: 0.041159, loss_fp: 0.003498, loss_freq: 0.039827
[07:10:24.304] iteration 26261: loss: 0.037560, loss_s1: 0.030751, loss_fp: 0.001989, loss_freq: 0.004450
[07:10:24.920] iteration 26262: loss: 0.043531, loss_s1: 0.024416, loss_fp: 0.002267, loss_freq: 0.026535
[07:10:25.542] iteration 26263: loss: 0.048594, loss_s1: 0.049562, loss_fp: 0.000971, loss_freq: 0.020768
[07:10:26.156] iteration 26264: loss: 0.060585, loss_s1: 0.078539, loss_fp: 0.002763, loss_freq: 0.012920
[07:10:26.776] iteration 26265: loss: 0.065151, loss_s1: 0.053546, loss_fp: 0.002044, loss_freq: 0.035056
[07:10:27.384] iteration 26266: loss: 0.063187, loss_s1: 0.050703, loss_fp: 0.006927, loss_freq: 0.028524
[07:10:27.991] iteration 26267: loss: 0.082292, loss_s1: 0.098867, loss_fp: 0.004208, loss_freq: 0.035324
[07:10:28.610] iteration 26268: loss: 0.039510, loss_s1: 0.029579, loss_fp: 0.001993, loss_freq: 0.014232
[07:10:29.234] iteration 26269: loss: 0.040023, loss_s1: 0.030778, loss_fp: 0.003681, loss_freq: 0.018913
[07:10:29.855] iteration 26270: loss: 0.033068, loss_s1: 0.016677, loss_fp: 0.002376, loss_freq: 0.014038
[07:10:30.481] iteration 26271: loss: 0.074691, loss_s1: 0.074325, loss_fp: 0.004927, loss_freq: 0.036981
[07:10:31.076] iteration 26272: loss: 0.050709, loss_s1: 0.020004, loss_fp: 0.006602, loss_freq: 0.053040
[07:10:31.706] iteration 26273: loss: 0.066919, loss_s1: 0.068584, loss_fp: 0.003511, loss_freq: 0.031175
[07:10:32.381] iteration 26274: loss: 0.048910, loss_s1: 0.028226, loss_fp: 0.008000, loss_freq: 0.032190
[07:10:33.035] iteration 26275: loss: 0.079283, loss_s1: 0.085730, loss_fp: 0.007293, loss_freq: 0.030631
[07:10:33.649] iteration 26276: loss: 0.074945, loss_s1: 0.095342, loss_fp: 0.003708, loss_freq: 0.028585
[07:10:34.277] iteration 26277: loss: 0.100627, loss_s1: 0.075618, loss_fp: 0.006790, loss_freq: 0.061511
[07:10:34.932] iteration 26278: loss: 0.056121, loss_s1: 0.042391, loss_fp: 0.005090, loss_freq: 0.030084
[07:10:35.543] iteration 26279: loss: 0.042016, loss_s1: 0.017446, loss_fp: 0.003809, loss_freq: 0.020280
[07:10:36.198] iteration 26280: loss: 0.056333, loss_s1: 0.051569, loss_fp: 0.002487, loss_freq: 0.023334
[07:10:36.851] iteration 26281: loss: 0.041787, loss_s1: 0.044693, loss_fp: 0.003218, loss_freq: 0.011876
[07:10:37.475] iteration 26282: loss: 0.057401, loss_s1: 0.045512, loss_fp: 0.011646, loss_freq: 0.023552
[07:10:38.093] iteration 26283: loss: 0.044909, loss_s1: 0.046912, loss_fp: 0.003348, loss_freq: 0.015777
[07:10:38.699] iteration 26284: loss: 0.038914, loss_s1: 0.011119, loss_fp: 0.010294, loss_freq: 0.032324
[07:10:39.304] iteration 26285: loss: 0.035933, loss_s1: 0.034080, loss_fp: 0.001387, loss_freq: 0.015233
[07:10:39.917] iteration 26286: loss: 0.083036, loss_s1: 0.081383, loss_fp: 0.004132, loss_freq: 0.038836
[07:10:40.537] iteration 26287: loss: 0.054656, loss_s1: 0.052037, loss_fp: 0.007286, loss_freq: 0.017291
[07:10:41.168] iteration 26288: loss: 0.046576, loss_s1: 0.048582, loss_fp: 0.007956, loss_freq: 0.012711
[07:10:41.791] iteration 26289: loss: 0.051492, loss_s1: 0.030348, loss_fp: 0.005560, loss_freq: 0.037394
[07:10:42.408] iteration 26290: loss: 0.053556, loss_s1: 0.028523, loss_fp: 0.005825, loss_freq: 0.041668
[07:10:43.050] iteration 26291: loss: 0.046572, loss_s1: 0.043985, loss_fp: 0.002465, loss_freq: 0.013981
[07:10:43.748] iteration 26292: loss: 0.043629, loss_s1: 0.036316, loss_fp: 0.004822, loss_freq: 0.011550
[07:10:44.377] iteration 26293: loss: 0.051058, loss_s1: 0.040733, loss_fp: 0.002670, loss_freq: 0.034998
[07:10:44.988] iteration 26294: loss: 0.039990, loss_s1: 0.024369, loss_fp: 0.002368, loss_freq: 0.026576
[07:10:45.606] iteration 26295: loss: 0.116991, loss_s1: 0.096626, loss_fp: 0.004741, loss_freq: 0.084638
[07:10:46.220] iteration 26296: loss: 0.076189, loss_s1: 0.038801, loss_fp: 0.009919, loss_freq: 0.059815
[07:10:46.845] iteration 26297: loss: 0.074148, loss_s1: 0.079024, loss_fp: 0.003259, loss_freq: 0.032693
[07:10:47.476] iteration 26298: loss: 0.064779, loss_s1: 0.061837, loss_fp: 0.005179, loss_freq: 0.038941
[07:10:48.118] iteration 26299: loss: 0.041107, loss_s1: 0.030162, loss_fp: 0.001770, loss_freq: 0.019549
[07:10:48.736] iteration 26300: loss: 0.061677, loss_s1: 0.055807, loss_fp: 0.002300, loss_freq: 0.027234
[07:10:49.360] iteration 26301: loss: 0.028521, loss_s1: 0.017640, loss_fp: 0.001696, loss_freq: 0.006694
[07:10:49.984] iteration 26302: loss: 0.083224, loss_s1: 0.079440, loss_fp: 0.002276, loss_freq: 0.066324
[07:10:50.601] iteration 26303: loss: 0.076947, loss_s1: 0.054926, loss_fp: 0.011755, loss_freq: 0.058984
[07:10:51.229] iteration 26304: loss: 0.054437, loss_s1: 0.042138, loss_fp: 0.002474, loss_freq: 0.034689
[07:10:51.915] iteration 26305: loss: 0.081711, loss_s1: 0.073969, loss_fp: 0.003826, loss_freq: 0.035631
[07:10:52.576] iteration 26306: loss: 0.058719, loss_s1: 0.047972, loss_fp: 0.003642, loss_freq: 0.038023
[07:10:53.212] iteration 26307: loss: 0.054421, loss_s1: 0.055938, loss_fp: 0.002146, loss_freq: 0.027897
[07:10:53.824] iteration 26308: loss: 0.041215, loss_s1: 0.014308, loss_fp: 0.011158, loss_freq: 0.022958
[07:10:54.443] iteration 26309: loss: 0.080542, loss_s1: 0.097734, loss_fp: 0.010360, loss_freq: 0.025813
[07:10:55.046] iteration 26310: loss: 0.087301, loss_s1: 0.042778, loss_fp: 0.005870, loss_freq: 0.093607
[07:10:55.675] iteration 26311: loss: 0.059103, loss_s1: 0.060446, loss_fp: 0.005633, loss_freq: 0.028698
[07:10:56.297] iteration 26312: loss: 0.045437, loss_s1: 0.045484, loss_fp: 0.003055, loss_freq: 0.006970
[07:10:56.912] iteration 26313: loss: 0.092649, loss_s1: 0.104194, loss_fp: 0.018968, loss_freq: 0.031729
[07:10:57.518] iteration 26314: loss: 0.039549, loss_s1: 0.025705, loss_fp: 0.003043, loss_freq: 0.022171
[07:10:58.137] iteration 26315: loss: 0.045851, loss_s1: 0.037882, loss_fp: 0.003754, loss_freq: 0.015718
[07:10:58.753] iteration 26316: loss: 0.040706, loss_s1: 0.034184, loss_fp: 0.002331, loss_freq: 0.019031
[07:10:59.359] iteration 26317: loss: 0.088131, loss_s1: 0.108417, loss_fp: 0.006747, loss_freq: 0.020468
[07:10:59.962] iteration 26318: loss: 0.049917, loss_s1: 0.042364, loss_fp: 0.005644, loss_freq: 0.026723
[07:11:00.574] iteration 26319: loss: 0.098872, loss_s1: 0.105727, loss_fp: 0.007351, loss_freq: 0.049031
[07:11:01.252] iteration 26320: loss: 0.048465, loss_s1: 0.050341, loss_fp: 0.002501, loss_freq: 0.017815
[07:11:01.913] iteration 26321: loss: 0.072657, loss_s1: 0.070951, loss_fp: 0.007039, loss_freq: 0.035049
[07:11:02.558] iteration 26322: loss: 0.072345, loss_s1: 0.072160, loss_fp: 0.002611, loss_freq: 0.040128
[07:11:03.173] iteration 26323: loss: 0.056490, loss_s1: 0.046378, loss_fp: 0.003060, loss_freq: 0.034498
[07:11:03.783] iteration 26324: loss: 0.057161, loss_s1: 0.063518, loss_fp: 0.003182, loss_freq: 0.018766
[07:11:04.444] iteration 26325: loss: 0.054959, loss_s1: 0.065472, loss_fp: 0.001767, loss_freq: 0.019261
[07:11:05.072] iteration 26326: loss: 0.067837, loss_s1: 0.061907, loss_fp: 0.002553, loss_freq: 0.036239
[07:11:05.717] iteration 26327: loss: 0.048185, loss_s1: 0.036052, loss_fp: 0.003021, loss_freq: 0.015457
[07:11:06.336] iteration 26328: loss: 0.071027, loss_s1: 0.073286, loss_fp: 0.002764, loss_freq: 0.025047
[07:11:06.961] iteration 26329: loss: 0.078521, loss_s1: 0.076616, loss_fp: 0.011241, loss_freq: 0.044530
[07:11:07.579] iteration 26330: loss: 0.053059, loss_s1: 0.035843, loss_fp: 0.001910, loss_freq: 0.037357
[07:11:08.215] iteration 26331: loss: 0.057065, loss_s1: 0.030585, loss_fp: 0.005299, loss_freq: 0.049104
[07:11:08.831] iteration 26332: loss: 0.061129, loss_s1: 0.045156, loss_fp: 0.002744, loss_freq: 0.044000
[07:11:09.446] iteration 26333: loss: 0.084945, loss_s1: 0.089838, loss_fp: 0.004565, loss_freq: 0.045058
[07:11:10.092] iteration 26334: loss: 0.074095, loss_s1: 0.072489, loss_fp: 0.007040, loss_freq: 0.038519
[07:11:10.713] iteration 26335: loss: 0.071618, loss_s1: 0.069068, loss_fp: 0.003335, loss_freq: 0.036545
[07:11:11.329] iteration 26336: loss: 0.042948, loss_s1: 0.043123, loss_fp: 0.000773, loss_freq: 0.008617
[07:11:11.960] iteration 26337: loss: 0.042675, loss_s1: 0.042770, loss_fp: 0.006345, loss_freq: 0.014235
[07:11:12.565] iteration 26338: loss: 0.071406, loss_s1: 0.060262, loss_fp: 0.001734, loss_freq: 0.053643
[07:11:13.174] iteration 26339: loss: 0.054836, loss_s1: 0.039102, loss_fp: 0.006520, loss_freq: 0.029624
[07:11:13.800] iteration 26340: loss: 0.063237, loss_s1: 0.060916, loss_fp: 0.005330, loss_freq: 0.027332
[07:11:14.418] iteration 26341: loss: 0.049823, loss_s1: 0.051343, loss_fp: 0.004273, loss_freq: 0.012411
[07:11:15.036] iteration 26342: loss: 0.063133, loss_s1: 0.059789, loss_fp: 0.015892, loss_freq: 0.032926
[07:11:15.652] iteration 26343: loss: 0.049912, loss_s1: 0.031520, loss_fp: 0.001793, loss_freq: 0.009824
[07:11:16.261] iteration 26344: loss: 0.053675, loss_s1: 0.048300, loss_fp: 0.006234, loss_freq: 0.029041
[07:11:16.902] iteration 26345: loss: 0.029795, loss_s1: 0.021699, loss_fp: 0.002025, loss_freq: 0.008026
[07:11:17.555] iteration 26346: loss: 0.070163, loss_s1: 0.045015, loss_fp: 0.003723, loss_freq: 0.069116
[07:11:18.193] iteration 26347: loss: 0.041724, loss_s1: 0.032398, loss_fp: 0.003036, loss_freq: 0.016810
[07:11:18.791] iteration 26348: loss: 0.054637, loss_s1: 0.046767, loss_fp: 0.003147, loss_freq: 0.025076
[07:11:19.408] iteration 26349: loss: 0.065124, loss_s1: 0.060463, loss_fp: 0.004890, loss_freq: 0.039620
[07:11:20.022] iteration 26350: loss: 0.055892, loss_s1: 0.040006, loss_fp: 0.001173, loss_freq: 0.037258
[07:11:20.966] iteration 26351: loss: 0.082815, loss_s1: 0.066329, loss_fp: 0.005830, loss_freq: 0.062019
[07:11:21.578] iteration 26352: loss: 0.054864, loss_s1: 0.045207, loss_fp: 0.004549, loss_freq: 0.024654
[07:11:22.181] iteration 26353: loss: 0.062384, loss_s1: 0.067903, loss_fp: 0.003475, loss_freq: 0.026279
[07:11:22.784] iteration 26354: loss: 0.043654, loss_s1: 0.034258, loss_fp: 0.003855, loss_freq: 0.020466
[07:11:23.378] iteration 26355: loss: 0.067422, loss_s1: 0.087563, loss_fp: 0.003786, loss_freq: 0.018432
[07:11:23.980] iteration 26356: loss: 0.062061, loss_s1: 0.057491, loss_fp: 0.001275, loss_freq: 0.037932
[07:11:24.588] iteration 26357: loss: 0.048418, loss_s1: 0.030887, loss_fp: 0.002728, loss_freq: 0.024309
[07:11:25.198] iteration 26358: loss: 0.046316, loss_s1: 0.030936, loss_fp: 0.003510, loss_freq: 0.017861
[07:11:25.812] iteration 26359: loss: 0.042389, loss_s1: 0.036701, loss_fp: 0.002856, loss_freq: 0.025788
[07:11:26.414] iteration 26360: loss: 0.075460, loss_s1: 0.073620, loss_fp: 0.004742, loss_freq: 0.039486
[07:11:27.020] iteration 26361: loss: 0.038439, loss_s1: 0.020567, loss_fp: 0.003102, loss_freq: 0.022474
[07:11:27.631] iteration 26362: loss: 0.097571, loss_s1: 0.092702, loss_fp: 0.003377, loss_freq: 0.067090
[07:11:28.239] iteration 26363: loss: 0.052806, loss_s1: 0.045324, loss_fp: 0.002245, loss_freq: 0.029287
[07:11:28.841] iteration 26364: loss: 0.088986, loss_s1: 0.054484, loss_fp: 0.008600, loss_freq: 0.085144
[07:11:29.455] iteration 26365: loss: 0.052804, loss_s1: 0.056196, loss_fp: 0.001684, loss_freq: 0.012864
[07:11:30.063] iteration 26366: loss: 0.060627, loss_s1: 0.062133, loss_fp: 0.003597, loss_freq: 0.027337
[07:11:30.664] iteration 26367: loss: 0.065224, loss_s1: 0.078718, loss_fp: 0.002622, loss_freq: 0.030218
[07:11:31.284] iteration 26368: loss: 0.029715, loss_s1: 0.017478, loss_fp: 0.003600, loss_freq: 0.010350
[07:11:31.904] iteration 26369: loss: 0.070311, loss_s1: 0.076622, loss_fp: 0.004931, loss_freq: 0.032042
[07:11:32.519] iteration 26370: loss: 0.053271, loss_s1: 0.051349, loss_fp: 0.003807, loss_freq: 0.010903
[07:11:33.133] iteration 26371: loss: 0.051215, loss_s1: 0.045899, loss_fp: 0.005098, loss_freq: 0.021480
[07:11:33.722] iteration 26372: loss: 0.044736, loss_s1: 0.034425, loss_fp: 0.012722, loss_freq: 0.022764
[07:11:34.334] iteration 26373: loss: 0.048185, loss_s1: 0.019103, loss_fp: 0.016462, loss_freq: 0.023434
[07:11:34.941] iteration 26374: loss: 0.049460, loss_s1: 0.051532, loss_fp: 0.002412, loss_freq: 0.015400
[07:11:35.553] iteration 26375: loss: 0.072534, loss_s1: 0.059534, loss_fp: 0.006071, loss_freq: 0.051373
[07:11:36.158] iteration 26376: loss: 0.051188, loss_s1: 0.043383, loss_fp: 0.003603, loss_freq: 0.035169
[07:11:36.767] iteration 26377: loss: 0.052473, loss_s1: 0.037423, loss_fp: 0.004060, loss_freq: 0.022751
[07:11:37.387] iteration 26378: loss: 0.051760, loss_s1: 0.044750, loss_fp: 0.002250, loss_freq: 0.019741
[07:11:38.009] iteration 26379: loss: 0.045381, loss_s1: 0.038195, loss_fp: 0.003481, loss_freq: 0.020320
[07:11:38.642] iteration 26380: loss: 0.094977, loss_s1: 0.128385, loss_fp: 0.003728, loss_freq: 0.021020
[07:11:39.254] iteration 26381: loss: 0.045866, loss_s1: 0.023835, loss_fp: 0.005312, loss_freq: 0.040599
[07:11:39.866] iteration 26382: loss: 0.091908, loss_s1: 0.109833, loss_fp: 0.015162, loss_freq: 0.023695
[07:11:40.487] iteration 26383: loss: 0.046325, loss_s1: 0.032286, loss_fp: 0.005318, loss_freq: 0.029981
[07:11:41.094] iteration 26384: loss: 0.038172, loss_s1: 0.012334, loss_fp: 0.007008, loss_freq: 0.016264
[07:11:41.701] iteration 26385: loss: 0.048484, loss_s1: 0.036622, loss_fp: 0.002028, loss_freq: 0.034263
[07:11:42.312] iteration 26386: loss: 0.040731, loss_s1: 0.025854, loss_fp: 0.001959, loss_freq: 0.009052
[07:11:42.924] iteration 26387: loss: 0.065255, loss_s1: 0.061876, loss_fp: 0.003400, loss_freq: 0.027081
[07:11:43.555] iteration 26388: loss: 0.078356, loss_s1: 0.117030, loss_fp: 0.001125, loss_freq: 0.015281
[07:11:44.166] iteration 26389: loss: 0.078487, loss_s1: 0.050173, loss_fp: 0.003973, loss_freq: 0.072191
[07:11:44.792] iteration 26390: loss: 0.063621, loss_s1: 0.060352, loss_fp: 0.005625, loss_freq: 0.037724
[07:11:45.412] iteration 26391: loss: 0.061705, loss_s1: 0.066348, loss_fp: 0.004514, loss_freq: 0.018443
[07:11:46.021] iteration 26392: loss: 0.055035, loss_s1: 0.046315, loss_fp: 0.006054, loss_freq: 0.028644
[07:11:46.643] iteration 26393: loss: 0.078815, loss_s1: 0.082581, loss_fp: 0.007940, loss_freq: 0.042884
[07:11:47.258] iteration 26394: loss: 0.086494, loss_s1: 0.100079, loss_fp: 0.005446, loss_freq: 0.047659
[07:11:47.869] iteration 26395: loss: 0.076250, loss_s1: 0.080740, loss_fp: 0.003459, loss_freq: 0.037554
[07:11:48.485] iteration 26396: loss: 0.081392, loss_s1: 0.101186, loss_fp: 0.011244, loss_freq: 0.019128
[07:11:49.096] iteration 26397: loss: 0.045418, loss_s1: 0.033619, loss_fp: 0.003058, loss_freq: 0.024351
[07:11:49.707] iteration 26398: loss: 0.066788, loss_s1: 0.070082, loss_fp: 0.004051, loss_freq: 0.029850
[07:11:50.332] iteration 26399: loss: 0.053828, loss_s1: 0.057404, loss_fp: 0.004881, loss_freq: 0.016185
[07:11:50.950] iteration 26400: loss: 0.042473, loss_s1: 0.022917, loss_fp: 0.001284, loss_freq: 0.028981
[07:11:54.227] iteration 26400 : mean_dice : 0.739324
[07:11:54.877] iteration 26401: loss: 0.055222, loss_s1: 0.046553, loss_fp: 0.007004, loss_freq: 0.022171
[07:11:55.482] iteration 26402: loss: 0.034722, loss_s1: 0.024535, loss_fp: 0.002291, loss_freq: 0.024043
[07:11:56.095] iteration 26403: loss: 0.038163, loss_s1: 0.015653, loss_fp: 0.001205, loss_freq: 0.023838
[07:11:56.711] iteration 26404: loss: 0.072528, loss_s1: 0.086665, loss_fp: 0.015646, loss_freq: 0.014864
[07:11:57.315] iteration 26405: loss: 0.047031, loss_s1: 0.017039, loss_fp: 0.001749, loss_freq: 0.027477
[07:11:57.925] iteration 26406: loss: 0.046709, loss_s1: 0.036617, loss_fp: 0.001636, loss_freq: 0.027233
[07:11:58.530] iteration 26407: loss: 0.070388, loss_s1: 0.075417, loss_fp: 0.013631, loss_freq: 0.026066
[07:11:59.138] iteration 26408: loss: 0.046389, loss_s1: 0.029536, loss_fp: 0.001156, loss_freq: 0.016449
[07:11:59.744] iteration 26409: loss: 0.042779, loss_s1: 0.034991, loss_fp: 0.003146, loss_freq: 0.023530
[07:12:00.354] iteration 26410: loss: 0.050535, loss_s1: 0.043718, loss_fp: 0.000813, loss_freq: 0.028563
[07:12:00.967] iteration 26411: loss: 0.034562, loss_s1: 0.028932, loss_fp: 0.001637, loss_freq: 0.017518
[07:12:01.587] iteration 26412: loss: 0.061094, loss_s1: 0.049589, loss_fp: 0.004841, loss_freq: 0.034036
[07:12:02.200] iteration 26413: loss: 0.044423, loss_s1: 0.035704, loss_fp: 0.003088, loss_freq: 0.017341
[07:12:02.817] iteration 26414: loss: 0.045255, loss_s1: 0.044178, loss_fp: 0.002467, loss_freq: 0.016925
[07:12:03.424] iteration 26415: loss: 0.063971, loss_s1: 0.069461, loss_fp: 0.003278, loss_freq: 0.013404
[07:12:04.102] iteration 26416: loss: 0.027493, loss_s1: 0.016055, loss_fp: 0.003007, loss_freq: 0.016966
[07:12:04.750] iteration 26417: loss: 0.047026, loss_s1: 0.043873, loss_fp: 0.003542, loss_freq: 0.009977
[07:12:05.397] iteration 26418: loss: 0.106609, loss_s1: 0.115561, loss_fp: 0.007564, loss_freq: 0.063391
[07:12:06.042] iteration 26419: loss: 0.045220, loss_s1: 0.009114, loss_fp: 0.009580, loss_freq: 0.045059
[07:12:06.702] iteration 26420: loss: 0.039586, loss_s1: 0.039683, loss_fp: 0.001628, loss_freq: 0.014847
[07:12:07.353] iteration 26421: loss: 0.063771, loss_s1: 0.034201, loss_fp: 0.009825, loss_freq: 0.023274
[07:12:08.056] iteration 26422: loss: 0.049072, loss_s1: 0.057900, loss_fp: 0.001982, loss_freq: 0.005734
[07:12:08.805] iteration 26423: loss: 0.056230, loss_s1: 0.037078, loss_fp: 0.006679, loss_freq: 0.035585
[07:12:09.506] iteration 26424: loss: 0.061882, loss_s1: 0.053861, loss_fp: 0.004908, loss_freq: 0.030353
[07:12:10.173] iteration 26425: loss: 0.045868, loss_s1: 0.026211, loss_fp: 0.005528, loss_freq: 0.035854
[07:12:10.899] iteration 26426: loss: 0.079967, loss_s1: 0.066340, loss_fp: 0.011005, loss_freq: 0.044123
[07:12:11.534] iteration 26427: loss: 0.045196, loss_s1: 0.029104, loss_fp: 0.006779, loss_freq: 0.025743
[07:12:12.268] iteration 26428: loss: 0.058547, loss_s1: 0.062533, loss_fp: 0.005928, loss_freq: 0.024806
[07:12:12.989] iteration 26429: loss: 0.051100, loss_s1: 0.032562, loss_fp: 0.008278, loss_freq: 0.040402
[07:12:13.694] iteration 26430: loss: 0.060868, loss_s1: 0.056057, loss_fp: 0.002965, loss_freq: 0.024484
[07:12:14.404] iteration 26431: loss: 0.062164, loss_s1: 0.043854, loss_fp: 0.006820, loss_freq: 0.042055
[07:12:15.072] iteration 26432: loss: 0.046205, loss_s1: 0.040123, loss_fp: 0.002622, loss_freq: 0.019834
[07:12:15.747] iteration 26433: loss: 0.061556, loss_s1: 0.072972, loss_fp: 0.010016, loss_freq: 0.012415
[07:12:16.371] iteration 26434: loss: 0.034660, loss_s1: 0.017457, loss_fp: 0.006187, loss_freq: 0.014088
[07:12:17.132] iteration 26435: loss: 0.037142, loss_s1: 0.020180, loss_fp: 0.002296, loss_freq: 0.019234
[07:12:17.823] iteration 26436: loss: 0.054882, loss_s1: 0.048281, loss_fp: 0.003868, loss_freq: 0.026435
[07:12:18.579] iteration 26437: loss: 0.053596, loss_s1: 0.046465, loss_fp: 0.006810, loss_freq: 0.032618
[07:12:19.316] iteration 26438: loss: 0.053252, loss_s1: 0.047155, loss_fp: 0.012452, loss_freq: 0.017270
[07:12:19.979] iteration 26439: loss: 0.057978, loss_s1: 0.038472, loss_fp: 0.013715, loss_freq: 0.035382
[07:12:20.614] iteration 26440: loss: 0.055174, loss_s1: 0.018790, loss_fp: 0.010342, loss_freq: 0.023024
[07:12:21.216] iteration 26441: loss: 0.074857, loss_s1: 0.070396, loss_fp: 0.005428, loss_freq: 0.043271
[07:12:21.828] iteration 26442: loss: 0.075036, loss_s1: 0.048024, loss_fp: 0.010454, loss_freq: 0.070723
[07:12:22.537] iteration 26443: loss: 0.044147, loss_s1: 0.026678, loss_fp: 0.004196, loss_freq: 0.020261
[07:12:23.437] iteration 26444: loss: 0.058496, loss_s1: 0.052480, loss_fp: 0.001220, loss_freq: 0.022552
[07:12:24.206] iteration 26445: loss: 0.048887, loss_s1: 0.028360, loss_fp: 0.007651, loss_freq: 0.032950
[07:12:24.946] iteration 26446: loss: 0.051275, loss_s1: 0.053488, loss_fp: 0.001398, loss_freq: 0.028320
[07:12:25.541] iteration 26447: loss: 0.098133, loss_s1: 0.124202, loss_fp: 0.005011, loss_freq: 0.020828
[07:12:26.148] iteration 26448: loss: 0.062805, loss_s1: 0.056934, loss_fp: 0.001385, loss_freq: 0.034146
[07:12:26.751] iteration 26449: loss: 0.070503, loss_s1: 0.065588, loss_fp: 0.013136, loss_freq: 0.038739
[07:12:27.361] iteration 26450: loss: 0.048111, loss_s1: 0.038280, loss_fp: 0.000691, loss_freq: 0.021070
[07:12:27.970] iteration 26451: loss: 0.046893, loss_s1: 0.030333, loss_fp: 0.007081, loss_freq: 0.029872
[07:12:28.580] iteration 26452: loss: 0.038341, loss_s1: 0.020867, loss_fp: 0.003765, loss_freq: 0.013227
[07:12:29.191] iteration 26453: loss: 0.039154, loss_s1: 0.021627, loss_fp: 0.001847, loss_freq: 0.026650
[07:12:29.800] iteration 26454: loss: 0.039126, loss_s1: 0.014324, loss_fp: 0.008071, loss_freq: 0.021472
[07:12:30.408] iteration 26455: loss: 0.026336, loss_s1: 0.012240, loss_fp: 0.006186, loss_freq: 0.012875
[07:12:31.003] iteration 26456: loss: 0.047520, loss_s1: 0.042448, loss_fp: 0.002094, loss_freq: 0.016686
[07:12:31.602] iteration 26457: loss: 0.063528, loss_s1: 0.067828, loss_fp: 0.003486, loss_freq: 0.017970
[07:12:32.236] iteration 26458: loss: 0.032569, loss_s1: 0.020349, loss_fp: 0.002995, loss_freq: 0.016585
[07:12:32.840] iteration 26459: loss: 0.057498, loss_s1: 0.062583, loss_fp: 0.002412, loss_freq: 0.021870
[07:12:33.449] iteration 26460: loss: 0.049849, loss_s1: 0.047141, loss_fp: 0.002631, loss_freq: 0.019856
[07:12:34.341] iteration 26461: loss: 0.048457, loss_s1: 0.038402, loss_fp: 0.006101, loss_freq: 0.020050
[07:12:35.173] iteration 26462: loss: 0.048328, loss_s1: 0.042782, loss_fp: 0.004293, loss_freq: 0.018645
[07:12:35.868] iteration 26463: loss: 0.063786, loss_s1: 0.053051, loss_fp: 0.004044, loss_freq: 0.045240
[07:12:36.507] iteration 26464: loss: 0.023988, loss_s1: 0.006326, loss_fp: 0.005238, loss_freq: 0.010681
[07:12:37.134] iteration 26465: loss: 0.069164, loss_s1: 0.042555, loss_fp: 0.003627, loss_freq: 0.046544
[07:12:37.747] iteration 26466: loss: 0.064451, loss_s1: 0.020522, loss_fp: 0.018700, loss_freq: 0.044425
[07:12:38.366] iteration 26467: loss: 0.048529, loss_s1: 0.030071, loss_fp: 0.001836, loss_freq: 0.025785
[07:12:38.976] iteration 26468: loss: 0.067001, loss_s1: 0.068235, loss_fp: 0.002004, loss_freq: 0.034818
[07:12:39.582] iteration 26469: loss: 0.071084, loss_s1: 0.034060, loss_fp: 0.001571, loss_freq: 0.079815
[07:12:40.195] iteration 26470: loss: 0.052677, loss_s1: 0.043476, loss_fp: 0.001627, loss_freq: 0.022974
[07:12:40.808] iteration 26471: loss: 0.034468, loss_s1: 0.023173, loss_fp: 0.002765, loss_freq: 0.007971
[07:12:41.423] iteration 26472: loss: 0.058419, loss_s1: 0.067957, loss_fp: 0.005601, loss_freq: 0.020829
[07:12:42.049] iteration 26473: loss: 0.058991, loss_s1: 0.034760, loss_fp: 0.011647, loss_freq: 0.039151
[07:12:42.680] iteration 26474: loss: 0.045882, loss_s1: 0.026592, loss_fp: 0.007900, loss_freq: 0.025177
[07:12:43.310] iteration 26475: loss: 0.068454, loss_s1: 0.048295, loss_fp: 0.003386, loss_freq: 0.051178
[07:12:43.913] iteration 26476: loss: 0.048726, loss_s1: 0.028184, loss_fp: 0.002621, loss_freq: 0.035561
[07:12:44.518] iteration 26477: loss: 0.110534, loss_s1: 0.098348, loss_fp: 0.014072, loss_freq: 0.083514
[07:12:45.138] iteration 26478: loss: 0.066705, loss_s1: 0.069667, loss_fp: 0.004623, loss_freq: 0.015711
[07:12:45.747] iteration 26479: loss: 0.043984, loss_s1: 0.038712, loss_fp: 0.007004, loss_freq: 0.015785
[07:12:46.352] iteration 26480: loss: 0.054625, loss_s1: 0.044600, loss_fp: 0.006688, loss_freq: 0.023300
[07:12:46.963] iteration 26481: loss: 0.048619, loss_s1: 0.028898, loss_fp: 0.003732, loss_freq: 0.038932
[07:12:47.573] iteration 26482: loss: 0.049203, loss_s1: 0.046447, loss_fp: 0.001144, loss_freq: 0.020158
[07:12:48.180] iteration 26483: loss: 0.072274, loss_s1: 0.058908, loss_fp: 0.014634, loss_freq: 0.030244
[07:12:48.794] iteration 26484: loss: 0.059947, loss_s1: 0.067442, loss_fp: 0.002394, loss_freq: 0.026282
[07:12:49.406] iteration 26485: loss: 0.082754, loss_s1: 0.063413, loss_fp: 0.006962, loss_freq: 0.056843
[07:12:50.013] iteration 26486: loss: 0.030234, loss_s1: 0.021799, loss_fp: 0.007647, loss_freq: 0.007317
[07:12:50.616] iteration 26487: loss: 0.069036, loss_s1: 0.081595, loss_fp: 0.002096, loss_freq: 0.014863
[07:12:51.228] iteration 26488: loss: 0.060560, loss_s1: 0.044800, loss_fp: 0.002710, loss_freq: 0.047240
[07:12:51.838] iteration 26489: loss: 0.094107, loss_s1: 0.100538, loss_fp: 0.008411, loss_freq: 0.045871
[07:12:52.442] iteration 26490: loss: 0.039556, loss_s1: 0.032917, loss_fp: 0.006027, loss_freq: 0.021999
[07:12:53.053] iteration 26491: loss: 0.050193, loss_s1: 0.036445, loss_fp: 0.012066, loss_freq: 0.016580
[07:12:53.695] iteration 26492: loss: 0.064171, loss_s1: 0.056541, loss_fp: 0.003129, loss_freq: 0.039873
[07:12:54.307] iteration 26493: loss: 0.032198, loss_s1: 0.023715, loss_fp: 0.001451, loss_freq: 0.012129
[07:12:54.913] iteration 26494: loss: 0.048715, loss_s1: 0.052080, loss_fp: 0.002986, loss_freq: 0.013740
[07:12:55.521] iteration 26495: loss: 0.026991, loss_s1: 0.011495, loss_fp: 0.006599, loss_freq: 0.008838
[07:12:56.128] iteration 26496: loss: 0.053819, loss_s1: 0.036414, loss_fp: 0.001399, loss_freq: 0.037958
[07:12:56.744] iteration 26497: loss: 0.044931, loss_s1: 0.035857, loss_fp: 0.001965, loss_freq: 0.021305
[07:12:57.340] iteration 26498: loss: 0.063091, loss_s1: 0.048209, loss_fp: 0.005943, loss_freq: 0.044653
[07:12:57.941] iteration 26499: loss: 0.051845, loss_s1: 0.043848, loss_fp: 0.002585, loss_freq: 0.034831
[07:12:58.550] iteration 26500: loss: 0.038473, loss_s1: 0.022356, loss_fp: 0.005049, loss_freq: 0.016882
[07:12:59.149] iteration 26501: loss: 0.058107, loss_s1: 0.044953, loss_fp: 0.015444, loss_freq: 0.027076
[07:12:59.753] iteration 26502: loss: 0.038218, loss_s1: 0.019710, loss_fp: 0.003688, loss_freq: 0.012118
[07:13:00.357] iteration 26503: loss: 0.072464, loss_s1: 0.052930, loss_fp: 0.008381, loss_freq: 0.049516
[07:13:00.966] iteration 26504: loss: 0.067491, loss_s1: 0.079324, loss_fp: 0.007771, loss_freq: 0.018368
[07:13:01.573] iteration 26505: loss: 0.077545, loss_s1: 0.057845, loss_fp: 0.004130, loss_freq: 0.036804
[07:13:02.188] iteration 26506: loss: 0.049456, loss_s1: 0.041765, loss_fp: 0.006112, loss_freq: 0.007526
[07:13:02.792] iteration 26507: loss: 0.028698, loss_s1: 0.018965, loss_fp: 0.008186, loss_freq: 0.011123
[07:13:03.402] iteration 26508: loss: 0.079807, loss_s1: 0.073965, loss_fp: 0.002933, loss_freq: 0.055148
[07:13:04.007] iteration 26509: loss: 0.055973, loss_s1: 0.037633, loss_fp: 0.005534, loss_freq: 0.036669
[07:13:04.617] iteration 26510: loss: 0.069885, loss_s1: 0.061237, loss_fp: 0.004719, loss_freq: 0.034629
[07:13:05.236] iteration 26511: loss: 0.034696, loss_s1: 0.029366, loss_fp: 0.002125, loss_freq: 0.006633
[07:13:05.850] iteration 26512: loss: 0.063512, loss_s1: 0.072330, loss_fp: 0.005768, loss_freq: 0.028043
[07:13:06.461] iteration 26513: loss: 0.038999, loss_s1: 0.021169, loss_fp: 0.001081, loss_freq: 0.007992
[07:13:07.101] iteration 26514: loss: 0.057029, loss_s1: 0.052601, loss_fp: 0.001597, loss_freq: 0.023873
[07:13:07.712] iteration 26515: loss: 0.034524, loss_s1: 0.026711, loss_fp: 0.001452, loss_freq: 0.010985
[07:13:08.322] iteration 26516: loss: 0.065037, loss_s1: 0.056423, loss_fp: 0.003555, loss_freq: 0.045416
[07:13:08.921] iteration 26517: loss: 0.038820, loss_s1: 0.022189, loss_fp: 0.002313, loss_freq: 0.020450
[07:13:09.525] iteration 26518: loss: 0.058144, loss_s1: 0.045727, loss_fp: 0.006310, loss_freq: 0.033806
[07:13:10.120] iteration 26519: loss: 0.064931, loss_s1: 0.065041, loss_fp: 0.002874, loss_freq: 0.039741
[07:13:10.720] iteration 26520: loss: 0.059826, loss_s1: 0.048452, loss_fp: 0.006500, loss_freq: 0.031612
[07:13:11.680] iteration 26521: loss: 0.055085, loss_s1: 0.030712, loss_fp: 0.006899, loss_freq: 0.035156
[07:13:12.296] iteration 26522: loss: 0.039487, loss_s1: 0.023432, loss_fp: 0.000854, loss_freq: 0.025125
[07:13:12.904] iteration 26523: loss: 0.051700, loss_s1: 0.038624, loss_fp: 0.010166, loss_freq: 0.026417
[07:13:13.525] iteration 26524: loss: 0.047566, loss_s1: 0.053036, loss_fp: 0.002186, loss_freq: 0.011035
[07:13:14.127] iteration 26525: loss: 0.065959, loss_s1: 0.071069, loss_fp: 0.002536, loss_freq: 0.025081
[07:13:14.754] iteration 26526: loss: 0.065352, loss_s1: 0.060505, loss_fp: 0.003128, loss_freq: 0.029449
[07:13:15.360] iteration 26527: loss: 0.061720, loss_s1: 0.059630, loss_fp: 0.003175, loss_freq: 0.029546
[07:13:15.980] iteration 26528: loss: 0.041549, loss_s1: 0.042129, loss_fp: 0.004178, loss_freq: 0.010971
[07:13:16.621] iteration 26529: loss: 0.053963, loss_s1: 0.040442, loss_fp: 0.003006, loss_freq: 0.042990
[07:13:17.241] iteration 26530: loss: 0.068700, loss_s1: 0.080249, loss_fp: 0.002858, loss_freq: 0.020389
[07:13:17.840] iteration 26531: loss: 0.060491, loss_s1: 0.042367, loss_fp: 0.002607, loss_freq: 0.045528
[07:13:18.484] iteration 26532: loss: 0.051518, loss_s1: 0.031369, loss_fp: 0.004714, loss_freq: 0.036417
[07:13:19.083] iteration 26533: loss: 0.052300, loss_s1: 0.036056, loss_fp: 0.001368, loss_freq: 0.038152
[07:13:19.685] iteration 26534: loss: 0.047822, loss_s1: 0.033386, loss_fp: 0.012430, loss_freq: 0.025123
[07:13:20.292] iteration 26535: loss: 0.069845, loss_s1: 0.066761, loss_fp: 0.003038, loss_freq: 0.035244
[07:13:20.907] iteration 26536: loss: 0.051559, loss_s1: 0.052178, loss_fp: 0.004086, loss_freq: 0.019795
[07:13:21.519] iteration 26537: loss: 0.061928, loss_s1: 0.038473, loss_fp: 0.002158, loss_freq: 0.063044
[07:13:22.136] iteration 26538: loss: 0.039508, loss_s1: 0.023547, loss_fp: 0.004441, loss_freq: 0.019915
[07:13:22.749] iteration 26539: loss: 0.060159, loss_s1: 0.059252, loss_fp: 0.006124, loss_freq: 0.028845
[07:13:23.356] iteration 26540: loss: 0.044274, loss_s1: 0.031056, loss_fp: 0.003551, loss_freq: 0.011608
[07:13:23.965] iteration 26541: loss: 0.040969, loss_s1: 0.031759, loss_fp: 0.003498, loss_freq: 0.020174
[07:13:24.582] iteration 26542: loss: 0.049110, loss_s1: 0.032683, loss_fp: 0.010263, loss_freq: 0.034226
[07:13:25.189] iteration 26543: loss: 0.044922, loss_s1: 0.027104, loss_fp: 0.002906, loss_freq: 0.024769
[07:13:25.818] iteration 26544: loss: 0.047017, loss_s1: 0.044739, loss_fp: 0.007988, loss_freq: 0.018123
[07:13:26.429] iteration 26545: loss: 0.042485, loss_s1: 0.026875, loss_fp: 0.001873, loss_freq: 0.027581
[07:13:27.082] iteration 26546: loss: 0.045848, loss_s1: 0.030242, loss_fp: 0.003991, loss_freq: 0.033812
[07:13:27.702] iteration 26547: loss: 0.032474, loss_s1: 0.020655, loss_fp: 0.005598, loss_freq: 0.008896
[07:13:28.309] iteration 26548: loss: 0.105624, loss_s1: 0.132005, loss_fp: 0.005125, loss_freq: 0.035369
[07:13:28.909] iteration 26549: loss: 0.048812, loss_s1: 0.036425, loss_fp: 0.002213, loss_freq: 0.032282
[07:13:29.578] iteration 26550: loss: 0.058017, loss_s1: 0.040945, loss_fp: 0.003046, loss_freq: 0.040773
[07:13:30.228] iteration 26551: loss: 0.051538, loss_s1: 0.024234, loss_fp: 0.003089, loss_freq: 0.050118
[07:13:30.876] iteration 26552: loss: 0.086772, loss_s1: 0.064165, loss_fp: 0.002009, loss_freq: 0.058686
[07:13:31.524] iteration 26553: loss: 0.058754, loss_s1: 0.047411, loss_fp: 0.001911, loss_freq: 0.043146
[07:13:32.169] iteration 26554: loss: 0.043294, loss_s1: 0.043890, loss_fp: 0.002582, loss_freq: 0.010440
[07:13:32.774] iteration 26555: loss: 0.051153, loss_s1: 0.051962, loss_fp: 0.003335, loss_freq: 0.027826
[07:13:33.374] iteration 26556: loss: 0.049603, loss_s1: 0.037389, loss_fp: 0.005444, loss_freq: 0.020449
[07:13:33.986] iteration 26557: loss: 0.046460, loss_s1: 0.023833, loss_fp: 0.001904, loss_freq: 0.031120
[07:13:34.599] iteration 26558: loss: 0.047852, loss_s1: 0.046631, loss_fp: 0.002701, loss_freq: 0.020521
[07:13:35.215] iteration 26559: loss: 0.044434, loss_s1: 0.035181, loss_fp: 0.003900, loss_freq: 0.021260
[07:13:35.835] iteration 26560: loss: 0.059698, loss_s1: 0.061282, loss_fp: 0.003278, loss_freq: 0.020306
[07:13:36.511] iteration 26561: loss: 0.041291, loss_s1: 0.030727, loss_fp: 0.001803, loss_freq: 0.009240
[07:13:37.117] iteration 26562: loss: 0.059929, loss_s1: 0.058604, loss_fp: 0.005056, loss_freq: 0.023106
[07:13:37.730] iteration 26563: loss: 0.077346, loss_s1: 0.080273, loss_fp: 0.004208, loss_freq: 0.040146
[07:13:38.336] iteration 26564: loss: 0.068454, loss_s1: 0.064750, loss_fp: 0.013866, loss_freq: 0.035605
[07:13:38.992] iteration 26565: loss: 0.048539, loss_s1: 0.031778, loss_fp: 0.001924, loss_freq: 0.019663
[07:13:39.608] iteration 26566: loss: 0.055793, loss_s1: 0.044084, loss_fp: 0.006853, loss_freq: 0.027568
[07:13:40.223] iteration 26567: loss: 0.053429, loss_s1: 0.032784, loss_fp: 0.005524, loss_freq: 0.036636
[07:13:40.839] iteration 26568: loss: 0.062291, loss_s1: 0.065407, loss_fp: 0.004229, loss_freq: 0.030800
[07:13:41.445] iteration 26569: loss: 0.038531, loss_s1: 0.039718, loss_fp: 0.003817, loss_freq: 0.006047
[07:13:42.049] iteration 26570: loss: 0.033074, loss_s1: 0.010660, loss_fp: 0.001789, loss_freq: 0.016710
[07:13:42.664] iteration 26571: loss: 0.038422, loss_s1: 0.023389, loss_fp: 0.003867, loss_freq: 0.016569
[07:13:43.277] iteration 26572: loss: 0.043176, loss_s1: 0.036487, loss_fp: 0.003212, loss_freq: 0.022128
[07:13:43.881] iteration 26573: loss: 0.028267, loss_s1: 0.011777, loss_fp: 0.001362, loss_freq: 0.013557
[07:13:44.496] iteration 26574: loss: 0.100555, loss_s1: 0.086466, loss_fp: 0.006524, loss_freq: 0.078459
[07:13:45.101] iteration 26575: loss: 0.059009, loss_s1: 0.036426, loss_fp: 0.001895, loss_freq: 0.051611
[07:13:45.708] iteration 26576: loss: 0.034107, loss_s1: 0.016331, loss_fp: 0.001991, loss_freq: 0.019097
[07:13:46.319] iteration 26577: loss: 0.046856, loss_s1: 0.034291, loss_fp: 0.002084, loss_freq: 0.037015
[07:13:46.935] iteration 26578: loss: 0.044899, loss_s1: 0.034116, loss_fp: 0.001476, loss_freq: 0.014960
[07:13:47.539] iteration 26579: loss: 0.037661, loss_s1: 0.030905, loss_fp: 0.002498, loss_freq: 0.016415
[07:13:48.147] iteration 26580: loss: 0.041750, loss_s1: 0.024071, loss_fp: 0.001135, loss_freq: 0.030496
[07:13:48.753] iteration 26581: loss: 0.027027, loss_s1: 0.024179, loss_fp: 0.001242, loss_freq: 0.004134
[07:13:49.371] iteration 26582: loss: 0.048824, loss_s1: 0.031644, loss_fp: 0.003804, loss_freq: 0.029813
[07:13:49.979] iteration 26583: loss: 0.035441, loss_s1: 0.019717, loss_fp: 0.003742, loss_freq: 0.016839
[07:13:50.598] iteration 26584: loss: 0.039295, loss_s1: 0.029179, loss_fp: 0.001509, loss_freq: 0.021223
[07:13:51.217] iteration 26585: loss: 0.059464, loss_s1: 0.071310, loss_fp: 0.002822, loss_freq: 0.008382
[07:13:51.853] iteration 26586: loss: 0.028046, loss_s1: 0.016888, loss_fp: 0.002363, loss_freq: 0.015935
[07:13:52.487] iteration 26587: loss: 0.045378, loss_s1: 0.037845, loss_fp: 0.003550, loss_freq: 0.011574
[07:13:53.110] iteration 26588: loss: 0.118278, loss_s1: 0.129929, loss_fp: 0.008981, loss_freq: 0.072344
[07:13:53.764] iteration 26589: loss: 0.029981, loss_s1: 0.015065, loss_fp: 0.002650, loss_freq: 0.013498
[07:13:54.369] iteration 26590: loss: 0.041273, loss_s1: 0.013341, loss_fp: 0.005370, loss_freq: 0.044184
[07:13:54.970] iteration 26591: loss: 0.042462, loss_s1: 0.024270, loss_fp: 0.002382, loss_freq: 0.027135
[07:13:55.591] iteration 26592: loss: 0.050524, loss_s1: 0.037370, loss_fp: 0.004834, loss_freq: 0.026643
[07:13:56.193] iteration 26593: loss: 0.064990, loss_s1: 0.053579, loss_fp: 0.007162, loss_freq: 0.044104
[07:13:56.799] iteration 26594: loss: 0.049287, loss_s1: 0.048242, loss_fp: 0.002606, loss_freq: 0.018130
[07:13:57.419] iteration 26595: loss: 0.062522, loss_s1: 0.046676, loss_fp: 0.003456, loss_freq: 0.051429
[07:13:58.030] iteration 26596: loss: 0.085299, loss_s1: 0.060908, loss_fp: 0.006332, loss_freq: 0.063975
[07:13:58.645] iteration 26597: loss: 0.056865, loss_s1: 0.029948, loss_fp: 0.003240, loss_freq: 0.049588
[07:13:59.247] iteration 26598: loss: 0.052395, loss_s1: 0.036306, loss_fp: 0.003578, loss_freq: 0.039378
[07:13:59.845] iteration 26599: loss: 0.038794, loss_s1: 0.025263, loss_fp: 0.008766, loss_freq: 0.020515
[07:14:00.454] iteration 26600: loss: 0.052937, loss_s1: 0.043658, loss_fp: 0.004509, loss_freq: 0.011778
[07:14:03.602] iteration 26600 : mean_dice : 0.742530
[07:14:04.256] iteration 26601: loss: 0.066078, loss_s1: 0.056646, loss_fp: 0.002694, loss_freq: 0.011844
[07:14:04.883] iteration 26602: loss: 0.045877, loss_s1: 0.034260, loss_fp: 0.006795, loss_freq: 0.016998
[07:14:05.497] iteration 26603: loss: 0.061130, loss_s1: 0.065357, loss_fp: 0.004989, loss_freq: 0.026648
[07:14:06.146] iteration 26604: loss: 0.070258, loss_s1: 0.089668, loss_fp: 0.002164, loss_freq: 0.012257
[07:14:06.800] iteration 26605: loss: 0.053589, loss_s1: 0.058789, loss_fp: 0.000972, loss_freq: 0.015803
[07:14:07.456] iteration 26606: loss: 0.047036, loss_s1: 0.036235, loss_fp: 0.004577, loss_freq: 0.021996
[07:14:08.112] iteration 26607: loss: 0.045012, loss_s1: 0.037653, loss_fp: 0.001608, loss_freq: 0.029534
[07:14:08.756] iteration 26608: loss: 0.070724, loss_s1: 0.076622, loss_fp: 0.004717, loss_freq: 0.016343
[07:14:09.373] iteration 26609: loss: 0.102233, loss_s1: 0.055823, loss_fp: 0.004655, loss_freq: 0.114585
[07:14:09.982] iteration 26610: loss: 0.054225, loss_s1: 0.053163, loss_fp: 0.006547, loss_freq: 0.013703
[07:14:10.585] iteration 26611: loss: 0.062544, loss_s1: 0.049135, loss_fp: 0.009735, loss_freq: 0.037507
[07:14:11.192] iteration 26612: loss: 0.047773, loss_s1: 0.046622, loss_fp: 0.001296, loss_freq: 0.020779
[07:14:11.836] iteration 26613: loss: 0.075549, loss_s1: 0.081540, loss_fp: 0.013353, loss_freq: 0.023094
[07:14:12.483] iteration 26614: loss: 0.064123, loss_s1: 0.060759, loss_fp: 0.002029, loss_freq: 0.038565
[07:14:13.121] iteration 26615: loss: 0.076189, loss_s1: 0.086280, loss_fp: 0.006747, loss_freq: 0.028319
[07:14:13.739] iteration 26616: loss: 0.042292, loss_s1: 0.036677, loss_fp: 0.001480, loss_freq: 0.021111
[07:14:14.353] iteration 26617: loss: 0.084818, loss_s1: 0.079970, loss_fp: 0.007131, loss_freq: 0.028286
[07:14:14.978] iteration 26618: loss: 0.081925, loss_s1: 0.055418, loss_fp: 0.003675, loss_freq: 0.054459
[07:14:15.604] iteration 26619: loss: 0.075215, loss_s1: 0.063881, loss_fp: 0.003679, loss_freq: 0.057895
[07:14:16.225] iteration 26620: loss: 0.038432, loss_s1: 0.022202, loss_fp: 0.007891, loss_freq: 0.009521
[07:14:16.845] iteration 26621: loss: 0.057701, loss_s1: 0.042615, loss_fp: 0.015547, loss_freq: 0.038027
[07:14:17.469] iteration 26622: loss: 0.039843, loss_s1: 0.019439, loss_fp: 0.002168, loss_freq: 0.016590
[07:14:18.093] iteration 26623: loss: 0.036115, loss_s1: 0.012983, loss_fp: 0.001205, loss_freq: 0.026215
[07:14:18.762] iteration 26624: loss: 0.045856, loss_s1: 0.041512, loss_fp: 0.009524, loss_freq: 0.016317
[07:14:19.367] iteration 26625: loss: 0.036180, loss_s1: 0.019041, loss_fp: 0.004497, loss_freq: 0.019772
[07:14:19.967] iteration 26626: loss: 0.068823, loss_s1: 0.072830, loss_fp: 0.019950, loss_freq: 0.013028
[07:14:20.565] iteration 26627: loss: 0.055058, loss_s1: 0.051918, loss_fp: 0.003775, loss_freq: 0.022308
[07:14:21.160] iteration 26628: loss: 0.033269, loss_s1: 0.015077, loss_fp: 0.006179, loss_freq: 0.018113
[07:14:21.763] iteration 26629: loss: 0.057877, loss_s1: 0.040886, loss_fp: 0.012303, loss_freq: 0.029089
[07:14:22.367] iteration 26630: loss: 0.050231, loss_s1: 0.046716, loss_fp: 0.001895, loss_freq: 0.023135
[07:14:22.982] iteration 26631: loss: 0.054676, loss_s1: 0.042669, loss_fp: 0.008411, loss_freq: 0.024524
[07:14:23.597] iteration 26632: loss: 0.039754, loss_s1: 0.027945, loss_fp: 0.003795, loss_freq: 0.020210
[07:14:24.215] iteration 26633: loss: 0.066072, loss_s1: 0.075384, loss_fp: 0.004719, loss_freq: 0.024188
[07:14:24.811] iteration 26634: loss: 0.029219, loss_s1: 0.023106, loss_fp: 0.003546, loss_freq: 0.011348
[07:14:25.410] iteration 26635: loss: 0.099351, loss_s1: 0.082582, loss_fp: 0.010083, loss_freq: 0.071390
[07:14:26.078] iteration 26636: loss: 0.082212, loss_s1: 0.066988, loss_fp: 0.003670, loss_freq: 0.065206
[07:14:26.693] iteration 26637: loss: 0.091937, loss_s1: 0.103808, loss_fp: 0.005936, loss_freq: 0.046523
[07:14:27.286] iteration 26638: loss: 0.061974, loss_s1: 0.077186, loss_fp: 0.005259, loss_freq: 0.015604
[07:14:27.894] iteration 26639: loss: 0.069496, loss_s1: 0.070733, loss_fp: 0.002352, loss_freq: 0.035327
[07:14:28.543] iteration 26640: loss: 0.033174, loss_s1: 0.023626, loss_fp: 0.002090, loss_freq: 0.003202
[07:14:29.421] iteration 26641: loss: 0.031833, loss_s1: 0.024607, loss_fp: 0.001740, loss_freq: 0.004743
[07:14:30.156] iteration 26642: loss: 0.057275, loss_s1: 0.065938, loss_fp: 0.002647, loss_freq: 0.020333
[07:14:30.844] iteration 26643: loss: 0.038896, loss_s1: 0.028699, loss_fp: 0.006247, loss_freq: 0.014039
[07:14:31.478] iteration 26644: loss: 0.039002, loss_s1: 0.022598, loss_fp: 0.004816, loss_freq: 0.024041
[07:14:32.084] iteration 26645: loss: 0.058504, loss_s1: 0.040020, loss_fp: 0.001722, loss_freq: 0.040168
[07:14:32.727] iteration 26646: loss: 0.042526, loss_s1: 0.034574, loss_fp: 0.001261, loss_freq: 0.020898
[07:14:33.342] iteration 26647: loss: 0.051182, loss_s1: 0.040718, loss_fp: 0.003069, loss_freq: 0.035238
[07:14:33.963] iteration 26648: loss: 0.038166, loss_s1: 0.028227, loss_fp: 0.001523, loss_freq: 0.014394
[07:14:34.579] iteration 26649: loss: 0.045392, loss_s1: 0.045401, loss_fp: 0.002842, loss_freq: 0.015809
[07:14:35.191] iteration 26650: loss: 0.070925, loss_s1: 0.050352, loss_fp: 0.012349, loss_freq: 0.042105
[07:14:35.791] iteration 26651: loss: 0.046105, loss_s1: 0.051554, loss_fp: 0.003988, loss_freq: 0.006474
[07:14:36.402] iteration 26652: loss: 0.091029, loss_s1: 0.077064, loss_fp: 0.004355, loss_freq: 0.036673
[07:14:36.998] iteration 26653: loss: 0.050491, loss_s1: 0.030380, loss_fp: 0.011663, loss_freq: 0.026571
[07:14:37.600] iteration 26654: loss: 0.057370, loss_s1: 0.057952, loss_fp: 0.001818, loss_freq: 0.022374
[07:14:38.199] iteration 26655: loss: 0.064082, loss_s1: 0.050350, loss_fp: 0.001531, loss_freq: 0.045621
[07:14:38.812] iteration 26656: loss: 0.024628, loss_s1: 0.015454, loss_fp: 0.004809, loss_freq: 0.003021
[07:14:39.417] iteration 26657: loss: 0.071490, loss_s1: 0.093554, loss_fp: 0.005229, loss_freq: 0.012707
[07:14:40.016] iteration 26658: loss: 0.047659, loss_s1: 0.036716, loss_fp: 0.001714, loss_freq: 0.033642
[07:14:40.619] iteration 26659: loss: 0.115001, loss_s1: 0.111140, loss_fp: 0.010182, loss_freq: 0.078837
[07:14:41.230] iteration 26660: loss: 0.059498, loss_s1: 0.066173, loss_fp: 0.002596, loss_freq: 0.031181
[07:14:41.842] iteration 26661: loss: 0.055699, loss_s1: 0.048046, loss_fp: 0.004103, loss_freq: 0.021959
[07:14:42.460] iteration 26662: loss: 0.049350, loss_s1: 0.042065, loss_fp: 0.002358, loss_freq: 0.020991
[07:14:43.074] iteration 26663: loss: 0.046654, loss_s1: 0.036160, loss_fp: 0.002793, loss_freq: 0.023956
[07:14:43.682] iteration 26664: loss: 0.042953, loss_s1: 0.052648, loss_fp: 0.000803, loss_freq: 0.005186
[07:14:44.297] iteration 26665: loss: 0.045477, loss_s1: 0.042663, loss_fp: 0.005517, loss_freq: 0.018624
[07:14:44.903] iteration 26666: loss: 0.062464, loss_s1: 0.027101, loss_fp: 0.006411, loss_freq: 0.058404
[07:14:45.512] iteration 26667: loss: 0.044570, loss_s1: 0.032837, loss_fp: 0.001832, loss_freq: 0.023920
[07:14:46.158] iteration 26668: loss: 0.055273, loss_s1: 0.050844, loss_fp: 0.014575, loss_freq: 0.021414
[07:14:46.759] iteration 26669: loss: 0.063360, loss_s1: 0.055136, loss_fp: 0.014186, loss_freq: 0.031690
[07:14:47.369] iteration 26670: loss: 0.059195, loss_s1: 0.041122, loss_fp: 0.001881, loss_freq: 0.044401
[07:14:47.982] iteration 26671: loss: 0.056646, loss_s1: 0.045220, loss_fp: 0.012110, loss_freq: 0.022409
[07:14:48.589] iteration 26672: loss: 0.069151, loss_s1: 0.073419, loss_fp: 0.012281, loss_freq: 0.022654
[07:14:49.206] iteration 26673: loss: 0.078249, loss_s1: 0.066869, loss_fp: 0.017746, loss_freq: 0.045733
[07:14:49.817] iteration 26674: loss: 0.084779, loss_s1: 0.075728, loss_fp: 0.006302, loss_freq: 0.060262
[07:14:50.432] iteration 26675: loss: 0.096662, loss_s1: 0.067732, loss_fp: 0.006959, loss_freq: 0.083333
[07:14:51.039] iteration 26676: loss: 0.047800, loss_s1: 0.053451, loss_fp: 0.001131, loss_freq: 0.006391
[07:14:51.655] iteration 26677: loss: 0.032661, loss_s1: 0.029520, loss_fp: 0.003293, loss_freq: 0.010517
[07:14:52.259] iteration 26678: loss: 0.079990, loss_s1: 0.061901, loss_fp: 0.003446, loss_freq: 0.064999
[07:14:52.872] iteration 26679: loss: 0.061632, loss_s1: 0.037189, loss_fp: 0.012025, loss_freq: 0.047949
[07:14:53.512] iteration 26680: loss: 0.099147, loss_s1: 0.089192, loss_fp: 0.007302, loss_freq: 0.067031
[07:14:54.114] iteration 26681: loss: 0.044827, loss_s1: 0.043168, loss_fp: 0.002578, loss_freq: 0.012203
[07:14:54.715] iteration 26682: loss: 0.052227, loss_s1: 0.043659, loss_fp: 0.008851, loss_freq: 0.031019
[07:14:55.314] iteration 26683: loss: 0.033589, loss_s1: 0.017756, loss_fp: 0.004024, loss_freq: 0.008218
[07:14:55.912] iteration 26684: loss: 0.049466, loss_s1: 0.048598, loss_fp: 0.006123, loss_freq: 0.020660
[07:14:56.523] iteration 26685: loss: 0.045503, loss_s1: 0.038099, loss_fp: 0.003396, loss_freq: 0.014994
[07:14:57.126] iteration 26686: loss: 0.061434, loss_s1: 0.053349, loss_fp: 0.004667, loss_freq: 0.043562
[07:14:57.734] iteration 26687: loss: 0.081397, loss_s1: 0.055439, loss_fp: 0.016297, loss_freq: 0.057058
[07:14:58.333] iteration 26688: loss: 0.072898, loss_s1: 0.090345, loss_fp: 0.004717, loss_freq: 0.017440
[07:14:58.931] iteration 26689: loss: 0.076180, loss_s1: 0.093172, loss_fp: 0.006763, loss_freq: 0.025762
[07:14:59.540] iteration 26690: loss: 0.080826, loss_s1: 0.113582, loss_fp: 0.002219, loss_freq: 0.012146
[07:15:00.531] iteration 26691: loss: 0.077609, loss_s1: 0.080835, loss_fp: 0.003811, loss_freq: 0.039972
[07:15:01.180] iteration 26692: loss: 0.048571, loss_s1: 0.033364, loss_fp: 0.002003, loss_freq: 0.022303
[07:15:01.837] iteration 26693: loss: 0.048725, loss_s1: 0.039420, loss_fp: 0.004369, loss_freq: 0.027151
[07:15:02.490] iteration 26694: loss: 0.045483, loss_s1: 0.028263, loss_fp: 0.006652, loss_freq: 0.022081
[07:15:03.195] iteration 26695: loss: 0.040842, loss_s1: 0.034734, loss_fp: 0.002805, loss_freq: 0.020123
[07:15:03.837] iteration 26696: loss: 0.072192, loss_s1: 0.059243, loss_fp: 0.002031, loss_freq: 0.044474
[07:15:04.479] iteration 26697: loss: 0.036838, loss_s1: 0.021662, loss_fp: 0.004140, loss_freq: 0.018048
[07:15:05.137] iteration 26698: loss: 0.042437, loss_s1: 0.034929, loss_fp: 0.003904, loss_freq: 0.020757
[07:15:05.808] iteration 26699: loss: 0.045606, loss_s1: 0.034271, loss_fp: 0.005141, loss_freq: 0.031790
[07:15:06.465] iteration 26700: loss: 0.082131, loss_s1: 0.081320, loss_fp: 0.004022, loss_freq: 0.034528
[07:15:07.094] iteration 26701: loss: 0.063944, loss_s1: 0.060131, loss_fp: 0.005767, loss_freq: 0.029255
[07:15:07.746] iteration 26702: loss: 0.058016, loss_s1: 0.046100, loss_fp: 0.001334, loss_freq: 0.038086
[07:15:08.364] iteration 26703: loss: 0.041843, loss_s1: 0.034598, loss_fp: 0.002548, loss_freq: 0.018418
[07:15:08.967] iteration 26704: loss: 0.072969, loss_s1: 0.044286, loss_fp: 0.004014, loss_freq: 0.070264
[07:15:09.577] iteration 26705: loss: 0.052072, loss_s1: 0.056795, loss_fp: 0.002322, loss_freq: 0.012846
[07:15:10.182] iteration 26706: loss: 0.058082, loss_s1: 0.052196, loss_fp: 0.005574, loss_freq: 0.028721
[07:15:10.791] iteration 26707: loss: 0.123398, loss_s1: 0.154822, loss_fp: 0.003317, loss_freq: 0.069999
[07:15:11.399] iteration 26708: loss: 0.035784, loss_s1: 0.025140, loss_fp: 0.001140, loss_freq: 0.010531
[07:15:11.999] iteration 26709: loss: 0.076476, loss_s1: 0.069060, loss_fp: 0.004735, loss_freq: 0.050381
[07:15:12.597] iteration 26710: loss: 0.062576, loss_s1: 0.070569, loss_fp: 0.002378, loss_freq: 0.021244
[07:15:13.237] iteration 26711: loss: 0.044509, loss_s1: 0.026338, loss_fp: 0.009185, loss_freq: 0.021289
[07:15:13.854] iteration 26712: loss: 0.038154, loss_s1: 0.024756, loss_fp: 0.007736, loss_freq: 0.023325
[07:15:14.460] iteration 26713: loss: 0.045623, loss_s1: 0.034167, loss_fp: 0.002473, loss_freq: 0.021839
[07:15:15.069] iteration 26714: loss: 0.045228, loss_s1: 0.025810, loss_fp: 0.002267, loss_freq: 0.034837
[07:15:15.671] iteration 26715: loss: 0.052192, loss_s1: 0.042723, loss_fp: 0.004107, loss_freq: 0.028643
[07:15:16.277] iteration 26716: loss: 0.070877, loss_s1: 0.068281, loss_fp: 0.005732, loss_freq: 0.046098
[07:15:16.904] iteration 26717: loss: 0.051492, loss_s1: 0.038917, loss_fp: 0.004973, loss_freq: 0.028953
[07:15:17.507] iteration 26718: loss: 0.090610, loss_s1: 0.060413, loss_fp: 0.010910, loss_freq: 0.076293
[07:15:18.168] iteration 26719: loss: 0.035679, loss_s1: 0.020344, loss_fp: 0.002080, loss_freq: 0.018643
[07:15:18.770] iteration 26720: loss: 0.043280, loss_s1: 0.035914, loss_fp: 0.003137, loss_freq: 0.019545
[07:15:19.370] iteration 26721: loss: 0.066791, loss_s1: 0.045721, loss_fp: 0.015245, loss_freq: 0.053762
[07:15:19.972] iteration 26722: loss: 0.085350, loss_s1: 0.080979, loss_fp: 0.004882, loss_freq: 0.049087
[07:15:20.587] iteration 26723: loss: 0.060344, loss_s1: 0.054143, loss_fp: 0.004888, loss_freq: 0.036716
[07:15:21.197] iteration 26724: loss: 0.043935, loss_s1: 0.041758, loss_fp: 0.001921, loss_freq: 0.007673
[07:15:21.806] iteration 26725: loss: 0.069251, loss_s1: 0.075864, loss_fp: 0.002397, loss_freq: 0.037460
[07:15:22.423] iteration 26726: loss: 0.055208, loss_s1: 0.046986, loss_fp: 0.004780, loss_freq: 0.013194
[07:15:23.054] iteration 26727: loss: 0.066022, loss_s1: 0.058402, loss_fp: 0.002749, loss_freq: 0.041349
[07:15:23.661] iteration 26728: loss: 0.031157, loss_s1: 0.024729, loss_fp: 0.001768, loss_freq: 0.011857
[07:15:24.268] iteration 26729: loss: 0.090485, loss_s1: 0.069267, loss_fp: 0.009216, loss_freq: 0.069812
[07:15:24.870] iteration 26730: loss: 0.067968, loss_s1: 0.072037, loss_fp: 0.006389, loss_freq: 0.033297
[07:15:25.485] iteration 26731: loss: 0.092442, loss_s1: 0.126575, loss_fp: 0.009347, loss_freq: 0.011124
[07:15:26.090] iteration 26732: loss: 0.045630, loss_s1: 0.044641, loss_fp: 0.002745, loss_freq: 0.013072
[07:15:26.693] iteration 26733: loss: 0.105612, loss_s1: 0.135358, loss_fp: 0.015599, loss_freq: 0.036002
[07:15:27.294] iteration 26734: loss: 0.109579, loss_s1: 0.114161, loss_fp: 0.007831, loss_freq: 0.076693
[07:15:27.900] iteration 26735: loss: 0.050419, loss_s1: 0.039671, loss_fp: 0.003291, loss_freq: 0.012277
[07:15:28.517] iteration 26736: loss: 0.082874, loss_s1: 0.078977, loss_fp: 0.004238, loss_freq: 0.043459
[07:15:29.126] iteration 26737: loss: 0.056064, loss_s1: 0.037013, loss_fp: 0.003939, loss_freq: 0.042694
[07:15:29.733] iteration 26738: loss: 0.049499, loss_s1: 0.030007, loss_fp: 0.006912, loss_freq: 0.030503
[07:15:30.339] iteration 26739: loss: 0.042028, loss_s1: 0.036543, loss_fp: 0.003196, loss_freq: 0.015512
[07:15:30.948] iteration 26740: loss: 0.029234, loss_s1: 0.018214, loss_fp: 0.002731, loss_freq: 0.008098
[07:15:31.553] iteration 26741: loss: 0.034489, loss_s1: 0.016006, loss_fp: 0.002501, loss_freq: 0.015376
[07:15:32.162] iteration 26742: loss: 0.065297, loss_s1: 0.056988, loss_fp: 0.006923, loss_freq: 0.038494
[07:15:32.783] iteration 26743: loss: 0.028505, loss_s1: 0.013919, loss_fp: 0.005117, loss_freq: 0.011215
[07:15:33.390] iteration 26744: loss: 0.055080, loss_s1: 0.041919, loss_fp: 0.007031, loss_freq: 0.033219
[07:15:34.005] iteration 26745: loss: 0.054592, loss_s1: 0.035276, loss_fp: 0.008517, loss_freq: 0.032662
[07:15:34.605] iteration 26746: loss: 0.035332, loss_s1: 0.020466, loss_fp: 0.000621, loss_freq: 0.014375
[07:15:35.258] iteration 26747: loss: 0.039695, loss_s1: 0.035730, loss_fp: 0.002320, loss_freq: 0.018769
[07:15:35.900] iteration 26748: loss: 0.055695, loss_s1: 0.027731, loss_fp: 0.001921, loss_freq: 0.044982
[07:15:36.522] iteration 26749: loss: 0.038046, loss_s1: 0.008732, loss_fp: 0.002714, loss_freq: 0.041269
[07:15:37.148] iteration 26750: loss: 0.049711, loss_s1: 0.045759, loss_fp: 0.002404, loss_freq: 0.026887
[07:15:37.767] iteration 26751: loss: 0.034894, loss_s1: 0.030983, loss_fp: 0.002489, loss_freq: 0.016144
[07:15:38.383] iteration 26752: loss: 0.064591, loss_s1: 0.065057, loss_fp: 0.003480, loss_freq: 0.032847
[07:15:38.995] iteration 26753: loss: 0.043774, loss_s1: 0.030567, loss_fp: 0.003302, loss_freq: 0.023339
[07:15:39.620] iteration 26754: loss: 0.056359, loss_s1: 0.041198, loss_fp: 0.001524, loss_freq: 0.042290
[07:15:40.237] iteration 26755: loss: 0.033434, loss_s1: 0.024944, loss_fp: 0.001873, loss_freq: 0.006085
[07:15:40.906] iteration 26756: loss: 0.073475, loss_s1: 0.078259, loss_fp: 0.003237, loss_freq: 0.042845
[07:15:41.561] iteration 26757: loss: 0.057296, loss_s1: 0.062487, loss_fp: 0.003405, loss_freq: 0.010312
[07:15:42.198] iteration 26758: loss: 0.067298, loss_s1: 0.052810, loss_fp: 0.006265, loss_freq: 0.052276
[07:15:42.833] iteration 26759: loss: 0.047721, loss_s1: 0.043366, loss_fp: 0.000966, loss_freq: 0.013324
[07:15:43.467] iteration 26760: loss: 0.038737, loss_s1: 0.024326, loss_fp: 0.005906, loss_freq: 0.022999
[07:15:44.071] iteration 26761: loss: 0.056001, loss_s1: 0.047295, loss_fp: 0.005119, loss_freq: 0.025751
[07:15:44.667] iteration 26762: loss: 0.038600, loss_s1: 0.024056, loss_fp: 0.006275, loss_freq: 0.015971
[07:15:45.263] iteration 26763: loss: 0.048477, loss_s1: 0.034390, loss_fp: 0.007963, loss_freq: 0.025227
[07:15:45.860] iteration 26764: loss: 0.059116, loss_s1: 0.063438, loss_fp: 0.009831, loss_freq: 0.017116
[07:15:46.482] iteration 26765: loss: 0.055882, loss_s1: 0.032332, loss_fp: 0.005826, loss_freq: 0.051277
[07:15:47.083] iteration 26766: loss: 0.069427, loss_s1: 0.037413, loss_fp: 0.011529, loss_freq: 0.058242
[07:15:47.695] iteration 26767: loss: 0.047151, loss_s1: 0.036292, loss_fp: 0.001912, loss_freq: 0.025976
[07:15:48.301] iteration 26768: loss: 0.096425, loss_s1: 0.098105, loss_fp: 0.009605, loss_freq: 0.060629
[07:15:48.904] iteration 26769: loss: 0.071844, loss_s1: 0.083881, loss_fp: 0.006162, loss_freq: 0.034651
[07:15:49.543] iteration 26770: loss: 0.055714, loss_s1: 0.055568, loss_fp: 0.004158, loss_freq: 0.022718
[07:15:50.177] iteration 26771: loss: 0.049578, loss_s1: 0.044613, loss_fp: 0.006708, loss_freq: 0.019658
[07:15:50.785] iteration 26772: loss: 0.068744, loss_s1: 0.068207, loss_fp: 0.005417, loss_freq: 0.036264
[07:15:51.393] iteration 26773: loss: 0.062109, loss_s1: 0.059472, loss_fp: 0.002867, loss_freq: 0.031194
[07:15:52.003] iteration 26774: loss: 0.036169, loss_s1: 0.019658, loss_fp: 0.002641, loss_freq: 0.020943
[07:15:52.606] iteration 26775: loss: 0.060932, loss_s1: 0.061754, loss_fp: 0.005389, loss_freq: 0.019022
[07:15:53.208] iteration 26776: loss: 0.079050, loss_s1: 0.098547, loss_fp: 0.003610, loss_freq: 0.020125
[07:15:53.815] iteration 26777: loss: 0.073318, loss_s1: 0.084215, loss_fp: 0.006807, loss_freq: 0.033769
[07:15:54.419] iteration 26778: loss: 0.042210, loss_s1: 0.042313, loss_fp: 0.003184, loss_freq: 0.011393
[07:15:55.025] iteration 26779: loss: 0.069294, loss_s1: 0.082735, loss_fp: 0.002348, loss_freq: 0.023922
[07:15:55.638] iteration 26780: loss: 0.054532, loss_s1: 0.049850, loss_fp: 0.001650, loss_freq: 0.014688
[07:15:56.247] iteration 26781: loss: 0.059427, loss_s1: 0.063826, loss_fp: 0.003330, loss_freq: 0.019419
[07:15:56.880] iteration 26782: loss: 0.059297, loss_s1: 0.051969, loss_fp: 0.002991, loss_freq: 0.040005
[07:15:57.488] iteration 26783: loss: 0.060413, loss_s1: 0.055382, loss_fp: 0.005304, loss_freq: 0.026858
[07:15:58.096] iteration 26784: loss: 0.047810, loss_s1: 0.039157, loss_fp: 0.003861, loss_freq: 0.028537
[07:15:58.700] iteration 26785: loss: 0.059811, loss_s1: 0.060939, loss_fp: 0.004931, loss_freq: 0.028661
[07:15:59.310] iteration 26786: loss: 0.049233, loss_s1: 0.052712, loss_fp: 0.004221, loss_freq: 0.021562
[07:15:59.920] iteration 26787: loss: 0.073175, loss_s1: 0.067931, loss_fp: 0.005573, loss_freq: 0.041597
[07:16:00.528] iteration 26788: loss: 0.054621, loss_s1: 0.046952, loss_fp: 0.002952, loss_freq: 0.029258
[07:16:01.136] iteration 26789: loss: 0.049955, loss_s1: 0.032722, loss_fp: 0.012155, loss_freq: 0.031409
[07:16:01.745] iteration 26790: loss: 0.048210, loss_s1: 0.029682, loss_fp: 0.008669, loss_freq: 0.028288
[07:16:02.356] iteration 26791: loss: 0.048396, loss_s1: 0.047438, loss_fp: 0.009225, loss_freq: 0.020961
[07:16:02.976] iteration 26792: loss: 0.047057, loss_s1: 0.023133, loss_fp: 0.007514, loss_freq: 0.025209
[07:16:03.592] iteration 26793: loss: 0.040448, loss_s1: 0.021752, loss_fp: 0.002937, loss_freq: 0.026011
[07:16:04.197] iteration 26794: loss: 0.040364, loss_s1: 0.030384, loss_fp: 0.002694, loss_freq: 0.019559
[07:16:04.811] iteration 26795: loss: 0.031185, loss_s1: 0.028789, loss_fp: 0.001286, loss_freq: 0.009068
[07:16:05.417] iteration 26796: loss: 0.095300, loss_s1: 0.096651, loss_fp: 0.005202, loss_freq: 0.017899
[07:16:06.028] iteration 26797: loss: 0.065504, loss_s1: 0.068711, loss_fp: 0.004973, loss_freq: 0.023513
[07:16:06.630] iteration 26798: loss: 0.062698, loss_s1: 0.061072, loss_fp: 0.008579, loss_freq: 0.029588
[07:16:07.231] iteration 26799: loss: 0.067106, loss_s1: 0.060336, loss_fp: 0.013809, loss_freq: 0.031564
[07:16:07.841] iteration 26800: loss: 0.041734, loss_s1: 0.031411, loss_fp: 0.008268, loss_freq: 0.021763
[07:16:11.417] iteration 26800 : mean_dice : 0.748721
[07:16:12.112] iteration 26801: loss: 0.056340, loss_s1: 0.033796, loss_fp: 0.005641, loss_freq: 0.037603
[07:16:12.786] iteration 26802: loss: 0.051622, loss_s1: 0.034902, loss_fp: 0.004737, loss_freq: 0.034546
[07:16:13.472] iteration 26803: loss: 0.049329, loss_s1: 0.043733, loss_fp: 0.002212, loss_freq: 0.026640
[07:16:14.150] iteration 26804: loss: 0.037067, loss_s1: 0.029981, loss_fp: 0.004808, loss_freq: 0.018998
[07:16:14.805] iteration 26805: loss: 0.079788, loss_s1: 0.071006, loss_fp: 0.005264, loss_freq: 0.048093
[07:16:15.454] iteration 26806: loss: 0.049732, loss_s1: 0.033162, loss_fp: 0.004680, loss_freq: 0.033460
[07:16:16.097] iteration 26807: loss: 0.055894, loss_s1: 0.051297, loss_fp: 0.002652, loss_freq: 0.028777
[07:16:16.738] iteration 26808: loss: 0.046050, loss_s1: 0.039033, loss_fp: 0.004909, loss_freq: 0.020957
[07:16:17.340] iteration 26809: loss: 0.052845, loss_s1: 0.030094, loss_fp: 0.001689, loss_freq: 0.045078
[07:16:17.947] iteration 26810: loss: 0.044141, loss_s1: 0.045564, loss_fp: 0.000676, loss_freq: 0.008562
[07:16:18.553] iteration 26811: loss: 0.035555, loss_s1: 0.030336, loss_fp: 0.003962, loss_freq: 0.011293
[07:16:19.204] iteration 26812: loss: 0.076709, loss_s1: 0.075872, loss_fp: 0.008750, loss_freq: 0.049086
[07:16:19.818] iteration 26813: loss: 0.090060, loss_s1: 0.049724, loss_fp: 0.030012, loss_freq: 0.072475
[07:16:20.445] iteration 26814: loss: 0.046910, loss_s1: 0.033948, loss_fp: 0.008167, loss_freq: 0.021149
[07:16:21.110] iteration 26815: loss: 0.068282, loss_s1: 0.043707, loss_fp: 0.004714, loss_freq: 0.056073
[07:16:21.740] iteration 26816: loss: 0.038511, loss_s1: 0.025400, loss_fp: 0.003454, loss_freq: 0.015450
[07:16:22.369] iteration 26817: loss: 0.063402, loss_s1: 0.043537, loss_fp: 0.006198, loss_freq: 0.056329
[07:16:22.998] iteration 26818: loss: 0.091750, loss_s1: 0.095740, loss_fp: 0.004557, loss_freq: 0.043353
[07:16:23.640] iteration 26819: loss: 0.075622, loss_s1: 0.063139, loss_fp: 0.007931, loss_freq: 0.055558
[07:16:24.268] iteration 26820: loss: 0.061937, loss_s1: 0.045097, loss_fp: 0.008601, loss_freq: 0.043890
[07:16:24.894] iteration 26821: loss: 0.058088, loss_s1: 0.077798, loss_fp: 0.004735, loss_freq: 0.009724
[07:16:25.507] iteration 26822: loss: 0.079850, loss_s1: 0.067252, loss_fp: 0.004858, loss_freq: 0.031421
[07:16:26.124] iteration 26823: loss: 0.092794, loss_s1: 0.108476, loss_fp: 0.009616, loss_freq: 0.039240
[07:16:26.764] iteration 26824: loss: 0.053551, loss_s1: 0.057602, loss_fp: 0.003147, loss_freq: 0.016977
[07:16:27.393] iteration 26825: loss: 0.061779, loss_s1: 0.045021, loss_fp: 0.012998, loss_freq: 0.031259
[07:16:28.020] iteration 26826: loss: 0.030840, loss_s1: 0.021762, loss_fp: 0.002962, loss_freq: 0.011082
[07:16:28.641] iteration 26827: loss: 0.056384, loss_s1: 0.063216, loss_fp: 0.002952, loss_freq: 0.012265
[07:16:29.251] iteration 26828: loss: 0.080305, loss_s1: 0.050591, loss_fp: 0.006695, loss_freq: 0.076724
[07:16:29.858] iteration 26829: loss: 0.076468, loss_s1: 0.058615, loss_fp: 0.010926, loss_freq: 0.057301
[07:16:30.458] iteration 26830: loss: 0.054663, loss_s1: 0.056063, loss_fp: 0.002362, loss_freq: 0.030571
[07:16:31.062] iteration 26831: loss: 0.070021, loss_s1: 0.059822, loss_fp: 0.011079, loss_freq: 0.037853
[07:16:31.659] iteration 26832: loss: 0.054947, loss_s1: 0.041983, loss_fp: 0.002745, loss_freq: 0.033716
[07:16:32.256] iteration 26833: loss: 0.033472, loss_s1: 0.019824, loss_fp: 0.002726, loss_freq: 0.017068
[07:16:32.864] iteration 26834: loss: 0.035022, loss_s1: 0.029944, loss_fp: 0.006204, loss_freq: 0.005755
[07:16:33.466] iteration 26835: loss: 0.038725, loss_s1: 0.017667, loss_fp: 0.004845, loss_freq: 0.033243
[07:16:34.083] iteration 26836: loss: 0.062155, loss_s1: 0.057763, loss_fp: 0.003448, loss_freq: 0.033178
[07:16:35.021] iteration 26837: loss: 0.049290, loss_s1: 0.035627, loss_fp: 0.003382, loss_freq: 0.028279
[07:16:35.983] iteration 26838: loss: 0.083199, loss_s1: 0.088412, loss_fp: 0.005097, loss_freq: 0.032074
[07:16:36.854] iteration 26839: loss: 0.058291, loss_s1: 0.055036, loss_fp: 0.002718, loss_freq: 0.039560
[07:16:37.460] iteration 26840: loss: 0.054869, loss_s1: 0.033240, loss_fp: 0.003752, loss_freq: 0.032578
[07:16:38.101] iteration 26841: loss: 0.056458, loss_s1: 0.049211, loss_fp: 0.007571, loss_freq: 0.023731
[07:16:38.714] iteration 26842: loss: 0.071602, loss_s1: 0.071206, loss_fp: 0.001257, loss_freq: 0.041426
[07:16:39.350] iteration 26843: loss: 0.076309, loss_s1: 0.054566, loss_fp: 0.006397, loss_freq: 0.063435
[07:16:39.968] iteration 26844: loss: 0.094562, loss_s1: 0.100805, loss_fp: 0.004338, loss_freq: 0.059052
[07:16:40.583] iteration 26845: loss: 0.088656, loss_s1: 0.081470, loss_fp: 0.002588, loss_freq: 0.046846
[07:16:41.207] iteration 26846: loss: 0.059774, loss_s1: 0.061387, loss_fp: 0.001993, loss_freq: 0.015301
[07:16:41.836] iteration 26847: loss: 0.026738, loss_s1: 0.018978, loss_fp: 0.001987, loss_freq: 0.011082
[07:16:42.460] iteration 26848: loss: 0.085892, loss_s1: 0.077659, loss_fp: 0.007246, loss_freq: 0.060439
[07:16:43.123] iteration 26849: loss: 0.054773, loss_s1: 0.062498, loss_fp: 0.005416, loss_freq: 0.013489
[07:16:43.785] iteration 26850: loss: 0.076298, loss_s1: 0.069487, loss_fp: 0.004956, loss_freq: 0.046240
[07:16:44.448] iteration 26851: loss: 0.052339, loss_s1: 0.054402, loss_fp: 0.005349, loss_freq: 0.012897
[07:16:45.115] iteration 26852: loss: 0.060384, loss_s1: 0.064094, loss_fp: 0.006816, loss_freq: 0.031817
[07:16:45.723] iteration 26853: loss: 0.039017, loss_s1: 0.020996, loss_fp: 0.004658, loss_freq: 0.015284
[07:16:46.334] iteration 26854: loss: 0.046000, loss_s1: 0.036821, loss_fp: 0.011921, loss_freq: 0.014985
[07:16:46.934] iteration 26855: loss: 0.050689, loss_s1: 0.045948, loss_fp: 0.003689, loss_freq: 0.019118
[07:16:47.544] iteration 26856: loss: 0.090003, loss_s1: 0.097964, loss_fp: 0.006648, loss_freq: 0.046492
[07:16:48.140] iteration 26857: loss: 0.060085, loss_s1: 0.048127, loss_fp: 0.003291, loss_freq: 0.025892
[07:16:48.741] iteration 26858: loss: 0.086091, loss_s1: 0.113911, loss_fp: 0.001272, loss_freq: 0.020460
[07:16:49.338] iteration 26859: loss: 0.069424, loss_s1: 0.066392, loss_fp: 0.003124, loss_freq: 0.040157
[07:16:49.931] iteration 26860: loss: 0.058080, loss_s1: 0.062599, loss_fp: 0.002491, loss_freq: 0.017662
[07:16:50.875] iteration 26861: loss: 0.067013, loss_s1: 0.061130, loss_fp: 0.001987, loss_freq: 0.037334
[07:16:51.513] iteration 26862: loss: 0.047606, loss_s1: 0.030721, loss_fp: 0.004499, loss_freq: 0.028711
[07:16:52.151] iteration 26863: loss: 0.058085, loss_s1: 0.057566, loss_fp: 0.004920, loss_freq: 0.026009
[07:16:52.766] iteration 26864: loss: 0.035457, loss_s1: 0.028945, loss_fp: 0.001172, loss_freq: 0.013725
[07:16:53.400] iteration 26865: loss: 0.048164, loss_s1: 0.051147, loss_fp: 0.002280, loss_freq: 0.017025
[07:16:54.006] iteration 26866: loss: 0.078635, loss_s1: 0.087374, loss_fp: 0.003965, loss_freq: 0.036208
[07:16:54.606] iteration 26867: loss: 0.049799, loss_s1: 0.027926, loss_fp: 0.004058, loss_freq: 0.019497
[07:16:55.206] iteration 26868: loss: 0.051208, loss_s1: 0.041670, loss_fp: 0.002472, loss_freq: 0.028327
[07:16:55.818] iteration 26869: loss: 0.042914, loss_s1: 0.039973, loss_fp: 0.004965, loss_freq: 0.016453
[07:16:56.431] iteration 26870: loss: 0.085814, loss_s1: 0.073597, loss_fp: 0.004482, loss_freq: 0.059819
[07:16:57.056] iteration 26871: loss: 0.062979, loss_s1: 0.048296, loss_fp: 0.006406, loss_freq: 0.043007
[07:16:57.660] iteration 26872: loss: 0.070967, loss_s1: 0.075579, loss_fp: 0.001439, loss_freq: 0.035702
[07:16:58.263] iteration 26873: loss: 0.073606, loss_s1: 0.036354, loss_fp: 0.002332, loss_freq: 0.079766
[07:16:58.881] iteration 26874: loss: 0.059516, loss_s1: 0.055552, loss_fp: 0.008873, loss_freq: 0.019896
[07:16:59.480] iteration 26875: loss: 0.051624, loss_s1: 0.034694, loss_fp: 0.001691, loss_freq: 0.010666
[07:17:00.095] iteration 26876: loss: 0.061645, loss_s1: 0.059001, loss_fp: 0.008461, loss_freq: 0.018901
[07:17:00.727] iteration 26877: loss: 0.064563, loss_s1: 0.041068, loss_fp: 0.003632, loss_freq: 0.061582
[07:17:01.339] iteration 26878: loss: 0.042480, loss_s1: 0.033946, loss_fp: 0.004656, loss_freq: 0.012389
[07:17:01.937] iteration 26879: loss: 0.062104, loss_s1: 0.071522, loss_fp: 0.001516, loss_freq: 0.025078
[07:17:02.547] iteration 26880: loss: 0.084018, loss_s1: 0.088818, loss_fp: 0.009071, loss_freq: 0.017717
[07:17:03.172] iteration 26881: loss: 0.040749, loss_s1: 0.024249, loss_fp: 0.004462, loss_freq: 0.020649
[07:17:03.795] iteration 26882: loss: 0.057400, loss_s1: 0.029601, loss_fp: 0.004773, loss_freq: 0.045573
[07:17:04.420] iteration 26883: loss: 0.043895, loss_s1: 0.032610, loss_fp: 0.002326, loss_freq: 0.018070
[07:17:05.035] iteration 26884: loss: 0.036036, loss_s1: 0.028636, loss_fp: 0.004419, loss_freq: 0.012594
[07:17:05.638] iteration 26885: loss: 0.068757, loss_s1: 0.064703, loss_fp: 0.003423, loss_freq: 0.042900
[07:17:06.240] iteration 26886: loss: 0.059187, loss_s1: 0.057990, loss_fp: 0.003098, loss_freq: 0.027035
[07:17:06.851] iteration 26887: loss: 0.039060, loss_s1: 0.040171, loss_fp: 0.002070, loss_freq: 0.003755
[07:17:07.477] iteration 26888: loss: 0.070256, loss_s1: 0.073470, loss_fp: 0.004123, loss_freq: 0.032481
[07:17:08.084] iteration 26889: loss: 0.044895, loss_s1: 0.025942, loss_fp: 0.007100, loss_freq: 0.032234
[07:17:08.686] iteration 26890: loss: 0.077954, loss_s1: 0.083202, loss_fp: 0.004411, loss_freq: 0.032380
[07:17:09.301] iteration 26891: loss: 0.050674, loss_s1: 0.043322, loss_fp: 0.004458, loss_freq: 0.032389
[07:17:09.897] iteration 26892: loss: 0.084583, loss_s1: 0.090811, loss_fp: 0.003522, loss_freq: 0.039718
[07:17:10.503] iteration 26893: loss: 0.062397, loss_s1: 0.048960, loss_fp: 0.019530, loss_freq: 0.031607
[07:17:11.101] iteration 26894: loss: 0.032539, loss_s1: 0.032961, loss_fp: 0.001080, loss_freq: 0.006789
[07:17:11.699] iteration 26895: loss: 0.039380, loss_s1: 0.020226, loss_fp: 0.001470, loss_freq: 0.036210
[07:17:12.300] iteration 26896: loss: 0.039563, loss_s1: 0.020833, loss_fp: 0.005896, loss_freq: 0.019478
[07:17:12.912] iteration 26897: loss: 0.060888, loss_s1: 0.039602, loss_fp: 0.007862, loss_freq: 0.039374
[07:17:13.519] iteration 26898: loss: 0.040893, loss_s1: 0.026938, loss_fp: 0.009284, loss_freq: 0.020968
[07:17:14.119] iteration 26899: loss: 0.090324, loss_s1: 0.093857, loss_fp: 0.003111, loss_freq: 0.049075
[07:17:14.722] iteration 26900: loss: 0.043917, loss_s1: 0.035699, loss_fp: 0.004391, loss_freq: 0.020085
[07:17:15.329] iteration 26901: loss: 0.043570, loss_s1: 0.039549, loss_fp: 0.005132, loss_freq: 0.006108
[07:17:15.930] iteration 26902: loss: 0.060695, loss_s1: 0.037393, loss_fp: 0.005908, loss_freq: 0.048395
[07:17:16.535] iteration 26903: loss: 0.109602, loss_s1: 0.142107, loss_fp: 0.004336, loss_freq: 0.032882
[07:17:17.131] iteration 26904: loss: 0.057653, loss_s1: 0.041997, loss_fp: 0.003864, loss_freq: 0.051302
[07:17:17.738] iteration 26905: loss: 0.055253, loss_s1: 0.049874, loss_fp: 0.004940, loss_freq: 0.018536
[07:17:18.340] iteration 26906: loss: 0.088547, loss_s1: 0.100927, loss_fp: 0.003483, loss_freq: 0.042170
[07:17:18.946] iteration 26907: loss: 0.050865, loss_s1: 0.017103, loss_fp: 0.006030, loss_freq: 0.039697
[07:17:19.551] iteration 26908: loss: 0.048427, loss_s1: 0.025736, loss_fp: 0.003500, loss_freq: 0.039727
[07:17:20.299] iteration 26909: loss: 0.033058, loss_s1: 0.031032, loss_fp: 0.000890, loss_freq: 0.007286
[07:17:20.940] iteration 26910: loss: 0.038683, loss_s1: 0.017020, loss_fp: 0.002063, loss_freq: 0.015813
[07:17:21.590] iteration 26911: loss: 0.039782, loss_s1: 0.021057, loss_fp: 0.003488, loss_freq: 0.026056
[07:17:22.239] iteration 26912: loss: 0.068780, loss_s1: 0.074320, loss_fp: 0.004634, loss_freq: 0.037552
[07:17:22.883] iteration 26913: loss: 0.040650, loss_s1: 0.024810, loss_fp: 0.001875, loss_freq: 0.028721
[07:17:23.497] iteration 26914: loss: 0.060090, loss_s1: 0.063535, loss_fp: 0.003021, loss_freq: 0.022575
[07:17:24.101] iteration 26915: loss: 0.045417, loss_s1: 0.019914, loss_fp: 0.001805, loss_freq: 0.031458
[07:17:24.711] iteration 26916: loss: 0.052262, loss_s1: 0.051465, loss_fp: 0.003233, loss_freq: 0.019879
[07:17:25.368] iteration 26917: loss: 0.044056, loss_s1: 0.040571, loss_fp: 0.001687, loss_freq: 0.027355
[07:17:25.973] iteration 26918: loss: 0.050873, loss_s1: 0.030556, loss_fp: 0.003939, loss_freq: 0.023336
[07:17:26.577] iteration 26919: loss: 0.040176, loss_s1: 0.024444, loss_fp: 0.003810, loss_freq: 0.029086
[07:17:27.237] iteration 26920: loss: 0.052584, loss_s1: 0.036988, loss_fp: 0.001701, loss_freq: 0.034788
[07:17:27.883] iteration 26921: loss: 0.025310, loss_s1: 0.020597, loss_fp: 0.002693, loss_freq: 0.005689
[07:17:28.528] iteration 26922: loss: 0.069321, loss_s1: 0.068029, loss_fp: 0.003272, loss_freq: 0.038540
[07:17:29.169] iteration 26923: loss: 0.035769, loss_s1: 0.021857, loss_fp: 0.002871, loss_freq: 0.011982
[07:17:29.778] iteration 26924: loss: 0.043477, loss_s1: 0.038437, loss_fp: 0.006371, loss_freq: 0.015541
[07:17:30.391] iteration 26925: loss: 0.063390, loss_s1: 0.077221, loss_fp: 0.004036, loss_freq: 0.015259
[07:17:30.992] iteration 26926: loss: 0.066863, loss_s1: 0.062520, loss_fp: 0.002106, loss_freq: 0.049205
[07:17:31.598] iteration 26927: loss: 0.034248, loss_s1: 0.020911, loss_fp: 0.001588, loss_freq: 0.010555
[07:17:32.205] iteration 26928: loss: 0.103455, loss_s1: 0.097050, loss_fp: 0.019600, loss_freq: 0.065662
[07:17:32.819] iteration 26929: loss: 0.053074, loss_s1: 0.027593, loss_fp: 0.005660, loss_freq: 0.039992
[07:17:33.428] iteration 26930: loss: 0.070126, loss_s1: 0.062460, loss_fp: 0.003808, loss_freq: 0.052966
[07:17:34.031] iteration 26931: loss: 0.065032, loss_s1: 0.033172, loss_fp: 0.002511, loss_freq: 0.033053
[07:17:34.641] iteration 26932: loss: 0.049342, loss_s1: 0.045359, loss_fp: 0.003984, loss_freq: 0.013685
[07:17:35.248] iteration 26933: loss: 0.056454, loss_s1: 0.037874, loss_fp: 0.004473, loss_freq: 0.038085
[07:17:35.848] iteration 26934: loss: 0.064340, loss_s1: 0.077469, loss_fp: 0.003374, loss_freq: 0.017575
[07:17:36.447] iteration 26935: loss: 0.062914, loss_s1: 0.041245, loss_fp: 0.002974, loss_freq: 0.052108
[07:17:37.051] iteration 26936: loss: 0.053042, loss_s1: 0.034335, loss_fp: 0.004893, loss_freq: 0.030262
[07:17:37.678] iteration 26937: loss: 0.056949, loss_s1: 0.044920, loss_fp: 0.000842, loss_freq: 0.031531
[07:17:38.277] iteration 26938: loss: 0.074070, loss_s1: 0.061356, loss_fp: 0.006465, loss_freq: 0.052887
[07:17:38.881] iteration 26939: loss: 0.055761, loss_s1: 0.058055, loss_fp: 0.018727, loss_freq: 0.018171
[07:17:39.490] iteration 26940: loss: 0.056557, loss_s1: 0.048705, loss_fp: 0.005361, loss_freq: 0.028294
[07:17:40.103] iteration 26941: loss: 0.064714, loss_s1: 0.069402, loss_fp: 0.002446, loss_freq: 0.022201
[07:17:40.739] iteration 26942: loss: 0.065955, loss_s1: 0.053321, loss_fp: 0.007607, loss_freq: 0.044351
[07:17:41.343] iteration 26943: loss: 0.060679, loss_s1: 0.073673, loss_fp: 0.002150, loss_freq: 0.017956
[07:17:41.998] iteration 26944: loss: 0.039426, loss_s1: 0.028327, loss_fp: 0.001448, loss_freq: 0.022622
[07:17:42.649] iteration 26945: loss: 0.047148, loss_s1: 0.025035, loss_fp: 0.007044, loss_freq: 0.024889
[07:17:43.311] iteration 26946: loss: 0.055146, loss_s1: 0.045115, loss_fp: 0.002429, loss_freq: 0.030632
[07:17:43.925] iteration 26947: loss: 0.066015, loss_s1: 0.075266, loss_fp: 0.003507, loss_freq: 0.032260
[07:17:44.542] iteration 26948: loss: 0.049261, loss_s1: 0.054464, loss_fp: 0.003155, loss_freq: 0.015964
[07:17:45.159] iteration 26949: loss: 0.079425, loss_s1: 0.093203, loss_fp: 0.005217, loss_freq: 0.030118
[07:17:45.761] iteration 26950: loss: 0.038866, loss_s1: 0.030729, loss_fp: 0.001871, loss_freq: 0.008764
[07:17:46.403] iteration 26951: loss: 0.070283, loss_s1: 0.061169, loss_fp: 0.003013, loss_freq: 0.039993
[07:17:47.036] iteration 26952: loss: 0.039843, loss_s1: 0.032124, loss_fp: 0.005874, loss_freq: 0.021406
[07:17:47.655] iteration 26953: loss: 0.065040, loss_s1: 0.057027, loss_fp: 0.010266, loss_freq: 0.018152
[07:17:48.261] iteration 26954: loss: 0.060315, loss_s1: 0.065096, loss_fp: 0.001922, loss_freq: 0.030940
[07:17:48.868] iteration 26955: loss: 0.080969, loss_s1: 0.078134, loss_fp: 0.015467, loss_freq: 0.039015
[07:17:49.493] iteration 26956: loss: 0.062296, loss_s1: 0.065325, loss_fp: 0.003460, loss_freq: 0.034068
[07:17:50.102] iteration 26957: loss: 0.055754, loss_s1: 0.036480, loss_fp: 0.003123, loss_freq: 0.027762
[07:17:50.705] iteration 26958: loss: 0.077007, loss_s1: 0.049553, loss_fp: 0.002978, loss_freq: 0.066827
[07:17:51.304] iteration 26959: loss: 0.057951, loss_s1: 0.046319, loss_fp: 0.003434, loss_freq: 0.037400
[07:17:51.899] iteration 26960: loss: 0.049511, loss_s1: 0.043016, loss_fp: 0.001355, loss_freq: 0.023388
[07:17:52.493] iteration 26961: loss: 0.065532, loss_s1: 0.073807, loss_fp: 0.003988, loss_freq: 0.032701
[07:17:53.088] iteration 26962: loss: 0.041028, loss_s1: 0.036010, loss_fp: 0.001968, loss_freq: 0.013333
[07:17:53.682] iteration 26963: loss: 0.040444, loss_s1: 0.024807, loss_fp: 0.004298, loss_freq: 0.022933
[07:17:54.279] iteration 26964: loss: 0.043522, loss_s1: 0.032990, loss_fp: 0.002799, loss_freq: 0.024573
[07:17:54.884] iteration 26965: loss: 0.034835, loss_s1: 0.035353, loss_fp: 0.003177, loss_freq: 0.011256
[07:17:55.497] iteration 26966: loss: 0.060331, loss_s1: 0.064978, loss_fp: 0.004869, loss_freq: 0.012481
[07:17:56.100] iteration 26967: loss: 0.063316, loss_s1: 0.062245, loss_fp: 0.006027, loss_freq: 0.026891
[07:17:56.706] iteration 26968: loss: 0.040312, loss_s1: 0.031593, loss_fp: 0.003712, loss_freq: 0.019698
[07:17:57.324] iteration 26969: loss: 0.069355, loss_s1: 0.041073, loss_fp: 0.002249, loss_freq: 0.068143
[07:17:57.931] iteration 26970: loss: 0.053848, loss_s1: 0.059987, loss_fp: 0.006534, loss_freq: 0.015289
[07:17:58.546] iteration 26971: loss: 0.040956, loss_s1: 0.026171, loss_fp: 0.003565, loss_freq: 0.018328
[07:17:59.149] iteration 26972: loss: 0.050474, loss_s1: 0.028444, loss_fp: 0.006668, loss_freq: 0.029648
[07:17:59.761] iteration 26973: loss: 0.059176, loss_s1: 0.072622, loss_fp: 0.003068, loss_freq: 0.019928
[07:18:00.363] iteration 26974: loss: 0.021485, loss_s1: 0.011679, loss_fp: 0.004188, loss_freq: 0.003649
[07:18:00.970] iteration 26975: loss: 0.075745, loss_s1: 0.066795, loss_fp: 0.002858, loss_freq: 0.049671
[07:18:01.568] iteration 26976: loss: 0.058031, loss_s1: 0.043366, loss_fp: 0.005912, loss_freq: 0.037461
[07:18:02.177] iteration 26977: loss: 0.051034, loss_s1: 0.037959, loss_fp: 0.001048, loss_freq: 0.028050
[07:18:02.787] iteration 26978: loss: 0.038864, loss_s1: 0.020459, loss_fp: 0.005740, loss_freq: 0.028078
[07:18:03.394] iteration 26979: loss: 0.061755, loss_s1: 0.035520, loss_fp: 0.001993, loss_freq: 0.061800
[07:18:03.999] iteration 26980: loss: 0.026601, loss_s1: 0.018574, loss_fp: 0.001462, loss_freq: 0.003968
[07:18:04.593] iteration 26981: loss: 0.055818, loss_s1: 0.067463, loss_fp: 0.002777, loss_freq: 0.010456
[07:18:05.192] iteration 26982: loss: 0.070671, loss_s1: 0.073775, loss_fp: 0.019161, loss_freq: 0.027903
[07:18:05.801] iteration 26983: loss: 0.055716, loss_s1: 0.060541, loss_fp: 0.003262, loss_freq: 0.021113
[07:18:06.408] iteration 26984: loss: 0.047742, loss_s1: 0.025689, loss_fp: 0.005936, loss_freq: 0.034020
[07:18:07.016] iteration 26985: loss: 0.054693, loss_s1: 0.055754, loss_fp: 0.004176, loss_freq: 0.018492
[07:18:07.623] iteration 26986: loss: 0.046087, loss_s1: 0.038585, loss_fp: 0.003029, loss_freq: 0.018419
[07:18:08.237] iteration 26987: loss: 0.041352, loss_s1: 0.022707, loss_fp: 0.002489, loss_freq: 0.034235
[07:18:08.852] iteration 26988: loss: 0.031566, loss_s1: 0.014778, loss_fp: 0.002632, loss_freq: 0.006984
[07:18:09.452] iteration 26989: loss: 0.042084, loss_s1: 0.034213, loss_fp: 0.010406, loss_freq: 0.016031
[07:18:10.053] iteration 26990: loss: 0.104649, loss_s1: 0.129039, loss_fp: 0.006797, loss_freq: 0.042286
[07:18:10.656] iteration 26991: loss: 0.039187, loss_s1: 0.037555, loss_fp: 0.002438, loss_freq: 0.016279
[07:18:11.263] iteration 26992: loss: 0.066820, loss_s1: 0.036855, loss_fp: 0.005877, loss_freq: 0.047426
[07:18:11.875] iteration 26993: loss: 0.078005, loss_s1: 0.083161, loss_fp: 0.006628, loss_freq: 0.035506
[07:18:12.474] iteration 26994: loss: 0.077666, loss_s1: 0.094929, loss_fp: 0.003466, loss_freq: 0.028901
[07:18:13.076] iteration 26995: loss: 0.057015, loss_s1: 0.049035, loss_fp: 0.005837, loss_freq: 0.028137
[07:18:13.695] iteration 26996: loss: 0.038150, loss_s1: 0.036690, loss_fp: 0.000782, loss_freq: 0.017400
[07:18:14.304] iteration 26997: loss: 0.057845, loss_s1: 0.056719, loss_fp: 0.003846, loss_freq: 0.017340
[07:18:14.920] iteration 26998: loss: 0.043776, loss_s1: 0.037028, loss_fp: 0.004270, loss_freq: 0.022595
[07:18:15.521] iteration 26999: loss: 0.104685, loss_s1: 0.113464, loss_fp: 0.002540, loss_freq: 0.065760
[07:18:16.134] iteration 27000: loss: 0.057584, loss_s1: 0.060359, loss_fp: 0.004260, loss_freq: 0.031674
[07:18:19.557] iteration 27000 : mean_dice : 0.751799
[07:18:20.212] iteration 27001: loss: 0.052027, loss_s1: 0.031008, loss_fp: 0.012302, loss_freq: 0.018391
[07:18:20.826] iteration 27002: loss: 0.039727, loss_s1: 0.022703, loss_fp: 0.002774, loss_freq: 0.020872
[07:18:21.469] iteration 27003: loss: 0.028899, loss_s1: 0.021626, loss_fp: 0.002433, loss_freq: 0.008594
[07:18:22.183] iteration 27004: loss: 0.037187, loss_s1: 0.029076, loss_fp: 0.001550, loss_freq: 0.009322
[07:18:22.849] iteration 27005: loss: 0.029829, loss_s1: 0.017784, loss_fp: 0.002763, loss_freq: 0.014444
[07:18:23.543] iteration 27006: loss: 0.062002, loss_s1: 0.045088, loss_fp: 0.003014, loss_freq: 0.038148
[07:18:24.185] iteration 27007: loss: 0.036199, loss_s1: 0.024392, loss_fp: 0.003228, loss_freq: 0.013948
[07:18:24.854] iteration 27008: loss: 0.040632, loss_s1: 0.029140, loss_fp: 0.004510, loss_freq: 0.023858
[07:18:25.528] iteration 27009: loss: 0.043773, loss_s1: 0.040917, loss_fp: 0.004572, loss_freq: 0.024735
[07:18:26.146] iteration 27010: loss: 0.045379, loss_s1: 0.033387, loss_fp: 0.004974, loss_freq: 0.020683
[07:18:26.829] iteration 27011: loss: 0.056136, loss_s1: 0.046946, loss_fp: 0.010450, loss_freq: 0.023199
[07:18:27.490] iteration 27012: loss: 0.060182, loss_s1: 0.072692, loss_fp: 0.003447, loss_freq: 0.016667
[07:18:28.153] iteration 27013: loss: 0.070769, loss_s1: 0.073662, loss_fp: 0.005600, loss_freq: 0.026251
[07:18:28.778] iteration 27014: loss: 0.081589, loss_s1: 0.081952, loss_fp: 0.005458, loss_freq: 0.046991
[07:18:29.400] iteration 27015: loss: 0.070032, loss_s1: 0.047175, loss_fp: 0.011020, loss_freq: 0.038248
[07:18:30.018] iteration 27016: loss: 0.036230, loss_s1: 0.026153, loss_fp: 0.001648, loss_freq: 0.009615
[07:18:30.633] iteration 27017: loss: 0.036348, loss_s1: 0.036134, loss_fp: 0.002114, loss_freq: 0.015147
[07:18:31.240] iteration 27018: loss: 0.070948, loss_s1: 0.056449, loss_fp: 0.005320, loss_freq: 0.048944
[07:18:31.845] iteration 27019: loss: 0.070376, loss_s1: 0.074646, loss_fp: 0.007963, loss_freq: 0.029426
[07:18:32.450] iteration 27020: loss: 0.064359, loss_s1: 0.068687, loss_fp: 0.006641, loss_freq: 0.024971
[07:18:33.054] iteration 27021: loss: 0.052658, loss_s1: 0.058555, loss_fp: 0.007644, loss_freq: 0.005418
[07:18:33.657] iteration 27022: loss: 0.063311, loss_s1: 0.052375, loss_fp: 0.007742, loss_freq: 0.047424
[07:18:34.320] iteration 27023: loss: 0.030867, loss_s1: 0.016501, loss_fp: 0.002508, loss_freq: 0.007709
[07:18:34.983] iteration 27024: loss: 0.059576, loss_s1: 0.064056, loss_fp: 0.011087, loss_freq: 0.020748
[07:18:35.651] iteration 27025: loss: 0.028410, loss_s1: 0.010862, loss_fp: 0.003799, loss_freq: 0.013666
[07:18:36.317] iteration 27026: loss: 0.052416, loss_s1: 0.041129, loss_fp: 0.007383, loss_freq: 0.034512
[07:18:36.925] iteration 27027: loss: 0.063625, loss_s1: 0.060494, loss_fp: 0.006869, loss_freq: 0.029421
[07:18:37.538] iteration 27028: loss: 0.083075, loss_s1: 0.045910, loss_fp: 0.018492, loss_freq: 0.069986
[07:18:38.158] iteration 27029: loss: 0.063718, loss_s1: 0.041928, loss_fp: 0.002768, loss_freq: 0.061048
[07:18:38.774] iteration 27030: loss: 0.058297, loss_s1: 0.062440, loss_fp: 0.008526, loss_freq: 0.011776
[07:18:39.885] iteration 27031: loss: 0.062689, loss_s1: 0.043673, loss_fp: 0.006965, loss_freq: 0.030041
[07:18:40.859] iteration 27032: loss: 0.057103, loss_s1: 0.050007, loss_fp: 0.007054, loss_freq: 0.027732
[07:18:41.823] iteration 27033: loss: 0.051032, loss_s1: 0.046137, loss_fp: 0.006854, loss_freq: 0.022613
[07:18:42.471] iteration 27034: loss: 0.052267, loss_s1: 0.049903, loss_fp: 0.002345, loss_freq: 0.022917
[07:18:43.082] iteration 27035: loss: 0.068038, loss_s1: 0.044198, loss_fp: 0.006376, loss_freq: 0.056537
[07:18:43.698] iteration 27036: loss: 0.053712, loss_s1: 0.047238, loss_fp: 0.007634, loss_freq: 0.022533
[07:18:44.329] iteration 27037: loss: 0.054238, loss_s1: 0.038105, loss_fp: 0.007157, loss_freq: 0.038956
[07:18:44.964] iteration 27038: loss: 0.028039, loss_s1: 0.021912, loss_fp: 0.001842, loss_freq: 0.008001
[07:18:45.599] iteration 27039: loss: 0.042298, loss_s1: 0.033566, loss_fp: 0.003445, loss_freq: 0.025883
[07:18:46.239] iteration 27040: loss: 0.069194, loss_s1: 0.062753, loss_fp: 0.006339, loss_freq: 0.029665
[07:18:46.871] iteration 27041: loss: 0.059531, loss_s1: 0.046667, loss_fp: 0.006520, loss_freq: 0.038038
[07:18:47.506] iteration 27042: loss: 0.078750, loss_s1: 0.052740, loss_fp: 0.003260, loss_freq: 0.074817
[07:18:48.140] iteration 27043: loss: 0.066389, loss_s1: 0.048070, loss_fp: 0.008305, loss_freq: 0.037378
[07:18:48.812] iteration 27044: loss: 0.057374, loss_s1: 0.036372, loss_fp: 0.016276, loss_freq: 0.033857
[07:18:49.438] iteration 27045: loss: 0.037920, loss_s1: 0.031629, loss_fp: 0.001310, loss_freq: 0.012425
[07:18:50.047] iteration 27046: loss: 0.044521, loss_s1: 0.023849, loss_fp: 0.002833, loss_freq: 0.030996
[07:18:50.667] iteration 27047: loss: 0.079404, loss_s1: 0.100959, loss_fp: 0.003657, loss_freq: 0.037550
[07:18:51.300] iteration 27048: loss: 0.035751, loss_s1: 0.028790, loss_fp: 0.002593, loss_freq: 0.007486
[07:18:51.908] iteration 27049: loss: 0.075989, loss_s1: 0.091045, loss_fp: 0.006941, loss_freq: 0.027752
[07:18:52.529] iteration 27050: loss: 0.052965, loss_s1: 0.049886, loss_fp: 0.003014, loss_freq: 0.020700
[07:18:53.150] iteration 27051: loss: 0.060130, loss_s1: 0.032863, loss_fp: 0.006026, loss_freq: 0.051617
[07:18:53.758] iteration 27052: loss: 0.039928, loss_s1: 0.032771, loss_fp: 0.004584, loss_freq: 0.020612
[07:18:54.382] iteration 27053: loss: 0.047528, loss_s1: 0.037354, loss_fp: 0.001444, loss_freq: 0.019496
[07:18:55.036] iteration 27054: loss: 0.052402, loss_s1: 0.057619, loss_fp: 0.004872, loss_freq: 0.013964
[07:18:55.649] iteration 27055: loss: 0.045466, loss_s1: 0.026108, loss_fp: 0.002779, loss_freq: 0.032369
[07:18:56.267] iteration 27056: loss: 0.044104, loss_s1: 0.038663, loss_fp: 0.004575, loss_freq: 0.024205
[07:18:56.881] iteration 27057: loss: 0.045316, loss_s1: 0.037577, loss_fp: 0.007701, loss_freq: 0.005399
[07:18:57.493] iteration 27058: loss: 0.120139, loss_s1: 0.103231, loss_fp: 0.014891, loss_freq: 0.065620
[07:18:58.113] iteration 27059: loss: 0.053917, loss_s1: 0.040640, loss_fp: 0.005024, loss_freq: 0.033935
[07:18:58.730] iteration 27060: loss: 0.074423, loss_s1: 0.074084, loss_fp: 0.007353, loss_freq: 0.036528
[07:18:59.339] iteration 27061: loss: 0.063663, loss_s1: 0.057958, loss_fp: 0.003740, loss_freq: 0.046068
[07:18:59.949] iteration 27062: loss: 0.061284, loss_s1: 0.039812, loss_fp: 0.002500, loss_freq: 0.035408
[07:19:00.568] iteration 27063: loss: 0.051331, loss_s1: 0.046736, loss_fp: 0.006042, loss_freq: 0.023827
[07:19:01.188] iteration 27064: loss: 0.047107, loss_s1: 0.036937, loss_fp: 0.017154, loss_freq: 0.011303
[07:19:01.805] iteration 27065: loss: 0.038493, loss_s1: 0.023119, loss_fp: 0.002598, loss_freq: 0.032879
[07:19:02.422] iteration 27066: loss: 0.054966, loss_s1: 0.045142, loss_fp: 0.002712, loss_freq: 0.018081
[07:19:03.041] iteration 27067: loss: 0.050983, loss_s1: 0.034998, loss_fp: 0.007661, loss_freq: 0.027139
[07:19:03.661] iteration 27068: loss: 0.060795, loss_s1: 0.069446, loss_fp: 0.003761, loss_freq: 0.020991
[07:19:04.271] iteration 27069: loss: 0.089400, loss_s1: 0.119545, loss_fp: 0.003369, loss_freq: 0.023908
[07:19:04.930] iteration 27070: loss: 0.053172, loss_s1: 0.037542, loss_fp: 0.005291, loss_freq: 0.039537
[07:19:05.549] iteration 27071: loss: 0.065059, loss_s1: 0.079806, loss_fp: 0.006451, loss_freq: 0.015185
[07:19:06.166] iteration 27072: loss: 0.069184, loss_s1: 0.073336, loss_fp: 0.004426, loss_freq: 0.018461
[07:19:06.782] iteration 27073: loss: 0.057318, loss_s1: 0.056301, loss_fp: 0.002822, loss_freq: 0.025591
[07:19:07.405] iteration 27074: loss: 0.104513, loss_s1: 0.093116, loss_fp: 0.006097, loss_freq: 0.082257
[07:19:08.017] iteration 27075: loss: 0.063718, loss_s1: 0.038082, loss_fp: 0.002663, loss_freq: 0.052226
[07:19:08.629] iteration 27076: loss: 0.083333, loss_s1: 0.105571, loss_fp: 0.007678, loss_freq: 0.023212
[07:19:09.238] iteration 27077: loss: 0.063091, loss_s1: 0.040589, loss_fp: 0.003872, loss_freq: 0.050456
[07:19:09.848] iteration 27078: loss: 0.069868, loss_s1: 0.068250, loss_fp: 0.005983, loss_freq: 0.025417
[07:19:10.464] iteration 27079: loss: 0.047983, loss_s1: 0.055839, loss_fp: 0.003449, loss_freq: 0.008933
[07:19:11.076] iteration 27080: loss: 0.044607, loss_s1: 0.046461, loss_fp: 0.002578, loss_freq: 0.006250
[07:19:11.688] iteration 27081: loss: 0.037768, loss_s1: 0.025402, loss_fp: 0.001490, loss_freq: 0.014797
[07:19:12.297] iteration 27082: loss: 0.066045, loss_s1: 0.093729, loss_fp: 0.002420, loss_freq: 0.014358
[07:19:12.912] iteration 27083: loss: 0.044301, loss_s1: 0.027173, loss_fp: 0.006948, loss_freq: 0.011717
[07:19:13.527] iteration 27084: loss: 0.102836, loss_s1: 0.141298, loss_fp: 0.003239, loss_freq: 0.026176
[07:19:14.138] iteration 27085: loss: 0.054361, loss_s1: 0.035832, loss_fp: 0.008497, loss_freq: 0.031651
[07:19:14.752] iteration 27086: loss: 0.034623, loss_s1: 0.019415, loss_fp: 0.001574, loss_freq: 0.014347
[07:19:15.360] iteration 27087: loss: 0.067862, loss_s1: 0.091101, loss_fp: 0.005274, loss_freq: 0.020259
[07:19:15.971] iteration 27088: loss: 0.045424, loss_s1: 0.016924, loss_fp: 0.007266, loss_freq: 0.032406
[07:19:16.585] iteration 27089: loss: 0.032593, loss_s1: 0.026844, loss_fp: 0.001817, loss_freq: 0.016441
[07:19:17.195] iteration 27090: loss: 0.054721, loss_s1: 0.033080, loss_fp: 0.004797, loss_freq: 0.042045
[07:19:17.816] iteration 27091: loss: 0.030806, loss_s1: 0.030710, loss_fp: 0.001627, loss_freq: 0.006677
[07:19:18.432] iteration 27092: loss: 0.069764, loss_s1: 0.056944, loss_fp: 0.004896, loss_freq: 0.038672
[07:19:19.043] iteration 27093: loss: 0.030114, loss_s1: 0.017774, loss_fp: 0.003320, loss_freq: 0.009202
[07:19:19.656] iteration 27094: loss: 0.041717, loss_s1: 0.024977, loss_fp: 0.002102, loss_freq: 0.024277
[07:19:20.278] iteration 27095: loss: 0.028927, loss_s1: 0.013999, loss_fp: 0.002013, loss_freq: 0.009365
[07:19:20.892] iteration 27096: loss: 0.047701, loss_s1: 0.043654, loss_fp: 0.004185, loss_freq: 0.027712
[07:19:21.511] iteration 27097: loss: 0.040084, loss_s1: 0.036449, loss_fp: 0.003540, loss_freq: 0.009492
[07:19:22.127] iteration 27098: loss: 0.098597, loss_s1: 0.099840, loss_fp: 0.004613, loss_freq: 0.063743
[07:19:22.748] iteration 27099: loss: 0.025495, loss_s1: 0.017443, loss_fp: 0.001357, loss_freq: 0.005058
[07:19:23.364] iteration 27100: loss: 0.046665, loss_s1: 0.046778, loss_fp: 0.002471, loss_freq: 0.022336
[07:19:23.985] iteration 27101: loss: 0.048169, loss_s1: 0.032836, loss_fp: 0.010280, loss_freq: 0.021666
[07:19:24.599] iteration 27102: loss: 0.048502, loss_s1: 0.024388, loss_fp: 0.002737, loss_freq: 0.040244
[07:19:25.235] iteration 27103: loss: 0.077762, loss_s1: 0.090024, loss_fp: 0.008440, loss_freq: 0.033196
[07:19:25.853] iteration 27104: loss: 0.045656, loss_s1: 0.047344, loss_fp: 0.003834, loss_freq: 0.012294
[07:19:26.463] iteration 27105: loss: 0.061169, loss_s1: 0.025855, loss_fp: 0.014251, loss_freq: 0.056583
[07:19:27.066] iteration 27106: loss: 0.047937, loss_s1: 0.031891, loss_fp: 0.010564, loss_freq: 0.021215
[07:19:27.681] iteration 27107: loss: 0.037332, loss_s1: 0.031072, loss_fp: 0.001641, loss_freq: 0.014793
[07:19:28.284] iteration 27108: loss: 0.039566, loss_s1: 0.032417, loss_fp: 0.005290, loss_freq: 0.014519
[07:19:28.889] iteration 27109: loss: 0.047283, loss_s1: 0.024805, loss_fp: 0.009730, loss_freq: 0.036177
[07:19:29.496] iteration 27110: loss: 0.078199, loss_s1: 0.052877, loss_fp: 0.005580, loss_freq: 0.062743
[07:19:30.108] iteration 27111: loss: 0.039724, loss_s1: 0.038311, loss_fp: 0.004092, loss_freq: 0.005271
[07:19:30.710] iteration 27112: loss: 0.051760, loss_s1: 0.053777, loss_fp: 0.002383, loss_freq: 0.018577
[07:19:31.315] iteration 27113: loss: 0.051952, loss_s1: 0.056761, loss_fp: 0.006315, loss_freq: 0.015723
[07:19:31.925] iteration 27114: loss: 0.040223, loss_s1: 0.036261, loss_fp: 0.003428, loss_freq: 0.016274
[07:19:32.533] iteration 27115: loss: 0.050669, loss_s1: 0.039295, loss_fp: 0.001639, loss_freq: 0.028901
[07:19:33.143] iteration 27116: loss: 0.070192, loss_s1: 0.038052, loss_fp: 0.005713, loss_freq: 0.059633
[07:19:33.752] iteration 27117: loss: 0.053116, loss_s1: 0.061452, loss_fp: 0.002961, loss_freq: 0.022573
[07:19:34.374] iteration 27118: loss: 0.048169, loss_s1: 0.033740, loss_fp: 0.002454, loss_freq: 0.033974
[07:19:34.988] iteration 27119: loss: 0.058853, loss_s1: 0.059083, loss_fp: 0.007549, loss_freq: 0.021327
[07:19:35.598] iteration 27120: loss: 0.058856, loss_s1: 0.054562, loss_fp: 0.005828, loss_freq: 0.022152
[07:19:36.203] iteration 27121: loss: 0.079975, loss_s1: 0.098316, loss_fp: 0.005941, loss_freq: 0.022602
[07:19:36.815] iteration 27122: loss: 0.065239, loss_s1: 0.051210, loss_fp: 0.004440, loss_freq: 0.050282
[07:19:37.432] iteration 27123: loss: 0.064023, loss_s1: 0.060008, loss_fp: 0.004353, loss_freq: 0.025039
[07:19:38.043] iteration 27124: loss: 0.057076, loss_s1: 0.066927, loss_fp: 0.003416, loss_freq: 0.020873
[07:19:38.651] iteration 27125: loss: 0.056189, loss_s1: 0.060531, loss_fp: 0.010250, loss_freq: 0.016688
[07:19:39.267] iteration 27126: loss: 0.040369, loss_s1: 0.031730, loss_fp: 0.003928, loss_freq: 0.025880
[07:19:39.882] iteration 27127: loss: 0.052748, loss_s1: 0.028409, loss_fp: 0.005493, loss_freq: 0.040078
[07:19:40.500] iteration 27128: loss: 0.059831, loss_s1: 0.046170, loss_fp: 0.003967, loss_freq: 0.040404
[07:19:41.114] iteration 27129: loss: 0.044984, loss_s1: 0.031197, loss_fp: 0.014344, loss_freq: 0.017454
[07:19:41.724] iteration 27130: loss: 0.053154, loss_s1: 0.036363, loss_fp: 0.003656, loss_freq: 0.027922
[07:19:42.340] iteration 27131: loss: 0.047745, loss_s1: 0.035837, loss_fp: 0.001579, loss_freq: 0.028611
[07:19:42.957] iteration 27132: loss: 0.046638, loss_s1: 0.038011, loss_fp: 0.002757, loss_freq: 0.010647
[07:19:43.580] iteration 27133: loss: 0.051078, loss_s1: 0.035341, loss_fp: 0.003309, loss_freq: 0.025469
[07:19:44.188] iteration 27134: loss: 0.038054, loss_s1: 0.018426, loss_fp: 0.004144, loss_freq: 0.027568
[07:19:44.806] iteration 27135: loss: 0.052690, loss_s1: 0.031843, loss_fp: 0.003637, loss_freq: 0.033749
[07:19:45.420] iteration 27136: loss: 0.066169, loss_s1: 0.045030, loss_fp: 0.002818, loss_freq: 0.046733
[07:19:46.030] iteration 27137: loss: 0.036417, loss_s1: 0.030288, loss_fp: 0.002272, loss_freq: 0.010663
[07:19:46.633] iteration 27138: loss: 0.051526, loss_s1: 0.041505, loss_fp: 0.004144, loss_freq: 0.033413
[07:19:47.238] iteration 27139: loss: 0.049747, loss_s1: 0.015739, loss_fp: 0.013539, loss_freq: 0.040573
[07:19:47.850] iteration 27140: loss: 0.070944, loss_s1: 0.073549, loss_fp: 0.004069, loss_freq: 0.036563
[07:19:48.457] iteration 27141: loss: 0.074437, loss_s1: 0.077087, loss_fp: 0.010730, loss_freq: 0.026599
[07:19:49.056] iteration 27142: loss: 0.051097, loss_s1: 0.036383, loss_fp: 0.005207, loss_freq: 0.030301
[07:19:49.664] iteration 27143: loss: 0.062330, loss_s1: 0.069197, loss_fp: 0.004413, loss_freq: 0.029896
[07:19:50.271] iteration 27144: loss: 0.031754, loss_s1: 0.019364, loss_fp: 0.003001, loss_freq: 0.023111
[07:19:50.881] iteration 27145: loss: 0.049334, loss_s1: 0.025563, loss_fp: 0.008549, loss_freq: 0.033949
[07:19:51.489] iteration 27146: loss: 0.086722, loss_s1: 0.044104, loss_fp: 0.009234, loss_freq: 0.091522
[07:19:52.095] iteration 27147: loss: 0.042077, loss_s1: 0.040347, loss_fp: 0.002083, loss_freq: 0.014496
[07:19:52.704] iteration 27148: loss: 0.059407, loss_s1: 0.041235, loss_fp: 0.005915, loss_freq: 0.047713
[07:19:53.315] iteration 27149: loss: 0.051113, loss_s1: 0.025849, loss_fp: 0.006249, loss_freq: 0.042756
[07:19:53.934] iteration 27150: loss: 0.059384, loss_s1: 0.031391, loss_fp: 0.004125, loss_freq: 0.050330
[07:19:54.542] iteration 27151: loss: 0.025265, loss_s1: 0.013549, loss_fp: 0.001599, loss_freq: 0.005610
[07:19:55.154] iteration 27152: loss: 0.083072, loss_s1: 0.093161, loss_fp: 0.004628, loss_freq: 0.049761
[07:19:55.763] iteration 27153: loss: 0.080393, loss_s1: 0.059996, loss_fp: 0.002684, loss_freq: 0.070643
[07:19:56.398] iteration 27154: loss: 0.051097, loss_s1: 0.031863, loss_fp: 0.005923, loss_freq: 0.038229
[07:19:57.040] iteration 27155: loss: 0.049264, loss_s1: 0.041472, loss_fp: 0.002659, loss_freq: 0.022978
[07:19:57.709] iteration 27156: loss: 0.032242, loss_s1: 0.016232, loss_fp: 0.002936, loss_freq: 0.017969
[07:19:58.367] iteration 27157: loss: 0.064030, loss_s1: 0.056874, loss_fp: 0.002326, loss_freq: 0.045434
[07:19:59.024] iteration 27158: loss: 0.063912, loss_s1: 0.050023, loss_fp: 0.002356, loss_freq: 0.038651
[07:19:59.691] iteration 27159: loss: 0.057339, loss_s1: 0.054426, loss_fp: 0.003442, loss_freq: 0.031936
[07:20:00.342] iteration 27160: loss: 0.088588, loss_s1: 0.104391, loss_fp: 0.007908, loss_freq: 0.034314
[07:20:00.954] iteration 27161: loss: 0.037486, loss_s1: 0.030215, loss_fp: 0.008164, loss_freq: 0.012198
[07:20:01.569] iteration 27162: loss: 0.066561, loss_s1: 0.077991, loss_fp: 0.003893, loss_freq: 0.015346
[07:20:02.181] iteration 27163: loss: 0.058579, loss_s1: 0.050970, loss_fp: 0.002185, loss_freq: 0.028218
[07:20:02.793] iteration 27164: loss: 0.059928, loss_s1: 0.058324, loss_fp: 0.006330, loss_freq: 0.027637
[07:20:03.406] iteration 27165: loss: 0.099569, loss_s1: 0.122948, loss_fp: 0.003285, loss_freq: 0.035664
[07:20:04.021] iteration 27166: loss: 0.033404, loss_s1: 0.026136, loss_fp: 0.005502, loss_freq: 0.008476
[07:20:04.649] iteration 27167: loss: 0.081646, loss_s1: 0.101987, loss_fp: 0.002655, loss_freq: 0.021068
[07:20:05.261] iteration 27168: loss: 0.069745, loss_s1: 0.047301, loss_fp: 0.006400, loss_freq: 0.061444
[07:20:05.886] iteration 27169: loss: 0.091741, loss_s1: 0.074218, loss_fp: 0.011507, loss_freq: 0.062141
[07:20:06.507] iteration 27170: loss: 0.051765, loss_s1: 0.056115, loss_fp: 0.003952, loss_freq: 0.024620
[07:20:07.129] iteration 27171: loss: 0.061931, loss_s1: 0.037773, loss_fp: 0.011178, loss_freq: 0.040079
[07:20:07.745] iteration 27172: loss: 0.043632, loss_s1: 0.039682, loss_fp: 0.001955, loss_freq: 0.018302
[07:20:08.358] iteration 27173: loss: 0.054178, loss_s1: 0.038828, loss_fp: 0.009338, loss_freq: 0.033650
[07:20:08.972] iteration 27174: loss: 0.029893, loss_s1: 0.016630, loss_fp: 0.002085, loss_freq: 0.013541
[07:20:09.579] iteration 27175: loss: 0.029841, loss_s1: 0.020289, loss_fp: 0.002327, loss_freq: 0.014496
[07:20:10.191] iteration 27176: loss: 0.044905, loss_s1: 0.021814, loss_fp: 0.002447, loss_freq: 0.033145
[07:20:10.806] iteration 27177: loss: 0.039621, loss_s1: 0.021525, loss_fp: 0.002856, loss_freq: 0.023918
[07:20:11.413] iteration 27178: loss: 0.106903, loss_s1: 0.128957, loss_fp: 0.005680, loss_freq: 0.055463
[07:20:12.026] iteration 27179: loss: 0.049154, loss_s1: 0.035647, loss_fp: 0.003356, loss_freq: 0.035941
[07:20:12.644] iteration 27180: loss: 0.039101, loss_s1: 0.026880, loss_fp: 0.002026, loss_freq: 0.017604
[07:20:13.264] iteration 27181: loss: 0.072984, loss_s1: 0.069954, loss_fp: 0.025301, loss_freq: 0.019736
[07:20:13.880] iteration 27182: loss: 0.045087, loss_s1: 0.033603, loss_fp: 0.006218, loss_freq: 0.019480
[07:20:14.494] iteration 27183: loss: 0.090668, loss_s1: 0.103667, loss_fp: 0.007326, loss_freq: 0.045586
[07:20:15.122] iteration 27184: loss: 0.093726, loss_s1: 0.099896, loss_fp: 0.008557, loss_freq: 0.054238
[07:20:15.734] iteration 27185: loss: 0.100162, loss_s1: 0.080136, loss_fp: 0.011351, loss_freq: 0.055032
[07:20:16.350] iteration 27186: loss: 0.047080, loss_s1: 0.054236, loss_fp: 0.001656, loss_freq: 0.006767
[07:20:16.963] iteration 27187: loss: 0.031146, loss_s1: 0.025410, loss_fp: 0.003509, loss_freq: 0.014108
[07:20:17.645] iteration 27188: loss: 0.059288, loss_s1: 0.051309, loss_fp: 0.004554, loss_freq: 0.035276
[07:20:18.284] iteration 27189: loss: 0.051562, loss_s1: 0.039263, loss_fp: 0.008424, loss_freq: 0.024577
[07:20:18.911] iteration 27190: loss: 0.058017, loss_s1: 0.030051, loss_fp: 0.003523, loss_freq: 0.051782
[07:20:19.529] iteration 27191: loss: 0.041439, loss_s1: 0.041300, loss_fp: 0.002318, loss_freq: 0.005394
[07:20:20.145] iteration 27192: loss: 0.053349, loss_s1: 0.054151, loss_fp: 0.003458, loss_freq: 0.030361
[07:20:20.754] iteration 27193: loss: 0.027544, loss_s1: 0.011044, loss_fp: 0.001889, loss_freq: 0.005193
[07:20:21.372] iteration 27194: loss: 0.038330, loss_s1: 0.020009, loss_fp: 0.003048, loss_freq: 0.027026
[07:20:21.991] iteration 27195: loss: 0.042102, loss_s1: 0.037310, loss_fp: 0.001990, loss_freq: 0.013569
[07:20:22.608] iteration 27196: loss: 0.059735, loss_s1: 0.058190, loss_fp: 0.003170, loss_freq: 0.033989
[07:20:23.227] iteration 27197: loss: 0.066362, loss_s1: 0.053237, loss_fp: 0.007626, loss_freq: 0.039962
[07:20:23.841] iteration 27198: loss: 0.095090, loss_s1: 0.125234, loss_fp: 0.005072, loss_freq: 0.026420
[07:20:24.459] iteration 27199: loss: 0.047289, loss_s1: 0.041772, loss_fp: 0.004229, loss_freq: 0.024882
[07:20:25.062] iteration 27200: loss: 0.087270, loss_s1: 0.118959, loss_fp: 0.004940, loss_freq: 0.017243
[07:20:28.352] iteration 27200 : mean_dice : 0.744091
[07:20:29.295] iteration 27201: loss: 0.058375, loss_s1: 0.056082, loss_fp: 0.009197, loss_freq: 0.017352
[07:20:29.907] iteration 27202: loss: 0.054858, loss_s1: 0.032117, loss_fp: 0.005548, loss_freq: 0.038170
[07:20:30.515] iteration 27203: loss: 0.072132, loss_s1: 0.088870, loss_fp: 0.009167, loss_freq: 0.019992
[07:20:31.123] iteration 27204: loss: 0.045535, loss_s1: 0.038134, loss_fp: 0.002340, loss_freq: 0.020304
[07:20:31.735] iteration 27205: loss: 0.040851, loss_s1: 0.028048, loss_fp: 0.006917, loss_freq: 0.021070
[07:20:32.350] iteration 27206: loss: 0.055330, loss_s1: 0.052148, loss_fp: 0.001827, loss_freq: 0.023834
[07:20:32.956] iteration 27207: loss: 0.042588, loss_s1: 0.037797, loss_fp: 0.003637, loss_freq: 0.016553
[07:20:33.566] iteration 27208: loss: 0.046709, loss_s1: 0.051300, loss_fp: 0.003009, loss_freq: 0.016509
[07:20:34.175] iteration 27209: loss: 0.034475, loss_s1: 0.036747, loss_fp: 0.002278, loss_freq: 0.009904
[07:20:34.839] iteration 27210: loss: 0.084025, loss_s1: 0.067052, loss_fp: 0.005663, loss_freq: 0.028851
[07:20:35.502] iteration 27211: loss: 0.072287, loss_s1: 0.079487, loss_fp: 0.006531, loss_freq: 0.030047
[07:20:36.160] iteration 27212: loss: 0.069324, loss_s1: 0.039892, loss_fp: 0.004866, loss_freq: 0.062490
[07:20:36.788] iteration 27213: loss: 0.046107, loss_s1: 0.039331, loss_fp: 0.010612, loss_freq: 0.018271
[07:20:37.408] iteration 27214: loss: 0.080708, loss_s1: 0.082342, loss_fp: 0.006898, loss_freq: 0.033924
[07:20:38.015] iteration 27215: loss: 0.069441, loss_s1: 0.055183, loss_fp: 0.007815, loss_freq: 0.035509
[07:20:38.638] iteration 27216: loss: 0.040848, loss_s1: 0.018821, loss_fp: 0.010850, loss_freq: 0.022712
[07:20:39.248] iteration 27217: loss: 0.095881, loss_s1: 0.061044, loss_fp: 0.002578, loss_freq: 0.102233
[07:20:39.860] iteration 27218: loss: 0.026895, loss_s1: 0.015961, loss_fp: 0.002465, loss_freq: 0.007484
[07:20:40.478] iteration 27219: loss: 0.071873, loss_s1: 0.066022, loss_fp: 0.008841, loss_freq: 0.040604
[07:20:41.097] iteration 27220: loss: 0.038677, loss_s1: 0.030875, loss_fp: 0.002051, loss_freq: 0.013932
[07:20:41.707] iteration 27221: loss: 0.049233, loss_s1: 0.023355, loss_fp: 0.005653, loss_freq: 0.038514
[07:20:42.320] iteration 27222: loss: 0.052349, loss_s1: 0.041191, loss_fp: 0.005748, loss_freq: 0.035232
[07:20:42.936] iteration 27223: loss: 0.075303, loss_s1: 0.064433, loss_fp: 0.005981, loss_freq: 0.040240
[07:20:43.592] iteration 27224: loss: 0.047161, loss_s1: 0.035430, loss_fp: 0.007173, loss_freq: 0.031497
[07:20:44.206] iteration 27225: loss: 0.046133, loss_s1: 0.029426, loss_fp: 0.005291, loss_freq: 0.032302
[07:20:44.930] iteration 27226: loss: 0.053342, loss_s1: 0.040163, loss_fp: 0.004154, loss_freq: 0.041441
[07:20:45.900] iteration 27227: loss: 0.060825, loss_s1: 0.033307, loss_fp: 0.002175, loss_freq: 0.020045
[07:20:46.666] iteration 27228: loss: 0.080562, loss_s1: 0.076314, loss_fp: 0.004769, loss_freq: 0.046053
[07:20:47.271] iteration 27229: loss: 0.047680, loss_s1: 0.039817, loss_fp: 0.011795, loss_freq: 0.018688
[07:20:47.899] iteration 27230: loss: 0.088914, loss_s1: 0.073152, loss_fp: 0.004594, loss_freq: 0.062937
[07:20:48.502] iteration 27231: loss: 0.069206, loss_s1: 0.059985, loss_fp: 0.003177, loss_freq: 0.049409
[07:20:49.156] iteration 27232: loss: 0.088775, loss_s1: 0.101893, loss_fp: 0.009412, loss_freq: 0.033591
[07:20:49.759] iteration 27233: loss: 0.064025, loss_s1: 0.058430, loss_fp: 0.006412, loss_freq: 0.032902
[07:20:50.452] iteration 27234: loss: 0.048748, loss_s1: 0.039413, loss_fp: 0.007640, loss_freq: 0.017273
[07:20:51.117] iteration 27235: loss: 0.047734, loss_s1: 0.042743, loss_fp: 0.001746, loss_freq: 0.017960
[07:20:51.779] iteration 27236: loss: 0.047306, loss_s1: 0.027551, loss_fp: 0.002347, loss_freq: 0.024650
[07:20:52.391] iteration 27237: loss: 0.064186, loss_s1: 0.053908, loss_fp: 0.001529, loss_freq: 0.039955
[07:20:52.999] iteration 27238: loss: 0.051389, loss_s1: 0.061008, loss_fp: 0.004422, loss_freq: 0.009351
[07:20:53.613] iteration 27239: loss: 0.069555, loss_s1: 0.053254, loss_fp: 0.003208, loss_freq: 0.051687
[07:20:54.220] iteration 27240: loss: 0.094316, loss_s1: 0.139465, loss_fp: 0.002042, loss_freq: 0.023896
[07:20:54.830] iteration 27241: loss: 0.069058, loss_s1: 0.062532, loss_fp: 0.014770, loss_freq: 0.024957
[07:20:55.463] iteration 27242: loss: 0.054103, loss_s1: 0.049569, loss_fp: 0.005365, loss_freq: 0.026400
[07:20:56.070] iteration 27243: loss: 0.075028, loss_s1: 0.088992, loss_fp: 0.003553, loss_freq: 0.036183
[07:20:56.686] iteration 27244: loss: 0.099517, loss_s1: 0.122358, loss_fp: 0.002662, loss_freq: 0.054073
[07:20:57.292] iteration 27245: loss: 0.050805, loss_s1: 0.034433, loss_fp: 0.002780, loss_freq: 0.016065
[07:20:57.905] iteration 27246: loss: 0.056695, loss_s1: 0.050361, loss_fp: 0.006777, loss_freq: 0.021803
[07:20:58.517] iteration 27247: loss: 0.065915, loss_s1: 0.026907, loss_fp: 0.006837, loss_freq: 0.052093
[07:20:59.131] iteration 27248: loss: 0.081786, loss_s1: 0.089819, loss_fp: 0.005979, loss_freq: 0.040388
[07:20:59.743] iteration 27249: loss: 0.033866, loss_s1: 0.027045, loss_fp: 0.001241, loss_freq: 0.013062
[07:21:00.352] iteration 27250: loss: 0.042104, loss_s1: 0.030794, loss_fp: 0.000612, loss_freq: 0.008333
[07:21:00.965] iteration 27251: loss: 0.064523, loss_s1: 0.048223, loss_fp: 0.007332, loss_freq: 0.040724
[07:21:01.577] iteration 27252: loss: 0.048920, loss_s1: 0.058255, loss_fp: 0.003253, loss_freq: 0.015150
[07:21:02.190] iteration 27253: loss: 0.058033, loss_s1: 0.072469, loss_fp: 0.002163, loss_freq: 0.015393
[07:21:02.808] iteration 27254: loss: 0.063861, loss_s1: 0.072146, loss_fp: 0.005776, loss_freq: 0.019427
[07:21:03.432] iteration 27255: loss: 0.049906, loss_s1: 0.020061, loss_fp: 0.008287, loss_freq: 0.034274
[07:21:04.107] iteration 27256: loss: 0.049252, loss_s1: 0.045063, loss_fp: 0.001075, loss_freq: 0.019772
[07:21:04.780] iteration 27257: loss: 0.055561, loss_s1: 0.029816, loss_fp: 0.001568, loss_freq: 0.056961
[07:21:05.403] iteration 27258: loss: 0.036043, loss_s1: 0.019012, loss_fp: 0.009644, loss_freq: 0.009022
[07:21:06.012] iteration 27259: loss: 0.044565, loss_s1: 0.039922, loss_fp: 0.002399, loss_freq: 0.023530
[07:21:06.624] iteration 27260: loss: 0.053398, loss_s1: 0.058705, loss_fp: 0.002141, loss_freq: 0.016737
[07:21:07.244] iteration 27261: loss: 0.034659, loss_s1: 0.009882, loss_fp: 0.002279, loss_freq: 0.006447
[07:21:07.851] iteration 27262: loss: 0.071075, loss_s1: 0.045858, loss_fp: 0.007180, loss_freq: 0.041485
[07:21:08.463] iteration 27263: loss: 0.043424, loss_s1: 0.033579, loss_fp: 0.006165, loss_freq: 0.013745
[07:21:09.073] iteration 27264: loss: 0.051223, loss_s1: 0.042238, loss_fp: 0.005273, loss_freq: 0.029135
[07:21:09.683] iteration 27265: loss: 0.029905, loss_s1: 0.015368, loss_fp: 0.002429, loss_freq: 0.005042
[07:21:10.297] iteration 27266: loss: 0.052428, loss_s1: 0.044631, loss_fp: 0.004192, loss_freq: 0.034212
[07:21:10.915] iteration 27267: loss: 0.037224, loss_s1: 0.026050, loss_fp: 0.001269, loss_freq: 0.010716
[07:21:11.584] iteration 27268: loss: 0.088373, loss_s1: 0.082641, loss_fp: 0.006259, loss_freq: 0.053049
[07:21:12.239] iteration 27269: loss: 0.033580, loss_s1: 0.018310, loss_fp: 0.003284, loss_freq: 0.017128
[07:21:12.872] iteration 27270: loss: 0.057332, loss_s1: 0.056199, loss_fp: 0.002904, loss_freq: 0.037844
[07:21:13.484] iteration 27271: loss: 0.062484, loss_s1: 0.039720, loss_fp: 0.007786, loss_freq: 0.048061
[07:21:14.095] iteration 27272: loss: 0.044995, loss_s1: 0.022755, loss_fp: 0.002759, loss_freq: 0.033020
[07:21:14.723] iteration 27273: loss: 0.048357, loss_s1: 0.037707, loss_fp: 0.005410, loss_freq: 0.028142
[07:21:15.333] iteration 27274: loss: 0.051829, loss_s1: 0.046455, loss_fp: 0.003727, loss_freq: 0.016677
[07:21:15.949] iteration 27275: loss: 0.055676, loss_s1: 0.036898, loss_fp: 0.004962, loss_freq: 0.039557
[07:21:16.575] iteration 27276: loss: 0.083490, loss_s1: 0.049508, loss_fp: 0.012808, loss_freq: 0.072600
[07:21:17.184] iteration 27277: loss: 0.054662, loss_s1: 0.053536, loss_fp: 0.001151, loss_freq: 0.026115
[07:21:17.869] iteration 27278: loss: 0.053825, loss_s1: 0.031243, loss_fp: 0.002622, loss_freq: 0.047892
[07:21:18.550] iteration 27279: loss: 0.066976, loss_s1: 0.063737, loss_fp: 0.007608, loss_freq: 0.042891
[07:21:19.216] iteration 27280: loss: 0.059737, loss_s1: 0.052821, loss_fp: 0.003354, loss_freq: 0.021041
[07:21:19.885] iteration 27281: loss: 0.044448, loss_s1: 0.026669, loss_fp: 0.011236, loss_freq: 0.015584
[07:21:20.548] iteration 27282: loss: 0.056429, loss_s1: 0.050666, loss_fp: 0.004434, loss_freq: 0.029517
[07:21:21.212] iteration 27283: loss: 0.054767, loss_s1: 0.064737, loss_fp: 0.002328, loss_freq: 0.017258
[07:21:21.877] iteration 27284: loss: 0.060206, loss_s1: 0.066171, loss_fp: 0.005482, loss_freq: 0.009211
[07:21:22.497] iteration 27285: loss: 0.047694, loss_s1: 0.026399, loss_fp: 0.004902, loss_freq: 0.032087
[07:21:23.110] iteration 27286: loss: 0.066081, loss_s1: 0.055016, loss_fp: 0.002434, loss_freq: 0.036618
[07:21:23.721] iteration 27287: loss: 0.077380, loss_s1: 0.081967, loss_fp: 0.006158, loss_freq: 0.047593
[07:21:24.335] iteration 27288: loss: 0.064311, loss_s1: 0.055313, loss_fp: 0.003255, loss_freq: 0.034117
[07:21:24.947] iteration 27289: loss: 0.051123, loss_s1: 0.045034, loss_fp: 0.007482, loss_freq: 0.017866
[07:21:25.560] iteration 27290: loss: 0.037496, loss_s1: 0.019616, loss_fp: 0.001399, loss_freq: 0.019398
[07:21:26.168] iteration 27291: loss: 0.070478, loss_s1: 0.077618, loss_fp: 0.001224, loss_freq: 0.035453
[07:21:26.773] iteration 27292: loss: 0.072025, loss_s1: 0.090977, loss_fp: 0.001659, loss_freq: 0.032262
[07:21:27.380] iteration 27293: loss: 0.052955, loss_s1: 0.047633, loss_fp: 0.004004, loss_freq: 0.016816
[07:21:27.989] iteration 27294: loss: 0.043332, loss_s1: 0.050135, loss_fp: 0.002227, loss_freq: 0.012421
[07:21:28.607] iteration 27295: loss: 0.048675, loss_s1: 0.049136, loss_fp: 0.009577, loss_freq: 0.010475
[07:21:29.217] iteration 27296: loss: 0.052807, loss_s1: 0.047317, loss_fp: 0.006794, loss_freq: 0.024996
[07:21:29.829] iteration 27297: loss: 0.062757, loss_s1: 0.059545, loss_fp: 0.002950, loss_freq: 0.029595
[07:21:30.442] iteration 27298: loss: 0.073567, loss_s1: 0.039331, loss_fp: 0.012567, loss_freq: 0.065953
[07:21:31.058] iteration 27299: loss: 0.062281, loss_s1: 0.036193, loss_fp: 0.008276, loss_freq: 0.048835
[07:21:31.671] iteration 27300: loss: 0.050318, loss_s1: 0.026719, loss_fp: 0.003583, loss_freq: 0.034779
[07:21:32.287] iteration 27301: loss: 0.063439, loss_s1: 0.051985, loss_fp: 0.005017, loss_freq: 0.040325
[07:21:32.897] iteration 27302: loss: 0.040446, loss_s1: 0.024435, loss_fp: 0.003704, loss_freq: 0.014197
[07:21:33.520] iteration 27303: loss: 0.043194, loss_s1: 0.036517, loss_fp: 0.005360, loss_freq: 0.022259
[07:21:34.129] iteration 27304: loss: 0.044704, loss_s1: 0.034885, loss_fp: 0.008794, loss_freq: 0.014777
[07:21:34.778] iteration 27305: loss: 0.031060, loss_s1: 0.017575, loss_fp: 0.005771, loss_freq: 0.016156
[07:21:35.585] iteration 27306: loss: 0.058648, loss_s1: 0.064052, loss_fp: 0.002959, loss_freq: 0.018755
[07:21:36.322] iteration 27307: loss: 0.060080, loss_s1: 0.067864, loss_fp: 0.007092, loss_freq: 0.015577
[07:21:36.993] iteration 27308: loss: 0.044949, loss_s1: 0.030128, loss_fp: 0.002907, loss_freq: 0.030078
[07:21:37.698] iteration 27309: loss: 0.043221, loss_s1: 0.015914, loss_fp: 0.010508, loss_freq: 0.032015
[07:21:38.360] iteration 27310: loss: 0.050055, loss_s1: 0.042623, loss_fp: 0.001410, loss_freq: 0.026864
[07:21:39.075] iteration 27311: loss: 0.046011, loss_s1: 0.041225, loss_fp: 0.001899, loss_freq: 0.014758
[07:21:39.783] iteration 27312: loss: 0.054812, loss_s1: 0.035388, loss_fp: 0.004653, loss_freq: 0.034331
[07:21:40.514] iteration 27313: loss: 0.037194, loss_s1: 0.031854, loss_fp: 0.002165, loss_freq: 0.019633
[07:21:41.291] iteration 27314: loss: 0.022147, loss_s1: 0.012008, loss_fp: 0.003344, loss_freq: 0.012610
[07:21:41.977] iteration 27315: loss: 0.084486, loss_s1: 0.078246, loss_fp: 0.003077, loss_freq: 0.055518
[07:21:42.731] iteration 27316: loss: 0.050007, loss_s1: 0.029819, loss_fp: 0.006151, loss_freq: 0.027362
[07:21:43.349] iteration 27317: loss: 0.078193, loss_s1: 0.079746, loss_fp: 0.001324, loss_freq: 0.040565
[07:21:43.985] iteration 27318: loss: 0.064968, loss_s1: 0.056599, loss_fp: 0.005647, loss_freq: 0.041463
[07:21:44.639] iteration 27319: loss: 0.074436, loss_s1: 0.066261, loss_fp: 0.003835, loss_freq: 0.054492
[07:21:45.361] iteration 27320: loss: 0.046606, loss_s1: 0.021281, loss_fp: 0.003462, loss_freq: 0.029790
[07:21:46.049] iteration 27321: loss: 0.052653, loss_s1: 0.063618, loss_fp: 0.001058, loss_freq: 0.008016
[07:21:46.673] iteration 27322: loss: 0.087281, loss_s1: 0.105689, loss_fp: 0.003882, loss_freq: 0.046021
[07:21:47.304] iteration 27323: loss: 0.086551, loss_s1: 0.084537, loss_fp: 0.004490, loss_freq: 0.054133
[07:21:47.916] iteration 27324: loss: 0.046382, loss_s1: 0.041394, loss_fp: 0.011602, loss_freq: 0.012904
[07:21:48.524] iteration 27325: loss: 0.063699, loss_s1: 0.052490, loss_fp: 0.005286, loss_freq: 0.041369
[07:21:49.137] iteration 27326: loss: 0.038489, loss_s1: 0.024055, loss_fp: 0.006192, loss_freq: 0.019072
[07:21:49.746] iteration 27327: loss: 0.044847, loss_s1: 0.033976, loss_fp: 0.001130, loss_freq: 0.026734
[07:21:50.385] iteration 27328: loss: 0.038771, loss_s1: 0.028092, loss_fp: 0.001431, loss_freq: 0.010984
[07:21:50.997] iteration 27329: loss: 0.053243, loss_s1: 0.044032, loss_fp: 0.012534, loss_freq: 0.029853
[07:21:51.609] iteration 27330: loss: 0.083393, loss_s1: 0.065309, loss_fp: 0.007885, loss_freq: 0.051007
[07:21:52.222] iteration 27331: loss: 0.062899, loss_s1: 0.075673, loss_fp: 0.002539, loss_freq: 0.018643
[07:21:52.837] iteration 27332: loss: 0.061656, loss_s1: 0.039158, loss_fp: 0.006063, loss_freq: 0.034612
[07:21:53.454] iteration 27333: loss: 0.057099, loss_s1: 0.054431, loss_fp: 0.007460, loss_freq: 0.019578
[07:21:54.069] iteration 27334: loss: 0.050145, loss_s1: 0.046737, loss_fp: 0.001964, loss_freq: 0.025227
[07:21:54.686] iteration 27335: loss: 0.055803, loss_s1: 0.032367, loss_fp: 0.004124, loss_freq: 0.042590
[07:21:55.302] iteration 27336: loss: 0.038922, loss_s1: 0.037469, loss_fp: 0.003505, loss_freq: 0.012242
[07:21:55.909] iteration 27337: loss: 0.062205, loss_s1: 0.061906, loss_fp: 0.005740, loss_freq: 0.019058
[07:21:56.567] iteration 27338: loss: 0.058661, loss_s1: 0.050172, loss_fp: 0.003843, loss_freq: 0.035218
[07:21:57.183] iteration 27339: loss: 0.059298, loss_s1: 0.045388, loss_fp: 0.004351, loss_freq: 0.035023
[07:21:57.795] iteration 27340: loss: 0.111291, loss_s1: 0.158180, loss_fp: 0.003325, loss_freq: 0.040766
[07:21:58.412] iteration 27341: loss: 0.045573, loss_s1: 0.032626, loss_fp: 0.005912, loss_freq: 0.017579
[07:21:59.029] iteration 27342: loss: 0.051589, loss_s1: 0.037762, loss_fp: 0.002600, loss_freq: 0.029075
[07:21:59.650] iteration 27343: loss: 0.042310, loss_s1: 0.036054, loss_fp: 0.003806, loss_freq: 0.018527
[07:22:00.269] iteration 27344: loss: 0.055037, loss_s1: 0.029505, loss_fp: 0.009933, loss_freq: 0.041011
[07:22:00.888] iteration 27345: loss: 0.036121, loss_s1: 0.019479, loss_fp: 0.002324, loss_freq: 0.017009
[07:22:01.505] iteration 27346: loss: 0.057786, loss_s1: 0.027126, loss_fp: 0.015885, loss_freq: 0.034458
[07:22:02.255] iteration 27347: loss: 0.044721, loss_s1: 0.031254, loss_fp: 0.002753, loss_freq: 0.024735
[07:22:03.148] iteration 27348: loss: 0.053471, loss_s1: 0.056386, loss_fp: 0.002910, loss_freq: 0.024300
[07:22:04.025] iteration 27349: loss: 0.051549, loss_s1: 0.037502, loss_fp: 0.003169, loss_freq: 0.043700
[07:22:04.686] iteration 27350: loss: 0.060432, loss_s1: 0.037073, loss_fp: 0.007286, loss_freq: 0.041248
[07:22:05.351] iteration 27351: loss: 0.047575, loss_s1: 0.036141, loss_fp: 0.009130, loss_freq: 0.018810
[07:22:05.967] iteration 27352: loss: 0.088367, loss_s1: 0.109687, loss_fp: 0.004975, loss_freq: 0.034223
[07:22:06.580] iteration 27353: loss: 0.054088, loss_s1: 0.040878, loss_fp: 0.007545, loss_freq: 0.031174
[07:22:07.189] iteration 27354: loss: 0.069328, loss_s1: 0.077386, loss_fp: 0.006605, loss_freq: 0.027618
[07:22:07.794] iteration 27355: loss: 0.060034, loss_s1: 0.041617, loss_fp: 0.007667, loss_freq: 0.033988
[07:22:08.401] iteration 27356: loss: 0.027660, loss_s1: 0.017163, loss_fp: 0.001671, loss_freq: 0.009624
[07:22:09.060] iteration 27357: loss: 0.037415, loss_s1: 0.041898, loss_fp: 0.003111, loss_freq: 0.008794
[07:22:09.666] iteration 27358: loss: 0.068274, loss_s1: 0.074417, loss_fp: 0.002049, loss_freq: 0.033242
[07:22:10.279] iteration 27359: loss: 0.049096, loss_s1: 0.030533, loss_fp: 0.006822, loss_freq: 0.030237
[07:22:10.891] iteration 27360: loss: 0.097071, loss_s1: 0.090854, loss_fp: 0.007006, loss_freq: 0.057381
[07:22:11.501] iteration 27361: loss: 0.068132, loss_s1: 0.098651, loss_fp: 0.002971, loss_freq: 0.004587
[07:22:12.109] iteration 27362: loss: 0.072862, loss_s1: 0.064586, loss_fp: 0.017446, loss_freq: 0.039446
[07:22:12.716] iteration 27363: loss: 0.032718, loss_s1: 0.019661, loss_fp: 0.000618, loss_freq: 0.009248
[07:22:13.328] iteration 27364: loss: 0.051749, loss_s1: 0.042987, loss_fp: 0.004824, loss_freq: 0.027143
[07:22:13.940] iteration 27365: loss: 0.033704, loss_s1: 0.021194, loss_fp: 0.000807, loss_freq: 0.011413
[07:22:14.550] iteration 27366: loss: 0.072637, loss_s1: 0.094655, loss_fp: 0.009652, loss_freq: 0.021372
[07:22:15.158] iteration 27367: loss: 0.074460, loss_s1: 0.076306, loss_fp: 0.006380, loss_freq: 0.024845
[07:22:15.764] iteration 27368: loss: 0.056173, loss_s1: 0.058376, loss_fp: 0.002514, loss_freq: 0.021216
[07:22:16.366] iteration 27369: loss: 0.086173, loss_s1: 0.072501, loss_fp: 0.007408, loss_freq: 0.063225
[07:22:16.971] iteration 27370: loss: 0.050428, loss_s1: 0.047322, loss_fp: 0.014824, loss_freq: 0.006556
[07:22:17.895] iteration 27371: loss: 0.058670, loss_s1: 0.053692, loss_fp: 0.004571, loss_freq: 0.028048
[07:22:18.554] iteration 27372: loss: 0.063667, loss_s1: 0.062455, loss_fp: 0.003338, loss_freq: 0.032108
[07:22:19.206] iteration 27373: loss: 0.075419, loss_s1: 0.091141, loss_fp: 0.007957, loss_freq: 0.027351
[07:22:19.869] iteration 27374: loss: 0.062725, loss_s1: 0.060859, loss_fp: 0.001619, loss_freq: 0.033420
[07:22:20.539] iteration 27375: loss: 0.045301, loss_s1: 0.034884, loss_fp: 0.005414, loss_freq: 0.016414
[07:22:21.205] iteration 27376: loss: 0.071212, loss_s1: 0.069417, loss_fp: 0.001428, loss_freq: 0.033606
[07:22:21.881] iteration 27377: loss: 0.047599, loss_s1: 0.028980, loss_fp: 0.002803, loss_freq: 0.033509
[07:22:22.538] iteration 27378: loss: 0.038610, loss_s1: 0.031077, loss_fp: 0.002600, loss_freq: 0.015730
[07:22:23.195] iteration 27379: loss: 0.039328, loss_s1: 0.025456, loss_fp: 0.005194, loss_freq: 0.012965
[07:22:23.855] iteration 27380: loss: 0.059133, loss_s1: 0.039077, loss_fp: 0.009547, loss_freq: 0.027759
[07:22:24.505] iteration 27381: loss: 0.047608, loss_s1: 0.026917, loss_fp: 0.003018, loss_freq: 0.038208
[07:22:25.115] iteration 27382: loss: 0.065762, loss_s1: 0.060893, loss_fp: 0.002036, loss_freq: 0.039472
[07:22:25.727] iteration 27383: loss: 0.035326, loss_s1: 0.030778, loss_fp: 0.001549, loss_freq: 0.013164
[07:22:26.346] iteration 27384: loss: 0.063743, loss_s1: 0.065374, loss_fp: 0.004994, loss_freq: 0.027051
[07:22:26.954] iteration 27385: loss: 0.042272, loss_s1: 0.028322, loss_fp: 0.002636, loss_freq: 0.022231
[07:22:27.568] iteration 27386: loss: 0.035498, loss_s1: 0.027406, loss_fp: 0.001649, loss_freq: 0.008033
[07:22:28.186] iteration 27387: loss: 0.145752, loss_s1: 0.126661, loss_fp: 0.006085, loss_freq: 0.141186
[07:22:28.807] iteration 27388: loss: 0.044588, loss_s1: 0.024275, loss_fp: 0.002848, loss_freq: 0.015744
[07:22:29.423] iteration 27389: loss: 0.089862, loss_s1: 0.091971, loss_fp: 0.014109, loss_freq: 0.045885
[07:22:30.047] iteration 27390: loss: 0.051089, loss_s1: 0.044558, loss_fp: 0.005571, loss_freq: 0.017716
[07:22:30.661] iteration 27391: loss: 0.062166, loss_s1: 0.053176, loss_fp: 0.005538, loss_freq: 0.032139
[07:22:31.291] iteration 27392: loss: 0.040509, loss_s1: 0.025870, loss_fp: 0.005322, loss_freq: 0.030752
[07:22:31.901] iteration 27393: loss: 0.052581, loss_s1: 0.039636, loss_fp: 0.002300, loss_freq: 0.024998
[07:22:32.516] iteration 27394: loss: 0.057244, loss_s1: 0.046564, loss_fp: 0.002954, loss_freq: 0.029166
[07:22:33.130] iteration 27395: loss: 0.095656, loss_s1: 0.129702, loss_fp: 0.002610, loss_freq: 0.032951
[07:22:33.742] iteration 27396: loss: 0.049600, loss_s1: 0.038958, loss_fp: 0.012180, loss_freq: 0.026530
[07:22:34.355] iteration 27397: loss: 0.045903, loss_s1: 0.020225, loss_fp: 0.003413, loss_freq: 0.017854
[07:22:34.994] iteration 27398: loss: 0.113927, loss_s1: 0.140171, loss_fp: 0.003699, loss_freq: 0.039353
[07:22:35.600] iteration 27399: loss: 0.036227, loss_s1: 0.027665, loss_fp: 0.000979, loss_freq: 0.014764
[07:22:36.206] iteration 27400: loss: 0.090368, loss_s1: 0.115168, loss_fp: 0.010509, loss_freq: 0.026601
[07:22:39.779] iteration 27400 : mean_dice : 0.740811
[07:22:40.441] iteration 27401: loss: 0.054488, loss_s1: 0.037143, loss_fp: 0.004742, loss_freq: 0.049013
[07:22:41.050] iteration 27402: loss: 0.052865, loss_s1: 0.035453, loss_fp: 0.003135, loss_freq: 0.028034
[07:22:41.707] iteration 27403: loss: 0.064615, loss_s1: 0.051181, loss_fp: 0.009686, loss_freq: 0.039009
[07:22:42.380] iteration 27404: loss: 0.051724, loss_s1: 0.030881, loss_fp: 0.004271, loss_freq: 0.027970
[07:22:43.005] iteration 27405: loss: 0.059943, loss_s1: 0.062419, loss_fp: 0.002904, loss_freq: 0.033843
[07:22:43.625] iteration 27406: loss: 0.047744, loss_s1: 0.023221, loss_fp: 0.003440, loss_freq: 0.016430
[07:22:44.286] iteration 27407: loss: 0.047350, loss_s1: 0.033130, loss_fp: 0.002027, loss_freq: 0.027395
[07:22:44.908] iteration 27408: loss: 0.038086, loss_s1: 0.033456, loss_fp: 0.005204, loss_freq: 0.011379
[07:22:45.525] iteration 27409: loss: 0.074022, loss_s1: 0.061242, loss_fp: 0.005882, loss_freq: 0.033070
[07:22:46.139] iteration 27410: loss: 0.079422, loss_s1: 0.093875, loss_fp: 0.004448, loss_freq: 0.028218
[07:22:46.764] iteration 27411: loss: 0.066151, loss_s1: 0.045418, loss_fp: 0.001449, loss_freq: 0.056799
[07:22:47.376] iteration 27412: loss: 0.061175, loss_s1: 0.034120, loss_fp: 0.007818, loss_freq: 0.026485
[07:22:47.985] iteration 27413: loss: 0.104698, loss_s1: 0.135969, loss_fp: 0.014174, loss_freq: 0.035989
[07:22:48.594] iteration 27414: loss: 0.086446, loss_s1: 0.063184, loss_fp: 0.008368, loss_freq: 0.080349
[07:22:49.206] iteration 27415: loss: 0.042182, loss_s1: 0.028256, loss_fp: 0.001314, loss_freq: 0.013397
[07:22:49.889] iteration 27416: loss: 0.108782, loss_s1: 0.113152, loss_fp: 0.011945, loss_freq: 0.055369
[07:22:50.694] iteration 27417: loss: 0.048742, loss_s1: 0.036372, loss_fp: 0.003690, loss_freq: 0.030437
[07:22:51.364] iteration 27418: loss: 0.052734, loss_s1: 0.047448, loss_fp: 0.010350, loss_freq: 0.017154
[07:22:52.146] iteration 27419: loss: 0.029096, loss_s1: 0.010223, loss_fp: 0.002582, loss_freq: 0.012790
[07:22:52.791] iteration 27420: loss: 0.063268, loss_s1: 0.062730, loss_fp: 0.000895, loss_freq: 0.011481
[07:22:53.470] iteration 27421: loss: 0.046217, loss_s1: 0.043584, loss_fp: 0.001824, loss_freq: 0.017187
[07:22:54.123] iteration 27422: loss: 0.035509, loss_s1: 0.034364, loss_fp: 0.002031, loss_freq: 0.013023
[07:22:54.780] iteration 27423: loss: 0.031316, loss_s1: 0.009550, loss_fp: 0.001665, loss_freq: 0.021248
[07:22:55.417] iteration 27424: loss: 0.042221, loss_s1: 0.037105, loss_fp: 0.007466, loss_freq: 0.014707
[07:22:56.029] iteration 27425: loss: 0.062471, loss_s1: 0.023228, loss_fp: 0.002860, loss_freq: 0.065950
[07:22:56.636] iteration 27426: loss: 0.040386, loss_s1: 0.023283, loss_fp: 0.001489, loss_freq: 0.024415
[07:22:57.248] iteration 27427: loss: 0.050750, loss_s1: 0.036008, loss_fp: 0.005794, loss_freq: 0.033493
[07:22:57.861] iteration 27428: loss: 0.046557, loss_s1: 0.033686, loss_fp: 0.006350, loss_freq: 0.012351
[07:22:58.508] iteration 27429: loss: 0.036384, loss_s1: 0.021281, loss_fp: 0.001940, loss_freq: 0.020596
[07:22:59.125] iteration 27430: loss: 0.041618, loss_s1: 0.026826, loss_fp: 0.003254, loss_freq: 0.028140
[07:22:59.752] iteration 27431: loss: 0.020713, loss_s1: 0.007933, loss_fp: 0.002682, loss_freq: 0.004141
[07:23:00.425] iteration 27432: loss: 0.061594, loss_s1: 0.050976, loss_fp: 0.004730, loss_freq: 0.034704
[07:23:01.085] iteration 27433: loss: 0.038636, loss_s1: 0.033904, loss_fp: 0.003930, loss_freq: 0.010490
[07:23:01.780] iteration 27434: loss: 0.061370, loss_s1: 0.058339, loss_fp: 0.002670, loss_freq: 0.036987
[07:23:02.444] iteration 27435: loss: 0.031694, loss_s1: 0.015613, loss_fp: 0.002370, loss_freq: 0.011108
[07:23:03.071] iteration 27436: loss: 0.050075, loss_s1: 0.057304, loss_fp: 0.001509, loss_freq: 0.022982
[07:23:03.709] iteration 27437: loss: 0.030713, loss_s1: 0.014886, loss_fp: 0.002014, loss_freq: 0.010726
[07:23:04.329] iteration 27438: loss: 0.063286, loss_s1: 0.059188, loss_fp: 0.004816, loss_freq: 0.034249
[07:23:04.949] iteration 27439: loss: 0.037828, loss_s1: 0.017662, loss_fp: 0.002297, loss_freq: 0.019113
[07:23:05.561] iteration 27440: loss: 0.039967, loss_s1: 0.046771, loss_fp: 0.002759, loss_freq: 0.009254
[07:23:06.170] iteration 27441: loss: 0.082644, loss_s1: 0.082337, loss_fp: 0.009015, loss_freq: 0.043434
[07:23:06.783] iteration 27442: loss: 0.042998, loss_s1: 0.029528, loss_fp: 0.005506, loss_freq: 0.018397
[07:23:07.419] iteration 27443: loss: 0.074599, loss_s1: 0.057580, loss_fp: 0.008274, loss_freq: 0.056989
[07:23:08.029] iteration 27444: loss: 0.068058, loss_s1: 0.078208, loss_fp: 0.003216, loss_freq: 0.023637
[07:23:08.638] iteration 27445: loss: 0.061991, loss_s1: 0.021802, loss_fp: 0.009904, loss_freq: 0.058704
[07:23:09.247] iteration 27446: loss: 0.072340, loss_s1: 0.061281, loss_fp: 0.008399, loss_freq: 0.041074
[07:23:09.861] iteration 27447: loss: 0.063156, loss_s1: 0.063462, loss_fp: 0.003198, loss_freq: 0.024019
[07:23:10.477] iteration 27448: loss: 0.065712, loss_s1: 0.034641, loss_fp: 0.011812, loss_freq: 0.058778
[07:23:11.084] iteration 27449: loss: 0.043537, loss_s1: 0.023261, loss_fp: 0.016624, loss_freq: 0.024704
[07:23:11.695] iteration 27450: loss: 0.072305, loss_s1: 0.055352, loss_fp: 0.007350, loss_freq: 0.041983
[07:23:12.303] iteration 27451: loss: 0.053903, loss_s1: 0.045772, loss_fp: 0.002338, loss_freq: 0.027394
[07:23:12.916] iteration 27452: loss: 0.079821, loss_s1: 0.072897, loss_fp: 0.004705, loss_freq: 0.051841
[07:23:13.536] iteration 27453: loss: 0.047896, loss_s1: 0.048066, loss_fp: 0.002900, loss_freq: 0.016685
[07:23:14.150] iteration 27454: loss: 0.030156, loss_s1: 0.011805, loss_fp: 0.002249, loss_freq: 0.017054
[07:23:14.765] iteration 27455: loss: 0.057814, loss_s1: 0.046398, loss_fp: 0.002426, loss_freq: 0.029940
[07:23:15.376] iteration 27456: loss: 0.051395, loss_s1: 0.042188, loss_fp: 0.011651, loss_freq: 0.018133
[07:23:15.989] iteration 27457: loss: 0.047534, loss_s1: 0.032026, loss_fp: 0.004442, loss_freq: 0.041018
[07:23:16.641] iteration 27458: loss: 0.058497, loss_s1: 0.063393, loss_fp: 0.003519, loss_freq: 0.019744
[07:23:17.299] iteration 27459: loss: 0.072966, loss_s1: 0.085603, loss_fp: 0.002616, loss_freq: 0.028512
[07:23:17.959] iteration 27460: loss: 0.041445, loss_s1: 0.031562, loss_fp: 0.002152, loss_freq: 0.017612
[07:23:18.616] iteration 27461: loss: 0.070366, loss_s1: 0.079462, loss_fp: 0.001996, loss_freq: 0.025195
[07:23:19.276] iteration 27462: loss: 0.063717, loss_s1: 0.067143, loss_fp: 0.020113, loss_freq: 0.020033
[07:23:19.889] iteration 27463: loss: 0.071149, loss_s1: 0.057686, loss_fp: 0.004592, loss_freq: 0.044468
[07:23:20.522] iteration 27464: loss: 0.062740, loss_s1: 0.051244, loss_fp: 0.006339, loss_freq: 0.044365
[07:23:21.131] iteration 27465: loss: 0.055936, loss_s1: 0.054554, loss_fp: 0.005890, loss_freq: 0.022564
[07:23:21.746] iteration 27466: loss: 0.045856, loss_s1: 0.036777, loss_fp: 0.006206, loss_freq: 0.024975
[07:23:22.359] iteration 27467: loss: 0.103041, loss_s1: 0.089371, loss_fp: 0.008854, loss_freq: 0.053870
[07:23:22.984] iteration 27468: loss: 0.082932, loss_s1: 0.056995, loss_fp: 0.003785, loss_freq: 0.063249
[07:23:23.598] iteration 27469: loss: 0.042768, loss_s1: 0.033398, loss_fp: 0.008418, loss_freq: 0.020281
[07:23:24.215] iteration 27470: loss: 0.052625, loss_s1: 0.050326, loss_fp: 0.002655, loss_freq: 0.019191
[07:23:24.824] iteration 27471: loss: 0.049482, loss_s1: 0.030505, loss_fp: 0.002519, loss_freq: 0.043719
[07:23:25.434] iteration 27472: loss: 0.056155, loss_s1: 0.066061, loss_fp: 0.004467, loss_freq: 0.007312
[07:23:26.042] iteration 27473: loss: 0.043360, loss_s1: 0.028604, loss_fp: 0.007533, loss_freq: 0.020205
[07:23:26.651] iteration 27474: loss: 0.052279, loss_s1: 0.031005, loss_fp: 0.002681, loss_freq: 0.042700
[07:23:27.260] iteration 27475: loss: 0.032789, loss_s1: 0.023394, loss_fp: 0.002400, loss_freq: 0.018987
[07:23:27.876] iteration 27476: loss: 0.079018, loss_s1: 0.071231, loss_fp: 0.006131, loss_freq: 0.040530
[07:23:28.486] iteration 27477: loss: 0.033969, loss_s1: 0.019816, loss_fp: 0.001903, loss_freq: 0.013573
[07:23:29.098] iteration 27478: loss: 0.032079, loss_s1: 0.023668, loss_fp: 0.003284, loss_freq: 0.013580
[07:23:29.719] iteration 27479: loss: 0.061160, loss_s1: 0.034655, loss_fp: 0.007246, loss_freq: 0.045117
[07:23:30.328] iteration 27480: loss: 0.065400, loss_s1: 0.053394, loss_fp: 0.005144, loss_freq: 0.034684
[07:23:30.941] iteration 27481: loss: 0.045659, loss_s1: 0.038559, loss_fp: 0.005603, loss_freq: 0.015710
[07:23:31.561] iteration 27482: loss: 0.032981, loss_s1: 0.026244, loss_fp: 0.004400, loss_freq: 0.006917
[07:23:32.172] iteration 27483: loss: 0.045831, loss_s1: 0.032479, loss_fp: 0.007590, loss_freq: 0.023959
[07:23:32.781] iteration 27484: loss: 0.029694, loss_s1: 0.015827, loss_fp: 0.001303, loss_freq: 0.022700
[07:23:33.400] iteration 27485: loss: 0.060163, loss_s1: 0.053733, loss_fp: 0.005358, loss_freq: 0.028993
[07:23:34.020] iteration 27486: loss: 0.062693, loss_s1: 0.062402, loss_fp: 0.003802, loss_freq: 0.029003
[07:23:34.634] iteration 27487: loss: 0.046478, loss_s1: 0.036435, loss_fp: 0.002888, loss_freq: 0.019834
[07:23:35.237] iteration 27488: loss: 0.035018, loss_s1: 0.022550, loss_fp: 0.005467, loss_freq: 0.012417
[07:23:35.851] iteration 27489: loss: 0.052230, loss_s1: 0.025284, loss_fp: 0.006622, loss_freq: 0.041864
[07:23:36.459] iteration 27490: loss: 0.059417, loss_s1: 0.068544, loss_fp: 0.005100, loss_freq: 0.008530
[07:23:37.067] iteration 27491: loss: 0.033851, loss_s1: 0.015209, loss_fp: 0.002461, loss_freq: 0.012317
[07:23:37.757] iteration 27492: loss: 0.103414, loss_s1: 0.121395, loss_fp: 0.005622, loss_freq: 0.058648
[07:23:38.423] iteration 27493: loss: 0.063624, loss_s1: 0.026463, loss_fp: 0.005892, loss_freq: 0.066175
[07:23:39.086] iteration 27494: loss: 0.073608, loss_s1: 0.056047, loss_fp: 0.004526, loss_freq: 0.058075
[07:23:39.739] iteration 27495: loss: 0.062490, loss_s1: 0.048883, loss_fp: 0.006740, loss_freq: 0.030932
[07:23:40.397] iteration 27496: loss: 0.044856, loss_s1: 0.037382, loss_fp: 0.004459, loss_freq: 0.015538
[07:23:41.056] iteration 27497: loss: 0.067490, loss_s1: 0.057325, loss_fp: 0.002901, loss_freq: 0.056007
[07:23:41.668] iteration 27498: loss: 0.049040, loss_s1: 0.044356, loss_fp: 0.001172, loss_freq: 0.013733
[07:23:42.276] iteration 27499: loss: 0.045934, loss_s1: 0.028906, loss_fp: 0.002573, loss_freq: 0.032772
[07:23:42.891] iteration 27500: loss: 0.102132, loss_s1: 0.097648, loss_fp: 0.009119, loss_freq: 0.065680
[07:23:43.498] iteration 27501: loss: 0.039162, loss_s1: 0.044514, loss_fp: 0.003548, loss_freq: 0.007998
[07:23:44.112] iteration 27502: loss: 0.047068, loss_s1: 0.036372, loss_fp: 0.002683, loss_freq: 0.014196
[07:23:44.721] iteration 27503: loss: 0.066361, loss_s1: 0.069975, loss_fp: 0.005299, loss_freq: 0.025881
[07:23:45.323] iteration 27504: loss: 0.040023, loss_s1: 0.038983, loss_fp: 0.004885, loss_freq: 0.012462
[07:23:45.932] iteration 27505: loss: 0.039421, loss_s1: 0.026858, loss_fp: 0.001730, loss_freq: 0.018969
[07:23:46.541] iteration 27506: loss: 0.027094, loss_s1: 0.022046, loss_fp: 0.001540, loss_freq: 0.009071
[07:23:47.162] iteration 27507: loss: 0.059837, loss_s1: 0.056918, loss_fp: 0.005834, loss_freq: 0.017076
[07:23:47.764] iteration 27508: loss: 0.056895, loss_s1: 0.046459, loss_fp: 0.008283, loss_freq: 0.027215
[07:23:48.368] iteration 27509: loss: 0.089350, loss_s1: 0.104234, loss_fp: 0.006356, loss_freq: 0.043751
[07:23:48.976] iteration 27510: loss: 0.045327, loss_s1: 0.047294, loss_fp: 0.004269, loss_freq: 0.018369
[07:23:49.588] iteration 27511: loss: 0.061748, loss_s1: 0.046970, loss_fp: 0.002459, loss_freq: 0.031993
[07:23:50.200] iteration 27512: loss: 0.049942, loss_s1: 0.040737, loss_fp: 0.002411, loss_freq: 0.024920
[07:23:50.805] iteration 27513: loss: 0.034408, loss_s1: 0.028437, loss_fp: 0.002514, loss_freq: 0.015658
[07:23:51.413] iteration 27514: loss: 0.050767, loss_s1: 0.041394, loss_fp: 0.004600, loss_freq: 0.024983
[07:23:52.072] iteration 27515: loss: 0.026347, loss_s1: 0.018486, loss_fp: 0.003734, loss_freq: 0.007250
[07:23:52.736] iteration 27516: loss: 0.065940, loss_s1: 0.055722, loss_fp: 0.003995, loss_freq: 0.034432
[07:23:53.391] iteration 27517: loss: 0.047785, loss_s1: 0.020018, loss_fp: 0.003001, loss_freq: 0.034983
[07:23:54.033] iteration 27518: loss: 0.102845, loss_s1: 0.118793, loss_fp: 0.006866, loss_freq: 0.056538
[07:23:54.640] iteration 27519: loss: 0.056005, loss_s1: 0.051556, loss_fp: 0.006702, loss_freq: 0.031801
[07:23:55.264] iteration 27520: loss: 0.043572, loss_s1: 0.036649, loss_fp: 0.003211, loss_freq: 0.014685
[07:23:55.876] iteration 27521: loss: 0.082099, loss_s1: 0.078437, loss_fp: 0.011630, loss_freq: 0.037652
[07:23:56.485] iteration 27522: loss: 0.052249, loss_s1: 0.035074, loss_fp: 0.004564, loss_freq: 0.036104
[07:23:57.093] iteration 27523: loss: 0.049449, loss_s1: 0.054907, loss_fp: 0.002479, loss_freq: 0.012828
[07:23:57.703] iteration 27524: loss: 0.098558, loss_s1: 0.133831, loss_fp: 0.005684, loss_freq: 0.032326
[07:23:58.314] iteration 27525: loss: 0.069924, loss_s1: 0.074786, loss_fp: 0.003342, loss_freq: 0.026929
[07:23:58.922] iteration 27526: loss: 0.029208, loss_s1: 0.020800, loss_fp: 0.001534, loss_freq: 0.005323
[07:23:59.531] iteration 27527: loss: 0.033187, loss_s1: 0.024939, loss_fp: 0.003009, loss_freq: 0.009750
[07:24:00.140] iteration 27528: loss: 0.094882, loss_s1: 0.076704, loss_fp: 0.006770, loss_freq: 0.071103
[07:24:00.774] iteration 27529: loss: 0.051168, loss_s1: 0.040524, loss_fp: 0.003713, loss_freq: 0.027977
[07:24:01.386] iteration 27530: loss: 0.078551, loss_s1: 0.083876, loss_fp: 0.004648, loss_freq: 0.035777
[07:24:01.997] iteration 27531: loss: 0.035688, loss_s1: 0.024504, loss_fp: 0.004616, loss_freq: 0.008500
[07:24:02.606] iteration 27532: loss: 0.049704, loss_s1: 0.030100, loss_fp: 0.009890, loss_freq: 0.030843
[07:24:03.212] iteration 27533: loss: 0.033789, loss_s1: 0.014599, loss_fp: 0.003321, loss_freq: 0.010541
[07:24:03.819] iteration 27534: loss: 0.043677, loss_s1: 0.038052, loss_fp: 0.003920, loss_freq: 0.021256
[07:24:04.419] iteration 27535: loss: 0.046463, loss_s1: 0.044153, loss_fp: 0.005514, loss_freq: 0.014668
[07:24:05.019] iteration 27536: loss: 0.073072, loss_s1: 0.067778, loss_fp: 0.005020, loss_freq: 0.051997
[07:24:05.624] iteration 27537: loss: 0.058519, loss_s1: 0.060327, loss_fp: 0.004344, loss_freq: 0.020762
[07:24:06.303] iteration 27538: loss: 0.054545, loss_s1: 0.051955, loss_fp: 0.002264, loss_freq: 0.022238
[07:24:06.898] iteration 27539: loss: 0.059026, loss_s1: 0.059437, loss_fp: 0.001715, loss_freq: 0.034906
[07:24:07.501] iteration 27540: loss: 0.055836, loss_s1: 0.042854, loss_fp: 0.007554, loss_freq: 0.024375
[07:24:08.444] iteration 27541: loss: 0.033285, loss_s1: 0.016623, loss_fp: 0.001438, loss_freq: 0.020372
[07:24:09.118] iteration 27542: loss: 0.067562, loss_s1: 0.070046, loss_fp: 0.007555, loss_freq: 0.025604
[07:24:09.786] iteration 27543: loss: 0.053302, loss_s1: 0.044381, loss_fp: 0.004831, loss_freq: 0.034832
[07:24:10.458] iteration 27544: loss: 0.053813, loss_s1: 0.052853, loss_fp: 0.002313, loss_freq: 0.023202
[07:24:11.117] iteration 27545: loss: 0.042302, loss_s1: 0.021007, loss_fp: 0.002575, loss_freq: 0.038207
[07:24:11.742] iteration 27546: loss: 0.081242, loss_s1: 0.064237, loss_fp: 0.008160, loss_freq: 0.060230
[07:24:12.367] iteration 27547: loss: 0.050799, loss_s1: 0.035489, loss_fp: 0.007116, loss_freq: 0.033981
[07:24:13.030] iteration 27548: loss: 0.037454, loss_s1: 0.037524, loss_fp: 0.003432, loss_freq: 0.013644
[07:24:13.683] iteration 27549: loss: 0.056437, loss_s1: 0.046539, loss_fp: 0.005488, loss_freq: 0.041694
[07:24:14.338] iteration 27550: loss: 0.069591, loss_s1: 0.074339, loss_fp: 0.006742, loss_freq: 0.027801
[07:24:14.955] iteration 27551: loss: 0.053087, loss_s1: 0.029654, loss_fp: 0.004139, loss_freq: 0.045399
[07:24:15.621] iteration 27552: loss: 0.046278, loss_s1: 0.041273, loss_fp: 0.003046, loss_freq: 0.016914
[07:24:16.316] iteration 27553: loss: 0.052421, loss_s1: 0.038106, loss_fp: 0.009612, loss_freq: 0.023233
[07:24:16.946] iteration 27554: loss: 0.054052, loss_s1: 0.052902, loss_fp: 0.008501, loss_freq: 0.017795
[07:24:17.593] iteration 27555: loss: 0.077239, loss_s1: 0.064088, loss_fp: 0.016508, loss_freq: 0.029315
[07:24:18.249] iteration 27556: loss: 0.063412, loss_s1: 0.051736, loss_fp: 0.015906, loss_freq: 0.028463
[07:24:18.905] iteration 27557: loss: 0.070092, loss_s1: 0.063015, loss_fp: 0.007360, loss_freq: 0.050169
[07:24:19.559] iteration 27558: loss: 0.045765, loss_s1: 0.026580, loss_fp: 0.002881, loss_freq: 0.031279
[07:24:20.218] iteration 27559: loss: 0.080127, loss_s1: 0.090572, loss_fp: 0.011601, loss_freq: 0.028934
[07:24:20.875] iteration 27560: loss: 0.052855, loss_s1: 0.062903, loss_fp: 0.002300, loss_freq: 0.011824
[07:24:21.530] iteration 27561: loss: 0.060498, loss_s1: 0.041480, loss_fp: 0.003504, loss_freq: 0.040843
[07:24:22.137] iteration 27562: loss: 0.048540, loss_s1: 0.053264, loss_fp: 0.003877, loss_freq: 0.019701
[07:24:22.756] iteration 27563: loss: 0.055672, loss_s1: 0.031663, loss_fp: 0.002147, loss_freq: 0.040795
[07:24:23.369] iteration 27564: loss: 0.045563, loss_s1: 0.039529, loss_fp: 0.002783, loss_freq: 0.024041
[07:24:23.972] iteration 27565: loss: 0.058929, loss_s1: 0.026958, loss_fp: 0.003101, loss_freq: 0.052570
[07:24:24.580] iteration 27566: loss: 0.049601, loss_s1: 0.050353, loss_fp: 0.001924, loss_freq: 0.026841
[07:24:25.183] iteration 27567: loss: 0.058790, loss_s1: 0.061538, loss_fp: 0.003033, loss_freq: 0.021248
[07:24:25.789] iteration 27568: loss: 0.097885, loss_s1: 0.118252, loss_fp: 0.013647, loss_freq: 0.033789
[07:24:26.394] iteration 27569: loss: 0.043690, loss_s1: 0.027575, loss_fp: 0.007252, loss_freq: 0.027538
[07:24:27.008] iteration 27570: loss: 0.052430, loss_s1: 0.042456, loss_fp: 0.008893, loss_freq: 0.022702
[07:24:27.612] iteration 27571: loss: 0.058837, loss_s1: 0.035410, loss_fp: 0.005871, loss_freq: 0.055756
[07:24:28.229] iteration 27572: loss: 0.094249, loss_s1: 0.086430, loss_fp: 0.004358, loss_freq: 0.038451
[07:24:28.843] iteration 27573: loss: 0.060838, loss_s1: 0.059901, loss_fp: 0.008726, loss_freq: 0.021921
[07:24:29.453] iteration 27574: loss: 0.034494, loss_s1: 0.029115, loss_fp: 0.003765, loss_freq: 0.009218
[07:24:30.065] iteration 27575: loss: 0.050211, loss_s1: 0.048862, loss_fp: 0.003981, loss_freq: 0.029278
[07:24:30.679] iteration 27576: loss: 0.043514, loss_s1: 0.024016, loss_fp: 0.006312, loss_freq: 0.016897
[07:24:31.292] iteration 27577: loss: 0.056798, loss_s1: 0.035359, loss_fp: 0.002615, loss_freq: 0.035262
[07:24:31.905] iteration 27578: loss: 0.078369, loss_s1: 0.106694, loss_fp: 0.003023, loss_freq: 0.023302
[07:24:32.519] iteration 27579: loss: 0.079584, loss_s1: 0.047625, loss_fp: 0.002615, loss_freq: 0.062909
[07:24:33.122] iteration 27580: loss: 0.053005, loss_s1: 0.038319, loss_fp: 0.006392, loss_freq: 0.034942
[07:24:33.728] iteration 27581: loss: 0.067754, loss_s1: 0.041563, loss_fp: 0.002730, loss_freq: 0.057808
[07:24:34.338] iteration 27582: loss: 0.064042, loss_s1: 0.061717, loss_fp: 0.002842, loss_freq: 0.017864
[07:24:34.949] iteration 27583: loss: 0.071744, loss_s1: 0.085247, loss_fp: 0.004155, loss_freq: 0.032074
[07:24:35.561] iteration 27584: loss: 0.069232, loss_s1: 0.069290, loss_fp: 0.009887, loss_freq: 0.039189
[07:24:36.172] iteration 27585: loss: 0.069172, loss_s1: 0.056976, loss_fp: 0.006584, loss_freq: 0.043052
[07:24:36.782] iteration 27586: loss: 0.088561, loss_s1: 0.106976, loss_fp: 0.008941, loss_freq: 0.028068
[07:24:37.401] iteration 27587: loss: 0.042399, loss_s1: 0.029895, loss_fp: 0.004782, loss_freq: 0.019574
[07:24:38.007] iteration 27588: loss: 0.078841, loss_s1: 0.069462, loss_fp: 0.004200, loss_freq: 0.058430
[07:24:38.617] iteration 27589: loss: 0.042487, loss_s1: 0.029117, loss_fp: 0.001155, loss_freq: 0.017413
[07:24:39.241] iteration 27590: loss: 0.030125, loss_s1: 0.014921, loss_fp: 0.001370, loss_freq: 0.007109
[07:24:39.855] iteration 27591: loss: 0.048248, loss_s1: 0.024748, loss_fp: 0.003374, loss_freq: 0.025084
[07:24:40.463] iteration 27592: loss: 0.053430, loss_s1: 0.059974, loss_fp: 0.003996, loss_freq: 0.021997
[07:24:41.072] iteration 27593: loss: 0.049304, loss_s1: 0.059098, loss_fp: 0.002309, loss_freq: 0.010399
[07:24:41.689] iteration 27594: loss: 0.083554, loss_s1: 0.091881, loss_fp: 0.001216, loss_freq: 0.036796
[07:24:42.298] iteration 27595: loss: 0.064682, loss_s1: 0.022465, loss_fp: 0.005876, loss_freq: 0.057567
[07:24:42.907] iteration 27596: loss: 0.026436, loss_s1: 0.011566, loss_fp: 0.001443, loss_freq: 0.009447
[07:24:43.514] iteration 27597: loss: 0.049162, loss_s1: 0.050170, loss_fp: 0.008142, loss_freq: 0.019826
[07:24:44.121] iteration 27598: loss: 0.045496, loss_s1: 0.038929, loss_fp: 0.001673, loss_freq: 0.013724
[07:24:44.741] iteration 27599: loss: 0.035295, loss_s1: 0.018654, loss_fp: 0.004542, loss_freq: 0.023083
[07:24:45.347] iteration 27600: loss: 0.048552, loss_s1: 0.032818, loss_fp: 0.002401, loss_freq: 0.034401
[07:24:48.601] iteration 27600 : mean_dice : 0.750507
[07:24:49.232] iteration 27601: loss: 0.028266, loss_s1: 0.027762, loss_fp: 0.003342, loss_freq: 0.004762
[07:24:49.845] iteration 27602: loss: 0.064965, loss_s1: 0.050317, loss_fp: 0.003217, loss_freq: 0.042443
[07:24:50.453] iteration 27603: loss: 0.033517, loss_s1: 0.019796, loss_fp: 0.002663, loss_freq: 0.011686
[07:24:51.061] iteration 27604: loss: 0.042455, loss_s1: 0.032286, loss_fp: 0.004267, loss_freq: 0.023065
[07:24:51.673] iteration 27605: loss: 0.040696, loss_s1: 0.037088, loss_fp: 0.003026, loss_freq: 0.010939
[07:24:52.284] iteration 27606: loss: 0.032325, loss_s1: 0.015917, loss_fp: 0.002348, loss_freq: 0.022602
[07:24:52.889] iteration 27607: loss: 0.046523, loss_s1: 0.038484, loss_fp: 0.000704, loss_freq: 0.014199
[07:24:53.493] iteration 27608: loss: 0.106878, loss_s1: 0.122066, loss_fp: 0.006682, loss_freq: 0.056466
[07:24:54.109] iteration 27609: loss: 0.037184, loss_s1: 0.022020, loss_fp: 0.001111, loss_freq: 0.020968
[07:24:54.723] iteration 27610: loss: 0.048046, loss_s1: 0.048856, loss_fp: 0.003225, loss_freq: 0.023615
[07:24:55.338] iteration 27611: loss: 0.064269, loss_s1: 0.062879, loss_fp: 0.009154, loss_freq: 0.025226
[07:24:56.160] iteration 27612: loss: 0.053103, loss_s1: 0.030029, loss_fp: 0.006650, loss_freq: 0.035328
[07:24:56.887] iteration 27613: loss: 0.071521, loss_s1: 0.062712, loss_fp: 0.004661, loss_freq: 0.052170
[07:24:57.496] iteration 27614: loss: 0.043986, loss_s1: 0.035345, loss_fp: 0.003126, loss_freq: 0.016999
[07:24:58.112] iteration 27615: loss: 0.059542, loss_s1: 0.041995, loss_fp: 0.001054, loss_freq: 0.044962
[07:24:58.728] iteration 27616: loss: 0.051936, loss_s1: 0.041924, loss_fp: 0.003441, loss_freq: 0.029468
[07:24:59.340] iteration 27617: loss: 0.056097, loss_s1: 0.041665, loss_fp: 0.009641, loss_freq: 0.030797
[07:24:59.968] iteration 27618: loss: 0.071763, loss_s1: 0.077783, loss_fp: 0.002741, loss_freq: 0.031420
[07:25:00.618] iteration 27619: loss: 0.059935, loss_s1: 0.040424, loss_fp: 0.011456, loss_freq: 0.047752
[07:25:01.234] iteration 27620: loss: 0.082044, loss_s1: 0.068685, loss_fp: 0.002698, loss_freq: 0.057891
[07:25:01.842] iteration 27621: loss: 0.034022, loss_s1: 0.014425, loss_fp: 0.001468, loss_freq: 0.009260
[07:25:02.447] iteration 27622: loss: 0.048520, loss_s1: 0.032203, loss_fp: 0.005283, loss_freq: 0.025996
[07:25:03.047] iteration 27623: loss: 0.084933, loss_s1: 0.100262, loss_fp: 0.008012, loss_freq: 0.033349
[07:25:03.651] iteration 27624: loss: 0.045018, loss_s1: 0.047281, loss_fp: 0.004034, loss_freq: 0.012919
[07:25:04.264] iteration 27625: loss: 0.037979, loss_s1: 0.018612, loss_fp: 0.002527, loss_freq: 0.025115
[07:25:04.878] iteration 27626: loss: 0.064577, loss_s1: 0.068659, loss_fp: 0.003423, loss_freq: 0.014680
[07:25:05.485] iteration 27627: loss: 0.042159, loss_s1: 0.035626, loss_fp: 0.003641, loss_freq: 0.027163
[07:25:06.095] iteration 27628: loss: 0.075705, loss_s1: 0.096108, loss_fp: 0.002264, loss_freq: 0.021415
[07:25:06.705] iteration 27629: loss: 0.071714, loss_s1: 0.043665, loss_fp: 0.017198, loss_freq: 0.044144
[07:25:07.360] iteration 27630: loss: 0.063027, loss_s1: 0.064968, loss_fp: 0.001445, loss_freq: 0.024934
[07:25:07.973] iteration 27631: loss: 0.083028, loss_s1: 0.108434, loss_fp: 0.006008, loss_freq: 0.019666
[07:25:08.584] iteration 27632: loss: 0.057261, loss_s1: 0.065940, loss_fp: 0.005855, loss_freq: 0.023366
[07:25:09.253] iteration 27633: loss: 0.056352, loss_s1: 0.033380, loss_fp: 0.006543, loss_freq: 0.031412
[07:25:09.924] iteration 27634: loss: 0.056479, loss_s1: 0.036078, loss_fp: 0.007057, loss_freq: 0.046700
[07:25:10.594] iteration 27635: loss: 0.073323, loss_s1: 0.085995, loss_fp: 0.005041, loss_freq: 0.029341
[07:25:11.238] iteration 27636: loss: 0.049842, loss_s1: 0.041014, loss_fp: 0.005054, loss_freq: 0.031120
[07:25:11.857] iteration 27637: loss: 0.065275, loss_s1: 0.070450, loss_fp: 0.002911, loss_freq: 0.021114
[07:25:12.472] iteration 27638: loss: 0.072313, loss_s1: 0.060122, loss_fp: 0.003242, loss_freq: 0.048392
[07:25:13.102] iteration 27639: loss: 0.062161, loss_s1: 0.060914, loss_fp: 0.001429, loss_freq: 0.038187
[07:25:13.737] iteration 27640: loss: 0.051450, loss_s1: 0.039483, loss_fp: 0.004650, loss_freq: 0.023543
[07:25:14.370] iteration 27641: loss: 0.083908, loss_s1: 0.107033, loss_fp: 0.006626, loss_freq: 0.032615
[07:25:14.981] iteration 27642: loss: 0.045811, loss_s1: 0.022181, loss_fp: 0.003998, loss_freq: 0.028008
[07:25:15.612] iteration 27643: loss: 0.028175, loss_s1: 0.020024, loss_fp: 0.001096, loss_freq: 0.006649
[07:25:16.362] iteration 27644: loss: 0.052121, loss_s1: 0.023737, loss_fp: 0.001937, loss_freq: 0.048838
[07:25:17.015] iteration 27645: loss: 0.038328, loss_s1: 0.028628, loss_fp: 0.002269, loss_freq: 0.009619
[07:25:17.817] iteration 27646: loss: 0.065353, loss_s1: 0.067480, loss_fp: 0.001259, loss_freq: 0.019179
[07:25:18.519] iteration 27647: loss: 0.045732, loss_s1: 0.025332, loss_fp: 0.008742, loss_freq: 0.025726
[07:25:19.206] iteration 27648: loss: 0.045447, loss_s1: 0.037148, loss_fp: 0.007376, loss_freq: 0.022882
[07:25:19.940] iteration 27649: loss: 0.036966, loss_s1: 0.017113, loss_fp: 0.012170, loss_freq: 0.018077
[07:25:20.640] iteration 27650: loss: 0.046398, loss_s1: 0.052622, loss_fp: 0.001738, loss_freq: 0.013751
[07:25:21.357] iteration 27651: loss: 0.035403, loss_s1: 0.027320, loss_fp: 0.002685, loss_freq: 0.010974
[07:25:21.978] iteration 27652: loss: 0.051277, loss_s1: 0.045545, loss_fp: 0.001745, loss_freq: 0.024783
[07:25:22.616] iteration 27653: loss: 0.058453, loss_s1: 0.051910, loss_fp: 0.004569, loss_freq: 0.035183
[07:25:23.228] iteration 27654: loss: 0.034839, loss_s1: 0.025082, loss_fp: 0.005088, loss_freq: 0.012685
[07:25:23.975] iteration 27655: loss: 0.078347, loss_s1: 0.040775, loss_fp: 0.003306, loss_freq: 0.073493
[07:25:24.656] iteration 27656: loss: 0.073991, loss_s1: 0.052218, loss_fp: 0.002992, loss_freq: 0.054450
[07:25:25.441] iteration 27657: loss: 0.055217, loss_s1: 0.047425, loss_fp: 0.002352, loss_freq: 0.032973
[07:25:26.174] iteration 27658: loss: 0.067674, loss_s1: 0.061233, loss_fp: 0.017379, loss_freq: 0.032297
[07:25:26.837] iteration 27659: loss: 0.086172, loss_s1: 0.061570, loss_fp: 0.008468, loss_freq: 0.071657
[07:25:27.587] iteration 27660: loss: 0.039153, loss_s1: 0.018442, loss_fp: 0.006678, loss_freq: 0.013319
[07:25:28.225] iteration 27661: loss: 0.046896, loss_s1: 0.045255, loss_fp: 0.003142, loss_freq: 0.013985
[07:25:28.830] iteration 27662: loss: 0.079236, loss_s1: 0.075199, loss_fp: 0.005143, loss_freq: 0.058852
[07:25:29.438] iteration 27663: loss: 0.055431, loss_s1: 0.030752, loss_fp: 0.003836, loss_freq: 0.046078
[07:25:30.058] iteration 27664: loss: 0.048411, loss_s1: 0.033085, loss_fp: 0.006601, loss_freq: 0.030359
[07:25:30.664] iteration 27665: loss: 0.047402, loss_s1: 0.032988, loss_fp: 0.002345, loss_freq: 0.027667
[07:25:31.274] iteration 27666: loss: 0.055714, loss_s1: 0.043374, loss_fp: 0.006022, loss_freq: 0.025938
[07:25:31.885] iteration 27667: loss: 0.063373, loss_s1: 0.062380, loss_fp: 0.008895, loss_freq: 0.036614
[07:25:32.537] iteration 27668: loss: 0.043988, loss_s1: 0.010266, loss_fp: 0.002673, loss_freq: 0.035082
[07:25:33.150] iteration 27669: loss: 0.053534, loss_s1: 0.054396, loss_fp: 0.011612, loss_freq: 0.019054
[07:25:33.764] iteration 27670: loss: 0.063006, loss_s1: 0.043566, loss_fp: 0.017032, loss_freq: 0.035826
[07:25:34.378] iteration 27671: loss: 0.028944, loss_s1: 0.019951, loss_fp: 0.002226, loss_freq: 0.013157
[07:25:34.974] iteration 27672: loss: 0.071594, loss_s1: 0.052190, loss_fp: 0.004597, loss_freq: 0.048207
[07:25:35.582] iteration 27673: loss: 0.066713, loss_s1: 0.064548, loss_fp: 0.002844, loss_freq: 0.032372
[07:25:36.187] iteration 27674: loss: 0.032941, loss_s1: 0.019609, loss_fp: 0.001032, loss_freq: 0.021769
[07:25:36.795] iteration 27675: loss: 0.074743, loss_s1: 0.064247, loss_fp: 0.000631, loss_freq: 0.053139
[07:25:37.405] iteration 27676: loss: 0.034212, loss_s1: 0.029540, loss_fp: 0.004476, loss_freq: 0.012178
[07:25:38.015] iteration 27677: loss: 0.059038, loss_s1: 0.069623, loss_fp: 0.001231, loss_freq: 0.013489
[07:25:38.625] iteration 27678: loss: 0.047997, loss_s1: 0.024973, loss_fp: 0.009032, loss_freq: 0.033352
[07:25:39.316] iteration 27679: loss: 0.064547, loss_s1: 0.074781, loss_fp: 0.004307, loss_freq: 0.022996
[07:25:39.936] iteration 27680: loss: 0.059870, loss_s1: 0.049762, loss_fp: 0.003603, loss_freq: 0.046578
[07:25:40.554] iteration 27681: loss: 0.042768, loss_s1: 0.012464, loss_fp: 0.006619, loss_freq: 0.033239
[07:25:41.158] iteration 27682: loss: 0.060247, loss_s1: 0.042499, loss_fp: 0.003378, loss_freq: 0.038363
[07:25:41.766] iteration 27683: loss: 0.042240, loss_s1: 0.044760, loss_fp: 0.002915, loss_freq: 0.013538
[07:25:42.408] iteration 27684: loss: 0.036769, loss_s1: 0.024751, loss_fp: 0.003791, loss_freq: 0.014351
[07:25:43.068] iteration 27685: loss: 0.033833, loss_s1: 0.029157, loss_fp: 0.002839, loss_freq: 0.011732
[07:25:43.698] iteration 27686: loss: 0.042080, loss_s1: 0.025412, loss_fp: 0.002042, loss_freq: 0.030951
[07:25:44.329] iteration 27687: loss: 0.064817, loss_s1: 0.048591, loss_fp: 0.002151, loss_freq: 0.032541
[07:25:45.172] iteration 27688: loss: 0.065756, loss_s1: 0.076724, loss_fp: 0.003310, loss_freq: 0.025354
[07:25:46.062] iteration 27689: loss: 0.062672, loss_s1: 0.055957, loss_fp: 0.005565, loss_freq: 0.044274
[07:25:46.719] iteration 27690: loss: 0.082782, loss_s1: 0.064307, loss_fp: 0.003691, loss_freq: 0.062296
[07:25:47.371] iteration 27691: loss: 0.079554, loss_s1: 0.054723, loss_fp: 0.014693, loss_freq: 0.059266
[07:25:48.024] iteration 27692: loss: 0.076368, loss_s1: 0.098780, loss_fp: 0.004660, loss_freq: 0.021759
[07:25:48.648] iteration 27693: loss: 0.050786, loss_s1: 0.049482, loss_fp: 0.003689, loss_freq: 0.023313
[07:25:49.254] iteration 27694: loss: 0.075337, loss_s1: 0.077048, loss_fp: 0.004298, loss_freq: 0.041779
[07:25:49.869] iteration 27695: loss: 0.062278, loss_s1: 0.060699, loss_fp: 0.003615, loss_freq: 0.025984
[07:25:50.478] iteration 27696: loss: 0.051100, loss_s1: 0.063386, loss_fp: 0.001674, loss_freq: 0.007691
[07:25:51.101] iteration 27697: loss: 0.037850, loss_s1: 0.041340, loss_fp: 0.004151, loss_freq: 0.013478
[07:25:51.709] iteration 27698: loss: 0.067620, loss_s1: 0.062452, loss_fp: 0.003766, loss_freq: 0.035831
[07:25:52.319] iteration 27699: loss: 0.040823, loss_s1: 0.025097, loss_fp: 0.003786, loss_freq: 0.022920
[07:25:52.929] iteration 27700: loss: 0.061789, loss_s1: 0.056700, loss_fp: 0.002103, loss_freq: 0.020351
[07:25:53.556] iteration 27701: loss: 0.040724, loss_s1: 0.038741, loss_fp: 0.005654, loss_freq: 0.006449
[07:25:54.178] iteration 27702: loss: 0.051274, loss_s1: 0.055309, loss_fp: 0.004612, loss_freq: 0.022436
[07:25:54.795] iteration 27703: loss: 0.036063, loss_s1: 0.014367, loss_fp: 0.002356, loss_freq: 0.016194
[07:25:55.406] iteration 27704: loss: 0.035891, loss_s1: 0.025773, loss_fp: 0.004218, loss_freq: 0.018358
[07:25:56.052] iteration 27705: loss: 0.034247, loss_s1: 0.018707, loss_fp: 0.002259, loss_freq: 0.011875
[07:25:56.739] iteration 27706: loss: 0.066864, loss_s1: 0.045919, loss_fp: 0.005537, loss_freq: 0.060235
[07:25:57.402] iteration 27707: loss: 0.049997, loss_s1: 0.048723, loss_fp: 0.001921, loss_freq: 0.018355
[07:25:58.019] iteration 27708: loss: 0.067244, loss_s1: 0.055758, loss_fp: 0.006472, loss_freq: 0.038931
[07:25:58.621] iteration 27709: loss: 0.080008, loss_s1: 0.073911, loss_fp: 0.010514, loss_freq: 0.048558
[07:25:59.233] iteration 27710: loss: 0.035786, loss_s1: 0.030312, loss_fp: 0.003086, loss_freq: 0.006941
[07:26:00.233] iteration 27711: loss: 0.074146, loss_s1: 0.046630, loss_fp: 0.005020, loss_freq: 0.066582
[07:26:00.854] iteration 27712: loss: 0.046415, loss_s1: 0.026523, loss_fp: 0.005426, loss_freq: 0.032742
[07:26:01.473] iteration 27713: loss: 0.077869, loss_s1: 0.098722, loss_fp: 0.008481, loss_freq: 0.023589
[07:26:02.087] iteration 27714: loss: 0.046871, loss_s1: 0.044719, loss_fp: 0.002220, loss_freq: 0.016268
[07:26:02.700] iteration 27715: loss: 0.086909, loss_s1: 0.101461, loss_fp: 0.006857, loss_freq: 0.029166
[07:26:03.321] iteration 27716: loss: 0.066743, loss_s1: 0.043431, loss_fp: 0.004715, loss_freq: 0.057347
[07:26:03.976] iteration 27717: loss: 0.052761, loss_s1: 0.013399, loss_fp: 0.005415, loss_freq: 0.056266
[07:26:04.633] iteration 27718: loss: 0.055975, loss_s1: 0.049932, loss_fp: 0.017137, loss_freq: 0.011620
[07:26:05.312] iteration 27719: loss: 0.044314, loss_s1: 0.045533, loss_fp: 0.002502, loss_freq: 0.019662
[07:26:05.997] iteration 27720: loss: 0.089630, loss_s1: 0.090368, loss_fp: 0.002549, loss_freq: 0.047118
[07:26:06.661] iteration 27721: loss: 0.053330, loss_s1: 0.033594, loss_fp: 0.002933, loss_freq: 0.035031
[07:26:07.275] iteration 27722: loss: 0.063058, loss_s1: 0.047224, loss_fp: 0.001169, loss_freq: 0.050246
[07:26:07.890] iteration 27723: loss: 0.039244, loss_s1: 0.021487, loss_fp: 0.004495, loss_freq: 0.026693
[07:26:08.505] iteration 27724: loss: 0.089734, loss_s1: 0.082188, loss_fp: 0.004237, loss_freq: 0.064534
[07:26:09.122] iteration 27725: loss: 0.034010, loss_s1: 0.027776, loss_fp: 0.002560, loss_freq: 0.008137
[07:26:09.739] iteration 27726: loss: 0.045250, loss_s1: 0.038475, loss_fp: 0.003630, loss_freq: 0.019883
[07:26:10.354] iteration 27727: loss: 0.070742, loss_s1: 0.062986, loss_fp: 0.014121, loss_freq: 0.044402
[07:26:10.968] iteration 27728: loss: 0.045248, loss_s1: 0.038989, loss_fp: 0.001102, loss_freq: 0.009519
[07:26:11.578] iteration 27729: loss: 0.066641, loss_s1: 0.055588, loss_fp: 0.010183, loss_freq: 0.041755
[07:26:12.191] iteration 27730: loss: 0.046381, loss_s1: 0.041566, loss_fp: 0.002161, loss_freq: 0.007659
[07:26:12.818] iteration 27731: loss: 0.064709, loss_s1: 0.034742, loss_fp: 0.002979, loss_freq: 0.062798
[07:26:13.429] iteration 27732: loss: 0.046183, loss_s1: 0.045843, loss_fp: 0.002778, loss_freq: 0.019927
[07:26:14.036] iteration 27733: loss: 0.064280, loss_s1: 0.069605, loss_fp: 0.003245, loss_freq: 0.023557
[07:26:14.656] iteration 27734: loss: 0.044898, loss_s1: 0.030170, loss_fp: 0.003061, loss_freq: 0.026889
[07:26:15.263] iteration 27735: loss: 0.083377, loss_s1: 0.084312, loss_fp: 0.002249, loss_freq: 0.050261
[07:26:15.872] iteration 27736: loss: 0.049555, loss_s1: 0.034371, loss_fp: 0.007408, loss_freq: 0.035614
[07:26:16.480] iteration 27737: loss: 0.035452, loss_s1: 0.021967, loss_fp: 0.004125, loss_freq: 0.012528
[07:26:17.096] iteration 27738: loss: 0.079229, loss_s1: 0.070353, loss_fp: 0.004926, loss_freq: 0.044438
[07:26:17.708] iteration 27739: loss: 0.042339, loss_s1: 0.039537, loss_fp: 0.001815, loss_freq: 0.020571
[07:26:18.318] iteration 27740: loss: 0.072279, loss_s1: 0.053472, loss_fp: 0.011706, loss_freq: 0.052707
[07:26:18.930] iteration 27741: loss: 0.042149, loss_s1: 0.022912, loss_fp: 0.002387, loss_freq: 0.037026
[07:26:19.543] iteration 27742: loss: 0.092239, loss_s1: 0.114900, loss_fp: 0.005410, loss_freq: 0.027124
[07:26:20.162] iteration 27743: loss: 0.047368, loss_s1: 0.036154, loss_fp: 0.013674, loss_freq: 0.012912
[07:26:20.786] iteration 27744: loss: 0.051087, loss_s1: 0.046088, loss_fp: 0.007335, loss_freq: 0.019190
[07:26:21.404] iteration 27745: loss: 0.039948, loss_s1: 0.019064, loss_fp: 0.002866, loss_freq: 0.035845
[07:26:22.026] iteration 27746: loss: 0.056118, loss_s1: 0.040809, loss_fp: 0.011171, loss_freq: 0.025074
[07:26:22.647] iteration 27747: loss: 0.059920, loss_s1: 0.034019, loss_fp: 0.002002, loss_freq: 0.046979
[07:26:23.258] iteration 27748: loss: 0.063630, loss_s1: 0.086329, loss_fp: 0.002775, loss_freq: 0.010025
[07:26:23.868] iteration 27749: loss: 0.082646, loss_s1: 0.083006, loss_fp: 0.005279, loss_freq: 0.039366
[07:26:24.474] iteration 27750: loss: 0.070656, loss_s1: 0.078842, loss_fp: 0.013782, loss_freq: 0.023323
[07:26:25.087] iteration 27751: loss: 0.056538, loss_s1: 0.059852, loss_fp: 0.005295, loss_freq: 0.013820
[07:26:25.696] iteration 27752: loss: 0.069153, loss_s1: 0.073329, loss_fp: 0.004859, loss_freq: 0.025964
[07:26:26.303] iteration 27753: loss: 0.087246, loss_s1: 0.085163, loss_fp: 0.006842, loss_freq: 0.059200
[07:26:26.911] iteration 27754: loss: 0.085936, loss_s1: 0.077883, loss_fp: 0.007209, loss_freq: 0.057428
[07:26:27.518] iteration 27755: loss: 0.055961, loss_s1: 0.015051, loss_fp: 0.011537, loss_freq: 0.037925
[07:26:28.126] iteration 27756: loss: 0.049114, loss_s1: 0.037542, loss_fp: 0.006202, loss_freq: 0.022385
[07:26:28.740] iteration 27757: loss: 0.054730, loss_s1: 0.045851, loss_fp: 0.003812, loss_freq: 0.028990
[07:26:29.364] iteration 27758: loss: 0.064358, loss_s1: 0.088544, loss_fp: 0.001688, loss_freq: 0.011559
[07:26:29.973] iteration 27759: loss: 0.048280, loss_s1: 0.052053, loss_fp: 0.003581, loss_freq: 0.018533
[07:26:30.584] iteration 27760: loss: 0.052911, loss_s1: 0.053144, loss_fp: 0.001093, loss_freq: 0.015140
[07:26:31.190] iteration 27761: loss: 0.046066, loss_s1: 0.032076, loss_fp: 0.003867, loss_freq: 0.019381
[07:26:31.801] iteration 27762: loss: 0.051830, loss_s1: 0.055068, loss_fp: 0.003743, loss_freq: 0.027826
[07:26:32.412] iteration 27763: loss: 0.040748, loss_s1: 0.016708, loss_fp: 0.001001, loss_freq: 0.030510
[07:26:33.024] iteration 27764: loss: 0.094002, loss_s1: 0.093260, loss_fp: 0.003635, loss_freq: 0.044529
[07:26:33.633] iteration 27765: loss: 0.055899, loss_s1: 0.020300, loss_fp: 0.010281, loss_freq: 0.048380
[07:26:34.245] iteration 27766: loss: 0.040421, loss_s1: 0.030648, loss_fp: 0.001342, loss_freq: 0.018145
[07:26:34.854] iteration 27767: loss: 0.038311, loss_s1: 0.027159, loss_fp: 0.004652, loss_freq: 0.025456
[07:26:35.463] iteration 27768: loss: 0.039281, loss_s1: 0.017870, loss_fp: 0.007140, loss_freq: 0.012622
[07:26:36.073] iteration 27769: loss: 0.036020, loss_s1: 0.018981, loss_fp: 0.002631, loss_freq: 0.030234
[07:26:36.684] iteration 27770: loss: 0.045538, loss_s1: 0.038054, loss_fp: 0.001352, loss_freq: 0.023592
[07:26:37.289] iteration 27771: loss: 0.036994, loss_s1: 0.034910, loss_fp: 0.007097, loss_freq: 0.010488
[07:26:37.895] iteration 27772: loss: 0.044858, loss_s1: 0.031577, loss_fp: 0.001585, loss_freq: 0.024969
[07:26:38.505] iteration 27773: loss: 0.054475, loss_s1: 0.047862, loss_fp: 0.003117, loss_freq: 0.021490
[07:26:39.117] iteration 27774: loss: 0.046139, loss_s1: 0.044164, loss_fp: 0.004335, loss_freq: 0.019652
[07:26:39.727] iteration 27775: loss: 0.034742, loss_s1: 0.030344, loss_fp: 0.001111, loss_freq: 0.007125
[07:26:40.337] iteration 27776: loss: 0.072897, loss_s1: 0.086195, loss_fp: 0.003674, loss_freq: 0.035930
[07:26:40.947] iteration 27777: loss: 0.052467, loss_s1: 0.038879, loss_fp: 0.003181, loss_freq: 0.006520
[07:26:41.563] iteration 27778: loss: 0.078003, loss_s1: 0.097169, loss_fp: 0.004098, loss_freq: 0.028874
[07:26:42.175] iteration 27779: loss: 0.029753, loss_s1: 0.014662, loss_fp: 0.000592, loss_freq: 0.017245
[07:26:42.784] iteration 27780: loss: 0.042708, loss_s1: 0.032780, loss_fp: 0.001049, loss_freq: 0.027815
[07:26:43.404] iteration 27781: loss: 0.056047, loss_s1: 0.030727, loss_fp: 0.003048, loss_freq: 0.045889
[07:26:44.007] iteration 27782: loss: 0.039795, loss_s1: 0.030047, loss_fp: 0.002357, loss_freq: 0.014434
[07:26:44.614] iteration 27783: loss: 0.052356, loss_s1: 0.030412, loss_fp: 0.016209, loss_freq: 0.032029
[07:26:45.219] iteration 27784: loss: 0.070764, loss_s1: 0.096972, loss_fp: 0.003734, loss_freq: 0.012431
[07:26:45.825] iteration 27785: loss: 0.060622, loss_s1: 0.040087, loss_fp: 0.009513, loss_freq: 0.047569
[07:26:46.431] iteration 27786: loss: 0.066573, loss_s1: 0.037121, loss_fp: 0.008653, loss_freq: 0.055148
[07:26:47.035] iteration 27787: loss: 0.044793, loss_s1: 0.042829, loss_fp: 0.001677, loss_freq: 0.017518
[07:26:47.644] iteration 27788: loss: 0.061970, loss_s1: 0.067666, loss_fp: 0.005229, loss_freq: 0.026398
[07:26:48.258] iteration 27789: loss: 0.039076, loss_s1: 0.027164, loss_fp: 0.012349, loss_freq: 0.019616
[07:26:48.873] iteration 27790: loss: 0.049351, loss_s1: 0.035535, loss_fp: 0.005954, loss_freq: 0.022322
[07:26:49.508] iteration 27791: loss: 0.035401, loss_s1: 0.031026, loss_fp: 0.004857, loss_freq: 0.007979
[07:26:50.132] iteration 27792: loss: 0.050130, loss_s1: 0.046327, loss_fp: 0.004100, loss_freq: 0.021075
[07:26:50.755] iteration 27793: loss: 0.079714, loss_s1: 0.075776, loss_fp: 0.021931, loss_freq: 0.032086
[07:26:51.361] iteration 27794: loss: 0.047960, loss_s1: 0.034302, loss_fp: 0.009606, loss_freq: 0.015609
[07:26:51.969] iteration 27795: loss: 0.054896, loss_s1: 0.036746, loss_fp: 0.004679, loss_freq: 0.032716
[07:26:52.576] iteration 27796: loss: 0.045967, loss_s1: 0.033885, loss_fp: 0.002293, loss_freq: 0.020082
[07:26:53.241] iteration 27797: loss: 0.064046, loss_s1: 0.078383, loss_fp: 0.008380, loss_freq: 0.020842
[07:26:53.900] iteration 27798: loss: 0.078816, loss_s1: 0.091709, loss_fp: 0.008881, loss_freq: 0.028953
[07:26:54.552] iteration 27799: loss: 0.077725, loss_s1: 0.093677, loss_fp: 0.007070, loss_freq: 0.027646
[07:26:55.207] iteration 27800: loss: 0.048897, loss_s1: 0.050199, loss_fp: 0.001638, loss_freq: 0.012072
[07:26:58.788] iteration 27800 : mean_dice : 0.745289
[07:26:59.478] iteration 27801: loss: 0.072822, loss_s1: 0.075802, loss_fp: 0.012394, loss_freq: 0.026616
[07:27:00.322] iteration 27802: loss: 0.031113, loss_s1: 0.017376, loss_fp: 0.003090, loss_freq: 0.018580
[07:27:01.016] iteration 27803: loss: 0.052505, loss_s1: 0.037605, loss_fp: 0.006897, loss_freq: 0.025252
[07:27:01.715] iteration 27804: loss: 0.046653, loss_s1: 0.041418, loss_fp: 0.002660, loss_freq: 0.020165
[07:27:02.325] iteration 27805: loss: 0.082407, loss_s1: 0.093016, loss_fp: 0.008166, loss_freq: 0.026828
[07:27:02.934] iteration 27806: loss: 0.050734, loss_s1: 0.053348, loss_fp: 0.001626, loss_freq: 0.021206
[07:27:03.539] iteration 27807: loss: 0.079102, loss_s1: 0.076535, loss_fp: 0.004144, loss_freq: 0.047037
[07:27:04.159] iteration 27808: loss: 0.043417, loss_s1: 0.026616, loss_fp: 0.001640, loss_freq: 0.026874
[07:27:04.763] iteration 27809: loss: 0.052054, loss_s1: 0.050915, loss_fp: 0.003510, loss_freq: 0.024447
[07:27:05.367] iteration 27810: loss: 0.047505, loss_s1: 0.040269, loss_fp: 0.003912, loss_freq: 0.019979
[07:27:05.972] iteration 27811: loss: 0.068360, loss_s1: 0.078448, loss_fp: 0.007367, loss_freq: 0.026737
[07:27:06.579] iteration 27812: loss: 0.036920, loss_s1: 0.021442, loss_fp: 0.005310, loss_freq: 0.016418
[07:27:07.187] iteration 27813: loss: 0.052209, loss_s1: 0.045569, loss_fp: 0.002987, loss_freq: 0.026292
[07:27:07.796] iteration 27814: loss: 0.047000, loss_s1: 0.040338, loss_fp: 0.003888, loss_freq: 0.012489
[07:27:08.405] iteration 27815: loss: 0.022995, loss_s1: 0.007281, loss_fp: 0.001575, loss_freq: 0.018285
[07:27:09.008] iteration 27816: loss: 0.049751, loss_s1: 0.029752, loss_fp: 0.003843, loss_freq: 0.028095
[07:27:09.620] iteration 27817: loss: 0.061501, loss_s1: 0.054534, loss_fp: 0.009167, loss_freq: 0.027345
[07:27:10.232] iteration 27818: loss: 0.048376, loss_s1: 0.039530, loss_fp: 0.002709, loss_freq: 0.027769
[07:27:10.837] iteration 27819: loss: 0.055763, loss_s1: 0.031874, loss_fp: 0.011670, loss_freq: 0.035700
[07:27:11.444] iteration 27820: loss: 0.041008, loss_s1: 0.024427, loss_fp: 0.003833, loss_freq: 0.025822
[07:27:12.053] iteration 27821: loss: 0.061707, loss_s1: 0.037002, loss_fp: 0.003692, loss_freq: 0.050309
[07:27:12.658] iteration 27822: loss: 0.051370, loss_s1: 0.039207, loss_fp: 0.009861, loss_freq: 0.020024
[07:27:13.284] iteration 27823: loss: 0.045480, loss_s1: 0.040271, loss_fp: 0.002780, loss_freq: 0.022454
[07:27:13.895] iteration 27824: loss: 0.030334, loss_s1: 0.013344, loss_fp: 0.004918, loss_freq: 0.018184
[07:27:14.507] iteration 27825: loss: 0.079426, loss_s1: 0.054725, loss_fp: 0.006890, loss_freq: 0.058809
[07:27:15.139] iteration 27826: loss: 0.063637, loss_s1: 0.036672, loss_fp: 0.009428, loss_freq: 0.040896
[07:27:15.755] iteration 27827: loss: 0.100681, loss_s1: 0.125987, loss_fp: 0.005048, loss_freq: 0.037550
[07:27:16.414] iteration 27828: loss: 0.046848, loss_s1: 0.044123, loss_fp: 0.006094, loss_freq: 0.015445
[07:27:17.030] iteration 27829: loss: 0.056798, loss_s1: 0.023479, loss_fp: 0.004498, loss_freq: 0.054000
[07:27:17.647] iteration 27830: loss: 0.039547, loss_s1: 0.019723, loss_fp: 0.002101, loss_freq: 0.021125
[07:27:18.261] iteration 27831: loss: 0.031822, loss_s1: 0.017143, loss_fp: 0.003416, loss_freq: 0.009461
[07:27:18.877] iteration 27832: loss: 0.072375, loss_s1: 0.068080, loss_fp: 0.006321, loss_freq: 0.049612
[07:27:19.496] iteration 27833: loss: 0.072955, loss_s1: 0.089388, loss_fp: 0.013863, loss_freq: 0.018643
[07:27:20.106] iteration 27834: loss: 0.044933, loss_s1: 0.038397, loss_fp: 0.007515, loss_freq: 0.013755
[07:27:20.734] iteration 27835: loss: 0.072182, loss_s1: 0.059848, loss_fp: 0.001212, loss_freq: 0.048652
[07:27:21.351] iteration 27836: loss: 0.044967, loss_s1: 0.029415, loss_fp: 0.000832, loss_freq: 0.024961
[07:27:21.965] iteration 27837: loss: 0.098147, loss_s1: 0.094770, loss_fp: 0.007122, loss_freq: 0.077305
[07:27:22.576] iteration 27838: loss: 0.056627, loss_s1: 0.041101, loss_fp: 0.012549, loss_freq: 0.011489
[07:27:23.181] iteration 27839: loss: 0.039011, loss_s1: 0.037661, loss_fp: 0.003771, loss_freq: 0.012849
[07:27:23.791] iteration 27840: loss: 0.064393, loss_s1: 0.049713, loss_fp: 0.008644, loss_freq: 0.041178
[07:27:24.399] iteration 27841: loss: 0.055018, loss_s1: 0.069371, loss_fp: 0.004882, loss_freq: 0.013939
[07:27:25.000] iteration 27842: loss: 0.062854, loss_s1: 0.068720, loss_fp: 0.002015, loss_freq: 0.012677
[07:27:25.651] iteration 27843: loss: 0.081016, loss_s1: 0.088869, loss_fp: 0.008455, loss_freq: 0.029494
[07:27:26.261] iteration 27844: loss: 0.053122, loss_s1: 0.059543, loss_fp: 0.001292, loss_freq: 0.017260
[07:27:26.881] iteration 27845: loss: 0.054219, loss_s1: 0.056535, loss_fp: 0.001707, loss_freq: 0.015702
[07:27:27.493] iteration 27846: loss: 0.025259, loss_s1: 0.018040, loss_fp: 0.005571, loss_freq: 0.005872
[07:27:28.103] iteration 27847: loss: 0.051935, loss_s1: 0.037239, loss_fp: 0.005572, loss_freq: 0.013414
[07:27:28.721] iteration 27848: loss: 0.067417, loss_s1: 0.081231, loss_fp: 0.002649, loss_freq: 0.023427
[07:27:29.333] iteration 27849: loss: 0.075211, loss_s1: 0.082373, loss_fp: 0.010730, loss_freq: 0.028003
[07:27:29.947] iteration 27850: loss: 0.047894, loss_s1: 0.061474, loss_fp: 0.002759, loss_freq: 0.010262
[07:27:30.556] iteration 27851: loss: 0.069410, loss_s1: 0.053459, loss_fp: 0.006293, loss_freq: 0.045207
[07:27:31.160] iteration 27852: loss: 0.045116, loss_s1: 0.040524, loss_fp: 0.002762, loss_freq: 0.018671
[07:27:31.767] iteration 27853: loss: 0.043269, loss_s1: 0.040982, loss_fp: 0.002265, loss_freq: 0.017209
[07:27:32.376] iteration 27854: loss: 0.047033, loss_s1: 0.037822, loss_fp: 0.006329, loss_freq: 0.017867
[07:27:32.992] iteration 27855: loss: 0.031985, loss_s1: 0.018707, loss_fp: 0.005695, loss_freq: 0.015516
[07:27:33.603] iteration 27856: loss: 0.045064, loss_s1: 0.037000, loss_fp: 0.001072, loss_freq: 0.016690
[07:27:34.214] iteration 27857: loss: 0.039648, loss_s1: 0.033257, loss_fp: 0.000659, loss_freq: 0.016629
[07:27:34.827] iteration 27858: loss: 0.081743, loss_s1: 0.091526, loss_fp: 0.008606, loss_freq: 0.039989
[07:27:35.434] iteration 27859: loss: 0.044652, loss_s1: 0.029679, loss_fp: 0.004044, loss_freq: 0.036671
[07:27:36.050] iteration 27860: loss: 0.061842, loss_s1: 0.036385, loss_fp: 0.012166, loss_freq: 0.039779
[07:27:36.661] iteration 27861: loss: 0.085977, loss_s1: 0.096369, loss_fp: 0.004508, loss_freq: 0.030361
[07:27:37.272] iteration 27862: loss: 0.052524, loss_s1: 0.053791, loss_fp: 0.003598, loss_freq: 0.016495
[07:27:37.884] iteration 27863: loss: 0.091211, loss_s1: 0.099105, loss_fp: 0.005922, loss_freq: 0.047686
[07:27:38.504] iteration 27864: loss: 0.087934, loss_s1: 0.108360, loss_fp: 0.012983, loss_freq: 0.029693
[07:27:39.124] iteration 27865: loss: 0.077503, loss_s1: 0.052583, loss_fp: 0.005530, loss_freq: 0.052567
[07:27:39.735] iteration 27866: loss: 0.026998, loss_s1: 0.015580, loss_fp: 0.000938, loss_freq: 0.009469
[07:27:40.346] iteration 27867: loss: 0.036853, loss_s1: 0.029281, loss_fp: 0.007990, loss_freq: 0.014971
[07:27:40.977] iteration 27868: loss: 0.061951, loss_s1: 0.039664, loss_fp: 0.006066, loss_freq: 0.048403
[07:27:41.586] iteration 27869: loss: 0.078257, loss_s1: 0.059721, loss_fp: 0.013594, loss_freq: 0.054952
[07:27:42.198] iteration 27870: loss: 0.072551, loss_s1: 0.065509, loss_fp: 0.006055, loss_freq: 0.040307
[07:27:42.810] iteration 27871: loss: 0.060375, loss_s1: 0.064528, loss_fp: 0.004819, loss_freq: 0.016512
[07:27:43.415] iteration 27872: loss: 0.045879, loss_s1: 0.031306, loss_fp: 0.003720, loss_freq: 0.037557
[07:27:44.029] iteration 27873: loss: 0.038960, loss_s1: 0.014614, loss_fp: 0.002376, loss_freq: 0.024598
[07:27:44.643] iteration 27874: loss: 0.038226, loss_s1: 0.023228, loss_fp: 0.005678, loss_freq: 0.025265
[07:27:45.261] iteration 27875: loss: 0.038881, loss_s1: 0.024548, loss_fp: 0.003095, loss_freq: 0.014703
[07:27:45.872] iteration 27876: loss: 0.100792, loss_s1: 0.103546, loss_fp: 0.007380, loss_freq: 0.066800
[07:27:46.561] iteration 27877: loss: 0.044340, loss_s1: 0.020290, loss_fp: 0.003827, loss_freq: 0.035721
[07:27:47.228] iteration 27878: loss: 0.050963, loss_s1: 0.039335, loss_fp: 0.003310, loss_freq: 0.021336
[07:27:47.884] iteration 27879: loss: 0.072065, loss_s1: 0.079401, loss_fp: 0.002295, loss_freq: 0.034448
[07:27:48.537] iteration 27880: loss: 0.054718, loss_s1: 0.029760, loss_fp: 0.010172, loss_freq: 0.036176
[07:27:49.505] iteration 27881: loss: 0.038981, loss_s1: 0.024687, loss_fp: 0.004490, loss_freq: 0.019599
[07:27:50.117] iteration 27882: loss: 0.078376, loss_s1: 0.056927, loss_fp: 0.008967, loss_freq: 0.056913
[07:27:50.734] iteration 27883: loss: 0.056637, loss_s1: 0.051541, loss_fp: 0.005006, loss_freq: 0.030716
[07:27:51.351] iteration 27884: loss: 0.047542, loss_s1: 0.044928, loss_fp: 0.001824, loss_freq: 0.015675
[07:27:51.968] iteration 27885: loss: 0.042309, loss_s1: 0.038725, loss_fp: 0.004788, loss_freq: 0.016216
[07:27:52.589] iteration 27886: loss: 0.052139, loss_s1: 0.021979, loss_fp: 0.005004, loss_freq: 0.039086
[07:27:53.211] iteration 27887: loss: 0.052571, loss_s1: 0.033577, loss_fp: 0.003990, loss_freq: 0.040443
[07:27:53.829] iteration 27888: loss: 0.048631, loss_s1: 0.046872, loss_fp: 0.005525, loss_freq: 0.019521
[07:27:54.455] iteration 27889: loss: 0.053571, loss_s1: 0.071398, loss_fp: 0.001186, loss_freq: 0.012937
[07:27:55.078] iteration 27890: loss: 0.056247, loss_s1: 0.040870, loss_fp: 0.004609, loss_freq: 0.033810
[07:27:55.691] iteration 27891: loss: 0.067284, loss_s1: 0.065104, loss_fp: 0.001753, loss_freq: 0.035451
[07:27:56.306] iteration 27892: loss: 0.050279, loss_s1: 0.044357, loss_fp: 0.005077, loss_freq: 0.020195
[07:27:56.930] iteration 27893: loss: 0.045291, loss_s1: 0.033817, loss_fp: 0.001576, loss_freq: 0.030755
[07:27:57.548] iteration 27894: loss: 0.064573, loss_s1: 0.059298, loss_fp: 0.004529, loss_freq: 0.029764
[07:27:58.160] iteration 27895: loss: 0.054412, loss_s1: 0.027374, loss_fp: 0.003705, loss_freq: 0.033803
[07:27:58.796] iteration 27896: loss: 0.037515, loss_s1: 0.025631, loss_fp: 0.005035, loss_freq: 0.020212
[07:27:59.405] iteration 27897: loss: 0.085604, loss_s1: 0.022473, loss_fp: 0.003332, loss_freq: 0.125739
[07:28:00.020] iteration 27898: loss: 0.032808, loss_s1: 0.024668, loss_fp: 0.002649, loss_freq: 0.006721
[07:28:00.637] iteration 27899: loss: 0.076500, loss_s1: 0.082202, loss_fp: 0.009416, loss_freq: 0.036053
[07:28:01.248] iteration 27900: loss: 0.056806, loss_s1: 0.047948, loss_fp: 0.004521, loss_freq: 0.023618
[07:28:01.866] iteration 27901: loss: 0.053774, loss_s1: 0.032781, loss_fp: 0.004035, loss_freq: 0.040257
[07:28:02.498] iteration 27902: loss: 0.055086, loss_s1: 0.052893, loss_fp: 0.010925, loss_freq: 0.025302
[07:28:03.110] iteration 27903: loss: 0.060056, loss_s1: 0.049521, loss_fp: 0.002721, loss_freq: 0.033838
[07:28:03.717] iteration 27904: loss: 0.056100, loss_s1: 0.032360, loss_fp: 0.002341, loss_freq: 0.045820
[07:28:04.332] iteration 27905: loss: 0.076257, loss_s1: 0.076828, loss_fp: 0.003591, loss_freq: 0.040347
[07:28:04.950] iteration 27906: loss: 0.048089, loss_s1: 0.052409, loss_fp: 0.004006, loss_freq: 0.019146
[07:28:05.570] iteration 27907: loss: 0.059015, loss_s1: 0.067663, loss_fp: 0.003236, loss_freq: 0.013813
[07:28:06.241] iteration 27908: loss: 0.068912, loss_s1: 0.067170, loss_fp: 0.003818, loss_freq: 0.034578
[07:28:06.903] iteration 27909: loss: 0.076411, loss_s1: 0.065423, loss_fp: 0.004431, loss_freq: 0.048716
[07:28:07.538] iteration 27910: loss: 0.072885, loss_s1: 0.069402, loss_fp: 0.002937, loss_freq: 0.041051
[07:28:08.150] iteration 27911: loss: 0.048701, loss_s1: 0.030508, loss_fp: 0.002734, loss_freq: 0.037883
[07:28:08.796] iteration 27912: loss: 0.076526, loss_s1: 0.078647, loss_fp: 0.005334, loss_freq: 0.031596
[07:28:09.411] iteration 27913: loss: 0.051686, loss_s1: 0.049093, loss_fp: 0.005672, loss_freq: 0.020145
[07:28:10.021] iteration 27914: loss: 0.038346, loss_s1: 0.034694, loss_fp: 0.002381, loss_freq: 0.014102
[07:28:10.660] iteration 27915: loss: 0.057677, loss_s1: 0.065607, loss_fp: 0.003188, loss_freq: 0.027997
[07:28:11.294] iteration 27916: loss: 0.046225, loss_s1: 0.035996, loss_fp: 0.002027, loss_freq: 0.019166
[07:28:11.922] iteration 27917: loss: 0.087164, loss_s1: 0.102837, loss_fp: 0.003749, loss_freq: 0.039180
[07:28:12.534] iteration 27918: loss: 0.039533, loss_s1: 0.027571, loss_fp: 0.001001, loss_freq: 0.021937
[07:28:13.161] iteration 27919: loss: 0.120517, loss_s1: 0.125568, loss_fp: 0.008697, loss_freq: 0.076124
[07:28:13.785] iteration 27920: loss: 0.075411, loss_s1: 0.074159, loss_fp: 0.008568, loss_freq: 0.034521
[07:28:14.395] iteration 27921: loss: 0.072040, loss_s1: 0.052900, loss_fp: 0.004691, loss_freq: 0.046448
[07:28:15.012] iteration 27922: loss: 0.081022, loss_s1: 0.079429, loss_fp: 0.005110, loss_freq: 0.046594
[07:28:15.624] iteration 27923: loss: 0.099184, loss_s1: 0.105920, loss_fp: 0.003461, loss_freq: 0.065823
[07:28:16.237] iteration 27924: loss: 0.106544, loss_s1: 0.144527, loss_fp: 0.004602, loss_freq: 0.042996
[07:28:16.850] iteration 27925: loss: 0.071322, loss_s1: 0.073100, loss_fp: 0.003575, loss_freq: 0.024447
[07:28:17.466] iteration 27926: loss: 0.066528, loss_s1: 0.061310, loss_fp: 0.009770, loss_freq: 0.031877
[07:28:18.089] iteration 27927: loss: 0.034134, loss_s1: 0.017308, loss_fp: 0.004469, loss_freq: 0.018404
[07:28:18.696] iteration 27928: loss: 0.057795, loss_s1: 0.057098, loss_fp: 0.003312, loss_freq: 0.029308
[07:28:19.304] iteration 27929: loss: 0.035011, loss_s1: 0.026182, loss_fp: 0.003256, loss_freq: 0.013685
[07:28:19.916] iteration 27930: loss: 0.037348, loss_s1: 0.027081, loss_fp: 0.000611, loss_freq: 0.014170
[07:28:20.523] iteration 27931: loss: 0.038497, loss_s1: 0.022362, loss_fp: 0.002497, loss_freq: 0.018124
[07:28:21.135] iteration 27932: loss: 0.046255, loss_s1: 0.036000, loss_fp: 0.003632, loss_freq: 0.034921
[07:28:21.739] iteration 27933: loss: 0.029785, loss_s1: 0.011434, loss_fp: 0.001333, loss_freq: 0.015508
[07:28:22.349] iteration 27934: loss: 0.090790, loss_s1: 0.057762, loss_fp: 0.005168, loss_freq: 0.092134
[07:28:22.953] iteration 27935: loss: 0.050192, loss_s1: 0.015574, loss_fp: 0.003712, loss_freq: 0.051282
[07:28:23.559] iteration 27936: loss: 0.037227, loss_s1: 0.021372, loss_fp: 0.000929, loss_freq: 0.020283
[07:28:24.227] iteration 27937: loss: 0.056224, loss_s1: 0.050123, loss_fp: 0.002472, loss_freq: 0.039182
[07:28:24.890] iteration 27938: loss: 0.049370, loss_s1: 0.038418, loss_fp: 0.001485, loss_freq: 0.019892
[07:28:25.499] iteration 27939: loss: 0.033856, loss_s1: 0.018736, loss_fp: 0.003222, loss_freq: 0.022517
[07:28:26.110] iteration 27940: loss: 0.045036, loss_s1: 0.035967, loss_fp: 0.002482, loss_freq: 0.018388
[07:28:26.721] iteration 27941: loss: 0.041524, loss_s1: 0.041697, loss_fp: 0.007253, loss_freq: 0.011011
[07:28:27.387] iteration 27942: loss: 0.089379, loss_s1: 0.051702, loss_fp: 0.001901, loss_freq: 0.083864
[07:28:28.042] iteration 27943: loss: 0.042939, loss_s1: 0.029260, loss_fp: 0.003897, loss_freq: 0.007188
[07:28:28.706] iteration 27944: loss: 0.041653, loss_s1: 0.036197, loss_fp: 0.002103, loss_freq: 0.020881
[07:28:29.353] iteration 27945: loss: 0.029753, loss_s1: 0.020531, loss_fp: 0.001388, loss_freq: 0.004827
[07:28:29.967] iteration 27946: loss: 0.050451, loss_s1: 0.055116, loss_fp: 0.002970, loss_freq: 0.021133
[07:28:30.584] iteration 27947: loss: 0.048609, loss_s1: 0.026200, loss_fp: 0.003474, loss_freq: 0.032217
[07:28:31.227] iteration 27948: loss: 0.080839, loss_s1: 0.059784, loss_fp: 0.011944, loss_freq: 0.050185
[07:28:31.843] iteration 27949: loss: 0.025247, loss_s1: 0.013605, loss_fp: 0.001279, loss_freq: 0.009965
[07:28:32.451] iteration 27950: loss: 0.030654, loss_s1: 0.010847, loss_fp: 0.002802, loss_freq: 0.019958
[07:28:33.065] iteration 27951: loss: 0.038785, loss_s1: 0.026581, loss_fp: 0.002914, loss_freq: 0.018280
[07:28:33.675] iteration 27952: loss: 0.046994, loss_s1: 0.017003, loss_fp: 0.003007, loss_freq: 0.043197
[07:28:34.309] iteration 27953: loss: 0.061602, loss_s1: 0.034086, loss_fp: 0.007252, loss_freq: 0.057925
[07:28:34.915] iteration 27954: loss: 0.048247, loss_s1: 0.047491, loss_fp: 0.004586, loss_freq: 0.012511
[07:28:35.537] iteration 27955: loss: 0.048235, loss_s1: 0.014650, loss_fp: 0.004674, loss_freq: 0.044241
[07:28:36.179] iteration 27956: loss: 0.063401, loss_s1: 0.067445, loss_fp: 0.004431, loss_freq: 0.027254
[07:28:36.799] iteration 27957: loss: 0.055778, loss_s1: 0.049946, loss_fp: 0.002563, loss_freq: 0.028622
[07:28:37.475] iteration 27958: loss: 0.051687, loss_s1: 0.047821, loss_fp: 0.008020, loss_freq: 0.024258
[07:28:38.095] iteration 27959: loss: 0.056362, loss_s1: 0.059660, loss_fp: 0.007836, loss_freq: 0.026302
[07:28:38.706] iteration 27960: loss: 0.059517, loss_s1: 0.044108, loss_fp: 0.005322, loss_freq: 0.033917
[07:28:39.317] iteration 27961: loss: 0.039547, loss_s1: 0.015755, loss_fp: 0.009500, loss_freq: 0.015545
[07:28:39.924] iteration 27962: loss: 0.060964, loss_s1: 0.046070, loss_fp: 0.006625, loss_freq: 0.040828
[07:28:40.522] iteration 27963: loss: 0.053421, loss_s1: 0.041838, loss_fp: 0.002006, loss_freq: 0.029430
[07:28:41.120] iteration 27964: loss: 0.037065, loss_s1: 0.030974, loss_fp: 0.003565, loss_freq: 0.011246
[07:28:41.715] iteration 27965: loss: 0.053550, loss_s1: 0.041737, loss_fp: 0.004773, loss_freq: 0.017740
[07:28:42.312] iteration 27966: loss: 0.056384, loss_s1: 0.041763, loss_fp: 0.005772, loss_freq: 0.022326
[07:28:42.936] iteration 27967: loss: 0.084660, loss_s1: 0.109616, loss_fp: 0.002925, loss_freq: 0.038266
[07:28:43.537] iteration 27968: loss: 0.058531, loss_s1: 0.041663, loss_fp: 0.006213, loss_freq: 0.029301
[07:28:44.148] iteration 27969: loss: 0.056915, loss_s1: 0.044041, loss_fp: 0.003767, loss_freq: 0.035869
[07:28:44.761] iteration 27970: loss: 0.034268, loss_s1: 0.026004, loss_fp: 0.002569, loss_freq: 0.008397
[07:28:45.427] iteration 27971: loss: 0.076053, loss_s1: 0.096390, loss_fp: 0.003171, loss_freq: 0.025698
[07:28:46.041] iteration 27972: loss: 0.037589, loss_s1: 0.032240, loss_fp: 0.002282, loss_freq: 0.021449
[07:28:46.650] iteration 27973: loss: 0.062821, loss_s1: 0.063309, loss_fp: 0.002218, loss_freq: 0.019864
[07:28:47.261] iteration 27974: loss: 0.046282, loss_s1: 0.032469, loss_fp: 0.004832, loss_freq: 0.034413
[07:28:47.865] iteration 27975: loss: 0.065638, loss_s1: 0.058743, loss_fp: 0.005134, loss_freq: 0.041977
[07:28:48.469] iteration 27976: loss: 0.033770, loss_s1: 0.023443, loss_fp: 0.002524, loss_freq: 0.021767
[07:28:49.078] iteration 27977: loss: 0.069187, loss_s1: 0.060921, loss_fp: 0.005469, loss_freq: 0.043145
[07:28:49.682] iteration 27978: loss: 0.061196, loss_s1: 0.041635, loss_fp: 0.002802, loss_freq: 0.050478
[07:28:50.280] iteration 27979: loss: 0.060948, loss_s1: 0.055048, loss_fp: 0.005456, loss_freq: 0.036671
[07:28:50.895] iteration 27980: loss: 0.035772, loss_s1: 0.024923, loss_fp: 0.003043, loss_freq: 0.014110
[07:28:51.503] iteration 27981: loss: 0.046851, loss_s1: 0.039842, loss_fp: 0.004726, loss_freq: 0.028301
[07:28:52.152] iteration 27982: loss: 0.047353, loss_s1: 0.031045, loss_fp: 0.002609, loss_freq: 0.021987
[07:28:52.808] iteration 27983: loss: 0.039800, loss_s1: 0.025380, loss_fp: 0.004475, loss_freq: 0.018451
[07:28:53.458] iteration 27984: loss: 0.037467, loss_s1: 0.022917, loss_fp: 0.003282, loss_freq: 0.018657
[07:28:54.111] iteration 27985: loss: 0.029437, loss_s1: 0.027366, loss_fp: 0.003792, loss_freq: 0.009241
[07:28:54.720] iteration 27986: loss: 0.059955, loss_s1: 0.064195, loss_fp: 0.003810, loss_freq: 0.020497
[07:28:55.318] iteration 27987: loss: 0.069650, loss_s1: 0.064663, loss_fp: 0.003949, loss_freq: 0.035145
[07:28:55.919] iteration 27988: loss: 0.043330, loss_s1: 0.031487, loss_fp: 0.010725, loss_freq: 0.019069
[07:28:56.538] iteration 27989: loss: 0.114806, loss_s1: 0.037157, loss_fp: 0.011768, loss_freq: 0.149483
[07:28:57.145] iteration 27990: loss: 0.053566, loss_s1: 0.044223, loss_fp: 0.005537, loss_freq: 0.033263
[07:28:57.753] iteration 27991: loss: 0.077725, loss_s1: 0.063034, loss_fp: 0.004753, loss_freq: 0.033566
[07:28:58.378] iteration 27992: loss: 0.036819, loss_s1: 0.025590, loss_fp: 0.005304, loss_freq: 0.009340
[07:28:59.000] iteration 27993: loss: 0.043316, loss_s1: 0.027598, loss_fp: 0.003821, loss_freq: 0.033746
[07:28:59.601] iteration 27994: loss: 0.054262, loss_s1: 0.072374, loss_fp: 0.009122, loss_freq: 0.007046
[07:29:00.196] iteration 27995: loss: 0.063575, loss_s1: 0.052053, loss_fp: 0.005166, loss_freq: 0.039109
[07:29:00.800] iteration 27996: loss: 0.063717, loss_s1: 0.068846, loss_fp: 0.004207, loss_freq: 0.025544
[07:29:01.404] iteration 27997: loss: 0.081931, loss_s1: 0.096862, loss_fp: 0.002961, loss_freq: 0.033141
[07:29:02.017] iteration 27998: loss: 0.075472, loss_s1: 0.080570, loss_fp: 0.003499, loss_freq: 0.029624
[07:29:02.640] iteration 27999: loss: 0.102097, loss_s1: 0.060102, loss_fp: 0.001802, loss_freq: 0.109145
[07:29:03.243] iteration 28000: loss: 0.042231, loss_s1: 0.039808, loss_fp: 0.008692, loss_freq: 0.006395
[07:29:06.950] iteration 28000 : mean_dice : 0.754770
[07:29:07.596] iteration 28001: loss: 0.038828, loss_s1: 0.025112, loss_fp: 0.006204, loss_freq: 0.010266
[07:29:08.197] iteration 28002: loss: 0.047372, loss_s1: 0.037989, loss_fp: 0.007331, loss_freq: 0.030674
[07:29:08.812] iteration 28003: loss: 0.042511, loss_s1: 0.019996, loss_fp: 0.019727, loss_freq: 0.018832
[07:29:09.421] iteration 28004: loss: 0.054964, loss_s1: 0.069455, loss_fp: 0.002790, loss_freq: 0.009073
[07:29:10.028] iteration 28005: loss: 0.072275, loss_s1: 0.048965, loss_fp: 0.010135, loss_freq: 0.054536
[07:29:10.646] iteration 28006: loss: 0.042967, loss_s1: 0.023162, loss_fp: 0.002403, loss_freq: 0.024481
[07:29:11.253] iteration 28007: loss: 0.061678, loss_s1: 0.041852, loss_fp: 0.001972, loss_freq: 0.057744
[07:29:11.858] iteration 28008: loss: 0.046383, loss_s1: 0.029275, loss_fp: 0.004575, loss_freq: 0.016654
[07:29:12.497] iteration 28009: loss: 0.064962, loss_s1: 0.087216, loss_fp: 0.000899, loss_freq: 0.017789
[07:29:13.101] iteration 28010: loss: 0.072894, loss_s1: 0.055399, loss_fp: 0.003600, loss_freq: 0.054088
[07:29:13.716] iteration 28011: loss: 0.038326, loss_s1: 0.044548, loss_fp: 0.005488, loss_freq: 0.006996
[07:29:14.321] iteration 28012: loss: 0.074301, loss_s1: 0.082904, loss_fp: 0.010316, loss_freq: 0.016732
[07:29:14.926] iteration 28013: loss: 0.064539, loss_s1: 0.056742, loss_fp: 0.008841, loss_freq: 0.027031
[07:29:15.592] iteration 28014: loss: 0.079673, loss_s1: 0.083198, loss_fp: 0.002470, loss_freq: 0.048336
[07:29:16.224] iteration 28015: loss: 0.053042, loss_s1: 0.043456, loss_fp: 0.001404, loss_freq: 0.026625
[07:29:16.834] iteration 28016: loss: 0.039684, loss_s1: 0.040749, loss_fp: 0.001299, loss_freq: 0.013484
[07:29:17.447] iteration 28017: loss: 0.036162, loss_s1: 0.018055, loss_fp: 0.002962, loss_freq: 0.014577
[07:29:18.060] iteration 28018: loss: 0.040064, loss_s1: 0.029430, loss_fp: 0.004413, loss_freq: 0.021237
[07:29:18.659] iteration 28019: loss: 0.082576, loss_s1: 0.113132, loss_fp: 0.002442, loss_freq: 0.026288
[07:29:19.266] iteration 28020: loss: 0.056577, loss_s1: 0.057692, loss_fp: 0.002784, loss_freq: 0.033272
[07:29:19.867] iteration 28021: loss: 0.070254, loss_s1: 0.069828, loss_fp: 0.004724, loss_freq: 0.026568
[07:29:20.470] iteration 28022: loss: 0.043342, loss_s1: 0.026843, loss_fp: 0.003477, loss_freq: 0.022715
[07:29:21.090] iteration 28023: loss: 0.050602, loss_s1: 0.046830, loss_fp: 0.005100, loss_freq: 0.022519
[07:29:21.696] iteration 28024: loss: 0.041486, loss_s1: 0.040216, loss_fp: 0.001315, loss_freq: 0.010574
[07:29:22.305] iteration 28025: loss: 0.034693, loss_s1: 0.025868, loss_fp: 0.007451, loss_freq: 0.008656
[07:29:22.908] iteration 28026: loss: 0.063014, loss_s1: 0.052542, loss_fp: 0.004245, loss_freq: 0.034216
[07:29:23.518] iteration 28027: loss: 0.052098, loss_s1: 0.045441, loss_fp: 0.009802, loss_freq: 0.016871
[07:29:24.117] iteration 28028: loss: 0.074376, loss_s1: 0.093306, loss_fp: 0.003605, loss_freq: 0.027809
[07:29:24.734] iteration 28029: loss: 0.042262, loss_s1: 0.019373, loss_fp: 0.003465, loss_freq: 0.038443
[07:29:25.359] iteration 28030: loss: 0.070386, loss_s1: 0.050704, loss_fp: 0.010814, loss_freq: 0.037851
[07:29:25.989] iteration 28031: loss: 0.062329, loss_s1: 0.035257, loss_fp: 0.018503, loss_freq: 0.034517
[07:29:26.592] iteration 28032: loss: 0.048300, loss_s1: 0.041195, loss_fp: 0.003874, loss_freq: 0.018697
[07:29:27.205] iteration 28033: loss: 0.081975, loss_s1: 0.072235, loss_fp: 0.005099, loss_freq: 0.058560
[07:29:27.815] iteration 28034: loss: 0.057381, loss_s1: 0.060999, loss_fp: 0.004131, loss_freq: 0.025945
[07:29:28.417] iteration 28035: loss: 0.084937, loss_s1: 0.068888, loss_fp: 0.005426, loss_freq: 0.064764
[07:29:29.023] iteration 28036: loss: 0.028921, loss_s1: 0.014112, loss_fp: 0.000935, loss_freq: 0.012655
[07:29:29.637] iteration 28037: loss: 0.035129, loss_s1: 0.031441, loss_fp: 0.002169, loss_freq: 0.014034
[07:29:30.239] iteration 28038: loss: 0.088765, loss_s1: 0.086073, loss_fp: 0.003198, loss_freq: 0.061324
[07:29:30.843] iteration 28039: loss: 0.045420, loss_s1: 0.027594, loss_fp: 0.005207, loss_freq: 0.029952
[07:29:31.469] iteration 28040: loss: 0.064395, loss_s1: 0.045470, loss_fp: 0.003780, loss_freq: 0.048904
[07:29:32.078] iteration 28041: loss: 0.043763, loss_s1: 0.034972, loss_fp: 0.003366, loss_freq: 0.013615
[07:29:32.751] iteration 28042: loss: 0.061505, loss_s1: 0.055480, loss_fp: 0.013139, loss_freq: 0.035568
[07:29:33.421] iteration 28043: loss: 0.032786, loss_s1: 0.021226, loss_fp: 0.001129, loss_freq: 0.013879
[07:29:34.070] iteration 28044: loss: 0.037609, loss_s1: 0.021598, loss_fp: 0.004913, loss_freq: 0.019730
[07:29:34.750] iteration 28045: loss: 0.035078, loss_s1: 0.028747, loss_fp: 0.001402, loss_freq: 0.012524
[07:29:35.406] iteration 28046: loss: 0.069415, loss_s1: 0.072330, loss_fp: 0.001217, loss_freq: 0.045404
[07:29:36.078] iteration 28047: loss: 0.047212, loss_s1: 0.027731, loss_fp: 0.005481, loss_freq: 0.027448
[07:29:36.752] iteration 28048: loss: 0.077465, loss_s1: 0.075915, loss_fp: 0.001771, loss_freq: 0.038572
[07:29:37.401] iteration 28049: loss: 0.067984, loss_s1: 0.070766, loss_fp: 0.001956, loss_freq: 0.034444
[07:29:38.045] iteration 28050: loss: 0.037548, loss_s1: 0.011990, loss_fp: 0.003594, loss_freq: 0.025804
[07:29:39.016] iteration 28051: loss: 0.047464, loss_s1: 0.032130, loss_fp: 0.005598, loss_freq: 0.025466
[07:29:39.685] iteration 28052: loss: 0.072140, loss_s1: 0.069782, loss_fp: 0.004124, loss_freq: 0.034121
[07:29:40.374] iteration 28053: loss: 0.051726, loss_s1: 0.039273, loss_fp: 0.003030, loss_freq: 0.036498
[07:29:41.030] iteration 28054: loss: 0.046840, loss_s1: 0.040308, loss_fp: 0.000879, loss_freq: 0.022667
[07:29:41.672] iteration 28055: loss: 0.045051, loss_s1: 0.045629, loss_fp: 0.002894, loss_freq: 0.016510
[07:29:42.289] iteration 28056: loss: 0.051850, loss_s1: 0.057462, loss_fp: 0.001557, loss_freq: 0.012874
[07:29:42.916] iteration 28057: loss: 0.045664, loss_s1: 0.037558, loss_fp: 0.004363, loss_freq: 0.020425
[07:29:43.535] iteration 28058: loss: 0.044717, loss_s1: 0.028926, loss_fp: 0.003745, loss_freq: 0.028986
[07:29:44.160] iteration 28059: loss: 0.037985, loss_s1: 0.034644, loss_fp: 0.003623, loss_freq: 0.018079
[07:29:44.780] iteration 28060: loss: 0.070900, loss_s1: 0.072852, loss_fp: 0.003064, loss_freq: 0.033450
[07:29:45.401] iteration 28061: loss: 0.066931, loss_s1: 0.076294, loss_fp: 0.002667, loss_freq: 0.026216
[07:29:46.041] iteration 28062: loss: 0.052303, loss_s1: 0.030823, loss_fp: 0.002240, loss_freq: 0.020197
[07:29:46.662] iteration 28063: loss: 0.049455, loss_s1: 0.027318, loss_fp: 0.002534, loss_freq: 0.038530
[07:29:47.312] iteration 28064: loss: 0.069779, loss_s1: 0.091303, loss_fp: 0.003533, loss_freq: 0.016136
[07:29:47.940] iteration 28065: loss: 0.069532, loss_s1: 0.069164, loss_fp: 0.008744, loss_freq: 0.029555
[07:29:48.566] iteration 28066: loss: 0.043181, loss_s1: 0.019680, loss_fp: 0.003285, loss_freq: 0.028469
[07:29:49.168] iteration 28067: loss: 0.072513, loss_s1: 0.082331, loss_fp: 0.005576, loss_freq: 0.039401
[07:29:49.797] iteration 28068: loss: 0.046408, loss_s1: 0.048702, loss_fp: 0.003252, loss_freq: 0.009198
[07:29:50.403] iteration 28069: loss: 0.068785, loss_s1: 0.068626, loss_fp: 0.008896, loss_freq: 0.033572
[07:29:51.030] iteration 28070: loss: 0.045015, loss_s1: 0.035184, loss_fp: 0.001525, loss_freq: 0.020214
[07:29:51.663] iteration 28071: loss: 0.039044, loss_s1: 0.020425, loss_fp: 0.004093, loss_freq: 0.023478
[07:29:52.295] iteration 28072: loss: 0.048384, loss_s1: 0.035574, loss_fp: 0.003035, loss_freq: 0.035678
[07:29:52.918] iteration 28073: loss: 0.054373, loss_s1: 0.038069, loss_fp: 0.008031, loss_freq: 0.029644
[07:29:53.551] iteration 28074: loss: 0.040496, loss_s1: 0.039928, loss_fp: 0.001586, loss_freq: 0.018066
[07:29:54.175] iteration 28075: loss: 0.075839, loss_s1: 0.067344, loss_fp: 0.008385, loss_freq: 0.045726
[07:29:54.775] iteration 28076: loss: 0.055283, loss_s1: 0.041539, loss_fp: 0.010871, loss_freq: 0.033398
[07:29:55.396] iteration 28077: loss: 0.055162, loss_s1: 0.036261, loss_fp: 0.005396, loss_freq: 0.036676
[07:29:56.044] iteration 28078: loss: 0.127314, loss_s1: 0.097408, loss_fp: 0.006062, loss_freq: 0.115137
[07:29:56.688] iteration 28079: loss: 0.061589, loss_s1: 0.056189, loss_fp: 0.002408, loss_freq: 0.035071
[07:29:57.335] iteration 28080: loss: 0.067958, loss_s1: 0.066932, loss_fp: 0.004892, loss_freq: 0.030060
[07:29:57.994] iteration 28081: loss: 0.055806, loss_s1: 0.019273, loss_fp: 0.007873, loss_freq: 0.065913
[07:29:58.641] iteration 28082: loss: 0.083331, loss_s1: 0.072474, loss_fp: 0.003911, loss_freq: 0.051107
[07:29:59.288] iteration 28083: loss: 0.051617, loss_s1: 0.037042, loss_fp: 0.015200, loss_freq: 0.020570
[07:29:59.922] iteration 28084: loss: 0.041416, loss_s1: 0.025417, loss_fp: 0.003994, loss_freq: 0.022410
[07:30:00.526] iteration 28085: loss: 0.050621, loss_s1: 0.048303, loss_fp: 0.003794, loss_freq: 0.023194
[07:30:01.143] iteration 28086: loss: 0.065823, loss_s1: 0.045417, loss_fp: 0.003504, loss_freq: 0.024825
[07:30:01.761] iteration 28087: loss: 0.053570, loss_s1: 0.030977, loss_fp: 0.002574, loss_freq: 0.043020
[07:30:02.399] iteration 28088: loss: 0.043742, loss_s1: 0.038952, loss_fp: 0.002469, loss_freq: 0.013932
[07:30:03.021] iteration 28089: loss: 0.056771, loss_s1: 0.035548, loss_fp: 0.006130, loss_freq: 0.043842
[07:30:03.639] iteration 28090: loss: 0.062140, loss_s1: 0.058496, loss_fp: 0.002394, loss_freq: 0.033900
[07:30:04.260] iteration 28091: loss: 0.083558, loss_s1: 0.075668, loss_fp: 0.005022, loss_freq: 0.045883
[07:30:04.874] iteration 28092: loss: 0.068330, loss_s1: 0.043129, loss_fp: 0.006140, loss_freq: 0.052297
[07:30:05.484] iteration 28093: loss: 0.096590, loss_s1: 0.108936, loss_fp: 0.008244, loss_freq: 0.050146
[07:30:06.091] iteration 28094: loss: 0.065931, loss_s1: 0.052923, loss_fp: 0.002376, loss_freq: 0.054451
[07:30:06.695] iteration 28095: loss: 0.058893, loss_s1: 0.045235, loss_fp: 0.003378, loss_freq: 0.024817
[07:30:07.309] iteration 28096: loss: 0.089424, loss_s1: 0.105882, loss_fp: 0.006621, loss_freq: 0.033409
[07:30:07.917] iteration 28097: loss: 0.056471, loss_s1: 0.046575, loss_fp: 0.007154, loss_freq: 0.031850
[07:30:08.594] iteration 28098: loss: 0.052790, loss_s1: 0.038399, loss_fp: 0.001203, loss_freq: 0.040927
[07:30:09.250] iteration 28099: loss: 0.037013, loss_s1: 0.022681, loss_fp: 0.004821, loss_freq: 0.010863
[07:30:09.887] iteration 28100: loss: 0.037524, loss_s1: 0.024930, loss_fp: 0.001304, loss_freq: 0.015360
[07:30:10.532] iteration 28101: loss: 0.037093, loss_s1: 0.012685, loss_fp: 0.002038, loss_freq: 0.019885
[07:30:11.200] iteration 28102: loss: 0.050968, loss_s1: 0.057710, loss_fp: 0.003842, loss_freq: 0.019628
[07:30:11.850] iteration 28103: loss: 0.038777, loss_s1: 0.024689, loss_fp: 0.004021, loss_freq: 0.013987
[07:30:12.495] iteration 28104: loss: 0.071982, loss_s1: 0.082045, loss_fp: 0.008427, loss_freq: 0.019363
[07:30:13.141] iteration 28105: loss: 0.057855, loss_s1: 0.025964, loss_fp: 0.012855, loss_freq: 0.030050
[07:30:13.763] iteration 28106: loss: 0.036322, loss_s1: 0.019674, loss_fp: 0.001423, loss_freq: 0.021204
[07:30:14.408] iteration 28107: loss: 0.036253, loss_s1: 0.022521, loss_fp: 0.001159, loss_freq: 0.024064
[07:30:15.018] iteration 28108: loss: 0.050813, loss_s1: 0.042988, loss_fp: 0.004064, loss_freq: 0.019169
[07:30:15.635] iteration 28109: loss: 0.038233, loss_s1: 0.023021, loss_fp: 0.003422, loss_freq: 0.025619
[07:30:16.251] iteration 28110: loss: 0.067786, loss_s1: 0.066671, loss_fp: 0.002662, loss_freq: 0.031867
[07:30:16.877] iteration 28111: loss: 0.033691, loss_s1: 0.031360, loss_fp: 0.003678, loss_freq: 0.007106
[07:30:17.506] iteration 28112: loss: 0.064270, loss_s1: 0.056894, loss_fp: 0.001760, loss_freq: 0.031325
[07:30:18.125] iteration 28113: loss: 0.046919, loss_s1: 0.047371, loss_fp: 0.002427, loss_freq: 0.012742
[07:30:18.741] iteration 28114: loss: 0.036333, loss_s1: 0.025951, loss_fp: 0.005981, loss_freq: 0.012656
[07:30:19.350] iteration 28115: loss: 0.084224, loss_s1: 0.119295, loss_fp: 0.002282, loss_freq: 0.008581
[07:30:19.962] iteration 28116: loss: 0.041025, loss_s1: 0.026016, loss_fp: 0.002771, loss_freq: 0.033346
[07:30:20.574] iteration 28117: loss: 0.042788, loss_s1: 0.043309, loss_fp: 0.001923, loss_freq: 0.009077
[07:30:21.176] iteration 28118: loss: 0.094130, loss_s1: 0.085865, loss_fp: 0.024761, loss_freq: 0.054533
[07:30:21.773] iteration 28119: loss: 0.033581, loss_s1: 0.026636, loss_fp: 0.004300, loss_freq: 0.011161
[07:30:22.373] iteration 28120: loss: 0.059373, loss_s1: 0.044099, loss_fp: 0.018274, loss_freq: 0.032891
[07:30:22.980] iteration 28121: loss: 0.082775, loss_s1: 0.079958, loss_fp: 0.006599, loss_freq: 0.042805
[07:30:23.597] iteration 28122: loss: 0.056803, loss_s1: 0.051535, loss_fp: 0.005195, loss_freq: 0.027125
[07:30:24.204] iteration 28123: loss: 0.046717, loss_s1: 0.025631, loss_fp: 0.003673, loss_freq: 0.039308
[07:30:24.825] iteration 28124: loss: 0.045502, loss_s1: 0.046783, loss_fp: 0.003570, loss_freq: 0.014173
[07:30:25.653] iteration 28125: loss: 0.057629, loss_s1: 0.031804, loss_fp: 0.002134, loss_freq: 0.048762
[07:30:26.357] iteration 28126: loss: 0.070896, loss_s1: 0.080032, loss_fp: 0.005697, loss_freq: 0.016335
[07:30:27.087] iteration 28127: loss: 0.041812, loss_s1: 0.028017, loss_fp: 0.001561, loss_freq: 0.029005
[07:30:27.821] iteration 28128: loss: 0.066867, loss_s1: 0.078606, loss_fp: 0.006791, loss_freq: 0.025375
[07:30:28.527] iteration 28129: loss: 0.062459, loss_s1: 0.051247, loss_fp: 0.002872, loss_freq: 0.051342
[07:30:29.150] iteration 28130: loss: 0.050840, loss_s1: 0.033769, loss_fp: 0.005955, loss_freq: 0.029854
[07:30:29.791] iteration 28131: loss: 0.036882, loss_s1: 0.025838, loss_fp: 0.003396, loss_freq: 0.012280
[07:30:30.518] iteration 28132: loss: 0.058698, loss_s1: 0.055062, loss_fp: 0.006794, loss_freq: 0.023737
[07:30:31.157] iteration 28133: loss: 0.056441, loss_s1: 0.068698, loss_fp: 0.006049, loss_freq: 0.013327
[07:30:31.911] iteration 28134: loss: 0.044271, loss_s1: 0.043051, loss_fp: 0.002295, loss_freq: 0.016511
[07:30:32.535] iteration 28135: loss: 0.057057, loss_s1: 0.050653, loss_fp: 0.002333, loss_freq: 0.025617
[07:30:33.197] iteration 28136: loss: 0.073353, loss_s1: 0.064626, loss_fp: 0.004355, loss_freq: 0.044938
[07:30:33.830] iteration 28137: loss: 0.041613, loss_s1: 0.039233, loss_fp: 0.002093, loss_freq: 0.021111
[07:30:34.513] iteration 28138: loss: 0.056341, loss_s1: 0.065686, loss_fp: 0.002836, loss_freq: 0.016162
[07:30:35.158] iteration 28139: loss: 0.084230, loss_s1: 0.074639, loss_fp: 0.002893, loss_freq: 0.063799
[07:30:35.810] iteration 28140: loss: 0.041410, loss_s1: 0.039243, loss_fp: 0.001484, loss_freq: 0.011089
[07:30:36.567] iteration 28141: loss: 0.089491, loss_s1: 0.088890, loss_fp: 0.004860, loss_freq: 0.057575
[07:30:37.224] iteration 28142: loss: 0.053664, loss_s1: 0.047923, loss_fp: 0.002287, loss_freq: 0.037749
[07:30:37.822] iteration 28143: loss: 0.053721, loss_s1: 0.045056, loss_fp: 0.004157, loss_freq: 0.020866
[07:30:38.458] iteration 28144: loss: 0.051035, loss_s1: 0.037789, loss_fp: 0.008362, loss_freq: 0.025448
[07:30:39.061] iteration 28145: loss: 0.062055, loss_s1: 0.062047, loss_fp: 0.007694, loss_freq: 0.026745
[07:30:39.663] iteration 28146: loss: 0.042379, loss_s1: 0.031096, loss_fp: 0.002433, loss_freq: 0.029403
[07:30:40.278] iteration 28147: loss: 0.071878, loss_s1: 0.093217, loss_fp: 0.003331, loss_freq: 0.011096
[07:30:40.888] iteration 28148: loss: 0.082234, loss_s1: 0.072826, loss_fp: 0.018208, loss_freq: 0.044864
[07:30:41.501] iteration 28149: loss: 0.057565, loss_s1: 0.030411, loss_fp: 0.004427, loss_freq: 0.048813
[07:30:42.107] iteration 28150: loss: 0.050518, loss_s1: 0.047323, loss_fp: 0.009514, loss_freq: 0.013126
[07:30:42.712] iteration 28151: loss: 0.058181, loss_s1: 0.059948, loss_fp: 0.004994, loss_freq: 0.031063
[07:30:43.328] iteration 28152: loss: 0.058979, loss_s1: 0.033812, loss_fp: 0.008380, loss_freq: 0.045058
[07:30:43.975] iteration 28153: loss: 0.035809, loss_s1: 0.020460, loss_fp: 0.003753, loss_freq: 0.023448
[07:30:44.586] iteration 28154: loss: 0.037626, loss_s1: 0.023784, loss_fp: 0.001755, loss_freq: 0.018259
[07:30:45.190] iteration 28155: loss: 0.036601, loss_s1: 0.018956, loss_fp: 0.002426, loss_freq: 0.019243
[07:30:45.795] iteration 28156: loss: 0.078483, loss_s1: 0.092899, loss_fp: 0.005602, loss_freq: 0.024856
[07:30:46.400] iteration 28157: loss: 0.046785, loss_s1: 0.043687, loss_fp: 0.002425, loss_freq: 0.017788
[07:30:47.012] iteration 28158: loss: 0.058234, loss_s1: 0.054655, loss_fp: 0.003134, loss_freq: 0.031955
[07:30:47.622] iteration 28159: loss: 0.090194, loss_s1: 0.054626, loss_fp: 0.007928, loss_freq: 0.087032
[07:30:48.231] iteration 28160: loss: 0.048730, loss_s1: 0.032733, loss_fp: 0.002983, loss_freq: 0.036977
[07:30:48.835] iteration 28161: loss: 0.044115, loss_s1: 0.039802, loss_fp: 0.006914, loss_freq: 0.011672
[07:30:49.439] iteration 28162: loss: 0.045116, loss_s1: 0.042545, loss_fp: 0.006653, loss_freq: 0.012986
[07:30:50.100] iteration 28163: loss: 0.045348, loss_s1: 0.038926, loss_fp: 0.003756, loss_freq: 0.025317
[07:30:50.755] iteration 28164: loss: 0.026505, loss_s1: 0.014081, loss_fp: 0.001854, loss_freq: 0.016562
[07:30:51.410] iteration 28165: loss: 0.072991, loss_s1: 0.067498, loss_fp: 0.003965, loss_freq: 0.044877
[07:30:52.218] iteration 28166: loss: 0.072090, loss_s1: 0.064516, loss_fp: 0.007486, loss_freq: 0.045466
[07:30:52.887] iteration 28167: loss: 0.035120, loss_s1: 0.018517, loss_fp: 0.003032, loss_freq: 0.016924
[07:30:53.729] iteration 28168: loss: 0.059026, loss_s1: 0.052784, loss_fp: 0.007202, loss_freq: 0.035372
[07:30:54.348] iteration 28169: loss: 0.059563, loss_s1: 0.039194, loss_fp: 0.002135, loss_freq: 0.050515
[07:30:55.024] iteration 28170: loss: 0.065026, loss_s1: 0.080559, loss_fp: 0.005286, loss_freq: 0.006662
[07:30:55.663] iteration 28171: loss: 0.039724, loss_s1: 0.030411, loss_fp: 0.001892, loss_freq: 0.009574
[07:30:56.300] iteration 28172: loss: 0.057498, loss_s1: 0.042410, loss_fp: 0.004800, loss_freq: 0.045782
[07:30:56.908] iteration 28173: loss: 0.115439, loss_s1: 0.129925, loss_fp: 0.009595, loss_freq: 0.060515
[07:30:57.527] iteration 28174: loss: 0.042589, loss_s1: 0.035763, loss_fp: 0.013197, loss_freq: 0.008387
[07:30:58.133] iteration 28175: loss: 0.085383, loss_s1: 0.095569, loss_fp: 0.007974, loss_freq: 0.033364
[07:30:58.737] iteration 28176: loss: 0.038508, loss_s1: 0.023761, loss_fp: 0.002648, loss_freq: 0.021112
[07:30:59.343] iteration 28177: loss: 0.041114, loss_s1: 0.028167, loss_fp: 0.002250, loss_freq: 0.029362
[07:30:59.969] iteration 28178: loss: 0.045503, loss_s1: 0.029280, loss_fp: 0.003572, loss_freq: 0.008909
[07:31:00.579] iteration 28179: loss: 0.071671, loss_s1: 0.057357, loss_fp: 0.007813, loss_freq: 0.056484
[07:31:01.206] iteration 28180: loss: 0.077223, loss_s1: 0.054939, loss_fp: 0.011249, loss_freq: 0.063755
[07:31:01.816] iteration 28181: loss: 0.046842, loss_s1: 0.049761, loss_fp: 0.005154, loss_freq: 0.016997
[07:31:02.431] iteration 28182: loss: 0.067684, loss_s1: 0.068344, loss_fp: 0.007809, loss_freq: 0.029198
[07:31:03.053] iteration 28183: loss: 0.106745, loss_s1: 0.123012, loss_fp: 0.008488, loss_freq: 0.041239
[07:31:03.670] iteration 28184: loss: 0.058904, loss_s1: 0.061619, loss_fp: 0.001289, loss_freq: 0.025468
[07:31:04.298] iteration 28185: loss: 0.048228, loss_s1: 0.036003, loss_fp: 0.002188, loss_freq: 0.028534
[07:31:04.917] iteration 28186: loss: 0.032263, loss_s1: 0.028114, loss_fp: 0.001006, loss_freq: 0.014932
[07:31:05.538] iteration 28187: loss: 0.062226, loss_s1: 0.054853, loss_fp: 0.004625, loss_freq: 0.013943
[07:31:06.146] iteration 28188: loss: 0.059918, loss_s1: 0.051757, loss_fp: 0.008643, loss_freq: 0.029562
[07:31:06.777] iteration 28189: loss: 0.087371, loss_s1: 0.101128, loss_fp: 0.003743, loss_freq: 0.042773
[07:31:07.385] iteration 28190: loss: 0.060019, loss_s1: 0.053421, loss_fp: 0.005994, loss_freq: 0.042103
[07:31:07.998] iteration 28191: loss: 0.052091, loss_s1: 0.033280, loss_fp: 0.004127, loss_freq: 0.033315
[07:31:08.611] iteration 28192: loss: 0.052713, loss_s1: 0.055938, loss_fp: 0.000883, loss_freq: 0.015852
[07:31:09.229] iteration 28193: loss: 0.072626, loss_s1: 0.090030, loss_fp: 0.002407, loss_freq: 0.028696
[07:31:09.890] iteration 28194: loss: 0.047157, loss_s1: 0.051521, loss_fp: 0.001529, loss_freq: 0.010238
[07:31:10.567] iteration 28195: loss: 0.047999, loss_s1: 0.055736, loss_fp: 0.002549, loss_freq: 0.016081
[07:31:11.209] iteration 28196: loss: 0.058646, loss_s1: 0.034802, loss_fp: 0.001106, loss_freq: 0.047697
[07:31:11.847] iteration 28197: loss: 0.035861, loss_s1: 0.027225, loss_fp: 0.001461, loss_freq: 0.014561
[07:31:12.458] iteration 28198: loss: 0.053181, loss_s1: 0.045881, loss_fp: 0.002813, loss_freq: 0.029439
[07:31:13.085] iteration 28199: loss: 0.057122, loss_s1: 0.068397, loss_fp: 0.000842, loss_freq: 0.021380
[07:31:13.694] iteration 28200: loss: 0.049285, loss_s1: 0.041591, loss_fp: 0.011168, loss_freq: 0.015055
[07:31:16.843] iteration 28200 : mean_dice : 0.746750
[07:31:17.491] iteration 28201: loss: 0.060659, loss_s1: 0.044120, loss_fp: 0.005097, loss_freq: 0.030611
[07:31:18.106] iteration 28202: loss: 0.075911, loss_s1: 0.088373, loss_fp: 0.003312, loss_freq: 0.025223
[07:31:18.771] iteration 28203: loss: 0.060746, loss_s1: 0.045859, loss_fp: 0.004869, loss_freq: 0.043428
[07:31:19.440] iteration 28204: loss: 0.070013, loss_s1: 0.055485, loss_fp: 0.006309, loss_freq: 0.030970
[07:31:20.104] iteration 28205: loss: 0.073377, loss_s1: 0.067735, loss_fp: 0.002494, loss_freq: 0.041548
[07:31:20.770] iteration 28206: loss: 0.031851, loss_s1: 0.022097, loss_fp: 0.002566, loss_freq: 0.012493
[07:31:21.387] iteration 28207: loss: 0.045947, loss_s1: 0.048012, loss_fp: 0.002278, loss_freq: 0.022124
[07:31:21.989] iteration 28208: loss: 0.056636, loss_s1: 0.053013, loss_fp: 0.004202, loss_freq: 0.030650
[07:31:22.598] iteration 28209: loss: 0.064560, loss_s1: 0.063325, loss_fp: 0.008412, loss_freq: 0.026549
[07:31:23.203] iteration 28210: loss: 0.071823, loss_s1: 0.061922, loss_fp: 0.002354, loss_freq: 0.038388
[07:31:23.808] iteration 28211: loss: 0.032643, loss_s1: 0.024834, loss_fp: 0.002583, loss_freq: 0.009081
[07:31:24.443] iteration 28212: loss: 0.056141, loss_s1: 0.048057, loss_fp: 0.010790, loss_freq: 0.033915
[07:31:25.084] iteration 28213: loss: 0.030258, loss_s1: 0.012370, loss_fp: 0.001244, loss_freq: 0.011079
[07:31:25.700] iteration 28214: loss: 0.042802, loss_s1: 0.035311, loss_fp: 0.002933, loss_freq: 0.014591
[07:31:26.323] iteration 28215: loss: 0.034970, loss_s1: 0.020750, loss_fp: 0.001091, loss_freq: 0.013820
[07:31:26.958] iteration 28216: loss: 0.059438, loss_s1: 0.065124, loss_fp: 0.002388, loss_freq: 0.028305
[07:31:27.578] iteration 28217: loss: 0.051469, loss_s1: 0.048079, loss_fp: 0.002906, loss_freq: 0.021258
[07:31:28.192] iteration 28218: loss: 0.075114, loss_s1: 0.055987, loss_fp: 0.008609, loss_freq: 0.047503
[07:31:28.796] iteration 28219: loss: 0.068364, loss_s1: 0.059485, loss_fp: 0.011827, loss_freq: 0.036141
[07:31:29.394] iteration 28220: loss: 0.099938, loss_s1: 0.129056, loss_fp: 0.016210, loss_freq: 0.019158
[07:31:30.292] iteration 28221: loss: 0.079016, loss_s1: 0.091540, loss_fp: 0.003461, loss_freq: 0.028002
[07:31:30.939] iteration 28222: loss: 0.059251, loss_s1: 0.045683, loss_fp: 0.005062, loss_freq: 0.026427
[07:31:31.567] iteration 28223: loss: 0.043208, loss_s1: 0.029135, loss_fp: 0.002274, loss_freq: 0.030933
[07:31:32.179] iteration 28224: loss: 0.039257, loss_s1: 0.036508, loss_fp: 0.001761, loss_freq: 0.013248
[07:31:32.794] iteration 28225: loss: 0.041670, loss_s1: 0.032936, loss_fp: 0.014165, loss_freq: 0.015211
[07:31:33.400] iteration 28226: loss: 0.091198, loss_s1: 0.110549, loss_fp: 0.003487, loss_freq: 0.041035
[07:31:34.005] iteration 28227: loss: 0.051727, loss_s1: 0.034482, loss_fp: 0.006620, loss_freq: 0.031057
[07:31:34.611] iteration 28228: loss: 0.047436, loss_s1: 0.038582, loss_fp: 0.005060, loss_freq: 0.021657
[07:31:35.223] iteration 28229: loss: 0.049768, loss_s1: 0.040528, loss_fp: 0.008478, loss_freq: 0.029401
[07:31:35.827] iteration 28230: loss: 0.079082, loss_s1: 0.096117, loss_fp: 0.007357, loss_freq: 0.025513
[07:31:36.442] iteration 28231: loss: 0.075008, loss_s1: 0.052000, loss_fp: 0.003269, loss_freq: 0.058117
[07:31:37.058] iteration 28232: loss: 0.100747, loss_s1: 0.091176, loss_fp: 0.002320, loss_freq: 0.076249
[07:31:37.668] iteration 28233: loss: 0.045114, loss_s1: 0.035884, loss_fp: 0.000810, loss_freq: 0.027949
[07:31:38.275] iteration 28234: loss: 0.070450, loss_s1: 0.074981, loss_fp: 0.010465, loss_freq: 0.029444
[07:31:38.873] iteration 28235: loss: 0.062480, loss_s1: 0.060840, loss_fp: 0.001719, loss_freq: 0.026485
[07:31:39.485] iteration 28236: loss: 0.046851, loss_s1: 0.044082, loss_fp: 0.000766, loss_freq: 0.010609
[07:31:40.089] iteration 28237: loss: 0.085264, loss_s1: 0.050815, loss_fp: 0.005528, loss_freq: 0.095579
[07:31:40.691] iteration 28238: loss: 0.039146, loss_s1: 0.029764, loss_fp: 0.003309, loss_freq: 0.018085
[07:31:41.302] iteration 28239: loss: 0.089428, loss_s1: 0.091888, loss_fp: 0.014657, loss_freq: 0.044635
[07:31:41.908] iteration 28240: loss: 0.049377, loss_s1: 0.050583, loss_fp: 0.004422, loss_freq: 0.011846
[07:31:42.525] iteration 28241: loss: 0.037813, loss_s1: 0.019954, loss_fp: 0.003506, loss_freq: 0.024371
[07:31:43.129] iteration 28242: loss: 0.051491, loss_s1: 0.037150, loss_fp: 0.005268, loss_freq: 0.040723
[07:31:43.749] iteration 28243: loss: 0.052055, loss_s1: 0.026997, loss_fp: 0.004242, loss_freq: 0.026534
[07:31:44.361] iteration 28244: loss: 0.047645, loss_s1: 0.045732, loss_fp: 0.003913, loss_freq: 0.023930
[07:31:44.963] iteration 28245: loss: 0.073364, loss_s1: 0.070012, loss_fp: 0.004470, loss_freq: 0.045882
[07:31:45.580] iteration 28246: loss: 0.044028, loss_s1: 0.032199, loss_fp: 0.001412, loss_freq: 0.034333
[07:31:46.232] iteration 28247: loss: 0.037718, loss_s1: 0.029095, loss_fp: 0.001121, loss_freq: 0.008651
[07:31:46.840] iteration 28248: loss: 0.086800, loss_s1: 0.084678, loss_fp: 0.008763, loss_freq: 0.033719
[07:31:47.441] iteration 28249: loss: 0.044719, loss_s1: 0.038886, loss_fp: 0.003244, loss_freq: 0.019703
[07:31:48.083] iteration 28250: loss: 0.050004, loss_s1: 0.023820, loss_fp: 0.006266, loss_freq: 0.034056
[07:31:48.692] iteration 28251: loss: 0.049922, loss_s1: 0.035501, loss_fp: 0.008168, loss_freq: 0.033030
[07:31:49.303] iteration 28252: loss: 0.087341, loss_s1: 0.090725, loss_fp: 0.002445, loss_freq: 0.046690
[07:31:49.901] iteration 28253: loss: 0.073295, loss_s1: 0.090692, loss_fp: 0.001791, loss_freq: 0.029109
[07:31:50.515] iteration 28254: loss: 0.036476, loss_s1: 0.023575, loss_fp: 0.002476, loss_freq: 0.010592
[07:31:51.114] iteration 28255: loss: 0.039146, loss_s1: 0.033001, loss_fp: 0.006508, loss_freq: 0.019305
[07:31:51.728] iteration 28256: loss: 0.045708, loss_s1: 0.032311, loss_fp: 0.007056, loss_freq: 0.015181
[07:31:52.339] iteration 28257: loss: 0.062152, loss_s1: 0.039051, loss_fp: 0.008956, loss_freq: 0.045220
[07:31:52.940] iteration 28258: loss: 0.041815, loss_s1: 0.036583, loss_fp: 0.002168, loss_freq: 0.021317
[07:31:53.542] iteration 28259: loss: 0.103148, loss_s1: 0.093745, loss_fp: 0.006752, loss_freq: 0.063860
[07:31:54.144] iteration 28260: loss: 0.064622, loss_s1: 0.072071, loss_fp: 0.007378, loss_freq: 0.026982
[07:31:54.745] iteration 28261: loss: 0.137186, loss_s1: 0.176583, loss_fp: 0.001594, loss_freq: 0.064114
[07:31:55.389] iteration 28262: loss: 0.043559, loss_s1: 0.025083, loss_fp: 0.006256, loss_freq: 0.027576
[07:31:55.995] iteration 28263: loss: 0.088728, loss_s1: 0.118167, loss_fp: 0.002386, loss_freq: 0.030507
[07:31:56.607] iteration 28264: loss: 0.079103, loss_s1: 0.078986, loss_fp: 0.006459, loss_freq: 0.053014
[07:31:57.216] iteration 28265: loss: 0.049800, loss_s1: 0.046559, loss_fp: 0.003020, loss_freq: 0.017129
[07:31:57.828] iteration 28266: loss: 0.069257, loss_s1: 0.050266, loss_fp: 0.008385, loss_freq: 0.049250
[07:31:58.435] iteration 28267: loss: 0.055953, loss_s1: 0.037756, loss_fp: 0.001864, loss_freq: 0.033949
[07:31:59.037] iteration 28268: loss: 0.044409, loss_s1: 0.044389, loss_fp: 0.002448, loss_freq: 0.015922
[07:31:59.634] iteration 28269: loss: 0.039616, loss_s1: 0.036520, loss_fp: 0.001177, loss_freq: 0.016083
[07:32:00.229] iteration 28270: loss: 0.040856, loss_s1: 0.022572, loss_fp: 0.003361, loss_freq: 0.019842
[07:32:00.828] iteration 28271: loss: 0.044961, loss_s1: 0.017961, loss_fp: 0.005587, loss_freq: 0.029502
[07:32:01.448] iteration 28272: loss: 0.052733, loss_s1: 0.046910, loss_fp: 0.002442, loss_freq: 0.040142
[07:32:02.050] iteration 28273: loss: 0.032444, loss_s1: 0.012195, loss_fp: 0.003389, loss_freq: 0.012924
[07:32:02.668] iteration 28274: loss: 0.062109, loss_s1: 0.076453, loss_fp: 0.004739, loss_freq: 0.016112
[07:32:03.273] iteration 28275: loss: 0.032682, loss_s1: 0.016750, loss_fp: 0.001380, loss_freq: 0.017273
[07:32:03.884] iteration 28276: loss: 0.040033, loss_s1: 0.028584, loss_fp: 0.002509, loss_freq: 0.021334
[07:32:04.491] iteration 28277: loss: 0.045063, loss_s1: 0.039114, loss_fp: 0.003284, loss_freq: 0.028154
[07:32:05.088] iteration 28278: loss: 0.072099, loss_s1: 0.059956, loss_fp: 0.006431, loss_freq: 0.038610
[07:32:05.688] iteration 28279: loss: 0.045378, loss_s1: 0.013797, loss_fp: 0.002285, loss_freq: 0.048216
[07:32:06.289] iteration 28280: loss: 0.053392, loss_s1: 0.024786, loss_fp: 0.009055, loss_freq: 0.041702
[07:32:06.889] iteration 28281: loss: 0.018967, loss_s1: 0.008339, loss_fp: 0.000865, loss_freq: 0.004440
[07:32:07.488] iteration 28282: loss: 0.050682, loss_s1: 0.032066, loss_fp: 0.005944, loss_freq: 0.036739
[07:32:08.117] iteration 28283: loss: 0.045115, loss_s1: 0.044366, loss_fp: 0.002318, loss_freq: 0.012823
[07:32:08.736] iteration 28284: loss: 0.042472, loss_s1: 0.031374, loss_fp: 0.002846, loss_freq: 0.021749
[07:32:09.347] iteration 28285: loss: 0.029722, loss_s1: 0.011621, loss_fp: 0.002751, loss_freq: 0.012617
[07:32:09.953] iteration 28286: loss: 0.047203, loss_s1: 0.034678, loss_fp: 0.001310, loss_freq: 0.037242
[07:32:10.559] iteration 28287: loss: 0.048125, loss_s1: 0.037101, loss_fp: 0.001135, loss_freq: 0.024272
[07:32:11.171] iteration 28288: loss: 0.097225, loss_s1: 0.083405, loss_fp: 0.007830, loss_freq: 0.077167
[07:32:11.775] iteration 28289: loss: 0.036187, loss_s1: 0.014912, loss_fp: 0.001480, loss_freq: 0.024822
[07:32:12.378] iteration 28290: loss: 0.043939, loss_s1: 0.033252, loss_fp: 0.003311, loss_freq: 0.029078
[07:32:12.978] iteration 28291: loss: 0.074451, loss_s1: 0.084120, loss_fp: 0.002000, loss_freq: 0.033274
[07:32:13.576] iteration 28292: loss: 0.042478, loss_s1: 0.017743, loss_fp: 0.004287, loss_freq: 0.029490
[07:32:14.199] iteration 28293: loss: 0.071966, loss_s1: 0.053057, loss_fp: 0.006507, loss_freq: 0.058859
[07:32:14.800] iteration 28294: loss: 0.085887, loss_s1: 0.110656, loss_fp: 0.008043, loss_freq: 0.023434
[07:32:15.402] iteration 28295: loss: 0.068013, loss_s1: 0.050042, loss_fp: 0.002275, loss_freq: 0.057711
[07:32:16.030] iteration 28296: loss: 0.059226, loss_s1: 0.045174, loss_fp: 0.005375, loss_freq: 0.032867
[07:32:16.625] iteration 28297: loss: 0.081113, loss_s1: 0.082336, loss_fp: 0.003810, loss_freq: 0.040261
[07:32:17.221] iteration 28298: loss: 0.077575, loss_s1: 0.074524, loss_fp: 0.007039, loss_freq: 0.048674
[07:32:17.814] iteration 28299: loss: 0.052133, loss_s1: 0.032337, loss_fp: 0.005157, loss_freq: 0.045833
[07:32:18.413] iteration 28300: loss: 0.058443, loss_s1: 0.038286, loss_fp: 0.006922, loss_freq: 0.040282
[07:32:19.011] iteration 28301: loss: 0.046783, loss_s1: 0.049005, loss_fp: 0.002037, loss_freq: 0.009184
[07:32:19.630] iteration 28302: loss: 0.059685, loss_s1: 0.047740, loss_fp: 0.007852, loss_freq: 0.031568
[07:32:20.234] iteration 28303: loss: 0.051939, loss_s1: 0.045444, loss_fp: 0.003223, loss_freq: 0.029560
[07:32:20.851] iteration 28304: loss: 0.040649, loss_s1: 0.028799, loss_fp: 0.005266, loss_freq: 0.016839
[07:32:21.456] iteration 28305: loss: 0.060202, loss_s1: 0.057050, loss_fp: 0.001326, loss_freq: 0.030314
[07:32:22.065] iteration 28306: loss: 0.050866, loss_s1: 0.050593, loss_fp: 0.002761, loss_freq: 0.019143
[07:32:22.665] iteration 28307: loss: 0.088930, loss_s1: 0.081585, loss_fp: 0.004961, loss_freq: 0.067631
[07:32:23.367] iteration 28308: loss: 0.060827, loss_s1: 0.073164, loss_fp: 0.002355, loss_freq: 0.014271
[07:32:23.996] iteration 28309: loss: 0.040455, loss_s1: 0.023222, loss_fp: 0.002628, loss_freq: 0.027089
[07:32:24.596] iteration 28310: loss: 0.027909, loss_s1: 0.016896, loss_fp: 0.003167, loss_freq: 0.004431
[07:32:25.197] iteration 28311: loss: 0.055366, loss_s1: 0.039812, loss_fp: 0.005062, loss_freq: 0.036574
[07:32:25.803] iteration 28312: loss: 0.045175, loss_s1: 0.038976, loss_fp: 0.006475, loss_freq: 0.024329
[07:32:26.413] iteration 28313: loss: 0.049443, loss_s1: 0.041996, loss_fp: 0.006908, loss_freq: 0.012544
[07:32:27.019] iteration 28314: loss: 0.042173, loss_s1: 0.025043, loss_fp: 0.002327, loss_freq: 0.034370
[07:32:27.622] iteration 28315: loss: 0.058771, loss_s1: 0.057480, loss_fp: 0.004079, loss_freq: 0.028920
[07:32:28.229] iteration 28316: loss: 0.068154, loss_s1: 0.068244, loss_fp: 0.013032, loss_freq: 0.034660
[07:32:28.839] iteration 28317: loss: 0.095414, loss_s1: 0.083480, loss_fp: 0.005974, loss_freq: 0.070438
[07:32:29.449] iteration 28318: loss: 0.061104, loss_s1: 0.055944, loss_fp: 0.003063, loss_freq: 0.031661
[07:32:30.054] iteration 28319: loss: 0.048046, loss_s1: 0.052312, loss_fp: 0.003908, loss_freq: 0.014353
[07:32:30.656] iteration 28320: loss: 0.047273, loss_s1: 0.038873, loss_fp: 0.006772, loss_freq: 0.020568
[07:32:31.266] iteration 28321: loss: 0.069789, loss_s1: 0.095950, loss_fp: 0.003500, loss_freq: 0.019198
[07:32:31.871] iteration 28322: loss: 0.040268, loss_s1: 0.023282, loss_fp: 0.004385, loss_freq: 0.016913
[07:32:32.478] iteration 28323: loss: 0.028476, loss_s1: 0.020216, loss_fp: 0.002816, loss_freq: 0.008647
[07:32:33.088] iteration 28324: loss: 0.040627, loss_s1: 0.016349, loss_fp: 0.005440, loss_freq: 0.027749
[07:32:33.687] iteration 28325: loss: 0.031352, loss_s1: 0.015007, loss_fp: 0.004239, loss_freq: 0.015340
[07:32:34.292] iteration 28326: loss: 0.060373, loss_s1: 0.055853, loss_fp: 0.005156, loss_freq: 0.033526
[07:32:34.885] iteration 28327: loss: 0.064903, loss_s1: 0.076781, loss_fp: 0.005055, loss_freq: 0.013925
[07:32:35.485] iteration 28328: loss: 0.057135, loss_s1: 0.040387, loss_fp: 0.002849, loss_freq: 0.027281
[07:32:36.114] iteration 28329: loss: 0.049536, loss_s1: 0.035145, loss_fp: 0.005532, loss_freq: 0.032903
[07:32:36.709] iteration 28330: loss: 0.047350, loss_s1: 0.042043, loss_fp: 0.002444, loss_freq: 0.024811
[07:32:37.324] iteration 28331: loss: 0.041884, loss_s1: 0.023815, loss_fp: 0.003873, loss_freq: 0.023471
[07:32:37.935] iteration 28332: loss: 0.057836, loss_s1: 0.044853, loss_fp: 0.003615, loss_freq: 0.029470
[07:32:38.543] iteration 28333: loss: 0.045852, loss_s1: 0.037736, loss_fp: 0.002465, loss_freq: 0.030929
[07:32:39.144] iteration 28334: loss: 0.023205, loss_s1: 0.007552, loss_fp: 0.002599, loss_freq: 0.014681
[07:32:39.753] iteration 28335: loss: 0.040914, loss_s1: 0.029786, loss_fp: 0.002601, loss_freq: 0.018127
[07:32:40.368] iteration 28336: loss: 0.059670, loss_s1: 0.045745, loss_fp: 0.009593, loss_freq: 0.033318
[07:32:40.979] iteration 28337: loss: 0.041662, loss_s1: 0.022480, loss_fp: 0.003471, loss_freq: 0.023823
[07:32:41.577] iteration 28338: loss: 0.039487, loss_s1: 0.026766, loss_fp: 0.007089, loss_freq: 0.020995
[07:32:42.175] iteration 28339: loss: 0.060553, loss_s1: 0.049041, loss_fp: 0.002195, loss_freq: 0.039632
[07:32:42.775] iteration 28340: loss: 0.056004, loss_s1: 0.050614, loss_fp: 0.001949, loss_freq: 0.028206
[07:32:43.384] iteration 28341: loss: 0.033412, loss_s1: 0.022752, loss_fp: 0.004989, loss_freq: 0.005441
[07:32:43.986] iteration 28342: loss: 0.089111, loss_s1: 0.090107, loss_fp: 0.008895, loss_freq: 0.057776
[07:32:44.585] iteration 28343: loss: 0.077059, loss_s1: 0.081211, loss_fp: 0.008523, loss_freq: 0.039390
[07:32:45.180] iteration 28344: loss: 0.061435, loss_s1: 0.042935, loss_fp: 0.004196, loss_freq: 0.046025
[07:32:45.776] iteration 28345: loss: 0.070853, loss_s1: 0.050688, loss_fp: 0.005229, loss_freq: 0.051590
[07:32:46.376] iteration 28346: loss: 0.049511, loss_s1: 0.035596, loss_fp: 0.007378, loss_freq: 0.027784
[07:32:46.986] iteration 28347: loss: 0.063004, loss_s1: 0.051924, loss_fp: 0.002091, loss_freq: 0.049910
[07:32:47.594] iteration 28348: loss: 0.043078, loss_s1: 0.022411, loss_fp: 0.004100, loss_freq: 0.014381
[07:32:48.254] iteration 28349: loss: 0.050539, loss_s1: 0.061673, loss_fp: 0.004852, loss_freq: 0.007836
[07:32:48.860] iteration 28350: loss: 0.089961, loss_s1: 0.066208, loss_fp: 0.002040, loss_freq: 0.083240
[07:32:49.470] iteration 28351: loss: 0.046638, loss_s1: 0.045159, loss_fp: 0.002248, loss_freq: 0.022605
[07:32:50.083] iteration 28352: loss: 0.059180, loss_s1: 0.034368, loss_fp: 0.002773, loss_freq: 0.030452
[07:32:50.691] iteration 28353: loss: 0.057003, loss_s1: 0.054669, loss_fp: 0.007278, loss_freq: 0.020329
[07:32:51.290] iteration 28354: loss: 0.062302, loss_s1: 0.052866, loss_fp: 0.004863, loss_freq: 0.040655
[07:32:51.891] iteration 28355: loss: 0.050425, loss_s1: 0.036451, loss_fp: 0.003988, loss_freq: 0.021288
[07:32:52.506] iteration 28356: loss: 0.035207, loss_s1: 0.042249, loss_fp: 0.002082, loss_freq: 0.005732
[07:32:53.104] iteration 28357: loss: 0.059813, loss_s1: 0.059494, loss_fp: 0.011338, loss_freq: 0.009861
[07:32:53.760] iteration 28358: loss: 0.032982, loss_s1: 0.021942, loss_fp: 0.001410, loss_freq: 0.018537
[07:32:54.364] iteration 28359: loss: 0.075128, loss_s1: 0.074714, loss_fp: 0.003390, loss_freq: 0.033406
[07:32:54.972] iteration 28360: loss: 0.070908, loss_s1: 0.070109, loss_fp: 0.002753, loss_freq: 0.047184
[07:32:55.576] iteration 28361: loss: 0.063387, loss_s1: 0.052131, loss_fp: 0.006767, loss_freq: 0.036865
[07:32:56.184] iteration 28362: loss: 0.060301, loss_s1: 0.065280, loss_fp: 0.006842, loss_freq: 0.018349
[07:32:56.793] iteration 28363: loss: 0.034666, loss_s1: 0.027034, loss_fp: 0.002695, loss_freq: 0.016515
[07:32:57.402] iteration 28364: loss: 0.043924, loss_s1: 0.027796, loss_fp: 0.003446, loss_freq: 0.019846
[07:32:58.010] iteration 28365: loss: 0.030573, loss_s1: 0.019741, loss_fp: 0.003220, loss_freq: 0.012039
[07:32:58.618] iteration 28366: loss: 0.051767, loss_s1: 0.056776, loss_fp: 0.002397, loss_freq: 0.012903
[07:32:59.236] iteration 28367: loss: 0.062270, loss_s1: 0.073626, loss_fp: 0.001937, loss_freq: 0.017380
[07:32:59.841] iteration 28368: loss: 0.054901, loss_s1: 0.050081, loss_fp: 0.005951, loss_freq: 0.029928
[07:33:00.436] iteration 28369: loss: 0.080955, loss_s1: 0.087458, loss_fp: 0.004724, loss_freq: 0.051718
[07:33:01.036] iteration 28370: loss: 0.056766, loss_s1: 0.029635, loss_fp: 0.007282, loss_freq: 0.033702
[07:33:01.632] iteration 28371: loss: 0.071641, loss_s1: 0.080483, loss_fp: 0.006430, loss_freq: 0.023693
[07:33:02.236] iteration 28372: loss: 0.048266, loss_s1: 0.035206, loss_fp: 0.002711, loss_freq: 0.027233
[07:33:02.842] iteration 28373: loss: 0.041224, loss_s1: 0.031988, loss_fp: 0.003844, loss_freq: 0.020272
[07:33:03.439] iteration 28374: loss: 0.082455, loss_s1: 0.069562, loss_fp: 0.005081, loss_freq: 0.057787
[07:33:04.040] iteration 28375: loss: 0.060338, loss_s1: 0.056800, loss_fp: 0.003238, loss_freq: 0.022785
[07:33:04.639] iteration 28376: loss: 0.039834, loss_s1: 0.041109, loss_fp: 0.001280, loss_freq: 0.005920
[07:33:05.237] iteration 28377: loss: 0.041737, loss_s1: 0.043872, loss_fp: 0.003066, loss_freq: 0.018238
[07:33:05.836] iteration 28378: loss: 0.054738, loss_s1: 0.045842, loss_fp: 0.003199, loss_freq: 0.032868
[07:33:06.438] iteration 28379: loss: 0.047461, loss_s1: 0.034310, loss_fp: 0.004566, loss_freq: 0.027294
[07:33:07.115] iteration 28380: loss: 0.060084, loss_s1: 0.046176, loss_fp: 0.004845, loss_freq: 0.036781
[07:33:07.757] iteration 28381: loss: 0.057986, loss_s1: 0.050107, loss_fp: 0.009735, loss_freq: 0.026656
[07:33:08.402] iteration 28382: loss: 0.055973, loss_s1: 0.062451, loss_fp: 0.011664, loss_freq: 0.016744
[07:33:09.047] iteration 28383: loss: 0.041700, loss_s1: 0.024567, loss_fp: 0.002205, loss_freq: 0.021442
[07:33:09.705] iteration 28384: loss: 0.049129, loss_s1: 0.035350, loss_fp: 0.006752, loss_freq: 0.030491
[07:33:10.352] iteration 28385: loss: 0.028748, loss_s1: 0.021099, loss_fp: 0.001493, loss_freq: 0.006001
[07:33:10.997] iteration 28386: loss: 0.062129, loss_s1: 0.062898, loss_fp: 0.005796, loss_freq: 0.030318
[07:33:11.641] iteration 28387: loss: 0.057196, loss_s1: 0.052857, loss_fp: 0.014526, loss_freq: 0.019357
[07:33:12.296] iteration 28388: loss: 0.082678, loss_s1: 0.107314, loss_fp: 0.004796, loss_freq: 0.025794
[07:33:12.931] iteration 28389: loss: 0.079839, loss_s1: 0.079712, loss_fp: 0.003556, loss_freq: 0.048354
[07:33:13.879] iteration 28390: loss: 0.060620, loss_s1: 0.050720, loss_fp: 0.002985, loss_freq: 0.034445
[07:33:15.088] iteration 28391: loss: 0.040076, loss_s1: 0.031705, loss_fp: 0.000719, loss_freq: 0.015411
[07:33:15.702] iteration 28392: loss: 0.051389, loss_s1: 0.045797, loss_fp: 0.004376, loss_freq: 0.018348
[07:33:16.314] iteration 28393: loss: 0.068595, loss_s1: 0.076449, loss_fp: 0.003989, loss_freq: 0.030535
[07:33:16.931] iteration 28394: loss: 0.035919, loss_s1: 0.024168, loss_fp: 0.000932, loss_freq: 0.016293
[07:33:17.550] iteration 28395: loss: 0.065170, loss_s1: 0.069966, loss_fp: 0.006694, loss_freq: 0.021287
[07:33:18.151] iteration 28396: loss: 0.068823, loss_s1: 0.050926, loss_fp: 0.007044, loss_freq: 0.035562
[07:33:18.781] iteration 28397: loss: 0.050441, loss_s1: 0.032731, loss_fp: 0.002779, loss_freq: 0.035559
[07:33:19.394] iteration 28398: loss: 0.033668, loss_s1: 0.032593, loss_fp: 0.003000, loss_freq: 0.008733
[07:33:20.017] iteration 28399: loss: 0.042613, loss_s1: 0.046178, loss_fp: 0.003796, loss_freq: 0.008881
[07:33:20.640] iteration 28400: loss: 0.052179, loss_s1: 0.027815, loss_fp: 0.013434, loss_freq: 0.027866
[07:33:24.126] iteration 28400 : mean_dice : 0.742801
[07:33:24.819] iteration 28401: loss: 0.060422, loss_s1: 0.053423, loss_fp: 0.002603, loss_freq: 0.025666
[07:33:25.458] iteration 28402: loss: 0.045761, loss_s1: 0.027490, loss_fp: 0.000883, loss_freq: 0.032844
[07:33:26.110] iteration 28403: loss: 0.074838, loss_s1: 0.040604, loss_fp: 0.008261, loss_freq: 0.072357
[07:33:26.748] iteration 28404: loss: 0.054001, loss_s1: 0.043328, loss_fp: 0.011306, loss_freq: 0.027343
[07:33:27.352] iteration 28405: loss: 0.044429, loss_s1: 0.027984, loss_fp: 0.009624, loss_freq: 0.024016
[07:33:27.959] iteration 28406: loss: 0.065408, loss_s1: 0.070894, loss_fp: 0.002197, loss_freq: 0.023856
[07:33:28.576] iteration 28407: loss: 0.062059, loss_s1: 0.037567, loss_fp: 0.003201, loss_freq: 0.063516
[07:33:29.219] iteration 28408: loss: 0.040391, loss_s1: 0.040178, loss_fp: 0.003843, loss_freq: 0.012895
[07:33:29.859] iteration 28409: loss: 0.044131, loss_s1: 0.028106, loss_fp: 0.006423, loss_freq: 0.025130
[07:33:30.490] iteration 28410: loss: 0.057512, loss_s1: 0.060596, loss_fp: 0.002764, loss_freq: 0.017653
[07:33:31.096] iteration 28411: loss: 0.051014, loss_s1: 0.033647, loss_fp: 0.002905, loss_freq: 0.037617
[07:33:31.706] iteration 28412: loss: 0.038436, loss_s1: 0.019343, loss_fp: 0.004684, loss_freq: 0.035285
[07:33:32.352] iteration 28413: loss: 0.045645, loss_s1: 0.034168, loss_fp: 0.002736, loss_freq: 0.016836
[07:33:33.013] iteration 28414: loss: 0.043940, loss_s1: 0.039464, loss_fp: 0.003230, loss_freq: 0.017988
[07:33:33.678] iteration 28415: loss: 0.070372, loss_s1: 0.077542, loss_fp: 0.004211, loss_freq: 0.030496
[07:33:34.362] iteration 28416: loss: 0.045408, loss_s1: 0.037235, loss_fp: 0.002402, loss_freq: 0.028303
[07:33:35.021] iteration 28417: loss: 0.054770, loss_s1: 0.029701, loss_fp: 0.006042, loss_freq: 0.030900
[07:33:35.696] iteration 28418: loss: 0.052431, loss_s1: 0.033222, loss_fp: 0.012812, loss_freq: 0.025300
[07:33:36.360] iteration 28419: loss: 0.042957, loss_s1: 0.027899, loss_fp: 0.004027, loss_freq: 0.030458
[07:33:36.995] iteration 28420: loss: 0.077906, loss_s1: 0.074258, loss_fp: 0.002913, loss_freq: 0.048827
[07:33:37.635] iteration 28421: loss: 0.048804, loss_s1: 0.029251, loss_fp: 0.005440, loss_freq: 0.037740
[07:33:38.279] iteration 28422: loss: 0.109500, loss_s1: 0.108285, loss_fp: 0.009750, loss_freq: 0.063264
[07:33:38.927] iteration 28423: loss: 0.065729, loss_s1: 0.069472, loss_fp: 0.005554, loss_freq: 0.014999
[07:33:39.543] iteration 28424: loss: 0.053586, loss_s1: 0.045005, loss_fp: 0.006855, loss_freq: 0.028946
[07:33:40.154] iteration 28425: loss: 0.054998, loss_s1: 0.063538, loss_fp: 0.001978, loss_freq: 0.021720
[07:33:40.756] iteration 28426: loss: 0.057772, loss_s1: 0.050684, loss_fp: 0.001634, loss_freq: 0.022662
[07:33:41.363] iteration 28427: loss: 0.064138, loss_s1: 0.047372, loss_fp: 0.006681, loss_freq: 0.032870
[07:33:41.968] iteration 28428: loss: 0.044544, loss_s1: 0.044348, loss_fp: 0.003040, loss_freq: 0.014352
[07:33:42.573] iteration 28429: loss: 0.057943, loss_s1: 0.048932, loss_fp: 0.008167, loss_freq: 0.028502
[07:33:43.195] iteration 28430: loss: 0.068758, loss_s1: 0.075724, loss_fp: 0.008990, loss_freq: 0.028028
[07:33:43.808] iteration 28431: loss: 0.043593, loss_s1: 0.034461, loss_fp: 0.000650, loss_freq: 0.006417
[07:33:44.424] iteration 28432: loss: 0.062265, loss_s1: 0.051847, loss_fp: 0.013903, loss_freq: 0.019405
[07:33:45.042] iteration 28433: loss: 0.078919, loss_s1: 0.074821, loss_fp: 0.002872, loss_freq: 0.056549
[07:33:45.658] iteration 28434: loss: 0.046360, loss_s1: 0.036276, loss_fp: 0.005487, loss_freq: 0.027196
[07:33:46.277] iteration 28435: loss: 0.042557, loss_s1: 0.026599, loss_fp: 0.000778, loss_freq: 0.021636
[07:33:46.889] iteration 28436: loss: 0.074473, loss_s1: 0.090502, loss_fp: 0.009233, loss_freq: 0.019978
[07:33:47.503] iteration 28437: loss: 0.047173, loss_s1: 0.024979, loss_fp: 0.003277, loss_freq: 0.036385
[07:33:48.162] iteration 28438: loss: 0.048635, loss_s1: 0.025964, loss_fp: 0.003886, loss_freq: 0.043888
[07:33:48.816] iteration 28439: loss: 0.054177, loss_s1: 0.067034, loss_fp: 0.001918, loss_freq: 0.015595
[07:33:49.462] iteration 28440: loss: 0.033493, loss_s1: 0.021190, loss_fp: 0.000667, loss_freq: 0.014428
[07:33:50.116] iteration 28441: loss: 0.036632, loss_s1: 0.025914, loss_fp: 0.002564, loss_freq: 0.014717
[07:33:50.768] iteration 28442: loss: 0.078449, loss_s1: 0.084639, loss_fp: 0.004499, loss_freq: 0.045207
[07:33:51.406] iteration 28443: loss: 0.063879, loss_s1: 0.075341, loss_fp: 0.001148, loss_freq: 0.014464
[07:33:52.029] iteration 28444: loss: 0.053458, loss_s1: 0.048869, loss_fp: 0.007812, loss_freq: 0.021001
[07:33:52.635] iteration 28445: loss: 0.050775, loss_s1: 0.028779, loss_fp: 0.002373, loss_freq: 0.033903
[07:33:53.253] iteration 28446: loss: 0.031154, loss_s1: 0.014693, loss_fp: 0.001436, loss_freq: 0.014678
[07:33:53.859] iteration 28447: loss: 0.049164, loss_s1: 0.034941, loss_fp: 0.008423, loss_freq: 0.036450
[07:33:54.475] iteration 28448: loss: 0.044435, loss_s1: 0.026243, loss_fp: 0.004731, loss_freq: 0.018718
[07:33:55.083] iteration 28449: loss: 0.035685, loss_s1: 0.015314, loss_fp: 0.002308, loss_freq: 0.028823
[07:33:55.681] iteration 28450: loss: 0.049697, loss_s1: 0.037785, loss_fp: 0.002745, loss_freq: 0.032079
[07:33:56.289] iteration 28451: loss: 0.027915, loss_s1: 0.028735, loss_fp: 0.001469, loss_freq: 0.004222
[07:33:56.897] iteration 28452: loss: 0.063243, loss_s1: 0.053951, loss_fp: 0.007554, loss_freq: 0.035903
[07:33:57.506] iteration 28453: loss: 0.043213, loss_s1: 0.033713, loss_fp: 0.001192, loss_freq: 0.015225
[07:33:58.115] iteration 28454: loss: 0.049608, loss_s1: 0.039500, loss_fp: 0.003138, loss_freq: 0.034050
[07:33:58.753] iteration 28455: loss: 0.058486, loss_s1: 0.070917, loss_fp: 0.002596, loss_freq: 0.007908
[07:33:59.366] iteration 28456: loss: 0.042722, loss_s1: 0.038843, loss_fp: 0.002274, loss_freq: 0.021892
[07:33:59.972] iteration 28457: loss: 0.050340, loss_s1: 0.050335, loss_fp: 0.000427, loss_freq: 0.007668
[07:34:00.579] iteration 28458: loss: 0.076270, loss_s1: 0.065796, loss_fp: 0.015980, loss_freq: 0.043594
[07:34:01.182] iteration 28459: loss: 0.040157, loss_s1: 0.034054, loss_fp: 0.003069, loss_freq: 0.011614
[07:34:01.788] iteration 28460: loss: 0.049393, loss_s1: 0.049757, loss_fp: 0.002449, loss_freq: 0.019790
[07:34:02.405] iteration 28461: loss: 0.074709, loss_s1: 0.075729, loss_fp: 0.010386, loss_freq: 0.034174
[07:34:03.012] iteration 28462: loss: 0.061476, loss_s1: 0.036751, loss_fp: 0.004074, loss_freq: 0.047811
[07:34:03.626] iteration 28463: loss: 0.077875, loss_s1: 0.058351, loss_fp: 0.008885, loss_freq: 0.064527
[07:34:04.247] iteration 28464: loss: 0.036235, loss_s1: 0.019825, loss_fp: 0.005921, loss_freq: 0.015186
[07:34:04.848] iteration 28465: loss: 0.062458, loss_s1: 0.057152, loss_fp: 0.005528, loss_freq: 0.038337
[07:34:05.450] iteration 28466: loss: 0.061194, loss_s1: 0.054388, loss_fp: 0.006808, loss_freq: 0.030497
[07:34:06.047] iteration 28467: loss: 0.058426, loss_s1: 0.057935, loss_fp: 0.005438, loss_freq: 0.024155
[07:34:06.655] iteration 28468: loss: 0.096699, loss_s1: 0.111198, loss_fp: 0.017327, loss_freq: 0.032870
[07:34:07.263] iteration 28469: loss: 0.042504, loss_s1: 0.031870, loss_fp: 0.003734, loss_freq: 0.026791
[07:34:07.899] iteration 28470: loss: 0.063096, loss_s1: 0.060189, loss_fp: 0.003539, loss_freq: 0.019690
[07:34:08.505] iteration 28471: loss: 0.035574, loss_s1: 0.022600, loss_fp: 0.002172, loss_freq: 0.010952
[07:34:09.115] iteration 28472: loss: 0.053589, loss_s1: 0.034422, loss_fp: 0.006538, loss_freq: 0.034731
[07:34:09.717] iteration 28473: loss: 0.038855, loss_s1: 0.036466, loss_fp: 0.003865, loss_freq: 0.015346
[07:34:10.324] iteration 28474: loss: 0.028997, loss_s1: 0.017506, loss_fp: 0.002891, loss_freq: 0.008466
[07:34:10.922] iteration 28475: loss: 0.047114, loss_s1: 0.036886, loss_fp: 0.002924, loss_freq: 0.022790
[07:34:11.516] iteration 28476: loss: 0.064627, loss_s1: 0.059255, loss_fp: 0.004938, loss_freq: 0.030409
[07:34:12.118] iteration 28477: loss: 0.068066, loss_s1: 0.096918, loss_fp: 0.002723, loss_freq: 0.017796
[07:34:12.721] iteration 28478: loss: 0.059247, loss_s1: 0.061214, loss_fp: 0.011002, loss_freq: 0.022574
[07:34:13.329] iteration 28479: loss: 0.042102, loss_s1: 0.030649, loss_fp: 0.004783, loss_freq: 0.021131
[07:34:13.947] iteration 28480: loss: 0.053183, loss_s1: 0.034039, loss_fp: 0.003413, loss_freq: 0.021006
[07:34:14.561] iteration 28481: loss: 0.071245, loss_s1: 0.080131, loss_fp: 0.003908, loss_freq: 0.025473
[07:34:15.172] iteration 28482: loss: 0.049040, loss_s1: 0.018321, loss_fp: 0.005372, loss_freq: 0.051813
[07:34:15.770] iteration 28483: loss: 0.056055, loss_s1: 0.045197, loss_fp: 0.011426, loss_freq: 0.022188
[07:34:16.370] iteration 28484: loss: 0.053963, loss_s1: 0.049497, loss_fp: 0.005342, loss_freq: 0.031318
[07:34:16.970] iteration 28485: loss: 0.056770, loss_s1: 0.044024, loss_fp: 0.008033, loss_freq: 0.033669
[07:34:17.570] iteration 28486: loss: 0.046844, loss_s1: 0.029310, loss_fp: 0.007192, loss_freq: 0.032437
[07:34:18.169] iteration 28487: loss: 0.070853, loss_s1: 0.047064, loss_fp: 0.001042, loss_freq: 0.060646
[07:34:18.776] iteration 28488: loss: 0.061449, loss_s1: 0.034664, loss_fp: 0.006175, loss_freq: 0.053359
[07:34:19.382] iteration 28489: loss: 0.060844, loss_s1: 0.048744, loss_fp: 0.004307, loss_freq: 0.044664
[07:34:19.988] iteration 28490: loss: 0.049222, loss_s1: 0.043842, loss_fp: 0.003068, loss_freq: 0.015113
[07:34:20.601] iteration 28491: loss: 0.054874, loss_s1: 0.067121, loss_fp: 0.003553, loss_freq: 0.012882
[07:34:21.211] iteration 28492: loss: 0.037816, loss_s1: 0.026901, loss_fp: 0.001899, loss_freq: 0.013178
[07:34:21.810] iteration 28493: loss: 0.036420, loss_s1: 0.027737, loss_fp: 0.003832, loss_freq: 0.015337
[07:34:22.408] iteration 28494: loss: 0.045300, loss_s1: 0.040427, loss_fp: 0.001960, loss_freq: 0.017282
[07:34:23.006] iteration 28495: loss: 0.051241, loss_s1: 0.052984, loss_fp: 0.005013, loss_freq: 0.021071
[07:34:23.607] iteration 28496: loss: 0.062400, loss_s1: 0.073426, loss_fp: 0.002340, loss_freq: 0.017616
[07:34:24.202] iteration 28497: loss: 0.053841, loss_s1: 0.053335, loss_fp: 0.000990, loss_freq: 0.023677
[07:34:24.801] iteration 28498: loss: 0.041564, loss_s1: 0.040111, loss_fp: 0.002755, loss_freq: 0.015157
[07:34:25.403] iteration 28499: loss: 0.042600, loss_s1: 0.042090, loss_fp: 0.005236, loss_freq: 0.011180
[07:34:26.008] iteration 28500: loss: 0.054832, loss_s1: 0.049156, loss_fp: 0.004953, loss_freq: 0.030247
[07:34:26.620] iteration 28501: loss: 0.038554, loss_s1: 0.022837, loss_fp: 0.005686, loss_freq: 0.019421
[07:34:27.236] iteration 28502: loss: 0.036095, loss_s1: 0.026295, loss_fp: 0.002382, loss_freq: 0.014963
[07:34:27.838] iteration 28503: loss: 0.061827, loss_s1: 0.064773, loss_fp: 0.005286, loss_freq: 0.024417
[07:34:28.434] iteration 28504: loss: 0.034847, loss_s1: 0.039343, loss_fp: 0.003816, loss_freq: 0.006037
[07:34:29.095] iteration 28505: loss: 0.057918, loss_s1: 0.041072, loss_fp: 0.008980, loss_freq: 0.036382
[07:34:29.747] iteration 28506: loss: 0.075321, loss_s1: 0.074474, loss_fp: 0.005785, loss_freq: 0.042522
[07:34:30.415] iteration 28507: loss: 0.068460, loss_s1: 0.060892, loss_fp: 0.007558, loss_freq: 0.029810
[07:34:31.063] iteration 28508: loss: 0.055990, loss_s1: 0.054137, loss_fp: 0.010315, loss_freq: 0.023589
[07:34:31.692] iteration 28509: loss: 0.065577, loss_s1: 0.080074, loss_fp: 0.001950, loss_freq: 0.021486
[07:34:32.294] iteration 28510: loss: 0.032369, loss_s1: 0.022574, loss_fp: 0.001316, loss_freq: 0.013907
[07:34:32.913] iteration 28511: loss: 0.048933, loss_s1: 0.058894, loss_fp: 0.001071, loss_freq: 0.011416
[07:34:33.519] iteration 28512: loss: 0.058964, loss_s1: 0.067791, loss_fp: 0.005806, loss_freq: 0.025227
[07:34:34.117] iteration 28513: loss: 0.087303, loss_s1: 0.077213, loss_fp: 0.008375, loss_freq: 0.061596
[07:34:34.723] iteration 28514: loss: 0.052642, loss_s1: 0.054825, loss_fp: 0.004048, loss_freq: 0.020767
[07:34:35.328] iteration 28515: loss: 0.076445, loss_s1: 0.052736, loss_fp: 0.013080, loss_freq: 0.057007
[07:34:35.945] iteration 28516: loss: 0.049177, loss_s1: 0.035313, loss_fp: 0.001757, loss_freq: 0.029569
[07:34:36.552] iteration 28517: loss: 0.083140, loss_s1: 0.122847, loss_fp: 0.002645, loss_freq: 0.019250
[07:34:37.161] iteration 28518: loss: 0.052287, loss_s1: 0.030969, loss_fp: 0.005008, loss_freq: 0.031012
[07:34:37.757] iteration 28519: loss: 0.074976, loss_s1: 0.068803, loss_fp: 0.002960, loss_freq: 0.052982
[07:34:38.370] iteration 28520: loss: 0.065087, loss_s1: 0.079771, loss_fp: 0.002931, loss_freq: 0.019484
[07:34:38.969] iteration 28521: loss: 0.054030, loss_s1: 0.029476, loss_fp: 0.022491, loss_freq: 0.037934
[07:34:39.567] iteration 28522: loss: 0.060453, loss_s1: 0.056679, loss_fp: 0.004555, loss_freq: 0.020753
[07:34:40.164] iteration 28523: loss: 0.066875, loss_s1: 0.062128, loss_fp: 0.007482, loss_freq: 0.030224
[07:34:40.761] iteration 28524: loss: 0.054383, loss_s1: 0.056716, loss_fp: 0.006361, loss_freq: 0.022130
[07:34:41.355] iteration 28525: loss: 0.061325, loss_s1: 0.077419, loss_fp: 0.001609, loss_freq: 0.011456
[07:34:41.992] iteration 28526: loss: 0.034810, loss_s1: 0.032761, loss_fp: 0.001467, loss_freq: 0.015700
[07:34:42.590] iteration 28527: loss: 0.049206, loss_s1: 0.043072, loss_fp: 0.002682, loss_freq: 0.010271
[07:34:43.205] iteration 28528: loss: 0.051317, loss_s1: 0.036232, loss_fp: 0.005993, loss_freq: 0.036339
[07:34:43.802] iteration 28529: loss: 0.059582, loss_s1: 0.042042, loss_fp: 0.001736, loss_freq: 0.045616
[07:34:44.416] iteration 28530: loss: 0.062795, loss_s1: 0.074480, loss_fp: 0.008337, loss_freq: 0.020005
[07:34:45.018] iteration 28531: loss: 0.057751, loss_s1: 0.044079, loss_fp: 0.002650, loss_freq: 0.037337
[07:34:45.616] iteration 28532: loss: 0.064511, loss_s1: 0.068437, loss_fp: 0.007968, loss_freq: 0.021492
[07:34:46.235] iteration 28533: loss: 0.056732, loss_s1: 0.053081, loss_fp: 0.009086, loss_freq: 0.021217
[07:34:46.842] iteration 28534: loss: 0.056477, loss_s1: 0.061038, loss_fp: 0.004173, loss_freq: 0.018519
[07:34:47.447] iteration 28535: loss: 0.032842, loss_s1: 0.032717, loss_fp: 0.002674, loss_freq: 0.010598
[07:34:48.042] iteration 28536: loss: 0.052173, loss_s1: 0.035722, loss_fp: 0.001391, loss_freq: 0.036121
[07:34:48.642] iteration 28537: loss: 0.036466, loss_s1: 0.025579, loss_fp: 0.003549, loss_freq: 0.016970
[07:34:49.245] iteration 28538: loss: 0.096084, loss_s1: 0.103304, loss_fp: 0.008321, loss_freq: 0.058000
[07:34:49.842] iteration 28539: loss: 0.055830, loss_s1: 0.048651, loss_fp: 0.001791, loss_freq: 0.034081
[07:34:50.455] iteration 28540: loss: 0.041275, loss_s1: 0.022764, loss_fp: 0.004303, loss_freq: 0.019585
[07:34:51.065] iteration 28541: loss: 0.082120, loss_s1: 0.063552, loss_fp: 0.014500, loss_freq: 0.055279
[07:34:51.662] iteration 28542: loss: 0.041812, loss_s1: 0.032347, loss_fp: 0.005801, loss_freq: 0.013616
[07:34:52.266] iteration 28543: loss: 0.055009, loss_s1: 0.040881, loss_fp: 0.004816, loss_freq: 0.032556
[07:34:52.877] iteration 28544: loss: 0.087930, loss_s1: 0.060812, loss_fp: 0.012246, loss_freq: 0.075398
[07:34:53.492] iteration 28545: loss: 0.089585, loss_s1: 0.107796, loss_fp: 0.003155, loss_freq: 0.019151
[07:34:54.102] iteration 28546: loss: 0.031724, loss_s1: 0.021866, loss_fp: 0.001558, loss_freq: 0.009086
[07:34:54.702] iteration 28547: loss: 0.044357, loss_s1: 0.030134, loss_fp: 0.003348, loss_freq: 0.028534
[07:34:55.311] iteration 28548: loss: 0.075408, loss_s1: 0.054689, loss_fp: 0.002978, loss_freq: 0.062513
[07:34:55.910] iteration 28549: loss: 0.055042, loss_s1: 0.050632, loss_fp: 0.006736, loss_freq: 0.022304
[07:34:56.515] iteration 28550: loss: 0.077638, loss_s1: 0.061707, loss_fp: 0.006754, loss_freq: 0.045360
[07:34:57.126] iteration 28551: loss: 0.036609, loss_s1: 0.032468, loss_fp: 0.003582, loss_freq: 0.007781
[07:34:57.730] iteration 28552: loss: 0.083348, loss_s1: 0.079133, loss_fp: 0.008844, loss_freq: 0.054713
[07:34:58.332] iteration 28553: loss: 0.032353, loss_s1: 0.013286, loss_fp: 0.001209, loss_freq: 0.009330
[07:34:58.930] iteration 28554: loss: 0.060726, loss_s1: 0.051466, loss_fp: 0.006700, loss_freq: 0.030427
[07:34:59.542] iteration 28555: loss: 0.030635, loss_s1: 0.015956, loss_fp: 0.001734, loss_freq: 0.013345
[07:35:00.144] iteration 28556: loss: 0.046254, loss_s1: 0.038742, loss_fp: 0.009999, loss_freq: 0.023766
[07:35:00.742] iteration 28557: loss: 0.053184, loss_s1: 0.033800, loss_fp: 0.005031, loss_freq: 0.036442
[07:35:01.341] iteration 28558: loss: 0.084338, loss_s1: 0.088393, loss_fp: 0.008088, loss_freq: 0.039798
[07:35:01.936] iteration 28559: loss: 0.058497, loss_s1: 0.045255, loss_fp: 0.009837, loss_freq: 0.035637
[07:35:02.548] iteration 28560: loss: 0.072194, loss_s1: 0.056821, loss_fp: 0.007100, loss_freq: 0.047067
[07:35:03.450] iteration 28561: loss: 0.058372, loss_s1: 0.046723, loss_fp: 0.002176, loss_freq: 0.029579
[07:35:04.049] iteration 28562: loss: 0.047554, loss_s1: 0.019562, loss_fp: 0.001995, loss_freq: 0.043535
[07:35:04.649] iteration 28563: loss: 0.055439, loss_s1: 0.048700, loss_fp: 0.003985, loss_freq: 0.032579
[07:35:05.272] iteration 28564: loss: 0.041411, loss_s1: 0.033137, loss_fp: 0.002562, loss_freq: 0.014701
[07:35:05.875] iteration 28565: loss: 0.035250, loss_s1: 0.024983, loss_fp: 0.001782, loss_freq: 0.019653
[07:35:06.468] iteration 28566: loss: 0.061409, loss_s1: 0.059917, loss_fp: 0.001602, loss_freq: 0.027877
[07:35:07.066] iteration 28567: loss: 0.042763, loss_s1: 0.034282, loss_fp: 0.003708, loss_freq: 0.019410
[07:35:07.666] iteration 28568: loss: 0.041340, loss_s1: 0.041255, loss_fp: 0.001946, loss_freq: 0.016614
[07:35:08.270] iteration 28569: loss: 0.030299, loss_s1: 0.026451, loss_fp: 0.001554, loss_freq: 0.010521
[07:35:08.866] iteration 28570: loss: 0.064867, loss_s1: 0.057565, loss_fp: 0.008380, loss_freq: 0.029526
[07:35:09.467] iteration 28571: loss: 0.039513, loss_s1: 0.019189, loss_fp: 0.001556, loss_freq: 0.028060
[07:35:10.073] iteration 28572: loss: 0.059378, loss_s1: 0.043183, loss_fp: 0.001729, loss_freq: 0.042980
[07:35:10.674] iteration 28573: loss: 0.067481, loss_s1: 0.031166, loss_fp: 0.001606, loss_freq: 0.074846
[07:35:11.282] iteration 28574: loss: 0.041644, loss_s1: 0.036687, loss_fp: 0.008009, loss_freq: 0.014896
[07:35:11.884] iteration 28575: loss: 0.046979, loss_s1: 0.033242, loss_fp: 0.003553, loss_freq: 0.020391
[07:35:12.477] iteration 28576: loss: 0.043856, loss_s1: 0.032834, loss_fp: 0.010278, loss_freq: 0.017280
[07:35:13.071] iteration 28577: loss: 0.053761, loss_s1: 0.028220, loss_fp: 0.005815, loss_freq: 0.052003
[07:35:13.661] iteration 28578: loss: 0.035858, loss_s1: 0.023857, loss_fp: 0.004654, loss_freq: 0.011717
[07:35:14.297] iteration 28579: loss: 0.099641, loss_s1: 0.081024, loss_fp: 0.011319, loss_freq: 0.080166
[07:35:14.935] iteration 28580: loss: 0.039652, loss_s1: 0.032683, loss_fp: 0.001269, loss_freq: 0.011140
[07:35:15.635] iteration 28581: loss: 0.040357, loss_s1: 0.031890, loss_fp: 0.001649, loss_freq: 0.018213
[07:35:16.397] iteration 28582: loss: 0.060016, loss_s1: 0.027435, loss_fp: 0.010472, loss_freq: 0.056249
[07:35:17.145] iteration 28583: loss: 0.055024, loss_s1: 0.037262, loss_fp: 0.004108, loss_freq: 0.038586
[07:35:17.862] iteration 28584: loss: 0.060442, loss_s1: 0.050085, loss_fp: 0.002309, loss_freq: 0.032971
[07:35:18.461] iteration 28585: loss: 0.061285, loss_s1: 0.065948, loss_fp: 0.005640, loss_freq: 0.022164
[07:35:19.060] iteration 28586: loss: 0.051494, loss_s1: 0.044007, loss_fp: 0.006509, loss_freq: 0.033791
[07:35:19.660] iteration 28587: loss: 0.037474, loss_s1: 0.022883, loss_fp: 0.003826, loss_freq: 0.014942
[07:35:20.262] iteration 28588: loss: 0.056031, loss_s1: 0.033941, loss_fp: 0.006317, loss_freq: 0.041686
[07:35:20.856] iteration 28589: loss: 0.044509, loss_s1: 0.042624, loss_fp: 0.001863, loss_freq: 0.018203
[07:35:21.461] iteration 28590: loss: 0.070814, loss_s1: 0.068304, loss_fp: 0.012636, loss_freq: 0.031712
[07:35:22.054] iteration 28591: loss: 0.074690, loss_s1: 0.060631, loss_fp: 0.012041, loss_freq: 0.056501
[07:35:22.649] iteration 28592: loss: 0.072672, loss_s1: 0.074174, loss_fp: 0.002716, loss_freq: 0.037614
[07:35:23.250] iteration 28593: loss: 0.046997, loss_s1: 0.047703, loss_fp: 0.005830, loss_freq: 0.019112
[07:35:23.850] iteration 28594: loss: 0.031029, loss_s1: 0.023627, loss_fp: 0.003838, loss_freq: 0.007805
[07:35:24.449] iteration 28595: loss: 0.041803, loss_s1: 0.038390, loss_fp: 0.002385, loss_freq: 0.023605
[07:35:25.052] iteration 28596: loss: 0.049674, loss_s1: 0.049864, loss_fp: 0.003810, loss_freq: 0.009807
[07:35:25.657] iteration 28597: loss: 0.053710, loss_s1: 0.042152, loss_fp: 0.002665, loss_freq: 0.029670
[07:35:26.253] iteration 28598: loss: 0.078170, loss_s1: 0.099018, loss_fp: 0.013843, loss_freq: 0.021579
[07:35:26.859] iteration 28599: loss: 0.080012, loss_s1: 0.079106, loss_fp: 0.017929, loss_freq: 0.030740
[07:35:27.456] iteration 28600: loss: 0.058844, loss_s1: 0.063464, loss_fp: 0.005157, loss_freq: 0.020516
[07:35:30.654] iteration 28600 : mean_dice : 0.747077
[07:35:31.276] iteration 28601: loss: 0.033165, loss_s1: 0.023680, loss_fp: 0.000577, loss_freq: 0.012195
[07:35:31.872] iteration 28602: loss: 0.054300, loss_s1: 0.048260, loss_fp: 0.004679, loss_freq: 0.017276
[07:35:32.485] iteration 28603: loss: 0.100749, loss_s1: 0.144933, loss_fp: 0.003305, loss_freq: 0.026858
[07:35:33.077] iteration 28604: loss: 0.102935, loss_s1: 0.113111, loss_fp: 0.005971, loss_freq: 0.063059
[07:35:33.683] iteration 28605: loss: 0.076575, loss_s1: 0.078376, loss_fp: 0.004638, loss_freq: 0.030187
[07:35:34.280] iteration 28606: loss: 0.065787, loss_s1: 0.072717, loss_fp: 0.013260, loss_freq: 0.015550
[07:35:34.891] iteration 28607: loss: 0.045353, loss_s1: 0.034788, loss_fp: 0.001607, loss_freq: 0.022756
[07:35:35.484] iteration 28608: loss: 0.059206, loss_s1: 0.053462, loss_fp: 0.005477, loss_freq: 0.023318
[07:35:36.089] iteration 28609: loss: 0.032236, loss_s1: 0.022773, loss_fp: 0.002079, loss_freq: 0.013413
[07:35:36.710] iteration 28610: loss: 0.030531, loss_s1: 0.011184, loss_fp: 0.003280, loss_freq: 0.011012
[07:35:37.324] iteration 28611: loss: 0.046623, loss_s1: 0.022894, loss_fp: 0.005191, loss_freq: 0.028273
[07:35:37.933] iteration 28612: loss: 0.036386, loss_s1: 0.036479, loss_fp: 0.003035, loss_freq: 0.013079
[07:35:38.581] iteration 28613: loss: 0.037529, loss_s1: 0.020283, loss_fp: 0.003815, loss_freq: 0.023491
[07:35:39.235] iteration 28614: loss: 0.104695, loss_s1: 0.079992, loss_fp: 0.011913, loss_freq: 0.088834
[07:35:39.883] iteration 28615: loss: 0.045657, loss_s1: 0.028321, loss_fp: 0.004157, loss_freq: 0.025836
[07:35:40.478] iteration 28616: loss: 0.030180, loss_s1: 0.010112, loss_fp: 0.004547, loss_freq: 0.014750
[07:35:41.078] iteration 28617: loss: 0.054596, loss_s1: 0.050466, loss_fp: 0.010966, loss_freq: 0.028057
[07:35:41.686] iteration 28618: loss: 0.052963, loss_s1: 0.037627, loss_fp: 0.005995, loss_freq: 0.025110
[07:35:42.296] iteration 28619: loss: 0.038312, loss_s1: 0.023191, loss_fp: 0.006220, loss_freq: 0.025583
[07:35:42.908] iteration 28620: loss: 0.040349, loss_s1: 0.022850, loss_fp: 0.003242, loss_freq: 0.027196
[07:35:43.508] iteration 28621: loss: 0.035829, loss_s1: 0.033555, loss_fp: 0.006388, loss_freq: 0.011797
[07:35:44.109] iteration 28622: loss: 0.061987, loss_s1: 0.057430, loss_fp: 0.002184, loss_freq: 0.031032
[07:35:44.710] iteration 28623: loss: 0.045856, loss_s1: 0.040021, loss_fp: 0.001763, loss_freq: 0.017277
[07:35:45.309] iteration 28624: loss: 0.032583, loss_s1: 0.032913, loss_fp: 0.002042, loss_freq: 0.006272
[07:35:45.909] iteration 28625: loss: 0.040127, loss_s1: 0.036883, loss_fp: 0.002753, loss_freq: 0.006711
[07:35:46.515] iteration 28626: loss: 0.029894, loss_s1: 0.012315, loss_fp: 0.003675, loss_freq: 0.022349
[07:35:47.126] iteration 28627: loss: 0.048919, loss_s1: 0.047760, loss_fp: 0.001372, loss_freq: 0.015221
[07:35:47.730] iteration 28628: loss: 0.122971, loss_s1: 0.136500, loss_fp: 0.007752, loss_freq: 0.074231
[07:35:48.325] iteration 28629: loss: 0.038924, loss_s1: 0.029371, loss_fp: 0.004571, loss_freq: 0.016062
[07:35:48.920] iteration 28630: loss: 0.041479, loss_s1: 0.032088, loss_fp: 0.001627, loss_freq: 0.022379
[07:35:49.519] iteration 28631: loss: 0.055835, loss_s1: 0.033962, loss_fp: 0.006481, loss_freq: 0.043284
[07:35:50.123] iteration 28632: loss: 0.049776, loss_s1: 0.026802, loss_fp: 0.003125, loss_freq: 0.038411
[07:35:50.723] iteration 28633: loss: 0.063123, loss_s1: 0.052564, loss_fp: 0.002753, loss_freq: 0.043639
[07:35:51.321] iteration 28634: loss: 0.076327, loss_s1: 0.115143, loss_fp: 0.002996, loss_freq: 0.007075
[07:35:51.924] iteration 28635: loss: 0.052720, loss_s1: 0.020447, loss_fp: 0.004259, loss_freq: 0.058113
[07:35:52.534] iteration 28636: loss: 0.073076, loss_s1: 0.046059, loss_fp: 0.028952, loss_freq: 0.032819
[07:35:53.136] iteration 28637: loss: 0.052140, loss_s1: 0.027774, loss_fp: 0.006364, loss_freq: 0.042113
[07:35:53.730] iteration 28638: loss: 0.078268, loss_s1: 0.080249, loss_fp: 0.006630, loss_freq: 0.046512
[07:35:54.331] iteration 28639: loss: 0.044552, loss_s1: 0.042836, loss_fp: 0.002227, loss_freq: 0.022954
[07:35:54.932] iteration 28640: loss: 0.076332, loss_s1: 0.053995, loss_fp: 0.009498, loss_freq: 0.056316
[07:35:55.539] iteration 28641: loss: 0.064223, loss_s1: 0.039514, loss_fp: 0.004036, loss_freq: 0.035556
[07:35:56.147] iteration 28642: loss: 0.081434, loss_s1: 0.064419, loss_fp: 0.007949, loss_freq: 0.054103
[07:35:56.748] iteration 28643: loss: 0.070813, loss_s1: 0.089506, loss_fp: 0.002185, loss_freq: 0.027721
[07:35:57.348] iteration 28644: loss: 0.035133, loss_s1: 0.030655, loss_fp: 0.005269, loss_freq: 0.010585
[07:35:57.961] iteration 28645: loss: 0.056916, loss_s1: 0.053353, loss_fp: 0.003407, loss_freq: 0.031947
[07:35:58.565] iteration 28646: loss: 0.060008, loss_s1: 0.048117, loss_fp: 0.010121, loss_freq: 0.023191
[07:35:59.163] iteration 28647: loss: 0.084258, loss_s1: 0.096180, loss_fp: 0.004793, loss_freq: 0.048472
[07:35:59.786] iteration 28648: loss: 0.076567, loss_s1: 0.072654, loss_fp: 0.020713, loss_freq: 0.031758
[07:36:00.380] iteration 28649: loss: 0.040326, loss_s1: 0.030732, loss_fp: 0.007789, loss_freq: 0.016686
[07:36:00.979] iteration 28650: loss: 0.070946, loss_s1: 0.050243, loss_fp: 0.005017, loss_freq: 0.038527
[07:36:01.573] iteration 28651: loss: 0.068326, loss_s1: 0.071956, loss_fp: 0.003494, loss_freq: 0.029032
[07:36:02.178] iteration 28652: loss: 0.074904, loss_s1: 0.095822, loss_fp: 0.005006, loss_freq: 0.025301
[07:36:02.798] iteration 28653: loss: 0.078987, loss_s1: 0.065699, loss_fp: 0.006136, loss_freq: 0.051390
[07:36:03.446] iteration 28654: loss: 0.050995, loss_s1: 0.029677, loss_fp: 0.005002, loss_freq: 0.045711
[07:36:04.045] iteration 28655: loss: 0.058780, loss_s1: 0.047054, loss_fp: 0.007641, loss_freq: 0.032892
[07:36:04.641] iteration 28656: loss: 0.041980, loss_s1: 0.029573, loss_fp: 0.002697, loss_freq: 0.030573
[07:36:05.236] iteration 28657: loss: 0.064525, loss_s1: 0.070629, loss_fp: 0.007625, loss_freq: 0.023098
[07:36:05.902] iteration 28658: loss: 0.058319, loss_s1: 0.041872, loss_fp: 0.003731, loss_freq: 0.037346
[07:36:06.526] iteration 28659: loss: 0.076028, loss_s1: 0.048359, loss_fp: 0.009652, loss_freq: 0.067987
[07:36:07.128] iteration 28660: loss: 0.052633, loss_s1: 0.044824, loss_fp: 0.002883, loss_freq: 0.027329
[07:36:07.733] iteration 28661: loss: 0.048876, loss_s1: 0.053894, loss_fp: 0.002742, loss_freq: 0.019936
[07:36:08.333] iteration 28662: loss: 0.043028, loss_s1: 0.034095, loss_fp: 0.002817, loss_freq: 0.014776
[07:36:08.941] iteration 28663: loss: 0.049019, loss_s1: 0.037121, loss_fp: 0.006489, loss_freq: 0.030147
[07:36:09.544] iteration 28664: loss: 0.041769, loss_s1: 0.029772, loss_fp: 0.001765, loss_freq: 0.020316
[07:36:10.149] iteration 28665: loss: 0.027723, loss_s1: 0.021051, loss_fp: 0.001839, loss_freq: 0.011422
[07:36:10.748] iteration 28666: loss: 0.049546, loss_s1: 0.043852, loss_fp: 0.004931, loss_freq: 0.018930
[07:36:11.346] iteration 28667: loss: 0.044161, loss_s1: 0.039951, loss_fp: 0.001941, loss_freq: 0.011936
[07:36:11.941] iteration 28668: loss: 0.056730, loss_s1: 0.050597, loss_fp: 0.009981, loss_freq: 0.023947
[07:36:12.534] iteration 28669: loss: 0.050878, loss_s1: 0.036360, loss_fp: 0.008490, loss_freq: 0.030485
[07:36:13.138] iteration 28670: loss: 0.047936, loss_s1: 0.030305, loss_fp: 0.009028, loss_freq: 0.030785
[07:36:13.749] iteration 28671: loss: 0.058495, loss_s1: 0.045695, loss_fp: 0.001533, loss_freq: 0.036327
[07:36:14.351] iteration 28672: loss: 0.053578, loss_s1: 0.048198, loss_fp: 0.003554, loss_freq: 0.018465
[07:36:14.951] iteration 28673: loss: 0.068350, loss_s1: 0.071621, loss_fp: 0.006406, loss_freq: 0.033074
[07:36:15.554] iteration 28674: loss: 0.035122, loss_s1: 0.037258, loss_fp: 0.002535, loss_freq: 0.007628
[07:36:16.161] iteration 28675: loss: 0.080138, loss_s1: 0.069082, loss_fp: 0.004430, loss_freq: 0.055459
[07:36:16.769] iteration 28676: loss: 0.051689, loss_s1: 0.037520, loss_fp: 0.008233, loss_freq: 0.022066
[07:36:17.419] iteration 28677: loss: 0.082557, loss_s1: 0.086320, loss_fp: 0.004132, loss_freq: 0.027625
[07:36:18.017] iteration 28678: loss: 0.055121, loss_s1: 0.062537, loss_fp: 0.002211, loss_freq: 0.022519
[07:36:18.622] iteration 28679: loss: 0.052650, loss_s1: 0.058314, loss_fp: 0.005479, loss_freq: 0.010090
[07:36:19.236] iteration 28680: loss: 0.047711, loss_s1: 0.042923, loss_fp: 0.003298, loss_freq: 0.019846
[07:36:19.832] iteration 28681: loss: 0.037997, loss_s1: 0.030478, loss_fp: 0.002234, loss_freq: 0.008439
[07:36:20.438] iteration 28682: loss: 0.053420, loss_s1: 0.049672, loss_fp: 0.003743, loss_freq: 0.030675
[07:36:21.039] iteration 28683: loss: 0.059289, loss_s1: 0.058560, loss_fp: 0.005143, loss_freq: 0.019858
[07:36:21.649] iteration 28684: loss: 0.038558, loss_s1: 0.023445, loss_fp: 0.006438, loss_freq: 0.018068
[07:36:22.264] iteration 28685: loss: 0.057777, loss_s1: 0.025810, loss_fp: 0.017330, loss_freq: 0.042323
[07:36:22.868] iteration 28686: loss: 0.071040, loss_s1: 0.082370, loss_fp: 0.003876, loss_freq: 0.022007
[07:36:23.475] iteration 28687: loss: 0.047272, loss_s1: 0.017148, loss_fp: 0.003076, loss_freq: 0.051780
[07:36:24.080] iteration 28688: loss: 0.040669, loss_s1: 0.015823, loss_fp: 0.002501, loss_freq: 0.028839
[07:36:24.682] iteration 28689: loss: 0.052692, loss_s1: 0.054638, loss_fp: 0.002369, loss_freq: 0.023894
[07:36:25.284] iteration 28690: loss: 0.085707, loss_s1: 0.078291, loss_fp: 0.005370, loss_freq: 0.055007
[07:36:25.888] iteration 28691: loss: 0.046667, loss_s1: 0.042221, loss_fp: 0.003190, loss_freq: 0.025561
[07:36:26.498] iteration 28692: loss: 0.059403, loss_s1: 0.039711, loss_fp: 0.002181, loss_freq: 0.028318
[07:36:27.097] iteration 28693: loss: 0.066834, loss_s1: 0.060377, loss_fp: 0.017221, loss_freq: 0.023671
[07:36:27.720] iteration 28694: loss: 0.036388, loss_s1: 0.033559, loss_fp: 0.001595, loss_freq: 0.012507
[07:36:28.321] iteration 28695: loss: 0.048663, loss_s1: 0.039098, loss_fp: 0.002432, loss_freq: 0.023482
[07:36:28.925] iteration 28696: loss: 0.047775, loss_s1: 0.041141, loss_fp: 0.014542, loss_freq: 0.015525
[07:36:29.532] iteration 28697: loss: 0.052237, loss_s1: 0.051233, loss_fp: 0.002512, loss_freq: 0.016575
[07:36:30.134] iteration 28698: loss: 0.070863, loss_s1: 0.058556, loss_fp: 0.002105, loss_freq: 0.057496
[07:36:30.731] iteration 28699: loss: 0.057947, loss_s1: 0.052933, loss_fp: 0.009570, loss_freq: 0.028584
[07:36:31.338] iteration 28700: loss: 0.051647, loss_s1: 0.052264, loss_fp: 0.001950, loss_freq: 0.024054
[07:36:31.935] iteration 28701: loss: 0.055606, loss_s1: 0.046404, loss_fp: 0.009870, loss_freq: 0.024824
[07:36:32.532] iteration 28702: loss: 0.049961, loss_s1: 0.041177, loss_fp: 0.004393, loss_freq: 0.021057
[07:36:33.128] iteration 28703: loss: 0.026592, loss_s1: 0.011820, loss_fp: 0.001829, loss_freq: 0.013607
[07:36:33.730] iteration 28704: loss: 0.053519, loss_s1: 0.055959, loss_fp: 0.002186, loss_freq: 0.009395
[07:36:34.337] iteration 28705: loss: 0.040740, loss_s1: 0.037484, loss_fp: 0.006595, loss_freq: 0.013231
[07:36:34.932] iteration 28706: loss: 0.048543, loss_s1: 0.035250, loss_fp: 0.007974, loss_freq: 0.017021
[07:36:35.528] iteration 28707: loss: 0.048994, loss_s1: 0.034754, loss_fp: 0.004842, loss_freq: 0.022791
[07:36:36.124] iteration 28708: loss: 0.049000, loss_s1: 0.044053, loss_fp: 0.005000, loss_freq: 0.018675
[07:36:36.723] iteration 28709: loss: 0.049069, loss_s1: 0.041026, loss_fp: 0.004809, loss_freq: 0.029838
[07:36:37.317] iteration 28710: loss: 0.053790, loss_s1: 0.056847, loss_fp: 0.003918, loss_freq: 0.012923
[07:36:37.928] iteration 28711: loss: 0.079618, loss_s1: 0.077062, loss_fp: 0.014541, loss_freq: 0.025165
[07:36:38.525] iteration 28712: loss: 0.044668, loss_s1: 0.025718, loss_fp: 0.004873, loss_freq: 0.024677
[07:36:39.124] iteration 28713: loss: 0.057058, loss_s1: 0.066215, loss_fp: 0.003133, loss_freq: 0.020312
[07:36:39.719] iteration 28714: loss: 0.082159, loss_s1: 0.094525, loss_fp: 0.004629, loss_freq: 0.037137
[07:36:40.312] iteration 28715: loss: 0.066258, loss_s1: 0.066882, loss_fp: 0.003433, loss_freq: 0.031715
[07:36:40.918] iteration 28716: loss: 0.040295, loss_s1: 0.027178, loss_fp: 0.002089, loss_freq: 0.012691
[07:36:41.515] iteration 28717: loss: 0.032138, loss_s1: 0.016084, loss_fp: 0.004824, loss_freq: 0.022112
[07:36:42.131] iteration 28718: loss: 0.080819, loss_s1: 0.086011, loss_fp: 0.001566, loss_freq: 0.043963
[07:36:42.725] iteration 28719: loss: 0.065798, loss_s1: 0.052900, loss_fp: 0.004622, loss_freq: 0.043936
[07:36:43.325] iteration 28720: loss: 0.042518, loss_s1: 0.024552, loss_fp: 0.006566, loss_freq: 0.024258
[07:36:43.932] iteration 28721: loss: 0.046456, loss_s1: 0.031098, loss_fp: 0.005907, loss_freq: 0.026215
[07:36:44.532] iteration 28722: loss: 0.061296, loss_s1: 0.061710, loss_fp: 0.010650, loss_freq: 0.032336
[07:36:45.142] iteration 28723: loss: 0.032837, loss_s1: 0.016133, loss_fp: 0.000868, loss_freq: 0.011644
[07:36:45.745] iteration 28724: loss: 0.071464, loss_s1: 0.064342, loss_fp: 0.005231, loss_freq: 0.046966
[07:36:46.350] iteration 28725: loss: 0.032603, loss_s1: 0.024887, loss_fp: 0.003866, loss_freq: 0.012463
[07:36:46.943] iteration 28726: loss: 0.049736, loss_s1: 0.027901, loss_fp: 0.008712, loss_freq: 0.038841
[07:36:47.538] iteration 28727: loss: 0.047390, loss_s1: 0.027343, loss_fp: 0.005864, loss_freq: 0.036421
[07:36:48.143] iteration 28728: loss: 0.070713, loss_s1: 0.078969, loss_fp: 0.002244, loss_freq: 0.029953
[07:36:48.738] iteration 28729: loss: 0.040700, loss_s1: 0.032898, loss_fp: 0.003857, loss_freq: 0.022133
[07:36:49.338] iteration 28730: loss: 0.058165, loss_s1: 0.044951, loss_fp: 0.002236, loss_freq: 0.040127
[07:36:50.240] iteration 28731: loss: 0.064825, loss_s1: 0.063343, loss_fp: 0.005613, loss_freq: 0.024790
[07:36:50.844] iteration 28732: loss: 0.059088, loss_s1: 0.050002, loss_fp: 0.001679, loss_freq: 0.025317
[07:36:51.442] iteration 28733: loss: 0.060782, loss_s1: 0.062866, loss_fp: 0.005611, loss_freq: 0.023598
[07:36:52.058] iteration 28734: loss: 0.036723, loss_s1: 0.025315, loss_fp: 0.003604, loss_freq: 0.018559
[07:36:52.666] iteration 28735: loss: 0.046049, loss_s1: 0.044332, loss_fp: 0.006531, loss_freq: 0.015027
[07:36:53.298] iteration 28736: loss: 0.069151, loss_s1: 0.075881, loss_fp: 0.003188, loss_freq: 0.024964
[07:36:53.895] iteration 28737: loss: 0.032902, loss_s1: 0.021810, loss_fp: 0.003287, loss_freq: 0.013171
[07:36:54.495] iteration 28738: loss: 0.037178, loss_s1: 0.029945, loss_fp: 0.005785, loss_freq: 0.013261
[07:36:55.109] iteration 28739: loss: 0.047554, loss_s1: 0.050904, loss_fp: 0.002693, loss_freq: 0.022740
[07:36:55.713] iteration 28740: loss: 0.050884, loss_s1: 0.032939, loss_fp: 0.006740, loss_freq: 0.028648
[07:36:56.325] iteration 28741: loss: 0.053689, loss_s1: 0.047509, loss_fp: 0.003140, loss_freq: 0.021995
[07:36:56.924] iteration 28742: loss: 0.066690, loss_s1: 0.051056, loss_fp: 0.003885, loss_freq: 0.050586
[07:36:57.517] iteration 28743: loss: 0.055409, loss_s1: 0.046948, loss_fp: 0.004545, loss_freq: 0.032412
[07:36:58.164] iteration 28744: loss: 0.058797, loss_s1: 0.052025, loss_fp: 0.006997, loss_freq: 0.026170
[07:36:58.768] iteration 28745: loss: 0.058225, loss_s1: 0.066632, loss_fp: 0.005550, loss_freq: 0.012626
[07:36:59.369] iteration 28746: loss: 0.038743, loss_s1: 0.029766, loss_fp: 0.006580, loss_freq: 0.011359
[07:36:59.977] iteration 28747: loss: 0.078494, loss_s1: 0.080373, loss_fp: 0.009329, loss_freq: 0.049522
[07:37:00.590] iteration 28748: loss: 0.077261, loss_s1: 0.038468, loss_fp: 0.001212, loss_freq: 0.010686
[07:37:01.197] iteration 28749: loss: 0.089605, loss_s1: 0.083649, loss_fp: 0.010219, loss_freq: 0.056686
[07:37:01.801] iteration 28750: loss: 0.055096, loss_s1: 0.056052, loss_fp: 0.004037, loss_freq: 0.013722
[07:37:02.405] iteration 28751: loss: 0.038306, loss_s1: 0.029330, loss_fp: 0.006655, loss_freq: 0.013569
[07:37:03.029] iteration 28752: loss: 0.057577, loss_s1: 0.057318, loss_fp: 0.007363, loss_freq: 0.026441
[07:37:03.630] iteration 28753: loss: 0.055444, loss_s1: 0.036054, loss_fp: 0.001246, loss_freq: 0.032089
[07:37:04.236] iteration 28754: loss: 0.045451, loss_s1: 0.047753, loss_fp: 0.001870, loss_freq: 0.016463
[07:37:04.833] iteration 28755: loss: 0.045334, loss_s1: 0.036872, loss_fp: 0.004831, loss_freq: 0.022344
[07:37:05.432] iteration 28756: loss: 0.049659, loss_s1: 0.053010, loss_fp: 0.001579, loss_freq: 0.024139
[07:37:06.080] iteration 28757: loss: 0.062010, loss_s1: 0.046296, loss_fp: 0.005658, loss_freq: 0.035229
[07:37:06.730] iteration 28758: loss: 0.050701, loss_s1: 0.034903, loss_fp: 0.007065, loss_freq: 0.022480
[07:37:07.383] iteration 28759: loss: 0.055289, loss_s1: 0.039178, loss_fp: 0.005950, loss_freq: 0.038050
[07:37:08.013] iteration 28760: loss: 0.056419, loss_s1: 0.033652, loss_fp: 0.001579, loss_freq: 0.036919
[07:37:08.617] iteration 28761: loss: 0.059868, loss_s1: 0.045249, loss_fp: 0.004888, loss_freq: 0.050539
[07:37:09.221] iteration 28762: loss: 0.086097, loss_s1: 0.070900, loss_fp: 0.003710, loss_freq: 0.064714
[07:37:09.832] iteration 28763: loss: 0.052966, loss_s1: 0.043091, loss_fp: 0.006681, loss_freq: 0.029523
[07:37:10.445] iteration 28764: loss: 0.058079, loss_s1: 0.047556, loss_fp: 0.008101, loss_freq: 0.024038
[07:37:11.060] iteration 28765: loss: 0.049261, loss_s1: 0.060187, loss_fp: 0.002580, loss_freq: 0.018355
[07:37:11.664] iteration 28766: loss: 0.047837, loss_s1: 0.021622, loss_fp: 0.004212, loss_freq: 0.016149
[07:37:12.310] iteration 28767: loss: 0.064574, loss_s1: 0.052796, loss_fp: 0.004514, loss_freq: 0.043907
[07:37:12.963] iteration 28768: loss: 0.047583, loss_s1: 0.044808, loss_fp: 0.010269, loss_freq: 0.016407
[07:37:13.611] iteration 28769: loss: 0.087162, loss_s1: 0.103654, loss_fp: 0.006848, loss_freq: 0.035154
[07:37:14.269] iteration 28770: loss: 0.048171, loss_s1: 0.043965, loss_fp: 0.002297, loss_freq: 0.028193
[07:37:14.915] iteration 28771: loss: 0.051547, loss_s1: 0.029450, loss_fp: 0.007964, loss_freq: 0.030833
[07:37:15.532] iteration 28772: loss: 0.069537, loss_s1: 0.088039, loss_fp: 0.003170, loss_freq: 0.019160
[07:37:16.143] iteration 28773: loss: 0.069402, loss_s1: 0.083763, loss_fp: 0.004805, loss_freq: 0.027444
[07:37:16.750] iteration 28774: loss: 0.090292, loss_s1: 0.092476, loss_fp: 0.004195, loss_freq: 0.063156
[07:37:17.354] iteration 28775: loss: 0.062423, loss_s1: 0.047351, loss_fp: 0.006310, loss_freq: 0.038810
[07:37:17.960] iteration 28776: loss: 0.061593, loss_s1: 0.053259, loss_fp: 0.003796, loss_freq: 0.034226
[07:37:18.580] iteration 28777: loss: 0.069772, loss_s1: 0.054636, loss_fp: 0.012153, loss_freq: 0.045135
[07:37:19.190] iteration 28778: loss: 0.045018, loss_s1: 0.022282, loss_fp: 0.002241, loss_freq: 0.037642
[07:37:19.805] iteration 28779: loss: 0.041140, loss_s1: 0.032070, loss_fp: 0.004112, loss_freq: 0.011065
[07:37:20.436] iteration 28780: loss: 0.053070, loss_s1: 0.042206, loss_fp: 0.004114, loss_freq: 0.026061
[07:37:21.044] iteration 28781: loss: 0.042602, loss_s1: 0.018384, loss_fp: 0.003067, loss_freq: 0.033345
[07:37:21.655] iteration 28782: loss: 0.038197, loss_s1: 0.025741, loss_fp: 0.004974, loss_freq: 0.025644
[07:37:22.267] iteration 28783: loss: 0.052495, loss_s1: 0.049911, loss_fp: 0.003067, loss_freq: 0.022835
[07:37:22.872] iteration 28784: loss: 0.056015, loss_s1: 0.047546, loss_fp: 0.001538, loss_freq: 0.036588
[07:37:23.478] iteration 28785: loss: 0.037301, loss_s1: 0.024303, loss_fp: 0.004817, loss_freq: 0.014183
[07:37:24.096] iteration 28786: loss: 0.030811, loss_s1: 0.003682, loss_fp: 0.002615, loss_freq: 0.021805
[07:37:24.698] iteration 28787: loss: 0.064591, loss_s1: 0.054817, loss_fp: 0.003535, loss_freq: 0.046783
[07:37:25.302] iteration 28788: loss: 0.043864, loss_s1: 0.022472, loss_fp: 0.005121, loss_freq: 0.019705
[07:37:25.902] iteration 28789: loss: 0.035975, loss_s1: 0.017998, loss_fp: 0.003102, loss_freq: 0.025174
[07:37:26.500] iteration 28790: loss: 0.077887, loss_s1: 0.049371, loss_fp: 0.001987, loss_freq: 0.076655
[07:37:27.095] iteration 28791: loss: 0.029113, loss_s1: 0.020893, loss_fp: 0.005344, loss_freq: 0.008895
[07:37:27.694] iteration 28792: loss: 0.059614, loss_s1: 0.028413, loss_fp: 0.003280, loss_freq: 0.053434
[07:37:28.292] iteration 28793: loss: 0.040116, loss_s1: 0.025402, loss_fp: 0.004307, loss_freq: 0.010755
[07:37:28.891] iteration 28794: loss: 0.054184, loss_s1: 0.059048, loss_fp: 0.004769, loss_freq: 0.020625
[07:37:29.500] iteration 28795: loss: 0.031178, loss_s1: 0.021427, loss_fp: 0.000491, loss_freq: 0.006595
[07:37:30.110] iteration 28796: loss: 0.050343, loss_s1: 0.045836, loss_fp: 0.002224, loss_freq: 0.033058
[07:37:30.714] iteration 28797: loss: 0.036560, loss_s1: 0.020755, loss_fp: 0.003678, loss_freq: 0.015683
[07:37:31.331] iteration 28798: loss: 0.122891, loss_s1: 0.163749, loss_fp: 0.009808, loss_freq: 0.043508
[07:37:31.946] iteration 28799: loss: 0.042656, loss_s1: 0.037917, loss_fp: 0.003645, loss_freq: 0.018616
[07:37:32.569] iteration 28800: loss: 0.051686, loss_s1: 0.036180, loss_fp: 0.003492, loss_freq: 0.045725
[07:37:35.748] iteration 28800 : mean_dice : 0.747864
[07:37:36.375] iteration 28801: loss: 0.060987, loss_s1: 0.055448, loss_fp: 0.008361, loss_freq: 0.024619
[07:37:36.984] iteration 28802: loss: 0.056360, loss_s1: 0.043870, loss_fp: 0.002431, loss_freq: 0.034666
[07:37:37.593] iteration 28803: loss: 0.060945, loss_s1: 0.048982, loss_fp: 0.007101, loss_freq: 0.028497
[07:37:38.197] iteration 28804: loss: 0.045833, loss_s1: 0.046948, loss_fp: 0.004014, loss_freq: 0.012895
[07:37:38.798] iteration 28805: loss: 0.056612, loss_s1: 0.026045, loss_fp: 0.002700, loss_freq: 0.062247
[07:37:39.405] iteration 28806: loss: 0.052798, loss_s1: 0.050756, loss_fp: 0.010595, loss_freq: 0.014985
[07:37:40.017] iteration 28807: loss: 0.054564, loss_s1: 0.042035, loss_fp: 0.004302, loss_freq: 0.034552
[07:37:40.618] iteration 28808: loss: 0.091642, loss_s1: 0.110516, loss_fp: 0.008559, loss_freq: 0.037164
[07:37:41.226] iteration 28809: loss: 0.050089, loss_s1: 0.048184, loss_fp: 0.004490, loss_freq: 0.026126
[07:37:41.827] iteration 28810: loss: 0.056854, loss_s1: 0.049630, loss_fp: 0.005810, loss_freq: 0.026677
[07:37:42.475] iteration 28811: loss: 0.037159, loss_s1: 0.030591, loss_fp: 0.004628, loss_freq: 0.008492
[07:37:43.074] iteration 28812: loss: 0.045069, loss_s1: 0.033384, loss_fp: 0.002554, loss_freq: 0.025971
[07:37:43.690] iteration 28813: loss: 0.046631, loss_s1: 0.046488, loss_fp: 0.003162, loss_freq: 0.022036
[07:37:44.294] iteration 28814: loss: 0.037439, loss_s1: 0.030285, loss_fp: 0.001534, loss_freq: 0.009139
[07:37:44.897] iteration 28815: loss: 0.037787, loss_s1: 0.024810, loss_fp: 0.004623, loss_freq: 0.017774
[07:37:45.497] iteration 28816: loss: 0.061122, loss_s1: 0.066646, loss_fp: 0.002957, loss_freq: 0.015874
[07:37:46.104] iteration 28817: loss: 0.084579, loss_s1: 0.097238, loss_fp: 0.003820, loss_freq: 0.048157
[07:37:46.711] iteration 28818: loss: 0.048705, loss_s1: 0.048873, loss_fp: 0.004703, loss_freq: 0.014714
[07:37:47.322] iteration 28819: loss: 0.045798, loss_s1: 0.034441, loss_fp: 0.007019, loss_freq: 0.018309
[07:37:47.923] iteration 28820: loss: 0.030365, loss_s1: 0.013922, loss_fp: 0.004856, loss_freq: 0.009369
[07:37:48.532] iteration 28821: loss: 0.065270, loss_s1: 0.075925, loss_fp: 0.003029, loss_freq: 0.021686
[07:37:49.128] iteration 28822: loss: 0.076868, loss_s1: 0.034969, loss_fp: 0.006576, loss_freq: 0.088682
[07:37:49.730] iteration 28823: loss: 0.054049, loss_s1: 0.040047, loss_fp: 0.004851, loss_freq: 0.023430
[07:37:50.342] iteration 28824: loss: 0.046125, loss_s1: 0.040990, loss_fp: 0.006612, loss_freq: 0.019544
[07:37:50.946] iteration 28825: loss: 0.055659, loss_s1: 0.033799, loss_fp: 0.004605, loss_freq: 0.036978
[07:37:51.562] iteration 28826: loss: 0.077089, loss_s1: 0.094429, loss_fp: 0.012698, loss_freq: 0.028446
[07:37:52.174] iteration 28827: loss: 0.057204, loss_s1: 0.032466, loss_fp: 0.004129, loss_freq: 0.045198
[07:37:52.794] iteration 28828: loss: 0.065863, loss_s1: 0.031770, loss_fp: 0.002991, loss_freq: 0.063135
[07:37:53.400] iteration 28829: loss: 0.078458, loss_s1: 0.059618, loss_fp: 0.002442, loss_freq: 0.072127
[07:37:54.006] iteration 28830: loss: 0.042648, loss_s1: 0.035375, loss_fp: 0.008389, loss_freq: 0.014509
[07:37:54.652] iteration 28831: loss: 0.078292, loss_s1: 0.081829, loss_fp: 0.003169, loss_freq: 0.050947
[07:37:55.262] iteration 28832: loss: 0.048527, loss_s1: 0.035432, loss_fp: 0.003826, loss_freq: 0.014368
[07:37:55.862] iteration 28833: loss: 0.048681, loss_s1: 0.048017, loss_fp: 0.007362, loss_freq: 0.015342
[07:37:56.468] iteration 28834: loss: 0.043353, loss_s1: 0.024487, loss_fp: 0.013991, loss_freq: 0.019759
[07:37:57.065] iteration 28835: loss: 0.024880, loss_s1: 0.016058, loss_fp: 0.001484, loss_freq: 0.014572
[07:37:57.673] iteration 28836: loss: 0.058663, loss_s1: 0.059744, loss_fp: 0.003350, loss_freq: 0.020305
[07:37:58.288] iteration 28837: loss: 0.055868, loss_s1: 0.057978, loss_fp: 0.004110, loss_freq: 0.016705
[07:37:58.889] iteration 28838: loss: 0.030121, loss_s1: 0.023287, loss_fp: 0.002903, loss_freq: 0.008332
[07:37:59.490] iteration 28839: loss: 0.049886, loss_s1: 0.038644, loss_fp: 0.004278, loss_freq: 0.024524
[07:38:00.101] iteration 28840: loss: 0.031762, loss_s1: 0.023703, loss_fp: 0.001913, loss_freq: 0.014454
[07:38:00.701] iteration 28841: loss: 0.044674, loss_s1: 0.044261, loss_fp: 0.003011, loss_freq: 0.013219
[07:38:01.311] iteration 28842: loss: 0.042773, loss_s1: 0.025525, loss_fp: 0.009894, loss_freq: 0.020197
[07:38:01.913] iteration 28843: loss: 0.061762, loss_s1: 0.057061, loss_fp: 0.003763, loss_freq: 0.037297
[07:38:02.513] iteration 28844: loss: 0.029159, loss_s1: 0.021473, loss_fp: 0.002400, loss_freq: 0.014396
[07:38:03.129] iteration 28845: loss: 0.061544, loss_s1: 0.039459, loss_fp: 0.006862, loss_freq: 0.047088
[07:38:03.760] iteration 28846: loss: 0.043691, loss_s1: 0.031515, loss_fp: 0.001216, loss_freq: 0.026612
[07:38:04.399] iteration 28847: loss: 0.081018, loss_s1: 0.074279, loss_fp: 0.009462, loss_freq: 0.050780
[07:38:04.989] iteration 28848: loss: 0.068677, loss_s1: 0.074671, loss_fp: 0.004165, loss_freq: 0.031204
[07:38:05.599] iteration 28849: loss: 0.055097, loss_s1: 0.036561, loss_fp: 0.005435, loss_freq: 0.039867
[07:38:06.208] iteration 28850: loss: 0.023456, loss_s1: 0.008290, loss_fp: 0.002590, loss_freq: 0.004921
[07:38:06.819] iteration 28851: loss: 0.033056, loss_s1: 0.031073, loss_fp: 0.001776, loss_freq: 0.006768
[07:38:07.425] iteration 28852: loss: 0.075453, loss_s1: 0.069769, loss_fp: 0.008838, loss_freq: 0.055576
[07:38:08.024] iteration 28853: loss: 0.062309, loss_s1: 0.053237, loss_fp: 0.009375, loss_freq: 0.033484
[07:38:08.624] iteration 28854: loss: 0.029025, loss_s1: 0.016743, loss_fp: 0.002699, loss_freq: 0.012056
[07:38:09.241] iteration 28855: loss: 0.065871, loss_s1: 0.055338, loss_fp: 0.007544, loss_freq: 0.037174
[07:38:09.843] iteration 28856: loss: 0.037125, loss_s1: 0.028472, loss_fp: 0.004055, loss_freq: 0.015079
[07:38:10.442] iteration 28857: loss: 0.060357, loss_s1: 0.045927, loss_fp: 0.009926, loss_freq: 0.043519
[07:38:11.046] iteration 28858: loss: 0.040070, loss_s1: 0.036401, loss_fp: 0.001486, loss_freq: 0.006345
[07:38:11.641] iteration 28859: loss: 0.058953, loss_s1: 0.064826, loss_fp: 0.002925, loss_freq: 0.022197
[07:38:12.241] iteration 28860: loss: 0.060534, loss_s1: 0.053042, loss_fp: 0.019885, loss_freq: 0.020592
[07:38:12.841] iteration 28861: loss: 0.077309, loss_s1: 0.096406, loss_fp: 0.010469, loss_freq: 0.023876
[07:38:13.451] iteration 28862: loss: 0.052036, loss_s1: 0.050818, loss_fp: 0.002487, loss_freq: 0.020450
[07:38:14.054] iteration 28863: loss: 0.068579, loss_s1: 0.064876, loss_fp: 0.002662, loss_freq: 0.034955
[07:38:14.698] iteration 28864: loss: 0.052622, loss_s1: 0.052542, loss_fp: 0.006456, loss_freq: 0.018887
[07:38:15.312] iteration 28865: loss: 0.106979, loss_s1: 0.119086, loss_fp: 0.005221, loss_freq: 0.054624
[07:38:15.941] iteration 28866: loss: 0.032296, loss_s1: 0.030221, loss_fp: 0.003236, loss_freq: 0.006304
[07:38:16.550] iteration 28867: loss: 0.069570, loss_s1: 0.063842, loss_fp: 0.002226, loss_freq: 0.022886
[07:38:17.151] iteration 28868: loss: 0.048753, loss_s1: 0.041760, loss_fp: 0.006038, loss_freq: 0.025462
[07:38:17.763] iteration 28869: loss: 0.097953, loss_s1: 0.126737, loss_fp: 0.007468, loss_freq: 0.030326
[07:38:18.363] iteration 28870: loss: 0.057322, loss_s1: 0.071442, loss_fp: 0.004288, loss_freq: 0.018114
[07:38:18.976] iteration 28871: loss: 0.060971, loss_s1: 0.048394, loss_fp: 0.004356, loss_freq: 0.033673
[07:38:19.579] iteration 28872: loss: 0.051298, loss_s1: 0.033847, loss_fp: 0.001437, loss_freq: 0.031818
[07:38:20.176] iteration 28873: loss: 0.054567, loss_s1: 0.055140, loss_fp: 0.005198, loss_freq: 0.023383
[07:38:20.781] iteration 28874: loss: 0.028334, loss_s1: 0.018429, loss_fp: 0.001957, loss_freq: 0.008785
[07:38:21.393] iteration 28875: loss: 0.022390, loss_s1: 0.009322, loss_fp: 0.003831, loss_freq: 0.007606
[07:38:22.001] iteration 28876: loss: 0.072341, loss_s1: 0.024221, loss_fp: 0.004715, loss_freq: 0.082435
[07:38:22.610] iteration 28877: loss: 0.043053, loss_s1: 0.033777, loss_fp: 0.001536, loss_freq: 0.020871
[07:38:23.212] iteration 28878: loss: 0.105603, loss_s1: 0.131704, loss_fp: 0.003303, loss_freq: 0.052919
[07:38:23.824] iteration 28879: loss: 0.043259, loss_s1: 0.029142, loss_fp: 0.002690, loss_freq: 0.029099
[07:38:24.428] iteration 28880: loss: 0.053301, loss_s1: 0.054826, loss_fp: 0.001692, loss_freq: 0.016588
[07:38:25.032] iteration 28881: loss: 0.064274, loss_s1: 0.042737, loss_fp: 0.007357, loss_freq: 0.049245
[07:38:25.637] iteration 28882: loss: 0.056949, loss_s1: 0.041959, loss_fp: 0.002127, loss_freq: 0.037888
[07:38:26.242] iteration 28883: loss: 0.052806, loss_s1: 0.041490, loss_fp: 0.004112, loss_freq: 0.028719
[07:38:26.843] iteration 28884: loss: 0.060607, loss_s1: 0.044724, loss_fp: 0.005699, loss_freq: 0.045222
[07:38:27.444] iteration 28885: loss: 0.074873, loss_s1: 0.044829, loss_fp: 0.012776, loss_freq: 0.034017
[07:38:28.045] iteration 28886: loss: 0.031715, loss_s1: 0.020560, loss_fp: 0.001065, loss_freq: 0.011161
[07:38:28.662] iteration 28887: loss: 0.025534, loss_s1: 0.022102, loss_fp: 0.003186, loss_freq: 0.007021
[07:38:29.273] iteration 28888: loss: 0.080631, loss_s1: 0.068450, loss_fp: 0.002031, loss_freq: 0.061026
[07:38:29.873] iteration 28889: loss: 0.041430, loss_s1: 0.015770, loss_fp: 0.011620, loss_freq: 0.028369
[07:38:30.480] iteration 28890: loss: 0.064395, loss_s1: 0.057216, loss_fp: 0.007957, loss_freq: 0.032704
[07:38:31.091] iteration 28891: loss: 0.062191, loss_s1: 0.081597, loss_fp: 0.001124, loss_freq: 0.005959
[07:38:31.741] iteration 28892: loss: 0.056338, loss_s1: 0.053369, loss_fp: 0.004214, loss_freq: 0.035729
[07:38:32.378] iteration 28893: loss: 0.032697, loss_s1: 0.020015, loss_fp: 0.004699, loss_freq: 0.008695
[07:38:32.986] iteration 28894: loss: 0.063924, loss_s1: 0.064550, loss_fp: 0.003397, loss_freq: 0.034489
[07:38:33.595] iteration 28895: loss: 0.031538, loss_s1: 0.009798, loss_fp: 0.001504, loss_freq: 0.022294
[07:38:34.214] iteration 28896: loss: 0.045830, loss_s1: 0.036974, loss_fp: 0.004377, loss_freq: 0.030574
[07:38:34.816] iteration 28897: loss: 0.033205, loss_s1: 0.023080, loss_fp: 0.002023, loss_freq: 0.010904
[07:38:35.420] iteration 28898: loss: 0.083153, loss_s1: 0.059791, loss_fp: 0.008486, loss_freq: 0.068095
[07:38:36.022] iteration 28899: loss: 0.045707, loss_s1: 0.024263, loss_fp: 0.003175, loss_freq: 0.039422
[07:38:36.615] iteration 28900: loss: 0.054091, loss_s1: 0.050730, loss_fp: 0.001530, loss_freq: 0.016535
[07:38:37.497] iteration 28901: loss: 0.049850, loss_s1: 0.030380, loss_fp: 0.005548, loss_freq: 0.031155
[07:38:38.100] iteration 28902: loss: 0.071051, loss_s1: 0.071758, loss_fp: 0.003430, loss_freq: 0.029371
[07:38:38.703] iteration 28903: loss: 0.064296, loss_s1: 0.058276, loss_fp: 0.002578, loss_freq: 0.042551
[07:38:39.305] iteration 28904: loss: 0.052379, loss_s1: 0.057936, loss_fp: 0.002565, loss_freq: 0.010545
[07:38:39.920] iteration 28905: loss: 0.037791, loss_s1: 0.030399, loss_fp: 0.003440, loss_freq: 0.018712
[07:38:40.530] iteration 28906: loss: 0.061511, loss_s1: 0.038459, loss_fp: 0.002670, loss_freq: 0.049246
[07:38:41.129] iteration 28907: loss: 0.037970, loss_s1: 0.021094, loss_fp: 0.000317, loss_freq: 0.022491
[07:38:41.729] iteration 28908: loss: 0.051118, loss_s1: 0.047621, loss_fp: 0.002673, loss_freq: 0.018535
[07:38:42.338] iteration 28909: loss: 0.044485, loss_s1: 0.053537, loss_fp: 0.001121, loss_freq: 0.014636
[07:38:42.943] iteration 28910: loss: 0.055198, loss_s1: 0.042615, loss_fp: 0.007192, loss_freq: 0.023573
[07:38:43.542] iteration 28911: loss: 0.048157, loss_s1: 0.028094, loss_fp: 0.006301, loss_freq: 0.021891
[07:38:44.144] iteration 28912: loss: 0.079479, loss_s1: 0.083898, loss_fp: 0.003160, loss_freq: 0.044252
[07:38:44.745] iteration 28913: loss: 0.072041, loss_s1: 0.054868, loss_fp: 0.002531, loss_freq: 0.064964
[07:38:45.350] iteration 28914: loss: 0.063334, loss_s1: 0.060316, loss_fp: 0.008377, loss_freq: 0.028453
[07:38:45.945] iteration 28915: loss: 0.056973, loss_s1: 0.048233, loss_fp: 0.003355, loss_freq: 0.029083
[07:38:46.555] iteration 28916: loss: 0.034366, loss_s1: 0.027149, loss_fp: 0.002494, loss_freq: 0.009243
[07:38:47.156] iteration 28917: loss: 0.058901, loss_s1: 0.044826, loss_fp: 0.007538, loss_freq: 0.047291
[07:38:47.757] iteration 28918: loss: 0.038427, loss_s1: 0.035316, loss_fp: 0.004092, loss_freq: 0.010261
[07:38:48.356] iteration 28919: loss: 0.045530, loss_s1: 0.030362, loss_fp: 0.006100, loss_freq: 0.030764
[07:38:48.951] iteration 28920: loss: 0.064078, loss_s1: 0.086023, loss_fp: 0.001811, loss_freq: 0.009423
[07:38:49.591] iteration 28921: loss: 0.046615, loss_s1: 0.025932, loss_fp: 0.002180, loss_freq: 0.031144
[07:38:50.240] iteration 28922: loss: 0.046864, loss_s1: 0.022002, loss_fp: 0.002899, loss_freq: 0.047581
[07:38:50.866] iteration 28923: loss: 0.048335, loss_s1: 0.036289, loss_fp: 0.003136, loss_freq: 0.027074
[07:38:51.477] iteration 28924: loss: 0.041224, loss_s1: 0.024626, loss_fp: 0.001862, loss_freq: 0.024140
[07:38:52.087] iteration 28925: loss: 0.058173, loss_s1: 0.031380, loss_fp: 0.006884, loss_freq: 0.053117
[07:38:52.696] iteration 28926: loss: 0.050136, loss_s1: 0.045223, loss_fp: 0.004482, loss_freq: 0.024891
[07:38:53.299] iteration 28927: loss: 0.050256, loss_s1: 0.033625, loss_fp: 0.004404, loss_freq: 0.023591
[07:38:53.905] iteration 28928: loss: 0.086253, loss_s1: 0.109104, loss_fp: 0.003550, loss_freq: 0.029457
[07:38:54.515] iteration 28929: loss: 0.036783, loss_s1: 0.030223, loss_fp: 0.002265, loss_freq: 0.017690
[07:38:55.122] iteration 28930: loss: 0.066727, loss_s1: 0.064164, loss_fp: 0.007293, loss_freq: 0.031499
[07:38:55.727] iteration 28931: loss: 0.067672, loss_s1: 0.041114, loss_fp: 0.005537, loss_freq: 0.070615
[07:38:56.343] iteration 28932: loss: 0.059873, loss_s1: 0.042468, loss_fp: 0.010220, loss_freq: 0.029772
[07:38:56.959] iteration 28933: loss: 0.078272, loss_s1: 0.088572, loss_fp: 0.002814, loss_freq: 0.038002
[07:38:57.553] iteration 28934: loss: 0.037621, loss_s1: 0.035173, loss_fp: 0.002247, loss_freq: 0.006831
[07:38:58.147] iteration 28935: loss: 0.053453, loss_s1: 0.072422, loss_fp: 0.001729, loss_freq: 0.012839
[07:38:58.781] iteration 28936: loss: 0.047748, loss_s1: 0.046075, loss_fp: 0.001729, loss_freq: 0.015120
[07:38:59.427] iteration 28937: loss: 0.073118, loss_s1: 0.057648, loss_fp: 0.005295, loss_freq: 0.054446
[07:39:00.078] iteration 28938: loss: 0.061820, loss_s1: 0.070400, loss_fp: 0.005939, loss_freq: 0.021462
[07:39:00.727] iteration 28939: loss: 0.082885, loss_s1: 0.098594, loss_fp: 0.002843, loss_freq: 0.029745
[07:39:01.352] iteration 28940: loss: 0.058779, loss_s1: 0.063992, loss_fp: 0.006352, loss_freq: 0.023361
[07:39:01.964] iteration 28941: loss: 0.063019, loss_s1: 0.056973, loss_fp: 0.005238, loss_freq: 0.028303
[07:39:02.564] iteration 28942: loss: 0.057376, loss_s1: 0.041303, loss_fp: 0.003541, loss_freq: 0.036942
[07:39:03.172] iteration 28943: loss: 0.108188, loss_s1: 0.138111, loss_fp: 0.004193, loss_freq: 0.052751
[07:39:03.778] iteration 28944: loss: 0.080026, loss_s1: 0.103961, loss_fp: 0.004754, loss_freq: 0.030999
[07:39:04.386] iteration 28945: loss: 0.069850, loss_s1: 0.068803, loss_fp: 0.006861, loss_freq: 0.023766
[07:39:04.990] iteration 28946: loss: 0.079575, loss_s1: 0.097393, loss_fp: 0.003731, loss_freq: 0.025226
[07:39:05.585] iteration 28947: loss: 0.064903, loss_s1: 0.044127, loss_fp: 0.004228, loss_freq: 0.032423
[07:39:06.195] iteration 28948: loss: 0.051535, loss_s1: 0.041756, loss_fp: 0.005595, loss_freq: 0.028103
[07:39:06.807] iteration 28949: loss: 0.056967, loss_s1: 0.075717, loss_fp: 0.002979, loss_freq: 0.008280
[07:39:07.419] iteration 28950: loss: 0.053848, loss_s1: 0.058532, loss_fp: 0.001108, loss_freq: 0.016513
[07:39:08.018] iteration 28951: loss: 0.042559, loss_s1: 0.021442, loss_fp: 0.008203, loss_freq: 0.019187
[07:39:08.616] iteration 28952: loss: 0.038904, loss_s1: 0.038748, loss_fp: 0.004425, loss_freq: 0.017946
[07:39:09.229] iteration 28953: loss: 0.059737, loss_s1: 0.054964, loss_fp: 0.004049, loss_freq: 0.023648
[07:39:09.865] iteration 28954: loss: 0.048568, loss_s1: 0.044894, loss_fp: 0.003520, loss_freq: 0.021743
[07:39:10.464] iteration 28955: loss: 0.048344, loss_s1: 0.033902, loss_fp: 0.001752, loss_freq: 0.015480
[07:39:11.067] iteration 28956: loss: 0.042112, loss_s1: 0.037433, loss_fp: 0.001280, loss_freq: 0.009389
[07:39:11.665] iteration 28957: loss: 0.057430, loss_s1: 0.051416, loss_fp: 0.007727, loss_freq: 0.032467
[07:39:12.271] iteration 28958: loss: 0.039850, loss_s1: 0.033054, loss_fp: 0.002178, loss_freq: 0.012998
[07:39:12.878] iteration 28959: loss: 0.050124, loss_s1: 0.048472, loss_fp: 0.003377, loss_freq: 0.021233
[07:39:13.488] iteration 28960: loss: 0.045787, loss_s1: 0.028439, loss_fp: 0.002876, loss_freq: 0.032097
[07:39:14.094] iteration 28961: loss: 0.020110, loss_s1: 0.010599, loss_fp: 0.001857, loss_freq: 0.005955
[07:39:14.697] iteration 28962: loss: 0.077942, loss_s1: 0.052954, loss_fp: 0.001799, loss_freq: 0.067200
[07:39:15.350] iteration 28963: loss: 0.047436, loss_s1: 0.044330, loss_fp: 0.001509, loss_freq: 0.020359
[07:39:16.002] iteration 28964: loss: 0.047192, loss_s1: 0.037369, loss_fp: 0.004371, loss_freq: 0.024726
[07:39:16.652] iteration 28965: loss: 0.039017, loss_s1: 0.023306, loss_fp: 0.006615, loss_freq: 0.019068
[07:39:17.300] iteration 28966: loss: 0.045694, loss_s1: 0.028518, loss_fp: 0.004558, loss_freq: 0.032891
[07:39:17.954] iteration 28967: loss: 0.045571, loss_s1: 0.045645, loss_fp: 0.001751, loss_freq: 0.013663
[07:39:18.569] iteration 28968: loss: 0.066137, loss_s1: 0.066197, loss_fp: 0.013666, loss_freq: 0.026931
[07:39:19.173] iteration 28969: loss: 0.041451, loss_s1: 0.031302, loss_fp: 0.001296, loss_freq: 0.018525
[07:39:19.788] iteration 28970: loss: 0.053467, loss_s1: 0.054947, loss_fp: 0.000898, loss_freq: 0.013588
[07:39:20.392] iteration 28971: loss: 0.066994, loss_s1: 0.029288, loss_fp: 0.003732, loss_freq: 0.068573
[07:39:21.059] iteration 28972: loss: 0.049598, loss_s1: 0.043549, loss_fp: 0.002902, loss_freq: 0.019346
[07:39:21.669] iteration 28973: loss: 0.045494, loss_s1: 0.036727, loss_fp: 0.004432, loss_freq: 0.023762
[07:39:22.285] iteration 28974: loss: 0.053299, loss_s1: 0.043600, loss_fp: 0.014563, loss_freq: 0.017274
[07:39:22.890] iteration 28975: loss: 0.046345, loss_s1: 0.033281, loss_fp: 0.004050, loss_freq: 0.032019
[07:39:23.504] iteration 28976: loss: 0.056177, loss_s1: 0.053344, loss_fp: 0.005108, loss_freq: 0.017081
[07:39:24.437] iteration 28977: loss: 0.061532, loss_s1: 0.054189, loss_fp: 0.002050, loss_freq: 0.035665
[07:39:25.391] iteration 28978: loss: 0.089518, loss_s1: 0.092945, loss_fp: 0.009971, loss_freq: 0.054848
[07:39:26.201] iteration 28979: loss: 0.047196, loss_s1: 0.020147, loss_fp: 0.003687, loss_freq: 0.044723
[07:39:26.811] iteration 28980: loss: 0.056195, loss_s1: 0.050909, loss_fp: 0.004132, loss_freq: 0.022950
[07:39:27.416] iteration 28981: loss: 0.042281, loss_s1: 0.040683, loss_fp: 0.002854, loss_freq: 0.015186
[07:39:28.016] iteration 28982: loss: 0.050188, loss_s1: 0.014378, loss_fp: 0.002435, loss_freq: 0.052357
[07:39:28.617] iteration 28983: loss: 0.067277, loss_s1: 0.067403, loss_fp: 0.006398, loss_freq: 0.032203
[07:39:29.217] iteration 28984: loss: 0.035824, loss_s1: 0.026545, loss_fp: 0.004767, loss_freq: 0.016981
[07:39:29.829] iteration 28985: loss: 0.051997, loss_s1: 0.049387, loss_fp: 0.004569, loss_freq: 0.017885
[07:39:30.439] iteration 28986: loss: 0.055655, loss_s1: 0.050828, loss_fp: 0.004673, loss_freq: 0.026859
[07:39:31.043] iteration 28987: loss: 0.053807, loss_s1: 0.053164, loss_fp: 0.005277, loss_freq: 0.027928
[07:39:31.656] iteration 28988: loss: 0.053899, loss_s1: 0.044691, loss_fp: 0.005369, loss_freq: 0.029842
[07:39:32.267] iteration 28989: loss: 0.045245, loss_s1: 0.022983, loss_fp: 0.002256, loss_freq: 0.035554
[07:39:32.868] iteration 28990: loss: 0.042754, loss_s1: 0.021137, loss_fp: 0.006487, loss_freq: 0.008967
[07:39:33.469] iteration 28991: loss: 0.048699, loss_s1: 0.042956, loss_fp: 0.003920, loss_freq: 0.019519
[07:39:34.067] iteration 28992: loss: 0.066277, loss_s1: 0.051383, loss_fp: 0.006192, loss_freq: 0.056309
[07:39:34.672] iteration 28993: loss: 0.066529, loss_s1: 0.045967, loss_fp: 0.006312, loss_freq: 0.041927
[07:39:35.267] iteration 28994: loss: 0.048985, loss_s1: 0.043582, loss_fp: 0.005900, loss_freq: 0.026193
[07:39:35.865] iteration 28995: loss: 0.062312, loss_s1: 0.074301, loss_fp: 0.007467, loss_freq: 0.015016
[07:39:36.455] iteration 28996: loss: 0.036837, loss_s1: 0.021216, loss_fp: 0.003646, loss_freq: 0.025856
[07:39:37.044] iteration 28997: loss: 0.083126, loss_s1: 0.084688, loss_fp: 0.006713, loss_freq: 0.037992
[07:39:37.634] iteration 28998: loss: 0.079235, loss_s1: 0.074617, loss_fp: 0.002745, loss_freq: 0.042379
[07:39:38.221] iteration 28999: loss: 0.071504, loss_s1: 0.061550, loss_fp: 0.006869, loss_freq: 0.049197
[07:39:38.811] iteration 29000: loss: 0.048330, loss_s1: 0.047458, loss_fp: 0.005527, loss_freq: 0.012203
[07:39:42.103] iteration 29000 : mean_dice : 0.745502
[07:39:42.794] iteration 29001: loss: 0.067969, loss_s1: 0.075722, loss_fp: 0.004595, loss_freq: 0.033591
[07:39:43.590] iteration 29002: loss: 0.041384, loss_s1: 0.037027, loss_fp: 0.001902, loss_freq: 0.011193
[07:39:44.279] iteration 29003: loss: 0.051344, loss_s1: 0.041624, loss_fp: 0.006886, loss_freq: 0.028219
[07:39:45.015] iteration 29004: loss: 0.037937, loss_s1: 0.021436, loss_fp: 0.005489, loss_freq: 0.021956
[07:39:45.766] iteration 29005: loss: 0.046613, loss_s1: 0.052432, loss_fp: 0.003267, loss_freq: 0.019442
[07:39:46.423] iteration 29006: loss: 0.050067, loss_s1: 0.048346, loss_fp: 0.008553, loss_freq: 0.013078
[07:39:47.165] iteration 29007: loss: 0.047805, loss_s1: 0.039153, loss_fp: 0.003444, loss_freq: 0.023438
[07:39:47.820] iteration 29008: loss: 0.033579, loss_s1: 0.032502, loss_fp: 0.001630, loss_freq: 0.010089
[07:39:48.538] iteration 29009: loss: 0.051697, loss_s1: 0.034943, loss_fp: 0.003368, loss_freq: 0.038888
[07:39:49.166] iteration 29010: loss: 0.050084, loss_s1: 0.045744, loss_fp: 0.006544, loss_freq: 0.024234
[07:39:49.946] iteration 29011: loss: 0.050357, loss_s1: 0.037662, loss_fp: 0.005104, loss_freq: 0.020705
[07:39:50.616] iteration 29012: loss: 0.046801, loss_s1: 0.030639, loss_fp: 0.004378, loss_freq: 0.029250
[07:39:51.312] iteration 29013: loss: 0.045048, loss_s1: 0.043362, loss_fp: 0.007469, loss_freq: 0.014183
[07:39:51.992] iteration 29014: loss: 0.048647, loss_s1: 0.049846, loss_fp: 0.006590, loss_freq: 0.016898
[07:39:52.667] iteration 29015: loss: 0.104793, loss_s1: 0.061976, loss_fp: 0.008049, loss_freq: 0.103857
[07:39:53.438] iteration 29016: loss: 0.058041, loss_s1: 0.045540, loss_fp: 0.006010, loss_freq: 0.033362
[07:39:54.077] iteration 29017: loss: 0.063872, loss_s1: 0.077335, loss_fp: 0.002287, loss_freq: 0.017913
[07:39:54.772] iteration 29018: loss: 0.066675, loss_s1: 0.067460, loss_fp: 0.004374, loss_freq: 0.034382
[07:39:55.380] iteration 29019: loss: 0.054650, loss_s1: 0.060703, loss_fp: 0.003485, loss_freq: 0.012669
[07:39:55.994] iteration 29020: loss: 0.042497, loss_s1: 0.035722, loss_fp: 0.009445, loss_freq: 0.010176
[07:39:56.596] iteration 29021: loss: 0.030075, loss_s1: 0.009967, loss_fp: 0.004836, loss_freq: 0.005427
[07:39:57.204] iteration 29022: loss: 0.092555, loss_s1: 0.092738, loss_fp: 0.002318, loss_freq: 0.070292
[07:39:57.799] iteration 29023: loss: 0.098084, loss_s1: 0.080679, loss_fp: 0.004600, loss_freq: 0.083822
[07:39:58.399] iteration 29024: loss: 0.056041, loss_s1: 0.030854, loss_fp: 0.004655, loss_freq: 0.050343
[07:39:59.004] iteration 29025: loss: 0.055185, loss_s1: 0.039327, loss_fp: 0.002303, loss_freq: 0.041214
[07:39:59.611] iteration 29026: loss: 0.057524, loss_s1: 0.046454, loss_fp: 0.004112, loss_freq: 0.022246
[07:40:00.215] iteration 29027: loss: 0.033058, loss_s1: 0.018899, loss_fp: 0.001473, loss_freq: 0.020743
[07:40:00.816] iteration 29028: loss: 0.068299, loss_s1: 0.056325, loss_fp: 0.006638, loss_freq: 0.040582
[07:40:01.438] iteration 29029: loss: 0.050349, loss_s1: 0.045306, loss_fp: 0.002262, loss_freq: 0.026769
[07:40:02.046] iteration 29030: loss: 0.072720, loss_s1: 0.068999, loss_fp: 0.015080, loss_freq: 0.033845
[07:40:02.642] iteration 29031: loss: 0.037800, loss_s1: 0.034676, loss_fp: 0.005490, loss_freq: 0.014256
[07:40:03.250] iteration 29032: loss: 0.081864, loss_s1: 0.086246, loss_fp: 0.004337, loss_freq: 0.037779
[07:40:03.847] iteration 29033: loss: 0.072632, loss_s1: 0.060244, loss_fp: 0.012984, loss_freq: 0.040059
[07:40:04.445] iteration 29034: loss: 0.052497, loss_s1: 0.045374, loss_fp: 0.005510, loss_freq: 0.027323
[07:40:05.043] iteration 29035: loss: 0.056279, loss_s1: 0.042147, loss_fp: 0.003918, loss_freq: 0.034374
[07:40:05.637] iteration 29036: loss: 0.032843, loss_s1: 0.032281, loss_fp: 0.003474, loss_freq: 0.008495
[07:40:06.231] iteration 29037: loss: 0.043739, loss_s1: 0.037081, loss_fp: 0.000880, loss_freq: 0.008517
[07:40:06.839] iteration 29038: loss: 0.081109, loss_s1: 0.091509, loss_fp: 0.002115, loss_freq: 0.041798
[07:40:07.436] iteration 29039: loss: 0.102510, loss_s1: 0.133906, loss_fp: 0.004617, loss_freq: 0.039136
[07:40:08.036] iteration 29040: loss: 0.042759, loss_s1: 0.032047, loss_fp: 0.003540, loss_freq: 0.028015
[07:40:08.651] iteration 29041: loss: 0.061907, loss_s1: 0.051592, loss_fp: 0.011006, loss_freq: 0.023519
[07:40:09.254] iteration 29042: loss: 0.058026, loss_s1: 0.022314, loss_fp: 0.007945, loss_freq: 0.050255
[07:40:09.862] iteration 29043: loss: 0.047468, loss_s1: 0.054638, loss_fp: 0.002145, loss_freq: 0.014167
[07:40:10.479] iteration 29044: loss: 0.041318, loss_s1: 0.029944, loss_fp: 0.003032, loss_freq: 0.020880
[07:40:11.087] iteration 29045: loss: 0.031273, loss_s1: 0.025991, loss_fp: 0.003614, loss_freq: 0.011585
[07:40:11.808] iteration 29046: loss: 0.049312, loss_s1: 0.048313, loss_fp: 0.003283, loss_freq: 0.017244
[07:40:12.502] iteration 29047: loss: 0.055274, loss_s1: 0.048234, loss_fp: 0.003957, loss_freq: 0.023544
[07:40:13.217] iteration 29048: loss: 0.102824, loss_s1: 0.137515, loss_fp: 0.007359, loss_freq: 0.035517
[07:40:13.901] iteration 29049: loss: 0.049944, loss_s1: 0.042687, loss_fp: 0.002419, loss_freq: 0.030899
[07:40:14.502] iteration 29050: loss: 0.045955, loss_s1: 0.018162, loss_fp: 0.005070, loss_freq: 0.020501
[07:40:15.094] iteration 29051: loss: 0.091083, loss_s1: 0.062976, loss_fp: 0.017755, loss_freq: 0.062003
[07:40:15.701] iteration 29052: loss: 0.067524, loss_s1: 0.098535, loss_fp: 0.001850, loss_freq: 0.007365
[07:40:16.304] iteration 29053: loss: 0.062719, loss_s1: 0.072799, loss_fp: 0.003783, loss_freq: 0.021952
[07:40:16.919] iteration 29054: loss: 0.060162, loss_s1: 0.054174, loss_fp: 0.004628, loss_freq: 0.026275
[07:40:17.520] iteration 29055: loss: 0.053537, loss_s1: 0.035453, loss_fp: 0.003995, loss_freq: 0.035732
[07:40:18.121] iteration 29056: loss: 0.033702, loss_s1: 0.028023, loss_fp: 0.001437, loss_freq: 0.008514
[07:40:18.734] iteration 29057: loss: 0.039060, loss_s1: 0.041605, loss_fp: 0.003666, loss_freq: 0.013250
[07:40:19.353] iteration 29058: loss: 0.062494, loss_s1: 0.053940, loss_fp: 0.002637, loss_freq: 0.041665
[07:40:19.972] iteration 29059: loss: 0.053063, loss_s1: 0.029339, loss_fp: 0.002129, loss_freq: 0.042919
[07:40:20.583] iteration 29060: loss: 0.069972, loss_s1: 0.077850, loss_fp: 0.008089, loss_freq: 0.023901
[07:40:21.199] iteration 29061: loss: 0.036095, loss_s1: 0.030220, loss_fp: 0.002274, loss_freq: 0.010444
[07:40:21.814] iteration 29062: loss: 0.042058, loss_s1: 0.028435, loss_fp: 0.004494, loss_freq: 0.031387
[07:40:22.429] iteration 29063: loss: 0.043914, loss_s1: 0.035144, loss_fp: 0.003675, loss_freq: 0.009339
[07:40:23.042] iteration 29064: loss: 0.062933, loss_s1: 0.065151, loss_fp: 0.003028, loss_freq: 0.034810
[07:40:23.654] iteration 29065: loss: 0.037503, loss_s1: 0.022935, loss_fp: 0.001805, loss_freq: 0.012450
[07:40:24.256] iteration 29066: loss: 0.057586, loss_s1: 0.056976, loss_fp: 0.005364, loss_freq: 0.031276
[07:40:24.863] iteration 29067: loss: 0.041249, loss_s1: 0.027920, loss_fp: 0.003746, loss_freq: 0.019842
[07:40:25.470] iteration 29068: loss: 0.106149, loss_s1: 0.117245, loss_fp: 0.005041, loss_freq: 0.056542
[07:40:26.076] iteration 29069: loss: 0.055477, loss_s1: 0.050953, loss_fp: 0.005774, loss_freq: 0.029780
[07:40:26.677] iteration 29070: loss: 0.058448, loss_s1: 0.031606, loss_fp: 0.017523, loss_freq: 0.032019
[07:40:27.638] iteration 29071: loss: 0.084906, loss_s1: 0.079927, loss_fp: 0.006663, loss_freq: 0.048285
[07:40:28.280] iteration 29072: loss: 0.070783, loss_s1: 0.079310, loss_fp: 0.003742, loss_freq: 0.027718
[07:40:28.931] iteration 29073: loss: 0.052223, loss_s1: 0.044403, loss_fp: 0.007492, loss_freq: 0.026289
[07:40:29.578] iteration 29074: loss: 0.053643, loss_s1: 0.038100, loss_fp: 0.002258, loss_freq: 0.015190
[07:40:30.224] iteration 29075: loss: 0.048615, loss_s1: 0.042818, loss_fp: 0.002784, loss_freq: 0.025549
[07:40:30.864] iteration 29076: loss: 0.047763, loss_s1: 0.032161, loss_fp: 0.002359, loss_freq: 0.030853
[07:40:31.489] iteration 29077: loss: 0.079114, loss_s1: 0.069715, loss_fp: 0.006043, loss_freq: 0.057157
[07:40:32.092] iteration 29078: loss: 0.036841, loss_s1: 0.026991, loss_fp: 0.005195, loss_freq: 0.014223
[07:40:32.715] iteration 29079: loss: 0.045033, loss_s1: 0.039782, loss_fp: 0.001887, loss_freq: 0.017909
[07:40:33.325] iteration 29080: loss: 0.087154, loss_s1: 0.082502, loss_fp: 0.008048, loss_freq: 0.049171
[07:40:34.005] iteration 29081: loss: 0.043637, loss_s1: 0.034750, loss_fp: 0.005194, loss_freq: 0.020121
[07:40:34.647] iteration 29082: loss: 0.077444, loss_s1: 0.073218, loss_fp: 0.002199, loss_freq: 0.047928
[07:40:35.291] iteration 29083: loss: 0.039456, loss_s1: 0.022315, loss_fp: 0.003104, loss_freq: 0.024254
[07:40:35.918] iteration 29084: loss: 0.044460, loss_s1: 0.028549, loss_fp: 0.012216, loss_freq: 0.022911
[07:40:36.528] iteration 29085: loss: 0.077755, loss_s1: 0.076676, loss_fp: 0.002133, loss_freq: 0.041366
[07:40:37.128] iteration 29086: loss: 0.060830, loss_s1: 0.074660, loss_fp: 0.002918, loss_freq: 0.015623
[07:40:37.731] iteration 29087: loss: 0.110554, loss_s1: 0.103504, loss_fp: 0.005011, loss_freq: 0.090883
[07:40:38.335] iteration 29088: loss: 0.052719, loss_s1: 0.052192, loss_fp: 0.001854, loss_freq: 0.013548
[07:40:38.930] iteration 29089: loss: 0.069837, loss_s1: 0.060373, loss_fp: 0.012248, loss_freq: 0.036425
[07:40:39.536] iteration 29090: loss: 0.059576, loss_s1: 0.060964, loss_fp: 0.001971, loss_freq: 0.026950
[07:40:40.154] iteration 29091: loss: 0.038170, loss_s1: 0.025276, loss_fp: 0.001999, loss_freq: 0.019061
[07:40:40.754] iteration 29092: loss: 0.039052, loss_s1: 0.039623, loss_fp: 0.006748, loss_freq: 0.014819
[07:40:41.360] iteration 29093: loss: 0.055648, loss_s1: 0.035323, loss_fp: 0.002346, loss_freq: 0.034978
[07:40:41.963] iteration 29094: loss: 0.045693, loss_s1: 0.037518, loss_fp: 0.005452, loss_freq: 0.018075
[07:40:42.574] iteration 29095: loss: 0.076333, loss_s1: 0.086066, loss_fp: 0.003612, loss_freq: 0.031037
[07:40:43.175] iteration 29096: loss: 0.062630, loss_s1: 0.054488, loss_fp: 0.004485, loss_freq: 0.040600
[07:40:43.776] iteration 29097: loss: 0.044928, loss_s1: 0.026271, loss_fp: 0.005958, loss_freq: 0.022916
[07:40:44.391] iteration 29098: loss: 0.090783, loss_s1: 0.115618, loss_fp: 0.002426, loss_freq: 0.025788
[07:40:45.021] iteration 29099: loss: 0.044754, loss_s1: 0.024449, loss_fp: 0.004194, loss_freq: 0.036760
[07:40:45.634] iteration 29100: loss: 0.078658, loss_s1: 0.071657, loss_fp: 0.005876, loss_freq: 0.048468
[07:40:46.240] iteration 29101: loss: 0.069009, loss_s1: 0.063315, loss_fp: 0.007810, loss_freq: 0.049389
[07:40:46.840] iteration 29102: loss: 0.064824, loss_s1: 0.036763, loss_fp: 0.003133, loss_freq: 0.056149
[07:40:47.445] iteration 29103: loss: 0.048970, loss_s1: 0.048849, loss_fp: 0.003107, loss_freq: 0.015980
[07:40:48.043] iteration 29104: loss: 0.046117, loss_s1: 0.033596, loss_fp: 0.005607, loss_freq: 0.020343
[07:40:48.684] iteration 29105: loss: 0.070546, loss_s1: 0.062054, loss_fp: 0.004407, loss_freq: 0.050325
[07:40:49.292] iteration 29106: loss: 0.050507, loss_s1: 0.051908, loss_fp: 0.006098, loss_freq: 0.008937
[07:40:49.891] iteration 29107: loss: 0.050247, loss_s1: 0.053384, loss_fp: 0.001471, loss_freq: 0.015730
[07:40:50.496] iteration 29108: loss: 0.037138, loss_s1: 0.034252, loss_fp: 0.001467, loss_freq: 0.012672
[07:40:51.097] iteration 29109: loss: 0.058953, loss_s1: 0.052894, loss_fp: 0.003214, loss_freq: 0.028910
[07:40:51.708] iteration 29110: loss: 0.066909, loss_s1: 0.060212, loss_fp: 0.019164, loss_freq: 0.028034
[07:40:52.326] iteration 29111: loss: 0.078678, loss_s1: 0.093118, loss_fp: 0.010142, loss_freq: 0.019497
[07:40:52.931] iteration 29112: loss: 0.053130, loss_s1: 0.018139, loss_fp: 0.004290, loss_freq: 0.044256
[07:40:53.531] iteration 29113: loss: 0.096894, loss_s1: 0.111428, loss_fp: 0.002648, loss_freq: 0.051762
[07:40:54.160] iteration 29114: loss: 0.101347, loss_s1: 0.098515, loss_fp: 0.004392, loss_freq: 0.080881
[07:40:54.799] iteration 29115: loss: 0.057333, loss_s1: 0.031752, loss_fp: 0.008222, loss_freq: 0.042573
[07:40:55.413] iteration 29116: loss: 0.054578, loss_s1: 0.052706, loss_fp: 0.008412, loss_freq: 0.019945
[07:40:56.025] iteration 29117: loss: 0.061229, loss_s1: 0.039187, loss_fp: 0.002996, loss_freq: 0.043068
[07:40:56.641] iteration 29118: loss: 0.062089, loss_s1: 0.051978, loss_fp: 0.009038, loss_freq: 0.034635
[07:40:57.256] iteration 29119: loss: 0.040662, loss_s1: 0.039992, loss_fp: 0.002134, loss_freq: 0.008874
[07:40:57.872] iteration 29120: loss: 0.054051, loss_s1: 0.048755, loss_fp: 0.002305, loss_freq: 0.018602
[07:40:58.489] iteration 29121: loss: 0.038695, loss_s1: 0.021584, loss_fp: 0.005183, loss_freq: 0.021231
[07:40:59.106] iteration 29122: loss: 0.044748, loss_s1: 0.050199, loss_fp: 0.000763, loss_freq: 0.016970
[07:40:59.720] iteration 29123: loss: 0.042535, loss_s1: 0.018709, loss_fp: 0.001090, loss_freq: 0.016737
[07:41:00.334] iteration 29124: loss: 0.045930, loss_s1: 0.027914, loss_fp: 0.014385, loss_freq: 0.022411
[07:41:00.956] iteration 29125: loss: 0.053988, loss_s1: 0.022744, loss_fp: 0.004663, loss_freq: 0.031155
[07:41:01.563] iteration 29126: loss: 0.045746, loss_s1: 0.026576, loss_fp: 0.002077, loss_freq: 0.015606
[07:41:02.184] iteration 29127: loss: 0.044610, loss_s1: 0.038417, loss_fp: 0.004968, loss_freq: 0.024904
[07:41:02.801] iteration 29128: loss: 0.042563, loss_s1: 0.018249, loss_fp: 0.001251, loss_freq: 0.023621
[07:41:03.446] iteration 29129: loss: 0.067277, loss_s1: 0.043839, loss_fp: 0.005158, loss_freq: 0.055140
[07:41:04.086] iteration 29130: loss: 0.044337, loss_s1: 0.029249, loss_fp: 0.003513, loss_freq: 0.026531
[07:41:04.739] iteration 29131: loss: 0.018925, loss_s1: 0.003805, loss_fp: 0.002773, loss_freq: 0.010098
[07:41:05.395] iteration 29132: loss: 0.043873, loss_s1: 0.020952, loss_fp: 0.004130, loss_freq: 0.023354
[07:41:06.041] iteration 29133: loss: 0.048950, loss_s1: 0.047146, loss_fp: 0.003016, loss_freq: 0.015514
[07:41:06.651] iteration 29134: loss: 0.030665, loss_s1: 0.008980, loss_fp: 0.004386, loss_freq: 0.024947
[07:41:07.274] iteration 29135: loss: 0.087853, loss_s1: 0.129026, loss_fp: 0.001584, loss_freq: 0.007389
[07:41:07.894] iteration 29136: loss: 0.041216, loss_s1: 0.039001, loss_fp: 0.003597, loss_freq: 0.019223
[07:41:08.509] iteration 29137: loss: 0.028256, loss_s1: 0.012596, loss_fp: 0.001370, loss_freq: 0.010108
[07:41:09.120] iteration 29138: loss: 0.092599, loss_s1: 0.112488, loss_fp: 0.010497, loss_freq: 0.035785
[07:41:09.731] iteration 29139: loss: 0.035546, loss_s1: 0.026067, loss_fp: 0.002228, loss_freq: 0.015605
[07:41:10.370] iteration 29140: loss: 0.040181, loss_s1: 0.036267, loss_fp: 0.002233, loss_freq: 0.020746
[07:41:11.019] iteration 29141: loss: 0.073519, loss_s1: 0.065001, loss_fp: 0.009833, loss_freq: 0.039037
[07:41:11.667] iteration 29142: loss: 0.046439, loss_s1: 0.032159, loss_fp: 0.001403, loss_freq: 0.023134
[07:41:12.294] iteration 29143: loss: 0.063024, loss_s1: 0.066523, loss_fp: 0.007697, loss_freq: 0.026108
[07:41:12.905] iteration 29144: loss: 0.047531, loss_s1: 0.042233, loss_fp: 0.002043, loss_freq: 0.021718
[07:41:13.520] iteration 29145: loss: 0.050496, loss_s1: 0.033522, loss_fp: 0.001012, loss_freq: 0.043873
[07:41:14.131] iteration 29146: loss: 0.041695, loss_s1: 0.022823, loss_fp: 0.004160, loss_freq: 0.024186
[07:41:14.751] iteration 29147: loss: 0.043778, loss_s1: 0.022679, loss_fp: 0.003586, loss_freq: 0.027939
[07:41:15.373] iteration 29148: loss: 0.066984, loss_s1: 0.071305, loss_fp: 0.009876, loss_freq: 0.029315
[07:41:15.985] iteration 29149: loss: 0.059222, loss_s1: 0.032856, loss_fp: 0.012444, loss_freq: 0.050189
[07:41:16.600] iteration 29150: loss: 0.059078, loss_s1: 0.064784, loss_fp: 0.003767, loss_freq: 0.019691
[07:41:17.210] iteration 29151: loss: 0.043710, loss_s1: 0.037090, loss_fp: 0.002700, loss_freq: 0.017265
[07:41:17.829] iteration 29152: loss: 0.058119, loss_s1: 0.065033, loss_fp: 0.002859, loss_freq: 0.018284
[07:41:18.433] iteration 29153: loss: 0.044262, loss_s1: 0.033082, loss_fp: 0.007493, loss_freq: 0.018870
[07:41:19.084] iteration 29154: loss: 0.030105, loss_s1: 0.016273, loss_fp: 0.002146, loss_freq: 0.013133
[07:41:19.737] iteration 29155: loss: 0.055210, loss_s1: 0.056941, loss_fp: 0.001921, loss_freq: 0.019090
[07:41:20.391] iteration 29156: loss: 0.050071, loss_s1: 0.035348, loss_fp: 0.001889, loss_freq: 0.032891
[07:41:21.048] iteration 29157: loss: 0.061890, loss_s1: 0.061205, loss_fp: 0.003881, loss_freq: 0.034938
[07:41:21.696] iteration 29158: loss: 0.040438, loss_s1: 0.035333, loss_fp: 0.003808, loss_freq: 0.013852
[07:41:22.352] iteration 29159: loss: 0.034639, loss_s1: 0.021592, loss_fp: 0.003363, loss_freq: 0.018341
[07:41:22.964] iteration 29160: loss: 0.040664, loss_s1: 0.028119, loss_fp: 0.003294, loss_freq: 0.018049
[07:41:23.568] iteration 29161: loss: 0.061071, loss_s1: 0.058264, loss_fp: 0.006218, loss_freq: 0.029554
[07:41:24.168] iteration 29162: loss: 0.045736, loss_s1: 0.025657, loss_fp: 0.003141, loss_freq: 0.039660
[07:41:24.837] iteration 29163: loss: 0.084555, loss_s1: 0.104171, loss_fp: 0.008913, loss_freq: 0.019345
[07:41:25.447] iteration 29164: loss: 0.046332, loss_s1: 0.043942, loss_fp: 0.002111, loss_freq: 0.024055
[07:41:26.058] iteration 29165: loss: 0.064508, loss_s1: 0.050659, loss_fp: 0.008955, loss_freq: 0.041464
[07:41:26.681] iteration 29166: loss: 0.042414, loss_s1: 0.029269, loss_fp: 0.001414, loss_freq: 0.030428
[07:41:27.293] iteration 29167: loss: 0.111462, loss_s1: 0.101984, loss_fp: 0.003178, loss_freq: 0.075682
[07:41:27.906] iteration 29168: loss: 0.078758, loss_s1: 0.041520, loss_fp: 0.006056, loss_freq: 0.081671
[07:41:28.513] iteration 29169: loss: 0.077412, loss_s1: 0.065789, loss_fp: 0.005031, loss_freq: 0.061129
[07:41:29.133] iteration 29170: loss: 0.056601, loss_s1: 0.055520, loss_fp: 0.004519, loss_freq: 0.023890
[07:41:29.791] iteration 29171: loss: 0.049111, loss_s1: 0.043963, loss_fp: 0.005102, loss_freq: 0.028510
[07:41:30.454] iteration 29172: loss: 0.060053, loss_s1: 0.050209, loss_fp: 0.006958, loss_freq: 0.022560
[07:41:31.117] iteration 29173: loss: 0.038101, loss_s1: 0.021892, loss_fp: 0.002576, loss_freq: 0.024803
[07:41:31.750] iteration 29174: loss: 0.045601, loss_s1: 0.042702, loss_fp: 0.004606, loss_freq: 0.014918
[07:41:32.373] iteration 29175: loss: 0.044256, loss_s1: 0.046516, loss_fp: 0.002991, loss_freq: 0.019415
[07:41:32.982] iteration 29176: loss: 0.062147, loss_s1: 0.068517, loss_fp: 0.004984, loss_freq: 0.016417
[07:41:33.652] iteration 29177: loss: 0.057978, loss_s1: 0.063338, loss_fp: 0.002101, loss_freq: 0.017886
[07:41:34.321] iteration 29178: loss: 0.045123, loss_s1: 0.035831, loss_fp: 0.006075, loss_freq: 0.019504
[07:41:34.968] iteration 29179: loss: 0.067281, loss_s1: 0.028540, loss_fp: 0.005349, loss_freq: 0.070602
[07:41:35.584] iteration 29180: loss: 0.053372, loss_s1: 0.051777, loss_fp: 0.008347, loss_freq: 0.018922
[07:41:36.255] iteration 29181: loss: 0.040001, loss_s1: 0.037856, loss_fp: 0.002540, loss_freq: 0.014142
[07:41:36.895] iteration 29182: loss: 0.044760, loss_s1: 0.050021, loss_fp: 0.004272, loss_freq: 0.009386
[07:41:37.507] iteration 29183: loss: 0.047022, loss_s1: 0.045283, loss_fp: 0.004134, loss_freq: 0.021731
[07:41:38.113] iteration 29184: loss: 0.028366, loss_s1: 0.015916, loss_fp: 0.003965, loss_freq: 0.012621
[07:41:38.718] iteration 29185: loss: 0.095988, loss_s1: 0.104383, loss_fp: 0.004771, loss_freq: 0.048616
[07:41:39.339] iteration 29186: loss: 0.057323, loss_s1: 0.056477, loss_fp: 0.004954, loss_freq: 0.025376
[07:41:39.959] iteration 29187: loss: 0.044049, loss_s1: 0.028796, loss_fp: 0.006292, loss_freq: 0.024242
[07:41:40.572] iteration 29188: loss: 0.057787, loss_s1: 0.063625, loss_fp: 0.002698, loss_freq: 0.020698
[07:41:41.211] iteration 29189: loss: 0.050117, loss_s1: 0.032211, loss_fp: 0.006325, loss_freq: 0.019582
[07:41:41.934] iteration 29190: loss: 0.028157, loss_s1: 0.020570, loss_fp: 0.001087, loss_freq: 0.004854
[07:41:42.608] iteration 29191: loss: 0.024277, loss_s1: 0.009996, loss_fp: 0.001552, loss_freq: 0.006788
[07:41:43.270] iteration 29192: loss: 0.066341, loss_s1: 0.074312, loss_fp: 0.007094, loss_freq: 0.031416
[07:41:43.928] iteration 29193: loss: 0.081759, loss_s1: 0.055581, loss_fp: 0.026197, loss_freq: 0.048451
[07:41:44.567] iteration 29194: loss: 0.059924, loss_s1: 0.048499, loss_fp: 0.001348, loss_freq: 0.025133
[07:41:45.201] iteration 29195: loss: 0.109505, loss_s1: 0.065371, loss_fp: 0.068656, loss_freq: 0.055340
[07:41:45.819] iteration 29196: loss: 0.051836, loss_s1: 0.052173, loss_fp: 0.002364, loss_freq: 0.017647
[07:41:46.447] iteration 29197: loss: 0.064617, loss_s1: 0.080298, loss_fp: 0.003205, loss_freq: 0.025116
[07:41:47.070] iteration 29198: loss: 0.046060, loss_s1: 0.032084, loss_fp: 0.007708, loss_freq: 0.017364
[07:41:47.685] iteration 29199: loss: 0.054860, loss_s1: 0.063713, loss_fp: 0.004520, loss_freq: 0.018528
[07:41:48.326] iteration 29200: loss: 0.053867, loss_s1: 0.062160, loss_fp: 0.002580, loss_freq: 0.017241
[07:41:51.966] iteration 29200 : mean_dice : 0.750163
[07:41:52.701] iteration 29201: loss: 0.065210, loss_s1: 0.070583, loss_fp: 0.005456, loss_freq: 0.032709
[07:41:53.370] iteration 29202: loss: 0.051490, loss_s1: 0.028408, loss_fp: 0.005060, loss_freq: 0.032337
[07:41:54.020] iteration 29203: loss: 0.062831, loss_s1: 0.054994, loss_fp: 0.008612, loss_freq: 0.026642
[07:41:54.683] iteration 29204: loss: 0.055865, loss_s1: 0.059028, loss_fp: 0.005688, loss_freq: 0.019459
[07:41:55.348] iteration 29205: loss: 0.106141, loss_s1: 0.061893, loss_fp: 0.005266, loss_freq: 0.111922
[07:41:56.001] iteration 29206: loss: 0.032898, loss_s1: 0.031101, loss_fp: 0.001997, loss_freq: 0.010464
[07:41:56.627] iteration 29207: loss: 0.052719, loss_s1: 0.054601, loss_fp: 0.000856, loss_freq: 0.012787
[07:41:57.254] iteration 29208: loss: 0.046484, loss_s1: 0.026356, loss_fp: 0.001979, loss_freq: 0.037401
[07:41:57.895] iteration 29209: loss: 0.088912, loss_s1: 0.082938, loss_fp: 0.009099, loss_freq: 0.053884
[07:41:58.518] iteration 29210: loss: 0.079065, loss_s1: 0.088982, loss_fp: 0.006819, loss_freq: 0.031436
[07:41:59.138] iteration 29211: loss: 0.072742, loss_s1: 0.065508, loss_fp: 0.004392, loss_freq: 0.045856
[07:41:59.797] iteration 29212: loss: 0.046706, loss_s1: 0.024231, loss_fp: 0.007801, loss_freq: 0.024605
[07:42:00.483] iteration 29213: loss: 0.027910, loss_s1: 0.017999, loss_fp: 0.002028, loss_freq: 0.012724
[07:42:01.137] iteration 29214: loss: 0.048475, loss_s1: 0.043859, loss_fp: 0.005186, loss_freq: 0.014526
[07:42:01.781] iteration 29215: loss: 0.029431, loss_s1: 0.013445, loss_fp: 0.005752, loss_freq: 0.007774
[07:42:02.445] iteration 29216: loss: 0.047158, loss_s1: 0.024838, loss_fp: 0.001851, loss_freq: 0.033106
[07:42:03.068] iteration 29217: loss: 0.045276, loss_s1: 0.027404, loss_fp: 0.002489, loss_freq: 0.019698
[07:42:03.677] iteration 29218: loss: 0.071074, loss_s1: 0.055601, loss_fp: 0.005637, loss_freq: 0.054671
[07:42:04.308] iteration 29219: loss: 0.056133, loss_s1: 0.040902, loss_fp: 0.002864, loss_freq: 0.046086
[07:42:04.916] iteration 29220: loss: 0.045941, loss_s1: 0.034052, loss_fp: 0.004349, loss_freq: 0.024074
[07:42:05.528] iteration 29221: loss: 0.057037, loss_s1: 0.060682, loss_fp: 0.003637, loss_freq: 0.022640
[07:42:06.161] iteration 29222: loss: 0.047322, loss_s1: 0.052627, loss_fp: 0.002618, loss_freq: 0.011924
[07:42:06.765] iteration 29223: loss: 0.056512, loss_s1: 0.043483, loss_fp: 0.008131, loss_freq: 0.030641
[07:42:07.374] iteration 29224: loss: 0.076596, loss_s1: 0.084109, loss_fp: 0.007706, loss_freq: 0.030775
[07:42:07.982] iteration 29225: loss: 0.073906, loss_s1: 0.053719, loss_fp: 0.005965, loss_freq: 0.052406
[07:42:08.584] iteration 29226: loss: 0.036994, loss_s1: 0.022680, loss_fp: 0.000802, loss_freq: 0.019287
[07:42:09.198] iteration 29227: loss: 0.030853, loss_s1: 0.023213, loss_fp: 0.003809, loss_freq: 0.013271
[07:42:09.811] iteration 29228: loss: 0.059213, loss_s1: 0.042306, loss_fp: 0.001859, loss_freq: 0.042694
[07:42:10.415] iteration 29229: loss: 0.077876, loss_s1: 0.043395, loss_fp: 0.011246, loss_freq: 0.070961
[07:42:11.021] iteration 29230: loss: 0.067449, loss_s1: 0.062415, loss_fp: 0.003513, loss_freq: 0.039376
[07:42:11.611] iteration 29231: loss: 0.044363, loss_s1: 0.041433, loss_fp: 0.003839, loss_freq: 0.009105
[07:42:12.210] iteration 29232: loss: 0.061481, loss_s1: 0.049624, loss_fp: 0.010724, loss_freq: 0.042618
[07:42:12.825] iteration 29233: loss: 0.030329, loss_s1: 0.016331, loss_fp: 0.001231, loss_freq: 0.005138
[07:42:13.439] iteration 29234: loss: 0.046222, loss_s1: 0.039467, loss_fp: 0.002927, loss_freq: 0.016504
[07:42:14.040] iteration 29235: loss: 0.028303, loss_s1: 0.013856, loss_fp: 0.003575, loss_freq: 0.011570
[07:42:14.656] iteration 29236: loss: 0.083870, loss_s1: 0.124361, loss_fp: 0.005696, loss_freq: 0.018193
[07:42:15.280] iteration 29237: loss: 0.040988, loss_s1: 0.020096, loss_fp: 0.004834, loss_freq: 0.016654
[07:42:15.893] iteration 29238: loss: 0.052450, loss_s1: 0.037788, loss_fp: 0.004128, loss_freq: 0.032227
[07:42:16.510] iteration 29239: loss: 0.070010, loss_s1: 0.076388, loss_fp: 0.006487, loss_freq: 0.030013
[07:42:17.126] iteration 29240: loss: 0.042834, loss_s1: 0.031997, loss_fp: 0.009187, loss_freq: 0.008512
[07:42:18.060] iteration 29241: loss: 0.059246, loss_s1: 0.027735, loss_fp: 0.005882, loss_freq: 0.030315
[07:42:18.676] iteration 29242: loss: 0.057282, loss_s1: 0.031441, loss_fp: 0.014593, loss_freq: 0.036738
[07:42:19.276] iteration 29243: loss: 0.038549, loss_s1: 0.032843, loss_fp: 0.004832, loss_freq: 0.016502
[07:42:19.896] iteration 29244: loss: 0.028832, loss_s1: 0.012766, loss_fp: 0.001264, loss_freq: 0.015811
[07:42:20.501] iteration 29245: loss: 0.103270, loss_s1: 0.157180, loss_fp: 0.015354, loss_freq: 0.010373
[07:42:21.111] iteration 29246: loss: 0.058739, loss_s1: 0.031917, loss_fp: 0.002063, loss_freq: 0.027840
[07:42:21.728] iteration 29247: loss: 0.035391, loss_s1: 0.031547, loss_fp: 0.002320, loss_freq: 0.007631
[07:42:22.334] iteration 29248: loss: 0.045616, loss_s1: 0.041402, loss_fp: 0.005306, loss_freq: 0.019016
[07:42:22.937] iteration 29249: loss: 0.033029, loss_s1: 0.009664, loss_fp: 0.003006, loss_freq: 0.021253
[07:42:23.538] iteration 29250: loss: 0.055735, loss_s1: 0.050898, loss_fp: 0.001849, loss_freq: 0.023017
[07:42:24.145] iteration 29251: loss: 0.040998, loss_s1: 0.029065, loss_fp: 0.005857, loss_freq: 0.014743
[07:42:24.760] iteration 29252: loss: 0.072782, loss_s1: 0.064370, loss_fp: 0.002959, loss_freq: 0.046252
[07:42:25.363] iteration 29253: loss: 0.044446, loss_s1: 0.037683, loss_fp: 0.003208, loss_freq: 0.024099
[07:42:25.969] iteration 29254: loss: 0.058427, loss_s1: 0.058341, loss_fp: 0.001374, loss_freq: 0.028408
[07:42:26.583] iteration 29255: loss: 0.040973, loss_s1: 0.020567, loss_fp: 0.003969, loss_freq: 0.019156
[07:42:27.184] iteration 29256: loss: 0.034897, loss_s1: 0.022761, loss_fp: 0.001499, loss_freq: 0.013423
[07:42:27.788] iteration 29257: loss: 0.082421, loss_s1: 0.053123, loss_fp: 0.007630, loss_freq: 0.085777
[07:42:28.399] iteration 29258: loss: 0.027834, loss_s1: 0.017207, loss_fp: 0.002004, loss_freq: 0.011206
[07:42:29.001] iteration 29259: loss: 0.053021, loss_s1: 0.034360, loss_fp: 0.010773, loss_freq: 0.035200
[07:42:29.608] iteration 29260: loss: 0.056686, loss_s1: 0.045139, loss_fp: 0.004617, loss_freq: 0.025766
[07:42:30.218] iteration 29261: loss: 0.039661, loss_s1: 0.027253, loss_fp: 0.004850, loss_freq: 0.013311
[07:42:30.821] iteration 29262: loss: 0.060594, loss_s1: 0.053335, loss_fp: 0.004584, loss_freq: 0.040370
[07:42:31.429] iteration 29263: loss: 0.053616, loss_s1: 0.029229, loss_fp: 0.002715, loss_freq: 0.032398
[07:42:32.039] iteration 29264: loss: 0.042991, loss_s1: 0.025381, loss_fp: 0.001771, loss_freq: 0.016015
[07:42:32.652] iteration 29265: loss: 0.057741, loss_s1: 0.052935, loss_fp: 0.005543, loss_freq: 0.030017
[07:42:33.261] iteration 29266: loss: 0.049906, loss_s1: 0.045649, loss_fp: 0.007307, loss_freq: 0.027330
[07:42:33.874] iteration 29267: loss: 0.041909, loss_s1: 0.023362, loss_fp: 0.004019, loss_freq: 0.019039
[07:42:34.477] iteration 29268: loss: 0.051606, loss_s1: 0.029989, loss_fp: 0.002193, loss_freq: 0.039115
[07:42:35.082] iteration 29269: loss: 0.066783, loss_s1: 0.055842, loss_fp: 0.004835, loss_freq: 0.037208
[07:42:35.685] iteration 29270: loss: 0.077047, loss_s1: 0.073813, loss_fp: 0.003407, loss_freq: 0.043465
[07:42:36.287] iteration 29271: loss: 0.057214, loss_s1: 0.034326, loss_fp: 0.011087, loss_freq: 0.050066
[07:42:36.890] iteration 29272: loss: 0.068587, loss_s1: 0.068143, loss_fp: 0.004852, loss_freq: 0.028965
[07:42:37.492] iteration 29273: loss: 0.068260, loss_s1: 0.063738, loss_fp: 0.004150, loss_freq: 0.039624
[07:42:38.099] iteration 29274: loss: 0.046176, loss_s1: 0.026954, loss_fp: 0.017442, loss_freq: 0.017039
[07:42:38.719] iteration 29275: loss: 0.062428, loss_s1: 0.081748, loss_fp: 0.001514, loss_freq: 0.021889
[07:42:39.327] iteration 29276: loss: 0.035029, loss_s1: 0.017554, loss_fp: 0.004212, loss_freq: 0.013969
[07:42:39.936] iteration 29277: loss: 0.060908, loss_s1: 0.043556, loss_fp: 0.005176, loss_freq: 0.039894
[07:42:40.536] iteration 29278: loss: 0.057439, loss_s1: 0.065343, loss_fp: 0.001988, loss_freq: 0.020900
[07:42:41.150] iteration 29279: loss: 0.075640, loss_s1: 0.070112, loss_fp: 0.002285, loss_freq: 0.050771
[07:42:41.760] iteration 29280: loss: 0.069079, loss_s1: 0.082581, loss_fp: 0.010022, loss_freq: 0.022465
[07:42:42.350] iteration 29281: loss: 0.090256, loss_s1: 0.068859, loss_fp: 0.003140, loss_freq: 0.066468
[07:42:42.961] iteration 29282: loss: 0.046613, loss_s1: 0.043813, loss_fp: 0.002899, loss_freq: 0.019881
[07:42:43.563] iteration 29283: loss: 0.069810, loss_s1: 0.083134, loss_fp: 0.007047, loss_freq: 0.023211
[07:42:44.171] iteration 29284: loss: 0.083284, loss_s1: 0.087111, loss_fp: 0.004967, loss_freq: 0.055762
[07:42:44.766] iteration 29285: loss: 0.070265, loss_s1: 0.047146, loss_fp: 0.007849, loss_freq: 0.050750
[07:42:45.445] iteration 29286: loss: 0.069488, loss_s1: 0.089432, loss_fp: 0.004826, loss_freq: 0.019009
[07:42:46.057] iteration 29287: loss: 0.066188, loss_s1: 0.049899, loss_fp: 0.004169, loss_freq: 0.046727
[07:42:46.656] iteration 29288: loss: 0.046242, loss_s1: 0.047176, loss_fp: 0.002930, loss_freq: 0.017636
[07:42:47.258] iteration 29289: loss: 0.041646, loss_s1: 0.037510, loss_fp: 0.001443, loss_freq: 0.013746
[07:42:47.869] iteration 29290: loss: 0.033463, loss_s1: 0.022402, loss_fp: 0.001472, loss_freq: 0.007952
[07:42:48.475] iteration 29291: loss: 0.043189, loss_s1: 0.034363, loss_fp: 0.003420, loss_freq: 0.017319
[07:42:49.092] iteration 29292: loss: 0.050893, loss_s1: 0.041750, loss_fp: 0.004214, loss_freq: 0.038194
[07:42:49.693] iteration 29293: loss: 0.059062, loss_s1: 0.048021, loss_fp: 0.002053, loss_freq: 0.030143
[07:42:50.298] iteration 29294: loss: 0.060277, loss_s1: 0.048733, loss_fp: 0.004727, loss_freq: 0.034126
[07:42:50.910] iteration 29295: loss: 0.052653, loss_s1: 0.021412, loss_fp: 0.006032, loss_freq: 0.041217
[07:42:51.513] iteration 29296: loss: 0.048937, loss_s1: 0.034083, loss_fp: 0.005653, loss_freq: 0.026931
[07:42:52.125] iteration 29297: loss: 0.049898, loss_s1: 0.049743, loss_fp: 0.006228, loss_freq: 0.025016
[07:42:52.724] iteration 29298: loss: 0.032579, loss_s1: 0.007641, loss_fp: 0.003018, loss_freq: 0.015027
[07:42:53.335] iteration 29299: loss: 0.057465, loss_s1: 0.029737, loss_fp: 0.006852, loss_freq: 0.050260
[07:42:53.945] iteration 29300: loss: 0.039548, loss_s1: 0.024187, loss_fp: 0.001095, loss_freq: 0.025840
[07:42:54.543] iteration 29301: loss: 0.028587, loss_s1: 0.020274, loss_fp: 0.003139, loss_freq: 0.009397
[07:42:55.152] iteration 29302: loss: 0.050964, loss_s1: 0.029412, loss_fp: 0.001316, loss_freq: 0.041312
[07:42:55.749] iteration 29303: loss: 0.036725, loss_s1: 0.026595, loss_fp: 0.001794, loss_freq: 0.012102
[07:42:56.352] iteration 29304: loss: 0.046937, loss_s1: 0.037193, loss_fp: 0.004774, loss_freq: 0.022454
[07:42:56.954] iteration 29305: loss: 0.040113, loss_s1: 0.038223, loss_fp: 0.002394, loss_freq: 0.006806
[07:42:57.563] iteration 29306: loss: 0.049920, loss_s1: 0.038048, loss_fp: 0.005602, loss_freq: 0.029295
[07:42:58.170] iteration 29307: loss: 0.033907, loss_s1: 0.010150, loss_fp: 0.001245, loss_freq: 0.010573
[07:42:58.783] iteration 29308: loss: 0.091056, loss_s1: 0.087881, loss_fp: 0.022440, loss_freq: 0.048429
[07:42:59.427] iteration 29309: loss: 0.045483, loss_s1: 0.036498, loss_fp: 0.002452, loss_freq: 0.024962
[07:43:00.118] iteration 29310: loss: 0.036913, loss_s1: 0.034006, loss_fp: 0.002360, loss_freq: 0.017740
[07:43:00.828] iteration 29311: loss: 0.050431, loss_s1: 0.037136, loss_fp: 0.006548, loss_freq: 0.028411
[07:43:01.476] iteration 29312: loss: 0.042007, loss_s1: 0.025754, loss_fp: 0.001871, loss_freq: 0.025494
[07:43:02.128] iteration 29313: loss: 0.065008, loss_s1: 0.032664, loss_fp: 0.010100, loss_freq: 0.059849
[07:43:02.775] iteration 29314: loss: 0.060787, loss_s1: 0.072918, loss_fp: 0.002159, loss_freq: 0.016644
[07:43:03.434] iteration 29315: loss: 0.053156, loss_s1: 0.036969, loss_fp: 0.004758, loss_freq: 0.037204
[07:43:04.076] iteration 29316: loss: 0.064266, loss_s1: 0.056172, loss_fp: 0.013564, loss_freq: 0.029746
[07:43:04.700] iteration 29317: loss: 0.063090, loss_s1: 0.041008, loss_fp: 0.003260, loss_freq: 0.045782
[07:43:05.320] iteration 29318: loss: 0.069607, loss_s1: 0.068344, loss_fp: 0.006833, loss_freq: 0.044001
[07:43:05.959] iteration 29319: loss: 0.045004, loss_s1: 0.038665, loss_fp: 0.002280, loss_freq: 0.031831
[07:43:06.571] iteration 29320: loss: 0.059394, loss_s1: 0.052993, loss_fp: 0.003742, loss_freq: 0.027001
[07:43:07.193] iteration 29321: loss: 0.043382, loss_s1: 0.045955, loss_fp: 0.003628, loss_freq: 0.007533
[07:43:07.808] iteration 29322: loss: 0.050565, loss_s1: 0.037802, loss_fp: 0.007033, loss_freq: 0.017069
[07:43:08.431] iteration 29323: loss: 0.058332, loss_s1: 0.053053, loss_fp: 0.006968, loss_freq: 0.031894
[07:43:09.051] iteration 29324: loss: 0.035497, loss_s1: 0.020862, loss_fp: 0.003288, loss_freq: 0.016977
[07:43:09.681] iteration 29325: loss: 0.055323, loss_s1: 0.059645, loss_fp: 0.002589, loss_freq: 0.018863
[07:43:10.308] iteration 29326: loss: 0.049635, loss_s1: 0.020413, loss_fp: 0.013798, loss_freq: 0.027317
[07:43:10.938] iteration 29327: loss: 0.040412, loss_s1: 0.031963, loss_fp: 0.005279, loss_freq: 0.023097
[07:43:11.566] iteration 29328: loss: 0.054413, loss_s1: 0.051938, loss_fp: 0.003404, loss_freq: 0.029154
[07:43:12.194] iteration 29329: loss: 0.039584, loss_s1: 0.021912, loss_fp: 0.004103, loss_freq: 0.025553
[07:43:12.812] iteration 29330: loss: 0.029711, loss_s1: 0.014717, loss_fp: 0.006849, loss_freq: 0.005431
[07:43:13.427] iteration 29331: loss: 0.077863, loss_s1: 0.087776, loss_fp: 0.005387, loss_freq: 0.029956
[07:43:14.039] iteration 29332: loss: 0.035540, loss_s1: 0.018788, loss_fp: 0.001362, loss_freq: 0.031155
[07:43:14.666] iteration 29333: loss: 0.065400, loss_s1: 0.066359, loss_fp: 0.003606, loss_freq: 0.022467
[07:43:15.288] iteration 29334: loss: 0.053926, loss_s1: 0.050914, loss_fp: 0.002074, loss_freq: 0.021475
[07:43:15.921] iteration 29335: loss: 0.079317, loss_s1: 0.080415, loss_fp: 0.007251, loss_freq: 0.043763
[07:43:16.542] iteration 29336: loss: 0.054683, loss_s1: 0.043801, loss_fp: 0.007561, loss_freq: 0.038768
[07:43:17.168] iteration 29337: loss: 0.097943, loss_s1: 0.099486, loss_fp: 0.001864, loss_freq: 0.063308
[07:43:17.791] iteration 29338: loss: 0.060419, loss_s1: 0.042787, loss_fp: 0.006990, loss_freq: 0.038531
[07:43:18.420] iteration 29339: loss: 0.064699, loss_s1: 0.053851, loss_fp: 0.003936, loss_freq: 0.047224
[07:43:19.039] iteration 29340: loss: 0.045287, loss_s1: 0.030145, loss_fp: 0.005019, loss_freq: 0.021282
[07:43:19.664] iteration 29341: loss: 0.042796, loss_s1: 0.030802, loss_fp: 0.005182, loss_freq: 0.031089
[07:43:20.301] iteration 29342: loss: 0.043147, loss_s1: 0.018981, loss_fp: 0.004955, loss_freq: 0.020937
[07:43:20.924] iteration 29343: loss: 0.028634, loss_s1: 0.012969, loss_fp: 0.004449, loss_freq: 0.013511
[07:43:21.540] iteration 29344: loss: 0.045003, loss_s1: 0.035796, loss_fp: 0.004097, loss_freq: 0.017622
[07:43:22.152] iteration 29345: loss: 0.043624, loss_s1: 0.034431, loss_fp: 0.000877, loss_freq: 0.025808
[07:43:22.776] iteration 29346: loss: 0.073657, loss_s1: 0.082959, loss_fp: 0.007748, loss_freq: 0.026422
[07:43:23.410] iteration 29347: loss: 0.062308, loss_s1: 0.076884, loss_fp: 0.006418, loss_freq: 0.011914
[07:43:24.028] iteration 29348: loss: 0.063924, loss_s1: 0.049215, loss_fp: 0.002546, loss_freq: 0.049632
[07:43:24.640] iteration 29349: loss: 0.103854, loss_s1: 0.100928, loss_fp: 0.003807, loss_freq: 0.063416
[07:43:25.260] iteration 29350: loss: 0.042444, loss_s1: 0.036806, loss_fp: 0.002000, loss_freq: 0.022833
[07:43:25.882] iteration 29351: loss: 0.033211, loss_s1: 0.017054, loss_fp: 0.003306, loss_freq: 0.016968
[07:43:26.495] iteration 29352: loss: 0.058058, loss_s1: 0.051180, loss_fp: 0.001596, loss_freq: 0.024393
[07:43:27.113] iteration 29353: loss: 0.037622, loss_s1: 0.040020, loss_fp: 0.002205, loss_freq: 0.011023
[07:43:27.742] iteration 29354: loss: 0.056306, loss_s1: 0.053556, loss_fp: 0.005113, loss_freq: 0.029812
[07:43:28.356] iteration 29355: loss: 0.104502, loss_s1: 0.067604, loss_fp: 0.009217, loss_freq: 0.097858
[07:43:28.975] iteration 29356: loss: 0.065434, loss_s1: 0.051110, loss_fp: 0.005385, loss_freq: 0.043420
[07:43:29.604] iteration 29357: loss: 0.054933, loss_s1: 0.040600, loss_fp: 0.011205, loss_freq: 0.026087
[07:43:30.227] iteration 29358: loss: 0.054259, loss_s1: 0.038341, loss_fp: 0.003030, loss_freq: 0.037483
[07:43:30.844] iteration 29359: loss: 0.059532, loss_s1: 0.057947, loss_fp: 0.002416, loss_freq: 0.028344
[07:43:31.468] iteration 29360: loss: 0.049770, loss_s1: 0.028696, loss_fp: 0.001583, loss_freq: 0.037881
[07:43:32.085] iteration 29361: loss: 0.031213, loss_s1: 0.022491, loss_fp: 0.004899, loss_freq: 0.008736
[07:43:32.698] iteration 29362: loss: 0.070239, loss_s1: 0.067773, loss_fp: 0.005857, loss_freq: 0.047765
[07:43:33.293] iteration 29363: loss: 0.080883, loss_s1: 0.068071, loss_fp: 0.004146, loss_freq: 0.062324
[07:43:33.894] iteration 29364: loss: 0.033748, loss_s1: 0.021680, loss_fp: 0.000760, loss_freq: 0.010398
[07:43:34.787] iteration 29365: loss: 0.073453, loss_s1: 0.059242, loss_fp: 0.008919, loss_freq: 0.037933
[07:43:35.640] iteration 29366: loss: 0.051269, loss_s1: 0.056123, loss_fp: 0.005844, loss_freq: 0.009733
[07:43:36.433] iteration 29367: loss: 0.077965, loss_s1: 0.057052, loss_fp: 0.027096, loss_freq: 0.050751
[07:43:37.081] iteration 29368: loss: 0.048381, loss_s1: 0.023010, loss_fp: 0.002417, loss_freq: 0.032770
[07:43:37.691] iteration 29369: loss: 0.045020, loss_s1: 0.030594, loss_fp: 0.005804, loss_freq: 0.024989
[07:43:38.283] iteration 29370: loss: 0.069655, loss_s1: 0.053889, loss_fp: 0.011411, loss_freq: 0.044990
[07:43:38.882] iteration 29371: loss: 0.058963, loss_s1: 0.061281, loss_fp: 0.003345, loss_freq: 0.031011
[07:43:39.478] iteration 29372: loss: 0.051793, loss_s1: 0.045901, loss_fp: 0.008468, loss_freq: 0.020729
[07:43:40.078] iteration 29373: loss: 0.070774, loss_s1: 0.066824, loss_fp: 0.007547, loss_freq: 0.036389
[07:43:40.690] iteration 29374: loss: 0.056192, loss_s1: 0.051513, loss_fp: 0.019599, loss_freq: 0.016160
[07:43:41.304] iteration 29375: loss: 0.147954, loss_s1: 0.156817, loss_fp: 0.013250, loss_freq: 0.094998
[07:43:41.996] iteration 29376: loss: 0.031526, loss_s1: 0.023595, loss_fp: 0.006024, loss_freq: 0.011449
[07:43:42.646] iteration 29377: loss: 0.044993, loss_s1: 0.042860, loss_fp: 0.002481, loss_freq: 0.015564
[07:43:43.296] iteration 29378: loss: 0.041266, loss_s1: 0.024438, loss_fp: 0.004616, loss_freq: 0.029327
[07:43:43.935] iteration 29379: loss: 0.077352, loss_s1: 0.063497, loss_fp: 0.003791, loss_freq: 0.060571
[07:43:44.534] iteration 29380: loss: 0.055337, loss_s1: 0.077899, loss_fp: 0.002466, loss_freq: 0.009701
[07:43:45.129] iteration 29381: loss: 0.040940, loss_s1: 0.023136, loss_fp: 0.002116, loss_freq: 0.025440
[07:43:45.720] iteration 29382: loss: 0.041699, loss_s1: 0.028909, loss_fp: 0.005270, loss_freq: 0.017165
[07:43:46.317] iteration 29383: loss: 0.054483, loss_s1: 0.054022, loss_fp: 0.004843, loss_freq: 0.022625
[07:43:46.917] iteration 29384: loss: 0.034288, loss_s1: 0.023302, loss_fp: 0.003687, loss_freq: 0.011077
[07:43:47.511] iteration 29385: loss: 0.033572, loss_s1: 0.024950, loss_fp: 0.003319, loss_freq: 0.016806
[07:43:48.112] iteration 29386: loss: 0.054834, loss_s1: 0.048028, loss_fp: 0.006058, loss_freq: 0.029842
[07:43:48.713] iteration 29387: loss: 0.039074, loss_s1: 0.032762, loss_fp: 0.001711, loss_freq: 0.016958
[07:43:49.390] iteration 29388: loss: 0.093504, loss_s1: 0.114125, loss_fp: 0.003338, loss_freq: 0.044800
[07:43:50.039] iteration 29389: loss: 0.041731, loss_s1: 0.029646, loss_fp: 0.005706, loss_freq: 0.019448
[07:43:50.643] iteration 29390: loss: 0.066802, loss_s1: 0.054436, loss_fp: 0.006069, loss_freq: 0.035298
[07:43:51.238] iteration 29391: loss: 0.045056, loss_s1: 0.025793, loss_fp: 0.014964, loss_freq: 0.015723
[07:43:51.838] iteration 29392: loss: 0.041585, loss_s1: 0.035338, loss_fp: 0.006783, loss_freq: 0.007604
[07:43:52.435] iteration 29393: loss: 0.087993, loss_s1: 0.087396, loss_fp: 0.008248, loss_freq: 0.052371
[07:43:53.029] iteration 29394: loss: 0.055990, loss_s1: 0.041584, loss_fp: 0.004894, loss_freq: 0.037072
[07:43:53.637] iteration 29395: loss: 0.072355, loss_s1: 0.051739, loss_fp: 0.003197, loss_freq: 0.036294
[07:43:54.231] iteration 29396: loss: 0.025432, loss_s1: 0.010043, loss_fp: 0.000869, loss_freq: 0.010126
[07:43:54.842] iteration 29397: loss: 0.032195, loss_s1: 0.031257, loss_fp: 0.002427, loss_freq: 0.013149
[07:43:55.440] iteration 29398: loss: 0.067741, loss_s1: 0.057677, loss_fp: 0.006596, loss_freq: 0.040822
[07:43:56.039] iteration 29399: loss: 0.048613, loss_s1: 0.044283, loss_fp: 0.003289, loss_freq: 0.020044
[07:43:56.629] iteration 29400: loss: 0.100778, loss_s1: 0.101121, loss_fp: 0.003993, loss_freq: 0.061899
[07:44:00.045] iteration 29400 : mean_dice : 0.745450
[07:44:00.718] iteration 29401: loss: 0.043508, loss_s1: 0.033656, loss_fp: 0.003950, loss_freq: 0.011114
[07:44:01.363] iteration 29402: loss: 0.047364, loss_s1: 0.056524, loss_fp: 0.006484, loss_freq: 0.011804
[07:44:02.002] iteration 29403: loss: 0.026361, loss_s1: 0.011288, loss_fp: 0.000823, loss_freq: 0.009089
[07:44:02.641] iteration 29404: loss: 0.045469, loss_s1: 0.043667, loss_fp: 0.005135, loss_freq: 0.018101
[07:44:03.247] iteration 29405: loss: 0.026557, loss_s1: 0.012459, loss_fp: 0.003425, loss_freq: 0.010419
[07:44:03.851] iteration 29406: loss: 0.033950, loss_s1: 0.014934, loss_fp: 0.000887, loss_freq: 0.031361
[07:44:04.457] iteration 29407: loss: 0.048282, loss_s1: 0.044858, loss_fp: 0.006421, loss_freq: 0.017166
[07:44:05.058] iteration 29408: loss: 0.062275, loss_s1: 0.052590, loss_fp: 0.005990, loss_freq: 0.036262
[07:44:05.659] iteration 29409: loss: 0.066186, loss_s1: 0.063868, loss_fp: 0.002805, loss_freq: 0.034045
[07:44:06.269] iteration 29410: loss: 0.051907, loss_s1: 0.031264, loss_fp: 0.006907, loss_freq: 0.030355
[07:44:07.260] iteration 29411: loss: 0.077172, loss_s1: 0.063936, loss_fp: 0.003609, loss_freq: 0.050527
[07:44:07.929] iteration 29412: loss: 0.052980, loss_s1: 0.016656, loss_fp: 0.006935, loss_freq: 0.054636
[07:44:08.583] iteration 29413: loss: 0.054659, loss_s1: 0.055768, loss_fp: 0.004941, loss_freq: 0.022556
[07:44:09.228] iteration 29414: loss: 0.051096, loss_s1: 0.050557, loss_fp: 0.001378, loss_freq: 0.014079
[07:44:09.829] iteration 29415: loss: 0.051031, loss_s1: 0.056180, loss_fp: 0.004043, loss_freq: 0.013271
[07:44:10.431] iteration 29416: loss: 0.063776, loss_s1: 0.066855, loss_fp: 0.001261, loss_freq: 0.023081
[07:44:11.026] iteration 29417: loss: 0.039670, loss_s1: 0.025556, loss_fp: 0.002220, loss_freq: 0.022982
[07:44:11.626] iteration 29418: loss: 0.033097, loss_s1: 0.022704, loss_fp: 0.009053, loss_freq: 0.010513
[07:44:12.281] iteration 29419: loss: 0.049856, loss_s1: 0.059098, loss_fp: 0.003883, loss_freq: 0.018311
[07:44:12.964] iteration 29420: loss: 0.074496, loss_s1: 0.085565, loss_fp: 0.008324, loss_freq: 0.023867
[07:44:13.609] iteration 29421: loss: 0.078881, loss_s1: 0.085877, loss_fp: 0.004906, loss_freq: 0.034200
[07:44:14.263] iteration 29422: loss: 0.047497, loss_s1: 0.048284, loss_fp: 0.001943, loss_freq: 0.016123
[07:44:14.909] iteration 29423: loss: 0.064816, loss_s1: 0.055307, loss_fp: 0.006413, loss_freq: 0.043284
[07:44:15.504] iteration 29424: loss: 0.033060, loss_s1: 0.014544, loss_fp: 0.006514, loss_freq: 0.016826
[07:44:16.165] iteration 29425: loss: 0.052744, loss_s1: 0.043842, loss_fp: 0.004774, loss_freq: 0.010852
[07:44:16.763] iteration 29426: loss: 0.056661, loss_s1: 0.073477, loss_fp: 0.004345, loss_freq: 0.009704
[07:44:17.373] iteration 29427: loss: 0.110760, loss_s1: 0.156444, loss_fp: 0.003839, loss_freq: 0.041592
[07:44:17.973] iteration 29428: loss: 0.035733, loss_s1: 0.021056, loss_fp: 0.004511, loss_freq: 0.014591
[07:44:18.588] iteration 29429: loss: 0.076747, loss_s1: 0.081535, loss_fp: 0.007043, loss_freq: 0.036172
[07:44:19.189] iteration 29430: loss: 0.067374, loss_s1: 0.086316, loss_fp: 0.002163, loss_freq: 0.017457
[07:44:19.792] iteration 29431: loss: 0.047792, loss_s1: 0.033711, loss_fp: 0.003588, loss_freq: 0.022929
[07:44:20.399] iteration 29432: loss: 0.055767, loss_s1: 0.044970, loss_fp: 0.009496, loss_freq: 0.040372
[07:44:21.009] iteration 29433: loss: 0.058124, loss_s1: 0.042208, loss_fp: 0.004318, loss_freq: 0.020768
[07:44:21.641] iteration 29434: loss: 0.053386, loss_s1: 0.024277, loss_fp: 0.002700, loss_freq: 0.056984
[07:44:22.243] iteration 29435: loss: 0.114746, loss_s1: 0.122902, loss_fp: 0.020243, loss_freq: 0.062061
[07:44:22.848] iteration 29436: loss: 0.033657, loss_s1: 0.023250, loss_fp: 0.002360, loss_freq: 0.022027
[07:44:23.476] iteration 29437: loss: 0.039748, loss_s1: 0.020007, loss_fp: 0.004635, loss_freq: 0.020065
[07:44:24.093] iteration 29438: loss: 0.069858, loss_s1: 0.069349, loss_fp: 0.005427, loss_freq: 0.026223
[07:44:24.704] iteration 29439: loss: 0.040804, loss_s1: 0.022533, loss_fp: 0.005691, loss_freq: 0.029391
[07:44:25.348] iteration 29440: loss: 0.072080, loss_s1: 0.077208, loss_fp: 0.004751, loss_freq: 0.023888
[07:44:25.969] iteration 29441: loss: 0.074064, loss_s1: 0.064836, loss_fp: 0.004911, loss_freq: 0.054875
[07:44:26.571] iteration 29442: loss: 0.089623, loss_s1: 0.086450, loss_fp: 0.002067, loss_freq: 0.055005
[07:44:27.175] iteration 29443: loss: 0.060112, loss_s1: 0.038158, loss_fp: 0.009643, loss_freq: 0.049938
[07:44:27.777] iteration 29444: loss: 0.037118, loss_s1: 0.021439, loss_fp: 0.002338, loss_freq: 0.008176
[07:44:28.382] iteration 29445: loss: 0.048115, loss_s1: 0.036857, loss_fp: 0.002682, loss_freq: 0.031294
[07:44:28.990] iteration 29446: loss: 0.036671, loss_s1: 0.028767, loss_fp: 0.003653, loss_freq: 0.012337
[07:44:29.605] iteration 29447: loss: 0.054841, loss_s1: 0.043825, loss_fp: 0.001830, loss_freq: 0.035199
[07:44:30.200] iteration 29448: loss: 0.078490, loss_s1: 0.114714, loss_fp: 0.004364, loss_freq: 0.013647
[07:44:30.800] iteration 29449: loss: 0.066139, loss_s1: 0.052610, loss_fp: 0.020376, loss_freq: 0.028622
[07:44:31.406] iteration 29450: loss: 0.059034, loss_s1: 0.061402, loss_fp: 0.003577, loss_freq: 0.026514
[07:44:32.006] iteration 29451: loss: 0.058965, loss_s1: 0.073905, loss_fp: 0.006930, loss_freq: 0.010369
[07:44:32.602] iteration 29452: loss: 0.051002, loss_s1: 0.042778, loss_fp: 0.007473, loss_freq: 0.026891
[07:44:33.193] iteration 29453: loss: 0.066883, loss_s1: 0.071505, loss_fp: 0.003529, loss_freq: 0.036188
[07:44:33.789] iteration 29454: loss: 0.076333, loss_s1: 0.072110, loss_fp: 0.003803, loss_freq: 0.052150
[07:44:34.392] iteration 29455: loss: 0.064582, loss_s1: 0.051954, loss_fp: 0.005521, loss_freq: 0.041233
[07:44:35.008] iteration 29456: loss: 0.067328, loss_s1: 0.060887, loss_fp: 0.011899, loss_freq: 0.034338
[07:44:35.685] iteration 29457: loss: 0.051130, loss_s1: 0.040221, loss_fp: 0.006934, loss_freq: 0.025443
[07:44:36.330] iteration 29458: loss: 0.036727, loss_s1: 0.017179, loss_fp: 0.003093, loss_freq: 0.028078
[07:44:36.969] iteration 29459: loss: 0.051181, loss_s1: 0.059847, loss_fp: 0.001833, loss_freq: 0.014668
[07:44:37.615] iteration 29460: loss: 0.032435, loss_s1: 0.016347, loss_fp: 0.002005, loss_freq: 0.012624
[07:44:38.262] iteration 29461: loss: 0.069270, loss_s1: 0.055640, loss_fp: 0.006594, loss_freq: 0.036726
[07:44:38.897] iteration 29462: loss: 0.061210, loss_s1: 0.064752, loss_fp: 0.006969, loss_freq: 0.026654
[07:44:39.538] iteration 29463: loss: 0.051701, loss_s1: 0.041517, loss_fp: 0.000838, loss_freq: 0.030179
[07:44:40.147] iteration 29464: loss: 0.088506, loss_s1: 0.049670, loss_fp: 0.011447, loss_freq: 0.087754
[07:44:40.790] iteration 29465: loss: 0.034116, loss_s1: 0.019749, loss_fp: 0.004072, loss_freq: 0.014387
[07:44:41.388] iteration 29466: loss: 0.032558, loss_s1: 0.017371, loss_fp: 0.003215, loss_freq: 0.017566
[07:44:41.990] iteration 29467: loss: 0.055429, loss_s1: 0.050790, loss_fp: 0.003442, loss_freq: 0.034096
[07:44:42.594] iteration 29468: loss: 0.038151, loss_s1: 0.020960, loss_fp: 0.008064, loss_freq: 0.013160
[07:44:43.205] iteration 29469: loss: 0.042165, loss_s1: 0.024670, loss_fp: 0.006741, loss_freq: 0.025145
[07:44:43.808] iteration 29470: loss: 0.049327, loss_s1: 0.037727, loss_fp: 0.009829, loss_freq: 0.019846
[07:44:44.417] iteration 29471: loss: 0.036566, loss_s1: 0.036323, loss_fp: 0.004224, loss_freq: 0.012639
[07:44:45.024] iteration 29472: loss: 0.064680, loss_s1: 0.058361, loss_fp: 0.002964, loss_freq: 0.036883
[07:44:45.628] iteration 29473: loss: 0.031796, loss_s1: 0.017191, loss_fp: 0.002045, loss_freq: 0.012025
[07:44:46.243] iteration 29474: loss: 0.045887, loss_s1: 0.034159, loss_fp: 0.005580, loss_freq: 0.029441
[07:44:46.866] iteration 29475: loss: 0.061637, loss_s1: 0.077584, loss_fp: 0.004673, loss_freq: 0.008332
[07:44:47.506] iteration 29476: loss: 0.033801, loss_s1: 0.015048, loss_fp: 0.003646, loss_freq: 0.028775
[07:44:48.149] iteration 29477: loss: 0.050759, loss_s1: 0.040275, loss_fp: 0.001399, loss_freq: 0.019739
[07:44:48.791] iteration 29478: loss: 0.076519, loss_s1: 0.063165, loss_fp: 0.010817, loss_freq: 0.058260
[07:44:49.403] iteration 29479: loss: 0.036703, loss_s1: 0.012196, loss_fp: 0.001245, loss_freq: 0.031898
[07:44:50.004] iteration 29480: loss: 0.042825, loss_s1: 0.028463, loss_fp: 0.002462, loss_freq: 0.035778
[07:44:50.607] iteration 29481: loss: 0.080675, loss_s1: 0.075155, loss_fp: 0.007749, loss_freq: 0.037255
[07:44:51.211] iteration 29482: loss: 0.062261, loss_s1: 0.035621, loss_fp: 0.002222, loss_freq: 0.054575
[07:44:51.810] iteration 29483: loss: 0.080912, loss_s1: 0.084214, loss_fp: 0.008622, loss_freq: 0.043914
[07:44:52.408] iteration 29484: loss: 0.057505, loss_s1: 0.056991, loss_fp: 0.006425, loss_freq: 0.024169
[07:44:53.000] iteration 29485: loss: 0.053613, loss_s1: 0.030024, loss_fp: 0.001465, loss_freq: 0.049647
[07:44:53.605] iteration 29486: loss: 0.056757, loss_s1: 0.041262, loss_fp: 0.007031, loss_freq: 0.030505
[07:44:54.204] iteration 29487: loss: 0.049095, loss_s1: 0.026538, loss_fp: 0.002718, loss_freq: 0.042026
[07:44:54.806] iteration 29488: loss: 0.053536, loss_s1: 0.036333, loss_fp: 0.007071, loss_freq: 0.038826
[07:44:55.408] iteration 29489: loss: 0.043911, loss_s1: 0.026914, loss_fp: 0.012143, loss_freq: 0.027954
[07:44:56.015] iteration 29490: loss: 0.038384, loss_s1: 0.026480, loss_fp: 0.004630, loss_freq: 0.015748
[07:44:56.630] iteration 29491: loss: 0.040892, loss_s1: 0.040490, loss_fp: 0.002700, loss_freq: 0.005167
[07:44:57.247] iteration 29492: loss: 0.064225, loss_s1: 0.054667, loss_fp: 0.002643, loss_freq: 0.041285
[07:44:57.840] iteration 29493: loss: 0.062486, loss_s1: 0.067066, loss_fp: 0.002194, loss_freq: 0.031444
[07:44:58.435] iteration 29494: loss: 0.060726, loss_s1: 0.070544, loss_fp: 0.008771, loss_freq: 0.014676
[07:44:59.034] iteration 29495: loss: 0.056122, loss_s1: 0.051768, loss_fp: 0.002111, loss_freq: 0.029305
[07:44:59.632] iteration 29496: loss: 0.049073, loss_s1: 0.024034, loss_fp: 0.002492, loss_freq: 0.037264
[07:45:00.227] iteration 29497: loss: 0.083600, loss_s1: 0.111369, loss_fp: 0.006842, loss_freq: 0.023646
[07:45:00.833] iteration 29498: loss: 0.077407, loss_s1: 0.098215, loss_fp: 0.007648, loss_freq: 0.022834
[07:45:01.436] iteration 29499: loss: 0.056707, loss_s1: 0.052784, loss_fp: 0.004511, loss_freq: 0.026243
[07:45:02.039] iteration 29500: loss: 0.060955, loss_s1: 0.047948, loss_fp: 0.019297, loss_freq: 0.019835
[07:45:02.641] iteration 29501: loss: 0.051901, loss_s1: 0.052211, loss_fp: 0.002666, loss_freq: 0.016453
[07:45:03.250] iteration 29502: loss: 0.041972, loss_s1: 0.036348, loss_fp: 0.004185, loss_freq: 0.022815
[07:45:03.854] iteration 29503: loss: 0.048552, loss_s1: 0.039036, loss_fp: 0.004515, loss_freq: 0.019496
[07:45:04.460] iteration 29504: loss: 0.052031, loss_s1: 0.034969, loss_fp: 0.003755, loss_freq: 0.032168
[07:45:05.061] iteration 29505: loss: 0.076541, loss_s1: 0.091136, loss_fp: 0.008948, loss_freq: 0.028066
[07:45:05.663] iteration 29506: loss: 0.058796, loss_s1: 0.062746, loss_fp: 0.005290, loss_freq: 0.027821
[07:45:06.256] iteration 29507: loss: 0.053418, loss_s1: 0.048353, loss_fp: 0.001229, loss_freq: 0.025820
[07:45:06.858] iteration 29508: loss: 0.055776, loss_s1: 0.052456, loss_fp: 0.004268, loss_freq: 0.023244
[07:45:07.457] iteration 29509: loss: 0.035330, loss_s1: 0.022648, loss_fp: 0.001827, loss_freq: 0.015328
[07:45:08.103] iteration 29510: loss: 0.044558, loss_s1: 0.033767, loss_fp: 0.001708, loss_freq: 0.017217
[07:45:08.747] iteration 29511: loss: 0.067740, loss_s1: 0.080475, loss_fp: 0.001677, loss_freq: 0.032790
[07:45:09.358] iteration 29512: loss: 0.053710, loss_s1: 0.043251, loss_fp: 0.003279, loss_freq: 0.015109
[07:45:09.959] iteration 29513: loss: 0.026742, loss_s1: 0.014002, loss_fp: 0.002377, loss_freq: 0.011935
[07:45:10.553] iteration 29514: loss: 0.056696, loss_s1: 0.025885, loss_fp: 0.006817, loss_freq: 0.040297
[07:45:11.152] iteration 29515: loss: 0.034115, loss_s1: 0.027252, loss_fp: 0.009672, loss_freq: 0.011827
[07:45:11.749] iteration 29516: loss: 0.072450, loss_s1: 0.078502, loss_fp: 0.003062, loss_freq: 0.034617
[07:45:12.353] iteration 29517: loss: 0.039590, loss_s1: 0.040579, loss_fp: 0.002234, loss_freq: 0.009258
[07:45:12.947] iteration 29518: loss: 0.058341, loss_s1: 0.062858, loss_fp: 0.001960, loss_freq: 0.029367
[07:45:13.550] iteration 29519: loss: 0.053835, loss_s1: 0.024460, loss_fp: 0.010037, loss_freq: 0.045500
[07:45:14.212] iteration 29520: loss: 0.047218, loss_s1: 0.047590, loss_fp: 0.004961, loss_freq: 0.018200
[07:45:14.880] iteration 29521: loss: 0.037184, loss_s1: 0.019385, loss_fp: 0.002243, loss_freq: 0.022748
[07:45:15.528] iteration 29522: loss: 0.034402, loss_s1: 0.029743, loss_fp: 0.002735, loss_freq: 0.009377
[07:45:16.173] iteration 29523: loss: 0.056300, loss_s1: 0.046563, loss_fp: 0.004327, loss_freq: 0.036609
[07:45:16.780] iteration 29524: loss: 0.031841, loss_s1: 0.026964, loss_fp: 0.006952, loss_freq: 0.012182
[07:45:17.378] iteration 29525: loss: 0.070804, loss_s1: 0.059772, loss_fp: 0.011445, loss_freq: 0.039054
[07:45:17.993] iteration 29526: loss: 0.049382, loss_s1: 0.035544, loss_fp: 0.004110, loss_freq: 0.023418
[07:45:18.593] iteration 29527: loss: 0.078146, loss_s1: 0.090572, loss_fp: 0.002203, loss_freq: 0.033272
[07:45:19.194] iteration 29528: loss: 0.076180, loss_s1: 0.061560, loss_fp: 0.012376, loss_freq: 0.048223
[07:45:19.799] iteration 29529: loss: 0.055022, loss_s1: 0.046756, loss_fp: 0.003798, loss_freq: 0.033135
[07:45:20.405] iteration 29530: loss: 0.049574, loss_s1: 0.056525, loss_fp: 0.001709, loss_freq: 0.011122
[07:45:21.013] iteration 29531: loss: 0.038664, loss_s1: 0.039489, loss_fp: 0.001485, loss_freq: 0.007373
[07:45:21.616] iteration 29532: loss: 0.094013, loss_s1: 0.100907, loss_fp: 0.006162, loss_freq: 0.055453
[07:45:22.211] iteration 29533: loss: 0.087959, loss_s1: 0.101449, loss_fp: 0.003090, loss_freq: 0.038271
[07:45:22.811] iteration 29534: loss: 0.054099, loss_s1: 0.048828, loss_fp: 0.005756, loss_freq: 0.026967
[07:45:23.411] iteration 29535: loss: 0.062810, loss_s1: 0.046587, loss_fp: 0.005181, loss_freq: 0.035124
[07:45:24.014] iteration 29536: loss: 0.044661, loss_s1: 0.030862, loss_fp: 0.005023, loss_freq: 0.022030
[07:45:24.620] iteration 29537: loss: 0.065850, loss_s1: 0.071673, loss_fp: 0.004976, loss_freq: 0.033891
[07:45:25.215] iteration 29538: loss: 0.065103, loss_s1: 0.041035, loss_fp: 0.006630, loss_freq: 0.040452
[07:45:25.821] iteration 29539: loss: 0.075198, loss_s1: 0.065852, loss_fp: 0.006740, loss_freq: 0.045435
[07:45:26.428] iteration 29540: loss: 0.067469, loss_s1: 0.052127, loss_fp: 0.007848, loss_freq: 0.045738
[07:45:27.033] iteration 29541: loss: 0.057307, loss_s1: 0.073013, loss_fp: 0.000991, loss_freq: 0.020229
[07:45:27.634] iteration 29542: loss: 0.052963, loss_s1: 0.049343, loss_fp: 0.004774, loss_freq: 0.021330
[07:45:28.232] iteration 29543: loss: 0.080097, loss_s1: 0.074027, loss_fp: 0.003741, loss_freq: 0.053559
[07:45:28.831] iteration 29544: loss: 0.048601, loss_s1: 0.042063, loss_fp: 0.003065, loss_freq: 0.029628
[07:45:29.430] iteration 29545: loss: 0.077695, loss_s1: 0.079527, loss_fp: 0.002319, loss_freq: 0.039462
[07:45:30.035] iteration 29546: loss: 0.033906, loss_s1: 0.030064, loss_fp: 0.003168, loss_freq: 0.013977
[07:45:30.633] iteration 29547: loss: 0.051477, loss_s1: 0.041364, loss_fp: 0.001105, loss_freq: 0.027789
[07:45:31.238] iteration 29548: loss: 0.060603, loss_s1: 0.059135, loss_fp: 0.005256, loss_freq: 0.029924
[07:45:31.844] iteration 29549: loss: 0.062545, loss_s1: 0.043978, loss_fp: 0.008172, loss_freq: 0.046499
[07:45:32.448] iteration 29550: loss: 0.084448, loss_s1: 0.094619, loss_fp: 0.006527, loss_freq: 0.046752
[07:45:33.057] iteration 29551: loss: 0.042389, loss_s1: 0.035228, loss_fp: 0.001347, loss_freq: 0.017812
[07:45:33.661] iteration 29552: loss: 0.038234, loss_s1: 0.021550, loss_fp: 0.001357, loss_freq: 0.021018
[07:45:34.263] iteration 29553: loss: 0.049321, loss_s1: 0.044715, loss_fp: 0.007203, loss_freq: 0.023246
[07:45:34.865] iteration 29554: loss: 0.044194, loss_s1: 0.041038, loss_fp: 0.000915, loss_freq: 0.008080
[07:45:35.463] iteration 29555: loss: 0.045076, loss_s1: 0.042778, loss_fp: 0.004431, loss_freq: 0.011768
[07:45:36.103] iteration 29556: loss: 0.041896, loss_s1: 0.039223, loss_fp: 0.001170, loss_freq: 0.011333
[07:45:36.747] iteration 29557: loss: 0.041045, loss_s1: 0.026134, loss_fp: 0.002244, loss_freq: 0.025259
[07:45:37.353] iteration 29558: loss: 0.075681, loss_s1: 0.085978, loss_fp: 0.004082, loss_freq: 0.038728
[07:45:38.067] iteration 29559: loss: 0.053987, loss_s1: 0.051842, loss_fp: 0.006425, loss_freq: 0.029783
[07:45:38.686] iteration 29560: loss: 0.054759, loss_s1: 0.039324, loss_fp: 0.001442, loss_freq: 0.030610
[07:45:39.354] iteration 29561: loss: 0.072755, loss_s1: 0.058022, loss_fp: 0.011094, loss_freq: 0.046862
[07:45:40.009] iteration 29562: loss: 0.044506, loss_s1: 0.030128, loss_fp: 0.011820, loss_freq: 0.017652
[07:45:40.617] iteration 29563: loss: 0.068822, loss_s1: 0.087258, loss_fp: 0.004437, loss_freq: 0.019737
[07:45:41.273] iteration 29564: loss: 0.051588, loss_s1: 0.042311, loss_fp: 0.006035, loss_freq: 0.031403
[07:45:41.914] iteration 29565: loss: 0.054142, loss_s1: 0.030162, loss_fp: 0.006228, loss_freq: 0.040252
[07:45:42.558] iteration 29566: loss: 0.048603, loss_s1: 0.050864, loss_fp: 0.000574, loss_freq: 0.017028
[07:45:43.201] iteration 29567: loss: 0.043839, loss_s1: 0.039334, loss_fp: 0.002230, loss_freq: 0.019197
[07:45:43.845] iteration 29568: loss: 0.063237, loss_s1: 0.046352, loss_fp: 0.002822, loss_freq: 0.044949
[07:45:44.488] iteration 29569: loss: 0.060246, loss_s1: 0.039610, loss_fp: 0.005161, loss_freq: 0.048849
[07:45:45.132] iteration 29570: loss: 0.083175, loss_s1: 0.089287, loss_fp: 0.011413, loss_freq: 0.029690
[07:45:45.772] iteration 29571: loss: 0.040963, loss_s1: 0.038657, loss_fp: 0.002315, loss_freq: 0.010134
[07:45:46.383] iteration 29572: loss: 0.046698, loss_s1: 0.042104, loss_fp: 0.005824, loss_freq: 0.023625
[07:45:47.031] iteration 29573: loss: 0.029346, loss_s1: 0.015868, loss_fp: 0.001570, loss_freq: 0.005034
[07:45:47.677] iteration 29574: loss: 0.048877, loss_s1: 0.057128, loss_fp: 0.000957, loss_freq: 0.013378
[07:45:48.284] iteration 29575: loss: 0.029995, loss_s1: 0.019259, loss_fp: 0.003414, loss_freq: 0.008754
[07:45:48.877] iteration 29576: loss: 0.058094, loss_s1: 0.034666, loss_fp: 0.003701, loss_freq: 0.048739
[07:45:49.463] iteration 29577: loss: 0.036956, loss_s1: 0.028612, loss_fp: 0.002736, loss_freq: 0.010264
[07:45:50.052] iteration 29578: loss: 0.095096, loss_s1: 0.108752, loss_fp: 0.003369, loss_freq: 0.046178
[07:45:50.632] iteration 29579: loss: 0.093026, loss_s1: 0.087882, loss_fp: 0.006130, loss_freq: 0.065731
[07:45:51.213] iteration 29580: loss: 0.066911, loss_s1: 0.074382, loss_fp: 0.005673, loss_freq: 0.021133
[07:45:52.301] iteration 29581: loss: 0.080761, loss_s1: 0.086403, loss_fp: 0.000772, loss_freq: 0.045459
[07:45:52.904] iteration 29582: loss: 0.045404, loss_s1: 0.030222, loss_fp: 0.005414, loss_freq: 0.020058
[07:45:53.500] iteration 29583: loss: 0.041189, loss_s1: 0.032106, loss_fp: 0.003848, loss_freq: 0.022197
[07:45:54.094] iteration 29584: loss: 0.031827, loss_s1: 0.025890, loss_fp: 0.001260, loss_freq: 0.008403
[07:45:54.697] iteration 29585: loss: 0.045072, loss_s1: 0.031924, loss_fp: 0.005721, loss_freq: 0.030897
[07:45:55.300] iteration 29586: loss: 0.049140, loss_s1: 0.030946, loss_fp: 0.006709, loss_freq: 0.026550
[07:45:55.940] iteration 29587: loss: 0.040508, loss_s1: 0.030332, loss_fp: 0.002693, loss_freq: 0.015642
[07:45:56.536] iteration 29588: loss: 0.057367, loss_s1: 0.058079, loss_fp: 0.002799, loss_freq: 0.026261
[07:45:57.136] iteration 29589: loss: 0.050332, loss_s1: 0.054387, loss_fp: 0.001861, loss_freq: 0.025733
[07:45:57.740] iteration 29590: loss: 0.096418, loss_s1: 0.114180, loss_fp: 0.016692, loss_freq: 0.031815
[07:45:58.347] iteration 29591: loss: 0.075569, loss_s1: 0.064966, loss_fp: 0.004507, loss_freq: 0.050998
[07:45:58.940] iteration 29592: loss: 0.066485, loss_s1: 0.091687, loss_fp: 0.002315, loss_freq: 0.012545
[07:45:59.550] iteration 29593: loss: 0.048247, loss_s1: 0.028271, loss_fp: 0.002186, loss_freq: 0.040360
[07:46:00.151] iteration 29594: loss: 0.066426, loss_s1: 0.057001, loss_fp: 0.004932, loss_freq: 0.048457
[07:46:00.753] iteration 29595: loss: 0.053116, loss_s1: 0.058826, loss_fp: 0.003303, loss_freq: 0.008154
[07:46:01.356] iteration 29596: loss: 0.053804, loss_s1: 0.049320, loss_fp: 0.002849, loss_freq: 0.026401
[07:46:01.962] iteration 29597: loss: 0.099873, loss_s1: 0.107016, loss_fp: 0.005282, loss_freq: 0.068826
[07:46:02.561] iteration 29598: loss: 0.023373, loss_s1: 0.011849, loss_fp: 0.000973, loss_freq: 0.008343
[07:46:03.162] iteration 29599: loss: 0.071770, loss_s1: 0.053838, loss_fp: 0.012809, loss_freq: 0.043383
[07:46:03.770] iteration 29600: loss: 0.067303, loss_s1: 0.071487, loss_fp: 0.002551, loss_freq: 0.024531
[07:46:07.281] iteration 29600 : mean_dice : 0.741692
[07:46:07.905] iteration 29601: loss: 0.041645, loss_s1: 0.036072, loss_fp: 0.001673, loss_freq: 0.015836
[07:46:08.503] iteration 29602: loss: 0.040333, loss_s1: 0.027945, loss_fp: 0.006575, loss_freq: 0.025131
[07:46:09.094] iteration 29603: loss: 0.054475, loss_s1: 0.043689, loss_fp: 0.002390, loss_freq: 0.032381
[07:46:09.685] iteration 29604: loss: 0.046142, loss_s1: 0.025068, loss_fp: 0.003195, loss_freq: 0.034781
[07:46:10.281] iteration 29605: loss: 0.094491, loss_s1: 0.073414, loss_fp: 0.008549, loss_freq: 0.075938
[07:46:10.879] iteration 29606: loss: 0.055627, loss_s1: 0.061191, loss_fp: 0.001904, loss_freq: 0.023570
[07:46:11.469] iteration 29607: loss: 0.047852, loss_s1: 0.037661, loss_fp: 0.005086, loss_freq: 0.019798
[07:46:12.102] iteration 29608: loss: 0.052478, loss_s1: 0.043737, loss_fp: 0.004265, loss_freq: 0.026906
[07:46:12.704] iteration 29609: loss: 0.039582, loss_s1: 0.023893, loss_fp: 0.006072, loss_freq: 0.022302
[07:46:13.303] iteration 29610: loss: 0.049550, loss_s1: 0.040147, loss_fp: 0.005180, loss_freq: 0.021969
[07:46:13.913] iteration 29611: loss: 0.062632, loss_s1: 0.055463, loss_fp: 0.005183, loss_freq: 0.043382
[07:46:14.523] iteration 29612: loss: 0.069470, loss_s1: 0.063573, loss_fp: 0.003377, loss_freq: 0.032692
[07:46:15.134] iteration 29613: loss: 0.053218, loss_s1: 0.050810, loss_fp: 0.006516, loss_freq: 0.025463
[07:46:15.738] iteration 29614: loss: 0.045736, loss_s1: 0.023262, loss_fp: 0.004244, loss_freq: 0.018185
[07:46:16.354] iteration 29615: loss: 0.040388, loss_s1: 0.019721, loss_fp: 0.001235, loss_freq: 0.040447
[07:46:17.016] iteration 29616: loss: 0.052193, loss_s1: 0.055919, loss_fp: 0.001894, loss_freq: 0.012147
[07:46:17.689] iteration 29617: loss: 0.077834, loss_s1: 0.071985, loss_fp: 0.005397, loss_freq: 0.043453
[07:46:18.353] iteration 29618: loss: 0.070618, loss_s1: 0.088807, loss_fp: 0.002597, loss_freq: 0.023600
[07:46:19.004] iteration 29619: loss: 0.059518, loss_s1: 0.037739, loss_fp: 0.002532, loss_freq: 0.050510
[07:46:19.663] iteration 29620: loss: 0.064108, loss_s1: 0.071496, loss_fp: 0.003249, loss_freq: 0.028352
[07:46:20.311] iteration 29621: loss: 0.070995, loss_s1: 0.074383, loss_fp: 0.003559, loss_freq: 0.033270
[07:46:20.955] iteration 29622: loss: 0.057907, loss_s1: 0.061133, loss_fp: 0.002528, loss_freq: 0.018986
[07:46:21.592] iteration 29623: loss: 0.071544, loss_s1: 0.074283, loss_fp: 0.007430, loss_freq: 0.040645
[07:46:22.246] iteration 29624: loss: 0.070440, loss_s1: 0.061293, loss_fp: 0.005602, loss_freq: 0.040722
[07:46:22.885] iteration 29625: loss: 0.056402, loss_s1: 0.041828, loss_fp: 0.004533, loss_freq: 0.028532
[07:46:23.502] iteration 29626: loss: 0.056431, loss_s1: 0.057926, loss_fp: 0.009136, loss_freq: 0.013943
[07:46:24.136] iteration 29627: loss: 0.059056, loss_s1: 0.051964, loss_fp: 0.005496, loss_freq: 0.032127
[07:46:24.785] iteration 29628: loss: 0.062776, loss_s1: 0.058703, loss_fp: 0.003666, loss_freq: 0.040056
[07:46:25.437] iteration 29629: loss: 0.055194, loss_s1: 0.044854, loss_fp: 0.003622, loss_freq: 0.035707
[07:46:26.081] iteration 29630: loss: 0.045236, loss_s1: 0.048898, loss_fp: 0.000786, loss_freq: 0.010657
[07:46:26.722] iteration 29631: loss: 0.038792, loss_s1: 0.028661, loss_fp: 0.009331, loss_freq: 0.010984
[07:46:27.324] iteration 29632: loss: 0.037700, loss_s1: 0.034355, loss_fp: 0.001968, loss_freq: 0.018433
[07:46:27.928] iteration 29633: loss: 0.045618, loss_s1: 0.046943, loss_fp: 0.001264, loss_freq: 0.011164
[07:46:28.536] iteration 29634: loss: 0.103418, loss_s1: 0.074289, loss_fp: 0.004186, loss_freq: 0.092010
[07:46:29.133] iteration 29635: loss: 0.030177, loss_s1: 0.010548, loss_fp: 0.003582, loss_freq: 0.015808
[07:46:29.723] iteration 29636: loss: 0.043387, loss_s1: 0.045493, loss_fp: 0.001875, loss_freq: 0.010774
[07:46:30.321] iteration 29637: loss: 0.040259, loss_s1: 0.027634, loss_fp: 0.008257, loss_freq: 0.025435
[07:46:30.921] iteration 29638: loss: 0.048620, loss_s1: 0.039700, loss_fp: 0.002595, loss_freq: 0.021290
[07:46:31.525] iteration 29639: loss: 0.043966, loss_s1: 0.024908, loss_fp: 0.003728, loss_freq: 0.034478
[07:46:32.117] iteration 29640: loss: 0.048774, loss_s1: 0.059292, loss_fp: 0.001164, loss_freq: 0.011489
[07:46:32.719] iteration 29641: loss: 0.027436, loss_s1: 0.019303, loss_fp: 0.005654, loss_freq: 0.006286
[07:46:33.316] iteration 29642: loss: 0.044092, loss_s1: 0.024723, loss_fp: 0.001331, loss_freq: 0.031176
[07:46:33.905] iteration 29643: loss: 0.045149, loss_s1: 0.024447, loss_fp: 0.005237, loss_freq: 0.024724
[07:46:34.497] iteration 29644: loss: 0.059963, loss_s1: 0.057067, loss_fp: 0.005243, loss_freq: 0.030244
[07:46:35.090] iteration 29645: loss: 0.076465, loss_s1: 0.112932, loss_fp: 0.001729, loss_freq: 0.006937
[07:46:35.690] iteration 29646: loss: 0.040135, loss_s1: 0.027030, loss_fp: 0.003679, loss_freq: 0.030719
[07:46:36.284] iteration 29647: loss: 0.043615, loss_s1: 0.036681, loss_fp: 0.004002, loss_freq: 0.008577
[07:46:36.872] iteration 29648: loss: 0.065240, loss_s1: 0.056766, loss_fp: 0.006623, loss_freq: 0.046441
[07:46:37.483] iteration 29649: loss: 0.032139, loss_s1: 0.020904, loss_fp: 0.006618, loss_freq: 0.010060
[07:46:38.080] iteration 29650: loss: 0.050080, loss_s1: 0.047260, loss_fp: 0.004606, loss_freq: 0.030386
[07:46:38.674] iteration 29651: loss: 0.047234, loss_s1: 0.028457, loss_fp: 0.006386, loss_freq: 0.029805
[07:46:39.277] iteration 29652: loss: 0.055672, loss_s1: 0.034528, loss_fp: 0.005792, loss_freq: 0.034942
[07:46:39.867] iteration 29653: loss: 0.066761, loss_s1: 0.055583, loss_fp: 0.007799, loss_freq: 0.040798
[07:46:40.460] iteration 29654: loss: 0.055972, loss_s1: 0.047372, loss_fp: 0.006125, loss_freq: 0.032215
[07:46:41.051] iteration 29655: loss: 0.074539, loss_s1: 0.050783, loss_fp: 0.002725, loss_freq: 0.069803
[07:46:41.639] iteration 29656: loss: 0.069504, loss_s1: 0.025184, loss_fp: 0.004020, loss_freq: 0.068674
[07:46:42.288] iteration 29657: loss: 0.049644, loss_s1: 0.041364, loss_fp: 0.002664, loss_freq: 0.026384
[07:46:42.931] iteration 29658: loss: 0.062822, loss_s1: 0.037958, loss_fp: 0.007689, loss_freq: 0.057331
[07:46:43.570] iteration 29659: loss: 0.048158, loss_s1: 0.038478, loss_fp: 0.008192, loss_freq: 0.030088
[07:46:44.209] iteration 29660: loss: 0.051013, loss_s1: 0.048192, loss_fp: 0.001101, loss_freq: 0.022762
[07:46:44.848] iteration 29661: loss: 0.040362, loss_s1: 0.017558, loss_fp: 0.011429, loss_freq: 0.011943
[07:46:45.471] iteration 29662: loss: 0.062682, loss_s1: 0.055221, loss_fp: 0.004293, loss_freq: 0.035053
[07:46:46.063] iteration 29663: loss: 0.051576, loss_s1: 0.046700, loss_fp: 0.001026, loss_freq: 0.024850
[07:46:46.649] iteration 29664: loss: 0.034753, loss_s1: 0.022097, loss_fp: 0.003989, loss_freq: 0.014415
[07:46:47.239] iteration 29665: loss: 0.059319, loss_s1: 0.048284, loss_fp: 0.002783, loss_freq: 0.039028
[07:46:47.825] iteration 29666: loss: 0.056405, loss_s1: 0.056279, loss_fp: 0.002543, loss_freq: 0.015532
[07:46:48.406] iteration 29667: loss: 0.061650, loss_s1: 0.062214, loss_fp: 0.004531, loss_freq: 0.035066
[07:46:48.987] iteration 29668: loss: 0.075195, loss_s1: 0.078197, loss_fp: 0.007240, loss_freq: 0.030113
[07:46:49.586] iteration 29669: loss: 0.047210, loss_s1: 0.034899, loss_fp: 0.003509, loss_freq: 0.027912
[07:46:50.181] iteration 29670: loss: 0.048484, loss_s1: 0.050340, loss_fp: 0.001073, loss_freq: 0.014703
[07:46:50.781] iteration 29671: loss: 0.076657, loss_s1: 0.063985, loss_fp: 0.004134, loss_freq: 0.057281
[07:46:51.367] iteration 29672: loss: 0.047433, loss_s1: 0.019301, loss_fp: 0.008588, loss_freq: 0.046884
[07:46:51.986] iteration 29673: loss: 0.088880, loss_s1: 0.083861, loss_fp: 0.008806, loss_freq: 0.037470
[07:46:52.617] iteration 29674: loss: 0.059692, loss_s1: 0.047226, loss_fp: 0.005028, loss_freq: 0.042036
[07:46:53.247] iteration 29675: loss: 0.059831, loss_s1: 0.062131, loss_fp: 0.007289, loss_freq: 0.023372
[07:46:53.873] iteration 29676: loss: 0.040168, loss_s1: 0.031464, loss_fp: 0.002803, loss_freq: 0.026372
[07:46:54.464] iteration 29677: loss: 0.064894, loss_s1: 0.053229, loss_fp: 0.004323, loss_freq: 0.030794
[07:46:55.056] iteration 29678: loss: 0.063263, loss_s1: 0.030205, loss_fp: 0.004822, loss_freq: 0.063170
[07:46:55.645] iteration 29679: loss: 0.060146, loss_s1: 0.049112, loss_fp: 0.018843, loss_freq: 0.027426
[07:46:56.232] iteration 29680: loss: 0.048447, loss_s1: 0.032548, loss_fp: 0.003286, loss_freq: 0.030721
[07:46:56.821] iteration 29681: loss: 0.078834, loss_s1: 0.098785, loss_fp: 0.002505, loss_freq: 0.035228
[07:46:57.416] iteration 29682: loss: 0.040273, loss_s1: 0.027710, loss_fp: 0.001654, loss_freq: 0.019611
[07:46:58.005] iteration 29683: loss: 0.042519, loss_s1: 0.033764, loss_fp: 0.008161, loss_freq: 0.019382
[07:46:58.600] iteration 29684: loss: 0.050638, loss_s1: 0.041140, loss_fp: 0.002716, loss_freq: 0.027870
[07:46:59.186] iteration 29685: loss: 0.020280, loss_s1: 0.008390, loss_fp: 0.001286, loss_freq: 0.008963
[07:46:59.773] iteration 29686: loss: 0.063298, loss_s1: 0.063914, loss_fp: 0.008107, loss_freq: 0.024668
[07:47:00.363] iteration 29687: loss: 0.041940, loss_s1: 0.032881, loss_fp: 0.008669, loss_freq: 0.010628
[07:47:00.950] iteration 29688: loss: 0.050469, loss_s1: 0.042798, loss_fp: 0.005161, loss_freq: 0.028748
[07:47:01.543] iteration 29689: loss: 0.077519, loss_s1: 0.064744, loss_fp: 0.011258, loss_freq: 0.052148
[07:47:02.136] iteration 29690: loss: 0.035854, loss_s1: 0.020405, loss_fp: 0.003683, loss_freq: 0.025791
[07:47:02.734] iteration 29691: loss: 0.041198, loss_s1: 0.024576, loss_fp: 0.004845, loss_freq: 0.015050
[07:47:03.333] iteration 29692: loss: 0.044898, loss_s1: 0.043738, loss_fp: 0.005203, loss_freq: 0.016481
[07:47:03.952] iteration 29693: loss: 0.052715, loss_s1: 0.038105, loss_fp: 0.004877, loss_freq: 0.033693
[07:47:04.549] iteration 29694: loss: 0.027465, loss_s1: 0.019904, loss_fp: 0.002454, loss_freq: 0.015224
[07:47:05.136] iteration 29695: loss: 0.070934, loss_s1: 0.054607, loss_fp: 0.002788, loss_freq: 0.039008
[07:47:05.720] iteration 29696: loss: 0.054298, loss_s1: 0.042327, loss_fp: 0.004511, loss_freq: 0.032779
[07:47:06.311] iteration 29697: loss: 0.067985, loss_s1: 0.052545, loss_fp: 0.003763, loss_freq: 0.050287
[07:47:06.898] iteration 29698: loss: 0.053495, loss_s1: 0.044708, loss_fp: 0.007359, loss_freq: 0.030084
[07:47:07.479] iteration 29699: loss: 0.096404, loss_s1: 0.122085, loss_fp: 0.010550, loss_freq: 0.025624
[07:47:08.063] iteration 29700: loss: 0.032719, loss_s1: 0.020653, loss_fp: 0.001661, loss_freq: 0.014187
[07:47:08.650] iteration 29701: loss: 0.037106, loss_s1: 0.030967, loss_fp: 0.002973, loss_freq: 0.011049
[07:47:09.236] iteration 29702: loss: 0.103424, loss_s1: 0.127056, loss_fp: 0.006328, loss_freq: 0.055205
[07:47:09.825] iteration 29703: loss: 0.063801, loss_s1: 0.040490, loss_fp: 0.012867, loss_freq: 0.031272
[07:47:10.418] iteration 29704: loss: 0.087066, loss_s1: 0.041216, loss_fp: 0.008170, loss_freq: 0.095290
[07:47:11.005] iteration 29705: loss: 0.078805, loss_s1: 0.072671, loss_fp: 0.004029, loss_freq: 0.040449
[07:47:11.597] iteration 29706: loss: 0.052151, loss_s1: 0.042416, loss_fp: 0.005723, loss_freq: 0.026202
[07:47:12.188] iteration 29707: loss: 0.070775, loss_s1: 0.076130, loss_fp: 0.002085, loss_freq: 0.041904
[07:47:12.786] iteration 29708: loss: 0.035470, loss_s1: 0.012819, loss_fp: 0.006794, loss_freq: 0.009327
[07:47:13.376] iteration 29709: loss: 0.039807, loss_s1: 0.036132, loss_fp: 0.004562, loss_freq: 0.018982
[07:47:13.972] iteration 29710: loss: 0.067679, loss_s1: 0.051238, loss_fp: 0.007130, loss_freq: 0.047808
[07:47:14.571] iteration 29711: loss: 0.057313, loss_s1: 0.066130, loss_fp: 0.004643, loss_freq: 0.023136
[07:47:15.156] iteration 29712: loss: 0.041628, loss_s1: 0.028070, loss_fp: 0.002136, loss_freq: 0.022870
[07:47:15.744] iteration 29713: loss: 0.056805, loss_s1: 0.047934, loss_fp: 0.009626, loss_freq: 0.025079
[07:47:16.337] iteration 29714: loss: 0.039940, loss_s1: 0.042931, loss_fp: 0.002958, loss_freq: 0.011420
[07:47:16.942] iteration 29715: loss: 0.088310, loss_s1: 0.067459, loss_fp: 0.003099, loss_freq: 0.072076
[07:47:17.543] iteration 29716: loss: 0.037951, loss_s1: 0.030152, loss_fp: 0.004029, loss_freq: 0.018097
[07:47:18.139] iteration 29717: loss: 0.064974, loss_s1: 0.064806, loss_fp: 0.004157, loss_freq: 0.028347
[07:47:18.726] iteration 29718: loss: 0.067275, loss_s1: 0.049112, loss_fp: 0.007606, loss_freq: 0.051611
[07:47:19.316] iteration 29719: loss: 0.048366, loss_s1: 0.049084, loss_fp: 0.001835, loss_freq: 0.017926
[07:47:19.910] iteration 29720: loss: 0.055899, loss_s1: 0.050254, loss_fp: 0.001662, loss_freq: 0.040216
[07:47:20.505] iteration 29721: loss: 0.071310, loss_s1: 0.051689, loss_fp: 0.004868, loss_freq: 0.037360
[07:47:21.091] iteration 29722: loss: 0.029590, loss_s1: 0.013397, loss_fp: 0.001436, loss_freq: 0.015020
[07:47:21.678] iteration 29723: loss: 0.038238, loss_s1: 0.030772, loss_fp: 0.002256, loss_freq: 0.018840
[07:47:22.266] iteration 29724: loss: 0.036506, loss_s1: 0.028923, loss_fp: 0.003025, loss_freq: 0.010407
[07:47:22.901] iteration 29725: loss: 0.038588, loss_s1: 0.034097, loss_fp: 0.002856, loss_freq: 0.018707
[07:47:23.514] iteration 29726: loss: 0.051744, loss_s1: 0.050448, loss_fp: 0.002517, loss_freq: 0.019511
[07:47:24.136] iteration 29727: loss: 0.040269, loss_s1: 0.031335, loss_fp: 0.002049, loss_freq: 0.018625
[07:47:24.793] iteration 29728: loss: 0.121031, loss_s1: 0.188254, loss_fp: 0.003301, loss_freq: 0.029510
[07:47:25.380] iteration 29729: loss: 0.049591, loss_s1: 0.058084, loss_fp: 0.004724, loss_freq: 0.015807
[07:47:25.969] iteration 29730: loss: 0.057054, loss_s1: 0.047478, loss_fp: 0.000589, loss_freq: 0.031942
[07:47:26.583] iteration 29731: loss: 0.058660, loss_s1: 0.051974, loss_fp: 0.008240, loss_freq: 0.026222
[07:47:27.174] iteration 29732: loss: 0.060429, loss_s1: 0.070155, loss_fp: 0.001456, loss_freq: 0.016566
[07:47:27.802] iteration 29733: loss: 0.074971, loss_s1: 0.082784, loss_fp: 0.006834, loss_freq: 0.034264
[07:47:28.431] iteration 29734: loss: 0.108393, loss_s1: 0.100884, loss_fp: 0.015534, loss_freq: 0.070648
[07:47:29.050] iteration 29735: loss: 0.068199, loss_s1: 0.065983, loss_fp: 0.002689, loss_freq: 0.018509
[07:47:29.642] iteration 29736: loss: 0.036631, loss_s1: 0.018139, loss_fp: 0.001896, loss_freq: 0.026369
[07:47:30.231] iteration 29737: loss: 0.022561, loss_s1: 0.010083, loss_fp: 0.001525, loss_freq: 0.013617
[07:47:30.822] iteration 29738: loss: 0.070733, loss_s1: 0.054066, loss_fp: 0.001752, loss_freq: 0.055336
[07:47:31.416] iteration 29739: loss: 0.051035, loss_s1: 0.032465, loss_fp: 0.006486, loss_freq: 0.034277
[07:47:32.005] iteration 29740: loss: 0.086794, loss_s1: 0.102210, loss_fp: 0.005603, loss_freq: 0.034400
[07:47:32.591] iteration 29741: loss: 0.048137, loss_s1: 0.052958, loss_fp: 0.004976, loss_freq: 0.010406
[07:47:33.189] iteration 29742: loss: 0.078158, loss_s1: 0.079631, loss_fp: 0.003890, loss_freq: 0.052764
[07:47:33.776] iteration 29743: loss: 0.036579, loss_s1: 0.017462, loss_fp: 0.002537, loss_freq: 0.011611
[07:47:34.371] iteration 29744: loss: 0.055884, loss_s1: 0.049913, loss_fp: 0.003007, loss_freq: 0.035921
[07:47:34.960] iteration 29745: loss: 0.036729, loss_s1: 0.024165, loss_fp: 0.001909, loss_freq: 0.022737
[07:47:35.546] iteration 29746: loss: 0.054580, loss_s1: 0.062502, loss_fp: 0.002272, loss_freq: 0.022873
[07:47:36.132] iteration 29747: loss: 0.046880, loss_s1: 0.019465, loss_fp: 0.002686, loss_freq: 0.044242
[07:47:36.779] iteration 29748: loss: 0.074769, loss_s1: 0.054064, loss_fp: 0.004487, loss_freq: 0.059220
[07:47:37.410] iteration 29749: loss: 0.085643, loss_s1: 0.115927, loss_fp: 0.005018, loss_freq: 0.028072
[07:47:37.997] iteration 29750: loss: 0.037541, loss_s1: 0.021465, loss_fp: 0.004297, loss_freq: 0.016557
[07:47:39.297] iteration 29751: loss: 0.035047, loss_s1: 0.027823, loss_fp: 0.001498, loss_freq: 0.010017
[07:47:39.882] iteration 29752: loss: 0.051230, loss_s1: 0.038830, loss_fp: 0.007212, loss_freq: 0.027271
[07:47:40.470] iteration 29753: loss: 0.045196, loss_s1: 0.037751, loss_fp: 0.001618, loss_freq: 0.025643
[07:47:41.057] iteration 29754: loss: 0.048456, loss_s1: 0.051660, loss_fp: 0.001282, loss_freq: 0.011707
[07:47:41.649] iteration 29755: loss: 0.032327, loss_s1: 0.022542, loss_fp: 0.003501, loss_freq: 0.014172
[07:47:42.237] iteration 29756: loss: 0.050258, loss_s1: 0.042703, loss_fp: 0.001865, loss_freq: 0.019534
[07:47:42.831] iteration 29757: loss: 0.055153, loss_s1: 0.034019, loss_fp: 0.001989, loss_freq: 0.039804
[07:47:43.458] iteration 29758: loss: 0.054286, loss_s1: 0.058477, loss_fp: 0.004378, loss_freq: 0.017564
[07:47:44.098] iteration 29759: loss: 0.032309, loss_s1: 0.029684, loss_fp: 0.002863, loss_freq: 0.008941
[07:47:44.783] iteration 29760: loss: 0.047282, loss_s1: 0.033796, loss_fp: 0.003079, loss_freq: 0.023466
[07:47:45.377] iteration 29761: loss: 0.058541, loss_s1: 0.057382, loss_fp: 0.001979, loss_freq: 0.024467
[07:47:46.015] iteration 29762: loss: 0.038580, loss_s1: 0.030480, loss_fp: 0.002914, loss_freq: 0.013331
[07:47:46.602] iteration 29763: loss: 0.035805, loss_s1: 0.024666, loss_fp: 0.003055, loss_freq: 0.020524
[07:47:47.229] iteration 29764: loss: 0.079092, loss_s1: 0.085050, loss_fp: 0.009031, loss_freq: 0.036007
[07:47:47.858] iteration 29765: loss: 0.052686, loss_s1: 0.036885, loss_fp: 0.005050, loss_freq: 0.023592
[07:47:48.461] iteration 29766: loss: 0.048653, loss_s1: 0.054135, loss_fp: 0.002739, loss_freq: 0.011880
[07:47:49.044] iteration 29767: loss: 0.056497, loss_s1: 0.038983, loss_fp: 0.004504, loss_freq: 0.049816
[07:47:49.631] iteration 29768: loss: 0.055034, loss_s1: 0.054011, loss_fp: 0.003267, loss_freq: 0.016291
[07:47:50.215] iteration 29769: loss: 0.083897, loss_s1: 0.058295, loss_fp: 0.018497, loss_freq: 0.061528
[07:47:50.813] iteration 29770: loss: 0.055766, loss_s1: 0.063469, loss_fp: 0.002553, loss_freq: 0.014470
[07:47:51.419] iteration 29771: loss: 0.049716, loss_s1: 0.019942, loss_fp: 0.002474, loss_freq: 0.042021
[07:47:52.007] iteration 29772: loss: 0.039716, loss_s1: 0.023456, loss_fp: 0.004354, loss_freq: 0.028566
[07:47:52.592] iteration 29773: loss: 0.052174, loss_s1: 0.026122, loss_fp: 0.004822, loss_freq: 0.025936
[07:47:53.184] iteration 29774: loss: 0.039434, loss_s1: 0.032610, loss_fp: 0.001604, loss_freq: 0.022288
[07:47:53.773] iteration 29775: loss: 0.109802, loss_s1: 0.145694, loss_fp: 0.007348, loss_freq: 0.039539
[07:47:54.384] iteration 29776: loss: 0.052310, loss_s1: 0.045305, loss_fp: 0.003153, loss_freq: 0.034122
[07:47:54.988] iteration 29777: loss: 0.049225, loss_s1: 0.025056, loss_fp: 0.002225, loss_freq: 0.006235
[07:47:55.593] iteration 29778: loss: 0.093802, loss_s1: 0.128654, loss_fp: 0.007459, loss_freq: 0.021782
[07:47:56.195] iteration 29779: loss: 0.042574, loss_s1: 0.027131, loss_fp: 0.002963, loss_freq: 0.027708
[07:47:56.804] iteration 29780: loss: 0.071088, loss_s1: 0.048394, loss_fp: 0.013696, loss_freq: 0.036997
[07:47:57.408] iteration 29781: loss: 0.057796, loss_s1: 0.037893, loss_fp: 0.009049, loss_freq: 0.045797
[07:47:58.012] iteration 29782: loss: 0.057911, loss_s1: 0.039023, loss_fp: 0.004127, loss_freq: 0.038194
[07:47:58.626] iteration 29783: loss: 0.046530, loss_s1: 0.027679, loss_fp: 0.004718, loss_freq: 0.031511
[07:47:59.235] iteration 29784: loss: 0.043352, loss_s1: 0.027283, loss_fp: 0.002390, loss_freq: 0.023632
[07:47:59.853] iteration 29785: loss: 0.047507, loss_s1: 0.042327, loss_fp: 0.002136, loss_freq: 0.030793
[07:48:00.459] iteration 29786: loss: 0.049616, loss_s1: 0.034506, loss_fp: 0.006876, loss_freq: 0.020020
[07:48:01.064] iteration 29787: loss: 0.055629, loss_s1: 0.041001, loss_fp: 0.007016, loss_freq: 0.033837
[07:48:01.668] iteration 29788: loss: 0.038071, loss_s1: 0.031246, loss_fp: 0.001567, loss_freq: 0.020130
[07:48:02.276] iteration 29789: loss: 0.089449, loss_s1: 0.097556, loss_fp: 0.003625, loss_freq: 0.041602
[07:48:02.884] iteration 29790: loss: 0.059737, loss_s1: 0.044904, loss_fp: 0.006471, loss_freq: 0.045033
[07:48:03.483] iteration 29791: loss: 0.055597, loss_s1: 0.048447, loss_fp: 0.016691, loss_freq: 0.017520
[07:48:04.083] iteration 29792: loss: 0.065008, loss_s1: 0.077576, loss_fp: 0.005856, loss_freq: 0.018447
[07:48:04.674] iteration 29793: loss: 0.090353, loss_s1: 0.122504, loss_fp: 0.001089, loss_freq: 0.027388
[07:48:05.263] iteration 29794: loss: 0.071789, loss_s1: 0.066466, loss_fp: 0.002478, loss_freq: 0.058339
[07:48:05.853] iteration 29795: loss: 0.063666, loss_s1: 0.025499, loss_fp: 0.013270, loss_freq: 0.052968
[07:48:06.447] iteration 29796: loss: 0.067840, loss_s1: 0.059360, loss_fp: 0.003969, loss_freq: 0.037142
[07:48:07.037] iteration 29797: loss: 0.064335, loss_s1: 0.069852, loss_fp: 0.003314, loss_freq: 0.024108
[07:48:07.623] iteration 29798: loss: 0.048028, loss_s1: 0.044694, loss_fp: 0.002625, loss_freq: 0.024128
[07:48:08.212] iteration 29799: loss: 0.029697, loss_s1: 0.010299, loss_fp: 0.003067, loss_freq: 0.013688
[07:48:08.799] iteration 29800: loss: 0.037614, loss_s1: 0.026063, loss_fp: 0.001158, loss_freq: 0.010172
[07:48:12.220] iteration 29800 : mean_dice : 0.741893
[07:48:12.840] iteration 29801: loss: 0.048987, loss_s1: 0.041209, loss_fp: 0.003674, loss_freq: 0.024658
[07:48:13.433] iteration 29802: loss: 0.028764, loss_s1: 0.013655, loss_fp: 0.004046, loss_freq: 0.018079
[07:48:14.026] iteration 29803: loss: 0.032197, loss_s1: 0.015395, loss_fp: 0.002982, loss_freq: 0.013511
[07:48:14.613] iteration 29804: loss: 0.102332, loss_s1: 0.131402, loss_fp: 0.005641, loss_freq: 0.039683
[07:48:15.292] iteration 29805: loss: 0.054535, loss_s1: 0.058423, loss_fp: 0.003761, loss_freq: 0.013931
[07:48:15.923] iteration 29806: loss: 0.029307, loss_s1: 0.009295, loss_fp: 0.004659, loss_freq: 0.013947
[07:48:16.552] iteration 29807: loss: 0.058919, loss_s1: 0.056506, loss_fp: 0.004269, loss_freq: 0.038048
[07:48:17.158] iteration 29808: loss: 0.036928, loss_s1: 0.022207, loss_fp: 0.003030, loss_freq: 0.016604
[07:48:17.746] iteration 29809: loss: 0.046720, loss_s1: 0.032620, loss_fp: 0.009222, loss_freq: 0.031211
[07:48:18.335] iteration 29810: loss: 0.059836, loss_s1: 0.062127, loss_fp: 0.002570, loss_freq: 0.024632
[07:48:18.925] iteration 29811: loss: 0.031030, loss_s1: 0.033992, loss_fp: 0.002063, loss_freq: 0.006217
[07:48:19.518] iteration 29812: loss: 0.044016, loss_s1: 0.026779, loss_fp: 0.002890, loss_freq: 0.028697
[07:48:20.108] iteration 29813: loss: 0.041307, loss_s1: 0.034453, loss_fp: 0.002971, loss_freq: 0.011640
[07:48:20.732] iteration 29814: loss: 0.038244, loss_s1: 0.034659, loss_fp: 0.002917, loss_freq: 0.015790
[07:48:21.396] iteration 29815: loss: 0.035984, loss_s1: 0.030081, loss_fp: 0.002970, loss_freq: 0.005152
[07:48:22.021] iteration 29816: loss: 0.046061, loss_s1: 0.031932, loss_fp: 0.005429, loss_freq: 0.025877
[07:48:22.655] iteration 29817: loss: 0.038129, loss_s1: 0.026927, loss_fp: 0.002577, loss_freq: 0.009619
[07:48:23.267] iteration 29818: loss: 0.100202, loss_s1: 0.117430, loss_fp: 0.015787, loss_freq: 0.038268
[07:48:23.849] iteration 29819: loss: 0.034389, loss_s1: 0.026067, loss_fp: 0.002884, loss_freq: 0.014755
[07:48:24.437] iteration 29820: loss: 0.056373, loss_s1: 0.052692, loss_fp: 0.004369, loss_freq: 0.038094
[07:48:25.027] iteration 29821: loss: 0.065122, loss_s1: 0.057107, loss_fp: 0.004650, loss_freq: 0.040818
[07:48:25.624] iteration 29822: loss: 0.034981, loss_s1: 0.015442, loss_fp: 0.005676, loss_freq: 0.016650
[07:48:26.221] iteration 29823: loss: 0.047900, loss_s1: 0.034317, loss_fp: 0.006316, loss_freq: 0.028812
[07:48:26.818] iteration 29824: loss: 0.050658, loss_s1: 0.038920, loss_fp: 0.007959, loss_freq: 0.026624
[07:48:27.412] iteration 29825: loss: 0.041407, loss_s1: 0.017078, loss_fp: 0.011001, loss_freq: 0.030297
[07:48:28.010] iteration 29826: loss: 0.072124, loss_s1: 0.084850, loss_fp: 0.002971, loss_freq: 0.023405
[07:48:28.608] iteration 29827: loss: 0.046678, loss_s1: 0.025307, loss_fp: 0.001100, loss_freq: 0.037725
[07:48:29.208] iteration 29828: loss: 0.055628, loss_s1: 0.024366, loss_fp: 0.009263, loss_freq: 0.051112
[07:48:29.799] iteration 29829: loss: 0.061751, loss_s1: 0.050145, loss_fp: 0.011075, loss_freq: 0.042492
[07:48:30.396] iteration 29830: loss: 0.053544, loss_s1: 0.048542, loss_fp: 0.002339, loss_freq: 0.019058
[07:48:30.987] iteration 29831: loss: 0.101926, loss_s1: 0.110736, loss_fp: 0.010864, loss_freq: 0.051885
[07:48:31.596] iteration 29832: loss: 0.059371, loss_s1: 0.049242, loss_fp: 0.005645, loss_freq: 0.032944
[07:48:32.207] iteration 29833: loss: 0.051412, loss_s1: 0.044326, loss_fp: 0.003657, loss_freq: 0.020886
[07:48:32.820] iteration 29834: loss: 0.032233, loss_s1: 0.020903, loss_fp: 0.001329, loss_freq: 0.018365
[07:48:33.417] iteration 29835: loss: 0.044696, loss_s1: 0.028199, loss_fp: 0.002918, loss_freq: 0.022031
[07:48:34.006] iteration 29836: loss: 0.063248, loss_s1: 0.061398, loss_fp: 0.007745, loss_freq: 0.015024
[07:48:34.600] iteration 29837: loss: 0.063393, loss_s1: 0.072238, loss_fp: 0.006720, loss_freq: 0.026416
[07:48:35.200] iteration 29838: loss: 0.045206, loss_s1: 0.025324, loss_fp: 0.002575, loss_freq: 0.022887
[07:48:35.793] iteration 29839: loss: 0.046658, loss_s1: 0.030747, loss_fp: 0.002693, loss_freq: 0.030051
[07:48:36.388] iteration 29840: loss: 0.081157, loss_s1: 0.070690, loss_fp: 0.007744, loss_freq: 0.043818
[07:48:36.985] iteration 29841: loss: 0.054541, loss_s1: 0.052706, loss_fp: 0.004227, loss_freq: 0.023258
[07:48:37.588] iteration 29842: loss: 0.043834, loss_s1: 0.048803, loss_fp: 0.001753, loss_freq: 0.017240
[07:48:38.181] iteration 29843: loss: 0.071441, loss_s1: 0.050426, loss_fp: 0.016053, loss_freq: 0.039105
[07:48:38.767] iteration 29844: loss: 0.043797, loss_s1: 0.044337, loss_fp: 0.002627, loss_freq: 0.017661
[07:48:39.368] iteration 29845: loss: 0.064758, loss_s1: 0.075881, loss_fp: 0.008036, loss_freq: 0.020097
[07:48:39.967] iteration 29846: loss: 0.054805, loss_s1: 0.040867, loss_fp: 0.000869, loss_freq: 0.046023
[07:48:40.567] iteration 29847: loss: 0.065071, loss_s1: 0.047708, loss_fp: 0.001052, loss_freq: 0.043942
[07:48:41.166] iteration 29848: loss: 0.058638, loss_s1: 0.044945, loss_fp: 0.003182, loss_freq: 0.036933
[07:48:41.759] iteration 29849: loss: 0.053405, loss_s1: 0.047642, loss_fp: 0.012316, loss_freq: 0.020733
[07:48:42.357] iteration 29850: loss: 0.050977, loss_s1: 0.047648, loss_fp: 0.005426, loss_freq: 0.019941
[07:48:42.943] iteration 29851: loss: 0.079691, loss_s1: 0.082838, loss_fp: 0.002921, loss_freq: 0.051971
[07:48:43.536] iteration 29852: loss: 0.041620, loss_s1: 0.028624, loss_fp: 0.002881, loss_freq: 0.012854
[07:48:44.120] iteration 29853: loss: 0.041362, loss_s1: 0.030336, loss_fp: 0.008188, loss_freq: 0.018044
[07:48:44.704] iteration 29854: loss: 0.036461, loss_s1: 0.024101, loss_fp: 0.004412, loss_freq: 0.014809
[07:48:45.325] iteration 29855: loss: 0.029608, loss_s1: 0.030536, loss_fp: 0.002707, loss_freq: 0.005035
[07:48:45.918] iteration 29856: loss: 0.094233, loss_s1: 0.126444, loss_fp: 0.004073, loss_freq: 0.028571
[07:48:46.511] iteration 29857: loss: 0.066251, loss_s1: 0.054200, loss_fp: 0.009007, loss_freq: 0.035656
[07:48:47.102] iteration 29858: loss: 0.036100, loss_s1: 0.023474, loss_fp: 0.001359, loss_freq: 0.020764
[07:48:47.692] iteration 29859: loss: 0.064238, loss_s1: 0.028146, loss_fp: 0.009086, loss_freq: 0.061875
[07:48:48.280] iteration 29860: loss: 0.057101, loss_s1: 0.069973, loss_fp: 0.004037, loss_freq: 0.017583
[07:48:48.866] iteration 29861: loss: 0.038253, loss_s1: 0.021768, loss_fp: 0.002787, loss_freq: 0.019717
[07:48:49.457] iteration 29862: loss: 0.055249, loss_s1: 0.056246, loss_fp: 0.003835, loss_freq: 0.024596
[07:48:50.049] iteration 29863: loss: 0.062082, loss_s1: 0.047239, loss_fp: 0.007348, loss_freq: 0.046360
[07:48:50.640] iteration 29864: loss: 0.040930, loss_s1: 0.046842, loss_fp: 0.001718, loss_freq: 0.013697
[07:48:51.229] iteration 29865: loss: 0.102911, loss_s1: 0.097788, loss_fp: 0.003821, loss_freq: 0.065335
[07:48:51.817] iteration 29866: loss: 0.074675, loss_s1: 0.058824, loss_fp: 0.007548, loss_freq: 0.044094
[07:48:52.409] iteration 29867: loss: 0.092931, loss_s1: 0.098058, loss_fp: 0.011629, loss_freq: 0.037143
[07:48:53.001] iteration 29868: loss: 0.065827, loss_s1: 0.071490, loss_fp: 0.002919, loss_freq: 0.034790
[07:48:53.600] iteration 29869: loss: 0.067421, loss_s1: 0.060468, loss_fp: 0.002828, loss_freq: 0.047392
[07:48:54.191] iteration 29870: loss: 0.069664, loss_s1: 0.065914, loss_fp: 0.000998, loss_freq: 0.033448
[07:48:54.786] iteration 29871: loss: 0.041372, loss_s1: 0.045029, loss_fp: 0.001055, loss_freq: 0.006965
[07:48:55.381] iteration 29872: loss: 0.054290, loss_s1: 0.063757, loss_fp: 0.001950, loss_freq: 0.021992
[07:48:55.972] iteration 29873: loss: 0.072306, loss_s1: 0.065412, loss_fp: 0.004027, loss_freq: 0.048013
[07:48:56.562] iteration 29874: loss: 0.056314, loss_s1: 0.039781, loss_fp: 0.004953, loss_freq: 0.040989
[07:48:57.152] iteration 29875: loss: 0.054703, loss_s1: 0.042218, loss_fp: 0.010326, loss_freq: 0.025450
[07:48:57.750] iteration 29876: loss: 0.039974, loss_s1: 0.029942, loss_fp: 0.003995, loss_freq: 0.015432
[07:48:58.346] iteration 29877: loss: 0.064785, loss_s1: 0.061479, loss_fp: 0.005544, loss_freq: 0.040249
[07:48:58.940] iteration 29878: loss: 0.083824, loss_s1: 0.072913, loss_fp: 0.010381, loss_freq: 0.040648
[07:48:59.539] iteration 29879: loss: 0.072214, loss_s1: 0.044046, loss_fp: 0.012021, loss_freq: 0.062633
[07:49:00.135] iteration 29880: loss: 0.052606, loss_s1: 0.053236, loss_fp: 0.002920, loss_freq: 0.016369
[07:49:00.719] iteration 29881: loss: 0.066610, loss_s1: 0.049798, loss_fp: 0.022453, loss_freq: 0.037748
[07:49:01.305] iteration 29882: loss: 0.052193, loss_s1: 0.037166, loss_fp: 0.011436, loss_freq: 0.023376
[07:49:01.891] iteration 29883: loss: 0.068341, loss_s1: 0.062943, loss_fp: 0.004353, loss_freq: 0.025550
[07:49:02.480] iteration 29884: loss: 0.061900, loss_s1: 0.067364, loss_fp: 0.007934, loss_freq: 0.020062
[07:49:03.068] iteration 29885: loss: 0.101431, loss_s1: 0.137786, loss_fp: 0.009043, loss_freq: 0.018726
[07:49:03.656] iteration 29886: loss: 0.033703, loss_s1: 0.025983, loss_fp: 0.005530, loss_freq: 0.015025
[07:49:04.244] iteration 29887: loss: 0.053737, loss_s1: 0.040622, loss_fp: 0.003175, loss_freq: 0.026632
[07:49:04.831] iteration 29888: loss: 0.068540, loss_s1: 0.038590, loss_fp: 0.012101, loss_freq: 0.064498
[07:49:05.421] iteration 29889: loss: 0.092033, loss_s1: 0.072538, loss_fp: 0.003654, loss_freq: 0.078938
[07:49:06.013] iteration 29890: loss: 0.072378, loss_s1: 0.086776, loss_fp: 0.002818, loss_freq: 0.036826
[07:49:06.600] iteration 29891: loss: 0.065853, loss_s1: 0.056305, loss_fp: 0.003296, loss_freq: 0.042295
[07:49:07.186] iteration 29892: loss: 0.047924, loss_s1: 0.028948, loss_fp: 0.002213, loss_freq: 0.032133
[07:49:07.783] iteration 29893: loss: 0.057985, loss_s1: 0.070009, loss_fp: 0.006553, loss_freq: 0.014113
[07:49:08.376] iteration 29894: loss: 0.043568, loss_s1: 0.036127, loss_fp: 0.004134, loss_freq: 0.018764
[07:49:08.961] iteration 29895: loss: 0.038750, loss_s1: 0.034208, loss_fp: 0.004293, loss_freq: 0.008272
[07:49:09.551] iteration 29896: loss: 0.045777, loss_s1: 0.035993, loss_fp: 0.002232, loss_freq: 0.018174
[07:49:10.139] iteration 29897: loss: 0.048939, loss_s1: 0.045442, loss_fp: 0.003470, loss_freq: 0.018860
[07:49:10.731] iteration 29898: loss: 0.063806, loss_s1: 0.048662, loss_fp: 0.014456, loss_freq: 0.033597
[07:49:11.318] iteration 29899: loss: 0.078036, loss_s1: 0.056857, loss_fp: 0.005510, loss_freq: 0.074022
[07:49:11.908] iteration 29900: loss: 0.069052, loss_s1: 0.054029, loss_fp: 0.003260, loss_freq: 0.053673
[07:49:12.498] iteration 29901: loss: 0.060358, loss_s1: 0.050152, loss_fp: 0.013767, loss_freq: 0.025592
[07:49:13.090] iteration 29902: loss: 0.081705, loss_s1: 0.110624, loss_fp: 0.003196, loss_freq: 0.018185
[07:49:13.682] iteration 29903: loss: 0.070399, loss_s1: 0.065415, loss_fp: 0.006446, loss_freq: 0.043478
[07:49:14.275] iteration 29904: loss: 0.079643, loss_s1: 0.076714, loss_fp: 0.008501, loss_freq: 0.043781
[07:49:14.871] iteration 29905: loss: 0.069524, loss_s1: 0.068346, loss_fp: 0.006054, loss_freq: 0.036165
[07:49:15.462] iteration 29906: loss: 0.041109, loss_s1: 0.042081, loss_fp: 0.002625, loss_freq: 0.009315
[07:49:16.062] iteration 29907: loss: 0.024139, loss_s1: 0.018825, loss_fp: 0.002627, loss_freq: 0.006295
[07:49:16.657] iteration 29908: loss: 0.055234, loss_s1: 0.046984, loss_fp: 0.000931, loss_freq: 0.035447
[07:49:17.251] iteration 29909: loss: 0.068800, loss_s1: 0.041036, loss_fp: 0.006865, loss_freq: 0.059638
[07:49:17.842] iteration 29910: loss: 0.063217, loss_s1: 0.045891, loss_fp: 0.006182, loss_freq: 0.034408
[07:49:18.450] iteration 29911: loss: 0.044004, loss_s1: 0.046965, loss_fp: 0.002246, loss_freq: 0.011173
[07:49:19.045] iteration 29912: loss: 0.048587, loss_s1: 0.033148, loss_fp: 0.001560, loss_freq: 0.044154
[07:49:19.641] iteration 29913: loss: 0.027743, loss_s1: 0.014969, loss_fp: 0.001276, loss_freq: 0.004937
[07:49:20.236] iteration 29914: loss: 0.052298, loss_s1: 0.059580, loss_fp: 0.001118, loss_freq: 0.022870
[07:49:20.832] iteration 29915: loss: 0.031272, loss_s1: 0.017449, loss_fp: 0.001594, loss_freq: 0.012642
[07:49:21.420] iteration 29916: loss: 0.037436, loss_s1: 0.034319, loss_fp: 0.004224, loss_freq: 0.014589
[07:49:22.004] iteration 29917: loss: 0.051315, loss_s1: 0.060966, loss_fp: 0.002661, loss_freq: 0.009209
[07:49:22.589] iteration 29918: loss: 0.079331, loss_s1: 0.080235, loss_fp: 0.007307, loss_freq: 0.038188
[07:49:23.168] iteration 29919: loss: 0.083808, loss_s1: 0.093917, loss_fp: 0.005330, loss_freq: 0.046039
[07:49:23.749] iteration 29920: loss: 0.051138, loss_s1: 0.042834, loss_fp: 0.003708, loss_freq: 0.026277
[07:49:24.688] iteration 29921: loss: 0.093242, loss_s1: 0.069276, loss_fp: 0.002715, loss_freq: 0.044580
[07:49:25.323] iteration 29922: loss: 0.066159, loss_s1: 0.067307, loss_fp: 0.006103, loss_freq: 0.023263
[07:49:25.959] iteration 29923: loss: 0.054180, loss_s1: 0.057434, loss_fp: 0.003504, loss_freq: 0.021696
[07:49:26.562] iteration 29924: loss: 0.041187, loss_s1: 0.027257, loss_fp: 0.008970, loss_freq: 0.016636
[07:49:27.168] iteration 29925: loss: 0.065386, loss_s1: 0.069751, loss_fp: 0.011633, loss_freq: 0.024369
[07:49:27.769] iteration 29926: loss: 0.079584, loss_s1: 0.066069, loss_fp: 0.001922, loss_freq: 0.051211
[07:49:28.370] iteration 29927: loss: 0.042127, loss_s1: 0.034711, loss_fp: 0.001049, loss_freq: 0.020945
[07:49:28.951] iteration 29928: loss: 0.033412, loss_s1: 0.030247, loss_fp: 0.002705, loss_freq: 0.008802
[07:49:29.534] iteration 29929: loss: 0.028759, loss_s1: 0.022467, loss_fp: 0.004101, loss_freq: 0.010246
[07:49:30.114] iteration 29930: loss: 0.048300, loss_s1: 0.040810, loss_fp: 0.004494, loss_freq: 0.022386
[07:49:30.700] iteration 29931: loss: 0.060092, loss_s1: 0.055342, loss_fp: 0.001517, loss_freq: 0.029257
[07:49:31.292] iteration 29932: loss: 0.071140, loss_s1: 0.081259, loss_fp: 0.003769, loss_freq: 0.020806
[07:49:31.883] iteration 29933: loss: 0.048825, loss_s1: 0.044037, loss_fp: 0.002044, loss_freq: 0.023720
[07:49:32.480] iteration 29934: loss: 0.045611, loss_s1: 0.047156, loss_fp: 0.003993, loss_freq: 0.012998
[07:49:33.080] iteration 29935: loss: 0.085573, loss_s1: 0.103359, loss_fp: 0.002701, loss_freq: 0.028039
[07:49:33.679] iteration 29936: loss: 0.039352, loss_s1: 0.036489, loss_fp: 0.003727, loss_freq: 0.010253
[07:49:34.310] iteration 29937: loss: 0.120404, loss_s1: 0.109222, loss_fp: 0.003171, loss_freq: 0.108887
[07:49:34.946] iteration 29938: loss: 0.031503, loss_s1: 0.021537, loss_fp: 0.001865, loss_freq: 0.013022
[07:49:35.554] iteration 29939: loss: 0.079558, loss_s1: 0.096979, loss_fp: 0.004269, loss_freq: 0.030097
[07:49:36.141] iteration 29940: loss: 0.045066, loss_s1: 0.039584, loss_fp: 0.003422, loss_freq: 0.016199
[07:49:36.730] iteration 29941: loss: 0.034664, loss_s1: 0.011743, loss_fp: 0.004030, loss_freq: 0.019857
[07:49:37.321] iteration 29942: loss: 0.032528, loss_s1: 0.015883, loss_fp: 0.004320, loss_freq: 0.027507
[07:49:37.912] iteration 29943: loss: 0.058659, loss_s1: 0.051230, loss_fp: 0.008729, loss_freq: 0.018575
[07:49:38.512] iteration 29944: loss: 0.052982, loss_s1: 0.044132, loss_fp: 0.001814, loss_freq: 0.034936
[07:49:39.107] iteration 29945: loss: 0.045053, loss_s1: 0.035931, loss_fp: 0.003194, loss_freq: 0.024275
[07:49:39.697] iteration 29946: loss: 0.035211, loss_s1: 0.025103, loss_fp: 0.002697, loss_freq: 0.022361
[07:49:40.282] iteration 29947: loss: 0.050869, loss_s1: 0.048241, loss_fp: 0.003912, loss_freq: 0.015940
[07:49:40.868] iteration 29948: loss: 0.066741, loss_s1: 0.056931, loss_fp: 0.011418, loss_freq: 0.028448
[07:49:41.457] iteration 29949: loss: 0.047934, loss_s1: 0.034693, loss_fp: 0.002402, loss_freq: 0.024799
[07:49:42.043] iteration 29950: loss: 0.083803, loss_s1: 0.075148, loss_fp: 0.006330, loss_freq: 0.044792
[07:49:42.629] iteration 29951: loss: 0.060000, loss_s1: 0.043794, loss_fp: 0.008755, loss_freq: 0.048652
[07:49:43.232] iteration 29952: loss: 0.061814, loss_s1: 0.041583, loss_fp: 0.005708, loss_freq: 0.038111
[07:49:43.823] iteration 29953: loss: 0.040433, loss_s1: 0.031840, loss_fp: 0.007223, loss_freq: 0.017729
[07:49:44.423] iteration 29954: loss: 0.058828, loss_s1: 0.057726, loss_fp: 0.005747, loss_freq: 0.029980
[07:49:45.020] iteration 29955: loss: 0.065633, loss_s1: 0.082209, loss_fp: 0.002957, loss_freq: 0.025908
[07:49:45.618] iteration 29956: loss: 0.053730, loss_s1: 0.043764, loss_fp: 0.001990, loss_freq: 0.027482
[07:49:46.209] iteration 29957: loss: 0.073140, loss_s1: 0.044215, loss_fp: 0.001863, loss_freq: 0.064194
[07:49:46.794] iteration 29958: loss: 0.047103, loss_s1: 0.048645, loss_fp: 0.003289, loss_freq: 0.021205
[07:49:47.386] iteration 29959: loss: 0.079906, loss_s1: 0.090079, loss_fp: 0.010746, loss_freq: 0.027697
[07:49:47.969] iteration 29960: loss: 0.054083, loss_s1: 0.053764, loss_fp: 0.006554, loss_freq: 0.018139
[07:49:48.556] iteration 29961: loss: 0.051873, loss_s1: 0.066420, loss_fp: 0.002870, loss_freq: 0.008129
[07:49:49.140] iteration 29962: loss: 0.056934, loss_s1: 0.035584, loss_fp: 0.002444, loss_freq: 0.020807
[07:49:49.831] iteration 29963: loss: 0.077714, loss_s1: 0.077410, loss_fp: 0.006130, loss_freq: 0.048632
[07:49:50.481] iteration 29964: loss: 0.084313, loss_s1: 0.096230, loss_fp: 0.002048, loss_freq: 0.053420
[07:49:51.134] iteration 29965: loss: 0.050126, loss_s1: 0.035484, loss_fp: 0.004394, loss_freq: 0.025266
[07:49:51.778] iteration 29966: loss: 0.098681, loss_s1: 0.111999, loss_fp: 0.012320, loss_freq: 0.036597
[07:49:52.374] iteration 29967: loss: 0.033242, loss_s1: 0.018131, loss_fp: 0.002671, loss_freq: 0.017931
[07:49:52.966] iteration 29968: loss: 0.061097, loss_s1: 0.061125, loss_fp: 0.003197, loss_freq: 0.031754
[07:49:53.563] iteration 29969: loss: 0.045526, loss_s1: 0.049705, loss_fp: 0.004617, loss_freq: 0.006790
[07:49:54.156] iteration 29970: loss: 0.030134, loss_s1: 0.017305, loss_fp: 0.001287, loss_freq: 0.007405
[07:49:54.749] iteration 29971: loss: 0.046852, loss_s1: 0.028495, loss_fp: 0.003097, loss_freq: 0.033749
[07:49:55.346] iteration 29972: loss: 0.079534, loss_s1: 0.094536, loss_fp: 0.003908, loss_freq: 0.042539
[07:49:55.937] iteration 29973: loss: 0.050924, loss_s1: 0.034061, loss_fp: 0.004278, loss_freq: 0.026218
[07:49:56.526] iteration 29974: loss: 0.044656, loss_s1: 0.026383, loss_fp: 0.007351, loss_freq: 0.027706
[07:49:57.115] iteration 29975: loss: 0.044161, loss_s1: 0.027041, loss_fp: 0.006008, loss_freq: 0.016488
[07:49:57.710] iteration 29976: loss: 0.044322, loss_s1: 0.037655, loss_fp: 0.001957, loss_freq: 0.019938
[07:49:58.304] iteration 29977: loss: 0.040435, loss_s1: 0.042468, loss_fp: 0.003713, loss_freq: 0.015152
[07:49:58.904] iteration 29978: loss: 0.047024, loss_s1: 0.028249, loss_fp: 0.000930, loss_freq: 0.025028
[07:49:59.498] iteration 29979: loss: 0.046317, loss_s1: 0.030578, loss_fp: 0.004409, loss_freq: 0.030729
[07:50:00.095] iteration 29980: loss: 0.044115, loss_s1: 0.019476, loss_fp: 0.001735, loss_freq: 0.025762
[07:50:00.683] iteration 29981: loss: 0.020602, loss_s1: 0.011241, loss_fp: 0.001265, loss_freq: 0.009038
[07:50:01.269] iteration 29982: loss: 0.062233, loss_s1: 0.040554, loss_fp: 0.001428, loss_freq: 0.047879
[07:50:01.854] iteration 29983: loss: 0.041999, loss_s1: 0.040277, loss_fp: 0.003952, loss_freq: 0.006704
[07:50:02.440] iteration 29984: loss: 0.051164, loss_s1: 0.055523, loss_fp: 0.004375, loss_freq: 0.019868
[07:50:03.029] iteration 29985: loss: 0.027445, loss_s1: 0.014974, loss_fp: 0.002495, loss_freq: 0.007935
[07:50:03.621] iteration 29986: loss: 0.078118, loss_s1: 0.102124, loss_fp: 0.002636, loss_freq: 0.026636
[07:50:04.217] iteration 29987: loss: 0.039902, loss_s1: 0.039184, loss_fp: 0.000832, loss_freq: 0.007510
[07:50:04.875] iteration 29988: loss: 0.093210, loss_s1: 0.124929, loss_fp: 0.005262, loss_freq: 0.034059
[07:50:05.507] iteration 29989: loss: 0.036906, loss_s1: 0.027754, loss_fp: 0.001194, loss_freq: 0.019107
[07:50:06.139] iteration 29990: loss: 0.049320, loss_s1: 0.042188, loss_fp: 0.002426, loss_freq: 0.034048
[07:50:06.761] iteration 29991: loss: 0.059559, loss_s1: 0.043831, loss_fp: 0.006881, loss_freq: 0.034182
[07:50:07.348] iteration 29992: loss: 0.050045, loss_s1: 0.039165, loss_fp: 0.003816, loss_freq: 0.026961
[07:50:07.935] iteration 29993: loss: 0.079643, loss_s1: 0.078795, loss_fp: 0.018018, loss_freq: 0.034874
[07:50:08.523] iteration 29994: loss: 0.047940, loss_s1: 0.043211, loss_fp: 0.007145, loss_freq: 0.014481
[07:50:09.112] iteration 29995: loss: 0.050536, loss_s1: 0.024341, loss_fp: 0.001454, loss_freq: 0.049617
[07:50:09.698] iteration 29996: loss: 0.088095, loss_s1: 0.066333, loss_fp: 0.006815, loss_freq: 0.072838
[07:50:10.280] iteration 29997: loss: 0.051373, loss_s1: 0.048390, loss_fp: 0.004145, loss_freq: 0.022410
[07:50:10.861] iteration 29998: loss: 0.078044, loss_s1: 0.046437, loss_fp: 0.006097, loss_freq: 0.062534
[07:50:11.462] iteration 29999: loss: 0.032698, loss_s1: 0.022872, loss_fp: 0.002242, loss_freq: 0.020049
[07:50:12.049] iteration 30000: loss: 0.075767, loss_s1: 0.081999, loss_fp: 0.003912, loss_freq: 0.035302
[07:50:15.486] iteration 30000 : mean_dice : 0.746730
