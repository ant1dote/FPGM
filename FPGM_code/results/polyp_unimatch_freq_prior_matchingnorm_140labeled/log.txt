[14:30:46.317] Namespace(config='/home/wth/My_codes/SSL_MIS_Exps/Freq_adaptive_modulation/configs/kvasir.yaml', labeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/10%_labeled.txt', unlabeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/10%_unlabeled.txt', save_path='/home/wth/My_codes/SSL_MIS_Exps/models/KVASIR', seed=1337, deterministic=1, local_rank=0, port=None)
[14:30:49.922] iteration 1: loss: 0.777597, loss_s1: 0.088568, loss_fp: 0.175435, loss_freq: 0.069406
[14:30:50.619] iteration 2: loss: 1.348067, loss_s1: 0.502729, loss_fp: 0.499915, loss_freq: 0.507836
[14:30:51.247] iteration 3: loss: 1.278939, loss_s1: 0.512215, loss_fp: 0.502437, loss_freq: 0.508409
[14:30:51.877] iteration 4: loss: 1.225132, loss_s1: 0.504974, loss_fp: 0.500168, loss_freq: 0.502815
[14:30:52.516] iteration 5: loss: 1.185355, loss_s1: 0.508100, loss_fp: 0.501077, loss_freq: 0.507997
[14:30:53.161] iteration 6: loss: 1.152999, loss_s1: 0.506311, loss_fp: 0.502401, loss_freq: 0.502418
[14:30:53.786] iteration 7: loss: 1.117554, loss_s1: 0.502255, loss_fp: 0.501540, loss_freq: 0.503061
[14:30:54.409] iteration 8: loss: 1.086951, loss_s1: 0.501148, loss_fp: 0.501040, loss_freq: 0.501552
[14:30:55.034] iteration 9: loss: 1.068175, loss_s1: 0.500642, loss_fp: 0.501041, loss_freq: 0.501076
[14:30:55.653] iteration 10: loss: 1.109296, loss_s1: 0.501211, loss_fp: 0.501267, loss_freq: 0.501348
[14:30:56.303] iteration 11: loss: 1.082024, loss_s1: 0.500978, loss_fp: 0.501291, loss_freq: 0.501043
[14:30:56.929] iteration 12: loss: 1.096811, loss_s1: 0.501033, loss_fp: 0.500704, loss_freq: 0.501221
[14:30:57.551] iteration 13: loss: 1.013467, loss_s1: 0.501175, loss_fp: 0.500555, loss_freq: 0.500709
[14:30:58.174] iteration 14: loss: 1.035067, loss_s1: 0.500650, loss_fp: 0.500318, loss_freq: 0.501172
[14:30:58.796] iteration 15: loss: 0.991303, loss_s1: 0.501381, loss_fp: 0.500537, loss_freq: 0.500446
[14:30:59.427] iteration 16: loss: 1.036406, loss_s1: 0.501444, loss_fp: 0.500237, loss_freq: 0.501128
[14:31:00.058] iteration 17: loss: 1.138272, loss_s1: 0.501912, loss_fp: 0.500217, loss_freq: 0.500542
[14:31:00.682] iteration 18: loss: 1.052425, loss_s1: 0.501188, loss_fp: 0.500195, loss_freq: 0.500696
[14:31:01.311] iteration 19: loss: 1.115407, loss_s1: 0.500977, loss_fp: 0.500236, loss_freq: 0.500950
[14:31:01.943] iteration 20: loss: 1.083260, loss_s1: 0.500883, loss_fp: 0.500407, loss_freq: 0.500950
[14:31:02.568] iteration 21: loss: 1.091587, loss_s1: 0.502026, loss_fp: 0.500302, loss_freq: 0.500707
[14:31:03.198] iteration 22: loss: 1.090610, loss_s1: 0.500748, loss_fp: 0.500052, loss_freq: 0.500582
[14:31:03.825] iteration 23: loss: 1.108334, loss_s1: 0.500381, loss_fp: 0.500139, loss_freq: 0.500991
[14:31:04.469] iteration 24: loss: 1.046109, loss_s1: 0.500777, loss_fp: 0.500313, loss_freq: 0.500875
[14:31:05.097] iteration 25: loss: 1.094816, loss_s1: 0.501637, loss_fp: 0.500288, loss_freq: 0.501287
[14:31:05.723] iteration 26: loss: 1.059142, loss_s1: 0.500471, loss_fp: 0.500098, loss_freq: 0.501472
[14:31:06.362] iteration 27: loss: 1.106158, loss_s1: 0.500343, loss_fp: 0.500122, loss_freq: 0.500705
[14:31:06.989] iteration 28: loss: 1.072475, loss_s1: 0.500892, loss_fp: 0.500328, loss_freq: 0.500948
[14:31:07.611] iteration 29: loss: 1.066887, loss_s1: 0.500988, loss_fp: 0.500043, loss_freq: 0.501097
[14:31:08.222] iteration 30: loss: 1.076584, loss_s1: 0.500168, loss_fp: 0.500410, loss_freq: 0.500527
[14:31:08.857] iteration 31: loss: 1.032070, loss_s1: 0.500292, loss_fp: 0.500108, loss_freq: 0.500519
[14:31:09.488] iteration 32: loss: 0.998942, loss_s1: 0.500488, loss_fp: 0.500203, loss_freq: 0.500580
[14:31:10.110] iteration 33: loss: 1.035299, loss_s1: 0.500711, loss_fp: 0.500348, loss_freq: 0.500915
[14:31:10.789] iteration 34: loss: 1.048984, loss_s1: 0.501159, loss_fp: 0.500261, loss_freq: 0.500305
[14:31:11.439] iteration 35: loss: 1.075028, loss_s1: 0.501254, loss_fp: 0.500132, loss_freq: 0.500841
[14:31:12.067] iteration 36: loss: 1.082171, loss_s1: 0.500688, loss_fp: 0.500196, loss_freq: 0.500467
[14:31:12.690] iteration 37: loss: 1.068265, loss_s1: 0.502228, loss_fp: 0.500230, loss_freq: 0.502129
[14:31:13.316] iteration 38: loss: 1.064517, loss_s1: 0.501586, loss_fp: 0.500198, loss_freq: 0.501308
[14:31:13.938] iteration 39: loss: 1.053032, loss_s1: 0.504868, loss_fp: 0.500266, loss_freq: 0.503267
[14:31:14.562] iteration 40: loss: 1.105979, loss_s1: 0.501787, loss_fp: 0.500220, loss_freq: 0.501365
[14:31:15.185] iteration 41: loss: 1.058913, loss_s1: 0.502650, loss_fp: 0.500157, loss_freq: 0.500994
[14:31:15.809] iteration 42: loss: 1.055923, loss_s1: 0.502433, loss_fp: 0.500268, loss_freq: 0.501634
[14:31:16.434] iteration 43: loss: 1.073619, loss_s1: 0.502303, loss_fp: 0.500257, loss_freq: 0.502004
[14:31:17.056] iteration 44: loss: 1.022113, loss_s1: 0.501456, loss_fp: 0.500260, loss_freq: 0.501210
[14:31:17.677] iteration 45: loss: 1.138845, loss_s1: 0.502768, loss_fp: 0.500142, loss_freq: 0.503861
[14:31:18.315] iteration 46: loss: 1.077185, loss_s1: 0.502311, loss_fp: 0.500312, loss_freq: 0.502239
[14:31:18.956] iteration 47: loss: 1.085640, loss_s1: 0.503099, loss_fp: 0.500557, loss_freq: 0.501376
[14:31:19.585] iteration 48: loss: 1.007179, loss_s1: 0.500613, loss_fp: 0.500386, loss_freq: 0.502224
[14:31:20.217] iteration 49: loss: 1.033911, loss_s1: 0.504357, loss_fp: 0.500305, loss_freq: 0.501062
[14:31:20.846] iteration 50: loss: 1.002345, loss_s1: 0.500567, loss_fp: 0.500497, loss_freq: 0.500568
[14:31:21.474] iteration 51: loss: 1.039329, loss_s1: 0.501900, loss_fp: 0.500315, loss_freq: 0.500895
[14:31:22.105] iteration 52: loss: 1.087287, loss_s1: 0.500349, loss_fp: 0.500238, loss_freq: 0.500983
[14:31:22.731] iteration 53: loss: 1.041090, loss_s1: 0.500086, loss_fp: 0.500132, loss_freq: 0.500237
[14:31:23.352] iteration 54: loss: 1.083337, loss_s1: 0.500110, loss_fp: 0.500088, loss_freq: 0.500561
[14:31:23.979] iteration 55: loss: 1.084116, loss_s1: 0.500563, loss_fp: 0.500373, loss_freq: 0.500463
[14:31:24.605] iteration 56: loss: 1.091075, loss_s1: 0.500471, loss_fp: 0.500321, loss_freq: 0.500683
[14:31:25.230] iteration 57: loss: 1.068594, loss_s1: 0.500881, loss_fp: 0.500195, loss_freq: 0.500386
[14:31:25.854] iteration 58: loss: 1.093236, loss_s1: 0.500311, loss_fp: 0.500142, loss_freq: 0.500444
[14:31:26.481] iteration 59: loss: 1.011360, loss_s1: 0.500319, loss_fp: 0.500540, loss_freq: 0.500583
[14:31:27.108] iteration 60: loss: 1.080127, loss_s1: 0.500430, loss_fp: 0.500096, loss_freq: 0.500728
[14:31:27.732] iteration 61: loss: 1.029998, loss_s1: 0.500157, loss_fp: 0.500052, loss_freq: 0.500991
[14:31:28.359] iteration 62: loss: 1.088561, loss_s1: 0.502899, loss_fp: 0.500218, loss_freq: 0.500811
[14:31:28.981] iteration 63: loss: 1.065560, loss_s1: 0.501041, loss_fp: 0.500290, loss_freq: 0.500957
[14:31:29.605] iteration 64: loss: 1.068841, loss_s1: 0.502727, loss_fp: 0.500453, loss_freq: 0.501030
[14:31:30.228] iteration 65: loss: 1.066038, loss_s1: 0.500745, loss_fp: 0.500041, loss_freq: 0.500687
[14:31:30.844] iteration 66: loss: 0.995767, loss_s1: 0.501343, loss_fp: 0.500173, loss_freq: 0.500373
[14:31:31.457] iteration 67: loss: 0.982486, loss_s1: 0.500800, loss_fp: 0.500199, loss_freq: 0.501097
[14:31:32.075] iteration 68: loss: 1.043308, loss_s1: 0.500704, loss_fp: 0.500149, loss_freq: 0.501357
[14:31:32.696] iteration 69: loss: 1.042844, loss_s1: 0.501971, loss_fp: 0.500279, loss_freq: 0.500646
[14:31:33.323] iteration 70: loss: 1.063372, loss_s1: 0.500711, loss_fp: 0.500073, loss_freq: 0.501178
[14:31:33.945] iteration 71: loss: 1.070487, loss_s1: 0.502163, loss_fp: 0.500096, loss_freq: 0.500670
[14:31:34.572] iteration 72: loss: 1.058798, loss_s1: 0.501052, loss_fp: 0.500317, loss_freq: 0.500566
[14:31:35.194] iteration 73: loss: 1.055684, loss_s1: 0.501508, loss_fp: 0.500408, loss_freq: 0.501624
[14:31:35.817] iteration 74: loss: 1.041912, loss_s1: 0.502289, loss_fp: 0.500329, loss_freq: 0.501728
[14:31:36.444] iteration 75: loss: 1.100301, loss_s1: 0.503153, loss_fp: 0.500328, loss_freq: 0.501017
[14:31:37.062] iteration 76: loss: 1.066171, loss_s1: 0.500475, loss_fp: 0.500230, loss_freq: 0.501192
[14:31:37.683] iteration 77: loss: 1.049489, loss_s1: 0.501421, loss_fp: 0.500527, loss_freq: 0.501573
[14:31:38.301] iteration 78: loss: 1.062216, loss_s1: 0.502560, loss_fp: 0.500275, loss_freq: 0.501674
[14:31:38.917] iteration 79: loss: 1.021405, loss_s1: 0.502957, loss_fp: 0.500149, loss_freq: 0.500899
[14:31:39.538] iteration 80: loss: 1.121460, loss_s1: 0.501629, loss_fp: 0.500099, loss_freq: 0.501726
[14:31:40.164] iteration 81: loss: 1.076477, loss_s1: 0.502030, loss_fp: 0.500272, loss_freq: 0.501779
[14:31:40.787] iteration 82: loss: 1.088028, loss_s1: 0.501142, loss_fp: 0.500352, loss_freq: 0.500310
[14:31:41.410] iteration 83: loss: 1.003815, loss_s1: 0.502049, loss_fp: 0.500361, loss_freq: 0.502017
[14:31:42.038] iteration 84: loss: 1.026252, loss_s1: 0.500844, loss_fp: 0.500469, loss_freq: 0.501310
[14:31:42.656] iteration 85: loss: 1.002815, loss_s1: 0.500171, loss_fp: 0.500285, loss_freq: 0.500512
[14:31:43.272] iteration 86: loss: 1.039515, loss_s1: 0.501480, loss_fp: 0.500570, loss_freq: 0.500887
[14:31:43.889] iteration 87: loss: 1.074435, loss_s1: 0.501620, loss_fp: 0.500326, loss_freq: 0.500933
[14:31:44.508] iteration 88: loss: 1.037389, loss_s1: 0.500310, loss_fp: 0.500133, loss_freq: 0.500224
[14:31:45.132] iteration 89: loss: 1.087874, loss_s1: 0.501449, loss_fp: 0.500361, loss_freq: 0.500697
[14:31:45.756] iteration 90: loss: 1.048737, loss_s1: 0.502879, loss_fp: 0.500447, loss_freq: 0.500675
[14:31:46.381] iteration 91: loss: 1.087634, loss_s1: 0.501293, loss_fp: 0.500466, loss_freq: 0.500687
[14:31:47.009] iteration 92: loss: 1.066400, loss_s1: 0.500424, loss_fp: 0.500362, loss_freq: 0.500575
[14:31:47.630] iteration 93: loss: 1.089478, loss_s1: 0.501596, loss_fp: 0.500514, loss_freq: 0.500659
[14:31:48.300] iteration 94: loss: 1.011339, loss_s1: 0.500538, loss_fp: 0.500078, loss_freq: 0.500348
[14:31:48.938] iteration 95: loss: 1.074244, loss_s1: 0.500763, loss_fp: 0.500349, loss_freq: 0.500636
[14:31:49.554] iteration 96: loss: 1.020734, loss_s1: 0.500564, loss_fp: 0.500408, loss_freq: 0.500561
[14:31:50.175] iteration 97: loss: 1.081089, loss_s1: 0.500720, loss_fp: 0.500361, loss_freq: 0.500652
[14:31:50.792] iteration 98: loss: 1.067460, loss_s1: 0.501196, loss_fp: 0.500082, loss_freq: 0.502085
[14:31:51.413] iteration 99: loss: 1.055868, loss_s1: 0.501205, loss_fp: 0.500129, loss_freq: 0.501216
[14:31:52.035] iteration 100: loss: 1.061188, loss_s1: 0.500563, loss_fp: 0.500097, loss_freq: 0.500499
[14:31:52.663] iteration 101: loss: 1.010179, loss_s1: 0.500886, loss_fp: 0.500208, loss_freq: 0.500958
[14:31:53.279] iteration 102: loss: 0.985758, loss_s1: 0.500291, loss_fp: 0.500285, loss_freq: 0.500509
[14:31:53.895] iteration 103: loss: 1.046272, loss_s1: 0.500411, loss_fp: 0.500052, loss_freq: 0.500678
[14:31:54.522] iteration 104: loss: 1.040037, loss_s1: 0.500816, loss_fp: 0.500249, loss_freq: 0.501086
[14:31:55.152] iteration 105: loss: 1.063363, loss_s1: 0.502902, loss_fp: 0.500196, loss_freq: 0.500453
[14:31:55.775] iteration 106: loss: 1.078657, loss_s1: 0.500656, loss_fp: 0.501514, loss_freq: 0.500276
[14:31:56.399] iteration 107: loss: 1.057086, loss_s1: 0.502297, loss_fp: 0.500302, loss_freq: 0.500915
[14:31:57.026] iteration 108: loss: 1.053261, loss_s1: 0.500798, loss_fp: 0.500421, loss_freq: 0.501377
[14:31:57.647] iteration 109: loss: 1.040561, loss_s1: 0.502596, loss_fp: 0.500418, loss_freq: 0.501408
[14:31:58.276] iteration 110: loss: 1.122916, loss_s1: 0.502782, loss_fp: 0.500483, loss_freq: 0.501224
[14:31:58.895] iteration 111: loss: 1.040251, loss_s1: 0.501318, loss_fp: 0.500175, loss_freq: 0.501462
[14:31:59.518] iteration 112: loss: 1.031531, loss_s1: 0.500945, loss_fp: 0.500482, loss_freq: 0.501210
[14:32:00.137] iteration 113: loss: 1.051455, loss_s1: 0.501930, loss_fp: 0.500173, loss_freq: 0.501562
[14:32:00.763] iteration 114: loss: 1.022391, loss_s1: 0.501423, loss_fp: 0.500441, loss_freq: 0.500964
[14:32:01.392] iteration 115: loss: 1.118832, loss_s1: 0.503228, loss_fp: 0.500116, loss_freq: 0.500901
[14:32:02.020] iteration 116: loss: 1.075653, loss_s1: 0.502230, loss_fp: 0.500088, loss_freq: 0.501264
[14:32:02.646] iteration 117: loss: 1.072014, loss_s1: 0.500304, loss_fp: 0.500092, loss_freq: 0.500548
[14:32:03.271] iteration 118: loss: 0.994317, loss_s1: 0.500850, loss_fp: 0.500314, loss_freq: 0.500834
[14:32:03.891] iteration 119: loss: 1.019805, loss_s1: 0.501831, loss_fp: 0.500242, loss_freq: 0.500884
[14:32:04.519] iteration 120: loss: 1.008090, loss_s1: 0.502267, loss_fp: 0.500384, loss_freq: 0.501397
[14:32:05.153] iteration 121: loss: 1.052873, loss_s1: 0.502471, loss_fp: 0.500266, loss_freq: 0.501735
[14:32:05.787] iteration 122: loss: 1.075632, loss_s1: 0.500361, loss_fp: 0.500142, loss_freq: 0.500435
[14:32:06.414] iteration 123: loss: 1.028926, loss_s1: 0.500519, loss_fp: 0.500349, loss_freq: 0.500280
[14:32:07.068] iteration 124: loss: 1.087736, loss_s1: 0.501587, loss_fp: 0.500288, loss_freq: 0.501296
[14:32:07.703] iteration 125: loss: 1.037872, loss_s1: 0.500347, loss_fp: 0.500099, loss_freq: 0.500837
[14:32:08.337] iteration 126: loss: 1.068794, loss_s1: 0.501415, loss_fp: 0.500216, loss_freq: 0.501370
[14:32:08.989] iteration 127: loss: 1.068352, loss_s1: 0.501855, loss_fp: 0.500170, loss_freq: 0.500818
[14:32:09.649] iteration 128: loss: 1.116917, loss_s1: 0.501746, loss_fp: 0.500418, loss_freq: 0.500484
[14:32:10.301] iteration 129: loss: 1.003775, loss_s1: 0.500286, loss_fp: 0.500425, loss_freq: 0.500939
[14:32:10.958] iteration 130: loss: 1.076337, loss_s1: 0.502774, loss_fp: 0.500093, loss_freq: 0.502045
[14:32:11.572] iteration 131: loss: 1.018943, loss_s1: 0.500692, loss_fp: 0.500125, loss_freq: 0.500712
[14:32:12.186] iteration 132: loss: 1.094876, loss_s1: 0.501263, loss_fp: 0.500097, loss_freq: 0.501649
[14:32:12.848] iteration 133: loss: 1.067066, loss_s1: 0.501434, loss_fp: 0.500165, loss_freq: 0.500708
[14:32:13.465] iteration 134: loss: 1.052433, loss_s1: 0.501243, loss_fp: 0.500370, loss_freq: 0.501048
[14:32:14.077] iteration 135: loss: 1.071773, loss_s1: 0.500149, loss_fp: 0.500303, loss_freq: 0.500723
[14:32:14.689] iteration 136: loss: 1.004524, loss_s1: 0.501942, loss_fp: 0.500340, loss_freq: 0.500922
[14:32:15.311] iteration 137: loss: 0.992858, loss_s1: 0.500400, loss_fp: 0.500035, loss_freq: 0.500264
[14:32:15.934] iteration 138: loss: 1.053958, loss_s1: 0.502918, loss_fp: 0.500272, loss_freq: 0.500770
[14:32:16.544] iteration 139: loss: 1.038131, loss_s1: 0.500947, loss_fp: 0.500400, loss_freq: 0.500521
[14:32:17.156] iteration 140: loss: 1.065407, loss_s1: 0.500627, loss_fp: 0.500694, loss_freq: 0.500303
[14:32:17.778] iteration 141: loss: 1.068976, loss_s1: 0.501608, loss_fp: 0.500186, loss_freq: 0.500538
[14:32:18.390] iteration 142: loss: 1.058495, loss_s1: 0.500179, loss_fp: 0.500350, loss_freq: 0.500607
[14:32:19.002] iteration 143: loss: 1.057809, loss_s1: 0.500561, loss_fp: 0.500117, loss_freq: 0.500627
[14:32:19.622] iteration 144: loss: 1.040692, loss_s1: 0.500548, loss_fp: 0.500083, loss_freq: 0.500503
[14:32:20.243] iteration 145: loss: 1.100912, loss_s1: 0.500717, loss_fp: 0.500570, loss_freq: 0.501501
[14:32:20.865] iteration 146: loss: 1.040738, loss_s1: 0.500485, loss_fp: 0.500607, loss_freq: 0.500856
[14:32:21.491] iteration 147: loss: 1.037194, loss_s1: 0.501057, loss_fp: 0.500280, loss_freq: 0.500495
[14:32:22.115] iteration 148: loss: 1.058597, loss_s1: 0.500472, loss_fp: 0.500593, loss_freq: 0.501245
[14:32:22.730] iteration 149: loss: 1.027373, loss_s1: 0.500684, loss_fp: 0.500465, loss_freq: 0.501326
[14:32:23.390] iteration 150: loss: 1.117556, loss_s1: 0.502175, loss_fp: 0.500502, loss_freq: 0.501009
[14:32:24.044] iteration 151: loss: 1.072354, loss_s1: 0.501085, loss_fp: 0.500177, loss_freq: 0.501080
[14:32:24.730] iteration 152: loss: 1.073199, loss_s1: 0.500891, loss_fp: 0.500355, loss_freq: 0.500317
[14:32:25.458] iteration 153: loss: 0.989696, loss_s1: 0.500492, loss_fp: 0.500066, loss_freq: 0.500932
[14:32:26.123] iteration 154: loss: 1.016191, loss_s1: 0.500767, loss_fp: 0.500315, loss_freq: 0.500467
[14:32:26.791] iteration 155: loss: 1.002674, loss_s1: 0.500843, loss_fp: 0.500509, loss_freq: 0.500663
[14:32:27.445] iteration 156: loss: 1.025073, loss_s1: 0.500867, loss_fp: 0.500142, loss_freq: 0.500434
[14:32:28.063] iteration 157: loss: 1.067988, loss_s1: 0.501069, loss_fp: 0.500046, loss_freq: 0.500638
[14:32:28.687] iteration 158: loss: 1.027669, loss_s1: 0.502064, loss_fp: 0.500126, loss_freq: 0.500599
[14:32:29.308] iteration 159: loss: 1.094232, loss_s1: 0.500458, loss_fp: 0.500402, loss_freq: 0.500844
[14:32:29.930] iteration 160: loss: 1.016436, loss_s1: 0.501490, loss_fp: 0.500310, loss_freq: 0.500713
[14:32:30.546] iteration 161: loss: 1.070041, loss_s1: 0.501217, loss_fp: 0.500098, loss_freq: 0.501060
[14:32:31.507] iteration 162: loss: 1.076480, loss_s1: 0.500816, loss_fp: 0.500188, loss_freq: 0.500767
[14:32:32.129] iteration 163: loss: 1.038914, loss_s1: 0.506928, loss_fp: 0.500116, loss_freq: 0.500559
[14:32:32.748] iteration 164: loss: 1.030526, loss_s1: 0.501344, loss_fp: 0.500167, loss_freq: 0.501385
[14:32:33.374] iteration 165: loss: 1.053392, loss_s1: 0.506672, loss_fp: 0.500236, loss_freq: 0.501737
[14:32:33.999] iteration 166: loss: 1.098454, loss_s1: 0.503082, loss_fp: 0.500135, loss_freq: 0.500737
[14:32:34.627] iteration 167: loss: 1.045562, loss_s1: 0.500815, loss_fp: 0.500369, loss_freq: 0.500479
[14:32:35.282] iteration 168: loss: 1.018808, loss_s1: 0.501711, loss_fp: 0.500280, loss_freq: 0.500878
[14:32:35.901] iteration 169: loss: 1.065689, loss_s1: 0.501773, loss_fp: 0.500203, loss_freq: 0.500940
[14:32:36.527] iteration 170: loss: 1.019737, loss_s1: 0.501974, loss_fp: 0.500218, loss_freq: 0.500534
[14:32:37.146] iteration 171: loss: 1.120233, loss_s1: 0.505090, loss_fp: 0.500238, loss_freq: 0.501271
[14:32:37.771] iteration 172: loss: 1.073680, loss_s1: 0.502201, loss_fp: 0.500288, loss_freq: 0.501200
[14:32:38.394] iteration 173: loss: 1.067240, loss_s1: 0.502765, loss_fp: 0.500219, loss_freq: 0.501579
[14:32:39.012] iteration 174: loss: 0.990797, loss_s1: 0.502168, loss_fp: 0.500172, loss_freq: 0.500632
[14:32:39.633] iteration 175: loss: 1.003299, loss_s1: 0.500371, loss_fp: 0.500102, loss_freq: 0.500649
[14:32:40.263] iteration 176: loss: 0.992798, loss_s1: 0.503524, loss_fp: 0.500294, loss_freq: 0.500206
[14:32:40.897] iteration 177: loss: 1.041313, loss_s1: 0.502081, loss_fp: 0.500210, loss_freq: 0.500551
[14:32:41.516] iteration 178: loss: 1.092853, loss_s1: 0.501409, loss_fp: 0.500146, loss_freq: 0.500419
[14:32:42.136] iteration 179: loss: 1.037869, loss_s1: 0.500720, loss_fp: 0.500075, loss_freq: 0.500591
[14:32:42.757] iteration 180: loss: 1.077324, loss_s1: 0.500956, loss_fp: 0.500191, loss_freq: 0.500808
[14:32:43.370] iteration 181: loss: 1.068111, loss_s1: 0.500994, loss_fp: 0.500156, loss_freq: 0.501019
[14:32:43.991] iteration 182: loss: 1.064247, loss_s1: 0.500679, loss_fp: 0.500260, loss_freq: 0.500649
[14:32:44.618] iteration 183: loss: 1.066077, loss_s1: 0.501218, loss_fp: 0.500137, loss_freq: 0.500702
[14:32:45.250] iteration 184: loss: 1.072345, loss_s1: 0.503397, loss_fp: 0.500462, loss_freq: 0.500848
[14:32:45.876] iteration 185: loss: 1.000603, loss_s1: 0.500239, loss_fp: 0.500946, loss_freq: 0.500446
[14:32:46.496] iteration 186: loss: 1.073256, loss_s1: 0.503553, loss_fp: 0.500126, loss_freq: 0.500856
[14:32:47.115] iteration 187: loss: 1.012290, loss_s1: 0.500785, loss_fp: 0.500165, loss_freq: 0.500503
[14:32:47.731] iteration 188: loss: 1.084721, loss_s1: 0.500155, loss_fp: 0.500244, loss_freq: 0.500447
[14:32:48.352] iteration 189: loss: 1.071759, loss_s1: 0.501422, loss_fp: 0.500259, loss_freq: 0.501630
[14:32:48.972] iteration 190: loss: 1.047553, loss_s1: 0.500759, loss_fp: 0.500205, loss_freq: 0.500920
[14:32:49.589] iteration 191: loss: 1.058546, loss_s1: 0.502184, loss_fp: 0.500187, loss_freq: 0.500551
[14:32:50.207] iteration 192: loss: 1.001505, loss_s1: 0.501006, loss_fp: 0.500858, loss_freq: 0.500784
[14:32:50.827] iteration 193: loss: 0.985193, loss_s1: 0.501107, loss_fp: 0.500244, loss_freq: 0.500529
[14:32:51.450] iteration 194: loss: 1.037689, loss_s1: 0.502149, loss_fp: 0.500614, loss_freq: 0.501212
[14:32:52.070] iteration 195: loss: 1.028377, loss_s1: 0.501331, loss_fp: 0.500232, loss_freq: 0.500524
[14:32:52.687] iteration 196: loss: 1.048845, loss_s1: 0.500488, loss_fp: 0.500212, loss_freq: 0.500649
[14:32:53.306] iteration 197: loss: 1.067433, loss_s1: 0.500905, loss_fp: 0.500257, loss_freq: 0.500318
[14:32:53.925] iteration 198: loss: 1.034567, loss_s1: 0.500877, loss_fp: 0.500135, loss_freq: 0.501155
[14:32:54.541] iteration 199: loss: 1.044986, loss_s1: 0.504708, loss_fp: 0.500177, loss_freq: 0.501197
[14:32:55.161] iteration 200: loss: 1.037503, loss_s1: 0.503308, loss_fp: 0.500447, loss_freq: 0.501694
[14:32:57.064] iteration 200 : mean_dice : 0.000239
[14:32:57.689] iteration 201: loss: 1.097106, loss_s1: 0.500408, loss_fp: 0.500240, loss_freq: 0.500892
[14:32:58.308] iteration 202: loss: 1.031499, loss_s1: 0.501901, loss_fp: 0.500237, loss_freq: 0.500871
[14:32:58.925] iteration 203: loss: 1.031280, loss_s1: 0.501783, loss_fp: 0.500482, loss_freq: 0.500750
[14:32:59.541] iteration 204: loss: 1.037320, loss_s1: 0.501725, loss_fp: 0.500167, loss_freq: 0.500620
[14:33:00.153] iteration 205: loss: 1.013710, loss_s1: 0.501304, loss_fp: 0.500169, loss_freq: 0.500814
[14:33:00.772] iteration 206: loss: 1.108238, loss_s1: 0.501523, loss_fp: 0.500156, loss_freq: 0.502523
[14:33:01.392] iteration 207: loss: 1.079232, loss_s1: 0.503156, loss_fp: 0.500211, loss_freq: 0.501499
[14:33:02.013] iteration 208: loss: 1.056925, loss_s1: 0.500927, loss_fp: 0.500117, loss_freq: 0.500808
[14:33:02.642] iteration 209: loss: 0.982071, loss_s1: 0.502257, loss_fp: 0.500152, loss_freq: 0.501684
[14:33:03.283] iteration 210: loss: 1.022632, loss_s1: 0.502224, loss_fp: 0.500296, loss_freq: 0.500617
[14:33:03.904] iteration 211: loss: 0.989663, loss_s1: 0.501252, loss_fp: 0.500507, loss_freq: 0.500658
[14:33:04.524] iteration 212: loss: 1.020482, loss_s1: 0.501602, loss_fp: 0.500130, loss_freq: 0.501302
[14:33:05.145] iteration 213: loss: 1.080238, loss_s1: 0.502469, loss_fp: 0.500369, loss_freq: 0.501428
[14:33:05.764] iteration 214: loss: 1.025275, loss_s1: 0.504014, loss_fp: 0.500576, loss_freq: 0.500544
[14:33:06.381] iteration 215: loss: 1.077287, loss_s1: 0.502502, loss_fp: 0.500325, loss_freq: 0.500740
[14:33:07.004] iteration 216: loss: 1.048388, loss_s1: 0.500721, loss_fp: 0.500156, loss_freq: 0.500574
[14:33:07.628] iteration 217: loss: 1.054912, loss_s1: 0.500679, loss_fp: 0.500440, loss_freq: 0.501023
[14:33:08.251] iteration 218: loss: 1.058596, loss_s1: 0.502346, loss_fp: 0.500229, loss_freq: 0.500550
[14:33:08.872] iteration 219: loss: 1.053789, loss_s1: 0.502630, loss_fp: 0.500128, loss_freq: 0.500603
[14:33:09.494] iteration 220: loss: 0.997088, loss_s1: 0.502223, loss_fp: 0.500641, loss_freq: 0.500541
[14:33:10.112] iteration 221: loss: 1.055203, loss_s1: 0.502542, loss_fp: 0.500201, loss_freq: 0.500578
[14:33:10.735] iteration 222: loss: 1.007892, loss_s1: 0.501209, loss_fp: 0.500160, loss_freq: 0.501253
[14:33:11.362] iteration 223: loss: 1.082954, loss_s1: 0.501541, loss_fp: 0.500250, loss_freq: 0.500684
[14:33:11.988] iteration 224: loss: 1.055393, loss_s1: 0.502662, loss_fp: 0.500093, loss_freq: 0.500905
[14:33:12.608] iteration 225: loss: 1.054011, loss_s1: 0.501268, loss_fp: 0.500221, loss_freq: 0.501001
[14:33:13.227] iteration 226: loss: 1.050229, loss_s1: 0.501211, loss_fp: 0.500476, loss_freq: 0.500677
[14:33:13.848] iteration 227: loss: 0.998909, loss_s1: 0.502676, loss_fp: 0.500355, loss_freq: 0.500311
[14:33:14.473] iteration 228: loss: 0.984399, loss_s1: 0.501196, loss_fp: 0.500351, loss_freq: 0.501059
[14:33:15.095] iteration 229: loss: 1.019565, loss_s1: 0.501439, loss_fp: 0.500157, loss_freq: 0.501146
[14:33:15.717] iteration 230: loss: 1.021140, loss_s1: 0.501553, loss_fp: 0.500357, loss_freq: 0.500409
[14:33:16.336] iteration 231: loss: 1.059431, loss_s1: 0.501916, loss_fp: 0.500331, loss_freq: 0.500976
[14:33:16.956] iteration 232: loss: 1.060200, loss_s1: 0.501043, loss_fp: 0.500158, loss_freq: 0.500535
[14:33:17.582] iteration 233: loss: 1.040764, loss_s1: 0.502975, loss_fp: 0.500065, loss_freq: 0.500426
[14:33:18.200] iteration 234: loss: 1.040956, loss_s1: 0.502533, loss_fp: 0.500153, loss_freq: 0.501058
[14:33:18.823] iteration 235: loss: 1.022256, loss_s1: 0.503330, loss_fp: 0.500457, loss_freq: 0.501419
[14:33:19.441] iteration 236: loss: 1.085641, loss_s1: 0.501636, loss_fp: 0.500235, loss_freq: 0.501157
[14:33:20.063] iteration 237: loss: 1.031830, loss_s1: 0.501779, loss_fp: 0.500450, loss_freq: 0.500756
[14:33:20.689] iteration 238: loss: 1.049381, loss_s1: 0.503227, loss_fp: 0.500125, loss_freq: 0.501179
[14:33:21.308] iteration 239: loss: 1.032281, loss_s1: 0.503050, loss_fp: 0.500318, loss_freq: 0.501529
[14:33:21.929] iteration 240: loss: 1.014404, loss_s1: 0.503957, loss_fp: 0.500404, loss_freq: 0.501052
[14:33:22.555] iteration 241: loss: 1.100758, loss_s1: 0.502944, loss_fp: 0.500437, loss_freq: 0.502133
[14:33:23.179] iteration 242: loss: 1.094424, loss_s1: 0.503076, loss_fp: 0.500513, loss_freq: 0.502262
[14:33:23.802] iteration 243: loss: 1.065678, loss_s1: 0.502133, loss_fp: 0.500498, loss_freq: 0.500950
[14:33:24.430] iteration 244: loss: 0.984452, loss_s1: 0.505792, loss_fp: 0.500444, loss_freq: 0.502241
[14:33:25.057] iteration 245: loss: 1.018425, loss_s1: 0.503550, loss_fp: 0.500137, loss_freq: 0.501316
[14:33:25.677] iteration 246: loss: 0.972843, loss_s1: 0.506029, loss_fp: 0.500433, loss_freq: 0.500449
[14:33:26.296] iteration 247: loss: 1.024728, loss_s1: 0.503066, loss_fp: 0.500323, loss_freq: 0.501173
[14:33:26.922] iteration 248: loss: 1.079286, loss_s1: 0.500766, loss_fp: 0.501858, loss_freq: 0.500914
[14:33:27.540] iteration 249: loss: 1.017418, loss_s1: 0.502010, loss_fp: 0.500450, loss_freq: 0.500293
[14:33:28.157] iteration 250: loss: 1.079239, loss_s1: 0.502467, loss_fp: 0.500645, loss_freq: 0.500894
[14:33:28.780] iteration 251: loss: 1.062060, loss_s1: 0.503568, loss_fp: 0.500263, loss_freq: 0.500616
[14:33:29.401] iteration 252: loss: 1.069300, loss_s1: 0.503008, loss_fp: 0.500376, loss_freq: 0.500782
[14:33:30.024] iteration 253: loss: 1.052014, loss_s1: 0.502374, loss_fp: 0.500062, loss_freq: 0.500681
[14:33:30.644] iteration 254: loss: 1.063422, loss_s1: 0.501695, loss_fp: 0.500197, loss_freq: 0.500728
[14:33:31.265] iteration 255: loss: 0.992570, loss_s1: 0.501878, loss_fp: 0.500292, loss_freq: 0.500753
[14:33:31.886] iteration 256: loss: 1.045326, loss_s1: 0.504344, loss_fp: 0.500298, loss_freq: 0.500923
[14:33:32.510] iteration 257: loss: 0.999325, loss_s1: 0.504569, loss_fp: 0.500438, loss_freq: 0.500743
[14:33:33.135] iteration 258: loss: 1.088323, loss_s1: 0.506851, loss_fp: 0.500383, loss_freq: 0.501126
[14:33:33.757] iteration 259: loss: 1.055354, loss_s1: 0.506906, loss_fp: 0.500231, loss_freq: 0.502687
[14:33:34.381] iteration 260: loss: 1.056506, loss_s1: 0.505552, loss_fp: 0.500726, loss_freq: 0.501617
[14:33:35.006] iteration 261: loss: 1.052266, loss_s1: 0.505137, loss_fp: 0.500202, loss_freq: 0.501151
[14:33:35.633] iteration 262: loss: 0.988344, loss_s1: 0.504000, loss_fp: 0.500308, loss_freq: 0.501750
[14:33:36.259] iteration 263: loss: 0.988321, loss_s1: 0.505239, loss_fp: 0.500166, loss_freq: 0.500523
[14:33:36.884] iteration 264: loss: 1.020089, loss_s1: 0.503707, loss_fp: 0.500233, loss_freq: 0.500716
[14:33:37.505] iteration 265: loss: 1.025072, loss_s1: 0.502633, loss_fp: 0.500123, loss_freq: 0.501079
[14:33:38.127] iteration 266: loss: 1.059108, loss_s1: 0.501990, loss_fp: 0.500371, loss_freq: 0.500525
[14:33:38.746] iteration 267: loss: 1.061228, loss_s1: 0.500708, loss_fp: 0.500492, loss_freq: 0.500430
[14:33:39.365] iteration 268: loss: 1.042918, loss_s1: 0.502817, loss_fp: 0.501572, loss_freq: 0.501222
[14:33:39.986] iteration 269: loss: 1.058553, loss_s1: 0.501485, loss_fp: 0.500074, loss_freq: 0.501056
[14:33:40.607] iteration 270: loss: 1.026172, loss_s1: 0.502255, loss_fp: 0.500942, loss_freq: 0.501976
[14:33:41.222] iteration 271: loss: 1.081581, loss_s1: 0.502865, loss_fp: 0.500185, loss_freq: 0.500905
[14:33:41.835] iteration 272: loss: 1.015953, loss_s1: 0.501651, loss_fp: 0.500195, loss_freq: 0.501691
[14:33:42.453] iteration 273: loss: 1.001027, loss_s1: 0.503083, loss_fp: 0.500072, loss_freq: 0.501313
[14:33:43.065] iteration 274: loss: 1.050009, loss_s1: 0.502091, loss_fp: 0.500139, loss_freq: 0.501419
[14:33:43.684] iteration 275: loss: 0.999816, loss_s1: 0.502105, loss_fp: 0.500328, loss_freq: 0.501522
[14:33:44.309] iteration 276: loss: 1.088724, loss_s1: 0.502613, loss_fp: 0.500183, loss_freq: 0.500855
[14:33:44.932] iteration 277: loss: 1.076741, loss_s1: 0.504318, loss_fp: 0.500083, loss_freq: 0.501307
[14:33:45.554] iteration 278: loss: 1.020814, loss_s1: 0.502592, loss_fp: 0.500188, loss_freq: 0.500832
[14:33:46.171] iteration 279: loss: 0.972735, loss_s1: 0.504454, loss_fp: 0.500446, loss_freq: 0.500990
[14:33:46.789] iteration 280: loss: 1.032605, loss_s1: 0.504475, loss_fp: 0.500278, loss_freq: 0.501003
[14:33:47.411] iteration 281: loss: 0.986402, loss_s1: 0.506000, loss_fp: 0.500289, loss_freq: 0.501615
[14:33:48.034] iteration 282: loss: 1.008066, loss_s1: 0.502607, loss_fp: 0.500112, loss_freq: 0.502012
[14:33:48.648] iteration 283: loss: 1.085059, loss_s1: 0.503072, loss_fp: 0.500142, loss_freq: 0.500594
[14:33:49.269] iteration 284: loss: 1.015402, loss_s1: 0.501052, loss_fp: 0.500435, loss_freq: 0.502146
[14:33:49.888] iteration 285: loss: 1.066300, loss_s1: 0.500982, loss_fp: 0.500085, loss_freq: 0.501514
[14:33:50.508] iteration 286: loss: 1.058950, loss_s1: 0.501916, loss_fp: 0.500287, loss_freq: 0.501256
[14:33:51.125] iteration 287: loss: 1.058753, loss_s1: 0.501541, loss_fp: 0.500289, loss_freq: 0.501472
[14:33:51.741] iteration 288: loss: 1.017402, loss_s1: 0.503304, loss_fp: 0.500206, loss_freq: 0.502228
[14:33:52.356] iteration 289: loss: 1.069570, loss_s1: 0.504367, loss_fp: 0.500190, loss_freq: 0.500584
[14:33:52.973] iteration 290: loss: 0.997781, loss_s1: 0.503459, loss_fp: 0.500162, loss_freq: 0.502205
[14:33:53.592] iteration 291: loss: 1.013886, loss_s1: 0.502824, loss_fp: 0.500157, loss_freq: 0.502960
[14:33:54.215] iteration 292: loss: 0.967742, loss_s1: 0.501106, loss_fp: 0.500186, loss_freq: 0.500938
[14:33:54.835] iteration 293: loss: 1.087503, loss_s1: 0.502282, loss_fp: 0.500170, loss_freq: 0.502186
[14:33:55.455] iteration 294: loss: 1.038694, loss_s1: 0.503348, loss_fp: 0.500162, loss_freq: 0.500971
[14:33:56.073] iteration 295: loss: 1.055248, loss_s1: 0.505206, loss_fp: 0.500082, loss_freq: 0.501090
[14:33:56.690] iteration 296: loss: 1.052223, loss_s1: 0.503043, loss_fp: 0.500277, loss_freq: 0.501177
[14:33:57.309] iteration 297: loss: 0.991739, loss_s1: 0.503062, loss_fp: 0.500242, loss_freq: 0.501085
[14:33:57.930] iteration 298: loss: 0.982684, loss_s1: 0.503030, loss_fp: 0.500044, loss_freq: 0.500396
[14:33:58.547] iteration 299: loss: 0.991918, loss_s1: 0.502102, loss_fp: 0.500301, loss_freq: 0.500794
[14:33:59.167] iteration 300: loss: 0.994931, loss_s1: 0.500530, loss_fp: 0.500071, loss_freq: 0.500765
[14:33:59.790] iteration 301: loss: 1.061551, loss_s1: 0.500732, loss_fp: 0.500498, loss_freq: 0.500512
[14:34:00.408] iteration 302: loss: 1.032347, loss_s1: 0.501518, loss_fp: 0.500199, loss_freq: 0.501108
[14:34:01.025] iteration 303: loss: 1.037252, loss_s1: 0.503540, loss_fp: 0.500186, loss_freq: 0.501106
[14:34:01.643] iteration 304: loss: 1.065233, loss_s1: 0.502005, loss_fp: 0.500495, loss_freq: 0.500897
[14:34:02.261] iteration 305: loss: 1.010311, loss_s1: 0.503302, loss_fp: 0.500280, loss_freq: 0.501919
[14:34:02.888] iteration 306: loss: 1.049542, loss_s1: 0.503567, loss_fp: 0.500242, loss_freq: 0.502665
[14:34:03.506] iteration 307: loss: 1.017401, loss_s1: 0.501158, loss_fp: 0.500213, loss_freq: 0.501032
[14:34:04.128] iteration 308: loss: 0.990518, loss_s1: 0.501945, loss_fp: 0.500137, loss_freq: 0.500884
[14:34:04.760] iteration 309: loss: 1.035409, loss_s1: 0.500909, loss_fp: 0.500205, loss_freq: 0.500949
[14:34:05.391] iteration 310: loss: 0.995419, loss_s1: 0.501799, loss_fp: 0.500239, loss_freq: 0.501240
[14:34:06.017] iteration 311: loss: 1.074235, loss_s1: 0.502648, loss_fp: 0.500257, loss_freq: 0.501221
[14:34:06.641] iteration 312: loss: 1.066422, loss_s1: 0.503666, loss_fp: 0.500072, loss_freq: 0.501315
[14:34:07.264] iteration 313: loss: 1.044751, loss_s1: 0.507294, loss_fp: 0.500187, loss_freq: 0.500286
[14:34:07.888] iteration 314: loss: 0.960077, loss_s1: 0.505933, loss_fp: 0.500567, loss_freq: 0.502193
[14:34:08.507] iteration 315: loss: 1.037775, loss_s1: 0.503236, loss_fp: 0.500057, loss_freq: 0.500285
[14:34:09.123] iteration 316: loss: 0.979697, loss_s1: 0.502263, loss_fp: 0.500716, loss_freq: 0.500918
[14:34:09.738] iteration 317: loss: 1.000673, loss_s1: 0.502356, loss_fp: 0.500165, loss_freq: 0.500578
[14:34:10.356] iteration 318: loss: 1.078971, loss_s1: 0.505409, loss_fp: 0.500335, loss_freq: 0.501523
[14:34:10.972] iteration 319: loss: 1.013731, loss_s1: 0.503323, loss_fp: 0.500454, loss_freq: 0.500684
[14:34:11.590] iteration 320: loss: 1.080358, loss_s1: 0.503265, loss_fp: 0.500661, loss_freq: 0.501198
[14:34:12.204] iteration 321: loss: 1.008471, loss_s1: 0.501991, loss_fp: 0.500162, loss_freq: 0.500598
[14:34:12.817] iteration 322: loss: 1.024941, loss_s1: 0.501607, loss_fp: 0.500279, loss_freq: 0.501500
[14:34:13.768] iteration 323: loss: 1.040766, loss_s1: 0.501888, loss_fp: 0.500169, loss_freq: 0.501032
[14:34:14.391] iteration 324: loss: 1.026280, loss_s1: 0.504508, loss_fp: 0.500242, loss_freq: 0.500673
[14:34:15.021] iteration 325: loss: 1.007046, loss_s1: 0.504128, loss_fp: 0.500229, loss_freq: 0.501065
[14:34:15.636] iteration 326: loss: 1.013728, loss_s1: 0.504774, loss_fp: 0.500161, loss_freq: 0.502018
[14:34:16.252] iteration 327: loss: 1.060213, loss_s1: 0.502550, loss_fp: 0.500136, loss_freq: 0.500887
[14:34:16.871] iteration 328: loss: 1.018402, loss_s1: 0.503939, loss_fp: 0.500397, loss_freq: 0.501132
[14:34:17.493] iteration 329: loss: 0.979753, loss_s1: 0.503110, loss_fp: 0.500649, loss_freq: 0.501999
[14:34:18.111] iteration 330: loss: 1.006309, loss_s1: 0.502973, loss_fp: 0.500322, loss_freq: 0.501012
[14:34:18.727] iteration 331: loss: 0.982233, loss_s1: 0.503816, loss_fp: 0.500304, loss_freq: 0.501083
[14:34:19.349] iteration 332: loss: 1.045892, loss_s1: 0.504608, loss_fp: 0.500266, loss_freq: 0.502131
[14:34:19.971] iteration 333: loss: 1.055649, loss_s1: 0.504795, loss_fp: 0.500602, loss_freq: 0.501597
[14:34:20.596] iteration 334: loss: 0.981529, loss_s1: 0.505703, loss_fp: 0.500467, loss_freq: 0.503289
[14:34:21.218] iteration 335: loss: 0.921482, loss_s1: 0.503186, loss_fp: 0.501025, loss_freq: 0.501919
[14:34:21.841] iteration 336: loss: 1.007961, loss_s1: 0.504431, loss_fp: 0.502650, loss_freq: 0.502794
[14:34:22.461] iteration 337: loss: 0.930872, loss_s1: 0.505067, loss_fp: 0.500226, loss_freq: 0.501471
[14:34:23.084] iteration 338: loss: 0.979836, loss_s1: 0.503144, loss_fp: 0.500634, loss_freq: 0.502124
[14:34:23.702] iteration 339: loss: 1.093790, loss_s1: 0.503982, loss_fp: 0.500641, loss_freq: 0.500881
[14:34:24.325] iteration 340: loss: 0.998439, loss_s1: 0.502382, loss_fp: 0.500218, loss_freq: 0.500790
[14:34:24.950] iteration 341: loss: 1.089547, loss_s1: 0.502069, loss_fp: 0.500443, loss_freq: 0.501690
[14:34:25.571] iteration 342: loss: 1.041302, loss_s1: 0.502495, loss_fp: 0.500127, loss_freq: 0.501791
[14:34:26.193] iteration 343: loss: 1.045825, loss_s1: 0.504337, loss_fp: 0.500591, loss_freq: 0.503236
[14:34:26.819] iteration 344: loss: 1.001400, loss_s1: 0.503805, loss_fp: 0.500560, loss_freq: 0.502336
[14:34:27.441] iteration 345: loss: 1.013855, loss_s1: 0.505355, loss_fp: 0.500294, loss_freq: 0.502342
[14:34:28.062] iteration 346: loss: 0.981225, loss_s1: 0.505335, loss_fp: 0.500712, loss_freq: 0.501269
[14:34:28.688] iteration 347: loss: 1.007303, loss_s1: 0.508699, loss_fp: 0.500197, loss_freq: 0.501658
[14:34:29.316] iteration 348: loss: 0.946897, loss_s1: 0.503558, loss_fp: 0.500625, loss_freq: 0.500779
[14:34:29.939] iteration 349: loss: 1.077901, loss_s1: 0.505325, loss_fp: 0.500145, loss_freq: 0.501230
[14:34:30.561] iteration 350: loss: 1.026829, loss_s1: 0.506216, loss_fp: 0.500183, loss_freq: 0.503518
[14:34:31.218] iteration 351: loss: 1.040839, loss_s1: 0.502812, loss_fp: 0.500326, loss_freq: 0.502153
[14:34:31.908] iteration 352: loss: 1.010919, loss_s1: 0.508045, loss_fp: 0.500421, loss_freq: 0.501092
[14:34:32.523] iteration 353: loss: 0.957612, loss_s1: 0.501707, loss_fp: 0.500140, loss_freq: 0.501315
[14:34:33.141] iteration 354: loss: 0.977178, loss_s1: 0.505230, loss_fp: 0.500195, loss_freq: 0.501189
[14:34:33.762] iteration 355: loss: 0.983840, loss_s1: 0.504868, loss_fp: 0.500471, loss_freq: 0.502060
[14:34:34.384] iteration 356: loss: 0.993991, loss_s1: 0.503313, loss_fp: 0.500203, loss_freq: 0.502260
[14:34:35.002] iteration 357: loss: 1.044804, loss_s1: 0.505894, loss_fp: 0.500180, loss_freq: 0.501349
[14:34:35.619] iteration 358: loss: 1.033238, loss_s1: 0.502779, loss_fp: 0.500452, loss_freq: 0.500795
[14:34:36.238] iteration 359: loss: 1.007990, loss_s1: 0.503044, loss_fp: 0.500542, loss_freq: 0.502374
[14:34:36.854] iteration 360: loss: 1.013122, loss_s1: 0.501965, loss_fp: 0.500190, loss_freq: 0.501632
[14:34:37.479] iteration 361: loss: 1.005960, loss_s1: 0.505159, loss_fp: 0.500213, loss_freq: 0.502519
[14:34:38.101] iteration 362: loss: 1.036657, loss_s1: 0.506082, loss_fp: 0.500128, loss_freq: 0.502302
[14:34:38.717] iteration 363: loss: 0.992933, loss_s1: 0.501187, loss_fp: 0.500246, loss_freq: 0.502222
[14:34:39.345] iteration 364: loss: 0.998099, loss_s1: 0.504799, loss_fp: 0.500221, loss_freq: 0.500843
[14:34:39.966] iteration 365: loss: 0.991941, loss_s1: 0.505528, loss_fp: 0.500582, loss_freq: 0.501565
[14:34:40.586] iteration 366: loss: 0.968099, loss_s1: 0.503510, loss_fp: 0.500339, loss_freq: 0.501575
[14:34:41.210] iteration 367: loss: 1.064832, loss_s1: 0.505505, loss_fp: 0.500280, loss_freq: 0.505357
[14:34:41.830] iteration 368: loss: 1.068977, loss_s1: 0.505824, loss_fp: 0.500071, loss_freq: 0.503437
[14:34:42.445] iteration 369: loss: 1.008064, loss_s1: 0.504193, loss_fp: 0.500283, loss_freq: 0.502063
[14:34:43.070] iteration 370: loss: 0.933639, loss_s1: 0.505018, loss_fp: 0.500442, loss_freq: 0.503117
[14:34:43.693] iteration 371: loss: 1.028082, loss_s1: 0.504656, loss_fp: 0.500213, loss_freq: 0.501114
[14:34:44.317] iteration 372: loss: 0.955595, loss_s1: 0.503423, loss_fp: 0.500875, loss_freq: 0.501362
[14:34:44.939] iteration 373: loss: 0.979211, loss_s1: 0.503290, loss_fp: 0.500194, loss_freq: 0.500839
[14:34:45.557] iteration 374: loss: 1.091569, loss_s1: 0.503799, loss_fp: 0.500243, loss_freq: 0.500689
[14:34:46.180] iteration 375: loss: 0.992353, loss_s1: 0.504000, loss_fp: 0.500768, loss_freq: 0.501167
[14:34:46.795] iteration 376: loss: 1.087880, loss_s1: 0.502044, loss_fp: 0.500657, loss_freq: 0.502172
[14:34:47.426] iteration 377: loss: 1.021504, loss_s1: 0.503195, loss_fp: 0.500173, loss_freq: 0.501212
[14:34:48.051] iteration 378: loss: 1.018908, loss_s1: 0.505045, loss_fp: 0.500187, loss_freq: 0.502134
[14:34:48.681] iteration 379: loss: 1.008769, loss_s1: 0.504362, loss_fp: 0.500228, loss_freq: 0.501596
[14:34:49.300] iteration 380: loss: 1.010523, loss_s1: 0.504851, loss_fp: 0.500270, loss_freq: 0.501006
[14:34:49.923] iteration 381: loss: 0.991775, loss_s1: 0.501448, loss_fp: 0.500083, loss_freq: 0.501584
[14:34:50.566] iteration 382: loss: 0.995661, loss_s1: 0.500506, loss_fp: 0.500319, loss_freq: 0.501420
[14:34:51.185] iteration 383: loss: 0.950750, loss_s1: 0.504043, loss_fp: 0.500106, loss_freq: 0.500736
[14:34:51.809] iteration 384: loss: 1.065038, loss_s1: 0.505701, loss_fp: 0.500360, loss_freq: 0.500969
[14:34:52.429] iteration 385: loss: 0.999940, loss_s1: 0.504510, loss_fp: 0.500064, loss_freq: 0.501168
[14:34:53.052] iteration 386: loss: 1.048331, loss_s1: 0.503400, loss_fp: 0.500196, loss_freq: 0.501687
[14:34:53.677] iteration 387: loss: 1.012924, loss_s1: 0.501902, loss_fp: 0.500170, loss_freq: 0.500896
[14:34:54.303] iteration 388: loss: 0.973378, loss_s1: 0.502990, loss_fp: 0.500541, loss_freq: 0.500594
[14:34:54.928] iteration 389: loss: 0.986299, loss_s1: 0.505301, loss_fp: 0.500449, loss_freq: 0.502058
[14:34:55.552] iteration 390: loss: 0.960550, loss_s1: 0.501763, loss_fp: 0.500087, loss_freq: 0.500719
[14:34:56.178] iteration 391: loss: 0.976597, loss_s1: 0.503236, loss_fp: 0.500174, loss_freq: 0.501661
[14:34:56.803] iteration 392: loss: 1.031799, loss_s1: 0.502565, loss_fp: 0.500597, loss_freq: 0.501604
[14:34:57.425] iteration 393: loss: 1.009000, loss_s1: 0.501676, loss_fp: 0.500106, loss_freq: 0.501257
[14:34:58.049] iteration 394: loss: 1.006111, loss_s1: 0.502729, loss_fp: 0.500179, loss_freq: 0.501029
[14:34:58.674] iteration 395: loss: 1.017161, loss_s1: 0.503666, loss_fp: 0.500134, loss_freq: 0.502009
[14:34:59.294] iteration 396: loss: 0.989943, loss_s1: 0.506595, loss_fp: 0.500142, loss_freq: 0.502556
[14:34:59.915] iteration 397: loss: 1.039125, loss_s1: 0.502953, loss_fp: 0.500171, loss_freq: 0.503063
[14:35:00.539] iteration 398: loss: 0.996587, loss_s1: 0.505334, loss_fp: 0.500180, loss_freq: 0.502453
[14:35:01.163] iteration 399: loss: 1.031423, loss_s1: 0.503322, loss_fp: 0.500325, loss_freq: 0.501389
[14:35:01.786] iteration 400: loss: 0.976598, loss_s1: 0.504490, loss_fp: 0.500177, loss_freq: 0.501986
[14:35:03.796] iteration 400 : mean_dice : 0.004323
[14:35:04.462] iteration 401: loss: 0.968222, loss_s1: 0.505590, loss_fp: 0.500414, loss_freq: 0.501840
[14:35:05.099] iteration 402: loss: 1.030216, loss_s1: 0.504851, loss_fp: 0.500228, loss_freq: 0.504180
[14:35:05.739] iteration 403: loss: 1.044783, loss_s1: 0.505660, loss_fp: 0.500193, loss_freq: 0.503631
[14:35:06.376] iteration 404: loss: 0.982599, loss_s1: 0.503794, loss_fp: 0.500531, loss_freq: 0.502349
[14:35:07.002] iteration 405: loss: 0.935607, loss_s1: 0.504650, loss_fp: 0.500375, loss_freq: 0.506523
[14:35:07.627] iteration 406: loss: 1.024410, loss_s1: 0.503725, loss_fp: 0.500953, loss_freq: 0.503177
[14:35:08.241] iteration 407: loss: 0.926266, loss_s1: 0.505108, loss_fp: 0.500253, loss_freq: 0.501305
[14:35:08.861] iteration 408: loss: 0.990713, loss_s1: 0.502500, loss_fp: 0.500304, loss_freq: 0.501253
[14:35:09.479] iteration 409: loss: 1.077371, loss_s1: 0.503431, loss_fp: 0.500410, loss_freq: 0.501863
[14:35:10.098] iteration 410: loss: 1.013119, loss_s1: 0.503460, loss_fp: 0.500609, loss_freq: 0.501321
[14:35:10.717] iteration 411: loss: 1.078191, loss_s1: 0.504512, loss_fp: 0.500857, loss_freq: 0.500813
[14:35:11.333] iteration 412: loss: 1.029317, loss_s1: 0.503468, loss_fp: 0.500306, loss_freq: 0.500626
[14:35:11.950] iteration 413: loss: 1.065308, loss_s1: 0.503127, loss_fp: 0.500129, loss_freq: 0.500431
[14:35:12.569] iteration 414: loss: 1.003468, loss_s1: 0.502075, loss_fp: 0.500324, loss_freq: 0.500998
[14:35:13.187] iteration 415: loss: 1.038757, loss_s1: 0.502636, loss_fp: 0.500272, loss_freq: 0.500211
[14:35:13.806] iteration 416: loss: 0.969907, loss_s1: 0.502597, loss_fp: 0.500542, loss_freq: 0.500463
[14:35:14.426] iteration 417: loss: 0.984313, loss_s1: 0.502769, loss_fp: 0.500169, loss_freq: 0.500802
[14:35:15.045] iteration 418: loss: 0.951092, loss_s1: 0.503028, loss_fp: 0.500215, loss_freq: 0.500500
[14:35:15.659] iteration 419: loss: 1.045252, loss_s1: 0.504116, loss_fp: 0.500088, loss_freq: 0.501133
[14:35:16.280] iteration 420: loss: 1.025196, loss_s1: 0.508878, loss_fp: 0.500201, loss_freq: 0.502230
[14:35:16.899] iteration 421: loss: 1.047675, loss_s1: 0.505708, loss_fp: 0.500695, loss_freq: 0.501770
[14:35:17.519] iteration 422: loss: 1.006968, loss_s1: 0.501168, loss_fp: 0.500194, loss_freq: 0.501866
[14:35:18.140] iteration 423: loss: 0.931252, loss_s1: 0.502229, loss_fp: 0.500221, loss_freq: 0.501568
[14:35:18.759] iteration 424: loss: 0.951218, loss_s1: 0.501715, loss_fp: 0.500356, loss_freq: 0.500803
[14:35:19.376] iteration 425: loss: 0.970295, loss_s1: 0.503144, loss_fp: 0.500235, loss_freq: 0.501629
[14:35:19.994] iteration 426: loss: 0.982692, loss_s1: 0.504427, loss_fp: 0.500117, loss_freq: 0.502125
[14:35:20.611] iteration 427: loss: 1.079065, loss_s1: 0.503452, loss_fp: 0.503461, loss_freq: 0.504064
[14:35:21.231] iteration 428: loss: 1.007522, loss_s1: 0.505052, loss_fp: 0.500341, loss_freq: 0.502480
[14:35:21.846] iteration 429: loss: 0.966487, loss_s1: 0.503135, loss_fp: 0.500471, loss_freq: 0.502940
[14:35:22.465] iteration 430: loss: 1.028785, loss_s1: 0.505685, loss_fp: 0.500348, loss_freq: 0.503726
[14:35:23.081] iteration 431: loss: 1.005106, loss_s1: 0.507271, loss_fp: 0.500628, loss_freq: 0.506411
[14:35:23.699] iteration 432: loss: 1.026210, loss_s1: 0.504011, loss_fp: 0.502737, loss_freq: 0.503218
[14:35:24.320] iteration 433: loss: 0.988214, loss_s1: 0.503946, loss_fp: 0.500346, loss_freq: 0.504236
[14:35:24.942] iteration 434: loss: 0.944266, loss_s1: 0.506475, loss_fp: 0.500592, loss_freq: 0.503913
[14:35:25.563] iteration 435: loss: 1.032755, loss_s1: 0.505808, loss_fp: 0.500304, loss_freq: 0.505049
[14:35:26.183] iteration 436: loss: 0.933716, loss_s1: 0.504364, loss_fp: 0.500213, loss_freq: 0.502955
[14:35:26.804] iteration 437: loss: 1.042567, loss_s1: 0.503545, loss_fp: 0.500697, loss_freq: 0.501015
[14:35:27.423] iteration 438: loss: 1.031996, loss_s1: 0.506065, loss_fp: 0.500238, loss_freq: 0.502242
[14:35:28.044] iteration 439: loss: 1.015202, loss_s1: 0.506271, loss_fp: 0.500477, loss_freq: 0.501446
[14:35:28.669] iteration 440: loss: 0.911780, loss_s1: 0.504760, loss_fp: 0.500270, loss_freq: 0.500688
[14:35:29.289] iteration 441: loss: 0.987437, loss_s1: 0.504918, loss_fp: 0.500338, loss_freq: 0.502046
[14:35:29.906] iteration 442: loss: 0.933647, loss_s1: 0.505105, loss_fp: 0.500288, loss_freq: 0.504207
[14:35:30.520] iteration 443: loss: 0.966955, loss_s1: 0.506395, loss_fp: 0.500268, loss_freq: 0.503225
[14:35:31.137] iteration 444: loss: 1.062665, loss_s1: 0.504558, loss_fp: 0.500404, loss_freq: 0.503433
[14:35:31.754] iteration 445: loss: 0.994111, loss_s1: 0.506990, loss_fp: 0.501022, loss_freq: 0.504344
[14:35:32.372] iteration 446: loss: 1.013103, loss_s1: 0.506706, loss_fp: 0.500360, loss_freq: 0.503662
[14:35:32.994] iteration 447: loss: 1.029609, loss_s1: 0.504848, loss_fp: 0.500489, loss_freq: 0.501954
[14:35:33.615] iteration 448: loss: 1.058931, loss_s1: 0.504704, loss_fp: 0.501400, loss_freq: 0.503440
[14:35:34.231] iteration 449: loss: 0.985810, loss_s1: 0.504043, loss_fp: 0.500253, loss_freq: 0.501953
[14:35:34.851] iteration 450: loss: 1.027254, loss_s1: 0.505518, loss_fp: 0.500232, loss_freq: 0.501145
[14:35:35.471] iteration 451: loss: 0.978195, loss_s1: 0.504957, loss_fp: 0.500293, loss_freq: 0.502218
[14:35:36.092] iteration 452: loss: 0.979926, loss_s1: 0.504539, loss_fp: 0.500227, loss_freq: 0.502107
[14:35:36.715] iteration 453: loss: 0.934138, loss_s1: 0.503911, loss_fp: 0.500312, loss_freq: 0.501005
[14:35:37.338] iteration 454: loss: 1.062947, loss_s1: 0.503051, loss_fp: 0.500333, loss_freq: 0.502428
[14:35:37.962] iteration 455: loss: 0.992306, loss_s1: 0.502962, loss_fp: 0.500170, loss_freq: 0.501574
[14:35:38.588] iteration 456: loss: 1.011543, loss_s1: 0.504265, loss_fp: 0.500824, loss_freq: 0.501229
[14:35:39.225] iteration 457: loss: 1.008784, loss_s1: 0.503502, loss_fp: 0.500377, loss_freq: 0.500680
[14:35:39.847] iteration 458: loss: 0.960963, loss_s1: 0.506543, loss_fp: 0.500584, loss_freq: 0.501621
[14:35:40.473] iteration 459: loss: 0.990439, loss_s1: 0.505138, loss_fp: 0.500181, loss_freq: 0.500753
[14:35:41.096] iteration 460: loss: 0.970749, loss_s1: 0.503978, loss_fp: 0.500225, loss_freq: 0.500794
[14:35:41.719] iteration 461: loss: 0.973605, loss_s1: 0.501898, loss_fp: 0.500332, loss_freq: 0.501172
[14:35:42.343] iteration 462: loss: 1.034328, loss_s1: 0.503469, loss_fp: 0.500931, loss_freq: 0.501329
[14:35:43.002] iteration 463: loss: 1.009430, loss_s1: 0.504267, loss_fp: 0.501260, loss_freq: 0.501017
[14:35:43.632] iteration 464: loss: 0.996615, loss_s1: 0.506691, loss_fp: 0.500105, loss_freq: 0.501246
[14:35:44.277] iteration 465: loss: 1.006487, loss_s1: 0.501321, loss_fp: 0.500113, loss_freq: 0.500883
[14:35:44.909] iteration 466: loss: 0.987761, loss_s1: 0.502202, loss_fp: 0.500169, loss_freq: 0.502149
[14:35:45.545] iteration 467: loss: 1.009519, loss_s1: 0.504348, loss_fp: 0.500372, loss_freq: 0.502290
[14:35:46.174] iteration 468: loss: 0.986904, loss_s1: 0.502402, loss_fp: 0.500283, loss_freq: 0.502833
[14:35:46.808] iteration 469: loss: 1.017676, loss_s1: 0.503523, loss_fp: 0.500137, loss_freq: 0.500684
[14:35:47.440] iteration 470: loss: 0.978474, loss_s1: 0.505852, loss_fp: 0.500175, loss_freq: 0.502082
[14:35:48.071] iteration 471: loss: 0.944559, loss_s1: 0.503237, loss_fp: 0.500378, loss_freq: 0.504294
[14:35:48.696] iteration 472: loss: 1.006847, loss_s1: 0.507757, loss_fp: 0.500077, loss_freq: 0.502666
[14:35:49.322] iteration 473: loss: 1.035542, loss_s1: 0.507219, loss_fp: 0.500134, loss_freq: 0.502499
[14:35:49.946] iteration 474: loss: 0.979828, loss_s1: 0.503450, loss_fp: 0.500276, loss_freq: 0.500733
[14:35:50.570] iteration 475: loss: 0.900582, loss_s1: 0.506284, loss_fp: 0.500368, loss_freq: 0.503791
[14:35:51.196] iteration 476: loss: 0.983740, loss_s1: 0.504521, loss_fp: 0.500451, loss_freq: 0.501142
[14:35:51.820] iteration 477: loss: 0.976635, loss_s1: 0.509944, loss_fp: 0.500813, loss_freq: 0.503355
[14:35:52.446] iteration 478: loss: 0.956247, loss_s1: 0.503519, loss_fp: 0.500471, loss_freq: 0.503976
[14:35:53.073] iteration 479: loss: 1.058993, loss_s1: 0.505588, loss_fp: 0.500527, loss_freq: 0.503379
[14:35:53.699] iteration 480: loss: 1.013873, loss_s1: 0.509180, loss_fp: 0.500474, loss_freq: 0.503358
[14:35:54.328] iteration 481: loss: 1.029010, loss_s1: 0.506842, loss_fp: 0.500224, loss_freq: 0.502936
[14:35:54.949] iteration 482: loss: 0.974934, loss_s1: 0.503076, loss_fp: 0.500859, loss_freq: 0.502357
[14:35:55.572] iteration 483: loss: 1.008985, loss_s1: 0.506497, loss_fp: 0.500435, loss_freq: 0.504552
[14:35:56.497] iteration 484: loss: 0.999414, loss_s1: 0.504330, loss_fp: 0.500829, loss_freq: 0.501575
[14:35:57.120] iteration 485: loss: 0.935530, loss_s1: 0.505169, loss_fp: 0.500473, loss_freq: 0.504451
[14:35:57.740] iteration 486: loss: 0.966430, loss_s1: 0.503652, loss_fp: 0.500352, loss_freq: 0.502976
[14:35:58.367] iteration 487: loss: 0.967780, loss_s1: 0.504894, loss_fp: 0.500257, loss_freq: 0.503592
[14:35:58.995] iteration 488: loss: 1.030625, loss_s1: 0.506100, loss_fp: 0.500526, loss_freq: 0.502738
[14:35:59.614] iteration 489: loss: 0.993901, loss_s1: 0.504444, loss_fp: 0.500246, loss_freq: 0.501811
[14:36:00.237] iteration 490: loss: 0.936013, loss_s1: 0.503647, loss_fp: 0.500141, loss_freq: 0.501476
[14:36:00.855] iteration 491: loss: 0.962873, loss_s1: 0.502626, loss_fp: 0.500252, loss_freq: 0.501893
[14:36:01.474] iteration 492: loss: 0.927162, loss_s1: 0.504220, loss_fp: 0.500233, loss_freq: 0.501685
[14:36:02.096] iteration 493: loss: 1.003586, loss_s1: 0.504085, loss_fp: 0.500623, loss_freq: 0.502868
[14:36:02.718] iteration 494: loss: 1.045013, loss_s1: 0.505832, loss_fp: 0.500295, loss_freq: 0.502232
[14:36:03.337] iteration 495: loss: 0.988222, loss_s1: 0.508622, loss_fp: 0.500655, loss_freq: 0.503600
[14:36:03.958] iteration 496: loss: 0.903154, loss_s1: 0.503482, loss_fp: 0.500228, loss_freq: 0.501898
[14:36:04.572] iteration 497: loss: 1.003559, loss_s1: 0.504954, loss_fp: 0.500734, loss_freq: 0.501871
[14:36:05.193] iteration 498: loss: 0.932394, loss_s1: 0.506074, loss_fp: 0.500512, loss_freq: 0.501170
[14:36:05.814] iteration 499: loss: 0.950274, loss_s1: 0.504235, loss_fp: 0.500124, loss_freq: 0.501728
[14:36:06.437] iteration 500: loss: 1.065536, loss_s1: 0.504567, loss_fp: 0.500511, loss_freq: 0.501219
[14:36:07.060] iteration 501: loss: 0.962431, loss_s1: 0.502483, loss_fp: 0.500253, loss_freq: 0.500529
[14:36:07.684] iteration 502: loss: 1.018336, loss_s1: 0.502857, loss_fp: 0.500113, loss_freq: 0.500875
[14:36:08.305] iteration 503: loss: 1.006703, loss_s1: 0.502444, loss_fp: 0.500152, loss_freq: 0.501675
[14:36:08.931] iteration 504: loss: 1.016232, loss_s1: 0.503384, loss_fp: 0.500204, loss_freq: 0.503248
[14:36:09.555] iteration 505: loss: 0.969708, loss_s1: 0.503861, loss_fp: 0.500181, loss_freq: 0.502467
[14:36:10.176] iteration 506: loss: 0.999273, loss_s1: 0.504589, loss_fp: 0.500151, loss_freq: 0.503768
[14:36:10.795] iteration 507: loss: 0.970393, loss_s1: 0.501281, loss_fp: 0.500333, loss_freq: 0.501806
[14:36:11.421] iteration 508: loss: 0.957015, loss_s1: 0.508048, loss_fp: 0.500235, loss_freq: 0.502852
[14:36:12.043] iteration 509: loss: 0.907066, loss_s1: 0.503120, loss_fp: 0.500119, loss_freq: 0.501361
[14:36:12.663] iteration 510: loss: 1.032108, loss_s1: 0.502411, loss_fp: 0.500146, loss_freq: 0.502411
[14:36:13.284] iteration 511: loss: 0.985487, loss_s1: 0.507602, loss_fp: 0.500124, loss_freq: 0.505401
[14:36:13.904] iteration 512: loss: 0.998524, loss_s1: 0.505485, loss_fp: 0.500174, loss_freq: 0.503071
[14:36:14.527] iteration 513: loss: 0.984685, loss_s1: 0.504402, loss_fp: 0.500780, loss_freq: 0.501429
[14:36:15.151] iteration 514: loss: 0.923702, loss_s1: 0.502802, loss_fp: 0.500387, loss_freq: 0.502450
[14:36:15.770] iteration 515: loss: 0.987279, loss_s1: 0.507626, loss_fp: 0.500231, loss_freq: 0.503658
[14:36:16.387] iteration 516: loss: 0.943189, loss_s1: 0.507272, loss_fp: 0.500180, loss_freq: 0.504713
[14:36:17.013] iteration 517: loss: 0.981079, loss_s1: 0.505085, loss_fp: 0.500133, loss_freq: 0.503308
[14:36:17.639] iteration 518: loss: 1.050905, loss_s1: 0.503368, loss_fp: 0.500550, loss_freq: 0.502003
[14:36:18.258] iteration 519: loss: 0.967098, loss_s1: 0.504430, loss_fp: 0.500657, loss_freq: 0.501539
[14:36:18.878] iteration 520: loss: 0.970996, loss_s1: 0.505109, loss_fp: 0.500339, loss_freq: 0.505817
[14:36:19.504] iteration 521: loss: 0.987571, loss_s1: 0.505438, loss_fp: 0.500123, loss_freq: 0.504296
[14:36:20.124] iteration 522: loss: 0.981406, loss_s1: 0.506653, loss_fp: 0.500071, loss_freq: 0.502149
[14:36:20.743] iteration 523: loss: 1.021041, loss_s1: 0.504755, loss_fp: 0.500141, loss_freq: 0.502744
[14:36:21.364] iteration 524: loss: 0.969928, loss_s1: 0.502761, loss_fp: 0.500352, loss_freq: 0.502530
[14:36:21.982] iteration 525: loss: 0.989620, loss_s1: 0.505174, loss_fp: 0.500063, loss_freq: 0.501374
[14:36:22.598] iteration 526: loss: 1.011324, loss_s1: 0.507139, loss_fp: 0.500442, loss_freq: 0.502948
[14:36:23.224] iteration 527: loss: 0.941622, loss_s1: 0.504304, loss_fp: 0.500403, loss_freq: 0.503360
[14:36:23.844] iteration 528: loss: 1.037054, loss_s1: 0.508363, loss_fp: 0.500102, loss_freq: 0.503673
[14:36:24.466] iteration 529: loss: 1.044383, loss_s1: 0.504564, loss_fp: 0.500192, loss_freq: 0.504009
[14:36:25.085] iteration 530: loss: 0.963276, loss_s1: 0.504169, loss_fp: 0.500367, loss_freq: 0.502005
[14:36:25.697] iteration 531: loss: 0.890938, loss_s1: 0.504696, loss_fp: 0.500211, loss_freq: 0.502783
[14:36:26.322] iteration 532: loss: 1.013700, loss_s1: 0.503467, loss_fp: 0.500087, loss_freq: 0.501711
[14:36:26.943] iteration 533: loss: 0.911064, loss_s1: 0.505834, loss_fp: 0.500313, loss_freq: 0.502533
[14:36:27.563] iteration 534: loss: 0.962083, loss_s1: 0.505348, loss_fp: 0.500437, loss_freq: 0.502163
[14:36:28.187] iteration 535: loss: 1.051104, loss_s1: 0.501610, loss_fp: 0.500491, loss_freq: 0.501867
[14:36:28.805] iteration 536: loss: 0.932412, loss_s1: 0.504391, loss_fp: 0.500356, loss_freq: 0.501767
[14:36:29.421] iteration 537: loss: 1.020688, loss_s1: 0.502646, loss_fp: 0.500251, loss_freq: 0.502611
[14:36:30.054] iteration 538: loss: 0.939789, loss_s1: 0.504417, loss_fp: 0.501395, loss_freq: 0.501084
[14:36:30.675] iteration 539: loss: 1.007089, loss_s1: 0.505891, loss_fp: 0.500475, loss_freq: 0.502706
[14:36:31.303] iteration 540: loss: 0.989047, loss_s1: 0.503641, loss_fp: 0.500395, loss_freq: 0.501729
[14:36:31.932] iteration 541: loss: 0.990822, loss_s1: 0.504826, loss_fp: 0.500312, loss_freq: 0.502249
[14:36:32.554] iteration 542: loss: 0.962307, loss_s1: 0.505217, loss_fp: 0.500725, loss_freq: 0.501180
[14:36:33.177] iteration 543: loss: 0.955028, loss_s1: 0.501949, loss_fp: 0.500110, loss_freq: 0.501480
[14:36:33.801] iteration 544: loss: 0.918917, loss_s1: 0.503995, loss_fp: 0.500139, loss_freq: 0.501058
[14:36:34.435] iteration 545: loss: 1.011654, loss_s1: 0.508877, loss_fp: 0.500282, loss_freq: 0.501950
[14:36:35.065] iteration 546: loss: 1.000981, loss_s1: 0.502584, loss_fp: 0.500083, loss_freq: 0.501428
[14:36:35.969] iteration 547: loss: 1.028478, loss_s1: 0.503241, loss_fp: 0.500179, loss_freq: 0.502254
[14:36:36.811] iteration 548: loss: 0.949542, loss_s1: 0.501400, loss_fp: 0.500425, loss_freq: 0.501811
[14:36:37.430] iteration 549: loss: 0.922015, loss_s1: 0.505973, loss_fp: 0.500207, loss_freq: 0.501520
[14:36:38.050] iteration 550: loss: 0.945142, loss_s1: 0.501261, loss_fp: 0.500186, loss_freq: 0.503974
[14:36:38.663] iteration 551: loss: 0.916307, loss_s1: 0.504227, loss_fp: 0.500128, loss_freq: 0.500478
[14:36:39.334] iteration 552: loss: 0.959952, loss_s1: 0.504820, loss_fp: 0.500184, loss_freq: 0.502822
[14:36:39.959] iteration 553: loss: 1.008801, loss_s1: 0.505210, loss_fp: 0.500807, loss_freq: 0.502678
[14:36:40.583] iteration 554: loss: 1.004530, loss_s1: 0.501791, loss_fp: 0.500320, loss_freq: 0.501564
[14:36:41.199] iteration 555: loss: 0.959713, loss_s1: 0.503751, loss_fp: 0.500442, loss_freq: 0.500851
[14:36:41.822] iteration 556: loss: 0.989988, loss_s1: 0.501091, loss_fp: 0.500136, loss_freq: 0.503579
[14:36:42.447] iteration 557: loss: 0.970954, loss_s1: 0.505100, loss_fp: 0.500330, loss_freq: 0.502463
[14:36:43.073] iteration 558: loss: 1.001163, loss_s1: 0.505123, loss_fp: 0.500217, loss_freq: 0.503815
[14:36:43.698] iteration 559: loss: 0.948420, loss_s1: 0.504600, loss_fp: 0.500311, loss_freq: 0.501831
[14:36:44.322] iteration 560: loss: 0.986236, loss_s1: 0.505616, loss_fp: 0.500114, loss_freq: 0.501566
[14:36:44.947] iteration 561: loss: 0.947318, loss_s1: 0.502268, loss_fp: 0.500637, loss_freq: 0.503282
[14:36:45.570] iteration 562: loss: 0.929235, loss_s1: 0.505687, loss_fp: 0.500144, loss_freq: 0.501555
[14:36:46.195] iteration 563: loss: 1.012932, loss_s1: 0.507589, loss_fp: 0.500165, loss_freq: 0.503584
[14:36:46.824] iteration 564: loss: 1.020092, loss_s1: 0.504794, loss_fp: 0.500113, loss_freq: 0.503070
[14:36:47.451] iteration 565: loss: 0.950005, loss_s1: 0.504115, loss_fp: 0.500331, loss_freq: 0.502831
[14:36:48.079] iteration 566: loss: 0.897230, loss_s1: 0.505258, loss_fp: 0.500214, loss_freq: 0.506655
[14:36:48.703] iteration 567: loss: 0.937919, loss_s1: 0.506718, loss_fp: 0.500428, loss_freq: 0.503417
[14:36:49.328] iteration 568: loss: 0.933821, loss_s1: 0.506442, loss_fp: 0.500577, loss_freq: 0.503044
[14:36:49.950] iteration 569: loss: 0.947871, loss_s1: 0.503813, loss_fp: 0.500423, loss_freq: 0.502528
[14:36:50.568] iteration 570: loss: 1.079891, loss_s1: 0.503368, loss_fp: 0.500233, loss_freq: 0.501589
[14:36:51.191] iteration 571: loss: 0.955116, loss_s1: 0.506125, loss_fp: 0.500509, loss_freq: 0.501641
[14:36:51.815] iteration 572: loss: 0.988616, loss_s1: 0.503925, loss_fp: 0.500415, loss_freq: 0.502131
[14:36:52.442] iteration 573: loss: 0.981314, loss_s1: 0.502803, loss_fp: 0.500604, loss_freq: 0.501349
[14:36:53.061] iteration 574: loss: 1.048834, loss_s1: 0.502202, loss_fp: 0.500274, loss_freq: 0.501342
[14:36:53.679] iteration 575: loss: 0.971222, loss_s1: 0.504220, loss_fp: 0.500251, loss_freq: 0.501975
[14:36:54.305] iteration 576: loss: 1.026450, loss_s1: 0.503440, loss_fp: 0.500371, loss_freq: 0.501382
[14:36:54.929] iteration 577: loss: 0.953098, loss_s1: 0.504191, loss_fp: 0.500346, loss_freq: 0.500792
[14:36:55.547] iteration 578: loss: 0.937357, loss_s1: 0.503595, loss_fp: 0.500142, loss_freq: 0.502750
[14:36:56.172] iteration 579: loss: 0.903912, loss_s1: 0.502251, loss_fp: 0.500140, loss_freq: 0.501355
[14:36:56.797] iteration 580: loss: 1.010686, loss_s1: 0.502275, loss_fp: 0.500229, loss_freq: 0.501438
[14:36:57.422] iteration 581: loss: 0.973369, loss_s1: 0.502883, loss_fp: 0.500195, loss_freq: 0.502093
[14:36:58.047] iteration 582: loss: 0.996919, loss_s1: 0.504190, loss_fp: 0.500091, loss_freq: 0.502171
[14:36:58.666] iteration 583: loss: 0.952559, loss_s1: 0.501986, loss_fp: 0.500119, loss_freq: 0.501281
[14:36:59.290] iteration 584: loss: 0.901418, loss_s1: 0.505488, loss_fp: 0.500432, loss_freq: 0.502023
[14:36:59.913] iteration 585: loss: 0.941204, loss_s1: 0.503031, loss_fp: 0.500302, loss_freq: 0.501716
[14:37:00.537] iteration 586: loss: 0.928670, loss_s1: 0.502923, loss_fp: 0.500690, loss_freq: 0.502229
[14:37:01.161] iteration 587: loss: 0.937868, loss_s1: 0.503188, loss_fp: 0.500323, loss_freq: 0.501848
[14:37:01.783] iteration 588: loss: 1.041528, loss_s1: 0.504563, loss_fp: 0.500404, loss_freq: 0.504402
[14:37:02.407] iteration 589: loss: 0.978179, loss_s1: 0.505023, loss_fp: 0.500343, loss_freq: 0.501283
[14:37:03.032] iteration 590: loss: 0.918617, loss_s1: 0.504582, loss_fp: 0.500546, loss_freq: 0.503281
[14:37:03.658] iteration 591: loss: 1.020798, loss_s1: 0.502559, loss_fp: 0.500072, loss_freq: 0.502627
[14:37:04.285] iteration 592: loss: 0.966156, loss_s1: 0.504685, loss_fp: 0.500122, loss_freq: 0.504763
[14:37:04.906] iteration 593: loss: 1.009566, loss_s1: 0.505899, loss_fp: 0.500158, loss_freq: 0.502088
[14:37:05.528] iteration 594: loss: 0.939182, loss_s1: 0.504698, loss_fp: 0.500433, loss_freq: 0.504787
[14:37:06.149] iteration 595: loss: 0.906974, loss_s1: 0.505173, loss_fp: 0.500322, loss_freq: 0.503264
[14:37:06.776] iteration 596: loss: 0.977242, loss_s1: 0.505708, loss_fp: 0.500529, loss_freq: 0.504465
[14:37:07.400] iteration 597: loss: 0.906231, loss_s1: 0.505744, loss_fp: 0.500347, loss_freq: 0.502171
[14:37:08.025] iteration 598: loss: 0.994373, loss_s1: 0.503278, loss_fp: 0.500349, loss_freq: 0.501442
[14:37:08.647] iteration 599: loss: 1.046226, loss_s1: 0.504476, loss_fp: 0.500203, loss_freq: 0.503525
[14:37:09.270] iteration 600: loss: 0.937353, loss_s1: 0.505149, loss_fp: 0.500401, loss_freq: 0.501478
[14:37:11.411] iteration 600 : mean_dice : 0.034455
[14:37:12.074] iteration 601: loss: 0.898205, loss_s1: 0.505389, loss_fp: 0.500385, loss_freq: 0.501197
[14:37:12.697] iteration 602: loss: 0.978739, loss_s1: 0.509569, loss_fp: 0.500815, loss_freq: 0.502897
[14:37:13.327] iteration 603: loss: 0.924123, loss_s1: 0.503765, loss_fp: 0.500430, loss_freq: 0.503788
[14:37:13.952] iteration 604: loss: 0.938710, loss_s1: 0.505176, loss_fp: 0.501058, loss_freq: 0.502291
[14:37:14.579] iteration 605: loss: 1.002696, loss_s1: 0.504856, loss_fp: 0.500351, loss_freq: 0.501822
[14:37:15.202] iteration 606: loss: 0.947648, loss_s1: 0.503831, loss_fp: 0.500949, loss_freq: 0.502357
[14:37:15.824] iteration 607: loss: 0.972318, loss_s1: 0.503475, loss_fp: 0.500283, loss_freq: 0.501298
[14:37:16.447] iteration 608: loss: 0.994644, loss_s1: 0.502428, loss_fp: 0.500348, loss_freq: 0.501586
[14:37:17.067] iteration 609: loss: 1.043270, loss_s1: 0.501415, loss_fp: 0.500324, loss_freq: 0.502606
[14:37:17.692] iteration 610: loss: 0.954831, loss_s1: 0.504816, loss_fp: 0.500268, loss_freq: 0.501548
[14:37:18.309] iteration 611: loss: 1.019225, loss_s1: 0.501773, loss_fp: 0.500318, loss_freq: 0.500809
[14:37:18.940] iteration 612: loss: 0.941844, loss_s1: 0.504436, loss_fp: 0.500315, loss_freq: 0.501945
[14:37:19.573] iteration 613: loss: 0.929029, loss_s1: 0.504503, loss_fp: 0.500128, loss_freq: 0.501083
[14:37:20.203] iteration 614: loss: 0.908873, loss_s1: 0.501534, loss_fp: 0.500191, loss_freq: 0.501112
[14:37:20.849] iteration 615: loss: 1.002649, loss_s1: 0.504467, loss_fp: 0.500236, loss_freq: 0.502696
[14:37:21.476] iteration 616: loss: 0.956773, loss_s1: 0.506416, loss_fp: 0.500481, loss_freq: 0.502117
[14:37:22.093] iteration 617: loss: 0.965561, loss_s1: 0.505738, loss_fp: 0.500233, loss_freq: 0.501850
[14:37:22.712] iteration 618: loss: 0.997059, loss_s1: 0.506503, loss_fp: 0.500440, loss_freq: 0.501778
[14:37:23.331] iteration 619: loss: 0.897869, loss_s1: 0.507390, loss_fp: 0.500472, loss_freq: 0.502455
[14:37:23.957] iteration 620: loss: 0.974785, loss_s1: 0.504210, loss_fp: 0.500361, loss_freq: 0.504272
[14:37:24.578] iteration 621: loss: 0.931519, loss_s1: 0.505679, loss_fp: 0.500204, loss_freq: 0.501448
[14:37:25.202] iteration 622: loss: 0.981966, loss_s1: 0.505376, loss_fp: 0.500136, loss_freq: 0.502578
[14:37:25.823] iteration 623: loss: 0.986264, loss_s1: 0.509023, loss_fp: 0.500817, loss_freq: 0.503981
[14:37:26.447] iteration 624: loss: 0.987810, loss_s1: 0.503585, loss_fp: 0.500245, loss_freq: 0.502587
[14:37:27.067] iteration 625: loss: 0.926269, loss_s1: 0.504616, loss_fp: 0.500256, loss_freq: 0.501899
[14:37:27.690] iteration 626: loss: 1.007818, loss_s1: 0.505517, loss_fp: 0.500396, loss_freq: 0.502086
[14:37:28.310] iteration 627: loss: 0.986256, loss_s1: 0.506245, loss_fp: 0.500272, loss_freq: 0.504217
[14:37:28.929] iteration 628: loss: 0.978921, loss_s1: 0.504448, loss_fp: 0.500677, loss_freq: 0.503539
[14:37:29.552] iteration 629: loss: 0.940142, loss_s1: 0.503253, loss_fp: 0.500094, loss_freq: 0.502843
[14:37:30.173] iteration 630: loss: 1.002514, loss_s1: 0.503119, loss_fp: 0.500205, loss_freq: 0.502522
[14:37:30.794] iteration 631: loss: 0.945138, loss_s1: 0.503572, loss_fp: 0.500652, loss_freq: 0.501707
[14:37:31.414] iteration 632: loss: 0.908654, loss_s1: 0.504139, loss_fp: 0.500460, loss_freq: 0.505222
[14:37:32.028] iteration 633: loss: 0.997619, loss_s1: 0.504730, loss_fp: 0.500392, loss_freq: 0.502325
[14:37:32.652] iteration 634: loss: 1.036187, loss_s1: 0.506721, loss_fp: 0.500312, loss_freq: 0.503809
[14:37:33.278] iteration 635: loss: 0.965393, loss_s1: 0.506835, loss_fp: 0.500336, loss_freq: 0.500425
[14:37:33.901] iteration 636: loss: 0.891001, loss_s1: 0.504196, loss_fp: 0.500379, loss_freq: 0.502603
[14:37:34.531] iteration 637: loss: 0.971541, loss_s1: 0.508095, loss_fp: 0.500319, loss_freq: 0.501159
[14:37:35.153] iteration 638: loss: 0.914464, loss_s1: 0.504618, loss_fp: 0.500288, loss_freq: 0.501702
[14:37:35.773] iteration 639: loss: 0.942852, loss_s1: 0.502910, loss_fp: 0.500473, loss_freq: 0.503796
[14:37:36.392] iteration 640: loss: 1.019546, loss_s1: 0.508724, loss_fp: 0.500295, loss_freq: 0.502224
[14:37:37.010] iteration 641: loss: 0.993475, loss_s1: 0.512928, loss_fp: 0.500418, loss_freq: 0.502446
[14:37:37.634] iteration 642: loss: 1.014728, loss_s1: 0.504412, loss_fp: 0.500283, loss_freq: 0.502714
[14:37:38.250] iteration 643: loss: 0.951667, loss_s1: 0.505660, loss_fp: 0.500339, loss_freq: 0.502636
[14:37:38.866] iteration 644: loss: 0.978200, loss_s1: 0.505538, loss_fp: 0.500138, loss_freq: 0.504411
[14:37:39.814] iteration 645: loss: 0.970126, loss_s1: 0.504882, loss_fp: 0.500501, loss_freq: 0.501236
[14:37:40.437] iteration 646: loss: 0.916020, loss_s1: 0.507045, loss_fp: 0.500452, loss_freq: 0.502930
[14:37:41.055] iteration 647: loss: 0.936590, loss_s1: 0.504460, loss_fp: 0.500165, loss_freq: 0.502725
[14:37:41.680] iteration 648: loss: 0.949151, loss_s1: 0.506105, loss_fp: 0.500376, loss_freq: 0.504666
[14:37:42.305] iteration 649: loss: 1.004092, loss_s1: 0.503792, loss_fp: 0.500133, loss_freq: 0.501852
[14:37:42.929] iteration 650: loss: 0.948636, loss_s1: 0.504916, loss_fp: 0.500358, loss_freq: 0.501081
[14:37:43.547] iteration 651: loss: 0.941860, loss_s1: 0.506461, loss_fp: 0.500338, loss_freq: 0.501733
[14:37:44.164] iteration 652: loss: 0.946037, loss_s1: 0.509318, loss_fp: 0.500752, loss_freq: 0.501358
[14:37:44.788] iteration 653: loss: 0.900725, loss_s1: 0.506986, loss_fp: 0.500297, loss_freq: 0.501926
[14:37:45.404] iteration 654: loss: 0.971593, loss_s1: 0.505130, loss_fp: 0.500219, loss_freq: 0.505209
[14:37:46.023] iteration 655: loss: 1.023184, loss_s1: 0.503989, loss_fp: 0.500544, loss_freq: 0.502352
[14:37:46.645] iteration 656: loss: 0.945628, loss_s1: 0.509343, loss_fp: 0.500392, loss_freq: 0.503621
[14:37:47.269] iteration 657: loss: 0.857197, loss_s1: 0.503702, loss_fp: 0.500254, loss_freq: 0.503342
[14:37:47.893] iteration 658: loss: 0.935786, loss_s1: 0.507999, loss_fp: 0.500234, loss_freq: 0.504397
[14:37:48.512] iteration 659: loss: 0.899679, loss_s1: 0.505314, loss_fp: 0.500466, loss_freq: 0.501810
[14:37:49.131] iteration 660: loss: 0.917546, loss_s1: 0.505763, loss_fp: 0.500294, loss_freq: 0.503422
[14:37:49.752] iteration 661: loss: 1.047899, loss_s1: 0.503189, loss_fp: 0.500305, loss_freq: 0.500827
[14:37:50.374] iteration 662: loss: 0.910763, loss_s1: 0.503058, loss_fp: 0.500214, loss_freq: 0.501087
[14:37:50.991] iteration 663: loss: 0.986338, loss_s1: 0.503178, loss_fp: 0.500854, loss_freq: 0.501523
[14:37:51.616] iteration 664: loss: 0.953988, loss_s1: 0.505788, loss_fp: 0.500113, loss_freq: 0.503867
[14:37:52.241] iteration 665: loss: 0.969939, loss_s1: 0.506522, loss_fp: 0.500173, loss_freq: 0.502106
[14:37:52.863] iteration 666: loss: 0.963965, loss_s1: 0.506422, loss_fp: 0.500224, loss_freq: 0.502508
[14:37:53.483] iteration 667: loss: 0.984344, loss_s1: 0.506304, loss_fp: 0.500491, loss_freq: 0.503720
[14:37:54.104] iteration 668: loss: 0.939574, loss_s1: 0.509546, loss_fp: 0.500612, loss_freq: 0.502732
[14:37:54.729] iteration 669: loss: 0.940751, loss_s1: 0.510645, loss_fp: 0.500513, loss_freq: 0.502857
[14:37:55.355] iteration 670: loss: 0.907578, loss_s1: 0.505565, loss_fp: 0.500394, loss_freq: 0.501539
[14:37:55.982] iteration 671: loss: 0.987807, loss_s1: 0.507150, loss_fp: 0.500360, loss_freq: 0.501521
[14:37:56.604] iteration 672: loss: 0.947739, loss_s1: 0.507074, loss_fp: 0.500289, loss_freq: 0.505136
[14:37:57.227] iteration 673: loss: 0.995224, loss_s1: 0.502020, loss_fp: 0.500236, loss_freq: 0.501392
[14:37:57.845] iteration 674: loss: 0.932963, loss_s1: 0.505940, loss_fp: 0.500412, loss_freq: 0.503519
[14:37:58.466] iteration 675: loss: 0.918157, loss_s1: 0.506785, loss_fp: 0.500222, loss_freq: 0.502710
[14:37:59.091] iteration 676: loss: 0.953556, loss_s1: 0.504290, loss_fp: 0.500307, loss_freq: 0.504272
[14:37:59.716] iteration 677: loss: 0.923838, loss_s1: 0.502723, loss_fp: 0.500228, loss_freq: 0.503450
[14:38:00.339] iteration 678: loss: 0.983215, loss_s1: 0.501964, loss_fp: 0.500147, loss_freq: 0.502990
[14:38:00.965] iteration 679: loss: 1.019312, loss_s1: 0.502598, loss_fp: 0.500147, loss_freq: 0.502367
[14:38:01.589] iteration 680: loss: 0.945148, loss_s1: 0.505532, loss_fp: 0.500603, loss_freq: 0.501873
[14:38:02.207] iteration 681: loss: 0.928153, loss_s1: 0.506103, loss_fp: 0.500389, loss_freq: 0.506605
[14:38:02.826] iteration 682: loss: 0.994107, loss_s1: 0.505522, loss_fp: 0.500340, loss_freq: 0.503986
[14:38:03.447] iteration 683: loss: 1.009869, loss_s1: 0.504229, loss_fp: 0.500306, loss_freq: 0.501837
[14:38:04.071] iteration 684: loss: 0.990841, loss_s1: 0.505361, loss_fp: 0.500322, loss_freq: 0.503623
[14:38:04.690] iteration 685: loss: 0.969011, loss_s1: 0.503567, loss_fp: 0.500351, loss_freq: 0.502342
[14:38:05.309] iteration 686: loss: 0.947966, loss_s1: 0.506348, loss_fp: 0.500142, loss_freq: 0.501461
[14:38:05.936] iteration 687: loss: 0.933733, loss_s1: 0.506488, loss_fp: 0.500174, loss_freq: 0.501822
[14:38:06.559] iteration 688: loss: 0.919720, loss_s1: 0.504194, loss_fp: 0.500256, loss_freq: 0.501860
[14:38:07.188] iteration 689: loss: 1.045113, loss_s1: 0.506299, loss_fp: 0.500215, loss_freq: 0.505640
[14:38:07.814] iteration 690: loss: 1.006328, loss_s1: 0.508249, loss_fp: 0.500324, loss_freq: 0.503253
[14:38:08.444] iteration 691: loss: 0.981156, loss_s1: 0.501517, loss_fp: 0.500443, loss_freq: 0.503035
[14:38:09.074] iteration 692: loss: 0.872089, loss_s1: 0.507091, loss_fp: 0.500281, loss_freq: 0.502592
[14:38:09.698] iteration 693: loss: 0.967129, loss_s1: 0.506181, loss_fp: 0.500257, loss_freq: 0.501168
[14:38:10.323] iteration 694: loss: 0.938473, loss_s1: 0.506392, loss_fp: 0.500323, loss_freq: 0.502893
[14:38:10.956] iteration 695: loss: 0.943814, loss_s1: 0.504252, loss_fp: 0.500329, loss_freq: 0.502591
[14:38:11.577] iteration 696: loss: 1.051987, loss_s1: 0.507765, loss_fp: 0.500172, loss_freq: 0.501978
[14:38:12.203] iteration 697: loss: 0.928357, loss_s1: 0.503702, loss_fp: 0.500476, loss_freq: 0.502943
[14:38:12.831] iteration 698: loss: 0.974541, loss_s1: 0.504500, loss_fp: 0.500333, loss_freq: 0.503637
[14:38:13.451] iteration 699: loss: 0.925481, loss_s1: 0.505645, loss_fp: 0.500240, loss_freq: 0.501852
[14:38:14.077] iteration 700: loss: 0.994680, loss_s1: 0.508773, loss_fp: 0.500466, loss_freq: 0.504277
[14:38:14.699] iteration 701: loss: 0.955847, loss_s1: 0.507990, loss_fp: 0.500148, loss_freq: 0.502415
[14:38:15.321] iteration 702: loss: 0.975096, loss_s1: 0.504059, loss_fp: 0.500152, loss_freq: 0.501755
[14:38:15.948] iteration 703: loss: 0.960288, loss_s1: 0.503722, loss_fp: 0.500471, loss_freq: 0.501556
[14:38:16.573] iteration 704: loss: 0.919011, loss_s1: 0.503740, loss_fp: 0.500059, loss_freq: 0.500884
[14:38:17.200] iteration 705: loss: 0.919309, loss_s1: 0.506603, loss_fp: 0.500193, loss_freq: 0.501372
[14:38:17.825] iteration 706: loss: 0.989800, loss_s1: 0.506119, loss_fp: 0.500347, loss_freq: 0.502602
[14:38:18.451] iteration 707: loss: 0.931546, loss_s1: 0.504262, loss_fp: 0.500198, loss_freq: 0.501816
[14:38:19.077] iteration 708: loss: 0.968425, loss_s1: 0.506025, loss_fp: 0.500498, loss_freq: 0.502117
[14:38:19.706] iteration 709: loss: 0.945897, loss_s1: 0.502757, loss_fp: 0.500408, loss_freq: 0.502211
[14:38:20.332] iteration 710: loss: 0.901014, loss_s1: 0.506413, loss_fp: 0.500111, loss_freq: 0.501979
[14:38:20.957] iteration 711: loss: 0.959796, loss_s1: 0.506044, loss_fp: 0.500664, loss_freq: 0.504272
[14:38:21.580] iteration 712: loss: 0.908186, loss_s1: 0.502684, loss_fp: 0.500200, loss_freq: 0.500617
[14:38:22.205] iteration 713: loss: 0.930647, loss_s1: 0.505618, loss_fp: 0.500361, loss_freq: 0.502862
[14:38:22.820] iteration 714: loss: 0.962401, loss_s1: 0.504328, loss_fp: 0.500962, loss_freq: 0.502685
[14:38:23.441] iteration 715: loss: 0.974284, loss_s1: 0.503632, loss_fp: 0.500198, loss_freq: 0.501379
[14:38:24.071] iteration 716: loss: 0.927193, loss_s1: 0.505242, loss_fp: 0.500124, loss_freq: 0.501839
[14:38:24.701] iteration 717: loss: 0.972151, loss_s1: 0.502923, loss_fp: 0.500568, loss_freq: 0.503638
[14:38:25.332] iteration 718: loss: 0.957065, loss_s1: 0.506322, loss_fp: 0.500436, loss_freq: 0.504084
[14:38:25.990] iteration 719: loss: 0.972338, loss_s1: 0.507552, loss_fp: 0.500369, loss_freq: 0.504370
[14:38:26.625] iteration 720: loss: 0.920263, loss_s1: 0.506186, loss_fp: 0.500468, loss_freq: 0.503719
[14:38:27.260] iteration 721: loss: 0.951386, loss_s1: 0.505379, loss_fp: 0.500243, loss_freq: 0.503237
[14:38:27.889] iteration 722: loss: 0.961958, loss_s1: 0.505046, loss_fp: 0.500182, loss_freq: 0.503634
[14:38:28.523] iteration 723: loss: 0.902464, loss_s1: 0.505439, loss_fp: 0.500595, loss_freq: 0.503799
[14:38:29.155] iteration 724: loss: 0.965833, loss_s1: 0.506665, loss_fp: 0.500258, loss_freq: 0.505601
[14:38:29.789] iteration 725: loss: 0.983596, loss_s1: 0.507542, loss_fp: 0.500263, loss_freq: 0.505005
[14:38:30.422] iteration 726: loss: 0.959024, loss_s1: 0.503655, loss_fp: 0.500430, loss_freq: 0.502813
[14:38:31.053] iteration 727: loss: 0.910195, loss_s1: 0.504398, loss_fp: 0.500197, loss_freq: 0.507008
[14:38:31.678] iteration 728: loss: 0.955415, loss_s1: 0.505427, loss_fp: 0.500204, loss_freq: 0.503988
[14:38:32.304] iteration 729: loss: 0.881126, loss_s1: 0.502007, loss_fp: 0.500183, loss_freq: 0.503135
[14:38:32.926] iteration 730: loss: 0.939034, loss_s1: 0.505358, loss_fp: 0.500258, loss_freq: 0.504072
[14:38:33.555] iteration 731: loss: 1.049145, loss_s1: 0.505480, loss_fp: 0.500901, loss_freq: 0.503338
[14:38:34.176] iteration 732: loss: 0.923550, loss_s1: 0.505969, loss_fp: 0.500507, loss_freq: 0.502151
[14:38:34.793] iteration 733: loss: 0.972441, loss_s1: 0.502479, loss_fp: 0.500565, loss_freq: 0.503096
[14:38:35.416] iteration 734: loss: 0.916932, loss_s1: 0.502421, loss_fp: 0.500430, loss_freq: 0.501815
[14:38:36.036] iteration 735: loss: 1.011868, loss_s1: 0.503496, loss_fp: 0.500188, loss_freq: 0.501180
[14:38:36.661] iteration 736: loss: 0.925644, loss_s1: 0.505134, loss_fp: 0.500250, loss_freq: 0.501678
[14:38:37.286] iteration 737: loss: 1.002849, loss_s1: 0.505094, loss_fp: 0.500413, loss_freq: 0.501170
[14:38:37.955] iteration 738: loss: 0.914588, loss_s1: 0.503805, loss_fp: 0.500217, loss_freq: 0.500712
[14:38:38.568] iteration 739: loss: 0.919021, loss_s1: 0.502147, loss_fp: 0.500288, loss_freq: 0.502386
[14:38:39.196] iteration 740: loss: 0.881631, loss_s1: 0.504072, loss_fp: 0.500244, loss_freq: 0.501471
[14:38:39.908] iteration 741: loss: 0.947908, loss_s1: 0.504924, loss_fp: 0.500168, loss_freq: 0.502063
[14:38:40.539] iteration 742: loss: 0.943279, loss_s1: 0.505938, loss_fp: 0.500194, loss_freq: 0.503528
[14:38:41.163] iteration 743: loss: 0.951968, loss_s1: 0.504798, loss_fp: 0.500222, loss_freq: 0.502780
[14:38:41.788] iteration 744: loss: 0.912765, loss_s1: 0.501972, loss_fp: 0.500475, loss_freq: 0.501640
[14:38:42.412] iteration 745: loss: 0.895286, loss_s1: 0.502713, loss_fp: 0.500211, loss_freq: 0.501550
[14:38:43.028] iteration 746: loss: 0.962851, loss_s1: 0.505889, loss_fp: 0.500275, loss_freq: 0.502244
[14:38:43.693] iteration 747: loss: 0.917719, loss_s1: 0.506419, loss_fp: 0.500579, loss_freq: 0.503594
[14:38:44.318] iteration 748: loss: 0.952783, loss_s1: 0.503511, loss_fp: 0.500880, loss_freq: 0.502096
[14:38:44.965] iteration 749: loss: 0.987913, loss_s1: 0.502437, loss_fp: 0.500150, loss_freq: 0.504516
[14:38:45.589] iteration 750: loss: 0.959930, loss_s1: 0.504166, loss_fp: 0.500544, loss_freq: 0.501738
[14:38:46.209] iteration 751: loss: 0.899473, loss_s1: 0.506009, loss_fp: 0.500674, loss_freq: 0.501630
[14:38:46.833] iteration 752: loss: 0.943046, loss_s1: 0.504947, loss_fp: 0.500167, loss_freq: 0.501929
[14:38:47.456] iteration 753: loss: 0.961490, loss_s1: 0.505758, loss_fp: 0.500249, loss_freq: 0.504671
[14:38:48.083] iteration 754: loss: 0.986272, loss_s1: 0.505297, loss_fp: 0.500370, loss_freq: 0.501290
[14:38:48.709] iteration 755: loss: 0.944961, loss_s1: 0.505907, loss_fp: 0.500393, loss_freq: 0.503568
[14:38:49.336] iteration 756: loss: 0.910361, loss_s1: 0.505697, loss_fp: 0.500198, loss_freq: 0.502428
[14:38:49.962] iteration 757: loss: 0.943845, loss_s1: 0.504148, loss_fp: 0.500229, loss_freq: 0.503095
[14:38:50.591] iteration 758: loss: 0.907698, loss_s1: 0.502518, loss_fp: 0.500268, loss_freq: 0.503093
[14:38:51.247] iteration 759: loss: 0.965520, loss_s1: 0.504530, loss_fp: 0.500319, loss_freq: 0.500929
[14:38:51.868] iteration 760: loss: 0.998256, loss_s1: 0.505863, loss_fp: 0.500180, loss_freq: 0.502391
[14:38:52.496] iteration 761: loss: 0.944034, loss_s1: 0.503555, loss_fp: 0.500256, loss_freq: 0.500722
[14:38:53.127] iteration 762: loss: 0.850767, loss_s1: 0.503516, loss_fp: 0.500172, loss_freq: 0.501916
[14:38:53.753] iteration 763: loss: 0.915245, loss_s1: 0.508040, loss_fp: 0.500327, loss_freq: 0.502476
[14:38:54.374] iteration 764: loss: 0.910535, loss_s1: 0.506269, loss_fp: 0.500244, loss_freq: 0.505399
[14:38:54.999] iteration 765: loss: 0.876905, loss_s1: 0.503706, loss_fp: 0.500441, loss_freq: 0.502120
[14:38:55.617] iteration 766: loss: 1.022464, loss_s1: 0.505133, loss_fp: 0.500472, loss_freq: 0.505046
[14:38:56.240] iteration 767: loss: 0.955742, loss_s1: 0.506399, loss_fp: 0.500900, loss_freq: 0.505186
[14:38:56.864] iteration 768: loss: 0.975902, loss_s1: 0.505182, loss_fp: 0.500088, loss_freq: 0.502714
[14:38:57.484] iteration 769: loss: 0.927687, loss_s1: 0.505669, loss_fp: 0.500168, loss_freq: 0.502199
[14:38:58.108] iteration 770: loss: 0.992533, loss_s1: 0.503558, loss_fp: 0.500092, loss_freq: 0.504055
[14:38:58.731] iteration 771: loss: 0.901137, loss_s1: 0.504688, loss_fp: 0.500156, loss_freq: 0.502544
[14:38:59.353] iteration 772: loss: 0.974696, loss_s1: 0.503434, loss_fp: 0.500145, loss_freq: 0.501339
[14:38:59.971] iteration 773: loss: 0.902417, loss_s1: 0.503221, loss_fp: 0.500261, loss_freq: 0.503856
[14:39:00.590] iteration 774: loss: 0.932019, loss_s1: 0.502711, loss_fp: 0.500112, loss_freq: 0.501299
[14:39:01.213] iteration 775: loss: 0.886355, loss_s1: 0.505484, loss_fp: 0.500249, loss_freq: 0.501844
[14:39:01.830] iteration 776: loss: 0.976094, loss_s1: 0.505610, loss_fp: 0.500263, loss_freq: 0.503591
[14:39:02.450] iteration 777: loss: 0.956439, loss_s1: 0.503832, loss_fp: 0.500109, loss_freq: 0.501599
[14:39:03.077] iteration 778: loss: 0.974707, loss_s1: 0.506201, loss_fp: 0.500267, loss_freq: 0.502444
[14:39:03.694] iteration 779: loss: 0.944387, loss_s1: 0.508418, loss_fp: 0.500279, loss_freq: 0.503386
[14:39:04.316] iteration 780: loss: 0.880752, loss_s1: 0.507984, loss_fp: 0.500344, loss_freq: 0.503371
[14:39:04.938] iteration 781: loss: 0.941226, loss_s1: 0.504277, loss_fp: 0.500160, loss_freq: 0.506816
[14:39:05.556] iteration 782: loss: 0.879474, loss_s1: 0.503489, loss_fp: 0.500136, loss_freq: 0.502163
[14:39:06.179] iteration 783: loss: 0.917031, loss_s1: 0.503720, loss_fp: 0.500971, loss_freq: 0.502669
[14:39:06.801] iteration 784: loss: 1.046192, loss_s1: 0.506649, loss_fp: 0.500448, loss_freq: 0.504945
[14:39:07.419] iteration 785: loss: 0.946719, loss_s1: 0.503718, loss_fp: 0.500301, loss_freq: 0.502228
[14:39:08.042] iteration 786: loss: 0.900425, loss_s1: 0.502414, loss_fp: 0.500323, loss_freq: 0.503547
[14:39:08.663] iteration 787: loss: 1.008656, loss_s1: 0.501842, loss_fp: 0.500225, loss_freq: 0.502178
[14:39:09.281] iteration 788: loss: 0.961529, loss_s1: 0.503834, loss_fp: 0.500301, loss_freq: 0.503370
[14:39:09.900] iteration 789: loss: 0.935729, loss_s1: 0.505178, loss_fp: 0.500218, loss_freq: 0.504521
[14:39:10.518] iteration 790: loss: 0.965301, loss_s1: 0.500946, loss_fp: 0.500153, loss_freq: 0.502403
[14:39:11.139] iteration 791: loss: 0.915666, loss_s1: 0.504966, loss_fp: 0.500652, loss_freq: 0.501929
[14:39:11.764] iteration 792: loss: 0.948400, loss_s1: 0.504076, loss_fp: 0.500107, loss_freq: 0.501594
[14:39:12.383] iteration 793: loss: 0.931339, loss_s1: 0.504195, loss_fp: 0.500198, loss_freq: 0.505406
[14:39:13.011] iteration 794: loss: 0.974677, loss_s1: 0.503899, loss_fp: 0.500116, loss_freq: 0.501694
[14:39:13.633] iteration 795: loss: 0.997860, loss_s1: 0.505213, loss_fp: 0.500096, loss_freq: 0.503157
[14:39:14.251] iteration 796: loss: 0.954763, loss_s1: 0.504020, loss_fp: 0.500443, loss_freq: 0.500436
[14:39:14.874] iteration 797: loss: 0.871090, loss_s1: 0.506269, loss_fp: 0.500203, loss_freq: 0.503316
[14:39:15.500] iteration 798: loss: 0.944309, loss_s1: 0.503399, loss_fp: 0.500244, loss_freq: 0.501190
[14:39:16.116] iteration 799: loss: 0.931311, loss_s1: 0.503565, loss_fp: 0.500064, loss_freq: 0.502078
[14:39:16.737] iteration 800: loss: 0.905371, loss_s1: 0.505960, loss_fp: 0.500356, loss_freq: 0.503075
[14:39:19.055] iteration 800 : mean_dice : 0.062962
[14:39:19.692] iteration 801: loss: 1.019213, loss_s1: 0.505803, loss_fp: 0.500214, loss_freq: 0.502908
[14:39:20.314] iteration 802: loss: 0.937630, loss_s1: 0.503468, loss_fp: 0.500627, loss_freq: 0.502452
[14:39:20.937] iteration 803: loss: 0.913380, loss_s1: 0.503124, loss_fp: 0.500214, loss_freq: 0.501581
[14:39:21.557] iteration 804: loss: 0.910675, loss_s1: 0.501821, loss_fp: 0.500225, loss_freq: 0.502049
[14:39:22.174] iteration 805: loss: 0.958758, loss_s1: 0.502307, loss_fp: 0.500228, loss_freq: 0.503515
[14:39:23.166] iteration 806: loss: 0.905689, loss_s1: 0.503492, loss_fp: 0.500336, loss_freq: 0.501855
[14:39:23.813] iteration 807: loss: 0.916141, loss_s1: 0.507429, loss_fp: 0.500276, loss_freq: 0.502017
[14:39:24.461] iteration 808: loss: 0.926350, loss_s1: 0.503928, loss_fp: 0.500079, loss_freq: 0.501794
[14:39:25.113] iteration 809: loss: 0.950023, loss_s1: 0.502697, loss_fp: 0.500162, loss_freq: 0.502273
[14:39:25.758] iteration 810: loss: 1.017327, loss_s1: 0.503276, loss_fp: 0.500133, loss_freq: 0.502603
[14:39:26.402] iteration 811: loss: 0.955094, loss_s1: 0.505717, loss_fp: 0.500214, loss_freq: 0.501249
[14:39:27.040] iteration 812: loss: 0.900496, loss_s1: 0.505209, loss_fp: 0.500136, loss_freq: 0.504367
[14:39:27.681] iteration 813: loss: 0.897146, loss_s1: 0.506510, loss_fp: 0.500194, loss_freq: 0.501895
[14:39:28.322] iteration 814: loss: 0.872575, loss_s1: 0.501698, loss_fp: 0.500103, loss_freq: 0.501296
[14:39:28.957] iteration 815: loss: 0.944632, loss_s1: 0.506687, loss_fp: 0.500395, loss_freq: 0.504330
[14:39:29.646] iteration 816: loss: 0.995677, loss_s1: 0.503033, loss_fp: 0.500208, loss_freq: 0.502589
[14:39:30.308] iteration 817: loss: 0.932939, loss_s1: 0.505326, loss_fp: 0.500142, loss_freq: 0.503345
[14:39:30.934] iteration 818: loss: 0.877376, loss_s1: 0.501844, loss_fp: 0.500334, loss_freq: 0.502393
[14:39:31.567] iteration 819: loss: 0.929079, loss_s1: 0.504432, loss_fp: 0.500125, loss_freq: 0.503983
[14:39:32.195] iteration 820: loss: 0.874445, loss_s1: 0.506341, loss_fp: 0.500247, loss_freq: 0.501620
[14:39:32.823] iteration 821: loss: 0.925632, loss_s1: 0.503152, loss_fp: 0.500251, loss_freq: 0.504793
[14:39:33.446] iteration 822: loss: 0.998703, loss_s1: 0.503282, loss_fp: 0.500105, loss_freq: 0.501134
[14:39:34.075] iteration 823: loss: 0.886951, loss_s1: 0.502927, loss_fp: 0.500166, loss_freq: 0.501727
[14:39:34.703] iteration 824: loss: 0.938219, loss_s1: 0.502914, loss_fp: 0.500190, loss_freq: 0.501933
[14:39:35.337] iteration 825: loss: 0.917335, loss_s1: 0.503289, loss_fp: 0.500267, loss_freq: 0.502751
[14:39:35.969] iteration 826: loss: 0.935919, loss_s1: 0.506643, loss_fp: 0.500204, loss_freq: 0.502715
[14:39:36.596] iteration 827: loss: 0.931973, loss_s1: 0.504837, loss_fp: 0.500128, loss_freq: 0.502857
[14:39:37.222] iteration 828: loss: 0.982368, loss_s1: 0.505685, loss_fp: 0.500103, loss_freq: 0.503127
[14:39:37.850] iteration 829: loss: 0.889657, loss_s1: 0.507373, loss_fp: 0.500728, loss_freq: 0.504421
[14:39:38.473] iteration 830: loss: 0.942056, loss_s1: 0.507429, loss_fp: 0.500264, loss_freq: 0.504241
[14:39:39.099] iteration 831: loss: 0.862367, loss_s1: 0.501902, loss_fp: 0.500123, loss_freq: 0.501636
[14:39:39.726] iteration 832: loss: 0.997019, loss_s1: 0.507813, loss_fp: 0.500383, loss_freq: 0.502269
[14:39:40.354] iteration 833: loss: 0.961912, loss_s1: 0.507767, loss_fp: 0.500441, loss_freq: 0.507285
[14:39:40.973] iteration 834: loss: 0.991134, loss_s1: 0.506569, loss_fp: 0.500259, loss_freq: 0.502204
[14:39:41.601] iteration 835: loss: 0.942138, loss_s1: 0.506225, loss_fp: 0.500525, loss_freq: 0.504075
[14:39:42.224] iteration 836: loss: 0.885562, loss_s1: 0.504574, loss_fp: 0.500195, loss_freq: 0.502880
[14:39:42.848] iteration 837: loss: 0.910871, loss_s1: 0.505979, loss_fp: 0.500115, loss_freq: 0.502770
[14:39:43.470] iteration 838: loss: 0.894928, loss_s1: 0.505738, loss_fp: 0.500849, loss_freq: 0.504125
[14:39:44.104] iteration 839: loss: 0.930877, loss_s1: 0.504383, loss_fp: 0.500113, loss_freq: 0.503113
[14:39:44.727] iteration 840: loss: 1.011244, loss_s1: 0.503987, loss_fp: 0.500172, loss_freq: 0.502486
[14:39:45.357] iteration 841: loss: 0.909920, loss_s1: 0.505272, loss_fp: 0.500921, loss_freq: 0.501171
[14:39:45.982] iteration 842: loss: 0.901403, loss_s1: 0.508935, loss_fp: 0.500449, loss_freq: 0.504600
[14:39:46.606] iteration 843: loss: 0.934055, loss_s1: 0.503613, loss_fp: 0.500248, loss_freq: 0.504609
[14:39:47.229] iteration 844: loss: 0.961567, loss_s1: 0.506657, loss_fp: 0.500147, loss_freq: 0.500923
[14:39:47.854] iteration 845: loss: 0.937751, loss_s1: 0.505885, loss_fp: 0.500232, loss_freq: 0.503300
[14:39:48.473] iteration 846: loss: 0.907513, loss_s1: 0.503069, loss_fp: 0.500502, loss_freq: 0.502113
[14:39:49.113] iteration 847: loss: 0.911928, loss_s1: 0.508283, loss_fp: 0.500065, loss_freq: 0.501470
[14:39:49.748] iteration 848: loss: 0.923365, loss_s1: 0.503460, loss_fp: 0.500226, loss_freq: 0.501885
[14:39:50.388] iteration 849: loss: 0.897722, loss_s1: 0.502149, loss_fp: 0.500178, loss_freq: 0.502068
[14:39:51.029] iteration 850: loss: 0.958244, loss_s1: 0.504591, loss_fp: 0.500417, loss_freq: 0.503793
[14:39:51.662] iteration 851: loss: 0.958885, loss_s1: 0.503498, loss_fp: 0.500175, loss_freq: 0.505640
[14:39:52.293] iteration 852: loss: 0.930970, loss_s1: 0.504606, loss_fp: 0.500118, loss_freq: 0.501718
[14:39:52.928] iteration 853: loss: 0.880774, loss_s1: 0.505395, loss_fp: 0.500164, loss_freq: 0.504481
[14:39:53.561] iteration 854: loss: 0.956447, loss_s1: 0.505963, loss_fp: 0.500251, loss_freq: 0.501869
[14:39:54.195] iteration 855: loss: 0.856556, loss_s1: 0.505185, loss_fp: 0.500162, loss_freq: 0.501915
[14:39:54.828] iteration 856: loss: 0.918011, loss_s1: 0.504924, loss_fp: 0.500550, loss_freq: 0.501743
[14:39:55.460] iteration 857: loss: 1.032839, loss_s1: 0.504063, loss_fp: 0.500080, loss_freq: 0.501154
[14:39:56.089] iteration 858: loss: 0.849801, loss_s1: 0.503738, loss_fp: 0.500129, loss_freq: 0.501323
[14:39:56.721] iteration 859: loss: 0.941287, loss_s1: 0.502335, loss_fp: 0.500116, loss_freq: 0.502916
[14:39:57.353] iteration 860: loss: 0.902304, loss_s1: 0.504420, loss_fp: 0.500341, loss_freq: 0.501938
[14:39:57.981] iteration 861: loss: 0.965898, loss_s1: 0.505441, loss_fp: 0.500282, loss_freq: 0.504176
[14:39:58.619] iteration 862: loss: 0.927417, loss_s1: 0.504224, loss_fp: 0.500091, loss_freq: 0.503963
[14:39:59.250] iteration 863: loss: 0.973127, loss_s1: 0.504646, loss_fp: 0.500123, loss_freq: 0.501341
[14:39:59.883] iteration 864: loss: 0.953897, loss_s1: 0.505707, loss_fp: 0.500194, loss_freq: 0.501322
[14:40:00.509] iteration 865: loss: 0.903151, loss_s1: 0.504921, loss_fp: 0.500178, loss_freq: 0.500798
[14:40:01.141] iteration 866: loss: 0.891312, loss_s1: 0.506447, loss_fp: 0.500191, loss_freq: 0.502053
[14:40:01.773] iteration 867: loss: 0.950403, loss_s1: 0.503359, loss_fp: 0.500197, loss_freq: 0.502096
[14:40:02.404] iteration 868: loss: 0.944688, loss_s1: 0.504219, loss_fp: 0.500109, loss_freq: 0.503277
[14:40:03.028] iteration 869: loss: 0.948279, loss_s1: 0.507319, loss_fp: 0.500460, loss_freq: 0.502501
[14:40:03.661] iteration 870: loss: 0.920534, loss_s1: 0.505617, loss_fp: 0.500205, loss_freq: 0.501193
[14:40:04.290] iteration 871: loss: 0.897626, loss_s1: 0.507814, loss_fp: 0.500213, loss_freq: 0.501669
[14:40:04.931] iteration 872: loss: 0.917238, loss_s1: 0.503423, loss_fp: 0.500154, loss_freq: 0.505578
[14:40:05.559] iteration 873: loss: 0.873763, loss_s1: 0.503835, loss_fp: 0.500100, loss_freq: 0.500521
[14:40:06.199] iteration 874: loss: 0.931480, loss_s1: 0.506141, loss_fp: 0.500149, loss_freq: 0.503177
[14:40:06.837] iteration 875: loss: 1.000939, loss_s1: 0.509517, loss_fp: 0.500499, loss_freq: 0.501555
[14:40:07.474] iteration 876: loss: 0.929495, loss_s1: 0.507805, loss_fp: 0.500466, loss_freq: 0.501943
[14:40:08.107] iteration 877: loss: 0.905474, loss_s1: 0.504082, loss_fp: 0.500188, loss_freq: 0.502112
[14:40:08.738] iteration 878: loss: 0.933767, loss_s1: 0.507416, loss_fp: 0.500086, loss_freq: 0.503167
[14:40:09.370] iteration 879: loss: 0.921304, loss_s1: 0.507542, loss_fp: 0.500183, loss_freq: 0.503258
[14:40:10.009] iteration 880: loss: 0.919435, loss_s1: 0.508277, loss_fp: 0.500116, loss_freq: 0.504295
[14:40:10.641] iteration 881: loss: 0.916711, loss_s1: 0.505104, loss_fp: 0.500398, loss_freq: 0.503186
[14:40:11.275] iteration 882: loss: 0.941775, loss_s1: 0.502190, loss_fp: 0.500189, loss_freq: 0.502438
[14:40:11.911] iteration 883: loss: 0.897213, loss_s1: 0.509063, loss_fp: 0.500344, loss_freq: 0.503054
[14:40:12.547] iteration 884: loss: 0.884828, loss_s1: 0.507545, loss_fp: 0.500058, loss_freq: 0.502515
[14:40:13.185] iteration 885: loss: 0.912622, loss_s1: 0.507146, loss_fp: 0.500350, loss_freq: 0.503384
[14:40:13.819] iteration 886: loss: 0.986911, loss_s1: 0.506898, loss_fp: 0.500189, loss_freq: 0.502489
[14:40:14.454] iteration 887: loss: 0.940869, loss_s1: 0.502478, loss_fp: 0.500171, loss_freq: 0.501259
[14:40:15.086] iteration 888: loss: 0.877189, loss_s1: 0.506938, loss_fp: 0.500128, loss_freq: 0.505908
[14:40:15.724] iteration 889: loss: 0.932396, loss_s1: 0.503515, loss_fp: 0.500374, loss_freq: 0.502817
[14:40:16.359] iteration 890: loss: 0.860285, loss_s1: 0.503488, loss_fp: 0.500255, loss_freq: 0.502152
[14:40:16.995] iteration 891: loss: 0.880969, loss_s1: 0.503450, loss_fp: 0.500191, loss_freq: 0.502724
[14:40:17.629] iteration 892: loss: 0.975464, loss_s1: 0.505407, loss_fp: 0.500125, loss_freq: 0.502071
[14:40:18.258] iteration 893: loss: 0.875588, loss_s1: 0.506481, loss_fp: 0.500122, loss_freq: 0.501936
[14:40:18.880] iteration 894: loss: 0.971404, loss_s1: 0.506245, loss_fp: 0.500120, loss_freq: 0.503162
[14:40:19.505] iteration 895: loss: 0.892681, loss_s1: 0.503775, loss_fp: 0.500160, loss_freq: 0.501829
[14:40:20.123] iteration 896: loss: 0.981402, loss_s1: 0.504670, loss_fp: 0.500275, loss_freq: 0.501530
[14:40:20.746] iteration 897: loss: 0.929757, loss_s1: 0.504738, loss_fp: 0.500196, loss_freq: 0.502370
[14:40:21.365] iteration 898: loss: 0.994083, loss_s1: 0.508177, loss_fp: 0.500301, loss_freq: 0.500795
[14:40:21.991] iteration 899: loss: 0.908818, loss_s1: 0.505334, loss_fp: 0.500213, loss_freq: 0.501932
[14:40:22.611] iteration 900: loss: 0.891491, loss_s1: 0.503147, loss_fp: 0.500343, loss_freq: 0.502322
[14:40:23.230] iteration 901: loss: 0.883663, loss_s1: 0.502747, loss_fp: 0.500387, loss_freq: 0.503540
[14:40:23.851] iteration 902: loss: 0.921991, loss_s1: 0.501674, loss_fp: 0.500134, loss_freq: 0.501842
[14:40:24.470] iteration 903: loss: 0.936048, loss_s1: 0.506048, loss_fp: 0.500508, loss_freq: 0.504083
[14:40:25.090] iteration 904: loss: 0.919940, loss_s1: 0.502845, loss_fp: 0.500232, loss_freq: 0.502233
[14:40:25.711] iteration 905: loss: 0.908886, loss_s1: 0.503198, loss_fp: 0.500123, loss_freq: 0.501635
[14:40:26.335] iteration 906: loss: 0.849623, loss_s1: 0.503479, loss_fp: 0.500114, loss_freq: 0.500957
[14:40:26.962] iteration 907: loss: 0.945601, loss_s1: 0.506901, loss_fp: 0.500185, loss_freq: 0.502140
[14:40:27.587] iteration 908: loss: 0.874085, loss_s1: 0.505166, loss_fp: 0.500274, loss_freq: 0.503663
[14:40:28.208] iteration 909: loss: 0.928470, loss_s1: 0.502743, loss_fp: 0.500085, loss_freq: 0.501893
[14:40:28.831] iteration 910: loss: 0.966819, loss_s1: 0.504144, loss_fp: 0.500099, loss_freq: 0.504511
[14:40:29.451] iteration 911: loss: 0.961107, loss_s1: 0.505384, loss_fp: 0.500209, loss_freq: 0.501973
[14:40:30.074] iteration 912: loss: 0.883703, loss_s1: 0.506332, loss_fp: 0.500146, loss_freq: 0.502203
[14:40:30.698] iteration 913: loss: 0.928007, loss_s1: 0.504891, loss_fp: 0.500204, loss_freq: 0.503081
[14:40:31.340] iteration 914: loss: 0.938133, loss_s1: 0.504927, loss_fp: 0.500300, loss_freq: 0.504747
[14:40:31.965] iteration 915: loss: 0.962267, loss_s1: 0.504358, loss_fp: 0.500211, loss_freq: 0.502659
[14:40:32.584] iteration 916: loss: 0.947099, loss_s1: 0.502881, loss_fp: 0.500062, loss_freq: 0.504393
[14:40:33.212] iteration 917: loss: 0.860002, loss_s1: 0.503427, loss_fp: 0.500356, loss_freq: 0.504297
[14:40:33.835] iteration 918: loss: 0.881826, loss_s1: 0.505361, loss_fp: 0.500187, loss_freq: 0.502350
[14:40:34.474] iteration 919: loss: 0.872351, loss_s1: 0.502487, loss_fp: 0.500104, loss_freq: 0.502708
[14:40:35.106] iteration 920: loss: 0.933848, loss_s1: 0.503628, loss_fp: 0.500129, loss_freq: 0.501225
[14:40:35.745] iteration 921: loss: 0.975484, loss_s1: 0.503960, loss_fp: 0.500449, loss_freq: 0.501794
[14:40:36.382] iteration 922: loss: 0.932958, loss_s1: 0.502725, loss_fp: 0.500351, loss_freq: 0.501427
[14:40:37.014] iteration 923: loss: 0.840889, loss_s1: 0.505097, loss_fp: 0.500165, loss_freq: 0.503151
[14:40:37.642] iteration 924: loss: 0.920032, loss_s1: 0.502763, loss_fp: 0.500372, loss_freq: 0.503113
[14:40:38.273] iteration 925: loss: 0.863202, loss_s1: 0.508418, loss_fp: 0.500415, loss_freq: 0.503338
[14:40:38.901] iteration 926: loss: 0.879595, loss_s1: 0.503815, loss_fp: 0.501355, loss_freq: 0.501622
[14:40:39.528] iteration 927: loss: 0.995340, loss_s1: 0.504484, loss_fp: 0.500254, loss_freq: 0.503851
[14:40:40.168] iteration 928: loss: 0.912252, loss_s1: 0.505645, loss_fp: 0.500403, loss_freq: 0.501940
[14:40:40.799] iteration 929: loss: 0.924807, loss_s1: 0.504622, loss_fp: 0.500349, loss_freq: 0.501607
[14:40:41.475] iteration 930: loss: 0.892588, loss_s1: 0.502470, loss_fp: 0.500245, loss_freq: 0.501653
[14:40:42.108] iteration 931: loss: 0.940062, loss_s1: 0.504154, loss_fp: 0.500147, loss_freq: 0.502151
[14:40:42.746] iteration 932: loss: 0.916830, loss_s1: 0.502336, loss_fp: 0.500171, loss_freq: 0.501318
[14:40:43.383] iteration 933: loss: 0.969432, loss_s1: 0.505339, loss_fp: 0.500116, loss_freq: 0.501851
[14:40:44.007] iteration 934: loss: 0.883028, loss_s1: 0.503121, loss_fp: 0.500229, loss_freq: 0.501984
[14:40:44.621] iteration 935: loss: 0.886735, loss_s1: 0.503266, loss_fp: 0.500211, loss_freq: 0.500648
[14:40:45.235] iteration 936: loss: 0.857168, loss_s1: 0.505767, loss_fp: 0.500259, loss_freq: 0.502239
[14:40:45.863] iteration 937: loss: 0.922362, loss_s1: 0.506309, loss_fp: 0.500134, loss_freq: 0.502744
[14:40:46.491] iteration 938: loss: 0.946255, loss_s1: 0.505230, loss_fp: 0.500067, loss_freq: 0.501106
[14:40:47.114] iteration 939: loss: 0.922871, loss_s1: 0.502044, loss_fp: 0.500083, loss_freq: 0.501704
[14:40:47.738] iteration 940: loss: 0.900172, loss_s1: 0.504077, loss_fp: 0.500253, loss_freq: 0.503630
[14:40:48.354] iteration 941: loss: 0.882604, loss_s1: 0.504830, loss_fp: 0.500077, loss_freq: 0.504368
[14:40:48.998] iteration 942: loss: 0.941056, loss_s1: 0.505486, loss_fp: 0.500291, loss_freq: 0.504357
[14:40:49.623] iteration 943: loss: 0.840254, loss_s1: 0.503415, loss_fp: 0.500104, loss_freq: 0.500979
[14:40:50.243] iteration 944: loss: 0.901233, loss_s1: 0.502862, loss_fp: 0.500151, loss_freq: 0.502711
[14:40:50.865] iteration 945: loss: 0.977909, loss_s1: 0.505936, loss_fp: 0.500344, loss_freq: 0.505114
[14:40:51.488] iteration 946: loss: 0.915175, loss_s1: 0.503961, loss_fp: 0.500293, loss_freq: 0.503261
[14:40:52.158] iteration 947: loss: 0.900806, loss_s1: 0.502945, loss_fp: 0.500166, loss_freq: 0.503412
[14:40:52.790] iteration 948: loss: 0.934714, loss_s1: 0.504345, loss_fp: 0.500122, loss_freq: 0.502551
[14:40:53.425] iteration 949: loss: 0.978274, loss_s1: 0.503502, loss_fp: 0.500113, loss_freq: 0.504431
[14:40:54.051] iteration 950: loss: 0.932169, loss_s1: 0.503408, loss_fp: 0.500295, loss_freq: 0.503756
[14:40:54.674] iteration 951: loss: 0.929467, loss_s1: 0.506195, loss_fp: 0.500687, loss_freq: 0.503441
[14:40:55.297] iteration 952: loss: 0.902320, loss_s1: 0.505269, loss_fp: 0.500221, loss_freq: 0.502195
[14:40:55.925] iteration 953: loss: 0.889369, loss_s1: 0.503481, loss_fp: 0.500192, loss_freq: 0.500865
[14:40:56.553] iteration 954: loss: 0.890404, loss_s1: 0.507719, loss_fp: 0.500147, loss_freq: 0.503962
[14:40:57.179] iteration 955: loss: 0.950397, loss_s1: 0.510244, loss_fp: 0.500244, loss_freq: 0.502811
[14:40:57.799] iteration 956: loss: 1.004407, loss_s1: 0.505707, loss_fp: 0.500107, loss_freq: 0.504437
[14:40:58.424] iteration 957: loss: 0.933684, loss_s1: 0.505599, loss_fp: 0.500202, loss_freq: 0.500700
[14:40:59.048] iteration 958: loss: 0.855749, loss_s1: 0.504707, loss_fp: 0.500130, loss_freq: 0.502970
[14:40:59.670] iteration 959: loss: 0.888730, loss_s1: 0.502890, loss_fp: 0.500102, loss_freq: 0.500760
[14:41:00.297] iteration 960: loss: 0.888124, loss_s1: 0.510147, loss_fp: 0.500234, loss_freq: 0.501614
[14:41:00.914] iteration 961: loss: 0.919399, loss_s1: 0.506168, loss_fp: 0.500179, loss_freq: 0.506110
[14:41:01.536] iteration 962: loss: 0.995670, loss_s1: 0.504287, loss_fp: 0.500437, loss_freq: 0.501822
[14:41:02.157] iteration 963: loss: 0.913035, loss_s1: 0.504084, loss_fp: 0.500207, loss_freq: 0.501783
[14:41:02.778] iteration 964: loss: 0.897299, loss_s1: 0.503365, loss_fp: 0.500180, loss_freq: 0.502272
[14:41:03.401] iteration 965: loss: 0.878544, loss_s1: 0.505730, loss_fp: 0.500376, loss_freq: 0.501548
[14:41:04.022] iteration 966: loss: 0.940396, loss_s1: 0.506008, loss_fp: 0.500139, loss_freq: 0.502434
[14:41:04.956] iteration 967: loss: 0.884781, loss_s1: 0.502801, loss_fp: 0.500364, loss_freq: 0.502023
[14:41:05.586] iteration 968: loss: 0.879144, loss_s1: 0.506708, loss_fp: 0.500264, loss_freq: 0.504294
[14:41:06.208] iteration 969: loss: 0.922689, loss_s1: 0.504847, loss_fp: 0.500394, loss_freq: 0.502425
[14:41:06.832] iteration 970: loss: 0.953602, loss_s1: 0.506170, loss_fp: 0.500405, loss_freq: 0.503756
[14:41:07.452] iteration 971: loss: 0.942592, loss_s1: 0.503219, loss_fp: 0.500161, loss_freq: 0.503219
[14:41:08.073] iteration 972: loss: 0.948723, loss_s1: 0.503900, loss_fp: 0.500453, loss_freq: 0.501635
[14:41:08.691] iteration 973: loss: 0.896408, loss_s1: 0.503578, loss_fp: 0.500379, loss_freq: 0.502137
[14:41:09.305] iteration 974: loss: 0.918685, loss_s1: 0.506969, loss_fp: 0.500115, loss_freq: 0.501025
[14:41:09.926] iteration 975: loss: 0.842649, loss_s1: 0.506212, loss_fp: 0.500113, loss_freq: 0.502244
[14:41:10.552] iteration 976: loss: 0.922593, loss_s1: 0.509221, loss_fp: 0.500172, loss_freq: 0.504835
[14:41:11.174] iteration 977: loss: 0.909040, loss_s1: 0.506856, loss_fp: 0.500138, loss_freq: 0.504074
[14:41:11.798] iteration 978: loss: 0.909594, loss_s1: 0.507138, loss_fp: 0.500174, loss_freq: 0.504202
[14:41:12.438] iteration 979: loss: 0.833754, loss_s1: 0.504706, loss_fp: 0.500196, loss_freq: 0.502307
[14:41:13.059] iteration 980: loss: 0.933669, loss_s1: 0.504159, loss_fp: 0.500236, loss_freq: 0.503976
[14:41:13.677] iteration 981: loss: 0.858700, loss_s1: 0.506745, loss_fp: 0.500130, loss_freq: 0.501677
[14:41:14.300] iteration 982: loss: 0.894724, loss_s1: 0.505594, loss_fp: 0.500545, loss_freq: 0.504050
[14:41:14.930] iteration 983: loss: 0.992523, loss_s1: 0.503838, loss_fp: 0.500119, loss_freq: 0.501195
[14:41:15.557] iteration 984: loss: 0.903465, loss_s1: 0.504169, loss_fp: 0.500094, loss_freq: 0.503151
[14:41:16.181] iteration 985: loss: 0.920032, loss_s1: 0.505778, loss_fp: 0.500205, loss_freq: 0.500642
[14:41:16.804] iteration 986: loss: 0.921357, loss_s1: 0.502701, loss_fp: 0.500134, loss_freq: 0.504040
[14:41:17.425] iteration 987: loss: 0.929723, loss_s1: 0.505045, loss_fp: 0.500081, loss_freq: 0.504209
[14:41:18.047] iteration 988: loss: 0.924457, loss_s1: 0.505834, loss_fp: 0.500201, loss_freq: 0.502849
[14:41:18.681] iteration 989: loss: 0.962473, loss_s1: 0.504731, loss_fp: 0.500092, loss_freq: 0.501951
[14:41:19.303] iteration 990: loss: 0.915791, loss_s1: 0.505010, loss_fp: 0.500099, loss_freq: 0.502169
[14:41:19.925] iteration 991: loss: 0.884454, loss_s1: 0.505818, loss_fp: 0.500220, loss_freq: 0.502912
[14:41:20.548] iteration 992: loss: 0.889160, loss_s1: 0.503694, loss_fp: 0.500072, loss_freq: 0.502396
[14:41:21.166] iteration 993: loss: 0.943775, loss_s1: 0.505917, loss_fp: 0.500268, loss_freq: 0.501418
[14:41:21.785] iteration 994: loss: 0.937101, loss_s1: 0.506193, loss_fp: 0.500266, loss_freq: 0.504858
[14:41:22.409] iteration 995: loss: 0.937511, loss_s1: 0.505091, loss_fp: 0.500263, loss_freq: 0.500945
[14:41:23.031] iteration 996: loss: 0.911099, loss_s1: 0.503511, loss_fp: 0.500322, loss_freq: 0.501557
[14:41:23.655] iteration 997: loss: 0.882824, loss_s1: 0.502589, loss_fp: 0.500371, loss_freq: 0.502072
[14:41:24.277] iteration 998: loss: 0.892363, loss_s1: 0.504493, loss_fp: 0.500217, loss_freq: 0.502551
[14:41:24.896] iteration 999: loss: 0.858270, loss_s1: 0.505260, loss_fp: 0.500338, loss_freq: 0.503756
[14:41:25.521] iteration 1000: loss: 0.919747, loss_s1: 0.502588, loss_fp: 0.500332, loss_freq: 0.501872
[14:41:27.661] iteration 1000 : mean_dice : 0.070694
[14:41:28.302] iteration 1001: loss: 1.024675, loss_s1: 0.503339, loss_fp: 0.500197, loss_freq: 0.500753
[14:41:28.926] iteration 1002: loss: 0.892712, loss_s1: 0.506486, loss_fp: 0.500208, loss_freq: 0.501633
[14:41:29.548] iteration 1003: loss: 0.909707, loss_s1: 0.505033, loss_fp: 0.500271, loss_freq: 0.507002
[14:41:30.173] iteration 1004: loss: 0.905019, loss_s1: 0.508053, loss_fp: 0.500321, loss_freq: 0.505547
[14:41:30.791] iteration 1005: loss: 0.930174, loss_s1: 0.502694, loss_fp: 0.500158, loss_freq: 0.501370
[14:41:31.409] iteration 1006: loss: 0.909017, loss_s1: 0.503106, loss_fp: 0.500174, loss_freq: 0.502912
[14:41:32.037] iteration 1007: loss: 0.950860, loss_s1: 0.504758, loss_fp: 0.500213, loss_freq: 0.502888
[14:41:32.658] iteration 1008: loss: 0.897201, loss_s1: 0.503460, loss_fp: 0.500324, loss_freq: 0.502160
[14:41:33.278] iteration 1009: loss: 0.924088, loss_s1: 0.506175, loss_fp: 0.500270, loss_freq: 0.502388
[14:41:33.905] iteration 1010: loss: 0.874443, loss_s1: 0.505830, loss_fp: 0.500138, loss_freq: 0.503106
[14:41:34.530] iteration 1011: loss: 0.921366, loss_s1: 0.507593, loss_fp: 0.500120, loss_freq: 0.503030
[14:41:35.154] iteration 1012: loss: 0.987283, loss_s1: 0.509999, loss_fp: 0.500124, loss_freq: 0.505066
[14:41:35.777] iteration 1013: loss: 0.902778, loss_s1: 0.505265, loss_fp: 0.500474, loss_freq: 0.501390
[14:41:36.398] iteration 1014: loss: 0.839661, loss_s1: 0.503125, loss_fp: 0.500114, loss_freq: 0.504268
[14:41:37.022] iteration 1015: loss: 0.915427, loss_s1: 0.501212, loss_fp: 0.500076, loss_freq: 0.503132
[14:41:37.642] iteration 1016: loss: 0.864325, loss_s1: 0.504168, loss_fp: 0.500356, loss_freq: 0.502247
[14:41:38.271] iteration 1017: loss: 0.886552, loss_s1: 0.504292, loss_fp: 0.500166, loss_freq: 0.501953
[14:41:38.894] iteration 1018: loss: 1.001578, loss_s1: 0.503365, loss_fp: 0.500214, loss_freq: 0.501522
[14:41:39.516] iteration 1019: loss: 0.847614, loss_s1: 0.504210, loss_fp: 0.500280, loss_freq: 0.501606
[14:41:40.168] iteration 1020: loss: 0.883957, loss_s1: 0.507015, loss_fp: 0.500098, loss_freq: 0.502324
[14:41:40.793] iteration 1021: loss: 0.887899, loss_s1: 0.502847, loss_fp: 0.500077, loss_freq: 0.501574
[14:41:41.416] iteration 1022: loss: 0.947530, loss_s1: 0.506444, loss_fp: 0.500084, loss_freq: 0.502924
[14:41:42.041] iteration 1023: loss: 0.898808, loss_s1: 0.503186, loss_fp: 0.500356, loss_freq: 0.504694
[14:41:42.669] iteration 1024: loss: 0.937704, loss_s1: 0.505443, loss_fp: 0.500254, loss_freq: 0.501918
[14:41:43.314] iteration 1025: loss: 0.957262, loss_s1: 0.505615, loss_fp: 0.500217, loss_freq: 0.503632
[14:41:43.955] iteration 1026: loss: 0.891335, loss_s1: 0.501987, loss_fp: 0.500162, loss_freq: 0.501302
[14:41:44.599] iteration 1027: loss: 0.877518, loss_s1: 0.504744, loss_fp: 0.500079, loss_freq: 0.501402
[14:41:45.241] iteration 1028: loss: 0.888509, loss_s1: 0.503093, loss_fp: 0.500093, loss_freq: 0.501467
[14:41:45.863] iteration 1029: loss: 0.893658, loss_s1: 0.502993, loss_fp: 0.500076, loss_freq: 0.502924
[14:41:46.485] iteration 1030: loss: 0.930280, loss_s1: 0.506785, loss_fp: 0.500208, loss_freq: 0.503922
[14:41:47.109] iteration 1031: loss: 0.881534, loss_s1: 0.504232, loss_fp: 0.500167, loss_freq: 0.501288
[14:41:47.752] iteration 1032: loss: 0.874133, loss_s1: 0.504024, loss_fp: 0.500173, loss_freq: 0.503547
[14:41:48.390] iteration 1033: loss: 0.873603, loss_s1: 0.503845, loss_fp: 0.500131, loss_freq: 0.506420
[14:41:49.026] iteration 1034: loss: 0.825063, loss_s1: 0.505500, loss_fp: 0.500039, loss_freq: 0.500194
[14:41:49.662] iteration 1035: loss: 0.914069, loss_s1: 0.504186, loss_fp: 0.500124, loss_freq: 0.505063
[14:41:50.298] iteration 1036: loss: 0.947984, loss_s1: 0.505920, loss_fp: 0.500581, loss_freq: 0.502340
[14:41:50.933] iteration 1037: loss: 0.910582, loss_s1: 0.505265, loss_fp: 0.500106, loss_freq: 0.502468
[14:41:51.573] iteration 1038: loss: 0.854733, loss_s1: 0.503615, loss_fp: 0.500055, loss_freq: 0.501884
[14:41:52.215] iteration 1039: loss: 0.873666, loss_s1: 0.505579, loss_fp: 0.500117, loss_freq: 0.503299
[14:41:52.851] iteration 1040: loss: 0.917069, loss_s1: 0.508262, loss_fp: 0.500120, loss_freq: 0.503189
[14:41:53.482] iteration 1041: loss: 0.901863, loss_s1: 0.508351, loss_fp: 0.500212, loss_freq: 0.504177
[14:41:54.117] iteration 1042: loss: 0.894765, loss_s1: 0.507452, loss_fp: 0.500104, loss_freq: 0.504467
[14:41:54.749] iteration 1043: loss: 0.934395, loss_s1: 0.504078, loss_fp: 0.500391, loss_freq: 0.503086
[14:41:55.373] iteration 1044: loss: 0.869604, loss_s1: 0.506893, loss_fp: 0.500297, loss_freq: 0.503739
[14:41:55.994] iteration 1045: loss: 0.871673, loss_s1: 0.505144, loss_fp: 0.500092, loss_freq: 0.502529
[14:41:56.631] iteration 1046: loss: 0.900544, loss_s1: 0.507919, loss_fp: 0.500088, loss_freq: 0.502839
[14:41:57.271] iteration 1047: loss: 0.911519, loss_s1: 0.504978, loss_fp: 0.500113, loss_freq: 0.503360
[14:41:57.903] iteration 1048: loss: 0.889094, loss_s1: 0.504885, loss_fp: 0.500503, loss_freq: 0.502576
[14:41:58.538] iteration 1049: loss: 0.836324, loss_s1: 0.505329, loss_fp: 0.500127, loss_freq: 0.504288
[14:41:59.163] iteration 1050: loss: 0.896702, loss_s1: 0.503849, loss_fp: 0.500193, loss_freq: 0.501829
[14:41:59.782] iteration 1051: loss: 0.840933, loss_s1: 0.505198, loss_fp: 0.500269, loss_freq: 0.502060
[14:42:00.404] iteration 1052: loss: 0.889565, loss_s1: 0.502486, loss_fp: 0.500139, loss_freq: 0.502203
[14:42:01.029] iteration 1053: loss: 1.042747, loss_s1: 0.505218, loss_fp: 0.500315, loss_freq: 0.503433
[14:42:01.653] iteration 1054: loss: 0.860980, loss_s1: 0.502532, loss_fp: 0.500366, loss_freq: 0.502549
[14:42:02.276] iteration 1055: loss: 0.951284, loss_s1: 0.503177, loss_fp: 0.500138, loss_freq: 0.501575
[14:42:02.898] iteration 1056: loss: 0.865583, loss_s1: 0.502320, loss_fp: 0.500093, loss_freq: 0.500867
[14:42:03.518] iteration 1057: loss: 0.938932, loss_s1: 0.504207, loss_fp: 0.500054, loss_freq: 0.501045
[14:42:04.138] iteration 1058: loss: 0.873515, loss_s1: 0.504596, loss_fp: 0.500311, loss_freq: 0.501392
[14:42:04.760] iteration 1059: loss: 0.974226, loss_s1: 0.501871, loss_fp: 0.500144, loss_freq: 0.500523
[14:42:05.381] iteration 1060: loss: 0.866883, loss_s1: 0.501386, loss_fp: 0.500094, loss_freq: 0.500927
[14:42:06.002] iteration 1061: loss: 0.866925, loss_s1: 0.505259, loss_fp: 0.500740, loss_freq: 0.504370
[14:42:06.620] iteration 1062: loss: 0.864346, loss_s1: 0.504399, loss_fp: 0.500241, loss_freq: 0.503304
[14:42:07.247] iteration 1063: loss: 0.881403, loss_s1: 0.500310, loss_fp: 0.500058, loss_freq: 0.502468
[14:42:07.874] iteration 1064: loss: 0.907568, loss_s1: 0.503199, loss_fp: 0.500450, loss_freq: 0.504287
[14:42:08.499] iteration 1065: loss: 0.906681, loss_s1: 0.503768, loss_fp: 0.500130, loss_freq: 0.506605
[14:42:09.123] iteration 1066: loss: 0.873884, loss_s1: 0.505102, loss_fp: 0.500290, loss_freq: 0.501510
[14:42:09.744] iteration 1067: loss: 0.877363, loss_s1: 0.505279, loss_fp: 0.500702, loss_freq: 0.502734
[14:42:10.364] iteration 1068: loss: 0.898187, loss_s1: 0.507554, loss_fp: 0.500359, loss_freq: 0.503176
[14:42:10.986] iteration 1069: loss: 0.885588, loss_s1: 0.507942, loss_fp: 0.500333, loss_freq: 0.503505
[14:42:11.604] iteration 1070: loss: 0.864006, loss_s1: 0.505029, loss_fp: 0.500274, loss_freq: 0.502148
[14:42:12.243] iteration 1071: loss: 0.978460, loss_s1: 0.506654, loss_fp: 0.500113, loss_freq: 0.505320
[14:42:12.867] iteration 1072: loss: 0.972568, loss_s1: 0.509833, loss_fp: 0.500144, loss_freq: 0.501547
[14:42:13.494] iteration 1073: loss: 0.886175, loss_s1: 0.505315, loss_fp: 0.500397, loss_freq: 0.502777
[14:42:14.118] iteration 1074: loss: 0.916837, loss_s1: 0.505915, loss_fp: 0.500359, loss_freq: 0.503916
[14:42:14.742] iteration 1075: loss: 0.879966, loss_s1: 0.505453, loss_fp: 0.500037, loss_freq: 0.505363
[14:42:15.362] iteration 1076: loss: 0.932460, loss_s1: 0.508637, loss_fp: 0.500202, loss_freq: 0.502602
[14:42:15.986] iteration 1077: loss: 0.909108, loss_s1: 0.504290, loss_fp: 0.500490, loss_freq: 0.504243
[14:42:16.610] iteration 1078: loss: 0.900348, loss_s1: 0.506011, loss_fp: 0.500287, loss_freq: 0.504890
[14:42:17.247] iteration 1079: loss: 0.897497, loss_s1: 0.502945, loss_fp: 0.500296, loss_freq: 0.503234
[14:42:17.874] iteration 1080: loss: 0.845490, loss_s1: 0.501629, loss_fp: 0.500098, loss_freq: 0.504869
[14:42:18.500] iteration 1081: loss: 0.906672, loss_s1: 0.500569, loss_fp: 0.500354, loss_freq: 0.501105
[14:42:19.125] iteration 1082: loss: 0.921358, loss_s1: 0.504889, loss_fp: 0.500308, loss_freq: 0.503096
[14:42:19.757] iteration 1083: loss: 0.894358, loss_s1: 0.504759, loss_fp: 0.500213, loss_freq: 0.501860
[14:42:20.375] iteration 1084: loss: 0.825445, loss_s1: 0.503963, loss_fp: 0.500225, loss_freq: 0.504228
[14:42:20.997] iteration 1085: loss: 0.919430, loss_s1: 0.506658, loss_fp: 0.500199, loss_freq: 0.503824
[14:42:21.621] iteration 1086: loss: 0.847806, loss_s1: 0.508386, loss_fp: 0.500199, loss_freq: 0.504889
[14:42:22.242] iteration 1087: loss: 0.870962, loss_s1: 0.505144, loss_fp: 0.500213, loss_freq: 0.502711
[14:42:22.860] iteration 1088: loss: 0.949825, loss_s1: 0.506295, loss_fp: 0.500485, loss_freq: 0.503279
[14:42:23.477] iteration 1089: loss: 0.895745, loss_s1: 0.502156, loss_fp: 0.500351, loss_freq: 0.502885
[14:42:24.095] iteration 1090: loss: 0.905308, loss_s1: 0.506685, loss_fp: 0.500575, loss_freq: 0.503050
[14:42:24.715] iteration 1091: loss: 0.879085, loss_s1: 0.502187, loss_fp: 0.500075, loss_freq: 0.500630
[14:42:25.334] iteration 1092: loss: 0.900193, loss_s1: 0.504385, loss_fp: 0.500086, loss_freq: 0.502888
[14:42:25.953] iteration 1093: loss: 0.893552, loss_s1: 0.502847, loss_fp: 0.500162, loss_freq: 0.501567
[14:42:26.573] iteration 1094: loss: 0.958445, loss_s1: 0.502979, loss_fp: 0.500097, loss_freq: 0.501406
[14:42:27.194] iteration 1095: loss: 0.896423, loss_s1: 0.504331, loss_fp: 0.500099, loss_freq: 0.501463
[14:42:27.814] iteration 1096: loss: 0.892829, loss_s1: 0.501459, loss_fp: 0.500294, loss_freq: 0.501547
[14:42:28.439] iteration 1097: loss: 0.857743, loss_s1: 0.503559, loss_fp: 0.500112, loss_freq: 0.502321
[14:42:29.061] iteration 1098: loss: 0.913324, loss_s1: 0.504303, loss_fp: 0.500405, loss_freq: 0.503959
[14:42:29.680] iteration 1099: loss: 0.906372, loss_s1: 0.506338, loss_fp: 0.500096, loss_freq: 0.503052
[14:42:30.343] iteration 1100: loss: 0.898055, loss_s1: 0.502024, loss_fp: 0.500227, loss_freq: 0.502026
[14:42:30.961] iteration 1101: loss: 0.871767, loss_s1: 0.504190, loss_fp: 0.500143, loss_freq: 0.503972
[14:42:31.606] iteration 1102: loss: 0.884952, loss_s1: 0.503394, loss_fp: 0.500159, loss_freq: 0.504678
[14:42:32.239] iteration 1103: loss: 0.915896, loss_s1: 0.504935, loss_fp: 0.500431, loss_freq: 0.505865
[14:42:32.867] iteration 1104: loss: 0.856291, loss_s1: 0.505193, loss_fp: 0.500208, loss_freq: 0.502227
[14:42:33.493] iteration 1105: loss: 0.876361, loss_s1: 0.504997, loss_fp: 0.500069, loss_freq: 0.503063
[14:42:34.122] iteration 1106: loss: 0.964053, loss_s1: 0.505201, loss_fp: 0.500187, loss_freq: 0.505079
[14:42:34.754] iteration 1107: loss: 0.928619, loss_s1: 0.500991, loss_fp: 0.500196, loss_freq: 0.501477
[14:42:35.382] iteration 1108: loss: 0.850914, loss_s1: 0.503986, loss_fp: 0.500161, loss_freq: 0.501279
[14:42:36.008] iteration 1109: loss: 0.886644, loss_s1: 0.503813, loss_fp: 0.500070, loss_freq: 0.501511
[14:42:36.635] iteration 1110: loss: 0.890048, loss_s1: 0.505863, loss_fp: 0.500055, loss_freq: 0.505032
[14:42:37.260] iteration 1111: loss: 0.906745, loss_s1: 0.501711, loss_fp: 0.500217, loss_freq: 0.502597
[14:42:37.881] iteration 1112: loss: 0.952819, loss_s1: 0.502283, loss_fp: 0.500080, loss_freq: 0.502318
[14:42:38.503] iteration 1113: loss: 0.895009, loss_s1: 0.504350, loss_fp: 0.500133, loss_freq: 0.501434
[14:42:39.128] iteration 1114: loss: 0.865873, loss_s1: 0.504720, loss_fp: 0.500108, loss_freq: 0.500708
[14:42:39.752] iteration 1115: loss: 0.886639, loss_s1: 0.502527, loss_fp: 0.500236, loss_freq: 0.504007
[14:42:40.377] iteration 1116: loss: 0.919250, loss_s1: 0.505005, loss_fp: 0.500181, loss_freq: 0.502183
[14:42:41.000] iteration 1117: loss: 0.912255, loss_s1: 0.505290, loss_fp: 0.500132, loss_freq: 0.504326
[14:42:41.621] iteration 1118: loss: 0.868296, loss_s1: 0.505470, loss_fp: 0.500209, loss_freq: 0.500778
[14:42:42.243] iteration 1119: loss: 0.838342, loss_s1: 0.507065, loss_fp: 0.500264, loss_freq: 0.502976
[14:42:42.867] iteration 1120: loss: 0.875677, loss_s1: 0.504472, loss_fp: 0.500144, loss_freq: 0.501074
[14:42:43.491] iteration 1121: loss: 0.836766, loss_s1: 0.504797, loss_fp: 0.500392, loss_freq: 0.501867
[14:42:44.114] iteration 1122: loss: 0.882452, loss_s1: 0.503102, loss_fp: 0.500269, loss_freq: 0.505309
[14:42:44.739] iteration 1123: loss: 0.963812, loss_s1: 0.504309, loss_fp: 0.500294, loss_freq: 0.503497
[14:42:45.414] iteration 1124: loss: 0.904409, loss_s1: 0.505360, loss_fp: 0.500202, loss_freq: 0.503114
[14:42:46.073] iteration 1125: loss: 0.943013, loss_s1: 0.504377, loss_fp: 0.500119, loss_freq: 0.503755
[14:42:46.698] iteration 1126: loss: 0.848652, loss_s1: 0.503569, loss_fp: 0.500334, loss_freq: 0.501551
[14:42:47.321] iteration 1127: loss: 0.942030, loss_s1: 0.503435, loss_fp: 0.500431, loss_freq: 0.503933
[14:42:48.264] iteration 1128: loss: 0.891053, loss_s1: 0.504275, loss_fp: 0.500262, loss_freq: 0.500795
[14:42:48.890] iteration 1129: loss: 0.858308, loss_s1: 0.505089, loss_fp: 0.500349, loss_freq: 0.503544
[14:42:49.517] iteration 1130: loss: 0.897605, loss_s1: 0.501440, loss_fp: 0.500076, loss_freq: 0.501383
[14:42:50.143] iteration 1131: loss: 0.887401, loss_s1: 0.504938, loss_fp: 0.500154, loss_freq: 0.503025
[14:42:50.765] iteration 1132: loss: 0.953561, loss_s1: 0.503277, loss_fp: 0.500237, loss_freq: 0.502137
[14:42:51.391] iteration 1133: loss: 0.947453, loss_s1: 0.504785, loss_fp: 0.500353, loss_freq: 0.500552
[14:42:52.018] iteration 1134: loss: 0.855340, loss_s1: 0.502271, loss_fp: 0.500132, loss_freq: 0.502266
[14:42:52.643] iteration 1135: loss: 0.892548, loss_s1: 0.506801, loss_fp: 0.500112, loss_freq: 0.500837
[14:42:53.268] iteration 1136: loss: 0.839131, loss_s1: 0.503940, loss_fp: 0.500141, loss_freq: 0.501095
[14:42:53.894] iteration 1137: loss: 0.956712, loss_s1: 0.506109, loss_fp: 0.500124, loss_freq: 0.504778
[14:42:54.514] iteration 1138: loss: 0.915133, loss_s1: 0.505580, loss_fp: 0.500142, loss_freq: 0.505089
[14:42:55.140] iteration 1139: loss: 0.902045, loss_s1: 0.505226, loss_fp: 0.500142, loss_freq: 0.503460
[14:42:55.766] iteration 1140: loss: 0.830034, loss_s1: 0.502849, loss_fp: 0.500126, loss_freq: 0.502275
[14:42:56.430] iteration 1141: loss: 0.940173, loss_s1: 0.502768, loss_fp: 0.500146, loss_freq: 0.505695
[14:42:57.056] iteration 1142: loss: 0.849399, loss_s1: 0.507458, loss_fp: 0.500177, loss_freq: 0.502293
[14:42:57.678] iteration 1143: loss: 0.860243, loss_s1: 0.505764, loss_fp: 0.500251, loss_freq: 0.503919
[14:42:58.301] iteration 1144: loss: 1.006041, loss_s1: 0.504425, loss_fp: 0.500592, loss_freq: 0.501929
[14:42:58.919] iteration 1145: loss: 0.905994, loss_s1: 0.500619, loss_fp: 0.500327, loss_freq: 0.502809
[14:42:59.541] iteration 1146: loss: 0.919141, loss_s1: 0.502439, loss_fp: 0.500212, loss_freq: 0.501729
[14:43:00.166] iteration 1147: loss: 0.909634, loss_s1: 0.501913, loss_fp: 0.500423, loss_freq: 0.504959
[14:43:00.795] iteration 1148: loss: 0.901493, loss_s1: 0.504960, loss_fp: 0.500231, loss_freq: 0.504670
[14:43:01.422] iteration 1149: loss: 0.922348, loss_s1: 0.503013, loss_fp: 0.500217, loss_freq: 0.502849
[14:43:02.049] iteration 1150: loss: 0.975960, loss_s1: 0.504185, loss_fp: 0.500391, loss_freq: 0.503281
[14:43:02.677] iteration 1151: loss: 0.866419, loss_s1: 0.505908, loss_fp: 0.500289, loss_freq: 0.504612
[14:43:03.302] iteration 1152: loss: 0.870794, loss_s1: 0.503243, loss_fp: 0.500170, loss_freq: 0.503663
[14:43:03.929] iteration 1153: loss: 0.844783, loss_s1: 0.500587, loss_fp: 0.500212, loss_freq: 0.501293
[14:43:04.551] iteration 1154: loss: 0.944165, loss_s1: 0.504506, loss_fp: 0.500382, loss_freq: 0.501575
[14:43:05.178] iteration 1155: loss: 0.945621, loss_s1: 0.506390, loss_fp: 0.500153, loss_freq: 0.504302
[14:43:05.801] iteration 1156: loss: 0.890838, loss_s1: 0.503935, loss_fp: 0.500046, loss_freq: 0.500867
[14:43:06.424] iteration 1157: loss: 0.881753, loss_s1: 0.510504, loss_fp: 0.500194, loss_freq: 0.501829
[14:43:07.048] iteration 1158: loss: 0.869472, loss_s1: 0.508307, loss_fp: 0.500523, loss_freq: 0.504405
[14:43:07.674] iteration 1159: loss: 0.909915, loss_s1: 0.505245, loss_fp: 0.500162, loss_freq: 0.504630
[14:43:08.300] iteration 1160: loss: 0.852316, loss_s1: 0.501402, loss_fp: 0.500268, loss_freq: 0.506367
[14:43:08.921] iteration 1161: loss: 0.897595, loss_s1: 0.501729, loss_fp: 0.500463, loss_freq: 0.501829
[14:43:09.550] iteration 1162: loss: 0.977352, loss_s1: 0.502699, loss_fp: 0.500201, loss_freq: 0.501248
[14:43:10.172] iteration 1163: loss: 0.903425, loss_s1: 0.503575, loss_fp: 0.500091, loss_freq: 0.500628
[14:43:10.797] iteration 1164: loss: 0.881205, loss_s1: 0.503426, loss_fp: 0.500235, loss_freq: 0.504863
[14:43:11.428] iteration 1165: loss: 0.908586, loss_s1: 0.504442, loss_fp: 0.500077, loss_freq: 0.503464
[14:43:12.054] iteration 1166: loss: 0.917473, loss_s1: 0.503269, loss_fp: 0.500250, loss_freq: 0.501019
[14:43:12.675] iteration 1167: loss: 0.921778, loss_s1: 0.506352, loss_fp: 0.500290, loss_freq: 0.503672
[14:43:13.302] iteration 1168: loss: 0.929870, loss_s1: 0.505106, loss_fp: 0.500190, loss_freq: 0.503394
[14:43:13.922] iteration 1169: loss: 0.856396, loss_s1: 0.503415, loss_fp: 0.500468, loss_freq: 0.501077
[14:43:14.549] iteration 1170: loss: 0.878641, loss_s1: 0.505516, loss_fp: 0.500156, loss_freq: 0.504437
[14:43:15.170] iteration 1171: loss: 0.817903, loss_s1: 0.502433, loss_fp: 0.500608, loss_freq: 0.502334
[14:43:15.797] iteration 1172: loss: 0.883254, loss_s1: 0.507075, loss_fp: 0.500427, loss_freq: 0.505459
[14:43:16.423] iteration 1173: loss: 0.908691, loss_s1: 0.505146, loss_fp: 0.500094, loss_freq: 0.505228
[14:43:17.050] iteration 1174: loss: 0.889746, loss_s1: 0.501229, loss_fp: 0.500171, loss_freq: 0.501940
[14:43:17.676] iteration 1175: loss: 0.836068, loss_s1: 0.504113, loss_fp: 0.500288, loss_freq: 0.505374
[14:43:18.298] iteration 1176: loss: 0.888784, loss_s1: 0.501612, loss_fp: 0.500170, loss_freq: 0.501489
[14:43:18.919] iteration 1177: loss: 0.840027, loss_s1: 0.502825, loss_fp: 0.500281, loss_freq: 0.502465
[14:43:19.543] iteration 1178: loss: 0.844885, loss_s1: 0.504969, loss_fp: 0.500182, loss_freq: 0.502833
[14:43:20.166] iteration 1179: loss: 0.996191, loss_s1: 0.503223, loss_fp: 0.500344, loss_freq: 0.501546
[14:43:20.792] iteration 1180: loss: 0.841555, loss_s1: 0.501565, loss_fp: 0.500085, loss_freq: 0.502283
[14:43:21.419] iteration 1181: loss: 0.931637, loss_s1: 0.503585, loss_fp: 0.500238, loss_freq: 0.501481
[14:43:22.043] iteration 1182: loss: 0.877670, loss_s1: 0.503079, loss_fp: 0.500095, loss_freq: 0.501654
[14:43:22.672] iteration 1183: loss: 0.889559, loss_s1: 0.503033, loss_fp: 0.500137, loss_freq: 0.503241
[14:43:23.298] iteration 1184: loss: 0.879314, loss_s1: 0.502692, loss_fp: 0.500163, loss_freq: 0.502942
[14:43:23.926] iteration 1185: loss: 0.926416, loss_s1: 0.503296, loss_fp: 0.500222, loss_freq: 0.501991
[14:43:24.548] iteration 1186: loss: 0.899080, loss_s1: 0.502982, loss_fp: 0.500162, loss_freq: 0.502010
[14:43:25.214] iteration 1187: loss: 0.860002, loss_s1: 0.504560, loss_fp: 0.500252, loss_freq: 0.500639
[14:43:25.836] iteration 1188: loss: 0.850857, loss_s1: 0.504277, loss_fp: 0.500290, loss_freq: 0.500504
[14:43:26.457] iteration 1189: loss: 0.880970, loss_s1: 0.505859, loss_fp: 0.500167, loss_freq: 0.501683
[14:43:27.079] iteration 1190: loss: 0.868967, loss_s1: 0.502978, loss_fp: 0.500135, loss_freq: 0.501912
[14:43:27.699] iteration 1191: loss: 0.884641, loss_s1: 0.505002, loss_fp: 0.500124, loss_freq: 0.503547
[14:43:28.323] iteration 1192: loss: 0.869499, loss_s1: 0.503107, loss_fp: 0.500387, loss_freq: 0.500694
[14:43:28.945] iteration 1193: loss: 0.886062, loss_s1: 0.504472, loss_fp: 0.500095, loss_freq: 0.503713
[14:43:29.569] iteration 1194: loss: 0.880359, loss_s1: 0.502377, loss_fp: 0.500421, loss_freq: 0.504144
[14:43:30.192] iteration 1195: loss: 0.816268, loss_s1: 0.502539, loss_fp: 0.500255, loss_freq: 0.500550
[14:43:30.812] iteration 1196: loss: 0.871196, loss_s1: 0.503986, loss_fp: 0.500211, loss_freq: 0.503404
[14:43:31.439] iteration 1197: loss: 0.940148, loss_s1: 0.505713, loss_fp: 0.500183, loss_freq: 0.502827
[14:43:32.060] iteration 1198: loss: 0.891594, loss_s1: 0.503279, loss_fp: 0.500151, loss_freq: 0.501039
[14:43:32.688] iteration 1199: loss: 0.866423, loss_s1: 0.507225, loss_fp: 0.500296, loss_freq: 0.502431
[14:43:33.312] iteration 1200: loss: 0.892067, loss_s1: 0.503195, loss_fp: 0.500096, loss_freq: 0.502672
[14:43:36.024] iteration 1200 : mean_dice : 0.173412
[14:43:36.685] iteration 1201: loss: 0.902256, loss_s1: 0.504942, loss_fp: 0.500054, loss_freq: 0.502769
[14:43:37.310] iteration 1202: loss: 0.902529, loss_s1: 0.504802, loss_fp: 0.500072, loss_freq: 0.505290
[14:43:37.937] iteration 1203: loss: 0.901836, loss_s1: 0.509798, loss_fp: 0.500135, loss_freq: 0.505560
[14:43:38.560] iteration 1204: loss: 0.913469, loss_s1: 0.501442, loss_fp: 0.501490, loss_freq: 0.503412
[14:43:39.177] iteration 1205: loss: 0.857382, loss_s1: 0.502950, loss_fp: 0.500281, loss_freq: 0.501791
[14:43:39.799] iteration 1206: loss: 0.807469, loss_s1: 0.504094, loss_fp: 0.420346, loss_freq: 0.497807
[14:43:40.424] iteration 1207: loss: 0.892367, loss_s1: 0.505383, loss_fp: 0.500171, loss_freq: 0.502082
[14:43:41.049] iteration 1208: loss: 0.949409, loss_s1: 0.504591, loss_fp: 0.500102, loss_freq: 0.503869
[14:43:41.675] iteration 1209: loss: 0.891236, loss_s1: 0.506373, loss_fp: 0.500034, loss_freq: 0.501472
[14:43:42.301] iteration 1210: loss: 0.824430, loss_s1: 0.504044, loss_fp: 0.500034, loss_freq: 0.504173
[14:43:42.926] iteration 1211: loss: 0.893448, loss_s1: 0.505504, loss_fp: 0.500032, loss_freq: 0.501616
[14:43:43.547] iteration 1212: loss: 0.849278, loss_s1: 0.503685, loss_fp: 0.500154, loss_freq: 0.501330
[14:43:44.169] iteration 1213: loss: 0.849903, loss_s1: 0.503798, loss_fp: 0.500065, loss_freq: 0.500793
[14:43:44.789] iteration 1214: loss: 0.991626, loss_s1: 0.501022, loss_fp: 0.500045, loss_freq: 0.502261
[14:43:45.412] iteration 1215: loss: 0.905851, loss_s1: 0.503109, loss_fp: 0.500033, loss_freq: 0.501267
[14:43:46.035] iteration 1216: loss: 0.895827, loss_s1: 0.504117, loss_fp: 0.500148, loss_freq: 0.502245
[14:43:46.676] iteration 1217: loss: 0.871597, loss_s1: 0.503165, loss_fp: 0.500036, loss_freq: 0.501016
[14:43:47.302] iteration 1218: loss: 0.951971, loss_s1: 0.502389, loss_fp: 0.500036, loss_freq: 0.500565
[14:43:47.927] iteration 1219: loss: 0.882338, loss_s1: 0.502705, loss_fp: 0.500486, loss_freq: 0.501947
[14:43:48.549] iteration 1220: loss: 0.968427, loss_s1: 0.501606, loss_fp: 0.500030, loss_freq: 0.501002
[14:43:49.172] iteration 1221: loss: 0.868483, loss_s1: 0.502185, loss_fp: 0.500040, loss_freq: 0.500840
[14:43:49.793] iteration 1222: loss: 0.842910, loss_s1: 0.504150, loss_fp: 0.500031, loss_freq: 0.502766
[14:43:50.409] iteration 1223: loss: 0.855708, loss_s1: 0.501492, loss_fp: 0.500043, loss_freq: 0.503512
[14:43:51.031] iteration 1224: loss: 0.866500, loss_s1: 0.458255, loss_fp: 0.500033, loss_freq: 0.501566
[14:43:51.653] iteration 1225: loss: 0.891313, loss_s1: 0.502591, loss_fp: 0.500116, loss_freq: 0.502400
[14:43:52.279] iteration 1226: loss: 0.884052, loss_s1: 0.502903, loss_fp: 0.500056, loss_freq: 0.504005
[14:43:52.906] iteration 1227: loss: 0.610545, loss_s1: 0.458990, loss_fp: 0.138874, loss_freq: 0.414509
[14:43:53.533] iteration 1228: loss: 0.830579, loss_s1: 0.502177, loss_fp: 0.500030, loss_freq: 0.501528
[14:43:54.159] iteration 1229: loss: 0.862770, loss_s1: 0.502251, loss_fp: 0.500109, loss_freq: 0.502083
[14:43:54.781] iteration 1230: loss: 0.820489, loss_s1: 0.502841, loss_fp: 0.500070, loss_freq: 0.501740
[14:43:55.406] iteration 1231: loss: 0.866000, loss_s1: 0.500796, loss_fp: 0.500052, loss_freq: 0.500501
[14:43:56.033] iteration 1232: loss: 0.936648, loss_s1: 0.501852, loss_fp: 0.500101, loss_freq: 0.502982
[14:43:56.651] iteration 1233: loss: 0.923865, loss_s1: 0.500479, loss_fp: 0.500009, loss_freq: 0.500147
[14:43:57.274] iteration 1234: loss: 0.852019, loss_s1: 0.501582, loss_fp: 0.500067, loss_freq: 0.501396
[14:43:57.900] iteration 1235: loss: 0.879309, loss_s1: 0.501483, loss_fp: 0.500044, loss_freq: 0.502007
[14:43:58.523] iteration 1236: loss: 0.901605, loss_s1: 0.501560, loss_fp: 0.500014, loss_freq: 0.502790
[14:43:59.147] iteration 1237: loss: 0.956745, loss_s1: 0.501738, loss_fp: 0.500073, loss_freq: 0.501901
[14:43:59.771] iteration 1238: loss: 0.916524, loss_s1: 0.502033, loss_fp: 0.500015, loss_freq: 0.502243
[14:44:00.393] iteration 1239: loss: 0.839956, loss_s1: 0.502491, loss_fp: 0.500241, loss_freq: 0.503187
[14:44:01.013] iteration 1240: loss: 0.886909, loss_s1: 0.504955, loss_fp: 0.500010, loss_freq: 0.502519
[14:44:01.677] iteration 1241: loss: 0.844169, loss_s1: 0.504734, loss_fp: 0.500008, loss_freq: 0.503718
[14:44:02.302] iteration 1242: loss: 0.902769, loss_s1: 0.502700, loss_fp: 0.500007, loss_freq: 0.500859
[14:44:02.932] iteration 1243: loss: 0.904508, loss_s1: 0.505035, loss_fp: 0.500274, loss_freq: 0.503333
[14:44:03.553] iteration 1244: loss: 0.860152, loss_s1: 0.506544, loss_fp: 0.500059, loss_freq: 0.502969
[14:44:04.176] iteration 1245: loss: 0.835774, loss_s1: 0.505346, loss_fp: 0.500060, loss_freq: 0.501536
[14:44:04.801] iteration 1246: loss: 0.897233, loss_s1: 0.505215, loss_fp: 0.500047, loss_freq: 0.504238
[14:44:05.431] iteration 1247: loss: 0.864339, loss_s1: 0.504523, loss_fp: 0.500031, loss_freq: 0.501314
[14:44:06.055] iteration 1248: loss: 0.870887, loss_s1: 0.502623, loss_fp: 0.500026, loss_freq: 0.502270
[14:44:06.677] iteration 1249: loss: 0.679453, loss_s1: 0.500175, loss_fp: 0.035834, loss_freq: 0.400323
[14:44:07.299] iteration 1250: loss: 0.905645, loss_s1: 0.502265, loss_fp: 0.500030, loss_freq: 0.501885
[14:44:07.930] iteration 1251: loss: 0.857993, loss_s1: 0.502219, loss_fp: 0.500095, loss_freq: 0.501879
[14:44:08.558] iteration 1252: loss: 0.913720, loss_s1: 0.501295, loss_fp: 0.500019, loss_freq: 0.500174
[14:44:09.179] iteration 1253: loss: 0.949282, loss_s1: 0.501397, loss_fp: 0.500012, loss_freq: 0.501211
[14:44:09.803] iteration 1254: loss: 0.957025, loss_s1: 0.502272, loss_fp: 0.500018, loss_freq: 0.501524
[14:44:10.431] iteration 1255: loss: 0.974970, loss_s1: 0.501705, loss_fp: 0.500078, loss_freq: 0.501909
[14:44:11.053] iteration 1256: loss: 0.919497, loss_s1: 0.503517, loss_fp: 0.500046, loss_freq: 0.503110
[14:44:11.675] iteration 1257: loss: 0.847217, loss_s1: 0.504464, loss_fp: 0.500026, loss_freq: 0.501911
[14:44:12.295] iteration 1258: loss: 0.861134, loss_s1: 0.507986, loss_fp: 0.500018, loss_freq: 0.501673
[14:44:12.919] iteration 1259: loss: 0.941503, loss_s1: 0.505115, loss_fp: 0.500046, loss_freq: 0.504724
[14:44:13.547] iteration 1260: loss: 0.936671, loss_s1: 0.504181, loss_fp: 0.500030, loss_freq: 0.501783
[14:44:14.171] iteration 1261: loss: 0.897541, loss_s1: 0.505545, loss_fp: 0.500059, loss_freq: 0.501077
[14:44:14.795] iteration 1262: loss: 0.560260, loss_s1: 0.422577, loss_fp: 0.054706, loss_freq: 0.357768
[14:44:15.421] iteration 1263: loss: 0.843627, loss_s1: 0.503303, loss_fp: 0.500176, loss_freq: 0.501779
[14:44:16.047] iteration 1264: loss: 0.904567, loss_s1: 0.501595, loss_fp: 0.500096, loss_freq: 0.500642
[14:44:16.671] iteration 1265: loss: 0.853415, loss_s1: 0.501231, loss_fp: 0.500015, loss_freq: 0.500147
[14:44:17.293] iteration 1266: loss: 0.915753, loss_s1: 0.502420, loss_fp: 0.500059, loss_freq: 0.500270
[14:44:17.911] iteration 1267: loss: 0.975447, loss_s1: 0.502369, loss_fp: 0.500039, loss_freq: 0.501648
[14:44:18.537] iteration 1268: loss: 0.906216, loss_s1: 0.503668, loss_fp: 0.500040, loss_freq: 0.500250
[14:44:19.161] iteration 1269: loss: 0.889599, loss_s1: 0.505030, loss_fp: 0.500072, loss_freq: 0.501745
[14:44:19.785] iteration 1270: loss: 0.881427, loss_s1: 0.502324, loss_fp: 0.500039, loss_freq: 0.500412
[14:44:20.411] iteration 1271: loss: 0.931124, loss_s1: 0.505155, loss_fp: 0.500016, loss_freq: 0.503029
[14:44:21.038] iteration 1272: loss: 0.908772, loss_s1: 0.504243, loss_fp: 0.500073, loss_freq: 0.501472
[14:44:21.663] iteration 1273: loss: 0.908321, loss_s1: 0.505216, loss_fp: 0.500028, loss_freq: 0.502599
[14:44:22.288] iteration 1274: loss: 0.891289, loss_s1: 0.505642, loss_fp: 0.500070, loss_freq: 0.503046
[14:44:22.906] iteration 1275: loss: 0.881222, loss_s1: 0.502799, loss_fp: 0.500020, loss_freq: 0.500870
[14:44:23.531] iteration 1276: loss: 0.862697, loss_s1: 0.503433, loss_fp: 0.500100, loss_freq: 0.504725
[14:44:24.151] iteration 1277: loss: 0.885013, loss_s1: 0.506528, loss_fp: 0.500027, loss_freq: 0.504095
[14:44:24.777] iteration 1278: loss: 0.906239, loss_s1: 0.505578, loss_fp: 0.500055, loss_freq: 0.506383
[14:44:25.396] iteration 1279: loss: 0.891908, loss_s1: 0.506336, loss_fp: 0.500091, loss_freq: 0.501978
[14:44:26.021] iteration 1280: loss: 0.844916, loss_s1: 0.502884, loss_fp: 0.500034, loss_freq: 0.504248
[14:44:26.644] iteration 1281: loss: 0.882271, loss_s1: 0.502466, loss_fp: 0.500036, loss_freq: 0.503552
[14:44:27.285] iteration 1282: loss: 0.864640, loss_s1: 0.508393, loss_fp: 0.500083, loss_freq: 0.502170
[14:44:27.907] iteration 1283: loss: 0.902486, loss_s1: 0.502576, loss_fp: 0.500019, loss_freq: 0.505426
[14:44:28.545] iteration 1284: loss: 0.933452, loss_s1: 0.505240, loss_fp: 0.500089, loss_freq: 0.501608
[14:44:29.177] iteration 1285: loss: 0.852190, loss_s1: 0.509427, loss_fp: 0.500141, loss_freq: 0.504337
[14:44:29.820] iteration 1286: loss: 0.884972, loss_s1: 0.504776, loss_fp: 0.500221, loss_freq: 0.501854
[14:44:30.479] iteration 1287: loss: 0.879059, loss_s1: 0.505023, loss_fp: 0.500223, loss_freq: 0.500923
[14:44:31.108] iteration 1288: loss: 0.783733, loss_s1: 0.494979, loss_fp: 0.259494, loss_freq: 0.485513
[14:44:32.038] iteration 1289: loss: 0.889880, loss_s1: 0.504278, loss_fp: 0.500059, loss_freq: 0.501043
[14:44:32.667] iteration 1290: loss: 0.897131, loss_s1: 0.507337, loss_fp: 0.500370, loss_freq: 0.502911
[14:44:33.295] iteration 1291: loss: 0.973619, loss_s1: 0.506052, loss_fp: 0.500225, loss_freq: 0.500965
[14:44:33.923] iteration 1292: loss: 0.992382, loss_s1: 0.506388, loss_fp: 0.500015, loss_freq: 0.504168
[14:44:34.559] iteration 1293: loss: 0.962729, loss_s1: 0.505128, loss_fp: 0.500037, loss_freq: 0.504808
[14:44:35.191] iteration 1294: loss: 0.933141, loss_s1: 0.505381, loss_fp: 0.500056, loss_freq: 0.503181
[14:44:35.817] iteration 1295: loss: 0.903103, loss_s1: 0.503684, loss_fp: 0.500138, loss_freq: 0.502277
[14:44:36.449] iteration 1296: loss: 0.876489, loss_s1: 0.503151, loss_fp: 0.500106, loss_freq: 0.501059
[14:44:37.072] iteration 1297: loss: 0.859399, loss_s1: 0.505032, loss_fp: 0.500018, loss_freq: 0.501208
[14:44:37.697] iteration 1298: loss: 1.001108, loss_s1: 0.508031, loss_fp: 0.500077, loss_freq: 0.504294
[14:44:38.320] iteration 1299: loss: 0.928891, loss_s1: 0.502257, loss_fp: 0.500024, loss_freq: 0.504110
[14:44:38.949] iteration 1300: loss: 0.909610, loss_s1: 0.508444, loss_fp: 0.500035, loss_freq: 0.503818
[14:44:39.572] iteration 1301: loss: 0.839334, loss_s1: 0.502662, loss_fp: 0.500027, loss_freq: 0.500883
[14:44:40.202] iteration 1302: loss: 0.945286, loss_s1: 0.504259, loss_fp: 0.500093, loss_freq: 0.505528
[14:44:40.832] iteration 1303: loss: 0.838116, loss_s1: 0.504855, loss_fp: 0.500091, loss_freq: 0.500602
[14:44:41.461] iteration 1304: loss: 0.882577, loss_s1: 0.506181, loss_fp: 0.500023, loss_freq: 0.502681
[14:44:42.089] iteration 1305: loss: 0.611100, loss_s1: 0.467538, loss_fp: 0.029764, loss_freq: 0.347956
[14:44:42.719] iteration 1306: loss: 0.870524, loss_s1: 0.504266, loss_fp: 0.500098, loss_freq: 0.501041
[14:44:43.340] iteration 1307: loss: 0.937267, loss_s1: 0.504361, loss_fp: 0.500124, loss_freq: 0.500788
[14:44:43.966] iteration 1308: loss: 0.898225, loss_s1: 0.502292, loss_fp: 0.500030, loss_freq: 0.502512
[14:44:44.585] iteration 1309: loss: 0.931003, loss_s1: 0.505844, loss_fp: 0.500160, loss_freq: 0.500351
[14:44:45.213] iteration 1310: loss: 0.915169, loss_s1: 0.503915, loss_fp: 0.500099, loss_freq: 0.501734
[14:44:45.834] iteration 1311: loss: 0.961186, loss_s1: 0.502123, loss_fp: 0.500008, loss_freq: 0.500795
[14:44:46.462] iteration 1312: loss: 0.891060, loss_s1: 0.503467, loss_fp: 0.500017, loss_freq: 0.503904
[14:44:47.084] iteration 1313: loss: 0.861505, loss_s1: 0.505224, loss_fp: 0.500022, loss_freq: 0.501376
[14:44:47.710] iteration 1314: loss: 0.838670, loss_s1: 0.503219, loss_fp: 0.500047, loss_freq: 0.500759
[14:44:48.333] iteration 1315: loss: 0.934723, loss_s1: 0.506811, loss_fp: 0.500033, loss_freq: 0.501992
[14:44:48.961] iteration 1316: loss: 0.933852, loss_s1: 0.507652, loss_fp: 0.500062, loss_freq: 0.503851
[14:44:49.584] iteration 1317: loss: 0.878962, loss_s1: 0.504065, loss_fp: 0.500058, loss_freq: 0.501582
[14:44:50.213] iteration 1318: loss: 0.852221, loss_s1: 0.505024, loss_fp: 0.500097, loss_freq: 0.502015
[14:44:50.923] iteration 1319: loss: 0.875235, loss_s1: 0.502610, loss_fp: 0.500144, loss_freq: 0.501767
[14:44:51.593] iteration 1320: loss: 0.941201, loss_s1: 0.504709, loss_fp: 0.500089, loss_freq: 0.502783
[14:44:52.212] iteration 1321: loss: 0.895588, loss_s1: 0.504652, loss_fp: 0.500032, loss_freq: 0.503971
[14:44:52.833] iteration 1322: loss: 0.909442, loss_s1: 0.502634, loss_fp: 0.500028, loss_freq: 0.502244
[14:44:53.449] iteration 1323: loss: 0.926217, loss_s1: 0.503636, loss_fp: 0.500017, loss_freq: 0.502729
[14:44:54.072] iteration 1324: loss: 0.931084, loss_s1: 0.505295, loss_fp: 0.500244, loss_freq: 0.500924
[14:44:54.692] iteration 1325: loss: 0.898688, loss_s1: 0.502847, loss_fp: 0.500503, loss_freq: 0.503663
[14:44:55.318] iteration 1326: loss: 0.881935, loss_s1: 0.505281, loss_fp: 0.500045, loss_freq: 0.503873
[14:44:55.941] iteration 1327: loss: 0.892529, loss_s1: 0.504932, loss_fp: 0.500036, loss_freq: 0.502266
[14:44:56.568] iteration 1328: loss: 0.941905, loss_s1: 0.504826, loss_fp: 0.500155, loss_freq: 0.503263
[14:44:57.193] iteration 1329: loss: 0.916992, loss_s1: 0.505061, loss_fp: 0.500073, loss_freq: 0.503004
[14:44:57.816] iteration 1330: loss: 0.877662, loss_s1: 0.503192, loss_fp: 0.500027, loss_freq: 0.501695
[14:44:58.440] iteration 1331: loss: 0.842205, loss_s1: 0.503934, loss_fp: 0.500047, loss_freq: 0.502273
[14:44:59.065] iteration 1332: loss: 0.875550, loss_s1: 0.504195, loss_fp: 0.500078, loss_freq: 0.502615
[14:44:59.691] iteration 1333: loss: 0.900643, loss_s1: 0.506715, loss_fp: 0.500035, loss_freq: 0.502887
[14:45:00.310] iteration 1334: loss: 0.875666, loss_s1: 0.503730, loss_fp: 0.500021, loss_freq: 0.506163
[14:45:00.936] iteration 1335: loss: 0.872739, loss_s1: 0.499467, loss_fp: 0.500063, loss_freq: 0.502937
[14:45:01.565] iteration 1336: loss: 0.838271, loss_s1: 0.503701, loss_fp: 0.500014, loss_freq: 0.503846
[14:45:02.190] iteration 1337: loss: 0.936329, loss_s1: 0.503859, loss_fp: 0.500044, loss_freq: 0.502742
[14:45:02.816] iteration 1338: loss: 0.842299, loss_s1: 0.506860, loss_fp: 0.500089, loss_freq: 0.503652
[14:45:03.436] iteration 1339: loss: 0.831129, loss_s1: 0.505675, loss_fp: 0.500685, loss_freq: 0.503839
[14:45:04.058] iteration 1340: loss: 0.967209, loss_s1: 0.503504, loss_fp: 0.500007, loss_freq: 0.505072
[14:45:04.678] iteration 1341: loss: 0.896537, loss_s1: 0.502987, loss_fp: 0.500032, loss_freq: 0.501412
[14:45:05.303] iteration 1342: loss: 0.874560, loss_s1: 0.505462, loss_fp: 0.500019, loss_freq: 0.501829
[14:45:05.925] iteration 1343: loss: 0.907244, loss_s1: 0.503855, loss_fp: 0.500047, loss_freq: 0.501472
[14:45:06.548] iteration 1344: loss: 0.879978, loss_s1: 0.507507, loss_fp: 0.500032, loss_freq: 0.502699
[14:45:07.179] iteration 1345: loss: 0.868980, loss_s1: 0.503923, loss_fp: 0.500018, loss_freq: 0.503966
[14:45:07.805] iteration 1346: loss: 0.937632, loss_s1: 0.504006, loss_fp: 0.500039, loss_freq: 0.503410
[14:45:08.431] iteration 1347: loss: 0.885631, loss_s1: 0.501543, loss_fp: 0.500034, loss_freq: 0.502061
[14:45:09.057] iteration 1348: loss: 0.853934, loss_s1: 0.501680, loss_fp: 0.500013, loss_freq: 0.500385
[14:45:09.682] iteration 1349: loss: 0.857726, loss_s1: 0.504073, loss_fp: 0.500069, loss_freq: 0.500780
[14:45:10.317] iteration 1350: loss: 0.860465, loss_s1: 0.506065, loss_fp: 0.500142, loss_freq: 0.501089
[14:45:10.941] iteration 1351: loss: 0.864777, loss_s1: 0.502189, loss_fp: 0.500081, loss_freq: 0.501264
[14:45:11.565] iteration 1352: loss: 0.899850, loss_s1: 0.506145, loss_fp: 0.500254, loss_freq: 0.503447
[14:45:12.189] iteration 1353: loss: 0.866022, loss_s1: 0.503663, loss_fp: 0.500045, loss_freq: 0.500324
[14:45:12.814] iteration 1354: loss: 0.832781, loss_s1: 0.506737, loss_fp: 0.500039, loss_freq: 0.501579
[14:45:13.435] iteration 1355: loss: 0.904727, loss_s1: 0.505743, loss_fp: 0.500033, loss_freq: 0.503510
[14:45:14.055] iteration 1356: loss: 0.829777, loss_s1: 0.503070, loss_fp: 0.500174, loss_freq: 0.500580
[14:45:14.678] iteration 1357: loss: 0.879555, loss_s1: 0.503244, loss_fp: 0.500023, loss_freq: 0.502536
[14:45:15.307] iteration 1358: loss: 0.978658, loss_s1: 0.509291, loss_fp: 0.500020, loss_freq: 0.502846
[14:45:15.935] iteration 1359: loss: 0.885512, loss_s1: 0.502564, loss_fp: 0.500124, loss_freq: 0.501744
[14:45:16.579] iteration 1360: loss: 0.872442, loss_s1: 0.503425, loss_fp: 0.500601, loss_freq: 0.502884
[14:45:17.210] iteration 1361: loss: 0.900158, loss_s1: 0.503872, loss_fp: 0.500024, loss_freq: 0.503281
[14:45:17.835] iteration 1362: loss: 0.863220, loss_s1: 0.505987, loss_fp: 0.500051, loss_freq: 0.503300
[14:45:18.465] iteration 1363: loss: 0.884436, loss_s1: 0.507491, loss_fp: 0.500012, loss_freq: 0.504009
[14:45:19.099] iteration 1364: loss: 0.877648, loss_s1: 0.502921, loss_fp: 0.500021, loss_freq: 0.502762
[14:45:19.717] iteration 1365: loss: 0.906957, loss_s1: 0.502000, loss_fp: 0.500067, loss_freq: 0.502398
[14:45:20.342] iteration 1366: loss: 0.852950, loss_s1: 0.504125, loss_fp: 0.500013, loss_freq: 0.501193
[14:45:20.972] iteration 1367: loss: 0.658971, loss_s1: 0.491253, loss_fp: 0.184951, loss_freq: 0.478082
[14:45:21.595] iteration 1368: loss: 0.851192, loss_s1: 0.503745, loss_fp: 0.500006, loss_freq: 0.501195
[14:45:22.225] iteration 1369: loss: 0.869619, loss_s1: 0.507476, loss_fp: 0.500024, loss_freq: 0.502349
[14:45:22.852] iteration 1370: loss: 0.866104, loss_s1: 0.504634, loss_fp: 0.500022, loss_freq: 0.502919
[14:45:23.482] iteration 1371: loss: 0.839724, loss_s1: 0.505757, loss_fp: 0.500007, loss_freq: 0.504438
[14:45:24.114] iteration 1372: loss: 0.949809, loss_s1: 0.504499, loss_fp: 0.500020, loss_freq: 0.502124
[14:45:24.737] iteration 1373: loss: 0.842264, loss_s1: 0.505527, loss_fp: 0.500065, loss_freq: 0.503597
[14:45:25.363] iteration 1374: loss: 0.842329, loss_s1: 0.506538, loss_fp: 0.500009, loss_freq: 0.502400
[14:45:25.991] iteration 1375: loss: 1.057163, loss_s1: 0.502699, loss_fp: 0.500008, loss_freq: 0.502934
[14:45:26.631] iteration 1376: loss: 0.877101, loss_s1: 0.501434, loss_fp: 0.500008, loss_freq: 0.500916
[14:45:27.273] iteration 1377: loss: 0.913764, loss_s1: 0.504617, loss_fp: 0.500008, loss_freq: 0.501717
[14:45:27.910] iteration 1378: loss: 0.902881, loss_s1: 0.504363, loss_fp: 0.500032, loss_freq: 0.500866
[14:45:28.548] iteration 1379: loss: 0.932792, loss_s1: 0.502053, loss_fp: 0.500044, loss_freq: 0.500774
[14:45:29.188] iteration 1380: loss: 0.893407, loss_s1: 0.503465, loss_fp: 0.500030, loss_freq: 0.503504
[14:45:29.824] iteration 1381: loss: 0.990758, loss_s1: 0.504187, loss_fp: 0.500019, loss_freq: 0.502244
[14:45:30.458] iteration 1382: loss: 0.874421, loss_s1: 0.502978, loss_fp: 0.500014, loss_freq: 0.502137
[14:45:31.095] iteration 1383: loss: 0.870032, loss_s1: 0.503844, loss_fp: 0.500018, loss_freq: 0.501482
[14:45:31.732] iteration 1384: loss: 0.852444, loss_s1: 0.505112, loss_fp: 0.500025, loss_freq: 0.504443
[14:45:32.371] iteration 1385: loss: 0.846085, loss_s1: 0.503617, loss_fp: 0.500031, loss_freq: 0.501946
[14:45:33.002] iteration 1386: loss: 0.883344, loss_s1: 0.501781, loss_fp: 0.500011, loss_freq: 0.502699
[14:45:33.633] iteration 1387: loss: 0.874531, loss_s1: 0.502862, loss_fp: 0.500028, loss_freq: 0.502441
[14:45:34.264] iteration 1388: loss: 0.818977, loss_s1: 0.505579, loss_fp: 0.500026, loss_freq: 0.501397
[14:45:34.891] iteration 1389: loss: 0.841563, loss_s1: 0.506522, loss_fp: 0.500086, loss_freq: 0.501803
[14:45:35.518] iteration 1390: loss: 0.897577, loss_s1: 0.504146, loss_fp: 0.500028, loss_freq: 0.503551
[14:45:36.150] iteration 1391: loss: 0.860516, loss_s1: 0.509945, loss_fp: 0.500073, loss_freq: 0.505050
[14:45:36.779] iteration 1392: loss: 0.851916, loss_s1: 0.503433, loss_fp: 0.500052, loss_freq: 0.501689
[14:45:37.414] iteration 1393: loss: 0.688488, loss_s1: 0.480341, loss_fp: 0.037863, loss_freq: 0.456928
[14:45:38.037] iteration 1394: loss: 0.932962, loss_s1: 0.503313, loss_fp: 0.500037, loss_freq: 0.500711
[14:45:38.662] iteration 1395: loss: 0.857371, loss_s1: 0.509218, loss_fp: 0.500042, loss_freq: 0.503437
[14:45:39.286] iteration 1396: loss: 0.913026, loss_s1: 0.506890, loss_fp: 0.500033, loss_freq: 0.501928
[14:45:39.911] iteration 1397: loss: 0.926757, loss_s1: 0.505198, loss_fp: 0.500025, loss_freq: 0.506253
[14:45:40.535] iteration 1398: loss: 0.923943, loss_s1: 0.505828, loss_fp: 0.500038, loss_freq: 0.502039
[14:45:41.164] iteration 1399: loss: 0.949117, loss_s1: 0.503862, loss_fp: 0.500017, loss_freq: 0.503327
[14:45:41.785] iteration 1400: loss: 0.875413, loss_s1: 0.506178, loss_fp: 0.500121, loss_freq: 0.504363
[14:45:44.612] iteration 1400 : mean_dice : 0.324331
[14:45:45.248] iteration 1401: loss: 0.881943, loss_s1: 0.502008, loss_fp: 0.500071, loss_freq: 0.504364
[14:45:45.872] iteration 1402: loss: 0.843187, loss_s1: 0.503778, loss_fp: 0.500105, loss_freq: 0.502689
[14:45:46.497] iteration 1403: loss: 0.909600, loss_s1: 0.503741, loss_fp: 0.500016, loss_freq: 0.500950
[14:45:47.118] iteration 1404: loss: 0.852343, loss_s1: 0.503634, loss_fp: 0.500047, loss_freq: 0.503063
[14:45:47.744] iteration 1405: loss: 0.876096, loss_s1: 0.505800, loss_fp: 0.500020, loss_freq: 0.503310
[14:45:48.366] iteration 1406: loss: 0.830344, loss_s1: 0.504973, loss_fp: 0.500044, loss_freq: 0.504399
[14:45:48.988] iteration 1407: loss: 0.882239, loss_s1: 0.505175, loss_fp: 0.500049, loss_freq: 0.505798
[14:45:49.619] iteration 1408: loss: 0.854499, loss_s1: 0.504618, loss_fp: 0.500073, loss_freq: 0.503245
[14:45:50.241] iteration 1409: loss: 0.855980, loss_s1: 0.502545, loss_fp: 0.500025, loss_freq: 0.503347
[14:45:50.864] iteration 1410: loss: 0.701319, loss_s1: 0.478705, loss_fp: 0.084580, loss_freq: 0.461887
[14:45:51.487] iteration 1411: loss: 0.894640, loss_s1: 0.503234, loss_fp: 0.500098, loss_freq: 0.502699
[14:45:52.112] iteration 1412: loss: 0.896664, loss_s1: 0.504464, loss_fp: 0.500017, loss_freq: 0.501501
[14:45:52.742] iteration 1413: loss: 0.874446, loss_s1: 0.503838, loss_fp: 0.500049, loss_freq: 0.501487
[14:45:53.366] iteration 1414: loss: 0.885072, loss_s1: 0.501143, loss_fp: 0.500012, loss_freq: 0.502623
[14:45:53.991] iteration 1415: loss: 0.889941, loss_s1: 0.504091, loss_fp: 0.500015, loss_freq: 0.501222
[14:45:54.610] iteration 1416: loss: 0.965658, loss_s1: 0.505066, loss_fp: 0.500023, loss_freq: 0.501434
[14:45:55.231] iteration 1417: loss: 0.894063, loss_s1: 0.506025, loss_fp: 0.500003, loss_freq: 0.502917
[14:45:55.858] iteration 1418: loss: 0.826679, loss_s1: 0.504061, loss_fp: 0.500059, loss_freq: 0.500653
[14:45:56.484] iteration 1419: loss: 0.828434, loss_s1: 0.501543, loss_fp: 0.500032, loss_freq: 0.502311
[14:45:57.108] iteration 1420: loss: 0.931640, loss_s1: 0.504155, loss_fp: 0.500008, loss_freq: 0.502932
[14:45:57.729] iteration 1421: loss: 0.894029, loss_s1: 0.504792, loss_fp: 0.500028, loss_freq: 0.501441
[14:45:58.353] iteration 1422: loss: 0.947182, loss_s1: 0.510475, loss_fp: 0.500020, loss_freq: 0.501476
[14:45:58.980] iteration 1423: loss: 0.863908, loss_s1: 0.504835, loss_fp: 0.500008, loss_freq: 0.503810
[14:45:59.602] iteration 1424: loss: 0.867415, loss_s1: 0.504728, loss_fp: 0.500007, loss_freq: 0.507327
[14:46:00.225] iteration 1425: loss: 0.926846, loss_s1: 0.505687, loss_fp: 0.500006, loss_freq: 0.504541
[14:46:00.850] iteration 1426: loss: 0.821172, loss_s1: 0.507382, loss_fp: 0.500059, loss_freq: 0.502202
[14:46:01.476] iteration 1427: loss: 0.853723, loss_s1: 0.503252, loss_fp: 0.500011, loss_freq: 0.502435
[14:46:02.105] iteration 1428: loss: 0.928547, loss_s1: 0.502759, loss_fp: 0.500014, loss_freq: 0.502815
[14:46:02.724] iteration 1429: loss: 0.919535, loss_s1: 0.507577, loss_fp: 0.500008, loss_freq: 0.501190
[14:46:03.349] iteration 1430: loss: 0.656170, loss_s1: 0.481930, loss_fp: 0.079751, loss_freq: 0.473179
[14:46:03.967] iteration 1431: loss: 0.950547, loss_s1: 0.506325, loss_fp: 0.500002, loss_freq: 0.502009
[14:46:04.594] iteration 1432: loss: 0.978921, loss_s1: 0.502728, loss_fp: 0.500005, loss_freq: 0.504036
[14:46:05.216] iteration 1433: loss: 0.905684, loss_s1: 0.502458, loss_fp: 0.500012, loss_freq: 0.501367
[14:46:05.843] iteration 1434: loss: 0.652491, loss_s1: 0.471417, loss_fp: 0.021961, loss_freq: 0.387336
[14:46:06.470] iteration 1435: loss: 0.856096, loss_s1: 0.502816, loss_fp: 0.500019, loss_freq: 0.501846
[14:46:07.089] iteration 1436: loss: 0.867082, loss_s1: 0.503249, loss_fp: 0.500010, loss_freq: 0.500196
[14:46:07.712] iteration 1437: loss: 0.852207, loss_s1: 0.502890, loss_fp: 0.500008, loss_freq: 0.501330
[14:46:08.333] iteration 1438: loss: 0.871269, loss_s1: 0.502528, loss_fp: 0.375456, loss_freq: 0.496038
[14:46:08.960] iteration 1439: loss: 1.014661, loss_s1: 0.503381, loss_fp: 0.500012, loss_freq: 0.503371
[14:46:09.577] iteration 1440: loss: 0.875101, loss_s1: 0.501263, loss_fp: 0.500008, loss_freq: 0.500946
[14:46:10.200] iteration 1441: loss: 0.848037, loss_s1: 0.503183, loss_fp: 0.500018, loss_freq: 0.500768
[14:46:10.820] iteration 1442: loss: 0.927164, loss_s1: 0.503489, loss_fp: 0.500004, loss_freq: 0.500964
[14:46:11.441] iteration 1443: loss: 0.847484, loss_s1: 0.501400, loss_fp: 0.500019, loss_freq: 0.500726
[14:46:12.062] iteration 1444: loss: 0.854228, loss_s1: 0.503849, loss_fp: 0.500004, loss_freq: 0.501154
[14:46:12.682] iteration 1445: loss: 0.967910, loss_s1: 0.503918, loss_fp: 0.500003, loss_freq: 0.501352
[14:46:13.309] iteration 1446: loss: 0.865218, loss_s1: 0.504293, loss_fp: 0.500007, loss_freq: 0.503397
[14:46:13.928] iteration 1447: loss: 0.915597, loss_s1: 0.503629, loss_fp: 0.500004, loss_freq: 0.500956
[14:46:14.542] iteration 1448: loss: 0.881647, loss_s1: 0.504126, loss_fp: 0.500010, loss_freq: 0.501534
[14:46:15.159] iteration 1449: loss: 0.760530, loss_s1: 0.498684, loss_fp: 0.045491, loss_freq: 0.487502
[14:46:16.080] iteration 1450: loss: 0.836918, loss_s1: 0.459264, loss_fp: 0.500028, loss_freq: 0.500760
[14:46:16.704] iteration 1451: loss: 0.829507, loss_s1: 0.503395, loss_fp: 0.500013, loss_freq: 0.502213
[14:46:17.331] iteration 1452: loss: 0.948462, loss_s1: 0.503582, loss_fp: 0.500010, loss_freq: 0.502293
[14:46:17.956] iteration 1453: loss: 0.935771, loss_s1: 0.473208, loss_fp: 0.500008, loss_freq: 0.502131
[14:46:18.579] iteration 1454: loss: 0.946803, loss_s1: 0.501920, loss_fp: 0.500001, loss_freq: 0.502268
[14:46:19.208] iteration 1455: loss: 0.914016, loss_s1: 0.503368, loss_fp: 0.500003, loss_freq: 0.503835
[14:46:19.822] iteration 1456: loss: 0.873498, loss_s1: 0.502576, loss_fp: 0.500009, loss_freq: 0.501008
[14:46:20.444] iteration 1457: loss: 0.871909, loss_s1: 0.502828, loss_fp: 0.500002, loss_freq: 0.501261
[14:46:21.068] iteration 1458: loss: 0.826046, loss_s1: 0.504402, loss_fp: 0.500000, loss_freq: 0.501020
[14:46:21.690] iteration 1459: loss: 0.868020, loss_s1: 0.506087, loss_fp: 0.500010, loss_freq: 0.503429
[14:46:22.318] iteration 1460: loss: 0.962388, loss_s1: 0.502712, loss_fp: 0.499999, loss_freq: 0.505025
[14:46:22.937] iteration 1461: loss: 0.899593, loss_s1: 0.503150, loss_fp: 0.500008, loss_freq: 0.503914
[14:46:23.558] iteration 1462: loss: 0.824774, loss_s1: 0.503513, loss_fp: 0.500002, loss_freq: 0.501169
[14:46:24.181] iteration 1463: loss: 0.929392, loss_s1: 0.505292, loss_fp: 0.500002, loss_freq: 0.502833
[14:46:24.802] iteration 1464: loss: 0.850502, loss_s1: 0.504131, loss_fp: 0.500041, loss_freq: 0.501625
[14:46:25.426] iteration 1465: loss: 0.854887, loss_s1: 0.502509, loss_fp: 0.500005, loss_freq: 0.501731
[14:46:26.049] iteration 1466: loss: 0.652272, loss_s1: 0.493451, loss_fp: 0.011949, loss_freq: 0.315937
[14:46:26.673] iteration 1467: loss: 0.880534, loss_s1: 0.503678, loss_fp: 0.500003, loss_freq: 0.500503
[14:46:27.297] iteration 1468: loss: 0.906343, loss_s1: 0.503277, loss_fp: 0.500002, loss_freq: 0.500435
[14:46:27.917] iteration 1469: loss: 0.886795, loss_s1: 0.501375, loss_fp: 0.500002, loss_freq: 0.500797
[14:46:28.538] iteration 1470: loss: 0.904406, loss_s1: 0.502717, loss_fp: 0.500006, loss_freq: 0.502717
[14:46:29.162] iteration 1471: loss: 0.937100, loss_s1: 0.503054, loss_fp: 0.500021, loss_freq: 0.501116
[14:46:29.787] iteration 1472: loss: 0.948529, loss_s1: 0.501453, loss_fp: 0.500001, loss_freq: 0.500430
[14:46:30.409] iteration 1473: loss: 0.892776, loss_s1: 0.501959, loss_fp: 0.500158, loss_freq: 0.501822
[14:46:31.029] iteration 1474: loss: 0.843162, loss_s1: 0.502729, loss_fp: 0.500004, loss_freq: 0.502276
[14:46:31.653] iteration 1475: loss: 0.840163, loss_s1: 0.504245, loss_fp: 0.500008, loss_freq: 0.500536
[14:46:32.275] iteration 1476: loss: 0.852423, loss_s1: 0.503152, loss_fp: 0.500007, loss_freq: 0.500689
[14:46:32.900] iteration 1477: loss: 0.922123, loss_s1: 0.505992, loss_fp: 0.500020, loss_freq: 0.503354
[14:46:33.522] iteration 1478: loss: 0.941717, loss_s1: 0.501175, loss_fp: 0.500001, loss_freq: 0.501483
[14:46:34.139] iteration 1479: loss: 0.886392, loss_s1: 0.504416, loss_fp: 0.500005, loss_freq: 0.501204
[14:46:34.765] iteration 1480: loss: 0.837288, loss_s1: 0.506551, loss_fp: 0.500006, loss_freq: 0.501763
[14:46:35.389] iteration 1481: loss: 0.901024, loss_s1: 0.505842, loss_fp: 0.500011, loss_freq: 0.503213
[14:46:36.008] iteration 1482: loss: 0.847221, loss_s1: 0.504405, loss_fp: 0.500006, loss_freq: 0.504095
[14:46:36.630] iteration 1483: loss: 0.875796, loss_s1: 0.504529, loss_fp: 0.500039, loss_freq: 0.502602
[14:46:37.247] iteration 1484: loss: 0.971987, loss_s1: 0.503840, loss_fp: 0.500029, loss_freq: 0.501645
[14:46:37.864] iteration 1485: loss: 0.755497, loss_s1: 0.496835, loss_fp: 0.264697, loss_freq: 0.492730
[14:46:38.484] iteration 1486: loss: 0.864925, loss_s1: 0.504554, loss_fp: 0.500046, loss_freq: 0.502426
[14:46:39.104] iteration 1487: loss: 0.898873, loss_s1: 0.503790, loss_fp: 0.500020, loss_freq: 0.502239
[14:46:39.727] iteration 1488: loss: 0.882663, loss_s1: 0.502503, loss_fp: 0.500006, loss_freq: 0.500626
[14:46:40.352] iteration 1489: loss: 0.982280, loss_s1: 0.502671, loss_fp: 0.500003, loss_freq: 0.500973
[14:46:40.973] iteration 1490: loss: 0.956234, loss_s1: 0.504264, loss_fp: 0.500001, loss_freq: 0.502259
[14:46:41.601] iteration 1491: loss: 0.655653, loss_s1: 0.492460, loss_fp: 0.049286, loss_freq: 0.448069
[14:46:42.222] iteration 1492: loss: 0.964068, loss_s1: 0.504129, loss_fp: 0.500023, loss_freq: 0.500756
[14:46:42.845] iteration 1493: loss: 0.874652, loss_s1: 0.501450, loss_fp: 0.500034, loss_freq: 0.501439
[14:46:43.469] iteration 1494: loss: 0.990868, loss_s1: 0.505516, loss_fp: 0.500005, loss_freq: 0.502556
[14:46:44.088] iteration 1495: loss: 1.006791, loss_s1: 0.503957, loss_fp: 0.500011, loss_freq: 0.500971
[14:46:44.711] iteration 1496: loss: 0.926631, loss_s1: 0.500907, loss_fp: 0.500000, loss_freq: 0.500220
[14:46:45.332] iteration 1497: loss: 0.881168, loss_s1: 0.502584, loss_fp: 0.500017, loss_freq: 0.501562
[14:46:45.976] iteration 1498: loss: 0.971295, loss_s1: 0.501605, loss_fp: 0.500002, loss_freq: 0.500464
[14:46:46.598] iteration 1499: loss: 0.861073, loss_s1: 0.502238, loss_fp: 0.500517, loss_freq: 0.500633
[14:46:47.218] iteration 1500: loss: 0.848592, loss_s1: 0.501639, loss_fp: 0.500001, loss_freq: 0.500531
[14:46:47.838] iteration 1501: loss: 0.959390, loss_s1: 0.504428, loss_fp: 0.499999, loss_freq: 0.500878
[14:46:48.459] iteration 1502: loss: 0.877334, loss_s1: 0.504797, loss_fp: 0.500003, loss_freq: 0.500087
[14:46:49.076] iteration 1503: loss: 0.999859, loss_s1: 0.504787, loss_fp: 0.500009, loss_freq: 0.500588
[14:46:49.692] iteration 1504: loss: 0.928041, loss_s1: 0.503100, loss_fp: 0.500013, loss_freq: 0.500329
[14:46:50.313] iteration 1505: loss: 0.936490, loss_s1: 0.504829, loss_fp: 0.500008, loss_freq: 0.502171
[14:46:50.961] iteration 1506: loss: 0.962090, loss_s1: 0.504194, loss_fp: 0.500005, loss_freq: 0.502026
[14:46:51.594] iteration 1507: loss: 0.957612, loss_s1: 0.501398, loss_fp: 0.500007, loss_freq: 0.500659
[14:46:52.244] iteration 1508: loss: 0.959704, loss_s1: 0.501887, loss_fp: 0.500016, loss_freq: 0.500434
[14:46:52.877] iteration 1509: loss: 0.898217, loss_s1: 0.503609, loss_fp: 0.499998, loss_freq: 0.500490
[14:46:53.508] iteration 1510: loss: 0.874901, loss_s1: 0.502906, loss_fp: 0.500007, loss_freq: 0.501111
[14:46:54.142] iteration 1511: loss: 0.891140, loss_s1: 0.504630, loss_fp: 0.500010, loss_freq: 0.500795
[14:46:54.782] iteration 1512: loss: 0.883555, loss_s1: 0.501614, loss_fp: 0.500013, loss_freq: 0.502848
[14:46:55.415] iteration 1513: loss: 0.973673, loss_s1: 0.505652, loss_fp: 0.500066, loss_freq: 0.501585
[14:46:56.054] iteration 1514: loss: 0.875574, loss_s1: 0.503061, loss_fp: 0.500003, loss_freq: 0.500629
[14:46:56.686] iteration 1515: loss: 0.888301, loss_s1: 0.505275, loss_fp: 0.500017, loss_freq: 0.502285
[14:46:57.322] iteration 1516: loss: 0.893608, loss_s1: 0.501057, loss_fp: 0.500039, loss_freq: 0.506049
[14:46:57.955] iteration 1517: loss: 0.824859, loss_s1: 0.505520, loss_fp: 0.500004, loss_freq: 0.500635
[14:46:58.589] iteration 1518: loss: 0.880835, loss_s1: 0.504572, loss_fp: 0.500008, loss_freq: 0.502284
[14:46:59.222] iteration 1519: loss: 0.948399, loss_s1: 0.503612, loss_fp: 0.500007, loss_freq: 0.502422
[14:46:59.857] iteration 1520: loss: 0.966765, loss_s1: 0.504762, loss_fp: 0.500192, loss_freq: 0.500876
[14:47:00.489] iteration 1521: loss: 0.907269, loss_s1: 0.501516, loss_fp: 0.500003, loss_freq: 0.500646
[14:47:01.155] iteration 1522: loss: 0.888945, loss_s1: 0.501718, loss_fp: 0.500015, loss_freq: 0.506611
[14:47:01.778] iteration 1523: loss: 0.885494, loss_s1: 0.503884, loss_fp: 0.500007, loss_freq: 0.503218
[14:47:02.407] iteration 1524: loss: 0.897645, loss_s1: 0.501050, loss_fp: 0.500019, loss_freq: 0.504647
[14:47:03.032] iteration 1525: loss: 0.918071, loss_s1: 0.504383, loss_fp: 0.500011, loss_freq: 0.502479
[14:47:03.653] iteration 1526: loss: 0.840052, loss_s1: 0.502683, loss_fp: 0.402234, loss_freq: 0.489379
[14:47:04.271] iteration 1527: loss: 0.850426, loss_s1: 0.505177, loss_fp: 0.447938, loss_freq: 0.500792
[14:47:04.891] iteration 1528: loss: 0.473649, loss_s1: 0.396746, loss_fp: 0.055441, loss_freq: 0.338011
[14:47:05.513] iteration 1529: loss: 0.910123, loss_s1: 0.502258, loss_fp: 0.500011, loss_freq: 0.501268
[14:47:06.134] iteration 1530: loss: 0.955968, loss_s1: 0.502815, loss_fp: 0.500028, loss_freq: 0.501557
[14:47:06.757] iteration 1531: loss: 0.892831, loss_s1: 0.501908, loss_fp: 0.500023, loss_freq: 0.500369
[14:47:07.403] iteration 1532: loss: 0.872101, loss_s1: 0.503807, loss_fp: 0.500016, loss_freq: 0.501638
[14:47:08.025] iteration 1533: loss: 0.892414, loss_s1: 0.501505, loss_fp: 0.500025, loss_freq: 0.500755
[14:47:08.643] iteration 1534: loss: 0.846994, loss_s1: 0.501310, loss_fp: 0.500018, loss_freq: 0.500560
[14:47:09.260] iteration 1535: loss: 0.837894, loss_s1: 0.501439, loss_fp: 0.500020, loss_freq: 0.501051
[14:47:09.883] iteration 1536: loss: 1.047954, loss_s1: 0.502817, loss_fp: 0.500183, loss_freq: 0.501558
[14:47:10.503] iteration 1537: loss: 0.862928, loss_s1: 0.501684, loss_fp: 0.500013, loss_freq: 0.500426
[14:47:11.125] iteration 1538: loss: 0.954657, loss_s1: 0.502217, loss_fp: 0.500037, loss_freq: 0.501036
[14:47:11.754] iteration 1539: loss: 0.873978, loss_s1: 0.502449, loss_fp: 0.500040, loss_freq: 0.501124
[14:47:12.380] iteration 1540: loss: 0.973895, loss_s1: 0.502734, loss_fp: 0.500007, loss_freq: 0.500940
[14:47:13.007] iteration 1541: loss: 0.902832, loss_s1: 0.505287, loss_fp: 0.500013, loss_freq: 0.502024
[14:47:13.631] iteration 1542: loss: 0.972761, loss_s1: 0.504050, loss_fp: 0.500012, loss_freq: 0.500799
[14:47:14.251] iteration 1543: loss: 0.926550, loss_s1: 0.504205, loss_fp: 0.500021, loss_freq: 0.500431
[14:47:14.871] iteration 1544: loss: 0.861330, loss_s1: 0.506679, loss_fp: 0.500058, loss_freq: 0.502349
[14:47:15.494] iteration 1545: loss: 0.849360, loss_s1: 0.504701, loss_fp: 0.500009, loss_freq: 0.504126
[14:47:16.132] iteration 1546: loss: 0.829054, loss_s1: 0.398827, loss_fp: 0.500022, loss_freq: 0.501430
[14:47:16.749] iteration 1547: loss: 0.914293, loss_s1: 0.501871, loss_fp: 0.500006, loss_freq: 0.501482
[14:47:17.368] iteration 1548: loss: 0.654118, loss_s1: 0.503024, loss_fp: 0.087717, loss_freq: 0.446613
[14:47:17.983] iteration 1549: loss: 0.537354, loss_s1: 0.484629, loss_fp: 0.030928, loss_freq: 0.274677
[14:47:18.605] iteration 1550: loss: 0.833287, loss_s1: 0.503410, loss_fp: 0.500003, loss_freq: 0.500566
[14:47:19.248] iteration 1551: loss: 0.425854, loss_s1: 0.349099, loss_fp: 0.091981, loss_freq: 0.111155
[14:47:19.873] iteration 1552: loss: 0.844569, loss_s1: 0.501418, loss_fp: 0.500979, loss_freq: 0.501306
[14:47:20.504] iteration 1553: loss: 0.443999, loss_s1: 0.414669, loss_fp: 0.036540, loss_freq: 0.165536
[14:47:21.140] iteration 1554: loss: 0.771954, loss_s1: 0.484969, loss_fp: 0.032258, loss_freq: 0.391074
[14:47:21.763] iteration 1555: loss: 0.452352, loss_s1: 0.207882, loss_fp: 0.004866, loss_freq: 0.055955
[14:47:22.395] iteration 1556: loss: 0.954194, loss_s1: 0.501586, loss_fp: 0.500040, loss_freq: 0.500863
[14:47:23.018] iteration 1557: loss: 0.995896, loss_s1: 0.500432, loss_fp: 0.462355, loss_freq: 0.499460
[14:47:23.651] iteration 1558: loss: 1.108106, loss_s1: 0.502692, loss_fp: 0.500076, loss_freq: 0.503900
[14:47:24.271] iteration 1559: loss: 1.046585, loss_s1: 0.501137, loss_fp: 0.500021, loss_freq: 0.501398
[14:47:24.907] iteration 1560: loss: 0.995573, loss_s1: 0.502931, loss_fp: 0.500029, loss_freq: 0.502669
[14:47:25.523] iteration 1561: loss: 0.975522, loss_s1: 0.501098, loss_fp: 0.500036, loss_freq: 0.504073
[14:47:26.146] iteration 1562: loss: 0.984118, loss_s1: 0.501256, loss_fp: 0.500032, loss_freq: 0.502119
[14:47:26.765] iteration 1563: loss: 0.957251, loss_s1: 0.501313, loss_fp: 0.500027, loss_freq: 0.502726
[14:47:27.385] iteration 1564: loss: 1.006443, loss_s1: 0.505667, loss_fp: 0.500064, loss_freq: 0.500599
[14:47:28.008] iteration 1565: loss: 1.034472, loss_s1: 0.507323, loss_fp: 0.500027, loss_freq: 0.500672
[14:47:28.629] iteration 1566: loss: 0.955208, loss_s1: 0.504799, loss_fp: 0.500003, loss_freq: 0.500899
[14:47:29.253] iteration 1567: loss: 0.886585, loss_s1: 0.502673, loss_fp: 0.500018, loss_freq: 0.501285
[14:47:29.867] iteration 1568: loss: 0.951922, loss_s1: 0.503744, loss_fp: 0.500043, loss_freq: 0.501776
[14:47:30.492] iteration 1569: loss: 0.872934, loss_s1: 0.504852, loss_fp: 0.500020, loss_freq: 0.501419
[14:47:31.111] iteration 1570: loss: 0.924165, loss_s1: 0.501202, loss_fp: 0.500007, loss_freq: 0.501715
[14:47:31.730] iteration 1571: loss: 0.410944, loss_s1: 0.251775, loss_fp: 0.003115, loss_freq: 0.036502
[14:47:32.347] iteration 1572: loss: 0.958162, loss_s1: 0.504705, loss_fp: 0.500012, loss_freq: 0.502396
[14:47:32.976] iteration 1573: loss: 0.965385, loss_s1: 0.507161, loss_fp: 0.500016, loss_freq: 0.501712
[14:47:33.601] iteration 1574: loss: 0.995660, loss_s1: 0.502797, loss_fp: 0.500023, loss_freq: 0.501077
[14:47:34.223] iteration 1575: loss: 0.954866, loss_s1: 0.504001, loss_fp: 0.500062, loss_freq: 0.502920
[14:47:34.847] iteration 1576: loss: 0.954177, loss_s1: 0.503682, loss_fp: 0.500058, loss_freq: 0.500900
[14:47:35.471] iteration 1577: loss: 0.999983, loss_s1: 0.503178, loss_fp: 0.500046, loss_freq: 0.502014
[14:47:36.093] iteration 1578: loss: 0.928660, loss_s1: 0.503211, loss_fp: 0.500226, loss_freq: 0.502020
[14:47:36.716] iteration 1579: loss: 0.913469, loss_s1: 0.503386, loss_fp: 0.500026, loss_freq: 0.501008
[14:47:37.339] iteration 1580: loss: 0.886976, loss_s1: 0.503484, loss_fp: 0.500388, loss_freq: 0.500914
[14:47:37.957] iteration 1581: loss: 0.963188, loss_s1: 0.502249, loss_fp: 0.500030, loss_freq: 0.502235
[14:47:38.581] iteration 1582: loss: 0.931526, loss_s1: 0.502723, loss_fp: 0.500008, loss_freq: 0.500703
[14:47:39.204] iteration 1583: loss: 0.918324, loss_s1: 0.504155, loss_fp: 0.500036, loss_freq: 0.500675
[14:47:39.827] iteration 1584: loss: 0.563568, loss_s1: 0.412335, loss_fp: 0.017287, loss_freq: 0.410369
[14:47:40.449] iteration 1585: loss: 0.875179, loss_s1: 0.504502, loss_fp: 0.500058, loss_freq: 0.504619
[14:47:41.074] iteration 1586: loss: 0.935806, loss_s1: 0.502287, loss_fp: 0.500006, loss_freq: 0.501400
[14:47:41.702] iteration 1587: loss: 0.460033, loss_s1: 0.428024, loss_fp: 0.068559, loss_freq: 0.207286
[14:47:42.327] iteration 1588: loss: 0.925001, loss_s1: 0.501435, loss_fp: 0.500054, loss_freq: 0.501236
[14:47:42.958] iteration 1589: loss: 0.487749, loss_s1: 0.402966, loss_fp: 0.009085, loss_freq: 0.093077
[14:47:43.585] iteration 1590: loss: 0.946451, loss_s1: 0.500152, loss_fp: 0.500004, loss_freq: 0.500214
[14:47:44.210] iteration 1591: loss: 0.927002, loss_s1: 0.499798, loss_fp: 0.500004, loss_freq: 0.500155
[14:47:44.861] iteration 1592: loss: 0.967822, loss_s1: 0.425373, loss_fp: 0.500003, loss_freq: 0.500084
[14:47:45.485] iteration 1593: loss: 0.679730, loss_s1: 0.455737, loss_fp: 0.018241, loss_freq: 0.443503
[14:47:46.111] iteration 1594: loss: 1.020578, loss_s1: 0.500834, loss_fp: 0.500002, loss_freq: 0.500376
[14:47:46.731] iteration 1595: loss: 0.496006, loss_s1: 0.268221, loss_fp: 0.009067, loss_freq: 0.262278
[14:47:47.354] iteration 1596: loss: 0.975230, loss_s1: 0.501299, loss_fp: 0.500014, loss_freq: 0.500593
[14:47:48.006] iteration 1597: loss: 0.633918, loss_s1: 0.501385, loss_fp: 0.034478, loss_freq: 0.391596
[14:47:48.631] iteration 1598: loss: 0.939179, loss_s1: 0.500822, loss_fp: 0.500014, loss_freq: 0.501059
[14:47:49.257] iteration 1599: loss: 0.961595, loss_s1: 0.504749, loss_fp: 0.500022, loss_freq: 0.502090
[14:47:49.883] iteration 1600: loss: 0.601284, loss_s1: 0.349766, loss_fp: 0.004461, loss_freq: 0.309345
[14:47:52.600] iteration 1600 : mean_dice : 0.171904
[14:47:53.270] iteration 1601: loss: 0.940720, loss_s1: 0.504188, loss_fp: 0.500007, loss_freq: 0.500579
[14:47:53.910] iteration 1602: loss: 0.875990, loss_s1: 0.502081, loss_fp: 0.500003, loss_freq: 0.500613
[14:47:54.539] iteration 1603: loss: 1.046981, loss_s1: 0.502216, loss_fp: 0.500000, loss_freq: 0.500648
[14:47:55.184] iteration 1604: loss: 0.885182, loss_s1: 0.503447, loss_fp: 0.500006, loss_freq: 0.501544
[14:47:55.809] iteration 1605: loss: 0.843181, loss_s1: 0.500873, loss_fp: 0.500008, loss_freq: 0.500837
[14:47:56.429] iteration 1606: loss: 0.957994, loss_s1: 0.502134, loss_fp: 0.500006, loss_freq: 0.500549
[14:47:57.050] iteration 1607: loss: 0.886238, loss_s1: 0.502687, loss_fp: 0.500007, loss_freq: 0.501087
[14:47:57.696] iteration 1608: loss: 0.952350, loss_s1: 0.503287, loss_fp: 0.499999, loss_freq: 0.500493
[14:47:58.319] iteration 1609: loss: 0.484353, loss_s1: 0.467179, loss_fp: 0.017441, loss_freq: 0.176788
[14:47:58.943] iteration 1610: loss: 0.936612, loss_s1: 0.502615, loss_fp: 0.500002, loss_freq: 0.501360
[14:47:59.873] iteration 1611: loss: 0.915774, loss_s1: 0.500799, loss_fp: 0.500009, loss_freq: 0.500746
[14:48:00.505] iteration 1612: loss: 0.871850, loss_s1: 0.500885, loss_fp: 0.500007, loss_freq: 0.501282
[14:48:01.140] iteration 1613: loss: 0.918646, loss_s1: 0.501829, loss_fp: 0.500002, loss_freq: 0.500141
[14:48:01.766] iteration 1614: loss: 0.723817, loss_s1: 0.482397, loss_fp: 0.022423, loss_freq: 0.450330
[14:48:02.388] iteration 1615: loss: 0.953030, loss_s1: 0.502444, loss_fp: 0.500008, loss_freq: 0.501844
[14:48:03.007] iteration 1616: loss: 0.955996, loss_s1: 0.501020, loss_fp: 0.500015, loss_freq: 0.500725
[14:48:03.629] iteration 1617: loss: 0.770337, loss_s1: 0.313994, loss_fp: 0.500012, loss_freq: 0.500845
[14:48:04.257] iteration 1618: loss: 0.862957, loss_s1: 0.501446, loss_fp: 0.500001, loss_freq: 0.500852
[14:48:04.882] iteration 1619: loss: 0.866198, loss_s1: 0.500973, loss_fp: 0.500006, loss_freq: 0.500406
[14:48:05.504] iteration 1620: loss: 0.872274, loss_s1: 0.503434, loss_fp: 0.500003, loss_freq: 0.503272
[14:48:06.126] iteration 1621: loss: 0.948869, loss_s1: 0.503071, loss_fp: 0.500009, loss_freq: 0.502760
[14:48:06.750] iteration 1622: loss: 0.903501, loss_s1: 0.504875, loss_fp: 0.500014, loss_freq: 0.501237
[14:48:07.372] iteration 1623: loss: 0.836697, loss_s1: 0.500737, loss_fp: 0.500004, loss_freq: 0.501645
[14:48:07.995] iteration 1624: loss: 0.932160, loss_s1: 0.506462, loss_fp: 0.500016, loss_freq: 0.501475
[14:48:08.615] iteration 1625: loss: 0.854431, loss_s1: 0.503624, loss_fp: 0.500055, loss_freq: 0.500656
[14:48:09.240] iteration 1626: loss: 0.879314, loss_s1: 0.503646, loss_fp: 0.500003, loss_freq: 0.500568
[14:48:09.865] iteration 1627: loss: 0.309967, loss_s1: 0.189772, loss_fp: 0.002304, loss_freq: 0.029771
[14:48:10.490] iteration 1628: loss: 0.855808, loss_s1: 0.500674, loss_fp: 0.500002, loss_freq: 0.500845
[14:48:11.115] iteration 1629: loss: 0.965368, loss_s1: 0.502807, loss_fp: 0.500004, loss_freq: 0.500644
[14:48:11.748] iteration 1630: loss: 0.545190, loss_s1: 0.447149, loss_fp: 0.007842, loss_freq: 0.399205
[14:48:12.379] iteration 1631: loss: 0.943038, loss_s1: 0.501279, loss_fp: 0.500006, loss_freq: 0.501505
[14:48:13.009] iteration 1632: loss: 0.884232, loss_s1: 0.500478, loss_fp: 0.500002, loss_freq: 0.500643
[14:48:13.639] iteration 1633: loss: 1.017767, loss_s1: 0.500921, loss_fp: 0.500002, loss_freq: 0.500418
[14:48:14.272] iteration 1634: loss: 0.861265, loss_s1: 0.500642, loss_fp: 0.500016, loss_freq: 0.501818
[14:48:14.909] iteration 1635: loss: 0.859772, loss_s1: 0.501489, loss_fp: 0.500004, loss_freq: 0.500351
[14:48:15.535] iteration 1636: loss: 0.334625, loss_s1: 0.344328, loss_fp: 0.005110, loss_freq: 0.107051
[14:48:16.164] iteration 1637: loss: 0.503802, loss_s1: 0.435775, loss_fp: 0.044932, loss_freq: 0.231708
[14:48:16.793] iteration 1638: loss: 0.942352, loss_s1: 0.501596, loss_fp: 0.500002, loss_freq: 0.501450
[14:48:17.417] iteration 1639: loss: 0.460962, loss_s1: 0.382126, loss_fp: 0.013010, loss_freq: 0.040897
[14:48:18.041] iteration 1640: loss: 0.967152, loss_s1: 0.500600, loss_fp: 0.500007, loss_freq: 0.500118
[14:48:18.666] iteration 1641: loss: 1.003011, loss_s1: 0.500965, loss_fp: 0.500010, loss_freq: 0.500073
[14:48:19.287] iteration 1642: loss: 0.960765, loss_s1: 0.489406, loss_fp: 0.500009, loss_freq: 0.500010
[14:48:19.913] iteration 1643: loss: 0.405800, loss_s1: 0.499081, loss_fp: 0.003957, loss_freq: 0.149657
[14:48:20.538] iteration 1644: loss: 0.469308, loss_s1: 0.255547, loss_fp: 0.003017, loss_freq: 0.275572
[14:48:21.158] iteration 1645: loss: 1.044245, loss_s1: 0.498155, loss_fp: 0.500000, loss_freq: 0.500117
[14:48:21.784] iteration 1646: loss: 0.395786, loss_s1: 0.383124, loss_fp: 0.010151, loss_freq: 0.013872
[14:48:22.409] iteration 1647: loss: 0.939019, loss_s1: 0.504173, loss_fp: 0.500003, loss_freq: 0.501858
[14:48:23.035] iteration 1648: loss: 0.880156, loss_s1: 0.502686, loss_fp: 0.500000, loss_freq: 0.500968
[14:48:23.661] iteration 1649: loss: 0.586982, loss_s1: 0.504777, loss_fp: 0.003221, loss_freq: 0.249570
[14:48:24.284] iteration 1650: loss: 0.951031, loss_s1: 0.502635, loss_fp: 0.500005, loss_freq: 0.503284
[14:48:24.908] iteration 1651: loss: 1.003417, loss_s1: 0.505474, loss_fp: 0.500002, loss_freq: 0.500767
[14:48:25.541] iteration 1652: loss: 0.446522, loss_s1: 0.389400, loss_fp: 0.007297, loss_freq: 0.293713
[14:48:26.164] iteration 1653: loss: 0.571653, loss_s1: 0.462269, loss_fp: 0.006277, loss_freq: 0.412114
[14:48:26.786] iteration 1654: loss: 0.881074, loss_s1: 0.502113, loss_fp: 0.454042, loss_freq: 0.500241
[14:48:27.407] iteration 1655: loss: 0.542398, loss_s1: 0.393790, loss_fp: 0.002777, loss_freq: 0.339849
[14:48:28.030] iteration 1656: loss: 0.551257, loss_s1: 0.408587, loss_fp: 0.004466, loss_freq: 0.323756
[14:48:28.654] iteration 1657: loss: 0.408230, loss_s1: 0.464430, loss_fp: 0.007328, loss_freq: 0.069354
[14:48:29.278] iteration 1658: loss: 0.561926, loss_s1: 0.452627, loss_fp: 0.008045, loss_freq: 0.469278
[14:48:29.897] iteration 1659: loss: 0.953910, loss_s1: 0.501320, loss_fp: 0.500008, loss_freq: 0.500238
[14:48:30.524] iteration 1660: loss: 0.865755, loss_s1: 0.501059, loss_fp: 0.500013, loss_freq: 0.500548
[14:48:31.153] iteration 1661: loss: 0.415262, loss_s1: 0.438501, loss_fp: 0.013885, loss_freq: 0.121617
[14:48:31.774] iteration 1662: loss: 0.785265, loss_s1: 0.499542, loss_fp: 0.010994, loss_freq: 0.288027
[14:48:32.403] iteration 1663: loss: 0.323119, loss_s1: 0.285215, loss_fp: 0.003240, loss_freq: 0.016654
[14:48:33.031] iteration 1664: loss: 0.486334, loss_s1: 0.306598, loss_fp: 0.008248, loss_freq: 0.238016
[14:48:33.652] iteration 1665: loss: 0.439108, loss_s1: 0.340372, loss_fp: 0.002103, loss_freq: 0.039895
[14:48:34.277] iteration 1666: loss: 0.984370, loss_s1: 0.500848, loss_fp: 0.500005, loss_freq: 0.500185
[14:48:34.905] iteration 1667: loss: 0.385758, loss_s1: 0.117911, loss_fp: 0.006838, loss_freq: 0.032251
[14:48:35.528] iteration 1668: loss: 1.066281, loss_s1: 0.500821, loss_fp: 0.500013, loss_freq: 0.500070
[14:48:36.161] iteration 1669: loss: 0.608387, loss_s1: 0.435422, loss_fp: 0.075135, loss_freq: 0.269269
[14:48:36.784] iteration 1670: loss: 0.920457, loss_s1: 0.500454, loss_fp: 0.500000, loss_freq: 0.500019
[14:48:37.408] iteration 1671: loss: 0.156903, loss_s1: 0.025876, loss_fp: 0.003549, loss_freq: 0.003160
[14:48:38.033] iteration 1672: loss: 0.550299, loss_s1: 0.436623, loss_fp: 0.009540, loss_freq: 0.156995
[14:48:38.659] iteration 1673: loss: 0.403880, loss_s1: 0.264620, loss_fp: 0.001846, loss_freq: 0.020613
[14:48:39.282] iteration 1674: loss: 0.963455, loss_s1: 0.500657, loss_fp: 0.500006, loss_freq: 0.500197
[14:48:39.904] iteration 1675: loss: 0.491737, loss_s1: 0.490244, loss_fp: 0.010843, loss_freq: 0.012959
[14:48:40.529] iteration 1676: loss: 0.282686, loss_s1: 0.068823, loss_fp: 0.007347, loss_freq: 0.007693
[14:48:41.153] iteration 1677: loss: 0.927956, loss_s1: 0.501963, loss_fp: 0.500010, loss_freq: 0.500301
[14:48:41.772] iteration 1678: loss: 0.859794, loss_s1: 0.501766, loss_fp: 0.500016, loss_freq: 0.500027
[14:48:42.391] iteration 1679: loss: 0.871667, loss_s1: 0.501189, loss_fp: 0.380357, loss_freq: 0.493310
[14:48:43.014] iteration 1680: loss: 0.676858, loss_s1: 0.497566, loss_fp: 0.107625, loss_freq: 0.256849
[14:48:43.636] iteration 1681: loss: 0.996855, loss_s1: 0.500486, loss_fp: 0.500010, loss_freq: 0.500046
[14:48:44.257] iteration 1682: loss: 0.980292, loss_s1: 0.504030, loss_fp: 0.500002, loss_freq: 0.500578
[14:48:44.879] iteration 1683: loss: 0.562602, loss_s1: 0.216470, loss_fp: 0.028932, loss_freq: 0.326145
[14:48:45.502] iteration 1684: loss: 0.824637, loss_s1: 0.086816, loss_fp: 0.500002, loss_freq: 0.500108
[14:48:46.130] iteration 1685: loss: 1.022007, loss_s1: 0.502746, loss_fp: 0.500005, loss_freq: 0.500266
[14:48:46.760] iteration 1686: loss: 1.039957, loss_s1: 0.497274, loss_fp: 0.500019, loss_freq: 0.500850
[14:48:47.379] iteration 1687: loss: 0.474648, loss_s1: 0.278579, loss_fp: 0.010888, loss_freq: 0.200343
[14:48:48.002] iteration 1688: loss: 0.491336, loss_s1: 0.454620, loss_fp: 0.058185, loss_freq: 0.139334
[14:48:48.621] iteration 1689: loss: 0.376058, loss_s1: 0.314099, loss_fp: 0.002607, loss_freq: 0.010176
[14:48:49.247] iteration 1690: loss: 1.009691, loss_s1: 0.503686, loss_fp: 0.500015, loss_freq: 0.500236
[14:48:49.862] iteration 1691: loss: 0.937399, loss_s1: 0.502492, loss_fp: 0.500006, loss_freq: 0.501998
[14:48:50.485] iteration 1692: loss: 0.929875, loss_s1: 0.501206, loss_fp: 0.500037, loss_freq: 0.500892
[14:48:51.103] iteration 1693: loss: 0.573700, loss_s1: 0.450120, loss_fp: 0.005392, loss_freq: 0.409722
[14:48:51.726] iteration 1694: loss: 1.064065, loss_s1: 0.502344, loss_fp: 0.500012, loss_freq: 0.500727
[14:48:52.346] iteration 1695: loss: 0.896831, loss_s1: 0.501303, loss_fp: 0.500030, loss_freq: 0.500415
[14:48:52.971] iteration 1696: loss: 0.897701, loss_s1: 0.500719, loss_fp: 0.500105, loss_freq: 0.500624
[14:48:53.592] iteration 1697: loss: 0.712649, loss_s1: 0.345469, loss_fp: 0.020139, loss_freq: 0.409165
[14:48:54.216] iteration 1698: loss: 0.936306, loss_s1: 0.500540, loss_fp: 0.500014, loss_freq: 0.500116
[14:48:54.843] iteration 1699: loss: 0.995340, loss_s1: 0.500513, loss_fp: 0.500041, loss_freq: 0.500084
[14:48:55.466] iteration 1700: loss: 0.983958, loss_s1: 0.500776, loss_fp: 0.500023, loss_freq: 0.500039
[14:48:56.083] iteration 1701: loss: 1.029199, loss_s1: 0.500190, loss_fp: 0.500039, loss_freq: 0.500104
[14:48:56.704] iteration 1702: loss: 0.982729, loss_s1: 0.500871, loss_fp: 0.500002, loss_freq: 0.500169
[14:48:57.369] iteration 1703: loss: 1.062897, loss_s1: 0.500106, loss_fp: 0.500019, loss_freq: 0.500089
[14:48:58.049] iteration 1704: loss: 0.971194, loss_s1: 0.500341, loss_fp: 0.500013, loss_freq: 0.500080
[14:48:58.725] iteration 1705: loss: 0.940364, loss_s1: 0.501560, loss_fp: 0.500245, loss_freq: 0.500921
[14:48:59.394] iteration 1706: loss: 0.914522, loss_s1: 0.500576, loss_fp: 0.500075, loss_freq: 0.500206
[14:49:00.038] iteration 1707: loss: 0.944430, loss_s1: 0.500762, loss_fp: 0.500009, loss_freq: 0.500285
[14:49:00.658] iteration 1708: loss: 0.967875, loss_s1: 0.502365, loss_fp: 0.500020, loss_freq: 0.500452
[14:49:01.277] iteration 1709: loss: 0.940922, loss_s1: 0.502470, loss_fp: 0.500012, loss_freq: 0.501136
[14:49:01.908] iteration 1710: loss: 0.887912, loss_s1: 0.503210, loss_fp: 0.500059, loss_freq: 0.500789
[14:49:02.530] iteration 1711: loss: 0.906918, loss_s1: 0.504414, loss_fp: 0.500024, loss_freq: 0.500840
[14:49:03.153] iteration 1712: loss: 0.568555, loss_s1: 0.439710, loss_fp: 0.016807, loss_freq: 0.258499
[14:49:03.772] iteration 1713: loss: 0.906056, loss_s1: 0.502329, loss_fp: 0.500139, loss_freq: 0.501212
[14:49:04.394] iteration 1714: loss: 0.482636, loss_s1: 0.397690, loss_fp: 0.013798, loss_freq: 0.292779
[14:49:05.015] iteration 1715: loss: 0.683514, loss_s1: 0.438355, loss_fp: 0.031680, loss_freq: 0.423735
[14:49:05.639] iteration 1716: loss: 0.438078, loss_s1: 0.408933, loss_fp: 0.019551, loss_freq: 0.027578
[14:49:06.264] iteration 1717: loss: 0.863794, loss_s1: 0.502017, loss_fp: 0.500067, loss_freq: 0.500652
[14:49:06.888] iteration 1718: loss: 1.005525, loss_s1: 0.502109, loss_fp: 0.500051, loss_freq: 0.500271
[14:49:07.523] iteration 1719: loss: 1.007855, loss_s1: 0.501020, loss_fp: 0.500013, loss_freq: 0.501243
[14:49:08.142] iteration 1720: loss: 1.034845, loss_s1: 0.500645, loss_fp: 0.500003, loss_freq: 0.500021
[14:49:08.757] iteration 1721: loss: 0.489486, loss_s1: 0.303064, loss_fp: 0.005109, loss_freq: 0.023566
[14:49:09.379] iteration 1722: loss: 0.938329, loss_s1: 0.500235, loss_fp: 0.500011, loss_freq: 0.500071
[14:49:10.000] iteration 1723: loss: 0.872842, loss_s1: 0.501151, loss_fp: 0.500041, loss_freq: 0.500225
[14:49:10.619] iteration 1724: loss: 0.890359, loss_s1: 0.500308, loss_fp: 0.500005, loss_freq: 0.500033
[14:49:11.242] iteration 1725: loss: 0.952921, loss_s1: 0.500118, loss_fp: 0.500004, loss_freq: 0.500015
[14:49:11.861] iteration 1726: loss: 0.963153, loss_s1: 0.500549, loss_fp: 0.500007, loss_freq: 0.500280
[14:49:12.484] iteration 1727: loss: 0.873359, loss_s1: 0.502017, loss_fp: 0.500006, loss_freq: 0.500665
[14:49:13.108] iteration 1728: loss: 0.857895, loss_s1: 0.500436, loss_fp: 0.500007, loss_freq: 0.500343
[14:49:13.738] iteration 1729: loss: 0.950036, loss_s1: 0.502757, loss_fp: 0.500012, loss_freq: 0.500739
[14:49:14.363] iteration 1730: loss: 0.883944, loss_s1: 0.505997, loss_fp: 0.500093, loss_freq: 0.501580
[14:49:14.987] iteration 1731: loss: 0.891086, loss_s1: 0.502162, loss_fp: 0.500017, loss_freq: 0.501327
[14:49:15.610] iteration 1732: loss: 0.463558, loss_s1: 0.336854, loss_fp: 0.012272, loss_freq: 0.040626
[14:49:16.228] iteration 1733: loss: 0.915798, loss_s1: 0.501458, loss_fp: 0.500118, loss_freq: 0.500850
[14:49:16.853] iteration 1734: loss: 0.962420, loss_s1: 0.502567, loss_fp: 0.500017, loss_freq: 0.500342
[14:49:17.472] iteration 1735: loss: 0.860964, loss_s1: 0.397576, loss_fp: 0.500009, loss_freq: 0.500010
[14:49:18.098] iteration 1736: loss: 0.949676, loss_s1: 0.502644, loss_fp: 0.500207, loss_freq: 0.500599
[14:49:18.716] iteration 1737: loss: 0.416473, loss_s1: 0.325571, loss_fp: 0.007194, loss_freq: 0.166449
[14:49:19.338] iteration 1738: loss: 0.958574, loss_s1: 0.503983, loss_fp: 0.500081, loss_freq: 0.500730
[14:49:19.960] iteration 1739: loss: 0.915353, loss_s1: 0.500746, loss_fp: 0.500016, loss_freq: 0.501177
[14:49:20.583] iteration 1740: loss: 0.885364, loss_s1: 0.501866, loss_fp: 0.500290, loss_freq: 0.500199
[14:49:21.205] iteration 1741: loss: 0.907434, loss_s1: 0.503998, loss_fp: 0.500397, loss_freq: 0.500227
[14:49:21.826] iteration 1742: loss: 0.956082, loss_s1: 0.501882, loss_fp: 0.500014, loss_freq: 0.500866
[14:49:22.449] iteration 1743: loss: 0.890633, loss_s1: 0.500855, loss_fp: 0.500034, loss_freq: 0.500135
[14:49:23.073] iteration 1744: loss: 0.875175, loss_s1: 0.500901, loss_fp: 0.500067, loss_freq: 0.500139
[14:49:23.693] iteration 1745: loss: 0.496217, loss_s1: 0.290532, loss_fp: 0.264497, loss_freq: 0.140624
[14:49:24.319] iteration 1746: loss: 0.872090, loss_s1: 0.502711, loss_fp: 0.500007, loss_freq: 0.502337
[14:49:24.940] iteration 1747: loss: 0.987430, loss_s1: 0.501995, loss_fp: 0.500005, loss_freq: 0.500105
[14:49:25.575] iteration 1748: loss: 0.822881, loss_s1: 0.501182, loss_fp: 0.500016, loss_freq: 0.500090
[14:49:26.205] iteration 1749: loss: 0.927438, loss_s1: 0.502989, loss_fp: 0.500007, loss_freq: 0.500572
[14:49:26.837] iteration 1750: loss: 0.318197, loss_s1: 0.110910, loss_fp: 0.003438, loss_freq: 0.039473
[14:49:27.470] iteration 1751: loss: 0.929304, loss_s1: 0.500814, loss_fp: 0.500126, loss_freq: 0.500751
[14:49:28.115] iteration 1752: loss: 0.926816, loss_s1: 0.503057, loss_fp: 0.500007, loss_freq: 0.500039
[14:49:28.735] iteration 1753: loss: 0.931001, loss_s1: 0.501444, loss_fp: 0.500085, loss_freq: 0.500131
[14:49:29.355] iteration 1754: loss: 0.939199, loss_s1: 0.501702, loss_fp: 0.500024, loss_freq: 0.500761
[14:49:29.971] iteration 1755: loss: 0.978754, loss_s1: 0.500805, loss_fp: 0.500001, loss_freq: 0.500086
[14:49:30.593] iteration 1756: loss: 0.335774, loss_s1: 0.136177, loss_fp: 0.003996, loss_freq: 0.030543
[14:49:31.226] iteration 1757: loss: 0.925498, loss_s1: 0.501254, loss_fp: 0.500019, loss_freq: 0.500563
[14:49:31.864] iteration 1758: loss: 0.320625, loss_s1: 0.286655, loss_fp: 0.050303, loss_freq: 0.029076
[14:49:32.503] iteration 1759: loss: 0.850145, loss_s1: 0.500239, loss_fp: 0.500005, loss_freq: 0.500132
[14:49:33.145] iteration 1760: loss: 0.504034, loss_s1: 0.474837, loss_fp: 0.049026, loss_freq: 0.194051
[14:49:33.778] iteration 1761: loss: 0.437352, loss_s1: 0.297703, loss_fp: 0.005860, loss_freq: 0.213988
[14:49:34.417] iteration 1762: loss: 0.890953, loss_s1: 0.501297, loss_fp: 0.500018, loss_freq: 0.500058
[14:49:35.063] iteration 1763: loss: 0.898961, loss_s1: 0.500156, loss_fp: 0.500036, loss_freq: 0.500016
[14:49:35.702] iteration 1764: loss: 1.012067, loss_s1: 0.500264, loss_fp: 0.500004, loss_freq: 0.500069
[14:49:36.338] iteration 1765: loss: 0.912230, loss_s1: 0.500094, loss_fp: 0.500032, loss_freq: 0.500057
[14:49:36.974] iteration 1766: loss: 0.880949, loss_s1: 0.500177, loss_fp: 0.500089, loss_freq: 0.500121
[14:49:37.610] iteration 1767: loss: 1.019184, loss_s1: 0.500051, loss_fp: 0.499999, loss_freq: 0.500026
[14:49:38.246] iteration 1768: loss: 0.880404, loss_s1: 0.500791, loss_fp: 0.500003, loss_freq: 0.500103
[14:49:38.886] iteration 1769: loss: 0.956360, loss_s1: 0.502257, loss_fp: 0.500088, loss_freq: 0.500341
[14:49:39.507] iteration 1770: loss: 0.263107, loss_s1: 0.205066, loss_fp: 0.002996, loss_freq: 0.071024
[14:49:40.128] iteration 1771: loss: 0.363057, loss_s1: 0.200548, loss_fp: 0.015947, loss_freq: 0.018100
[14:49:41.045] iteration 1772: loss: 0.581417, loss_s1: 0.457548, loss_fp: 0.091259, loss_freq: 0.151731
[14:49:41.662] iteration 1773: loss: 0.885025, loss_s1: 0.500880, loss_fp: 0.500001, loss_freq: 0.500658
[14:49:42.290] iteration 1774: loss: 0.910596, loss_s1: 0.501274, loss_fp: 0.499998, loss_freq: 0.500452
[14:49:42.913] iteration 1775: loss: 0.984597, loss_s1: 0.501125, loss_fp: 0.500009, loss_freq: 0.500128
[14:49:43.536] iteration 1776: loss: 1.036647, loss_s1: 0.500871, loss_fp: 0.500039, loss_freq: 0.500811
[14:49:44.155] iteration 1777: loss: 1.049567, loss_s1: 0.500775, loss_fp: 0.500027, loss_freq: 0.500132
[14:49:44.773] iteration 1778: loss: 0.328390, loss_s1: 0.192878, loss_fp: 0.013653, loss_freq: 0.112522
[14:49:45.390] iteration 1779: loss: 0.900095, loss_s1: 0.500129, loss_fp: 0.500022, loss_freq: 0.500092
[14:49:46.015] iteration 1780: loss: 0.901982, loss_s1: 0.501806, loss_fp: 0.500002, loss_freq: 0.500014
[14:49:46.637] iteration 1781: loss: 0.554984, loss_s1: 0.411197, loss_fp: 0.010562, loss_freq: 0.278922
[14:49:47.270] iteration 1782: loss: 0.995060, loss_s1: 0.502478, loss_fp: 0.500015, loss_freq: 0.500598
[14:49:47.894] iteration 1783: loss: 0.395987, loss_s1: 0.329055, loss_fp: 0.003133, loss_freq: 0.057765
[14:49:48.514] iteration 1784: loss: 0.866254, loss_s1: 0.502136, loss_fp: 0.500008, loss_freq: 0.500008
[14:49:49.136] iteration 1785: loss: 0.962194, loss_s1: 0.501691, loss_fp: 0.500003, loss_freq: 0.500298
[14:49:49.780] iteration 1786: loss: 0.849975, loss_s1: 0.500342, loss_fp: 0.500006, loss_freq: 0.500026
[14:49:50.420] iteration 1787: loss: 0.131170, loss_s1: 0.007669, loss_fp: 0.005492, loss_freq: 0.046877
[14:49:51.048] iteration 1788: loss: 0.401601, loss_s1: 0.244230, loss_fp: 0.001358, loss_freq: 0.012083
[14:49:51.672] iteration 1789: loss: 0.261991, loss_s1: 0.084620, loss_fp: 0.002769, loss_freq: 0.010221
[14:49:52.299] iteration 1790: loss: 0.601876, loss_s1: 0.460522, loss_fp: 0.047748, loss_freq: 0.219280
[14:49:52.926] iteration 1791: loss: 0.326503, loss_s1: 0.090588, loss_fp: 0.002480, loss_freq: 0.032965
[14:49:53.550] iteration 1792: loss: 0.367195, loss_s1: 0.327778, loss_fp: 0.003907, loss_freq: 0.015770
[14:49:54.174] iteration 1793: loss: 0.954580, loss_s1: 0.501743, loss_fp: 0.500002, loss_freq: 0.500875
[14:49:54.802] iteration 1794: loss: 1.010430, loss_s1: 0.501788, loss_fp: 0.500009, loss_freq: 0.500037
[14:49:55.430] iteration 1795: loss: 0.921991, loss_s1: 0.502519, loss_fp: 0.500007, loss_freq: 0.500223
[14:49:56.059] iteration 1796: loss: 0.870584, loss_s1: 0.500615, loss_fp: 0.500004, loss_freq: 0.500004
[14:49:56.681] iteration 1797: loss: 0.364614, loss_s1: 0.350066, loss_fp: 0.004199, loss_freq: 0.096716
[14:49:57.312] iteration 1798: loss: 0.327255, loss_s1: 0.260649, loss_fp: 0.004980, loss_freq: 0.047088
[14:49:57.939] iteration 1799: loss: 0.932749, loss_s1: 0.500947, loss_fp: 0.500003, loss_freq: 0.500027
[14:49:58.563] iteration 1800: loss: 1.067178, loss_s1: 0.500095, loss_fp: 0.500002, loss_freq: 0.500009
[14:50:00.537] iteration 1800 : mean_dice : 0.020875
[14:50:01.199] iteration 1801: loss: 0.775190, loss_s1: 0.498900, loss_fp: 0.180860, loss_freq: 0.423681
[14:50:01.827] iteration 1802: loss: 0.958513, loss_s1: 0.500042, loss_fp: 0.500002, loss_freq: 0.500005
[14:50:02.455] iteration 1803: loss: 0.501076, loss_s1: 0.498403, loss_fp: 0.001968, loss_freq: 0.011018
[14:50:03.079] iteration 1804: loss: 0.770836, loss_s1: 0.495830, loss_fp: 0.241416, loss_freq: 0.489443
[14:50:03.703] iteration 1805: loss: 0.240976, loss_s1: 0.024775, loss_fp: 0.001959, loss_freq: 0.038437
[14:50:04.332] iteration 1806: loss: 0.469235, loss_s1: 0.191229, loss_fp: 0.001900, loss_freq: 0.045445
[14:50:04.958] iteration 1807: loss: 0.444717, loss_s1: 0.250178, loss_fp: 0.002773, loss_freq: 0.020284
[14:50:05.582] iteration 1808: loss: 0.422318, loss_s1: 0.294448, loss_fp: 0.001230, loss_freq: 0.003620
[14:50:06.202] iteration 1809: loss: 1.001429, loss_s1: 0.500427, loss_fp: 0.499999, loss_freq: 0.500003
[14:50:06.820] iteration 1810: loss: 0.523700, loss_s1: 0.370517, loss_fp: 0.001644, loss_freq: 0.008647
[14:50:07.441] iteration 1811: loss: 1.178407, loss_s1: 0.500266, loss_fp: 0.499996, loss_freq: 0.500123
[14:50:08.062] iteration 1812: loss: 1.066136, loss_s1: 0.449245, loss_fp: 0.499984, loss_freq: 0.499998
[14:50:08.685] iteration 1813: loss: 0.356116, loss_s1: 0.318062, loss_fp: 0.000395, loss_freq: 0.003278
[14:50:09.308] iteration 1814: loss: 1.001038, loss_s1: 0.500175, loss_fp: 0.499994, loss_freq: 0.500071
[14:50:09.931] iteration 1815: loss: 0.679545, loss_s1: 0.497357, loss_fp: 0.046403, loss_freq: 0.456982
[14:50:10.566] iteration 1816: loss: 0.462256, loss_s1: 0.171019, loss_fp: 0.002989, loss_freq: 0.182965
[14:50:11.191] iteration 1817: loss: 0.755654, loss_s1: 0.477401, loss_fp: 0.029316, loss_freq: 0.425410
[14:50:11.812] iteration 1818: loss: 0.364176, loss_s1: 0.240477, loss_fp: 0.001018, loss_freq: 0.031396
[14:50:12.436] iteration 1819: loss: 0.358583, loss_s1: 0.292381, loss_fp: 0.001459, loss_freq: 0.005348
[14:50:13.062] iteration 1820: loss: 0.967031, loss_s1: 0.501136, loss_fp: 0.500007, loss_freq: 0.500331
[14:50:13.691] iteration 1821: loss: 0.880941, loss_s1: 0.502213, loss_fp: 0.500004, loss_freq: 0.501218
[14:50:14.320] iteration 1822: loss: 0.748044, loss_s1: 0.496689, loss_fp: 0.302738, loss_freq: 0.394818
[14:50:14.942] iteration 1823: loss: 0.600608, loss_s1: 0.204017, loss_fp: 0.006281, loss_freq: 0.278476
[14:50:15.565] iteration 1824: loss: 1.049648, loss_s1: 0.502699, loss_fp: 0.500014, loss_freq: 0.500163
[14:50:16.187] iteration 1825: loss: 0.787688, loss_s1: 0.503057, loss_fp: 0.186575, loss_freq: 0.120216
[14:50:16.809] iteration 1826: loss: 0.534897, loss_s1: 0.355323, loss_fp: 0.004998, loss_freq: 0.071594
[14:50:17.432] iteration 1827: loss: 1.115288, loss_s1: 0.501349, loss_fp: 0.499999, loss_freq: 0.500663
[14:50:18.057] iteration 1828: loss: 1.140517, loss_s1: 0.451403, loss_fp: 0.500114, loss_freq: 0.500198
[14:50:18.682] iteration 1829: loss: 1.077884, loss_s1: 0.436070, loss_fp: 0.500047, loss_freq: 0.500365
[14:50:19.303] iteration 1830: loss: 1.027377, loss_s1: 0.500148, loss_fp: 0.500025, loss_freq: 0.500015
[14:50:19.926] iteration 1831: loss: 1.076140, loss_s1: 0.500918, loss_fp: 0.500018, loss_freq: 0.500084
[14:50:20.549] iteration 1832: loss: 1.033935, loss_s1: 0.500549, loss_fp: 0.500081, loss_freq: 0.500026
[14:50:21.179] iteration 1833: loss: 1.080355, loss_s1: 0.500499, loss_fp: 0.500007, loss_freq: 0.500079
[14:50:21.801] iteration 1834: loss: 1.044534, loss_s1: 0.500188, loss_fp: 0.500028, loss_freq: 0.500040
[14:50:22.422] iteration 1835: loss: 1.042177, loss_s1: 0.500105, loss_fp: 0.500012, loss_freq: 0.500071
[14:50:23.042] iteration 1836: loss: 1.028024, loss_s1: 0.500055, loss_fp: 0.500016, loss_freq: 0.500008
[14:50:23.670] iteration 1837: loss: 0.968344, loss_s1: 0.500080, loss_fp: 0.500000, loss_freq: 0.500025
[14:50:24.293] iteration 1838: loss: 0.961004, loss_s1: 0.500169, loss_fp: 0.500047, loss_freq: 0.500233
[14:50:24.918] iteration 1839: loss: 0.918729, loss_s1: 0.500034, loss_fp: 0.500008, loss_freq: 0.500037
[14:50:25.545] iteration 1840: loss: 0.987876, loss_s1: 0.500129, loss_fp: 0.499999, loss_freq: 0.500098
[14:50:26.168] iteration 1841: loss: 1.050291, loss_s1: 0.500551, loss_fp: 0.500054, loss_freq: 0.500054
[14:50:26.789] iteration 1842: loss: 1.004764, loss_s1: 0.500382, loss_fp: 0.500024, loss_freq: 0.500089
[14:50:27.411] iteration 1843: loss: 1.019794, loss_s1: 0.500861, loss_fp: 0.500004, loss_freq: 0.500278
[14:50:28.033] iteration 1844: loss: 1.002366, loss_s1: 0.500889, loss_fp: 0.500012, loss_freq: 0.500436
[14:50:28.660] iteration 1845: loss: 1.015458, loss_s1: 0.501298, loss_fp: 0.500069, loss_freq: 0.500346
[14:50:29.283] iteration 1846: loss: 1.004965, loss_s1: 0.501706, loss_fp: 0.500040, loss_freq: 0.500381
[14:50:29.898] iteration 1847: loss: 0.970348, loss_s1: 0.500895, loss_fp: 0.500376, loss_freq: 0.500298
[14:50:30.518] iteration 1848: loss: 0.995919, loss_s1: 0.500792, loss_fp: 0.500045, loss_freq: 0.500329
[14:50:31.142] iteration 1849: loss: 0.957510, loss_s1: 0.501315, loss_fp: 0.500041, loss_freq: 0.500359
[14:50:31.767] iteration 1850: loss: 0.974784, loss_s1: 0.500282, loss_fp: 0.500009, loss_freq: 0.500090
[14:50:32.385] iteration 1851: loss: 1.020405, loss_s1: 0.500615, loss_fp: 0.500477, loss_freq: 0.500758
[14:50:33.008] iteration 1852: loss: 1.033033, loss_s1: 0.502356, loss_fp: 0.500008, loss_freq: 0.500879
[14:50:33.630] iteration 1853: loss: 0.996737, loss_s1: 0.500364, loss_fp: 0.501305, loss_freq: 0.500214
[14:50:34.252] iteration 1854: loss: 0.888621, loss_s1: 0.502084, loss_fp: 0.500168, loss_freq: 0.500879
[14:50:34.876] iteration 1855: loss: 0.995497, loss_s1: 0.500885, loss_fp: 0.500220, loss_freq: 0.500260
[14:50:35.497] iteration 1856: loss: 0.897943, loss_s1: 0.500415, loss_fp: 0.500043, loss_freq: 0.500172
[14:50:36.122] iteration 1857: loss: 0.860208, loss_s1: 0.501402, loss_fp: 0.500078, loss_freq: 0.500578
[14:50:36.746] iteration 1858: loss: 1.036693, loss_s1: 0.501363, loss_fp: 0.500014, loss_freq: 0.500400
[14:50:37.364] iteration 1859: loss: 0.945829, loss_s1: 0.502265, loss_fp: 0.500051, loss_freq: 0.500332
[14:50:37.983] iteration 1860: loss: 0.985597, loss_s1: 0.501450, loss_fp: 0.500014, loss_freq: 0.500740
[14:50:38.606] iteration 1861: loss: 1.023585, loss_s1: 0.501731, loss_fp: 0.500084, loss_freq: 0.500108
[14:50:39.227] iteration 1862: loss: 1.015284, loss_s1: 0.501281, loss_fp: 0.500211, loss_freq: 0.500162
[14:50:39.846] iteration 1863: loss: 1.012657, loss_s1: 0.502560, loss_fp: 0.500099, loss_freq: 0.501450
[14:50:40.472] iteration 1864: loss: 1.041437, loss_s1: 0.500358, loss_fp: 0.500053, loss_freq: 0.500267
[14:50:41.095] iteration 1865: loss: 0.942893, loss_s1: 0.501820, loss_fp: 0.500089, loss_freq: 0.500119
[14:50:41.722] iteration 1866: loss: 0.948195, loss_s1: 0.502940, loss_fp: 0.500005, loss_freq: 0.500319
[14:50:42.345] iteration 1867: loss: 0.893045, loss_s1: 0.501979, loss_fp: 0.500020, loss_freq: 0.500975
[14:50:42.967] iteration 1868: loss: 0.948152, loss_s1: 0.502203, loss_fp: 0.500013, loss_freq: 0.500174
[14:50:43.589] iteration 1869: loss: 0.971032, loss_s1: 0.502090, loss_fp: 0.500046, loss_freq: 0.501101
[14:50:44.210] iteration 1870: loss: 1.001955, loss_s1: 0.503583, loss_fp: 0.500072, loss_freq: 0.501077
[14:50:44.828] iteration 1871: loss: 0.920376, loss_s1: 0.501852, loss_fp: 0.500042, loss_freq: 0.500487
[14:50:45.453] iteration 1872: loss: 0.890421, loss_s1: 0.501627, loss_fp: 0.500030, loss_freq: 0.500421
[14:50:46.076] iteration 1873: loss: 0.678037, loss_s1: 0.489161, loss_fp: 0.135031, loss_freq: 0.397254
[14:50:46.698] iteration 1874: loss: 0.908307, loss_s1: 0.502238, loss_fp: 0.500153, loss_freq: 0.501506
[14:50:47.321] iteration 1875: loss: 0.935762, loss_s1: 0.502230, loss_fp: 0.500034, loss_freq: 0.500681
[14:50:47.945] iteration 1876: loss: 0.970881, loss_s1: 0.501822, loss_fp: 0.500029, loss_freq: 0.500781
[14:50:48.564] iteration 1877: loss: 0.987451, loss_s1: 0.501752, loss_fp: 0.500025, loss_freq: 0.500339
[14:50:49.193] iteration 1878: loss: 0.905467, loss_s1: 0.502737, loss_fp: 0.500015, loss_freq: 0.500666
[14:50:49.817] iteration 1879: loss: 0.937357, loss_s1: 0.504403, loss_fp: 0.500046, loss_freq: 0.501506
[14:50:50.441] iteration 1880: loss: 0.968652, loss_s1: 0.502269, loss_fp: 0.500025, loss_freq: 0.501379
[14:50:51.075] iteration 1881: loss: 0.993720, loss_s1: 0.500180, loss_fp: 0.500009, loss_freq: 0.500375
[14:50:51.704] iteration 1882: loss: 0.992937, loss_s1: 0.501896, loss_fp: 0.500072, loss_freq: 0.501020
[14:50:52.330] iteration 1883: loss: 0.858842, loss_s1: 0.502808, loss_fp: 0.500023, loss_freq: 0.501922
[14:50:52.954] iteration 1884: loss: 0.867830, loss_s1: 0.503274, loss_fp: 0.500078, loss_freq: 0.502546
[14:50:53.585] iteration 1885: loss: 0.890106, loss_s1: 0.501314, loss_fp: 0.500016, loss_freq: 0.500529
[14:50:54.208] iteration 1886: loss: 0.979841, loss_s1: 0.500926, loss_fp: 0.500041, loss_freq: 0.500166
[14:50:54.837] iteration 1887: loss: 0.969519, loss_s1: 0.502776, loss_fp: 0.500046, loss_freq: 0.500802
[14:50:55.463] iteration 1888: loss: 0.916922, loss_s1: 0.501679, loss_fp: 0.500018, loss_freq: 0.500729
[14:50:56.086] iteration 1889: loss: 0.834431, loss_s1: 0.503963, loss_fp: 0.500112, loss_freq: 0.501848
[14:50:56.708] iteration 1890: loss: 0.943030, loss_s1: 0.502730, loss_fp: 0.500076, loss_freq: 0.501124
[14:50:57.330] iteration 1891: loss: 0.879149, loss_s1: 0.505310, loss_fp: 0.500056, loss_freq: 0.502916
[14:50:57.994] iteration 1892: loss: 0.884429, loss_s1: 0.503055, loss_fp: 0.500043, loss_freq: 0.501665
[14:50:58.615] iteration 1893: loss: 0.444697, loss_s1: 0.337468, loss_fp: 0.021340, loss_freq: 0.062126
[14:50:59.235] iteration 1894: loss: 0.893688, loss_s1: 0.503327, loss_fp: 0.500048, loss_freq: 0.501182
[14:50:59.854] iteration 1895: loss: 0.973090, loss_s1: 0.502182, loss_fp: 0.500034, loss_freq: 0.500753
[14:51:00.478] iteration 1896: loss: 0.864312, loss_s1: 0.388662, loss_fp: 0.500020, loss_freq: 0.500045
[14:51:01.104] iteration 1897: loss: 0.951355, loss_s1: 0.500424, loss_fp: 0.500058, loss_freq: 0.501628
[14:51:01.726] iteration 1898: loss: 0.921260, loss_s1: 0.500700, loss_fp: 0.500026, loss_freq: 0.501042
[14:51:02.349] iteration 1899: loss: 1.043912, loss_s1: 0.500741, loss_fp: 0.500029, loss_freq: 0.500144
[14:51:03.004] iteration 1900: loss: 0.933296, loss_s1: 0.500017, loss_fp: 0.500009, loss_freq: 0.500414
[14:51:03.742] iteration 1901: loss: 0.921665, loss_s1: 0.500278, loss_fp: 0.500010, loss_freq: 0.500075
[14:51:04.387] iteration 1902: loss: 0.853138, loss_s1: 0.500716, loss_fp: 0.500167, loss_freq: 0.500734
[14:51:05.031] iteration 1903: loss: 0.931194, loss_s1: 0.500782, loss_fp: 0.500071, loss_freq: 0.500439
[14:51:05.665] iteration 1904: loss: 0.907474, loss_s1: 0.500992, loss_fp: 0.500021, loss_freq: 0.500029
[14:51:06.293] iteration 1905: loss: 0.940294, loss_s1: 0.501153, loss_fp: 0.500005, loss_freq: 0.500101
[14:51:06.931] iteration 1906: loss: 0.351508, loss_s1: 0.364752, loss_fp: 0.006117, loss_freq: 0.051784
[14:51:07.553] iteration 1907: loss: 0.861464, loss_s1: 0.500579, loss_fp: 0.500010, loss_freq: 0.500693
[14:51:08.175] iteration 1908: loss: 0.909162, loss_s1: 0.501723, loss_fp: 0.500035, loss_freq: 0.500127
[14:51:08.798] iteration 1909: loss: 0.850353, loss_s1: 0.500276, loss_fp: 0.500023, loss_freq: 0.500027
[14:51:09.417] iteration 1910: loss: 0.902165, loss_s1: 0.500252, loss_fp: 0.500007, loss_freq: 0.500365
[14:51:10.036] iteration 1911: loss: 0.924446, loss_s1: 0.500962, loss_fp: 0.500028, loss_freq: 0.500115
[14:51:10.658] iteration 1912: loss: 0.955339, loss_s1: 0.500260, loss_fp: 0.500022, loss_freq: 0.500019
[14:51:11.280] iteration 1913: loss: 0.888298, loss_s1: 0.500071, loss_fp: 0.500036, loss_freq: 0.500308
[14:51:11.899] iteration 1914: loss: 0.912082, loss_s1: 0.501432, loss_fp: 0.500013, loss_freq: 0.500014
[14:51:12.519] iteration 1915: loss: 0.940290, loss_s1: 0.501676, loss_fp: 0.500039, loss_freq: 0.500179
[14:51:13.137] iteration 1916: loss: 0.939503, loss_s1: 0.500211, loss_fp: 0.500012, loss_freq: 0.500063
[14:51:13.763] iteration 1917: loss: 0.256990, loss_s1: 0.148899, loss_fp: 0.004002, loss_freq: 0.026951
[14:51:14.385] iteration 1918: loss: 0.893100, loss_s1: 0.500027, loss_fp: 0.500034, loss_freq: 0.500062
[14:51:15.008] iteration 1919: loss: 0.880538, loss_s1: 0.499703, loss_fp: 0.500007, loss_freq: 0.500062
[14:51:15.631] iteration 1920: loss: 0.864343, loss_s1: 0.500285, loss_fp: 0.500162, loss_freq: 0.500111
[14:51:16.258] iteration 1921: loss: 0.889843, loss_s1: 0.475764, loss_fp: 0.500022, loss_freq: 0.500048
[14:51:16.884] iteration 1922: loss: 0.983135, loss_s1: 0.500430, loss_fp: 0.500007, loss_freq: 0.500052
[14:51:17.504] iteration 1923: loss: 0.914463, loss_s1: 0.500183, loss_fp: 0.500040, loss_freq: 0.500038
[14:51:18.127] iteration 1924: loss: 0.846869, loss_s1: 0.500058, loss_fp: 0.500040, loss_freq: 0.500015
[14:51:18.751] iteration 1925: loss: 0.911326, loss_s1: 0.500167, loss_fp: 0.500004, loss_freq: 0.500138
[14:51:19.374] iteration 1926: loss: 0.852244, loss_s1: 0.501821, loss_fp: 0.500014, loss_freq: 0.500030
[14:51:19.996] iteration 1927: loss: 0.831494, loss_s1: 0.500675, loss_fp: 0.500284, loss_freq: 0.500012
[14:51:20.620] iteration 1928: loss: 1.031964, loss_s1: 0.501085, loss_fp: 0.500020, loss_freq: 0.500021
[14:51:21.239] iteration 1929: loss: 0.880628, loss_s1: 0.501679, loss_fp: 0.500024, loss_freq: 0.500312
[14:51:21.859] iteration 1930: loss: 0.938130, loss_s1: 0.501768, loss_fp: 0.500021, loss_freq: 0.500048
[14:51:22.477] iteration 1931: loss: 0.271131, loss_s1: 0.211036, loss_fp: 0.011018, loss_freq: 0.012170
[14:51:23.098] iteration 1932: loss: 0.583637, loss_s1: 0.375606, loss_fp: 0.159866, loss_freq: 0.268764
[14:51:24.016] iteration 1933: loss: 0.954308, loss_s1: 0.500161, loss_fp: 0.500006, loss_freq: 0.500008
[14:51:24.635] iteration 1934: loss: 0.884302, loss_s1: 0.500246, loss_fp: 0.500010, loss_freq: 0.500141
[14:51:25.261] iteration 1935: loss: 0.958179, loss_s1: 0.500061, loss_fp: 0.500002, loss_freq: 0.500013
[14:51:25.882] iteration 1936: loss: 1.043129, loss_s1: 0.500066, loss_fp: 0.500027, loss_freq: 0.500017
[14:51:26.512] iteration 1937: loss: 0.826257, loss_s1: 0.119694, loss_fp: 0.500015, loss_freq: 0.500007
[14:51:27.146] iteration 1938: loss: 1.098528, loss_s1: 0.500043, loss_fp: 0.500007, loss_freq: 0.500005
[14:51:27.765] iteration 1939: loss: 0.664427, loss_s1: 0.038311, loss_fp: 0.500013, loss_freq: 0.500005
[14:51:28.385] iteration 1940: loss: 0.914534, loss_s1: 0.500479, loss_fp: 0.500008, loss_freq: 0.500178
[14:51:29.004] iteration 1941: loss: 0.913777, loss_s1: 0.500718, loss_fp: 0.500090, loss_freq: 0.500005
[14:51:29.625] iteration 1942: loss: 0.969292, loss_s1: 0.498807, loss_fp: 0.500001, loss_freq: 0.500023
[14:51:30.249] iteration 1943: loss: 0.934362, loss_s1: 0.425353, loss_fp: 0.500006, loss_freq: 0.500027
[14:51:30.877] iteration 1944: loss: 0.911378, loss_s1: 0.501712, loss_fp: 0.500010, loss_freq: 0.500034
[14:51:31.500] iteration 1945: loss: 0.670916, loss_s1: 0.136994, loss_fp: 0.500008, loss_freq: 0.500011
[14:51:32.122] iteration 1946: loss: 0.718349, loss_s1: 0.482475, loss_fp: 0.051107, loss_freq: 0.309522
[14:51:32.743] iteration 1947: loss: 0.867482, loss_s1: 0.500392, loss_fp: 0.500163, loss_freq: 0.500029
[14:51:33.363] iteration 1948: loss: 0.894703, loss_s1: 0.500663, loss_fp: 0.500040, loss_freq: 0.500051
[14:51:33.988] iteration 1949: loss: 0.331103, loss_s1: 0.084192, loss_fp: 0.004739, loss_freq: 0.004787
[14:51:34.615] iteration 1950: loss: 0.908334, loss_s1: 0.500028, loss_fp: 0.500015, loss_freq: 0.500009
[14:51:35.240] iteration 1951: loss: 0.982836, loss_s1: 0.500007, loss_fp: 0.500023, loss_freq: 0.500015
[14:51:35.865] iteration 1952: loss: 0.920879, loss_s1: 0.500062, loss_fp: 0.500008, loss_freq: 0.500008
[14:51:36.490] iteration 1953: loss: 0.967153, loss_s1: 0.500060, loss_fp: 0.500016, loss_freq: 0.500062
[14:51:37.122] iteration 1954: loss: 0.970457, loss_s1: 0.500680, loss_fp: 0.500011, loss_freq: 0.500123
[14:51:37.752] iteration 1955: loss: 0.465726, loss_s1: 0.060898, loss_fp: 0.243942, loss_freq: 0.028594
[14:51:38.388] iteration 1956: loss: 0.922458, loss_s1: 0.500676, loss_fp: 0.500009, loss_freq: 0.500159
[14:51:39.017] iteration 1957: loss: 0.894266, loss_s1: 0.501400, loss_fp: 0.500017, loss_freq: 0.500158
[14:51:39.639] iteration 1958: loss: 0.844535, loss_s1: 0.500224, loss_fp: 0.500011, loss_freq: 0.499999
[14:51:40.265] iteration 1959: loss: 0.959922, loss_s1: 0.500272, loss_fp: 0.500036, loss_freq: 0.500003
[14:51:40.891] iteration 1960: loss: 0.888116, loss_s1: 0.501008, loss_fp: 0.500007, loss_freq: 0.500230
[14:51:41.516] iteration 1961: loss: 0.996980, loss_s1: 0.500847, loss_fp: 0.500009, loss_freq: 0.500008
[14:51:42.142] iteration 1962: loss: 0.924466, loss_s1: 0.500155, loss_fp: 0.500003, loss_freq: 0.500191
[14:51:42.772] iteration 1963: loss: 0.873541, loss_s1: 0.500648, loss_fp: 0.500006, loss_freq: 0.500093
[14:51:43.398] iteration 1964: loss: 0.428268, loss_s1: 0.396459, loss_fp: 0.006020, loss_freq: 0.006274
[14:51:44.024] iteration 1965: loss: 0.842826, loss_s1: 0.500984, loss_fp: 0.500003, loss_freq: 0.500567
[14:51:44.649] iteration 1966: loss: 0.299850, loss_s1: 0.321384, loss_fp: 0.001648, loss_freq: 0.010064
[14:51:45.272] iteration 1967: loss: 0.976904, loss_s1: 0.500427, loss_fp: 0.500025, loss_freq: 0.500117
[14:51:45.892] iteration 1968: loss: 0.978303, loss_s1: 0.500272, loss_fp: 0.500035, loss_freq: 0.500000
[14:51:46.523] iteration 1969: loss: 0.880718, loss_s1: 0.500937, loss_fp: 0.500004, loss_freq: 0.500325
[14:51:47.151] iteration 1970: loss: 0.930838, loss_s1: 0.500667, loss_fp: 0.500006, loss_freq: 0.500286
[14:51:47.773] iteration 1971: loss: 0.939390, loss_s1: 0.500513, loss_fp: 0.500004, loss_freq: 0.500252
[14:51:48.396] iteration 1972: loss: 0.931638, loss_s1: 0.500379, loss_fp: 0.499999, loss_freq: 0.500027
[14:51:49.020] iteration 1973: loss: 0.931813, loss_s1: 0.500721, loss_fp: 0.500000, loss_freq: 0.500056
[14:51:49.644] iteration 1974: loss: 0.443687, loss_s1: 0.363173, loss_fp: 0.023179, loss_freq: 0.180255
[14:51:50.267] iteration 1975: loss: 0.895123, loss_s1: 0.500233, loss_fp: 0.500005, loss_freq: 0.500426
[14:51:50.889] iteration 1976: loss: 0.859051, loss_s1: 0.500028, loss_fp: 0.500013, loss_freq: 0.500023
[14:51:51.507] iteration 1977: loss: 0.315484, loss_s1: 0.312855, loss_fp: 0.003949, loss_freq: 0.022481
[14:51:52.132] iteration 1978: loss: 0.952637, loss_s1: 0.500065, loss_fp: 0.499998, loss_freq: 0.500002
[14:51:52.757] iteration 1979: loss: 0.938965, loss_s1: 0.500003, loss_fp: 0.500014, loss_freq: 0.499999
[14:51:53.383] iteration 1980: loss: 0.884933, loss_s1: 0.500006, loss_fp: 0.500003, loss_freq: 0.500003
[14:51:54.009] iteration 1981: loss: 1.001253, loss_s1: 0.500015, loss_fp: 0.500002, loss_freq: 0.500001
[14:51:54.640] iteration 1982: loss: 0.856026, loss_s1: 0.500010, loss_fp: 0.500000, loss_freq: 0.500003
[14:51:55.262] iteration 1983: loss: 0.852341, loss_s1: 0.500013, loss_fp: 0.500058, loss_freq: 0.500003
[14:51:55.892] iteration 1984: loss: 1.047272, loss_s1: 0.500015, loss_fp: 0.500001, loss_freq: 0.500002
[14:51:56.516] iteration 1985: loss: 0.905383, loss_s1: 0.500114, loss_fp: 0.499999, loss_freq: 0.500021
[14:51:57.139] iteration 1986: loss: 0.987354, loss_s1: 0.500063, loss_fp: 0.500008, loss_freq: 0.500044
[14:51:57.761] iteration 1987: loss: 0.889647, loss_s1: 0.500286, loss_fp: 0.500005, loss_freq: 0.500005
[14:51:58.383] iteration 1988: loss: 0.914524, loss_s1: 0.500955, loss_fp: 0.500023, loss_freq: 0.500766
[14:51:59.008] iteration 1989: loss: 0.925075, loss_s1: 0.502328, loss_fp: 0.500010, loss_freq: 0.500390
[14:51:59.635] iteration 1990: loss: 0.922811, loss_s1: 0.501371, loss_fp: 0.499998, loss_freq: 0.500509
[14:52:00.262] iteration 1991: loss: 0.912872, loss_s1: 0.501216, loss_fp: 0.500073, loss_freq: 0.501596
[14:52:00.890] iteration 1992: loss: 0.853405, loss_s1: 0.501264, loss_fp: 0.499999, loss_freq: 0.500713
[14:52:01.511] iteration 1993: loss: 0.844600, loss_s1: 0.501944, loss_fp: 0.500013, loss_freq: 0.500466
[14:52:02.138] iteration 1994: loss: 0.887230, loss_s1: 0.502990, loss_fp: 0.500004, loss_freq: 0.500535
[14:52:02.767] iteration 1995: loss: 0.795546, loss_s1: 0.364855, loss_fp: 0.500000, loss_freq: 0.500629
[14:52:03.397] iteration 1996: loss: 0.949800, loss_s1: 0.503929, loss_fp: 0.500000, loss_freq: 0.501827
[14:52:04.018] iteration 1997: loss: 0.297755, loss_s1: 0.151538, loss_fp: 0.004573, loss_freq: 0.185520
[14:52:04.635] iteration 1998: loss: 0.864499, loss_s1: 0.500657, loss_fp: 0.500000, loss_freq: 0.500115
[14:52:05.261] iteration 1999: loss: 0.900466, loss_s1: 0.500311, loss_fp: 0.500005, loss_freq: 0.500149
[14:52:05.892] iteration 2000: loss: 0.763004, loss_s1: 0.344242, loss_fp: 0.500002, loss_freq: 0.499996
[14:52:08.347] iteration 2000 : mean_dice : 0.192005
[14:52:08.994] iteration 2001: loss: 0.896176, loss_s1: 0.500273, loss_fp: 0.500035, loss_freq: 0.500002
[14:52:09.616] iteration 2002: loss: 0.962692, loss_s1: 0.500071, loss_fp: 0.500069, loss_freq: 0.500300
[14:52:10.243] iteration 2003: loss: 0.970152, loss_s1: 0.500180, loss_fp: 0.500004, loss_freq: 0.500003
[14:52:10.867] iteration 2004: loss: 0.902046, loss_s1: 0.500064, loss_fp: 0.500003, loss_freq: 0.500006
[14:52:11.497] iteration 2005: loss: 0.988300, loss_s1: 0.500043, loss_fp: 0.500019, loss_freq: 0.500028
[14:52:12.121] iteration 2006: loss: 0.926684, loss_s1: 0.499733, loss_fp: 0.500008, loss_freq: 0.500031
[14:52:12.745] iteration 2007: loss: 0.942905, loss_s1: 0.500078, loss_fp: 0.500008, loss_freq: 0.500071
[14:52:13.370] iteration 2008: loss: 0.927957, loss_s1: 0.500055, loss_fp: 0.500003, loss_freq: 0.500045
[14:52:13.990] iteration 2009: loss: 0.233074, loss_s1: 0.125638, loss_fp: 0.008659, loss_freq: 0.026094
[14:52:14.616] iteration 2010: loss: 0.883956, loss_s1: 0.500691, loss_fp: 0.500009, loss_freq: 0.500233
[14:52:15.244] iteration 2011: loss: 0.127730, loss_s1: 0.025180, loss_fp: 0.003477, loss_freq: 0.003011
[14:52:15.866] iteration 2012: loss: 0.887317, loss_s1: 0.500754, loss_fp: 0.500017, loss_freq: 0.500207
[14:52:16.496] iteration 2013: loss: 0.948782, loss_s1: 0.500490, loss_fp: 0.500021, loss_freq: 0.500274
[14:52:17.119] iteration 2014: loss: 0.293404, loss_s1: 0.325543, loss_fp: 0.011074, loss_freq: 0.017810
[14:52:17.742] iteration 2015: loss: 0.874508, loss_s1: 0.501575, loss_fp: 0.500005, loss_freq: 0.501044
[14:52:18.364] iteration 2016: loss: 0.916819, loss_s1: 0.500591, loss_fp: 0.500010, loss_freq: 0.500066
[14:52:18.984] iteration 2017: loss: 0.859110, loss_s1: 0.500011, loss_fp: 0.500012, loss_freq: 0.500105
[14:52:19.611] iteration 2018: loss: 0.827513, loss_s1: 0.500616, loss_fp: 0.499997, loss_freq: 0.500920
[14:52:20.235] iteration 2019: loss: 0.400588, loss_s1: 0.238540, loss_fp: 0.003801, loss_freq: 0.036085
[14:52:20.853] iteration 2020: loss: 0.889569, loss_s1: 0.500115, loss_fp: 0.500004, loss_freq: 0.500171
[14:52:21.479] iteration 2021: loss: 0.259850, loss_s1: 0.042021, loss_fp: 0.002421, loss_freq: 0.004893
[14:52:22.101] iteration 2022: loss: 0.891525, loss_s1: 0.500099, loss_fp: 0.500000, loss_freq: 0.499994
[14:52:22.723] iteration 2023: loss: 1.042642, loss_s1: 0.499998, loss_fp: 0.499997, loss_freq: 0.499995
[14:52:23.346] iteration 2024: loss: 0.952435, loss_s1: 0.500185, loss_fp: 0.500023, loss_freq: 0.499997
[14:52:23.970] iteration 2025: loss: 0.988862, loss_s1: 0.500504, loss_fp: 0.500021, loss_freq: 0.499997
[14:52:24.589] iteration 2026: loss: 0.932237, loss_s1: 0.500087, loss_fp: 0.500007, loss_freq: 0.499991
[14:52:25.213] iteration 2027: loss: 0.872553, loss_s1: 0.500076, loss_fp: 0.500017, loss_freq: 0.500012
[14:52:25.835] iteration 2028: loss: 0.841459, loss_s1: 0.500083, loss_fp: 0.500026, loss_freq: 0.500016
[14:52:26.456] iteration 2029: loss: 0.944731, loss_s1: 0.501201, loss_fp: 0.500016, loss_freq: 0.500003
[14:52:27.086] iteration 2030: loss: 0.929390, loss_s1: 0.500010, loss_fp: 0.500007, loss_freq: 0.500030
[14:52:27.711] iteration 2031: loss: 0.924775, loss_s1: 0.500324, loss_fp: 0.500010, loss_freq: 0.500033
[14:52:28.334] iteration 2032: loss: 0.881177, loss_s1: 0.500925, loss_fp: 0.500019, loss_freq: 0.500005
[14:52:28.954] iteration 2033: loss: 0.877770, loss_s1: 0.503221, loss_fp: 0.500024, loss_freq: 0.500217
[14:52:29.573] iteration 2034: loss: 0.323114, loss_s1: 0.312945, loss_fp: 0.001176, loss_freq: 0.004819
[14:52:30.200] iteration 2035: loss: 0.903866, loss_s1: 0.502283, loss_fp: 0.500016, loss_freq: 0.501100
[14:52:30.824] iteration 2036: loss: 0.185472, loss_s1: 0.018552, loss_fp: 0.001883, loss_freq: 0.002673
[14:52:31.448] iteration 2037: loss: 0.464340, loss_s1: 0.220356, loss_fp: 0.005107, loss_freq: 0.260634
[14:52:32.077] iteration 2038: loss: 0.478457, loss_s1: 0.423922, loss_fp: 0.089707, loss_freq: 0.055365
[14:52:32.698] iteration 2039: loss: 0.901966, loss_s1: 0.500314, loss_fp: 0.500002, loss_freq: 0.500003
[14:52:33.320] iteration 2040: loss: 0.891544, loss_s1: 0.500140, loss_fp: 0.500046, loss_freq: 0.500025
[14:52:33.947] iteration 2041: loss: 0.981023, loss_s1: 0.500027, loss_fp: 0.500001, loss_freq: 0.500005
[14:52:34.573] iteration 2042: loss: 0.978040, loss_s1: 0.500001, loss_fp: 0.500001, loss_freq: 0.499999
[14:52:35.201] iteration 2043: loss: 0.970712, loss_s1: 0.500000, loss_fp: 0.500000, loss_freq: 0.499999
[14:52:35.825] iteration 2044: loss: 0.905080, loss_s1: 0.500005, loss_fp: 0.500011, loss_freq: 0.500001
[14:52:36.448] iteration 2045: loss: 0.881174, loss_s1: 0.500008, loss_fp: 0.500001, loss_freq: 0.500000
[14:52:37.082] iteration 2046: loss: 0.869993, loss_s1: 0.500007, loss_fp: 0.500005, loss_freq: 0.500000
[14:52:37.707] iteration 2047: loss: 0.907948, loss_s1: 0.500005, loss_fp: 0.499989, loss_freq: 0.500000
[14:52:38.330] iteration 2048: loss: 0.292762, loss_s1: 0.236677, loss_fp: 0.005217, loss_freq: 0.015390
[14:52:38.952] iteration 2049: loss: 0.875997, loss_s1: 0.500027, loss_fp: 0.499992, loss_freq: 0.500005
[14:52:39.575] iteration 2050: loss: 0.133626, loss_s1: 0.037725, loss_fp: 0.001984, loss_freq: 0.005528
[14:52:40.199] iteration 2051: loss: 0.914684, loss_s1: 0.500066, loss_fp: 0.499997, loss_freq: 0.500002
[14:52:40.822] iteration 2052: loss: 0.859418, loss_s1: 0.500059, loss_fp: 0.500093, loss_freq: 0.500008
[14:52:41.448] iteration 2053: loss: 0.862869, loss_s1: 0.500048, loss_fp: 0.499973, loss_freq: 0.500022
[14:52:42.071] iteration 2054: loss: 0.244699, loss_s1: 0.001857, loss_fp: 0.002539, loss_freq: 0.003912
[14:52:42.692] iteration 2055: loss: 0.875146, loss_s1: 0.500733, loss_fp: 0.500027, loss_freq: 0.500003
[14:52:43.318] iteration 2056: loss: 0.919801, loss_s1: 0.500060, loss_fp: 0.499995, loss_freq: 0.500370
[14:52:43.941] iteration 2057: loss: 0.310157, loss_s1: 0.303416, loss_fp: 0.004423, loss_freq: 0.026055
[14:52:44.567] iteration 2058: loss: 0.938356, loss_s1: 0.500003, loss_fp: 0.499995, loss_freq: 0.500008
[14:52:45.193] iteration 2059: loss: 0.899644, loss_s1: 0.499999, loss_fp: 0.500000, loss_freq: 0.500000
[14:52:45.814] iteration 2060: loss: 1.010537, loss_s1: 0.500001, loss_fp: 0.499983, loss_freq: 0.499993
[14:52:46.438] iteration 2061: loss: 0.906774, loss_s1: 0.500000, loss_fp: 0.500002, loss_freq: 0.500000
[14:52:47.057] iteration 2062: loss: 0.886835, loss_s1: 0.500006, loss_fp: 0.499991, loss_freq: 0.499997
[14:52:47.677] iteration 2063: loss: 0.876571, loss_s1: 0.500004, loss_fp: 0.499993, loss_freq: 0.499999
[14:52:48.301] iteration 2064: loss: 0.901292, loss_s1: 0.500001, loss_fp: 0.500008, loss_freq: 0.500000
[14:52:48.921] iteration 2065: loss: 0.915793, loss_s1: 0.500002, loss_fp: 0.500010, loss_freq: 0.499998
[14:52:49.543] iteration 2066: loss: 0.884018, loss_s1: 0.500018, loss_fp: 0.500000, loss_freq: 0.499998
[14:52:50.165] iteration 2067: loss: 0.851993, loss_s1: 0.500018, loss_fp: 0.499992, loss_freq: 0.500003
[14:52:50.789] iteration 2068: loss: 0.924969, loss_s1: 0.500015, loss_fp: 0.500001, loss_freq: 0.500005
[14:52:51.412] iteration 2069: loss: 0.983844, loss_s1: 0.500015, loss_fp: 0.500008, loss_freq: 0.500015
[14:52:52.034] iteration 2070: loss: 0.821255, loss_s1: 0.501205, loss_fp: 0.499985, loss_freq: 0.500024
[14:52:52.656] iteration 2071: loss: 0.885152, loss_s1: 0.500141, loss_fp: 0.500015, loss_freq: 0.500080
[14:52:53.279] iteration 2072: loss: 0.441866, loss_s1: 0.493842, loss_fp: 0.002623, loss_freq: 0.050383
[14:52:53.895] iteration 2073: loss: 0.933015, loss_s1: 0.500006, loss_fp: 0.500015, loss_freq: 0.500034
[14:52:54.518] iteration 2074: loss: 0.888168, loss_s1: 0.500006, loss_fp: 0.500130, loss_freq: 0.500004
[14:52:55.142] iteration 2075: loss: 0.859587, loss_s1: 0.500021, loss_fp: 0.499983, loss_freq: 0.499998
[14:52:55.792] iteration 2076: loss: 0.880256, loss_s1: 0.500017, loss_fp: 0.499995, loss_freq: 0.500003
[14:52:56.422] iteration 2077: loss: 0.939860, loss_s1: 0.500164, loss_fp: 0.500000, loss_freq: 0.500007
[14:52:57.051] iteration 2078: loss: 0.305535, loss_s1: 0.133019, loss_fp: 0.000947, loss_freq: 0.007729
[14:52:57.679] iteration 2079: loss: 0.218826, loss_s1: 0.158949, loss_fp: 0.002438, loss_freq: 0.011346
[14:52:58.309] iteration 2080: loss: 0.229861, loss_s1: 0.028806, loss_fp: 0.006761, loss_freq: 0.170329
[14:52:58.935] iteration 2081: loss: 0.843280, loss_s1: 0.500010, loss_fp: 0.499996, loss_freq: 0.500013
[14:52:59.559] iteration 2082: loss: 0.289416, loss_s1: 0.242384, loss_fp: 0.010225, loss_freq: 0.030303
[14:53:00.182] iteration 2083: loss: 0.911884, loss_s1: 0.500343, loss_fp: 0.499997, loss_freq: 0.500040
[14:53:00.804] iteration 2084: loss: 0.879427, loss_s1: 0.500148, loss_fp: 0.499990, loss_freq: 0.500009
[14:53:01.424] iteration 2085: loss: 0.854215, loss_s1: 0.500034, loss_fp: 0.500000, loss_freq: 0.500009
[14:53:02.046] iteration 2086: loss: 0.940239, loss_s1: 0.500017, loss_fp: 0.500065, loss_freq: 0.500009
[14:53:02.676] iteration 2087: loss: 0.829356, loss_s1: 0.500006, loss_fp: 0.500000, loss_freq: 0.500004
[14:53:03.297] iteration 2088: loss: 0.820915, loss_s1: 0.500021, loss_fp: 0.500005, loss_freq: 0.500015
[14:53:03.918] iteration 2089: loss: 0.529783, loss_s1: 0.459706, loss_fp: 0.014954, loss_freq: 0.100158
[14:53:04.546] iteration 2090: loss: 0.891679, loss_s1: 0.500803, loss_fp: 0.499998, loss_freq: 0.500014
[14:53:05.175] iteration 2091: loss: 0.967871, loss_s1: 0.500011, loss_fp: 0.500025, loss_freq: 0.500000
[14:53:05.796] iteration 2092: loss: 0.934234, loss_s1: 0.495132, loss_fp: 0.500008, loss_freq: 0.500009
[14:53:06.421] iteration 2093: loss: 0.252458, loss_s1: 0.115810, loss_fp: 0.008901, loss_freq: 0.010863
[14:53:07.383] iteration 2094: loss: 0.236442, loss_s1: 0.041173, loss_fp: 0.000994, loss_freq: 0.055787
[14:53:08.016] iteration 2095: loss: 0.912208, loss_s1: 0.501582, loss_fp: 0.500007, loss_freq: 0.500143
[14:53:08.895] iteration 2096: loss: 0.405933, loss_s1: 0.448559, loss_fp: 0.003751, loss_freq: 0.053835
[14:53:09.653] iteration 2097: loss: 0.346530, loss_s1: 0.224806, loss_fp: 0.001498, loss_freq: 0.134637
[14:53:10.400] iteration 2098: loss: 0.302146, loss_s1: 0.157434, loss_fp: 0.003265, loss_freq: 0.001425
[14:53:11.046] iteration 2099: loss: 0.922014, loss_s1: 0.501166, loss_fp: 0.500026, loss_freq: 0.500049
[14:53:11.673] iteration 2100: loss: 0.207357, loss_s1: 0.155541, loss_fp: 0.010555, loss_freq: 0.001867
[14:53:12.294] iteration 2101: loss: 0.391291, loss_s1: 0.312772, loss_fp: 0.007125, loss_freq: 0.174703
[14:53:12.915] iteration 2102: loss: 0.206717, loss_s1: 0.020965, loss_fp: 0.020008, loss_freq: 0.032589
[14:53:13.539] iteration 2103: loss: 0.481714, loss_s1: 0.163216, loss_fp: 0.283501, loss_freq: 0.102978
[14:53:14.174] iteration 2104: loss: 0.248560, loss_s1: 0.191818, loss_fp: 0.003740, loss_freq: 0.010986
[14:53:14.823] iteration 2105: loss: 0.965856, loss_s1: 0.500065, loss_fp: 0.500003, loss_freq: 0.499997
[14:53:15.457] iteration 2106: loss: 0.766635, loss_s1: 0.499923, loss_fp: 0.192107, loss_freq: 0.445160
[14:53:16.093] iteration 2107: loss: 0.939829, loss_s1: 0.500010, loss_fp: 0.500003, loss_freq: 0.499993
[14:53:16.733] iteration 2108: loss: 0.403272, loss_s1: 0.462518, loss_fp: 0.001912, loss_freq: 0.081640
[14:53:17.370] iteration 2109: loss: 0.918819, loss_s1: 0.500380, loss_fp: 0.500008, loss_freq: 0.500017
[14:53:18.008] iteration 2110: loss: 0.637930, loss_s1: 0.500545, loss_fp: 0.001486, loss_freq: 0.028628
[14:53:18.642] iteration 2111: loss: 0.536006, loss_s1: 0.397937, loss_fp: 0.001525, loss_freq: 0.121306
[14:53:19.286] iteration 2112: loss: 0.693817, loss_s1: 0.396692, loss_fp: 0.039035, loss_freq: 0.173933
[14:53:19.921] iteration 2113: loss: 0.376780, loss_s1: 0.164722, loss_fp: 0.001008, loss_freq: 0.116818
[14:53:20.541] iteration 2114: loss: 0.424821, loss_s1: 0.126212, loss_fp: 0.005410, loss_freq: 0.172283
[14:53:21.161] iteration 2115: loss: 0.594270, loss_s1: 0.351331, loss_fp: 0.036587, loss_freq: 0.102282
[14:53:21.799] iteration 2116: loss: 0.561008, loss_s1: 0.183842, loss_fp: 0.001938, loss_freq: 0.297151
[14:53:22.420] iteration 2117: loss: 0.659508, loss_s1: 0.395756, loss_fp: 0.046265, loss_freq: 0.395088
[14:53:23.049] iteration 2118: loss: 0.833539, loss_s1: 0.312556, loss_fp: 0.500001, loss_freq: 0.500085
[14:53:23.670] iteration 2119: loss: 0.368085, loss_s1: 0.252891, loss_fp: 0.002536, loss_freq: 0.077480
[14:53:24.295] iteration 2120: loss: 0.431333, loss_s1: 0.191067, loss_fp: 0.001601, loss_freq: 0.046373
[14:53:24.921] iteration 2121: loss: 0.494933, loss_s1: 0.150454, loss_fp: 0.002248, loss_freq: 0.267634
[14:53:25.545] iteration 2122: loss: 0.303575, loss_s1: 0.010020, loss_fp: 0.001139, loss_freq: 0.009493
[14:53:26.173] iteration 2123: loss: 0.430707, loss_s1: 0.191018, loss_fp: 0.003018, loss_freq: 0.124478
[14:53:26.799] iteration 2124: loss: 0.378883, loss_s1: 0.363741, loss_fp: 0.010167, loss_freq: 0.061413
[14:53:27.424] iteration 2125: loss: 0.293446, loss_s1: 0.131847, loss_fp: 0.005963, loss_freq: 0.006009
[14:53:28.046] iteration 2126: loss: 0.305077, loss_s1: 0.306586, loss_fp: 0.004338, loss_freq: 0.005769
[14:53:28.671] iteration 2127: loss: 0.312441, loss_s1: 0.195980, loss_fp: 0.001538, loss_freq: 0.007933
[14:53:29.300] iteration 2128: loss: 0.405509, loss_s1: 0.273976, loss_fp: 0.002523, loss_freq: 0.008621
[14:53:29.933] iteration 2129: loss: 0.254687, loss_s1: 0.080002, loss_fp: 0.010466, loss_freq: 0.008659
[14:53:30.555] iteration 2130: loss: 0.454815, loss_s1: 0.225784, loss_fp: 0.008988, loss_freq: 0.191341
[14:53:31.185] iteration 2131: loss: 0.468491, loss_s1: 0.337441, loss_fp: 0.022063, loss_freq: 0.123477
[14:53:31.814] iteration 2132: loss: 0.366787, loss_s1: 0.225908, loss_fp: 0.015160, loss_freq: 0.030089
[14:53:32.433] iteration 2133: loss: 0.671935, loss_s1: 0.484367, loss_fp: 0.180469, loss_freq: 0.253644
[14:53:33.059] iteration 2134: loss: 0.271187, loss_s1: 0.133727, loss_fp: 0.002024, loss_freq: 0.004698
[14:53:33.687] iteration 2135: loss: 0.185897, loss_s1: 0.017455, loss_fp: 0.004856, loss_freq: 0.001593
[14:53:34.308] iteration 2136: loss: 0.517954, loss_s1: 0.299973, loss_fp: 0.002546, loss_freq: 0.375352
[14:53:34.928] iteration 2137: loss: 0.215688, loss_s1: 0.088998, loss_fp: 0.001881, loss_freq: 0.005846
[14:53:35.552] iteration 2138: loss: 0.428108, loss_s1: 0.229013, loss_fp: 0.003611, loss_freq: 0.200950
[14:53:36.211] iteration 2139: loss: 0.381469, loss_s1: 0.191288, loss_fp: 0.006250, loss_freq: 0.024418
[14:53:36.840] iteration 2140: loss: 0.308353, loss_s1: 0.154623, loss_fp: 0.001938, loss_freq: 0.076415
[14:53:37.496] iteration 2141: loss: 0.251665, loss_s1: 0.143840, loss_fp: 0.010331, loss_freq: 0.103878
[14:53:38.116] iteration 2142: loss: 1.004183, loss_s1: 0.500007, loss_fp: 0.500004, loss_freq: 0.500003
[14:53:38.765] iteration 2143: loss: 0.875016, loss_s1: 0.500214, loss_fp: 0.500009, loss_freq: 0.500007
[14:53:39.394] iteration 2144: loss: 0.384021, loss_s1: 0.489075, loss_fp: 0.006491, loss_freq: 0.027496
[14:53:40.022] iteration 2145: loss: 0.529051, loss_s1: 0.181705, loss_fp: 0.011355, loss_freq: 0.017217
[14:53:40.649] iteration 2146: loss: 0.218346, loss_s1: 0.032931, loss_fp: 0.017868, loss_freq: 0.012399
[14:53:41.274] iteration 2147: loss: 0.969889, loss_s1: 0.461835, loss_fp: 0.500000, loss_freq: 0.500049
[14:53:41.905] iteration 2148: loss: 0.410587, loss_s1: 0.152180, loss_fp: 0.000537, loss_freq: 0.004006
[14:53:42.540] iteration 2149: loss: 1.011924, loss_s1: 0.501131, loss_fp: 0.500005, loss_freq: 0.500069
[14:53:43.168] iteration 2150: loss: 0.334929, loss_s1: 0.029099, loss_fp: 0.001375, loss_freq: 0.124767
[14:53:43.795] iteration 2151: loss: 0.776376, loss_s1: 0.485447, loss_fp: 0.229922, loss_freq: 0.343275
[14:53:44.424] iteration 2152: loss: 0.939214, loss_s1: 0.500300, loss_fp: 0.500021, loss_freq: 0.500029
[14:53:45.056] iteration 2153: loss: 0.971679, loss_s1: 0.500113, loss_fp: 0.500008, loss_freq: 0.500017
[14:53:45.698] iteration 2154: loss: 0.963767, loss_s1: 0.500144, loss_fp: 0.500011, loss_freq: 0.500018
[14:53:46.332] iteration 2155: loss: 0.989369, loss_s1: 0.500137, loss_fp: 0.500250, loss_freq: 0.500010
[14:53:46.954] iteration 2156: loss: 0.965641, loss_s1: 0.500012, loss_fp: 0.500003, loss_freq: 0.500014
[14:53:47.584] iteration 2157: loss: 0.989115, loss_s1: 0.500500, loss_fp: 0.500018, loss_freq: 0.500086
[14:53:48.213] iteration 2158: loss: 0.908729, loss_s1: 0.501157, loss_fp: 0.500003, loss_freq: 0.499993
[14:53:48.834] iteration 2159: loss: 0.355194, loss_s1: 0.154060, loss_fp: 0.091762, loss_freq: 0.193847
[14:53:49.456] iteration 2160: loss: 0.931681, loss_s1: 0.500044, loss_fp: 0.500001, loss_freq: 0.499995
[14:53:50.083] iteration 2161: loss: 0.883077, loss_s1: 0.499757, loss_fp: 0.500006, loss_freq: 0.499991
[14:53:50.712] iteration 2162: loss: 0.942821, loss_s1: 0.500000, loss_fp: 0.499998, loss_freq: 0.499998
[14:53:51.331] iteration 2163: loss: 0.986431, loss_s1: 0.500083, loss_fp: 0.500000, loss_freq: 0.500002
[14:53:51.952] iteration 2164: loss: 0.967026, loss_s1: 0.500101, loss_fp: 0.500008, loss_freq: 0.500087
[14:53:52.609] iteration 2165: loss: 0.929086, loss_s1: 0.500010, loss_fp: 0.499995, loss_freq: 0.499997
[14:53:53.231] iteration 2166: loss: 1.030299, loss_s1: 0.500004, loss_fp: 0.499996, loss_freq: 0.499999
[14:53:53.856] iteration 2167: loss: 0.402292, loss_s1: 0.179543, loss_fp: 0.000913, loss_freq: 0.016406
[14:53:54.481] iteration 2168: loss: 1.014535, loss_s1: 0.500008, loss_fp: 0.499997, loss_freq: 0.500005
[14:53:55.106] iteration 2169: loss: 0.957818, loss_s1: 0.500346, loss_fp: 0.500001, loss_freq: 0.500005
[14:53:55.727] iteration 2170: loss: 0.924173, loss_s1: 0.500057, loss_fp: 0.500010, loss_freq: 0.500015
[14:53:56.349] iteration 2171: loss: 0.912776, loss_s1: 0.500142, loss_fp: 0.500001, loss_freq: 0.500011
[14:53:56.972] iteration 2172: loss: 0.350583, loss_s1: 0.308547, loss_fp: 0.001156, loss_freq: 0.028140
[14:53:57.594] iteration 2173: loss: 0.969510, loss_s1: 0.500213, loss_fp: 0.500009, loss_freq: 0.500098
[14:53:58.214] iteration 2174: loss: 0.952449, loss_s1: 0.500839, loss_fp: 0.499991, loss_freq: 0.500159
[14:53:58.833] iteration 2175: loss: 0.597487, loss_s1: 0.467146, loss_fp: 0.018171, loss_freq: 0.216851
[14:53:59.458] iteration 2176: loss: 0.881408, loss_s1: 0.500344, loss_fp: 0.500002, loss_freq: 0.500346
[14:54:00.083] iteration 2177: loss: 0.920924, loss_s1: 0.500482, loss_fp: 0.499999, loss_freq: 0.500006
[14:54:00.707] iteration 2178: loss: 0.297052, loss_s1: 0.278841, loss_fp: 0.048795, loss_freq: 0.042895
[14:54:01.334] iteration 2179: loss: 0.840343, loss_s1: 0.500012, loss_fp: 0.500003, loss_freq: 0.500005
[14:54:01.953] iteration 2180: loss: 0.518722, loss_s1: 0.406014, loss_fp: 0.001285, loss_freq: 0.000988
[14:54:02.570] iteration 2181: loss: 0.454034, loss_s1: 0.499886, loss_fp: 0.039137, loss_freq: 0.036703
[14:54:03.189] iteration 2182: loss: 0.943889, loss_s1: 0.500067, loss_fp: 0.499997, loss_freq: 0.500017
[14:54:03.807] iteration 2183: loss: 0.528430, loss_s1: 0.477769, loss_fp: 0.002671, loss_freq: 0.180050
[14:54:04.425] iteration 2184: loss: 0.346246, loss_s1: 0.046886, loss_fp: 0.001099, loss_freq: 0.025745
[14:54:05.043] iteration 2185: loss: 0.811084, loss_s1: 0.115184, loss_fp: 0.499991, loss_freq: 0.500102
[14:54:05.658] iteration 2186: loss: 0.462944, loss_s1: 0.284078, loss_fp: 0.002533, loss_freq: 0.035296
[14:54:06.275] iteration 2187: loss: 0.463429, loss_s1: 0.084904, loss_fp: 0.050413, loss_freq: 0.401701
[14:54:06.897] iteration 2188: loss: 0.359712, loss_s1: 0.302115, loss_fp: 0.003073, loss_freq: 0.106262
[14:54:07.513] iteration 2189: loss: 0.194506, loss_s1: 0.065129, loss_fp: 0.001210, loss_freq: 0.045339
[14:54:08.136] iteration 2190: loss: 0.314499, loss_s1: 0.143370, loss_fp: 0.000711, loss_freq: 0.015835
[14:54:08.755] iteration 2191: loss: 0.282315, loss_s1: 0.159489, loss_fp: 0.003297, loss_freq: 0.027978
[14:54:09.382] iteration 2192: loss: 0.381927, loss_s1: 0.330231, loss_fp: 0.001757, loss_freq: 0.022809
[14:54:09.997] iteration 2193: loss: 0.349112, loss_s1: 0.104471, loss_fp: 0.004180, loss_freq: 0.257365
[14:54:10.623] iteration 2194: loss: 0.907301, loss_s1: 0.500673, loss_fp: 0.500003, loss_freq: 0.500000
[14:54:11.247] iteration 2195: loss: 0.256637, loss_s1: 0.060324, loss_fp: 0.033866, loss_freq: 0.002252
[14:54:11.857] iteration 2196: loss: 0.883615, loss_s1: 0.500216, loss_fp: 0.500002, loss_freq: 0.500001
[14:54:12.480] iteration 2197: loss: 0.322280, loss_s1: 0.234221, loss_fp: 0.002455, loss_freq: 0.004653
[14:54:13.104] iteration 2198: loss: 1.000366, loss_s1: 0.500051, loss_fp: 0.500011, loss_freq: 0.500004
[14:54:13.729] iteration 2199: loss: 0.327973, loss_s1: 0.017462, loss_fp: 0.086749, loss_freq: 0.014126
[14:54:14.356] iteration 2200: loss: 0.279884, loss_s1: 0.113575, loss_fp: 0.002618, loss_freq: 0.057665
[14:54:16.486] iteration 2200 : mean_dice : 0.059524
[14:54:17.137] iteration 2201: loss: 0.997221, loss_s1: 0.500228, loss_fp: 0.499999, loss_freq: 0.500000
[14:54:17.760] iteration 2202: loss: 0.937077, loss_s1: 0.500012, loss_fp: 0.500001, loss_freq: 0.500147
[14:54:18.380] iteration 2203: loss: 1.029967, loss_s1: 0.500013, loss_fp: 0.500009, loss_freq: 0.500012
[14:54:19.004] iteration 2204: loss: 0.968378, loss_s1: 0.500228, loss_fp: 0.499987, loss_freq: 0.500021
[14:54:19.629] iteration 2205: loss: 0.464482, loss_s1: 0.383200, loss_fp: 0.010064, loss_freq: 0.175374
[14:54:20.256] iteration 2206: loss: 0.298265, loss_s1: 0.172436, loss_fp: 0.010648, loss_freq: 0.027140
[14:54:20.883] iteration 2207: loss: 0.893433, loss_s1: 0.500055, loss_fp: 0.500008, loss_freq: 0.500069
[14:54:21.508] iteration 2208: loss: 0.244283, loss_s1: 0.107491, loss_fp: 0.001209, loss_freq: 0.002427
[14:54:22.133] iteration 2209: loss: 0.459912, loss_s1: 0.368200, loss_fp: 0.001353, loss_freq: 0.021208
[14:54:22.758] iteration 2210: loss: 0.923988, loss_s1: 0.500028, loss_fp: 0.500004, loss_freq: 0.500001
[14:54:23.380] iteration 2211: loss: 0.183413, loss_s1: 0.066371, loss_fp: 0.002825, loss_freq: 0.015020
[14:54:23.993] iteration 2212: loss: 0.924508, loss_s1: 0.500483, loss_fp: 0.499997, loss_freq: 0.500434
[14:54:24.613] iteration 2213: loss: 0.852244, loss_s1: 0.500077, loss_fp: 0.499997, loss_freq: 0.500331
[14:54:25.229] iteration 2214: loss: 0.877782, loss_s1: 0.500316, loss_fp: 0.500005, loss_freq: 0.500060
[14:54:25.854] iteration 2215: loss: 0.346118, loss_s1: 0.009364, loss_fp: 0.000691, loss_freq: 0.001116
[14:54:26.474] iteration 2216: loss: 0.175776, loss_s1: 0.009788, loss_fp: 0.007388, loss_freq: 0.002862
[14:54:27.092] iteration 2217: loss: 0.872877, loss_s1: 0.280155, loss_fp: 0.499995, loss_freq: 0.500234
[14:54:27.714] iteration 2218: loss: 0.267352, loss_s1: 0.035939, loss_fp: 0.000795, loss_freq: 0.001801
[14:54:28.338] iteration 2219: loss: 1.000523, loss_s1: 0.500123, loss_fp: 0.499996, loss_freq: 0.500049
[14:54:28.961] iteration 2220: loss: 0.286342, loss_s1: 0.188267, loss_fp: 0.003724, loss_freq: 0.011841
[14:54:29.585] iteration 2221: loss: 0.357703, loss_s1: 0.206425, loss_fp: 0.003649, loss_freq: 0.001367
[14:54:30.204] iteration 2222: loss: 0.934294, loss_s1: 0.500002, loss_fp: 0.499996, loss_freq: 0.500002
[14:54:30.823] iteration 2223: loss: 0.167656, loss_s1: 0.004052, loss_fp: 0.001630, loss_freq: 0.008802
[14:54:31.444] iteration 2224: loss: 0.863174, loss_s1: 0.500212, loss_fp: 0.499999, loss_freq: 0.499999
[14:54:32.068] iteration 2225: loss: 0.950872, loss_s1: 0.500314, loss_fp: 0.500000, loss_freq: 0.500026
[14:54:32.694] iteration 2226: loss: 0.898738, loss_s1: 0.499990, loss_fp: 0.499981, loss_freq: 0.500003
[14:54:33.375] iteration 2227: loss: 0.452011, loss_s1: 0.440986, loss_fp: 0.019565, loss_freq: 0.011224
[14:54:34.004] iteration 2228: loss: 0.358651, loss_s1: 0.327313, loss_fp: 0.000922, loss_freq: 0.020361
[14:54:34.650] iteration 2229: loss: 0.879016, loss_s1: 0.500273, loss_fp: 0.500002, loss_freq: 0.500046
[14:54:35.295] iteration 2230: loss: 0.192444, loss_s1: 0.001826, loss_fp: 0.001588, loss_freq: 0.002438
[14:54:35.929] iteration 2231: loss: 0.184222, loss_s1: 0.149171, loss_fp: 0.001042, loss_freq: 0.001208
[14:54:36.561] iteration 2232: loss: 0.904887, loss_s1: 0.500163, loss_fp: 0.500000, loss_freq: 0.500037
[14:54:37.195] iteration 2233: loss: 0.243869, loss_s1: 0.014502, loss_fp: 0.000672, loss_freq: 0.007991
[14:54:37.830] iteration 2234: loss: 0.230618, loss_s1: 0.000717, loss_fp: 0.000806, loss_freq: 0.000940
[14:54:38.457] iteration 2235: loss: 0.491344, loss_s1: 0.161890, loss_fp: 0.001130, loss_freq: 0.489722
[14:54:39.089] iteration 2236: loss: 0.245852, loss_s1: 0.134512, loss_fp: 0.001905, loss_freq: 0.003702
[14:54:39.715] iteration 2237: loss: 0.975674, loss_s1: 0.499999, loss_fp: 0.500004, loss_freq: 0.499999
[14:54:40.349] iteration 2238: loss: 0.978655, loss_s1: 0.499996, loss_fp: 0.500008, loss_freq: 0.499997
[14:54:40.982] iteration 2239: loss: 0.202509, loss_s1: 0.006428, loss_fp: 0.003188, loss_freq: 0.001015
[14:54:41.612] iteration 2240: loss: 0.488009, loss_s1: 0.077741, loss_fp: 0.002264, loss_freq: 0.491614
[14:54:42.243] iteration 2241: loss: 0.259178, loss_s1: 0.180059, loss_fp: 0.001509, loss_freq: 0.038343
[14:54:42.879] iteration 2242: loss: 0.195667, loss_s1: 0.153000, loss_fp: 0.001515, loss_freq: 0.001723
[14:54:43.518] iteration 2243: loss: 0.272205, loss_s1: 0.159148, loss_fp: 0.003732, loss_freq: 0.002758
[14:54:44.145] iteration 2244: loss: 0.418836, loss_s1: 0.499658, loss_fp: 0.000730, loss_freq: 0.001483
[14:54:44.771] iteration 2245: loss: 0.322254, loss_s1: 0.353693, loss_fp: 0.005024, loss_freq: 0.005954
[14:54:45.399] iteration 2246: loss: 0.273382, loss_s1: 0.283937, loss_fp: 0.003163, loss_freq: 0.003886
[14:54:46.025] iteration 2247: loss: 0.365834, loss_s1: 0.151404, loss_fp: 0.011866, loss_freq: 0.146960
[14:54:46.652] iteration 2248: loss: 0.327262, loss_s1: 0.366812, loss_fp: 0.006213, loss_freq: 0.053820
[14:54:47.280] iteration 2249: loss: 0.200975, loss_s1: 0.078882, loss_fp: 0.001519, loss_freq: 0.113413
[14:54:47.906] iteration 2250: loss: 0.266071, loss_s1: 0.077123, loss_fp: 0.001881, loss_freq: 0.002920
[14:54:48.533] iteration 2251: loss: 0.488096, loss_s1: 0.315330, loss_fp: 0.002016, loss_freq: 0.379112
[14:54:49.157] iteration 2252: loss: 0.666058, loss_s1: 0.112472, loss_fp: 0.407270, loss_freq: 0.398616
[14:54:49.778] iteration 2253: loss: 0.184988, loss_s1: 0.051471, loss_fp: 0.002348, loss_freq: 0.046840
[14:54:50.401] iteration 2254: loss: 0.248394, loss_s1: 0.018821, loss_fp: 0.001484, loss_freq: 0.003225
[14:54:51.336] iteration 2255: loss: 0.288882, loss_s1: 0.118189, loss_fp: 0.003507, loss_freq: 0.003400
[14:54:51.973] iteration 2256: loss: 0.863700, loss_s1: 0.500156, loss_fp: 0.500004, loss_freq: 0.500128
[14:54:52.642] iteration 2257: loss: 0.982778, loss_s1: 0.499539, loss_fp: 0.500002, loss_freq: 0.500003
[14:54:53.266] iteration 2258: loss: 0.370511, loss_s1: 0.348318, loss_fp: 0.004049, loss_freq: 0.025442
[14:54:53.901] iteration 2259: loss: 0.654269, loss_s1: 0.122415, loss_fp: 0.226491, loss_freq: 0.380059
[14:54:54.526] iteration 2260: loss: 1.005043, loss_s1: 0.500482, loss_fp: 0.499999, loss_freq: 0.500295
[14:54:55.154] iteration 2261: loss: 0.229668, loss_s1: 0.112716, loss_fp: 0.001333, loss_freq: 0.006723
[14:54:55.778] iteration 2262: loss: 0.900766, loss_s1: 0.500012, loss_fp: 0.500002, loss_freq: 0.499992
[14:54:56.405] iteration 2263: loss: 0.902801, loss_s1: 0.500408, loss_fp: 0.500000, loss_freq: 0.499994
[14:54:57.034] iteration 2264: loss: 0.299337, loss_s1: 0.127238, loss_fp: 0.002603, loss_freq: 0.015945
[14:54:57.662] iteration 2265: loss: 0.235655, loss_s1: 0.037037, loss_fp: 0.003233, loss_freq: 0.007571
[14:54:58.289] iteration 2266: loss: 0.963664, loss_s1: 0.500121, loss_fp: 0.499996, loss_freq: 0.500011
[14:54:58.905] iteration 2267: loss: 0.616106, loss_s1: 0.146773, loss_fp: 0.359577, loss_freq: 0.433489
[14:54:59.523] iteration 2268: loss: 0.977423, loss_s1: 0.499999, loss_fp: 0.500000, loss_freq: 0.500000
[14:55:00.146] iteration 2269: loss: 0.535421, loss_s1: 0.450208, loss_fp: 0.031916, loss_freq: 0.380843
[14:55:00.767] iteration 2270: loss: 0.847833, loss_s1: 0.449390, loss_fp: 0.500003, loss_freq: 0.499997
[14:55:01.392] iteration 2271: loss: 0.405705, loss_s1: 0.205624, loss_fp: 0.000825, loss_freq: 0.007292
[14:55:02.013] iteration 2272: loss: 0.955337, loss_s1: 0.500011, loss_fp: 0.499998, loss_freq: 0.499986
[14:55:02.638] iteration 2273: loss: 0.872206, loss_s1: 0.222066, loss_fp: 0.499999, loss_freq: 0.499997
[14:55:03.256] iteration 2274: loss: 0.329934, loss_s1: 0.096964, loss_fp: 0.000877, loss_freq: 0.007684
[14:55:03.876] iteration 2275: loss: 0.230479, loss_s1: 0.018536, loss_fp: 0.002462, loss_freq: 0.018364
[14:55:04.509] iteration 2276: loss: 0.417354, loss_s1: 0.204814, loss_fp: 0.002875, loss_freq: 0.087047
[14:55:05.138] iteration 2277: loss: 0.324872, loss_s1: 0.064168, loss_fp: 0.001715, loss_freq: 0.026122
[14:55:05.760] iteration 2278: loss: 0.254982, loss_s1: 0.072619, loss_fp: 0.001058, loss_freq: 0.052358
[14:55:06.384] iteration 2279: loss: 0.441645, loss_s1: 0.411286, loss_fp: 0.009466, loss_freq: 0.009241
[14:55:07.000] iteration 2280: loss: 0.178911, loss_s1: 0.092424, loss_fp: 0.000542, loss_freq: 0.000630
[14:55:07.624] iteration 2281: loss: 0.245547, loss_s1: 0.027671, loss_fp: 0.000781, loss_freq: 0.000844
[14:55:08.248] iteration 2282: loss: 0.336919, loss_s1: 0.106657, loss_fp: 0.001290, loss_freq: 0.011457
[14:55:08.872] iteration 2283: loss: 0.321654, loss_s1: 0.210039, loss_fp: 0.000374, loss_freq: 0.001725
[14:55:09.492] iteration 2284: loss: 0.448357, loss_s1: 0.242960, loss_fp: 0.001432, loss_freq: 0.050906
[14:55:10.116] iteration 2285: loss: 0.356468, loss_s1: 0.204323, loss_fp: 0.008553, loss_freq: 0.207547
[14:55:10.735] iteration 2286: loss: 0.250767, loss_s1: 0.030159, loss_fp: 0.000690, loss_freq: 0.025728
[14:55:11.357] iteration 2287: loss: 0.239689, loss_s1: 0.137798, loss_fp: 0.001170, loss_freq: 0.004525
[14:55:11.980] iteration 2288: loss: 0.233606, loss_s1: 0.098936, loss_fp: 0.021435, loss_freq: 0.000742
[14:55:12.612] iteration 2289: loss: 0.385142, loss_s1: 0.071869, loss_fp: 0.001232, loss_freq: 0.083179
[14:55:13.250] iteration 2290: loss: 0.306179, loss_s1: 0.073225, loss_fp: 0.000892, loss_freq: 0.003642
[14:55:13.875] iteration 2291: loss: 0.413641, loss_s1: 0.296228, loss_fp: 0.025269, loss_freq: 0.079952
[14:55:14.501] iteration 2292: loss: 0.959881, loss_s1: 0.501488, loss_fp: 0.499999, loss_freq: 0.500000
[14:55:15.297] iteration 2293: loss: 1.006035, loss_s1: 0.500092, loss_fp: 0.500012, loss_freq: 0.500004
[14:55:15.936] iteration 2294: loss: 0.748433, loss_s1: 0.476344, loss_fp: 0.104607, loss_freq: 0.369022
[14:55:16.570] iteration 2295: loss: 0.284616, loss_s1: 0.002027, loss_fp: 0.001274, loss_freq: 0.001500
[14:55:17.194] iteration 2296: loss: 0.378977, loss_s1: 0.027565, loss_fp: 0.000823, loss_freq: 0.355012
[14:55:17.820] iteration 2297: loss: 0.475409, loss_s1: 0.397902, loss_fp: 0.011381, loss_freq: 0.170771
[14:55:18.448] iteration 2298: loss: 0.944453, loss_s1: 0.500099, loss_fp: 0.499996, loss_freq: 0.500099
[14:55:19.076] iteration 2299: loss: 0.300153, loss_s1: 0.154067, loss_fp: 0.001611, loss_freq: 0.001969
[14:55:19.701] iteration 2300: loss: 1.000303, loss_s1: 0.500428, loss_fp: 0.500003, loss_freq: 0.500005
[14:55:20.323] iteration 2301: loss: 0.213575, loss_s1: 0.047673, loss_fp: 0.001774, loss_freq: 0.002562
[14:55:20.940] iteration 2302: loss: 0.432297, loss_s1: 0.496037, loss_fp: 0.003943, loss_freq: 0.003164
[14:55:21.559] iteration 2303: loss: 0.337702, loss_s1: 0.148614, loss_fp: 0.001323, loss_freq: 0.085146
[14:55:22.178] iteration 2304: loss: 0.289806, loss_s1: 0.051756, loss_fp: 0.031472, loss_freq: 0.153804
[14:55:22.802] iteration 2305: loss: 0.818224, loss_s1: 0.468727, loss_fp: 0.421638, loss_freq: 0.443423
[14:55:23.423] iteration 2306: loss: 0.349096, loss_s1: 0.054818, loss_fp: 0.001192, loss_freq: 0.002759
[14:55:24.049] iteration 2307: loss: 0.249277, loss_s1: 0.061200, loss_fp: 0.002378, loss_freq: 0.003979
[14:55:24.674] iteration 2308: loss: 0.253953, loss_s1: 0.013794, loss_fp: 0.002888, loss_freq: 0.006579
[14:55:25.332] iteration 2309: loss: 0.382985, loss_s1: 0.087607, loss_fp: 0.002867, loss_freq: 0.129535
[14:55:25.957] iteration 2310: loss: 0.955792, loss_s1: 0.500554, loss_fp: 0.499997, loss_freq: 0.500234
[14:55:26.582] iteration 2311: loss: 0.365778, loss_s1: 0.224682, loss_fp: 0.083986, loss_freq: 0.004353
[14:55:27.266] iteration 2312: loss: 0.370674, loss_s1: 0.214930, loss_fp: 0.001368, loss_freq: 0.003955
[14:55:27.892] iteration 2313: loss: 0.287687, loss_s1: 0.108012, loss_fp: 0.002775, loss_freq: 0.005870
[14:55:28.514] iteration 2314: loss: 0.280624, loss_s1: 0.012433, loss_fp: 0.010774, loss_freq: 0.208176
[14:55:29.147] iteration 2315: loss: 0.182991, loss_s1: 0.107158, loss_fp: 0.001365, loss_freq: 0.001712
[14:55:29.771] iteration 2316: loss: 0.356135, loss_s1: 0.178904, loss_fp: 0.000905, loss_freq: 0.193795
[14:55:30.408] iteration 2317: loss: 0.188118, loss_s1: 0.041317, loss_fp: 0.002053, loss_freq: 0.002323
[14:55:31.049] iteration 2318: loss: 0.319865, loss_s1: 0.153523, loss_fp: 0.001824, loss_freq: 0.003283
[14:55:31.689] iteration 2319: loss: 0.419555, loss_s1: 0.366459, loss_fp: 0.002859, loss_freq: 0.015917
[14:55:32.311] iteration 2320: loss: 0.273179, loss_s1: 0.206202, loss_fp: 0.001449, loss_freq: 0.001821
[14:55:32.933] iteration 2321: loss: 0.973388, loss_s1: 0.500011, loss_fp: 0.500152, loss_freq: 0.500016
[14:55:33.555] iteration 2322: loss: 0.231078, loss_s1: 0.156362, loss_fp: 0.000829, loss_freq: 0.032498
[14:55:34.179] iteration 2323: loss: 0.254877, loss_s1: 0.109022, loss_fp: 0.001857, loss_freq: 0.027165
[14:55:34.805] iteration 2324: loss: 0.384029, loss_s1: 0.243523, loss_fp: 0.001537, loss_freq: 0.040282
[14:55:35.429] iteration 2325: loss: 0.430909, loss_s1: 0.413206, loss_fp: 0.000816, loss_freq: 0.013235
[14:55:36.062] iteration 2326: loss: 0.229505, loss_s1: 0.036299, loss_fp: 0.001916, loss_freq: 0.000857
[14:55:36.686] iteration 2327: loss: 0.231142, loss_s1: 0.172843, loss_fp: 0.001681, loss_freq: 0.003274
[14:55:37.312] iteration 2328: loss: 0.937592, loss_s1: 0.454840, loss_fp: 0.500013, loss_freq: 0.500008
[14:55:37.937] iteration 2329: loss: 1.014199, loss_s1: 0.500769, loss_fp: 0.500018, loss_freq: 0.500032
[14:55:38.561] iteration 2330: loss: 0.918081, loss_s1: 0.500778, loss_fp: 0.400739, loss_freq: 0.473281
[14:55:39.188] iteration 2331: loss: 0.254445, loss_s1: 0.026331, loss_fp: 0.001709, loss_freq: 0.001749
[14:55:39.811] iteration 2332: loss: 0.312337, loss_s1: 0.220651, loss_fp: 0.004710, loss_freq: 0.059087
[14:55:40.435] iteration 2333: loss: 0.179439, loss_s1: 0.037689, loss_fp: 0.000905, loss_freq: 0.001628
[14:55:41.059] iteration 2334: loss: 0.344262, loss_s1: 0.180119, loss_fp: 0.004858, loss_freq: 0.030634
[14:55:41.684] iteration 2335: loss: 0.375967, loss_s1: 0.097249, loss_fp: 0.041761, loss_freq: 0.056104
[14:55:42.337] iteration 2336: loss: 0.281163, loss_s1: 0.220059, loss_fp: 0.001171, loss_freq: 0.000971
[14:55:42.974] iteration 2337: loss: 0.169324, loss_s1: 0.061055, loss_fp: 0.001253, loss_freq: 0.006201
[14:55:43.608] iteration 2338: loss: 0.983758, loss_s1: 0.499997, loss_fp: 0.500003, loss_freq: 0.499995
[14:55:44.233] iteration 2339: loss: 0.391710, loss_s1: 0.103682, loss_fp: 0.035244, loss_freq: 0.420656
[14:55:44.860] iteration 2340: loss: 0.453000, loss_s1: 0.494681, loss_fp: 0.168666, loss_freq: 0.050118
[14:55:45.489] iteration 2341: loss: 0.471689, loss_s1: 0.295277, loss_fp: 0.002361, loss_freq: 0.010008
[14:55:46.118] iteration 2342: loss: 0.915468, loss_s1: 0.499999, loss_fp: 0.499996, loss_freq: 0.499996
[14:55:46.747] iteration 2343: loss: 0.967202, loss_s1: 0.500000, loss_fp: 0.499996, loss_freq: 0.499993
[14:55:47.377] iteration 2344: loss: 0.261103, loss_s1: 0.150917, loss_fp: 0.004623, loss_freq: 0.027302
[14:55:48.004] iteration 2345: loss: 0.446497, loss_s1: 0.122815, loss_fp: 0.002441, loss_freq: 0.151668
[14:55:48.630] iteration 2346: loss: 0.484944, loss_s1: 0.347410, loss_fp: 0.001178, loss_freq: 0.134017
[14:55:49.250] iteration 2347: loss: 0.357775, loss_s1: 0.006406, loss_fp: 0.001170, loss_freq: 0.064127
[14:55:49.871] iteration 2348: loss: 0.286052, loss_s1: 0.153431, loss_fp: 0.000816, loss_freq: 0.023321
[14:55:50.491] iteration 2349: loss: 0.250748, loss_s1: 0.134111, loss_fp: 0.001119, loss_freq: 0.077721
[14:55:51.118] iteration 2350: loss: 0.250095, loss_s1: 0.221252, loss_fp: 0.001007, loss_freq: 0.039709
[14:55:51.744] iteration 2351: loss: 0.278760, loss_s1: 0.145804, loss_fp: 0.000343, loss_freq: 0.022514
[14:55:52.372] iteration 2352: loss: 0.261095, loss_s1: 0.061167, loss_fp: 0.000911, loss_freq: 0.107569
[14:55:52.997] iteration 2353: loss: 0.289254, loss_s1: 0.167726, loss_fp: 0.001292, loss_freq: 0.020152
[14:55:53.649] iteration 2354: loss: 0.226904, loss_s1: 0.121353, loss_fp: 0.000403, loss_freq: 0.038317
[14:55:54.281] iteration 2355: loss: 0.193071, loss_s1: 0.101062, loss_fp: 0.000666, loss_freq: 0.060160
[14:55:54.904] iteration 2356: loss: 0.238917, loss_s1: 0.124665, loss_fp: 0.000757, loss_freq: 0.084940
[14:55:55.526] iteration 2357: loss: 0.393699, loss_s1: 0.340576, loss_fp: 0.001247, loss_freq: 0.177698
[14:55:56.146] iteration 2358: loss: 0.232516, loss_s1: 0.088189, loss_fp: 0.000733, loss_freq: 0.028147
[14:55:56.775] iteration 2359: loss: 0.411507, loss_s1: 0.178553, loss_fp: 0.000771, loss_freq: 0.137422
[14:55:57.399] iteration 2360: loss: 0.246857, loss_s1: 0.091501, loss_fp: 0.000514, loss_freq: 0.001472
[14:55:58.022] iteration 2361: loss: 0.286007, loss_s1: 0.183341, loss_fp: 0.001303, loss_freq: 0.014875
[14:55:58.647] iteration 2362: loss: 0.552546, loss_s1: 0.439083, loss_fp: 0.005453, loss_freq: 0.288821
[14:55:59.267] iteration 2363: loss: 0.484635, loss_s1: 0.271699, loss_fp: 0.010807, loss_freq: 0.306977
[14:55:59.889] iteration 2364: loss: 0.337801, loss_s1: 0.111265, loss_fp: 0.000689, loss_freq: 0.038014
[14:56:00.512] iteration 2365: loss: 0.212339, loss_s1: 0.049451, loss_fp: 0.000727, loss_freq: 0.000724
[14:56:01.129] iteration 2366: loss: 0.341437, loss_s1: 0.348919, loss_fp: 0.002022, loss_freq: 0.035822
[14:56:01.756] iteration 2367: loss: 0.409886, loss_s1: 0.212406, loss_fp: 0.003344, loss_freq: 0.261245
[14:56:02.378] iteration 2368: loss: 0.259899, loss_s1: 0.215991, loss_fp: 0.001095, loss_freq: 0.052455
[14:56:03.002] iteration 2369: loss: 0.286575, loss_s1: 0.173487, loss_fp: 0.002843, loss_freq: 0.006455
[14:56:03.625] iteration 2370: loss: 0.233544, loss_s1: 0.028377, loss_fp: 0.000607, loss_freq: 0.000731
[14:56:04.245] iteration 2371: loss: 0.282549, loss_s1: 0.263209, loss_fp: 0.000296, loss_freq: 0.001337
[14:56:04.869] iteration 2372: loss: 0.215494, loss_s1: 0.193709, loss_fp: 0.002394, loss_freq: 0.008588
[14:56:05.485] iteration 2373: loss: 0.966123, loss_s1: 0.500028, loss_fp: 0.499999, loss_freq: 0.500057
[14:56:06.118] iteration 2374: loss: 0.560674, loss_s1: 0.477836, loss_fp: 0.041030, loss_freq: 0.373911
[14:56:06.749] iteration 2375: loss: 0.282039, loss_s1: 0.284410, loss_fp: 0.001460, loss_freq: 0.022709
[14:56:07.376] iteration 2376: loss: 0.344480, loss_s1: 0.087191, loss_fp: 0.000593, loss_freq: 0.017202
[14:56:08.001] iteration 2377: loss: 0.214458, loss_s1: 0.141020, loss_fp: 0.000720, loss_freq: 0.008334
[14:56:08.625] iteration 2378: loss: 0.846129, loss_s1: 0.238039, loss_fp: 0.499998, loss_freq: 0.500056
[14:56:09.245] iteration 2379: loss: 0.230998, loss_s1: 0.018200, loss_fp: 0.002464, loss_freq: 0.000314
[14:56:09.863] iteration 2380: loss: 0.958991, loss_s1: 0.499997, loss_fp: 0.500000, loss_freq: 0.499994
[14:56:10.482] iteration 2381: loss: 0.940881, loss_s1: 0.500138, loss_fp: 0.499999, loss_freq: 0.500005
[14:56:11.104] iteration 2382: loss: 0.294761, loss_s1: 0.141021, loss_fp: 0.000636, loss_freq: 0.000769
[14:56:11.722] iteration 2383: loss: 0.286410, loss_s1: 0.154469, loss_fp: 0.025722, loss_freq: 0.098144
[14:56:12.340] iteration 2384: loss: 0.349003, loss_s1: 0.424279, loss_fp: 0.000820, loss_freq: 0.003363
[14:56:12.961] iteration 2385: loss: 0.443747, loss_s1: 0.372633, loss_fp: 0.000959, loss_freq: 0.328795
[14:56:13.580] iteration 2386: loss: 0.369631, loss_s1: 0.312780, loss_fp: 0.001537, loss_freq: 0.108786
[14:56:14.211] iteration 2387: loss: 0.218803, loss_s1: 0.059489, loss_fp: 0.041146, loss_freq: 0.035640
[14:56:14.828] iteration 2388: loss: 0.443569, loss_s1: 0.453591, loss_fp: 0.000498, loss_freq: 0.002914
[14:56:15.459] iteration 2389: loss: 0.206264, loss_s1: 0.141624, loss_fp: 0.000623, loss_freq: 0.005867
[14:56:16.088] iteration 2390: loss: 0.903525, loss_s1: 0.501128, loss_fp: 0.500040, loss_freq: 0.500057
[14:56:16.710] iteration 2391: loss: 0.378363, loss_s1: 0.157250, loss_fp: 0.001212, loss_freq: 0.210026
[14:56:17.327] iteration 2392: loss: 0.125542, loss_s1: 0.017476, loss_fp: 0.001135, loss_freq: 0.004158
[14:56:17.955] iteration 2393: loss: 0.318332, loss_s1: 0.076423, loss_fp: 0.000890, loss_freq: 0.165876
[14:56:18.574] iteration 2394: loss: 0.367294, loss_s1: 0.162259, loss_fp: 0.000668, loss_freq: 0.030165
[14:56:19.196] iteration 2395: loss: 0.359219, loss_s1: 0.224298, loss_fp: 0.008609, loss_freq: 0.064350
[14:56:19.816] iteration 2396: loss: 0.311778, loss_s1: 0.047107, loss_fp: 0.004034, loss_freq: 0.114464
[14:56:20.439] iteration 2397: loss: 0.242771, loss_s1: 0.054208, loss_fp: 0.000901, loss_freq: 0.002727
[14:56:21.064] iteration 2398: loss: 0.374129, loss_s1: 0.235095, loss_fp: 0.001057, loss_freq: 0.000568
[14:56:21.686] iteration 2399: loss: 0.258553, loss_s1: 0.016164, loss_fp: 0.001290, loss_freq: 0.045382
[14:56:22.306] iteration 2400: loss: 0.187428, loss_s1: 0.010058, loss_fp: 0.000531, loss_freq: 0.001911
[14:56:25.055] iteration 2400 : mean_dice : 0.265130
[14:56:25.688] iteration 2401: loss: 0.227650, loss_s1: 0.116097, loss_fp: 0.000778, loss_freq: 0.006348
[14:56:26.311] iteration 2402: loss: 0.353773, loss_s1: 0.187662, loss_fp: 0.001091, loss_freq: 0.150977
[14:56:26.936] iteration 2403: loss: 0.165560, loss_s1: 0.046172, loss_fp: 0.000495, loss_freq: 0.002942
[14:56:27.553] iteration 2404: loss: 0.253355, loss_s1: 0.119630, loss_fp: 0.000681, loss_freq: 0.001143
[14:56:28.174] iteration 2405: loss: 0.394328, loss_s1: 0.256178, loss_fp: 0.000930, loss_freq: 0.114897
[14:56:28.791] iteration 2406: loss: 0.229328, loss_s1: 0.082219, loss_fp: 0.000700, loss_freq: 0.006005
[14:56:29.411] iteration 2407: loss: 0.127965, loss_s1: 0.015295, loss_fp: 0.000507, loss_freq: 0.009538
[14:56:30.033] iteration 2408: loss: 0.526064, loss_s1: 0.500690, loss_fp: 0.000713, loss_freq: 0.030938
[14:56:30.655] iteration 2409: loss: 0.276021, loss_s1: 0.266166, loss_fp: 0.001194, loss_freq: 0.000953
[14:56:31.274] iteration 2410: loss: 0.203993, loss_s1: 0.246324, loss_fp: 0.001486, loss_freq: 0.001126
[14:56:31.896] iteration 2411: loss: 0.282549, loss_s1: 0.003821, loss_fp: 0.000841, loss_freq: 0.012119
[14:56:32.521] iteration 2412: loss: 0.347444, loss_s1: 0.349797, loss_fp: 0.001363, loss_freq: 0.074314
[14:56:33.137] iteration 2413: loss: 0.322819, loss_s1: 0.200059, loss_fp: 0.002107, loss_freq: 0.000690
[14:56:33.758] iteration 2414: loss: 0.211195, loss_s1: 0.053335, loss_fp: 0.002136, loss_freq: 0.063398
[14:56:34.380] iteration 2415: loss: 0.247951, loss_s1: 0.050473, loss_fp: 0.002512, loss_freq: 0.002976
[14:56:35.311] iteration 2416: loss: 0.236355, loss_s1: 0.050557, loss_fp: 0.000516, loss_freq: 0.012575
[14:56:35.933] iteration 2417: loss: 0.922442, loss_s1: 0.500610, loss_fp: 0.500011, loss_freq: 0.500337
[14:56:36.558] iteration 2418: loss: 0.272294, loss_s1: 0.214821, loss_fp: 0.001337, loss_freq: 0.002173
[14:56:37.182] iteration 2419: loss: 0.190585, loss_s1: 0.001428, loss_fp: 0.001184, loss_freq: 0.009544
[14:56:37.820] iteration 2420: loss: 0.272795, loss_s1: 0.065840, loss_fp: 0.000460, loss_freq: 0.001129
[14:56:38.437] iteration 2421: loss: 0.260750, loss_s1: 0.092207, loss_fp: 0.004317, loss_freq: 0.001812
[14:56:39.056] iteration 2422: loss: 0.285605, loss_s1: 0.114070, loss_fp: 0.001134, loss_freq: 0.139820
[14:56:39.676] iteration 2423: loss: 0.247982, loss_s1: 0.198270, loss_fp: 0.001819, loss_freq: 0.054030
[14:56:40.300] iteration 2424: loss: 0.186091, loss_s1: 0.131390, loss_fp: 0.004090, loss_freq: 0.028196
[14:56:40.922] iteration 2425: loss: 0.254211, loss_s1: 0.159769, loss_fp: 0.001257, loss_freq: 0.016112
[14:56:41.547] iteration 2426: loss: 0.233254, loss_s1: 0.065389, loss_fp: 0.000664, loss_freq: 0.002488
[14:56:42.167] iteration 2427: loss: 0.186868, loss_s1: 0.001142, loss_fp: 0.001020, loss_freq: 0.002138
[14:56:42.782] iteration 2428: loss: 0.179337, loss_s1: 0.069017, loss_fp: 0.000692, loss_freq: 0.044142
[14:56:43.397] iteration 2429: loss: 0.263601, loss_s1: 0.167990, loss_fp: 0.003311, loss_freq: 0.018728
[14:56:44.018] iteration 2430: loss: 0.244955, loss_s1: 0.210894, loss_fp: 0.000904, loss_freq: 0.002375
[14:56:44.635] iteration 2431: loss: 0.135670, loss_s1: 0.011361, loss_fp: 0.001862, loss_freq: 0.001315
[14:56:45.254] iteration 2432: loss: 0.343717, loss_s1: 0.163492, loss_fp: 0.000786, loss_freq: 0.019834
[14:56:45.872] iteration 2433: loss: 0.156580, loss_s1: 0.039515, loss_fp: 0.001114, loss_freq: 0.019048
[14:56:46.491] iteration 2434: loss: 0.208190, loss_s1: 0.003521, loss_fp: 0.000965, loss_freq: 0.003499
[14:56:47.117] iteration 2435: loss: 0.227681, loss_s1: 0.137502, loss_fp: 0.027268, loss_freq: 0.010126
[14:56:47.739] iteration 2436: loss: 0.895337, loss_s1: 0.500014, loss_fp: 0.499998, loss_freq: 0.500158
[14:56:48.358] iteration 2437: loss: 0.564328, loss_s1: 0.494360, loss_fp: 0.005487, loss_freq: 0.279074
[14:56:48.973] iteration 2438: loss: 0.293849, loss_s1: 0.101327, loss_fp: 0.001279, loss_freq: 0.017894
[14:56:49.594] iteration 2439: loss: 0.863319, loss_s1: 0.500586, loss_fp: 0.500002, loss_freq: 0.500430
[14:56:50.216] iteration 2440: loss: 0.228053, loss_s1: 0.206144, loss_fp: 0.001866, loss_freq: 0.002740
[14:56:50.839] iteration 2441: loss: 0.127969, loss_s1: 0.067522, loss_fp: 0.001858, loss_freq: 0.001077
[14:56:51.466] iteration 2442: loss: 0.262072, loss_s1: 0.239872, loss_fp: 0.002222, loss_freq: 0.000553
[14:56:52.092] iteration 2443: loss: 0.250931, loss_s1: 0.005554, loss_fp: 0.001153, loss_freq: 0.033155
[14:56:52.718] iteration 2444: loss: 0.205851, loss_s1: 0.029636, loss_fp: 0.001191, loss_freq: 0.001367
[14:56:53.340] iteration 2445: loss: 0.183711, loss_s1: 0.088437, loss_fp: 0.001141, loss_freq: 0.001044
[14:56:53.966] iteration 2446: loss: 0.847170, loss_s1: 0.500074, loss_fp: 0.500005, loss_freq: 0.500008
[14:56:54.590] iteration 2447: loss: 0.174406, loss_s1: 0.003583, loss_fp: 0.001531, loss_freq: 0.000829
[14:56:55.213] iteration 2448: loss: 0.099568, loss_s1: 0.011932, loss_fp: 0.000896, loss_freq: 0.000631
[14:56:55.842] iteration 2449: loss: 0.190598, loss_s1: 0.069090, loss_fp: 0.000739, loss_freq: 0.007478
[14:56:56.462] iteration 2450: loss: 0.263411, loss_s1: 0.054565, loss_fp: 0.001110, loss_freq: 0.006497
[14:56:57.075] iteration 2451: loss: 0.320105, loss_s1: 0.038789, loss_fp: 0.000866, loss_freq: 0.085183
[14:56:57.696] iteration 2452: loss: 0.938548, loss_s1: 0.500443, loss_fp: 0.500001, loss_freq: 0.500045
[14:56:58.313] iteration 2453: loss: 0.412576, loss_s1: 0.412388, loss_fp: 0.029339, loss_freq: 0.034819
[14:56:58.942] iteration 2454: loss: 0.921831, loss_s1: 0.500306, loss_fp: 0.500008, loss_freq: 0.500581
[14:56:59.561] iteration 2455: loss: 0.219659, loss_s1: 0.014993, loss_fp: 0.000805, loss_freq: 0.011646
[14:57:00.187] iteration 2456: loss: 0.212777, loss_s1: 0.010850, loss_fp: 0.000487, loss_freq: 0.001385
[14:57:00.811] iteration 2457: loss: 0.164125, loss_s1: 0.001661, loss_fp: 0.000750, loss_freq: 0.001407
[14:57:01.438] iteration 2458: loss: 0.227641, loss_s1: 0.047745, loss_fp: 0.001212, loss_freq: 0.116180
[14:57:02.057] iteration 2459: loss: 0.125270, loss_s1: 0.035177, loss_fp: 0.001165, loss_freq: 0.000606
[14:57:02.679] iteration 2460: loss: 0.185064, loss_s1: 0.070191, loss_fp: 0.001739, loss_freq: 0.006346
[14:57:03.303] iteration 2461: loss: 0.242194, loss_s1: 0.014233, loss_fp: 0.007082, loss_freq: 0.167161
[14:57:03.921] iteration 2462: loss: 0.865097, loss_s1: 0.492463, loss_fp: 0.499976, loss_freq: 0.499982
[14:57:04.546] iteration 2463: loss: 0.676697, loss_s1: 0.097264, loss_fp: 0.500004, loss_freq: 0.499986
[14:57:05.167] iteration 2464: loss: 0.940982, loss_s1: 0.499998, loss_fp: 0.500001, loss_freq: 0.499980
[14:57:05.790] iteration 2465: loss: 0.870109, loss_s1: 0.499987, loss_fp: 0.499991, loss_freq: 0.499965
[14:57:06.412] iteration 2466: loss: 0.837522, loss_s1: 0.499991, loss_fp: 0.499992, loss_freq: 0.499981
[14:57:07.039] iteration 2467: loss: 1.087026, loss_s1: 0.499985, loss_fp: 0.500008, loss_freq: 0.499965
[14:57:07.659] iteration 2468: loss: 0.913492, loss_s1: 0.499984, loss_fp: 0.499991, loss_freq: 0.499968
[14:57:08.280] iteration 2469: loss: 0.970970, loss_s1: 0.499987, loss_fp: 0.500000, loss_freq: 0.499963
[14:57:08.906] iteration 2470: loss: 0.922383, loss_s1: 0.499978, loss_fp: 0.499996, loss_freq: 0.499959
[14:57:09.535] iteration 2471: loss: 0.955487, loss_s1: 0.499992, loss_fp: 0.499978, loss_freq: 0.499978
[14:57:10.158] iteration 2472: loss: 0.614853, loss_s1: 0.472731, loss_fp: 0.002580, loss_freq: 0.271356
[14:57:10.783] iteration 2473: loss: 0.994027, loss_s1: 0.500109, loss_fp: 0.499998, loss_freq: 0.499968
[14:57:11.406] iteration 2474: loss: 0.345898, loss_s1: 0.175945, loss_fp: 0.004088, loss_freq: 0.157163
[14:57:12.024] iteration 2475: loss: 0.297904, loss_s1: 0.196309, loss_fp: 0.002264, loss_freq: 0.080428
[14:57:12.648] iteration 2476: loss: 0.239408, loss_s1: 0.107017, loss_fp: 0.001034, loss_freq: 0.019052
[14:57:13.268] iteration 2477: loss: 0.346638, loss_s1: 0.185025, loss_fp: 0.002239, loss_freq: 0.083130
[14:57:13.893] iteration 2478: loss: 0.256031, loss_s1: 0.054318, loss_fp: 0.007568, loss_freq: 0.042245
[14:57:14.516] iteration 2479: loss: 0.520669, loss_s1: 0.370743, loss_fp: 0.002040, loss_freq: 0.250318
[14:57:15.138] iteration 2480: loss: 0.309276, loss_s1: 0.082210, loss_fp: 0.006294, loss_freq: 0.025355
[14:57:15.759] iteration 2481: loss: 0.304848, loss_s1: 0.128940, loss_fp: 0.000517, loss_freq: 0.098686
[14:57:16.384] iteration 2482: loss: 0.315017, loss_s1: 0.084975, loss_fp: 0.003337, loss_freq: 0.164441
[14:57:17.001] iteration 2483: loss: 0.170384, loss_s1: 0.083837, loss_fp: 0.001211, loss_freq: 0.071940
[14:57:17.628] iteration 2484: loss: 0.341875, loss_s1: 0.093197, loss_fp: 0.000677, loss_freq: 0.111335
[14:57:18.252] iteration 2485: loss: 0.393286, loss_s1: 0.029846, loss_fp: 0.004101, loss_freq: 0.165323
[14:57:18.874] iteration 2486: loss: 0.362770, loss_s1: 0.207453, loss_fp: 0.004223, loss_freq: 0.095741
[14:57:19.497] iteration 2487: loss: 0.217873, loss_s1: 0.072186, loss_fp: 0.002110, loss_freq: 0.003441
[14:57:20.130] iteration 2488: loss: 0.209605, loss_s1: 0.082203, loss_fp: 0.000750, loss_freq: 0.015381
[14:57:20.800] iteration 2489: loss: 0.289466, loss_s1: 0.113917, loss_fp: 0.001120, loss_freq: 0.016477
[14:57:21.484] iteration 2490: loss: 0.565544, loss_s1: 0.319010, loss_fp: 0.001686, loss_freq: 0.227547
[14:57:22.139] iteration 2491: loss: 0.404722, loss_s1: 0.323736, loss_fp: 0.011876, loss_freq: 0.051450
[14:57:22.760] iteration 2492: loss: 0.222179, loss_s1: 0.039431, loss_fp: 0.000809, loss_freq: 0.023113
[14:57:23.399] iteration 2493: loss: 0.377868, loss_s1: 0.256186, loss_fp: 0.013111, loss_freq: 0.176752
[14:57:24.021] iteration 2494: loss: 0.196621, loss_s1: 0.050036, loss_fp: 0.000748, loss_freq: 0.003576
[14:57:24.642] iteration 2495: loss: 0.422328, loss_s1: 0.333461, loss_fp: 0.003165, loss_freq: 0.061592
[14:57:25.264] iteration 2496: loss: 0.344995, loss_s1: 0.156568, loss_fp: 0.001664, loss_freq: 0.133994
[14:57:25.884] iteration 2497: loss: 0.222239, loss_s1: 0.101697, loss_fp: 0.002229, loss_freq: 0.021888
[14:57:26.501] iteration 2498: loss: 0.881157, loss_s1: 0.501910, loss_fp: 0.500007, loss_freq: 0.502071
[14:57:27.124] iteration 2499: loss: 0.533129, loss_s1: 0.290252, loss_fp: 0.060404, loss_freq: 0.154861
[14:57:27.743] iteration 2500: loss: 0.362069, loss_s1: 0.231090, loss_fp: 0.001843, loss_freq: 0.169735
[14:57:28.371] iteration 2501: loss: 0.621448, loss_s1: 0.318999, loss_fp: 0.247234, loss_freq: 0.455462
[14:57:29.002] iteration 2502: loss: 0.510716, loss_s1: 0.252600, loss_fp: 0.018330, loss_freq: 0.070849
[14:57:29.629] iteration 2503: loss: 0.285016, loss_s1: 0.147415, loss_fp: 0.001990, loss_freq: 0.033849
[14:57:30.277] iteration 2504: loss: 0.836023, loss_s1: 0.207848, loss_fp: 0.500003, loss_freq: 0.500064
[14:57:30.931] iteration 2505: loss: 0.416050, loss_s1: 0.169135, loss_fp: 0.000645, loss_freq: 0.062769
[14:57:31.567] iteration 2506: loss: 0.388776, loss_s1: 0.171764, loss_fp: 0.001331, loss_freq: 0.015772
[14:57:32.196] iteration 2507: loss: 0.494727, loss_s1: 0.292182, loss_fp: 0.008839, loss_freq: 0.247190
[14:57:32.825] iteration 2508: loss: 0.365912, loss_s1: 0.102819, loss_fp: 0.000742, loss_freq: 0.004900
[14:57:33.457] iteration 2509: loss: 0.283654, loss_s1: 0.031599, loss_fp: 0.001061, loss_freq: 0.006462
[14:57:34.085] iteration 2510: loss: 0.292139, loss_s1: 0.120508, loss_fp: 0.004716, loss_freq: 0.017899
[14:57:34.713] iteration 2511: loss: 0.232021, loss_s1: 0.114271, loss_fp: 0.005599, loss_freq: 0.001561
[14:57:35.340] iteration 2512: loss: 0.249562, loss_s1: 0.064399, loss_fp: 0.006158, loss_freq: 0.000714
[14:57:35.966] iteration 2513: loss: 0.395487, loss_s1: 0.205423, loss_fp: 0.000713, loss_freq: 0.007958
[14:57:36.593] iteration 2514: loss: 0.335111, loss_s1: 0.110417, loss_fp: 0.000882, loss_freq: 0.005621
[14:57:37.220] iteration 2515: loss: 0.264741, loss_s1: 0.103316, loss_fp: 0.004329, loss_freq: 0.050368
[14:57:37.843] iteration 2516: loss: 0.180411, loss_s1: 0.068465, loss_fp: 0.000849, loss_freq: 0.000996
[14:57:38.468] iteration 2517: loss: 0.193618, loss_s1: 0.012904, loss_fp: 0.003363, loss_freq: 0.000699
[14:57:39.117] iteration 2518: loss: 0.506255, loss_s1: 0.420892, loss_fp: 0.003053, loss_freq: 0.282301
[14:57:39.745] iteration 2519: loss: 0.291517, loss_s1: 0.122288, loss_fp: 0.000752, loss_freq: 0.007354
[14:57:40.373] iteration 2520: loss: 0.319909, loss_s1: 0.143818, loss_fp: 0.003010, loss_freq: 0.005091
[14:57:40.991] iteration 2521: loss: 0.303801, loss_s1: 0.105193, loss_fp: 0.001139, loss_freq: 0.056523
[14:57:41.609] iteration 2522: loss: 0.346529, loss_s1: 0.273169, loss_fp: 0.002094, loss_freq: 0.046350
[14:57:42.231] iteration 2523: loss: 0.388057, loss_s1: 0.359433, loss_fp: 0.004224, loss_freq: 0.044964
[14:57:42.852] iteration 2524: loss: 0.992185, loss_s1: 0.500625, loss_fp: 0.500011, loss_freq: 0.500208
[14:57:43.474] iteration 2525: loss: 0.414317, loss_s1: 0.342529, loss_fp: 0.002700, loss_freq: 0.051276
[14:57:44.095] iteration 2526: loss: 0.257026, loss_s1: 0.088254, loss_fp: 0.001176, loss_freq: 0.008415
[14:57:44.715] iteration 2527: loss: 0.245550, loss_s1: 0.098725, loss_fp: 0.002732, loss_freq: 0.037167
[14:57:45.336] iteration 2528: loss: 0.295238, loss_s1: 0.159307, loss_fp: 0.000643, loss_freq: 0.158173
[14:57:45.955] iteration 2529: loss: 0.154496, loss_s1: 0.008247, loss_fp: 0.000691, loss_freq: 0.069795
[14:57:46.577] iteration 2530: loss: 0.494394, loss_s1: 0.228934, loss_fp: 0.001663, loss_freq: 0.442562
[14:57:47.195] iteration 2531: loss: 0.241263, loss_s1: 0.062951, loss_fp: 0.001269, loss_freq: 0.003954
[14:57:47.823] iteration 2532: loss: 0.229152, loss_s1: 0.101825, loss_fp: 0.001673, loss_freq: 0.041099
[14:57:48.450] iteration 2533: loss: 0.325787, loss_s1: 0.434943, loss_fp: 0.006600, loss_freq: 0.000664
[14:57:49.073] iteration 2534: loss: 0.210029, loss_s1: 0.047552, loss_fp: 0.001481, loss_freq: 0.018025
[14:57:49.698] iteration 2535: loss: 0.873263, loss_s1: 0.500243, loss_fp: 0.500006, loss_freq: 0.500058
[14:57:50.324] iteration 2536: loss: 0.836359, loss_s1: 0.500569, loss_fp: 0.500005, loss_freq: 0.500015
[14:57:50.947] iteration 2537: loss: 0.287124, loss_s1: 0.048689, loss_fp: 0.001538, loss_freq: 0.072746
[14:57:51.572] iteration 2538: loss: 0.332046, loss_s1: 0.152369, loss_fp: 0.017705, loss_freq: 0.147260
[14:57:52.210] iteration 2539: loss: 0.449085, loss_s1: 0.013712, loss_fp: 0.017403, loss_freq: 0.383785
[14:57:52.837] iteration 2540: loss: 0.273476, loss_s1: 0.158485, loss_fp: 0.001338, loss_freq: 0.055179
[14:57:53.462] iteration 2541: loss: 0.813049, loss_s1: 0.196484, loss_fp: 0.500009, loss_freq: 0.500072
[14:57:54.089] iteration 2542: loss: 0.271077, loss_s1: 0.141562, loss_fp: 0.003741, loss_freq: 0.000942
[14:57:54.711] iteration 2543: loss: 0.241091, loss_s1: 0.002186, loss_fp: 0.001973, loss_freq: 0.000628
[14:57:55.332] iteration 2544: loss: 0.227572, loss_s1: 0.188900, loss_fp: 0.002112, loss_freq: 0.001361
[14:57:55.954] iteration 2545: loss: 0.255905, loss_s1: 0.171331, loss_fp: 0.001389, loss_freq: 0.003619
[14:57:56.578] iteration 2546: loss: 0.836666, loss_s1: 0.500000, loss_fp: 0.499999, loss_freq: 0.499997
[14:57:57.200] iteration 2547: loss: 0.932046, loss_s1: 0.500633, loss_fp: 0.500005, loss_freq: 0.499999
[14:57:57.825] iteration 2548: loss: 0.746735, loss_s1: 0.164549, loss_fp: 0.500003, loss_freq: 0.499995
[14:57:58.446] iteration 2549: loss: 0.382665, loss_s1: 0.407307, loss_fp: 0.001841, loss_freq: 0.014941
[14:57:59.075] iteration 2550: loss: 0.207345, loss_s1: 0.103824, loss_fp: 0.003905, loss_freq: 0.001855
[14:57:59.701] iteration 2551: loss: 0.656395, loss_s1: 0.019401, loss_fp: 0.500007, loss_freq: 0.500008
[14:58:00.327] iteration 2552: loss: 0.285719, loss_s1: 0.111298, loss_fp: 0.002257, loss_freq: 0.127071
[14:58:00.946] iteration 2553: loss: 0.197922, loss_s1: 0.091547, loss_fp: 0.016704, loss_freq: 0.001909
[14:58:01.570] iteration 2554: loss: 0.676381, loss_s1: 0.442591, loss_fp: 0.076761, loss_freq: 0.463164
[14:58:02.193] iteration 2555: loss: 0.555194, loss_s1: 0.463627, loss_fp: 0.094954, loss_freq: 0.092343
[14:58:02.820] iteration 2556: loss: 0.246766, loss_s1: 0.049890, loss_fp: 0.000562, loss_freq: 0.000614
[14:58:03.438] iteration 2557: loss: 0.319496, loss_s1: 0.222645, loss_fp: 0.002315, loss_freq: 0.135802
[14:58:04.059] iteration 2558: loss: 0.292388, loss_s1: 0.182477, loss_fp: 0.000760, loss_freq: 0.000948
[14:58:04.680] iteration 2559: loss: 0.950836, loss_s1: 0.500032, loss_fp: 0.500002, loss_freq: 0.500078
[14:58:05.303] iteration 2560: loss: 0.275959, loss_s1: 0.116170, loss_fp: 0.005476, loss_freq: 0.002628
[14:58:05.924] iteration 2561: loss: 0.288817, loss_s1: 0.087871, loss_fp: 0.000707, loss_freq: 0.000428
[14:58:06.543] iteration 2562: loss: 0.232183, loss_s1: 0.043930, loss_fp: 0.002209, loss_freq: 0.151228
[14:58:07.165] iteration 2563: loss: 0.210847, loss_s1: 0.099996, loss_fp: 0.001209, loss_freq: 0.081553
[14:58:07.785] iteration 2564: loss: 0.193353, loss_s1: 0.110793, loss_fp: 0.000817, loss_freq: 0.001514
[14:58:08.410] iteration 2565: loss: 0.227877, loss_s1: 0.077209, loss_fp: 0.001061, loss_freq: 0.001186
[14:58:09.031] iteration 2566: loss: 0.372367, loss_s1: 0.364620, loss_fp: 0.001384, loss_freq: 0.012560
[14:58:09.652] iteration 2567: loss: 0.297262, loss_s1: 0.169150, loss_fp: 0.000501, loss_freq: 0.002894
[14:58:10.273] iteration 2568: loss: 0.138317, loss_s1: 0.011418, loss_fp: 0.000934, loss_freq: 0.073290
[14:58:10.897] iteration 2569: loss: 0.531082, loss_s1: 0.307503, loss_fp: 0.001863, loss_freq: 0.289184
[14:58:11.518] iteration 2570: loss: 0.146529, loss_s1: 0.039587, loss_fp: 0.000486, loss_freq: 0.052268
[14:58:12.140] iteration 2571: loss: 0.531285, loss_s1: 0.444230, loss_fp: 0.003307, loss_freq: 0.407775
[14:58:12.759] iteration 2572: loss: 0.290048, loss_s1: 0.057720, loss_fp: 0.000988, loss_freq: 0.012864
[14:58:13.386] iteration 2573: loss: 0.263009, loss_s1: 0.199028, loss_fp: 0.000870, loss_freq: 0.029662
[14:58:14.008] iteration 2574: loss: 0.266850, loss_s1: 0.073221, loss_fp: 0.000529, loss_freq: 0.012477
[14:58:14.626] iteration 2575: loss: 0.170765, loss_s1: 0.011864, loss_fp: 0.000774, loss_freq: 0.001271
[14:58:15.247] iteration 2576: loss: 0.234588, loss_s1: 0.084073, loss_fp: 0.001116, loss_freq: 0.001529
[14:58:16.227] iteration 2577: loss: 0.306682, loss_s1: 0.142345, loss_fp: 0.002474, loss_freq: 0.018186
[14:58:16.844] iteration 2578: loss: 0.921503, loss_s1: 0.499996, loss_fp: 0.499982, loss_freq: 0.500002
[14:58:17.462] iteration 2579: loss: 0.205659, loss_s1: 0.017581, loss_fp: 0.002154, loss_freq: 0.022214
[14:58:18.083] iteration 2580: loss: 0.265608, loss_s1: 0.044627, loss_fp: 0.000884, loss_freq: 0.034589
[14:58:18.704] iteration 2581: loss: 0.292943, loss_s1: 0.116803, loss_fp: 0.000716, loss_freq: 0.000343
[14:58:19.324] iteration 2582: loss: 0.375898, loss_s1: 0.278049, loss_fp: 0.008830, loss_freq: 0.022064
[14:58:19.948] iteration 2583: loss: 0.264866, loss_s1: 0.133219, loss_fp: 0.001083, loss_freq: 0.066452
[14:58:20.569] iteration 2584: loss: 0.278970, loss_s1: 0.287486, loss_fp: 0.000802, loss_freq: 0.005761
[14:58:21.188] iteration 2585: loss: 0.205316, loss_s1: 0.140842, loss_fp: 0.000786, loss_freq: 0.001558
[14:58:21.814] iteration 2586: loss: 0.220328, loss_s1: 0.138880, loss_fp: 0.003790, loss_freq: 0.000964
[14:58:22.438] iteration 2587: loss: 0.277048, loss_s1: 0.096583, loss_fp: 0.000825, loss_freq: 0.004572
[14:58:23.062] iteration 2588: loss: 0.183100, loss_s1: 0.002079, loss_fp: 0.001436, loss_freq: 0.020993
[14:58:23.686] iteration 2589: loss: 0.247567, loss_s1: 0.282349, loss_fp: 0.000875, loss_freq: 0.004089
[14:58:24.310] iteration 2590: loss: 0.278170, loss_s1: 0.003637, loss_fp: 0.000505, loss_freq: 0.164754
[14:58:24.935] iteration 2591: loss: 0.127306, loss_s1: 0.013849, loss_fp: 0.008807, loss_freq: 0.000666
[14:58:25.554] iteration 2592: loss: 0.147862, loss_s1: 0.027315, loss_fp: 0.000527, loss_freq: 0.003183
[14:58:26.181] iteration 2593: loss: 0.267077, loss_s1: 0.003400, loss_fp: 0.000449, loss_freq: 0.000606
[14:58:26.806] iteration 2594: loss: 0.156823, loss_s1: 0.054973, loss_fp: 0.001316, loss_freq: 0.001776
[14:58:27.431] iteration 2595: loss: 0.203372, loss_s1: 0.004461, loss_fp: 0.000571, loss_freq: 0.001051
[14:58:28.055] iteration 2596: loss: 0.149736, loss_s1: 0.023842, loss_fp: 0.003885, loss_freq: 0.000553
[14:58:28.676] iteration 2597: loss: 0.409382, loss_s1: 0.254991, loss_fp: 0.000840, loss_freq: 0.149892
[14:58:29.301] iteration 2598: loss: 0.375016, loss_s1: 0.283412, loss_fp: 0.001776, loss_freq: 0.125023
[14:58:29.927] iteration 2599: loss: 0.276905, loss_s1: 0.074536, loss_fp: 0.000525, loss_freq: 0.016127
[14:58:30.547] iteration 2600: loss: 0.882971, loss_s1: 0.501288, loss_fp: 0.499999, loss_freq: 0.500607
[14:58:33.687] iteration 2600 : mean_dice : 0.483708
[14:58:34.349] iteration 2601: loss: 0.166535, loss_s1: 0.012406, loss_fp: 0.000757, loss_freq: 0.000657
[14:58:34.977] iteration 2602: loss: 0.188518, loss_s1: 0.186743, loss_fp: 0.001240, loss_freq: 0.000495
[14:58:35.596] iteration 2603: loss: 0.216684, loss_s1: 0.119595, loss_fp: 0.000511, loss_freq: 0.000514
[14:58:36.225] iteration 2604: loss: 0.520581, loss_s1: 0.459321, loss_fp: 0.003720, loss_freq: 0.270101
[14:58:36.846] iteration 2605: loss: 0.255168, loss_s1: 0.017805, loss_fp: 0.000367, loss_freq: 0.000744
[14:58:37.466] iteration 2606: loss: 0.176926, loss_s1: 0.036392, loss_fp: 0.000945, loss_freq: 0.026626
[14:58:38.087] iteration 2607: loss: 0.863739, loss_s1: 0.500047, loss_fp: 0.499991, loss_freq: 0.499997
[14:58:38.708] iteration 2608: loss: 0.233781, loss_s1: 0.079499, loss_fp: 0.001214, loss_freq: 0.001252
[14:58:39.331] iteration 2609: loss: 0.159504, loss_s1: 0.145014, loss_fp: 0.001080, loss_freq: 0.002270
[14:58:39.953] iteration 2610: loss: 0.196445, loss_s1: 0.089817, loss_fp: 0.000427, loss_freq: 0.002802
[14:58:40.574] iteration 2611: loss: 0.278999, loss_s1: 0.064150, loss_fp: 0.000759, loss_freq: 0.001037
[14:58:41.197] iteration 2612: loss: 0.311678, loss_s1: 0.138987, loss_fp: 0.000753, loss_freq: 0.049495
[14:58:41.821] iteration 2613: loss: 0.307025, loss_s1: 0.216153, loss_fp: 0.001653, loss_freq: 0.001661
[14:58:42.443] iteration 2614: loss: 0.271561, loss_s1: 0.061618, loss_fp: 0.001749, loss_freq: 0.070873
[14:58:43.063] iteration 2615: loss: 0.939259, loss_s1: 0.500047, loss_fp: 0.500001, loss_freq: 0.500006
[14:58:43.684] iteration 2616: loss: 0.314118, loss_s1: 0.213710, loss_fp: 0.001234, loss_freq: 0.003007
[14:58:44.309] iteration 2617: loss: 0.148625, loss_s1: 0.025597, loss_fp: 0.000768, loss_freq: 0.002567
[14:58:44.934] iteration 2618: loss: 0.199533, loss_s1: 0.036632, loss_fp: 0.000423, loss_freq: 0.000659
[14:58:45.560] iteration 2619: loss: 0.248719, loss_s1: 0.217747, loss_fp: 0.000978, loss_freq: 0.025359
[14:58:46.178] iteration 2620: loss: 0.112986, loss_s1: 0.052499, loss_fp: 0.000901, loss_freq: 0.000582
[14:58:46.806] iteration 2621: loss: 0.271210, loss_s1: 0.141787, loss_fp: 0.001224, loss_freq: 0.039808
[14:58:47.431] iteration 2622: loss: 0.217582, loss_s1: 0.045270, loss_fp: 0.000566, loss_freq: 0.001106
[14:58:48.055] iteration 2623: loss: 0.248141, loss_s1: 0.053977, loss_fp: 0.000529, loss_freq: 0.001196
[14:58:48.717] iteration 2624: loss: 0.101547, loss_s1: 0.020437, loss_fp: 0.000738, loss_freq: 0.004460
[14:58:49.348] iteration 2625: loss: 0.315757, loss_s1: 0.307088, loss_fp: 0.002206, loss_freq: 0.001029
[14:58:49.976] iteration 2626: loss: 0.193584, loss_s1: 0.186707, loss_fp: 0.000706, loss_freq: 0.000490
[14:58:50.606] iteration 2627: loss: 0.433964, loss_s1: 0.377197, loss_fp: 0.005084, loss_freq: 0.281717
[14:58:51.235] iteration 2628: loss: 0.384363, loss_s1: 0.246301, loss_fp: 0.001035, loss_freq: 0.015331
[14:58:51.861] iteration 2629: loss: 0.171163, loss_s1: 0.076933, loss_fp: 0.000800, loss_freq: 0.008365
[14:58:52.485] iteration 2630: loss: 0.267971, loss_s1: 0.093081, loss_fp: 0.000754, loss_freq: 0.018147
[14:58:53.114] iteration 2631: loss: 0.212940, loss_s1: 0.121301, loss_fp: 0.000639, loss_freq: 0.071714
[14:58:53.735] iteration 2632: loss: 0.913701, loss_s1: 0.500031, loss_fp: 0.500019, loss_freq: 0.500035
[14:58:54.360] iteration 2633: loss: 0.226883, loss_s1: 0.043055, loss_fp: 0.003031, loss_freq: 0.000628
[14:58:54.988] iteration 2634: loss: 0.295336, loss_s1: 0.063852, loss_fp: 0.002428, loss_freq: 0.006778
[14:58:55.611] iteration 2635: loss: 0.283650, loss_s1: 0.081650, loss_fp: 0.000862, loss_freq: 0.118599
[14:58:56.234] iteration 2636: loss: 0.205269, loss_s1: 0.087570, loss_fp: 0.000592, loss_freq: 0.009694
[14:58:56.858] iteration 2637: loss: 0.103305, loss_s1: 0.009823, loss_fp: 0.004760, loss_freq: 0.002077
[14:58:57.482] iteration 2638: loss: 0.191414, loss_s1: 0.105419, loss_fp: 0.001950, loss_freq: 0.015815
[14:58:58.110] iteration 2639: loss: 0.169721, loss_s1: 0.070860, loss_fp: 0.000934, loss_freq: 0.000853
[14:58:58.734] iteration 2640: loss: 0.614834, loss_s1: 0.480108, loss_fp: 0.011030, loss_freq: 0.425668
[14:58:59.364] iteration 2641: loss: 0.244107, loss_s1: 0.091219, loss_fp: 0.000780, loss_freq: 0.014629
[14:58:59.984] iteration 2642: loss: 0.213803, loss_s1: 0.032041, loss_fp: 0.003490, loss_freq: 0.122112
[14:59:00.607] iteration 2643: loss: 0.310519, loss_s1: 0.033261, loss_fp: 0.000832, loss_freq: 0.165192
[14:59:01.227] iteration 2644: loss: 0.150698, loss_s1: 0.095915, loss_fp: 0.005943, loss_freq: 0.039848
[14:59:01.848] iteration 2645: loss: 0.166237, loss_s1: 0.019494, loss_fp: 0.000599, loss_freq: 0.020919
[14:59:02.468] iteration 2646: loss: 0.315487, loss_s1: 0.138983, loss_fp: 0.001338, loss_freq: 0.023459
[14:59:03.090] iteration 2647: loss: 0.274329, loss_s1: 0.033728, loss_fp: 0.000521, loss_freq: 0.102144
[14:59:03.715] iteration 2648: loss: 0.204079, loss_s1: 0.009789, loss_fp: 0.000553, loss_freq: 0.006550
[14:59:04.339] iteration 2649: loss: 0.222327, loss_s1: 0.121666, loss_fp: 0.000693, loss_freq: 0.009645
[14:59:04.964] iteration 2650: loss: 0.199538, loss_s1: 0.036019, loss_fp: 0.000727, loss_freq: 0.000855
[14:59:05.580] iteration 2651: loss: 0.904064, loss_s1: 0.500763, loss_fp: 0.500000, loss_freq: 0.501063
[14:59:06.205] iteration 2652: loss: 0.242015, loss_s1: 0.162563, loss_fp: 0.000307, loss_freq: 0.000521
[14:59:06.823] iteration 2653: loss: 0.166673, loss_s1: 0.006512, loss_fp: 0.000658, loss_freq: 0.007544
[14:59:07.447] iteration 2654: loss: 0.498793, loss_s1: 0.274808, loss_fp: 0.001811, loss_freq: 0.473127
[14:59:08.070] iteration 2655: loss: 0.180941, loss_s1: 0.141663, loss_fp: 0.000750, loss_freq: 0.006515
[14:59:08.693] iteration 2656: loss: 0.230583, loss_s1: 0.124471, loss_fp: 0.001291, loss_freq: 0.028633
[14:59:09.323] iteration 2657: loss: 0.330601, loss_s1: 0.236012, loss_fp: 0.006005, loss_freq: 0.072966
[14:59:09.947] iteration 2658: loss: 0.178733, loss_s1: 0.035375, loss_fp: 0.000751, loss_freq: 0.002038
[14:59:10.573] iteration 2659: loss: 0.453102, loss_s1: 0.347103, loss_fp: 0.012838, loss_freq: 0.309204
[14:59:11.198] iteration 2660: loss: 0.183070, loss_s1: 0.020916, loss_fp: 0.001546, loss_freq: 0.000260
[14:59:11.823] iteration 2661: loss: 0.183956, loss_s1: 0.130290, loss_fp: 0.012064, loss_freq: 0.007782
[14:59:12.448] iteration 2662: loss: 0.077748, loss_s1: 0.004367, loss_fp: 0.006301, loss_freq: 0.003290
[14:59:13.068] iteration 2663: loss: 0.388399, loss_s1: 0.276948, loss_fp: 0.000592, loss_freq: 0.015985
[14:59:13.690] iteration 2664: loss: 0.455142, loss_s1: 0.377341, loss_fp: 0.036524, loss_freq: 0.174849
[14:59:14.316] iteration 2665: loss: 0.283199, loss_s1: 0.182788, loss_fp: 0.004394, loss_freq: 0.000616
[14:59:14.944] iteration 2666: loss: 0.194841, loss_s1: 0.001535, loss_fp: 0.001707, loss_freq: 0.000805
[14:59:15.562] iteration 2667: loss: 0.222477, loss_s1: 0.033542, loss_fp: 0.001126, loss_freq: 0.013588
[14:59:16.187] iteration 2668: loss: 0.467361, loss_s1: 0.376643, loss_fp: 0.006506, loss_freq: 0.196917
[14:59:16.813] iteration 2669: loss: 0.256642, loss_s1: 0.001301, loss_fp: 0.001700, loss_freq: 0.000700
[14:59:17.435] iteration 2670: loss: 0.170689, loss_s1: 0.025133, loss_fp: 0.000339, loss_freq: 0.000430
[14:59:18.061] iteration 2671: loss: 0.168634, loss_s1: 0.004336, loss_fp: 0.002142, loss_freq: 0.047063
[14:59:18.683] iteration 2672: loss: 0.125669, loss_s1: 0.046136, loss_fp: 0.001362, loss_freq: 0.004825
[14:59:19.305] iteration 2673: loss: 0.208164, loss_s1: 0.045864, loss_fp: 0.001064, loss_freq: 0.001737
[14:59:19.923] iteration 2674: loss: 0.173917, loss_s1: 0.043287, loss_fp: 0.001656, loss_freq: 0.001988
[14:59:20.542] iteration 2675: loss: 0.174874, loss_s1: 0.017294, loss_fp: 0.000485, loss_freq: 0.001866
[14:59:21.160] iteration 2676: loss: 0.200025, loss_s1: 0.108432, loss_fp: 0.001849, loss_freq: 0.000997
[14:59:21.785] iteration 2677: loss: 0.137814, loss_s1: 0.065200, loss_fp: 0.000369, loss_freq: 0.001573
[14:59:22.410] iteration 2678: loss: 0.191242, loss_s1: 0.070570, loss_fp: 0.000634, loss_freq: 0.000753
[14:59:23.033] iteration 2679: loss: 0.262683, loss_s1: 0.182626, loss_fp: 0.002739, loss_freq: 0.040586
[14:59:23.661] iteration 2680: loss: 0.160444, loss_s1: 0.017481, loss_fp: 0.000230, loss_freq: 0.001739
[14:59:24.282] iteration 2681: loss: 0.232196, loss_s1: 0.006689, loss_fp: 0.000548, loss_freq: 0.001737
[14:59:24.907] iteration 2682: loss: 0.221841, loss_s1: 0.043462, loss_fp: 0.001177, loss_freq: 0.002761
[14:59:25.534] iteration 2683: loss: 0.259786, loss_s1: 0.198371, loss_fp: 0.000956, loss_freq: 0.005160
[14:59:26.161] iteration 2684: loss: 0.230506, loss_s1: 0.035728, loss_fp: 0.015675, loss_freq: 0.133535
[14:59:26.794] iteration 2685: loss: 0.237033, loss_s1: 0.055288, loss_fp: 0.001664, loss_freq: 0.140513
[14:59:27.417] iteration 2686: loss: 0.217160, loss_s1: 0.057826, loss_fp: 0.001151, loss_freq: 0.005954
[14:59:28.041] iteration 2687: loss: 0.221491, loss_s1: 0.032837, loss_fp: 0.000516, loss_freq: 0.024019
[14:59:28.657] iteration 2688: loss: 0.204289, loss_s1: 0.042592, loss_fp: 0.001185, loss_freq: 0.078343
[14:59:29.279] iteration 2689: loss: 0.401422, loss_s1: 0.224172, loss_fp: 0.016362, loss_freq: 0.304455
[14:59:29.902] iteration 2690: loss: 0.298366, loss_s1: 0.159210, loss_fp: 0.003363, loss_freq: 0.245465
[14:59:30.522] iteration 2691: loss: 0.200031, loss_s1: 0.140242, loss_fp: 0.000660, loss_freq: 0.000480
[14:59:31.142] iteration 2692: loss: 0.258087, loss_s1: 0.131622, loss_fp: 0.000455, loss_freq: 0.000394
[14:59:31.762] iteration 2693: loss: 0.208544, loss_s1: 0.053590, loss_fp: 0.000493, loss_freq: 0.022108
[14:59:32.384] iteration 2694: loss: 0.381327, loss_s1: 0.255535, loss_fp: 0.000656, loss_freq: 0.291683
[14:59:33.007] iteration 2695: loss: 0.364109, loss_s1: 0.313776, loss_fp: 0.015123, loss_freq: 0.002991
[14:59:33.629] iteration 2696: loss: 0.465073, loss_s1: 0.314835, loss_fp: 0.002118, loss_freq: 0.364100
[14:59:34.252] iteration 2697: loss: 0.147960, loss_s1: 0.027300, loss_fp: 0.001058, loss_freq: 0.026952
[14:59:34.872] iteration 2698: loss: 0.299920, loss_s1: 0.035621, loss_fp: 0.000614, loss_freq: 0.021859
[14:59:35.492] iteration 2699: loss: 0.258468, loss_s1: 0.112911, loss_fp: 0.000950, loss_freq: 0.006865
[14:59:36.114] iteration 2700: loss: 0.380076, loss_s1: 0.260949, loss_fp: 0.001598, loss_freq: 0.102141
[14:59:36.739] iteration 2701: loss: 0.368880, loss_s1: 0.245444, loss_fp: 0.000243, loss_freq: 0.000392
[14:59:37.364] iteration 2702: loss: 0.234805, loss_s1: 0.003878, loss_fp: 0.000600, loss_freq: 0.001197
[14:59:37.987] iteration 2703: loss: 0.498589, loss_s1: 0.489705, loss_fp: 0.012477, loss_freq: 0.142084
[14:59:38.605] iteration 2704: loss: 0.288713, loss_s1: 0.084159, loss_fp: 0.000822, loss_freq: 0.029477
[14:59:39.223] iteration 2705: loss: 0.250793, loss_s1: 0.213456, loss_fp: 0.000661, loss_freq: 0.006586
[14:59:39.845] iteration 2706: loss: 0.230860, loss_s1: 0.089065, loss_fp: 0.000567, loss_freq: 0.008573
[14:59:40.460] iteration 2707: loss: 0.169802, loss_s1: 0.040163, loss_fp: 0.003743, loss_freq: 0.063073
[14:59:41.080] iteration 2708: loss: 0.522469, loss_s1: 0.254387, loss_fp: 0.001733, loss_freq: 0.452547
[14:59:41.697] iteration 2709: loss: 0.284146, loss_s1: 0.151174, loss_fp: 0.001603, loss_freq: 0.000681
[14:59:42.323] iteration 2710: loss: 0.239302, loss_s1: 0.060036, loss_fp: 0.001900, loss_freq: 0.013983
[14:59:42.941] iteration 2711: loss: 0.240288, loss_s1: 0.115274, loss_fp: 0.001215, loss_freq: 0.001420
[14:59:43.559] iteration 2712: loss: 0.199879, loss_s1: 0.143796, loss_fp: 0.005489, loss_freq: 0.006030
[14:59:44.175] iteration 2713: loss: 0.349214, loss_s1: 0.207225, loss_fp: 0.000654, loss_freq: 0.001947
[14:59:44.794] iteration 2714: loss: 0.133215, loss_s1: 0.023962, loss_fp: 0.001626, loss_freq: 0.008490
[14:59:45.419] iteration 2715: loss: 0.362178, loss_s1: 0.146329, loss_fp: 0.001353, loss_freq: 0.340829
[14:59:46.039] iteration 2716: loss: 0.246277, loss_s1: 0.006790, loss_fp: 0.000723, loss_freq: 0.015601
[14:59:46.667] iteration 2717: loss: 0.220747, loss_s1: 0.066770, loss_fp: 0.000635, loss_freq: 0.023528
[14:59:47.293] iteration 2718: loss: 0.236670, loss_s1: 0.053137, loss_fp: 0.000852, loss_freq: 0.066224
[14:59:47.961] iteration 2719: loss: 0.213153, loss_s1: 0.082630, loss_fp: 0.000632, loss_freq: 0.011959
[14:59:48.593] iteration 2720: loss: 0.369039, loss_s1: 0.290927, loss_fp: 0.006443, loss_freq: 0.034929
[14:59:49.237] iteration 2721: loss: 0.432033, loss_s1: 0.302154, loss_fp: 0.005198, loss_freq: 0.057437
[14:59:49.868] iteration 2722: loss: 0.191000, loss_s1: 0.027006, loss_fp: 0.000446, loss_freq: 0.016614
[14:59:50.497] iteration 2723: loss: 0.301679, loss_s1: 0.183476, loss_fp: 0.000710, loss_freq: 0.098376
[14:59:51.125] iteration 2724: loss: 0.217918, loss_s1: 0.061772, loss_fp: 0.000949, loss_freq: 0.123249
[14:59:51.751] iteration 2725: loss: 0.177461, loss_s1: 0.097815, loss_fp: 0.000847, loss_freq: 0.000429
[14:59:52.381] iteration 2726: loss: 0.153022, loss_s1: 0.000793, loss_fp: 0.000303, loss_freq: 0.006335
[14:59:53.009] iteration 2727: loss: 0.213472, loss_s1: 0.049659, loss_fp: 0.000898, loss_freq: 0.019178
[14:59:53.636] iteration 2728: loss: 0.341616, loss_s1: 0.035597, loss_fp: 0.001565, loss_freq: 0.249752
[14:59:54.260] iteration 2729: loss: 0.135108, loss_s1: 0.041340, loss_fp: 0.001566, loss_freq: 0.065859
[14:59:54.886] iteration 2730: loss: 0.345589, loss_s1: 0.283254, loss_fp: 0.015672, loss_freq: 0.029973
[14:59:55.510] iteration 2731: loss: 0.285233, loss_s1: 0.320443, loss_fp: 0.000950, loss_freq: 0.032541
[14:59:56.131] iteration 2732: loss: 0.165839, loss_s1: 0.054281, loss_fp: 0.001349, loss_freq: 0.044635
[14:59:56.771] iteration 2733: loss: 0.285650, loss_s1: 0.032017, loss_fp: 0.000690, loss_freq: 0.031487
[14:59:57.393] iteration 2734: loss: 0.287820, loss_s1: 0.158056, loss_fp: 0.008844, loss_freq: 0.084373
[14:59:58.018] iteration 2735: loss: 0.282396, loss_s1: 0.217258, loss_fp: 0.000881, loss_freq: 0.034412
[14:59:58.641] iteration 2736: loss: 0.280386, loss_s1: 0.100549, loss_fp: 0.056594, loss_freq: 0.071864
[14:59:59.259] iteration 2737: loss: 0.270781, loss_s1: 0.010880, loss_fp: 0.000590, loss_freq: 0.000522
[15:00:00.225] iteration 2738: loss: 0.276178, loss_s1: 0.113927, loss_fp: 0.000610, loss_freq: 0.031527
[15:00:00.855] iteration 2739: loss: 0.345962, loss_s1: 0.440756, loss_fp: 0.000878, loss_freq: 0.016374
[15:00:01.489] iteration 2740: loss: 0.250321, loss_s1: 0.176583, loss_fp: 0.000803, loss_freq: 0.004974
[15:00:02.125] iteration 2741: loss: 0.212985, loss_s1: 0.063437, loss_fp: 0.000485, loss_freq: 0.000696
[15:00:02.749] iteration 2742: loss: 0.257446, loss_s1: 0.079424, loss_fp: 0.001067, loss_freq: 0.000585
[15:00:03.377] iteration 2743: loss: 0.358018, loss_s1: 0.285264, loss_fp: 0.006126, loss_freq: 0.061022
[15:00:04.035] iteration 2744: loss: 0.178531, loss_s1: 0.102765, loss_fp: 0.000549, loss_freq: 0.015572
[15:00:04.662] iteration 2745: loss: 0.229563, loss_s1: 0.070919, loss_fp: 0.003755, loss_freq: 0.129733
[15:00:05.287] iteration 2746: loss: 0.208309, loss_s1: 0.164996, loss_fp: 0.001350, loss_freq: 0.002830
[15:00:05.908] iteration 2747: loss: 0.171268, loss_s1: 0.006081, loss_fp: 0.001315, loss_freq: 0.010409
[15:00:06.531] iteration 2748: loss: 0.205330, loss_s1: 0.023266, loss_fp: 0.000955, loss_freq: 0.000979
[15:00:07.150] iteration 2749: loss: 0.287313, loss_s1: 0.123431, loss_fp: 0.000700, loss_freq: 0.076881
[15:00:07.810] iteration 2750: loss: 0.125317, loss_s1: 0.058981, loss_fp: 0.000825, loss_freq: 0.001024
[15:00:08.476] iteration 2751: loss: 0.238127, loss_s1: 0.025042, loss_fp: 0.006590, loss_freq: 0.058173
[15:00:09.111] iteration 2752: loss: 0.096086, loss_s1: 0.001845, loss_fp: 0.000886, loss_freq: 0.000670
[15:00:09.744] iteration 2753: loss: 0.119939, loss_s1: 0.038590, loss_fp: 0.002566, loss_freq: 0.018176
[15:00:10.376] iteration 2754: loss: 0.263680, loss_s1: 0.037055, loss_fp: 0.000478, loss_freq: 0.000782
[15:00:11.007] iteration 2755: loss: 0.249147, loss_s1: 0.133728, loss_fp: 0.003040, loss_freq: 0.061991
[15:00:11.635] iteration 2756: loss: 0.292070, loss_s1: 0.120606, loss_fp: 0.001431, loss_freq: 0.049897
[15:00:12.259] iteration 2757: loss: 0.205380, loss_s1: 0.106237, loss_fp: 0.004208, loss_freq: 0.000793
[15:00:12.881] iteration 2758: loss: 0.155395, loss_s1: 0.001154, loss_fp: 0.001026, loss_freq: 0.000367
[15:00:13.506] iteration 2759: loss: 0.330899, loss_s1: 0.289898, loss_fp: 0.003419, loss_freq: 0.033584
[15:00:14.128] iteration 2760: loss: 0.285179, loss_s1: 0.065281, loss_fp: 0.000589, loss_freq: 0.001842
[15:00:14.746] iteration 2761: loss: 0.557305, loss_s1: 0.484601, loss_fp: 0.076153, loss_freq: 0.277061
[15:00:15.371] iteration 2762: loss: 0.241012, loss_s1: 0.230491, loss_fp: 0.000781, loss_freq: 0.000432
[15:00:15.995] iteration 2763: loss: 0.104997, loss_s1: 0.030754, loss_fp: 0.000695, loss_freq: 0.008151
[15:00:16.618] iteration 2764: loss: 0.197785, loss_s1: 0.056605, loss_fp: 0.002502, loss_freq: 0.000800
[15:00:17.237] iteration 2765: loss: 0.356015, loss_s1: 0.333711, loss_fp: 0.001174, loss_freq: 0.035699
[15:00:17.858] iteration 2766: loss: 0.245594, loss_s1: 0.099128, loss_fp: 0.000624, loss_freq: 0.008250
[15:00:18.480] iteration 2767: loss: 0.194106, loss_s1: 0.041911, loss_fp: 0.000693, loss_freq: 0.004425
[15:00:19.105] iteration 2768: loss: 0.143016, loss_s1: 0.062488, loss_fp: 0.002578, loss_freq: 0.000313
[15:00:19.744] iteration 2769: loss: 0.267275, loss_s1: 0.123575, loss_fp: 0.000521, loss_freq: 0.001295
[15:00:20.372] iteration 2770: loss: 0.119454, loss_s1: 0.083272, loss_fp: 0.000495, loss_freq: 0.011757
[15:00:21.042] iteration 2771: loss: 0.199409, loss_s1: 0.103001, loss_fp: 0.000678, loss_freq: 0.046481
[15:00:21.668] iteration 2772: loss: 0.303292, loss_s1: 0.056873, loss_fp: 0.001530, loss_freq: 0.024841
[15:00:22.292] iteration 2773: loss: 0.249222, loss_s1: 0.083258, loss_fp: 0.000789, loss_freq: 0.040761
[15:00:22.917] iteration 2774: loss: 0.238814, loss_s1: 0.096474, loss_fp: 0.000604, loss_freq: 0.000840
[15:00:23.542] iteration 2775: loss: 0.134652, loss_s1: 0.038582, loss_fp: 0.001138, loss_freq: 0.001130
[15:00:24.167] iteration 2776: loss: 0.220634, loss_s1: 0.043396, loss_fp: 0.001115, loss_freq: 0.004549
[15:00:24.789] iteration 2777: loss: 0.282147, loss_s1: 0.157276, loss_fp: 0.003784, loss_freq: 0.007811
[15:00:25.412] iteration 2778: loss: 0.151991, loss_s1: 0.020557, loss_fp: 0.000677, loss_freq: 0.006501
[15:00:26.035] iteration 2779: loss: 0.211039, loss_s1: 0.053272, loss_fp: 0.000484, loss_freq: 0.002133
[15:00:26.662] iteration 2780: loss: 0.220938, loss_s1: 0.073048, loss_fp: 0.000511, loss_freq: 0.063117
[15:00:27.292] iteration 2781: loss: 0.177516, loss_s1: 0.106239, loss_fp: 0.000702, loss_freq: 0.000455
[15:00:27.918] iteration 2782: loss: 0.258877, loss_s1: 0.183276, loss_fp: 0.000615, loss_freq: 0.009427
[15:00:28.542] iteration 2783: loss: 0.245290, loss_s1: 0.073180, loss_fp: 0.000678, loss_freq: 0.000525
[15:00:29.163] iteration 2784: loss: 0.205135, loss_s1: 0.038322, loss_fp: 0.000882, loss_freq: 0.025692
[15:00:29.793] iteration 2785: loss: 0.119542, loss_s1: 0.010238, loss_fp: 0.002831, loss_freq: 0.000579
[15:00:30.444] iteration 2786: loss: 0.246083, loss_s1: 0.147534, loss_fp: 0.000825, loss_freq: 0.001729
[15:00:31.073] iteration 2787: loss: 0.140836, loss_s1: 0.025838, loss_fp: 0.000326, loss_freq: 0.034550
[15:00:31.703] iteration 2788: loss: 0.184334, loss_s1: 0.074001, loss_fp: 0.010815, loss_freq: 0.124760
[15:00:32.329] iteration 2789: loss: 0.342786, loss_s1: 0.117611, loss_fp: 0.000603, loss_freq: 0.050545
[15:00:32.952] iteration 2790: loss: 0.134578, loss_s1: 0.032154, loss_fp: 0.000297, loss_freq: 0.003680
[15:00:33.576] iteration 2791: loss: 0.385703, loss_s1: 0.279224, loss_fp: 0.000863, loss_freq: 0.138742
[15:00:34.197] iteration 2792: loss: 0.145410, loss_s1: 0.026373, loss_fp: 0.000769, loss_freq: 0.007685
[15:00:34.812] iteration 2793: loss: 0.912500, loss_s1: 0.501545, loss_fp: 0.500006, loss_freq: 0.500157
[15:00:35.435] iteration 2794: loss: 0.212983, loss_s1: 0.049590, loss_fp: 0.000481, loss_freq: 0.005944
[15:00:36.059] iteration 2795: loss: 0.234350, loss_s1: 0.063464, loss_fp: 0.000744, loss_freq: 0.000424
[15:00:36.678] iteration 2796: loss: 0.158223, loss_s1: 0.046198, loss_fp: 0.000820, loss_freq: 0.014268
[15:00:37.310] iteration 2797: loss: 0.152868, loss_s1: 0.059155, loss_fp: 0.001021, loss_freq: 0.010273
[15:00:37.935] iteration 2798: loss: 0.085470, loss_s1: 0.027629, loss_fp: 0.000390, loss_freq: 0.003600
[15:00:38.560] iteration 2799: loss: 0.197534, loss_s1: 0.041832, loss_fp: 0.000608, loss_freq: 0.081925
[15:00:39.181] iteration 2800: loss: 0.120272, loss_s1: 0.009830, loss_fp: 0.001766, loss_freq: 0.002451
[15:00:41.679] iteration 2800 : mean_dice : 0.261719
[15:00:42.335] iteration 2801: loss: 0.552877, loss_s1: 0.434567, loss_fp: 0.012414, loss_freq: 0.344884
[15:00:42.962] iteration 2802: loss: 0.114003, loss_s1: 0.017617, loss_fp: 0.000545, loss_freq: 0.002038
[15:00:43.588] iteration 2803: loss: 0.153205, loss_s1: 0.016499, loss_fp: 0.000952, loss_freq: 0.026311
[15:00:44.220] iteration 2804: loss: 0.225568, loss_s1: 0.022032, loss_fp: 0.004322, loss_freq: 0.080670
[15:00:44.847] iteration 2805: loss: 0.130321, loss_s1: 0.050806, loss_fp: 0.000469, loss_freq: 0.008940
[15:00:45.482] iteration 2806: loss: 0.252782, loss_s1: 0.240648, loss_fp: 0.000923, loss_freq: 0.041854
[15:00:46.108] iteration 2807: loss: 0.242322, loss_s1: 0.034288, loss_fp: 0.000852, loss_freq: 0.026233
[15:00:46.734] iteration 2808: loss: 0.350400, loss_s1: 0.081521, loss_fp: 0.004029, loss_freq: 0.117829
[15:00:47.359] iteration 2809: loss: 0.210907, loss_s1: 0.100457, loss_fp: 0.000323, loss_freq: 0.057402
[15:00:47.989] iteration 2810: loss: 0.220456, loss_s1: 0.062735, loss_fp: 0.000514, loss_freq: 0.074561
[15:00:48.611] iteration 2811: loss: 0.221760, loss_s1: 0.027847, loss_fp: 0.001111, loss_freq: 0.000650
[15:00:49.245] iteration 2812: loss: 0.406940, loss_s1: 0.195023, loss_fp: 0.002082, loss_freq: 0.108536
[15:00:49.861] iteration 2813: loss: 0.274477, loss_s1: 0.123942, loss_fp: 0.000463, loss_freq: 0.000470
[15:00:50.492] iteration 2814: loss: 0.214106, loss_s1: 0.087017, loss_fp: 0.001625, loss_freq: 0.000626
[15:00:51.163] iteration 2815: loss: 0.545082, loss_s1: 0.441395, loss_fp: 0.018316, loss_freq: 0.362755
[15:00:51.832] iteration 2816: loss: 0.158200, loss_s1: 0.109234, loss_fp: 0.000609, loss_freq: 0.021729
[15:00:52.458] iteration 2817: loss: 0.210766, loss_s1: 0.073424, loss_fp: 0.001403, loss_freq: 0.025582
[15:00:53.094] iteration 2818: loss: 0.209214, loss_s1: 0.019957, loss_fp: 0.000788, loss_freq: 0.001412
[15:00:53.721] iteration 2819: loss: 0.223104, loss_s1: 0.071292, loss_fp: 0.003698, loss_freq: 0.009185
[15:00:54.348] iteration 2820: loss: 0.253046, loss_s1: 0.161557, loss_fp: 0.001076, loss_freq: 0.156994
[15:00:54.976] iteration 2821: loss: 0.240305, loss_s1: 0.047904, loss_fp: 0.001316, loss_freq: 0.083214
[15:00:55.606] iteration 2822: loss: 0.184323, loss_s1: 0.111791, loss_fp: 0.000876, loss_freq: 0.045615
[15:00:56.237] iteration 2823: loss: 0.095257, loss_s1: 0.045922, loss_fp: 0.001488, loss_freq: 0.006917
[15:00:56.863] iteration 2824: loss: 0.228825, loss_s1: 0.028923, loss_fp: 0.000460, loss_freq: 0.006786
[15:00:57.492] iteration 2825: loss: 0.183761, loss_s1: 0.110506, loss_fp: 0.000508, loss_freq: 0.015617
[15:00:58.121] iteration 2826: loss: 0.230105, loss_s1: 0.048257, loss_fp: 0.000437, loss_freq: 0.016129
[15:00:58.744] iteration 2827: loss: 0.210741, loss_s1: 0.076576, loss_fp: 0.000560, loss_freq: 0.019793
[15:00:59.371] iteration 2828: loss: 0.222253, loss_s1: 0.057933, loss_fp: 0.000603, loss_freq: 0.001837
[15:00:59.995] iteration 2829: loss: 0.226409, loss_s1: 0.111812, loss_fp: 0.000698, loss_freq: 0.018102
[15:01:00.612] iteration 2830: loss: 0.325158, loss_s1: 0.041449, loss_fp: 0.000489, loss_freq: 0.029421
[15:01:01.242] iteration 2831: loss: 0.186894, loss_s1: 0.038582, loss_fp: 0.000485, loss_freq: 0.048662
[15:01:01.858] iteration 2832: loss: 0.194638, loss_s1: 0.041258, loss_fp: 0.000676, loss_freq: 0.084815
[15:01:02.481] iteration 2833: loss: 0.119513, loss_s1: 0.051366, loss_fp: 0.000472, loss_freq: 0.001968
[15:01:03.103] iteration 2834: loss: 0.139097, loss_s1: 0.011515, loss_fp: 0.000462, loss_freq: 0.006106
[15:01:03.726] iteration 2835: loss: 0.159693, loss_s1: 0.012152, loss_fp: 0.000418, loss_freq: 0.004576
[15:01:04.354] iteration 2836: loss: 0.211197, loss_s1: 0.000811, loss_fp: 0.000470, loss_freq: 0.000622
[15:01:04.981] iteration 2837: loss: 0.137449, loss_s1: 0.037835, loss_fp: 0.000842, loss_freq: 0.006561
[15:01:05.613] iteration 2838: loss: 0.108381, loss_s1: 0.036720, loss_fp: 0.000400, loss_freq: 0.002213
[15:01:06.252] iteration 2839: loss: 0.170986, loss_s1: 0.026755, loss_fp: 0.000497, loss_freq: 0.017325
[15:01:06.879] iteration 2840: loss: 0.324859, loss_s1: 0.244038, loss_fp: 0.002492, loss_freq: 0.173235
[15:01:07.513] iteration 2841: loss: 0.171132, loss_s1: 0.088162, loss_fp: 0.000436, loss_freq: 0.003329
[15:01:08.145] iteration 2842: loss: 0.209602, loss_s1: 0.027316, loss_fp: 0.000519, loss_freq: 0.006538
[15:01:08.777] iteration 2843: loss: 0.214258, loss_s1: 0.039124, loss_fp: 0.000409, loss_freq: 0.001823
[15:01:09.405] iteration 2844: loss: 0.163139, loss_s1: 0.019586, loss_fp: 0.000569, loss_freq: 0.000641
[15:01:10.037] iteration 2845: loss: 0.251170, loss_s1: 0.127425, loss_fp: 0.000764, loss_freq: 0.095212
[15:01:10.671] iteration 2846: loss: 0.253359, loss_s1: 0.094768, loss_fp: 0.001047, loss_freq: 0.118042
[15:01:11.301] iteration 2847: loss: 0.253005, loss_s1: 0.103872, loss_fp: 0.000427, loss_freq: 0.004555
[15:01:11.941] iteration 2848: loss: 0.209413, loss_s1: 0.021710, loss_fp: 0.001624, loss_freq: 0.046581
[15:01:12.572] iteration 2849: loss: 0.275684, loss_s1: 0.288005, loss_fp: 0.000856, loss_freq: 0.024502
[15:01:13.192] iteration 2850: loss: 0.193269, loss_s1: 0.080706, loss_fp: 0.000616, loss_freq: 0.115419
[15:01:13.816] iteration 2851: loss: 0.187234, loss_s1: 0.151523, loss_fp: 0.002150, loss_freq: 0.001181
[15:01:14.441] iteration 2852: loss: 0.179528, loss_s1: 0.017456, loss_fp: 0.000444, loss_freq: 0.001530
[15:01:15.067] iteration 2853: loss: 0.197273, loss_s1: 0.015166, loss_fp: 0.000633, loss_freq: 0.000755
[15:01:15.691] iteration 2854: loss: 0.264415, loss_s1: 0.114234, loss_fp: 0.000631, loss_freq: 0.143754
[15:01:16.344] iteration 2855: loss: 0.150535, loss_s1: 0.107072, loss_fp: 0.000667, loss_freq: 0.047979
[15:01:16.969] iteration 2856: loss: 0.437632, loss_s1: 0.326684, loss_fp: 0.001064, loss_freq: 0.234601
[15:01:17.592] iteration 2857: loss: 0.840440, loss_s1: 0.500588, loss_fp: 0.499997, loss_freq: 0.499997
[15:01:18.215] iteration 2858: loss: 0.101974, loss_s1: 0.017744, loss_fp: 0.001142, loss_freq: 0.001039
[15:01:18.840] iteration 2859: loss: 0.264970, loss_s1: 0.108440, loss_fp: 0.000376, loss_freq: 0.006674
[15:01:19.460] iteration 2860: loss: 0.209891, loss_s1: 0.196133, loss_fp: 0.001340, loss_freq: 0.012978
[15:01:20.084] iteration 2861: loss: 0.266447, loss_s1: 0.022577, loss_fp: 0.000592, loss_freq: 0.015154
[15:01:20.709] iteration 2862: loss: 0.282790, loss_s1: 0.126937, loss_fp: 0.000430, loss_freq: 0.076974
[15:01:21.335] iteration 2863: loss: 0.218238, loss_s1: 0.011185, loss_fp: 0.000323, loss_freq: 0.029553
[15:01:21.963] iteration 2864: loss: 0.228597, loss_s1: 0.076244, loss_fp: 0.000676, loss_freq: 0.005608
[15:01:22.621] iteration 2865: loss: 0.279236, loss_s1: 0.126814, loss_fp: 0.000421, loss_freq: 0.029314
[15:01:23.246] iteration 2866: loss: 0.251862, loss_s1: 0.182280, loss_fp: 0.000544, loss_freq: 0.007017
[15:01:23.867] iteration 2867: loss: 0.180517, loss_s1: 0.101113, loss_fp: 0.000663, loss_freq: 0.000440
[15:01:24.494] iteration 2868: loss: 0.173156, loss_s1: 0.188036, loss_fp: 0.001162, loss_freq: 0.028285
[15:01:25.114] iteration 2869: loss: 0.302467, loss_s1: 0.323949, loss_fp: 0.001945, loss_freq: 0.001332
[15:01:25.741] iteration 2870: loss: 0.244022, loss_s1: 0.150237, loss_fp: 0.001083, loss_freq: 0.024558
[15:01:26.377] iteration 2871: loss: 0.238425, loss_s1: 0.076961, loss_fp: 0.008687, loss_freq: 0.003937
[15:01:27.004] iteration 2872: loss: 0.162848, loss_s1: 0.106964, loss_fp: 0.000269, loss_freq: 0.015583
[15:01:27.618] iteration 2873: loss: 0.135788, loss_s1: 0.021647, loss_fp: 0.001120, loss_freq: 0.024260
[15:01:28.244] iteration 2874: loss: 0.163009, loss_s1: 0.033110, loss_fp: 0.000555, loss_freq: 0.002477
[15:01:28.868] iteration 2875: loss: 0.129704, loss_s1: 0.040423, loss_fp: 0.000471, loss_freq: 0.019828
[15:01:29.622] iteration 2876: loss: 0.631283, loss_s1: 0.049454, loss_fp: 0.500000, loss_freq: 0.500648
[15:01:30.264] iteration 2877: loss: 0.195851, loss_s1: 0.010620, loss_fp: 0.000641, loss_freq: 0.000796
[15:01:30.891] iteration 2878: loss: 0.241695, loss_s1: 0.088389, loss_fp: 0.000142, loss_freq: 0.011385
[15:01:31.513] iteration 2879: loss: 0.157110, loss_s1: 0.024109, loss_fp: 0.000518, loss_freq: 0.063718
[15:01:32.140] iteration 2880: loss: 0.180700, loss_s1: 0.106871, loss_fp: 0.000451, loss_freq: 0.003683
[15:01:32.767] iteration 2881: loss: 0.206579, loss_s1: 0.080401, loss_fp: 0.000899, loss_freq: 0.015679
[15:01:33.403] iteration 2882: loss: 0.236070, loss_s1: 0.025170, loss_fp: 0.000825, loss_freq: 0.006560
[15:01:34.024] iteration 2883: loss: 0.175525, loss_s1: 0.013388, loss_fp: 0.000432, loss_freq: 0.001873
[15:01:34.641] iteration 2884: loss: 0.141697, loss_s1: 0.044485, loss_fp: 0.001191, loss_freq: 0.027985
[15:01:35.267] iteration 2885: loss: 0.125817, loss_s1: 0.058731, loss_fp: 0.000608, loss_freq: 0.013581
[15:01:35.887] iteration 2886: loss: 0.099972, loss_s1: 0.033358, loss_fp: 0.000588, loss_freq: 0.011433
[15:01:36.507] iteration 2887: loss: 0.168002, loss_s1: 0.049634, loss_fp: 0.000505, loss_freq: 0.040292
[15:01:37.133] iteration 2888: loss: 0.311609, loss_s1: 0.059884, loss_fp: 0.000404, loss_freq: 0.069072
[15:01:37.757] iteration 2889: loss: 0.202204, loss_s1: 0.156528, loss_fp: 0.000585, loss_freq: 0.017286
[15:01:38.377] iteration 2890: loss: 0.086753, loss_s1: 0.014280, loss_fp: 0.000537, loss_freq: 0.001238
[15:01:39.006] iteration 2891: loss: 0.218305, loss_s1: 0.135944, loss_fp: 0.000753, loss_freq: 0.008372
[15:01:39.628] iteration 2892: loss: 0.173217, loss_s1: 0.050930, loss_fp: 0.000673, loss_freq: 0.059583
[15:01:40.252] iteration 2893: loss: 0.180780, loss_s1: 0.116797, loss_fp: 0.000306, loss_freq: 0.021284
[15:01:40.876] iteration 2894: loss: 0.313907, loss_s1: 0.142689, loss_fp: 0.000813, loss_freq: 0.018074
[15:01:41.500] iteration 2895: loss: 0.184114, loss_s1: 0.080048, loss_fp: 0.001137, loss_freq: 0.060796
[15:01:42.119] iteration 2896: loss: 0.227437, loss_s1: 0.004154, loss_fp: 0.001412, loss_freq: 0.061457
[15:01:42.741] iteration 2897: loss: 0.218732, loss_s1: 0.102019, loss_fp: 0.000501, loss_freq: 0.081970
[15:01:43.371] iteration 2898: loss: 0.222954, loss_s1: 0.151503, loss_fp: 0.001200, loss_freq: 0.002411
[15:01:44.365] iteration 2899: loss: 0.188884, loss_s1: 0.019249, loss_fp: 0.000637, loss_freq: 0.012146
[15:01:44.994] iteration 2900: loss: 0.196851, loss_s1: 0.083479, loss_fp: 0.001218, loss_freq: 0.014460
[15:01:45.626] iteration 2901: loss: 0.179431, loss_s1: 0.110415, loss_fp: 0.000854, loss_freq: 0.002524
[15:01:46.254] iteration 2902: loss: 0.182769, loss_s1: 0.086607, loss_fp: 0.000560, loss_freq: 0.000406
[15:01:46.881] iteration 2903: loss: 0.212718, loss_s1: 0.009138, loss_fp: 0.001156, loss_freq: 0.000597
[15:01:47.502] iteration 2904: loss: 0.351965, loss_s1: 0.275870, loss_fp: 0.001271, loss_freq: 0.016380
[15:01:48.129] iteration 2905: loss: 0.150556, loss_s1: 0.031311, loss_fp: 0.002243, loss_freq: 0.081408
[15:01:48.751] iteration 2906: loss: 0.096983, loss_s1: 0.002381, loss_fp: 0.000737, loss_freq: 0.004290
[15:01:49.371] iteration 2907: loss: 0.371957, loss_s1: 0.176051, loss_fp: 0.000691, loss_freq: 0.369004
[15:01:49.996] iteration 2908: loss: 0.198411, loss_s1: 0.096997, loss_fp: 0.000827, loss_freq: 0.053149
[15:01:50.617] iteration 2909: loss: 0.177032, loss_s1: 0.029242, loss_fp: 0.000495, loss_freq: 0.011859
[15:01:51.242] iteration 2910: loss: 0.133824, loss_s1: 0.039551, loss_fp: 0.001263, loss_freq: 0.004706
[15:01:51.866] iteration 2911: loss: 0.179692, loss_s1: 0.195864, loss_fp: 0.000706, loss_freq: 0.007422
[15:01:52.488] iteration 2912: loss: 0.183733, loss_s1: 0.054018, loss_fp: 0.001171, loss_freq: 0.001578
[15:01:53.116] iteration 2913: loss: 0.156000, loss_s1: 0.065957, loss_fp: 0.000874, loss_freq: 0.080883
[15:01:53.742] iteration 2914: loss: 0.130516, loss_s1: 0.065955, loss_fp: 0.000457, loss_freq: 0.007656
[15:01:54.367] iteration 2915: loss: 0.303357, loss_s1: 0.088031, loss_fp: 0.000505, loss_freq: 0.013312
[15:01:54.988] iteration 2916: loss: 0.178460, loss_s1: 0.036211, loss_fp: 0.000556, loss_freq: 0.029378
[15:01:55.608] iteration 2917: loss: 0.231633, loss_s1: 0.041419, loss_fp: 0.001242, loss_freq: 0.041625
[15:01:56.231] iteration 2918: loss: 0.147294, loss_s1: 0.044463, loss_fp: 0.000379, loss_freq: 0.012952
[15:01:56.849] iteration 2919: loss: 0.204493, loss_s1: 0.102545, loss_fp: 0.000410, loss_freq: 0.016089
[15:01:57.467] iteration 2920: loss: 0.307680, loss_s1: 0.143165, loss_fp: 0.000562, loss_freq: 0.171167
[15:01:58.088] iteration 2921: loss: 0.232234, loss_s1: 0.063379, loss_fp: 0.002702, loss_freq: 0.021854
[15:01:58.707] iteration 2922: loss: 0.481200, loss_s1: 0.460254, loss_fp: 0.088969, loss_freq: 0.224561
[15:01:59.338] iteration 2923: loss: 0.252277, loss_s1: 0.188226, loss_fp: 0.000926, loss_freq: 0.054224
[15:01:59.961] iteration 2924: loss: 0.118073, loss_s1: 0.015116, loss_fp: 0.000480, loss_freq: 0.002193
[15:02:00.585] iteration 2925: loss: 0.167553, loss_s1: 0.074320, loss_fp: 0.000470, loss_freq: 0.000554
[15:02:01.210] iteration 2926: loss: 0.418221, loss_s1: 0.260355, loss_fp: 0.000710, loss_freq: 0.172751
[15:02:01.867] iteration 2927: loss: 0.172140, loss_s1: 0.057937, loss_fp: 0.022908, loss_freq: 0.001117
[15:02:02.495] iteration 2928: loss: 0.174845, loss_s1: 0.009311, loss_fp: 0.000951, loss_freq: 0.038198
[15:02:03.113] iteration 2929: loss: 0.104581, loss_s1: 0.051565, loss_fp: 0.012615, loss_freq: 0.000470
[15:02:03.736] iteration 2930: loss: 0.226105, loss_s1: 0.106887, loss_fp: 0.000547, loss_freq: 0.005172
[15:02:04.366] iteration 2931: loss: 0.068928, loss_s1: 0.009947, loss_fp: 0.001772, loss_freq: 0.002080
[15:02:04.986] iteration 2932: loss: 0.125958, loss_s1: 0.030074, loss_fp: 0.001876, loss_freq: 0.004053
[15:02:05.611] iteration 2933: loss: 0.290459, loss_s1: 0.085186, loss_fp: 0.000643, loss_freq: 0.003578
[15:02:06.235] iteration 2934: loss: 0.201666, loss_s1: 0.075841, loss_fp: 0.000594, loss_freq: 0.015480
[15:02:06.883] iteration 2935: loss: 0.250262, loss_s1: 0.120004, loss_fp: 0.010415, loss_freq: 0.001060
[15:02:07.509] iteration 2936: loss: 0.182566, loss_s1: 0.013534, loss_fp: 0.003547, loss_freq: 0.008593
[15:02:08.140] iteration 2937: loss: 0.188655, loss_s1: 0.054915, loss_fp: 0.000450, loss_freq: 0.001480
[15:02:08.763] iteration 2938: loss: 0.198163, loss_s1: 0.038372, loss_fp: 0.004224, loss_freq: 0.001620
[15:02:09.383] iteration 2939: loss: 0.277757, loss_s1: 0.133704, loss_fp: 0.000409, loss_freq: 0.000329
[15:02:10.005] iteration 2940: loss: 0.136212, loss_s1: 0.034115, loss_fp: 0.000269, loss_freq: 0.023174
[15:02:10.628] iteration 2941: loss: 0.158341, loss_s1: 0.064004, loss_fp: 0.004210, loss_freq: 0.033522
[15:02:11.281] iteration 2942: loss: 0.073689, loss_s1: 0.000338, loss_fp: 0.000543, loss_freq: 0.000286
[15:02:11.911] iteration 2943: loss: 0.163819, loss_s1: 0.007212, loss_fp: 0.000510, loss_freq: 0.004907
[15:02:12.539] iteration 2944: loss: 0.216082, loss_s1: 0.025236, loss_fp: 0.000884, loss_freq: 0.003652
[15:02:13.161] iteration 2945: loss: 0.171383, loss_s1: 0.133856, loss_fp: 0.000706, loss_freq: 0.009741
[15:02:13.782] iteration 2946: loss: 0.079280, loss_s1: 0.001325, loss_fp: 0.000555, loss_freq: 0.007874
[15:02:14.403] iteration 2947: loss: 0.232278, loss_s1: 0.124451, loss_fp: 0.000816, loss_freq: 0.034580
[15:02:15.034] iteration 2948: loss: 0.103338, loss_s1: 0.017005, loss_fp: 0.000792, loss_freq: 0.002146
[15:02:15.655] iteration 2949: loss: 0.123680, loss_s1: 0.106135, loss_fp: 0.001302, loss_freq: 0.001844
[15:02:16.275] iteration 2950: loss: 0.268377, loss_s1: 0.060807, loss_fp: 0.000839, loss_freq: 0.045467
[15:02:16.896] iteration 2951: loss: 0.150213, loss_s1: 0.060414, loss_fp: 0.000416, loss_freq: 0.012688
[15:02:17.523] iteration 2952: loss: 0.245282, loss_s1: 0.201922, loss_fp: 0.001024, loss_freq: 0.003244
[15:02:18.143] iteration 2953: loss: 0.195846, loss_s1: 0.098939, loss_fp: 0.000380, loss_freq: 0.019894
[15:02:18.772] iteration 2954: loss: 0.500145, loss_s1: 0.451034, loss_fp: 0.005209, loss_freq: 0.287849
[15:02:19.397] iteration 2955: loss: 0.174166, loss_s1: 0.070269, loss_fp: 0.000503, loss_freq: 0.002885
[15:02:20.024] iteration 2956: loss: 0.261246, loss_s1: 0.150722, loss_fp: 0.001866, loss_freq: 0.000329
[15:02:20.656] iteration 2957: loss: 0.120344, loss_s1: 0.020274, loss_fp: 0.001448, loss_freq: 0.002647
[15:02:21.281] iteration 2958: loss: 0.178577, loss_s1: 0.085062, loss_fp: 0.000790, loss_freq: 0.064212
[15:02:21.907] iteration 2959: loss: 0.121531, loss_s1: 0.106321, loss_fp: 0.000496, loss_freq: 0.009741
[15:02:22.529] iteration 2960: loss: 0.153268, loss_s1: 0.035364, loss_fp: 0.000650, loss_freq: 0.093921
[15:02:23.152] iteration 2961: loss: 0.124424, loss_s1: 0.034405, loss_fp: 0.000490, loss_freq: 0.002228
[15:02:23.779] iteration 2962: loss: 0.423754, loss_s1: 0.360666, loss_fp: 0.002434, loss_freq: 0.060223
[15:02:24.404] iteration 2963: loss: 0.118225, loss_s1: 0.007810, loss_fp: 0.000507, loss_freq: 0.005168
[15:02:25.028] iteration 2964: loss: 0.085512, loss_s1: 0.026454, loss_fp: 0.001128, loss_freq: 0.001769
[15:02:25.654] iteration 2965: loss: 0.264533, loss_s1: 0.187886, loss_fp: 0.001596, loss_freq: 0.016109
[15:02:26.280] iteration 2966: loss: 0.135190, loss_s1: 0.100715, loss_fp: 0.000665, loss_freq: 0.001852
[15:02:26.904] iteration 2967: loss: 0.110592, loss_s1: 0.032595, loss_fp: 0.007079, loss_freq: 0.001505
[15:02:27.524] iteration 2968: loss: 0.248618, loss_s1: 0.077196, loss_fp: 0.000348, loss_freq: 0.001428
[15:02:28.147] iteration 2969: loss: 0.243874, loss_s1: 0.111123, loss_fp: 0.000468, loss_freq: 0.048401
[15:02:28.769] iteration 2970: loss: 0.221398, loss_s1: 0.032735, loss_fp: 0.000680, loss_freq: 0.074638
[15:02:29.389] iteration 2971: loss: 0.179807, loss_s1: 0.037594, loss_fp: 0.000644, loss_freq: 0.029046
[15:02:30.015] iteration 2972: loss: 0.167236, loss_s1: 0.031704, loss_fp: 0.000600, loss_freq: 0.012897
[15:02:30.638] iteration 2973: loss: 0.254692, loss_s1: 0.037169, loss_fp: 0.000725, loss_freq: 0.120592
[15:02:31.263] iteration 2974: loss: 0.205425, loss_s1: 0.123673, loss_fp: 0.000948, loss_freq: 0.021336
[15:02:31.891] iteration 2975: loss: 0.150558, loss_s1: 0.066950, loss_fp: 0.000363, loss_freq: 0.007174
[15:02:32.518] iteration 2976: loss: 0.263522, loss_s1: 0.209879, loss_fp: 0.000900, loss_freq: 0.135718
[15:02:33.148] iteration 2977: loss: 0.105157, loss_s1: 0.050990, loss_fp: 0.000749, loss_freq: 0.000403
[15:02:33.771] iteration 2978: loss: 0.126083, loss_s1: 0.008898, loss_fp: 0.000864, loss_freq: 0.000895
[15:02:34.397] iteration 2979: loss: 0.270272, loss_s1: 0.136631, loss_fp: 0.003374, loss_freq: 0.020693
[15:02:35.020] iteration 2980: loss: 0.217499, loss_s1: 0.125191, loss_fp: 0.000516, loss_freq: 0.004275
[15:02:35.646] iteration 2981: loss: 0.200755, loss_s1: 0.133732, loss_fp: 0.003332, loss_freq: 0.110929
[15:02:36.275] iteration 2982: loss: 0.184379, loss_s1: 0.059839, loss_fp: 0.000871, loss_freq: 0.000363
[15:02:36.898] iteration 2983: loss: 0.114923, loss_s1: 0.033132, loss_fp: 0.000788, loss_freq: 0.049310
[15:02:37.524] iteration 2984: loss: 0.225436, loss_s1: 0.311994, loss_fp: 0.000828, loss_freq: 0.000881
[15:02:38.146] iteration 2985: loss: 0.194061, loss_s1: 0.023966, loss_fp: 0.000410, loss_freq: 0.000535
[15:02:38.773] iteration 2986: loss: 0.201283, loss_s1: 0.148891, loss_fp: 0.000729, loss_freq: 0.069350
[15:02:39.397] iteration 2987: loss: 0.177378, loss_s1: 0.015022, loss_fp: 0.000583, loss_freq: 0.012470
[15:02:40.025] iteration 2988: loss: 0.154636, loss_s1: 0.035855, loss_fp: 0.000533, loss_freq: 0.011496
[15:02:40.650] iteration 2989: loss: 0.184948, loss_s1: 0.048466, loss_fp: 0.000519, loss_freq: 0.005128
[15:02:41.275] iteration 2990: loss: 0.217770, loss_s1: 0.119239, loss_fp: 0.000948, loss_freq: 0.055365
[15:02:41.897] iteration 2991: loss: 0.244107, loss_s1: 0.057995, loss_fp: 0.000459, loss_freq: 0.004281
[15:02:42.522] iteration 2992: loss: 0.159517, loss_s1: 0.071102, loss_fp: 0.000791, loss_freq: 0.004140
[15:02:43.144] iteration 2993: loss: 0.134282, loss_s1: 0.049791, loss_fp: 0.000588, loss_freq: 0.057091
[15:02:43.772] iteration 2994: loss: 0.108036, loss_s1: 0.079576, loss_fp: 0.000566, loss_freq: 0.010268
[15:02:44.401] iteration 2995: loss: 0.141216, loss_s1: 0.023573, loss_fp: 0.000695, loss_freq: 0.002047
[15:02:45.027] iteration 2996: loss: 0.174196, loss_s1: 0.037088, loss_fp: 0.000489, loss_freq: 0.010415
[15:02:45.645] iteration 2997: loss: 0.160797, loss_s1: 0.014169, loss_fp: 0.000408, loss_freq: 0.006814
[15:02:46.268] iteration 2998: loss: 0.137450, loss_s1: 0.040010, loss_fp: 0.000619, loss_freq: 0.009710
[15:02:46.885] iteration 2999: loss: 0.126770, loss_s1: 0.040405, loss_fp: 0.000286, loss_freq: 0.013134
[15:02:47.505] iteration 3000: loss: 0.189867, loss_s1: 0.028371, loss_fp: 0.000516, loss_freq: 0.028644
[15:02:50.693] iteration 3000 : mean_dice : 0.430792
[15:02:51.366] iteration 3001: loss: 0.273791, loss_s1: 0.308151, loss_fp: 0.000526, loss_freq: 0.017007
[15:02:51.991] iteration 3002: loss: 0.147089, loss_s1: 0.072320, loss_fp: 0.000383, loss_freq: 0.001417
[15:02:52.626] iteration 3003: loss: 0.217567, loss_s1: 0.060971, loss_fp: 0.000787, loss_freq: 0.019402
[15:02:53.246] iteration 3004: loss: 0.147087, loss_s1: 0.054255, loss_fp: 0.000763, loss_freq: 0.013567
[15:02:53.862] iteration 3005: loss: 0.174005, loss_s1: 0.075770, loss_fp: 0.001506, loss_freq: 0.002328
[15:02:54.483] iteration 3006: loss: 0.195214, loss_s1: 0.093071, loss_fp: 0.000816, loss_freq: 0.049492
[15:02:55.103] iteration 3007: loss: 0.325120, loss_s1: 0.100558, loss_fp: 0.002539, loss_freq: 0.295808
[15:02:55.725] iteration 3008: loss: 0.210579, loss_s1: 0.022020, loss_fp: 0.000824, loss_freq: 0.020176
[15:02:56.341] iteration 3009: loss: 0.148615, loss_s1: 0.022111, loss_fp: 0.000742, loss_freq: 0.007626
[15:02:57.007] iteration 3010: loss: 0.155936, loss_s1: 0.136617, loss_fp: 0.000656, loss_freq: 0.001117
[15:02:57.636] iteration 3011: loss: 0.281994, loss_s1: 0.133507, loss_fp: 0.000793, loss_freq: 0.200185
[15:02:58.265] iteration 3012: loss: 0.138738, loss_s1: 0.120752, loss_fp: 0.000763, loss_freq: 0.030027
[15:02:58.897] iteration 3013: loss: 0.122329, loss_s1: 0.075571, loss_fp: 0.000979, loss_freq: 0.002130
[15:02:59.524] iteration 3014: loss: 0.155682, loss_s1: 0.014773, loss_fp: 0.000607, loss_freq: 0.012619
[15:03:00.144] iteration 3015: loss: 0.143464, loss_s1: 0.063355, loss_fp: 0.001689, loss_freq: 0.038473
[15:03:00.773] iteration 3016: loss: 0.141017, loss_s1: 0.056048, loss_fp: 0.000563, loss_freq: 0.021902
[15:03:01.401] iteration 3017: loss: 0.173681, loss_s1: 0.000491, loss_fp: 0.000618, loss_freq: 0.028743
[15:03:02.029] iteration 3018: loss: 0.203393, loss_s1: 0.142777, loss_fp: 0.000976, loss_freq: 0.118747
[15:03:02.666] iteration 3019: loss: 0.120924, loss_s1: 0.092101, loss_fp: 0.004928, loss_freq: 0.007100
[15:03:03.297] iteration 3020: loss: 0.293043, loss_s1: 0.102506, loss_fp: 0.000762, loss_freq: 0.013583
[15:03:03.921] iteration 3021: loss: 0.177200, loss_s1: 0.060695, loss_fp: 0.001152, loss_freq: 0.100151
[15:03:04.547] iteration 3022: loss: 0.216200, loss_s1: 0.005948, loss_fp: 0.000406, loss_freq: 0.056264
[15:03:05.173] iteration 3023: loss: 0.182819, loss_s1: 0.078658, loss_fp: 0.000972, loss_freq: 0.039824
[15:03:05.797] iteration 3024: loss: 0.165719, loss_s1: 0.017820, loss_fp: 0.006070, loss_freq: 0.019845
[15:03:06.440] iteration 3025: loss: 0.190962, loss_s1: 0.085124, loss_fp: 0.000740, loss_freq: 0.000285
[15:03:07.066] iteration 3026: loss: 0.259471, loss_s1: 0.164443, loss_fp: 0.000436, loss_freq: 0.008562
[15:03:07.692] iteration 3027: loss: 0.158456, loss_s1: 0.078931, loss_fp: 0.000763, loss_freq: 0.055345
[15:03:08.315] iteration 3028: loss: 0.188882, loss_s1: 0.134167, loss_fp: 0.000812, loss_freq: 0.018892
[15:03:08.949] iteration 3029: loss: 0.099406, loss_s1: 0.039030, loss_fp: 0.001141, loss_freq: 0.000650
[15:03:09.573] iteration 3030: loss: 0.237584, loss_s1: 0.269586, loss_fp: 0.001912, loss_freq: 0.001252
[15:03:10.194] iteration 3031: loss: 0.164323, loss_s1: 0.053420, loss_fp: 0.001565, loss_freq: 0.001802
[15:03:10.814] iteration 3032: loss: 0.208272, loss_s1: 0.020573, loss_fp: 0.000431, loss_freq: 0.000737
[15:03:11.434] iteration 3033: loss: 0.132205, loss_s1: 0.063468, loss_fp: 0.000427, loss_freq: 0.000920
[15:03:12.055] iteration 3034: loss: 0.212518, loss_s1: 0.048923, loss_fp: 0.000909, loss_freq: 0.216690
[15:03:12.680] iteration 3035: loss: 0.220969, loss_s1: 0.109625, loss_fp: 0.001796, loss_freq: 0.009597
[15:03:13.307] iteration 3036: loss: 0.116253, loss_s1: 0.072489, loss_fp: 0.000593, loss_freq: 0.038407
[15:03:13.932] iteration 3037: loss: 0.270892, loss_s1: 0.318200, loss_fp: 0.005392, loss_freq: 0.046916
[15:03:14.556] iteration 3038: loss: 0.243899, loss_s1: 0.137395, loss_fp: 0.000281, loss_freq: 0.012401
[15:03:15.182] iteration 3039: loss: 0.255124, loss_s1: 0.116153, loss_fp: 0.002089, loss_freq: 0.100549
[15:03:15.809] iteration 3040: loss: 0.135961, loss_s1: 0.046389, loss_fp: 0.000669, loss_freq: 0.004512
[15:03:16.435] iteration 3041: loss: 0.130773, loss_s1: 0.036148, loss_fp: 0.000680, loss_freq: 0.004177
[15:03:17.066] iteration 3042: loss: 0.187073, loss_s1: 0.028386, loss_fp: 0.000705, loss_freq: 0.019024
[15:03:17.695] iteration 3043: loss: 0.196286, loss_s1: 0.013430, loss_fp: 0.000697, loss_freq: 0.001621
[15:03:18.322] iteration 3044: loss: 0.219189, loss_s1: 0.045781, loss_fp: 0.000460, loss_freq: 0.062785
[15:03:18.948] iteration 3045: loss: 0.132999, loss_s1: 0.040002, loss_fp: 0.000631, loss_freq: 0.034661
[15:03:19.572] iteration 3046: loss: 0.154149, loss_s1: 0.091577, loss_fp: 0.001854, loss_freq: 0.036489
[15:03:20.198] iteration 3047: loss: 0.106086, loss_s1: 0.040886, loss_fp: 0.000612, loss_freq: 0.010678
[15:03:20.822] iteration 3048: loss: 0.148305, loss_s1: 0.034162, loss_fp: 0.000576, loss_freq: 0.006512
[15:03:21.445] iteration 3049: loss: 0.220744, loss_s1: 0.036307, loss_fp: 0.000464, loss_freq: 0.120889
[15:03:22.065] iteration 3050: loss: 0.229479, loss_s1: 0.206367, loss_fp: 0.000512, loss_freq: 0.019360
[15:03:22.691] iteration 3051: loss: 0.078938, loss_s1: 0.051754, loss_fp: 0.000449, loss_freq: 0.004794
[15:03:23.313] iteration 3052: loss: 0.438744, loss_s1: 0.318135, loss_fp: 0.001836, loss_freq: 0.234879
[15:03:23.934] iteration 3053: loss: 0.143023, loss_s1: 0.095503, loss_fp: 0.001149, loss_freq: 0.023541
[15:03:24.555] iteration 3054: loss: 0.136233, loss_s1: 0.088719, loss_fp: 0.000654, loss_freq: 0.023280
[15:03:25.178] iteration 3055: loss: 0.201466, loss_s1: 0.078484, loss_fp: 0.000810, loss_freq: 0.033525
[15:03:25.798] iteration 3056: loss: 0.158567, loss_s1: 0.049478, loss_fp: 0.000945, loss_freq: 0.048239
[15:03:26.415] iteration 3057: loss: 0.205114, loss_s1: 0.075095, loss_fp: 0.000647, loss_freq: 0.018813
[15:03:27.040] iteration 3058: loss: 0.182332, loss_s1: 0.105053, loss_fp: 0.000366, loss_freq: 0.048582
[15:03:27.665] iteration 3059: loss: 0.203561, loss_s1: 0.141778, loss_fp: 0.001418, loss_freq: 0.008278
[15:03:28.631] iteration 3060: loss: 0.182949, loss_s1: 0.016326, loss_fp: 0.000848, loss_freq: 0.012634
[15:03:29.259] iteration 3061: loss: 0.360972, loss_s1: 0.301339, loss_fp: 0.001485, loss_freq: 0.183497
[15:03:29.882] iteration 3062: loss: 0.130402, loss_s1: 0.019572, loss_fp: 0.000472, loss_freq: 0.010033
[15:03:30.504] iteration 3063: loss: 0.173847, loss_s1: 0.045366, loss_fp: 0.000694, loss_freq: 0.006234
[15:03:31.128] iteration 3064: loss: 0.174516, loss_s1: 0.013658, loss_fp: 0.000438, loss_freq: 0.003490
[15:03:31.747] iteration 3065: loss: 0.427907, loss_s1: 0.317914, loss_fp: 0.001195, loss_freq: 0.098600
[15:03:32.368] iteration 3066: loss: 0.130825, loss_s1: 0.085198, loss_fp: 0.000397, loss_freq: 0.002099
[15:03:32.989] iteration 3067: loss: 0.221274, loss_s1: 0.174890, loss_fp: 0.087107, loss_freq: 0.041947
[15:03:33.609] iteration 3068: loss: 0.090943, loss_s1: 0.023918, loss_fp: 0.000591, loss_freq: 0.007019
[15:03:34.301] iteration 3069: loss: 0.145827, loss_s1: 0.060712, loss_fp: 0.001564, loss_freq: 0.051184
[15:03:34.938] iteration 3070: loss: 0.188300, loss_s1: 0.017089, loss_fp: 0.001878, loss_freq: 0.002490
[15:03:35.664] iteration 3071: loss: 0.125695, loss_s1: 0.020099, loss_fp: 0.000556, loss_freq: 0.001238
[15:03:36.293] iteration 3072: loss: 0.139818, loss_s1: 0.094352, loss_fp: 0.000676, loss_freq: 0.002154
[15:03:36.929] iteration 3073: loss: 0.294260, loss_s1: 0.180406, loss_fp: 0.000804, loss_freq: 0.116236
[15:03:37.561] iteration 3074: loss: 0.092533, loss_s1: 0.037406, loss_fp: 0.001302, loss_freq: 0.009221
[15:03:38.187] iteration 3075: loss: 0.129469, loss_s1: 0.049201, loss_fp: 0.001309, loss_freq: 0.007199
[15:03:38.816] iteration 3076: loss: 0.159840, loss_s1: 0.015746, loss_fp: 0.000904, loss_freq: 0.009926
[15:03:39.442] iteration 3077: loss: 0.165334, loss_s1: 0.129574, loss_fp: 0.004277, loss_freq: 0.019235
[15:03:40.068] iteration 3078: loss: 0.152265, loss_s1: 0.026661, loss_fp: 0.000573, loss_freq: 0.016089
[15:03:40.697] iteration 3079: loss: 0.162286, loss_s1: 0.050209, loss_fp: 0.002033, loss_freq: 0.030032
[15:03:41.326] iteration 3080: loss: 0.122451, loss_s1: 0.000787, loss_fp: 0.001584, loss_freq: 0.001971
[15:03:41.948] iteration 3081: loss: 0.191749, loss_s1: 0.103509, loss_fp: 0.000616, loss_freq: 0.001720
[15:03:42.578] iteration 3082: loss: 0.187933, loss_s1: 0.030341, loss_fp: 0.000500, loss_freq: 0.017012
[15:03:43.197] iteration 3083: loss: 0.461516, loss_s1: 0.389955, loss_fp: 0.014150, loss_freq: 0.295091
[15:03:43.822] iteration 3084: loss: 0.121770, loss_s1: 0.032568, loss_fp: 0.001010, loss_freq: 0.003349
[15:03:44.441] iteration 3085: loss: 0.121091, loss_s1: 0.011632, loss_fp: 0.001440, loss_freq: 0.082018
[15:03:45.063] iteration 3086: loss: 0.159390, loss_s1: 0.104153, loss_fp: 0.002372, loss_freq: 0.010675
[15:03:45.683] iteration 3087: loss: 0.161725, loss_s1: 0.018024, loss_fp: 0.000498, loss_freq: 0.062682
[15:03:46.303] iteration 3088: loss: 0.148250, loss_s1: 0.008202, loss_fp: 0.000551, loss_freq: 0.020203
[15:03:46.924] iteration 3089: loss: 0.169616, loss_s1: 0.112037, loss_fp: 0.001986, loss_freq: 0.016770
[15:03:47.546] iteration 3090: loss: 0.190685, loss_s1: 0.145903, loss_fp: 0.000621, loss_freq: 0.000745
[15:03:48.171] iteration 3091: loss: 0.211516, loss_s1: 0.050594, loss_fp: 0.000960, loss_freq: 0.005075
[15:03:48.793] iteration 3092: loss: 0.111072, loss_s1: 0.071340, loss_fp: 0.000830, loss_freq: 0.043083
[15:03:49.421] iteration 3093: loss: 0.150505, loss_s1: 0.034069, loss_fp: 0.000576, loss_freq: 0.024070
[15:03:50.040] iteration 3094: loss: 0.251982, loss_s1: 0.022966, loss_fp: 0.000775, loss_freq: 0.007679
[15:03:50.660] iteration 3095: loss: 0.193588, loss_s1: 0.040886, loss_fp: 0.000797, loss_freq: 0.021916
[15:03:51.278] iteration 3096: loss: 0.187116, loss_s1: 0.086538, loss_fp: 0.000930, loss_freq: 0.006132
[15:03:51.898] iteration 3097: loss: 0.214762, loss_s1: 0.086469, loss_fp: 0.000391, loss_freq: 0.079987
[15:03:52.518] iteration 3098: loss: 0.160107, loss_s1: 0.078160, loss_fp: 0.000660, loss_freq: 0.006463
[15:03:53.141] iteration 3099: loss: 0.238903, loss_s1: 0.046699, loss_fp: 0.000492, loss_freq: 0.026067
[15:03:53.769] iteration 3100: loss: 0.136084, loss_s1: 0.008553, loss_fp: 0.000562, loss_freq: 0.019379
[15:03:54.392] iteration 3101: loss: 0.100681, loss_s1: 0.044169, loss_fp: 0.000942, loss_freq: 0.004329
[15:03:55.013] iteration 3102: loss: 0.162760, loss_s1: 0.037558, loss_fp: 0.002730, loss_freq: 0.099420
[15:03:55.636] iteration 3103: loss: 0.129882, loss_s1: 0.048250, loss_fp: 0.002192, loss_freq: 0.045419
[15:03:56.263] iteration 3104: loss: 0.133182, loss_s1: 0.048828, loss_fp: 0.000297, loss_freq: 0.005924
[15:03:56.888] iteration 3105: loss: 0.203414, loss_s1: 0.015772, loss_fp: 0.000229, loss_freq: 0.002982
[15:03:57.510] iteration 3106: loss: 0.112219, loss_s1: 0.026188, loss_fp: 0.000718, loss_freq: 0.027277
[15:03:58.136] iteration 3107: loss: 0.128101, loss_s1: 0.034209, loss_fp: 0.000614, loss_freq: 0.043053
[15:03:58.760] iteration 3108: loss: 0.208622, loss_s1: 0.072842, loss_fp: 0.001467, loss_freq: 0.047774
[15:03:59.388] iteration 3109: loss: 0.134340, loss_s1: 0.044591, loss_fp: 0.001140, loss_freq: 0.046547
[15:04:00.019] iteration 3110: loss: 0.138617, loss_s1: 0.125410, loss_fp: 0.000990, loss_freq: 0.006421
[15:04:00.642] iteration 3111: loss: 0.262586, loss_s1: 0.063122, loss_fp: 0.000582, loss_freq: 0.063619
[15:04:01.268] iteration 3112: loss: 0.133258, loss_s1: 0.026887, loss_fp: 0.000499, loss_freq: 0.011993
[15:04:01.893] iteration 3113: loss: 0.260102, loss_s1: 0.108314, loss_fp: 0.000802, loss_freq: 0.019330
[15:04:02.518] iteration 3114: loss: 0.121523, loss_s1: 0.045610, loss_fp: 0.000924, loss_freq: 0.015879
[15:04:03.141] iteration 3115: loss: 0.358765, loss_s1: 0.292549, loss_fp: 0.001633, loss_freq: 0.141670
[15:04:03.766] iteration 3116: loss: 0.153642, loss_s1: 0.035242, loss_fp: 0.001192, loss_freq: 0.014022
[15:04:04.398] iteration 3117: loss: 0.182590, loss_s1: 0.020379, loss_fp: 0.000588, loss_freq: 0.007837
[15:04:05.033] iteration 3118: loss: 0.142267, loss_s1: 0.021113, loss_fp: 0.000514, loss_freq: 0.043001
[15:04:05.669] iteration 3119: loss: 0.166025, loss_s1: 0.122519, loss_fp: 0.000648, loss_freq: 0.017343
[15:04:06.296] iteration 3120: loss: 0.129348, loss_s1: 0.049808, loss_fp: 0.000931, loss_freq: 0.075134
[15:04:06.916] iteration 3121: loss: 0.130773, loss_s1: 0.057326, loss_fp: 0.000647, loss_freq: 0.025038
[15:04:07.538] iteration 3122: loss: 0.173935, loss_s1: 0.075372, loss_fp: 0.001644, loss_freq: 0.062244
[15:04:08.162] iteration 3123: loss: 0.281740, loss_s1: 0.105489, loss_fp: 0.001186, loss_freq: 0.195604
[15:04:08.782] iteration 3124: loss: 0.184600, loss_s1: 0.086704, loss_fp: 0.000683, loss_freq: 0.018701
[15:04:09.397] iteration 3125: loss: 0.117457, loss_s1: 0.012611, loss_fp: 0.000806, loss_freq: 0.048192
[15:04:10.019] iteration 3126: loss: 0.216065, loss_s1: 0.053030, loss_fp: 0.001226, loss_freq: 0.081954
[15:04:10.658] iteration 3127: loss: 0.108716, loss_s1: 0.082037, loss_fp: 0.001137, loss_freq: 0.015695
[15:04:11.280] iteration 3128: loss: 0.152774, loss_s1: 0.120596, loss_fp: 0.001312, loss_freq: 0.022641
[15:04:11.905] iteration 3129: loss: 0.242590, loss_s1: 0.028318, loss_fp: 0.000611, loss_freq: 0.059290
[15:04:12.528] iteration 3130: loss: 0.244969, loss_s1: 0.172541, loss_fp: 0.001712, loss_freq: 0.038965
[15:04:13.151] iteration 3131: loss: 0.143605, loss_s1: 0.029243, loss_fp: 0.000548, loss_freq: 0.003728
[15:04:13.775] iteration 3132: loss: 0.109715, loss_s1: 0.013330, loss_fp: 0.000598, loss_freq: 0.002008
[15:04:14.396] iteration 3133: loss: 0.186695, loss_s1: 0.088481, loss_fp: 0.000664, loss_freq: 0.009382
[15:04:15.021] iteration 3134: loss: 0.211351, loss_s1: 0.042236, loss_fp: 0.000800, loss_freq: 0.094934
[15:04:15.647] iteration 3135: loss: 0.233158, loss_s1: 0.161818, loss_fp: 0.000601, loss_freq: 0.024772
[15:04:16.274] iteration 3136: loss: 0.169999, loss_s1: 0.045533, loss_fp: 0.000760, loss_freq: 0.047266
[15:04:16.897] iteration 3137: loss: 0.130096, loss_s1: 0.005478, loss_fp: 0.000710, loss_freq: 0.064612
[15:04:17.524] iteration 3138: loss: 0.102267, loss_s1: 0.083737, loss_fp: 0.000603, loss_freq: 0.003063
[15:04:18.151] iteration 3139: loss: 0.210201, loss_s1: 0.133749, loss_fp: 0.000423, loss_freq: 0.015450
[15:04:18.781] iteration 3140: loss: 0.264330, loss_s1: 0.067259, loss_fp: 0.000812, loss_freq: 0.053093
[15:04:19.412] iteration 3141: loss: 0.136747, loss_s1: 0.066819, loss_fp: 0.000437, loss_freq: 0.019789
[15:04:20.042] iteration 3142: loss: 0.185892, loss_s1: 0.149308, loss_fp: 0.001078, loss_freq: 0.054274
[15:04:20.723] iteration 3143: loss: 0.152753, loss_s1: 0.027978, loss_fp: 0.000641, loss_freq: 0.000303
[15:04:21.349] iteration 3144: loss: 0.159093, loss_s1: 0.094498, loss_fp: 0.000631, loss_freq: 0.078384
[15:04:21.985] iteration 3145: loss: 0.079280, loss_s1: 0.036974, loss_fp: 0.000363, loss_freq: 0.000288
[15:04:22.617] iteration 3146: loss: 0.229654, loss_s1: 0.026515, loss_fp: 0.000464, loss_freq: 0.026228
[15:04:23.241] iteration 3147: loss: 0.162813, loss_s1: 0.090305, loss_fp: 0.000431, loss_freq: 0.074818
[15:04:23.861] iteration 3148: loss: 0.275607, loss_s1: 0.212641, loss_fp: 0.001403, loss_freq: 0.074559
[15:04:24.489] iteration 3149: loss: 0.184811, loss_s1: 0.097112, loss_fp: 0.001917, loss_freq: 0.012379
[15:04:25.114] iteration 3150: loss: 0.210881, loss_s1: 0.082947, loss_fp: 0.000835, loss_freq: 0.006909
[15:04:25.738] iteration 3151: loss: 0.143872, loss_s1: 0.029619, loss_fp: 0.001298, loss_freq: 0.003246
[15:04:26.361] iteration 3152: loss: 0.205440, loss_s1: 0.047908, loss_fp: 0.000444, loss_freq: 0.006370
[15:04:26.985] iteration 3153: loss: 0.173119, loss_s1: 0.089144, loss_fp: 0.000530, loss_freq: 0.039149
[15:04:27.607] iteration 3154: loss: 0.119013, loss_s1: 0.047077, loss_fp: 0.000566, loss_freq: 0.001464
[15:04:28.230] iteration 3155: loss: 0.071720, loss_s1: 0.016864, loss_fp: 0.000570, loss_freq: 0.001652
[15:04:28.850] iteration 3156: loss: 0.092418, loss_s1: 0.017062, loss_fp: 0.000842, loss_freq: 0.000645
[15:04:29.472] iteration 3157: loss: 0.186497, loss_s1: 0.020339, loss_fp: 0.000619, loss_freq: 0.041269
[15:04:30.096] iteration 3158: loss: 0.185298, loss_s1: 0.020158, loss_fp: 0.000406, loss_freq: 0.003924
[15:04:30.719] iteration 3159: loss: 0.143097, loss_s1: 0.051073, loss_fp: 0.001228, loss_freq: 0.051420
[15:04:31.352] iteration 3160: loss: 0.094382, loss_s1: 0.011944, loss_fp: 0.000488, loss_freq: 0.001209
[15:04:31.973] iteration 3161: loss: 0.176195, loss_s1: 0.055455, loss_fp: 0.000533, loss_freq: 0.036552
[15:04:32.601] iteration 3162: loss: 0.359985, loss_s1: 0.333940, loss_fp: 0.001359, loss_freq: 0.151042
[15:04:33.224] iteration 3163: loss: 0.132462, loss_s1: 0.059727, loss_fp: 0.001075, loss_freq: 0.005317
[15:04:33.841] iteration 3164: loss: 0.263657, loss_s1: 0.098654, loss_fp: 0.000523, loss_freq: 0.025812
[15:04:34.462] iteration 3165: loss: 0.187899, loss_s1: 0.048879, loss_fp: 0.001497, loss_freq: 0.003205
[15:04:35.085] iteration 3166: loss: 0.168719, loss_s1: 0.063387, loss_fp: 0.001275, loss_freq: 0.002425
[15:04:35.712] iteration 3167: loss: 0.171101, loss_s1: 0.108685, loss_fp: 0.000516, loss_freq: 0.036255
[15:04:36.335] iteration 3168: loss: 0.347673, loss_s1: 0.153700, loss_fp: 0.001997, loss_freq: 0.234667
[15:04:36.959] iteration 3169: loss: 0.205054, loss_s1: 0.106537, loss_fp: 0.001058, loss_freq: 0.012908
[15:04:37.585] iteration 3170: loss: 0.171265, loss_s1: 0.023103, loss_fp: 0.000648, loss_freq: 0.018076
[15:04:38.204] iteration 3171: loss: 0.108555, loss_s1: 0.017000, loss_fp: 0.000690, loss_freq: 0.056129
[15:04:38.827] iteration 3172: loss: 0.335072, loss_s1: 0.245636, loss_fp: 0.001178, loss_freq: 0.279351
[15:04:39.451] iteration 3173: loss: 0.182102, loss_s1: 0.147092, loss_fp: 0.002124, loss_freq: 0.011025
[15:04:40.075] iteration 3174: loss: 0.125724, loss_s1: 0.028228, loss_fp: 0.000547, loss_freq: 0.001218
[15:04:40.694] iteration 3175: loss: 0.135274, loss_s1: 0.039574, loss_fp: 0.001420, loss_freq: 0.001083
[15:04:41.319] iteration 3176: loss: 0.207797, loss_s1: 0.107440, loss_fp: 0.000682, loss_freq: 0.079739
[15:04:41.949] iteration 3177: loss: 0.150032, loss_s1: 0.061478, loss_fp: 0.002982, loss_freq: 0.009163
[15:04:42.569] iteration 3178: loss: 0.247497, loss_s1: 0.105613, loss_fp: 0.000655, loss_freq: 0.084117
[15:04:43.190] iteration 3179: loss: 0.275905, loss_s1: 0.305100, loss_fp: 0.001169, loss_freq: 0.096721
[15:04:43.817] iteration 3180: loss: 0.075043, loss_s1: 0.012222, loss_fp: 0.002521, loss_freq: 0.004128
[15:04:44.440] iteration 3181: loss: 0.239891, loss_s1: 0.024879, loss_fp: 0.000323, loss_freq: 0.008542
[15:04:45.070] iteration 3182: loss: 0.160678, loss_s1: 0.032605, loss_fp: 0.000437, loss_freq: 0.088602
[15:04:45.688] iteration 3183: loss: 0.225238, loss_s1: 0.061690, loss_fp: 0.001120, loss_freq: 0.024964
[15:04:46.307] iteration 3184: loss: 0.198161, loss_s1: 0.113632, loss_fp: 0.001529, loss_freq: 0.052831
[15:04:46.929] iteration 3185: loss: 0.187393, loss_s1: 0.088081, loss_fp: 0.000900, loss_freq: 0.003555
[15:04:47.547] iteration 3186: loss: 0.196833, loss_s1: 0.022770, loss_fp: 0.000812, loss_freq: 0.015453
[15:04:48.164] iteration 3187: loss: 0.199633, loss_s1: 0.055293, loss_fp: 0.001353, loss_freq: 0.017113
[15:04:48.786] iteration 3188: loss: 0.165627, loss_s1: 0.099131, loss_fp: 0.002173, loss_freq: 0.015356
[15:04:49.405] iteration 3189: loss: 0.147167, loss_s1: 0.044509, loss_fp: 0.000809, loss_freq: 0.000630
[15:04:50.029] iteration 3190: loss: 0.125937, loss_s1: 0.096048, loss_fp: 0.006887, loss_freq: 0.032618
[15:04:50.650] iteration 3191: loss: 0.698068, loss_s1: 0.169735, loss_fp: 0.499988, loss_freq: 0.500065
[15:04:51.270] iteration 3192: loss: 0.168889, loss_s1: 0.057177, loss_fp: 0.001327, loss_freq: 0.006679
[15:04:51.889] iteration 3193: loss: 0.148991, loss_s1: 0.056218, loss_fp: 0.004888, loss_freq: 0.012364
[15:04:52.510] iteration 3194: loss: 0.126793, loss_s1: 0.077600, loss_fp: 0.000466, loss_freq: 0.005235
[15:04:53.138] iteration 3195: loss: 0.292133, loss_s1: 0.245918, loss_fp: 0.000623, loss_freq: 0.175640
[15:04:53.762] iteration 3196: loss: 0.159293, loss_s1: 0.030080, loss_fp: 0.000906, loss_freq: 0.002954
[15:04:54.384] iteration 3197: loss: 0.073937, loss_s1: 0.035229, loss_fp: 0.000490, loss_freq: 0.012361
[15:04:55.018] iteration 3198: loss: 0.184250, loss_s1: 0.156579, loss_fp: 0.000374, loss_freq: 0.037594
[15:04:55.643] iteration 3199: loss: 0.183530, loss_s1: 0.076340, loss_fp: 0.000657, loss_freq: 0.046752
[15:04:56.267] iteration 3200: loss: 0.206351, loss_s1: 0.062361, loss_fp: 0.000595, loss_freq: 0.069383
[15:04:59.309] iteration 3200 : mean_dice : 0.533445
[15:04:59.949] iteration 3201: loss: 0.137676, loss_s1: 0.047765, loss_fp: 0.001305, loss_freq: 0.031253
[15:05:00.574] iteration 3202: loss: 0.141030, loss_s1: 0.059730, loss_fp: 0.001407, loss_freq: 0.003232
[15:05:01.203] iteration 3203: loss: 0.215652, loss_s1: 0.091066, loss_fp: 0.000808, loss_freq: 0.005815
[15:05:01.839] iteration 3204: loss: 0.197555, loss_s1: 0.052638, loss_fp: 0.000725, loss_freq: 0.000658
[15:05:02.480] iteration 3205: loss: 0.189414, loss_s1: 0.038867, loss_fp: 0.000320, loss_freq: 0.009689
[15:05:03.156] iteration 3206: loss: 0.105813, loss_s1: 0.042538, loss_fp: 0.000556, loss_freq: 0.003081
[15:05:03.781] iteration 3207: loss: 0.141088, loss_s1: 0.038186, loss_fp: 0.000503, loss_freq: 0.074410
[15:05:04.402] iteration 3208: loss: 0.174294, loss_s1: 0.058904, loss_fp: 0.001054, loss_freq: 0.017574
[15:05:05.022] iteration 3209: loss: 0.150258, loss_s1: 0.055760, loss_fp: 0.001343, loss_freq: 0.004870
[15:05:05.642] iteration 3210: loss: 0.218562, loss_s1: 0.123219, loss_fp: 0.000537, loss_freq: 0.054638
[15:05:06.259] iteration 3211: loss: 0.277605, loss_s1: 0.189805, loss_fp: 0.014517, loss_freq: 0.027588
[15:05:06.883] iteration 3212: loss: 0.074449, loss_s1: 0.027694, loss_fp: 0.000571, loss_freq: 0.001597
[15:05:07.503] iteration 3213: loss: 0.199337, loss_s1: 0.050783, loss_fp: 0.001856, loss_freq: 0.030530
[15:05:08.122] iteration 3214: loss: 0.128880, loss_s1: 0.031456, loss_fp: 0.000737, loss_freq: 0.008568
[15:05:08.748] iteration 3215: loss: 0.091235, loss_s1: 0.007345, loss_fp: 0.000754, loss_freq: 0.040279
[15:05:09.371] iteration 3216: loss: 0.194323, loss_s1: 0.057836, loss_fp: 0.001155, loss_freq: 0.014749
[15:05:09.988] iteration 3217: loss: 0.211322, loss_s1: 0.100183, loss_fp: 0.000511, loss_freq: 0.061382
[15:05:10.608] iteration 3218: loss: 0.177353, loss_s1: 0.064669, loss_fp: 0.000836, loss_freq: 0.007050
[15:05:11.230] iteration 3219: loss: 0.163248, loss_s1: 0.092060, loss_fp: 0.000738, loss_freq: 0.031424
[15:05:11.855] iteration 3220: loss: 0.149983, loss_s1: 0.052238, loss_fp: 0.000721, loss_freq: 0.004819
[15:05:12.810] iteration 3221: loss: 0.165868, loss_s1: 0.053850, loss_fp: 0.000574, loss_freq: 0.008994
[15:05:13.451] iteration 3222: loss: 0.255902, loss_s1: 0.148271, loss_fp: 0.001187, loss_freq: 0.095060
[15:05:14.075] iteration 3223: loss: 0.170923, loss_s1: 0.074707, loss_fp: 0.000580, loss_freq: 0.009416
[15:05:14.700] iteration 3224: loss: 0.156605, loss_s1: 0.047114, loss_fp: 0.000497, loss_freq: 0.001724
[15:05:15.322] iteration 3225: loss: 0.153578, loss_s1: 0.008805, loss_fp: 0.000994, loss_freq: 0.001694
[15:05:15.943] iteration 3226: loss: 0.238679, loss_s1: 0.196381, loss_fp: 0.000551, loss_freq: 0.003505
[15:05:16.563] iteration 3227: loss: 0.103290, loss_s1: 0.041755, loss_fp: 0.000605, loss_freq: 0.010828
[15:05:17.188] iteration 3228: loss: 0.104136, loss_s1: 0.053728, loss_fp: 0.000590, loss_freq: 0.020333
[15:05:17.809] iteration 3229: loss: 0.061222, loss_s1: 0.005558, loss_fp: 0.004467, loss_freq: 0.000596
[15:05:18.430] iteration 3230: loss: 0.135171, loss_s1: 0.078363, loss_fp: 0.000454, loss_freq: 0.032540
[15:05:19.050] iteration 3231: loss: 0.124488, loss_s1: 0.033651, loss_fp: 0.000871, loss_freq: 0.025106
[15:05:19.700] iteration 3232: loss: 0.143376, loss_s1: 0.048110, loss_fp: 0.000715, loss_freq: 0.025678
[15:05:20.331] iteration 3233: loss: 0.112979, loss_s1: 0.034104, loss_fp: 0.003742, loss_freq: 0.019793
[15:05:20.965] iteration 3234: loss: 0.132095, loss_s1: 0.007812, loss_fp: 0.000739, loss_freq: 0.007771
[15:05:21.600] iteration 3235: loss: 0.104104, loss_s1: 0.026201, loss_fp: 0.001568, loss_freq: 0.004068
[15:05:22.223] iteration 3236: loss: 0.117240, loss_s1: 0.035784, loss_fp: 0.001015, loss_freq: 0.003287
[15:05:22.853] iteration 3237: loss: 0.182953, loss_s1: 0.059845, loss_fp: 0.001424, loss_freq: 0.004352
[15:05:23.480] iteration 3238: loss: 0.132745, loss_s1: 0.022071, loss_fp: 0.001760, loss_freq: 0.029242
[15:05:24.109] iteration 3239: loss: 0.178077, loss_s1: 0.017552, loss_fp: 0.000755, loss_freq: 0.005403
[15:05:24.756] iteration 3240: loss: 0.097324, loss_s1: 0.013654, loss_fp: 0.000634, loss_freq: 0.005910
[15:05:25.380] iteration 3241: loss: 0.201311, loss_s1: 0.160648, loss_fp: 0.002146, loss_freq: 0.036314
[15:05:26.007] iteration 3242: loss: 0.153469, loss_s1: 0.083845, loss_fp: 0.000919, loss_freq: 0.020122
[15:05:26.630] iteration 3243: loss: 0.246545, loss_s1: 0.023678, loss_fp: 0.000703, loss_freq: 0.095670
[15:05:27.258] iteration 3244: loss: 0.394994, loss_s1: 0.151452, loss_fp: 0.003512, loss_freq: 0.486651
[15:05:27.880] iteration 3245: loss: 0.120297, loss_s1: 0.087361, loss_fp: 0.000464, loss_freq: 0.001392
[15:05:28.572] iteration 3246: loss: 0.105998, loss_s1: 0.029737, loss_fp: 0.001284, loss_freq: 0.042464
[15:05:29.207] iteration 3247: loss: 0.150840, loss_s1: 0.054437, loss_fp: 0.000521, loss_freq: 0.003791
[15:05:29.843] iteration 3248: loss: 0.240959, loss_s1: 0.049102, loss_fp: 0.003697, loss_freq: 0.133029
[15:05:30.477] iteration 3249: loss: 0.155240, loss_s1: 0.025234, loss_fp: 0.000438, loss_freq: 0.023932
[15:05:31.106] iteration 3250: loss: 0.162308, loss_s1: 0.054894, loss_fp: 0.000713, loss_freq: 0.025589
[15:05:31.734] iteration 3251: loss: 0.102759, loss_s1: 0.004435, loss_fp: 0.000840, loss_freq: 0.019963
[15:05:32.366] iteration 3252: loss: 0.154044, loss_s1: 0.027334, loss_fp: 0.000722, loss_freq: 0.003969
[15:05:33.002] iteration 3253: loss: 0.137190, loss_s1: 0.078063, loss_fp: 0.000999, loss_freq: 0.035579
[15:05:33.625] iteration 3254: loss: 0.102575, loss_s1: 0.036330, loss_fp: 0.000783, loss_freq: 0.007705
[15:05:34.249] iteration 3255: loss: 0.205193, loss_s1: 0.047921, loss_fp: 0.001200, loss_freq: 0.013375
[15:05:34.870] iteration 3256: loss: 0.170869, loss_s1: 0.027388, loss_fp: 0.001237, loss_freq: 0.005105
[15:05:35.490] iteration 3257: loss: 0.210944, loss_s1: 0.078807, loss_fp: 0.000841, loss_freq: 0.008274
[15:05:36.117] iteration 3258: loss: 0.203943, loss_s1: 0.135585, loss_fp: 0.000970, loss_freq: 0.089849
[15:05:36.744] iteration 3259: loss: 0.128365, loss_s1: 0.072780, loss_fp: 0.000452, loss_freq: 0.005861
[15:05:37.366] iteration 3260: loss: 0.185141, loss_s1: 0.040470, loss_fp: 0.000639, loss_freq: 0.032473
[15:05:37.987] iteration 3261: loss: 0.139755, loss_s1: 0.033619, loss_fp: 0.000637, loss_freq: 0.032174
[15:05:38.651] iteration 3262: loss: 0.113328, loss_s1: 0.051852, loss_fp: 0.000607, loss_freq: 0.000724
[15:05:39.318] iteration 3263: loss: 0.115350, loss_s1: 0.017681, loss_fp: 0.000562, loss_freq: 0.024583
[15:05:40.096] iteration 3264: loss: 0.113880, loss_s1: 0.053281, loss_fp: 0.001417, loss_freq: 0.029500
[15:05:40.794] iteration 3265: loss: 0.178715, loss_s1: 0.103013, loss_fp: 0.000659, loss_freq: 0.021213
[15:05:41.420] iteration 3266: loss: 0.157440, loss_s1: 0.032518, loss_fp: 0.000514, loss_freq: 0.002228
[15:05:42.039] iteration 3267: loss: 0.114688, loss_s1: 0.044851, loss_fp: 0.001022, loss_freq: 0.003745
[15:05:42.661] iteration 3268: loss: 0.137979, loss_s1: 0.095006, loss_fp: 0.001879, loss_freq: 0.007523
[15:05:43.300] iteration 3269: loss: 0.215105, loss_s1: 0.141429, loss_fp: 0.000888, loss_freq: 0.005404
[15:05:43.927] iteration 3270: loss: 0.096444, loss_s1: 0.010305, loss_fp: 0.000879, loss_freq: 0.006190
[15:05:44.552] iteration 3271: loss: 0.059144, loss_s1: 0.028771, loss_fp: 0.001464, loss_freq: 0.002811
[15:05:45.177] iteration 3272: loss: 0.216758, loss_s1: 0.038908, loss_fp: 0.000735, loss_freq: 0.014034
[15:05:45.797] iteration 3273: loss: 0.138677, loss_s1: 0.058025, loss_fp: 0.000418, loss_freq: 0.038761
[15:05:46.421] iteration 3274: loss: 0.192338, loss_s1: 0.043433, loss_fp: 0.000539, loss_freq: 0.016681
[15:05:47.044] iteration 3275: loss: 0.127345, loss_s1: 0.040945, loss_fp: 0.000614, loss_freq: 0.006232
[15:05:47.671] iteration 3276: loss: 0.575876, loss_s1: 0.441386, loss_fp: 0.048587, loss_freq: 0.433161
[15:05:48.298] iteration 3277: loss: 0.184577, loss_s1: 0.043857, loss_fp: 0.000507, loss_freq: 0.008889
[15:05:48.916] iteration 3278: loss: 0.226073, loss_s1: 0.022247, loss_fp: 0.004145, loss_freq: 0.013633
[15:05:49.539] iteration 3279: loss: 0.163723, loss_s1: 0.078664, loss_fp: 0.000661, loss_freq: 0.034595
[15:05:50.164] iteration 3280: loss: 0.077910, loss_s1: 0.039162, loss_fp: 0.000521, loss_freq: 0.001642
[15:05:50.785] iteration 3281: loss: 0.084070, loss_s1: 0.030969, loss_fp: 0.000702, loss_freq: 0.014679
[15:05:51.416] iteration 3282: loss: 0.170208, loss_s1: 0.119235, loss_fp: 0.000471, loss_freq: 0.006676
[15:05:52.037] iteration 3283: loss: 0.135829, loss_s1: 0.048133, loss_fp: 0.000771, loss_freq: 0.039520
[15:05:52.680] iteration 3284: loss: 0.139855, loss_s1: 0.079421, loss_fp: 0.000866, loss_freq: 0.024262
[15:05:53.311] iteration 3285: loss: 0.110262, loss_s1: 0.068407, loss_fp: 0.000658, loss_freq: 0.006104
[15:05:53.936] iteration 3286: loss: 0.107524, loss_s1: 0.045431, loss_fp: 0.001037, loss_freq: 0.001786
[15:05:54.565] iteration 3287: loss: 0.245262, loss_s1: 0.028481, loss_fp: 0.000842, loss_freq: 0.096253
[15:05:55.216] iteration 3288: loss: 0.094148, loss_s1: 0.048710, loss_fp: 0.000507, loss_freq: 0.016537
[15:05:55.848] iteration 3289: loss: 0.101430, loss_s1: 0.017290, loss_fp: 0.000817, loss_freq: 0.013208
[15:05:56.482] iteration 3290: loss: 0.187955, loss_s1: 0.035429, loss_fp: 0.001129, loss_freq: 0.048729
[15:05:57.126] iteration 3291: loss: 0.201995, loss_s1: 0.145518, loss_fp: 0.000488, loss_freq: 0.062583
[15:05:57.753] iteration 3292: loss: 0.169752, loss_s1: 0.038350, loss_fp: 0.047593, loss_freq: 0.066174
[15:05:58.375] iteration 3293: loss: 0.144187, loss_s1: 0.051457, loss_fp: 0.000776, loss_freq: 0.006528
[15:05:59.004] iteration 3294: loss: 0.138820, loss_s1: 0.018273, loss_fp: 0.001025, loss_freq: 0.014432
[15:05:59.623] iteration 3295: loss: 0.189932, loss_s1: 0.085255, loss_fp: 0.000701, loss_freq: 0.010068
[15:06:00.252] iteration 3296: loss: 0.175226, loss_s1: 0.047336, loss_fp: 0.000675, loss_freq: 0.005707
[15:06:00.877] iteration 3297: loss: 0.158877, loss_s1: 0.025324, loss_fp: 0.000433, loss_freq: 0.103932
[15:06:01.502] iteration 3298: loss: 0.243582, loss_s1: 0.143514, loss_fp: 0.001838, loss_freq: 0.190660
[15:06:02.123] iteration 3299: loss: 0.117706, loss_s1: 0.014978, loss_fp: 0.001377, loss_freq: 0.005842
[15:06:02.750] iteration 3300: loss: 0.143209, loss_s1: 0.086118, loss_fp: 0.000695, loss_freq: 0.023701
[15:06:03.374] iteration 3301: loss: 0.154058, loss_s1: 0.079875, loss_fp: 0.000505, loss_freq: 0.007589
[15:06:03.997] iteration 3302: loss: 0.188235, loss_s1: 0.089774, loss_fp: 0.000989, loss_freq: 0.012427
[15:06:04.620] iteration 3303: loss: 0.205127, loss_s1: 0.191288, loss_fp: 0.000589, loss_freq: 0.080348
[15:06:05.239] iteration 3304: loss: 0.173936, loss_s1: 0.011856, loss_fp: 0.003077, loss_freq: 0.003496
[15:06:05.871] iteration 3305: loss: 0.132329, loss_s1: 0.061843, loss_fp: 0.000472, loss_freq: 0.028087
[15:06:06.498] iteration 3306: loss: 0.116841, loss_s1: 0.080944, loss_fp: 0.000700, loss_freq: 0.001767
[15:06:07.125] iteration 3307: loss: 0.262063, loss_s1: 0.059840, loss_fp: 0.000527, loss_freq: 0.017420
[15:06:07.751] iteration 3308: loss: 0.150264, loss_s1: 0.075895, loss_fp: 0.001629, loss_freq: 0.038280
[15:06:08.373] iteration 3309: loss: 0.147560, loss_s1: 0.040107, loss_fp: 0.000506, loss_freq: 0.017565
[15:06:08.999] iteration 3310: loss: 0.115718, loss_s1: 0.023647, loss_fp: 0.003504, loss_freq: 0.006399
[15:06:09.626] iteration 3311: loss: 0.150061, loss_s1: 0.028494, loss_fp: 0.000574, loss_freq: 0.011804
[15:06:10.251] iteration 3312: loss: 0.172564, loss_s1: 0.081662, loss_fp: 0.000547, loss_freq: 0.012420
[15:06:10.875] iteration 3313: loss: 0.208847, loss_s1: 0.023465, loss_fp: 0.000616, loss_freq: 0.003639
[15:06:11.505] iteration 3314: loss: 0.116831, loss_s1: 0.022272, loss_fp: 0.000415, loss_freq: 0.001930
[15:06:12.153] iteration 3315: loss: 0.114814, loss_s1: 0.045261, loss_fp: 0.000496, loss_freq: 0.058869
[15:06:12.779] iteration 3316: loss: 0.070448, loss_s1: 0.015439, loss_fp: 0.000761, loss_freq: 0.004367
[15:06:13.421] iteration 3317: loss: 0.092432, loss_s1: 0.002039, loss_fp: 0.000466, loss_freq: 0.002123
[15:06:14.044] iteration 3318: loss: 0.145380, loss_s1: 0.030785, loss_fp: 0.002302, loss_freq: 0.022277
[15:06:14.669] iteration 3319: loss: 0.115407, loss_s1: 0.007381, loss_fp: 0.000597, loss_freq: 0.000999
[15:06:15.291] iteration 3320: loss: 0.109636, loss_s1: 0.042619, loss_fp: 0.000945, loss_freq: 0.008550
[15:06:15.915] iteration 3321: loss: 0.119235, loss_s1: 0.033459, loss_fp: 0.000455, loss_freq: 0.033330
[15:06:16.554] iteration 3322: loss: 0.196919, loss_s1: 0.030159, loss_fp: 0.000439, loss_freq: 0.008517
[15:06:17.174] iteration 3323: loss: 0.311459, loss_s1: 0.206453, loss_fp: 0.000819, loss_freq: 0.142595
[15:06:17.798] iteration 3324: loss: 0.126054, loss_s1: 0.092302, loss_fp: 0.007891, loss_freq: 0.002530
[15:06:18.422] iteration 3325: loss: 0.185548, loss_s1: 0.030798, loss_fp: 0.000456, loss_freq: 0.032716
[15:06:19.044] iteration 3326: loss: 0.159349, loss_s1: 0.053599, loss_fp: 0.001080, loss_freq: 0.026525
[15:06:19.665] iteration 3327: loss: 0.169921, loss_s1: 0.104925, loss_fp: 0.000725, loss_freq: 0.004280
[15:06:20.284] iteration 3328: loss: 0.171398, loss_s1: 0.064642, loss_fp: 0.001568, loss_freq: 0.072659
[15:06:20.918] iteration 3329: loss: 0.361864, loss_s1: 0.142803, loss_fp: 0.000955, loss_freq: 0.318385
[15:06:21.552] iteration 3330: loss: 0.143255, loss_s1: 0.013613, loss_fp: 0.000450, loss_freq: 0.006127
[15:06:22.190] iteration 3331: loss: 0.167358, loss_s1: 0.014643, loss_fp: 0.000519, loss_freq: 0.052059
[15:06:22.813] iteration 3332: loss: 0.091224, loss_s1: 0.016835, loss_fp: 0.000959, loss_freq: 0.000811
[15:06:23.437] iteration 3333: loss: 0.145682, loss_s1: 0.111169, loss_fp: 0.000994, loss_freq: 0.024582
[15:06:24.060] iteration 3334: loss: 0.113317, loss_s1: 0.087159, loss_fp: 0.000889, loss_freq: 0.006566
[15:06:24.683] iteration 3335: loss: 0.157222, loss_s1: 0.039100, loss_fp: 0.001152, loss_freq: 0.033177
[15:06:25.306] iteration 3336: loss: 0.207255, loss_s1: 0.101759, loss_fp: 0.000737, loss_freq: 0.011667
[15:06:25.928] iteration 3337: loss: 0.166965, loss_s1: 0.031212, loss_fp: 0.002413, loss_freq: 0.097560
[15:06:26.550] iteration 3338: loss: 0.102691, loss_s1: 0.066274, loss_fp: 0.000552, loss_freq: 0.037204
[15:06:27.177] iteration 3339: loss: 0.266038, loss_s1: 0.065372, loss_fp: 0.000826, loss_freq: 0.157690
[15:06:27.801] iteration 3340: loss: 0.181531, loss_s1: 0.085299, loss_fp: 0.001402, loss_freq: 0.139992
[15:06:28.426] iteration 3341: loss: 0.078994, loss_s1: 0.030850, loss_fp: 0.000609, loss_freq: 0.002444
[15:06:29.058] iteration 3342: loss: 0.221428, loss_s1: 0.060555, loss_fp: 0.000443, loss_freq: 0.025308
[15:06:29.695] iteration 3343: loss: 0.264468, loss_s1: 0.255096, loss_fp: 0.023086, loss_freq: 0.061451
[15:06:30.336] iteration 3344: loss: 0.198204, loss_s1: 0.072374, loss_fp: 0.000567, loss_freq: 0.005583
[15:06:30.972] iteration 3345: loss: 0.168669, loss_s1: 0.048970, loss_fp: 0.001066, loss_freq: 0.038676
[15:06:31.610] iteration 3346: loss: 0.162379, loss_s1: 0.031081, loss_fp: 0.000864, loss_freq: 0.039794
[15:06:32.264] iteration 3347: loss: 0.193055, loss_s1: 0.054867, loss_fp: 0.004036, loss_freq: 0.003822
[15:06:32.892] iteration 3348: loss: 0.189292, loss_s1: 0.040872, loss_fp: 0.001438, loss_freq: 0.010118
[15:06:33.518] iteration 3349: loss: 0.167394, loss_s1: 0.091594, loss_fp: 0.000488, loss_freq: 0.033749
[15:06:34.142] iteration 3350: loss: 0.136217, loss_s1: 0.086565, loss_fp: 0.000519, loss_freq: 0.003640
[15:06:34.762] iteration 3351: loss: 0.166547, loss_s1: 0.211586, loss_fp: 0.000566, loss_freq: 0.029848
[15:06:35.386] iteration 3352: loss: 0.103720, loss_s1: 0.002249, loss_fp: 0.000384, loss_freq: 0.002381
[15:06:36.012] iteration 3353: loss: 0.188082, loss_s1: 0.071797, loss_fp: 0.000949, loss_freq: 0.046934
[15:06:36.647] iteration 3354: loss: 0.098302, loss_s1: 0.003443, loss_fp: 0.000683, loss_freq: 0.003572
[15:06:37.277] iteration 3355: loss: 0.157446, loss_s1: 0.058250, loss_fp: 0.001964, loss_freq: 0.020755
[15:06:37.898] iteration 3356: loss: 0.104001, loss_s1: 0.030125, loss_fp: 0.002150, loss_freq: 0.057437
[15:06:38.521] iteration 3357: loss: 0.130432, loss_s1: 0.033275, loss_fp: 0.003544, loss_freq: 0.001620
[15:06:39.147] iteration 3358: loss: 0.149869, loss_s1: 0.058096, loss_fp: 0.000625, loss_freq: 0.024764
[15:06:39.766] iteration 3359: loss: 0.137056, loss_s1: 0.023856, loss_fp: 0.000520, loss_freq: 0.091781
[15:06:40.382] iteration 3360: loss: 0.220416, loss_s1: 0.064972, loss_fp: 0.001215, loss_freq: 0.031133
[15:06:40.999] iteration 3361: loss: 0.182463, loss_s1: 0.051188, loss_fp: 0.005576, loss_freq: 0.086366
[15:06:41.619] iteration 3362: loss: 0.125443, loss_s1: 0.024803, loss_fp: 0.000686, loss_freq: 0.007491
[15:06:42.240] iteration 3363: loss: 0.139691, loss_s1: 0.042572, loss_fp: 0.000958, loss_freq: 0.004944
[15:06:42.861] iteration 3364: loss: 0.127784, loss_s1: 0.024963, loss_fp: 0.010850, loss_freq: 0.010147
[15:06:43.482] iteration 3365: loss: 0.151152, loss_s1: 0.039180, loss_fp: 0.001225, loss_freq: 0.007308
[15:06:44.110] iteration 3366: loss: 0.131147, loss_s1: 0.039600, loss_fp: 0.002545, loss_freq: 0.002257
[15:06:44.738] iteration 3367: loss: 0.089696, loss_s1: 0.029933, loss_fp: 0.000558, loss_freq: 0.012693
[15:06:45.362] iteration 3368: loss: 0.139848, loss_s1: 0.046290, loss_fp: 0.000653, loss_freq: 0.073937
[15:06:45.988] iteration 3369: loss: 0.100118, loss_s1: 0.014870, loss_fp: 0.000525, loss_freq: 0.006294
[15:06:46.613] iteration 3370: loss: 0.137861, loss_s1: 0.116909, loss_fp: 0.000308, loss_freq: 0.005684
[15:06:47.236] iteration 3371: loss: 0.198033, loss_s1: 0.108261, loss_fp: 0.000892, loss_freq: 0.005332
[15:06:47.868] iteration 3372: loss: 0.132859, loss_s1: 0.008579, loss_fp: 0.000901, loss_freq: 0.062418
[15:06:48.518] iteration 3373: loss: 0.090987, loss_s1: 0.039418, loss_fp: 0.000473, loss_freq: 0.001072
[15:06:49.143] iteration 3374: loss: 0.158215, loss_s1: 0.018817, loss_fp: 0.000816, loss_freq: 0.002429
[15:06:49.766] iteration 3375: loss: 0.123009, loss_s1: 0.045506, loss_fp: 0.000966, loss_freq: 0.033263
[15:06:50.396] iteration 3376: loss: 0.080962, loss_s1: 0.027134, loss_fp: 0.000562, loss_freq: 0.013333
[15:06:51.022] iteration 3377: loss: 0.186030, loss_s1: 0.048986, loss_fp: 0.000678, loss_freq: 0.010521
[15:06:51.645] iteration 3378: loss: 0.149558, loss_s1: 0.051270, loss_fp: 0.021899, loss_freq: 0.036941
[15:06:52.271] iteration 3379: loss: 0.210971, loss_s1: 0.072759, loss_fp: 0.001211, loss_freq: 0.026430
[15:06:52.891] iteration 3380: loss: 0.111518, loss_s1: 0.049590, loss_fp: 0.000450, loss_freq: 0.016294
[15:06:53.512] iteration 3381: loss: 0.184209, loss_s1: 0.146797, loss_fp: 0.002869, loss_freq: 0.014481
[15:06:54.471] iteration 3382: loss: 0.181441, loss_s1: 0.045459, loss_fp: 0.001975, loss_freq: 0.008761
[15:06:55.127] iteration 3383: loss: 0.102805, loss_s1: 0.030083, loss_fp: 0.006777, loss_freq: 0.010010
[15:06:55.760] iteration 3384: loss: 0.119856, loss_s1: 0.058621, loss_fp: 0.000655, loss_freq: 0.009173
[15:06:56.389] iteration 3385: loss: 0.144164, loss_s1: 0.053822, loss_fp: 0.000531, loss_freq: 0.000786
[15:06:57.021] iteration 3386: loss: 0.136966, loss_s1: 0.015023, loss_fp: 0.000857, loss_freq: 0.001607
[15:06:57.653] iteration 3387: loss: 0.288464, loss_s1: 0.136090, loss_fp: 0.000847, loss_freq: 0.142405
[15:06:58.272] iteration 3388: loss: 0.072415, loss_s1: 0.004183, loss_fp: 0.001035, loss_freq: 0.006696
[15:06:58.893] iteration 3389: loss: 0.144829, loss_s1: 0.064344, loss_fp: 0.000583, loss_freq: 0.072773
[15:06:59.513] iteration 3390: loss: 0.107234, loss_s1: 0.049733, loss_fp: 0.001214, loss_freq: 0.004207
[15:07:00.137] iteration 3391: loss: 0.129272, loss_s1: 0.020869, loss_fp: 0.000495, loss_freq: 0.079315
[15:07:00.763] iteration 3392: loss: 0.128594, loss_s1: 0.040160, loss_fp: 0.001067, loss_freq: 0.002960
[15:07:01.381] iteration 3393: loss: 0.138003, loss_s1: 0.032651, loss_fp: 0.000441, loss_freq: 0.049070
[15:07:02.007] iteration 3394: loss: 0.110295, loss_s1: 0.060934, loss_fp: 0.001409, loss_freq: 0.054259
[15:07:02.631] iteration 3395: loss: 0.196890, loss_s1: 0.073768, loss_fp: 0.000657, loss_freq: 0.017359
[15:07:03.254] iteration 3396: loss: 0.115113, loss_s1: 0.028748, loss_fp: 0.001110, loss_freq: 0.026641
[15:07:03.884] iteration 3397: loss: 0.105024, loss_s1: 0.014659, loss_fp: 0.003619, loss_freq: 0.060542
[15:07:04.509] iteration 3398: loss: 0.194357, loss_s1: 0.094153, loss_fp: 0.000342, loss_freq: 0.020037
[15:07:05.133] iteration 3399: loss: 0.125282, loss_s1: 0.028194, loss_fp: 0.000562, loss_freq: 0.004148
[15:07:05.759] iteration 3400: loss: 0.178804, loss_s1: 0.067314, loss_fp: 0.001507, loss_freq: 0.026500
[15:07:08.623] iteration 3400 : mean_dice : 0.440346
[15:07:09.290] iteration 3401: loss: 0.128394, loss_s1: 0.060129, loss_fp: 0.009047, loss_freq: 0.004978
[15:07:09.955] iteration 3402: loss: 0.139120, loss_s1: 0.083788, loss_fp: 0.000547, loss_freq: 0.002525
[15:07:10.586] iteration 3403: loss: 0.224799, loss_s1: 0.168644, loss_fp: 0.002342, loss_freq: 0.034301
[15:07:11.230] iteration 3404: loss: 0.170777, loss_s1: 0.055266, loss_fp: 0.001085, loss_freq: 0.002803
[15:07:11.855] iteration 3405: loss: 0.130936, loss_s1: 0.069520, loss_fp: 0.010956, loss_freq: 0.048320
[15:07:12.473] iteration 3406: loss: 0.100969, loss_s1: 0.043409, loss_fp: 0.000636, loss_freq: 0.011159
[15:07:13.094] iteration 3407: loss: 0.112138, loss_s1: 0.030437, loss_fp: 0.000598, loss_freq: 0.041414
[15:07:13.717] iteration 3408: loss: 0.112803, loss_s1: 0.045435, loss_fp: 0.000861, loss_freq: 0.001987
[15:07:14.364] iteration 3409: loss: 0.201716, loss_s1: 0.050095, loss_fp: 0.000829, loss_freq: 0.016402
[15:07:14.993] iteration 3410: loss: 0.141718, loss_s1: 0.059610, loss_fp: 0.008924, loss_freq: 0.003869
[15:07:15.627] iteration 3411: loss: 0.145024, loss_s1: 0.095933, loss_fp: 0.001045, loss_freq: 0.007151
[15:07:16.263] iteration 3412: loss: 0.122096, loss_s1: 0.131466, loss_fp: 0.000914, loss_freq: 0.011951
[15:07:16.895] iteration 3413: loss: 0.147600, loss_s1: 0.008657, loss_fp: 0.000532, loss_freq: 0.010261
[15:07:17.521] iteration 3414: loss: 0.092509, loss_s1: 0.054605, loss_fp: 0.000551, loss_freq: 0.020454
[15:07:18.144] iteration 3415: loss: 0.077718, loss_s1: 0.049081, loss_fp: 0.000590, loss_freq: 0.004419
[15:07:18.771] iteration 3416: loss: 0.167780, loss_s1: 0.027090, loss_fp: 0.001481, loss_freq: 0.013317
[15:07:19.410] iteration 3417: loss: 0.192230, loss_s1: 0.081201, loss_fp: 0.001568, loss_freq: 0.033917
[15:07:20.035] iteration 3418: loss: 0.183995, loss_s1: 0.094279, loss_fp: 0.000681, loss_freq: 0.051787
[15:07:20.660] iteration 3419: loss: 0.112101, loss_s1: 0.029998, loss_fp: 0.000496, loss_freq: 0.053804
[15:07:21.296] iteration 3420: loss: 0.175199, loss_s1: 0.068614, loss_fp: 0.000719, loss_freq: 0.046393
[15:07:21.919] iteration 3421: loss: 0.174765, loss_s1: 0.034888, loss_fp: 0.000645, loss_freq: 0.037914
[15:07:22.548] iteration 3422: loss: 0.204703, loss_s1: 0.092042, loss_fp: 0.000457, loss_freq: 0.009737
[15:07:23.177] iteration 3423: loss: 0.093691, loss_s1: 0.041389, loss_fp: 0.000891, loss_freq: 0.008491
[15:07:23.799] iteration 3424: loss: 0.143786, loss_s1: 0.105804, loss_fp: 0.000544, loss_freq: 0.045044
[15:07:24.425] iteration 3425: loss: 0.158294, loss_s1: 0.148564, loss_fp: 0.001926, loss_freq: 0.030004
[15:07:25.046] iteration 3426: loss: 0.118852, loss_s1: 0.058522, loss_fp: 0.000560, loss_freq: 0.017078
[15:07:25.666] iteration 3427: loss: 0.121892, loss_s1: 0.007761, loss_fp: 0.000881, loss_freq: 0.044632
[15:07:26.296] iteration 3428: loss: 0.101423, loss_s1: 0.026960, loss_fp: 0.000669, loss_freq: 0.047192
[15:07:26.922] iteration 3429: loss: 0.111009, loss_s1: 0.075388, loss_fp: 0.009283, loss_freq: 0.009711
[15:07:27.549] iteration 3430: loss: 0.200203, loss_s1: 0.095600, loss_fp: 0.000668, loss_freq: 0.012890
[15:07:28.179] iteration 3431: loss: 0.099317, loss_s1: 0.040786, loss_fp: 0.000655, loss_freq: 0.020265
[15:07:28.804] iteration 3432: loss: 0.067828, loss_s1: 0.044703, loss_fp: 0.000797, loss_freq: 0.001390
[15:07:29.438] iteration 3433: loss: 0.203776, loss_s1: 0.035234, loss_fp: 0.000993, loss_freq: 0.032746
[15:07:30.071] iteration 3434: loss: 0.142016, loss_s1: 0.075410, loss_fp: 0.000588, loss_freq: 0.028286
[15:07:30.696] iteration 3435: loss: 0.250544, loss_s1: 0.124852, loss_fp: 0.001591, loss_freq: 0.102657
[15:07:31.318] iteration 3436: loss: 0.136622, loss_s1: 0.032867, loss_fp: 0.000508, loss_freq: 0.012829
[15:07:31.938] iteration 3437: loss: 0.858837, loss_s1: 0.502677, loss_fp: 0.500004, loss_freq: 0.502253
[15:07:32.564] iteration 3438: loss: 0.167076, loss_s1: 0.033140, loss_fp: 0.000717, loss_freq: 0.027923
[15:07:33.186] iteration 3439: loss: 0.169054, loss_s1: 0.022513, loss_fp: 0.000481, loss_freq: 0.001873
[15:07:33.813] iteration 3440: loss: 0.124214, loss_s1: 0.058828, loss_fp: 0.000879, loss_freq: 0.023556
[15:07:34.437] iteration 3441: loss: 0.081853, loss_s1: 0.030562, loss_fp: 0.001088, loss_freq: 0.015618
[15:07:35.067] iteration 3442: loss: 0.105959, loss_s1: 0.030669, loss_fp: 0.000421, loss_freq: 0.051840
[15:07:35.695] iteration 3443: loss: 0.087283, loss_s1: 0.015028, loss_fp: 0.000635, loss_freq: 0.028701
[15:07:36.322] iteration 3444: loss: 0.137794, loss_s1: 0.076242, loss_fp: 0.001474, loss_freq: 0.025146
[15:07:36.943] iteration 3445: loss: 0.266061, loss_s1: 0.177658, loss_fp: 0.000741, loss_freq: 0.019925
[15:07:37.570] iteration 3446: loss: 0.112187, loss_s1: 0.037191, loss_fp: 0.000592, loss_freq: 0.008740
[15:07:38.195] iteration 3447: loss: 0.176774, loss_s1: 0.164006, loss_fp: 0.000484, loss_freq: 0.006405
[15:07:38.817] iteration 3448: loss: 0.261663, loss_s1: 0.117435, loss_fp: 0.000773, loss_freq: 0.118901
[15:07:39.442] iteration 3449: loss: 0.113601, loss_s1: 0.078861, loss_fp: 0.002511, loss_freq: 0.004991
[15:07:40.089] iteration 3450: loss: 0.131033, loss_s1: 0.067213, loss_fp: 0.001747, loss_freq: 0.023257
[15:07:40.722] iteration 3451: loss: 0.233368, loss_s1: 0.088873, loss_fp: 0.000550, loss_freq: 0.073643
[15:07:41.352] iteration 3452: loss: 0.165157, loss_s1: 0.074621, loss_fp: 0.002457, loss_freq: 0.028911
[15:07:41.981] iteration 3453: loss: 0.143905, loss_s1: 0.062181, loss_fp: 0.006470, loss_freq: 0.026012
[15:07:42.608] iteration 3454: loss: 0.099643, loss_s1: 0.009995, loss_fp: 0.000366, loss_freq: 0.025019
[15:07:43.230] iteration 3455: loss: 0.146246, loss_s1: 0.090622, loss_fp: 0.000551, loss_freq: 0.013653
[15:07:43.852] iteration 3456: loss: 0.196933, loss_s1: 0.099168, loss_fp: 0.006957, loss_freq: 0.068039
[15:07:44.476] iteration 3457: loss: 0.159694, loss_s1: 0.069335, loss_fp: 0.000792, loss_freq: 0.004579
[15:07:45.102] iteration 3458: loss: 0.126968, loss_s1: 0.016449, loss_fp: 0.001318, loss_freq: 0.045128
[15:07:45.736] iteration 3459: loss: 0.185462, loss_s1: 0.166839, loss_fp: 0.000774, loss_freq: 0.071119
[15:07:46.478] iteration 3460: loss: 0.104218, loss_s1: 0.038915, loss_fp: 0.000801, loss_freq: 0.020339
[15:07:47.136] iteration 3461: loss: 0.190152, loss_s1: 0.082746, loss_fp: 0.010688, loss_freq: 0.072858
[15:07:47.759] iteration 3462: loss: 0.136823, loss_s1: 0.057953, loss_fp: 0.000630, loss_freq: 0.025937
[15:07:48.387] iteration 3463: loss: 0.137474, loss_s1: 0.071384, loss_fp: 0.001079, loss_freq: 0.005919
[15:07:49.012] iteration 3464: loss: 0.158646, loss_s1: 0.121799, loss_fp: 0.024874, loss_freq: 0.024545
[15:07:49.639] iteration 3465: loss: 0.172446, loss_s1: 0.030039, loss_fp: 0.000725, loss_freq: 0.034602
[15:07:50.262] iteration 3466: loss: 0.126683, loss_s1: 0.106205, loss_fp: 0.000752, loss_freq: 0.006864
[15:07:50.893] iteration 3467: loss: 0.065345, loss_s1: 0.002727, loss_fp: 0.001808, loss_freq: 0.019123
[15:07:51.516] iteration 3468: loss: 0.266074, loss_s1: 0.135820, loss_fp: 0.000471, loss_freq: 0.008216
[15:07:52.136] iteration 3469: loss: 0.136170, loss_s1: 0.080573, loss_fp: 0.000952, loss_freq: 0.040331
[15:07:52.762] iteration 3470: loss: 0.150846, loss_s1: 0.112902, loss_fp: 0.000565, loss_freq: 0.011776
[15:07:53.383] iteration 3471: loss: 0.134670, loss_s1: 0.091332, loss_fp: 0.000421, loss_freq: 0.011125
[15:07:54.009] iteration 3472: loss: 0.202273, loss_s1: 0.043329, loss_fp: 0.001351, loss_freq: 0.021688
[15:07:54.630] iteration 3473: loss: 0.174400, loss_s1: 0.109020, loss_fp: 0.000450, loss_freq: 0.007071
[15:07:55.251] iteration 3474: loss: 0.210503, loss_s1: 0.027318, loss_fp: 0.000626, loss_freq: 0.000579
[15:07:55.875] iteration 3475: loss: 0.181529, loss_s1: 0.091887, loss_fp: 0.000518, loss_freq: 0.059671
[15:07:56.496] iteration 3476: loss: 0.100256, loss_s1: 0.049351, loss_fp: 0.000555, loss_freq: 0.020097
[15:07:57.116] iteration 3477: loss: 0.079556, loss_s1: 0.025128, loss_fp: 0.001000, loss_freq: 0.009278
[15:07:57.736] iteration 3478: loss: 0.103692, loss_s1: 0.037851, loss_fp: 0.001047, loss_freq: 0.001024
[15:07:58.358] iteration 3479: loss: 0.142072, loss_s1: 0.038441, loss_fp: 0.000678, loss_freq: 0.020100
[15:07:58.982] iteration 3480: loss: 0.153892, loss_s1: 0.007368, loss_fp: 0.000298, loss_freq: 0.001775
[15:07:59.603] iteration 3481: loss: 0.099593, loss_s1: 0.027789, loss_fp: 0.001127, loss_freq: 0.046480
[15:08:00.234] iteration 3482: loss: 0.114562, loss_s1: 0.009825, loss_fp: 0.000682, loss_freq: 0.044261
[15:08:00.862] iteration 3483: loss: 0.124381, loss_s1: 0.036659, loss_fp: 0.000944, loss_freq: 0.004651
[15:08:01.492] iteration 3484: loss: 0.193439, loss_s1: 0.054594, loss_fp: 0.001439, loss_freq: 0.136962
[15:08:02.115] iteration 3485: loss: 0.138811, loss_s1: 0.003146, loss_fp: 0.029244, loss_freq: 0.002262
[15:08:02.739] iteration 3486: loss: 0.195251, loss_s1: 0.089018, loss_fp: 0.001615, loss_freq: 0.014803
[15:08:03.366] iteration 3487: loss: 0.172104, loss_s1: 0.072815, loss_fp: 0.000766, loss_freq: 0.017820
[15:08:03.992] iteration 3488: loss: 0.150014, loss_s1: 0.051032, loss_fp: 0.001290, loss_freq: 0.011339
[15:08:04.653] iteration 3489: loss: 0.243479, loss_s1: 0.175380, loss_fp: 0.000745, loss_freq: 0.090620
[15:08:05.277] iteration 3490: loss: 0.314773, loss_s1: 0.107740, loss_fp: 0.001198, loss_freq: 0.291840
[15:08:05.904] iteration 3491: loss: 0.163771, loss_s1: 0.040369, loss_fp: 0.001119, loss_freq: 0.049075
[15:08:06.529] iteration 3492: loss: 0.161668, loss_s1: 0.022221, loss_fp: 0.000659, loss_freq: 0.001594
[15:08:07.151] iteration 3493: loss: 0.107199, loss_s1: 0.050027, loss_fp: 0.003185, loss_freq: 0.036971
[15:08:07.772] iteration 3494: loss: 0.162298, loss_s1: 0.119366, loss_fp: 0.000550, loss_freq: 0.030603
[15:08:08.392] iteration 3495: loss: 0.079826, loss_s1: 0.039227, loss_fp: 0.000976, loss_freq: 0.007661
[15:08:09.012] iteration 3496: loss: 0.162210, loss_s1: 0.160834, loss_fp: 0.000708, loss_freq: 0.006814
[15:08:09.630] iteration 3497: loss: 0.104891, loss_s1: 0.020263, loss_fp: 0.000973, loss_freq: 0.007900
[15:08:10.248] iteration 3498: loss: 0.154752, loss_s1: 0.060275, loss_fp: 0.000804, loss_freq: 0.060010
[15:08:10.866] iteration 3499: loss: 0.131076, loss_s1: 0.068565, loss_fp: 0.001199, loss_freq: 0.090696
[15:08:11.487] iteration 3500: loss: 0.257308, loss_s1: 0.055941, loss_fp: 0.001449, loss_freq: 0.148315
[15:08:12.114] iteration 3501: loss: 0.291157, loss_s1: 0.235055, loss_fp: 0.001936, loss_freq: 0.216950
[15:08:12.742] iteration 3502: loss: 0.122172, loss_s1: 0.119205, loss_fp: 0.002638, loss_freq: 0.017071
[15:08:13.365] iteration 3503: loss: 0.204660, loss_s1: 0.023107, loss_fp: 0.000569, loss_freq: 0.032020
[15:08:13.987] iteration 3504: loss: 0.206355, loss_s1: 0.137808, loss_fp: 0.002184, loss_freq: 0.057396
[15:08:14.614] iteration 3505: loss: 0.266324, loss_s1: 0.154516, loss_fp: 0.000690, loss_freq: 0.063096
[15:08:15.238] iteration 3506: loss: 0.154053, loss_s1: 0.038335, loss_fp: 0.000942, loss_freq: 0.025178
[15:08:15.856] iteration 3507: loss: 0.209845, loss_s1: 0.054189, loss_fp: 0.005708, loss_freq: 0.034994
[15:08:16.478] iteration 3508: loss: 0.162518, loss_s1: 0.078406, loss_fp: 0.001084, loss_freq: 0.008215
[15:08:17.100] iteration 3509: loss: 0.201048, loss_s1: 0.079186, loss_fp: 0.000796, loss_freq: 0.029685
[15:08:17.729] iteration 3510: loss: 0.116550, loss_s1: 0.069436, loss_fp: 0.005346, loss_freq: 0.010719
[15:08:18.348] iteration 3511: loss: 0.132535, loss_s1: 0.075240, loss_fp: 0.000865, loss_freq: 0.037462
[15:08:18.969] iteration 3512: loss: 0.228100, loss_s1: 0.206586, loss_fp: 0.003685, loss_freq: 0.123338
[15:08:19.601] iteration 3513: loss: 0.132652, loss_s1: 0.043341, loss_fp: 0.001455, loss_freq: 0.057769
[15:08:20.221] iteration 3514: loss: 0.196864, loss_s1: 0.069265, loss_fp: 0.001048, loss_freq: 0.082657
[15:08:20.842] iteration 3515: loss: 0.107600, loss_s1: 0.018170, loss_fp: 0.001244, loss_freq: 0.013392
[15:08:21.467] iteration 3516: loss: 0.120396, loss_s1: 0.044794, loss_fp: 0.001595, loss_freq: 0.022058
[15:08:22.093] iteration 3517: loss: 0.187237, loss_s1: 0.080450, loss_fp: 0.001174, loss_freq: 0.158804
[15:08:22.720] iteration 3518: loss: 0.157274, loss_s1: 0.035134, loss_fp: 0.002428, loss_freq: 0.037750
[15:08:23.345] iteration 3519: loss: 0.115184, loss_s1: 0.056651, loss_fp: 0.000673, loss_freq: 0.047047
[15:08:23.970] iteration 3520: loss: 0.157048, loss_s1: 0.099172, loss_fp: 0.001749, loss_freq: 0.059192
[15:08:24.592] iteration 3521: loss: 0.147786, loss_s1: 0.045201, loss_fp: 0.000626, loss_freq: 0.036900
[15:08:25.212] iteration 3522: loss: 0.187674, loss_s1: 0.013051, loss_fp: 0.022618, loss_freq: 0.014477
[15:08:25.836] iteration 3523: loss: 0.120093, loss_s1: 0.051203, loss_fp: 0.000920, loss_freq: 0.012242
[15:08:26.461] iteration 3524: loss: 0.142757, loss_s1: 0.083511, loss_fp: 0.000833, loss_freq: 0.001327
[15:08:27.087] iteration 3525: loss: 0.202375, loss_s1: 0.182853, loss_fp: 0.003121, loss_freq: 0.009001
[15:08:27.707] iteration 3526: loss: 0.164312, loss_s1: 0.039887, loss_fp: 0.000540, loss_freq: 0.004635
[15:08:28.331] iteration 3527: loss: 0.177034, loss_s1: 0.014429, loss_fp: 0.000774, loss_freq: 0.027240
[15:08:28.953] iteration 3528: loss: 0.121512, loss_s1: 0.040186, loss_fp: 0.001148, loss_freq: 0.049421
[15:08:29.572] iteration 3529: loss: 0.104415, loss_s1: 0.028595, loss_fp: 0.000560, loss_freq: 0.038851
[15:08:30.192] iteration 3530: loss: 0.130661, loss_s1: 0.034183, loss_fp: 0.000525, loss_freq: 0.010448
[15:08:30.818] iteration 3531: loss: 0.206304, loss_s1: 0.148254, loss_fp: 0.000576, loss_freq: 0.013650
[15:08:31.440] iteration 3532: loss: 0.210380, loss_s1: 0.050488, loss_fp: 0.000694, loss_freq: 0.061319
[15:08:32.063] iteration 3533: loss: 0.162112, loss_s1: 0.074795, loss_fp: 0.001916, loss_freq: 0.069591
[15:08:32.685] iteration 3534: loss: 0.113196, loss_s1: 0.061115, loss_fp: 0.001377, loss_freq: 0.022553
[15:08:33.308] iteration 3535: loss: 0.184273, loss_s1: 0.069731, loss_fp: 0.001664, loss_freq: 0.023930
[15:08:33.931] iteration 3536: loss: 0.120365, loss_s1: 0.084296, loss_fp: 0.001445, loss_freq: 0.012543
[15:08:34.556] iteration 3537: loss: 0.132100, loss_s1: 0.073880, loss_fp: 0.001784, loss_freq: 0.038723
[15:08:35.177] iteration 3538: loss: 0.197760, loss_s1: 0.101824, loss_fp: 0.001963, loss_freq: 0.020334
[15:08:35.799] iteration 3539: loss: 0.282548, loss_s1: 0.257974, loss_fp: 0.000924, loss_freq: 0.066621
[15:08:36.419] iteration 3540: loss: 0.134295, loss_s1: 0.046308, loss_fp: 0.000583, loss_freq: 0.011931
[15:08:37.048] iteration 3541: loss: 0.116384, loss_s1: 0.027656, loss_fp: 0.000636, loss_freq: 0.030225
[15:08:37.670] iteration 3542: loss: 0.116862, loss_s1: 0.084314, loss_fp: 0.000586, loss_freq: 0.003794
[15:08:38.612] iteration 3543: loss: 0.112237, loss_s1: 0.040539, loss_fp: 0.000439, loss_freq: 0.004449
[15:08:39.237] iteration 3544: loss: 0.183694, loss_s1: 0.072079, loss_fp: 0.000576, loss_freq: 0.116484
[15:08:39.862] iteration 3545: loss: 0.167634, loss_s1: 0.085467, loss_fp: 0.000621, loss_freq: 0.056074
[15:08:40.489] iteration 3546: loss: 0.143055, loss_s1: 0.048859, loss_fp: 0.000999, loss_freq: 0.001504
[15:08:41.115] iteration 3547: loss: 0.157172, loss_s1: 0.062333, loss_fp: 0.000898, loss_freq: 0.011319
[15:08:41.734] iteration 3548: loss: 0.323218, loss_s1: 0.185757, loss_fp: 0.001110, loss_freq: 0.157786
[15:08:42.353] iteration 3549: loss: 0.101406, loss_s1: 0.077264, loss_fp: 0.003070, loss_freq: 0.015768
[15:08:42.989] iteration 3550: loss: 0.131475, loss_s1: 0.022569, loss_fp: 0.004091, loss_freq: 0.101927
[15:08:43.617] iteration 3551: loss: 0.110797, loss_s1: 0.083756, loss_fp: 0.005691, loss_freq: 0.003085
[15:08:44.238] iteration 3552: loss: 0.235437, loss_s1: 0.131265, loss_fp: 0.000552, loss_freq: 0.123479
[15:08:44.868] iteration 3553: loss: 0.131075, loss_s1: 0.027509, loss_fp: 0.000507, loss_freq: 0.007655
[15:08:45.493] iteration 3554: loss: 0.171666, loss_s1: 0.046132, loss_fp: 0.001004, loss_freq: 0.048049
[15:08:46.116] iteration 3555: loss: 0.084862, loss_s1: 0.062940, loss_fp: 0.001333, loss_freq: 0.008163
[15:08:46.737] iteration 3556: loss: 0.163781, loss_s1: 0.053996, loss_fp: 0.001540, loss_freq: 0.013161
[15:08:47.359] iteration 3557: loss: 0.119761, loss_s1: 0.083066, loss_fp: 0.000658, loss_freq: 0.013843
[15:08:47.982] iteration 3558: loss: 0.141320, loss_s1: 0.082730, loss_fp: 0.010323, loss_freq: 0.049370
[15:08:48.604] iteration 3559: loss: 0.229828, loss_s1: 0.058185, loss_fp: 0.000585, loss_freq: 0.005446
[15:08:49.225] iteration 3560: loss: 0.096616, loss_s1: 0.043411, loss_fp: 0.000862, loss_freq: 0.018276
[15:08:49.850] iteration 3561: loss: 0.171055, loss_s1: 0.018001, loss_fp: 0.000497, loss_freq: 0.016895
[15:08:50.479] iteration 3562: loss: 0.159129, loss_s1: 0.027848, loss_fp: 0.000848, loss_freq: 0.035167
[15:08:51.107] iteration 3563: loss: 0.089091, loss_s1: 0.018468, loss_fp: 0.000544, loss_freq: 0.010376
[15:08:51.732] iteration 3564: loss: 0.209885, loss_s1: 0.081886, loss_fp: 0.001377, loss_freq: 0.050216
[15:08:52.361] iteration 3565: loss: 0.163824, loss_s1: 0.026074, loss_fp: 0.000435, loss_freq: 0.006328
[15:08:52.995] iteration 3566: loss: 0.342474, loss_s1: 0.313709, loss_fp: 0.001595, loss_freq: 0.201671
[15:08:53.618] iteration 3567: loss: 0.082595, loss_s1: 0.023584, loss_fp: 0.000949, loss_freq: 0.008614
[15:08:54.243] iteration 3568: loss: 0.114897, loss_s1: 0.040361, loss_fp: 0.001133, loss_freq: 0.038205
[15:08:54.862] iteration 3569: loss: 0.110631, loss_s1: 0.036625, loss_fp: 0.002260, loss_freq: 0.005848
[15:08:55.485] iteration 3570: loss: 0.169434, loss_s1: 0.056517, loss_fp: 0.000547, loss_freq: 0.076390
[15:08:56.112] iteration 3571: loss: 0.154974, loss_s1: 0.073731, loss_fp: 0.033919, loss_freq: 0.011496
[15:08:56.740] iteration 3572: loss: 0.168837, loss_s1: 0.060420, loss_fp: 0.008464, loss_freq: 0.029367
[15:08:57.366] iteration 3573: loss: 0.121229, loss_s1: 0.102667, loss_fp: 0.000448, loss_freq: 0.001721
[15:08:57.986] iteration 3574: loss: 0.227569, loss_s1: 0.103767, loss_fp: 0.004840, loss_freq: 0.017118
[15:08:58.608] iteration 3575: loss: 0.118049, loss_s1: 0.068328, loss_fp: 0.001895, loss_freq: 0.036213
[15:08:59.235] iteration 3576: loss: 0.112983, loss_s1: 0.036898, loss_fp: 0.003071, loss_freq: 0.004724
[15:08:59.870] iteration 3577: loss: 0.156044, loss_s1: 0.017553, loss_fp: 0.002824, loss_freq: 0.020114
[15:09:00.491] iteration 3578: loss: 0.157908, loss_s1: 0.039531, loss_fp: 0.000861, loss_freq: 0.015578
[15:09:01.122] iteration 3579: loss: 0.141599, loss_s1: 0.031690, loss_fp: 0.000528, loss_freq: 0.014012
[15:09:01.751] iteration 3580: loss: 0.137107, loss_s1: 0.081445, loss_fp: 0.000981, loss_freq: 0.074807
[15:09:02.378] iteration 3581: loss: 0.158674, loss_s1: 0.087927, loss_fp: 0.000960, loss_freq: 0.014470
[15:09:03.006] iteration 3582: loss: 0.168465, loss_s1: 0.136599, loss_fp: 0.001719, loss_freq: 0.028196
[15:09:03.634] iteration 3583: loss: 0.170960, loss_s1: 0.096870, loss_fp: 0.000422, loss_freq: 0.009601
[15:09:04.256] iteration 3584: loss: 0.104353, loss_s1: 0.025929, loss_fp: 0.000899, loss_freq: 0.004743
[15:09:04.875] iteration 3585: loss: 0.145223, loss_s1: 0.094406, loss_fp: 0.000546, loss_freq: 0.045759
[15:09:05.494] iteration 3586: loss: 0.132721, loss_s1: 0.054109, loss_fp: 0.001984, loss_freq: 0.033559
[15:09:06.124] iteration 3587: loss: 0.152217, loss_s1: 0.046266, loss_fp: 0.000745, loss_freq: 0.050294
[15:09:06.752] iteration 3588: loss: 0.183751, loss_s1: 0.109812, loss_fp: 0.000780, loss_freq: 0.054789
[15:09:07.374] iteration 3589: loss: 0.088604, loss_s1: 0.025247, loss_fp: 0.000654, loss_freq: 0.005894
[15:09:08.000] iteration 3590: loss: 0.081944, loss_s1: 0.016934, loss_fp: 0.007938, loss_freq: 0.005271
[15:09:08.622] iteration 3591: loss: 0.212035, loss_s1: 0.085963, loss_fp: 0.000664, loss_freq: 0.044983
[15:09:09.246] iteration 3592: loss: 0.106531, loss_s1: 0.048343, loss_fp: 0.000813, loss_freq: 0.007753
[15:09:09.878] iteration 3593: loss: 0.056041, loss_s1: 0.028971, loss_fp: 0.000487, loss_freq: 0.002432
[15:09:10.504] iteration 3594: loss: 0.192044, loss_s1: 0.023294, loss_fp: 0.000479, loss_freq: 0.057142
[15:09:11.126] iteration 3595: loss: 0.158181, loss_s1: 0.076838, loss_fp: 0.002943, loss_freq: 0.075735
[15:09:11.751] iteration 3596: loss: 0.161175, loss_s1: 0.037104, loss_fp: 0.000545, loss_freq: 0.024664
[15:09:12.377] iteration 3597: loss: 0.123609, loss_s1: 0.081801, loss_fp: 0.000414, loss_freq: 0.021164
[15:09:12.998] iteration 3598: loss: 0.425468, loss_s1: 0.312853, loss_fp: 0.002335, loss_freq: 0.314333
[15:09:13.624] iteration 3599: loss: 0.182835, loss_s1: 0.024012, loss_fp: 0.000579, loss_freq: 0.013619
[15:09:14.249] iteration 3600: loss: 0.211803, loss_s1: 0.119428, loss_fp: 0.000798, loss_freq: 0.010249
[15:09:17.116] iteration 3600 : mean_dice : 0.507106
[15:09:17.759] iteration 3601: loss: 0.088387, loss_s1: 0.023525, loss_fp: 0.000775, loss_freq: 0.044146
[15:09:18.380] iteration 3602: loss: 0.091604, loss_s1: 0.069331, loss_fp: 0.000701, loss_freq: 0.004779
[15:09:19.003] iteration 3603: loss: 0.078769, loss_s1: 0.026444, loss_fp: 0.002555, loss_freq: 0.030624
[15:09:19.625] iteration 3604: loss: 0.107268, loss_s1: 0.033442, loss_fp: 0.000575, loss_freq: 0.004937
[15:09:20.251] iteration 3605: loss: 0.128103, loss_s1: 0.048994, loss_fp: 0.001580, loss_freq: 0.021657
[15:09:20.877] iteration 3606: loss: 0.214779, loss_s1: 0.169206, loss_fp: 0.000819, loss_freq: 0.036144
[15:09:21.500] iteration 3607: loss: 0.083938, loss_s1: 0.021297, loss_fp: 0.001605, loss_freq: 0.010254
[15:09:22.122] iteration 3608: loss: 0.077743, loss_s1: 0.044655, loss_fp: 0.001894, loss_freq: 0.013035
[15:09:22.741] iteration 3609: loss: 0.180829, loss_s1: 0.066898, loss_fp: 0.000784, loss_freq: 0.052617
[15:09:23.360] iteration 3610: loss: 0.097852, loss_s1: 0.026784, loss_fp: 0.009526, loss_freq: 0.038098
[15:09:23.981] iteration 3611: loss: 0.102582, loss_s1: 0.040994, loss_fp: 0.004333, loss_freq: 0.032452
[15:09:24.604] iteration 3612: loss: 0.217283, loss_s1: 0.145634, loss_fp: 0.003388, loss_freq: 0.050629
[15:09:25.231] iteration 3613: loss: 0.164059, loss_s1: 0.027300, loss_fp: 0.002602, loss_freq: 0.024302
[15:09:25.846] iteration 3614: loss: 0.164500, loss_s1: 0.105286, loss_fp: 0.002213, loss_freq: 0.058823
[15:09:26.469] iteration 3615: loss: 0.122596, loss_s1: 0.043804, loss_fp: 0.000421, loss_freq: 0.042152
[15:09:27.089] iteration 3616: loss: 0.173705, loss_s1: 0.033120, loss_fp: 0.000739, loss_freq: 0.033017
[15:09:27.707] iteration 3617: loss: 0.194949, loss_s1: 0.049366, loss_fp: 0.001730, loss_freq: 0.134680
[15:09:28.333] iteration 3618: loss: 0.142483, loss_s1: 0.071941, loss_fp: 0.002706, loss_freq: 0.030934
[15:09:28.957] iteration 3619: loss: 0.143533, loss_s1: 0.055351, loss_fp: 0.002636, loss_freq: 0.103188
[15:09:29.582] iteration 3620: loss: 0.149097, loss_s1: 0.097433, loss_fp: 0.001589, loss_freq: 0.056633
[15:09:30.206] iteration 3621: loss: 0.068348, loss_s1: 0.016744, loss_fp: 0.001229, loss_freq: 0.014432
[15:09:30.831] iteration 3622: loss: 0.164427, loss_s1: 0.136550, loss_fp: 0.000728, loss_freq: 0.042064
[15:09:31.451] iteration 3623: loss: 0.146503, loss_s1: 0.028194, loss_fp: 0.002342, loss_freq: 0.016389
[15:09:32.072] iteration 3624: loss: 0.124794, loss_s1: 0.044988, loss_fp: 0.001752, loss_freq: 0.026910
[15:09:32.694] iteration 3625: loss: 0.137231, loss_s1: 0.108334, loss_fp: 0.002400, loss_freq: 0.049074
[15:09:33.319] iteration 3626: loss: 0.112066, loss_s1: 0.009062, loss_fp: 0.000808, loss_freq: 0.008345
[15:09:33.941] iteration 3627: loss: 0.082381, loss_s1: 0.022627, loss_fp: 0.000747, loss_freq: 0.036539
[15:09:34.569] iteration 3628: loss: 0.098428, loss_s1: 0.090350, loss_fp: 0.001210, loss_freq: 0.007897
[15:09:35.197] iteration 3629: loss: 0.214306, loss_s1: 0.072317, loss_fp: 0.000437, loss_freq: 0.005535
[15:09:35.829] iteration 3630: loss: 0.146160, loss_s1: 0.126152, loss_fp: 0.001157, loss_freq: 0.031452
[15:09:36.460] iteration 3631: loss: 0.179226, loss_s1: 0.143846, loss_fp: 0.001417, loss_freq: 0.000972
[15:09:37.089] iteration 3632: loss: 0.138795, loss_s1: 0.050322, loss_fp: 0.000391, loss_freq: 0.003119
[15:09:37.717] iteration 3633: loss: 0.170242, loss_s1: 0.068864, loss_fp: 0.001834, loss_freq: 0.021705
[15:09:38.344] iteration 3634: loss: 0.135557, loss_s1: 0.054074, loss_fp: 0.000550, loss_freq: 0.015480
[15:09:38.967] iteration 3635: loss: 0.185572, loss_s1: 0.031750, loss_fp: 0.000494, loss_freq: 0.035366
[15:09:39.590] iteration 3636: loss: 0.135603, loss_s1: 0.072630, loss_fp: 0.001080, loss_freq: 0.036475
[15:09:40.219] iteration 3637: loss: 0.120613, loss_s1: 0.059249, loss_fp: 0.000701, loss_freq: 0.094528
[15:09:40.893] iteration 3638: loss: 0.081778, loss_s1: 0.030662, loss_fp: 0.005510, loss_freq: 0.007494
[15:09:41.519] iteration 3639: loss: 0.091559, loss_s1: 0.021328, loss_fp: 0.000653, loss_freq: 0.003105
[15:09:42.141] iteration 3640: loss: 0.123237, loss_s1: 0.017319, loss_fp: 0.000864, loss_freq: 0.035295
[15:09:42.776] iteration 3641: loss: 0.130749, loss_s1: 0.054574, loss_fp: 0.000479, loss_freq: 0.001700
[15:09:43.397] iteration 3642: loss: 0.085382, loss_s1: 0.023243, loss_fp: 0.001887, loss_freq: 0.032558
[15:09:44.019] iteration 3643: loss: 0.115315, loss_s1: 0.067646, loss_fp: 0.003253, loss_freq: 0.028923
[15:09:44.639] iteration 3644: loss: 0.180390, loss_s1: 0.049215, loss_fp: 0.002581, loss_freq: 0.019883
[15:09:45.257] iteration 3645: loss: 0.189339, loss_s1: 0.096528, loss_fp: 0.001484, loss_freq: 0.029742
[15:09:45.875] iteration 3646: loss: 0.101757, loss_s1: 0.035668, loss_fp: 0.003074, loss_freq: 0.016258
[15:09:46.501] iteration 3647: loss: 0.146431, loss_s1: 0.033913, loss_fp: 0.000406, loss_freq: 0.013931
[15:09:47.124] iteration 3648: loss: 0.125749, loss_s1: 0.052659, loss_fp: 0.001277, loss_freq: 0.014840
[15:09:47.742] iteration 3649: loss: 0.128170, loss_s1: 0.033878, loss_fp: 0.021098, loss_freq: 0.006657
[15:09:48.368] iteration 3650: loss: 0.174502, loss_s1: 0.112283, loss_fp: 0.005720, loss_freq: 0.079305
[15:09:48.996] iteration 3651: loss: 0.306975, loss_s1: 0.110293, loss_fp: 0.001492, loss_freq: 0.310960
[15:09:49.700] iteration 3652: loss: 0.145944, loss_s1: 0.029696, loss_fp: 0.000616, loss_freq: 0.040031
[15:09:50.351] iteration 3653: loss: 0.137116, loss_s1: 0.014845, loss_fp: 0.000613, loss_freq: 0.010411
[15:09:50.974] iteration 3654: loss: 0.082535, loss_s1: 0.014832, loss_fp: 0.002110, loss_freq: 0.058883
[15:09:51.610] iteration 3655: loss: 0.147993, loss_s1: 0.109082, loss_fp: 0.003469, loss_freq: 0.035508
[15:09:52.236] iteration 3656: loss: 0.101601, loss_s1: 0.088795, loss_fp: 0.001155, loss_freq: 0.015601
[15:09:52.859] iteration 3657: loss: 0.136001, loss_s1: 0.130562, loss_fp: 0.000636, loss_freq: 0.001554
[15:09:53.485] iteration 3658: loss: 0.197248, loss_s1: 0.150291, loss_fp: 0.001574, loss_freq: 0.057775
[15:09:54.114] iteration 3659: loss: 0.126919, loss_s1: 0.027435, loss_fp: 0.009573, loss_freq: 0.026567
[15:09:54.738] iteration 3660: loss: 0.117713, loss_s1: 0.091855, loss_fp: 0.003436, loss_freq: 0.036632
[15:09:55.361] iteration 3661: loss: 0.266758, loss_s1: 0.146642, loss_fp: 0.001537, loss_freq: 0.109441
[15:09:55.995] iteration 3662: loss: 0.188054, loss_s1: 0.086884, loss_fp: 0.001000, loss_freq: 0.169072
[15:09:56.629] iteration 3663: loss: 0.123758, loss_s1: 0.094693, loss_fp: 0.021148, loss_freq: 0.006558
[15:09:57.257] iteration 3664: loss: 0.188689, loss_s1: 0.034054, loss_fp: 0.000525, loss_freq: 0.016074
[15:09:57.876] iteration 3665: loss: 0.182278, loss_s1: 0.212752, loss_fp: 0.000973, loss_freq: 0.012239
[15:09:58.501] iteration 3666: loss: 0.136042, loss_s1: 0.064117, loss_fp: 0.000451, loss_freq: 0.034429
[15:09:59.131] iteration 3667: loss: 0.125431, loss_s1: 0.057599, loss_fp: 0.000527, loss_freq: 0.014460
[15:09:59.760] iteration 3668: loss: 0.115713, loss_s1: 0.034577, loss_fp: 0.002490, loss_freq: 0.023974
[15:10:00.383] iteration 3669: loss: 0.109115, loss_s1: 0.040478, loss_fp: 0.000663, loss_freq: 0.005896
[15:10:01.008] iteration 3670: loss: 0.250457, loss_s1: 0.138403, loss_fp: 0.003145, loss_freq: 0.019451
[15:10:01.636] iteration 3671: loss: 0.137159, loss_s1: 0.096853, loss_fp: 0.001102, loss_freq: 0.014990
[15:10:02.251] iteration 3672: loss: 0.083008, loss_s1: 0.055647, loss_fp: 0.002168, loss_freq: 0.010433
[15:10:02.871] iteration 3673: loss: 0.097312, loss_s1: 0.031756, loss_fp: 0.005691, loss_freq: 0.035806
[15:10:03.492] iteration 3674: loss: 0.132143, loss_s1: 0.055201, loss_fp: 0.001206, loss_freq: 0.052364
[15:10:04.116] iteration 3675: loss: 0.175012, loss_s1: 0.135401, loss_fp: 0.009774, loss_freq: 0.054889
[15:10:04.742] iteration 3676: loss: 0.105561, loss_s1: 0.041893, loss_fp: 0.007356, loss_freq: 0.029382
[15:10:05.361] iteration 3677: loss: 0.083020, loss_s1: 0.030723, loss_fp: 0.003230, loss_freq: 0.013916
[15:10:05.987] iteration 3678: loss: 0.159804, loss_s1: 0.127230, loss_fp: 0.001313, loss_freq: 0.078160
[15:10:06.615] iteration 3679: loss: 0.138272, loss_s1: 0.025223, loss_fp: 0.000567, loss_freq: 0.007520
[15:10:07.246] iteration 3680: loss: 0.102712, loss_s1: 0.019626, loss_fp: 0.000439, loss_freq: 0.045120
[15:10:07.872] iteration 3681: loss: 0.114241, loss_s1: 0.055188, loss_fp: 0.004542, loss_freq: 0.051730
[15:10:08.499] iteration 3682: loss: 0.193056, loss_s1: 0.086607, loss_fp: 0.002564, loss_freq: 0.024016
[15:10:09.119] iteration 3683: loss: 0.144060, loss_s1: 0.105395, loss_fp: 0.000981, loss_freq: 0.035763
[15:10:09.739] iteration 3684: loss: 0.166842, loss_s1: 0.084957, loss_fp: 0.000977, loss_freq: 0.023310
[15:10:10.362] iteration 3685: loss: 0.101369, loss_s1: 0.028673, loss_fp: 0.002399, loss_freq: 0.005034
[15:10:10.987] iteration 3686: loss: 0.154601, loss_s1: 0.051708, loss_fp: 0.000924, loss_freq: 0.026031
[15:10:11.613] iteration 3687: loss: 0.139222, loss_s1: 0.061886, loss_fp: 0.001829, loss_freq: 0.033931
[15:10:12.242] iteration 3688: loss: 0.170924, loss_s1: 0.044844, loss_fp: 0.001228, loss_freq: 0.041819
[15:10:12.861] iteration 3689: loss: 0.083254, loss_s1: 0.038165, loss_fp: 0.002104, loss_freq: 0.017535
[15:10:13.480] iteration 3690: loss: 0.101867, loss_s1: 0.061167, loss_fp: 0.001261, loss_freq: 0.020865
[15:10:14.101] iteration 3691: loss: 0.071760, loss_s1: 0.021626, loss_fp: 0.000499, loss_freq: 0.010386
[15:10:14.731] iteration 3692: loss: 0.095282, loss_s1: 0.028526, loss_fp: 0.001195, loss_freq: 0.018781
[15:10:15.360] iteration 3693: loss: 0.213593, loss_s1: 0.090948, loss_fp: 0.000823, loss_freq: 0.045692
[15:10:15.989] iteration 3694: loss: 0.209720, loss_s1: 0.170016, loss_fp: 0.001191, loss_freq: 0.022788
[15:10:16.613] iteration 3695: loss: 0.086416, loss_s1: 0.054209, loss_fp: 0.001598, loss_freq: 0.006839
[15:10:17.236] iteration 3696: loss: 0.199798, loss_s1: 0.094884, loss_fp: 0.002020, loss_freq: 0.027658
[15:10:17.858] iteration 3697: loss: 0.133408, loss_s1: 0.055662, loss_fp: 0.001914, loss_freq: 0.029345
[15:10:18.479] iteration 3698: loss: 0.114657, loss_s1: 0.037409, loss_fp: 0.001080, loss_freq: 0.035940
[15:10:19.101] iteration 3699: loss: 0.167580, loss_s1: 0.056274, loss_fp: 0.000710, loss_freq: 0.008304
[15:10:19.725] iteration 3700: loss: 0.157969, loss_s1: 0.082284, loss_fp: 0.001037, loss_freq: 0.065056
[15:10:20.356] iteration 3701: loss: 0.134456, loss_s1: 0.093290, loss_fp: 0.000634, loss_freq: 0.004710
[15:10:20.973] iteration 3702: loss: 0.105241, loss_s1: 0.020622, loss_fp: 0.002861, loss_freq: 0.031037
[15:10:21.593] iteration 3703: loss: 0.134936, loss_s1: 0.059616, loss_fp: 0.005679, loss_freq: 0.058465
[15:10:22.526] iteration 3704: loss: 0.077104, loss_s1: 0.015377, loss_fp: 0.000704, loss_freq: 0.009749
[15:10:23.154] iteration 3705: loss: 0.221153, loss_s1: 0.130873, loss_fp: 0.001282, loss_freq: 0.097115
[15:10:23.784] iteration 3706: loss: 0.154117, loss_s1: 0.087583, loss_fp: 0.001175, loss_freq: 0.004834
[15:10:24.451] iteration 3707: loss: 0.123909, loss_s1: 0.031770, loss_fp: 0.000553, loss_freq: 0.013515
[15:10:25.083] iteration 3708: loss: 0.168472, loss_s1: 0.025413, loss_fp: 0.011907, loss_freq: 0.053528
[15:10:25.708] iteration 3709: loss: 0.198178, loss_s1: 0.074557, loss_fp: 0.002447, loss_freq: 0.068749
[15:10:26.336] iteration 3710: loss: 0.070656, loss_s1: 0.013906, loss_fp: 0.006156, loss_freq: 0.016288
[15:10:26.958] iteration 3711: loss: 0.121327, loss_s1: 0.054732, loss_fp: 0.002330, loss_freq: 0.062525
[15:10:27.581] iteration 3712: loss: 0.133546, loss_s1: 0.097655, loss_fp: 0.043793, loss_freq: 0.011808
[15:10:28.212] iteration 3713: loss: 0.134926, loss_s1: 0.078195, loss_fp: 0.016675, loss_freq: 0.040356
[15:10:28.837] iteration 3714: loss: 0.093585, loss_s1: 0.020178, loss_fp: 0.000511, loss_freq: 0.006105
[15:10:29.463] iteration 3715: loss: 0.132053, loss_s1: 0.039445, loss_fp: 0.000357, loss_freq: 0.027352
[15:10:30.090] iteration 3716: loss: 0.099488, loss_s1: 0.046253, loss_fp: 0.002570, loss_freq: 0.036564
[15:10:30.710] iteration 3717: loss: 0.159851, loss_s1: 0.025600, loss_fp: 0.000681, loss_freq: 0.047927
[15:10:31.335] iteration 3718: loss: 0.078276, loss_s1: 0.038767, loss_fp: 0.000590, loss_freq: 0.006408
[15:10:31.958] iteration 3719: loss: 0.135701, loss_s1: 0.059367, loss_fp: 0.000555, loss_freq: 0.046952
[15:10:32.620] iteration 3720: loss: 0.140567, loss_s1: 0.046361, loss_fp: 0.001060, loss_freq: 0.009086
[15:10:33.245] iteration 3721: loss: 0.096884, loss_s1: 0.006429, loss_fp: 0.001298, loss_freq: 0.015912
[15:10:33.873] iteration 3722: loss: 0.166446, loss_s1: 0.023580, loss_fp: 0.000675, loss_freq: 0.016832
[15:10:34.494] iteration 3723: loss: 0.123158, loss_s1: 0.045524, loss_fp: 0.001218, loss_freq: 0.022086
[15:10:35.123] iteration 3724: loss: 0.105538, loss_s1: 0.003593, loss_fp: 0.002872, loss_freq: 0.006257
[15:10:35.748] iteration 3725: loss: 0.136369, loss_s1: 0.062745, loss_fp: 0.006351, loss_freq: 0.013455
[15:10:36.373] iteration 3726: loss: 0.138731, loss_s1: 0.027525, loss_fp: 0.000492, loss_freq: 0.015891
[15:10:37.022] iteration 3727: loss: 0.148673, loss_s1: 0.077705, loss_fp: 0.001929, loss_freq: 0.076441
[15:10:37.649] iteration 3728: loss: 0.083196, loss_s1: 0.030729, loss_fp: 0.001375, loss_freq: 0.005747
[15:10:38.272] iteration 3729: loss: 0.114710, loss_s1: 0.048952, loss_fp: 0.000544, loss_freq: 0.017270
[15:10:38.909] iteration 3730: loss: 0.105344, loss_s1: 0.043622, loss_fp: 0.000844, loss_freq: 0.013500
[15:10:39.532] iteration 3731: loss: 0.175250, loss_s1: 0.041082, loss_fp: 0.000526, loss_freq: 0.039962
[15:10:40.161] iteration 3732: loss: 0.176230, loss_s1: 0.039875, loss_fp: 0.001132, loss_freq: 0.015164
[15:10:40.777] iteration 3733: loss: 0.073513, loss_s1: 0.031899, loss_fp: 0.001553, loss_freq: 0.014330
[15:10:41.401] iteration 3734: loss: 0.082277, loss_s1: 0.055421, loss_fp: 0.002401, loss_freq: 0.011038
[15:10:42.022] iteration 3735: loss: 0.193108, loss_s1: 0.057865, loss_fp: 0.003089, loss_freq: 0.029548
[15:10:42.647] iteration 3736: loss: 0.103094, loss_s1: 0.055010, loss_fp: 0.001559, loss_freq: 0.035437
[15:10:43.267] iteration 3737: loss: 0.105211, loss_s1: 0.047323, loss_fp: 0.000874, loss_freq: 0.006865
[15:10:43.896] iteration 3738: loss: 0.195025, loss_s1: 0.056766, loss_fp: 0.002571, loss_freq: 0.012542
[15:10:44.524] iteration 3739: loss: 0.162706, loss_s1: 0.037709, loss_fp: 0.000609, loss_freq: 0.030673
[15:10:45.153] iteration 3740: loss: 0.100564, loss_s1: 0.013874, loss_fp: 0.002309, loss_freq: 0.018193
[15:10:45.779] iteration 3741: loss: 0.198971, loss_s1: 0.105683, loss_fp: 0.000814, loss_freq: 0.150308
[15:10:46.404] iteration 3742: loss: 0.149753, loss_s1: 0.032082, loss_fp: 0.008109, loss_freq: 0.016944
[15:10:47.030] iteration 3743: loss: 0.148810, loss_s1: 0.107614, loss_fp: 0.003464, loss_freq: 0.032223
[15:10:47.653] iteration 3744: loss: 0.196028, loss_s1: 0.106832, loss_fp: 0.005520, loss_freq: 0.016608
[15:10:48.269] iteration 3745: loss: 0.111195, loss_s1: 0.080485, loss_fp: 0.004193, loss_freq: 0.018363
[15:10:48.888] iteration 3746: loss: 0.155786, loss_s1: 0.075758, loss_fp: 0.000588, loss_freq: 0.085546
[15:10:49.522] iteration 3747: loss: 0.074385, loss_s1: 0.028839, loss_fp: 0.006484, loss_freq: 0.012611
[15:10:50.152] iteration 3748: loss: 0.126756, loss_s1: 0.029180, loss_fp: 0.001085, loss_freq: 0.057000
[15:10:50.778] iteration 3749: loss: 0.145590, loss_s1: 0.089245, loss_fp: 0.000835, loss_freq: 0.010518
[15:10:51.402] iteration 3750: loss: 0.083589, loss_s1: 0.034230, loss_fp: 0.000545, loss_freq: 0.011208
[15:10:52.031] iteration 3751: loss: 0.062703, loss_s1: 0.039420, loss_fp: 0.001115, loss_freq: 0.009274
[15:10:52.663] iteration 3752: loss: 0.181258, loss_s1: 0.081912, loss_fp: 0.001368, loss_freq: 0.050732
[15:10:53.292] iteration 3753: loss: 0.110104, loss_s1: 0.051673, loss_fp: 0.000790, loss_freq: 0.004257
[15:10:53.918] iteration 3754: loss: 0.077547, loss_s1: 0.044415, loss_fp: 0.000442, loss_freq: 0.025081
[15:10:54.537] iteration 3755: loss: 0.170775, loss_s1: 0.031060, loss_fp: 0.003326, loss_freq: 0.049371
[15:10:55.157] iteration 3756: loss: 0.191548, loss_s1: 0.122551, loss_fp: 0.017030, loss_freq: 0.090574
[15:10:55.790] iteration 3757: loss: 0.204802, loss_s1: 0.075998, loss_fp: 0.002839, loss_freq: 0.015375
[15:10:56.414] iteration 3758: loss: 0.153586, loss_s1: 0.062165, loss_fp: 0.000576, loss_freq: 0.026425
[15:10:57.040] iteration 3759: loss: 0.232930, loss_s1: 0.250868, loss_fp: 0.002579, loss_freq: 0.051704
[15:10:57.664] iteration 3760: loss: 0.135097, loss_s1: 0.031939, loss_fp: 0.000472, loss_freq: 0.027274
[15:10:58.294] iteration 3761: loss: 0.237418, loss_s1: 0.063277, loss_fp: 0.000901, loss_freq: 0.106262
[15:10:58.919] iteration 3762: loss: 0.111872, loss_s1: 0.092203, loss_fp: 0.000465, loss_freq: 0.025974
[15:10:59.542] iteration 3763: loss: 0.072388, loss_s1: 0.024687, loss_fp: 0.000836, loss_freq: 0.007976
[15:11:00.170] iteration 3764: loss: 0.120422, loss_s1: 0.072313, loss_fp: 0.001292, loss_freq: 0.058556
[15:11:00.798] iteration 3765: loss: 0.099292, loss_s1: 0.028572, loss_fp: 0.008253, loss_freq: 0.017055
[15:11:01.423] iteration 3766: loss: 0.116692, loss_s1: 0.068439, loss_fp: 0.002095, loss_freq: 0.020447
[15:11:02.052] iteration 3767: loss: 0.147880, loss_s1: 0.074687, loss_fp: 0.014461, loss_freq: 0.051745
[15:11:02.683] iteration 3768: loss: 0.116573, loss_s1: 0.074406, loss_fp: 0.006286, loss_freq: 0.006592
[15:11:03.311] iteration 3769: loss: 0.106580, loss_s1: 0.066517, loss_fp: 0.000704, loss_freq: 0.031658
[15:11:04.012] iteration 3770: loss: 0.203470, loss_s1: 0.065076, loss_fp: 0.002485, loss_freq: 0.097726
[15:11:04.674] iteration 3771: loss: 0.066148, loss_s1: 0.022507, loss_fp: 0.005049, loss_freq: 0.026601
[15:11:05.336] iteration 3772: loss: 0.083331, loss_s1: 0.042819, loss_fp: 0.000460, loss_freq: 0.017202
[15:11:05.962] iteration 3773: loss: 0.162308, loss_s1: 0.052509, loss_fp: 0.000581, loss_freq: 0.020535
[15:11:06.586] iteration 3774: loss: 0.200580, loss_s1: 0.087746, loss_fp: 0.000971, loss_freq: 0.050999
[15:11:07.209] iteration 3775: loss: 0.171334, loss_s1: 0.091129, loss_fp: 0.000836, loss_freq: 0.080804
[15:11:07.832] iteration 3776: loss: 0.089313, loss_s1: 0.021814, loss_fp: 0.000888, loss_freq: 0.015845
[15:11:08.451] iteration 3777: loss: 0.128953, loss_s1: 0.023623, loss_fp: 0.000401, loss_freq: 0.035663
[15:11:09.086] iteration 3778: loss: 0.130208, loss_s1: 0.048894, loss_fp: 0.001158, loss_freq: 0.049072
[15:11:09.718] iteration 3779: loss: 0.199864, loss_s1: 0.079899, loss_fp: 0.000982, loss_freq: 0.053198
[15:11:10.349] iteration 3780: loss: 0.135351, loss_s1: 0.063630, loss_fp: 0.044905, loss_freq: 0.049458
[15:11:10.971] iteration 3781: loss: 0.138658, loss_s1: 0.102223, loss_fp: 0.000808, loss_freq: 0.060797
[15:11:11.595] iteration 3782: loss: 0.091624, loss_s1: 0.029628, loss_fp: 0.001146, loss_freq: 0.012906
[15:11:12.220] iteration 3783: loss: 0.125124, loss_s1: 0.051260, loss_fp: 0.002279, loss_freq: 0.022610
[15:11:12.842] iteration 3784: loss: 0.112002, loss_s1: 0.043422, loss_fp: 0.005624, loss_freq: 0.033277
[15:11:13.466] iteration 3785: loss: 0.115805, loss_s1: 0.091477, loss_fp: 0.000473, loss_freq: 0.012868
[15:11:14.092] iteration 3786: loss: 0.175300, loss_s1: 0.152118, loss_fp: 0.001079, loss_freq: 0.081962
[15:11:14.717] iteration 3787: loss: 0.156356, loss_s1: 0.080292, loss_fp: 0.001800, loss_freq: 0.009043
[15:11:15.347] iteration 3788: loss: 0.104776, loss_s1: 0.026258, loss_fp: 0.002651, loss_freq: 0.027198
[15:11:15.972] iteration 3789: loss: 0.088469, loss_s1: 0.085274, loss_fp: 0.004708, loss_freq: 0.002742
[15:11:16.593] iteration 3790: loss: 0.260165, loss_s1: 0.119481, loss_fp: 0.001232, loss_freq: 0.039924
[15:11:17.218] iteration 3791: loss: 0.130915, loss_s1: 0.044858, loss_fp: 0.010805, loss_freq: 0.069638
[15:11:17.842] iteration 3792: loss: 0.154749, loss_s1: 0.058765, loss_fp: 0.002628, loss_freq: 0.007074
[15:11:18.460] iteration 3793: loss: 0.123728, loss_s1: 0.032836, loss_fp: 0.001553, loss_freq: 0.022565
[15:11:19.081] iteration 3794: loss: 0.126066, loss_s1: 0.036944, loss_fp: 0.000940, loss_freq: 0.021666
[15:11:19.702] iteration 3795: loss: 0.192014, loss_s1: 0.076951, loss_fp: 0.001011, loss_freq: 0.037178
[15:11:20.324] iteration 3796: loss: 0.184321, loss_s1: 0.050559, loss_fp: 0.000841, loss_freq: 0.039877
[15:11:20.958] iteration 3797: loss: 0.102578, loss_s1: 0.062391, loss_fp: 0.000637, loss_freq: 0.029126
[15:11:21.582] iteration 3798: loss: 0.089797, loss_s1: 0.045954, loss_fp: 0.000743, loss_freq: 0.022163
[15:11:22.209] iteration 3799: loss: 0.090700, loss_s1: 0.066409, loss_fp: 0.001087, loss_freq: 0.017815
[15:11:22.833] iteration 3800: loss: 0.080005, loss_s1: 0.036737, loss_fp: 0.000542, loss_freq: 0.018757
[15:11:25.699] iteration 3800 : mean_dice : 0.513776
[15:11:26.338] iteration 3801: loss: 0.136658, loss_s1: 0.070358, loss_fp: 0.001183, loss_freq: 0.036785
[15:11:26.964] iteration 3802: loss: 0.119636, loss_s1: 0.028052, loss_fp: 0.000209, loss_freq: 0.005031
[15:11:27.588] iteration 3803: loss: 0.080410, loss_s1: 0.033982, loss_fp: 0.000871, loss_freq: 0.035404
[15:11:28.212] iteration 3804: loss: 0.092992, loss_s1: 0.017439, loss_fp: 0.000681, loss_freq: 0.038251
[15:11:28.835] iteration 3805: loss: 0.169801, loss_s1: 0.068676, loss_fp: 0.001512, loss_freq: 0.010600
[15:11:29.460] iteration 3806: loss: 0.216090, loss_s1: 0.152261, loss_fp: 0.021208, loss_freq: 0.051615
[15:11:30.107] iteration 3807: loss: 0.123768, loss_s1: 0.066065, loss_fp: 0.000844, loss_freq: 0.051386
[15:11:30.733] iteration 3808: loss: 0.211508, loss_s1: 0.061768, loss_fp: 0.003803, loss_freq: 0.046169
[15:11:31.391] iteration 3809: loss: 0.144302, loss_s1: 0.035165, loss_fp: 0.002835, loss_freq: 0.017670
[15:11:32.025] iteration 3810: loss: 0.113317, loss_s1: 0.012820, loss_fp: 0.001573, loss_freq: 0.029543
[15:11:32.662] iteration 3811: loss: 0.146314, loss_s1: 0.102751, loss_fp: 0.001012, loss_freq: 0.029160
[15:11:33.298] iteration 3812: loss: 0.380260, loss_s1: 0.162844, loss_fp: 0.001021, loss_freq: 0.349712
[15:11:33.932] iteration 3813: loss: 0.185065, loss_s1: 0.049588, loss_fp: 0.000975, loss_freq: 0.032148
[15:11:34.566] iteration 3814: loss: 0.146373, loss_s1: 0.012604, loss_fp: 0.000715, loss_freq: 0.014697
[15:11:35.196] iteration 3815: loss: 0.111122, loss_s1: 0.057932, loss_fp: 0.000888, loss_freq: 0.040274
[15:11:35.822] iteration 3816: loss: 0.212923, loss_s1: 0.130827, loss_fp: 0.004488, loss_freq: 0.137173
[15:11:36.454] iteration 3817: loss: 0.125139, loss_s1: 0.070200, loss_fp: 0.001172, loss_freq: 0.045934
[15:11:37.084] iteration 3818: loss: 0.075146, loss_s1: 0.023511, loss_fp: 0.001687, loss_freq: 0.003250
[15:11:37.716] iteration 3819: loss: 0.208228, loss_s1: 0.063502, loss_fp: 0.001257, loss_freq: 0.043794
[15:11:38.339] iteration 3820: loss: 0.118323, loss_s1: 0.078446, loss_fp: 0.001676, loss_freq: 0.028594
[15:11:38.962] iteration 3821: loss: 0.079886, loss_s1: 0.048749, loss_fp: 0.002206, loss_freq: 0.034065
[15:11:39.586] iteration 3822: loss: 0.170407, loss_s1: 0.027648, loss_fp: 0.001953, loss_freq: 0.051628
[15:11:40.214] iteration 3823: loss: 0.216187, loss_s1: 0.174297, loss_fp: 0.000943, loss_freq: 0.125994
[15:11:40.845] iteration 3824: loss: 0.117956, loss_s1: 0.056587, loss_fp: 0.000758, loss_freq: 0.039477
[15:11:41.467] iteration 3825: loss: 0.220477, loss_s1: 0.033551, loss_fp: 0.005727, loss_freq: 0.012495
[15:11:42.098] iteration 3826: loss: 0.222485, loss_s1: 0.172356, loss_fp: 0.006279, loss_freq: 0.030659
[15:11:42.725] iteration 3827: loss: 0.135135, loss_s1: 0.055661, loss_fp: 0.000414, loss_freq: 0.020552
[15:11:43.350] iteration 3828: loss: 0.240371, loss_s1: 0.082100, loss_fp: 0.002526, loss_freq: 0.061249
[15:11:43.975] iteration 3829: loss: 0.149600, loss_s1: 0.028132, loss_fp: 0.003920, loss_freq: 0.007650
[15:11:44.599] iteration 3830: loss: 0.176933, loss_s1: 0.068257, loss_fp: 0.002711, loss_freq: 0.004793
[15:11:45.223] iteration 3831: loss: 0.189634, loss_s1: 0.045788, loss_fp: 0.000533, loss_freq: 0.027546
[15:11:45.846] iteration 3832: loss: 0.117612, loss_s1: 0.072540, loss_fp: 0.001451, loss_freq: 0.015807
[15:11:46.494] iteration 3833: loss: 0.100780, loss_s1: 0.032841, loss_fp: 0.001240, loss_freq: 0.025199
[15:11:47.116] iteration 3834: loss: 0.084850, loss_s1: 0.046578, loss_fp: 0.001240, loss_freq: 0.020012
[15:11:47.742] iteration 3835: loss: 0.147636, loss_s1: 0.029674, loss_fp: 0.001099, loss_freq: 0.012893
[15:11:48.354] iteration 3836: loss: 0.155781, loss_s1: 0.097951, loss_fp: 0.001036, loss_freq: 0.044114
[15:11:48.981] iteration 3837: loss: 0.102520, loss_s1: 0.061917, loss_fp: 0.001505, loss_freq: 0.003732
[15:11:49.609] iteration 3838: loss: 0.121153, loss_s1: 0.092625, loss_fp: 0.001126, loss_freq: 0.018639
[15:11:50.233] iteration 3839: loss: 0.111314, loss_s1: 0.077775, loss_fp: 0.001594, loss_freq: 0.023196
[15:11:50.859] iteration 3840: loss: 0.137869, loss_s1: 0.043564, loss_fp: 0.000748, loss_freq: 0.009487
[15:11:51.493] iteration 3841: loss: 0.093737, loss_s1: 0.041670, loss_fp: 0.000835, loss_freq: 0.037363
[15:11:52.122] iteration 3842: loss: 0.109701, loss_s1: 0.083478, loss_fp: 0.001274, loss_freq: 0.043024
[15:11:52.803] iteration 3843: loss: 0.187323, loss_s1: 0.061231, loss_fp: 0.001346, loss_freq: 0.044010
[15:11:53.467] iteration 3844: loss: 0.189546, loss_s1: 0.067959, loss_fp: 0.003910, loss_freq: 0.047470
[15:11:54.131] iteration 3845: loss: 0.105883, loss_s1: 0.028783, loss_fp: 0.000617, loss_freq: 0.014155
[15:11:54.845] iteration 3846: loss: 0.124027, loss_s1: 0.049214, loss_fp: 0.003058, loss_freq: 0.008779
[15:11:55.466] iteration 3847: loss: 0.139173, loss_s1: 0.090026, loss_fp: 0.001029, loss_freq: 0.019028
[15:11:56.087] iteration 3848: loss: 0.120542, loss_s1: 0.047862, loss_fp: 0.002198, loss_freq: 0.008308
[15:11:56.707] iteration 3849: loss: 0.114641, loss_s1: 0.029525, loss_fp: 0.009492, loss_freq: 0.026003
[15:11:57.324] iteration 3850: loss: 0.072625, loss_s1: 0.045399, loss_fp: 0.000758, loss_freq: 0.007144
[15:11:57.943] iteration 3851: loss: 0.123243, loss_s1: 0.057614, loss_fp: 0.001039, loss_freq: 0.059975
[15:11:58.562] iteration 3852: loss: 0.104209, loss_s1: 0.029781, loss_fp: 0.004984, loss_freq: 0.027209
[15:11:59.186] iteration 3853: loss: 0.117922, loss_s1: 0.066650, loss_fp: 0.000561, loss_freq: 0.022483
[15:11:59.811] iteration 3854: loss: 0.169653, loss_s1: 0.029129, loss_fp: 0.009375, loss_freq: 0.034861
[15:12:00.435] iteration 3855: loss: 0.184655, loss_s1: 0.101901, loss_fp: 0.002177, loss_freq: 0.087649
[15:12:01.062] iteration 3856: loss: 0.130573, loss_s1: 0.094853, loss_fp: 0.001415, loss_freq: 0.028189
[15:12:01.688] iteration 3857: loss: 0.207478, loss_s1: 0.089699, loss_fp: 0.011342, loss_freq: 0.022366
[15:12:02.314] iteration 3858: loss: 0.101169, loss_s1: 0.025418, loss_fp: 0.001323, loss_freq: 0.036589
[15:12:02.938] iteration 3859: loss: 0.086126, loss_s1: 0.041112, loss_fp: 0.000829, loss_freq: 0.016212
[15:12:03.559] iteration 3860: loss: 0.184105, loss_s1: 0.034843, loss_fp: 0.003906, loss_freq: 0.037403
[15:12:04.180] iteration 3861: loss: 0.160211, loss_s1: 0.061676, loss_fp: 0.007113, loss_freq: 0.053966
[15:12:04.806] iteration 3862: loss: 0.172278, loss_s1: 0.060922, loss_fp: 0.000581, loss_freq: 0.019845
[15:12:05.430] iteration 3863: loss: 0.119471, loss_s1: 0.045428, loss_fp: 0.008441, loss_freq: 0.024332
[15:12:06.047] iteration 3864: loss: 0.169088, loss_s1: 0.047551, loss_fp: 0.000605, loss_freq: 0.056922
[15:12:07.046] iteration 3865: loss: 0.138100, loss_s1: 0.040758, loss_fp: 0.000900, loss_freq: 0.007700
[15:12:07.705] iteration 3866: loss: 0.203235, loss_s1: 0.106671, loss_fp: 0.001155, loss_freq: 0.069022
[15:12:08.412] iteration 3867: loss: 0.090198, loss_s1: 0.031570, loss_fp: 0.001063, loss_freq: 0.019328
[15:12:09.039] iteration 3868: loss: 0.119617, loss_s1: 0.047775, loss_fp: 0.000612, loss_freq: 0.007172
[15:12:09.686] iteration 3869: loss: 0.129771, loss_s1: 0.041970, loss_fp: 0.000475, loss_freq: 0.003855
[15:12:10.337] iteration 3870: loss: 0.192108, loss_s1: 0.098489, loss_fp: 0.002433, loss_freq: 0.033032
[15:12:10.966] iteration 3871: loss: 0.087143, loss_s1: 0.020461, loss_fp: 0.000711, loss_freq: 0.011922
[15:12:11.592] iteration 3872: loss: 0.119001, loss_s1: 0.040486, loss_fp: 0.005903, loss_freq: 0.063182
[15:12:12.214] iteration 3873: loss: 0.053374, loss_s1: 0.008886, loss_fp: 0.002990, loss_freq: 0.015670
[15:12:12.858] iteration 3874: loss: 0.123739, loss_s1: 0.093261, loss_fp: 0.004067, loss_freq: 0.010437
[15:12:13.499] iteration 3875: loss: 0.128012, loss_s1: 0.010056, loss_fp: 0.001031, loss_freq: 0.006889
[15:12:14.124] iteration 3876: loss: 0.205889, loss_s1: 0.107247, loss_fp: 0.000623, loss_freq: 0.056960
[15:12:14.748] iteration 3877: loss: 0.066326, loss_s1: 0.025235, loss_fp: 0.001889, loss_freq: 0.021130
[15:12:15.377] iteration 3878: loss: 0.195335, loss_s1: 0.061739, loss_fp: 0.003608, loss_freq: 0.086750
[15:12:16.007] iteration 3879: loss: 0.095957, loss_s1: 0.041111, loss_fp: 0.002279, loss_freq: 0.012362
[15:12:16.638] iteration 3880: loss: 0.160149, loss_s1: 0.115773, loss_fp: 0.000842, loss_freq: 0.016898
[15:12:17.259] iteration 3881: loss: 0.197579, loss_s1: 0.088656, loss_fp: 0.005201, loss_freq: 0.023247
[15:12:17.886] iteration 3882: loss: 0.111707, loss_s1: 0.062798, loss_fp: 0.003408, loss_freq: 0.013960
[15:12:18.513] iteration 3883: loss: 0.149730, loss_s1: 0.056239, loss_fp: 0.001530, loss_freq: 0.032841
[15:12:19.143] iteration 3884: loss: 0.133191, loss_s1: 0.039891, loss_fp: 0.000436, loss_freq: 0.021351
[15:12:19.768] iteration 3885: loss: 0.109569, loss_s1: 0.031385, loss_fp: 0.001140, loss_freq: 0.007922
[15:12:20.392] iteration 3886: loss: 0.129474, loss_s1: 0.056861, loss_fp: 0.000811, loss_freq: 0.043831
[15:12:21.007] iteration 3887: loss: 0.148496, loss_s1: 0.026803, loss_fp: 0.001362, loss_freq: 0.008446
[15:12:21.629] iteration 3888: loss: 0.250365, loss_s1: 0.156178, loss_fp: 0.001335, loss_freq: 0.228685
[15:12:22.249] iteration 3889: loss: 0.103819, loss_s1: 0.088176, loss_fp: 0.000751, loss_freq: 0.007167
[15:12:22.872] iteration 3890: loss: 0.079039, loss_s1: 0.032713, loss_fp: 0.000898, loss_freq: 0.031406
[15:12:23.499] iteration 3891: loss: 0.115607, loss_s1: 0.076064, loss_fp: 0.001717, loss_freq: 0.008102
[15:12:24.131] iteration 3892: loss: 0.236402, loss_s1: 0.129617, loss_fp: 0.002760, loss_freq: 0.077379
[15:12:24.758] iteration 3893: loss: 0.083090, loss_s1: 0.024803, loss_fp: 0.004445, loss_freq: 0.008053
[15:12:25.387] iteration 3894: loss: 0.089609, loss_s1: 0.025948, loss_fp: 0.000647, loss_freq: 0.019343
[15:12:26.006] iteration 3895: loss: 0.100139, loss_s1: 0.072512, loss_fp: 0.000634, loss_freq: 0.008960
[15:12:26.635] iteration 3896: loss: 0.154898, loss_s1: 0.012338, loss_fp: 0.006158, loss_freq: 0.015342
[15:12:27.301] iteration 3897: loss: 0.120144, loss_s1: 0.082810, loss_fp: 0.002052, loss_freq: 0.036610
[15:12:27.918] iteration 3898: loss: 0.118365, loss_s1: 0.077505, loss_fp: 0.010481, loss_freq: 0.010791
[15:12:28.538] iteration 3899: loss: 0.173917, loss_s1: 0.046953, loss_fp: 0.001128, loss_freq: 0.006630
[15:12:29.159] iteration 3900: loss: 0.092059, loss_s1: 0.028317, loss_fp: 0.000621, loss_freq: 0.026945
[15:12:29.779] iteration 3901: loss: 0.265160, loss_s1: 0.192508, loss_fp: 0.001357, loss_freq: 0.088744
[15:12:30.401] iteration 3902: loss: 0.151473, loss_s1: 0.078882, loss_fp: 0.001284, loss_freq: 0.065077
[15:12:31.026] iteration 3903: loss: 0.160250, loss_s1: 0.111120, loss_fp: 0.000811, loss_freq: 0.071162
[15:12:31.647] iteration 3904: loss: 0.142108, loss_s1: 0.059939, loss_fp: 0.004835, loss_freq: 0.062993
[15:12:32.272] iteration 3905: loss: 0.170119, loss_s1: 0.045863, loss_fp: 0.000335, loss_freq: 0.006245
[15:12:32.888] iteration 3906: loss: 0.092822, loss_s1: 0.068115, loss_fp: 0.010043, loss_freq: 0.017911
[15:12:33.513] iteration 3907: loss: 0.099792, loss_s1: 0.060756, loss_fp: 0.001588, loss_freq: 0.013721
[15:12:34.140] iteration 3908: loss: 0.112337, loss_s1: 0.091633, loss_fp: 0.001239, loss_freq: 0.011105
[15:12:34.772] iteration 3909: loss: 0.119036, loss_s1: 0.009374, loss_fp: 0.000982, loss_freq: 0.071121
[15:12:35.398] iteration 3910: loss: 0.144795, loss_s1: 0.080568, loss_fp: 0.002491, loss_freq: 0.023223
[15:12:36.028] iteration 3911: loss: 0.162533, loss_s1: 0.057539, loss_fp: 0.001135, loss_freq: 0.043311
[15:12:36.651] iteration 3912: loss: 0.077894, loss_s1: 0.033049, loss_fp: 0.002917, loss_freq: 0.012402
[15:12:37.267] iteration 3913: loss: 0.172686, loss_s1: 0.065291, loss_fp: 0.003591, loss_freq: 0.014862
[15:12:37.893] iteration 3914: loss: 0.109945, loss_s1: 0.057496, loss_fp: 0.001329, loss_freq: 0.032398
[15:12:38.522] iteration 3915: loss: 0.088307, loss_s1: 0.061002, loss_fp: 0.000491, loss_freq: 0.018057
[15:12:39.147] iteration 3916: loss: 0.233447, loss_s1: 0.048353, loss_fp: 0.006691, loss_freq: 0.056812
[15:12:39.772] iteration 3917: loss: 0.116273, loss_s1: 0.027922, loss_fp: 0.003842, loss_freq: 0.053490
[15:12:40.389] iteration 3918: loss: 0.129875, loss_s1: 0.106935, loss_fp: 0.002607, loss_freq: 0.028211
[15:12:41.015] iteration 3919: loss: 0.195817, loss_s1: 0.066229, loss_fp: 0.001407, loss_freq: 0.007659
[15:12:41.645] iteration 3920: loss: 0.225439, loss_s1: 0.265713, loss_fp: 0.002336, loss_freq: 0.043992
[15:12:42.275] iteration 3921: loss: 0.100437, loss_s1: 0.025392, loss_fp: 0.000406, loss_freq: 0.008234
[15:12:42.896] iteration 3922: loss: 0.138885, loss_s1: 0.023682, loss_fp: 0.001185, loss_freq: 0.018976
[15:12:43.519] iteration 3923: loss: 0.128415, loss_s1: 0.073188, loss_fp: 0.001377, loss_freq: 0.032815
[15:12:44.145] iteration 3924: loss: 0.071904, loss_s1: 0.026352, loss_fp: 0.000699, loss_freq: 0.021892
[15:12:44.770] iteration 3925: loss: 0.077512, loss_s1: 0.017449, loss_fp: 0.002029, loss_freq: 0.030494
[15:12:45.396] iteration 3926: loss: 0.115426, loss_s1: 0.050475, loss_fp: 0.001978, loss_freq: 0.021018
[15:12:46.020] iteration 3927: loss: 0.162907, loss_s1: 0.061011, loss_fp: 0.009960, loss_freq: 0.022754
[15:12:46.648] iteration 3928: loss: 0.247424, loss_s1: 0.093223, loss_fp: 0.005752, loss_freq: 0.067189
[15:12:47.279] iteration 3929: loss: 0.162148, loss_s1: 0.078080, loss_fp: 0.002308, loss_freq: 0.014652
[15:12:47.903] iteration 3930: loss: 0.107252, loss_s1: 0.055035, loss_fp: 0.002084, loss_freq: 0.016034
[15:12:48.529] iteration 3931: loss: 0.204777, loss_s1: 0.109320, loss_fp: 0.008150, loss_freq: 0.050276
[15:12:49.154] iteration 3932: loss: 0.097195, loss_s1: 0.104032, loss_fp: 0.000558, loss_freq: 0.017569
[15:12:49.778] iteration 3933: loss: 0.080874, loss_s1: 0.038347, loss_fp: 0.001122, loss_freq: 0.012162
[15:12:50.404] iteration 3934: loss: 0.184845, loss_s1: 0.073759, loss_fp: 0.001650, loss_freq: 0.060304
[15:12:51.028] iteration 3935: loss: 0.184357, loss_s1: 0.069220, loss_fp: 0.002497, loss_freq: 0.008586
[15:12:51.651] iteration 3936: loss: 0.138713, loss_s1: 0.062884, loss_fp: 0.000965, loss_freq: 0.057809
[15:12:52.276] iteration 3937: loss: 0.157337, loss_s1: 0.033323, loss_fp: 0.003334, loss_freq: 0.031126
[15:12:52.902] iteration 3938: loss: 0.146102, loss_s1: 0.037280, loss_fp: 0.000665, loss_freq: 0.053102
[15:12:53.527] iteration 3939: loss: 0.193042, loss_s1: 0.117527, loss_fp: 0.003020, loss_freq: 0.058431
[15:12:54.153] iteration 3940: loss: 0.178464, loss_s1: 0.066042, loss_fp: 0.025620, loss_freq: 0.041486
[15:12:54.769] iteration 3941: loss: 0.144893, loss_s1: 0.078451, loss_fp: 0.002965, loss_freq: 0.034692
[15:12:55.398] iteration 3942: loss: 0.158166, loss_s1: 0.137955, loss_fp: 0.005050, loss_freq: 0.055981
[15:12:56.020] iteration 3943: loss: 0.098916, loss_s1: 0.073751, loss_fp: 0.001595, loss_freq: 0.025753
[15:12:56.646] iteration 3944: loss: 0.100361, loss_s1: 0.081047, loss_fp: 0.002052, loss_freq: 0.005583
[15:12:57.275] iteration 3945: loss: 0.103741, loss_s1: 0.042891, loss_fp: 0.001467, loss_freq: 0.030670
[15:12:57.902] iteration 3946: loss: 0.158933, loss_s1: 0.087781, loss_fp: 0.002892, loss_freq: 0.014080
[15:12:58.523] iteration 3947: loss: 0.179340, loss_s1: 0.114038, loss_fp: 0.002296, loss_freq: 0.122294
[15:12:59.145] iteration 3948: loss: 0.161609, loss_s1: 0.037980, loss_fp: 0.001158, loss_freq: 0.025380
[15:12:59.770] iteration 3949: loss: 0.124671, loss_s1: 0.082632, loss_fp: 0.002968, loss_freq: 0.055882
[15:13:00.394] iteration 3950: loss: 0.066063, loss_s1: 0.030281, loss_fp: 0.000878, loss_freq: 0.021487
[15:13:01.019] iteration 3951: loss: 0.190941, loss_s1: 0.043648, loss_fp: 0.000963, loss_freq: 0.043752
[15:13:01.649] iteration 3952: loss: 0.115918, loss_s1: 0.083161, loss_fp: 0.001177, loss_freq: 0.019711
[15:13:02.276] iteration 3953: loss: 0.191808, loss_s1: 0.070666, loss_fp: 0.001149, loss_freq: 0.018330
[15:13:02.903] iteration 3954: loss: 0.115460, loss_s1: 0.026471, loss_fp: 0.001004, loss_freq: 0.007425
[15:13:03.524] iteration 3955: loss: 0.135754, loss_s1: 0.040714, loss_fp: 0.000632, loss_freq: 0.024885
[15:13:04.144] iteration 3956: loss: 0.151412, loss_s1: 0.070933, loss_fp: 0.001018, loss_freq: 0.021102
[15:13:04.764] iteration 3957: loss: 0.203702, loss_s1: 0.096917, loss_fp: 0.001596, loss_freq: 0.036587
[15:13:05.388] iteration 3958: loss: 0.108821, loss_s1: 0.040560, loss_fp: 0.001386, loss_freq: 0.060803
[15:13:06.014] iteration 3959: loss: 0.111239, loss_s1: 0.066899, loss_fp: 0.000978, loss_freq: 0.042160
[15:13:06.637] iteration 3960: loss: 0.087494, loss_s1: 0.040766, loss_fp: 0.002664, loss_freq: 0.020513
[15:13:07.261] iteration 3961: loss: 0.082121, loss_s1: 0.019049, loss_fp: 0.006888, loss_freq: 0.012805
[15:13:07.886] iteration 3962: loss: 0.134298, loss_s1: 0.018153, loss_fp: 0.007852, loss_freq: 0.034857
[15:13:08.506] iteration 3963: loss: 0.167841, loss_s1: 0.089074, loss_fp: 0.000843, loss_freq: 0.032381
[15:13:09.128] iteration 3964: loss: 0.100062, loss_s1: 0.034386, loss_fp: 0.001506, loss_freq: 0.043307
[15:13:09.746] iteration 3965: loss: 0.113198, loss_s1: 0.063601, loss_fp: 0.000597, loss_freq: 0.026510
[15:13:10.366] iteration 3966: loss: 0.140171, loss_s1: 0.043628, loss_fp: 0.001794, loss_freq: 0.024556
[15:13:10.986] iteration 3967: loss: 0.204426, loss_s1: 0.153341, loss_fp: 0.002715, loss_freq: 0.031152
[15:13:11.611] iteration 3968: loss: 0.115010, loss_s1: 0.062848, loss_fp: 0.000483, loss_freq: 0.070423
[15:13:12.227] iteration 3969: loss: 0.216118, loss_s1: 0.031641, loss_fp: 0.001539, loss_freq: 0.036280
[15:13:12.850] iteration 3970: loss: 0.144394, loss_s1: 0.044133, loss_fp: 0.000731, loss_freq: 0.026777
[15:13:13.468] iteration 3971: loss: 0.131114, loss_s1: 0.065298, loss_fp: 0.007587, loss_freq: 0.026677
[15:13:14.086] iteration 3972: loss: 0.154897, loss_s1: 0.063847, loss_fp: 0.003489, loss_freq: 0.064534
[15:13:14.706] iteration 3973: loss: 0.237966, loss_s1: 0.086032, loss_fp: 0.004107, loss_freq: 0.155606
[15:13:15.328] iteration 3974: loss: 0.161184, loss_s1: 0.048535, loss_fp: 0.001287, loss_freq: 0.046368
[15:13:15.952] iteration 3975: loss: 0.147890, loss_s1: 0.010803, loss_fp: 0.000635, loss_freq: 0.014422
[15:13:16.578] iteration 3976: loss: 0.104234, loss_s1: 0.065975, loss_fp: 0.004480, loss_freq: 0.038564
[15:13:17.196] iteration 3977: loss: 0.145680, loss_s1: 0.094080, loss_fp: 0.001307, loss_freq: 0.051286
[15:13:17.820] iteration 3978: loss: 0.108997, loss_s1: 0.064289, loss_fp: 0.000608, loss_freq: 0.056482
[15:13:18.445] iteration 3979: loss: 0.083455, loss_s1: 0.022658, loss_fp: 0.000999, loss_freq: 0.026580
[15:13:19.068] iteration 3980: loss: 0.151070, loss_s1: 0.093004, loss_fp: 0.001908, loss_freq: 0.030840
[15:13:19.686] iteration 3981: loss: 0.141456, loss_s1: 0.057412, loss_fp: 0.004269, loss_freq: 0.052215
[15:13:20.306] iteration 3982: loss: 0.143112, loss_s1: 0.057857, loss_fp: 0.000772, loss_freq: 0.099958
[15:13:20.928] iteration 3983: loss: 0.178259, loss_s1: 0.083248, loss_fp: 0.001607, loss_freq: 0.029557
[15:13:21.555] iteration 3984: loss: 0.178322, loss_s1: 0.112649, loss_fp: 0.003460, loss_freq: 0.113566
[15:13:22.177] iteration 3985: loss: 0.110513, loss_s1: 0.021747, loss_fp: 0.001399, loss_freq: 0.022334
[15:13:22.798] iteration 3986: loss: 0.173728, loss_s1: 0.018563, loss_fp: 0.001174, loss_freq: 0.040156
[15:13:23.421] iteration 3987: loss: 0.163318, loss_s1: 0.109451, loss_fp: 0.000807, loss_freq: 0.071823
[15:13:24.043] iteration 3988: loss: 0.159009, loss_s1: 0.059042, loss_fp: 0.010098, loss_freq: 0.018209
[15:13:24.666] iteration 3989: loss: 0.141416, loss_s1: 0.056226, loss_fp: 0.001905, loss_freq: 0.059636
[15:13:25.287] iteration 3990: loss: 0.154495, loss_s1: 0.033809, loss_fp: 0.000485, loss_freq: 0.021020
[15:13:25.911] iteration 3991: loss: 0.118060, loss_s1: 0.039844, loss_fp: 0.001956, loss_freq: 0.013135
[15:13:26.530] iteration 3992: loss: 0.231288, loss_s1: 0.164626, loss_fp: 0.001196, loss_freq: 0.049853
[15:13:27.153] iteration 3993: loss: 0.104858, loss_s1: 0.055953, loss_fp: 0.015353, loss_freq: 0.033121
[15:13:27.777] iteration 3994: loss: 0.127223, loss_s1: 0.048799, loss_fp: 0.009004, loss_freq: 0.020876
[15:13:28.391] iteration 3995: loss: 0.094465, loss_s1: 0.051903, loss_fp: 0.002240, loss_freq: 0.032684
[15:13:29.014] iteration 3996: loss: 0.169887, loss_s1: 0.162846, loss_fp: 0.000629, loss_freq: 0.067382
[15:13:29.635] iteration 3997: loss: 0.175243, loss_s1: 0.113377, loss_fp: 0.010550, loss_freq: 0.030988
[15:13:30.258] iteration 3998: loss: 0.109252, loss_s1: 0.027025, loss_fp: 0.002336, loss_freq: 0.036367
[15:13:30.875] iteration 3999: loss: 0.114551, loss_s1: 0.042295, loss_fp: 0.000701, loss_freq: 0.047634
[15:13:31.499] iteration 4000: loss: 0.120697, loss_s1: 0.091129, loss_fp: 0.002703, loss_freq: 0.022361
[15:13:34.509] iteration 4000 : mean_dice : 0.556359
[15:13:35.146] iteration 4001: loss: 0.180947, loss_s1: 0.092640, loss_fp: 0.002890, loss_freq: 0.021628
[15:13:35.808] iteration 4002: loss: 0.081149, loss_s1: 0.035016, loss_fp: 0.001388, loss_freq: 0.028733
[15:13:36.431] iteration 4003: loss: 0.155972, loss_s1: 0.110095, loss_fp: 0.009625, loss_freq: 0.071300
[15:13:37.054] iteration 4004: loss: 0.225356, loss_s1: 0.123953, loss_fp: 0.004052, loss_freq: 0.088671
[15:13:37.678] iteration 4005: loss: 0.155422, loss_s1: 0.055718, loss_fp: 0.001953, loss_freq: 0.103614
[15:13:38.301] iteration 4006: loss: 0.165039, loss_s1: 0.036360, loss_fp: 0.000434, loss_freq: 0.051787
[15:13:38.962] iteration 4007: loss: 0.176215, loss_s1: 0.138387, loss_fp: 0.004903, loss_freq: 0.020425
[15:13:39.586] iteration 4008: loss: 0.171120, loss_s1: 0.082768, loss_fp: 0.002104, loss_freq: 0.009545
[15:13:40.210] iteration 4009: loss: 0.090727, loss_s1: 0.027472, loss_fp: 0.001523, loss_freq: 0.001432
[15:13:40.866] iteration 4010: loss: 0.141741, loss_s1: 0.066817, loss_fp: 0.009816, loss_freq: 0.022749
[15:13:41.492] iteration 4011: loss: 0.080125, loss_s1: 0.048902, loss_fp: 0.001882, loss_freq: 0.032669
[15:13:42.120] iteration 4012: loss: 0.089105, loss_s1: 0.056248, loss_fp: 0.000826, loss_freq: 0.031340
[15:13:42.742] iteration 4013: loss: 0.107511, loss_s1: 0.036765, loss_fp: 0.002243, loss_freq: 0.029561
[15:13:43.362] iteration 4014: loss: 0.122982, loss_s1: 0.059950, loss_fp: 0.000901, loss_freq: 0.017146
[15:13:43.984] iteration 4015: loss: 0.147028, loss_s1: 0.127326, loss_fp: 0.001076, loss_freq: 0.035775
[15:13:44.608] iteration 4016: loss: 0.214396, loss_s1: 0.139290, loss_fp: 0.009882, loss_freq: 0.097639
[15:13:45.233] iteration 4017: loss: 0.116315, loss_s1: 0.047133, loss_fp: 0.031095, loss_freq: 0.013987
[15:13:45.856] iteration 4018: loss: 0.165557, loss_s1: 0.070508, loss_fp: 0.002345, loss_freq: 0.010800
[15:13:46.484] iteration 4019: loss: 0.071595, loss_s1: 0.039830, loss_fp: 0.001472, loss_freq: 0.011501
[15:13:47.107] iteration 4020: loss: 0.088564, loss_s1: 0.034104, loss_fp: 0.001088, loss_freq: 0.034561
[15:13:47.743] iteration 4021: loss: 0.175089, loss_s1: 0.030661, loss_fp: 0.005114, loss_freq: 0.037980
[15:13:48.366] iteration 4022: loss: 0.197949, loss_s1: 0.040040, loss_fp: 0.018139, loss_freq: 0.116035
[15:13:48.996] iteration 4023: loss: 0.140073, loss_s1: 0.056516, loss_fp: 0.001020, loss_freq: 0.008568
[15:13:49.621] iteration 4024: loss: 0.120750, loss_s1: 0.012117, loss_fp: 0.001294, loss_freq: 0.031371
[15:13:50.243] iteration 4025: loss: 0.128691, loss_s1: 0.039450, loss_fp: 0.007303, loss_freq: 0.011457
[15:13:51.191] iteration 4026: loss: 0.120557, loss_s1: 0.037440, loss_fp: 0.001161, loss_freq: 0.021336
[15:13:51.815] iteration 4027: loss: 0.137696, loss_s1: 0.103443, loss_fp: 0.002939, loss_freq: 0.013852
[15:13:52.437] iteration 4028: loss: 0.103464, loss_s1: 0.043226, loss_fp: 0.007546, loss_freq: 0.026406
[15:13:53.061] iteration 4029: loss: 0.149958, loss_s1: 0.094698, loss_fp: 0.001086, loss_freq: 0.013855
[15:13:53.719] iteration 4030: loss: 0.138132, loss_s1: 0.075822, loss_fp: 0.001122, loss_freq: 0.037767
[15:13:54.346] iteration 4031: loss: 0.179308, loss_s1: 0.057365, loss_fp: 0.001189, loss_freq: 0.055096
[15:13:54.974] iteration 4032: loss: 0.089405, loss_s1: 0.019426, loss_fp: 0.000779, loss_freq: 0.005602
[15:13:55.596] iteration 4033: loss: 0.127614, loss_s1: 0.074093, loss_fp: 0.001183, loss_freq: 0.069070
[15:13:56.221] iteration 4034: loss: 0.111965, loss_s1: 0.080194, loss_fp: 0.021105, loss_freq: 0.016896
[15:13:56.848] iteration 4035: loss: 0.155850, loss_s1: 0.140310, loss_fp: 0.000595, loss_freq: 0.040626
[15:13:57.478] iteration 4036: loss: 0.101941, loss_s1: 0.021061, loss_fp: 0.002128, loss_freq: 0.011593
[15:13:58.169] iteration 4037: loss: 0.178364, loss_s1: 0.080875, loss_fp: 0.002065, loss_freq: 0.059825
[15:13:58.825] iteration 4038: loss: 0.164450, loss_s1: 0.111896, loss_fp: 0.033344, loss_freq: 0.094209
[15:13:59.500] iteration 4039: loss: 0.168974, loss_s1: 0.064498, loss_fp: 0.001563, loss_freq: 0.006945
[15:14:00.159] iteration 4040: loss: 0.081689, loss_s1: 0.041963, loss_fp: 0.001357, loss_freq: 0.015259
[15:14:00.789] iteration 4041: loss: 0.178677, loss_s1: 0.089836, loss_fp: 0.006818, loss_freq: 0.072928
[15:14:01.417] iteration 4042: loss: 0.138652, loss_s1: 0.055217, loss_fp: 0.000912, loss_freq: 0.013744
[15:14:02.041] iteration 4043: loss: 0.104464, loss_s1: 0.013026, loss_fp: 0.010258, loss_freq: 0.034712
[15:14:02.665] iteration 4044: loss: 0.126545, loss_s1: 0.045905, loss_fp: 0.002056, loss_freq: 0.023865
[15:14:03.283] iteration 4045: loss: 0.113193, loss_s1: 0.048482, loss_fp: 0.001988, loss_freq: 0.037298
[15:14:03.910] iteration 4046: loss: 0.126178, loss_s1: 0.071281, loss_fp: 0.001112, loss_freq: 0.011815
[15:14:04.530] iteration 4047: loss: 0.133636, loss_s1: 0.066332, loss_fp: 0.001214, loss_freq: 0.018376
[15:14:05.150] iteration 4048: loss: 0.178218, loss_s1: 0.036760, loss_fp: 0.001225, loss_freq: 0.016870
[15:14:05.771] iteration 4049: loss: 0.281949, loss_s1: 0.251089, loss_fp: 0.001483, loss_freq: 0.227200
[15:14:06.395] iteration 4050: loss: 0.065161, loss_s1: 0.015573, loss_fp: 0.000871, loss_freq: 0.008962
[15:14:07.021] iteration 4051: loss: 0.112414, loss_s1: 0.060695, loss_fp: 0.001243, loss_freq: 0.039353
[15:14:07.648] iteration 4052: loss: 0.112275, loss_s1: 0.058224, loss_fp: 0.000667, loss_freq: 0.029020
[15:14:08.272] iteration 4053: loss: 0.134059, loss_s1: 0.031096, loss_fp: 0.000644, loss_freq: 0.032996
[15:14:08.897] iteration 4054: loss: 0.104216, loss_s1: 0.073977, loss_fp: 0.002848, loss_freq: 0.017325
[15:14:09.519] iteration 4055: loss: 0.105790, loss_s1: 0.025997, loss_fp: 0.001445, loss_freq: 0.011163
[15:14:10.138] iteration 4056: loss: 0.128621, loss_s1: 0.106945, loss_fp: 0.003888, loss_freq: 0.004345
[15:14:10.759] iteration 4057: loss: 0.167580, loss_s1: 0.060419, loss_fp: 0.001643, loss_freq: 0.011535
[15:14:11.382] iteration 4058: loss: 0.091222, loss_s1: 0.056569, loss_fp: 0.003695, loss_freq: 0.023669
[15:14:12.002] iteration 4059: loss: 0.084587, loss_s1: 0.047410, loss_fp: 0.004768, loss_freq: 0.010794
[15:14:12.625] iteration 4060: loss: 0.213573, loss_s1: 0.040668, loss_fp: 0.001064, loss_freq: 0.015864
[15:14:13.270] iteration 4061: loss: 0.124429, loss_s1: 0.076810, loss_fp: 0.004752, loss_freq: 0.057970
[15:14:13.891] iteration 4062: loss: 0.118301, loss_s1: 0.034750, loss_fp: 0.011193, loss_freq: 0.023419
[15:14:14.511] iteration 4063: loss: 0.141568, loss_s1: 0.055018, loss_fp: 0.000770, loss_freq: 0.046399
[15:14:15.132] iteration 4064: loss: 0.116253, loss_s1: 0.037740, loss_fp: 0.005301, loss_freq: 0.013684
[15:14:15.750] iteration 4065: loss: 0.128594, loss_s1: 0.065327, loss_fp: 0.001041, loss_freq: 0.041361
[15:14:16.372] iteration 4066: loss: 0.166531, loss_s1: 0.077239, loss_fp: 0.000871, loss_freq: 0.035282
[15:14:16.994] iteration 4067: loss: 0.068662, loss_s1: 0.020972, loss_fp: 0.000873, loss_freq: 0.022430
[15:14:17.618] iteration 4068: loss: 0.096428, loss_s1: 0.050120, loss_fp: 0.001206, loss_freq: 0.024770
[15:14:18.241] iteration 4069: loss: 0.129346, loss_s1: 0.107066, loss_fp: 0.003631, loss_freq: 0.035372
[15:14:18.862] iteration 4070: loss: 0.131490, loss_s1: 0.039680, loss_fp: 0.000925, loss_freq: 0.057036
[15:14:19.490] iteration 4071: loss: 0.158258, loss_s1: 0.102688, loss_fp: 0.001019, loss_freq: 0.040614
[15:14:20.118] iteration 4072: loss: 0.104459, loss_s1: 0.026308, loss_fp: 0.002472, loss_freq: 0.011543
[15:14:20.740] iteration 4073: loss: 0.099788, loss_s1: 0.053193, loss_fp: 0.000753, loss_freq: 0.015141
[15:14:21.367] iteration 4074: loss: 0.170421, loss_s1: 0.046345, loss_fp: 0.002269, loss_freq: 0.032603
[15:14:21.995] iteration 4075: loss: 0.126211, loss_s1: 0.104250, loss_fp: 0.001303, loss_freq: 0.016292
[15:14:22.619] iteration 4076: loss: 0.088039, loss_s1: 0.037362, loss_fp: 0.001382, loss_freq: 0.038789
[15:14:23.240] iteration 4077: loss: 0.173789, loss_s1: 0.032228, loss_fp: 0.006211, loss_freq: 0.034672
[15:14:23.861] iteration 4078: loss: 0.137107, loss_s1: 0.076738, loss_fp: 0.001567, loss_freq: 0.053181
[15:14:24.478] iteration 4079: loss: 0.209145, loss_s1: 0.139072, loss_fp: 0.000775, loss_freq: 0.026898
[15:14:25.103] iteration 4080: loss: 0.130069, loss_s1: 0.050703, loss_fp: 0.000533, loss_freq: 0.011169
[15:14:25.727] iteration 4081: loss: 0.198222, loss_s1: 0.215088, loss_fp: 0.001016, loss_freq: 0.050421
[15:14:26.352] iteration 4082: loss: 0.137890, loss_s1: 0.042070, loss_fp: 0.000543, loss_freq: 0.034677
[15:14:26.972] iteration 4083: loss: 0.158027, loss_s1: 0.043923, loss_fp: 0.005987, loss_freq: 0.037967
[15:14:27.595] iteration 4084: loss: 0.087283, loss_s1: 0.033503, loss_fp: 0.001775, loss_freq: 0.037999
[15:14:28.217] iteration 4085: loss: 0.101427, loss_s1: 0.075871, loss_fp: 0.003249, loss_freq: 0.025158
[15:14:28.841] iteration 4086: loss: 0.079411, loss_s1: 0.044588, loss_fp: 0.000670, loss_freq: 0.022563
[15:14:29.456] iteration 4087: loss: 0.153934, loss_s1: 0.146604, loss_fp: 0.000844, loss_freq: 0.024730
[15:14:30.087] iteration 4088: loss: 0.124824, loss_s1: 0.065315, loss_fp: 0.000935, loss_freq: 0.030310
[15:14:30.706] iteration 4089: loss: 0.183884, loss_s1: 0.072718, loss_fp: 0.001939, loss_freq: 0.029045
[15:14:31.327] iteration 4090: loss: 0.083326, loss_s1: 0.029135, loss_fp: 0.004603, loss_freq: 0.010854
[15:14:31.948] iteration 4091: loss: 0.122637, loss_s1: 0.060830, loss_fp: 0.001094, loss_freq: 0.049243
[15:14:32.569] iteration 4092: loss: 0.168986, loss_s1: 0.070994, loss_fp: 0.000904, loss_freq: 0.054347
[15:14:33.189] iteration 4093: loss: 0.063179, loss_s1: 0.048256, loss_fp: 0.001538, loss_freq: 0.015994
[15:14:33.811] iteration 4094: loss: 0.102104, loss_s1: 0.038233, loss_fp: 0.002021, loss_freq: 0.022979
[15:14:34.435] iteration 4095: loss: 0.185443, loss_s1: 0.081939, loss_fp: 0.003718, loss_freq: 0.021058
[15:14:35.054] iteration 4096: loss: 0.158161, loss_s1: 0.175245, loss_fp: 0.002113, loss_freq: 0.031245
[15:14:35.676] iteration 4097: loss: 0.153262, loss_s1: 0.072415, loss_fp: 0.003083, loss_freq: 0.051506
[15:14:36.295] iteration 4098: loss: 0.121949, loss_s1: 0.024026, loss_fp: 0.003395, loss_freq: 0.025888
[15:14:36.920] iteration 4099: loss: 0.122556, loss_s1: 0.021426, loss_fp: 0.000979, loss_freq: 0.057986
[15:14:37.542] iteration 4100: loss: 0.123449, loss_s1: 0.040502, loss_fp: 0.006653, loss_freq: 0.066267
[15:14:38.159] iteration 4101: loss: 0.145902, loss_s1: 0.060109, loss_fp: 0.001853, loss_freq: 0.045473
[15:14:38.777] iteration 4102: loss: 0.124750, loss_s1: 0.063488, loss_fp: 0.003533, loss_freq: 0.077225
[15:14:39.393] iteration 4103: loss: 0.149605, loss_s1: 0.092170, loss_fp: 0.003226, loss_freq: 0.089910
[15:14:40.017] iteration 4104: loss: 0.090374, loss_s1: 0.046248, loss_fp: 0.001943, loss_freq: 0.028088
[15:14:40.642] iteration 4105: loss: 0.097831, loss_s1: 0.025220, loss_fp: 0.010017, loss_freq: 0.038630
[15:14:41.264] iteration 4106: loss: 0.125518, loss_s1: 0.089723, loss_fp: 0.011313, loss_freq: 0.041681
[15:14:41.883] iteration 4107: loss: 0.145734, loss_s1: 0.070946, loss_fp: 0.001137, loss_freq: 0.018713
[15:14:42.503] iteration 4108: loss: 0.153902, loss_s1: 0.095774, loss_fp: 0.002849, loss_freq: 0.099608
[15:14:43.120] iteration 4109: loss: 0.136507, loss_s1: 0.029343, loss_fp: 0.003232, loss_freq: 0.038848
[15:14:43.739] iteration 4110: loss: 0.110560, loss_s1: 0.073180, loss_fp: 0.023601, loss_freq: 0.028521
[15:14:44.364] iteration 4111: loss: 0.088226, loss_s1: 0.069150, loss_fp: 0.002605, loss_freq: 0.022015
[15:14:44.987] iteration 4112: loss: 0.190188, loss_s1: 0.064824, loss_fp: 0.009815, loss_freq: 0.040514
[15:14:45.613] iteration 4113: loss: 0.106402, loss_s1: 0.068459, loss_fp: 0.002906, loss_freq: 0.023821
[15:14:46.237] iteration 4114: loss: 0.131531, loss_s1: 0.064643, loss_fp: 0.005181, loss_freq: 0.014844
[15:14:46.863] iteration 4115: loss: 0.180403, loss_s1: 0.045772, loss_fp: 0.002691, loss_freq: 0.028421
[15:14:47.486] iteration 4116: loss: 0.186293, loss_s1: 0.065247, loss_fp: 0.006010, loss_freq: 0.013398
[15:14:48.108] iteration 4117: loss: 0.154925, loss_s1: 0.079206, loss_fp: 0.001505, loss_freq: 0.013024
[15:14:48.729] iteration 4118: loss: 0.211504, loss_s1: 0.079150, loss_fp: 0.001865, loss_freq: 0.020201
[15:14:49.348] iteration 4119: loss: 0.127913, loss_s1: 0.056318, loss_fp: 0.001194, loss_freq: 0.031853
[15:14:49.967] iteration 4120: loss: 0.082535, loss_s1: 0.054505, loss_fp: 0.000812, loss_freq: 0.016858
[15:14:50.588] iteration 4121: loss: 0.101520, loss_s1: 0.061616, loss_fp: 0.000874, loss_freq: 0.042848
[15:14:51.212] iteration 4122: loss: 0.160613, loss_s1: 0.133633, loss_fp: 0.004700, loss_freq: 0.017624
[15:14:51.834] iteration 4123: loss: 0.111251, loss_s1: 0.026621, loss_fp: 0.001014, loss_freq: 0.016705
[15:14:52.455] iteration 4124: loss: 0.143284, loss_s1: 0.094458, loss_fp: 0.000434, loss_freq: 0.005775
[15:14:53.081] iteration 4125: loss: 0.152120, loss_s1: 0.062254, loss_fp: 0.002612, loss_freq: 0.048855
[15:14:53.701] iteration 4126: loss: 0.114408, loss_s1: 0.030722, loss_fp: 0.000803, loss_freq: 0.037466
[15:14:54.322] iteration 4127: loss: 0.106260, loss_s1: 0.052065, loss_fp: 0.001552, loss_freq: 0.002803
[15:14:54.944] iteration 4128: loss: 0.259865, loss_s1: 0.168623, loss_fp: 0.001529, loss_freq: 0.099052
[15:14:55.563] iteration 4129: loss: 0.124301, loss_s1: 0.083651, loss_fp: 0.001594, loss_freq: 0.042591
[15:14:56.186] iteration 4130: loss: 0.177338, loss_s1: 0.045517, loss_fp: 0.001594, loss_freq: 0.065294
[15:14:56.807] iteration 4131: loss: 0.164965, loss_s1: 0.048893, loss_fp: 0.006770, loss_freq: 0.025426
[15:14:57.427] iteration 4132: loss: 0.101566, loss_s1: 0.049426, loss_fp: 0.000867, loss_freq: 0.012711
[15:14:58.046] iteration 4133: loss: 0.192136, loss_s1: 0.106446, loss_fp: 0.001461, loss_freq: 0.131591
[15:14:58.670] iteration 4134: loss: 0.246871, loss_s1: 0.165496, loss_fp: 0.000360, loss_freq: 0.144917
[15:14:59.290] iteration 4135: loss: 0.136954, loss_s1: 0.047116, loss_fp: 0.001080, loss_freq: 0.026788
[15:14:59.907] iteration 4136: loss: 0.173697, loss_s1: 0.064447, loss_fp: 0.001350, loss_freq: 0.047746
[15:15:00.524] iteration 4137: loss: 0.097268, loss_s1: 0.070968, loss_fp: 0.001025, loss_freq: 0.031621
[15:15:01.160] iteration 4138: loss: 0.222912, loss_s1: 0.166941, loss_fp: 0.000935, loss_freq: 0.110118
[15:15:01.784] iteration 4139: loss: 0.116701, loss_s1: 0.047945, loss_fp: 0.003789, loss_freq: 0.050819
[15:15:02.406] iteration 4140: loss: 0.110005, loss_s1: 0.043032, loss_fp: 0.003523, loss_freq: 0.026476
[15:15:03.029] iteration 4141: loss: 0.223614, loss_s1: 0.121800, loss_fp: 0.001374, loss_freq: 0.054143
[15:15:03.649] iteration 4142: loss: 0.110784, loss_s1: 0.025405, loss_fp: 0.000745, loss_freq: 0.050601
[15:15:04.268] iteration 4143: loss: 0.154913, loss_s1: 0.077919, loss_fp: 0.002568, loss_freq: 0.088902
[15:15:04.894] iteration 4144: loss: 0.172169, loss_s1: 0.046450, loss_fp: 0.003465, loss_freq: 0.063654
[15:15:05.516] iteration 4145: loss: 0.200532, loss_s1: 0.142625, loss_fp: 0.004419, loss_freq: 0.146447
[15:15:06.141] iteration 4146: loss: 0.103291, loss_s1: 0.060251, loss_fp: 0.000892, loss_freq: 0.035677
[15:15:06.762] iteration 4147: loss: 0.154803, loss_s1: 0.032212, loss_fp: 0.000739, loss_freq: 0.011460
[15:15:07.384] iteration 4148: loss: 0.090331, loss_s1: 0.011436, loss_fp: 0.008807, loss_freq: 0.013369
[15:15:08.007] iteration 4149: loss: 0.087792, loss_s1: 0.022246, loss_fp: 0.000829, loss_freq: 0.016745
[15:15:08.628] iteration 4150: loss: 0.153710, loss_s1: 0.063841, loss_fp: 0.000891, loss_freq: 0.041173
[15:15:09.251] iteration 4151: loss: 0.146565, loss_s1: 0.048483, loss_fp: 0.003476, loss_freq: 0.007816
[15:15:09.872] iteration 4152: loss: 0.149589, loss_s1: 0.075635, loss_fp: 0.000894, loss_freq: 0.010177
[15:15:10.499] iteration 4153: loss: 0.221562, loss_s1: 0.107211, loss_fp: 0.001313, loss_freq: 0.055909
[15:15:11.126] iteration 4154: loss: 0.091710, loss_s1: 0.064499, loss_fp: 0.001400, loss_freq: 0.024613
[15:15:11.748] iteration 4155: loss: 0.090468, loss_s1: 0.057113, loss_fp: 0.001984, loss_freq: 0.011527
[15:15:12.365] iteration 4156: loss: 0.119427, loss_s1: 0.080513, loss_fp: 0.002406, loss_freq: 0.054513
[15:15:12.987] iteration 4157: loss: 0.092356, loss_s1: 0.021467, loss_fp: 0.004257, loss_freq: 0.037345
[15:15:13.608] iteration 4158: loss: 0.124170, loss_s1: 0.052298, loss_fp: 0.011959, loss_freq: 0.022115
[15:15:14.231] iteration 4159: loss: 0.191807, loss_s1: 0.090800, loss_fp: 0.015623, loss_freq: 0.063548
[15:15:14.857] iteration 4160: loss: 0.132533, loss_s1: 0.104737, loss_fp: 0.001376, loss_freq: 0.051832
[15:15:15.479] iteration 4161: loss: 0.110484, loss_s1: 0.085793, loss_fp: 0.002009, loss_freq: 0.026245
[15:15:16.103] iteration 4162: loss: 0.167471, loss_s1: 0.066591, loss_fp: 0.009408, loss_freq: 0.057975
[15:15:16.723] iteration 4163: loss: 0.109200, loss_s1: 0.047704, loss_fp: 0.002037, loss_freq: 0.063386
[15:15:17.348] iteration 4164: loss: 0.110366, loss_s1: 0.062031, loss_fp: 0.001986, loss_freq: 0.024340
[15:15:17.970] iteration 4165: loss: 0.173104, loss_s1: 0.058608, loss_fp: 0.004342, loss_freq: 0.074852
[15:15:18.591] iteration 4166: loss: 0.173999, loss_s1: 0.149961, loss_fp: 0.002345, loss_freq: 0.054051
[15:15:19.209] iteration 4167: loss: 0.146776, loss_s1: 0.043894, loss_fp: 0.002177, loss_freq: 0.023372
[15:15:19.841] iteration 4168: loss: 0.109318, loss_s1: 0.012705, loss_fp: 0.001500, loss_freq: 0.047859
[15:15:20.472] iteration 4169: loss: 0.129952, loss_s1: 0.072309, loss_fp: 0.002853, loss_freq: 0.008899
[15:15:21.095] iteration 4170: loss: 0.077314, loss_s1: 0.024582, loss_fp: 0.003502, loss_freq: 0.002771
[15:15:21.715] iteration 4171: loss: 0.146449, loss_s1: 0.023719, loss_fp: 0.005407, loss_freq: 0.024141
[15:15:22.356] iteration 4172: loss: 0.098419, loss_s1: 0.060742, loss_fp: 0.001115, loss_freq: 0.048858
[15:15:22.972] iteration 4173: loss: 0.108421, loss_s1: 0.064248, loss_fp: 0.001368, loss_freq: 0.029798
[15:15:23.590] iteration 4174: loss: 0.079281, loss_s1: 0.031920, loss_fp: 0.001068, loss_freq: 0.017932
[15:15:24.213] iteration 4175: loss: 0.134612, loss_s1: 0.095117, loss_fp: 0.003423, loss_freq: 0.049107
[15:15:24.836] iteration 4176: loss: 0.162959, loss_s1: 0.063349, loss_fp: 0.000967, loss_freq: 0.031247
[15:15:25.465] iteration 4177: loss: 0.171841, loss_s1: 0.123806, loss_fp: 0.001750, loss_freq: 0.113440
[15:15:26.088] iteration 4178: loss: 0.081811, loss_s1: 0.046392, loss_fp: 0.001040, loss_freq: 0.010281
[15:15:26.713] iteration 4179: loss: 0.143552, loss_s1: 0.044525, loss_fp: 0.001833, loss_freq: 0.036656
[15:15:27.332] iteration 4180: loss: 0.094434, loss_s1: 0.030839, loss_fp: 0.006338, loss_freq: 0.028317
[15:15:27.953] iteration 4181: loss: 0.085030, loss_s1: 0.013160, loss_fp: 0.001956, loss_freq: 0.045039
[15:15:28.576] iteration 4182: loss: 0.201846, loss_s1: 0.106648, loss_fp: 0.002523, loss_freq: 0.015500
[15:15:29.204] iteration 4183: loss: 0.191065, loss_s1: 0.130979, loss_fp: 0.004913, loss_freq: 0.055307
[15:15:29.827] iteration 4184: loss: 0.199591, loss_s1: 0.088444, loss_fp: 0.002995, loss_freq: 0.068397
[15:15:30.446] iteration 4185: loss: 0.191457, loss_s1: 0.050179, loss_fp: 0.000805, loss_freq: 0.048587
[15:15:31.067] iteration 4186: loss: 0.080485, loss_s1: 0.010984, loss_fp: 0.001002, loss_freq: 0.025729
[15:15:32.041] iteration 4187: loss: 0.190098, loss_s1: 0.096747, loss_fp: 0.004198, loss_freq: 0.042471
[15:15:32.667] iteration 4188: loss: 0.162623, loss_s1: 0.113702, loss_fp: 0.000866, loss_freq: 0.045756
[15:15:33.290] iteration 4189: loss: 0.133559, loss_s1: 0.065830, loss_fp: 0.000545, loss_freq: 0.026060
[15:15:33.912] iteration 4190: loss: 0.125580, loss_s1: 0.026429, loss_fp: 0.000599, loss_freq: 0.054648
[15:15:34.535] iteration 4191: loss: 0.128298, loss_s1: 0.061544, loss_fp: 0.015535, loss_freq: 0.022100
[15:15:35.160] iteration 4192: loss: 0.165723, loss_s1: 0.050783, loss_fp: 0.004534, loss_freq: 0.007558
[15:15:35.786] iteration 4193: loss: 0.059122, loss_s1: 0.016187, loss_fp: 0.000703, loss_freq: 0.002382
[15:15:36.412] iteration 4194: loss: 0.107621, loss_s1: 0.051636, loss_fp: 0.003664, loss_freq: 0.067261
[15:15:37.038] iteration 4195: loss: 0.154243, loss_s1: 0.115498, loss_fp: 0.004139, loss_freq: 0.027246
[15:15:37.661] iteration 4196: loss: 0.158565, loss_s1: 0.118984, loss_fp: 0.001777, loss_freq: 0.063500
[15:15:38.285] iteration 4197: loss: 0.081132, loss_s1: 0.027354, loss_fp: 0.001082, loss_freq: 0.007381
[15:15:38.902] iteration 4198: loss: 0.117720, loss_s1: 0.024300, loss_fp: 0.000594, loss_freq: 0.029993
[15:15:39.524] iteration 4199: loss: 0.084931, loss_s1: 0.045492, loss_fp: 0.014975, loss_freq: 0.037311
[15:15:40.144] iteration 4200: loss: 0.174895, loss_s1: 0.120717, loss_fp: 0.003808, loss_freq: 0.028163
[15:15:43.369] iteration 4200 : mean_dice : 0.593818
[15:15:44.033] iteration 4201: loss: 0.103532, loss_s1: 0.091581, loss_fp: 0.001530, loss_freq: 0.018701
[15:15:44.657] iteration 4202: loss: 0.137892, loss_s1: 0.084533, loss_fp: 0.002563, loss_freq: 0.088332
[15:15:45.281] iteration 4203: loss: 0.152536, loss_s1: 0.057266, loss_fp: 0.001639, loss_freq: 0.021629
[15:15:45.901] iteration 4204: loss: 0.116670, loss_s1: 0.091675, loss_fp: 0.025241, loss_freq: 0.019990
[15:15:46.522] iteration 4205: loss: 0.168611, loss_s1: 0.087409, loss_fp: 0.000822, loss_freq: 0.028257
[15:15:47.141] iteration 4206: loss: 0.121729, loss_s1: 0.079690, loss_fp: 0.005404, loss_freq: 0.019579
[15:15:47.762] iteration 4207: loss: 0.091089, loss_s1: 0.050563, loss_fp: 0.001031, loss_freq: 0.009684
[15:15:48.384] iteration 4208: loss: 0.129202, loss_s1: 0.092648, loss_fp: 0.001145, loss_freq: 0.026502
[15:15:49.002] iteration 4209: loss: 0.169068, loss_s1: 0.035906, loss_fp: 0.003071, loss_freq: 0.028030
[15:15:49.627] iteration 4210: loss: 0.184577, loss_s1: 0.128775, loss_fp: 0.009750, loss_freq: 0.149015
[15:15:50.250] iteration 4211: loss: 0.057914, loss_s1: 0.008759, loss_fp: 0.001650, loss_freq: 0.014568
[15:15:50.874] iteration 4212: loss: 0.123562, loss_s1: 0.060459, loss_fp: 0.002762, loss_freq: 0.041222
[15:15:51.497] iteration 4213: loss: 0.112714, loss_s1: 0.031960, loss_fp: 0.000724, loss_freq: 0.063139
[15:15:52.120] iteration 4214: loss: 0.156230, loss_s1: 0.058109, loss_fp: 0.009507, loss_freq: 0.033473
[15:15:52.747] iteration 4215: loss: 0.085413, loss_s1: 0.057716, loss_fp: 0.009908, loss_freq: 0.015498
[15:15:53.372] iteration 4216: loss: 0.077228, loss_s1: 0.041500, loss_fp: 0.001361, loss_freq: 0.011882
[15:15:54.000] iteration 4217: loss: 0.091282, loss_s1: 0.064757, loss_fp: 0.000848, loss_freq: 0.010394
[15:15:54.627] iteration 4218: loss: 0.166726, loss_s1: 0.029233, loss_fp: 0.000680, loss_freq: 0.017295
[15:15:55.246] iteration 4219: loss: 0.086846, loss_s1: 0.039021, loss_fp: 0.000665, loss_freq: 0.031945
[15:15:55.872] iteration 4220: loss: 0.090166, loss_s1: 0.056594, loss_fp: 0.001588, loss_freq: 0.027845
[15:15:56.495] iteration 4221: loss: 0.171207, loss_s1: 0.044780, loss_fp: 0.000937, loss_freq: 0.014482
[15:15:57.121] iteration 4222: loss: 0.152066, loss_s1: 0.060330, loss_fp: 0.001717, loss_freq: 0.042019
[15:15:57.743] iteration 4223: loss: 0.156144, loss_s1: 0.116478, loss_fp: 0.002555, loss_freq: 0.042601
[15:15:58.362] iteration 4224: loss: 0.115497, loss_s1: 0.084438, loss_fp: 0.002230, loss_freq: 0.051185
[15:15:58.985] iteration 4225: loss: 0.179223, loss_s1: 0.077994, loss_fp: 0.001737, loss_freq: 0.053088
[15:15:59.603] iteration 4226: loss: 0.168663, loss_s1: 0.109638, loss_fp: 0.002088, loss_freq: 0.045291
[15:16:00.227] iteration 4227: loss: 0.172275, loss_s1: 0.062248, loss_fp: 0.002928, loss_freq: 0.084596
[15:16:00.852] iteration 4228: loss: 0.082291, loss_s1: 0.071101, loss_fp: 0.002584, loss_freq: 0.006487
[15:16:01.475] iteration 4229: loss: 0.119101, loss_s1: 0.068679, loss_fp: 0.008548, loss_freq: 0.037132
[15:16:02.094] iteration 4230: loss: 0.132742, loss_s1: 0.099279, loss_fp: 0.013712, loss_freq: 0.020700
[15:16:02.749] iteration 4231: loss: 0.118248, loss_s1: 0.028183, loss_fp: 0.000946, loss_freq: 0.092154
[15:16:03.412] iteration 4232: loss: 0.129241, loss_s1: 0.091211, loss_fp: 0.004318, loss_freq: 0.016904
[15:16:04.103] iteration 4233: loss: 0.151646, loss_s1: 0.054871, loss_fp: 0.000849, loss_freq: 0.032910
[15:16:04.734] iteration 4234: loss: 0.076438, loss_s1: 0.037008, loss_fp: 0.001497, loss_freq: 0.025894
[15:16:05.364] iteration 4235: loss: 0.191259, loss_s1: 0.136479, loss_fp: 0.001082, loss_freq: 0.022067
[15:16:05.997] iteration 4236: loss: 0.127745, loss_s1: 0.043053, loss_fp: 0.001323, loss_freq: 0.071266
[15:16:06.622] iteration 4237: loss: 0.115022, loss_s1: 0.126819, loss_fp: 0.000933, loss_freq: 0.010657
[15:16:07.250] iteration 4238: loss: 0.139552, loss_s1: 0.022945, loss_fp: 0.002396, loss_freq: 0.025867
[15:16:07.870] iteration 4239: loss: 0.121550, loss_s1: 0.074528, loss_fp: 0.005955, loss_freq: 0.050057
[15:16:08.489] iteration 4240: loss: 0.173863, loss_s1: 0.109600, loss_fp: 0.002020, loss_freq: 0.024278
[15:16:09.114] iteration 4241: loss: 0.134207, loss_s1: 0.111578, loss_fp: 0.001234, loss_freq: 0.019611
[15:16:09.742] iteration 4242: loss: 0.187932, loss_s1: 0.201541, loss_fp: 0.028264, loss_freq: 0.027655
[15:16:10.366] iteration 4243: loss: 0.121161, loss_s1: 0.026863, loss_fp: 0.000318, loss_freq: 0.020424
[15:16:10.987] iteration 4244: loss: 0.170026, loss_s1: 0.107010, loss_fp: 0.003107, loss_freq: 0.032532
[15:16:11.612] iteration 4245: loss: 0.082731, loss_s1: 0.060116, loss_fp: 0.003905, loss_freq: 0.015790
[15:16:12.239] iteration 4246: loss: 0.099961, loss_s1: 0.067977, loss_fp: 0.000978, loss_freq: 0.021315
[15:16:12.864] iteration 4247: loss: 0.063648, loss_s1: 0.022415, loss_fp: 0.002044, loss_freq: 0.019828
[15:16:13.489] iteration 4248: loss: 0.136729, loss_s1: 0.086298, loss_fp: 0.004952, loss_freq: 0.008213
[15:16:14.112] iteration 4249: loss: 0.137106, loss_s1: 0.081789, loss_fp: 0.002100, loss_freq: 0.035553
[15:16:14.748] iteration 4250: loss: 0.103116, loss_s1: 0.056739, loss_fp: 0.002876, loss_freq: 0.038532
[15:16:15.367] iteration 4251: loss: 0.083509, loss_s1: 0.022873, loss_fp: 0.003747, loss_freq: 0.005461
[15:16:15.989] iteration 4252: loss: 0.161688, loss_s1: 0.130610, loss_fp: 0.004956, loss_freq: 0.054221
[15:16:16.614] iteration 4253: loss: 0.163446, loss_s1: 0.048078, loss_fp: 0.001000, loss_freq: 0.063188
[15:16:17.239] iteration 4254: loss: 0.130836, loss_s1: 0.119745, loss_fp: 0.008806, loss_freq: 0.057822
[15:16:17.861] iteration 4255: loss: 0.103477, loss_s1: 0.047740, loss_fp: 0.000759, loss_freq: 0.028974
[15:16:18.485] iteration 4256: loss: 0.157451, loss_s1: 0.057968, loss_fp: 0.004051, loss_freq: 0.028198
[15:16:19.109] iteration 4257: loss: 0.121874, loss_s1: 0.016234, loss_fp: 0.001534, loss_freq: 0.025815
[15:16:19.729] iteration 4258: loss: 0.152463, loss_s1: 0.082432, loss_fp: 0.003398, loss_freq: 0.088919
[15:16:20.350] iteration 4259: loss: 0.106501, loss_s1: 0.018318, loss_fp: 0.000569, loss_freq: 0.051999
[15:16:20.976] iteration 4260: loss: 0.130331, loss_s1: 0.020670, loss_fp: 0.001768, loss_freq: 0.052052
[15:16:21.601] iteration 4261: loss: 0.139415, loss_s1: 0.093302, loss_fp: 0.001030, loss_freq: 0.068769
[15:16:22.225] iteration 4262: loss: 0.172303, loss_s1: 0.089478, loss_fp: 0.003665, loss_freq: 0.061383
[15:16:22.848] iteration 4263: loss: 0.130718, loss_s1: 0.115432, loss_fp: 0.004498, loss_freq: 0.050564
[15:16:23.474] iteration 4264: loss: 0.115951, loss_s1: 0.052608, loss_fp: 0.003350, loss_freq: 0.051700
[15:16:24.097] iteration 4265: loss: 0.096822, loss_s1: 0.039688, loss_fp: 0.013257, loss_freq: 0.029946
[15:16:24.721] iteration 4266: loss: 0.127429, loss_s1: 0.053130, loss_fp: 0.000645, loss_freq: 0.056930
[15:16:25.351] iteration 4267: loss: 0.155845, loss_s1: 0.054817, loss_fp: 0.000777, loss_freq: 0.083579
[15:16:25.979] iteration 4268: loss: 0.114286, loss_s1: 0.077008, loss_fp: 0.002877, loss_freq: 0.041995
[15:16:26.606] iteration 4269: loss: 0.158640, loss_s1: 0.077967, loss_fp: 0.004351, loss_freq: 0.153050
[15:16:27.230] iteration 4270: loss: 0.154490, loss_s1: 0.056613, loss_fp: 0.001385, loss_freq: 0.016978
[15:16:27.855] iteration 4271: loss: 0.126869, loss_s1: 0.058302, loss_fp: 0.004960, loss_freq: 0.100621
[15:16:28.480] iteration 4272: loss: 0.063785, loss_s1: 0.035918, loss_fp: 0.001339, loss_freq: 0.003086
[15:16:29.105] iteration 4273: loss: 0.191419, loss_s1: 0.082098, loss_fp: 0.000728, loss_freq: 0.050300
[15:16:29.730] iteration 4274: loss: 0.148509, loss_s1: 0.086644, loss_fp: 0.000819, loss_freq: 0.057039
[15:16:30.350] iteration 4275: loss: 0.140838, loss_s1: 0.040210, loss_fp: 0.004850, loss_freq: 0.034879
[15:16:30.971] iteration 4276: loss: 0.130211, loss_s1: 0.063886, loss_fp: 0.001067, loss_freq: 0.013831
[15:16:31.594] iteration 4277: loss: 0.126148, loss_s1: 0.035609, loss_fp: 0.002198, loss_freq: 0.011899
[15:16:32.218] iteration 4278: loss: 0.189161, loss_s1: 0.068316, loss_fp: 0.003268, loss_freq: 0.022948
[15:16:32.837] iteration 4279: loss: 0.237414, loss_s1: 0.049711, loss_fp: 0.013404, loss_freq: 0.014741
[15:16:33.460] iteration 4280: loss: 0.110145, loss_s1: 0.034742, loss_fp: 0.001882, loss_freq: 0.027839
[15:16:34.079] iteration 4281: loss: 0.099136, loss_s1: 0.031679, loss_fp: 0.001530, loss_freq: 0.050216
[15:16:34.700] iteration 4282: loss: 0.106707, loss_s1: 0.064019, loss_fp: 0.004284, loss_freq: 0.038694
[15:16:35.326] iteration 4283: loss: 0.108404, loss_s1: 0.059631, loss_fp: 0.007775, loss_freq: 0.026601
[15:16:35.959] iteration 4284: loss: 0.125172, loss_s1: 0.064098, loss_fp: 0.000573, loss_freq: 0.023950
[15:16:36.581] iteration 4285: loss: 0.193844, loss_s1: 0.022161, loss_fp: 0.002637, loss_freq: 0.007786
[15:16:37.205] iteration 4286: loss: 0.117685, loss_s1: 0.060697, loss_fp: 0.002309, loss_freq: 0.035001
[15:16:37.826] iteration 4287: loss: 0.125548, loss_s1: 0.074269, loss_fp: 0.009478, loss_freq: 0.024139
[15:16:38.450] iteration 4288: loss: 0.149098, loss_s1: 0.088966, loss_fp: 0.001425, loss_freq: 0.030670
[15:16:39.072] iteration 4289: loss: 0.171493, loss_s1: 0.066955, loss_fp: 0.006343, loss_freq: 0.078845
[15:16:39.694] iteration 4290: loss: 0.106093, loss_s1: 0.061835, loss_fp: 0.000932, loss_freq: 0.042226
[15:16:40.318] iteration 4291: loss: 0.142866, loss_s1: 0.036634, loss_fp: 0.001417, loss_freq: 0.018310
[15:16:40.939] iteration 4292: loss: 0.097919, loss_s1: 0.056065, loss_fp: 0.001596, loss_freq: 0.022339
[15:16:41.564] iteration 4293: loss: 0.117340, loss_s1: 0.022933, loss_fp: 0.001479, loss_freq: 0.010816
[15:16:42.193] iteration 4294: loss: 0.219141, loss_s1: 0.172697, loss_fp: 0.001025, loss_freq: 0.113873
[15:16:42.819] iteration 4295: loss: 0.304252, loss_s1: 0.216257, loss_fp: 0.001139, loss_freq: 0.210243
[15:16:43.446] iteration 4296: loss: 0.161407, loss_s1: 0.048310, loss_fp: 0.002645, loss_freq: 0.083258
[15:16:44.071] iteration 4297: loss: 0.130757, loss_s1: 0.030076, loss_fp: 0.001238, loss_freq: 0.037639
[15:16:44.700] iteration 4298: loss: 0.064584, loss_s1: 0.013430, loss_fp: 0.000552, loss_freq: 0.015015
[15:16:45.320] iteration 4299: loss: 0.128860, loss_s1: 0.085752, loss_fp: 0.001311, loss_freq: 0.046550
[15:16:45.940] iteration 4300: loss: 0.084523, loss_s1: 0.035782, loss_fp: 0.001386, loss_freq: 0.034369
[15:16:46.568] iteration 4301: loss: 0.084676, loss_s1: 0.045257, loss_fp: 0.003896, loss_freq: 0.005057
[15:16:47.190] iteration 4302: loss: 0.149177, loss_s1: 0.093361, loss_fp: 0.000793, loss_freq: 0.053312
[15:16:47.811] iteration 4303: loss: 0.084477, loss_s1: 0.046386, loss_fp: 0.004776, loss_freq: 0.018784
[15:16:48.430] iteration 4304: loss: 0.116537, loss_s1: 0.062673, loss_fp: 0.000904, loss_freq: 0.031777
[15:16:49.050] iteration 4305: loss: 0.176098, loss_s1: 0.048345, loss_fp: 0.003272, loss_freq: 0.044873
[15:16:49.668] iteration 4306: loss: 0.150605, loss_s1: 0.093721, loss_fp: 0.002567, loss_freq: 0.132148
[15:16:50.284] iteration 4307: loss: 0.084395, loss_s1: 0.033649, loss_fp: 0.008499, loss_freq: 0.050602
[15:16:50.906] iteration 4308: loss: 0.179528, loss_s1: 0.052616, loss_fp: 0.000520, loss_freq: 0.013546
[15:16:51.528] iteration 4309: loss: 0.119005, loss_s1: 0.069179, loss_fp: 0.006413, loss_freq: 0.067637
[15:16:52.151] iteration 4310: loss: 0.157180, loss_s1: 0.068987, loss_fp: 0.000858, loss_freq: 0.054523
[15:16:52.775] iteration 4311: loss: 0.174159, loss_s1: 0.079990, loss_fp: 0.001935, loss_freq: 0.074825
[15:16:53.403] iteration 4312: loss: 0.167319, loss_s1: 0.107089, loss_fp: 0.002710, loss_freq: 0.040498
[15:16:54.028] iteration 4313: loss: 0.131282, loss_s1: 0.035337, loss_fp: 0.005427, loss_freq: 0.017693
[15:16:54.652] iteration 4314: loss: 0.231966, loss_s1: 0.131782, loss_fp: 0.003579, loss_freq: 0.036224
[15:16:55.276] iteration 4315: loss: 0.104834, loss_s1: 0.078239, loss_fp: 0.004115, loss_freq: 0.018606
[15:16:55.891] iteration 4316: loss: 0.093522, loss_s1: 0.052180, loss_fp: 0.001382, loss_freq: 0.025778
[15:16:56.515] iteration 4317: loss: 0.105368, loss_s1: 0.052316, loss_fp: 0.000576, loss_freq: 0.057297
[15:16:57.167] iteration 4318: loss: 0.133437, loss_s1: 0.078218, loss_fp: 0.007202, loss_freq: 0.034848
[15:16:57.805] iteration 4319: loss: 0.097205, loss_s1: 0.041431, loss_fp: 0.000591, loss_freq: 0.017601
[15:16:58.438] iteration 4320: loss: 0.097693, loss_s1: 0.036226, loss_fp: 0.003701, loss_freq: 0.020120
[15:16:59.074] iteration 4321: loss: 0.108924, loss_s1: 0.064293, loss_fp: 0.004659, loss_freq: 0.050366
[15:16:59.707] iteration 4322: loss: 0.124108, loss_s1: 0.109042, loss_fp: 0.002234, loss_freq: 0.028220
[15:17:00.344] iteration 4323: loss: 0.146874, loss_s1: 0.051801, loss_fp: 0.007251, loss_freq: 0.040276
[15:17:00.982] iteration 4324: loss: 0.077917, loss_s1: 0.029203, loss_fp: 0.006593, loss_freq: 0.008794
[15:17:01.618] iteration 4325: loss: 0.110399, loss_s1: 0.074944, loss_fp: 0.007832, loss_freq: 0.047017
[15:17:02.244] iteration 4326: loss: 0.162632, loss_s1: 0.058328, loss_fp: 0.005591, loss_freq: 0.061208
[15:17:02.867] iteration 4327: loss: 0.195341, loss_s1: 0.117658, loss_fp: 0.003209, loss_freq: 0.055661
[15:17:03.504] iteration 4328: loss: 0.103243, loss_s1: 0.022056, loss_fp: 0.001112, loss_freq: 0.026608
[15:17:04.138] iteration 4329: loss: 0.119501, loss_s1: 0.041873, loss_fp: 0.005004, loss_freq: 0.037858
[15:17:04.772] iteration 4330: loss: 0.151797, loss_s1: 0.065996, loss_fp: 0.006159, loss_freq: 0.043026
[15:17:05.407] iteration 4331: loss: 0.091514, loss_s1: 0.012302, loss_fp: 0.000716, loss_freq: 0.020278
[15:17:06.038] iteration 4332: loss: 0.128088, loss_s1: 0.038469, loss_fp: 0.003695, loss_freq: 0.007276
[15:17:06.665] iteration 4333: loss: 0.092596, loss_s1: 0.029351, loss_fp: 0.000611, loss_freq: 0.055880
[15:17:07.299] iteration 4334: loss: 0.129095, loss_s1: 0.107797, loss_fp: 0.013627, loss_freq: 0.038420
[15:17:07.925] iteration 4335: loss: 0.097245, loss_s1: 0.080251, loss_fp: 0.003871, loss_freq: 0.021174
[15:17:08.554] iteration 4336: loss: 0.162227, loss_s1: 0.153292, loss_fp: 0.012092, loss_freq: 0.054978
[15:17:09.185] iteration 4337: loss: 0.128414, loss_s1: 0.078142, loss_fp: 0.000831, loss_freq: 0.019327
[15:17:09.811] iteration 4338: loss: 0.177671, loss_s1: 0.133012, loss_fp: 0.002093, loss_freq: 0.086196
[15:17:10.440] iteration 4339: loss: 0.083434, loss_s1: 0.046220, loss_fp: 0.005287, loss_freq: 0.037948
[15:17:11.072] iteration 4340: loss: 0.151414, loss_s1: 0.076320, loss_fp: 0.002970, loss_freq: 0.033358
[15:17:11.698] iteration 4341: loss: 0.087911, loss_s1: 0.046585, loss_fp: 0.001352, loss_freq: 0.015171
[15:17:12.326] iteration 4342: loss: 0.064412, loss_s1: 0.019463, loss_fp: 0.001112, loss_freq: 0.023731
[15:17:12.957] iteration 4343: loss: 0.130891, loss_s1: 0.020101, loss_fp: 0.001645, loss_freq: 0.020068
[15:17:13.588] iteration 4344: loss: 0.165390, loss_s1: 0.108645, loss_fp: 0.001425, loss_freq: 0.103833
[15:17:14.217] iteration 4345: loss: 0.141371, loss_s1: 0.088026, loss_fp: 0.005006, loss_freq: 0.014908
[15:17:14.840] iteration 4346: loss: 0.110628, loss_s1: 0.040971, loss_fp: 0.016525, loss_freq: 0.037134
[15:17:15.465] iteration 4347: loss: 0.189837, loss_s1: 0.091632, loss_fp: 0.001381, loss_freq: 0.121208
[15:17:16.404] iteration 4348: loss: 0.150350, loss_s1: 0.058017, loss_fp: 0.001973, loss_freq: 0.011576
[15:17:17.056] iteration 4349: loss: 0.173066, loss_s1: 0.065794, loss_fp: 0.003579, loss_freq: 0.067180
[15:17:17.685] iteration 4350: loss: 0.132130, loss_s1: 0.062126, loss_fp: 0.001003, loss_freq: 0.070681
[15:17:18.317] iteration 4351: loss: 0.122693, loss_s1: 0.033288, loss_fp: 0.000972, loss_freq: 0.016413
[15:17:18.947] iteration 4352: loss: 0.129005, loss_s1: 0.054538, loss_fp: 0.002872, loss_freq: 0.031235
[15:17:19.577] iteration 4353: loss: 0.142315, loss_s1: 0.023106, loss_fp: 0.003140, loss_freq: 0.061035
[15:17:20.201] iteration 4354: loss: 0.068090, loss_s1: 0.032151, loss_fp: 0.000759, loss_freq: 0.025275
[15:17:20.824] iteration 4355: loss: 0.130487, loss_s1: 0.085553, loss_fp: 0.000740, loss_freq: 0.058626
[15:17:21.444] iteration 4356: loss: 0.128027, loss_s1: 0.075922, loss_fp: 0.008543, loss_freq: 0.028164
[15:17:22.068] iteration 4357: loss: 0.121876, loss_s1: 0.096170, loss_fp: 0.011377, loss_freq: 0.042079
[15:17:22.692] iteration 4358: loss: 0.166824, loss_s1: 0.049964, loss_fp: 0.001197, loss_freq: 0.014787
[15:17:23.324] iteration 4359: loss: 0.164634, loss_s1: 0.049096, loss_fp: 0.004895, loss_freq: 0.071264
[15:17:23.949] iteration 4360: loss: 0.157797, loss_s1: 0.069069, loss_fp: 0.052395, loss_freq: 0.053469
[15:17:24.575] iteration 4361: loss: 0.155444, loss_s1: 0.031552, loss_fp: 0.002566, loss_freq: 0.051480
[15:17:25.200] iteration 4362: loss: 0.103210, loss_s1: 0.050957, loss_fp: 0.001544, loss_freq: 0.026915
[15:17:25.822] iteration 4363: loss: 0.150826, loss_s1: 0.050661, loss_fp: 0.001428, loss_freq: 0.079643
[15:17:26.444] iteration 4364: loss: 0.127228, loss_s1: 0.099660, loss_fp: 0.003441, loss_freq: 0.023134
[15:17:27.070] iteration 4365: loss: 0.115531, loss_s1: 0.043193, loss_fp: 0.002824, loss_freq: 0.046142
[15:17:27.704] iteration 4366: loss: 0.118435, loss_s1: 0.084887, loss_fp: 0.002393, loss_freq: 0.026868
[15:17:28.339] iteration 4367: loss: 0.171792, loss_s1: 0.130504, loss_fp: 0.007461, loss_freq: 0.034317
[15:17:28.971] iteration 4368: loss: 0.127094, loss_s1: 0.090663, loss_fp: 0.002330, loss_freq: 0.017575
[15:17:29.592] iteration 4369: loss: 0.132346, loss_s1: 0.070171, loss_fp: 0.001466, loss_freq: 0.024145
[15:17:30.218] iteration 4370: loss: 0.145733, loss_s1: 0.041315, loss_fp: 0.000691, loss_freq: 0.020586
[15:17:30.841] iteration 4371: loss: 0.200613, loss_s1: 0.155644, loss_fp: 0.023720, loss_freq: 0.094443
[15:17:31.467] iteration 4372: loss: 0.070596, loss_s1: 0.030352, loss_fp: 0.000615, loss_freq: 0.010555
[15:17:32.093] iteration 4373: loss: 0.105771, loss_s1: 0.037467, loss_fp: 0.000824, loss_freq: 0.072301
[15:17:32.712] iteration 4374: loss: 0.162494, loss_s1: 0.102851, loss_fp: 0.000698, loss_freq: 0.100704
[15:17:33.336] iteration 4375: loss: 0.202623, loss_s1: 0.103439, loss_fp: 0.015330, loss_freq: 0.057716
[15:17:33.959] iteration 4376: loss: 0.097512, loss_s1: 0.031396, loss_fp: 0.003644, loss_freq: 0.047594
[15:17:34.584] iteration 4377: loss: 0.098264, loss_s1: 0.051225, loss_fp: 0.004338, loss_freq: 0.017855
[15:17:35.206] iteration 4378: loss: 0.138829, loss_s1: 0.118295, loss_fp: 0.003753, loss_freq: 0.035144
[15:17:35.830] iteration 4379: loss: 0.166327, loss_s1: 0.040721, loss_fp: 0.002266, loss_freq: 0.042491
[15:17:36.454] iteration 4380: loss: 0.108863, loss_s1: 0.104684, loss_fp: 0.001400, loss_freq: 0.024541
[15:17:37.076] iteration 4381: loss: 0.070049, loss_s1: 0.039536, loss_fp: 0.002738, loss_freq: 0.009776
[15:17:37.701] iteration 4382: loss: 0.145467, loss_s1: 0.020554, loss_fp: 0.000629, loss_freq: 0.013980
[15:17:38.324] iteration 4383: loss: 0.153895, loss_s1: 0.125666, loss_fp: 0.003306, loss_freq: 0.064346
[15:17:38.967] iteration 4384: loss: 0.144423, loss_s1: 0.077524, loss_fp: 0.002517, loss_freq: 0.049374
[15:17:39.603] iteration 4385: loss: 0.095689, loss_s1: 0.032372, loss_fp: 0.018746, loss_freq: 0.028404
[15:17:40.276] iteration 4386: loss: 0.152429, loss_s1: 0.074297, loss_fp: 0.001020, loss_freq: 0.043058
[15:17:40.917] iteration 4387: loss: 0.159012, loss_s1: 0.070591, loss_fp: 0.002553, loss_freq: 0.093254
[15:17:41.554] iteration 4388: loss: 0.112695, loss_s1: 0.054790, loss_fp: 0.000559, loss_freq: 0.026191
[15:17:42.189] iteration 4389: loss: 0.094610, loss_s1: 0.095597, loss_fp: 0.004068, loss_freq: 0.007106
[15:17:42.821] iteration 4390: loss: 0.091795, loss_s1: 0.042996, loss_fp: 0.001654, loss_freq: 0.030873
[15:17:43.453] iteration 4391: loss: 0.152719, loss_s1: 0.139129, loss_fp: 0.001979, loss_freq: 0.023965
[15:17:44.081] iteration 4392: loss: 0.126667, loss_s1: 0.054008, loss_fp: 0.001014, loss_freq: 0.051859
[15:17:44.714] iteration 4393: loss: 0.103644, loss_s1: 0.048946, loss_fp: 0.007238, loss_freq: 0.014533
[15:17:45.344] iteration 4394: loss: 0.091029, loss_s1: 0.042718, loss_fp: 0.002796, loss_freq: 0.016823
[15:17:45.973] iteration 4395: loss: 0.083843, loss_s1: 0.051516, loss_fp: 0.002504, loss_freq: 0.007192
[15:17:46.600] iteration 4396: loss: 0.146205, loss_s1: 0.092657, loss_fp: 0.004052, loss_freq: 0.013411
[15:17:47.228] iteration 4397: loss: 0.122462, loss_s1: 0.072574, loss_fp: 0.000584, loss_freq: 0.026835
[15:17:47.874] iteration 4398: loss: 0.053732, loss_s1: 0.008017, loss_fp: 0.000468, loss_freq: 0.025055
[15:17:48.512] iteration 4399: loss: 0.161976, loss_s1: 0.055378, loss_fp: 0.002229, loss_freq: 0.017808
[15:17:49.136] iteration 4400: loss: 0.173248, loss_s1: 0.118825, loss_fp: 0.002243, loss_freq: 0.085963
[15:17:52.155] iteration 4400 : mean_dice : 0.544703
[15:17:52.801] iteration 4401: loss: 0.215000, loss_s1: 0.071958, loss_fp: 0.002245, loss_freq: 0.056971
[15:17:53.428] iteration 4402: loss: 0.197744, loss_s1: 0.107495, loss_fp: 0.003076, loss_freq: 0.019965
[15:17:54.062] iteration 4403: loss: 0.303652, loss_s1: 0.312819, loss_fp: 0.001275, loss_freq: 0.078604
[15:17:54.690] iteration 4404: loss: 0.152498, loss_s1: 0.039964, loss_fp: 0.001124, loss_freq: 0.051992
[15:17:55.318] iteration 4405: loss: 0.191393, loss_s1: 0.056316, loss_fp: 0.008984, loss_freq: 0.042051
[15:17:55.950] iteration 4406: loss: 0.088212, loss_s1: 0.032484, loss_fp: 0.003637, loss_freq: 0.031955
[15:17:56.600] iteration 4407: loss: 0.113388, loss_s1: 0.119833, loss_fp: 0.000419, loss_freq: 0.008755
[15:17:57.266] iteration 4408: loss: 0.089215, loss_s1: 0.051978, loss_fp: 0.001038, loss_freq: 0.037164
[15:17:57.911] iteration 4409: loss: 0.101372, loss_s1: 0.033394, loss_fp: 0.000553, loss_freq: 0.037765
[15:17:58.566] iteration 4410: loss: 0.113324, loss_s1: 0.050470, loss_fp: 0.000939, loss_freq: 0.024972
[15:17:59.195] iteration 4411: loss: 0.129755, loss_s1: 0.116290, loss_fp: 0.000600, loss_freq: 0.010236
[15:17:59.833] iteration 4412: loss: 0.132284, loss_s1: 0.064062, loss_fp: 0.000589, loss_freq: 0.006915
[15:18:00.461] iteration 4413: loss: 0.199393, loss_s1: 0.178867, loss_fp: 0.010557, loss_freq: 0.024963
[15:18:01.083] iteration 4414: loss: 0.161025, loss_s1: 0.027693, loss_fp: 0.001597, loss_freq: 0.087221
[15:18:01.705] iteration 4415: loss: 0.094654, loss_s1: 0.050655, loss_fp: 0.001382, loss_freq: 0.052974
[15:18:02.329] iteration 4416: loss: 0.105278, loss_s1: 0.069621, loss_fp: 0.001419, loss_freq: 0.004963
[15:18:02.956] iteration 4417: loss: 0.146242, loss_s1: 0.042518, loss_fp: 0.003281, loss_freq: 0.020903
[15:18:03.577] iteration 4418: loss: 0.145011, loss_s1: 0.051902, loss_fp: 0.002171, loss_freq: 0.048872
[15:18:04.202] iteration 4419: loss: 0.125454, loss_s1: 0.063869, loss_fp: 0.000907, loss_freq: 0.059281
[15:18:04.828] iteration 4420: loss: 0.100830, loss_s1: 0.022573, loss_fp: 0.001436, loss_freq: 0.022768
[15:18:05.454] iteration 4421: loss: 0.130622, loss_s1: 0.044549, loss_fp: 0.003546, loss_freq: 0.048682
[15:18:06.082] iteration 4422: loss: 0.135081, loss_s1: 0.050360, loss_fp: 0.002153, loss_freq: 0.046022
[15:18:06.726] iteration 4423: loss: 0.152353, loss_s1: 0.094953, loss_fp: 0.001070, loss_freq: 0.047114
[15:18:07.362] iteration 4424: loss: 0.105026, loss_s1: 0.027590, loss_fp: 0.001439, loss_freq: 0.070460
[15:18:08.006] iteration 4425: loss: 0.108800, loss_s1: 0.051695, loss_fp: 0.001195, loss_freq: 0.053658
[15:18:08.640] iteration 4426: loss: 0.056561, loss_s1: 0.014833, loss_fp: 0.000946, loss_freq: 0.010760
[15:18:09.258] iteration 4427: loss: 0.083530, loss_s1: 0.036749, loss_fp: 0.002574, loss_freq: 0.035299
[15:18:09.884] iteration 4428: loss: 0.159496, loss_s1: 0.075499, loss_fp: 0.004101, loss_freq: 0.068274
[15:18:10.510] iteration 4429: loss: 0.157606, loss_s1: 0.068983, loss_fp: 0.006626, loss_freq: 0.037991
[15:18:11.151] iteration 4430: loss: 0.274848, loss_s1: 0.299576, loss_fp: 0.017927, loss_freq: 0.105730
[15:18:11.786] iteration 4431: loss: 0.134010, loss_s1: 0.034273, loss_fp: 0.001744, loss_freq: 0.012390
[15:18:12.420] iteration 4432: loss: 0.140886, loss_s1: 0.062180, loss_fp: 0.006032, loss_freq: 0.095942
[15:18:13.058] iteration 4433: loss: 0.090347, loss_s1: 0.087316, loss_fp: 0.004724, loss_freq: 0.010006
[15:18:13.697] iteration 4434: loss: 0.219716, loss_s1: 0.083351, loss_fp: 0.000562, loss_freq: 0.018221
[15:18:14.333] iteration 4435: loss: 0.122010, loss_s1: 0.078188, loss_fp: 0.001035, loss_freq: 0.027831
[15:18:14.965] iteration 4436: loss: 0.148964, loss_s1: 0.147978, loss_fp: 0.009033, loss_freq: 0.018825
[15:18:15.600] iteration 4437: loss: 0.151448, loss_s1: 0.131974, loss_fp: 0.000747, loss_freq: 0.006511
[15:18:16.236] iteration 4438: loss: 0.105276, loss_s1: 0.038780, loss_fp: 0.001182, loss_freq: 0.016710
[15:18:16.874] iteration 4439: loss: 0.125347, loss_s1: 0.038164, loss_fp: 0.001556, loss_freq: 0.015004
[15:18:17.512] iteration 4440: loss: 0.158488, loss_s1: 0.041544, loss_fp: 0.000840, loss_freq: 0.028982
[15:18:18.150] iteration 4441: loss: 0.111840, loss_s1: 0.048526, loss_fp: 0.001167, loss_freq: 0.030982
[15:18:18.786] iteration 4442: loss: 0.083936, loss_s1: 0.051007, loss_fp: 0.001229, loss_freq: 0.032548
[15:18:19.422] iteration 4443: loss: 0.106732, loss_s1: 0.073700, loss_fp: 0.000635, loss_freq: 0.031736
[15:18:20.060] iteration 4444: loss: 0.115715, loss_s1: 0.020834, loss_fp: 0.005616, loss_freq: 0.026473
[15:18:20.702] iteration 4445: loss: 0.126703, loss_s1: 0.032701, loss_fp: 0.001032, loss_freq: 0.019171
[15:18:21.337] iteration 4446: loss: 0.178127, loss_s1: 0.117236, loss_fp: 0.004578, loss_freq: 0.033323
[15:18:21.972] iteration 4447: loss: 0.125887, loss_s1: 0.082747, loss_fp: 0.002827, loss_freq: 0.050414
[15:18:22.611] iteration 4448: loss: 0.137712, loss_s1: 0.067127, loss_fp: 0.004295, loss_freq: 0.045693
[15:18:23.245] iteration 4449: loss: 0.125174, loss_s1: 0.044972, loss_fp: 0.004622, loss_freq: 0.035167
[15:18:23.881] iteration 4450: loss: 0.159128, loss_s1: 0.110930, loss_fp: 0.009933, loss_freq: 0.057985
[15:18:24.520] iteration 4451: loss: 0.127991, loss_s1: 0.037048, loss_fp: 0.006169, loss_freq: 0.083574
[15:18:25.154] iteration 4452: loss: 0.193254, loss_s1: 0.053625, loss_fp: 0.021883, loss_freq: 0.047740
[15:18:25.790] iteration 4453: loss: 0.151576, loss_s1: 0.057080, loss_fp: 0.001369, loss_freq: 0.032466
[15:18:26.428] iteration 4454: loss: 0.140889, loss_s1: 0.039872, loss_fp: 0.000714, loss_freq: 0.017479
[15:18:27.067] iteration 4455: loss: 0.192793, loss_s1: 0.182873, loss_fp: 0.001033, loss_freq: 0.056594
[15:18:27.707] iteration 4456: loss: 0.232960, loss_s1: 0.115947, loss_fp: 0.005276, loss_freq: 0.160117
[15:18:28.346] iteration 4457: loss: 0.160950, loss_s1: 0.095929, loss_fp: 0.002140, loss_freq: 0.053203
[15:18:28.978] iteration 4458: loss: 0.137032, loss_s1: 0.024509, loss_fp: 0.000765, loss_freq: 0.030647
[15:18:29.603] iteration 4459: loss: 0.106167, loss_s1: 0.079569, loss_fp: 0.001024, loss_freq: 0.051116
[15:18:30.231] iteration 4460: loss: 0.170550, loss_s1: 0.131001, loss_fp: 0.007321, loss_freq: 0.064043
[15:18:30.858] iteration 4461: loss: 0.083338, loss_s1: 0.043879, loss_fp: 0.001788, loss_freq: 0.026556
[15:18:31.485] iteration 4462: loss: 0.080245, loss_s1: 0.030612, loss_fp: 0.000763, loss_freq: 0.005749
[15:18:32.110] iteration 4463: loss: 0.207299, loss_s1: 0.150471, loss_fp: 0.001178, loss_freq: 0.074221
[15:18:32.738] iteration 4464: loss: 0.084761, loss_s1: 0.026136, loss_fp: 0.004306, loss_freq: 0.035426
[15:18:33.365] iteration 4465: loss: 0.116202, loss_s1: 0.104804, loss_fp: 0.005798, loss_freq: 0.047771
[15:18:33.991] iteration 4466: loss: 0.166439, loss_s1: 0.106473, loss_fp: 0.002203, loss_freq: 0.028852
[15:18:34.615] iteration 4467: loss: 0.128439, loss_s1: 0.048361, loss_fp: 0.002085, loss_freq: 0.117671
[15:18:35.241] iteration 4468: loss: 0.081813, loss_s1: 0.010066, loss_fp: 0.005374, loss_freq: 0.053899
[15:18:35.864] iteration 4469: loss: 0.201713, loss_s1: 0.016005, loss_fp: 0.000838, loss_freq: 0.010012
[15:18:36.487] iteration 4470: loss: 0.164603, loss_s1: 0.152092, loss_fp: 0.012975, loss_freq: 0.037051
[15:18:37.129] iteration 4471: loss: 0.125209, loss_s1: 0.060155, loss_fp: 0.001042, loss_freq: 0.074645
[15:18:37.763] iteration 4472: loss: 0.152086, loss_s1: 0.064085, loss_fp: 0.002514, loss_freq: 0.055818
[15:18:38.393] iteration 4473: loss: 0.154635, loss_s1: 0.025759, loss_fp: 0.005525, loss_freq: 0.011758
[15:18:39.023] iteration 4474: loss: 0.123193, loss_s1: 0.036969, loss_fp: 0.000873, loss_freq: 0.030755
[15:18:39.655] iteration 4475: loss: 0.203574, loss_s1: 0.050504, loss_fp: 0.002692, loss_freq: 0.073299
[15:18:40.279] iteration 4476: loss: 0.100403, loss_s1: 0.065187, loss_fp: 0.001203, loss_freq: 0.003543
[15:18:40.906] iteration 4477: loss: 0.116535, loss_s1: 0.109588, loss_fp: 0.000984, loss_freq: 0.009336
[15:18:41.534] iteration 4478: loss: 0.082799, loss_s1: 0.040243, loss_fp: 0.001329, loss_freq: 0.036554
[15:18:42.162] iteration 4479: loss: 0.126994, loss_s1: 0.108987, loss_fp: 0.003667, loss_freq: 0.037892
[15:18:42.789] iteration 4480: loss: 0.124298, loss_s1: 0.069489, loss_fp: 0.010153, loss_freq: 0.032486
[15:18:43.412] iteration 4481: loss: 0.083453, loss_s1: 0.043980, loss_fp: 0.005554, loss_freq: 0.036489
[15:18:44.039] iteration 4482: loss: 0.187048, loss_s1: 0.120820, loss_fp: 0.002521, loss_freq: 0.033959
[15:18:44.664] iteration 4483: loss: 0.123021, loss_s1: 0.082749, loss_fp: 0.001653, loss_freq: 0.035384
[15:18:45.292] iteration 4484: loss: 0.133589, loss_s1: 0.030861, loss_fp: 0.001234, loss_freq: 0.063492
[15:18:45.916] iteration 4485: loss: 0.128109, loss_s1: 0.095273, loss_fp: 0.004549, loss_freq: 0.037677
[15:18:46.545] iteration 4486: loss: 0.094473, loss_s1: 0.035946, loss_fp: 0.004753, loss_freq: 0.053867
[15:18:47.170] iteration 4487: loss: 0.168304, loss_s1: 0.033428, loss_fp: 0.004194, loss_freq: 0.063282
[15:18:47.796] iteration 4488: loss: 0.154403, loss_s1: 0.062281, loss_fp: 0.002563, loss_freq: 0.086914
[15:18:48.418] iteration 4489: loss: 0.156904, loss_s1: 0.060409, loss_fp: 0.006032, loss_freq: 0.033768
[15:18:49.044] iteration 4490: loss: 0.139251, loss_s1: 0.081673, loss_fp: 0.001251, loss_freq: 0.027807
[15:18:49.677] iteration 4491: loss: 0.118724, loss_s1: 0.073195, loss_fp: 0.003471, loss_freq: 0.017968
[15:18:50.301] iteration 4492: loss: 0.118545, loss_s1: 0.011848, loss_fp: 0.002119, loss_freq: 0.009326
[15:18:50.924] iteration 4493: loss: 0.129531, loss_s1: 0.049659, loss_fp: 0.003070, loss_freq: 0.016446
[15:18:51.545] iteration 4494: loss: 0.065846, loss_s1: 0.032405, loss_fp: 0.003370, loss_freq: 0.025770
[15:18:52.175] iteration 4495: loss: 0.122382, loss_s1: 0.097925, loss_fp: 0.001583, loss_freq: 0.032940
[15:18:52.801] iteration 4496: loss: 0.092938, loss_s1: 0.023913, loss_fp: 0.002583, loss_freq: 0.027901
[15:18:53.427] iteration 4497: loss: 0.123096, loss_s1: 0.070827, loss_fp: 0.001482, loss_freq: 0.036559
[15:18:54.053] iteration 4498: loss: 0.118683, loss_s1: 0.035463, loss_fp: 0.001188, loss_freq: 0.064687
[15:18:54.673] iteration 4499: loss: 0.165830, loss_s1: 0.088700, loss_fp: 0.002647, loss_freq: 0.072093
[15:18:55.298] iteration 4500: loss: 0.074719, loss_s1: 0.064700, loss_fp: 0.007631, loss_freq: 0.014670
[15:18:55.922] iteration 4501: loss: 0.149372, loss_s1: 0.071653, loss_fp: 0.003325, loss_freq: 0.048055
[15:18:56.545] iteration 4502: loss: 0.107863, loss_s1: 0.051821, loss_fp: 0.000683, loss_freq: 0.016927
[15:18:57.170] iteration 4503: loss: 0.098431, loss_s1: 0.078685, loss_fp: 0.002369, loss_freq: 0.020919
[15:18:57.803] iteration 4504: loss: 0.141777, loss_s1: 0.056706, loss_fp: 0.001979, loss_freq: 0.019731
[15:18:58.438] iteration 4505: loss: 0.182746, loss_s1: 0.130414, loss_fp: 0.011368, loss_freq: 0.110293
[15:18:59.071] iteration 4506: loss: 0.115749, loss_s1: 0.048919, loss_fp: 0.002079, loss_freq: 0.024342
[15:18:59.695] iteration 4507: loss: 0.131631, loss_s1: 0.049487, loss_fp: 0.001516, loss_freq: 0.069068
[15:19:00.317] iteration 4508: loss: 0.153227, loss_s1: 0.071214, loss_fp: 0.001317, loss_freq: 0.056011
[15:19:01.271] iteration 4509: loss: 0.088684, loss_s1: 0.057116, loss_fp: 0.001409, loss_freq: 0.011869
[15:19:01.899] iteration 4510: loss: 0.133792, loss_s1: 0.099766, loss_fp: 0.001185, loss_freq: 0.054625
[15:19:02.521] iteration 4511: loss: 0.152021, loss_s1: 0.053707, loss_fp: 0.001036, loss_freq: 0.046575
[15:19:03.150] iteration 4512: loss: 0.136085, loss_s1: 0.025406, loss_fp: 0.000729, loss_freq: 0.028173
[15:19:03.774] iteration 4513: loss: 0.109265, loss_s1: 0.028208, loss_fp: 0.001516, loss_freq: 0.018735
[15:19:04.397] iteration 4514: loss: 0.194141, loss_s1: 0.030435, loss_fp: 0.001811, loss_freq: 0.061580
[15:19:05.017] iteration 4515: loss: 0.079841, loss_s1: 0.054315, loss_fp: 0.003249, loss_freq: 0.036485
[15:19:05.639] iteration 4516: loss: 0.131239, loss_s1: 0.079072, loss_fp: 0.001680, loss_freq: 0.080413
[15:19:06.263] iteration 4517: loss: 0.118851, loss_s1: 0.095416, loss_fp: 0.004257, loss_freq: 0.020127
[15:19:06.881] iteration 4518: loss: 0.114514, loss_s1: 0.048151, loss_fp: 0.011316, loss_freq: 0.065292
[15:19:07.507] iteration 4519: loss: 0.102206, loss_s1: 0.044559, loss_fp: 0.002055, loss_freq: 0.023589
[15:19:08.132] iteration 4520: loss: 0.169114, loss_s1: 0.068991, loss_fp: 0.000459, loss_freq: 0.051565
[15:19:08.751] iteration 4521: loss: 0.090233, loss_s1: 0.056271, loss_fp: 0.001145, loss_freq: 0.034102
[15:19:09.402] iteration 4522: loss: 0.136860, loss_s1: 0.058267, loss_fp: 0.000932, loss_freq: 0.019925
[15:19:10.021] iteration 4523: loss: 0.094555, loss_s1: 0.032722, loss_fp: 0.001363, loss_freq: 0.027553
[15:19:10.644] iteration 4524: loss: 0.154399, loss_s1: 0.060847, loss_fp: 0.002912, loss_freq: 0.085461
[15:19:11.267] iteration 4525: loss: 0.104909, loss_s1: 0.038675, loss_fp: 0.001347, loss_freq: 0.014834
[15:19:11.887] iteration 4526: loss: 0.091594, loss_s1: 0.032689, loss_fp: 0.004802, loss_freq: 0.036332
[15:19:12.513] iteration 4527: loss: 0.145911, loss_s1: 0.044585, loss_fp: 0.014756, loss_freq: 0.034318
[15:19:13.135] iteration 4528: loss: 0.101320, loss_s1: 0.050232, loss_fp: 0.000856, loss_freq: 0.028209
[15:19:13.764] iteration 4529: loss: 0.113819, loss_s1: 0.110276, loss_fp: 0.009994, loss_freq: 0.003439
[15:19:14.386] iteration 4530: loss: 0.133924, loss_s1: 0.064257, loss_fp: 0.001604, loss_freq: 0.030682
[15:19:15.026] iteration 4531: loss: 0.118375, loss_s1: 0.002974, loss_fp: 0.000855, loss_freq: 0.019920
[15:19:15.655] iteration 4532: loss: 0.254188, loss_s1: 0.145728, loss_fp: 0.043152, loss_freq: 0.208212
[15:19:16.277] iteration 4533: loss: 0.075783, loss_s1: 0.032200, loss_fp: 0.001564, loss_freq: 0.027852
[15:19:16.910] iteration 4534: loss: 0.101286, loss_s1: 0.054469, loss_fp: 0.001491, loss_freq: 0.048189
[15:19:17.533] iteration 4535: loss: 0.111825, loss_s1: 0.088500, loss_fp: 0.001390, loss_freq: 0.021283
[15:19:18.157] iteration 4536: loss: 0.137683, loss_s1: 0.094369, loss_fp: 0.003215, loss_freq: 0.033756
[15:19:18.782] iteration 4537: loss: 0.079866, loss_s1: 0.031110, loss_fp: 0.012207, loss_freq: 0.037869
[15:19:19.401] iteration 4538: loss: 0.105507, loss_s1: 0.032531, loss_fp: 0.000858, loss_freq: 0.021588
[15:19:20.029] iteration 4539: loss: 0.091821, loss_s1: 0.028124, loss_fp: 0.001551, loss_freq: 0.020974
[15:19:20.654] iteration 4540: loss: 0.147319, loss_s1: 0.060721, loss_fp: 0.005100, loss_freq: 0.010712
[15:19:21.287] iteration 4541: loss: 0.153891, loss_s1: 0.133276, loss_fp: 0.001268, loss_freq: 0.039811
[15:19:21.908] iteration 4542: loss: 0.103429, loss_s1: 0.070437, loss_fp: 0.001059, loss_freq: 0.018631
[15:19:22.532] iteration 4543: loss: 0.163510, loss_s1: 0.038335, loss_fp: 0.002734, loss_freq: 0.025657
[15:19:23.157] iteration 4544: loss: 0.218577, loss_s1: 0.106107, loss_fp: 0.004616, loss_freq: 0.068992
[15:19:23.789] iteration 4545: loss: 0.125959, loss_s1: 0.071947, loss_fp: 0.002744, loss_freq: 0.033598
[15:19:24.410] iteration 4546: loss: 0.084078, loss_s1: 0.036880, loss_fp: 0.001247, loss_freq: 0.016707
[15:19:25.030] iteration 4547: loss: 0.160483, loss_s1: 0.116918, loss_fp: 0.001129, loss_freq: 0.091719
[15:19:25.654] iteration 4548: loss: 0.136761, loss_s1: 0.078587, loss_fp: 0.006532, loss_freq: 0.064984
[15:19:26.281] iteration 4549: loss: 0.133200, loss_s1: 0.042366, loss_fp: 0.004335, loss_freq: 0.058997
[15:19:26.905] iteration 4550: loss: 0.073657, loss_s1: 0.050922, loss_fp: 0.001123, loss_freq: 0.011196
[15:19:27.523] iteration 4551: loss: 0.122970, loss_s1: 0.072326, loss_fp: 0.009519, loss_freq: 0.043473
[15:19:28.146] iteration 4552: loss: 0.101548, loss_s1: 0.072394, loss_fp: 0.000869, loss_freq: 0.026016
[15:19:28.771] iteration 4553: loss: 0.106114, loss_s1: 0.041753, loss_fp: 0.001246, loss_freq: 0.056593
[15:19:29.396] iteration 4554: loss: 0.137876, loss_s1: 0.094875, loss_fp: 0.001361, loss_freq: 0.027775
[15:19:30.018] iteration 4555: loss: 0.113711, loss_s1: 0.066722, loss_fp: 0.001322, loss_freq: 0.009071
[15:19:30.638] iteration 4556: loss: 0.098495, loss_s1: 0.073025, loss_fp: 0.000938, loss_freq: 0.028082
[15:19:31.262] iteration 4557: loss: 0.148370, loss_s1: 0.051310, loss_fp: 0.002652, loss_freq: 0.039970
[15:19:31.885] iteration 4558: loss: 0.109362, loss_s1: 0.064443, loss_fp: 0.001116, loss_freq: 0.055713
[15:19:32.503] iteration 4559: loss: 0.102498, loss_s1: 0.084825, loss_fp: 0.004843, loss_freq: 0.026036
[15:19:33.124] iteration 4560: loss: 0.157206, loss_s1: 0.048435, loss_fp: 0.004563, loss_freq: 0.025129
[15:19:33.767] iteration 4561: loss: 0.114638, loss_s1: 0.054968, loss_fp: 0.001707, loss_freq: 0.055334
[15:19:34.400] iteration 4562: loss: 0.135005, loss_s1: 0.052266, loss_fp: 0.000721, loss_freq: 0.027147
[15:19:35.024] iteration 4563: loss: 0.098690, loss_s1: 0.036057, loss_fp: 0.000689, loss_freq: 0.023015
[15:19:35.649] iteration 4564: loss: 0.171293, loss_s1: 0.168360, loss_fp: 0.000950, loss_freq: 0.076007
[15:19:36.274] iteration 4565: loss: 0.098521, loss_s1: 0.057285, loss_fp: 0.000534, loss_freq: 0.018821
[15:19:36.898] iteration 4566: loss: 0.163509, loss_s1: 0.037476, loss_fp: 0.001627, loss_freq: 0.053928
[15:19:37.516] iteration 4567: loss: 0.086853, loss_s1: 0.032595, loss_fp: 0.005937, loss_freq: 0.029386
[15:19:38.140] iteration 4568: loss: 0.069696, loss_s1: 0.020200, loss_fp: 0.001337, loss_freq: 0.017308
[15:19:38.766] iteration 4569: loss: 0.102875, loss_s1: 0.057640, loss_fp: 0.003053, loss_freq: 0.039663
[15:19:39.392] iteration 4570: loss: 0.124318, loss_s1: 0.092889, loss_fp: 0.001235, loss_freq: 0.024418
[15:19:40.017] iteration 4571: loss: 0.115249, loss_s1: 0.087762, loss_fp: 0.001826, loss_freq: 0.027606
[15:19:40.647] iteration 4572: loss: 0.125250, loss_s1: 0.020498, loss_fp: 0.003644, loss_freq: 0.014810
[15:19:41.277] iteration 4573: loss: 0.095116, loss_s1: 0.066254, loss_fp: 0.001745, loss_freq: 0.018063
[15:19:41.900] iteration 4574: loss: 0.099124, loss_s1: 0.032584, loss_fp: 0.015244, loss_freq: 0.031392
[15:19:42.526] iteration 4575: loss: 0.183065, loss_s1: 0.078979, loss_fp: 0.007385, loss_freq: 0.071255
[15:19:43.149] iteration 4576: loss: 0.078237, loss_s1: 0.040231, loss_fp: 0.000989, loss_freq: 0.042841
[15:19:43.770] iteration 4577: loss: 0.096680, loss_s1: 0.028007, loss_fp: 0.003636, loss_freq: 0.019818
[15:19:44.391] iteration 4578: loss: 0.153031, loss_s1: 0.025561, loss_fp: 0.001856, loss_freq: 0.036538
[15:19:45.045] iteration 4579: loss: 0.171636, loss_s1: 0.152703, loss_fp: 0.001943, loss_freq: 0.043315
[15:19:45.670] iteration 4580: loss: 0.178110, loss_s1: 0.112146, loss_fp: 0.008588, loss_freq: 0.096515
[15:19:46.295] iteration 4581: loss: 0.112938, loss_s1: 0.021704, loss_fp: 0.001891, loss_freq: 0.061696
[15:19:46.916] iteration 4582: loss: 0.087950, loss_s1: 0.050754, loss_fp: 0.002083, loss_freq: 0.018763
[15:19:47.537] iteration 4583: loss: 0.087837, loss_s1: 0.016645, loss_fp: 0.009531, loss_freq: 0.020417
[15:19:48.162] iteration 4584: loss: 0.162398, loss_s1: 0.075599, loss_fp: 0.004268, loss_freq: 0.087744
[15:19:48.784] iteration 4585: loss: 0.116761, loss_s1: 0.102331, loss_fp: 0.010888, loss_freq: 0.050719
[15:19:49.411] iteration 4586: loss: 0.149385, loss_s1: 0.162230, loss_fp: 0.004382, loss_freq: 0.039089
[15:19:50.036] iteration 4587: loss: 0.071117, loss_s1: 0.053660, loss_fp: 0.001559, loss_freq: 0.011517
[15:19:50.659] iteration 4588: loss: 0.130521, loss_s1: 0.102466, loss_fp: 0.001252, loss_freq: 0.057548
[15:19:51.285] iteration 4589: loss: 0.141975, loss_s1: 0.041208, loss_fp: 0.001714, loss_freq: 0.061924
[15:19:51.905] iteration 4590: loss: 0.125501, loss_s1: 0.160519, loss_fp: 0.002583, loss_freq: 0.024118
[15:19:52.531] iteration 4591: loss: 0.254727, loss_s1: 0.174475, loss_fp: 0.001568, loss_freq: 0.187291
[15:19:53.159] iteration 4592: loss: 0.186379, loss_s1: 0.096985, loss_fp: 0.000619, loss_freq: 0.022946
[15:19:53.789] iteration 4593: loss: 0.147540, loss_s1: 0.080250, loss_fp: 0.001901, loss_freq: 0.121175
[15:19:54.410] iteration 4594: loss: 0.083021, loss_s1: 0.058549, loss_fp: 0.001276, loss_freq: 0.039702
[15:19:55.035] iteration 4595: loss: 0.161018, loss_s1: 0.044441, loss_fp: 0.002328, loss_freq: 0.073442
[15:19:55.666] iteration 4596: loss: 0.072917, loss_s1: 0.027736, loss_fp: 0.002347, loss_freq: 0.013878
[15:19:56.291] iteration 4597: loss: 0.192083, loss_s1: 0.129127, loss_fp: 0.007990, loss_freq: 0.047973
[15:19:56.937] iteration 4598: loss: 0.126936, loss_s1: 0.073556, loss_fp: 0.015475, loss_freq: 0.022091
[15:19:57.594] iteration 4599: loss: 0.107279, loss_s1: 0.015570, loss_fp: 0.003796, loss_freq: 0.024614
[15:19:58.243] iteration 4600: loss: 0.160119, loss_s1: 0.074094, loss_fp: 0.004792, loss_freq: 0.037868
[15:20:01.312] iteration 4600 : mean_dice : 0.606946
[15:20:01.963] iteration 4601: loss: 0.200422, loss_s1: 0.053362, loss_fp: 0.019604, loss_freq: 0.017474
[15:20:02.598] iteration 4602: loss: 0.087428, loss_s1: 0.046177, loss_fp: 0.002570, loss_freq: 0.016158
[15:20:03.227] iteration 4603: loss: 0.077874, loss_s1: 0.027714, loss_fp: 0.000691, loss_freq: 0.038332
[15:20:03.867] iteration 4604: loss: 0.052929, loss_s1: 0.022565, loss_fp: 0.002052, loss_freq: 0.010612
[15:20:04.501] iteration 4605: loss: 0.110464, loss_s1: 0.053603, loss_fp: 0.001562, loss_freq: 0.033989
[15:20:05.139] iteration 4606: loss: 0.095601, loss_s1: 0.038590, loss_fp: 0.000926, loss_freq: 0.018125
[15:20:05.777] iteration 4607: loss: 0.157421, loss_s1: 0.073844, loss_fp: 0.003593, loss_freq: 0.038238
[15:20:06.399] iteration 4608: loss: 0.079914, loss_s1: 0.062394, loss_fp: 0.001641, loss_freq: 0.019342
[15:20:07.024] iteration 4609: loss: 0.095736, loss_s1: 0.096778, loss_fp: 0.002029, loss_freq: 0.015101
[15:20:07.649] iteration 4610: loss: 0.102955, loss_s1: 0.032026, loss_fp: 0.001170, loss_freq: 0.032506
[15:20:08.273] iteration 4611: loss: 0.158075, loss_s1: 0.065986, loss_fp: 0.000920, loss_freq: 0.049506
[15:20:08.896] iteration 4612: loss: 0.109692, loss_s1: 0.037959, loss_fp: 0.001028, loss_freq: 0.062538
[15:20:09.522] iteration 4613: loss: 0.115155, loss_s1: 0.036494, loss_fp: 0.001225, loss_freq: 0.024568
[15:20:10.378] iteration 4614: loss: 0.120714, loss_s1: 0.044337, loss_fp: 0.001923, loss_freq: 0.023026
[15:20:11.094] iteration 4615: loss: 0.140012, loss_s1: 0.049536, loss_fp: 0.001039, loss_freq: 0.012588
[15:20:11.762] iteration 4616: loss: 0.133073, loss_s1: 0.089589, loss_fp: 0.001334, loss_freq: 0.057960
[15:20:12.383] iteration 4617: loss: 0.237525, loss_s1: 0.103454, loss_fp: 0.003060, loss_freq: 0.142405
[15:20:13.012] iteration 4618: loss: 0.129650, loss_s1: 0.058589, loss_fp: 0.002660, loss_freq: 0.040692
[15:20:13.637] iteration 4619: loss: 0.129297, loss_s1: 0.045354, loss_fp: 0.001743, loss_freq: 0.025418
[15:20:14.274] iteration 4620: loss: 0.074237, loss_s1: 0.024302, loss_fp: 0.007718, loss_freq: 0.036849
[15:20:14.908] iteration 4621: loss: 0.200336, loss_s1: 0.208374, loss_fp: 0.006270, loss_freq: 0.072967
[15:20:15.550] iteration 4622: loss: 0.114041, loss_s1: 0.033191, loss_fp: 0.001173, loss_freq: 0.039418
[15:20:16.193] iteration 4623: loss: 0.100668, loss_s1: 0.050900, loss_fp: 0.001383, loss_freq: 0.009439
[15:20:16.819] iteration 4624: loss: 0.154156, loss_s1: 0.114786, loss_fp: 0.011352, loss_freq: 0.073760
[15:20:17.441] iteration 4625: loss: 0.152308, loss_s1: 0.147223, loss_fp: 0.002246, loss_freq: 0.023593
[15:20:18.074] iteration 4626: loss: 0.134014, loss_s1: 0.143812, loss_fp: 0.001877, loss_freq: 0.027679
[15:20:18.702] iteration 4627: loss: 0.154149, loss_s1: 0.073799, loss_fp: 0.001691, loss_freq: 0.055246
[15:20:19.332] iteration 4628: loss: 0.160886, loss_s1: 0.154927, loss_fp: 0.000941, loss_freq: 0.083062
[15:20:19.958] iteration 4629: loss: 0.115009, loss_s1: 0.045487, loss_fp: 0.016106, loss_freq: 0.071602
[15:20:20.583] iteration 4630: loss: 0.152485, loss_s1: 0.042465, loss_fp: 0.000693, loss_freq: 0.010587
[15:20:21.209] iteration 4631: loss: 0.153777, loss_s1: 0.087566, loss_fp: 0.013806, loss_freq: 0.110074
[15:20:21.831] iteration 4632: loss: 0.104856, loss_s1: 0.014248, loss_fp: 0.001794, loss_freq: 0.028222
[15:20:22.459] iteration 4633: loss: 0.151561, loss_s1: 0.031558, loss_fp: 0.000842, loss_freq: 0.064617
[15:20:23.091] iteration 4634: loss: 0.143253, loss_s1: 0.058991, loss_fp: 0.000994, loss_freq: 0.028674
[15:20:23.718] iteration 4635: loss: 0.107134, loss_s1: 0.033284, loss_fp: 0.001050, loss_freq: 0.026146
[15:20:24.341] iteration 4636: loss: 0.261893, loss_s1: 0.151428, loss_fp: 0.011654, loss_freq: 0.094027
[15:20:24.966] iteration 4637: loss: 0.119898, loss_s1: 0.125680, loss_fp: 0.005688, loss_freq: 0.019996
[15:20:25.592] iteration 4638: loss: 0.109508, loss_s1: 0.085523, loss_fp: 0.000877, loss_freq: 0.013993
[15:20:26.223] iteration 4639: loss: 0.150535, loss_s1: 0.113983, loss_fp: 0.003276, loss_freq: 0.077801
[15:20:26.859] iteration 4640: loss: 0.140159, loss_s1: 0.087298, loss_fp: 0.002410, loss_freq: 0.073218
[15:20:27.483] iteration 4641: loss: 0.122835, loss_s1: 0.081188, loss_fp: 0.003856, loss_freq: 0.034187
[15:20:28.108] iteration 4642: loss: 0.210084, loss_s1: 0.099960, loss_fp: 0.005513, loss_freq: 0.046517
[15:20:28.731] iteration 4643: loss: 0.112062, loss_s1: 0.060133, loss_fp: 0.012526, loss_freq: 0.066408
[15:20:29.360] iteration 4644: loss: 0.098906, loss_s1: 0.089317, loss_fp: 0.001862, loss_freq: 0.021153
[15:20:29.984] iteration 4645: loss: 0.150886, loss_s1: 0.049216, loss_fp: 0.001359, loss_freq: 0.067266
[15:20:30.610] iteration 4646: loss: 0.109776, loss_s1: 0.033529, loss_fp: 0.006380, loss_freq: 0.014854
[15:20:31.231] iteration 4647: loss: 0.080344, loss_s1: 0.028127, loss_fp: 0.003212, loss_freq: 0.031408
[15:20:31.854] iteration 4648: loss: 0.181113, loss_s1: 0.043152, loss_fp: 0.001846, loss_freq: 0.057488
[15:20:32.476] iteration 4649: loss: 0.131402, loss_s1: 0.065002, loss_fp: 0.003165, loss_freq: 0.051930
[15:20:33.100] iteration 4650: loss: 0.123408, loss_s1: 0.041452, loss_fp: 0.001312, loss_freq: 0.019330
[15:20:33.726] iteration 4651: loss: 0.119865, loss_s1: 0.034325, loss_fp: 0.001232, loss_freq: 0.054993
[15:20:34.352] iteration 4652: loss: 0.108845, loss_s1: 0.069861, loss_fp: 0.001561, loss_freq: 0.016803
[15:20:34.977] iteration 4653: loss: 0.108649, loss_s1: 0.029397, loss_fp: 0.003058, loss_freq: 0.020348
[15:20:35.595] iteration 4654: loss: 0.110535, loss_s1: 0.026923, loss_fp: 0.002064, loss_freq: 0.011207
[15:20:36.219] iteration 4655: loss: 0.094401, loss_s1: 0.089065, loss_fp: 0.001314, loss_freq: 0.029293
[15:20:36.842] iteration 4656: loss: 0.134585, loss_s1: 0.083203, loss_fp: 0.001954, loss_freq: 0.043281
[15:20:37.490] iteration 4657: loss: 0.100882, loss_s1: 0.044273, loss_fp: 0.001882, loss_freq: 0.018381
[15:20:38.111] iteration 4658: loss: 0.126067, loss_s1: 0.077309, loss_fp: 0.004235, loss_freq: 0.054599
[15:20:38.733] iteration 4659: loss: 0.131873, loss_s1: 0.049254, loss_fp: 0.010132, loss_freq: 0.028826
[15:20:39.356] iteration 4660: loss: 0.146971, loss_s1: 0.111363, loss_fp: 0.001829, loss_freq: 0.069940
[15:20:39.977] iteration 4661: loss: 0.075891, loss_s1: 0.067979, loss_fp: 0.004384, loss_freq: 0.016458
[15:20:40.602] iteration 4662: loss: 0.221180, loss_s1: 0.178157, loss_fp: 0.004294, loss_freq: 0.025037
[15:20:41.225] iteration 4663: loss: 0.090747, loss_s1: 0.023969, loss_fp: 0.000835, loss_freq: 0.013996
[15:20:41.853] iteration 4664: loss: 0.101887, loss_s1: 0.098851, loss_fp: 0.002696, loss_freq: 0.014456
[15:20:42.472] iteration 4665: loss: 0.148203, loss_s1: 0.042196, loss_fp: 0.000464, loss_freq: 0.017109
[15:20:43.097] iteration 4666: loss: 0.154685, loss_s1: 0.088601, loss_fp: 0.001061, loss_freq: 0.092522
[15:20:43.722] iteration 4667: loss: 0.101309, loss_s1: 0.064869, loss_fp: 0.000895, loss_freq: 0.029224
[15:20:44.345] iteration 4668: loss: 0.165469, loss_s1: 0.039963, loss_fp: 0.001549, loss_freq: 0.056383
[15:20:44.971] iteration 4669: loss: 0.100366, loss_s1: 0.049088, loss_fp: 0.004889, loss_freq: 0.032232
[15:20:45.931] iteration 4670: loss: 0.126114, loss_s1: 0.043423, loss_fp: 0.001981, loss_freq: 0.017338
[15:20:46.562] iteration 4671: loss: 0.153677, loss_s1: 0.085640, loss_fp: 0.001031, loss_freq: 0.095915
[15:20:47.192] iteration 4672: loss: 0.114079, loss_s1: 0.060214, loss_fp: 0.001800, loss_freq: 0.032478
[15:20:47.828] iteration 4673: loss: 0.119745, loss_s1: 0.050939, loss_fp: 0.000304, loss_freq: 0.037028
[15:20:48.453] iteration 4674: loss: 0.089998, loss_s1: 0.048753, loss_fp: 0.000780, loss_freq: 0.026739
[15:20:49.072] iteration 4675: loss: 0.193564, loss_s1: 0.086637, loss_fp: 0.008722, loss_freq: 0.062336
[15:20:49.699] iteration 4676: loss: 0.050388, loss_s1: 0.006516, loss_fp: 0.001522, loss_freq: 0.012574
[15:20:50.331] iteration 4677: loss: 0.124481, loss_s1: 0.076745, loss_fp: 0.001738, loss_freq: 0.065468
[15:20:50.955] iteration 4678: loss: 0.112288, loss_s1: 0.081583, loss_fp: 0.002158, loss_freq: 0.027764
[15:20:51.587] iteration 4679: loss: 0.127661, loss_s1: 0.085008, loss_fp: 0.004458, loss_freq: 0.048493
[15:20:52.212] iteration 4680: loss: 0.135207, loss_s1: 0.076240, loss_fp: 0.001217, loss_freq: 0.045234
[15:20:52.835] iteration 4681: loss: 0.158895, loss_s1: 0.124185, loss_fp: 0.010050, loss_freq: 0.067282
[15:20:53.465] iteration 4682: loss: 0.102770, loss_s1: 0.024234, loss_fp: 0.010803, loss_freq: 0.047374
[15:20:54.090] iteration 4683: loss: 0.109494, loss_s1: 0.043865, loss_fp: 0.009938, loss_freq: 0.021633
[15:20:54.717] iteration 4684: loss: 0.126815, loss_s1: 0.085614, loss_fp: 0.006070, loss_freq: 0.043607
[15:20:55.356] iteration 4685: loss: 0.160549, loss_s1: 0.082274, loss_fp: 0.001131, loss_freq: 0.087917
[15:20:55.976] iteration 4686: loss: 0.121582, loss_s1: 0.086079, loss_fp: 0.002351, loss_freq: 0.014776
[15:20:56.622] iteration 4687: loss: 0.117496, loss_s1: 0.065693, loss_fp: 0.003065, loss_freq: 0.041641
[15:20:57.245] iteration 4688: loss: 0.136210, loss_s1: 0.055773, loss_fp: 0.001224, loss_freq: 0.037103
[15:20:57.870] iteration 4689: loss: 0.135056, loss_s1: 0.096177, loss_fp: 0.003889, loss_freq: 0.046234
[15:20:58.501] iteration 4690: loss: 0.095160, loss_s1: 0.037626, loss_fp: 0.001896, loss_freq: 0.010331
[15:20:59.128] iteration 4691: loss: 0.115806, loss_s1: 0.080346, loss_fp: 0.001986, loss_freq: 0.023820
[15:20:59.749] iteration 4692: loss: 0.129725, loss_s1: 0.044776, loss_fp: 0.000977, loss_freq: 0.016017
[15:21:00.374] iteration 4693: loss: 0.135312, loss_s1: 0.114426, loss_fp: 0.001661, loss_freq: 0.064012
[15:21:01.007] iteration 4694: loss: 0.062503, loss_s1: 0.035242, loss_fp: 0.000741, loss_freq: 0.015827
[15:21:01.636] iteration 4695: loss: 0.125569, loss_s1: 0.081941, loss_fp: 0.003631, loss_freq: 0.037654
[15:21:02.262] iteration 4696: loss: 0.152049, loss_s1: 0.060948, loss_fp: 0.000627, loss_freq: 0.136216
[15:21:02.889] iteration 4697: loss: 0.132660, loss_s1: 0.069556, loss_fp: 0.002872, loss_freq: 0.040707
[15:21:03.512] iteration 4698: loss: 0.119302, loss_s1: 0.051028, loss_fp: 0.006613, loss_freq: 0.041697
[15:21:04.136] iteration 4699: loss: 0.084974, loss_s1: 0.022842, loss_fp: 0.008254, loss_freq: 0.011957
[15:21:04.761] iteration 4700: loss: 0.088106, loss_s1: 0.047254, loss_fp: 0.002115, loss_freq: 0.019048
[15:21:05.387] iteration 4701: loss: 0.168951, loss_s1: 0.054718, loss_fp: 0.014822, loss_freq: 0.035110
[15:21:06.012] iteration 4702: loss: 0.059571, loss_s1: 0.017035, loss_fp: 0.000600, loss_freq: 0.006228
[15:21:06.634] iteration 4703: loss: 0.056973, loss_s1: 0.022741, loss_fp: 0.001683, loss_freq: 0.016594
[15:21:07.254] iteration 4704: loss: 0.209943, loss_s1: 0.097103, loss_fp: 0.011887, loss_freq: 0.019308
[15:21:07.882] iteration 4705: loss: 0.133578, loss_s1: 0.087179, loss_fp: 0.004724, loss_freq: 0.053645
[15:21:08.508] iteration 4706: loss: 0.151707, loss_s1: 0.100635, loss_fp: 0.003877, loss_freq: 0.049890
[15:21:09.138] iteration 4707: loss: 0.126745, loss_s1: 0.048368, loss_fp: 0.002509, loss_freq: 0.029900
[15:21:09.767] iteration 4708: loss: 0.157954, loss_s1: 0.091514, loss_fp: 0.000568, loss_freq: 0.104130
[15:21:10.393] iteration 4709: loss: 0.137104, loss_s1: 0.072514, loss_fp: 0.002226, loss_freq: 0.062366
[15:21:11.017] iteration 4710: loss: 0.171765, loss_s1: 0.033238, loss_fp: 0.002989, loss_freq: 0.021153
[15:21:11.639] iteration 4711: loss: 0.054465, loss_s1: 0.015096, loss_fp: 0.000946, loss_freq: 0.025983
[15:21:12.258] iteration 4712: loss: 0.097645, loss_s1: 0.031619, loss_fp: 0.009128, loss_freq: 0.037704
[15:21:12.883] iteration 4713: loss: 0.113654, loss_s1: 0.069012, loss_fp: 0.003340, loss_freq: 0.030889
[15:21:13.507] iteration 4714: loss: 0.110154, loss_s1: 0.036307, loss_fp: 0.001846, loss_freq: 0.067268
[15:21:14.135] iteration 4715: loss: 0.082891, loss_s1: 0.020947, loss_fp: 0.004027, loss_freq: 0.008535
[15:21:14.765] iteration 4716: loss: 0.093520, loss_s1: 0.044233, loss_fp: 0.002146, loss_freq: 0.016571
[15:21:15.396] iteration 4717: loss: 0.096451, loss_s1: 0.079723, loss_fp: 0.008462, loss_freq: 0.008413
[15:21:16.027] iteration 4718: loss: 0.153509, loss_s1: 0.075357, loss_fp: 0.000842, loss_freq: 0.020895
[15:21:16.661] iteration 4719: loss: 0.155861, loss_s1: 0.134065, loss_fp: 0.013085, loss_freq: 0.042135
[15:21:17.302] iteration 4720: loss: 0.093218, loss_s1: 0.080996, loss_fp: 0.004645, loss_freq: 0.006356
[15:21:17.923] iteration 4721: loss: 0.112055, loss_s1: 0.006307, loss_fp: 0.001510, loss_freq: 0.026408
[15:21:18.549] iteration 4722: loss: 0.130022, loss_s1: 0.058672, loss_fp: 0.004526, loss_freq: 0.088123
[15:21:19.176] iteration 4723: loss: 0.154064, loss_s1: 0.109484, loss_fp: 0.000927, loss_freq: 0.010928
[15:21:19.810] iteration 4724: loss: 0.121842, loss_s1: 0.058573, loss_fp: 0.006764, loss_freq: 0.020919
[15:21:20.438] iteration 4725: loss: 0.160386, loss_s1: 0.170049, loss_fp: 0.005190, loss_freq: 0.038258
[15:21:21.063] iteration 4726: loss: 0.141377, loss_s1: 0.081454, loss_fp: 0.002031, loss_freq: 0.009534
[15:21:21.687] iteration 4727: loss: 0.146587, loss_s1: 0.087239, loss_fp: 0.005215, loss_freq: 0.052270
[15:21:22.314] iteration 4728: loss: 0.161163, loss_s1: 0.090636, loss_fp: 0.002657, loss_freq: 0.019966
[15:21:22.937] iteration 4729: loss: 0.061429, loss_s1: 0.014621, loss_fp: 0.001617, loss_freq: 0.014519
[15:21:23.563] iteration 4730: loss: 0.074292, loss_s1: 0.039285, loss_fp: 0.001049, loss_freq: 0.022206
[15:21:24.189] iteration 4731: loss: 0.095954, loss_s1: 0.030455, loss_fp: 0.002170, loss_freq: 0.032264
[15:21:24.815] iteration 4732: loss: 0.102058, loss_s1: 0.062730, loss_fp: 0.003382, loss_freq: 0.017686
[15:21:25.443] iteration 4733: loss: 0.122031, loss_s1: 0.056832, loss_fp: 0.002016, loss_freq: 0.045562
[15:21:26.076] iteration 4734: loss: 0.063071, loss_s1: 0.018760, loss_fp: 0.000929, loss_freq: 0.009001
[15:21:26.700] iteration 4735: loss: 0.125044, loss_s1: 0.061838, loss_fp: 0.001504, loss_freq: 0.045903
[15:21:27.330] iteration 4736: loss: 0.149664, loss_s1: 0.056698, loss_fp: 0.001433, loss_freq: 0.049054
[15:21:27.955] iteration 4737: loss: 0.076151, loss_s1: 0.030829, loss_fp: 0.002352, loss_freq: 0.044652
[15:21:28.582] iteration 4738: loss: 0.104252, loss_s1: 0.073744, loss_fp: 0.002106, loss_freq: 0.018223
[15:21:29.205] iteration 4739: loss: 0.132502, loss_s1: 0.077346, loss_fp: 0.001154, loss_freq: 0.009756
[15:21:29.838] iteration 4740: loss: 0.147622, loss_s1: 0.023478, loss_fp: 0.005126, loss_freq: 0.017881
[15:21:30.466] iteration 4741: loss: 0.161472, loss_s1: 0.046283, loss_fp: 0.000802, loss_freq: 0.105036
[15:21:31.096] iteration 4742: loss: 0.106325, loss_s1: 0.063678, loss_fp: 0.000297, loss_freq: 0.022157
[15:21:31.722] iteration 4743: loss: 0.110363, loss_s1: 0.076950, loss_fp: 0.002644, loss_freq: 0.014478
[15:21:32.348] iteration 4744: loss: 0.174204, loss_s1: 0.185357, loss_fp: 0.005887, loss_freq: 0.023428
[15:21:32.971] iteration 4745: loss: 0.178522, loss_s1: 0.141176, loss_fp: 0.001918, loss_freq: 0.082889
[15:21:33.599] iteration 4746: loss: 0.138030, loss_s1: 0.073846, loss_fp: 0.000650, loss_freq: 0.084706
[15:21:34.225] iteration 4747: loss: 0.118135, loss_s1: 0.132904, loss_fp: 0.013245, loss_freq: 0.019175
[15:21:34.850] iteration 4748: loss: 0.075952, loss_s1: 0.072379, loss_fp: 0.001816, loss_freq: 0.006301
[15:21:35.476] iteration 4749: loss: 0.110624, loss_s1: 0.090799, loss_fp: 0.003800, loss_freq: 0.026428
[15:21:36.103] iteration 4750: loss: 0.150527, loss_s1: 0.137966, loss_fp: 0.003318, loss_freq: 0.037769
[15:21:36.729] iteration 4751: loss: 0.053506, loss_s1: 0.021704, loss_fp: 0.006108, loss_freq: 0.015521
[15:21:37.356] iteration 4752: loss: 0.215921, loss_s1: 0.189542, loss_fp: 0.012955, loss_freq: 0.132339
[15:21:37.978] iteration 4753: loss: 0.090792, loss_s1: 0.028077, loss_fp: 0.004405, loss_freq: 0.022419
[15:21:38.611] iteration 4754: loss: 0.111653, loss_s1: 0.024574, loss_fp: 0.027499, loss_freq: 0.065151
[15:21:39.238] iteration 4755: loss: 0.059828, loss_s1: 0.034288, loss_fp: 0.001238, loss_freq: 0.010862
[15:21:39.861] iteration 4756: loss: 0.171145, loss_s1: 0.042088, loss_fp: 0.000593, loss_freq: 0.016438
[15:21:40.493] iteration 4757: loss: 0.099496, loss_s1: 0.050340, loss_fp: 0.000887, loss_freq: 0.015974
[15:21:41.114] iteration 4758: loss: 0.147455, loss_s1: 0.087591, loss_fp: 0.001931, loss_freq: 0.021766
[15:21:41.738] iteration 4759: loss: 0.087471, loss_s1: 0.023784, loss_fp: 0.001706, loss_freq: 0.013479
[15:21:42.361] iteration 4760: loss: 0.134740, loss_s1: 0.041771, loss_fp: 0.003077, loss_freq: 0.017783
[15:21:42.985] iteration 4761: loss: 0.096638, loss_s1: 0.013415, loss_fp: 0.000835, loss_freq: 0.014879
[15:21:43.608] iteration 4762: loss: 0.160535, loss_s1: 0.025734, loss_fp: 0.008722, loss_freq: 0.025136
[15:21:44.234] iteration 4763: loss: 0.081323, loss_s1: 0.037497, loss_fp: 0.001086, loss_freq: 0.025880
[15:21:44.857] iteration 4764: loss: 0.094721, loss_s1: 0.071195, loss_fp: 0.002076, loss_freq: 0.039295
[15:21:45.478] iteration 4765: loss: 0.083873, loss_s1: 0.053766, loss_fp: 0.001180, loss_freq: 0.023513
[15:21:46.105] iteration 4766: loss: 0.097373, loss_s1: 0.048649, loss_fp: 0.004183, loss_freq: 0.030470
[15:21:46.727] iteration 4767: loss: 0.104332, loss_s1: 0.026183, loss_fp: 0.001045, loss_freq: 0.020638
[15:21:47.353] iteration 4768: loss: 0.111380, loss_s1: 0.064647, loss_fp: 0.001425, loss_freq: 0.019962
[15:21:47.980] iteration 4769: loss: 0.081594, loss_s1: 0.042208, loss_fp: 0.001737, loss_freq: 0.028470
[15:21:48.605] iteration 4770: loss: 0.140184, loss_s1: 0.095044, loss_fp: 0.001246, loss_freq: 0.042792
[15:21:49.230] iteration 4771: loss: 0.109849, loss_s1: 0.026504, loss_fp: 0.001509, loss_freq: 0.022260
[15:21:49.856] iteration 4772: loss: 0.140595, loss_s1: 0.090624, loss_fp: 0.000580, loss_freq: 0.053546
[15:21:50.480] iteration 4773: loss: 0.179284, loss_s1: 0.130412, loss_fp: 0.002613, loss_freq: 0.066269
[15:21:51.110] iteration 4774: loss: 0.144222, loss_s1: 0.048084, loss_fp: 0.003553, loss_freq: 0.024124
[15:21:51.730] iteration 4775: loss: 0.107714, loss_s1: 0.055843, loss_fp: 0.000530, loss_freq: 0.021288
[15:21:52.353] iteration 4776: loss: 0.089962, loss_s1: 0.036743, loss_fp: 0.003015, loss_freq: 0.006342
[15:21:52.979] iteration 4777: loss: 0.154380, loss_s1: 0.095943, loss_fp: 0.004130, loss_freq: 0.059873
[15:21:53.607] iteration 4778: loss: 0.205995, loss_s1: 0.081418, loss_fp: 0.003393, loss_freq: 0.220488
[15:21:54.230] iteration 4779: loss: 0.097445, loss_s1: 0.034381, loss_fp: 0.000822, loss_freq: 0.062429
[15:21:54.855] iteration 4780: loss: 0.158811, loss_s1: 0.059379, loss_fp: 0.003977, loss_freq: 0.034329
[15:21:55.483] iteration 4781: loss: 0.071331, loss_s1: 0.056405, loss_fp: 0.003806, loss_freq: 0.009807
[15:21:56.109] iteration 4782: loss: 0.134385, loss_s1: 0.071223, loss_fp: 0.002233, loss_freq: 0.073175
[15:21:56.731] iteration 4783: loss: 0.067800, loss_s1: 0.028688, loss_fp: 0.001788, loss_freq: 0.034404
[15:21:57.364] iteration 4784: loss: 0.095065, loss_s1: 0.054502, loss_fp: 0.002620, loss_freq: 0.007066
[15:21:57.991] iteration 4785: loss: 0.175712, loss_s1: 0.049622, loss_fp: 0.003809, loss_freq: 0.055461
[15:21:58.615] iteration 4786: loss: 0.127584, loss_s1: 0.051390, loss_fp: 0.008151, loss_freq: 0.022148
[15:21:59.242] iteration 4787: loss: 0.112182, loss_s1: 0.057678, loss_fp: 0.001986, loss_freq: 0.061003
[15:21:59.867] iteration 4788: loss: 0.122808, loss_s1: 0.041162, loss_fp: 0.003482, loss_freq: 0.035402
[15:22:00.491] iteration 4789: loss: 0.162337, loss_s1: 0.075841, loss_fp: 0.003270, loss_freq: 0.104175
[15:22:01.122] iteration 4790: loss: 0.079332, loss_s1: 0.050510, loss_fp: 0.001572, loss_freq: 0.023298
[15:22:01.747] iteration 4791: loss: 0.146576, loss_s1: 0.038133, loss_fp: 0.000635, loss_freq: 0.016700
[15:22:02.384] iteration 4792: loss: 0.141422, loss_s1: 0.128413, loss_fp: 0.000568, loss_freq: 0.045163
[15:22:03.011] iteration 4793: loss: 0.136271, loss_s1: 0.106946, loss_fp: 0.003294, loss_freq: 0.031626
[15:22:03.635] iteration 4794: loss: 0.111782, loss_s1: 0.060327, loss_fp: 0.001120, loss_freq: 0.035322
[15:22:04.254] iteration 4795: loss: 0.102585, loss_s1: 0.044442, loss_fp: 0.002287, loss_freq: 0.031791
[15:22:04.876] iteration 4796: loss: 0.073511, loss_s1: 0.020194, loss_fp: 0.000801, loss_freq: 0.013733
[15:22:05.507] iteration 4797: loss: 0.238445, loss_s1: 0.185078, loss_fp: 0.002004, loss_freq: 0.082488
[15:22:06.132] iteration 4798: loss: 0.066809, loss_s1: 0.050711, loss_fp: 0.001579, loss_freq: 0.007501
[15:22:06.756] iteration 4799: loss: 0.089669, loss_s1: 0.052462, loss_fp: 0.001830, loss_freq: 0.031748
[15:22:07.428] iteration 4800: loss: 0.129256, loss_s1: 0.080451, loss_fp: 0.004453, loss_freq: 0.064494
[15:22:10.849] iteration 4800 : mean_dice : 0.613107
[15:22:11.485] iteration 4801: loss: 0.170293, loss_s1: 0.068985, loss_fp: 0.006714, loss_freq: 0.083630
[15:22:12.146] iteration 4802: loss: 0.112483, loss_s1: 0.050814, loss_fp: 0.002447, loss_freq: 0.054827
[15:22:12.877] iteration 4803: loss: 0.151988, loss_s1: 0.100341, loss_fp: 0.000557, loss_freq: 0.032013
[15:22:13.521] iteration 4804: loss: 0.167999, loss_s1: 0.144794, loss_fp: 0.004358, loss_freq: 0.078769
[15:22:14.159] iteration 4805: loss: 0.123547, loss_s1: 0.078141, loss_fp: 0.002699, loss_freq: 0.052693
[15:22:14.872] iteration 4806: loss: 0.116761, loss_s1: 0.051835, loss_fp: 0.001561, loss_freq: 0.046995
[15:22:15.513] iteration 4807: loss: 0.109076, loss_s1: 0.085492, loss_fp: 0.002691, loss_freq: 0.035974
[15:22:16.137] iteration 4808: loss: 0.097632, loss_s1: 0.048499, loss_fp: 0.013840, loss_freq: 0.036675
[15:22:16.763] iteration 4809: loss: 0.198779, loss_s1: 0.077379, loss_fp: 0.006775, loss_freq: 0.066829
[15:22:17.386] iteration 4810: loss: 0.130665, loss_s1: 0.092845, loss_fp: 0.001420, loss_freq: 0.032813
[15:22:18.010] iteration 4811: loss: 0.099191, loss_s1: 0.025876, loss_fp: 0.001682, loss_freq: 0.018016
[15:22:18.641] iteration 4812: loss: 0.124612, loss_s1: 0.059289, loss_fp: 0.003061, loss_freq: 0.057358
[15:22:19.264] iteration 4813: loss: 0.156505, loss_s1: 0.111991, loss_fp: 0.001647, loss_freq: 0.028688
[15:22:19.880] iteration 4814: loss: 0.116533, loss_s1: 0.051086, loss_fp: 0.006222, loss_freq: 0.013537
[15:22:20.500] iteration 4815: loss: 0.136955, loss_s1: 0.036362, loss_fp: 0.006388, loss_freq: 0.009245
[15:22:21.127] iteration 4816: loss: 0.086156, loss_s1: 0.057448, loss_fp: 0.002595, loss_freq: 0.044407
[15:22:21.754] iteration 4817: loss: 0.096584, loss_s1: 0.073717, loss_fp: 0.002162, loss_freq: 0.021211
[15:22:22.389] iteration 4818: loss: 0.086840, loss_s1: 0.028590, loss_fp: 0.002410, loss_freq: 0.044166
[15:22:23.011] iteration 4819: loss: 0.123834, loss_s1: 0.051845, loss_fp: 0.006702, loss_freq: 0.029992
[15:22:23.639] iteration 4820: loss: 0.126775, loss_s1: 0.047115, loss_fp: 0.002485, loss_freq: 0.012656
[15:22:24.256] iteration 4821: loss: 0.112870, loss_s1: 0.093982, loss_fp: 0.004224, loss_freq: 0.042536
[15:22:24.878] iteration 4822: loss: 0.049603, loss_s1: 0.016416, loss_fp: 0.004960, loss_freq: 0.009280
[15:22:25.505] iteration 4823: loss: 0.137731, loss_s1: 0.021973, loss_fp: 0.000619, loss_freq: 0.028677
[15:22:26.133] iteration 4824: loss: 0.089148, loss_s1: 0.043643, loss_fp: 0.005234, loss_freq: 0.009171
[15:22:26.754] iteration 4825: loss: 0.097857, loss_s1: 0.065693, loss_fp: 0.000732, loss_freq: 0.011317
[15:22:27.375] iteration 4826: loss: 0.226364, loss_s1: 0.051128, loss_fp: 0.000583, loss_freq: 0.019275
[15:22:27.994] iteration 4827: loss: 0.140387, loss_s1: 0.076371, loss_fp: 0.008697, loss_freq: 0.059135
[15:22:28.615] iteration 4828: loss: 0.115154, loss_s1: 0.055714, loss_fp: 0.003878, loss_freq: 0.036347
[15:22:29.242] iteration 4829: loss: 0.166695, loss_s1: 0.106080, loss_fp: 0.001815, loss_freq: 0.026577
[15:22:29.876] iteration 4830: loss: 0.132670, loss_s1: 0.049706, loss_fp: 0.003532, loss_freq: 0.046085
[15:22:31.139] iteration 4831: loss: 0.152709, loss_s1: 0.066147, loss_fp: 0.000535, loss_freq: 0.025210
[15:22:31.765] iteration 4832: loss: 0.114406, loss_s1: 0.079975, loss_fp: 0.001091, loss_freq: 0.011419
[15:22:32.391] iteration 4833: loss: 0.128149, loss_s1: 0.057166, loss_fp: 0.000757, loss_freq: 0.035703
[15:22:33.056] iteration 4834: loss: 0.105836, loss_s1: 0.018802, loss_fp: 0.000294, loss_freq: 0.028451
[15:22:33.682] iteration 4835: loss: 0.138356, loss_s1: 0.037531, loss_fp: 0.002850, loss_freq: 0.023898
[15:22:34.318] iteration 4836: loss: 0.192764, loss_s1: 0.131744, loss_fp: 0.002770, loss_freq: 0.077022
[15:22:34.944] iteration 4837: loss: 0.077226, loss_s1: 0.081227, loss_fp: 0.000636, loss_freq: 0.010689
[15:22:35.573] iteration 4838: loss: 0.106447, loss_s1: 0.075226, loss_fp: 0.007974, loss_freq: 0.046004
[15:22:36.205] iteration 4839: loss: 0.070409, loss_s1: 0.039867, loss_fp: 0.000966, loss_freq: 0.011417
[15:22:36.837] iteration 4840: loss: 0.099290, loss_s1: 0.081365, loss_fp: 0.004277, loss_freq: 0.030342
[15:22:37.468] iteration 4841: loss: 0.115554, loss_s1: 0.032011, loss_fp: 0.001538, loss_freq: 0.017758
[15:22:38.099] iteration 4842: loss: 0.175268, loss_s1: 0.079993, loss_fp: 0.000527, loss_freq: 0.055838
[15:22:38.728] iteration 4843: loss: 0.089554, loss_s1: 0.031637, loss_fp: 0.009291, loss_freq: 0.021033
[15:22:39.358] iteration 4844: loss: 0.161350, loss_s1: 0.128132, loss_fp: 0.007151, loss_freq: 0.031114
[15:22:39.984] iteration 4845: loss: 0.137878, loss_s1: 0.093965, loss_fp: 0.004688, loss_freq: 0.017857
[15:22:40.606] iteration 4846: loss: 0.115114, loss_s1: 0.058093, loss_fp: 0.006500, loss_freq: 0.040588
[15:22:41.234] iteration 4847: loss: 0.105633, loss_s1: 0.040277, loss_fp: 0.001315, loss_freq: 0.017548
[15:22:41.865] iteration 4848: loss: 0.105803, loss_s1: 0.046619, loss_fp: 0.000666, loss_freq: 0.048273
[15:22:42.510] iteration 4849: loss: 0.142248, loss_s1: 0.029324, loss_fp: 0.000498, loss_freq: 0.011680
[15:22:43.152] iteration 4850: loss: 0.123684, loss_s1: 0.033920, loss_fp: 0.001245, loss_freq: 0.029515
[15:22:43.796] iteration 4851: loss: 0.082179, loss_s1: 0.057927, loss_fp: 0.000667, loss_freq: 0.008958
[15:22:44.467] iteration 4852: loss: 0.156162, loss_s1: 0.077506, loss_fp: 0.001960, loss_freq: 0.029558
[15:22:45.104] iteration 4853: loss: 0.123430, loss_s1: 0.078328, loss_fp: 0.000827, loss_freq: 0.013837
[15:22:45.730] iteration 4854: loss: 0.213684, loss_s1: 0.120041, loss_fp: 0.001479, loss_freq: 0.155652
[15:22:46.352] iteration 4855: loss: 0.058484, loss_s1: 0.024556, loss_fp: 0.000410, loss_freq: 0.016556
[15:22:46.982] iteration 4856: loss: 0.108089, loss_s1: 0.069017, loss_fp: 0.001206, loss_freq: 0.061787
[15:22:47.612] iteration 4857: loss: 0.104050, loss_s1: 0.076319, loss_fp: 0.006242, loss_freq: 0.014355
[15:22:48.244] iteration 4858: loss: 0.130096, loss_s1: 0.095341, loss_fp: 0.002065, loss_freq: 0.027772
[15:22:48.914] iteration 4859: loss: 0.137006, loss_s1: 0.071691, loss_fp: 0.000995, loss_freq: 0.024100
[15:22:49.546] iteration 4860: loss: 0.111561, loss_s1: 0.070388, loss_fp: 0.003690, loss_freq: 0.021327
[15:22:50.167] iteration 4861: loss: 0.083922, loss_s1: 0.014836, loss_fp: 0.001502, loss_freq: 0.028887
[15:22:50.807] iteration 4862: loss: 0.161606, loss_s1: 0.029616, loss_fp: 0.007014, loss_freq: 0.024171
[15:22:51.477] iteration 4863: loss: 0.117127, loss_s1: 0.078807, loss_fp: 0.005435, loss_freq: 0.030835
[15:22:52.139] iteration 4864: loss: 0.075422, loss_s1: 0.032462, loss_fp: 0.001057, loss_freq: 0.026591
[15:22:52.798] iteration 4865: loss: 0.104864, loss_s1: 0.018125, loss_fp: 0.009384, loss_freq: 0.018550
[15:22:53.428] iteration 4866: loss: 0.091822, loss_s1: 0.058335, loss_fp: 0.000541, loss_freq: 0.017077
[15:22:54.096] iteration 4867: loss: 0.130166, loss_s1: 0.059836, loss_fp: 0.007173, loss_freq: 0.032198
[15:22:54.761] iteration 4868: loss: 0.074913, loss_s1: 0.043092, loss_fp: 0.000582, loss_freq: 0.013387
[15:22:55.421] iteration 4869: loss: 0.165621, loss_s1: 0.107898, loss_fp: 0.001599, loss_freq: 0.086916
[15:22:56.039] iteration 4870: loss: 0.096264, loss_s1: 0.050803, loss_fp: 0.000979, loss_freq: 0.057157
[15:22:56.657] iteration 4871: loss: 0.106725, loss_s1: 0.022934, loss_fp: 0.001775, loss_freq: 0.011506
[15:22:57.276] iteration 4872: loss: 0.074315, loss_s1: 0.042009, loss_fp: 0.001739, loss_freq: 0.029606
[15:22:57.899] iteration 4873: loss: 0.114985, loss_s1: 0.096307, loss_fp: 0.001614, loss_freq: 0.025256
[15:22:58.525] iteration 4874: loss: 0.100732, loss_s1: 0.105646, loss_fp: 0.001253, loss_freq: 0.026624
[15:22:59.155] iteration 4875: loss: 0.099945, loss_s1: 0.047439, loss_fp: 0.003934, loss_freq: 0.048242
[15:22:59.814] iteration 4876: loss: 0.134924, loss_s1: 0.070088, loss_fp: 0.000560, loss_freq: 0.014988
[15:23:00.477] iteration 4877: loss: 0.082506, loss_s1: 0.022158, loss_fp: 0.001083, loss_freq: 0.028361
[15:23:01.140] iteration 4878: loss: 0.064466, loss_s1: 0.049321, loss_fp: 0.007666, loss_freq: 0.007099
[15:23:01.791] iteration 4879: loss: 0.151542, loss_s1: 0.038825, loss_fp: 0.003619, loss_freq: 0.022243
[15:23:02.416] iteration 4880: loss: 0.095421, loss_s1: 0.041936, loss_fp: 0.003033, loss_freq: 0.052318
[15:23:03.036] iteration 4881: loss: 0.102380, loss_s1: 0.100150, loss_fp: 0.002224, loss_freq: 0.043765
[15:23:03.669] iteration 4882: loss: 0.165281, loss_s1: 0.067237, loss_fp: 0.002089, loss_freq: 0.015735
[15:23:04.291] iteration 4883: loss: 0.115094, loss_s1: 0.053753, loss_fp: 0.004067, loss_freq: 0.070558
[15:23:04.919] iteration 4884: loss: 0.057806, loss_s1: 0.030915, loss_fp: 0.001555, loss_freq: 0.004454
[15:23:05.541] iteration 4885: loss: 0.119508, loss_s1: 0.078310, loss_fp: 0.003614, loss_freq: 0.024402
[15:23:06.163] iteration 4886: loss: 0.134576, loss_s1: 0.130765, loss_fp: 0.006226, loss_freq: 0.025167
[15:23:06.798] iteration 4887: loss: 0.101766, loss_s1: 0.043309, loss_fp: 0.001740, loss_freq: 0.020119
[15:23:07.456] iteration 4888: loss: 0.174937, loss_s1: 0.037986, loss_fp: 0.005852, loss_freq: 0.036038
[15:23:08.138] iteration 4889: loss: 0.077261, loss_s1: 0.032794, loss_fp: 0.001506, loss_freq: 0.019608
[15:23:08.787] iteration 4890: loss: 0.082492, loss_s1: 0.052792, loss_fp: 0.001155, loss_freq: 0.019803
[15:23:09.419] iteration 4891: loss: 0.094380, loss_s1: 0.047581, loss_fp: 0.006111, loss_freq: 0.053906
[15:23:10.058] iteration 4892: loss: 0.079557, loss_s1: 0.027249, loss_fp: 0.002983, loss_freq: 0.014444
[15:23:10.710] iteration 4893: loss: 0.122632, loss_s1: 0.094672, loss_fp: 0.005531, loss_freq: 0.029414
[15:23:11.369] iteration 4894: loss: 0.109655, loss_s1: 0.067970, loss_fp: 0.005220, loss_freq: 0.015721
[15:23:12.019] iteration 4895: loss: 0.082645, loss_s1: 0.025645, loss_fp: 0.003176, loss_freq: 0.015449
[15:23:12.685] iteration 4896: loss: 0.125241, loss_s1: 0.050181, loss_fp: 0.009052, loss_freq: 0.066759
[15:23:13.351] iteration 4897: loss: 0.095383, loss_s1: 0.023658, loss_fp: 0.001382, loss_freq: 0.042165
[15:23:13.997] iteration 4898: loss: 0.121628, loss_s1: 0.070762, loss_fp: 0.005517, loss_freq: 0.051072
[15:23:14.619] iteration 4899: loss: 0.107706, loss_s1: 0.048275, loss_fp: 0.001586, loss_freq: 0.021952
[15:23:15.246] iteration 4900: loss: 0.158773, loss_s1: 0.041739, loss_fp: 0.003767, loss_freq: 0.051808
[15:23:15.866] iteration 4901: loss: 0.135137, loss_s1: 0.073549, loss_fp: 0.005141, loss_freq: 0.048718
[15:23:16.494] iteration 4902: loss: 0.112192, loss_s1: 0.085067, loss_fp: 0.006833, loss_freq: 0.036269
[15:23:17.118] iteration 4903: loss: 0.099973, loss_s1: 0.029147, loss_fp: 0.007597, loss_freq: 0.042230
[15:23:17.743] iteration 4904: loss: 0.145091, loss_s1: 0.096874, loss_fp: 0.001640, loss_freq: 0.056836
[15:23:18.362] iteration 4905: loss: 0.152522, loss_s1: 0.071995, loss_fp: 0.005743, loss_freq: 0.118122
[15:23:18.989] iteration 4906: loss: 0.155743, loss_s1: 0.101126, loss_fp: 0.003334, loss_freq: 0.061574
[15:23:19.608] iteration 4907: loss: 0.096704, loss_s1: 0.033697, loss_fp: 0.015657, loss_freq: 0.048093
[15:23:20.227] iteration 4908: loss: 0.077864, loss_s1: 0.055655, loss_fp: 0.007945, loss_freq: 0.028992
[15:23:20.846] iteration 4909: loss: 0.073437, loss_s1: 0.031756, loss_fp: 0.003274, loss_freq: 0.026138
[15:23:21.466] iteration 4910: loss: 0.125998, loss_s1: 0.064415, loss_fp: 0.001654, loss_freq: 0.086310
[15:23:22.089] iteration 4911: loss: 0.115574, loss_s1: 0.015948, loss_fp: 0.001820, loss_freq: 0.042064
[15:23:22.716] iteration 4912: loss: 0.062414, loss_s1: 0.035010, loss_fp: 0.001457, loss_freq: 0.015033
[15:23:23.331] iteration 4913: loss: 0.196976, loss_s1: 0.112613, loss_fp: 0.007990, loss_freq: 0.213603
[15:23:23.952] iteration 4914: loss: 0.178538, loss_s1: 0.054392, loss_fp: 0.001670, loss_freq: 0.010420
[15:23:24.575] iteration 4915: loss: 0.151569, loss_s1: 0.073775, loss_fp: 0.006418, loss_freq: 0.126271
[15:23:25.194] iteration 4916: loss: 0.047739, loss_s1: 0.013063, loss_fp: 0.002648, loss_freq: 0.012641
[15:23:25.819] iteration 4917: loss: 0.168158, loss_s1: 0.056703, loss_fp: 0.009067, loss_freq: 0.019953
[15:23:26.439] iteration 4918: loss: 0.090671, loss_s1: 0.038305, loss_fp: 0.000702, loss_freq: 0.037282
[15:23:27.064] iteration 4919: loss: 0.165264, loss_s1: 0.062115, loss_fp: 0.012935, loss_freq: 0.057551
[15:23:27.685] iteration 4920: loss: 0.128263, loss_s1: 0.030784, loss_fp: 0.005224, loss_freq: 0.032726
[15:23:28.303] iteration 4921: loss: 0.157659, loss_s1: 0.057815, loss_fp: 0.003608, loss_freq: 0.019725
[15:23:28.923] iteration 4922: loss: 0.099691, loss_s1: 0.047208, loss_fp: 0.000773, loss_freq: 0.007302
[15:23:29.541] iteration 4923: loss: 0.148785, loss_s1: 0.014478, loss_fp: 0.002882, loss_freq: 0.008524
[15:23:30.163] iteration 4924: loss: 0.099727, loss_s1: 0.040879, loss_fp: 0.002141, loss_freq: 0.025971
[15:23:30.780] iteration 4925: loss: 0.067652, loss_s1: 0.052370, loss_fp: 0.000927, loss_freq: 0.018213
[15:23:31.395] iteration 4926: loss: 0.096461, loss_s1: 0.099049, loss_fp: 0.002027, loss_freq: 0.009033
[15:23:32.033] iteration 4927: loss: 0.126039, loss_s1: 0.039288, loss_fp: 0.005584, loss_freq: 0.041363
[15:23:32.670] iteration 4928: loss: 0.107323, loss_s1: 0.029220, loss_fp: 0.000961, loss_freq: 0.023722
[15:23:33.297] iteration 4929: loss: 0.169866, loss_s1: 0.090188, loss_fp: 0.000924, loss_freq: 0.023288
[15:23:33.914] iteration 4930: loss: 0.103695, loss_s1: 0.076447, loss_fp: 0.002034, loss_freq: 0.049333
[15:23:34.540] iteration 4931: loss: 0.153804, loss_s1: 0.147046, loss_fp: 0.001266, loss_freq: 0.038628
[15:23:35.169] iteration 4932: loss: 0.162715, loss_s1: 0.047572, loss_fp: 0.002743, loss_freq: 0.046229
[15:23:35.789] iteration 4933: loss: 0.137269, loss_s1: 0.056055, loss_fp: 0.001162, loss_freq: 0.032709
[15:23:36.405] iteration 4934: loss: 0.186334, loss_s1: 0.158576, loss_fp: 0.002004, loss_freq: 0.105808
[15:23:37.024] iteration 4935: loss: 0.167664, loss_s1: 0.049267, loss_fp: 0.006826, loss_freq: 0.043588
[15:23:37.647] iteration 4936: loss: 0.107081, loss_s1: 0.017594, loss_fp: 0.001201, loss_freq: 0.027063
[15:23:38.269] iteration 4937: loss: 0.117776, loss_s1: 0.046095, loss_fp: 0.001580, loss_freq: 0.007800
[15:23:38.883] iteration 4938: loss: 0.200370, loss_s1: 0.161728, loss_fp: 0.002738, loss_freq: 0.075235
[15:23:39.510] iteration 4939: loss: 0.294186, loss_s1: 0.171583, loss_fp: 0.007103, loss_freq: 0.234776
[15:23:40.138] iteration 4940: loss: 0.095641, loss_s1: 0.054008, loss_fp: 0.002018, loss_freq: 0.014404
[15:23:40.757] iteration 4941: loss: 0.124005, loss_s1: 0.011501, loss_fp: 0.000949, loss_freq: 0.021058
[15:23:41.375] iteration 4942: loss: 0.095665, loss_s1: 0.064448, loss_fp: 0.001662, loss_freq: 0.054580
[15:23:41.998] iteration 4943: loss: 0.132432, loss_s1: 0.049082, loss_fp: 0.004171, loss_freq: 0.085948
[15:23:42.617] iteration 4944: loss: 0.093820, loss_s1: 0.046768, loss_fp: 0.002633, loss_freq: 0.046203
[15:23:43.237] iteration 4945: loss: 0.056255, loss_s1: 0.025419, loss_fp: 0.001887, loss_freq: 0.004456
[15:23:43.853] iteration 4946: loss: 0.151188, loss_s1: 0.086129, loss_fp: 0.001043, loss_freq: 0.056763
[15:23:44.472] iteration 4947: loss: 0.107209, loss_s1: 0.094792, loss_fp: 0.000871, loss_freq: 0.019011
[15:23:45.097] iteration 4948: loss: 0.086660, loss_s1: 0.025680, loss_fp: 0.000735, loss_freq: 0.024026
[15:23:45.715] iteration 4949: loss: 0.133343, loss_s1: 0.030773, loss_fp: 0.000968, loss_freq: 0.039642
[15:23:46.340] iteration 4950: loss: 0.147345, loss_s1: 0.070078, loss_fp: 0.000680, loss_freq: 0.133656
[15:23:46.961] iteration 4951: loss: 0.077333, loss_s1: 0.029933, loss_fp: 0.001150, loss_freq: 0.021328
[15:23:47.585] iteration 4952: loss: 0.198125, loss_s1: 0.023548, loss_fp: 0.000543, loss_freq: 0.009192
[15:23:48.207] iteration 4953: loss: 0.128771, loss_s1: 0.107926, loss_fp: 0.002402, loss_freq: 0.043327
[15:23:48.826] iteration 4954: loss: 0.193385, loss_s1: 0.155787, loss_fp: 0.002287, loss_freq: 0.074390
[15:23:49.450] iteration 4955: loss: 0.155240, loss_s1: 0.059818, loss_fp: 0.002582, loss_freq: 0.038307
[15:23:50.109] iteration 4956: loss: 0.091307, loss_s1: 0.016867, loss_fp: 0.001352, loss_freq: 0.008982
[15:23:50.726] iteration 4957: loss: 0.117946, loss_s1: 0.046163, loss_fp: 0.000405, loss_freq: 0.028325
[15:23:51.351] iteration 4958: loss: 0.214415, loss_s1: 0.060136, loss_fp: 0.007499, loss_freq: 0.132758
[15:23:51.975] iteration 4959: loss: 0.132010, loss_s1: 0.126868, loss_fp: 0.003808, loss_freq: 0.016542
[15:23:52.674] iteration 4960: loss: 0.064381, loss_s1: 0.038965, loss_fp: 0.000810, loss_freq: 0.005066
[15:23:53.336] iteration 4961: loss: 0.093520, loss_s1: 0.037813, loss_fp: 0.003909, loss_freq: 0.050451
[15:23:53.962] iteration 4962: loss: 0.110351, loss_s1: 0.058639, loss_fp: 0.000952, loss_freq: 0.028725
[15:23:54.584] iteration 4963: loss: 0.100623, loss_s1: 0.053738, loss_fp: 0.000792, loss_freq: 0.017945
[15:23:55.205] iteration 4964: loss: 0.097769, loss_s1: 0.061550, loss_fp: 0.005589, loss_freq: 0.021307
[15:23:55.821] iteration 4965: loss: 0.084382, loss_s1: 0.039150, loss_fp: 0.001583, loss_freq: 0.026326
[15:23:56.444] iteration 4966: loss: 0.135747, loss_s1: 0.112713, loss_fp: 0.003411, loss_freq: 0.053318
[15:23:57.070] iteration 4967: loss: 0.122442, loss_s1: 0.038316, loss_fp: 0.001221, loss_freq: 0.051283
[15:23:57.695] iteration 4968: loss: 0.089159, loss_s1: 0.066693, loss_fp: 0.001068, loss_freq: 0.024464
[15:23:58.319] iteration 4969: loss: 0.078209, loss_s1: 0.034884, loss_fp: 0.002069, loss_freq: 0.013865
[15:23:58.942] iteration 4970: loss: 0.211559, loss_s1: 0.070914, loss_fp: 0.001237, loss_freq: 0.094543
[15:23:59.572] iteration 4971: loss: 0.114324, loss_s1: 0.099856, loss_fp: 0.003033, loss_freq: 0.031890
[15:24:00.198] iteration 4972: loss: 0.132256, loss_s1: 0.047798, loss_fp: 0.001082, loss_freq: 0.055982
[15:24:00.815] iteration 4973: loss: 0.096219, loss_s1: 0.063221, loss_fp: 0.005632, loss_freq: 0.024477
[15:24:01.440] iteration 4974: loss: 0.093231, loss_s1: 0.072386, loss_fp: 0.001179, loss_freq: 0.011737
[15:24:02.066] iteration 4975: loss: 0.101690, loss_s1: 0.025647, loss_fp: 0.002531, loss_freq: 0.011187
[15:24:02.688] iteration 4976: loss: 0.108214, loss_s1: 0.043952, loss_fp: 0.001262, loss_freq: 0.022881
[15:24:03.305] iteration 4977: loss: 0.111598, loss_s1: 0.079932, loss_fp: 0.001406, loss_freq: 0.064597
[15:24:03.935] iteration 4978: loss: 0.112110, loss_s1: 0.082618, loss_fp: 0.003278, loss_freq: 0.038665
[15:24:04.564] iteration 4979: loss: 0.087849, loss_s1: 0.029062, loss_fp: 0.003888, loss_freq: 0.054451
[15:24:05.191] iteration 4980: loss: 0.140464, loss_s1: 0.108643, loss_fp: 0.002179, loss_freq: 0.027895
[15:24:05.819] iteration 4981: loss: 0.088508, loss_s1: 0.019980, loss_fp: 0.002069, loss_freq: 0.020025
[15:24:06.446] iteration 4982: loss: 0.087366, loss_s1: 0.057690, loss_fp: 0.003263, loss_freq: 0.039726
[15:24:07.073] iteration 4983: loss: 0.072150, loss_s1: 0.047389, loss_fp: 0.005208, loss_freq: 0.012176
[15:24:07.692] iteration 4984: loss: 0.132510, loss_s1: 0.047494, loss_fp: 0.001874, loss_freq: 0.035417
[15:24:08.318] iteration 4985: loss: 0.090763, loss_s1: 0.025154, loss_fp: 0.001033, loss_freq: 0.016049
[15:24:08.951] iteration 4986: loss: 0.073046, loss_s1: 0.024498, loss_fp: 0.004543, loss_freq: 0.023309
[15:24:09.577] iteration 4987: loss: 0.163459, loss_s1: 0.036386, loss_fp: 0.000746, loss_freq: 0.017389
[15:24:10.209] iteration 4988: loss: 0.165996, loss_s1: 0.034657, loss_fp: 0.002507, loss_freq: 0.073600
[15:24:10.835] iteration 4989: loss: 0.124411, loss_s1: 0.064637, loss_fp: 0.011007, loss_freq: 0.036748
[15:24:11.463] iteration 4990: loss: 0.153849, loss_s1: 0.071798, loss_fp: 0.002873, loss_freq: 0.015087
[15:24:12.086] iteration 4991: loss: 0.111757, loss_s1: 0.103734, loss_fp: 0.000528, loss_freq: 0.022871
[15:24:13.158] iteration 4992: loss: 0.164425, loss_s1: 0.068440, loss_fp: 0.000971, loss_freq: 0.024711
[15:24:13.821] iteration 4993: loss: 0.100124, loss_s1: 0.049781, loss_fp: 0.001083, loss_freq: 0.027901
[15:24:14.490] iteration 4994: loss: 0.135163, loss_s1: 0.085084, loss_fp: 0.001622, loss_freq: 0.028178
[15:24:15.147] iteration 4995: loss: 0.152969, loss_s1: 0.118710, loss_fp: 0.003542, loss_freq: 0.058687
[15:24:15.812] iteration 4996: loss: 0.118737, loss_s1: 0.028468, loss_fp: 0.000702, loss_freq: 0.015613
[15:24:16.440] iteration 4997: loss: 0.267570, loss_s1: 0.173280, loss_fp: 0.015795, loss_freq: 0.101819
[15:24:17.062] iteration 4998: loss: 0.061235, loss_s1: 0.038696, loss_fp: 0.009056, loss_freq: 0.008739
[15:24:17.694] iteration 4999: loss: 0.098910, loss_s1: 0.068510, loss_fp: 0.001067, loss_freq: 0.047706
[15:24:18.377] iteration 5000: loss: 0.096907, loss_s1: 0.060467, loss_fp: 0.004703, loss_freq: 0.044908
[15:24:22.201] iteration 5000 : mean_dice : 0.612078
[15:24:22.860] iteration 5001: loss: 0.148945, loss_s1: 0.138748, loss_fp: 0.018109, loss_freq: 0.036744
[15:24:23.494] iteration 5002: loss: 0.084695, loss_s1: 0.016909, loss_fp: 0.000885, loss_freq: 0.007482
[15:24:24.118] iteration 5003: loss: 0.115813, loss_s1: 0.063699, loss_fp: 0.003245, loss_freq: 0.046707
[15:24:24.743] iteration 5004: loss: 0.088527, loss_s1: 0.047640, loss_fp: 0.011878, loss_freq: 0.052093
[15:24:25.370] iteration 5005: loss: 0.136830, loss_s1: 0.047440, loss_fp: 0.004147, loss_freq: 0.052478
[15:24:25.998] iteration 5006: loss: 0.099133, loss_s1: 0.052826, loss_fp: 0.001731, loss_freq: 0.021766
[15:24:26.620] iteration 5007: loss: 0.184338, loss_s1: 0.083748, loss_fp: 0.000777, loss_freq: 0.138927
[15:24:27.253] iteration 5008: loss: 0.146070, loss_s1: 0.069474, loss_fp: 0.004742, loss_freq: 0.022400
[15:24:27.879] iteration 5009: loss: 0.082865, loss_s1: 0.032828, loss_fp: 0.002195, loss_freq: 0.025371
[15:24:28.510] iteration 5010: loss: 0.128374, loss_s1: 0.034736, loss_fp: 0.000993, loss_freq: 0.011687
[15:24:29.138] iteration 5011: loss: 0.164047, loss_s1: 0.101783, loss_fp: 0.001146, loss_freq: 0.038245
[15:24:29.791] iteration 5012: loss: 0.080047, loss_s1: 0.019222, loss_fp: 0.007953, loss_freq: 0.010349
[15:24:30.416] iteration 5013: loss: 0.123865, loss_s1: 0.071801, loss_fp: 0.001169, loss_freq: 0.036759
[15:24:31.046] iteration 5014: loss: 0.114216, loss_s1: 0.044966, loss_fp: 0.000479, loss_freq: 0.027335
[15:24:31.722] iteration 5015: loss: 0.135763, loss_s1: 0.104956, loss_fp: 0.006175, loss_freq: 0.049733
[15:24:32.350] iteration 5016: loss: 0.086817, loss_s1: 0.076675, loss_fp: 0.002595, loss_freq: 0.021510
[15:24:32.973] iteration 5017: loss: 0.092593, loss_s1: 0.037131, loss_fp: 0.004889, loss_freq: 0.066281
[15:24:33.598] iteration 5018: loss: 0.122550, loss_s1: 0.067459, loss_fp: 0.006979, loss_freq: 0.051158
[15:24:34.256] iteration 5019: loss: 0.163420, loss_s1: 0.100997, loss_fp: 0.003432, loss_freq: 0.043082
[15:24:34.884] iteration 5020: loss: 0.066378, loss_s1: 0.039232, loss_fp: 0.005375, loss_freq: 0.018837
[15:24:35.504] iteration 5021: loss: 0.118865, loss_s1: 0.059270, loss_fp: 0.001357, loss_freq: 0.011451
[15:24:36.136] iteration 5022: loss: 0.059303, loss_s1: 0.034470, loss_fp: 0.006379, loss_freq: 0.009002
[15:24:36.757] iteration 5023: loss: 0.127841, loss_s1: 0.074704, loss_fp: 0.000680, loss_freq: 0.016252
[15:24:37.401] iteration 5024: loss: 0.063975, loss_s1: 0.024939, loss_fp: 0.001492, loss_freq: 0.019811
[15:24:38.026] iteration 5025: loss: 0.067343, loss_s1: 0.037526, loss_fp: 0.000576, loss_freq: 0.022381
[15:24:38.643] iteration 5026: loss: 0.159009, loss_s1: 0.055575, loss_fp: 0.003674, loss_freq: 0.015996
[15:24:39.264] iteration 5027: loss: 0.163659, loss_s1: 0.097600, loss_fp: 0.005184, loss_freq: 0.049094
[15:24:39.882] iteration 5028: loss: 0.201384, loss_s1: 0.081239, loss_fp: 0.007359, loss_freq: 0.102373
[15:24:40.505] iteration 5029: loss: 0.108122, loss_s1: 0.051765, loss_fp: 0.001431, loss_freq: 0.036391
[15:24:41.122] iteration 5030: loss: 0.190386, loss_s1: 0.128940, loss_fp: 0.002487, loss_freq: 0.082873
[15:24:41.754] iteration 5031: loss: 0.167576, loss_s1: 0.091599, loss_fp: 0.004576, loss_freq: 0.072462
[15:24:42.378] iteration 5032: loss: 0.128154, loss_s1: 0.023126, loss_fp: 0.001288, loss_freq: 0.031121
[15:24:43.010] iteration 5033: loss: 0.083316, loss_s1: 0.062072, loss_fp: 0.002040, loss_freq: 0.030445
[15:24:43.633] iteration 5034: loss: 0.109258, loss_s1: 0.092286, loss_fp: 0.001184, loss_freq: 0.028239
[15:24:44.266] iteration 5035: loss: 0.113685, loss_s1: 0.102151, loss_fp: 0.002494, loss_freq: 0.030247
[15:24:44.896] iteration 5036: loss: 0.210330, loss_s1: 0.128746, loss_fp: 0.000799, loss_freq: 0.078566
[15:24:45.522] iteration 5037: loss: 0.070961, loss_s1: 0.014358, loss_fp: 0.001212, loss_freq: 0.003728
[15:24:46.148] iteration 5038: loss: 0.076460, loss_s1: 0.017811, loss_fp: 0.001042, loss_freq: 0.034351
[15:24:46.772] iteration 5039: loss: 0.094504, loss_s1: 0.074810, loss_fp: 0.009802, loss_freq: 0.024324
[15:24:47.393] iteration 5040: loss: 0.116120, loss_s1: 0.057122, loss_fp: 0.004173, loss_freq: 0.020251
[15:24:48.020] iteration 5041: loss: 0.127117, loss_s1: 0.116220, loss_fp: 0.000980, loss_freq: 0.056008
[15:24:48.645] iteration 5042: loss: 0.087163, loss_s1: 0.100434, loss_fp: 0.000475, loss_freq: 0.009638
[15:24:49.270] iteration 5043: loss: 0.194989, loss_s1: 0.037881, loss_fp: 0.008901, loss_freq: 0.018612
[15:24:49.904] iteration 5044: loss: 0.073397, loss_s1: 0.029851, loss_fp: 0.002067, loss_freq: 0.027586
[15:24:50.536] iteration 5045: loss: 0.139718, loss_s1: 0.058651, loss_fp: 0.002495, loss_freq: 0.044535
[15:24:51.163] iteration 5046: loss: 0.122310, loss_s1: 0.051070, loss_fp: 0.000565, loss_freq: 0.040309
[15:24:51.819] iteration 5047: loss: 0.189591, loss_s1: 0.196508, loss_fp: 0.001453, loss_freq: 0.038225
[15:24:52.489] iteration 5048: loss: 0.088631, loss_s1: 0.026812, loss_fp: 0.000920, loss_freq: 0.009611
[15:24:53.149] iteration 5049: loss: 0.180841, loss_s1: 0.050407, loss_fp: 0.001497, loss_freq: 0.056618
[15:24:53.816] iteration 5050: loss: 0.075286, loss_s1: 0.014010, loss_fp: 0.013253, loss_freq: 0.007531
[15:24:54.445] iteration 5051: loss: 0.081856, loss_s1: 0.047397, loss_fp: 0.001019, loss_freq: 0.013218
[15:24:55.073] iteration 5052: loss: 0.063914, loss_s1: 0.029173, loss_fp: 0.002199, loss_freq: 0.015430
[15:24:55.701] iteration 5053: loss: 0.099762, loss_s1: 0.060188, loss_fp: 0.000640, loss_freq: 0.065659
[15:24:56.320] iteration 5054: loss: 0.106099, loss_s1: 0.052616, loss_fp: 0.003341, loss_freq: 0.017546
[15:24:56.945] iteration 5055: loss: 0.120754, loss_s1: 0.056767, loss_fp: 0.021230, loss_freq: 0.040429
[15:24:57.570] iteration 5056: loss: 0.121086, loss_s1: 0.077536, loss_fp: 0.004416, loss_freq: 0.033689
[15:24:58.201] iteration 5057: loss: 0.088066, loss_s1: 0.083524, loss_fp: 0.001904, loss_freq: 0.022148
[15:24:58.824] iteration 5058: loss: 0.112226, loss_s1: 0.027790, loss_fp: 0.002973, loss_freq: 0.062637
[15:24:59.457] iteration 5059: loss: 0.075128, loss_s1: 0.054693, loss_fp: 0.001526, loss_freq: 0.019044
[15:25:00.109] iteration 5060: loss: 0.095709, loss_s1: 0.037470, loss_fp: 0.004636, loss_freq: 0.041304
[15:25:00.770] iteration 5061: loss: 0.132042, loss_s1: 0.033142, loss_fp: 0.004265, loss_freq: 0.038420
[15:25:01.426] iteration 5062: loss: 0.116878, loss_s1: 0.078764, loss_fp: 0.011231, loss_freq: 0.013307
[15:25:02.061] iteration 5063: loss: 0.125207, loss_s1: 0.056344, loss_fp: 0.002610, loss_freq: 0.058759
[15:25:02.689] iteration 5064: loss: 0.122801, loss_s1: 0.059011, loss_fp: 0.002239, loss_freq: 0.053101
[15:25:03.313] iteration 5065: loss: 0.066438, loss_s1: 0.018894, loss_fp: 0.000470, loss_freq: 0.011521
[15:25:03.939] iteration 5066: loss: 0.145021, loss_s1: 0.101642, loss_fp: 0.001802, loss_freq: 0.031356
[15:25:04.562] iteration 5067: loss: 0.173358, loss_s1: 0.101029, loss_fp: 0.000403, loss_freq: 0.064045
[15:25:05.192] iteration 5068: loss: 0.097657, loss_s1: 0.075110, loss_fp: 0.001107, loss_freq: 0.042994
[15:25:05.823] iteration 5069: loss: 0.082850, loss_s1: 0.049129, loss_fp: 0.002255, loss_freq: 0.032186
[15:25:06.457] iteration 5070: loss: 0.068395, loss_s1: 0.038110, loss_fp: 0.002164, loss_freq: 0.021785
[15:25:07.084] iteration 5071: loss: 0.071939, loss_s1: 0.026511, loss_fp: 0.000650, loss_freq: 0.033554
[15:25:07.715] iteration 5072: loss: 0.109044, loss_s1: 0.032820, loss_fp: 0.001782, loss_freq: 0.059267
[15:25:08.341] iteration 5073: loss: 0.114824, loss_s1: 0.059252, loss_fp: 0.004815, loss_freq: 0.040398
[15:25:08.970] iteration 5074: loss: 0.161580, loss_s1: 0.192383, loss_fp: 0.008231, loss_freq: 0.042286
[15:25:09.608] iteration 5075: loss: 0.146773, loss_s1: 0.036465, loss_fp: 0.005218, loss_freq: 0.022258
[15:25:10.241] iteration 5076: loss: 0.183921, loss_s1: 0.108326, loss_fp: 0.009827, loss_freq: 0.165614
[15:25:10.871] iteration 5077: loss: 0.082299, loss_s1: 0.032030, loss_fp: 0.001326, loss_freq: 0.042393
[15:25:11.500] iteration 5078: loss: 0.131353, loss_s1: 0.040817, loss_fp: 0.001626, loss_freq: 0.045496
[15:25:12.128] iteration 5079: loss: 0.118738, loss_s1: 0.103820, loss_fp: 0.002017, loss_freq: 0.036928
[15:25:12.750] iteration 5080: loss: 0.124775, loss_s1: 0.096274, loss_fp: 0.002161, loss_freq: 0.043089
[15:25:13.375] iteration 5081: loss: 0.137800, loss_s1: 0.053874, loss_fp: 0.000409, loss_freq: 0.040721
[15:25:13.995] iteration 5082: loss: 0.120289, loss_s1: 0.023577, loss_fp: 0.001439, loss_freq: 0.036830
[15:25:14.622] iteration 5083: loss: 0.124468, loss_s1: 0.067997, loss_fp: 0.000727, loss_freq: 0.033431
[15:25:15.245] iteration 5084: loss: 0.182019, loss_s1: 0.031084, loss_fp: 0.001298, loss_freq: 0.028863
[15:25:15.872] iteration 5085: loss: 0.078558, loss_s1: 0.014945, loss_fp: 0.001513, loss_freq: 0.032296
[15:25:16.490] iteration 5086: loss: 0.081606, loss_s1: 0.078653, loss_fp: 0.000872, loss_freq: 0.012762
[15:25:17.117] iteration 5087: loss: 0.087931, loss_s1: 0.041531, loss_fp: 0.000980, loss_freq: 0.018784
[15:25:17.738] iteration 5088: loss: 0.088916, loss_s1: 0.045041, loss_fp: 0.003899, loss_freq: 0.024221
[15:25:18.402] iteration 5089: loss: 0.102889, loss_s1: 0.009620, loss_fp: 0.001038, loss_freq: 0.024710
[15:25:19.033] iteration 5090: loss: 0.120571, loss_s1: 0.039186, loss_fp: 0.001430, loss_freq: 0.036545
[15:25:19.659] iteration 5091: loss: 0.072372, loss_s1: 0.046104, loss_fp: 0.001797, loss_freq: 0.029177
[15:25:20.288] iteration 5092: loss: 0.141337, loss_s1: 0.084197, loss_fp: 0.007490, loss_freq: 0.059768
[15:25:20.913] iteration 5093: loss: 0.174118, loss_s1: 0.077320, loss_fp: 0.002014, loss_freq: 0.058837
[15:25:21.534] iteration 5094: loss: 0.157876, loss_s1: 0.083957, loss_fp: 0.002847, loss_freq: 0.067586
[15:25:22.154] iteration 5095: loss: 0.107956, loss_s1: 0.061102, loss_fp: 0.001024, loss_freq: 0.058691
[15:25:22.783] iteration 5096: loss: 0.114288, loss_s1: 0.044551, loss_fp: 0.004540, loss_freq: 0.022312
[15:25:23.412] iteration 5097: loss: 0.136977, loss_s1: 0.034924, loss_fp: 0.003073, loss_freq: 0.038998
[15:25:24.030] iteration 5098: loss: 0.160755, loss_s1: 0.076422, loss_fp: 0.001674, loss_freq: 0.031826
[15:25:24.662] iteration 5099: loss: 0.157273, loss_s1: 0.133337, loss_fp: 0.003034, loss_freq: 0.086457
[15:25:25.291] iteration 5100: loss: 0.247030, loss_s1: 0.132178, loss_fp: 0.002979, loss_freq: 0.228045
[15:25:25.912] iteration 5101: loss: 0.090456, loss_s1: 0.047172, loss_fp: 0.004123, loss_freq: 0.027692
[15:25:26.539] iteration 5102: loss: 0.131920, loss_s1: 0.029999, loss_fp: 0.000723, loss_freq: 0.032442
[15:25:27.167] iteration 5103: loss: 0.073648, loss_s1: 0.046368, loss_fp: 0.002230, loss_freq: 0.033984
[15:25:27.791] iteration 5104: loss: 0.123970, loss_s1: 0.080790, loss_fp: 0.004878, loss_freq: 0.059724
[15:25:28.421] iteration 5105: loss: 0.122677, loss_s1: 0.095774, loss_fp: 0.002411, loss_freq: 0.047020
[15:25:29.049] iteration 5106: loss: 0.064963, loss_s1: 0.037498, loss_fp: 0.002569, loss_freq: 0.012333
[15:25:29.671] iteration 5107: loss: 0.114761, loss_s1: 0.057010, loss_fp: 0.002239, loss_freq: 0.065786
[15:25:30.290] iteration 5108: loss: 0.097720, loss_s1: 0.060899, loss_fp: 0.001250, loss_freq: 0.041503
[15:25:30.954] iteration 5109: loss: 0.096309, loss_s1: 0.059730, loss_fp: 0.001199, loss_freq: 0.054525
[15:25:31.613] iteration 5110: loss: 0.161586, loss_s1: 0.075338, loss_fp: 0.002758, loss_freq: 0.041919
[15:25:32.281] iteration 5111: loss: 0.149872, loss_s1: 0.071205, loss_fp: 0.006712, loss_freq: 0.139311
[15:25:32.939] iteration 5112: loss: 0.117624, loss_s1: 0.060074, loss_fp: 0.001237, loss_freq: 0.101002
[15:25:33.570] iteration 5113: loss: 0.139799, loss_s1: 0.026544, loss_fp: 0.012318, loss_freq: 0.011701
[15:25:34.198] iteration 5114: loss: 0.136126, loss_s1: 0.094362, loss_fp: 0.006592, loss_freq: 0.041752
[15:25:34.829] iteration 5115: loss: 0.144709, loss_s1: 0.044650, loss_fp: 0.002925, loss_freq: 0.078373
[15:25:35.462] iteration 5116: loss: 0.123914, loss_s1: 0.060154, loss_fp: 0.000693, loss_freq: 0.033993
[15:25:36.116] iteration 5117: loss: 0.132895, loss_s1: 0.077062, loss_fp: 0.011232, loss_freq: 0.014144
[15:25:36.803] iteration 5118: loss: 0.125674, loss_s1: 0.043528, loss_fp: 0.000796, loss_freq: 0.006305
[15:25:37.465] iteration 5119: loss: 0.236671, loss_s1: 0.123066, loss_fp: 0.006727, loss_freq: 0.127312
[15:25:38.124] iteration 5120: loss: 0.093961, loss_s1: 0.066129, loss_fp: 0.000867, loss_freq: 0.014176
[15:25:38.787] iteration 5121: loss: 0.078403, loss_s1: 0.049108, loss_fp: 0.000709, loss_freq: 0.011629
[15:25:39.414] iteration 5122: loss: 0.093476, loss_s1: 0.036593, loss_fp: 0.009157, loss_freq: 0.057939
[15:25:40.037] iteration 5123: loss: 0.103082, loss_s1: 0.087142, loss_fp: 0.000949, loss_freq: 0.006599
[15:25:40.657] iteration 5124: loss: 0.084239, loss_s1: 0.044800, loss_fp: 0.012980, loss_freq: 0.020449
[15:25:41.279] iteration 5125: loss: 0.126719, loss_s1: 0.056683, loss_fp: 0.002463, loss_freq: 0.058531
[15:25:41.909] iteration 5126: loss: 0.086969, loss_s1: 0.036990, loss_fp: 0.014560, loss_freq: 0.040439
[15:25:42.526] iteration 5127: loss: 0.135046, loss_s1: 0.122296, loss_fp: 0.001658, loss_freq: 0.042574
[15:25:43.150] iteration 5128: loss: 0.082539, loss_s1: 0.023421, loss_fp: 0.001047, loss_freq: 0.037077
[15:25:43.769] iteration 5129: loss: 0.075872, loss_s1: 0.026761, loss_fp: 0.007879, loss_freq: 0.034158
[15:25:44.430] iteration 5130: loss: 0.079039, loss_s1: 0.023149, loss_fp: 0.002997, loss_freq: 0.013948
[15:25:45.079] iteration 5131: loss: 0.198777, loss_s1: 0.116545, loss_fp: 0.001656, loss_freq: 0.061462
[15:25:45.704] iteration 5132: loss: 0.136233, loss_s1: 0.069964, loss_fp: 0.006731, loss_freq: 0.078106
[15:25:46.335] iteration 5133: loss: 0.114832, loss_s1: 0.051542, loss_fp: 0.000866, loss_freq: 0.026767
[15:25:46.952] iteration 5134: loss: 0.126696, loss_s1: 0.079716, loss_fp: 0.003878, loss_freq: 0.012668
[15:25:47.574] iteration 5135: loss: 0.094882, loss_s1: 0.053858, loss_fp: 0.025817, loss_freq: 0.028401
[15:25:48.195] iteration 5136: loss: 0.108937, loss_s1: 0.049618, loss_fp: 0.005202, loss_freq: 0.045029
[15:25:48.826] iteration 5137: loss: 0.094012, loss_s1: 0.040478, loss_fp: 0.002970, loss_freq: 0.009131
[15:25:49.451] iteration 5138: loss: 0.088912, loss_s1: 0.063315, loss_fp: 0.008646, loss_freq: 0.050909
[15:25:50.124] iteration 5139: loss: 0.105006, loss_s1: 0.058229, loss_fp: 0.001435, loss_freq: 0.027925
[15:25:50.780] iteration 5140: loss: 0.074888, loss_s1: 0.048478, loss_fp: 0.001402, loss_freq: 0.016957
[15:25:51.441] iteration 5141: loss: 0.135884, loss_s1: 0.064773, loss_fp: 0.000702, loss_freq: 0.081548
[15:25:52.089] iteration 5142: loss: 0.108703, loss_s1: 0.049919, loss_fp: 0.002047, loss_freq: 0.021264
[15:25:52.744] iteration 5143: loss: 0.105345, loss_s1: 0.056980, loss_fp: 0.004280, loss_freq: 0.036990
[15:25:53.377] iteration 5144: loss: 0.054575, loss_s1: 0.035244, loss_fp: 0.001338, loss_freq: 0.012744
[15:25:54.002] iteration 5145: loss: 0.135739, loss_s1: 0.047375, loss_fp: 0.000668, loss_freq: 0.027425
[15:25:54.631] iteration 5146: loss: 0.079871, loss_s1: 0.029931, loss_fp: 0.001295, loss_freq: 0.007976
[15:25:55.256] iteration 5147: loss: 0.076979, loss_s1: 0.055477, loss_fp: 0.001115, loss_freq: 0.018477
[15:25:55.877] iteration 5148: loss: 0.163014, loss_s1: 0.026218, loss_fp: 0.002704, loss_freq: 0.020765
[15:25:56.510] iteration 5149: loss: 0.132828, loss_s1: 0.076215, loss_fp: 0.002341, loss_freq: 0.061532
[15:25:57.134] iteration 5150: loss: 0.127061, loss_s1: 0.036325, loss_fp: 0.001596, loss_freq: 0.024737
[15:25:57.761] iteration 5151: loss: 0.116684, loss_s1: 0.096033, loss_fp: 0.001463, loss_freq: 0.018272
[15:25:58.387] iteration 5152: loss: 0.128833, loss_s1: 0.133442, loss_fp: 0.000994, loss_freq: 0.021187
[15:25:59.332] iteration 5153: loss: 0.111237, loss_s1: 0.080453, loss_fp: 0.001227, loss_freq: 0.032188
[15:25:59.994] iteration 5154: loss: 0.139064, loss_s1: 0.083459, loss_fp: 0.002754, loss_freq: 0.057778
[15:26:00.659] iteration 5155: loss: 0.094559, loss_s1: 0.064607, loss_fp: 0.002324, loss_freq: 0.024062
[15:26:01.323] iteration 5156: loss: 0.123550, loss_s1: 0.042777, loss_fp: 0.000710, loss_freq: 0.032580
[15:26:01.940] iteration 5157: loss: 0.087139, loss_s1: 0.059865, loss_fp: 0.001075, loss_freq: 0.024116
[15:26:02.564] iteration 5158: loss: 0.126995, loss_s1: 0.041095, loss_fp: 0.001543, loss_freq: 0.028626
[15:26:03.188] iteration 5159: loss: 0.050353, loss_s1: 0.030658, loss_fp: 0.001237, loss_freq: 0.006984
[15:26:03.812] iteration 5160: loss: 0.113828, loss_s1: 0.068557, loss_fp: 0.002883, loss_freq: 0.077921
[15:26:04.439] iteration 5161: loss: 0.120932, loss_s1: 0.076547, loss_fp: 0.002799, loss_freq: 0.025663
[15:26:05.065] iteration 5162: loss: 0.081570, loss_s1: 0.058318, loss_fp: 0.001350, loss_freq: 0.019869
[15:26:05.688] iteration 5163: loss: 0.068435, loss_s1: 0.021424, loss_fp: 0.001033, loss_freq: 0.019757
[15:26:06.314] iteration 5164: loss: 0.143740, loss_s1: 0.087256, loss_fp: 0.002125, loss_freq: 0.091368
[15:26:06.961] iteration 5165: loss: 0.100997, loss_s1: 0.067710, loss_fp: 0.001553, loss_freq: 0.067293
[15:26:07.582] iteration 5166: loss: 0.128759, loss_s1: 0.081880, loss_fp: 0.002050, loss_freq: 0.050614
[15:26:08.204] iteration 5167: loss: 0.081110, loss_s1: 0.031504, loss_fp: 0.004828, loss_freq: 0.038581
[15:26:08.831] iteration 5168: loss: 0.141610, loss_s1: 0.066215, loss_fp: 0.016120, loss_freq: 0.086870
[15:26:09.452] iteration 5169: loss: 0.181308, loss_s1: 0.097319, loss_fp: 0.006812, loss_freq: 0.020478
[15:26:10.090] iteration 5170: loss: 0.107042, loss_s1: 0.060611, loss_fp: 0.001162, loss_freq: 0.036879
[15:26:10.719] iteration 5171: loss: 0.144735, loss_s1: 0.072539, loss_fp: 0.000636, loss_freq: 0.021808
[15:26:11.343] iteration 5172: loss: 0.133423, loss_s1: 0.094294, loss_fp: 0.000697, loss_freq: 0.039587
[15:26:11.965] iteration 5173: loss: 0.084869, loss_s1: 0.070962, loss_fp: 0.000547, loss_freq: 0.014577
[15:26:12.581] iteration 5174: loss: 0.094084, loss_s1: 0.044636, loss_fp: 0.002590, loss_freq: 0.008285
[15:26:13.215] iteration 5175: loss: 0.123704, loss_s1: 0.050065, loss_fp: 0.004890, loss_freq: 0.037785
[15:26:13.831] iteration 5176: loss: 0.128129, loss_s1: 0.088058, loss_fp: 0.005381, loss_freq: 0.062887
[15:26:14.453] iteration 5177: loss: 0.054370, loss_s1: 0.025456, loss_fp: 0.000464, loss_freq: 0.017742
[15:26:15.070] iteration 5178: loss: 0.120394, loss_s1: 0.052251, loss_fp: 0.003362, loss_freq: 0.084127
[15:26:15.691] iteration 5179: loss: 0.116441, loss_s1: 0.091297, loss_fp: 0.002050, loss_freq: 0.033309
[15:26:16.310] iteration 5180: loss: 0.110369, loss_s1: 0.037208, loss_fp: 0.003117, loss_freq: 0.039807
[15:26:16.933] iteration 5181: loss: 0.079886, loss_s1: 0.052451, loss_fp: 0.002467, loss_freq: 0.028098
[15:26:17.554] iteration 5182: loss: 0.097342, loss_s1: 0.047056, loss_fp: 0.001455, loss_freq: 0.012693
[15:26:18.171] iteration 5183: loss: 0.068186, loss_s1: 0.039899, loss_fp: 0.005029, loss_freq: 0.023296
[15:26:18.791] iteration 5184: loss: 0.183960, loss_s1: 0.098477, loss_fp: 0.002979, loss_freq: 0.013817
[15:26:19.407] iteration 5185: loss: 0.106087, loss_s1: 0.047329, loss_fp: 0.006160, loss_freq: 0.039935
[15:26:20.030] iteration 5186: loss: 0.063200, loss_s1: 0.042014, loss_fp: 0.005776, loss_freq: 0.010028
[15:26:20.650] iteration 5187: loss: 0.108947, loss_s1: 0.039978, loss_fp: 0.003206, loss_freq: 0.019691
[15:26:21.274] iteration 5188: loss: 0.184280, loss_s1: 0.088320, loss_fp: 0.001040, loss_freq: 0.057235
[15:26:21.890] iteration 5189: loss: 0.129830, loss_s1: 0.106452, loss_fp: 0.003065, loss_freq: 0.017627
[15:26:22.516] iteration 5190: loss: 0.085317, loss_s1: 0.073516, loss_fp: 0.001389, loss_freq: 0.011252
[15:26:23.133] iteration 5191: loss: 0.197093, loss_s1: 0.177984, loss_fp: 0.002765, loss_freq: 0.121151
[15:26:23.751] iteration 5192: loss: 0.142395, loss_s1: 0.058885, loss_fp: 0.003106, loss_freq: 0.058011
[15:26:24.381] iteration 5193: loss: 0.105955, loss_s1: 0.026292, loss_fp: 0.001168, loss_freq: 0.039038
[15:26:25.024] iteration 5194: loss: 0.051454, loss_s1: 0.018939, loss_fp: 0.002089, loss_freq: 0.025171
[15:26:25.650] iteration 5195: loss: 0.079159, loss_s1: 0.054159, loss_fp: 0.001299, loss_freq: 0.014820
[15:26:26.283] iteration 5196: loss: 0.081250, loss_s1: 0.049285, loss_fp: 0.001131, loss_freq: 0.034503
[15:26:26.909] iteration 5197: loss: 0.098010, loss_s1: 0.039370, loss_fp: 0.001024, loss_freq: 0.061647
[15:26:27.533] iteration 5198: loss: 0.125382, loss_s1: 0.029470, loss_fp: 0.001394, loss_freq: 0.015104
[15:26:28.154] iteration 5199: loss: 0.071833, loss_s1: 0.032619, loss_fp: 0.001092, loss_freq: 0.023575
[15:26:28.774] iteration 5200: loss: 0.049246, loss_s1: 0.032200, loss_fp: 0.001165, loss_freq: 0.008857
[15:26:31.692] iteration 5200 : mean_dice : 0.592672
[15:26:32.333] iteration 5201: loss: 0.092347, loss_s1: 0.055331, loss_fp: 0.001425, loss_freq: 0.016037
[15:26:32.953] iteration 5202: loss: 0.121006, loss_s1: 0.043566, loss_fp: 0.002079, loss_freq: 0.076291
[15:26:33.580] iteration 5203: loss: 0.126222, loss_s1: 0.113718, loss_fp: 0.001284, loss_freq: 0.060432
[15:26:34.204] iteration 5204: loss: 0.167462, loss_s1: 0.040303, loss_fp: 0.001104, loss_freq: 0.019970
[15:26:34.831] iteration 5205: loss: 0.128569, loss_s1: 0.069053, loss_fp: 0.001439, loss_freq: 0.084170
[15:26:35.454] iteration 5206: loss: 0.102880, loss_s1: 0.047602, loss_fp: 0.002825, loss_freq: 0.033711
[15:26:36.080] iteration 5207: loss: 0.134952, loss_s1: 0.093528, loss_fp: 0.008883, loss_freq: 0.044283
[15:26:36.704] iteration 5208: loss: 0.147279, loss_s1: 0.128331, loss_fp: 0.002376, loss_freq: 0.056330
[15:26:37.345] iteration 5209: loss: 0.093586, loss_s1: 0.026772, loss_fp: 0.004597, loss_freq: 0.033375
[15:26:37.972] iteration 5210: loss: 0.154965, loss_s1: 0.054680, loss_fp: 0.000803, loss_freq: 0.051274
[15:26:38.592] iteration 5211: loss: 0.068923, loss_s1: 0.048237, loss_fp: 0.000719, loss_freq: 0.014804
[15:26:39.214] iteration 5212: loss: 0.061641, loss_s1: 0.029496, loss_fp: 0.010006, loss_freq: 0.020170
[15:26:39.836] iteration 5213: loss: 0.094047, loss_s1: 0.065458, loss_fp: 0.001014, loss_freq: 0.054807
[15:26:40.460] iteration 5214: loss: 0.082948, loss_s1: 0.046303, loss_fp: 0.002622, loss_freq: 0.027388
[15:26:41.075] iteration 5215: loss: 0.083490, loss_s1: 0.047451, loss_fp: 0.000834, loss_freq: 0.023759
[15:26:41.699] iteration 5216: loss: 0.096571, loss_s1: 0.052506, loss_fp: 0.008079, loss_freq: 0.028918
[15:26:42.323] iteration 5217: loss: 0.073405, loss_s1: 0.043643, loss_fp: 0.001169, loss_freq: 0.017868
[15:26:42.942] iteration 5218: loss: 0.151076, loss_s1: 0.059215, loss_fp: 0.005892, loss_freq: 0.082205
[15:26:43.566] iteration 5219: loss: 0.119281, loss_s1: 0.068969, loss_fp: 0.004539, loss_freq: 0.073387
[15:26:44.188] iteration 5220: loss: 0.085682, loss_s1: 0.073987, loss_fp: 0.005991, loss_freq: 0.037987
[15:26:44.810] iteration 5221: loss: 0.087757, loss_s1: 0.052781, loss_fp: 0.001073, loss_freq: 0.011178
[15:26:45.432] iteration 5222: loss: 0.147609, loss_s1: 0.024058, loss_fp: 0.001015, loss_freq: 0.058021
[15:26:46.052] iteration 5223: loss: 0.103644, loss_s1: 0.072427, loss_fp: 0.002580, loss_freq: 0.022732
[15:26:46.666] iteration 5224: loss: 0.173354, loss_s1: 0.085799, loss_fp: 0.000972, loss_freq: 0.109565
[15:26:47.283] iteration 5225: loss: 0.068093, loss_s1: 0.013684, loss_fp: 0.004701, loss_freq: 0.039584
[15:26:47.907] iteration 5226: loss: 0.090530, loss_s1: 0.039878, loss_fp: 0.000690, loss_freq: 0.028599
[15:26:48.528] iteration 5227: loss: 0.132984, loss_s1: 0.098731, loss_fp: 0.001865, loss_freq: 0.048420
[15:26:49.145] iteration 5228: loss: 0.166541, loss_s1: 0.081337, loss_fp: 0.002305, loss_freq: 0.068516
[15:26:49.759] iteration 5229: loss: 0.124603, loss_s1: 0.043214, loss_fp: 0.003644, loss_freq: 0.094087
[15:26:50.381] iteration 5230: loss: 0.121258, loss_s1: 0.090542, loss_fp: 0.016103, loss_freq: 0.058409
[15:26:50.996] iteration 5231: loss: 0.076417, loss_s1: 0.069185, loss_fp: 0.003994, loss_freq: 0.019327
[15:26:51.610] iteration 5232: loss: 0.092376, loss_s1: 0.035221, loss_fp: 0.001896, loss_freq: 0.038232
[15:26:52.228] iteration 5233: loss: 0.133544, loss_s1: 0.019355, loss_fp: 0.007209, loss_freq: 0.047961
[15:26:52.845] iteration 5234: loss: 0.063433, loss_s1: 0.031555, loss_fp: 0.005233, loss_freq: 0.012852
[15:26:53.471] iteration 5235: loss: 0.154451, loss_s1: 0.114690, loss_fp: 0.021231, loss_freq: 0.081999
[15:26:54.085] iteration 5236: loss: 0.154686, loss_s1: 0.052559, loss_fp: 0.002932, loss_freq: 0.011651
[15:26:54.708] iteration 5237: loss: 0.136859, loss_s1: 0.124854, loss_fp: 0.010381, loss_freq: 0.080079
[15:26:55.332] iteration 5238: loss: 0.084992, loss_s1: 0.057035, loss_fp: 0.001165, loss_freq: 0.023888
[15:26:55.948] iteration 5239: loss: 0.125812, loss_s1: 0.061041, loss_fp: 0.001211, loss_freq: 0.082602
[15:26:56.564] iteration 5240: loss: 0.063618, loss_s1: 0.034104, loss_fp: 0.003960, loss_freq: 0.009931
[15:26:57.180] iteration 5241: loss: 0.178261, loss_s1: 0.151500, loss_fp: 0.003257, loss_freq: 0.037905
[15:26:57.798] iteration 5242: loss: 0.086883, loss_s1: 0.039251, loss_fp: 0.002133, loss_freq: 0.009261
[15:26:58.418] iteration 5243: loss: 0.123380, loss_s1: 0.059424, loss_fp: 0.000354, loss_freq: 0.047075
[15:26:59.034] iteration 5244: loss: 0.129543, loss_s1: 0.089745, loss_fp: 0.005834, loss_freq: 0.021357
[15:26:59.709] iteration 5245: loss: 0.190236, loss_s1: 0.090345, loss_fp: 0.000723, loss_freq: 0.019657
[15:27:00.365] iteration 5246: loss: 0.083060, loss_s1: 0.022521, loss_fp: 0.001889, loss_freq: 0.037860
[15:27:01.027] iteration 5247: loss: 0.075044, loss_s1: 0.048870, loss_fp: 0.002216, loss_freq: 0.024641
[15:27:01.689] iteration 5248: loss: 0.062948, loss_s1: 0.033226, loss_fp: 0.003077, loss_freq: 0.018606
[15:27:02.317] iteration 5249: loss: 0.102518, loss_s1: 0.026475, loss_fp: 0.000789, loss_freq: 0.034337
[15:27:02.945] iteration 5250: loss: 0.077929, loss_s1: 0.020450, loss_fp: 0.000311, loss_freq: 0.020080
[15:27:03.575] iteration 5251: loss: 0.073676, loss_s1: 0.037287, loss_fp: 0.000474, loss_freq: 0.017813
[15:27:04.202] iteration 5252: loss: 0.115550, loss_s1: 0.075662, loss_fp: 0.025216, loss_freq: 0.034888
[15:27:04.835] iteration 5253: loss: 0.084401, loss_s1: 0.062611, loss_fp: 0.000416, loss_freq: 0.043384
[15:27:05.460] iteration 5254: loss: 0.092576, loss_s1: 0.028952, loss_fp: 0.010551, loss_freq: 0.013309
[15:27:06.092] iteration 5255: loss: 0.121273, loss_s1: 0.055033, loss_fp: 0.005433, loss_freq: 0.074033
[15:27:06.716] iteration 5256: loss: 0.102455, loss_s1: 0.054486, loss_fp: 0.009628, loss_freq: 0.070370
[15:27:07.387] iteration 5257: loss: 0.146891, loss_s1: 0.085734, loss_fp: 0.001791, loss_freq: 0.033140
[15:27:08.048] iteration 5258: loss: 0.100857, loss_s1: 0.051862, loss_fp: 0.001350, loss_freq: 0.035176
[15:27:08.702] iteration 5259: loss: 0.088676, loss_s1: 0.041288, loss_fp: 0.000965, loss_freq: 0.018875
[15:27:09.333] iteration 5260: loss: 0.202161, loss_s1: 0.128550, loss_fp: 0.008002, loss_freq: 0.108075
[15:27:09.955] iteration 5261: loss: 0.277828, loss_s1: 0.177526, loss_fp: 0.003311, loss_freq: 0.202449
[15:27:10.580] iteration 5262: loss: 0.088645, loss_s1: 0.055763, loss_fp: 0.003899, loss_freq: 0.030138
[15:27:11.208] iteration 5263: loss: 0.142855, loss_s1: 0.045028, loss_fp: 0.006021, loss_freq: 0.062210
[15:27:11.835] iteration 5264: loss: 0.074570, loss_s1: 0.058906, loss_fp: 0.008526, loss_freq: 0.022264
[15:27:12.463] iteration 5265: loss: 0.183137, loss_s1: 0.104261, loss_fp: 0.017642, loss_freq: 0.155733
[15:27:13.087] iteration 5266: loss: 0.091320, loss_s1: 0.037488, loss_fp: 0.008453, loss_freq: 0.062232
[15:27:13.726] iteration 5267: loss: 0.059248, loss_s1: 0.016346, loss_fp: 0.000711, loss_freq: 0.005779
[15:27:14.381] iteration 5268: loss: 0.152678, loss_s1: 0.126139, loss_fp: 0.001558, loss_freq: 0.026274
[15:27:15.038] iteration 5269: loss: 0.124992, loss_s1: 0.118027, loss_fp: 0.002255, loss_freq: 0.044534
[15:27:15.694] iteration 5270: loss: 0.119997, loss_s1: 0.067517, loss_fp: 0.004711, loss_freq: 0.104738
[15:27:16.351] iteration 5271: loss: 0.155576, loss_s1: 0.051580, loss_fp: 0.008482, loss_freq: 0.034236
[15:27:16.977] iteration 5272: loss: 0.157719, loss_s1: 0.085468, loss_fp: 0.002112, loss_freq: 0.163435
[15:27:17.602] iteration 5273: loss: 0.058186, loss_s1: 0.040993, loss_fp: 0.002085, loss_freq: 0.012070
[15:27:18.229] iteration 5274: loss: 0.152343, loss_s1: 0.020052, loss_fp: 0.001039, loss_freq: 0.005552
[15:27:18.856] iteration 5275: loss: 0.124171, loss_s1: 0.084808, loss_fp: 0.003770, loss_freq: 0.058519
[15:27:19.478] iteration 5276: loss: 0.143913, loss_s1: 0.128048, loss_fp: 0.002439, loss_freq: 0.017127
[15:27:20.104] iteration 5277: loss: 0.113280, loss_s1: 0.021083, loss_fp: 0.006425, loss_freq: 0.042719
[15:27:20.771] iteration 5278: loss: 0.146343, loss_s1: 0.017244, loss_fp: 0.032422, loss_freq: 0.009296
[15:27:21.423] iteration 5279: loss: 0.114046, loss_s1: 0.065538, loss_fp: 0.000722, loss_freq: 0.022438
[15:27:22.053] iteration 5280: loss: 0.239971, loss_s1: 0.125719, loss_fp: 0.000710, loss_freq: 0.151128
[15:27:22.676] iteration 5281: loss: 0.094163, loss_s1: 0.054832, loss_fp: 0.001137, loss_freq: 0.010295
[15:27:23.300] iteration 5282: loss: 0.109512, loss_s1: 0.063928, loss_fp: 0.003877, loss_freq: 0.025963
[15:27:23.916] iteration 5283: loss: 0.145771, loss_s1: 0.089941, loss_fp: 0.003411, loss_freq: 0.095452
[15:27:24.537] iteration 5284: loss: 0.120007, loss_s1: 0.052327, loss_fp: 0.003220, loss_freq: 0.060894
[15:27:25.163] iteration 5285: loss: 0.087595, loss_s1: 0.036223, loss_fp: 0.004562, loss_freq: 0.022184
[15:27:25.783] iteration 5286: loss: 0.132944, loss_s1: 0.068942, loss_fp: 0.003448, loss_freq: 0.059579
[15:27:26.411] iteration 5287: loss: 0.132864, loss_s1: 0.123954, loss_fp: 0.005940, loss_freq: 0.059165
[15:27:27.041] iteration 5288: loss: 0.120727, loss_s1: 0.105761, loss_fp: 0.002414, loss_freq: 0.036673
[15:27:27.656] iteration 5289: loss: 0.165733, loss_s1: 0.073514, loss_fp: 0.000967, loss_freq: 0.041862
[15:27:28.275] iteration 5290: loss: 0.116662, loss_s1: 0.074620, loss_fp: 0.001695, loss_freq: 0.020449
[15:27:28.895] iteration 5291: loss: 0.104209, loss_s1: 0.081190, loss_fp: 0.002541, loss_freq: 0.019785
[15:27:29.508] iteration 5292: loss: 0.167603, loss_s1: 0.072000, loss_fp: 0.003149, loss_freq: 0.100495
[15:27:30.129] iteration 5293: loss: 0.155849, loss_s1: 0.099803, loss_fp: 0.006070, loss_freq: 0.061134
[15:27:30.752] iteration 5294: loss: 0.090243, loss_s1: 0.036397, loss_fp: 0.000528, loss_freq: 0.023304
[15:27:31.370] iteration 5295: loss: 0.144868, loss_s1: 0.083535, loss_fp: 0.004705, loss_freq: 0.057424
[15:27:31.989] iteration 5296: loss: 0.099893, loss_s1: 0.059134, loss_fp: 0.004616, loss_freq: 0.029045
[15:27:32.609] iteration 5297: loss: 0.075957, loss_s1: 0.011979, loss_fp: 0.001710, loss_freq: 0.023982
[15:27:33.233] iteration 5298: loss: 0.105971, loss_s1: 0.046209, loss_fp: 0.000474, loss_freq: 0.019451
[15:27:33.850] iteration 5299: loss: 0.069783, loss_s1: 0.024922, loss_fp: 0.002491, loss_freq: 0.054920
[15:27:34.511] iteration 5300: loss: 0.094390, loss_s1: 0.061930, loss_fp: 0.002436, loss_freq: 0.029210
[15:27:35.168] iteration 5301: loss: 0.071252, loss_s1: 0.020961, loss_fp: 0.001143, loss_freq: 0.015045
[15:27:35.829] iteration 5302: loss: 0.162209, loss_s1: 0.156564, loss_fp: 0.002043, loss_freq: 0.046604
[15:27:36.485] iteration 5303: loss: 0.110767, loss_s1: 0.035289, loss_fp: 0.001183, loss_freq: 0.034043
[15:27:37.120] iteration 5304: loss: 0.168751, loss_s1: 0.127003, loss_fp: 0.002120, loss_freq: 0.083485
[15:27:37.775] iteration 5305: loss: 0.094392, loss_s1: 0.052902, loss_fp: 0.001105, loss_freq: 0.019527
[15:27:38.433] iteration 5306: loss: 0.198083, loss_s1: 0.101496, loss_fp: 0.001748, loss_freq: 0.038681
[15:27:39.090] iteration 5307: loss: 0.072820, loss_s1: 0.025642, loss_fp: 0.003342, loss_freq: 0.014039
[15:27:39.748] iteration 5308: loss: 0.110707, loss_s1: 0.033958, loss_fp: 0.002174, loss_freq: 0.047343
[15:27:40.397] iteration 5309: loss: 0.146402, loss_s1: 0.022945, loss_fp: 0.001017, loss_freq: 0.043576
[15:27:41.022] iteration 5310: loss: 0.176086, loss_s1: 0.087708, loss_fp: 0.001413, loss_freq: 0.086328
[15:27:41.637] iteration 5311: loss: 0.129092, loss_s1: 0.102187, loss_fp: 0.005327, loss_freq: 0.041705
[15:27:42.254] iteration 5312: loss: 0.110299, loss_s1: 0.043072, loss_fp: 0.001807, loss_freq: 0.025963
[15:27:42.881] iteration 5313: loss: 0.130904, loss_s1: 0.085437, loss_fp: 0.001071, loss_freq: 0.046428
[15:27:43.865] iteration 5314: loss: 0.099863, loss_s1: 0.014227, loss_fp: 0.000879, loss_freq: 0.025428
[15:27:44.482] iteration 5315: loss: 0.096507, loss_s1: 0.041265, loss_fp: 0.002638, loss_freq: 0.032724
[15:27:45.106] iteration 5316: loss: 0.105351, loss_s1: 0.042873, loss_fp: 0.001986, loss_freq: 0.036234
[15:27:45.725] iteration 5317: loss: 0.142961, loss_s1: 0.071612, loss_fp: 0.004844, loss_freq: 0.051126
[15:27:46.343] iteration 5318: loss: 0.138306, loss_s1: 0.031370, loss_fp: 0.002284, loss_freq: 0.019945
[15:27:46.969] iteration 5319: loss: 0.192271, loss_s1: 0.078548, loss_fp: 0.002346, loss_freq: 0.070686
[15:27:47.583] iteration 5320: loss: 0.039002, loss_s1: 0.010295, loss_fp: 0.000789, loss_freq: 0.008791
[15:27:48.235] iteration 5321: loss: 0.119552, loss_s1: 0.052985, loss_fp: 0.003999, loss_freq: 0.102650
[15:27:48.895] iteration 5322: loss: 0.073869, loss_s1: 0.054229, loss_fp: 0.001100, loss_freq: 0.017773
[15:27:49.562] iteration 5323: loss: 0.169339, loss_s1: 0.153727, loss_fp: 0.004592, loss_freq: 0.049534
[15:27:50.191] iteration 5324: loss: 0.080297, loss_s1: 0.014621, loss_fp: 0.002285, loss_freq: 0.019956
[15:27:50.804] iteration 5325: loss: 0.090340, loss_s1: 0.038038, loss_fp: 0.006690, loss_freq: 0.038820
[15:27:51.424] iteration 5326: loss: 0.096034, loss_s1: 0.064422, loss_fp: 0.001957, loss_freq: 0.054772
[15:27:52.044] iteration 5327: loss: 0.136082, loss_s1: 0.076329, loss_fp: 0.001465, loss_freq: 0.039175
[15:27:52.657] iteration 5328: loss: 0.108222, loss_s1: 0.072497, loss_fp: 0.000467, loss_freq: 0.025365
[15:27:53.282] iteration 5329: loss: 0.165421, loss_s1: 0.070088, loss_fp: 0.002588, loss_freq: 0.097769
[15:27:53.905] iteration 5330: loss: 0.131320, loss_s1: 0.049174, loss_fp: 0.002873, loss_freq: 0.017364
[15:27:54.537] iteration 5331: loss: 0.087002, loss_s1: 0.056527, loss_fp: 0.002135, loss_freq: 0.032191
[15:27:55.164] iteration 5332: loss: 0.106821, loss_s1: 0.058471, loss_fp: 0.000679, loss_freq: 0.024596
[15:27:55.788] iteration 5333: loss: 0.122149, loss_s1: 0.058470, loss_fp: 0.002129, loss_freq: 0.036959
[15:27:56.410] iteration 5334: loss: 0.058878, loss_s1: 0.017689, loss_fp: 0.000923, loss_freq: 0.002576
[15:27:57.037] iteration 5335: loss: 0.102809, loss_s1: 0.083005, loss_fp: 0.003083, loss_freq: 0.022184
[15:27:57.655] iteration 5336: loss: 0.127367, loss_s1: 0.040492, loss_fp: 0.002195, loss_freq: 0.015191
[15:27:58.293] iteration 5337: loss: 0.156583, loss_s1: 0.163028, loss_fp: 0.002821, loss_freq: 0.067728
[15:27:58.931] iteration 5338: loss: 0.055655, loss_s1: 0.026431, loss_fp: 0.000480, loss_freq: 0.024927
[15:27:59.563] iteration 5339: loss: 0.128974, loss_s1: 0.075128, loss_fp: 0.002690, loss_freq: 0.087394
[15:28:00.179] iteration 5340: loss: 0.118820, loss_s1: 0.073305, loss_fp: 0.002257, loss_freq: 0.072812
[15:28:00.805] iteration 5341: loss: 0.176341, loss_s1: 0.058938, loss_fp: 0.000654, loss_freq: 0.061106
[15:28:01.422] iteration 5342: loss: 0.133474, loss_s1: 0.092637, loss_fp: 0.001165, loss_freq: 0.033205
[15:28:02.042] iteration 5343: loss: 0.094415, loss_s1: 0.039166, loss_fp: 0.003478, loss_freq: 0.011482
[15:28:02.661] iteration 5344: loss: 0.086571, loss_s1: 0.074840, loss_fp: 0.001546, loss_freq: 0.025569
[15:28:03.287] iteration 5345: loss: 0.154262, loss_s1: 0.059258, loss_fp: 0.001304, loss_freq: 0.034384
[15:28:03.906] iteration 5346: loss: 0.089953, loss_s1: 0.063647, loss_fp: 0.001317, loss_freq: 0.039378
[15:28:04.519] iteration 5347: loss: 0.081191, loss_s1: 0.055081, loss_fp: 0.001620, loss_freq: 0.017365
[15:28:05.183] iteration 5348: loss: 0.176025, loss_s1: 0.085050, loss_fp: 0.002247, loss_freq: 0.041513
[15:28:05.808] iteration 5349: loss: 0.143058, loss_s1: 0.118994, loss_fp: 0.003116, loss_freq: 0.047607
[15:28:06.430] iteration 5350: loss: 0.212485, loss_s1: 0.139588, loss_fp: 0.002127, loss_freq: 0.112568
[15:28:07.053] iteration 5351: loss: 0.076343, loss_s1: 0.040141, loss_fp: 0.000565, loss_freq: 0.007687
[15:28:07.672] iteration 5352: loss: 0.162657, loss_s1: 0.121949, loss_fp: 0.002523, loss_freq: 0.081215
[15:28:08.351] iteration 5353: loss: 0.124672, loss_s1: 0.122476, loss_fp: 0.005355, loss_freq: 0.030327
[15:28:09.006] iteration 5354: loss: 0.143990, loss_s1: 0.079626, loss_fp: 0.004043, loss_freq: 0.052822
[15:28:09.664] iteration 5355: loss: 0.079636, loss_s1: 0.054723, loss_fp: 0.008411, loss_freq: 0.034568
[15:28:10.325] iteration 5356: loss: 0.086056, loss_s1: 0.036091, loss_fp: 0.001227, loss_freq: 0.059062
[15:28:10.987] iteration 5357: loss: 0.092270, loss_s1: 0.056464, loss_fp: 0.001082, loss_freq: 0.042558
[15:28:11.613] iteration 5358: loss: 0.144322, loss_s1: 0.128975, loss_fp: 0.000806, loss_freq: 0.059804
[15:28:12.241] iteration 5359: loss: 0.125852, loss_s1: 0.095762, loss_fp: 0.002709, loss_freq: 0.032313
[15:28:12.865] iteration 5360: loss: 0.068467, loss_s1: 0.049302, loss_fp: 0.002252, loss_freq: 0.015196
[15:28:13.490] iteration 5361: loss: 0.069200, loss_s1: 0.038016, loss_fp: 0.000773, loss_freq: 0.021723
[15:28:14.194] iteration 5362: loss: 0.101058, loss_s1: 0.046786, loss_fp: 0.005341, loss_freq: 0.016029
[15:28:14.868] iteration 5363: loss: 0.083580, loss_s1: 0.034589, loss_fp: 0.002837, loss_freq: 0.027692
[15:28:15.526] iteration 5364: loss: 0.072827, loss_s1: 0.046023, loss_fp: 0.000727, loss_freq: 0.033243
[15:28:16.185] iteration 5365: loss: 0.090682, loss_s1: 0.015772, loss_fp: 0.000954, loss_freq: 0.030925
[15:28:16.845] iteration 5366: loss: 0.105162, loss_s1: 0.037510, loss_fp: 0.006653, loss_freq: 0.062601
[15:28:17.495] iteration 5367: loss: 0.123751, loss_s1: 0.126176, loss_fp: 0.001571, loss_freq: 0.033251
[15:28:18.117] iteration 5368: loss: 0.120511, loss_s1: 0.074527, loss_fp: 0.001677, loss_freq: 0.020181
[15:28:18.745] iteration 5369: loss: 0.158798, loss_s1: 0.181105, loss_fp: 0.002144, loss_freq: 0.049709
[15:28:19.375] iteration 5370: loss: 0.076222, loss_s1: 0.038586, loss_fp: 0.010535, loss_freq: 0.014176
[15:28:20.009] iteration 5371: loss: 0.157769, loss_s1: 0.017206, loss_fp: 0.012593, loss_freq: 0.054037
[15:28:20.634] iteration 5372: loss: 0.086638, loss_s1: 0.071920, loss_fp: 0.002362, loss_freq: 0.025835
[15:28:21.266] iteration 5373: loss: 0.061764, loss_s1: 0.033766, loss_fp: 0.005010, loss_freq: 0.028200
[15:28:21.894] iteration 5374: loss: 0.104671, loss_s1: 0.038333, loss_fp: 0.001154, loss_freq: 0.020550
[15:28:22.517] iteration 5375: loss: 0.076158, loss_s1: 0.035682, loss_fp: 0.007935, loss_freq: 0.022458
[15:28:23.149] iteration 5376: loss: 0.100756, loss_s1: 0.076843, loss_fp: 0.006898, loss_freq: 0.022918
[15:28:23.777] iteration 5377: loss: 0.109994, loss_s1: 0.054031, loss_fp: 0.008578, loss_freq: 0.031605
[15:28:24.402] iteration 5378: loss: 0.089191, loss_s1: 0.067971, loss_fp: 0.003351, loss_freq: 0.005248
[15:28:25.031] iteration 5379: loss: 0.133793, loss_s1: 0.057647, loss_fp: 0.014670, loss_freq: 0.055098
[15:28:25.660] iteration 5380: loss: 0.136526, loss_s1: 0.090238, loss_fp: 0.002994, loss_freq: 0.072009
[15:28:26.288] iteration 5381: loss: 0.089661, loss_s1: 0.055041, loss_fp: 0.000583, loss_freq: 0.042285
[15:28:26.908] iteration 5382: loss: 0.105276, loss_s1: 0.081479, loss_fp: 0.004784, loss_freq: 0.042310
[15:28:27.532] iteration 5383: loss: 0.126152, loss_s1: 0.045428, loss_fp: 0.016795, loss_freq: 0.035928
[15:28:28.158] iteration 5384: loss: 0.098856, loss_s1: 0.052031, loss_fp: 0.001962, loss_freq: 0.039360
[15:28:28.791] iteration 5385: loss: 0.114068, loss_s1: 0.057486, loss_fp: 0.001064, loss_freq: 0.051789
[15:28:29.418] iteration 5386: loss: 0.124302, loss_s1: 0.061943, loss_fp: 0.008486, loss_freq: 0.053734
[15:28:30.220] iteration 5387: loss: 0.098678, loss_s1: 0.053900, loss_fp: 0.001152, loss_freq: 0.026533
[15:28:30.888] iteration 5388: loss: 0.129571, loss_s1: 0.098793, loss_fp: 0.001289, loss_freq: 0.028140
[15:28:31.589] iteration 5389: loss: 0.181394, loss_s1: 0.087073, loss_fp: 0.003241, loss_freq: 0.124627
[15:28:32.209] iteration 5390: loss: 0.151764, loss_s1: 0.117536, loss_fp: 0.003978, loss_freq: 0.055157
[15:28:32.822] iteration 5391: loss: 0.110970, loss_s1: 0.107689, loss_fp: 0.003735, loss_freq: 0.032276
[15:28:33.448] iteration 5392: loss: 0.069050, loss_s1: 0.046925, loss_fp: 0.004211, loss_freq: 0.015047
[15:28:34.065] iteration 5393: loss: 0.105034, loss_s1: 0.061933, loss_fp: 0.032390, loss_freq: 0.031299
[15:28:34.677] iteration 5394: loss: 0.121221, loss_s1: 0.025148, loss_fp: 0.004985, loss_freq: 0.023757
[15:28:35.294] iteration 5395: loss: 0.089042, loss_s1: 0.060731, loss_fp: 0.006351, loss_freq: 0.035207
[15:28:35.914] iteration 5396: loss: 0.152995, loss_s1: 0.091985, loss_fp: 0.007360, loss_freq: 0.131486
[15:28:36.535] iteration 5397: loss: 0.190003, loss_s1: 0.085674, loss_fp: 0.009366, loss_freq: 0.073243
[15:28:37.190] iteration 5398: loss: 0.114827, loss_s1: 0.071432, loss_fp: 0.005166, loss_freq: 0.071353
[15:28:37.808] iteration 5399: loss: 0.080480, loss_s1: 0.059974, loss_fp: 0.002842, loss_freq: 0.018827
[15:28:38.448] iteration 5400: loss: 0.187121, loss_s1: 0.069898, loss_fp: 0.005882, loss_freq: 0.055333
[15:28:41.680] iteration 5400 : mean_dice : 0.665032
[15:28:42.314] iteration 5401: loss: 0.076460, loss_s1: 0.028956, loss_fp: 0.001327, loss_freq: 0.016558
[15:28:42.928] iteration 5402: loss: 0.133671, loss_s1: 0.093195, loss_fp: 0.007337, loss_freq: 0.058626
[15:28:43.542] iteration 5403: loss: 0.121061, loss_s1: 0.049393, loss_fp: 0.005489, loss_freq: 0.026285
[15:28:44.159] iteration 5404: loss: 0.138221, loss_s1: 0.027898, loss_fp: 0.000589, loss_freq: 0.043348
[15:28:44.781] iteration 5405: loss: 0.117093, loss_s1: 0.081409, loss_fp: 0.000828, loss_freq: 0.009440
[15:28:45.401] iteration 5406: loss: 0.140847, loss_s1: 0.043968, loss_fp: 0.000539, loss_freq: 0.029489
[15:28:46.027] iteration 5407: loss: 0.086899, loss_s1: 0.053165, loss_fp: 0.000697, loss_freq: 0.022621
[15:28:46.652] iteration 5408: loss: 0.065185, loss_s1: 0.033835, loss_fp: 0.000472, loss_freq: 0.013908
[15:28:47.274] iteration 5409: loss: 0.054113, loss_s1: 0.018320, loss_fp: 0.001331, loss_freq: 0.014996
[15:28:47.888] iteration 5410: loss: 0.097929, loss_s1: 0.011549, loss_fp: 0.000592, loss_freq: 0.027794
[15:28:48.505] iteration 5411: loss: 0.112899, loss_s1: 0.026289, loss_fp: 0.001367, loss_freq: 0.019635
[15:28:49.139] iteration 5412: loss: 0.159582, loss_s1: 0.082145, loss_fp: 0.003641, loss_freq: 0.013336
[15:28:49.759] iteration 5413: loss: 0.108615, loss_s1: 0.056873, loss_fp: 0.000650, loss_freq: 0.023014
[15:28:50.381] iteration 5414: loss: 0.157134, loss_s1: 0.070429, loss_fp: 0.001404, loss_freq: 0.054111
[15:28:51.003] iteration 5415: loss: 0.140718, loss_s1: 0.037512, loss_fp: 0.005283, loss_freq: 0.054411
[15:28:51.659] iteration 5416: loss: 0.136352, loss_s1: 0.051063, loss_fp: 0.002581, loss_freq: 0.044427
[15:28:52.326] iteration 5417: loss: 0.091764, loss_s1: 0.034725, loss_fp: 0.004819, loss_freq: 0.050817
[15:28:52.960] iteration 5418: loss: 0.133104, loss_s1: 0.050001, loss_fp: 0.000915, loss_freq: 0.035806
[15:28:53.603] iteration 5419: loss: 0.109465, loss_s1: 0.029205, loss_fp: 0.000971, loss_freq: 0.021154
[15:28:54.225] iteration 5420: loss: 0.104769, loss_s1: 0.023120, loss_fp: 0.000426, loss_freq: 0.011174
[15:28:54.898] iteration 5421: loss: 0.163438, loss_s1: 0.104333, loss_fp: 0.001300, loss_freq: 0.079756
[15:28:55.562] iteration 5422: loss: 0.229716, loss_s1: 0.126405, loss_fp: 0.003215, loss_freq: 0.204710
[15:28:56.206] iteration 5423: loss: 0.097971, loss_s1: 0.038917, loss_fp: 0.001788, loss_freq: 0.039164
[15:28:56.845] iteration 5424: loss: 0.120907, loss_s1: 0.053505, loss_fp: 0.000835, loss_freq: 0.039761
[15:28:57.471] iteration 5425: loss: 0.075997, loss_s1: 0.046676, loss_fp: 0.000726, loss_freq: 0.042626
[15:28:58.096] iteration 5426: loss: 0.176097, loss_s1: 0.115488, loss_fp: 0.003414, loss_freq: 0.121319
[15:28:58.731] iteration 5427: loss: 0.079620, loss_s1: 0.032421, loss_fp: 0.001299, loss_freq: 0.024819
[15:28:59.358] iteration 5428: loss: 0.067295, loss_s1: 0.031545, loss_fp: 0.009021, loss_freq: 0.001707
[15:28:59.998] iteration 5429: loss: 0.117290, loss_s1: 0.075000, loss_fp: 0.006667, loss_freq: 0.031796
[15:29:00.637] iteration 5430: loss: 0.129762, loss_s1: 0.095990, loss_fp: 0.003931, loss_freq: 0.049732
[15:29:01.265] iteration 5431: loss: 0.068888, loss_s1: 0.031793, loss_fp: 0.005676, loss_freq: 0.010134
[15:29:01.895] iteration 5432: loss: 0.117374, loss_s1: 0.024440, loss_fp: 0.000589, loss_freq: 0.031680
[15:29:02.531] iteration 5433: loss: 0.178168, loss_s1: 0.091161, loss_fp: 0.002885, loss_freq: 0.186934
[15:29:03.152] iteration 5434: loss: 0.064055, loss_s1: 0.020084, loss_fp: 0.002251, loss_freq: 0.044889
[15:29:03.780] iteration 5435: loss: 0.137586, loss_s1: 0.029225, loss_fp: 0.001246, loss_freq: 0.007779
[15:29:04.417] iteration 5436: loss: 0.099343, loss_s1: 0.044735, loss_fp: 0.006706, loss_freq: 0.024401
[15:29:05.052] iteration 5437: loss: 0.162526, loss_s1: 0.093287, loss_fp: 0.004534, loss_freq: 0.135808
[15:29:05.676] iteration 5438: loss: 0.183806, loss_s1: 0.058450, loss_fp: 0.000447, loss_freq: 0.039942
[15:29:06.308] iteration 5439: loss: 0.149760, loss_s1: 0.072456, loss_fp: 0.000802, loss_freq: 0.025019
[15:29:06.945] iteration 5440: loss: 0.097590, loss_s1: 0.067302, loss_fp: 0.001192, loss_freq: 0.009667
[15:29:07.579] iteration 5441: loss: 0.195803, loss_s1: 0.125782, loss_fp: 0.001527, loss_freq: 0.051385
[15:29:08.207] iteration 5442: loss: 0.085836, loss_s1: 0.056959, loss_fp: 0.011565, loss_freq: 0.007714
[15:29:08.826] iteration 5443: loss: 0.080580, loss_s1: 0.043571, loss_fp: 0.001967, loss_freq: 0.010693
[15:29:09.452] iteration 5444: loss: 0.114053, loss_s1: 0.071140, loss_fp: 0.002299, loss_freq: 0.074423
[15:29:10.072] iteration 5445: loss: 0.151622, loss_s1: 0.097600, loss_fp: 0.010500, loss_freq: 0.095382
[15:29:10.697] iteration 5446: loss: 0.126423, loss_s1: 0.049677, loss_fp: 0.017906, loss_freq: 0.032015
[15:29:11.317] iteration 5447: loss: 0.144396, loss_s1: 0.054419, loss_fp: 0.004449, loss_freq: 0.050798
[15:29:11.942] iteration 5448: loss: 0.119526, loss_s1: 0.089114, loss_fp: 0.001020, loss_freq: 0.064512
[15:29:12.569] iteration 5449: loss: 0.082003, loss_s1: 0.037509, loss_fp: 0.009260, loss_freq: 0.020098
[15:29:13.194] iteration 5450: loss: 0.128489, loss_s1: 0.058246, loss_fp: 0.004692, loss_freq: 0.059550
[15:29:13.822] iteration 5451: loss: 0.103408, loss_s1: 0.068063, loss_fp: 0.003306, loss_freq: 0.014438
[15:29:14.448] iteration 5452: loss: 0.081464, loss_s1: 0.068502, loss_fp: 0.001976, loss_freq: 0.023614
[15:29:15.072] iteration 5453: loss: 0.211984, loss_s1: 0.112909, loss_fp: 0.007687, loss_freq: 0.081236
[15:29:15.698] iteration 5454: loss: 0.181334, loss_s1: 0.135038, loss_fp: 0.006450, loss_freq: 0.035893
[15:29:16.320] iteration 5455: loss: 0.118403, loss_s1: 0.031522, loss_fp: 0.005360, loss_freq: 0.035808
[15:29:16.976] iteration 5456: loss: 0.110635, loss_s1: 0.050440, loss_fp: 0.002587, loss_freq: 0.027220
[15:29:17.630] iteration 5457: loss: 0.125761, loss_s1: 0.087332, loss_fp: 0.007383, loss_freq: 0.059875
[15:29:18.292] iteration 5458: loss: 0.075034, loss_s1: 0.045786, loss_fp: 0.001141, loss_freq: 0.006879
[15:29:18.956] iteration 5459: loss: 0.097801, loss_s1: 0.059762, loss_fp: 0.001496, loss_freq: 0.012533
[15:29:19.610] iteration 5460: loss: 0.090221, loss_s1: 0.049241, loss_fp: 0.005169, loss_freq: 0.061838
[15:29:20.240] iteration 5461: loss: 0.099047, loss_s1: 0.066918, loss_fp: 0.004216, loss_freq: 0.033923
[15:29:20.861] iteration 5462: loss: 0.086371, loss_s1: 0.026207, loss_fp: 0.002139, loss_freq: 0.033459
[15:29:21.487] iteration 5463: loss: 0.110117, loss_s1: 0.068921, loss_fp: 0.016936, loss_freq: 0.059964
[15:29:22.108] iteration 5464: loss: 0.107872, loss_s1: 0.031675, loss_fp: 0.005721, loss_freq: 0.039448
[15:29:22.734] iteration 5465: loss: 0.241466, loss_s1: 0.223556, loss_fp: 0.005142, loss_freq: 0.104313
[15:29:23.359] iteration 5466: loss: 0.096203, loss_s1: 0.053011, loss_fp: 0.007637, loss_freq: 0.023894
[15:29:23.980] iteration 5467: loss: 0.117057, loss_s1: 0.054590, loss_fp: 0.004887, loss_freq: 0.016026
[15:29:24.617] iteration 5468: loss: 0.078514, loss_s1: 0.021321, loss_fp: 0.002829, loss_freq: 0.011504
[15:29:25.239] iteration 5469: loss: 0.120077, loss_s1: 0.062940, loss_fp: 0.000654, loss_freq: 0.047667
[15:29:25.857] iteration 5470: loss: 0.134273, loss_s1: 0.064670, loss_fp: 0.000698, loss_freq: 0.031275
[15:29:26.479] iteration 5471: loss: 0.163387, loss_s1: 0.068437, loss_fp: 0.001308, loss_freq: 0.095585
[15:29:27.102] iteration 5472: loss: 0.198216, loss_s1: 0.110400, loss_fp: 0.015085, loss_freq: 0.071015
[15:29:27.727] iteration 5473: loss: 0.131482, loss_s1: 0.041205, loss_fp: 0.001483, loss_freq: 0.031575
[15:29:28.346] iteration 5474: loss: 0.093373, loss_s1: 0.081070, loss_fp: 0.000833, loss_freq: 0.018993
[15:29:29.379] iteration 5475: loss: 0.101587, loss_s1: 0.051541, loss_fp: 0.000697, loss_freq: 0.034150
[15:29:30.011] iteration 5476: loss: 0.164117, loss_s1: 0.087111, loss_fp: 0.007069, loss_freq: 0.067035
[15:29:30.647] iteration 5477: loss: 0.150419, loss_s1: 0.075925, loss_fp: 0.001123, loss_freq: 0.052752
[15:29:31.305] iteration 5478: loss: 0.091677, loss_s1: 0.031718, loss_fp: 0.000901, loss_freq: 0.022100
[15:29:31.946] iteration 5479: loss: 0.158061, loss_s1: 0.069780, loss_fp: 0.002945, loss_freq: 0.018433
[15:29:32.580] iteration 5480: loss: 0.194862, loss_s1: 0.091773, loss_fp: 0.014167, loss_freq: 0.072652
[15:29:33.210] iteration 5481: loss: 0.077198, loss_s1: 0.061407, loss_fp: 0.003343, loss_freq: 0.022355
[15:29:33.834] iteration 5482: loss: 0.087215, loss_s1: 0.037027, loss_fp: 0.007241, loss_freq: 0.050460
[15:29:34.508] iteration 5483: loss: 0.082769, loss_s1: 0.044721, loss_fp: 0.000874, loss_freq: 0.034090
[15:29:35.173] iteration 5484: loss: 0.131097, loss_s1: 0.094576, loss_fp: 0.002641, loss_freq: 0.075364
[15:29:35.830] iteration 5485: loss: 0.105328, loss_s1: 0.030200, loss_fp: 0.003755, loss_freq: 0.025002
[15:29:36.489] iteration 5486: loss: 0.115572, loss_s1: 0.058551, loss_fp: 0.004531, loss_freq: 0.046291
[15:29:37.153] iteration 5487: loss: 0.105929, loss_s1: 0.102311, loss_fp: 0.006163, loss_freq: 0.043537
[15:29:37.812] iteration 5488: loss: 0.144750, loss_s1: 0.133674, loss_fp: 0.004101, loss_freq: 0.046214
[15:29:38.475] iteration 5489: loss: 0.089250, loss_s1: 0.037655, loss_fp: 0.004513, loss_freq: 0.023212
[15:29:39.104] iteration 5490: loss: 0.128231, loss_s1: 0.078645, loss_fp: 0.004141, loss_freq: 0.036687
[15:29:39.731] iteration 5491: loss: 0.155704, loss_s1: 0.077342, loss_fp: 0.016187, loss_freq: 0.033627
[15:29:40.354] iteration 5492: loss: 0.086699, loss_s1: 0.055518, loss_fp: 0.002188, loss_freq: 0.011599
[15:29:41.004] iteration 5493: loss: 0.099045, loss_s1: 0.039774, loss_fp: 0.015668, loss_freq: 0.027978
[15:29:41.627] iteration 5494: loss: 0.091428, loss_s1: 0.040259, loss_fp: 0.001374, loss_freq: 0.020080
[15:29:42.250] iteration 5495: loss: 0.092719, loss_s1: 0.035026, loss_fp: 0.003442, loss_freq: 0.042757
[15:29:42.878] iteration 5496: loss: 0.117357, loss_s1: 0.076143, loss_fp: 0.000564, loss_freq: 0.035204
[15:29:43.503] iteration 5497: loss: 0.107906, loss_s1: 0.044041, loss_fp: 0.001870, loss_freq: 0.011521
[15:29:44.125] iteration 5498: loss: 0.155581, loss_s1: 0.129669, loss_fp: 0.015653, loss_freq: 0.095375
[15:29:44.746] iteration 5499: loss: 0.059530, loss_s1: 0.031423, loss_fp: 0.001110, loss_freq: 0.017682
[15:29:45.378] iteration 5500: loss: 0.128171, loss_s1: 0.100060, loss_fp: 0.005046, loss_freq: 0.054402
[15:29:45.999] iteration 5501: loss: 0.084248, loss_s1: 0.023565, loss_fp: 0.003268, loss_freq: 0.048522
[15:29:46.624] iteration 5502: loss: 0.112515, loss_s1: 0.038753, loss_fp: 0.009375, loss_freq: 0.051897
[15:29:47.246] iteration 5503: loss: 0.108887, loss_s1: 0.102243, loss_fp: 0.001322, loss_freq: 0.048329
[15:29:47.871] iteration 5504: loss: 0.086034, loss_s1: 0.043936, loss_fp: 0.001331, loss_freq: 0.023966
[15:29:48.489] iteration 5505: loss: 0.119063, loss_s1: 0.040094, loss_fp: 0.000924, loss_freq: 0.035078
[15:29:49.112] iteration 5506: loss: 0.088912, loss_s1: 0.017143, loss_fp: 0.001742, loss_freq: 0.009702
[15:29:49.736] iteration 5507: loss: 0.063666, loss_s1: 0.038752, loss_fp: 0.002384, loss_freq: 0.026370
[15:29:50.364] iteration 5508: loss: 0.075943, loss_s1: 0.031241, loss_fp: 0.006091, loss_freq: 0.021441
[15:29:50.986] iteration 5509: loss: 0.111779, loss_s1: 0.029661, loss_fp: 0.000673, loss_freq: 0.023799
[15:29:51.607] iteration 5510: loss: 0.140309, loss_s1: 0.061897, loss_fp: 0.001746, loss_freq: 0.044708
[15:29:52.236] iteration 5511: loss: 0.145559, loss_s1: 0.152267, loss_fp: 0.001788, loss_freq: 0.018060
[15:29:52.863] iteration 5512: loss: 0.080453, loss_s1: 0.073227, loss_fp: 0.004052, loss_freq: 0.014247
[15:29:53.492] iteration 5513: loss: 0.176436, loss_s1: 0.102875, loss_fp: 0.000519, loss_freq: 0.116325
[15:29:54.113] iteration 5514: loss: 0.184513, loss_s1: 0.143205, loss_fp: 0.001050, loss_freq: 0.102289
[15:29:54.740] iteration 5515: loss: 0.151746, loss_s1: 0.064281, loss_fp: 0.003531, loss_freq: 0.051520
[15:29:55.364] iteration 5516: loss: 0.062824, loss_s1: 0.032110, loss_fp: 0.005506, loss_freq: 0.013510
[15:29:55.992] iteration 5517: loss: 0.111508, loss_s1: 0.066223, loss_fp: 0.001240, loss_freq: 0.054390
[15:29:56.624] iteration 5518: loss: 0.061715, loss_s1: 0.023598, loss_fp: 0.001528, loss_freq: 0.019770
[15:29:57.248] iteration 5519: loss: 0.153399, loss_s1: 0.133067, loss_fp: 0.005234, loss_freq: 0.077089
[15:29:57.881] iteration 5520: loss: 0.070354, loss_s1: 0.037670, loss_fp: 0.002699, loss_freq: 0.023230
[15:29:58.511] iteration 5521: loss: 0.068213, loss_s1: 0.031975, loss_fp: 0.000783, loss_freq: 0.004953
[15:29:59.138] iteration 5522: loss: 0.078746, loss_s1: 0.027496, loss_fp: 0.005587, loss_freq: 0.024809
[15:29:59.805] iteration 5523: loss: 0.123134, loss_s1: 0.075953, loss_fp: 0.000411, loss_freq: 0.020893
[15:30:00.433] iteration 5524: loss: 0.111128, loss_s1: 0.046938, loss_fp: 0.005921, loss_freq: 0.053932
[15:30:01.061] iteration 5525: loss: 0.086636, loss_s1: 0.048730, loss_fp: 0.000467, loss_freq: 0.053013
[15:30:01.679] iteration 5526: loss: 0.174647, loss_s1: 0.021583, loss_fp: 0.000918, loss_freq: 0.011752
[15:30:02.306] iteration 5527: loss: 0.124957, loss_s1: 0.082895, loss_fp: 0.001716, loss_freq: 0.056961
[15:30:02.940] iteration 5528: loss: 0.115013, loss_s1: 0.041114, loss_fp: 0.002526, loss_freq: 0.046381
[15:30:03.566] iteration 5529: loss: 0.154807, loss_s1: 0.062796, loss_fp: 0.008603, loss_freq: 0.039110
[15:30:04.200] iteration 5530: loss: 0.159685, loss_s1: 0.183193, loss_fp: 0.004084, loss_freq: 0.023586
[15:30:04.823] iteration 5531: loss: 0.095166, loss_s1: 0.044642, loss_fp: 0.001381, loss_freq: 0.015520
[15:30:05.454] iteration 5532: loss: 0.103855, loss_s1: 0.024347, loss_fp: 0.001046, loss_freq: 0.032868
[15:30:06.075] iteration 5533: loss: 0.078257, loss_s1: 0.041446, loss_fp: 0.005085, loss_freq: 0.020440
[15:30:06.700] iteration 5534: loss: 0.085088, loss_s1: 0.062568, loss_fp: 0.000982, loss_freq: 0.021112
[15:30:07.325] iteration 5535: loss: 0.084237, loss_s1: 0.048488, loss_fp: 0.000549, loss_freq: 0.030736
[15:30:07.949] iteration 5536: loss: 0.104141, loss_s1: 0.112526, loss_fp: 0.003837, loss_freq: 0.012244
[15:30:08.574] iteration 5537: loss: 0.095538, loss_s1: 0.047796, loss_fp: 0.003202, loss_freq: 0.019784
[15:30:09.205] iteration 5538: loss: 0.136180, loss_s1: 0.029629, loss_fp: 0.001697, loss_freq: 0.032812
[15:30:09.838] iteration 5539: loss: 0.082356, loss_s1: 0.068001, loss_fp: 0.001069, loss_freq: 0.006978
[15:30:10.473] iteration 5540: loss: 0.102277, loss_s1: 0.042449, loss_fp: 0.004772, loss_freq: 0.049260
[15:30:11.110] iteration 5541: loss: 0.114259, loss_s1: 0.046187, loss_fp: 0.002100, loss_freq: 0.036556
[15:30:11.744] iteration 5542: loss: 0.101049, loss_s1: 0.067216, loss_fp: 0.003165, loss_freq: 0.041358
[15:30:12.364] iteration 5543: loss: 0.085384, loss_s1: 0.066300, loss_fp: 0.000792, loss_freq: 0.022906
[15:30:12.994] iteration 5544: loss: 0.151600, loss_s1: 0.037223, loss_fp: 0.000656, loss_freq: 0.026543
[15:30:13.623] iteration 5545: loss: 0.109445, loss_s1: 0.058049, loss_fp: 0.006726, loss_freq: 0.061856
[15:30:14.248] iteration 5546: loss: 0.155733, loss_s1: 0.112074, loss_fp: 0.004258, loss_freq: 0.046567
[15:30:14.889] iteration 5547: loss: 0.121936, loss_s1: 0.072755, loss_fp: 0.001811, loss_freq: 0.058112
[15:30:15.521] iteration 5548: loss: 0.093702, loss_s1: 0.053762, loss_fp: 0.001425, loss_freq: 0.035238
[15:30:16.147] iteration 5549: loss: 0.140730, loss_s1: 0.061457, loss_fp: 0.000811, loss_freq: 0.070892
[15:30:16.773] iteration 5550: loss: 0.138603, loss_s1: 0.075479, loss_fp: 0.000457, loss_freq: 0.033602
[15:30:17.396] iteration 5551: loss: 0.112362, loss_s1: 0.065977, loss_fp: 0.001214, loss_freq: 0.084655
[15:30:18.023] iteration 5552: loss: 0.088845, loss_s1: 0.066416, loss_fp: 0.002356, loss_freq: 0.024576
[15:30:18.654] iteration 5553: loss: 0.082762, loss_s1: 0.038264, loss_fp: 0.000878, loss_freq: 0.013539
[15:30:19.273] iteration 5554: loss: 0.094908, loss_s1: 0.080384, loss_fp: 0.007266, loss_freq: 0.014130
[15:30:19.907] iteration 5555: loss: 0.103097, loss_s1: 0.050631, loss_fp: 0.002048, loss_freq: 0.041566
[15:30:20.535] iteration 5556: loss: 0.073255, loss_s1: 0.036482, loss_fp: 0.003039, loss_freq: 0.026482
[15:30:21.156] iteration 5557: loss: 0.173887, loss_s1: 0.129218, loss_fp: 0.004847, loss_freq: 0.116629
[15:30:21.782] iteration 5558: loss: 0.112988, loss_s1: 0.041651, loss_fp: 0.008160, loss_freq: 0.040078
[15:30:22.405] iteration 5559: loss: 0.141159, loss_s1: 0.077172, loss_fp: 0.008712, loss_freq: 0.115756
[15:30:23.029] iteration 5560: loss: 0.070109, loss_s1: 0.030665, loss_fp: 0.002396, loss_freq: 0.033700
[15:30:23.689] iteration 5561: loss: 0.132450, loss_s1: 0.063358, loss_fp: 0.001792, loss_freq: 0.059166
[15:30:24.309] iteration 5562: loss: 0.072894, loss_s1: 0.052995, loss_fp: 0.003571, loss_freq: 0.010055
[15:30:24.930] iteration 5563: loss: 0.110995, loss_s1: 0.119625, loss_fp: 0.005995, loss_freq: 0.015646
[15:30:25.589] iteration 5564: loss: 0.122781, loss_s1: 0.096019, loss_fp: 0.005531, loss_freq: 0.019777
[15:30:26.254] iteration 5565: loss: 0.094447, loss_s1: 0.046158, loss_fp: 0.000801, loss_freq: 0.036905
[15:30:26.918] iteration 5566: loss: 0.132172, loss_s1: 0.087336, loss_fp: 0.003045, loss_freq: 0.017639
[15:30:27.578] iteration 5567: loss: 0.125227, loss_s1: 0.024009, loss_fp: 0.000679, loss_freq: 0.016666
[15:30:28.242] iteration 5568: loss: 0.113113, loss_s1: 0.033262, loss_fp: 0.001016, loss_freq: 0.044269
[15:30:28.912] iteration 5569: loss: 0.079689, loss_s1: 0.054284, loss_fp: 0.000712, loss_freq: 0.015103
[15:30:29.570] iteration 5570: loss: 0.072854, loss_s1: 0.062076, loss_fp: 0.001576, loss_freq: 0.017881
[15:30:30.195] iteration 5571: loss: 0.126562, loss_s1: 0.102600, loss_fp: 0.001049, loss_freq: 0.039661
[15:30:30.814] iteration 5572: loss: 0.084109, loss_s1: 0.025660, loss_fp: 0.000369, loss_freq: 0.029593
[15:30:31.437] iteration 5573: loss: 0.138584, loss_s1: 0.131302, loss_fp: 0.000954, loss_freq: 0.021095
[15:30:32.054] iteration 5574: loss: 0.093124, loss_s1: 0.104873, loss_fp: 0.000928, loss_freq: 0.015088
[15:30:32.680] iteration 5575: loss: 0.102489, loss_s1: 0.065002, loss_fp: 0.008153, loss_freq: 0.022331
[15:30:33.296] iteration 5576: loss: 0.096136, loss_s1: 0.034985, loss_fp: 0.002324, loss_freq: 0.027796
[15:30:33.918] iteration 5577: loss: 0.141574, loss_s1: 0.051420, loss_fp: 0.006165, loss_freq: 0.069010
[15:30:34.585] iteration 5578: loss: 0.134725, loss_s1: 0.070165, loss_fp: 0.004890, loss_freq: 0.127374
[15:30:35.488] iteration 5579: loss: 0.197946, loss_s1: 0.071584, loss_fp: 0.004784, loss_freq: 0.046848
[15:30:36.247] iteration 5580: loss: 0.087821, loss_s1: 0.053152, loss_fp: 0.002361, loss_freq: 0.027075
[15:30:36.932] iteration 5581: loss: 0.094952, loss_s1: 0.044063, loss_fp: 0.001053, loss_freq: 0.018171
[15:30:37.552] iteration 5582: loss: 0.155197, loss_s1: 0.111236, loss_fp: 0.009238, loss_freq: 0.098265
[15:30:38.169] iteration 5583: loss: 0.258663, loss_s1: 0.227701, loss_fp: 0.001478, loss_freq: 0.207067
[15:30:38.784] iteration 5584: loss: 0.113352, loss_s1: 0.071508, loss_fp: 0.001860, loss_freq: 0.056803
[15:30:39.397] iteration 5585: loss: 0.139276, loss_s1: 0.029205, loss_fp: 0.004591, loss_freq: 0.025556
[15:30:40.017] iteration 5586: loss: 0.062618, loss_s1: 0.025663, loss_fp: 0.003084, loss_freq: 0.036652
[15:30:40.637] iteration 5587: loss: 0.111111, loss_s1: 0.040919, loss_fp: 0.005869, loss_freq: 0.057652
[15:30:41.254] iteration 5588: loss: 0.099767, loss_s1: 0.057099, loss_fp: 0.004414, loss_freq: 0.070924
[15:30:41.877] iteration 5589: loss: 0.085014, loss_s1: 0.014860, loss_fp: 0.001629, loss_freq: 0.006409
[15:30:42.498] iteration 5590: loss: 0.118873, loss_s1: 0.054716, loss_fp: 0.006832, loss_freq: 0.075775
[15:30:43.116] iteration 5591: loss: 0.135242, loss_s1: 0.034141, loss_fp: 0.006175, loss_freq: 0.061307
[15:30:43.743] iteration 5592: loss: 0.055535, loss_s1: 0.039223, loss_fp: 0.002002, loss_freq: 0.021796
[15:30:44.370] iteration 5593: loss: 0.103766, loss_s1: 0.025125, loss_fp: 0.004824, loss_freq: 0.014265
[15:30:44.996] iteration 5594: loss: 0.193376, loss_s1: 0.148857, loss_fp: 0.002919, loss_freq: 0.136665
[15:30:45.623] iteration 5595: loss: 0.095949, loss_s1: 0.059723, loss_fp: 0.001995, loss_freq: 0.050846
[15:30:46.250] iteration 5596: loss: 0.103804, loss_s1: 0.033982, loss_fp: 0.001670, loss_freq: 0.008718
[15:30:46.881] iteration 5597: loss: 0.136756, loss_s1: 0.101983, loss_fp: 0.009969, loss_freq: 0.041922
[15:30:47.510] iteration 5598: loss: 0.108168, loss_s1: 0.041773, loss_fp: 0.017499, loss_freq: 0.017492
[15:30:48.130] iteration 5599: loss: 0.095919, loss_s1: 0.026582, loss_fp: 0.001080, loss_freq: 0.029252
[15:30:48.751] iteration 5600: loss: 0.144836, loss_s1: 0.015395, loss_fp: 0.001428, loss_freq: 0.020864
[15:30:51.875] iteration 5600 : mean_dice : 0.637626
[15:30:52.526] iteration 5601: loss: 0.113732, loss_s1: 0.044379, loss_fp: 0.002880, loss_freq: 0.020836
[15:30:53.149] iteration 5602: loss: 0.208193, loss_s1: 0.077583, loss_fp: 0.001882, loss_freq: 0.071715
[15:30:53.767] iteration 5603: loss: 0.087095, loss_s1: 0.054735, loss_fp: 0.002847, loss_freq: 0.016214
[15:30:54.394] iteration 5604: loss: 0.093515, loss_s1: 0.065193, loss_fp: 0.003988, loss_freq: 0.011818
[15:30:55.012] iteration 5605: loss: 0.085662, loss_s1: 0.033622, loss_fp: 0.001746, loss_freq: 0.056097
[15:30:55.633] iteration 5606: loss: 0.165973, loss_s1: 0.106401, loss_fp: 0.002650, loss_freq: 0.102157
[15:30:56.251] iteration 5607: loss: 0.126484, loss_s1: 0.056260, loss_fp: 0.006285, loss_freq: 0.028787
[15:30:56.872] iteration 5608: loss: 0.108522, loss_s1: 0.053659, loss_fp: 0.001358, loss_freq: 0.055789
[15:30:57.492] iteration 5609: loss: 0.086840, loss_s1: 0.040563, loss_fp: 0.000825, loss_freq: 0.042238
[15:30:58.107] iteration 5610: loss: 0.089017, loss_s1: 0.055558, loss_fp: 0.003847, loss_freq: 0.015536
[15:30:58.727] iteration 5611: loss: 0.117601, loss_s1: 0.023383, loss_fp: 0.000455, loss_freq: 0.057771
[15:30:59.347] iteration 5612: loss: 0.101102, loss_s1: 0.079610, loss_fp: 0.002719, loss_freq: 0.021802
[15:30:59.968] iteration 5613: loss: 0.128449, loss_s1: 0.030829, loss_fp: 0.000558, loss_freq: 0.025425
[15:31:00.593] iteration 5614: loss: 0.162802, loss_s1: 0.082110, loss_fp: 0.002441, loss_freq: 0.060472
[15:31:01.216] iteration 5615: loss: 0.109973, loss_s1: 0.053472, loss_fp: 0.003549, loss_freq: 0.058932
[15:31:01.839] iteration 5616: loss: 0.096741, loss_s1: 0.045205, loss_fp: 0.000760, loss_freq: 0.027849
[15:31:02.476] iteration 5617: loss: 0.112591, loss_s1: 0.076916, loss_fp: 0.009285, loss_freq: 0.039341
[15:31:03.116] iteration 5618: loss: 0.129435, loss_s1: 0.077036, loss_fp: 0.001187, loss_freq: 0.025360
[15:31:03.739] iteration 5619: loss: 0.076537, loss_s1: 0.030184, loss_fp: 0.002744, loss_freq: 0.021425
[15:31:04.398] iteration 5620: loss: 0.098939, loss_s1: 0.053672, loss_fp: 0.001105, loss_freq: 0.015161
[15:31:05.053] iteration 5621: loss: 0.092132, loss_s1: 0.093299, loss_fp: 0.001079, loss_freq: 0.027168
[15:31:05.708] iteration 5622: loss: 0.077827, loss_s1: 0.059209, loss_fp: 0.001484, loss_freq: 0.018757
[15:31:06.327] iteration 5623: loss: 0.086525, loss_s1: 0.067798, loss_fp: 0.001404, loss_freq: 0.019223
[15:31:06.950] iteration 5624: loss: 0.104067, loss_s1: 0.044615, loss_fp: 0.000564, loss_freq: 0.069721
[15:31:07.583] iteration 5625: loss: 0.113372, loss_s1: 0.032242, loss_fp: 0.000954, loss_freq: 0.077423
[15:31:08.208] iteration 5626: loss: 0.114958, loss_s1: 0.109026, loss_fp: 0.004439, loss_freq: 0.024869
[15:31:08.834] iteration 5627: loss: 0.085730, loss_s1: 0.058824, loss_fp: 0.004939, loss_freq: 0.013923
[15:31:09.454] iteration 5628: loss: 0.132625, loss_s1: 0.075149, loss_fp: 0.001984, loss_freq: 0.009255
[15:31:10.076] iteration 5629: loss: 0.079286, loss_s1: 0.029968, loss_fp: 0.002545, loss_freq: 0.013022
[15:31:10.696] iteration 5630: loss: 0.078668, loss_s1: 0.063444, loss_fp: 0.000473, loss_freq: 0.019269
[15:31:11.343] iteration 5631: loss: 0.122027, loss_s1: 0.103884, loss_fp: 0.000589, loss_freq: 0.004978
[15:31:12.007] iteration 5632: loss: 0.139443, loss_s1: 0.069174, loss_fp: 0.001285, loss_freq: 0.109575
[15:31:12.664] iteration 5633: loss: 0.165034, loss_s1: 0.059737, loss_fp: 0.006888, loss_freq: 0.030075
[15:31:13.316] iteration 5634: loss: 0.092308, loss_s1: 0.058125, loss_fp: 0.000430, loss_freq: 0.026336
[15:31:13.971] iteration 5635: loss: 0.103667, loss_s1: 0.040865, loss_fp: 0.002175, loss_freq: 0.042141
[15:31:15.041] iteration 5636: loss: 0.079188, loss_s1: 0.042521, loss_fp: 0.001072, loss_freq: 0.017079
[15:31:15.702] iteration 5637: loss: 0.110701, loss_s1: 0.064620, loss_fp: 0.002878, loss_freq: 0.053255
[15:31:16.359] iteration 5638: loss: 0.114489, loss_s1: 0.060899, loss_fp: 0.001711, loss_freq: 0.048785
[15:31:17.017] iteration 5639: loss: 0.067870, loss_s1: 0.030501, loss_fp: 0.002587, loss_freq: 0.026232
[15:31:17.668] iteration 5640: loss: 0.113636, loss_s1: 0.046542, loss_fp: 0.001162, loss_freq: 0.011681
[15:31:18.327] iteration 5641: loss: 0.166881, loss_s1: 0.068523, loss_fp: 0.002706, loss_freq: 0.137242
[15:31:18.960] iteration 5642: loss: 0.067251, loss_s1: 0.039517, loss_fp: 0.006418, loss_freq: 0.036842
[15:31:19.572] iteration 5643: loss: 0.110252, loss_s1: 0.088723, loss_fp: 0.001003, loss_freq: 0.072203
[15:31:20.199] iteration 5644: loss: 0.106108, loss_s1: 0.074426, loss_fp: 0.007300, loss_freq: 0.012917
[15:31:20.820] iteration 5645: loss: 0.132014, loss_s1: 0.086638, loss_fp: 0.017728, loss_freq: 0.073360
[15:31:21.438] iteration 5646: loss: 0.115364, loss_s1: 0.054751, loss_fp: 0.005100, loss_freq: 0.029201
[15:31:22.055] iteration 5647: loss: 0.112597, loss_s1: 0.035751, loss_fp: 0.009046, loss_freq: 0.055964
[15:31:22.681] iteration 5648: loss: 0.092146, loss_s1: 0.072317, loss_fp: 0.011588, loss_freq: 0.040926
[15:31:23.314] iteration 5649: loss: 0.171115, loss_s1: 0.111286, loss_fp: 0.003580, loss_freq: 0.059664
[15:31:23.932] iteration 5650: loss: 0.072663, loss_s1: 0.029629, loss_fp: 0.002430, loss_freq: 0.011606
[15:31:24.566] iteration 5651: loss: 0.114075, loss_s1: 0.067594, loss_fp: 0.001269, loss_freq: 0.036863
[15:31:25.195] iteration 5652: loss: 0.092964, loss_s1: 0.025910, loss_fp: 0.003638, loss_freq: 0.012130
[15:31:25.826] iteration 5653: loss: 0.117104, loss_s1: 0.054142, loss_fp: 0.001420, loss_freq: 0.033125
[15:31:26.454] iteration 5654: loss: 0.096748, loss_s1: 0.040758, loss_fp: 0.002735, loss_freq: 0.020115
[15:31:27.076] iteration 5655: loss: 0.096768, loss_s1: 0.028606, loss_fp: 0.029495, loss_freq: 0.033595
[15:31:27.703] iteration 5656: loss: 0.068988, loss_s1: 0.041153, loss_fp: 0.001555, loss_freq: 0.005681
[15:31:28.330] iteration 5657: loss: 0.069806, loss_s1: 0.033689, loss_fp: 0.000928, loss_freq: 0.023875
[15:31:28.954] iteration 5658: loss: 0.151539, loss_s1: 0.041123, loss_fp: 0.000627, loss_freq: 0.056466
[15:31:29.580] iteration 5659: loss: 0.208224, loss_s1: 0.157633, loss_fp: 0.007403, loss_freq: 0.188367
[15:31:30.203] iteration 5660: loss: 0.056075, loss_s1: 0.025088, loss_fp: 0.003523, loss_freq: 0.025481
[15:31:30.832] iteration 5661: loss: 0.079534, loss_s1: 0.048338, loss_fp: 0.001729, loss_freq: 0.038411
[15:31:31.456] iteration 5662: loss: 0.082886, loss_s1: 0.045999, loss_fp: 0.002038, loss_freq: 0.034536
[15:31:32.076] iteration 5663: loss: 0.169971, loss_s1: 0.111738, loss_fp: 0.003199, loss_freq: 0.053195
[15:31:32.702] iteration 5664: loss: 0.077097, loss_s1: 0.047363, loss_fp: 0.002757, loss_freq: 0.025806
[15:31:33.323] iteration 5665: loss: 0.084543, loss_s1: 0.047092, loss_fp: 0.001362, loss_freq: 0.016649
[15:31:33.948] iteration 5666: loss: 0.068330, loss_s1: 0.049150, loss_fp: 0.000724, loss_freq: 0.006720
[15:31:34.571] iteration 5667: loss: 0.124569, loss_s1: 0.027233, loss_fp: 0.004165, loss_freq: 0.031399
[15:31:35.195] iteration 5668: loss: 0.093736, loss_s1: 0.084964, loss_fp: 0.000614, loss_freq: 0.019791
[15:31:35.845] iteration 5669: loss: 0.065477, loss_s1: 0.051382, loss_fp: 0.001611, loss_freq: 0.020896
[15:31:36.499] iteration 5670: loss: 0.112953, loss_s1: 0.049226, loss_fp: 0.005007, loss_freq: 0.009969
[15:31:37.150] iteration 5671: loss: 0.109230, loss_s1: 0.083173, loss_fp: 0.004853, loss_freq: 0.031127
[15:31:37.783] iteration 5672: loss: 0.110285, loss_s1: 0.058252, loss_fp: 0.001750, loss_freq: 0.053872
[15:31:38.401] iteration 5673: loss: 0.090017, loss_s1: 0.067461, loss_fp: 0.004667, loss_freq: 0.027484
[15:31:39.022] iteration 5674: loss: 0.125055, loss_s1: 0.074000, loss_fp: 0.000596, loss_freq: 0.065810
[15:31:39.652] iteration 5675: loss: 0.137986, loss_s1: 0.080898, loss_fp: 0.003374, loss_freq: 0.038394
[15:31:40.273] iteration 5676: loss: 0.098659, loss_s1: 0.044270, loss_fp: 0.001909, loss_freq: 0.029670
[15:31:40.937] iteration 5677: loss: 0.103598, loss_s1: 0.081701, loss_fp: 0.010425, loss_freq: 0.055771
[15:31:41.602] iteration 5678: loss: 0.091232, loss_s1: 0.031618, loss_fp: 0.002570, loss_freq: 0.070992
[15:31:42.260] iteration 5679: loss: 0.099086, loss_s1: 0.068528, loss_fp: 0.003633, loss_freq: 0.035714
[15:31:42.884] iteration 5680: loss: 0.137035, loss_s1: 0.080372, loss_fp: 0.000951, loss_freq: 0.093127
[15:31:43.558] iteration 5681: loss: 0.081582, loss_s1: 0.029968, loss_fp: 0.000504, loss_freq: 0.030415
[15:31:44.235] iteration 5682: loss: 0.111319, loss_s1: 0.052096, loss_fp: 0.000969, loss_freq: 0.019112
[15:31:44.849] iteration 5683: loss: 0.060360, loss_s1: 0.045279, loss_fp: 0.000708, loss_freq: 0.024029
[15:31:45.467] iteration 5684: loss: 0.103783, loss_s1: 0.059495, loss_fp: 0.003756, loss_freq: 0.028190
[15:31:46.093] iteration 5685: loss: 0.115779, loss_s1: 0.136393, loss_fp: 0.002470, loss_freq: 0.022716
[15:31:46.710] iteration 5686: loss: 0.076291, loss_s1: 0.070026, loss_fp: 0.004013, loss_freq: 0.022508
[15:31:47.328] iteration 5687: loss: 0.110482, loss_s1: 0.037567, loss_fp: 0.000958, loss_freq: 0.021490
[15:31:47.947] iteration 5688: loss: 0.135205, loss_s1: 0.112310, loss_fp: 0.002699, loss_freq: 0.073281
[15:31:48.571] iteration 5689: loss: 0.218325, loss_s1: 0.208153, loss_fp: 0.002221, loss_freq: 0.040152
[15:31:49.191] iteration 5690: loss: 0.118390, loss_s1: 0.028574, loss_fp: 0.002754, loss_freq: 0.070403
[15:31:49.850] iteration 5691: loss: 0.098771, loss_s1: 0.068296, loss_fp: 0.001626, loss_freq: 0.040552
[15:31:50.508] iteration 5692: loss: 0.078043, loss_s1: 0.025248, loss_fp: 0.001641, loss_freq: 0.013536
[15:31:51.161] iteration 5693: loss: 0.141566, loss_s1: 0.071255, loss_fp: 0.004178, loss_freq: 0.039131
[15:31:51.817] iteration 5694: loss: 0.065913, loss_s1: 0.045086, loss_fp: 0.005504, loss_freq: 0.010020
[15:31:52.476] iteration 5695: loss: 0.080329, loss_s1: 0.063235, loss_fp: 0.003102, loss_freq: 0.024217
[15:31:53.117] iteration 5696: loss: 0.064256, loss_s1: 0.023695, loss_fp: 0.003001, loss_freq: 0.024700
[15:31:53.738] iteration 5697: loss: 0.082990, loss_s1: 0.045468, loss_fp: 0.002107, loss_freq: 0.049233
[15:31:54.349] iteration 5698: loss: 0.114499, loss_s1: 0.091652, loss_fp: 0.002300, loss_freq: 0.038381
[15:31:54.968] iteration 5699: loss: 0.108309, loss_s1: 0.031647, loss_fp: 0.000543, loss_freq: 0.054591
[15:31:55.591] iteration 5700: loss: 0.081401, loss_s1: 0.066448, loss_fp: 0.005724, loss_freq: 0.008826
[15:31:56.220] iteration 5701: loss: 0.091535, loss_s1: 0.019848, loss_fp: 0.005569, loss_freq: 0.064974
[15:31:56.844] iteration 5702: loss: 0.123468, loss_s1: 0.052844, loss_fp: 0.008061, loss_freq: 0.054465
[15:31:57.465] iteration 5703: loss: 0.088869, loss_s1: 0.067564, loss_fp: 0.002224, loss_freq: 0.047928
[15:31:58.074] iteration 5704: loss: 0.072972, loss_s1: 0.027325, loss_fp: 0.000540, loss_freq: 0.021242
[15:31:58.704] iteration 5705: loss: 0.163729, loss_s1: 0.101976, loss_fp: 0.001311, loss_freq: 0.066444
[15:31:59.330] iteration 5706: loss: 0.121131, loss_s1: 0.045090, loss_fp: 0.003983, loss_freq: 0.041565
[15:31:59.952] iteration 5707: loss: 0.151019, loss_s1: 0.082392, loss_fp: 0.003719, loss_freq: 0.069640
[15:32:00.572] iteration 5708: loss: 0.113734, loss_s1: 0.049073, loss_fp: 0.002159, loss_freq: 0.065978
[15:32:01.197] iteration 5709: loss: 0.140698, loss_s1: 0.091134, loss_fp: 0.001580, loss_freq: 0.025319
[15:32:01.818] iteration 5710: loss: 0.098861, loss_s1: 0.072837, loss_fp: 0.003009, loss_freq: 0.050379
[15:32:02.440] iteration 5711: loss: 0.131071, loss_s1: 0.075809, loss_fp: 0.001353, loss_freq: 0.077476
[15:32:03.103] iteration 5712: loss: 0.103585, loss_s1: 0.043465, loss_fp: 0.001452, loss_freq: 0.062003
[15:32:03.771] iteration 5713: loss: 0.109452, loss_s1: 0.049403, loss_fp: 0.004098, loss_freq: 0.045174
[15:32:04.437] iteration 5714: loss: 0.069894, loss_s1: 0.048589, loss_fp: 0.005890, loss_freq: 0.014926
[15:32:05.067] iteration 5715: loss: 0.099068, loss_s1: 0.112280, loss_fp: 0.001668, loss_freq: 0.013212
[15:32:05.685] iteration 5716: loss: 0.111080, loss_s1: 0.049075, loss_fp: 0.001172, loss_freq: 0.062188
[15:32:06.305] iteration 5717: loss: 0.099839, loss_s1: 0.097646, loss_fp: 0.005706, loss_freq: 0.021517
[15:32:06.939] iteration 5718: loss: 0.210063, loss_s1: 0.222266, loss_fp: 0.008595, loss_freq: 0.120991
[15:32:07.574] iteration 5719: loss: 0.142713, loss_s1: 0.107288, loss_fp: 0.002965, loss_freq: 0.072937
[15:32:08.197] iteration 5720: loss: 0.164119, loss_s1: 0.109718, loss_fp: 0.006419, loss_freq: 0.103127
[15:32:08.817] iteration 5721: loss: 0.079759, loss_s1: 0.053525, loss_fp: 0.001221, loss_freq: 0.031920
[15:32:09.444] iteration 5722: loss: 0.124286, loss_s1: 0.086963, loss_fp: 0.001564, loss_freq: 0.047677
[15:32:10.108] iteration 5723: loss: 0.088523, loss_s1: 0.055579, loss_fp: 0.000735, loss_freq: 0.009988
[15:32:10.761] iteration 5724: loss: 0.109822, loss_s1: 0.059040, loss_fp: 0.004621, loss_freq: 0.054890
[15:32:11.423] iteration 5725: loss: 0.123363, loss_s1: 0.092336, loss_fp: 0.004865, loss_freq: 0.016311
[15:32:12.071] iteration 5726: loss: 0.136636, loss_s1: 0.052068, loss_fp: 0.008958, loss_freq: 0.043457
[15:32:12.734] iteration 5727: loss: 0.096297, loss_s1: 0.059777, loss_fp: 0.002374, loss_freq: 0.012604
[15:32:13.398] iteration 5728: loss: 0.134506, loss_s1: 0.046852, loss_fp: 0.000890, loss_freq: 0.016187
[15:32:14.068] iteration 5729: loss: 0.136285, loss_s1: 0.050912, loss_fp: 0.000851, loss_freq: 0.035028
[15:32:14.731] iteration 5730: loss: 0.074260, loss_s1: 0.031098, loss_fp: 0.000708, loss_freq: 0.038683
[15:32:15.367] iteration 5731: loss: 0.093660, loss_s1: 0.046185, loss_fp: 0.003939, loss_freq: 0.051850
[15:32:15.996] iteration 5732: loss: 0.091797, loss_s1: 0.044685, loss_fp: 0.002429, loss_freq: 0.033585
[15:32:16.625] iteration 5733: loss: 0.067752, loss_s1: 0.013068, loss_fp: 0.001330, loss_freq: 0.011702
[15:32:17.245] iteration 5734: loss: 0.092925, loss_s1: 0.049527, loss_fp: 0.001654, loss_freq: 0.015160
[15:32:17.905] iteration 5735: loss: 0.093360, loss_s1: 0.081761, loss_fp: 0.001921, loss_freq: 0.012638
[15:32:18.564] iteration 5736: loss: 0.115339, loss_s1: 0.098101, loss_fp: 0.005507, loss_freq: 0.022309
[15:32:19.219] iteration 5737: loss: 0.154176, loss_s1: 0.071129, loss_fp: 0.003754, loss_freq: 0.052891
[15:32:19.892] iteration 5738: loss: 0.199287, loss_s1: 0.083193, loss_fp: 0.002853, loss_freq: 0.092844
[15:32:20.519] iteration 5739: loss: 0.177617, loss_s1: 0.127983, loss_fp: 0.010798, loss_freq: 0.087180
[15:32:21.142] iteration 5740: loss: 0.162083, loss_s1: 0.022105, loss_fp: 0.004047, loss_freq: 0.042328
[15:32:21.765] iteration 5741: loss: 0.084261, loss_s1: 0.032458, loss_fp: 0.001091, loss_freq: 0.032170
[15:32:22.384] iteration 5742: loss: 0.113460, loss_s1: 0.045113, loss_fp: 0.000759, loss_freq: 0.025942
[15:32:23.019] iteration 5743: loss: 0.166882, loss_s1: 0.115499, loss_fp: 0.005015, loss_freq: 0.081340
[15:32:23.643] iteration 5744: loss: 0.176086, loss_s1: 0.088559, loss_fp: 0.002069, loss_freq: 0.155814
[15:32:24.262] iteration 5745: loss: 0.133850, loss_s1: 0.054966, loss_fp: 0.003295, loss_freq: 0.044738
[15:32:24.884] iteration 5746: loss: 0.101251, loss_s1: 0.024969, loss_fp: 0.000681, loss_freq: 0.045111
[15:32:25.502] iteration 5747: loss: 0.070922, loss_s1: 0.045116, loss_fp: 0.005275, loss_freq: 0.029212
[15:32:26.126] iteration 5748: loss: 0.109657, loss_s1: 0.041887, loss_fp: 0.006969, loss_freq: 0.077388
[15:32:26.747] iteration 5749: loss: 0.112575, loss_s1: 0.074701, loss_fp: 0.002676, loss_freq: 0.070291
[15:32:27.378] iteration 5750: loss: 0.044760, loss_s1: 0.025497, loss_fp: 0.000365, loss_freq: 0.003220
[15:32:27.995] iteration 5751: loss: 0.143752, loss_s1: 0.060962, loss_fp: 0.002199, loss_freq: 0.036939
[15:32:28.649] iteration 5752: loss: 0.096444, loss_s1: 0.067055, loss_fp: 0.001630, loss_freq: 0.025100
[15:32:29.309] iteration 5753: loss: 0.089525, loss_s1: 0.049788, loss_fp: 0.005479, loss_freq: 0.051564
[15:32:29.967] iteration 5754: loss: 0.189055, loss_s1: 0.060483, loss_fp: 0.001293, loss_freq: 0.048198
[15:32:30.679] iteration 5755: loss: 0.101601, loss_s1: 0.048120, loss_fp: 0.000677, loss_freq: 0.054694
[15:32:31.349] iteration 5756: loss: 0.078765, loss_s1: 0.042108, loss_fp: 0.001738, loss_freq: 0.028183
[15:32:32.011] iteration 5757: loss: 0.111157, loss_s1: 0.033296, loss_fp: 0.000516, loss_freq: 0.013841
[15:32:32.681] iteration 5758: loss: 0.099230, loss_s1: 0.060961, loss_fp: 0.002720, loss_freq: 0.021442
[15:32:33.344] iteration 5759: loss: 0.091601, loss_s1: 0.060733, loss_fp: 0.001115, loss_freq: 0.014974
[15:32:34.003] iteration 5760: loss: 0.117238, loss_s1: 0.039430, loss_fp: 0.002311, loss_freq: 0.018813
[15:32:34.633] iteration 5761: loss: 0.138762, loss_s1: 0.030414, loss_fp: 0.002430, loss_freq: 0.035892
[15:32:35.248] iteration 5762: loss: 0.118636, loss_s1: 0.023407, loss_fp: 0.000519, loss_freq: 0.011279
[15:32:35.870] iteration 5763: loss: 0.169804, loss_s1: 0.050236, loss_fp: 0.005066, loss_freq: 0.032204
[15:32:36.500] iteration 5764: loss: 0.062133, loss_s1: 0.030072, loss_fp: 0.001208, loss_freq: 0.008472
[15:32:37.117] iteration 5765: loss: 0.075017, loss_s1: 0.039428, loss_fp: 0.002346, loss_freq: 0.011333
[15:32:37.738] iteration 5766: loss: 0.106059, loss_s1: 0.077913, loss_fp: 0.001638, loss_freq: 0.054157
[15:32:38.354] iteration 5767: loss: 0.153878, loss_s1: 0.048977, loss_fp: 0.005102, loss_freq: 0.073718
[15:32:38.977] iteration 5768: loss: 0.099002, loss_s1: 0.056605, loss_fp: 0.006430, loss_freq: 0.021425
[15:32:39.634] iteration 5769: loss: 0.112015, loss_s1: 0.055544, loss_fp: 0.013503, loss_freq: 0.050034
[15:32:40.272] iteration 5770: loss: 0.136592, loss_s1: 0.085383, loss_fp: 0.002595, loss_freq: 0.089717
[15:32:41.005] iteration 5771: loss: 0.102159, loss_s1: 0.097073, loss_fp: 0.001743, loss_freq: 0.022286
[15:32:41.793] iteration 5772: loss: 0.113035, loss_s1: 0.045017, loss_fp: 0.004765, loss_freq: 0.047122
[15:32:42.451] iteration 5773: loss: 0.087379, loss_s1: 0.045398, loss_fp: 0.000826, loss_freq: 0.017222
[15:32:43.110] iteration 5774: loss: 0.087054, loss_s1: 0.085249, loss_fp: 0.000765, loss_freq: 0.022474
[15:32:43.773] iteration 5775: loss: 0.149752, loss_s1: 0.070149, loss_fp: 0.010335, loss_freq: 0.047684
[15:32:44.431] iteration 5776: loss: 0.122885, loss_s1: 0.071058, loss_fp: 0.012684, loss_freq: 0.036313
[15:32:45.065] iteration 5777: loss: 0.112443, loss_s1: 0.040823, loss_fp: 0.003528, loss_freq: 0.017376
[15:32:45.688] iteration 5778: loss: 0.130538, loss_s1: 0.064748, loss_fp: 0.002961, loss_freq: 0.043350
[15:32:46.318] iteration 5779: loss: 0.104816, loss_s1: 0.103461, loss_fp: 0.006945, loss_freq: 0.009034
[15:32:46.943] iteration 5780: loss: 0.064497, loss_s1: 0.031816, loss_fp: 0.000622, loss_freq: 0.010774
[15:32:47.569] iteration 5781: loss: 0.104122, loss_s1: 0.048119, loss_fp: 0.002162, loss_freq: 0.034788
[15:32:48.192] iteration 5782: loss: 0.089394, loss_s1: 0.067462, loss_fp: 0.006016, loss_freq: 0.052767
[15:32:48.816] iteration 5783: loss: 0.101837, loss_s1: 0.053079, loss_fp: 0.004645, loss_freq: 0.043691
[15:32:49.439] iteration 5784: loss: 0.071240, loss_s1: 0.030733, loss_fp: 0.003012, loss_freq: 0.027276
[15:32:50.060] iteration 5785: loss: 0.097080, loss_s1: 0.092788, loss_fp: 0.003113, loss_freq: 0.022678
[15:32:50.678] iteration 5786: loss: 0.128303, loss_s1: 0.092949, loss_fp: 0.001841, loss_freq: 0.066775
[15:32:51.291] iteration 5787: loss: 0.154468, loss_s1: 0.143025, loss_fp: 0.003447, loss_freq: 0.089367
[15:32:51.916] iteration 5788: loss: 0.106608, loss_s1: 0.054940, loss_fp: 0.004645, loss_freq: 0.026411
[15:32:52.536] iteration 5789: loss: 0.126872, loss_s1: 0.019834, loss_fp: 0.002469, loss_freq: 0.016485
[15:32:53.154] iteration 5790: loss: 0.068354, loss_s1: 0.017181, loss_fp: 0.000969, loss_freq: 0.012102
[15:32:53.771] iteration 5791: loss: 0.093461, loss_s1: 0.068156, loss_fp: 0.003000, loss_freq: 0.028629
[15:32:54.395] iteration 5792: loss: 0.127076, loss_s1: 0.028637, loss_fp: 0.000658, loss_freq: 0.018545
[15:32:55.014] iteration 5793: loss: 0.097790, loss_s1: 0.042011, loss_fp: 0.000748, loss_freq: 0.057257
[15:32:55.640] iteration 5794: loss: 0.130539, loss_s1: 0.068481, loss_fp: 0.004675, loss_freq: 0.028629
[15:32:56.255] iteration 5795: loss: 0.127497, loss_s1: 0.080898, loss_fp: 0.000787, loss_freq: 0.019231
[15:32:56.873] iteration 5796: loss: 0.119006, loss_s1: 0.064815, loss_fp: 0.003730, loss_freq: 0.027048
[15:32:57.877] iteration 5797: loss: 0.084892, loss_s1: 0.048804, loss_fp: 0.000547, loss_freq: 0.018362
[15:32:58.531] iteration 5798: loss: 0.128472, loss_s1: 0.075899, loss_fp: 0.000619, loss_freq: 0.023235
[15:32:59.158] iteration 5799: loss: 0.103355, loss_s1: 0.041658, loss_fp: 0.001161, loss_freq: 0.046747
[15:32:59.797] iteration 5800: loss: 0.095939, loss_s1: 0.066336, loss_fp: 0.000499, loss_freq: 0.032141
[15:33:02.910] iteration 5800 : mean_dice : 0.623912
[15:33:03.607] iteration 5801: loss: 0.090154, loss_s1: 0.042316, loss_fp: 0.000967, loss_freq: 0.019124
[15:33:04.268] iteration 5802: loss: 0.168500, loss_s1: 0.092199, loss_fp: 0.009798, loss_freq: 0.072820
[15:33:04.925] iteration 5803: loss: 0.062241, loss_s1: 0.039804, loss_fp: 0.004286, loss_freq: 0.022666
[15:33:05.582] iteration 5804: loss: 0.107864, loss_s1: 0.062719, loss_fp: 0.000705, loss_freq: 0.060337
[15:33:06.242] iteration 5805: loss: 0.130291, loss_s1: 0.125824, loss_fp: 0.007689, loss_freq: 0.020389
[15:33:06.891] iteration 5806: loss: 0.092815, loss_s1: 0.072573, loss_fp: 0.002992, loss_freq: 0.044731
[15:33:07.517] iteration 5807: loss: 0.080775, loss_s1: 0.023608, loss_fp: 0.004104, loss_freq: 0.023575
[15:33:08.140] iteration 5808: loss: 0.086447, loss_s1: 0.027914, loss_fp: 0.003210, loss_freq: 0.040991
[15:33:08.760] iteration 5809: loss: 0.066823, loss_s1: 0.040351, loss_fp: 0.004482, loss_freq: 0.033337
[15:33:09.381] iteration 5810: loss: 0.125698, loss_s1: 0.089103, loss_fp: 0.000973, loss_freq: 0.036710
[15:33:10.005] iteration 5811: loss: 0.098723, loss_s1: 0.059141, loss_fp: 0.012663, loss_freq: 0.033125
[15:33:10.628] iteration 5812: loss: 0.099549, loss_s1: 0.055107, loss_fp: 0.004182, loss_freq: 0.067456
[15:33:11.251] iteration 5813: loss: 0.113245, loss_s1: 0.038730, loss_fp: 0.002724, loss_freq: 0.023133
[15:33:11.876] iteration 5814: loss: 0.104238, loss_s1: 0.088102, loss_fp: 0.002450, loss_freq: 0.020505
[15:33:12.496] iteration 5815: loss: 0.110297, loss_s1: 0.085643, loss_fp: 0.001082, loss_freq: 0.035279
[15:33:13.113] iteration 5816: loss: 0.107230, loss_s1: 0.047103, loss_fp: 0.006013, loss_freq: 0.015566
[15:33:13.733] iteration 5817: loss: 0.077551, loss_s1: 0.041810, loss_fp: 0.006514, loss_freq: 0.040099
[15:33:14.352] iteration 5818: loss: 0.089181, loss_s1: 0.051658, loss_fp: 0.006454, loss_freq: 0.028026
[15:33:15.012] iteration 5819: loss: 0.109467, loss_s1: 0.023666, loss_fp: 0.000549, loss_freq: 0.036615
[15:33:15.675] iteration 5820: loss: 0.161339, loss_s1: 0.129010, loss_fp: 0.002823, loss_freq: 0.114660
[15:33:16.331] iteration 5821: loss: 0.065764, loss_s1: 0.032986, loss_fp: 0.002614, loss_freq: 0.027770
[15:33:16.948] iteration 5822: loss: 0.120716, loss_s1: 0.083658, loss_fp: 0.001547, loss_freq: 0.064810
[15:33:17.574] iteration 5823: loss: 0.097204, loss_s1: 0.030305, loss_fp: 0.001682, loss_freq: 0.032952
[15:33:18.204] iteration 5824: loss: 0.123405, loss_s1: 0.068864, loss_fp: 0.002991, loss_freq: 0.037292
[15:33:18.833] iteration 5825: loss: 0.084924, loss_s1: 0.042207, loss_fp: 0.002025, loss_freq: 0.022204
[15:33:19.461] iteration 5826: loss: 0.048559, loss_s1: 0.018665, loss_fp: 0.002053, loss_freq: 0.007795
[15:33:20.087] iteration 5827: loss: 0.055234, loss_s1: 0.027747, loss_fp: 0.001130, loss_freq: 0.008742
[15:33:20.710] iteration 5828: loss: 0.094837, loss_s1: 0.053590, loss_fp: 0.003261, loss_freq: 0.028260
[15:33:21.328] iteration 5829: loss: 0.074553, loss_s1: 0.036723, loss_fp: 0.008586, loss_freq: 0.014705
[15:33:21.952] iteration 5830: loss: 0.076214, loss_s1: 0.074552, loss_fp: 0.004805, loss_freq: 0.012312
[15:33:22.582] iteration 5831: loss: 0.113971, loss_s1: 0.036556, loss_fp: 0.003700, loss_freq: 0.030893
[15:33:23.200] iteration 5832: loss: 0.084707, loss_s1: 0.033594, loss_fp: 0.009654, loss_freq: 0.048695
[15:33:23.833] iteration 5833: loss: 0.130575, loss_s1: 0.127021, loss_fp: 0.003400, loss_freq: 0.042916
[15:33:24.460] iteration 5834: loss: 0.136577, loss_s1: 0.127457, loss_fp: 0.006026, loss_freq: 0.029480
[15:33:25.086] iteration 5835: loss: 0.172410, loss_s1: 0.150932, loss_fp: 0.009639, loss_freq: 0.085184
[15:33:25.706] iteration 5836: loss: 0.135785, loss_s1: 0.047698, loss_fp: 0.002903, loss_freq: 0.036033
[15:33:26.326] iteration 5837: loss: 0.134372, loss_s1: 0.082046, loss_fp: 0.000775, loss_freq: 0.024257
[15:33:26.960] iteration 5838: loss: 0.096376, loss_s1: 0.070756, loss_fp: 0.006799, loss_freq: 0.050183
[15:33:27.583] iteration 5839: loss: 0.108402, loss_s1: 0.099225, loss_fp: 0.002288, loss_freq: 0.046856
[15:33:28.208] iteration 5840: loss: 0.066038, loss_s1: 0.034348, loss_fp: 0.002948, loss_freq: 0.031108
[15:33:28.907] iteration 5841: loss: 0.116613, loss_s1: 0.072910, loss_fp: 0.001301, loss_freq: 0.091343
[15:33:29.566] iteration 5842: loss: 0.084603, loss_s1: 0.060439, loss_fp: 0.000715, loss_freq: 0.008151
[15:33:30.185] iteration 5843: loss: 0.069819, loss_s1: 0.038654, loss_fp: 0.001282, loss_freq: 0.032210
[15:33:30.813] iteration 5844: loss: 0.087168, loss_s1: 0.051045, loss_fp: 0.006634, loss_freq: 0.015583
[15:33:31.433] iteration 5845: loss: 0.093933, loss_s1: 0.033276, loss_fp: 0.000771, loss_freq: 0.006587
[15:33:32.060] iteration 5846: loss: 0.095339, loss_s1: 0.076788, loss_fp: 0.001588, loss_freq: 0.037540
[15:33:32.680] iteration 5847: loss: 0.134504, loss_s1: 0.144990, loss_fp: 0.032998, loss_freq: 0.021346
[15:33:33.298] iteration 5848: loss: 0.148113, loss_s1: 0.029868, loss_fp: 0.000645, loss_freq: 0.020407
[15:33:33.925] iteration 5849: loss: 0.103819, loss_s1: 0.053080, loss_fp: 0.001964, loss_freq: 0.066193
[15:33:34.547] iteration 5850: loss: 0.106931, loss_s1: 0.032816, loss_fp: 0.002723, loss_freq: 0.040779
[15:33:35.167] iteration 5851: loss: 0.108883, loss_s1: 0.034900, loss_fp: 0.004144, loss_freq: 0.038064
[15:33:35.787] iteration 5852: loss: 0.126650, loss_s1: 0.123799, loss_fp: 0.000653, loss_freq: 0.033293
[15:33:36.471] iteration 5853: loss: 0.081997, loss_s1: 0.040451, loss_fp: 0.001796, loss_freq: 0.019144
[15:33:37.101] iteration 5854: loss: 0.143285, loss_s1: 0.033934, loss_fp: 0.009780, loss_freq: 0.107278
[15:33:37.720] iteration 5855: loss: 0.071247, loss_s1: 0.056298, loss_fp: 0.001080, loss_freq: 0.012344
[15:33:38.356] iteration 5856: loss: 0.095318, loss_s1: 0.067033, loss_fp: 0.005675, loss_freq: 0.013539
[15:33:38.986] iteration 5857: loss: 0.097009, loss_s1: 0.071587, loss_fp: 0.011661, loss_freq: 0.034072
[15:33:39.608] iteration 5858: loss: 0.055412, loss_s1: 0.023665, loss_fp: 0.003634, loss_freq: 0.013689
[15:33:40.225] iteration 5859: loss: 0.123723, loss_s1: 0.086195, loss_fp: 0.004504, loss_freq: 0.026876
[15:33:40.852] iteration 5860: loss: 0.090379, loss_s1: 0.009719, loss_fp: 0.009347, loss_freq: 0.018715
[15:33:41.473] iteration 5861: loss: 0.102918, loss_s1: 0.057474, loss_fp: 0.002344, loss_freq: 0.012170
[15:33:42.093] iteration 5862: loss: 0.085801, loss_s1: 0.044241, loss_fp: 0.003243, loss_freq: 0.021779
[15:33:42.717] iteration 5863: loss: 0.104994, loss_s1: 0.039202, loss_fp: 0.001123, loss_freq: 0.025919
[15:33:43.335] iteration 5864: loss: 0.084578, loss_s1: 0.054263, loss_fp: 0.001102, loss_freq: 0.022052
[15:33:43.966] iteration 5865: loss: 0.091942, loss_s1: 0.023435, loss_fp: 0.005209, loss_freq: 0.015688
[15:33:44.590] iteration 5866: loss: 0.168543, loss_s1: 0.079123, loss_fp: 0.001903, loss_freq: 0.021293
[15:33:45.228] iteration 5867: loss: 0.149993, loss_s1: 0.079583, loss_fp: 0.005131, loss_freq: 0.066516
[15:33:45.862] iteration 5868: loss: 0.109820, loss_s1: 0.055037, loss_fp: 0.005436, loss_freq: 0.046059
[15:33:46.500] iteration 5869: loss: 0.119721, loss_s1: 0.078023, loss_fp: 0.001260, loss_freq: 0.051183
[15:33:47.139] iteration 5870: loss: 0.052825, loss_s1: 0.009546, loss_fp: 0.000794, loss_freq: 0.014015
[15:33:47.776] iteration 5871: loss: 0.094973, loss_s1: 0.049819, loss_fp: 0.007351, loss_freq: 0.040418
[15:33:48.411] iteration 5872: loss: 0.152609, loss_s1: 0.050610, loss_fp: 0.002682, loss_freq: 0.056541
[15:33:49.052] iteration 5873: loss: 0.090980, loss_s1: 0.056455, loss_fp: 0.002548, loss_freq: 0.053099
[15:33:49.697] iteration 5874: loss: 0.076462, loss_s1: 0.037112, loss_fp: 0.002740, loss_freq: 0.045624
[15:33:50.337] iteration 5875: loss: 0.053335, loss_s1: 0.025244, loss_fp: 0.001142, loss_freq: 0.014813
[15:33:50.955] iteration 5876: loss: 0.095550, loss_s1: 0.062526, loss_fp: 0.000919, loss_freq: 0.064663
[15:33:51.577] iteration 5877: loss: 0.095904, loss_s1: 0.063685, loss_fp: 0.001074, loss_freq: 0.034667
[15:33:52.195] iteration 5878: loss: 0.141224, loss_s1: 0.124439, loss_fp: 0.002562, loss_freq: 0.031298
[15:33:52.813] iteration 5879: loss: 0.194892, loss_s1: 0.167331, loss_fp: 0.009886, loss_freq: 0.152873
[15:33:53.440] iteration 5880: loss: 0.090766, loss_s1: 0.051348, loss_fp: 0.008505, loss_freq: 0.023305
[15:33:54.059] iteration 5881: loss: 0.117223, loss_s1: 0.071838, loss_fp: 0.015139, loss_freq: 0.067233
[15:33:54.688] iteration 5882: loss: 0.052950, loss_s1: 0.028442, loss_fp: 0.001154, loss_freq: 0.022779
[15:33:55.329] iteration 5883: loss: 0.106719, loss_s1: 0.043404, loss_fp: 0.004235, loss_freq: 0.028355
[15:33:55.997] iteration 5884: loss: 0.111990, loss_s1: 0.122235, loss_fp: 0.000383, loss_freq: 0.010064
[15:33:56.645] iteration 5885: loss: 0.151753, loss_s1: 0.078601, loss_fp: 0.003750, loss_freq: 0.052415
[15:33:57.270] iteration 5886: loss: 0.119521, loss_s1: 0.042880, loss_fp: 0.008275, loss_freq: 0.013752
[15:33:57.892] iteration 5887: loss: 0.125582, loss_s1: 0.043959, loss_fp: 0.002092, loss_freq: 0.031428
[15:33:58.514] iteration 5888: loss: 0.099824, loss_s1: 0.075189, loss_fp: 0.001696, loss_freq: 0.011690
[15:33:59.130] iteration 5889: loss: 0.218848, loss_s1: 0.081044, loss_fp: 0.000968, loss_freq: 0.020829
[15:33:59.755] iteration 5890: loss: 0.058097, loss_s1: 0.014093, loss_fp: 0.000329, loss_freq: 0.026133
[15:34:00.378] iteration 5891: loss: 0.056142, loss_s1: 0.046050, loss_fp: 0.001349, loss_freq: 0.013822
[15:34:00.998] iteration 5892: loss: 0.062616, loss_s1: 0.028750, loss_fp: 0.002715, loss_freq: 0.029110
[15:34:01.621] iteration 5893: loss: 0.092724, loss_s1: 0.041965, loss_fp: 0.002191, loss_freq: 0.042174
[15:34:02.239] iteration 5894: loss: 0.091738, loss_s1: 0.025997, loss_fp: 0.001143, loss_freq: 0.038182
[15:34:02.867] iteration 5895: loss: 0.112527, loss_s1: 0.107367, loss_fp: 0.000837, loss_freq: 0.024723
[15:34:03.491] iteration 5896: loss: 0.121688, loss_s1: 0.109732, loss_fp: 0.003917, loss_freq: 0.065461
[15:34:04.114] iteration 5897: loss: 0.084973, loss_s1: 0.059125, loss_fp: 0.004652, loss_freq: 0.019600
[15:34:04.739] iteration 5898: loss: 0.103931, loss_s1: 0.026755, loss_fp: 0.005680, loss_freq: 0.047366
[15:34:05.360] iteration 5899: loss: 0.128121, loss_s1: 0.049161, loss_fp: 0.005442, loss_freq: 0.054383
[15:34:05.990] iteration 5900: loss: 0.132192, loss_s1: 0.063067, loss_fp: 0.013954, loss_freq: 0.076841
[15:34:06.613] iteration 5901: loss: 0.138653, loss_s1: 0.078471, loss_fp: 0.005500, loss_freq: 0.020327
[15:34:07.257] iteration 5902: loss: 0.081672, loss_s1: 0.025658, loss_fp: 0.002562, loss_freq: 0.034609
[15:34:07.894] iteration 5903: loss: 0.083848, loss_s1: 0.017170, loss_fp: 0.001918, loss_freq: 0.010351
[15:34:08.541] iteration 5904: loss: 0.210689, loss_s1: 0.176992, loss_fp: 0.002182, loss_freq: 0.102246
[15:34:09.176] iteration 5905: loss: 0.263347, loss_s1: 0.172417, loss_fp: 0.005163, loss_freq: 0.185722
[15:34:09.819] iteration 5906: loss: 0.101674, loss_s1: 0.050949, loss_fp: 0.002146, loss_freq: 0.028042
[15:34:10.463] iteration 5907: loss: 0.102183, loss_s1: 0.032498, loss_fp: 0.000434, loss_freq: 0.030519
[15:34:11.087] iteration 5908: loss: 0.074919, loss_s1: 0.019181, loss_fp: 0.004675, loss_freq: 0.065400
[15:34:11.719] iteration 5909: loss: 0.108169, loss_s1: 0.087880, loss_fp: 0.001685, loss_freq: 0.046648
[15:34:12.350] iteration 5910: loss: 0.123695, loss_s1: 0.111358, loss_fp: 0.001995, loss_freq: 0.065010
[15:34:12.989] iteration 5911: loss: 0.078412, loss_s1: 0.055294, loss_fp: 0.002344, loss_freq: 0.003947
[15:34:13.620] iteration 5912: loss: 0.115055, loss_s1: 0.085370, loss_fp: 0.001526, loss_freq: 0.035924
[15:34:14.247] iteration 5913: loss: 0.188541, loss_s1: 0.125301, loss_fp: 0.002232, loss_freq: 0.072200
[15:34:14.888] iteration 5914: loss: 0.088929, loss_s1: 0.039371, loss_fp: 0.001383, loss_freq: 0.013281
[15:34:15.525] iteration 5915: loss: 0.109965, loss_s1: 0.061165, loss_fp: 0.000993, loss_freq: 0.029044
[15:34:16.158] iteration 5916: loss: 0.191743, loss_s1: 0.146705, loss_fp: 0.003027, loss_freq: 0.107918
[15:34:16.797] iteration 5917: loss: 0.163435, loss_s1: 0.142271, loss_fp: 0.000325, loss_freq: 0.111449
[15:34:17.429] iteration 5918: loss: 0.130482, loss_s1: 0.069631, loss_fp: 0.002021, loss_freq: 0.023930
[15:34:18.064] iteration 5919: loss: 0.113939, loss_s1: 0.106715, loss_fp: 0.001383, loss_freq: 0.012284
[15:34:18.693] iteration 5920: loss: 0.070909, loss_s1: 0.049653, loss_fp: 0.001058, loss_freq: 0.014774
[15:34:19.331] iteration 5921: loss: 0.096531, loss_s1: 0.036014, loss_fp: 0.003897, loss_freq: 0.028039
[15:34:19.959] iteration 5922: loss: 0.125045, loss_s1: 0.065991, loss_fp: 0.006659, loss_freq: 0.015615
[15:34:20.581] iteration 5923: loss: 0.105805, loss_s1: 0.071419, loss_fp: 0.004747, loss_freq: 0.022197
[15:34:21.206] iteration 5924: loss: 0.208605, loss_s1: 0.184741, loss_fp: 0.001989, loss_freq: 0.052474
[15:34:21.826] iteration 5925: loss: 0.100861, loss_s1: 0.049305, loss_fp: 0.002916, loss_freq: 0.024738
[15:34:22.449] iteration 5926: loss: 0.095416, loss_s1: 0.079439, loss_fp: 0.003317, loss_freq: 0.025082
[15:34:23.068] iteration 5927: loss: 0.102937, loss_s1: 0.068685, loss_fp: 0.002329, loss_freq: 0.080582
[15:34:23.684] iteration 5928: loss: 0.113157, loss_s1: 0.073372, loss_fp: 0.008427, loss_freq: 0.066064
[15:34:24.306] iteration 5929: loss: 0.085224, loss_s1: 0.035209, loss_fp: 0.014354, loss_freq: 0.019108
[15:34:24.919] iteration 5930: loss: 0.155699, loss_s1: 0.103507, loss_fp: 0.003701, loss_freq: 0.089259
[15:34:25.538] iteration 5931: loss: 0.092238, loss_s1: 0.038854, loss_fp: 0.008258, loss_freq: 0.059557
[15:34:26.159] iteration 5932: loss: 0.067534, loss_s1: 0.042752, loss_fp: 0.007971, loss_freq: 0.021750
[15:34:26.789] iteration 5933: loss: 0.104531, loss_s1: 0.035976, loss_fp: 0.004239, loss_freq: 0.046547
[15:34:27.406] iteration 5934: loss: 0.085310, loss_s1: 0.039338, loss_fp: 0.003599, loss_freq: 0.049660
[15:34:28.029] iteration 5935: loss: 0.109908, loss_s1: 0.076521, loss_fp: 0.011053, loss_freq: 0.024561
[15:34:28.646] iteration 5936: loss: 0.203863, loss_s1: 0.132074, loss_fp: 0.003426, loss_freq: 0.040221
[15:34:29.263] iteration 5937: loss: 0.134787, loss_s1: 0.116897, loss_fp: 0.006022, loss_freq: 0.056849
[15:34:29.890] iteration 5938: loss: 0.089529, loss_s1: 0.034284, loss_fp: 0.001878, loss_freq: 0.034127
[15:34:30.508] iteration 5939: loss: 0.116965, loss_s1: 0.034494, loss_fp: 0.003636, loss_freq: 0.066846
[15:34:31.124] iteration 5940: loss: 0.133838, loss_s1: 0.115540, loss_fp: 0.010339, loss_freq: 0.026429
[15:34:31.746] iteration 5941: loss: 0.060121, loss_s1: 0.019947, loss_fp: 0.000588, loss_freq: 0.026593
[15:34:32.365] iteration 5942: loss: 0.108525, loss_s1: 0.073605, loss_fp: 0.011908, loss_freq: 0.015536
[15:34:32.986] iteration 5943: loss: 0.092398, loss_s1: 0.054648, loss_fp: 0.009867, loss_freq: 0.075660
[15:34:33.611] iteration 5944: loss: 0.092584, loss_s1: 0.086429, loss_fp: 0.001567, loss_freq: 0.023412
[15:34:34.234] iteration 5945: loss: 0.093499, loss_s1: 0.030001, loss_fp: 0.002720, loss_freq: 0.016923
[15:34:34.859] iteration 5946: loss: 0.123046, loss_s1: 0.041484, loss_fp: 0.001414, loss_freq: 0.068292
[15:34:35.486] iteration 5947: loss: 0.099260, loss_s1: 0.057668, loss_fp: 0.002896, loss_freq: 0.015556
[15:34:36.107] iteration 5948: loss: 0.114062, loss_s1: 0.102334, loss_fp: 0.006809, loss_freq: 0.057475
[15:34:36.722] iteration 5949: loss: 0.064605, loss_s1: 0.034570, loss_fp: 0.009075, loss_freq: 0.020380
[15:34:37.344] iteration 5950: loss: 0.107389, loss_s1: 0.049176, loss_fp: 0.002231, loss_freq: 0.040198
[15:34:37.969] iteration 5951: loss: 0.082547, loss_s1: 0.025887, loss_fp: 0.003008, loss_freq: 0.022851
[15:34:38.590] iteration 5952: loss: 0.069628, loss_s1: 0.022788, loss_fp: 0.005481, loss_freq: 0.021827
[15:34:39.209] iteration 5953: loss: 0.083077, loss_s1: 0.028261, loss_fp: 0.002553, loss_freq: 0.017081
[15:34:39.831] iteration 5954: loss: 0.119229, loss_s1: 0.067296, loss_fp: 0.000397, loss_freq: 0.047947
[15:34:40.449] iteration 5955: loss: 0.132062, loss_s1: 0.093606, loss_fp: 0.005346, loss_freq: 0.050933
[15:34:41.071] iteration 5956: loss: 0.107319, loss_s1: 0.065480, loss_fp: 0.003541, loss_freq: 0.011065
[15:34:41.692] iteration 5957: loss: 0.100131, loss_s1: 0.061825, loss_fp: 0.004375, loss_freq: 0.034142
[15:34:42.651] iteration 5958: loss: 0.068879, loss_s1: 0.035497, loss_fp: 0.002309, loss_freq: 0.017677
[15:34:43.278] iteration 5959: loss: 0.141443, loss_s1: 0.075814, loss_fp: 0.001593, loss_freq: 0.043828
[15:34:43.940] iteration 5960: loss: 0.130369, loss_s1: 0.089239, loss_fp: 0.005239, loss_freq: 0.019203
[15:34:44.597] iteration 5961: loss: 0.078477, loss_s1: 0.028137, loss_fp: 0.010344, loss_freq: 0.031858
[15:34:45.264] iteration 5962: loss: 0.096502, loss_s1: 0.051903, loss_fp: 0.002884, loss_freq: 0.024540
[15:34:45.941] iteration 5963: loss: 0.125759, loss_s1: 0.020944, loss_fp: 0.005175, loss_freq: 0.042072
[15:34:46.601] iteration 5964: loss: 0.037401, loss_s1: 0.005121, loss_fp: 0.000677, loss_freq: 0.018639
[15:34:47.224] iteration 5965: loss: 0.091786, loss_s1: 0.052894, loss_fp: 0.001870, loss_freq: 0.069888
[15:34:47.854] iteration 5966: loss: 0.073261, loss_s1: 0.034024, loss_fp: 0.010845, loss_freq: 0.017625
[15:34:48.476] iteration 5967: loss: 0.109274, loss_s1: 0.064189, loss_fp: 0.006781, loss_freq: 0.064684
[15:34:49.097] iteration 5968: loss: 0.060045, loss_s1: 0.015875, loss_fp: 0.001192, loss_freq: 0.028295
[15:34:49.721] iteration 5969: loss: 0.113661, loss_s1: 0.096115, loss_fp: 0.001625, loss_freq: 0.055387
[15:34:50.341] iteration 5970: loss: 0.057518, loss_s1: 0.039085, loss_fp: 0.008380, loss_freq: 0.017852
[15:34:50.961] iteration 5971: loss: 0.107839, loss_s1: 0.029022, loss_fp: 0.009662, loss_freq: 0.045252
[15:34:51.576] iteration 5972: loss: 0.068988, loss_s1: 0.029873, loss_fp: 0.003403, loss_freq: 0.028268
[15:34:52.206] iteration 5973: loss: 0.113218, loss_s1: 0.058289, loss_fp: 0.009238, loss_freq: 0.062193
[15:34:52.821] iteration 5974: loss: 0.144709, loss_s1: 0.056751, loss_fp: 0.009237, loss_freq: 0.018932
[15:34:53.460] iteration 5975: loss: 0.078745, loss_s1: 0.035527, loss_fp: 0.001185, loss_freq: 0.034030
[15:34:54.083] iteration 5976: loss: 0.072682, loss_s1: 0.055004, loss_fp: 0.000536, loss_freq: 0.008818
[15:34:54.700] iteration 5977: loss: 0.111966, loss_s1: 0.088845, loss_fp: 0.000931, loss_freq: 0.028226
[15:34:55.314] iteration 5978: loss: 0.069702, loss_s1: 0.012958, loss_fp: 0.000861, loss_freq: 0.008855
[15:34:55.929] iteration 5979: loss: 0.095333, loss_s1: 0.047026, loss_fp: 0.001909, loss_freq: 0.035418
[15:34:56.543] iteration 5980: loss: 0.089696, loss_s1: 0.028270, loss_fp: 0.000434, loss_freq: 0.038039
[15:34:57.156] iteration 5981: loss: 0.148948, loss_s1: 0.100446, loss_fp: 0.003875, loss_freq: 0.123452
[15:34:57.817] iteration 5982: loss: 0.056386, loss_s1: 0.037347, loss_fp: 0.000920, loss_freq: 0.015240
[15:34:58.474] iteration 5983: loss: 0.110429, loss_s1: 0.077377, loss_fp: 0.006429, loss_freq: 0.040645
[15:34:59.143] iteration 5984: loss: 0.098665, loss_s1: 0.058105, loss_fp: 0.010016, loss_freq: 0.037938
[15:34:59.782] iteration 5985: loss: 0.148990, loss_s1: 0.132985, loss_fp: 0.005323, loss_freq: 0.042868
[15:35:00.423] iteration 5986: loss: 0.149018, loss_s1: 0.081283, loss_fp: 0.000807, loss_freq: 0.041219
[15:35:01.062] iteration 5987: loss: 0.105308, loss_s1: 0.052104, loss_fp: 0.001772, loss_freq: 0.013631
[15:35:01.699] iteration 5988: loss: 0.075444, loss_s1: 0.054465, loss_fp: 0.006815, loss_freq: 0.015125
[15:35:02.340] iteration 5989: loss: 0.093171, loss_s1: 0.021647, loss_fp: 0.001685, loss_freq: 0.030409
[15:35:02.982] iteration 5990: loss: 0.079160, loss_s1: 0.036122, loss_fp: 0.002270, loss_freq: 0.042975
[15:35:03.619] iteration 5991: loss: 0.069608, loss_s1: 0.064481, loss_fp: 0.003774, loss_freq: 0.013075
[15:35:04.253] iteration 5992: loss: 0.110538, loss_s1: 0.045310, loss_fp: 0.007892, loss_freq: 0.024310
[15:35:04.889] iteration 5993: loss: 0.094171, loss_s1: 0.054793, loss_fp: 0.004186, loss_freq: 0.041775
[15:35:05.519] iteration 5994: loss: 0.187149, loss_s1: 0.124389, loss_fp: 0.006627, loss_freq: 0.110002
[15:35:06.153] iteration 5995: loss: 0.091539, loss_s1: 0.039992, loss_fp: 0.008453, loss_freq: 0.009572
[15:35:06.790] iteration 5996: loss: 0.151547, loss_s1: 0.114621, loss_fp: 0.011450, loss_freq: 0.064806
[15:35:07.422] iteration 5997: loss: 0.081192, loss_s1: 0.036965, loss_fp: 0.004669, loss_freq: 0.042104
[15:35:08.049] iteration 5998: loss: 0.105204, loss_s1: 0.011560, loss_fp: 0.002515, loss_freq: 0.038461
[15:35:08.684] iteration 5999: loss: 0.082924, loss_s1: 0.061724, loss_fp: 0.003088, loss_freq: 0.021584
[15:35:09.325] iteration 6000: loss: 0.088891, loss_s1: 0.044120, loss_fp: 0.001972, loss_freq: 0.045336
[15:35:12.670] iteration 6000 : mean_dice : 0.643813
[15:35:13.331] iteration 6001: loss: 0.086688, loss_s1: 0.060511, loss_fp: 0.001634, loss_freq: 0.034224
[15:35:13.958] iteration 6002: loss: 0.117894, loss_s1: 0.107561, loss_fp: 0.001596, loss_freq: 0.057679
[15:35:14.583] iteration 6003: loss: 0.093131, loss_s1: 0.046353, loss_fp: 0.005103, loss_freq: 0.003744
[15:35:15.211] iteration 6004: loss: 0.078811, loss_s1: 0.029604, loss_fp: 0.002336, loss_freq: 0.022215
[15:35:15.836] iteration 6005: loss: 0.059686, loss_s1: 0.045026, loss_fp: 0.002375, loss_freq: 0.004562
[15:35:16.455] iteration 6006: loss: 0.102844, loss_s1: 0.027815, loss_fp: 0.003130, loss_freq: 0.015119
[15:35:17.082] iteration 6007: loss: 0.135592, loss_s1: 0.089248, loss_fp: 0.000857, loss_freq: 0.048137
[15:35:17.707] iteration 6008: loss: 0.074947, loss_s1: 0.030793, loss_fp: 0.003685, loss_freq: 0.047314
[15:35:18.331] iteration 6009: loss: 0.109108, loss_s1: 0.044547, loss_fp: 0.005497, loss_freq: 0.011283
[15:35:18.955] iteration 6010: loss: 0.106046, loss_s1: 0.063324, loss_fp: 0.004787, loss_freq: 0.057484
[15:35:19.580] iteration 6011: loss: 0.072629, loss_s1: 0.032161, loss_fp: 0.000875, loss_freq: 0.029404
[15:35:20.207] iteration 6012: loss: 0.111136, loss_s1: 0.033540, loss_fp: 0.000688, loss_freq: 0.032579
[15:35:20.833] iteration 6013: loss: 0.155164, loss_s1: 0.113044, loss_fp: 0.006410, loss_freq: 0.079223
[15:35:21.463] iteration 6014: loss: 0.110109, loss_s1: 0.014163, loss_fp: 0.000917, loss_freq: 0.032323
[15:35:22.081] iteration 6015: loss: 0.166840, loss_s1: 0.073039, loss_fp: 0.001883, loss_freq: 0.070072
[15:35:22.692] iteration 6016: loss: 0.090929, loss_s1: 0.104114, loss_fp: 0.001392, loss_freq: 0.009998
[15:35:23.310] iteration 6017: loss: 0.070777, loss_s1: 0.030554, loss_fp: 0.001157, loss_freq: 0.017645
[15:35:23.934] iteration 6018: loss: 0.072298, loss_s1: 0.069723, loss_fp: 0.008802, loss_freq: 0.010131
[15:35:24.551] iteration 6019: loss: 0.073148, loss_s1: 0.049455, loss_fp: 0.000467, loss_freq: 0.024475
[15:35:25.176] iteration 6020: loss: 0.111576, loss_s1: 0.071711, loss_fp: 0.005426, loss_freq: 0.015660
[15:35:25.793] iteration 6021: loss: 0.082105, loss_s1: 0.038112, loss_fp: 0.001495, loss_freq: 0.022892
[15:35:26.408] iteration 6022: loss: 0.083302, loss_s1: 0.037309, loss_fp: 0.000796, loss_freq: 0.016503
[15:35:27.032] iteration 6023: loss: 0.120947, loss_s1: 0.050724, loss_fp: 0.003265, loss_freq: 0.057558
[15:35:27.647] iteration 6024: loss: 0.135733, loss_s1: 0.097881, loss_fp: 0.001221, loss_freq: 0.056852
[15:35:28.259] iteration 6025: loss: 0.067721, loss_s1: 0.041668, loss_fp: 0.004312, loss_freq: 0.031947
[15:35:28.877] iteration 6026: loss: 0.081269, loss_s1: 0.035861, loss_fp: 0.008223, loss_freq: 0.034375
[15:35:29.492] iteration 6027: loss: 0.121799, loss_s1: 0.037191, loss_fp: 0.000854, loss_freq: 0.020659
[15:35:30.122] iteration 6028: loss: 0.112924, loss_s1: 0.033868, loss_fp: 0.005779, loss_freq: 0.031612
[15:35:30.819] iteration 6029: loss: 0.109209, loss_s1: 0.091683, loss_fp: 0.003440, loss_freq: 0.036990
[15:35:31.477] iteration 6030: loss: 0.105923, loss_s1: 0.036807, loss_fp: 0.002333, loss_freq: 0.093920
[15:35:32.110] iteration 6031: loss: 0.086890, loss_s1: 0.043544, loss_fp: 0.000569, loss_freq: 0.022817
[15:35:32.729] iteration 6032: loss: 0.122425, loss_s1: 0.120917, loss_fp: 0.001873, loss_freq: 0.049584
[15:35:33.360] iteration 6033: loss: 0.200355, loss_s1: 0.156140, loss_fp: 0.039905, loss_freq: 0.083470
[15:35:34.025] iteration 6034: loss: 0.099071, loss_s1: 0.069266, loss_fp: 0.007839, loss_freq: 0.037342
[15:35:34.643] iteration 6035: loss: 0.113192, loss_s1: 0.079484, loss_fp: 0.016644, loss_freq: 0.046985
[15:35:35.265] iteration 6036: loss: 0.070601, loss_s1: 0.031256, loss_fp: 0.015367, loss_freq: 0.019554
[15:35:35.877] iteration 6037: loss: 0.099064, loss_s1: 0.087309, loss_fp: 0.005721, loss_freq: 0.042088
[15:35:36.502] iteration 6038: loss: 0.145840, loss_s1: 0.086866, loss_fp: 0.002176, loss_freq: 0.053789
[15:35:37.131] iteration 6039: loss: 0.121568, loss_s1: 0.110712, loss_fp: 0.002886, loss_freq: 0.045513
[15:35:37.755] iteration 6040: loss: 0.169515, loss_s1: 0.108545, loss_fp: 0.007918, loss_freq: 0.133004
[15:35:38.383] iteration 6041: loss: 0.097114, loss_s1: 0.036177, loss_fp: 0.001608, loss_freq: 0.028097
[15:35:39.012] iteration 6042: loss: 0.184402, loss_s1: 0.113906, loss_fp: 0.025634, loss_freq: 0.135704
[15:35:39.637] iteration 6043: loss: 0.099043, loss_s1: 0.082413, loss_fp: 0.005227, loss_freq: 0.046766
[15:35:40.267] iteration 6044: loss: 0.153334, loss_s1: 0.084592, loss_fp: 0.004181, loss_freq: 0.050728
[15:35:40.896] iteration 6045: loss: 0.092066, loss_s1: 0.048412, loss_fp: 0.007874, loss_freq: 0.046841
[15:35:41.523] iteration 6046: loss: 0.105407, loss_s1: 0.046243, loss_fp: 0.002571, loss_freq: 0.043944
[15:35:42.187] iteration 6047: loss: 0.102719, loss_s1: 0.046057, loss_fp: 0.001262, loss_freq: 0.042964
[15:35:42.863] iteration 6048: loss: 0.147325, loss_s1: 0.035880, loss_fp: 0.003042, loss_freq: 0.040227
[15:35:43.499] iteration 6049: loss: 0.100628, loss_s1: 0.046145, loss_fp: 0.002304, loss_freq: 0.031084
[15:35:44.125] iteration 6050: loss: 0.198547, loss_s1: 0.035511, loss_fp: 0.002110, loss_freq: 0.036063
[15:35:44.752] iteration 6051: loss: 0.097755, loss_s1: 0.052938, loss_fp: 0.001463, loss_freq: 0.036336
[15:35:45.377] iteration 6052: loss: 0.052486, loss_s1: 0.019761, loss_fp: 0.001635, loss_freq: 0.015065
[15:35:46.005] iteration 6053: loss: 0.088740, loss_s1: 0.083320, loss_fp: 0.001004, loss_freq: 0.020679
[15:35:46.631] iteration 6054: loss: 0.073261, loss_s1: 0.034502, loss_fp: 0.001204, loss_freq: 0.032510
[15:35:47.258] iteration 6055: loss: 0.129977, loss_s1: 0.028748, loss_fp: 0.003666, loss_freq: 0.025377
[15:35:47.883] iteration 6056: loss: 0.099067, loss_s1: 0.051765, loss_fp: 0.003806, loss_freq: 0.040138
[15:35:48.514] iteration 6057: loss: 0.101306, loss_s1: 0.101450, loss_fp: 0.001686, loss_freq: 0.027723
[15:35:49.138] iteration 6058: loss: 0.106768, loss_s1: 0.090232, loss_fp: 0.002145, loss_freq: 0.043397
[15:35:49.763] iteration 6059: loss: 0.094888, loss_s1: 0.043672, loss_fp: 0.001470, loss_freq: 0.039076
[15:35:50.389] iteration 6060: loss: 0.146423, loss_s1: 0.094894, loss_fp: 0.002344, loss_freq: 0.033522
[15:35:51.025] iteration 6061: loss: 0.119002, loss_s1: 0.066655, loss_fp: 0.005575, loss_freq: 0.041295
[15:35:51.685] iteration 6062: loss: 0.137341, loss_s1: 0.054460, loss_fp: 0.003248, loss_freq: 0.040885
[15:35:52.348] iteration 6063: loss: 0.084217, loss_s1: 0.030519, loss_fp: 0.001481, loss_freq: 0.031092
[15:35:53.010] iteration 6064: loss: 0.116421, loss_s1: 0.067595, loss_fp: 0.002185, loss_freq: 0.020769
[15:35:53.656] iteration 6065: loss: 0.183214, loss_s1: 0.107882, loss_fp: 0.000916, loss_freq: 0.113624
[15:35:54.282] iteration 6066: loss: 0.207110, loss_s1: 0.137634, loss_fp: 0.008156, loss_freq: 0.173128
[15:35:54.910] iteration 6067: loss: 0.111419, loss_s1: 0.047002, loss_fp: 0.001507, loss_freq: 0.050745
[15:35:55.540] iteration 6068: loss: 0.093472, loss_s1: 0.070712, loss_fp: 0.001323, loss_freq: 0.019033
[15:35:56.166] iteration 6069: loss: 0.078406, loss_s1: 0.057242, loss_fp: 0.001770, loss_freq: 0.033210
[15:35:56.794] iteration 6070: loss: 0.123624, loss_s1: 0.092156, loss_fp: 0.002030, loss_freq: 0.052574
[15:35:57.417] iteration 6071: loss: 0.091464, loss_s1: 0.052204, loss_fp: 0.001479, loss_freq: 0.057982
[15:35:58.043] iteration 6072: loss: 0.067202, loss_s1: 0.030324, loss_fp: 0.014852, loss_freq: 0.012206
[15:35:58.670] iteration 6073: loss: 0.159318, loss_s1: 0.160527, loss_fp: 0.001809, loss_freq: 0.064964
[15:35:59.293] iteration 6074: loss: 0.120844, loss_s1: 0.081566, loss_fp: 0.009163, loss_freq: 0.029376
[15:35:59.920] iteration 6075: loss: 0.116614, loss_s1: 0.064341, loss_fp: 0.005330, loss_freq: 0.066225
[15:36:00.547] iteration 6076: loss: 0.182805, loss_s1: 0.105820, loss_fp: 0.000439, loss_freq: 0.042133
[15:36:01.171] iteration 6077: loss: 0.147101, loss_s1: 0.130145, loss_fp: 0.000576, loss_freq: 0.084756
[15:36:01.798] iteration 6078: loss: 0.088171, loss_s1: 0.025346, loss_fp: 0.002164, loss_freq: 0.076774
[15:36:02.422] iteration 6079: loss: 0.092793, loss_s1: 0.033349, loss_fp: 0.000624, loss_freq: 0.019153
[15:36:03.054] iteration 6080: loss: 0.143048, loss_s1: 0.122205, loss_fp: 0.003004, loss_freq: 0.044635
[15:36:03.678] iteration 6081: loss: 0.078993, loss_s1: 0.053974, loss_fp: 0.000701, loss_freq: 0.007211
[15:36:04.301] iteration 6082: loss: 0.118979, loss_s1: 0.035858, loss_fp: 0.000490, loss_freq: 0.055340
[15:36:04.930] iteration 6083: loss: 0.118677, loss_s1: 0.032078, loss_fp: 0.000615, loss_freq: 0.036932
[15:36:05.553] iteration 6084: loss: 0.088046, loss_s1: 0.030098, loss_fp: 0.001639, loss_freq: 0.007574
[15:36:06.178] iteration 6085: loss: 0.194096, loss_s1: 0.163740, loss_fp: 0.009523, loss_freq: 0.047240
[15:36:06.805] iteration 6086: loss: 0.076601, loss_s1: 0.058542, loss_fp: 0.000981, loss_freq: 0.012003
[15:36:07.436] iteration 6087: loss: 0.090016, loss_s1: 0.056500, loss_fp: 0.005236, loss_freq: 0.012540
[15:36:08.063] iteration 6088: loss: 0.115858, loss_s1: 0.084495, loss_fp: 0.003607, loss_freq: 0.078321
[15:36:08.686] iteration 6089: loss: 0.101960, loss_s1: 0.066613, loss_fp: 0.005719, loss_freq: 0.027099
[15:36:09.308] iteration 6090: loss: 0.080082, loss_s1: 0.056268, loss_fp: 0.000834, loss_freq: 0.010282
[15:36:09.931] iteration 6091: loss: 0.103376, loss_s1: 0.096468, loss_fp: 0.001773, loss_freq: 0.024815
[15:36:10.593] iteration 6092: loss: 0.116327, loss_s1: 0.083802, loss_fp: 0.002702, loss_freq: 0.066555
[15:36:11.253] iteration 6093: loss: 0.090713, loss_s1: 0.083160, loss_fp: 0.004454, loss_freq: 0.029984
[15:36:11.889] iteration 6094: loss: 0.098330, loss_s1: 0.054854, loss_fp: 0.001394, loss_freq: 0.043645
[15:36:12.512] iteration 6095: loss: 0.092398, loss_s1: 0.082037, loss_fp: 0.003059, loss_freq: 0.030187
[15:36:13.136] iteration 6096: loss: 0.086382, loss_s1: 0.045747, loss_fp: 0.002261, loss_freq: 0.049572
[15:36:13.809] iteration 6097: loss: 0.148434, loss_s1: 0.031892, loss_fp: 0.001378, loss_freq: 0.041005
[15:36:14.467] iteration 6098: loss: 0.107226, loss_s1: 0.047274, loss_fp: 0.005305, loss_freq: 0.069502
[15:36:15.122] iteration 6099: loss: 0.102190, loss_s1: 0.030953, loss_fp: 0.003734, loss_freq: 0.031353
[15:36:15.743] iteration 6100: loss: 0.145611, loss_s1: 0.097870, loss_fp: 0.001687, loss_freq: 0.057636
[15:36:16.388] iteration 6101: loss: 0.091213, loss_s1: 0.044588, loss_fp: 0.003631, loss_freq: 0.036151
[15:36:17.078] iteration 6102: loss: 0.072078, loss_s1: 0.054316, loss_fp: 0.000615, loss_freq: 0.011695
[15:36:17.737] iteration 6103: loss: 0.101965, loss_s1: 0.016592, loss_fp: 0.010774, loss_freq: 0.020226
[15:36:18.395] iteration 6104: loss: 0.074828, loss_s1: 0.049170, loss_fp: 0.004260, loss_freq: 0.048827
[15:36:19.059] iteration 6105: loss: 0.127374, loss_s1: 0.119143, loss_fp: 0.001958, loss_freq: 0.034799
[15:36:19.720] iteration 6106: loss: 0.096706, loss_s1: 0.046358, loss_fp: 0.007521, loss_freq: 0.027111
[15:36:20.348] iteration 6107: loss: 0.115513, loss_s1: 0.086817, loss_fp: 0.006197, loss_freq: 0.058679
[15:36:20.970] iteration 6108: loss: 0.095091, loss_s1: 0.070960, loss_fp: 0.002310, loss_freq: 0.040916
[15:36:21.594] iteration 6109: loss: 0.140448, loss_s1: 0.071336, loss_fp: 0.000976, loss_freq: 0.125105
[15:36:22.223] iteration 6110: loss: 0.107975, loss_s1: 0.095897, loss_fp: 0.005184, loss_freq: 0.029252
[15:36:22.846] iteration 6111: loss: 0.134750, loss_s1: 0.053991, loss_fp: 0.001467, loss_freq: 0.027399
[15:36:23.468] iteration 6112: loss: 0.082010, loss_s1: 0.032717, loss_fp: 0.008294, loss_freq: 0.011243
[15:36:24.089] iteration 6113: loss: 0.101316, loss_s1: 0.085657, loss_fp: 0.001776, loss_freq: 0.017713
[15:36:24.712] iteration 6114: loss: 0.095679, loss_s1: 0.012674, loss_fp: 0.000675, loss_freq: 0.012103
[15:36:25.334] iteration 6115: loss: 0.111021, loss_s1: 0.082126, loss_fp: 0.006275, loss_freq: 0.042493
[15:36:25.956] iteration 6116: loss: 0.118537, loss_s1: 0.085962, loss_fp: 0.009707, loss_freq: 0.023574
[15:36:26.582] iteration 6117: loss: 0.090117, loss_s1: 0.019574, loss_fp: 0.001424, loss_freq: 0.015497
[15:36:27.205] iteration 6118: loss: 0.105109, loss_s1: 0.060006, loss_fp: 0.001594, loss_freq: 0.024207
[15:36:28.181] iteration 6119: loss: 0.071355, loss_s1: 0.037680, loss_fp: 0.001941, loss_freq: 0.024486
[15:36:28.826] iteration 6120: loss: 0.078046, loss_s1: 0.052998, loss_fp: 0.000597, loss_freq: 0.028483
[15:36:29.455] iteration 6121: loss: 0.087856, loss_s1: 0.025912, loss_fp: 0.000777, loss_freq: 0.082372
[15:36:30.082] iteration 6122: loss: 0.107053, loss_s1: 0.035754, loss_fp: 0.000536, loss_freq: 0.032664
[15:36:30.712] iteration 6123: loss: 0.098233, loss_s1: 0.077353, loss_fp: 0.000825, loss_freq: 0.027210
[15:36:31.339] iteration 6124: loss: 0.135406, loss_s1: 0.036442, loss_fp: 0.001308, loss_freq: 0.083730
[15:36:31.959] iteration 6125: loss: 0.058258, loss_s1: 0.039237, loss_fp: 0.001092, loss_freq: 0.011800
[15:36:32.579] iteration 6126: loss: 0.066531, loss_s1: 0.032605, loss_fp: 0.000631, loss_freq: 0.029772
[15:36:33.205] iteration 6127: loss: 0.114506, loss_s1: 0.115069, loss_fp: 0.002987, loss_freq: 0.026232
[15:36:33.832] iteration 6128: loss: 0.120771, loss_s1: 0.117993, loss_fp: 0.000737, loss_freq: 0.054023
[15:36:34.457] iteration 6129: loss: 0.064963, loss_s1: 0.023738, loss_fp: 0.003089, loss_freq: 0.015416
[15:36:35.084] iteration 6130: loss: 0.097171, loss_s1: 0.048757, loss_fp: 0.001204, loss_freq: 0.045587
[15:36:35.758] iteration 6131: loss: 0.070914, loss_s1: 0.054881, loss_fp: 0.001187, loss_freq: 0.032167
[15:36:36.379] iteration 6132: loss: 0.144428, loss_s1: 0.062774, loss_fp: 0.002384, loss_freq: 0.037571
[15:36:37.006] iteration 6133: loss: 0.105349, loss_s1: 0.095635, loss_fp: 0.001754, loss_freq: 0.014987
[15:36:37.630] iteration 6134: loss: 0.157960, loss_s1: 0.118810, loss_fp: 0.003884, loss_freq: 0.089516
[15:36:38.259] iteration 6135: loss: 0.122384, loss_s1: 0.055730, loss_fp: 0.000882, loss_freq: 0.011641
[15:36:38.885] iteration 6136: loss: 0.095339, loss_s1: 0.058972, loss_fp: 0.003962, loss_freq: 0.029253
[15:36:39.511] iteration 6137: loss: 0.089130, loss_s1: 0.035014, loss_fp: 0.004567, loss_freq: 0.037480
[15:36:40.137] iteration 6138: loss: 0.115004, loss_s1: 0.073037, loss_fp: 0.001406, loss_freq: 0.028566
[15:36:40.769] iteration 6139: loss: 0.065027, loss_s1: 0.024810, loss_fp: 0.030291, loss_freq: 0.013807
[15:36:41.401] iteration 6140: loss: 0.085425, loss_s1: 0.048578, loss_fp: 0.001332, loss_freq: 0.036210
[15:36:42.029] iteration 6141: loss: 0.120087, loss_s1: 0.037944, loss_fp: 0.000878, loss_freq: 0.020261
[15:36:42.653] iteration 6142: loss: 0.197338, loss_s1: 0.177561, loss_fp: 0.009526, loss_freq: 0.153976
[15:36:43.284] iteration 6143: loss: 0.054657, loss_s1: 0.024664, loss_fp: 0.001025, loss_freq: 0.026542
[15:36:43.909] iteration 6144: loss: 0.107027, loss_s1: 0.077313, loss_fp: 0.000951, loss_freq: 0.059130
[15:36:44.539] iteration 6145: loss: 0.079817, loss_s1: 0.067527, loss_fp: 0.001801, loss_freq: 0.020032
[15:36:45.169] iteration 6146: loss: 0.148078, loss_s1: 0.071167, loss_fp: 0.001991, loss_freq: 0.058207
[15:36:45.796] iteration 6147: loss: 0.091271, loss_s1: 0.085729, loss_fp: 0.002007, loss_freq: 0.035377
[15:36:46.425] iteration 6148: loss: 0.074974, loss_s1: 0.040651, loss_fp: 0.007867, loss_freq: 0.020019
[15:36:47.050] iteration 6149: loss: 0.091032, loss_s1: 0.079615, loss_fp: 0.001926, loss_freq: 0.009918
[15:36:47.674] iteration 6150: loss: 0.167849, loss_s1: 0.102497, loss_fp: 0.000730, loss_freq: 0.037024
[15:36:48.301] iteration 6151: loss: 0.085921, loss_s1: 0.065282, loss_fp: 0.002469, loss_freq: 0.017637
[15:36:48.933] iteration 6152: loss: 0.067894, loss_s1: 0.041349, loss_fp: 0.003915, loss_freq: 0.018319
[15:36:49.592] iteration 6153: loss: 0.097753, loss_s1: 0.025120, loss_fp: 0.001322, loss_freq: 0.019986
[15:36:50.278] iteration 6154: loss: 0.108228, loss_s1: 0.058807, loss_fp: 0.001389, loss_freq: 0.055515
[15:36:50.925] iteration 6155: loss: 0.176171, loss_s1: 0.119648, loss_fp: 0.007681, loss_freq: 0.068931
[15:36:51.561] iteration 6156: loss: 0.083950, loss_s1: 0.050934, loss_fp: 0.002991, loss_freq: 0.045925
[15:36:52.184] iteration 6157: loss: 0.151506, loss_s1: 0.104809, loss_fp: 0.001210, loss_freq: 0.089479
[15:36:52.804] iteration 6158: loss: 0.105238, loss_s1: 0.071453, loss_fp: 0.004540, loss_freq: 0.046993
[15:36:53.428] iteration 6159: loss: 0.099320, loss_s1: 0.023074, loss_fp: 0.006309, loss_freq: 0.038264
[15:36:54.055] iteration 6160: loss: 0.060885, loss_s1: 0.031720, loss_fp: 0.006656, loss_freq: 0.031473
[15:36:54.680] iteration 6161: loss: 0.066316, loss_s1: 0.040891, loss_fp: 0.001413, loss_freq: 0.016255
[15:36:55.308] iteration 6162: loss: 0.075807, loss_s1: 0.058734, loss_fp: 0.004565, loss_freq: 0.014582
[15:36:55.937] iteration 6163: loss: 0.087696, loss_s1: 0.079908, loss_fp: 0.000811, loss_freq: 0.025780
[15:36:56.578] iteration 6164: loss: 0.077055, loss_s1: 0.031116, loss_fp: 0.001298, loss_freq: 0.028368
[15:36:57.207] iteration 6165: loss: 0.096318, loss_s1: 0.041919, loss_fp: 0.000270, loss_freq: 0.035219
[15:36:57.828] iteration 6166: loss: 0.075746, loss_s1: 0.065723, loss_fp: 0.002474, loss_freq: 0.022559
[15:36:58.452] iteration 6167: loss: 0.123648, loss_s1: 0.081088, loss_fp: 0.001764, loss_freq: 0.015646
[15:36:59.078] iteration 6168: loss: 0.088638, loss_s1: 0.055104, loss_fp: 0.004772, loss_freq: 0.021052
[15:36:59.704] iteration 6169: loss: 0.070664, loss_s1: 0.036906, loss_fp: 0.006085, loss_freq: 0.039451
[15:37:00.328] iteration 6170: loss: 0.088478, loss_s1: 0.015238, loss_fp: 0.008169, loss_freq: 0.024080
[15:37:00.952] iteration 6171: loss: 0.113815, loss_s1: 0.058538, loss_fp: 0.001166, loss_freq: 0.069073
[15:37:01.575] iteration 6172: loss: 0.072176, loss_s1: 0.056330, loss_fp: 0.003721, loss_freq: 0.016609
[15:37:02.199] iteration 6173: loss: 0.118986, loss_s1: 0.054430, loss_fp: 0.003936, loss_freq: 0.032441
[15:37:02.823] iteration 6174: loss: 0.091885, loss_s1: 0.067828, loss_fp: 0.002386, loss_freq: 0.047527
[15:37:03.446] iteration 6175: loss: 0.055149, loss_s1: 0.013822, loss_fp: 0.001126, loss_freq: 0.009400
[15:37:04.070] iteration 6176: loss: 0.097620, loss_s1: 0.049364, loss_fp: 0.001041, loss_freq: 0.039315
[15:37:04.698] iteration 6177: loss: 0.060237, loss_s1: 0.040456, loss_fp: 0.001015, loss_freq: 0.005110
[15:37:05.325] iteration 6178: loss: 0.074913, loss_s1: 0.050070, loss_fp: 0.000966, loss_freq: 0.025496
[15:37:05.953] iteration 6179: loss: 0.060683, loss_s1: 0.030044, loss_fp: 0.001233, loss_freq: 0.027806
[15:37:06.577] iteration 6180: loss: 0.088117, loss_s1: 0.051382, loss_fp: 0.012889, loss_freq: 0.023411
[15:37:07.204] iteration 6181: loss: 0.126522, loss_s1: 0.100721, loss_fp: 0.001061, loss_freq: 0.048443
[15:37:07.825] iteration 6182: loss: 0.085977, loss_s1: 0.059364, loss_fp: 0.002153, loss_freq: 0.018257
[15:37:08.454] iteration 6183: loss: 0.075719, loss_s1: 0.059991, loss_fp: 0.000543, loss_freq: 0.022513
[15:37:09.081] iteration 6184: loss: 0.111196, loss_s1: 0.048000, loss_fp: 0.004078, loss_freq: 0.053076
[15:37:09.706] iteration 6185: loss: 0.112483, loss_s1: 0.069538, loss_fp: 0.001448, loss_freq: 0.058041
[15:37:10.335] iteration 6186: loss: 0.098628, loss_s1: 0.090889, loss_fp: 0.003818, loss_freq: 0.034502
[15:37:10.977] iteration 6187: loss: 0.064539, loss_s1: 0.039200, loss_fp: 0.002928, loss_freq: 0.014771
[15:37:11.616] iteration 6188: loss: 0.150947, loss_s1: 0.064959, loss_fp: 0.013510, loss_freq: 0.021777
[15:37:12.254] iteration 6189: loss: 0.085054, loss_s1: 0.045432, loss_fp: 0.001700, loss_freq: 0.044687
[15:37:12.894] iteration 6190: loss: 0.118084, loss_s1: 0.084953, loss_fp: 0.002026, loss_freq: 0.040145
[15:37:13.526] iteration 6191: loss: 0.105415, loss_s1: 0.050699, loss_fp: 0.009385, loss_freq: 0.054315
[15:37:14.165] iteration 6192: loss: 0.066616, loss_s1: 0.032879, loss_fp: 0.001787, loss_freq: 0.023993
[15:37:14.810] iteration 6193: loss: 0.114544, loss_s1: 0.118252, loss_fp: 0.000784, loss_freq: 0.031416
[15:37:15.431] iteration 6194: loss: 0.152726, loss_s1: 0.035830, loss_fp: 0.004714, loss_freq: 0.100006
[15:37:16.053] iteration 6195: loss: 0.084697, loss_s1: 0.069676, loss_fp: 0.001420, loss_freq: 0.034007
[15:37:16.677] iteration 6196: loss: 0.072973, loss_s1: 0.048541, loss_fp: 0.009493, loss_freq: 0.036011
[15:37:17.366] iteration 6197: loss: 0.061579, loss_s1: 0.048803, loss_fp: 0.003830, loss_freq: 0.009403
[15:37:18.025] iteration 6198: loss: 0.068353, loss_s1: 0.059944, loss_fp: 0.001668, loss_freq: 0.015241
[15:37:18.688] iteration 6199: loss: 0.124280, loss_s1: 0.036279, loss_fp: 0.005814, loss_freq: 0.037991
[15:37:19.347] iteration 6200: loss: 0.095021, loss_s1: 0.083414, loss_fp: 0.007470, loss_freq: 0.021300
[15:37:22.457] iteration 6200 : mean_dice : 0.638781
[15:37:23.108] iteration 6201: loss: 0.153302, loss_s1: 0.165135, loss_fp: 0.001269, loss_freq: 0.079224
[15:37:23.737] iteration 6202: loss: 0.101430, loss_s1: 0.045493, loss_fp: 0.003309, loss_freq: 0.042775
[15:37:24.361] iteration 6203: loss: 0.146146, loss_s1: 0.099307, loss_fp: 0.004625, loss_freq: 0.125618
[15:37:24.986] iteration 6204: loss: 0.074464, loss_s1: 0.026078, loss_fp: 0.001402, loss_freq: 0.050107
[15:37:25.608] iteration 6205: loss: 0.128001, loss_s1: 0.051353, loss_fp: 0.002108, loss_freq: 0.067053
[15:37:26.234] iteration 6206: loss: 0.078610, loss_s1: 0.038868, loss_fp: 0.000995, loss_freq: 0.016897
[15:37:26.857] iteration 6207: loss: 0.087557, loss_s1: 0.045888, loss_fp: 0.001543, loss_freq: 0.061549
[15:37:27.478] iteration 6208: loss: 0.126106, loss_s1: 0.072526, loss_fp: 0.002000, loss_freq: 0.028193
[15:37:28.101] iteration 6209: loss: 0.137878, loss_s1: 0.068728, loss_fp: 0.000512, loss_freq: 0.035306
[15:37:28.727] iteration 6210: loss: 0.077347, loss_s1: 0.067423, loss_fp: 0.005213, loss_freq: 0.012285
[15:37:29.352] iteration 6211: loss: 0.167997, loss_s1: 0.028392, loss_fp: 0.008625, loss_freq: 0.011330
[15:37:30.017] iteration 6212: loss: 0.096658, loss_s1: 0.060164, loss_fp: 0.001640, loss_freq: 0.016409
[15:37:30.657] iteration 6213: loss: 0.071647, loss_s1: 0.053640, loss_fp: 0.011889, loss_freq: 0.016263
[15:37:31.345] iteration 6214: loss: 0.066758, loss_s1: 0.040218, loss_fp: 0.002960, loss_freq: 0.015073
[15:37:31.999] iteration 6215: loss: 0.072245, loss_s1: 0.025695, loss_fp: 0.003175, loss_freq: 0.038351
[15:37:32.658] iteration 6216: loss: 0.086628, loss_s1: 0.047401, loss_fp: 0.000818, loss_freq: 0.024123
[15:37:33.323] iteration 6217: loss: 0.135079, loss_s1: 0.061060, loss_fp: 0.001999, loss_freq: 0.044059
[15:37:33.992] iteration 6218: loss: 0.090165, loss_s1: 0.088238, loss_fp: 0.003748, loss_freq: 0.026238
[15:37:34.659] iteration 6219: loss: 0.092253, loss_s1: 0.077977, loss_fp: 0.002664, loss_freq: 0.008805
[15:37:35.294] iteration 6220: loss: 0.123943, loss_s1: 0.040254, loss_fp: 0.006918, loss_freq: 0.066523
[15:37:35.948] iteration 6221: loss: 0.154092, loss_s1: 0.077644, loss_fp: 0.010047, loss_freq: 0.063551
[15:37:36.575] iteration 6222: loss: 0.134389, loss_s1: 0.043986, loss_fp: 0.011483, loss_freq: 0.101164
[15:37:37.207] iteration 6223: loss: 0.160644, loss_s1: 0.085948, loss_fp: 0.009107, loss_freq: 0.041954
[15:37:37.839] iteration 6224: loss: 0.076348, loss_s1: 0.042881, loss_fp: 0.001903, loss_freq: 0.038493
[15:37:38.470] iteration 6225: loss: 0.157575, loss_s1: 0.028778, loss_fp: 0.003917, loss_freq: 0.023799
[15:37:39.096] iteration 6226: loss: 0.177271, loss_s1: 0.122311, loss_fp: 0.016112, loss_freq: 0.049202
[15:37:39.725] iteration 6227: loss: 0.263343, loss_s1: 0.152628, loss_fp: 0.001994, loss_freq: 0.236858
[15:37:40.353] iteration 6228: loss: 0.111431, loss_s1: 0.082951, loss_fp: 0.001530, loss_freq: 0.055749
[15:37:40.980] iteration 6229: loss: 0.089022, loss_s1: 0.018837, loss_fp: 0.001120, loss_freq: 0.035745
[15:37:41.608] iteration 6230: loss: 0.074674, loss_s1: 0.061580, loss_fp: 0.001747, loss_freq: 0.036467
[15:37:42.236] iteration 6231: loss: 0.149101, loss_s1: 0.087805, loss_fp: 0.001797, loss_freq: 0.116975
[15:37:42.868] iteration 6232: loss: 0.078321, loss_s1: 0.064418, loss_fp: 0.001871, loss_freq: 0.015582
[15:37:43.500] iteration 6233: loss: 0.073090, loss_s1: 0.029484, loss_fp: 0.000584, loss_freq: 0.009899
[15:37:44.133] iteration 6234: loss: 0.085392, loss_s1: 0.059176, loss_fp: 0.000615, loss_freq: 0.024606
[15:37:44.765] iteration 6235: loss: 0.067376, loss_s1: 0.036256, loss_fp: 0.000533, loss_freq: 0.023470
[15:37:45.396] iteration 6236: loss: 0.089281, loss_s1: 0.021009, loss_fp: 0.013070, loss_freq: 0.048861
[15:37:46.025] iteration 6237: loss: 0.089296, loss_s1: 0.052500, loss_fp: 0.008092, loss_freq: 0.024476
[15:37:46.655] iteration 6238: loss: 0.094691, loss_s1: 0.041328, loss_fp: 0.001081, loss_freq: 0.088109
[15:37:47.284] iteration 6239: loss: 0.062210, loss_s1: 0.024632, loss_fp: 0.000435, loss_freq: 0.036814
[15:37:47.915] iteration 6240: loss: 0.111098, loss_s1: 0.022440, loss_fp: 0.001646, loss_freq: 0.012347
[15:37:48.542] iteration 6241: loss: 0.064924, loss_s1: 0.036459, loss_fp: 0.003396, loss_freq: 0.019180
[15:37:49.166] iteration 6242: loss: 0.082505, loss_s1: 0.020827, loss_fp: 0.003040, loss_freq: 0.025610
[15:37:49.810] iteration 6243: loss: 0.097857, loss_s1: 0.031246, loss_fp: 0.000605, loss_freq: 0.040287
[15:37:50.467] iteration 6244: loss: 0.087124, loss_s1: 0.036694, loss_fp: 0.014990, loss_freq: 0.010486
[15:37:51.129] iteration 6245: loss: 0.081273, loss_s1: 0.029433, loss_fp: 0.000969, loss_freq: 0.009270
[15:37:51.785] iteration 6246: loss: 0.151663, loss_s1: 0.090248, loss_fp: 0.002097, loss_freq: 0.038042
[15:37:52.442] iteration 6247: loss: 0.072261, loss_s1: 0.065769, loss_fp: 0.003337, loss_freq: 0.019617
[15:37:53.100] iteration 6248: loss: 0.083901, loss_s1: 0.079170, loss_fp: 0.001168, loss_freq: 0.014475
[15:37:53.750] iteration 6249: loss: 0.110007, loss_s1: 0.076559, loss_fp: 0.001187, loss_freq: 0.059713
[15:37:54.373] iteration 6250: loss: 0.139496, loss_s1: 0.082970, loss_fp: 0.001272, loss_freq: 0.043419
[15:37:54.995] iteration 6251: loss: 0.095459, loss_s1: 0.055942, loss_fp: 0.001615, loss_freq: 0.028857
[15:37:55.621] iteration 6252: loss: 0.084353, loss_s1: 0.036949, loss_fp: 0.001944, loss_freq: 0.047222
[15:37:56.236] iteration 6253: loss: 0.135161, loss_s1: 0.094915, loss_fp: 0.004350, loss_freq: 0.098888
[15:37:56.866] iteration 6254: loss: 0.072480, loss_s1: 0.046917, loss_fp: 0.001318, loss_freq: 0.010233
[15:37:57.498] iteration 6255: loss: 0.079166, loss_s1: 0.014654, loss_fp: 0.012410, loss_freq: 0.047526
[15:37:58.127] iteration 6256: loss: 0.094102, loss_s1: 0.065545, loss_fp: 0.001844, loss_freq: 0.047717
[15:37:58.755] iteration 6257: loss: 0.064194, loss_s1: 0.026024, loss_fp: 0.001479, loss_freq: 0.031355
[15:37:59.386] iteration 6258: loss: 0.166063, loss_s1: 0.077647, loss_fp: 0.004013, loss_freq: 0.062270
[15:38:00.011] iteration 6259: loss: 0.120081, loss_s1: 0.088064, loss_fp: 0.012523, loss_freq: 0.061609
[15:38:00.640] iteration 6260: loss: 0.101160, loss_s1: 0.032800, loss_fp: 0.008378, loss_freq: 0.021523
[15:38:01.265] iteration 6261: loss: 0.145321, loss_s1: 0.046874, loss_fp: 0.006990, loss_freq: 0.051778
[15:38:01.903] iteration 6262: loss: 0.111555, loss_s1: 0.078291, loss_fp: 0.004151, loss_freq: 0.018963
[15:38:02.571] iteration 6263: loss: 0.068025, loss_s1: 0.045473, loss_fp: 0.003268, loss_freq: 0.010075
[15:38:03.231] iteration 6264: loss: 0.100046, loss_s1: 0.072666, loss_fp: 0.002302, loss_freq: 0.021547
[15:38:03.893] iteration 6265: loss: 0.079202, loss_s1: 0.058570, loss_fp: 0.002002, loss_freq: 0.048135
[15:38:04.561] iteration 6266: loss: 0.082334, loss_s1: 0.062088, loss_fp: 0.000870, loss_freq: 0.028890
[15:38:05.199] iteration 6267: loss: 0.073237, loss_s1: 0.022057, loss_fp: 0.001047, loss_freq: 0.029320
[15:38:05.831] iteration 6268: loss: 0.131134, loss_s1: 0.110525, loss_fp: 0.009066, loss_freq: 0.037059
[15:38:06.465] iteration 6269: loss: 0.077425, loss_s1: 0.035905, loss_fp: 0.003379, loss_freq: 0.024263
[15:38:07.120] iteration 6270: loss: 0.114591, loss_s1: 0.067032, loss_fp: 0.006053, loss_freq: 0.070775
[15:38:07.752] iteration 6271: loss: 0.054437, loss_s1: 0.027539, loss_fp: 0.004092, loss_freq: 0.015723
[15:38:08.378] iteration 6272: loss: 0.077166, loss_s1: 0.058689, loss_fp: 0.009328, loss_freq: 0.015910
[15:38:09.000] iteration 6273: loss: 0.055114, loss_s1: 0.003850, loss_fp: 0.001072, loss_freq: 0.008363
[15:38:09.629] iteration 6274: loss: 0.081269, loss_s1: 0.080548, loss_fp: 0.001748, loss_freq: 0.015136
[15:38:10.258] iteration 6275: loss: 0.084537, loss_s1: 0.017390, loss_fp: 0.000632, loss_freq: 0.033536
[15:38:10.885] iteration 6276: loss: 0.089489, loss_s1: 0.028774, loss_fp: 0.000799, loss_freq: 0.073712
[15:38:11.513] iteration 6277: loss: 0.077782, loss_s1: 0.050411, loss_fp: 0.006784, loss_freq: 0.030097
[15:38:12.136] iteration 6278: loss: 0.103224, loss_s1: 0.034117, loss_fp: 0.000955, loss_freq: 0.036549
[15:38:12.759] iteration 6279: loss: 0.128380, loss_s1: 0.091505, loss_fp: 0.005688, loss_freq: 0.070858
[15:38:13.718] iteration 6280: loss: 0.116200, loss_s1: 0.065231, loss_fp: 0.005805, loss_freq: 0.018606
[15:38:14.343] iteration 6281: loss: 0.131188, loss_s1: 0.120687, loss_fp: 0.011632, loss_freq: 0.031847
[15:38:14.969] iteration 6282: loss: 0.138896, loss_s1: 0.031233, loss_fp: 0.005630, loss_freq: 0.023155
[15:38:15.595] iteration 6283: loss: 0.080864, loss_s1: 0.012195, loss_fp: 0.002084, loss_freq: 0.025107
[15:38:16.223] iteration 6284: loss: 0.101765, loss_s1: 0.079283, loss_fp: 0.001715, loss_freq: 0.026455
[15:38:16.848] iteration 6285: loss: 0.183216, loss_s1: 0.084793, loss_fp: 0.003098, loss_freq: 0.040485
[15:38:17.472] iteration 6286: loss: 0.057261, loss_s1: 0.044676, loss_fp: 0.001482, loss_freq: 0.023620
[15:38:18.100] iteration 6287: loss: 0.098270, loss_s1: 0.087917, loss_fp: 0.006007, loss_freq: 0.047464
[15:38:18.729] iteration 6288: loss: 0.057456, loss_s1: 0.025671, loss_fp: 0.004822, loss_freq: 0.014570
[15:38:19.355] iteration 6289: loss: 0.113503, loss_s1: 0.106954, loss_fp: 0.001086, loss_freq: 0.045064
[15:38:19.978] iteration 6290: loss: 0.069353, loss_s1: 0.023344, loss_fp: 0.004387, loss_freq: 0.005220
[15:38:20.603] iteration 6291: loss: 0.117498, loss_s1: 0.077889, loss_fp: 0.005363, loss_freq: 0.042210
[15:38:21.228] iteration 6292: loss: 0.111755, loss_s1: 0.073523, loss_fp: 0.009516, loss_freq: 0.069118
[15:38:21.858] iteration 6293: loss: 0.160108, loss_s1: 0.043363, loss_fp: 0.002403, loss_freq: 0.085447
[15:38:22.482] iteration 6294: loss: 0.086396, loss_s1: 0.055858, loss_fp: 0.002913, loss_freq: 0.027328
[15:38:23.109] iteration 6295: loss: 0.127172, loss_s1: 0.095731, loss_fp: 0.004985, loss_freq: 0.068183
[15:38:23.740] iteration 6296: loss: 0.122110, loss_s1: 0.106483, loss_fp: 0.004527, loss_freq: 0.016902
[15:38:24.367] iteration 6297: loss: 0.077430, loss_s1: 0.046595, loss_fp: 0.007349, loss_freq: 0.025112
[15:38:24.999] iteration 6298: loss: 0.075145, loss_s1: 0.044388, loss_fp: 0.000389, loss_freq: 0.018939
[15:38:25.627] iteration 6299: loss: 0.105833, loss_s1: 0.077442, loss_fp: 0.005302, loss_freq: 0.022154
[15:38:26.257] iteration 6300: loss: 0.075896, loss_s1: 0.054278, loss_fp: 0.002915, loss_freq: 0.025556
[15:38:26.885] iteration 6301: loss: 0.074391, loss_s1: 0.046245, loss_fp: 0.002024, loss_freq: 0.035425
[15:38:27.515] iteration 6302: loss: 0.113311, loss_s1: 0.057878, loss_fp: 0.001868, loss_freq: 0.016005
[15:38:28.144] iteration 6303: loss: 0.129401, loss_s1: 0.112116, loss_fp: 0.014471, loss_freq: 0.040368
[15:38:28.771] iteration 6304: loss: 0.073542, loss_s1: 0.074324, loss_fp: 0.004211, loss_freq: 0.020050
[15:38:29.399] iteration 6305: loss: 0.117281, loss_s1: 0.087839, loss_fp: 0.004416, loss_freq: 0.074562
[15:38:30.025] iteration 6306: loss: 0.118518, loss_s1: 0.095808, loss_fp: 0.001955, loss_freq: 0.028894
[15:38:30.652] iteration 6307: loss: 0.168434, loss_s1: 0.068839, loss_fp: 0.008946, loss_freq: 0.061217
[15:38:31.280] iteration 6308: loss: 0.114803, loss_s1: 0.081941, loss_fp: 0.001443, loss_freq: 0.046777
[15:38:31.906] iteration 6309: loss: 0.108302, loss_s1: 0.055628, loss_fp: 0.001812, loss_freq: 0.018072
[15:38:32.561] iteration 6310: loss: 0.097586, loss_s1: 0.087127, loss_fp: 0.001176, loss_freq: 0.025443
[15:38:33.189] iteration 6311: loss: 0.055733, loss_s1: 0.020580, loss_fp: 0.003509, loss_freq: 0.007351
[15:38:33.815] iteration 6312: loss: 0.073193, loss_s1: 0.041155, loss_fp: 0.001754, loss_freq: 0.023182
[15:38:34.440] iteration 6313: loss: 0.080706, loss_s1: 0.048625, loss_fp: 0.003327, loss_freq: 0.017273
[15:38:35.067] iteration 6314: loss: 0.131957, loss_s1: 0.061661, loss_fp: 0.006528, loss_freq: 0.019091
[15:38:35.731] iteration 6315: loss: 0.137076, loss_s1: 0.048223, loss_fp: 0.007806, loss_freq: 0.019102
[15:38:36.387] iteration 6316: loss: 0.097723, loss_s1: 0.054333, loss_fp: 0.008217, loss_freq: 0.029613
[15:38:37.047] iteration 6317: loss: 0.074606, loss_s1: 0.033922, loss_fp: 0.000975, loss_freq: 0.024949
[15:38:37.702] iteration 6318: loss: 0.140534, loss_s1: 0.074248, loss_fp: 0.001605, loss_freq: 0.103542
[15:38:38.348] iteration 6319: loss: 0.092587, loss_s1: 0.035652, loss_fp: 0.005308, loss_freq: 0.023543
[15:38:38.981] iteration 6320: loss: 0.124225, loss_s1: 0.074135, loss_fp: 0.000635, loss_freq: 0.022725
[15:38:39.609] iteration 6321: loss: 0.051934, loss_s1: 0.028821, loss_fp: 0.001007, loss_freq: 0.017712
[15:38:40.237] iteration 6322: loss: 0.082385, loss_s1: 0.060027, loss_fp: 0.000986, loss_freq: 0.030629
[15:38:40.866] iteration 6323: loss: 0.062741, loss_s1: 0.016028, loss_fp: 0.002024, loss_freq: 0.018695
[15:38:41.495] iteration 6324: loss: 0.093446, loss_s1: 0.051888, loss_fp: 0.001739, loss_freq: 0.057891
[15:38:42.125] iteration 6325: loss: 0.090978, loss_s1: 0.065490, loss_fp: 0.001066, loss_freq: 0.017063
[15:38:42.753] iteration 6326: loss: 0.055032, loss_s1: 0.025509, loss_fp: 0.001454, loss_freq: 0.014112
[15:38:43.381] iteration 6327: loss: 0.059645, loss_s1: 0.039265, loss_fp: 0.000932, loss_freq: 0.018703
[15:38:44.002] iteration 6328: loss: 0.121553, loss_s1: 0.049919, loss_fp: 0.002623, loss_freq: 0.010671
[15:38:44.627] iteration 6329: loss: 0.071723, loss_s1: 0.026979, loss_fp: 0.001786, loss_freq: 0.049621
[15:38:45.259] iteration 6330: loss: 0.084246, loss_s1: 0.072206, loss_fp: 0.002092, loss_freq: 0.038226
[15:38:45.883] iteration 6331: loss: 0.157337, loss_s1: 0.014062, loss_fp: 0.002788, loss_freq: 0.015795
[15:38:46.507] iteration 6332: loss: 0.139716, loss_s1: 0.072103, loss_fp: 0.004149, loss_freq: 0.074095
[15:38:47.135] iteration 6333: loss: 0.090636, loss_s1: 0.066206, loss_fp: 0.003119, loss_freq: 0.035633
[15:38:47.789] iteration 6334: loss: 0.093819, loss_s1: 0.050013, loss_fp: 0.002873, loss_freq: 0.039770
[15:38:48.422] iteration 6335: loss: 0.070068, loss_s1: 0.039581, loss_fp: 0.001836, loss_freq: 0.034562
[15:38:49.048] iteration 6336: loss: 0.065790, loss_s1: 0.038788, loss_fp: 0.000550, loss_freq: 0.008603
[15:38:49.679] iteration 6337: loss: 0.139849, loss_s1: 0.026016, loss_fp: 0.000926, loss_freq: 0.086001
[15:38:50.306] iteration 6338: loss: 0.061935, loss_s1: 0.031380, loss_fp: 0.000484, loss_freq: 0.011434
[15:38:50.931] iteration 6339: loss: 0.094656, loss_s1: 0.066133, loss_fp: 0.002177, loss_freq: 0.034321
[15:38:51.553] iteration 6340: loss: 0.081803, loss_s1: 0.063132, loss_fp: 0.002359, loss_freq: 0.020743
[15:38:52.180] iteration 6341: loss: 0.054993, loss_s1: 0.027192, loss_fp: 0.001386, loss_freq: 0.018482
[15:38:52.812] iteration 6342: loss: 0.108750, loss_s1: 0.085395, loss_fp: 0.001716, loss_freq: 0.021719
[15:38:53.486] iteration 6343: loss: 0.098966, loss_s1: 0.087889, loss_fp: 0.000444, loss_freq: 0.014542
[15:38:54.159] iteration 6344: loss: 0.104599, loss_s1: 0.084263, loss_fp: 0.012069, loss_freq: 0.025511
[15:38:54.818] iteration 6345: loss: 0.089249, loss_s1: 0.023568, loss_fp: 0.003965, loss_freq: 0.087006
[15:38:55.442] iteration 6346: loss: 0.145875, loss_s1: 0.143248, loss_fp: 0.006622, loss_freq: 0.066526
[15:38:56.067] iteration 6347: loss: 0.090781, loss_s1: 0.082335, loss_fp: 0.001856, loss_freq: 0.044528
[15:38:56.691] iteration 6348: loss: 0.099948, loss_s1: 0.090873, loss_fp: 0.007972, loss_freq: 0.032882
[15:38:57.314] iteration 6349: loss: 0.100654, loss_s1: 0.056300, loss_fp: 0.002109, loss_freq: 0.019871
[15:38:57.936] iteration 6350: loss: 0.119574, loss_s1: 0.045557, loss_fp: 0.010865, loss_freq: 0.082121
[15:38:58.558] iteration 6351: loss: 0.107544, loss_s1: 0.076924, loss_fp: 0.005098, loss_freq: 0.051292
[15:38:59.190] iteration 6352: loss: 0.089853, loss_s1: 0.040097, loss_fp: 0.000905, loss_freq: 0.056120
[15:38:59.821] iteration 6353: loss: 0.073315, loss_s1: 0.054118, loss_fp: 0.002759, loss_freq: 0.011724
[15:39:00.453] iteration 6354: loss: 0.102999, loss_s1: 0.086592, loss_fp: 0.003461, loss_freq: 0.034911
[15:39:01.080] iteration 6355: loss: 0.107324, loss_s1: 0.070770, loss_fp: 0.001035, loss_freq: 0.024906
[15:39:01.705] iteration 6356: loss: 0.136688, loss_s1: 0.108559, loss_fp: 0.012169, loss_freq: 0.083561
[15:39:02.332] iteration 6357: loss: 0.092445, loss_s1: 0.080321, loss_fp: 0.003309, loss_freq: 0.017161
[15:39:02.960] iteration 6358: loss: 0.074655, loss_s1: 0.056568, loss_fp: 0.001210, loss_freq: 0.014084
[15:39:03.585] iteration 6359: loss: 0.090536, loss_s1: 0.054669, loss_fp: 0.001868, loss_freq: 0.064877
[15:39:04.214] iteration 6360: loss: 0.113925, loss_s1: 0.064445, loss_fp: 0.003078, loss_freq: 0.075301
[15:39:04.840] iteration 6361: loss: 0.092558, loss_s1: 0.100243, loss_fp: 0.005396, loss_freq: 0.031379
[15:39:05.469] iteration 6362: loss: 0.154271, loss_s1: 0.090946, loss_fp: 0.032047, loss_freq: 0.109975
[15:39:06.098] iteration 6363: loss: 0.137297, loss_s1: 0.068194, loss_fp: 0.006224, loss_freq: 0.037621
[15:39:06.723] iteration 6364: loss: 0.103611, loss_s1: 0.034956, loss_fp: 0.006084, loss_freq: 0.077138
[15:39:07.351] iteration 6365: loss: 0.061570, loss_s1: 0.037726, loss_fp: 0.004860, loss_freq: 0.025208
[15:39:07.976] iteration 6366: loss: 0.119091, loss_s1: 0.070617, loss_fp: 0.000555, loss_freq: 0.068416
[15:39:08.598] iteration 6367: loss: 0.077592, loss_s1: 0.038925, loss_fp: 0.000751, loss_freq: 0.021284
[15:39:09.224] iteration 6368: loss: 0.070963, loss_s1: 0.040476, loss_fp: 0.003387, loss_freq: 0.026115
[15:39:09.850] iteration 6369: loss: 0.099392, loss_s1: 0.044157, loss_fp: 0.002783, loss_freq: 0.020807
[15:39:10.475] iteration 6370: loss: 0.093298, loss_s1: 0.089314, loss_fp: 0.000399, loss_freq: 0.011783
[15:39:11.102] iteration 6371: loss: 0.084688, loss_s1: 0.046164, loss_fp: 0.002317, loss_freq: 0.010927
[15:39:11.724] iteration 6372: loss: 0.119496, loss_s1: 0.037194, loss_fp: 0.000640, loss_freq: 0.024652
[15:39:12.349] iteration 6373: loss: 0.053537, loss_s1: 0.014862, loss_fp: 0.006112, loss_freq: 0.009331
[15:39:12.974] iteration 6374: loss: 0.049003, loss_s1: 0.039547, loss_fp: 0.001807, loss_freq: 0.008186
[15:39:13.598] iteration 6375: loss: 0.056154, loss_s1: 0.029925, loss_fp: 0.005504, loss_freq: 0.009481
[15:39:14.220] iteration 6376: loss: 0.106717, loss_s1: 0.049828, loss_fp: 0.000773, loss_freq: 0.028876
[15:39:14.838] iteration 6377: loss: 0.093648, loss_s1: 0.031233, loss_fp: 0.005933, loss_freq: 0.035188
[15:39:15.461] iteration 6378: loss: 0.086191, loss_s1: 0.080040, loss_fp: 0.003193, loss_freq: 0.009396
[15:39:16.098] iteration 6379: loss: 0.087961, loss_s1: 0.061378, loss_fp: 0.001314, loss_freq: 0.028986
[15:39:16.719] iteration 6380: loss: 0.092365, loss_s1: 0.058870, loss_fp: 0.005708, loss_freq: 0.035282
[15:39:17.341] iteration 6381: loss: 0.152385, loss_s1: 0.098712, loss_fp: 0.001174, loss_freq: 0.035626
[15:39:17.988] iteration 6382: loss: 0.122744, loss_s1: 0.094966, loss_fp: 0.001259, loss_freq: 0.061862
[15:39:18.647] iteration 6383: loss: 0.109588, loss_s1: 0.060955, loss_fp: 0.001368, loss_freq: 0.100599
[15:39:19.305] iteration 6384: loss: 0.101483, loss_s1: 0.023907, loss_fp: 0.002400, loss_freq: 0.027394
[15:39:19.939] iteration 6385: loss: 0.071258, loss_s1: 0.025387, loss_fp: 0.001311, loss_freq: 0.028986
[15:39:20.563] iteration 6386: loss: 0.098009, loss_s1: 0.031278, loss_fp: 0.001137, loss_freq: 0.023941
[15:39:21.195] iteration 6387: loss: 0.134184, loss_s1: 0.068064, loss_fp: 0.002466, loss_freq: 0.058791
[15:39:21.824] iteration 6388: loss: 0.186395, loss_s1: 0.068254, loss_fp: 0.005775, loss_freq: 0.170484
[15:39:22.449] iteration 6389: loss: 0.108449, loss_s1: 0.042122, loss_fp: 0.008848, loss_freq: 0.037766
[15:39:23.074] iteration 6390: loss: 0.132359, loss_s1: 0.018883, loss_fp: 0.001418, loss_freq: 0.070218
[15:39:23.701] iteration 6391: loss: 0.104680, loss_s1: 0.071460, loss_fp: 0.018857, loss_freq: 0.055485
[15:39:24.329] iteration 6392: loss: 0.105645, loss_s1: 0.042236, loss_fp: 0.014339, loss_freq: 0.062572
[15:39:24.979] iteration 6393: loss: 0.108843, loss_s1: 0.066293, loss_fp: 0.000917, loss_freq: 0.057480
[15:39:25.637] iteration 6394: loss: 0.043808, loss_s1: 0.026139, loss_fp: 0.000775, loss_freq: 0.005862
[15:39:26.295] iteration 6395: loss: 0.110220, loss_s1: 0.058968, loss_fp: 0.003381, loss_freq: 0.055205
[15:39:26.949] iteration 6396: loss: 0.097599, loss_s1: 0.066783, loss_fp: 0.006805, loss_freq: 0.032785
[15:39:27.596] iteration 6397: loss: 0.071252, loss_s1: 0.037979, loss_fp: 0.004105, loss_freq: 0.036246
[15:39:28.220] iteration 6398: loss: 0.084503, loss_s1: 0.027956, loss_fp: 0.004668, loss_freq: 0.044704
[15:39:28.841] iteration 6399: loss: 0.106794, loss_s1: 0.057410, loss_fp: 0.010087, loss_freq: 0.089919
[15:39:29.462] iteration 6400: loss: 0.099711, loss_s1: 0.023994, loss_fp: 0.007922, loss_freq: 0.085520
[15:39:32.530] iteration 6400 : mean_dice : 0.634923
[15:39:33.184] iteration 6401: loss: 0.133704, loss_s1: 0.034698, loss_fp: 0.000625, loss_freq: 0.047966
[15:39:33.806] iteration 6402: loss: 0.067008, loss_s1: 0.030462, loss_fp: 0.002038, loss_freq: 0.032167
[15:39:34.431] iteration 6403: loss: 0.074077, loss_s1: 0.043949, loss_fp: 0.003705, loss_freq: 0.027930
[15:39:35.056] iteration 6404: loss: 0.115097, loss_s1: 0.054721, loss_fp: 0.002386, loss_freq: 0.039036
[15:39:35.679] iteration 6405: loss: 0.103746, loss_s1: 0.031303, loss_fp: 0.011823, loss_freq: 0.017387
[15:39:36.302] iteration 6406: loss: 0.062891, loss_s1: 0.024056, loss_fp: 0.000935, loss_freq: 0.010579
[15:39:36.925] iteration 6407: loss: 0.285848, loss_s1: 0.254536, loss_fp: 0.015960, loss_freq: 0.070115
[15:39:37.549] iteration 6408: loss: 0.088214, loss_s1: 0.045711, loss_fp: 0.001604, loss_freq: 0.010659
[15:39:38.176] iteration 6409: loss: 0.117326, loss_s1: 0.108072, loss_fp: 0.001735, loss_freq: 0.027691
[15:39:38.801] iteration 6410: loss: 0.112240, loss_s1: 0.062281, loss_fp: 0.002691, loss_freq: 0.100202
[15:39:39.430] iteration 6411: loss: 0.127002, loss_s1: 0.104619, loss_fp: 0.001927, loss_freq: 0.061684
[15:39:40.056] iteration 6412: loss: 0.123705, loss_s1: 0.093747, loss_fp: 0.009028, loss_freq: 0.049533
[15:39:40.679] iteration 6413: loss: 0.122378, loss_s1: 0.135117, loss_fp: 0.009875, loss_freq: 0.023975
[15:39:41.304] iteration 6414: loss: 0.112875, loss_s1: 0.084330, loss_fp: 0.011212, loss_freq: 0.055286
[15:39:41.930] iteration 6415: loss: 0.074578, loss_s1: 0.066176, loss_fp: 0.002229, loss_freq: 0.027634
[15:39:42.552] iteration 6416: loss: 0.100965, loss_s1: 0.067090, loss_fp: 0.001808, loss_freq: 0.029685
[15:39:43.199] iteration 6417: loss: 0.090412, loss_s1: 0.051097, loss_fp: 0.001653, loss_freq: 0.036845
[15:39:43.872] iteration 6418: loss: 0.110638, loss_s1: 0.078160, loss_fp: 0.002198, loss_freq: 0.031457
[15:39:44.542] iteration 6419: loss: 0.115763, loss_s1: 0.086663, loss_fp: 0.002159, loss_freq: 0.039274
[15:39:45.205] iteration 6420: loss: 0.150479, loss_s1: 0.108838, loss_fp: 0.003006, loss_freq: 0.078506
[15:39:45.869] iteration 6421: loss: 0.087477, loss_s1: 0.041392, loss_fp: 0.004879, loss_freq: 0.016344
[15:39:46.533] iteration 6422: loss: 0.095534, loss_s1: 0.044494, loss_fp: 0.004427, loss_freq: 0.027789
[15:39:47.207] iteration 6423: loss: 0.124382, loss_s1: 0.093760, loss_fp: 0.005450, loss_freq: 0.027496
[15:39:47.834] iteration 6424: loss: 0.065901, loss_s1: 0.044149, loss_fp: 0.013798, loss_freq: 0.009828
[15:39:48.456] iteration 6425: loss: 0.073377, loss_s1: 0.024312, loss_fp: 0.001385, loss_freq: 0.022112
[15:39:49.078] iteration 6426: loss: 0.099162, loss_s1: 0.075392, loss_fp: 0.002531, loss_freq: 0.060442
[15:39:49.703] iteration 6427: loss: 0.083429, loss_s1: 0.082463, loss_fp: 0.003508, loss_freq: 0.014864
[15:39:50.326] iteration 6428: loss: 0.069763, loss_s1: 0.034464, loss_fp: 0.004471, loss_freq: 0.025925
[15:39:50.952] iteration 6429: loss: 0.172579, loss_s1: 0.127669, loss_fp: 0.001270, loss_freq: 0.046810
[15:39:51.577] iteration 6430: loss: 0.137265, loss_s1: 0.057068, loss_fp: 0.009600, loss_freq: 0.072809
[15:39:52.230] iteration 6431: loss: 0.150964, loss_s1: 0.124028, loss_fp: 0.025644, loss_freq: 0.074995
[15:39:52.867] iteration 6432: loss: 0.063936, loss_s1: 0.035842, loss_fp: 0.000756, loss_freq: 0.013650
[15:39:53.491] iteration 6433: loss: 0.087213, loss_s1: 0.021961, loss_fp: 0.001599, loss_freq: 0.009449
[15:39:54.114] iteration 6434: loss: 0.082522, loss_s1: 0.018976, loss_fp: 0.002360, loss_freq: 0.010907
[15:39:54.738] iteration 6435: loss: 0.089858, loss_s1: 0.075457, loss_fp: 0.001234, loss_freq: 0.023291
[15:39:55.371] iteration 6436: loss: 0.061148, loss_s1: 0.018766, loss_fp: 0.000993, loss_freq: 0.020199
[15:39:56.000] iteration 6437: loss: 0.163898, loss_s1: 0.108706, loss_fp: 0.001693, loss_freq: 0.066529
[15:39:56.621] iteration 6438: loss: 0.123336, loss_s1: 0.085528, loss_fp: 0.012318, loss_freq: 0.052747
[15:39:57.243] iteration 6439: loss: 0.114724, loss_s1: 0.080009, loss_fp: 0.000250, loss_freq: 0.025018
[15:39:57.868] iteration 6440: loss: 0.147402, loss_s1: 0.139460, loss_fp: 0.001820, loss_freq: 0.055467
[15:39:58.828] iteration 6441: loss: 0.078268, loss_s1: 0.061192, loss_fp: 0.001466, loss_freq: 0.008963
[15:39:59.493] iteration 6442: loss: 0.119640, loss_s1: 0.075706, loss_fp: 0.006008, loss_freq: 0.033135
[15:40:00.161] iteration 6443: loss: 0.152910, loss_s1: 0.074209, loss_fp: 0.001299, loss_freq: 0.044115
[15:40:00.821] iteration 6444: loss: 0.109942, loss_s1: 0.027780, loss_fp: 0.000922, loss_freq: 0.033945
[15:40:01.449] iteration 6445: loss: 0.095469, loss_s1: 0.062498, loss_fp: 0.014390, loss_freq: 0.039514
[15:40:02.082] iteration 6446: loss: 0.140819, loss_s1: 0.040985, loss_fp: 0.003859, loss_freq: 0.057879
[15:40:02.712] iteration 6447: loss: 0.069255, loss_s1: 0.049978, loss_fp: 0.007670, loss_freq: 0.016109
[15:40:03.381] iteration 6448: loss: 0.139878, loss_s1: 0.095800, loss_fp: 0.001393, loss_freq: 0.061021
[15:40:04.003] iteration 6449: loss: 0.101221, loss_s1: 0.062477, loss_fp: 0.002297, loss_freq: 0.070413
[15:40:04.635] iteration 6450: loss: 0.136288, loss_s1: 0.077828, loss_fp: 0.002576, loss_freq: 0.105139
[15:40:05.275] iteration 6451: loss: 0.112509, loss_s1: 0.040271, loss_fp: 0.000595, loss_freq: 0.021440
[15:40:05.900] iteration 6452: loss: 0.109355, loss_s1: 0.042661, loss_fp: 0.003829, loss_freq: 0.070453
[15:40:06.542] iteration 6453: loss: 0.094558, loss_s1: 0.035993, loss_fp: 0.001177, loss_freq: 0.075233
[15:40:07.174] iteration 6454: loss: 0.119060, loss_s1: 0.029569, loss_fp: 0.000389, loss_freq: 0.053544
[15:40:07.801] iteration 6455: loss: 0.057384, loss_s1: 0.027116, loss_fp: 0.001598, loss_freq: 0.014018
[15:40:08.435] iteration 6456: loss: 0.142132, loss_s1: 0.161057, loss_fp: 0.000956, loss_freq: 0.042664
[15:40:09.060] iteration 6457: loss: 0.119572, loss_s1: 0.048998, loss_fp: 0.001587, loss_freq: 0.018938
[15:40:09.681] iteration 6458: loss: 0.101402, loss_s1: 0.070017, loss_fp: 0.002194, loss_freq: 0.030160
[15:40:10.318] iteration 6459: loss: 0.123792, loss_s1: 0.083025, loss_fp: 0.001478, loss_freq: 0.038022
[15:40:10.946] iteration 6460: loss: 0.080978, loss_s1: 0.024140, loss_fp: 0.002806, loss_freq: 0.049024
[15:40:11.585] iteration 6461: loss: 0.080246, loss_s1: 0.051013, loss_fp: 0.002840, loss_freq: 0.012563
[15:40:12.215] iteration 6462: loss: 0.084281, loss_s1: 0.032126, loss_fp: 0.000833, loss_freq: 0.022799
[15:40:12.839] iteration 6463: loss: 0.108134, loss_s1: 0.040119, loss_fp: 0.002001, loss_freq: 0.016934
[15:40:13.466] iteration 6464: loss: 0.145845, loss_s1: 0.089723, loss_fp: 0.005998, loss_freq: 0.104091
[15:40:14.094] iteration 6465: loss: 0.045759, loss_s1: 0.015513, loss_fp: 0.000497, loss_freq: 0.028753
[15:40:14.725] iteration 6466: loss: 0.085992, loss_s1: 0.049088, loss_fp: 0.001610, loss_freq: 0.026808
[15:40:15.353] iteration 6467: loss: 0.091527, loss_s1: 0.032737, loss_fp: 0.005365, loss_freq: 0.045354
[15:40:15.976] iteration 6468: loss: 0.189319, loss_s1: 0.115360, loss_fp: 0.007580, loss_freq: 0.059506
[15:40:16.606] iteration 6469: loss: 0.084594, loss_s1: 0.059267, loss_fp: 0.004750, loss_freq: 0.033472
[15:40:17.229] iteration 6470: loss: 0.050534, loss_s1: 0.022010, loss_fp: 0.001823, loss_freq: 0.011861
[15:40:17.854] iteration 6471: loss: 0.066095, loss_s1: 0.055711, loss_fp: 0.002565, loss_freq: 0.008546
[15:40:18.484] iteration 6472: loss: 0.107657, loss_s1: 0.038986, loss_fp: 0.004217, loss_freq: 0.035880
[15:40:19.113] iteration 6473: loss: 0.064829, loss_s1: 0.043716, loss_fp: 0.003287, loss_freq: 0.023580
[15:40:19.735] iteration 6474: loss: 0.080457, loss_s1: 0.050266, loss_fp: 0.000669, loss_freq: 0.028060
[15:40:20.360] iteration 6475: loss: 0.131895, loss_s1: 0.040654, loss_fp: 0.003312, loss_freq: 0.041027
[15:40:20.990] iteration 6476: loss: 0.121621, loss_s1: 0.099735, loss_fp: 0.004837, loss_freq: 0.039570
[15:40:21.614] iteration 6477: loss: 0.145796, loss_s1: 0.083140, loss_fp: 0.013383, loss_freq: 0.022692
[15:40:22.244] iteration 6478: loss: 0.069233, loss_s1: 0.022669, loss_fp: 0.002106, loss_freq: 0.029782
[15:40:22.866] iteration 6479: loss: 0.099043, loss_s1: 0.074322, loss_fp: 0.003400, loss_freq: 0.022776
[15:40:23.487] iteration 6480: loss: 0.096756, loss_s1: 0.043861, loss_fp: 0.002873, loss_freq: 0.046508
[15:40:24.111] iteration 6481: loss: 0.099989, loss_s1: 0.035463, loss_fp: 0.003069, loss_freq: 0.014930
[15:40:24.737] iteration 6482: loss: 0.090639, loss_s1: 0.062240, loss_fp: 0.012464, loss_freq: 0.036171
[15:40:25.361] iteration 6483: loss: 0.113317, loss_s1: 0.089559, loss_fp: 0.000935, loss_freq: 0.071836
[15:40:25.984] iteration 6484: loss: 0.081897, loss_s1: 0.048304, loss_fp: 0.002300, loss_freq: 0.029109
[15:40:26.611] iteration 6485: loss: 0.107778, loss_s1: 0.079664, loss_fp: 0.001391, loss_freq: 0.069780
[15:40:27.243] iteration 6486: loss: 0.095247, loss_s1: 0.051135, loss_fp: 0.001557, loss_freq: 0.047493
[15:40:27.865] iteration 6487: loss: 0.094123, loss_s1: 0.060945, loss_fp: 0.004704, loss_freq: 0.012264
[15:40:28.490] iteration 6488: loss: 0.088293, loss_s1: 0.037128, loss_fp: 0.002403, loss_freq: 0.060816
[15:40:29.117] iteration 6489: loss: 0.109377, loss_s1: 0.059182, loss_fp: 0.001199, loss_freq: 0.022909
[15:40:29.737] iteration 6490: loss: 0.083773, loss_s1: 0.045735, loss_fp: 0.001170, loss_freq: 0.038266
[15:40:30.362] iteration 6491: loss: 0.097998, loss_s1: 0.051187, loss_fp: 0.002248, loss_freq: 0.076196
[15:40:30.984] iteration 6492: loss: 0.118026, loss_s1: 0.038938, loss_fp: 0.001227, loss_freq: 0.008537
[15:40:31.609] iteration 6493: loss: 0.092661, loss_s1: 0.050610, loss_fp: 0.000883, loss_freq: 0.046270
[15:40:32.232] iteration 6494: loss: 0.144141, loss_s1: 0.069194, loss_fp: 0.007106, loss_freq: 0.018183
[15:40:32.853] iteration 6495: loss: 0.075907, loss_s1: 0.013080, loss_fp: 0.000704, loss_freq: 0.018021
[15:40:33.478] iteration 6496: loss: 0.131712, loss_s1: 0.122821, loss_fp: 0.001411, loss_freq: 0.057507
[15:40:34.107] iteration 6497: loss: 0.062723, loss_s1: 0.031266, loss_fp: 0.002283, loss_freq: 0.015213
[15:40:34.740] iteration 6498: loss: 0.166822, loss_s1: 0.105478, loss_fp: 0.002968, loss_freq: 0.113073
[15:40:35.406] iteration 6499: loss: 0.055199, loss_s1: 0.038266, loss_fp: 0.001554, loss_freq: 0.005550
[15:40:36.059] iteration 6500: loss: 0.055052, loss_s1: 0.032191, loss_fp: 0.001872, loss_freq: 0.018448
[15:40:36.724] iteration 6501: loss: 0.056454, loss_s1: 0.024450, loss_fp: 0.001347, loss_freq: 0.025820
[15:40:37.366] iteration 6502: loss: 0.064031, loss_s1: 0.033536, loss_fp: 0.001601, loss_freq: 0.025848
[15:40:37.990] iteration 6503: loss: 0.095313, loss_s1: 0.058205, loss_fp: 0.003211, loss_freq: 0.026152
[15:40:38.610] iteration 6504: loss: 0.099889, loss_s1: 0.084876, loss_fp: 0.009002, loss_freq: 0.013002
[15:40:39.237] iteration 6505: loss: 0.076586, loss_s1: 0.054879, loss_fp: 0.000890, loss_freq: 0.009969
[15:40:39.859] iteration 6506: loss: 0.085438, loss_s1: 0.024366, loss_fp: 0.001061, loss_freq: 0.075533
[15:40:40.488] iteration 6507: loss: 0.099196, loss_s1: 0.071634, loss_fp: 0.001765, loss_freq: 0.039937
[15:40:41.120] iteration 6508: loss: 0.071721, loss_s1: 0.046676, loss_fp: 0.002686, loss_freq: 0.044496
[15:40:41.748] iteration 6509: loss: 0.095255, loss_s1: 0.050015, loss_fp: 0.004580, loss_freq: 0.031603
[15:40:42.372] iteration 6510: loss: 0.140859, loss_s1: 0.074609, loss_fp: 0.004919, loss_freq: 0.063758
[15:40:43.005] iteration 6511: loss: 0.127278, loss_s1: 0.052742, loss_fp: 0.007739, loss_freq: 0.096148
[15:40:43.633] iteration 6512: loss: 0.130734, loss_s1: 0.100272, loss_fp: 0.006239, loss_freq: 0.065402
[15:40:44.256] iteration 6513: loss: 0.096166, loss_s1: 0.059715, loss_fp: 0.003277, loss_freq: 0.032299
[15:40:44.890] iteration 6514: loss: 0.063468, loss_s1: 0.029818, loss_fp: 0.001303, loss_freq: 0.021392
[15:40:45.514] iteration 6515: loss: 0.093255, loss_s1: 0.071179, loss_fp: 0.000775, loss_freq: 0.041532
[15:40:46.184] iteration 6516: loss: 0.152032, loss_s1: 0.053789, loss_fp: 0.001137, loss_freq: 0.082214
[15:40:46.847] iteration 6517: loss: 0.131491, loss_s1: 0.074918, loss_fp: 0.008566, loss_freq: 0.087006
[15:40:47.506] iteration 6518: loss: 0.075213, loss_s1: 0.059455, loss_fp: 0.003075, loss_freq: 0.022318
[15:40:48.155] iteration 6519: loss: 0.048462, loss_s1: 0.011165, loss_fp: 0.003058, loss_freq: 0.027489
[15:40:48.780] iteration 6520: loss: 0.098915, loss_s1: 0.085020, loss_fp: 0.000960, loss_freq: 0.040468
[15:40:49.406] iteration 6521: loss: 0.108479, loss_s1: 0.097369, loss_fp: 0.004324, loss_freq: 0.028142
[15:40:50.033] iteration 6522: loss: 0.125153, loss_s1: 0.123394, loss_fp: 0.005335, loss_freq: 0.038754
[15:40:50.656] iteration 6523: loss: 0.135384, loss_s1: 0.116697, loss_fp: 0.003009, loss_freq: 0.065817
[15:40:51.282] iteration 6524: loss: 0.135837, loss_s1: 0.070217, loss_fp: 0.010042, loss_freq: 0.018858
[15:40:51.904] iteration 6525: loss: 0.167652, loss_s1: 0.139986, loss_fp: 0.005301, loss_freq: 0.059166
[15:40:52.528] iteration 6526: loss: 0.062452, loss_s1: 0.042404, loss_fp: 0.001026, loss_freq: 0.024006
[15:40:53.152] iteration 6527: loss: 0.180028, loss_s1: 0.070086, loss_fp: 0.011382, loss_freq: 0.058143
[15:40:53.775] iteration 6528: loss: 0.072015, loss_s1: 0.042353, loss_fp: 0.004717, loss_freq: 0.027959
[15:40:54.395] iteration 6529: loss: 0.082867, loss_s1: 0.054024, loss_fp: 0.002436, loss_freq: 0.025957
[15:40:55.018] iteration 6530: loss: 0.087466, loss_s1: 0.028769, loss_fp: 0.010000, loss_freq: 0.019473
[15:40:55.651] iteration 6531: loss: 0.077058, loss_s1: 0.029648, loss_fp: 0.001414, loss_freq: 0.006977
[15:40:56.285] iteration 6532: loss: 0.087212, loss_s1: 0.067869, loss_fp: 0.001706, loss_freq: 0.019442
[15:40:57.001] iteration 6533: loss: 0.139053, loss_s1: 0.059866, loss_fp: 0.002383, loss_freq: 0.021335
[15:40:57.636] iteration 6534: loss: 0.098201, loss_s1: 0.038333, loss_fp: 0.011060, loss_freq: 0.025141
[15:40:58.263] iteration 6535: loss: 0.098855, loss_s1: 0.094787, loss_fp: 0.001034, loss_freq: 0.045655
[15:40:58.886] iteration 6536: loss: 0.078279, loss_s1: 0.047974, loss_fp: 0.003046, loss_freq: 0.041976
[15:40:59.510] iteration 6537: loss: 0.060948, loss_s1: 0.017408, loss_fp: 0.001582, loss_freq: 0.021017
[15:41:00.138] iteration 6538: loss: 0.076928, loss_s1: 0.026484, loss_fp: 0.000862, loss_freq: 0.031068
[15:41:00.768] iteration 6539: loss: 0.164122, loss_s1: 0.164955, loss_fp: 0.007892, loss_freq: 0.033523
[15:41:01.393] iteration 6540: loss: 0.063222, loss_s1: 0.040859, loss_fp: 0.005589, loss_freq: 0.021689
[15:41:02.015] iteration 6541: loss: 0.111513, loss_s1: 0.065313, loss_fp: 0.001168, loss_freq: 0.078506
[15:41:02.640] iteration 6542: loss: 0.118383, loss_s1: 0.039507, loss_fp: 0.003365, loss_freq: 0.077731
[15:41:03.262] iteration 6543: loss: 0.111252, loss_s1: 0.070356, loss_fp: 0.003446, loss_freq: 0.033216
[15:41:03.888] iteration 6544: loss: 0.141772, loss_s1: 0.110695, loss_fp: 0.001488, loss_freq: 0.094417
[15:41:04.512] iteration 6545: loss: 0.109430, loss_s1: 0.047779, loss_fp: 0.002683, loss_freq: 0.022114
[15:41:05.142] iteration 6546: loss: 0.068818, loss_s1: 0.029600, loss_fp: 0.001366, loss_freq: 0.031152
[15:41:05.775] iteration 6547: loss: 0.104365, loss_s1: 0.022042, loss_fp: 0.000533, loss_freq: 0.023210
[15:41:06.403] iteration 6548: loss: 0.131993, loss_s1: 0.067388, loss_fp: 0.008227, loss_freq: 0.067278
[15:41:07.035] iteration 6549: loss: 0.297761, loss_s1: 0.226265, loss_fp: 0.012740, loss_freq: 0.218581
[15:41:07.665] iteration 6550: loss: 0.093165, loss_s1: 0.048036, loss_fp: 0.000944, loss_freq: 0.034770
[15:41:08.291] iteration 6551: loss: 0.124610, loss_s1: 0.033676, loss_fp: 0.003242, loss_freq: 0.073665
[15:41:08.917] iteration 6552: loss: 0.088566, loss_s1: 0.067627, loss_fp: 0.006397, loss_freq: 0.044639
[15:41:09.545] iteration 6553: loss: 0.112767, loss_s1: 0.069238, loss_fp: 0.006815, loss_freq: 0.068877
[15:41:10.170] iteration 6554: loss: 0.104619, loss_s1: 0.070252, loss_fp: 0.001454, loss_freq: 0.050540
[15:41:10.797] iteration 6555: loss: 0.057035, loss_s1: 0.010868, loss_fp: 0.000489, loss_freq: 0.003059
[15:41:11.425] iteration 6556: loss: 0.109646, loss_s1: 0.068226, loss_fp: 0.012125, loss_freq: 0.051223
[15:41:12.056] iteration 6557: loss: 0.101729, loss_s1: 0.090496, loss_fp: 0.006478, loss_freq: 0.044525
[15:41:12.685] iteration 6558: loss: 0.081716, loss_s1: 0.022552, loss_fp: 0.000561, loss_freq: 0.070902
[15:41:13.311] iteration 6559: loss: 0.089898, loss_s1: 0.035913, loss_fp: 0.001022, loss_freq: 0.036560
[15:41:13.939] iteration 6560: loss: 0.121302, loss_s1: 0.121746, loss_fp: 0.001369, loss_freq: 0.065889
[15:41:14.565] iteration 6561: loss: 0.089678, loss_s1: 0.044165, loss_fp: 0.000795, loss_freq: 0.071027
[15:41:15.190] iteration 6562: loss: 0.109503, loss_s1: 0.010119, loss_fp: 0.002434, loss_freq: 0.013204
[15:41:15.821] iteration 6563: loss: 0.096899, loss_s1: 0.067123, loss_fp: 0.002319, loss_freq: 0.018720
[15:41:16.451] iteration 6564: loss: 0.090714, loss_s1: 0.065309, loss_fp: 0.037226, loss_freq: 0.011883
[15:41:17.078] iteration 6565: loss: 0.079683, loss_s1: 0.030448, loss_fp: 0.001987, loss_freq: 0.031985
[15:41:17.705] iteration 6566: loss: 0.062491, loss_s1: 0.018103, loss_fp: 0.000635, loss_freq: 0.014071
[15:41:18.331] iteration 6567: loss: 0.071125, loss_s1: 0.030355, loss_fp: 0.007980, loss_freq: 0.015689
[15:41:18.958] iteration 6568: loss: 0.201275, loss_s1: 0.141039, loss_fp: 0.002530, loss_freq: 0.089821
[15:41:19.586] iteration 6569: loss: 0.102259, loss_s1: 0.065450, loss_fp: 0.006364, loss_freq: 0.017773
[15:41:20.241] iteration 6570: loss: 0.092944, loss_s1: 0.093634, loss_fp: 0.002154, loss_freq: 0.017669
[15:41:20.900] iteration 6571: loss: 0.101708, loss_s1: 0.062652, loss_fp: 0.001876, loss_freq: 0.074255
[15:41:21.523] iteration 6572: loss: 0.137348, loss_s1: 0.070999, loss_fp: 0.006567, loss_freq: 0.112030
[15:41:22.149] iteration 6573: loss: 0.085794, loss_s1: 0.038887, loss_fp: 0.001737, loss_freq: 0.020480
[15:41:22.775] iteration 6574: loss: 0.086441, loss_s1: 0.026849, loss_fp: 0.006738, loss_freq: 0.054649
[15:41:23.400] iteration 6575: loss: 0.108120, loss_s1: 0.097488, loss_fp: 0.002112, loss_freq: 0.046852
[15:41:24.023] iteration 6576: loss: 0.096888, loss_s1: 0.067356, loss_fp: 0.007762, loss_freq: 0.049666
[15:41:24.648] iteration 6577: loss: 0.068338, loss_s1: 0.023422, loss_fp: 0.000905, loss_freq: 0.021581
[15:41:25.270] iteration 6578: loss: 0.067583, loss_s1: 0.037481, loss_fp: 0.001640, loss_freq: 0.030621
[15:41:25.892] iteration 6579: loss: 0.065729, loss_s1: 0.036226, loss_fp: 0.005628, loss_freq: 0.028127
[15:41:26.517] iteration 6580: loss: 0.143380, loss_s1: 0.106827, loss_fp: 0.002188, loss_freq: 0.062580
[15:41:27.148] iteration 6581: loss: 0.124430, loss_s1: 0.100814, loss_fp: 0.001991, loss_freq: 0.048078
[15:41:27.772] iteration 6582: loss: 0.072973, loss_s1: 0.035522, loss_fp: 0.008114, loss_freq: 0.026074
[15:41:28.394] iteration 6583: loss: 0.095304, loss_s1: 0.041564, loss_fp: 0.005011, loss_freq: 0.041034
[15:41:29.017] iteration 6584: loss: 0.102248, loss_s1: 0.079698, loss_fp: 0.003418, loss_freq: 0.018233
[15:41:29.644] iteration 6585: loss: 0.070057, loss_s1: 0.028587, loss_fp: 0.004679, loss_freq: 0.004467
[15:41:30.267] iteration 6586: loss: 0.116595, loss_s1: 0.089357, loss_fp: 0.012764, loss_freq: 0.009697
[15:41:30.894] iteration 6587: loss: 0.113746, loss_s1: 0.077720, loss_fp: 0.004584, loss_freq: 0.074540
[15:41:31.518] iteration 6588: loss: 0.098792, loss_s1: 0.089864, loss_fp: 0.002519, loss_freq: 0.027590
[15:41:32.143] iteration 6589: loss: 0.060367, loss_s1: 0.023579, loss_fp: 0.000990, loss_freq: 0.018893
[15:41:32.767] iteration 6590: loss: 0.092599, loss_s1: 0.076842, loss_fp: 0.012185, loss_freq: 0.031363
[15:41:33.390] iteration 6591: loss: 0.092766, loss_s1: 0.038685, loss_fp: 0.002561, loss_freq: 0.055726
[15:41:34.011] iteration 6592: loss: 0.150579, loss_s1: 0.119986, loss_fp: 0.004251, loss_freq: 0.075745
[15:41:34.639] iteration 6593: loss: 0.052794, loss_s1: 0.034997, loss_fp: 0.002789, loss_freq: 0.015059
[15:41:35.265] iteration 6594: loss: 0.093257, loss_s1: 0.066613, loss_fp: 0.004196, loss_freq: 0.034424
[15:41:35.889] iteration 6595: loss: 0.081345, loss_s1: 0.026153, loss_fp: 0.003507, loss_freq: 0.036220
[15:41:36.514] iteration 6596: loss: 0.087805, loss_s1: 0.026375, loss_fp: 0.001674, loss_freq: 0.020236
[15:41:37.143] iteration 6597: loss: 0.126876, loss_s1: 0.028698, loss_fp: 0.000470, loss_freq: 0.014756
[15:41:37.772] iteration 6598: loss: 0.102290, loss_s1: 0.047620, loss_fp: 0.001368, loss_freq: 0.067821
[15:41:38.396] iteration 6599: loss: 0.099999, loss_s1: 0.067842, loss_fp: 0.003819, loss_freq: 0.045898
[15:41:39.017] iteration 6600: loss: 0.077908, loss_s1: 0.023817, loss_fp: 0.014085, loss_freq: 0.010950
[15:41:42.320] iteration 6600 : mean_dice : 0.653431
[15:41:42.963] iteration 6601: loss: 0.080616, loss_s1: 0.050346, loss_fp: 0.004129, loss_freq: 0.023486
[15:41:43.972] iteration 6602: loss: 0.076583, loss_s1: 0.058473, loss_fp: 0.000892, loss_freq: 0.027139
[15:41:44.644] iteration 6603: loss: 0.115265, loss_s1: 0.051944, loss_fp: 0.000838, loss_freq: 0.065236
[15:41:45.308] iteration 6604: loss: 0.092948, loss_s1: 0.043704, loss_fp: 0.001524, loss_freq: 0.041226
[15:41:45.964] iteration 6605: loss: 0.059735, loss_s1: 0.018513, loss_fp: 0.003532, loss_freq: 0.018171
[15:41:46.616] iteration 6606: loss: 0.091357, loss_s1: 0.028936, loss_fp: 0.001269, loss_freq: 0.030766
[15:41:47.245] iteration 6607: loss: 0.232276, loss_s1: 0.127141, loss_fp: 0.002474, loss_freq: 0.088250
[15:41:47.878] iteration 6608: loss: 0.057264, loss_s1: 0.035529, loss_fp: 0.006442, loss_freq: 0.016352
[15:41:48.511] iteration 6609: loss: 0.082786, loss_s1: 0.065056, loss_fp: 0.002552, loss_freq: 0.042653
[15:41:49.140] iteration 6610: loss: 0.091037, loss_s1: 0.057138, loss_fp: 0.021856, loss_freq: 0.024178
[15:41:49.776] iteration 6611: loss: 0.146710, loss_s1: 0.154540, loss_fp: 0.003318, loss_freq: 0.043311
[15:41:50.400] iteration 6612: loss: 0.067567, loss_s1: 0.025775, loss_fp: 0.001061, loss_freq: 0.016229
[15:41:51.027] iteration 6613: loss: 0.116586, loss_s1: 0.068883, loss_fp: 0.003982, loss_freq: 0.070492
[15:41:51.652] iteration 6614: loss: 0.100745, loss_s1: 0.057528, loss_fp: 0.012272, loss_freq: 0.059501
[15:41:52.275] iteration 6615: loss: 0.103164, loss_s1: 0.046001, loss_fp: 0.003538, loss_freq: 0.028491
[15:41:52.898] iteration 6616: loss: 0.075176, loss_s1: 0.045362, loss_fp: 0.001311, loss_freq: 0.034973
[15:41:53.520] iteration 6617: loss: 0.100578, loss_s1: 0.028321, loss_fp: 0.001588, loss_freq: 0.070760
[15:41:54.147] iteration 6618: loss: 0.119852, loss_s1: 0.074272, loss_fp: 0.005505, loss_freq: 0.019211
[15:41:54.775] iteration 6619: loss: 0.075435, loss_s1: 0.051828, loss_fp: 0.006498, loss_freq: 0.015157
[15:41:55.406] iteration 6620: loss: 0.142497, loss_s1: 0.041812, loss_fp: 0.003059, loss_freq: 0.014456
[15:41:56.032] iteration 6621: loss: 0.140879, loss_s1: 0.129433, loss_fp: 0.003866, loss_freq: 0.035624
[15:41:56.661] iteration 6622: loss: 0.076988, loss_s1: 0.049331, loss_fp: 0.005177, loss_freq: 0.023549
[15:41:57.289] iteration 6623: loss: 0.091243, loss_s1: 0.042831, loss_fp: 0.000927, loss_freq: 0.023779
[15:41:57.914] iteration 6624: loss: 0.120822, loss_s1: 0.083896, loss_fp: 0.000249, loss_freq: 0.047314
[15:41:58.546] iteration 6625: loss: 0.166246, loss_s1: 0.137207, loss_fp: 0.006036, loss_freq: 0.135749
[15:41:59.173] iteration 6626: loss: 0.064842, loss_s1: 0.022871, loss_fp: 0.001759, loss_freq: 0.037545
[15:41:59.799] iteration 6627: loss: 0.102349, loss_s1: 0.067718, loss_fp: 0.002897, loss_freq: 0.034230
[15:42:00.425] iteration 6628: loss: 0.099547, loss_s1: 0.042981, loss_fp: 0.001483, loss_freq: 0.078426
[15:42:01.049] iteration 6629: loss: 0.116982, loss_s1: 0.079562, loss_fp: 0.009910, loss_freq: 0.048260
[15:42:01.675] iteration 6630: loss: 0.090602, loss_s1: 0.069038, loss_fp: 0.002266, loss_freq: 0.032650
[15:42:02.299] iteration 6631: loss: 0.065301, loss_s1: 0.030718, loss_fp: 0.002737, loss_freq: 0.022998
[15:42:02.927] iteration 6632: loss: 0.081932, loss_s1: 0.036356, loss_fp: 0.001224, loss_freq: 0.008733
[15:42:03.554] iteration 6633: loss: 0.103973, loss_s1: 0.064377, loss_fp: 0.005603, loss_freq: 0.015810
[15:42:04.178] iteration 6634: loss: 0.061192, loss_s1: 0.043650, loss_fp: 0.002139, loss_freq: 0.021849
[15:42:04.801] iteration 6635: loss: 0.056921, loss_s1: 0.036313, loss_fp: 0.001530, loss_freq: 0.021762
[15:42:05.427] iteration 6636: loss: 0.150940, loss_s1: 0.044676, loss_fp: 0.009977, loss_freq: 0.051344
[15:42:06.061] iteration 6637: loss: 0.071415, loss_s1: 0.051556, loss_fp: 0.005042, loss_freq: 0.015884
[15:42:06.713] iteration 6638: loss: 0.122375, loss_s1: 0.055860, loss_fp: 0.001857, loss_freq: 0.116714
[15:42:07.369] iteration 6639: loss: 0.087687, loss_s1: 0.063803, loss_fp: 0.001389, loss_freq: 0.030415
[15:42:08.027] iteration 6640: loss: 0.149531, loss_s1: 0.090537, loss_fp: 0.002384, loss_freq: 0.090866
[15:42:08.662] iteration 6641: loss: 0.064240, loss_s1: 0.041417, loss_fp: 0.001275, loss_freq: 0.017923
[15:42:09.292] iteration 6642: loss: 0.118151, loss_s1: 0.063835, loss_fp: 0.004708, loss_freq: 0.022342
[15:42:09.917] iteration 6643: loss: 0.088646, loss_s1: 0.069332, loss_fp: 0.006916, loss_freq: 0.031268
[15:42:10.538] iteration 6644: loss: 0.113493, loss_s1: 0.093483, loss_fp: 0.011044, loss_freq: 0.071551
[15:42:11.165] iteration 6645: loss: 0.132203, loss_s1: 0.107023, loss_fp: 0.008311, loss_freq: 0.053144
[15:42:11.791] iteration 6646: loss: 0.119660, loss_s1: 0.072688, loss_fp: 0.001954, loss_freq: 0.077610
[15:42:12.421] iteration 6647: loss: 0.098670, loss_s1: 0.062830, loss_fp: 0.002088, loss_freq: 0.020124
[15:42:13.063] iteration 6648: loss: 0.049923, loss_s1: 0.025151, loss_fp: 0.000832, loss_freq: 0.022474
[15:42:13.702] iteration 6649: loss: 0.060563, loss_s1: 0.042564, loss_fp: 0.001458, loss_freq: 0.029791
[15:42:14.344] iteration 6650: loss: 0.082546, loss_s1: 0.070781, loss_fp: 0.002597, loss_freq: 0.009624
[15:42:14.985] iteration 6651: loss: 0.077572, loss_s1: 0.040637, loss_fp: 0.001034, loss_freq: 0.054183
[15:42:15.624] iteration 6652: loss: 0.078385, loss_s1: 0.074429, loss_fp: 0.001370, loss_freq: 0.017346
[15:42:16.265] iteration 6653: loss: 0.097683, loss_s1: 0.029545, loss_fp: 0.000971, loss_freq: 0.013899
[15:42:16.907] iteration 6654: loss: 0.108780, loss_s1: 0.046242, loss_fp: 0.001192, loss_freq: 0.076573
[15:42:17.547] iteration 6655: loss: 0.076212, loss_s1: 0.029339, loss_fp: 0.003103, loss_freq: 0.021846
[15:42:18.194] iteration 6656: loss: 0.101934, loss_s1: 0.040077, loss_fp: 0.000987, loss_freq: 0.049024
[15:42:18.836] iteration 6657: loss: 0.143979, loss_s1: 0.122929, loss_fp: 0.001551, loss_freq: 0.097646
[15:42:19.511] iteration 6658: loss: 0.066628, loss_s1: 0.029512, loss_fp: 0.000934, loss_freq: 0.013328
[15:42:20.147] iteration 6659: loss: 0.125687, loss_s1: 0.057205, loss_fp: 0.001271, loss_freq: 0.038162
[15:42:20.775] iteration 6660: loss: 0.102588, loss_s1: 0.089505, loss_fp: 0.000964, loss_freq: 0.030511
[15:42:21.421] iteration 6661: loss: 0.085337, loss_s1: 0.067759, loss_fp: 0.001666, loss_freq: 0.029189
[15:42:22.057] iteration 6662: loss: 0.078749, loss_s1: 0.052092, loss_fp: 0.007327, loss_freq: 0.026147
[15:42:22.688] iteration 6663: loss: 0.068124, loss_s1: 0.066435, loss_fp: 0.001879, loss_freq: 0.004989
[15:42:23.320] iteration 6664: loss: 0.103614, loss_s1: 0.078978, loss_fp: 0.001152, loss_freq: 0.026660
[15:42:23.954] iteration 6665: loss: 0.096875, loss_s1: 0.080262, loss_fp: 0.013055, loss_freq: 0.032761
[15:42:24.585] iteration 6666: loss: 0.059972, loss_s1: 0.034916, loss_fp: 0.002572, loss_freq: 0.008875
[15:42:25.220] iteration 6667: loss: 0.104673, loss_s1: 0.042603, loss_fp: 0.001846, loss_freq: 0.081552
[15:42:25.847] iteration 6668: loss: 0.116610, loss_s1: 0.049319, loss_fp: 0.001861, loss_freq: 0.037063
[15:42:26.474] iteration 6669: loss: 0.058732, loss_s1: 0.038807, loss_fp: 0.002303, loss_freq: 0.022740
[15:42:27.099] iteration 6670: loss: 0.113853, loss_s1: 0.104352, loss_fp: 0.002011, loss_freq: 0.053065
[15:42:27.768] iteration 6671: loss: 0.173935, loss_s1: 0.087615, loss_fp: 0.006079, loss_freq: 0.105906
[15:42:28.390] iteration 6672: loss: 0.117848, loss_s1: 0.095150, loss_fp: 0.003312, loss_freq: 0.076892
[15:42:29.020] iteration 6673: loss: 0.119144, loss_s1: 0.099560, loss_fp: 0.001909, loss_freq: 0.068845
[15:42:29.648] iteration 6674: loss: 0.106290, loss_s1: 0.048712, loss_fp: 0.003274, loss_freq: 0.079290
[15:42:30.297] iteration 6675: loss: 0.064804, loss_s1: 0.035988, loss_fp: 0.000784, loss_freq: 0.021056
[15:42:30.957] iteration 6676: loss: 0.131336, loss_s1: 0.131296, loss_fp: 0.008833, loss_freq: 0.032631
[15:42:31.622] iteration 6677: loss: 0.114147, loss_s1: 0.066328, loss_fp: 0.001525, loss_freq: 0.045749
[15:42:32.282] iteration 6678: loss: 0.107239, loss_s1: 0.076112, loss_fp: 0.000898, loss_freq: 0.064325
[15:42:32.941] iteration 6679: loss: 0.097736, loss_s1: 0.078062, loss_fp: 0.010614, loss_freq: 0.041051
[15:42:33.568] iteration 6680: loss: 0.070072, loss_s1: 0.044028, loss_fp: 0.002596, loss_freq: 0.025217
[15:42:34.205] iteration 6681: loss: 0.084954, loss_s1: 0.059448, loss_fp: 0.001093, loss_freq: 0.025247
[15:42:34.841] iteration 6682: loss: 0.090218, loss_s1: 0.080053, loss_fp: 0.002015, loss_freq: 0.035257
[15:42:35.469] iteration 6683: loss: 0.069036, loss_s1: 0.062328, loss_fp: 0.003786, loss_freq: 0.021314
[15:42:36.104] iteration 6684: loss: 0.159347, loss_s1: 0.130355, loss_fp: 0.031440, loss_freq: 0.109423
[15:42:36.733] iteration 6685: loss: 0.081743, loss_s1: 0.030258, loss_fp: 0.000724, loss_freq: 0.044922
[15:42:37.363] iteration 6686: loss: 0.135113, loss_s1: 0.095285, loss_fp: 0.004418, loss_freq: 0.092154
[15:42:37.991] iteration 6687: loss: 0.081644, loss_s1: 0.064372, loss_fp: 0.005548, loss_freq: 0.035820
[15:42:38.618] iteration 6688: loss: 0.124664, loss_s1: 0.059828, loss_fp: 0.000653, loss_freq: 0.080371
[15:42:39.245] iteration 6689: loss: 0.094201, loss_s1: 0.059810, loss_fp: 0.001525, loss_freq: 0.023149
[15:42:39.871] iteration 6690: loss: 0.132388, loss_s1: 0.078383, loss_fp: 0.003588, loss_freq: 0.093509
[15:42:40.501] iteration 6691: loss: 0.134865, loss_s1: 0.048499, loss_fp: 0.001766, loss_freq: 0.029476
[15:42:41.174] iteration 6692: loss: 0.114026, loss_s1: 0.021375, loss_fp: 0.000378, loss_freq: 0.028907
[15:42:41.806] iteration 6693: loss: 0.092340, loss_s1: 0.035053, loss_fp: 0.001368, loss_freq: 0.026266
[15:42:42.438] iteration 6694: loss: 0.132894, loss_s1: 0.007743, loss_fp: 0.000797, loss_freq: 0.009324
[15:42:43.069] iteration 6695: loss: 0.073017, loss_s1: 0.052478, loss_fp: 0.001021, loss_freq: 0.016971
[15:42:43.697] iteration 6696: loss: 0.051727, loss_s1: 0.016803, loss_fp: 0.005500, loss_freq: 0.013425
[15:42:44.324] iteration 6697: loss: 0.079814, loss_s1: 0.057415, loss_fp: 0.001909, loss_freq: 0.041501
[15:42:44.949] iteration 6698: loss: 0.077316, loss_s1: 0.032984, loss_fp: 0.001342, loss_freq: 0.048254
[15:42:45.575] iteration 6699: loss: 0.086379, loss_s1: 0.027807, loss_fp: 0.000695, loss_freq: 0.021451
[15:42:46.203] iteration 6700: loss: 0.061341, loss_s1: 0.021172, loss_fp: 0.001793, loss_freq: 0.016656
[15:42:46.832] iteration 6701: loss: 0.088983, loss_s1: 0.073828, loss_fp: 0.012111, loss_freq: 0.025549
[15:42:47.484] iteration 6702: loss: 0.103095, loss_s1: 0.062972, loss_fp: 0.001236, loss_freq: 0.039461
[15:42:48.153] iteration 6703: loss: 0.108007, loss_s1: 0.052491, loss_fp: 0.003104, loss_freq: 0.046693
[15:42:48.777] iteration 6704: loss: 0.112457, loss_s1: 0.068689, loss_fp: 0.002071, loss_freq: 0.058373
[15:42:49.403] iteration 6705: loss: 0.119346, loss_s1: 0.051923, loss_fp: 0.003026, loss_freq: 0.076788
[15:42:50.051] iteration 6706: loss: 0.138982, loss_s1: 0.080646, loss_fp: 0.002957, loss_freq: 0.036810
[15:42:50.681] iteration 6707: loss: 0.089211, loss_s1: 0.045332, loss_fp: 0.001219, loss_freq: 0.018169
[15:42:51.362] iteration 6708: loss: 0.081236, loss_s1: 0.025242, loss_fp: 0.002530, loss_freq: 0.015289
[15:42:52.030] iteration 6709: loss: 0.125451, loss_s1: 0.086977, loss_fp: 0.001030, loss_freq: 0.055793
[15:42:52.682] iteration 6710: loss: 0.202277, loss_s1: 0.102117, loss_fp: 0.002302, loss_freq: 0.207379
[15:42:53.343] iteration 6711: loss: 0.066966, loss_s1: 0.025202, loss_fp: 0.001783, loss_freq: 0.040633
[15:42:54.008] iteration 6712: loss: 0.106780, loss_s1: 0.037741, loss_fp: 0.001846, loss_freq: 0.023346
[15:42:54.643] iteration 6713: loss: 0.085973, loss_s1: 0.035888, loss_fp: 0.001513, loss_freq: 0.068195
[15:42:55.271] iteration 6714: loss: 0.124206, loss_s1: 0.082810, loss_fp: 0.001673, loss_freq: 0.051617
[15:42:55.897] iteration 6715: loss: 0.095543, loss_s1: 0.067967, loss_fp: 0.002218, loss_freq: 0.051078
[15:42:56.523] iteration 6716: loss: 0.062898, loss_s1: 0.038342, loss_fp: 0.001000, loss_freq: 0.011068
[15:42:57.206] iteration 6717: loss: 0.178330, loss_s1: 0.107737, loss_fp: 0.003678, loss_freq: 0.050577
[15:42:57.859] iteration 6718: loss: 0.108236, loss_s1: 0.038981, loss_fp: 0.002023, loss_freq: 0.119960
[15:42:58.492] iteration 6719: loss: 0.082612, loss_s1: 0.033538, loss_fp: 0.003317, loss_freq: 0.067831
[15:42:59.220] iteration 6720: loss: 0.145155, loss_s1: 0.068145, loss_fp: 0.004173, loss_freq: 0.061425
[15:42:59.989] iteration 6721: loss: 0.178503, loss_s1: 0.134624, loss_fp: 0.001365, loss_freq: 0.130243
[15:43:00.633] iteration 6722: loss: 0.082068, loss_s1: 0.020615, loss_fp: 0.003331, loss_freq: 0.069793
[15:43:01.315] iteration 6723: loss: 0.076014, loss_s1: 0.020369, loss_fp: 0.003809, loss_freq: 0.019838
[15:43:01.973] iteration 6724: loss: 0.126264, loss_s1: 0.103174, loss_fp: 0.006660, loss_freq: 0.029531
[15:43:02.601] iteration 6725: loss: 0.144668, loss_s1: 0.055290, loss_fp: 0.006153, loss_freq: 0.095761
[15:43:03.222] iteration 6726: loss: 0.115980, loss_s1: 0.033973, loss_fp: 0.000807, loss_freq: 0.026209
[15:43:03.844] iteration 6727: loss: 0.085163, loss_s1: 0.033708, loss_fp: 0.001444, loss_freq: 0.014366
[15:43:04.469] iteration 6728: loss: 0.082862, loss_s1: 0.050487, loss_fp: 0.001018, loss_freq: 0.023909
[15:43:05.097] iteration 6729: loss: 0.162302, loss_s1: 0.083166, loss_fp: 0.001110, loss_freq: 0.034358
[15:43:05.722] iteration 6730: loss: 0.075459, loss_s1: 0.054419, loss_fp: 0.004530, loss_freq: 0.012992
[15:43:06.348] iteration 6731: loss: 0.072761, loss_s1: 0.021207, loss_fp: 0.002104, loss_freq: 0.019922
[15:43:06.973] iteration 6732: loss: 0.110118, loss_s1: 0.043721, loss_fp: 0.002735, loss_freq: 0.077731
[15:43:07.607] iteration 6733: loss: 0.136418, loss_s1: 0.074467, loss_fp: 0.001705, loss_freq: 0.095482
[15:43:08.233] iteration 6734: loss: 0.081618, loss_s1: 0.061787, loss_fp: 0.001030, loss_freq: 0.019231
[15:43:08.862] iteration 6735: loss: 0.109614, loss_s1: 0.078940, loss_fp: 0.003712, loss_freq: 0.043683
[15:43:09.485] iteration 6736: loss: 0.125918, loss_s1: 0.109088, loss_fp: 0.001406, loss_freq: 0.044072
[15:43:10.167] iteration 6737: loss: 0.070288, loss_s1: 0.053696, loss_fp: 0.001332, loss_freq: 0.030994
[15:43:10.831] iteration 6738: loss: 0.106869, loss_s1: 0.038220, loss_fp: 0.001225, loss_freq: 0.052676
[15:43:11.492] iteration 6739: loss: 0.088622, loss_s1: 0.062453, loss_fp: 0.004608, loss_freq: 0.023114
[15:43:12.128] iteration 6740: loss: 0.102611, loss_s1: 0.056599, loss_fp: 0.008944, loss_freq: 0.033406
[15:43:12.752] iteration 6741: loss: 0.173392, loss_s1: 0.097102, loss_fp: 0.000898, loss_freq: 0.092583
[15:43:13.380] iteration 6742: loss: 0.127793, loss_s1: 0.105796, loss_fp: 0.008935, loss_freq: 0.051557
[15:43:14.008] iteration 6743: loss: 0.135441, loss_s1: 0.052975, loss_fp: 0.002116, loss_freq: 0.050398
[15:43:14.635] iteration 6744: loss: 0.131942, loss_s1: 0.058909, loss_fp: 0.002864, loss_freq: 0.042314
[15:43:15.264] iteration 6745: loss: 0.099390, loss_s1: 0.037656, loss_fp: 0.004493, loss_freq: 0.016383
[15:43:15.892] iteration 6746: loss: 0.078766, loss_s1: 0.027298, loss_fp: 0.002491, loss_freq: 0.019427
[15:43:16.519] iteration 6747: loss: 0.086974, loss_s1: 0.029819, loss_fp: 0.005100, loss_freq: 0.019474
[15:43:17.156] iteration 6748: loss: 0.078634, loss_s1: 0.054556, loss_fp: 0.001368, loss_freq: 0.050898
[15:43:17.823] iteration 6749: loss: 0.103421, loss_s1: 0.105041, loss_fp: 0.002466, loss_freq: 0.020401
[15:43:18.488] iteration 6750: loss: 0.095343, loss_s1: 0.078996, loss_fp: 0.002439, loss_freq: 0.019953
[15:43:19.156] iteration 6751: loss: 0.096918, loss_s1: 0.061105, loss_fp: 0.005154, loss_freq: 0.043631
[15:43:19.824] iteration 6752: loss: 0.097832, loss_s1: 0.073436, loss_fp: 0.002354, loss_freq: 0.016858
[15:43:20.487] iteration 6753: loss: 0.158142, loss_s1: 0.164783, loss_fp: 0.025549, loss_freq: 0.054232
[15:43:21.156] iteration 6754: loss: 0.116854, loss_s1: 0.053110, loss_fp: 0.001264, loss_freq: 0.008071
[15:43:21.823] iteration 6755: loss: 0.073378, loss_s1: 0.020132, loss_fp: 0.001933, loss_freq: 0.011122
[15:43:22.491] iteration 6756: loss: 0.079391, loss_s1: 0.042878, loss_fp: 0.001386, loss_freq: 0.016987
[15:43:23.187] iteration 6757: loss: 0.078634, loss_s1: 0.037685, loss_fp: 0.000309, loss_freq: 0.019214
[15:43:23.852] iteration 6758: loss: 0.096152, loss_s1: 0.049298, loss_fp: 0.001444, loss_freq: 0.014287
[15:43:24.520] iteration 6759: loss: 0.095476, loss_s1: 0.052631, loss_fp: 0.003527, loss_freq: 0.036727
[15:43:25.179] iteration 6760: loss: 0.099742, loss_s1: 0.055493, loss_fp: 0.009185, loss_freq: 0.044513
[15:43:25.803] iteration 6761: loss: 0.152139, loss_s1: 0.126291, loss_fp: 0.012051, loss_freq: 0.030141
[15:43:26.427] iteration 6762: loss: 0.080854, loss_s1: 0.062047, loss_fp: 0.006515, loss_freq: 0.023991
[15:43:27.401] iteration 6763: loss: 0.095818, loss_s1: 0.088573, loss_fp: 0.002252, loss_freq: 0.039825
[15:43:28.057] iteration 6764: loss: 0.083503, loss_s1: 0.037832, loss_fp: 0.001908, loss_freq: 0.038680
[15:43:28.718] iteration 6765: loss: 0.077800, loss_s1: 0.020871, loss_fp: 0.001096, loss_freq: 0.037681
[15:43:29.380] iteration 6766: loss: 0.063608, loss_s1: 0.007031, loss_fp: 0.000517, loss_freq: 0.029228
[15:43:30.044] iteration 6767: loss: 0.077665, loss_s1: 0.056654, loss_fp: 0.003705, loss_freq: 0.023414
[15:43:30.700] iteration 6768: loss: 0.170000, loss_s1: 0.108255, loss_fp: 0.003111, loss_freq: 0.076231
[15:43:31.328] iteration 6769: loss: 0.051572, loss_s1: 0.021520, loss_fp: 0.003609, loss_freq: 0.021567
[15:43:31.953] iteration 6770: loss: 0.070028, loss_s1: 0.038204, loss_fp: 0.002908, loss_freq: 0.025844
[15:43:32.579] iteration 6771: loss: 0.098117, loss_s1: 0.080825, loss_fp: 0.002249, loss_freq: 0.021629
[15:43:33.208] iteration 6772: loss: 0.069317, loss_s1: 0.044823, loss_fp: 0.002628, loss_freq: 0.027540
[15:43:33.861] iteration 6773: loss: 0.061089, loss_s1: 0.011051, loss_fp: 0.000652, loss_freq: 0.026926
[15:43:34.489] iteration 6774: loss: 0.083647, loss_s1: 0.050601, loss_fp: 0.001053, loss_freq: 0.035667
[15:43:35.116] iteration 6775: loss: 0.078596, loss_s1: 0.064703, loss_fp: 0.006860, loss_freq: 0.039409
[15:43:35.742] iteration 6776: loss: 0.112555, loss_s1: 0.073595, loss_fp: 0.001841, loss_freq: 0.055653
[15:43:36.376] iteration 6777: loss: 0.085595, loss_s1: 0.072575, loss_fp: 0.001848, loss_freq: 0.023068
[15:43:36.997] iteration 6778: loss: 0.109332, loss_s1: 0.112218, loss_fp: 0.001691, loss_freq: 0.035911
[15:43:37.655] iteration 6779: loss: 0.122066, loss_s1: 0.074002, loss_fp: 0.000755, loss_freq: 0.030407
[15:43:38.312] iteration 6780: loss: 0.067839, loss_s1: 0.030322, loss_fp: 0.002814, loss_freq: 0.027476
[15:43:38.972] iteration 6781: loss: 0.075259, loss_s1: 0.031179, loss_fp: 0.000352, loss_freq: 0.023994
[15:43:39.601] iteration 6782: loss: 0.090807, loss_s1: 0.048195, loss_fp: 0.002022, loss_freq: 0.011170
[15:43:40.223] iteration 6783: loss: 0.049889, loss_s1: 0.030177, loss_fp: 0.002200, loss_freq: 0.004727
[15:43:40.851] iteration 6784: loss: 0.114115, loss_s1: 0.049931, loss_fp: 0.000784, loss_freq: 0.033890
[15:43:41.476] iteration 6785: loss: 0.097978, loss_s1: 0.041884, loss_fp: 0.000888, loss_freq: 0.027855
[15:43:42.101] iteration 6786: loss: 0.222078, loss_s1: 0.145491, loss_fp: 0.005563, loss_freq: 0.225947
[15:43:42.728] iteration 6787: loss: 0.085885, loss_s1: 0.083712, loss_fp: 0.000994, loss_freq: 0.024984
[15:43:43.351] iteration 6788: loss: 0.100591, loss_s1: 0.064980, loss_fp: 0.003944, loss_freq: 0.020946
[15:43:43.975] iteration 6789: loss: 0.071529, loss_s1: 0.035084, loss_fp: 0.003251, loss_freq: 0.026872
[15:43:44.598] iteration 6790: loss: 0.094013, loss_s1: 0.065138, loss_fp: 0.001412, loss_freq: 0.038366
[15:43:45.223] iteration 6791: loss: 0.087356, loss_s1: 0.043437, loss_fp: 0.002004, loss_freq: 0.043054
[15:43:45.847] iteration 6792: loss: 0.076328, loss_s1: 0.071645, loss_fp: 0.001160, loss_freq: 0.024355
[15:43:46.472] iteration 6793: loss: 0.050966, loss_s1: 0.039243, loss_fp: 0.003852, loss_freq: 0.010727
[15:43:47.100] iteration 6794: loss: 0.089387, loss_s1: 0.061210, loss_fp: 0.008276, loss_freq: 0.013429
[15:43:47.728] iteration 6795: loss: 0.075950, loss_s1: 0.071150, loss_fp: 0.001673, loss_freq: 0.031696
[15:43:48.351] iteration 6796: loss: 0.077034, loss_s1: 0.044132, loss_fp: 0.001157, loss_freq: 0.018407
[15:43:48.976] iteration 6797: loss: 0.110301, loss_s1: 0.062154, loss_fp: 0.005220, loss_freq: 0.044297
[15:43:49.599] iteration 6798: loss: 0.097765, loss_s1: 0.045582, loss_fp: 0.001512, loss_freq: 0.063600
[15:43:50.224] iteration 6799: loss: 0.123339, loss_s1: 0.062426, loss_fp: 0.006192, loss_freq: 0.047526
[15:43:50.849] iteration 6800: loss: 0.083366, loss_s1: 0.066432, loss_fp: 0.004482, loss_freq: 0.027730
[15:43:54.018] iteration 6800 : mean_dice : 0.673074
[15:43:54.658] iteration 6801: loss: 0.135990, loss_s1: 0.084483, loss_fp: 0.000469, loss_freq: 0.094752
[15:43:55.289] iteration 6802: loss: 0.085706, loss_s1: 0.018988, loss_fp: 0.003646, loss_freq: 0.032978
[15:43:55.914] iteration 6803: loss: 0.126251, loss_s1: 0.063156, loss_fp: 0.001694, loss_freq: 0.022367
[15:43:56.539] iteration 6804: loss: 0.085919, loss_s1: 0.070790, loss_fp: 0.002677, loss_freq: 0.043256
[15:43:57.164] iteration 6805: loss: 0.117439, loss_s1: 0.090844, loss_fp: 0.004187, loss_freq: 0.064300
[15:43:57.791] iteration 6806: loss: 0.075075, loss_s1: 0.078897, loss_fp: 0.001773, loss_freq: 0.011561
[15:43:58.416] iteration 6807: loss: 0.096951, loss_s1: 0.058130, loss_fp: 0.002057, loss_freq: 0.054531
[15:43:59.040] iteration 6808: loss: 0.071815, loss_s1: 0.041340, loss_fp: 0.001378, loss_freq: 0.015890
[15:43:59.667] iteration 6809: loss: 0.088008, loss_s1: 0.058991, loss_fp: 0.001043, loss_freq: 0.040411
[15:44:00.292] iteration 6810: loss: 0.079379, loss_s1: 0.066705, loss_fp: 0.003745, loss_freq: 0.034227
[15:44:00.921] iteration 6811: loss: 0.087136, loss_s1: 0.063963, loss_fp: 0.005669, loss_freq: 0.028333
[15:44:01.547] iteration 6812: loss: 0.106775, loss_s1: 0.088498, loss_fp: 0.005326, loss_freq: 0.022287
[15:44:02.172] iteration 6813: loss: 0.074275, loss_s1: 0.032318, loss_fp: 0.005451, loss_freq: 0.044802
[15:44:02.799] iteration 6814: loss: 0.092778, loss_s1: 0.043780, loss_fp: 0.003275, loss_freq: 0.012202
[15:44:03.427] iteration 6815: loss: 0.104808, loss_s1: 0.053415, loss_fp: 0.001798, loss_freq: 0.074326
[15:44:04.052] iteration 6816: loss: 0.081926, loss_s1: 0.048903, loss_fp: 0.004445, loss_freq: 0.024562
[15:44:04.683] iteration 6817: loss: 0.125096, loss_s1: 0.076996, loss_fp: 0.000792, loss_freq: 0.021563
[15:44:05.311] iteration 6818: loss: 0.131749, loss_s1: 0.130450, loss_fp: 0.002878, loss_freq: 0.041045
[15:44:05.943] iteration 6819: loss: 0.070126, loss_s1: 0.029362, loss_fp: 0.000883, loss_freq: 0.007031
[15:44:06.568] iteration 6820: loss: 0.106523, loss_s1: 0.030939, loss_fp: 0.000920, loss_freq: 0.035187
[15:44:07.193] iteration 6821: loss: 0.085080, loss_s1: 0.055746, loss_fp: 0.001750, loss_freq: 0.031262
[15:44:07.820] iteration 6822: loss: 0.065361, loss_s1: 0.058705, loss_fp: 0.001678, loss_freq: 0.022742
[15:44:08.444] iteration 6823: loss: 0.079888, loss_s1: 0.059234, loss_fp: 0.001068, loss_freq: 0.026182
[15:44:09.069] iteration 6824: loss: 0.062589, loss_s1: 0.031627, loss_fp: 0.001540, loss_freq: 0.027317
[15:44:09.696] iteration 6825: loss: 0.105765, loss_s1: 0.103470, loss_fp: 0.001672, loss_freq: 0.021570
[15:44:10.323] iteration 6826: loss: 0.111811, loss_s1: 0.059995, loss_fp: 0.007233, loss_freq: 0.025521
[15:44:10.948] iteration 6827: loss: 0.064061, loss_s1: 0.023278, loss_fp: 0.001632, loss_freq: 0.011374
[15:44:11.575] iteration 6828: loss: 0.106548, loss_s1: 0.052874, loss_fp: 0.005498, loss_freq: 0.085970
[15:44:12.198] iteration 6829: loss: 0.080107, loss_s1: 0.019246, loss_fp: 0.004411, loss_freq: 0.061659
[15:44:12.819] iteration 6830: loss: 0.097019, loss_s1: 0.084948, loss_fp: 0.003164, loss_freq: 0.048321
[15:44:13.445] iteration 6831: loss: 0.085590, loss_s1: 0.041429, loss_fp: 0.004771, loss_freq: 0.024276
[15:44:14.071] iteration 6832: loss: 0.130176, loss_s1: 0.041978, loss_fp: 0.009612, loss_freq: 0.041581
[15:44:14.695] iteration 6833: loss: 0.094688, loss_s1: 0.063050, loss_fp: 0.008810, loss_freq: 0.026965
[15:44:15.321] iteration 6834: loss: 0.099339, loss_s1: 0.037285, loss_fp: 0.003617, loss_freq: 0.055032
[15:44:15.947] iteration 6835: loss: 0.094592, loss_s1: 0.059706, loss_fp: 0.004371, loss_freq: 0.042541
[15:44:16.568] iteration 6836: loss: 0.120132, loss_s1: 0.111710, loss_fp: 0.000757, loss_freq: 0.036336
[15:44:17.193] iteration 6837: loss: 0.092657, loss_s1: 0.068621, loss_fp: 0.005833, loss_freq: 0.055289
[15:44:17.816] iteration 6838: loss: 0.118032, loss_s1: 0.058317, loss_fp: 0.013588, loss_freq: 0.030389
[15:44:18.443] iteration 6839: loss: 0.112127, loss_s1: 0.107617, loss_fp: 0.005103, loss_freq: 0.050707
[15:44:19.066] iteration 6840: loss: 0.098596, loss_s1: 0.085816, loss_fp: 0.004611, loss_freq: 0.054468
[15:44:19.690] iteration 6841: loss: 0.064927, loss_s1: 0.041873, loss_fp: 0.004308, loss_freq: 0.012565
[15:44:20.316] iteration 6842: loss: 0.076164, loss_s1: 0.049563, loss_fp: 0.007359, loss_freq: 0.037362
[15:44:20.939] iteration 6843: loss: 0.105450, loss_s1: 0.045382, loss_fp: 0.001992, loss_freq: 0.035265
[15:44:21.565] iteration 6844: loss: 0.051154, loss_s1: 0.018252, loss_fp: 0.005914, loss_freq: 0.015194
[15:44:22.191] iteration 6845: loss: 0.126668, loss_s1: 0.097466, loss_fp: 0.013580, loss_freq: 0.070640
[15:44:22.813] iteration 6846: loss: 0.086105, loss_s1: 0.033248, loss_fp: 0.001267, loss_freq: 0.025007
[15:44:23.440] iteration 6847: loss: 0.177472, loss_s1: 0.156059, loss_fp: 0.009237, loss_freq: 0.131857
[15:44:24.066] iteration 6848: loss: 0.080228, loss_s1: 0.047483, loss_fp: 0.004951, loss_freq: 0.051419
[15:44:24.692] iteration 6849: loss: 0.125641, loss_s1: 0.108598, loss_fp: 0.003367, loss_freq: 0.049972
[15:44:25.317] iteration 6850: loss: 0.071899, loss_s1: 0.055868, loss_fp: 0.001900, loss_freq: 0.017041
[15:44:25.936] iteration 6851: loss: 0.089586, loss_s1: 0.050681, loss_fp: 0.007608, loss_freq: 0.053658
[15:44:26.564] iteration 6852: loss: 0.093549, loss_s1: 0.054344, loss_fp: 0.001138, loss_freq: 0.047508
[15:44:27.191] iteration 6853: loss: 0.058545, loss_s1: 0.010387, loss_fp: 0.001200, loss_freq: 0.018891
[15:44:27.815] iteration 6854: loss: 0.060624, loss_s1: 0.039685, loss_fp: 0.003056, loss_freq: 0.016340
[15:44:28.443] iteration 6855: loss: 0.092557, loss_s1: 0.021044, loss_fp: 0.001898, loss_freq: 0.020491
[15:44:29.069] iteration 6856: loss: 0.068379, loss_s1: 0.040881, loss_fp: 0.007119, loss_freq: 0.017270
[15:44:29.696] iteration 6857: loss: 0.080513, loss_s1: 0.053178, loss_fp: 0.004435, loss_freq: 0.049483
[15:44:30.348] iteration 6858: loss: 0.057776, loss_s1: 0.031238, loss_fp: 0.003921, loss_freq: 0.018969
[15:44:31.005] iteration 6859: loss: 0.059962, loss_s1: 0.025592, loss_fp: 0.002216, loss_freq: 0.018626
[15:44:31.666] iteration 6860: loss: 0.083098, loss_s1: 0.032330, loss_fp: 0.000297, loss_freq: 0.027530
[15:44:32.320] iteration 6861: loss: 0.062876, loss_s1: 0.040553, loss_fp: 0.002330, loss_freq: 0.018548
[15:44:32.946] iteration 6862: loss: 0.081441, loss_s1: 0.033858, loss_fp: 0.018444, loss_freq: 0.026532
[15:44:33.589] iteration 6863: loss: 0.114492, loss_s1: 0.080995, loss_fp: 0.004240, loss_freq: 0.030670
[15:44:34.228] iteration 6864: loss: 0.090584, loss_s1: 0.060691, loss_fp: 0.003247, loss_freq: 0.033739
[15:44:34.865] iteration 6865: loss: 0.117897, loss_s1: 0.104053, loss_fp: 0.012006, loss_freq: 0.040705
[15:44:35.490] iteration 6866: loss: 0.106029, loss_s1: 0.070549, loss_fp: 0.004644, loss_freq: 0.043300
[15:44:36.116] iteration 6867: loss: 0.152411, loss_s1: 0.094684, loss_fp: 0.001835, loss_freq: 0.040285
[15:44:36.740] iteration 6868: loss: 0.112027, loss_s1: 0.038488, loss_fp: 0.001972, loss_freq: 0.029099
[15:44:37.399] iteration 6869: loss: 0.080004, loss_s1: 0.037910, loss_fp: 0.003563, loss_freq: 0.025346
[15:44:38.060] iteration 6870: loss: 0.099331, loss_s1: 0.056556, loss_fp: 0.006155, loss_freq: 0.044049
[15:44:38.716] iteration 6871: loss: 0.168197, loss_s1: 0.085263, loss_fp: 0.011274, loss_freq: 0.138744
[15:44:39.358] iteration 6872: loss: 0.083078, loss_s1: 0.063995, loss_fp: 0.005264, loss_freq: 0.038169
[15:44:39.983] iteration 6873: loss: 0.142313, loss_s1: 0.031818, loss_fp: 0.000789, loss_freq: 0.042420
[15:44:40.611] iteration 6874: loss: 0.079617, loss_s1: 0.029739, loss_fp: 0.011185, loss_freq: 0.041956
[15:44:41.236] iteration 6875: loss: 0.151535, loss_s1: 0.127110, loss_fp: 0.020873, loss_freq: 0.097468
[15:44:41.865] iteration 6876: loss: 0.054662, loss_s1: 0.019659, loss_fp: 0.002987, loss_freq: 0.021502
[15:44:42.491] iteration 6877: loss: 0.054871, loss_s1: 0.035405, loss_fp: 0.002983, loss_freq: 0.007676
[15:44:43.146] iteration 6878: loss: 0.118344, loss_s1: 0.074510, loss_fp: 0.001131, loss_freq: 0.092780
[15:44:43.772] iteration 6879: loss: 0.093200, loss_s1: 0.069688, loss_fp: 0.002649, loss_freq: 0.027416
[15:44:44.395] iteration 6880: loss: 0.086030, loss_s1: 0.039949, loss_fp: 0.001020, loss_freq: 0.046833
[15:44:45.017] iteration 6881: loss: 0.091765, loss_s1: 0.021504, loss_fp: 0.001166, loss_freq: 0.036822
[15:44:45.638] iteration 6882: loss: 0.156371, loss_s1: 0.139957, loss_fp: 0.002331, loss_freq: 0.101175
[15:44:46.290] iteration 6883: loss: 0.091923, loss_s1: 0.030016, loss_fp: 0.003170, loss_freq: 0.088441
[15:44:46.948] iteration 6884: loss: 0.087817, loss_s1: 0.037711, loss_fp: 0.002787, loss_freq: 0.031393
[15:44:47.605] iteration 6885: loss: 0.090736, loss_s1: 0.071814, loss_fp: 0.001442, loss_freq: 0.024904
[15:44:48.254] iteration 6886: loss: 0.074308, loss_s1: 0.038917, loss_fp: 0.008057, loss_freq: 0.023036
[15:44:48.875] iteration 6887: loss: 0.097135, loss_s1: 0.053446, loss_fp: 0.003058, loss_freq: 0.048121
[15:44:49.500] iteration 6888: loss: 0.106972, loss_s1: 0.046245, loss_fp: 0.006401, loss_freq: 0.028820
[15:44:50.128] iteration 6889: loss: 0.097548, loss_s1: 0.069523, loss_fp: 0.005938, loss_freq: 0.026549
[15:44:50.753] iteration 6890: loss: 0.210198, loss_s1: 0.102237, loss_fp: 0.005582, loss_freq: 0.122048
[15:44:51.381] iteration 6891: loss: 0.093273, loss_s1: 0.103319, loss_fp: 0.002936, loss_freq: 0.012713
[15:44:52.007] iteration 6892: loss: 0.083956, loss_s1: 0.070004, loss_fp: 0.004529, loss_freq: 0.021263
[15:44:52.631] iteration 6893: loss: 0.191280, loss_s1: 0.192160, loss_fp: 0.012269, loss_freq: 0.089493
[15:44:53.257] iteration 6894: loss: 0.131278, loss_s1: 0.056147, loss_fp: 0.003396, loss_freq: 0.075087
[15:44:53.882] iteration 6895: loss: 0.086335, loss_s1: 0.050588, loss_fp: 0.001931, loss_freq: 0.015262
[15:44:54.505] iteration 6896: loss: 0.103665, loss_s1: 0.064353, loss_fp: 0.009795, loss_freq: 0.017348
[15:44:55.130] iteration 6897: loss: 0.103897, loss_s1: 0.075750, loss_fp: 0.019266, loss_freq: 0.062055
[15:44:55.753] iteration 6898: loss: 0.081685, loss_s1: 0.061450, loss_fp: 0.001869, loss_freq: 0.010064
[15:44:56.378] iteration 6899: loss: 0.129613, loss_s1: 0.036899, loss_fp: 0.005181, loss_freq: 0.044660
[15:44:57.007] iteration 6900: loss: 0.110632, loss_s1: 0.078047, loss_fp: 0.017405, loss_freq: 0.027415
[15:44:57.637] iteration 6901: loss: 0.082925, loss_s1: 0.042510, loss_fp: 0.017254, loss_freq: 0.026000
[15:44:58.263] iteration 6902: loss: 0.137797, loss_s1: 0.069408, loss_fp: 0.011983, loss_freq: 0.044829
[15:44:58.888] iteration 6903: loss: 0.123226, loss_s1: 0.098509, loss_fp: 0.006381, loss_freq: 0.047538
[15:44:59.519] iteration 6904: loss: 0.127632, loss_s1: 0.034392, loss_fp: 0.003860, loss_freq: 0.061354
[15:45:00.145] iteration 6905: loss: 0.143692, loss_s1: 0.124639, loss_fp: 0.001775, loss_freq: 0.048982
[15:45:00.816] iteration 6906: loss: 0.065184, loss_s1: 0.041784, loss_fp: 0.002726, loss_freq: 0.011600
[15:45:01.492] iteration 6907: loss: 0.113180, loss_s1: 0.035984, loss_fp: 0.001511, loss_freq: 0.007257
[15:45:02.166] iteration 6908: loss: 0.115901, loss_s1: 0.046963, loss_fp: 0.006283, loss_freq: 0.047588
[15:45:02.821] iteration 6909: loss: 0.064024, loss_s1: 0.024674, loss_fp: 0.000708, loss_freq: 0.048049
[15:45:03.521] iteration 6910: loss: 0.070140, loss_s1: 0.041419, loss_fp: 0.002961, loss_freq: 0.027390
[15:45:04.184] iteration 6911: loss: 0.076294, loss_s1: 0.038868, loss_fp: 0.003298, loss_freq: 0.045873
[15:45:04.904] iteration 6912: loss: 0.088441, loss_s1: 0.070803, loss_fp: 0.000862, loss_freq: 0.018769
[15:45:05.581] iteration 6913: loss: 0.156652, loss_s1: 0.070005, loss_fp: 0.001011, loss_freq: 0.065307
[15:45:06.230] iteration 6914: loss: 0.112172, loss_s1: 0.101604, loss_fp: 0.003257, loss_freq: 0.067727
[15:45:06.869] iteration 6915: loss: 0.057055, loss_s1: 0.025625, loss_fp: 0.004399, loss_freq: 0.015729
[15:45:07.496] iteration 6916: loss: 0.127420, loss_s1: 0.065830, loss_fp: 0.004436, loss_freq: 0.035297
[15:45:08.120] iteration 6917: loss: 0.044144, loss_s1: 0.018846, loss_fp: 0.002096, loss_freq: 0.005496
[15:45:08.743] iteration 6918: loss: 0.070620, loss_s1: 0.051151, loss_fp: 0.000481, loss_freq: 0.024978
[15:45:09.369] iteration 6919: loss: 0.070456, loss_s1: 0.036107, loss_fp: 0.003020, loss_freq: 0.025682
[15:45:09.998] iteration 6920: loss: 0.090546, loss_s1: 0.058935, loss_fp: 0.000782, loss_freq: 0.019953
[15:45:10.625] iteration 6921: loss: 0.109442, loss_s1: 0.080759, loss_fp: 0.010496, loss_freq: 0.051852
[15:45:11.248] iteration 6922: loss: 0.102471, loss_s1: 0.030540, loss_fp: 0.000447, loss_freq: 0.029687
[15:45:11.870] iteration 6923: loss: 0.103996, loss_s1: 0.102654, loss_fp: 0.001314, loss_freq: 0.033875
[15:45:12.861] iteration 6924: loss: 0.049876, loss_s1: 0.033988, loss_fp: 0.002070, loss_freq: 0.011097
[15:45:13.492] iteration 6925: loss: 0.125270, loss_s1: 0.061535, loss_fp: 0.000404, loss_freq: 0.038077
[15:45:14.122] iteration 6926: loss: 0.131284, loss_s1: 0.050408, loss_fp: 0.001755, loss_freq: 0.039932
[15:45:14.748] iteration 6927: loss: 0.071567, loss_s1: 0.015736, loss_fp: 0.001277, loss_freq: 0.023777
[15:45:15.371] iteration 6928: loss: 0.092968, loss_s1: 0.061380, loss_fp: 0.004668, loss_freq: 0.012519
[15:45:15.997] iteration 6929: loss: 0.190780, loss_s1: 0.165436, loss_fp: 0.001716, loss_freq: 0.084142
[15:45:16.619] iteration 6930: loss: 0.057949, loss_s1: 0.031526, loss_fp: 0.000990, loss_freq: 0.022571
[15:45:17.247] iteration 6931: loss: 0.078476, loss_s1: 0.053820, loss_fp: 0.000935, loss_freq: 0.040559
[15:45:17.872] iteration 6932: loss: 0.083740, loss_s1: 0.075453, loss_fp: 0.005070, loss_freq: 0.028154
[15:45:18.524] iteration 6933: loss: 0.133892, loss_s1: 0.103511, loss_fp: 0.013762, loss_freq: 0.056097
[15:45:19.159] iteration 6934: loss: 0.122894, loss_s1: 0.042997, loss_fp: 0.002086, loss_freq: 0.019555
[15:45:19.782] iteration 6935: loss: 0.108445, loss_s1: 0.054036, loss_fp: 0.001022, loss_freq: 0.039126
[15:45:20.406] iteration 6936: loss: 0.098394, loss_s1: 0.070249, loss_fp: 0.002221, loss_freq: 0.058110
[15:45:21.029] iteration 6937: loss: 0.136932, loss_s1: 0.096664, loss_fp: 0.001525, loss_freq: 0.032051
[15:45:21.650] iteration 6938: loss: 0.067392, loss_s1: 0.062226, loss_fp: 0.000335, loss_freq: 0.016207
[15:45:22.273] iteration 6939: loss: 0.085491, loss_s1: 0.046020, loss_fp: 0.012270, loss_freq: 0.025308
[15:45:22.901] iteration 6940: loss: 0.112188, loss_s1: 0.068292, loss_fp: 0.000730, loss_freq: 0.011327
[15:45:23.526] iteration 6941: loss: 0.105609, loss_s1: 0.059274, loss_fp: 0.001737, loss_freq: 0.055911
[15:45:24.150] iteration 6942: loss: 0.099069, loss_s1: 0.057678, loss_fp: 0.001244, loss_freq: 0.034921
[15:45:24.775] iteration 6943: loss: 0.095820, loss_s1: 0.039583, loss_fp: 0.001524, loss_freq: 0.039013
[15:45:25.399] iteration 6944: loss: 0.068764, loss_s1: 0.042078, loss_fp: 0.001146, loss_freq: 0.012641
[15:45:26.023] iteration 6945: loss: 0.090225, loss_s1: 0.044110, loss_fp: 0.001647, loss_freq: 0.047001
[15:45:26.648] iteration 6946: loss: 0.096224, loss_s1: 0.027835, loss_fp: 0.007770, loss_freq: 0.026599
[15:45:27.274] iteration 6947: loss: 0.146210, loss_s1: 0.072482, loss_fp: 0.004320, loss_freq: 0.108168
[15:45:27.898] iteration 6948: loss: 0.081915, loss_s1: 0.032041, loss_fp: 0.013012, loss_freq: 0.044395
[15:45:28.524] iteration 6949: loss: 0.096939, loss_s1: 0.051097, loss_fp: 0.004835, loss_freq: 0.068782
[15:45:29.149] iteration 6950: loss: 0.073974, loss_s1: 0.052274, loss_fp: 0.004364, loss_freq: 0.026977
[15:45:29.775] iteration 6951: loss: 0.149895, loss_s1: 0.059301, loss_fp: 0.020005, loss_freq: 0.094972
[15:45:30.401] iteration 6952: loss: 0.086589, loss_s1: 0.058842, loss_fp: 0.002244, loss_freq: 0.050375
[15:45:31.025] iteration 6953: loss: 0.049615, loss_s1: 0.019221, loss_fp: 0.002137, loss_freq: 0.017760
[15:45:31.649] iteration 6954: loss: 0.065423, loss_s1: 0.022502, loss_fp: 0.001573, loss_freq: 0.018712
[15:45:32.312] iteration 6955: loss: 0.129065, loss_s1: 0.028593, loss_fp: 0.003169, loss_freq: 0.022299
[15:45:32.975] iteration 6956: loss: 0.065033, loss_s1: 0.028081, loss_fp: 0.001086, loss_freq: 0.046990
[15:45:33.630] iteration 6957: loss: 0.055746, loss_s1: 0.045891, loss_fp: 0.001377, loss_freq: 0.014144
[15:45:34.288] iteration 6958: loss: 0.075439, loss_s1: 0.026410, loss_fp: 0.001333, loss_freq: 0.038466
[15:45:34.943] iteration 6959: loss: 0.104847, loss_s1: 0.066357, loss_fp: 0.002391, loss_freq: 0.083414
[15:45:35.597] iteration 6960: loss: 0.132991, loss_s1: 0.098049, loss_fp: 0.002236, loss_freq: 0.067436
[15:45:36.226] iteration 6961: loss: 0.082781, loss_s1: 0.029557, loss_fp: 0.006894, loss_freq: 0.037951
[15:45:36.854] iteration 6962: loss: 0.117586, loss_s1: 0.087948, loss_fp: 0.000350, loss_freq: 0.035446
[15:45:37.480] iteration 6963: loss: 0.102298, loss_s1: 0.087471, loss_fp: 0.003493, loss_freq: 0.064011
[15:45:38.103] iteration 6964: loss: 0.093272, loss_s1: 0.023112, loss_fp: 0.001327, loss_freq: 0.032512
[15:45:38.727] iteration 6965: loss: 0.107736, loss_s1: 0.090665, loss_fp: 0.009286, loss_freq: 0.055810
[15:45:39.355] iteration 6966: loss: 0.126707, loss_s1: 0.113690, loss_fp: 0.007563, loss_freq: 0.054448
[15:45:40.032] iteration 6967: loss: 0.084352, loss_s1: 0.074700, loss_fp: 0.018353, loss_freq: 0.009551
[15:45:40.714] iteration 6968: loss: 0.090814, loss_s1: 0.033300, loss_fp: 0.000620, loss_freq: 0.055733
[15:45:41.387] iteration 6969: loss: 0.059306, loss_s1: 0.035590, loss_fp: 0.000995, loss_freq: 0.006474
[15:45:42.071] iteration 6970: loss: 0.052972, loss_s1: 0.041770, loss_fp: 0.000515, loss_freq: 0.007996
[15:45:42.757] iteration 6971: loss: 0.105325, loss_s1: 0.126196, loss_fp: 0.004648, loss_freq: 0.012914
[15:45:43.433] iteration 6972: loss: 0.102916, loss_s1: 0.046614, loss_fp: 0.013960, loss_freq: 0.054535
[15:45:44.072] iteration 6973: loss: 0.107008, loss_s1: 0.073642, loss_fp: 0.003284, loss_freq: 0.040413
[15:45:44.717] iteration 6974: loss: 0.068540, loss_s1: 0.048327, loss_fp: 0.000994, loss_freq: 0.036853
[15:45:45.358] iteration 6975: loss: 0.098476, loss_s1: 0.036483, loss_fp: 0.007282, loss_freq: 0.024769
[15:45:45.999] iteration 6976: loss: 0.094912, loss_s1: 0.044910, loss_fp: 0.000589, loss_freq: 0.061020
[15:45:46.641] iteration 6977: loss: 0.086019, loss_s1: 0.049577, loss_fp: 0.001626, loss_freq: 0.042597
[15:45:47.311] iteration 6978: loss: 0.079327, loss_s1: 0.034492, loss_fp: 0.005349, loss_freq: 0.027916
[15:45:47.969] iteration 6979: loss: 0.199187, loss_s1: 0.148010, loss_fp: 0.011557, loss_freq: 0.102117
[15:45:48.638] iteration 6980: loss: 0.089944, loss_s1: 0.051553, loss_fp: 0.000710, loss_freq: 0.018532
[15:45:49.312] iteration 6981: loss: 0.105995, loss_s1: 0.039673, loss_fp: 0.001493, loss_freq: 0.033170
[15:45:49.984] iteration 6982: loss: 0.065495, loss_s1: 0.024784, loss_fp: 0.001149, loss_freq: 0.009474
[15:45:50.648] iteration 6983: loss: 0.060971, loss_s1: 0.039043, loss_fp: 0.001063, loss_freq: 0.020431
[15:45:51.283] iteration 6984: loss: 0.065092, loss_s1: 0.034189, loss_fp: 0.002374, loss_freq: 0.026975
[15:45:51.911] iteration 6985: loss: 0.059237, loss_s1: 0.033082, loss_fp: 0.000771, loss_freq: 0.022027
[15:45:52.542] iteration 6986: loss: 0.073498, loss_s1: 0.053234, loss_fp: 0.002074, loss_freq: 0.012816
[15:45:53.170] iteration 6987: loss: 0.086118, loss_s1: 0.025538, loss_fp: 0.010705, loss_freq: 0.042594
[15:45:53.798] iteration 6988: loss: 0.082151, loss_s1: 0.053930, loss_fp: 0.022857, loss_freq: 0.012328
[15:45:54.427] iteration 6989: loss: 0.100426, loss_s1: 0.028731, loss_fp: 0.010377, loss_freq: 0.079460
[15:45:55.057] iteration 6990: loss: 0.096707, loss_s1: 0.033232, loss_fp: 0.002733, loss_freq: 0.066239
[15:45:55.683] iteration 6991: loss: 0.068668, loss_s1: 0.054771, loss_fp: 0.000639, loss_freq: 0.040297
[15:45:56.309] iteration 6992: loss: 0.059823, loss_s1: 0.012588, loss_fp: 0.000639, loss_freq: 0.027858
[15:45:56.936] iteration 6993: loss: 0.166374, loss_s1: 0.084223, loss_fp: 0.007495, loss_freq: 0.070329
[15:45:57.563] iteration 6994: loss: 0.107211, loss_s1: 0.059491, loss_fp: 0.002405, loss_freq: 0.048555
[15:45:58.195] iteration 6995: loss: 0.089081, loss_s1: 0.050161, loss_fp: 0.000969, loss_freq: 0.071977
[15:45:58.825] iteration 6996: loss: 0.110492, loss_s1: 0.039701, loss_fp: 0.007392, loss_freq: 0.059374
[15:45:59.449] iteration 6997: loss: 0.078088, loss_s1: 0.050514, loss_fp: 0.001149, loss_freq: 0.018912
[15:46:00.083] iteration 6998: loss: 0.127714, loss_s1: 0.120425, loss_fp: 0.001308, loss_freq: 0.069258
[15:46:00.710] iteration 6999: loss: 0.116347, loss_s1: 0.078070, loss_fp: 0.001195, loss_freq: 0.054498
[15:46:01.335] iteration 7000: loss: 0.150994, loss_s1: 0.124805, loss_fp: 0.006602, loss_freq: 0.055422
[15:46:04.535] iteration 7000 : mean_dice : 0.665179
[15:46:05.188] iteration 7001: loss: 0.057992, loss_s1: 0.028366, loss_fp: 0.011155, loss_freq: 0.021878
[15:46:05.813] iteration 7002: loss: 0.054821, loss_s1: 0.028555, loss_fp: 0.003336, loss_freq: 0.008086
[15:46:06.448] iteration 7003: loss: 0.114900, loss_s1: 0.076978, loss_fp: 0.007643, loss_freq: 0.059355
[15:46:07.076] iteration 7004: loss: 0.103690, loss_s1: 0.028386, loss_fp: 0.000856, loss_freq: 0.066579
[15:46:07.701] iteration 7005: loss: 0.079922, loss_s1: 0.066457, loss_fp: 0.003617, loss_freq: 0.037214
[15:46:08.368] iteration 7006: loss: 0.190791, loss_s1: 0.119090, loss_fp: 0.003595, loss_freq: 0.202215
[15:46:08.999] iteration 7007: loss: 0.121563, loss_s1: 0.070239, loss_fp: 0.005962, loss_freq: 0.030503
[15:46:09.627] iteration 7008: loss: 0.128627, loss_s1: 0.075935, loss_fp: 0.004383, loss_freq: 0.118619
[15:46:10.264] iteration 7009: loss: 0.051423, loss_s1: 0.012700, loss_fp: 0.002012, loss_freq: 0.027929
[15:46:10.889] iteration 7010: loss: 0.142671, loss_s1: 0.048863, loss_fp: 0.001055, loss_freq: 0.035255
[15:46:11.528] iteration 7011: loss: 0.063634, loss_s1: 0.049872, loss_fp: 0.001188, loss_freq: 0.010219
[15:46:12.151] iteration 7012: loss: 0.093620, loss_s1: 0.074784, loss_fp: 0.001578, loss_freq: 0.061853
[15:46:12.780] iteration 7013: loss: 0.079504, loss_s1: 0.055501, loss_fp: 0.001097, loss_freq: 0.023613
[15:46:13.407] iteration 7014: loss: 0.057699, loss_s1: 0.009127, loss_fp: 0.001277, loss_freq: 0.011655
[15:46:14.033] iteration 7015: loss: 0.078720, loss_s1: 0.031916, loss_fp: 0.001015, loss_freq: 0.009018
[15:46:14.665] iteration 7016: loss: 0.155790, loss_s1: 0.082646, loss_fp: 0.001256, loss_freq: 0.049019
[15:46:15.318] iteration 7017: loss: 0.070031, loss_s1: 0.025802, loss_fp: 0.001040, loss_freq: 0.029623
[15:46:15.981] iteration 7018: loss: 0.059942, loss_s1: 0.041652, loss_fp: 0.001275, loss_freq: 0.012616
[15:46:16.637] iteration 7019: loss: 0.066515, loss_s1: 0.027529, loss_fp: 0.001599, loss_freq: 0.026358
[15:46:17.264] iteration 7020: loss: 0.065054, loss_s1: 0.031571, loss_fp: 0.000599, loss_freq: 0.014597
[15:46:17.891] iteration 7021: loss: 0.095576, loss_s1: 0.036650, loss_fp: 0.000512, loss_freq: 0.042692
[15:46:18.517] iteration 7022: loss: 0.100637, loss_s1: 0.031845, loss_fp: 0.008126, loss_freq: 0.017371
[15:46:19.144] iteration 7023: loss: 0.112009, loss_s1: 0.087163, loss_fp: 0.015002, loss_freq: 0.022974
[15:46:19.769] iteration 7024: loss: 0.125824, loss_s1: 0.094638, loss_fp: 0.004323, loss_freq: 0.036948
[15:46:20.392] iteration 7025: loss: 0.107795, loss_s1: 0.057576, loss_fp: 0.002414, loss_freq: 0.053880
[15:46:21.021] iteration 7026: loss: 0.177545, loss_s1: 0.147919, loss_fp: 0.009989, loss_freq: 0.065569
[15:46:21.647] iteration 7027: loss: 0.103545, loss_s1: 0.055088, loss_fp: 0.011309, loss_freq: 0.069075
[15:46:22.270] iteration 7028: loss: 0.115058, loss_s1: 0.029701, loss_fp: 0.002829, loss_freq: 0.016155
[15:46:22.895] iteration 7029: loss: 0.060796, loss_s1: 0.021735, loss_fp: 0.001537, loss_freq: 0.037923
[15:46:23.521] iteration 7030: loss: 0.085689, loss_s1: 0.054091, loss_fp: 0.002663, loss_freq: 0.006457
[15:46:24.151] iteration 7031: loss: 0.146377, loss_s1: 0.118720, loss_fp: 0.000748, loss_freq: 0.095778
[15:46:24.775] iteration 7032: loss: 0.186927, loss_s1: 0.100956, loss_fp: 0.010366, loss_freq: 0.183364
[15:46:25.395] iteration 7033: loss: 0.106313, loss_s1: 0.064312, loss_fp: 0.001597, loss_freq: 0.027152
[15:46:26.017] iteration 7034: loss: 0.138851, loss_s1: 0.036731, loss_fp: 0.000608, loss_freq: 0.060111
[15:46:26.641] iteration 7035: loss: 0.102368, loss_s1: 0.059559, loss_fp: 0.003049, loss_freq: 0.078739
[15:46:27.267] iteration 7036: loss: 0.143505, loss_s1: 0.146588, loss_fp: 0.000908, loss_freq: 0.070147
[15:46:27.892] iteration 7037: loss: 0.104940, loss_s1: 0.078534, loss_fp: 0.001777, loss_freq: 0.066251
[15:46:28.515] iteration 7038: loss: 0.084102, loss_s1: 0.024078, loss_fp: 0.000799, loss_freq: 0.007297
[15:46:29.142] iteration 7039: loss: 0.134412, loss_s1: 0.073818, loss_fp: 0.044912, loss_freq: 0.039095
[15:46:29.769] iteration 7040: loss: 0.072511, loss_s1: 0.052763, loss_fp: 0.001452, loss_freq: 0.036947
[15:46:30.394] iteration 7041: loss: 0.066449, loss_s1: 0.046716, loss_fp: 0.002118, loss_freq: 0.032379
[15:46:31.015] iteration 7042: loss: 0.101135, loss_s1: 0.035301, loss_fp: 0.003015, loss_freq: 0.030279
[15:46:31.707] iteration 7043: loss: 0.084879, loss_s1: 0.047487, loss_fp: 0.000454, loss_freq: 0.071056
[15:46:32.369] iteration 7044: loss: 0.116152, loss_s1: 0.100482, loss_fp: 0.001459, loss_freq: 0.066243
[15:46:33.005] iteration 7045: loss: 0.101895, loss_s1: 0.063840, loss_fp: 0.003430, loss_freq: 0.020889
[15:46:33.637] iteration 7046: loss: 0.079333, loss_s1: 0.052751, loss_fp: 0.001069, loss_freq: 0.007654
[15:46:34.265] iteration 7047: loss: 0.120931, loss_s1: 0.084573, loss_fp: 0.002086, loss_freq: 0.027514
[15:46:34.887] iteration 7048: loss: 0.090745, loss_s1: 0.042385, loss_fp: 0.001533, loss_freq: 0.042753
[15:46:35.529] iteration 7049: loss: 0.066099, loss_s1: 0.023548, loss_fp: 0.000629, loss_freq: 0.018313
[15:46:36.172] iteration 7050: loss: 0.064978, loss_s1: 0.023051, loss_fp: 0.001343, loss_freq: 0.019960
[15:46:36.817] iteration 7051: loss: 0.164013, loss_s1: 0.055211, loss_fp: 0.041496, loss_freq: 0.075066
[15:46:37.464] iteration 7052: loss: 0.087840, loss_s1: 0.096830, loss_fp: 0.000919, loss_freq: 0.010008
[15:46:38.112] iteration 7053: loss: 0.074145, loss_s1: 0.062913, loss_fp: 0.000527, loss_freq: 0.019163
[15:46:38.750] iteration 7054: loss: 0.104314, loss_s1: 0.051129, loss_fp: 0.001426, loss_freq: 0.094099
[15:46:39.390] iteration 7055: loss: 0.140002, loss_s1: 0.131110, loss_fp: 0.001668, loss_freq: 0.051708
[15:46:40.034] iteration 7056: loss: 0.102416, loss_s1: 0.094212, loss_fp: 0.002548, loss_freq: 0.016541
[15:46:40.676] iteration 7057: loss: 0.136518, loss_s1: 0.134873, loss_fp: 0.011848, loss_freq: 0.029037
[15:46:41.316] iteration 7058: loss: 0.068672, loss_s1: 0.046303, loss_fp: 0.001177, loss_freq: 0.038590
[15:46:41.982] iteration 7059: loss: 0.090240, loss_s1: 0.066210, loss_fp: 0.001548, loss_freq: 0.053528
[15:46:42.659] iteration 7060: loss: 0.103868, loss_s1: 0.076216, loss_fp: 0.002676, loss_freq: 0.026475
[15:46:43.289] iteration 7061: loss: 0.069806, loss_s1: 0.034412, loss_fp: 0.001456, loss_freq: 0.030777
[15:46:43.916] iteration 7062: loss: 0.083080, loss_s1: 0.040940, loss_fp: 0.006355, loss_freq: 0.034737
[15:46:44.543] iteration 7063: loss: 0.149320, loss_s1: 0.121627, loss_fp: 0.021759, loss_freq: 0.061166
[15:46:45.167] iteration 7064: loss: 0.145235, loss_s1: 0.139016, loss_fp: 0.003239, loss_freq: 0.054655
[15:46:45.792] iteration 7065: loss: 0.087174, loss_s1: 0.055623, loss_fp: 0.001947, loss_freq: 0.032202
[15:46:46.417] iteration 7066: loss: 0.125488, loss_s1: 0.075465, loss_fp: 0.002112, loss_freq: 0.048267
[15:46:47.056] iteration 7067: loss: 0.075602, loss_s1: 0.048476, loss_fp: 0.019010, loss_freq: 0.031767
[15:46:47.695] iteration 7068: loss: 0.061642, loss_s1: 0.044654, loss_fp: 0.001923, loss_freq: 0.010440
[15:46:48.336] iteration 7069: loss: 0.122171, loss_s1: 0.101162, loss_fp: 0.005615, loss_freq: 0.035336
[15:46:48.978] iteration 7070: loss: 0.086832, loss_s1: 0.042721, loss_fp: 0.031045, loss_freq: 0.045867
[15:46:49.617] iteration 7071: loss: 0.081320, loss_s1: 0.064629, loss_fp: 0.003006, loss_freq: 0.020638
[15:46:50.261] iteration 7072: loss: 0.090443, loss_s1: 0.041733, loss_fp: 0.002723, loss_freq: 0.039120
[15:46:50.906] iteration 7073: loss: 0.092350, loss_s1: 0.041671, loss_fp: 0.005586, loss_freq: 0.037065
[15:46:51.549] iteration 7074: loss: 0.141809, loss_s1: 0.052054, loss_fp: 0.001619, loss_freq: 0.062370
[15:46:52.193] iteration 7075: loss: 0.182639, loss_s1: 0.121924, loss_fp: 0.010095, loss_freq: 0.106577
[15:46:52.820] iteration 7076: loss: 0.082013, loss_s1: 0.039719, loss_fp: 0.010412, loss_freq: 0.020574
[15:46:53.443] iteration 7077: loss: 0.102189, loss_s1: 0.098647, loss_fp: 0.000815, loss_freq: 0.024222
[15:46:54.115] iteration 7078: loss: 0.071652, loss_s1: 0.038989, loss_fp: 0.000673, loss_freq: 0.008297
[15:46:54.739] iteration 7079: loss: 0.088063, loss_s1: 0.089013, loss_fp: 0.000649, loss_freq: 0.027732
[15:46:55.364] iteration 7080: loss: 0.048704, loss_s1: 0.008345, loss_fp: 0.000793, loss_freq: 0.013534
[15:46:55.996] iteration 7081: loss: 0.116297, loss_s1: 0.057716, loss_fp: 0.004247, loss_freq: 0.078544
[15:46:56.617] iteration 7082: loss: 0.100664, loss_s1: 0.094746, loss_fp: 0.001444, loss_freq: 0.042823
[15:46:57.240] iteration 7083: loss: 0.087215, loss_s1: 0.079157, loss_fp: 0.001510, loss_freq: 0.014073
[15:46:57.864] iteration 7084: loss: 0.144290, loss_s1: 0.105496, loss_fp: 0.003730, loss_freq: 0.090650
[15:46:58.859] iteration 7085: loss: 0.073552, loss_s1: 0.063167, loss_fp: 0.000485, loss_freq: 0.015379
[15:46:59.484] iteration 7086: loss: 0.085101, loss_s1: 0.058335, loss_fp: 0.001083, loss_freq: 0.021884
[15:47:00.112] iteration 7087: loss: 0.112563, loss_s1: 0.080209, loss_fp: 0.004889, loss_freq: 0.031804
[15:47:00.737] iteration 7088: loss: 0.124280, loss_s1: 0.079926, loss_fp: 0.002944, loss_freq: 0.023403
[15:47:01.362] iteration 7089: loss: 0.067529, loss_s1: 0.022841, loss_fp: 0.001193, loss_freq: 0.026899
[15:47:01.989] iteration 7090: loss: 0.103435, loss_s1: 0.041363, loss_fp: 0.005282, loss_freq: 0.043996
[15:47:02.620] iteration 7091: loss: 0.046916, loss_s1: 0.018932, loss_fp: 0.001043, loss_freq: 0.009645
[15:47:03.246] iteration 7092: loss: 0.102102, loss_s1: 0.068266, loss_fp: 0.002254, loss_freq: 0.067711
[15:47:03.873] iteration 7093: loss: 0.107598, loss_s1: 0.105936, loss_fp: 0.016534, loss_freq: 0.029540
[15:47:04.502] iteration 7094: loss: 0.121859, loss_s1: 0.119940, loss_fp: 0.005086, loss_freq: 0.057425
[15:47:05.127] iteration 7095: loss: 0.104729, loss_s1: 0.031639, loss_fp: 0.000622, loss_freq: 0.027129
[15:47:05.750] iteration 7096: loss: 0.103022, loss_s1: 0.079585, loss_fp: 0.001531, loss_freq: 0.040405
[15:47:06.376] iteration 7097: loss: 0.084229, loss_s1: 0.047106, loss_fp: 0.019505, loss_freq: 0.036540
[15:47:07.002] iteration 7098: loss: 0.130384, loss_s1: 0.059246, loss_fp: 0.001026, loss_freq: 0.053909
[15:47:07.678] iteration 7099: loss: 0.079805, loss_s1: 0.063456, loss_fp: 0.003436, loss_freq: 0.028451
[15:47:08.415] iteration 7100: loss: 0.124030, loss_s1: 0.066677, loss_fp: 0.005391, loss_freq: 0.071140
[15:47:09.088] iteration 7101: loss: 0.096870, loss_s1: 0.073534, loss_fp: 0.001831, loss_freq: 0.027181
[15:47:09.779] iteration 7102: loss: 0.088411, loss_s1: 0.051211, loss_fp: 0.003447, loss_freq: 0.039130
[15:47:10.490] iteration 7103: loss: 0.119405, loss_s1: 0.048611, loss_fp: 0.002014, loss_freq: 0.045162
[15:47:11.147] iteration 7104: loss: 0.103467, loss_s1: 0.032757, loss_fp: 0.007415, loss_freq: 0.029981
[15:47:11.777] iteration 7105: loss: 0.075805, loss_s1: 0.081923, loss_fp: 0.008728, loss_freq: 0.002745
[15:47:12.400] iteration 7106: loss: 0.083899, loss_s1: 0.051026, loss_fp: 0.001382, loss_freq: 0.022567
[15:47:13.030] iteration 7107: loss: 0.100195, loss_s1: 0.038279, loss_fp: 0.001038, loss_freq: 0.031284
[15:47:13.660] iteration 7108: loss: 0.122359, loss_s1: 0.115209, loss_fp: 0.008131, loss_freq: 0.063062
[15:47:14.285] iteration 7109: loss: 0.071729, loss_s1: 0.034162, loss_fp: 0.002968, loss_freq: 0.023816
[15:47:14.919] iteration 7110: loss: 0.088388, loss_s1: 0.047535, loss_fp: 0.003475, loss_freq: 0.060802
[15:47:15.545] iteration 7111: loss: 0.100037, loss_s1: 0.071994, loss_fp: 0.003655, loss_freq: 0.065534
[15:47:16.170] iteration 7112: loss: 0.113947, loss_s1: 0.037506, loss_fp: 0.004525, loss_freq: 0.040525
[15:47:16.792] iteration 7113: loss: 0.085830, loss_s1: 0.049673, loss_fp: 0.006068, loss_freq: 0.041341
[15:47:17.416] iteration 7114: loss: 0.070113, loss_s1: 0.036317, loss_fp: 0.003086, loss_freq: 0.033864
[15:47:18.041] iteration 7115: loss: 0.073099, loss_s1: 0.049039, loss_fp: 0.007493, loss_freq: 0.017999
[15:47:18.728] iteration 7116: loss: 0.136577, loss_s1: 0.050306, loss_fp: 0.009078, loss_freq: 0.040530
[15:47:19.388] iteration 7117: loss: 0.090267, loss_s1: 0.079603, loss_fp: 0.002238, loss_freq: 0.049903
[15:47:20.049] iteration 7118: loss: 0.061281, loss_s1: 0.023598, loss_fp: 0.001044, loss_freq: 0.023775
[15:47:20.703] iteration 7119: loss: 0.105866, loss_s1: 0.058253, loss_fp: 0.001538, loss_freq: 0.029956
[15:47:21.326] iteration 7120: loss: 0.107082, loss_s1: 0.062680, loss_fp: 0.017480, loss_freq: 0.039967
[15:47:21.950] iteration 7121: loss: 0.141049, loss_s1: 0.050629, loss_fp: 0.018784, loss_freq: 0.034513
[15:47:22.575] iteration 7122: loss: 0.085730, loss_s1: 0.044644, loss_fp: 0.006597, loss_freq: 0.027355
[15:47:23.203] iteration 7123: loss: 0.124639, loss_s1: 0.082488, loss_fp: 0.003038, loss_freq: 0.080706
[15:47:23.833] iteration 7124: loss: 0.088515, loss_s1: 0.078022, loss_fp: 0.001926, loss_freq: 0.032960
[15:47:24.457] iteration 7125: loss: 0.102056, loss_s1: 0.070454, loss_fp: 0.002205, loss_freq: 0.024584
[15:47:25.076] iteration 7126: loss: 0.075559, loss_s1: 0.063063, loss_fp: 0.000664, loss_freq: 0.035172
[15:47:25.699] iteration 7127: loss: 0.078755, loss_s1: 0.068986, loss_fp: 0.004790, loss_freq: 0.026281
[15:47:26.326] iteration 7128: loss: 0.053409, loss_s1: 0.033640, loss_fp: 0.001841, loss_freq: 0.016595
[15:47:26.949] iteration 7129: loss: 0.117739, loss_s1: 0.077302, loss_fp: 0.005007, loss_freq: 0.070920
[15:47:27.573] iteration 7130: loss: 0.065841, loss_s1: 0.038278, loss_fp: 0.000792, loss_freq: 0.017951
[15:47:28.229] iteration 7131: loss: 0.075874, loss_s1: 0.046882, loss_fp: 0.000533, loss_freq: 0.023650
[15:47:28.859] iteration 7132: loss: 0.067497, loss_s1: 0.076038, loss_fp: 0.002031, loss_freq: 0.004517
[15:47:29.483] iteration 7133: loss: 0.088933, loss_s1: 0.056373, loss_fp: 0.000938, loss_freq: 0.044524
[15:47:30.106] iteration 7134: loss: 0.136793, loss_s1: 0.105333, loss_fp: 0.001491, loss_freq: 0.080434
[15:47:30.731] iteration 7135: loss: 0.072704, loss_s1: 0.075624, loss_fp: 0.001022, loss_freq: 0.016736
[15:47:31.360] iteration 7136: loss: 0.203061, loss_s1: 0.030123, loss_fp: 0.000879, loss_freq: 0.024629
[15:47:31.984] iteration 7137: loss: 0.080766, loss_s1: 0.049082, loss_fp: 0.002501, loss_freq: 0.033307
[15:47:32.612] iteration 7138: loss: 0.071689, loss_s1: 0.026233, loss_fp: 0.002516, loss_freq: 0.032772
[15:47:33.236] iteration 7139: loss: 0.105026, loss_s1: 0.072047, loss_fp: 0.001205, loss_freq: 0.016164
[15:47:33.861] iteration 7140: loss: 0.128440, loss_s1: 0.114054, loss_fp: 0.001422, loss_freq: 0.047799
[15:47:34.487] iteration 7141: loss: 0.043538, loss_s1: 0.004811, loss_fp: 0.000949, loss_freq: 0.006272
[15:47:35.114] iteration 7142: loss: 0.148920, loss_s1: 0.076112, loss_fp: 0.000735, loss_freq: 0.082323
[15:47:35.739] iteration 7143: loss: 0.053748, loss_s1: 0.030120, loss_fp: 0.000904, loss_freq: 0.016068
[15:47:36.360] iteration 7144: loss: 0.069244, loss_s1: 0.063017, loss_fp: 0.001988, loss_freq: 0.020938
[15:47:36.987] iteration 7145: loss: 0.093542, loss_s1: 0.026820, loss_fp: 0.002426, loss_freq: 0.051540
[15:47:37.612] iteration 7146: loss: 0.080277, loss_s1: 0.039513, loss_fp: 0.006985, loss_freq: 0.014218
[15:47:38.239] iteration 7147: loss: 0.102937, loss_s1: 0.075027, loss_fp: 0.001982, loss_freq: 0.026167
[15:47:38.863] iteration 7148: loss: 0.114023, loss_s1: 0.092802, loss_fp: 0.001210, loss_freq: 0.007683
[15:47:39.487] iteration 7149: loss: 0.049938, loss_s1: 0.039810, loss_fp: 0.001616, loss_freq: 0.004112
[15:47:40.110] iteration 7150: loss: 0.092776, loss_s1: 0.033697, loss_fp: 0.002287, loss_freq: 0.048407
[15:47:40.735] iteration 7151: loss: 0.110028, loss_s1: 0.036643, loss_fp: 0.003392, loss_freq: 0.040268
[15:47:41.360] iteration 7152: loss: 0.081056, loss_s1: 0.048280, loss_fp: 0.000585, loss_freq: 0.038480
[15:47:41.983] iteration 7153: loss: 0.085571, loss_s1: 0.033360, loss_fp: 0.001623, loss_freq: 0.043456
[15:47:42.612] iteration 7154: loss: 0.093891, loss_s1: 0.045263, loss_fp: 0.004065, loss_freq: 0.033152
[15:47:43.235] iteration 7155: loss: 0.093328, loss_s1: 0.072370, loss_fp: 0.001592, loss_freq: 0.048854
[15:47:43.859] iteration 7156: loss: 0.118521, loss_s1: 0.058827, loss_fp: 0.001490, loss_freq: 0.074948
[15:47:44.480] iteration 7157: loss: 0.070158, loss_s1: 0.027980, loss_fp: 0.001114, loss_freq: 0.038748
[15:47:45.103] iteration 7158: loss: 0.067287, loss_s1: 0.039997, loss_fp: 0.001333, loss_freq: 0.011142
[15:47:45.725] iteration 7159: loss: 0.101143, loss_s1: 0.055611, loss_fp: 0.000968, loss_freq: 0.049993
[15:47:46.348] iteration 7160: loss: 0.137085, loss_s1: 0.098028, loss_fp: 0.001985, loss_freq: 0.056112
[15:47:46.966] iteration 7161: loss: 0.100795, loss_s1: 0.084572, loss_fp: 0.001356, loss_freq: 0.062652
[15:47:47.596] iteration 7162: loss: 0.065339, loss_s1: 0.062124, loss_fp: 0.001474, loss_freq: 0.020850
[15:47:48.223] iteration 7163: loss: 0.065290, loss_s1: 0.028735, loss_fp: 0.000486, loss_freq: 0.019961
[15:47:48.848] iteration 7164: loss: 0.100154, loss_s1: 0.087275, loss_fp: 0.004549, loss_freq: 0.033749
[15:47:49.475] iteration 7165: loss: 0.125404, loss_s1: 0.100101, loss_fp: 0.014872, loss_freq: 0.052723
[15:47:50.098] iteration 7166: loss: 0.110611, loss_s1: 0.088601, loss_fp: 0.009191, loss_freq: 0.072037
[15:47:50.721] iteration 7167: loss: 0.155694, loss_s1: 0.131079, loss_fp: 0.017056, loss_freq: 0.086285
[15:47:51.344] iteration 7168: loss: 0.126420, loss_s1: 0.090780, loss_fp: 0.001850, loss_freq: 0.063967
[15:47:51.966] iteration 7169: loss: 0.095299, loss_s1: 0.070059, loss_fp: 0.011129, loss_freq: 0.046216
[15:47:52.591] iteration 7170: loss: 0.063753, loss_s1: 0.030698, loss_fp: 0.000869, loss_freq: 0.046640
[15:47:53.224] iteration 7171: loss: 0.131675, loss_s1: 0.049367, loss_fp: 0.003892, loss_freq: 0.021974
[15:47:53.882] iteration 7172: loss: 0.067589, loss_s1: 0.030865, loss_fp: 0.003372, loss_freq: 0.013081
[15:47:54.516] iteration 7173: loss: 0.115165, loss_s1: 0.109212, loss_fp: 0.006146, loss_freq: 0.049831
[15:47:55.149] iteration 7174: loss: 0.102367, loss_s1: 0.082858, loss_fp: 0.001903, loss_freq: 0.027051
[15:47:55.773] iteration 7175: loss: 0.127442, loss_s1: 0.032453, loss_fp: 0.001777, loss_freq: 0.013393
[15:47:56.406] iteration 7176: loss: 0.072940, loss_s1: 0.035601, loss_fp: 0.000656, loss_freq: 0.029046
[15:47:57.036] iteration 7177: loss: 0.167035, loss_s1: 0.037879, loss_fp: 0.000707, loss_freq: 0.032195
[15:47:57.667] iteration 7178: loss: 0.079690, loss_s1: 0.040227, loss_fp: 0.001177, loss_freq: 0.028149
[15:47:58.293] iteration 7179: loss: 0.068416, loss_s1: 0.066380, loss_fp: 0.003004, loss_freq: 0.025550
[15:47:58.919] iteration 7180: loss: 0.070488, loss_s1: 0.024480, loss_fp: 0.004001, loss_freq: 0.032381
[15:47:59.576] iteration 7181: loss: 0.101972, loss_s1: 0.038397, loss_fp: 0.002170, loss_freq: 0.032315
[15:48:00.239] iteration 7182: loss: 0.070646, loss_s1: 0.019221, loss_fp: 0.002128, loss_freq: 0.020117
[15:48:00.882] iteration 7183: loss: 0.090223, loss_s1: 0.044155, loss_fp: 0.003136, loss_freq: 0.010786
[15:48:01.537] iteration 7184: loss: 0.062773, loss_s1: 0.043635, loss_fp: 0.006075, loss_freq: 0.017671
[15:48:02.200] iteration 7185: loss: 0.064211, loss_s1: 0.021526, loss_fp: 0.004705, loss_freq: 0.026917
[15:48:02.830] iteration 7186: loss: 0.080543, loss_s1: 0.018746, loss_fp: 0.005711, loss_freq: 0.046807
[15:48:03.453] iteration 7187: loss: 0.110954, loss_s1: 0.103695, loss_fp: 0.001489, loss_freq: 0.034855
[15:48:04.080] iteration 7188: loss: 0.136776, loss_s1: 0.128820, loss_fp: 0.009781, loss_freq: 0.053330
[15:48:04.706] iteration 7189: loss: 0.179310, loss_s1: 0.102778, loss_fp: 0.017370, loss_freq: 0.075530
[15:48:05.330] iteration 7190: loss: 0.075809, loss_s1: 0.025434, loss_fp: 0.004456, loss_freq: 0.036483
[15:48:05.957] iteration 7191: loss: 0.121909, loss_s1: 0.041672, loss_fp: 0.000326, loss_freq: 0.026422
[15:48:06.581] iteration 7192: loss: 0.123403, loss_s1: 0.117981, loss_fp: 0.001677, loss_freq: 0.038970
[15:48:07.206] iteration 7193: loss: 0.234683, loss_s1: 0.188869, loss_fp: 0.002679, loss_freq: 0.145308
[15:48:07.831] iteration 7194: loss: 0.077950, loss_s1: 0.054015, loss_fp: 0.004280, loss_freq: 0.024592
[15:48:08.458] iteration 7195: loss: 0.101815, loss_s1: 0.031070, loss_fp: 0.002993, loss_freq: 0.037573
[15:48:09.083] iteration 7196: loss: 0.098999, loss_s1: 0.045513, loss_fp: 0.008555, loss_freq: 0.077255
[15:48:09.709] iteration 7197: loss: 0.109629, loss_s1: 0.080312, loss_fp: 0.001931, loss_freq: 0.061513
[15:48:10.337] iteration 7198: loss: 0.082044, loss_s1: 0.046136, loss_fp: 0.002366, loss_freq: 0.050798
[15:48:10.966] iteration 7199: loss: 0.043612, loss_s1: 0.018396, loss_fp: 0.001665, loss_freq: 0.004972
[15:48:11.591] iteration 7200: loss: 0.118657, loss_s1: 0.112654, loss_fp: 0.005182, loss_freq: 0.041694
[15:48:14.680] iteration 7200 : mean_dice : 0.656091
[15:48:15.328] iteration 7201: loss: 0.127941, loss_s1: 0.163165, loss_fp: 0.001265, loss_freq: 0.029730
[15:48:15.989] iteration 7202: loss: 0.085437, loss_s1: 0.057983, loss_fp: 0.001222, loss_freq: 0.024701
[15:48:16.648] iteration 7203: loss: 0.118691, loss_s1: 0.058334, loss_fp: 0.000998, loss_freq: 0.023029
[15:48:17.307] iteration 7204: loss: 0.158657, loss_s1: 0.086747, loss_fp: 0.016248, loss_freq: 0.160365
[15:48:17.964] iteration 7205: loss: 0.047292, loss_s1: 0.017509, loss_fp: 0.000914, loss_freq: 0.019454
[15:48:18.627] iteration 7206: loss: 0.074947, loss_s1: 0.032559, loss_fp: 0.003844, loss_freq: 0.026130
[15:48:19.273] iteration 7207: loss: 0.106160, loss_s1: 0.096455, loss_fp: 0.002720, loss_freq: 0.029740
[15:48:19.899] iteration 7208: loss: 0.097261, loss_s1: 0.055101, loss_fp: 0.001487, loss_freq: 0.023790
[15:48:20.527] iteration 7209: loss: 0.112382, loss_s1: 0.066770, loss_fp: 0.001116, loss_freq: 0.055729
[15:48:21.151] iteration 7210: loss: 0.090198, loss_s1: 0.033421, loss_fp: 0.005133, loss_freq: 0.035925
[15:48:21.774] iteration 7211: loss: 0.127834, loss_s1: 0.039900, loss_fp: 0.003598, loss_freq: 0.017716
[15:48:22.400] iteration 7212: loss: 0.192097, loss_s1: 0.148653, loss_fp: 0.011943, loss_freq: 0.109952
[15:48:23.029] iteration 7213: loss: 0.069211, loss_s1: 0.078128, loss_fp: 0.000524, loss_freq: 0.009201
[15:48:23.654] iteration 7214: loss: 0.072637, loss_s1: 0.070735, loss_fp: 0.007600, loss_freq: 0.012438
[15:48:24.279] iteration 7215: loss: 0.103971, loss_s1: 0.050286, loss_fp: 0.003660, loss_freq: 0.096147
[15:48:24.904] iteration 7216: loss: 0.151287, loss_s1: 0.154821, loss_fp: 0.002903, loss_freq: 0.077356
[15:48:25.530] iteration 7217: loss: 0.100005, loss_s1: 0.080959, loss_fp: 0.015745, loss_freq: 0.032802
[15:48:26.161] iteration 7218: loss: 0.080681, loss_s1: 0.048494, loss_fp: 0.001397, loss_freq: 0.022305
[15:48:26.792] iteration 7219: loss: 0.101670, loss_s1: 0.054607, loss_fp: 0.000863, loss_freq: 0.049702
[15:48:27.421] iteration 7220: loss: 0.059457, loss_s1: 0.052001, loss_fp: 0.001105, loss_freq: 0.009793
[15:48:28.046] iteration 7221: loss: 0.099556, loss_s1: 0.029639, loss_fp: 0.001624, loss_freq: 0.047882
[15:48:28.669] iteration 7222: loss: 0.077450, loss_s1: 0.061096, loss_fp: 0.001759, loss_freq: 0.034693
[15:48:29.294] iteration 7223: loss: 0.065112, loss_s1: 0.019515, loss_fp: 0.009219, loss_freq: 0.035920
[15:48:29.967] iteration 7224: loss: 0.114970, loss_s1: 0.064723, loss_fp: 0.003377, loss_freq: 0.033010
[15:48:30.618] iteration 7225: loss: 0.144609, loss_s1: 0.153634, loss_fp: 0.003716, loss_freq: 0.029456
[15:48:31.252] iteration 7226: loss: 0.110490, loss_s1: 0.028549, loss_fp: 0.002129, loss_freq: 0.056608
[15:48:31.883] iteration 7227: loss: 0.130526, loss_s1: 0.071926, loss_fp: 0.003961, loss_freq: 0.059002
[15:48:32.511] iteration 7228: loss: 0.115365, loss_s1: 0.099344, loss_fp: 0.017427, loss_freq: 0.046085
[15:48:33.141] iteration 7229: loss: 0.065816, loss_s1: 0.038979, loss_fp: 0.001312, loss_freq: 0.036778
[15:48:33.769] iteration 7230: loss: 0.072141, loss_s1: 0.027028, loss_fp: 0.002724, loss_freq: 0.017528
[15:48:34.397] iteration 7231: loss: 0.111092, loss_s1: 0.078211, loss_fp: 0.003995, loss_freq: 0.088079
[15:48:35.028] iteration 7232: loss: 0.095200, loss_s1: 0.085482, loss_fp: 0.006889, loss_freq: 0.020111
[15:48:35.656] iteration 7233: loss: 0.089042, loss_s1: 0.033388, loss_fp: 0.004209, loss_freq: 0.031446
[15:48:36.282] iteration 7234: loss: 0.100483, loss_s1: 0.081592, loss_fp: 0.001210, loss_freq: 0.029393
[15:48:36.908] iteration 7235: loss: 0.104556, loss_s1: 0.039941, loss_fp: 0.000799, loss_freq: 0.042435
[15:48:37.540] iteration 7236: loss: 0.104526, loss_s1: 0.079529, loss_fp: 0.007943, loss_freq: 0.051432
[15:48:38.172] iteration 7237: loss: 0.062502, loss_s1: 0.053285, loss_fp: 0.002344, loss_freq: 0.016144
[15:48:38.801] iteration 7238: loss: 0.107012, loss_s1: 0.056065, loss_fp: 0.000911, loss_freq: 0.039131
[15:48:39.428] iteration 7239: loss: 0.068605, loss_s1: 0.013816, loss_fp: 0.001267, loss_freq: 0.018799
[15:48:40.054] iteration 7240: loss: 0.094579, loss_s1: 0.065618, loss_fp: 0.003017, loss_freq: 0.019113
[15:48:40.680] iteration 7241: loss: 0.069867, loss_s1: 0.025233, loss_fp: 0.001020, loss_freq: 0.020958
[15:48:41.305] iteration 7242: loss: 0.110780, loss_s1: 0.082347, loss_fp: 0.000533, loss_freq: 0.038840
[15:48:41.929] iteration 7243: loss: 0.151461, loss_s1: 0.051525, loss_fp: 0.030828, loss_freq: 0.093460
[15:48:42.550] iteration 7244: loss: 0.086449, loss_s1: 0.053945, loss_fp: 0.000620, loss_freq: 0.018975
[15:48:43.177] iteration 7245: loss: 0.109852, loss_s1: 0.087411, loss_fp: 0.001082, loss_freq: 0.064532
[15:48:44.131] iteration 7246: loss: 0.128329, loss_s1: 0.063855, loss_fp: 0.003180, loss_freq: 0.022784
[15:48:44.756] iteration 7247: loss: 0.114387, loss_s1: 0.077441, loss_fp: 0.002253, loss_freq: 0.064331
[15:48:45.390] iteration 7248: loss: 0.090220, loss_s1: 0.050249, loss_fp: 0.001791, loss_freq: 0.037646
[15:48:46.017] iteration 7249: loss: 0.098474, loss_s1: 0.016358, loss_fp: 0.002754, loss_freq: 0.016407
[15:48:46.647] iteration 7250: loss: 0.070646, loss_s1: 0.035639, loss_fp: 0.001445, loss_freq: 0.025644
[15:48:47.279] iteration 7251: loss: 0.150239, loss_s1: 0.046841, loss_fp: 0.001942, loss_freq: 0.050856
[15:48:47.908] iteration 7252: loss: 0.050001, loss_s1: 0.036865, loss_fp: 0.002321, loss_freq: 0.006020
[15:48:48.533] iteration 7253: loss: 0.067934, loss_s1: 0.045136, loss_fp: 0.005454, loss_freq: 0.024500
[15:48:49.160] iteration 7254: loss: 0.112173, loss_s1: 0.104166, loss_fp: 0.012583, loss_freq: 0.019387
[15:48:49.784] iteration 7255: loss: 0.092501, loss_s1: 0.073299, loss_fp: 0.006073, loss_freq: 0.054209
[15:48:50.463] iteration 7256: loss: 0.052157, loss_s1: 0.012544, loss_fp: 0.000349, loss_freq: 0.008361
[15:48:51.140] iteration 7257: loss: 0.073440, loss_s1: 0.044469, loss_fp: 0.001770, loss_freq: 0.037507
[15:48:51.822] iteration 7258: loss: 0.085730, loss_s1: 0.059439, loss_fp: 0.004820, loss_freq: 0.016016
[15:48:52.485] iteration 7259: loss: 0.070202, loss_s1: 0.013465, loss_fp: 0.001560, loss_freq: 0.038436
[15:48:53.144] iteration 7260: loss: 0.078873, loss_s1: 0.046812, loss_fp: 0.002134, loss_freq: 0.039544
[15:48:53.808] iteration 7261: loss: 0.136620, loss_s1: 0.117449, loss_fp: 0.007094, loss_freq: 0.070412
[15:48:54.468] iteration 7262: loss: 0.116433, loss_s1: 0.074222, loss_fp: 0.000920, loss_freq: 0.045494
[15:48:55.096] iteration 7263: loss: 0.086825, loss_s1: 0.067008, loss_fp: 0.005934, loss_freq: 0.023770
[15:48:55.780] iteration 7264: loss: 0.071021, loss_s1: 0.052048, loss_fp: 0.001047, loss_freq: 0.018060
[15:48:56.433] iteration 7265: loss: 0.097669, loss_s1: 0.079940, loss_fp: 0.001858, loss_freq: 0.025219
[15:48:57.091] iteration 7266: loss: 0.070819, loss_s1: 0.038769, loss_fp: 0.000583, loss_freq: 0.025328
[15:48:57.751] iteration 7267: loss: 0.093859, loss_s1: 0.077100, loss_fp: 0.001055, loss_freq: 0.026257
[15:48:58.409] iteration 7268: loss: 0.076927, loss_s1: 0.027177, loss_fp: 0.002980, loss_freq: 0.023268
[15:48:59.039] iteration 7269: loss: 0.196529, loss_s1: 0.160903, loss_fp: 0.001346, loss_freq: 0.150879
[15:48:59.664] iteration 7270: loss: 0.078754, loss_s1: 0.043867, loss_fp: 0.002202, loss_freq: 0.031786
[15:49:00.289] iteration 7271: loss: 0.109109, loss_s1: 0.069531, loss_fp: 0.005695, loss_freq: 0.051131
[15:49:00.912] iteration 7272: loss: 0.089282, loss_s1: 0.067189, loss_fp: 0.006952, loss_freq: 0.027901
[15:49:01.538] iteration 7273: loss: 0.160666, loss_s1: 0.113505, loss_fp: 0.015091, loss_freq: 0.101340
[15:49:02.160] iteration 7274: loss: 0.096803, loss_s1: 0.084694, loss_fp: 0.002245, loss_freq: 0.059011
[15:49:02.787] iteration 7275: loss: 0.068983, loss_s1: 0.031930, loss_fp: 0.001768, loss_freq: 0.030050
[15:49:03.410] iteration 7276: loss: 0.059041, loss_s1: 0.051716, loss_fp: 0.001108, loss_freq: 0.021380
[15:49:04.032] iteration 7277: loss: 0.080108, loss_s1: 0.022592, loss_fp: 0.002216, loss_freq: 0.029130
[15:49:04.658] iteration 7278: loss: 0.082761, loss_s1: 0.068211, loss_fp: 0.005881, loss_freq: 0.042565
[15:49:05.282] iteration 7279: loss: 0.070074, loss_s1: 0.055324, loss_fp: 0.003347, loss_freq: 0.023472
[15:49:05.907] iteration 7280: loss: 0.133564, loss_s1: 0.045576, loss_fp: 0.001041, loss_freq: 0.022193
[15:49:06.530] iteration 7281: loss: 0.112071, loss_s1: 0.079287, loss_fp: 0.003120, loss_freq: 0.049709
[15:49:07.153] iteration 7282: loss: 0.149855, loss_s1: 0.101292, loss_fp: 0.003919, loss_freq: 0.054316
[15:49:07.779] iteration 7283: loss: 0.139487, loss_s1: 0.064974, loss_fp: 0.002121, loss_freq: 0.054788
[15:49:08.405] iteration 7284: loss: 0.127091, loss_s1: 0.112366, loss_fp: 0.002534, loss_freq: 0.076121
[15:49:09.032] iteration 7285: loss: 0.095778, loss_s1: 0.055224, loss_fp: 0.010232, loss_freq: 0.062517
[15:49:09.656] iteration 7286: loss: 0.099776, loss_s1: 0.033100, loss_fp: 0.001821, loss_freq: 0.016557
[15:49:10.281] iteration 7287: loss: 0.081143, loss_s1: 0.061847, loss_fp: 0.006680, loss_freq: 0.035078
[15:49:10.904] iteration 7288: loss: 0.111659, loss_s1: 0.048031, loss_fp: 0.020463, loss_freq: 0.074165
[15:49:11.527] iteration 7289: loss: 0.098664, loss_s1: 0.057754, loss_fp: 0.003660, loss_freq: 0.039914
[15:49:12.155] iteration 7290: loss: 0.080534, loss_s1: 0.028753, loss_fp: 0.003622, loss_freq: 0.052397
[15:49:12.779] iteration 7291: loss: 0.085413, loss_s1: 0.053996, loss_fp: 0.001327, loss_freq: 0.014540
[15:49:13.407] iteration 7292: loss: 0.067563, loss_s1: 0.060783, loss_fp: 0.002280, loss_freq: 0.019883
[15:49:14.028] iteration 7293: loss: 0.070578, loss_s1: 0.054928, loss_fp: 0.005984, loss_freq: 0.021653
[15:49:14.696] iteration 7294: loss: 0.109303, loss_s1: 0.087575, loss_fp: 0.002737, loss_freq: 0.004551
[15:49:15.412] iteration 7295: loss: 0.098941, loss_s1: 0.108524, loss_fp: 0.001389, loss_freq: 0.012630
[15:49:16.087] iteration 7296: loss: 0.090028, loss_s1: 0.086150, loss_fp: 0.001198, loss_freq: 0.020474
[15:49:16.807] iteration 7297: loss: 0.099645, loss_s1: 0.039616, loss_fp: 0.000437, loss_freq: 0.024780
[15:49:17.439] iteration 7298: loss: 0.102515, loss_s1: 0.082479, loss_fp: 0.001339, loss_freq: 0.053271
[15:49:18.062] iteration 7299: loss: 0.096424, loss_s1: 0.051654, loss_fp: 0.000660, loss_freq: 0.029856
[15:49:18.692] iteration 7300: loss: 0.083202, loss_s1: 0.068241, loss_fp: 0.003623, loss_freq: 0.029829
[15:49:19.331] iteration 7301: loss: 0.127053, loss_s1: 0.096840, loss_fp: 0.004260, loss_freq: 0.049275
[15:49:19.957] iteration 7302: loss: 0.063867, loss_s1: 0.037864, loss_fp: 0.008951, loss_freq: 0.009211
[15:49:20.583] iteration 7303: loss: 0.119635, loss_s1: 0.061858, loss_fp: 0.003577, loss_freq: 0.064309
[15:49:21.207] iteration 7304: loss: 0.051260, loss_s1: 0.036204, loss_fp: 0.001508, loss_freq: 0.008480
[15:49:21.832] iteration 7305: loss: 0.059689, loss_s1: 0.038140, loss_fp: 0.001356, loss_freq: 0.020011
[15:49:22.458] iteration 7306: loss: 0.071813, loss_s1: 0.055880, loss_fp: 0.001871, loss_freq: 0.017808
[15:49:23.104] iteration 7307: loss: 0.070180, loss_s1: 0.041030, loss_fp: 0.001756, loss_freq: 0.025851
[15:49:23.733] iteration 7308: loss: 0.083783, loss_s1: 0.039403, loss_fp: 0.005392, loss_freq: 0.027009
[15:49:24.363] iteration 7309: loss: 0.070881, loss_s1: 0.050698, loss_fp: 0.002881, loss_freq: 0.029950
[15:49:24.996] iteration 7310: loss: 0.065144, loss_s1: 0.050926, loss_fp: 0.002044, loss_freq: 0.005483
[15:49:25.623] iteration 7311: loss: 0.120252, loss_s1: 0.048460, loss_fp: 0.008835, loss_freq: 0.060674
[15:49:26.251] iteration 7312: loss: 0.072961, loss_s1: 0.044143, loss_fp: 0.000725, loss_freq: 0.042092
[15:49:26.878] iteration 7313: loss: 0.064377, loss_s1: 0.038791, loss_fp: 0.002222, loss_freq: 0.037349
[15:49:27.506] iteration 7314: loss: 0.069607, loss_s1: 0.030415, loss_fp: 0.002978, loss_freq: 0.023305
[15:49:28.133] iteration 7315: loss: 0.110808, loss_s1: 0.049879, loss_fp: 0.002984, loss_freq: 0.068548
[15:49:28.757] iteration 7316: loss: 0.120996, loss_s1: 0.104344, loss_fp: 0.004075, loss_freq: 0.046055
[15:49:29.383] iteration 7317: loss: 0.097140, loss_s1: 0.062138, loss_fp: 0.003543, loss_freq: 0.074441
[15:49:30.011] iteration 7318: loss: 0.092194, loss_s1: 0.054986, loss_fp: 0.008281, loss_freq: 0.040381
[15:49:30.641] iteration 7319: loss: 0.096586, loss_s1: 0.071962, loss_fp: 0.002379, loss_freq: 0.027463
[15:49:31.268] iteration 7320: loss: 0.093733, loss_s1: 0.056910, loss_fp: 0.001738, loss_freq: 0.058680
[15:49:31.895] iteration 7321: loss: 0.119492, loss_s1: 0.061991, loss_fp: 0.000463, loss_freq: 0.051761
[15:49:32.523] iteration 7322: loss: 0.100418, loss_s1: 0.054436, loss_fp: 0.003174, loss_freq: 0.087461
[15:49:33.150] iteration 7323: loss: 0.075786, loss_s1: 0.076767, loss_fp: 0.001817, loss_freq: 0.018269
[15:49:33.778] iteration 7324: loss: 0.054367, loss_s1: 0.029408, loss_fp: 0.002941, loss_freq: 0.013698
[15:49:34.407] iteration 7325: loss: 0.097017, loss_s1: 0.077852, loss_fp: 0.005947, loss_freq: 0.045991
[15:49:35.065] iteration 7326: loss: 0.098789, loss_s1: 0.063822, loss_fp: 0.002143, loss_freq: 0.045465
[15:49:35.722] iteration 7327: loss: 0.107901, loss_s1: 0.046943, loss_fp: 0.004847, loss_freq: 0.059866
[15:49:36.384] iteration 7328: loss: 0.187949, loss_s1: 0.220636, loss_fp: 0.005197, loss_freq: 0.107719
[15:49:37.041] iteration 7329: loss: 0.072766, loss_s1: 0.048746, loss_fp: 0.004989, loss_freq: 0.019213
[15:49:37.703] iteration 7330: loss: 0.097004, loss_s1: 0.067194, loss_fp: 0.003125, loss_freq: 0.053325
[15:49:38.337] iteration 7331: loss: 0.083402, loss_s1: 0.088455, loss_fp: 0.001501, loss_freq: 0.023070
[15:49:38.959] iteration 7332: loss: 0.104993, loss_s1: 0.084142, loss_fp: 0.003071, loss_freq: 0.040627
[15:49:39.583] iteration 7333: loss: 0.094170, loss_s1: 0.055909, loss_fp: 0.002222, loss_freq: 0.028193
[15:49:40.211] iteration 7334: loss: 0.092943, loss_s1: 0.090919, loss_fp: 0.003945, loss_freq: 0.036560
[15:49:40.835] iteration 7335: loss: 0.065117, loss_s1: 0.027391, loss_fp: 0.002673, loss_freq: 0.020441
[15:49:41.461] iteration 7336: loss: 0.145552, loss_s1: 0.082655, loss_fp: 0.002210, loss_freq: 0.045314
[15:49:42.083] iteration 7337: loss: 0.063810, loss_s1: 0.020088, loss_fp: 0.002577, loss_freq: 0.020383
[15:49:42.708] iteration 7338: loss: 0.138585, loss_s1: 0.045982, loss_fp: 0.000908, loss_freq: 0.035860
[15:49:43.336] iteration 7339: loss: 0.108223, loss_s1: 0.078804, loss_fp: 0.004570, loss_freq: 0.024286
[15:49:43.992] iteration 7340: loss: 0.058940, loss_s1: 0.039634, loss_fp: 0.001488, loss_freq: 0.024217
[15:49:44.615] iteration 7341: loss: 0.066105, loss_s1: 0.053042, loss_fp: 0.000728, loss_freq: 0.015437
[15:49:45.245] iteration 7342: loss: 0.084591, loss_s1: 0.025028, loss_fp: 0.006446, loss_freq: 0.021219
[15:49:45.866] iteration 7343: loss: 0.061092, loss_s1: 0.029228, loss_fp: 0.003564, loss_freq: 0.024360
[15:49:46.495] iteration 7344: loss: 0.120433, loss_s1: 0.082698, loss_fp: 0.002146, loss_freq: 0.026781
[15:49:47.119] iteration 7345: loss: 0.083713, loss_s1: 0.063870, loss_fp: 0.006722, loss_freq: 0.031433
[15:49:47.746] iteration 7346: loss: 0.080722, loss_s1: 0.067875, loss_fp: 0.004324, loss_freq: 0.034742
[15:49:48.393] iteration 7347: loss: 0.121299, loss_s1: 0.049298, loss_fp: 0.002312, loss_freq: 0.049665
[15:49:49.015] iteration 7348: loss: 0.158877, loss_s1: 0.129460, loss_fp: 0.004063, loss_freq: 0.052978
[15:49:49.637] iteration 7349: loss: 0.087839, loss_s1: 0.043314, loss_fp: 0.002009, loss_freq: 0.056521
[15:49:50.267] iteration 7350: loss: 0.168004, loss_s1: 0.079311, loss_fp: 0.004333, loss_freq: 0.044077
[15:49:50.889] iteration 7351: loss: 0.055652, loss_s1: 0.022888, loss_fp: 0.001321, loss_freq: 0.027177
[15:49:51.511] iteration 7352: loss: 0.085721, loss_s1: 0.024238, loss_fp: 0.001990, loss_freq: 0.032223
[15:49:52.133] iteration 7353: loss: 0.123632, loss_s1: 0.062991, loss_fp: 0.008339, loss_freq: 0.089391
[15:49:52.755] iteration 7354: loss: 0.158962, loss_s1: 0.080233, loss_fp: 0.009376, loss_freq: 0.128986
[15:49:53.379] iteration 7355: loss: 0.072360, loss_s1: 0.046006, loss_fp: 0.001152, loss_freq: 0.038589
[15:49:53.999] iteration 7356: loss: 0.075550, loss_s1: 0.019344, loss_fp: 0.001567, loss_freq: 0.033714
[15:49:54.621] iteration 7357: loss: 0.084593, loss_s1: 0.042184, loss_fp: 0.001367, loss_freq: 0.075908
[15:49:55.243] iteration 7358: loss: 0.129394, loss_s1: 0.100786, loss_fp: 0.003067, loss_freq: 0.061751
[15:49:55.870] iteration 7359: loss: 0.061256, loss_s1: 0.019730, loss_fp: 0.001399, loss_freq: 0.040503
[15:49:56.491] iteration 7360: loss: 0.039736, loss_s1: 0.021289, loss_fp: 0.000941, loss_freq: 0.004069
[15:49:57.113] iteration 7361: loss: 0.159098, loss_s1: 0.153313, loss_fp: 0.001543, loss_freq: 0.060667
[15:49:57.735] iteration 7362: loss: 0.111420, loss_s1: 0.128388, loss_fp: 0.000778, loss_freq: 0.034632
[15:49:58.362] iteration 7363: loss: 0.057883, loss_s1: 0.038142, loss_fp: 0.003718, loss_freq: 0.015601
[15:49:58.985] iteration 7364: loss: 0.092263, loss_s1: 0.019934, loss_fp: 0.002610, loss_freq: 0.016185
[15:49:59.609] iteration 7365: loss: 0.098820, loss_s1: 0.058940, loss_fp: 0.001553, loss_freq: 0.087614
[15:50:00.230] iteration 7366: loss: 0.109675, loss_s1: 0.051474, loss_fp: 0.000993, loss_freq: 0.086882
[15:50:00.855] iteration 7367: loss: 0.125305, loss_s1: 0.025048, loss_fp: 0.003741, loss_freq: 0.017399
[15:50:01.485] iteration 7368: loss: 0.125757, loss_s1: 0.111325, loss_fp: 0.002416, loss_freq: 0.031903
[15:50:02.114] iteration 7369: loss: 0.091516, loss_s1: 0.054784, loss_fp: 0.018127, loss_freq: 0.037568
[15:50:02.735] iteration 7370: loss: 0.086864, loss_s1: 0.041610, loss_fp: 0.000801, loss_freq: 0.031948
[15:50:03.370] iteration 7371: loss: 0.067894, loss_s1: 0.026529, loss_fp: 0.000352, loss_freq: 0.009549
[15:50:04.012] iteration 7372: loss: 0.069126, loss_s1: 0.019942, loss_fp: 0.000812, loss_freq: 0.023070
[15:50:04.638] iteration 7373: loss: 0.135735, loss_s1: 0.036872, loss_fp: 0.002296, loss_freq: 0.065079
[15:50:05.265] iteration 7374: loss: 0.072058, loss_s1: 0.056242, loss_fp: 0.001001, loss_freq: 0.007727
[15:50:05.899] iteration 7375: loss: 0.090481, loss_s1: 0.095898, loss_fp: 0.003485, loss_freq: 0.013769
[15:50:06.525] iteration 7376: loss: 0.111258, loss_s1: 0.070137, loss_fp: 0.002963, loss_freq: 0.072993
[15:50:07.168] iteration 7377: loss: 0.100292, loss_s1: 0.072940, loss_fp: 0.002503, loss_freq: 0.047948
[15:50:07.807] iteration 7378: loss: 0.086407, loss_s1: 0.030010, loss_fp: 0.002206, loss_freq: 0.034213
[15:50:08.450] iteration 7379: loss: 0.068994, loss_s1: 0.041689, loss_fp: 0.001442, loss_freq: 0.030749
[15:50:09.080] iteration 7380: loss: 0.103217, loss_s1: 0.062428, loss_fp: 0.002600, loss_freq: 0.071137
[15:50:09.706] iteration 7381: loss: 0.101673, loss_s1: 0.091928, loss_fp: 0.003486, loss_freq: 0.013114
[15:50:10.335] iteration 7382: loss: 0.075935, loss_s1: 0.032065, loss_fp: 0.003017, loss_freq: 0.037109
[15:50:10.959] iteration 7383: loss: 0.088546, loss_s1: 0.069086, loss_fp: 0.002728, loss_freq: 0.032948
[15:50:11.586] iteration 7384: loss: 0.090539, loss_s1: 0.071471, loss_fp: 0.002041, loss_freq: 0.050535
[15:50:12.210] iteration 7385: loss: 0.119891, loss_s1: 0.066195, loss_fp: 0.001519, loss_freq: 0.061870
[15:50:12.835] iteration 7386: loss: 0.129614, loss_s1: 0.131608, loss_fp: 0.004450, loss_freq: 0.060027
[15:50:13.462] iteration 7387: loss: 0.100872, loss_s1: 0.019128, loss_fp: 0.025834, loss_freq: 0.034794
[15:50:14.086] iteration 7388: loss: 0.082937, loss_s1: 0.043061, loss_fp: 0.005866, loss_freq: 0.024626
[15:50:14.708] iteration 7389: loss: 0.085876, loss_s1: 0.081415, loss_fp: 0.021109, loss_freq: 0.017506
[15:50:15.331] iteration 7390: loss: 0.073256, loss_s1: 0.044937, loss_fp: 0.001769, loss_freq: 0.014358
[15:50:15.952] iteration 7391: loss: 0.071641, loss_s1: 0.028358, loss_fp: 0.004227, loss_freq: 0.006665
[15:50:16.579] iteration 7392: loss: 0.114810, loss_s1: 0.061037, loss_fp: 0.001890, loss_freq: 0.115583
[15:50:17.203] iteration 7393: loss: 0.093227, loss_s1: 0.075566, loss_fp: 0.001498, loss_freq: 0.018821
[15:50:17.825] iteration 7394: loss: 0.067956, loss_s1: 0.028112, loss_fp: 0.002905, loss_freq: 0.029759
[15:50:18.448] iteration 7395: loss: 0.077975, loss_s1: 0.041396, loss_fp: 0.002568, loss_freq: 0.028601
[15:50:19.069] iteration 7396: loss: 0.079047, loss_s1: 0.024849, loss_fp: 0.000668, loss_freq: 0.040327
[15:50:19.692] iteration 7397: loss: 0.088875, loss_s1: 0.089656, loss_fp: 0.003413, loss_freq: 0.032232
[15:50:20.316] iteration 7398: loss: 0.057481, loss_s1: 0.039683, loss_fp: 0.003315, loss_freq: 0.014596
[15:50:20.942] iteration 7399: loss: 0.092283, loss_s1: 0.024802, loss_fp: 0.002796, loss_freq: 0.039411
[15:50:21.568] iteration 7400: loss: 0.065336, loss_s1: 0.034060, loss_fp: 0.003713, loss_freq: 0.006203
[15:50:24.855] iteration 7400 : mean_dice : 0.655297
[15:50:25.499] iteration 7401: loss: 0.094842, loss_s1: 0.061574, loss_fp: 0.001232, loss_freq: 0.020685
[15:50:26.121] iteration 7402: loss: 0.044215, loss_s1: 0.008594, loss_fp: 0.000312, loss_freq: 0.007674
[15:50:26.743] iteration 7403: loss: 0.109824, loss_s1: 0.071674, loss_fp: 0.005117, loss_freq: 0.047421
[15:50:27.371] iteration 7404: loss: 0.093701, loss_s1: 0.086144, loss_fp: 0.011194, loss_freq: 0.028410
[15:50:27.994] iteration 7405: loss: 0.117697, loss_s1: 0.065891, loss_fp: 0.001702, loss_freq: 0.053617
[15:50:28.616] iteration 7406: loss: 0.091764, loss_s1: 0.042761, loss_fp: 0.003127, loss_freq: 0.046207
[15:50:29.646] iteration 7407: loss: 0.092110, loss_s1: 0.052504, loss_fp: 0.002359, loss_freq: 0.024408
[15:50:30.316] iteration 7408: loss: 0.129249, loss_s1: 0.146779, loss_fp: 0.001096, loss_freq: 0.012023
[15:50:30.979] iteration 7409: loss: 0.096973, loss_s1: 0.046009, loss_fp: 0.001124, loss_freq: 0.053097
[15:50:31.642] iteration 7410: loss: 0.064005, loss_s1: 0.031034, loss_fp: 0.001107, loss_freq: 0.019975
[15:50:32.277] iteration 7411: loss: 0.099736, loss_s1: 0.023328, loss_fp: 0.002697, loss_freq: 0.036999
[15:50:32.906] iteration 7412: loss: 0.157140, loss_s1: 0.119247, loss_fp: 0.001646, loss_freq: 0.056183
[15:50:33.533] iteration 7413: loss: 0.072289, loss_s1: 0.052749, loss_fp: 0.000613, loss_freq: 0.021999
[15:50:34.159] iteration 7414: loss: 0.090540, loss_s1: 0.078190, loss_fp: 0.003121, loss_freq: 0.050930
[15:50:34.783] iteration 7415: loss: 0.059643, loss_s1: 0.033972, loss_fp: 0.001695, loss_freq: 0.011425
[15:50:35.407] iteration 7416: loss: 0.117107, loss_s1: 0.105882, loss_fp: 0.004747, loss_freq: 0.059608
[15:50:36.030] iteration 7417: loss: 0.070807, loss_s1: 0.039503, loss_fp: 0.002024, loss_freq: 0.028918
[15:50:36.655] iteration 7418: loss: 0.126727, loss_s1: 0.082401, loss_fp: 0.002747, loss_freq: 0.051559
[15:50:37.279] iteration 7419: loss: 0.080415, loss_s1: 0.045562, loss_fp: 0.002167, loss_freq: 0.056401
[15:50:37.905] iteration 7420: loss: 0.108442, loss_s1: 0.049946, loss_fp: 0.006108, loss_freq: 0.047491
[15:50:38.533] iteration 7421: loss: 0.059286, loss_s1: 0.034868, loss_fp: 0.001812, loss_freq: 0.022687
[15:50:39.158] iteration 7422: loss: 0.150853, loss_s1: 0.095535, loss_fp: 0.002736, loss_freq: 0.113516
[15:50:39.785] iteration 7423: loss: 0.084382, loss_s1: 0.060795, loss_fp: 0.002081, loss_freq: 0.011689
[15:50:40.414] iteration 7424: loss: 0.082043, loss_s1: 0.070254, loss_fp: 0.001268, loss_freq: 0.018372
[15:50:41.043] iteration 7425: loss: 0.089757, loss_s1: 0.049802, loss_fp: 0.002064, loss_freq: 0.024813
[15:50:41.723] iteration 7426: loss: 0.096428, loss_s1: 0.030314, loss_fp: 0.010849, loss_freq: 0.049245
[15:50:42.351] iteration 7427: loss: 0.047212, loss_s1: 0.021104, loss_fp: 0.002710, loss_freq: 0.011093
[15:50:43.010] iteration 7428: loss: 0.063340, loss_s1: 0.019075, loss_fp: 0.003944, loss_freq: 0.021454
[15:50:43.670] iteration 7429: loss: 0.094150, loss_s1: 0.065928, loss_fp: 0.001496, loss_freq: 0.020595
[15:50:44.316] iteration 7430: loss: 0.188460, loss_s1: 0.257411, loss_fp: 0.002064, loss_freq: 0.065420
[15:50:44.944] iteration 7431: loss: 0.074042, loss_s1: 0.060376, loss_fp: 0.001594, loss_freq: 0.044228
[15:50:45.565] iteration 7432: loss: 0.077397, loss_s1: 0.027629, loss_fp: 0.008056, loss_freq: 0.039546
[15:50:46.200] iteration 7433: loss: 0.082414, loss_s1: 0.066553, loss_fp: 0.004246, loss_freq: 0.017387
[15:50:46.832] iteration 7434: loss: 0.199701, loss_s1: 0.093215, loss_fp: 0.015291, loss_freq: 0.045145
[15:50:47.457] iteration 7435: loss: 0.075572, loss_s1: 0.042084, loss_fp: 0.003473, loss_freq: 0.050183
[15:50:48.081] iteration 7436: loss: 0.064813, loss_s1: 0.032547, loss_fp: 0.007452, loss_freq: 0.023316
[15:50:48.708] iteration 7437: loss: 0.062558, loss_s1: 0.029501, loss_fp: 0.003002, loss_freq: 0.019870
[15:50:49.330] iteration 7438: loss: 0.092389, loss_s1: 0.073752, loss_fp: 0.001928, loss_freq: 0.017930
[15:50:49.953] iteration 7439: loss: 0.071500, loss_s1: 0.035849, loss_fp: 0.007226, loss_freq: 0.028281
[15:50:50.576] iteration 7440: loss: 0.067979, loss_s1: 0.063140, loss_fp: 0.002146, loss_freq: 0.022863
[15:50:51.198] iteration 7441: loss: 0.106980, loss_s1: 0.055226, loss_fp: 0.003624, loss_freq: 0.031836
[15:50:51.821] iteration 7442: loss: 0.108626, loss_s1: 0.096643, loss_fp: 0.001783, loss_freq: 0.053349
[15:50:52.449] iteration 7443: loss: 0.126384, loss_s1: 0.097072, loss_fp: 0.000895, loss_freq: 0.070140
[15:50:53.078] iteration 7444: loss: 0.099713, loss_s1: 0.057234, loss_fp: 0.005786, loss_freq: 0.043135
[15:50:53.702] iteration 7445: loss: 0.167181, loss_s1: 0.144183, loss_fp: 0.002800, loss_freq: 0.101081
[15:50:54.328] iteration 7446: loss: 0.085555, loss_s1: 0.049095, loss_fp: 0.000803, loss_freq: 0.064014
[15:50:54.957] iteration 7447: loss: 0.116089, loss_s1: 0.058825, loss_fp: 0.002747, loss_freq: 0.024851
[15:50:55.589] iteration 7448: loss: 0.083898, loss_s1: 0.051197, loss_fp: 0.002983, loss_freq: 0.061335
[15:50:56.263] iteration 7449: loss: 0.103118, loss_s1: 0.093286, loss_fp: 0.004069, loss_freq: 0.040553
[15:50:56.940] iteration 7450: loss: 0.066521, loss_s1: 0.036988, loss_fp: 0.005715, loss_freq: 0.035828
[15:50:57.601] iteration 7451: loss: 0.090367, loss_s1: 0.043275, loss_fp: 0.001447, loss_freq: 0.052347
[15:50:58.263] iteration 7452: loss: 0.081679, loss_s1: 0.084758, loss_fp: 0.002949, loss_freq: 0.010545
[15:50:58.895] iteration 7453: loss: 0.059945, loss_s1: 0.061367, loss_fp: 0.001083, loss_freq: 0.009321
[15:50:59.529] iteration 7454: loss: 0.070459, loss_s1: 0.057814, loss_fp: 0.006741, loss_freq: 0.022087
[15:51:00.165] iteration 7455: loss: 0.076804, loss_s1: 0.057710, loss_fp: 0.008427, loss_freq: 0.021828
[15:51:00.799] iteration 7456: loss: 0.072775, loss_s1: 0.065304, loss_fp: 0.002858, loss_freq: 0.024465
[15:51:01.431] iteration 7457: loss: 0.099892, loss_s1: 0.094912, loss_fp: 0.000768, loss_freq: 0.032845
[15:51:02.062] iteration 7458: loss: 0.068897, loss_s1: 0.019714, loss_fp: 0.002473, loss_freq: 0.030324
[15:51:02.691] iteration 7459: loss: 0.091770, loss_s1: 0.052441, loss_fp: 0.005421, loss_freq: 0.038414
[15:51:03.324] iteration 7460: loss: 0.088903, loss_s1: 0.052400, loss_fp: 0.009605, loss_freq: 0.031687
[15:51:03.952] iteration 7461: loss: 0.127764, loss_s1: 0.064059, loss_fp: 0.001507, loss_freq: 0.036548
[15:51:04.585] iteration 7462: loss: 0.111513, loss_s1: 0.134905, loss_fp: 0.007589, loss_freq: 0.020149
[15:51:05.213] iteration 7463: loss: 0.073371, loss_s1: 0.028053, loss_fp: 0.002380, loss_freq: 0.011631
[15:51:05.842] iteration 7464: loss: 0.114775, loss_s1: 0.058807, loss_fp: 0.000621, loss_freq: 0.071876
[15:51:06.473] iteration 7465: loss: 0.052618, loss_s1: 0.026920, loss_fp: 0.001285, loss_freq: 0.009656
[15:51:07.104] iteration 7466: loss: 0.054515, loss_s1: 0.030460, loss_fp: 0.004298, loss_freq: 0.012699
[15:51:07.736] iteration 7467: loss: 0.063475, loss_s1: 0.043219, loss_fp: 0.001667, loss_freq: 0.025403
[15:51:08.364] iteration 7468: loss: 0.065551, loss_s1: 0.028100, loss_fp: 0.002570, loss_freq: 0.012793
[15:51:08.993] iteration 7469: loss: 0.070589, loss_s1: 0.036002, loss_fp: 0.001490, loss_freq: 0.021817
[15:51:09.626] iteration 7470: loss: 0.111302, loss_s1: 0.104854, loss_fp: 0.001897, loss_freq: 0.010825
[15:51:10.252] iteration 7471: loss: 0.062107, loss_s1: 0.026991, loss_fp: 0.001698, loss_freq: 0.014448
[15:51:10.878] iteration 7472: loss: 0.098346, loss_s1: 0.058630, loss_fp: 0.004069, loss_freq: 0.071922
[15:51:11.504] iteration 7473: loss: 0.073457, loss_s1: 0.027840, loss_fp: 0.001501, loss_freq: 0.049051
[15:51:12.128] iteration 7474: loss: 0.047232, loss_s1: 0.020662, loss_fp: 0.005617, loss_freq: 0.023495
[15:51:12.753] iteration 7475: loss: 0.073656, loss_s1: 0.051807, loss_fp: 0.008565, loss_freq: 0.031532
[15:51:13.376] iteration 7476: loss: 0.105462, loss_s1: 0.040816, loss_fp: 0.004444, loss_freq: 0.041509
[15:51:14.001] iteration 7477: loss: 0.105585, loss_s1: 0.058720, loss_fp: 0.011550, loss_freq: 0.062625
[15:51:14.629] iteration 7478: loss: 0.097286, loss_s1: 0.033316, loss_fp: 0.004074, loss_freq: 0.088088
[15:51:15.278] iteration 7479: loss: 0.102665, loss_s1: 0.041772, loss_fp: 0.000703, loss_freq: 0.089197
[15:51:15.941] iteration 7480: loss: 0.080468, loss_s1: 0.033602, loss_fp: 0.002340, loss_freq: 0.010496
[15:51:16.600] iteration 7481: loss: 0.066636, loss_s1: 0.051699, loss_fp: 0.003312, loss_freq: 0.021500
[15:51:17.230] iteration 7482: loss: 0.092973, loss_s1: 0.024887, loss_fp: 0.001246, loss_freq: 0.030660
[15:51:17.855] iteration 7483: loss: 0.106908, loss_s1: 0.074728, loss_fp: 0.004410, loss_freq: 0.055351
[15:51:18.484] iteration 7484: loss: 0.060780, loss_s1: 0.048022, loss_fp: 0.001814, loss_freq: 0.024811
[15:51:19.149] iteration 7485: loss: 0.073845, loss_s1: 0.029399, loss_fp: 0.005391, loss_freq: 0.029395
[15:51:19.824] iteration 7486: loss: 0.096229, loss_s1: 0.054683, loss_fp: 0.005729, loss_freq: 0.063564
[15:51:20.501] iteration 7487: loss: 0.115278, loss_s1: 0.061881, loss_fp: 0.007708, loss_freq: 0.045336
[15:51:21.175] iteration 7488: loss: 0.108441, loss_s1: 0.126370, loss_fp: 0.004270, loss_freq: 0.024202
[15:51:21.847] iteration 7489: loss: 0.143984, loss_s1: 0.111386, loss_fp: 0.007173, loss_freq: 0.103201
[15:51:22.502] iteration 7490: loss: 0.124323, loss_s1: 0.070212, loss_fp: 0.002687, loss_freq: 0.020388
[15:51:23.132] iteration 7491: loss: 0.131299, loss_s1: 0.122760, loss_fp: 0.002512, loss_freq: 0.071286
[15:51:23.756] iteration 7492: loss: 0.065471, loss_s1: 0.060420, loss_fp: 0.000614, loss_freq: 0.014142
[15:51:24.380] iteration 7493: loss: 0.149844, loss_s1: 0.093486, loss_fp: 0.000352, loss_freq: 0.048298
[15:51:25.006] iteration 7494: loss: 0.059858, loss_s1: 0.027845, loss_fp: 0.004521, loss_freq: 0.021304
[15:51:25.632] iteration 7495: loss: 0.065499, loss_s1: 0.049143, loss_fp: 0.002769, loss_freq: 0.026413
[15:51:26.278] iteration 7496: loss: 0.109298, loss_s1: 0.053454, loss_fp: 0.003938, loss_freq: 0.038149
[15:51:26.906] iteration 7497: loss: 0.066431, loss_s1: 0.013377, loss_fp: 0.000782, loss_freq: 0.014083
[15:51:27.529] iteration 7498: loss: 0.076119, loss_s1: 0.032230, loss_fp: 0.002964, loss_freq: 0.010149
[15:51:28.156] iteration 7499: loss: 0.078298, loss_s1: 0.034475, loss_fp: 0.006280, loss_freq: 0.023519
[15:51:28.780] iteration 7500: loss: 0.093213, loss_s1: 0.090445, loss_fp: 0.000460, loss_freq: 0.015825
[15:51:29.404] iteration 7501: loss: 0.051635, loss_s1: 0.025354, loss_fp: 0.000632, loss_freq: 0.003329
[15:51:30.025] iteration 7502: loss: 0.093367, loss_s1: 0.056048, loss_fp: 0.009053, loss_freq: 0.051647
[15:51:30.651] iteration 7503: loss: 0.092928, loss_s1: 0.059651, loss_fp: 0.001269, loss_freq: 0.052227
[15:51:31.274] iteration 7504: loss: 0.059198, loss_s1: 0.017998, loss_fp: 0.001351, loss_freq: 0.020829
[15:51:31.899] iteration 7505: loss: 0.098124, loss_s1: 0.097022, loss_fp: 0.000891, loss_freq: 0.012831
[15:51:32.527] iteration 7506: loss: 0.080292, loss_s1: 0.072310, loss_fp: 0.001659, loss_freq: 0.025653
[15:51:33.150] iteration 7507: loss: 0.059788, loss_s1: 0.033965, loss_fp: 0.004214, loss_freq: 0.017058
[15:51:33.774] iteration 7508: loss: 0.111142, loss_s1: 0.046569, loss_fp: 0.002265, loss_freq: 0.081327
[15:51:34.398] iteration 7509: loss: 0.135785, loss_s1: 0.120794, loss_fp: 0.001322, loss_freq: 0.034387
[15:51:35.028] iteration 7510: loss: 0.091768, loss_s1: 0.069245, loss_fp: 0.001932, loss_freq: 0.057529
[15:51:35.654] iteration 7511: loss: 0.097379, loss_s1: 0.023187, loss_fp: 0.009123, loss_freq: 0.018047
[15:51:36.296] iteration 7512: loss: 0.070731, loss_s1: 0.028345, loss_fp: 0.006451, loss_freq: 0.029518
[15:51:36.937] iteration 7513: loss: 0.088525, loss_s1: 0.048025, loss_fp: 0.001339, loss_freq: 0.034929
[15:51:37.579] iteration 7514: loss: 0.143173, loss_s1: 0.137975, loss_fp: 0.005439, loss_freq: 0.059405
[15:51:38.217] iteration 7515: loss: 0.176767, loss_s1: 0.081127, loss_fp: 0.005756, loss_freq: 0.184227
[15:51:38.856] iteration 7516: loss: 0.069572, loss_s1: 0.050520, loss_fp: 0.001207, loss_freq: 0.024050
[15:51:39.484] iteration 7517: loss: 0.103772, loss_s1: 0.051433, loss_fp: 0.001585, loss_freq: 0.053740
[15:51:40.110] iteration 7518: loss: 0.093014, loss_s1: 0.070828, loss_fp: 0.002770, loss_freq: 0.056690
[15:51:40.734] iteration 7519: loss: 0.084594, loss_s1: 0.056302, loss_fp: 0.006862, loss_freq: 0.047395
[15:51:41.392] iteration 7520: loss: 0.064435, loss_s1: 0.028137, loss_fp: 0.000325, loss_freq: 0.034535
[15:51:42.052] iteration 7521: loss: 0.045157, loss_s1: 0.022150, loss_fp: 0.000409, loss_freq: 0.008223
[15:51:42.720] iteration 7522: loss: 0.098113, loss_s1: 0.042625, loss_fp: 0.003211, loss_freq: 0.062727
[15:51:43.376] iteration 7523: loss: 0.109798, loss_s1: 0.086675, loss_fp: 0.001366, loss_freq: 0.068097
[15:51:44.034] iteration 7524: loss: 0.088929, loss_s1: 0.059714, loss_fp: 0.002608, loss_freq: 0.042409
[15:51:44.666] iteration 7525: loss: 0.074029, loss_s1: 0.033682, loss_fp: 0.001228, loss_freq: 0.050875
[15:51:45.291] iteration 7526: loss: 0.135586, loss_s1: 0.090561, loss_fp: 0.011287, loss_freq: 0.100997
[15:51:45.946] iteration 7527: loss: 0.083976, loss_s1: 0.038273, loss_fp: 0.000993, loss_freq: 0.057898
[15:51:46.626] iteration 7528: loss: 0.087218, loss_s1: 0.021045, loss_fp: 0.000720, loss_freq: 0.022718
[15:51:47.301] iteration 7529: loss: 0.094534, loss_s1: 0.083897, loss_fp: 0.006084, loss_freq: 0.018218
[15:51:47.953] iteration 7530: loss: 0.084690, loss_s1: 0.045663, loss_fp: 0.002528, loss_freq: 0.058925
[15:51:48.595] iteration 7531: loss: 0.106844, loss_s1: 0.053614, loss_fp: 0.003781, loss_freq: 0.052988
[15:51:49.238] iteration 7532: loss: 0.103476, loss_s1: 0.026552, loss_fp: 0.006300, loss_freq: 0.028315
[15:51:49.881] iteration 7533: loss: 0.080430, loss_s1: 0.048409, loss_fp: 0.002880, loss_freq: 0.012625
[15:51:50.517] iteration 7534: loss: 0.194374, loss_s1: 0.207354, loss_fp: 0.001886, loss_freq: 0.080229
[15:51:51.142] iteration 7535: loss: 0.057576, loss_s1: 0.031702, loss_fp: 0.007786, loss_freq: 0.006908
[15:51:51.769] iteration 7536: loss: 0.079430, loss_s1: 0.071501, loss_fp: 0.002631, loss_freq: 0.014399
[15:51:52.393] iteration 7537: loss: 0.138903, loss_s1: 0.117991, loss_fp: 0.002337, loss_freq: 0.082883
[15:51:53.017] iteration 7538: loss: 0.182288, loss_s1: 0.177764, loss_fp: 0.001043, loss_freq: 0.103177
[15:51:53.672] iteration 7539: loss: 0.085083, loss_s1: 0.046517, loss_fp: 0.002213, loss_freq: 0.033674
[15:51:54.306] iteration 7540: loss: 0.059983, loss_s1: 0.034047, loss_fp: 0.006763, loss_freq: 0.013362
[15:51:54.931] iteration 7541: loss: 0.105662, loss_s1: 0.071699, loss_fp: 0.004965, loss_freq: 0.083600
[15:51:55.560] iteration 7542: loss: 0.089213, loss_s1: 0.083168, loss_fp: 0.002711, loss_freq: 0.028779
[15:51:56.188] iteration 7543: loss: 0.105550, loss_s1: 0.075428, loss_fp: 0.001501, loss_freq: 0.032905
[15:51:56.818] iteration 7544: loss: 0.089457, loss_s1: 0.061664, loss_fp: 0.003429, loss_freq: 0.038293
[15:51:57.445] iteration 7545: loss: 0.071672, loss_s1: 0.058079, loss_fp: 0.001241, loss_freq: 0.022148
[15:51:58.071] iteration 7546: loss: 0.117490, loss_s1: 0.063221, loss_fp: 0.016593, loss_freq: 0.034018
[15:51:58.697] iteration 7547: loss: 0.151454, loss_s1: 0.159427, loss_fp: 0.003570, loss_freq: 0.053220
[15:51:59.321] iteration 7548: loss: 0.090183, loss_s1: 0.026164, loss_fp: 0.010076, loss_freq: 0.033467
[15:51:59.948] iteration 7549: loss: 0.110723, loss_s1: 0.079393, loss_fp: 0.002520, loss_freq: 0.028228
[15:52:00.572] iteration 7550: loss: 0.074842, loss_s1: 0.065409, loss_fp: 0.002316, loss_freq: 0.017186
[15:52:01.197] iteration 7551: loss: 0.046608, loss_s1: 0.030345, loss_fp: 0.002159, loss_freq: 0.003100
[15:52:01.819] iteration 7552: loss: 0.100019, loss_s1: 0.059659, loss_fp: 0.011803, loss_freq: 0.020696
[15:52:02.446] iteration 7553: loss: 0.118316, loss_s1: 0.096220, loss_fp: 0.004129, loss_freq: 0.082957
[15:52:03.067] iteration 7554: loss: 0.080215, loss_s1: 0.068150, loss_fp: 0.001300, loss_freq: 0.022761
[15:52:03.692] iteration 7555: loss: 0.065374, loss_s1: 0.028185, loss_fp: 0.000958, loss_freq: 0.032290
[15:52:04.314] iteration 7556: loss: 0.075990, loss_s1: 0.033884, loss_fp: 0.007312, loss_freq: 0.030148
[15:52:04.941] iteration 7557: loss: 0.129857, loss_s1: 0.068518, loss_fp: 0.006859, loss_freq: 0.071353
[15:52:05.567] iteration 7558: loss: 0.134547, loss_s1: 0.129807, loss_fp: 0.009689, loss_freq: 0.073361
[15:52:06.189] iteration 7559: loss: 0.064708, loss_s1: 0.027243, loss_fp: 0.001801, loss_freq: 0.026101
[15:52:06.816] iteration 7560: loss: 0.087222, loss_s1: 0.052167, loss_fp: 0.010229, loss_freq: 0.035006
[15:52:07.443] iteration 7561: loss: 0.124904, loss_s1: 0.071112, loss_fp: 0.000638, loss_freq: 0.014138
[15:52:08.072] iteration 7562: loss: 0.091344, loss_s1: 0.039631, loss_fp: 0.001107, loss_freq: 0.014666
[15:52:08.694] iteration 7563: loss: 0.062073, loss_s1: 0.033662, loss_fp: 0.001169, loss_freq: 0.017885
[15:52:09.317] iteration 7564: loss: 0.083437, loss_s1: 0.047258, loss_fp: 0.002467, loss_freq: 0.051184
[15:52:09.943] iteration 7565: loss: 0.110035, loss_s1: 0.088266, loss_fp: 0.002329, loss_freq: 0.058682
[15:52:10.563] iteration 7566: loss: 0.188712, loss_s1: 0.066111, loss_fp: 0.000735, loss_freq: 0.040862
[15:52:11.185] iteration 7567: loss: 0.113550, loss_s1: 0.076827, loss_fp: 0.011721, loss_freq: 0.071382
[15:52:12.158] iteration 7568: loss: 0.068809, loss_s1: 0.036272, loss_fp: 0.005471, loss_freq: 0.028167
[15:52:12.814] iteration 7569: loss: 0.061533, loss_s1: 0.036859, loss_fp: 0.002392, loss_freq: 0.007447
[15:52:13.487] iteration 7570: loss: 0.117245, loss_s1: 0.037903, loss_fp: 0.001174, loss_freq: 0.042693
[15:52:14.110] iteration 7571: loss: 0.076074, loss_s1: 0.045577, loss_fp: 0.000960, loss_freq: 0.016614
[15:52:14.732] iteration 7572: loss: 0.088162, loss_s1: 0.062357, loss_fp: 0.005050, loss_freq: 0.019975
[15:52:15.355] iteration 7573: loss: 0.173706, loss_s1: 0.115157, loss_fp: 0.003458, loss_freq: 0.100328
[15:52:16.013] iteration 7574: loss: 0.067304, loss_s1: 0.053878, loss_fp: 0.002175, loss_freq: 0.023790
[15:52:16.670] iteration 7575: loss: 0.083105, loss_s1: 0.063336, loss_fp: 0.000834, loss_freq: 0.038494
[15:52:17.329] iteration 7576: loss: 0.073240, loss_s1: 0.046075, loss_fp: 0.004622, loss_freq: 0.021142
[15:52:17.983] iteration 7577: loss: 0.090014, loss_s1: 0.089539, loss_fp: 0.002640, loss_freq: 0.031459
[15:52:18.609] iteration 7578: loss: 0.095137, loss_s1: 0.028941, loss_fp: 0.002992, loss_freq: 0.039693
[15:52:19.263] iteration 7579: loss: 0.115504, loss_s1: 0.082024, loss_fp: 0.001312, loss_freq: 0.083483
[15:52:19.888] iteration 7580: loss: 0.072578, loss_s1: 0.045118, loss_fp: 0.002675, loss_freq: 0.038979
[15:52:20.510] iteration 7581: loss: 0.141804, loss_s1: 0.034185, loss_fp: 0.001648, loss_freq: 0.038003
[15:52:21.132] iteration 7582: loss: 0.063994, loss_s1: 0.040861, loss_fp: 0.003519, loss_freq: 0.032272
[15:52:21.759] iteration 7583: loss: 0.132866, loss_s1: 0.117011, loss_fp: 0.004482, loss_freq: 0.049089
[15:52:22.384] iteration 7584: loss: 0.100230, loss_s1: 0.034310, loss_fp: 0.001946, loss_freq: 0.028109
[15:52:23.010] iteration 7585: loss: 0.082492, loss_s1: 0.036865, loss_fp: 0.001038, loss_freq: 0.028520
[15:52:23.667] iteration 7586: loss: 0.071646, loss_s1: 0.059661, loss_fp: 0.002189, loss_freq: 0.018043
[15:52:24.295] iteration 7587: loss: 0.088353, loss_s1: 0.060563, loss_fp: 0.001139, loss_freq: 0.031223
[15:52:24.918] iteration 7588: loss: 0.059565, loss_s1: 0.038659, loss_fp: 0.000387, loss_freq: 0.011521
[15:52:25.547] iteration 7589: loss: 0.094490, loss_s1: 0.057524, loss_fp: 0.001190, loss_freq: 0.025166
[15:52:26.173] iteration 7590: loss: 0.097500, loss_s1: 0.046201, loss_fp: 0.000809, loss_freq: 0.033113
[15:52:26.799] iteration 7591: loss: 0.182145, loss_s1: 0.216315, loss_fp: 0.002054, loss_freq: 0.080693
[15:52:27.427] iteration 7592: loss: 0.051454, loss_s1: 0.023154, loss_fp: 0.000731, loss_freq: 0.028779
[15:52:28.054] iteration 7593: loss: 0.097256, loss_s1: 0.076186, loss_fp: 0.001294, loss_freq: 0.044063
[15:52:28.678] iteration 7594: loss: 0.100123, loss_s1: 0.111235, loss_fp: 0.007116, loss_freq: 0.018875
[15:52:29.300] iteration 7595: loss: 0.145210, loss_s1: 0.154875, loss_fp: 0.003943, loss_freq: 0.030363
[15:52:29.920] iteration 7596: loss: 0.070084, loss_s1: 0.053549, loss_fp: 0.000999, loss_freq: 0.026053
[15:52:30.541] iteration 7597: loss: 0.066039, loss_s1: 0.054325, loss_fp: 0.001842, loss_freq: 0.010111
[15:52:31.167] iteration 7598: loss: 0.053826, loss_s1: 0.032237, loss_fp: 0.002020, loss_freq: 0.017923
[15:52:31.792] iteration 7599: loss: 0.095545, loss_s1: 0.072921, loss_fp: 0.002851, loss_freq: 0.026499
[15:52:32.417] iteration 7600: loss: 0.062803, loss_s1: 0.039876, loss_fp: 0.001541, loss_freq: 0.020671
[15:52:35.682] iteration 7600 : mean_dice : 0.687957
[15:52:36.335] iteration 7601: loss: 0.056418, loss_s1: 0.036577, loss_fp: 0.000696, loss_freq: 0.005635
[15:52:36.959] iteration 7602: loss: 0.096160, loss_s1: 0.014133, loss_fp: 0.001231, loss_freq: 0.023969
[15:52:37.587] iteration 7603: loss: 0.078578, loss_s1: 0.070191, loss_fp: 0.000775, loss_freq: 0.031222
[15:52:38.212] iteration 7604: loss: 0.090821, loss_s1: 0.069615, loss_fp: 0.003200, loss_freq: 0.034367
[15:52:38.842] iteration 7605: loss: 0.067471, loss_s1: 0.046231, loss_fp: 0.009779, loss_freq: 0.022287
[15:52:39.467] iteration 7606: loss: 0.113718, loss_s1: 0.090207, loss_fp: 0.003236, loss_freq: 0.064529
[15:52:40.128] iteration 7607: loss: 0.096458, loss_s1: 0.095449, loss_fp: 0.002081, loss_freq: 0.041257
[15:52:40.790] iteration 7608: loss: 0.089314, loss_s1: 0.015789, loss_fp: 0.005426, loss_freq: 0.020018
[15:52:41.453] iteration 7609: loss: 0.068935, loss_s1: 0.071348, loss_fp: 0.000518, loss_freq: 0.008289
[15:52:42.080] iteration 7610: loss: 0.068305, loss_s1: 0.047308, loss_fp: 0.005437, loss_freq: 0.024692
[15:52:42.705] iteration 7611: loss: 0.099589, loss_s1: 0.113430, loss_fp: 0.004809, loss_freq: 0.010560
[15:52:43.333] iteration 7612: loss: 0.077321, loss_s1: 0.039759, loss_fp: 0.005188, loss_freq: 0.046596
[15:52:43.962] iteration 7613: loss: 0.066905, loss_s1: 0.066342, loss_fp: 0.000417, loss_freq: 0.007814
[15:52:44.596] iteration 7614: loss: 0.046281, loss_s1: 0.028868, loss_fp: 0.001345, loss_freq: 0.008466
[15:52:45.227] iteration 7615: loss: 0.065239, loss_s1: 0.071985, loss_fp: 0.005097, loss_freq: 0.011960
[15:52:45.854] iteration 7616: loss: 0.096261, loss_s1: 0.074810, loss_fp: 0.000731, loss_freq: 0.007555
[15:52:46.481] iteration 7617: loss: 0.096971, loss_s1: 0.078561, loss_fp: 0.000858, loss_freq: 0.058839
[15:52:47.107] iteration 7618: loss: 0.049286, loss_s1: 0.021508, loss_fp: 0.000473, loss_freq: 0.027225
[15:52:47.737] iteration 7619: loss: 0.126139, loss_s1: 0.021766, loss_fp: 0.004014, loss_freq: 0.016612
[15:52:48.359] iteration 7620: loss: 0.097908, loss_s1: 0.065786, loss_fp: 0.007072, loss_freq: 0.035378
[15:52:48.984] iteration 7621: loss: 0.071822, loss_s1: 0.039275, loss_fp: 0.001577, loss_freq: 0.027785
[15:52:49.611] iteration 7622: loss: 0.073434, loss_s1: 0.018569, loss_fp: 0.001637, loss_freq: 0.023711
[15:52:50.236] iteration 7623: loss: 0.114102, loss_s1: 0.083977, loss_fp: 0.000852, loss_freq: 0.066286
[15:52:50.862] iteration 7624: loss: 0.074477, loss_s1: 0.029949, loss_fp: 0.024265, loss_freq: 0.022741
[15:52:51.485] iteration 7625: loss: 0.100421, loss_s1: 0.051150, loss_fp: 0.001314, loss_freq: 0.030096
[15:52:52.115] iteration 7626: loss: 0.046492, loss_s1: 0.036807, loss_fp: 0.001435, loss_freq: 0.009504
[15:52:52.743] iteration 7627: loss: 0.062534, loss_s1: 0.035452, loss_fp: 0.002609, loss_freq: 0.022787
[15:52:53.368] iteration 7628: loss: 0.082400, loss_s1: 0.043547, loss_fp: 0.002531, loss_freq: 0.039509
[15:52:53.998] iteration 7629: loss: 0.051875, loss_s1: 0.019607, loss_fp: 0.001302, loss_freq: 0.015058
[15:52:54.632] iteration 7630: loss: 0.077815, loss_s1: 0.052245, loss_fp: 0.003033, loss_freq: 0.031584
[15:52:55.261] iteration 7631: loss: 0.051695, loss_s1: 0.014878, loss_fp: 0.002557, loss_freq: 0.026286
[15:52:55.893] iteration 7632: loss: 0.063147, loss_s1: 0.056808, loss_fp: 0.002766, loss_freq: 0.024361
[15:52:56.532] iteration 7633: loss: 0.085535, loss_s1: 0.051480, loss_fp: 0.002163, loss_freq: 0.057794
[15:52:57.162] iteration 7634: loss: 0.104172, loss_s1: 0.076703, loss_fp: 0.001094, loss_freq: 0.061415
[15:52:57.788] iteration 7635: loss: 0.072380, loss_s1: 0.064327, loss_fp: 0.004117, loss_freq: 0.027921
[15:52:58.419] iteration 7636: loss: 0.082687, loss_s1: 0.071354, loss_fp: 0.002002, loss_freq: 0.030969
[15:52:59.042] iteration 7637: loss: 0.147916, loss_s1: 0.101624, loss_fp: 0.007518, loss_freq: 0.058234
[15:52:59.674] iteration 7638: loss: 0.085294, loss_s1: 0.054805, loss_fp: 0.005256, loss_freq: 0.052956
[15:53:00.311] iteration 7639: loss: 0.138950, loss_s1: 0.078324, loss_fp: 0.002480, loss_freq: 0.065537
[15:53:00.935] iteration 7640: loss: 0.091636, loss_s1: 0.071881, loss_fp: 0.004266, loss_freq: 0.046261
[15:53:01.566] iteration 7641: loss: 0.087247, loss_s1: 0.054391, loss_fp: 0.003276, loss_freq: 0.032242
[15:53:02.201] iteration 7642: loss: 0.102650, loss_s1: 0.059692, loss_fp: 0.005637, loss_freq: 0.076416
[15:53:02.840] iteration 7643: loss: 0.162351, loss_s1: 0.151550, loss_fp: 0.001606, loss_freq: 0.088524
[15:53:03.463] iteration 7644: loss: 0.127401, loss_s1: 0.119580, loss_fp: 0.005490, loss_freq: 0.056218
[15:53:04.097] iteration 7645: loss: 0.074481, loss_s1: 0.058239, loss_fp: 0.005249, loss_freq: 0.024338
[15:53:04.723] iteration 7646: loss: 0.065699, loss_s1: 0.058047, loss_fp: 0.002457, loss_freq: 0.012022
[15:53:05.359] iteration 7647: loss: 0.088594, loss_s1: 0.051296, loss_fp: 0.001026, loss_freq: 0.070071
[15:53:05.982] iteration 7648: loss: 0.072964, loss_s1: 0.053979, loss_fp: 0.000471, loss_freq: 0.028579
[15:53:06.638] iteration 7649: loss: 0.070803, loss_s1: 0.062121, loss_fp: 0.006312, loss_freq: 0.018832
[15:53:07.258] iteration 7650: loss: 0.175988, loss_s1: 0.149792, loss_fp: 0.006551, loss_freq: 0.149998
[15:53:07.883] iteration 7651: loss: 0.082000, loss_s1: 0.022098, loss_fp: 0.003946, loss_freq: 0.040219
[15:53:08.518] iteration 7652: loss: 0.116892, loss_s1: 0.063063, loss_fp: 0.004809, loss_freq: 0.093382
[15:53:09.148] iteration 7653: loss: 0.066339, loss_s1: 0.048310, loss_fp: 0.003447, loss_freq: 0.031627
[15:53:09.779] iteration 7654: loss: 0.082241, loss_s1: 0.040080, loss_fp: 0.005595, loss_freq: 0.040928
[15:53:10.417] iteration 7655: loss: 0.080019, loss_s1: 0.071142, loss_fp: 0.001518, loss_freq: 0.019618
[15:53:11.077] iteration 7656: loss: 0.111899, loss_s1: 0.075687, loss_fp: 0.007268, loss_freq: 0.048325
[15:53:11.712] iteration 7657: loss: 0.069221, loss_s1: 0.041489, loss_fp: 0.001514, loss_freq: 0.015705
[15:53:12.348] iteration 7658: loss: 0.100524, loss_s1: 0.036208, loss_fp: 0.001668, loss_freq: 0.015699
[15:53:12.980] iteration 7659: loss: 0.109730, loss_s1: 0.083910, loss_fp: 0.003520, loss_freq: 0.038932
[15:53:13.612] iteration 7660: loss: 0.149137, loss_s1: 0.076651, loss_fp: 0.002991, loss_freq: 0.049403
[15:53:14.287] iteration 7661: loss: 0.057835, loss_s1: 0.044897, loss_fp: 0.001154, loss_freq: 0.013269
[15:53:14.960] iteration 7662: loss: 0.093625, loss_s1: 0.046194, loss_fp: 0.043990, loss_freq: 0.023789
[15:53:15.612] iteration 7663: loss: 0.076668, loss_s1: 0.069836, loss_fp: 0.002756, loss_freq: 0.017127
[15:53:16.246] iteration 7664: loss: 0.073740, loss_s1: 0.033688, loss_fp: 0.000478, loss_freq: 0.024222
[15:53:16.884] iteration 7665: loss: 0.072995, loss_s1: 0.021481, loss_fp: 0.001176, loss_freq: 0.010417
[15:53:17.523] iteration 7666: loss: 0.087750, loss_s1: 0.053713, loss_fp: 0.001327, loss_freq: 0.023636
[15:53:18.152] iteration 7667: loss: 0.082263, loss_s1: 0.059483, loss_fp: 0.003286, loss_freq: 0.022633
[15:53:18.787] iteration 7668: loss: 0.085746, loss_s1: 0.045306, loss_fp: 0.001882, loss_freq: 0.025336
[15:53:19.423] iteration 7669: loss: 0.131644, loss_s1: 0.063460, loss_fp: 0.005114, loss_freq: 0.075407
[15:53:20.055] iteration 7670: loss: 0.127191, loss_s1: 0.101039, loss_fp: 0.011097, loss_freq: 0.068297
[15:53:20.680] iteration 7671: loss: 0.103685, loss_s1: 0.099276, loss_fp: 0.005707, loss_freq: 0.028588
[15:53:21.309] iteration 7672: loss: 0.086047, loss_s1: 0.057828, loss_fp: 0.002112, loss_freq: 0.022280
[15:53:21.939] iteration 7673: loss: 0.061960, loss_s1: 0.016150, loss_fp: 0.001589, loss_freq: 0.028183
[15:53:22.567] iteration 7674: loss: 0.070125, loss_s1: 0.028992, loss_fp: 0.001692, loss_freq: 0.026419
[15:53:23.199] iteration 7675: loss: 0.110973, loss_s1: 0.082110, loss_fp: 0.007289, loss_freq: 0.073068
[15:53:23.828] iteration 7676: loss: 0.157669, loss_s1: 0.066417, loss_fp: 0.003081, loss_freq: 0.143158
[15:53:24.471] iteration 7677: loss: 0.129353, loss_s1: 0.122816, loss_fp: 0.012845, loss_freq: 0.049596
[15:53:25.124] iteration 7678: loss: 0.070302, loss_s1: 0.036174, loss_fp: 0.001559, loss_freq: 0.011900
[15:53:25.963] iteration 7679: loss: 0.100506, loss_s1: 0.055141, loss_fp: 0.008147, loss_freq: 0.075045
[15:53:26.668] iteration 7680: loss: 0.089721, loss_s1: 0.061362, loss_fp: 0.001113, loss_freq: 0.033620
[15:53:27.291] iteration 7681: loss: 0.077504, loss_s1: 0.048584, loss_fp: 0.001052, loss_freq: 0.035510
[15:53:27.914] iteration 7682: loss: 0.049397, loss_s1: 0.019579, loss_fp: 0.000246, loss_freq: 0.003833
[15:53:28.535] iteration 7683: loss: 0.131318, loss_s1: 0.096385, loss_fp: 0.001194, loss_freq: 0.037539
[15:53:29.160] iteration 7684: loss: 0.072737, loss_s1: 0.058724, loss_fp: 0.000975, loss_freq: 0.019738
[15:53:29.790] iteration 7685: loss: 0.065118, loss_s1: 0.016837, loss_fp: 0.001194, loss_freq: 0.039704
[15:53:30.414] iteration 7686: loss: 0.062305, loss_s1: 0.044076, loss_fp: 0.001569, loss_freq: 0.018252
[15:53:31.040] iteration 7687: loss: 0.140629, loss_s1: 0.093987, loss_fp: 0.010404, loss_freq: 0.100907
[15:53:31.670] iteration 7688: loss: 0.090370, loss_s1: 0.038900, loss_fp: 0.004351, loss_freq: 0.076346
[15:53:32.296] iteration 7689: loss: 0.075381, loss_s1: 0.038557, loss_fp: 0.002000, loss_freq: 0.042075
[15:53:32.920] iteration 7690: loss: 0.100220, loss_s1: 0.069264, loss_fp: 0.013466, loss_freq: 0.041846
[15:53:33.544] iteration 7691: loss: 0.112283, loss_s1: 0.073604, loss_fp: 0.029529, loss_freq: 0.041561
[15:53:34.170] iteration 7692: loss: 0.084134, loss_s1: 0.038957, loss_fp: 0.003856, loss_freq: 0.042280
[15:53:34.801] iteration 7693: loss: 0.103775, loss_s1: 0.034643, loss_fp: 0.002388, loss_freq: 0.024354
[15:53:35.429] iteration 7694: loss: 0.083546, loss_s1: 0.065731, loss_fp: 0.003026, loss_freq: 0.007037
[15:53:36.056] iteration 7695: loss: 0.112940, loss_s1: 0.012295, loss_fp: 0.002882, loss_freq: 0.056173
[15:53:36.680] iteration 7696: loss: 0.089287, loss_s1: 0.082051, loss_fp: 0.002309, loss_freq: 0.015427
[15:53:37.306] iteration 7697: loss: 0.075313, loss_s1: 0.069873, loss_fp: 0.001911, loss_freq: 0.026332
[15:53:37.927] iteration 7698: loss: 0.121438, loss_s1: 0.081026, loss_fp: 0.003754, loss_freq: 0.092874
[15:53:38.553] iteration 7699: loss: 0.138468, loss_s1: 0.081631, loss_fp: 0.003743, loss_freq: 0.065012
[15:53:39.175] iteration 7700: loss: 0.109648, loss_s1: 0.107219, loss_fp: 0.006316, loss_freq: 0.025038
[15:53:39.823] iteration 7701: loss: 0.138837, loss_s1: 0.061309, loss_fp: 0.002985, loss_freq: 0.011131
[15:53:40.445] iteration 7702: loss: 0.099928, loss_s1: 0.067269, loss_fp: 0.003975, loss_freq: 0.056593
[15:53:41.103] iteration 7703: loss: 0.088626, loss_s1: 0.040449, loss_fp: 0.001051, loss_freq: 0.066875
[15:53:41.761] iteration 7704: loss: 0.079525, loss_s1: 0.027415, loss_fp: 0.004487, loss_freq: 0.039372
[15:53:42.417] iteration 7705: loss: 0.076779, loss_s1: 0.068255, loss_fp: 0.004713, loss_freq: 0.033673
[15:53:43.058] iteration 7706: loss: 0.064484, loss_s1: 0.051660, loss_fp: 0.003986, loss_freq: 0.020313
[15:53:43.683] iteration 7707: loss: 0.132940, loss_s1: 0.076966, loss_fp: 0.001908, loss_freq: 0.064069
[15:53:44.306] iteration 7708: loss: 0.093190, loss_s1: 0.043220, loss_fp: 0.001754, loss_freq: 0.053727
[15:53:44.932] iteration 7709: loss: 0.079837, loss_s1: 0.027995, loss_fp: 0.005767, loss_freq: 0.040201
[15:53:45.556] iteration 7710: loss: 0.119016, loss_s1: 0.037981, loss_fp: 0.005101, loss_freq: 0.063799
[15:53:46.178] iteration 7711: loss: 0.077902, loss_s1: 0.038913, loss_fp: 0.002835, loss_freq: 0.030821
[15:53:46.802] iteration 7712: loss: 0.085666, loss_s1: 0.044980, loss_fp: 0.001182, loss_freq: 0.013276
[15:53:47.426] iteration 7713: loss: 0.073832, loss_s1: 0.046327, loss_fp: 0.002221, loss_freq: 0.010738
[15:53:48.050] iteration 7714: loss: 0.124285, loss_s1: 0.079188, loss_fp: 0.007136, loss_freq: 0.101778
[15:53:48.670] iteration 7715: loss: 0.087445, loss_s1: 0.041885, loss_fp: 0.002071, loss_freq: 0.048583
[15:53:49.294] iteration 7716: loss: 0.062173, loss_s1: 0.031050, loss_fp: 0.001273, loss_freq: 0.018536
[15:53:49.916] iteration 7717: loss: 0.103941, loss_s1: 0.049786, loss_fp: 0.004251, loss_freq: 0.046287
[15:53:50.540] iteration 7718: loss: 0.072454, loss_s1: 0.033909, loss_fp: 0.002519, loss_freq: 0.008820
[15:53:51.170] iteration 7719: loss: 0.089194, loss_s1: 0.071069, loss_fp: 0.007855, loss_freq: 0.027265
[15:53:51.807] iteration 7720: loss: 0.064440, loss_s1: 0.066860, loss_fp: 0.000768, loss_freq: 0.011843
[15:53:52.439] iteration 7721: loss: 0.099760, loss_s1: 0.047085, loss_fp: 0.001769, loss_freq: 0.010389
[15:53:53.065] iteration 7722: loss: 0.068342, loss_s1: 0.042782, loss_fp: 0.001782, loss_freq: 0.022591
[15:53:53.694] iteration 7723: loss: 0.061889, loss_s1: 0.057027, loss_fp: 0.000855, loss_freq: 0.009233
[15:53:54.321] iteration 7724: loss: 0.064606, loss_s1: 0.021094, loss_fp: 0.000488, loss_freq: 0.010540
[15:53:54.949] iteration 7725: loss: 0.078801, loss_s1: 0.037323, loss_fp: 0.005315, loss_freq: 0.031616
[15:53:55.571] iteration 7726: loss: 0.094892, loss_s1: 0.031344, loss_fp: 0.023822, loss_freq: 0.057851
[15:53:56.188] iteration 7727: loss: 0.057030, loss_s1: 0.021038, loss_fp: 0.000355, loss_freq: 0.023331
[15:53:56.806] iteration 7728: loss: 0.084509, loss_s1: 0.087149, loss_fp: 0.001125, loss_freq: 0.015981
[15:53:57.781] iteration 7729: loss: 0.079516, loss_s1: 0.043665, loss_fp: 0.000289, loss_freq: 0.016413
[15:53:58.443] iteration 7730: loss: 0.091889, loss_s1: 0.060175, loss_fp: 0.003092, loss_freq: 0.045318
[15:53:59.074] iteration 7731: loss: 0.090513, loss_s1: 0.037888, loss_fp: 0.009089, loss_freq: 0.054561
[15:53:59.700] iteration 7732: loss: 0.067263, loss_s1: 0.032546, loss_fp: 0.000650, loss_freq: 0.017403
[15:54:00.328] iteration 7733: loss: 0.058899, loss_s1: 0.033336, loss_fp: 0.002536, loss_freq: 0.020566
[15:54:00.961] iteration 7734: loss: 0.229389, loss_s1: 0.201757, loss_fp: 0.003980, loss_freq: 0.096322
[15:54:01.588] iteration 7735: loss: 0.058044, loss_s1: 0.036510, loss_fp: 0.004009, loss_freq: 0.021696
[15:54:02.215] iteration 7736: loss: 0.083771, loss_s1: 0.050556, loss_fp: 0.001276, loss_freq: 0.051370
[15:54:02.846] iteration 7737: loss: 0.078768, loss_s1: 0.085562, loss_fp: 0.004565, loss_freq: 0.020931
[15:54:03.473] iteration 7738: loss: 0.139621, loss_s1: 0.144169, loss_fp: 0.004266, loss_freq: 0.047862
[15:54:04.099] iteration 7739: loss: 0.071633, loss_s1: 0.054959, loss_fp: 0.000528, loss_freq: 0.023740
[15:54:04.723] iteration 7740: loss: 0.065759, loss_s1: 0.041719, loss_fp: 0.001257, loss_freq: 0.032180
[15:54:05.348] iteration 7741: loss: 0.100473, loss_s1: 0.087126, loss_fp: 0.005230, loss_freq: 0.065379
[15:54:05.970] iteration 7742: loss: 0.124881, loss_s1: 0.028069, loss_fp: 0.004748, loss_freq: 0.045376
[15:54:06.594] iteration 7743: loss: 0.067283, loss_s1: 0.044752, loss_fp: 0.003852, loss_freq: 0.038654
[15:54:07.215] iteration 7744: loss: 0.082673, loss_s1: 0.040961, loss_fp: 0.011737, loss_freq: 0.053601
[15:54:07.839] iteration 7745: loss: 0.077387, loss_s1: 0.053971, loss_fp: 0.001424, loss_freq: 0.013933
[15:54:08.462] iteration 7746: loss: 0.072149, loss_s1: 0.039684, loss_fp: 0.004755, loss_freq: 0.030533
[15:54:09.087] iteration 7747: loss: 0.091973, loss_s1: 0.081263, loss_fp: 0.005055, loss_freq: 0.022568
[15:54:09.711] iteration 7748: loss: 0.113534, loss_s1: 0.045554, loss_fp: 0.000727, loss_freq: 0.038399
[15:54:10.390] iteration 7749: loss: 0.058255, loss_s1: 0.018423, loss_fp: 0.000426, loss_freq: 0.013748
[15:54:11.049] iteration 7750: loss: 0.072734, loss_s1: 0.032454, loss_fp: 0.002882, loss_freq: 0.024494
[15:54:11.709] iteration 7751: loss: 0.108417, loss_s1: 0.056556, loss_fp: 0.001056, loss_freq: 0.041802
[15:54:12.349] iteration 7752: loss: 0.248027, loss_s1: 0.127210, loss_fp: 0.016980, loss_freq: 0.290023
[15:54:12.973] iteration 7753: loss: 0.080576, loss_s1: 0.078307, loss_fp: 0.000804, loss_freq: 0.018391
[15:54:13.598] iteration 7754: loss: 0.071815, loss_s1: 0.044896, loss_fp: 0.001707, loss_freq: 0.021814
[15:54:14.230] iteration 7755: loss: 0.102211, loss_s1: 0.079659, loss_fp: 0.001283, loss_freq: 0.058197
[15:54:14.848] iteration 7756: loss: 0.132453, loss_s1: 0.061364, loss_fp: 0.003243, loss_freq: 0.077365
[15:54:15.469] iteration 7757: loss: 0.099624, loss_s1: 0.094575, loss_fp: 0.008821, loss_freq: 0.040737
[15:54:16.098] iteration 7758: loss: 0.052038, loss_s1: 0.019538, loss_fp: 0.003366, loss_freq: 0.027932
[15:54:16.725] iteration 7759: loss: 0.068315, loss_s1: 0.063789, loss_fp: 0.001020, loss_freq: 0.030821
[15:54:17.355] iteration 7760: loss: 0.125254, loss_s1: 0.095349, loss_fp: 0.002856, loss_freq: 0.019528
[15:54:17.983] iteration 7761: loss: 0.075127, loss_s1: 0.060405, loss_fp: 0.003583, loss_freq: 0.045639
[15:54:18.606] iteration 7762: loss: 0.067482, loss_s1: 0.081599, loss_fp: 0.000839, loss_freq: 0.006113
[15:54:19.229] iteration 7763: loss: 0.127671, loss_s1: 0.061193, loss_fp: 0.002193, loss_freq: 0.033068
[15:54:19.855] iteration 7764: loss: 0.085126, loss_s1: 0.043067, loss_fp: 0.002573, loss_freq: 0.054314
[15:54:20.519] iteration 7765: loss: 0.162207, loss_s1: 0.123273, loss_fp: 0.022388, loss_freq: 0.070889
[15:54:21.180] iteration 7766: loss: 0.065756, loss_s1: 0.031447, loss_fp: 0.005056, loss_freq: 0.016103
[15:54:21.839] iteration 7767: loss: 0.148047, loss_s1: 0.114591, loss_fp: 0.003335, loss_freq: 0.080321
[15:54:22.496] iteration 7768: loss: 0.093373, loss_s1: 0.070014, loss_fp: 0.000965, loss_freq: 0.029128
[15:54:23.131] iteration 7769: loss: 0.084001, loss_s1: 0.039572, loss_fp: 0.002139, loss_freq: 0.026392
[15:54:23.753] iteration 7770: loss: 0.092614, loss_s1: 0.065366, loss_fp: 0.004890, loss_freq: 0.063296
[15:54:24.377] iteration 7771: loss: 0.123238, loss_s1: 0.094195, loss_fp: 0.012162, loss_freq: 0.060903
[15:54:25.002] iteration 7772: loss: 0.076209, loss_s1: 0.042492, loss_fp: 0.000927, loss_freq: 0.029788
[15:54:25.628] iteration 7773: loss: 0.109174, loss_s1: 0.045678, loss_fp: 0.000892, loss_freq: 0.044963
[15:54:26.254] iteration 7774: loss: 0.063959, loss_s1: 0.033016, loss_fp: 0.001889, loss_freq: 0.019570
[15:54:26.883] iteration 7775: loss: 0.040050, loss_s1: 0.021055, loss_fp: 0.000462, loss_freq: 0.007280
[15:54:27.508] iteration 7776: loss: 0.054467, loss_s1: 0.039815, loss_fp: 0.003548, loss_freq: 0.018589
[15:54:28.130] iteration 7777: loss: 0.095545, loss_s1: 0.061368, loss_fp: 0.000736, loss_freq: 0.011413
[15:54:28.752] iteration 7778: loss: 0.072260, loss_s1: 0.040349, loss_fp: 0.002431, loss_freq: 0.038962
[15:54:29.377] iteration 7779: loss: 0.054705, loss_s1: 0.021405, loss_fp: 0.001476, loss_freq: 0.020367
[15:54:30.000] iteration 7780: loss: 0.081766, loss_s1: 0.046500, loss_fp: 0.009272, loss_freq: 0.013692
[15:54:30.628] iteration 7781: loss: 0.090473, loss_s1: 0.045445, loss_fp: 0.001906, loss_freq: 0.042089
[15:54:31.253] iteration 7782: loss: 0.069638, loss_s1: 0.037437, loss_fp: 0.002083, loss_freq: 0.026108
[15:54:31.887] iteration 7783: loss: 0.112073, loss_s1: 0.087216, loss_fp: 0.001045, loss_freq: 0.034230
[15:54:32.509] iteration 7784: loss: 0.099335, loss_s1: 0.102431, loss_fp: 0.000434, loss_freq: 0.030326
[15:54:33.130] iteration 7785: loss: 0.090557, loss_s1: 0.074752, loss_fp: 0.000618, loss_freq: 0.020616
[15:54:33.752] iteration 7786: loss: 0.144803, loss_s1: 0.102300, loss_fp: 0.004661, loss_freq: 0.045009
[15:54:34.378] iteration 7787: loss: 0.054809, loss_s1: 0.028787, loss_fp: 0.003052, loss_freq: 0.005643
[15:54:35.006] iteration 7788: loss: 0.070569, loss_s1: 0.035671, loss_fp: 0.002670, loss_freq: 0.018022
[15:54:35.632] iteration 7789: loss: 0.078490, loss_s1: 0.032944, loss_fp: 0.003651, loss_freq: 0.028113
[15:54:36.257] iteration 7790: loss: 0.053162, loss_s1: 0.031324, loss_fp: 0.002779, loss_freq: 0.017921
[15:54:36.879] iteration 7791: loss: 0.075198, loss_s1: 0.039742, loss_fp: 0.004686, loss_freq: 0.031916
[15:54:37.504] iteration 7792: loss: 0.069889, loss_s1: 0.037845, loss_fp: 0.000793, loss_freq: 0.023930
[15:54:38.129] iteration 7793: loss: 0.101714, loss_s1: 0.095544, loss_fp: 0.001103, loss_freq: 0.026860
[15:54:38.751] iteration 7794: loss: 0.099885, loss_s1: 0.045686, loss_fp: 0.008529, loss_freq: 0.048724
[15:54:39.375] iteration 7795: loss: 0.073565, loss_s1: 0.020793, loss_fp: 0.002888, loss_freq: 0.040258
[15:54:40.001] iteration 7796: loss: 0.056881, loss_s1: 0.035548, loss_fp: 0.001431, loss_freq: 0.022735
[15:54:40.626] iteration 7797: loss: 0.072541, loss_s1: 0.035441, loss_fp: 0.004737, loss_freq: 0.037794
[15:54:41.255] iteration 7798: loss: 0.073478, loss_s1: 0.025410, loss_fp: 0.002128, loss_freq: 0.030349
[15:54:41.882] iteration 7799: loss: 0.097651, loss_s1: 0.088409, loss_fp: 0.010526, loss_freq: 0.034464
[15:54:42.509] iteration 7800: loss: 0.099501, loss_s1: 0.067468, loss_fp: 0.007202, loss_freq: 0.028767
[15:54:45.778] iteration 7800 : mean_dice : 0.679082
[15:54:46.467] iteration 7801: loss: 0.083208, loss_s1: 0.027978, loss_fp: 0.007419, loss_freq: 0.061641
[15:54:47.131] iteration 7802: loss: 0.074494, loss_s1: 0.035505, loss_fp: 0.003691, loss_freq: 0.014586
[15:54:47.788] iteration 7803: loss: 0.095887, loss_s1: 0.076206, loss_fp: 0.001228, loss_freq: 0.034446
[15:54:48.446] iteration 7804: loss: 0.138362, loss_s1: 0.084976, loss_fp: 0.002602, loss_freq: 0.067068
[15:54:49.077] iteration 7805: loss: 0.092518, loss_s1: 0.057744, loss_fp: 0.002526, loss_freq: 0.043400
[15:54:49.705] iteration 7806: loss: 0.062276, loss_s1: 0.026771, loss_fp: 0.003001, loss_freq: 0.028088
[15:54:50.334] iteration 7807: loss: 0.068882, loss_s1: 0.025676, loss_fp: 0.001660, loss_freq: 0.020772
[15:54:50.990] iteration 7808: loss: 0.075598, loss_s1: 0.073820, loss_fp: 0.005802, loss_freq: 0.018907
[15:54:51.646] iteration 7809: loss: 0.101017, loss_s1: 0.045876, loss_fp: 0.002645, loss_freq: 0.078164
[15:54:52.306] iteration 7810: loss: 0.068613, loss_s1: 0.055933, loss_fp: 0.001499, loss_freq: 0.018347
[15:54:52.957] iteration 7811: loss: 0.124603, loss_s1: 0.112320, loss_fp: 0.017034, loss_freq: 0.064842
[15:54:53.580] iteration 7812: loss: 0.070574, loss_s1: 0.019872, loss_fp: 0.002303, loss_freq: 0.009090
[15:54:54.203] iteration 7813: loss: 0.159429, loss_s1: 0.120270, loss_fp: 0.016913, loss_freq: 0.102644
[15:54:54.832] iteration 7814: loss: 0.070046, loss_s1: 0.038285, loss_fp: 0.003147, loss_freq: 0.051519
[15:54:55.460] iteration 7815: loss: 0.127370, loss_s1: 0.104558, loss_fp: 0.001069, loss_freq: 0.034251
[15:54:56.083] iteration 7816: loss: 0.087159, loss_s1: 0.078495, loss_fp: 0.000540, loss_freq: 0.013724
[15:54:56.704] iteration 7817: loss: 0.120617, loss_s1: 0.083609, loss_fp: 0.007125, loss_freq: 0.069567
[15:54:57.328] iteration 7818: loss: 0.071921, loss_s1: 0.028644, loss_fp: 0.002236, loss_freq: 0.019367
[15:54:57.950] iteration 7819: loss: 0.123993, loss_s1: 0.050623, loss_fp: 0.001810, loss_freq: 0.026100
[15:54:58.577] iteration 7820: loss: 0.080230, loss_s1: 0.067027, loss_fp: 0.001800, loss_freq: 0.016679
[15:54:59.201] iteration 7821: loss: 0.135383, loss_s1: 0.053951, loss_fp: 0.006588, loss_freq: 0.036429
[15:54:59.819] iteration 7822: loss: 0.073736, loss_s1: 0.025626, loss_fp: 0.000928, loss_freq: 0.051708
[15:55:00.432] iteration 7823: loss: 0.050635, loss_s1: 0.029035, loss_fp: 0.000320, loss_freq: 0.006321
[15:55:01.043] iteration 7824: loss: 0.053959, loss_s1: 0.016227, loss_fp: 0.004045, loss_freq: 0.006357
[15:55:01.668] iteration 7825: loss: 0.075674, loss_s1: 0.057623, loss_fp: 0.000498, loss_freq: 0.027161
[15:55:02.294] iteration 7826: loss: 0.064072, loss_s1: 0.015025, loss_fp: 0.000715, loss_freq: 0.040893
[15:55:02.916] iteration 7827: loss: 0.079301, loss_s1: 0.064899, loss_fp: 0.009252, loss_freq: 0.025992
[15:55:03.537] iteration 7828: loss: 0.065683, loss_s1: 0.045963, loss_fp: 0.002682, loss_freq: 0.037004
[15:55:04.161] iteration 7829: loss: 0.069798, loss_s1: 0.042893, loss_fp: 0.002115, loss_freq: 0.031262
[15:55:04.780] iteration 7830: loss: 0.075690, loss_s1: 0.032305, loss_fp: 0.001455, loss_freq: 0.052147
[15:55:05.442] iteration 7831: loss: 0.095776, loss_s1: 0.056730, loss_fp: 0.010466, loss_freq: 0.034941
[15:55:06.063] iteration 7832: loss: 0.104945, loss_s1: 0.057962, loss_fp: 0.004380, loss_freq: 0.084493
[15:55:06.679] iteration 7833: loss: 0.106675, loss_s1: 0.072593, loss_fp: 0.004553, loss_freq: 0.038108
[15:55:07.304] iteration 7834: loss: 0.046243, loss_s1: 0.024332, loss_fp: 0.001286, loss_freq: 0.019686
[15:55:07.929] iteration 7835: loss: 0.073531, loss_s1: 0.025369, loss_fp: 0.000877, loss_freq: 0.023036
[15:55:08.551] iteration 7836: loss: 0.150128, loss_s1: 0.168391, loss_fp: 0.002235, loss_freq: 0.056668
[15:55:09.178] iteration 7837: loss: 0.192154, loss_s1: 0.111455, loss_fp: 0.004667, loss_freq: 0.146059
[15:55:09.804] iteration 7838: loss: 0.058104, loss_s1: 0.021112, loss_fp: 0.006160, loss_freq: 0.038119
[15:55:10.432] iteration 7839: loss: 0.084192, loss_s1: 0.044193, loss_fp: 0.003126, loss_freq: 0.053781
[15:55:11.053] iteration 7840: loss: 0.085917, loss_s1: 0.052386, loss_fp: 0.003723, loss_freq: 0.065397
[15:55:11.679] iteration 7841: loss: 0.164624, loss_s1: 0.150045, loss_fp: 0.004448, loss_freq: 0.097795
[15:55:12.301] iteration 7842: loss: 0.091099, loss_s1: 0.077479, loss_fp: 0.010728, loss_freq: 0.023247
[15:55:12.925] iteration 7843: loss: 0.052156, loss_s1: 0.024222, loss_fp: 0.004151, loss_freq: 0.012801
[15:55:13.551] iteration 7844: loss: 0.081281, loss_s1: 0.058427, loss_fp: 0.003568, loss_freq: 0.028496
[15:55:14.174] iteration 7845: loss: 0.087504, loss_s1: 0.045726, loss_fp: 0.000746, loss_freq: 0.052269
[15:55:14.799] iteration 7846: loss: 0.070450, loss_s1: 0.044450, loss_fp: 0.001360, loss_freq: 0.044204
[15:55:15.428] iteration 7847: loss: 0.077755, loss_s1: 0.048539, loss_fp: 0.002679, loss_freq: 0.042094
[15:55:16.057] iteration 7848: loss: 0.102604, loss_s1: 0.065606, loss_fp: 0.009041, loss_freq: 0.079180
[15:55:16.686] iteration 7849: loss: 0.092573, loss_s1: 0.054184, loss_fp: 0.011690, loss_freq: 0.064125
[15:55:17.313] iteration 7850: loss: 0.104073, loss_s1: 0.025380, loss_fp: 0.009887, loss_freq: 0.016622
[15:55:17.941] iteration 7851: loss: 0.088272, loss_s1: 0.063648, loss_fp: 0.003450, loss_freq: 0.029927
[15:55:18.571] iteration 7852: loss: 0.082971, loss_s1: 0.074511, loss_fp: 0.002097, loss_freq: 0.021598
[15:55:19.201] iteration 7853: loss: 0.117222, loss_s1: 0.063902, loss_fp: 0.007886, loss_freq: 0.077650
[15:55:19.827] iteration 7854: loss: 0.078834, loss_s1: 0.053119, loss_fp: 0.008897, loss_freq: 0.026140
[15:55:20.456] iteration 7855: loss: 0.073721, loss_s1: 0.047114, loss_fp: 0.001451, loss_freq: 0.020644
[15:55:21.083] iteration 7856: loss: 0.167207, loss_s1: 0.096243, loss_fp: 0.018268, loss_freq: 0.092804
[15:55:21.713] iteration 7857: loss: 0.089122, loss_s1: 0.092562, loss_fp: 0.001899, loss_freq: 0.028626
[15:55:22.340] iteration 7858: loss: 0.059057, loss_s1: 0.034105, loss_fp: 0.002933, loss_freq: 0.018789
[15:55:22.965] iteration 7859: loss: 0.129033, loss_s1: 0.070282, loss_fp: 0.002552, loss_freq: 0.120931
[15:55:23.590] iteration 7860: loss: 0.112530, loss_s1: 0.118512, loss_fp: 0.000878, loss_freq: 0.035270
[15:55:24.217] iteration 7861: loss: 0.084338, loss_s1: 0.066121, loss_fp: 0.002007, loss_freq: 0.020391
[15:55:24.844] iteration 7862: loss: 0.094286, loss_s1: 0.104928, loss_fp: 0.004077, loss_freq: 0.036295
[15:55:25.470] iteration 7863: loss: 0.113263, loss_s1: 0.078905, loss_fp: 0.003047, loss_freq: 0.063239
[15:55:26.092] iteration 7864: loss: 0.083273, loss_s1: 0.042317, loss_fp: 0.003183, loss_freq: 0.041838
[15:55:26.718] iteration 7865: loss: 0.078663, loss_s1: 0.028493, loss_fp: 0.003997, loss_freq: 0.048146
[15:55:27.390] iteration 7866: loss: 0.073668, loss_s1: 0.066532, loss_fp: 0.002137, loss_freq: 0.022788
[15:55:28.112] iteration 7867: loss: 0.062721, loss_s1: 0.043785, loss_fp: 0.005853, loss_freq: 0.023785
[15:55:28.774] iteration 7868: loss: 0.115987, loss_s1: 0.045798, loss_fp: 0.004112, loss_freq: 0.036682
[15:55:29.436] iteration 7869: loss: 0.092459, loss_s1: 0.041352, loss_fp: 0.008579, loss_freq: 0.077470
[15:55:30.091] iteration 7870: loss: 0.080999, loss_s1: 0.048484, loss_fp: 0.002413, loss_freq: 0.022312
[15:55:30.748] iteration 7871: loss: 0.105377, loss_s1: 0.053631, loss_fp: 0.005934, loss_freq: 0.029260
[15:55:31.401] iteration 7872: loss: 0.078161, loss_s1: 0.066482, loss_fp: 0.001500, loss_freq: 0.029340
[15:55:32.034] iteration 7873: loss: 0.065031, loss_s1: 0.022543, loss_fp: 0.004577, loss_freq: 0.029890
[15:55:32.656] iteration 7874: loss: 0.128264, loss_s1: 0.052390, loss_fp: 0.008072, loss_freq: 0.055535
[15:55:33.317] iteration 7875: loss: 0.084031, loss_s1: 0.059264, loss_fp: 0.002959, loss_freq: 0.055359
[15:55:33.979] iteration 7876: loss: 0.090861, loss_s1: 0.074268, loss_fp: 0.002682, loss_freq: 0.035789
[15:55:34.641] iteration 7877: loss: 0.062959, loss_s1: 0.024545, loss_fp: 0.001859, loss_freq: 0.034872
[15:55:35.301] iteration 7878: loss: 0.103735, loss_s1: 0.087337, loss_fp: 0.001723, loss_freq: 0.038890
[15:55:35.928] iteration 7879: loss: 0.103442, loss_s1: 0.069918, loss_fp: 0.005745, loss_freq: 0.065101
[15:55:36.555] iteration 7880: loss: 0.103114, loss_s1: 0.106109, loss_fp: 0.002326, loss_freq: 0.032557
[15:55:37.184] iteration 7881: loss: 0.054537, loss_s1: 0.034627, loss_fp: 0.002731, loss_freq: 0.012605
[15:55:37.812] iteration 7882: loss: 0.084766, loss_s1: 0.064119, loss_fp: 0.000799, loss_freq: 0.032312
[15:55:38.439] iteration 7883: loss: 0.054046, loss_s1: 0.022094, loss_fp: 0.000722, loss_freq: 0.019077
[15:55:39.063] iteration 7884: loss: 0.077520, loss_s1: 0.060497, loss_fp: 0.001468, loss_freq: 0.027954
[15:55:39.688] iteration 7885: loss: 0.072220, loss_s1: 0.023607, loss_fp: 0.000437, loss_freq: 0.011234
[15:55:40.310] iteration 7886: loss: 0.092707, loss_s1: 0.038589, loss_fp: 0.003775, loss_freq: 0.043596
[15:55:40.933] iteration 7887: loss: 0.105493, loss_s1: 0.056102, loss_fp: 0.003081, loss_freq: 0.058629
[15:55:41.552] iteration 7888: loss: 0.096715, loss_s1: 0.069772, loss_fp: 0.000902, loss_freq: 0.025102
[15:55:42.172] iteration 7889: loss: 0.081046, loss_s1: 0.040080, loss_fp: 0.000179, loss_freq: 0.040668
[15:55:43.163] iteration 7890: loss: 0.054186, loss_s1: 0.029963, loss_fp: 0.000647, loss_freq: 0.018088
[15:55:43.822] iteration 7891: loss: 0.079567, loss_s1: 0.057132, loss_fp: 0.000551, loss_freq: 0.017519
[15:55:44.478] iteration 7892: loss: 0.092590, loss_s1: 0.023296, loss_fp: 0.004786, loss_freq: 0.030488
[15:55:45.125] iteration 7893: loss: 0.103945, loss_s1: 0.019857, loss_fp: 0.003933, loss_freq: 0.017739
[15:55:45.747] iteration 7894: loss: 0.118974, loss_s1: 0.090702, loss_fp: 0.003850, loss_freq: 0.029466
[15:55:46.368] iteration 7895: loss: 0.135631, loss_s1: 0.095605, loss_fp: 0.021476, loss_freq: 0.035544
[15:55:46.993] iteration 7896: loss: 0.047458, loss_s1: 0.024243, loss_fp: 0.000656, loss_freq: 0.019122
[15:55:47.615] iteration 7897: loss: 0.073233, loss_s1: 0.045315, loss_fp: 0.005289, loss_freq: 0.025525
[15:55:48.241] iteration 7898: loss: 0.082820, loss_s1: 0.088199, loss_fp: 0.002827, loss_freq: 0.026048
[15:55:48.865] iteration 7899: loss: 0.082807, loss_s1: 0.052213, loss_fp: 0.005683, loss_freq: 0.043554
[15:55:49.489] iteration 7900: loss: 0.074417, loss_s1: 0.024804, loss_fp: 0.001583, loss_freq: 0.029908
[15:55:50.111] iteration 7901: loss: 0.090396, loss_s1: 0.039241, loss_fp: 0.002810, loss_freq: 0.032897
[15:55:50.751] iteration 7902: loss: 0.087011, loss_s1: 0.072284, loss_fp: 0.002004, loss_freq: 0.044672
[15:55:51.380] iteration 7903: loss: 0.072760, loss_s1: 0.019208, loss_fp: 0.002274, loss_freq: 0.030401
[15:55:52.010] iteration 7904: loss: 0.067454, loss_s1: 0.032842, loss_fp: 0.001765, loss_freq: 0.038680
[15:55:52.635] iteration 7905: loss: 0.145794, loss_s1: 0.104030, loss_fp: 0.001057, loss_freq: 0.109876
[15:55:53.263] iteration 7906: loss: 0.074827, loss_s1: 0.034745, loss_fp: 0.008658, loss_freq: 0.018419
[15:55:53.887] iteration 7907: loss: 0.084361, loss_s1: 0.043830, loss_fp: 0.002643, loss_freq: 0.045747
[15:55:54.515] iteration 7908: loss: 0.076221, loss_s1: 0.059795, loss_fp: 0.004547, loss_freq: 0.021812
[15:55:55.141] iteration 7909: loss: 0.058723, loss_s1: 0.022104, loss_fp: 0.002157, loss_freq: 0.012405
[15:55:55.767] iteration 7910: loss: 0.092791, loss_s1: 0.045059, loss_fp: 0.020562, loss_freq: 0.044696
[15:55:56.392] iteration 7911: loss: 0.061180, loss_s1: 0.049058, loss_fp: 0.001363, loss_freq: 0.018057
[15:55:57.048] iteration 7912: loss: 0.094613, loss_s1: 0.072025, loss_fp: 0.003050, loss_freq: 0.025733
[15:55:57.707] iteration 7913: loss: 0.171041, loss_s1: 0.171186, loss_fp: 0.007083, loss_freq: 0.101262
[15:55:58.363] iteration 7914: loss: 0.057577, loss_s1: 0.033765, loss_fp: 0.001587, loss_freq: 0.022718
[15:55:59.019] iteration 7915: loss: 0.116005, loss_s1: 0.106378, loss_fp: 0.001308, loss_freq: 0.055627
[15:55:59.676] iteration 7916: loss: 0.095918, loss_s1: 0.077226, loss_fp: 0.001650, loss_freq: 0.021467
[15:56:00.325] iteration 7917: loss: 0.093880, loss_s1: 0.049776, loss_fp: 0.012460, loss_freq: 0.032982
[15:56:00.945] iteration 7918: loss: 0.062690, loss_s1: 0.038450, loss_fp: 0.002827, loss_freq: 0.026787
[15:56:01.569] iteration 7919: loss: 0.067181, loss_s1: 0.072230, loss_fp: 0.004270, loss_freq: 0.008656
[15:56:02.190] iteration 7920: loss: 0.052227, loss_s1: 0.038160, loss_fp: 0.000805, loss_freq: 0.016132
[15:56:02.818] iteration 7921: loss: 0.078908, loss_s1: 0.042021, loss_fp: 0.002909, loss_freq: 0.015881
[15:56:03.441] iteration 7922: loss: 0.067717, loss_s1: 0.054974, loss_fp: 0.000696, loss_freq: 0.026594
[15:56:04.069] iteration 7923: loss: 0.105479, loss_s1: 0.123146, loss_fp: 0.000629, loss_freq: 0.016433
[15:56:04.697] iteration 7924: loss: 0.079589, loss_s1: 0.020140, loss_fp: 0.000349, loss_freq: 0.017432
[15:56:05.351] iteration 7925: loss: 0.090055, loss_s1: 0.089957, loss_fp: 0.016335, loss_freq: 0.032230
[15:56:06.025] iteration 7926: loss: 0.084954, loss_s1: 0.012935, loss_fp: 0.001662, loss_freq: 0.037751
[15:56:06.697] iteration 7927: loss: 0.077171, loss_s1: 0.065563, loss_fp: 0.008569, loss_freq: 0.017784
[15:56:07.368] iteration 7928: loss: 0.128954, loss_s1: 0.064606, loss_fp: 0.000313, loss_freq: 0.098416
[15:56:08.005] iteration 7929: loss: 0.081066, loss_s1: 0.060755, loss_fp: 0.002510, loss_freq: 0.025830
[15:56:08.644] iteration 7930: loss: 0.073329, loss_s1: 0.042263, loss_fp: 0.000993, loss_freq: 0.020127
[15:56:09.282] iteration 7931: loss: 0.083748, loss_s1: 0.078496, loss_fp: 0.007460, loss_freq: 0.031601
[15:56:09.920] iteration 7932: loss: 0.064158, loss_s1: 0.052951, loss_fp: 0.003779, loss_freq: 0.024930
[15:56:10.564] iteration 7933: loss: 0.054168, loss_s1: 0.018962, loss_fp: 0.001009, loss_freq: 0.031666
[15:56:11.205] iteration 7934: loss: 0.074135, loss_s1: 0.054258, loss_fp: 0.001234, loss_freq: 0.034514
[15:56:11.845] iteration 7935: loss: 0.073972, loss_s1: 0.039260, loss_fp: 0.005089, loss_freq: 0.016296
[15:56:12.481] iteration 7936: loss: 0.064229, loss_s1: 0.065299, loss_fp: 0.000387, loss_freq: 0.020574
[15:56:13.123] iteration 7937: loss: 0.056019, loss_s1: 0.044796, loss_fp: 0.001598, loss_freq: 0.015324
[15:56:13.782] iteration 7938: loss: 0.062421, loss_s1: 0.039659, loss_fp: 0.000518, loss_freq: 0.020824
[15:56:14.440] iteration 7939: loss: 0.085804, loss_s1: 0.056185, loss_fp: 0.004256, loss_freq: 0.059781
[15:56:15.095] iteration 7940: loss: 0.076472, loss_s1: 0.065443, loss_fp: 0.001122, loss_freq: 0.044117
[15:56:15.752] iteration 7941: loss: 0.058032, loss_s1: 0.033264, loss_fp: 0.005412, loss_freq: 0.012509
[15:56:16.380] iteration 7942: loss: 0.089905, loss_s1: 0.071273, loss_fp: 0.003069, loss_freq: 0.047050
[15:56:17.004] iteration 7943: loss: 0.103246, loss_s1: 0.052348, loss_fp: 0.003928, loss_freq: 0.096005
[15:56:17.626] iteration 7944: loss: 0.082001, loss_s1: 0.059535, loss_fp: 0.001385, loss_freq: 0.034444
[15:56:18.251] iteration 7945: loss: 0.088369, loss_s1: 0.062197, loss_fp: 0.002172, loss_freq: 0.016160
[15:56:18.873] iteration 7946: loss: 0.075235, loss_s1: 0.051469, loss_fp: 0.001492, loss_freq: 0.030628
[15:56:19.497] iteration 7947: loss: 0.070877, loss_s1: 0.023988, loss_fp: 0.000421, loss_freq: 0.044924
[15:56:20.120] iteration 7948: loss: 0.036167, loss_s1: 0.017473, loss_fp: 0.000532, loss_freq: 0.008699
[15:56:20.744] iteration 7949: loss: 0.046763, loss_s1: 0.032315, loss_fp: 0.003594, loss_freq: 0.021541
[15:56:21.367] iteration 7950: loss: 0.055630, loss_s1: 0.026248, loss_fp: 0.009819, loss_freq: 0.016553
[15:56:21.991] iteration 7951: loss: 0.078661, loss_s1: 0.045056, loss_fp: 0.014258, loss_freq: 0.026391
[15:56:22.617] iteration 7952: loss: 0.068919, loss_s1: 0.044153, loss_fp: 0.001856, loss_freq: 0.031322
[15:56:23.243] iteration 7953: loss: 0.062635, loss_s1: 0.020280, loss_fp: 0.000783, loss_freq: 0.047148
[15:56:23.870] iteration 7954: loss: 0.061182, loss_s1: 0.049055, loss_fp: 0.001098, loss_freq: 0.019116
[15:56:24.496] iteration 7955: loss: 0.105681, loss_s1: 0.039482, loss_fp: 0.022252, loss_freq: 0.098382
[15:56:25.118] iteration 7956: loss: 0.109012, loss_s1: 0.055223, loss_fp: 0.004723, loss_freq: 0.062257
[15:56:25.743] iteration 7957: loss: 0.075528, loss_s1: 0.045893, loss_fp: 0.002462, loss_freq: 0.050900
[15:56:26.365] iteration 7958: loss: 0.056601, loss_s1: 0.028810, loss_fp: 0.001395, loss_freq: 0.019879
[15:56:27.047] iteration 7959: loss: 0.103485, loss_s1: 0.066647, loss_fp: 0.003416, loss_freq: 0.030238
[15:56:27.702] iteration 7960: loss: 0.114320, loss_s1: 0.100399, loss_fp: 0.010905, loss_freq: 0.057335
[15:56:28.359] iteration 7961: loss: 0.088645, loss_s1: 0.054531, loss_fp: 0.003094, loss_freq: 0.049412
[15:56:29.018] iteration 7962: loss: 0.075026, loss_s1: 0.018176, loss_fp: 0.003944, loss_freq: 0.076474
[15:56:29.644] iteration 7963: loss: 0.072409, loss_s1: 0.071264, loss_fp: 0.001614, loss_freq: 0.011258
[15:56:30.274] iteration 7964: loss: 0.099720, loss_s1: 0.080432, loss_fp: 0.003254, loss_freq: 0.044337
[15:56:30.968] iteration 7965: loss: 0.120950, loss_s1: 0.085287, loss_fp: 0.004306, loss_freq: 0.078234
[15:56:31.633] iteration 7966: loss: 0.101617, loss_s1: 0.079539, loss_fp: 0.007636, loss_freq: 0.068801
[15:56:32.299] iteration 7967: loss: 0.084309, loss_s1: 0.070529, loss_fp: 0.002102, loss_freq: 0.033668
[15:56:32.947] iteration 7968: loss: 0.075069, loss_s1: 0.032773, loss_fp: 0.004321, loss_freq: 0.028317
[15:56:33.578] iteration 7969: loss: 0.079886, loss_s1: 0.068940, loss_fp: 0.002119, loss_freq: 0.040668
[15:56:34.202] iteration 7970: loss: 0.106695, loss_s1: 0.072145, loss_fp: 0.003030, loss_freq: 0.074376
[15:56:34.830] iteration 7971: loss: 0.100456, loss_s1: 0.059737, loss_fp: 0.004434, loss_freq: 0.030466
[15:56:35.476] iteration 7972: loss: 0.120337, loss_s1: 0.082303, loss_fp: 0.024997, loss_freq: 0.048237
[15:56:36.139] iteration 7973: loss: 0.090155, loss_s1: 0.028315, loss_fp: 0.002560, loss_freq: 0.050476
[15:56:36.760] iteration 7974: loss: 0.114490, loss_s1: 0.074212, loss_fp: 0.005845, loss_freq: 0.071220
[15:56:37.384] iteration 7975: loss: 0.079799, loss_s1: 0.072341, loss_fp: 0.003950, loss_freq: 0.037763
[15:56:38.007] iteration 7976: loss: 0.166405, loss_s1: 0.090132, loss_fp: 0.007933, loss_freq: 0.049908
[15:56:38.634] iteration 7977: loss: 0.096152, loss_s1: 0.071573, loss_fp: 0.002624, loss_freq: 0.025607
[15:56:39.266] iteration 7978: loss: 0.126341, loss_s1: 0.084007, loss_fp: 0.013854, loss_freq: 0.054551
[15:56:39.893] iteration 7979: loss: 0.077514, loss_s1: 0.031597, loss_fp: 0.004649, loss_freq: 0.039295
[15:56:40.528] iteration 7980: loss: 0.110004, loss_s1: 0.065154, loss_fp: 0.001965, loss_freq: 0.015412
[15:56:41.164] iteration 7981: loss: 0.063606, loss_s1: 0.037456, loss_fp: 0.002844, loss_freq: 0.016303
[15:56:41.848] iteration 7982: loss: 0.100558, loss_s1: 0.033603, loss_fp: 0.000403, loss_freq: 0.015076
[15:56:42.515] iteration 7983: loss: 0.045641, loss_s1: 0.027346, loss_fp: 0.004094, loss_freq: 0.009847
[15:56:43.194] iteration 7984: loss: 0.069198, loss_s1: 0.028465, loss_fp: 0.006214, loss_freq: 0.040358
[15:56:43.819] iteration 7985: loss: 0.074473, loss_s1: 0.051285, loss_fp: 0.000932, loss_freq: 0.038622
[15:56:44.455] iteration 7986: loss: 0.056933, loss_s1: 0.018806, loss_fp: 0.001078, loss_freq: 0.023956
[15:56:45.087] iteration 7987: loss: 0.059513, loss_s1: 0.025230, loss_fp: 0.000420, loss_freq: 0.019096
[15:56:45.716] iteration 7988: loss: 0.068166, loss_s1: 0.036269, loss_fp: 0.006480, loss_freq: 0.034859
[15:56:46.346] iteration 7989: loss: 0.101798, loss_s1: 0.095284, loss_fp: 0.002298, loss_freq: 0.028327
[15:56:46.974] iteration 7990: loss: 0.058238, loss_s1: 0.032462, loss_fp: 0.001756, loss_freq: 0.028456
[15:56:47.594] iteration 7991: loss: 0.099954, loss_s1: 0.043563, loss_fp: 0.006905, loss_freq: 0.038065
[15:56:48.224] iteration 7992: loss: 0.112749, loss_s1: 0.058040, loss_fp: 0.002546, loss_freq: 0.052226
[15:56:48.851] iteration 7993: loss: 0.110614, loss_s1: 0.078278, loss_fp: 0.003019, loss_freq: 0.053745
[15:56:49.478] iteration 7994: loss: 0.111812, loss_s1: 0.043119, loss_fp: 0.001956, loss_freq: 0.053909
[15:56:50.102] iteration 7995: loss: 0.066207, loss_s1: 0.037480, loss_fp: 0.003151, loss_freq: 0.029578
[15:56:50.730] iteration 7996: loss: 0.068814, loss_s1: 0.030570, loss_fp: 0.003021, loss_freq: 0.007442
[15:56:51.355] iteration 7997: loss: 0.135582, loss_s1: 0.097368, loss_fp: 0.006546, loss_freq: 0.074658
[15:56:51.982] iteration 7998: loss: 0.143152, loss_s1: 0.045157, loss_fp: 0.001810, loss_freq: 0.151757
[15:56:52.666] iteration 7999: loss: 0.076447, loss_s1: 0.048601, loss_fp: 0.001268, loss_freq: 0.020561
[15:56:53.343] iteration 8000: loss: 0.093763, loss_s1: 0.026280, loss_fp: 0.001090, loss_freq: 0.050406
[15:56:56.375] iteration 8000 : mean_dice : 0.624773
[15:56:57.024] iteration 8001: loss: 0.074426, loss_s1: 0.052335, loss_fp: 0.004575, loss_freq: 0.040804
[15:56:57.649] iteration 8002: loss: 0.165121, loss_s1: 0.153249, loss_fp: 0.003182, loss_freq: 0.077674
[15:56:58.276] iteration 8003: loss: 0.105921, loss_s1: 0.092499, loss_fp: 0.000991, loss_freq: 0.042013
[15:56:58.903] iteration 8004: loss: 0.060525, loss_s1: 0.041733, loss_fp: 0.002478, loss_freq: 0.004348
[15:56:59.529] iteration 8005: loss: 0.093895, loss_s1: 0.052377, loss_fp: 0.009426, loss_freq: 0.062921
[15:57:00.154] iteration 8006: loss: 0.082279, loss_s1: 0.090770, loss_fp: 0.007407, loss_freq: 0.029314
[15:57:00.782] iteration 8007: loss: 0.110007, loss_s1: 0.063115, loss_fp: 0.001780, loss_freq: 0.047385
[15:57:01.412] iteration 8008: loss: 0.081901, loss_s1: 0.056935, loss_fp: 0.000700, loss_freq: 0.033081
[15:57:02.045] iteration 8009: loss: 0.091839, loss_s1: 0.040249, loss_fp: 0.012944, loss_freq: 0.078910
[15:57:02.672] iteration 8010: loss: 0.094862, loss_s1: 0.075359, loss_fp: 0.001504, loss_freq: 0.063765
[15:57:03.299] iteration 8011: loss: 0.069080, loss_s1: 0.030693, loss_fp: 0.002778, loss_freq: 0.006404
[15:57:03.928] iteration 8012: loss: 0.082067, loss_s1: 0.060967, loss_fp: 0.007216, loss_freq: 0.042185
[15:57:04.554] iteration 8013: loss: 0.078737, loss_s1: 0.058588, loss_fp: 0.001843, loss_freq: 0.014353
[15:57:05.182] iteration 8014: loss: 0.094430, loss_s1: 0.041935, loss_fp: 0.003089, loss_freq: 0.076581
[15:57:05.807] iteration 8015: loss: 0.064223, loss_s1: 0.017592, loss_fp: 0.001298, loss_freq: 0.011702
[15:57:06.433] iteration 8016: loss: 0.080069, loss_s1: 0.041221, loss_fp: 0.000878, loss_freq: 0.025998
[15:57:07.106] iteration 8017: loss: 0.224441, loss_s1: 0.129138, loss_fp: 0.007890, loss_freq: 0.158468
[15:57:07.735] iteration 8018: loss: 0.079264, loss_s1: 0.041942, loss_fp: 0.000591, loss_freq: 0.011031
[15:57:08.390] iteration 8019: loss: 0.048108, loss_s1: 0.029619, loss_fp: 0.001005, loss_freq: 0.016970
[15:57:09.066] iteration 8020: loss: 0.097294, loss_s1: 0.053350, loss_fp: 0.007527, loss_freq: 0.091508
[15:57:09.734] iteration 8021: loss: 0.097229, loss_s1: 0.040637, loss_fp: 0.002992, loss_freq: 0.042750
[15:57:10.400] iteration 8022: loss: 0.063308, loss_s1: 0.037772, loss_fp: 0.001521, loss_freq: 0.007177
[15:57:11.065] iteration 8023: loss: 0.092852, loss_s1: 0.093483, loss_fp: 0.000776, loss_freq: 0.016117
[15:57:11.729] iteration 8024: loss: 0.085202, loss_s1: 0.071722, loss_fp: 0.002237, loss_freq: 0.045447
[15:57:12.390] iteration 8025: loss: 0.068187, loss_s1: 0.037335, loss_fp: 0.007783, loss_freq: 0.021979
[15:57:13.075] iteration 8026: loss: 0.070185, loss_s1: 0.028762, loss_fp: 0.000496, loss_freq: 0.050698
[15:57:13.738] iteration 8027: loss: 0.095264, loss_s1: 0.055775, loss_fp: 0.003861, loss_freq: 0.058765
[15:57:14.408] iteration 8028: loss: 0.078644, loss_s1: 0.040252, loss_fp: 0.002724, loss_freq: 0.031185
[15:57:15.079] iteration 8029: loss: 0.111541, loss_s1: 0.052321, loss_fp: 0.004690, loss_freq: 0.042030
[15:57:15.723] iteration 8030: loss: 0.094968, loss_s1: 0.083611, loss_fp: 0.006691, loss_freq: 0.033085
[15:57:16.389] iteration 8031: loss: 0.120632, loss_s1: 0.065242, loss_fp: 0.014092, loss_freq: 0.039028
[15:57:17.043] iteration 8032: loss: 0.090128, loss_s1: 0.053001, loss_fp: 0.004205, loss_freq: 0.035496
[15:57:17.676] iteration 8033: loss: 0.112920, loss_s1: 0.106582, loss_fp: 0.004308, loss_freq: 0.039414
[15:57:18.315] iteration 8034: loss: 0.080953, loss_s1: 0.096575, loss_fp: 0.002121, loss_freq: 0.019072
[15:57:18.951] iteration 8035: loss: 0.084963, loss_s1: 0.039242, loss_fp: 0.003011, loss_freq: 0.030338
[15:57:19.588] iteration 8036: loss: 0.093722, loss_s1: 0.075635, loss_fp: 0.002807, loss_freq: 0.061483
[15:57:20.221] iteration 8037: loss: 0.088148, loss_s1: 0.086501, loss_fp: 0.002499, loss_freq: 0.031573
[15:57:20.852] iteration 8038: loss: 0.110058, loss_s1: 0.048129, loss_fp: 0.007302, loss_freq: 0.068173
[15:57:21.486] iteration 8039: loss: 0.092578, loss_s1: 0.073124, loss_fp: 0.001484, loss_freq: 0.048895
[15:57:22.116] iteration 8040: loss: 0.084962, loss_s1: 0.047900, loss_fp: 0.003026, loss_freq: 0.031331
[15:57:22.747] iteration 8041: loss: 0.107753, loss_s1: 0.103960, loss_fp: 0.002626, loss_freq: 0.065190
[15:57:23.377] iteration 8042: loss: 0.065015, loss_s1: 0.044330, loss_fp: 0.002041, loss_freq: 0.015756
[15:57:24.003] iteration 8043: loss: 0.105541, loss_s1: 0.057590, loss_fp: 0.002835, loss_freq: 0.033294
[15:57:24.631] iteration 8044: loss: 0.049646, loss_s1: 0.017816, loss_fp: 0.001315, loss_freq: 0.004914
[15:57:25.261] iteration 8045: loss: 0.102619, loss_s1: 0.108424, loss_fp: 0.000633, loss_freq: 0.030373
[15:57:25.889] iteration 8046: loss: 0.078248, loss_s1: 0.024593, loss_fp: 0.002007, loss_freq: 0.015231
[15:57:26.523] iteration 8047: loss: 0.132238, loss_s1: 0.062019, loss_fp: 0.005700, loss_freq: 0.059722
[15:57:27.149] iteration 8048: loss: 0.074543, loss_s1: 0.040472, loss_fp: 0.013440, loss_freq: 0.038684
[15:57:27.775] iteration 8049: loss: 0.089406, loss_s1: 0.062156, loss_fp: 0.002635, loss_freq: 0.023897
[15:57:28.397] iteration 8050: loss: 0.096673, loss_s1: 0.065897, loss_fp: 0.005150, loss_freq: 0.050050
[15:57:29.401] iteration 8051: loss: 0.067162, loss_s1: 0.049315, loss_fp: 0.001478, loss_freq: 0.032471
[15:57:30.028] iteration 8052: loss: 0.117470, loss_s1: 0.103187, loss_fp: 0.002977, loss_freq: 0.045313
[15:57:30.657] iteration 8053: loss: 0.074479, loss_s1: 0.049335, loss_fp: 0.000267, loss_freq: 0.016968
[15:57:31.397] iteration 8054: loss: 0.064926, loss_s1: 0.010606, loss_fp: 0.001331, loss_freq: 0.012049
[15:57:32.042] iteration 8055: loss: 0.114736, loss_s1: 0.080905, loss_fp: 0.015973, loss_freq: 0.043031
[15:57:32.686] iteration 8056: loss: 0.186465, loss_s1: 0.095017, loss_fp: 0.009950, loss_freq: 0.137355
[15:57:33.329] iteration 8057: loss: 0.065305, loss_s1: 0.060751, loss_fp: 0.003701, loss_freq: 0.013271
[15:57:33.954] iteration 8058: loss: 0.077829, loss_s1: 0.050894, loss_fp: 0.004100, loss_freq: 0.053370
[15:57:34.583] iteration 8059: loss: 0.078180, loss_s1: 0.070748, loss_fp: 0.008719, loss_freq: 0.024097
[15:57:35.210] iteration 8060: loss: 0.095508, loss_s1: 0.099314, loss_fp: 0.005265, loss_freq: 0.031468
[15:57:35.844] iteration 8061: loss: 0.063896, loss_s1: 0.037936, loss_fp: 0.001222, loss_freq: 0.014604
[15:57:36.473] iteration 8062: loss: 0.139096, loss_s1: 0.135044, loss_fp: 0.000513, loss_freq: 0.081024
[15:57:37.094] iteration 8063: loss: 0.083582, loss_s1: 0.065963, loss_fp: 0.007722, loss_freq: 0.036320
[15:57:37.727] iteration 8064: loss: 0.085693, loss_s1: 0.046682, loss_fp: 0.000946, loss_freq: 0.042705
[15:57:38.352] iteration 8065: loss: 0.051000, loss_s1: 0.031190, loss_fp: 0.001024, loss_freq: 0.020100
[15:57:38.978] iteration 8066: loss: 0.078000, loss_s1: 0.059812, loss_fp: 0.004701, loss_freq: 0.033604
[15:57:39.608] iteration 8067: loss: 0.090427, loss_s1: 0.086896, loss_fp: 0.005001, loss_freq: 0.013973
[15:57:40.232] iteration 8068: loss: 0.064894, loss_s1: 0.028539, loss_fp: 0.005071, loss_freq: 0.021153
[15:57:40.860] iteration 8069: loss: 0.102848, loss_s1: 0.036118, loss_fp: 0.007589, loss_freq: 0.024677
[15:57:41.492] iteration 8070: loss: 0.114115, loss_s1: 0.076959, loss_fp: 0.003309, loss_freq: 0.038333
[15:57:42.112] iteration 8071: loss: 0.046345, loss_s1: 0.010164, loss_fp: 0.001507, loss_freq: 0.010091
[15:57:42.743] iteration 8072: loss: 0.101648, loss_s1: 0.042297, loss_fp: 0.008461, loss_freq: 0.033126
[15:57:43.372] iteration 8073: loss: 0.095562, loss_s1: 0.035429, loss_fp: 0.001252, loss_freq: 0.018998
[15:57:43.995] iteration 8074: loss: 0.250459, loss_s1: 0.229203, loss_fp: 0.004943, loss_freq: 0.185854
[15:57:44.620] iteration 8075: loss: 0.055770, loss_s1: 0.034046, loss_fp: 0.002842, loss_freq: 0.027971
[15:57:45.246] iteration 8076: loss: 0.066411, loss_s1: 0.048216, loss_fp: 0.002551, loss_freq: 0.033003
[15:57:45.878] iteration 8077: loss: 0.081752, loss_s1: 0.035814, loss_fp: 0.000937, loss_freq: 0.071819
[15:57:46.497] iteration 8078: loss: 0.105762, loss_s1: 0.084356, loss_fp: 0.014620, loss_freq: 0.046882
[15:57:47.120] iteration 8079: loss: 0.080529, loss_s1: 0.040797, loss_fp: 0.001527, loss_freq: 0.054951
[15:57:47.751] iteration 8080: loss: 0.070073, loss_s1: 0.036220, loss_fp: 0.003905, loss_freq: 0.025134
[15:57:48.375] iteration 8081: loss: 0.064394, loss_s1: 0.051870, loss_fp: 0.002877, loss_freq: 0.026175
[15:57:48.997] iteration 8082: loss: 0.114628, loss_s1: 0.060791, loss_fp: 0.001437, loss_freq: 0.033497
[15:57:49.627] iteration 8083: loss: 0.072423, loss_s1: 0.061378, loss_fp: 0.001524, loss_freq: 0.036754
[15:57:50.248] iteration 8084: loss: 0.063852, loss_s1: 0.025360, loss_fp: 0.013802, loss_freq: 0.018632
[15:57:50.874] iteration 8085: loss: 0.081208, loss_s1: 0.041893, loss_fp: 0.002523, loss_freq: 0.016849
[15:57:51.500] iteration 8086: loss: 0.054787, loss_s1: 0.025505, loss_fp: 0.002116, loss_freq: 0.020477
[15:57:52.124] iteration 8087: loss: 0.143451, loss_s1: 0.099033, loss_fp: 0.020292, loss_freq: 0.068653
[15:57:52.748] iteration 8088: loss: 0.075909, loss_s1: 0.045017, loss_fp: 0.004768, loss_freq: 0.018175
[15:57:53.371] iteration 8089: loss: 0.149600, loss_s1: 0.111234, loss_fp: 0.001569, loss_freq: 0.100801
[15:57:54.025] iteration 8090: loss: 0.094572, loss_s1: 0.094687, loss_fp: 0.002431, loss_freq: 0.026634
[15:57:54.648] iteration 8091: loss: 0.075000, loss_s1: 0.030685, loss_fp: 0.001085, loss_freq: 0.023874
[15:57:55.271] iteration 8092: loss: 0.124939, loss_s1: 0.097196, loss_fp: 0.005978, loss_freq: 0.050721
[15:57:55.894] iteration 8093: loss: 0.086034, loss_s1: 0.067408, loss_fp: 0.003196, loss_freq: 0.042755
[15:57:56.518] iteration 8094: loss: 0.068051, loss_s1: 0.045432, loss_fp: 0.002356, loss_freq: 0.023430
[15:57:57.146] iteration 8095: loss: 0.080984, loss_s1: 0.032033, loss_fp: 0.001886, loss_freq: 0.049011
[15:57:57.778] iteration 8096: loss: 0.079182, loss_s1: 0.039951, loss_fp: 0.002179, loss_freq: 0.017612
[15:57:58.405] iteration 8097: loss: 0.089875, loss_s1: 0.046167, loss_fp: 0.000969, loss_freq: 0.009013
[15:57:59.032] iteration 8098: loss: 0.080440, loss_s1: 0.071472, loss_fp: 0.002702, loss_freq: 0.032686
[15:57:59.654] iteration 8099: loss: 0.077256, loss_s1: 0.046045, loss_fp: 0.000912, loss_freq: 0.016543
[15:58:00.279] iteration 8100: loss: 0.072702, loss_s1: 0.035362, loss_fp: 0.000857, loss_freq: 0.044371
[15:58:00.904] iteration 8101: loss: 0.073677, loss_s1: 0.064843, loss_fp: 0.002374, loss_freq: 0.030744
[15:58:01.526] iteration 8102: loss: 0.103886, loss_s1: 0.033019, loss_fp: 0.002104, loss_freq: 0.022413
[15:58:02.158] iteration 8103: loss: 0.100667, loss_s1: 0.069548, loss_fp: 0.002257, loss_freq: 0.050163
[15:58:02.783] iteration 8104: loss: 0.105145, loss_s1: 0.069452, loss_fp: 0.006035, loss_freq: 0.035488
[15:58:03.405] iteration 8105: loss: 0.122006, loss_s1: 0.049430, loss_fp: 0.001503, loss_freq: 0.036355
[15:58:04.036] iteration 8106: loss: 0.108775, loss_s1: 0.125736, loss_fp: 0.001171, loss_freq: 0.025740
[15:58:04.665] iteration 8107: loss: 0.072270, loss_s1: 0.029954, loss_fp: 0.001030, loss_freq: 0.002914
[15:58:05.292] iteration 8108: loss: 0.113983, loss_s1: 0.052944, loss_fp: 0.001015, loss_freq: 0.070525
[15:58:05.927] iteration 8109: loss: 0.048314, loss_s1: 0.027770, loss_fp: 0.000854, loss_freq: 0.009758
[15:58:06.552] iteration 8110: loss: 0.047892, loss_s1: 0.026683, loss_fp: 0.000808, loss_freq: 0.025806
[15:58:07.177] iteration 8111: loss: 0.078152, loss_s1: 0.049411, loss_fp: 0.001837, loss_freq: 0.020912
[15:58:07.806] iteration 8112: loss: 0.063141, loss_s1: 0.056215, loss_fp: 0.005311, loss_freq: 0.018955
[15:58:08.432] iteration 8113: loss: 0.059549, loss_s1: 0.024757, loss_fp: 0.001052, loss_freq: 0.017789
[15:58:09.061] iteration 8114: loss: 0.098044, loss_s1: 0.085919, loss_fp: 0.002912, loss_freq: 0.019427
[15:58:09.684] iteration 8115: loss: 0.074991, loss_s1: 0.059276, loss_fp: 0.000683, loss_freq: 0.008600
[15:58:10.309] iteration 8116: loss: 0.106668, loss_s1: 0.089505, loss_fp: 0.002050, loss_freq: 0.060587
[15:58:10.932] iteration 8117: loss: 0.082823, loss_s1: 0.032145, loss_fp: 0.006267, loss_freq: 0.030436
[15:58:11.557] iteration 8118: loss: 0.070763, loss_s1: 0.051055, loss_fp: 0.005162, loss_freq: 0.033968
[15:58:12.180] iteration 8119: loss: 0.054331, loss_s1: 0.027010, loss_fp: 0.011947, loss_freq: 0.009776
[15:58:12.802] iteration 8120: loss: 0.085940, loss_s1: 0.040518, loss_fp: 0.006221, loss_freq: 0.030576
[15:58:13.426] iteration 8121: loss: 0.122724, loss_s1: 0.075435, loss_fp: 0.010070, loss_freq: 0.058405
[15:58:14.051] iteration 8122: loss: 0.106063, loss_s1: 0.040298, loss_fp: 0.002969, loss_freq: 0.047552
[15:58:14.676] iteration 8123: loss: 0.093599, loss_s1: 0.034288, loss_fp: 0.005566, loss_freq: 0.053511
[15:58:15.300] iteration 8124: loss: 0.065008, loss_s1: 0.032544, loss_fp: 0.002442, loss_freq: 0.024797
[15:58:15.929] iteration 8125: loss: 0.106700, loss_s1: 0.104332, loss_fp: 0.014657, loss_freq: 0.035881
[15:58:16.554] iteration 8126: loss: 0.107151, loss_s1: 0.095074, loss_fp: 0.001669, loss_freq: 0.020260
[15:58:17.175] iteration 8127: loss: 0.101986, loss_s1: 0.035873, loss_fp: 0.002958, loss_freq: 0.061710
[15:58:17.798] iteration 8128: loss: 0.052323, loss_s1: 0.032984, loss_fp: 0.002348, loss_freq: 0.022377
[15:58:18.421] iteration 8129: loss: 0.068230, loss_s1: 0.048740, loss_fp: 0.001447, loss_freq: 0.025892
[15:58:19.043] iteration 8130: loss: 0.109257, loss_s1: 0.111688, loss_fp: 0.001220, loss_freq: 0.045997
[15:58:19.666] iteration 8131: loss: 0.090797, loss_s1: 0.053103, loss_fp: 0.004813, loss_freq: 0.012438
[15:58:20.286] iteration 8132: loss: 0.089170, loss_s1: 0.057064, loss_fp: 0.006673, loss_freq: 0.063141
[15:58:20.910] iteration 8133: loss: 0.119532, loss_s1: 0.094531, loss_fp: 0.008249, loss_freq: 0.084937
[15:58:21.531] iteration 8134: loss: 0.076057, loss_s1: 0.036405, loss_fp: 0.004299, loss_freq: 0.023243
[15:58:22.153] iteration 8135: loss: 0.099104, loss_s1: 0.088375, loss_fp: 0.001871, loss_freq: 0.053632
[15:58:22.777] iteration 8136: loss: 0.058651, loss_s1: 0.045276, loss_fp: 0.003572, loss_freq: 0.013883
[15:58:23.401] iteration 8137: loss: 0.084473, loss_s1: 0.060301, loss_fp: 0.002971, loss_freq: 0.024270
[15:58:24.023] iteration 8138: loss: 0.052560, loss_s1: 0.021150, loss_fp: 0.004865, loss_freq: 0.007038
[15:58:24.648] iteration 8139: loss: 0.122159, loss_s1: 0.113035, loss_fp: 0.011708, loss_freq: 0.054224
[15:58:25.275] iteration 8140: loss: 0.096944, loss_s1: 0.064149, loss_fp: 0.003357, loss_freq: 0.038428
[15:58:25.899] iteration 8141: loss: 0.095258, loss_s1: 0.079699, loss_fp: 0.002877, loss_freq: 0.013412
[15:58:26.520] iteration 8142: loss: 0.091216, loss_s1: 0.041898, loss_fp: 0.001240, loss_freq: 0.014811
[15:58:27.149] iteration 8143: loss: 0.075409, loss_s1: 0.031714, loss_fp: 0.002224, loss_freq: 0.016220
[15:58:27.771] iteration 8144: loss: 0.079321, loss_s1: 0.052728, loss_fp: 0.001875, loss_freq: 0.021739
[15:58:28.394] iteration 8145: loss: 0.048345, loss_s1: 0.026140, loss_fp: 0.009500, loss_freq: 0.019378
[15:58:29.052] iteration 8146: loss: 0.082957, loss_s1: 0.070062, loss_fp: 0.003233, loss_freq: 0.037085
[15:58:29.682] iteration 8147: loss: 0.089640, loss_s1: 0.064699, loss_fp: 0.001132, loss_freq: 0.040752
[15:58:30.312] iteration 8148: loss: 0.060691, loss_s1: 0.013070, loss_fp: 0.002030, loss_freq: 0.033330
[15:58:30.937] iteration 8149: loss: 0.077334, loss_s1: 0.031100, loss_fp: 0.011580, loss_freq: 0.007935
[15:58:31.562] iteration 8150: loss: 0.048101, loss_s1: 0.018600, loss_fp: 0.005645, loss_freq: 0.026663
[15:58:32.186] iteration 8151: loss: 0.070236, loss_s1: 0.077045, loss_fp: 0.001714, loss_freq: 0.009653
[15:58:32.809] iteration 8152: loss: 0.098085, loss_s1: 0.055877, loss_fp: 0.008826, loss_freq: 0.059108
[15:58:33.437] iteration 8153: loss: 0.148234, loss_s1: 0.116869, loss_fp: 0.009946, loss_freq: 0.080406
[15:58:34.062] iteration 8154: loss: 0.114132, loss_s1: 0.103325, loss_fp: 0.004592, loss_freq: 0.057998
[15:58:34.688] iteration 8155: loss: 0.110252, loss_s1: 0.071213, loss_fp: 0.004287, loss_freq: 0.026746
[15:58:35.310] iteration 8156: loss: 0.103342, loss_s1: 0.080645, loss_fp: 0.004942, loss_freq: 0.036883
[15:58:35.940] iteration 8157: loss: 0.056299, loss_s1: 0.022768, loss_fp: 0.000764, loss_freq: 0.010398
[15:58:36.565] iteration 8158: loss: 0.138887, loss_s1: 0.132868, loss_fp: 0.022115, loss_freq: 0.050322
[15:58:37.189] iteration 8159: loss: 0.143009, loss_s1: 0.083532, loss_fp: 0.005069, loss_freq: 0.117295
[15:58:37.808] iteration 8160: loss: 0.071135, loss_s1: 0.032239, loss_fp: 0.001176, loss_freq: 0.021972
[15:58:38.433] iteration 8161: loss: 0.103705, loss_s1: 0.035720, loss_fp: 0.005755, loss_freq: 0.026095
[15:58:39.054] iteration 8162: loss: 0.093560, loss_s1: 0.061331, loss_fp: 0.004899, loss_freq: 0.066347
[15:58:39.674] iteration 8163: loss: 0.136856, loss_s1: 0.077342, loss_fp: 0.005171, loss_freq: 0.076734
[15:58:40.297] iteration 8164: loss: 0.087940, loss_s1: 0.043439, loss_fp: 0.002006, loss_freq: 0.042992
[15:58:40.920] iteration 8165: loss: 0.060165, loss_s1: 0.041262, loss_fp: 0.002018, loss_freq: 0.008944
[15:58:41.543] iteration 8166: loss: 0.122262, loss_s1: 0.113773, loss_fp: 0.009355, loss_freq: 0.035711
[15:58:42.170] iteration 8167: loss: 0.098822, loss_s1: 0.077272, loss_fp: 0.009466, loss_freq: 0.024078
[15:58:42.792] iteration 8168: loss: 0.090227, loss_s1: 0.073309, loss_fp: 0.005493, loss_freq: 0.020164
[15:58:43.415] iteration 8169: loss: 0.080593, loss_s1: 0.083318, loss_fp: 0.001373, loss_freq: 0.017597
[15:58:44.035] iteration 8170: loss: 0.123158, loss_s1: 0.054093, loss_fp: 0.001574, loss_freq: 0.129047
[15:58:44.655] iteration 8171: loss: 0.093004, loss_s1: 0.030785, loss_fp: 0.000731, loss_freq: 0.107677
[15:58:45.278] iteration 8172: loss: 0.108727, loss_s1: 0.075236, loss_fp: 0.001471, loss_freq: 0.042631
[15:58:45.904] iteration 8173: loss: 0.087021, loss_s1: 0.054333, loss_fp: 0.008558, loss_freq: 0.024090
[15:58:46.533] iteration 8174: loss: 0.097966, loss_s1: 0.056667, loss_fp: 0.009256, loss_freq: 0.057052
[15:58:47.158] iteration 8175: loss: 0.085798, loss_s1: 0.023875, loss_fp: 0.001116, loss_freq: 0.050658
[15:58:47.781] iteration 8176: loss: 0.086300, loss_s1: 0.036875, loss_fp: 0.000283, loss_freq: 0.039606
[15:58:48.402] iteration 8177: loss: 0.066547, loss_s1: 0.037822, loss_fp: 0.000607, loss_freq: 0.014786
[15:58:49.028] iteration 8178: loss: 0.172756, loss_s1: 0.088954, loss_fp: 0.008870, loss_freq: 0.140163
[15:58:49.651] iteration 8179: loss: 0.069089, loss_s1: 0.079739, loss_fp: 0.000463, loss_freq: 0.016722
[15:58:50.276] iteration 8180: loss: 0.092396, loss_s1: 0.048565, loss_fp: 0.001564, loss_freq: 0.019937
[15:58:50.899] iteration 8181: loss: 0.072076, loss_s1: 0.022754, loss_fp: 0.002615, loss_freq: 0.065952
[15:58:51.520] iteration 8182: loss: 0.111468, loss_s1: 0.089705, loss_fp: 0.000765, loss_freq: 0.057503
[15:58:52.143] iteration 8183: loss: 0.139544, loss_s1: 0.115788, loss_fp: 0.007861, loss_freq: 0.025173
[15:58:52.764] iteration 8184: loss: 0.074579, loss_s1: 0.068034, loss_fp: 0.009205, loss_freq: 0.028085
[15:58:53.390] iteration 8185: loss: 0.103951, loss_s1: 0.041784, loss_fp: 0.003588, loss_freq: 0.112775
[15:58:54.013] iteration 8186: loss: 0.063542, loss_s1: 0.042861, loss_fp: 0.003354, loss_freq: 0.027304
[15:58:54.636] iteration 8187: loss: 0.075556, loss_s1: 0.026884, loss_fp: 0.002324, loss_freq: 0.048319
[15:58:55.260] iteration 8188: loss: 0.062793, loss_s1: 0.039839, loss_fp: 0.003418, loss_freq: 0.032396
[15:58:55.879] iteration 8189: loss: 0.126382, loss_s1: 0.067568, loss_fp: 0.002132, loss_freq: 0.024205
[15:58:56.503] iteration 8190: loss: 0.190184, loss_s1: 0.152869, loss_fp: 0.003379, loss_freq: 0.084500
[15:58:57.130] iteration 8191: loss: 0.072316, loss_s1: 0.052700, loss_fp: 0.004330, loss_freq: 0.023412
[15:58:57.749] iteration 8192: loss: 0.063468, loss_s1: 0.031701, loss_fp: 0.001478, loss_freq: 0.028072
[15:58:58.374] iteration 8193: loss: 0.139054, loss_s1: 0.120544, loss_fp: 0.001674, loss_freq: 0.035000
[15:58:58.999] iteration 8194: loss: 0.145622, loss_s1: 0.112332, loss_fp: 0.002095, loss_freq: 0.065585
[15:58:59.643] iteration 8195: loss: 0.044768, loss_s1: 0.028858, loss_fp: 0.000881, loss_freq: 0.015782
[15:59:00.266] iteration 8196: loss: 0.084913, loss_s1: 0.022798, loss_fp: 0.003690, loss_freq: 0.035277
[15:59:00.927] iteration 8197: loss: 0.118615, loss_s1: 0.078782, loss_fp: 0.005765, loss_freq: 0.092423
[15:59:01.585] iteration 8198: loss: 0.075901, loss_s1: 0.064878, loss_fp: 0.002993, loss_freq: 0.021026
[15:59:02.209] iteration 8199: loss: 0.087187, loss_s1: 0.033768, loss_fp: 0.010722, loss_freq: 0.041890
[15:59:02.841] iteration 8200: loss: 0.085860, loss_s1: 0.047256, loss_fp: 0.007486, loss_freq: 0.032355
[15:59:06.079] iteration 8200 : mean_dice : 0.672801
[15:59:06.722] iteration 8201: loss: 0.084744, loss_s1: 0.045987, loss_fp: 0.003636, loss_freq: 0.015303
[15:59:07.350] iteration 8202: loss: 0.099956, loss_s1: 0.046991, loss_fp: 0.024214, loss_freq: 0.058238
[15:59:07.977] iteration 8203: loss: 0.065261, loss_s1: 0.054070, loss_fp: 0.005879, loss_freq: 0.018412
[15:59:08.605] iteration 8204: loss: 0.084516, loss_s1: 0.048979, loss_fp: 0.001810, loss_freq: 0.025233
[15:59:09.227] iteration 8205: loss: 0.056287, loss_s1: 0.043481, loss_fp: 0.000701, loss_freq: 0.007726
[15:59:09.852] iteration 8206: loss: 0.070110, loss_s1: 0.053702, loss_fp: 0.001804, loss_freq: 0.027984
[15:59:10.474] iteration 8207: loss: 0.092521, loss_s1: 0.029651, loss_fp: 0.010609, loss_freq: 0.022974
[15:59:11.101] iteration 8208: loss: 0.076610, loss_s1: 0.024599, loss_fp: 0.002827, loss_freq: 0.019170
[15:59:11.726] iteration 8209: loss: 0.110171, loss_s1: 0.092794, loss_fp: 0.004262, loss_freq: 0.051664
[15:59:12.354] iteration 8210: loss: 0.090915, loss_s1: 0.045006, loss_fp: 0.001047, loss_freq: 0.015508
[15:59:12.976] iteration 8211: loss: 0.100159, loss_s1: 0.059966, loss_fp: 0.046653, loss_freq: 0.024826
[15:59:13.936] iteration 8212: loss: 0.085236, loss_s1: 0.069102, loss_fp: 0.000334, loss_freq: 0.033183
[15:59:14.565] iteration 8213: loss: 0.079559, loss_s1: 0.037087, loss_fp: 0.015279, loss_freq: 0.039608
[15:59:15.191] iteration 8214: loss: 0.078942, loss_s1: 0.034693, loss_fp: 0.000838, loss_freq: 0.028822
[15:59:15.815] iteration 8215: loss: 0.085821, loss_s1: 0.060796, loss_fp: 0.001008, loss_freq: 0.020382
[15:59:16.439] iteration 8216: loss: 0.065162, loss_s1: 0.053513, loss_fp: 0.004803, loss_freq: 0.016961
[15:59:17.066] iteration 8217: loss: 0.131159, loss_s1: 0.104235, loss_fp: 0.001471, loss_freq: 0.031783
[15:59:17.695] iteration 8218: loss: 0.080475, loss_s1: 0.080062, loss_fp: 0.005361, loss_freq: 0.031259
[15:59:18.321] iteration 8219: loss: 0.082547, loss_s1: 0.032544, loss_fp: 0.001253, loss_freq: 0.044218
[15:59:18.946] iteration 8220: loss: 0.057762, loss_s1: 0.039977, loss_fp: 0.005388, loss_freq: 0.010603
[15:59:19.574] iteration 8221: loss: 0.082961, loss_s1: 0.041897, loss_fp: 0.005681, loss_freq: 0.028137
[15:59:20.199] iteration 8222: loss: 0.056708, loss_s1: 0.024841, loss_fp: 0.001729, loss_freq: 0.019099
[15:59:20.821] iteration 8223: loss: 0.078230, loss_s1: 0.045043, loss_fp: 0.004505, loss_freq: 0.055980
[15:59:21.445] iteration 8224: loss: 0.110059, loss_s1: 0.076310, loss_fp: 0.018429, loss_freq: 0.072194
[15:59:22.071] iteration 8225: loss: 0.097330, loss_s1: 0.018579, loss_fp: 0.005716, loss_freq: 0.049944
[15:59:22.696] iteration 8226: loss: 0.047181, loss_s1: 0.026203, loss_fp: 0.000583, loss_freq: 0.014542
[15:59:23.319] iteration 8227: loss: 0.114016, loss_s1: 0.053660, loss_fp: 0.005115, loss_freq: 0.100405
[15:59:23.943] iteration 8228: loss: 0.070880, loss_s1: 0.040392, loss_fp: 0.005402, loss_freq: 0.020904
[15:59:24.570] iteration 8229: loss: 0.089016, loss_s1: 0.059568, loss_fp: 0.004806, loss_freq: 0.047319
[15:59:25.198] iteration 8230: loss: 0.059745, loss_s1: 0.037325, loss_fp: 0.000744, loss_freq: 0.026639
[15:59:25.831] iteration 8231: loss: 0.096389, loss_s1: 0.081314, loss_fp: 0.004025, loss_freq: 0.022079
[15:59:26.456] iteration 8232: loss: 0.057145, loss_s1: 0.034488, loss_fp: 0.002789, loss_freq: 0.019700
[15:59:27.088] iteration 8233: loss: 0.066354, loss_s1: 0.032337, loss_fp: 0.000587, loss_freq: 0.017038
[15:59:27.713] iteration 8234: loss: 0.120472, loss_s1: 0.098128, loss_fp: 0.001759, loss_freq: 0.033167
[15:59:28.336] iteration 8235: loss: 0.171901, loss_s1: 0.119429, loss_fp: 0.012812, loss_freq: 0.148839
[15:59:28.964] iteration 8236: loss: 0.058632, loss_s1: 0.035361, loss_fp: 0.003078, loss_freq: 0.026505
[15:59:29.587] iteration 8237: loss: 0.097680, loss_s1: 0.057589, loss_fp: 0.009104, loss_freq: 0.078735
[15:59:30.215] iteration 8238: loss: 0.050732, loss_s1: 0.020237, loss_fp: 0.000352, loss_freq: 0.013827
[15:59:30.844] iteration 8239: loss: 0.107414, loss_s1: 0.073404, loss_fp: 0.008414, loss_freq: 0.057212
[15:59:31.471] iteration 8240: loss: 0.070403, loss_s1: 0.059107, loss_fp: 0.003216, loss_freq: 0.037737
[15:59:32.099] iteration 8241: loss: 0.064215, loss_s1: 0.023226, loss_fp: 0.001584, loss_freq: 0.013956
[15:59:32.723] iteration 8242: loss: 0.073495, loss_s1: 0.067906, loss_fp: 0.004930, loss_freq: 0.028002
[15:59:33.351] iteration 8243: loss: 0.060402, loss_s1: 0.035394, loss_fp: 0.003205, loss_freq: 0.008274
[15:59:33.976] iteration 8244: loss: 0.047035, loss_s1: 0.019531, loss_fp: 0.001879, loss_freq: 0.029433
[15:59:34.732] iteration 8245: loss: 0.064647, loss_s1: 0.048597, loss_fp: 0.001163, loss_freq: 0.023193
[15:59:35.395] iteration 8246: loss: 0.147588, loss_s1: 0.047251, loss_fp: 0.008157, loss_freq: 0.013441
[15:59:36.076] iteration 8247: loss: 0.070220, loss_s1: 0.050827, loss_fp: 0.004494, loss_freq: 0.013532
[15:59:36.745] iteration 8248: loss: 0.150599, loss_s1: 0.130216, loss_fp: 0.005343, loss_freq: 0.059452
[15:59:37.402] iteration 8249: loss: 0.127905, loss_s1: 0.084719, loss_fp: 0.018282, loss_freq: 0.051933
[15:59:38.074] iteration 8250: loss: 0.133685, loss_s1: 0.103109, loss_fp: 0.003290, loss_freq: 0.074011
[15:59:38.726] iteration 8251: loss: 0.073195, loss_s1: 0.031297, loss_fp: 0.007373, loss_freq: 0.036422
[15:59:39.379] iteration 8252: loss: 0.066412, loss_s1: 0.019210, loss_fp: 0.000396, loss_freq: 0.021790
[15:59:40.003] iteration 8253: loss: 0.128949, loss_s1: 0.132745, loss_fp: 0.004916, loss_freq: 0.075166
[15:59:40.630] iteration 8254: loss: 0.099413, loss_s1: 0.054788, loss_fp: 0.006223, loss_freq: 0.068121
[15:59:41.265] iteration 8255: loss: 0.081957, loss_s1: 0.081811, loss_fp: 0.005224, loss_freq: 0.030593
[15:59:41.885] iteration 8256: loss: 0.081040, loss_s1: 0.067860, loss_fp: 0.002477, loss_freq: 0.036236
[15:59:42.509] iteration 8257: loss: 0.086253, loss_s1: 0.065764, loss_fp: 0.003693, loss_freq: 0.023812
[15:59:43.136] iteration 8258: loss: 0.046349, loss_s1: 0.031822, loss_fp: 0.000762, loss_freq: 0.007059
[15:59:43.759] iteration 8259: loss: 0.081904, loss_s1: 0.079966, loss_fp: 0.004344, loss_freq: 0.030162
[15:59:44.379] iteration 8260: loss: 0.052405, loss_s1: 0.029592, loss_fp: 0.001694, loss_freq: 0.006076
[15:59:44.999] iteration 8261: loss: 0.073115, loss_s1: 0.056859, loss_fp: 0.004385, loss_freq: 0.028384
[15:59:45.627] iteration 8262: loss: 0.051322, loss_s1: 0.019669, loss_fp: 0.001852, loss_freq: 0.030671
[15:59:46.252] iteration 8263: loss: 0.077041, loss_s1: 0.024634, loss_fp: 0.001622, loss_freq: 0.032969
[15:59:46.877] iteration 8264: loss: 0.082695, loss_s1: 0.037144, loss_fp: 0.003815, loss_freq: 0.064019
[15:59:47.503] iteration 8265: loss: 0.067686, loss_s1: 0.042163, loss_fp: 0.002768, loss_freq: 0.022432
[15:59:48.129] iteration 8266: loss: 0.071946, loss_s1: 0.053139, loss_fp: 0.000329, loss_freq: 0.014863
[15:59:48.753] iteration 8267: loss: 0.077223, loss_s1: 0.051628, loss_fp: 0.001859, loss_freq: 0.013002
[15:59:49.402] iteration 8268: loss: 0.077672, loss_s1: 0.049983, loss_fp: 0.008671, loss_freq: 0.008611
[15:59:50.063] iteration 8269: loss: 0.073294, loss_s1: 0.036633, loss_fp: 0.004607, loss_freq: 0.023089
[15:59:50.693] iteration 8270: loss: 0.050273, loss_s1: 0.027139, loss_fp: 0.001998, loss_freq: 0.009188
[15:59:51.323] iteration 8271: loss: 0.062483, loss_s1: 0.063323, loss_fp: 0.001280, loss_freq: 0.015204
[15:59:51.947] iteration 8272: loss: 0.062257, loss_s1: 0.023880, loss_fp: 0.000957, loss_freq: 0.026420
[15:59:52.569] iteration 8273: loss: 0.099367, loss_s1: 0.116115, loss_fp: 0.003326, loss_freq: 0.013257
[15:59:53.199] iteration 8274: loss: 0.078690, loss_s1: 0.035753, loss_fp: 0.004509, loss_freq: 0.012396
[15:59:53.822] iteration 8275: loss: 0.128337, loss_s1: 0.061891, loss_fp: 0.000690, loss_freq: 0.029292
[15:59:54.443] iteration 8276: loss: 0.066204, loss_s1: 0.031402, loss_fp: 0.003622, loss_freq: 0.008985
[15:59:55.068] iteration 8277: loss: 0.093981, loss_s1: 0.034332, loss_fp: 0.001344, loss_freq: 0.089723
[15:59:55.694] iteration 8278: loss: 0.080956, loss_s1: 0.029847, loss_fp: 0.001440, loss_freq: 0.069180
[15:59:56.320] iteration 8279: loss: 0.085794, loss_s1: 0.072429, loss_fp: 0.003081, loss_freq: 0.047252
[15:59:56.948] iteration 8280: loss: 0.078726, loss_s1: 0.058556, loss_fp: 0.007401, loss_freq: 0.033199
[15:59:57.577] iteration 8281: loss: 0.097140, loss_s1: 0.033648, loss_fp: 0.015757, loss_freq: 0.011925
[15:59:58.202] iteration 8282: loss: 0.086645, loss_s1: 0.086852, loss_fp: 0.003542, loss_freq: 0.027909
[15:59:58.829] iteration 8283: loss: 0.129133, loss_s1: 0.105631, loss_fp: 0.002359, loss_freq: 0.060765
[15:59:59.461] iteration 8284: loss: 0.106582, loss_s1: 0.081079, loss_fp: 0.011186, loss_freq: 0.049569
[16:00:00.090] iteration 8285: loss: 0.058012, loss_s1: 0.037066, loss_fp: 0.002959, loss_freq: 0.012861
[16:00:00.719] iteration 8286: loss: 0.084063, loss_s1: 0.097101, loss_fp: 0.001298, loss_freq: 0.016992
[16:00:01.344] iteration 8287: loss: 0.146520, loss_s1: 0.114368, loss_fp: 0.004827, loss_freq: 0.035328
[16:00:01.967] iteration 8288: loss: 0.089388, loss_s1: 0.052529, loss_fp: 0.003190, loss_freq: 0.044000
[16:00:02.593] iteration 8289: loss: 0.057887, loss_s1: 0.031280, loss_fp: 0.002094, loss_freq: 0.032158
[16:00:03.221] iteration 8290: loss: 0.044351, loss_s1: 0.018530, loss_fp: 0.009191, loss_freq: 0.007530
[16:00:03.848] iteration 8291: loss: 0.048669, loss_s1: 0.021335, loss_fp: 0.000484, loss_freq: 0.022792
[16:00:04.475] iteration 8292: loss: 0.099413, loss_s1: 0.043583, loss_fp: 0.003211, loss_freq: 0.039402
[16:00:05.104] iteration 8293: loss: 0.091084, loss_s1: 0.074486, loss_fp: 0.002733, loss_freq: 0.043659
[16:00:05.731] iteration 8294: loss: 0.168312, loss_s1: 0.210142, loss_fp: 0.013965, loss_freq: 0.068232
[16:00:06.359] iteration 8295: loss: 0.118241, loss_s1: 0.046651, loss_fp: 0.008250, loss_freq: 0.057085
[16:00:06.989] iteration 8296: loss: 0.152114, loss_s1: 0.159663, loss_fp: 0.005427, loss_freq: 0.080445
[16:00:07.615] iteration 8297: loss: 0.049396, loss_s1: 0.013690, loss_fp: 0.003017, loss_freq: 0.019289
[16:00:08.242] iteration 8298: loss: 0.106875, loss_s1: 0.017054, loss_fp: 0.003630, loss_freq: 0.055187
[16:00:08.870] iteration 8299: loss: 0.103368, loss_s1: 0.106703, loss_fp: 0.000733, loss_freq: 0.012883
[16:00:09.501] iteration 8300: loss: 0.097402, loss_s1: 0.034262, loss_fp: 0.003541, loss_freq: 0.066883
[16:00:10.185] iteration 8301: loss: 0.088547, loss_s1: 0.027884, loss_fp: 0.001002, loss_freq: 0.036177
[16:00:10.846] iteration 8302: loss: 0.081366, loss_s1: 0.012728, loss_fp: 0.001994, loss_freq: 0.021816
[16:00:11.506] iteration 8303: loss: 0.096603, loss_s1: 0.120344, loss_fp: 0.000426, loss_freq: 0.005086
[16:00:12.172] iteration 8304: loss: 0.155684, loss_s1: 0.034537, loss_fp: 0.001187, loss_freq: 0.015814
[16:00:12.830] iteration 8305: loss: 0.057711, loss_s1: 0.023740, loss_fp: 0.002260, loss_freq: 0.018817
[16:00:13.457] iteration 8306: loss: 0.074017, loss_s1: 0.047944, loss_fp: 0.000923, loss_freq: 0.063954
[16:00:14.079] iteration 8307: loss: 0.068180, loss_s1: 0.041618, loss_fp: 0.004215, loss_freq: 0.029448
[16:00:14.702] iteration 8308: loss: 0.064276, loss_s1: 0.049898, loss_fp: 0.000417, loss_freq: 0.018817
[16:00:15.330] iteration 8309: loss: 0.077951, loss_s1: 0.033990, loss_fp: 0.000224, loss_freq: 0.024087
[16:00:15.955] iteration 8310: loss: 0.065816, loss_s1: 0.042364, loss_fp: 0.002432, loss_freq: 0.020772
[16:00:16.578] iteration 8311: loss: 0.065260, loss_s1: 0.038737, loss_fp: 0.003029, loss_freq: 0.032482
[16:00:17.203] iteration 8312: loss: 0.064655, loss_s1: 0.066542, loss_fp: 0.001493, loss_freq: 0.012418
[16:00:17.826] iteration 8313: loss: 0.102002, loss_s1: 0.048827, loss_fp: 0.002478, loss_freq: 0.077603
[16:00:18.449] iteration 8314: loss: 0.118686, loss_s1: 0.100943, loss_fp: 0.004379, loss_freq: 0.062906
[16:00:19.109] iteration 8315: loss: 0.088397, loss_s1: 0.053138, loss_fp: 0.006946, loss_freq: 0.047282
[16:00:19.765] iteration 8316: loss: 0.104851, loss_s1: 0.043736, loss_fp: 0.010281, loss_freq: 0.035088
[16:00:20.409] iteration 8317: loss: 0.077761, loss_s1: 0.020924, loss_fp: 0.000334, loss_freq: 0.026576
[16:00:21.036] iteration 8318: loss: 0.087696, loss_s1: 0.023610, loss_fp: 0.001374, loss_freq: 0.020252
[16:00:21.659] iteration 8319: loss: 0.113325, loss_s1: 0.094766, loss_fp: 0.001707, loss_freq: 0.030794
[16:00:22.286] iteration 8320: loss: 0.196943, loss_s1: 0.124704, loss_fp: 0.004704, loss_freq: 0.147442
[16:00:22.919] iteration 8321: loss: 0.087562, loss_s1: 0.068836, loss_fp: 0.000754, loss_freq: 0.016193
[16:00:23.543] iteration 8322: loss: 0.070049, loss_s1: 0.026973, loss_fp: 0.002312, loss_freq: 0.030375
[16:00:24.166] iteration 8323: loss: 0.093826, loss_s1: 0.063132, loss_fp: 0.000774, loss_freq: 0.072859
[16:00:24.787] iteration 8324: loss: 0.118702, loss_s1: 0.108777, loss_fp: 0.007909, loss_freq: 0.048627
[16:00:25.459] iteration 8325: loss: 0.075239, loss_s1: 0.037393, loss_fp: 0.001076, loss_freq: 0.048001
[16:00:26.113] iteration 8326: loss: 0.051410, loss_s1: 0.020725, loss_fp: 0.000378, loss_freq: 0.003476
[16:00:26.772] iteration 8327: loss: 0.073049, loss_s1: 0.066029, loss_fp: 0.003242, loss_freq: 0.015324
[16:00:27.414] iteration 8328: loss: 0.127132, loss_s1: 0.120004, loss_fp: 0.005510, loss_freq: 0.058959
[16:00:28.038] iteration 8329: loss: 0.077028, loss_s1: 0.056682, loss_fp: 0.002317, loss_freq: 0.034363
[16:00:28.669] iteration 8330: loss: 0.076026, loss_s1: 0.049053, loss_fp: 0.001708, loss_freq: 0.032700
[16:00:29.293] iteration 8331: loss: 0.109245, loss_s1: 0.069468, loss_fp: 0.000645, loss_freq: 0.099540
[16:00:29.918] iteration 8332: loss: 0.076278, loss_s1: 0.020779, loss_fp: 0.001890, loss_freq: 0.074612
[16:00:30.544] iteration 8333: loss: 0.088661, loss_s1: 0.036068, loss_fp: 0.001987, loss_freq: 0.020568
[16:00:31.175] iteration 8334: loss: 0.085230, loss_s1: 0.044466, loss_fp: 0.004211, loss_freq: 0.033137
[16:00:31.803] iteration 8335: loss: 0.072625, loss_s1: 0.067630, loss_fp: 0.003256, loss_freq: 0.018579
[16:00:32.426] iteration 8336: loss: 0.136871, loss_s1: 0.083079, loss_fp: 0.001872, loss_freq: 0.050559
[16:00:33.051] iteration 8337: loss: 0.074741, loss_s1: 0.047713, loss_fp: 0.000849, loss_freq: 0.019961
[16:00:33.671] iteration 8338: loss: 0.053399, loss_s1: 0.038966, loss_fp: 0.001087, loss_freq: 0.012472
[16:00:34.292] iteration 8339: loss: 0.208101, loss_s1: 0.149177, loss_fp: 0.002255, loss_freq: 0.100733
[16:00:34.976] iteration 8340: loss: 0.077143, loss_s1: 0.056923, loss_fp: 0.003096, loss_freq: 0.014119
[16:00:35.634] iteration 8341: loss: 0.069747, loss_s1: 0.033931, loss_fp: 0.000827, loss_freq: 0.011869
[16:00:36.291] iteration 8342: loss: 0.097203, loss_s1: 0.061271, loss_fp: 0.002616, loss_freq: 0.067824
[16:00:36.931] iteration 8343: loss: 0.202729, loss_s1: 0.143129, loss_fp: 0.003108, loss_freq: 0.049163
[16:00:37.553] iteration 8344: loss: 0.068438, loss_s1: 0.037439, loss_fp: 0.001613, loss_freq: 0.024464
[16:00:38.177] iteration 8345: loss: 0.128156, loss_s1: 0.042019, loss_fp: 0.008545, loss_freq: 0.039764
[16:00:38.808] iteration 8346: loss: 0.102872, loss_s1: 0.087027, loss_fp: 0.006640, loss_freq: 0.052179
[16:00:39.432] iteration 8347: loss: 0.086876, loss_s1: 0.051837, loss_fp: 0.003803, loss_freq: 0.041072
[16:00:40.054] iteration 8348: loss: 0.079371, loss_s1: 0.020280, loss_fp: 0.000694, loss_freq: 0.053795
[16:00:40.675] iteration 8349: loss: 0.093467, loss_s1: 0.043941, loss_fp: 0.010884, loss_freq: 0.046219
[16:00:41.298] iteration 8350: loss: 0.092653, loss_s1: 0.074599, loss_fp: 0.005512, loss_freq: 0.049277
[16:00:41.927] iteration 8351: loss: 0.111539, loss_s1: 0.094288, loss_fp: 0.000825, loss_freq: 0.040420
[16:00:42.550] iteration 8352: loss: 0.100449, loss_s1: 0.085642, loss_fp: 0.002587, loss_freq: 0.059087
[16:00:43.178] iteration 8353: loss: 0.097460, loss_s1: 0.049136, loss_fp: 0.002422, loss_freq: 0.028612
[16:00:43.801] iteration 8354: loss: 0.086099, loss_s1: 0.030404, loss_fp: 0.006149, loss_freq: 0.018757
[16:00:44.426] iteration 8355: loss: 0.111421, loss_s1: 0.086193, loss_fp: 0.001975, loss_freq: 0.036208
[16:00:45.048] iteration 8356: loss: 0.083289, loss_s1: 0.054706, loss_fp: 0.002120, loss_freq: 0.048580
[16:00:45.670] iteration 8357: loss: 0.089895, loss_s1: 0.067380, loss_fp: 0.001008, loss_freq: 0.021632
[16:00:46.295] iteration 8358: loss: 0.096398, loss_s1: 0.059517, loss_fp: 0.004500, loss_freq: 0.077867
[16:00:46.921] iteration 8359: loss: 0.069384, loss_s1: 0.050155, loss_fp: 0.004523, loss_freq: 0.025521
[16:00:47.543] iteration 8360: loss: 0.076869, loss_s1: 0.050687, loss_fp: 0.000841, loss_freq: 0.010074
[16:00:48.166] iteration 8361: loss: 0.117600, loss_s1: 0.061949, loss_fp: 0.002647, loss_freq: 0.066138
[16:00:48.790] iteration 8362: loss: 0.113275, loss_s1: 0.068792, loss_fp: 0.000460, loss_freq: 0.025840
[16:00:49.416] iteration 8363: loss: 0.166832, loss_s1: 0.119811, loss_fp: 0.003992, loss_freq: 0.090050
[16:00:50.038] iteration 8364: loss: 0.063938, loss_s1: 0.057411, loss_fp: 0.001227, loss_freq: 0.025662
[16:00:50.664] iteration 8365: loss: 0.112139, loss_s1: 0.053124, loss_fp: 0.000734, loss_freq: 0.035660
[16:00:51.288] iteration 8366: loss: 0.064261, loss_s1: 0.034659, loss_fp: 0.001652, loss_freq: 0.021064
[16:00:51.913] iteration 8367: loss: 0.070379, loss_s1: 0.057519, loss_fp: 0.002517, loss_freq: 0.013746
[16:00:52.537] iteration 8368: loss: 0.104579, loss_s1: 0.034101, loss_fp: 0.000378, loss_freq: 0.020575
[16:00:53.159] iteration 8369: loss: 0.103630, loss_s1: 0.072428, loss_fp: 0.001076, loss_freq: 0.046639
[16:00:53.784] iteration 8370: loss: 0.090827, loss_s1: 0.067179, loss_fp: 0.005656, loss_freq: 0.043988
[16:00:54.406] iteration 8371: loss: 0.113768, loss_s1: 0.060046, loss_fp: 0.007136, loss_freq: 0.042916
[16:00:55.026] iteration 8372: loss: 0.110316, loss_s1: 0.064340, loss_fp: 0.023300, loss_freq: 0.045530
[16:00:56.011] iteration 8373: loss: 0.071333, loss_s1: 0.032640, loss_fp: 0.002888, loss_freq: 0.035649
[16:00:56.639] iteration 8374: loss: 0.123315, loss_s1: 0.071156, loss_fp: 0.013305, loss_freq: 0.028841
[16:00:57.298] iteration 8375: loss: 0.075164, loss_s1: 0.025712, loss_fp: 0.000398, loss_freq: 0.034085
[16:00:57.957] iteration 8376: loss: 0.061532, loss_s1: 0.048456, loss_fp: 0.001038, loss_freq: 0.011698
[16:00:58.616] iteration 8377: loss: 0.048411, loss_s1: 0.020668, loss_fp: 0.005356, loss_freq: 0.013086
[16:00:59.244] iteration 8378: loss: 0.116980, loss_s1: 0.062147, loss_fp: 0.005681, loss_freq: 0.055122
[16:00:59.871] iteration 8379: loss: 0.063820, loss_s1: 0.035079, loss_fp: 0.003760, loss_freq: 0.051333
[16:01:00.520] iteration 8380: loss: 0.064621, loss_s1: 0.026911, loss_fp: 0.003305, loss_freq: 0.036586
[16:01:01.147] iteration 8381: loss: 0.087109, loss_s1: 0.061488, loss_fp: 0.005837, loss_freq: 0.049610
[16:01:01.776] iteration 8382: loss: 0.112681, loss_s1: 0.107834, loss_fp: 0.013194, loss_freq: 0.041966
[16:01:02.435] iteration 8383: loss: 0.058818, loss_s1: 0.032475, loss_fp: 0.001769, loss_freq: 0.021178
[16:01:03.090] iteration 8384: loss: 0.127982, loss_s1: 0.086880, loss_fp: 0.002264, loss_freq: 0.082744
[16:01:03.748] iteration 8385: loss: 0.089895, loss_s1: 0.089117, loss_fp: 0.011368, loss_freq: 0.036124
[16:01:04.404] iteration 8386: loss: 0.104810, loss_s1: 0.050426, loss_fp: 0.004506, loss_freq: 0.065631
[16:01:05.041] iteration 8387: loss: 0.063252, loss_s1: 0.054674, loss_fp: 0.014325, loss_freq: 0.013937
[16:01:05.666] iteration 8388: loss: 0.081687, loss_s1: 0.032840, loss_fp: 0.008753, loss_freq: 0.043355
[16:01:06.290] iteration 8389: loss: 0.087260, loss_s1: 0.055222, loss_fp: 0.000796, loss_freq: 0.022225
[16:01:06.913] iteration 8390: loss: 0.097788, loss_s1: 0.055076, loss_fp: 0.006228, loss_freq: 0.053337
[16:01:07.538] iteration 8391: loss: 0.083269, loss_s1: 0.038562, loss_fp: 0.001227, loss_freq: 0.027497
[16:01:08.161] iteration 8392: loss: 0.054722, loss_s1: 0.014318, loss_fp: 0.005304, loss_freq: 0.028899
[16:01:08.812] iteration 8393: loss: 0.079210, loss_s1: 0.071857, loss_fp: 0.000695, loss_freq: 0.013616
[16:01:09.437] iteration 8394: loss: 0.071687, loss_s1: 0.043433, loss_fp: 0.002439, loss_freq: 0.018439
[16:01:10.066] iteration 8395: loss: 0.068035, loss_s1: 0.024925, loss_fp: 0.005233, loss_freq: 0.035273
[16:01:10.691] iteration 8396: loss: 0.214166, loss_s1: 0.136997, loss_fp: 0.004072, loss_freq: 0.213553
[16:01:11.318] iteration 8397: loss: 0.053510, loss_s1: 0.027164, loss_fp: 0.001955, loss_freq: 0.035654
[16:01:11.940] iteration 8398: loss: 0.115037, loss_s1: 0.071692, loss_fp: 0.002915, loss_freq: 0.086799
[16:01:12.563] iteration 8399: loss: 0.072323, loss_s1: 0.045844, loss_fp: 0.015099, loss_freq: 0.024747
[16:01:13.189] iteration 8400: loss: 0.088957, loss_s1: 0.061599, loss_fp: 0.007488, loss_freq: 0.039723
[16:01:16.563] iteration 8400 : mean_dice : 0.702509
[16:01:17.208] iteration 8401: loss: 0.091017, loss_s1: 0.071380, loss_fp: 0.007467, loss_freq: 0.032867
[16:01:17.835] iteration 8402: loss: 0.083273, loss_s1: 0.058032, loss_fp: 0.005203, loss_freq: 0.022567
[16:01:18.463] iteration 8403: loss: 0.073082, loss_s1: 0.032022, loss_fp: 0.000667, loss_freq: 0.039599
[16:01:19.089] iteration 8404: loss: 0.151197, loss_s1: 0.047036, loss_fp: 0.007307, loss_freq: 0.029202
[16:01:19.718] iteration 8405: loss: 0.071966, loss_s1: 0.036357, loss_fp: 0.003548, loss_freq: 0.037919
[16:01:20.340] iteration 8406: loss: 0.046757, loss_s1: 0.025609, loss_fp: 0.001898, loss_freq: 0.011921
[16:01:20.965] iteration 8407: loss: 0.112782, loss_s1: 0.032183, loss_fp: 0.005770, loss_freq: 0.030479
[16:01:21.591] iteration 8408: loss: 0.093150, loss_s1: 0.054730, loss_fp: 0.003955, loss_freq: 0.056299
[16:01:22.218] iteration 8409: loss: 0.115627, loss_s1: 0.080039, loss_fp: 0.004304, loss_freq: 0.047951
[16:01:22.841] iteration 8410: loss: 0.106958, loss_s1: 0.061632, loss_fp: 0.010268, loss_freq: 0.061510
[16:01:23.482] iteration 8411: loss: 0.114090, loss_s1: 0.095281, loss_fp: 0.002182, loss_freq: 0.071656
[16:01:24.122] iteration 8412: loss: 0.101613, loss_s1: 0.054971, loss_fp: 0.005136, loss_freq: 0.057273
[16:01:24.763] iteration 8413: loss: 0.118511, loss_s1: 0.042747, loss_fp: 0.007290, loss_freq: 0.016173
[16:01:25.400] iteration 8414: loss: 0.119928, loss_s1: 0.076428, loss_fp: 0.010010, loss_freq: 0.089802
[16:01:26.040] iteration 8415: loss: 0.069435, loss_s1: 0.040322, loss_fp: 0.001521, loss_freq: 0.022114
[16:01:26.676] iteration 8416: loss: 0.066330, loss_s1: 0.058277, loss_fp: 0.001479, loss_freq: 0.009387
[16:01:27.318] iteration 8417: loss: 0.072106, loss_s1: 0.029889, loss_fp: 0.003507, loss_freq: 0.038332
[16:01:27.955] iteration 8418: loss: 0.066620, loss_s1: 0.039628, loss_fp: 0.000770, loss_freq: 0.029261
[16:01:28.593] iteration 8419: loss: 0.050203, loss_s1: 0.019578, loss_fp: 0.002509, loss_freq: 0.027678
[16:01:29.233] iteration 8420: loss: 0.072749, loss_s1: 0.068764, loss_fp: 0.001643, loss_freq: 0.023911
[16:01:29.869] iteration 8421: loss: 0.059624, loss_s1: 0.047789, loss_fp: 0.002252, loss_freq: 0.006519
[16:01:30.505] iteration 8422: loss: 0.074083, loss_s1: 0.062389, loss_fp: 0.002594, loss_freq: 0.020978
[16:01:31.143] iteration 8423: loss: 0.097246, loss_s1: 0.100432, loss_fp: 0.004538, loss_freq: 0.033953
[16:01:31.783] iteration 8424: loss: 0.114950, loss_s1: 0.067512, loss_fp: 0.004270, loss_freq: 0.063287
[16:01:32.426] iteration 8425: loss: 0.096744, loss_s1: 0.084965, loss_fp: 0.002213, loss_freq: 0.046639
[16:01:33.065] iteration 8426: loss: 0.086798, loss_s1: 0.069555, loss_fp: 0.008222, loss_freq: 0.024650
[16:01:33.709] iteration 8427: loss: 0.064802, loss_s1: 0.025264, loss_fp: 0.000869, loss_freq: 0.026834
[16:01:34.349] iteration 8428: loss: 0.098318, loss_s1: 0.083238, loss_fp: 0.006486, loss_freq: 0.053460
[16:01:34.990] iteration 8429: loss: 0.059031, loss_s1: 0.035031, loss_fp: 0.002561, loss_freq: 0.013318
[16:01:35.626] iteration 8430: loss: 0.096762, loss_s1: 0.006886, loss_fp: 0.036122, loss_freq: 0.052280
[16:01:36.250] iteration 8431: loss: 0.084120, loss_s1: 0.087519, loss_fp: 0.000721, loss_freq: 0.015324
[16:01:36.875] iteration 8432: loss: 0.058599, loss_s1: 0.047495, loss_fp: 0.004908, loss_freq: 0.011190
[16:01:37.503] iteration 8433: loss: 0.040690, loss_s1: 0.013879, loss_fp: 0.005076, loss_freq: 0.016736
[16:01:38.129] iteration 8434: loss: 0.074998, loss_s1: 0.056161, loss_fp: 0.003389, loss_freq: 0.022325
[16:01:38.758] iteration 8435: loss: 0.093739, loss_s1: 0.088812, loss_fp: 0.002386, loss_freq: 0.019301
[16:01:39.395] iteration 8436: loss: 0.070900, loss_s1: 0.067813, loss_fp: 0.004076, loss_freq: 0.013985
[16:01:40.032] iteration 8437: loss: 0.103131, loss_s1: 0.048530, loss_fp: 0.001500, loss_freq: 0.033123
[16:01:40.879] iteration 8438: loss: 0.096235, loss_s1: 0.058664, loss_fp: 0.006297, loss_freq: 0.075023
[16:01:41.502] iteration 8439: loss: 0.070269, loss_s1: 0.021009, loss_fp: 0.001174, loss_freq: 0.037189
[16:01:42.125] iteration 8440: loss: 0.065035, loss_s1: 0.036253, loss_fp: 0.011611, loss_freq: 0.030443
[16:01:42.748] iteration 8441: loss: 0.074352, loss_s1: 0.039228, loss_fp: 0.002986, loss_freq: 0.024798
[16:01:43.371] iteration 8442: loss: 0.101250, loss_s1: 0.086762, loss_fp: 0.001625, loss_freq: 0.035623
[16:01:43.995] iteration 8443: loss: 0.104701, loss_s1: 0.065586, loss_fp: 0.008521, loss_freq: 0.060546
[16:01:44.615] iteration 8444: loss: 0.092861, loss_s1: 0.065909, loss_fp: 0.002851, loss_freq: 0.032117
[16:01:45.245] iteration 8445: loss: 0.075653, loss_s1: 0.058677, loss_fp: 0.002290, loss_freq: 0.022748
[16:01:45.867] iteration 8446: loss: 0.092381, loss_s1: 0.050598, loss_fp: 0.001876, loss_freq: 0.015221
[16:01:46.496] iteration 8447: loss: 0.113863, loss_s1: 0.068714, loss_fp: 0.003115, loss_freq: 0.078966
[16:01:47.122] iteration 8448: loss: 0.081777, loss_s1: 0.057851, loss_fp: 0.001623, loss_freq: 0.019748
[16:01:47.748] iteration 8449: loss: 0.110840, loss_s1: 0.129625, loss_fp: 0.003737, loss_freq: 0.039538
[16:01:48.373] iteration 8450: loss: 0.072743, loss_s1: 0.066217, loss_fp: 0.004872, loss_freq: 0.033661
[16:01:48.997] iteration 8451: loss: 0.055014, loss_s1: 0.029254, loss_fp: 0.001425, loss_freq: 0.007936
[16:01:49.621] iteration 8452: loss: 0.096320, loss_s1: 0.093033, loss_fp: 0.002841, loss_freq: 0.026953
[16:01:50.248] iteration 8453: loss: 0.102193, loss_s1: 0.055861, loss_fp: 0.003481, loss_freq: 0.061718
[16:01:50.881] iteration 8454: loss: 0.090222, loss_s1: 0.069698, loss_fp: 0.003541, loss_freq: 0.043688
[16:01:51.506] iteration 8455: loss: 0.154547, loss_s1: 0.163896, loss_fp: 0.006233, loss_freq: 0.086970
[16:01:52.166] iteration 8456: loss: 0.093938, loss_s1: 0.045697, loss_fp: 0.007140, loss_freq: 0.035828
[16:01:52.822] iteration 8457: loss: 0.122450, loss_s1: 0.128914, loss_fp: 0.010858, loss_freq: 0.057525
[16:01:53.475] iteration 8458: loss: 0.096280, loss_s1: 0.075393, loss_fp: 0.004788, loss_freq: 0.024199
[16:01:54.099] iteration 8459: loss: 0.118316, loss_s1: 0.032114, loss_fp: 0.001983, loss_freq: 0.044352
[16:01:54.723] iteration 8460: loss: 0.069233, loss_s1: 0.027591, loss_fp: 0.006697, loss_freq: 0.013209
[16:01:55.353] iteration 8461: loss: 0.145377, loss_s1: 0.067009, loss_fp: 0.105912, loss_freq: 0.057645
[16:01:55.977] iteration 8462: loss: 0.110966, loss_s1: 0.042725, loss_fp: 0.002346, loss_freq: 0.052235
[16:01:56.601] iteration 8463: loss: 0.081840, loss_s1: 0.057486, loss_fp: 0.001206, loss_freq: 0.012430
[16:01:57.241] iteration 8464: loss: 0.100471, loss_s1: 0.097957, loss_fp: 0.001342, loss_freq: 0.016838
[16:01:57.863] iteration 8465: loss: 0.184440, loss_s1: 0.061525, loss_fp: 0.000502, loss_freq: 0.030190
[16:01:58.485] iteration 8466: loss: 0.080027, loss_s1: 0.047300, loss_fp: 0.000429, loss_freq: 0.020041
[16:01:59.110] iteration 8467: loss: 0.061663, loss_s1: 0.041983, loss_fp: 0.002787, loss_freq: 0.020252
[16:01:59.733] iteration 8468: loss: 0.072212, loss_s1: 0.060851, loss_fp: 0.000980, loss_freq: 0.033078
[16:02:00.356] iteration 8469: loss: 0.088823, loss_s1: 0.043113, loss_fp: 0.002699, loss_freq: 0.035679
[16:02:00.984] iteration 8470: loss: 0.070951, loss_s1: 0.039051, loss_fp: 0.000526, loss_freq: 0.033040
[16:02:01.611] iteration 8471: loss: 0.081359, loss_s1: 0.075378, loss_fp: 0.001830, loss_freq: 0.019269
[16:02:02.238] iteration 8472: loss: 0.061012, loss_s1: 0.033017, loss_fp: 0.005202, loss_freq: 0.029752
[16:02:02.866] iteration 8473: loss: 0.070211, loss_s1: 0.035889, loss_fp: 0.000784, loss_freq: 0.026769
[16:02:03.489] iteration 8474: loss: 0.085757, loss_s1: 0.037101, loss_fp: 0.002554, loss_freq: 0.066395
[16:02:04.113] iteration 8475: loss: 0.120053, loss_s1: 0.049992, loss_fp: 0.011299, loss_freq: 0.070758
[16:02:04.735] iteration 8476: loss: 0.128685, loss_s1: 0.072547, loss_fp: 0.006141, loss_freq: 0.076266
[16:02:05.359] iteration 8477: loss: 0.088938, loss_s1: 0.046347, loss_fp: 0.001793, loss_freq: 0.030192
[16:02:05.988] iteration 8478: loss: 0.050228, loss_s1: 0.011843, loss_fp: 0.002946, loss_freq: 0.018544
[16:02:06.617] iteration 8479: loss: 0.058064, loss_s1: 0.015180, loss_fp: 0.001751, loss_freq: 0.016257
[16:02:07.242] iteration 8480: loss: 0.146680, loss_s1: 0.097545, loss_fp: 0.004951, loss_freq: 0.060090
[16:02:07.870] iteration 8481: loss: 0.225264, loss_s1: 0.152143, loss_fp: 0.006819, loss_freq: 0.156337
[16:02:08.495] iteration 8482: loss: 0.087222, loss_s1: 0.066796, loss_fp: 0.005967, loss_freq: 0.041281
[16:02:09.118] iteration 8483: loss: 0.116026, loss_s1: 0.056703, loss_fp: 0.003580, loss_freq: 0.075521
[16:02:09.743] iteration 8484: loss: 0.082625, loss_s1: 0.033691, loss_fp: 0.006870, loss_freq: 0.069186
[16:02:10.366] iteration 8485: loss: 0.119766, loss_s1: 0.076087, loss_fp: 0.011528, loss_freq: 0.066079
[16:02:10.996] iteration 8486: loss: 0.075972, loss_s1: 0.030439, loss_fp: 0.000732, loss_freq: 0.037205
[16:02:11.623] iteration 8487: loss: 0.044409, loss_s1: 0.021343, loss_fp: 0.001164, loss_freq: 0.007638
[16:02:12.249] iteration 8488: loss: 0.114331, loss_s1: 0.043998, loss_fp: 0.002922, loss_freq: 0.042650
[16:02:12.880] iteration 8489: loss: 0.071099, loss_s1: 0.038222, loss_fp: 0.002040, loss_freq: 0.043665
[16:02:13.506] iteration 8490: loss: 0.092748, loss_s1: 0.043833, loss_fp: 0.003512, loss_freq: 0.038746
[16:02:14.132] iteration 8491: loss: 0.094099, loss_s1: 0.049830, loss_fp: 0.015954, loss_freq: 0.028403
[16:02:14.759] iteration 8492: loss: 0.104033, loss_s1: 0.053488, loss_fp: 0.006166, loss_freq: 0.070650
[16:02:15.390] iteration 8493: loss: 0.140136, loss_s1: 0.102953, loss_fp: 0.001565, loss_freq: 0.125826
[16:02:16.025] iteration 8494: loss: 0.179236, loss_s1: 0.045674, loss_fp: 0.000815, loss_freq: 0.019450
[16:02:16.680] iteration 8495: loss: 0.096908, loss_s1: 0.087010, loss_fp: 0.001136, loss_freq: 0.012087
[16:02:17.341] iteration 8496: loss: 0.081763, loss_s1: 0.043715, loss_fp: 0.002253, loss_freq: 0.036320
[16:02:18.000] iteration 8497: loss: 0.130428, loss_s1: 0.018027, loss_fp: 0.000815, loss_freq: 0.037541
[16:02:18.664] iteration 8498: loss: 0.087147, loss_s1: 0.061163, loss_fp: 0.001986, loss_freq: 0.013723
[16:02:19.307] iteration 8499: loss: 0.061122, loss_s1: 0.038212, loss_fp: 0.000671, loss_freq: 0.020730
[16:02:19.935] iteration 8500: loss: 0.131174, loss_s1: 0.043279, loss_fp: 0.001293, loss_freq: 0.061533
[16:02:20.568] iteration 8501: loss: 0.079752, loss_s1: 0.066188, loss_fp: 0.001322, loss_freq: 0.012154
[16:02:21.199] iteration 8502: loss: 0.074500, loss_s1: 0.081864, loss_fp: 0.003508, loss_freq: 0.010715
[16:02:21.833] iteration 8503: loss: 0.109197, loss_s1: 0.075071, loss_fp: 0.001496, loss_freq: 0.078400
[16:02:22.460] iteration 8504: loss: 0.091254, loss_s1: 0.049995, loss_fp: 0.000718, loss_freq: 0.048600
[16:02:23.088] iteration 8505: loss: 0.110190, loss_s1: 0.093358, loss_fp: 0.010646, loss_freq: 0.041367
[16:02:23.712] iteration 8506: loss: 0.095223, loss_s1: 0.075939, loss_fp: 0.005728, loss_freq: 0.025279
[16:02:24.345] iteration 8507: loss: 0.090345, loss_s1: 0.050746, loss_fp: 0.001697, loss_freq: 0.072925
[16:02:24.969] iteration 8508: loss: 0.066227, loss_s1: 0.037861, loss_fp: 0.002100, loss_freq: 0.030247
[16:02:25.595] iteration 8509: loss: 0.058675, loss_s1: 0.025817, loss_fp: 0.001257, loss_freq: 0.027951
[16:02:26.229] iteration 8510: loss: 0.053207, loss_s1: 0.031875, loss_fp: 0.000993, loss_freq: 0.019704
[16:02:26.858] iteration 8511: loss: 0.094109, loss_s1: 0.047387, loss_fp: 0.002585, loss_freq: 0.042483
[16:02:27.486] iteration 8512: loss: 0.139418, loss_s1: 0.081501, loss_fp: 0.007089, loss_freq: 0.064889
[16:02:28.113] iteration 8513: loss: 0.095853, loss_s1: 0.080553, loss_fp: 0.005223, loss_freq: 0.057272
[16:02:28.735] iteration 8514: loss: 0.098052, loss_s1: 0.038445, loss_fp: 0.004435, loss_freq: 0.023033
[16:02:29.356] iteration 8515: loss: 0.115298, loss_s1: 0.063870, loss_fp: 0.009963, loss_freq: 0.032093
[16:02:29.984] iteration 8516: loss: 0.096765, loss_s1: 0.092084, loss_fp: 0.001525, loss_freq: 0.025351
[16:02:30.608] iteration 8517: loss: 0.066211, loss_s1: 0.041766, loss_fp: 0.005667, loss_freq: 0.018641
[16:02:31.236] iteration 8518: loss: 0.099381, loss_s1: 0.080223, loss_fp: 0.006654, loss_freq: 0.013882
[16:02:31.863] iteration 8519: loss: 0.095524, loss_s1: 0.073760, loss_fp: 0.003397, loss_freq: 0.074118
[16:02:32.487] iteration 8520: loss: 0.090839, loss_s1: 0.076120, loss_fp: 0.002806, loss_freq: 0.017392
[16:02:33.114] iteration 8521: loss: 0.061738, loss_s1: 0.037370, loss_fp: 0.002094, loss_freq: 0.015368
[16:02:33.744] iteration 8522: loss: 0.074631, loss_s1: 0.046063, loss_fp: 0.009266, loss_freq: 0.029205
[16:02:34.370] iteration 8523: loss: 0.095269, loss_s1: 0.038895, loss_fp: 0.002218, loss_freq: 0.062860
[16:02:34.993] iteration 8524: loss: 0.147216, loss_s1: 0.116088, loss_fp: 0.001269, loss_freq: 0.106368
[16:02:35.618] iteration 8525: loss: 0.062759, loss_s1: 0.036986, loss_fp: 0.001257, loss_freq: 0.023230
[16:02:36.247] iteration 8526: loss: 0.082478, loss_s1: 0.054591, loss_fp: 0.004997, loss_freq: 0.035750
[16:02:36.868] iteration 8527: loss: 0.067241, loss_s1: 0.021396, loss_fp: 0.001461, loss_freq: 0.012689
[16:02:37.495] iteration 8528: loss: 0.062598, loss_s1: 0.023632, loss_fp: 0.001595, loss_freq: 0.041570
[16:02:38.120] iteration 8529: loss: 0.052475, loss_s1: 0.018238, loss_fp: 0.001039, loss_freq: 0.017539
[16:02:38.742] iteration 8530: loss: 0.099229, loss_s1: 0.032693, loss_fp: 0.006218, loss_freq: 0.055401
[16:02:39.366] iteration 8531: loss: 0.121794, loss_s1: 0.085672, loss_fp: 0.010227, loss_freq: 0.090920
[16:02:39.990] iteration 8532: loss: 0.088717, loss_s1: 0.059088, loss_fp: 0.007248, loss_freq: 0.029164
[16:02:40.609] iteration 8533: loss: 0.087856, loss_s1: 0.066958, loss_fp: 0.001472, loss_freq: 0.034005
[16:02:41.578] iteration 8534: loss: 0.081357, loss_s1: 0.061925, loss_fp: 0.001837, loss_freq: 0.041251
[16:02:42.230] iteration 8535: loss: 0.101902, loss_s1: 0.056336, loss_fp: 0.000462, loss_freq: 0.024220
[16:02:42.888] iteration 8536: loss: 0.079746, loss_s1: 0.038178, loss_fp: 0.000553, loss_freq: 0.036860
[16:02:43.549] iteration 8537: loss: 0.052631, loss_s1: 0.016886, loss_fp: 0.000345, loss_freq: 0.017077
[16:02:44.173] iteration 8538: loss: 0.098459, loss_s1: 0.046388, loss_fp: 0.004717, loss_freq: 0.066750
[16:02:44.795] iteration 8539: loss: 0.161044, loss_s1: 0.078833, loss_fp: 0.014582, loss_freq: 0.084353
[16:02:45.416] iteration 8540: loss: 0.042915, loss_s1: 0.028194, loss_fp: 0.002193, loss_freq: 0.009481
[16:02:46.043] iteration 8541: loss: 0.066477, loss_s1: 0.038822, loss_fp: 0.012870, loss_freq: 0.041555
[16:02:46.673] iteration 8542: loss: 0.091299, loss_s1: 0.067231, loss_fp: 0.008722, loss_freq: 0.038675
[16:02:47.296] iteration 8543: loss: 0.116820, loss_s1: 0.143742, loss_fp: 0.001247, loss_freq: 0.028242
[16:02:47.925] iteration 8544: loss: 0.039066, loss_s1: 0.012294, loss_fp: 0.001143, loss_freq: 0.010749
[16:02:48.547] iteration 8545: loss: 0.114084, loss_s1: 0.039788, loss_fp: 0.001885, loss_freq: 0.057986
[16:02:49.171] iteration 8546: loss: 0.080535, loss_s1: 0.051705, loss_fp: 0.012552, loss_freq: 0.051753
[16:02:49.798] iteration 8547: loss: 0.128496, loss_s1: 0.105401, loss_fp: 0.003204, loss_freq: 0.059524
[16:02:50.420] iteration 8548: loss: 0.048886, loss_s1: 0.031025, loss_fp: 0.002200, loss_freq: 0.012287
[16:02:51.041] iteration 8549: loss: 0.122898, loss_s1: 0.100966, loss_fp: 0.001048, loss_freq: 0.061007
[16:02:51.666] iteration 8550: loss: 0.069653, loss_s1: 0.049980, loss_fp: 0.003779, loss_freq: 0.018005
[16:02:52.288] iteration 8551: loss: 0.078451, loss_s1: 0.068458, loss_fp: 0.003987, loss_freq: 0.027993
[16:02:52.909] iteration 8552: loss: 0.082162, loss_s1: 0.030204, loss_fp: 0.001245, loss_freq: 0.037546
[16:02:53.531] iteration 8553: loss: 0.107604, loss_s1: 0.085419, loss_fp: 0.000965, loss_freq: 0.038207
[16:02:54.212] iteration 8554: loss: 0.061527, loss_s1: 0.049058, loss_fp: 0.001081, loss_freq: 0.018904
[16:02:54.876] iteration 8555: loss: 0.057034, loss_s1: 0.018131, loss_fp: 0.002439, loss_freq: 0.035415
[16:02:55.531] iteration 8556: loss: 0.102440, loss_s1: 0.040922, loss_fp: 0.001955, loss_freq: 0.013340
[16:02:56.189] iteration 8557: loss: 0.334546, loss_s1: 0.262976, loss_fp: 0.012222, loss_freq: 0.330419
[16:02:56.839] iteration 8558: loss: 0.050872, loss_s1: 0.017653, loss_fp: 0.000657, loss_freq: 0.031853
[16:02:57.465] iteration 8559: loss: 0.098380, loss_s1: 0.070619, loss_fp: 0.002343, loss_freq: 0.035616
[16:02:58.096] iteration 8560: loss: 0.052598, loss_s1: 0.017367, loss_fp: 0.000994, loss_freq: 0.022287
[16:02:58.727] iteration 8561: loss: 0.084897, loss_s1: 0.037922, loss_fp: 0.024337, loss_freq: 0.026099
[16:02:59.353] iteration 8562: loss: 0.064886, loss_s1: 0.039895, loss_fp: 0.004171, loss_freq: 0.035473
[16:02:59.984] iteration 8563: loss: 0.060776, loss_s1: 0.047830, loss_fp: 0.000720, loss_freq: 0.004981
[16:03:00.608] iteration 8564: loss: 0.062074, loss_s1: 0.056526, loss_fp: 0.006137, loss_freq: 0.018493
[16:03:01.239] iteration 8565: loss: 0.137382, loss_s1: 0.057797, loss_fp: 0.001469, loss_freq: 0.019111
[16:03:01.867] iteration 8566: loss: 0.072477, loss_s1: 0.043829, loss_fp: 0.002921, loss_freq: 0.018529
[16:03:02.489] iteration 8567: loss: 0.049738, loss_s1: 0.023984, loss_fp: 0.000529, loss_freq: 0.011501
[16:03:03.110] iteration 8568: loss: 0.081962, loss_s1: 0.023503, loss_fp: 0.002241, loss_freq: 0.034190
[16:03:03.732] iteration 8569: loss: 0.109012, loss_s1: 0.076139, loss_fp: 0.004922, loss_freq: 0.055440
[16:03:04.354] iteration 8570: loss: 0.135992, loss_s1: 0.096256, loss_fp: 0.004245, loss_freq: 0.054491
[16:03:04.972] iteration 8571: loss: 0.099747, loss_s1: 0.064527, loss_fp: 0.006486, loss_freq: 0.033753
[16:03:05.597] iteration 8572: loss: 0.124825, loss_s1: 0.086971, loss_fp: 0.001191, loss_freq: 0.069484
[16:03:06.218] iteration 8573: loss: 0.134874, loss_s1: 0.131047, loss_fp: 0.002869, loss_freq: 0.049700
[16:03:06.840] iteration 8574: loss: 0.075613, loss_s1: 0.020383, loss_fp: 0.002578, loss_freq: 0.018092
[16:03:07.465] iteration 8575: loss: 0.135438, loss_s1: 0.141714, loss_fp: 0.009043, loss_freq: 0.061385
[16:03:08.091] iteration 8576: loss: 0.077293, loss_s1: 0.033969, loss_fp: 0.004218, loss_freq: 0.059260
[16:03:08.716] iteration 8577: loss: 0.052416, loss_s1: 0.023514, loss_fp: 0.002217, loss_freq: 0.022880
[16:03:09.341] iteration 8578: loss: 0.090661, loss_s1: 0.058268, loss_fp: 0.004267, loss_freq: 0.049545
[16:03:09.968] iteration 8579: loss: 0.060432, loss_s1: 0.041905, loss_fp: 0.000661, loss_freq: 0.011498
[16:03:10.594] iteration 8580: loss: 0.053997, loss_s1: 0.037112, loss_fp: 0.000644, loss_freq: 0.011265
[16:03:11.217] iteration 8581: loss: 0.046918, loss_s1: 0.013688, loss_fp: 0.007268, loss_freq: 0.022693
[16:03:11.844] iteration 8582: loss: 0.071008, loss_s1: 0.052753, loss_fp: 0.001046, loss_freq: 0.008632
[16:03:12.467] iteration 8583: loss: 0.084659, loss_s1: 0.068136, loss_fp: 0.001358, loss_freq: 0.027059
[16:03:13.091] iteration 8584: loss: 0.082577, loss_s1: 0.057455, loss_fp: 0.011265, loss_freq: 0.041474
[16:03:13.716] iteration 8585: loss: 0.057952, loss_s1: 0.017667, loss_fp: 0.001475, loss_freq: 0.009098
[16:03:14.340] iteration 8586: loss: 0.063838, loss_s1: 0.036328, loss_fp: 0.003809, loss_freq: 0.025749
[16:03:14.964] iteration 8587: loss: 0.071607, loss_s1: 0.041281, loss_fp: 0.000636, loss_freq: 0.028513
[16:03:15.585] iteration 8588: loss: 0.060003, loss_s1: 0.022362, loss_fp: 0.000392, loss_freq: 0.029044
[16:03:16.211] iteration 8589: loss: 0.092066, loss_s1: 0.041577, loss_fp: 0.002378, loss_freq: 0.053740
[16:03:16.859] iteration 8590: loss: 0.066563, loss_s1: 0.011149, loss_fp: 0.000603, loss_freq: 0.032759
[16:03:17.487] iteration 8591: loss: 0.093357, loss_s1: 0.031506, loss_fp: 0.000439, loss_freq: 0.071190
[16:03:18.116] iteration 8592: loss: 0.045949, loss_s1: 0.008556, loss_fp: 0.001912, loss_freq: 0.006021
[16:03:18.744] iteration 8593: loss: 0.048580, loss_s1: 0.024821, loss_fp: 0.001122, loss_freq: 0.018543
[16:03:19.366] iteration 8594: loss: 0.066836, loss_s1: 0.037237, loss_fp: 0.001127, loss_freq: 0.022369
[16:03:19.989] iteration 8595: loss: 0.070087, loss_s1: 0.066948, loss_fp: 0.002281, loss_freq: 0.009068
[16:03:20.609] iteration 8596: loss: 0.105753, loss_s1: 0.082260, loss_fp: 0.004346, loss_freq: 0.012262
[16:03:21.234] iteration 8597: loss: 0.059578, loss_s1: 0.029899, loss_fp: 0.005919, loss_freq: 0.023876
[16:03:21.856] iteration 8598: loss: 0.057867, loss_s1: 0.044097, loss_fp: 0.008183, loss_freq: 0.011466
[16:03:22.477] iteration 8599: loss: 0.079125, loss_s1: 0.051796, loss_fp: 0.002187, loss_freq: 0.063164
[16:03:23.099] iteration 8600: loss: 0.091668, loss_s1: 0.041215, loss_fp: 0.002215, loss_freq: 0.039373
[16:03:26.431] iteration 8600 : mean_dice : 0.662518
[16:03:27.116] iteration 8601: loss: 0.084252, loss_s1: 0.077301, loss_fp: 0.001509, loss_freq: 0.041340
[16:03:27.770] iteration 8602: loss: 0.060102, loss_s1: 0.032723, loss_fp: 0.002425, loss_freq: 0.034136
[16:03:28.423] iteration 8603: loss: 0.115522, loss_s1: 0.051363, loss_fp: 0.006352, loss_freq: 0.018334
[16:03:29.084] iteration 8604: loss: 0.077125, loss_s1: 0.057392, loss_fp: 0.004778, loss_freq: 0.038402
[16:03:29.708] iteration 8605: loss: 0.065109, loss_s1: 0.020574, loss_fp: 0.002158, loss_freq: 0.044295
[16:03:30.357] iteration 8606: loss: 0.062477, loss_s1: 0.032976, loss_fp: 0.006195, loss_freq: 0.037602
[16:03:30.980] iteration 8607: loss: 0.047673, loss_s1: 0.017973, loss_fp: 0.001433, loss_freq: 0.008973
[16:03:31.606] iteration 8608: loss: 0.111679, loss_s1: 0.102464, loss_fp: 0.001158, loss_freq: 0.058245
[16:03:32.231] iteration 8609: loss: 0.119598, loss_s1: 0.068801, loss_fp: 0.007321, loss_freq: 0.070570
[16:03:32.854] iteration 8610: loss: 0.091892, loss_s1: 0.063576, loss_fp: 0.008343, loss_freq: 0.052170
[16:03:33.477] iteration 8611: loss: 0.096436, loss_s1: 0.076130, loss_fp: 0.002824, loss_freq: 0.027408
[16:03:34.099] iteration 8612: loss: 0.055551, loss_s1: 0.023316, loss_fp: 0.015938, loss_freq: 0.019637
[16:03:34.724] iteration 8613: loss: 0.074576, loss_s1: 0.038963, loss_fp: 0.002841, loss_freq: 0.037517
[16:03:35.345] iteration 8614: loss: 0.101657, loss_s1: 0.092302, loss_fp: 0.002661, loss_freq: 0.043990
[16:03:35.970] iteration 8615: loss: 0.058228, loss_s1: 0.040986, loss_fp: 0.001370, loss_freq: 0.032991
[16:03:36.591] iteration 8616: loss: 0.134275, loss_s1: 0.074403, loss_fp: 0.015337, loss_freq: 0.083244
[16:03:37.277] iteration 8617: loss: 0.078002, loss_s1: 0.023248, loss_fp: 0.005671, loss_freq: 0.049540
[16:03:37.931] iteration 8618: loss: 0.137369, loss_s1: 0.137268, loss_fp: 0.003227, loss_freq: 0.061297
[16:03:38.584] iteration 8619: loss: 0.063338, loss_s1: 0.041511, loss_fp: 0.001661, loss_freq: 0.027807
[16:03:39.236] iteration 8620: loss: 0.071291, loss_s1: 0.062755, loss_fp: 0.001198, loss_freq: 0.014226
[16:03:39.875] iteration 8621: loss: 0.067255, loss_s1: 0.030472, loss_fp: 0.021007, loss_freq: 0.011443
[16:03:40.514] iteration 8622: loss: 0.111090, loss_s1: 0.090552, loss_fp: 0.017731, loss_freq: 0.049625
[16:03:41.139] iteration 8623: loss: 0.090134, loss_s1: 0.070067, loss_fp: 0.001140, loss_freq: 0.036608
[16:03:41.761] iteration 8624: loss: 0.078817, loss_s1: 0.023557, loss_fp: 0.000815, loss_freq: 0.034241
[16:03:42.430] iteration 8625: loss: 0.048259, loss_s1: 0.028854, loss_fp: 0.001097, loss_freq: 0.012751
[16:03:43.098] iteration 8626: loss: 0.140281, loss_s1: 0.065231, loss_fp: 0.001766, loss_freq: 0.018993
[16:03:43.772] iteration 8627: loss: 0.059967, loss_s1: 0.044359, loss_fp: 0.001073, loss_freq: 0.022586
[16:03:44.445] iteration 8628: loss: 0.053786, loss_s1: 0.056400, loss_fp: 0.000744, loss_freq: 0.015659
[16:03:45.128] iteration 8629: loss: 0.064675, loss_s1: 0.043753, loss_fp: 0.005266, loss_freq: 0.017982
[16:03:45.757] iteration 8630: loss: 0.087251, loss_s1: 0.028849, loss_fp: 0.002466, loss_freq: 0.034928
[16:03:46.381] iteration 8631: loss: 0.107583, loss_s1: 0.016355, loss_fp: 0.001553, loss_freq: 0.026280
[16:03:47.014] iteration 8632: loss: 0.065186, loss_s1: 0.049608, loss_fp: 0.001077, loss_freq: 0.026030
[16:03:47.638] iteration 8633: loss: 0.094780, loss_s1: 0.106639, loss_fp: 0.003063, loss_freq: 0.018922
[16:03:48.265] iteration 8634: loss: 0.125027, loss_s1: 0.109104, loss_fp: 0.012185, loss_freq: 0.029988
[16:03:48.887] iteration 8635: loss: 0.113715, loss_s1: 0.079029, loss_fp: 0.001796, loss_freq: 0.034059
[16:03:49.529] iteration 8636: loss: 0.083998, loss_s1: 0.046538, loss_fp: 0.006933, loss_freq: 0.057537
[16:03:50.154] iteration 8637: loss: 0.087384, loss_s1: 0.039293, loss_fp: 0.002278, loss_freq: 0.059421
[16:03:50.781] iteration 8638: loss: 0.083273, loss_s1: 0.047391, loss_fp: 0.002090, loss_freq: 0.026765
[16:03:51.407] iteration 8639: loss: 0.048033, loss_s1: 0.014428, loss_fp: 0.001585, loss_freq: 0.020424
[16:03:52.027] iteration 8640: loss: 0.076837, loss_s1: 0.028042, loss_fp: 0.001855, loss_freq: 0.013689
[16:03:52.649] iteration 8641: loss: 0.083025, loss_s1: 0.035921, loss_fp: 0.004879, loss_freq: 0.060872
[16:03:53.271] iteration 8642: loss: 0.145270, loss_s1: 0.125744, loss_fp: 0.006396, loss_freq: 0.084256
[16:03:53.893] iteration 8643: loss: 0.100533, loss_s1: 0.036154, loss_fp: 0.001109, loss_freq: 0.043801
[16:03:54.516] iteration 8644: loss: 0.079508, loss_s1: 0.013957, loss_fp: 0.006884, loss_freq: 0.021112
[16:03:55.176] iteration 8645: loss: 0.080985, loss_s1: 0.034275, loss_fp: 0.003687, loss_freq: 0.078722
[16:03:55.832] iteration 8646: loss: 0.072265, loss_s1: 0.039867, loss_fp: 0.001229, loss_freq: 0.042096
[16:03:56.466] iteration 8647: loss: 0.068892, loss_s1: 0.020002, loss_fp: 0.004215, loss_freq: 0.049895
[16:03:57.090] iteration 8648: loss: 0.060592, loss_s1: 0.047409, loss_fp: 0.001949, loss_freq: 0.006983
[16:03:57.708] iteration 8649: loss: 0.091318, loss_s1: 0.062690, loss_fp: 0.003808, loss_freq: 0.052458
[16:03:58.334] iteration 8650: loss: 0.088986, loss_s1: 0.070868, loss_fp: 0.011241, loss_freq: 0.052869
[16:03:58.955] iteration 8651: loss: 0.074056, loss_s1: 0.054103, loss_fp: 0.002826, loss_freq: 0.047298
[16:03:59.577] iteration 8652: loss: 0.069057, loss_s1: 0.025360, loss_fp: 0.005640, loss_freq: 0.026215
[16:04:00.206] iteration 8653: loss: 0.131269, loss_s1: 0.074850, loss_fp: 0.009558, loss_freq: 0.111377
[16:04:00.832] iteration 8654: loss: 0.071398, loss_s1: 0.008860, loss_fp: 0.003342, loss_freq: 0.072263
[16:04:01.497] iteration 8655: loss: 0.069347, loss_s1: 0.017211, loss_fp: 0.007671, loss_freq: 0.011720
[16:04:02.136] iteration 8656: loss: 0.113714, loss_s1: 0.107530, loss_fp: 0.001446, loss_freq: 0.039173
[16:04:02.761] iteration 8657: loss: 0.082562, loss_s1: 0.049526, loss_fp: 0.008343, loss_freq: 0.021130
[16:04:03.386] iteration 8658: loss: 0.113634, loss_s1: 0.049045, loss_fp: 0.002654, loss_freq: 0.062046
[16:04:04.009] iteration 8659: loss: 0.066624, loss_s1: 0.022079, loss_fp: 0.003542, loss_freq: 0.036151
[16:04:04.634] iteration 8660: loss: 0.042279, loss_s1: 0.015007, loss_fp: 0.004938, loss_freq: 0.011785
[16:04:05.261] iteration 8661: loss: 0.203506, loss_s1: 0.176499, loss_fp: 0.003103, loss_freq: 0.076183
[16:04:05.881] iteration 8662: loss: 0.078546, loss_s1: 0.076855, loss_fp: 0.002261, loss_freq: 0.015867
[16:04:06.516] iteration 8663: loss: 0.073850, loss_s1: 0.049376, loss_fp: 0.002324, loss_freq: 0.006133
[16:04:07.143] iteration 8664: loss: 0.081829, loss_s1: 0.057014, loss_fp: 0.002957, loss_freq: 0.049414
[16:04:07.767] iteration 8665: loss: 0.124819, loss_s1: 0.061339, loss_fp: 0.000627, loss_freq: 0.035168
[16:04:08.396] iteration 8666: loss: 0.120111, loss_s1: 0.149953, loss_fp: 0.006430, loss_freq: 0.017620
[16:04:09.023] iteration 8667: loss: 0.090668, loss_s1: 0.086512, loss_fp: 0.002094, loss_freq: 0.014893
[16:04:09.646] iteration 8668: loss: 0.132195, loss_s1: 0.130635, loss_fp: 0.001454, loss_freq: 0.078849
[16:04:10.272] iteration 8669: loss: 0.083125, loss_s1: 0.075178, loss_fp: 0.002898, loss_freq: 0.033112
[16:04:10.897] iteration 8670: loss: 0.063432, loss_s1: 0.023829, loss_fp: 0.001134, loss_freq: 0.031818
[16:04:11.522] iteration 8671: loss: 0.076375, loss_s1: 0.033733, loss_fp: 0.004036, loss_freq: 0.031768
[16:04:12.150] iteration 8672: loss: 0.065460, loss_s1: 0.015642, loss_fp: 0.027275, loss_freq: 0.028550
[16:04:12.779] iteration 8673: loss: 0.133939, loss_s1: 0.097492, loss_fp: 0.005957, loss_freq: 0.045643
[16:04:13.424] iteration 8674: loss: 0.069601, loss_s1: 0.027900, loss_fp: 0.000508, loss_freq: 0.047475
[16:04:14.105] iteration 8675: loss: 0.081039, loss_s1: 0.038940, loss_fp: 0.002289, loss_freq: 0.038531
[16:04:14.785] iteration 8676: loss: 0.101786, loss_s1: 0.031108, loss_fp: 0.009077, loss_freq: 0.061992
[16:04:15.450] iteration 8677: loss: 0.102212, loss_s1: 0.053436, loss_fp: 0.001285, loss_freq: 0.026049
[16:04:16.074] iteration 8678: loss: 0.040081, loss_s1: 0.014706, loss_fp: 0.001702, loss_freq: 0.004485
[16:04:16.704] iteration 8679: loss: 0.076906, loss_s1: 0.034141, loss_fp: 0.002535, loss_freq: 0.031857
[16:04:17.336] iteration 8680: loss: 0.093669, loss_s1: 0.073368, loss_fp: 0.002824, loss_freq: 0.072672
[16:04:17.969] iteration 8681: loss: 0.070611, loss_s1: 0.061644, loss_fp: 0.000542, loss_freq: 0.011227
[16:04:18.601] iteration 8682: loss: 0.106406, loss_s1: 0.050220, loss_fp: 0.000646, loss_freq: 0.080338
[16:04:19.232] iteration 8683: loss: 0.110473, loss_s1: 0.067033, loss_fp: 0.000678, loss_freq: 0.069248
[16:04:19.864] iteration 8684: loss: 0.087200, loss_s1: 0.037781, loss_fp: 0.001821, loss_freq: 0.048993
[16:04:20.493] iteration 8685: loss: 0.122524, loss_s1: 0.126604, loss_fp: 0.022018, loss_freq: 0.034066
[16:04:21.121] iteration 8686: loss: 0.074524, loss_s1: 0.061798, loss_fp: 0.001239, loss_freq: 0.034072
[16:04:21.748] iteration 8687: loss: 0.078336, loss_s1: 0.059131, loss_fp: 0.002186, loss_freq: 0.022937
[16:04:22.381] iteration 8688: loss: 0.049078, loss_s1: 0.018811, loss_fp: 0.004889, loss_freq: 0.020950
[16:04:23.012] iteration 8689: loss: 0.050055, loss_s1: 0.037689, loss_fp: 0.001710, loss_freq: 0.011099
[16:04:23.641] iteration 8690: loss: 0.092133, loss_s1: 0.011970, loss_fp: 0.000934, loss_freq: 0.016466
[16:04:24.273] iteration 8691: loss: 0.093481, loss_s1: 0.070092, loss_fp: 0.005916, loss_freq: 0.043404
[16:04:24.897] iteration 8692: loss: 0.063098, loss_s1: 0.043614, loss_fp: 0.009781, loss_freq: 0.019633
[16:04:25.520] iteration 8693: loss: 0.069087, loss_s1: 0.028419, loss_fp: 0.001842, loss_freq: 0.033277
[16:04:26.142] iteration 8694: loss: 0.115181, loss_s1: 0.079862, loss_fp: 0.000846, loss_freq: 0.055414
[16:04:27.164] iteration 8695: loss: 0.074201, loss_s1: 0.050669, loss_fp: 0.000873, loss_freq: 0.030720
[16:04:27.821] iteration 8696: loss: 0.082289, loss_s1: 0.047588, loss_fp: 0.003529, loss_freq: 0.036431
[16:04:28.482] iteration 8697: loss: 0.061970, loss_s1: 0.018074, loss_fp: 0.002143, loss_freq: 0.022644
[16:04:29.152] iteration 8698: loss: 0.074737, loss_s1: 0.029298, loss_fp: 0.001392, loss_freq: 0.019498
[16:04:29.808] iteration 8699: loss: 0.101253, loss_s1: 0.064642, loss_fp: 0.003587, loss_freq: 0.026669
[16:04:30.466] iteration 8700: loss: 0.117810, loss_s1: 0.072661, loss_fp: 0.003802, loss_freq: 0.028497
[16:04:31.124] iteration 8701: loss: 0.076222, loss_s1: 0.070828, loss_fp: 0.001590, loss_freq: 0.027917
[16:04:31.786] iteration 8702: loss: 0.062600, loss_s1: 0.027276, loss_fp: 0.000547, loss_freq: 0.020002
[16:04:32.413] iteration 8703: loss: 0.098654, loss_s1: 0.061388, loss_fp: 0.002636, loss_freq: 0.059508
[16:04:33.044] iteration 8704: loss: 0.119607, loss_s1: 0.072309, loss_fp: 0.005091, loss_freq: 0.053352
[16:04:33.672] iteration 8705: loss: 0.050313, loss_s1: 0.025015, loss_fp: 0.002264, loss_freq: 0.021951
[16:04:34.295] iteration 8706: loss: 0.085459, loss_s1: 0.047299, loss_fp: 0.000533, loss_freq: 0.026171
[16:04:34.924] iteration 8707: loss: 0.105120, loss_s1: 0.079027, loss_fp: 0.006982, loss_freq: 0.071131
[16:04:35.551] iteration 8708: loss: 0.123618, loss_s1: 0.042734, loss_fp: 0.003076, loss_freq: 0.048508
[16:04:36.180] iteration 8709: loss: 0.055044, loss_s1: 0.037776, loss_fp: 0.002317, loss_freq: 0.015802
[16:04:36.805] iteration 8710: loss: 0.161101, loss_s1: 0.100403, loss_fp: 0.002188, loss_freq: 0.094521
[16:04:37.440] iteration 8711: loss: 0.080356, loss_s1: 0.040511, loss_fp: 0.004380, loss_freq: 0.020988
[16:04:38.064] iteration 8712: loss: 0.077886, loss_s1: 0.052919, loss_fp: 0.001835, loss_freq: 0.031476
[16:04:38.689] iteration 8713: loss: 0.064698, loss_s1: 0.046046, loss_fp: 0.001174, loss_freq: 0.015381
[16:04:39.312] iteration 8714: loss: 0.099364, loss_s1: 0.031646, loss_fp: 0.005474, loss_freq: 0.025531
[16:04:39.938] iteration 8715: loss: 0.077935, loss_s1: 0.068626, loss_fp: 0.002138, loss_freq: 0.024843
[16:04:40.562] iteration 8716: loss: 0.119508, loss_s1: 0.094530, loss_fp: 0.004373, loss_freq: 0.024786
[16:04:41.187] iteration 8717: loss: 0.110569, loss_s1: 0.046812, loss_fp: 0.008495, loss_freq: 0.051690
[16:04:41.813] iteration 8718: loss: 0.181290, loss_s1: 0.122914, loss_fp: 0.001123, loss_freq: 0.190840
[16:04:42.436] iteration 8719: loss: 0.042673, loss_s1: 0.014744, loss_fp: 0.001005, loss_freq: 0.024665
[16:04:43.060] iteration 8720: loss: 0.097827, loss_s1: 0.064879, loss_fp: 0.000631, loss_freq: 0.073585
[16:04:43.691] iteration 8721: loss: 0.098216, loss_s1: 0.039086, loss_fp: 0.000836, loss_freq: 0.096978
[16:04:44.316] iteration 8722: loss: 0.162052, loss_s1: 0.097162, loss_fp: 0.003061, loss_freq: 0.064253
[16:04:44.940] iteration 8723: loss: 0.070225, loss_s1: 0.057200, loss_fp: 0.009788, loss_freq: 0.019880
[16:04:45.565] iteration 8724: loss: 0.074822, loss_s1: 0.026816, loss_fp: 0.001134, loss_freq: 0.008233
[16:04:46.194] iteration 8725: loss: 0.051461, loss_s1: 0.032057, loss_fp: 0.004947, loss_freq: 0.011228
[16:04:46.819] iteration 8726: loss: 0.100880, loss_s1: 0.046023, loss_fp: 0.004308, loss_freq: 0.024183
[16:04:47.443] iteration 8727: loss: 0.067389, loss_s1: 0.039548, loss_fp: 0.000711, loss_freq: 0.036917
[16:04:48.065] iteration 8728: loss: 0.045976, loss_s1: 0.027736, loss_fp: 0.002114, loss_freq: 0.010839
[16:04:48.691] iteration 8729: loss: 0.071325, loss_s1: 0.024108, loss_fp: 0.005569, loss_freq: 0.040694
[16:04:49.313] iteration 8730: loss: 0.064578, loss_s1: 0.031478, loss_fp: 0.014992, loss_freq: 0.018862
[16:04:49.934] iteration 8731: loss: 0.119269, loss_s1: 0.078182, loss_fp: 0.008649, loss_freq: 0.067525
[16:04:50.555] iteration 8732: loss: 0.077963, loss_s1: 0.019127, loss_fp: 0.002393, loss_freq: 0.058109
[16:04:51.183] iteration 8733: loss: 0.138701, loss_s1: 0.098658, loss_fp: 0.037132, loss_freq: 0.076032
[16:04:51.801] iteration 8734: loss: 0.095428, loss_s1: 0.082842, loss_fp: 0.004339, loss_freq: 0.032708
[16:04:52.424] iteration 8735: loss: 0.076467, loss_s1: 0.037149, loss_fp: 0.008775, loss_freq: 0.032551
[16:04:53.047] iteration 8736: loss: 0.097459, loss_s1: 0.075478, loss_fp: 0.004322, loss_freq: 0.062532
[16:04:53.672] iteration 8737: loss: 0.080309, loss_s1: 0.050589, loss_fp: 0.002663, loss_freq: 0.032016
[16:04:54.298] iteration 8738: loss: 0.063996, loss_s1: 0.034561, loss_fp: 0.005866, loss_freq: 0.042610
[16:04:54.927] iteration 8739: loss: 0.074203, loss_s1: 0.033395, loss_fp: 0.001093, loss_freq: 0.041058
[16:04:55.557] iteration 8740: loss: 0.071550, loss_s1: 0.053620, loss_fp: 0.000902, loss_freq: 0.016613
[16:04:56.184] iteration 8741: loss: 0.050642, loss_s1: 0.043700, loss_fp: 0.001929, loss_freq: 0.009279
[16:04:56.803] iteration 8742: loss: 0.052684, loss_s1: 0.039550, loss_fp: 0.003451, loss_freq: 0.019192
[16:04:57.496] iteration 8743: loss: 0.071200, loss_s1: 0.042971, loss_fp: 0.003531, loss_freq: 0.019572
[16:04:58.156] iteration 8744: loss: 0.072148, loss_s1: 0.062673, loss_fp: 0.000804, loss_freq: 0.025406
[16:04:58.800] iteration 8745: loss: 0.065888, loss_s1: 0.064250, loss_fp: 0.000581, loss_freq: 0.019494
[16:04:59.423] iteration 8746: loss: 0.072283, loss_s1: 0.029121, loss_fp: 0.009185, loss_freq: 0.032305
[16:05:00.048] iteration 8747: loss: 0.065693, loss_s1: 0.030480, loss_fp: 0.001523, loss_freq: 0.031849
[16:05:00.672] iteration 8748: loss: 0.118189, loss_s1: 0.066514, loss_fp: 0.007030, loss_freq: 0.034399
[16:05:01.299] iteration 8749: loss: 0.055416, loss_s1: 0.034662, loss_fp: 0.000704, loss_freq: 0.011331
[16:05:01.927] iteration 8750: loss: 0.151347, loss_s1: 0.168121, loss_fp: 0.001818, loss_freq: 0.070055
[16:05:02.551] iteration 8751: loss: 0.056080, loss_s1: 0.032856, loss_fp: 0.007849, loss_freq: 0.007779
[16:05:03.175] iteration 8752: loss: 0.091223, loss_s1: 0.028297, loss_fp: 0.000653, loss_freq: 0.029314
[16:05:03.822] iteration 8753: loss: 0.064487, loss_s1: 0.050446, loss_fp: 0.000958, loss_freq: 0.006198
[16:05:04.466] iteration 8754: loss: 0.058945, loss_s1: 0.055755, loss_fp: 0.000857, loss_freq: 0.018040
[16:05:05.103] iteration 8755: loss: 0.084874, loss_s1: 0.063266, loss_fp: 0.000927, loss_freq: 0.042253
[16:05:05.742] iteration 8756: loss: 0.059340, loss_s1: 0.047703, loss_fp: 0.002803, loss_freq: 0.007455
[16:05:06.377] iteration 8757: loss: 0.058567, loss_s1: 0.040548, loss_fp: 0.000491, loss_freq: 0.013218
[16:05:07.008] iteration 8758: loss: 0.076442, loss_s1: 0.056686, loss_fp: 0.001403, loss_freq: 0.010612
[16:05:07.632] iteration 8759: loss: 0.081086, loss_s1: 0.073636, loss_fp: 0.008127, loss_freq: 0.032196
[16:05:08.260] iteration 8760: loss: 0.143363, loss_s1: 0.068516, loss_fp: 0.003249, loss_freq: 0.115637
[16:05:08.891] iteration 8761: loss: 0.074248, loss_s1: 0.038867, loss_fp: 0.002768, loss_freq: 0.045373
[16:05:09.515] iteration 8762: loss: 0.091478, loss_s1: 0.080457, loss_fp: 0.007611, loss_freq: 0.052959
[16:05:10.147] iteration 8763: loss: 0.072143, loss_s1: 0.018471, loss_fp: 0.009107, loss_freq: 0.054939
[16:05:10.778] iteration 8764: loss: 0.095510, loss_s1: 0.052495, loss_fp: 0.001635, loss_freq: 0.035876
[16:05:11.407] iteration 8765: loss: 0.093755, loss_s1: 0.068463, loss_fp: 0.010372, loss_freq: 0.064083
[16:05:12.063] iteration 8766: loss: 0.075715, loss_s1: 0.069379, loss_fp: 0.003150, loss_freq: 0.033013
[16:05:12.719] iteration 8767: loss: 0.091061, loss_s1: 0.016494, loss_fp: 0.001798, loss_freq: 0.066789
[16:05:13.382] iteration 8768: loss: 0.067921, loss_s1: 0.065114, loss_fp: 0.000434, loss_freq: 0.008970
[16:05:14.041] iteration 8769: loss: 0.107669, loss_s1: 0.107080, loss_fp: 0.001959, loss_freq: 0.034403
[16:05:14.714] iteration 8770: loss: 0.110121, loss_s1: 0.086285, loss_fp: 0.001771, loss_freq: 0.051013
[16:05:15.364] iteration 8771: loss: 0.110221, loss_s1: 0.081287, loss_fp: 0.002189, loss_freq: 0.100680
[16:05:15.987] iteration 8772: loss: 0.071789, loss_s1: 0.064631, loss_fp: 0.001145, loss_freq: 0.032712
[16:05:16.617] iteration 8773: loss: 0.068443, loss_s1: 0.040310, loss_fp: 0.001103, loss_freq: 0.025718
[16:05:17.244] iteration 8774: loss: 0.096918, loss_s1: 0.079891, loss_fp: 0.000928, loss_freq: 0.044198
[16:05:17.871] iteration 8775: loss: 0.100205, loss_s1: 0.071911, loss_fp: 0.005019, loss_freq: 0.042537
[16:05:18.498] iteration 8776: loss: 0.082129, loss_s1: 0.061631, loss_fp: 0.011862, loss_freq: 0.040597
[16:05:19.122] iteration 8777: loss: 0.168214, loss_s1: 0.149391, loss_fp: 0.003966, loss_freq: 0.133864
[16:05:19.750] iteration 8778: loss: 0.080130, loss_s1: 0.023075, loss_fp: 0.003302, loss_freq: 0.028986
[16:05:20.374] iteration 8779: loss: 0.181021, loss_s1: 0.137203, loss_fp: 0.007536, loss_freq: 0.163436
[16:05:21.004] iteration 8780: loss: 0.054629, loss_s1: 0.027348, loss_fp: 0.000960, loss_freq: 0.026285
[16:05:21.639] iteration 8781: loss: 0.091348, loss_s1: 0.039128, loss_fp: 0.000405, loss_freq: 0.065500
[16:05:22.263] iteration 8782: loss: 0.067373, loss_s1: 0.056188, loss_fp: 0.000676, loss_freq: 0.005544
[16:05:22.888] iteration 8783: loss: 0.059748, loss_s1: 0.029345, loss_fp: 0.000609, loss_freq: 0.037748
[16:05:23.510] iteration 8784: loss: 0.123722, loss_s1: 0.046588, loss_fp: 0.002347, loss_freq: 0.044134
[16:05:24.135] iteration 8785: loss: 0.067872, loss_s1: 0.029763, loss_fp: 0.000712, loss_freq: 0.022436
[16:05:24.773] iteration 8786: loss: 0.079915, loss_s1: 0.040742, loss_fp: 0.001357, loss_freq: 0.012261
[16:05:25.404] iteration 8787: loss: 0.165117, loss_s1: 0.095780, loss_fp: 0.000395, loss_freq: 0.022283
[16:05:26.038] iteration 8788: loss: 0.113882, loss_s1: 0.099317, loss_fp: 0.000360, loss_freq: 0.034156
[16:05:26.667] iteration 8789: loss: 0.081079, loss_s1: 0.085255, loss_fp: 0.002245, loss_freq: 0.031874
[16:05:27.296] iteration 8790: loss: 0.055432, loss_s1: 0.034588, loss_fp: 0.001473, loss_freq: 0.011224
[16:05:27.928] iteration 8791: loss: 0.053123, loss_s1: 0.036353, loss_fp: 0.000738, loss_freq: 0.018496
[16:05:28.554] iteration 8792: loss: 0.066311, loss_s1: 0.024019, loss_fp: 0.000328, loss_freq: 0.014408
[16:05:29.187] iteration 8793: loss: 0.096961, loss_s1: 0.060248, loss_fp: 0.004363, loss_freq: 0.027996
[16:05:29.825] iteration 8794: loss: 0.073790, loss_s1: 0.070448, loss_fp: 0.009431, loss_freq: 0.014930
[16:05:30.449] iteration 8795: loss: 0.070850, loss_s1: 0.059671, loss_fp: 0.001615, loss_freq: 0.013318
[16:05:31.076] iteration 8796: loss: 0.087817, loss_s1: 0.040822, loss_fp: 0.001564, loss_freq: 0.042929
[16:05:31.705] iteration 8797: loss: 0.154273, loss_s1: 0.048921, loss_fp: 0.009338, loss_freq: 0.110085
[16:05:32.331] iteration 8798: loss: 0.105379, loss_s1: 0.064698, loss_fp: 0.006588, loss_freq: 0.075388
[16:05:32.953] iteration 8799: loss: 0.107708, loss_s1: 0.051885, loss_fp: 0.000757, loss_freq: 0.026878
[16:05:33.575] iteration 8800: loss: 0.067328, loss_s1: 0.034293, loss_fp: 0.008137, loss_freq: 0.028512
[16:05:36.755] iteration 8800 : mean_dice : 0.691878
[16:05:37.404] iteration 8801: loss: 0.095426, loss_s1: 0.043478, loss_fp: 0.003340, loss_freq: 0.032887
[16:05:38.031] iteration 8802: loss: 0.130351, loss_s1: 0.112792, loss_fp: 0.007571, loss_freq: 0.049003
[16:05:38.657] iteration 8803: loss: 0.150311, loss_s1: 0.052270, loss_fp: 0.006370, loss_freq: 0.154530
[16:05:39.285] iteration 8804: loss: 0.097444, loss_s1: 0.093843, loss_fp: 0.002252, loss_freq: 0.028923
[16:05:39.924] iteration 8805: loss: 0.054207, loss_s1: 0.016831, loss_fp: 0.003230, loss_freq: 0.017448
[16:05:40.547] iteration 8806: loss: 0.112026, loss_s1: 0.076846, loss_fp: 0.003773, loss_freq: 0.062128
[16:05:41.178] iteration 8807: loss: 0.095927, loss_s1: 0.054005, loss_fp: 0.002382, loss_freq: 0.062930
[16:05:41.805] iteration 8808: loss: 0.061850, loss_s1: 0.027350, loss_fp: 0.002026, loss_freq: 0.040840
[16:05:42.430] iteration 8809: loss: 0.050900, loss_s1: 0.041321, loss_fp: 0.003339, loss_freq: 0.007242
[16:05:43.058] iteration 8810: loss: 0.094517, loss_s1: 0.066029, loss_fp: 0.006018, loss_freq: 0.031643
[16:05:43.689] iteration 8811: loss: 0.088952, loss_s1: 0.055329, loss_fp: 0.013414, loss_freq: 0.047268
[16:05:44.316] iteration 8812: loss: 0.072706, loss_s1: 0.048496, loss_fp: 0.001331, loss_freq: 0.037865
[16:05:44.946] iteration 8813: loss: 0.088365, loss_s1: 0.088052, loss_fp: 0.001548, loss_freq: 0.021210
[16:05:45.571] iteration 8814: loss: 0.105616, loss_s1: 0.036713, loss_fp: 0.007705, loss_freq: 0.086663
[16:05:46.190] iteration 8815: loss: 0.114713, loss_s1: 0.066407, loss_fp: 0.001527, loss_freq: 0.109655
[16:05:47.088] iteration 8816: loss: 0.087092, loss_s1: 0.051673, loss_fp: 0.001826, loss_freq: 0.010663
[16:05:47.901] iteration 8817: loss: 0.087239, loss_s1: 0.075130, loss_fp: 0.007611, loss_freq: 0.028350
[16:05:48.657] iteration 8818: loss: 0.071402, loss_s1: 0.064723, loss_fp: 0.001689, loss_freq: 0.003458
[16:05:49.301] iteration 8819: loss: 0.107798, loss_s1: 0.066472, loss_fp: 0.001931, loss_freq: 0.044580
[16:05:49.923] iteration 8820: loss: 0.078817, loss_s1: 0.042479, loss_fp: 0.002148, loss_freq: 0.024304
[16:05:50.584] iteration 8821: loss: 0.060317, loss_s1: 0.035112, loss_fp: 0.000636, loss_freq: 0.013565
[16:05:51.212] iteration 8822: loss: 0.178150, loss_s1: 0.136412, loss_fp: 0.001015, loss_freq: 0.121445
[16:05:51.838] iteration 8823: loss: 0.049818, loss_s1: 0.023900, loss_fp: 0.000822, loss_freq: 0.013089
[16:05:52.465] iteration 8824: loss: 0.071832, loss_s1: 0.063845, loss_fp: 0.009449, loss_freq: 0.023672
[16:05:53.093] iteration 8825: loss: 0.093829, loss_s1: 0.071355, loss_fp: 0.002439, loss_freq: 0.058862
[16:05:53.717] iteration 8826: loss: 0.098363, loss_s1: 0.059479, loss_fp: 0.000904, loss_freq: 0.068277
[16:05:54.350] iteration 8827: loss: 0.084129, loss_s1: 0.082900, loss_fp: 0.002477, loss_freq: 0.008568
[16:05:54.976] iteration 8828: loss: 0.081619, loss_s1: 0.036708, loss_fp: 0.004538, loss_freq: 0.029584
[16:05:55.600] iteration 8829: loss: 0.107817, loss_s1: 0.110162, loss_fp: 0.004023, loss_freq: 0.042156
[16:05:56.227] iteration 8830: loss: 0.069352, loss_s1: 0.088258, loss_fp: 0.000727, loss_freq: 0.011728
[16:05:56.851] iteration 8831: loss: 0.065439, loss_s1: 0.042800, loss_fp: 0.002552, loss_freq: 0.028914
[16:05:57.474] iteration 8832: loss: 0.059910, loss_s1: 0.025204, loss_fp: 0.018837, loss_freq: 0.033148
[16:05:58.099] iteration 8833: loss: 0.071611, loss_s1: 0.052651, loss_fp: 0.004894, loss_freq: 0.033706
[16:05:58.722] iteration 8834: loss: 0.113075, loss_s1: 0.066602, loss_fp: 0.002376, loss_freq: 0.041075
[16:05:59.347] iteration 8835: loss: 0.092789, loss_s1: 0.089603, loss_fp: 0.005144, loss_freq: 0.045605
[16:05:59.971] iteration 8836: loss: 0.075767, loss_s1: 0.033497, loss_fp: 0.008121, loss_freq: 0.032959
[16:06:00.593] iteration 8837: loss: 0.094757, loss_s1: 0.044978, loss_fp: 0.002395, loss_freq: 0.078994
[16:06:01.254] iteration 8838: loss: 0.086166, loss_s1: 0.049225, loss_fp: 0.001512, loss_freq: 0.043786
[16:06:01.917] iteration 8839: loss: 0.060892, loss_s1: 0.049327, loss_fp: 0.001499, loss_freq: 0.008539
[16:06:02.563] iteration 8840: loss: 0.079090, loss_s1: 0.049321, loss_fp: 0.010927, loss_freq: 0.017347
[16:06:03.195] iteration 8841: loss: 0.098237, loss_s1: 0.049023, loss_fp: 0.001332, loss_freq: 0.094898
[16:06:03.828] iteration 8842: loss: 0.074739, loss_s1: 0.055251, loss_fp: 0.001827, loss_freq: 0.025006
[16:06:04.457] iteration 8843: loss: 0.072801, loss_s1: 0.026218, loss_fp: 0.001875, loss_freq: 0.037297
[16:06:05.088] iteration 8844: loss: 0.127868, loss_s1: 0.111867, loss_fp: 0.018134, loss_freq: 0.051324
[16:06:05.715] iteration 8845: loss: 0.054803, loss_s1: 0.016944, loss_fp: 0.001109, loss_freq: 0.018998
[16:06:06.394] iteration 8846: loss: 0.072961, loss_s1: 0.048490, loss_fp: 0.008502, loss_freq: 0.042844
[16:06:07.095] iteration 8847: loss: 0.065769, loss_s1: 0.045933, loss_fp: 0.004815, loss_freq: 0.025222
[16:06:07.759] iteration 8848: loss: 0.097180, loss_s1: 0.057285, loss_fp: 0.006586, loss_freq: 0.056351
[16:06:08.427] iteration 8849: loss: 0.050417, loss_s1: 0.020642, loss_fp: 0.001916, loss_freq: 0.015059
[16:06:09.092] iteration 8850: loss: 0.109123, loss_s1: 0.066049, loss_fp: 0.007060, loss_freq: 0.031665
[16:06:09.720] iteration 8851: loss: 0.043893, loss_s1: 0.023071, loss_fp: 0.000950, loss_freq: 0.008756
[16:06:10.350] iteration 8852: loss: 0.109189, loss_s1: 0.089150, loss_fp: 0.004347, loss_freq: 0.037997
[16:06:10.979] iteration 8853: loss: 0.102547, loss_s1: 0.086573, loss_fp: 0.008299, loss_freq: 0.040685
[16:06:11.603] iteration 8854: loss: 0.104419, loss_s1: 0.043802, loss_fp: 0.004545, loss_freq: 0.024913
[16:06:12.226] iteration 8855: loss: 0.129958, loss_s1: 0.095604, loss_fp: 0.002224, loss_freq: 0.099335
[16:06:13.166] iteration 8856: loss: 0.066005, loss_s1: 0.041274, loss_fp: 0.001427, loss_freq: 0.015259
[16:06:13.792] iteration 8857: loss: 0.071175, loss_s1: 0.027614, loss_fp: 0.006218, loss_freq: 0.026136
[16:06:14.418] iteration 8858: loss: 0.079881, loss_s1: 0.044093, loss_fp: 0.002383, loss_freq: 0.053632
[16:06:15.083] iteration 8859: loss: 0.041336, loss_s1: 0.009032, loss_fp: 0.000777, loss_freq: 0.012645
[16:06:15.712] iteration 8860: loss: 0.083693, loss_s1: 0.045251, loss_fp: 0.001756, loss_freq: 0.022773
[16:06:16.342] iteration 8861: loss: 0.166573, loss_s1: 0.074442, loss_fp: 0.002596, loss_freq: 0.045333
[16:06:16.971] iteration 8862: loss: 0.067886, loss_s1: 0.052826, loss_fp: 0.001850, loss_freq: 0.037419
[16:06:17.593] iteration 8863: loss: 0.078418, loss_s1: 0.049794, loss_fp: 0.004359, loss_freq: 0.054743
[16:06:18.221] iteration 8864: loss: 0.090308, loss_s1: 0.077795, loss_fp: 0.003875, loss_freq: 0.040622
[16:06:18.844] iteration 8865: loss: 0.100290, loss_s1: 0.068713, loss_fp: 0.004891, loss_freq: 0.026155
[16:06:19.516] iteration 8866: loss: 0.063185, loss_s1: 0.049140, loss_fp: 0.001918, loss_freq: 0.015147
[16:06:20.141] iteration 8867: loss: 0.091010, loss_s1: 0.073931, loss_fp: 0.003404, loss_freq: 0.043366
[16:06:20.789] iteration 8868: loss: 0.108947, loss_s1: 0.056751, loss_fp: 0.047831, loss_freq: 0.056401
[16:06:21.416] iteration 8869: loss: 0.093725, loss_s1: 0.062398, loss_fp: 0.007143, loss_freq: 0.059587
[16:06:22.074] iteration 8870: loss: 0.071835, loss_s1: 0.066281, loss_fp: 0.005986, loss_freq: 0.019096
[16:06:22.698] iteration 8871: loss: 0.122742, loss_s1: 0.128450, loss_fp: 0.008298, loss_freq: 0.050046
[16:06:23.325] iteration 8872: loss: 0.072426, loss_s1: 0.046782, loss_fp: 0.002729, loss_freq: 0.037921
[16:06:23.950] iteration 8873: loss: 0.101061, loss_s1: 0.089447, loss_fp: 0.001817, loss_freq: 0.049272
[16:06:24.571] iteration 8874: loss: 0.103115, loss_s1: 0.042721, loss_fp: 0.002319, loss_freq: 0.026377
[16:06:25.198] iteration 8875: loss: 0.067449, loss_s1: 0.034046, loss_fp: 0.000964, loss_freq: 0.040973
[16:06:25.825] iteration 8876: loss: 0.039644, loss_s1: 0.019284, loss_fp: 0.000881, loss_freq: 0.004899
[16:06:26.453] iteration 8877: loss: 0.089177, loss_s1: 0.060848, loss_fp: 0.001405, loss_freq: 0.022518
[16:06:27.076] iteration 8878: loss: 0.085851, loss_s1: 0.052031, loss_fp: 0.010071, loss_freq: 0.018264
[16:06:27.701] iteration 8879: loss: 0.191557, loss_s1: 0.124198, loss_fp: 0.003501, loss_freq: 0.194412
[16:06:28.328] iteration 8880: loss: 0.051587, loss_s1: 0.045362, loss_fp: 0.000757, loss_freq: 0.017235
[16:06:28.955] iteration 8881: loss: 0.114836, loss_s1: 0.078845, loss_fp: 0.001938, loss_freq: 0.050938
[16:06:29.583] iteration 8882: loss: 0.073563, loss_s1: 0.049800, loss_fp: 0.002343, loss_freq: 0.033508
[16:06:30.212] iteration 8883: loss: 0.142419, loss_s1: 0.131298, loss_fp: 0.013186, loss_freq: 0.056823
[16:06:30.835] iteration 8884: loss: 0.074553, loss_s1: 0.060542, loss_fp: 0.007347, loss_freq: 0.031538
[16:06:31.459] iteration 8885: loss: 0.069954, loss_s1: 0.069401, loss_fp: 0.000737, loss_freq: 0.010575
[16:06:32.085] iteration 8886: loss: 0.077928, loss_s1: 0.064857, loss_fp: 0.006995, loss_freq: 0.018355
[16:06:32.706] iteration 8887: loss: 0.108547, loss_s1: 0.037534, loss_fp: 0.003377, loss_freq: 0.031324
[16:06:33.326] iteration 8888: loss: 0.057351, loss_s1: 0.027234, loss_fp: 0.002418, loss_freq: 0.023510
[16:06:33.949] iteration 8889: loss: 0.048957, loss_s1: 0.029897, loss_fp: 0.001647, loss_freq: 0.011397
[16:06:34.571] iteration 8890: loss: 0.098727, loss_s1: 0.062775, loss_fp: 0.001659, loss_freq: 0.037483
[16:06:35.199] iteration 8891: loss: 0.104154, loss_s1: 0.076452, loss_fp: 0.007226, loss_freq: 0.040744
[16:06:35.820] iteration 8892: loss: 0.129620, loss_s1: 0.060410, loss_fp: 0.008209, loss_freq: 0.065481
[16:06:36.443] iteration 8893: loss: 0.089624, loss_s1: 0.058874, loss_fp: 0.005591, loss_freq: 0.021393
[16:06:37.067] iteration 8894: loss: 0.132587, loss_s1: 0.135087, loss_fp: 0.004148, loss_freq: 0.069022
[16:06:37.689] iteration 8895: loss: 0.086680, loss_s1: 0.066498, loss_fp: 0.010177, loss_freq: 0.040095
[16:06:38.317] iteration 8896: loss: 0.093867, loss_s1: 0.063381, loss_fp: 0.012532, loss_freq: 0.023807
[16:06:38.947] iteration 8897: loss: 0.104667, loss_s1: 0.074836, loss_fp: 0.016667, loss_freq: 0.058570
[16:06:39.570] iteration 8898: loss: 0.064510, loss_s1: 0.060054, loss_fp: 0.001991, loss_freq: 0.022707
[16:06:40.195] iteration 8899: loss: 0.076530, loss_s1: 0.052384, loss_fp: 0.002741, loss_freq: 0.036726
[16:06:40.817] iteration 8900: loss: 0.061050, loss_s1: 0.047082, loss_fp: 0.004801, loss_freq: 0.019936
[16:06:41.445] iteration 8901: loss: 0.087816, loss_s1: 0.036004, loss_fp: 0.002594, loss_freq: 0.016301
[16:06:42.072] iteration 8902: loss: 0.050312, loss_s1: 0.028707, loss_fp: 0.000658, loss_freq: 0.010019
[16:06:42.723] iteration 8903: loss: 0.088557, loss_s1: 0.070354, loss_fp: 0.009161, loss_freq: 0.036288
[16:06:43.383] iteration 8904: loss: 0.072509, loss_s1: 0.052525, loss_fp: 0.008248, loss_freq: 0.007674
[16:06:44.044] iteration 8905: loss: 0.095151, loss_s1: 0.065396, loss_fp: 0.003451, loss_freq: 0.066279
[16:06:44.708] iteration 8906: loss: 0.140491, loss_s1: 0.135179, loss_fp: 0.009472, loss_freq: 0.074022
[16:06:45.370] iteration 8907: loss: 0.079908, loss_s1: 0.016610, loss_fp: 0.005879, loss_freq: 0.026371
[16:06:46.000] iteration 8908: loss: 0.090463, loss_s1: 0.064767, loss_fp: 0.006462, loss_freq: 0.054881
[16:06:46.628] iteration 8909: loss: 0.073934, loss_s1: 0.039840, loss_fp: 0.002742, loss_freq: 0.063198
[16:06:47.256] iteration 8910: loss: 0.081455, loss_s1: 0.034814, loss_fp: 0.001818, loss_freq: 0.018939
[16:06:47.888] iteration 8911: loss: 0.102011, loss_s1: 0.116264, loss_fp: 0.000605, loss_freq: 0.025952
[16:06:48.523] iteration 8912: loss: 0.037932, loss_s1: 0.012445, loss_fp: 0.000770, loss_freq: 0.004378
[16:06:49.208] iteration 8913: loss: 0.061410, loss_s1: 0.022917, loss_fp: 0.004168, loss_freq: 0.021279
[16:06:49.867] iteration 8914: loss: 0.056901, loss_s1: 0.036526, loss_fp: 0.004135, loss_freq: 0.009595
[16:06:50.524] iteration 8915: loss: 0.073516, loss_s1: 0.052134, loss_fp: 0.000700, loss_freq: 0.019187
[16:06:51.177] iteration 8916: loss: 0.066352, loss_s1: 0.044594, loss_fp: 0.008807, loss_freq: 0.027877
[16:06:51.800] iteration 8917: loss: 0.069704, loss_s1: 0.078970, loss_fp: 0.002834, loss_freq: 0.006086
[16:06:52.431] iteration 8918: loss: 0.082851, loss_s1: 0.062005, loss_fp: 0.006021, loss_freq: 0.021995
[16:06:53.061] iteration 8919: loss: 0.059988, loss_s1: 0.047058, loss_fp: 0.001993, loss_freq: 0.022606
[16:06:53.698] iteration 8920: loss: 0.104845, loss_s1: 0.080313, loss_fp: 0.001788, loss_freq: 0.023154
[16:06:54.324] iteration 8921: loss: 0.113064, loss_s1: 0.064881, loss_fp: 0.003995, loss_freq: 0.086889
[16:06:54.954] iteration 8922: loss: 0.094956, loss_s1: 0.022331, loss_fp: 0.001466, loss_freq: 0.049633
[16:06:55.578] iteration 8923: loss: 0.060564, loss_s1: 0.039898, loss_fp: 0.001502, loss_freq: 0.044437
[16:06:56.205] iteration 8924: loss: 0.061163, loss_s1: 0.045591, loss_fp: 0.004474, loss_freq: 0.026032
[16:06:56.834] iteration 8925: loss: 0.129651, loss_s1: 0.082490, loss_fp: 0.006282, loss_freq: 0.050554
[16:06:57.459] iteration 8926: loss: 0.100222, loss_s1: 0.039164, loss_fp: 0.014216, loss_freq: 0.074986
[16:06:58.082] iteration 8927: loss: 0.084293, loss_s1: 0.030771, loss_fp: 0.004043, loss_freq: 0.045242
[16:06:58.739] iteration 8928: loss: 0.110249, loss_s1: 0.084230, loss_fp: 0.001810, loss_freq: 0.035902
[16:06:59.399] iteration 8929: loss: 0.056055, loss_s1: 0.030719, loss_fp: 0.001497, loss_freq: 0.026815
[16:07:00.058] iteration 8930: loss: 0.113021, loss_s1: 0.098610, loss_fp: 0.001716, loss_freq: 0.049023
[16:07:00.706] iteration 8931: loss: 0.084363, loss_s1: 0.050819, loss_fp: 0.010684, loss_freq: 0.035306
[16:07:01.330] iteration 8932: loss: 0.090477, loss_s1: 0.061233, loss_fp: 0.003970, loss_freq: 0.054154
[16:07:01.950] iteration 8933: loss: 0.074496, loss_s1: 0.052921, loss_fp: 0.006710, loss_freq: 0.030113
[16:07:02.580] iteration 8934: loss: 0.060760, loss_s1: 0.027611, loss_fp: 0.002547, loss_freq: 0.023736
[16:07:03.209] iteration 8935: loss: 0.099339, loss_s1: 0.043701, loss_fp: 0.001303, loss_freq: 0.051774
[16:07:03.831] iteration 8936: loss: 0.089610, loss_s1: 0.058315, loss_fp: 0.000900, loss_freq: 0.043317
[16:07:04.452] iteration 8937: loss: 0.095454, loss_s1: 0.081304, loss_fp: 0.002640, loss_freq: 0.039221
[16:07:05.076] iteration 8938: loss: 0.105770, loss_s1: 0.070206, loss_fp: 0.003036, loss_freq: 0.067861
[16:07:05.700] iteration 8939: loss: 0.116245, loss_s1: 0.076605, loss_fp: 0.003758, loss_freq: 0.049475
[16:07:06.323] iteration 8940: loss: 0.140861, loss_s1: 0.122479, loss_fp: 0.003799, loss_freq: 0.104480
[16:07:06.947] iteration 8941: loss: 0.061093, loss_s1: 0.051649, loss_fp: 0.003701, loss_freq: 0.022736
[16:07:07.578] iteration 8942: loss: 0.127582, loss_s1: 0.041239, loss_fp: 0.001572, loss_freq: 0.044901
[16:07:08.208] iteration 8943: loss: 0.062309, loss_s1: 0.051680, loss_fp: 0.004024, loss_freq: 0.018172
[16:07:08.832] iteration 8944: loss: 0.136455, loss_s1: 0.116362, loss_fp: 0.010269, loss_freq: 0.054605
[16:07:09.455] iteration 8945: loss: 0.052564, loss_s1: 0.014918, loss_fp: 0.001293, loss_freq: 0.021418
[16:07:10.084] iteration 8946: loss: 0.071132, loss_s1: 0.059035, loss_fp: 0.004145, loss_freq: 0.011378
[16:07:10.707] iteration 8947: loss: 0.085086, loss_s1: 0.053658, loss_fp: 0.005281, loss_freq: 0.040590
[16:07:11.331] iteration 8948: loss: 0.104889, loss_s1: 0.064003, loss_fp: 0.003915, loss_freq: 0.034136
[16:07:11.959] iteration 8949: loss: 0.055667, loss_s1: 0.031165, loss_fp: 0.001593, loss_freq: 0.009261
[16:07:12.584] iteration 8950: loss: 0.062661, loss_s1: 0.061070, loss_fp: 0.006780, loss_freq: 0.012614
[16:07:13.234] iteration 8951: loss: 0.073617, loss_s1: 0.049877, loss_fp: 0.000808, loss_freq: 0.043132
[16:07:13.856] iteration 8952: loss: 0.059956, loss_s1: 0.018156, loss_fp: 0.001504, loss_freq: 0.019150
[16:07:14.482] iteration 8953: loss: 0.061403, loss_s1: 0.009021, loss_fp: 0.000344, loss_freq: 0.011050
[16:07:15.158] iteration 8954: loss: 0.067487, loss_s1: 0.041224, loss_fp: 0.002304, loss_freq: 0.015892
[16:07:15.816] iteration 8955: loss: 0.047575, loss_s1: 0.033161, loss_fp: 0.007204, loss_freq: 0.005906
[16:07:16.476] iteration 8956: loss: 0.090232, loss_s1: 0.057222, loss_fp: 0.001924, loss_freq: 0.019246
[16:07:17.139] iteration 8957: loss: 0.099214, loss_s1: 0.030341, loss_fp: 0.004140, loss_freq: 0.058176
[16:07:17.763] iteration 8958: loss: 0.119138, loss_s1: 0.064756, loss_fp: 0.007736, loss_freq: 0.044265
[16:07:18.388] iteration 8959: loss: 0.079261, loss_s1: 0.062452, loss_fp: 0.000932, loss_freq: 0.037666
[16:07:19.018] iteration 8960: loss: 0.095400, loss_s1: 0.032438, loss_fp: 0.007387, loss_freq: 0.045883
[16:07:19.647] iteration 8961: loss: 0.053888, loss_s1: 0.025800, loss_fp: 0.001036, loss_freq: 0.022331
[16:07:20.275] iteration 8962: loss: 0.078721, loss_s1: 0.032321, loss_fp: 0.001357, loss_freq: 0.017207
[16:07:20.903] iteration 8963: loss: 0.150703, loss_s1: 0.106542, loss_fp: 0.001044, loss_freq: 0.116206
[16:07:21.529] iteration 8964: loss: 0.255309, loss_s1: 0.187096, loss_fp: 0.007338, loss_freq: 0.194410
[16:07:22.155] iteration 8965: loss: 0.097111, loss_s1: 0.080304, loss_fp: 0.001904, loss_freq: 0.042799
[16:07:22.782] iteration 8966: loss: 0.093887, loss_s1: 0.026419, loss_fp: 0.000693, loss_freq: 0.050210
[16:07:23.415] iteration 8967: loss: 0.109170, loss_s1: 0.050775, loss_fp: 0.004199, loss_freq: 0.079133
[16:07:24.036] iteration 8968: loss: 0.082694, loss_s1: 0.030790, loss_fp: 0.003707, loss_freq: 0.049460
[16:07:24.659] iteration 8969: loss: 0.074506, loss_s1: 0.053952, loss_fp: 0.003423, loss_freq: 0.026887
[16:07:25.312] iteration 8970: loss: 0.039577, loss_s1: 0.018533, loss_fp: 0.001417, loss_freq: 0.004836
[16:07:25.934] iteration 8971: loss: 0.112908, loss_s1: 0.053932, loss_fp: 0.001914, loss_freq: 0.083626
[16:07:26.560] iteration 8972: loss: 0.084797, loss_s1: 0.054834, loss_fp: 0.004951, loss_freq: 0.033630
[16:07:27.184] iteration 8973: loss: 0.051038, loss_s1: 0.024479, loss_fp: 0.000547, loss_freq: 0.024679
[16:07:27.806] iteration 8974: loss: 0.067404, loss_s1: 0.028729, loss_fp: 0.002223, loss_freq: 0.025634
[16:07:28.430] iteration 8975: loss: 0.094977, loss_s1: 0.050503, loss_fp: 0.004273, loss_freq: 0.086018
[16:07:29.054] iteration 8976: loss: 0.079110, loss_s1: 0.031588, loss_fp: 0.002995, loss_freq: 0.076583
[16:07:29.679] iteration 8977: loss: 0.077241, loss_s1: 0.030152, loss_fp: 0.000741, loss_freq: 0.008452
[16:07:30.302] iteration 8978: loss: 0.092899, loss_s1: 0.094292, loss_fp: 0.001152, loss_freq: 0.025105
[16:07:30.924] iteration 8979: loss: 0.065823, loss_s1: 0.043913, loss_fp: 0.001125, loss_freq: 0.017286
[16:07:31.550] iteration 8980: loss: 0.094915, loss_s1: 0.036909, loss_fp: 0.001989, loss_freq: 0.057454
[16:07:32.171] iteration 8981: loss: 0.098384, loss_s1: 0.033079, loss_fp: 0.003027, loss_freq: 0.041689
[16:07:32.796] iteration 8982: loss: 0.059732, loss_s1: 0.031368, loss_fp: 0.001898, loss_freq: 0.009752
[16:07:33.423] iteration 8983: loss: 0.180143, loss_s1: 0.115344, loss_fp: 0.003090, loss_freq: 0.098594
[16:07:34.047] iteration 8984: loss: 0.067317, loss_s1: 0.029550, loss_fp: 0.001361, loss_freq: 0.011151
[16:07:34.671] iteration 8985: loss: 0.076679, loss_s1: 0.062388, loss_fp: 0.005389, loss_freq: 0.023098
[16:07:35.302] iteration 8986: loss: 0.103969, loss_s1: 0.102381, loss_fp: 0.001463, loss_freq: 0.049968
[16:07:35.931] iteration 8987: loss: 0.097465, loss_s1: 0.079272, loss_fp: 0.010597, loss_freq: 0.037836
[16:07:36.556] iteration 8988: loss: 0.059285, loss_s1: 0.039797, loss_fp: 0.004520, loss_freq: 0.028910
[16:07:37.180] iteration 8989: loss: 0.049385, loss_s1: 0.029704, loss_fp: 0.005025, loss_freq: 0.017919
[16:07:37.808] iteration 8990: loss: 0.105724, loss_s1: 0.074786, loss_fp: 0.003929, loss_freq: 0.053972
[16:07:38.437] iteration 8991: loss: 0.041949, loss_s1: 0.025052, loss_fp: 0.002135, loss_freq: 0.008924
[16:07:39.064] iteration 8992: loss: 0.067934, loss_s1: 0.022183, loss_fp: 0.002811, loss_freq: 0.046208
[16:07:39.687] iteration 8993: loss: 0.061913, loss_s1: 0.035228, loss_fp: 0.010707, loss_freq: 0.019318
[16:07:40.315] iteration 8994: loss: 0.063051, loss_s1: 0.041770, loss_fp: 0.008768, loss_freq: 0.022739
[16:07:40.941] iteration 8995: loss: 0.103750, loss_s1: 0.084701, loss_fp: 0.001629, loss_freq: 0.031941
[16:07:41.571] iteration 8996: loss: 0.134641, loss_s1: 0.116569, loss_fp: 0.018757, loss_freq: 0.039158
[16:07:42.232] iteration 8997: loss: 0.090888, loss_s1: 0.054045, loss_fp: 0.004987, loss_freq: 0.038201
[16:07:42.893] iteration 8998: loss: 0.093231, loss_s1: 0.071980, loss_fp: 0.006532, loss_freq: 0.015689
[16:07:43.552] iteration 8999: loss: 0.092771, loss_s1: 0.088899, loss_fp: 0.005691, loss_freq: 0.038903
[16:07:44.215] iteration 9000: loss: 0.062384, loss_s1: 0.032867, loss_fp: 0.001845, loss_freq: 0.019340
[16:07:47.655] iteration 9000 : mean_dice : 0.685053
[16:07:48.332] iteration 9001: loss: 0.069437, loss_s1: 0.031977, loss_fp: 0.012032, loss_freq: 0.018077
[16:07:48.989] iteration 9002: loss: 0.102078, loss_s1: 0.058650, loss_fp: 0.003415, loss_freq: 0.088210
[16:07:49.648] iteration 9003: loss: 0.059716, loss_s1: 0.048771, loss_fp: 0.003991, loss_freq: 0.021610
[16:07:50.302] iteration 9004: loss: 0.079813, loss_s1: 0.041494, loss_fp: 0.002425, loss_freq: 0.028557
[16:07:50.964] iteration 9005: loss: 0.083271, loss_s1: 0.057933, loss_fp: 0.001907, loss_freq: 0.025593
[16:07:51.591] iteration 9006: loss: 0.120880, loss_s1: 0.051053, loss_fp: 0.005423, loss_freq: 0.066841
[16:07:52.217] iteration 9007: loss: 0.086995, loss_s1: 0.056197, loss_fp: 0.003502, loss_freq: 0.048953
[16:07:53.006] iteration 9008: loss: 0.068769, loss_s1: 0.057911, loss_fp: 0.001404, loss_freq: 0.027547
[16:07:53.694] iteration 9009: loss: 0.077491, loss_s1: 0.059688, loss_fp: 0.002073, loss_freq: 0.041788
[16:07:54.324] iteration 9010: loss: 0.069018, loss_s1: 0.033469, loss_fp: 0.001520, loss_freq: 0.017073
[16:07:55.031] iteration 9011: loss: 0.073445, loss_s1: 0.043334, loss_fp: 0.001629, loss_freq: 0.021014
[16:07:55.714] iteration 9012: loss: 0.057611, loss_s1: 0.023567, loss_fp: 0.001123, loss_freq: 0.027900
[16:07:56.368] iteration 9013: loss: 0.113193, loss_s1: 0.061488, loss_fp: 0.001219, loss_freq: 0.044440
[16:07:57.030] iteration 9014: loss: 0.112486, loss_s1: 0.081619, loss_fp: 0.013674, loss_freq: 0.050679
[16:07:57.682] iteration 9015: loss: 0.048233, loss_s1: 0.029861, loss_fp: 0.003563, loss_freq: 0.015298
[16:07:58.334] iteration 9016: loss: 0.077494, loss_s1: 0.056837, loss_fp: 0.001815, loss_freq: 0.023525
[16:07:59.309] iteration 9017: loss: 0.055242, loss_s1: 0.012218, loss_fp: 0.003136, loss_freq: 0.030535
[16:07:59.952] iteration 9018: loss: 0.100305, loss_s1: 0.087632, loss_fp: 0.003835, loss_freq: 0.029341
[16:08:00.592] iteration 9019: loss: 0.087396, loss_s1: 0.052490, loss_fp: 0.003211, loss_freq: 0.026580
[16:08:01.252] iteration 9020: loss: 0.066143, loss_s1: 0.032637, loss_fp: 0.000351, loss_freq: 0.010414
[16:08:01.909] iteration 9021: loss: 0.070258, loss_s1: 0.047848, loss_fp: 0.002478, loss_freq: 0.018294
[16:08:02.565] iteration 9022: loss: 0.123153, loss_s1: 0.030194, loss_fp: 0.004090, loss_freq: 0.036238
[16:08:03.228] iteration 9023: loss: 0.072764, loss_s1: 0.067962, loss_fp: 0.002227, loss_freq: 0.019492
[16:08:03.894] iteration 9024: loss: 0.061774, loss_s1: 0.047204, loss_fp: 0.001038, loss_freq: 0.039361
[16:08:04.543] iteration 9025: loss: 0.065980, loss_s1: 0.037498, loss_fp: 0.006961, loss_freq: 0.027012
[16:08:05.174] iteration 9026: loss: 0.118289, loss_s1: 0.118003, loss_fp: 0.003274, loss_freq: 0.052506
[16:08:05.804] iteration 9027: loss: 0.052673, loss_s1: 0.017685, loss_fp: 0.003687, loss_freq: 0.009372
[16:08:06.434] iteration 9028: loss: 0.075055, loss_s1: 0.039838, loss_fp: 0.003269, loss_freq: 0.043440
[16:08:07.065] iteration 9029: loss: 0.069596, loss_s1: 0.056878, loss_fp: 0.001685, loss_freq: 0.040012
[16:08:07.704] iteration 9030: loss: 0.103578, loss_s1: 0.041623, loss_fp: 0.001620, loss_freq: 0.040677
[16:08:08.346] iteration 9031: loss: 0.048310, loss_s1: 0.034254, loss_fp: 0.008182, loss_freq: 0.017409
[16:08:08.984] iteration 9032: loss: 0.131371, loss_s1: 0.109419, loss_fp: 0.023588, loss_freq: 0.077322
[16:08:09.627] iteration 9033: loss: 0.082097, loss_s1: 0.077180, loss_fp: 0.004292, loss_freq: 0.013763
[16:08:10.268] iteration 9034: loss: 0.098339, loss_s1: 0.094769, loss_fp: 0.005735, loss_freq: 0.028606
[16:08:10.909] iteration 9035: loss: 0.070219, loss_s1: 0.042417, loss_fp: 0.001764, loss_freq: 0.024702
[16:08:11.546] iteration 9036: loss: 0.117609, loss_s1: 0.046559, loss_fp: 0.004864, loss_freq: 0.040927
[16:08:12.191] iteration 9037: loss: 0.052696, loss_s1: 0.039680, loss_fp: 0.000403, loss_freq: 0.008142
[16:08:12.829] iteration 9038: loss: 0.077287, loss_s1: 0.052485, loss_fp: 0.006242, loss_freq: 0.037289
[16:08:13.471] iteration 9039: loss: 0.077822, loss_s1: 0.047861, loss_fp: 0.001132, loss_freq: 0.034762
[16:08:14.118] iteration 9040: loss: 0.192582, loss_s1: 0.092490, loss_fp: 0.005790, loss_freq: 0.223339
[16:08:14.758] iteration 9041: loss: 0.042163, loss_s1: 0.022356, loss_fp: 0.000711, loss_freq: 0.014171
[16:08:15.399] iteration 9042: loss: 0.087464, loss_s1: 0.077755, loss_fp: 0.005375, loss_freq: 0.034041
[16:08:16.025] iteration 9043: loss: 0.058746, loss_s1: 0.019330, loss_fp: 0.002384, loss_freq: 0.033543
[16:08:16.644] iteration 9044: loss: 0.121540, loss_s1: 0.092606, loss_fp: 0.019732, loss_freq: 0.060005
[16:08:17.267] iteration 9045: loss: 0.076093, loss_s1: 0.058104, loss_fp: 0.005285, loss_freq: 0.047527
[16:08:17.890] iteration 9046: loss: 0.050003, loss_s1: 0.030790, loss_fp: 0.003769, loss_freq: 0.025020
[16:08:18.517] iteration 9047: loss: 0.046128, loss_s1: 0.030263, loss_fp: 0.005496, loss_freq: 0.010995
[16:08:19.145] iteration 9048: loss: 0.092272, loss_s1: 0.031172, loss_fp: 0.004917, loss_freq: 0.042219
[16:08:19.770] iteration 9049: loss: 0.066579, loss_s1: 0.031107, loss_fp: 0.005868, loss_freq: 0.027394
[16:08:20.399] iteration 9050: loss: 0.053535, loss_s1: 0.026416, loss_fp: 0.003725, loss_freq: 0.015201
[16:08:21.025] iteration 9051: loss: 0.097223, loss_s1: 0.055677, loss_fp: 0.009433, loss_freq: 0.037953
[16:08:21.654] iteration 9052: loss: 0.065105, loss_s1: 0.029171, loss_fp: 0.002439, loss_freq: 0.029876
[16:08:22.277] iteration 9053: loss: 0.091740, loss_s1: 0.040289, loss_fp: 0.002292, loss_freq: 0.037227
[16:08:22.901] iteration 9054: loss: 0.091348, loss_s1: 0.052192, loss_fp: 0.010842, loss_freq: 0.040998
[16:08:23.521] iteration 9055: loss: 0.187779, loss_s1: 0.181025, loss_fp: 0.014884, loss_freq: 0.115804
[16:08:24.148] iteration 9056: loss: 0.096962, loss_s1: 0.049546, loss_fp: 0.002985, loss_freq: 0.047690
[16:08:24.774] iteration 9057: loss: 0.066504, loss_s1: 0.055079, loss_fp: 0.001021, loss_freq: 0.018203
[16:08:25.397] iteration 9058: loss: 0.082386, loss_s1: 0.047111, loss_fp: 0.008335, loss_freq: 0.059680
[16:08:26.019] iteration 9059: loss: 0.066759, loss_s1: 0.054955, loss_fp: 0.001390, loss_freq: 0.017476
[16:08:26.644] iteration 9060: loss: 0.081044, loss_s1: 0.049770, loss_fp: 0.001551, loss_freq: 0.048020
[16:08:27.268] iteration 9061: loss: 0.077869, loss_s1: 0.052437, loss_fp: 0.001254, loss_freq: 0.033380
[16:08:27.891] iteration 9062: loss: 0.081050, loss_s1: 0.069722, loss_fp: 0.003190, loss_freq: 0.022116
[16:08:28.515] iteration 9063: loss: 0.072727, loss_s1: 0.051198, loss_fp: 0.007341, loss_freq: 0.031120
[16:08:29.130] iteration 9064: loss: 0.057210, loss_s1: 0.048936, loss_fp: 0.001975, loss_freq: 0.018053
[16:08:29.752] iteration 9065: loss: 0.079777, loss_s1: 0.046868, loss_fp: 0.005176, loss_freq: 0.017773
[16:08:30.380] iteration 9066: loss: 0.078325, loss_s1: 0.064366, loss_fp: 0.003778, loss_freq: 0.038096
[16:08:31.008] iteration 9067: loss: 0.095357, loss_s1: 0.093315, loss_fp: 0.001418, loss_freq: 0.048015
[16:08:31.630] iteration 9068: loss: 0.078798, loss_s1: 0.044906, loss_fp: 0.003585, loss_freq: 0.032716
[16:08:32.255] iteration 9069: loss: 0.094638, loss_s1: 0.023184, loss_fp: 0.002007, loss_freq: 0.088679
[16:08:32.883] iteration 9070: loss: 0.109427, loss_s1: 0.088336, loss_fp: 0.005174, loss_freq: 0.027051
[16:08:33.541] iteration 9071: loss: 0.088501, loss_s1: 0.040859, loss_fp: 0.000305, loss_freq: 0.028775
[16:08:34.167] iteration 9072: loss: 0.089976, loss_s1: 0.076252, loss_fp: 0.002415, loss_freq: 0.021311
[16:08:34.795] iteration 9073: loss: 0.056315, loss_s1: 0.047306, loss_fp: 0.001540, loss_freq: 0.008156
[16:08:35.418] iteration 9074: loss: 0.093900, loss_s1: 0.027285, loss_fp: 0.001181, loss_freq: 0.015827
[16:08:36.053] iteration 9075: loss: 0.035399, loss_s1: 0.016038, loss_fp: 0.001505, loss_freq: 0.006405
[16:08:36.678] iteration 9076: loss: 0.057395, loss_s1: 0.046682, loss_fp: 0.003913, loss_freq: 0.020314
[16:08:37.304] iteration 9077: loss: 0.062225, loss_s1: 0.048683, loss_fp: 0.000814, loss_freq: 0.020168
[16:08:37.930] iteration 9078: loss: 0.062111, loss_s1: 0.029122, loss_fp: 0.005053, loss_freq: 0.027054
[16:08:38.565] iteration 9079: loss: 0.071660, loss_s1: 0.043350, loss_fp: 0.001647, loss_freq: 0.023719
[16:08:39.193] iteration 9080: loss: 0.086524, loss_s1: 0.051596, loss_fp: 0.007136, loss_freq: 0.043632
[16:08:39.819] iteration 9081: loss: 0.069567, loss_s1: 0.048522, loss_fp: 0.002800, loss_freq: 0.013932
[16:08:40.447] iteration 9082: loss: 0.088250, loss_s1: 0.025781, loss_fp: 0.004936, loss_freq: 0.091980
[16:08:41.073] iteration 9083: loss: 0.088776, loss_s1: 0.065628, loss_fp: 0.001236, loss_freq: 0.048596
[16:08:41.695] iteration 9084: loss: 0.066771, loss_s1: 0.052019, loss_fp: 0.002510, loss_freq: 0.031362
[16:08:42.328] iteration 9085: loss: 0.062429, loss_s1: 0.027955, loss_fp: 0.001534, loss_freq: 0.026791
[16:08:42.950] iteration 9086: loss: 0.106796, loss_s1: 0.051690, loss_fp: 0.001476, loss_freq: 0.025511
[16:08:43.574] iteration 9087: loss: 0.089555, loss_s1: 0.050531, loss_fp: 0.010256, loss_freq: 0.054438
[16:08:44.204] iteration 9088: loss: 0.087205, loss_s1: 0.069772, loss_fp: 0.000965, loss_freq: 0.033768
[16:08:44.832] iteration 9089: loss: 0.065896, loss_s1: 0.052462, loss_fp: 0.002306, loss_freq: 0.014813
[16:08:45.453] iteration 9090: loss: 0.073434, loss_s1: 0.046887, loss_fp: 0.008567, loss_freq: 0.032223
[16:08:46.076] iteration 9091: loss: 0.060040, loss_s1: 0.044099, loss_fp: 0.005302, loss_freq: 0.015860
[16:08:46.698] iteration 9092: loss: 0.114172, loss_s1: 0.084853, loss_fp: 0.002737, loss_freq: 0.064845
[16:08:47.326] iteration 9093: loss: 0.082245, loss_s1: 0.050650, loss_fp: 0.003868, loss_freq: 0.045636
[16:08:47.948] iteration 9094: loss: 0.070193, loss_s1: 0.076470, loss_fp: 0.005610, loss_freq: 0.015097
[16:08:48.570] iteration 9095: loss: 0.053245, loss_s1: 0.016083, loss_fp: 0.006430, loss_freq: 0.021561
[16:08:49.195] iteration 9096: loss: 0.065964, loss_s1: 0.033986, loss_fp: 0.000512, loss_freq: 0.047966
[16:08:49.821] iteration 9097: loss: 0.075831, loss_s1: 0.053371, loss_fp: 0.001407, loss_freq: 0.034008
[16:08:50.445] iteration 9098: loss: 0.065875, loss_s1: 0.050210, loss_fp: 0.008794, loss_freq: 0.031727
[16:08:51.068] iteration 9099: loss: 0.134821, loss_s1: 0.116206, loss_fp: 0.036913, loss_freq: 0.072209
[16:08:51.689] iteration 9100: loss: 0.073229, loss_s1: 0.048115, loss_fp: 0.014254, loss_freq: 0.024926
[16:08:52.314] iteration 9101: loss: 0.139619, loss_s1: 0.108221, loss_fp: 0.009971, loss_freq: 0.100329
[16:08:52.936] iteration 9102: loss: 0.054650, loss_s1: 0.023648, loss_fp: 0.002257, loss_freq: 0.039866
[16:08:53.560] iteration 9103: loss: 0.113373, loss_s1: 0.104337, loss_fp: 0.000805, loss_freq: 0.016539
[16:08:54.243] iteration 9104: loss: 0.056491, loss_s1: 0.034290, loss_fp: 0.002297, loss_freq: 0.014689
[16:08:54.901] iteration 9105: loss: 0.070282, loss_s1: 0.023957, loss_fp: 0.004016, loss_freq: 0.043247
[16:08:55.562] iteration 9106: loss: 0.094425, loss_s1: 0.060541, loss_fp: 0.001933, loss_freq: 0.042060
[16:08:56.220] iteration 9107: loss: 0.117144, loss_s1: 0.055264, loss_fp: 0.004073, loss_freq: 0.005278
[16:08:56.853] iteration 9108: loss: 0.077905, loss_s1: 0.081282, loss_fp: 0.001501, loss_freq: 0.011502
[16:08:57.483] iteration 9109: loss: 0.157417, loss_s1: 0.081808, loss_fp: 0.001989, loss_freq: 0.014976
[16:08:58.111] iteration 9110: loss: 0.061069, loss_s1: 0.031267, loss_fp: 0.001170, loss_freq: 0.025304
[16:08:58.737] iteration 9111: loss: 0.071705, loss_s1: 0.042206, loss_fp: 0.003529, loss_freq: 0.040557
[16:08:59.363] iteration 9112: loss: 0.065508, loss_s1: 0.038493, loss_fp: 0.003507, loss_freq: 0.032870
[16:08:59.994] iteration 9113: loss: 0.078398, loss_s1: 0.053574, loss_fp: 0.005605, loss_freq: 0.023046
[16:09:00.621] iteration 9114: loss: 0.083347, loss_s1: 0.017795, loss_fp: 0.001584, loss_freq: 0.048490
[16:09:01.251] iteration 9115: loss: 0.073457, loss_s1: 0.071271, loss_fp: 0.003048, loss_freq: 0.012176
[16:09:01.903] iteration 9116: loss: 0.056961, loss_s1: 0.037379, loss_fp: 0.000744, loss_freq: 0.030173
[16:09:02.528] iteration 9117: loss: 0.077495, loss_s1: 0.054005, loss_fp: 0.008259, loss_freq: 0.034091
[16:09:03.157] iteration 9118: loss: 0.109950, loss_s1: 0.049218, loss_fp: 0.002625, loss_freq: 0.085108
[16:09:03.785] iteration 9119: loss: 0.098876, loss_s1: 0.060921, loss_fp: 0.010366, loss_freq: 0.021049
[16:09:04.405] iteration 9120: loss: 0.079855, loss_s1: 0.056003, loss_fp: 0.006949, loss_freq: 0.045375
[16:09:05.029] iteration 9121: loss: 0.072882, loss_s1: 0.032567, loss_fp: 0.004643, loss_freq: 0.021133
[16:09:05.711] iteration 9122: loss: 0.091281, loss_s1: 0.069821, loss_fp: 0.001040, loss_freq: 0.059991
[16:09:06.370] iteration 9123: loss: 0.091045, loss_s1: 0.052162, loss_fp: 0.004045, loss_freq: 0.010404
[16:09:07.023] iteration 9124: loss: 0.130573, loss_s1: 0.073895, loss_fp: 0.001115, loss_freq: 0.073474
[16:09:07.680] iteration 9125: loss: 0.210399, loss_s1: 0.144596, loss_fp: 0.002031, loss_freq: 0.181806
[16:09:08.313] iteration 9126: loss: 0.075777, loss_s1: 0.050042, loss_fp: 0.003854, loss_freq: 0.027872
[16:09:08.937] iteration 9127: loss: 0.079687, loss_s1: 0.027374, loss_fp: 0.003628, loss_freq: 0.035760
[16:09:09.561] iteration 9128: loss: 0.083483, loss_s1: 0.035402, loss_fp: 0.003768, loss_freq: 0.060233
[16:09:10.185] iteration 9129: loss: 0.139647, loss_s1: 0.105265, loss_fp: 0.001179, loss_freq: 0.076353
[16:09:10.810] iteration 9130: loss: 0.077210, loss_s1: 0.053410, loss_fp: 0.000695, loss_freq: 0.031507
[16:09:11.445] iteration 9131: loss: 0.038454, loss_s1: 0.019061, loss_fp: 0.002822, loss_freq: 0.005407
[16:09:12.073] iteration 9132: loss: 0.110921, loss_s1: 0.060586, loss_fp: 0.002875, loss_freq: 0.081377
[16:09:12.710] iteration 9133: loss: 0.065427, loss_s1: 0.020675, loss_fp: 0.005136, loss_freq: 0.031572
[16:09:13.337] iteration 9134: loss: 0.086333, loss_s1: 0.059515, loss_fp: 0.001171, loss_freq: 0.037926
[16:09:13.965] iteration 9135: loss: 0.117856, loss_s1: 0.053598, loss_fp: 0.002772, loss_freq: 0.030012
[16:09:14.592] iteration 9136: loss: 0.097227, loss_s1: 0.042011, loss_fp: 0.016834, loss_freq: 0.091459
[16:09:15.219] iteration 9137: loss: 0.047722, loss_s1: 0.018417, loss_fp: 0.001325, loss_freq: 0.026620
[16:09:15.843] iteration 9138: loss: 0.068257, loss_s1: 0.023095, loss_fp: 0.017783, loss_freq: 0.018284
[16:09:16.507] iteration 9139: loss: 0.083359, loss_s1: 0.058843, loss_fp: 0.005022, loss_freq: 0.031888
[16:09:17.164] iteration 9140: loss: 0.064596, loss_s1: 0.037674, loss_fp: 0.003659, loss_freq: 0.013980
[16:09:17.822] iteration 9141: loss: 0.117967, loss_s1: 0.052863, loss_fp: 0.004473, loss_freq: 0.049803
[16:09:18.477] iteration 9142: loss: 0.100146, loss_s1: 0.064153, loss_fp: 0.000655, loss_freq: 0.023307
[16:09:19.118] iteration 9143: loss: 0.073196, loss_s1: 0.037981, loss_fp: 0.003418, loss_freq: 0.012459
[16:09:19.746] iteration 9144: loss: 0.142687, loss_s1: 0.102331, loss_fp: 0.001632, loss_freq: 0.021126
[16:09:20.371] iteration 9145: loss: 0.059838, loss_s1: 0.032853, loss_fp: 0.004229, loss_freq: 0.023712
[16:09:20.995] iteration 9146: loss: 0.093735, loss_s1: 0.094337, loss_fp: 0.012106, loss_freq: 0.020481
[16:09:21.620] iteration 9147: loss: 0.123575, loss_s1: 0.079825, loss_fp: 0.005589, loss_freq: 0.116186
[16:09:22.247] iteration 9148: loss: 0.079848, loss_s1: 0.062371, loss_fp: 0.006208, loss_freq: 0.020757
[16:09:22.875] iteration 9149: loss: 0.112323, loss_s1: 0.058195, loss_fp: 0.003043, loss_freq: 0.038239
[16:09:23.503] iteration 9150: loss: 0.070649, loss_s1: 0.047879, loss_fp: 0.001662, loss_freq: 0.031733
[16:09:24.128] iteration 9151: loss: 0.089669, loss_s1: 0.068013, loss_fp: 0.003909, loss_freq: 0.036711
[16:09:24.753] iteration 9152: loss: 0.076862, loss_s1: 0.059878, loss_fp: 0.002266, loss_freq: 0.045629
[16:09:25.377] iteration 9153: loss: 0.053199, loss_s1: 0.018001, loss_fp: 0.000376, loss_freq: 0.009563
[16:09:25.998] iteration 9154: loss: 0.065004, loss_s1: 0.051962, loss_fp: 0.010867, loss_freq: 0.016085
[16:09:26.625] iteration 9155: loss: 0.057979, loss_s1: 0.014708, loss_fp: 0.008157, loss_freq: 0.028074
[16:09:27.257] iteration 9156: loss: 0.120930, loss_s1: 0.079673, loss_fp: 0.002580, loss_freq: 0.040817
[16:09:27.876] iteration 9157: loss: 0.096927, loss_s1: 0.083943, loss_fp: 0.007753, loss_freq: 0.049720
[16:09:28.496] iteration 9158: loss: 0.070651, loss_s1: 0.056479, loss_fp: 0.000753, loss_freq: 0.025495
[16:09:29.120] iteration 9159: loss: 0.120862, loss_s1: 0.045264, loss_fp: 0.002429, loss_freq: 0.031570
[16:09:29.768] iteration 9160: loss: 0.116143, loss_s1: 0.093779, loss_fp: 0.004662, loss_freq: 0.026728
[16:09:30.412] iteration 9161: loss: 0.048403, loss_s1: 0.013884, loss_fp: 0.004196, loss_freq: 0.013140
[16:09:31.034] iteration 9162: loss: 0.081974, loss_s1: 0.053280, loss_fp: 0.002672, loss_freq: 0.014301
[16:09:31.656] iteration 9163: loss: 0.072852, loss_s1: 0.043207, loss_fp: 0.008843, loss_freq: 0.042014
[16:09:32.281] iteration 9164: loss: 0.078246, loss_s1: 0.063627, loss_fp: 0.004495, loss_freq: 0.033239
[16:09:32.906] iteration 9165: loss: 0.098088, loss_s1: 0.063230, loss_fp: 0.006292, loss_freq: 0.039215
[16:09:33.528] iteration 9166: loss: 0.103125, loss_s1: 0.066351, loss_fp: 0.008003, loss_freq: 0.061417
[16:09:34.152] iteration 9167: loss: 0.114846, loss_s1: 0.048004, loss_fp: 0.006694, loss_freq: 0.049670
[16:09:34.777] iteration 9168: loss: 0.111848, loss_s1: 0.113515, loss_fp: 0.008446, loss_freq: 0.042719
[16:09:35.404] iteration 9169: loss: 0.069150, loss_s1: 0.060429, loss_fp: 0.002851, loss_freq: 0.019595
[16:09:36.029] iteration 9170: loss: 0.072120, loss_s1: 0.037675, loss_fp: 0.001634, loss_freq: 0.039308
[16:09:36.655] iteration 9171: loss: 0.073797, loss_s1: 0.065850, loss_fp: 0.000198, loss_freq: 0.013078
[16:09:37.282] iteration 9172: loss: 0.082403, loss_s1: 0.043257, loss_fp: 0.000585, loss_freq: 0.042137
[16:09:37.902] iteration 9173: loss: 0.052304, loss_s1: 0.027594, loss_fp: 0.000249, loss_freq: 0.011055
[16:09:38.528] iteration 9174: loss: 0.098486, loss_s1: 0.078752, loss_fp: 0.002863, loss_freq: 0.035429
[16:09:39.152] iteration 9175: loss: 0.094072, loss_s1: 0.090505, loss_fp: 0.002437, loss_freq: 0.040873
[16:09:39.774] iteration 9176: loss: 0.052230, loss_s1: 0.009875, loss_fp: 0.000516, loss_freq: 0.021248
[16:09:40.399] iteration 9177: loss: 0.062490, loss_s1: 0.023332, loss_fp: 0.002043, loss_freq: 0.036876
[16:09:41.357] iteration 9178: loss: 0.067526, loss_s1: 0.047282, loss_fp: 0.000305, loss_freq: 0.032092
[16:09:41.981] iteration 9179: loss: 0.094015, loss_s1: 0.057226, loss_fp: 0.002611, loss_freq: 0.017879
[16:09:42.609] iteration 9180: loss: 0.079637, loss_s1: 0.066043, loss_fp: 0.002269, loss_freq: 0.028036
[16:09:43.233] iteration 9181: loss: 0.057883, loss_s1: 0.017739, loss_fp: 0.003110, loss_freq: 0.015457
[16:09:43.854] iteration 9182: loss: 0.084866, loss_s1: 0.038599, loss_fp: 0.004118, loss_freq: 0.016312
[16:09:44.478] iteration 9183: loss: 0.139026, loss_s1: 0.094164, loss_fp: 0.013351, loss_freq: 0.063260
[16:09:45.100] iteration 9184: loss: 0.058604, loss_s1: 0.048695, loss_fp: 0.001827, loss_freq: 0.029346
[16:09:45.725] iteration 9185: loss: 0.072010, loss_s1: 0.047630, loss_fp: 0.003092, loss_freq: 0.047535
[16:09:46.351] iteration 9186: loss: 0.114944, loss_s1: 0.082006, loss_fp: 0.006542, loss_freq: 0.034680
[16:09:46.975] iteration 9187: loss: 0.095764, loss_s1: 0.061592, loss_fp: 0.011255, loss_freq: 0.042621
[16:09:47.600] iteration 9188: loss: 0.057918, loss_s1: 0.017771, loss_fp: 0.003375, loss_freq: 0.022457
[16:09:48.227] iteration 9189: loss: 0.094500, loss_s1: 0.066050, loss_fp: 0.042630, loss_freq: 0.032666
[16:09:48.848] iteration 9190: loss: 0.102491, loss_s1: 0.069613, loss_fp: 0.004674, loss_freq: 0.087823
[16:09:49.476] iteration 9191: loss: 0.082691, loss_s1: 0.033004, loss_fp: 0.004294, loss_freq: 0.051997
[16:09:50.103] iteration 9192: loss: 0.060444, loss_s1: 0.049464, loss_fp: 0.000989, loss_freq: 0.013473
[16:09:50.759] iteration 9193: loss: 0.144845, loss_s1: 0.106041, loss_fp: 0.005124, loss_freq: 0.128053
[16:09:51.414] iteration 9194: loss: 0.130124, loss_s1: 0.114034, loss_fp: 0.001688, loss_freq: 0.015545
[16:09:52.069] iteration 9195: loss: 0.066752, loss_s1: 0.033382, loss_fp: 0.004412, loss_freq: 0.035644
[16:09:52.724] iteration 9196: loss: 0.042457, loss_s1: 0.027532, loss_fp: 0.000468, loss_freq: 0.009991
[16:09:53.380] iteration 9197: loss: 0.098676, loss_s1: 0.034517, loss_fp: 0.000717, loss_freq: 0.048903
[16:09:54.005] iteration 9198: loss: 0.096826, loss_s1: 0.106306, loss_fp: 0.002832, loss_freq: 0.005873
[16:09:54.630] iteration 9199: loss: 0.053978, loss_s1: 0.037362, loss_fp: 0.000548, loss_freq: 0.017814
[16:09:55.251] iteration 9200: loss: 0.072990, loss_s1: 0.033255, loss_fp: 0.000894, loss_freq: 0.014886
[16:09:58.519] iteration 9200 : mean_dice : 0.698838
[16:09:59.287] iteration 9201: loss: 0.245914, loss_s1: 0.141649, loss_fp: 0.006691, loss_freq: 0.288110
[16:09:59.952] iteration 9202: loss: 0.052747, loss_s1: 0.046263, loss_fp: 0.000516, loss_freq: 0.016218
[16:10:00.624] iteration 9203: loss: 0.085629, loss_s1: 0.037258, loss_fp: 0.003157, loss_freq: 0.074381
[16:10:01.280] iteration 9204: loss: 0.114281, loss_s1: 0.072065, loss_fp: 0.006061, loss_freq: 0.080558
[16:10:01.923] iteration 9205: loss: 0.099643, loss_s1: 0.044560, loss_fp: 0.014113, loss_freq: 0.040092
[16:10:02.545] iteration 9206: loss: 0.072671, loss_s1: 0.064664, loss_fp: 0.003612, loss_freq: 0.027901
[16:10:03.171] iteration 9207: loss: 0.044839, loss_s1: 0.027190, loss_fp: 0.000450, loss_freq: 0.008341
[16:10:03.793] iteration 9208: loss: 0.052097, loss_s1: 0.038287, loss_fp: 0.005244, loss_freq: 0.018437
[16:10:04.416] iteration 9209: loss: 0.066175, loss_s1: 0.015066, loss_fp: 0.004699, loss_freq: 0.018466
[16:10:05.036] iteration 9210: loss: 0.047393, loss_s1: 0.016198, loss_fp: 0.001074, loss_freq: 0.024179
[16:10:05.657] iteration 9211: loss: 0.071467, loss_s1: 0.060975, loss_fp: 0.007715, loss_freq: 0.016518
[16:10:06.281] iteration 9212: loss: 0.090856, loss_s1: 0.085653, loss_fp: 0.001664, loss_freq: 0.020157
[16:10:06.912] iteration 9213: loss: 0.059347, loss_s1: 0.035344, loss_fp: 0.000976, loss_freq: 0.027229
[16:10:07.535] iteration 9214: loss: 0.153851, loss_s1: 0.137128, loss_fp: 0.001777, loss_freq: 0.075935
[16:10:08.160] iteration 9215: loss: 0.098582, loss_s1: 0.079405, loss_fp: 0.018531, loss_freq: 0.019738
[16:10:08.792] iteration 9216: loss: 0.120755, loss_s1: 0.068222, loss_fp: 0.003374, loss_freq: 0.042560
[16:10:09.452] iteration 9217: loss: 0.110987, loss_s1: 0.077267, loss_fp: 0.004529, loss_freq: 0.059708
[16:10:10.089] iteration 9218: loss: 0.087553, loss_s1: 0.054780, loss_fp: 0.007125, loss_freq: 0.032370
[16:10:10.747] iteration 9219: loss: 0.115500, loss_s1: 0.100395, loss_fp: 0.013439, loss_freq: 0.071081
[16:10:11.407] iteration 9220: loss: 0.061127, loss_s1: 0.054600, loss_fp: 0.003777, loss_freq: 0.017551
[16:10:12.064] iteration 9221: loss: 0.064766, loss_s1: 0.036147, loss_fp: 0.004505, loss_freq: 0.036425
[16:10:12.705] iteration 9222: loss: 0.072643, loss_s1: 0.037335, loss_fp: 0.005638, loss_freq: 0.042071
[16:10:13.334] iteration 9223: loss: 0.060581, loss_s1: 0.022636, loss_fp: 0.001055, loss_freq: 0.024993
[16:10:13.959] iteration 9224: loss: 0.048164, loss_s1: 0.037227, loss_fp: 0.002396, loss_freq: 0.011561
[16:10:14.586] iteration 9225: loss: 0.074026, loss_s1: 0.041077, loss_fp: 0.001704, loss_freq: 0.019673
[16:10:15.214] iteration 9226: loss: 0.072397, loss_s1: 0.051875, loss_fp: 0.001563, loss_freq: 0.018656
[16:10:15.840] iteration 9227: loss: 0.090810, loss_s1: 0.051890, loss_fp: 0.000739, loss_freq: 0.086369
[16:10:16.466] iteration 9228: loss: 0.097520, loss_s1: 0.112576, loss_fp: 0.003033, loss_freq: 0.032630
[16:10:17.093] iteration 9229: loss: 0.065922, loss_s1: 0.022042, loss_fp: 0.006906, loss_freq: 0.025815
[16:10:17.718] iteration 9230: loss: 0.094798, loss_s1: 0.079008, loss_fp: 0.003412, loss_freq: 0.036869
[16:10:18.343] iteration 9231: loss: 0.102467, loss_s1: 0.036954, loss_fp: 0.004059, loss_freq: 0.063048
[16:10:18.965] iteration 9232: loss: 0.090324, loss_s1: 0.045337, loss_fp: 0.007117, loss_freq: 0.028175
[16:10:19.594] iteration 9233: loss: 0.084904, loss_s1: 0.065678, loss_fp: 0.002890, loss_freq: 0.026761
[16:10:20.220] iteration 9234: loss: 0.042039, loss_s1: 0.022241, loss_fp: 0.001562, loss_freq: 0.006179
[16:10:20.842] iteration 9235: loss: 0.100932, loss_s1: 0.049454, loss_fp: 0.001443, loss_freq: 0.065815
[16:10:21.463] iteration 9236: loss: 0.040320, loss_s1: 0.012541, loss_fp: 0.003384, loss_freq: 0.003957
[16:10:22.084] iteration 9237: loss: 0.066707, loss_s1: 0.017403, loss_fp: 0.001046, loss_freq: 0.043982
[16:10:22.703] iteration 9238: loss: 0.059213, loss_s1: 0.016392, loss_fp: 0.008136, loss_freq: 0.025937
[16:10:23.332] iteration 9239: loss: 0.061853, loss_s1: 0.044610, loss_fp: 0.002996, loss_freq: 0.020369
[16:10:23.956] iteration 9240: loss: 0.080750, loss_s1: 0.045577, loss_fp: 0.002874, loss_freq: 0.016063
[16:10:24.579] iteration 9241: loss: 0.061732, loss_s1: 0.055391, loss_fp: 0.002332, loss_freq: 0.017184
[16:10:25.202] iteration 9242: loss: 0.076877, loss_s1: 0.067792, loss_fp: 0.005123, loss_freq: 0.008382
[16:10:25.823] iteration 9243: loss: 0.099395, loss_s1: 0.084870, loss_fp: 0.001713, loss_freq: 0.061136
[16:10:26.447] iteration 9244: loss: 0.103673, loss_s1: 0.047678, loss_fp: 0.002842, loss_freq: 0.059651
[16:10:27.072] iteration 9245: loss: 0.052780, loss_s1: 0.029547, loss_fp: 0.002340, loss_freq: 0.020687
[16:10:27.694] iteration 9246: loss: 0.074348, loss_s1: 0.038707, loss_fp: 0.000747, loss_freq: 0.029439
[16:10:28.315] iteration 9247: loss: 0.090930, loss_s1: 0.052956, loss_fp: 0.001008, loss_freq: 0.025896
[16:10:28.939] iteration 9248: loss: 0.118612, loss_s1: 0.087313, loss_fp: 0.025507, loss_freq: 0.046599
[16:10:29.561] iteration 9249: loss: 0.075661, loss_s1: 0.050861, loss_fp: 0.001699, loss_freq: 0.043967
[16:10:30.190] iteration 9250: loss: 0.092062, loss_s1: 0.084618, loss_fp: 0.008890, loss_freq: 0.031856
[16:10:30.814] iteration 9251: loss: 0.056215, loss_s1: 0.034751, loss_fp: 0.003146, loss_freq: 0.009904
[16:10:31.432] iteration 9252: loss: 0.115671, loss_s1: 0.090185, loss_fp: 0.004451, loss_freq: 0.082129
[16:10:32.059] iteration 9253: loss: 0.118728, loss_s1: 0.081022, loss_fp: 0.003778, loss_freq: 0.072481
[16:10:32.683] iteration 9254: loss: 0.082129, loss_s1: 0.044656, loss_fp: 0.012490, loss_freq: 0.048195
[16:10:33.306] iteration 9255: loss: 0.056425, loss_s1: 0.040024, loss_fp: 0.002891, loss_freq: 0.025489
[16:10:33.929] iteration 9256: loss: 0.063327, loss_s1: 0.039318, loss_fp: 0.000866, loss_freq: 0.029028
[16:10:34.554] iteration 9257: loss: 0.063633, loss_s1: 0.029125, loss_fp: 0.011960, loss_freq: 0.032647
[16:10:35.180] iteration 9258: loss: 0.085723, loss_s1: 0.033170, loss_fp: 0.001964, loss_freq: 0.065319
[16:10:35.802] iteration 9259: loss: 0.087131, loss_s1: 0.077109, loss_fp: 0.011980, loss_freq: 0.044468
[16:10:36.426] iteration 9260: loss: 0.083307, loss_s1: 0.047948, loss_fp: 0.003407, loss_freq: 0.069273
[16:10:37.056] iteration 9261: loss: 0.067388, loss_s1: 0.057831, loss_fp: 0.001402, loss_freq: 0.012198
[16:10:37.680] iteration 9262: loss: 0.118946, loss_s1: 0.124352, loss_fp: 0.005830, loss_freq: 0.061564
[16:10:38.303] iteration 9263: loss: 0.068960, loss_s1: 0.053791, loss_fp: 0.001644, loss_freq: 0.031750
[16:10:38.925] iteration 9264: loss: 0.099360, loss_s1: 0.053019, loss_fp: 0.002056, loss_freq: 0.024900
[16:10:39.550] iteration 9265: loss: 0.065550, loss_s1: 0.061453, loss_fp: 0.006292, loss_freq: 0.012557
[16:10:40.170] iteration 9266: loss: 0.095949, loss_s1: 0.062376, loss_fp: 0.002604, loss_freq: 0.074962
[16:10:40.801] iteration 9267: loss: 0.099810, loss_s1: 0.093943, loss_fp: 0.004267, loss_freq: 0.029876
[16:10:41.451] iteration 9268: loss: 0.071154, loss_s1: 0.029878, loss_fp: 0.002019, loss_freq: 0.033940
[16:10:42.104] iteration 9269: loss: 0.078186, loss_s1: 0.043731, loss_fp: 0.001917, loss_freq: 0.014778
[16:10:42.758] iteration 9270: loss: 0.064044, loss_s1: 0.009686, loss_fp: 0.001013, loss_freq: 0.012067
[16:10:43.413] iteration 9271: loss: 0.064137, loss_s1: 0.020551, loss_fp: 0.000922, loss_freq: 0.024011
[16:10:44.055] iteration 9272: loss: 0.049316, loss_s1: 0.032300, loss_fp: 0.000534, loss_freq: 0.009772
[16:10:44.678] iteration 9273: loss: 0.050916, loss_s1: 0.028899, loss_fp: 0.003508, loss_freq: 0.023613
[16:10:45.301] iteration 9274: loss: 0.066095, loss_s1: 0.024457, loss_fp: 0.000707, loss_freq: 0.014776
[16:10:45.926] iteration 9275: loss: 0.065213, loss_s1: 0.017252, loss_fp: 0.000692, loss_freq: 0.040081
[16:10:46.548] iteration 9276: loss: 0.082397, loss_s1: 0.046556, loss_fp: 0.001297, loss_freq: 0.014134
[16:10:47.171] iteration 9277: loss: 0.075336, loss_s1: 0.068982, loss_fp: 0.004557, loss_freq: 0.021829
[16:10:47.794] iteration 9278: loss: 0.066377, loss_s1: 0.059109, loss_fp: 0.001560, loss_freq: 0.035883
[16:10:48.419] iteration 9279: loss: 0.089982, loss_s1: 0.043035, loss_fp: 0.001746, loss_freq: 0.040851
[16:10:49.043] iteration 9280: loss: 0.107273, loss_s1: 0.095990, loss_fp: 0.000459, loss_freq: 0.074146
[16:10:49.696] iteration 9281: loss: 0.075793, loss_s1: 0.056033, loss_fp: 0.001786, loss_freq: 0.049374
[16:10:50.353] iteration 9282: loss: 0.080760, loss_s1: 0.049326, loss_fp: 0.007439, loss_freq: 0.021095
[16:10:51.001] iteration 9283: loss: 0.054053, loss_s1: 0.018874, loss_fp: 0.003142, loss_freq: 0.027635
[16:10:51.631] iteration 9284: loss: 0.047705, loss_s1: 0.016279, loss_fp: 0.008289, loss_freq: 0.014735
[16:10:52.261] iteration 9285: loss: 0.107259, loss_s1: 0.089172, loss_fp: 0.004310, loss_freq: 0.034725
[16:10:52.891] iteration 9286: loss: 0.164354, loss_s1: 0.092962, loss_fp: 0.002072, loss_freq: 0.105135
[16:10:53.547] iteration 9287: loss: 0.074126, loss_s1: 0.069214, loss_fp: 0.002715, loss_freq: 0.032625
[16:10:54.169] iteration 9288: loss: 0.071144, loss_s1: 0.033071, loss_fp: 0.001856, loss_freq: 0.046886
[16:10:54.793] iteration 9289: loss: 0.066132, loss_s1: 0.035476, loss_fp: 0.004361, loss_freq: 0.045158
[16:10:55.415] iteration 9290: loss: 0.082113, loss_s1: 0.055338, loss_fp: 0.005742, loss_freq: 0.054015
[16:10:56.040] iteration 9291: loss: 0.081424, loss_s1: 0.045009, loss_fp: 0.000981, loss_freq: 0.065797
[16:10:56.663] iteration 9292: loss: 0.040047, loss_s1: 0.019961, loss_fp: 0.001166, loss_freq: 0.012125
[16:10:57.324] iteration 9293: loss: 0.111435, loss_s1: 0.086785, loss_fp: 0.003177, loss_freq: 0.064589
[16:10:57.981] iteration 9294: loss: 0.082783, loss_s1: 0.048346, loss_fp: 0.002850, loss_freq: 0.058223
[16:10:58.643] iteration 9295: loss: 0.051247, loss_s1: 0.023522, loss_fp: 0.000819, loss_freq: 0.024364
[16:10:59.308] iteration 9296: loss: 0.078974, loss_s1: 0.032894, loss_fp: 0.003055, loss_freq: 0.030418
[16:10:59.951] iteration 9297: loss: 0.145219, loss_s1: 0.123960, loss_fp: 0.016651, loss_freq: 0.102299
[16:11:00.579] iteration 9298: loss: 0.136301, loss_s1: 0.044339, loss_fp: 0.003947, loss_freq: 0.115201
[16:11:01.207] iteration 9299: loss: 0.149766, loss_s1: 0.023064, loss_fp: 0.029045, loss_freq: 0.014588
[16:11:01.835] iteration 9300: loss: 0.081586, loss_s1: 0.086685, loss_fp: 0.004940, loss_freq: 0.017240
[16:11:02.465] iteration 9301: loss: 0.077341, loss_s1: 0.086560, loss_fp: 0.002112, loss_freq: 0.009032
[16:11:03.090] iteration 9302: loss: 0.076409, loss_s1: 0.039592, loss_fp: 0.001529, loss_freq: 0.016833
[16:11:03.721] iteration 9303: loss: 0.072528, loss_s1: 0.038294, loss_fp: 0.011217, loss_freq: 0.034002
[16:11:04.346] iteration 9304: loss: 0.098165, loss_s1: 0.076183, loss_fp: 0.001342, loss_freq: 0.018542
[16:11:05.008] iteration 9305: loss: 0.113051, loss_s1: 0.035337, loss_fp: 0.000596, loss_freq: 0.053466
[16:11:05.672] iteration 9306: loss: 0.059136, loss_s1: 0.017330, loss_fp: 0.003621, loss_freq: 0.014556
[16:11:06.303] iteration 9307: loss: 0.046598, loss_s1: 0.025358, loss_fp: 0.004418, loss_freq: 0.012826
[16:11:06.927] iteration 9308: loss: 0.100437, loss_s1: 0.040457, loss_fp: 0.010062, loss_freq: 0.106327
[16:11:07.555] iteration 9309: loss: 0.089565, loss_s1: 0.079881, loss_fp: 0.002101, loss_freq: 0.012174
[16:11:08.183] iteration 9310: loss: 0.112126, loss_s1: 0.116562, loss_fp: 0.002971, loss_freq: 0.030953
[16:11:08.808] iteration 9311: loss: 0.054380, loss_s1: 0.031913, loss_fp: 0.003251, loss_freq: 0.022387
[16:11:09.434] iteration 9312: loss: 0.069722, loss_s1: 0.040035, loss_fp: 0.014886, loss_freq: 0.032235
[16:11:10.069] iteration 9313: loss: 0.066611, loss_s1: 0.072749, loss_fp: 0.002801, loss_freq: 0.014019
[16:11:10.706] iteration 9314: loss: 0.090797, loss_s1: 0.054015, loss_fp: 0.000365, loss_freq: 0.051095
[16:11:11.334] iteration 9315: loss: 0.056542, loss_s1: 0.039786, loss_fp: 0.002871, loss_freq: 0.014850
[16:11:11.963] iteration 9316: loss: 0.072344, loss_s1: 0.068503, loss_fp: 0.003638, loss_freq: 0.026066
[16:11:12.589] iteration 9317: loss: 0.138056, loss_s1: 0.132344, loss_fp: 0.001145, loss_freq: 0.052670
[16:11:13.216] iteration 9318: loss: 0.098655, loss_s1: 0.074126, loss_fp: 0.001160, loss_freq: 0.046290
[16:11:13.843] iteration 9319: loss: 0.061282, loss_s1: 0.037386, loss_fp: 0.001736, loss_freq: 0.018550
[16:11:14.469] iteration 9320: loss: 0.082921, loss_s1: 0.035845, loss_fp: 0.003012, loss_freq: 0.055370
[16:11:15.101] iteration 9321: loss: 0.103993, loss_s1: 0.093031, loss_fp: 0.005712, loss_freq: 0.053501
[16:11:15.725] iteration 9322: loss: 0.059963, loss_s1: 0.035189, loss_fp: 0.008218, loss_freq: 0.012701
[16:11:16.355] iteration 9323: loss: 0.093670, loss_s1: 0.063056, loss_fp: 0.007714, loss_freq: 0.027980
[16:11:16.980] iteration 9324: loss: 0.067541, loss_s1: 0.054466, loss_fp: 0.003263, loss_freq: 0.034044
[16:11:17.603] iteration 9325: loss: 0.100030, loss_s1: 0.062145, loss_fp: 0.000425, loss_freq: 0.027581
[16:11:18.231] iteration 9326: loss: 0.083154, loss_s1: 0.070796, loss_fp: 0.002431, loss_freq: 0.021560
[16:11:18.856] iteration 9327: loss: 0.095336, loss_s1: 0.063469, loss_fp: 0.003172, loss_freq: 0.039985
[16:11:19.479] iteration 9328: loss: 0.094405, loss_s1: 0.033243, loss_fp: 0.001058, loss_freq: 0.031929
[16:11:20.103] iteration 9329: loss: 0.095938, loss_s1: 0.105260, loss_fp: 0.002409, loss_freq: 0.044514
[16:11:20.731] iteration 9330: loss: 0.049358, loss_s1: 0.031465, loss_fp: 0.001745, loss_freq: 0.014183
[16:11:21.355] iteration 9331: loss: 0.081603, loss_s1: 0.027944, loss_fp: 0.004302, loss_freq: 0.040959
[16:11:21.982] iteration 9332: loss: 0.034852, loss_s1: 0.009418, loss_fp: 0.001240, loss_freq: 0.005019
[16:11:22.610] iteration 9333: loss: 0.071476, loss_s1: 0.040304, loss_fp: 0.003818, loss_freq: 0.045400
[16:11:23.232] iteration 9334: loss: 0.067140, loss_s1: 0.060910, loss_fp: 0.000510, loss_freq: 0.016384
[16:11:23.860] iteration 9335: loss: 0.113810, loss_s1: 0.088365, loss_fp: 0.001484, loss_freq: 0.079105
[16:11:24.484] iteration 9336: loss: 0.114389, loss_s1: 0.084232, loss_fp: 0.020630, loss_freq: 0.028890
[16:11:25.104] iteration 9337: loss: 0.083157, loss_s1: 0.055738, loss_fp: 0.001480, loss_freq: 0.011666
[16:11:25.723] iteration 9338: loss: 0.069010, loss_s1: 0.018605, loss_fp: 0.001859, loss_freq: 0.056995
[16:11:26.751] iteration 9339: loss: 0.055801, loss_s1: 0.019457, loss_fp: 0.001234, loss_freq: 0.022723
[16:11:27.413] iteration 9340: loss: 0.094116, loss_s1: 0.076122, loss_fp: 0.001346, loss_freq: 0.019365
[16:11:28.074] iteration 9341: loss: 0.082094, loss_s1: 0.038822, loss_fp: 0.001486, loss_freq: 0.041491
[16:11:28.698] iteration 9342: loss: 0.060617, loss_s1: 0.027943, loss_fp: 0.001209, loss_freq: 0.012944
[16:11:29.324] iteration 9343: loss: 0.074725, loss_s1: 0.056273, loss_fp: 0.003411, loss_freq: 0.028565
[16:11:29.949] iteration 9344: loss: 0.156337, loss_s1: 0.163293, loss_fp: 0.003378, loss_freq: 0.057717
[16:11:30.580] iteration 9345: loss: 0.055718, loss_s1: 0.035311, loss_fp: 0.001652, loss_freq: 0.036204
[16:11:31.206] iteration 9346: loss: 0.060483, loss_s1: 0.035045, loss_fp: 0.002198, loss_freq: 0.028197
[16:11:31.832] iteration 9347: loss: 0.066681, loss_s1: 0.056944, loss_fp: 0.000584, loss_freq: 0.006536
[16:11:32.459] iteration 9348: loss: 0.100614, loss_s1: 0.056622, loss_fp: 0.006721, loss_freq: 0.048220
[16:11:33.091] iteration 9349: loss: 0.056876, loss_s1: 0.014970, loss_fp: 0.000499, loss_freq: 0.020260
[16:11:33.718] iteration 9350: loss: 0.099534, loss_s1: 0.045668, loss_fp: 0.004869, loss_freq: 0.087946
[16:11:34.343] iteration 9351: loss: 0.108636, loss_s1: 0.051243, loss_fp: 0.004136, loss_freq: 0.094293
[16:11:34.973] iteration 9352: loss: 0.086924, loss_s1: 0.067675, loss_fp: 0.006095, loss_freq: 0.017701
[16:11:35.598] iteration 9353: loss: 0.062496, loss_s1: 0.059105, loss_fp: 0.007975, loss_freq: 0.008525
[16:11:36.224] iteration 9354: loss: 0.135229, loss_s1: 0.097718, loss_fp: 0.001833, loss_freq: 0.120125
[16:11:36.852] iteration 9355: loss: 0.057250, loss_s1: 0.025499, loss_fp: 0.004502, loss_freq: 0.017221
[16:11:37.479] iteration 9356: loss: 0.073572, loss_s1: 0.026367, loss_fp: 0.009689, loss_freq: 0.039408
[16:11:38.101] iteration 9357: loss: 0.133669, loss_s1: 0.058005, loss_fp: 0.010237, loss_freq: 0.031677
[16:11:38.727] iteration 9358: loss: 0.091712, loss_s1: 0.047229, loss_fp: 0.001770, loss_freq: 0.036169
[16:11:39.349] iteration 9359: loss: 0.067103, loss_s1: 0.042127, loss_fp: 0.006001, loss_freq: 0.018291
[16:11:39.972] iteration 9360: loss: 0.067919, loss_s1: 0.050988, loss_fp: 0.002067, loss_freq: 0.029602
[16:11:40.598] iteration 9361: loss: 0.093903, loss_s1: 0.067238, loss_fp: 0.001810, loss_freq: 0.017316
[16:11:41.220] iteration 9362: loss: 0.213478, loss_s1: 0.105750, loss_fp: 0.002947, loss_freq: 0.221363
[16:11:41.847] iteration 9363: loss: 0.064031, loss_s1: 0.044230, loss_fp: 0.000695, loss_freq: 0.026309
[16:11:42.473] iteration 9364: loss: 0.106702, loss_s1: 0.047889, loss_fp: 0.005209, loss_freq: 0.071830
[16:11:43.103] iteration 9365: loss: 0.056252, loss_s1: 0.027590, loss_fp: 0.000548, loss_freq: 0.022125
[16:11:43.730] iteration 9366: loss: 0.110964, loss_s1: 0.076701, loss_fp: 0.001820, loss_freq: 0.077045
[16:11:44.378] iteration 9367: loss: 0.102964, loss_s1: 0.067830, loss_fp: 0.005949, loss_freq: 0.059625
[16:11:45.002] iteration 9368: loss: 0.062676, loss_s1: 0.039870, loss_fp: 0.001537, loss_freq: 0.023599
[16:11:45.627] iteration 9369: loss: 0.081867, loss_s1: 0.080677, loss_fp: 0.000728, loss_freq: 0.014908
[16:11:46.258] iteration 9370: loss: 0.078324, loss_s1: 0.043188, loss_fp: 0.007706, loss_freq: 0.012722
[16:11:46.882] iteration 9371: loss: 0.062059, loss_s1: 0.050130, loss_fp: 0.001978, loss_freq: 0.022353
[16:11:47.508] iteration 9372: loss: 0.062088, loss_s1: 0.037903, loss_fp: 0.003263, loss_freq: 0.019393
[16:11:48.133] iteration 9373: loss: 0.086039, loss_s1: 0.032195, loss_fp: 0.005448, loss_freq: 0.039543
[16:11:48.755] iteration 9374: loss: 0.081610, loss_s1: 0.057350, loss_fp: 0.011983, loss_freq: 0.035862
[16:11:49.381] iteration 9375: loss: 0.134526, loss_s1: 0.138547, loss_fp: 0.003527, loss_freq: 0.043447
[16:11:50.006] iteration 9376: loss: 0.059165, loss_s1: 0.036712, loss_fp: 0.002142, loss_freq: 0.020404
[16:11:50.631] iteration 9377: loss: 0.139239, loss_s1: 0.108731, loss_fp: 0.001563, loss_freq: 0.098739
[16:11:51.256] iteration 9378: loss: 0.070421, loss_s1: 0.036729, loss_fp: 0.003570, loss_freq: 0.037042
[16:11:51.881] iteration 9379: loss: 0.106405, loss_s1: 0.062124, loss_fp: 0.003157, loss_freq: 0.046688
[16:11:52.504] iteration 9380: loss: 0.074529, loss_s1: 0.062842, loss_fp: 0.003580, loss_freq: 0.027898
[16:11:53.132] iteration 9381: loss: 0.061098, loss_s1: 0.022770, loss_fp: 0.003565, loss_freq: 0.036135
[16:11:53.755] iteration 9382: loss: 0.063073, loss_s1: 0.041595, loss_fp: 0.002509, loss_freq: 0.026127
[16:11:54.381] iteration 9383: loss: 0.064356, loss_s1: 0.032866, loss_fp: 0.011724, loss_freq: 0.027803
[16:11:55.010] iteration 9384: loss: 0.067038, loss_s1: 0.052856, loss_fp: 0.000884, loss_freq: 0.005654
[16:11:55.634] iteration 9385: loss: 0.051901, loss_s1: 0.034435, loss_fp: 0.000736, loss_freq: 0.006103
[16:11:56.256] iteration 9386: loss: 0.048834, loss_s1: 0.042423, loss_fp: 0.001574, loss_freq: 0.013227
[16:11:56.877] iteration 9387: loss: 0.100766, loss_s1: 0.069249, loss_fp: 0.001441, loss_freq: 0.027906
[16:11:57.500] iteration 9388: loss: 0.083118, loss_s1: 0.056784, loss_fp: 0.000880, loss_freq: 0.062762
[16:11:58.123] iteration 9389: loss: 0.081608, loss_s1: 0.043296, loss_fp: 0.005969, loss_freq: 0.054861
[16:11:58.747] iteration 9390: loss: 0.071022, loss_s1: 0.051310, loss_fp: 0.001380, loss_freq: 0.024356
[16:11:59.370] iteration 9391: loss: 0.100307, loss_s1: 0.079145, loss_fp: 0.002029, loss_freq: 0.037307
[16:11:59.991] iteration 9392: loss: 0.075582, loss_s1: 0.058389, loss_fp: 0.002148, loss_freq: 0.015491
[16:12:00.615] iteration 9393: loss: 0.089911, loss_s1: 0.033814, loss_fp: 0.002063, loss_freq: 0.031420
[16:12:01.240] iteration 9394: loss: 0.063956, loss_s1: 0.039813, loss_fp: 0.001028, loss_freq: 0.032612
[16:12:01.867] iteration 9395: loss: 0.053279, loss_s1: 0.027938, loss_fp: 0.000950, loss_freq: 0.002166
[16:12:02.550] iteration 9396: loss: 0.097536, loss_s1: 0.049947, loss_fp: 0.001745, loss_freq: 0.043262
[16:12:03.208] iteration 9397: loss: 0.031216, loss_s1: 0.013777, loss_fp: 0.000416, loss_freq: 0.008100
[16:12:03.855] iteration 9398: loss: 0.056815, loss_s1: 0.035629, loss_fp: 0.003945, loss_freq: 0.029683
[16:12:04.496] iteration 9399: loss: 0.055124, loss_s1: 0.024740, loss_fp: 0.001986, loss_freq: 0.044146
[16:12:05.130] iteration 9400: loss: 0.054651, loss_s1: 0.039018, loss_fp: 0.004213, loss_freq: 0.015885
[16:12:08.489] iteration 9400 : mean_dice : 0.702873
[16:12:09.136] iteration 9401: loss: 0.060999, loss_s1: 0.039417, loss_fp: 0.001394, loss_freq: 0.015013
[16:12:09.760] iteration 9402: loss: 0.050288, loss_s1: 0.036225, loss_fp: 0.000695, loss_freq: 0.014261
[16:12:10.389] iteration 9403: loss: 0.098944, loss_s1: 0.090237, loss_fp: 0.006212, loss_freq: 0.014890
[16:12:11.025] iteration 9404: loss: 0.089352, loss_s1: 0.035789, loss_fp: 0.001777, loss_freq: 0.074467
[16:12:11.652] iteration 9405: loss: 0.101302, loss_s1: 0.050284, loss_fp: 0.012868, loss_freq: 0.057476
[16:12:12.278] iteration 9406: loss: 0.071321, loss_s1: 0.055936, loss_fp: 0.006922, loss_freq: 0.033793
[16:12:12.913] iteration 9407: loss: 0.061415, loss_s1: 0.019970, loss_fp: 0.001461, loss_freq: 0.030351
[16:12:13.537] iteration 9408: loss: 0.111267, loss_s1: 0.107647, loss_fp: 0.002607, loss_freq: 0.026648
[16:12:14.166] iteration 9409: loss: 0.076839, loss_s1: 0.037006, loss_fp: 0.002719, loss_freq: 0.044400
[16:12:14.794] iteration 9410: loss: 0.105917, loss_s1: 0.090655, loss_fp: 0.003907, loss_freq: 0.039773
[16:12:15.425] iteration 9411: loss: 0.075029, loss_s1: 0.032003, loss_fp: 0.004079, loss_freq: 0.056340
[16:12:16.051] iteration 9412: loss: 0.063391, loss_s1: 0.031082, loss_fp: 0.002851, loss_freq: 0.016726
[16:12:16.676] iteration 9413: loss: 0.123100, loss_s1: 0.125097, loss_fp: 0.008077, loss_freq: 0.061562
[16:12:17.310] iteration 9414: loss: 0.086290, loss_s1: 0.063021, loss_fp: 0.001145, loss_freq: 0.030686
[16:12:17.935] iteration 9415: loss: 0.146331, loss_s1: 0.131076, loss_fp: 0.033401, loss_freq: 0.067710
[16:12:18.560] iteration 9416: loss: 0.071704, loss_s1: 0.056626, loss_fp: 0.006278, loss_freq: 0.020912
[16:12:19.184] iteration 9417: loss: 0.039821, loss_s1: 0.016127, loss_fp: 0.000802, loss_freq: 0.007243
[16:12:19.807] iteration 9418: loss: 0.071298, loss_s1: 0.066850, loss_fp: 0.001540, loss_freq: 0.032246
[16:12:20.431] iteration 9419: loss: 0.064060, loss_s1: 0.039633, loss_fp: 0.005054, loss_freq: 0.028962
[16:12:21.110] iteration 9420: loss: 0.110727, loss_s1: 0.080804, loss_fp: 0.014445, loss_freq: 0.059566
[16:12:21.769] iteration 9421: loss: 0.209451, loss_s1: 0.188383, loss_fp: 0.038677, loss_freq: 0.130709
[16:12:22.428] iteration 9422: loss: 0.110964, loss_s1: 0.064290, loss_fp: 0.003428, loss_freq: 0.036556
[16:12:23.088] iteration 9423: loss: 0.169253, loss_s1: 0.152577, loss_fp: 0.032663, loss_freq: 0.084128
[16:12:23.747] iteration 9424: loss: 0.077930, loss_s1: 0.051740, loss_fp: 0.013560, loss_freq: 0.037794
[16:12:24.385] iteration 9425: loss: 0.045861, loss_s1: 0.008819, loss_fp: 0.001193, loss_freq: 0.013191
[16:12:25.013] iteration 9426: loss: 0.081414, loss_s1: 0.077716, loss_fp: 0.000976, loss_freq: 0.011133
[16:12:25.647] iteration 9427: loss: 0.096438, loss_s1: 0.027170, loss_fp: 0.047263, loss_freq: 0.051480
[16:12:26.275] iteration 9428: loss: 0.072865, loss_s1: 0.070893, loss_fp: 0.000506, loss_freq: 0.016730
[16:12:26.903] iteration 9429: loss: 0.132380, loss_s1: 0.054071, loss_fp: 0.002555, loss_freq: 0.015776
[16:12:27.535] iteration 9430: loss: 0.109386, loss_s1: 0.098503, loss_fp: 0.001196, loss_freq: 0.020726
[16:12:28.168] iteration 9431: loss: 0.121686, loss_s1: 0.046622, loss_fp: 0.000573, loss_freq: 0.014951
[16:12:28.797] iteration 9432: loss: 0.079943, loss_s1: 0.069657, loss_fp: 0.000520, loss_freq: 0.028113
[16:12:29.422] iteration 9433: loss: 0.081048, loss_s1: 0.053930, loss_fp: 0.000816, loss_freq: 0.043027
[16:12:30.047] iteration 9434: loss: 0.067017, loss_s1: 0.053304, loss_fp: 0.003353, loss_freq: 0.026335
[16:12:30.680] iteration 9435: loss: 0.075192, loss_s1: 0.019981, loss_fp: 0.002516, loss_freq: 0.014791
[16:12:31.356] iteration 9436: loss: 0.069980, loss_s1: 0.029547, loss_fp: 0.001454, loss_freq: 0.015873
[16:12:32.022] iteration 9437: loss: 0.117818, loss_s1: 0.097621, loss_fp: 0.005579, loss_freq: 0.015975
[16:12:32.681] iteration 9438: loss: 0.098656, loss_s1: 0.057573, loss_fp: 0.004836, loss_freq: 0.036651
[16:12:33.324] iteration 9439: loss: 0.067936, loss_s1: 0.061426, loss_fp: 0.002231, loss_freq: 0.013999
[16:12:33.964] iteration 9440: loss: 0.081455, loss_s1: 0.027283, loss_fp: 0.000965, loss_freq: 0.067831
[16:12:34.593] iteration 9441: loss: 0.125674, loss_s1: 0.109433, loss_fp: 0.001412, loss_freq: 0.060420
[16:12:35.219] iteration 9442: loss: 0.087832, loss_s1: 0.040468, loss_fp: 0.003923, loss_freq: 0.045586
[16:12:35.858] iteration 9443: loss: 0.161571, loss_s1: 0.072249, loss_fp: 0.006284, loss_freq: 0.038127
[16:12:36.498] iteration 9444: loss: 0.056795, loss_s1: 0.031720, loss_fp: 0.001516, loss_freq: 0.035544
[16:12:37.141] iteration 9445: loss: 0.081776, loss_s1: 0.043485, loss_fp: 0.001412, loss_freq: 0.021526
[16:12:37.782] iteration 9446: loss: 0.110906, loss_s1: 0.112303, loss_fp: 0.005123, loss_freq: 0.048956
[16:12:38.408] iteration 9447: loss: 0.162827, loss_s1: 0.079708, loss_fp: 0.002721, loss_freq: 0.171034
[16:12:39.035] iteration 9448: loss: 0.068435, loss_s1: 0.046357, loss_fp: 0.001630, loss_freq: 0.042475
[16:12:39.662] iteration 9449: loss: 0.091229, loss_s1: 0.048289, loss_fp: 0.001640, loss_freq: 0.017179
[16:12:40.289] iteration 9450: loss: 0.081536, loss_s1: 0.057856, loss_fp: 0.002973, loss_freq: 0.035812
[16:12:40.918] iteration 9451: loss: 0.133414, loss_s1: 0.084716, loss_fp: 0.004158, loss_freq: 0.090040
[16:12:41.540] iteration 9452: loss: 0.080457, loss_s1: 0.055426, loss_fp: 0.002374, loss_freq: 0.051310
[16:12:42.172] iteration 9453: loss: 0.046574, loss_s1: 0.007348, loss_fp: 0.002308, loss_freq: 0.006892
[16:12:42.799] iteration 9454: loss: 0.098783, loss_s1: 0.071098, loss_fp: 0.000981, loss_freq: 0.039642
[16:12:43.427] iteration 9455: loss: 0.077719, loss_s1: 0.045055, loss_fp: 0.004419, loss_freq: 0.018558
[16:12:44.053] iteration 9456: loss: 0.080479, loss_s1: 0.079190, loss_fp: 0.003036, loss_freq: 0.030216
[16:12:44.678] iteration 9457: loss: 0.068748, loss_s1: 0.027700, loss_fp: 0.002312, loss_freq: 0.034743
[16:12:45.303] iteration 9458: loss: 0.103658, loss_s1: 0.060810, loss_fp: 0.002470, loss_freq: 0.087580
[16:12:45.992] iteration 9459: loss: 0.106902, loss_s1: 0.042562, loss_fp: 0.001533, loss_freq: 0.113336
[16:12:46.697] iteration 9460: loss: 0.075826, loss_s1: 0.036190, loss_fp: 0.000702, loss_freq: 0.019243
[16:12:47.347] iteration 9461: loss: 0.066413, loss_s1: 0.033029, loss_fp: 0.008398, loss_freq: 0.030590
[16:12:47.976] iteration 9462: loss: 0.072063, loss_s1: 0.052933, loss_fp: 0.002850, loss_freq: 0.035004
[16:12:48.605] iteration 9463: loss: 0.101205, loss_s1: 0.019322, loss_fp: 0.001428, loss_freq: 0.066423
[16:12:49.229] iteration 9464: loss: 0.065724, loss_s1: 0.025549, loss_fp: 0.000542, loss_freq: 0.012563
[16:12:49.855] iteration 9465: loss: 0.073959, loss_s1: 0.045519, loss_fp: 0.000919, loss_freq: 0.014555
[16:12:50.483] iteration 9466: loss: 0.099901, loss_s1: 0.036665, loss_fp: 0.002042, loss_freq: 0.033778
[16:12:51.116] iteration 9467: loss: 0.082667, loss_s1: 0.049777, loss_fp: 0.000492, loss_freq: 0.022467
[16:12:51.746] iteration 9468: loss: 0.052754, loss_s1: 0.039507, loss_fp: 0.000880, loss_freq: 0.015762
[16:12:52.373] iteration 9469: loss: 0.098024, loss_s1: 0.079531, loss_fp: 0.005354, loss_freq: 0.064445
[16:12:53.000] iteration 9470: loss: 0.093500, loss_s1: 0.048374, loss_fp: 0.021956, loss_freq: 0.025372
[16:12:53.627] iteration 9471: loss: 0.113583, loss_s1: 0.095552, loss_fp: 0.006101, loss_freq: 0.067338
[16:12:54.252] iteration 9472: loss: 0.070536, loss_s1: 0.062626, loss_fp: 0.002972, loss_freq: 0.020252
[16:12:54.877] iteration 9473: loss: 0.064398, loss_s1: 0.010556, loss_fp: 0.002872, loss_freq: 0.064624
[16:12:55.504] iteration 9474: loss: 0.078815, loss_s1: 0.069910, loss_fp: 0.002470, loss_freq: 0.021635
[16:12:56.133] iteration 9475: loss: 0.055090, loss_s1: 0.026801, loss_fp: 0.000850, loss_freq: 0.027211
[16:12:56.758] iteration 9476: loss: 0.073720, loss_s1: 0.056151, loss_fp: 0.002004, loss_freq: 0.011117
[16:12:57.390] iteration 9477: loss: 0.062992, loss_s1: 0.032450, loss_fp: 0.011916, loss_freq: 0.029080
[16:12:58.018] iteration 9478: loss: 0.122312, loss_s1: 0.060204, loss_fp: 0.009038, loss_freq: 0.070388
[16:12:58.643] iteration 9479: loss: 0.061726, loss_s1: 0.037015, loss_fp: 0.003501, loss_freq: 0.033543
[16:12:59.267] iteration 9480: loss: 0.078383, loss_s1: 0.027186, loss_fp: 0.003254, loss_freq: 0.049481
[16:12:59.895] iteration 9481: loss: 0.147942, loss_s1: 0.086715, loss_fp: 0.008693, loss_freq: 0.068170
[16:13:00.519] iteration 9482: loss: 0.072109, loss_s1: 0.055320, loss_fp: 0.002961, loss_freq: 0.028759
[16:13:01.149] iteration 9483: loss: 0.077605, loss_s1: 0.018068, loss_fp: 0.001695, loss_freq: 0.015705
[16:13:01.774] iteration 9484: loss: 0.086131, loss_s1: 0.075980, loss_fp: 0.001565, loss_freq: 0.034339
[16:13:02.405] iteration 9485: loss: 0.059539, loss_s1: 0.039615, loss_fp: 0.002410, loss_freq: 0.030155
[16:13:03.032] iteration 9486: loss: 0.056870, loss_s1: 0.056069, loss_fp: 0.002899, loss_freq: 0.012659
[16:13:03.658] iteration 9487: loss: 0.076319, loss_s1: 0.045745, loss_fp: 0.002443, loss_freq: 0.034442
[16:13:04.284] iteration 9488: loss: 0.091357, loss_s1: 0.059625, loss_fp: 0.003728, loss_freq: 0.058445
[16:13:04.911] iteration 9489: loss: 0.058178, loss_s1: 0.030931, loss_fp: 0.004445, loss_freq: 0.018018
[16:13:05.575] iteration 9490: loss: 0.119392, loss_s1: 0.102524, loss_fp: 0.007795, loss_freq: 0.083857
[16:13:06.202] iteration 9491: loss: 0.050149, loss_s1: 0.027016, loss_fp: 0.002124, loss_freq: 0.029280
[16:13:06.825] iteration 9492: loss: 0.117138, loss_s1: 0.092374, loss_fp: 0.004871, loss_freq: 0.025884
[16:13:07.482] iteration 9493: loss: 0.050633, loss_s1: 0.023617, loss_fp: 0.001157, loss_freq: 0.006199
[16:13:08.108] iteration 9494: loss: 0.085294, loss_s1: 0.064163, loss_fp: 0.001963, loss_freq: 0.043231
[16:13:08.731] iteration 9495: loss: 0.060403, loss_s1: 0.022045, loss_fp: 0.000725, loss_freq: 0.024246
[16:13:09.364] iteration 9496: loss: 0.112927, loss_s1: 0.034676, loss_fp: 0.007679, loss_freq: 0.074969
[16:13:09.996] iteration 9497: loss: 0.078642, loss_s1: 0.061693, loss_fp: 0.009424, loss_freq: 0.031770
[16:13:10.622] iteration 9498: loss: 0.048666, loss_s1: 0.027098, loss_fp: 0.005147, loss_freq: 0.010118
[16:13:11.247] iteration 9499: loss: 0.085988, loss_s1: 0.047581, loss_fp: 0.009213, loss_freq: 0.043430
[16:13:12.250] iteration 9500: loss: 0.059110, loss_s1: 0.040719, loss_fp: 0.002094, loss_freq: 0.031985
[16:13:12.915] iteration 9501: loss: 0.076658, loss_s1: 0.045941, loss_fp: 0.003104, loss_freq: 0.024115
[16:13:13.580] iteration 9502: loss: 0.102775, loss_s1: 0.066588, loss_fp: 0.005802, loss_freq: 0.048020
[16:13:14.244] iteration 9503: loss: 0.061203, loss_s1: 0.037491, loss_fp: 0.001360, loss_freq: 0.015052
[16:13:14.888] iteration 9504: loss: 0.048075, loss_s1: 0.023134, loss_fp: 0.002886, loss_freq: 0.007567
[16:13:15.516] iteration 9505: loss: 0.148264, loss_s1: 0.120399, loss_fp: 0.004450, loss_freq: 0.044030
[16:13:16.153] iteration 9506: loss: 0.074324, loss_s1: 0.086089, loss_fp: 0.000850, loss_freq: 0.011353
[16:13:16.782] iteration 9507: loss: 0.057535, loss_s1: 0.032966, loss_fp: 0.001795, loss_freq: 0.034945
[16:13:17.411] iteration 9508: loss: 0.066880, loss_s1: 0.060646, loss_fp: 0.012945, loss_freq: 0.015451
[16:13:18.048] iteration 9509: loss: 0.077792, loss_s1: 0.082171, loss_fp: 0.008724, loss_freq: 0.016905
[16:13:18.675] iteration 9510: loss: 0.074293, loss_s1: 0.044425, loss_fp: 0.001394, loss_freq: 0.029001
[16:13:19.305] iteration 9511: loss: 0.072681, loss_s1: 0.040446, loss_fp: 0.003613, loss_freq: 0.047641
[16:13:19.936] iteration 9512: loss: 0.070074, loss_s1: 0.040978, loss_fp: 0.008022, loss_freq: 0.046086
[16:13:20.563] iteration 9513: loss: 0.060939, loss_s1: 0.032605, loss_fp: 0.001723, loss_freq: 0.015783
[16:13:21.197] iteration 9514: loss: 0.070004, loss_s1: 0.059649, loss_fp: 0.000628, loss_freq: 0.034154
[16:13:21.828] iteration 9515: loss: 0.085847, loss_s1: 0.063105, loss_fp: 0.002033, loss_freq: 0.049674
[16:13:22.479] iteration 9516: loss: 0.156773, loss_s1: 0.039892, loss_fp: 0.002594, loss_freq: 0.014566
[16:13:23.102] iteration 9517: loss: 0.061847, loss_s1: 0.027540, loss_fp: 0.001517, loss_freq: 0.031775
[16:13:23.786] iteration 9518: loss: 0.048888, loss_s1: 0.014519, loss_fp: 0.000664, loss_freq: 0.007710
[16:13:24.449] iteration 9519: loss: 0.078040, loss_s1: 0.053621, loss_fp: 0.002160, loss_freq: 0.019023
[16:13:25.109] iteration 9520: loss: 0.042726, loss_s1: 0.017933, loss_fp: 0.000462, loss_freq: 0.011266
[16:13:25.764] iteration 9521: loss: 0.051177, loss_s1: 0.026408, loss_fp: 0.001726, loss_freq: 0.013962
[16:13:26.409] iteration 9522: loss: 0.074262, loss_s1: 0.042303, loss_fp: 0.001400, loss_freq: 0.023272
[16:13:27.048] iteration 9523: loss: 0.245649, loss_s1: 0.159816, loss_fp: 0.000976, loss_freq: 0.283030
[16:13:27.675] iteration 9524: loss: 0.055854, loss_s1: 0.044680, loss_fp: 0.001374, loss_freq: 0.023955
[16:13:28.336] iteration 9525: loss: 0.094822, loss_s1: 0.065876, loss_fp: 0.000900, loss_freq: 0.058071
[16:13:29.001] iteration 9526: loss: 0.088805, loss_s1: 0.051885, loss_fp: 0.002882, loss_freq: 0.053686
[16:13:29.658] iteration 9527: loss: 0.101336, loss_s1: 0.075541, loss_fp: 0.034883, loss_freq: 0.036863
[16:13:30.293] iteration 9528: loss: 0.090375, loss_s1: 0.055379, loss_fp: 0.002256, loss_freq: 0.035382
[16:13:30.923] iteration 9529: loss: 0.055109, loss_s1: 0.035049, loss_fp: 0.000619, loss_freq: 0.019161
[16:13:31.553] iteration 9530: loss: 0.055225, loss_s1: 0.052275, loss_fp: 0.001897, loss_freq: 0.013723
[16:13:32.183] iteration 9531: loss: 0.064106, loss_s1: 0.047376, loss_fp: 0.002871, loss_freq: 0.011712
[16:13:32.809] iteration 9532: loss: 0.061676, loss_s1: 0.021774, loss_fp: 0.002193, loss_freq: 0.041752
[16:13:33.437] iteration 9533: loss: 0.048413, loss_s1: 0.027531, loss_fp: 0.001644, loss_freq: 0.026946
[16:13:34.062] iteration 9534: loss: 0.093198, loss_s1: 0.020283, loss_fp: 0.005250, loss_freq: 0.018301
[16:13:34.691] iteration 9535: loss: 0.106413, loss_s1: 0.073944, loss_fp: 0.011196, loss_freq: 0.060275
[16:13:35.314] iteration 9536: loss: 0.126852, loss_s1: 0.111916, loss_fp: 0.004514, loss_freq: 0.044097
[16:13:35.943] iteration 9537: loss: 0.102609, loss_s1: 0.063652, loss_fp: 0.002971, loss_freq: 0.045576
[16:13:36.572] iteration 9538: loss: 0.116281, loss_s1: 0.077889, loss_fp: 0.011619, loss_freq: 0.043125
[16:13:37.234] iteration 9539: loss: 0.084857, loss_s1: 0.061463, loss_fp: 0.003084, loss_freq: 0.029800
[16:13:37.860] iteration 9540: loss: 0.095994, loss_s1: 0.045598, loss_fp: 0.003222, loss_freq: 0.037968
[16:13:38.484] iteration 9541: loss: 0.097843, loss_s1: 0.085914, loss_fp: 0.004022, loss_freq: 0.058447
[16:13:39.116] iteration 9542: loss: 0.100583, loss_s1: 0.084458, loss_fp: 0.004304, loss_freq: 0.049021
[16:13:39.741] iteration 9543: loss: 0.107779, loss_s1: 0.113901, loss_fp: 0.001632, loss_freq: 0.047786
[16:13:40.366] iteration 9544: loss: 0.097355, loss_s1: 0.069503, loss_fp: 0.018250, loss_freq: 0.051342
[16:13:40.991] iteration 9545: loss: 0.079938, loss_s1: 0.059158, loss_fp: 0.002093, loss_freq: 0.010869
[16:13:41.618] iteration 9546: loss: 0.050236, loss_s1: 0.036622, loss_fp: 0.003082, loss_freq: 0.006655
[16:13:42.248] iteration 9547: loss: 0.074608, loss_s1: 0.084269, loss_fp: 0.005203, loss_freq: 0.017371
[16:13:42.875] iteration 9548: loss: 0.069154, loss_s1: 0.032299, loss_fp: 0.001053, loss_freq: 0.035762
[16:13:43.501] iteration 9549: loss: 0.076438, loss_s1: 0.057323, loss_fp: 0.007269, loss_freq: 0.041480
[16:13:44.125] iteration 9550: loss: 0.063853, loss_s1: 0.050913, loss_fp: 0.003542, loss_freq: 0.019376
[16:13:44.749] iteration 9551: loss: 0.058025, loss_s1: 0.024287, loss_fp: 0.003489, loss_freq: 0.022056
[16:13:45.372] iteration 9552: loss: 0.081983, loss_s1: 0.057747, loss_fp: 0.001074, loss_freq: 0.041203
[16:13:46.004] iteration 9553: loss: 0.086118, loss_s1: 0.053130, loss_fp: 0.001434, loss_freq: 0.062639
[16:13:46.626] iteration 9554: loss: 0.076854, loss_s1: 0.014593, loss_fp: 0.003048, loss_freq: 0.020364
[16:13:47.252] iteration 9555: loss: 0.131999, loss_s1: 0.083181, loss_fp: 0.008833, loss_freq: 0.097234
[16:13:47.875] iteration 9556: loss: 0.071200, loss_s1: 0.044542, loss_fp: 0.004648, loss_freq: 0.024724
[16:13:48.501] iteration 9557: loss: 0.109334, loss_s1: 0.048472, loss_fp: 0.000332, loss_freq: 0.065768
[16:13:49.128] iteration 9558: loss: 0.054325, loss_s1: 0.039174, loss_fp: 0.003389, loss_freq: 0.013962
[16:13:49.757] iteration 9559: loss: 0.054119, loss_s1: 0.045505, loss_fp: 0.004641, loss_freq: 0.014246
[16:13:50.382] iteration 9560: loss: 0.053222, loss_s1: 0.032625, loss_fp: 0.003602, loss_freq: 0.026036
[16:13:51.007] iteration 9561: loss: 0.071366, loss_s1: 0.059172, loss_fp: 0.004506, loss_freq: 0.019740
[16:13:51.632] iteration 9562: loss: 0.083584, loss_s1: 0.046941, loss_fp: 0.001232, loss_freq: 0.017785
[16:13:52.256] iteration 9563: loss: 0.076532, loss_s1: 0.028781, loss_fp: 0.008282, loss_freq: 0.034146
[16:13:52.881] iteration 9564: loss: 0.095111, loss_s1: 0.098558, loss_fp: 0.001455, loss_freq: 0.019956
[16:13:53.507] iteration 9565: loss: 0.068051, loss_s1: 0.035957, loss_fp: 0.003215, loss_freq: 0.038970
[16:13:54.131] iteration 9566: loss: 0.070793, loss_s1: 0.046527, loss_fp: 0.004559, loss_freq: 0.034623
[16:13:54.761] iteration 9567: loss: 0.059545, loss_s1: 0.035597, loss_fp: 0.002157, loss_freq: 0.037835
[16:13:55.387] iteration 9568: loss: 0.051048, loss_s1: 0.028969, loss_fp: 0.003268, loss_freq: 0.018577
[16:13:56.011] iteration 9569: loss: 0.094525, loss_s1: 0.037033, loss_fp: 0.001622, loss_freq: 0.026740
[16:13:56.634] iteration 9570: loss: 0.065781, loss_s1: 0.068431, loss_fp: 0.003841, loss_freq: 0.017100
[16:13:57.262] iteration 9571: loss: 0.072736, loss_s1: 0.020259, loss_fp: 0.002162, loss_freq: 0.036372
[16:13:57.885] iteration 9572: loss: 0.067790, loss_s1: 0.042891, loss_fp: 0.003749, loss_freq: 0.028612
[16:13:58.513] iteration 9573: loss: 0.057397, loss_s1: 0.036349, loss_fp: 0.001554, loss_freq: 0.015005
[16:13:59.136] iteration 9574: loss: 0.095237, loss_s1: 0.094843, loss_fp: 0.001068, loss_freq: 0.044817
[16:13:59.762] iteration 9575: loss: 0.069693, loss_s1: 0.041513, loss_fp: 0.003881, loss_freq: 0.016955
[16:14:00.387] iteration 9576: loss: 0.108434, loss_s1: 0.089797, loss_fp: 0.003300, loss_freq: 0.061444
[16:14:01.016] iteration 9577: loss: 0.045760, loss_s1: 0.027113, loss_fp: 0.006903, loss_freq: 0.015228
[16:14:01.642] iteration 9578: loss: 0.048596, loss_s1: 0.032634, loss_fp: 0.001564, loss_freq: 0.020389
[16:14:02.270] iteration 9579: loss: 0.092505, loss_s1: 0.093512, loss_fp: 0.007955, loss_freq: 0.032034
[16:14:02.897] iteration 9580: loss: 0.142563, loss_s1: 0.134794, loss_fp: 0.003615, loss_freq: 0.100643
[16:14:03.523] iteration 9581: loss: 0.094754, loss_s1: 0.083415, loss_fp: 0.006756, loss_freq: 0.049374
[16:14:04.148] iteration 9582: loss: 0.093906, loss_s1: 0.084011, loss_fp: 0.018568, loss_freq: 0.039897
[16:14:04.774] iteration 9583: loss: 0.079629, loss_s1: 0.044872, loss_fp: 0.006604, loss_freq: 0.054597
[16:14:05.398] iteration 9584: loss: 0.099933, loss_s1: 0.046493, loss_fp: 0.005454, loss_freq: 0.100067
[16:14:06.029] iteration 9585: loss: 0.049381, loss_s1: 0.019347, loss_fp: 0.003267, loss_freq: 0.032905
[16:14:06.729] iteration 9586: loss: 0.116248, loss_s1: 0.055612, loss_fp: 0.004357, loss_freq: 0.044555
[16:14:07.384] iteration 9587: loss: 0.056331, loss_s1: 0.029467, loss_fp: 0.001760, loss_freq: 0.015070
[16:14:08.054] iteration 9588: loss: 0.103505, loss_s1: 0.098675, loss_fp: 0.005929, loss_freq: 0.036262
[16:14:08.692] iteration 9589: loss: 0.084605, loss_s1: 0.050503, loss_fp: 0.001624, loss_freq: 0.039914
[16:14:09.362] iteration 9590: loss: 0.120596, loss_s1: 0.033716, loss_fp: 0.001148, loss_freq: 0.025013
[16:14:09.984] iteration 9591: loss: 0.084138, loss_s1: 0.075965, loss_fp: 0.002900, loss_freq: 0.026166
[16:14:10.611] iteration 9592: loss: 0.103376, loss_s1: 0.034536, loss_fp: 0.001939, loss_freq: 0.011159
[16:14:11.237] iteration 9593: loss: 0.064310, loss_s1: 0.030917, loss_fp: 0.001732, loss_freq: 0.029338
[16:14:11.862] iteration 9594: loss: 0.058737, loss_s1: 0.070404, loss_fp: 0.000536, loss_freq: 0.010621
[16:14:12.486] iteration 9595: loss: 0.053822, loss_s1: 0.030048, loss_fp: 0.002135, loss_freq: 0.020148
[16:14:13.112] iteration 9596: loss: 0.068682, loss_s1: 0.049028, loss_fp: 0.001065, loss_freq: 0.019953
[16:14:13.738] iteration 9597: loss: 0.073206, loss_s1: 0.025320, loss_fp: 0.000619, loss_freq: 0.037766
[16:14:14.369] iteration 9598: loss: 0.076264, loss_s1: 0.086994, loss_fp: 0.000733, loss_freq: 0.017306
[16:14:14.999] iteration 9599: loss: 0.079976, loss_s1: 0.081967, loss_fp: 0.005391, loss_freq: 0.032337
[16:14:15.627] iteration 9600: loss: 0.078620, loss_s1: 0.047224, loss_fp: 0.002500, loss_freq: 0.044224
[16:14:18.775] iteration 9600 : mean_dice : 0.678949
[16:14:19.428] iteration 9601: loss: 0.084069, loss_s1: 0.031873, loss_fp: 0.003789, loss_freq: 0.045539
[16:14:20.052] iteration 9602: loss: 0.075485, loss_s1: 0.048628, loss_fp: 0.007847, loss_freq: 0.037080
[16:14:20.679] iteration 9603: loss: 0.083556, loss_s1: 0.058605, loss_fp: 0.004398, loss_freq: 0.048899
[16:14:21.309] iteration 9604: loss: 0.068123, loss_s1: 0.047964, loss_fp: 0.001956, loss_freq: 0.017463
[16:14:21.937] iteration 9605: loss: 0.048079, loss_s1: 0.022849, loss_fp: 0.002493, loss_freq: 0.027065
[16:14:22.570] iteration 9606: loss: 0.052428, loss_s1: 0.020034, loss_fp: 0.001850, loss_freq: 0.023607
[16:14:23.231] iteration 9607: loss: 0.134796, loss_s1: 0.085455, loss_fp: 0.003564, loss_freq: 0.111364
[16:14:23.887] iteration 9608: loss: 0.155539, loss_s1: 0.085952, loss_fp: 0.013759, loss_freq: 0.113472
[16:14:24.544] iteration 9609: loss: 0.089290, loss_s1: 0.087257, loss_fp: 0.002629, loss_freq: 0.020291
[16:14:25.193] iteration 9610: loss: 0.086750, loss_s1: 0.050053, loss_fp: 0.009389, loss_freq: 0.037389
[16:14:25.819] iteration 9611: loss: 0.093915, loss_s1: 0.086798, loss_fp: 0.005138, loss_freq: 0.046496
[16:14:26.446] iteration 9612: loss: 0.087643, loss_s1: 0.072362, loss_fp: 0.005697, loss_freq: 0.029389
[16:14:27.071] iteration 9613: loss: 0.080688, loss_s1: 0.052395, loss_fp: 0.002348, loss_freq: 0.042654
[16:14:27.694] iteration 9614: loss: 0.039360, loss_s1: 0.021148, loss_fp: 0.000241, loss_freq: 0.004996
[16:14:28.324] iteration 9615: loss: 0.097342, loss_s1: 0.071970, loss_fp: 0.009304, loss_freq: 0.041137
[16:14:28.947] iteration 9616: loss: 0.083999, loss_s1: 0.040588, loss_fp: 0.002573, loss_freq: 0.079129
[16:14:29.573] iteration 9617: loss: 0.039451, loss_s1: 0.022429, loss_fp: 0.000576, loss_freq: 0.014959
[16:14:30.200] iteration 9618: loss: 0.068032, loss_s1: 0.032199, loss_fp: 0.001247, loss_freq: 0.017487
[16:14:30.824] iteration 9619: loss: 0.099034, loss_s1: 0.073895, loss_fp: 0.003195, loss_freq: 0.067276
[16:14:31.488] iteration 9620: loss: 0.074676, loss_s1: 0.072389, loss_fp: 0.005441, loss_freq: 0.019335
[16:14:32.140] iteration 9621: loss: 0.065675, loss_s1: 0.034736, loss_fp: 0.000321, loss_freq: 0.016308
[16:14:32.766] iteration 9622: loss: 0.072505, loss_s1: 0.051122, loss_fp: 0.001117, loss_freq: 0.031634
[16:14:33.391] iteration 9623: loss: 0.062428, loss_s1: 0.058629, loss_fp: 0.001658, loss_freq: 0.012574
[16:14:34.014] iteration 9624: loss: 0.092540, loss_s1: 0.068999, loss_fp: 0.000656, loss_freq: 0.046949
[16:14:34.657] iteration 9625: loss: 0.077154, loss_s1: 0.017053, loss_fp: 0.007320, loss_freq: 0.027689
[16:14:35.282] iteration 9626: loss: 0.068546, loss_s1: 0.038329, loss_fp: 0.000433, loss_freq: 0.016967
[16:14:35.912] iteration 9627: loss: 0.188643, loss_s1: 0.069281, loss_fp: 0.000710, loss_freq: 0.136445
[16:14:36.534] iteration 9628: loss: 0.066559, loss_s1: 0.043920, loss_fp: 0.000516, loss_freq: 0.006463
[16:14:37.165] iteration 9629: loss: 0.079014, loss_s1: 0.094405, loss_fp: 0.001363, loss_freq: 0.018643
[16:14:37.786] iteration 9630: loss: 0.096860, loss_s1: 0.075457, loss_fp: 0.001863, loss_freq: 0.073860
[16:14:38.413] iteration 9631: loss: 0.057564, loss_s1: 0.027316, loss_fp: 0.003857, loss_freq: 0.038691
[16:14:39.043] iteration 9632: loss: 0.083465, loss_s1: 0.087198, loss_fp: 0.003067, loss_freq: 0.028417
[16:14:39.670] iteration 9633: loss: 0.070678, loss_s1: 0.059545, loss_fp: 0.005597, loss_freq: 0.027831
[16:14:40.296] iteration 9634: loss: 0.112209, loss_s1: 0.086986, loss_fp: 0.001381, loss_freq: 0.085472
[16:14:40.921] iteration 9635: loss: 0.060041, loss_s1: 0.047455, loss_fp: 0.004183, loss_freq: 0.025286
[16:14:41.547] iteration 9636: loss: 0.081162, loss_s1: 0.033211, loss_fp: 0.006425, loss_freq: 0.032830
[16:14:42.175] iteration 9637: loss: 0.057023, loss_s1: 0.038936, loss_fp: 0.004359, loss_freq: 0.024591
[16:14:42.821] iteration 9638: loss: 0.069385, loss_s1: 0.060014, loss_fp: 0.001071, loss_freq: 0.020658
[16:14:43.480] iteration 9639: loss: 0.107021, loss_s1: 0.083235, loss_fp: 0.005164, loss_freq: 0.043824
[16:14:44.120] iteration 9640: loss: 0.095570, loss_s1: 0.084014, loss_fp: 0.003634, loss_freq: 0.052252
[16:14:44.746] iteration 9641: loss: 0.076448, loss_s1: 0.040347, loss_fp: 0.002417, loss_freq: 0.038862
[16:14:45.378] iteration 9642: loss: 0.098329, loss_s1: 0.059177, loss_fp: 0.006741, loss_freq: 0.043961
[16:14:46.027] iteration 9643: loss: 0.099239, loss_s1: 0.084727, loss_fp: 0.006736, loss_freq: 0.040398
[16:14:46.659] iteration 9644: loss: 0.042559, loss_s1: 0.021673, loss_fp: 0.000576, loss_freq: 0.006833
[16:14:47.289] iteration 9645: loss: 0.074405, loss_s1: 0.044860, loss_fp: 0.007947, loss_freq: 0.020928
[16:14:47.914] iteration 9646: loss: 0.112396, loss_s1: 0.112105, loss_fp: 0.005600, loss_freq: 0.060833
[16:14:48.548] iteration 9647: loss: 0.076930, loss_s1: 0.049198, loss_fp: 0.004928, loss_freq: 0.039838
[16:14:49.173] iteration 9648: loss: 0.088457, loss_s1: 0.051474, loss_fp: 0.001750, loss_freq: 0.024405
[16:14:49.799] iteration 9649: loss: 0.128425, loss_s1: 0.111225, loss_fp: 0.013267, loss_freq: 0.064945
[16:14:50.424] iteration 9650: loss: 0.097176, loss_s1: 0.030222, loss_fp: 0.005155, loss_freq: 0.042615
[16:14:51.049] iteration 9651: loss: 0.123055, loss_s1: 0.112655, loss_fp: 0.013247, loss_freq: 0.059140
[16:14:51.681] iteration 9652: loss: 0.061477, loss_s1: 0.037818, loss_fp: 0.004003, loss_freq: 0.029315
[16:14:52.308] iteration 9653: loss: 0.060428, loss_s1: 0.038439, loss_fp: 0.002413, loss_freq: 0.016842
[16:14:52.940] iteration 9654: loss: 0.041828, loss_s1: 0.019847, loss_fp: 0.013520, loss_freq: 0.004975
[16:14:53.562] iteration 9655: loss: 0.041121, loss_s1: 0.011487, loss_fp: 0.000815, loss_freq: 0.019299
[16:14:54.191] iteration 9656: loss: 0.051498, loss_s1: 0.026410, loss_fp: 0.001359, loss_freq: 0.011970
[16:14:54.824] iteration 9657: loss: 0.084591, loss_s1: 0.044055, loss_fp: 0.003877, loss_freq: 0.059410
[16:14:55.450] iteration 9658: loss: 0.132721, loss_s1: 0.088393, loss_fp: 0.008797, loss_freq: 0.058667
[16:14:56.075] iteration 9659: loss: 0.074018, loss_s1: 0.053011, loss_fp: 0.002831, loss_freq: 0.027537
[16:14:56.699] iteration 9660: loss: 0.078045, loss_s1: 0.023074, loss_fp: 0.000452, loss_freq: 0.065401
[16:14:57.657] iteration 9661: loss: 0.050123, loss_s1: 0.027935, loss_fp: 0.001774, loss_freq: 0.021009
[16:14:58.283] iteration 9662: loss: 0.077543, loss_s1: 0.071859, loss_fp: 0.001467, loss_freq: 0.014380
[16:14:58.911] iteration 9663: loss: 0.085851, loss_s1: 0.027833, loss_fp: 0.002840, loss_freq: 0.052894
[16:14:59.537] iteration 9664: loss: 0.065618, loss_s1: 0.058828, loss_fp: 0.000732, loss_freq: 0.013987
[16:15:00.166] iteration 9665: loss: 0.084935, loss_s1: 0.029705, loss_fp: 0.002371, loss_freq: 0.031675
[16:15:00.792] iteration 9666: loss: 0.160394, loss_s1: 0.098985, loss_fp: 0.007133, loss_freq: 0.060656
[16:15:01.422] iteration 9667: loss: 0.059269, loss_s1: 0.045304, loss_fp: 0.002805, loss_freq: 0.025303
[16:15:02.053] iteration 9668: loss: 0.090027, loss_s1: 0.086423, loss_fp: 0.003745, loss_freq: 0.032917
[16:15:02.678] iteration 9669: loss: 0.057865, loss_s1: 0.019418, loss_fp: 0.002796, loss_freq: 0.030931
[16:15:03.309] iteration 9670: loss: 0.095045, loss_s1: 0.049644, loss_fp: 0.004598, loss_freq: 0.027159
[16:15:03.938] iteration 9671: loss: 0.054200, loss_s1: 0.022544, loss_fp: 0.004164, loss_freq: 0.018040
[16:15:04.565] iteration 9672: loss: 0.093113, loss_s1: 0.067385, loss_fp: 0.005901, loss_freq: 0.065493
[16:15:05.191] iteration 9673: loss: 0.063483, loss_s1: 0.046119, loss_fp: 0.002133, loss_freq: 0.039041
[16:15:05.816] iteration 9674: loss: 0.072202, loss_s1: 0.021846, loss_fp: 0.001674, loss_freq: 0.029218
[16:15:06.438] iteration 9675: loss: 0.060755, loss_s1: 0.048456, loss_fp: 0.002319, loss_freq: 0.020521
[16:15:07.063] iteration 9676: loss: 0.127158, loss_s1: 0.108158, loss_fp: 0.007713, loss_freq: 0.070964
[16:15:07.687] iteration 9677: loss: 0.104063, loss_s1: 0.038309, loss_fp: 0.003622, loss_freq: 0.015528
[16:15:08.309] iteration 9678: loss: 0.092047, loss_s1: 0.068209, loss_fp: 0.001606, loss_freq: 0.063398
[16:15:08.965] iteration 9679: loss: 0.082887, loss_s1: 0.053333, loss_fp: 0.002849, loss_freq: 0.025375
[16:15:09.587] iteration 9680: loss: 0.107986, loss_s1: 0.046375, loss_fp: 0.006658, loss_freq: 0.050051
[16:15:10.210] iteration 9681: loss: 0.055912, loss_s1: 0.019697, loss_fp: 0.005311, loss_freq: 0.016062
[16:15:10.835] iteration 9682: loss: 0.066597, loss_s1: 0.025291, loss_fp: 0.002568, loss_freq: 0.020365
[16:15:11.459] iteration 9683: loss: 0.086730, loss_s1: 0.032916, loss_fp: 0.002553, loss_freq: 0.030302
[16:15:12.086] iteration 9684: loss: 0.241699, loss_s1: 0.215149, loss_fp: 0.009980, loss_freq: 0.188769
[16:15:12.725] iteration 9685: loss: 0.037777, loss_s1: 0.013545, loss_fp: 0.003286, loss_freq: 0.019156
[16:15:13.370] iteration 9686: loss: 0.064118, loss_s1: 0.049983, loss_fp: 0.001697, loss_freq: 0.029987
[16:15:13.998] iteration 9687: loss: 0.078024, loss_s1: 0.063634, loss_fp: 0.001080, loss_freq: 0.030636
[16:15:14.624] iteration 9688: loss: 0.128716, loss_s1: 0.065666, loss_fp: 0.010115, loss_freq: 0.063228
[16:15:15.254] iteration 9689: loss: 0.063779, loss_s1: 0.050311, loss_fp: 0.001530, loss_freq: 0.034964
[16:15:15.879] iteration 9690: loss: 0.055282, loss_s1: 0.036891, loss_fp: 0.002162, loss_freq: 0.014358
[16:15:16.503] iteration 9691: loss: 0.045537, loss_s1: 0.035859, loss_fp: 0.001598, loss_freq: 0.018922
[16:15:17.127] iteration 9692: loss: 0.073459, loss_s1: 0.047393, loss_fp: 0.002202, loss_freq: 0.021768
[16:15:17.780] iteration 9693: loss: 0.057787, loss_s1: 0.047583, loss_fp: 0.000997, loss_freq: 0.009251
[16:15:18.443] iteration 9694: loss: 0.044588, loss_s1: 0.028642, loss_fp: 0.003256, loss_freq: 0.008066
[16:15:19.104] iteration 9695: loss: 0.115732, loss_s1: 0.028612, loss_fp: 0.001898, loss_freq: 0.023639
[16:15:19.765] iteration 9696: loss: 0.079251, loss_s1: 0.070086, loss_fp: 0.001038, loss_freq: 0.030416
[16:15:20.421] iteration 9697: loss: 0.131155, loss_s1: 0.096838, loss_fp: 0.002328, loss_freq: 0.047633
[16:15:21.077] iteration 9698: loss: 0.062103, loss_s1: 0.026552, loss_fp: 0.005651, loss_freq: 0.017981
[16:15:21.745] iteration 9699: loss: 0.144265, loss_s1: 0.133041, loss_fp: 0.001915, loss_freq: 0.077207
[16:15:22.382] iteration 9700: loss: 0.106397, loss_s1: 0.076214, loss_fp: 0.005631, loss_freq: 0.067540
[16:15:23.008] iteration 9701: loss: 0.057790, loss_s1: 0.026082, loss_fp: 0.001065, loss_freq: 0.006897
[16:15:23.640] iteration 9702: loss: 0.106254, loss_s1: 0.078037, loss_fp: 0.006313, loss_freq: 0.075673
[16:15:24.270] iteration 9703: loss: 0.063554, loss_s1: 0.039944, loss_fp: 0.003934, loss_freq: 0.039719
[16:15:24.898] iteration 9704: loss: 0.072018, loss_s1: 0.049694, loss_fp: 0.002324, loss_freq: 0.039331
[16:15:25.531] iteration 9705: loss: 0.085366, loss_s1: 0.062609, loss_fp: 0.009239, loss_freq: 0.032259
[16:15:26.154] iteration 9706: loss: 0.062437, loss_s1: 0.039088, loss_fp: 0.001932, loss_freq: 0.014507
[16:15:26.779] iteration 9707: loss: 0.057979, loss_s1: 0.038440, loss_fp: 0.002913, loss_freq: 0.024431
[16:15:27.410] iteration 9708: loss: 0.061497, loss_s1: 0.058305, loss_fp: 0.001729, loss_freq: 0.014917
[16:15:28.039] iteration 9709: loss: 0.065553, loss_s1: 0.057246, loss_fp: 0.002058, loss_freq: 0.015753
[16:15:28.661] iteration 9710: loss: 0.093800, loss_s1: 0.052850, loss_fp: 0.007561, loss_freq: 0.066537
[16:15:29.296] iteration 9711: loss: 0.064417, loss_s1: 0.039541, loss_fp: 0.003296, loss_freq: 0.031921
[16:15:29.922] iteration 9712: loss: 0.061844, loss_s1: 0.021606, loss_fp: 0.000643, loss_freq: 0.038494
[16:15:30.549] iteration 9713: loss: 0.068426, loss_s1: 0.035786, loss_fp: 0.001398, loss_freq: 0.026725
[16:15:31.178] iteration 9714: loss: 0.093063, loss_s1: 0.041210, loss_fp: 0.003393, loss_freq: 0.060316
[16:15:31.808] iteration 9715: loss: 0.052445, loss_s1: 0.022018, loss_fp: 0.000538, loss_freq: 0.016546
[16:15:32.434] iteration 9716: loss: 0.091953, loss_s1: 0.083522, loss_fp: 0.002007, loss_freq: 0.030436
[16:15:33.064] iteration 9717: loss: 0.043594, loss_s1: 0.037896, loss_fp: 0.001215, loss_freq: 0.004044
[16:15:33.695] iteration 9718: loss: 0.091506, loss_s1: 0.040735, loss_fp: 0.000746, loss_freq: 0.040657
[16:15:34.323] iteration 9719: loss: 0.074850, loss_s1: 0.073351, loss_fp: 0.000822, loss_freq: 0.020037
[16:15:34.951] iteration 9720: loss: 0.044913, loss_s1: 0.022511, loss_fp: 0.002513, loss_freq: 0.024555
[16:15:35.586] iteration 9721: loss: 0.076553, loss_s1: 0.069791, loss_fp: 0.004934, loss_freq: 0.037565
[16:15:36.212] iteration 9722: loss: 0.052589, loss_s1: 0.025581, loss_fp: 0.003330, loss_freq: 0.018201
[16:15:36.869] iteration 9723: loss: 0.054375, loss_s1: 0.021947, loss_fp: 0.000377, loss_freq: 0.007916
[16:15:37.527] iteration 9724: loss: 0.100913, loss_s1: 0.090391, loss_fp: 0.002720, loss_freq: 0.032225
[16:15:38.189] iteration 9725: loss: 0.043881, loss_s1: 0.021788, loss_fp: 0.002150, loss_freq: 0.022478
[16:15:38.849] iteration 9726: loss: 0.103259, loss_s1: 0.058868, loss_fp: 0.001856, loss_freq: 0.098281
[16:15:39.498] iteration 9727: loss: 0.068197, loss_s1: 0.023888, loss_fp: 0.001305, loss_freq: 0.038913
[16:15:40.127] iteration 9728: loss: 0.067769, loss_s1: 0.045322, loss_fp: 0.007003, loss_freq: 0.038680
[16:15:40.751] iteration 9729: loss: 0.044078, loss_s1: 0.021875, loss_fp: 0.006130, loss_freq: 0.016123
[16:15:41.391] iteration 9730: loss: 0.079588, loss_s1: 0.061651, loss_fp: 0.002118, loss_freq: 0.023614
[16:15:42.019] iteration 9731: loss: 0.119178, loss_s1: 0.107332, loss_fp: 0.004376, loss_freq: 0.033684
[16:15:42.644] iteration 9732: loss: 0.069017, loss_s1: 0.067359, loss_fp: 0.002350, loss_freq: 0.026059
[16:15:43.276] iteration 9733: loss: 0.095566, loss_s1: 0.064920, loss_fp: 0.002331, loss_freq: 0.063139
[16:15:43.911] iteration 9734: loss: 0.070110, loss_s1: 0.059734, loss_fp: 0.003632, loss_freq: 0.012939
[16:15:44.546] iteration 9735: loss: 0.093780, loss_s1: 0.084847, loss_fp: 0.002935, loss_freq: 0.031067
[16:15:45.181] iteration 9736: loss: 0.121753, loss_s1: 0.105922, loss_fp: 0.006363, loss_freq: 0.033147
[16:15:45.811] iteration 9737: loss: 0.101679, loss_s1: 0.090985, loss_fp: 0.006882, loss_freq: 0.056367
[16:15:46.432] iteration 9738: loss: 0.069595, loss_s1: 0.053419, loss_fp: 0.004190, loss_freq: 0.033582
[16:15:47.060] iteration 9739: loss: 0.042481, loss_s1: 0.019977, loss_fp: 0.005340, loss_freq: 0.005111
[16:15:47.684] iteration 9740: loss: 0.083456, loss_s1: 0.083450, loss_fp: 0.003191, loss_freq: 0.028186
[16:15:48.314] iteration 9741: loss: 0.048919, loss_s1: 0.035361, loss_fp: 0.001625, loss_freq: 0.019601
[16:15:48.943] iteration 9742: loss: 0.091278, loss_s1: 0.082035, loss_fp: 0.013424, loss_freq: 0.032415
[16:15:49.568] iteration 9743: loss: 0.114836, loss_s1: 0.128253, loss_fp: 0.001551, loss_freq: 0.062913
[16:15:50.196] iteration 9744: loss: 0.068441, loss_s1: 0.034312, loss_fp: 0.008327, loss_freq: 0.023228
[16:15:50.824] iteration 9745: loss: 0.198425, loss_s1: 0.129083, loss_fp: 0.014593, loss_freq: 0.201962
[16:15:51.449] iteration 9746: loss: 0.049676, loss_s1: 0.032033, loss_fp: 0.000985, loss_freq: 0.021919
[16:15:52.073] iteration 9747: loss: 0.121971, loss_s1: 0.036019, loss_fp: 0.044492, loss_freq: 0.014935
[16:15:52.700] iteration 9748: loss: 0.045337, loss_s1: 0.033258, loss_fp: 0.002635, loss_freq: 0.007956
[16:15:53.337] iteration 9749: loss: 0.062138, loss_s1: 0.041144, loss_fp: 0.003495, loss_freq: 0.022892
[16:15:53.962] iteration 9750: loss: 0.097851, loss_s1: 0.045086, loss_fp: 0.002141, loss_freq: 0.045366
[16:15:54.593] iteration 9751: loss: 0.084533, loss_s1: 0.021008, loss_fp: 0.001421, loss_freq: 0.011716
[16:15:55.248] iteration 9752: loss: 0.073335, loss_s1: 0.034401, loss_fp: 0.000555, loss_freq: 0.024653
[16:15:55.912] iteration 9753: loss: 0.101882, loss_s1: 0.043320, loss_fp: 0.002883, loss_freq: 0.031320
[16:15:56.575] iteration 9754: loss: 0.059911, loss_s1: 0.043978, loss_fp: 0.007434, loss_freq: 0.010803
[16:15:57.235] iteration 9755: loss: 0.067019, loss_s1: 0.043018, loss_fp: 0.001801, loss_freq: 0.027694
[16:15:57.884] iteration 9756: loss: 0.047575, loss_s1: 0.038550, loss_fp: 0.004673, loss_freq: 0.009408
[16:15:58.511] iteration 9757: loss: 0.059942, loss_s1: 0.031426, loss_fp: 0.000309, loss_freq: 0.016461
[16:15:59.135] iteration 9758: loss: 0.073871, loss_s1: 0.044264, loss_fp: 0.001343, loss_freq: 0.024469
[16:15:59.795] iteration 9759: loss: 0.068992, loss_s1: 0.032223, loss_fp: 0.016370, loss_freq: 0.015924
[16:16:00.449] iteration 9760: loss: 0.085796, loss_s1: 0.058493, loss_fp: 0.003672, loss_freq: 0.015022
[16:16:01.112] iteration 9761: loss: 0.101064, loss_s1: 0.081279, loss_fp: 0.000904, loss_freq: 0.066683
[16:16:01.779] iteration 9762: loss: 0.086497, loss_s1: 0.041052, loss_fp: 0.005018, loss_freq: 0.061136
[16:16:02.411] iteration 9763: loss: 0.106165, loss_s1: 0.077838, loss_fp: 0.009312, loss_freq: 0.058320
[16:16:03.039] iteration 9764: loss: 0.070737, loss_s1: 0.051799, loss_fp: 0.005789, loss_freq: 0.034133
[16:16:03.672] iteration 9765: loss: 0.084550, loss_s1: 0.018641, loss_fp: 0.005083, loss_freq: 0.029502
[16:16:04.301] iteration 9766: loss: 0.058004, loss_s1: 0.024245, loss_fp: 0.011599, loss_freq: 0.029781
[16:16:04.929] iteration 9767: loss: 0.060746, loss_s1: 0.031514, loss_fp: 0.002413, loss_freq: 0.015922
[16:16:05.557] iteration 9768: loss: 0.119931, loss_s1: 0.052504, loss_fp: 0.010553, loss_freq: 0.116838
[16:16:06.185] iteration 9769: loss: 0.180313, loss_s1: 0.086197, loss_fp: 0.009095, loss_freq: 0.188876
[16:16:06.814] iteration 9770: loss: 0.070615, loss_s1: 0.060611, loss_fp: 0.005367, loss_freq: 0.029422
[16:16:07.440] iteration 9771: loss: 0.081683, loss_s1: 0.032552, loss_fp: 0.001383, loss_freq: 0.052083
[16:16:08.068] iteration 9772: loss: 0.095963, loss_s1: 0.061331, loss_fp: 0.006913, loss_freq: 0.071696
[16:16:08.697] iteration 9773: loss: 0.104099, loss_s1: 0.120171, loss_fp: 0.002635, loss_freq: 0.028610
[16:16:09.325] iteration 9774: loss: 0.080155, loss_s1: 0.032037, loss_fp: 0.001658, loss_freq: 0.050968
[16:16:09.954] iteration 9775: loss: 0.056127, loss_s1: 0.028579, loss_fp: 0.001346, loss_freq: 0.009292
[16:16:10.578] iteration 9776: loss: 0.129154, loss_s1: 0.097067, loss_fp: 0.018041, loss_freq: 0.090536
[16:16:11.210] iteration 9777: loss: 0.087061, loss_s1: 0.068055, loss_fp: 0.004657, loss_freq: 0.048065
[16:16:11.836] iteration 9778: loss: 0.040638, loss_s1: 0.011872, loss_fp: 0.003954, loss_freq: 0.022148
[16:16:12.462] iteration 9779: loss: 0.085715, loss_s1: 0.075081, loss_fp: 0.001333, loss_freq: 0.033994
[16:16:13.092] iteration 9780: loss: 0.088166, loss_s1: 0.034760, loss_fp: 0.004064, loss_freq: 0.083657
[16:16:13.724] iteration 9781: loss: 0.035406, loss_s1: 0.013350, loss_fp: 0.001591, loss_freq: 0.006006
[16:16:14.350] iteration 9782: loss: 0.110990, loss_s1: 0.057850, loss_fp: 0.006808, loss_freq: 0.050297
[16:16:15.101] iteration 9783: loss: 0.105065, loss_s1: 0.075519, loss_fp: 0.006571, loss_freq: 0.008310
[16:16:15.776] iteration 9784: loss: 0.050762, loss_s1: 0.024932, loss_fp: 0.004196, loss_freq: 0.019387
[16:16:16.449] iteration 9785: loss: 0.085895, loss_s1: 0.028154, loss_fp: 0.002388, loss_freq: 0.056091
[16:16:17.103] iteration 9786: loss: 0.080925, loss_s1: 0.013666, loss_fp: 0.012800, loss_freq: 0.013120
[16:16:17.766] iteration 9787: loss: 0.060165, loss_s1: 0.025399, loss_fp: 0.000507, loss_freq: 0.008668
[16:16:18.435] iteration 9788: loss: 0.134138, loss_s1: 0.075911, loss_fp: 0.006795, loss_freq: 0.038961
[16:16:19.067] iteration 9789: loss: 0.054323, loss_s1: 0.035711, loss_fp: 0.000875, loss_freq: 0.019948
[16:16:19.692] iteration 9790: loss: 0.040767, loss_s1: 0.023381, loss_fp: 0.000748, loss_freq: 0.010494
[16:16:20.324] iteration 9791: loss: 0.102740, loss_s1: 0.060134, loss_fp: 0.003187, loss_freq: 0.090483
[16:16:20.947] iteration 9792: loss: 0.108662, loss_s1: 0.113366, loss_fp: 0.002011, loss_freq: 0.048143
[16:16:21.571] iteration 9793: loss: 0.101788, loss_s1: 0.092625, loss_fp: 0.003411, loss_freq: 0.037592
[16:16:22.197] iteration 9794: loss: 0.061429, loss_s1: 0.041722, loss_fp: 0.003779, loss_freq: 0.013786
[16:16:22.822] iteration 9795: loss: 0.071276, loss_s1: 0.062922, loss_fp: 0.006323, loss_freq: 0.026027
[16:16:23.449] iteration 9796: loss: 0.071250, loss_s1: 0.071982, loss_fp: 0.008975, loss_freq: 0.018122
[16:16:24.072] iteration 9797: loss: 0.059125, loss_s1: 0.005994, loss_fp: 0.001112, loss_freq: 0.050490
[16:16:24.696] iteration 9798: loss: 0.042553, loss_s1: 0.023286, loss_fp: 0.000809, loss_freq: 0.015170
[16:16:25.322] iteration 9799: loss: 0.065499, loss_s1: 0.035467, loss_fp: 0.001893, loss_freq: 0.033582
[16:16:25.947] iteration 9800: loss: 0.118139, loss_s1: 0.064667, loss_fp: 0.001297, loss_freq: 0.066228
[16:16:29.192] iteration 9800 : mean_dice : 0.679889
[16:16:29.860] iteration 9801: loss: 0.090558, loss_s1: 0.067376, loss_fp: 0.002016, loss_freq: 0.062381
[16:16:30.488] iteration 9802: loss: 0.045470, loss_s1: 0.020433, loss_fp: 0.002108, loss_freq: 0.009715
[16:16:31.113] iteration 9803: loss: 0.089972, loss_s1: 0.049660, loss_fp: 0.007569, loss_freq: 0.039187
[16:16:31.735] iteration 9804: loss: 0.087261, loss_s1: 0.041567, loss_fp: 0.002750, loss_freq: 0.038559
[16:16:32.365] iteration 9805: loss: 0.062606, loss_s1: 0.043594, loss_fp: 0.005601, loss_freq: 0.018657
[16:16:32.990] iteration 9806: loss: 0.087979, loss_s1: 0.082215, loss_fp: 0.006773, loss_freq: 0.019587
[16:16:33.618] iteration 9807: loss: 0.096600, loss_s1: 0.076560, loss_fp: 0.002285, loss_freq: 0.076069
[16:16:34.243] iteration 9808: loss: 0.066141, loss_s1: 0.053877, loss_fp: 0.006718, loss_freq: 0.020432
[16:16:34.868] iteration 9809: loss: 0.053667, loss_s1: 0.022048, loss_fp: 0.006011, loss_freq: 0.013613
[16:16:35.496] iteration 9810: loss: 0.112931, loss_s1: 0.065215, loss_fp: 0.026405, loss_freq: 0.065060
[16:16:36.120] iteration 9811: loss: 0.066268, loss_s1: 0.054341, loss_fp: 0.003502, loss_freq: 0.021843
[16:16:36.744] iteration 9812: loss: 0.120558, loss_s1: 0.119394, loss_fp: 0.003602, loss_freq: 0.069241
[16:16:37.397] iteration 9813: loss: 0.060740, loss_s1: 0.050520, loss_fp: 0.003480, loss_freq: 0.020125
[16:16:38.035] iteration 9814: loss: 0.072278, loss_s1: 0.042094, loss_fp: 0.002172, loss_freq: 0.017268
[16:16:38.677] iteration 9815: loss: 0.055046, loss_s1: 0.026391, loss_fp: 0.001996, loss_freq: 0.010543
[16:16:39.319] iteration 9816: loss: 0.066550, loss_s1: 0.056676, loss_fp: 0.001309, loss_freq: 0.008629
[16:16:39.955] iteration 9817: loss: 0.073373, loss_s1: 0.013270, loss_fp: 0.000969, loss_freq: 0.013422
[16:16:40.605] iteration 9818: loss: 0.087803, loss_s1: 0.080928, loss_fp: 0.003779, loss_freq: 0.036285
[16:16:41.269] iteration 9819: loss: 0.101204, loss_s1: 0.051911, loss_fp: 0.025615, loss_freq: 0.061336
[16:16:41.927] iteration 9820: loss: 0.083988, loss_s1: 0.067552, loss_fp: 0.001438, loss_freq: 0.029735
[16:16:42.583] iteration 9821: loss: 0.069181, loss_s1: 0.055974, loss_fp: 0.001649, loss_freq: 0.026572
[16:16:43.608] iteration 9822: loss: 0.057682, loss_s1: 0.046830, loss_fp: 0.001824, loss_freq: 0.025994
[16:16:44.265] iteration 9823: loss: 0.081529, loss_s1: 0.059156, loss_fp: 0.004080, loss_freq: 0.033900
[16:16:44.933] iteration 9824: loss: 0.059208, loss_s1: 0.018438, loss_fp: 0.001041, loss_freq: 0.035103
[16:16:45.570] iteration 9825: loss: 0.050888, loss_s1: 0.033189, loss_fp: 0.000426, loss_freq: 0.015983
[16:16:46.202] iteration 9826: loss: 0.076049, loss_s1: 0.059079, loss_fp: 0.001628, loss_freq: 0.035536
[16:16:46.838] iteration 9827: loss: 0.156243, loss_s1: 0.120882, loss_fp: 0.015406, loss_freq: 0.032777
[16:16:47.501] iteration 9828: loss: 0.074051, loss_s1: 0.049877, loss_fp: 0.003460, loss_freq: 0.032972
[16:16:48.171] iteration 9829: loss: 0.032119, loss_s1: 0.017087, loss_fp: 0.000724, loss_freq: 0.011430
[16:16:48.836] iteration 9830: loss: 0.085350, loss_s1: 0.080533, loss_fp: 0.001198, loss_freq: 0.033451
[16:16:49.476] iteration 9831: loss: 0.091243, loss_s1: 0.041670, loss_fp: 0.003357, loss_freq: 0.054143
[16:16:50.104] iteration 9832: loss: 0.057976, loss_s1: 0.022105, loss_fp: 0.006293, loss_freq: 0.027313
[16:16:50.735] iteration 9833: loss: 0.075071, loss_s1: 0.047585, loss_fp: 0.002782, loss_freq: 0.020154
[16:16:51.365] iteration 9834: loss: 0.061520, loss_s1: 0.043375, loss_fp: 0.002179, loss_freq: 0.035518
[16:16:51.995] iteration 9835: loss: 0.099079, loss_s1: 0.062367, loss_fp: 0.006606, loss_freq: 0.061094
[16:16:52.625] iteration 9836: loss: 0.071334, loss_s1: 0.069170, loss_fp: 0.015517, loss_freq: 0.017774
[16:16:53.252] iteration 9837: loss: 0.103863, loss_s1: 0.067977, loss_fp: 0.024506, loss_freq: 0.052960
[16:16:53.881] iteration 9838: loss: 0.079589, loss_s1: 0.049953, loss_fp: 0.000971, loss_freq: 0.010868
[16:16:54.516] iteration 9839: loss: 0.096771, loss_s1: 0.067937, loss_fp: 0.001743, loss_freq: 0.043309
[16:16:55.147] iteration 9840: loss: 0.061218, loss_s1: 0.034526, loss_fp: 0.001026, loss_freq: 0.028739
[16:16:55.776] iteration 9841: loss: 0.101119, loss_s1: 0.080811, loss_fp: 0.002840, loss_freq: 0.027096
[16:16:56.403] iteration 9842: loss: 0.066770, loss_s1: 0.036797, loss_fp: 0.000910, loss_freq: 0.016067
[16:16:57.033] iteration 9843: loss: 0.058356, loss_s1: 0.015755, loss_fp: 0.000790, loss_freq: 0.015245
[16:16:57.658] iteration 9844: loss: 0.092702, loss_s1: 0.041967, loss_fp: 0.001003, loss_freq: 0.028089
[16:16:58.285] iteration 9845: loss: 0.150115, loss_s1: 0.041129, loss_fp: 0.004425, loss_freq: 0.191811
[16:16:58.916] iteration 9846: loss: 0.065949, loss_s1: 0.054256, loss_fp: 0.001408, loss_freq: 0.024476
[16:16:59.544] iteration 9847: loss: 0.104567, loss_s1: 0.091088, loss_fp: 0.003497, loss_freq: 0.038981
[16:17:00.172] iteration 9848: loss: 0.044254, loss_s1: 0.011305, loss_fp: 0.001988, loss_freq: 0.023419
[16:17:00.797] iteration 9849: loss: 0.122351, loss_s1: 0.096129, loss_fp: 0.022708, loss_freq: 0.054093
[16:17:01.422] iteration 9850: loss: 0.095160, loss_s1: 0.074929, loss_fp: 0.007550, loss_freq: 0.043071
[16:17:02.050] iteration 9851: loss: 0.054356, loss_s1: 0.016428, loss_fp: 0.006175, loss_freq: 0.016017
[16:17:02.681] iteration 9852: loss: 0.040020, loss_s1: 0.019086, loss_fp: 0.002995, loss_freq: 0.012556
[16:17:03.308] iteration 9853: loss: 0.088989, loss_s1: 0.035864, loss_fp: 0.001560, loss_freq: 0.058437
[16:17:03.934] iteration 9854: loss: 0.051570, loss_s1: 0.037165, loss_fp: 0.001960, loss_freq: 0.018451
[16:17:04.563] iteration 9855: loss: 0.064381, loss_s1: 0.027820, loss_fp: 0.001772, loss_freq: 0.028824
[16:17:05.190] iteration 9856: loss: 0.083858, loss_s1: 0.017066, loss_fp: 0.001602, loss_freq: 0.036533
[16:17:05.818] iteration 9857: loss: 0.074333, loss_s1: 0.050738, loss_fp: 0.005067, loss_freq: 0.028780
[16:17:06.444] iteration 9858: loss: 0.090345, loss_s1: 0.062261, loss_fp: 0.006261, loss_freq: 0.036648
[16:17:07.069] iteration 9859: loss: 0.102323, loss_s1: 0.056592, loss_fp: 0.026963, loss_freq: 0.038326
[16:17:07.698] iteration 9860: loss: 0.170900, loss_s1: 0.146459, loss_fp: 0.005510, loss_freq: 0.093380
[16:17:08.326] iteration 9861: loss: 0.084153, loss_s1: 0.081219, loss_fp: 0.001699, loss_freq: 0.027192
[16:17:08.956] iteration 9862: loss: 0.069848, loss_s1: 0.034631, loss_fp: 0.003813, loss_freq: 0.016422
[16:17:09.586] iteration 9863: loss: 0.111646, loss_s1: 0.089558, loss_fp: 0.004280, loss_freq: 0.066474
[16:17:10.215] iteration 9864: loss: 0.102409, loss_s1: 0.083471, loss_fp: 0.015219, loss_freq: 0.067225
[16:17:10.893] iteration 9865: loss: 0.080809, loss_s1: 0.060061, loss_fp: 0.001616, loss_freq: 0.042451
[16:17:11.544] iteration 9866: loss: 0.096931, loss_s1: 0.057177, loss_fp: 0.007776, loss_freq: 0.056681
[16:17:12.175] iteration 9867: loss: 0.090896, loss_s1: 0.082827, loss_fp: 0.000912, loss_freq: 0.017588
[16:17:12.805] iteration 9868: loss: 0.045154, loss_s1: 0.022414, loss_fp: 0.002305, loss_freq: 0.010866
[16:17:13.435] iteration 9869: loss: 0.091553, loss_s1: 0.076637, loss_fp: 0.007719, loss_freq: 0.054469
[16:17:14.065] iteration 9870: loss: 0.101378, loss_s1: 0.067069, loss_fp: 0.002190, loss_freq: 0.022242
[16:17:14.693] iteration 9871: loss: 0.086665, loss_s1: 0.073327, loss_fp: 0.005536, loss_freq: 0.042503
[16:17:15.321] iteration 9872: loss: 0.094716, loss_s1: 0.096342, loss_fp: 0.001197, loss_freq: 0.039849
[16:17:15.949] iteration 9873: loss: 0.083547, loss_s1: 0.046104, loss_fp: 0.003180, loss_freq: 0.028137
[16:17:16.576] iteration 9874: loss: 0.084731, loss_s1: 0.059254, loss_fp: 0.001568, loss_freq: 0.050999
[16:17:17.239] iteration 9875: loss: 0.069841, loss_s1: 0.050628, loss_fp: 0.003864, loss_freq: 0.029858
[16:17:17.904] iteration 9876: loss: 0.071834, loss_s1: 0.055213, loss_fp: 0.004374, loss_freq: 0.013211
[16:17:18.563] iteration 9877: loss: 0.118353, loss_s1: 0.119114, loss_fp: 0.002440, loss_freq: 0.050375
[16:17:19.223] iteration 9878: loss: 0.045992, loss_s1: 0.039452, loss_fp: 0.000426, loss_freq: 0.007037
[16:17:19.885] iteration 9879: loss: 0.083304, loss_s1: 0.026689, loss_fp: 0.000571, loss_freq: 0.047008
[16:17:20.543] iteration 9880: loss: 0.039367, loss_s1: 0.033750, loss_fp: 0.000508, loss_freq: 0.006668
[16:17:21.204] iteration 9881: loss: 0.047032, loss_s1: 0.026133, loss_fp: 0.000429, loss_freq: 0.026030
[16:17:21.861] iteration 9882: loss: 0.100193, loss_s1: 0.081537, loss_fp: 0.002710, loss_freq: 0.026562
[16:17:22.512] iteration 9883: loss: 0.075442, loss_s1: 0.060432, loss_fp: 0.006130, loss_freq: 0.015425
[16:17:23.136] iteration 9884: loss: 0.047800, loss_s1: 0.026804, loss_fp: 0.001991, loss_freq: 0.013660
[16:17:23.763] iteration 9885: loss: 0.071886, loss_s1: 0.051686, loss_fp: 0.001900, loss_freq: 0.038539
[16:17:24.388] iteration 9886: loss: 0.057344, loss_s1: 0.019235, loss_fp: 0.012363, loss_freq: 0.015830
[16:17:25.016] iteration 9887: loss: 0.056152, loss_s1: 0.030885, loss_fp: 0.000744, loss_freq: 0.035291
[16:17:25.647] iteration 9888: loss: 0.073063, loss_s1: 0.025101, loss_fp: 0.000794, loss_freq: 0.038833
[16:17:26.292] iteration 9889: loss: 0.067782, loss_s1: 0.055308, loss_fp: 0.001762, loss_freq: 0.034651
[16:17:26.933] iteration 9890: loss: 0.043786, loss_s1: 0.021282, loss_fp: 0.001664, loss_freq: 0.024483
[16:17:27.576] iteration 9891: loss: 0.124228, loss_s1: 0.069212, loss_fp: 0.006018, loss_freq: 0.022525
[16:17:28.215] iteration 9892: loss: 0.080967, loss_s1: 0.051717, loss_fp: 0.001922, loss_freq: 0.047607
[16:17:28.857] iteration 9893: loss: 0.078094, loss_s1: 0.041371, loss_fp: 0.000536, loss_freq: 0.038435
[16:17:29.495] iteration 9894: loss: 0.082875, loss_s1: 0.070738, loss_fp: 0.000928, loss_freq: 0.034456
[16:17:30.144] iteration 9895: loss: 0.059570, loss_s1: 0.034186, loss_fp: 0.001444, loss_freq: 0.022752
[16:17:30.782] iteration 9896: loss: 0.103077, loss_s1: 0.088870, loss_fp: 0.005868, loss_freq: 0.050412
[16:17:31.441] iteration 9897: loss: 0.093161, loss_s1: 0.080356, loss_fp: 0.004366, loss_freq: 0.016956
[16:17:32.101] iteration 9898: loss: 0.100580, loss_s1: 0.097818, loss_fp: 0.002936, loss_freq: 0.056243
[16:17:32.768] iteration 9899: loss: 0.083454, loss_s1: 0.087672, loss_fp: 0.002025, loss_freq: 0.018870
[16:17:33.429] iteration 9900: loss: 0.044548, loss_s1: 0.024611, loss_fp: 0.000608, loss_freq: 0.007211
[16:17:34.097] iteration 9901: loss: 0.089728, loss_s1: 0.086783, loss_fp: 0.004158, loss_freq: 0.017571
[16:17:34.764] iteration 9902: loss: 0.108102, loss_s1: 0.110929, loss_fp: 0.001057, loss_freq: 0.049588
[16:17:35.413] iteration 9903: loss: 0.095703, loss_s1: 0.110166, loss_fp: 0.010410, loss_freq: 0.034412
[16:17:36.041] iteration 9904: loss: 0.141625, loss_s1: 0.168956, loss_fp: 0.023415, loss_freq: 0.046520
[16:17:36.674] iteration 9905: loss: 0.076154, loss_s1: 0.055577, loss_fp: 0.001279, loss_freq: 0.032552
[16:17:37.307] iteration 9906: loss: 0.178479, loss_s1: 0.106819, loss_fp: 0.021636, loss_freq: 0.152876
[16:17:37.938] iteration 9907: loss: 0.068655, loss_s1: 0.055860, loss_fp: 0.001644, loss_freq: 0.040201
[16:17:38.568] iteration 9908: loss: 0.127489, loss_s1: 0.075832, loss_fp: 0.000451, loss_freq: 0.058335
[16:17:39.198] iteration 9909: loss: 0.059560, loss_s1: 0.034968, loss_fp: 0.001446, loss_freq: 0.013476
[16:17:39.832] iteration 9910: loss: 0.074328, loss_s1: 0.047348, loss_fp: 0.002448, loss_freq: 0.042085
[16:17:40.465] iteration 9911: loss: 0.081542, loss_s1: 0.073613, loss_fp: 0.001191, loss_freq: 0.024745
[16:17:41.095] iteration 9912: loss: 0.066766, loss_s1: 0.025718, loss_fp: 0.003909, loss_freq: 0.027990
[16:17:41.721] iteration 9913: loss: 0.102131, loss_s1: 0.087061, loss_fp: 0.002106, loss_freq: 0.026802
[16:17:42.378] iteration 9914: loss: 0.103683, loss_s1: 0.056343, loss_fp: 0.001609, loss_freq: 0.027131
[16:17:43.010] iteration 9915: loss: 0.064983, loss_s1: 0.046590, loss_fp: 0.002921, loss_freq: 0.010456
[16:17:43.637] iteration 9916: loss: 0.085362, loss_s1: 0.082107, loss_fp: 0.000809, loss_freq: 0.041146
[16:17:44.266] iteration 9917: loss: 0.087701, loss_s1: 0.097687, loss_fp: 0.000544, loss_freq: 0.029428
[16:17:44.896] iteration 9918: loss: 0.059010, loss_s1: 0.029888, loss_fp: 0.000541, loss_freq: 0.019862
[16:17:45.525] iteration 9919: loss: 0.060453, loss_s1: 0.008151, loss_fp: 0.000293, loss_freq: 0.029443
[16:17:46.151] iteration 9920: loss: 0.067463, loss_s1: 0.036363, loss_fp: 0.002695, loss_freq: 0.010274
[16:17:46.777] iteration 9921: loss: 0.079630, loss_s1: 0.076695, loss_fp: 0.002635, loss_freq: 0.027668
[16:17:47.405] iteration 9922: loss: 0.057772, loss_s1: 0.042680, loss_fp: 0.000745, loss_freq: 0.028750
[16:17:48.036] iteration 9923: loss: 0.079895, loss_s1: 0.027625, loss_fp: 0.002372, loss_freq: 0.033132
[16:17:48.662] iteration 9924: loss: 0.089339, loss_s1: 0.051213, loss_fp: 0.007116, loss_freq: 0.061123
[16:17:49.289] iteration 9925: loss: 0.123677, loss_s1: 0.120182, loss_fp: 0.004424, loss_freq: 0.053139
[16:17:49.919] iteration 9926: loss: 0.081796, loss_s1: 0.024263, loss_fp: 0.001139, loss_freq: 0.013655
[16:17:50.553] iteration 9927: loss: 0.047909, loss_s1: 0.022677, loss_fp: 0.001961, loss_freq: 0.023722
[16:17:51.188] iteration 9928: loss: 0.070260, loss_s1: 0.029227, loss_fp: 0.000753, loss_freq: 0.014648
[16:17:51.821] iteration 9929: loss: 0.134749, loss_s1: 0.077995, loss_fp: 0.008997, loss_freq: 0.115534
[16:17:52.449] iteration 9930: loss: 0.170349, loss_s1: 0.126833, loss_fp: 0.001802, loss_freq: 0.149567
[16:17:53.077] iteration 9931: loss: 0.070229, loss_s1: 0.053343, loss_fp: 0.004534, loss_freq: 0.040552
[16:17:53.722] iteration 9932: loss: 0.071164, loss_s1: 0.029250, loss_fp: 0.007914, loss_freq: 0.042676
[16:17:54.365] iteration 9933: loss: 0.061050, loss_s1: 0.032947, loss_fp: 0.002476, loss_freq: 0.029929
[16:17:55.013] iteration 9934: loss: 0.124986, loss_s1: 0.087355, loss_fp: 0.006495, loss_freq: 0.092292
[16:17:55.657] iteration 9935: loss: 0.067192, loss_s1: 0.049943, loss_fp: 0.006817, loss_freq: 0.037232
[16:17:56.300] iteration 9936: loss: 0.048091, loss_s1: 0.033768, loss_fp: 0.000388, loss_freq: 0.007065
[16:17:56.940] iteration 9937: loss: 0.095074, loss_s1: 0.076708, loss_fp: 0.009860, loss_freq: 0.036505
[16:17:57.582] iteration 9938: loss: 0.070979, loss_s1: 0.064101, loss_fp: 0.003835, loss_freq: 0.014805
[16:17:58.208] iteration 9939: loss: 0.083233, loss_s1: 0.078114, loss_fp: 0.007516, loss_freq: 0.034168
[16:17:58.833] iteration 9940: loss: 0.095086, loss_s1: 0.095602, loss_fp: 0.003439, loss_freq: 0.035128
[16:17:59.458] iteration 9941: loss: 0.096364, loss_s1: 0.057729, loss_fp: 0.001081, loss_freq: 0.094312
[16:18:00.079] iteration 9942: loss: 0.094132, loss_s1: 0.080817, loss_fp: 0.001555, loss_freq: 0.053010
[16:18:00.706] iteration 9943: loss: 0.098589, loss_s1: 0.031288, loss_fp: 0.000784, loss_freq: 0.066428
[16:18:01.332] iteration 9944: loss: 0.083986, loss_s1: 0.081393, loss_fp: 0.003035, loss_freq: 0.027230
[16:18:01.961] iteration 9945: loss: 0.062354, loss_s1: 0.046959, loss_fp: 0.001639, loss_freq: 0.020825
[16:18:02.588] iteration 9946: loss: 0.087434, loss_s1: 0.054332, loss_fp: 0.000503, loss_freq: 0.058443
[16:18:03.212] iteration 9947: loss: 0.107247, loss_s1: 0.063871, loss_fp: 0.000525, loss_freq: 0.017503
[16:18:03.839] iteration 9948: loss: 0.073025, loss_s1: 0.070992, loss_fp: 0.000800, loss_freq: 0.008961
[16:18:04.467] iteration 9949: loss: 0.194726, loss_s1: 0.163962, loss_fp: 0.003856, loss_freq: 0.151499
[16:18:05.094] iteration 9950: loss: 0.054583, loss_s1: 0.041619, loss_fp: 0.005566, loss_freq: 0.006855
[16:18:05.723] iteration 9951: loss: 0.046709, loss_s1: 0.043053, loss_fp: 0.001043, loss_freq: 0.007530
[16:18:06.351] iteration 9952: loss: 0.112747, loss_s1: 0.052064, loss_fp: 0.004433, loss_freq: 0.094934
[16:18:06.981] iteration 9953: loss: 0.104244, loss_s1: 0.127567, loss_fp: 0.001262, loss_freq: 0.024182
[16:18:07.612] iteration 9954: loss: 0.098275, loss_s1: 0.102043, loss_fp: 0.007475, loss_freq: 0.021946
[16:18:08.243] iteration 9955: loss: 0.042833, loss_s1: 0.018672, loss_fp: 0.004222, loss_freq: 0.023184
[16:18:08.872] iteration 9956: loss: 0.128660, loss_s1: 0.098787, loss_fp: 0.003974, loss_freq: 0.082088
[16:18:09.499] iteration 9957: loss: 0.050445, loss_s1: 0.045285, loss_fp: 0.002941, loss_freq: 0.006809
[16:18:10.123] iteration 9958: loss: 0.079252, loss_s1: 0.043953, loss_fp: 0.005026, loss_freq: 0.044407
[16:18:10.757] iteration 9959: loss: 0.073515, loss_s1: 0.049567, loss_fp: 0.005839, loss_freq: 0.034318
[16:18:11.388] iteration 9960: loss: 0.052450, loss_s1: 0.013483, loss_fp: 0.003505, loss_freq: 0.032656
[16:18:12.015] iteration 9961: loss: 0.109023, loss_s1: 0.070980, loss_fp: 0.014494, loss_freq: 0.023194
[16:18:12.641] iteration 9962: loss: 0.074696, loss_s1: 0.067107, loss_fp: 0.004756, loss_freq: 0.031550
[16:18:13.268] iteration 9963: loss: 0.071582, loss_s1: 0.043827, loss_fp: 0.004071, loss_freq: 0.019381
[16:18:13.892] iteration 9964: loss: 0.061076, loss_s1: 0.049343, loss_fp: 0.005208, loss_freq: 0.018922
[16:18:14.522] iteration 9965: loss: 0.066464, loss_s1: 0.050945, loss_fp: 0.003777, loss_freq: 0.020619
[16:18:15.147] iteration 9966: loss: 0.072351, loss_s1: 0.071015, loss_fp: 0.012766, loss_freq: 0.019209
[16:18:15.772] iteration 9967: loss: 0.075430, loss_s1: 0.051971, loss_fp: 0.011538, loss_freq: 0.026224
[16:18:16.398] iteration 9968: loss: 0.100618, loss_s1: 0.054633, loss_fp: 0.002229, loss_freq: 0.074030
[16:18:17.032] iteration 9969: loss: 0.059046, loss_s1: 0.045307, loss_fp: 0.003945, loss_freq: 0.024192
[16:18:17.689] iteration 9970: loss: 0.049124, loss_s1: 0.024629, loss_fp: 0.002914, loss_freq: 0.017858
[16:18:18.347] iteration 9971: loss: 0.105265, loss_s1: 0.061777, loss_fp: 0.011435, loss_freq: 0.066296
[16:18:19.039] iteration 9972: loss: 0.116749, loss_s1: 0.085504, loss_fp: 0.023755, loss_freq: 0.054743
[16:18:19.725] iteration 9973: loss: 0.127763, loss_s1: 0.101104, loss_fp: 0.002243, loss_freq: 0.088414
[16:18:20.522] iteration 9974: loss: 0.042987, loss_s1: 0.021616, loss_fp: 0.002604, loss_freq: 0.016485
[16:18:21.244] iteration 9975: loss: 0.094219, loss_s1: 0.046763, loss_fp: 0.005032, loss_freq: 0.018249
[16:18:21.878] iteration 9976: loss: 0.054530, loss_s1: 0.024870, loss_fp: 0.003908, loss_freq: 0.009720
[16:18:22.503] iteration 9977: loss: 0.082460, loss_s1: 0.032754, loss_fp: 0.001604, loss_freq: 0.030692
[16:18:23.126] iteration 9978: loss: 0.077834, loss_s1: 0.029482, loss_fp: 0.001365, loss_freq: 0.015925
[16:18:23.752] iteration 9979: loss: 0.094518, loss_s1: 0.083244, loss_fp: 0.001289, loss_freq: 0.036316
[16:18:24.374] iteration 9980: loss: 0.082731, loss_s1: 0.041534, loss_fp: 0.007202, loss_freq: 0.034243
[16:18:24.996] iteration 9981: loss: 0.075927, loss_s1: 0.067958, loss_fp: 0.001927, loss_freq: 0.024678
[16:18:25.618] iteration 9982: loss: 0.080708, loss_s1: 0.042758, loss_fp: 0.005494, loss_freq: 0.050283
[16:18:26.632] iteration 9983: loss: 0.044405, loss_s1: 0.031120, loss_fp: 0.001869, loss_freq: 0.011858
[16:18:27.291] iteration 9984: loss: 0.076299, loss_s1: 0.054497, loss_fp: 0.001551, loss_freq: 0.041367
[16:18:27.946] iteration 9985: loss: 0.077034, loss_s1: 0.042834, loss_fp: 0.002719, loss_freq: 0.023188
[16:18:28.605] iteration 9986: loss: 0.053573, loss_s1: 0.039582, loss_fp: 0.002282, loss_freq: 0.008810
[16:18:29.262] iteration 9987: loss: 0.066510, loss_s1: 0.048763, loss_fp: 0.002840, loss_freq: 0.011754
[16:18:29.900] iteration 9988: loss: 0.161878, loss_s1: 0.095257, loss_fp: 0.008209, loss_freq: 0.060471
[16:18:30.532] iteration 9989: loss: 0.066338, loss_s1: 0.057655, loss_fp: 0.003056, loss_freq: 0.026587
[16:18:31.156] iteration 9990: loss: 0.079154, loss_s1: 0.061541, loss_fp: 0.001722, loss_freq: 0.034119
[16:18:31.779] iteration 9991: loss: 0.097895, loss_s1: 0.114589, loss_fp: 0.006477, loss_freq: 0.028290
[16:18:32.401] iteration 9992: loss: 0.123917, loss_s1: 0.120151, loss_fp: 0.002095, loss_freq: 0.051004
[16:18:33.029] iteration 9993: loss: 0.050086, loss_s1: 0.017038, loss_fp: 0.006138, loss_freq: 0.012260
[16:18:33.651] iteration 9994: loss: 0.070961, loss_s1: 0.058083, loss_fp: 0.007311, loss_freq: 0.024492
[16:18:34.273] iteration 9995: loss: 0.097469, loss_s1: 0.069114, loss_fp: 0.002135, loss_freq: 0.074333
[16:18:34.894] iteration 9996: loss: 0.123687, loss_s1: 0.106392, loss_fp: 0.004016, loss_freq: 0.057511
[16:18:35.521] iteration 9997: loss: 0.068351, loss_s1: 0.043222, loss_fp: 0.002904, loss_freq: 0.029854
[16:18:36.142] iteration 9998: loss: 0.115164, loss_s1: 0.083413, loss_fp: 0.003768, loss_freq: 0.089103
[16:18:36.763] iteration 9999: loss: 0.092846, loss_s1: 0.062433, loss_fp: 0.001896, loss_freq: 0.013243
[16:18:37.386] iteration 10000: loss: 0.104611, loss_s1: 0.077023, loss_fp: 0.003130, loss_freq: 0.054644
[16:18:40.899] iteration 10000 : mean_dice : 0.710890
[16:18:41.543] iteration 10001: loss: 0.082075, loss_s1: 0.055145, loss_fp: 0.003352, loss_freq: 0.024508
[16:18:42.168] iteration 10002: loss: 0.075286, loss_s1: 0.042552, loss_fp: 0.001401, loss_freq: 0.018305
[16:18:42.792] iteration 10003: loss: 0.090220, loss_s1: 0.092039, loss_fp: 0.002011, loss_freq: 0.020247
[16:18:43.420] iteration 10004: loss: 0.062619, loss_s1: 0.053785, loss_fp: 0.001220, loss_freq: 0.024494
[16:18:44.043] iteration 10005: loss: 0.090343, loss_s1: 0.064280, loss_fp: 0.006184, loss_freq: 0.011738
[16:18:44.665] iteration 10006: loss: 0.199422, loss_s1: 0.111385, loss_fp: 0.003480, loss_freq: 0.238698
[16:18:45.287] iteration 10007: loss: 0.084861, loss_s1: 0.077454, loss_fp: 0.002534, loss_freq: 0.025480
[16:18:45.909] iteration 10008: loss: 0.084285, loss_s1: 0.042877, loss_fp: 0.004004, loss_freq: 0.057390
[16:18:46.532] iteration 10009: loss: 0.048261, loss_s1: 0.009682, loss_fp: 0.009646, loss_freq: 0.025252
[16:18:47.154] iteration 10010: loss: 0.120133, loss_s1: 0.073574, loss_fp: 0.022171, loss_freq: 0.085391
[16:18:47.775] iteration 10011: loss: 0.068838, loss_s1: 0.055914, loss_fp: 0.001928, loss_freq: 0.041034
[16:18:48.403] iteration 10012: loss: 0.062418, loss_s1: 0.037693, loss_fp: 0.005895, loss_freq: 0.028419
[16:18:49.029] iteration 10013: loss: 0.077677, loss_s1: 0.070235, loss_fp: 0.005975, loss_freq: 0.030743
[16:18:49.651] iteration 10014: loss: 0.153170, loss_s1: 0.017790, loss_fp: 0.005251, loss_freq: 0.011553
[16:18:50.277] iteration 10015: loss: 0.058863, loss_s1: 0.032475, loss_fp: 0.001279, loss_freq: 0.030700
[16:18:50.899] iteration 10016: loss: 0.075474, loss_s1: 0.071118, loss_fp: 0.000969, loss_freq: 0.012357
[16:18:51.524] iteration 10017: loss: 0.132550, loss_s1: 0.061334, loss_fp: 0.004046, loss_freq: 0.034240
[16:18:52.145] iteration 10018: loss: 0.078278, loss_s1: 0.074184, loss_fp: 0.015413, loss_freq: 0.025107
[16:18:52.772] iteration 10019: loss: 0.092775, loss_s1: 0.070258, loss_fp: 0.011215, loss_freq: 0.035249
[16:18:53.395] iteration 10020: loss: 0.058589, loss_s1: 0.023590, loss_fp: 0.002037, loss_freq: 0.027291
[16:18:54.023] iteration 10021: loss: 0.098231, loss_s1: 0.067958, loss_fp: 0.000985, loss_freq: 0.053050
[16:18:54.651] iteration 10022: loss: 0.083494, loss_s1: 0.064641, loss_fp: 0.002128, loss_freq: 0.031947
[16:18:55.273] iteration 10023: loss: 0.080168, loss_s1: 0.017261, loss_fp: 0.012239, loss_freq: 0.032884
[16:18:55.896] iteration 10024: loss: 0.116909, loss_s1: 0.069823, loss_fp: 0.030176, loss_freq: 0.088090
[16:18:56.519] iteration 10025: loss: 0.068263, loss_s1: 0.057786, loss_fp: 0.002308, loss_freq: 0.029476
[16:18:57.142] iteration 10026: loss: 0.057988, loss_s1: 0.028628, loss_fp: 0.002231, loss_freq: 0.027387
[16:18:57.768] iteration 10027: loss: 0.059242, loss_s1: 0.030064, loss_fp: 0.001925, loss_freq: 0.029179
[16:18:58.395] iteration 10028: loss: 0.059106, loss_s1: 0.035869, loss_fp: 0.000804, loss_freq: 0.031214
[16:18:59.019] iteration 10029: loss: 0.044692, loss_s1: 0.018251, loss_fp: 0.003735, loss_freq: 0.020830
[16:18:59.641] iteration 10030: loss: 0.055549, loss_s1: 0.041575, loss_fp: 0.005138, loss_freq: 0.018521
[16:19:00.266] iteration 10031: loss: 0.080621, loss_s1: 0.060234, loss_fp: 0.006225, loss_freq: 0.015919
[16:19:00.923] iteration 10032: loss: 0.074211, loss_s1: 0.033588, loss_fp: 0.010040, loss_freq: 0.026272
[16:19:01.579] iteration 10033: loss: 0.091042, loss_s1: 0.053058, loss_fp: 0.000608, loss_freq: 0.078354
[16:19:02.234] iteration 10034: loss: 0.065613, loss_s1: 0.028841, loss_fp: 0.009261, loss_freq: 0.030294
[16:19:02.863] iteration 10035: loss: 0.080964, loss_s1: 0.050874, loss_fp: 0.002639, loss_freq: 0.039315
[16:19:03.493] iteration 10036: loss: 0.088155, loss_s1: 0.090569, loss_fp: 0.004506, loss_freq: 0.030791
[16:19:04.120] iteration 10037: loss: 0.083489, loss_s1: 0.063435, loss_fp: 0.000328, loss_freq: 0.038273
[16:19:04.767] iteration 10038: loss: 0.097380, loss_s1: 0.107457, loss_fp: 0.008185, loss_freq: 0.024114
[16:19:05.392] iteration 10039: loss: 0.052405, loss_s1: 0.012679, loss_fp: 0.002913, loss_freq: 0.003872
[16:19:06.016] iteration 10040: loss: 0.066288, loss_s1: 0.020079, loss_fp: 0.006512, loss_freq: 0.018313
[16:19:06.640] iteration 10041: loss: 0.031498, loss_s1: 0.014503, loss_fp: 0.003902, loss_freq: 0.003796
[16:19:07.267] iteration 10042: loss: 0.059703, loss_s1: 0.033424, loss_fp: 0.000551, loss_freq: 0.023608
[16:19:07.889] iteration 10043: loss: 0.075179, loss_s1: 0.037645, loss_fp: 0.003538, loss_freq: 0.052983
[16:19:08.566] iteration 10044: loss: 0.042582, loss_s1: 0.026703, loss_fp: 0.002340, loss_freq: 0.007686
[16:19:09.218] iteration 10045: loss: 0.070080, loss_s1: 0.044331, loss_fp: 0.001527, loss_freq: 0.019044
[16:19:09.861] iteration 10046: loss: 0.103637, loss_s1: 0.081493, loss_fp: 0.001381, loss_freq: 0.038222
[16:19:10.507] iteration 10047: loss: 0.051342, loss_s1: 0.032368, loss_fp: 0.002481, loss_freq: 0.014698
[16:19:11.146] iteration 10048: loss: 0.078943, loss_s1: 0.052221, loss_fp: 0.001082, loss_freq: 0.066242
[16:19:11.783] iteration 10049: loss: 0.077098, loss_s1: 0.029091, loss_fp: 0.001988, loss_freq: 0.032567
[16:19:12.407] iteration 10050: loss: 0.061476, loss_s1: 0.056938, loss_fp: 0.003483, loss_freq: 0.027743
[16:19:13.031] iteration 10051: loss: 0.067802, loss_s1: 0.040030, loss_fp: 0.004312, loss_freq: 0.016379
[16:19:13.656] iteration 10052: loss: 0.104200, loss_s1: 0.071510, loss_fp: 0.006780, loss_freq: 0.024998
[16:19:14.280] iteration 10053: loss: 0.108411, loss_s1: 0.093730, loss_fp: 0.003177, loss_freq: 0.062530
[16:19:14.936] iteration 10054: loss: 0.096196, loss_s1: 0.062305, loss_fp: 0.001253, loss_freq: 0.043316
[16:19:15.592] iteration 10055: loss: 0.064315, loss_s1: 0.025710, loss_fp: 0.001127, loss_freq: 0.057943
[16:19:16.233] iteration 10056: loss: 0.043376, loss_s1: 0.016582, loss_fp: 0.001711, loss_freq: 0.016024
[16:19:16.857] iteration 10057: loss: 0.115602, loss_s1: 0.134234, loss_fp: 0.000810, loss_freq: 0.038210
[16:19:17.489] iteration 10058: loss: 0.071586, loss_s1: 0.039422, loss_fp: 0.001626, loss_freq: 0.015086
[16:19:18.120] iteration 10059: loss: 0.080565, loss_s1: 0.084506, loss_fp: 0.003535, loss_freq: 0.035956
[16:19:18.747] iteration 10060: loss: 0.093856, loss_s1: 0.092315, loss_fp: 0.000746, loss_freq: 0.032724
[16:19:19.375] iteration 10061: loss: 0.037809, loss_s1: 0.017576, loss_fp: 0.000803, loss_freq: 0.012724
[16:19:20.001] iteration 10062: loss: 0.059374, loss_s1: 0.047036, loss_fp: 0.002584, loss_freq: 0.020012
[16:19:20.633] iteration 10063: loss: 0.078699, loss_s1: 0.048842, loss_fp: 0.000726, loss_freq: 0.042454
[16:19:21.263] iteration 10064: loss: 0.092662, loss_s1: 0.059057, loss_fp: 0.006480, loss_freq: 0.036770
[16:19:21.891] iteration 10065: loss: 0.137663, loss_s1: 0.096726, loss_fp: 0.003263, loss_freq: 0.126058
[16:19:22.520] iteration 10066: loss: 0.134524, loss_s1: 0.065361, loss_fp: 0.000691, loss_freq: 0.064816
[16:19:23.149] iteration 10067: loss: 0.126484, loss_s1: 0.125009, loss_fp: 0.007049, loss_freq: 0.054456
[16:19:23.778] iteration 10068: loss: 0.053176, loss_s1: 0.042532, loss_fp: 0.002025, loss_freq: 0.019376
[16:19:24.409] iteration 10069: loss: 0.069553, loss_s1: 0.027724, loss_fp: 0.001387, loss_freq: 0.030525
[16:19:25.041] iteration 10070: loss: 0.060945, loss_s1: 0.051482, loss_fp: 0.000591, loss_freq: 0.006546
[16:19:25.671] iteration 10071: loss: 0.101046, loss_s1: 0.070587, loss_fp: 0.013076, loss_freq: 0.068445
[16:19:26.304] iteration 10072: loss: 0.079559, loss_s1: 0.044601, loss_fp: 0.008384, loss_freq: 0.023652
[16:19:26.932] iteration 10073: loss: 0.050774, loss_s1: 0.026103, loss_fp: 0.000391, loss_freq: 0.014259
[16:19:27.557] iteration 10074: loss: 0.102181, loss_s1: 0.072760, loss_fp: 0.002227, loss_freq: 0.029073
[16:19:28.187] iteration 10075: loss: 0.130000, loss_s1: 0.075205, loss_fp: 0.000565, loss_freq: 0.015600
[16:19:28.812] iteration 10076: loss: 0.045744, loss_s1: 0.028823, loss_fp: 0.000327, loss_freq: 0.007480
[16:19:29.436] iteration 10077: loss: 0.068787, loss_s1: 0.041679, loss_fp: 0.001613, loss_freq: 0.050214
[16:19:30.060] iteration 10078: loss: 0.051947, loss_s1: 0.041483, loss_fp: 0.002418, loss_freq: 0.017843
[16:19:30.685] iteration 10079: loss: 0.040306, loss_s1: 0.018680, loss_fp: 0.002845, loss_freq: 0.016145
[16:19:31.310] iteration 10080: loss: 0.059131, loss_s1: 0.012319, loss_fp: 0.002340, loss_freq: 0.043575
[16:19:31.933] iteration 10081: loss: 0.091262, loss_s1: 0.034343, loss_fp: 0.002665, loss_freq: 0.021451
[16:19:32.557] iteration 10082: loss: 0.053292, loss_s1: 0.032620, loss_fp: 0.002541, loss_freq: 0.029025
[16:19:33.182] iteration 10083: loss: 0.045905, loss_s1: 0.031930, loss_fp: 0.000922, loss_freq: 0.015180
[16:19:33.805] iteration 10084: loss: 0.069704, loss_s1: 0.044993, loss_fp: 0.003240, loss_freq: 0.039656
[16:19:34.430] iteration 10085: loss: 0.081623, loss_s1: 0.053222, loss_fp: 0.002780, loss_freq: 0.055844
[16:19:35.084] iteration 10086: loss: 0.105307, loss_s1: 0.103388, loss_fp: 0.003240, loss_freq: 0.053055
[16:19:35.748] iteration 10087: loss: 0.127313, loss_s1: 0.029118, loss_fp: 0.002433, loss_freq: 0.026225
[16:19:36.391] iteration 10088: loss: 0.077822, loss_s1: 0.068225, loss_fp: 0.003911, loss_freq: 0.037563
[16:19:37.018] iteration 10089: loss: 0.077881, loss_s1: 0.025740, loss_fp: 0.000817, loss_freq: 0.026797
[16:19:37.646] iteration 10090: loss: 0.156329, loss_s1: 0.099935, loss_fp: 0.012181, loss_freq: 0.140855
[16:19:38.273] iteration 10091: loss: 0.126357, loss_s1: 0.061128, loss_fp: 0.005324, loss_freq: 0.120853
[16:19:38.900] iteration 10092: loss: 0.059769, loss_s1: 0.015015, loss_fp: 0.003068, loss_freq: 0.021971
[16:19:39.524] iteration 10093: loss: 0.080282, loss_s1: 0.014178, loss_fp: 0.002535, loss_freq: 0.044656
[16:19:40.148] iteration 10094: loss: 0.093757, loss_s1: 0.056863, loss_fp: 0.005509, loss_freq: 0.072025
[16:19:40.773] iteration 10095: loss: 0.101491, loss_s1: 0.074341, loss_fp: 0.024444, loss_freq: 0.052115
[16:19:41.396] iteration 10096: loss: 0.064084, loss_s1: 0.033000, loss_fp: 0.000833, loss_freq: 0.053033
[16:19:42.022] iteration 10097: loss: 0.042822, loss_s1: 0.018654, loss_fp: 0.003322, loss_freq: 0.009206
[16:19:42.657] iteration 10098: loss: 0.096314, loss_s1: 0.061809, loss_fp: 0.002675, loss_freq: 0.021731
[16:19:43.282] iteration 10099: loss: 0.073039, loss_s1: 0.066014, loss_fp: 0.002805, loss_freq: 0.013620
[16:19:43.924] iteration 10100: loss: 0.067907, loss_s1: 0.022494, loss_fp: 0.008587, loss_freq: 0.019969
[16:19:44.561] iteration 10101: loss: 0.090720, loss_s1: 0.038578, loss_fp: 0.006050, loss_freq: 0.062409
[16:19:45.190] iteration 10102: loss: 0.110315, loss_s1: 0.094082, loss_fp: 0.002825, loss_freq: 0.082378
[16:19:45.824] iteration 10103: loss: 0.127980, loss_s1: 0.056849, loss_fp: 0.004598, loss_freq: 0.135177
[16:19:46.452] iteration 10104: loss: 0.053177, loss_s1: 0.035374, loss_fp: 0.001034, loss_freq: 0.013400
[16:19:47.080] iteration 10105: loss: 0.100671, loss_s1: 0.096206, loss_fp: 0.003682, loss_freq: 0.011223
[16:19:47.708] iteration 10106: loss: 0.101217, loss_s1: 0.070792, loss_fp: 0.008517, loss_freq: 0.046315
[16:19:48.334] iteration 10107: loss: 0.095945, loss_s1: 0.046589, loss_fp: 0.001451, loss_freq: 0.060413
[16:19:48.960] iteration 10108: loss: 0.081426, loss_s1: 0.034003, loss_fp: 0.000602, loss_freq: 0.022215
[16:19:49.591] iteration 10109: loss: 0.074119, loss_s1: 0.056517, loss_fp: 0.005778, loss_freq: 0.007274
[16:19:50.214] iteration 10110: loss: 0.148181, loss_s1: 0.055791, loss_fp: 0.006010, loss_freq: 0.070102
[16:19:50.844] iteration 10111: loss: 0.058347, loss_s1: 0.049247, loss_fp: 0.000381, loss_freq: 0.020435
[16:19:51.490] iteration 10112: loss: 0.063236, loss_s1: 0.065143, loss_fp: 0.002920, loss_freq: 0.014438
[16:19:52.178] iteration 10113: loss: 0.083457, loss_s1: 0.054798, loss_fp: 0.011624, loss_freq: 0.056608
[16:19:52.835] iteration 10114: loss: 0.090285, loss_s1: 0.094480, loss_fp: 0.001999, loss_freq: 0.031643
[16:19:53.475] iteration 10115: loss: 0.052615, loss_s1: 0.018954, loss_fp: 0.002554, loss_freq: 0.026844
[16:19:54.098] iteration 10116: loss: 0.080160, loss_s1: 0.053594, loss_fp: 0.003981, loss_freq: 0.031118
[16:19:54.725] iteration 10117: loss: 0.065374, loss_s1: 0.038806, loss_fp: 0.003559, loss_freq: 0.037507
[16:19:55.363] iteration 10118: loss: 0.049054, loss_s1: 0.034955, loss_fp: 0.003649, loss_freq: 0.019127
[16:19:56.009] iteration 10119: loss: 0.079872, loss_s1: 0.041769, loss_fp: 0.002074, loss_freq: 0.041314
[16:19:56.651] iteration 10120: loss: 0.052499, loss_s1: 0.038090, loss_fp: 0.001679, loss_freq: 0.015746
[16:19:57.290] iteration 10121: loss: 0.064649, loss_s1: 0.055120, loss_fp: 0.003052, loss_freq: 0.015741
[16:19:57.930] iteration 10122: loss: 0.124567, loss_s1: 0.087267, loss_fp: 0.002978, loss_freq: 0.049182
[16:19:58.572] iteration 10123: loss: 0.085306, loss_s1: 0.067658, loss_fp: 0.003196, loss_freq: 0.030618
[16:19:59.215] iteration 10124: loss: 0.101512, loss_s1: 0.062113, loss_fp: 0.015903, loss_freq: 0.044305
[16:19:59.856] iteration 10125: loss: 0.116564, loss_s1: 0.094264, loss_fp: 0.004883, loss_freq: 0.054652
[16:20:00.479] iteration 10126: loss: 0.114626, loss_s1: 0.070318, loss_fp: 0.001213, loss_freq: 0.030595
[16:20:01.106] iteration 10127: loss: 0.067193, loss_s1: 0.048473, loss_fp: 0.003947, loss_freq: 0.035142
[16:20:01.727] iteration 10128: loss: 0.073217, loss_s1: 0.056109, loss_fp: 0.002287, loss_freq: 0.025098
[16:20:02.355] iteration 10129: loss: 0.074386, loss_s1: 0.056932, loss_fp: 0.006592, loss_freq: 0.051508
[16:20:02.983] iteration 10130: loss: 0.100416, loss_s1: 0.097060, loss_fp: 0.002887, loss_freq: 0.035886
[16:20:03.609] iteration 10131: loss: 0.078433, loss_s1: 0.037210, loss_fp: 0.004643, loss_freq: 0.038500
[16:20:04.234] iteration 10132: loss: 0.125168, loss_s1: 0.085283, loss_fp: 0.004086, loss_freq: 0.082732
[16:20:04.860] iteration 10133: loss: 0.085444, loss_s1: 0.048128, loss_fp: 0.002546, loss_freq: 0.035181
[16:20:05.482] iteration 10134: loss: 0.098401, loss_s1: 0.066114, loss_fp: 0.008623, loss_freq: 0.065709
[16:20:06.110] iteration 10135: loss: 0.068645, loss_s1: 0.062206, loss_fp: 0.004490, loss_freq: 0.022641
[16:20:06.730] iteration 10136: loss: 0.081367, loss_s1: 0.041036, loss_fp: 0.003563, loss_freq: 0.013737
[16:20:07.357] iteration 10137: loss: 0.049487, loss_s1: 0.032801, loss_fp: 0.000468, loss_freq: 0.006076
[16:20:07.981] iteration 10138: loss: 0.056485, loss_s1: 0.049622, loss_fp: 0.000729, loss_freq: 0.011733
[16:20:08.605] iteration 10139: loss: 0.068381, loss_s1: 0.025298, loss_fp: 0.000925, loss_freq: 0.022401
[16:20:09.236] iteration 10140: loss: 0.095349, loss_s1: 0.085284, loss_fp: 0.003277, loss_freq: 0.023074
[16:20:09.863] iteration 10141: loss: 0.094855, loss_s1: 0.074028, loss_fp: 0.018658, loss_freq: 0.026653
[16:20:10.481] iteration 10142: loss: 0.088191, loss_s1: 0.041377, loss_fp: 0.008857, loss_freq: 0.022309
[16:20:11.107] iteration 10143: loss: 0.115290, loss_s1: 0.137643, loss_fp: 0.005002, loss_freq: 0.035476
[16:20:12.085] iteration 10144: loss: 0.091563, loss_s1: 0.068786, loss_fp: 0.002136, loss_freq: 0.036081
[16:20:12.710] iteration 10145: loss: 0.072644, loss_s1: 0.086631, loss_fp: 0.005317, loss_freq: 0.007507
[16:20:13.339] iteration 10146: loss: 0.080686, loss_s1: 0.033017, loss_fp: 0.001269, loss_freq: 0.019339
[16:20:13.969] iteration 10147: loss: 0.047920, loss_s1: 0.014966, loss_fp: 0.000624, loss_freq: 0.017313
[16:20:14.594] iteration 10148: loss: 0.076120, loss_s1: 0.056851, loss_fp: 0.007413, loss_freq: 0.032376
[16:20:15.240] iteration 10149: loss: 0.110920, loss_s1: 0.098596, loss_fp: 0.004035, loss_freq: 0.022989
[16:20:15.876] iteration 10150: loss: 0.041478, loss_s1: 0.009814, loss_fp: 0.001084, loss_freq: 0.028755
[16:20:16.516] iteration 10151: loss: 0.086124, loss_s1: 0.083821, loss_fp: 0.006915, loss_freq: 0.031830
[16:20:17.152] iteration 10152: loss: 0.071985, loss_s1: 0.044252, loss_fp: 0.015583, loss_freq: 0.031118
[16:20:17.776] iteration 10153: loss: 0.097398, loss_s1: 0.080963, loss_fp: 0.014434, loss_freq: 0.028165
[16:20:18.403] iteration 10154: loss: 0.059157, loss_s1: 0.019543, loss_fp: 0.001018, loss_freq: 0.025430
[16:20:19.029] iteration 10155: loss: 0.146376, loss_s1: 0.134968, loss_fp: 0.003386, loss_freq: 0.059823
[16:20:19.657] iteration 10156: loss: 0.094637, loss_s1: 0.046645, loss_fp: 0.014442, loss_freq: 0.047881
[16:20:20.281] iteration 10157: loss: 0.084924, loss_s1: 0.025132, loss_fp: 0.001466, loss_freq: 0.063749
[16:20:20.902] iteration 10158: loss: 0.060164, loss_s1: 0.028854, loss_fp: 0.001803, loss_freq: 0.025192
[16:20:21.523] iteration 10159: loss: 0.142878, loss_s1: 0.141669, loss_fp: 0.005255, loss_freq: 0.066346
[16:20:22.144] iteration 10160: loss: 0.099830, loss_s1: 0.073813, loss_fp: 0.003534, loss_freq: 0.016671
[16:20:22.771] iteration 10161: loss: 0.091119, loss_s1: 0.060612, loss_fp: 0.003390, loss_freq: 0.051254
[16:20:23.398] iteration 10162: loss: 0.057012, loss_s1: 0.052084, loss_fp: 0.001263, loss_freq: 0.013023
[16:20:24.023] iteration 10163: loss: 0.055049, loss_s1: 0.033811, loss_fp: 0.001099, loss_freq: 0.021058
[16:20:24.654] iteration 10164: loss: 0.050202, loss_s1: 0.024008, loss_fp: 0.001041, loss_freq: 0.004240
[16:20:25.370] iteration 10165: loss: 0.065998, loss_s1: 0.031818, loss_fp: 0.001270, loss_freq: 0.033410
[16:20:26.034] iteration 10166: loss: 0.104932, loss_s1: 0.070362, loss_fp: 0.003423, loss_freq: 0.033960
[16:20:26.696] iteration 10167: loss: 0.169712, loss_s1: 0.085902, loss_fp: 0.034828, loss_freq: 0.156763
[16:20:27.359] iteration 10168: loss: 0.052134, loss_s1: 0.043517, loss_fp: 0.001728, loss_freq: 0.017401
[16:20:28.019] iteration 10169: loss: 0.065738, loss_s1: 0.034420, loss_fp: 0.003915, loss_freq: 0.029786
[16:20:28.651] iteration 10170: loss: 0.053348, loss_s1: 0.038220, loss_fp: 0.000511, loss_freq: 0.018933
[16:20:29.280] iteration 10171: loss: 0.086139, loss_s1: 0.049122, loss_fp: 0.010132, loss_freq: 0.023990
[16:20:29.903] iteration 10172: loss: 0.083746, loss_s1: 0.060172, loss_fp: 0.003411, loss_freq: 0.049232
[16:20:30.526] iteration 10173: loss: 0.065451, loss_s1: 0.040476, loss_fp: 0.002277, loss_freq: 0.010187
[16:20:31.155] iteration 10174: loss: 0.052901, loss_s1: 0.033104, loss_fp: 0.008160, loss_freq: 0.015918
[16:20:31.779] iteration 10175: loss: 0.119171, loss_s1: 0.044758, loss_fp: 0.002177, loss_freq: 0.020539
[16:20:32.400] iteration 10176: loss: 0.064919, loss_s1: 0.034579, loss_fp: 0.007195, loss_freq: 0.022026
[16:20:33.024] iteration 10177: loss: 0.046296, loss_s1: 0.041024, loss_fp: 0.000779, loss_freq: 0.013215
[16:20:33.657] iteration 10178: loss: 0.074085, loss_s1: 0.030188, loss_fp: 0.000447, loss_freq: 0.017143
[16:20:34.278] iteration 10179: loss: 0.084730, loss_s1: 0.079742, loss_fp: 0.000617, loss_freq: 0.017663
[16:20:34.899] iteration 10180: loss: 0.096395, loss_s1: 0.072559, loss_fp: 0.002786, loss_freq: 0.057125
[16:20:35.529] iteration 10181: loss: 0.099743, loss_s1: 0.084131, loss_fp: 0.003348, loss_freq: 0.039513
[16:20:36.152] iteration 10182: loss: 0.107487, loss_s1: 0.071853, loss_fp: 0.006523, loss_freq: 0.067874
[16:20:36.779] iteration 10183: loss: 0.065007, loss_s1: 0.041851, loss_fp: 0.000662, loss_freq: 0.014636
[16:20:37.408] iteration 10184: loss: 0.078545, loss_s1: 0.052831, loss_fp: 0.007556, loss_freq: 0.005872
[16:20:38.054] iteration 10185: loss: 0.101084, loss_s1: 0.096824, loss_fp: 0.003560, loss_freq: 0.053863
[16:20:38.711] iteration 10186: loss: 0.062745, loss_s1: 0.023324, loss_fp: 0.010334, loss_freq: 0.037233
[16:20:39.359] iteration 10187: loss: 0.085816, loss_s1: 0.042418, loss_fp: 0.006584, loss_freq: 0.059247
[16:20:39.980] iteration 10188: loss: 0.068164, loss_s1: 0.045909, loss_fp: 0.005104, loss_freq: 0.027898
[16:20:40.600] iteration 10189: loss: 0.068236, loss_s1: 0.061221, loss_fp: 0.003444, loss_freq: 0.012556
[16:20:41.216] iteration 10190: loss: 0.050999, loss_s1: 0.030057, loss_fp: 0.000398, loss_freq: 0.027273
[16:20:41.840] iteration 10191: loss: 0.084600, loss_s1: 0.059999, loss_fp: 0.000874, loss_freq: 0.034340
[16:20:42.493] iteration 10192: loss: 0.077612, loss_s1: 0.046675, loss_fp: 0.000695, loss_freq: 0.034605
[16:20:43.149] iteration 10193: loss: 0.070429, loss_s1: 0.057689, loss_fp: 0.000823, loss_freq: 0.029949
[16:20:43.782] iteration 10194: loss: 0.094455, loss_s1: 0.073309, loss_fp: 0.001871, loss_freq: 0.061701
[16:20:44.406] iteration 10195: loss: 0.055560, loss_s1: 0.021700, loss_fp: 0.000933, loss_freq: 0.033940
[16:20:45.027] iteration 10196: loss: 0.053821, loss_s1: 0.015774, loss_fp: 0.004888, loss_freq: 0.020705
[16:20:45.696] iteration 10197: loss: 0.068947, loss_s1: 0.045292, loss_fp: 0.000581, loss_freq: 0.030181
[16:20:46.356] iteration 10198: loss: 0.079121, loss_s1: 0.034442, loss_fp: 0.001585, loss_freq: 0.031406
[16:20:47.015] iteration 10199: loss: 0.145846, loss_s1: 0.152793, loss_fp: 0.006411, loss_freq: 0.066238
[16:20:47.674] iteration 10200: loss: 0.054564, loss_s1: 0.023534, loss_fp: 0.001830, loss_freq: 0.019506
[16:20:50.919] iteration 10200 : mean_dice : 0.688179
[16:20:51.596] iteration 10201: loss: 0.083945, loss_s1: 0.018211, loss_fp: 0.011021, loss_freq: 0.050144
[16:20:52.250] iteration 10202: loss: 0.049098, loss_s1: 0.042168, loss_fp: 0.000626, loss_freq: 0.011269
[16:20:52.908] iteration 10203: loss: 0.053648, loss_s1: 0.034078, loss_fp: 0.002390, loss_freq: 0.018359
[16:20:53.539] iteration 10204: loss: 0.057439, loss_s1: 0.022331, loss_fp: 0.002256, loss_freq: 0.012587
[16:20:54.165] iteration 10205: loss: 0.045288, loss_s1: 0.034781, loss_fp: 0.002692, loss_freq: 0.004741
[16:20:54.791] iteration 10206: loss: 0.062044, loss_s1: 0.033925, loss_fp: 0.000993, loss_freq: 0.018269
[16:20:55.419] iteration 10207: loss: 0.090205, loss_s1: 0.051263, loss_fp: 0.004147, loss_freq: 0.046916
[16:20:56.042] iteration 10208: loss: 0.067533, loss_s1: 0.064099, loss_fp: 0.009398, loss_freq: 0.015599
[16:20:56.668] iteration 10209: loss: 0.081906, loss_s1: 0.037970, loss_fp: 0.001085, loss_freq: 0.081517
[16:20:57.293] iteration 10210: loss: 0.067431, loss_s1: 0.033717, loss_fp: 0.001851, loss_freq: 0.042757
[16:20:57.917] iteration 10211: loss: 0.052347, loss_s1: 0.042985, loss_fp: 0.001204, loss_freq: 0.023634
[16:20:58.542] iteration 10212: loss: 0.035157, loss_s1: 0.020535, loss_fp: 0.000629, loss_freq: 0.009019
[16:20:59.167] iteration 10213: loss: 0.101309, loss_s1: 0.055225, loss_fp: 0.000804, loss_freq: 0.010944
[16:20:59.793] iteration 10214: loss: 0.093770, loss_s1: 0.071233, loss_fp: 0.003281, loss_freq: 0.067954
[16:21:00.421] iteration 10215: loss: 0.061252, loss_s1: 0.026937, loss_fp: 0.000498, loss_freq: 0.042137
[16:21:01.050] iteration 10216: loss: 0.074753, loss_s1: 0.050249, loss_fp: 0.009784, loss_freq: 0.037434
[16:21:01.677] iteration 10217: loss: 0.043298, loss_s1: 0.014861, loss_fp: 0.002104, loss_freq: 0.016152
[16:21:02.302] iteration 10218: loss: 0.085018, loss_s1: 0.073194, loss_fp: 0.001525, loss_freq: 0.041825
[16:21:02.930] iteration 10219: loss: 0.129892, loss_s1: 0.120522, loss_fp: 0.000568, loss_freq: 0.030759
[16:21:03.552] iteration 10220: loss: 0.104691, loss_s1: 0.090070, loss_fp: 0.005156, loss_freq: 0.046705
[16:21:04.177] iteration 10221: loss: 0.069307, loss_s1: 0.077577, loss_fp: 0.002437, loss_freq: 0.013663
[16:21:04.801] iteration 10222: loss: 0.050135, loss_s1: 0.023568, loss_fp: 0.002313, loss_freq: 0.011983
[16:21:05.424] iteration 10223: loss: 0.066954, loss_s1: 0.044613, loss_fp: 0.001633, loss_freq: 0.031160
[16:21:06.050] iteration 10224: loss: 0.069908, loss_s1: 0.036185, loss_fp: 0.001889, loss_freq: 0.046155
[16:21:06.675] iteration 10225: loss: 0.125017, loss_s1: 0.163138, loss_fp: 0.004332, loss_freq: 0.031742
[16:21:07.299] iteration 10226: loss: 0.119601, loss_s1: 0.066932, loss_fp: 0.007364, loss_freq: 0.107139
[16:21:07.922] iteration 10227: loss: 0.098609, loss_s1: 0.081037, loss_fp: 0.003311, loss_freq: 0.046821
[16:21:08.545] iteration 10228: loss: 0.129807, loss_s1: 0.105569, loss_fp: 0.007179, loss_freq: 0.073909
[16:21:09.169] iteration 10229: loss: 0.057000, loss_s1: 0.049029, loss_fp: 0.001685, loss_freq: 0.022670
[16:21:09.794] iteration 10230: loss: 0.061392, loss_s1: 0.027476, loss_fp: 0.001463, loss_freq: 0.030514
[16:21:10.422] iteration 10231: loss: 0.075178, loss_s1: 0.076315, loss_fp: 0.004820, loss_freq: 0.018890
[16:21:11.047] iteration 10232: loss: 0.055960, loss_s1: 0.035748, loss_fp: 0.001879, loss_freq: 0.025484
[16:21:11.672] iteration 10233: loss: 0.099784, loss_s1: 0.078222, loss_fp: 0.000654, loss_freq: 0.038158
[16:21:12.299] iteration 10234: loss: 0.081316, loss_s1: 0.038034, loss_fp: 0.002638, loss_freq: 0.017432
[16:21:12.927] iteration 10235: loss: 0.071030, loss_s1: 0.028661, loss_fp: 0.002013, loss_freq: 0.013019
[16:21:13.552] iteration 10236: loss: 0.109599, loss_s1: 0.059675, loss_fp: 0.000849, loss_freq: 0.021330
[16:21:14.178] iteration 10237: loss: 0.047616, loss_s1: 0.043411, loss_fp: 0.001592, loss_freq: 0.010258
[16:21:14.800] iteration 10238: loss: 0.052694, loss_s1: 0.034496, loss_fp: 0.001924, loss_freq: 0.022161
[16:21:15.423] iteration 10239: loss: 0.039955, loss_s1: 0.020688, loss_fp: 0.002733, loss_freq: 0.015431
[16:21:16.047] iteration 10240: loss: 0.054043, loss_s1: 0.036659, loss_fp: 0.000511, loss_freq: 0.014790
[16:21:16.670] iteration 10241: loss: 0.049307, loss_s1: 0.018209, loss_fp: 0.001391, loss_freq: 0.019238
[16:21:17.292] iteration 10242: loss: 0.058060, loss_s1: 0.045401, loss_fp: 0.002040, loss_freq: 0.015337
[16:21:17.916] iteration 10243: loss: 0.073687, loss_s1: 0.056335, loss_fp: 0.004929, loss_freq: 0.024837
[16:21:18.539] iteration 10244: loss: 0.086725, loss_s1: 0.076868, loss_fp: 0.007029, loss_freq: 0.047327
[16:21:19.162] iteration 10245: loss: 0.094202, loss_s1: 0.050202, loss_fp: 0.005509, loss_freq: 0.061733
[16:21:19.786] iteration 10246: loss: 0.114064, loss_s1: 0.065548, loss_fp: 0.004042, loss_freq: 0.074445
[16:21:20.411] iteration 10247: loss: 0.069342, loss_s1: 0.038913, loss_fp: 0.005382, loss_freq: 0.043994
[16:21:21.034] iteration 10248: loss: 0.093083, loss_s1: 0.059054, loss_fp: 0.002886, loss_freq: 0.027021
[16:21:21.659] iteration 10249: loss: 0.051393, loss_s1: 0.024104, loss_fp: 0.003345, loss_freq: 0.024742
[16:21:22.284] iteration 10250: loss: 0.079549, loss_s1: 0.038819, loss_fp: 0.006077, loss_freq: 0.018152
[16:21:22.909] iteration 10251: loss: 0.116955, loss_s1: 0.108428, loss_fp: 0.002887, loss_freq: 0.058367
[16:21:23.532] iteration 10252: loss: 0.156371, loss_s1: 0.096079, loss_fp: 0.017200, loss_freq: 0.111740
[16:21:24.158] iteration 10253: loss: 0.061938, loss_s1: 0.033675, loss_fp: 0.002028, loss_freq: 0.036356
[16:21:24.783] iteration 10254: loss: 0.071188, loss_s1: 0.016266, loss_fp: 0.001481, loss_freq: 0.037092
[16:21:25.411] iteration 10255: loss: 0.105217, loss_s1: 0.047737, loss_fp: 0.002992, loss_freq: 0.106441
[16:21:26.036] iteration 10256: loss: 0.086805, loss_s1: 0.059784, loss_fp: 0.008052, loss_freq: 0.056422
[16:21:26.659] iteration 10257: loss: 0.060004, loss_s1: 0.041686, loss_fp: 0.000652, loss_freq: 0.035377
[16:21:27.279] iteration 10258: loss: 0.037821, loss_s1: 0.016103, loss_fp: 0.000718, loss_freq: 0.004590
[16:21:27.902] iteration 10259: loss: 0.108307, loss_s1: 0.067864, loss_fp: 0.001112, loss_freq: 0.092505
[16:21:28.522] iteration 10260: loss: 0.072867, loss_s1: 0.065666, loss_fp: 0.004285, loss_freq: 0.034536
[16:21:29.144] iteration 10261: loss: 0.057554, loss_s1: 0.045742, loss_fp: 0.004449, loss_freq: 0.017760
[16:21:29.764] iteration 10262: loss: 0.065833, loss_s1: 0.041786, loss_fp: 0.005670, loss_freq: 0.032987
[16:21:30.389] iteration 10263: loss: 0.106316, loss_s1: 0.050421, loss_fp: 0.002209, loss_freq: 0.107283
[16:21:31.015] iteration 10264: loss: 0.060415, loss_s1: 0.051419, loss_fp: 0.004834, loss_freq: 0.013043
[16:21:31.641] iteration 10265: loss: 0.091357, loss_s1: 0.052885, loss_fp: 0.000831, loss_freq: 0.025315
[16:21:32.263] iteration 10266: loss: 0.053012, loss_s1: 0.043170, loss_fp: 0.002700, loss_freq: 0.017407
[16:21:32.884] iteration 10267: loss: 0.107557, loss_s1: 0.062254, loss_fp: 0.004309, loss_freq: 0.016609
[16:21:33.503] iteration 10268: loss: 0.130587, loss_s1: 0.058883, loss_fp: 0.000798, loss_freq: 0.089303
[16:21:34.125] iteration 10269: loss: 0.092026, loss_s1: 0.049365, loss_fp: 0.002828, loss_freq: 0.047433
[16:21:34.748] iteration 10270: loss: 0.080868, loss_s1: 0.068838, loss_fp: 0.001793, loss_freq: 0.022662
[16:21:35.372] iteration 10271: loss: 0.104029, loss_s1: 0.080743, loss_fp: 0.004013, loss_freq: 0.032946
[16:21:35.991] iteration 10272: loss: 0.056435, loss_s1: 0.033093, loss_fp: 0.000269, loss_freq: 0.018569
[16:21:36.611] iteration 10273: loss: 0.047743, loss_s1: 0.034716, loss_fp: 0.002724, loss_freq: 0.018144
[16:21:37.242] iteration 10274: loss: 0.110311, loss_s1: 0.059700, loss_fp: 0.006901, loss_freq: 0.097102
[16:21:37.863] iteration 10275: loss: 0.083154, loss_s1: 0.081741, loss_fp: 0.000373, loss_freq: 0.023410
[16:21:38.487] iteration 10276: loss: 0.086489, loss_s1: 0.073809, loss_fp: 0.001221, loss_freq: 0.033896
[16:21:39.111] iteration 10277: loss: 0.049124, loss_s1: 0.026196, loss_fp: 0.002037, loss_freq: 0.013747
[16:21:39.733] iteration 10278: loss: 0.069998, loss_s1: 0.051059, loss_fp: 0.001090, loss_freq: 0.042282
[16:21:40.358] iteration 10279: loss: 0.076930, loss_s1: 0.072982, loss_fp: 0.001123, loss_freq: 0.024950
[16:21:40.980] iteration 10280: loss: 0.053668, loss_s1: 0.034646, loss_fp: 0.001715, loss_freq: 0.010238
[16:21:41.608] iteration 10281: loss: 0.078917, loss_s1: 0.049956, loss_fp: 0.012450, loss_freq: 0.045014
[16:21:42.236] iteration 10282: loss: 0.079929, loss_s1: 0.074217, loss_fp: 0.003486, loss_freq: 0.016121
[16:21:42.864] iteration 10283: loss: 0.104831, loss_s1: 0.075738, loss_fp: 0.013623, loss_freq: 0.051061
[16:21:43.486] iteration 10284: loss: 0.115583, loss_s1: 0.109223, loss_fp: 0.017654, loss_freq: 0.061040
[16:21:44.110] iteration 10285: loss: 0.051984, loss_s1: 0.020236, loss_fp: 0.012562, loss_freq: 0.023353
[16:21:44.733] iteration 10286: loss: 0.105080, loss_s1: 0.050589, loss_fp: 0.003566, loss_freq: 0.053018
[16:21:45.358] iteration 10287: loss: 0.112252, loss_s1: 0.084189, loss_fp: 0.010356, loss_freq: 0.036279
[16:21:45.979] iteration 10288: loss: 0.069763, loss_s1: 0.041923, loss_fp: 0.013774, loss_freq: 0.024656
[16:21:46.600] iteration 10289: loss: 0.099312, loss_s1: 0.095739, loss_fp: 0.005467, loss_freq: 0.032942
[16:21:47.223] iteration 10290: loss: 0.096760, loss_s1: 0.073219, loss_fp: 0.004640, loss_freq: 0.074133
[16:21:47.845] iteration 10291: loss: 0.084321, loss_s1: 0.047899, loss_fp: 0.001390, loss_freq: 0.017273
[16:21:48.465] iteration 10292: loss: 0.090571, loss_s1: 0.052808, loss_fp: 0.002452, loss_freq: 0.040788
[16:21:49.092] iteration 10293: loss: 0.131757, loss_s1: 0.087712, loss_fp: 0.001508, loss_freq: 0.063519
[16:21:49.714] iteration 10294: loss: 0.108439, loss_s1: 0.081185, loss_fp: 0.016725, loss_freq: 0.048310
[16:21:50.339] iteration 10295: loss: 0.146009, loss_s1: 0.170301, loss_fp: 0.006616, loss_freq: 0.060037
[16:21:50.963] iteration 10296: loss: 0.064473, loss_s1: 0.060069, loss_fp: 0.002072, loss_freq: 0.022991
[16:21:51.586] iteration 10297: loss: 0.110511, loss_s1: 0.058648, loss_fp: 0.001118, loss_freq: 0.049568
[16:21:52.214] iteration 10298: loss: 0.056004, loss_s1: 0.045029, loss_fp: 0.002654, loss_freq: 0.007825
[16:21:52.837] iteration 10299: loss: 0.048564, loss_s1: 0.035209, loss_fp: 0.004081, loss_freq: 0.009590
[16:21:53.458] iteration 10300: loss: 0.097181, loss_s1: 0.041410, loss_fp: 0.000924, loss_freq: 0.015409
[16:21:54.080] iteration 10301: loss: 0.108458, loss_s1: 0.126174, loss_fp: 0.002667, loss_freq: 0.025096
[16:21:54.704] iteration 10302: loss: 0.101590, loss_s1: 0.068204, loss_fp: 0.003794, loss_freq: 0.034408
[16:21:55.322] iteration 10303: loss: 0.062947, loss_s1: 0.050424, loss_fp: 0.001948, loss_freq: 0.006539
[16:21:55.941] iteration 10304: loss: 0.091494, loss_s1: 0.030703, loss_fp: 0.004998, loss_freq: 0.049205
[16:21:56.893] iteration 10305: loss: 0.059958, loss_s1: 0.025244, loss_fp: 0.002133, loss_freq: 0.021266
[16:21:57.535] iteration 10306: loss: 0.058281, loss_s1: 0.031423, loss_fp: 0.008641, loss_freq: 0.018390
[16:21:58.158] iteration 10307: loss: 0.090816, loss_s1: 0.043939, loss_fp: 0.002916, loss_freq: 0.037661
[16:21:58.783] iteration 10308: loss: 0.039707, loss_s1: 0.011582, loss_fp: 0.000347, loss_freq: 0.008798
[16:21:59.405] iteration 10309: loss: 0.076577, loss_s1: 0.058755, loss_fp: 0.002158, loss_freq: 0.021294
[16:22:00.023] iteration 10310: loss: 0.184488, loss_s1: 0.138073, loss_fp: 0.016408, loss_freq: 0.033814
[16:22:00.647] iteration 10311: loss: 0.057645, loss_s1: 0.037853, loss_fp: 0.002336, loss_freq: 0.031933
[16:22:01.306] iteration 10312: loss: 0.103020, loss_s1: 0.104247, loss_fp: 0.001273, loss_freq: 0.041887
[16:22:01.968] iteration 10313: loss: 0.064051, loss_s1: 0.033533, loss_fp: 0.002886, loss_freq: 0.039786
[16:22:02.622] iteration 10314: loss: 0.075219, loss_s1: 0.046664, loss_fp: 0.007989, loss_freq: 0.036789
[16:22:03.278] iteration 10315: loss: 0.045061, loss_s1: 0.024507, loss_fp: 0.001252, loss_freq: 0.007341
[16:22:03.910] iteration 10316: loss: 0.094080, loss_s1: 0.057615, loss_fp: 0.005985, loss_freq: 0.069335
[16:22:04.568] iteration 10317: loss: 0.103386, loss_s1: 0.082717, loss_fp: 0.005344, loss_freq: 0.079872
[16:22:05.228] iteration 10318: loss: 0.097956, loss_s1: 0.067446, loss_fp: 0.002882, loss_freq: 0.041413
[16:22:05.889] iteration 10319: loss: 0.062024, loss_s1: 0.027304, loss_fp: 0.005265, loss_freq: 0.034561
[16:22:06.561] iteration 10320: loss: 0.091842, loss_s1: 0.060157, loss_fp: 0.008037, loss_freq: 0.051821
[16:22:07.221] iteration 10321: loss: 0.069043, loss_s1: 0.027348, loss_fp: 0.004494, loss_freq: 0.012208
[16:22:07.853] iteration 10322: loss: 0.066928, loss_s1: 0.035117, loss_fp: 0.001519, loss_freq: 0.039017
[16:22:08.486] iteration 10323: loss: 0.055375, loss_s1: 0.011365, loss_fp: 0.001143, loss_freq: 0.032828
[16:22:09.113] iteration 10324: loss: 0.097262, loss_s1: 0.077790, loss_fp: 0.001455, loss_freq: 0.019546
[16:22:09.741] iteration 10325: loss: 0.076476, loss_s1: 0.067576, loss_fp: 0.000469, loss_freq: 0.010261
[16:22:10.369] iteration 10326: loss: 0.094944, loss_s1: 0.082470, loss_fp: 0.001668, loss_freq: 0.026688
[16:22:10.996] iteration 10327: loss: 0.106406, loss_s1: 0.077055, loss_fp: 0.004104, loss_freq: 0.055351
[16:22:11.621] iteration 10328: loss: 0.191928, loss_s1: 0.103512, loss_fp: 0.019604, loss_freq: 0.202198
[16:22:12.282] iteration 10329: loss: 0.059051, loss_s1: 0.048968, loss_fp: 0.000639, loss_freq: 0.021219
[16:22:12.941] iteration 10330: loss: 0.078193, loss_s1: 0.066175, loss_fp: 0.002494, loss_freq: 0.032021
[16:22:13.596] iteration 10331: loss: 0.072220, loss_s1: 0.041817, loss_fp: 0.001928, loss_freq: 0.038404
[16:22:14.222] iteration 10332: loss: 0.112214, loss_s1: 0.078212, loss_fp: 0.000903, loss_freq: 0.073676
[16:22:14.845] iteration 10333: loss: 0.090071, loss_s1: 0.084627, loss_fp: 0.002482, loss_freq: 0.039337
[16:22:15.466] iteration 10334: loss: 0.057822, loss_s1: 0.036831, loss_fp: 0.000441, loss_freq: 0.028868
[16:22:16.089] iteration 10335: loss: 0.048457, loss_s1: 0.029026, loss_fp: 0.006340, loss_freq: 0.028826
[16:22:16.727] iteration 10336: loss: 0.063135, loss_s1: 0.039676, loss_fp: 0.004837, loss_freq: 0.019266
[16:22:17.354] iteration 10337: loss: 0.065794, loss_s1: 0.028175, loss_fp: 0.001720, loss_freq: 0.022118
[16:22:17.982] iteration 10338: loss: 0.043322, loss_s1: 0.034886, loss_fp: 0.002123, loss_freq: 0.013314
[16:22:18.606] iteration 10339: loss: 0.095890, loss_s1: 0.039575, loss_fp: 0.001305, loss_freq: 0.023614
[16:22:19.237] iteration 10340: loss: 0.069340, loss_s1: 0.037786, loss_fp: 0.002719, loss_freq: 0.036438
[16:22:19.867] iteration 10341: loss: 0.094666, loss_s1: 0.046485, loss_fp: 0.001607, loss_freq: 0.045578
[16:22:20.493] iteration 10342: loss: 0.067551, loss_s1: 0.023171, loss_fp: 0.001767, loss_freq: 0.046224
[16:22:21.119] iteration 10343: loss: 0.138739, loss_s1: 0.112932, loss_fp: 0.001229, loss_freq: 0.101461
[16:22:21.740] iteration 10344: loss: 0.060013, loss_s1: 0.042146, loss_fp: 0.003906, loss_freq: 0.026593
[16:22:22.391] iteration 10345: loss: 0.070964, loss_s1: 0.041086, loss_fp: 0.007328, loss_freq: 0.020198
[16:22:23.021] iteration 10346: loss: 0.109595, loss_s1: 0.088310, loss_fp: 0.003257, loss_freq: 0.082489
[16:22:23.689] iteration 10347: loss: 0.057569, loss_s1: 0.029063, loss_fp: 0.003223, loss_freq: 0.045921
[16:22:24.356] iteration 10348: loss: 0.087601, loss_s1: 0.048121, loss_fp: 0.009633, loss_freq: 0.042907
[16:22:25.025] iteration 10349: loss: 0.099360, loss_s1: 0.086421, loss_fp: 0.004939, loss_freq: 0.065132
[16:22:25.671] iteration 10350: loss: 0.039164, loss_s1: 0.011805, loss_fp: 0.000664, loss_freq: 0.009337
[16:22:26.302] iteration 10351: loss: 0.051245, loss_s1: 0.033934, loss_fp: 0.001013, loss_freq: 0.016202
[16:22:26.936] iteration 10352: loss: 0.062959, loss_s1: 0.045375, loss_fp: 0.005843, loss_freq: 0.024720
[16:22:27.564] iteration 10353: loss: 0.059173, loss_s1: 0.043855, loss_fp: 0.000986, loss_freq: 0.025295
[16:22:28.195] iteration 10354: loss: 0.074920, loss_s1: 0.035782, loss_fp: 0.000811, loss_freq: 0.064329
[16:22:28.827] iteration 10355: loss: 0.101618, loss_s1: 0.119526, loss_fp: 0.000592, loss_freq: 0.030547
[16:22:29.686] iteration 10356: loss: 0.074268, loss_s1: 0.048360, loss_fp: 0.001252, loss_freq: 0.018469
[16:22:30.444] iteration 10357: loss: 0.081745, loss_s1: 0.059435, loss_fp: 0.000912, loss_freq: 0.056692
[16:22:31.201] iteration 10358: loss: 0.081467, loss_s1: 0.072520, loss_fp: 0.001736, loss_freq: 0.036469
[16:22:31.899] iteration 10359: loss: 0.069796, loss_s1: 0.036014, loss_fp: 0.000988, loss_freq: 0.021013
[16:22:32.534] iteration 10360: loss: 0.113455, loss_s1: 0.130184, loss_fp: 0.001835, loss_freq: 0.041688
[16:22:33.163] iteration 10361: loss: 0.052574, loss_s1: 0.046828, loss_fp: 0.000790, loss_freq: 0.003122
[16:22:33.785] iteration 10362: loss: 0.063589, loss_s1: 0.030128, loss_fp: 0.002740, loss_freq: 0.032435
[16:22:34.421] iteration 10363: loss: 0.046238, loss_s1: 0.031783, loss_fp: 0.001561, loss_freq: 0.021038
[16:22:35.059] iteration 10364: loss: 0.073864, loss_s1: 0.057615, loss_fp: 0.002829, loss_freq: 0.041329
[16:22:35.686] iteration 10365: loss: 0.063780, loss_s1: 0.025944, loss_fp: 0.001390, loss_freq: 0.023906
[16:22:36.329] iteration 10366: loss: 0.055341, loss_s1: 0.038082, loss_fp: 0.008206, loss_freq: 0.018647
[16:22:36.954] iteration 10367: loss: 0.050468, loss_s1: 0.031165, loss_fp: 0.000428, loss_freq: 0.015918
[16:22:37.581] iteration 10368: loss: 0.061473, loss_s1: 0.059294, loss_fp: 0.001324, loss_freq: 0.018510
[16:22:38.212] iteration 10369: loss: 0.053044, loss_s1: 0.030559, loss_fp: 0.008178, loss_freq: 0.017591
[16:22:38.839] iteration 10370: loss: 0.062946, loss_s1: 0.040235, loss_fp: 0.002085, loss_freq: 0.039422
[16:22:39.468] iteration 10371: loss: 0.058982, loss_s1: 0.026453, loss_fp: 0.001615, loss_freq: 0.038843
[16:22:40.098] iteration 10372: loss: 0.050896, loss_s1: 0.027752, loss_fp: 0.004941, loss_freq: 0.032651
[16:22:40.730] iteration 10373: loss: 0.054033, loss_s1: 0.009928, loss_fp: 0.000635, loss_freq: 0.013617
[16:22:41.357] iteration 10374: loss: 0.099926, loss_s1: 0.047927, loss_fp: 0.001076, loss_freq: 0.022552
[16:22:41.984] iteration 10375: loss: 0.069173, loss_s1: 0.061963, loss_fp: 0.003445, loss_freq: 0.026296
[16:22:42.611] iteration 10376: loss: 0.084554, loss_s1: 0.039442, loss_fp: 0.001221, loss_freq: 0.036876
[16:22:43.237] iteration 10377: loss: 0.094527, loss_s1: 0.057043, loss_fp: 0.002222, loss_freq: 0.034043
[16:22:43.858] iteration 10378: loss: 0.042734, loss_s1: 0.018819, loss_fp: 0.002132, loss_freq: 0.010227
[16:22:44.482] iteration 10379: loss: 0.062153, loss_s1: 0.043452, loss_fp: 0.003076, loss_freq: 0.024001
[16:22:45.110] iteration 10380: loss: 0.098583, loss_s1: 0.085188, loss_fp: 0.030011, loss_freq: 0.012475
[16:22:45.735] iteration 10381: loss: 0.074964, loss_s1: 0.048356, loss_fp: 0.009169, loss_freq: 0.043266
[16:22:46.365] iteration 10382: loss: 0.071522, loss_s1: 0.065875, loss_fp: 0.003611, loss_freq: 0.035017
[16:22:46.992] iteration 10383: loss: 0.063637, loss_s1: 0.048194, loss_fp: 0.004063, loss_freq: 0.014051
[16:22:47.616] iteration 10384: loss: 0.043117, loss_s1: 0.013555, loss_fp: 0.003138, loss_freq: 0.017939
[16:22:48.241] iteration 10385: loss: 0.046804, loss_s1: 0.035770, loss_fp: 0.003482, loss_freq: 0.015267
[16:22:48.864] iteration 10386: loss: 0.069221, loss_s1: 0.062730, loss_fp: 0.004417, loss_freq: 0.032861
[16:22:49.491] iteration 10387: loss: 0.103741, loss_s1: 0.095382, loss_fp: 0.007791, loss_freq: 0.039715
[16:22:50.115] iteration 10388: loss: 0.076823, loss_s1: 0.025656, loss_fp: 0.004072, loss_freq: 0.015735
[16:22:50.738] iteration 10389: loss: 0.145294, loss_s1: 0.133028, loss_fp: 0.020706, loss_freq: 0.094720
[16:22:51.357] iteration 10390: loss: 0.043039, loss_s1: 0.030131, loss_fp: 0.001546, loss_freq: 0.014509
[16:22:51.983] iteration 10391: loss: 0.083867, loss_s1: 0.076319, loss_fp: 0.001438, loss_freq: 0.014940
[16:22:52.605] iteration 10392: loss: 0.039861, loss_s1: 0.013398, loss_fp: 0.002617, loss_freq: 0.011688
[16:22:53.233] iteration 10393: loss: 0.065716, loss_s1: 0.065101, loss_fp: 0.003056, loss_freq: 0.017819
[16:22:53.857] iteration 10394: loss: 0.107204, loss_s1: 0.075787, loss_fp: 0.004759, loss_freq: 0.035690
[16:22:54.484] iteration 10395: loss: 0.082717, loss_s1: 0.037442, loss_fp: 0.003347, loss_freq: 0.020129
[16:22:55.114] iteration 10396: loss: 0.057064, loss_s1: 0.027040, loss_fp: 0.004401, loss_freq: 0.011740
[16:22:55.742] iteration 10397: loss: 0.103917, loss_s1: 0.032079, loss_fp: 0.003483, loss_freq: 0.019634
[16:22:56.380] iteration 10398: loss: 0.057544, loss_s1: 0.025629, loss_fp: 0.000269, loss_freq: 0.032524
[16:22:57.039] iteration 10399: loss: 0.054205, loss_s1: 0.025316, loss_fp: 0.003157, loss_freq: 0.031186
[16:22:57.701] iteration 10400: loss: 0.060005, loss_s1: 0.041933, loss_fp: 0.006458, loss_freq: 0.026550
[16:23:01.002] iteration 10400 : mean_dice : 0.664328
[16:23:01.700] iteration 10401: loss: 0.044193, loss_s1: 0.020865, loss_fp: 0.000499, loss_freq: 0.015574
[16:23:02.369] iteration 10402: loss: 0.058861, loss_s1: 0.008896, loss_fp: 0.000787, loss_freq: 0.035929
[16:23:02.993] iteration 10403: loss: 0.053816, loss_s1: 0.025619, loss_fp: 0.002878, loss_freq: 0.015315
[16:23:03.614] iteration 10404: loss: 0.046026, loss_s1: 0.036594, loss_fp: 0.002675, loss_freq: 0.010340
[16:23:04.239] iteration 10405: loss: 0.074318, loss_s1: 0.058358, loss_fp: 0.013736, loss_freq: 0.021216
[16:23:04.864] iteration 10406: loss: 0.095005, loss_s1: 0.058040, loss_fp: 0.009913, loss_freq: 0.068656
[16:23:05.490] iteration 10407: loss: 0.079118, loss_s1: 0.070683, loss_fp: 0.001476, loss_freq: 0.041988
[16:23:06.121] iteration 10408: loss: 0.070256, loss_s1: 0.065914, loss_fp: 0.002118, loss_freq: 0.027035
[16:23:06.744] iteration 10409: loss: 0.074448, loss_s1: 0.028556, loss_fp: 0.001395, loss_freq: 0.025401
[16:23:07.368] iteration 10410: loss: 0.041487, loss_s1: 0.016893, loss_fp: 0.006305, loss_freq: 0.017064
[16:23:07.990] iteration 10411: loss: 0.100353, loss_s1: 0.034175, loss_fp: 0.004140, loss_freq: 0.041073
[16:23:08.613] iteration 10412: loss: 0.120382, loss_s1: 0.071045, loss_fp: 0.012812, loss_freq: 0.064515
[16:23:09.236] iteration 10413: loss: 0.166192, loss_s1: 0.133668, loss_fp: 0.003280, loss_freq: 0.112827
[16:23:09.858] iteration 10414: loss: 0.066249, loss_s1: 0.060403, loss_fp: 0.002164, loss_freq: 0.026349
[16:23:10.483] iteration 10415: loss: 0.065293, loss_s1: 0.014072, loss_fp: 0.001132, loss_freq: 0.018179
[16:23:11.108] iteration 10416: loss: 0.055492, loss_s1: 0.025141, loss_fp: 0.004036, loss_freq: 0.034973
[16:23:11.730] iteration 10417: loss: 0.111214, loss_s1: 0.095214, loss_fp: 0.002612, loss_freq: 0.053883
[16:23:12.355] iteration 10418: loss: 0.073997, loss_s1: 0.044860, loss_fp: 0.002182, loss_freq: 0.025644
[16:23:12.978] iteration 10419: loss: 0.041948, loss_s1: 0.024735, loss_fp: 0.002057, loss_freq: 0.007265
[16:23:13.602] iteration 10420: loss: 0.140613, loss_s1: 0.124645, loss_fp: 0.001514, loss_freq: 0.085713
[16:23:14.227] iteration 10421: loss: 0.061375, loss_s1: 0.053826, loss_fp: 0.002113, loss_freq: 0.025348
[16:23:14.853] iteration 10422: loss: 0.040594, loss_s1: 0.016201, loss_fp: 0.001503, loss_freq: 0.020380
[16:23:15.475] iteration 10423: loss: 0.079928, loss_s1: 0.040726, loss_fp: 0.002429, loss_freq: 0.056362
[16:23:16.104] iteration 10424: loss: 0.112814, loss_s1: 0.076507, loss_fp: 0.001775, loss_freq: 0.102029
[16:23:16.734] iteration 10425: loss: 0.066336, loss_s1: 0.038268, loss_fp: 0.004672, loss_freq: 0.047119
[16:23:17.358] iteration 10426: loss: 0.140482, loss_s1: 0.045945, loss_fp: 0.003530, loss_freq: 0.056311
[16:23:17.982] iteration 10427: loss: 0.102560, loss_s1: 0.079410, loss_fp: 0.038426, loss_freq: 0.014553
[16:23:18.607] iteration 10428: loss: 0.049557, loss_s1: 0.036837, loss_fp: 0.003741, loss_freq: 0.007952
[16:23:19.233] iteration 10429: loss: 0.115521, loss_s1: 0.038554, loss_fp: 0.001764, loss_freq: 0.037939
[16:23:19.859] iteration 10430: loss: 0.101152, loss_s1: 0.063655, loss_fp: 0.003699, loss_freq: 0.034839
[16:23:20.490] iteration 10431: loss: 0.069208, loss_s1: 0.055901, loss_fp: 0.004476, loss_freq: 0.019218
[16:23:21.112] iteration 10432: loss: 0.155568, loss_s1: 0.090628, loss_fp: 0.001229, loss_freq: 0.088934
[16:23:21.739] iteration 10433: loss: 0.077380, loss_s1: 0.068091, loss_fp: 0.003546, loss_freq: 0.036775
[16:23:22.363] iteration 10434: loss: 0.053098, loss_s1: 0.041322, loss_fp: 0.001576, loss_freq: 0.013525
[16:23:22.982] iteration 10435: loss: 0.115286, loss_s1: 0.091848, loss_fp: 0.006573, loss_freq: 0.092852
[16:23:23.611] iteration 10436: loss: 0.076585, loss_s1: 0.074102, loss_fp: 0.000428, loss_freq: 0.031441
[16:23:24.237] iteration 10437: loss: 0.090845, loss_s1: 0.051827, loss_fp: 0.004318, loss_freq: 0.033293
[16:23:24.863] iteration 10438: loss: 0.057649, loss_s1: 0.054040, loss_fp: 0.001839, loss_freq: 0.019679
[16:23:25.487] iteration 10439: loss: 0.056634, loss_s1: 0.038687, loss_fp: 0.003475, loss_freq: 0.028821
[16:23:26.110] iteration 10440: loss: 0.078063, loss_s1: 0.097628, loss_fp: 0.001487, loss_freq: 0.020923
[16:23:26.734] iteration 10441: loss: 0.066699, loss_s1: 0.033240, loss_fp: 0.000942, loss_freq: 0.033844
[16:23:27.359] iteration 10442: loss: 0.056829, loss_s1: 0.043066, loss_fp: 0.000804, loss_freq: 0.020878
[16:23:27.988] iteration 10443: loss: 0.093788, loss_s1: 0.097188, loss_fp: 0.003039, loss_freq: 0.038611
[16:23:28.613] iteration 10444: loss: 0.096237, loss_s1: 0.042861, loss_fp: 0.007130, loss_freq: 0.064674
[16:23:29.239] iteration 10445: loss: 0.078789, loss_s1: 0.063995, loss_fp: 0.004466, loss_freq: 0.048377
[16:23:29.863] iteration 10446: loss: 0.062149, loss_s1: 0.037899, loss_fp: 0.005287, loss_freq: 0.016374
[16:23:30.488] iteration 10447: loss: 0.091368, loss_s1: 0.020197, loss_fp: 0.002603, loss_freq: 0.049287
[16:23:31.114] iteration 10448: loss: 0.065316, loss_s1: 0.051532, loss_fp: 0.000768, loss_freq: 0.021633
[16:23:31.743] iteration 10449: loss: 0.063951, loss_s1: 0.055911, loss_fp: 0.006754, loss_freq: 0.013916
[16:23:32.366] iteration 10450: loss: 0.060077, loss_s1: 0.034081, loss_fp: 0.002066, loss_freq: 0.014461
[16:23:32.992] iteration 10451: loss: 0.099496, loss_s1: 0.086683, loss_fp: 0.001723, loss_freq: 0.065319
[16:23:33.616] iteration 10452: loss: 0.069659, loss_s1: 0.039451, loss_fp: 0.002794, loss_freq: 0.026436
[16:23:34.241] iteration 10453: loss: 0.051450, loss_s1: 0.034834, loss_fp: 0.002546, loss_freq: 0.011635
[16:23:34.881] iteration 10454: loss: 0.101657, loss_s1: 0.118534, loss_fp: 0.003724, loss_freq: 0.028502
[16:23:35.507] iteration 10455: loss: 0.075330, loss_s1: 0.031061, loss_fp: 0.007167, loss_freq: 0.048875
[16:23:36.132] iteration 10456: loss: 0.084629, loss_s1: 0.082069, loss_fp: 0.001436, loss_freq: 0.046678
[16:23:36.758] iteration 10457: loss: 0.059778, loss_s1: 0.033918, loss_fp: 0.003484, loss_freq: 0.023409
[16:23:37.383] iteration 10458: loss: 0.093253, loss_s1: 0.087439, loss_fp: 0.000738, loss_freq: 0.026460
[16:23:38.012] iteration 10459: loss: 0.041125, loss_s1: 0.021326, loss_fp: 0.001903, loss_freq: 0.009306
[16:23:38.637] iteration 10460: loss: 0.056713, loss_s1: 0.028793, loss_fp: 0.001588, loss_freq: 0.021854
[16:23:39.263] iteration 10461: loss: 0.035838, loss_s1: 0.007975, loss_fp: 0.000313, loss_freq: 0.008678
[16:23:39.887] iteration 10462: loss: 0.059208, loss_s1: 0.029130, loss_fp: 0.000968, loss_freq: 0.030737
[16:23:40.528] iteration 10463: loss: 0.097483, loss_s1: 0.093727, loss_fp: 0.008256, loss_freq: 0.034112
[16:23:41.192] iteration 10464: loss: 0.036801, loss_s1: 0.012430, loss_fp: 0.001340, loss_freq: 0.010664
[16:23:41.854] iteration 10465: loss: 0.069924, loss_s1: 0.035403, loss_fp: 0.001330, loss_freq: 0.019157
[16:23:42.842] iteration 10466: loss: 0.073200, loss_s1: 0.047339, loss_fp: 0.000376, loss_freq: 0.035378
[16:23:43.484] iteration 10467: loss: 0.080875, loss_s1: 0.073812, loss_fp: 0.007532, loss_freq: 0.030052
[16:23:44.125] iteration 10468: loss: 0.092736, loss_s1: 0.107945, loss_fp: 0.005273, loss_freq: 0.018684
[16:23:44.769] iteration 10469: loss: 0.063184, loss_s1: 0.039230, loss_fp: 0.001268, loss_freq: 0.030844
[16:23:45.416] iteration 10470: loss: 0.048384, loss_s1: 0.034148, loss_fp: 0.000478, loss_freq: 0.008667
[16:23:46.065] iteration 10471: loss: 0.159405, loss_s1: 0.109808, loss_fp: 0.019634, loss_freq: 0.082079
[16:23:46.708] iteration 10472: loss: 0.053358, loss_s1: 0.043731, loss_fp: 0.000576, loss_freq: 0.019643
[16:23:47.352] iteration 10473: loss: 0.069036, loss_s1: 0.048988, loss_fp: 0.005376, loss_freq: 0.037571
[16:23:48.000] iteration 10474: loss: 0.073036, loss_s1: 0.053568, loss_fp: 0.001971, loss_freq: 0.033815
[16:23:48.643] iteration 10475: loss: 0.074250, loss_s1: 0.044807, loss_fp: 0.010136, loss_freq: 0.027768
[16:23:49.287] iteration 10476: loss: 0.047758, loss_s1: 0.012486, loss_fp: 0.000682, loss_freq: 0.015001
[16:23:49.927] iteration 10477: loss: 0.059040, loss_s1: 0.026880, loss_fp: 0.000316, loss_freq: 0.034658
[16:23:50.568] iteration 10478: loss: 0.099863, loss_s1: 0.086659, loss_fp: 0.008229, loss_freq: 0.062026
[16:23:51.245] iteration 10479: loss: 0.080345, loss_s1: 0.034530, loss_fp: 0.006094, loss_freq: 0.061293
[16:23:51.895] iteration 10480: loss: 0.064752, loss_s1: 0.075480, loss_fp: 0.008534, loss_freq: 0.009465
[16:23:52.539] iteration 10481: loss: 0.100700, loss_s1: 0.085361, loss_fp: 0.009579, loss_freq: 0.054969
[16:23:53.179] iteration 10482: loss: 0.091475, loss_s1: 0.061296, loss_fp: 0.005416, loss_freq: 0.017446
[16:23:53.820] iteration 10483: loss: 0.074845, loss_s1: 0.064046, loss_fp: 0.003874, loss_freq: 0.024971
[16:23:54.458] iteration 10484: loss: 0.052895, loss_s1: 0.020711, loss_fp: 0.001547, loss_freq: 0.022985
[16:23:55.098] iteration 10485: loss: 0.091555, loss_s1: 0.061922, loss_fp: 0.003687, loss_freq: 0.012208
[16:23:55.742] iteration 10486: loss: 0.037587, loss_s1: 0.024266, loss_fp: 0.000423, loss_freq: 0.002906
[16:23:56.383] iteration 10487: loss: 0.071081, loss_s1: 0.047936, loss_fp: 0.000778, loss_freq: 0.015850
[16:23:57.023] iteration 10488: loss: 0.081800, loss_s1: 0.064841, loss_fp: 0.001179, loss_freq: 0.020769
[16:23:57.663] iteration 10489: loss: 0.111336, loss_s1: 0.113488, loss_fp: 0.003252, loss_freq: 0.058459
[16:23:58.306] iteration 10490: loss: 0.043195, loss_s1: 0.024234, loss_fp: 0.000426, loss_freq: 0.019765
[16:23:58.947] iteration 10491: loss: 0.078855, loss_s1: 0.056040, loss_fp: 0.001111, loss_freq: 0.033400
[16:23:59.585] iteration 10492: loss: 0.061456, loss_s1: 0.044938, loss_fp: 0.002906, loss_freq: 0.014768
[16:24:00.228] iteration 10493: loss: 0.121732, loss_s1: 0.071204, loss_fp: 0.001611, loss_freq: 0.073711
[16:24:00.868] iteration 10494: loss: 0.098277, loss_s1: 0.049692, loss_fp: 0.002298, loss_freq: 0.043059
[16:24:01.508] iteration 10495: loss: 0.047507, loss_s1: 0.028172, loss_fp: 0.001276, loss_freq: 0.010228
[16:24:02.152] iteration 10496: loss: 0.078271, loss_s1: 0.063759, loss_fp: 0.012288, loss_freq: 0.011785
[16:24:02.790] iteration 10497: loss: 0.078357, loss_s1: 0.035767, loss_fp: 0.006103, loss_freq: 0.040819
[16:24:03.431] iteration 10498: loss: 0.102466, loss_s1: 0.091032, loss_fp: 0.001953, loss_freq: 0.053165
[16:24:04.071] iteration 10499: loss: 0.075690, loss_s1: 0.048065, loss_fp: 0.004661, loss_freq: 0.046427
[16:24:04.709] iteration 10500: loss: 0.092187, loss_s1: 0.042923, loss_fp: 0.001419, loss_freq: 0.029847
[16:24:05.347] iteration 10501: loss: 0.098550, loss_s1: 0.100642, loss_fp: 0.009013, loss_freq: 0.050279
[16:24:05.986] iteration 10502: loss: 0.093256, loss_s1: 0.081780, loss_fp: 0.001221, loss_freq: 0.051374
[16:24:06.625] iteration 10503: loss: 0.066094, loss_s1: 0.041247, loss_fp: 0.003117, loss_freq: 0.029902
[16:24:07.261] iteration 10504: loss: 0.096079, loss_s1: 0.061964, loss_fp: 0.000875, loss_freq: 0.060294
[16:24:07.899] iteration 10505: loss: 0.061044, loss_s1: 0.039308, loss_fp: 0.001636, loss_freq: 0.027634
[16:24:08.537] iteration 10506: loss: 0.069428, loss_s1: 0.034790, loss_fp: 0.000670, loss_freq: 0.045009
[16:24:09.177] iteration 10507: loss: 0.121159, loss_s1: 0.125041, loss_fp: 0.014600, loss_freq: 0.056331
[16:24:09.815] iteration 10508: loss: 0.095916, loss_s1: 0.057672, loss_fp: 0.009552, loss_freq: 0.067787
[16:24:10.456] iteration 10509: loss: 0.074841, loss_s1: 0.065548, loss_fp: 0.013622, loss_freq: 0.018530
[16:24:11.106] iteration 10510: loss: 0.067446, loss_s1: 0.049282, loss_fp: 0.002745, loss_freq: 0.031020
[16:24:11.749] iteration 10511: loss: 0.070838, loss_s1: 0.082382, loss_fp: 0.002787, loss_freq: 0.007878
[16:24:12.392] iteration 10512: loss: 0.035211, loss_s1: 0.019086, loss_fp: 0.000522, loss_freq: 0.005480
[16:24:13.068] iteration 10513: loss: 0.052939, loss_s1: 0.033550, loss_fp: 0.007774, loss_freq: 0.027438
[16:24:13.691] iteration 10514: loss: 0.068219, loss_s1: 0.054089, loss_fp: 0.001559, loss_freq: 0.019408
[16:24:14.317] iteration 10515: loss: 0.101150, loss_s1: 0.081275, loss_fp: 0.002863, loss_freq: 0.071414
[16:24:14.942] iteration 10516: loss: 0.064439, loss_s1: 0.041993, loss_fp: 0.004598, loss_freq: 0.026093
[16:24:15.611] iteration 10517: loss: 0.059702, loss_s1: 0.047968, loss_fp: 0.001780, loss_freq: 0.020713
[16:24:16.292] iteration 10518: loss: 0.073397, loss_s1: 0.041424, loss_fp: 0.007260, loss_freq: 0.034206
[16:24:16.950] iteration 10519: loss: 0.076271, loss_s1: 0.042261, loss_fp: 0.017449, loss_freq: 0.027824
[16:24:17.609] iteration 10520: loss: 0.084125, loss_s1: 0.044657, loss_fp: 0.002909, loss_freq: 0.015902
[16:24:18.266] iteration 10521: loss: 0.121394, loss_s1: 0.120027, loss_fp: 0.002048, loss_freq: 0.043160
[16:24:18.927] iteration 10522: loss: 0.048971, loss_s1: 0.017372, loss_fp: 0.003920, loss_freq: 0.017758
[16:24:19.557] iteration 10523: loss: 0.076594, loss_s1: 0.028150, loss_fp: 0.006031, loss_freq: 0.044584
[16:24:20.187] iteration 10524: loss: 0.038661, loss_s1: 0.015532, loss_fp: 0.001571, loss_freq: 0.010295
[16:24:20.812] iteration 10525: loss: 0.058079, loss_s1: 0.042706, loss_fp: 0.001015, loss_freq: 0.022389
[16:24:21.438] iteration 10526: loss: 0.067482, loss_s1: 0.048002, loss_fp: 0.004153, loss_freq: 0.046493
[16:24:22.063] iteration 10527: loss: 0.056392, loss_s1: 0.028076, loss_fp: 0.001662, loss_freq: 0.023918
[16:24:22.693] iteration 10528: loss: 0.059240, loss_s1: 0.048140, loss_fp: 0.001200, loss_freq: 0.022789
[16:24:23.320] iteration 10529: loss: 0.058421, loss_s1: 0.046265, loss_fp: 0.002250, loss_freq: 0.023806
[16:24:23.950] iteration 10530: loss: 0.053151, loss_s1: 0.036607, loss_fp: 0.007928, loss_freq: 0.026498
[16:24:24.576] iteration 10531: loss: 0.085601, loss_s1: 0.055723, loss_fp: 0.002605, loss_freq: 0.069832
[16:24:25.207] iteration 10532: loss: 0.061720, loss_s1: 0.027977, loss_fp: 0.000906, loss_freq: 0.030145
[16:24:25.834] iteration 10533: loss: 0.060873, loss_s1: 0.055845, loss_fp: 0.002912, loss_freq: 0.021012
[16:24:26.469] iteration 10534: loss: 0.046321, loss_s1: 0.014678, loss_fp: 0.000567, loss_freq: 0.020042
[16:24:27.097] iteration 10535: loss: 0.090516, loss_s1: 0.035790, loss_fp: 0.002606, loss_freq: 0.036199
[16:24:27.721] iteration 10536: loss: 0.110362, loss_s1: 0.084339, loss_fp: 0.008238, loss_freq: 0.080781
[16:24:28.348] iteration 10537: loss: 0.065168, loss_s1: 0.032297, loss_fp: 0.001121, loss_freq: 0.039662
[16:24:28.974] iteration 10538: loss: 0.107476, loss_s1: 0.058082, loss_fp: 0.002794, loss_freq: 0.065059
[16:24:29.600] iteration 10539: loss: 0.066105, loss_s1: 0.045568, loss_fp: 0.002611, loss_freq: 0.024192
[16:24:30.232] iteration 10540: loss: 0.087434, loss_s1: 0.074656, loss_fp: 0.004956, loss_freq: 0.037621
[16:24:30.860] iteration 10541: loss: 0.087958, loss_s1: 0.072572, loss_fp: 0.003616, loss_freq: 0.020371
[16:24:31.488] iteration 10542: loss: 0.089755, loss_s1: 0.069585, loss_fp: 0.008142, loss_freq: 0.039217
[16:24:32.114] iteration 10543: loss: 0.058284, loss_s1: 0.049640, loss_fp: 0.000830, loss_freq: 0.009878
[16:24:32.738] iteration 10544: loss: 0.039613, loss_s1: 0.015266, loss_fp: 0.006718, loss_freq: 0.003139
[16:24:33.366] iteration 10545: loss: 0.069527, loss_s1: 0.041121, loss_fp: 0.000350, loss_freq: 0.040005
[16:24:33.997] iteration 10546: loss: 0.083181, loss_s1: 0.071397, loss_fp: 0.005054, loss_freq: 0.043504
[16:24:34.630] iteration 10547: loss: 0.044632, loss_s1: 0.026118, loss_fp: 0.002778, loss_freq: 0.015371
[16:24:35.562] iteration 10548: loss: 0.129801, loss_s1: 0.107630, loss_fp: 0.003326, loss_freq: 0.097101
[16:24:36.375] iteration 10549: loss: 0.047126, loss_s1: 0.021926, loss_fp: 0.003997, loss_freq: 0.015200
[16:24:37.046] iteration 10550: loss: 0.068742, loss_s1: 0.061547, loss_fp: 0.001040, loss_freq: 0.034417
[16:24:37.672] iteration 10551: loss: 0.046255, loss_s1: 0.023679, loss_fp: 0.001390, loss_freq: 0.024958
[16:24:38.300] iteration 10552: loss: 0.086195, loss_s1: 0.095846, loss_fp: 0.000601, loss_freq: 0.016819
[16:24:38.928] iteration 10553: loss: 0.056677, loss_s1: 0.038586, loss_fp: 0.002503, loss_freq: 0.012755
[16:24:39.561] iteration 10554: loss: 0.099048, loss_s1: 0.042052, loss_fp: 0.019143, loss_freq: 0.057234
[16:24:40.190] iteration 10555: loss: 0.122274, loss_s1: 0.069317, loss_fp: 0.019042, loss_freq: 0.056201
[16:24:40.820] iteration 10556: loss: 0.090694, loss_s1: 0.065618, loss_fp: 0.007108, loss_freq: 0.022068
[16:24:41.449] iteration 10557: loss: 0.089823, loss_s1: 0.071126, loss_fp: 0.002226, loss_freq: 0.041656
[16:24:42.078] iteration 10558: loss: 0.116698, loss_s1: 0.054224, loss_fp: 0.002617, loss_freq: 0.027733
[16:24:42.707] iteration 10559: loss: 0.067342, loss_s1: 0.040056, loss_fp: 0.003860, loss_freq: 0.017281
[16:24:43.334] iteration 10560: loss: 0.065050, loss_s1: 0.034203, loss_fp: 0.000527, loss_freq: 0.033726
[16:24:43.965] iteration 10561: loss: 0.064501, loss_s1: 0.051056, loss_fp: 0.000950, loss_freq: 0.036441
[16:24:44.590] iteration 10562: loss: 0.088604, loss_s1: 0.052392, loss_fp: 0.001701, loss_freq: 0.020728
[16:24:45.219] iteration 10563: loss: 0.053082, loss_s1: 0.018463, loss_fp: 0.000523, loss_freq: 0.020357
[16:24:45.847] iteration 10564: loss: 0.064601, loss_s1: 0.051358, loss_fp: 0.007047, loss_freq: 0.029790
[16:24:46.473] iteration 10565: loss: 0.085845, loss_s1: 0.044019, loss_fp: 0.005475, loss_freq: 0.016784
[16:24:47.144] iteration 10566: loss: 0.081538, loss_s1: 0.059954, loss_fp: 0.006901, loss_freq: 0.043081
[16:24:47.768] iteration 10567: loss: 0.102998, loss_s1: 0.059805, loss_fp: 0.015600, loss_freq: 0.056468
[16:24:48.394] iteration 10568: loss: 0.100937, loss_s1: 0.098237, loss_fp: 0.002223, loss_freq: 0.034520
[16:24:49.020] iteration 10569: loss: 0.075365, loss_s1: 0.070395, loss_fp: 0.003651, loss_freq: 0.021095
[16:24:49.643] iteration 10570: loss: 0.098957, loss_s1: 0.042981, loss_fp: 0.013724, loss_freq: 0.050347
[16:24:50.270] iteration 10571: loss: 0.093919, loss_s1: 0.052923, loss_fp: 0.005250, loss_freq: 0.049142
[16:24:50.897] iteration 10572: loss: 0.059146, loss_s1: 0.036891, loss_fp: 0.002707, loss_freq: 0.024191
[16:24:51.546] iteration 10573: loss: 0.084346, loss_s1: 0.046277, loss_fp: 0.004207, loss_freq: 0.037083
[16:24:52.177] iteration 10574: loss: 0.169774, loss_s1: 0.137238, loss_fp: 0.001919, loss_freq: 0.124040
[16:24:52.806] iteration 10575: loss: 0.056062, loss_s1: 0.025494, loss_fp: 0.003089, loss_freq: 0.036768
[16:24:53.440] iteration 10576: loss: 0.088240, loss_s1: 0.057278, loss_fp: 0.004558, loss_freq: 0.037083
[16:24:54.071] iteration 10577: loss: 0.082822, loss_s1: 0.044906, loss_fp: 0.002737, loss_freq: 0.036907
[16:24:54.701] iteration 10578: loss: 0.123217, loss_s1: 0.074992, loss_fp: 0.019909, loss_freq: 0.082603
[16:24:55.332] iteration 10579: loss: 0.079570, loss_s1: 0.063654, loss_fp: 0.003590, loss_freq: 0.035356
[16:24:56.049] iteration 10580: loss: 0.047471, loss_s1: 0.022256, loss_fp: 0.001243, loss_freq: 0.018132
[16:24:56.715] iteration 10581: loss: 0.096820, loss_s1: 0.057457, loss_fp: 0.007340, loss_freq: 0.038614
[16:24:57.382] iteration 10582: loss: 0.067205, loss_s1: 0.037329, loss_fp: 0.008616, loss_freq: 0.031200
[16:24:58.045] iteration 10583: loss: 0.064095, loss_s1: 0.053205, loss_fp: 0.001687, loss_freq: 0.020510
[16:24:58.695] iteration 10584: loss: 0.088441, loss_s1: 0.041900, loss_fp: 0.003203, loss_freq: 0.047177
[16:24:59.347] iteration 10585: loss: 0.114831, loss_s1: 0.085124, loss_fp: 0.002097, loss_freq: 0.086448
[16:24:59.973] iteration 10586: loss: 0.097565, loss_s1: 0.047571, loss_fp: 0.001449, loss_freq: 0.092440
[16:25:00.604] iteration 10587: loss: 0.151091, loss_s1: 0.036195, loss_fp: 0.000722, loss_freq: 0.026225
[16:25:01.240] iteration 10588: loss: 0.088075, loss_s1: 0.063214, loss_fp: 0.000621, loss_freq: 0.059007
[16:25:01.866] iteration 10589: loss: 0.051876, loss_s1: 0.023354, loss_fp: 0.001152, loss_freq: 0.015633
[16:25:02.495] iteration 10590: loss: 0.111602, loss_s1: 0.061887, loss_fp: 0.001488, loss_freq: 0.081469
[16:25:03.125] iteration 10591: loss: 0.067670, loss_s1: 0.031732, loss_fp: 0.000805, loss_freq: 0.026462
[16:25:03.751] iteration 10592: loss: 0.052496, loss_s1: 0.017271, loss_fp: 0.005363, loss_freq: 0.014712
[16:25:04.378] iteration 10593: loss: 0.120678, loss_s1: 0.096700, loss_fp: 0.002774, loss_freq: 0.023819
[16:25:05.008] iteration 10594: loss: 0.067945, loss_s1: 0.060193, loss_fp: 0.000689, loss_freq: 0.024263
[16:25:05.635] iteration 10595: loss: 0.063351, loss_s1: 0.036442, loss_fp: 0.001958, loss_freq: 0.004430
[16:25:06.261] iteration 10596: loss: 0.103113, loss_s1: 0.059940, loss_fp: 0.004725, loss_freq: 0.087995
[16:25:06.898] iteration 10597: loss: 0.106963, loss_s1: 0.095178, loss_fp: 0.001198, loss_freq: 0.061410
[16:25:07.539] iteration 10598: loss: 0.080940, loss_s1: 0.046313, loss_fp: 0.009487, loss_freq: 0.032217
[16:25:08.174] iteration 10599: loss: 0.081862, loss_s1: 0.032475, loss_fp: 0.000623, loss_freq: 0.045014
[16:25:08.807] iteration 10600: loss: 0.098611, loss_s1: 0.064528, loss_fp: 0.001953, loss_freq: 0.057235
[16:25:12.148] iteration 10600 : mean_dice : 0.698703
[16:25:12.828] iteration 10601: loss: 0.051917, loss_s1: 0.052651, loss_fp: 0.001692, loss_freq: 0.013898
[16:25:13.456] iteration 10602: loss: 0.065902, loss_s1: 0.018568, loss_fp: 0.004769, loss_freq: 0.040079
[16:25:14.087] iteration 10603: loss: 0.069010, loss_s1: 0.027371, loss_fp: 0.004782, loss_freq: 0.031981
[16:25:14.712] iteration 10604: loss: 0.062333, loss_s1: 0.044590, loss_fp: 0.005120, loss_freq: 0.026939
[16:25:15.343] iteration 10605: loss: 0.119046, loss_s1: 0.070723, loss_fp: 0.013593, loss_freq: 0.046430
[16:25:15.969] iteration 10606: loss: 0.098687, loss_s1: 0.114417, loss_fp: 0.001410, loss_freq: 0.030540
[16:25:16.600] iteration 10607: loss: 0.090697, loss_s1: 0.050055, loss_fp: 0.003830, loss_freq: 0.027938
[16:25:17.228] iteration 10608: loss: 0.110462, loss_s1: 0.075458, loss_fp: 0.000793, loss_freq: 0.066545
[16:25:17.855] iteration 10609: loss: 0.093770, loss_s1: 0.055538, loss_fp: 0.007805, loss_freq: 0.031022
[16:25:18.483] iteration 10610: loss: 0.065110, loss_s1: 0.036669, loss_fp: 0.001776, loss_freq: 0.010797
[16:25:19.113] iteration 10611: loss: 0.079718, loss_s1: 0.049666, loss_fp: 0.005094, loss_freq: 0.023118
[16:25:19.744] iteration 10612: loss: 0.112567, loss_s1: 0.071811, loss_fp: 0.022984, loss_freq: 0.083325
[16:25:20.371] iteration 10613: loss: 0.065958, loss_s1: 0.047337, loss_fp: 0.001428, loss_freq: 0.008208
[16:25:20.997] iteration 10614: loss: 0.068125, loss_s1: 0.038206, loss_fp: 0.005903, loss_freq: 0.043208
[16:25:21.623] iteration 10615: loss: 0.090701, loss_s1: 0.052699, loss_fp: 0.003928, loss_freq: 0.064470
[16:25:22.249] iteration 10616: loss: 0.095572, loss_s1: 0.054798, loss_fp: 0.003323, loss_freq: 0.038868
[16:25:22.876] iteration 10617: loss: 0.108292, loss_s1: 0.095327, loss_fp: 0.003020, loss_freq: 0.075630
[16:25:23.501] iteration 10618: loss: 0.053787, loss_s1: 0.051915, loss_fp: 0.001454, loss_freq: 0.017587
[16:25:24.128] iteration 10619: loss: 0.088267, loss_s1: 0.062011, loss_fp: 0.003303, loss_freq: 0.032471
[16:25:24.768] iteration 10620: loss: 0.040198, loss_s1: 0.018761, loss_fp: 0.000682, loss_freq: 0.011424
[16:25:25.435] iteration 10621: loss: 0.064694, loss_s1: 0.062951, loss_fp: 0.000799, loss_freq: 0.019875
[16:25:26.099] iteration 10622: loss: 0.054816, loss_s1: 0.022486, loss_fp: 0.000498, loss_freq: 0.022746
[16:25:26.772] iteration 10623: loss: 0.131725, loss_s1: 0.117157, loss_fp: 0.004270, loss_freq: 0.030541
[16:25:27.406] iteration 10624: loss: 0.083545, loss_s1: 0.046106, loss_fp: 0.009667, loss_freq: 0.051633
[16:25:28.033] iteration 10625: loss: 0.124840, loss_s1: 0.043113, loss_fp: 0.002614, loss_freq: 0.014908
[16:25:28.659] iteration 10626: loss: 0.108007, loss_s1: 0.111854, loss_fp: 0.000539, loss_freq: 0.043841
[16:25:29.639] iteration 10627: loss: 0.085108, loss_s1: 0.033396, loss_fp: 0.000287, loss_freq: 0.023447
[16:25:30.301] iteration 10628: loss: 0.067856, loss_s1: 0.034837, loss_fp: 0.001606, loss_freq: 0.011880
[16:25:30.965] iteration 10629: loss: 0.052209, loss_s1: 0.023322, loss_fp: 0.001093, loss_freq: 0.020390
[16:25:31.629] iteration 10630: loss: 0.055200, loss_s1: 0.025833, loss_fp: 0.001705, loss_freq: 0.014638
[16:25:32.261] iteration 10631: loss: 0.086758, loss_s1: 0.092127, loss_fp: 0.000853, loss_freq: 0.014092
[16:25:32.897] iteration 10632: loss: 0.145980, loss_s1: 0.096914, loss_fp: 0.002444, loss_freq: 0.052631
[16:25:33.523] iteration 10633: loss: 0.041516, loss_s1: 0.033639, loss_fp: 0.000667, loss_freq: 0.014809
[16:25:34.148] iteration 10634: loss: 0.055044, loss_s1: 0.040223, loss_fp: 0.006176, loss_freq: 0.027108
[16:25:34.776] iteration 10635: loss: 0.071975, loss_s1: 0.047989, loss_fp: 0.005807, loss_freq: 0.034391
[16:25:35.401] iteration 10636: loss: 0.060811, loss_s1: 0.036886, loss_fp: 0.001499, loss_freq: 0.021284
[16:25:36.027] iteration 10637: loss: 0.036458, loss_s1: 0.008714, loss_fp: 0.000520, loss_freq: 0.006883
[16:25:36.651] iteration 10638: loss: 0.086594, loss_s1: 0.051483, loss_fp: 0.007475, loss_freq: 0.057986
[16:25:37.282] iteration 10639: loss: 0.075077, loss_s1: 0.047140, loss_fp: 0.006601, loss_freq: 0.053742
[16:25:37.908] iteration 10640: loss: 0.090467, loss_s1: 0.073639, loss_fp: 0.000679, loss_freq: 0.055947
[16:25:38.538] iteration 10641: loss: 0.072287, loss_s1: 0.053121, loss_fp: 0.000467, loss_freq: 0.032334
[16:25:39.170] iteration 10642: loss: 0.100697, loss_s1: 0.020572, loss_fp: 0.040370, loss_freq: 0.070294
[16:25:39.798] iteration 10643: loss: 0.071857, loss_s1: 0.050653, loss_fp: 0.001704, loss_freq: 0.033381
[16:25:40.424] iteration 10644: loss: 0.086316, loss_s1: 0.046816, loss_fp: 0.002867, loss_freq: 0.035695
[16:25:41.045] iteration 10645: loss: 0.070521, loss_s1: 0.031660, loss_fp: 0.001351, loss_freq: 0.037698
[16:25:41.667] iteration 10646: loss: 0.062530, loss_s1: 0.046761, loss_fp: 0.002163, loss_freq: 0.017608
[16:25:42.291] iteration 10647: loss: 0.058882, loss_s1: 0.044419, loss_fp: 0.002479, loss_freq: 0.007168
[16:25:42.916] iteration 10648: loss: 0.053297, loss_s1: 0.025524, loss_fp: 0.002285, loss_freq: 0.020094
[16:25:43.540] iteration 10649: loss: 0.068162, loss_s1: 0.026443, loss_fp: 0.003159, loss_freq: 0.034241
[16:25:44.160] iteration 10650: loss: 0.216818, loss_s1: 0.135426, loss_fp: 0.001683, loss_freq: 0.234118
[16:25:44.782] iteration 10651: loss: 0.058401, loss_s1: 0.023318, loss_fp: 0.004348, loss_freq: 0.045847
[16:25:45.406] iteration 10652: loss: 0.055851, loss_s1: 0.033760, loss_fp: 0.002534, loss_freq: 0.024098
[16:25:46.032] iteration 10653: loss: 0.062969, loss_s1: 0.069265, loss_fp: 0.000969, loss_freq: 0.010097
[16:25:46.656] iteration 10654: loss: 0.086258, loss_s1: 0.046940, loss_fp: 0.002097, loss_freq: 0.038623
[16:25:47.284] iteration 10655: loss: 0.061657, loss_s1: 0.024119, loss_fp: 0.002868, loss_freq: 0.024811
[16:25:47.909] iteration 10656: loss: 0.056221, loss_s1: 0.059279, loss_fp: 0.001365, loss_freq: 0.007116
[16:25:48.535] iteration 10657: loss: 0.070169, loss_s1: 0.062313, loss_fp: 0.006743, loss_freq: 0.024243
[16:25:49.163] iteration 10658: loss: 0.113917, loss_s1: 0.067782, loss_fp: 0.001808, loss_freq: 0.034841
[16:25:49.790] iteration 10659: loss: 0.050100, loss_s1: 0.033572, loss_fp: 0.001419, loss_freq: 0.022996
[16:25:50.419] iteration 10660: loss: 0.054700, loss_s1: 0.026461, loss_fp: 0.000616, loss_freq: 0.021198
[16:25:51.051] iteration 10661: loss: 0.080131, loss_s1: 0.036420, loss_fp: 0.002964, loss_freq: 0.043935
[16:25:51.679] iteration 10662: loss: 0.097691, loss_s1: 0.071370, loss_fp: 0.002166, loss_freq: 0.031459
[16:25:52.307] iteration 10663: loss: 0.091030, loss_s1: 0.058473, loss_fp: 0.005653, loss_freq: 0.043213
[16:25:52.933] iteration 10664: loss: 0.078414, loss_s1: 0.085418, loss_fp: 0.001032, loss_freq: 0.022262
[16:25:53.559] iteration 10665: loss: 0.132801, loss_s1: 0.120708, loss_fp: 0.002042, loss_freq: 0.083282
[16:25:54.189] iteration 10666: loss: 0.064758, loss_s1: 0.031992, loss_fp: 0.003710, loss_freq: 0.041621
[16:25:54.815] iteration 10667: loss: 0.090436, loss_s1: 0.042602, loss_fp: 0.009533, loss_freq: 0.033005
[16:25:55.474] iteration 10668: loss: 0.116701, loss_s1: 0.120914, loss_fp: 0.003576, loss_freq: 0.066382
[16:25:56.131] iteration 10669: loss: 0.113478, loss_s1: 0.120415, loss_fp: 0.014188, loss_freq: 0.047837
[16:25:56.764] iteration 10670: loss: 0.065431, loss_s1: 0.049600, loss_fp: 0.001319, loss_freq: 0.026608
[16:25:57.391] iteration 10671: loss: 0.099578, loss_s1: 0.075649, loss_fp: 0.004974, loss_freq: 0.042215
[16:25:58.016] iteration 10672: loss: 0.074135, loss_s1: 0.051009, loss_fp: 0.000386, loss_freq: 0.020952
[16:25:58.638] iteration 10673: loss: 0.041664, loss_s1: 0.020735, loss_fp: 0.001057, loss_freq: 0.013270
[16:25:59.261] iteration 10674: loss: 0.095077, loss_s1: 0.114850, loss_fp: 0.004187, loss_freq: 0.030148
[16:25:59.885] iteration 10675: loss: 0.083682, loss_s1: 0.045951, loss_fp: 0.004297, loss_freq: 0.024794
[16:26:00.509] iteration 10676: loss: 0.091491, loss_s1: 0.089376, loss_fp: 0.004760, loss_freq: 0.041126
[16:26:01.134] iteration 10677: loss: 0.078258, loss_s1: 0.071348, loss_fp: 0.004117, loss_freq: 0.031287
[16:26:01.758] iteration 10678: loss: 0.071903, loss_s1: 0.027333, loss_fp: 0.020841, loss_freq: 0.028584
[16:26:02.381] iteration 10679: loss: 0.045636, loss_s1: 0.026513, loss_fp: 0.000747, loss_freq: 0.015415
[16:26:03.001] iteration 10680: loss: 0.055373, loss_s1: 0.032680, loss_fp: 0.006456, loss_freq: 0.016509
[16:26:03.632] iteration 10681: loss: 0.050243, loss_s1: 0.023139, loss_fp: 0.000789, loss_freq: 0.020146
[16:26:04.254] iteration 10682: loss: 0.117532, loss_s1: 0.138887, loss_fp: 0.002250, loss_freq: 0.038080
[16:26:04.876] iteration 10683: loss: 0.048540, loss_s1: 0.023855, loss_fp: 0.002641, loss_freq: 0.015863
[16:26:05.498] iteration 10684: loss: 0.100860, loss_s1: 0.060597, loss_fp: 0.001169, loss_freq: 0.049624
[16:26:06.122] iteration 10685: loss: 0.031631, loss_s1: 0.005543, loss_fp: 0.001121, loss_freq: 0.005194
[16:26:06.746] iteration 10686: loss: 0.054597, loss_s1: 0.018571, loss_fp: 0.003912, loss_freq: 0.022742
[16:26:07.374] iteration 10687: loss: 0.044699, loss_s1: 0.019149, loss_fp: 0.000825, loss_freq: 0.023285
[16:26:07.994] iteration 10688: loss: 0.071281, loss_s1: 0.064936, loss_fp: 0.002080, loss_freq: 0.004671
[16:26:08.616] iteration 10689: loss: 0.060776, loss_s1: 0.038690, loss_fp: 0.002997, loss_freq: 0.020529
[16:26:09.245] iteration 10690: loss: 0.066762, loss_s1: 0.041037, loss_fp: 0.004725, loss_freq: 0.033268
[16:26:09.931] iteration 10691: loss: 0.055615, loss_s1: 0.033362, loss_fp: 0.001917, loss_freq: 0.015782
[16:26:10.572] iteration 10692: loss: 0.074038, loss_s1: 0.027543, loss_fp: 0.005690, loss_freq: 0.055894
[16:26:11.198] iteration 10693: loss: 0.092334, loss_s1: 0.037594, loss_fp: 0.003537, loss_freq: 0.050731
[16:26:11.823] iteration 10694: loss: 0.051169, loss_s1: 0.036302, loss_fp: 0.000732, loss_freq: 0.029921
[16:26:12.448] iteration 10695: loss: 0.059367, loss_s1: 0.044775, loss_fp: 0.002588, loss_freq: 0.025607
[16:26:13.071] iteration 10696: loss: 0.099455, loss_s1: 0.040251, loss_fp: 0.003521, loss_freq: 0.064969
[16:26:13.693] iteration 10697: loss: 0.088877, loss_s1: 0.057268, loss_fp: 0.004151, loss_freq: 0.070286
[16:26:14.317] iteration 10698: loss: 0.111214, loss_s1: 0.110769, loss_fp: 0.002058, loss_freq: 0.062715
[16:26:14.945] iteration 10699: loss: 0.088039, loss_s1: 0.049505, loss_fp: 0.002526, loss_freq: 0.045335
[16:26:15.569] iteration 10700: loss: 0.067324, loss_s1: 0.048492, loss_fp: 0.003308, loss_freq: 0.010572
[16:26:16.195] iteration 10701: loss: 0.109318, loss_s1: 0.103364, loss_fp: 0.015797, loss_freq: 0.032149
[16:26:16.819] iteration 10702: loss: 0.092184, loss_s1: 0.076622, loss_fp: 0.001878, loss_freq: 0.022883
[16:26:17.479] iteration 10703: loss: 0.066446, loss_s1: 0.037447, loss_fp: 0.008693, loss_freq: 0.039232
[16:26:18.136] iteration 10704: loss: 0.062326, loss_s1: 0.053237, loss_fp: 0.003088, loss_freq: 0.026019
[16:26:18.794] iteration 10705: loss: 0.044357, loss_s1: 0.035495, loss_fp: 0.001202, loss_freq: 0.010974
[16:26:19.441] iteration 10706: loss: 0.057082, loss_s1: 0.052513, loss_fp: 0.001797, loss_freq: 0.013229
[16:26:20.062] iteration 10707: loss: 0.059865, loss_s1: 0.022310, loss_fp: 0.004591, loss_freq: 0.038194
[16:26:20.683] iteration 10708: loss: 0.079820, loss_s1: 0.098886, loss_fp: 0.004364, loss_freq: 0.016246
[16:26:21.311] iteration 10709: loss: 0.089538, loss_s1: 0.063623, loss_fp: 0.009303, loss_freq: 0.060761
[16:26:21.931] iteration 10710: loss: 0.104556, loss_s1: 0.049748, loss_fp: 0.002232, loss_freq: 0.077359
[16:26:22.555] iteration 10711: loss: 0.177666, loss_s1: 0.176819, loss_fp: 0.011342, loss_freq: 0.118993
[16:26:23.179] iteration 10712: loss: 0.058480, loss_s1: 0.052273, loss_fp: 0.001009, loss_freq: 0.023729
[16:26:23.804] iteration 10713: loss: 0.132648, loss_s1: 0.058638, loss_fp: 0.003996, loss_freq: 0.033704
[16:26:24.427] iteration 10714: loss: 0.065439, loss_s1: 0.068366, loss_fp: 0.002021, loss_freq: 0.016287
[16:26:25.050] iteration 10715: loss: 0.082442, loss_s1: 0.079936, loss_fp: 0.004513, loss_freq: 0.038089
[16:26:25.680] iteration 10716: loss: 0.097288, loss_s1: 0.061773, loss_fp: 0.001576, loss_freq: 0.025865
[16:26:26.308] iteration 10717: loss: 0.067475, loss_s1: 0.043606, loss_fp: 0.006932, loss_freq: 0.022646
[16:26:26.932] iteration 10718: loss: 0.077985, loss_s1: 0.093181, loss_fp: 0.001727, loss_freq: 0.014867
[16:26:27.557] iteration 10719: loss: 0.084456, loss_s1: 0.052237, loss_fp: 0.000438, loss_freq: 0.013947
[16:26:28.217] iteration 10720: loss: 0.063578, loss_s1: 0.046867, loss_fp: 0.002290, loss_freq: 0.016328
[16:26:28.872] iteration 10721: loss: 0.057665, loss_s1: 0.063959, loss_fp: 0.001061, loss_freq: 0.016855
[16:26:29.528] iteration 10722: loss: 0.043477, loss_s1: 0.027468, loss_fp: 0.002613, loss_freq: 0.020690
[16:26:30.168] iteration 10723: loss: 0.058061, loss_s1: 0.025281, loss_fp: 0.001315, loss_freq: 0.017678
[16:26:30.791] iteration 10724: loss: 0.051416, loss_s1: 0.010274, loss_fp: 0.001888, loss_freq: 0.021405
[16:26:31.416] iteration 10725: loss: 0.064490, loss_s1: 0.037269, loss_fp: 0.003647, loss_freq: 0.029873
[16:26:32.036] iteration 10726: loss: 0.053865, loss_s1: 0.042428, loss_fp: 0.000701, loss_freq: 0.015546
[16:26:32.662] iteration 10727: loss: 0.046377, loss_s1: 0.029312, loss_fp: 0.004244, loss_freq: 0.025168
[16:26:33.286] iteration 10728: loss: 0.089766, loss_s1: 0.055510, loss_fp: 0.004276, loss_freq: 0.066547
[16:26:33.909] iteration 10729: loss: 0.120870, loss_s1: 0.079488, loss_fp: 0.001599, loss_freq: 0.091420
[16:26:34.531] iteration 10730: loss: 0.077488, loss_s1: 0.074045, loss_fp: 0.003614, loss_freq: 0.038597
[16:26:35.154] iteration 10731: loss: 0.083424, loss_s1: 0.036347, loss_fp: 0.001088, loss_freq: 0.017075
[16:26:35.781] iteration 10732: loss: 0.058224, loss_s1: 0.014014, loss_fp: 0.002088, loss_freq: 0.026838
[16:26:36.404] iteration 10733: loss: 0.057179, loss_s1: 0.046815, loss_fp: 0.001460, loss_freq: 0.007496
[16:26:37.030] iteration 10734: loss: 0.112272, loss_s1: 0.108156, loss_fp: 0.010091, loss_freq: 0.033902
[16:26:37.653] iteration 10735: loss: 0.106261, loss_s1: 0.056270, loss_fp: 0.003504, loss_freq: 0.090622
[16:26:38.272] iteration 10736: loss: 0.057939, loss_s1: 0.038170, loss_fp: 0.001710, loss_freq: 0.025823
[16:26:38.897] iteration 10737: loss: 0.078152, loss_s1: 0.042412, loss_fp: 0.003117, loss_freq: 0.046531
[16:26:39.527] iteration 10738: loss: 0.072953, loss_s1: 0.066456, loss_fp: 0.002492, loss_freq: 0.030728
[16:26:40.162] iteration 10739: loss: 0.082463, loss_s1: 0.033125, loss_fp: 0.016632, loss_freq: 0.044186
[16:26:40.799] iteration 10740: loss: 0.064139, loss_s1: 0.027950, loss_fp: 0.002210, loss_freq: 0.053461
[16:26:41.439] iteration 10741: loss: 0.050897, loss_s1: 0.040152, loss_fp: 0.000293, loss_freq: 0.012889
[16:26:42.082] iteration 10742: loss: 0.110220, loss_s1: 0.106415, loss_fp: 0.004639, loss_freq: 0.052560
[16:26:42.705] iteration 10743: loss: 0.093949, loss_s1: 0.059713, loss_fp: 0.006368, loss_freq: 0.046522
[16:26:43.333] iteration 10744: loss: 0.054909, loss_s1: 0.052866, loss_fp: 0.002251, loss_freq: 0.012478
[16:26:43.955] iteration 10745: loss: 0.065164, loss_s1: 0.038622, loss_fp: 0.009941, loss_freq: 0.024466
[16:26:44.582] iteration 10746: loss: 0.141432, loss_s1: 0.060683, loss_fp: 0.002544, loss_freq: 0.156292
[16:26:45.239] iteration 10747: loss: 0.091533, loss_s1: 0.032741, loss_fp: 0.003364, loss_freq: 0.099336
[16:26:45.869] iteration 10748: loss: 0.103170, loss_s1: 0.080031, loss_fp: 0.003453, loss_freq: 0.045550
[16:26:46.500] iteration 10749: loss: 0.060302, loss_s1: 0.054533, loss_fp: 0.007037, loss_freq: 0.006108
[16:26:47.127] iteration 10750: loss: 0.072461, loss_s1: 0.028405, loss_fp: 0.025903, loss_freq: 0.040473
[16:26:47.752] iteration 10751: loss: 0.075400, loss_s1: 0.049263, loss_fp: 0.003219, loss_freq: 0.033930
[16:26:48.378] iteration 10752: loss: 0.078957, loss_s1: 0.048007, loss_fp: 0.004877, loss_freq: 0.019340
[16:26:49.003] iteration 10753: loss: 0.071194, loss_s1: 0.045760, loss_fp: 0.003900, loss_freq: 0.007035
[16:26:49.628] iteration 10754: loss: 0.111042, loss_s1: 0.082260, loss_fp: 0.002594, loss_freq: 0.034733
[16:26:50.256] iteration 10755: loss: 0.053501, loss_s1: 0.041191, loss_fp: 0.000624, loss_freq: 0.010638
[16:26:50.880] iteration 10756: loss: 0.068351, loss_s1: 0.047118, loss_fp: 0.006862, loss_freq: 0.025583
[16:26:51.552] iteration 10757: loss: 0.134566, loss_s1: 0.100043, loss_fp: 0.007156, loss_freq: 0.109316
[16:26:52.173] iteration 10758: loss: 0.079923, loss_s1: 0.070278, loss_fp: 0.001037, loss_freq: 0.024441
[16:26:52.795] iteration 10759: loss: 0.070854, loss_s1: 0.040242, loss_fp: 0.006330, loss_freq: 0.037988
[16:26:53.424] iteration 10760: loss: 0.082702, loss_s1: 0.094050, loss_fp: 0.001830, loss_freq: 0.010234
[16:26:54.049] iteration 10761: loss: 0.089268, loss_s1: 0.053485, loss_fp: 0.006128, loss_freq: 0.076902
[16:26:54.711] iteration 10762: loss: 0.064494, loss_s1: 0.059296, loss_fp: 0.001804, loss_freq: 0.026009
[16:26:55.369] iteration 10763: loss: 0.078709, loss_s1: 0.059749, loss_fp: 0.004432, loss_freq: 0.033887
[16:26:56.029] iteration 10764: loss: 0.053806, loss_s1: 0.026077, loss_fp: 0.007676, loss_freq: 0.030635
[16:26:56.659] iteration 10765: loss: 0.091891, loss_s1: 0.052612, loss_fp: 0.004147, loss_freq: 0.025257
[16:26:57.289] iteration 10766: loss: 0.198960, loss_s1: 0.214498, loss_fp: 0.002835, loss_freq: 0.050778
[16:26:57.922] iteration 10767: loss: 0.069464, loss_s1: 0.049982, loss_fp: 0.001715, loss_freq: 0.034272
[16:26:58.545] iteration 10768: loss: 0.078942, loss_s1: 0.064671, loss_fp: 0.001587, loss_freq: 0.016671
[16:26:59.169] iteration 10769: loss: 0.071080, loss_s1: 0.026401, loss_fp: 0.000619, loss_freq: 0.033538
[16:26:59.798] iteration 10770: loss: 0.097723, loss_s1: 0.084627, loss_fp: 0.006254, loss_freq: 0.046994
[16:27:00.422] iteration 10771: loss: 0.060255, loss_s1: 0.029762, loss_fp: 0.002917, loss_freq: 0.023901
[16:27:01.047] iteration 10772: loss: 0.105089, loss_s1: 0.062671, loss_fp: 0.001495, loss_freq: 0.028258
[16:27:01.671] iteration 10773: loss: 0.116231, loss_s1: 0.115831, loss_fp: 0.008197, loss_freq: 0.072341
[16:27:02.299] iteration 10774: loss: 0.055646, loss_s1: 0.034836, loss_fp: 0.001243, loss_freq: 0.025019
[16:27:02.926] iteration 10775: loss: 0.100422, loss_s1: 0.053476, loss_fp: 0.010108, loss_freq: 0.044222
[16:27:03.550] iteration 10776: loss: 0.114672, loss_s1: 0.080048, loss_fp: 0.008526, loss_freq: 0.064637
[16:27:04.180] iteration 10777: loss: 0.096917, loss_s1: 0.045213, loss_fp: 0.000897, loss_freq: 0.063938
[16:27:04.806] iteration 10778: loss: 0.146891, loss_s1: 0.143063, loss_fp: 0.005007, loss_freq: 0.092728
[16:27:05.435] iteration 10779: loss: 0.056987, loss_s1: 0.034995, loss_fp: 0.010567, loss_freq: 0.029704
[16:27:06.060] iteration 10780: loss: 0.081262, loss_s1: 0.065989, loss_fp: 0.001304, loss_freq: 0.041352
[16:27:06.733] iteration 10781: loss: 0.042876, loss_s1: 0.028333, loss_fp: 0.002110, loss_freq: 0.013699
[16:27:07.365] iteration 10782: loss: 0.055344, loss_s1: 0.043823, loss_fp: 0.003162, loss_freq: 0.016340
[16:27:08.030] iteration 10783: loss: 0.061022, loss_s1: 0.019385, loss_fp: 0.002093, loss_freq: 0.023248
[16:27:08.654] iteration 10784: loss: 0.071841, loss_s1: 0.060923, loss_fp: 0.002621, loss_freq: 0.015186
[16:27:09.278] iteration 10785: loss: 0.089848, loss_s1: 0.044995, loss_fp: 0.008124, loss_freq: 0.081161
[16:27:09.897] iteration 10786: loss: 0.055736, loss_s1: 0.046382, loss_fp: 0.001061, loss_freq: 0.018336
[16:27:10.520] iteration 10787: loss: 0.077618, loss_s1: 0.059669, loss_fp: 0.001504, loss_freq: 0.039777
[16:27:11.506] iteration 10788: loss: 0.118131, loss_s1: 0.048710, loss_fp: 0.002817, loss_freq: 0.035709
[16:27:12.132] iteration 10789: loss: 0.084892, loss_s1: 0.042061, loss_fp: 0.002240, loss_freq: 0.036774
[16:27:12.758] iteration 10790: loss: 0.081869, loss_s1: 0.016802, loss_fp: 0.002404, loss_freq: 0.026064
[16:27:13.441] iteration 10791: loss: 0.054109, loss_s1: 0.027196, loss_fp: 0.000469, loss_freq: 0.019946
[16:27:14.099] iteration 10792: loss: 0.072876, loss_s1: 0.063473, loss_fp: 0.004096, loss_freq: 0.015812
[16:27:14.757] iteration 10793: loss: 0.148630, loss_s1: 0.086828, loss_fp: 0.020855, loss_freq: 0.051762
[16:27:15.409] iteration 10794: loss: 0.082347, loss_s1: 0.061118, loss_fp: 0.003073, loss_freq: 0.039775
[16:27:16.066] iteration 10795: loss: 0.100777, loss_s1: 0.064188, loss_fp: 0.004593, loss_freq: 0.039048
[16:27:16.720] iteration 10796: loss: 0.074786, loss_s1: 0.063880, loss_fp: 0.006981, loss_freq: 0.029372
[16:27:17.374] iteration 10797: loss: 0.053315, loss_s1: 0.038013, loss_fp: 0.003524, loss_freq: 0.019196
[16:27:18.004] iteration 10798: loss: 0.039308, loss_s1: 0.007238, loss_fp: 0.001145, loss_freq: 0.019223
[16:27:18.629] iteration 10799: loss: 0.102132, loss_s1: 0.072958, loss_fp: 0.004369, loss_freq: 0.057210
[16:27:19.255] iteration 10800: loss: 0.068545, loss_s1: 0.039842, loss_fp: 0.006704, loss_freq: 0.046951
[16:27:22.420] iteration 10800 : mean_dice : 0.695731
[16:27:23.114] iteration 10801: loss: 0.100141, loss_s1: 0.073145, loss_fp: 0.005442, loss_freq: 0.042977
[16:27:23.778] iteration 10802: loss: 0.079692, loss_s1: 0.084150, loss_fp: 0.005914, loss_freq: 0.020122
[16:27:24.440] iteration 10803: loss: 0.084460, loss_s1: 0.041521, loss_fp: 0.002740, loss_freq: 0.071289
[16:27:25.109] iteration 10804: loss: 0.055691, loss_s1: 0.025160, loss_fp: 0.002815, loss_freq: 0.012792
[16:27:25.784] iteration 10805: loss: 0.066384, loss_s1: 0.046362, loss_fp: 0.001617, loss_freq: 0.017285
[16:27:26.448] iteration 10806: loss: 0.063006, loss_s1: 0.040031, loss_fp: 0.001245, loss_freq: 0.018043
[16:27:27.119] iteration 10807: loss: 0.061593, loss_s1: 0.035283, loss_fp: 0.001841, loss_freq: 0.012507
[16:27:27.799] iteration 10808: loss: 0.039341, loss_s1: 0.013851, loss_fp: 0.001956, loss_freq: 0.009524
[16:27:28.464] iteration 10809: loss: 0.062752, loss_s1: 0.045003, loss_fp: 0.000540, loss_freq: 0.027446
[16:27:29.140] iteration 10810: loss: 0.076354, loss_s1: 0.058513, loss_fp: 0.002808, loss_freq: 0.021533
[16:27:29.767] iteration 10811: loss: 0.305884, loss_s1: 0.233155, loss_fp: 0.027683, loss_freq: 0.271403
[16:27:30.395] iteration 10812: loss: 0.045331, loss_s1: 0.018387, loss_fp: 0.003057, loss_freq: 0.019049
[16:27:31.026] iteration 10813: loss: 0.054386, loss_s1: 0.012520, loss_fp: 0.004339, loss_freq: 0.032491
[16:27:31.648] iteration 10814: loss: 0.048945, loss_s1: 0.026157, loss_fp: 0.008434, loss_freq: 0.008259
[16:27:32.312] iteration 10815: loss: 0.119170, loss_s1: 0.105881, loss_fp: 0.008632, loss_freq: 0.065039
[16:27:32.939] iteration 10816: loss: 0.068627, loss_s1: 0.063681, loss_fp: 0.002838, loss_freq: 0.034468
[16:27:33.568] iteration 10817: loss: 0.075081, loss_s1: 0.050301, loss_fp: 0.001965, loss_freq: 0.015275
[16:27:34.189] iteration 10818: loss: 0.046598, loss_s1: 0.038678, loss_fp: 0.002716, loss_freq: 0.013875
[16:27:34.812] iteration 10819: loss: 0.052080, loss_s1: 0.023673, loss_fp: 0.002980, loss_freq: 0.019818
[16:27:35.454] iteration 10820: loss: 0.049936, loss_s1: 0.035647, loss_fp: 0.000750, loss_freq: 0.022135
[16:27:36.081] iteration 10821: loss: 0.052143, loss_s1: 0.050216, loss_fp: 0.001118, loss_freq: 0.007512
[16:27:36.705] iteration 10822: loss: 0.078696, loss_s1: 0.033576, loss_fp: 0.002795, loss_freq: 0.030144
[16:27:37.328] iteration 10823: loss: 0.097757, loss_s1: 0.082106, loss_fp: 0.008095, loss_freq: 0.059066
[16:27:37.951] iteration 10824: loss: 0.134930, loss_s1: 0.130645, loss_fp: 0.001762, loss_freq: 0.067765
[16:27:38.572] iteration 10825: loss: 0.103148, loss_s1: 0.069951, loss_fp: 0.009780, loss_freq: 0.043710
[16:27:39.197] iteration 10826: loss: 0.107738, loss_s1: 0.076167, loss_fp: 0.008660, loss_freq: 0.070756
[16:27:39.821] iteration 10827: loss: 0.112345, loss_s1: 0.071401, loss_fp: 0.004281, loss_freq: 0.028724
[16:27:40.447] iteration 10828: loss: 0.081411, loss_s1: 0.041711, loss_fp: 0.007733, loss_freq: 0.017955
[16:27:41.073] iteration 10829: loss: 0.092355, loss_s1: 0.046807, loss_fp: 0.002920, loss_freq: 0.067044
[16:27:41.701] iteration 10830: loss: 0.068664, loss_s1: 0.042297, loss_fp: 0.002449, loss_freq: 0.036098
[16:27:42.328] iteration 10831: loss: 0.071198, loss_s1: 0.039854, loss_fp: 0.004554, loss_freq: 0.023808
[16:27:42.956] iteration 10832: loss: 0.058031, loss_s1: 0.017666, loss_fp: 0.003303, loss_freq: 0.039070
[16:27:43.584] iteration 10833: loss: 0.045890, loss_s1: 0.011889, loss_fp: 0.002217, loss_freq: 0.006701
[16:27:44.212] iteration 10834: loss: 0.038115, loss_s1: 0.020720, loss_fp: 0.001027, loss_freq: 0.016953
[16:27:44.834] iteration 10835: loss: 0.063669, loss_s1: 0.045286, loss_fp: 0.000753, loss_freq: 0.033264
[16:27:45.460] iteration 10836: loss: 0.062446, loss_s1: 0.044194, loss_fp: 0.000349, loss_freq: 0.027880
[16:27:46.086] iteration 10837: loss: 0.068957, loss_s1: 0.041071, loss_fp: 0.000874, loss_freq: 0.053606
[16:27:46.711] iteration 10838: loss: 0.051919, loss_s1: 0.033440, loss_fp: 0.000688, loss_freq: 0.022705
[16:27:47.340] iteration 10839: loss: 0.070362, loss_s1: 0.056365, loss_fp: 0.000792, loss_freq: 0.022088
[16:27:47.962] iteration 10840: loss: 0.075142, loss_s1: 0.057879, loss_fp: 0.001305, loss_freq: 0.041606
[16:27:48.622] iteration 10841: loss: 0.096366, loss_s1: 0.041414, loss_fp: 0.024507, loss_freq: 0.074938
[16:27:49.282] iteration 10842: loss: 0.072952, loss_s1: 0.072195, loss_fp: 0.000434, loss_freq: 0.026135
[16:27:49.945] iteration 10843: loss: 0.069853, loss_s1: 0.066633, loss_fp: 0.001409, loss_freq: 0.018218
[16:27:50.588] iteration 10844: loss: 0.044822, loss_s1: 0.040503, loss_fp: 0.001906, loss_freq: 0.004833
[16:27:51.219] iteration 10845: loss: 0.059605, loss_s1: 0.023369, loss_fp: 0.000751, loss_freq: 0.022243
[16:27:51.843] iteration 10846: loss: 0.048942, loss_s1: 0.046804, loss_fp: 0.001375, loss_freq: 0.005522
[16:27:52.471] iteration 10847: loss: 0.054631, loss_s1: 0.052925, loss_fp: 0.000307, loss_freq: 0.017258
[16:27:53.094] iteration 10848: loss: 0.070982, loss_s1: 0.033185, loss_fp: 0.003949, loss_freq: 0.044105
[16:27:53.719] iteration 10849: loss: 0.050978, loss_s1: 0.028876, loss_fp: 0.003661, loss_freq: 0.012719
[16:27:54.342] iteration 10850: loss: 0.059389, loss_s1: 0.035002, loss_fp: 0.003893, loss_freq: 0.014692
[16:27:54.963] iteration 10851: loss: 0.054836, loss_s1: 0.034593, loss_fp: 0.003418, loss_freq: 0.023226
[16:27:55.590] iteration 10852: loss: 0.090857, loss_s1: 0.066788, loss_fp: 0.003067, loss_freq: 0.025508
[16:27:56.219] iteration 10853: loss: 0.098404, loss_s1: 0.069376, loss_fp: 0.005074, loss_freq: 0.066470
[16:27:56.842] iteration 10854: loss: 0.094127, loss_s1: 0.049488, loss_fp: 0.001415, loss_freq: 0.056425
[16:27:57.469] iteration 10855: loss: 0.062386, loss_s1: 0.047274, loss_fp: 0.000764, loss_freq: 0.032615
[16:27:58.091] iteration 10856: loss: 0.065888, loss_s1: 0.045643, loss_fp: 0.004634, loss_freq: 0.022148
[16:27:58.713] iteration 10857: loss: 0.092988, loss_s1: 0.032601, loss_fp: 0.001639, loss_freq: 0.013721
[16:27:59.340] iteration 10858: loss: 0.076131, loss_s1: 0.036128, loss_fp: 0.011143, loss_freq: 0.026700
[16:27:59.971] iteration 10859: loss: 0.086544, loss_s1: 0.062463, loss_fp: 0.001283, loss_freq: 0.031797
[16:28:00.595] iteration 10860: loss: 0.078044, loss_s1: 0.051305, loss_fp: 0.002286, loss_freq: 0.049979
[16:28:01.223] iteration 10861: loss: 0.073902, loss_s1: 0.064777, loss_fp: 0.001913, loss_freq: 0.021318
[16:28:01.881] iteration 10862: loss: 0.072665, loss_s1: 0.054893, loss_fp: 0.000378, loss_freq: 0.038671
[16:28:02.541] iteration 10863: loss: 0.094872, loss_s1: 0.081223, loss_fp: 0.003515, loss_freq: 0.035697
[16:28:03.200] iteration 10864: loss: 0.086061, loss_s1: 0.057784, loss_fp: 0.005223, loss_freq: 0.032738
[16:28:03.847] iteration 10865: loss: 0.045412, loss_s1: 0.010069, loss_fp: 0.002358, loss_freq: 0.019234
[16:28:04.475] iteration 10866: loss: 0.046857, loss_s1: 0.038442, loss_fp: 0.001460, loss_freq: 0.010790
[16:28:05.096] iteration 10867: loss: 0.073241, loss_s1: 0.065677, loss_fp: 0.004054, loss_freq: 0.036747
[16:28:05.719] iteration 10868: loss: 0.070357, loss_s1: 0.037087, loss_fp: 0.010289, loss_freq: 0.039052
[16:28:06.346] iteration 10869: loss: 0.111335, loss_s1: 0.057123, loss_fp: 0.003998, loss_freq: 0.055271
[16:28:06.972] iteration 10870: loss: 0.112691, loss_s1: 0.100123, loss_fp: 0.003836, loss_freq: 0.072619
[16:28:07.600] iteration 10871: loss: 0.123067, loss_s1: 0.071091, loss_fp: 0.010228, loss_freq: 0.021656
[16:28:08.230] iteration 10872: loss: 0.086823, loss_s1: 0.087280, loss_fp: 0.004763, loss_freq: 0.034920
[16:28:08.856] iteration 10873: loss: 0.038068, loss_s1: 0.025012, loss_fp: 0.004276, loss_freq: 0.007523
[16:28:09.481] iteration 10874: loss: 0.063544, loss_s1: 0.026275, loss_fp: 0.001923, loss_freq: 0.023656
[16:28:10.113] iteration 10875: loss: 0.074038, loss_s1: 0.076481, loss_fp: 0.003446, loss_freq: 0.016114
[16:28:10.753] iteration 10876: loss: 0.075850, loss_s1: 0.057700, loss_fp: 0.001491, loss_freq: 0.053796
[16:28:11.383] iteration 10877: loss: 0.093594, loss_s1: 0.055935, loss_fp: 0.002150, loss_freq: 0.041628
[16:28:12.009] iteration 10878: loss: 0.066359, loss_s1: 0.027028, loss_fp: 0.001041, loss_freq: 0.019573
[16:28:12.635] iteration 10879: loss: 0.070988, loss_s1: 0.048584, loss_fp: 0.010219, loss_freq: 0.023710
[16:28:13.264] iteration 10880: loss: 0.106359, loss_s1: 0.052687, loss_fp: 0.001536, loss_freq: 0.026120
[16:28:13.892] iteration 10881: loss: 0.053019, loss_s1: 0.030394, loss_fp: 0.001616, loss_freq: 0.018344
[16:28:14.518] iteration 10882: loss: 0.038331, loss_s1: 0.015958, loss_fp: 0.003587, loss_freq: 0.021909
[16:28:15.148] iteration 10883: loss: 0.066377, loss_s1: 0.061987, loss_fp: 0.001174, loss_freq: 0.026133
[16:28:15.772] iteration 10884: loss: 0.047595, loss_s1: 0.031764, loss_fp: 0.001368, loss_freq: 0.014837
[16:28:16.400] iteration 10885: loss: 0.068002, loss_s1: 0.029988, loss_fp: 0.000809, loss_freq: 0.044501
[16:28:17.030] iteration 10886: loss: 0.055113, loss_s1: 0.041164, loss_fp: 0.002996, loss_freq: 0.029629
[16:28:17.689] iteration 10887: loss: 0.061224, loss_s1: 0.048655, loss_fp: 0.004655, loss_freq: 0.017005
[16:28:18.346] iteration 10888: loss: 0.070112, loss_s1: 0.067411, loss_fp: 0.002136, loss_freq: 0.032893
[16:28:19.005] iteration 10889: loss: 0.084850, loss_s1: 0.065205, loss_fp: 0.001672, loss_freq: 0.043459
[16:28:19.672] iteration 10890: loss: 0.074289, loss_s1: 0.048054, loss_fp: 0.001043, loss_freq: 0.030697
[16:28:20.332] iteration 10891: loss: 0.091592, loss_s1: 0.082853, loss_fp: 0.005127, loss_freq: 0.044975
[16:28:20.989] iteration 10892: loss: 0.051783, loss_s1: 0.023715, loss_fp: 0.001808, loss_freq: 0.012815
[16:28:21.624] iteration 10893: loss: 0.044666, loss_s1: 0.012252, loss_fp: 0.003316, loss_freq: 0.020390
[16:28:22.256] iteration 10894: loss: 0.050788, loss_s1: 0.016351, loss_fp: 0.003444, loss_freq: 0.023080
[16:28:22.884] iteration 10895: loss: 0.144915, loss_s1: 0.107162, loss_fp: 0.001165, loss_freq: 0.100852
[16:28:23.509] iteration 10896: loss: 0.168084, loss_s1: 0.087491, loss_fp: 0.006886, loss_freq: 0.160682
[16:28:24.132] iteration 10897: loss: 0.053830, loss_s1: 0.022399, loss_fp: 0.000919, loss_freq: 0.029633
[16:28:24.757] iteration 10898: loss: 0.070761, loss_s1: 0.033218, loss_fp: 0.001086, loss_freq: 0.018204
[16:28:25.385] iteration 10899: loss: 0.064830, loss_s1: 0.047012, loss_fp: 0.004170, loss_freq: 0.032636
[16:28:26.009] iteration 10900: loss: 0.106286, loss_s1: 0.113712, loss_fp: 0.011184, loss_freq: 0.042623
[16:28:26.635] iteration 10901: loss: 0.068483, loss_s1: 0.037693, loss_fp: 0.002232, loss_freq: 0.050689
[16:28:27.268] iteration 10902: loss: 0.059777, loss_s1: 0.052316, loss_fp: 0.002491, loss_freq: 0.009238
[16:28:27.891] iteration 10903: loss: 0.141426, loss_s1: 0.132365, loss_fp: 0.005697, loss_freq: 0.077246
[16:28:28.523] iteration 10904: loss: 0.080858, loss_s1: 0.060119, loss_fp: 0.000912, loss_freq: 0.039447
[16:28:29.151] iteration 10905: loss: 0.062751, loss_s1: 0.036727, loss_fp: 0.002368, loss_freq: 0.014144
[16:28:29.774] iteration 10906: loss: 0.037915, loss_s1: 0.014518, loss_fp: 0.003614, loss_freq: 0.010192
[16:28:30.411] iteration 10907: loss: 0.162800, loss_s1: 0.098576, loss_fp: 0.001438, loss_freq: 0.185771
[16:28:31.037] iteration 10908: loss: 0.072272, loss_s1: 0.041081, loss_fp: 0.003521, loss_freq: 0.053565
[16:28:31.673] iteration 10909: loss: 0.050971, loss_s1: 0.017783, loss_fp: 0.007429, loss_freq: 0.005618
[16:28:32.299] iteration 10910: loss: 0.045163, loss_s1: 0.035737, loss_fp: 0.000897, loss_freq: 0.007095
[16:28:32.923] iteration 10911: loss: 0.065154, loss_s1: 0.051371, loss_fp: 0.004768, loss_freq: 0.022895
[16:28:33.549] iteration 10912: loss: 0.106627, loss_s1: 0.046583, loss_fp: 0.002113, loss_freq: 0.050874
[16:28:34.172] iteration 10913: loss: 0.076430, loss_s1: 0.019672, loss_fp: 0.002229, loss_freq: 0.009529
[16:28:34.797] iteration 10914: loss: 0.080001, loss_s1: 0.028127, loss_fp: 0.000935, loss_freq: 0.034950
[16:28:35.432] iteration 10915: loss: 0.182788, loss_s1: 0.195625, loss_fp: 0.002627, loss_freq: 0.086935
[16:28:36.055] iteration 10916: loss: 0.054589, loss_s1: 0.047568, loss_fp: 0.001643, loss_freq: 0.018161
[16:28:36.684] iteration 10917: loss: 0.049734, loss_s1: 0.024186, loss_fp: 0.008615, loss_freq: 0.011305
[16:28:37.316] iteration 10918: loss: 0.113715, loss_s1: 0.079797, loss_fp: 0.005553, loss_freq: 0.105888
[16:28:37.944] iteration 10919: loss: 0.072985, loss_s1: 0.068203, loss_fp: 0.004010, loss_freq: 0.019287
[16:28:38.574] iteration 10920: loss: 0.089134, loss_s1: 0.067165, loss_fp: 0.005218, loss_freq: 0.048119
[16:28:39.200] iteration 10921: loss: 0.076986, loss_s1: 0.083102, loss_fp: 0.003008, loss_freq: 0.020736
[16:28:39.827] iteration 10922: loss: 0.097349, loss_s1: 0.061564, loss_fp: 0.008227, loss_freq: 0.046746
[16:28:40.465] iteration 10923: loss: 0.065198, loss_s1: 0.064215, loss_fp: 0.006441, loss_freq: 0.025098
[16:28:41.089] iteration 10924: loss: 0.061189, loss_s1: 0.017111, loss_fp: 0.001270, loss_freq: 0.055493
[16:28:41.721] iteration 10925: loss: 0.065327, loss_s1: 0.056288, loss_fp: 0.003492, loss_freq: 0.017048
[16:28:42.529] iteration 10926: loss: 0.059585, loss_s1: 0.029998, loss_fp: 0.010233, loss_freq: 0.034888
[16:28:43.171] iteration 10927: loss: 0.086166, loss_s1: 0.047129, loss_fp: 0.001622, loss_freq: 0.035222
[16:28:43.807] iteration 10928: loss: 0.104149, loss_s1: 0.118000, loss_fp: 0.001482, loss_freq: 0.030954
[16:28:44.455] iteration 10929: loss: 0.070890, loss_s1: 0.041393, loss_fp: 0.008622, loss_freq: 0.031264
[16:28:45.088] iteration 10930: loss: 0.082119, loss_s1: 0.024533, loss_fp: 0.001940, loss_freq: 0.039335
[16:28:45.720] iteration 10931: loss: 0.116973, loss_s1: 0.122674, loss_fp: 0.002315, loss_freq: 0.032318
[16:28:46.352] iteration 10932: loss: 0.072472, loss_s1: 0.060546, loss_fp: 0.003762, loss_freq: 0.013851
[16:28:46.983] iteration 10933: loss: 0.124480, loss_s1: 0.103502, loss_fp: 0.006860, loss_freq: 0.034633
[16:28:47.610] iteration 10934: loss: 0.075422, loss_s1: 0.037634, loss_fp: 0.012490, loss_freq: 0.045160
[16:28:48.236] iteration 10935: loss: 0.072715, loss_s1: 0.057392, loss_fp: 0.001684, loss_freq: 0.028026
[16:28:48.859] iteration 10936: loss: 0.062581, loss_s1: 0.039716, loss_fp: 0.010839, loss_freq: 0.022948
[16:28:49.485] iteration 10937: loss: 0.131275, loss_s1: 0.118549, loss_fp: 0.000877, loss_freq: 0.059381
[16:28:50.118] iteration 10938: loss: 0.084083, loss_s1: 0.048514, loss_fp: 0.011195, loss_freq: 0.027630
[16:28:50.749] iteration 10939: loss: 0.124473, loss_s1: 0.118426, loss_fp: 0.009324, loss_freq: 0.071294
[16:28:51.379] iteration 10940: loss: 0.060235, loss_s1: 0.028343, loss_fp: 0.002676, loss_freq: 0.023041
[16:28:51.998] iteration 10941: loss: 0.078572, loss_s1: 0.056052, loss_fp: 0.001478, loss_freq: 0.052681
[16:28:52.624] iteration 10942: loss: 0.058747, loss_s1: 0.015000, loss_fp: 0.001059, loss_freq: 0.018290
[16:28:53.250] iteration 10943: loss: 0.057728, loss_s1: 0.025081, loss_fp: 0.001191, loss_freq: 0.024712
[16:28:53.875] iteration 10944: loss: 0.096994, loss_s1: 0.033176, loss_fp: 0.000926, loss_freq: 0.009050
[16:28:54.500] iteration 10945: loss: 0.073445, loss_s1: 0.046822, loss_fp: 0.001210, loss_freq: 0.043965
[16:28:55.131] iteration 10946: loss: 0.077869, loss_s1: 0.053711, loss_fp: 0.002345, loss_freq: 0.037292
[16:28:55.751] iteration 10947: loss: 0.071205, loss_s1: 0.038984, loss_fp: 0.003702, loss_freq: 0.011618
[16:28:56.375] iteration 10948: loss: 0.100807, loss_s1: 0.092211, loss_fp: 0.001193, loss_freq: 0.038836
[16:28:57.368] iteration 10949: loss: 0.058882, loss_s1: 0.058001, loss_fp: 0.001571, loss_freq: 0.009898
[16:28:57.987] iteration 10950: loss: 0.081154, loss_s1: 0.055835, loss_fp: 0.001864, loss_freq: 0.040209
[16:28:58.612] iteration 10951: loss: 0.116993, loss_s1: 0.069502, loss_fp: 0.001602, loss_freq: 0.031722
[16:28:59.233] iteration 10952: loss: 0.059775, loss_s1: 0.035091, loss_fp: 0.000584, loss_freq: 0.017853
[16:28:59.861] iteration 10953: loss: 0.051866, loss_s1: 0.022816, loss_fp: 0.005732, loss_freq: 0.025425
[16:29:00.486] iteration 10954: loss: 0.165686, loss_s1: 0.085291, loss_fp: 0.002915, loss_freq: 0.062530
[16:29:01.148] iteration 10955: loss: 0.044573, loss_s1: 0.032756, loss_fp: 0.000727, loss_freq: 0.009611
[16:29:01.815] iteration 10956: loss: 0.058892, loss_s1: 0.051763, loss_fp: 0.000372, loss_freq: 0.024541
[16:29:02.477] iteration 10957: loss: 0.065047, loss_s1: 0.030051, loss_fp: 0.001887, loss_freq: 0.058678
[16:29:03.137] iteration 10958: loss: 0.062058, loss_s1: 0.044096, loss_fp: 0.003947, loss_freq: 0.028767
[16:29:03.803] iteration 10959: loss: 0.061019, loss_s1: 0.059965, loss_fp: 0.000186, loss_freq: 0.015336
[16:29:04.464] iteration 10960: loss: 0.079223, loss_s1: 0.073539, loss_fp: 0.006646, loss_freq: 0.024560
[16:29:05.125] iteration 10961: loss: 0.063318, loss_s1: 0.042359, loss_fp: 0.006219, loss_freq: 0.037961
[16:29:05.786] iteration 10962: loss: 0.070918, loss_s1: 0.027543, loss_fp: 0.001213, loss_freq: 0.048186
[16:29:06.434] iteration 10963: loss: 0.048407, loss_s1: 0.027951, loss_fp: 0.002268, loss_freq: 0.014672
[16:29:07.061] iteration 10964: loss: 0.092588, loss_s1: 0.055428, loss_fp: 0.015130, loss_freq: 0.066012
[16:29:07.688] iteration 10965: loss: 0.081619, loss_s1: 0.049564, loss_fp: 0.003708, loss_freq: 0.026687
[16:29:08.313] iteration 10966: loss: 0.090468, loss_s1: 0.079874, loss_fp: 0.003078, loss_freq: 0.041112
[16:29:08.942] iteration 10967: loss: 0.079404, loss_s1: 0.082001, loss_fp: 0.001261, loss_freq: 0.032363
[16:29:09.567] iteration 10968: loss: 0.089903, loss_s1: 0.060762, loss_fp: 0.001056, loss_freq: 0.049679
[16:29:10.194] iteration 10969: loss: 0.049626, loss_s1: 0.024295, loss_fp: 0.005858, loss_freq: 0.009845
[16:29:10.824] iteration 10970: loss: 0.049797, loss_s1: 0.022606, loss_fp: 0.001660, loss_freq: 0.024801
[16:29:11.451] iteration 10971: loss: 0.093059, loss_s1: 0.038386, loss_fp: 0.003350, loss_freq: 0.044184
[16:29:12.078] iteration 10972: loss: 0.133487, loss_s1: 0.085513, loss_fp: 0.005224, loss_freq: 0.126911
[16:29:12.701] iteration 10973: loss: 0.064118, loss_s1: 0.027421, loss_fp: 0.000441, loss_freq: 0.045773
[16:29:13.330] iteration 10974: loss: 0.062495, loss_s1: 0.042429, loss_fp: 0.003087, loss_freq: 0.025746
[16:29:13.962] iteration 10975: loss: 0.044496, loss_s1: 0.017685, loss_fp: 0.000470, loss_freq: 0.025438
[16:29:14.588] iteration 10976: loss: 0.103249, loss_s1: 0.101329, loss_fp: 0.017024, loss_freq: 0.034632
[16:29:15.216] iteration 10977: loss: 0.068609, loss_s1: 0.052796, loss_fp: 0.002817, loss_freq: 0.044719
[16:29:15.843] iteration 10978: loss: 0.050704, loss_s1: 0.028785, loss_fp: 0.003007, loss_freq: 0.011220
[16:29:16.469] iteration 10979: loss: 0.068219, loss_s1: 0.057577, loss_fp: 0.006855, loss_freq: 0.022562
[16:29:17.097] iteration 10980: loss: 0.090962, loss_s1: 0.084058, loss_fp: 0.004897, loss_freq: 0.031907
[16:29:17.725] iteration 10981: loss: 0.070454, loss_s1: 0.077341, loss_fp: 0.001970, loss_freq: 0.015649
[16:29:18.349] iteration 10982: loss: 0.054814, loss_s1: 0.049320, loss_fp: 0.000869, loss_freq: 0.019790
[16:29:18.979] iteration 10983: loss: 0.073737, loss_s1: 0.026022, loss_fp: 0.005061, loss_freq: 0.038006
[16:29:19.603] iteration 10984: loss: 0.057556, loss_s1: 0.022143, loss_fp: 0.006015, loss_freq: 0.030749
[16:29:20.227] iteration 10985: loss: 0.085984, loss_s1: 0.050896, loss_fp: 0.006852, loss_freq: 0.034029
[16:29:20.853] iteration 10986: loss: 0.078150, loss_s1: 0.080004, loss_fp: 0.001811, loss_freq: 0.015825
[16:29:21.480] iteration 10987: loss: 0.122735, loss_s1: 0.108295, loss_fp: 0.005056, loss_freq: 0.075632
[16:29:22.104] iteration 10988: loss: 0.079364, loss_s1: 0.071615, loss_fp: 0.002015, loss_freq: 0.036074
[16:29:22.731] iteration 10989: loss: 0.076467, loss_s1: 0.048690, loss_fp: 0.005090, loss_freq: 0.036374
[16:29:23.355] iteration 10990: loss: 0.065968, loss_s1: 0.044370, loss_fp: 0.003738, loss_freq: 0.041072
[16:29:23.983] iteration 10991: loss: 0.093661, loss_s1: 0.050441, loss_fp: 0.002013, loss_freq: 0.029494
[16:29:24.603] iteration 10992: loss: 0.072236, loss_s1: 0.033259, loss_fp: 0.001839, loss_freq: 0.048819
[16:29:25.227] iteration 10993: loss: 0.078637, loss_s1: 0.033424, loss_fp: 0.002042, loss_freq: 0.064564
[16:29:25.851] iteration 10994: loss: 0.085458, loss_s1: 0.072557, loss_fp: 0.003425, loss_freq: 0.035384
[16:29:26.475] iteration 10995: loss: 0.068283, loss_s1: 0.050218, loss_fp: 0.008385, loss_freq: 0.023844
[16:29:27.104] iteration 10996: loss: 0.057971, loss_s1: 0.034827, loss_fp: 0.001450, loss_freq: 0.029378
[16:29:27.731] iteration 10997: loss: 0.107410, loss_s1: 0.085045, loss_fp: 0.000735, loss_freq: 0.063583
[16:29:28.355] iteration 10998: loss: 0.105766, loss_s1: 0.079126, loss_fp: 0.005959, loss_freq: 0.075792
[16:29:28.978] iteration 10999: loss: 0.082879, loss_s1: 0.033095, loss_fp: 0.000408, loss_freq: 0.071547
[16:29:29.604] iteration 11000: loss: 0.054330, loss_s1: 0.023065, loss_fp: 0.000381, loss_freq: 0.022341
[16:29:32.833] iteration 11000 : mean_dice : 0.707198
[16:29:33.522] iteration 11001: loss: 0.078444, loss_s1: 0.047446, loss_fp: 0.004926, loss_freq: 0.036960
[16:29:34.181] iteration 11002: loss: 0.065964, loss_s1: 0.032033, loss_fp: 0.003220, loss_freq: 0.035203
[16:29:34.825] iteration 11003: loss: 0.059736, loss_s1: 0.041241, loss_fp: 0.000705, loss_freq: 0.024588
[16:29:35.454] iteration 11004: loss: 0.072944, loss_s1: 0.053149, loss_fp: 0.012186, loss_freq: 0.025293
[16:29:36.077] iteration 11005: loss: 0.043406, loss_s1: 0.015906, loss_fp: 0.002777, loss_freq: 0.010537
[16:29:36.704] iteration 11006: loss: 0.080351, loss_s1: 0.050343, loss_fp: 0.001041, loss_freq: 0.035159
[16:29:37.336] iteration 11007: loss: 0.054545, loss_s1: 0.048084, loss_fp: 0.000588, loss_freq: 0.010175
[16:29:37.967] iteration 11008: loss: 0.074195, loss_s1: 0.042462, loss_fp: 0.002101, loss_freq: 0.043816
[16:29:38.598] iteration 11009: loss: 0.055210, loss_s1: 0.035480, loss_fp: 0.004424, loss_freq: 0.020059
[16:29:39.261] iteration 11010: loss: 0.069118, loss_s1: 0.026523, loss_fp: 0.045170, loss_freq: 0.006303
[16:29:39.927] iteration 11011: loss: 0.070267, loss_s1: 0.038549, loss_fp: 0.001371, loss_freq: 0.021499
[16:29:40.585] iteration 11012: loss: 0.083166, loss_s1: 0.063364, loss_fp: 0.018022, loss_freq: 0.006067
[16:29:41.212] iteration 11013: loss: 0.061170, loss_s1: 0.039532, loss_fp: 0.001199, loss_freq: 0.021145
[16:29:41.836] iteration 11014: loss: 0.084906, loss_s1: 0.027207, loss_fp: 0.002792, loss_freq: 0.084380
[16:29:42.461] iteration 11015: loss: 0.054468, loss_s1: 0.018217, loss_fp: 0.000818, loss_freq: 0.036313
[16:29:43.086] iteration 11016: loss: 0.043520, loss_s1: 0.034723, loss_fp: 0.002026, loss_freq: 0.013682
[16:29:43.711] iteration 11017: loss: 0.073540, loss_s1: 0.040807, loss_fp: 0.010316, loss_freq: 0.010850
[16:29:44.333] iteration 11018: loss: 0.081629, loss_s1: 0.046774, loss_fp: 0.003510, loss_freq: 0.041028
[16:29:44.956] iteration 11019: loss: 0.072235, loss_s1: 0.063426, loss_fp: 0.004172, loss_freq: 0.035976
[16:29:45.580] iteration 11020: loss: 0.099677, loss_s1: 0.034458, loss_fp: 0.003022, loss_freq: 0.052719
[16:29:46.205] iteration 11021: loss: 0.086655, loss_s1: 0.060387, loss_fp: 0.001945, loss_freq: 0.023730
[16:29:46.832] iteration 11022: loss: 0.057488, loss_s1: 0.036393, loss_fp: 0.001292, loss_freq: 0.012299
[16:29:47.456] iteration 11023: loss: 0.088365, loss_s1: 0.081657, loss_fp: 0.003238, loss_freq: 0.029720
[16:29:48.076] iteration 11024: loss: 0.072024, loss_s1: 0.054061, loss_fp: 0.004350, loss_freq: 0.026481
[16:29:48.704] iteration 11025: loss: 0.092379, loss_s1: 0.093506, loss_fp: 0.003587, loss_freq: 0.036870
[16:29:49.331] iteration 11026: loss: 0.068556, loss_s1: 0.055659, loss_fp: 0.006700, loss_freq: 0.024743
[16:29:49.956] iteration 11027: loss: 0.038489, loss_s1: 0.017145, loss_fp: 0.001086, loss_freq: 0.015222
[16:29:50.581] iteration 11028: loss: 0.080071, loss_s1: 0.052250, loss_fp: 0.002825, loss_freq: 0.032579
[16:29:51.206] iteration 11029: loss: 0.079527, loss_s1: 0.036136, loss_fp: 0.002480, loss_freq: 0.066294
[16:29:51.830] iteration 11030: loss: 0.057277, loss_s1: 0.058006, loss_fp: 0.002896, loss_freq: 0.016880
[16:29:52.450] iteration 11031: loss: 0.120434, loss_s1: 0.087240, loss_fp: 0.021959, loss_freq: 0.095246
[16:29:53.117] iteration 11032: loss: 0.055195, loss_s1: 0.030192, loss_fp: 0.001387, loss_freq: 0.030274
[16:29:53.741] iteration 11033: loss: 0.101585, loss_s1: 0.090301, loss_fp: 0.004032, loss_freq: 0.069596
[16:29:54.360] iteration 11034: loss: 0.061908, loss_s1: 0.056701, loss_fp: 0.002139, loss_freq: 0.021554
[16:29:54.984] iteration 11035: loss: 0.096044, loss_s1: 0.039034, loss_fp: 0.001202, loss_freq: 0.040282
[16:29:55.614] iteration 11036: loss: 0.061887, loss_s1: 0.041042, loss_fp: 0.005985, loss_freq: 0.024967
[16:29:56.246] iteration 11037: loss: 0.106125, loss_s1: 0.092658, loss_fp: 0.003624, loss_freq: 0.051955
[16:29:56.877] iteration 11038: loss: 0.073936, loss_s1: 0.073726, loss_fp: 0.002606, loss_freq: 0.025174
[16:29:57.509] iteration 11039: loss: 0.069666, loss_s1: 0.032752, loss_fp: 0.000777, loss_freq: 0.020533
[16:29:58.139] iteration 11040: loss: 0.082182, loss_s1: 0.072676, loss_fp: 0.002019, loss_freq: 0.012960
[16:29:58.768] iteration 11041: loss: 0.063511, loss_s1: 0.024608, loss_fp: 0.001291, loss_freq: 0.007071
[16:29:59.394] iteration 11042: loss: 0.046037, loss_s1: 0.034993, loss_fp: 0.001554, loss_freq: 0.010404
[16:30:00.024] iteration 11043: loss: 0.048619, loss_s1: 0.031009, loss_fp: 0.014021, loss_freq: 0.011067
[16:30:00.648] iteration 11044: loss: 0.036111, loss_s1: 0.018718, loss_fp: 0.000599, loss_freq: 0.008826
[16:30:01.275] iteration 11045: loss: 0.046908, loss_s1: 0.018901, loss_fp: 0.000479, loss_freq: 0.018946
[16:30:01.901] iteration 11046: loss: 0.054608, loss_s1: 0.034969, loss_fp: 0.000282, loss_freq: 0.024457
[16:30:02.527] iteration 11047: loss: 0.058579, loss_s1: 0.039771, loss_fp: 0.000840, loss_freq: 0.028211
[16:30:03.150] iteration 11048: loss: 0.086237, loss_s1: 0.106003, loss_fp: 0.002925, loss_freq: 0.019878
[16:30:03.784] iteration 11049: loss: 0.068954, loss_s1: 0.071718, loss_fp: 0.008049, loss_freq: 0.017943
[16:30:04.411] iteration 11050: loss: 0.085561, loss_s1: 0.061406, loss_fp: 0.001772, loss_freq: 0.054727
[16:30:05.040] iteration 11051: loss: 0.077755, loss_s1: 0.041784, loss_fp: 0.005092, loss_freq: 0.052875
[16:30:05.668] iteration 11052: loss: 0.076509, loss_s1: 0.049611, loss_fp: 0.007380, loss_freq: 0.044882
[16:30:06.294] iteration 11053: loss: 0.053737, loss_s1: 0.019157, loss_fp: 0.002497, loss_freq: 0.021793
[16:30:06.923] iteration 11054: loss: 0.073838, loss_s1: 0.046963, loss_fp: 0.006938, loss_freq: 0.040934
[16:30:07.548] iteration 11055: loss: 0.061541, loss_s1: 0.025850, loss_fp: 0.002235, loss_freq: 0.019526
[16:30:08.178] iteration 11056: loss: 0.136623, loss_s1: 0.151834, loss_fp: 0.000778, loss_freq: 0.064836
[16:30:08.806] iteration 11057: loss: 0.145994, loss_s1: 0.098262, loss_fp: 0.001751, loss_freq: 0.124940
[16:30:09.432] iteration 11058: loss: 0.046702, loss_s1: 0.028165, loss_fp: 0.008733, loss_freq: 0.018410
[16:30:10.056] iteration 11059: loss: 0.052185, loss_s1: 0.012302, loss_fp: 0.001014, loss_freq: 0.028465
[16:30:10.679] iteration 11060: loss: 0.060409, loss_s1: 0.032463, loss_fp: 0.003711, loss_freq: 0.041256
[16:30:11.306] iteration 11061: loss: 0.070845, loss_s1: 0.065652, loss_fp: 0.006441, loss_freq: 0.020426
[16:30:11.931] iteration 11062: loss: 0.063311, loss_s1: 0.037135, loss_fp: 0.001361, loss_freq: 0.032283
[16:30:12.601] iteration 11063: loss: 0.040624, loss_s1: 0.018924, loss_fp: 0.001401, loss_freq: 0.004777
[16:30:13.263] iteration 11064: loss: 0.076308, loss_s1: 0.058193, loss_fp: 0.001889, loss_freq: 0.035258
[16:30:13.897] iteration 11065: loss: 0.062388, loss_s1: 0.042800, loss_fp: 0.004775, loss_freq: 0.042957
[16:30:14.520] iteration 11066: loss: 0.050548, loss_s1: 0.036467, loss_fp: 0.008118, loss_freq: 0.013188
[16:30:15.150] iteration 11067: loss: 0.066242, loss_s1: 0.019241, loss_fp: 0.003602, loss_freq: 0.016613
[16:30:15.777] iteration 11068: loss: 0.059909, loss_s1: 0.020823, loss_fp: 0.007169, loss_freq: 0.048407
[16:30:16.413] iteration 11069: loss: 0.076843, loss_s1: 0.028915, loss_fp: 0.002430, loss_freq: 0.061785
[16:30:17.051] iteration 11070: loss: 0.103963, loss_s1: 0.058706, loss_fp: 0.000810, loss_freq: 0.055683
[16:30:17.679] iteration 11071: loss: 0.046913, loss_s1: 0.013063, loss_fp: 0.004866, loss_freq: 0.014005
[16:30:18.305] iteration 11072: loss: 0.057272, loss_s1: 0.024691, loss_fp: 0.000471, loss_freq: 0.027345
[16:30:18.935] iteration 11073: loss: 0.095034, loss_s1: 0.057608, loss_fp: 0.001189, loss_freq: 0.035985
[16:30:19.564] iteration 11074: loss: 0.056335, loss_s1: 0.008303, loss_fp: 0.000801, loss_freq: 0.007043
[16:30:20.190] iteration 11075: loss: 0.052500, loss_s1: 0.035700, loss_fp: 0.002278, loss_freq: 0.009883
[16:30:20.818] iteration 11076: loss: 0.129758, loss_s1: 0.075641, loss_fp: 0.001708, loss_freq: 0.114409
[16:30:21.443] iteration 11077: loss: 0.096506, loss_s1: 0.112486, loss_fp: 0.000930, loss_freq: 0.027534
[16:30:22.070] iteration 11078: loss: 0.072475, loss_s1: 0.087264, loss_fp: 0.001690, loss_freq: 0.018397
[16:30:22.695] iteration 11079: loss: 0.084028, loss_s1: 0.034375, loss_fp: 0.004153, loss_freq: 0.073189
[16:30:23.349] iteration 11080: loss: 0.065550, loss_s1: 0.044139, loss_fp: 0.001842, loss_freq: 0.019538
[16:30:24.033] iteration 11081: loss: 0.100961, loss_s1: 0.070859, loss_fp: 0.017442, loss_freq: 0.032162
[16:30:24.675] iteration 11082: loss: 0.063017, loss_s1: 0.063660, loss_fp: 0.002045, loss_freq: 0.020415
[16:30:25.306] iteration 11083: loss: 0.093007, loss_s1: 0.025720, loss_fp: 0.002518, loss_freq: 0.073275
[16:30:25.939] iteration 11084: loss: 0.074074, loss_s1: 0.050919, loss_fp: 0.001670, loss_freq: 0.033053
[16:30:26.573] iteration 11085: loss: 0.078227, loss_s1: 0.045736, loss_fp: 0.000886, loss_freq: 0.042757
[16:30:27.212] iteration 11086: loss: 0.051007, loss_s1: 0.038511, loss_fp: 0.004302, loss_freq: 0.020442
[16:30:27.842] iteration 11087: loss: 0.057904, loss_s1: 0.048761, loss_fp: 0.015330, loss_freq: 0.010356
[16:30:28.468] iteration 11088: loss: 0.143258, loss_s1: 0.111607, loss_fp: 0.009035, loss_freq: 0.053316
[16:30:29.102] iteration 11089: loss: 0.105761, loss_s1: 0.070987, loss_fp: 0.007496, loss_freq: 0.044493
[16:30:29.730] iteration 11090: loss: 0.088998, loss_s1: 0.023691, loss_fp: 0.001881, loss_freq: 0.024257
[16:30:30.358] iteration 11091: loss: 0.090760, loss_s1: 0.052530, loss_fp: 0.003808, loss_freq: 0.079999
[16:30:30.988] iteration 11092: loss: 0.098953, loss_s1: 0.096700, loss_fp: 0.004058, loss_freq: 0.038285
[16:30:31.614] iteration 11093: loss: 0.071524, loss_s1: 0.043750, loss_fp: 0.001342, loss_freq: 0.017059
[16:30:32.274] iteration 11094: loss: 0.094072, loss_s1: 0.091909, loss_fp: 0.004382, loss_freq: 0.028652
[16:30:32.947] iteration 11095: loss: 0.090737, loss_s1: 0.081970, loss_fp: 0.001568, loss_freq: 0.063381
[16:30:33.590] iteration 11096: loss: 0.045361, loss_s1: 0.028955, loss_fp: 0.001607, loss_freq: 0.021786
[16:30:34.216] iteration 11097: loss: 0.085720, loss_s1: 0.045772, loss_fp: 0.000883, loss_freq: 0.012731
[16:30:34.846] iteration 11098: loss: 0.095733, loss_s1: 0.098387, loss_fp: 0.003280, loss_freq: 0.034090
[16:30:35.478] iteration 11099: loss: 0.085529, loss_s1: 0.064406, loss_fp: 0.002985, loss_freq: 0.031412
[16:30:36.108] iteration 11100: loss: 0.070590, loss_s1: 0.066223, loss_fp: 0.002296, loss_freq: 0.030919
[16:30:36.741] iteration 11101: loss: 0.061175, loss_s1: 0.031143, loss_fp: 0.002348, loss_freq: 0.015327
[16:30:37.369] iteration 11102: loss: 0.124366, loss_s1: 0.117931, loss_fp: 0.006393, loss_freq: 0.031599
[16:30:38.028] iteration 11103: loss: 0.062615, loss_s1: 0.039782, loss_fp: 0.000506, loss_freq: 0.012651
[16:30:38.686] iteration 11104: loss: 0.071927, loss_s1: 0.052698, loss_fp: 0.003481, loss_freq: 0.025405
[16:30:39.349] iteration 11105: loss: 0.052506, loss_s1: 0.029086, loss_fp: 0.001583, loss_freq: 0.010798
[16:30:40.018] iteration 11106: loss: 0.103812, loss_s1: 0.107325, loss_fp: 0.005490, loss_freq: 0.039324
[16:30:40.678] iteration 11107: loss: 0.112024, loss_s1: 0.104913, loss_fp: 0.005010, loss_freq: 0.064669
[16:30:41.317] iteration 11108: loss: 0.064822, loss_s1: 0.053150, loss_fp: 0.003186, loss_freq: 0.018903
[16:30:41.934] iteration 11109: loss: 0.068300, loss_s1: 0.016241, loss_fp: 0.000972, loss_freq: 0.046655
[16:30:42.914] iteration 11110: loss: 0.051155, loss_s1: 0.013428, loss_fp: 0.001992, loss_freq: 0.007897
[16:30:43.580] iteration 11111: loss: 0.080038, loss_s1: 0.056171, loss_fp: 0.011060, loss_freq: 0.035777
[16:30:44.237] iteration 11112: loss: 0.049009, loss_s1: 0.014197, loss_fp: 0.001908, loss_freq: 0.026234
[16:30:44.893] iteration 11113: loss: 0.050074, loss_s1: 0.024257, loss_fp: 0.000955, loss_freq: 0.024137
[16:30:45.521] iteration 11114: loss: 0.068235, loss_s1: 0.025597, loss_fp: 0.001539, loss_freq: 0.039277
[16:30:46.164] iteration 11115: loss: 0.129763, loss_s1: 0.075765, loss_fp: 0.003934, loss_freq: 0.031626
[16:30:46.801] iteration 11116: loss: 0.050417, loss_s1: 0.029938, loss_fp: 0.001598, loss_freq: 0.033388
[16:30:47.447] iteration 11117: loss: 0.044609, loss_s1: 0.019493, loss_fp: 0.002234, loss_freq: 0.023294
[16:30:48.085] iteration 11118: loss: 0.082458, loss_s1: 0.084404, loss_fp: 0.011095, loss_freq: 0.025243
[16:30:48.715] iteration 11119: loss: 0.057781, loss_s1: 0.050168, loss_fp: 0.000665, loss_freq: 0.007594
[16:30:49.351] iteration 11120: loss: 0.055640, loss_s1: 0.022392, loss_fp: 0.012057, loss_freq: 0.021203
[16:30:50.044] iteration 11121: loss: 0.083420, loss_s1: 0.077739, loss_fp: 0.000445, loss_freq: 0.038126
[16:30:50.681] iteration 11122: loss: 0.073961, loss_s1: 0.039141, loss_fp: 0.004842, loss_freq: 0.072656
[16:30:51.318] iteration 11123: loss: 0.085005, loss_s1: 0.047543, loss_fp: 0.006540, loss_freq: 0.050450
[16:30:51.959] iteration 11124: loss: 0.057668, loss_s1: 0.051123, loss_fp: 0.006289, loss_freq: 0.012784
[16:30:52.584] iteration 11125: loss: 0.117132, loss_s1: 0.087817, loss_fp: 0.010534, loss_freq: 0.077255
[16:30:53.209] iteration 11126: loss: 0.107281, loss_s1: 0.096761, loss_fp: 0.001343, loss_freq: 0.011144
[16:30:53.832] iteration 11127: loss: 0.047202, loss_s1: 0.026547, loss_fp: 0.001654, loss_freq: 0.019653
[16:30:54.452] iteration 11128: loss: 0.077362, loss_s1: 0.062799, loss_fp: 0.001448, loss_freq: 0.025473
[16:30:55.077] iteration 11129: loss: 0.071070, loss_s1: 0.052930, loss_fp: 0.002268, loss_freq: 0.017958
[16:30:55.702] iteration 11130: loss: 0.041821, loss_s1: 0.015568, loss_fp: 0.002010, loss_freq: 0.004108
[16:30:56.326] iteration 11131: loss: 0.060146, loss_s1: 0.045994, loss_fp: 0.002323, loss_freq: 0.027633
[16:30:56.953] iteration 11132: loss: 0.063418, loss_s1: 0.034349, loss_fp: 0.002371, loss_freq: 0.022311
[16:30:57.576] iteration 11133: loss: 0.217945, loss_s1: 0.102834, loss_fp: 0.010437, loss_freq: 0.268673
[16:30:58.199] iteration 11134: loss: 0.051536, loss_s1: 0.041852, loss_fp: 0.003240, loss_freq: 0.013438
[16:30:58.826] iteration 11135: loss: 0.074267, loss_s1: 0.080330, loss_fp: 0.003023, loss_freq: 0.023137
[16:30:59.451] iteration 11136: loss: 0.048623, loss_s1: 0.028333, loss_fp: 0.000715, loss_freq: 0.016143
[16:31:00.073] iteration 11137: loss: 0.083203, loss_s1: 0.045199, loss_fp: 0.004261, loss_freq: 0.042548
[16:31:00.694] iteration 11138: loss: 0.070929, loss_s1: 0.060598, loss_fp: 0.003549, loss_freq: 0.035923
[16:31:01.320] iteration 11139: loss: 0.050395, loss_s1: 0.015831, loss_fp: 0.006114, loss_freq: 0.010373
[16:31:01.943] iteration 11140: loss: 0.055738, loss_s1: 0.050493, loss_fp: 0.001649, loss_freq: 0.024477
[16:31:02.567] iteration 11141: loss: 0.090546, loss_s1: 0.025914, loss_fp: 0.000727, loss_freq: 0.019773
[16:31:03.193] iteration 11142: loss: 0.056541, loss_s1: 0.043362, loss_fp: 0.000636, loss_freq: 0.028827
[16:31:03.820] iteration 11143: loss: 0.054173, loss_s1: 0.028092, loss_fp: 0.001004, loss_freq: 0.010472
[16:31:04.440] iteration 11144: loss: 0.072386, loss_s1: 0.027734, loss_fp: 0.000558, loss_freq: 0.023198
[16:31:05.064] iteration 11145: loss: 0.060408, loss_s1: 0.046238, loss_fp: 0.001883, loss_freq: 0.038702
[16:31:05.687] iteration 11146: loss: 0.096375, loss_s1: 0.050814, loss_fp: 0.004366, loss_freq: 0.055044
[16:31:06.308] iteration 11147: loss: 0.083144, loss_s1: 0.047606, loss_fp: 0.006742, loss_freq: 0.029677
[16:31:06.936] iteration 11148: loss: 0.093605, loss_s1: 0.091056, loss_fp: 0.002515, loss_freq: 0.037793
[16:31:07.560] iteration 11149: loss: 0.097995, loss_s1: 0.110227, loss_fp: 0.002082, loss_freq: 0.035356
[16:31:08.184] iteration 11150: loss: 0.071741, loss_s1: 0.046341, loss_fp: 0.007195, loss_freq: 0.021037
[16:31:08.811] iteration 11151: loss: 0.118197, loss_s1: 0.088717, loss_fp: 0.015500, loss_freq: 0.078749
[16:31:09.435] iteration 11152: loss: 0.074256, loss_s1: 0.032035, loss_fp: 0.004960, loss_freq: 0.049478
[16:31:10.058] iteration 11153: loss: 0.070223, loss_s1: 0.056190, loss_fp: 0.002475, loss_freq: 0.040580
[16:31:10.684] iteration 11154: loss: 0.085301, loss_s1: 0.051738, loss_fp: 0.001389, loss_freq: 0.055990
[16:31:11.309] iteration 11155: loss: 0.055238, loss_s1: 0.024526, loss_fp: 0.001143, loss_freq: 0.006659
[16:31:11.930] iteration 11156: loss: 0.046542, loss_s1: 0.032205, loss_fp: 0.000340, loss_freq: 0.005032
[16:31:12.556] iteration 11157: loss: 0.087708, loss_s1: 0.077107, loss_fp: 0.005456, loss_freq: 0.054824
[16:31:13.178] iteration 11158: loss: 0.058270, loss_s1: 0.012875, loss_fp: 0.002658, loss_freq: 0.006208
[16:31:13.801] iteration 11159: loss: 0.076431, loss_s1: 0.074255, loss_fp: 0.007122, loss_freq: 0.027252
[16:31:14.424] iteration 11160: loss: 0.089981, loss_s1: 0.093549, loss_fp: 0.000581, loss_freq: 0.043128
[16:31:15.045] iteration 11161: loss: 0.058567, loss_s1: 0.032166, loss_fp: 0.001936, loss_freq: 0.025544
[16:31:15.668] iteration 11162: loss: 0.068124, loss_s1: 0.037841, loss_fp: 0.002167, loss_freq: 0.040996
[16:31:16.295] iteration 11163: loss: 0.076782, loss_s1: 0.050849, loss_fp: 0.002452, loss_freq: 0.037971
[16:31:16.920] iteration 11164: loss: 0.045965, loss_s1: 0.020602, loss_fp: 0.000447, loss_freq: 0.013248
[16:31:17.544] iteration 11165: loss: 0.082561, loss_s1: 0.054622, loss_fp: 0.005291, loss_freq: 0.059000
[16:31:18.168] iteration 11166: loss: 0.054811, loss_s1: 0.033722, loss_fp: 0.002319, loss_freq: 0.013651
[16:31:18.797] iteration 11167: loss: 0.086989, loss_s1: 0.036137, loss_fp: 0.005553, loss_freq: 0.026441
[16:31:19.425] iteration 11168: loss: 0.036741, loss_s1: 0.016074, loss_fp: 0.001759, loss_freq: 0.015283
[16:31:20.048] iteration 11169: loss: 0.058362, loss_s1: 0.032943, loss_fp: 0.003397, loss_freq: 0.027424
[16:31:20.673] iteration 11170: loss: 0.054022, loss_s1: 0.029538, loss_fp: 0.000867, loss_freq: 0.028297
[16:31:21.296] iteration 11171: loss: 0.069714, loss_s1: 0.062806, loss_fp: 0.004314, loss_freq: 0.007277
[16:31:21.919] iteration 11172: loss: 0.061962, loss_s1: 0.051318, loss_fp: 0.004528, loss_freq: 0.014482
[16:31:22.557] iteration 11173: loss: 0.077761, loss_s1: 0.036824, loss_fp: 0.006932, loss_freq: 0.050570
[16:31:23.181] iteration 11174: loss: 0.052207, loss_s1: 0.027905, loss_fp: 0.007946, loss_freq: 0.021081
[16:31:23.803] iteration 11175: loss: 0.092136, loss_s1: 0.058771, loss_fp: 0.006708, loss_freq: 0.071145
[16:31:24.424] iteration 11176: loss: 0.063913, loss_s1: 0.042505, loss_fp: 0.002084, loss_freq: 0.024494
[16:31:25.051] iteration 11177: loss: 0.049675, loss_s1: 0.042760, loss_fp: 0.001172, loss_freq: 0.019699
[16:31:25.672] iteration 11178: loss: 0.059706, loss_s1: 0.044318, loss_fp: 0.002331, loss_freq: 0.019889
[16:31:26.296] iteration 11179: loss: 0.069404, loss_s1: 0.020585, loss_fp: 0.002312, loss_freq: 0.020789
[16:31:26.918] iteration 11180: loss: 0.077343, loss_s1: 0.068413, loss_fp: 0.003757, loss_freq: 0.033555
[16:31:27.542] iteration 11181: loss: 0.081090, loss_s1: 0.056721, loss_fp: 0.000918, loss_freq: 0.038253
[16:31:28.169] iteration 11182: loss: 0.064359, loss_s1: 0.058630, loss_fp: 0.001209, loss_freq: 0.017596
[16:31:28.805] iteration 11183: loss: 0.068548, loss_s1: 0.055679, loss_fp: 0.000974, loss_freq: 0.018820
[16:31:29.433] iteration 11184: loss: 0.061889, loss_s1: 0.044740, loss_fp: 0.001445, loss_freq: 0.030758
[16:31:30.095] iteration 11185: loss: 0.080105, loss_s1: 0.060455, loss_fp: 0.000729, loss_freq: 0.027893
[16:31:30.760] iteration 11186: loss: 0.088082, loss_s1: 0.072555, loss_fp: 0.001992, loss_freq: 0.068707
[16:31:31.424] iteration 11187: loss: 0.089747, loss_s1: 0.103238, loss_fp: 0.005333, loss_freq: 0.016761
[16:31:32.092] iteration 11188: loss: 0.055906, loss_s1: 0.051257, loss_fp: 0.001847, loss_freq: 0.008932
[16:31:32.721] iteration 11189: loss: 0.070180, loss_s1: 0.029713, loss_fp: 0.003379, loss_freq: 0.039496
[16:31:33.350] iteration 11190: loss: 0.085184, loss_s1: 0.075304, loss_fp: 0.006079, loss_freq: 0.036875
[16:31:33.977] iteration 11191: loss: 0.074441, loss_s1: 0.074127, loss_fp: 0.002588, loss_freq: 0.032578
[16:31:34.605] iteration 11192: loss: 0.091198, loss_s1: 0.095337, loss_fp: 0.012599, loss_freq: 0.035329
[16:31:35.236] iteration 11193: loss: 0.058517, loss_s1: 0.030715, loss_fp: 0.013940, loss_freq: 0.026395
[16:31:35.863] iteration 11194: loss: 0.147861, loss_s1: 0.113728, loss_fp: 0.004243, loss_freq: 0.129824
[16:31:36.491] iteration 11195: loss: 0.050802, loss_s1: 0.035034, loss_fp: 0.000776, loss_freq: 0.014166
[16:31:37.118] iteration 11196: loss: 0.092494, loss_s1: 0.048087, loss_fp: 0.001104, loss_freq: 0.037315
[16:31:37.743] iteration 11197: loss: 0.059112, loss_s1: 0.048175, loss_fp: 0.000700, loss_freq: 0.010161
[16:31:38.369] iteration 11198: loss: 0.071135, loss_s1: 0.039964, loss_fp: 0.002503, loss_freq: 0.050170
[16:31:38.996] iteration 11199: loss: 0.063614, loss_s1: 0.038961, loss_fp: 0.000437, loss_freq: 0.035281
[16:31:39.625] iteration 11200: loss: 0.063977, loss_s1: 0.046733, loss_fp: 0.000856, loss_freq: 0.027020
[16:31:42.815] iteration 11200 : mean_dice : 0.710482
[16:31:43.470] iteration 11201: loss: 0.072117, loss_s1: 0.044943, loss_fp: 0.000591, loss_freq: 0.015224
[16:31:44.096] iteration 11202: loss: 0.115883, loss_s1: 0.067680, loss_fp: 0.001439, loss_freq: 0.024374
[16:31:44.724] iteration 11203: loss: 0.052094, loss_s1: 0.026990, loss_fp: 0.002727, loss_freq: 0.019291
[16:31:45.350] iteration 11204: loss: 0.043951, loss_s1: 0.033542, loss_fp: 0.000797, loss_freq: 0.009549
[16:31:45.977] iteration 11205: loss: 0.041260, loss_s1: 0.012371, loss_fp: 0.002473, loss_freq: 0.029335
[16:31:46.600] iteration 11206: loss: 0.054624, loss_s1: 0.012185, loss_fp: 0.000987, loss_freq: 0.030697
[16:31:47.229] iteration 11207: loss: 0.061045, loss_s1: 0.024271, loss_fp: 0.001306, loss_freq: 0.023844
[16:31:47.855] iteration 11208: loss: 0.078301, loss_s1: 0.058973, loss_fp: 0.003482, loss_freq: 0.015028
[16:31:48.478] iteration 11209: loss: 0.109511, loss_s1: 0.106799, loss_fp: 0.009746, loss_freq: 0.052256
[16:31:49.103] iteration 11210: loss: 0.110999, loss_s1: 0.109735, loss_fp: 0.004202, loss_freq: 0.063486
[16:31:49.731] iteration 11211: loss: 0.071232, loss_s1: 0.035311, loss_fp: 0.006445, loss_freq: 0.043030
[16:31:50.354] iteration 11212: loss: 0.093529, loss_s1: 0.053436, loss_fp: 0.005284, loss_freq: 0.059458
[16:31:50.982] iteration 11213: loss: 0.111539, loss_s1: 0.116650, loss_fp: 0.006028, loss_freq: 0.043132
[16:31:51.606] iteration 11214: loss: 0.078441, loss_s1: 0.047711, loss_fp: 0.002028, loss_freq: 0.023514
[16:31:52.235] iteration 11215: loss: 0.059041, loss_s1: 0.043180, loss_fp: 0.007637, loss_freq: 0.027895
[16:31:52.858] iteration 11216: loss: 0.050476, loss_s1: 0.016893, loss_fp: 0.000738, loss_freq: 0.012843
[16:31:53.480] iteration 11217: loss: 0.115300, loss_s1: 0.130882, loss_fp: 0.002758, loss_freq: 0.036990
[16:31:54.139] iteration 11218: loss: 0.126932, loss_s1: 0.105457, loss_fp: 0.004950, loss_freq: 0.084849
[16:31:54.794] iteration 11219: loss: 0.080701, loss_s1: 0.068579, loss_fp: 0.001138, loss_freq: 0.040436
[16:31:55.451] iteration 11220: loss: 0.060137, loss_s1: 0.034036, loss_fp: 0.002244, loss_freq: 0.019628
[16:31:56.099] iteration 11221: loss: 0.072638, loss_s1: 0.034205, loss_fp: 0.001918, loss_freq: 0.065349
[16:31:56.721] iteration 11222: loss: 0.081471, loss_s1: 0.073119, loss_fp: 0.008661, loss_freq: 0.035132
[16:31:57.354] iteration 11223: loss: 0.085271, loss_s1: 0.056213, loss_fp: 0.003937, loss_freq: 0.049090
[16:31:57.976] iteration 11224: loss: 0.043991, loss_s1: 0.027341, loss_fp: 0.003679, loss_freq: 0.008131
[16:31:58.605] iteration 11225: loss: 0.086465, loss_s1: 0.062922, loss_fp: 0.001599, loss_freq: 0.031827
[16:31:59.234] iteration 11226: loss: 0.074215, loss_s1: 0.059576, loss_fp: 0.005952, loss_freq: 0.019763
[16:31:59.860] iteration 11227: loss: 0.046961, loss_s1: 0.016422, loss_fp: 0.003298, loss_freq: 0.023944
[16:32:00.483] iteration 11228: loss: 0.095780, loss_s1: 0.096740, loss_fp: 0.005857, loss_freq: 0.031874
[16:32:01.109] iteration 11229: loss: 0.121157, loss_s1: 0.090260, loss_fp: 0.000476, loss_freq: 0.116421
[16:32:01.734] iteration 11230: loss: 0.092816, loss_s1: 0.032104, loss_fp: 0.001861, loss_freq: 0.115551
[16:32:02.363] iteration 11231: loss: 0.077808, loss_s1: 0.020793, loss_fp: 0.002998, loss_freq: 0.068738
[16:32:02.989] iteration 11232: loss: 0.156261, loss_s1: 0.175840, loss_fp: 0.010703, loss_freq: 0.045240
[16:32:03.616] iteration 11233: loss: 0.072585, loss_s1: 0.056210, loss_fp: 0.000610, loss_freq: 0.019628
[16:32:04.241] iteration 11234: loss: 0.078256, loss_s1: 0.047157, loss_fp: 0.000952, loss_freq: 0.027790
[16:32:04.863] iteration 11235: loss: 0.092091, loss_s1: 0.063184, loss_fp: 0.032929, loss_freq: 0.014014
[16:32:05.518] iteration 11236: loss: 0.094266, loss_s1: 0.033214, loss_fp: 0.005117, loss_freq: 0.020411
[16:32:06.148] iteration 11237: loss: 0.154223, loss_s1: 0.052239, loss_fp: 0.021010, loss_freq: 0.098013
[16:32:06.772] iteration 11238: loss: 0.051135, loss_s1: 0.035822, loss_fp: 0.005069, loss_freq: 0.017508
[16:32:07.397] iteration 11239: loss: 0.064041, loss_s1: 0.053410, loss_fp: 0.007303, loss_freq: 0.024240
[16:32:08.020] iteration 11240: loss: 0.109550, loss_s1: 0.083042, loss_fp: 0.006630, loss_freq: 0.077133
[16:32:08.649] iteration 11241: loss: 0.113051, loss_s1: 0.092859, loss_fp: 0.001800, loss_freq: 0.086509
[16:32:09.273] iteration 11242: loss: 0.047508, loss_s1: 0.027671, loss_fp: 0.001896, loss_freq: 0.013957
[16:32:09.897] iteration 11243: loss: 0.098043, loss_s1: 0.095672, loss_fp: 0.005978, loss_freq: 0.040063
[16:32:10.525] iteration 11244: loss: 0.075639, loss_s1: 0.030212, loss_fp: 0.001422, loss_freq: 0.075139
[16:32:11.147] iteration 11245: loss: 0.068891, loss_s1: 0.070128, loss_fp: 0.009511, loss_freq: 0.024196
[16:32:11.771] iteration 11246: loss: 0.057037, loss_s1: 0.028395, loss_fp: 0.000633, loss_freq: 0.035518
[16:32:12.396] iteration 11247: loss: 0.055856, loss_s1: 0.030081, loss_fp: 0.000925, loss_freq: 0.018865
[16:32:13.016] iteration 11248: loss: 0.062848, loss_s1: 0.036463, loss_fp: 0.001307, loss_freq: 0.015122
[16:32:13.676] iteration 11249: loss: 0.126192, loss_s1: 0.089150, loss_fp: 0.014185, loss_freq: 0.059272
[16:32:14.335] iteration 11250: loss: 0.068086, loss_s1: 0.047046, loss_fp: 0.003257, loss_freq: 0.022670
[16:32:14.994] iteration 11251: loss: 0.060170, loss_s1: 0.048101, loss_fp: 0.002404, loss_freq: 0.013102
[16:32:15.618] iteration 11252: loss: 0.105177, loss_s1: 0.069939, loss_fp: 0.003278, loss_freq: 0.032265
[16:32:16.245] iteration 11253: loss: 0.068292, loss_s1: 0.032275, loss_fp: 0.000515, loss_freq: 0.038911
[16:32:16.868] iteration 11254: loss: 0.054013, loss_s1: 0.033045, loss_fp: 0.009725, loss_freq: 0.020455
[16:32:17.515] iteration 11255: loss: 0.090125, loss_s1: 0.075745, loss_fp: 0.009954, loss_freq: 0.016491
[16:32:18.151] iteration 11256: loss: 0.086938, loss_s1: 0.069720, loss_fp: 0.003423, loss_freq: 0.062613
[16:32:18.792] iteration 11257: loss: 0.054069, loss_s1: 0.041772, loss_fp: 0.004770, loss_freq: 0.023333
[16:32:19.427] iteration 11258: loss: 0.041694, loss_s1: 0.017818, loss_fp: 0.005485, loss_freq: 0.009782
[16:32:20.053] iteration 11259: loss: 0.086798, loss_s1: 0.053752, loss_fp: 0.003119, loss_freq: 0.049845
[16:32:20.677] iteration 11260: loss: 0.050573, loss_s1: 0.029519, loss_fp: 0.002566, loss_freq: 0.021967
[16:32:21.300] iteration 11261: loss: 0.113562, loss_s1: 0.113972, loss_fp: 0.006114, loss_freq: 0.064606
[16:32:21.924] iteration 11262: loss: 0.059654, loss_s1: 0.035646, loss_fp: 0.002300, loss_freq: 0.037352
[16:32:22.549] iteration 11263: loss: 0.075752, loss_s1: 0.069955, loss_fp: 0.004606, loss_freq: 0.027061
[16:32:23.175] iteration 11264: loss: 0.042699, loss_s1: 0.020478, loss_fp: 0.001305, loss_freq: 0.020178
[16:32:23.803] iteration 11265: loss: 0.047964, loss_s1: 0.032441, loss_fp: 0.001535, loss_freq: 0.013587
[16:32:24.430] iteration 11266: loss: 0.065709, loss_s1: 0.023505, loss_fp: 0.005452, loss_freq: 0.028463
[16:32:25.059] iteration 11267: loss: 0.069531, loss_s1: 0.046058, loss_fp: 0.001644, loss_freq: 0.028743
[16:32:25.687] iteration 11268: loss: 0.057347, loss_s1: 0.022449, loss_fp: 0.005232, loss_freq: 0.015950
[16:32:26.310] iteration 11269: loss: 0.072371, loss_s1: 0.046480, loss_fp: 0.004093, loss_freq: 0.016451
[16:32:26.933] iteration 11270: loss: 0.090429, loss_s1: 0.094179, loss_fp: 0.002090, loss_freq: 0.034973
[16:32:27.956] iteration 11271: loss: 0.051258, loss_s1: 0.024403, loss_fp: 0.000297, loss_freq: 0.015724
[16:32:28.609] iteration 11272: loss: 0.065565, loss_s1: 0.050176, loss_fp: 0.003707, loss_freq: 0.026470
[16:32:29.267] iteration 11273: loss: 0.064585, loss_s1: 0.044092, loss_fp: 0.001556, loss_freq: 0.026823
[16:32:29.919] iteration 11274: loss: 0.052956, loss_s1: 0.029140, loss_fp: 0.001362, loss_freq: 0.010698
[16:32:30.544] iteration 11275: loss: 0.081520, loss_s1: 0.044040, loss_fp: 0.008352, loss_freq: 0.033656
[16:32:31.168] iteration 11276: loss: 0.130514, loss_s1: 0.065721, loss_fp: 0.002396, loss_freq: 0.056085
[16:32:31.793] iteration 11277: loss: 0.077203, loss_s1: 0.085653, loss_fp: 0.002776, loss_freq: 0.030371
[16:32:32.418] iteration 11278: loss: 0.062453, loss_s1: 0.052120, loss_fp: 0.002336, loss_freq: 0.024178
[16:32:33.062] iteration 11279: loss: 0.079489, loss_s1: 0.043939, loss_fp: 0.013886, loss_freq: 0.038007
[16:32:33.699] iteration 11280: loss: 0.078815, loss_s1: 0.081664, loss_fp: 0.005555, loss_freq: 0.023942
[16:32:34.324] iteration 11281: loss: 0.035550, loss_s1: 0.008913, loss_fp: 0.003277, loss_freq: 0.013796
[16:32:34.951] iteration 11282: loss: 0.069930, loss_s1: 0.051159, loss_fp: 0.002531, loss_freq: 0.032289
[16:32:35.575] iteration 11283: loss: 0.073451, loss_s1: 0.041195, loss_fp: 0.006825, loss_freq: 0.064577
[16:32:36.200] iteration 11284: loss: 0.084501, loss_s1: 0.030616, loss_fp: 0.001574, loss_freq: 0.059272
[16:32:36.857] iteration 11285: loss: 0.067190, loss_s1: 0.052250, loss_fp: 0.003386, loss_freq: 0.026531
[16:32:37.509] iteration 11286: loss: 0.099427, loss_s1: 0.076731, loss_fp: 0.003667, loss_freq: 0.044594
[16:32:38.165] iteration 11287: loss: 0.079396, loss_s1: 0.076837, loss_fp: 0.003166, loss_freq: 0.015218
[16:32:38.801] iteration 11288: loss: 0.064111, loss_s1: 0.031465, loss_fp: 0.006778, loss_freq: 0.037265
[16:32:39.427] iteration 11289: loss: 0.073865, loss_s1: 0.053347, loss_fp: 0.001656, loss_freq: 0.029754
[16:32:40.048] iteration 11290: loss: 0.075539, loss_s1: 0.074953, loss_fp: 0.003586, loss_freq: 0.016804
[16:32:40.671] iteration 11291: loss: 0.051152, loss_s1: 0.026558, loss_fp: 0.006418, loss_freq: 0.011690
[16:32:41.329] iteration 11292: loss: 0.046748, loss_s1: 0.028524, loss_fp: 0.001001, loss_freq: 0.018189
[16:32:41.996] iteration 11293: loss: 0.075826, loss_s1: 0.051221, loss_fp: 0.002680, loss_freq: 0.022369
[16:32:42.691] iteration 11294: loss: 0.162663, loss_s1: 0.060780, loss_fp: 0.001808, loss_freq: 0.223683
[16:32:43.329] iteration 11295: loss: 0.047047, loss_s1: 0.024651, loss_fp: 0.001546, loss_freq: 0.030011
[16:32:43.960] iteration 11296: loss: 0.085650, loss_s1: 0.080289, loss_fp: 0.001986, loss_freq: 0.023320
[16:32:44.585] iteration 11297: loss: 0.055895, loss_s1: 0.050956, loss_fp: 0.003008, loss_freq: 0.014612
[16:32:45.209] iteration 11298: loss: 0.105853, loss_s1: 0.075738, loss_fp: 0.012419, loss_freq: 0.057223
[16:32:45.834] iteration 11299: loss: 0.086743, loss_s1: 0.063132, loss_fp: 0.003009, loss_freq: 0.053002
[16:32:46.458] iteration 11300: loss: 0.068037, loss_s1: 0.077179, loss_fp: 0.000521, loss_freq: 0.014104
[16:32:47.088] iteration 11301: loss: 0.050395, loss_s1: 0.037330, loss_fp: 0.002226, loss_freq: 0.013764
[16:32:47.750] iteration 11302: loss: 0.084378, loss_s1: 0.070644, loss_fp: 0.010299, loss_freq: 0.012076
[16:32:48.409] iteration 11303: loss: 0.050403, loss_s1: 0.029878, loss_fp: 0.001836, loss_freq: 0.026412
[16:32:49.063] iteration 11304: loss: 0.066528, loss_s1: 0.041190, loss_fp: 0.001920, loss_freq: 0.013277
[16:32:49.717] iteration 11305: loss: 0.078610, loss_s1: 0.039424, loss_fp: 0.000590, loss_freq: 0.031674
[16:32:50.346] iteration 11306: loss: 0.072104, loss_s1: 0.056101, loss_fp: 0.002317, loss_freq: 0.034465
[16:32:50.970] iteration 11307: loss: 0.081739, loss_s1: 0.055571, loss_fp: 0.004279, loss_freq: 0.028487
[16:32:51.594] iteration 11308: loss: 0.063621, loss_s1: 0.029234, loss_fp: 0.006637, loss_freq: 0.029543
[16:32:52.217] iteration 11309: loss: 0.117157, loss_s1: 0.093872, loss_fp: 0.003058, loss_freq: 0.073224
[16:32:52.846] iteration 11310: loss: 0.062821, loss_s1: 0.029699, loss_fp: 0.001209, loss_freq: 0.041176
[16:32:53.811] iteration 11311: loss: 0.070611, loss_s1: 0.038956, loss_fp: 0.000610, loss_freq: 0.031202
[16:32:54.624] iteration 11312: loss: 0.099001, loss_s1: 0.106480, loss_fp: 0.006784, loss_freq: 0.045192
[16:32:55.363] iteration 11313: loss: 0.071549, loss_s1: 0.050145, loss_fp: 0.001347, loss_freq: 0.050476
[16:32:55.996] iteration 11314: loss: 0.048125, loss_s1: 0.025715, loss_fp: 0.002803, loss_freq: 0.029138
[16:32:56.624] iteration 11315: loss: 0.081476, loss_s1: 0.034312, loss_fp: 0.005394, loss_freq: 0.076739
[16:32:57.247] iteration 11316: loss: 0.065625, loss_s1: 0.051908, loss_fp: 0.003086, loss_freq: 0.019831
[16:32:57.870] iteration 11317: loss: 0.035150, loss_s1: 0.021815, loss_fp: 0.003194, loss_freq: 0.004847
[16:32:58.490] iteration 11318: loss: 0.066160, loss_s1: 0.070350, loss_fp: 0.004084, loss_freq: 0.020932
[16:32:59.112] iteration 11319: loss: 0.065052, loss_s1: 0.047115, loss_fp: 0.002122, loss_freq: 0.023788
[16:32:59.735] iteration 11320: loss: 0.053844, loss_s1: 0.020527, loss_fp: 0.002007, loss_freq: 0.038153
[16:33:00.361] iteration 11321: loss: 0.096528, loss_s1: 0.074151, loss_fp: 0.002053, loss_freq: 0.057283
[16:33:00.984] iteration 11322: loss: 0.098925, loss_s1: 0.038414, loss_fp: 0.004653, loss_freq: 0.059148
[16:33:01.608] iteration 11323: loss: 0.066893, loss_s1: 0.042306, loss_fp: 0.005537, loss_freq: 0.026241
[16:33:02.232] iteration 11324: loss: 0.092746, loss_s1: 0.036223, loss_fp: 0.003280, loss_freq: 0.037714
[16:33:02.856] iteration 11325: loss: 0.060621, loss_s1: 0.032865, loss_fp: 0.003050, loss_freq: 0.016465
[16:33:03.485] iteration 11326: loss: 0.091021, loss_s1: 0.084352, loss_fp: 0.001497, loss_freq: 0.017175
[16:33:04.110] iteration 11327: loss: 0.056477, loss_s1: 0.032648, loss_fp: 0.007193, loss_freq: 0.015012
[16:33:04.735] iteration 11328: loss: 0.061710, loss_s1: 0.028531, loss_fp: 0.006974, loss_freq: 0.009458
[16:33:05.360] iteration 11329: loss: 0.052624, loss_s1: 0.017706, loss_fp: 0.003313, loss_freq: 0.033838
[16:33:05.992] iteration 11330: loss: 0.034329, loss_s1: 0.014861, loss_fp: 0.002729, loss_freq: 0.018027
[16:33:06.615] iteration 11331: loss: 0.062471, loss_s1: 0.022408, loss_fp: 0.001675, loss_freq: 0.026811
[16:33:07.243] iteration 11332: loss: 0.049875, loss_s1: 0.023536, loss_fp: 0.008035, loss_freq: 0.015075
[16:33:07.868] iteration 11333: loss: 0.101959, loss_s1: 0.064718, loss_fp: 0.001436, loss_freq: 0.028066
[16:33:08.492] iteration 11334: loss: 0.067538, loss_s1: 0.019776, loss_fp: 0.002198, loss_freq: 0.051494
[16:33:09.116] iteration 11335: loss: 0.048038, loss_s1: 0.018540, loss_fp: 0.008850, loss_freq: 0.014323
[16:33:09.739] iteration 11336: loss: 0.100324, loss_s1: 0.052336, loss_fp: 0.006739, loss_freq: 0.066741
[16:33:10.367] iteration 11337: loss: 0.067223, loss_s1: 0.029474, loss_fp: 0.000625, loss_freq: 0.027850
[16:33:10.993] iteration 11338: loss: 0.068817, loss_s1: 0.051691, loss_fp: 0.011233, loss_freq: 0.033134
[16:33:11.621] iteration 11339: loss: 0.064167, loss_s1: 0.044080, loss_fp: 0.005019, loss_freq: 0.014973
[16:33:12.245] iteration 11340: loss: 0.075704, loss_s1: 0.037075, loss_fp: 0.001245, loss_freq: 0.032922
[16:33:12.867] iteration 11341: loss: 0.076546, loss_s1: 0.052108, loss_fp: 0.005691, loss_freq: 0.033818
[16:33:13.493] iteration 11342: loss: 0.090692, loss_s1: 0.082198, loss_fp: 0.002529, loss_freq: 0.032028
[16:33:14.117] iteration 11343: loss: 0.098353, loss_s1: 0.097763, loss_fp: 0.002517, loss_freq: 0.032461
[16:33:14.739] iteration 11344: loss: 0.054880, loss_s1: 0.030821, loss_fp: 0.002408, loss_freq: 0.030056
[16:33:15.393] iteration 11345: loss: 0.100900, loss_s1: 0.083564, loss_fp: 0.000835, loss_freq: 0.052088
[16:33:16.048] iteration 11346: loss: 0.067399, loss_s1: 0.053920, loss_fp: 0.001388, loss_freq: 0.017931
[16:33:16.703] iteration 11347: loss: 0.115273, loss_s1: 0.081042, loss_fp: 0.005900, loss_freq: 0.058515
[16:33:17.360] iteration 11348: loss: 0.066082, loss_s1: 0.050851, loss_fp: 0.000864, loss_freq: 0.039397
[16:33:18.042] iteration 11349: loss: 0.039245, loss_s1: 0.037067, loss_fp: 0.003054, loss_freq: 0.004397
[16:33:18.696] iteration 11350: loss: 0.062663, loss_s1: 0.038878, loss_fp: 0.001781, loss_freq: 0.042026
[16:33:19.329] iteration 11351: loss: 0.103189, loss_s1: 0.085563, loss_fp: 0.004207, loss_freq: 0.068053
[16:33:19.955] iteration 11352: loss: 0.135129, loss_s1: 0.106010, loss_fp: 0.000934, loss_freq: 0.121901
[16:33:20.579] iteration 11353: loss: 0.111303, loss_s1: 0.089207, loss_fp: 0.001628, loss_freq: 0.093711
[16:33:21.206] iteration 11354: loss: 0.103374, loss_s1: 0.078110, loss_fp: 0.001715, loss_freq: 0.029590
[16:33:21.837] iteration 11355: loss: 0.128149, loss_s1: 0.134158, loss_fp: 0.006702, loss_freq: 0.051692
[16:33:22.464] iteration 11356: loss: 0.061330, loss_s1: 0.054059, loss_fp: 0.001118, loss_freq: 0.026221
[16:33:23.094] iteration 11357: loss: 0.200927, loss_s1: 0.075006, loss_fp: 0.010233, loss_freq: 0.016281
[16:33:23.719] iteration 11358: loss: 0.047422, loss_s1: 0.039821, loss_fp: 0.001154, loss_freq: 0.011789
[16:33:24.351] iteration 11359: loss: 0.077570, loss_s1: 0.014494, loss_fp: 0.002209, loss_freq: 0.024942
[16:33:25.035] iteration 11360: loss: 0.076557, loss_s1: 0.045197, loss_fp: 0.008334, loss_freq: 0.031656
[16:33:25.673] iteration 11361: loss: 0.063280, loss_s1: 0.009165, loss_fp: 0.000668, loss_freq: 0.016126
[16:33:26.296] iteration 11362: loss: 0.054992, loss_s1: 0.038360, loss_fp: 0.000721, loss_freq: 0.012859
[16:33:26.924] iteration 11363: loss: 0.134428, loss_s1: 0.055395, loss_fp: 0.002634, loss_freq: 0.053892
[16:33:27.549] iteration 11364: loss: 0.063865, loss_s1: 0.034074, loss_fp: 0.000534, loss_freq: 0.015894
[16:33:28.176] iteration 11365: loss: 0.065967, loss_s1: 0.059442, loss_fp: 0.003615, loss_freq: 0.023358
[16:33:28.800] iteration 11366: loss: 0.065351, loss_s1: 0.054968, loss_fp: 0.003878, loss_freq: 0.025956
[16:33:29.426] iteration 11367: loss: 0.065004, loss_s1: 0.046838, loss_fp: 0.001993, loss_freq: 0.028132
[16:33:30.049] iteration 11368: loss: 0.058257, loss_s1: 0.016478, loss_fp: 0.002905, loss_freq: 0.025434
[16:33:30.672] iteration 11369: loss: 0.099808, loss_s1: 0.090452, loss_fp: 0.000637, loss_freq: 0.026743
[16:33:31.293] iteration 11370: loss: 0.059706, loss_s1: 0.053658, loss_fp: 0.002120, loss_freq: 0.015554
[16:33:31.915] iteration 11371: loss: 0.071156, loss_s1: 0.062951, loss_fp: 0.005045, loss_freq: 0.020868
[16:33:32.538] iteration 11372: loss: 0.112273, loss_s1: 0.039419, loss_fp: 0.019035, loss_freq: 0.072311
[16:33:33.161] iteration 11373: loss: 0.104663, loss_s1: 0.071616, loss_fp: 0.000553, loss_freq: 0.073514
[16:33:33.784] iteration 11374: loss: 0.113096, loss_s1: 0.084230, loss_fp: 0.007293, loss_freq: 0.061423
[16:33:34.409] iteration 11375: loss: 0.097061, loss_s1: 0.045054, loss_fp: 0.005966, loss_freq: 0.020986
[16:33:35.031] iteration 11376: loss: 0.070055, loss_s1: 0.031238, loss_fp: 0.004349, loss_freq: 0.045434
[16:33:35.655] iteration 11377: loss: 0.087008, loss_s1: 0.041533, loss_fp: 0.001115, loss_freq: 0.021940
[16:33:36.282] iteration 11378: loss: 0.127538, loss_s1: 0.084325, loss_fp: 0.002590, loss_freq: 0.093268
[16:33:36.907] iteration 11379: loss: 0.140569, loss_s1: 0.099997, loss_fp: 0.013108, loss_freq: 0.093951
[16:33:37.532] iteration 11380: loss: 0.081497, loss_s1: 0.058382, loss_fp: 0.004862, loss_freq: 0.036574
[16:33:38.158] iteration 11381: loss: 0.090270, loss_s1: 0.040220, loss_fp: 0.008745, loss_freq: 0.049466
[16:33:38.781] iteration 11382: loss: 0.064642, loss_s1: 0.032332, loss_fp: 0.001386, loss_freq: 0.039347
[16:33:39.404] iteration 11383: loss: 0.134385, loss_s1: 0.059827, loss_fp: 0.005454, loss_freq: 0.063937
[16:33:40.030] iteration 11384: loss: 0.058384, loss_s1: 0.021387, loss_fp: 0.000922, loss_freq: 0.039251
[16:33:40.655] iteration 11385: loss: 0.067319, loss_s1: 0.036904, loss_fp: 0.000841, loss_freq: 0.008575
[16:33:41.278] iteration 11386: loss: 0.091068, loss_s1: 0.056729, loss_fp: 0.009178, loss_freq: 0.052807
[16:33:41.900] iteration 11387: loss: 0.109718, loss_s1: 0.101448, loss_fp: 0.001444, loss_freq: 0.049038
[16:33:42.523] iteration 11388: loss: 0.047526, loss_s1: 0.021031, loss_fp: 0.001192, loss_freq: 0.013167
[16:33:43.146] iteration 11389: loss: 0.057840, loss_s1: 0.024397, loss_fp: 0.001916, loss_freq: 0.041326
[16:33:43.769] iteration 11390: loss: 0.076723, loss_s1: 0.030679, loss_fp: 0.007092, loss_freq: 0.071354
[16:33:44.395] iteration 11391: loss: 0.049582, loss_s1: 0.007322, loss_fp: 0.003052, loss_freq: 0.039744
[16:33:45.019] iteration 11392: loss: 0.071034, loss_s1: 0.033510, loss_fp: 0.003508, loss_freq: 0.034626
[16:33:45.643] iteration 11393: loss: 0.056875, loss_s1: 0.030282, loss_fp: 0.003120, loss_freq: 0.018656
[16:33:46.266] iteration 11394: loss: 0.070637, loss_s1: 0.053838, loss_fp: 0.001226, loss_freq: 0.030629
[16:33:46.889] iteration 11395: loss: 0.057201, loss_s1: 0.023325, loss_fp: 0.001297, loss_freq: 0.036749
[16:33:47.513] iteration 11396: loss: 0.076902, loss_s1: 0.068140, loss_fp: 0.003678, loss_freq: 0.025424
[16:33:48.142] iteration 11397: loss: 0.047565, loss_s1: 0.022556, loss_fp: 0.003222, loss_freq: 0.011232
[16:33:48.765] iteration 11398: loss: 0.133419, loss_s1: 0.089510, loss_fp: 0.010242, loss_freq: 0.046363
[16:33:49.390] iteration 11399: loss: 0.072582, loss_s1: 0.055073, loss_fp: 0.004243, loss_freq: 0.024491
[16:33:50.020] iteration 11400: loss: 0.081680, loss_s1: 0.063830, loss_fp: 0.001641, loss_freq: 0.009041
[16:33:53.047] iteration 11400 : mean_dice : 0.659483
[16:33:53.688] iteration 11401: loss: 0.097059, loss_s1: 0.054722, loss_fp: 0.015804, loss_freq: 0.085583
[16:33:54.309] iteration 11402: loss: 0.104695, loss_s1: 0.086692, loss_fp: 0.000663, loss_freq: 0.036770
[16:33:54.933] iteration 11403: loss: 0.063944, loss_s1: 0.042028, loss_fp: 0.005386, loss_freq: 0.020679
[16:33:55.556] iteration 11404: loss: 0.073982, loss_s1: 0.034965, loss_fp: 0.002686, loss_freq: 0.030441
[16:33:56.181] iteration 11405: loss: 0.079744, loss_s1: 0.048657, loss_fp: 0.001964, loss_freq: 0.054622
[16:33:56.806] iteration 11406: loss: 0.069404, loss_s1: 0.063521, loss_fp: 0.013624, loss_freq: 0.014941
[16:33:57.428] iteration 11407: loss: 0.065171, loss_s1: 0.031000, loss_fp: 0.001926, loss_freq: 0.030158
[16:33:58.049] iteration 11408: loss: 0.059174, loss_s1: 0.026796, loss_fp: 0.004749, loss_freq: 0.036834
[16:33:58.672] iteration 11409: loss: 0.071155, loss_s1: 0.047364, loss_fp: 0.004043, loss_freq: 0.036060
[16:33:59.302] iteration 11410: loss: 0.091926, loss_s1: 0.056657, loss_fp: 0.004782, loss_freq: 0.038099
[16:33:59.929] iteration 11411: loss: 0.109301, loss_s1: 0.110794, loss_fp: 0.002309, loss_freq: 0.053189
[16:34:00.559] iteration 11412: loss: 0.079000, loss_s1: 0.068221, loss_fp: 0.002873, loss_freq: 0.027071
[16:34:01.188] iteration 11413: loss: 0.112409, loss_s1: 0.045203, loss_fp: 0.001815, loss_freq: 0.062242
[16:34:01.811] iteration 11414: loss: 0.093902, loss_s1: 0.079304, loss_fp: 0.007566, loss_freq: 0.027866
[16:34:02.436] iteration 11415: loss: 0.044556, loss_s1: 0.038478, loss_fp: 0.001397, loss_freq: 0.007154
[16:34:03.059] iteration 11416: loss: 0.090395, loss_s1: 0.070514, loss_fp: 0.012031, loss_freq: 0.014640
[16:34:03.684] iteration 11417: loss: 0.107886, loss_s1: 0.100309, loss_fp: 0.004684, loss_freq: 0.073084
[16:34:04.308] iteration 11418: loss: 0.087923, loss_s1: 0.055077, loss_fp: 0.002514, loss_freq: 0.044811
[16:34:04.931] iteration 11419: loss: 0.077972, loss_s1: 0.041142, loss_fp: 0.005165, loss_freq: 0.022883
[16:34:05.555] iteration 11420: loss: 0.101003, loss_s1: 0.074413, loss_fp: 0.002867, loss_freq: 0.041911
[16:34:06.181] iteration 11421: loss: 0.098821, loss_s1: 0.055632, loss_fp: 0.001624, loss_freq: 0.042430
[16:34:06.808] iteration 11422: loss: 0.127869, loss_s1: 0.148927, loss_fp: 0.013646, loss_freq: 0.047325
[16:34:07.439] iteration 11423: loss: 0.062321, loss_s1: 0.011820, loss_fp: 0.002596, loss_freq: 0.044373
[16:34:08.062] iteration 11424: loss: 0.064747, loss_s1: 0.054792, loss_fp: 0.004331, loss_freq: 0.013805
[16:34:08.687] iteration 11425: loss: 0.068390, loss_s1: 0.029125, loss_fp: 0.009393, loss_freq: 0.048099
[16:34:09.309] iteration 11426: loss: 0.053138, loss_s1: 0.035063, loss_fp: 0.001928, loss_freq: 0.021320
[16:34:09.933] iteration 11427: loss: 0.070836, loss_s1: 0.027242, loss_fp: 0.000922, loss_freq: 0.015108
[16:34:10.580] iteration 11428: loss: 0.106616, loss_s1: 0.075293, loss_fp: 0.007225, loss_freq: 0.071847
[16:34:11.254] iteration 11429: loss: 0.116301, loss_s1: 0.065775, loss_fp: 0.010334, loss_freq: 0.077864
[16:34:11.907] iteration 11430: loss: 0.111764, loss_s1: 0.092660, loss_fp: 0.016035, loss_freq: 0.016435
[16:34:12.562] iteration 11431: loss: 0.067790, loss_s1: 0.054254, loss_fp: 0.001947, loss_freq: 0.034688
[16:34:13.551] iteration 11432: loss: 0.071350, loss_s1: 0.066580, loss_fp: 0.001949, loss_freq: 0.007269
[16:34:14.190] iteration 11433: loss: 0.049046, loss_s1: 0.023665, loss_fp: 0.003097, loss_freq: 0.014608
[16:34:14.811] iteration 11434: loss: 0.075762, loss_s1: 0.043576, loss_fp: 0.001696, loss_freq: 0.042564
[16:34:15.434] iteration 11435: loss: 0.049639, loss_s1: 0.028419, loss_fp: 0.000342, loss_freq: 0.010902
[16:34:16.058] iteration 11436: loss: 0.086144, loss_s1: 0.066892, loss_fp: 0.000496, loss_freq: 0.015395
[16:34:16.679] iteration 11437: loss: 0.121388, loss_s1: 0.079655, loss_fp: 0.011203, loss_freq: 0.032507
[16:34:17.304] iteration 11438: loss: 0.053838, loss_s1: 0.037148, loss_fp: 0.000394, loss_freq: 0.033867
[16:34:17.931] iteration 11439: loss: 0.060201, loss_s1: 0.031925, loss_fp: 0.004835, loss_freq: 0.022278
[16:34:18.558] iteration 11440: loss: 0.065472, loss_s1: 0.058253, loss_fp: 0.002988, loss_freq: 0.023943
[16:34:19.183] iteration 11441: loss: 0.115316, loss_s1: 0.098529, loss_fp: 0.007987, loss_freq: 0.035089
[16:34:19.809] iteration 11442: loss: 0.055992, loss_s1: 0.014239, loss_fp: 0.001708, loss_freq: 0.022254
[16:34:20.431] iteration 11443: loss: 0.090887, loss_s1: 0.060331, loss_fp: 0.001157, loss_freq: 0.036750
[16:34:21.057] iteration 11444: loss: 0.068868, loss_s1: 0.043746, loss_fp: 0.002554, loss_freq: 0.051924
[16:34:21.678] iteration 11445: loss: 0.067381, loss_s1: 0.028060, loss_fp: 0.000847, loss_freq: 0.038768
[16:34:22.298] iteration 11446: loss: 0.037416, loss_s1: 0.019418, loss_fp: 0.000632, loss_freq: 0.014312
[16:34:22.925] iteration 11447: loss: 0.109299, loss_s1: 0.042435, loss_fp: 0.009511, loss_freq: 0.109912
[16:34:23.582] iteration 11448: loss: 0.074443, loss_s1: 0.070623, loss_fp: 0.006873, loss_freq: 0.017307
[16:34:24.210] iteration 11449: loss: 0.074334, loss_s1: 0.061916, loss_fp: 0.000813, loss_freq: 0.020156
[16:34:24.835] iteration 11450: loss: 0.062948, loss_s1: 0.018034, loss_fp: 0.000371, loss_freq: 0.024262
[16:34:25.458] iteration 11451: loss: 0.061717, loss_s1: 0.054964, loss_fp: 0.001057, loss_freq: 0.010133
[16:34:26.084] iteration 11452: loss: 0.062917, loss_s1: 0.051249, loss_fp: 0.001208, loss_freq: 0.017388
[16:34:26.708] iteration 11453: loss: 0.043887, loss_s1: 0.021477, loss_fp: 0.001889, loss_freq: 0.013695
[16:34:27.358] iteration 11454: loss: 0.059214, loss_s1: 0.023398, loss_fp: 0.000562, loss_freq: 0.007515
[16:34:28.035] iteration 11455: loss: 0.128188, loss_s1: 0.089646, loss_fp: 0.002273, loss_freq: 0.108825
[16:34:28.695] iteration 11456: loss: 0.034613, loss_s1: 0.012728, loss_fp: 0.000458, loss_freq: 0.018697
[16:34:29.395] iteration 11457: loss: 0.085240, loss_s1: 0.048031, loss_fp: 0.008516, loss_freq: 0.046422
[16:34:30.022] iteration 11458: loss: 0.041513, loss_s1: 0.021926, loss_fp: 0.000642, loss_freq: 0.013617
[16:34:30.647] iteration 11459: loss: 0.079307, loss_s1: 0.066263, loss_fp: 0.003668, loss_freq: 0.046758
[16:34:31.274] iteration 11460: loss: 0.068999, loss_s1: 0.047916, loss_fp: 0.008174, loss_freq: 0.043110
[16:34:31.899] iteration 11461: loss: 0.037809, loss_s1: 0.025865, loss_fp: 0.000596, loss_freq: 0.005374
[16:34:32.528] iteration 11462: loss: 0.069224, loss_s1: 0.074654, loss_fp: 0.003381, loss_freq: 0.019871
[16:34:33.153] iteration 11463: loss: 0.066482, loss_s1: 0.037027, loss_fp: 0.008146, loss_freq: 0.029045
[16:34:33.779] iteration 11464: loss: 0.065284, loss_s1: 0.052057, loss_fp: 0.002419, loss_freq: 0.025098
[16:34:34.403] iteration 11465: loss: 0.052222, loss_s1: 0.041095, loss_fp: 0.001032, loss_freq: 0.013787
[16:34:35.029] iteration 11466: loss: 0.104118, loss_s1: 0.065064, loss_fp: 0.002186, loss_freq: 0.028340
[16:34:35.655] iteration 11467: loss: 0.071545, loss_s1: 0.056717, loss_fp: 0.002083, loss_freq: 0.031779
[16:34:36.282] iteration 11468: loss: 0.086273, loss_s1: 0.057744, loss_fp: 0.007582, loss_freq: 0.016712
[16:34:36.911] iteration 11469: loss: 0.083202, loss_s1: 0.050858, loss_fp: 0.002790, loss_freq: 0.052139
[16:34:37.539] iteration 11470: loss: 0.115239, loss_s1: 0.096703, loss_fp: 0.001524, loss_freq: 0.063199
[16:34:38.169] iteration 11471: loss: 0.063146, loss_s1: 0.056856, loss_fp: 0.001288, loss_freq: 0.017811
[16:34:38.831] iteration 11472: loss: 0.072273, loss_s1: 0.043649, loss_fp: 0.004826, loss_freq: 0.035560
[16:34:39.488] iteration 11473: loss: 0.108275, loss_s1: 0.107250, loss_fp: 0.004452, loss_freq: 0.065435
[16:34:40.115] iteration 11474: loss: 0.077029, loss_s1: 0.047298, loss_fp: 0.001084, loss_freq: 0.044990
[16:34:40.741] iteration 11475: loss: 0.059223, loss_s1: 0.029112, loss_fp: 0.008220, loss_freq: 0.041016
[16:34:41.371] iteration 11476: loss: 0.072512, loss_s1: 0.025229, loss_fp: 0.003427, loss_freq: 0.038780
[16:34:42.060] iteration 11477: loss: 0.057447, loss_s1: 0.039853, loss_fp: 0.002406, loss_freq: 0.011443
[16:34:42.718] iteration 11478: loss: 0.056885, loss_s1: 0.033727, loss_fp: 0.002267, loss_freq: 0.031130
[16:34:43.367] iteration 11479: loss: 0.049604, loss_s1: 0.046244, loss_fp: 0.001388, loss_freq: 0.013592
[16:34:43.991] iteration 11480: loss: 0.069313, loss_s1: 0.070526, loss_fp: 0.002442, loss_freq: 0.013496
[16:34:44.614] iteration 11481: loss: 0.091253, loss_s1: 0.112383, loss_fp: 0.000856, loss_freq: 0.034363
[16:34:45.240] iteration 11482: loss: 0.089449, loss_s1: 0.059133, loss_fp: 0.004418, loss_freq: 0.067859
[16:34:45.862] iteration 11483: loss: 0.067562, loss_s1: 0.033171, loss_fp: 0.001387, loss_freq: 0.025631
[16:34:46.485] iteration 11484: loss: 0.049651, loss_s1: 0.014014, loss_fp: 0.005395, loss_freq: 0.024234
[16:34:47.110] iteration 11485: loss: 0.070780, loss_s1: 0.033269, loss_fp: 0.003865, loss_freq: 0.023154
[16:34:47.732] iteration 11486: loss: 0.070358, loss_s1: 0.038882, loss_fp: 0.000540, loss_freq: 0.010746
[16:34:48.394] iteration 11487: loss: 0.071402, loss_s1: 0.057883, loss_fp: 0.007443, loss_freq: 0.017810
[16:34:49.053] iteration 11488: loss: 0.049411, loss_s1: 0.034141, loss_fp: 0.002674, loss_freq: 0.007549
[16:34:49.725] iteration 11489: loss: 0.081569, loss_s1: 0.048204, loss_fp: 0.001360, loss_freq: 0.036805
[16:34:50.345] iteration 11490: loss: 0.038103, loss_s1: 0.015536, loss_fp: 0.001586, loss_freq: 0.010743
[16:34:50.967] iteration 11491: loss: 0.050562, loss_s1: 0.030015, loss_fp: 0.001882, loss_freq: 0.023389
[16:34:51.588] iteration 11492: loss: 0.070815, loss_s1: 0.069202, loss_fp: 0.000670, loss_freq: 0.024241
[16:34:52.211] iteration 11493: loss: 0.064183, loss_s1: 0.039984, loss_fp: 0.009104, loss_freq: 0.022275
[16:34:52.830] iteration 11494: loss: 0.050175, loss_s1: 0.029800, loss_fp: 0.001182, loss_freq: 0.023194
[16:34:53.452] iteration 11495: loss: 0.054605, loss_s1: 0.031349, loss_fp: 0.007002, loss_freq: 0.013540
[16:34:54.072] iteration 11496: loss: 0.070528, loss_s1: 0.061842, loss_fp: 0.006268, loss_freq: 0.020257
[16:34:54.693] iteration 11497: loss: 0.089763, loss_s1: 0.071050, loss_fp: 0.006006, loss_freq: 0.069431
[16:34:55.316] iteration 11498: loss: 0.082122, loss_s1: 0.048011, loss_fp: 0.001488, loss_freq: 0.042334
[16:34:55.966] iteration 11499: loss: 0.055687, loss_s1: 0.043271, loss_fp: 0.002719, loss_freq: 0.024665
[16:34:56.624] iteration 11500: loss: 0.052566, loss_s1: 0.039377, loss_fp: 0.007153, loss_freq: 0.014747
[16:34:57.283] iteration 11501: loss: 0.104563, loss_s1: 0.072725, loss_fp: 0.005752, loss_freq: 0.022026
[16:34:58.037] iteration 11502: loss: 0.102359, loss_s1: 0.092030, loss_fp: 0.002194, loss_freq: 0.056492
[16:34:59.003] iteration 11503: loss: 0.111197, loss_s1: 0.115438, loss_fp: 0.001643, loss_freq: 0.040119
[16:34:59.774] iteration 11504: loss: 0.059087, loss_s1: 0.045457, loss_fp: 0.001735, loss_freq: 0.013516
[16:35:00.514] iteration 11505: loss: 0.068907, loss_s1: 0.060814, loss_fp: 0.001812, loss_freq: 0.014507
[16:35:01.139] iteration 11506: loss: 0.077885, loss_s1: 0.074866, loss_fp: 0.000799, loss_freq: 0.044743
[16:35:01.769] iteration 11507: loss: 0.059297, loss_s1: 0.039457, loss_fp: 0.001251, loss_freq: 0.022220
[16:35:02.392] iteration 11508: loss: 0.048095, loss_s1: 0.027995, loss_fp: 0.000785, loss_freq: 0.025656
[16:35:03.019] iteration 11509: loss: 0.040068, loss_s1: 0.015176, loss_fp: 0.001031, loss_freq: 0.020915
[16:35:03.647] iteration 11510: loss: 0.054146, loss_s1: 0.019135, loss_fp: 0.001702, loss_freq: 0.011811
[16:35:04.274] iteration 11511: loss: 0.064318, loss_s1: 0.039460, loss_fp: 0.004390, loss_freq: 0.023144
[16:35:04.901] iteration 11512: loss: 0.056005, loss_s1: 0.041613, loss_fp: 0.005303, loss_freq: 0.022158
[16:35:05.529] iteration 11513: loss: 0.087644, loss_s1: 0.049281, loss_fp: 0.025901, loss_freq: 0.039814
[16:35:06.155] iteration 11514: loss: 0.117739, loss_s1: 0.094167, loss_fp: 0.016863, loss_freq: 0.070782
[16:35:06.782] iteration 11515: loss: 0.094092, loss_s1: 0.049380, loss_fp: 0.000865, loss_freq: 0.065339
[16:35:07.404] iteration 11516: loss: 0.127171, loss_s1: 0.115267, loss_fp: 0.004780, loss_freq: 0.080017
[16:35:08.029] iteration 11517: loss: 0.056611, loss_s1: 0.026801, loss_fp: 0.000911, loss_freq: 0.039068
[16:35:08.655] iteration 11518: loss: 0.187058, loss_s1: 0.113724, loss_fp: 0.001122, loss_freq: 0.029197
[16:35:09.279] iteration 11519: loss: 0.088132, loss_s1: 0.043741, loss_fp: 0.006135, loss_freq: 0.019182
[16:35:09.904] iteration 11520: loss: 0.059414, loss_s1: 0.057428, loss_fp: 0.003837, loss_freq: 0.013006
[16:35:10.533] iteration 11521: loss: 0.083369, loss_s1: 0.041538, loss_fp: 0.001364, loss_freq: 0.056072
[16:35:11.158] iteration 11522: loss: 0.068310, loss_s1: 0.046811, loss_fp: 0.000941, loss_freq: 0.028896
[16:35:11.785] iteration 11523: loss: 0.059282, loss_s1: 0.042589, loss_fp: 0.000925, loss_freq: 0.018768
[16:35:12.409] iteration 11524: loss: 0.098816, loss_s1: 0.027799, loss_fp: 0.001647, loss_freq: 0.025278
[16:35:13.034] iteration 11525: loss: 0.065609, loss_s1: 0.062965, loss_fp: 0.000849, loss_freq: 0.024001
[16:35:13.661] iteration 11526: loss: 0.050581, loss_s1: 0.019678, loss_fp: 0.004440, loss_freq: 0.029794
[16:35:14.289] iteration 11527: loss: 0.061966, loss_s1: 0.032728, loss_fp: 0.002859, loss_freq: 0.036658
[16:35:14.921] iteration 11528: loss: 0.067833, loss_s1: 0.044582, loss_fp: 0.001217, loss_freq: 0.026275
[16:35:15.544] iteration 11529: loss: 0.060001, loss_s1: 0.014394, loss_fp: 0.003260, loss_freq: 0.036003
[16:35:16.170] iteration 11530: loss: 0.064773, loss_s1: 0.029869, loss_fp: 0.002030, loss_freq: 0.012774
[16:35:16.796] iteration 11531: loss: 0.068822, loss_s1: 0.050513, loss_fp: 0.011000, loss_freq: 0.027158
[16:35:17.458] iteration 11532: loss: 0.105289, loss_s1: 0.093717, loss_fp: 0.005095, loss_freq: 0.036805
[16:35:18.143] iteration 11533: loss: 0.068483, loss_s1: 0.033798, loss_fp: 0.000941, loss_freq: 0.027796
[16:35:18.804] iteration 11534: loss: 0.076294, loss_s1: 0.043328, loss_fp: 0.003914, loss_freq: 0.043796
[16:35:19.461] iteration 11535: loss: 0.073136, loss_s1: 0.038421, loss_fp: 0.002607, loss_freq: 0.045650
[16:35:20.122] iteration 11536: loss: 0.065209, loss_s1: 0.026463, loss_fp: 0.006775, loss_freq: 0.013189
[16:35:20.783] iteration 11537: loss: 0.047127, loss_s1: 0.031429, loss_fp: 0.003685, loss_freq: 0.011978
[16:35:21.428] iteration 11538: loss: 0.073598, loss_s1: 0.040242, loss_fp: 0.000875, loss_freq: 0.006286
[16:35:22.057] iteration 11539: loss: 0.116391, loss_s1: 0.061875, loss_fp: 0.000931, loss_freq: 0.072553
[16:35:22.687] iteration 11540: loss: 0.153833, loss_s1: 0.141123, loss_fp: 0.010859, loss_freq: 0.064121
[16:35:23.317] iteration 11541: loss: 0.057483, loss_s1: 0.030230, loss_fp: 0.001294, loss_freq: 0.038836
[16:35:23.944] iteration 11542: loss: 0.073095, loss_s1: 0.043772, loss_fp: 0.003059, loss_freq: 0.027738
[16:35:24.570] iteration 11543: loss: 0.056743, loss_s1: 0.018966, loss_fp: 0.001467, loss_freq: 0.033013
[16:35:25.198] iteration 11544: loss: 0.075953, loss_s1: 0.051965, loss_fp: 0.003314, loss_freq: 0.052461
[16:35:25.824] iteration 11545: loss: 0.057773, loss_s1: 0.043056, loss_fp: 0.000907, loss_freq: 0.031906
[16:35:26.456] iteration 11546: loss: 0.044578, loss_s1: 0.024192, loss_fp: 0.000872, loss_freq: 0.005148
[16:35:27.084] iteration 11547: loss: 0.084815, loss_s1: 0.041001, loss_fp: 0.002077, loss_freq: 0.055753
[16:35:27.709] iteration 11548: loss: 0.065128, loss_s1: 0.039665, loss_fp: 0.007443, loss_freq: 0.047365
[16:35:28.336] iteration 11549: loss: 0.042481, loss_s1: 0.029376, loss_fp: 0.000253, loss_freq: 0.018276
[16:35:28.956] iteration 11550: loss: 0.056261, loss_s1: 0.037205, loss_fp: 0.005945, loss_freq: 0.021616
[16:35:29.581] iteration 11551: loss: 0.134502, loss_s1: 0.085858, loss_fp: 0.004379, loss_freq: 0.141374
[16:35:30.204] iteration 11552: loss: 0.053446, loss_s1: 0.027407, loss_fp: 0.005456, loss_freq: 0.024782
[16:35:30.830] iteration 11553: loss: 0.061181, loss_s1: 0.039907, loss_fp: 0.007656, loss_freq: 0.017272
[16:35:31.456] iteration 11554: loss: 0.081762, loss_s1: 0.090234, loss_fp: 0.000798, loss_freq: 0.021823
[16:35:32.080] iteration 11555: loss: 0.053990, loss_s1: 0.033556, loss_fp: 0.002484, loss_freq: 0.027161
[16:35:32.703] iteration 11556: loss: 0.063456, loss_s1: 0.021935, loss_fp: 0.002104, loss_freq: 0.043809
[16:35:33.333] iteration 11557: loss: 0.082272, loss_s1: 0.064113, loss_fp: 0.005402, loss_freq: 0.025665
[16:35:33.958] iteration 11558: loss: 0.061757, loss_s1: 0.047136, loss_fp: 0.001768, loss_freq: 0.019124
[16:35:34.589] iteration 11559: loss: 0.117299, loss_s1: 0.059024, loss_fp: 0.033189, loss_freq: 0.044120
[16:35:35.216] iteration 11560: loss: 0.059177, loss_s1: 0.045341, loss_fp: 0.002291, loss_freq: 0.026387
[16:35:35.841] iteration 11561: loss: 0.043376, loss_s1: 0.033566, loss_fp: 0.000803, loss_freq: 0.016291
[16:35:36.491] iteration 11562: loss: 0.107640, loss_s1: 0.071161, loss_fp: 0.001306, loss_freq: 0.097908
[16:35:37.152] iteration 11563: loss: 0.071975, loss_s1: 0.072535, loss_fp: 0.001780, loss_freq: 0.016211
[16:35:37.813] iteration 11564: loss: 0.097720, loss_s1: 0.086803, loss_fp: 0.005983, loss_freq: 0.047827
[16:35:38.469] iteration 11565: loss: 0.086386, loss_s1: 0.051594, loss_fp: 0.012212, loss_freq: 0.009697
[16:35:39.097] iteration 11566: loss: 0.085215, loss_s1: 0.059454, loss_fp: 0.003474, loss_freq: 0.048232
[16:35:39.721] iteration 11567: loss: 0.065039, loss_s1: 0.067476, loss_fp: 0.002427, loss_freq: 0.020244
[16:35:40.349] iteration 11568: loss: 0.042410, loss_s1: 0.016157, loss_fp: 0.000757, loss_freq: 0.015435
[16:35:40.979] iteration 11569: loss: 0.066998, loss_s1: 0.052376, loss_fp: 0.002903, loss_freq: 0.027823
[16:35:41.607] iteration 11570: loss: 0.072513, loss_s1: 0.067722, loss_fp: 0.014686, loss_freq: 0.022379
[16:35:42.236] iteration 11571: loss: 0.103864, loss_s1: 0.083772, loss_fp: 0.004346, loss_freq: 0.038223
[16:35:42.864] iteration 11572: loss: 0.084699, loss_s1: 0.057896, loss_fp: 0.001292, loss_freq: 0.045805
[16:35:43.493] iteration 11573: loss: 0.050276, loss_s1: 0.039930, loss_fp: 0.005384, loss_freq: 0.010980
[16:35:44.118] iteration 11574: loss: 0.104501, loss_s1: 0.079447, loss_fp: 0.023482, loss_freq: 0.054562
[16:35:44.744] iteration 11575: loss: 0.074188, loss_s1: 0.088347, loss_fp: 0.001813, loss_freq: 0.012946
[16:35:45.369] iteration 11576: loss: 0.054626, loss_s1: 0.037486, loss_fp: 0.006492, loss_freq: 0.013163
[16:35:45.996] iteration 11577: loss: 0.074733, loss_s1: 0.025841, loss_fp: 0.005285, loss_freq: 0.025852
[16:35:46.621] iteration 11578: loss: 0.126563, loss_s1: 0.103433, loss_fp: 0.009853, loss_freq: 0.092172
[16:35:47.246] iteration 11579: loss: 0.073634, loss_s1: 0.065494, loss_fp: 0.001308, loss_freq: 0.009739
[16:35:47.870] iteration 11580: loss: 0.059559, loss_s1: 0.032990, loss_fp: 0.001785, loss_freq: 0.015627
[16:35:48.498] iteration 11581: loss: 0.089871, loss_s1: 0.053247, loss_fp: 0.006055, loss_freq: 0.076184
[16:35:49.152] iteration 11582: loss: 0.081551, loss_s1: 0.061284, loss_fp: 0.003721, loss_freq: 0.055516
[16:35:49.788] iteration 11583: loss: 0.120498, loss_s1: 0.098811, loss_fp: 0.008795, loss_freq: 0.087259
[16:35:50.412] iteration 11584: loss: 0.057807, loss_s1: 0.036745, loss_fp: 0.006883, loss_freq: 0.029234
[16:35:51.036] iteration 11585: loss: 0.076367, loss_s1: 0.040855, loss_fp: 0.002363, loss_freq: 0.031959
[16:35:51.664] iteration 11586: loss: 0.039909, loss_s1: 0.015646, loss_fp: 0.001633, loss_freq: 0.014426
[16:35:52.292] iteration 11587: loss: 0.076927, loss_s1: 0.059048, loss_fp: 0.001267, loss_freq: 0.028597
[16:35:52.916] iteration 11588: loss: 0.042840, loss_s1: 0.023515, loss_fp: 0.000381, loss_freq: 0.013093
[16:35:53.545] iteration 11589: loss: 0.073169, loss_s1: 0.034023, loss_fp: 0.001175, loss_freq: 0.058671
[16:35:54.178] iteration 11590: loss: 0.073991, loss_s1: 0.057642, loss_fp: 0.012017, loss_freq: 0.024730
[16:35:54.799] iteration 11591: loss: 0.051760, loss_s1: 0.041250, loss_fp: 0.001906, loss_freq: 0.012204
[16:35:55.420] iteration 11592: loss: 0.055358, loss_s1: 0.024587, loss_fp: 0.001114, loss_freq: 0.023736
[16:35:56.432] iteration 11593: loss: 0.087200, loss_s1: 0.069968, loss_fp: 0.001875, loss_freq: 0.028996
[16:35:57.090] iteration 11594: loss: 0.092371, loss_s1: 0.060813, loss_fp: 0.016075, loss_freq: 0.044319
[16:35:57.740] iteration 11595: loss: 0.065402, loss_s1: 0.058648, loss_fp: 0.005233, loss_freq: 0.017550
[16:35:58.374] iteration 11596: loss: 0.056287, loss_s1: 0.031737, loss_fp: 0.001094, loss_freq: 0.025591
[16:35:59.003] iteration 11597: loss: 0.049973, loss_s1: 0.015206, loss_fp: 0.007408, loss_freq: 0.026184
[16:35:59.665] iteration 11598: loss: 0.119875, loss_s1: 0.043614, loss_fp: 0.012591, loss_freq: 0.051496
[16:36:00.324] iteration 11599: loss: 0.057730, loss_s1: 0.051179, loss_fp: 0.001432, loss_freq: 0.023737
[16:36:00.965] iteration 11600: loss: 0.070512, loss_s1: 0.031465, loss_fp: 0.003559, loss_freq: 0.050285
[16:36:04.055] iteration 11600 : mean_dice : 0.658784
[16:36:04.710] iteration 11601: loss: 0.083906, loss_s1: 0.073931, loss_fp: 0.002585, loss_freq: 0.022375
[16:36:05.333] iteration 11602: loss: 0.103087, loss_s1: 0.122763, loss_fp: 0.003188, loss_freq: 0.027674
[16:36:05.957] iteration 11603: loss: 0.047165, loss_s1: 0.021155, loss_fp: 0.002059, loss_freq: 0.029834
[16:36:06.578] iteration 11604: loss: 0.107669, loss_s1: 0.115300, loss_fp: 0.005389, loss_freq: 0.038757
[16:36:07.201] iteration 11605: loss: 0.086639, loss_s1: 0.057505, loss_fp: 0.005763, loss_freq: 0.069150
[16:36:07.825] iteration 11606: loss: 0.099670, loss_s1: 0.053439, loss_fp: 0.000926, loss_freq: 0.037234
[16:36:08.449] iteration 11607: loss: 0.053354, loss_s1: 0.049772, loss_fp: 0.003265, loss_freq: 0.008507
[16:36:09.070] iteration 11608: loss: 0.106238, loss_s1: 0.095557, loss_fp: 0.002715, loss_freq: 0.066748
[16:36:09.694] iteration 11609: loss: 0.094353, loss_s1: 0.024914, loss_fp: 0.000601, loss_freq: 0.011951
[16:36:10.313] iteration 11610: loss: 0.070538, loss_s1: 0.036946, loss_fp: 0.007083, loss_freq: 0.027941
[16:36:10.941] iteration 11611: loss: 0.064491, loss_s1: 0.045112, loss_fp: 0.001057, loss_freq: 0.017005
[16:36:11.565] iteration 11612: loss: 0.084468, loss_s1: 0.078770, loss_fp: 0.001710, loss_freq: 0.037686
[16:36:12.191] iteration 11613: loss: 0.060113, loss_s1: 0.027148, loss_fp: 0.000642, loss_freq: 0.005370
[16:36:12.820] iteration 11614: loss: 0.048334, loss_s1: 0.029215, loss_fp: 0.001085, loss_freq: 0.018407
[16:36:13.448] iteration 11615: loss: 0.103794, loss_s1: 0.068035, loss_fp: 0.005106, loss_freq: 0.041903
[16:36:14.071] iteration 11616: loss: 0.178360, loss_s1: 0.108298, loss_fp: 0.001880, loss_freq: 0.201126
[16:36:14.697] iteration 11617: loss: 0.046976, loss_s1: 0.026153, loss_fp: 0.001583, loss_freq: 0.018839
[16:36:15.323] iteration 11618: loss: 0.110144, loss_s1: 0.056348, loss_fp: 0.002857, loss_freq: 0.084548
[16:36:15.953] iteration 11619: loss: 0.060770, loss_s1: 0.031130, loss_fp: 0.002989, loss_freq: 0.036590
[16:36:16.574] iteration 11620: loss: 0.064252, loss_s1: 0.061624, loss_fp: 0.002866, loss_freq: 0.013258
[16:36:17.198] iteration 11621: loss: 0.039550, loss_s1: 0.015398, loss_fp: 0.002056, loss_freq: 0.019758
[16:36:17.820] iteration 11622: loss: 0.061550, loss_s1: 0.051191, loss_fp: 0.003859, loss_freq: 0.017353
[16:36:18.445] iteration 11623: loss: 0.049062, loss_s1: 0.050675, loss_fp: 0.002379, loss_freq: 0.009598
[16:36:19.070] iteration 11624: loss: 0.090812, loss_s1: 0.009792, loss_fp: 0.001011, loss_freq: 0.030560
[16:36:19.691] iteration 11625: loss: 0.061926, loss_s1: 0.038295, loss_fp: 0.001433, loss_freq: 0.042884
[16:36:20.316] iteration 11626: loss: 0.075182, loss_s1: 0.081347, loss_fp: 0.003293, loss_freq: 0.007793
[16:36:20.941] iteration 11627: loss: 0.084623, loss_s1: 0.027279, loss_fp: 0.004068, loss_freq: 0.043181
[16:36:21.563] iteration 11628: loss: 0.068502, loss_s1: 0.072219, loss_fp: 0.001674, loss_freq: 0.017307
[16:36:22.184] iteration 11629: loss: 0.087079, loss_s1: 0.038669, loss_fp: 0.012573, loss_freq: 0.039075
[16:36:22.805] iteration 11630: loss: 0.051279, loss_s1: 0.023298, loss_fp: 0.003600, loss_freq: 0.029150
[16:36:23.430] iteration 11631: loss: 0.120974, loss_s1: 0.063110, loss_fp: 0.006051, loss_freq: 0.105426
[16:36:24.058] iteration 11632: loss: 0.061797, loss_s1: 0.044482, loss_fp: 0.001283, loss_freq: 0.033289
[16:36:24.682] iteration 11633: loss: 0.075865, loss_s1: 0.036912, loss_fp: 0.007067, loss_freq: 0.017078
[16:36:25.303] iteration 11634: loss: 0.122298, loss_s1: 0.153074, loss_fp: 0.004870, loss_freq: 0.039380
[16:36:25.926] iteration 11635: loss: 0.113061, loss_s1: 0.093470, loss_fp: 0.008953, loss_freq: 0.046587
[16:36:26.549] iteration 11636: loss: 0.085042, loss_s1: 0.088982, loss_fp: 0.003597, loss_freq: 0.024393
[16:36:27.169] iteration 11637: loss: 0.106389, loss_s1: 0.078676, loss_fp: 0.005402, loss_freq: 0.056628
[16:36:27.796] iteration 11638: loss: 0.103054, loss_s1: 0.058492, loss_fp: 0.006796, loss_freq: 0.013381
[16:36:28.418] iteration 11639: loss: 0.046150, loss_s1: 0.021700, loss_fp: 0.000983, loss_freq: 0.033192
[16:36:29.041] iteration 11640: loss: 0.075200, loss_s1: 0.034638, loss_fp: 0.017636, loss_freq: 0.021039
[16:36:29.670] iteration 11641: loss: 0.050499, loss_s1: 0.036747, loss_fp: 0.004114, loss_freq: 0.013961
[16:36:30.297] iteration 11642: loss: 0.065672, loss_s1: 0.047107, loss_fp: 0.002010, loss_freq: 0.038059
[16:36:30.923] iteration 11643: loss: 0.054431, loss_s1: 0.031445, loss_fp: 0.007852, loss_freq: 0.025976
[16:36:31.549] iteration 11644: loss: 0.056994, loss_s1: 0.027102, loss_fp: 0.000925, loss_freq: 0.022145
[16:36:32.175] iteration 11645: loss: 0.056542, loss_s1: 0.026824, loss_fp: 0.000875, loss_freq: 0.036184
[16:36:32.805] iteration 11646: loss: 0.064755, loss_s1: 0.040780, loss_fp: 0.006925, loss_freq: 0.038176
[16:36:33.429] iteration 11647: loss: 0.050749, loss_s1: 0.011149, loss_fp: 0.000698, loss_freq: 0.007505
[16:36:34.070] iteration 11648: loss: 0.110676, loss_s1: 0.111351, loss_fp: 0.002962, loss_freq: 0.046107
[16:36:34.741] iteration 11649: loss: 0.043912, loss_s1: 0.028077, loss_fp: 0.000856, loss_freq: 0.008860
[16:36:35.412] iteration 11650: loss: 0.116003, loss_s1: 0.113746, loss_fp: 0.000831, loss_freq: 0.053384
[16:36:36.078] iteration 11651: loss: 0.046644, loss_s1: 0.027629, loss_fp: 0.001976, loss_freq: 0.014070
[16:36:36.744] iteration 11652: loss: 0.033052, loss_s1: 0.014428, loss_fp: 0.000643, loss_freq: 0.015505
[16:36:37.412] iteration 11653: loss: 0.043764, loss_s1: 0.013150, loss_fp: 0.002214, loss_freq: 0.022396
[16:36:38.079] iteration 11654: loss: 0.061214, loss_s1: 0.044595, loss_fp: 0.012063, loss_freq: 0.022250
[16:36:38.707] iteration 11655: loss: 0.058057, loss_s1: 0.017874, loss_fp: 0.004644, loss_freq: 0.027385
[16:36:39.341] iteration 11656: loss: 0.082593, loss_s1: 0.081224, loss_fp: 0.008999, loss_freq: 0.029377
[16:36:39.971] iteration 11657: loss: 0.050846, loss_s1: 0.031259, loss_fp: 0.002654, loss_freq: 0.023089
[16:36:40.597] iteration 11658: loss: 0.108527, loss_s1: 0.088207, loss_fp: 0.008414, loss_freq: 0.062860
[16:36:41.225] iteration 11659: loss: 0.106868, loss_s1: 0.050495, loss_fp: 0.003214, loss_freq: 0.042494
[16:36:41.846] iteration 11660: loss: 0.070354, loss_s1: 0.071033, loss_fp: 0.002896, loss_freq: 0.031742
[16:36:42.475] iteration 11661: loss: 0.065423, loss_s1: 0.015689, loss_fp: 0.003370, loss_freq: 0.046146
[16:36:43.099] iteration 11662: loss: 0.109739, loss_s1: 0.080104, loss_fp: 0.002844, loss_freq: 0.049637
[16:36:43.730] iteration 11663: loss: 0.104034, loss_s1: 0.053263, loss_fp: 0.004298, loss_freq: 0.024346
[16:36:44.354] iteration 11664: loss: 0.060395, loss_s1: 0.051949, loss_fp: 0.000501, loss_freq: 0.027050
[16:36:44.981] iteration 11665: loss: 0.077239, loss_s1: 0.062084, loss_fp: 0.002359, loss_freq: 0.035549
[16:36:45.606] iteration 11666: loss: 0.072687, loss_s1: 0.071017, loss_fp: 0.002198, loss_freq: 0.019818
[16:36:46.233] iteration 11667: loss: 0.070965, loss_s1: 0.046687, loss_fp: 0.002186, loss_freq: 0.032156
[16:36:46.859] iteration 11668: loss: 0.075921, loss_s1: 0.078244, loss_fp: 0.002190, loss_freq: 0.009045
[16:36:47.484] iteration 11669: loss: 0.099291, loss_s1: 0.105127, loss_fp: 0.001387, loss_freq: 0.042011
[16:36:48.108] iteration 11670: loss: 0.064792, loss_s1: 0.054688, loss_fp: 0.003497, loss_freq: 0.027216
[16:36:48.738] iteration 11671: loss: 0.041229, loss_s1: 0.034253, loss_fp: 0.002171, loss_freq: 0.004802
[16:36:49.365] iteration 11672: loss: 0.067532, loss_s1: 0.043731, loss_fp: 0.002965, loss_freq: 0.039379
[16:36:50.034] iteration 11673: loss: 0.070169, loss_s1: 0.033515, loss_fp: 0.007457, loss_freq: 0.052316
[16:36:50.697] iteration 11674: loss: 0.068914, loss_s1: 0.075719, loss_fp: 0.006144, loss_freq: 0.020377
[16:36:51.363] iteration 11675: loss: 0.117501, loss_s1: 0.062390, loss_fp: 0.003516, loss_freq: 0.128187
[16:36:52.018] iteration 11676: loss: 0.085451, loss_s1: 0.037456, loss_fp: 0.010385, loss_freq: 0.070120
[16:36:52.673] iteration 11677: loss: 0.099051, loss_s1: 0.118557, loss_fp: 0.005620, loss_freq: 0.034912
[16:36:53.332] iteration 11678: loss: 0.036270, loss_s1: 0.020214, loss_fp: 0.001312, loss_freq: 0.008375
[16:36:53.974] iteration 11679: loss: 0.109219, loss_s1: 0.058397, loss_fp: 0.000268, loss_freq: 0.036497
[16:36:54.596] iteration 11680: loss: 0.080851, loss_s1: 0.072334, loss_fp: 0.005471, loss_freq: 0.020832
[16:36:55.268] iteration 11681: loss: 0.057463, loss_s1: 0.030270, loss_fp: 0.000372, loss_freq: 0.030362
[16:36:55.909] iteration 11682: loss: 0.101283, loss_s1: 0.103028, loss_fp: 0.003592, loss_freq: 0.033463
[16:36:56.534] iteration 11683: loss: 0.058265, loss_s1: 0.026786, loss_fp: 0.001179, loss_freq: 0.028869
[16:36:57.158] iteration 11684: loss: 0.085318, loss_s1: 0.066193, loss_fp: 0.002940, loss_freq: 0.035659
[16:36:57.786] iteration 11685: loss: 0.101547, loss_s1: 0.026153, loss_fp: 0.001079, loss_freq: 0.072303
[16:36:58.408] iteration 11686: loss: 0.096517, loss_s1: 0.117773, loss_fp: 0.001121, loss_freq: 0.015695
[16:36:59.035] iteration 11687: loss: 0.046472, loss_s1: 0.027821, loss_fp: 0.000425, loss_freq: 0.028644
[16:36:59.661] iteration 11688: loss: 0.059563, loss_s1: 0.056110, loss_fp: 0.000823, loss_freq: 0.012541
[16:37:00.285] iteration 11689: loss: 0.056633, loss_s1: 0.046463, loss_fp: 0.000760, loss_freq: 0.016522
[16:37:00.909] iteration 11690: loss: 0.059935, loss_s1: 0.019857, loss_fp: 0.000298, loss_freq: 0.029572
[16:37:01.533] iteration 11691: loss: 0.059246, loss_s1: 0.037292, loss_fp: 0.003676, loss_freq: 0.022968
[16:37:02.159] iteration 11692: loss: 0.076263, loss_s1: 0.078337, loss_fp: 0.002301, loss_freq: 0.027268
[16:37:02.781] iteration 11693: loss: 0.067207, loss_s1: 0.046773, loss_fp: 0.005181, loss_freq: 0.016828
[16:37:03.412] iteration 11694: loss: 0.098898, loss_s1: 0.085098, loss_fp: 0.000953, loss_freq: 0.050488
[16:37:04.045] iteration 11695: loss: 0.110525, loss_s1: 0.105582, loss_fp: 0.004991, loss_freq: 0.044251
[16:37:05.009] iteration 11696: loss: 0.080074, loss_s1: 0.055799, loss_fp: 0.000586, loss_freq: 0.051506
[16:37:05.943] iteration 11697: loss: 0.067880, loss_s1: 0.024183, loss_fp: 0.000532, loss_freq: 0.016102
[16:37:06.566] iteration 11698: loss: 0.049885, loss_s1: 0.023981, loss_fp: 0.002630, loss_freq: 0.032593
[16:37:07.191] iteration 11699: loss: 0.065272, loss_s1: 0.065902, loss_fp: 0.001569, loss_freq: 0.012770
[16:37:07.813] iteration 11700: loss: 0.095474, loss_s1: 0.089004, loss_fp: 0.002046, loss_freq: 0.051900
[16:37:08.441] iteration 11701: loss: 0.117253, loss_s1: 0.091400, loss_fp: 0.002122, loss_freq: 0.056578
[16:37:09.065] iteration 11702: loss: 0.061985, loss_s1: 0.049277, loss_fp: 0.002445, loss_freq: 0.023572
[16:37:09.690] iteration 11703: loss: 0.093896, loss_s1: 0.057243, loss_fp: 0.001288, loss_freq: 0.035782
[16:37:10.311] iteration 11704: loss: 0.071276, loss_s1: 0.037947, loss_fp: 0.003336, loss_freq: 0.059972
[16:37:10.933] iteration 11705: loss: 0.063040, loss_s1: 0.059618, loss_fp: 0.006963, loss_freq: 0.018925
[16:37:11.588] iteration 11706: loss: 0.070517, loss_s1: 0.037358, loss_fp: 0.009753, loss_freq: 0.027251
[16:37:12.252] iteration 11707: loss: 0.039245, loss_s1: 0.025035, loss_fp: 0.002121, loss_freq: 0.009526
[16:37:12.906] iteration 11708: loss: 0.059278, loss_s1: 0.020034, loss_fp: 0.007127, loss_freq: 0.041004
[16:37:13.531] iteration 11709: loss: 0.053090, loss_s1: 0.032185, loss_fp: 0.003396, loss_freq: 0.032168
[16:37:14.171] iteration 11710: loss: 0.041104, loss_s1: 0.022172, loss_fp: 0.007187, loss_freq: 0.011172
[16:37:14.799] iteration 11711: loss: 0.082787, loss_s1: 0.039432, loss_fp: 0.002685, loss_freq: 0.041991
[16:37:15.425] iteration 11712: loss: 0.123099, loss_s1: 0.075861, loss_fp: 0.001517, loss_freq: 0.130899
[16:37:16.052] iteration 11713: loss: 0.079075, loss_s1: 0.019296, loss_fp: 0.006668, loss_freq: 0.077160
[16:37:16.678] iteration 11714: loss: 0.106961, loss_s1: 0.035647, loss_fp: 0.004525, loss_freq: 0.077499
[16:37:17.304] iteration 11715: loss: 0.084085, loss_s1: 0.064020, loss_fp: 0.015096, loss_freq: 0.029900
[16:37:17.927] iteration 11716: loss: 0.055466, loss_s1: 0.020691, loss_fp: 0.001782, loss_freq: 0.031041
[16:37:18.554] iteration 11717: loss: 0.127788, loss_s1: 0.095007, loss_fp: 0.001835, loss_freq: 0.020449
[16:37:19.179] iteration 11718: loss: 0.068440, loss_s1: 0.053310, loss_fp: 0.006656, loss_freq: 0.024048
[16:37:19.801] iteration 11719: loss: 0.070723, loss_s1: 0.046939, loss_fp: 0.002137, loss_freq: 0.009285
[16:37:20.426] iteration 11720: loss: 0.147251, loss_s1: 0.089476, loss_fp: 0.001134, loss_freq: 0.129787
[16:37:21.052] iteration 11721: loss: 0.061976, loss_s1: 0.050636, loss_fp: 0.002165, loss_freq: 0.019580
[16:37:21.678] iteration 11722: loss: 0.052907, loss_s1: 0.025068, loss_fp: 0.001827, loss_freq: 0.019076
[16:37:22.301] iteration 11723: loss: 0.071571, loss_s1: 0.045807, loss_fp: 0.002946, loss_freq: 0.049469
[16:37:22.925] iteration 11724: loss: 0.104660, loss_s1: 0.120099, loss_fp: 0.001646, loss_freq: 0.015369
[16:37:23.548] iteration 11725: loss: 0.105296, loss_s1: 0.111647, loss_fp: 0.009277, loss_freq: 0.030146
[16:37:24.176] iteration 11726: loss: 0.045082, loss_s1: 0.028724, loss_fp: 0.001901, loss_freq: 0.017641
[16:37:24.852] iteration 11727: loss: 0.070332, loss_s1: 0.045585, loss_fp: 0.003545, loss_freq: 0.043697
[16:37:25.528] iteration 11728: loss: 0.065995, loss_s1: 0.063946, loss_fp: 0.003478, loss_freq: 0.021881
[16:37:26.171] iteration 11729: loss: 0.044559, loss_s1: 0.016163, loss_fp: 0.005205, loss_freq: 0.009606
[16:37:26.827] iteration 11730: loss: 0.051253, loss_s1: 0.026762, loss_fp: 0.002905, loss_freq: 0.021246
[16:37:27.467] iteration 11731: loss: 0.045000, loss_s1: 0.029429, loss_fp: 0.002115, loss_freq: 0.021744
[16:37:28.092] iteration 11732: loss: 0.111203, loss_s1: 0.074642, loss_fp: 0.005416, loss_freq: 0.054591
[16:37:28.714] iteration 11733: loss: 0.056487, loss_s1: 0.043582, loss_fp: 0.002220, loss_freq: 0.022608
[16:37:29.338] iteration 11734: loss: 0.067415, loss_s1: 0.031334, loss_fp: 0.004799, loss_freq: 0.022804
[16:37:29.965] iteration 11735: loss: 0.095702, loss_s1: 0.050638, loss_fp: 0.011317, loss_freq: 0.052888
[16:37:30.592] iteration 11736: loss: 0.087294, loss_s1: 0.059873, loss_fp: 0.005020, loss_freq: 0.044856
[16:37:31.220] iteration 11737: loss: 0.054891, loss_s1: 0.032824, loss_fp: 0.001170, loss_freq: 0.013685
[16:37:31.845] iteration 11738: loss: 0.059024, loss_s1: 0.030053, loss_fp: 0.007075, loss_freq: 0.019842
[16:37:32.470] iteration 11739: loss: 0.062539, loss_s1: 0.042956, loss_fp: 0.003406, loss_freq: 0.042269
[16:37:33.100] iteration 11740: loss: 0.075768, loss_s1: 0.068653, loss_fp: 0.001318, loss_freq: 0.014887
[16:37:33.758] iteration 11741: loss: 0.067340, loss_s1: 0.047389, loss_fp: 0.006022, loss_freq: 0.025020
[16:37:34.435] iteration 11742: loss: 0.071603, loss_s1: 0.036876, loss_fp: 0.008719, loss_freq: 0.043247
[16:37:35.119] iteration 11743: loss: 0.087317, loss_s1: 0.037959, loss_fp: 0.005008, loss_freq: 0.029751
[16:37:35.783] iteration 11744: loss: 0.097017, loss_s1: 0.086920, loss_fp: 0.002210, loss_freq: 0.069479
[16:37:36.445] iteration 11745: loss: 0.054622, loss_s1: 0.028719, loss_fp: 0.001974, loss_freq: 0.030665
[16:37:37.102] iteration 11746: loss: 0.064922, loss_s1: 0.038991, loss_fp: 0.002019, loss_freq: 0.044935
[16:37:37.756] iteration 11747: loss: 0.041202, loss_s1: 0.026727, loss_fp: 0.001036, loss_freq: 0.014472
[16:37:38.386] iteration 11748: loss: 0.038950, loss_s1: 0.016529, loss_fp: 0.002587, loss_freq: 0.013224
[16:37:39.014] iteration 11749: loss: 0.050374, loss_s1: 0.007513, loss_fp: 0.002324, loss_freq: 0.012509
[16:37:39.643] iteration 11750: loss: 0.089838, loss_s1: 0.064709, loss_fp: 0.002076, loss_freq: 0.053810
[16:37:40.267] iteration 11751: loss: 0.094194, loss_s1: 0.072795, loss_fp: 0.001952, loss_freq: 0.056653
[16:37:40.888] iteration 11752: loss: 0.070250, loss_s1: 0.047231, loss_fp: 0.003600, loss_freq: 0.013933
[16:37:41.509] iteration 11753: loss: 0.063237, loss_s1: 0.040132, loss_fp: 0.005031, loss_freq: 0.039467
[16:37:42.458] iteration 11754: loss: 0.050751, loss_s1: 0.037911, loss_fp: 0.000499, loss_freq: 0.012694
[16:37:43.118] iteration 11755: loss: 0.071757, loss_s1: 0.053908, loss_fp: 0.002035, loss_freq: 0.031521
[16:37:43.780] iteration 11756: loss: 0.081672, loss_s1: 0.052073, loss_fp: 0.002036, loss_freq: 0.031675
[16:37:44.404] iteration 11757: loss: 0.044111, loss_s1: 0.028709, loss_fp: 0.000867, loss_freq: 0.013288
[16:37:45.089] iteration 11758: loss: 0.051061, loss_s1: 0.030363, loss_fp: 0.010608, loss_freq: 0.013596
[16:37:45.746] iteration 11759: loss: 0.094108, loss_s1: 0.051822, loss_fp: 0.003768, loss_freq: 0.028819
[16:37:46.405] iteration 11760: loss: 0.052947, loss_s1: 0.034142, loss_fp: 0.000869, loss_freq: 0.026623
[16:37:47.060] iteration 11761: loss: 0.051656, loss_s1: 0.043922, loss_fp: 0.001238, loss_freq: 0.021827
[16:37:47.687] iteration 11762: loss: 0.065155, loss_s1: 0.053416, loss_fp: 0.006352, loss_freq: 0.032731
[16:37:48.313] iteration 11763: loss: 0.059876, loss_s1: 0.035549, loss_fp: 0.003612, loss_freq: 0.027224
[16:37:48.941] iteration 11764: loss: 0.049330, loss_s1: 0.032235, loss_fp: 0.000927, loss_freq: 0.023507
[16:37:49.567] iteration 11765: loss: 0.111950, loss_s1: 0.086490, loss_fp: 0.004591, loss_freq: 0.064988
[16:37:50.195] iteration 11766: loss: 0.083477, loss_s1: 0.055234, loss_fp: 0.002279, loss_freq: 0.061013
[16:37:50.823] iteration 11767: loss: 0.075676, loss_s1: 0.012405, loss_fp: 0.000804, loss_freq: 0.015715
[16:37:51.449] iteration 11768: loss: 0.066270, loss_s1: 0.061375, loss_fp: 0.005047, loss_freq: 0.034450
[16:37:52.072] iteration 11769: loss: 0.090657, loss_s1: 0.037364, loss_fp: 0.012367, loss_freq: 0.065528
[16:37:52.699] iteration 11770: loss: 0.051276, loss_s1: 0.025877, loss_fp: 0.009233, loss_freq: 0.019428
[16:37:53.323] iteration 11771: loss: 0.082848, loss_s1: 0.085770, loss_fp: 0.002090, loss_freq: 0.020961
[16:37:53.947] iteration 11772: loss: 0.062369, loss_s1: 0.035555, loss_fp: 0.000455, loss_freq: 0.020769
[16:37:54.574] iteration 11773: loss: 0.070409, loss_s1: 0.015225, loss_fp: 0.005568, loss_freq: 0.040104
[16:37:55.200] iteration 11774: loss: 0.049008, loss_s1: 0.047302, loss_fp: 0.001722, loss_freq: 0.007939
[16:37:55.822] iteration 11775: loss: 0.060158, loss_s1: 0.050761, loss_fp: 0.002288, loss_freq: 0.017615
[16:37:56.448] iteration 11776: loss: 0.083418, loss_s1: 0.067935, loss_fp: 0.006199, loss_freq: 0.017761
[16:37:57.075] iteration 11777: loss: 0.166429, loss_s1: 0.111738, loss_fp: 0.000631, loss_freq: 0.149976
[16:37:57.697] iteration 11778: loss: 0.061132, loss_s1: 0.048881, loss_fp: 0.005364, loss_freq: 0.034801
[16:37:58.329] iteration 11779: loss: 0.069956, loss_s1: 0.050381, loss_fp: 0.012768, loss_freq: 0.018752
[16:37:58.956] iteration 11780: loss: 0.053582, loss_s1: 0.038494, loss_fp: 0.003284, loss_freq: 0.013745
[16:37:59.585] iteration 11781: loss: 0.110689, loss_s1: 0.090707, loss_fp: 0.002869, loss_freq: 0.084848
[16:38:00.205] iteration 11782: loss: 0.077030, loss_s1: 0.058015, loss_fp: 0.004876, loss_freq: 0.036279
[16:38:00.828] iteration 11783: loss: 0.039619, loss_s1: 0.017364, loss_fp: 0.001259, loss_freq: 0.018693
[16:38:01.451] iteration 11784: loss: 0.065079, loss_s1: 0.058531, loss_fp: 0.006509, loss_freq: 0.016647
[16:38:02.078] iteration 11785: loss: 0.077949, loss_s1: 0.030927, loss_fp: 0.000908, loss_freq: 0.015281
[16:38:02.701] iteration 11786: loss: 0.046690, loss_s1: 0.021241, loss_fp: 0.003062, loss_freq: 0.024438
[16:38:03.325] iteration 11787: loss: 0.050693, loss_s1: 0.050075, loss_fp: 0.002201, loss_freq: 0.012049
[16:38:03.950] iteration 11788: loss: 0.095978, loss_s1: 0.020214, loss_fp: 0.002875, loss_freq: 0.032686
[16:38:04.574] iteration 11789: loss: 0.101191, loss_s1: 0.097873, loss_fp: 0.006035, loss_freq: 0.043717
[16:38:05.197] iteration 11790: loss: 0.079366, loss_s1: 0.061652, loss_fp: 0.005623, loss_freq: 0.043216
[16:38:05.822] iteration 11791: loss: 0.072633, loss_s1: 0.042702, loss_fp: 0.010714, loss_freq: 0.031466
[16:38:06.446] iteration 11792: loss: 0.085647, loss_s1: 0.056442, loss_fp: 0.003559, loss_freq: 0.059519
[16:38:07.071] iteration 11793: loss: 0.058433, loss_s1: 0.035313, loss_fp: 0.002084, loss_freq: 0.031746
[16:38:07.696] iteration 11794: loss: 0.091496, loss_s1: 0.050511, loss_fp: 0.010357, loss_freq: 0.045718
[16:38:08.321] iteration 11795: loss: 0.089733, loss_s1: 0.067942, loss_fp: 0.008307, loss_freq: 0.051440
[16:38:08.946] iteration 11796: loss: 0.109831, loss_s1: 0.064661, loss_fp: 0.022166, loss_freq: 0.068889
[16:38:09.574] iteration 11797: loss: 0.082404, loss_s1: 0.037850, loss_fp: 0.010130, loss_freq: 0.033302
[16:38:10.201] iteration 11798: loss: 0.084086, loss_s1: 0.039393, loss_fp: 0.001787, loss_freq: 0.033398
[16:38:10.824] iteration 11799: loss: 0.086752, loss_s1: 0.068809, loss_fp: 0.004907, loss_freq: 0.016030
[16:38:11.449] iteration 11800: loss: 0.043607, loss_s1: 0.033781, loss_fp: 0.001676, loss_freq: 0.009596
[16:38:14.503] iteration 11800 : mean_dice : 0.707328
[16:38:15.167] iteration 11801: loss: 0.060025, loss_s1: 0.046394, loss_fp: 0.006880, loss_freq: 0.033752
[16:38:15.785] iteration 11802: loss: 0.098937, loss_s1: 0.098474, loss_fp: 0.014370, loss_freq: 0.010182
[16:38:16.406] iteration 11803: loss: 0.119425, loss_s1: 0.074090, loss_fp: 0.004612, loss_freq: 0.077840
[16:38:17.032] iteration 11804: loss: 0.047840, loss_s1: 0.029595, loss_fp: 0.001961, loss_freq: 0.017556
[16:38:17.657] iteration 11805: loss: 0.051107, loss_s1: 0.026725, loss_fp: 0.001657, loss_freq: 0.004717
[16:38:18.281] iteration 11806: loss: 0.078203, loss_s1: 0.045991, loss_fp: 0.003576, loss_freq: 0.035861
[16:38:18.907] iteration 11807: loss: 0.068055, loss_s1: 0.033063, loss_fp: 0.003588, loss_freq: 0.033651
[16:38:19.534] iteration 11808: loss: 0.043400, loss_s1: 0.015086, loss_fp: 0.000334, loss_freq: 0.007266
[16:38:20.156] iteration 11809: loss: 0.090444, loss_s1: 0.093457, loss_fp: 0.001783, loss_freq: 0.023644
[16:38:20.782] iteration 11810: loss: 0.040602, loss_s1: 0.019311, loss_fp: 0.004138, loss_freq: 0.011156
[16:38:21.407] iteration 11811: loss: 0.107971, loss_s1: 0.052181, loss_fp: 0.003045, loss_freq: 0.047416
[16:38:22.031] iteration 11812: loss: 0.053093, loss_s1: 0.038108, loss_fp: 0.001478, loss_freq: 0.009096
[16:38:22.654] iteration 11813: loss: 0.069296, loss_s1: 0.047064, loss_fp: 0.002351, loss_freq: 0.024441
[16:38:23.281] iteration 11814: loss: 0.056239, loss_s1: 0.014413, loss_fp: 0.001090, loss_freq: 0.031705
[16:38:23.904] iteration 11815: loss: 0.075428, loss_s1: 0.055328, loss_fp: 0.000796, loss_freq: 0.038435
[16:38:24.525] iteration 11816: loss: 0.048071, loss_s1: 0.033845, loss_fp: 0.000535, loss_freq: 0.009027
[16:38:25.151] iteration 11817: loss: 0.093535, loss_s1: 0.043978, loss_fp: 0.002811, loss_freq: 0.086123
[16:38:25.773] iteration 11818: loss: 0.073220, loss_s1: 0.076482, loss_fp: 0.004231, loss_freq: 0.023385
[16:38:26.401] iteration 11819: loss: 0.084941, loss_s1: 0.066383, loss_fp: 0.002044, loss_freq: 0.062536
[16:38:27.027] iteration 11820: loss: 0.082529, loss_s1: 0.029504, loss_fp: 0.002121, loss_freq: 0.045071
[16:38:27.651] iteration 11821: loss: 0.063342, loss_s1: 0.054835, loss_fp: 0.004868, loss_freq: 0.022555
[16:38:28.273] iteration 11822: loss: 0.054227, loss_s1: 0.047635, loss_fp: 0.004348, loss_freq: 0.012054
[16:38:28.895] iteration 11823: loss: 0.121872, loss_s1: 0.094707, loss_fp: 0.002012, loss_freq: 0.041661
[16:38:29.520] iteration 11824: loss: 0.077395, loss_s1: 0.053759, loss_fp: 0.002954, loss_freq: 0.047007
[16:38:30.147] iteration 11825: loss: 0.054669, loss_s1: 0.028185, loss_fp: 0.000532, loss_freq: 0.037677
[16:38:30.772] iteration 11826: loss: 0.098611, loss_s1: 0.058190, loss_fp: 0.001148, loss_freq: 0.052088
[16:38:31.398] iteration 11827: loss: 0.063029, loss_s1: 0.040877, loss_fp: 0.002940, loss_freq: 0.010479
[16:38:32.026] iteration 11828: loss: 0.091373, loss_s1: 0.073248, loss_fp: 0.002360, loss_freq: 0.059162
[16:38:32.651] iteration 11829: loss: 0.070245, loss_s1: 0.030484, loss_fp: 0.006440, loss_freq: 0.032962
[16:38:33.275] iteration 11830: loss: 0.065129, loss_s1: 0.042067, loss_fp: 0.001258, loss_freq: 0.043210
[16:38:33.960] iteration 11831: loss: 0.055784, loss_s1: 0.050486, loss_fp: 0.004987, loss_freq: 0.018161
[16:38:34.615] iteration 11832: loss: 0.044835, loss_s1: 0.041993, loss_fp: 0.000691, loss_freq: 0.011735
[16:38:35.272] iteration 11833: loss: 0.070643, loss_s1: 0.047810, loss_fp: 0.004486, loss_freq: 0.041381
[16:38:35.921] iteration 11834: loss: 0.081993, loss_s1: 0.066199, loss_fp: 0.002173, loss_freq: 0.029631
[16:38:36.547] iteration 11835: loss: 0.058593, loss_s1: 0.066343, loss_fp: 0.002263, loss_freq: 0.007053
[16:38:37.173] iteration 11836: loss: 0.119468, loss_s1: 0.086760, loss_fp: 0.010096, loss_freq: 0.090436
[16:38:37.797] iteration 11837: loss: 0.095240, loss_s1: 0.047651, loss_fp: 0.000684, loss_freq: 0.058710
[16:38:38.429] iteration 11838: loss: 0.076653, loss_s1: 0.061829, loss_fp: 0.004208, loss_freq: 0.052358
[16:38:39.058] iteration 11839: loss: 0.050110, loss_s1: 0.031576, loss_fp: 0.004879, loss_freq: 0.028815
[16:38:39.686] iteration 11840: loss: 0.064475, loss_s1: 0.032299, loss_fp: 0.009227, loss_freq: 0.021498
[16:38:40.311] iteration 11841: loss: 0.054977, loss_s1: 0.039315, loss_fp: 0.001989, loss_freq: 0.015693
[16:38:40.935] iteration 11842: loss: 0.058402, loss_s1: 0.051390, loss_fp: 0.003356, loss_freq: 0.022067
[16:38:41.561] iteration 11843: loss: 0.066596, loss_s1: 0.050749, loss_fp: 0.003668, loss_freq: 0.037103
[16:38:42.185] iteration 11844: loss: 0.070536, loss_s1: 0.025116, loss_fp: 0.002889, loss_freq: 0.029531
[16:38:42.811] iteration 11845: loss: 0.052599, loss_s1: 0.033975, loss_fp: 0.003242, loss_freq: 0.021043
[16:38:43.436] iteration 11846: loss: 0.077661, loss_s1: 0.029596, loss_fp: 0.003488, loss_freq: 0.024959
[16:38:44.062] iteration 11847: loss: 0.044137, loss_s1: 0.019910, loss_fp: 0.001627, loss_freq: 0.009898
[16:38:44.685] iteration 11848: loss: 0.040573, loss_s1: 0.023903, loss_fp: 0.002172, loss_freq: 0.022408
[16:38:45.310] iteration 11849: loss: 0.058690, loss_s1: 0.024951, loss_fp: 0.001390, loss_freq: 0.022368
[16:38:45.940] iteration 11850: loss: 0.052482, loss_s1: 0.022609, loss_fp: 0.000813, loss_freq: 0.023606
[16:38:46.564] iteration 11851: loss: 0.058877, loss_s1: 0.015422, loss_fp: 0.000429, loss_freq: 0.027640
[16:38:47.196] iteration 11852: loss: 0.063586, loss_s1: 0.057584, loss_fp: 0.007180, loss_freq: 0.019637
[16:38:47.819] iteration 11853: loss: 0.064412, loss_s1: 0.064924, loss_fp: 0.003453, loss_freq: 0.013183
[16:38:48.442] iteration 11854: loss: 0.063539, loss_s1: 0.049108, loss_fp: 0.001087, loss_freq: 0.028805
[16:38:49.066] iteration 11855: loss: 0.098398, loss_s1: 0.038225, loss_fp: 0.001680, loss_freq: 0.059173
[16:38:49.690] iteration 11856: loss: 0.082468, loss_s1: 0.076503, loss_fp: 0.004020, loss_freq: 0.035696
[16:38:50.316] iteration 11857: loss: 0.075922, loss_s1: 0.083200, loss_fp: 0.003949, loss_freq: 0.023848
[16:38:50.944] iteration 11858: loss: 0.084756, loss_s1: 0.028051, loss_fp: 0.005827, loss_freq: 0.056229
[16:38:51.566] iteration 11859: loss: 0.063067, loss_s1: 0.034827, loss_fp: 0.002941, loss_freq: 0.036887
[16:38:52.193] iteration 11860: loss: 0.035415, loss_s1: 0.005061, loss_fp: 0.001396, loss_freq: 0.011900
[16:38:52.821] iteration 11861: loss: 0.089417, loss_s1: 0.077925, loss_fp: 0.002137, loss_freq: 0.045340
[16:38:53.448] iteration 11862: loss: 0.130044, loss_s1: 0.110108, loss_fp: 0.001353, loss_freq: 0.100347
[16:38:54.072] iteration 11863: loss: 0.078858, loss_s1: 0.065857, loss_fp: 0.003172, loss_freq: 0.023072
[16:38:54.696] iteration 11864: loss: 0.058375, loss_s1: 0.021754, loss_fp: 0.001292, loss_freq: 0.019070
[16:38:55.324] iteration 11865: loss: 0.067062, loss_s1: 0.060766, loss_fp: 0.001221, loss_freq: 0.029853
[16:38:55.947] iteration 11866: loss: 0.059950, loss_s1: 0.047722, loss_fp: 0.001019, loss_freq: 0.020336
[16:38:56.575] iteration 11867: loss: 0.062381, loss_s1: 0.029090, loss_fp: 0.001414, loss_freq: 0.063291
[16:38:57.203] iteration 11868: loss: 0.031060, loss_s1: 0.009043, loss_fp: 0.001263, loss_freq: 0.005228
[16:38:57.825] iteration 11869: loss: 0.072365, loss_s1: 0.045175, loss_fp: 0.002475, loss_freq: 0.033120
[16:38:58.453] iteration 11870: loss: 0.052359, loss_s1: 0.022973, loss_fp: 0.000824, loss_freq: 0.042223
[16:38:59.080] iteration 11871: loss: 0.041514, loss_s1: 0.027914, loss_fp: 0.003657, loss_freq: 0.016514
[16:38:59.708] iteration 11872: loss: 0.069062, loss_s1: 0.026162, loss_fp: 0.003071, loss_freq: 0.031762
[16:39:00.336] iteration 11873: loss: 0.090258, loss_s1: 0.019630, loss_fp: 0.002681, loss_freq: 0.110632
[16:39:00.962] iteration 11874: loss: 0.069121, loss_s1: 0.022670, loss_fp: 0.012433, loss_freq: 0.052529
[16:39:01.589] iteration 11875: loss: 0.078743, loss_s1: 0.029758, loss_fp: 0.000938, loss_freq: 0.017046
[16:39:02.214] iteration 11876: loss: 0.053798, loss_s1: 0.036050, loss_fp: 0.000382, loss_freq: 0.009843
[16:39:02.837] iteration 11877: loss: 0.061535, loss_s1: 0.056082, loss_fp: 0.008754, loss_freq: 0.015069
[16:39:03.462] iteration 11878: loss: 0.069980, loss_s1: 0.050358, loss_fp: 0.008808, loss_freq: 0.028608
[16:39:04.089] iteration 11879: loss: 0.095551, loss_s1: 0.056813, loss_fp: 0.006520, loss_freq: 0.061393
[16:39:04.715] iteration 11880: loss: 0.071598, loss_s1: 0.057691, loss_fp: 0.000682, loss_freq: 0.033439
[16:39:05.376] iteration 11881: loss: 0.063995, loss_s1: 0.027885, loss_fp: 0.001119, loss_freq: 0.041777
[16:39:06.036] iteration 11882: loss: 0.041079, loss_s1: 0.027198, loss_fp: 0.001353, loss_freq: 0.009370
[16:39:06.693] iteration 11883: loss: 0.054670, loss_s1: 0.043951, loss_fp: 0.001476, loss_freq: 0.007277
[16:39:07.322] iteration 11884: loss: 0.053721, loss_s1: 0.037649, loss_fp: 0.002598, loss_freq: 0.026169
[16:39:08.006] iteration 11885: loss: 0.090655, loss_s1: 0.115106, loss_fp: 0.004214, loss_freq: 0.008945
[16:39:08.693] iteration 11886: loss: 0.062576, loss_s1: 0.051887, loss_fp: 0.004133, loss_freq: 0.012390
[16:39:09.331] iteration 11887: loss: 0.046212, loss_s1: 0.044878, loss_fp: 0.001553, loss_freq: 0.010998
[16:39:09.957] iteration 11888: loss: 0.060593, loss_s1: 0.023203, loss_fp: 0.004011, loss_freq: 0.039904
[16:39:10.579] iteration 11889: loss: 0.050150, loss_s1: 0.024933, loss_fp: 0.000804, loss_freq: 0.041349
[16:39:11.239] iteration 11890: loss: 0.039493, loss_s1: 0.012803, loss_fp: 0.001379, loss_freq: 0.017632
[16:39:11.895] iteration 11891: loss: 0.053592, loss_s1: 0.052881, loss_fp: 0.002462, loss_freq: 0.016196
[16:39:12.551] iteration 11892: loss: 0.050130, loss_s1: 0.036425, loss_fp: 0.002364, loss_freq: 0.020224
[16:39:13.178] iteration 11893: loss: 0.070567, loss_s1: 0.036550, loss_fp: 0.005045, loss_freq: 0.036474
[16:39:13.803] iteration 11894: loss: 0.089819, loss_s1: 0.089353, loss_fp: 0.006361, loss_freq: 0.035091
[16:39:14.428] iteration 11895: loss: 0.072044, loss_s1: 0.038451, loss_fp: 0.010506, loss_freq: 0.037346
[16:39:15.050] iteration 11896: loss: 0.092580, loss_s1: 0.059628, loss_fp: 0.001819, loss_freq: 0.032055
[16:39:15.680] iteration 11897: loss: 0.082484, loss_s1: 0.084540, loss_fp: 0.005050, loss_freq: 0.019302
[16:39:16.305] iteration 11898: loss: 0.059754, loss_s1: 0.042192, loss_fp: 0.002314, loss_freq: 0.007966
[16:39:16.926] iteration 11899: loss: 0.046360, loss_s1: 0.019835, loss_fp: 0.007304, loss_freq: 0.016214
[16:39:17.547] iteration 11900: loss: 0.085957, loss_s1: 0.063946, loss_fp: 0.006224, loss_freq: 0.057269
[16:39:18.176] iteration 11901: loss: 0.051563, loss_s1: 0.049376, loss_fp: 0.002198, loss_freq: 0.012499
[16:39:18.804] iteration 11902: loss: 0.062166, loss_s1: 0.051456, loss_fp: 0.006644, loss_freq: 0.024397
[16:39:19.436] iteration 11903: loss: 0.077495, loss_s1: 0.043295, loss_fp: 0.003501, loss_freq: 0.054788
[16:39:20.063] iteration 11904: loss: 0.095450, loss_s1: 0.036311, loss_fp: 0.013849, loss_freq: 0.032972
[16:39:20.696] iteration 11905: loss: 0.076096, loss_s1: 0.072906, loss_fp: 0.008207, loss_freq: 0.036043
[16:39:21.325] iteration 11906: loss: 0.083010, loss_s1: 0.044525, loss_fp: 0.003971, loss_freq: 0.021802
[16:39:21.955] iteration 11907: loss: 0.089692, loss_s1: 0.058602, loss_fp: 0.000878, loss_freq: 0.027960
[16:39:22.585] iteration 11908: loss: 0.039811, loss_s1: 0.020540, loss_fp: 0.001449, loss_freq: 0.015106
[16:39:23.212] iteration 11909: loss: 0.072111, loss_s1: 0.055483, loss_fp: 0.000661, loss_freq: 0.006580
[16:39:23.837] iteration 11910: loss: 0.065417, loss_s1: 0.031316, loss_fp: 0.016047, loss_freq: 0.015770
[16:39:24.464] iteration 11911: loss: 0.109363, loss_s1: 0.112811, loss_fp: 0.002232, loss_freq: 0.047831
[16:39:25.088] iteration 11912: loss: 0.072160, loss_s1: 0.061374, loss_fp: 0.002646, loss_freq: 0.036215
[16:39:25.710] iteration 11913: loss: 0.086193, loss_s1: 0.058910, loss_fp: 0.004390, loss_freq: 0.022992
[16:39:26.329] iteration 11914: loss: 0.070181, loss_s1: 0.048949, loss_fp: 0.002129, loss_freq: 0.048394
[16:39:27.302] iteration 11915: loss: 0.074806, loss_s1: 0.098132, loss_fp: 0.000801, loss_freq: 0.007463
[16:39:27.979] iteration 11916: loss: 0.069212, loss_s1: 0.036817, loss_fp: 0.003507, loss_freq: 0.022957
[16:39:28.606] iteration 11917: loss: 0.052636, loss_s1: 0.023553, loss_fp: 0.002208, loss_freq: 0.019996
[16:39:29.233] iteration 11918: loss: 0.058136, loss_s1: 0.054147, loss_fp: 0.003726, loss_freq: 0.010557
[16:39:29.854] iteration 11919: loss: 0.076215, loss_s1: 0.078704, loss_fp: 0.004139, loss_freq: 0.012369
[16:39:30.480] iteration 11920: loss: 0.132874, loss_s1: 0.077210, loss_fp: 0.003266, loss_freq: 0.053496
[16:39:31.105] iteration 11921: loss: 0.047001, loss_s1: 0.030888, loss_fp: 0.001184, loss_freq: 0.018643
[16:39:31.729] iteration 11922: loss: 0.049747, loss_s1: 0.046918, loss_fp: 0.001737, loss_freq: 0.012503
[16:39:32.361] iteration 11923: loss: 0.064038, loss_s1: 0.042502, loss_fp: 0.002382, loss_freq: 0.016400
[16:39:32.991] iteration 11924: loss: 0.069651, loss_s1: 0.048929, loss_fp: 0.002137, loss_freq: 0.032742
[16:39:33.614] iteration 11925: loss: 0.050718, loss_s1: 0.019249, loss_fp: 0.000875, loss_freq: 0.020090
[16:39:34.243] iteration 11926: loss: 0.073859, loss_s1: 0.067724, loss_fp: 0.003270, loss_freq: 0.023939
[16:39:34.870] iteration 11927: loss: 0.105437, loss_s1: 0.058631, loss_fp: 0.011415, loss_freq: 0.098761
[16:39:35.497] iteration 11928: loss: 0.064332, loss_s1: 0.044401, loss_fp: 0.003774, loss_freq: 0.023597
[16:39:36.119] iteration 11929: loss: 0.052990, loss_s1: 0.022730, loss_fp: 0.003940, loss_freq: 0.029277
[16:39:36.742] iteration 11930: loss: 0.139731, loss_s1: 0.133772, loss_fp: 0.003416, loss_freq: 0.083319
[16:39:37.366] iteration 11931: loss: 0.065636, loss_s1: 0.050288, loss_fp: 0.002019, loss_freq: 0.023113
[16:39:37.993] iteration 11932: loss: 0.087258, loss_s1: 0.049549, loss_fp: 0.004001, loss_freq: 0.045314
[16:39:38.618] iteration 11933: loss: 0.062684, loss_s1: 0.035946, loss_fp: 0.004478, loss_freq: 0.031530
[16:39:39.241] iteration 11934: loss: 0.082136, loss_s1: 0.044692, loss_fp: 0.002629, loss_freq: 0.039997
[16:39:39.871] iteration 11935: loss: 0.046812, loss_s1: 0.025643, loss_fp: 0.007689, loss_freq: 0.009182
[16:39:40.531] iteration 11936: loss: 0.052321, loss_s1: 0.037863, loss_fp: 0.006843, loss_freq: 0.016216
[16:39:41.192] iteration 11937: loss: 0.059522, loss_s1: 0.032986, loss_fp: 0.001089, loss_freq: 0.024381
[16:39:41.850] iteration 11938: loss: 0.209809, loss_s1: 0.112928, loss_fp: 0.002541, loss_freq: 0.256134
[16:39:42.506] iteration 11939: loss: 0.062065, loss_s1: 0.053792, loss_fp: 0.000545, loss_freq: 0.034381
[16:39:43.158] iteration 11940: loss: 0.092413, loss_s1: 0.075021, loss_fp: 0.012616, loss_freq: 0.061446
[16:39:43.811] iteration 11941: loss: 0.060301, loss_s1: 0.021421, loss_fp: 0.001678, loss_freq: 0.031583
[16:39:44.462] iteration 11942: loss: 0.145303, loss_s1: 0.087338, loss_fp: 0.018192, loss_freq: 0.086980
[16:39:45.083] iteration 11943: loss: 0.078805, loss_s1: 0.042191, loss_fp: 0.002151, loss_freq: 0.031850
[16:39:45.701] iteration 11944: loss: 0.050828, loss_s1: 0.025579, loss_fp: 0.007115, loss_freq: 0.019710
[16:39:46.323] iteration 11945: loss: 0.076297, loss_s1: 0.051044, loss_fp: 0.008736, loss_freq: 0.023108
[16:39:46.944] iteration 11946: loss: 0.051690, loss_s1: 0.032234, loss_fp: 0.002582, loss_freq: 0.012329
[16:39:47.564] iteration 11947: loss: 0.068335, loss_s1: 0.048983, loss_fp: 0.007240, loss_freq: 0.037467
[16:39:48.186] iteration 11948: loss: 0.059731, loss_s1: 0.038111, loss_fp: 0.005812, loss_freq: 0.017656
[16:39:48.805] iteration 11949: loss: 0.085154, loss_s1: 0.041082, loss_fp: 0.002128, loss_freq: 0.042592
[16:39:49.423] iteration 11950: loss: 0.087095, loss_s1: 0.043365, loss_fp: 0.003787, loss_freq: 0.064565
[16:39:50.049] iteration 11951: loss: 0.091395, loss_s1: 0.065485, loss_fp: 0.002175, loss_freq: 0.046538
[16:39:50.669] iteration 11952: loss: 0.079995, loss_s1: 0.045710, loss_fp: 0.002364, loss_freq: 0.026295
[16:39:51.292] iteration 11953: loss: 0.103936, loss_s1: 0.064474, loss_fp: 0.004624, loss_freq: 0.070611
[16:39:51.915] iteration 11954: loss: 0.098079, loss_s1: 0.064174, loss_fp: 0.004038, loss_freq: 0.049391
[16:39:52.533] iteration 11955: loss: 0.065740, loss_s1: 0.045575, loss_fp: 0.000810, loss_freq: 0.019881
[16:39:53.152] iteration 11956: loss: 0.077455, loss_s1: 0.065960, loss_fp: 0.000688, loss_freq: 0.042794
[16:39:53.774] iteration 11957: loss: 0.056423, loss_s1: 0.044039, loss_fp: 0.001618, loss_freq: 0.032245
[16:39:54.393] iteration 11958: loss: 0.080179, loss_s1: 0.039792, loss_fp: 0.001574, loss_freq: 0.056340
[16:39:55.020] iteration 11959: loss: 0.074453, loss_s1: 0.028248, loss_fp: 0.001461, loss_freq: 0.066326
[16:39:55.645] iteration 11960: loss: 0.091940, loss_s1: 0.070210, loss_fp: 0.004055, loss_freq: 0.030266
[16:39:56.269] iteration 11961: loss: 0.071759, loss_s1: 0.037883, loss_fp: 0.002339, loss_freq: 0.025794
[16:39:56.892] iteration 11962: loss: 0.064469, loss_s1: 0.059761, loss_fp: 0.007685, loss_freq: 0.027672
[16:39:57.515] iteration 11963: loss: 0.060757, loss_s1: 0.046366, loss_fp: 0.002138, loss_freq: 0.021720
[16:39:58.139] iteration 11964: loss: 0.061653, loss_s1: 0.056043, loss_fp: 0.007739, loss_freq: 0.020797
[16:39:58.761] iteration 11965: loss: 0.044074, loss_s1: 0.027911, loss_fp: 0.001247, loss_freq: 0.017605
[16:39:59.391] iteration 11966: loss: 0.083546, loss_s1: 0.026959, loss_fp: 0.001823, loss_freq: 0.031241
[16:40:00.012] iteration 11967: loss: 0.104366, loss_s1: 0.060092, loss_fp: 0.008572, loss_freq: 0.071413
[16:40:00.672] iteration 11968: loss: 0.136391, loss_s1: 0.068536, loss_fp: 0.007419, loss_freq: 0.044563
[16:40:01.332] iteration 11969: loss: 0.052473, loss_s1: 0.033277, loss_fp: 0.001516, loss_freq: 0.021329
[16:40:01.991] iteration 11970: loss: 0.097109, loss_s1: 0.105345, loss_fp: 0.004467, loss_freq: 0.033978
[16:40:02.647] iteration 11971: loss: 0.061671, loss_s1: 0.044847, loss_fp: 0.006068, loss_freq: 0.019507
[16:40:03.278] iteration 11972: loss: 0.113742, loss_s1: 0.070949, loss_fp: 0.002079, loss_freq: 0.088227
[16:40:03.906] iteration 11973: loss: 0.039722, loss_s1: 0.014372, loss_fp: 0.002672, loss_freq: 0.016876
[16:40:04.531] iteration 11974: loss: 0.051467, loss_s1: 0.036862, loss_fp: 0.004389, loss_freq: 0.025016
[16:40:05.156] iteration 11975: loss: 0.065768, loss_s1: 0.030574, loss_fp: 0.004646, loss_freq: 0.023408
[16:40:05.777] iteration 11976: loss: 0.044495, loss_s1: 0.025356, loss_fp: 0.002923, loss_freq: 0.008125
[16:40:06.402] iteration 11977: loss: 0.057251, loss_s1: 0.024077, loss_fp: 0.004867, loss_freq: 0.007892
[16:40:07.028] iteration 11978: loss: 0.059730, loss_s1: 0.024593, loss_fp: 0.004664, loss_freq: 0.042558
[16:40:07.655] iteration 11979: loss: 0.078457, loss_s1: 0.100491, loss_fp: 0.001640, loss_freq: 0.009687
[16:40:08.277] iteration 11980: loss: 0.069514, loss_s1: 0.038587, loss_fp: 0.003765, loss_freq: 0.048267
[16:40:08.905] iteration 11981: loss: 0.085151, loss_s1: 0.053680, loss_fp: 0.000945, loss_freq: 0.043103
[16:40:09.531] iteration 11982: loss: 0.074262, loss_s1: 0.055719, loss_fp: 0.005722, loss_freq: 0.037416
[16:40:10.192] iteration 11983: loss: 0.069732, loss_s1: 0.039360, loss_fp: 0.002613, loss_freq: 0.025444
[16:40:10.854] iteration 11984: loss: 0.109982, loss_s1: 0.054654, loss_fp: 0.001513, loss_freq: 0.031831
[16:40:11.517] iteration 11985: loss: 0.055708, loss_s1: 0.029899, loss_fp: 0.007484, loss_freq: 0.030784
[16:40:12.177] iteration 11986: loss: 0.085923, loss_s1: 0.041999, loss_fp: 0.001937, loss_freq: 0.034149
[16:40:12.834] iteration 11987: loss: 0.050967, loss_s1: 0.017183, loss_fp: 0.009902, loss_freq: 0.017528
[16:40:13.492] iteration 11988: loss: 0.053455, loss_s1: 0.034988, loss_fp: 0.001554, loss_freq: 0.015692
[16:40:14.118] iteration 11989: loss: 0.079697, loss_s1: 0.066178, loss_fp: 0.002363, loss_freq: 0.043231
[16:40:14.744] iteration 11990: loss: 0.121979, loss_s1: 0.102409, loss_fp: 0.001757, loss_freq: 0.068153
[16:40:15.371] iteration 11991: loss: 0.107836, loss_s1: 0.095045, loss_fp: 0.002178, loss_freq: 0.060888
[16:40:15.998] iteration 11992: loss: 0.044382, loss_s1: 0.026605, loss_fp: 0.007473, loss_freq: 0.016130
[16:40:16.622] iteration 11993: loss: 0.047071, loss_s1: 0.031474, loss_fp: 0.000574, loss_freq: 0.014782
[16:40:17.246] iteration 11994: loss: 0.078581, loss_s1: 0.080311, loss_fp: 0.001946, loss_freq: 0.027934
[16:40:17.869] iteration 11995: loss: 0.103665, loss_s1: 0.096402, loss_fp: 0.000532, loss_freq: 0.054149
[16:40:18.531] iteration 11996: loss: 0.071628, loss_s1: 0.062185, loss_fp: 0.002355, loss_freq: 0.035628
[16:40:19.193] iteration 11997: loss: 0.097915, loss_s1: 0.112574, loss_fp: 0.005753, loss_freq: 0.027973
[16:40:19.858] iteration 11998: loss: 0.080918, loss_s1: 0.015239, loss_fp: 0.000493, loss_freq: 0.026268
[16:40:20.504] iteration 11999: loss: 0.079116, loss_s1: 0.064001, loss_fp: 0.002312, loss_freq: 0.046437
[16:40:21.145] iteration 12000: loss: 0.066929, loss_s1: 0.056379, loss_fp: 0.001198, loss_freq: 0.029946
[16:40:24.481] iteration 12000 : mean_dice : 0.698906
[16:40:25.162] iteration 12001: loss: 0.071549, loss_s1: 0.049400, loss_fp: 0.003696, loss_freq: 0.006716
[16:40:25.841] iteration 12002: loss: 0.049001, loss_s1: 0.016284, loss_fp: 0.002204, loss_freq: 0.028091
[16:40:26.521] iteration 12003: loss: 0.072572, loss_s1: 0.050126, loss_fp: 0.001351, loss_freq: 0.052422
[16:40:27.204] iteration 12004: loss: 0.072054, loss_s1: 0.027869, loss_fp: 0.001926, loss_freq: 0.038169
[16:40:27.849] iteration 12005: loss: 0.069344, loss_s1: 0.032335, loss_fp: 0.000697, loss_freq: 0.028128
[16:40:28.487] iteration 12006: loss: 0.048362, loss_s1: 0.031659, loss_fp: 0.001214, loss_freq: 0.017464
[16:40:29.128] iteration 12007: loss: 0.048711, loss_s1: 0.008793, loss_fp: 0.000491, loss_freq: 0.009582
[16:40:29.765] iteration 12008: loss: 0.057917, loss_s1: 0.061846, loss_fp: 0.000865, loss_freq: 0.014694
[16:40:30.394] iteration 12009: loss: 0.044054, loss_s1: 0.027730, loss_fp: 0.003089, loss_freq: 0.010903
[16:40:31.017] iteration 12010: loss: 0.063748, loss_s1: 0.032203, loss_fp: 0.001857, loss_freq: 0.047683
[16:40:31.656] iteration 12011: loss: 0.057443, loss_s1: 0.015752, loss_fp: 0.020495, loss_freq: 0.025591
[16:40:32.293] iteration 12012: loss: 0.054248, loss_s1: 0.023230, loss_fp: 0.000514, loss_freq: 0.020226
[16:40:32.928] iteration 12013: loss: 0.046677, loss_s1: 0.019512, loss_fp: 0.005376, loss_freq: 0.015258
[16:40:33.564] iteration 12014: loss: 0.044376, loss_s1: 0.027798, loss_fp: 0.002193, loss_freq: 0.020645
[16:40:34.206] iteration 12015: loss: 0.084126, loss_s1: 0.073880, loss_fp: 0.014578, loss_freq: 0.042739
[16:40:34.833] iteration 12016: loss: 0.071927, loss_s1: 0.023430, loss_fp: 0.002124, loss_freq: 0.038414
[16:40:35.476] iteration 12017: loss: 0.098117, loss_s1: 0.084810, loss_fp: 0.004809, loss_freq: 0.060854
[16:40:36.117] iteration 12018: loss: 0.062400, loss_s1: 0.032620, loss_fp: 0.005483, loss_freq: 0.030280
[16:40:36.757] iteration 12019: loss: 0.062173, loss_s1: 0.025565, loss_fp: 0.004934, loss_freq: 0.034495
[16:40:37.398] iteration 12020: loss: 0.059741, loss_s1: 0.041321, loss_fp: 0.002394, loss_freq: 0.009082
[16:40:38.042] iteration 12021: loss: 0.044799, loss_s1: 0.025463, loss_fp: 0.000964, loss_freq: 0.017903
[16:40:38.682] iteration 12022: loss: 0.143618, loss_s1: 0.184835, loss_fp: 0.001696, loss_freq: 0.023035
[16:40:39.309] iteration 12023: loss: 0.132902, loss_s1: 0.104409, loss_fp: 0.002879, loss_freq: 0.101306
[16:40:39.941] iteration 12024: loss: 0.103020, loss_s1: 0.094393, loss_fp: 0.001906, loss_freq: 0.065378
[16:40:40.567] iteration 12025: loss: 0.057136, loss_s1: 0.015393, loss_fp: 0.003291, loss_freq: 0.025847
[16:40:41.189] iteration 12026: loss: 0.100096, loss_s1: 0.087444, loss_fp: 0.003802, loss_freq: 0.054305
[16:40:41.813] iteration 12027: loss: 0.101383, loss_s1: 0.082852, loss_fp: 0.005685, loss_freq: 0.045483
[16:40:42.434] iteration 12028: loss: 0.054270, loss_s1: 0.053550, loss_fp: 0.001641, loss_freq: 0.015168
[16:40:43.057] iteration 12029: loss: 0.073494, loss_s1: 0.072204, loss_fp: 0.001120, loss_freq: 0.010109
[16:40:43.683] iteration 12030: loss: 0.075998, loss_s1: 0.071748, loss_fp: 0.004796, loss_freq: 0.026603
[16:40:44.310] iteration 12031: loss: 0.066169, loss_s1: 0.028415, loss_fp: 0.008100, loss_freq: 0.053090
[16:40:44.935] iteration 12032: loss: 0.059467, loss_s1: 0.051068, loss_fp: 0.002203, loss_freq: 0.010750
[16:40:45.566] iteration 12033: loss: 0.083134, loss_s1: 0.061015, loss_fp: 0.013270, loss_freq: 0.035033
[16:40:46.193] iteration 12034: loss: 0.097414, loss_s1: 0.030546, loss_fp: 0.001267, loss_freq: 0.124985
[16:40:46.824] iteration 12035: loss: 0.084359, loss_s1: 0.037990, loss_fp: 0.006936, loss_freq: 0.083302
[16:40:47.457] iteration 12036: loss: 0.089788, loss_s1: 0.031627, loss_fp: 0.008426, loss_freq: 0.021567
[16:40:48.088] iteration 12037: loss: 0.095317, loss_s1: 0.108612, loss_fp: 0.008761, loss_freq: 0.016200
[16:40:48.717] iteration 12038: loss: 0.097032, loss_s1: 0.073510, loss_fp: 0.002232, loss_freq: 0.064874
[16:40:49.348] iteration 12039: loss: 0.071836, loss_s1: 0.050775, loss_fp: 0.004735, loss_freq: 0.034646
[16:40:49.972] iteration 12040: loss: 0.082971, loss_s1: 0.031357, loss_fp: 0.008175, loss_freq: 0.051166
[16:40:50.657] iteration 12041: loss: 0.061973, loss_s1: 0.045421, loss_fp: 0.000486, loss_freq: 0.016130
[16:40:51.313] iteration 12042: loss: 0.116095, loss_s1: 0.058626, loss_fp: 0.005073, loss_freq: 0.113796
[16:40:51.961] iteration 12043: loss: 0.035837, loss_s1: 0.011540, loss_fp: 0.000777, loss_freq: 0.015362
[16:40:52.583] iteration 12044: loss: 0.049346, loss_s1: 0.039700, loss_fp: 0.004691, loss_freq: 0.008891
[16:40:53.206] iteration 12045: loss: 0.110330, loss_s1: 0.063882, loss_fp: 0.009781, loss_freq: 0.099319
[16:40:53.832] iteration 12046: loss: 0.085194, loss_s1: 0.074044, loss_fp: 0.000949, loss_freq: 0.037373
[16:40:54.455] iteration 12047: loss: 0.118691, loss_s1: 0.134565, loss_fp: 0.003043, loss_freq: 0.036869
[16:40:55.083] iteration 12048: loss: 0.070892, loss_s1: 0.069336, loss_fp: 0.004958, loss_freq: 0.026219
[16:40:55.709] iteration 12049: loss: 0.080915, loss_s1: 0.035415, loss_fp: 0.007086, loss_freq: 0.075133
[16:40:56.333] iteration 12050: loss: 0.068188, loss_s1: 0.067875, loss_fp: 0.011924, loss_freq: 0.012590
[16:40:56.959] iteration 12051: loss: 0.068244, loss_s1: 0.034461, loss_fp: 0.000324, loss_freq: 0.021378
[16:40:57.581] iteration 12052: loss: 0.058726, loss_s1: 0.043021, loss_fp: 0.001694, loss_freq: 0.032179
[16:40:58.204] iteration 12053: loss: 0.053270, loss_s1: 0.035041, loss_fp: 0.003784, loss_freq: 0.025628
[16:40:58.829] iteration 12054: loss: 0.082049, loss_s1: 0.052810, loss_fp: 0.003323, loss_freq: 0.042594
[16:40:59.452] iteration 12055: loss: 0.083202, loss_s1: 0.064367, loss_fp: 0.003325, loss_freq: 0.030766
[16:41:00.081] iteration 12056: loss: 0.047845, loss_s1: 0.016132, loss_fp: 0.006405, loss_freq: 0.022446
[16:41:00.704] iteration 12057: loss: 0.058930, loss_s1: 0.029539, loss_fp: 0.001249, loss_freq: 0.035362
[16:41:01.327] iteration 12058: loss: 0.147902, loss_s1: 0.132911, loss_fp: 0.012000, loss_freq: 0.042158
[16:41:01.948] iteration 12059: loss: 0.063267, loss_s1: 0.027071, loss_fp: 0.001354, loss_freq: 0.034627
[16:41:02.569] iteration 12060: loss: 0.091935, loss_s1: 0.057234, loss_fp: 0.004546, loss_freq: 0.024760
[16:41:03.195] iteration 12061: loss: 0.068462, loss_s1: 0.045879, loss_fp: 0.003096, loss_freq: 0.044554
[16:41:03.816] iteration 12062: loss: 0.055201, loss_s1: 0.049710, loss_fp: 0.001465, loss_freq: 0.019167
[16:41:04.436] iteration 12063: loss: 0.066065, loss_s1: 0.044658, loss_fp: 0.004665, loss_freq: 0.031136
[16:41:05.056] iteration 12064: loss: 0.109230, loss_s1: 0.086466, loss_fp: 0.004184, loss_freq: 0.038351
[16:41:05.678] iteration 12065: loss: 0.084567, loss_s1: 0.057817, loss_fp: 0.001633, loss_freq: 0.042367
[16:41:06.302] iteration 12066: loss: 0.112707, loss_s1: 0.095677, loss_fp: 0.006092, loss_freq: 0.085311
[16:41:06.925] iteration 12067: loss: 0.049986, loss_s1: 0.036478, loss_fp: 0.002263, loss_freq: 0.018080
[16:41:07.551] iteration 12068: loss: 0.098886, loss_s1: 0.108729, loss_fp: 0.008997, loss_freq: 0.021432
[16:41:08.175] iteration 12069: loss: 0.042977, loss_s1: 0.020721, loss_fp: 0.002268, loss_freq: 0.025575
[16:41:08.797] iteration 12070: loss: 0.057279, loss_s1: 0.041183, loss_fp: 0.001177, loss_freq: 0.011476
[16:41:09.421] iteration 12071: loss: 0.046231, loss_s1: 0.027813, loss_fp: 0.001785, loss_freq: 0.014146
[16:41:10.048] iteration 12072: loss: 0.093555, loss_s1: 0.072207, loss_fp: 0.006811, loss_freq: 0.027068
[16:41:10.680] iteration 12073: loss: 0.084794, loss_s1: 0.068866, loss_fp: 0.012821, loss_freq: 0.032251
[16:41:11.306] iteration 12074: loss: 0.055765, loss_s1: 0.045250, loss_fp: 0.003485, loss_freq: 0.017659
[16:41:11.933] iteration 12075: loss: 0.078558, loss_s1: 0.034940, loss_fp: 0.013941, loss_freq: 0.051785
[16:41:13.028] iteration 12076: loss: 0.057054, loss_s1: 0.063323, loss_fp: 0.000589, loss_freq: 0.013088
[16:41:13.714] iteration 12077: loss: 0.109120, loss_s1: 0.053436, loss_fp: 0.000803, loss_freq: 0.090351
[16:41:14.371] iteration 12078: loss: 0.069804, loss_s1: 0.027193, loss_fp: 0.004132, loss_freq: 0.024266
[16:41:15.027] iteration 12079: loss: 0.050359, loss_s1: 0.027467, loss_fp: 0.003522, loss_freq: 0.014050
[16:41:15.653] iteration 12080: loss: 0.062649, loss_s1: 0.043449, loss_fp: 0.010469, loss_freq: 0.014201
[16:41:16.279] iteration 12081: loss: 0.144917, loss_s1: 0.104634, loss_fp: 0.004241, loss_freq: 0.064070
[16:41:16.905] iteration 12082: loss: 0.059304, loss_s1: 0.054629, loss_fp: 0.002115, loss_freq: 0.015040
[16:41:17.534] iteration 12083: loss: 0.043840, loss_s1: 0.026408, loss_fp: 0.001046, loss_freq: 0.021888
[16:41:18.165] iteration 12084: loss: 0.064896, loss_s1: 0.045794, loss_fp: 0.015531, loss_freq: 0.026534
[16:41:18.791] iteration 12085: loss: 0.093101, loss_s1: 0.069149, loss_fp: 0.017265, loss_freq: 0.053738
[16:41:19.412] iteration 12086: loss: 0.054947, loss_s1: 0.009551, loss_fp: 0.005214, loss_freq: 0.032268
[16:41:20.034] iteration 12087: loss: 0.080224, loss_s1: 0.055917, loss_fp: 0.001812, loss_freq: 0.066768
[16:41:20.656] iteration 12088: loss: 0.127014, loss_s1: 0.106485, loss_fp: 0.003754, loss_freq: 0.099935
[16:41:21.279] iteration 12089: loss: 0.074443, loss_s1: 0.047721, loss_fp: 0.005402, loss_freq: 0.043990
[16:41:21.934] iteration 12090: loss: 0.063249, loss_s1: 0.038945, loss_fp: 0.003755, loss_freq: 0.036712
[16:41:22.559] iteration 12091: loss: 0.099656, loss_s1: 0.072345, loss_fp: 0.005287, loss_freq: 0.071963
[16:41:23.186] iteration 12092: loss: 0.078845, loss_s1: 0.039531, loss_fp: 0.003178, loss_freq: 0.010217
[16:41:23.818] iteration 12093: loss: 0.070762, loss_s1: 0.047231, loss_fp: 0.001161, loss_freq: 0.033235
[16:41:24.442] iteration 12094: loss: 0.072309, loss_s1: 0.050622, loss_fp: 0.000384, loss_freq: 0.036856
[16:41:25.074] iteration 12095: loss: 0.066381, loss_s1: 0.040314, loss_fp: 0.003914, loss_freq: 0.023241
[16:41:25.699] iteration 12096: loss: 0.064086, loss_s1: 0.050020, loss_fp: 0.001589, loss_freq: 0.012446
[16:41:26.327] iteration 12097: loss: 0.047595, loss_s1: 0.027981, loss_fp: 0.002199, loss_freq: 0.021897
[16:41:26.949] iteration 12098: loss: 0.056756, loss_s1: 0.027392, loss_fp: 0.000556, loss_freq: 0.016272
[16:41:27.575] iteration 12099: loss: 0.157859, loss_s1: 0.109037, loss_fp: 0.001343, loss_freq: 0.159878
[16:41:28.199] iteration 12100: loss: 0.064083, loss_s1: 0.029401, loss_fp: 0.037737, loss_freq: 0.020752
[16:41:28.823] iteration 12101: loss: 0.076927, loss_s1: 0.080490, loss_fp: 0.002192, loss_freq: 0.022617
[16:41:29.446] iteration 12102: loss: 0.049944, loss_s1: 0.027130, loss_fp: 0.000964, loss_freq: 0.023902
[16:41:30.069] iteration 12103: loss: 0.127999, loss_s1: 0.095146, loss_fp: 0.009054, loss_freq: 0.071921
[16:41:30.692] iteration 12104: loss: 0.092180, loss_s1: 0.071810, loss_fp: 0.005658, loss_freq: 0.058411
[16:41:31.319] iteration 12105: loss: 0.058907, loss_s1: 0.035393, loss_fp: 0.002763, loss_freq: 0.011623
[16:41:31.945] iteration 12106: loss: 0.044521, loss_s1: 0.035683, loss_fp: 0.000710, loss_freq: 0.017793
[16:41:32.581] iteration 12107: loss: 0.060071, loss_s1: 0.033907, loss_fp: 0.001642, loss_freq: 0.029030
[16:41:33.221] iteration 12108: loss: 0.056543, loss_s1: 0.036947, loss_fp: 0.001408, loss_freq: 0.039354
[16:41:33.864] iteration 12109: loss: 0.046869, loss_s1: 0.018137, loss_fp: 0.000991, loss_freq: 0.009142
[16:41:34.503] iteration 12110: loss: 0.081020, loss_s1: 0.053706, loss_fp: 0.004066, loss_freq: 0.027933
[16:41:35.145] iteration 12111: loss: 0.073358, loss_s1: 0.066824, loss_fp: 0.002033, loss_freq: 0.025552
[16:41:35.800] iteration 12112: loss: 0.106133, loss_s1: 0.075869, loss_fp: 0.008168, loss_freq: 0.041737
[16:41:36.423] iteration 12113: loss: 0.082718, loss_s1: 0.034804, loss_fp: 0.001899, loss_freq: 0.061208
[16:41:37.047] iteration 12114: loss: 0.085999, loss_s1: 0.044620, loss_fp: 0.001013, loss_freq: 0.055108
[16:41:37.667] iteration 12115: loss: 0.087815, loss_s1: 0.067889, loss_fp: 0.006236, loss_freq: 0.027311
[16:41:38.288] iteration 12116: loss: 0.072125, loss_s1: 0.067638, loss_fp: 0.001270, loss_freq: 0.015790
[16:41:38.911] iteration 12117: loss: 0.118047, loss_s1: 0.094774, loss_fp: 0.001218, loss_freq: 0.096886
[16:41:39.532] iteration 12118: loss: 0.073133, loss_s1: 0.057032, loss_fp: 0.003687, loss_freq: 0.042662
[16:41:40.155] iteration 12119: loss: 0.079283, loss_s1: 0.027925, loss_fp: 0.002311, loss_freq: 0.059699
[16:41:40.777] iteration 12120: loss: 0.057576, loss_s1: 0.026933, loss_fp: 0.004018, loss_freq: 0.030603
[16:41:41.400] iteration 12121: loss: 0.055949, loss_s1: 0.031324, loss_fp: 0.004370, loss_freq: 0.015343
[16:41:42.021] iteration 12122: loss: 0.056248, loss_s1: 0.028101, loss_fp: 0.002399, loss_freq: 0.020569
[16:41:42.640] iteration 12123: loss: 0.067985, loss_s1: 0.056852, loss_fp: 0.005628, loss_freq: 0.033689
[16:41:43.265] iteration 12124: loss: 0.052426, loss_s1: 0.034384, loss_fp: 0.007494, loss_freq: 0.014344
[16:41:43.891] iteration 12125: loss: 0.100617, loss_s1: 0.111154, loss_fp: 0.002184, loss_freq: 0.028765
[16:41:44.512] iteration 12126: loss: 0.048099, loss_s1: 0.037506, loss_fp: 0.001443, loss_freq: 0.018926
[16:41:45.135] iteration 12127: loss: 0.065922, loss_s1: 0.045444, loss_fp: 0.002118, loss_freq: 0.024487
[16:41:45.758] iteration 12128: loss: 0.068326, loss_s1: 0.025723, loss_fp: 0.001541, loss_freq: 0.039313
[16:41:46.387] iteration 12129: loss: 0.072414, loss_s1: 0.065652, loss_fp: 0.001909, loss_freq: 0.031410
[16:41:47.010] iteration 12130: loss: 0.098593, loss_s1: 0.036240, loss_fp: 0.002023, loss_freq: 0.016554
[16:41:47.635] iteration 12131: loss: 0.063577, loss_s1: 0.040292, loss_fp: 0.007344, loss_freq: 0.023375
[16:41:48.260] iteration 12132: loss: 0.047073, loss_s1: 0.031708, loss_fp: 0.001386, loss_freq: 0.004759
[16:41:48.886] iteration 12133: loss: 0.080516, loss_s1: 0.052816, loss_fp: 0.002010, loss_freq: 0.030007
[16:41:49.515] iteration 12134: loss: 0.053512, loss_s1: 0.039014, loss_fp: 0.006780, loss_freq: 0.018966
[16:41:50.141] iteration 12135: loss: 0.048925, loss_s1: 0.033543, loss_fp: 0.005616, loss_freq: 0.018004
[16:41:50.768] iteration 12136: loss: 0.049100, loss_s1: 0.017861, loss_fp: 0.002721, loss_freq: 0.017586
[16:41:51.396] iteration 12137: loss: 0.047650, loss_s1: 0.016344, loss_fp: 0.000501, loss_freq: 0.030606
[16:41:52.020] iteration 12138: loss: 0.066880, loss_s1: 0.037638, loss_fp: 0.004353, loss_freq: 0.010401
[16:41:52.648] iteration 12139: loss: 0.061463, loss_s1: 0.034554, loss_fp: 0.005628, loss_freq: 0.026695
[16:41:53.275] iteration 12140: loss: 0.047277, loss_s1: 0.026081, loss_fp: 0.001659, loss_freq: 0.014323
[16:41:53.900] iteration 12141: loss: 0.058935, loss_s1: 0.030766, loss_fp: 0.002235, loss_freq: 0.049146
[16:41:54.524] iteration 12142: loss: 0.098508, loss_s1: 0.037340, loss_fp: 0.002491, loss_freq: 0.049490
[16:41:55.151] iteration 12143: loss: 0.069294, loss_s1: 0.063820, loss_fp: 0.001284, loss_freq: 0.029480
[16:41:55.776] iteration 12144: loss: 0.060693, loss_s1: 0.064431, loss_fp: 0.001704, loss_freq: 0.015859
[16:41:56.401] iteration 12145: loss: 0.107902, loss_s1: 0.071588, loss_fp: 0.006560, loss_freq: 0.052241
[16:41:57.022] iteration 12146: loss: 0.095291, loss_s1: 0.086787, loss_fp: 0.012623, loss_freq: 0.033518
[16:41:57.645] iteration 12147: loss: 0.074763, loss_s1: 0.081281, loss_fp: 0.001016, loss_freq: 0.022204
[16:41:58.268] iteration 12148: loss: 0.096576, loss_s1: 0.067563, loss_fp: 0.000621, loss_freq: 0.046475
[16:41:58.894] iteration 12149: loss: 0.067530, loss_s1: 0.018472, loss_fp: 0.003814, loss_freq: 0.035859
[16:41:59.517] iteration 12150: loss: 0.090101, loss_s1: 0.079797, loss_fp: 0.003227, loss_freq: 0.050919
[16:42:00.141] iteration 12151: loss: 0.079909, loss_s1: 0.079810, loss_fp: 0.001355, loss_freq: 0.017930
[16:42:00.765] iteration 12152: loss: 0.075249, loss_s1: 0.059484, loss_fp: 0.003628, loss_freq: 0.041277
[16:42:01.390] iteration 12153: loss: 0.086193, loss_s1: 0.098828, loss_fp: 0.008320, loss_freq: 0.023688
[16:42:02.010] iteration 12154: loss: 0.057703, loss_s1: 0.046007, loss_fp: 0.006007, loss_freq: 0.014479
[16:42:02.632] iteration 12155: loss: 0.083702, loss_s1: 0.087208, loss_fp: 0.000973, loss_freq: 0.032109
[16:42:03.256] iteration 12156: loss: 0.060230, loss_s1: 0.027058, loss_fp: 0.001065, loss_freq: 0.030981
[16:42:03.879] iteration 12157: loss: 0.081003, loss_s1: 0.077136, loss_fp: 0.001225, loss_freq: 0.048901
[16:42:04.504] iteration 12158: loss: 0.078181, loss_s1: 0.068066, loss_fp: 0.019548, loss_freq: 0.027658
[16:42:05.128] iteration 12159: loss: 0.134009, loss_s1: 0.092587, loss_fp: 0.010807, loss_freq: 0.036855
[16:42:05.751] iteration 12160: loss: 0.149160, loss_s1: 0.173126, loss_fp: 0.004501, loss_freq: 0.088629
[16:42:06.411] iteration 12161: loss: 0.049507, loss_s1: 0.035545, loss_fp: 0.002962, loss_freq: 0.019058
[16:42:07.067] iteration 12162: loss: 0.072333, loss_s1: 0.046018, loss_fp: 0.000834, loss_freq: 0.024667
[16:42:07.699] iteration 12163: loss: 0.056612, loss_s1: 0.049314, loss_fp: 0.001439, loss_freq: 0.022806
[16:42:08.320] iteration 12164: loss: 0.074677, loss_s1: 0.071659, loss_fp: 0.001984, loss_freq: 0.032371
[16:42:08.944] iteration 12165: loss: 0.059572, loss_s1: 0.044160, loss_fp: 0.006092, loss_freq: 0.014001
[16:42:09.569] iteration 12166: loss: 0.109195, loss_s1: 0.055394, loss_fp: 0.001081, loss_freq: 0.062957
[16:42:10.191] iteration 12167: loss: 0.084700, loss_s1: 0.045056, loss_fp: 0.001282, loss_freq: 0.020323
[16:42:10.821] iteration 12168: loss: 0.082800, loss_s1: 0.034833, loss_fp: 0.001782, loss_freq: 0.030243
[16:42:11.448] iteration 12169: loss: 0.059447, loss_s1: 0.064479, loss_fp: 0.001120, loss_freq: 0.013011
[16:42:12.076] iteration 12170: loss: 0.059464, loss_s1: 0.032981, loss_fp: 0.003016, loss_freq: 0.048825
[16:42:12.699] iteration 12171: loss: 0.049313, loss_s1: 0.043603, loss_fp: 0.004760, loss_freq: 0.014926
[16:42:13.319] iteration 12172: loss: 0.058349, loss_s1: 0.026164, loss_fp: 0.002561, loss_freq: 0.026621
[16:42:13.950] iteration 12173: loss: 0.077737, loss_s1: 0.038647, loss_fp: 0.001898, loss_freq: 0.057694
[16:42:14.581] iteration 12174: loss: 0.066882, loss_s1: 0.054123, loss_fp: 0.001876, loss_freq: 0.014138
[16:42:15.227] iteration 12175: loss: 0.059913, loss_s1: 0.038805, loss_fp: 0.004668, loss_freq: 0.020738
[16:42:15.850] iteration 12176: loss: 0.046075, loss_s1: 0.020771, loss_fp: 0.001564, loss_freq: 0.020126
[16:42:16.477] iteration 12177: loss: 0.081653, loss_s1: 0.061725, loss_fp: 0.003433, loss_freq: 0.048662
[16:42:17.101] iteration 12178: loss: 0.130102, loss_s1: 0.148182, loss_fp: 0.003888, loss_freq: 0.048446
[16:42:17.728] iteration 12179: loss: 0.070513, loss_s1: 0.044481, loss_fp: 0.002596, loss_freq: 0.047725
[16:42:18.355] iteration 12180: loss: 0.046099, loss_s1: 0.008715, loss_fp: 0.000450, loss_freq: 0.018602
[16:42:18.979] iteration 12181: loss: 0.050338, loss_s1: 0.032505, loss_fp: 0.001611, loss_freq: 0.025857
[16:42:19.607] iteration 12182: loss: 0.065051, loss_s1: 0.024666, loss_fp: 0.006780, loss_freq: 0.025190
[16:42:20.234] iteration 12183: loss: 0.073841, loss_s1: 0.057529, loss_fp: 0.003560, loss_freq: 0.040128
[16:42:20.863] iteration 12184: loss: 0.204122, loss_s1: 0.148513, loss_fp: 0.021576, loss_freq: 0.143548
[16:42:21.492] iteration 12185: loss: 0.044740, loss_s1: 0.026216, loss_fp: 0.000991, loss_freq: 0.024466
[16:42:22.122] iteration 12186: loss: 0.055942, loss_s1: 0.038627, loss_fp: 0.000472, loss_freq: 0.017705
[16:42:22.753] iteration 12187: loss: 0.054203, loss_s1: 0.030587, loss_fp: 0.000846, loss_freq: 0.033499
[16:42:23.387] iteration 12188: loss: 0.095047, loss_s1: 0.051122, loss_fp: 0.004719, loss_freq: 0.080357
[16:42:24.014] iteration 12189: loss: 0.052078, loss_s1: 0.024414, loss_fp: 0.000562, loss_freq: 0.025747
[16:42:24.641] iteration 12190: loss: 0.039971, loss_s1: 0.021257, loss_fp: 0.004524, loss_freq: 0.005155
[16:42:25.273] iteration 12191: loss: 0.058959, loss_s1: 0.042121, loss_fp: 0.001997, loss_freq: 0.025214
[16:42:25.901] iteration 12192: loss: 0.097181, loss_s1: 0.093133, loss_fp: 0.002625, loss_freq: 0.057915
[16:42:26.535] iteration 12193: loss: 0.063819, loss_s1: 0.029962, loss_fp: 0.001419, loss_freq: 0.040377
[16:42:27.163] iteration 12194: loss: 0.049458, loss_s1: 0.019300, loss_fp: 0.002883, loss_freq: 0.031621
[16:42:27.789] iteration 12195: loss: 0.056198, loss_s1: 0.006602, loss_fp: 0.005837, loss_freq: 0.057077
[16:42:28.420] iteration 12196: loss: 0.090769, loss_s1: 0.049468, loss_fp: 0.000894, loss_freq: 0.083419
[16:42:29.050] iteration 12197: loss: 0.059922, loss_s1: 0.040408, loss_fp: 0.003049, loss_freq: 0.017182
[16:42:29.681] iteration 12198: loss: 0.074046, loss_s1: 0.053370, loss_fp: 0.003760, loss_freq: 0.022133
[16:42:30.313] iteration 12199: loss: 0.056152, loss_s1: 0.060178, loss_fp: 0.000659, loss_freq: 0.012012
[16:42:30.937] iteration 12200: loss: 0.066984, loss_s1: 0.024225, loss_fp: 0.002275, loss_freq: 0.026657
[16:42:34.186] iteration 12200 : mean_dice : 0.701346
[16:42:34.868] iteration 12201: loss: 0.090784, loss_s1: 0.061445, loss_fp: 0.006404, loss_freq: 0.033230
[16:42:35.490] iteration 12202: loss: 0.096842, loss_s1: 0.089580, loss_fp: 0.004176, loss_freq: 0.027541
[16:42:36.115] iteration 12203: loss: 0.090540, loss_s1: 0.067126, loss_fp: 0.000877, loss_freq: 0.043493
[16:42:36.741] iteration 12204: loss: 0.082983, loss_s1: 0.083987, loss_fp: 0.001487, loss_freq: 0.041928
[16:42:37.364] iteration 12205: loss: 0.056398, loss_s1: 0.042809, loss_fp: 0.002177, loss_freq: 0.013524
[16:42:37.984] iteration 12206: loss: 0.082010, loss_s1: 0.054844, loss_fp: 0.005076, loss_freq: 0.049462
[16:42:38.606] iteration 12207: loss: 0.065804, loss_s1: 0.060336, loss_fp: 0.003850, loss_freq: 0.018891
[16:42:39.228] iteration 12208: loss: 0.056504, loss_s1: 0.041300, loss_fp: 0.007785, loss_freq: 0.019849
[16:42:39.857] iteration 12209: loss: 0.055924, loss_s1: 0.030170, loss_fp: 0.001698, loss_freq: 0.015965
[16:42:40.482] iteration 12210: loss: 0.092752, loss_s1: 0.041678, loss_fp: 0.004879, loss_freq: 0.081800
[16:42:41.111] iteration 12211: loss: 0.079517, loss_s1: 0.075284, loss_fp: 0.002123, loss_freq: 0.027424
[16:42:41.739] iteration 12212: loss: 0.074923, loss_s1: 0.040053, loss_fp: 0.000532, loss_freq: 0.021022
[16:42:42.371] iteration 12213: loss: 0.070707, loss_s1: 0.054128, loss_fp: 0.006794, loss_freq: 0.028483
[16:42:42.997] iteration 12214: loss: 0.051200, loss_s1: 0.035181, loss_fp: 0.002064, loss_freq: 0.025189
[16:42:43.621] iteration 12215: loss: 0.081546, loss_s1: 0.064974, loss_fp: 0.008265, loss_freq: 0.021585
[16:42:44.247] iteration 12216: loss: 0.096026, loss_s1: 0.095668, loss_fp: 0.013992, loss_freq: 0.044782
[16:42:44.876] iteration 12217: loss: 0.067494, loss_s1: 0.053176, loss_fp: 0.004407, loss_freq: 0.028017
[16:42:45.504] iteration 12218: loss: 0.083676, loss_s1: 0.043941, loss_fp: 0.002852, loss_freq: 0.051217
[16:42:46.132] iteration 12219: loss: 0.094327, loss_s1: 0.103824, loss_fp: 0.002467, loss_freq: 0.032509
[16:42:46.759] iteration 12220: loss: 0.047332, loss_s1: 0.026846, loss_fp: 0.004316, loss_freq: 0.019174
[16:42:47.395] iteration 12221: loss: 0.085762, loss_s1: 0.064230, loss_fp: 0.007684, loss_freq: 0.034600
[16:42:48.028] iteration 12222: loss: 0.150337, loss_s1: 0.119039, loss_fp: 0.009019, loss_freq: 0.127779
[16:42:48.661] iteration 12223: loss: 0.042344, loss_s1: 0.022967, loss_fp: 0.002629, loss_freq: 0.019587
[16:42:49.315] iteration 12224: loss: 0.043588, loss_s1: 0.018467, loss_fp: 0.003390, loss_freq: 0.010499
[16:42:49.979] iteration 12225: loss: 0.087479, loss_s1: 0.067412, loss_fp: 0.009826, loss_freq: 0.039869
[16:42:50.645] iteration 12226: loss: 0.082766, loss_s1: 0.070632, loss_fp: 0.002442, loss_freq: 0.041440
[16:42:51.302] iteration 12227: loss: 0.085160, loss_s1: 0.061833, loss_fp: 0.003608, loss_freq: 0.049598
[16:42:51.932] iteration 12228: loss: 0.074188, loss_s1: 0.077032, loss_fp: 0.003941, loss_freq: 0.031340
[16:42:52.592] iteration 12229: loss: 0.066878, loss_s1: 0.052270, loss_fp: 0.000915, loss_freq: 0.023783
[16:42:53.219] iteration 12230: loss: 0.048447, loss_s1: 0.032498, loss_fp: 0.002432, loss_freq: 0.009989
[16:42:53.842] iteration 12231: loss: 0.060458, loss_s1: 0.034820, loss_fp: 0.002914, loss_freq: 0.030398
[16:42:54.467] iteration 12232: loss: 0.050704, loss_s1: 0.016574, loss_fp: 0.001104, loss_freq: 0.026961
[16:42:55.089] iteration 12233: loss: 0.088610, loss_s1: 0.064021, loss_fp: 0.002835, loss_freq: 0.022265
[16:42:55.711] iteration 12234: loss: 0.069132, loss_s1: 0.036877, loss_fp: 0.005125, loss_freq: 0.043729
[16:42:56.331] iteration 12235: loss: 0.078068, loss_s1: 0.044656, loss_fp: 0.003090, loss_freq: 0.013118
[16:42:56.949] iteration 12236: loss: 0.076481, loss_s1: 0.061206, loss_fp: 0.001356, loss_freq: 0.038753
[16:42:57.996] iteration 12237: loss: 0.035762, loss_s1: 0.019548, loss_fp: 0.000783, loss_freq: 0.006325
[16:42:58.653] iteration 12238: loss: 0.089134, loss_s1: 0.073242, loss_fp: 0.005025, loss_freq: 0.034265
[16:42:59.308] iteration 12239: loss: 0.069773, loss_s1: 0.033986, loss_fp: 0.002951, loss_freq: 0.025820
[16:42:59.964] iteration 12240: loss: 0.047413, loss_s1: 0.015692, loss_fp: 0.001984, loss_freq: 0.011840
[16:43:00.626] iteration 12241: loss: 0.068545, loss_s1: 0.053722, loss_fp: 0.000851, loss_freq: 0.020894
[16:43:01.280] iteration 12242: loss: 0.098470, loss_s1: 0.052266, loss_fp: 0.004327, loss_freq: 0.047732
[16:43:01.910] iteration 12243: loss: 0.050966, loss_s1: 0.039964, loss_fp: 0.002352, loss_freq: 0.016447
[16:43:02.567] iteration 12244: loss: 0.058407, loss_s1: 0.035896, loss_fp: 0.002757, loss_freq: 0.040477
[16:43:03.231] iteration 12245: loss: 0.054456, loss_s1: 0.038785, loss_fp: 0.002164, loss_freq: 0.027853
[16:43:03.890] iteration 12246: loss: 0.068912, loss_s1: 0.058183, loss_fp: 0.005837, loss_freq: 0.031651
[16:43:04.520] iteration 12247: loss: 0.047844, loss_s1: 0.021111, loss_fp: 0.001905, loss_freq: 0.013451
[16:43:05.146] iteration 12248: loss: 0.045407, loss_s1: 0.016334, loss_fp: 0.000583, loss_freq: 0.036339
[16:43:05.774] iteration 12249: loss: 0.102221, loss_s1: 0.075196, loss_fp: 0.002920, loss_freq: 0.087621
[16:43:06.401] iteration 12250: loss: 0.083468, loss_s1: 0.054023, loss_fp: 0.007315, loss_freq: 0.027296
[16:43:07.029] iteration 12251: loss: 0.077093, loss_s1: 0.071736, loss_fp: 0.001743, loss_freq: 0.042391
[16:43:07.654] iteration 12252: loss: 0.078022, loss_s1: 0.051148, loss_fp: 0.009246, loss_freq: 0.057198
[16:43:08.282] iteration 12253: loss: 0.071334, loss_s1: 0.057836, loss_fp: 0.005571, loss_freq: 0.015056
[16:43:08.909] iteration 12254: loss: 0.048081, loss_s1: 0.021183, loss_fp: 0.002685, loss_freq: 0.024762
[16:43:09.535] iteration 12255: loss: 0.063557, loss_s1: 0.045411, loss_fp: 0.000462, loss_freq: 0.023624
[16:43:10.162] iteration 12256: loss: 0.137462, loss_s1: 0.120105, loss_fp: 0.009018, loss_freq: 0.026855
[16:43:10.813] iteration 12257: loss: 0.050261, loss_s1: 0.019324, loss_fp: 0.000936, loss_freq: 0.008182
[16:43:11.473] iteration 12258: loss: 0.077530, loss_s1: 0.042994, loss_fp: 0.002611, loss_freq: 0.020798
[16:43:12.104] iteration 12259: loss: 0.078042, loss_s1: 0.069131, loss_fp: 0.001326, loss_freq: 0.030943
[16:43:12.730] iteration 12260: loss: 0.134621, loss_s1: 0.073592, loss_fp: 0.003447, loss_freq: 0.128839
[16:43:13.358] iteration 12261: loss: 0.058863, loss_s1: 0.047169, loss_fp: 0.002240, loss_freq: 0.022237
[16:43:14.000] iteration 12262: loss: 0.073974, loss_s1: 0.049798, loss_fp: 0.004605, loss_freq: 0.025274
[16:43:14.631] iteration 12263: loss: 0.040104, loss_s1: 0.024592, loss_fp: 0.000692, loss_freq: 0.007184
[16:43:15.262] iteration 12264: loss: 0.101547, loss_s1: 0.084926, loss_fp: 0.002780, loss_freq: 0.056824
[16:43:15.895] iteration 12265: loss: 0.080608, loss_s1: 0.063311, loss_fp: 0.001804, loss_freq: 0.035723
[16:43:16.518] iteration 12266: loss: 0.054807, loss_s1: 0.050690, loss_fp: 0.001058, loss_freq: 0.013898
[16:43:17.141] iteration 12267: loss: 0.063963, loss_s1: 0.043024, loss_fp: 0.013360, loss_freq: 0.032468
[16:43:17.796] iteration 12268: loss: 0.077247, loss_s1: 0.041722, loss_fp: 0.002165, loss_freq: 0.011391
[16:43:18.419] iteration 12269: loss: 0.044206, loss_s1: 0.023215, loss_fp: 0.001336, loss_freq: 0.024139
[16:43:19.043] iteration 12270: loss: 0.059389, loss_s1: 0.043769, loss_fp: 0.006868, loss_freq: 0.021238
[16:43:19.673] iteration 12271: loss: 0.069485, loss_s1: 0.024491, loss_fp: 0.000689, loss_freq: 0.039633
[16:43:20.298] iteration 12272: loss: 0.089571, loss_s1: 0.083540, loss_fp: 0.012067, loss_freq: 0.041102
[16:43:20.925] iteration 12273: loss: 0.095179, loss_s1: 0.110194, loss_fp: 0.005565, loss_freq: 0.027274
[16:43:21.551] iteration 12274: loss: 0.111866, loss_s1: 0.079528, loss_fp: 0.012747, loss_freq: 0.036965
[16:43:22.179] iteration 12275: loss: 0.148229, loss_s1: 0.134982, loss_fp: 0.004023, loss_freq: 0.061335
[16:43:22.806] iteration 12276: loss: 0.092076, loss_s1: 0.065445, loss_fp: 0.002931, loss_freq: 0.055732
[16:43:23.435] iteration 12277: loss: 0.064072, loss_s1: 0.035626, loss_fp: 0.003509, loss_freq: 0.011417
[16:43:24.068] iteration 12278: loss: 0.106245, loss_s1: 0.112530, loss_fp: 0.004003, loss_freq: 0.058060
[16:43:24.694] iteration 12279: loss: 0.065024, loss_s1: 0.027126, loss_fp: 0.002981, loss_freq: 0.023686
[16:43:25.319] iteration 12280: loss: 0.068821, loss_s1: 0.044391, loss_fp: 0.008981, loss_freq: 0.023943
[16:43:25.944] iteration 12281: loss: 0.079646, loss_s1: 0.048330, loss_fp: 0.002220, loss_freq: 0.050550
[16:43:26.568] iteration 12282: loss: 0.074098, loss_s1: 0.073935, loss_fp: 0.001850, loss_freq: 0.010339
[16:43:27.195] iteration 12283: loss: 0.036653, loss_s1: 0.015451, loss_fp: 0.000869, loss_freq: 0.007235
[16:43:27.817] iteration 12284: loss: 0.071283, loss_s1: 0.050814, loss_fp: 0.016661, loss_freq: 0.033411
[16:43:28.443] iteration 12285: loss: 0.085746, loss_s1: 0.093863, loss_fp: 0.002136, loss_freq: 0.018810
[16:43:29.067] iteration 12286: loss: 0.071707, loss_s1: 0.055551, loss_fp: 0.002345, loss_freq: 0.038524
[16:43:29.694] iteration 12287: loss: 0.061667, loss_s1: 0.038349, loss_fp: 0.004437, loss_freq: 0.042736
[16:43:30.318] iteration 12288: loss: 0.068467, loss_s1: 0.034163, loss_fp: 0.000618, loss_freq: 0.027465
[16:43:30.942] iteration 12289: loss: 0.053711, loss_s1: 0.031496, loss_fp: 0.001975, loss_freq: 0.025855
[16:43:31.582] iteration 12290: loss: 0.069191, loss_s1: 0.035623, loss_fp: 0.004688, loss_freq: 0.043535
[16:43:32.208] iteration 12291: loss: 0.065727, loss_s1: 0.023943, loss_fp: 0.007306, loss_freq: 0.023994
[16:43:32.828] iteration 12292: loss: 0.083848, loss_s1: 0.091040, loss_fp: 0.002487, loss_freq: 0.014634
[16:43:33.451] iteration 12293: loss: 0.045744, loss_s1: 0.023279, loss_fp: 0.011307, loss_freq: 0.009169
[16:43:34.073] iteration 12294: loss: 0.089503, loss_s1: 0.043555, loss_fp: 0.000734, loss_freq: 0.048743
[16:43:34.698] iteration 12295: loss: 0.050065, loss_s1: 0.045991, loss_fp: 0.001823, loss_freq: 0.018009
[16:43:35.320] iteration 12296: loss: 0.069753, loss_s1: 0.042070, loss_fp: 0.000906, loss_freq: 0.034708
[16:43:35.945] iteration 12297: loss: 0.062347, loss_s1: 0.059104, loss_fp: 0.007783, loss_freq: 0.010574
[16:43:36.563] iteration 12298: loss: 0.046490, loss_s1: 0.041922, loss_fp: 0.002357, loss_freq: 0.013879
[16:43:37.185] iteration 12299: loss: 0.049910, loss_s1: 0.022955, loss_fp: 0.000592, loss_freq: 0.024140
[16:43:37.808] iteration 12300: loss: 0.057524, loss_s1: 0.040342, loss_fp: 0.008438, loss_freq: 0.021751
[16:43:38.433] iteration 12301: loss: 0.049321, loss_s1: 0.024531, loss_fp: 0.003172, loss_freq: 0.017905
[16:43:39.096] iteration 12302: loss: 0.088048, loss_s1: 0.061539, loss_fp: 0.004916, loss_freq: 0.046971
[16:43:39.754] iteration 12303: loss: 0.063507, loss_s1: 0.030504, loss_fp: 0.001529, loss_freq: 0.030878
[16:43:40.393] iteration 12304: loss: 0.063565, loss_s1: 0.049915, loss_fp: 0.001482, loss_freq: 0.030029
[16:43:41.015] iteration 12305: loss: 0.072804, loss_s1: 0.070262, loss_fp: 0.002180, loss_freq: 0.030092
[16:43:41.636] iteration 12306: loss: 0.065026, loss_s1: 0.032870, loss_fp: 0.001189, loss_freq: 0.027164
[16:43:42.261] iteration 12307: loss: 0.081811, loss_s1: 0.082468, loss_fp: 0.004291, loss_freq: 0.030222
[16:43:42.885] iteration 12308: loss: 0.065254, loss_s1: 0.032948, loss_fp: 0.000717, loss_freq: 0.022496
[16:43:43.507] iteration 12309: loss: 0.099134, loss_s1: 0.064763, loss_fp: 0.001263, loss_freq: 0.047986
[16:43:44.128] iteration 12310: loss: 0.046370, loss_s1: 0.020676, loss_fp: 0.001921, loss_freq: 0.008439
[16:43:44.754] iteration 12311: loss: 0.056457, loss_s1: 0.041108, loss_fp: 0.001059, loss_freq: 0.024561
[16:43:45.376] iteration 12312: loss: 0.087391, loss_s1: 0.081099, loss_fp: 0.001955, loss_freq: 0.021268
[16:43:45.999] iteration 12313: loss: 0.072737, loss_s1: 0.053408, loss_fp: 0.000833, loss_freq: 0.049135
[16:43:46.618] iteration 12314: loss: 0.052062, loss_s1: 0.024777, loss_fp: 0.002761, loss_freq: 0.015977
[16:43:47.243] iteration 12315: loss: 0.041687, loss_s1: 0.019907, loss_fp: 0.000509, loss_freq: 0.011478
[16:43:47.867] iteration 12316: loss: 0.060851, loss_s1: 0.030337, loss_fp: 0.011380, loss_freq: 0.034998
[16:43:48.492] iteration 12317: loss: 0.059499, loss_s1: 0.045814, loss_fp: 0.001752, loss_freq: 0.019923
[16:43:49.115] iteration 12318: loss: 0.069992, loss_s1: 0.050895, loss_fp: 0.004393, loss_freq: 0.045963
[16:43:49.740] iteration 12319: loss: 0.104125, loss_s1: 0.093505, loss_fp: 0.001208, loss_freq: 0.074276
[16:43:50.363] iteration 12320: loss: 0.094482, loss_s1: 0.027858, loss_fp: 0.001023, loss_freq: 0.040727
[16:43:50.986] iteration 12321: loss: 0.123944, loss_s1: 0.116565, loss_fp: 0.008455, loss_freq: 0.084459
[16:43:51.609] iteration 12322: loss: 0.044338, loss_s1: 0.027237, loss_fp: 0.000933, loss_freq: 0.019848
[16:43:52.232] iteration 12323: loss: 0.085163, loss_s1: 0.028647, loss_fp: 0.000444, loss_freq: 0.031300
[16:43:52.853] iteration 12324: loss: 0.054421, loss_s1: 0.041396, loss_fp: 0.001309, loss_freq: 0.014696
[16:43:53.477] iteration 12325: loss: 0.079034, loss_s1: 0.053976, loss_fp: 0.002273, loss_freq: 0.053137
[16:43:54.097] iteration 12326: loss: 0.074533, loss_s1: 0.051060, loss_fp: 0.003861, loss_freq: 0.053123
[16:43:54.721] iteration 12327: loss: 0.077193, loss_s1: 0.056585, loss_fp: 0.001755, loss_freq: 0.033147
[16:43:55.351] iteration 12328: loss: 0.052912, loss_s1: 0.025481, loss_fp: 0.005390, loss_freq: 0.030142
[16:43:55.975] iteration 12329: loss: 0.102268, loss_s1: 0.034224, loss_fp: 0.002232, loss_freq: 0.014132
[16:43:56.597] iteration 12330: loss: 0.039828, loss_s1: 0.017074, loss_fp: 0.005860, loss_freq: 0.014995
[16:43:57.224] iteration 12331: loss: 0.054489, loss_s1: 0.034449, loss_fp: 0.001368, loss_freq: 0.035676
[16:43:57.853] iteration 12332: loss: 0.055092, loss_s1: 0.022817, loss_fp: 0.002113, loss_freq: 0.019937
[16:43:58.492] iteration 12333: loss: 0.060282, loss_s1: 0.043423, loss_fp: 0.000657, loss_freq: 0.023687
[16:43:59.118] iteration 12334: loss: 0.048792, loss_s1: 0.028478, loss_fp: 0.003028, loss_freq: 0.015136
[16:43:59.747] iteration 12335: loss: 0.053187, loss_s1: 0.046924, loss_fp: 0.002350, loss_freq: 0.014846
[16:44:00.372] iteration 12336: loss: 0.055048, loss_s1: 0.037054, loss_fp: 0.005644, loss_freq: 0.026368
[16:44:00.999] iteration 12337: loss: 0.060463, loss_s1: 0.045316, loss_fp: 0.002501, loss_freq: 0.037660
[16:44:01.630] iteration 12338: loss: 0.061993, loss_s1: 0.030704, loss_fp: 0.004195, loss_freq: 0.041176
[16:44:02.286] iteration 12339: loss: 0.077067, loss_s1: 0.047911, loss_fp: 0.007405, loss_freq: 0.044140
[16:44:02.913] iteration 12340: loss: 0.078234, loss_s1: 0.053072, loss_fp: 0.003826, loss_freq: 0.051579
[16:44:03.542] iteration 12341: loss: 0.059724, loss_s1: 0.019349, loss_fp: 0.002790, loss_freq: 0.018009
[16:44:04.172] iteration 12342: loss: 0.089279, loss_s1: 0.088037, loss_fp: 0.005086, loss_freq: 0.035068
[16:44:04.797] iteration 12343: loss: 0.044771, loss_s1: 0.028880, loss_fp: 0.002891, loss_freq: 0.006692
[16:44:05.424] iteration 12344: loss: 0.101816, loss_s1: 0.040518, loss_fp: 0.000920, loss_freq: 0.051941
[16:44:06.050] iteration 12345: loss: 0.139805, loss_s1: 0.095638, loss_fp: 0.005038, loss_freq: 0.130529
[16:44:06.668] iteration 12346: loss: 0.067579, loss_s1: 0.021596, loss_fp: 0.001022, loss_freq: 0.033055
[16:44:07.329] iteration 12347: loss: 0.081939, loss_s1: 0.039022, loss_fp: 0.001241, loss_freq: 0.045810
[16:44:07.991] iteration 12348: loss: 0.067101, loss_s1: 0.029619, loss_fp: 0.011706, loss_freq: 0.044187
[16:44:08.636] iteration 12349: loss: 0.062281, loss_s1: 0.030977, loss_fp: 0.003005, loss_freq: 0.034578
[16:44:09.261] iteration 12350: loss: 0.058355, loss_s1: 0.034252, loss_fp: 0.001673, loss_freq: 0.041454
[16:44:09.888] iteration 12351: loss: 0.042641, loss_s1: 0.028047, loss_fp: 0.000729, loss_freq: 0.006266
[16:44:10.509] iteration 12352: loss: 0.069209, loss_s1: 0.057412, loss_fp: 0.002739, loss_freq: 0.022662
[16:44:11.130] iteration 12353: loss: 0.042026, loss_s1: 0.030645, loss_fp: 0.008049, loss_freq: 0.013046
[16:44:11.752] iteration 12354: loss: 0.056471, loss_s1: 0.055720, loss_fp: 0.002490, loss_freq: 0.011585
[16:44:12.375] iteration 12355: loss: 0.055084, loss_s1: 0.013438, loss_fp: 0.003326, loss_freq: 0.018657
[16:44:12.999] iteration 12356: loss: 0.118724, loss_s1: 0.123442, loss_fp: 0.003237, loss_freq: 0.068599
[16:44:13.622] iteration 12357: loss: 0.057146, loss_s1: 0.046775, loss_fp: 0.003933, loss_freq: 0.020054
[16:44:14.245] iteration 12358: loss: 0.062475, loss_s1: 0.037488, loss_fp: 0.001799, loss_freq: 0.015991
[16:44:14.870] iteration 12359: loss: 0.033598, loss_s1: 0.020148, loss_fp: 0.000925, loss_freq: 0.006948
[16:44:15.495] iteration 12360: loss: 0.074301, loss_s1: 0.049596, loss_fp: 0.002329, loss_freq: 0.040477
[16:44:16.119] iteration 12361: loss: 0.080450, loss_s1: 0.066269, loss_fp: 0.002168, loss_freq: 0.025157
[16:44:16.748] iteration 12362: loss: 0.082208, loss_s1: 0.028062, loss_fp: 0.002554, loss_freq: 0.015386
[16:44:17.375] iteration 12363: loss: 0.043855, loss_s1: 0.018759, loss_fp: 0.001601, loss_freq: 0.018842
[16:44:18.000] iteration 12364: loss: 0.140835, loss_s1: 0.104920, loss_fp: 0.016420, loss_freq: 0.101186
[16:44:18.627] iteration 12365: loss: 0.069728, loss_s1: 0.053373, loss_fp: 0.006865, loss_freq: 0.017530
[16:44:19.252] iteration 12366: loss: 0.062781, loss_s1: 0.044972, loss_fp: 0.009099, loss_freq: 0.014783
[16:44:19.880] iteration 12367: loss: 0.096720, loss_s1: 0.061093, loss_fp: 0.008014, loss_freq: 0.076055
[16:44:20.503] iteration 12368: loss: 0.130757, loss_s1: 0.124431, loss_fp: 0.001371, loss_freq: 0.017011
[16:44:21.130] iteration 12369: loss: 0.069956, loss_s1: 0.034686, loss_fp: 0.004846, loss_freq: 0.013164
[16:44:21.756] iteration 12370: loss: 0.061644, loss_s1: 0.055221, loss_fp: 0.004021, loss_freq: 0.016387
[16:44:22.379] iteration 12371: loss: 0.107702, loss_s1: 0.117463, loss_fp: 0.002704, loss_freq: 0.045676
[16:44:23.005] iteration 12372: loss: 0.045523, loss_s1: 0.023290, loss_fp: 0.011121, loss_freq: 0.013840
[16:44:23.634] iteration 12373: loss: 0.059508, loss_s1: 0.010991, loss_fp: 0.001263, loss_freq: 0.041735
[16:44:24.252] iteration 12374: loss: 0.056889, loss_s1: 0.045808, loss_fp: 0.001106, loss_freq: 0.035483
[16:44:24.878] iteration 12375: loss: 0.091124, loss_s1: 0.050516, loss_fp: 0.001240, loss_freq: 0.020225
[16:44:25.501] iteration 12376: loss: 0.059821, loss_s1: 0.028104, loss_fp: 0.001547, loss_freq: 0.019549
[16:44:26.125] iteration 12377: loss: 0.075840, loss_s1: 0.067048, loss_fp: 0.004506, loss_freq: 0.042868
[16:44:26.752] iteration 12378: loss: 0.075420, loss_s1: 0.052033, loss_fp: 0.002480, loss_freq: 0.027452
[16:44:27.379] iteration 12379: loss: 0.065023, loss_s1: 0.033611, loss_fp: 0.002143, loss_freq: 0.023802
[16:44:27.999] iteration 12380: loss: 0.084321, loss_s1: 0.065504, loss_fp: 0.010415, loss_freq: 0.013965
[16:44:28.619] iteration 12381: loss: 0.050207, loss_s1: 0.039561, loss_fp: 0.001194, loss_freq: 0.008772
[16:44:29.241] iteration 12382: loss: 0.085258, loss_s1: 0.064167, loss_fp: 0.002648, loss_freq: 0.029319
[16:44:29.862] iteration 12383: loss: 0.055308, loss_s1: 0.035320, loss_fp: 0.002813, loss_freq: 0.038587
[16:44:30.482] iteration 12384: loss: 0.050806, loss_s1: 0.051269, loss_fp: 0.002192, loss_freq: 0.009905
[16:44:31.107] iteration 12385: loss: 0.062206, loss_s1: 0.028821, loss_fp: 0.002733, loss_freq: 0.043332
[16:44:31.729] iteration 12386: loss: 0.082754, loss_s1: 0.044437, loss_fp: 0.007409, loss_freq: 0.047298
[16:44:32.348] iteration 12387: loss: 0.054210, loss_s1: 0.023562, loss_fp: 0.002330, loss_freq: 0.033083
[16:44:32.967] iteration 12388: loss: 0.103699, loss_s1: 0.098670, loss_fp: 0.010320, loss_freq: 0.058483
[16:44:33.585] iteration 12389: loss: 0.051680, loss_s1: 0.039732, loss_fp: 0.004114, loss_freq: 0.020403
[16:44:34.204] iteration 12390: loss: 0.074462, loss_s1: 0.080946, loss_fp: 0.001754, loss_freq: 0.018344
[16:44:34.828] iteration 12391: loss: 0.043622, loss_s1: 0.025119, loss_fp: 0.000947, loss_freq: 0.010360
[16:44:35.451] iteration 12392: loss: 0.060353, loss_s1: 0.045071, loss_fp: 0.000219, loss_freq: 0.009756
[16:44:36.074] iteration 12393: loss: 0.063948, loss_s1: 0.042118, loss_fp: 0.001815, loss_freq: 0.012466
[16:44:36.700] iteration 12394: loss: 0.108063, loss_s1: 0.123033, loss_fp: 0.004081, loss_freq: 0.030393
[16:44:37.329] iteration 12395: loss: 0.083631, loss_s1: 0.060508, loss_fp: 0.002379, loss_freq: 0.020976
[16:44:37.951] iteration 12396: loss: 0.060587, loss_s1: 0.059613, loss_fp: 0.007189, loss_freq: 0.016205
[16:44:38.568] iteration 12397: loss: 0.074289, loss_s1: 0.042287, loss_fp: 0.025447, loss_freq: 0.031888
[16:44:39.573] iteration 12398: loss: 0.057412, loss_s1: 0.039176, loss_fp: 0.003609, loss_freq: 0.024054
[16:44:40.230] iteration 12399: loss: 0.091832, loss_s1: 0.099724, loss_fp: 0.001279, loss_freq: 0.030993
[16:44:40.890] iteration 12400: loss: 0.063894, loss_s1: 0.056444, loss_fp: 0.003158, loss_freq: 0.021925
[16:44:44.115] iteration 12400 : mean_dice : 0.703361
[16:44:44.763] iteration 12401: loss: 0.055609, loss_s1: 0.027105, loss_fp: 0.002586, loss_freq: 0.014226
[16:44:45.390] iteration 12402: loss: 0.038929, loss_s1: 0.014139, loss_fp: 0.001561, loss_freq: 0.020658
[16:44:46.044] iteration 12403: loss: 0.116767, loss_s1: 0.066062, loss_fp: 0.007082, loss_freq: 0.080578
[16:44:46.704] iteration 12404: loss: 0.045276, loss_s1: 0.028398, loss_fp: 0.000760, loss_freq: 0.023209
[16:44:47.368] iteration 12405: loss: 0.059220, loss_s1: 0.028808, loss_fp: 0.011562, loss_freq: 0.035346
[16:44:48.015] iteration 12406: loss: 0.111612, loss_s1: 0.100499, loss_fp: 0.001677, loss_freq: 0.071986
[16:44:48.640] iteration 12407: loss: 0.064303, loss_s1: 0.060008, loss_fp: 0.005831, loss_freq: 0.013552
[16:44:49.263] iteration 12408: loss: 0.051743, loss_s1: 0.027839, loss_fp: 0.003582, loss_freq: 0.024549
[16:44:49.886] iteration 12409: loss: 0.089944, loss_s1: 0.056370, loss_fp: 0.003916, loss_freq: 0.063184
[16:44:50.508] iteration 12410: loss: 0.092289, loss_s1: 0.054693, loss_fp: 0.006381, loss_freq: 0.082386
[16:44:51.131] iteration 12411: loss: 0.113534, loss_s1: 0.078965, loss_fp: 0.002730, loss_freq: 0.092181
[16:44:51.755] iteration 12412: loss: 0.053770, loss_s1: 0.048166, loss_fp: 0.004184, loss_freq: 0.016682
[16:44:52.380] iteration 12413: loss: 0.074125, loss_s1: 0.065418, loss_fp: 0.000607, loss_freq: 0.042358
[16:44:53.004] iteration 12414: loss: 0.061067, loss_s1: 0.059762, loss_fp: 0.000719, loss_freq: 0.006793
[16:44:53.632] iteration 12415: loss: 0.085978, loss_s1: 0.058497, loss_fp: 0.007066, loss_freq: 0.030710
[16:44:54.259] iteration 12416: loss: 0.073600, loss_s1: 0.045668, loss_fp: 0.002177, loss_freq: 0.032901
[16:44:54.895] iteration 12417: loss: 0.070206, loss_s1: 0.044403, loss_fp: 0.002442, loss_freq: 0.023826
[16:44:55.521] iteration 12418: loss: 0.050126, loss_s1: 0.021686, loss_fp: 0.000218, loss_freq: 0.012084
[16:44:56.190] iteration 12419: loss: 0.063462, loss_s1: 0.029670, loss_fp: 0.002858, loss_freq: 0.016525
[16:44:56.850] iteration 12420: loss: 0.078120, loss_s1: 0.038375, loss_fp: 0.001016, loss_freq: 0.041417
[16:44:57.496] iteration 12421: loss: 0.178606, loss_s1: 0.145739, loss_fp: 0.007261, loss_freq: 0.156181
[16:44:58.119] iteration 12422: loss: 0.065373, loss_s1: 0.057444, loss_fp: 0.010076, loss_freq: 0.022535
[16:44:58.747] iteration 12423: loss: 0.076043, loss_s1: 0.036641, loss_fp: 0.001811, loss_freq: 0.052843
[16:44:59.374] iteration 12424: loss: 0.055008, loss_s1: 0.038032, loss_fp: 0.003663, loss_freq: 0.011739
[16:45:00.005] iteration 12425: loss: 0.099136, loss_s1: 0.095508, loss_fp: 0.018832, loss_freq: 0.031981
[16:45:00.631] iteration 12426: loss: 0.087579, loss_s1: 0.079489, loss_fp: 0.005275, loss_freq: 0.041557
[16:45:01.258] iteration 12427: loss: 0.048960, loss_s1: 0.031615, loss_fp: 0.002586, loss_freq: 0.008493
[16:45:01.889] iteration 12428: loss: 0.054897, loss_s1: 0.033281, loss_fp: 0.000703, loss_freq: 0.005618
[16:45:02.514] iteration 12429: loss: 0.053569, loss_s1: 0.014807, loss_fp: 0.003429, loss_freq: 0.013448
[16:45:03.142] iteration 12430: loss: 0.069949, loss_s1: 0.072188, loss_fp: 0.003539, loss_freq: 0.017017
[16:45:03.768] iteration 12431: loss: 0.039875, loss_s1: 0.017442, loss_fp: 0.000876, loss_freq: 0.014553
[16:45:04.394] iteration 12432: loss: 0.071051, loss_s1: 0.040186, loss_fp: 0.005985, loss_freq: 0.027002
[16:45:05.021] iteration 12433: loss: 0.069198, loss_s1: 0.072291, loss_fp: 0.002618, loss_freq: 0.028108
[16:45:05.649] iteration 12434: loss: 0.098724, loss_s1: 0.036146, loss_fp: 0.008484, loss_freq: 0.052379
[16:45:06.274] iteration 12435: loss: 0.078818, loss_s1: 0.042584, loss_fp: 0.000988, loss_freq: 0.044963
[16:45:06.902] iteration 12436: loss: 0.107840, loss_s1: 0.080661, loss_fp: 0.001295, loss_freq: 0.064742
[16:45:07.526] iteration 12437: loss: 0.072062, loss_s1: 0.050952, loss_fp: 0.008449, loss_freq: 0.037220
[16:45:08.147] iteration 12438: loss: 0.060186, loss_s1: 0.016870, loss_fp: 0.001055, loss_freq: 0.016953
[16:45:08.771] iteration 12439: loss: 0.102082, loss_s1: 0.058855, loss_fp: 0.004758, loss_freq: 0.093788
[16:45:09.395] iteration 12440: loss: 0.074624, loss_s1: 0.043904, loss_fp: 0.002914, loss_freq: 0.028004
[16:45:10.020] iteration 12441: loss: 0.055468, loss_s1: 0.028943, loss_fp: 0.005729, loss_freq: 0.027791
[16:45:10.644] iteration 12442: loss: 0.075889, loss_s1: 0.064843, loss_fp: 0.003157, loss_freq: 0.036838
[16:45:11.270] iteration 12443: loss: 0.042570, loss_s1: 0.023045, loss_fp: 0.001785, loss_freq: 0.011859
[16:45:11.892] iteration 12444: loss: 0.040792, loss_s1: 0.019830, loss_fp: 0.001261, loss_freq: 0.010205
[16:45:12.519] iteration 12445: loss: 0.074590, loss_s1: 0.073611, loss_fp: 0.007677, loss_freq: 0.031518
[16:45:13.147] iteration 12446: loss: 0.087194, loss_s1: 0.100779, loss_fp: 0.001975, loss_freq: 0.017542
[16:45:13.769] iteration 12447: loss: 0.074373, loss_s1: 0.061768, loss_fp: 0.009475, loss_freq: 0.037985
[16:45:14.398] iteration 12448: loss: 0.068492, loss_s1: 0.047004, loss_fp: 0.001161, loss_freq: 0.050183
[16:45:15.025] iteration 12449: loss: 0.063275, loss_s1: 0.043947, loss_fp: 0.002951, loss_freq: 0.019378
[16:45:15.651] iteration 12450: loss: 0.061644, loss_s1: 0.020836, loss_fp: 0.001369, loss_freq: 0.051814
[16:45:16.275] iteration 12451: loss: 0.072310, loss_s1: 0.066577, loss_fp: 0.004781, loss_freq: 0.033228
[16:45:16.901] iteration 12452: loss: 0.049689, loss_s1: 0.023050, loss_fp: 0.001785, loss_freq: 0.007895
[16:45:17.529] iteration 12453: loss: 0.080411, loss_s1: 0.058476, loss_fp: 0.001604, loss_freq: 0.026174
[16:45:18.154] iteration 12454: loss: 0.045433, loss_s1: 0.026624, loss_fp: 0.005631, loss_freq: 0.008320
[16:45:18.779] iteration 12455: loss: 0.083049, loss_s1: 0.040000, loss_fp: 0.005291, loss_freq: 0.048966
[16:45:19.415] iteration 12456: loss: 0.039720, loss_s1: 0.023327, loss_fp: 0.000344, loss_freq: 0.014954
[16:45:20.047] iteration 12457: loss: 0.045148, loss_s1: 0.024858, loss_fp: 0.002612, loss_freq: 0.025117
[16:45:20.680] iteration 12458: loss: 0.047330, loss_s1: 0.039735, loss_fp: 0.001811, loss_freq: 0.011155
[16:45:21.316] iteration 12459: loss: 0.075352, loss_s1: 0.063823, loss_fp: 0.015810, loss_freq: 0.010238
[16:45:22.055] iteration 12460: loss: 0.067547, loss_s1: 0.054613, loss_fp: 0.000965, loss_freq: 0.019192
[16:45:22.681] iteration 12461: loss: 0.056163, loss_s1: 0.026529, loss_fp: 0.001442, loss_freq: 0.026572
[16:45:23.306] iteration 12462: loss: 0.063165, loss_s1: 0.042717, loss_fp: 0.003068, loss_freq: 0.019504
[16:45:23.933] iteration 12463: loss: 0.071351, loss_s1: 0.026574, loss_fp: 0.005006, loss_freq: 0.066995
[16:45:24.557] iteration 12464: loss: 0.050577, loss_s1: 0.014339, loss_fp: 0.002558, loss_freq: 0.034006
[16:45:25.186] iteration 12465: loss: 0.048037, loss_s1: 0.025392, loss_fp: 0.005180, loss_freq: 0.028101
[16:45:25.813] iteration 12466: loss: 0.072716, loss_s1: 0.058109, loss_fp: 0.002976, loss_freq: 0.036808
[16:45:26.439] iteration 12467: loss: 0.063428, loss_s1: 0.034040, loss_fp: 0.002719, loss_freq: 0.019306
[16:45:27.062] iteration 12468: loss: 0.067980, loss_s1: 0.059950, loss_fp: 0.011316, loss_freq: 0.025517
[16:45:27.683] iteration 12469: loss: 0.068817, loss_s1: 0.019163, loss_fp: 0.000762, loss_freq: 0.018221
[16:45:28.307] iteration 12470: loss: 0.067606, loss_s1: 0.044329, loss_fp: 0.000433, loss_freq: 0.047513
[16:45:28.931] iteration 12471: loss: 0.053831, loss_s1: 0.032281, loss_fp: 0.006092, loss_freq: 0.017547
[16:45:29.555] iteration 12472: loss: 0.105914, loss_s1: 0.089172, loss_fp: 0.002724, loss_freq: 0.064173
[16:45:30.210] iteration 12473: loss: 0.089912, loss_s1: 0.092199, loss_fp: 0.003731, loss_freq: 0.013355
[16:45:30.829] iteration 12474: loss: 0.071338, loss_s1: 0.061434, loss_fp: 0.000818, loss_freq: 0.040933
[16:45:31.505] iteration 12475: loss: 0.048883, loss_s1: 0.023979, loss_fp: 0.005850, loss_freq: 0.030087
[16:45:32.129] iteration 12476: loss: 0.044415, loss_s1: 0.018627, loss_fp: 0.003418, loss_freq: 0.006935
[16:45:32.759] iteration 12477: loss: 0.093480, loss_s1: 0.073981, loss_fp: 0.001527, loss_freq: 0.066390
[16:45:33.385] iteration 12478: loss: 0.071928, loss_s1: 0.034288, loss_fp: 0.001898, loss_freq: 0.062128
[16:45:34.010] iteration 12479: loss: 0.079868, loss_s1: 0.051688, loss_fp: 0.005856, loss_freq: 0.024863
[16:45:34.636] iteration 12480: loss: 0.147619, loss_s1: 0.116473, loss_fp: 0.004290, loss_freq: 0.134593
[16:45:35.298] iteration 12481: loss: 0.087538, loss_s1: 0.051791, loss_fp: 0.010287, loss_freq: 0.011440
[16:45:35.957] iteration 12482: loss: 0.102710, loss_s1: 0.087715, loss_fp: 0.003697, loss_freq: 0.056464
[16:45:36.583] iteration 12483: loss: 0.059204, loss_s1: 0.048670, loss_fp: 0.000834, loss_freq: 0.026118
[16:45:37.249] iteration 12484: loss: 0.113491, loss_s1: 0.061939, loss_fp: 0.001717, loss_freq: 0.047750
[16:45:37.907] iteration 12485: loss: 0.053862, loss_s1: 0.032802, loss_fp: 0.001475, loss_freq: 0.023166
[16:45:38.568] iteration 12486: loss: 0.064947, loss_s1: 0.055346, loss_fp: 0.001844, loss_freq: 0.032773
[16:45:39.228] iteration 12487: loss: 0.064332, loss_s1: 0.037086, loss_fp: 0.002141, loss_freq: 0.028516
[16:45:39.864] iteration 12488: loss: 0.057618, loss_s1: 0.030033, loss_fp: 0.004785, loss_freq: 0.029128
[16:45:40.531] iteration 12489: loss: 0.057403, loss_s1: 0.039083, loss_fp: 0.001996, loss_freq: 0.021677
[16:45:41.194] iteration 12490: loss: 0.083056, loss_s1: 0.054459, loss_fp: 0.001685, loss_freq: 0.009355
[16:45:41.859] iteration 12491: loss: 0.043434, loss_s1: 0.019305, loss_fp: 0.011781, loss_freq: 0.021486
[16:45:42.512] iteration 12492: loss: 0.092916, loss_s1: 0.085859, loss_fp: 0.002647, loss_freq: 0.028886
[16:45:43.140] iteration 12493: loss: 0.079403, loss_s1: 0.052947, loss_fp: 0.001267, loss_freq: 0.043322
[16:45:43.766] iteration 12494: loss: 0.036908, loss_s1: 0.017075, loss_fp: 0.000301, loss_freq: 0.015112
[16:45:44.394] iteration 12495: loss: 0.065445, loss_s1: 0.030524, loss_fp: 0.001246, loss_freq: 0.038562
[16:45:45.022] iteration 12496: loss: 0.099364, loss_s1: 0.104741, loss_fp: 0.002917, loss_freq: 0.024612
[16:45:45.644] iteration 12497: loss: 0.071301, loss_s1: 0.084114, loss_fp: 0.002112, loss_freq: 0.016293
[16:45:46.265] iteration 12498: loss: 0.068294, loss_s1: 0.058992, loss_fp: 0.003532, loss_freq: 0.024423
[16:45:46.884] iteration 12499: loss: 0.091340, loss_s1: 0.048292, loss_fp: 0.003755, loss_freq: 0.065163
[16:45:47.503] iteration 12500: loss: 0.108541, loss_s1: 0.106250, loss_fp: 0.004284, loss_freq: 0.063239
[16:45:48.125] iteration 12501: loss: 0.079316, loss_s1: 0.071803, loss_fp: 0.003114, loss_freq: 0.029580
[16:45:48.744] iteration 12502: loss: 0.070693, loss_s1: 0.046303, loss_fp: 0.002373, loss_freq: 0.023025
[16:45:49.370] iteration 12503: loss: 0.044179, loss_s1: 0.030820, loss_fp: 0.000869, loss_freq: 0.022369
[16:45:49.995] iteration 12504: loss: 0.047565, loss_s1: 0.032752, loss_fp: 0.000778, loss_freq: 0.014129
[16:45:50.617] iteration 12505: loss: 0.106467, loss_s1: 0.098920, loss_fp: 0.001574, loss_freq: 0.063803
[16:45:51.245] iteration 12506: loss: 0.150423, loss_s1: 0.095769, loss_fp: 0.004727, loss_freq: 0.142176
[16:45:51.874] iteration 12507: loss: 0.079389, loss_s1: 0.038922, loss_fp: 0.007958, loss_freq: 0.060356
[16:45:52.495] iteration 12508: loss: 0.103539, loss_s1: 0.048862, loss_fp: 0.008518, loss_freq: 0.035725
[16:45:53.120] iteration 12509: loss: 0.058545, loss_s1: 0.022657, loss_fp: 0.001157, loss_freq: 0.047428
[16:45:53.738] iteration 12510: loss: 0.097066, loss_s1: 0.103480, loss_fp: 0.001624, loss_freq: 0.052691
[16:45:54.361] iteration 12511: loss: 0.061901, loss_s1: 0.036005, loss_fp: 0.002355, loss_freq: 0.020668
[16:45:54.986] iteration 12512: loss: 0.043414, loss_s1: 0.035890, loss_fp: 0.000359, loss_freq: 0.003010
[16:45:55.612] iteration 12513: loss: 0.115578, loss_s1: 0.099006, loss_fp: 0.001512, loss_freq: 0.068683
[16:45:56.238] iteration 12514: loss: 0.072909, loss_s1: 0.035723, loss_fp: 0.009372, loss_freq: 0.057758
[16:45:56.865] iteration 12515: loss: 0.051211, loss_s1: 0.027456, loss_fp: 0.000723, loss_freq: 0.019759
[16:45:57.490] iteration 12516: loss: 0.041801, loss_s1: 0.020051, loss_fp: 0.001632, loss_freq: 0.013863
[16:45:58.115] iteration 12517: loss: 0.107804, loss_s1: 0.065622, loss_fp: 0.002215, loss_freq: 0.105070
[16:45:58.740] iteration 12518: loss: 0.060370, loss_s1: 0.044968, loss_fp: 0.001427, loss_freq: 0.030795
[16:45:59.366] iteration 12519: loss: 0.082477, loss_s1: 0.047465, loss_fp: 0.001998, loss_freq: 0.050422
[16:45:59.992] iteration 12520: loss: 0.070715, loss_s1: 0.053118, loss_fp: 0.000794, loss_freq: 0.027719
[16:46:00.618] iteration 12521: loss: 0.062409, loss_s1: 0.070253, loss_fp: 0.000641, loss_freq: 0.008825
[16:46:01.246] iteration 12522: loss: 0.098811, loss_s1: 0.072627, loss_fp: 0.001044, loss_freq: 0.054574
[16:46:01.873] iteration 12523: loss: 0.101418, loss_s1: 0.086284, loss_fp: 0.000965, loss_freq: 0.048178
[16:46:02.500] iteration 12524: loss: 0.045322, loss_s1: 0.027074, loss_fp: 0.000409, loss_freq: 0.008902
[16:46:03.124] iteration 12525: loss: 0.137467, loss_s1: 0.041766, loss_fp: 0.001352, loss_freq: 0.095971
[16:46:03.749] iteration 12526: loss: 0.055293, loss_s1: 0.046137, loss_fp: 0.000288, loss_freq: 0.017115
[16:46:04.377] iteration 12527: loss: 0.047725, loss_s1: 0.016398, loss_fp: 0.002353, loss_freq: 0.025716
[16:46:04.995] iteration 12528: loss: 0.069644, loss_s1: 0.038105, loss_fp: 0.009082, loss_freq: 0.059239
[16:46:05.618] iteration 12529: loss: 0.071917, loss_s1: 0.067009, loss_fp: 0.001255, loss_freq: 0.027391
[16:46:06.240] iteration 12530: loss: 0.075926, loss_s1: 0.081652, loss_fp: 0.002079, loss_freq: 0.022480
[16:46:06.860] iteration 12531: loss: 0.066057, loss_s1: 0.070980, loss_fp: 0.002348, loss_freq: 0.014045
[16:46:07.480] iteration 12532: loss: 0.073237, loss_s1: 0.059064, loss_fp: 0.004022, loss_freq: 0.042161
[16:46:08.101] iteration 12533: loss: 0.081655, loss_s1: 0.067143, loss_fp: 0.006607, loss_freq: 0.056001
[16:46:08.753] iteration 12534: loss: 0.045746, loss_s1: 0.029369, loss_fp: 0.000554, loss_freq: 0.013354
[16:46:09.378] iteration 12535: loss: 0.052714, loss_s1: 0.035284, loss_fp: 0.002750, loss_freq: 0.018598
[16:46:10.009] iteration 12536: loss: 0.050289, loss_s1: 0.017385, loss_fp: 0.003117, loss_freq: 0.023116
[16:46:10.632] iteration 12537: loss: 0.092179, loss_s1: 0.061885, loss_fp: 0.011013, loss_freq: 0.030734
[16:46:11.257] iteration 12538: loss: 0.067216, loss_s1: 0.040736, loss_fp: 0.012111, loss_freq: 0.032733
[16:46:11.885] iteration 12539: loss: 0.057312, loss_s1: 0.026915, loss_fp: 0.005301, loss_freq: 0.018415
[16:46:12.509] iteration 12540: loss: 0.110949, loss_s1: 0.097565, loss_fp: 0.003073, loss_freq: 0.037388
[16:46:13.136] iteration 12541: loss: 0.063221, loss_s1: 0.042787, loss_fp: 0.002698, loss_freq: 0.028186
[16:46:13.761] iteration 12542: loss: 0.049406, loss_s1: 0.050722, loss_fp: 0.001029, loss_freq: 0.008742
[16:46:14.390] iteration 12543: loss: 0.079125, loss_s1: 0.060464, loss_fp: 0.006003, loss_freq: 0.018209
[16:46:15.016] iteration 12544: loss: 0.085450, loss_s1: 0.052771, loss_fp: 0.012666, loss_freq: 0.071095
[16:46:15.644] iteration 12545: loss: 0.064633, loss_s1: 0.075957, loss_fp: 0.001668, loss_freq: 0.010036
[16:46:16.268] iteration 12546: loss: 0.043747, loss_s1: 0.037139, loss_fp: 0.001667, loss_freq: 0.010264
[16:46:16.898] iteration 12547: loss: 0.089976, loss_s1: 0.051457, loss_fp: 0.004042, loss_freq: 0.069401
[16:46:17.522] iteration 12548: loss: 0.079228, loss_s1: 0.061094, loss_fp: 0.009414, loss_freq: 0.029690
[16:46:18.148] iteration 12549: loss: 0.096360, loss_s1: 0.090740, loss_fp: 0.003828, loss_freq: 0.064157
[16:46:18.778] iteration 12550: loss: 0.039805, loss_s1: 0.032502, loss_fp: 0.003868, loss_freq: 0.011170
[16:46:19.431] iteration 12551: loss: 0.090626, loss_s1: 0.036244, loss_fp: 0.003027, loss_freq: 0.036466
[16:46:20.095] iteration 12552: loss: 0.050398, loss_s1: 0.024073, loss_fp: 0.001383, loss_freq: 0.011820
[16:46:20.759] iteration 12553: loss: 0.051587, loss_s1: 0.040542, loss_fp: 0.000540, loss_freq: 0.023501
[16:46:21.423] iteration 12554: loss: 0.068141, loss_s1: 0.070453, loss_fp: 0.000810, loss_freq: 0.015097
[16:46:22.048] iteration 12555: loss: 0.094368, loss_s1: 0.075492, loss_fp: 0.007100, loss_freq: 0.053589
[16:46:22.702] iteration 12556: loss: 0.085375, loss_s1: 0.060023, loss_fp: 0.006197, loss_freq: 0.020433
[16:46:23.358] iteration 12557: loss: 0.076993, loss_s1: 0.068311, loss_fp: 0.003539, loss_freq: 0.013373
[16:46:24.011] iteration 12558: loss: 0.064379, loss_s1: 0.048341, loss_fp: 0.003682, loss_freq: 0.026071
[16:46:25.023] iteration 12559: loss: 0.066875, loss_s1: 0.056081, loss_fp: 0.001285, loss_freq: 0.030032
[16:46:25.657] iteration 12560: loss: 0.092217, loss_s1: 0.085292, loss_fp: 0.010122, loss_freq: 0.036128
[16:46:26.285] iteration 12561: loss: 0.078359, loss_s1: 0.060984, loss_fp: 0.000660, loss_freq: 0.031375
[16:46:26.916] iteration 12562: loss: 0.068318, loss_s1: 0.031193, loss_fp: 0.000707, loss_freq: 0.021085
[16:46:27.545] iteration 12563: loss: 0.062229, loss_s1: 0.031800, loss_fp: 0.003867, loss_freq: 0.028740
[16:46:28.171] iteration 12564: loss: 0.100885, loss_s1: 0.082230, loss_fp: 0.010382, loss_freq: 0.042056
[16:46:28.822] iteration 12565: loss: 0.059990, loss_s1: 0.037734, loss_fp: 0.002799, loss_freq: 0.029725
[16:46:29.483] iteration 12566: loss: 0.078814, loss_s1: 0.095281, loss_fp: 0.001377, loss_freq: 0.021791
[16:46:30.145] iteration 12567: loss: 0.056541, loss_s1: 0.043347, loss_fp: 0.017777, loss_freq: 0.016368
[16:46:30.804] iteration 12568: loss: 0.069237, loss_s1: 0.065547, loss_fp: 0.004294, loss_freq: 0.026823
[16:46:31.461] iteration 12569: loss: 0.044668, loss_s1: 0.015572, loss_fp: 0.002161, loss_freq: 0.013357
[16:46:32.124] iteration 12570: loss: 0.101684, loss_s1: 0.054352, loss_fp: 0.025515, loss_freq: 0.074977
[16:46:32.756] iteration 12571: loss: 0.101582, loss_s1: 0.042946, loss_fp: 0.005155, loss_freq: 0.061507
[16:46:33.383] iteration 12572: loss: 0.093082, loss_s1: 0.059966, loss_fp: 0.002632, loss_freq: 0.065993
[16:46:34.006] iteration 12573: loss: 0.069128, loss_s1: 0.068590, loss_fp: 0.007270, loss_freq: 0.024880
[16:46:34.633] iteration 12574: loss: 0.115293, loss_s1: 0.088987, loss_fp: 0.004185, loss_freq: 0.084806
[16:46:35.260] iteration 12575: loss: 0.081305, loss_s1: 0.017442, loss_fp: 0.003394, loss_freq: 0.009193
[16:46:35.882] iteration 12576: loss: 0.073310, loss_s1: 0.045202, loss_fp: 0.006418, loss_freq: 0.042780
[16:46:36.508] iteration 12577: loss: 0.042013, loss_s1: 0.011524, loss_fp: 0.000631, loss_freq: 0.030415
[16:46:37.133] iteration 12578: loss: 0.069310, loss_s1: 0.056062, loss_fp: 0.003996, loss_freq: 0.013926
[16:46:37.758] iteration 12579: loss: 0.061123, loss_s1: 0.063681, loss_fp: 0.001150, loss_freq: 0.012199
[16:46:38.382] iteration 12580: loss: 0.057554, loss_s1: 0.032500, loss_fp: 0.002402, loss_freq: 0.024347
[16:46:39.005] iteration 12581: loss: 0.075007, loss_s1: 0.034434, loss_fp: 0.007198, loss_freq: 0.019715
[16:46:39.631] iteration 12582: loss: 0.152877, loss_s1: 0.035801, loss_fp: 0.022972, loss_freq: 0.194032
[16:46:40.259] iteration 12583: loss: 0.041789, loss_s1: 0.031258, loss_fp: 0.002767, loss_freq: 0.009199
[16:46:40.879] iteration 12584: loss: 0.052005, loss_s1: 0.015972, loss_fp: 0.002977, loss_freq: 0.024968
[16:46:41.505] iteration 12585: loss: 0.062838, loss_s1: 0.061624, loss_fp: 0.002314, loss_freq: 0.015784
[16:46:42.129] iteration 12586: loss: 0.107067, loss_s1: 0.072969, loss_fp: 0.012636, loss_freq: 0.072244
[16:46:42.755] iteration 12587: loss: 0.097969, loss_s1: 0.104005, loss_fp: 0.012251, loss_freq: 0.028873
[16:46:43.380] iteration 12588: loss: 0.047963, loss_s1: 0.025162, loss_fp: 0.007508, loss_freq: 0.014514
[16:46:44.002] iteration 12589: loss: 0.059939, loss_s1: 0.064216, loss_fp: 0.002444, loss_freq: 0.012662
[16:46:44.623] iteration 12590: loss: 0.079504, loss_s1: 0.046731, loss_fp: 0.003616, loss_freq: 0.043274
[16:46:45.255] iteration 12591: loss: 0.054244, loss_s1: 0.038758, loss_fp: 0.001975, loss_freq: 0.016773
[16:46:45.876] iteration 12592: loss: 0.058264, loss_s1: 0.069219, loss_fp: 0.001095, loss_freq: 0.005905
[16:46:46.498] iteration 12593: loss: 0.063160, loss_s1: 0.016639, loss_fp: 0.005990, loss_freq: 0.025544
[16:46:47.153] iteration 12594: loss: 0.081311, loss_s1: 0.047124, loss_fp: 0.002936, loss_freq: 0.044468
[16:46:47.810] iteration 12595: loss: 0.119790, loss_s1: 0.060997, loss_fp: 0.015161, loss_freq: 0.065076
[16:46:48.432] iteration 12596: loss: 0.070256, loss_s1: 0.050565, loss_fp: 0.004235, loss_freq: 0.038023
[16:46:49.057] iteration 12597: loss: 0.132473, loss_s1: 0.142408, loss_fp: 0.002802, loss_freq: 0.064048
[16:46:49.676] iteration 12598: loss: 0.066114, loss_s1: 0.039239, loss_fp: 0.001275, loss_freq: 0.029257
[16:46:50.305] iteration 12599: loss: 0.054344, loss_s1: 0.026497, loss_fp: 0.005720, loss_freq: 0.007044
[16:46:50.927] iteration 12600: loss: 0.075974, loss_s1: 0.060598, loss_fp: 0.005055, loss_freq: 0.037593
[16:46:54.180] iteration 12600 : mean_dice : 0.685481
[16:46:54.834] iteration 12601: loss: 0.083598, loss_s1: 0.052151, loss_fp: 0.013974, loss_freq: 0.060096
[16:46:55.456] iteration 12602: loss: 0.060350, loss_s1: 0.018750, loss_fp: 0.001455, loss_freq: 0.036452
[16:46:56.079] iteration 12603: loss: 0.089752, loss_s1: 0.053390, loss_fp: 0.006657, loss_freq: 0.055951
[16:46:56.701] iteration 12604: loss: 0.083598, loss_s1: 0.049568, loss_fp: 0.001439, loss_freq: 0.059677
[16:46:57.328] iteration 12605: loss: 0.025139, loss_s1: 0.011519, loss_fp: 0.000748, loss_freq: 0.005286
[16:46:57.956] iteration 12606: loss: 0.047162, loss_s1: 0.037074, loss_fp: 0.007866, loss_freq: 0.015992
[16:46:58.580] iteration 12607: loss: 0.083115, loss_s1: 0.085960, loss_fp: 0.003812, loss_freq: 0.017633
[16:46:59.204] iteration 12608: loss: 0.078998, loss_s1: 0.089979, loss_fp: 0.000945, loss_freq: 0.030326
[16:46:59.832] iteration 12609: loss: 0.089660, loss_s1: 0.070350, loss_fp: 0.002483, loss_freq: 0.062457
[16:47:00.456] iteration 12610: loss: 0.038910, loss_s1: 0.011687, loss_fp: 0.000961, loss_freq: 0.016405
[16:47:01.082] iteration 12611: loss: 0.078955, loss_s1: 0.050713, loss_fp: 0.004382, loss_freq: 0.039908
[16:47:01.705] iteration 12612: loss: 0.057518, loss_s1: 0.045502, loss_fp: 0.000955, loss_freq: 0.022414
[16:47:02.329] iteration 12613: loss: 0.064991, loss_s1: 0.040599, loss_fp: 0.000965, loss_freq: 0.027635
[16:47:02.952] iteration 12614: loss: 0.067196, loss_s1: 0.048569, loss_fp: 0.003929, loss_freq: 0.026801
[16:47:03.576] iteration 12615: loss: 0.068625, loss_s1: 0.063963, loss_fp: 0.001784, loss_freq: 0.015221
[16:47:04.202] iteration 12616: loss: 0.069377, loss_s1: 0.036118, loss_fp: 0.002437, loss_freq: 0.035369
[16:47:04.826] iteration 12617: loss: 0.039770, loss_s1: 0.027235, loss_fp: 0.000991, loss_freq: 0.011915
[16:47:05.455] iteration 12618: loss: 0.036726, loss_s1: 0.010493, loss_fp: 0.001390, loss_freq: 0.026180
[16:47:06.080] iteration 12619: loss: 0.064916, loss_s1: 0.047609, loss_fp: 0.008738, loss_freq: 0.026952
[16:47:06.736] iteration 12620: loss: 0.062431, loss_s1: 0.061885, loss_fp: 0.002333, loss_freq: 0.014643
[16:47:07.399] iteration 12621: loss: 0.043178, loss_s1: 0.033453, loss_fp: 0.003075, loss_freq: 0.009154
[16:47:08.057] iteration 12622: loss: 0.074208, loss_s1: 0.079027, loss_fp: 0.004428, loss_freq: 0.014821
[16:47:08.713] iteration 12623: loss: 0.067257, loss_s1: 0.070133, loss_fp: 0.001163, loss_freq: 0.016640
[16:47:09.374] iteration 12624: loss: 0.065151, loss_s1: 0.031977, loss_fp: 0.001319, loss_freq: 0.041138
[16:47:10.005] iteration 12625: loss: 0.057442, loss_s1: 0.029514, loss_fp: 0.001871, loss_freq: 0.038480
[16:47:10.628] iteration 12626: loss: 0.047569, loss_s1: 0.033015, loss_fp: 0.002724, loss_freq: 0.023729
[16:47:11.253] iteration 12627: loss: 0.042859, loss_s1: 0.029435, loss_fp: 0.001742, loss_freq: 0.013344
[16:47:11.878] iteration 12628: loss: 0.061700, loss_s1: 0.029563, loss_fp: 0.002088, loss_freq: 0.026135
[16:47:12.505] iteration 12629: loss: 0.081981, loss_s1: 0.057002, loss_fp: 0.006317, loss_freq: 0.039241
[16:47:13.192] iteration 12630: loss: 0.054640, loss_s1: 0.038867, loss_fp: 0.004621, loss_freq: 0.026705
[16:47:13.885] iteration 12631: loss: 0.040949, loss_s1: 0.010312, loss_fp: 0.008923, loss_freq: 0.008952
[16:47:14.554] iteration 12632: loss: 0.066412, loss_s1: 0.038435, loss_fp: 0.001833, loss_freq: 0.021100
[16:47:15.218] iteration 12633: loss: 0.080308, loss_s1: 0.082949, loss_fp: 0.002631, loss_freq: 0.038071
[16:47:15.848] iteration 12634: loss: 0.059628, loss_s1: 0.039292, loss_fp: 0.004453, loss_freq: 0.013891
[16:47:16.477] iteration 12635: loss: 0.056514, loss_s1: 0.030135, loss_fp: 0.001293, loss_freq: 0.047050
[16:47:17.111] iteration 12636: loss: 0.062825, loss_s1: 0.042329, loss_fp: 0.002389, loss_freq: 0.018974
[16:47:17.747] iteration 12637: loss: 0.064528, loss_s1: 0.048805, loss_fp: 0.005839, loss_freq: 0.024149
[16:47:18.375] iteration 12638: loss: 0.089202, loss_s1: 0.054420, loss_fp: 0.003351, loss_freq: 0.028322
[16:47:19.009] iteration 12639: loss: 0.059404, loss_s1: 0.048467, loss_fp: 0.001725, loss_freq: 0.029492
[16:47:19.641] iteration 12640: loss: 0.059102, loss_s1: 0.046278, loss_fp: 0.004053, loss_freq: 0.024869
[16:47:20.273] iteration 12641: loss: 0.067109, loss_s1: 0.063228, loss_fp: 0.005216, loss_freq: 0.025973
[16:47:20.901] iteration 12642: loss: 0.065206, loss_s1: 0.046409, loss_fp: 0.003527, loss_freq: 0.015292
[16:47:21.527] iteration 12643: loss: 0.092059, loss_s1: 0.069110, loss_fp: 0.012588, loss_freq: 0.071026
[16:47:22.156] iteration 12644: loss: 0.067411, loss_s1: 0.061998, loss_fp: 0.001718, loss_freq: 0.027455
[16:47:22.787] iteration 12645: loss: 0.075064, loss_s1: 0.051909, loss_fp: 0.011888, loss_freq: 0.033695
[16:47:23.406] iteration 12646: loss: 0.056033, loss_s1: 0.042262, loss_fp: 0.003272, loss_freq: 0.007597
[16:47:24.031] iteration 12647: loss: 0.055901, loss_s1: 0.018103, loss_fp: 0.012284, loss_freq: 0.037203
[16:47:24.871] iteration 12648: loss: 0.064758, loss_s1: 0.027714, loss_fp: 0.004576, loss_freq: 0.031219
[16:47:25.846] iteration 12649: loss: 0.082455, loss_s1: 0.045816, loss_fp: 0.005490, loss_freq: 0.018688
[16:47:26.778] iteration 12650: loss: 0.057999, loss_s1: 0.030553, loss_fp: 0.001937, loss_freq: 0.019829
[16:47:27.404] iteration 12651: loss: 0.095462, loss_s1: 0.037688, loss_fp: 0.003596, loss_freq: 0.021977
[16:47:28.029] iteration 12652: loss: 0.074873, loss_s1: 0.041009, loss_fp: 0.002695, loss_freq: 0.030633
[16:47:28.691] iteration 12653: loss: 0.071775, loss_s1: 0.058733, loss_fp: 0.004540, loss_freq: 0.033877
[16:47:29.316] iteration 12654: loss: 0.053828, loss_s1: 0.044012, loss_fp: 0.002116, loss_freq: 0.026674
[16:47:29.946] iteration 12655: loss: 0.065828, loss_s1: 0.032877, loss_fp: 0.000512, loss_freq: 0.025683
[16:47:30.573] iteration 12656: loss: 0.047951, loss_s1: 0.020876, loss_fp: 0.000977, loss_freq: 0.022496
[16:47:31.196] iteration 12657: loss: 0.059004, loss_s1: 0.037202, loss_fp: 0.004677, loss_freq: 0.021741
[16:47:31.823] iteration 12658: loss: 0.071741, loss_s1: 0.076043, loss_fp: 0.003905, loss_freq: 0.024824
[16:47:32.446] iteration 12659: loss: 0.060345, loss_s1: 0.044861, loss_fp: 0.001461, loss_freq: 0.030692
[16:47:33.071] iteration 12660: loss: 0.093574, loss_s1: 0.041698, loss_fp: 0.002083, loss_freq: 0.076704
[16:47:33.703] iteration 12661: loss: 0.064041, loss_s1: 0.032855, loss_fp: 0.003869, loss_freq: 0.034707
[16:47:34.325] iteration 12662: loss: 0.100766, loss_s1: 0.078189, loss_fp: 0.002015, loss_freq: 0.071765
[16:47:34.954] iteration 12663: loss: 0.063961, loss_s1: 0.035971, loss_fp: 0.002949, loss_freq: 0.024504
[16:47:35.585] iteration 12664: loss: 0.055682, loss_s1: 0.026171, loss_fp: 0.006892, loss_freq: 0.034280
[16:47:36.215] iteration 12665: loss: 0.060472, loss_s1: 0.045977, loss_fp: 0.003013, loss_freq: 0.014335
[16:47:36.838] iteration 12666: loss: 0.087417, loss_s1: 0.035648, loss_fp: 0.002602, loss_freq: 0.048466
[16:47:37.465] iteration 12667: loss: 0.176457, loss_s1: 0.129074, loss_fp: 0.004143, loss_freq: 0.162353
[16:47:38.088] iteration 12668: loss: 0.065717, loss_s1: 0.024375, loss_fp: 0.009811, loss_freq: 0.018212
[16:47:38.722] iteration 12669: loss: 0.060732, loss_s1: 0.030110, loss_fp: 0.002193, loss_freq: 0.020596
[16:47:39.380] iteration 12670: loss: 0.082832, loss_s1: 0.067473, loss_fp: 0.003903, loss_freq: 0.040487
[16:47:40.005] iteration 12671: loss: 0.072814, loss_s1: 0.069429, loss_fp: 0.002329, loss_freq: 0.024350
[16:47:40.668] iteration 12672: loss: 0.072304, loss_s1: 0.052663, loss_fp: 0.000444, loss_freq: 0.023223
[16:47:41.330] iteration 12673: loss: 0.034500, loss_s1: 0.014821, loss_fp: 0.000756, loss_freq: 0.003386
[16:47:41.991] iteration 12674: loss: 0.064012, loss_s1: 0.047439, loss_fp: 0.005594, loss_freq: 0.025386
[16:47:42.653] iteration 12675: loss: 0.080866, loss_s1: 0.084402, loss_fp: 0.004780, loss_freq: 0.029862
[16:47:43.309] iteration 12676: loss: 0.062875, loss_s1: 0.053295, loss_fp: 0.001118, loss_freq: 0.027242
[16:47:43.940] iteration 12677: loss: 0.064904, loss_s1: 0.032169, loss_fp: 0.004482, loss_freq: 0.037611
[16:47:44.571] iteration 12678: loss: 0.148811, loss_s1: 0.117983, loss_fp: 0.007711, loss_freq: 0.119692
[16:47:45.201] iteration 12679: loss: 0.108695, loss_s1: 0.035055, loss_fp: 0.012975, loss_freq: 0.121917
[16:47:45.824] iteration 12680: loss: 0.163162, loss_s1: 0.083991, loss_fp: 0.006320, loss_freq: 0.081387
[16:47:46.479] iteration 12681: loss: 0.093128, loss_s1: 0.059157, loss_fp: 0.003265, loss_freq: 0.011531
[16:47:47.138] iteration 12682: loss: 0.079030, loss_s1: 0.054941, loss_fp: 0.002625, loss_freq: 0.020588
[16:47:47.796] iteration 12683: loss: 0.057203, loss_s1: 0.038090, loss_fp: 0.001177, loss_freq: 0.019015
[16:47:48.420] iteration 12684: loss: 0.060744, loss_s1: 0.018294, loss_fp: 0.002978, loss_freq: 0.027264
[16:47:49.043] iteration 12685: loss: 0.062754, loss_s1: 0.035786, loss_fp: 0.006886, loss_freq: 0.010208
[16:47:49.671] iteration 12686: loss: 0.135323, loss_s1: 0.061829, loss_fp: 0.007606, loss_freq: 0.085238
[16:47:50.296] iteration 12687: loss: 0.082185, loss_s1: 0.080269, loss_fp: 0.000714, loss_freq: 0.019754
[16:47:50.919] iteration 12688: loss: 0.044455, loss_s1: 0.033284, loss_fp: 0.002314, loss_freq: 0.010525
[16:47:51.543] iteration 12689: loss: 0.119962, loss_s1: 0.085371, loss_fp: 0.009269, loss_freq: 0.104577
[16:47:52.167] iteration 12690: loss: 0.069326, loss_s1: 0.058763, loss_fp: 0.001169, loss_freq: 0.030476
[16:47:52.791] iteration 12691: loss: 0.063898, loss_s1: 0.047963, loss_fp: 0.002155, loss_freq: 0.023708
[16:47:53.413] iteration 12692: loss: 0.068058, loss_s1: 0.043142, loss_fp: 0.004650, loss_freq: 0.028645
[16:47:54.037] iteration 12693: loss: 0.055451, loss_s1: 0.022987, loss_fp: 0.000567, loss_freq: 0.038611
[16:47:54.658] iteration 12694: loss: 0.055442, loss_s1: 0.049475, loss_fp: 0.000712, loss_freq: 0.012323
[16:47:55.284] iteration 12695: loss: 0.041578, loss_s1: 0.009324, loss_fp: 0.000589, loss_freq: 0.015848
[16:47:55.908] iteration 12696: loss: 0.062544, loss_s1: 0.042529, loss_fp: 0.005258, loss_freq: 0.031071
[16:47:56.531] iteration 12697: loss: 0.069126, loss_s1: 0.031632, loss_fp: 0.002255, loss_freq: 0.053783
[16:47:57.193] iteration 12698: loss: 0.082109, loss_s1: 0.050811, loss_fp: 0.005488, loss_freq: 0.044918
[16:47:57.818] iteration 12699: loss: 0.081169, loss_s1: 0.074605, loss_fp: 0.000829, loss_freq: 0.024329
[16:47:58.445] iteration 12700: loss: 0.074751, loss_s1: 0.058640, loss_fp: 0.004288, loss_freq: 0.030192
[16:47:59.067] iteration 12701: loss: 0.098801, loss_s1: 0.044556, loss_fp: 0.008745, loss_freq: 0.030098
[16:47:59.689] iteration 12702: loss: 0.053936, loss_s1: 0.026910, loss_fp: 0.003548, loss_freq: 0.031475
[16:48:00.318] iteration 12703: loss: 0.054621, loss_s1: 0.033667, loss_fp: 0.004736, loss_freq: 0.015529
[16:48:00.940] iteration 12704: loss: 0.056519, loss_s1: 0.022189, loss_fp: 0.008774, loss_freq: 0.006471
[16:48:01.567] iteration 12705: loss: 0.078004, loss_s1: 0.060673, loss_fp: 0.008761, loss_freq: 0.053309
[16:48:02.194] iteration 12706: loss: 0.064030, loss_s1: 0.067879, loss_fp: 0.001520, loss_freq: 0.011685
[16:48:02.814] iteration 12707: loss: 0.072459, loss_s1: 0.040124, loss_fp: 0.008094, loss_freq: 0.041216
[16:48:03.446] iteration 12708: loss: 0.106236, loss_s1: 0.089167, loss_fp: 0.006078, loss_freq: 0.052038
[16:48:04.070] iteration 12709: loss: 0.091437, loss_s1: 0.060157, loss_fp: 0.001328, loss_freq: 0.026106
[16:48:04.690] iteration 12710: loss: 0.121097, loss_s1: 0.092803, loss_fp: 0.033240, loss_freq: 0.063339
[16:48:05.323] iteration 12711: loss: 0.039392, loss_s1: 0.027283, loss_fp: 0.005938, loss_freq: 0.013246
[16:48:05.951] iteration 12712: loss: 0.066729, loss_s1: 0.036953, loss_fp: 0.005573, loss_freq: 0.044635
[16:48:06.574] iteration 12713: loss: 0.060258, loss_s1: 0.019009, loss_fp: 0.002457, loss_freq: 0.021287
[16:48:07.199] iteration 12714: loss: 0.044437, loss_s1: 0.028908, loss_fp: 0.001076, loss_freq: 0.019013
[16:48:07.824] iteration 12715: loss: 0.051094, loss_s1: 0.010417, loss_fp: 0.000888, loss_freq: 0.018396
[16:48:08.448] iteration 12716: loss: 0.093705, loss_s1: 0.062899, loss_fp: 0.003203, loss_freq: 0.068168
[16:48:09.078] iteration 12717: loss: 0.118559, loss_s1: 0.080368, loss_fp: 0.011105, loss_freq: 0.075916
[16:48:09.701] iteration 12718: loss: 0.073695, loss_s1: 0.085176, loss_fp: 0.001207, loss_freq: 0.015794
[16:48:10.324] iteration 12719: loss: 0.083509, loss_s1: 0.065564, loss_fp: 0.001028, loss_freq: 0.033333
[16:48:11.286] iteration 12720: loss: 0.044210, loss_s1: 0.038257, loss_fp: 0.000475, loss_freq: 0.011328
[16:48:11.907] iteration 12721: loss: 0.085978, loss_s1: 0.062217, loss_fp: 0.006736, loss_freq: 0.032920
[16:48:12.532] iteration 12722: loss: 0.078631, loss_s1: 0.051850, loss_fp: 0.000819, loss_freq: 0.036043
[16:48:13.160] iteration 12723: loss: 0.055168, loss_s1: 0.033355, loss_fp: 0.001037, loss_freq: 0.013562
[16:48:13.816] iteration 12724: loss: 0.058130, loss_s1: 0.043219, loss_fp: 0.002362, loss_freq: 0.012015
[16:48:14.475] iteration 12725: loss: 0.141349, loss_s1: 0.048929, loss_fp: 0.010633, loss_freq: 0.080163
[16:48:15.134] iteration 12726: loss: 0.075839, loss_s1: 0.058932, loss_fp: 0.001229, loss_freq: 0.047684
[16:48:15.792] iteration 12727: loss: 0.057596, loss_s1: 0.044615, loss_fp: 0.002374, loss_freq: 0.030652
[16:48:16.450] iteration 12728: loss: 0.064365, loss_s1: 0.059220, loss_fp: 0.001328, loss_freq: 0.035732
[16:48:17.110] iteration 12729: loss: 0.080493, loss_s1: 0.071780, loss_fp: 0.002930, loss_freq: 0.032473
[16:48:17.770] iteration 12730: loss: 0.041675, loss_s1: 0.027278, loss_fp: 0.001087, loss_freq: 0.013408
[16:48:18.396] iteration 12731: loss: 0.053030, loss_s1: 0.021499, loss_fp: 0.001286, loss_freq: 0.035440
[16:48:19.021] iteration 12732: loss: 0.053804, loss_s1: 0.031485, loss_fp: 0.004066, loss_freq: 0.029841
[16:48:19.647] iteration 12733: loss: 0.102724, loss_s1: 0.030829, loss_fp: 0.001844, loss_freq: 0.050874
[16:48:20.271] iteration 12734: loss: 0.065344, loss_s1: 0.036882, loss_fp: 0.010866, loss_freq: 0.011193
[16:48:20.901] iteration 12735: loss: 0.108298, loss_s1: 0.088891, loss_fp: 0.003232, loss_freq: 0.073712
[16:48:21.525] iteration 12736: loss: 0.058244, loss_s1: 0.027332, loss_fp: 0.006062, loss_freq: 0.021083
[16:48:22.149] iteration 12737: loss: 0.074322, loss_s1: 0.049558, loss_fp: 0.009866, loss_freq: 0.027397
[16:48:22.776] iteration 12738: loss: 0.045513, loss_s1: 0.023869, loss_fp: 0.001897, loss_freq: 0.012870
[16:48:23.402] iteration 12739: loss: 0.063933, loss_s1: 0.036182, loss_fp: 0.002737, loss_freq: 0.023326
[16:48:24.026] iteration 12740: loss: 0.032198, loss_s1: 0.009517, loss_fp: 0.001552, loss_freq: 0.008584
[16:48:24.650] iteration 12741: loss: 0.052326, loss_s1: 0.028735, loss_fp: 0.002806, loss_freq: 0.013824
[16:48:25.276] iteration 12742: loss: 0.064708, loss_s1: 0.038718, loss_fp: 0.001023, loss_freq: 0.014655
[16:48:25.902] iteration 12743: loss: 0.224279, loss_s1: 0.108083, loss_fp: 0.014943, loss_freq: 0.263231
[16:48:26.527] iteration 12744: loss: 0.058642, loss_s1: 0.050502, loss_fp: 0.006191, loss_freq: 0.023424
[16:48:27.159] iteration 12745: loss: 0.056298, loss_s1: 0.035165, loss_fp: 0.003361, loss_freq: 0.026821
[16:48:27.786] iteration 12746: loss: 0.068103, loss_s1: 0.053226, loss_fp: 0.001398, loss_freq: 0.039006
[16:48:28.412] iteration 12747: loss: 0.091144, loss_s1: 0.085851, loss_fp: 0.003787, loss_freq: 0.035846
[16:48:29.041] iteration 12748: loss: 0.055410, loss_s1: 0.036242, loss_fp: 0.003214, loss_freq: 0.029889
[16:48:29.664] iteration 12749: loss: 0.051285, loss_s1: 0.046456, loss_fp: 0.002566, loss_freq: 0.013908
[16:48:30.293] iteration 12750: loss: 0.055476, loss_s1: 0.045234, loss_fp: 0.001645, loss_freq: 0.017360
[16:48:30.916] iteration 12751: loss: 0.044574, loss_s1: 0.023927, loss_fp: 0.000791, loss_freq: 0.018636
[16:48:31.537] iteration 12752: loss: 0.053262, loss_s1: 0.041466, loss_fp: 0.000481, loss_freq: 0.022016
[16:48:32.161] iteration 12753: loss: 0.046361, loss_s1: 0.022686, loss_fp: 0.000527, loss_freq: 0.009695
[16:48:32.787] iteration 12754: loss: 0.084406, loss_s1: 0.061130, loss_fp: 0.002384, loss_freq: 0.037843
[16:48:33.418] iteration 12755: loss: 0.062956, loss_s1: 0.056239, loss_fp: 0.002824, loss_freq: 0.024921
[16:48:34.078] iteration 12756: loss: 0.105778, loss_s1: 0.073538, loss_fp: 0.010400, loss_freq: 0.075184
[16:48:34.737] iteration 12757: loss: 0.078381, loss_s1: 0.057767, loss_fp: 0.005199, loss_freq: 0.049294
[16:48:35.411] iteration 12758: loss: 0.105712, loss_s1: 0.105866, loss_fp: 0.002696, loss_freq: 0.049951
[16:48:36.063] iteration 12759: loss: 0.039548, loss_s1: 0.019581, loss_fp: 0.001881, loss_freq: 0.016158
[16:48:36.686] iteration 12760: loss: 0.059116, loss_s1: 0.026551, loss_fp: 0.005857, loss_freq: 0.018674
[16:48:37.315] iteration 12761: loss: 0.099964, loss_s1: 0.107244, loss_fp: 0.002717, loss_freq: 0.053878
[16:48:37.941] iteration 12762: loss: 0.057813, loss_s1: 0.055758, loss_fp: 0.004723, loss_freq: 0.016588
[16:48:38.565] iteration 12763: loss: 0.059644, loss_s1: 0.039253, loss_fp: 0.003571, loss_freq: 0.037956
[16:48:39.191] iteration 12764: loss: 0.082390, loss_s1: 0.082722, loss_fp: 0.005043, loss_freq: 0.032038
[16:48:39.816] iteration 12765: loss: 0.074651, loss_s1: 0.026908, loss_fp: 0.000921, loss_freq: 0.002868
[16:48:40.444] iteration 12766: loss: 0.037472, loss_s1: 0.013923, loss_fp: 0.000839, loss_freq: 0.017446
[16:48:41.073] iteration 12767: loss: 0.061438, loss_s1: 0.037230, loss_fp: 0.009884, loss_freq: 0.027124
[16:48:41.769] iteration 12768: loss: 0.064515, loss_s1: 0.059735, loss_fp: 0.006515, loss_freq: 0.013874
[16:48:42.437] iteration 12769: loss: 0.059945, loss_s1: 0.047936, loss_fp: 0.006770, loss_freq: 0.030346
[16:48:43.101] iteration 12770: loss: 0.077251, loss_s1: 0.060224, loss_fp: 0.005282, loss_freq: 0.044874
[16:48:43.763] iteration 12771: loss: 0.054564, loss_s1: 0.026804, loss_fp: 0.002154, loss_freq: 0.039318
[16:48:44.428] iteration 12772: loss: 0.062910, loss_s1: 0.032154, loss_fp: 0.000437, loss_freq: 0.022835
[16:48:45.062] iteration 12773: loss: 0.066238, loss_s1: 0.040902, loss_fp: 0.004868, loss_freq: 0.043338
[16:48:45.691] iteration 12774: loss: 0.054852, loss_s1: 0.026880, loss_fp: 0.001412, loss_freq: 0.012367
[16:48:46.323] iteration 12775: loss: 0.053290, loss_s1: 0.028742, loss_fp: 0.002748, loss_freq: 0.018034
[16:48:46.947] iteration 12776: loss: 0.066086, loss_s1: 0.036095, loss_fp: 0.002991, loss_freq: 0.035530
[16:48:47.574] iteration 12777: loss: 0.076790, loss_s1: 0.048106, loss_fp: 0.002708, loss_freq: 0.047090
[16:48:48.203] iteration 12778: loss: 0.034875, loss_s1: 0.009260, loss_fp: 0.009265, loss_freq: 0.006163
[16:48:48.829] iteration 12779: loss: 0.039833, loss_s1: 0.015606, loss_fp: 0.000893, loss_freq: 0.019949
[16:48:49.483] iteration 12780: loss: 0.046357, loss_s1: 0.016428, loss_fp: 0.001114, loss_freq: 0.026220
[16:48:50.144] iteration 12781: loss: 0.059585, loss_s1: 0.048568, loss_fp: 0.011909, loss_freq: 0.021631
[16:48:50.785] iteration 12782: loss: 0.068326, loss_s1: 0.035961, loss_fp: 0.001803, loss_freq: 0.029850
[16:48:51.412] iteration 12783: loss: 0.096532, loss_s1: 0.047143, loss_fp: 0.001853, loss_freq: 0.053456
[16:48:52.035] iteration 12784: loss: 0.053174, loss_s1: 0.035093, loss_fp: 0.002255, loss_freq: 0.021364
[16:48:52.661] iteration 12785: loss: 0.093490, loss_s1: 0.063958, loss_fp: 0.002380, loss_freq: 0.080225
[16:48:53.289] iteration 12786: loss: 0.069056, loss_s1: 0.028862, loss_fp: 0.002123, loss_freq: 0.058342
[16:48:53.913] iteration 12787: loss: 0.043474, loss_s1: 0.027334, loss_fp: 0.005907, loss_freq: 0.019368
[16:48:54.540] iteration 12788: loss: 0.056630, loss_s1: 0.032086, loss_fp: 0.002714, loss_freq: 0.035676
[16:48:55.170] iteration 12789: loss: 0.063430, loss_s1: 0.038394, loss_fp: 0.003304, loss_freq: 0.017288
[16:48:55.797] iteration 12790: loss: 0.089092, loss_s1: 0.059905, loss_fp: 0.003980, loss_freq: 0.049030
[16:48:56.423] iteration 12791: loss: 0.069577, loss_s1: 0.054161, loss_fp: 0.003532, loss_freq: 0.028023
[16:48:57.049] iteration 12792: loss: 0.080579, loss_s1: 0.093998, loss_fp: 0.000390, loss_freq: 0.019333
[16:48:57.675] iteration 12793: loss: 0.054540, loss_s1: 0.041309, loss_fp: 0.001207, loss_freq: 0.019407
[16:48:58.300] iteration 12794: loss: 0.097420, loss_s1: 0.089619, loss_fp: 0.003287, loss_freq: 0.058010
[16:48:58.928] iteration 12795: loss: 0.051123, loss_s1: 0.018038, loss_fp: 0.000627, loss_freq: 0.017515
[16:48:59.553] iteration 12796: loss: 0.053174, loss_s1: 0.044968, loss_fp: 0.002820, loss_freq: 0.023348
[16:49:00.183] iteration 12797: loss: 0.056133, loss_s1: 0.056859, loss_fp: 0.003636, loss_freq: 0.014308
[16:49:00.809] iteration 12798: loss: 0.051450, loss_s1: 0.035656, loss_fp: 0.001622, loss_freq: 0.019496
[16:49:01.440] iteration 12799: loss: 0.055444, loss_s1: 0.034657, loss_fp: 0.001193, loss_freq: 0.031036
[16:49:02.070] iteration 12800: loss: 0.075490, loss_s1: 0.052063, loss_fp: 0.003102, loss_freq: 0.035156
[16:49:05.201] iteration 12800 : mean_dice : 0.719910
[16:49:05.849] iteration 12801: loss: 0.058500, loss_s1: 0.034688, loss_fp: 0.002930, loss_freq: 0.035943
[16:49:06.476] iteration 12802: loss: 0.080750, loss_s1: 0.060475, loss_fp: 0.003368, loss_freq: 0.053730
[16:49:07.103] iteration 12803: loss: 0.078645, loss_s1: 0.057547, loss_fp: 0.007031, loss_freq: 0.032342
[16:49:07.728] iteration 12804: loss: 0.111795, loss_s1: 0.092288, loss_fp: 0.005839, loss_freq: 0.075489
[16:49:08.355] iteration 12805: loss: 0.039883, loss_s1: 0.013619, loss_fp: 0.003553, loss_freq: 0.027303
[16:49:08.980] iteration 12806: loss: 0.063735, loss_s1: 0.029334, loss_fp: 0.007101, loss_freq: 0.033534
[16:49:09.598] iteration 12807: loss: 0.059655, loss_s1: 0.048852, loss_fp: 0.000541, loss_freq: 0.015982
[16:49:10.233] iteration 12808: loss: 0.054195, loss_s1: 0.019639, loss_fp: 0.008212, loss_freq: 0.033669
[16:49:10.861] iteration 12809: loss: 0.066039, loss_s1: 0.031771, loss_fp: 0.006250, loss_freq: 0.039163
[16:49:11.485] iteration 12810: loss: 0.037876, loss_s1: 0.016436, loss_fp: 0.001219, loss_freq: 0.005091
[16:49:12.111] iteration 12811: loss: 0.078772, loss_s1: 0.054627, loss_fp: 0.016568, loss_freq: 0.019294
[16:49:12.741] iteration 12812: loss: 0.085536, loss_s1: 0.062353, loss_fp: 0.008216, loss_freq: 0.021504
[16:49:13.384] iteration 12813: loss: 0.071593, loss_s1: 0.051022, loss_fp: 0.006127, loss_freq: 0.046429
[16:49:14.082] iteration 12814: loss: 0.057987, loss_s1: 0.028432, loss_fp: 0.002242, loss_freq: 0.020453
[16:49:14.747] iteration 12815: loss: 0.069525, loss_s1: 0.066463, loss_fp: 0.001488, loss_freq: 0.028805
[16:49:15.391] iteration 12816: loss: 0.044620, loss_s1: 0.020844, loss_fp: 0.002462, loss_freq: 0.018319
[16:49:16.023] iteration 12817: loss: 0.053454, loss_s1: 0.021304, loss_fp: 0.001100, loss_freq: 0.038047
[16:49:16.657] iteration 12818: loss: 0.081848, loss_s1: 0.087184, loss_fp: 0.003022, loss_freq: 0.018804
[16:49:17.287] iteration 12819: loss: 0.052107, loss_s1: 0.040344, loss_fp: 0.007642, loss_freq: 0.015233
[16:49:17.913] iteration 12820: loss: 0.067601, loss_s1: 0.064813, loss_fp: 0.002387, loss_freq: 0.033911
[16:49:18.545] iteration 12821: loss: 0.085346, loss_s1: 0.065708, loss_fp: 0.002561, loss_freq: 0.059893
[16:49:19.174] iteration 12822: loss: 0.053962, loss_s1: 0.037957, loss_fp: 0.001790, loss_freq: 0.034519
[16:49:19.803] iteration 12823: loss: 0.060065, loss_s1: 0.033147, loss_fp: 0.003747, loss_freq: 0.043476
[16:49:20.434] iteration 12824: loss: 0.070183, loss_s1: 0.024624, loss_fp: 0.004155, loss_freq: 0.024786
[16:49:21.072] iteration 12825: loss: 0.047529, loss_s1: 0.027298, loss_fp: 0.000824, loss_freq: 0.017757
[16:49:21.707] iteration 12826: loss: 0.036797, loss_s1: 0.012417, loss_fp: 0.001805, loss_freq: 0.009658
[16:49:22.335] iteration 12827: loss: 0.060944, loss_s1: 0.028150, loss_fp: 0.004185, loss_freq: 0.048912
[16:49:22.963] iteration 12828: loss: 0.107936, loss_s1: 0.066424, loss_fp: 0.007767, loss_freq: 0.088747
[16:49:23.591] iteration 12829: loss: 0.060997, loss_s1: 0.038117, loss_fp: 0.001623, loss_freq: 0.027002
[16:49:24.220] iteration 12830: loss: 0.083989, loss_s1: 0.030323, loss_fp: 0.012638, loss_freq: 0.061886
[16:49:24.853] iteration 12831: loss: 0.095489, loss_s1: 0.048400, loss_fp: 0.012628, loss_freq: 0.074310
[16:49:25.477] iteration 12832: loss: 0.077228, loss_s1: 0.053010, loss_fp: 0.002722, loss_freq: 0.027587
[16:49:26.102] iteration 12833: loss: 0.062460, loss_s1: 0.032491, loss_fp: 0.002558, loss_freq: 0.036384
[16:49:26.729] iteration 12834: loss: 0.037758, loss_s1: 0.021382, loss_fp: 0.001385, loss_freq: 0.007972
[16:49:27.348] iteration 12835: loss: 0.085429, loss_s1: 0.026364, loss_fp: 0.012528, loss_freq: 0.064884
[16:49:27.978] iteration 12836: loss: 0.047547, loss_s1: 0.028570, loss_fp: 0.002707, loss_freq: 0.023122
[16:49:28.607] iteration 12837: loss: 0.049755, loss_s1: 0.035211, loss_fp: 0.002868, loss_freq: 0.024592
[16:49:29.326] iteration 12838: loss: 0.115368, loss_s1: 0.093534, loss_fp: 0.026423, loss_freq: 0.059878
[16:49:30.056] iteration 12839: loss: 0.093623, loss_s1: 0.068232, loss_fp: 0.002666, loss_freq: 0.080557
[16:49:30.786] iteration 12840: loss: 0.089975, loss_s1: 0.030268, loss_fp: 0.004435, loss_freq: 0.101094
[16:49:31.682] iteration 12841: loss: 0.082131, loss_s1: 0.036447, loss_fp: 0.005031, loss_freq: 0.037240
[16:49:32.308] iteration 12842: loss: 0.071390, loss_s1: 0.059942, loss_fp: 0.001790, loss_freq: 0.020399
[16:49:32.975] iteration 12843: loss: 0.075693, loss_s1: 0.084209, loss_fp: 0.007073, loss_freq: 0.024714
[16:49:33.635] iteration 12844: loss: 0.081218, loss_s1: 0.050304, loss_fp: 0.002123, loss_freq: 0.030825
[16:49:34.267] iteration 12845: loss: 0.066877, loss_s1: 0.029510, loss_fp: 0.000964, loss_freq: 0.035205
[16:49:34.888] iteration 12846: loss: 0.057419, loss_s1: 0.053577, loss_fp: 0.001827, loss_freq: 0.017233
[16:49:35.514] iteration 12847: loss: 0.082846, loss_s1: 0.064148, loss_fp: 0.003230, loss_freq: 0.007310
[16:49:36.137] iteration 12848: loss: 0.052281, loss_s1: 0.019251, loss_fp: 0.000661, loss_freq: 0.023530
[16:49:36.764] iteration 12849: loss: 0.061854, loss_s1: 0.050716, loss_fp: 0.002232, loss_freq: 0.013722
[16:49:37.388] iteration 12850: loss: 0.081490, loss_s1: 0.062955, loss_fp: 0.006473, loss_freq: 0.044517
[16:49:38.016] iteration 12851: loss: 0.095500, loss_s1: 0.099550, loss_fp: 0.010647, loss_freq: 0.028389
[16:49:38.646] iteration 12852: loss: 0.066811, loss_s1: 0.038881, loss_fp: 0.015501, loss_freq: 0.030289
[16:49:39.274] iteration 12853: loss: 0.047729, loss_s1: 0.029081, loss_fp: 0.005133, loss_freq: 0.025685
[16:49:39.900] iteration 12854: loss: 0.062459, loss_s1: 0.048953, loss_fp: 0.001737, loss_freq: 0.031100
[16:49:40.523] iteration 12855: loss: 0.054157, loss_s1: 0.023969, loss_fp: 0.008782, loss_freq: 0.036946
[16:49:41.145] iteration 12856: loss: 0.060091, loss_s1: 0.024074, loss_fp: 0.000290, loss_freq: 0.034639
[16:49:41.778] iteration 12857: loss: 0.064195, loss_s1: 0.046816, loss_fp: 0.008220, loss_freq: 0.026744
[16:49:42.406] iteration 12858: loss: 0.064691, loss_s1: 0.030188, loss_fp: 0.006546, loss_freq: 0.040330
[16:49:43.030] iteration 12859: loss: 0.085336, loss_s1: 0.069026, loss_fp: 0.006670, loss_freq: 0.026384
[16:49:43.657] iteration 12860: loss: 0.097105, loss_s1: 0.071952, loss_fp: 0.002392, loss_freq: 0.061726
[16:49:44.282] iteration 12861: loss: 0.040761, loss_s1: 0.014567, loss_fp: 0.003299, loss_freq: 0.019197
[16:49:44.907] iteration 12862: loss: 0.088058, loss_s1: 0.044336, loss_fp: 0.005827, loss_freq: 0.046415
[16:49:45.530] iteration 12863: loss: 0.085281, loss_s1: 0.062007, loss_fp: 0.002445, loss_freq: 0.047346
[16:49:46.153] iteration 12864: loss: 0.061386, loss_s1: 0.063650, loss_fp: 0.003803, loss_freq: 0.007823
[16:49:46.776] iteration 12865: loss: 0.131059, loss_s1: 0.123666, loss_fp: 0.015166, loss_freq: 0.035574
[16:49:47.399] iteration 12866: loss: 0.106852, loss_s1: 0.086627, loss_fp: 0.013182, loss_freq: 0.084215
[16:49:48.023] iteration 12867: loss: 0.055389, loss_s1: 0.057379, loss_fp: 0.000791, loss_freq: 0.010099
[16:49:48.649] iteration 12868: loss: 0.057603, loss_s1: 0.044913, loss_fp: 0.002942, loss_freq: 0.018324
[16:49:49.276] iteration 12869: loss: 0.073051, loss_s1: 0.030180, loss_fp: 0.002019, loss_freq: 0.024300
[16:49:49.900] iteration 12870: loss: 0.064369, loss_s1: 0.032276, loss_fp: 0.002743, loss_freq: 0.030417
[16:49:50.526] iteration 12871: loss: 0.118823, loss_s1: 0.089915, loss_fp: 0.009366, loss_freq: 0.103186
[16:49:51.151] iteration 12872: loss: 0.050078, loss_s1: 0.038218, loss_fp: 0.002282, loss_freq: 0.022146
[16:49:51.773] iteration 12873: loss: 0.094576, loss_s1: 0.066383, loss_fp: 0.002545, loss_freq: 0.036876
[16:49:52.408] iteration 12874: loss: 0.037407, loss_s1: 0.009307, loss_fp: 0.002388, loss_freq: 0.017204
[16:49:53.037] iteration 12875: loss: 0.059494, loss_s1: 0.038744, loss_fp: 0.001107, loss_freq: 0.018922
[16:49:53.666] iteration 12876: loss: 0.060800, loss_s1: 0.033165, loss_fp: 0.004043, loss_freq: 0.016256
[16:49:54.292] iteration 12877: loss: 0.084218, loss_s1: 0.055218, loss_fp: 0.008402, loss_freq: 0.045361
[16:49:54.915] iteration 12878: loss: 0.072742, loss_s1: 0.058137, loss_fp: 0.001897, loss_freq: 0.028592
[16:49:55.533] iteration 12879: loss: 0.051738, loss_s1: 0.019392, loss_fp: 0.002386, loss_freq: 0.009382
[16:49:56.153] iteration 12880: loss: 0.091252, loss_s1: 0.059655, loss_fp: 0.000912, loss_freq: 0.040481
[16:49:57.183] iteration 12881: loss: 0.062927, loss_s1: 0.072582, loss_fp: 0.001211, loss_freq: 0.012838
[16:49:57.841] iteration 12882: loss: 0.076038, loss_s1: 0.044959, loss_fp: 0.014326, loss_freq: 0.030772
[16:49:58.482] iteration 12883: loss: 0.063052, loss_s1: 0.054602, loss_fp: 0.003132, loss_freq: 0.019530
[16:49:59.119] iteration 12884: loss: 0.042948, loss_s1: 0.027001, loss_fp: 0.000401, loss_freq: 0.010275
[16:49:59.758] iteration 12885: loss: 0.057675, loss_s1: 0.022739, loss_fp: 0.001584, loss_freq: 0.022600
[16:50:00.396] iteration 12886: loss: 0.129375, loss_s1: 0.095451, loss_fp: 0.007650, loss_freq: 0.041456
[16:50:01.032] iteration 12887: loss: 0.039753, loss_s1: 0.025830, loss_fp: 0.003062, loss_freq: 0.016791
[16:50:01.668] iteration 12888: loss: 0.054852, loss_s1: 0.054628, loss_fp: 0.001275, loss_freq: 0.013449
[16:50:02.305] iteration 12889: loss: 0.053909, loss_s1: 0.034211, loss_fp: 0.003510, loss_freq: 0.017201
[16:50:02.943] iteration 12890: loss: 0.082460, loss_s1: 0.047204, loss_fp: 0.019233, loss_freq: 0.052936
[16:50:03.586] iteration 12891: loss: 0.037178, loss_s1: 0.012466, loss_fp: 0.000760, loss_freq: 0.009320
[16:50:04.222] iteration 12892: loss: 0.075726, loss_s1: 0.068275, loss_fp: 0.002745, loss_freq: 0.044834
[16:50:04.859] iteration 12893: loss: 0.096748, loss_s1: 0.068022, loss_fp: 0.013993, loss_freq: 0.078739
[16:50:05.495] iteration 12894: loss: 0.060964, loss_s1: 0.020627, loss_fp: 0.002613, loss_freq: 0.041683
[16:50:06.131] iteration 12895: loss: 0.057772, loss_s1: 0.047541, loss_fp: 0.002751, loss_freq: 0.022512
[16:50:06.769] iteration 12896: loss: 0.154607, loss_s1: 0.089801, loss_fp: 0.011649, loss_freq: 0.089362
[16:50:07.409] iteration 12897: loss: 0.096307, loss_s1: 0.062443, loss_fp: 0.014835, loss_freq: 0.016810
[16:50:08.044] iteration 12898: loss: 0.064838, loss_s1: 0.048456, loss_fp: 0.005745, loss_freq: 0.030817
[16:50:08.683] iteration 12899: loss: 0.056189, loss_s1: 0.011533, loss_fp: 0.000823, loss_freq: 0.035190
[16:50:09.322] iteration 12900: loss: 0.050193, loss_s1: 0.026823, loss_fp: 0.008335, loss_freq: 0.016499
[16:50:09.963] iteration 12901: loss: 0.065826, loss_s1: 0.060001, loss_fp: 0.008855, loss_freq: 0.006757
[16:50:10.605] iteration 12902: loss: 0.054295, loss_s1: 0.036027, loss_fp: 0.007879, loss_freq: 0.023159
[16:50:11.242] iteration 12903: loss: 0.063924, loss_s1: 0.025867, loss_fp: 0.004544, loss_freq: 0.036808
[16:50:11.880] iteration 12904: loss: 0.120392, loss_s1: 0.079729, loss_fp: 0.004284, loss_freq: 0.108961
[16:50:12.519] iteration 12905: loss: 0.064155, loss_s1: 0.064811, loss_fp: 0.001195, loss_freq: 0.027228
[16:50:13.159] iteration 12906: loss: 0.098849, loss_s1: 0.115765, loss_fp: 0.005261, loss_freq: 0.034137
[16:50:13.804] iteration 12907: loss: 0.030979, loss_s1: 0.015419, loss_fp: 0.001993, loss_freq: 0.006457
[16:50:14.441] iteration 12908: loss: 0.108802, loss_s1: 0.106868, loss_fp: 0.006586, loss_freq: 0.059994
[16:50:15.080] iteration 12909: loss: 0.075491, loss_s1: 0.051546, loss_fp: 0.010940, loss_freq: 0.049106
[16:50:15.716] iteration 12910: loss: 0.058431, loss_s1: 0.051999, loss_fp: 0.003595, loss_freq: 0.019770
[16:50:16.356] iteration 12911: loss: 0.084112, loss_s1: 0.054529, loss_fp: 0.004602, loss_freq: 0.027261
[16:50:16.997] iteration 12912: loss: 0.046429, loss_s1: 0.020887, loss_fp: 0.001221, loss_freq: 0.011685
[16:50:17.636] iteration 12913: loss: 0.049470, loss_s1: 0.020091, loss_fp: 0.004231, loss_freq: 0.023056
[16:50:18.258] iteration 12914: loss: 0.044426, loss_s1: 0.027633, loss_fp: 0.001527, loss_freq: 0.011817
[16:50:18.880] iteration 12915: loss: 0.081445, loss_s1: 0.038768, loss_fp: 0.003337, loss_freq: 0.020515
[16:50:19.503] iteration 12916: loss: 0.069566, loss_s1: 0.077637, loss_fp: 0.006546, loss_freq: 0.020790
[16:50:20.163] iteration 12917: loss: 0.063309, loss_s1: 0.057973, loss_fp: 0.004243, loss_freq: 0.023536
[16:50:20.817] iteration 12918: loss: 0.053019, loss_s1: 0.031626, loss_fp: 0.001404, loss_freq: 0.019616
[16:50:21.444] iteration 12919: loss: 0.088249, loss_s1: 0.060062, loss_fp: 0.001281, loss_freq: 0.049055
[16:50:22.073] iteration 12920: loss: 0.071220, loss_s1: 0.056086, loss_fp: 0.005002, loss_freq: 0.021950
[16:50:22.695] iteration 12921: loss: 0.063679, loss_s1: 0.022648, loss_fp: 0.002533, loss_freq: 0.023475
[16:50:23.349] iteration 12922: loss: 0.077330, loss_s1: 0.079111, loss_fp: 0.002876, loss_freq: 0.025338
[16:50:24.007] iteration 12923: loss: 0.066136, loss_s1: 0.041933, loss_fp: 0.018611, loss_freq: 0.035707
[16:50:24.665] iteration 12924: loss: 0.057707, loss_s1: 0.044911, loss_fp: 0.001603, loss_freq: 0.024684
[16:50:25.324] iteration 12925: loss: 0.072462, loss_s1: 0.039228, loss_fp: 0.002729, loss_freq: 0.055143
[16:50:25.975] iteration 12926: loss: 0.058693, loss_s1: 0.054704, loss_fp: 0.000667, loss_freq: 0.008983
[16:50:26.598] iteration 12927: loss: 0.036221, loss_s1: 0.007028, loss_fp: 0.000274, loss_freq: 0.015869
[16:50:27.219] iteration 12928: loss: 0.069126, loss_s1: 0.044322, loss_fp: 0.007396, loss_freq: 0.034996
[16:50:27.844] iteration 12929: loss: 0.077026, loss_s1: 0.075509, loss_fp: 0.003025, loss_freq: 0.021080
[16:50:28.489] iteration 12930: loss: 0.086681, loss_s1: 0.072072, loss_fp: 0.002338, loss_freq: 0.062315
[16:50:29.160] iteration 12931: loss: 0.080194, loss_s1: 0.090660, loss_fp: 0.002457, loss_freq: 0.024063
[16:50:29.835] iteration 12932: loss: 0.056661, loss_s1: 0.021616, loss_fp: 0.004867, loss_freq: 0.016214
[16:50:30.517] iteration 12933: loss: 0.057647, loss_s1: 0.031573, loss_fp: 0.006729, loss_freq: 0.024024
[16:50:31.191] iteration 12934: loss: 0.096108, loss_s1: 0.082191, loss_fp: 0.020016, loss_freq: 0.043104
[16:50:31.865] iteration 12935: loss: 0.070264, loss_s1: 0.042030, loss_fp: 0.001393, loss_freq: 0.019029
[16:50:32.520] iteration 12936: loss: 0.073945, loss_s1: 0.052789, loss_fp: 0.002947, loss_freq: 0.039899
[16:50:33.160] iteration 12937: loss: 0.037292, loss_s1: 0.026243, loss_fp: 0.001503, loss_freq: 0.007347
[16:50:33.797] iteration 12938: loss: 0.072107, loss_s1: 0.032240, loss_fp: 0.000530, loss_freq: 0.046138
[16:50:34.440] iteration 12939: loss: 0.060110, loss_s1: 0.065432, loss_fp: 0.001895, loss_freq: 0.007364
[16:50:35.079] iteration 12940: loss: 0.067829, loss_s1: 0.061912, loss_fp: 0.002657, loss_freq: 0.021019
[16:50:35.718] iteration 12941: loss: 0.060216, loss_s1: 0.031920, loss_fp: 0.000391, loss_freq: 0.039533
[16:50:36.360] iteration 12942: loss: 0.063860, loss_s1: 0.052725, loss_fp: 0.010584, loss_freq: 0.014919
[16:50:36.997] iteration 12943: loss: 0.061324, loss_s1: 0.054244, loss_fp: 0.001881, loss_freq: 0.020545
[16:50:37.635] iteration 12944: loss: 0.054065, loss_s1: 0.018093, loss_fp: 0.002090, loss_freq: 0.031573
[16:50:38.276] iteration 12945: loss: 0.069113, loss_s1: 0.044713, loss_fp: 0.003831, loss_freq: 0.036012
[16:50:38.915] iteration 12946: loss: 0.058254, loss_s1: 0.027739, loss_fp: 0.008177, loss_freq: 0.039086
[16:50:39.556] iteration 12947: loss: 0.067994, loss_s1: 0.025467, loss_fp: 0.001773, loss_freq: 0.037804
[16:50:40.193] iteration 12948: loss: 0.058835, loss_s1: 0.051771, loss_fp: 0.002521, loss_freq: 0.026698
[16:50:40.828] iteration 12949: loss: 0.052589, loss_s1: 0.039518, loss_fp: 0.006788, loss_freq: 0.013218
[16:50:41.463] iteration 12950: loss: 0.104697, loss_s1: 0.068680, loss_fp: 0.002120, loss_freq: 0.059098
[16:50:42.099] iteration 12951: loss: 0.064365, loss_s1: 0.044954, loss_fp: 0.003095, loss_freq: 0.036429
[16:50:42.740] iteration 12952: loss: 0.043902, loss_s1: 0.025553, loss_fp: 0.004815, loss_freq: 0.022692
[16:50:43.386] iteration 12953: loss: 0.052995, loss_s1: 0.018849, loss_fp: 0.001331, loss_freq: 0.032142
[16:50:44.025] iteration 12954: loss: 0.054430, loss_s1: 0.033816, loss_fp: 0.000584, loss_freq: 0.021714
[16:50:44.663] iteration 12955: loss: 0.067135, loss_s1: 0.073601, loss_fp: 0.005939, loss_freq: 0.018208
[16:50:45.301] iteration 12956: loss: 0.065389, loss_s1: 0.034974, loss_fp: 0.001632, loss_freq: 0.039556
[16:50:45.939] iteration 12957: loss: 0.093415, loss_s1: 0.091136, loss_fp: 0.001424, loss_freq: 0.055672
[16:50:46.594] iteration 12958: loss: 0.055423, loss_s1: 0.052035, loss_fp: 0.001011, loss_freq: 0.020685
[16:50:47.250] iteration 12959: loss: 0.047037, loss_s1: 0.033416, loss_fp: 0.003066, loss_freq: 0.006109
[16:50:47.907] iteration 12960: loss: 0.071808, loss_s1: 0.071100, loss_fp: 0.004142, loss_freq: 0.025355
[16:50:48.564] iteration 12961: loss: 0.054980, loss_s1: 0.031361, loss_fp: 0.008890, loss_freq: 0.024217
[16:50:49.219] iteration 12962: loss: 0.074664, loss_s1: 0.056126, loss_fp: 0.004564, loss_freq: 0.023722
[16:50:49.874] iteration 12963: loss: 0.092895, loss_s1: 0.108499, loss_fp: 0.002041, loss_freq: 0.035386
[16:50:50.516] iteration 12964: loss: 0.070332, loss_s1: 0.020208, loss_fp: 0.000906, loss_freq: 0.016103
[16:50:51.138] iteration 12965: loss: 0.085035, loss_s1: 0.098798, loss_fp: 0.003135, loss_freq: 0.031945
[16:50:51.757] iteration 12966: loss: 0.040592, loss_s1: 0.026742, loss_fp: 0.001028, loss_freq: 0.011927
[16:50:52.381] iteration 12967: loss: 0.084077, loss_s1: 0.049898, loss_fp: 0.002899, loss_freq: 0.059762
[16:50:53.001] iteration 12968: loss: 0.061796, loss_s1: 0.023995, loss_fp: 0.011803, loss_freq: 0.023632
[16:50:53.624] iteration 12969: loss: 0.078867, loss_s1: 0.066222, loss_fp: 0.024160, loss_freq: 0.024779
[16:50:54.250] iteration 12970: loss: 0.067255, loss_s1: 0.053451, loss_fp: 0.002296, loss_freq: 0.034550
[16:50:54.874] iteration 12971: loss: 0.080252, loss_s1: 0.045039, loss_fp: 0.001461, loss_freq: 0.040340
[16:50:55.502] iteration 12972: loss: 0.079645, loss_s1: 0.037365, loss_fp: 0.009795, loss_freq: 0.007568
[16:50:56.125] iteration 12973: loss: 0.068569, loss_s1: 0.014701, loss_fp: 0.000957, loss_freq: 0.025190
[16:50:56.749] iteration 12974: loss: 0.042953, loss_s1: 0.020796, loss_fp: 0.002503, loss_freq: 0.005080
[16:50:57.373] iteration 12975: loss: 0.061431, loss_s1: 0.034051, loss_fp: 0.004660, loss_freq: 0.034192
[16:50:58.004] iteration 12976: loss: 0.061291, loss_s1: 0.030765, loss_fp: 0.002808, loss_freq: 0.033391
[16:50:58.626] iteration 12977: loss: 0.082530, loss_s1: 0.071244, loss_fp: 0.000922, loss_freq: 0.041412
[16:50:59.252] iteration 12978: loss: 0.067838, loss_s1: 0.045449, loss_fp: 0.001703, loss_freq: 0.020268
[16:50:59.882] iteration 12979: loss: 0.074546, loss_s1: 0.058332, loss_fp: 0.004438, loss_freq: 0.022832
[16:51:00.502] iteration 12980: loss: 0.066274, loss_s1: 0.068244, loss_fp: 0.003455, loss_freq: 0.029906
[16:51:01.165] iteration 12981: loss: 0.069837, loss_s1: 0.023102, loss_fp: 0.006920, loss_freq: 0.052828
[16:51:01.827] iteration 12982: loss: 0.090578, loss_s1: 0.021401, loss_fp: 0.003721, loss_freq: 0.070493
[16:51:02.470] iteration 12983: loss: 0.102791, loss_s1: 0.099103, loss_fp: 0.005482, loss_freq: 0.041556
[16:51:03.095] iteration 12984: loss: 0.057168, loss_s1: 0.023237, loss_fp: 0.000585, loss_freq: 0.040906
[16:51:03.725] iteration 12985: loss: 0.059300, loss_s1: 0.040816, loss_fp: 0.005292, loss_freq: 0.014814
[16:51:04.353] iteration 12986: loss: 0.051709, loss_s1: 0.017661, loss_fp: 0.002383, loss_freq: 0.016222
[16:51:04.978] iteration 12987: loss: 0.043208, loss_s1: 0.008689, loss_fp: 0.001197, loss_freq: 0.006236
[16:51:05.606] iteration 12988: loss: 0.116057, loss_s1: 0.072331, loss_fp: 0.004002, loss_freq: 0.077069
[16:51:06.236] iteration 12989: loss: 0.122020, loss_s1: 0.073557, loss_fp: 0.008895, loss_freq: 0.099155
[16:51:06.857] iteration 12990: loss: 0.109426, loss_s1: 0.117979, loss_fp: 0.001622, loss_freq: 0.032373
[16:51:07.482] iteration 12991: loss: 0.064619, loss_s1: 0.018631, loss_fp: 0.001261, loss_freq: 0.010611
[16:51:08.104] iteration 12992: loss: 0.068560, loss_s1: 0.037674, loss_fp: 0.006095, loss_freq: 0.053327
[16:51:08.728] iteration 12993: loss: 0.061530, loss_s1: 0.040948, loss_fp: 0.003393, loss_freq: 0.015806
[16:51:09.350] iteration 12994: loss: 0.054999, loss_s1: 0.018150, loss_fp: 0.001126, loss_freq: 0.025722
[16:51:09.976] iteration 12995: loss: 0.040232, loss_s1: 0.032771, loss_fp: 0.000898, loss_freq: 0.006521
[16:51:10.600] iteration 12996: loss: 0.072901, loss_s1: 0.058104, loss_fp: 0.001900, loss_freq: 0.034199
[16:51:11.227] iteration 12997: loss: 0.076721, loss_s1: 0.069622, loss_fp: 0.001318, loss_freq: 0.026798
[16:51:11.850] iteration 12998: loss: 0.040100, loss_s1: 0.018689, loss_fp: 0.000492, loss_freq: 0.018072
[16:51:12.475] iteration 12999: loss: 0.086486, loss_s1: 0.045162, loss_fp: 0.003131, loss_freq: 0.049813
[16:51:13.100] iteration 13000: loss: 0.084987, loss_s1: 0.025776, loss_fp: 0.001781, loss_freq: 0.109074
[16:51:16.241] iteration 13000 : mean_dice : 0.706920
[16:51:16.892] iteration 13001: loss: 0.079814, loss_s1: 0.058962, loss_fp: 0.004088, loss_freq: 0.057209
[16:51:17.515] iteration 13002: loss: 0.084025, loss_s1: 0.037228, loss_fp: 0.002357, loss_freq: 0.041996
[16:51:18.145] iteration 13003: loss: 0.073086, loss_s1: 0.070236, loss_fp: 0.001390, loss_freq: 0.019518
[16:51:18.773] iteration 13004: loss: 0.055977, loss_s1: 0.058376, loss_fp: 0.003591, loss_freq: 0.011257
[16:51:19.400] iteration 13005: loss: 0.074050, loss_s1: 0.027999, loss_fp: 0.001247, loss_freq: 0.027845
[16:51:20.025] iteration 13006: loss: 0.044506, loss_s1: 0.011906, loss_fp: 0.000289, loss_freq: 0.017085
[16:51:20.651] iteration 13007: loss: 0.055967, loss_s1: 0.050484, loss_fp: 0.006329, loss_freq: 0.008431
[16:51:21.276] iteration 13008: loss: 0.098010, loss_s1: 0.058106, loss_fp: 0.004104, loss_freq: 0.045721
[16:51:21.900] iteration 13009: loss: 0.074120, loss_s1: 0.078404, loss_fp: 0.001134, loss_freq: 0.026256
[16:51:22.528] iteration 13010: loss: 0.031290, loss_s1: 0.020201, loss_fp: 0.002165, loss_freq: 0.007395
[16:51:23.154] iteration 13011: loss: 0.085602, loss_s1: 0.049827, loss_fp: 0.012106, loss_freq: 0.067018
[16:51:23.781] iteration 13012: loss: 0.074155, loss_s1: 0.086018, loss_fp: 0.006160, loss_freq: 0.014066
[16:51:24.409] iteration 13013: loss: 0.073005, loss_s1: 0.056667, loss_fp: 0.002577, loss_freq: 0.021015
[16:51:25.078] iteration 13014: loss: 0.050897, loss_s1: 0.038016, loss_fp: 0.006189, loss_freq: 0.013562
[16:51:25.701] iteration 13015: loss: 0.066651, loss_s1: 0.037254, loss_fp: 0.001763, loss_freq: 0.053190
[16:51:26.332] iteration 13016: loss: 0.058845, loss_s1: 0.063284, loss_fp: 0.003404, loss_freq: 0.011092
[16:51:26.963] iteration 13017: loss: 0.056415, loss_s1: 0.017441, loss_fp: 0.001045, loss_freq: 0.046810
[16:51:27.588] iteration 13018: loss: 0.042668, loss_s1: 0.027699, loss_fp: 0.001370, loss_freq: 0.020384
[16:51:28.213] iteration 13019: loss: 0.067403, loss_s1: 0.055009, loss_fp: 0.006800, loss_freq: 0.022893
[16:51:28.835] iteration 13020: loss: 0.119294, loss_s1: 0.103546, loss_fp: 0.006185, loss_freq: 0.047169
[16:51:29.457] iteration 13021: loss: 0.076524, loss_s1: 0.068982, loss_fp: 0.002853, loss_freq: 0.039700
[16:51:30.077] iteration 13022: loss: 0.059015, loss_s1: 0.043358, loss_fp: 0.001331, loss_freq: 0.025171
[16:51:30.700] iteration 13023: loss: 0.084881, loss_s1: 0.048149, loss_fp: 0.006347, loss_freq: 0.059614
[16:51:31.324] iteration 13024: loss: 0.095541, loss_s1: 0.059476, loss_fp: 0.001953, loss_freq: 0.040249
[16:51:31.947] iteration 13025: loss: 0.043561, loss_s1: 0.028057, loss_fp: 0.003212, loss_freq: 0.009909
[16:51:32.575] iteration 13026: loss: 0.101656, loss_s1: 0.087144, loss_fp: 0.013539, loss_freq: 0.034317
[16:51:33.197] iteration 13027: loss: 0.094356, loss_s1: 0.064470, loss_fp: 0.008514, loss_freq: 0.079141
[16:51:33.823] iteration 13028: loss: 0.062170, loss_s1: 0.038388, loss_fp: 0.004835, loss_freq: 0.025524
[16:51:34.456] iteration 13029: loss: 0.054556, loss_s1: 0.028535, loss_fp: 0.002986, loss_freq: 0.014589
[16:51:35.086] iteration 13030: loss: 0.101766, loss_s1: 0.092977, loss_fp: 0.005416, loss_freq: 0.050494
[16:51:36.101] iteration 13031: loss: 0.073359, loss_s1: 0.044002, loss_fp: 0.006347, loss_freq: 0.040323
[16:51:36.924] iteration 13032: loss: 0.121186, loss_s1: 0.105576, loss_fp: 0.007164, loss_freq: 0.086325
[16:51:37.553] iteration 13033: loss: 0.069396, loss_s1: 0.047735, loss_fp: 0.005274, loss_freq: 0.042836
[16:51:38.175] iteration 13034: loss: 0.079863, loss_s1: 0.064871, loss_fp: 0.003815, loss_freq: 0.028759
[16:51:38.800] iteration 13035: loss: 0.057171, loss_s1: 0.034119, loss_fp: 0.000632, loss_freq: 0.023758
[16:51:39.419] iteration 13036: loss: 0.062690, loss_s1: 0.049715, loss_fp: 0.004025, loss_freq: 0.016372
[16:51:40.046] iteration 13037: loss: 0.044996, loss_s1: 0.023714, loss_fp: 0.002033, loss_freq: 0.009737
[16:51:40.674] iteration 13038: loss: 0.097692, loss_s1: 0.035586, loss_fp: 0.001267, loss_freq: 0.062831
[16:51:41.296] iteration 13039: loss: 0.070729, loss_s1: 0.082025, loss_fp: 0.002155, loss_freq: 0.017177
[16:51:41.922] iteration 13040: loss: 0.059601, loss_s1: 0.040959, loss_fp: 0.002424, loss_freq: 0.011389
[16:51:42.546] iteration 13041: loss: 0.076924, loss_s1: 0.021636, loss_fp: 0.005415, loss_freq: 0.066678
[16:51:43.619] iteration 13042: loss: 0.058145, loss_s1: 0.046473, loss_fp: 0.001287, loss_freq: 0.020722
[16:51:44.247] iteration 13043: loss: 0.070732, loss_s1: 0.041284, loss_fp: 0.001012, loss_freq: 0.052197
[16:51:44.904] iteration 13044: loss: 0.076696, loss_s1: 0.052368, loss_fp: 0.001693, loss_freq: 0.014887
[16:51:45.565] iteration 13045: loss: 0.065745, loss_s1: 0.045811, loss_fp: 0.000920, loss_freq: 0.011138
[16:51:46.222] iteration 13046: loss: 0.054819, loss_s1: 0.024877, loss_fp: 0.013275, loss_freq: 0.011261
[16:51:46.869] iteration 13047: loss: 0.097062, loss_s1: 0.091353, loss_fp: 0.005221, loss_freq: 0.017413
[16:51:47.492] iteration 13048: loss: 0.075751, loss_s1: 0.062736, loss_fp: 0.004008, loss_freq: 0.045884
[16:51:48.144] iteration 13049: loss: 0.037292, loss_s1: 0.019857, loss_fp: 0.000283, loss_freq: 0.008118
[16:51:48.815] iteration 13050: loss: 0.092292, loss_s1: 0.091574, loss_fp: 0.007873, loss_freq: 0.015653
[16:51:49.474] iteration 13051: loss: 0.083801, loss_s1: 0.093669, loss_fp: 0.002138, loss_freq: 0.020829
[16:51:50.111] iteration 13052: loss: 0.036057, loss_s1: 0.006480, loss_fp: 0.001279, loss_freq: 0.013157
[16:51:50.747] iteration 13053: loss: 0.078777, loss_s1: 0.052118, loss_fp: 0.004398, loss_freq: 0.060174
[16:51:51.387] iteration 13054: loss: 0.053438, loss_s1: 0.024232, loss_fp: 0.002270, loss_freq: 0.035993
[16:51:52.023] iteration 13055: loss: 0.050318, loss_s1: 0.018117, loss_fp: 0.001043, loss_freq: 0.015310
[16:51:52.662] iteration 13056: loss: 0.050690, loss_s1: 0.032850, loss_fp: 0.012505, loss_freq: 0.016988
[16:51:53.302] iteration 13057: loss: 0.068776, loss_s1: 0.068517, loss_fp: 0.000404, loss_freq: 0.030385
[16:51:53.941] iteration 13058: loss: 0.091915, loss_s1: 0.037381, loss_fp: 0.002883, loss_freq: 0.021921
[16:51:54.579] iteration 13059: loss: 0.056225, loss_s1: 0.033297, loss_fp: 0.002871, loss_freq: 0.013485
[16:51:55.217] iteration 13060: loss: 0.043170, loss_s1: 0.029727, loss_fp: 0.000881, loss_freq: 0.016082
[16:51:55.853] iteration 13061: loss: 0.058033, loss_s1: 0.017093, loss_fp: 0.001321, loss_freq: 0.025695
[16:51:56.493] iteration 13062: loss: 0.034376, loss_s1: 0.015765, loss_fp: 0.004439, loss_freq: 0.004193
[16:51:57.132] iteration 13063: loss: 0.051876, loss_s1: 0.020920, loss_fp: 0.000900, loss_freq: 0.018814
[16:51:57.768] iteration 13064: loss: 0.062816, loss_s1: 0.053191, loss_fp: 0.004479, loss_freq: 0.013172
[16:51:58.471] iteration 13065: loss: 0.149095, loss_s1: 0.110105, loss_fp: 0.002700, loss_freq: 0.140700
[16:51:59.131] iteration 13066: loss: 0.084141, loss_s1: 0.085675, loss_fp: 0.001717, loss_freq: 0.036566
[16:51:59.791] iteration 13067: loss: 0.093139, loss_s1: 0.087706, loss_fp: 0.001787, loss_freq: 0.058288
[16:52:00.446] iteration 13068: loss: 0.052865, loss_s1: 0.023830, loss_fp: 0.003335, loss_freq: 0.031998
[16:52:01.071] iteration 13069: loss: 0.099655, loss_s1: 0.097510, loss_fp: 0.005552, loss_freq: 0.039998
[16:52:01.696] iteration 13070: loss: 0.062262, loss_s1: 0.035433, loss_fp: 0.006773, loss_freq: 0.028824
[16:52:02.323] iteration 13071: loss: 0.048722, loss_s1: 0.017909, loss_fp: 0.002831, loss_freq: 0.010022
[16:52:02.948] iteration 13072: loss: 0.049651, loss_s1: 0.046428, loss_fp: 0.002662, loss_freq: 0.003568
[16:52:03.576] iteration 13073: loss: 0.080314, loss_s1: 0.075020, loss_fp: 0.003254, loss_freq: 0.027526
[16:52:04.203] iteration 13074: loss: 0.045561, loss_s1: 0.024351, loss_fp: 0.001047, loss_freq: 0.028421
[16:52:04.829] iteration 13075: loss: 0.048840, loss_s1: 0.044014, loss_fp: 0.001898, loss_freq: 0.007689
[16:52:05.454] iteration 13076: loss: 0.064108, loss_s1: 0.024350, loss_fp: 0.001489, loss_freq: 0.040690
[16:52:06.089] iteration 13077: loss: 0.071873, loss_s1: 0.052236, loss_fp: 0.005982, loss_freq: 0.037322
[16:52:06.712] iteration 13078: loss: 0.114709, loss_s1: 0.089973, loss_fp: 0.012536, loss_freq: 0.077096
[16:52:07.332] iteration 13079: loss: 0.063773, loss_s1: 0.049731, loss_fp: 0.002266, loss_freq: 0.023186
[16:52:07.957] iteration 13080: loss: 0.102759, loss_s1: 0.072985, loss_fp: 0.000977, loss_freq: 0.071779
[16:52:08.581] iteration 13081: loss: 0.068188, loss_s1: 0.049437, loss_fp: 0.002714, loss_freq: 0.035428
[16:52:09.232] iteration 13082: loss: 0.053904, loss_s1: 0.033319, loss_fp: 0.001852, loss_freq: 0.015659
[16:52:09.893] iteration 13083: loss: 0.094151, loss_s1: 0.090099, loss_fp: 0.002137, loss_freq: 0.057442
[16:52:10.556] iteration 13084: loss: 0.071392, loss_s1: 0.052425, loss_fp: 0.004505, loss_freq: 0.037294
[16:52:11.232] iteration 13085: loss: 0.037297, loss_s1: 0.007400, loss_fp: 0.004447, loss_freq: 0.023656
[16:52:11.894] iteration 13086: loss: 0.068421, loss_s1: 0.043528, loss_fp: 0.004135, loss_freq: 0.047870
[16:52:12.556] iteration 13087: loss: 0.047003, loss_s1: 0.022678, loss_fp: 0.004127, loss_freq: 0.013424
[16:52:13.192] iteration 13088: loss: 0.047194, loss_s1: 0.027360, loss_fp: 0.002531, loss_freq: 0.027186
[16:52:13.828] iteration 13089: loss: 0.062236, loss_s1: 0.024527, loss_fp: 0.006480, loss_freq: 0.059938
[16:52:14.492] iteration 13090: loss: 0.064205, loss_s1: 0.040415, loss_fp: 0.002578, loss_freq: 0.036376
[16:52:15.154] iteration 13091: loss: 0.055085, loss_s1: 0.038405, loss_fp: 0.002757, loss_freq: 0.018399
[16:52:15.779] iteration 13092: loss: 0.043576, loss_s1: 0.022247, loss_fp: 0.001974, loss_freq: 0.023862
[16:52:16.406] iteration 13093: loss: 0.044986, loss_s1: 0.022701, loss_fp: 0.001310, loss_freq: 0.011757
[16:52:17.032] iteration 13094: loss: 0.042836, loss_s1: 0.026832, loss_fp: 0.001167, loss_freq: 0.013123
[16:52:17.653] iteration 13095: loss: 0.065068, loss_s1: 0.039653, loss_fp: 0.006697, loss_freq: 0.037239
[16:52:18.293] iteration 13096: loss: 0.052370, loss_s1: 0.027591, loss_fp: 0.004022, loss_freq: 0.007247
[16:52:18.929] iteration 13097: loss: 0.075395, loss_s1: 0.058357, loss_fp: 0.001612, loss_freq: 0.038614
[16:52:19.574] iteration 13098: loss: 0.036548, loss_s1: 0.016665, loss_fp: 0.003196, loss_freq: 0.009752
[16:52:20.215] iteration 13099: loss: 0.085639, loss_s1: 0.036340, loss_fp: 0.001349, loss_freq: 0.045214
[16:52:20.853] iteration 13100: loss: 0.050695, loss_s1: 0.020846, loss_fp: 0.002420, loss_freq: 0.014771
[16:52:21.490] iteration 13101: loss: 0.046237, loss_s1: 0.026921, loss_fp: 0.003939, loss_freq: 0.022448
[16:52:22.128] iteration 13102: loss: 0.069275, loss_s1: 0.059184, loss_fp: 0.005396, loss_freq: 0.018514
[16:52:22.777] iteration 13103: loss: 0.059310, loss_s1: 0.049829, loss_fp: 0.001478, loss_freq: 0.011158
[16:52:23.406] iteration 13104: loss: 0.069295, loss_s1: 0.027345, loss_fp: 0.001544, loss_freq: 0.021566
[16:52:24.032] iteration 13105: loss: 0.077803, loss_s1: 0.049427, loss_fp: 0.002503, loss_freq: 0.023026
[16:52:24.662] iteration 13106: loss: 0.044151, loss_s1: 0.028467, loss_fp: 0.007302, loss_freq: 0.013850
[16:52:25.284] iteration 13107: loss: 0.099987, loss_s1: 0.081867, loss_fp: 0.002984, loss_freq: 0.082746
[16:52:25.909] iteration 13108: loss: 0.077081, loss_s1: 0.014923, loss_fp: 0.006769, loss_freq: 0.057149
[16:52:26.534] iteration 13109: loss: 0.054815, loss_s1: 0.032503, loss_fp: 0.006030, loss_freq: 0.033222
[16:52:27.158] iteration 13110: loss: 0.058994, loss_s1: 0.059449, loss_fp: 0.001689, loss_freq: 0.017075
[16:52:27.783] iteration 13111: loss: 0.117850, loss_s1: 0.063610, loss_fp: 0.004948, loss_freq: 0.066734
[16:52:28.408] iteration 13112: loss: 0.060959, loss_s1: 0.049167, loss_fp: 0.004333, loss_freq: 0.025564
[16:52:29.034] iteration 13113: loss: 0.097528, loss_s1: 0.091253, loss_fp: 0.001801, loss_freq: 0.066846
[16:52:29.666] iteration 13114: loss: 0.063529, loss_s1: 0.041694, loss_fp: 0.000737, loss_freq: 0.033645
[16:52:30.293] iteration 13115: loss: 0.052819, loss_s1: 0.029150, loss_fp: 0.002592, loss_freq: 0.014779
[16:52:30.916] iteration 13116: loss: 0.098072, loss_s1: 0.059599, loss_fp: 0.004161, loss_freq: 0.081231
[16:52:31.540] iteration 13117: loss: 0.060718, loss_s1: 0.032931, loss_fp: 0.001468, loss_freq: 0.038520
[16:52:32.161] iteration 13118: loss: 0.089138, loss_s1: 0.078665, loss_fp: 0.001372, loss_freq: 0.054830
[16:52:32.786] iteration 13119: loss: 0.043379, loss_s1: 0.029157, loss_fp: 0.001396, loss_freq: 0.018405
[16:52:33.410] iteration 13120: loss: 0.047108, loss_s1: 0.010312, loss_fp: 0.000451, loss_freq: 0.007346
[16:52:34.035] iteration 13121: loss: 0.070405, loss_s1: 0.040945, loss_fp: 0.016385, loss_freq: 0.027483
[16:52:34.660] iteration 13122: loss: 0.054552, loss_s1: 0.023748, loss_fp: 0.004059, loss_freq: 0.031311
[16:52:35.287] iteration 13123: loss: 0.092869, loss_s1: 0.062047, loss_fp: 0.012148, loss_freq: 0.069463
[16:52:35.911] iteration 13124: loss: 0.120742, loss_s1: 0.092188, loss_fp: 0.007061, loss_freq: 0.091872
[16:52:36.532] iteration 13125: loss: 0.116030, loss_s1: 0.055204, loss_fp: 0.004476, loss_freq: 0.049470
[16:52:37.158] iteration 13126: loss: 0.090869, loss_s1: 0.058448, loss_fp: 0.011405, loss_freq: 0.063144
[16:52:37.780] iteration 13127: loss: 0.044225, loss_s1: 0.033475, loss_fp: 0.000490, loss_freq: 0.022101
[16:52:38.403] iteration 13128: loss: 0.056905, loss_s1: 0.024311, loss_fp: 0.001438, loss_freq: 0.035890
[16:52:39.026] iteration 13129: loss: 0.047663, loss_s1: 0.025436, loss_fp: 0.001394, loss_freq: 0.005807
[16:52:39.648] iteration 13130: loss: 0.062675, loss_s1: 0.036010, loss_fp: 0.004072, loss_freq: 0.034960
[16:52:40.276] iteration 13131: loss: 0.082642, loss_s1: 0.068137, loss_fp: 0.006693, loss_freq: 0.042478
[16:52:40.897] iteration 13132: loss: 0.074423, loss_s1: 0.045059, loss_fp: 0.013322, loss_freq: 0.021046
[16:52:41.523] iteration 13133: loss: 0.054601, loss_s1: 0.028794, loss_fp: 0.009262, loss_freq: 0.019811
[16:52:42.146] iteration 13134: loss: 0.067788, loss_s1: 0.011946, loss_fp: 0.002583, loss_freq: 0.010134
[16:52:42.772] iteration 13135: loss: 0.057186, loss_s1: 0.036175, loss_fp: 0.000367, loss_freq: 0.024613
[16:52:43.394] iteration 13136: loss: 0.057031, loss_s1: 0.031198, loss_fp: 0.003970, loss_freq: 0.014226
[16:52:44.025] iteration 13137: loss: 0.064643, loss_s1: 0.057391, loss_fp: 0.001344, loss_freq: 0.035348
[16:52:44.650] iteration 13138: loss: 0.042016, loss_s1: 0.027530, loss_fp: 0.003423, loss_freq: 0.017482
[16:52:45.275] iteration 13139: loss: 0.063123, loss_s1: 0.024513, loss_fp: 0.002248, loss_freq: 0.030282
[16:52:45.898] iteration 13140: loss: 0.053726, loss_s1: 0.061114, loss_fp: 0.002572, loss_freq: 0.007922
[16:52:46.519] iteration 13141: loss: 0.086332, loss_s1: 0.072220, loss_fp: 0.003632, loss_freq: 0.021046
[16:52:47.138] iteration 13142: loss: 0.063628, loss_s1: 0.041078, loss_fp: 0.011027, loss_freq: 0.037763
[16:52:47.762] iteration 13143: loss: 0.108663, loss_s1: 0.061184, loss_fp: 0.011817, loss_freq: 0.066651
[16:52:48.386] iteration 13144: loss: 0.115138, loss_s1: 0.089898, loss_fp: 0.009683, loss_freq: 0.068728
[16:52:49.012] iteration 13145: loss: 0.061154, loss_s1: 0.045442, loss_fp: 0.001278, loss_freq: 0.018172
[16:52:49.636] iteration 13146: loss: 0.068313, loss_s1: 0.051755, loss_fp: 0.002970, loss_freq: 0.024452
[16:52:50.261] iteration 13147: loss: 0.059985, loss_s1: 0.028251, loss_fp: 0.001407, loss_freq: 0.039243
[16:52:50.886] iteration 13148: loss: 0.079850, loss_s1: 0.085181, loss_fp: 0.000767, loss_freq: 0.022286
[16:52:51.511] iteration 13149: loss: 0.145228, loss_s1: 0.099840, loss_fp: 0.002260, loss_freq: 0.131110
[16:52:52.138] iteration 13150: loss: 0.185005, loss_s1: 0.111013, loss_fp: 0.039505, loss_freq: 0.157692
[16:52:52.762] iteration 13151: loss: 0.062401, loss_s1: 0.051468, loss_fp: 0.001963, loss_freq: 0.027298
[16:52:53.384] iteration 13152: loss: 0.050539, loss_s1: 0.009250, loss_fp: 0.001761, loss_freq: 0.013261
[16:52:54.005] iteration 13153: loss: 0.068827, loss_s1: 0.050122, loss_fp: 0.002359, loss_freq: 0.035309
[16:52:54.629] iteration 13154: loss: 0.064196, loss_s1: 0.069364, loss_fp: 0.002041, loss_freq: 0.021943
[16:52:55.250] iteration 13155: loss: 0.075327, loss_s1: 0.053562, loss_fp: 0.003746, loss_freq: 0.045617
[16:52:55.872] iteration 13156: loss: 0.044948, loss_s1: 0.031360, loss_fp: 0.000346, loss_freq: 0.005447
[16:52:56.495] iteration 13157: loss: 0.063086, loss_s1: 0.038590, loss_fp: 0.005726, loss_freq: 0.029467
[16:52:57.117] iteration 13158: loss: 0.053776, loss_s1: 0.055159, loss_fp: 0.000966, loss_freq: 0.013074
[16:52:57.744] iteration 13159: loss: 0.055736, loss_s1: 0.055005, loss_fp: 0.001327, loss_freq: 0.012480
[16:52:58.369] iteration 13160: loss: 0.069484, loss_s1: 0.041052, loss_fp: 0.001837, loss_freq: 0.054000
[16:52:58.990] iteration 13161: loss: 0.077469, loss_s1: 0.020644, loss_fp: 0.010700, loss_freq: 0.078761
[16:52:59.611] iteration 13162: loss: 0.047220, loss_s1: 0.043349, loss_fp: 0.001074, loss_freq: 0.011427
[16:53:00.234] iteration 13163: loss: 0.045213, loss_s1: 0.019675, loss_fp: 0.004514, loss_freq: 0.013608
[16:53:00.858] iteration 13164: loss: 0.077089, loss_s1: 0.066169, loss_fp: 0.010220, loss_freq: 0.013007
[16:53:01.484] iteration 13165: loss: 0.056390, loss_s1: 0.048728, loss_fp: 0.000720, loss_freq: 0.027578
[16:53:02.106] iteration 13166: loss: 0.094044, loss_s1: 0.039770, loss_fp: 0.002413, loss_freq: 0.049305
[16:53:02.805] iteration 13167: loss: 0.087845, loss_s1: 0.046366, loss_fp: 0.003096, loss_freq: 0.052907
[16:53:03.461] iteration 13168: loss: 0.055130, loss_s1: 0.030254, loss_fp: 0.000903, loss_freq: 0.017032
[16:53:04.121] iteration 13169: loss: 0.112869, loss_s1: 0.091256, loss_fp: 0.004103, loss_freq: 0.073105
[16:53:04.773] iteration 13170: loss: 0.058193, loss_s1: 0.052850, loss_fp: 0.000618, loss_freq: 0.015590
[16:53:05.397] iteration 13171: loss: 0.042095, loss_s1: 0.024064, loss_fp: 0.003130, loss_freq: 0.015619
[16:53:06.020] iteration 13172: loss: 0.085220, loss_s1: 0.057901, loss_fp: 0.008294, loss_freq: 0.061213
[16:53:06.646] iteration 13173: loss: 0.052020, loss_s1: 0.022720, loss_fp: 0.004958, loss_freq: 0.033184
[16:53:07.267] iteration 13174: loss: 0.073352, loss_s1: 0.069926, loss_fp: 0.003635, loss_freq: 0.022932
[16:53:07.890] iteration 13175: loss: 0.071109, loss_s1: 0.086853, loss_fp: 0.001979, loss_freq: 0.020298
[16:53:08.512] iteration 13176: loss: 0.089927, loss_s1: 0.086607, loss_fp: 0.001339, loss_freq: 0.055712
[16:53:09.139] iteration 13177: loss: 0.047970, loss_s1: 0.035697, loss_fp: 0.004221, loss_freq: 0.018292
[16:53:09.763] iteration 13178: loss: 0.042213, loss_s1: 0.012487, loss_fp: 0.002360, loss_freq: 0.026046
[16:53:10.390] iteration 13179: loss: 0.039820, loss_s1: 0.023156, loss_fp: 0.003813, loss_freq: 0.013139
[16:53:11.012] iteration 13180: loss: 0.062457, loss_s1: 0.030187, loss_fp: 0.008543, loss_freq: 0.038229
[16:53:11.637] iteration 13181: loss: 0.066588, loss_s1: 0.028895, loss_fp: 0.003671, loss_freq: 0.037352
[16:53:12.264] iteration 13182: loss: 0.077847, loss_s1: 0.082741, loss_fp: 0.001496, loss_freq: 0.034686
[16:53:12.888] iteration 13183: loss: 0.063479, loss_s1: 0.014275, loss_fp: 0.008563, loss_freq: 0.035008
[16:53:13.510] iteration 13184: loss: 0.094465, loss_s1: 0.032542, loss_fp: 0.006798, loss_freq: 0.071890
[16:53:14.140] iteration 13185: loss: 0.073391, loss_s1: 0.051730, loss_fp: 0.001973, loss_freq: 0.030962
[16:53:14.767] iteration 13186: loss: 0.057318, loss_s1: 0.038177, loss_fp: 0.004366, loss_freq: 0.021705
[16:53:15.393] iteration 13187: loss: 0.065446, loss_s1: 0.028004, loss_fp: 0.009039, loss_freq: 0.025118
[16:53:16.016] iteration 13188: loss: 0.116567, loss_s1: 0.074105, loss_fp: 0.003085, loss_freq: 0.105960
[16:53:16.640] iteration 13189: loss: 0.051781, loss_s1: 0.034862, loss_fp: 0.003337, loss_freq: 0.013128
[16:53:17.270] iteration 13190: loss: 0.074943, loss_s1: 0.081179, loss_fp: 0.003227, loss_freq: 0.017673
[16:53:17.896] iteration 13191: loss: 0.118140, loss_s1: 0.076751, loss_fp: 0.006859, loss_freq: 0.093798
[16:53:18.519] iteration 13192: loss: 0.064683, loss_s1: 0.058078, loss_fp: 0.003018, loss_freq: 0.017425
[16:53:19.147] iteration 13193: loss: 0.093909, loss_s1: 0.074767, loss_fp: 0.001982, loss_freq: 0.074893
[16:53:19.769] iteration 13194: loss: 0.054563, loss_s1: 0.046963, loss_fp: 0.001512, loss_freq: 0.017739
[16:53:20.400] iteration 13195: loss: 0.058338, loss_s1: 0.038083, loss_fp: 0.003015, loss_freq: 0.032383
[16:53:21.021] iteration 13196: loss: 0.038069, loss_s1: 0.028015, loss_fp: 0.000599, loss_freq: 0.010630
[16:53:21.645] iteration 13197: loss: 0.055000, loss_s1: 0.046500, loss_fp: 0.000309, loss_freq: 0.021460
[16:53:22.276] iteration 13198: loss: 0.042029, loss_s1: 0.008032, loss_fp: 0.001379, loss_freq: 0.011509
[16:53:22.902] iteration 13199: loss: 0.057455, loss_s1: 0.026119, loss_fp: 0.001103, loss_freq: 0.025219
[16:53:23.526] iteration 13200: loss: 0.112089, loss_s1: 0.094739, loss_fp: 0.022112, loss_freq: 0.048454
[16:53:27.006] iteration 13200 : mean_dice : 0.722619
[16:53:27.681] iteration 13201: loss: 0.048221, loss_s1: 0.021382, loss_fp: 0.004135, loss_freq: 0.015497
[16:53:28.309] iteration 13202: loss: 0.046124, loss_s1: 0.010374, loss_fp: 0.000777, loss_freq: 0.024864
[16:53:29.288] iteration 13203: loss: 0.051659, loss_s1: 0.037500, loss_fp: 0.004401, loss_freq: 0.010277
[16:53:29.914] iteration 13204: loss: 0.084118, loss_s1: 0.039269, loss_fp: 0.020694, loss_freq: 0.048709
[16:53:30.603] iteration 13205: loss: 0.071164, loss_s1: 0.052417, loss_fp: 0.001494, loss_freq: 0.022951
[16:53:31.281] iteration 13206: loss: 0.042009, loss_s1: 0.013065, loss_fp: 0.000479, loss_freq: 0.022258
[16:53:31.939] iteration 13207: loss: 0.049109, loss_s1: 0.024203, loss_fp: 0.005642, loss_freq: 0.011635
[16:53:32.561] iteration 13208: loss: 0.108994, loss_s1: 0.089022, loss_fp: 0.003886, loss_freq: 0.055027
[16:53:33.186] iteration 13209: loss: 0.049434, loss_s1: 0.039995, loss_fp: 0.005221, loss_freq: 0.011541
[16:53:33.808] iteration 13210: loss: 0.034411, loss_s1: 0.018469, loss_fp: 0.001609, loss_freq: 0.010707
[16:53:34.431] iteration 13211: loss: 0.048852, loss_s1: 0.030556, loss_fp: 0.002212, loss_freq: 0.034365
[16:53:35.054] iteration 13212: loss: 0.078981, loss_s1: 0.053009, loss_fp: 0.002010, loss_freq: 0.055843
[16:53:35.680] iteration 13213: loss: 0.042737, loss_s1: 0.021380, loss_fp: 0.001143, loss_freq: 0.010060
[16:53:36.304] iteration 13214: loss: 0.072336, loss_s1: 0.048263, loss_fp: 0.002995, loss_freq: 0.051229
[16:53:36.927] iteration 13215: loss: 0.078412, loss_s1: 0.055455, loss_fp: 0.007025, loss_freq: 0.051724
[16:53:37.552] iteration 13216: loss: 0.088421, loss_s1: 0.050446, loss_fp: 0.003685, loss_freq: 0.027392
[16:53:38.181] iteration 13217: loss: 0.069421, loss_s1: 0.074684, loss_fp: 0.000343, loss_freq: 0.015591
[16:53:38.810] iteration 13218: loss: 0.084529, loss_s1: 0.041577, loss_fp: 0.001198, loss_freq: 0.081377
[16:53:39.437] iteration 13219: loss: 0.067872, loss_s1: 0.030913, loss_fp: 0.002291, loss_freq: 0.019754
[16:53:40.074] iteration 13220: loss: 0.075099, loss_s1: 0.070874, loss_fp: 0.003367, loss_freq: 0.030742
[16:53:41.035] iteration 13221: loss: 0.068583, loss_s1: 0.052133, loss_fp: 0.002450, loss_freq: 0.026363
[16:53:41.822] iteration 13222: loss: 0.055673, loss_s1: 0.021967, loss_fp: 0.006282, loss_freq: 0.034751
[16:53:42.445] iteration 13223: loss: 0.061270, loss_s1: 0.046363, loss_fp: 0.002139, loss_freq: 0.016359
[16:53:43.069] iteration 13224: loss: 0.059820, loss_s1: 0.037068, loss_fp: 0.005645, loss_freq: 0.019756
[16:53:43.698] iteration 13225: loss: 0.085330, loss_s1: 0.080497, loss_fp: 0.000360, loss_freq: 0.017282
[16:53:44.319] iteration 13226: loss: 0.144296, loss_s1: 0.094356, loss_fp: 0.011466, loss_freq: 0.141185
[16:53:44.948] iteration 13227: loss: 0.038115, loss_s1: 0.020348, loss_fp: 0.002620, loss_freq: 0.020551
[16:53:45.574] iteration 13228: loss: 0.085255, loss_s1: 0.075951, loss_fp: 0.001722, loss_freq: 0.045322
[16:53:46.197] iteration 13229: loss: 0.052665, loss_s1: 0.033150, loss_fp: 0.000991, loss_freq: 0.019737
[16:53:46.821] iteration 13230: loss: 0.121238, loss_s1: 0.113851, loss_fp: 0.007895, loss_freq: 0.064852
[16:53:47.444] iteration 13231: loss: 0.069941, loss_s1: 0.055723, loss_fp: 0.003701, loss_freq: 0.036362
[16:53:48.066] iteration 13232: loss: 0.059575, loss_s1: 0.047245, loss_fp: 0.008460, loss_freq: 0.012373
[16:53:48.691] iteration 13233: loss: 0.057998, loss_s1: 0.059559, loss_fp: 0.001093, loss_freq: 0.020378
[16:53:49.314] iteration 13234: loss: 0.064364, loss_s1: 0.036201, loss_fp: 0.005709, loss_freq: 0.041782
[16:53:49.939] iteration 13235: loss: 0.058462, loss_s1: 0.045462, loss_fp: 0.002211, loss_freq: 0.024534
[16:53:50.563] iteration 13236: loss: 0.050893, loss_s1: 0.047461, loss_fp: 0.001784, loss_freq: 0.012914
[16:53:51.187] iteration 13237: loss: 0.076697, loss_s1: 0.041305, loss_fp: 0.011080, loss_freq: 0.024684
[16:53:51.809] iteration 13238: loss: 0.074622, loss_s1: 0.066486, loss_fp: 0.001932, loss_freq: 0.032241
[16:53:52.432] iteration 13239: loss: 0.084984, loss_s1: 0.043785, loss_fp: 0.004785, loss_freq: 0.067055
[16:53:53.057] iteration 13240: loss: 0.095148, loss_s1: 0.058760, loss_fp: 0.003039, loss_freq: 0.026386
[16:53:53.680] iteration 13241: loss: 0.116709, loss_s1: 0.105680, loss_fp: 0.004462, loss_freq: 0.069778
[16:53:54.303] iteration 13242: loss: 0.082587, loss_s1: 0.055827, loss_fp: 0.006164, loss_freq: 0.061072
[16:53:54.931] iteration 13243: loss: 0.062020, loss_s1: 0.054670, loss_fp: 0.002801, loss_freq: 0.008579
[16:53:55.561] iteration 13244: loss: 0.088963, loss_s1: 0.063658, loss_fp: 0.005168, loss_freq: 0.029825
[16:53:56.188] iteration 13245: loss: 0.073407, loss_s1: 0.038156, loss_fp: 0.003812, loss_freq: 0.058488
[16:53:56.814] iteration 13246: loss: 0.060177, loss_s1: 0.014129, loss_fp: 0.007407, loss_freq: 0.064677
[16:53:57.471] iteration 13247: loss: 0.074536, loss_s1: 0.053346, loss_fp: 0.005309, loss_freq: 0.040363
[16:53:58.157] iteration 13248: loss: 0.039937, loss_s1: 0.029869, loss_fp: 0.004260, loss_freq: 0.005654
[16:53:58.818] iteration 13249: loss: 0.038513, loss_s1: 0.012428, loss_fp: 0.000767, loss_freq: 0.032141
[16:53:59.478] iteration 13250: loss: 0.063398, loss_s1: 0.032923, loss_fp: 0.010224, loss_freq: 0.028504
[16:54:00.138] iteration 13251: loss: 0.054873, loss_s1: 0.048512, loss_fp: 0.003750, loss_freq: 0.013973
[16:54:00.794] iteration 13252: loss: 0.093391, loss_s1: 0.099956, loss_fp: 0.002469, loss_freq: 0.052110
[16:54:01.436] iteration 13253: loss: 0.051662, loss_s1: 0.021397, loss_fp: 0.000239, loss_freq: 0.041023
[16:54:02.093] iteration 13254: loss: 0.080308, loss_s1: 0.038625, loss_fp: 0.000775, loss_freq: 0.018237
[16:54:02.753] iteration 13255: loss: 0.065403, loss_s1: 0.032535, loss_fp: 0.016481, loss_freq: 0.015336
[16:54:03.412] iteration 13256: loss: 0.069704, loss_s1: 0.024896, loss_fp: 0.005287, loss_freq: 0.073550
[16:54:04.071] iteration 13257: loss: 0.038788, loss_s1: 0.026128, loss_fp: 0.001144, loss_freq: 0.009883
[16:54:04.711] iteration 13258: loss: 0.109532, loss_s1: 0.098191, loss_fp: 0.031790, loss_freq: 0.040344
[16:54:05.336] iteration 13259: loss: 0.050863, loss_s1: 0.022349, loss_fp: 0.001477, loss_freq: 0.025511
[16:54:05.962] iteration 13260: loss: 0.066034, loss_s1: 0.054232, loss_fp: 0.000698, loss_freq: 0.007715
[16:54:06.588] iteration 13261: loss: 0.041616, loss_s1: 0.033516, loss_fp: 0.006660, loss_freq: 0.010792
[16:54:07.210] iteration 13262: loss: 0.053841, loss_s1: 0.047025, loss_fp: 0.001108, loss_freq: 0.018204
[16:54:07.833] iteration 13263: loss: 0.042112, loss_s1: 0.026119, loss_fp: 0.001567, loss_freq: 0.011957
[16:54:08.456] iteration 13264: loss: 0.082807, loss_s1: 0.096251, loss_fp: 0.020102, loss_freq: 0.009289
[16:54:09.081] iteration 13265: loss: 0.048187, loss_s1: 0.022038, loss_fp: 0.001493, loss_freq: 0.026032
[16:54:09.730] iteration 13266: loss: 0.080802, loss_s1: 0.061320, loss_fp: 0.003891, loss_freq: 0.035393
[16:54:10.358] iteration 13267: loss: 0.050056, loss_s1: 0.038948, loss_fp: 0.004419, loss_freq: 0.014021
[16:54:10.980] iteration 13268: loss: 0.073613, loss_s1: 0.038427, loss_fp: 0.004338, loss_freq: 0.064886
[16:54:11.630] iteration 13269: loss: 0.056694, loss_s1: 0.040647, loss_fp: 0.001651, loss_freq: 0.024012
[16:54:12.289] iteration 13270: loss: 0.061108, loss_s1: 0.044871, loss_fp: 0.005599, loss_freq: 0.041388
[16:54:12.948] iteration 13271: loss: 0.078931, loss_s1: 0.050942, loss_fp: 0.009663, loss_freq: 0.054990
[16:54:13.578] iteration 13272: loss: 0.072111, loss_s1: 0.039368, loss_fp: 0.001141, loss_freq: 0.033313
[16:54:14.207] iteration 13273: loss: 0.087471, loss_s1: 0.048287, loss_fp: 0.004090, loss_freq: 0.051712
[16:54:14.833] iteration 13274: loss: 0.108957, loss_s1: 0.071304, loss_fp: 0.011140, loss_freq: 0.035662
[16:54:15.492] iteration 13275: loss: 0.060767, loss_s1: 0.029590, loss_fp: 0.001161, loss_freq: 0.031725
[16:54:16.149] iteration 13276: loss: 0.051636, loss_s1: 0.046099, loss_fp: 0.000913, loss_freq: 0.012155
[16:54:16.807] iteration 13277: loss: 0.061417, loss_s1: 0.068232, loss_fp: 0.001276, loss_freq: 0.013719
[16:54:17.467] iteration 13278: loss: 0.072458, loss_s1: 0.044878, loss_fp: 0.001253, loss_freq: 0.026157
[16:54:18.125] iteration 13279: loss: 0.081432, loss_s1: 0.069889, loss_fp: 0.004886, loss_freq: 0.037010
[16:54:18.790] iteration 13280: loss: 0.061479, loss_s1: 0.056494, loss_fp: 0.004520, loss_freq: 0.028051
[16:54:19.419] iteration 13281: loss: 0.050147, loss_s1: 0.018779, loss_fp: 0.001521, loss_freq: 0.015376
[16:54:20.040] iteration 13282: loss: 0.054405, loss_s1: 0.034160, loss_fp: 0.001101, loss_freq: 0.014137
[16:54:20.668] iteration 13283: loss: 0.070185, loss_s1: 0.083589, loss_fp: 0.001993, loss_freq: 0.018862
[16:54:21.290] iteration 13284: loss: 0.064980, loss_s1: 0.056112, loss_fp: 0.020856, loss_freq: 0.019436
[16:54:21.915] iteration 13285: loss: 0.074843, loss_s1: 0.066191, loss_fp: 0.007328, loss_freq: 0.039857
[16:54:22.540] iteration 13286: loss: 0.115797, loss_s1: 0.120721, loss_fp: 0.004956, loss_freq: 0.018855
[16:54:23.164] iteration 13287: loss: 0.103941, loss_s1: 0.079925, loss_fp: 0.002275, loss_freq: 0.089576
[16:54:23.790] iteration 13288: loss: 0.044569, loss_s1: 0.021797, loss_fp: 0.000632, loss_freq: 0.026527
[16:54:24.418] iteration 13289: loss: 0.058132, loss_s1: 0.044822, loss_fp: 0.000721, loss_freq: 0.015693
[16:54:25.047] iteration 13290: loss: 0.049388, loss_s1: 0.034254, loss_fp: 0.002316, loss_freq: 0.012188
[16:54:25.673] iteration 13291: loss: 0.064702, loss_s1: 0.041511, loss_fp: 0.002935, loss_freq: 0.039739
[16:54:26.301] iteration 13292: loss: 0.070279, loss_s1: 0.019672, loss_fp: 0.001469, loss_freq: 0.074651
[16:54:26.925] iteration 13293: loss: 0.050713, loss_s1: 0.034120, loss_fp: 0.005812, loss_freq: 0.013359
[16:54:27.546] iteration 13294: loss: 0.055798, loss_s1: 0.047340, loss_fp: 0.001503, loss_freq: 0.011747
[16:54:28.174] iteration 13295: loss: 0.062697, loss_s1: 0.024138, loss_fp: 0.007871, loss_freq: 0.018245
[16:54:28.834] iteration 13296: loss: 0.037795, loss_s1: 0.021562, loss_fp: 0.000779, loss_freq: 0.013387
[16:54:29.492] iteration 13297: loss: 0.051999, loss_s1: 0.024776, loss_fp: 0.010798, loss_freq: 0.029741
[16:54:30.150] iteration 13298: loss: 0.055716, loss_s1: 0.026336, loss_fp: 0.006638, loss_freq: 0.043216
[16:54:30.809] iteration 13299: loss: 0.064234, loss_s1: 0.028248, loss_fp: 0.000869, loss_freq: 0.031752
[16:54:31.451] iteration 13300: loss: 0.065264, loss_s1: 0.040292, loss_fp: 0.003279, loss_freq: 0.046902
[16:54:32.091] iteration 13301: loss: 0.054008, loss_s1: 0.054740, loss_fp: 0.001883, loss_freq: 0.017796
[16:54:32.714] iteration 13302: loss: 0.077383, loss_s1: 0.063737, loss_fp: 0.006351, loss_freq: 0.044101
[16:54:33.345] iteration 13303: loss: 0.072841, loss_s1: 0.066813, loss_fp: 0.004590, loss_freq: 0.042477
[16:54:33.976] iteration 13304: loss: 0.088185, loss_s1: 0.039331, loss_fp: 0.003605, loss_freq: 0.068034
[16:54:34.600] iteration 13305: loss: 0.068586, loss_s1: 0.035543, loss_fp: 0.007562, loss_freq: 0.046494
[16:54:35.229] iteration 13306: loss: 0.077678, loss_s1: 0.067682, loss_fp: 0.002465, loss_freq: 0.047078
[16:54:35.894] iteration 13307: loss: 0.096588, loss_s1: 0.057949, loss_fp: 0.009987, loss_freq: 0.045411
[16:54:36.557] iteration 13308: loss: 0.063861, loss_s1: 0.018147, loss_fp: 0.015250, loss_freq: 0.042189
[16:54:37.219] iteration 13309: loss: 0.080953, loss_s1: 0.044815, loss_fp: 0.001525, loss_freq: 0.022910
[16:54:37.852] iteration 13310: loss: 0.107173, loss_s1: 0.098017, loss_fp: 0.001477, loss_freq: 0.034422
[16:54:38.481] iteration 13311: loss: 0.153749, loss_s1: 0.117107, loss_fp: 0.015965, loss_freq: 0.119045
[16:54:39.105] iteration 13312: loss: 0.063080, loss_s1: 0.062625, loss_fp: 0.001706, loss_freq: 0.024541
[16:54:39.731] iteration 13313: loss: 0.059347, loss_s1: 0.030801, loss_fp: 0.001010, loss_freq: 0.013787
[16:54:40.353] iteration 13314: loss: 0.070783, loss_s1: 0.041220, loss_fp: 0.003294, loss_freq: 0.058235
[16:54:40.980] iteration 13315: loss: 0.058288, loss_s1: 0.053509, loss_fp: 0.004483, loss_freq: 0.023110
[16:54:41.604] iteration 13316: loss: 0.086051, loss_s1: 0.055456, loss_fp: 0.001650, loss_freq: 0.060170
[16:54:42.230] iteration 13317: loss: 0.026424, loss_s1: 0.005393, loss_fp: 0.003508, loss_freq: 0.003027
[16:54:42.859] iteration 13318: loss: 0.094412, loss_s1: 0.064100, loss_fp: 0.002098, loss_freq: 0.074450
[16:54:43.486] iteration 13319: loss: 0.053260, loss_s1: 0.017287, loss_fp: 0.003381, loss_freq: 0.027193
[16:54:44.110] iteration 13320: loss: 0.062868, loss_s1: 0.040820, loss_fp: 0.009900, loss_freq: 0.026239
[16:54:44.741] iteration 13321: loss: 0.085901, loss_s1: 0.087273, loss_fp: 0.012335, loss_freq: 0.018263
[16:54:45.369] iteration 13322: loss: 0.105608, loss_s1: 0.037332, loss_fp: 0.002510, loss_freq: 0.133328
[16:54:46.023] iteration 13323: loss: 0.076785, loss_s1: 0.024794, loss_fp: 0.002500, loss_freq: 0.087390
[16:54:46.653] iteration 13324: loss: 0.069763, loss_s1: 0.032162, loss_fp: 0.002109, loss_freq: 0.046720
[16:54:47.320] iteration 13325: loss: 0.100699, loss_s1: 0.076118, loss_fp: 0.030539, loss_freq: 0.038837
[16:54:47.961] iteration 13326: loss: 0.093202, loss_s1: 0.030321, loss_fp: 0.002378, loss_freq: 0.022019
[16:54:48.660] iteration 13327: loss: 0.094488, loss_s1: 0.025268, loss_fp: 0.003833, loss_freq: 0.061808
[16:54:49.325] iteration 13328: loss: 0.075024, loss_s1: 0.046515, loss_fp: 0.017111, loss_freq: 0.035475
[16:54:49.991] iteration 13329: loss: 0.060924, loss_s1: 0.012927, loss_fp: 0.000570, loss_freq: 0.013765
[16:54:50.659] iteration 13330: loss: 0.095611, loss_s1: 0.068983, loss_fp: 0.004116, loss_freq: 0.027952
[16:54:51.320] iteration 13331: loss: 0.089561, loss_s1: 0.077231, loss_fp: 0.001174, loss_freq: 0.015879
[16:54:51.982] iteration 13332: loss: 0.044782, loss_s1: 0.021315, loss_fp: 0.001884, loss_freq: 0.018256
[16:54:52.619] iteration 13333: loss: 0.114616, loss_s1: 0.112138, loss_fp: 0.010688, loss_freq: 0.073772
[16:54:53.249] iteration 13334: loss: 0.067380, loss_s1: 0.051862, loss_fp: 0.003069, loss_freq: 0.027877
[16:54:53.885] iteration 13335: loss: 0.055224, loss_s1: 0.042134, loss_fp: 0.006879, loss_freq: 0.011907
[16:54:54.513] iteration 13336: loss: 0.041022, loss_s1: 0.012790, loss_fp: 0.002947, loss_freq: 0.018906
[16:54:55.138] iteration 13337: loss: 0.078948, loss_s1: 0.049491, loss_fp: 0.002985, loss_freq: 0.060148
[16:54:55.767] iteration 13338: loss: 0.066807, loss_s1: 0.077647, loss_fp: 0.006336, loss_freq: 0.016621
[16:54:56.395] iteration 13339: loss: 0.062655, loss_s1: 0.020838, loss_fp: 0.001381, loss_freq: 0.044142
[16:54:57.022] iteration 13340: loss: 0.049701, loss_s1: 0.027621, loss_fp: 0.003786, loss_freq: 0.029309
[16:54:57.649] iteration 13341: loss: 0.054222, loss_s1: 0.035510, loss_fp: 0.004055, loss_freq: 0.030500
[16:54:58.272] iteration 13342: loss: 0.110520, loss_s1: 0.065693, loss_fp: 0.004108, loss_freq: 0.058181
[16:54:58.901] iteration 13343: loss: 0.085537, loss_s1: 0.073503, loss_fp: 0.008061, loss_freq: 0.040808
[16:54:59.527] iteration 13344: loss: 0.061375, loss_s1: 0.046454, loss_fp: 0.000923, loss_freq: 0.029730
[16:55:00.156] iteration 13345: loss: 0.084712, loss_s1: 0.070940, loss_fp: 0.002071, loss_freq: 0.040621
[16:55:00.779] iteration 13346: loss: 0.086268, loss_s1: 0.062441, loss_fp: 0.010782, loss_freq: 0.037861
[16:55:01.429] iteration 13347: loss: 0.036449, loss_s1: 0.017984, loss_fp: 0.001743, loss_freq: 0.012316
[16:55:02.102] iteration 13348: loss: 0.056657, loss_s1: 0.030589, loss_fp: 0.003390, loss_freq: 0.016242
[16:55:02.777] iteration 13349: loss: 0.090361, loss_s1: 0.057029, loss_fp: 0.006129, loss_freq: 0.077510
[16:55:03.422] iteration 13350: loss: 0.066448, loss_s1: 0.053062, loss_fp: 0.001733, loss_freq: 0.018628
[16:55:04.065] iteration 13351: loss: 0.065059, loss_s1: 0.037004, loss_fp: 0.005409, loss_freq: 0.040938
[16:55:04.706] iteration 13352: loss: 0.140061, loss_s1: 0.116968, loss_fp: 0.004363, loss_freq: 0.101898
[16:55:05.348] iteration 13353: loss: 0.070108, loss_s1: 0.040605, loss_fp: 0.000490, loss_freq: 0.029431
[16:55:05.987] iteration 13354: loss: 0.109611, loss_s1: 0.067148, loss_fp: 0.007180, loss_freq: 0.078910
[16:55:06.629] iteration 13355: loss: 0.059437, loss_s1: 0.050376, loss_fp: 0.002246, loss_freq: 0.021457
[16:55:07.272] iteration 13356: loss: 0.057114, loss_s1: 0.045715, loss_fp: 0.004733, loss_freq: 0.013897
[16:55:07.915] iteration 13357: loss: 0.049192, loss_s1: 0.034296, loss_fp: 0.001942, loss_freq: 0.006585
[16:55:08.555] iteration 13358: loss: 0.066942, loss_s1: 0.030649, loss_fp: 0.003642, loss_freq: 0.024681
[16:55:09.197] iteration 13359: loss: 0.045297, loss_s1: 0.018030, loss_fp: 0.000402, loss_freq: 0.019779
[16:55:09.838] iteration 13360: loss: 0.070743, loss_s1: 0.043952, loss_fp: 0.002094, loss_freq: 0.047430
[16:55:10.480] iteration 13361: loss: 0.061271, loss_s1: 0.046479, loss_fp: 0.007338, loss_freq: 0.027271
[16:55:11.098] iteration 13362: loss: 0.051201, loss_s1: 0.041378, loss_fp: 0.006795, loss_freq: 0.010962
[16:55:11.722] iteration 13363: loss: 0.069132, loss_s1: 0.039566, loss_fp: 0.001382, loss_freq: 0.044632
[16:55:12.765] iteration 13364: loss: 0.092904, loss_s1: 0.065194, loss_fp: 0.000141, loss_freq: 0.010996
[16:55:13.429] iteration 13365: loss: 0.065950, loss_s1: 0.054594, loss_fp: 0.000208, loss_freq: 0.031286
[16:55:14.122] iteration 13366: loss: 0.076893, loss_s1: 0.074988, loss_fp: 0.002347, loss_freq: 0.015078
[16:55:14.780] iteration 13367: loss: 0.076498, loss_s1: 0.027073, loss_fp: 0.004907, loss_freq: 0.024244
[16:55:15.444] iteration 13368: loss: 0.061447, loss_s1: 0.069865, loss_fp: 0.002514, loss_freq: 0.011935
[16:55:16.099] iteration 13369: loss: 0.126974, loss_s1: 0.123825, loss_fp: 0.003618, loss_freq: 0.067078
[16:55:16.759] iteration 13370: loss: 0.050901, loss_s1: 0.037998, loss_fp: 0.001729, loss_freq: 0.021527
[16:55:17.392] iteration 13371: loss: 0.036378, loss_s1: 0.021273, loss_fp: 0.000937, loss_freq: 0.016308
[16:55:18.021] iteration 13372: loss: 0.091821, loss_s1: 0.074350, loss_fp: 0.026018, loss_freq: 0.024766
[16:55:18.651] iteration 13373: loss: 0.091940, loss_s1: 0.089566, loss_fp: 0.017894, loss_freq: 0.026534
[16:55:19.277] iteration 13374: loss: 0.046659, loss_s1: 0.032145, loss_fp: 0.002037, loss_freq: 0.012999
[16:55:19.908] iteration 13375: loss: 0.084387, loss_s1: 0.044663, loss_fp: 0.001500, loss_freq: 0.063576
[16:55:20.535] iteration 13376: loss: 0.062922, loss_s1: 0.049119, loss_fp: 0.002733, loss_freq: 0.034321
[16:55:21.164] iteration 13377: loss: 0.066827, loss_s1: 0.027740, loss_fp: 0.001381, loss_freq: 0.039033
[16:55:21.791] iteration 13378: loss: 0.059369, loss_s1: 0.049935, loss_fp: 0.005133, loss_freq: 0.025656
[16:55:22.417] iteration 13379: loss: 0.120531, loss_s1: 0.110587, loss_fp: 0.015664, loss_freq: 0.069026
[16:55:23.040] iteration 13380: loss: 0.112809, loss_s1: 0.067611, loss_fp: 0.003157, loss_freq: 0.009603
[16:55:23.668] iteration 13381: loss: 0.056860, loss_s1: 0.047469, loss_fp: 0.005635, loss_freq: 0.013142
[16:55:24.292] iteration 13382: loss: 0.069319, loss_s1: 0.060239, loss_fp: 0.002102, loss_freq: 0.033249
[16:55:24.922] iteration 13383: loss: 0.047549, loss_s1: 0.023934, loss_fp: 0.002369, loss_freq: 0.012652
[16:55:25.550] iteration 13384: loss: 0.049968, loss_s1: 0.030811, loss_fp: 0.009555, loss_freq: 0.012388
[16:55:26.178] iteration 13385: loss: 0.045283, loss_s1: 0.024136, loss_fp: 0.000667, loss_freq: 0.013008
[16:55:26.804] iteration 13386: loss: 0.084648, loss_s1: 0.053208, loss_fp: 0.014173, loss_freq: 0.011745
[16:55:27.429] iteration 13387: loss: 0.127738, loss_s1: 0.078537, loss_fp: 0.001619, loss_freq: 0.128084
[16:55:28.053] iteration 13388: loss: 0.052629, loss_s1: 0.030820, loss_fp: 0.001346, loss_freq: 0.025827
[16:55:28.678] iteration 13389: loss: 0.071219, loss_s1: 0.043950, loss_fp: 0.002030, loss_freq: 0.061488
[16:55:29.299] iteration 13390: loss: 0.048380, loss_s1: 0.050578, loss_fp: 0.001310, loss_freq: 0.007997
[16:55:29.922] iteration 13391: loss: 0.076147, loss_s1: 0.045048, loss_fp: 0.001538, loss_freq: 0.055847
[16:55:30.547] iteration 13392: loss: 0.061576, loss_s1: 0.056076, loss_fp: 0.010272, loss_freq: 0.022698
[16:55:31.172] iteration 13393: loss: 0.057417, loss_s1: 0.051778, loss_fp: 0.003615, loss_freq: 0.010385
[16:55:31.797] iteration 13394: loss: 0.068022, loss_s1: 0.039756, loss_fp: 0.003124, loss_freq: 0.018957
[16:55:32.419] iteration 13395: loss: 0.054336, loss_s1: 0.029942, loss_fp: 0.004204, loss_freq: 0.019965
[16:55:33.045] iteration 13396: loss: 0.072632, loss_s1: 0.073495, loss_fp: 0.000924, loss_freq: 0.024444
[16:55:33.669] iteration 13397: loss: 0.047107, loss_s1: 0.037647, loss_fp: 0.000424, loss_freq: 0.016121
[16:55:34.295] iteration 13398: loss: 0.074387, loss_s1: 0.026568, loss_fp: 0.006054, loss_freq: 0.035867
[16:55:34.923] iteration 13399: loss: 0.070667, loss_s1: 0.058710, loss_fp: 0.008339, loss_freq: 0.016458
[16:55:35.551] iteration 13400: loss: 0.109024, loss_s1: 0.131199, loss_fp: 0.008768, loss_freq: 0.030474
[16:55:38.728] iteration 13400 : mean_dice : 0.723009
[16:55:39.403] iteration 13401: loss: 0.075233, loss_s1: 0.076113, loss_fp: 0.001262, loss_freq: 0.027085
[16:55:40.032] iteration 13402: loss: 0.079857, loss_s1: 0.058127, loss_fp: 0.001134, loss_freq: 0.051905
[16:55:40.661] iteration 13403: loss: 0.139707, loss_s1: 0.108917, loss_fp: 0.008102, loss_freq: 0.049778
[16:55:41.286] iteration 13404: loss: 0.052210, loss_s1: 0.021786, loss_fp: 0.005012, loss_freq: 0.016395
[16:55:41.920] iteration 13405: loss: 0.081990, loss_s1: 0.067431, loss_fp: 0.001507, loss_freq: 0.059687
[16:55:42.563] iteration 13406: loss: 0.050719, loss_s1: 0.023406, loss_fp: 0.001160, loss_freq: 0.043984
[16:55:43.264] iteration 13407: loss: 0.061574, loss_s1: 0.025204, loss_fp: 0.001951, loss_freq: 0.045381
[16:55:43.900] iteration 13408: loss: 0.057393, loss_s1: 0.026578, loss_fp: 0.005099, loss_freq: 0.030816
[16:55:44.550] iteration 13409: loss: 0.048436, loss_s1: 0.032347, loss_fp: 0.004113, loss_freq: 0.005277
[16:55:45.189] iteration 13410: loss: 0.040058, loss_s1: 0.029058, loss_fp: 0.001248, loss_freq: 0.015409
[16:55:45.831] iteration 13411: loss: 0.061270, loss_s1: 0.052205, loss_fp: 0.009890, loss_freq: 0.027403
[16:55:46.468] iteration 13412: loss: 0.060339, loss_s1: 0.068604, loss_fp: 0.003573, loss_freq: 0.007823
[16:55:47.115] iteration 13413: loss: 0.079015, loss_s1: 0.058049, loss_fp: 0.006708, loss_freq: 0.041996
[16:55:47.746] iteration 13414: loss: 0.066209, loss_s1: 0.072890, loss_fp: 0.002007, loss_freq: 0.022773
[16:55:48.367] iteration 13415: loss: 0.054858, loss_s1: 0.010921, loss_fp: 0.007157, loss_freq: 0.011933
[16:55:48.990] iteration 13416: loss: 0.045184, loss_s1: 0.024293, loss_fp: 0.002492, loss_freq: 0.019436
[16:55:49.611] iteration 13417: loss: 0.064456, loss_s1: 0.038536, loss_fp: 0.001889, loss_freq: 0.033656
[16:55:50.235] iteration 13418: loss: 0.056973, loss_s1: 0.041313, loss_fp: 0.001400, loss_freq: 0.015117
[16:55:50.862] iteration 13419: loss: 0.081979, loss_s1: 0.086496, loss_fp: 0.001510, loss_freq: 0.028262
[16:55:51.477] iteration 13420: loss: 0.036597, loss_s1: 0.007819, loss_fp: 0.001082, loss_freq: 0.009785
[16:55:52.130] iteration 13421: loss: 0.078445, loss_s1: 0.058675, loss_fp: 0.006598, loss_freq: 0.021014
[16:55:52.792] iteration 13422: loss: 0.030947, loss_s1: 0.016870, loss_fp: 0.001650, loss_freq: 0.008828
[16:55:53.469] iteration 13423: loss: 0.043528, loss_s1: 0.029919, loss_fp: 0.000555, loss_freq: 0.023241
[16:55:54.147] iteration 13424: loss: 0.043463, loss_s1: 0.045013, loss_fp: 0.001125, loss_freq: 0.012120
[16:55:54.800] iteration 13425: loss: 0.058550, loss_s1: 0.018645, loss_fp: 0.007507, loss_freq: 0.043328
[16:55:55.440] iteration 13426: loss: 0.056987, loss_s1: 0.041673, loss_fp: 0.005570, loss_freq: 0.016347
[16:55:56.069] iteration 13427: loss: 0.045260, loss_s1: 0.039864, loss_fp: 0.004911, loss_freq: 0.012093
[16:55:56.707] iteration 13428: loss: 0.059004, loss_s1: 0.059726, loss_fp: 0.002311, loss_freq: 0.016868
[16:55:57.351] iteration 13429: loss: 0.076256, loss_s1: 0.050145, loss_fp: 0.004700, loss_freq: 0.054008
[16:55:57.991] iteration 13430: loss: 0.072141, loss_s1: 0.035110, loss_fp: 0.004530, loss_freq: 0.056766
[16:55:58.631] iteration 13431: loss: 0.081624, loss_s1: 0.073703, loss_fp: 0.002462, loss_freq: 0.041875
[16:55:59.270] iteration 13432: loss: 0.040081, loss_s1: 0.031398, loss_fp: 0.001523, loss_freq: 0.007434
[16:55:59.919] iteration 13433: loss: 0.056075, loss_s1: 0.032180, loss_fp: 0.003369, loss_freq: 0.025317
[16:56:00.562] iteration 13434: loss: 0.070297, loss_s1: 0.027810, loss_fp: 0.006016, loss_freq: 0.044948
[16:56:01.203] iteration 13435: loss: 0.054136, loss_s1: 0.019890, loss_fp: 0.002366, loss_freq: 0.035391
[16:56:01.841] iteration 13436: loss: 0.066569, loss_s1: 0.044369, loss_fp: 0.008680, loss_freq: 0.023590
[16:56:02.463] iteration 13437: loss: 0.055782, loss_s1: 0.058651, loss_fp: 0.000752, loss_freq: 0.011381
[16:56:03.125] iteration 13438: loss: 0.120155, loss_s1: 0.108934, loss_fp: 0.025783, loss_freq: 0.068386
[16:56:03.783] iteration 13439: loss: 0.076919, loss_s1: 0.055003, loss_fp: 0.004602, loss_freq: 0.027494
[16:56:04.440] iteration 13440: loss: 0.073258, loss_s1: 0.053022, loss_fp: 0.004280, loss_freq: 0.057048
[16:56:05.067] iteration 13441: loss: 0.057764, loss_s1: 0.059164, loss_fp: 0.001393, loss_freq: 0.020280
[16:56:05.690] iteration 13442: loss: 0.046482, loss_s1: 0.008856, loss_fp: 0.005292, loss_freq: 0.028880
[16:56:06.314] iteration 13443: loss: 0.069906, loss_s1: 0.056594, loss_fp: 0.004011, loss_freq: 0.034664
[16:56:06.935] iteration 13444: loss: 0.063337, loss_s1: 0.025867, loss_fp: 0.007154, loss_freq: 0.050398
[16:56:07.558] iteration 13445: loss: 0.083519, loss_s1: 0.070950, loss_fp: 0.005570, loss_freq: 0.057758
[16:56:08.184] iteration 13446: loss: 0.128653, loss_s1: 0.070170, loss_fp: 0.014857, loss_freq: 0.138332
[16:56:08.810] iteration 13447: loss: 0.067510, loss_s1: 0.041875, loss_fp: 0.004652, loss_freq: 0.046837
[16:56:09.437] iteration 13448: loss: 0.068237, loss_s1: 0.028792, loss_fp: 0.015215, loss_freq: 0.056582
[16:56:10.066] iteration 13449: loss: 0.060556, loss_s1: 0.064268, loss_fp: 0.003611, loss_freq: 0.015168
[16:56:10.695] iteration 13450: loss: 0.082287, loss_s1: 0.103645, loss_fp: 0.003245, loss_freq: 0.005987
[16:56:11.321] iteration 13451: loss: 0.072490, loss_s1: 0.069480, loss_fp: 0.001752, loss_freq: 0.020308
[16:56:11.941] iteration 13452: loss: 0.097082, loss_s1: 0.093363, loss_fp: 0.003700, loss_freq: 0.047899
[16:56:12.561] iteration 13453: loss: 0.090534, loss_s1: 0.082373, loss_fp: 0.000790, loss_freq: 0.038237
[16:56:13.185] iteration 13454: loss: 0.083600, loss_s1: 0.055824, loss_fp: 0.003602, loss_freq: 0.016550
[16:56:13.821] iteration 13455: loss: 0.091065, loss_s1: 0.062068, loss_fp: 0.008955, loss_freq: 0.023163
[16:56:14.444] iteration 13456: loss: 0.110836, loss_s1: 0.041220, loss_fp: 0.002806, loss_freq: 0.028169
[16:56:15.066] iteration 13457: loss: 0.053284, loss_s1: 0.040891, loss_fp: 0.003054, loss_freq: 0.007156
[16:56:15.689] iteration 13458: loss: 0.071916, loss_s1: 0.061824, loss_fp: 0.000378, loss_freq: 0.039412
[16:56:16.311] iteration 13459: loss: 0.058582, loss_s1: 0.033564, loss_fp: 0.002970, loss_freq: 0.036523
[16:56:16.933] iteration 13460: loss: 0.074392, loss_s1: 0.042201, loss_fp: 0.002434, loss_freq: 0.047338
[16:56:17.554] iteration 13461: loss: 0.059126, loss_s1: 0.022526, loss_fp: 0.001072, loss_freq: 0.026560
[16:56:18.175] iteration 13462: loss: 0.079032, loss_s1: 0.084960, loss_fp: 0.005717, loss_freq: 0.026300
[16:56:18.829] iteration 13463: loss: 0.052350, loss_s1: 0.031457, loss_fp: 0.014284, loss_freq: 0.015466
[16:56:19.484] iteration 13464: loss: 0.069665, loss_s1: 0.062720, loss_fp: 0.006125, loss_freq: 0.032848
[16:56:20.135] iteration 13465: loss: 0.094148, loss_s1: 0.063745, loss_fp: 0.001261, loss_freq: 0.059876
[16:56:20.789] iteration 13466: loss: 0.076877, loss_s1: 0.069629, loss_fp: 0.002883, loss_freq: 0.034789
[16:56:21.412] iteration 13467: loss: 0.084138, loss_s1: 0.040676, loss_fp: 0.006599, loss_freq: 0.082058
[16:56:22.038] iteration 13468: loss: 0.086342, loss_s1: 0.067895, loss_fp: 0.003200, loss_freq: 0.021523
[16:56:22.657] iteration 13469: loss: 0.052806, loss_s1: 0.022167, loss_fp: 0.001592, loss_freq: 0.033261
[16:56:23.278] iteration 13470: loss: 0.101959, loss_s1: 0.054506, loss_fp: 0.002558, loss_freq: 0.020645
[16:56:23.900] iteration 13471: loss: 0.090641, loss_s1: 0.085326, loss_fp: 0.003454, loss_freq: 0.030085
[16:56:24.523] iteration 13472: loss: 0.149271, loss_s1: 0.074698, loss_fp: 0.016914, loss_freq: 0.120421
[16:56:25.143] iteration 13473: loss: 0.078848, loss_s1: 0.055636, loss_fp: 0.003480, loss_freq: 0.021539
[16:56:25.763] iteration 13474: loss: 0.071845, loss_s1: 0.029182, loss_fp: 0.004429, loss_freq: 0.037171
[16:56:26.385] iteration 13475: loss: 0.087268, loss_s1: 0.081057, loss_fp: 0.003262, loss_freq: 0.045431
[16:56:27.009] iteration 13476: loss: 0.091019, loss_s1: 0.069488, loss_fp: 0.011555, loss_freq: 0.060576
[16:56:27.632] iteration 13477: loss: 0.062302, loss_s1: 0.046462, loss_fp: 0.002000, loss_freq: 0.021528
[16:56:28.260] iteration 13478: loss: 0.045171, loss_s1: 0.028405, loss_fp: 0.001671, loss_freq: 0.014711
[16:56:28.886] iteration 13479: loss: 0.163613, loss_s1: 0.120056, loss_fp: 0.013835, loss_freq: 0.047012
[16:56:29.507] iteration 13480: loss: 0.039945, loss_s1: 0.020697, loss_fp: 0.005417, loss_freq: 0.009145
[16:56:30.130] iteration 13481: loss: 0.054491, loss_s1: 0.047591, loss_fp: 0.001992, loss_freq: 0.011211
[16:56:30.755] iteration 13482: loss: 0.072301, loss_s1: 0.049128, loss_fp: 0.021158, loss_freq: 0.020822
[16:56:31.376] iteration 13483: loss: 0.085043, loss_s1: 0.036443, loss_fp: 0.003093, loss_freq: 0.085562
[16:56:32.000] iteration 13484: loss: 0.039104, loss_s1: 0.024325, loss_fp: 0.000926, loss_freq: 0.008789
[16:56:32.624] iteration 13485: loss: 0.070897, loss_s1: 0.045841, loss_fp: 0.014314, loss_freq: 0.004746
[16:56:33.247] iteration 13486: loss: 0.060796, loss_s1: 0.045921, loss_fp: 0.005406, loss_freq: 0.009225
[16:56:33.874] iteration 13487: loss: 0.075044, loss_s1: 0.032447, loss_fp: 0.009338, loss_freq: 0.044454
[16:56:34.500] iteration 13488: loss: 0.078700, loss_s1: 0.037332, loss_fp: 0.001119, loss_freq: 0.038038
[16:56:35.117] iteration 13489: loss: 0.084122, loss_s1: 0.033460, loss_fp: 0.002340, loss_freq: 0.061220
[16:56:35.739] iteration 13490: loss: 0.074656, loss_s1: 0.059985, loss_fp: 0.003694, loss_freq: 0.023341
[16:56:36.364] iteration 13491: loss: 0.135484, loss_s1: 0.080161, loss_fp: 0.002104, loss_freq: 0.085850
[16:56:36.983] iteration 13492: loss: 0.077734, loss_s1: 0.055094, loss_fp: 0.000618, loss_freq: 0.042959
[16:56:37.608] iteration 13493: loss: 0.075403, loss_s1: 0.048070, loss_fp: 0.001727, loss_freq: 0.011635
[16:56:38.237] iteration 13494: loss: 0.119432, loss_s1: 0.108271, loss_fp: 0.013645, loss_freq: 0.081751
[16:56:38.862] iteration 13495: loss: 0.074335, loss_s1: 0.078974, loss_fp: 0.000460, loss_freq: 0.016882
[16:56:39.489] iteration 13496: loss: 0.109859, loss_s1: 0.076727, loss_fp: 0.002679, loss_freq: 0.051586
[16:56:40.114] iteration 13497: loss: 0.063637, loss_s1: 0.048443, loss_fp: 0.001701, loss_freq: 0.025543
[16:56:40.739] iteration 13498: loss: 0.112218, loss_s1: 0.073845, loss_fp: 0.003679, loss_freq: 0.092070
[16:56:41.362] iteration 13499: loss: 0.051338, loss_s1: 0.046141, loss_fp: 0.001732, loss_freq: 0.015265
[16:56:41.985] iteration 13500: loss: 0.050736, loss_s1: 0.025556, loss_fp: 0.002435, loss_freq: 0.022943
[16:56:42.617] iteration 13501: loss: 0.050243, loss_s1: 0.030121, loss_fp: 0.005655, loss_freq: 0.021333
[16:56:43.240] iteration 13502: loss: 0.060007, loss_s1: 0.045466, loss_fp: 0.000684, loss_freq: 0.021487
[16:56:43.865] iteration 13503: loss: 0.121580, loss_s1: 0.085654, loss_fp: 0.005501, loss_freq: 0.029743
[16:56:44.487] iteration 13504: loss: 0.044282, loss_s1: 0.022532, loss_fp: 0.001894, loss_freq: 0.022489
[16:56:45.109] iteration 13505: loss: 0.101391, loss_s1: 0.075970, loss_fp: 0.044768, loss_freq: 0.035068
[16:56:45.730] iteration 13506: loss: 0.150739, loss_s1: 0.109046, loss_fp: 0.007845, loss_freq: 0.058265
[16:56:46.387] iteration 13507: loss: 0.060800, loss_s1: 0.051378, loss_fp: 0.002966, loss_freq: 0.025416
[16:56:47.045] iteration 13508: loss: 0.053027, loss_s1: 0.044937, loss_fp: 0.001632, loss_freq: 0.019107
[16:56:47.699] iteration 13509: loss: 0.082137, loss_s1: 0.070566, loss_fp: 0.001715, loss_freq: 0.016770
[16:56:48.354] iteration 13510: loss: 0.111327, loss_s1: 0.086581, loss_fp: 0.001860, loss_freq: 0.094604
[16:56:49.013] iteration 13511: loss: 0.092119, loss_s1: 0.081966, loss_fp: 0.003019, loss_freq: 0.019029
[16:56:49.664] iteration 13512: loss: 0.061362, loss_s1: 0.019495, loss_fp: 0.004794, loss_freq: 0.026654
[16:56:50.285] iteration 13513: loss: 0.096998, loss_s1: 0.049900, loss_fp: 0.001745, loss_freq: 0.070490
[16:56:50.974] iteration 13514: loss: 0.119415, loss_s1: 0.084337, loss_fp: 0.002598, loss_freq: 0.064451
[16:56:51.638] iteration 13515: loss: 0.102645, loss_s1: 0.091571, loss_fp: 0.003208, loss_freq: 0.069940
[16:56:52.294] iteration 13516: loss: 0.053427, loss_s1: 0.042737, loss_fp: 0.003022, loss_freq: 0.023799
[16:56:52.950] iteration 13517: loss: 0.109868, loss_s1: 0.056241, loss_fp: 0.000825, loss_freq: 0.014621
[16:56:53.574] iteration 13518: loss: 0.032987, loss_s1: 0.017735, loss_fp: 0.004210, loss_freq: 0.006076
[16:56:54.201] iteration 13519: loss: 0.066730, loss_s1: 0.023799, loss_fp: 0.000603, loss_freq: 0.024269
[16:56:54.826] iteration 13520: loss: 0.071940, loss_s1: 0.025778, loss_fp: 0.001042, loss_freq: 0.019949
[16:56:55.451] iteration 13521: loss: 0.068516, loss_s1: 0.045536, loss_fp: 0.008468, loss_freq: 0.043041
[16:56:56.077] iteration 13522: loss: 0.069412, loss_s1: 0.048705, loss_fp: 0.014603, loss_freq: 0.032479
[16:56:56.700] iteration 13523: loss: 0.068494, loss_s1: 0.047294, loss_fp: 0.002297, loss_freq: 0.009551
[16:56:57.323] iteration 13524: loss: 0.051501, loss_s1: 0.024749, loss_fp: 0.001183, loss_freq: 0.030442
[16:56:58.265] iteration 13525: loss: 0.064353, loss_s1: 0.066135, loss_fp: 0.003268, loss_freq: 0.016566
[16:56:58.901] iteration 13526: loss: 0.061881, loss_s1: 0.059632, loss_fp: 0.002975, loss_freq: 0.014037
[16:56:59.528] iteration 13527: loss: 0.053494, loss_s1: 0.012659, loss_fp: 0.003264, loss_freq: 0.022326
[16:57:00.153] iteration 13528: loss: 0.048058, loss_s1: 0.024523, loss_fp: 0.000207, loss_freq: 0.010053
[16:57:00.777] iteration 13529: loss: 0.059389, loss_s1: 0.049428, loss_fp: 0.011184, loss_freq: 0.020126
[16:57:01.400] iteration 13530: loss: 0.158011, loss_s1: 0.115446, loss_fp: 0.001621, loss_freq: 0.088929
[16:57:02.029] iteration 13531: loss: 0.047223, loss_s1: 0.021363, loss_fp: 0.004392, loss_freq: 0.029941
[16:57:02.686] iteration 13532: loss: 0.048233, loss_s1: 0.025145, loss_fp: 0.000821, loss_freq: 0.019475
[16:57:03.342] iteration 13533: loss: 0.044225, loss_s1: 0.032043, loss_fp: 0.001058, loss_freq: 0.014205
[16:57:03.997] iteration 13534: loss: 0.098098, loss_s1: 0.090982, loss_fp: 0.001923, loss_freq: 0.054193
[16:57:04.654] iteration 13535: loss: 0.060522, loss_s1: 0.022924, loss_fp: 0.002910, loss_freq: 0.034241
[16:57:05.311] iteration 13536: loss: 0.098061, loss_s1: 0.062371, loss_fp: 0.004468, loss_freq: 0.055532
[16:57:05.965] iteration 13537: loss: 0.084205, loss_s1: 0.057642, loss_fp: 0.001733, loss_freq: 0.057401
[16:57:06.616] iteration 13538: loss: 0.067353, loss_s1: 0.028122, loss_fp: 0.007492, loss_freq: 0.036503
[16:57:07.246] iteration 13539: loss: 0.052308, loss_s1: 0.039079, loss_fp: 0.001130, loss_freq: 0.027468
[16:57:07.868] iteration 13540: loss: 0.113248, loss_s1: 0.050750, loss_fp: 0.001650, loss_freq: 0.124577
[16:57:08.491] iteration 13541: loss: 0.067807, loss_s1: 0.036805, loss_fp: 0.004775, loss_freq: 0.032788
[16:57:09.112] iteration 13542: loss: 0.051088, loss_s1: 0.041809, loss_fp: 0.002133, loss_freq: 0.015873
[16:57:09.736] iteration 13543: loss: 0.078524, loss_s1: 0.040633, loss_fp: 0.001477, loss_freq: 0.038960
[16:57:10.359] iteration 13544: loss: 0.116276, loss_s1: 0.029188, loss_fp: 0.000694, loss_freq: 0.015722
[16:57:10.982] iteration 13545: loss: 0.045602, loss_s1: 0.010096, loss_fp: 0.001293, loss_freq: 0.020256
[16:57:11.606] iteration 13546: loss: 0.080440, loss_s1: 0.061880, loss_fp: 0.004141, loss_freq: 0.035465
[16:57:12.233] iteration 13547: loss: 0.061561, loss_s1: 0.033375, loss_fp: 0.003903, loss_freq: 0.019776
[16:57:12.856] iteration 13548: loss: 0.194958, loss_s1: 0.148560, loss_fp: 0.004047, loss_freq: 0.174595
[16:57:13.479] iteration 13549: loss: 0.047002, loss_s1: 0.035774, loss_fp: 0.001498, loss_freq: 0.012338
[16:57:14.100] iteration 13550: loss: 0.058157, loss_s1: 0.030117, loss_fp: 0.001792, loss_freq: 0.045299
[16:57:14.726] iteration 13551: loss: 0.038435, loss_s1: 0.019578, loss_fp: 0.001590, loss_freq: 0.013333
[16:57:15.350] iteration 13552: loss: 0.120799, loss_s1: 0.083514, loss_fp: 0.016507, loss_freq: 0.070468
[16:57:15.972] iteration 13553: loss: 0.049377, loss_s1: 0.015479, loss_fp: 0.002373, loss_freq: 0.034772
[16:57:16.593] iteration 13554: loss: 0.042274, loss_s1: 0.019343, loss_fp: 0.002248, loss_freq: 0.010746
[16:57:17.215] iteration 13555: loss: 0.050378, loss_s1: 0.044135, loss_fp: 0.003704, loss_freq: 0.016424
[16:57:17.838] iteration 13556: loss: 0.053366, loss_s1: 0.037827, loss_fp: 0.008620, loss_freq: 0.016619
[16:57:18.463] iteration 13557: loss: 0.084534, loss_s1: 0.054673, loss_fp: 0.001167, loss_freq: 0.055801
[16:57:19.086] iteration 13558: loss: 0.049608, loss_s1: 0.034179, loss_fp: 0.009683, loss_freq: 0.007417
[16:57:19.737] iteration 13559: loss: 0.092110, loss_s1: 0.066683, loss_fp: 0.005140, loss_freq: 0.034550
[16:57:20.404] iteration 13560: loss: 0.098425, loss_s1: 0.074402, loss_fp: 0.013696, loss_freq: 0.068712
[16:57:21.059] iteration 13561: loss: 0.087840, loss_s1: 0.066512, loss_fp: 0.011071, loss_freq: 0.032597
[16:57:21.717] iteration 13562: loss: 0.078140, loss_s1: 0.064371, loss_fp: 0.014751, loss_freq: 0.030590
[16:57:22.380] iteration 13563: loss: 0.092253, loss_s1: 0.074095, loss_fp: 0.000423, loss_freq: 0.053047
[16:57:23.004] iteration 13564: loss: 0.075704, loss_s1: 0.059484, loss_fp: 0.002019, loss_freq: 0.031637
[16:57:23.628] iteration 13565: loss: 0.066555, loss_s1: 0.017078, loss_fp: 0.020407, loss_freq: 0.046663
[16:57:24.252] iteration 13566: loss: 0.112141, loss_s1: 0.106880, loss_fp: 0.005863, loss_freq: 0.070291
[16:57:24.876] iteration 13567: loss: 0.076194, loss_s1: 0.052546, loss_fp: 0.006571, loss_freq: 0.039011
[16:57:25.499] iteration 13568: loss: 0.089759, loss_s1: 0.061599, loss_fp: 0.001743, loss_freq: 0.044013
[16:57:26.125] iteration 13569: loss: 0.084202, loss_s1: 0.059810, loss_fp: 0.001248, loss_freq: 0.060425
[16:57:26.748] iteration 13570: loss: 0.054071, loss_s1: 0.023515, loss_fp: 0.002844, loss_freq: 0.012653
[16:57:27.372] iteration 13571: loss: 0.039596, loss_s1: 0.023466, loss_fp: 0.002780, loss_freq: 0.003110
[16:57:27.995] iteration 13572: loss: 0.045041, loss_s1: 0.029308, loss_fp: 0.001898, loss_freq: 0.021488
[16:57:28.619] iteration 13573: loss: 0.075153, loss_s1: 0.053937, loss_fp: 0.002135, loss_freq: 0.044737
[16:57:29.243] iteration 13574: loss: 0.125314, loss_s1: 0.079132, loss_fp: 0.008947, loss_freq: 0.101245
[16:57:29.867] iteration 13575: loss: 0.066435, loss_s1: 0.040992, loss_fp: 0.004385, loss_freq: 0.041109
[16:57:30.491] iteration 13576: loss: 0.057490, loss_s1: 0.034851, loss_fp: 0.000622, loss_freq: 0.015138
[16:57:31.117] iteration 13577: loss: 0.070848, loss_s1: 0.045549, loss_fp: 0.004618, loss_freq: 0.025391
[16:57:31.742] iteration 13578: loss: 0.064779, loss_s1: 0.046412, loss_fp: 0.001552, loss_freq: 0.026104
[16:57:32.370] iteration 13579: loss: 0.055557, loss_s1: 0.025018, loss_fp: 0.001196, loss_freq: 0.022626
[16:57:32.996] iteration 13580: loss: 0.115842, loss_s1: 0.076704, loss_fp: 0.004475, loss_freq: 0.047229
[16:57:33.623] iteration 13581: loss: 0.061462, loss_s1: 0.032715, loss_fp: 0.002785, loss_freq: 0.005970
[16:57:34.260] iteration 13582: loss: 0.059652, loss_s1: 0.032203, loss_fp: 0.000592, loss_freq: 0.021382
[16:57:34.887] iteration 13583: loss: 0.041527, loss_s1: 0.031529, loss_fp: 0.006148, loss_freq: 0.008314
[16:57:35.515] iteration 13584: loss: 0.040384, loss_s1: 0.010844, loss_fp: 0.002085, loss_freq: 0.012786
[16:57:36.178] iteration 13585: loss: 0.047981, loss_s1: 0.024055, loss_fp: 0.004753, loss_freq: 0.028062
[16:57:36.844] iteration 13586: loss: 0.070642, loss_s1: 0.051942, loss_fp: 0.004240, loss_freq: 0.014230
[16:57:37.514] iteration 13587: loss: 0.061837, loss_s1: 0.043593, loss_fp: 0.000872, loss_freq: 0.019098
[16:57:38.142] iteration 13588: loss: 0.073935, loss_s1: 0.062162, loss_fp: 0.001214, loss_freq: 0.030173
[16:57:38.772] iteration 13589: loss: 0.053440, loss_s1: 0.058494, loss_fp: 0.001800, loss_freq: 0.010408
[16:57:39.401] iteration 13590: loss: 0.062431, loss_s1: 0.030707, loss_fp: 0.001488, loss_freq: 0.054267
[16:57:40.032] iteration 13591: loss: 0.076336, loss_s1: 0.065558, loss_fp: 0.003054, loss_freq: 0.025256
[16:57:40.661] iteration 13592: loss: 0.079685, loss_s1: 0.089045, loss_fp: 0.003903, loss_freq: 0.031575
[16:57:41.287] iteration 13593: loss: 0.044300, loss_s1: 0.033355, loss_fp: 0.004548, loss_freq: 0.016023
[16:57:41.910] iteration 13594: loss: 0.062329, loss_s1: 0.047396, loss_fp: 0.001141, loss_freq: 0.021522
[16:57:42.533] iteration 13595: loss: 0.070897, loss_s1: 0.071450, loss_fp: 0.004706, loss_freq: 0.024963
[16:57:43.159] iteration 13596: loss: 0.072623, loss_s1: 0.050238, loss_fp: 0.008003, loss_freq: 0.043703
[16:57:43.790] iteration 13597: loss: 0.059678, loss_s1: 0.042402, loss_fp: 0.002966, loss_freq: 0.029626
[16:57:44.439] iteration 13598: loss: 0.048173, loss_s1: 0.018352, loss_fp: 0.001852, loss_freq: 0.024198
[16:57:45.127] iteration 13599: loss: 0.089784, loss_s1: 0.107927, loss_fp: 0.005682, loss_freq: 0.027246
[16:57:45.786] iteration 13600: loss: 0.091042, loss_s1: 0.099430, loss_fp: 0.000367, loss_freq: 0.026643
[16:57:49.666] iteration 13600 : mean_dice : 0.728351
[16:57:50.317] iteration 13601: loss: 0.044812, loss_s1: 0.031128, loss_fp: 0.001527, loss_freq: 0.022171
[16:57:50.940] iteration 13602: loss: 0.055120, loss_s1: 0.036524, loss_fp: 0.000585, loss_freq: 0.026566
[16:57:51.566] iteration 13603: loss: 0.047854, loss_s1: 0.028714, loss_fp: 0.001816, loss_freq: 0.008998
[16:57:52.188] iteration 13604: loss: 0.067170, loss_s1: 0.028208, loss_fp: 0.005129, loss_freq: 0.047429
[16:57:52.812] iteration 13605: loss: 0.056773, loss_s1: 0.027615, loss_fp: 0.004173, loss_freq: 0.041718
[16:57:53.440] iteration 13606: loss: 0.067676, loss_s1: 0.059586, loss_fp: 0.000486, loss_freq: 0.029301
[16:57:54.064] iteration 13607: loss: 0.108216, loss_s1: 0.075504, loss_fp: 0.010599, loss_freq: 0.091656
[16:57:54.691] iteration 13608: loss: 0.048257, loss_s1: 0.022610, loss_fp: 0.021313, loss_freq: 0.006951
[16:57:55.325] iteration 13609: loss: 0.134346, loss_s1: 0.118827, loss_fp: 0.005838, loss_freq: 0.095412
[16:57:56.008] iteration 13610: loss: 0.042611, loss_s1: 0.033799, loss_fp: 0.000460, loss_freq: 0.013647
[16:57:56.690] iteration 13611: loss: 0.079778, loss_s1: 0.079503, loss_fp: 0.001729, loss_freq: 0.014878
[16:57:57.373] iteration 13612: loss: 0.058650, loss_s1: 0.051942, loss_fp: 0.001507, loss_freq: 0.010926
[16:57:58.056] iteration 13613: loss: 0.099557, loss_s1: 0.104610, loss_fp: 0.006740, loss_freq: 0.045675
[16:57:58.701] iteration 13614: loss: 0.067069, loss_s1: 0.045364, loss_fp: 0.001674, loss_freq: 0.031230
[16:57:59.347] iteration 13615: loss: 0.057216, loss_s1: 0.016229, loss_fp: 0.001803, loss_freq: 0.009363
[16:57:59.988] iteration 13616: loss: 0.055449, loss_s1: 0.039156, loss_fp: 0.004111, loss_freq: 0.016842
[16:58:00.633] iteration 13617: loss: 0.077346, loss_s1: 0.045226, loss_fp: 0.001590, loss_freq: 0.016446
[16:58:01.272] iteration 13618: loss: 0.057699, loss_s1: 0.031719, loss_fp: 0.000398, loss_freq: 0.010237
[16:58:01.913] iteration 13619: loss: 0.049540, loss_s1: 0.018211, loss_fp: 0.001151, loss_freq: 0.022097
[16:58:02.552] iteration 13620: loss: 0.055551, loss_s1: 0.029210, loss_fp: 0.004524, loss_freq: 0.026847
[16:58:03.191] iteration 13621: loss: 0.043881, loss_s1: 0.028330, loss_fp: 0.002273, loss_freq: 0.019857
[16:58:03.829] iteration 13622: loss: 0.050593, loss_s1: 0.008541, loss_fp: 0.000526, loss_freq: 0.026530
[16:58:04.472] iteration 13623: loss: 0.061247, loss_s1: 0.054712, loss_fp: 0.010189, loss_freq: 0.019307
[16:58:05.109] iteration 13624: loss: 0.077357, loss_s1: 0.094215, loss_fp: 0.000555, loss_freq: 0.015556
[16:58:05.755] iteration 13625: loss: 0.092861, loss_s1: 0.114321, loss_fp: 0.012240, loss_freq: 0.020451
[16:58:06.394] iteration 13626: loss: 0.067076, loss_s1: 0.041641, loss_fp: 0.002687, loss_freq: 0.041081
[16:58:07.040] iteration 13627: loss: 0.083974, loss_s1: 0.063895, loss_fp: 0.001694, loss_freq: 0.054101
[16:58:07.715] iteration 13628: loss: 0.069225, loss_s1: 0.044205, loss_fp: 0.003147, loss_freq: 0.050966
[16:58:08.374] iteration 13629: loss: 0.056852, loss_s1: 0.029085, loss_fp: 0.001175, loss_freq: 0.016549
[16:58:09.032] iteration 13630: loss: 0.044975, loss_s1: 0.026990, loss_fp: 0.005874, loss_freq: 0.015497
[16:58:09.670] iteration 13631: loss: 0.038552, loss_s1: 0.027996, loss_fp: 0.001015, loss_freq: 0.006924
[16:58:10.299] iteration 13632: loss: 0.088140, loss_s1: 0.094256, loss_fp: 0.005231, loss_freq: 0.036597
[16:58:10.927] iteration 13633: loss: 0.108306, loss_s1: 0.075182, loss_fp: 0.009484, loss_freq: 0.085022
[16:58:11.550] iteration 13634: loss: 0.088496, loss_s1: 0.096276, loss_fp: 0.000468, loss_freq: 0.040490
[16:58:12.176] iteration 13635: loss: 0.050074, loss_s1: 0.026316, loss_fp: 0.001835, loss_freq: 0.014217
[16:58:12.800] iteration 13636: loss: 0.072446, loss_s1: 0.051696, loss_fp: 0.002756, loss_freq: 0.048742
[16:58:13.424] iteration 13637: loss: 0.126724, loss_s1: 0.121274, loss_fp: 0.003795, loss_freq: 0.040066
[16:58:14.048] iteration 13638: loss: 0.040604, loss_s1: 0.028874, loss_fp: 0.000830, loss_freq: 0.009804
[16:58:14.670] iteration 13639: loss: 0.029698, loss_s1: 0.014846, loss_fp: 0.000361, loss_freq: 0.005707
[16:58:15.291] iteration 13640: loss: 0.089227, loss_s1: 0.076083, loss_fp: 0.004398, loss_freq: 0.038117
[16:58:15.920] iteration 13641: loss: 0.073551, loss_s1: 0.071401, loss_fp: 0.004033, loss_freq: 0.030814
[16:58:16.551] iteration 13642: loss: 0.059867, loss_s1: 0.047673, loss_fp: 0.005482, loss_freq: 0.031260
[16:58:17.176] iteration 13643: loss: 0.066315, loss_s1: 0.046823, loss_fp: 0.003270, loss_freq: 0.027768
[16:58:17.798] iteration 13644: loss: 0.071943, loss_s1: 0.034700, loss_fp: 0.007983, loss_freq: 0.061112
[16:58:18.430] iteration 13645: loss: 0.071088, loss_s1: 0.067371, loss_fp: 0.006412, loss_freq: 0.025105
[16:58:19.052] iteration 13646: loss: 0.071337, loss_s1: 0.056603, loss_fp: 0.003978, loss_freq: 0.026740
[16:58:19.674] iteration 13647: loss: 0.057683, loss_s1: 0.056685, loss_fp: 0.000871, loss_freq: 0.012692
[16:58:20.298] iteration 13648: loss: 0.065207, loss_s1: 0.047124, loss_fp: 0.001577, loss_freq: 0.010035
[16:58:20.922] iteration 13649: loss: 0.078711, loss_s1: 0.044966, loss_fp: 0.001284, loss_freq: 0.025269
[16:58:21.545] iteration 13650: loss: 0.076199, loss_s1: 0.073488, loss_fp: 0.004194, loss_freq: 0.016387
[16:58:22.178] iteration 13651: loss: 0.089016, loss_s1: 0.084677, loss_fp: 0.001892, loss_freq: 0.023117
[16:58:22.801] iteration 13652: loss: 0.097764, loss_s1: 0.067250, loss_fp: 0.000887, loss_freq: 0.047440
[16:58:23.424] iteration 13653: loss: 0.046560, loss_s1: 0.028373, loss_fp: 0.000651, loss_freq: 0.026780
[16:58:24.047] iteration 13654: loss: 0.049406, loss_s1: 0.043433, loss_fp: 0.001152, loss_freq: 0.009255
[16:58:24.672] iteration 13655: loss: 0.084947, loss_s1: 0.045756, loss_fp: 0.013833, loss_freq: 0.064219
[16:58:25.301] iteration 13656: loss: 0.069722, loss_s1: 0.044892, loss_fp: 0.001883, loss_freq: 0.045569
[16:58:25.928] iteration 13657: loss: 0.089432, loss_s1: 0.092561, loss_fp: 0.002049, loss_freq: 0.027164
[16:58:26.557] iteration 13658: loss: 0.097311, loss_s1: 0.086197, loss_fp: 0.004657, loss_freq: 0.034763
[16:58:27.186] iteration 13659: loss: 0.095714, loss_s1: 0.052146, loss_fp: 0.002870, loss_freq: 0.050713
[16:58:27.848] iteration 13660: loss: 0.053408, loss_s1: 0.061035, loss_fp: 0.002046, loss_freq: 0.010066
[16:58:28.474] iteration 13661: loss: 0.036146, loss_s1: 0.011490, loss_fp: 0.001702, loss_freq: 0.009762
[16:58:29.104] iteration 13662: loss: 0.047584, loss_s1: 0.022961, loss_fp: 0.004668, loss_freq: 0.018838
[16:58:29.739] iteration 13663: loss: 0.081021, loss_s1: 0.073619, loss_fp: 0.006298, loss_freq: 0.044752
[16:58:30.389] iteration 13664: loss: 0.109978, loss_s1: 0.089646, loss_fp: 0.020259, loss_freq: 0.035566
[16:58:31.023] iteration 13665: loss: 0.076863, loss_s1: 0.051595, loss_fp: 0.005943, loss_freq: 0.046623
[16:58:31.658] iteration 13666: loss: 0.082190, loss_s1: 0.050562, loss_fp: 0.002456, loss_freq: 0.030602
[16:58:32.289] iteration 13667: loss: 0.095063, loss_s1: 0.059624, loss_fp: 0.013731, loss_freq: 0.044104
[16:58:32.920] iteration 13668: loss: 0.073407, loss_s1: 0.027167, loss_fp: 0.009885, loss_freq: 0.031874
[16:58:33.552] iteration 13669: loss: 0.046536, loss_s1: 0.029456, loss_fp: 0.004646, loss_freq: 0.015158
[16:58:34.178] iteration 13670: loss: 0.079436, loss_s1: 0.068932, loss_fp: 0.004021, loss_freq: 0.023953
[16:58:34.812] iteration 13671: loss: 0.102419, loss_s1: 0.089864, loss_fp: 0.002219, loss_freq: 0.070711
[16:58:35.440] iteration 13672: loss: 0.083853, loss_s1: 0.054853, loss_fp: 0.000910, loss_freq: 0.016404
[16:58:36.079] iteration 13673: loss: 0.057886, loss_s1: 0.025430, loss_fp: 0.008776, loss_freq: 0.017391
[16:58:36.712] iteration 13674: loss: 0.091677, loss_s1: 0.083380, loss_fp: 0.010537, loss_freq: 0.026513
[16:58:37.347] iteration 13675: loss: 0.091621, loss_s1: 0.030270, loss_fp: 0.001435, loss_freq: 0.020037
[16:58:37.979] iteration 13676: loss: 0.115642, loss_s1: 0.098641, loss_fp: 0.004904, loss_freq: 0.049172
[16:58:38.611] iteration 13677: loss: 0.070650, loss_s1: 0.048869, loss_fp: 0.000638, loss_freq: 0.053754
[16:58:39.243] iteration 13678: loss: 0.062975, loss_s1: 0.032214, loss_fp: 0.003072, loss_freq: 0.033641
[16:58:39.872] iteration 13679: loss: 0.041274, loss_s1: 0.024404, loss_fp: 0.000868, loss_freq: 0.010139
[16:58:40.504] iteration 13680: loss: 0.069545, loss_s1: 0.058798, loss_fp: 0.003029, loss_freq: 0.010797
[16:58:41.130] iteration 13681: loss: 0.035419, loss_s1: 0.016547, loss_fp: 0.000428, loss_freq: 0.007335
[16:58:41.764] iteration 13682: loss: 0.084201, loss_s1: 0.050490, loss_fp: 0.002955, loss_freq: 0.067422
[16:58:42.397] iteration 13683: loss: 0.095274, loss_s1: 0.083368, loss_fp: 0.004784, loss_freq: 0.040401
[16:58:43.017] iteration 13684: loss: 0.077015, loss_s1: 0.045726, loss_fp: 0.001265, loss_freq: 0.020286
[16:58:43.644] iteration 13685: loss: 0.065839, loss_s1: 0.026754, loss_fp: 0.014094, loss_freq: 0.023139
[16:58:44.589] iteration 13686: loss: 0.067767, loss_s1: 0.047634, loss_fp: 0.004005, loss_freq: 0.026903
[16:58:45.260] iteration 13687: loss: 0.076805, loss_s1: 0.085274, loss_fp: 0.006246, loss_freq: 0.021457
[16:58:45.922] iteration 13688: loss: 0.075509, loss_s1: 0.076471, loss_fp: 0.000568, loss_freq: 0.016412
[16:58:46.590] iteration 13689: loss: 0.045386, loss_s1: 0.024716, loss_fp: 0.002973, loss_freq: 0.014529
[16:58:47.245] iteration 13690: loss: 0.066832, loss_s1: 0.051919, loss_fp: 0.002996, loss_freq: 0.019579
[16:58:47.879] iteration 13691: loss: 0.169500, loss_s1: 0.131966, loss_fp: 0.006338, loss_freq: 0.063887
[16:58:48.506] iteration 13692: loss: 0.033502, loss_s1: 0.012024, loss_fp: 0.001276, loss_freq: 0.019237
[16:58:49.132] iteration 13693: loss: 0.047283, loss_s1: 0.019753, loss_fp: 0.002061, loss_freq: 0.023439
[16:58:49.754] iteration 13694: loss: 0.086897, loss_s1: 0.091563, loss_fp: 0.000987, loss_freq: 0.039484
[16:58:50.379] iteration 13695: loss: 0.041731, loss_s1: 0.014402, loss_fp: 0.000870, loss_freq: 0.024381
[16:58:51.002] iteration 13696: loss: 0.042884, loss_s1: 0.024031, loss_fp: 0.001551, loss_freq: 0.012814
[16:58:51.628] iteration 13697: loss: 0.067268, loss_s1: 0.046858, loss_fp: 0.001005, loss_freq: 0.041894
[16:58:52.251] iteration 13698: loss: 0.079220, loss_s1: 0.090277, loss_fp: 0.004150, loss_freq: 0.029620
[16:58:52.874] iteration 13699: loss: 0.062548, loss_s1: 0.039165, loss_fp: 0.001185, loss_freq: 0.026362
[16:58:53.501] iteration 13700: loss: 0.048087, loss_s1: 0.042356, loss_fp: 0.002993, loss_freq: 0.012233
[16:58:54.126] iteration 13701: loss: 0.072832, loss_s1: 0.074097, loss_fp: 0.003008, loss_freq: 0.024604
[16:58:54.748] iteration 13702: loss: 0.086300, loss_s1: 0.021429, loss_fp: 0.015654, loss_freq: 0.012456
[16:58:55.371] iteration 13703: loss: 0.077720, loss_s1: 0.076051, loss_fp: 0.006806, loss_freq: 0.033161
[16:58:55.993] iteration 13704: loss: 0.043070, loss_s1: 0.025881, loss_fp: 0.001299, loss_freq: 0.010598
[16:58:56.620] iteration 13705: loss: 0.072265, loss_s1: 0.033694, loss_fp: 0.004604, loss_freq: 0.031310
[16:58:57.244] iteration 13706: loss: 0.073942, loss_s1: 0.068825, loss_fp: 0.000708, loss_freq: 0.029890
[16:58:57.867] iteration 13707: loss: 0.048453, loss_s1: 0.043740, loss_fp: 0.002849, loss_freq: 0.010979
[16:58:58.497] iteration 13708: loss: 0.080120, loss_s1: 0.050199, loss_fp: 0.001515, loss_freq: 0.039517
[16:58:59.121] iteration 13709: loss: 0.186457, loss_s1: 0.180721, loss_fp: 0.001397, loss_freq: 0.139699
[16:58:59.744] iteration 13710: loss: 0.042318, loss_s1: 0.032452, loss_fp: 0.001354, loss_freq: 0.015401
[16:59:00.369] iteration 13711: loss: 0.082737, loss_s1: 0.060944, loss_fp: 0.009575, loss_freq: 0.047078
[16:59:00.996] iteration 13712: loss: 0.038787, loss_s1: 0.015104, loss_fp: 0.008957, loss_freq: 0.005077
[16:59:01.621] iteration 13713: loss: 0.072825, loss_s1: 0.058234, loss_fp: 0.003756, loss_freq: 0.019920
[16:59:02.246] iteration 13714: loss: 0.076106, loss_s1: 0.054235, loss_fp: 0.003246, loss_freq: 0.021871
[16:59:02.872] iteration 13715: loss: 0.061845, loss_s1: 0.072705, loss_fp: 0.002504, loss_freq: 0.012550
[16:59:03.494] iteration 13716: loss: 0.042411, loss_s1: 0.028663, loss_fp: 0.001720, loss_freq: 0.023662
[16:59:04.118] iteration 13717: loss: 0.058027, loss_s1: 0.034353, loss_fp: 0.001132, loss_freq: 0.017598
[16:59:04.743] iteration 13718: loss: 0.054631, loss_s1: 0.037218, loss_fp: 0.000420, loss_freq: 0.032556
[16:59:05.368] iteration 13719: loss: 0.047929, loss_s1: 0.020701, loss_fp: 0.003914, loss_freq: 0.007724
[16:59:05.991] iteration 13720: loss: 0.101717, loss_s1: 0.047203, loss_fp: 0.001373, loss_freq: 0.046270
[16:59:06.610] iteration 13721: loss: 0.074477, loss_s1: 0.057870, loss_fp: 0.008034, loss_freq: 0.040517
[16:59:07.235] iteration 13722: loss: 0.151101, loss_s1: 0.084443, loss_fp: 0.009212, loss_freq: 0.128574
[16:59:07.862] iteration 13723: loss: 0.084776, loss_s1: 0.070284, loss_fp: 0.004043, loss_freq: 0.038410
[16:59:08.481] iteration 13724: loss: 0.109513, loss_s1: 0.088755, loss_fp: 0.002111, loss_freq: 0.039643
[16:59:09.104] iteration 13725: loss: 0.075480, loss_s1: 0.053124, loss_fp: 0.007685, loss_freq: 0.044103
[16:59:09.730] iteration 13726: loss: 0.069142, loss_s1: 0.047915, loss_fp: 0.008129, loss_freq: 0.014138
[16:59:10.354] iteration 13727: loss: 0.108737, loss_s1: 0.086461, loss_fp: 0.006494, loss_freq: 0.078867
[16:59:10.981] iteration 13728: loss: 0.098259, loss_s1: 0.053661, loss_fp: 0.017626, loss_freq: 0.064535
[16:59:11.607] iteration 13729: loss: 0.074613, loss_s1: 0.047607, loss_fp: 0.005149, loss_freq: 0.045638
[16:59:12.235] iteration 13730: loss: 0.040347, loss_s1: 0.019266, loss_fp: 0.000811, loss_freq: 0.008970
[16:59:12.863] iteration 13731: loss: 0.046780, loss_s1: 0.037848, loss_fp: 0.002161, loss_freq: 0.007346
[16:59:13.492] iteration 13732: loss: 0.039896, loss_s1: 0.040467, loss_fp: 0.000703, loss_freq: 0.004116
[16:59:14.117] iteration 13733: loss: 0.090184, loss_s1: 0.089631, loss_fp: 0.005323, loss_freq: 0.038162
[16:59:14.742] iteration 13734: loss: 0.093424, loss_s1: 0.083411, loss_fp: 0.005554, loss_freq: 0.015479
[16:59:15.419] iteration 13735: loss: 0.078629, loss_s1: 0.059367, loss_fp: 0.009512, loss_freq: 0.045300
[16:59:16.057] iteration 13736: loss: 0.091814, loss_s1: 0.099336, loss_fp: 0.001902, loss_freq: 0.039840
[16:59:16.692] iteration 13737: loss: 0.061377, loss_s1: 0.034448, loss_fp: 0.004409, loss_freq: 0.028389
[16:59:17.317] iteration 13738: loss: 0.053459, loss_s1: 0.025637, loss_fp: 0.013232, loss_freq: 0.017236
[16:59:17.947] iteration 13739: loss: 0.070656, loss_s1: 0.037437, loss_fp: 0.008865, loss_freq: 0.040618
[16:59:18.569] iteration 13740: loss: 0.048287, loss_s1: 0.038433, loss_fp: 0.003004, loss_freq: 0.010194
[16:59:19.191] iteration 13741: loss: 0.065480, loss_s1: 0.025135, loss_fp: 0.003921, loss_freq: 0.036440
[16:59:19.849] iteration 13742: loss: 0.044547, loss_s1: 0.032800, loss_fp: 0.001950, loss_freq: 0.017013
[16:59:20.509] iteration 13743: loss: 0.067241, loss_s1: 0.038783, loss_fp: 0.001128, loss_freq: 0.025665
[16:59:21.164] iteration 13744: loss: 0.046249, loss_s1: 0.045312, loss_fp: 0.004152, loss_freq: 0.009119
[16:59:21.805] iteration 13745: loss: 0.065693, loss_s1: 0.068511, loss_fp: 0.002606, loss_freq: 0.015865
[16:59:22.424] iteration 13746: loss: 0.059329, loss_s1: 0.040125, loss_fp: 0.000927, loss_freq: 0.022011
[16:59:23.047] iteration 13747: loss: 0.103866, loss_s1: 0.132227, loss_fp: 0.001601, loss_freq: 0.024127
[16:59:23.670] iteration 13748: loss: 0.054819, loss_s1: 0.030037, loss_fp: 0.000780, loss_freq: 0.016580
[16:59:24.293] iteration 13749: loss: 0.081793, loss_s1: 0.052281, loss_fp: 0.007077, loss_freq: 0.021958
[16:59:24.924] iteration 13750: loss: 0.073397, loss_s1: 0.083886, loss_fp: 0.002037, loss_freq: 0.013458
[16:59:25.551] iteration 13751: loss: 0.119980, loss_s1: 0.076236, loss_fp: 0.001197, loss_freq: 0.091192
[16:59:26.177] iteration 13752: loss: 0.081231, loss_s1: 0.040843, loss_fp: 0.000591, loss_freq: 0.070619
[16:59:26.799] iteration 13753: loss: 0.077538, loss_s1: 0.059627, loss_fp: 0.006360, loss_freq: 0.046714
[16:59:27.421] iteration 13754: loss: 0.066921, loss_s1: 0.046688, loss_fp: 0.001194, loss_freq: 0.013727
[16:59:28.047] iteration 13755: loss: 0.086994, loss_s1: 0.074772, loss_fp: 0.000170, loss_freq: 0.026470
[16:59:28.672] iteration 13756: loss: 0.055800, loss_s1: 0.030684, loss_fp: 0.002529, loss_freq: 0.036793
[16:59:29.295] iteration 13757: loss: 0.058342, loss_s1: 0.050680, loss_fp: 0.002710, loss_freq: 0.026423
[16:59:29.918] iteration 13758: loss: 0.075385, loss_s1: 0.045974, loss_fp: 0.001798, loss_freq: 0.060974
[16:59:30.545] iteration 13759: loss: 0.037436, loss_s1: 0.020851, loss_fp: 0.002076, loss_freq: 0.009875
[16:59:31.171] iteration 13760: loss: 0.061488, loss_s1: 0.057631, loss_fp: 0.000607, loss_freq: 0.023979
[16:59:31.795] iteration 13761: loss: 0.088873, loss_s1: 0.078455, loss_fp: 0.003477, loss_freq: 0.036813
[16:59:32.420] iteration 13762: loss: 0.058660, loss_s1: 0.052338, loss_fp: 0.000813, loss_freq: 0.026221
[16:59:33.083] iteration 13763: loss: 0.072097, loss_s1: 0.072053, loss_fp: 0.002785, loss_freq: 0.028162
[16:59:33.740] iteration 13764: loss: 0.037486, loss_s1: 0.016955, loss_fp: 0.002997, loss_freq: 0.016825
[16:59:34.397] iteration 13765: loss: 0.078386, loss_s1: 0.067136, loss_fp: 0.001504, loss_freq: 0.040628
[16:59:35.044] iteration 13766: loss: 0.105233, loss_s1: 0.107018, loss_fp: 0.028616, loss_freq: 0.025967
[16:59:35.669] iteration 13767: loss: 0.072905, loss_s1: 0.064705, loss_fp: 0.005517, loss_freq: 0.037813
[16:59:36.293] iteration 13768: loss: 0.091558, loss_s1: 0.094739, loss_fp: 0.008787, loss_freq: 0.034796
[16:59:36.915] iteration 13769: loss: 0.081815, loss_s1: 0.055918, loss_fp: 0.004436, loss_freq: 0.037779
[16:59:37.537] iteration 13770: loss: 0.125678, loss_s1: 0.096812, loss_fp: 0.007212, loss_freq: 0.109866
[16:59:38.163] iteration 13771: loss: 0.063716, loss_s1: 0.071711, loss_fp: 0.002074, loss_freq: 0.009434
[16:59:38.787] iteration 13772: loss: 0.067341, loss_s1: 0.030755, loss_fp: 0.003395, loss_freq: 0.012059
[16:59:39.409] iteration 13773: loss: 0.062322, loss_s1: 0.054416, loss_fp: 0.001076, loss_freq: 0.015642
[16:59:40.031] iteration 13774: loss: 0.079700, loss_s1: 0.076032, loss_fp: 0.003589, loss_freq: 0.017879
[16:59:40.684] iteration 13775: loss: 0.044073, loss_s1: 0.025369, loss_fp: 0.003091, loss_freq: 0.017842
[16:59:41.344] iteration 13776: loss: 0.054364, loss_s1: 0.028214, loss_fp: 0.002434, loss_freq: 0.017258
[16:59:42.013] iteration 13777: loss: 0.068228, loss_s1: 0.045288, loss_fp: 0.004297, loss_freq: 0.016260
[16:59:42.671] iteration 13778: loss: 0.103442, loss_s1: 0.065318, loss_fp: 0.000782, loss_freq: 0.018689
[16:59:43.327] iteration 13779: loss: 0.068721, loss_s1: 0.068820, loss_fp: 0.001433, loss_freq: 0.020368
[16:59:43.988] iteration 13780: loss: 0.060735, loss_s1: 0.039995, loss_fp: 0.001352, loss_freq: 0.015796
[16:59:44.645] iteration 13781: loss: 0.055940, loss_s1: 0.038177, loss_fp: 0.001783, loss_freq: 0.033654
[16:59:45.271] iteration 13782: loss: 0.056866, loss_s1: 0.026191, loss_fp: 0.003863, loss_freq: 0.023918
[16:59:45.896] iteration 13783: loss: 0.045739, loss_s1: 0.011109, loss_fp: 0.002638, loss_freq: 0.020631
[16:59:46.520] iteration 13784: loss: 0.040757, loss_s1: 0.020599, loss_fp: 0.000786, loss_freq: 0.020891
[16:59:47.148] iteration 13785: loss: 0.044868, loss_s1: 0.023720, loss_fp: 0.004754, loss_freq: 0.019634
[16:59:47.773] iteration 13786: loss: 0.101236, loss_s1: 0.120528, loss_fp: 0.002601, loss_freq: 0.031092
[16:59:48.397] iteration 13787: loss: 0.054129, loss_s1: 0.027399, loss_fp: 0.006318, loss_freq: 0.021935
[16:59:49.017] iteration 13788: loss: 0.096699, loss_s1: 0.079226, loss_fp: 0.006851, loss_freq: 0.060844
[16:59:49.656] iteration 13789: loss: 0.064728, loss_s1: 0.060675, loss_fp: 0.002956, loss_freq: 0.030205
[16:59:50.615] iteration 13790: loss: 0.042448, loss_s1: 0.020561, loss_fp: 0.000478, loss_freq: 0.012393
[16:59:51.579] iteration 13791: loss: 0.040310, loss_s1: 0.017823, loss_fp: 0.003231, loss_freq: 0.021843
[16:59:52.231] iteration 13792: loss: 0.045576, loss_s1: 0.029399, loss_fp: 0.002497, loss_freq: 0.009702
[16:59:52.855] iteration 13793: loss: 0.100002, loss_s1: 0.072313, loss_fp: 0.006215, loss_freq: 0.047130
[16:59:53.479] iteration 13794: loss: 0.141822, loss_s1: 0.106126, loss_fp: 0.005157, loss_freq: 0.087857
[16:59:54.099] iteration 13795: loss: 0.071579, loss_s1: 0.057295, loss_fp: 0.013496, loss_freq: 0.030168
[16:59:54.721] iteration 13796: loss: 0.061263, loss_s1: 0.012717, loss_fp: 0.003985, loss_freq: 0.015914
[16:59:55.344] iteration 13797: loss: 0.055195, loss_s1: 0.028364, loss_fp: 0.005936, loss_freq: 0.037619
[16:59:55.967] iteration 13798: loss: 0.103626, loss_s1: 0.106716, loss_fp: 0.017389, loss_freq: 0.042277
[16:59:56.587] iteration 13799: loss: 0.051237, loss_s1: 0.028786, loss_fp: 0.001072, loss_freq: 0.029401
[16:59:57.210] iteration 13800: loss: 0.034481, loss_s1: 0.010234, loss_fp: 0.002659, loss_freq: 0.009694
[17:00:00.395] iteration 13800 : mean_dice : 0.687764
[17:00:01.042] iteration 13801: loss: 0.096556, loss_s1: 0.067646, loss_fp: 0.003326, loss_freq: 0.066964
[17:00:01.666] iteration 13802: loss: 0.062299, loss_s1: 0.041851, loss_fp: 0.004340, loss_freq: 0.021542
[17:00:02.292] iteration 13803: loss: 0.037013, loss_s1: 0.011394, loss_fp: 0.000578, loss_freq: 0.024478
[17:00:02.921] iteration 13804: loss: 0.043405, loss_s1: 0.018402, loss_fp: 0.002094, loss_freq: 0.013064
[17:00:03.548] iteration 13805: loss: 0.088041, loss_s1: 0.061851, loss_fp: 0.002499, loss_freq: 0.078011
[17:00:04.175] iteration 13806: loss: 0.087760, loss_s1: 0.040834, loss_fp: 0.000910, loss_freq: 0.088156
[17:00:04.801] iteration 13807: loss: 0.085304, loss_s1: 0.046667, loss_fp: 0.003590, loss_freq: 0.054959
[17:00:05.429] iteration 13808: loss: 0.070976, loss_s1: 0.068485, loss_fp: 0.005376, loss_freq: 0.018396
[17:00:06.053] iteration 13809: loss: 0.060257, loss_s1: 0.024841, loss_fp: 0.011308, loss_freq: 0.033235
[17:00:06.679] iteration 13810: loss: 0.048790, loss_s1: 0.023532, loss_fp: 0.001339, loss_freq: 0.029396
[17:00:07.306] iteration 13811: loss: 0.060629, loss_s1: 0.029575, loss_fp: 0.004954, loss_freq: 0.024955
[17:00:07.933] iteration 13812: loss: 0.055446, loss_s1: 0.046194, loss_fp: 0.003201, loss_freq: 0.012976
[17:00:08.560] iteration 13813: loss: 0.092449, loss_s1: 0.061046, loss_fp: 0.001292, loss_freq: 0.034762
[17:00:09.220] iteration 13814: loss: 0.051469, loss_s1: 0.020217, loss_fp: 0.001372, loss_freq: 0.020113
[17:00:09.877] iteration 13815: loss: 0.034252, loss_s1: 0.024229, loss_fp: 0.005434, loss_freq: 0.007050
[17:00:10.533] iteration 13816: loss: 0.085621, loss_s1: 0.067053, loss_fp: 0.003231, loss_freq: 0.057390
[17:00:11.192] iteration 13817: loss: 0.089761, loss_s1: 0.074938, loss_fp: 0.003839, loss_freq: 0.045336
[17:00:11.852] iteration 13818: loss: 0.061288, loss_s1: 0.043920, loss_fp: 0.011223, loss_freq: 0.021751
[17:00:12.496] iteration 13819: loss: 0.040532, loss_s1: 0.021002, loss_fp: 0.003247, loss_freq: 0.021347
[17:00:13.118] iteration 13820: loss: 0.058522, loss_s1: 0.044977, loss_fp: 0.000382, loss_freq: 0.031648
[17:00:13.735] iteration 13821: loss: 0.047980, loss_s1: 0.035449, loss_fp: 0.006484, loss_freq: 0.016956
[17:00:14.364] iteration 13822: loss: 0.043309, loss_s1: 0.020808, loss_fp: 0.001401, loss_freq: 0.013866
[17:00:14.989] iteration 13823: loss: 0.072403, loss_s1: 0.055699, loss_fp: 0.002784, loss_freq: 0.032505
[17:00:15.618] iteration 13824: loss: 0.040153, loss_s1: 0.013427, loss_fp: 0.002078, loss_freq: 0.021911
[17:00:16.245] iteration 13825: loss: 0.092257, loss_s1: 0.090113, loss_fp: 0.002427, loss_freq: 0.034860
[17:00:16.870] iteration 13826: loss: 0.086850, loss_s1: 0.098863, loss_fp: 0.004413, loss_freq: 0.018173
[17:00:17.488] iteration 13827: loss: 0.085002, loss_s1: 0.049301, loss_fp: 0.010635, loss_freq: 0.022920
[17:00:18.115] iteration 13828: loss: 0.085992, loss_s1: 0.060124, loss_fp: 0.001220, loss_freq: 0.049042
[17:00:18.739] iteration 13829: loss: 0.074539, loss_s1: 0.043196, loss_fp: 0.003356, loss_freq: 0.023028
[17:00:19.361] iteration 13830: loss: 0.037150, loss_s1: 0.022011, loss_fp: 0.004353, loss_freq: 0.008514
[17:00:19.984] iteration 13831: loss: 0.089516, loss_s1: 0.091796, loss_fp: 0.003399, loss_freq: 0.021075
[17:00:20.608] iteration 13832: loss: 0.074374, loss_s1: 0.059481, loss_fp: 0.008712, loss_freq: 0.040892
[17:00:21.234] iteration 13833: loss: 0.050183, loss_s1: 0.038312, loss_fp: 0.001741, loss_freq: 0.018460
[17:00:21.861] iteration 13834: loss: 0.055466, loss_s1: 0.029773, loss_fp: 0.012414, loss_freq: 0.034290
[17:00:22.491] iteration 13835: loss: 0.071856, loss_s1: 0.034286, loss_fp: 0.007794, loss_freq: 0.047432
[17:00:23.116] iteration 13836: loss: 0.061769, loss_s1: 0.021210, loss_fp: 0.003663, loss_freq: 0.056387
[17:00:23.738] iteration 13837: loss: 0.101216, loss_s1: 0.095299, loss_fp: 0.010443, loss_freq: 0.050596
[17:00:24.360] iteration 13838: loss: 0.059988, loss_s1: 0.068271, loss_fp: 0.002250, loss_freq: 0.018201
[17:00:24.987] iteration 13839: loss: 0.054217, loss_s1: 0.044068, loss_fp: 0.005702, loss_freq: 0.012923
[17:00:25.614] iteration 13840: loss: 0.033653, loss_s1: 0.022158, loss_fp: 0.000827, loss_freq: 0.012718
[17:00:26.240] iteration 13841: loss: 0.048034, loss_s1: 0.027834, loss_fp: 0.001398, loss_freq: 0.024468
[17:00:26.862] iteration 13842: loss: 0.054535, loss_s1: 0.019125, loss_fp: 0.000728, loss_freq: 0.011556
[17:00:27.488] iteration 13843: loss: 0.066029, loss_s1: 0.026220, loss_fp: 0.005191, loss_freq: 0.043433
[17:00:28.114] iteration 13844: loss: 0.094575, loss_s1: 0.082364, loss_fp: 0.006652, loss_freq: 0.025198
[17:00:28.736] iteration 13845: loss: 0.062807, loss_s1: 0.056573, loss_fp: 0.003155, loss_freq: 0.024722
[17:00:29.356] iteration 13846: loss: 0.055750, loss_s1: 0.048595, loss_fp: 0.004697, loss_freq: 0.014301
[17:00:30.392] iteration 13847: loss: 0.047663, loss_s1: 0.028089, loss_fp: 0.004185, loss_freq: 0.014835
[17:00:31.057] iteration 13848: loss: 0.065920, loss_s1: 0.048342, loss_fp: 0.000860, loss_freq: 0.024306
[17:00:31.714] iteration 13849: loss: 0.045534, loss_s1: 0.028421, loss_fp: 0.000697, loss_freq: 0.010776
[17:00:32.372] iteration 13850: loss: 0.046445, loss_s1: 0.040216, loss_fp: 0.000469, loss_freq: 0.010183
[17:00:33.043] iteration 13851: loss: 0.058932, loss_s1: 0.040234, loss_fp: 0.002295, loss_freq: 0.014112
[17:00:33.675] iteration 13852: loss: 0.113756, loss_s1: 0.091279, loss_fp: 0.004278, loss_freq: 0.057031
[17:00:34.306] iteration 13853: loss: 0.067487, loss_s1: 0.069758, loss_fp: 0.003171, loss_freq: 0.022370
[17:00:34.940] iteration 13854: loss: 0.058153, loss_s1: 0.061479, loss_fp: 0.000410, loss_freq: 0.017177
[17:00:35.571] iteration 13855: loss: 0.063575, loss_s1: 0.061013, loss_fp: 0.003263, loss_freq: 0.016447
[17:00:36.202] iteration 13856: loss: 0.078757, loss_s1: 0.068323, loss_fp: 0.011512, loss_freq: 0.037041
[17:00:36.838] iteration 13857: loss: 0.061271, loss_s1: 0.025296, loss_fp: 0.019787, loss_freq: 0.011560
[17:00:37.479] iteration 13858: loss: 0.062509, loss_s1: 0.029773, loss_fp: 0.017131, loss_freq: 0.015364
[17:00:38.102] iteration 13859: loss: 0.070767, loss_s1: 0.044004, loss_fp: 0.003299, loss_freq: 0.062522
[17:00:38.729] iteration 13860: loss: 0.053783, loss_s1: 0.033745, loss_fp: 0.000906, loss_freq: 0.027822
[17:00:39.357] iteration 13861: loss: 0.060052, loss_s1: 0.057140, loss_fp: 0.004626, loss_freq: 0.009229
[17:00:39.981] iteration 13862: loss: 0.133856, loss_s1: 0.113814, loss_fp: 0.004368, loss_freq: 0.101724
[17:00:40.617] iteration 13863: loss: 0.067603, loss_s1: 0.037822, loss_fp: 0.002852, loss_freq: 0.011079
[17:00:41.247] iteration 13864: loss: 0.040427, loss_s1: 0.021291, loss_fp: 0.004639, loss_freq: 0.011635
[17:00:41.880] iteration 13865: loss: 0.053155, loss_s1: 0.014470, loss_fp: 0.001676, loss_freq: 0.032838
[17:00:42.509] iteration 13866: loss: 0.044862, loss_s1: 0.016013, loss_fp: 0.007673, loss_freq: 0.013603
[17:00:43.164] iteration 13867: loss: 0.054537, loss_s1: 0.036858, loss_fp: 0.000433, loss_freq: 0.010236
[17:00:43.797] iteration 13868: loss: 0.073826, loss_s1: 0.053072, loss_fp: 0.005340, loss_freq: 0.022771
[17:00:44.423] iteration 13869: loss: 0.056149, loss_s1: 0.032412, loss_fp: 0.003008, loss_freq: 0.023020
[17:00:45.052] iteration 13870: loss: 0.080899, loss_s1: 0.076559, loss_fp: 0.002930, loss_freq: 0.043189
[17:00:45.681] iteration 13871: loss: 0.047271, loss_s1: 0.030204, loss_fp: 0.002661, loss_freq: 0.023648
[17:00:46.302] iteration 13872: loss: 0.056605, loss_s1: 0.033846, loss_fp: 0.002707, loss_freq: 0.023886
[17:00:46.929] iteration 13873: loss: 0.057956, loss_s1: 0.040556, loss_fp: 0.000911, loss_freq: 0.025863
[17:00:47.557] iteration 13874: loss: 0.090789, loss_s1: 0.052747, loss_fp: 0.010913, loss_freq: 0.073340
[17:00:48.184] iteration 13875: loss: 0.074624, loss_s1: 0.055406, loss_fp: 0.002833, loss_freq: 0.034265
[17:00:48.816] iteration 13876: loss: 0.047383, loss_s1: 0.045056, loss_fp: 0.002610, loss_freq: 0.007696
[17:00:49.444] iteration 13877: loss: 0.039613, loss_s1: 0.031217, loss_fp: 0.001495, loss_freq: 0.015255
[17:00:50.074] iteration 13878: loss: 0.063869, loss_s1: 0.050440, loss_fp: 0.003090, loss_freq: 0.006287
[17:00:50.700] iteration 13879: loss: 0.052057, loss_s1: 0.037504, loss_fp: 0.003436, loss_freq: 0.021313
[17:00:51.325] iteration 13880: loss: 0.039445, loss_s1: 0.021253, loss_fp: 0.001912, loss_freq: 0.016167
[17:00:51.951] iteration 13881: loss: 0.068439, loss_s1: 0.041815, loss_fp: 0.001577, loss_freq: 0.028246
[17:00:52.580] iteration 13882: loss: 0.059528, loss_s1: 0.050343, loss_fp: 0.009960, loss_freq: 0.020423
[17:00:53.206] iteration 13883: loss: 0.104077, loss_s1: 0.049312, loss_fp: 0.004660, loss_freq: 0.057483
[17:00:53.882] iteration 13884: loss: 0.056902, loss_s1: 0.039463, loss_fp: 0.003836, loss_freq: 0.018353
[17:00:54.508] iteration 13885: loss: 0.099025, loss_s1: 0.062846, loss_fp: 0.000625, loss_freq: 0.061565
[17:00:55.135] iteration 13886: loss: 0.061109, loss_s1: 0.061104, loss_fp: 0.001318, loss_freq: 0.022677
[17:00:55.761] iteration 13887: loss: 0.062189, loss_s1: 0.035247, loss_fp: 0.003597, loss_freq: 0.027690
[17:00:56.392] iteration 13888: loss: 0.074317, loss_s1: 0.046274, loss_fp: 0.001080, loss_freq: 0.062961
[17:00:57.013] iteration 13889: loss: 0.096943, loss_s1: 0.096002, loss_fp: 0.005596, loss_freq: 0.028916
[17:00:57.638] iteration 13890: loss: 0.055506, loss_s1: 0.020205, loss_fp: 0.003167, loss_freq: 0.041495
[17:00:58.269] iteration 13891: loss: 0.073752, loss_s1: 0.021905, loss_fp: 0.003319, loss_freq: 0.066312
[17:00:58.903] iteration 13892: loss: 0.071717, loss_s1: 0.046310, loss_fp: 0.003562, loss_freq: 0.013737
[17:00:59.532] iteration 13893: loss: 0.040045, loss_s1: 0.026288, loss_fp: 0.001500, loss_freq: 0.009317
[17:01:00.159] iteration 13894: loss: 0.053467, loss_s1: 0.028593, loss_fp: 0.004818, loss_freq: 0.035270
[17:01:00.810] iteration 13895: loss: 0.056834, loss_s1: 0.049945, loss_fp: 0.006886, loss_freq: 0.016914
[17:01:01.444] iteration 13896: loss: 0.057338, loss_s1: 0.051213, loss_fp: 0.000969, loss_freq: 0.027648
[17:01:02.079] iteration 13897: loss: 0.072140, loss_s1: 0.063849, loss_fp: 0.001453, loss_freq: 0.045725
[17:01:02.710] iteration 13898: loss: 0.056572, loss_s1: 0.038738, loss_fp: 0.000863, loss_freq: 0.020146
[17:01:03.346] iteration 13899: loss: 0.057966, loss_s1: 0.042139, loss_fp: 0.003806, loss_freq: 0.030543
[17:01:03.981] iteration 13900: loss: 0.050102, loss_s1: 0.023046, loss_fp: 0.000556, loss_freq: 0.025258
[17:01:04.616] iteration 13901: loss: 0.042039, loss_s1: 0.030732, loss_fp: 0.000683, loss_freq: 0.009082
[17:01:05.245] iteration 13902: loss: 0.065449, loss_s1: 0.066182, loss_fp: 0.001985, loss_freq: 0.019258
[17:01:05.875] iteration 13903: loss: 0.042089, loss_s1: 0.038625, loss_fp: 0.001030, loss_freq: 0.007379
[17:01:06.505] iteration 13904: loss: 0.076551, loss_s1: 0.039394, loss_fp: 0.001075, loss_freq: 0.048540
[17:01:07.136] iteration 13905: loss: 0.035406, loss_s1: 0.010500, loss_fp: 0.000707, loss_freq: 0.011319
[17:01:07.762] iteration 13906: loss: 0.031234, loss_s1: 0.010855, loss_fp: 0.000677, loss_freq: 0.014010
[17:01:08.392] iteration 13907: loss: 0.035220, loss_s1: 0.019823, loss_fp: 0.001714, loss_freq: 0.009330
[17:01:09.025] iteration 13908: loss: 0.044247, loss_s1: 0.035396, loss_fp: 0.000817, loss_freq: 0.017267
[17:01:09.654] iteration 13909: loss: 0.051370, loss_s1: 0.024031, loss_fp: 0.002311, loss_freq: 0.020194
[17:01:10.281] iteration 13910: loss: 0.057864, loss_s1: 0.028397, loss_fp: 0.006077, loss_freq: 0.026428
[17:01:10.915] iteration 13911: loss: 0.060705, loss_s1: 0.023471, loss_fp: 0.004388, loss_freq: 0.007875
[17:01:11.542] iteration 13912: loss: 0.091046, loss_s1: 0.042148, loss_fp: 0.003465, loss_freq: 0.094406
[17:01:12.170] iteration 13913: loss: 0.054500, loss_s1: 0.018104, loss_fp: 0.001532, loss_freq: 0.041149
[17:01:12.794] iteration 13914: loss: 0.065194, loss_s1: 0.066032, loss_fp: 0.003797, loss_freq: 0.022757
[17:01:13.422] iteration 13915: loss: 0.044196, loss_s1: 0.028594, loss_fp: 0.001287, loss_freq: 0.014856
[17:01:14.054] iteration 13916: loss: 0.070306, loss_s1: 0.059196, loss_fp: 0.003672, loss_freq: 0.032063
[17:01:14.687] iteration 13917: loss: 0.076476, loss_s1: 0.063622, loss_fp: 0.006621, loss_freq: 0.037563
[17:01:15.313] iteration 13918: loss: 0.041272, loss_s1: 0.012964, loss_fp: 0.000553, loss_freq: 0.031419
[17:01:15.938] iteration 13919: loss: 0.037994, loss_s1: 0.012851, loss_fp: 0.006365, loss_freq: 0.015262
[17:01:16.566] iteration 13920: loss: 0.031205, loss_s1: 0.011585, loss_fp: 0.001663, loss_freq: 0.007724
[17:01:17.193] iteration 13921: loss: 0.087618, loss_s1: 0.086038, loss_fp: 0.001216, loss_freq: 0.055910
[17:01:17.820] iteration 13922: loss: 0.084369, loss_s1: 0.053020, loss_fp: 0.012259, loss_freq: 0.049887
[17:01:18.444] iteration 13923: loss: 0.067087, loss_s1: 0.049851, loss_fp: 0.013126, loss_freq: 0.031568
[17:01:19.067] iteration 13924: loss: 0.043445, loss_s1: 0.036758, loss_fp: 0.002075, loss_freq: 0.011081
[17:01:19.691] iteration 13925: loss: 0.032386, loss_s1: 0.024307, loss_fp: 0.000528, loss_freq: 0.011831
[17:01:20.319] iteration 13926: loss: 0.044400, loss_s1: 0.023665, loss_fp: 0.002798, loss_freq: 0.019973
[17:01:20.945] iteration 13927: loss: 0.063822, loss_s1: 0.043415, loss_fp: 0.007195, loss_freq: 0.034448
[17:01:21.569] iteration 13928: loss: 0.084714, loss_s1: 0.090609, loss_fp: 0.001930, loss_freq: 0.037703
[17:01:22.196] iteration 13929: loss: 0.121665, loss_s1: 0.084129, loss_fp: 0.010925, loss_freq: 0.112545
[17:01:22.819] iteration 13930: loss: 0.076291, loss_s1: 0.057615, loss_fp: 0.002675, loss_freq: 0.045913
[17:01:23.443] iteration 13931: loss: 0.124338, loss_s1: 0.114225, loss_fp: 0.004240, loss_freq: 0.092213
[17:01:24.067] iteration 13932: loss: 0.032286, loss_s1: 0.011050, loss_fp: 0.001646, loss_freq: 0.013605
[17:01:24.693] iteration 13933: loss: 0.085159, loss_s1: 0.087712, loss_fp: 0.006537, loss_freq: 0.019383
[17:01:25.322] iteration 13934: loss: 0.054131, loss_s1: 0.043665, loss_fp: 0.003356, loss_freq: 0.021179
[17:01:25.946] iteration 13935: loss: 0.090834, loss_s1: 0.097061, loss_fp: 0.001000, loss_freq: 0.030605
[17:01:26.571] iteration 13936: loss: 0.075455, loss_s1: 0.023695, loss_fp: 0.000669, loss_freq: 0.055114
[17:01:27.193] iteration 13937: loss: 0.062821, loss_s1: 0.041963, loss_fp: 0.004182, loss_freq: 0.026245
[17:01:27.818] iteration 13938: loss: 0.088901, loss_s1: 0.100855, loss_fp: 0.006604, loss_freq: 0.016535
[17:01:28.443] iteration 13939: loss: 0.070252, loss_s1: 0.020798, loss_fp: 0.001415, loss_freq: 0.021672
[17:01:29.067] iteration 13940: loss: 0.053067, loss_s1: 0.031433, loss_fp: 0.000904, loss_freq: 0.013332
[17:01:29.691] iteration 13941: loss: 0.054095, loss_s1: 0.028608, loss_fp: 0.007043, loss_freq: 0.026940
[17:01:30.315] iteration 13942: loss: 0.059867, loss_s1: 0.044215, loss_fp: 0.002322, loss_freq: 0.027015
[17:01:30.934] iteration 13943: loss: 0.050183, loss_s1: 0.040193, loss_fp: 0.000617, loss_freq: 0.013109
[17:01:31.557] iteration 13944: loss: 0.066881, loss_s1: 0.019504, loss_fp: 0.000631, loss_freq: 0.043252
[17:01:32.177] iteration 13945: loss: 0.047667, loss_s1: 0.042401, loss_fp: 0.001473, loss_freq: 0.012869
[17:01:32.805] iteration 13946: loss: 0.088222, loss_s1: 0.080038, loss_fp: 0.014511, loss_freq: 0.042652
[17:01:33.431] iteration 13947: loss: 0.073624, loss_s1: 0.057458, loss_fp: 0.011761, loss_freq: 0.043191
[17:01:34.057] iteration 13948: loss: 0.077966, loss_s1: 0.045366, loss_fp: 0.005335, loss_freq: 0.060292
[17:01:34.682] iteration 13949: loss: 0.091194, loss_s1: 0.060669, loss_fp: 0.012395, loss_freq: 0.047964
[17:01:35.302] iteration 13950: loss: 0.055831, loss_s1: 0.035849, loss_fp: 0.001636, loss_freq: 0.024298
[17:01:35.941] iteration 13951: loss: 0.064222, loss_s1: 0.038640, loss_fp: 0.005222, loss_freq: 0.015652
[17:01:36.575] iteration 13952: loss: 0.057646, loss_s1: 0.041329, loss_fp: 0.005162, loss_freq: 0.032934
[17:01:37.207] iteration 13953: loss: 0.030785, loss_s1: 0.006515, loss_fp: 0.000374, loss_freq: 0.009155
[17:01:37.865] iteration 13954: loss: 0.137263, loss_s1: 0.136267, loss_fp: 0.001054, loss_freq: 0.069287
[17:01:38.547] iteration 13955: loss: 0.131641, loss_s1: 0.120322, loss_fp: 0.006515, loss_freq: 0.081001
[17:01:39.231] iteration 13956: loss: 0.046974, loss_s1: 0.031963, loss_fp: 0.005771, loss_freq: 0.022944
[17:01:39.896] iteration 13957: loss: 0.054799, loss_s1: 0.027886, loss_fp: 0.008907, loss_freq: 0.017032
[17:01:40.566] iteration 13958: loss: 0.090930, loss_s1: 0.090291, loss_fp: 0.001499, loss_freq: 0.042041
[17:01:41.229] iteration 13959: loss: 0.099562, loss_s1: 0.073365, loss_fp: 0.004440, loss_freq: 0.025430
[17:01:41.887] iteration 13960: loss: 0.068775, loss_s1: 0.043829, loss_fp: 0.015459, loss_freq: 0.015458
[17:01:42.514] iteration 13961: loss: 0.034590, loss_s1: 0.015780, loss_fp: 0.001056, loss_freq: 0.008162
[17:01:43.150] iteration 13962: loss: 0.077233, loss_s1: 0.065299, loss_fp: 0.011643, loss_freq: 0.031479
[17:01:43.782] iteration 13963: loss: 0.036668, loss_s1: 0.011040, loss_fp: 0.001979, loss_freq: 0.028390
[17:01:44.413] iteration 13964: loss: 0.047053, loss_s1: 0.044266, loss_fp: 0.001932, loss_freq: 0.008148
[17:01:45.040] iteration 13965: loss: 0.070522, loss_s1: 0.046020, loss_fp: 0.005675, loss_freq: 0.022956
[17:01:45.677] iteration 13966: loss: 0.122351, loss_s1: 0.073014, loss_fp: 0.002932, loss_freq: 0.126937
[17:01:46.310] iteration 13967: loss: 0.038507, loss_s1: 0.019850, loss_fp: 0.001017, loss_freq: 0.016928
[17:01:46.938] iteration 13968: loss: 0.125499, loss_s1: 0.081645, loss_fp: 0.002286, loss_freq: 0.025872
[17:01:47.567] iteration 13969: loss: 0.070619, loss_s1: 0.058029, loss_fp: 0.018547, loss_freq: 0.009856
[17:01:48.195] iteration 13970: loss: 0.038190, loss_s1: 0.018841, loss_fp: 0.003827, loss_freq: 0.012401
[17:01:48.827] iteration 13971: loss: 0.056575, loss_s1: 0.040986, loss_fp: 0.000333, loss_freq: 0.034804
[17:01:49.456] iteration 13972: loss: 0.073255, loss_s1: 0.030641, loss_fp: 0.004159, loss_freq: 0.027201
[17:01:50.082] iteration 13973: loss: 0.042504, loss_s1: 0.036540, loss_fp: 0.000227, loss_freq: 0.006525
[17:01:50.744] iteration 13974: loss: 0.112553, loss_s1: 0.091549, loss_fp: 0.000928, loss_freq: 0.050520
[17:01:51.406] iteration 13975: loss: 0.050086, loss_s1: 0.038884, loss_fp: 0.000474, loss_freq: 0.025151
[17:01:52.034] iteration 13976: loss: 0.050456, loss_s1: 0.036077, loss_fp: 0.001818, loss_freq: 0.013585
[17:01:52.660] iteration 13977: loss: 0.086977, loss_s1: 0.057195, loss_fp: 0.004910, loss_freq: 0.063284
[17:01:53.304] iteration 13978: loss: 0.058263, loss_s1: 0.033898, loss_fp: 0.005093, loss_freq: 0.018059
[17:01:53.951] iteration 13979: loss: 0.057103, loss_s1: 0.047128, loss_fp: 0.003630, loss_freq: 0.020703
[17:01:54.649] iteration 13980: loss: 0.049906, loss_s1: 0.047588, loss_fp: 0.002035, loss_freq: 0.009390
[17:01:55.470] iteration 13981: loss: 0.062363, loss_s1: 0.040851, loss_fp: 0.003135, loss_freq: 0.035828
[17:01:56.145] iteration 13982: loss: 0.082710, loss_s1: 0.076349, loss_fp: 0.001498, loss_freq: 0.035995
[17:01:56.766] iteration 13983: loss: 0.050866, loss_s1: 0.012841, loss_fp: 0.001335, loss_freq: 0.013245
[17:01:57.388] iteration 13984: loss: 0.053006, loss_s1: 0.037877, loss_fp: 0.003942, loss_freq: 0.019594
[17:01:58.010] iteration 13985: loss: 0.036788, loss_s1: 0.017031, loss_fp: 0.002219, loss_freq: 0.016562
[17:01:58.634] iteration 13986: loss: 0.058776, loss_s1: 0.018841, loss_fp: 0.001958, loss_freq: 0.041405
[17:01:59.262] iteration 13987: loss: 0.089796, loss_s1: 0.095254, loss_fp: 0.005085, loss_freq: 0.033518
[17:01:59.887] iteration 13988: loss: 0.037688, loss_s1: 0.016091, loss_fp: 0.001681, loss_freq: 0.015191
[17:02:00.507] iteration 13989: loss: 0.061548, loss_s1: 0.051614, loss_fp: 0.001279, loss_freq: 0.013982
[17:02:01.135] iteration 13990: loss: 0.090006, loss_s1: 0.062386, loss_fp: 0.002969, loss_freq: 0.047051
[17:02:01.762] iteration 13991: loss: 0.056301, loss_s1: 0.047110, loss_fp: 0.002957, loss_freq: 0.016719
[17:02:02.388] iteration 13992: loss: 0.066163, loss_s1: 0.037129, loss_fp: 0.002441, loss_freq: 0.026819
[17:02:03.015] iteration 13993: loss: 0.109850, loss_s1: 0.108954, loss_fp: 0.002652, loss_freq: 0.072450
[17:02:03.644] iteration 13994: loss: 0.055615, loss_s1: 0.044985, loss_fp: 0.000267, loss_freq: 0.014748
[17:02:04.271] iteration 13995: loss: 0.051523, loss_s1: 0.040350, loss_fp: 0.006540, loss_freq: 0.016777
[17:02:04.892] iteration 13996: loss: 0.094534, loss_s1: 0.081083, loss_fp: 0.005450, loss_freq: 0.033867
[17:02:05.518] iteration 13997: loss: 0.050227, loss_s1: 0.015249, loss_fp: 0.000705, loss_freq: 0.030191
[17:02:06.148] iteration 13998: loss: 0.160718, loss_s1: 0.188677, loss_fp: 0.007644, loss_freq: 0.073802
[17:02:06.773] iteration 13999: loss: 0.061395, loss_s1: 0.036281, loss_fp: 0.005849, loss_freq: 0.022241
[17:02:07.403] iteration 14000: loss: 0.056008, loss_s1: 0.032284, loss_fp: 0.008179, loss_freq: 0.020145
[17:02:10.671] iteration 14000 : mean_dice : 0.730179
[17:02:11.320] iteration 14001: loss: 0.043481, loss_s1: 0.038510, loss_fp: 0.000325, loss_freq: 0.004884
[17:02:11.948] iteration 14002: loss: 0.057698, loss_s1: 0.020497, loss_fp: 0.001647, loss_freq: 0.040997
[17:02:12.577] iteration 14003: loss: 0.039610, loss_s1: 0.014584, loss_fp: 0.001157, loss_freq: 0.015611
[17:02:13.206] iteration 14004: loss: 0.077974, loss_s1: 0.054955, loss_fp: 0.002308, loss_freq: 0.031128
[17:02:13.834] iteration 14005: loss: 0.059745, loss_s1: 0.047707, loss_fp: 0.013035, loss_freq: 0.020829
[17:02:14.453] iteration 14006: loss: 0.053247, loss_s1: 0.042592, loss_fp: 0.003232, loss_freq: 0.026580
[17:02:15.075] iteration 14007: loss: 0.062005, loss_s1: 0.020035, loss_fp: 0.001669, loss_freq: 0.050909
[17:02:16.084] iteration 14008: loss: 0.038920, loss_s1: 0.034132, loss_fp: 0.002261, loss_freq: 0.006557
[17:02:16.744] iteration 14009: loss: 0.064379, loss_s1: 0.043232, loss_fp: 0.004316, loss_freq: 0.039487
[17:02:17.407] iteration 14010: loss: 0.053238, loss_s1: 0.022612, loss_fp: 0.003166, loss_freq: 0.026718
[17:02:18.061] iteration 14011: loss: 0.042504, loss_s1: 0.015358, loss_fp: 0.004519, loss_freq: 0.022399
[17:02:18.683] iteration 14012: loss: 0.049295, loss_s1: 0.050269, loss_fp: 0.003526, loss_freq: 0.007495
[17:02:19.310] iteration 14013: loss: 0.075705, loss_s1: 0.034623, loss_fp: 0.005541, loss_freq: 0.038666
[17:02:19.939] iteration 14014: loss: 0.032597, loss_s1: 0.014012, loss_fp: 0.002775, loss_freq: 0.007466
[17:02:20.594] iteration 14015: loss: 0.054390, loss_s1: 0.025286, loss_fp: 0.001601, loss_freq: 0.028751
[17:02:21.217] iteration 14016: loss: 0.057485, loss_s1: 0.042574, loss_fp: 0.012088, loss_freq: 0.026925
[17:02:21.843] iteration 14017: loss: 0.060564, loss_s1: 0.030705, loss_fp: 0.005217, loss_freq: 0.038845
[17:02:22.472] iteration 14018: loss: 0.037016, loss_s1: 0.024057, loss_fp: 0.003718, loss_freq: 0.006942
[17:02:23.124] iteration 14019: loss: 0.072735, loss_s1: 0.080609, loss_fp: 0.003404, loss_freq: 0.016104
[17:02:23.770] iteration 14020: loss: 0.061062, loss_s1: 0.016890, loss_fp: 0.003266, loss_freq: 0.066511
[17:02:24.405] iteration 14021: loss: 0.046824, loss_s1: 0.014214, loss_fp: 0.000786, loss_freq: 0.038591
[17:02:25.079] iteration 14022: loss: 0.044950, loss_s1: 0.036781, loss_fp: 0.005419, loss_freq: 0.005819
[17:02:25.720] iteration 14023: loss: 0.181846, loss_s1: 0.178366, loss_fp: 0.002036, loss_freq: 0.142675
[17:02:26.357] iteration 14024: loss: 0.072256, loss_s1: 0.045327, loss_fp: 0.005863, loss_freq: 0.015715
[17:02:27.009] iteration 14025: loss: 0.063737, loss_s1: 0.043420, loss_fp: 0.000751, loss_freq: 0.033557
[17:02:27.642] iteration 14026: loss: 0.069811, loss_s1: 0.047546, loss_fp: 0.001692, loss_freq: 0.027239
[17:02:28.292] iteration 14027: loss: 0.093324, loss_s1: 0.055375, loss_fp: 0.003595, loss_freq: 0.024863
[17:02:28.933] iteration 14028: loss: 0.038923, loss_s1: 0.029450, loss_fp: 0.002057, loss_freq: 0.004694
[17:02:29.572] iteration 14029: loss: 0.062246, loss_s1: 0.059498, loss_fp: 0.001347, loss_freq: 0.021462
[17:02:30.205] iteration 14030: loss: 0.073533, loss_s1: 0.046317, loss_fp: 0.001986, loss_freq: 0.014615
[17:02:30.845] iteration 14031: loss: 0.114867, loss_s1: 0.068885, loss_fp: 0.004539, loss_freq: 0.114130
[17:02:31.480] iteration 14032: loss: 0.033862, loss_s1: 0.011598, loss_fp: 0.001671, loss_freq: 0.020005
[17:02:32.210] iteration 14033: loss: 0.048883, loss_s1: 0.025607, loss_fp: 0.001250, loss_freq: 0.022249
[17:02:32.842] iteration 14034: loss: 0.035567, loss_s1: 0.020601, loss_fp: 0.001512, loss_freq: 0.009297
[17:02:33.477] iteration 14035: loss: 0.104067, loss_s1: 0.091836, loss_fp: 0.005506, loss_freq: 0.068526
[17:02:34.109] iteration 14036: loss: 0.069423, loss_s1: 0.055213, loss_fp: 0.005036, loss_freq: 0.033828
[17:02:34.748] iteration 14037: loss: 0.040110, loss_s1: 0.029919, loss_fp: 0.003083, loss_freq: 0.009051
[17:02:35.379] iteration 14038: loss: 0.054568, loss_s1: 0.036942, loss_fp: 0.003725, loss_freq: 0.018327
[17:02:36.007] iteration 14039: loss: 0.047973, loss_s1: 0.038500, loss_fp: 0.006997, loss_freq: 0.009437
[17:02:36.633] iteration 14040: loss: 0.047357, loss_s1: 0.031743, loss_fp: 0.007216, loss_freq: 0.021410
[17:02:37.267] iteration 14041: loss: 0.043322, loss_s1: 0.044634, loss_fp: 0.003815, loss_freq: 0.005820
[17:02:37.902] iteration 14042: loss: 0.062735, loss_s1: 0.036295, loss_fp: 0.002903, loss_freq: 0.021175
[17:02:38.532] iteration 14043: loss: 0.062691, loss_s1: 0.055972, loss_fp: 0.004393, loss_freq: 0.030242
[17:02:39.167] iteration 14044: loss: 0.112160, loss_s1: 0.092080, loss_fp: 0.006250, loss_freq: 0.050948
[17:02:39.799] iteration 14045: loss: 0.058950, loss_s1: 0.022908, loss_fp: 0.005073, loss_freq: 0.036559
[17:02:40.432] iteration 14046: loss: 0.120348, loss_s1: 0.071127, loss_fp: 0.005933, loss_freq: 0.089855
[17:02:41.064] iteration 14047: loss: 0.071625, loss_s1: 0.080995, loss_fp: 0.004302, loss_freq: 0.019243
[17:02:41.730] iteration 14048: loss: 0.068214, loss_s1: 0.046182, loss_fp: 0.002212, loss_freq: 0.025787
[17:02:42.356] iteration 14049: loss: 0.113200, loss_s1: 0.115075, loss_fp: 0.004724, loss_freq: 0.071479
[17:02:43.027] iteration 14050: loss: 0.090008, loss_s1: 0.087286, loss_fp: 0.015395, loss_freq: 0.041294
[17:02:43.653] iteration 14051: loss: 0.075557, loss_s1: 0.067063, loss_fp: 0.001117, loss_freq: 0.037324
[17:02:44.285] iteration 14052: loss: 0.065066, loss_s1: 0.061082, loss_fp: 0.001043, loss_freq: 0.024179
[17:02:44.912] iteration 14053: loss: 0.069185, loss_s1: 0.060055, loss_fp: 0.002970, loss_freq: 0.014633
[17:02:45.534] iteration 14054: loss: 0.047102, loss_s1: 0.044801, loss_fp: 0.002503, loss_freq: 0.009319
[17:02:46.162] iteration 14055: loss: 0.072031, loss_s1: 0.045963, loss_fp: 0.010509, loss_freq: 0.039175
[17:02:46.789] iteration 14056: loss: 0.072240, loss_s1: 0.073835, loss_fp: 0.002704, loss_freq: 0.012707
[17:02:47.416] iteration 14057: loss: 0.068784, loss_s1: 0.032759, loss_fp: 0.007414, loss_freq: 0.059463
[17:02:48.042] iteration 14058: loss: 0.064602, loss_s1: 0.041141, loss_fp: 0.006287, loss_freq: 0.044573
[17:02:48.668] iteration 14059: loss: 0.053353, loss_s1: 0.018019, loss_fp: 0.001386, loss_freq: 0.021154
[17:02:49.299] iteration 14060: loss: 0.063646, loss_s1: 0.043774, loss_fp: 0.003367, loss_freq: 0.032609
[17:02:49.923] iteration 14061: loss: 0.075250, loss_s1: 0.068244, loss_fp: 0.001086, loss_freq: 0.039082
[17:02:50.550] iteration 14062: loss: 0.040351, loss_s1: 0.023726, loss_fp: 0.000702, loss_freq: 0.017464
[17:02:51.172] iteration 14063: loss: 0.086288, loss_s1: 0.094917, loss_fp: 0.002658, loss_freq: 0.035596
[17:02:51.799] iteration 14064: loss: 0.033843, loss_s1: 0.011728, loss_fp: 0.000908, loss_freq: 0.014922
[17:02:52.425] iteration 14065: loss: 0.082056, loss_s1: 0.070552, loss_fp: 0.004828, loss_freq: 0.015205
[17:02:53.050] iteration 14066: loss: 0.056713, loss_s1: 0.058500, loss_fp: 0.004646, loss_freq: 0.013364
[17:02:53.679] iteration 14067: loss: 0.057151, loss_s1: 0.031356, loss_fp: 0.001428, loss_freq: 0.030624
[17:02:54.303] iteration 14068: loss: 0.064068, loss_s1: 0.048749, loss_fp: 0.002013, loss_freq: 0.015844
[17:02:54.930] iteration 14069: loss: 0.041472, loss_s1: 0.030889, loss_fp: 0.000936, loss_freq: 0.014615
[17:02:55.555] iteration 14070: loss: 0.042938, loss_s1: 0.019516, loss_fp: 0.002758, loss_freq: 0.010366
[17:02:56.178] iteration 14071: loss: 0.053622, loss_s1: 0.022319, loss_fp: 0.000665, loss_freq: 0.029038
[17:02:56.804] iteration 14072: loss: 0.075059, loss_s1: 0.068285, loss_fp: 0.004490, loss_freq: 0.038436
[17:02:57.430] iteration 14073: loss: 0.075439, loss_s1: 0.043736, loss_fp: 0.013366, loss_freq: 0.055839
[17:02:58.055] iteration 14074: loss: 0.068960, loss_s1: 0.026719, loss_fp: 0.005259, loss_freq: 0.051510
[17:02:58.679] iteration 14075: loss: 0.087768, loss_s1: 0.082327, loss_fp: 0.003516, loss_freq: 0.052132
[17:02:59.306] iteration 14076: loss: 0.036648, loss_s1: 0.026814, loss_fp: 0.003693, loss_freq: 0.012456
[17:02:59.940] iteration 14077: loss: 0.083342, loss_s1: 0.049372, loss_fp: 0.004087, loss_freq: 0.016907
[17:03:00.563] iteration 14078: loss: 0.069991, loss_s1: 0.048296, loss_fp: 0.004607, loss_freq: 0.042970
[17:03:01.191] iteration 14079: loss: 0.092182, loss_s1: 0.045961, loss_fp: 0.002953, loss_freq: 0.048429
[17:03:01.821] iteration 14080: loss: 0.054220, loss_s1: 0.042430, loss_fp: 0.000344, loss_freq: 0.029768
[17:03:02.449] iteration 14081: loss: 0.056095, loss_s1: 0.040595, loss_fp: 0.005594, loss_freq: 0.015574
[17:03:03.084] iteration 14082: loss: 0.054607, loss_s1: 0.057013, loss_fp: 0.001775, loss_freq: 0.015267
[17:03:03.716] iteration 14083: loss: 0.104587, loss_s1: 0.071689, loss_fp: 0.001769, loss_freq: 0.024366
[17:03:04.337] iteration 14084: loss: 0.060459, loss_s1: 0.038444, loss_fp: 0.003394, loss_freq: 0.036520
[17:03:04.967] iteration 14085: loss: 0.048991, loss_s1: 0.044408, loss_fp: 0.000746, loss_freq: 0.010764
[17:03:05.592] iteration 14086: loss: 0.048988, loss_s1: 0.039170, loss_fp: 0.000971, loss_freq: 0.010167
[17:03:06.214] iteration 14087: loss: 0.077457, loss_s1: 0.062119, loss_fp: 0.001055, loss_freq: 0.046790
[17:03:06.843] iteration 14088: loss: 0.063113, loss_s1: 0.026023, loss_fp: 0.003449, loss_freq: 0.039467
[17:03:07.469] iteration 14089: loss: 0.068956, loss_s1: 0.084050, loss_fp: 0.002149, loss_freq: 0.018408
[17:03:08.092] iteration 14090: loss: 0.055636, loss_s1: 0.045029, loss_fp: 0.004929, loss_freq: 0.022847
[17:03:08.720] iteration 14091: loss: 0.047195, loss_s1: 0.032095, loss_fp: 0.000469, loss_freq: 0.014225
[17:03:09.343] iteration 14092: loss: 0.088337, loss_s1: 0.057789, loss_fp: 0.005558, loss_freq: 0.083980
[17:03:09.967] iteration 14093: loss: 0.035950, loss_s1: 0.016152, loss_fp: 0.003294, loss_freq: 0.009018
[17:03:10.589] iteration 14094: loss: 0.071531, loss_s1: 0.046898, loss_fp: 0.002440, loss_freq: 0.031944
[17:03:11.212] iteration 14095: loss: 0.032410, loss_s1: 0.014533, loss_fp: 0.000355, loss_freq: 0.010174
[17:03:11.833] iteration 14096: loss: 0.056978, loss_s1: 0.034705, loss_fp: 0.006056, loss_freq: 0.031420
[17:03:12.457] iteration 14097: loss: 0.083151, loss_s1: 0.064554, loss_fp: 0.005975, loss_freq: 0.040639
[17:03:13.078] iteration 14098: loss: 0.065919, loss_s1: 0.054876, loss_fp: 0.003421, loss_freq: 0.033928
[17:03:13.700] iteration 14099: loss: 0.064317, loss_s1: 0.041024, loss_fp: 0.001647, loss_freq: 0.016484
[17:03:14.325] iteration 14100: loss: 0.047991, loss_s1: 0.006100, loss_fp: 0.000306, loss_freq: 0.015222
[17:03:14.948] iteration 14101: loss: 0.031048, loss_s1: 0.019338, loss_fp: 0.001269, loss_freq: 0.006460
[17:03:15.567] iteration 14102: loss: 0.074102, loss_s1: 0.062699, loss_fp: 0.000707, loss_freq: 0.036291
[17:03:16.192] iteration 14103: loss: 0.057354, loss_s1: 0.051306, loss_fp: 0.003783, loss_freq: 0.015322
[17:03:16.815] iteration 14104: loss: 0.042075, loss_s1: 0.017569, loss_fp: 0.000442, loss_freq: 0.015599
[17:03:17.440] iteration 14105: loss: 0.057887, loss_s1: 0.012486, loss_fp: 0.001786, loss_freq: 0.045181
[17:03:18.062] iteration 14106: loss: 0.054304, loss_s1: 0.022465, loss_fp: 0.000661, loss_freq: 0.023880
[17:03:18.683] iteration 14107: loss: 0.045870, loss_s1: 0.043681, loss_fp: 0.000711, loss_freq: 0.013148
[17:03:19.305] iteration 14108: loss: 0.053379, loss_s1: 0.044199, loss_fp: 0.003339, loss_freq: 0.010711
[17:03:19.921] iteration 14109: loss: 0.061637, loss_s1: 0.035096, loss_fp: 0.001484, loss_freq: 0.046558
[17:03:20.547] iteration 14110: loss: 0.080859, loss_s1: 0.054189, loss_fp: 0.002593, loss_freq: 0.065358
[17:03:21.173] iteration 14111: loss: 0.058718, loss_s1: 0.039598, loss_fp: 0.010720, loss_freq: 0.027334
[17:03:21.797] iteration 14112: loss: 0.051268, loss_s1: 0.016712, loss_fp: 0.001380, loss_freq: 0.013334
[17:03:22.420] iteration 14113: loss: 0.060904, loss_s1: 0.042591, loss_fp: 0.005385, loss_freq: 0.024801
[17:03:23.043] iteration 14114: loss: 0.034645, loss_s1: 0.009633, loss_fp: 0.000218, loss_freq: 0.016447
[17:03:23.665] iteration 14115: loss: 0.081152, loss_s1: 0.071331, loss_fp: 0.002781, loss_freq: 0.051575
[17:03:24.288] iteration 14116: loss: 0.108902, loss_s1: 0.084383, loss_fp: 0.004195, loss_freq: 0.073095
[17:03:24.912] iteration 14117: loss: 0.050901, loss_s1: 0.035776, loss_fp: 0.002580, loss_freq: 0.025354
[17:03:25.535] iteration 14118: loss: 0.062080, loss_s1: 0.044899, loss_fp: 0.006049, loss_freq: 0.020503
[17:03:26.156] iteration 14119: loss: 0.068833, loss_s1: 0.039846, loss_fp: 0.004002, loss_freq: 0.055401
[17:03:26.777] iteration 14120: loss: 0.117353, loss_s1: 0.118510, loss_fp: 0.002360, loss_freq: 0.036930
[17:03:27.400] iteration 14121: loss: 0.050119, loss_s1: 0.031678, loss_fp: 0.003724, loss_freq: 0.022103
[17:03:28.022] iteration 14122: loss: 0.032427, loss_s1: 0.015770, loss_fp: 0.000621, loss_freq: 0.003521
[17:03:28.647] iteration 14123: loss: 0.091368, loss_s1: 0.048315, loss_fp: 0.007977, loss_freq: 0.056473
[17:03:29.268] iteration 14124: loss: 0.080019, loss_s1: 0.105906, loss_fp: 0.009486, loss_freq: 0.010404
[17:03:29.891] iteration 14125: loss: 0.035819, loss_s1: 0.020519, loss_fp: 0.000974, loss_freq: 0.009069
[17:03:30.511] iteration 14126: loss: 0.077293, loss_s1: 0.060889, loss_fp: 0.001181, loss_freq: 0.046438
[17:03:31.133] iteration 14127: loss: 0.093151, loss_s1: 0.054755, loss_fp: 0.020406, loss_freq: 0.066109
[17:03:31.755] iteration 14128: loss: 0.046163, loss_s1: 0.020803, loss_fp: 0.000969, loss_freq: 0.031932
[17:03:32.378] iteration 14129: loss: 0.093300, loss_s1: 0.052368, loss_fp: 0.012886, loss_freq: 0.048303
[17:03:32.999] iteration 14130: loss: 0.045668, loss_s1: 0.044340, loss_fp: 0.001193, loss_freq: 0.008983
[17:03:33.617] iteration 14131: loss: 0.059243, loss_s1: 0.046083, loss_fp: 0.001776, loss_freq: 0.013065
[17:03:34.236] iteration 14132: loss: 0.068339, loss_s1: 0.037668, loss_fp: 0.001865, loss_freq: 0.047130
[17:03:34.857] iteration 14133: loss: 0.074996, loss_s1: 0.081336, loss_fp: 0.001161, loss_freq: 0.015753
[17:03:35.478] iteration 14134: loss: 0.068218, loss_s1: 0.055964, loss_fp: 0.005762, loss_freq: 0.014390
[17:03:36.099] iteration 14135: loss: 0.082077, loss_s1: 0.041990, loss_fp: 0.000854, loss_freq: 0.061214
[17:03:36.727] iteration 14136: loss: 0.051901, loss_s1: 0.030552, loss_fp: 0.000808, loss_freq: 0.028475
[17:03:37.348] iteration 14137: loss: 0.043330, loss_s1: 0.045152, loss_fp: 0.001183, loss_freq: 0.005613
[17:03:37.970] iteration 14138: loss: 0.088407, loss_s1: 0.052626, loss_fp: 0.011232, loss_freq: 0.066434
[17:03:38.597] iteration 14139: loss: 0.090730, loss_s1: 0.130599, loss_fp: 0.000328, loss_freq: 0.011385
[17:03:39.217] iteration 14140: loss: 0.072818, loss_s1: 0.063776, loss_fp: 0.001707, loss_freq: 0.029034
[17:03:39.835] iteration 14141: loss: 0.057381, loss_s1: 0.050998, loss_fp: 0.010502, loss_freq: 0.012776
[17:03:40.456] iteration 14142: loss: 0.083485, loss_s1: 0.066577, loss_fp: 0.006148, loss_freq: 0.049832
[17:03:41.081] iteration 14143: loss: 0.049464, loss_s1: 0.040527, loss_fp: 0.002838, loss_freq: 0.022249
[17:03:41.703] iteration 14144: loss: 0.053249, loss_s1: 0.023153, loss_fp: 0.000837, loss_freq: 0.037596
[17:03:42.324] iteration 14145: loss: 0.065193, loss_s1: 0.054947, loss_fp: 0.002723, loss_freq: 0.034922
[17:03:42.947] iteration 14146: loss: 0.042143, loss_s1: 0.020670, loss_fp: 0.008443, loss_freq: 0.014327
[17:03:43.569] iteration 14147: loss: 0.069691, loss_s1: 0.048809, loss_fp: 0.005896, loss_freq: 0.023649
[17:03:44.189] iteration 14148: loss: 0.089862, loss_s1: 0.100322, loss_fp: 0.009073, loss_freq: 0.031386
[17:03:44.848] iteration 14149: loss: 0.063639, loss_s1: 0.036334, loss_fp: 0.005909, loss_freq: 0.026578
[17:03:45.475] iteration 14150: loss: 0.088661, loss_s1: 0.036366, loss_fp: 0.006053, loss_freq: 0.038305
[17:03:46.096] iteration 14151: loss: 0.081166, loss_s1: 0.087695, loss_fp: 0.006036, loss_freq: 0.026332
[17:03:46.714] iteration 14152: loss: 0.060556, loss_s1: 0.025783, loss_fp: 0.004219, loss_freq: 0.013020
[17:03:47.334] iteration 14153: loss: 0.076687, loss_s1: 0.058440, loss_fp: 0.002824, loss_freq: 0.023275
[17:03:47.955] iteration 14154: loss: 0.125659, loss_s1: 0.091699, loss_fp: 0.005441, loss_freq: 0.118404
[17:03:48.578] iteration 14155: loss: 0.064498, loss_s1: 0.051116, loss_fp: 0.003697, loss_freq: 0.015910
[17:03:49.202] iteration 14156: loss: 0.077905, loss_s1: 0.067765, loss_fp: 0.002035, loss_freq: 0.028034
[17:03:49.820] iteration 14157: loss: 0.136821, loss_s1: 0.119445, loss_fp: 0.003228, loss_freq: 0.071031
[17:03:50.449] iteration 14158: loss: 0.081553, loss_s1: 0.040465, loss_fp: 0.008616, loss_freq: 0.047926
[17:03:51.073] iteration 14159: loss: 0.096423, loss_s1: 0.082303, loss_fp: 0.017669, loss_freq: 0.050337
[17:03:51.694] iteration 14160: loss: 0.069215, loss_s1: 0.071364, loss_fp: 0.000903, loss_freq: 0.019089
[17:03:52.319] iteration 14161: loss: 0.101014, loss_s1: 0.077251, loss_fp: 0.005903, loss_freq: 0.016135
[17:03:52.946] iteration 14162: loss: 0.046803, loss_s1: 0.030241, loss_fp: 0.003893, loss_freq: 0.011934
[17:03:53.570] iteration 14163: loss: 0.103551, loss_s1: 0.076375, loss_fp: 0.003330, loss_freq: 0.036407
[17:03:54.193] iteration 14164: loss: 0.056333, loss_s1: 0.016742, loss_fp: 0.000246, loss_freq: 0.035242
[17:03:54.819] iteration 14165: loss: 0.067727, loss_s1: 0.040295, loss_fp: 0.005120, loss_freq: 0.038193
[17:03:55.443] iteration 14166: loss: 0.098109, loss_s1: 0.081336, loss_fp: 0.004499, loss_freq: 0.061030
[17:03:56.066] iteration 14167: loss: 0.074379, loss_s1: 0.044080, loss_fp: 0.001688, loss_freq: 0.012685
[17:03:56.688] iteration 14168: loss: 0.097741, loss_s1: 0.094925, loss_fp: 0.003283, loss_freq: 0.026593
[17:03:57.654] iteration 14169: loss: 0.060112, loss_s1: 0.015169, loss_fp: 0.001674, loss_freq: 0.013047
[17:03:58.279] iteration 14170: loss: 0.092839, loss_s1: 0.085824, loss_fp: 0.000589, loss_freq: 0.025522
[17:03:58.911] iteration 14171: loss: 0.041891, loss_s1: 0.012530, loss_fp: 0.002309, loss_freq: 0.017442
[17:03:59.546] iteration 14172: loss: 0.049531, loss_s1: 0.033343, loss_fp: 0.000500, loss_freq: 0.012487
[17:04:00.376] iteration 14173: loss: 0.045413, loss_s1: 0.031030, loss_fp: 0.001482, loss_freq: 0.010627
[17:04:01.130] iteration 14174: loss: 0.134475, loss_s1: 0.109857, loss_fp: 0.002188, loss_freq: 0.038168
[17:04:01.753] iteration 14175: loss: 0.061637, loss_s1: 0.053313, loss_fp: 0.000984, loss_freq: 0.023315
[17:04:02.374] iteration 14176: loss: 0.049154, loss_s1: 0.048365, loss_fp: 0.003288, loss_freq: 0.014639
[17:04:02.998] iteration 14177: loss: 0.068861, loss_s1: 0.035658, loss_fp: 0.010143, loss_freq: 0.060314
[17:04:03.622] iteration 14178: loss: 0.054154, loss_s1: 0.043067, loss_fp: 0.003260, loss_freq: 0.012264
[17:04:04.245] iteration 14179: loss: 0.062371, loss_s1: 0.022215, loss_fp: 0.000877, loss_freq: 0.037745
[17:04:04.869] iteration 14180: loss: 0.050916, loss_s1: 0.020941, loss_fp: 0.006046, loss_freq: 0.033331
[17:04:05.496] iteration 14181: loss: 0.090283, loss_s1: 0.058896, loss_fp: 0.014221, loss_freq: 0.070061
[17:04:06.121] iteration 14182: loss: 0.051289, loss_s1: 0.021320, loss_fp: 0.002006, loss_freq: 0.023225
[17:04:06.748] iteration 14183: loss: 0.051103, loss_s1: 0.038772, loss_fp: 0.010603, loss_freq: 0.008846
[17:04:07.370] iteration 14184: loss: 0.069691, loss_s1: 0.058580, loss_fp: 0.001527, loss_freq: 0.032619
[17:04:07.994] iteration 14185: loss: 0.109598, loss_s1: 0.057912, loss_fp: 0.001673, loss_freq: 0.029844
[17:04:08.620] iteration 14186: loss: 0.040120, loss_s1: 0.021993, loss_fp: 0.003374, loss_freq: 0.014422
[17:04:09.246] iteration 14187: loss: 0.088538, loss_s1: 0.016825, loss_fp: 0.001920, loss_freq: 0.023647
[17:04:09.864] iteration 14188: loss: 0.078554, loss_s1: 0.050489, loss_fp: 0.007518, loss_freq: 0.020686
[17:04:10.487] iteration 14189: loss: 0.036226, loss_s1: 0.027189, loss_fp: 0.001323, loss_freq: 0.005462
[17:04:11.112] iteration 14190: loss: 0.057087, loss_s1: 0.044888, loss_fp: 0.002720, loss_freq: 0.016649
[17:04:11.735] iteration 14191: loss: 0.065820, loss_s1: 0.032745, loss_fp: 0.002204, loss_freq: 0.040038
[17:04:12.357] iteration 14192: loss: 0.138961, loss_s1: 0.122990, loss_fp: 0.004074, loss_freq: 0.101068
[17:04:12.983] iteration 14193: loss: 0.059450, loss_s1: 0.057202, loss_fp: 0.000908, loss_freq: 0.025445
[17:04:13.612] iteration 14194: loss: 0.061754, loss_s1: 0.040005, loss_fp: 0.004097, loss_freq: 0.027672
[17:04:14.235] iteration 14195: loss: 0.034259, loss_s1: 0.012154, loss_fp: 0.000290, loss_freq: 0.005295
[17:04:14.859] iteration 14196: loss: 0.081373, loss_s1: 0.058632, loss_fp: 0.001852, loss_freq: 0.030404
[17:04:15.483] iteration 14197: loss: 0.062078, loss_s1: 0.023564, loss_fp: 0.002889, loss_freq: 0.033587
[17:04:16.104] iteration 14198: loss: 0.042395, loss_s1: 0.013150, loss_fp: 0.002093, loss_freq: 0.017275
[17:04:16.729] iteration 14199: loss: 0.054255, loss_s1: 0.056011, loss_fp: 0.005154, loss_freq: 0.010383
[17:04:17.355] iteration 14200: loss: 0.068751, loss_s1: 0.032959, loss_fp: 0.004692, loss_freq: 0.013841
[17:04:21.048] iteration 14200 : mean_dice : 0.737757
[17:04:21.730] iteration 14201: loss: 0.051327, loss_s1: 0.019113, loss_fp: 0.002658, loss_freq: 0.036505
[17:04:22.382] iteration 14202: loss: 0.057984, loss_s1: 0.045239, loss_fp: 0.002146, loss_freq: 0.009045
[17:04:23.029] iteration 14203: loss: 0.083507, loss_s1: 0.023566, loss_fp: 0.002767, loss_freq: 0.015140
[17:04:23.678] iteration 14204: loss: 0.098561, loss_s1: 0.088870, loss_fp: 0.007698, loss_freq: 0.040397
[17:04:24.349] iteration 14205: loss: 0.077300, loss_s1: 0.049079, loss_fp: 0.001236, loss_freq: 0.041659
[17:04:24.989] iteration 14206: loss: 0.075168, loss_s1: 0.054115, loss_fp: 0.000950, loss_freq: 0.022311
[17:04:25.618] iteration 14207: loss: 0.086458, loss_s1: 0.049069, loss_fp: 0.007166, loss_freq: 0.065391
[17:04:26.243] iteration 14208: loss: 0.102485, loss_s1: 0.105568, loss_fp: 0.004082, loss_freq: 0.058630
[17:04:26.867] iteration 14209: loss: 0.061829, loss_s1: 0.036748, loss_fp: 0.002014, loss_freq: 0.021197
[17:04:27.492] iteration 14210: loss: 0.108192, loss_s1: 0.091552, loss_fp: 0.009830, loss_freq: 0.066343
[17:04:28.115] iteration 14211: loss: 0.072648, loss_s1: 0.093486, loss_fp: 0.000582, loss_freq: 0.018402
[17:04:28.741] iteration 14212: loss: 0.061251, loss_s1: 0.037398, loss_fp: 0.002047, loss_freq: 0.038867
[17:04:29.368] iteration 14213: loss: 0.057486, loss_s1: 0.037181, loss_fp: 0.004612, loss_freq: 0.025424
[17:04:29.995] iteration 14214: loss: 0.067308, loss_s1: 0.070465, loss_fp: 0.003154, loss_freq: 0.014110
[17:04:30.617] iteration 14215: loss: 0.036985, loss_s1: 0.031439, loss_fp: 0.001963, loss_freq: 0.005293
[17:04:31.245] iteration 14216: loss: 0.082480, loss_s1: 0.070336, loss_fp: 0.009288, loss_freq: 0.037810
[17:04:31.869] iteration 14217: loss: 0.057918, loss_s1: 0.039630, loss_fp: 0.004925, loss_freq: 0.021528
[17:04:32.496] iteration 14218: loss: 0.077574, loss_s1: 0.049260, loss_fp: 0.009212, loss_freq: 0.052416
[17:04:33.123] iteration 14219: loss: 0.066703, loss_s1: 0.070688, loss_fp: 0.003051, loss_freq: 0.022722
[17:04:33.748] iteration 14220: loss: 0.055537, loss_s1: 0.025239, loss_fp: 0.007439, loss_freq: 0.028725
[17:04:34.383] iteration 14221: loss: 0.056343, loss_s1: 0.036464, loss_fp: 0.004004, loss_freq: 0.022424
[17:04:35.000] iteration 14222: loss: 0.050163, loss_s1: 0.026321, loss_fp: 0.001183, loss_freq: 0.022111
[17:04:35.628] iteration 14223: loss: 0.064504, loss_s1: 0.032287, loss_fp: 0.010788, loss_freq: 0.018371
[17:04:36.252] iteration 14224: loss: 0.068729, loss_s1: 0.039631, loss_fp: 0.002312, loss_freq: 0.042612
[17:04:36.877] iteration 14225: loss: 0.054266, loss_s1: 0.031149, loss_fp: 0.005859, loss_freq: 0.027068
[17:04:37.508] iteration 14226: loss: 0.094869, loss_s1: 0.077300, loss_fp: 0.001710, loss_freq: 0.052179
[17:04:38.134] iteration 14227: loss: 0.064624, loss_s1: 0.064397, loss_fp: 0.003110, loss_freq: 0.021806
[17:04:38.762] iteration 14228: loss: 0.054522, loss_s1: 0.048310, loss_fp: 0.001093, loss_freq: 0.016246
[17:04:39.392] iteration 14229: loss: 0.063342, loss_s1: 0.066212, loss_fp: 0.001291, loss_freq: 0.012942
[17:04:40.018] iteration 14230: loss: 0.069810, loss_s1: 0.073624, loss_fp: 0.001484, loss_freq: 0.009730
[17:04:40.641] iteration 14231: loss: 0.049640, loss_s1: 0.044198, loss_fp: 0.004421, loss_freq: 0.015069
[17:04:41.266] iteration 14232: loss: 0.051742, loss_s1: 0.041179, loss_fp: 0.000863, loss_freq: 0.017131
[17:04:41.898] iteration 14233: loss: 0.059110, loss_s1: 0.059247, loss_fp: 0.003382, loss_freq: 0.017431
[17:04:42.543] iteration 14234: loss: 0.069620, loss_s1: 0.028603, loss_fp: 0.002670, loss_freq: 0.063696
[17:04:43.176] iteration 14235: loss: 0.071417, loss_s1: 0.039834, loss_fp: 0.000420, loss_freq: 0.042572
[17:04:43.797] iteration 14236: loss: 0.063705, loss_s1: 0.044232, loss_fp: 0.004310, loss_freq: 0.032485
[17:04:44.424] iteration 14237: loss: 0.052344, loss_s1: 0.038936, loss_fp: 0.005491, loss_freq: 0.014621
[17:04:45.087] iteration 14238: loss: 0.055952, loss_s1: 0.025863, loss_fp: 0.001346, loss_freq: 0.029575
[17:04:45.742] iteration 14239: loss: 0.066660, loss_s1: 0.077612, loss_fp: 0.005131, loss_freq: 0.014114
[17:04:46.366] iteration 14240: loss: 0.048119, loss_s1: 0.032690, loss_fp: 0.002207, loss_freq: 0.017002
[17:04:46.998] iteration 14241: loss: 0.090671, loss_s1: 0.063379, loss_fp: 0.003075, loss_freq: 0.047499
[17:04:47.624] iteration 14242: loss: 0.057462, loss_s1: 0.034646, loss_fp: 0.001435, loss_freq: 0.020934
[17:04:48.250] iteration 14243: loss: 0.073399, loss_s1: 0.057494, loss_fp: 0.001861, loss_freq: 0.034807
[17:04:48.880] iteration 14244: loss: 0.069091, loss_s1: 0.077576, loss_fp: 0.001641, loss_freq: 0.005533
[17:04:49.504] iteration 14245: loss: 0.071770, loss_s1: 0.058639, loss_fp: 0.002830, loss_freq: 0.033424
[17:04:50.127] iteration 14246: loss: 0.043832, loss_s1: 0.028826, loss_fp: 0.002076, loss_freq: 0.012575
[17:04:50.755] iteration 14247: loss: 0.026647, loss_s1: 0.007418, loss_fp: 0.000784, loss_freq: 0.006729
[17:04:51.378] iteration 14248: loss: 0.059996, loss_s1: 0.045413, loss_fp: 0.004446, loss_freq: 0.022264
[17:04:52.001] iteration 14249: loss: 0.055678, loss_s1: 0.041945, loss_fp: 0.001884, loss_freq: 0.019524
[17:04:52.628] iteration 14250: loss: 0.078884, loss_s1: 0.050600, loss_fp: 0.012558, loss_freq: 0.055339
[17:04:53.253] iteration 14251: loss: 0.086614, loss_s1: 0.075565, loss_fp: 0.000977, loss_freq: 0.065405
[17:04:53.879] iteration 14252: loss: 0.079793, loss_s1: 0.022226, loss_fp: 0.006350, loss_freq: 0.016770
[17:04:54.503] iteration 14253: loss: 0.106274, loss_s1: 0.091236, loss_fp: 0.009097, loss_freq: 0.069546
[17:04:55.123] iteration 14254: loss: 0.054606, loss_s1: 0.055803, loss_fp: 0.000839, loss_freq: 0.015134
[17:04:55.748] iteration 14255: loss: 0.052415, loss_s1: 0.036479, loss_fp: 0.001392, loss_freq: 0.014160
[17:04:56.372] iteration 14256: loss: 0.049967, loss_s1: 0.040496, loss_fp: 0.001817, loss_freq: 0.017197
[17:04:56.998] iteration 14257: loss: 0.054068, loss_s1: 0.029962, loss_fp: 0.007529, loss_freq: 0.027917
[17:04:57.621] iteration 14258: loss: 0.062912, loss_s1: 0.056890, loss_fp: 0.002905, loss_freq: 0.023693
[17:04:58.249] iteration 14259: loss: 0.070261, loss_s1: 0.047033, loss_fp: 0.006383, loss_freq: 0.016261
[17:04:58.871] iteration 14260: loss: 0.058994, loss_s1: 0.055126, loss_fp: 0.002946, loss_freq: 0.010689
[17:04:59.497] iteration 14261: loss: 0.085782, loss_s1: 0.024403, loss_fp: 0.000597, loss_freq: 0.027546
[17:05:00.120] iteration 14262: loss: 0.056016, loss_s1: 0.046323, loss_fp: 0.001048, loss_freq: 0.020641
[17:05:00.750] iteration 14263: loss: 0.074515, loss_s1: 0.082188, loss_fp: 0.006378, loss_freq: 0.029640
[17:05:01.408] iteration 14264: loss: 0.063821, loss_s1: 0.053209, loss_fp: 0.004404, loss_freq: 0.039077
[17:05:02.052] iteration 14265: loss: 0.033708, loss_s1: 0.007747, loss_fp: 0.001223, loss_freq: 0.015270
[17:05:02.676] iteration 14266: loss: 0.049262, loss_s1: 0.012565, loss_fp: 0.000551, loss_freq: 0.038811
[17:05:03.300] iteration 14267: loss: 0.031472, loss_s1: 0.004431, loss_fp: 0.004809, loss_freq: 0.011347
[17:05:03.927] iteration 14268: loss: 0.068973, loss_s1: 0.061757, loss_fp: 0.004170, loss_freq: 0.017234
[17:05:04.550] iteration 14269: loss: 0.059212, loss_s1: 0.064734, loss_fp: 0.001794, loss_freq: 0.015894
[17:05:05.178] iteration 14270: loss: 0.098294, loss_s1: 0.046099, loss_fp: 0.005904, loss_freq: 0.078972
[17:05:05.846] iteration 14271: loss: 0.095889, loss_s1: 0.097062, loss_fp: 0.001687, loss_freq: 0.053795
[17:05:06.473] iteration 14272: loss: 0.087413, loss_s1: 0.076220, loss_fp: 0.005214, loss_freq: 0.044152
[17:05:07.097] iteration 14273: loss: 0.052160, loss_s1: 0.024184, loss_fp: 0.003674, loss_freq: 0.017686
[17:05:07.724] iteration 14274: loss: 0.052870, loss_s1: 0.045104, loss_fp: 0.005957, loss_freq: 0.012515
[17:05:08.354] iteration 14275: loss: 0.042049, loss_s1: 0.014992, loss_fp: 0.001200, loss_freq: 0.012961
[17:05:09.005] iteration 14276: loss: 0.133610, loss_s1: 0.071771, loss_fp: 0.007719, loss_freq: 0.118648
[17:05:09.637] iteration 14277: loss: 0.163763, loss_s1: 0.108223, loss_fp: 0.003821, loss_freq: 0.153116
[17:05:10.263] iteration 14278: loss: 0.063936, loss_s1: 0.066621, loss_fp: 0.000388, loss_freq: 0.025936
[17:05:10.888] iteration 14279: loss: 0.052495, loss_s1: 0.018136, loss_fp: 0.001742, loss_freq: 0.023279
[17:05:11.515] iteration 14280: loss: 0.060721, loss_s1: 0.028333, loss_fp: 0.004484, loss_freq: 0.041036
[17:05:12.141] iteration 14281: loss: 0.097850, loss_s1: 0.075964, loss_fp: 0.003187, loss_freq: 0.059523
[17:05:12.765] iteration 14282: loss: 0.058558, loss_s1: 0.048300, loss_fp: 0.001489, loss_freq: 0.017073
[17:05:13.389] iteration 14283: loss: 0.047076, loss_s1: 0.041291, loss_fp: 0.000955, loss_freq: 0.003975
[17:05:14.010] iteration 14284: loss: 0.053419, loss_s1: 0.027969, loss_fp: 0.002414, loss_freq: 0.024279
[17:05:14.633] iteration 14285: loss: 0.063081, loss_s1: 0.030508, loss_fp: 0.001473, loss_freq: 0.061198
[17:05:15.257] iteration 14286: loss: 0.060469, loss_s1: 0.050082, loss_fp: 0.000970, loss_freq: 0.034574
[17:05:15.879] iteration 14287: loss: 0.068758, loss_s1: 0.044183, loss_fp: 0.001881, loss_freq: 0.037605
[17:05:16.506] iteration 14288: loss: 0.085033, loss_s1: 0.085102, loss_fp: 0.002541, loss_freq: 0.044818
[17:05:17.131] iteration 14289: loss: 0.073900, loss_s1: 0.079169, loss_fp: 0.004543, loss_freq: 0.026914
[17:05:17.751] iteration 14290: loss: 0.061594, loss_s1: 0.040003, loss_fp: 0.001904, loss_freq: 0.030191
[17:05:18.373] iteration 14291: loss: 0.051357, loss_s1: 0.024954, loss_fp: 0.001244, loss_freq: 0.017890
[17:05:18.995] iteration 14292: loss: 0.034227, loss_s1: 0.008315, loss_fp: 0.000787, loss_freq: 0.010448
[17:05:19.617] iteration 14293: loss: 0.055839, loss_s1: 0.024046, loss_fp: 0.000871, loss_freq: 0.024138
[17:05:20.238] iteration 14294: loss: 0.095084, loss_s1: 0.083002, loss_fp: 0.000946, loss_freq: 0.038026
[17:05:20.861] iteration 14295: loss: 0.070784, loss_s1: 0.038104, loss_fp: 0.002410, loss_freq: 0.034657
[17:05:21.487] iteration 14296: loss: 0.121060, loss_s1: 0.105932, loss_fp: 0.002663, loss_freq: 0.075112
[17:05:22.108] iteration 14297: loss: 0.071473, loss_s1: 0.091227, loss_fp: 0.001147, loss_freq: 0.012841
[17:05:22.733] iteration 14298: loss: 0.035903, loss_s1: 0.015926, loss_fp: 0.002524, loss_freq: 0.014186
[17:05:23.356] iteration 14299: loss: 0.100483, loss_s1: 0.065459, loss_fp: 0.001520, loss_freq: 0.080304
[17:05:23.979] iteration 14300: loss: 0.073310, loss_s1: 0.066099, loss_fp: 0.001269, loss_freq: 0.023065
[17:05:24.600] iteration 14301: loss: 0.077957, loss_s1: 0.057200, loss_fp: 0.006858, loss_freq: 0.018073
[17:05:25.223] iteration 14302: loss: 0.051435, loss_s1: 0.032559, loss_fp: 0.003268, loss_freq: 0.022430
[17:05:25.847] iteration 14303: loss: 0.075258, loss_s1: 0.050932, loss_fp: 0.001343, loss_freq: 0.044509
[17:05:26.471] iteration 14304: loss: 0.083154, loss_s1: 0.100258, loss_fp: 0.002810, loss_freq: 0.027500
[17:05:27.099] iteration 14305: loss: 0.045172, loss_s1: 0.015657, loss_fp: 0.001714, loss_freq: 0.006151
[17:05:27.725] iteration 14306: loss: 0.042493, loss_s1: 0.016161, loss_fp: 0.000867, loss_freq: 0.019153
[17:05:28.348] iteration 14307: loss: 0.080980, loss_s1: 0.033997, loss_fp: 0.003191, loss_freq: 0.059816
[17:05:28.984] iteration 14308: loss: 0.084207, loss_s1: 0.048302, loss_fp: 0.003481, loss_freq: 0.034769
[17:05:29.609] iteration 14309: loss: 0.050402, loss_s1: 0.033859, loss_fp: 0.005514, loss_freq: 0.021461
[17:05:30.237] iteration 14310: loss: 0.057233, loss_s1: 0.023311, loss_fp: 0.001411, loss_freq: 0.020912
[17:05:30.864] iteration 14311: loss: 0.070937, loss_s1: 0.060338, loss_fp: 0.002266, loss_freq: 0.025986
[17:05:31.488] iteration 14312: loss: 0.108611, loss_s1: 0.112381, loss_fp: 0.001275, loss_freq: 0.052250
[17:05:32.113] iteration 14313: loss: 0.054622, loss_s1: 0.047986, loss_fp: 0.003557, loss_freq: 0.017999
[17:05:32.739] iteration 14314: loss: 0.061045, loss_s1: 0.032118, loss_fp: 0.010181, loss_freq: 0.008313
[17:05:33.365] iteration 14315: loss: 0.086266, loss_s1: 0.064058, loss_fp: 0.004543, loss_freq: 0.069484
[17:05:33.993] iteration 14316: loss: 0.033709, loss_s1: 0.021858, loss_fp: 0.003812, loss_freq: 0.011246
[17:05:34.620] iteration 14317: loss: 0.039904, loss_s1: 0.024393, loss_fp: 0.002465, loss_freq: 0.011964
[17:05:35.245] iteration 14318: loss: 0.062940, loss_s1: 0.047897, loss_fp: 0.000804, loss_freq: 0.027163
[17:05:35.868] iteration 14319: loss: 0.094637, loss_s1: 0.072311, loss_fp: 0.001471, loss_freq: 0.063941
[17:05:36.489] iteration 14320: loss: 0.097034, loss_s1: 0.096795, loss_fp: 0.007801, loss_freq: 0.053970
[17:05:37.114] iteration 14321: loss: 0.056116, loss_s1: 0.039468, loss_fp: 0.000829, loss_freq: 0.036396
[17:05:37.743] iteration 14322: loss: 0.051908, loss_s1: 0.034540, loss_fp: 0.000718, loss_freq: 0.022238
[17:05:38.367] iteration 14323: loss: 0.038582, loss_s1: 0.022568, loss_fp: 0.003308, loss_freq: 0.009391
[17:05:38.995] iteration 14324: loss: 0.057417, loss_s1: 0.031862, loss_fp: 0.003359, loss_freq: 0.026784
[17:05:39.624] iteration 14325: loss: 0.063684, loss_s1: 0.069702, loss_fp: 0.002229, loss_freq: 0.007773
[17:05:40.256] iteration 14326: loss: 0.070894, loss_s1: 0.067305, loss_fp: 0.003436, loss_freq: 0.017422
[17:05:40.887] iteration 14327: loss: 0.056560, loss_s1: 0.042850, loss_fp: 0.005506, loss_freq: 0.027828
[17:05:41.509] iteration 14328: loss: 0.062650, loss_s1: 0.058164, loss_fp: 0.000525, loss_freq: 0.024222
[17:05:42.130] iteration 14329: loss: 0.056045, loss_s1: 0.049140, loss_fp: 0.002060, loss_freq: 0.020186
[17:05:43.101] iteration 14330: loss: 0.054598, loss_s1: 0.057599, loss_fp: 0.003865, loss_freq: 0.014255
[17:05:43.731] iteration 14331: loss: 0.093559, loss_s1: 0.076226, loss_fp: 0.011571, loss_freq: 0.038919
[17:05:44.355] iteration 14332: loss: 0.064955, loss_s1: 0.048559, loss_fp: 0.006451, loss_freq: 0.027126
[17:05:44.981] iteration 14333: loss: 0.034096, loss_s1: 0.014660, loss_fp: 0.000246, loss_freq: 0.008156
[17:05:45.608] iteration 14334: loss: 0.054269, loss_s1: 0.049730, loss_fp: 0.002893, loss_freq: 0.014044
[17:05:46.233] iteration 14335: loss: 0.092371, loss_s1: 0.057174, loss_fp: 0.006277, loss_freq: 0.040269
[17:05:46.856] iteration 14336: loss: 0.046694, loss_s1: 0.034078, loss_fp: 0.006522, loss_freq: 0.010435
[17:05:47.479] iteration 14337: loss: 0.054260, loss_s1: 0.038482, loss_fp: 0.002864, loss_freq: 0.032572
[17:05:48.107] iteration 14338: loss: 0.100851, loss_s1: 0.095606, loss_fp: 0.011993, loss_freq: 0.042866
[17:05:48.735] iteration 14339: loss: 0.062515, loss_s1: 0.033489, loss_fp: 0.016187, loss_freq: 0.025842
[17:05:49.370] iteration 14340: loss: 0.059987, loss_s1: 0.028244, loss_fp: 0.008534, loss_freq: 0.010822
[17:05:49.999] iteration 14341: loss: 0.073091, loss_s1: 0.072626, loss_fp: 0.003567, loss_freq: 0.030016
[17:05:50.655] iteration 14342: loss: 0.082043, loss_s1: 0.063354, loss_fp: 0.004089, loss_freq: 0.058876
[17:05:51.280] iteration 14343: loss: 0.091787, loss_s1: 0.066362, loss_fp: 0.002825, loss_freq: 0.061401
[17:05:51.909] iteration 14344: loss: 0.085471, loss_s1: 0.075867, loss_fp: 0.004982, loss_freq: 0.053883
[17:05:52.539] iteration 14345: loss: 0.119983, loss_s1: 0.057574, loss_fp: 0.029906, loss_freq: 0.099096
[17:05:53.168] iteration 14346: loss: 0.059691, loss_s1: 0.037480, loss_fp: 0.000290, loss_freq: 0.008978
[17:05:53.801] iteration 14347: loss: 0.084310, loss_s1: 0.076319, loss_fp: 0.003946, loss_freq: 0.049340
[17:05:54.429] iteration 14348: loss: 0.054516, loss_s1: 0.021375, loss_fp: 0.001538, loss_freq: 0.029566
[17:05:55.059] iteration 14349: loss: 0.057133, loss_s1: 0.039845, loss_fp: 0.002245, loss_freq: 0.017342
[17:05:55.689] iteration 14350: loss: 0.095970, loss_s1: 0.119578, loss_fp: 0.000643, loss_freq: 0.021705
[17:05:56.319] iteration 14351: loss: 0.041540, loss_s1: 0.013401, loss_fp: 0.003324, loss_freq: 0.020114
[17:05:56.944] iteration 14352: loss: 0.061102, loss_s1: 0.048452, loss_fp: 0.000858, loss_freq: 0.025470
[17:05:57.574] iteration 14353: loss: 0.153495, loss_s1: 0.162031, loss_fp: 0.000638, loss_freq: 0.102840
[17:05:58.203] iteration 14354: loss: 0.048716, loss_s1: 0.049715, loss_fp: 0.000603, loss_freq: 0.016013
[17:05:58.835] iteration 14355: loss: 0.055221, loss_s1: 0.050790, loss_fp: 0.002132, loss_freq: 0.011168
[17:05:59.466] iteration 14356: loss: 0.049001, loss_s1: 0.042343, loss_fp: 0.000378, loss_freq: 0.011350
[17:06:00.098] iteration 14357: loss: 0.099664, loss_s1: 0.072285, loss_fp: 0.014883, loss_freq: 0.072149
[17:06:00.724] iteration 14358: loss: 0.071860, loss_s1: 0.062103, loss_fp: 0.007691, loss_freq: 0.033768
[17:06:01.351] iteration 14359: loss: 0.054350, loss_s1: 0.043349, loss_fp: 0.001459, loss_freq: 0.016850
[17:06:01.980] iteration 14360: loss: 0.060178, loss_s1: 0.046783, loss_fp: 0.001715, loss_freq: 0.016066
[17:06:02.603] iteration 14361: loss: 0.066546, loss_s1: 0.068131, loss_fp: 0.006235, loss_freq: 0.015839
[17:06:03.253] iteration 14362: loss: 0.072963, loss_s1: 0.053262, loss_fp: 0.002850, loss_freq: 0.049026
[17:06:03.912] iteration 14363: loss: 0.041707, loss_s1: 0.032256, loss_fp: 0.000852, loss_freq: 0.009412
[17:06:04.827] iteration 14364: loss: 0.074487, loss_s1: 0.030256, loss_fp: 0.001351, loss_freq: 0.030333
[17:06:05.620] iteration 14365: loss: 0.073831, loss_s1: 0.054050, loss_fp: 0.006590, loss_freq: 0.048641
[17:06:06.376] iteration 14366: loss: 0.056745, loss_s1: 0.041837, loss_fp: 0.001094, loss_freq: 0.019035
[17:06:06.998] iteration 14367: loss: 0.077235, loss_s1: 0.065638, loss_fp: 0.002958, loss_freq: 0.033502
[17:06:07.628] iteration 14368: loss: 0.111534, loss_s1: 0.108572, loss_fp: 0.000922, loss_freq: 0.062578
[17:06:08.256] iteration 14369: loss: 0.068588, loss_s1: 0.074721, loss_fp: 0.003138, loss_freq: 0.022079
[17:06:08.882] iteration 14370: loss: 0.054049, loss_s1: 0.012856, loss_fp: 0.003916, loss_freq: 0.021202
[17:06:09.518] iteration 14371: loss: 0.131073, loss_s1: 0.170294, loss_fp: 0.001809, loss_freq: 0.050356
[17:06:10.153] iteration 14372: loss: 0.056574, loss_s1: 0.059626, loss_fp: 0.001666, loss_freq: 0.020130
[17:06:10.784] iteration 14373: loss: 0.071115, loss_s1: 0.033725, loss_fp: 0.013941, loss_freq: 0.045092
[17:06:11.417] iteration 14374: loss: 0.081182, loss_s1: 0.038950, loss_fp: 0.012471, loss_freq: 0.066386
[17:06:12.050] iteration 14375: loss: 0.055429, loss_s1: 0.035936, loss_fp: 0.002528, loss_freq: 0.010697
[17:06:12.679] iteration 14376: loss: 0.043857, loss_s1: 0.030472, loss_fp: 0.003275, loss_freq: 0.013496
[17:06:13.312] iteration 14377: loss: 0.047998, loss_s1: 0.032766, loss_fp: 0.005306, loss_freq: 0.022608
[17:06:13.943] iteration 14378: loss: 0.080920, loss_s1: 0.079892, loss_fp: 0.003854, loss_freq: 0.036914
[17:06:14.572] iteration 14379: loss: 0.073795, loss_s1: 0.054021, loss_fp: 0.002483, loss_freq: 0.053503
[17:06:15.203] iteration 14380: loss: 0.064589, loss_s1: 0.066347, loss_fp: 0.000735, loss_freq: 0.020823
[17:06:15.831] iteration 14381: loss: 0.048670, loss_s1: 0.024276, loss_fp: 0.002091, loss_freq: 0.026324
[17:06:16.459] iteration 14382: loss: 0.061032, loss_s1: 0.056897, loss_fp: 0.002345, loss_freq: 0.020674
[17:06:17.092] iteration 14383: loss: 0.049241, loss_s1: 0.039603, loss_fp: 0.002642, loss_freq: 0.021672
[17:06:17.718] iteration 14384: loss: 0.043040, loss_s1: 0.021272, loss_fp: 0.001885, loss_freq: 0.012742
[17:06:18.340] iteration 14385: loss: 0.061408, loss_s1: 0.054442, loss_fp: 0.001200, loss_freq: 0.015378
[17:06:18.968] iteration 14386: loss: 0.061134, loss_s1: 0.052604, loss_fp: 0.001774, loss_freq: 0.021798
[17:06:19.594] iteration 14387: loss: 0.066550, loss_s1: 0.029929, loss_fp: 0.001188, loss_freq: 0.045831
[17:06:20.218] iteration 14388: loss: 0.048521, loss_s1: 0.043727, loss_fp: 0.001687, loss_freq: 0.010542
[17:06:20.843] iteration 14389: loss: 0.069460, loss_s1: 0.074078, loss_fp: 0.000799, loss_freq: 0.022161
[17:06:21.474] iteration 14390: loss: 0.039779, loss_s1: 0.018968, loss_fp: 0.000974, loss_freq: 0.019679
[17:06:22.102] iteration 14391: loss: 0.076269, loss_s1: 0.075567, loss_fp: 0.002639, loss_freq: 0.029139
[17:06:22.727] iteration 14392: loss: 0.064940, loss_s1: 0.057975, loss_fp: 0.009123, loss_freq: 0.017615
[17:06:23.349] iteration 14393: loss: 0.051076, loss_s1: 0.040900, loss_fp: 0.004051, loss_freq: 0.011300
[17:06:23.980] iteration 14394: loss: 0.063185, loss_s1: 0.052919, loss_fp: 0.010403, loss_freq: 0.021489
[17:06:24.605] iteration 14395: loss: 0.095675, loss_s1: 0.035751, loss_fp: 0.010399, loss_freq: 0.107301
[17:06:25.224] iteration 14396: loss: 0.073925, loss_s1: 0.064938, loss_fp: 0.001824, loss_freq: 0.023214
[17:06:25.846] iteration 14397: loss: 0.065234, loss_s1: 0.051940, loss_fp: 0.002592, loss_freq: 0.038576
[17:06:26.470] iteration 14398: loss: 0.062591, loss_s1: 0.040082, loss_fp: 0.011014, loss_freq: 0.033349
[17:06:27.095] iteration 14399: loss: 0.120336, loss_s1: 0.070304, loss_fp: 0.001933, loss_freq: 0.049710
[17:06:27.718] iteration 14400: loss: 0.067655, loss_s1: 0.065043, loss_fp: 0.002604, loss_freq: 0.031021
[17:06:31.127] iteration 14400 : mean_dice : 0.696304
[17:06:31.812] iteration 14401: loss: 0.054537, loss_s1: 0.021982, loss_fp: 0.002812, loss_freq: 0.035512
[17:06:32.439] iteration 14402: loss: 0.060078, loss_s1: 0.040296, loss_fp: 0.004451, loss_freq: 0.010637
[17:06:33.065] iteration 14403: loss: 0.049889, loss_s1: 0.029897, loss_fp: 0.000775, loss_freq: 0.004055
[17:06:33.689] iteration 14404: loss: 0.059369, loss_s1: 0.054567, loss_fp: 0.001619, loss_freq: 0.005548
[17:06:34.314] iteration 14405: loss: 0.065590, loss_s1: 0.056701, loss_fp: 0.003032, loss_freq: 0.015279
[17:06:34.939] iteration 14406: loss: 0.082186, loss_s1: 0.038744, loss_fp: 0.021283, loss_freq: 0.065803
[17:06:35.562] iteration 14407: loss: 0.052011, loss_s1: 0.039925, loss_fp: 0.001461, loss_freq: 0.023379
[17:06:36.183] iteration 14408: loss: 0.029299, loss_s1: 0.019133, loss_fp: 0.002062, loss_freq: 0.008104
[17:06:36.806] iteration 14409: loss: 0.073365, loss_s1: 0.061382, loss_fp: 0.003746, loss_freq: 0.041167
[17:06:37.437] iteration 14410: loss: 0.083967, loss_s1: 0.039096, loss_fp: 0.006350, loss_freq: 0.063690
[17:06:38.060] iteration 14411: loss: 0.072413, loss_s1: 0.049301, loss_fp: 0.005625, loss_freq: 0.021181
[17:06:38.687] iteration 14412: loss: 0.115236, loss_s1: 0.153572, loss_fp: 0.002833, loss_freq: 0.034037
[17:06:39.369] iteration 14413: loss: 0.092470, loss_s1: 0.107427, loss_fp: 0.000766, loss_freq: 0.018155
[17:06:39.996] iteration 14414: loss: 0.101955, loss_s1: 0.116163, loss_fp: 0.001928, loss_freq: 0.046556
[17:06:40.621] iteration 14415: loss: 0.053701, loss_s1: 0.034225, loss_fp: 0.002744, loss_freq: 0.031070
[17:06:41.245] iteration 14416: loss: 0.059656, loss_s1: 0.055885, loss_fp: 0.002504, loss_freq: 0.017816
[17:06:41.870] iteration 14417: loss: 0.076851, loss_s1: 0.090999, loss_fp: 0.001701, loss_freq: 0.020258
[17:06:42.492] iteration 14418: loss: 0.061228, loss_s1: 0.046351, loss_fp: 0.002258, loss_freq: 0.036287
[17:06:43.122] iteration 14419: loss: 0.068248, loss_s1: 0.042501, loss_fp: 0.001769, loss_freq: 0.050969
[17:06:43.750] iteration 14420: loss: 0.086646, loss_s1: 0.073750, loss_fp: 0.005466, loss_freq: 0.055576
[17:06:44.372] iteration 14421: loss: 0.074073, loss_s1: 0.059499, loss_fp: 0.001761, loss_freq: 0.036155
[17:06:44.997] iteration 14422: loss: 0.060047, loss_s1: 0.056192, loss_fp: 0.000909, loss_freq: 0.009509
[17:06:45.625] iteration 14423: loss: 0.044032, loss_s1: 0.036920, loss_fp: 0.000967, loss_freq: 0.019336
[17:06:46.252] iteration 14424: loss: 0.063083, loss_s1: 0.053927, loss_fp: 0.014871, loss_freq: 0.027350
[17:06:46.875] iteration 14425: loss: 0.060875, loss_s1: 0.058344, loss_fp: 0.003591, loss_freq: 0.024446
[17:06:47.500] iteration 14426: loss: 0.044994, loss_s1: 0.017891, loss_fp: 0.006797, loss_freq: 0.019166
[17:06:48.159] iteration 14427: loss: 0.061639, loss_s1: 0.019300, loss_fp: 0.001729, loss_freq: 0.041973
[17:06:48.845] iteration 14428: loss: 0.044150, loss_s1: 0.040408, loss_fp: 0.002589, loss_freq: 0.006144
[17:06:49.503] iteration 14429: loss: 0.051973, loss_s1: 0.035528, loss_fp: 0.004859, loss_freq: 0.020870
[17:06:50.160] iteration 14430: loss: 0.067158, loss_s1: 0.040055, loss_fp: 0.004530, loss_freq: 0.045364
[17:06:50.826] iteration 14431: loss: 0.067606, loss_s1: 0.036436, loss_fp: 0.006508, loss_freq: 0.039730
[17:06:51.460] iteration 14432: loss: 0.083591, loss_s1: 0.057798, loss_fp: 0.007705, loss_freq: 0.061827
[17:06:52.086] iteration 14433: loss: 0.044365, loss_s1: 0.023047, loss_fp: 0.014354, loss_freq: 0.018384
[17:06:52.710] iteration 14434: loss: 0.057853, loss_s1: 0.031368, loss_fp: 0.002328, loss_freq: 0.020105
[17:06:53.337] iteration 14435: loss: 0.063009, loss_s1: 0.030867, loss_fp: 0.001804, loss_freq: 0.047932
[17:06:53.961] iteration 14436: loss: 0.046376, loss_s1: 0.030817, loss_fp: 0.001177, loss_freq: 0.011870
[17:06:54.584] iteration 14437: loss: 0.086887, loss_s1: 0.076497, loss_fp: 0.002880, loss_freq: 0.050025
[17:06:55.209] iteration 14438: loss: 0.138068, loss_s1: 0.119447, loss_fp: 0.003586, loss_freq: 0.098881
[17:06:55.833] iteration 14439: loss: 0.044132, loss_s1: 0.028652, loss_fp: 0.001293, loss_freq: 0.019601
[17:06:56.485] iteration 14440: loss: 0.070279, loss_s1: 0.033313, loss_fp: 0.002180, loss_freq: 0.018350
[17:06:57.144] iteration 14441: loss: 0.062616, loss_s1: 0.046648, loss_fp: 0.004036, loss_freq: 0.035120
[17:06:57.804] iteration 14442: loss: 0.089855, loss_s1: 0.076414, loss_fp: 0.001397, loss_freq: 0.060526
[17:06:58.442] iteration 14443: loss: 0.067537, loss_s1: 0.066726, loss_fp: 0.001350, loss_freq: 0.021549
[17:06:59.073] iteration 14444: loss: 0.055644, loss_s1: 0.047610, loss_fp: 0.001479, loss_freq: 0.012273
[17:06:59.701] iteration 14445: loss: 0.081212, loss_s1: 0.063634, loss_fp: 0.001875, loss_freq: 0.054257
[17:07:00.323] iteration 14446: loss: 0.079273, loss_s1: 0.030229, loss_fp: 0.062703, loss_freq: 0.013243
[17:07:00.946] iteration 14447: loss: 0.058748, loss_s1: 0.025196, loss_fp: 0.004212, loss_freq: 0.034016
[17:07:01.576] iteration 14448: loss: 0.052043, loss_s1: 0.025894, loss_fp: 0.000904, loss_freq: 0.035126
[17:07:02.204] iteration 14449: loss: 0.108718, loss_s1: 0.084811, loss_fp: 0.006693, loss_freq: 0.082820
[17:07:02.832] iteration 14450: loss: 0.043319, loss_s1: 0.015234, loss_fp: 0.005349, loss_freq: 0.013085
[17:07:03.456] iteration 14451: loss: 0.102145, loss_s1: 0.052033, loss_fp: 0.005825, loss_freq: 0.063592
[17:07:04.080] iteration 14452: loss: 0.109450, loss_s1: 0.089862, loss_fp: 0.000450, loss_freq: 0.049085
[17:07:04.708] iteration 14453: loss: 0.091799, loss_s1: 0.117683, loss_fp: 0.004424, loss_freq: 0.022103
[17:07:05.337] iteration 14454: loss: 0.066946, loss_s1: 0.040967, loss_fp: 0.006846, loss_freq: 0.022726
[17:07:05.958] iteration 14455: loss: 0.075257, loss_s1: 0.061171, loss_fp: 0.014460, loss_freq: 0.027978
[17:07:06.582] iteration 14456: loss: 0.050419, loss_s1: 0.034763, loss_fp: 0.001248, loss_freq: 0.019540
[17:07:07.210] iteration 14457: loss: 0.161044, loss_s1: 0.119925, loss_fp: 0.003463, loss_freq: 0.111960
[17:07:07.834] iteration 14458: loss: 0.062194, loss_s1: 0.034459, loss_fp: 0.003708, loss_freq: 0.022281
[17:07:08.456] iteration 14459: loss: 0.065731, loss_s1: 0.076954, loss_fp: 0.004622, loss_freq: 0.008778
[17:07:09.080] iteration 14460: loss: 0.102311, loss_s1: 0.072715, loss_fp: 0.006588, loss_freq: 0.094141
[17:07:09.709] iteration 14461: loss: 0.098195, loss_s1: 0.116621, loss_fp: 0.004551, loss_freq: 0.013774
[17:07:10.332] iteration 14462: loss: 0.061919, loss_s1: 0.059501, loss_fp: 0.003633, loss_freq: 0.005855
[17:07:10.964] iteration 14463: loss: 0.043920, loss_s1: 0.027943, loss_fp: 0.003612, loss_freq: 0.021347
[17:07:11.584] iteration 14464: loss: 0.061114, loss_s1: 0.039929, loss_fp: 0.004224, loss_freq: 0.040367
[17:07:12.210] iteration 14465: loss: 0.053650, loss_s1: 0.038604, loss_fp: 0.004829, loss_freq: 0.024551
[17:07:12.832] iteration 14466: loss: 0.056505, loss_s1: 0.051242, loss_fp: 0.000867, loss_freq: 0.013748
[17:07:13.455] iteration 14467: loss: 0.036535, loss_s1: 0.012682, loss_fp: 0.004064, loss_freq: 0.014232
[17:07:14.079] iteration 14468: loss: 0.056503, loss_s1: 0.041860, loss_fp: 0.001595, loss_freq: 0.027304
[17:07:14.704] iteration 14469: loss: 0.072552, loss_s1: 0.057670, loss_fp: 0.009478, loss_freq: 0.024199
[17:07:15.329] iteration 14470: loss: 0.087809, loss_s1: 0.095344, loss_fp: 0.005490, loss_freq: 0.027626
[17:07:15.953] iteration 14471: loss: 0.060072, loss_s1: 0.036475, loss_fp: 0.002723, loss_freq: 0.021338
[17:07:16.574] iteration 14472: loss: 0.094136, loss_s1: 0.078354, loss_fp: 0.004927, loss_freq: 0.031719
[17:07:17.197] iteration 14473: loss: 0.087847, loss_s1: 0.085343, loss_fp: 0.010305, loss_freq: 0.034378
[17:07:17.817] iteration 14474: loss: 0.066148, loss_s1: 0.049882, loss_fp: 0.003658, loss_freq: 0.039756
[17:07:18.440] iteration 14475: loss: 0.060056, loss_s1: 0.031823, loss_fp: 0.016504, loss_freq: 0.018817
[17:07:19.061] iteration 14476: loss: 0.121226, loss_s1: 0.085556, loss_fp: 0.026305, loss_freq: 0.086997
[17:07:19.688] iteration 14477: loss: 0.050442, loss_s1: 0.048231, loss_fp: 0.001046, loss_freq: 0.006168
[17:07:20.312] iteration 14478: loss: 0.093235, loss_s1: 0.023173, loss_fp: 0.005263, loss_freq: 0.044461
[17:07:20.933] iteration 14479: loss: 0.089634, loss_s1: 0.052034, loss_fp: 0.002837, loss_freq: 0.043731
[17:07:21.555] iteration 14480: loss: 0.076122, loss_s1: 0.053193, loss_fp: 0.004799, loss_freq: 0.037406
[17:07:22.183] iteration 14481: loss: 0.095741, loss_s1: 0.095642, loss_fp: 0.005148, loss_freq: 0.054607
[17:07:22.807] iteration 14482: loss: 0.055438, loss_s1: 0.044025, loss_fp: 0.003693, loss_freq: 0.021942
[17:07:23.429] iteration 14483: loss: 0.072883, loss_s1: 0.049266, loss_fp: 0.002947, loss_freq: 0.036295
[17:07:24.051] iteration 14484: loss: 0.046676, loss_s1: 0.018713, loss_fp: 0.002546, loss_freq: 0.033207
[17:07:24.676] iteration 14485: loss: 0.041630, loss_s1: 0.021510, loss_fp: 0.001399, loss_freq: 0.017640
[17:07:25.304] iteration 14486: loss: 0.070392, loss_s1: 0.020395, loss_fp: 0.000568, loss_freq: 0.010909
[17:07:25.928] iteration 14487: loss: 0.075295, loss_s1: 0.064002, loss_fp: 0.002288, loss_freq: 0.037382
[17:07:26.555] iteration 14488: loss: 0.049742, loss_s1: 0.021561, loss_fp: 0.000706, loss_freq: 0.024866
[17:07:27.178] iteration 14489: loss: 0.053853, loss_s1: 0.049086, loss_fp: 0.000923, loss_freq: 0.022826
[17:07:27.801] iteration 14490: loss: 0.068177, loss_s1: 0.075253, loss_fp: 0.001237, loss_freq: 0.015357
[17:07:28.813] iteration 14491: loss: 0.081775, loss_s1: 0.074151, loss_fp: 0.001404, loss_freq: 0.033949
[17:07:29.455] iteration 14492: loss: 0.077542, loss_s1: 0.071854, loss_fp: 0.002108, loss_freq: 0.013604
[17:07:30.078] iteration 14493: loss: 0.054365, loss_s1: 0.029290, loss_fp: 0.002237, loss_freq: 0.015248
[17:07:30.704] iteration 14494: loss: 0.043438, loss_s1: 0.017184, loss_fp: 0.003256, loss_freq: 0.019268
[17:07:31.329] iteration 14495: loss: 0.051897, loss_s1: 0.035413, loss_fp: 0.001624, loss_freq: 0.028187
[17:07:31.954] iteration 14496: loss: 0.091909, loss_s1: 0.056112, loss_fp: 0.007578, loss_freq: 0.042260
[17:07:32.577] iteration 14497: loss: 0.060566, loss_s1: 0.058023, loss_fp: 0.002353, loss_freq: 0.031245
[17:07:33.201] iteration 14498: loss: 0.047049, loss_s1: 0.035530, loss_fp: 0.001053, loss_freq: 0.016814
[17:07:33.827] iteration 14499: loss: 0.046974, loss_s1: 0.026125, loss_fp: 0.006566, loss_freq: 0.025892
[17:07:34.455] iteration 14500: loss: 0.056693, loss_s1: 0.026090, loss_fp: 0.005908, loss_freq: 0.035386
[17:07:35.079] iteration 14501: loss: 0.056309, loss_s1: 0.017927, loss_fp: 0.003373, loss_freq: 0.036102
[17:07:35.704] iteration 14502: loss: 0.048023, loss_s1: 0.024624, loss_fp: 0.007539, loss_freq: 0.019115
[17:07:36.329] iteration 14503: loss: 0.120126, loss_s1: 0.056820, loss_fp: 0.008233, loss_freq: 0.070268
[17:07:36.953] iteration 14504: loss: 0.075686, loss_s1: 0.023557, loss_fp: 0.006091, loss_freq: 0.043966
[17:07:37.580] iteration 14505: loss: 0.053181, loss_s1: 0.049926, loss_fp: 0.002411, loss_freq: 0.015654
[17:07:38.210] iteration 14506: loss: 0.129740, loss_s1: 0.139847, loss_fp: 0.003910, loss_freq: 0.071018
[17:07:38.839] iteration 14507: loss: 0.050940, loss_s1: 0.028641, loss_fp: 0.001912, loss_freq: 0.007888
[17:07:39.464] iteration 14508: loss: 0.060579, loss_s1: 0.037645, loss_fp: 0.007568, loss_freq: 0.024358
[17:07:40.090] iteration 14509: loss: 0.049280, loss_s1: 0.029567, loss_fp: 0.001677, loss_freq: 0.012765
[17:07:40.713] iteration 14510: loss: 0.060840, loss_s1: 0.045343, loss_fp: 0.001616, loss_freq: 0.029460
[17:07:41.335] iteration 14511: loss: 0.046524, loss_s1: 0.022948, loss_fp: 0.007611, loss_freq: 0.015902
[17:07:41.956] iteration 14512: loss: 0.043376, loss_s1: 0.025027, loss_fp: 0.001130, loss_freq: 0.015215
[17:07:42.589] iteration 14513: loss: 0.068229, loss_s1: 0.034327, loss_fp: 0.000647, loss_freq: 0.041034
[17:07:43.218] iteration 14514: loss: 0.127950, loss_s1: 0.049694, loss_fp: 0.029546, loss_freq: 0.123641
[17:07:43.841] iteration 14515: loss: 0.047599, loss_s1: 0.025351, loss_fp: 0.002544, loss_freq: 0.015472
[17:07:44.466] iteration 14516: loss: 0.073400, loss_s1: 0.054332, loss_fp: 0.002303, loss_freq: 0.038376
[17:07:45.093] iteration 14517: loss: 0.039071, loss_s1: 0.025949, loss_fp: 0.001261, loss_freq: 0.015138
[17:07:45.721] iteration 14518: loss: 0.118221, loss_s1: 0.141039, loss_fp: 0.006168, loss_freq: 0.041584
[17:07:46.351] iteration 14519: loss: 0.058711, loss_s1: 0.031835, loss_fp: 0.007020, loss_freq: 0.040751
[17:07:46.976] iteration 14520: loss: 0.050709, loss_s1: 0.049228, loss_fp: 0.000743, loss_freq: 0.008109
[17:07:47.605] iteration 14521: loss: 0.035528, loss_s1: 0.029614, loss_fp: 0.000637, loss_freq: 0.004817
[17:07:48.233] iteration 14522: loss: 0.043354, loss_s1: 0.022926, loss_fp: 0.001840, loss_freq: 0.011947
[17:07:48.893] iteration 14523: loss: 0.040836, loss_s1: 0.021890, loss_fp: 0.000434, loss_freq: 0.022579
[17:07:49.549] iteration 14524: loss: 0.047164, loss_s1: 0.035507, loss_fp: 0.002239, loss_freq: 0.006287
[17:07:50.205] iteration 14525: loss: 0.058276, loss_s1: 0.028789, loss_fp: 0.002879, loss_freq: 0.028377
[17:07:50.830] iteration 14526: loss: 0.059419, loss_s1: 0.029230, loss_fp: 0.004270, loss_freq: 0.043180
[17:07:51.451] iteration 14527: loss: 0.087941, loss_s1: 0.079787, loss_fp: 0.002925, loss_freq: 0.038131
[17:07:52.072] iteration 14528: loss: 0.064946, loss_s1: 0.047525, loss_fp: 0.007904, loss_freq: 0.027743
[17:07:52.694] iteration 14529: loss: 0.098414, loss_s1: 0.098505, loss_fp: 0.001912, loss_freq: 0.045819
[17:07:53.333] iteration 14530: loss: 0.075004, loss_s1: 0.086225, loss_fp: 0.000942, loss_freq: 0.023685
[17:07:53.960] iteration 14531: loss: 0.073291, loss_s1: 0.069017, loss_fp: 0.005095, loss_freq: 0.022465
[17:07:54.587] iteration 14532: loss: 0.115570, loss_s1: 0.097042, loss_fp: 0.009687, loss_freq: 0.075748
[17:07:55.211] iteration 14533: loss: 0.090619, loss_s1: 0.057986, loss_fp: 0.001747, loss_freq: 0.058574
[17:07:55.834] iteration 14534: loss: 0.056314, loss_s1: 0.019539, loss_fp: 0.003163, loss_freq: 0.042066
[17:07:56.459] iteration 14535: loss: 0.066665, loss_s1: 0.024732, loss_fp: 0.002476, loss_freq: 0.064350
[17:07:57.086] iteration 14536: loss: 0.060790, loss_s1: 0.063616, loss_fp: 0.001007, loss_freq: 0.008514
[17:07:57.708] iteration 14537: loss: 0.046030, loss_s1: 0.029622, loss_fp: 0.000462, loss_freq: 0.019227
[17:07:58.331] iteration 14538: loss: 0.058180, loss_s1: 0.042037, loss_fp: 0.005042, loss_freq: 0.036468
[17:07:58.958] iteration 14539: loss: 0.072874, loss_s1: 0.059400, loss_fp: 0.001004, loss_freq: 0.008491
[17:07:59.580] iteration 14540: loss: 0.099432, loss_s1: 0.071671, loss_fp: 0.000867, loss_freq: 0.084398
[17:08:00.206] iteration 14541: loss: 0.076110, loss_s1: 0.082261, loss_fp: 0.001752, loss_freq: 0.029918
[17:08:00.830] iteration 14542: loss: 0.043743, loss_s1: 0.013219, loss_fp: 0.001757, loss_freq: 0.016586
[17:08:01.457] iteration 14543: loss: 0.047706, loss_s1: 0.026305, loss_fp: 0.002432, loss_freq: 0.019009
[17:08:02.084] iteration 14544: loss: 0.066496, loss_s1: 0.033442, loss_fp: 0.003578, loss_freq: 0.037035
[17:08:02.708] iteration 14545: loss: 0.029733, loss_s1: 0.011227, loss_fp: 0.000804, loss_freq: 0.009037
[17:08:03.332] iteration 14546: loss: 0.086464, loss_s1: 0.083257, loss_fp: 0.001880, loss_freq: 0.021755
[17:08:03.955] iteration 14547: loss: 0.039441, loss_s1: 0.017710, loss_fp: 0.001709, loss_freq: 0.010378
[17:08:04.585] iteration 14548: loss: 0.086116, loss_s1: 0.074961, loss_fp: 0.001931, loss_freq: 0.033182
[17:08:05.207] iteration 14549: loss: 0.044395, loss_s1: 0.019451, loss_fp: 0.003819, loss_freq: 0.024286
[17:08:05.832] iteration 14550: loss: 0.045649, loss_s1: 0.013599, loss_fp: 0.002261, loss_freq: 0.031291
[17:08:06.455] iteration 14551: loss: 0.059283, loss_s1: 0.032936, loss_fp: 0.007058, loss_freq: 0.021919
[17:08:07.077] iteration 14552: loss: 0.067458, loss_s1: 0.079017, loss_fp: 0.001285, loss_freq: 0.021776
[17:08:07.699] iteration 14553: loss: 0.054589, loss_s1: 0.030200, loss_fp: 0.001141, loss_freq: 0.027258
[17:08:08.322] iteration 14554: loss: 0.066441, loss_s1: 0.054526, loss_fp: 0.006003, loss_freq: 0.031131
[17:08:08.948] iteration 14555: loss: 0.055058, loss_s1: 0.059141, loss_fp: 0.001952, loss_freq: 0.005460
[17:08:09.577] iteration 14556: loss: 0.063989, loss_s1: 0.031115, loss_fp: 0.006416, loss_freq: 0.060052
[17:08:10.207] iteration 14557: loss: 0.074925, loss_s1: 0.052430, loss_fp: 0.001485, loss_freq: 0.050839
[17:08:10.922] iteration 14558: loss: 0.055473, loss_s1: 0.041684, loss_fp: 0.001847, loss_freq: 0.033102
[17:08:11.554] iteration 14559: loss: 0.074333, loss_s1: 0.050396, loss_fp: 0.006734, loss_freq: 0.033565
[17:08:12.180] iteration 14560: loss: 0.082779, loss_s1: 0.036280, loss_fp: 0.002342, loss_freq: 0.055795
[17:08:12.828] iteration 14561: loss: 0.073855, loss_s1: 0.031978, loss_fp: 0.017291, loss_freq: 0.049830
[17:08:13.451] iteration 14562: loss: 0.074713, loss_s1: 0.052765, loss_fp: 0.002334, loss_freq: 0.036941
[17:08:14.077] iteration 14563: loss: 0.080781, loss_s1: 0.059403, loss_fp: 0.006388, loss_freq: 0.047269
[17:08:14.701] iteration 14564: loss: 0.055734, loss_s1: 0.044682, loss_fp: 0.000445, loss_freq: 0.004132
[17:08:15.328] iteration 14565: loss: 0.081062, loss_s1: 0.077083, loss_fp: 0.006294, loss_freq: 0.037739
[17:08:15.953] iteration 14566: loss: 0.068192, loss_s1: 0.044968, loss_fp: 0.000909, loss_freq: 0.024820
[17:08:16.580] iteration 14567: loss: 0.080151, loss_s1: 0.046654, loss_fp: 0.017164, loss_freq: 0.060064
[17:08:17.204] iteration 14568: loss: 0.071411, loss_s1: 0.088935, loss_fp: 0.002199, loss_freq: 0.014881
[17:08:17.830] iteration 14569: loss: 0.033231, loss_s1: 0.028074, loss_fp: 0.003010, loss_freq: 0.003856
[17:08:18.455] iteration 14570: loss: 0.058815, loss_s1: 0.046323, loss_fp: 0.002858, loss_freq: 0.022011
[17:08:19.080] iteration 14571: loss: 0.046160, loss_s1: 0.042747, loss_fp: 0.002028, loss_freq: 0.008497
[17:08:19.702] iteration 14572: loss: 0.073769, loss_s1: 0.095695, loss_fp: 0.003698, loss_freq: 0.014912
[17:08:20.327] iteration 14573: loss: 0.050066, loss_s1: 0.045356, loss_fp: 0.005824, loss_freq: 0.015406
[17:08:20.954] iteration 14574: loss: 0.098580, loss_s1: 0.086026, loss_fp: 0.004135, loss_freq: 0.035302
[17:08:21.580] iteration 14575: loss: 0.075229, loss_s1: 0.046886, loss_fp: 0.005031, loss_freq: 0.052815
[17:08:22.202] iteration 14576: loss: 0.068467, loss_s1: 0.073963, loss_fp: 0.001592, loss_freq: 0.018010
[17:08:22.824] iteration 14577: loss: 0.078196, loss_s1: 0.067753, loss_fp: 0.002602, loss_freq: 0.026684
[17:08:23.448] iteration 14578: loss: 0.058605, loss_s1: 0.050868, loss_fp: 0.000534, loss_freq: 0.015897
[17:08:24.072] iteration 14579: loss: 0.056831, loss_s1: 0.022205, loss_fp: 0.010321, loss_freq: 0.036036
[17:08:24.702] iteration 14580: loss: 0.040572, loss_s1: 0.019582, loss_fp: 0.002229, loss_freq: 0.024509
[17:08:25.332] iteration 14581: loss: 0.072557, loss_s1: 0.045868, loss_fp: 0.001366, loss_freq: 0.009680
[17:08:25.958] iteration 14582: loss: 0.083988, loss_s1: 0.074761, loss_fp: 0.000673, loss_freq: 0.027419
[17:08:26.584] iteration 14583: loss: 0.089581, loss_s1: 0.032551, loss_fp: 0.000722, loss_freq: 0.047409
[17:08:27.206] iteration 14584: loss: 0.048749, loss_s1: 0.033249, loss_fp: 0.001662, loss_freq: 0.007226
[17:08:27.829] iteration 14585: loss: 0.074715, loss_s1: 0.046876, loss_fp: 0.003493, loss_freq: 0.053437
[17:08:28.452] iteration 14586: loss: 0.039517, loss_s1: 0.037761, loss_fp: 0.002105, loss_freq: 0.010277
[17:08:29.075] iteration 14587: loss: 0.068852, loss_s1: 0.056328, loss_fp: 0.011156, loss_freq: 0.028960
[17:08:29.700] iteration 14588: loss: 0.091483, loss_s1: 0.044225, loss_fp: 0.003800, loss_freq: 0.037254
[17:08:30.325] iteration 14589: loss: 0.064704, loss_s1: 0.037683, loss_fp: 0.001977, loss_freq: 0.022632
[17:08:30.948] iteration 14590: loss: 0.099128, loss_s1: 0.103003, loss_fp: 0.006913, loss_freq: 0.045845
[17:08:31.577] iteration 14591: loss: 0.058885, loss_s1: 0.053763, loss_fp: 0.006810, loss_freq: 0.016237
[17:08:32.201] iteration 14592: loss: 0.078297, loss_s1: 0.034422, loss_fp: 0.005275, loss_freq: 0.060803
[17:08:32.826] iteration 14593: loss: 0.072545, loss_s1: 0.051413, loss_fp: 0.001125, loss_freq: 0.033207
[17:08:33.448] iteration 14594: loss: 0.051933, loss_s1: 0.045506, loss_fp: 0.001639, loss_freq: 0.022416
[17:08:34.075] iteration 14595: loss: 0.107866, loss_s1: 0.042388, loss_fp: 0.001089, loss_freq: 0.024380
[17:08:34.703] iteration 14596: loss: 0.060608, loss_s1: 0.039652, loss_fp: 0.003855, loss_freq: 0.038070
[17:08:35.329] iteration 14597: loss: 0.038835, loss_s1: 0.019536, loss_fp: 0.000785, loss_freq: 0.008439
[17:08:35.980] iteration 14598: loss: 0.070246, loss_s1: 0.044988, loss_fp: 0.005371, loss_freq: 0.028755
[17:08:36.638] iteration 14599: loss: 0.121154, loss_s1: 0.060366, loss_fp: 0.004289, loss_freq: 0.111051
[17:08:37.295] iteration 14600: loss: 0.076102, loss_s1: 0.044816, loss_fp: 0.001238, loss_freq: 0.035668
[17:08:40.568] iteration 14600 : mean_dice : 0.718948
[17:08:41.216] iteration 14601: loss: 0.060452, loss_s1: 0.035531, loss_fp: 0.001072, loss_freq: 0.015047
[17:08:41.838] iteration 14602: loss: 0.083357, loss_s1: 0.053469, loss_fp: 0.002632, loss_freq: 0.071530
[17:08:42.467] iteration 14603: loss: 0.110663, loss_s1: 0.157272, loss_fp: 0.002966, loss_freq: 0.023413
[17:08:43.091] iteration 14604: loss: 0.059609, loss_s1: 0.051879, loss_fp: 0.001235, loss_freq: 0.028308
[17:08:43.715] iteration 14605: loss: 0.041412, loss_s1: 0.033339, loss_fp: 0.000639, loss_freq: 0.003778
[17:08:44.340] iteration 14606: loss: 0.054680, loss_s1: 0.035438, loss_fp: 0.010090, loss_freq: 0.029628
[17:08:44.968] iteration 14607: loss: 0.054196, loss_s1: 0.058018, loss_fp: 0.002823, loss_freq: 0.014177
[17:08:45.593] iteration 14608: loss: 0.047369, loss_s1: 0.037293, loss_fp: 0.001641, loss_freq: 0.017290
[17:08:46.221] iteration 14609: loss: 0.061098, loss_s1: 0.033792, loss_fp: 0.000607, loss_freq: 0.025760
[17:08:46.896] iteration 14610: loss: 0.094900, loss_s1: 0.051094, loss_fp: 0.000930, loss_freq: 0.098725
[17:08:47.569] iteration 14611: loss: 0.034266, loss_s1: 0.012069, loss_fp: 0.000736, loss_freq: 0.010901
[17:08:48.248] iteration 14612: loss: 0.073150, loss_s1: 0.039178, loss_fp: 0.003555, loss_freq: 0.046613
[17:08:48.910] iteration 14613: loss: 0.082139, loss_s1: 0.073627, loss_fp: 0.004029, loss_freq: 0.033818
[17:08:49.551] iteration 14614: loss: 0.080776, loss_s1: 0.033316, loss_fp: 0.001347, loss_freq: 0.062620
[17:08:50.200] iteration 14615: loss: 0.068127, loss_s1: 0.068671, loss_fp: 0.000974, loss_freq: 0.021039
[17:08:50.823] iteration 14616: loss: 0.057972, loss_s1: 0.021727, loss_fp: 0.005244, loss_freq: 0.030589
[17:08:51.448] iteration 14617: loss: 0.061347, loss_s1: 0.040201, loss_fp: 0.003584, loss_freq: 0.015730
[17:08:52.073] iteration 14618: loss: 0.140579, loss_s1: 0.087509, loss_fp: 0.011784, loss_freq: 0.111462
[17:08:52.714] iteration 14619: loss: 0.053032, loss_s1: 0.025013, loss_fp: 0.002086, loss_freq: 0.037673
[17:08:53.351] iteration 14620: loss: 0.057138, loss_s1: 0.034566, loss_fp: 0.003238, loss_freq: 0.008853
[17:08:53.994] iteration 14621: loss: 0.076755, loss_s1: 0.069112, loss_fp: 0.003801, loss_freq: 0.045768
[17:08:54.633] iteration 14622: loss: 0.067910, loss_s1: 0.060894, loss_fp: 0.001403, loss_freq: 0.031000
[17:08:55.281] iteration 14623: loss: 0.060688, loss_s1: 0.043462, loss_fp: 0.001901, loss_freq: 0.018106
[17:08:55.916] iteration 14624: loss: 0.046183, loss_s1: 0.025547, loss_fp: 0.001777, loss_freq: 0.023001
[17:08:56.555] iteration 14625: loss: 0.066143, loss_s1: 0.061281, loss_fp: 0.005064, loss_freq: 0.027017
[17:08:57.199] iteration 14626: loss: 0.048278, loss_s1: 0.024829, loss_fp: 0.005429, loss_freq: 0.029646
[17:08:57.823] iteration 14627: loss: 0.071205, loss_s1: 0.019671, loss_fp: 0.002220, loss_freq: 0.033709
[17:08:58.449] iteration 14628: loss: 0.051251, loss_s1: 0.039472, loss_fp: 0.000668, loss_freq: 0.021336
[17:08:59.089] iteration 14629: loss: 0.039663, loss_s1: 0.012689, loss_fp: 0.004757, loss_freq: 0.020245
[17:08:59.731] iteration 14630: loss: 0.086296, loss_s1: 0.080312, loss_fp: 0.003259, loss_freq: 0.025075
[17:09:00.372] iteration 14631: loss: 0.064747, loss_s1: 0.060425, loss_fp: 0.001284, loss_freq: 0.027917
[17:09:01.015] iteration 14632: loss: 0.049193, loss_s1: 0.026960, loss_fp: 0.002044, loss_freq: 0.025262
[17:09:01.660] iteration 14633: loss: 0.074607, loss_s1: 0.066754, loss_fp: 0.002734, loss_freq: 0.038262
[17:09:02.298] iteration 14634: loss: 0.062194, loss_s1: 0.057379, loss_fp: 0.003092, loss_freq: 0.020936
[17:09:02.938] iteration 14635: loss: 0.050773, loss_s1: 0.025193, loss_fp: 0.004799, loss_freq: 0.021036
[17:09:03.579] iteration 14636: loss: 0.082969, loss_s1: 0.074857, loss_fp: 0.002273, loss_freq: 0.036942
[17:09:04.223] iteration 14637: loss: 0.094995, loss_s1: 0.072750, loss_fp: 0.006200, loss_freq: 0.072329
[17:09:04.867] iteration 14638: loss: 0.041397, loss_s1: 0.033607, loss_fp: 0.004566, loss_freq: 0.009156
[17:09:05.560] iteration 14639: loss: 0.039565, loss_s1: 0.024404, loss_fp: 0.001591, loss_freq: 0.010887
[17:09:06.219] iteration 14640: loss: 0.084411, loss_s1: 0.058822, loss_fp: 0.008123, loss_freq: 0.047328
[17:09:06.873] iteration 14641: loss: 0.046204, loss_s1: 0.026983, loss_fp: 0.010928, loss_freq: 0.016745
[17:09:07.540] iteration 14642: loss: 0.102894, loss_s1: 0.104412, loss_fp: 0.009902, loss_freq: 0.050467
[17:09:08.180] iteration 14643: loss: 0.046820, loss_s1: 0.038382, loss_fp: 0.001550, loss_freq: 0.016836
[17:09:08.806] iteration 14644: loss: 0.061011, loss_s1: 0.029672, loss_fp: 0.004185, loss_freq: 0.027536
[17:09:09.436] iteration 14645: loss: 0.036964, loss_s1: 0.029303, loss_fp: 0.000827, loss_freq: 0.010604
[17:09:10.067] iteration 14646: loss: 0.048993, loss_s1: 0.028841, loss_fp: 0.002263, loss_freq: 0.026509
[17:09:10.701] iteration 14647: loss: 0.045300, loss_s1: 0.015064, loss_fp: 0.002280, loss_freq: 0.022321
[17:09:11.331] iteration 14648: loss: 0.060855, loss_s1: 0.020401, loss_fp: 0.013959, loss_freq: 0.043792
[17:09:11.962] iteration 14649: loss: 0.068121, loss_s1: 0.065800, loss_fp: 0.009310, loss_freq: 0.017089
[17:09:12.584] iteration 14650: loss: 0.075132, loss_s1: 0.052429, loss_fp: 0.004302, loss_freq: 0.042544
[17:09:13.211] iteration 14651: loss: 0.062318, loss_s1: 0.057394, loss_fp: 0.001614, loss_freq: 0.019839
[17:09:14.186] iteration 14652: loss: 0.061252, loss_s1: 0.063662, loss_fp: 0.001372, loss_freq: 0.011129
[17:09:14.871] iteration 14653: loss: 0.073383, loss_s1: 0.043783, loss_fp: 0.008294, loss_freq: 0.031351
[17:09:15.553] iteration 14654: loss: 0.065248, loss_s1: 0.040172, loss_fp: 0.005549, loss_freq: 0.037604
[17:09:16.215] iteration 14655: loss: 0.061476, loss_s1: 0.054216, loss_fp: 0.000568, loss_freq: 0.021883
[17:09:16.872] iteration 14656: loss: 0.044739, loss_s1: 0.026739, loss_fp: 0.003130, loss_freq: 0.015764
[17:09:17.503] iteration 14657: loss: 0.113204, loss_s1: 0.093614, loss_fp: 0.005409, loss_freq: 0.061135
[17:09:18.136] iteration 14658: loss: 0.043574, loss_s1: 0.040502, loss_fp: 0.000985, loss_freq: 0.009133
[17:09:18.763] iteration 14659: loss: 0.050672, loss_s1: 0.033414, loss_fp: 0.002341, loss_freq: 0.018022
[17:09:19.391] iteration 14660: loss: 0.100057, loss_s1: 0.064149, loss_fp: 0.011196, loss_freq: 0.082438
[17:09:20.019] iteration 14661: loss: 0.092145, loss_s1: 0.061290, loss_fp: 0.010882, loss_freq: 0.060314
[17:09:20.648] iteration 14662: loss: 0.046837, loss_s1: 0.031693, loss_fp: 0.004480, loss_freq: 0.009868
[17:09:21.277] iteration 14663: loss: 0.043095, loss_s1: 0.031866, loss_fp: 0.001613, loss_freq: 0.010349
[17:09:21.906] iteration 14664: loss: 0.055797, loss_s1: 0.027385, loss_fp: 0.005552, loss_freq: 0.040642
[17:09:22.539] iteration 14665: loss: 0.068329, loss_s1: 0.026315, loss_fp: 0.002394, loss_freq: 0.064619
[17:09:23.170] iteration 14666: loss: 0.049733, loss_s1: 0.036763, loss_fp: 0.010685, loss_freq: 0.017904
[17:09:23.800] iteration 14667: loss: 0.116015, loss_s1: 0.073803, loss_fp: 0.002172, loss_freq: 0.105755
[17:09:24.421] iteration 14668: loss: 0.051291, loss_s1: 0.029995, loss_fp: 0.006285, loss_freq: 0.011579
[17:09:25.047] iteration 14669: loss: 0.068794, loss_s1: 0.045965, loss_fp: 0.009161, loss_freq: 0.036066
[17:09:25.672] iteration 14670: loss: 0.052143, loss_s1: 0.019315, loss_fp: 0.000802, loss_freq: 0.022140
[17:09:26.299] iteration 14671: loss: 0.062846, loss_s1: 0.030215, loss_fp: 0.002670, loss_freq: 0.013587
[17:09:26.923] iteration 14672: loss: 0.036290, loss_s1: 0.022276, loss_fp: 0.000787, loss_freq: 0.003073
[17:09:27.547] iteration 14673: loss: 0.042492, loss_s1: 0.025926, loss_fp: 0.005087, loss_freq: 0.012281
[17:09:28.173] iteration 14674: loss: 0.047714, loss_s1: 0.026375, loss_fp: 0.001382, loss_freq: 0.025649
[17:09:28.804] iteration 14675: loss: 0.203968, loss_s1: 0.140609, loss_fp: 0.006149, loss_freq: 0.219084
[17:09:29.426] iteration 14676: loss: 0.051981, loss_s1: 0.057079, loss_fp: 0.000675, loss_freq: 0.013428
[17:09:30.054] iteration 14677: loss: 0.049229, loss_s1: 0.042612, loss_fp: 0.005202, loss_freq: 0.015847
[17:09:30.710] iteration 14678: loss: 0.041310, loss_s1: 0.039925, loss_fp: 0.001142, loss_freq: 0.004936
[17:09:31.367] iteration 14679: loss: 0.073044, loss_s1: 0.054932, loss_fp: 0.003190, loss_freq: 0.033829
[17:09:32.025] iteration 14680: loss: 0.090155, loss_s1: 0.099188, loss_fp: 0.003436, loss_freq: 0.037922
[17:09:32.653] iteration 14681: loss: 0.038700, loss_s1: 0.016492, loss_fp: 0.003036, loss_freq: 0.016230
[17:09:33.315] iteration 14682: loss: 0.049015, loss_s1: 0.043306, loss_fp: 0.002292, loss_freq: 0.020396
[17:09:33.971] iteration 14683: loss: 0.069107, loss_s1: 0.055725, loss_fp: 0.000544, loss_freq: 0.030032
[17:09:34.617] iteration 14684: loss: 0.051482, loss_s1: 0.039179, loss_fp: 0.002086, loss_freq: 0.020351
[17:09:35.242] iteration 14685: loss: 0.038269, loss_s1: 0.027904, loss_fp: 0.001290, loss_freq: 0.010133
[17:09:35.863] iteration 14686: loss: 0.078706, loss_s1: 0.047216, loss_fp: 0.002476, loss_freq: 0.053692
[17:09:36.489] iteration 14687: loss: 0.069308, loss_s1: 0.058460, loss_fp: 0.004249, loss_freq: 0.035028
[17:09:37.120] iteration 14688: loss: 0.069361, loss_s1: 0.036559, loss_fp: 0.003876, loss_freq: 0.052227
[17:09:37.752] iteration 14689: loss: 0.080770, loss_s1: 0.058144, loss_fp: 0.007560, loss_freq: 0.035702
[17:09:38.385] iteration 14690: loss: 0.108710, loss_s1: 0.059904, loss_fp: 0.000448, loss_freq: 0.078708
[17:09:39.021] iteration 14691: loss: 0.051016, loss_s1: 0.042323, loss_fp: 0.003168, loss_freq: 0.020023
[17:09:39.648] iteration 14692: loss: 0.051528, loss_s1: 0.013739, loss_fp: 0.006437, loss_freq: 0.014682
[17:09:40.275] iteration 14693: loss: 0.110764, loss_s1: 0.094346, loss_fp: 0.014563, loss_freq: 0.070682
[17:09:40.902] iteration 14694: loss: 0.091028, loss_s1: 0.092161, loss_fp: 0.003442, loss_freq: 0.044263
[17:09:41.531] iteration 14695: loss: 0.066629, loss_s1: 0.046358, loss_fp: 0.003141, loss_freq: 0.046578
[17:09:42.159] iteration 14696: loss: 0.056438, loss_s1: 0.046641, loss_fp: 0.002957, loss_freq: 0.017711
[17:09:42.788] iteration 14697: loss: 0.052016, loss_s1: 0.051040, loss_fp: 0.000415, loss_freq: 0.012387
[17:09:43.414] iteration 14698: loss: 0.038338, loss_s1: 0.028497, loss_fp: 0.002843, loss_freq: 0.010131
[17:09:44.042] iteration 14699: loss: 0.086092, loss_s1: 0.093633, loss_fp: 0.004219, loss_freq: 0.036931
[17:09:44.665] iteration 14700: loss: 0.063846, loss_s1: 0.046139, loss_fp: 0.005957, loss_freq: 0.025308
[17:09:45.293] iteration 14701: loss: 0.090622, loss_s1: 0.069392, loss_fp: 0.017686, loss_freq: 0.054935
[17:09:45.917] iteration 14702: loss: 0.107045, loss_s1: 0.130360, loss_fp: 0.003374, loss_freq: 0.032184
[17:09:46.607] iteration 14703: loss: 0.062658, loss_s1: 0.039543, loss_fp: 0.000760, loss_freq: 0.033197
[17:09:47.260] iteration 14704: loss: 0.064282, loss_s1: 0.027678, loss_fp: 0.007169, loss_freq: 0.045637
[17:09:47.883] iteration 14705: loss: 0.059032, loss_s1: 0.037585, loss_fp: 0.002498, loss_freq: 0.040369
[17:09:48.513] iteration 14706: loss: 0.041314, loss_s1: 0.023465, loss_fp: 0.000728, loss_freq: 0.017876
[17:09:49.140] iteration 14707: loss: 0.091811, loss_s1: 0.095016, loss_fp: 0.004876, loss_freq: 0.036088
[17:09:49.770] iteration 14708: loss: 0.056694, loss_s1: 0.044658, loss_fp: 0.000673, loss_freq: 0.013926
[17:09:50.395] iteration 14709: loss: 0.062734, loss_s1: 0.022069, loss_fp: 0.002322, loss_freq: 0.033942
[17:09:51.020] iteration 14710: loss: 0.061457, loss_s1: 0.033401, loss_fp: 0.001513, loss_freq: 0.025704
[17:09:51.645] iteration 14711: loss: 0.046479, loss_s1: 0.028178, loss_fp: 0.005381, loss_freq: 0.024362
[17:09:52.268] iteration 14712: loss: 0.051424, loss_s1: 0.028180, loss_fp: 0.002582, loss_freq: 0.025723
[17:09:52.891] iteration 14713: loss: 0.073109, loss_s1: 0.063032, loss_fp: 0.002714, loss_freq: 0.040854
[17:09:53.516] iteration 14714: loss: 0.057517, loss_s1: 0.025247, loss_fp: 0.001073, loss_freq: 0.013968
[17:09:54.140] iteration 14715: loss: 0.058991, loss_s1: 0.053184, loss_fp: 0.003568, loss_freq: 0.010407
[17:09:54.793] iteration 14716: loss: 0.051820, loss_s1: 0.017835, loss_fp: 0.000739, loss_freq: 0.014933
[17:09:55.464] iteration 14717: loss: 0.138530, loss_s1: 0.127316, loss_fp: 0.005442, loss_freq: 0.110691
[17:09:56.126] iteration 14718: loss: 0.071017, loss_s1: 0.023341, loss_fp: 0.002389, loss_freq: 0.039622
[17:09:56.786] iteration 14719: loss: 0.075241, loss_s1: 0.068442, loss_fp: 0.008986, loss_freq: 0.037565
[17:09:57.422] iteration 14720: loss: 0.053894, loss_s1: 0.052063, loss_fp: 0.004913, loss_freq: 0.012813
[17:09:58.053] iteration 14721: loss: 0.114916, loss_s1: 0.102545, loss_fp: 0.000406, loss_freq: 0.056998
[17:09:58.682] iteration 14722: loss: 0.075327, loss_s1: 0.043843, loss_fp: 0.016942, loss_freq: 0.026604
[17:09:59.308] iteration 14723: loss: 0.072666, loss_s1: 0.064043, loss_fp: 0.003361, loss_freq: 0.039658
[17:09:59.939] iteration 14724: loss: 0.044389, loss_s1: 0.023976, loss_fp: 0.002853, loss_freq: 0.019820
[17:10:00.564] iteration 14725: loss: 0.056066, loss_s1: 0.025713, loss_fp: 0.001096, loss_freq: 0.028552
[17:10:01.188] iteration 14726: loss: 0.068501, loss_s1: 0.034679, loss_fp: 0.003902, loss_freq: 0.057041
[17:10:01.814] iteration 14727: loss: 0.033729, loss_s1: 0.013220, loss_fp: 0.000458, loss_freq: 0.011535
[17:10:02.441] iteration 14728: loss: 0.063419, loss_s1: 0.054272, loss_fp: 0.012841, loss_freq: 0.023401
[17:10:03.065] iteration 14729: loss: 0.073347, loss_s1: 0.077980, loss_fp: 0.004527, loss_freq: 0.017739
[17:10:03.689] iteration 14730: loss: 0.044772, loss_s1: 0.026865, loss_fp: 0.003311, loss_freq: 0.022263
[17:10:04.314] iteration 14731: loss: 0.075366, loss_s1: 0.046759, loss_fp: 0.030191, loss_freq: 0.021395
[17:10:04.938] iteration 14732: loss: 0.094706, loss_s1: 0.086114, loss_fp: 0.001409, loss_freq: 0.064814
[17:10:05.563] iteration 14733: loss: 0.085690, loss_s1: 0.068761, loss_fp: 0.015068, loss_freq: 0.052430
[17:10:06.188] iteration 14734: loss: 0.086488, loss_s1: 0.077650, loss_fp: 0.005844, loss_freq: 0.054474
[17:10:06.815] iteration 14735: loss: 0.111487, loss_s1: 0.073576, loss_fp: 0.015459, loss_freq: 0.069783
[17:10:07.441] iteration 14736: loss: 0.079290, loss_s1: 0.080640, loss_fp: 0.003469, loss_freq: 0.041936
[17:10:08.066] iteration 14737: loss: 0.036692, loss_s1: 0.015293, loss_fp: 0.002637, loss_freq: 0.019508
[17:10:08.688] iteration 14738: loss: 0.085885, loss_s1: 0.101231, loss_fp: 0.003303, loss_freq: 0.012468
[17:10:09.315] iteration 14739: loss: 0.043166, loss_s1: 0.025454, loss_fp: 0.000472, loss_freq: 0.012875
[17:10:09.966] iteration 14740: loss: 0.073200, loss_s1: 0.089032, loss_fp: 0.003116, loss_freq: 0.018379
[17:10:10.626] iteration 14741: loss: 0.099288, loss_s1: 0.026537, loss_fp: 0.009713, loss_freq: 0.057977
[17:10:11.286] iteration 14742: loss: 0.070502, loss_s1: 0.013459, loss_fp: 0.001622, loss_freq: 0.046010
[17:10:11.943] iteration 14743: loss: 0.060815, loss_s1: 0.020082, loss_fp: 0.001062, loss_freq: 0.018602
[17:10:12.572] iteration 14744: loss: 0.048770, loss_s1: 0.004397, loss_fp: 0.006717, loss_freq: 0.023185
[17:10:13.196] iteration 14745: loss: 0.048210, loss_s1: 0.029750, loss_fp: 0.000589, loss_freq: 0.011787
[17:10:13.823] iteration 14746: loss: 0.052570, loss_s1: 0.047956, loss_fp: 0.001730, loss_freq: 0.020463
[17:10:14.454] iteration 14747: loss: 0.058848, loss_s1: 0.047739, loss_fp: 0.001794, loss_freq: 0.037512
[17:10:15.092] iteration 14748: loss: 0.045776, loss_s1: 0.032774, loss_fp: 0.000530, loss_freq: 0.020615
[17:10:15.744] iteration 14749: loss: 0.068740, loss_s1: 0.030208, loss_fp: 0.000305, loss_freq: 0.044583
[17:10:16.377] iteration 14750: loss: 0.033169, loss_s1: 0.010543, loss_fp: 0.002374, loss_freq: 0.013745
[17:10:17.041] iteration 14751: loss: 0.064473, loss_s1: 0.037408, loss_fp: 0.002848, loss_freq: 0.032124
[17:10:17.692] iteration 14752: loss: 0.067378, loss_s1: 0.065543, loss_fp: 0.001842, loss_freq: 0.028744
[17:10:18.319] iteration 14753: loss: 0.073451, loss_s1: 0.050696, loss_fp: 0.000746, loss_freq: 0.051636
[17:10:18.942] iteration 14754: loss: 0.097435, loss_s1: 0.096658, loss_fp: 0.000525, loss_freq: 0.026855
[17:10:19.566] iteration 14755: loss: 0.111172, loss_s1: 0.115747, loss_fp: 0.003689, loss_freq: 0.048076
[17:10:20.189] iteration 14756: loss: 0.047257, loss_s1: 0.007621, loss_fp: 0.002927, loss_freq: 0.011334
[17:10:20.815] iteration 14757: loss: 0.040957, loss_s1: 0.025798, loss_fp: 0.002449, loss_freq: 0.018968
[17:10:21.440] iteration 14758: loss: 0.063756, loss_s1: 0.040974, loss_fp: 0.002468, loss_freq: 0.019862
[17:10:22.065] iteration 14759: loss: 0.058835, loss_s1: 0.036928, loss_fp: 0.003024, loss_freq: 0.038739
[17:10:22.689] iteration 14760: loss: 0.130831, loss_s1: 0.064207, loss_fp: 0.002007, loss_freq: 0.132749
[17:10:23.310] iteration 14761: loss: 0.054536, loss_s1: 0.035501, loss_fp: 0.009910, loss_freq: 0.023701
[17:10:23.933] iteration 14762: loss: 0.048714, loss_s1: 0.036581, loss_fp: 0.001680, loss_freq: 0.018149
[17:10:24.555] iteration 14763: loss: 0.064104, loss_s1: 0.046483, loss_fp: 0.007860, loss_freq: 0.038252
[17:10:25.181] iteration 14764: loss: 0.089007, loss_s1: 0.074462, loss_fp: 0.006339, loss_freq: 0.045603
[17:10:25.802] iteration 14765: loss: 0.063731, loss_s1: 0.034954, loss_fp: 0.001936, loss_freq: 0.038359
[17:10:26.431] iteration 14766: loss: 0.042746, loss_s1: 0.027634, loss_fp: 0.001000, loss_freq: 0.011999
[17:10:27.056] iteration 14767: loss: 0.094857, loss_s1: 0.061205, loss_fp: 0.010316, loss_freq: 0.064225
[17:10:27.679] iteration 14768: loss: 0.056145, loss_s1: 0.026967, loss_fp: 0.013355, loss_freq: 0.039405
[17:10:28.304] iteration 14769: loss: 0.040163, loss_s1: 0.026651, loss_fp: 0.001409, loss_freq: 0.017676
[17:10:28.928] iteration 14770: loss: 0.070422, loss_s1: 0.063941, loss_fp: 0.000678, loss_freq: 0.023503
[17:10:29.553] iteration 14771: loss: 0.069579, loss_s1: 0.033162, loss_fp: 0.003048, loss_freq: 0.072499
[17:10:30.180] iteration 14772: loss: 0.052032, loss_s1: 0.027786, loss_fp: 0.004883, loss_freq: 0.035833
[17:10:30.809] iteration 14773: loss: 0.110898, loss_s1: 0.025785, loss_fp: 0.005451, loss_freq: 0.009988
[17:10:31.436] iteration 14774: loss: 0.048735, loss_s1: 0.015231, loss_fp: 0.004713, loss_freq: 0.013365
[17:10:32.061] iteration 14775: loss: 0.060029, loss_s1: 0.047659, loss_fp: 0.001331, loss_freq: 0.006751
[17:10:32.684] iteration 14776: loss: 0.050963, loss_s1: 0.031816, loss_fp: 0.001127, loss_freq: 0.015690
[17:10:33.308] iteration 14777: loss: 0.071533, loss_s1: 0.057837, loss_fp: 0.003554, loss_freq: 0.026594
[17:10:33.932] iteration 14778: loss: 0.050968, loss_s1: 0.050935, loss_fp: 0.001423, loss_freq: 0.004858
[17:10:34.557] iteration 14779: loss: 0.109184, loss_s1: 0.079607, loss_fp: 0.011197, loss_freq: 0.035266
[17:10:35.188] iteration 14780: loss: 0.048309, loss_s1: 0.040047, loss_fp: 0.007867, loss_freq: 0.016971
[17:10:35.813] iteration 14781: loss: 0.077160, loss_s1: 0.097174, loss_fp: 0.002107, loss_freq: 0.023432
[17:10:36.438] iteration 14782: loss: 0.125317, loss_s1: 0.103067, loss_fp: 0.006563, loss_freq: 0.108865
[17:10:37.064] iteration 14783: loss: 0.053001, loss_s1: 0.043290, loss_fp: 0.006408, loss_freq: 0.006980
[17:10:37.688] iteration 14784: loss: 0.083259, loss_s1: 0.068109, loss_fp: 0.002377, loss_freq: 0.022196
[17:10:38.314] iteration 14785: loss: 0.060807, loss_s1: 0.037843, loss_fp: 0.003032, loss_freq: 0.029629
[17:10:38.934] iteration 14786: loss: 0.081711, loss_s1: 0.074588, loss_fp: 0.001050, loss_freq: 0.035922
[17:10:39.559] iteration 14787: loss: 0.050854, loss_s1: 0.039338, loss_fp: 0.002512, loss_freq: 0.025179
[17:10:40.184] iteration 14788: loss: 0.038942, loss_s1: 0.006684, loss_fp: 0.000945, loss_freq: 0.014968
[17:10:40.812] iteration 14789: loss: 0.054904, loss_s1: 0.059651, loss_fp: 0.001859, loss_freq: 0.015724
[17:10:41.436] iteration 14790: loss: 0.051217, loss_s1: 0.038865, loss_fp: 0.008407, loss_freq: 0.014718
[17:10:42.062] iteration 14791: loss: 0.076108, loss_s1: 0.041424, loss_fp: 0.019709, loss_freq: 0.015291
[17:10:42.686] iteration 14792: loss: 0.080311, loss_s1: 0.050721, loss_fp: 0.011816, loss_freq: 0.044460
[17:10:43.309] iteration 14793: loss: 0.055407, loss_s1: 0.031520, loss_fp: 0.006122, loss_freq: 0.019015
[17:10:43.932] iteration 14794: loss: 0.079523, loss_s1: 0.070827, loss_fp: 0.001334, loss_freq: 0.045056
[17:10:44.562] iteration 14795: loss: 0.068461, loss_s1: 0.051101, loss_fp: 0.002437, loss_freq: 0.029453
[17:10:45.186] iteration 14796: loss: 0.031649, loss_s1: 0.008764, loss_fp: 0.000870, loss_freq: 0.008394
[17:10:45.810] iteration 14797: loss: 0.076353, loss_s1: 0.042052, loss_fp: 0.001681, loss_freq: 0.038763
[17:10:46.435] iteration 14798: loss: 0.097593, loss_s1: 0.088172, loss_fp: 0.004125, loss_freq: 0.070394
[17:10:47.060] iteration 14799: loss: 0.040736, loss_s1: 0.028678, loss_fp: 0.005926, loss_freq: 0.017643
[17:10:47.687] iteration 14800: loss: 0.053939, loss_s1: 0.035134, loss_fp: 0.006702, loss_freq: 0.026876
[17:10:50.924] iteration 14800 : mean_dice : 0.719000
[17:10:51.567] iteration 14801: loss: 0.102637, loss_s1: 0.091234, loss_fp: 0.007369, loss_freq: 0.064327
[17:10:52.192] iteration 14802: loss: 0.077445, loss_s1: 0.043086, loss_fp: 0.001750, loss_freq: 0.018875
[17:10:52.817] iteration 14803: loss: 0.103909, loss_s1: 0.073537, loss_fp: 0.006443, loss_freq: 0.046470
[17:10:53.441] iteration 14804: loss: 0.050121, loss_s1: 0.029066, loss_fp: 0.002070, loss_freq: 0.027920
[17:10:54.066] iteration 14805: loss: 0.061721, loss_s1: 0.033961, loss_fp: 0.014534, loss_freq: 0.029742
[17:10:54.689] iteration 14806: loss: 0.030787, loss_s1: 0.022361, loss_fp: 0.003511, loss_freq: 0.006367
[17:10:55.314] iteration 14807: loss: 0.045497, loss_s1: 0.032706, loss_fp: 0.000953, loss_freq: 0.013230
[17:10:55.933] iteration 14808: loss: 0.061429, loss_s1: 0.039010, loss_fp: 0.000980, loss_freq: 0.016820
[17:10:56.561] iteration 14809: loss: 0.066187, loss_s1: 0.056416, loss_fp: 0.002573, loss_freq: 0.029530
[17:10:57.187] iteration 14810: loss: 0.062551, loss_s1: 0.035889, loss_fp: 0.007615, loss_freq: 0.043041
[17:10:57.808] iteration 14811: loss: 0.070280, loss_s1: 0.067066, loss_fp: 0.006894, loss_freq: 0.012278
[17:10:58.429] iteration 14812: loss: 0.088103, loss_s1: 0.068776, loss_fp: 0.001999, loss_freq: 0.048880
[17:10:59.407] iteration 14813: loss: 0.071075, loss_s1: 0.085134, loss_fp: 0.003080, loss_freq: 0.013861
[17:11:00.047] iteration 14814: loss: 0.075646, loss_s1: 0.082704, loss_fp: 0.002236, loss_freq: 0.027314
[17:11:00.706] iteration 14815: loss: 0.068251, loss_s1: 0.053145, loss_fp: 0.004625, loss_freq: 0.021295
[17:11:01.360] iteration 14816: loss: 0.063107, loss_s1: 0.046984, loss_fp: 0.001664, loss_freq: 0.030364
[17:11:02.017] iteration 14817: loss: 0.042504, loss_s1: 0.022847, loss_fp: 0.001761, loss_freq: 0.017077
[17:11:02.666] iteration 14818: loss: 0.085089, loss_s1: 0.061045, loss_fp: 0.014126, loss_freq: 0.035935
[17:11:03.294] iteration 14819: loss: 0.077879, loss_s1: 0.110190, loss_fp: 0.003588, loss_freq: 0.006190
[17:11:03.917] iteration 14820: loss: 0.079731, loss_s1: 0.104514, loss_fp: 0.004867, loss_freq: 0.014160
[17:11:04.536] iteration 14821: loss: 0.063950, loss_s1: 0.053860, loss_fp: 0.008131, loss_freq: 0.030312
[17:11:05.164] iteration 14822: loss: 0.053750, loss_s1: 0.048323, loss_fp: 0.004366, loss_freq: 0.018150
[17:11:05.790] iteration 14823: loss: 0.061609, loss_s1: 0.028944, loss_fp: 0.005584, loss_freq: 0.038326
[17:11:06.420] iteration 14824: loss: 0.078541, loss_s1: 0.091312, loss_fp: 0.003079, loss_freq: 0.022421
[17:11:07.042] iteration 14825: loss: 0.102818, loss_s1: 0.083713, loss_fp: 0.001455, loss_freq: 0.085739
[17:11:07.662] iteration 14826: loss: 0.077264, loss_s1: 0.058910, loss_fp: 0.001685, loss_freq: 0.037888
[17:11:08.293] iteration 14827: loss: 0.075451, loss_s1: 0.078054, loss_fp: 0.006092, loss_freq: 0.030674
[17:11:08.920] iteration 14828: loss: 0.103622, loss_s1: 0.055110, loss_fp: 0.001591, loss_freq: 0.104592
[17:11:09.544] iteration 14829: loss: 0.059147, loss_s1: 0.049987, loss_fp: 0.006234, loss_freq: 0.009496
[17:11:10.173] iteration 14830: loss: 0.052721, loss_s1: 0.047258, loss_fp: 0.004199, loss_freq: 0.012463
[17:11:10.800] iteration 14831: loss: 0.056383, loss_s1: 0.046302, loss_fp: 0.001238, loss_freq: 0.014894
[17:11:11.421] iteration 14832: loss: 0.073619, loss_s1: 0.049005, loss_fp: 0.002830, loss_freq: 0.047522
[17:11:12.044] iteration 14833: loss: 0.043497, loss_s1: 0.032831, loss_fp: 0.000336, loss_freq: 0.009934
[17:11:12.670] iteration 14834: loss: 0.049099, loss_s1: 0.018598, loss_fp: 0.000742, loss_freq: 0.016633
[17:11:13.301] iteration 14835: loss: 0.041230, loss_s1: 0.015935, loss_fp: 0.001857, loss_freq: 0.017241
[17:11:13.927] iteration 14836: loss: 0.124012, loss_s1: 0.114432, loss_fp: 0.005599, loss_freq: 0.095993
[17:11:14.554] iteration 14837: loss: 0.054744, loss_s1: 0.024983, loss_fp: 0.003500, loss_freq: 0.021390
[17:11:15.179] iteration 14838: loss: 0.045086, loss_s1: 0.028452, loss_fp: 0.001714, loss_freq: 0.020789
[17:11:15.805] iteration 14839: loss: 0.037085, loss_s1: 0.022433, loss_fp: 0.002663, loss_freq: 0.010911
[17:11:16.431] iteration 14840: loss: 0.101933, loss_s1: 0.090525, loss_fp: 0.004324, loss_freq: 0.049500
[17:11:17.057] iteration 14841: loss: 0.061369, loss_s1: 0.046044, loss_fp: 0.001961, loss_freq: 0.035602
[17:11:17.682] iteration 14842: loss: 0.038962, loss_s1: 0.028917, loss_fp: 0.000576, loss_freq: 0.011205
[17:11:18.309] iteration 14843: loss: 0.043501, loss_s1: 0.028173, loss_fp: 0.007263, loss_freq: 0.017187
[17:11:18.934] iteration 14844: loss: 0.085645, loss_s1: 0.039175, loss_fp: 0.001379, loss_freq: 0.026725
[17:11:19.559] iteration 14845: loss: 0.051818, loss_s1: 0.046051, loss_fp: 0.001481, loss_freq: 0.016027
[17:11:20.187] iteration 14846: loss: 0.046791, loss_s1: 0.026576, loss_fp: 0.002252, loss_freq: 0.008290
[17:11:20.813] iteration 14847: loss: 0.087469, loss_s1: 0.030001, loss_fp: 0.006055, loss_freq: 0.049032
[17:11:21.436] iteration 14848: loss: 0.068169, loss_s1: 0.053921, loss_fp: 0.002924, loss_freq: 0.046212
[17:11:22.060] iteration 14849: loss: 0.110598, loss_s1: 0.074484, loss_fp: 0.023922, loss_freq: 0.052256
[17:11:22.684] iteration 14850: loss: 0.089144, loss_s1: 0.078859, loss_fp: 0.015113, loss_freq: 0.031618
[17:11:23.311] iteration 14851: loss: 0.057619, loss_s1: 0.015482, loss_fp: 0.001803, loss_freq: 0.048139
[17:11:23.941] iteration 14852: loss: 0.063378, loss_s1: 0.055330, loss_fp: 0.006925, loss_freq: 0.021202
[17:11:24.570] iteration 14853: loss: 0.071545, loss_s1: 0.033178, loss_fp: 0.023311, loss_freq: 0.014155
[17:11:25.195] iteration 14854: loss: 0.078635, loss_s1: 0.077604, loss_fp: 0.003537, loss_freq: 0.033769
[17:11:25.821] iteration 14855: loss: 0.083321, loss_s1: 0.048216, loss_fp: 0.014751, loss_freq: 0.056917
[17:11:26.448] iteration 14856: loss: 0.069572, loss_s1: 0.029766, loss_fp: 0.015692, loss_freq: 0.038291
[17:11:27.075] iteration 14857: loss: 0.074537, loss_s1: 0.048441, loss_fp: 0.006819, loss_freq: 0.026711
[17:11:27.700] iteration 14858: loss: 0.088168, loss_s1: 0.081830, loss_fp: 0.004315, loss_freq: 0.008683
[17:11:28.329] iteration 14859: loss: 0.041318, loss_s1: 0.030143, loss_fp: 0.006763, loss_freq: 0.011420
[17:11:28.953] iteration 14860: loss: 0.065738, loss_s1: 0.060480, loss_fp: 0.004128, loss_freq: 0.027689
[17:11:29.580] iteration 14861: loss: 0.067582, loss_s1: 0.044872, loss_fp: 0.001787, loss_freq: 0.026256
[17:11:30.207] iteration 14862: loss: 0.075072, loss_s1: 0.062321, loss_fp: 0.003772, loss_freq: 0.039861
[17:11:30.835] iteration 14863: loss: 0.075780, loss_s1: 0.051949, loss_fp: 0.005101, loss_freq: 0.050017
[17:11:31.461] iteration 14864: loss: 0.060484, loss_s1: 0.036724, loss_fp: 0.002293, loss_freq: 0.010961
[17:11:32.084] iteration 14865: loss: 0.056049, loss_s1: 0.018248, loss_fp: 0.001407, loss_freq: 0.054578
[17:11:32.713] iteration 14866: loss: 0.054043, loss_s1: 0.039517, loss_fp: 0.003830, loss_freq: 0.031735
[17:11:33.341] iteration 14867: loss: 0.043656, loss_s1: 0.017441, loss_fp: 0.000895, loss_freq: 0.019798
[17:11:33.968] iteration 14868: loss: 0.050281, loss_s1: 0.026732, loss_fp: 0.002107, loss_freq: 0.021799
[17:11:34.603] iteration 14869: loss: 0.039519, loss_s1: 0.017844, loss_fp: 0.003570, loss_freq: 0.007675
[17:11:35.229] iteration 14870: loss: 0.071744, loss_s1: 0.030104, loss_fp: 0.001822, loss_freq: 0.041428
[17:11:35.858] iteration 14871: loss: 0.039850, loss_s1: 0.023864, loss_fp: 0.000915, loss_freq: 0.012299
[17:11:36.485] iteration 14872: loss: 0.062870, loss_s1: 0.030976, loss_fp: 0.000675, loss_freq: 0.022106
[17:11:37.110] iteration 14873: loss: 0.054912, loss_s1: 0.036137, loss_fp: 0.000818, loss_freq: 0.020990
[17:11:37.734] iteration 14874: loss: 0.039357, loss_s1: 0.021807, loss_fp: 0.003512, loss_freq: 0.008867
[17:11:38.363] iteration 14875: loss: 0.049065, loss_s1: 0.018543, loss_fp: 0.000574, loss_freq: 0.022078
[17:11:38.991] iteration 14876: loss: 0.053730, loss_s1: 0.047425, loss_fp: 0.003769, loss_freq: 0.008916
[17:11:39.616] iteration 14877: loss: 0.047487, loss_s1: 0.036460, loss_fp: 0.001858, loss_freq: 0.016116
[17:11:40.240] iteration 14878: loss: 0.097987, loss_s1: 0.073228, loss_fp: 0.005843, loss_freq: 0.082638
[17:11:40.862] iteration 14879: loss: 0.068553, loss_s1: 0.027314, loss_fp: 0.003005, loss_freq: 0.043051
[17:11:41.488] iteration 14880: loss: 0.051282, loss_s1: 0.044024, loss_fp: 0.000747, loss_freq: 0.023789
[17:11:42.116] iteration 14881: loss: 0.047248, loss_s1: 0.034731, loss_fp: 0.004700, loss_freq: 0.018357
[17:11:42.744] iteration 14882: loss: 0.071894, loss_s1: 0.066020, loss_fp: 0.001620, loss_freq: 0.022582
[17:11:43.368] iteration 14883: loss: 0.077998, loss_s1: 0.052729, loss_fp: 0.002867, loss_freq: 0.048559
[17:11:43.991] iteration 14884: loss: 0.065107, loss_s1: 0.054230, loss_fp: 0.003569, loss_freq: 0.034143
[17:11:44.617] iteration 14885: loss: 0.064650, loss_s1: 0.048102, loss_fp: 0.003823, loss_freq: 0.039225
[17:11:45.245] iteration 14886: loss: 0.051396, loss_s1: 0.037698, loss_fp: 0.000900, loss_freq: 0.010472
[17:11:45.871] iteration 14887: loss: 0.092546, loss_s1: 0.065450, loss_fp: 0.011458, loss_freq: 0.056050
[17:11:46.559] iteration 14888: loss: 0.091416, loss_s1: 0.075518, loss_fp: 0.005792, loss_freq: 0.027972
[17:11:47.219] iteration 14889: loss: 0.064414, loss_s1: 0.037421, loss_fp: 0.002998, loss_freq: 0.054936
[17:11:47.863] iteration 14890: loss: 0.060036, loss_s1: 0.051290, loss_fp: 0.001421, loss_freq: 0.020301
[17:11:48.486] iteration 14891: loss: 0.045074, loss_s1: 0.029506, loss_fp: 0.004872, loss_freq: 0.008718
[17:11:49.109] iteration 14892: loss: 0.092577, loss_s1: 0.112458, loss_fp: 0.003704, loss_freq: 0.025811
[17:11:49.735] iteration 14893: loss: 0.093179, loss_s1: 0.076388, loss_fp: 0.000996, loss_freq: 0.051103
[17:11:50.360] iteration 14894: loss: 0.069274, loss_s1: 0.074581, loss_fp: 0.006766, loss_freq: 0.022904
[17:11:50.984] iteration 14895: loss: 0.050688, loss_s1: 0.040312, loss_fp: 0.007112, loss_freq: 0.011913
[17:11:51.612] iteration 14896: loss: 0.097135, loss_s1: 0.080043, loss_fp: 0.012819, loss_freq: 0.048999
[17:11:52.238] iteration 14897: loss: 0.091620, loss_s1: 0.067817, loss_fp: 0.005712, loss_freq: 0.064973
[17:11:52.859] iteration 14898: loss: 0.031457, loss_s1: 0.005558, loss_fp: 0.002288, loss_freq: 0.014822
[17:11:53.484] iteration 14899: loss: 0.180972, loss_s1: 0.056896, loss_fp: 0.000594, loss_freq: 0.027868
[17:11:54.108] iteration 14900: loss: 0.069709, loss_s1: 0.080723, loss_fp: 0.000797, loss_freq: 0.010062
[17:11:54.735] iteration 14901: loss: 0.052874, loss_s1: 0.049376, loss_fp: 0.001133, loss_freq: 0.010277
[17:11:55.411] iteration 14902: loss: 0.062568, loss_s1: 0.018779, loss_fp: 0.026235, loss_freq: 0.035007
[17:11:56.034] iteration 14903: loss: 0.084592, loss_s1: 0.072960, loss_fp: 0.002091, loss_freq: 0.027831
[17:11:56.655] iteration 14904: loss: 0.079808, loss_s1: 0.078436, loss_fp: 0.001310, loss_freq: 0.020257
[17:11:57.280] iteration 14905: loss: 0.058792, loss_s1: 0.025752, loss_fp: 0.001958, loss_freq: 0.019091
[17:11:57.903] iteration 14906: loss: 0.067884, loss_s1: 0.040913, loss_fp: 0.000246, loss_freq: 0.038055
[17:11:58.527] iteration 14907: loss: 0.062538, loss_s1: 0.057956, loss_fp: 0.001484, loss_freq: 0.029632
[17:11:59.152] iteration 14908: loss: 0.043283, loss_s1: 0.027077, loss_fp: 0.001702, loss_freq: 0.020493
[17:11:59.776] iteration 14909: loss: 0.047689, loss_s1: 0.020894, loss_fp: 0.000532, loss_freq: 0.036119
[17:12:00.403] iteration 14910: loss: 0.059453, loss_s1: 0.046770, loss_fp: 0.000336, loss_freq: 0.021925
[17:12:01.026] iteration 14911: loss: 0.091935, loss_s1: 0.068953, loss_fp: 0.005981, loss_freq: 0.051941
[17:12:01.649] iteration 14912: loss: 0.064123, loss_s1: 0.060950, loss_fp: 0.004188, loss_freq: 0.029443
[17:12:02.277] iteration 14913: loss: 0.127254, loss_s1: 0.155426, loss_fp: 0.005294, loss_freq: 0.021769
[17:12:02.899] iteration 14914: loss: 0.090048, loss_s1: 0.045838, loss_fp: 0.004361, loss_freq: 0.071468
[17:12:03.526] iteration 14915: loss: 0.104769, loss_s1: 0.090079, loss_fp: 0.012734, loss_freq: 0.063436
[17:12:04.149] iteration 14916: loss: 0.088278, loss_s1: 0.082102, loss_fp: 0.006395, loss_freq: 0.048307
[17:12:04.776] iteration 14917: loss: 0.064757, loss_s1: 0.048346, loss_fp: 0.005498, loss_freq: 0.018112
[17:12:05.399] iteration 14918: loss: 0.070434, loss_s1: 0.052749, loss_fp: 0.002825, loss_freq: 0.042560
[17:12:06.073] iteration 14919: loss: 0.059729, loss_s1: 0.043427, loss_fp: 0.003653, loss_freq: 0.010464
[17:12:06.697] iteration 14920: loss: 0.135068, loss_s1: 0.127688, loss_fp: 0.001866, loss_freq: 0.081257
[17:12:07.320] iteration 14921: loss: 0.123611, loss_s1: 0.061897, loss_fp: 0.005587, loss_freq: 0.115795
[17:12:07.943] iteration 14922: loss: 0.073442, loss_s1: 0.055853, loss_fp: 0.003833, loss_freq: 0.049264
[17:12:08.567] iteration 14923: loss: 0.064532, loss_s1: 0.024377, loss_fp: 0.005560, loss_freq: 0.015230
[17:12:09.195] iteration 14924: loss: 0.033277, loss_s1: 0.012962, loss_fp: 0.002764, loss_freq: 0.015124
[17:12:09.818] iteration 14925: loss: 0.083225, loss_s1: 0.078314, loss_fp: 0.004893, loss_freq: 0.048317
[17:12:10.446] iteration 14926: loss: 0.075008, loss_s1: 0.065605, loss_fp: 0.004145, loss_freq: 0.019606
[17:12:11.073] iteration 14927: loss: 0.038960, loss_s1: 0.021249, loss_fp: 0.002215, loss_freq: 0.008977
[17:12:11.710] iteration 14928: loss: 0.086856, loss_s1: 0.045163, loss_fp: 0.001863, loss_freq: 0.045237
[17:12:12.353] iteration 14929: loss: 0.073597, loss_s1: 0.056828, loss_fp: 0.002216, loss_freq: 0.051879
[17:12:13.010] iteration 14930: loss: 0.049148, loss_s1: 0.025566, loss_fp: 0.001528, loss_freq: 0.009259
[17:12:13.669] iteration 14931: loss: 0.061229, loss_s1: 0.045133, loss_fp: 0.002626, loss_freq: 0.027258
[17:12:14.328] iteration 14932: loss: 0.067012, loss_s1: 0.032073, loss_fp: 0.005271, loss_freq: 0.043953
[17:12:14.996] iteration 14933: loss: 0.049258, loss_s1: 0.029998, loss_fp: 0.001574, loss_freq: 0.030238
[17:12:15.640] iteration 14934: loss: 0.065547, loss_s1: 0.038776, loss_fp: 0.006396, loss_freq: 0.020614
[17:12:16.275] iteration 14935: loss: 0.037894, loss_s1: 0.026277, loss_fp: 0.003529, loss_freq: 0.009004
[17:12:16.908] iteration 14936: loss: 0.074052, loss_s1: 0.056194, loss_fp: 0.005745, loss_freq: 0.026985
[17:12:17.540] iteration 14937: loss: 0.060030, loss_s1: 0.015366, loss_fp: 0.002239, loss_freq: 0.026100
[17:12:18.172] iteration 14938: loss: 0.062830, loss_s1: 0.026872, loss_fp: 0.001444, loss_freq: 0.028716
[17:12:18.801] iteration 14939: loss: 0.063700, loss_s1: 0.045282, loss_fp: 0.000839, loss_freq: 0.029246
[17:12:19.491] iteration 14940: loss: 0.100125, loss_s1: 0.053857, loss_fp: 0.001672, loss_freq: 0.059496
[17:12:20.173] iteration 14941: loss: 0.056285, loss_s1: 0.036063, loss_fp: 0.004852, loss_freq: 0.024864
[17:12:20.897] iteration 14942: loss: 0.060206, loss_s1: 0.061698, loss_fp: 0.006563, loss_freq: 0.017029
[17:12:21.600] iteration 14943: loss: 0.114302, loss_s1: 0.076021, loss_fp: 0.005431, loss_freq: 0.107849
[17:12:22.278] iteration 14944: loss: 0.062982, loss_s1: 0.057080, loss_fp: 0.004345, loss_freq: 0.012192
[17:12:22.908] iteration 14945: loss: 0.056018, loss_s1: 0.043733, loss_fp: 0.001580, loss_freq: 0.009196
[17:12:23.537] iteration 14946: loss: 0.058467, loss_s1: 0.066869, loss_fp: 0.002058, loss_freq: 0.007484
[17:12:24.167] iteration 14947: loss: 0.056663, loss_s1: 0.039901, loss_fp: 0.002093, loss_freq: 0.025499
[17:12:24.794] iteration 14948: loss: 0.058942, loss_s1: 0.044095, loss_fp: 0.006640, loss_freq: 0.029815
[17:12:25.425] iteration 14949: loss: 0.047794, loss_s1: 0.006678, loss_fp: 0.002115, loss_freq: 0.036235
[17:12:26.054] iteration 14950: loss: 0.048384, loss_s1: 0.018603, loss_fp: 0.002819, loss_freq: 0.027325
[17:12:26.679] iteration 14951: loss: 0.044703, loss_s1: 0.028579, loss_fp: 0.000292, loss_freq: 0.021108
[17:12:27.307] iteration 14952: loss: 0.060703, loss_s1: 0.028586, loss_fp: 0.003146, loss_freq: 0.020208
[17:12:27.936] iteration 14953: loss: 0.077552, loss_s1: 0.064320, loss_fp: 0.003417, loss_freq: 0.055919
[17:12:28.564] iteration 14954: loss: 0.056199, loss_s1: 0.021075, loss_fp: 0.005591, loss_freq: 0.039890
[17:12:29.189] iteration 14955: loss: 0.075874, loss_s1: 0.042702, loss_fp: 0.001948, loss_freq: 0.029799
[17:12:29.815] iteration 14956: loss: 0.083212, loss_s1: 0.090771, loss_fp: 0.003917, loss_freq: 0.022088
[17:12:30.447] iteration 14957: loss: 0.060660, loss_s1: 0.049278, loss_fp: 0.004863, loss_freq: 0.010574
[17:12:31.075] iteration 14958: loss: 0.080699, loss_s1: 0.042367, loss_fp: 0.015992, loss_freq: 0.051406
[17:12:31.709] iteration 14959: loss: 0.079145, loss_s1: 0.069270, loss_fp: 0.001989, loss_freq: 0.053212
[17:12:32.338] iteration 14960: loss: 0.051581, loss_s1: 0.057027, loss_fp: 0.002835, loss_freq: 0.009635
[17:12:32.961] iteration 14961: loss: 0.069991, loss_s1: 0.052932, loss_fp: 0.003132, loss_freq: 0.014815
[17:12:33.590] iteration 14962: loss: 0.070419, loss_s1: 0.035236, loss_fp: 0.006426, loss_freq: 0.055746
[17:12:34.218] iteration 14963: loss: 0.065395, loss_s1: 0.035177, loss_fp: 0.004545, loss_freq: 0.032612
[17:12:34.844] iteration 14964: loss: 0.101983, loss_s1: 0.117468, loss_fp: 0.005706, loss_freq: 0.032623
[17:12:35.469] iteration 14965: loss: 0.053467, loss_s1: 0.036987, loss_fp: 0.004583, loss_freq: 0.029807
[17:12:36.093] iteration 14966: loss: 0.087672, loss_s1: 0.053926, loss_fp: 0.002029, loss_freq: 0.043741
[17:12:36.717] iteration 14967: loss: 0.043393, loss_s1: 0.044520, loss_fp: 0.000630, loss_freq: 0.002832
[17:12:37.345] iteration 14968: loss: 0.084742, loss_s1: 0.044925, loss_fp: 0.004114, loss_freq: 0.026256
[17:12:37.976] iteration 14969: loss: 0.068629, loss_s1: 0.039325, loss_fp: 0.000768, loss_freq: 0.025037
[17:12:38.605] iteration 14970: loss: 0.065377, loss_s1: 0.041168, loss_fp: 0.001177, loss_freq: 0.031227
[17:12:39.230] iteration 14971: loss: 0.074623, loss_s1: 0.061593, loss_fp: 0.002512, loss_freq: 0.035406
[17:12:39.854] iteration 14972: loss: 0.057298, loss_s1: 0.060498, loss_fp: 0.000622, loss_freq: 0.004288
[17:12:40.479] iteration 14973: loss: 0.044925, loss_s1: 0.013408, loss_fp: 0.003204, loss_freq: 0.014608
[17:12:41.504] iteration 14974: loss: 0.053342, loss_s1: 0.033884, loss_fp: 0.000398, loss_freq: 0.024307
[17:12:42.166] iteration 14975: loss: 0.069297, loss_s1: 0.061817, loss_fp: 0.007738, loss_freq: 0.027008
[17:12:42.825] iteration 14976: loss: 0.064879, loss_s1: 0.059321, loss_fp: 0.001016, loss_freq: 0.012602
[17:12:43.457] iteration 14977: loss: 0.037387, loss_s1: 0.009733, loss_fp: 0.000710, loss_freq: 0.014589
[17:12:44.085] iteration 14978: loss: 0.050063, loss_s1: 0.038794, loss_fp: 0.003304, loss_freq: 0.021409
[17:12:44.712] iteration 14979: loss: 0.083517, loss_s1: 0.060328, loss_fp: 0.001414, loss_freq: 0.042176
[17:12:45.340] iteration 14980: loss: 0.035541, loss_s1: 0.016973, loss_fp: 0.000933, loss_freq: 0.016847
[17:12:45.964] iteration 14981: loss: 0.054595, loss_s1: 0.052257, loss_fp: 0.001587, loss_freq: 0.015462
[17:12:46.589] iteration 14982: loss: 0.072830, loss_s1: 0.057835, loss_fp: 0.000700, loss_freq: 0.054576
[17:12:47.216] iteration 14983: loss: 0.073337, loss_s1: 0.086577, loss_fp: 0.003993, loss_freq: 0.008002
[17:12:47.845] iteration 14984: loss: 0.043165, loss_s1: 0.009824, loss_fp: 0.001821, loss_freq: 0.019520
[17:12:48.471] iteration 14985: loss: 0.067208, loss_s1: 0.030820, loss_fp: 0.004931, loss_freq: 0.038729
[17:12:49.108] iteration 14986: loss: 0.065542, loss_s1: 0.042853, loss_fp: 0.007269, loss_freq: 0.042659
[17:12:49.789] iteration 14987: loss: 0.062749, loss_s1: 0.035123, loss_fp: 0.004582, loss_freq: 0.038904
[17:12:50.458] iteration 14988: loss: 0.066738, loss_s1: 0.055000, loss_fp: 0.018583, loss_freq: 0.023232
[17:12:51.137] iteration 14989: loss: 0.061883, loss_s1: 0.046231, loss_fp: 0.005487, loss_freq: 0.030819
[17:12:51.792] iteration 14990: loss: 0.039636, loss_s1: 0.025555, loss_fp: 0.001254, loss_freq: 0.008057
[17:12:52.451] iteration 14991: loss: 0.070693, loss_s1: 0.029905, loss_fp: 0.003746, loss_freq: 0.049467
[17:12:53.077] iteration 14992: loss: 0.037441, loss_s1: 0.014275, loss_fp: 0.000864, loss_freq: 0.020324
[17:12:53.702] iteration 14993: loss: 0.107971, loss_s1: 0.048512, loss_fp: 0.005875, loss_freq: 0.033729
[17:12:54.328] iteration 14994: loss: 0.034424, loss_s1: 0.025034, loss_fp: 0.001436, loss_freq: 0.004270
[17:12:54.953] iteration 14995: loss: 0.043868, loss_s1: 0.030672, loss_fp: 0.002397, loss_freq: 0.019934
[17:12:55.576] iteration 14996: loss: 0.061775, loss_s1: 0.029781, loss_fp: 0.004350, loss_freq: 0.017979
[17:12:56.194] iteration 14997: loss: 0.129672, loss_s1: 0.098472, loss_fp: 0.001259, loss_freq: 0.117664
[17:12:56.819] iteration 14998: loss: 0.039424, loss_s1: 0.027811, loss_fp: 0.000588, loss_freq: 0.017916
[17:12:57.445] iteration 14999: loss: 0.076805, loss_s1: 0.074082, loss_fp: 0.003775, loss_freq: 0.030166
[17:12:58.067] iteration 15000: loss: 0.067553, loss_s1: 0.056241, loss_fp: 0.002425, loss_freq: 0.034340
[17:13:01.822] iteration 15000 : mean_dice : 0.716283
[17:13:02.524] iteration 15001: loss: 0.077893, loss_s1: 0.065124, loss_fp: 0.001281, loss_freq: 0.031779
[17:13:03.210] iteration 15002: loss: 0.092162, loss_s1: 0.054340, loss_fp: 0.006511, loss_freq: 0.041263
[17:13:03.855] iteration 15003: loss: 0.037216, loss_s1: 0.017695, loss_fp: 0.001120, loss_freq: 0.015542
[17:13:04.501] iteration 15004: loss: 0.046554, loss_s1: 0.040561, loss_fp: 0.000832, loss_freq: 0.022019
[17:13:05.139] iteration 15005: loss: 0.051809, loss_s1: 0.022705, loss_fp: 0.003711, loss_freq: 0.031154
[17:13:05.780] iteration 15006: loss: 0.056469, loss_s1: 0.032411, loss_fp: 0.005727, loss_freq: 0.034573
[17:13:06.424] iteration 15007: loss: 0.058122, loss_s1: 0.058171, loss_fp: 0.000275, loss_freq: 0.012091
[17:13:07.063] iteration 15008: loss: 0.062293, loss_s1: 0.037725, loss_fp: 0.004640, loss_freq: 0.020015
[17:13:07.706] iteration 15009: loss: 0.085378, loss_s1: 0.067989, loss_fp: 0.003554, loss_freq: 0.062077
[17:13:08.332] iteration 15010: loss: 0.104667, loss_s1: 0.072002, loss_fp: 0.012090, loss_freq: 0.039060
[17:13:08.968] iteration 15011: loss: 0.080658, loss_s1: 0.076753, loss_fp: 0.003717, loss_freq: 0.030726
[17:13:09.596] iteration 15012: loss: 0.078786, loss_s1: 0.073805, loss_fp: 0.005965, loss_freq: 0.030904
[17:13:10.220] iteration 15013: loss: 0.092462, loss_s1: 0.056505, loss_fp: 0.003592, loss_freq: 0.066673
[17:13:10.844] iteration 15014: loss: 0.065961, loss_s1: 0.053239, loss_fp: 0.002322, loss_freq: 0.031450
[17:13:11.470] iteration 15015: loss: 0.074981, loss_s1: 0.083066, loss_fp: 0.001484, loss_freq: 0.026885
[17:13:12.130] iteration 15016: loss: 0.077890, loss_s1: 0.053176, loss_fp: 0.006296, loss_freq: 0.042870
[17:13:12.788] iteration 15017: loss: 0.064715, loss_s1: 0.042508, loss_fp: 0.004951, loss_freq: 0.028467
[17:13:13.445] iteration 15018: loss: 0.043863, loss_s1: 0.019625, loss_fp: 0.002152, loss_freq: 0.021914
[17:13:14.107] iteration 15019: loss: 0.075790, loss_s1: 0.059076, loss_fp: 0.001790, loss_freq: 0.006894
[17:13:14.771] iteration 15020: loss: 0.045207, loss_s1: 0.028561, loss_fp: 0.001589, loss_freq: 0.020326
[17:13:15.443] iteration 15021: loss: 0.066016, loss_s1: 0.075904, loss_fp: 0.003147, loss_freq: 0.018256
[17:13:16.103] iteration 15022: loss: 0.054236, loss_s1: 0.056763, loss_fp: 0.002839, loss_freq: 0.007206
[17:13:16.761] iteration 15023: loss: 0.043573, loss_s1: 0.022268, loss_fp: 0.005062, loss_freq: 0.030649
[17:13:17.390] iteration 15024: loss: 0.092550, loss_s1: 0.109725, loss_fp: 0.003397, loss_freq: 0.034263
[17:13:18.012] iteration 15025: loss: 0.037563, loss_s1: 0.007419, loss_fp: 0.002697, loss_freq: 0.022139
[17:13:18.638] iteration 15026: loss: 0.050534, loss_s1: 0.027358, loss_fp: 0.001381, loss_freq: 0.034632
[17:13:19.270] iteration 15027: loss: 0.059612, loss_s1: 0.031382, loss_fp: 0.003566, loss_freq: 0.032854
[17:13:19.896] iteration 15028: loss: 0.050002, loss_s1: 0.038664, loss_fp: 0.002000, loss_freq: 0.020145
[17:13:20.524] iteration 15029: loss: 0.057720, loss_s1: 0.044626, loss_fp: 0.002039, loss_freq: 0.025250
[17:13:21.153] iteration 15030: loss: 0.045524, loss_s1: 0.037703, loss_fp: 0.001997, loss_freq: 0.012894
[17:13:21.779] iteration 15031: loss: 0.057423, loss_s1: 0.020178, loss_fp: 0.002079, loss_freq: 0.016640
[17:13:22.406] iteration 15032: loss: 0.039052, loss_s1: 0.031594, loss_fp: 0.002112, loss_freq: 0.006220
[17:13:23.034] iteration 15033: loss: 0.057580, loss_s1: 0.046403, loss_fp: 0.004242, loss_freq: 0.026411
[17:13:23.663] iteration 15034: loss: 0.046740, loss_s1: 0.036373, loss_fp: 0.000885, loss_freq: 0.017975
[17:13:24.287] iteration 15035: loss: 0.065990, loss_s1: 0.063811, loss_fp: 0.011755, loss_freq: 0.020452
[17:13:24.912] iteration 15036: loss: 0.043862, loss_s1: 0.030273, loss_fp: 0.001134, loss_freq: 0.011044
[17:13:25.537] iteration 15037: loss: 0.056075, loss_s1: 0.037959, loss_fp: 0.004819, loss_freq: 0.021447
[17:13:26.164] iteration 15038: loss: 0.119699, loss_s1: 0.178420, loss_fp: 0.008961, loss_freq: 0.012519
[17:13:26.789] iteration 15039: loss: 0.123266, loss_s1: 0.106087, loss_fp: 0.013204, loss_freq: 0.082394
[17:13:27.413] iteration 15040: loss: 0.070673, loss_s1: 0.057974, loss_fp: 0.001442, loss_freq: 0.026056
[17:13:28.046] iteration 15041: loss: 0.059232, loss_s1: 0.046810, loss_fp: 0.006537, loss_freq: 0.025293
[17:13:28.668] iteration 15042: loss: 0.051183, loss_s1: 0.043567, loss_fp: 0.001782, loss_freq: 0.018175
[17:13:29.293] iteration 15043: loss: 0.073695, loss_s1: 0.054581, loss_fp: 0.004386, loss_freq: 0.028764
[17:13:29.954] iteration 15044: loss: 0.065507, loss_s1: 0.061169, loss_fp: 0.005837, loss_freq: 0.024008
[17:13:30.616] iteration 15045: loss: 0.072001, loss_s1: 0.045641, loss_fp: 0.000983, loss_freq: 0.050516
[17:13:31.277] iteration 15046: loss: 0.057931, loss_s1: 0.024475, loss_fp: 0.003372, loss_freq: 0.028546
[17:13:31.934] iteration 15047: loss: 0.039477, loss_s1: 0.027059, loss_fp: 0.000888, loss_freq: 0.004288
[17:13:32.558] iteration 15048: loss: 0.077994, loss_s1: 0.072111, loss_fp: 0.005227, loss_freq: 0.034250
[17:13:33.186] iteration 15049: loss: 0.082194, loss_s1: 0.068421, loss_fp: 0.007232, loss_freq: 0.031387
[17:13:33.815] iteration 15050: loss: 0.050825, loss_s1: 0.028946, loss_fp: 0.001821, loss_freq: 0.028797
[17:13:34.444] iteration 15051: loss: 0.044180, loss_s1: 0.032746, loss_fp: 0.004238, loss_freq: 0.015429
[17:13:35.074] iteration 15052: loss: 0.039804, loss_s1: 0.026027, loss_fp: 0.000780, loss_freq: 0.005884
[17:13:35.709] iteration 15053: loss: 0.059705, loss_s1: 0.031207, loss_fp: 0.000506, loss_freq: 0.047553
[17:13:36.332] iteration 15054: loss: 0.050863, loss_s1: 0.035873, loss_fp: 0.000462, loss_freq: 0.021473
[17:13:36.958] iteration 15055: loss: 0.098467, loss_s1: 0.097687, loss_fp: 0.006968, loss_freq: 0.057916
[17:13:37.584] iteration 15056: loss: 0.104928, loss_s1: 0.043890, loss_fp: 0.002092, loss_freq: 0.128343
[17:13:38.211] iteration 15057: loss: 0.071524, loss_s1: 0.053429, loss_fp: 0.002511, loss_freq: 0.030840
[17:13:38.834] iteration 15058: loss: 0.094503, loss_s1: 0.109775, loss_fp: 0.001503, loss_freq: 0.046932
[17:13:39.457] iteration 15059: loss: 0.054011, loss_s1: 0.052977, loss_fp: 0.001108, loss_freq: 0.015529
[17:13:40.116] iteration 15060: loss: 0.069731, loss_s1: 0.047944, loss_fp: 0.002595, loss_freq: 0.009210
[17:13:40.748] iteration 15061: loss: 0.068602, loss_s1: 0.066705, loss_fp: 0.001066, loss_freq: 0.017065
[17:13:41.372] iteration 15062: loss: 0.044507, loss_s1: 0.024882, loss_fp: 0.001249, loss_freq: 0.024084
[17:13:42.002] iteration 15063: loss: 0.046530, loss_s1: 0.038243, loss_fp: 0.000902, loss_freq: 0.016076
[17:13:42.629] iteration 15064: loss: 0.048912, loss_s1: 0.027987, loss_fp: 0.001212, loss_freq: 0.019032
[17:13:43.253] iteration 15065: loss: 0.047597, loss_s1: 0.028635, loss_fp: 0.004870, loss_freq: 0.010066
[17:13:43.878] iteration 15066: loss: 0.072151, loss_s1: 0.022370, loss_fp: 0.002104, loss_freq: 0.028384
[17:13:44.502] iteration 15067: loss: 0.059615, loss_s1: 0.034280, loss_fp: 0.007792, loss_freq: 0.033428
[17:13:45.125] iteration 15068: loss: 0.041344, loss_s1: 0.030995, loss_fp: 0.002581, loss_freq: 0.019026
[17:13:45.751] iteration 15069: loss: 0.054094, loss_s1: 0.036037, loss_fp: 0.004253, loss_freq: 0.030628
[17:13:46.379] iteration 15070: loss: 0.059155, loss_s1: 0.036430, loss_fp: 0.000888, loss_freq: 0.022938
[17:13:47.006] iteration 15071: loss: 0.064863, loss_s1: 0.031011, loss_fp: 0.000223, loss_freq: 0.047455
[17:13:47.629] iteration 15072: loss: 0.060678, loss_s1: 0.050973, loss_fp: 0.008118, loss_freq: 0.016990
[17:13:48.253] iteration 15073: loss: 0.060273, loss_s1: 0.044583, loss_fp: 0.002086, loss_freq: 0.015101
[17:13:48.914] iteration 15074: loss: 0.063069, loss_s1: 0.051587, loss_fp: 0.004203, loss_freq: 0.019030
[17:13:49.568] iteration 15075: loss: 0.052560, loss_s1: 0.023716, loss_fp: 0.002304, loss_freq: 0.034927
[17:13:50.226] iteration 15076: loss: 0.066000, loss_s1: 0.073426, loss_fp: 0.004170, loss_freq: 0.019715
[17:13:50.867] iteration 15077: loss: 0.071736, loss_s1: 0.085753, loss_fp: 0.004421, loss_freq: 0.014935
[17:13:51.492] iteration 15078: loss: 0.052777, loss_s1: 0.023851, loss_fp: 0.001410, loss_freq: 0.012826
[17:13:52.119] iteration 15079: loss: 0.050272, loss_s1: 0.037541, loss_fp: 0.007841, loss_freq: 0.019347
[17:13:52.749] iteration 15080: loss: 0.053897, loss_s1: 0.027522, loss_fp: 0.005513, loss_freq: 0.010329
[17:13:53.377] iteration 15081: loss: 0.080603, loss_s1: 0.081305, loss_fp: 0.009894, loss_freq: 0.028144
[17:13:54.004] iteration 15082: loss: 0.131334, loss_s1: 0.082037, loss_fp: 0.009059, loss_freq: 0.117460
[17:13:54.634] iteration 15083: loss: 0.043169, loss_s1: 0.031759, loss_fp: 0.002446, loss_freq: 0.019019
[17:13:55.263] iteration 15084: loss: 0.045892, loss_s1: 0.023746, loss_fp: 0.002135, loss_freq: 0.021165
[17:13:55.889] iteration 15085: loss: 0.046697, loss_s1: 0.026446, loss_fp: 0.001092, loss_freq: 0.020915
[17:13:56.512] iteration 15086: loss: 0.082823, loss_s1: 0.054500, loss_fp: 0.007479, loss_freq: 0.048390
[17:13:57.135] iteration 15087: loss: 0.037425, loss_s1: 0.013451, loss_fp: 0.000713, loss_freq: 0.017055
[17:13:57.753] iteration 15088: loss: 0.037203, loss_s1: 0.015173, loss_fp: 0.001605, loss_freq: 0.006990
[17:13:58.375] iteration 15089: loss: 0.065288, loss_s1: 0.045119, loss_fp: 0.004642, loss_freq: 0.039825
[17:13:58.991] iteration 15090: loss: 0.052885, loss_s1: 0.024692, loss_fp: 0.004125, loss_freq: 0.042915
[17:13:59.618] iteration 15091: loss: 0.049764, loss_s1: 0.047547, loss_fp: 0.010401, loss_freq: 0.013630
[17:14:00.242] iteration 15092: loss: 0.085828, loss_s1: 0.085230, loss_fp: 0.001342, loss_freq: 0.037960
[17:14:00.866] iteration 15093: loss: 0.078183, loss_s1: 0.076166, loss_fp: 0.001676, loss_freq: 0.045646
[17:14:01.489] iteration 15094: loss: 0.036107, loss_s1: 0.010746, loss_fp: 0.003599, loss_freq: 0.019774
[17:14:02.123] iteration 15095: loss: 0.066555, loss_s1: 0.048393, loss_fp: 0.000674, loss_freq: 0.009803
[17:14:02.776] iteration 15096: loss: 0.075245, loss_s1: 0.073792, loss_fp: 0.003944, loss_freq: 0.019120
[17:14:03.430] iteration 15097: loss: 0.056897, loss_s1: 0.038767, loss_fp: 0.002173, loss_freq: 0.038960
[17:14:04.088] iteration 15098: loss: 0.058926, loss_s1: 0.013739, loss_fp: 0.008747, loss_freq: 0.034105
[17:14:04.747] iteration 15099: loss: 0.073637, loss_s1: 0.057282, loss_fp: 0.008765, loss_freq: 0.028865
[17:14:05.403] iteration 15100: loss: 0.046560, loss_s1: 0.025710, loss_fp: 0.001111, loss_freq: 0.005234
[17:14:06.043] iteration 15101: loss: 0.127926, loss_s1: 0.143805, loss_fp: 0.007833, loss_freq: 0.027807
[17:14:06.690] iteration 15102: loss: 0.072732, loss_s1: 0.079784, loss_fp: 0.002222, loss_freq: 0.032726
[17:14:07.353] iteration 15103: loss: 0.054701, loss_s1: 0.063253, loss_fp: 0.003710, loss_freq: 0.007036
[17:14:08.017] iteration 15104: loss: 0.086469, loss_s1: 0.070097, loss_fp: 0.002877, loss_freq: 0.064177
[17:14:08.679] iteration 15105: loss: 0.065069, loss_s1: 0.073438, loss_fp: 0.003918, loss_freq: 0.012952
[17:14:09.341] iteration 15106: loss: 0.088323, loss_s1: 0.096626, loss_fp: 0.006028, loss_freq: 0.012964
[17:14:10.000] iteration 15107: loss: 0.049934, loss_s1: 0.038309, loss_fp: 0.002328, loss_freq: 0.022318
[17:14:10.657] iteration 15108: loss: 0.069763, loss_s1: 0.048719, loss_fp: 0.001188, loss_freq: 0.024966
[17:14:11.287] iteration 15109: loss: 0.058815, loss_s1: 0.050853, loss_fp: 0.004111, loss_freq: 0.028399
[17:14:11.917] iteration 15110: loss: 0.074232, loss_s1: 0.042133, loss_fp: 0.006012, loss_freq: 0.047233
[17:14:12.544] iteration 15111: loss: 0.055035, loss_s1: 0.032193, loss_fp: 0.005721, loss_freq: 0.021559
[17:14:13.168] iteration 15112: loss: 0.062495, loss_s1: 0.064433, loss_fp: 0.006843, loss_freq: 0.024885
[17:14:13.790] iteration 15113: loss: 0.081740, loss_s1: 0.042756, loss_fp: 0.004069, loss_freq: 0.060885
[17:14:14.414] iteration 15114: loss: 0.099447, loss_s1: 0.100510, loss_fp: 0.003077, loss_freq: 0.035840
[17:14:15.040] iteration 15115: loss: 0.053396, loss_s1: 0.031996, loss_fp: 0.007821, loss_freq: 0.028942
[17:14:15.663] iteration 15116: loss: 0.129683, loss_s1: 0.073899, loss_fp: 0.016786, loss_freq: 0.090145
[17:14:16.287] iteration 15117: loss: 0.070693, loss_s1: 0.055458, loss_fp: 0.011318, loss_freq: 0.022572
[17:14:16.904] iteration 15118: loss: 0.052200, loss_s1: 0.030181, loss_fp: 0.002055, loss_freq: 0.024882
[17:14:17.531] iteration 15119: loss: 0.088461, loss_s1: 0.065889, loss_fp: 0.000923, loss_freq: 0.031072
[17:14:18.155] iteration 15120: loss: 0.096065, loss_s1: 0.061208, loss_fp: 0.006130, loss_freq: 0.085423
[17:14:18.778] iteration 15121: loss: 0.052055, loss_s1: 0.013766, loss_fp: 0.002841, loss_freq: 0.007394
[17:14:19.398] iteration 15122: loss: 0.067091, loss_s1: 0.054220, loss_fp: 0.003585, loss_freq: 0.022839
[17:14:20.023] iteration 15123: loss: 0.075445, loss_s1: 0.039909, loss_fp: 0.002931, loss_freq: 0.051108
[17:14:20.646] iteration 15124: loss: 0.081615, loss_s1: 0.051080, loss_fp: 0.003494, loss_freq: 0.027768
[17:14:21.268] iteration 15125: loss: 0.088989, loss_s1: 0.051492, loss_fp: 0.006673, loss_freq: 0.071522
[17:14:21.888] iteration 15126: loss: 0.045914, loss_s1: 0.042509, loss_fp: 0.000926, loss_freq: 0.011443
[17:14:22.516] iteration 15127: loss: 0.072710, loss_s1: 0.069310, loss_fp: 0.002292, loss_freq: 0.015133
[17:14:23.145] iteration 15128: loss: 0.051259, loss_s1: 0.039981, loss_fp: 0.000241, loss_freq: 0.016824
[17:14:23.776] iteration 15129: loss: 0.048508, loss_s1: 0.026711, loss_fp: 0.005780, loss_freq: 0.013281
[17:14:24.407] iteration 15130: loss: 0.074182, loss_s1: 0.006435, loss_fp: 0.001965, loss_freq: 0.007141
[17:14:25.121] iteration 15131: loss: 0.110311, loss_s1: 0.096022, loss_fp: 0.002953, loss_freq: 0.085818
[17:14:25.743] iteration 15132: loss: 0.053069, loss_s1: 0.034254, loss_fp: 0.000960, loss_freq: 0.027237
[17:14:26.370] iteration 15133: loss: 0.064946, loss_s1: 0.054382, loss_fp: 0.002903, loss_freq: 0.015137
[17:14:26.989] iteration 15134: loss: 0.062090, loss_s1: 0.048581, loss_fp: 0.002899, loss_freq: 0.019305
[17:14:27.932] iteration 15135: loss: 0.068546, loss_s1: 0.050850, loss_fp: 0.000623, loss_freq: 0.041144
[17:14:28.563] iteration 15136: loss: 0.078746, loss_s1: 0.038062, loss_fp: 0.000812, loss_freq: 0.040431
[17:14:29.188] iteration 15137: loss: 0.049594, loss_s1: 0.027826, loss_fp: 0.000832, loss_freq: 0.022621
[17:14:29.813] iteration 15138: loss: 0.056250, loss_s1: 0.022649, loss_fp: 0.000239, loss_freq: 0.012016
[17:14:30.438] iteration 15139: loss: 0.067173, loss_s1: 0.029797, loss_fp: 0.001285, loss_freq: 0.020428
[17:14:31.061] iteration 15140: loss: 0.115893, loss_s1: 0.090189, loss_fp: 0.005233, loss_freq: 0.040553
[17:14:31.683] iteration 15141: loss: 0.039599, loss_s1: 0.033766, loss_fp: 0.001322, loss_freq: 0.007998
[17:14:32.305] iteration 15142: loss: 0.047029, loss_s1: 0.034106, loss_fp: 0.001782, loss_freq: 0.020100
[17:14:32.930] iteration 15143: loss: 0.067049, loss_s1: 0.070875, loss_fp: 0.000550, loss_freq: 0.027023
[17:14:33.550] iteration 15144: loss: 0.060206, loss_s1: 0.046703, loss_fp: 0.009151, loss_freq: 0.023544
[17:14:34.178] iteration 15145: loss: 0.053235, loss_s1: 0.046906, loss_fp: 0.004194, loss_freq: 0.008557
[17:14:34.799] iteration 15146: loss: 0.074440, loss_s1: 0.074940, loss_fp: 0.000540, loss_freq: 0.029357
[17:14:35.423] iteration 15147: loss: 0.062345, loss_s1: 0.027763, loss_fp: 0.004127, loss_freq: 0.059091
[17:14:36.047] iteration 15148: loss: 0.081394, loss_s1: 0.029921, loss_fp: 0.000751, loss_freq: 0.043844
[17:14:36.670] iteration 15149: loss: 0.060082, loss_s1: 0.049402, loss_fp: 0.002579, loss_freq: 0.026869
[17:14:37.295] iteration 15150: loss: 0.123265, loss_s1: 0.141780, loss_fp: 0.003618, loss_freq: 0.062395
[17:14:37.920] iteration 15151: loss: 0.054047, loss_s1: 0.038560, loss_fp: 0.002955, loss_freq: 0.011096
[17:14:38.542] iteration 15152: loss: 0.056281, loss_s1: 0.034548, loss_fp: 0.004565, loss_freq: 0.030374
[17:14:39.163] iteration 15153: loss: 0.052064, loss_s1: 0.018624, loss_fp: 0.001478, loss_freq: 0.017818
[17:14:39.791] iteration 15154: loss: 0.079474, loss_s1: 0.070450, loss_fp: 0.001556, loss_freq: 0.032073
[17:14:40.417] iteration 15155: loss: 0.067406, loss_s1: 0.061398, loss_fp: 0.001214, loss_freq: 0.015437
[17:14:41.044] iteration 15156: loss: 0.059404, loss_s1: 0.034679, loss_fp: 0.002345, loss_freq: 0.025618
[17:14:41.670] iteration 15157: loss: 0.074139, loss_s1: 0.063587, loss_fp: 0.001115, loss_freq: 0.022565
[17:14:42.297] iteration 15158: loss: 0.101435, loss_s1: 0.077345, loss_fp: 0.001808, loss_freq: 0.073060
[17:14:42.925] iteration 15159: loss: 0.090676, loss_s1: 0.131552, loss_fp: 0.003839, loss_freq: 0.015023
[17:14:43.553] iteration 15160: loss: 0.090411, loss_s1: 0.066579, loss_fp: 0.001457, loss_freq: 0.049909
[17:14:44.176] iteration 15161: loss: 0.039658, loss_s1: 0.032171, loss_fp: 0.000221, loss_freq: 0.005341
[17:14:44.802] iteration 15162: loss: 0.078187, loss_s1: 0.063470, loss_fp: 0.010416, loss_freq: 0.040207
[17:14:45.429] iteration 15163: loss: 0.070888, loss_s1: 0.062916, loss_fp: 0.006016, loss_freq: 0.031515
[17:14:46.053] iteration 15164: loss: 0.044836, loss_s1: 0.020500, loss_fp: 0.000539, loss_freq: 0.017759
[17:14:46.679] iteration 15165: loss: 0.042820, loss_s1: 0.040105, loss_fp: 0.001901, loss_freq: 0.009792
[17:14:47.305] iteration 15166: loss: 0.060768, loss_s1: 0.043962, loss_fp: 0.003749, loss_freq: 0.019882
[17:14:47.930] iteration 15167: loss: 0.050067, loss_s1: 0.037444, loss_fp: 0.001441, loss_freq: 0.019934
[17:14:48.553] iteration 15168: loss: 0.047842, loss_s1: 0.038657, loss_fp: 0.000762, loss_freq: 0.007935
[17:14:49.241] iteration 15169: loss: 0.060284, loss_s1: 0.021191, loss_fp: 0.008396, loss_freq: 0.028483
[17:14:49.875] iteration 15170: loss: 0.078388, loss_s1: 0.053523, loss_fp: 0.006708, loss_freq: 0.053175
[17:14:50.502] iteration 15171: loss: 0.082641, loss_s1: 0.047956, loss_fp: 0.002424, loss_freq: 0.042969
[17:14:51.129] iteration 15172: loss: 0.095937, loss_s1: 0.078946, loss_fp: 0.004659, loss_freq: 0.073575
[17:14:51.757] iteration 15173: loss: 0.094433, loss_s1: 0.066572, loss_fp: 0.000698, loss_freq: 0.055301
[17:14:52.384] iteration 15174: loss: 0.077127, loss_s1: 0.035244, loss_fp: 0.001264, loss_freq: 0.067904
[17:14:53.012] iteration 15175: loss: 0.075264, loss_s1: 0.066626, loss_fp: 0.004039, loss_freq: 0.023225
[17:14:53.648] iteration 15176: loss: 0.091563, loss_s1: 0.082326, loss_fp: 0.004455, loss_freq: 0.052362
[17:14:54.275] iteration 15177: loss: 0.057103, loss_s1: 0.066324, loss_fp: 0.001052, loss_freq: 0.011880
[17:14:54.903] iteration 15178: loss: 0.058894, loss_s1: 0.038083, loss_fp: 0.001126, loss_freq: 0.037262
[17:14:55.531] iteration 15179: loss: 0.075143, loss_s1: 0.031181, loss_fp: 0.005129, loss_freq: 0.070787
[17:14:56.156] iteration 15180: loss: 0.038607, loss_s1: 0.023234, loss_fp: 0.000280, loss_freq: 0.012013
[17:14:56.782] iteration 15181: loss: 0.043592, loss_s1: 0.026241, loss_fp: 0.001609, loss_freq: 0.012438
[17:14:57.410] iteration 15182: loss: 0.042730, loss_s1: 0.034481, loss_fp: 0.002833, loss_freq: 0.014349
[17:14:58.039] iteration 15183: loss: 0.086652, loss_s1: 0.099883, loss_fp: 0.001710, loss_freq: 0.019338
[17:14:58.672] iteration 15184: loss: 0.063238, loss_s1: 0.037341, loss_fp: 0.004133, loss_freq: 0.040675
[17:14:59.300] iteration 15185: loss: 0.057262, loss_s1: 0.041775, loss_fp: 0.006037, loss_freq: 0.020053
[17:14:59.926] iteration 15186: loss: 0.044051, loss_s1: 0.030017, loss_fp: 0.001895, loss_freq: 0.007487
[17:15:00.561] iteration 15187: loss: 0.066046, loss_s1: 0.053217, loss_fp: 0.002718, loss_freq: 0.036130
[17:15:01.188] iteration 15188: loss: 0.060198, loss_s1: 0.034822, loss_fp: 0.001443, loss_freq: 0.044872
[17:15:01.814] iteration 15189: loss: 0.051274, loss_s1: 0.046820, loss_fp: 0.000942, loss_freq: 0.006585
[17:15:02.439] iteration 15190: loss: 0.060551, loss_s1: 0.044107, loss_fp: 0.003133, loss_freq: 0.017256
[17:15:03.067] iteration 15191: loss: 0.056862, loss_s1: 0.046918, loss_fp: 0.004620, loss_freq: 0.013318
[17:15:03.696] iteration 15192: loss: 0.052176, loss_s1: 0.018399, loss_fp: 0.000746, loss_freq: 0.032587
[17:15:04.329] iteration 15193: loss: 0.047769, loss_s1: 0.047918, loss_fp: 0.001258, loss_freq: 0.007679
[17:15:04.960] iteration 15194: loss: 0.045054, loss_s1: 0.018078, loss_fp: 0.002958, loss_freq: 0.028517
[17:15:05.586] iteration 15195: loss: 0.039869, loss_s1: 0.023947, loss_fp: 0.005997, loss_freq: 0.015094
[17:15:06.207] iteration 15196: loss: 0.048113, loss_s1: 0.041825, loss_fp: 0.003730, loss_freq: 0.010687
[17:15:06.831] iteration 15197: loss: 0.044686, loss_s1: 0.020738, loss_fp: 0.002754, loss_freq: 0.020304
[17:15:07.457] iteration 15198: loss: 0.047655, loss_s1: 0.029440, loss_fp: 0.002239, loss_freq: 0.020610
[17:15:08.083] iteration 15199: loss: 0.053551, loss_s1: 0.032520, loss_fp: 0.010085, loss_freq: 0.028742
[17:15:08.707] iteration 15200: loss: 0.081592, loss_s1: 0.042982, loss_fp: 0.015799, loss_freq: 0.068824
[17:15:11.918] iteration 15200 : mean_dice : 0.737964
[17:15:12.567] iteration 15201: loss: 0.061397, loss_s1: 0.029867, loss_fp: 0.002102, loss_freq: 0.041008
[17:15:13.192] iteration 15202: loss: 0.044310, loss_s1: 0.036519, loss_fp: 0.011145, loss_freq: 0.008095
[17:15:13.820] iteration 15203: loss: 0.044532, loss_s1: 0.030139, loss_fp: 0.002605, loss_freq: 0.018851
[17:15:14.448] iteration 15204: loss: 0.066724, loss_s1: 0.029424, loss_fp: 0.005079, loss_freq: 0.030627
[17:15:15.076] iteration 15205: loss: 0.077930, loss_s1: 0.053548, loss_fp: 0.004168, loss_freq: 0.054170
[17:15:15.701] iteration 15206: loss: 0.050891, loss_s1: 0.031632, loss_fp: 0.000711, loss_freq: 0.026643
[17:15:16.333] iteration 15207: loss: 0.036623, loss_s1: 0.016437, loss_fp: 0.003287, loss_freq: 0.012744
[17:15:16.962] iteration 15208: loss: 0.032680, loss_s1: 0.010409, loss_fp: 0.001760, loss_freq: 0.009565
[17:15:17.591] iteration 15209: loss: 0.062369, loss_s1: 0.050952, loss_fp: 0.005129, loss_freq: 0.023177
[17:15:18.217] iteration 15210: loss: 0.072758, loss_s1: 0.028499, loss_fp: 0.008861, loss_freq: 0.046531
[17:15:18.842] iteration 15211: loss: 0.073956, loss_s1: 0.064949, loss_fp: 0.003291, loss_freq: 0.021791
[17:15:19.478] iteration 15212: loss: 0.084104, loss_s1: 0.079857, loss_fp: 0.006194, loss_freq: 0.031718
[17:15:20.107] iteration 15213: loss: 0.042264, loss_s1: 0.032208, loss_fp: 0.003618, loss_freq: 0.006566
[17:15:20.789] iteration 15214: loss: 0.049207, loss_s1: 0.035054, loss_fp: 0.002764, loss_freq: 0.017905
[17:15:21.451] iteration 15215: loss: 0.045980, loss_s1: 0.031689, loss_fp: 0.002864, loss_freq: 0.018813
[17:15:22.085] iteration 15216: loss: 0.046618, loss_s1: 0.035407, loss_fp: 0.004205, loss_freq: 0.019657
[17:15:22.709] iteration 15217: loss: 0.123109, loss_s1: 0.130663, loss_fp: 0.006017, loss_freq: 0.062331
[17:15:23.336] iteration 15218: loss: 0.045104, loss_s1: 0.017516, loss_fp: 0.012849, loss_freq: 0.018838
[17:15:23.963] iteration 15219: loss: 0.105789, loss_s1: 0.104432, loss_fp: 0.004530, loss_freq: 0.066396
[17:15:24.591] iteration 15220: loss: 0.047451, loss_s1: 0.039859, loss_fp: 0.001236, loss_freq: 0.016776
[17:15:25.223] iteration 15221: loss: 0.092294, loss_s1: 0.107013, loss_fp: 0.002771, loss_freq: 0.032043
[17:15:25.867] iteration 15222: loss: 0.068816, loss_s1: 0.064837, loss_fp: 0.003546, loss_freq: 0.010756
[17:15:26.511] iteration 15223: loss: 0.081925, loss_s1: 0.071199, loss_fp: 0.019819, loss_freq: 0.036477
[17:15:27.157] iteration 15224: loss: 0.051322, loss_s1: 0.036612, loss_fp: 0.001072, loss_freq: 0.027048
[17:15:27.800] iteration 15225: loss: 0.069199, loss_s1: 0.054701, loss_fp: 0.002918, loss_freq: 0.040283
[17:15:28.438] iteration 15226: loss: 0.065161, loss_s1: 0.062814, loss_fp: 0.006694, loss_freq: 0.023346
[17:15:29.080] iteration 15227: loss: 0.090355, loss_s1: 0.034761, loss_fp: 0.002738, loss_freq: 0.021085
[17:15:29.723] iteration 15228: loss: 0.051256, loss_s1: 0.040182, loss_fp: 0.001700, loss_freq: 0.018864
[17:15:30.373] iteration 15229: loss: 0.078148, loss_s1: 0.096369, loss_fp: 0.001376, loss_freq: 0.029220
[17:15:31.016] iteration 15230: loss: 0.070195, loss_s1: 0.066121, loss_fp: 0.005973, loss_freq: 0.026471
[17:15:31.663] iteration 15231: loss: 0.046303, loss_s1: 0.034689, loss_fp: 0.001346, loss_freq: 0.013607
[17:15:32.307] iteration 15232: loss: 0.058633, loss_s1: 0.039672, loss_fp: 0.000468, loss_freq: 0.036041
[17:15:32.955] iteration 15233: loss: 0.036107, loss_s1: 0.020330, loss_fp: 0.000308, loss_freq: 0.016606
[17:15:33.578] iteration 15234: loss: 0.061351, loss_s1: 0.075103, loss_fp: 0.002248, loss_freq: 0.007666
[17:15:34.207] iteration 15235: loss: 0.053294, loss_s1: 0.055734, loss_fp: 0.001013, loss_freq: 0.017915
[17:15:34.830] iteration 15236: loss: 0.066271, loss_s1: 0.032815, loss_fp: 0.004605, loss_freq: 0.045301
[17:15:35.455] iteration 15237: loss: 0.081791, loss_s1: 0.052971, loss_fp: 0.002206, loss_freq: 0.074891
[17:15:36.083] iteration 15238: loss: 0.061449, loss_s1: 0.059115, loss_fp: 0.003660, loss_freq: 0.009072
[17:15:36.710] iteration 15239: loss: 0.073085, loss_s1: 0.051755, loss_fp: 0.002790, loss_freq: 0.020608
[17:15:37.336] iteration 15240: loss: 0.051497, loss_s1: 0.025020, loss_fp: 0.002521, loss_freq: 0.033383
[17:15:37.964] iteration 15241: loss: 0.030114, loss_s1: 0.020000, loss_fp: 0.000563, loss_freq: 0.006096
[17:15:38.588] iteration 15242: loss: 0.110143, loss_s1: 0.078967, loss_fp: 0.000738, loss_freq: 0.067194
[17:15:39.214] iteration 15243: loss: 0.085333, loss_s1: 0.057548, loss_fp: 0.007188, loss_freq: 0.061537
[17:15:39.836] iteration 15244: loss: 0.089266, loss_s1: 0.091489, loss_fp: 0.004085, loss_freq: 0.036932
[17:15:40.458] iteration 15245: loss: 0.044671, loss_s1: 0.017052, loss_fp: 0.000807, loss_freq: 0.023084
[17:15:41.084] iteration 15246: loss: 0.065557, loss_s1: 0.029310, loss_fp: 0.001966, loss_freq: 0.063708
[17:15:41.712] iteration 15247: loss: 0.079592, loss_s1: 0.084025, loss_fp: 0.028512, loss_freq: 0.014797
[17:15:42.339] iteration 15248: loss: 0.040656, loss_s1: 0.030337, loss_fp: 0.002064, loss_freq: 0.022786
[17:15:42.973] iteration 15249: loss: 0.028591, loss_s1: 0.006250, loss_fp: 0.000250, loss_freq: 0.008456
[17:15:43.599] iteration 15250: loss: 0.067087, loss_s1: 0.071346, loss_fp: 0.004200, loss_freq: 0.024857
[17:15:44.228] iteration 15251: loss: 0.048406, loss_s1: 0.035685, loss_fp: 0.002311, loss_freq: 0.024703
[17:15:44.853] iteration 15252: loss: 0.035899, loss_s1: 0.030880, loss_fp: 0.001645, loss_freq: 0.008874
[17:15:45.479] iteration 15253: loss: 0.048600, loss_s1: 0.033552, loss_fp: 0.005963, loss_freq: 0.015905
[17:15:46.108] iteration 15254: loss: 0.119042, loss_s1: 0.051487, loss_fp: 0.000955, loss_freq: 0.151203
[17:15:46.743] iteration 15255: loss: 0.051044, loss_s1: 0.037398, loss_fp: 0.003732, loss_freq: 0.025687
[17:15:47.367] iteration 15256: loss: 0.075890, loss_s1: 0.035467, loss_fp: 0.004058, loss_freq: 0.062783
[17:15:47.996] iteration 15257: loss: 0.076430, loss_s1: 0.066496, loss_fp: 0.009674, loss_freq: 0.027089
[17:15:48.619] iteration 15258: loss: 0.052725, loss_s1: 0.043899, loss_fp: 0.002688, loss_freq: 0.004944
[17:15:49.244] iteration 15259: loss: 0.079100, loss_s1: 0.049057, loss_fp: 0.010409, loss_freq: 0.037820
[17:15:49.863] iteration 15260: loss: 0.056465, loss_s1: 0.033152, loss_fp: 0.001590, loss_freq: 0.027633
[17:15:50.489] iteration 15261: loss: 0.052154, loss_s1: 0.043917, loss_fp: 0.002770, loss_freq: 0.011253
[17:15:51.115] iteration 15262: loss: 0.173966, loss_s1: 0.140330, loss_fp: 0.001951, loss_freq: 0.102646
[17:15:51.739] iteration 15263: loss: 0.056420, loss_s1: 0.062344, loss_fp: 0.003316, loss_freq: 0.013452
[17:15:52.365] iteration 15264: loss: 0.096494, loss_s1: 0.125790, loss_fp: 0.003212, loss_freq: 0.012533
[17:15:52.988] iteration 15265: loss: 0.075095, loss_s1: 0.045569, loss_fp: 0.005059, loss_freq: 0.065607
[17:15:53.613] iteration 15266: loss: 0.062353, loss_s1: 0.059587, loss_fp: 0.001110, loss_freq: 0.009955
[17:15:54.240] iteration 15267: loss: 0.072878, loss_s1: 0.053293, loss_fp: 0.002626, loss_freq: 0.036811
[17:15:54.861] iteration 15268: loss: 0.050986, loss_s1: 0.028701, loss_fp: 0.002479, loss_freq: 0.016147
[17:15:55.488] iteration 15269: loss: 0.093742, loss_s1: 0.087305, loss_fp: 0.001389, loss_freq: 0.052447
[17:15:56.112] iteration 15270: loss: 0.056096, loss_s1: 0.040729, loss_fp: 0.002698, loss_freq: 0.032997
[17:15:56.743] iteration 15271: loss: 0.059853, loss_s1: 0.026542, loss_fp: 0.001267, loss_freq: 0.035161
[17:15:57.367] iteration 15272: loss: 0.058474, loss_s1: 0.038939, loss_fp: 0.001528, loss_freq: 0.043375
[17:15:57.991] iteration 15273: loss: 0.052177, loss_s1: 0.046585, loss_fp: 0.000818, loss_freq: 0.019342
[17:15:58.611] iteration 15274: loss: 0.060229, loss_s1: 0.040322, loss_fp: 0.005746, loss_freq: 0.020002
[17:15:59.234] iteration 15275: loss: 0.081113, loss_s1: 0.078527, loss_fp: 0.005482, loss_freq: 0.026207
[17:15:59.857] iteration 15276: loss: 0.062122, loss_s1: 0.039921, loss_fp: 0.008088, loss_freq: 0.027432
[17:16:00.481] iteration 15277: loss: 0.097929, loss_s1: 0.081050, loss_fp: 0.010915, loss_freq: 0.059847
[17:16:01.110] iteration 15278: loss: 0.061560, loss_s1: 0.029958, loss_fp: 0.002811, loss_freq: 0.034590
[17:16:01.730] iteration 15279: loss: 0.032576, loss_s1: 0.011834, loss_fp: 0.008272, loss_freq: 0.008333
[17:16:02.358] iteration 15280: loss: 0.065401, loss_s1: 0.055600, loss_fp: 0.013648, loss_freq: 0.013885
[17:16:02.984] iteration 15281: loss: 0.091170, loss_s1: 0.057270, loss_fp: 0.003412, loss_freq: 0.084745
[17:16:03.609] iteration 15282: loss: 0.045827, loss_s1: 0.035037, loss_fp: 0.001403, loss_freq: 0.023969
[17:16:04.234] iteration 15283: loss: 0.066054, loss_s1: 0.048046, loss_fp: 0.004998, loss_freq: 0.015091
[17:16:04.859] iteration 15284: loss: 0.101140, loss_s1: 0.065124, loss_fp: 0.001477, loss_freq: 0.050037
[17:16:05.485] iteration 15285: loss: 0.070979, loss_s1: 0.035467, loss_fp: 0.003060, loss_freq: 0.055488
[17:16:06.109] iteration 15286: loss: 0.077805, loss_s1: 0.054943, loss_fp: 0.006545, loss_freq: 0.044799
[17:16:06.733] iteration 15287: loss: 0.028710, loss_s1: 0.016627, loss_fp: 0.001584, loss_freq: 0.008778
[17:16:07.361] iteration 15288: loss: 0.076938, loss_s1: 0.064476, loss_fp: 0.004150, loss_freq: 0.040265
[17:16:07.987] iteration 15289: loss: 0.045460, loss_s1: 0.017931, loss_fp: 0.004585, loss_freq: 0.008334
[17:16:08.610] iteration 15290: loss: 0.059148, loss_s1: 0.057796, loss_fp: 0.002809, loss_freq: 0.014396
[17:16:09.235] iteration 15291: loss: 0.056270, loss_s1: 0.048297, loss_fp: 0.001946, loss_freq: 0.011426
[17:16:09.860] iteration 15292: loss: 0.060818, loss_s1: 0.029757, loss_fp: 0.001019, loss_freq: 0.035128
[17:16:10.487] iteration 15293: loss: 0.061096, loss_s1: 0.055881, loss_fp: 0.001982, loss_freq: 0.013723
[17:16:11.107] iteration 15294: loss: 0.066480, loss_s1: 0.014884, loss_fp: 0.000600, loss_freq: 0.020546
[17:16:11.730] iteration 15295: loss: 0.053424, loss_s1: 0.041007, loss_fp: 0.010850, loss_freq: 0.008593
[17:16:12.689] iteration 15296: loss: 0.051642, loss_s1: 0.027391, loss_fp: 0.000914, loss_freq: 0.037474
[17:16:13.334] iteration 15297: loss: 0.058231, loss_s1: 0.040051, loss_fp: 0.002333, loss_freq: 0.033904
[17:16:13.978] iteration 15298: loss: 0.048156, loss_s1: 0.024134, loss_fp: 0.003325, loss_freq: 0.010695
[17:16:14.607] iteration 15299: loss: 0.044799, loss_s1: 0.018274, loss_fp: 0.001661, loss_freq: 0.015623
[17:16:15.230] iteration 15300: loss: 0.094925, loss_s1: 0.119114, loss_fp: 0.001493, loss_freq: 0.027953
[17:16:15.854] iteration 15301: loss: 0.116781, loss_s1: 0.071318, loss_fp: 0.012078, loss_freq: 0.049091
[17:16:16.490] iteration 15302: loss: 0.052430, loss_s1: 0.034592, loss_fp: 0.002366, loss_freq: 0.012614
[17:16:17.137] iteration 15303: loss: 0.070530, loss_s1: 0.084818, loss_fp: 0.004974, loss_freq: 0.011365
[17:16:17.759] iteration 15304: loss: 0.086081, loss_s1: 0.077972, loss_fp: 0.013067, loss_freq: 0.029977
[17:16:18.414] iteration 15305: loss: 0.082679, loss_s1: 0.082641, loss_fp: 0.003266, loss_freq: 0.036434
[17:16:19.044] iteration 15306: loss: 0.039497, loss_s1: 0.010729, loss_fp: 0.000656, loss_freq: 0.012156
[17:16:19.667] iteration 15307: loss: 0.075519, loss_s1: 0.077827, loss_fp: 0.000611, loss_freq: 0.023687
[17:16:20.295] iteration 15308: loss: 0.075079, loss_s1: 0.051056, loss_fp: 0.003603, loss_freq: 0.060664
[17:16:20.922] iteration 15309: loss: 0.060145, loss_s1: 0.035595, loss_fp: 0.001064, loss_freq: 0.027314
[17:16:21.548] iteration 15310: loss: 0.053880, loss_s1: 0.042744, loss_fp: 0.000758, loss_freq: 0.025008
[17:16:22.257] iteration 15311: loss: 0.097875, loss_s1: 0.063961, loss_fp: 0.005535, loss_freq: 0.083738
[17:16:22.915] iteration 15312: loss: 0.061200, loss_s1: 0.046475, loss_fp: 0.003262, loss_freq: 0.023287
[17:16:23.573] iteration 15313: loss: 0.047299, loss_s1: 0.017821, loss_fp: 0.000734, loss_freq: 0.021809
[17:16:24.227] iteration 15314: loss: 0.045417, loss_s1: 0.035940, loss_fp: 0.000534, loss_freq: 0.017045
[17:16:24.857] iteration 15315: loss: 0.085603, loss_s1: 0.048337, loss_fp: 0.004263, loss_freq: 0.032649
[17:16:25.482] iteration 15316: loss: 0.069476, loss_s1: 0.068701, loss_fp: 0.000389, loss_freq: 0.015426
[17:16:26.174] iteration 15317: loss: 0.045917, loss_s1: 0.020050, loss_fp: 0.001234, loss_freq: 0.010463
[17:16:26.839] iteration 15318: loss: 0.061542, loss_s1: 0.019993, loss_fp: 0.001252, loss_freq: 0.044409
[17:16:27.503] iteration 15319: loss: 0.169803, loss_s1: 0.122518, loss_fp: 0.001156, loss_freq: 0.165905
[17:16:28.159] iteration 15320: loss: 0.040764, loss_s1: 0.023809, loss_fp: 0.002385, loss_freq: 0.017064
[17:16:28.792] iteration 15321: loss: 0.079769, loss_s1: 0.061972, loss_fp: 0.003993, loss_freq: 0.056065
[17:16:29.437] iteration 15322: loss: 0.051462, loss_s1: 0.068459, loss_fp: 0.000195, loss_freq: 0.003446
[17:16:30.058] iteration 15323: loss: 0.075729, loss_s1: 0.064549, loss_fp: 0.006983, loss_freq: 0.018677
[17:16:30.681] iteration 15324: loss: 0.092831, loss_s1: 0.070533, loss_fp: 0.001404, loss_freq: 0.044275
[17:16:31.303] iteration 15325: loss: 0.049416, loss_s1: 0.041467, loss_fp: 0.001340, loss_freq: 0.008815
[17:16:31.926] iteration 15326: loss: 0.073558, loss_s1: 0.098271, loss_fp: 0.002001, loss_freq: 0.016959
[17:16:32.543] iteration 15327: loss: 0.044979, loss_s1: 0.033367, loss_fp: 0.002363, loss_freq: 0.011712
[17:16:33.168] iteration 15328: loss: 0.047002, loss_s1: 0.028505, loss_fp: 0.001816, loss_freq: 0.019785
[17:16:33.791] iteration 15329: loss: 0.040424, loss_s1: 0.023014, loss_fp: 0.003147, loss_freq: 0.008921
[17:16:34.411] iteration 15330: loss: 0.068201, loss_s1: 0.039108, loss_fp: 0.003923, loss_freq: 0.011812
[17:16:35.034] iteration 15331: loss: 0.073847, loss_s1: 0.087065, loss_fp: 0.006154, loss_freq: 0.015038
[17:16:35.658] iteration 15332: loss: 0.092702, loss_s1: 0.061218, loss_fp: 0.003401, loss_freq: 0.037747
[17:16:36.282] iteration 15333: loss: 0.069276, loss_s1: 0.064317, loss_fp: 0.001055, loss_freq: 0.023128
[17:16:36.904] iteration 15334: loss: 0.084175, loss_s1: 0.089634, loss_fp: 0.001627, loss_freq: 0.032164
[17:16:37.528] iteration 15335: loss: 0.066071, loss_s1: 0.042271, loss_fp: 0.007269, loss_freq: 0.041517
[17:16:38.151] iteration 15336: loss: 0.071435, loss_s1: 0.033996, loss_fp: 0.000929, loss_freq: 0.019962
[17:16:38.776] iteration 15337: loss: 0.104889, loss_s1: 0.121002, loss_fp: 0.003770, loss_freq: 0.049162
[17:16:39.404] iteration 15338: loss: 0.069877, loss_s1: 0.033437, loss_fp: 0.005285, loss_freq: 0.063718
[17:16:40.029] iteration 15339: loss: 0.050397, loss_s1: 0.025394, loss_fp: 0.006869, loss_freq: 0.031238
[17:16:40.655] iteration 15340: loss: 0.058518, loss_s1: 0.055345, loss_fp: 0.002022, loss_freq: 0.019393
[17:16:41.295] iteration 15341: loss: 0.071686, loss_s1: 0.064914, loss_fp: 0.000385, loss_freq: 0.003263
[17:16:41.915] iteration 15342: loss: 0.037533, loss_s1: 0.024044, loss_fp: 0.000838, loss_freq: 0.009934
[17:16:42.538] iteration 15343: loss: 0.056348, loss_s1: 0.053956, loss_fp: 0.000976, loss_freq: 0.018757
[17:16:43.163] iteration 15344: loss: 0.070520, loss_s1: 0.060812, loss_fp: 0.002079, loss_freq: 0.023546
[17:16:43.785] iteration 15345: loss: 0.058344, loss_s1: 0.054113, loss_fp: 0.000938, loss_freq: 0.025557
[17:16:44.410] iteration 15346: loss: 0.062043, loss_s1: 0.036894, loss_fp: 0.010153, loss_freq: 0.044154
[17:16:45.034] iteration 15347: loss: 0.043978, loss_s1: 0.020287, loss_fp: 0.003903, loss_freq: 0.014605
[17:16:45.659] iteration 15348: loss: 0.047619, loss_s1: 0.023222, loss_fp: 0.006269, loss_freq: 0.034002
[17:16:46.284] iteration 15349: loss: 0.065596, loss_s1: 0.045859, loss_fp: 0.005172, loss_freq: 0.040469
[17:16:46.907] iteration 15350: loss: 0.043932, loss_s1: 0.026629, loss_fp: 0.002390, loss_freq: 0.009219
[17:16:47.534] iteration 15351: loss: 0.063548, loss_s1: 0.045661, loss_fp: 0.001476, loss_freq: 0.036603
[17:16:48.158] iteration 15352: loss: 0.040294, loss_s1: 0.023901, loss_fp: 0.005100, loss_freq: 0.013233
[17:16:48.784] iteration 15353: loss: 0.067430, loss_s1: 0.044572, loss_fp: 0.008361, loss_freq: 0.021852
[17:16:49.412] iteration 15354: loss: 0.054239, loss_s1: 0.047984, loss_fp: 0.002481, loss_freq: 0.007318
[17:16:50.035] iteration 15355: loss: 0.037338, loss_s1: 0.025479, loss_fp: 0.001656, loss_freq: 0.016084
[17:16:50.672] iteration 15356: loss: 0.043246, loss_s1: 0.012843, loss_fp: 0.003956, loss_freq: 0.013128
[17:16:51.297] iteration 15357: loss: 0.043148, loss_s1: 0.025760, loss_fp: 0.004865, loss_freq: 0.011593
[17:16:51.917] iteration 15358: loss: 0.051781, loss_s1: 0.033509, loss_fp: 0.001413, loss_freq: 0.020086
[17:16:52.541] iteration 15359: loss: 0.074313, loss_s1: 0.063716, loss_fp: 0.010275, loss_freq: 0.018081
[17:16:53.165] iteration 15360: loss: 0.053045, loss_s1: 0.036129, loss_fp: 0.001101, loss_freq: 0.023565
[17:16:53.787] iteration 15361: loss: 0.066504, loss_s1: 0.041207, loss_fp: 0.002831, loss_freq: 0.035158
[17:16:54.409] iteration 15362: loss: 0.072532, loss_s1: 0.026407, loss_fp: 0.003015, loss_freq: 0.034339
[17:16:55.030] iteration 15363: loss: 0.072575, loss_s1: 0.078749, loss_fp: 0.006600, loss_freq: 0.031173
[17:16:55.650] iteration 15364: loss: 0.047789, loss_s1: 0.040547, loss_fp: 0.001093, loss_freq: 0.010852
[17:16:56.273] iteration 15365: loss: 0.080946, loss_s1: 0.045583, loss_fp: 0.002565, loss_freq: 0.046268
[17:16:56.894] iteration 15366: loss: 0.081543, loss_s1: 0.057047, loss_fp: 0.009744, loss_freq: 0.051689
[17:16:57.518] iteration 15367: loss: 0.056685, loss_s1: 0.037000, loss_fp: 0.001477, loss_freq: 0.013603
[17:16:58.142] iteration 15368: loss: 0.052411, loss_s1: 0.038615, loss_fp: 0.001355, loss_freq: 0.020519
[17:16:58.766] iteration 15369: loss: 0.059366, loss_s1: 0.049341, loss_fp: 0.002670, loss_freq: 0.010658
[17:16:59.390] iteration 15370: loss: 0.054129, loss_s1: 0.045158, loss_fp: 0.002764, loss_freq: 0.020401
[17:17:00.021] iteration 15371: loss: 0.085421, loss_s1: 0.073881, loss_fp: 0.000551, loss_freq: 0.012886
[17:17:00.644] iteration 15372: loss: 0.056229, loss_s1: 0.019211, loss_fp: 0.002863, loss_freq: 0.045983
[17:17:01.271] iteration 15373: loss: 0.038554, loss_s1: 0.019727, loss_fp: 0.003259, loss_freq: 0.021935
[17:17:01.896] iteration 15374: loss: 0.030554, loss_s1: 0.022768, loss_fp: 0.001080, loss_freq: 0.004020
[17:17:02.523] iteration 15375: loss: 0.045694, loss_s1: 0.033467, loss_fp: 0.000676, loss_freq: 0.011849
[17:17:03.151] iteration 15376: loss: 0.064298, loss_s1: 0.059792, loss_fp: 0.007310, loss_freq: 0.019637
[17:17:03.776] iteration 15377: loss: 0.065482, loss_s1: 0.037536, loss_fp: 0.001476, loss_freq: 0.060230
[17:17:04.403] iteration 15378: loss: 0.136974, loss_s1: 0.065499, loss_fp: 0.024839, loss_freq: 0.145284
[17:17:05.032] iteration 15379: loss: 0.070857, loss_s1: 0.031179, loss_fp: 0.003132, loss_freq: 0.044540
[17:17:05.661] iteration 15380: loss: 0.075873, loss_s1: 0.048783, loss_fp: 0.004371, loss_freq: 0.055539
[17:17:06.284] iteration 15381: loss: 0.059488, loss_s1: 0.045211, loss_fp: 0.002291, loss_freq: 0.035321
[17:17:06.909] iteration 15382: loss: 0.059080, loss_s1: 0.034882, loss_fp: 0.002360, loss_freq: 0.028588
[17:17:07.537] iteration 15383: loss: 0.046623, loss_s1: 0.039863, loss_fp: 0.002275, loss_freq: 0.010515
[17:17:08.157] iteration 15384: loss: 0.051288, loss_s1: 0.035353, loss_fp: 0.000988, loss_freq: 0.030358
[17:17:08.784] iteration 15385: loss: 0.078790, loss_s1: 0.065006, loss_fp: 0.000565, loss_freq: 0.040198
[17:17:09.414] iteration 15386: loss: 0.070641, loss_s1: 0.055173, loss_fp: 0.001718, loss_freq: 0.033151
[17:17:10.041] iteration 15387: loss: 0.054245, loss_s1: 0.035926, loss_fp: 0.005400, loss_freq: 0.017135
[17:17:10.698] iteration 15388: loss: 0.045654, loss_s1: 0.021960, loss_fp: 0.001204, loss_freq: 0.014828
[17:17:11.351] iteration 15389: loss: 0.056059, loss_s1: 0.029194, loss_fp: 0.009367, loss_freq: 0.018801
[17:17:11.976] iteration 15390: loss: 0.054248, loss_s1: 0.037319, loss_fp: 0.002137, loss_freq: 0.040808
[17:17:12.601] iteration 15391: loss: 0.046456, loss_s1: 0.022995, loss_fp: 0.001691, loss_freq: 0.030411
[17:17:13.227] iteration 15392: loss: 0.058442, loss_s1: 0.043444, loss_fp: 0.003578, loss_freq: 0.018989
[17:17:13.853] iteration 15393: loss: 0.080373, loss_s1: 0.065259, loss_fp: 0.003226, loss_freq: 0.041410
[17:17:14.478] iteration 15394: loss: 0.067011, loss_s1: 0.044458, loss_fp: 0.001812, loss_freq: 0.030325
[17:17:15.104] iteration 15395: loss: 0.037684, loss_s1: 0.024102, loss_fp: 0.001242, loss_freq: 0.012574
[17:17:15.731] iteration 15396: loss: 0.058271, loss_s1: 0.054049, loss_fp: 0.002489, loss_freq: 0.025806
[17:17:16.363] iteration 15397: loss: 0.074248, loss_s1: 0.022506, loss_fp: 0.001002, loss_freq: 0.050669
[17:17:16.987] iteration 15398: loss: 0.067422, loss_s1: 0.036496, loss_fp: 0.002549, loss_freq: 0.047968
[17:17:17.615] iteration 15399: loss: 0.046255, loss_s1: 0.026579, loss_fp: 0.006365, loss_freq: 0.018406
[17:17:18.246] iteration 15400: loss: 0.058939, loss_s1: 0.047127, loss_fp: 0.001109, loss_freq: 0.013178
[17:17:21.478] iteration 15400 : mean_dice : 0.712062
[17:17:22.183] iteration 15401: loss: 0.056851, loss_s1: 0.051636, loss_fp: 0.001581, loss_freq: 0.022694
[17:17:22.843] iteration 15402: loss: 0.046062, loss_s1: 0.022911, loss_fp: 0.000249, loss_freq: 0.018951
[17:17:23.502] iteration 15403: loss: 0.094092, loss_s1: 0.078064, loss_fp: 0.003785, loss_freq: 0.051871
[17:17:24.161] iteration 15404: loss: 0.106057, loss_s1: 0.068825, loss_fp: 0.009851, loss_freq: 0.076814
[17:17:24.792] iteration 15405: loss: 0.102822, loss_s1: 0.070371, loss_fp: 0.007651, loss_freq: 0.033772
[17:17:25.418] iteration 15406: loss: 0.057737, loss_s1: 0.043821, loss_fp: 0.000598, loss_freq: 0.015540
[17:17:26.046] iteration 15407: loss: 0.067211, loss_s1: 0.045367, loss_fp: 0.005728, loss_freq: 0.052085
[17:17:26.678] iteration 15408: loss: 0.069533, loss_s1: 0.073658, loss_fp: 0.000637, loss_freq: 0.034207
[17:17:27.308] iteration 15409: loss: 0.059172, loss_s1: 0.021917, loss_fp: 0.000708, loss_freq: 0.040629
[17:17:27.931] iteration 15410: loss: 0.041689, loss_s1: 0.031098, loss_fp: 0.000525, loss_freq: 0.008939
[17:17:28.556] iteration 15411: loss: 0.075449, loss_s1: 0.062542, loss_fp: 0.006984, loss_freq: 0.040351
[17:17:29.174] iteration 15412: loss: 0.050676, loss_s1: 0.039941, loss_fp: 0.000951, loss_freq: 0.021612
[17:17:29.801] iteration 15413: loss: 0.030803, loss_s1: 0.009310, loss_fp: 0.001946, loss_freq: 0.011766
[17:17:30.428] iteration 15414: loss: 0.082907, loss_s1: 0.071936, loss_fp: 0.003535, loss_freq: 0.036325
[17:17:31.052] iteration 15415: loss: 0.065687, loss_s1: 0.050423, loss_fp: 0.003500, loss_freq: 0.035986
[17:17:31.680] iteration 15416: loss: 0.067751, loss_s1: 0.045051, loss_fp: 0.008467, loss_freq: 0.034792
[17:17:32.308] iteration 15417: loss: 0.055901, loss_s1: 0.014877, loss_fp: 0.004920, loss_freq: 0.035847
[17:17:32.935] iteration 15418: loss: 0.089043, loss_s1: 0.076632, loss_fp: 0.009085, loss_freq: 0.046071
[17:17:33.565] iteration 15419: loss: 0.072234, loss_s1: 0.060546, loss_fp: 0.002150, loss_freq: 0.031117
[17:17:34.194] iteration 15420: loss: 0.055850, loss_s1: 0.038722, loss_fp: 0.003083, loss_freq: 0.020951
[17:17:34.819] iteration 15421: loss: 0.074853, loss_s1: 0.048396, loss_fp: 0.014916, loss_freq: 0.023704
[17:17:35.448] iteration 15422: loss: 0.047696, loss_s1: 0.026987, loss_fp: 0.001850, loss_freq: 0.021541
[17:17:36.082] iteration 15423: loss: 0.109724, loss_s1: 0.037980, loss_fp: 0.014774, loss_freq: 0.095506
[17:17:36.737] iteration 15424: loss: 0.084415, loss_s1: 0.071487, loss_fp: 0.000785, loss_freq: 0.045568
[17:17:37.399] iteration 15425: loss: 0.050740, loss_s1: 0.047849, loss_fp: 0.002218, loss_freq: 0.011491
[17:17:38.056] iteration 15426: loss: 0.094537, loss_s1: 0.055936, loss_fp: 0.004788, loss_freq: 0.084093
[17:17:38.679] iteration 15427: loss: 0.076517, loss_s1: 0.068785, loss_fp: 0.002482, loss_freq: 0.033951
[17:17:39.300] iteration 15428: loss: 0.077717, loss_s1: 0.072660, loss_fp: 0.002440, loss_freq: 0.029931
[17:17:39.925] iteration 15429: loss: 0.065584, loss_s1: 0.028492, loss_fp: 0.014368, loss_freq: 0.011903
[17:17:40.552] iteration 15430: loss: 0.075702, loss_s1: 0.048000, loss_fp: 0.001966, loss_freq: 0.061931
[17:17:41.179] iteration 15431: loss: 0.066534, loss_s1: 0.063847, loss_fp: 0.001260, loss_freq: 0.031589
[17:17:41.802] iteration 15432: loss: 0.039560, loss_s1: 0.013102, loss_fp: 0.001684, loss_freq: 0.017887
[17:17:42.424] iteration 15433: loss: 0.044216, loss_s1: 0.023048, loss_fp: 0.006144, loss_freq: 0.016609
[17:17:43.046] iteration 15434: loss: 0.058091, loss_s1: 0.022262, loss_fp: 0.005182, loss_freq: 0.046400
[17:17:43.669] iteration 15435: loss: 0.105971, loss_s1: 0.053898, loss_fp: 0.005200, loss_freq: 0.077221
[17:17:44.290] iteration 15436: loss: 0.049484, loss_s1: 0.019464, loss_fp: 0.012377, loss_freq: 0.024637
[17:17:44.938] iteration 15437: loss: 0.100590, loss_s1: 0.048547, loss_fp: 0.007358, loss_freq: 0.036568
[17:17:45.564] iteration 15438: loss: 0.098430, loss_s1: 0.070435, loss_fp: 0.018874, loss_freq: 0.053680
[17:17:46.181] iteration 15439: loss: 0.065339, loss_s1: 0.034598, loss_fp: 0.003553, loss_freq: 0.031045
[17:17:46.802] iteration 15440: loss: 0.071537, loss_s1: 0.051485, loss_fp: 0.003842, loss_freq: 0.030044
[17:17:47.425] iteration 15441: loss: 0.113805, loss_s1: 0.134465, loss_fp: 0.004644, loss_freq: 0.030814
[17:17:48.056] iteration 15442: loss: 0.081764, loss_s1: 0.055095, loss_fp: 0.012586, loss_freq: 0.055493
[17:17:48.692] iteration 15443: loss: 0.068619, loss_s1: 0.054858, loss_fp: 0.005388, loss_freq: 0.016587
[17:17:49.319] iteration 15444: loss: 0.079003, loss_s1: 0.044655, loss_fp: 0.014356, loss_freq: 0.025577
[17:17:49.951] iteration 15445: loss: 0.129846, loss_s1: 0.077133, loss_fp: 0.005810, loss_freq: 0.071608
[17:17:50.577] iteration 15446: loss: 0.102117, loss_s1: 0.044844, loss_fp: 0.005160, loss_freq: 0.058990
[17:17:51.204] iteration 15447: loss: 0.089771, loss_s1: 0.062313, loss_fp: 0.004593, loss_freq: 0.073163
[17:17:51.830] iteration 15448: loss: 0.040205, loss_s1: 0.028335, loss_fp: 0.005223, loss_freq: 0.011539
[17:17:52.461] iteration 15449: loss: 0.048017, loss_s1: 0.019966, loss_fp: 0.003391, loss_freq: 0.021511
[17:17:53.091] iteration 15450: loss: 0.030830, loss_s1: 0.022828, loss_fp: 0.001913, loss_freq: 0.007219
[17:17:53.714] iteration 15451: loss: 0.047403, loss_s1: 0.031346, loss_fp: 0.001089, loss_freq: 0.019426
[17:17:54.336] iteration 15452: loss: 0.061661, loss_s1: 0.025898, loss_fp: 0.000401, loss_freq: 0.017996
[17:17:54.965] iteration 15453: loss: 0.089835, loss_s1: 0.062276, loss_fp: 0.003934, loss_freq: 0.056605
[17:17:55.585] iteration 15454: loss: 0.119471, loss_s1: 0.134143, loss_fp: 0.013245, loss_freq: 0.049939
[17:17:56.208] iteration 15455: loss: 0.047058, loss_s1: 0.036916, loss_fp: 0.001300, loss_freq: 0.005680
[17:17:56.827] iteration 15456: loss: 0.083842, loss_s1: 0.073725, loss_fp: 0.002361, loss_freq: 0.040886
[17:17:57.821] iteration 15457: loss: 0.083871, loss_s1: 0.085397, loss_fp: 0.000468, loss_freq: 0.028114
[17:17:58.449] iteration 15458: loss: 0.087729, loss_s1: 0.051773, loss_fp: 0.000814, loss_freq: 0.067262
[17:17:59.072] iteration 15459: loss: 0.082559, loss_s1: 0.050295, loss_fp: 0.001291, loss_freq: 0.020632
[17:17:59.696] iteration 15460: loss: 0.047300, loss_s1: 0.026884, loss_fp: 0.000529, loss_freq: 0.017503
[17:18:00.328] iteration 15461: loss: 0.042731, loss_s1: 0.027927, loss_fp: 0.005202, loss_freq: 0.010829
[17:18:00.957] iteration 15462: loss: 0.154026, loss_s1: 0.136884, loss_fp: 0.019874, loss_freq: 0.059003
[17:18:01.586] iteration 15463: loss: 0.040343, loss_s1: 0.021350, loss_fp: 0.007697, loss_freq: 0.017103
[17:18:02.240] iteration 15464: loss: 0.057180, loss_s1: 0.063064, loss_fp: 0.001067, loss_freq: 0.013130
[17:18:02.903] iteration 15465: loss: 0.081110, loss_s1: 0.073342, loss_fp: 0.002089, loss_freq: 0.050195
[17:18:03.571] iteration 15466: loss: 0.056480, loss_s1: 0.020851, loss_fp: 0.005202, loss_freq: 0.021186
[17:18:04.233] iteration 15467: loss: 0.049610, loss_s1: 0.022137, loss_fp: 0.005461, loss_freq: 0.020795
[17:18:04.925] iteration 15468: loss: 0.049215, loss_s1: 0.012902, loss_fp: 0.005997, loss_freq: 0.034821
[17:18:05.560] iteration 15469: loss: 0.090576, loss_s1: 0.053047, loss_fp: 0.005674, loss_freq: 0.083456
[17:18:06.191] iteration 15470: loss: 0.053289, loss_s1: 0.037640, loss_fp: 0.001635, loss_freq: 0.020913
[17:18:06.823] iteration 15471: loss: 0.047607, loss_s1: 0.032600, loss_fp: 0.012625, loss_freq: 0.005974
[17:18:07.480] iteration 15472: loss: 0.116492, loss_s1: 0.064628, loss_fp: 0.005749, loss_freq: 0.118293
[17:18:08.146] iteration 15473: loss: 0.065744, loss_s1: 0.045673, loss_fp: 0.000615, loss_freq: 0.011926
[17:18:08.807] iteration 15474: loss: 0.039116, loss_s1: 0.026396, loss_fp: 0.001878, loss_freq: 0.012404
[17:18:09.439] iteration 15475: loss: 0.069537, loss_s1: 0.056771, loss_fp: 0.003058, loss_freq: 0.030684
[17:18:10.067] iteration 15476: loss: 0.071918, loss_s1: 0.018422, loss_fp: 0.002934, loss_freq: 0.012224
[17:18:10.692] iteration 15477: loss: 0.049838, loss_s1: 0.043270, loss_fp: 0.001116, loss_freq: 0.007858
[17:18:11.357] iteration 15478: loss: 0.046282, loss_s1: 0.033675, loss_fp: 0.000860, loss_freq: 0.018926
[17:18:11.985] iteration 15479: loss: 0.062268, loss_s1: 0.029654, loss_fp: 0.001430, loss_freq: 0.010185
[17:18:12.615] iteration 15480: loss: 0.077530, loss_s1: 0.075313, loss_fp: 0.000792, loss_freq: 0.042569
[17:18:13.252] iteration 15481: loss: 0.065847, loss_s1: 0.060881, loss_fp: 0.001383, loss_freq: 0.037038
[17:18:13.879] iteration 15482: loss: 0.068129, loss_s1: 0.049687, loss_fp: 0.002665, loss_freq: 0.050248
[17:18:14.511] iteration 15483: loss: 0.038867, loss_s1: 0.032311, loss_fp: 0.005763, loss_freq: 0.004394
[17:18:15.140] iteration 15484: loss: 0.111367, loss_s1: 0.043542, loss_fp: 0.028189, loss_freq: 0.062412
[17:18:15.766] iteration 15485: loss: 0.079006, loss_s1: 0.063661, loss_fp: 0.009835, loss_freq: 0.024872
[17:18:16.395] iteration 15486: loss: 0.058126, loss_s1: 0.053925, loss_fp: 0.001664, loss_freq: 0.008701
[17:18:17.035] iteration 15487: loss: 0.036896, loss_s1: 0.024306, loss_fp: 0.000952, loss_freq: 0.016345
[17:18:17.674] iteration 15488: loss: 0.040481, loss_s1: 0.023320, loss_fp: 0.001874, loss_freq: 0.011068
[17:18:18.315] iteration 15489: loss: 0.051868, loss_s1: 0.019720, loss_fp: 0.001471, loss_freq: 0.027088
[17:18:18.956] iteration 15490: loss: 0.046701, loss_s1: 0.037773, loss_fp: 0.005191, loss_freq: 0.008501
[17:18:19.597] iteration 15491: loss: 0.094643, loss_s1: 0.073765, loss_fp: 0.004473, loss_freq: 0.042631
[17:18:20.240] iteration 15492: loss: 0.072979, loss_s1: 0.057898, loss_fp: 0.006207, loss_freq: 0.044468
[17:18:20.883] iteration 15493: loss: 0.106569, loss_s1: 0.130543, loss_fp: 0.008332, loss_freq: 0.030951
[17:18:21.526] iteration 15494: loss: 0.076373, loss_s1: 0.036319, loss_fp: 0.005215, loss_freq: 0.054285
[17:18:22.172] iteration 15495: loss: 0.109685, loss_s1: 0.101482, loss_fp: 0.003425, loss_freq: 0.057432
[17:18:22.814] iteration 15496: loss: 0.076154, loss_s1: 0.069752, loss_fp: 0.003659, loss_freq: 0.034958
[17:18:23.456] iteration 15497: loss: 0.054302, loss_s1: 0.047573, loss_fp: 0.003130, loss_freq: 0.011253
[17:18:24.097] iteration 15498: loss: 0.088903, loss_s1: 0.060232, loss_fp: 0.001687, loss_freq: 0.077817
[17:18:24.742] iteration 15499: loss: 0.068040, loss_s1: 0.066449, loss_fp: 0.002205, loss_freq: 0.032512
[17:18:25.386] iteration 15500: loss: 0.049619, loss_s1: 0.026977, loss_fp: 0.001459, loss_freq: 0.040213
[17:18:26.027] iteration 15501: loss: 0.081461, loss_s1: 0.039294, loss_fp: 0.001935, loss_freq: 0.074404
[17:18:26.666] iteration 15502: loss: 0.072455, loss_s1: 0.049102, loss_fp: 0.002645, loss_freq: 0.020252
[17:18:27.305] iteration 15503: loss: 0.051119, loss_s1: 0.031602, loss_fp: 0.006077, loss_freq: 0.021052
[17:18:27.944] iteration 15504: loss: 0.054068, loss_s1: 0.035529, loss_fp: 0.002674, loss_freq: 0.027026
[17:18:28.587] iteration 15505: loss: 0.075611, loss_s1: 0.043800, loss_fp: 0.002226, loss_freq: 0.026245
[17:18:29.231] iteration 15506: loss: 0.054918, loss_s1: 0.039268, loss_fp: 0.006336, loss_freq: 0.028848
[17:18:29.988] iteration 15507: loss: 0.095244, loss_s1: 0.056118, loss_fp: 0.002451, loss_freq: 0.058785
[17:18:30.631] iteration 15508: loss: 0.054802, loss_s1: 0.021548, loss_fp: 0.004928, loss_freq: 0.035846
[17:18:31.266] iteration 15509: loss: 0.070974, loss_s1: 0.061105, loss_fp: 0.004000, loss_freq: 0.026085
[17:18:31.895] iteration 15510: loss: 0.066513, loss_s1: 0.047898, loss_fp: 0.004291, loss_freq: 0.024425
[17:18:32.562] iteration 15511: loss: 0.037991, loss_s1: 0.024169, loss_fp: 0.001278, loss_freq: 0.007154
[17:18:33.217] iteration 15512: loss: 0.096081, loss_s1: 0.103264, loss_fp: 0.007269, loss_freq: 0.022357
[17:18:33.879] iteration 15513: loss: 0.058922, loss_s1: 0.039193, loss_fp: 0.001569, loss_freq: 0.005584
[17:18:34.507] iteration 15514: loss: 0.050041, loss_s1: 0.008655, loss_fp: 0.001014, loss_freq: 0.028591
[17:18:35.131] iteration 15515: loss: 0.029393, loss_s1: 0.015470, loss_fp: 0.002700, loss_freq: 0.008132
[17:18:35.757] iteration 15516: loss: 0.041332, loss_s1: 0.032725, loss_fp: 0.004655, loss_freq: 0.017941
[17:18:36.386] iteration 15517: loss: 0.039106, loss_s1: 0.016905, loss_fp: 0.006149, loss_freq: 0.014704
[17:18:37.011] iteration 15518: loss: 0.073156, loss_s1: 0.069599, loss_fp: 0.003842, loss_freq: 0.024580
[17:18:37.639] iteration 15519: loss: 0.049138, loss_s1: 0.046748, loss_fp: 0.002926, loss_freq: 0.008554
[17:18:38.265] iteration 15520: loss: 0.039763, loss_s1: 0.031067, loss_fp: 0.002608, loss_freq: 0.009226
[17:18:38.891] iteration 15521: loss: 0.036953, loss_s1: 0.021361, loss_fp: 0.006096, loss_freq: 0.009136
[17:18:39.515] iteration 15522: loss: 0.051097, loss_s1: 0.026462, loss_fp: 0.002873, loss_freq: 0.043569
[17:18:40.144] iteration 15523: loss: 0.063941, loss_s1: 0.041726, loss_fp: 0.001402, loss_freq: 0.039878
[17:18:40.767] iteration 15524: loss: 0.062221, loss_s1: 0.057787, loss_fp: 0.002439, loss_freq: 0.026235
[17:18:41.395] iteration 15525: loss: 0.068296, loss_s1: 0.073153, loss_fp: 0.005551, loss_freq: 0.018256
[17:18:42.021] iteration 15526: loss: 0.073054, loss_s1: 0.051568, loss_fp: 0.002822, loss_freq: 0.032073
[17:18:42.648] iteration 15527: loss: 0.048906, loss_s1: 0.032390, loss_fp: 0.002552, loss_freq: 0.021943
[17:18:43.275] iteration 15528: loss: 0.050359, loss_s1: 0.045499, loss_fp: 0.000732, loss_freq: 0.009634
[17:18:43.902] iteration 15529: loss: 0.057075, loss_s1: 0.056042, loss_fp: 0.006781, loss_freq: 0.018276
[17:18:44.530] iteration 15530: loss: 0.045232, loss_s1: 0.025286, loss_fp: 0.000456, loss_freq: 0.009628
[17:18:45.160] iteration 15531: loss: 0.103207, loss_s1: 0.110920, loss_fp: 0.001666, loss_freq: 0.032778
[17:18:45.784] iteration 15532: loss: 0.071192, loss_s1: 0.058879, loss_fp: 0.001701, loss_freq: 0.013233
[17:18:46.408] iteration 15533: loss: 0.058621, loss_s1: 0.017603, loss_fp: 0.001093, loss_freq: 0.039085
[17:18:47.030] iteration 15534: loss: 0.078408, loss_s1: 0.092436, loss_fp: 0.003034, loss_freq: 0.031103
[17:18:47.658] iteration 15535: loss: 0.029543, loss_s1: 0.013747, loss_fp: 0.001851, loss_freq: 0.012765
[17:18:48.283] iteration 15536: loss: 0.057702, loss_s1: 0.033881, loss_fp: 0.003488, loss_freq: 0.034178
[17:18:48.906] iteration 15537: loss: 0.077656, loss_s1: 0.023566, loss_fp: 0.015100, loss_freq: 0.073466
[17:18:49.532] iteration 15538: loss: 0.056770, loss_s1: 0.060828, loss_fp: 0.000512, loss_freq: 0.021652
[17:18:50.158] iteration 15539: loss: 0.083985, loss_s1: 0.099557, loss_fp: 0.005502, loss_freq: 0.019391
[17:18:50.785] iteration 15540: loss: 0.075123, loss_s1: 0.075274, loss_fp: 0.003902, loss_freq: 0.026026
[17:18:51.411] iteration 15541: loss: 0.075385, loss_s1: 0.063375, loss_fp: 0.003147, loss_freq: 0.049212
[17:18:52.062] iteration 15542: loss: 0.060374, loss_s1: 0.065311, loss_fp: 0.001825, loss_freq: 0.020241
[17:18:52.694] iteration 15543: loss: 0.103107, loss_s1: 0.051960, loss_fp: 0.019657, loss_freq: 0.020335
[17:18:53.316] iteration 15544: loss: 0.051660, loss_s1: 0.047567, loss_fp: 0.000480, loss_freq: 0.009989
[17:18:53.939] iteration 15545: loss: 0.079121, loss_s1: 0.058255, loss_fp: 0.002488, loss_freq: 0.060253
[17:18:54.568] iteration 15546: loss: 0.063947, loss_s1: 0.037163, loss_fp: 0.002469, loss_freq: 0.026677
[17:18:55.196] iteration 15547: loss: 0.059268, loss_s1: 0.034279, loss_fp: 0.001880, loss_freq: 0.013875
[17:18:55.824] iteration 15548: loss: 0.049100, loss_s1: 0.038133, loss_fp: 0.002558, loss_freq: 0.021932
[17:18:56.450] iteration 15549: loss: 0.063502, loss_s1: 0.017834, loss_fp: 0.002688, loss_freq: 0.026293
[17:18:57.076] iteration 15550: loss: 0.046268, loss_s1: 0.031293, loss_fp: 0.000250, loss_freq: 0.005541
[17:18:57.706] iteration 15551: loss: 0.042362, loss_s1: 0.027601, loss_fp: 0.000825, loss_freq: 0.018629
[17:18:58.330] iteration 15552: loss: 0.049933, loss_s1: 0.037084, loss_fp: 0.001320, loss_freq: 0.030834
[17:18:58.958] iteration 15553: loss: 0.042438, loss_s1: 0.013405, loss_fp: 0.000274, loss_freq: 0.024037
[17:18:59.583] iteration 15554: loss: 0.039215, loss_s1: 0.010303, loss_fp: 0.001917, loss_freq: 0.018054
[17:19:00.202] iteration 15555: loss: 0.045025, loss_s1: 0.025540, loss_fp: 0.001684, loss_freq: 0.020047
[17:19:00.829] iteration 15556: loss: 0.042351, loss_s1: 0.023956, loss_fp: 0.001949, loss_freq: 0.015249
[17:19:01.456] iteration 15557: loss: 0.062622, loss_s1: 0.058937, loss_fp: 0.001402, loss_freq: 0.024392
[17:19:02.080] iteration 15558: loss: 0.055901, loss_s1: 0.034071, loss_fp: 0.002299, loss_freq: 0.028815
[17:19:02.706] iteration 15559: loss: 0.047235, loss_s1: 0.032257, loss_fp: 0.001300, loss_freq: 0.025566
[17:19:03.329] iteration 15560: loss: 0.056307, loss_s1: 0.027590, loss_fp: 0.006470, loss_freq: 0.044224
[17:19:03.957] iteration 15561: loss: 0.056002, loss_s1: 0.046652, loss_fp: 0.004177, loss_freq: 0.008360
[17:19:04.582] iteration 15562: loss: 0.046764, loss_s1: 0.032417, loss_fp: 0.000923, loss_freq: 0.024874
[17:19:05.206] iteration 15563: loss: 0.035207, loss_s1: 0.016398, loss_fp: 0.000614, loss_freq: 0.013510
[17:19:05.831] iteration 15564: loss: 0.102654, loss_s1: 0.068910, loss_fp: 0.009274, loss_freq: 0.087601
[17:19:06.457] iteration 15565: loss: 0.133579, loss_s1: 0.133761, loss_fp: 0.002175, loss_freq: 0.074368
[17:19:07.083] iteration 15566: loss: 0.068986, loss_s1: 0.061504, loss_fp: 0.001486, loss_freq: 0.037911
[17:19:07.711] iteration 15567: loss: 0.061897, loss_s1: 0.021851, loss_fp: 0.002914, loss_freq: 0.010856
[17:19:08.332] iteration 15568: loss: 0.065338, loss_s1: 0.051626, loss_fp: 0.001054, loss_freq: 0.032309
[17:19:08.960] iteration 15569: loss: 0.050627, loss_s1: 0.039183, loss_fp: 0.003956, loss_freq: 0.018065
[17:19:09.588] iteration 15570: loss: 0.058626, loss_s1: 0.033577, loss_fp: 0.004111, loss_freq: 0.039777
[17:19:10.228] iteration 15571: loss: 0.031085, loss_s1: 0.018360, loss_fp: 0.000807, loss_freq: 0.003797
[17:19:10.851] iteration 15572: loss: 0.078750, loss_s1: 0.087125, loss_fp: 0.001163, loss_freq: 0.023163
[17:19:11.477] iteration 15573: loss: 0.034851, loss_s1: 0.020512, loss_fp: 0.001061, loss_freq: 0.012516
[17:19:12.103] iteration 15574: loss: 0.029456, loss_s1: 0.009541, loss_fp: 0.002604, loss_freq: 0.014976
[17:19:12.728] iteration 15575: loss: 0.075646, loss_s1: 0.057798, loss_fp: 0.017917, loss_freq: 0.027027
[17:19:13.350] iteration 15576: loss: 0.084553, loss_s1: 0.058468, loss_fp: 0.004180, loss_freq: 0.070675
[17:19:13.975] iteration 15577: loss: 0.054014, loss_s1: 0.028559, loss_fp: 0.001564, loss_freq: 0.037969
[17:19:14.599] iteration 15578: loss: 0.054457, loss_s1: 0.023464, loss_fp: 0.004849, loss_freq: 0.021185
[17:19:15.226] iteration 15579: loss: 0.104838, loss_s1: 0.131102, loss_fp: 0.000716, loss_freq: 0.023565
[17:19:15.851] iteration 15580: loss: 0.051001, loss_s1: 0.037211, loss_fp: 0.001729, loss_freq: 0.009915
[17:19:16.478] iteration 15581: loss: 0.056114, loss_s1: 0.031326, loss_fp: 0.003797, loss_freq: 0.033391
[17:19:17.105] iteration 15582: loss: 0.060614, loss_s1: 0.045995, loss_fp: 0.006498, loss_freq: 0.022737
[17:19:17.730] iteration 15583: loss: 0.047128, loss_s1: 0.027614, loss_fp: 0.000164, loss_freq: 0.013828
[17:19:18.357] iteration 15584: loss: 0.084778, loss_s1: 0.066776, loss_fp: 0.004442, loss_freq: 0.057324
[17:19:18.979] iteration 15585: loss: 0.101754, loss_s1: 0.100358, loss_fp: 0.020472, loss_freq: 0.047683
[17:19:19.604] iteration 15586: loss: 0.045280, loss_s1: 0.034128, loss_fp: 0.007750, loss_freq: 0.009534
[17:19:20.229] iteration 15587: loss: 0.067196, loss_s1: 0.034543, loss_fp: 0.002828, loss_freq: 0.056519
[17:19:20.856] iteration 15588: loss: 0.059258, loss_s1: 0.064497, loss_fp: 0.002844, loss_freq: 0.016774
[17:19:21.482] iteration 15589: loss: 0.074213, loss_s1: 0.079829, loss_fp: 0.003195, loss_freq: 0.017028
[17:19:22.104] iteration 15590: loss: 0.057951, loss_s1: 0.048532, loss_fp: 0.003595, loss_freq: 0.007900
[17:19:22.731] iteration 15591: loss: 0.100667, loss_s1: 0.100683, loss_fp: 0.000820, loss_freq: 0.057822
[17:19:23.361] iteration 15592: loss: 0.063115, loss_s1: 0.073465, loss_fp: 0.001865, loss_freq: 0.017015
[17:19:23.984] iteration 15593: loss: 0.051285, loss_s1: 0.024125, loss_fp: 0.002696, loss_freq: 0.012031
[17:19:24.607] iteration 15594: loss: 0.061782, loss_s1: 0.047659, loss_fp: 0.007047, loss_freq: 0.033910
[17:19:25.230] iteration 15595: loss: 0.060077, loss_s1: 0.044458, loss_fp: 0.005630, loss_freq: 0.030275
[17:19:25.855] iteration 15596: loss: 0.114166, loss_s1: 0.058356, loss_fp: 0.010872, loss_freq: 0.032722
[17:19:26.479] iteration 15597: loss: 0.069588, loss_s1: 0.079475, loss_fp: 0.003393, loss_freq: 0.021812
[17:19:27.105] iteration 15598: loss: 0.064784, loss_s1: 0.028135, loss_fp: 0.001564, loss_freq: 0.039504
[17:19:27.729] iteration 15599: loss: 0.059011, loss_s1: 0.018223, loss_fp: 0.001074, loss_freq: 0.047654
[17:19:28.352] iteration 15600: loss: 0.074998, loss_s1: 0.041620, loss_fp: 0.014462, loss_freq: 0.022670
[17:19:31.592] iteration 15600 : mean_dice : 0.724081
[17:19:32.249] iteration 15601: loss: 0.039589, loss_s1: 0.023586, loss_fp: 0.000777, loss_freq: 0.010945
[17:19:32.871] iteration 15602: loss: 0.077841, loss_s1: 0.090718, loss_fp: 0.005982, loss_freq: 0.014919
[17:19:33.495] iteration 15603: loss: 0.104617, loss_s1: 0.087223, loss_fp: 0.004777, loss_freq: 0.087463
[17:19:34.120] iteration 15604: loss: 0.045761, loss_s1: 0.039840, loss_fp: 0.001482, loss_freq: 0.008517
[17:19:34.743] iteration 15605: loss: 0.073289, loss_s1: 0.062254, loss_fp: 0.003899, loss_freq: 0.038327
[17:19:35.371] iteration 15606: loss: 0.079526, loss_s1: 0.063489, loss_fp: 0.008342, loss_freq: 0.040909
[17:19:35.997] iteration 15607: loss: 0.145180, loss_s1: 0.058983, loss_fp: 0.006868, loss_freq: 0.089680
[17:19:36.621] iteration 15608: loss: 0.104370, loss_s1: 0.092813, loss_fp: 0.008168, loss_freq: 0.065817
[17:19:37.253] iteration 15609: loss: 0.067139, loss_s1: 0.052165, loss_fp: 0.002447, loss_freq: 0.019685
[17:19:37.877] iteration 15610: loss: 0.065398, loss_s1: 0.046850, loss_fp: 0.001296, loss_freq: 0.018346
[17:19:38.501] iteration 15611: loss: 0.031962, loss_s1: 0.013332, loss_fp: 0.000584, loss_freq: 0.018312
[17:19:39.123] iteration 15612: loss: 0.059574, loss_s1: 0.044145, loss_fp: 0.001607, loss_freq: 0.033178
[17:19:39.748] iteration 15613: loss: 0.051940, loss_s1: 0.023516, loss_fp: 0.001112, loss_freq: 0.030521
[17:19:40.372] iteration 15614: loss: 0.078804, loss_s1: 0.061536, loss_fp: 0.000856, loss_freq: 0.046354
[17:19:40.996] iteration 15615: loss: 0.062292, loss_s1: 0.054741, loss_fp: 0.001325, loss_freq: 0.016700
[17:19:41.618] iteration 15616: loss: 0.041906, loss_s1: 0.015643, loss_fp: 0.003245, loss_freq: 0.024024
[17:19:42.239] iteration 15617: loss: 0.050988, loss_s1: 0.025281, loss_fp: 0.002283, loss_freq: 0.021948
[17:19:43.224] iteration 15618: loss: 0.052727, loss_s1: 0.030040, loss_fp: 0.001453, loss_freq: 0.015656
[17:19:43.870] iteration 15619: loss: 0.053642, loss_s1: 0.034125, loss_fp: 0.000254, loss_freq: 0.033764
[17:19:44.501] iteration 15620: loss: 0.064794, loss_s1: 0.055674, loss_fp: 0.000956, loss_freq: 0.016898
[17:19:45.124] iteration 15621: loss: 0.043333, loss_s1: 0.015035, loss_fp: 0.001724, loss_freq: 0.018171
[17:19:45.750] iteration 15622: loss: 0.052842, loss_s1: 0.037454, loss_fp: 0.003155, loss_freq: 0.018619
[17:19:46.379] iteration 15623: loss: 0.112214, loss_s1: 0.068534, loss_fp: 0.012463, loss_freq: 0.042831
[17:19:47.003] iteration 15624: loss: 0.055729, loss_s1: 0.033179, loss_fp: 0.007903, loss_freq: 0.032457
[17:19:47.632] iteration 15625: loss: 0.047664, loss_s1: 0.032398, loss_fp: 0.006408, loss_freq: 0.021628
[17:19:48.267] iteration 15626: loss: 0.061989, loss_s1: 0.038236, loss_fp: 0.002531, loss_freq: 0.048870
[17:19:48.896] iteration 15627: loss: 0.064518, loss_s1: 0.046540, loss_fp: 0.007617, loss_freq: 0.028536
[17:19:49.523] iteration 15628: loss: 0.033891, loss_s1: 0.019698, loss_fp: 0.000644, loss_freq: 0.009907
[17:19:50.152] iteration 15629: loss: 0.073712, loss_s1: 0.065702, loss_fp: 0.002505, loss_freq: 0.033132
[17:19:50.781] iteration 15630: loss: 0.095085, loss_s1: 0.060398, loss_fp: 0.005747, loss_freq: 0.085670
[17:19:51.411] iteration 15631: loss: 0.060342, loss_s1: 0.026638, loss_fp: 0.003334, loss_freq: 0.045695
[17:19:52.040] iteration 15632: loss: 0.050929, loss_s1: 0.046062, loss_fp: 0.002301, loss_freq: 0.017918
[17:19:52.668] iteration 15633: loss: 0.088733, loss_s1: 0.044861, loss_fp: 0.011952, loss_freq: 0.076884
[17:19:53.297] iteration 15634: loss: 0.047337, loss_s1: 0.018635, loss_fp: 0.006233, loss_freq: 0.018529
[17:19:53.923] iteration 15635: loss: 0.053534, loss_s1: 0.021879, loss_fp: 0.001182, loss_freq: 0.028014
[17:19:54.550] iteration 15636: loss: 0.050413, loss_s1: 0.023101, loss_fp: 0.001311, loss_freq: 0.030431
[17:19:55.175] iteration 15637: loss: 0.079725, loss_s1: 0.060846, loss_fp: 0.004159, loss_freq: 0.041169
[17:19:55.800] iteration 15638: loss: 0.057073, loss_s1: 0.058860, loss_fp: 0.001341, loss_freq: 0.015653
[17:19:56.431] iteration 15639: loss: 0.060799, loss_s1: 0.049994, loss_fp: 0.004200, loss_freq: 0.014919
[17:19:57.056] iteration 15640: loss: 0.057418, loss_s1: 0.021962, loss_fp: 0.001422, loss_freq: 0.018258
[17:19:57.685] iteration 15641: loss: 0.122927, loss_s1: 0.081801, loss_fp: 0.005742, loss_freq: 0.113363
[17:19:58.312] iteration 15642: loss: 0.049415, loss_s1: 0.034527, loss_fp: 0.000405, loss_freq: 0.025091
[17:19:58.989] iteration 15643: loss: 0.047105, loss_s1: 0.023055, loss_fp: 0.001605, loss_freq: 0.024430
[17:19:59.651] iteration 15644: loss: 0.066019, loss_s1: 0.091805, loss_fp: 0.000804, loss_freq: 0.005597
[17:20:00.309] iteration 15645: loss: 0.080316, loss_s1: 0.058806, loss_fp: 0.016776, loss_freq: 0.038816
[17:20:00.972] iteration 15646: loss: 0.046896, loss_s1: 0.021606, loss_fp: 0.001912, loss_freq: 0.036772
[17:20:01.631] iteration 15647: loss: 0.055852, loss_s1: 0.057526, loss_fp: 0.003117, loss_freq: 0.011769
[17:20:02.280] iteration 15648: loss: 0.055747, loss_s1: 0.061589, loss_fp: 0.001773, loss_freq: 0.014795
[17:20:02.906] iteration 15649: loss: 0.057479, loss_s1: 0.053033, loss_fp: 0.002794, loss_freq: 0.015421
[17:20:03.534] iteration 15650: loss: 0.059110, loss_s1: 0.029985, loss_fp: 0.002410, loss_freq: 0.037756
[17:20:04.163] iteration 15651: loss: 0.055606, loss_s1: 0.072939, loss_fp: 0.001015, loss_freq: 0.006551
[17:20:04.789] iteration 15652: loss: 0.062374, loss_s1: 0.019358, loss_fp: 0.007294, loss_freq: 0.027699
[17:20:05.415] iteration 15653: loss: 0.045818, loss_s1: 0.032147, loss_fp: 0.002355, loss_freq: 0.021961
[17:20:06.035] iteration 15654: loss: 0.094087, loss_s1: 0.108892, loss_fp: 0.007113, loss_freq: 0.033289
[17:20:06.660] iteration 15655: loss: 0.053591, loss_s1: 0.022685, loss_fp: 0.002955, loss_freq: 0.020327
[17:20:07.289] iteration 15656: loss: 0.115442, loss_s1: 0.085572, loss_fp: 0.010847, loss_freq: 0.077084
[17:20:07.916] iteration 15657: loss: 0.055169, loss_s1: 0.041523, loss_fp: 0.003296, loss_freq: 0.022701
[17:20:08.579] iteration 15658: loss: 0.048865, loss_s1: 0.019645, loss_fp: 0.004005, loss_freq: 0.011962
[17:20:09.239] iteration 15659: loss: 0.090973, loss_s1: 0.102867, loss_fp: 0.008954, loss_freq: 0.036574
[17:20:09.897] iteration 15660: loss: 0.063892, loss_s1: 0.046887, loss_fp: 0.007406, loss_freq: 0.037001
[17:20:10.560] iteration 15661: loss: 0.058447, loss_s1: 0.041900, loss_fp: 0.003457, loss_freq: 0.041817
[17:20:11.196] iteration 15662: loss: 0.060433, loss_s1: 0.035219, loss_fp: 0.009059, loss_freq: 0.036195
[17:20:11.825] iteration 15663: loss: 0.090725, loss_s1: 0.073928, loss_fp: 0.001978, loss_freq: 0.058236
[17:20:12.453] iteration 15664: loss: 0.056357, loss_s1: 0.044207, loss_fp: 0.005886, loss_freq: 0.009625
[17:20:13.083] iteration 15665: loss: 0.060674, loss_s1: 0.060250, loss_fp: 0.005973, loss_freq: 0.019982
[17:20:13.707] iteration 15666: loss: 0.071924, loss_s1: 0.086208, loss_fp: 0.005682, loss_freq: 0.006227
[17:20:14.330] iteration 15667: loss: 0.055778, loss_s1: 0.041461, loss_fp: 0.003414, loss_freq: 0.034547
[17:20:14.956] iteration 15668: loss: 0.057475, loss_s1: 0.041700, loss_fp: 0.004543, loss_freq: 0.032501
[17:20:15.582] iteration 15669: loss: 0.075014, loss_s1: 0.057191, loss_fp: 0.008467, loss_freq: 0.017884
[17:20:16.205] iteration 15670: loss: 0.055242, loss_s1: 0.030510, loss_fp: 0.003109, loss_freq: 0.037775
[17:20:16.831] iteration 15671: loss: 0.054556, loss_s1: 0.034057, loss_fp: 0.002359, loss_freq: 0.032282
[17:20:17.463] iteration 15672: loss: 0.028752, loss_s1: 0.011381, loss_fp: 0.001059, loss_freq: 0.008589
[17:20:18.088] iteration 15673: loss: 0.050594, loss_s1: 0.033663, loss_fp: 0.002636, loss_freq: 0.022630
[17:20:18.711] iteration 15674: loss: 0.042698, loss_s1: 0.032893, loss_fp: 0.002710, loss_freq: 0.012720
[17:20:19.335] iteration 15675: loss: 0.073137, loss_s1: 0.029800, loss_fp: 0.001426, loss_freq: 0.042764
[17:20:19.967] iteration 15676: loss: 0.034170, loss_s1: 0.030025, loss_fp: 0.001124, loss_freq: 0.004939
[17:20:20.591] iteration 15677: loss: 0.056139, loss_s1: 0.050212, loss_fp: 0.005534, loss_freq: 0.020339
[17:20:21.217] iteration 15678: loss: 0.043659, loss_s1: 0.032779, loss_fp: 0.006625, loss_freq: 0.016952
[17:20:21.844] iteration 15679: loss: 0.050391, loss_s1: 0.034320, loss_fp: 0.002366, loss_freq: 0.028074
[17:20:22.531] iteration 15680: loss: 0.061202, loss_s1: 0.046543, loss_fp: 0.006070, loss_freq: 0.015033
[17:20:23.191] iteration 15681: loss: 0.064937, loss_s1: 0.039007, loss_fp: 0.005914, loss_freq: 0.042679
[17:20:23.850] iteration 15682: loss: 0.040361, loss_s1: 0.036522, loss_fp: 0.001004, loss_freq: 0.009755
[17:20:24.506] iteration 15683: loss: 0.069872, loss_s1: 0.052527, loss_fp: 0.000978, loss_freq: 0.037263
[17:20:25.142] iteration 15684: loss: 0.071248, loss_s1: 0.031038, loss_fp: 0.004026, loss_freq: 0.051956
[17:20:25.771] iteration 15685: loss: 0.076565, loss_s1: 0.085356, loss_fp: 0.005483, loss_freq: 0.027570
[17:20:26.399] iteration 15686: loss: 0.059308, loss_s1: 0.059476, loss_fp: 0.002484, loss_freq: 0.017606
[17:20:27.022] iteration 15687: loss: 0.087445, loss_s1: 0.053826, loss_fp: 0.004519, loss_freq: 0.026332
[17:20:27.647] iteration 15688: loss: 0.058393, loss_s1: 0.037100, loss_fp: 0.003304, loss_freq: 0.027880
[17:20:28.275] iteration 15689: loss: 0.065798, loss_s1: 0.022632, loss_fp: 0.000841, loss_freq: 0.038749
[17:20:28.899] iteration 15690: loss: 0.062844, loss_s1: 0.054737, loss_fp: 0.003562, loss_freq: 0.020068
[17:20:29.528] iteration 15691: loss: 0.039749, loss_s1: 0.019939, loss_fp: 0.003255, loss_freq: 0.005786
[17:20:30.188] iteration 15692: loss: 0.058356, loss_s1: 0.050439, loss_fp: 0.005146, loss_freq: 0.017827
[17:20:30.848] iteration 15693: loss: 0.061487, loss_s1: 0.059290, loss_fp: 0.003104, loss_freq: 0.006573
[17:20:31.508] iteration 15694: loss: 0.068455, loss_s1: 0.044520, loss_fp: 0.001507, loss_freq: 0.049679
[17:20:32.167] iteration 15695: loss: 0.050953, loss_s1: 0.041196, loss_fp: 0.001264, loss_freq: 0.023504
[17:20:32.827] iteration 15696: loss: 0.042306, loss_s1: 0.029674, loss_fp: 0.000368, loss_freq: 0.010008
[17:20:33.478] iteration 15697: loss: 0.074488, loss_s1: 0.059271, loss_fp: 0.005459, loss_freq: 0.031158
[17:20:34.106] iteration 15698: loss: 0.055475, loss_s1: 0.043336, loss_fp: 0.000931, loss_freq: 0.017205
[17:20:34.737] iteration 15699: loss: 0.060280, loss_s1: 0.051148, loss_fp: 0.008488, loss_freq: 0.031608
[17:20:35.697] iteration 15700: loss: 0.069018, loss_s1: 0.037828, loss_fp: 0.029801, loss_freq: 0.037372
[17:20:36.653] iteration 15701: loss: 0.094632, loss_s1: 0.116436, loss_fp: 0.002589, loss_freq: 0.029981
[17:20:37.277] iteration 15702: loss: 0.099592, loss_s1: 0.128603, loss_fp: 0.005426, loss_freq: 0.030022
[17:20:37.900] iteration 15703: loss: 0.053395, loss_s1: 0.013865, loss_fp: 0.001972, loss_freq: 0.055480
[17:20:38.533] iteration 15704: loss: 0.065813, loss_s1: 0.047738, loss_fp: 0.005897, loss_freq: 0.024497
[17:20:39.159] iteration 15705: loss: 0.045486, loss_s1: 0.024658, loss_fp: 0.002856, loss_freq: 0.017950
[17:20:39.796] iteration 15706: loss: 0.049879, loss_s1: 0.043877, loss_fp: 0.003362, loss_freq: 0.013508
[17:20:40.424] iteration 15707: loss: 0.067331, loss_s1: 0.058581, loss_fp: 0.001605, loss_freq: 0.037299
[17:20:41.049] iteration 15708: loss: 0.060296, loss_s1: 0.045840, loss_fp: 0.009738, loss_freq: 0.015577
[17:20:41.680] iteration 15709: loss: 0.048692, loss_s1: 0.038750, loss_fp: 0.003271, loss_freq: 0.010725
[17:20:42.306] iteration 15710: loss: 0.050457, loss_s1: 0.026063, loss_fp: 0.001409, loss_freq: 0.010492
[17:20:42.929] iteration 15711: loss: 0.053299, loss_s1: 0.050258, loss_fp: 0.002885, loss_freq: 0.016191
[17:20:43.552] iteration 15712: loss: 0.044469, loss_s1: 0.042956, loss_fp: 0.002028, loss_freq: 0.011200
[17:20:44.177] iteration 15713: loss: 0.056136, loss_s1: 0.041129, loss_fp: 0.002420, loss_freq: 0.032455
[17:20:44.806] iteration 15714: loss: 0.037554, loss_s1: 0.011192, loss_fp: 0.000334, loss_freq: 0.013003
[17:20:45.439] iteration 15715: loss: 0.051161, loss_s1: 0.016642, loss_fp: 0.001434, loss_freq: 0.033710
[17:20:46.067] iteration 15716: loss: 0.058918, loss_s1: 0.069815, loss_fp: 0.004912, loss_freq: 0.011261
[17:20:46.694] iteration 15717: loss: 0.059019, loss_s1: 0.052014, loss_fp: 0.004720, loss_freq: 0.023848
[17:20:47.320] iteration 15718: loss: 0.055159, loss_s1: 0.042932, loss_fp: 0.003242, loss_freq: 0.029375
[17:20:47.951] iteration 15719: loss: 0.096022, loss_s1: 0.060048, loss_fp: 0.002858, loss_freq: 0.067545
[17:20:48.576] iteration 15720: loss: 0.072408, loss_s1: 0.037261, loss_fp: 0.005871, loss_freq: 0.040725
[17:20:49.201] iteration 15721: loss: 0.085858, loss_s1: 0.068271, loss_fp: 0.005044, loss_freq: 0.049084
[17:20:49.827] iteration 15722: loss: 0.067580, loss_s1: 0.014832, loss_fp: 0.001039, loss_freq: 0.029614
[17:20:50.465] iteration 15723: loss: 0.050439, loss_s1: 0.021251, loss_fp: 0.010434, loss_freq: 0.030164
[17:20:51.091] iteration 15724: loss: 0.047043, loss_s1: 0.026715, loss_fp: 0.003612, loss_freq: 0.018666
[17:20:51.719] iteration 15725: loss: 0.096471, loss_s1: 0.093623, loss_fp: 0.002993, loss_freq: 0.028634
[17:20:52.348] iteration 15726: loss: 0.141691, loss_s1: 0.139381, loss_fp: 0.001726, loss_freq: 0.100605
[17:20:52.971] iteration 15727: loss: 0.072812, loss_s1: 0.071357, loss_fp: 0.001668, loss_freq: 0.027961
[17:20:53.596] iteration 15728: loss: 0.071966, loss_s1: 0.051306, loss_fp: 0.011661, loss_freq: 0.010848
[17:20:54.221] iteration 15729: loss: 0.050154, loss_s1: 0.024096, loss_fp: 0.003543, loss_freq: 0.031814
[17:20:54.843] iteration 15730: loss: 0.084666, loss_s1: 0.077658, loss_fp: 0.001947, loss_freq: 0.055810
[17:20:55.468] iteration 15731: loss: 0.053199, loss_s1: 0.044158, loss_fp: 0.001511, loss_freq: 0.024683
[17:20:56.093] iteration 15732: loss: 0.042874, loss_s1: 0.027726, loss_fp: 0.002492, loss_freq: 0.008196
[17:20:56.719] iteration 15733: loss: 0.077111, loss_s1: 0.064456, loss_fp: 0.005670, loss_freq: 0.033479
[17:20:57.342] iteration 15734: loss: 0.039698, loss_s1: 0.024288, loss_fp: 0.000699, loss_freq: 0.008869
[17:20:57.967] iteration 15735: loss: 0.037878, loss_s1: 0.010086, loss_fp: 0.003788, loss_freq: 0.012332
[17:20:58.591] iteration 15736: loss: 0.049447, loss_s1: 0.036837, loss_fp: 0.006841, loss_freq: 0.019078
[17:20:59.220] iteration 15737: loss: 0.074291, loss_s1: 0.043707, loss_fp: 0.004744, loss_freq: 0.064451
[17:20:59.844] iteration 15738: loss: 0.050891, loss_s1: 0.036579, loss_fp: 0.002722, loss_freq: 0.024730
[17:21:00.472] iteration 15739: loss: 0.073471, loss_s1: 0.069036, loss_fp: 0.002115, loss_freq: 0.019492
[17:21:01.097] iteration 15740: loss: 0.074850, loss_s1: 0.084682, loss_fp: 0.005485, loss_freq: 0.018114
[17:21:01.724] iteration 15741: loss: 0.054139, loss_s1: 0.031271, loss_fp: 0.001935, loss_freq: 0.036112
[17:21:02.350] iteration 15742: loss: 0.064651, loss_s1: 0.040896, loss_fp: 0.003632, loss_freq: 0.037873
[17:21:02.976] iteration 15743: loss: 0.065049, loss_s1: 0.044933, loss_fp: 0.010652, loss_freq: 0.016429
[17:21:03.605] iteration 15744: loss: 0.113365, loss_s1: 0.159432, loss_fp: 0.006528, loss_freq: 0.017495
[17:21:04.234] iteration 15745: loss: 0.110452, loss_s1: 0.043890, loss_fp: 0.009872, loss_freq: 0.096403
[17:21:04.860] iteration 15746: loss: 0.039675, loss_s1: 0.022107, loss_fp: 0.009342, loss_freq: 0.009807
[17:21:05.489] iteration 15747: loss: 0.054501, loss_s1: 0.031317, loss_fp: 0.008867, loss_freq: 0.016784
[17:21:06.115] iteration 15748: loss: 0.061477, loss_s1: 0.049873, loss_fp: 0.007972, loss_freq: 0.037064
[17:21:06.740] iteration 15749: loss: 0.062602, loss_s1: 0.063008, loss_fp: 0.002778, loss_freq: 0.020898
[17:21:07.387] iteration 15750: loss: 0.092900, loss_s1: 0.090486, loss_fp: 0.003306, loss_freq: 0.028133
[17:21:08.049] iteration 15751: loss: 0.050268, loss_s1: 0.035665, loss_fp: 0.001135, loss_freq: 0.015495
[17:21:08.709] iteration 15752: loss: 0.118623, loss_s1: 0.133567, loss_fp: 0.006983, loss_freq: 0.058920
[17:21:09.361] iteration 15753: loss: 0.058997, loss_s1: 0.053884, loss_fp: 0.009684, loss_freq: 0.019657
[17:21:09.985] iteration 15754: loss: 0.053829, loss_s1: 0.031414, loss_fp: 0.000594, loss_freq: 0.032845
[17:21:10.612] iteration 15755: loss: 0.037350, loss_s1: 0.013633, loss_fp: 0.001757, loss_freq: 0.020792
[17:21:11.234] iteration 15756: loss: 0.054605, loss_s1: 0.038971, loss_fp: 0.002767, loss_freq: 0.027555
[17:21:11.865] iteration 15757: loss: 0.100260, loss_s1: 0.077165, loss_fp: 0.003326, loss_freq: 0.050156
[17:21:12.496] iteration 15758: loss: 0.054437, loss_s1: 0.041787, loss_fp: 0.002676, loss_freq: 0.024783
[17:21:13.126] iteration 15759: loss: 0.072594, loss_s1: 0.030736, loss_fp: 0.013008, loss_freq: 0.025136
[17:21:13.754] iteration 15760: loss: 0.059646, loss_s1: 0.045796, loss_fp: 0.007709, loss_freq: 0.022778
[17:21:14.383] iteration 15761: loss: 0.074637, loss_s1: 0.052026, loss_fp: 0.004698, loss_freq: 0.040445
[17:21:15.007] iteration 15762: loss: 0.056961, loss_s1: 0.044681, loss_fp: 0.001211, loss_freq: 0.014670
[17:21:15.631] iteration 15763: loss: 0.066429, loss_s1: 0.036558, loss_fp: 0.018278, loss_freq: 0.024400
[17:21:16.254] iteration 15764: loss: 0.106077, loss_s1: 0.084069, loss_fp: 0.007265, loss_freq: 0.068248
[17:21:16.882] iteration 15765: loss: 0.039736, loss_s1: 0.026478, loss_fp: 0.003779, loss_freq: 0.010217
[17:21:17.513] iteration 15766: loss: 0.063741, loss_s1: 0.060558, loss_fp: 0.004051, loss_freq: 0.018924
[17:21:18.142] iteration 15767: loss: 0.085016, loss_s1: 0.054154, loss_fp: 0.013467, loss_freq: 0.039655
[17:21:18.770] iteration 15768: loss: 0.071556, loss_s1: 0.054889, loss_fp: 0.005552, loss_freq: 0.034412
[17:21:19.401] iteration 15769: loss: 0.086477, loss_s1: 0.072699, loss_fp: 0.005477, loss_freq: 0.057192
[17:21:20.026] iteration 15770: loss: 0.065723, loss_s1: 0.049033, loss_fp: 0.002127, loss_freq: 0.042770
[17:21:20.692] iteration 15771: loss: 0.079551, loss_s1: 0.053890, loss_fp: 0.007819, loss_freq: 0.029521
[17:21:21.350] iteration 15772: loss: 0.039395, loss_s1: 0.030273, loss_fp: 0.001713, loss_freq: 0.016529
[17:21:22.038] iteration 15773: loss: 0.065624, loss_s1: 0.053767, loss_fp: 0.005075, loss_freq: 0.014329
[17:21:22.701] iteration 15774: loss: 0.052744, loss_s1: 0.042942, loss_fp: 0.002025, loss_freq: 0.013075
[17:21:23.364] iteration 15775: loss: 0.066644, loss_s1: 0.032357, loss_fp: 0.007027, loss_freq: 0.048237
[17:21:24.009] iteration 15776: loss: 0.071998, loss_s1: 0.057290, loss_fp: 0.011264, loss_freq: 0.036015
[17:21:24.631] iteration 15777: loss: 0.053449, loss_s1: 0.045720, loss_fp: 0.002225, loss_freq: 0.017738
[17:21:25.251] iteration 15778: loss: 0.052303, loss_s1: 0.027455, loss_fp: 0.001340, loss_freq: 0.035042
[17:21:26.221] iteration 15779: loss: 0.056268, loss_s1: 0.029504, loss_fp: 0.000676, loss_freq: 0.032506
[17:21:26.877] iteration 15780: loss: 0.094928, loss_s1: 0.093041, loss_fp: 0.001204, loss_freq: 0.027751
[17:21:27.538] iteration 15781: loss: 0.051379, loss_s1: 0.036096, loss_fp: 0.002599, loss_freq: 0.021048
[17:21:28.197] iteration 15782: loss: 0.042541, loss_s1: 0.013528, loss_fp: 0.004730, loss_freq: 0.020434
[17:21:28.841] iteration 15783: loss: 0.046477, loss_s1: 0.019918, loss_fp: 0.017155, loss_freq: 0.016404
[17:21:29.464] iteration 15784: loss: 0.095656, loss_s1: 0.074979, loss_fp: 0.007324, loss_freq: 0.032258
[17:21:30.088] iteration 15785: loss: 0.044594, loss_s1: 0.032201, loss_fp: 0.004933, loss_freq: 0.017300
[17:21:30.708] iteration 15786: loss: 0.045662, loss_s1: 0.038318, loss_fp: 0.001871, loss_freq: 0.017656
[17:21:31.335] iteration 15787: loss: 0.060593, loss_s1: 0.040127, loss_fp: 0.005676, loss_freq: 0.047692
[17:21:31.960] iteration 15788: loss: 0.062914, loss_s1: 0.059076, loss_fp: 0.003611, loss_freq: 0.021431
[17:21:32.583] iteration 15789: loss: 0.049707, loss_s1: 0.038917, loss_fp: 0.000424, loss_freq: 0.018709
[17:21:33.243] iteration 15790: loss: 0.068530, loss_s1: 0.045089, loss_fp: 0.000978, loss_freq: 0.046377
[17:21:33.901] iteration 15791: loss: 0.061705, loss_s1: 0.041177, loss_fp: 0.002324, loss_freq: 0.049116
[17:21:34.560] iteration 15792: loss: 0.070497, loss_s1: 0.039608, loss_fp: 0.006444, loss_freq: 0.039538
[17:21:35.193] iteration 15793: loss: 0.090470, loss_s1: 0.092190, loss_fp: 0.003708, loss_freq: 0.055613
[17:21:35.818] iteration 15794: loss: 0.118611, loss_s1: 0.127557, loss_fp: 0.005840, loss_freq: 0.061550
[17:21:36.486] iteration 15795: loss: 0.050186, loss_s1: 0.038932, loss_fp: 0.001274, loss_freq: 0.010919
[17:21:37.140] iteration 15796: loss: 0.063877, loss_s1: 0.045307, loss_fp: 0.002160, loss_freq: 0.032898
[17:21:37.799] iteration 15797: loss: 0.071871, loss_s1: 0.035594, loss_fp: 0.003626, loss_freq: 0.029969
[17:21:38.435] iteration 15798: loss: 0.061094, loss_s1: 0.045501, loss_fp: 0.003333, loss_freq: 0.030217
[17:21:39.058] iteration 15799: loss: 0.054396, loss_s1: 0.061474, loss_fp: 0.000767, loss_freq: 0.005309
[17:21:39.682] iteration 15800: loss: 0.048225, loss_s1: 0.018079, loss_fp: 0.003081, loss_freq: 0.015281
[17:21:42.942] iteration 15800 : mean_dice : 0.718789
[17:21:43.599] iteration 15801: loss: 0.059125, loss_s1: 0.024784, loss_fp: 0.000975, loss_freq: 0.018723
[17:21:44.220] iteration 15802: loss: 0.086349, loss_s1: 0.065879, loss_fp: 0.003319, loss_freq: 0.063554
[17:21:44.843] iteration 15803: loss: 0.043299, loss_s1: 0.026968, loss_fp: 0.000520, loss_freq: 0.020344
[17:21:45.468] iteration 15804: loss: 0.071023, loss_s1: 0.055384, loss_fp: 0.001105, loss_freq: 0.043403
[17:21:46.093] iteration 15805: loss: 0.036058, loss_s1: 0.012126, loss_fp: 0.002831, loss_freq: 0.006960
[17:21:46.718] iteration 15806: loss: 0.061425, loss_s1: 0.021731, loss_fp: 0.013813, loss_freq: 0.037979
[17:21:47.345] iteration 15807: loss: 0.058190, loss_s1: 0.037044, loss_fp: 0.003736, loss_freq: 0.041283
[17:21:47.967] iteration 15808: loss: 0.038717, loss_s1: 0.020211, loss_fp: 0.001709, loss_freq: 0.017864
[17:21:48.590] iteration 15809: loss: 0.062161, loss_s1: 0.058457, loss_fp: 0.003232, loss_freq: 0.024918
[17:21:49.216] iteration 15810: loss: 0.066756, loss_s1: 0.048987, loss_fp: 0.010633, loss_freq: 0.030739
[17:21:49.840] iteration 15811: loss: 0.074522, loss_s1: 0.057415, loss_fp: 0.000499, loss_freq: 0.055268
[17:21:50.470] iteration 15812: loss: 0.032245, loss_s1: 0.018505, loss_fp: 0.000411, loss_freq: 0.005728
[17:21:51.095] iteration 15813: loss: 0.091521, loss_s1: 0.043754, loss_fp: 0.003066, loss_freq: 0.049586
[17:21:51.754] iteration 15814: loss: 0.071440, loss_s1: 0.045300, loss_fp: 0.007213, loss_freq: 0.052295
[17:21:52.385] iteration 15815: loss: 0.088054, loss_s1: 0.085976, loss_fp: 0.001329, loss_freq: 0.030661
[17:21:53.011] iteration 15816: loss: 0.047099, loss_s1: 0.021632, loss_fp: 0.005899, loss_freq: 0.023656
[17:21:53.639] iteration 15817: loss: 0.083548, loss_s1: 0.068667, loss_fp: 0.001431, loss_freq: 0.047457
[17:21:54.264] iteration 15818: loss: 0.062833, loss_s1: 0.033950, loss_fp: 0.005334, loss_freq: 0.027871
[17:21:54.891] iteration 15819: loss: 0.051118, loss_s1: 0.023017, loss_fp: 0.000548, loss_freq: 0.019175
[17:21:55.514] iteration 15820: loss: 0.058973, loss_s1: 0.038687, loss_fp: 0.002874, loss_freq: 0.043726
[17:21:56.140] iteration 15821: loss: 0.061171, loss_s1: 0.034819, loss_fp: 0.003223, loss_freq: 0.050131
[17:21:56.765] iteration 15822: loss: 0.058467, loss_s1: 0.043358, loss_fp: 0.002582, loss_freq: 0.033920
[17:21:57.392] iteration 15823: loss: 0.074087, loss_s1: 0.068078, loss_fp: 0.005029, loss_freq: 0.032754
[17:21:58.016] iteration 15824: loss: 0.068278, loss_s1: 0.066009, loss_fp: 0.002674, loss_freq: 0.007802
[17:21:58.640] iteration 15825: loss: 0.048135, loss_s1: 0.037952, loss_fp: 0.001553, loss_freq: 0.010727
[17:21:59.262] iteration 15826: loss: 0.051160, loss_s1: 0.042563, loss_fp: 0.001914, loss_freq: 0.023859
[17:21:59.887] iteration 15827: loss: 0.066148, loss_s1: 0.045692, loss_fp: 0.002124, loss_freq: 0.036298
[17:22:00.514] iteration 15828: loss: 0.056876, loss_s1: 0.049020, loss_fp: 0.000512, loss_freq: 0.035802
[17:22:01.141] iteration 15829: loss: 0.056641, loss_s1: 0.047870, loss_fp: 0.002919, loss_freq: 0.028658
[17:22:01.767] iteration 15830: loss: 0.061253, loss_s1: 0.035197, loss_fp: 0.002674, loss_freq: 0.041429
[17:22:02.394] iteration 15831: loss: 0.050992, loss_s1: 0.024137, loss_fp: 0.003601, loss_freq: 0.028162
[17:22:03.018] iteration 15832: loss: 0.064734, loss_s1: 0.055572, loss_fp: 0.002004, loss_freq: 0.032954
[17:22:03.643] iteration 15833: loss: 0.063236, loss_s1: 0.026678, loss_fp: 0.002002, loss_freq: 0.019806
[17:22:04.270] iteration 15834: loss: 0.067675, loss_s1: 0.063229, loss_fp: 0.005724, loss_freq: 0.018745
[17:22:04.929] iteration 15835: loss: 0.047999, loss_s1: 0.034792, loss_fp: 0.007509, loss_freq: 0.011049
[17:22:05.585] iteration 15836: loss: 0.068557, loss_s1: 0.051837, loss_fp: 0.000840, loss_freq: 0.029997
[17:22:06.243] iteration 15837: loss: 0.052928, loss_s1: 0.053020, loss_fp: 0.003975, loss_freq: 0.013960
[17:22:06.884] iteration 15838: loss: 0.052363, loss_s1: 0.047248, loss_fp: 0.004154, loss_freq: 0.017968
[17:22:07.511] iteration 15839: loss: 0.052823, loss_s1: 0.051238, loss_fp: 0.002960, loss_freq: 0.019245
[17:22:08.183] iteration 15840: loss: 0.053667, loss_s1: 0.047274, loss_fp: 0.011656, loss_freq: 0.016273
[17:22:08.864] iteration 15841: loss: 0.050052, loss_s1: 0.042556, loss_fp: 0.002406, loss_freq: 0.009537
[17:22:09.502] iteration 15842: loss: 0.078604, loss_s1: 0.049729, loss_fp: 0.004302, loss_freq: 0.033864
[17:22:10.142] iteration 15843: loss: 0.048938, loss_s1: 0.024654, loss_fp: 0.001685, loss_freq: 0.030999
[17:22:10.782] iteration 15844: loss: 0.108134, loss_s1: 0.046776, loss_fp: 0.020308, loss_freq: 0.089593
[17:22:11.418] iteration 15845: loss: 0.108444, loss_s1: 0.089904, loss_fp: 0.005883, loss_freq: 0.066222
[17:22:12.051] iteration 15846: loss: 0.054668, loss_s1: 0.030820, loss_fp: 0.015451, loss_freq: 0.033224
[17:22:12.685] iteration 15847: loss: 0.040881, loss_s1: 0.026122, loss_fp: 0.001546, loss_freq: 0.017999
[17:22:13.322] iteration 15848: loss: 0.061753, loss_s1: 0.009379, loss_fp: 0.007811, loss_freq: 0.031860
[17:22:13.967] iteration 15849: loss: 0.036841, loss_s1: 0.026326, loss_fp: 0.003938, loss_freq: 0.010109
[17:22:14.605] iteration 15850: loss: 0.053464, loss_s1: 0.023960, loss_fp: 0.004912, loss_freq: 0.039555
[17:22:15.245] iteration 15851: loss: 0.064172, loss_s1: 0.041180, loss_fp: 0.009360, loss_freq: 0.023359
[17:22:15.891] iteration 15852: loss: 0.040801, loss_s1: 0.025449, loss_fp: 0.002386, loss_freq: 0.008546
[17:22:16.529] iteration 15853: loss: 0.075179, loss_s1: 0.074949, loss_fp: 0.003973, loss_freq: 0.033315
[17:22:17.173] iteration 15854: loss: 0.098502, loss_s1: 0.108808, loss_fp: 0.002589, loss_freq: 0.046507
[17:22:17.811] iteration 15855: loss: 0.053688, loss_s1: 0.015793, loss_fp: 0.008633, loss_freq: 0.033552
[17:22:18.452] iteration 15856: loss: 0.044745, loss_s1: 0.027505, loss_fp: 0.002849, loss_freq: 0.017812
[17:22:19.097] iteration 15857: loss: 0.042786, loss_s1: 0.028876, loss_fp: 0.003034, loss_freq: 0.015729
[17:22:19.736] iteration 15858: loss: 0.058741, loss_s1: 0.062132, loss_fp: 0.001794, loss_freq: 0.015376
[17:22:20.378] iteration 15859: loss: 0.035224, loss_s1: 0.009397, loss_fp: 0.000808, loss_freq: 0.010702
[17:22:21.018] iteration 15860: loss: 0.083537, loss_s1: 0.101358, loss_fp: 0.002541, loss_freq: 0.032441
[17:22:21.659] iteration 15861: loss: 0.084110, loss_s1: 0.042650, loss_fp: 0.008475, loss_freq: 0.083882
[17:22:22.307] iteration 15862: loss: 0.076160, loss_s1: 0.069448, loss_fp: 0.001254, loss_freq: 0.026206
[17:22:22.952] iteration 15863: loss: 0.095998, loss_s1: 0.071095, loss_fp: 0.005673, loss_freq: 0.086241
[17:22:23.590] iteration 15864: loss: 0.065741, loss_s1: 0.064854, loss_fp: 0.002625, loss_freq: 0.028000
[17:22:24.228] iteration 15865: loss: 0.054151, loss_s1: 0.032097, loss_fp: 0.003676, loss_freq: 0.027320
[17:22:24.873] iteration 15866: loss: 0.058079, loss_s1: 0.055205, loss_fp: 0.001613, loss_freq: 0.011772
[17:22:25.516] iteration 15867: loss: 0.060183, loss_s1: 0.046022, loss_fp: 0.004886, loss_freq: 0.028767
[17:22:26.150] iteration 15868: loss: 0.086719, loss_s1: 0.054975, loss_fp: 0.006666, loss_freq: 0.049907
[17:22:26.786] iteration 15869: loss: 0.077663, loss_s1: 0.049248, loss_fp: 0.002954, loss_freq: 0.050988
[17:22:27.448] iteration 15870: loss: 0.061538, loss_s1: 0.026038, loss_fp: 0.004364, loss_freq: 0.034318
[17:22:28.106] iteration 15871: loss: 0.058638, loss_s1: 0.035274, loss_fp: 0.000694, loss_freq: 0.010547
[17:22:28.767] iteration 15872: loss: 0.038804, loss_s1: 0.017430, loss_fp: 0.000609, loss_freq: 0.012548
[17:22:29.411] iteration 15873: loss: 0.064594, loss_s1: 0.056959, loss_fp: 0.007160, loss_freq: 0.030807
[17:22:30.037] iteration 15874: loss: 0.045766, loss_s1: 0.037135, loss_fp: 0.004202, loss_freq: 0.010448
[17:22:30.665] iteration 15875: loss: 0.041119, loss_s1: 0.019904, loss_fp: 0.002982, loss_freq: 0.019664
[17:22:31.293] iteration 15876: loss: 0.072610, loss_s1: 0.047703, loss_fp: 0.000564, loss_freq: 0.044789
[17:22:31.919] iteration 15877: loss: 0.082157, loss_s1: 0.048398, loss_fp: 0.002728, loss_freq: 0.054609
[17:22:32.550] iteration 15878: loss: 0.059058, loss_s1: 0.048351, loss_fp: 0.003152, loss_freq: 0.024425
[17:22:33.180] iteration 15879: loss: 0.051419, loss_s1: 0.033460, loss_fp: 0.004466, loss_freq: 0.028309
[17:22:33.803] iteration 15880: loss: 0.120989, loss_s1: 0.056048, loss_fp: 0.018732, loss_freq: 0.077970
[17:22:34.431] iteration 15881: loss: 0.107661, loss_s1: 0.087658, loss_fp: 0.005481, loss_freq: 0.062617
[17:22:35.103] iteration 15882: loss: 0.076895, loss_s1: 0.073282, loss_fp: 0.004584, loss_freq: 0.042761
[17:22:35.728] iteration 15883: loss: 0.071069, loss_s1: 0.041091, loss_fp: 0.001345, loss_freq: 0.025875
[17:22:36.350] iteration 15884: loss: 0.058693, loss_s1: 0.035399, loss_fp: 0.001436, loss_freq: 0.044048
[17:22:37.031] iteration 15885: loss: 0.068903, loss_s1: 0.031101, loss_fp: 0.004868, loss_freq: 0.013401
[17:22:37.691] iteration 15886: loss: 0.129739, loss_s1: 0.145754, loss_fp: 0.001993, loss_freq: 0.066049
[17:22:38.361] iteration 15887: loss: 0.083547, loss_s1: 0.030147, loss_fp: 0.007451, loss_freq: 0.057960
[17:22:39.028] iteration 15888: loss: 0.044017, loss_s1: 0.023807, loss_fp: 0.001082, loss_freq: 0.032357
[17:22:39.693] iteration 15889: loss: 0.051144, loss_s1: 0.032321, loss_fp: 0.004132, loss_freq: 0.013687
[17:22:40.358] iteration 15890: loss: 0.054729, loss_s1: 0.042163, loss_fp: 0.003108, loss_freq: 0.022900
[17:22:40.989] iteration 15891: loss: 0.035018, loss_s1: 0.019596, loss_fp: 0.001350, loss_freq: 0.018892
[17:22:41.615] iteration 15892: loss: 0.057075, loss_s1: 0.025344, loss_fp: 0.002438, loss_freq: 0.041495
[17:22:42.246] iteration 15893: loss: 0.055386, loss_s1: 0.028988, loss_fp: 0.002016, loss_freq: 0.005914
[17:22:42.868] iteration 15894: loss: 0.107748, loss_s1: 0.081803, loss_fp: 0.006188, loss_freq: 0.078760
[17:22:43.494] iteration 15895: loss: 0.068611, loss_s1: 0.057042, loss_fp: 0.003576, loss_freq: 0.030414
[17:22:44.121] iteration 15896: loss: 0.054980, loss_s1: 0.046834, loss_fp: 0.002989, loss_freq: 0.024677
[17:22:44.746] iteration 15897: loss: 0.072719, loss_s1: 0.047050, loss_fp: 0.005784, loss_freq: 0.035949
[17:22:45.366] iteration 15898: loss: 0.094633, loss_s1: 0.075667, loss_fp: 0.002957, loss_freq: 0.049744
[17:22:45.991] iteration 15899: loss: 0.067861, loss_s1: 0.074907, loss_fp: 0.002283, loss_freq: 0.020819
[17:22:46.631] iteration 15900: loss: 0.086942, loss_s1: 0.032237, loss_fp: 0.002761, loss_freq: 0.035845
[17:22:47.263] iteration 15901: loss: 0.091987, loss_s1: 0.121758, loss_fp: 0.004268, loss_freq: 0.012337
[17:22:47.888] iteration 15902: loss: 0.043237, loss_s1: 0.023859, loss_fp: 0.001274, loss_freq: 0.017605
[17:22:48.519] iteration 15903: loss: 0.064782, loss_s1: 0.032841, loss_fp: 0.007178, loss_freq: 0.034946
[17:22:49.143] iteration 15904: loss: 0.088604, loss_s1: 0.084526, loss_fp: 0.005811, loss_freq: 0.038410
[17:22:49.768] iteration 15905: loss: 0.039909, loss_s1: 0.026695, loss_fp: 0.002723, loss_freq: 0.006751
[17:22:50.396] iteration 15906: loss: 0.100032, loss_s1: 0.042682, loss_fp: 0.006497, loss_freq: 0.029440
[17:22:51.024] iteration 15907: loss: 0.081195, loss_s1: 0.089112, loss_fp: 0.005444, loss_freq: 0.021415
[17:22:51.652] iteration 15908: loss: 0.050904, loss_s1: 0.055628, loss_fp: 0.005448, loss_freq: 0.006206
[17:22:52.287] iteration 15909: loss: 0.126904, loss_s1: 0.058385, loss_fp: 0.012773, loss_freq: 0.094329
[17:22:52.915] iteration 15910: loss: 0.084154, loss_s1: 0.080120, loss_fp: 0.007745, loss_freq: 0.042814
[17:22:53.540] iteration 15911: loss: 0.067083, loss_s1: 0.055585, loss_fp: 0.002669, loss_freq: 0.010365
[17:22:54.163] iteration 15912: loss: 0.048495, loss_s1: 0.026365, loss_fp: 0.001689, loss_freq: 0.017996
[17:22:54.788] iteration 15913: loss: 0.060638, loss_s1: 0.048999, loss_fp: 0.006088, loss_freq: 0.025495
[17:22:55.412] iteration 15914: loss: 0.048638, loss_s1: 0.043744, loss_fp: 0.001889, loss_freq: 0.018207
[17:22:56.035] iteration 15915: loss: 0.046990, loss_s1: 0.031075, loss_fp: 0.001308, loss_freq: 0.016316
[17:22:56.669] iteration 15916: loss: 0.042949, loss_s1: 0.024025, loss_fp: 0.000842, loss_freq: 0.025003
[17:22:57.296] iteration 15917: loss: 0.049750, loss_s1: 0.027894, loss_fp: 0.002200, loss_freq: 0.014840
[17:22:57.921] iteration 15918: loss: 0.081990, loss_s1: 0.059654, loss_fp: 0.007134, loss_freq: 0.042135
[17:22:58.553] iteration 15919: loss: 0.055948, loss_s1: 0.048460, loss_fp: 0.004554, loss_freq: 0.023701
[17:22:59.178] iteration 15920: loss: 0.054834, loss_s1: 0.041900, loss_fp: 0.000882, loss_freq: 0.021729
[17:22:59.809] iteration 15921: loss: 0.053667, loss_s1: 0.036356, loss_fp: 0.005390, loss_freq: 0.025349
[17:23:00.439] iteration 15922: loss: 0.101819, loss_s1: 0.101686, loss_fp: 0.012683, loss_freq: 0.029437
[17:23:01.072] iteration 15923: loss: 0.047449, loss_s1: 0.030139, loss_fp: 0.003483, loss_freq: 0.016211
[17:23:01.698] iteration 15924: loss: 0.050911, loss_s1: 0.031896, loss_fp: 0.005200, loss_freq: 0.011873
[17:23:02.333] iteration 15925: loss: 0.078894, loss_s1: 0.062393, loss_fp: 0.002234, loss_freq: 0.057750
[17:23:02.959] iteration 15926: loss: 0.048991, loss_s1: 0.042238, loss_fp: 0.002270, loss_freq: 0.016866
[17:23:03.587] iteration 15927: loss: 0.040758, loss_s1: 0.017813, loss_fp: 0.002776, loss_freq: 0.020854
[17:23:04.213] iteration 15928: loss: 0.143493, loss_s1: 0.084157, loss_fp: 0.005002, loss_freq: 0.076296
[17:23:04.842] iteration 15929: loss: 0.062191, loss_s1: 0.033589, loss_fp: 0.001337, loss_freq: 0.033011
[17:23:05.471] iteration 15930: loss: 0.110331, loss_s1: 0.104410, loss_fp: 0.009578, loss_freq: 0.070929
[17:23:06.094] iteration 15931: loss: 0.053692, loss_s1: 0.041573, loss_fp: 0.004394, loss_freq: 0.016372
[17:23:06.718] iteration 15932: loss: 0.077540, loss_s1: 0.061913, loss_fp: 0.011336, loss_freq: 0.021829
[17:23:07.357] iteration 15933: loss: 0.034577, loss_s1: 0.026748, loss_fp: 0.001021, loss_freq: 0.009164
[17:23:07.984] iteration 15934: loss: 0.049650, loss_s1: 0.032698, loss_fp: 0.001567, loss_freq: 0.017897
[17:23:08.616] iteration 15935: loss: 0.076254, loss_s1: 0.035572, loss_fp: 0.002193, loss_freq: 0.023232
[17:23:09.238] iteration 15936: loss: 0.078730, loss_s1: 0.037269, loss_fp: 0.001440, loss_freq: 0.067721
[17:23:09.863] iteration 15937: loss: 0.082177, loss_s1: 0.066542, loss_fp: 0.006226, loss_freq: 0.040548
[17:23:10.493] iteration 15938: loss: 0.047137, loss_s1: 0.015787, loss_fp: 0.003628, loss_freq: 0.016972
[17:23:11.115] iteration 15939: loss: 0.042028, loss_s1: 0.028915, loss_fp: 0.000877, loss_freq: 0.006344
[17:23:12.061] iteration 15940: loss: 0.064778, loss_s1: 0.047846, loss_fp: 0.002825, loss_freq: 0.035397
[17:23:12.691] iteration 15941: loss: 0.099233, loss_s1: 0.119583, loss_fp: 0.006308, loss_freq: 0.036919
[17:23:13.316] iteration 15942: loss: 0.050270, loss_s1: 0.030015, loss_fp: 0.001984, loss_freq: 0.010805
[17:23:13.940] iteration 15943: loss: 0.039414, loss_s1: 0.017268, loss_fp: 0.000376, loss_freq: 0.015689
[17:23:14.566] iteration 15944: loss: 0.063285, loss_s1: 0.035789, loss_fp: 0.001194, loss_freq: 0.031148
[17:23:15.192] iteration 15945: loss: 0.158025, loss_s1: 0.086204, loss_fp: 0.003066, loss_freq: 0.107408
[17:23:15.816] iteration 15946: loss: 0.031446, loss_s1: 0.015649, loss_fp: 0.001876, loss_freq: 0.015701
[17:23:16.448] iteration 15947: loss: 0.053010, loss_s1: 0.042577, loss_fp: 0.005640, loss_freq: 0.025677
[17:23:17.071] iteration 15948: loss: 0.070668, loss_s1: 0.072532, loss_fp: 0.003188, loss_freq: 0.027348
[17:23:17.696] iteration 15949: loss: 0.096523, loss_s1: 0.129218, loss_fp: 0.007837, loss_freq: 0.015516
[17:23:18.323] iteration 15950: loss: 0.039969, loss_s1: 0.019963, loss_fp: 0.010482, loss_freq: 0.008361
[17:23:18.958] iteration 15951: loss: 0.061204, loss_s1: 0.061016, loss_fp: 0.002739, loss_freq: 0.021101
[17:23:19.583] iteration 15952: loss: 0.101341, loss_s1: 0.074570, loss_fp: 0.005165, loss_freq: 0.091056
[17:23:20.202] iteration 15953: loss: 0.081104, loss_s1: 0.038806, loss_fp: 0.001232, loss_freq: 0.029609
[17:23:20.831] iteration 15954: loss: 0.064541, loss_s1: 0.031409, loss_fp: 0.008261, loss_freq: 0.038375
[17:23:21.457] iteration 15955: loss: 0.113965, loss_s1: 0.114733, loss_fp: 0.001208, loss_freq: 0.068556
[17:23:22.087] iteration 15956: loss: 0.060187, loss_s1: 0.047759, loss_fp: 0.002821, loss_freq: 0.013799
[17:23:22.726] iteration 15957: loss: 0.089948, loss_s1: 0.067916, loss_fp: 0.004908, loss_freq: 0.049835
[17:23:23.353] iteration 15958: loss: 0.067001, loss_s1: 0.053936, loss_fp: 0.002729, loss_freq: 0.031401
[17:23:23.982] iteration 15959: loss: 0.063510, loss_s1: 0.047515, loss_fp: 0.013955, loss_freq: 0.025075
[17:23:24.614] iteration 15960: loss: 0.073833, loss_s1: 0.091578, loss_fp: 0.004206, loss_freq: 0.008367
[17:23:25.243] iteration 15961: loss: 0.053195, loss_s1: 0.040066, loss_fp: 0.001618, loss_freq: 0.014958
[17:23:25.871] iteration 15962: loss: 0.074147, loss_s1: 0.043615, loss_fp: 0.001237, loss_freq: 0.018473
[17:23:26.501] iteration 15963: loss: 0.097470, loss_s1: 0.061035, loss_fp: 0.016938, loss_freq: 0.070470
[17:23:27.128] iteration 15964: loss: 0.058704, loss_s1: 0.030335, loss_fp: 0.004125, loss_freq: 0.034214
[17:23:27.754] iteration 15965: loss: 0.098468, loss_s1: 0.075193, loss_fp: 0.014771, loss_freq: 0.063211
[17:23:28.381] iteration 15966: loss: 0.042937, loss_s1: 0.008523, loss_fp: 0.000263, loss_freq: 0.032353
[17:23:29.014] iteration 15967: loss: 0.081025, loss_s1: 0.065161, loss_fp: 0.008725, loss_freq: 0.030488
[17:23:29.639] iteration 15968: loss: 0.092001, loss_s1: 0.100165, loss_fp: 0.003386, loss_freq: 0.038261
[17:23:30.268] iteration 15969: loss: 0.040881, loss_s1: 0.026793, loss_fp: 0.000683, loss_freq: 0.008547
[17:23:30.899] iteration 15970: loss: 0.076634, loss_s1: 0.091287, loss_fp: 0.001108, loss_freq: 0.016803
[17:23:31.527] iteration 15971: loss: 0.045450, loss_s1: 0.018702, loss_fp: 0.002229, loss_freq: 0.008438
[17:23:32.152] iteration 15972: loss: 0.060643, loss_s1: 0.042212, loss_fp: 0.002628, loss_freq: 0.038876
[17:23:32.784] iteration 15973: loss: 0.039976, loss_s1: 0.028529, loss_fp: 0.000850, loss_freq: 0.013715
[17:23:33.408] iteration 15974: loss: 0.053149, loss_s1: 0.030148, loss_fp: 0.001531, loss_freq: 0.020258
[17:23:34.034] iteration 15975: loss: 0.060998, loss_s1: 0.055759, loss_fp: 0.006302, loss_freq: 0.025675
[17:23:34.665] iteration 15976: loss: 0.091028, loss_s1: 0.097241, loss_fp: 0.006708, loss_freq: 0.025562
[17:23:35.297] iteration 15977: loss: 0.082032, loss_s1: 0.047374, loss_fp: 0.004494, loss_freq: 0.030013
[17:23:35.920] iteration 15978: loss: 0.066843, loss_s1: 0.043074, loss_fp: 0.006392, loss_freq: 0.031915
[17:23:36.541] iteration 15979: loss: 0.074963, loss_s1: 0.080676, loss_fp: 0.001180, loss_freq: 0.029123
[17:23:37.166] iteration 15980: loss: 0.055223, loss_s1: 0.041511, loss_fp: 0.001106, loss_freq: 0.018075
[17:23:37.790] iteration 15981: loss: 0.089274, loss_s1: 0.087198, loss_fp: 0.002005, loss_freq: 0.058581
[17:23:38.410] iteration 15982: loss: 0.077485, loss_s1: 0.058336, loss_fp: 0.003948, loss_freq: 0.052890
[17:23:39.036] iteration 15983: loss: 0.054262, loss_s1: 0.028440, loss_fp: 0.001233, loss_freq: 0.040684
[17:23:39.661] iteration 15984: loss: 0.061477, loss_s1: 0.058537, loss_fp: 0.004305, loss_freq: 0.022577
[17:23:40.286] iteration 15985: loss: 0.050547, loss_s1: 0.050572, loss_fp: 0.001435, loss_freq: 0.006496
[17:23:40.913] iteration 15986: loss: 0.031300, loss_s1: 0.015319, loss_fp: 0.002352, loss_freq: 0.008959
[17:23:41.535] iteration 15987: loss: 0.042903, loss_s1: 0.033113, loss_fp: 0.003507, loss_freq: 0.017068
[17:23:42.159] iteration 15988: loss: 0.057650, loss_s1: 0.036998, loss_fp: 0.005122, loss_freq: 0.025431
[17:23:42.789] iteration 15989: loss: 0.049331, loss_s1: 0.028879, loss_fp: 0.000684, loss_freq: 0.034135
[17:23:43.411] iteration 15990: loss: 0.072287, loss_s1: 0.054877, loss_fp: 0.005590, loss_freq: 0.040558
[17:23:44.033] iteration 15991: loss: 0.047090, loss_s1: 0.031225, loss_fp: 0.001589, loss_freq: 0.011933
[17:23:44.655] iteration 15992: loss: 0.058978, loss_s1: 0.057150, loss_fp: 0.001894, loss_freq: 0.012827
[17:23:45.316] iteration 15993: loss: 0.068465, loss_s1: 0.027592, loss_fp: 0.002600, loss_freq: 0.049514
[17:23:45.977] iteration 15994: loss: 0.044533, loss_s1: 0.016125, loss_fp: 0.000890, loss_freq: 0.007840
[17:23:46.639] iteration 15995: loss: 0.067485, loss_s1: 0.038687, loss_fp: 0.006847, loss_freq: 0.031451
[17:23:47.298] iteration 15996: loss: 0.046037, loss_s1: 0.022098, loss_fp: 0.001676, loss_freq: 0.026927
[17:23:47.924] iteration 15997: loss: 0.045709, loss_s1: 0.014661, loss_fp: 0.001727, loss_freq: 0.017476
[17:23:48.548] iteration 15998: loss: 0.038562, loss_s1: 0.019010, loss_fp: 0.001024, loss_freq: 0.008083
[17:23:49.174] iteration 15999: loss: 0.047772, loss_s1: 0.033889, loss_fp: 0.001449, loss_freq: 0.031308
[17:23:49.799] iteration 16000: loss: 0.050519, loss_s1: 0.014633, loss_fp: 0.003085, loss_freq: 0.027273
[17:23:53.164] iteration 16000 : mean_dice : 0.718571
[17:23:53.814] iteration 16001: loss: 0.072151, loss_s1: 0.082620, loss_fp: 0.004384, loss_freq: 0.018918
[17:23:54.434] iteration 16002: loss: 0.048934, loss_s1: 0.036579, loss_fp: 0.002065, loss_freq: 0.015115
[17:23:55.054] iteration 16003: loss: 0.050103, loss_s1: 0.032544, loss_fp: 0.000608, loss_freq: 0.019002
[17:23:55.676] iteration 16004: loss: 0.046480, loss_s1: 0.018946, loss_fp: 0.012660, loss_freq: 0.023602
[17:23:56.296] iteration 16005: loss: 0.082737, loss_s1: 0.050735, loss_fp: 0.005246, loss_freq: 0.073499
[17:23:56.914] iteration 16006: loss: 0.055076, loss_s1: 0.026860, loss_fp: 0.001514, loss_freq: 0.038798
[17:23:57.533] iteration 16007: loss: 0.077021, loss_s1: 0.069190, loss_fp: 0.002096, loss_freq: 0.048264
[17:23:58.157] iteration 16008: loss: 0.058390, loss_s1: 0.042736, loss_fp: 0.005014, loss_freq: 0.030435
[17:23:58.777] iteration 16009: loss: 0.104792, loss_s1: 0.117540, loss_fp: 0.001885, loss_freq: 0.027206
[17:23:59.400] iteration 16010: loss: 0.071954, loss_s1: 0.045342, loss_fp: 0.007723, loss_freq: 0.038509
[17:24:00.025] iteration 16011: loss: 0.052385, loss_s1: 0.012881, loss_fp: 0.001195, loss_freq: 0.035291
[17:24:00.646] iteration 16012: loss: 0.071319, loss_s1: 0.065852, loss_fp: 0.000631, loss_freq: 0.026454
[17:24:01.265] iteration 16013: loss: 0.058932, loss_s1: 0.065502, loss_fp: 0.002866, loss_freq: 0.009554
[17:24:01.885] iteration 16014: loss: 0.053229, loss_s1: 0.051734, loss_fp: 0.003069, loss_freq: 0.021173
[17:24:02.505] iteration 16015: loss: 0.045032, loss_s1: 0.043160, loss_fp: 0.001546, loss_freq: 0.005145
[17:24:03.125] iteration 16016: loss: 0.073811, loss_s1: 0.076246, loss_fp: 0.002519, loss_freq: 0.035817
[17:24:03.746] iteration 16017: loss: 0.041934, loss_s1: 0.033979, loss_fp: 0.002363, loss_freq: 0.011798
[17:24:04.365] iteration 16018: loss: 0.030996, loss_s1: 0.018560, loss_fp: 0.001255, loss_freq: 0.007825
[17:24:04.986] iteration 16019: loss: 0.059283, loss_s1: 0.032722, loss_fp: 0.008220, loss_freq: 0.035535
[17:24:05.617] iteration 16020: loss: 0.067416, loss_s1: 0.032487, loss_fp: 0.008968, loss_freq: 0.056840
[17:24:06.243] iteration 16021: loss: 0.071612, loss_s1: 0.047549, loss_fp: 0.008882, loss_freq: 0.043640
[17:24:06.867] iteration 16022: loss: 0.051809, loss_s1: 0.043021, loss_fp: 0.002168, loss_freq: 0.022844
[17:24:07.490] iteration 16023: loss: 0.056331, loss_s1: 0.038988, loss_fp: 0.022324, loss_freq: 0.012432
[17:24:08.108] iteration 16024: loss: 0.090659, loss_s1: 0.079392, loss_fp: 0.003009, loss_freq: 0.047374
[17:24:08.728] iteration 16025: loss: 0.058201, loss_s1: 0.068444, loss_fp: 0.000686, loss_freq: 0.009937
[17:24:09.349] iteration 16026: loss: 0.062373, loss_s1: 0.061297, loss_fp: 0.004041, loss_freq: 0.013258
[17:24:09.967] iteration 16027: loss: 0.040015, loss_s1: 0.025596, loss_fp: 0.004945, loss_freq: 0.013899
[17:24:10.640] iteration 16028: loss: 0.078850, loss_s1: 0.033636, loss_fp: 0.009111, loss_freq: 0.070192
[17:24:11.267] iteration 16029: loss: 0.072188, loss_s1: 0.045613, loss_fp: 0.004095, loss_freq: 0.055843
[17:24:11.892] iteration 16030: loss: 0.057669, loss_s1: 0.034949, loss_fp: 0.005402, loss_freq: 0.032120
[17:24:12.515] iteration 16031: loss: 0.056982, loss_s1: 0.049699, loss_fp: 0.003805, loss_freq: 0.018192
[17:24:13.137] iteration 16032: loss: 0.059901, loss_s1: 0.016738, loss_fp: 0.000566, loss_freq: 0.009265
[17:24:13.761] iteration 16033: loss: 0.053912, loss_s1: 0.046908, loss_fp: 0.000328, loss_freq: 0.024321
[17:24:14.387] iteration 16034: loss: 0.042040, loss_s1: 0.031310, loss_fp: 0.003781, loss_freq: 0.015181
[17:24:15.011] iteration 16035: loss: 0.050119, loss_s1: 0.032151, loss_fp: 0.004329, loss_freq: 0.024457
[17:24:15.636] iteration 16036: loss: 0.053579, loss_s1: 0.023613, loss_fp: 0.003851, loss_freq: 0.015927
[17:24:16.265] iteration 16037: loss: 0.055912, loss_s1: 0.013364, loss_fp: 0.001233, loss_freq: 0.046888
[17:24:16.890] iteration 16038: loss: 0.057243, loss_s1: 0.069697, loss_fp: 0.001843, loss_freq: 0.005192
[17:24:17.517] iteration 16039: loss: 0.086419, loss_s1: 0.106245, loss_fp: 0.001759, loss_freq: 0.029224
[17:24:18.142] iteration 16040: loss: 0.090913, loss_s1: 0.094857, loss_fp: 0.004976, loss_freq: 0.038723
[17:24:18.770] iteration 16041: loss: 0.087862, loss_s1: 0.048856, loss_fp: 0.003709, loss_freq: 0.063587
[17:24:19.393] iteration 16042: loss: 0.072979, loss_s1: 0.045300, loss_fp: 0.003520, loss_freq: 0.052350
[17:24:20.025] iteration 16043: loss: 0.059228, loss_s1: 0.059594, loss_fp: 0.002058, loss_freq: 0.011633
[17:24:20.651] iteration 16044: loss: 0.056331, loss_s1: 0.032814, loss_fp: 0.002016, loss_freq: 0.016094
[17:24:21.275] iteration 16045: loss: 0.054983, loss_s1: 0.031744, loss_fp: 0.002664, loss_freq: 0.042393
[17:24:21.931] iteration 16046: loss: 0.047383, loss_s1: 0.030348, loss_fp: 0.003605, loss_freq: 0.015052
[17:24:22.592] iteration 16047: loss: 0.075752, loss_s1: 0.060186, loss_fp: 0.002815, loss_freq: 0.031920
[17:24:23.252] iteration 16048: loss: 0.135868, loss_s1: 0.142005, loss_fp: 0.014062, loss_freq: 0.072791
[17:24:23.913] iteration 16049: loss: 0.075705, loss_s1: 0.094106, loss_fp: 0.002532, loss_freq: 0.017249
[17:24:24.573] iteration 16050: loss: 0.068469, loss_s1: 0.043439, loss_fp: 0.001938, loss_freq: 0.021328
[17:24:25.218] iteration 16051: loss: 0.067130, loss_s1: 0.052687, loss_fp: 0.005792, loss_freq: 0.041550
[17:24:25.838] iteration 16052: loss: 0.059451, loss_s1: 0.049781, loss_fp: 0.003970, loss_freq: 0.027221
[17:24:26.464] iteration 16053: loss: 0.061985, loss_s1: 0.027580, loss_fp: 0.004022, loss_freq: 0.037736
[17:24:27.091] iteration 16054: loss: 0.037223, loss_s1: 0.015404, loss_fp: 0.001499, loss_freq: 0.011073
[17:24:27.717] iteration 16055: loss: 0.145595, loss_s1: 0.106331, loss_fp: 0.007708, loss_freq: 0.126660
[17:24:28.343] iteration 16056: loss: 0.043250, loss_s1: 0.011747, loss_fp: 0.008114, loss_freq: 0.017760
[17:24:28.969] iteration 16057: loss: 0.067768, loss_s1: 0.020928, loss_fp: 0.000842, loss_freq: 0.016596
[17:24:29.596] iteration 16058: loss: 0.090732, loss_s1: 0.071021, loss_fp: 0.004633, loss_freq: 0.066511
[17:24:30.222] iteration 16059: loss: 0.117513, loss_s1: 0.090698, loss_fp: 0.004025, loss_freq: 0.107118
[17:24:30.849] iteration 16060: loss: 0.042454, loss_s1: 0.024454, loss_fp: 0.001847, loss_freq: 0.024536
[17:24:31.505] iteration 16061: loss: 0.083573, loss_s1: 0.041356, loss_fp: 0.005771, loss_freq: 0.044835
[17:24:32.163] iteration 16062: loss: 0.070996, loss_s1: 0.072453, loss_fp: 0.003153, loss_freq: 0.016967
[17:24:32.820] iteration 16063: loss: 0.072639, loss_s1: 0.082772, loss_fp: 0.001412, loss_freq: 0.003462
[17:24:33.475] iteration 16064: loss: 0.056112, loss_s1: 0.022182, loss_fp: 0.004448, loss_freq: 0.035157
[17:24:34.133] iteration 16065: loss: 0.041434, loss_s1: 0.017203, loss_fp: 0.002174, loss_freq: 0.022449
[17:24:34.778] iteration 16066: loss: 0.073993, loss_s1: 0.077265, loss_fp: 0.003476, loss_freq: 0.021771
[17:24:35.405] iteration 16067: loss: 0.092611, loss_s1: 0.070792, loss_fp: 0.013694, loss_freq: 0.038123
[17:24:36.031] iteration 16068: loss: 0.061633, loss_s1: 0.043756, loss_fp: 0.009314, loss_freq: 0.029670
[17:24:36.655] iteration 16069: loss: 0.046471, loss_s1: 0.041797, loss_fp: 0.001613, loss_freq: 0.012299
[17:24:37.280] iteration 16070: loss: 0.094159, loss_s1: 0.078059, loss_fp: 0.008990, loss_freq: 0.071082
[17:24:37.905] iteration 16071: loss: 0.079558, loss_s1: 0.083508, loss_fp: 0.003339, loss_freq: 0.032005
[17:24:38.535] iteration 16072: loss: 0.099828, loss_s1: 0.095304, loss_fp: 0.012145, loss_freq: 0.054496
[17:24:39.160] iteration 16073: loss: 0.064873, loss_s1: 0.053369, loss_fp: 0.006774, loss_freq: 0.027225
[17:24:39.777] iteration 16074: loss: 0.066608, loss_s1: 0.051923, loss_fp: 0.003508, loss_freq: 0.035832
[17:24:40.408] iteration 16075: loss: 0.031908, loss_s1: 0.016561, loss_fp: 0.002162, loss_freq: 0.015797
[17:24:41.035] iteration 16076: loss: 0.047410, loss_s1: 0.033389, loss_fp: 0.000639, loss_freq: 0.014249
[17:24:41.657] iteration 16077: loss: 0.043686, loss_s1: 0.023494, loss_fp: 0.009831, loss_freq: 0.018784
[17:24:42.374] iteration 16078: loss: 0.048725, loss_s1: 0.028002, loss_fp: 0.004388, loss_freq: 0.011764
[17:24:43.039] iteration 16079: loss: 0.063843, loss_s1: 0.033990, loss_fp: 0.005363, loss_freq: 0.030256
[17:24:43.704] iteration 16080: loss: 0.067127, loss_s1: 0.057671, loss_fp: 0.002700, loss_freq: 0.033518
[17:24:44.385] iteration 16081: loss: 0.049311, loss_s1: 0.034248, loss_fp: 0.001837, loss_freq: 0.018657
[17:24:45.062] iteration 16082: loss: 0.081010, loss_s1: 0.086133, loss_fp: 0.001111, loss_freq: 0.022261
[17:24:45.731] iteration 16083: loss: 0.056726, loss_s1: 0.028437, loss_fp: 0.011797, loss_freq: 0.018218
[17:24:46.353] iteration 16084: loss: 0.062614, loss_s1: 0.053867, loss_fp: 0.002917, loss_freq: 0.012983
[17:24:46.977] iteration 16085: loss: 0.061603, loss_s1: 0.055587, loss_fp: 0.001966, loss_freq: 0.015779
[17:24:47.600] iteration 16086: loss: 0.069953, loss_s1: 0.045217, loss_fp: 0.004565, loss_freq: 0.055471
[17:24:48.229] iteration 16087: loss: 0.046528, loss_s1: 0.022136, loss_fp: 0.000839, loss_freq: 0.023206
[17:24:48.860] iteration 16088: loss: 0.084880, loss_s1: 0.087503, loss_fp: 0.001301, loss_freq: 0.042956
[17:24:49.484] iteration 16089: loss: 0.086061, loss_s1: 0.053181, loss_fp: 0.001813, loss_freq: 0.061414
[17:24:50.107] iteration 16090: loss: 0.062803, loss_s1: 0.046263, loss_fp: 0.002032, loss_freq: 0.017872
[17:24:50.735] iteration 16091: loss: 0.087728, loss_s1: 0.050097, loss_fp: 0.009057, loss_freq: 0.054994
[17:24:51.357] iteration 16092: loss: 0.031804, loss_s1: 0.014618, loss_fp: 0.001760, loss_freq: 0.014551
[17:24:51.982] iteration 16093: loss: 0.058343, loss_s1: 0.045386, loss_fp: 0.005064, loss_freq: 0.027366
[17:24:52.635] iteration 16094: loss: 0.038624, loss_s1: 0.013022, loss_fp: 0.000473, loss_freq: 0.020583
[17:24:53.298] iteration 16095: loss: 0.037340, loss_s1: 0.020764, loss_fp: 0.001372, loss_freq: 0.011309
[17:24:53.961] iteration 16096: loss: 0.054969, loss_s1: 0.047638, loss_fp: 0.000650, loss_freq: 0.016704
[17:24:54.621] iteration 16097: loss: 0.066132, loss_s1: 0.049825, loss_fp: 0.000394, loss_freq: 0.032026
[17:24:55.250] iteration 16098: loss: 0.061086, loss_s1: 0.041441, loss_fp: 0.022728, loss_freq: 0.017255
[17:24:55.875] iteration 16099: loss: 0.045932, loss_s1: 0.023987, loss_fp: 0.001060, loss_freq: 0.016746
[17:24:56.497] iteration 16100: loss: 0.078112, loss_s1: 0.063119, loss_fp: 0.000655, loss_freq: 0.047093
[17:24:57.485] iteration 16101: loss: 0.046550, loss_s1: 0.024996, loss_fp: 0.002696, loss_freq: 0.015759
[17:24:58.109] iteration 16102: loss: 0.069904, loss_s1: 0.036075, loss_fp: 0.003516, loss_freq: 0.040314
[17:24:58.734] iteration 16103: loss: 0.051188, loss_s1: 0.035118, loss_fp: 0.001402, loss_freq: 0.020172
[17:24:59.363] iteration 16104: loss: 0.040821, loss_s1: 0.014260, loss_fp: 0.003183, loss_freq: 0.018013
[17:24:59.986] iteration 16105: loss: 0.061703, loss_s1: 0.037993, loss_fp: 0.002834, loss_freq: 0.035960
[17:25:00.643] iteration 16106: loss: 0.174425, loss_s1: 0.171405, loss_fp: 0.010475, loss_freq: 0.054533
[17:25:01.288] iteration 16107: loss: 0.043969, loss_s1: 0.036151, loss_fp: 0.002377, loss_freq: 0.016602
[17:25:01.909] iteration 16108: loss: 0.034769, loss_s1: 0.023093, loss_fp: 0.001300, loss_freq: 0.012989
[17:25:02.532] iteration 16109: loss: 0.056903, loss_s1: 0.029745, loss_fp: 0.001421, loss_freq: 0.038592
[17:25:03.158] iteration 16110: loss: 0.102337, loss_s1: 0.111729, loss_fp: 0.009720, loss_freq: 0.041591
[17:25:03.783] iteration 16111: loss: 0.048871, loss_s1: 0.021150, loss_fp: 0.001985, loss_freq: 0.026023
[17:25:04.414] iteration 16112: loss: 0.066673, loss_s1: 0.058042, loss_fp: 0.004647, loss_freq: 0.035217
[17:25:05.036] iteration 16113: loss: 0.066487, loss_s1: 0.030138, loss_fp: 0.003561, loss_freq: 0.065546
[17:25:05.660] iteration 16114: loss: 0.048415, loss_s1: 0.019554, loss_fp: 0.003659, loss_freq: 0.027648
[17:25:06.286] iteration 16115: loss: 0.063203, loss_s1: 0.063762, loss_fp: 0.002240, loss_freq: 0.025352
[17:25:06.910] iteration 16116: loss: 0.068148, loss_s1: 0.067649, loss_fp: 0.005937, loss_freq: 0.020852
[17:25:07.544] iteration 16117: loss: 0.057612, loss_s1: 0.056423, loss_fp: 0.000865, loss_freq: 0.011701
[17:25:08.168] iteration 16118: loss: 0.058854, loss_s1: 0.020692, loss_fp: 0.005263, loss_freq: 0.042954
[17:25:08.795] iteration 16119: loss: 0.037592, loss_s1: 0.015985, loss_fp: 0.001866, loss_freq: 0.017513
[17:25:09.421] iteration 16120: loss: 0.052166, loss_s1: 0.041345, loss_fp: 0.004922, loss_freq: 0.018920
[17:25:10.045] iteration 16121: loss: 0.043646, loss_s1: 0.014242, loss_fp: 0.000687, loss_freq: 0.008385
[17:25:10.667] iteration 16122: loss: 0.066443, loss_s1: 0.073021, loss_fp: 0.001518, loss_freq: 0.015964
[17:25:11.289] iteration 16123: loss: 0.050922, loss_s1: 0.023658, loss_fp: 0.001545, loss_freq: 0.018178
[17:25:11.914] iteration 16124: loss: 0.209803, loss_s1: 0.161540, loss_fp: 0.016684, loss_freq: 0.203133
[17:25:12.542] iteration 16125: loss: 0.040273, loss_s1: 0.029829, loss_fp: 0.001355, loss_freq: 0.017794
[17:25:13.169] iteration 16126: loss: 0.096275, loss_s1: 0.087058, loss_fp: 0.016781, loss_freq: 0.043251
[17:25:13.796] iteration 16127: loss: 0.030242, loss_s1: 0.011718, loss_fp: 0.005435, loss_freq: 0.007414
[17:25:14.419] iteration 16128: loss: 0.123262, loss_s1: 0.128803, loss_fp: 0.019757, loss_freq: 0.056883
[17:25:15.043] iteration 16129: loss: 0.078996, loss_s1: 0.071905, loss_fp: 0.010867, loss_freq: 0.039652
[17:25:15.667] iteration 16130: loss: 0.041348, loss_s1: 0.028873, loss_fp: 0.002794, loss_freq: 0.012266
[17:25:16.291] iteration 16131: loss: 0.039355, loss_s1: 0.032743, loss_fp: 0.001178, loss_freq: 0.010816
[17:25:16.913] iteration 16132: loss: 0.082662, loss_s1: 0.040004, loss_fp: 0.004038, loss_freq: 0.010484
[17:25:17.540] iteration 16133: loss: 0.049324, loss_s1: 0.041173, loss_fp: 0.002207, loss_freq: 0.014967
[17:25:18.161] iteration 16134: loss: 0.042804, loss_s1: 0.040242, loss_fp: 0.000891, loss_freq: 0.008398
[17:25:18.782] iteration 16135: loss: 0.070389, loss_s1: 0.042699, loss_fp: 0.002017, loss_freq: 0.029426
[17:25:19.405] iteration 16136: loss: 0.063235, loss_s1: 0.049354, loss_fp: 0.006236, loss_freq: 0.038218
[17:25:20.033] iteration 16137: loss: 0.099502, loss_s1: 0.056758, loss_fp: 0.004247, loss_freq: 0.062035
[17:25:20.659] iteration 16138: loss: 0.080042, loss_s1: 0.054513, loss_fp: 0.008842, loss_freq: 0.034591
[17:25:21.291] iteration 16139: loss: 0.094601, loss_s1: 0.075567, loss_fp: 0.001543, loss_freq: 0.063236
[17:25:21.915] iteration 16140: loss: 0.090924, loss_s1: 0.074858, loss_fp: 0.010992, loss_freq: 0.031098
[17:25:22.540] iteration 16141: loss: 0.065067, loss_s1: 0.040245, loss_fp: 0.016643, loss_freq: 0.017149
[17:25:23.171] iteration 16142: loss: 0.067883, loss_s1: 0.053713, loss_fp: 0.007321, loss_freq: 0.034545
[17:25:23.796] iteration 16143: loss: 0.111548, loss_s1: 0.062839, loss_fp: 0.027006, loss_freq: 0.084284
[17:25:24.421] iteration 16144: loss: 0.050507, loss_s1: 0.018723, loss_fp: 0.003917, loss_freq: 0.027994
[17:25:25.044] iteration 16145: loss: 0.093895, loss_s1: 0.032293, loss_fp: 0.013667, loss_freq: 0.043977
[17:25:25.668] iteration 16146: loss: 0.064480, loss_s1: 0.046947, loss_fp: 0.001162, loss_freq: 0.011191
[17:25:26.291] iteration 16147: loss: 0.044392, loss_s1: 0.030685, loss_fp: 0.002359, loss_freq: 0.008139
[17:25:26.915] iteration 16148: loss: 0.064079, loss_s1: 0.076516, loss_fp: 0.001680, loss_freq: 0.017490
[17:25:27.539] iteration 16149: loss: 0.092486, loss_s1: 0.083664, loss_fp: 0.001600, loss_freq: 0.009902
[17:25:28.160] iteration 16150: loss: 0.058506, loss_s1: 0.048729, loss_fp: 0.001335, loss_freq: 0.028365
[17:25:28.783] iteration 16151: loss: 0.074011, loss_s1: 0.059634, loss_fp: 0.005772, loss_freq: 0.050668
[17:25:29.406] iteration 16152: loss: 0.065741, loss_s1: 0.034449, loss_fp: 0.023507, loss_freq: 0.022036
[17:25:30.026] iteration 16153: loss: 0.046973, loss_s1: 0.024733, loss_fp: 0.000790, loss_freq: 0.032660
[17:25:30.647] iteration 16154: loss: 0.052042, loss_s1: 0.024304, loss_fp: 0.000856, loss_freq: 0.028287
[17:25:31.273] iteration 16155: loss: 0.078931, loss_s1: 0.046728, loss_fp: 0.001444, loss_freq: 0.016806
[17:25:31.900] iteration 16156: loss: 0.077814, loss_s1: 0.089663, loss_fp: 0.001593, loss_freq: 0.019372
[17:25:32.522] iteration 16157: loss: 0.053325, loss_s1: 0.033813, loss_fp: 0.004288, loss_freq: 0.008422
[17:25:33.145] iteration 16158: loss: 0.097567, loss_s1: 0.053298, loss_fp: 0.006107, loss_freq: 0.028695
[17:25:33.767] iteration 16159: loss: 0.053844, loss_s1: 0.046470, loss_fp: 0.004196, loss_freq: 0.007156
[17:25:34.396] iteration 16160: loss: 0.042882, loss_s1: 0.020137, loss_fp: 0.001190, loss_freq: 0.024208
[17:25:35.022] iteration 16161: loss: 0.052431, loss_s1: 0.043964, loss_fp: 0.001724, loss_freq: 0.020813
[17:25:35.645] iteration 16162: loss: 0.058315, loss_s1: 0.042986, loss_fp: 0.003487, loss_freq: 0.022171
[17:25:36.264] iteration 16163: loss: 0.072641, loss_s1: 0.042896, loss_fp: 0.003284, loss_freq: 0.037958
[17:25:36.885] iteration 16164: loss: 0.085900, loss_s1: 0.080783, loss_fp: 0.004116, loss_freq: 0.024638
[17:25:37.507] iteration 16165: loss: 0.044966, loss_s1: 0.030866, loss_fp: 0.005215, loss_freq: 0.007834
[17:25:38.128] iteration 16166: loss: 0.070539, loss_s1: 0.038264, loss_fp: 0.002716, loss_freq: 0.063212
[17:25:38.752] iteration 16167: loss: 0.080104, loss_s1: 0.031033, loss_fp: 0.002460, loss_freq: 0.044081
[17:25:39.381] iteration 16168: loss: 0.053885, loss_s1: 0.051728, loss_fp: 0.003508, loss_freq: 0.022698
[17:25:40.004] iteration 16169: loss: 0.048096, loss_s1: 0.032561, loss_fp: 0.000611, loss_freq: 0.024044
[17:25:40.629] iteration 16170: loss: 0.061648, loss_s1: 0.033700, loss_fp: 0.001191, loss_freq: 0.031950
[17:25:41.252] iteration 16171: loss: 0.086752, loss_s1: 0.080055, loss_fp: 0.003516, loss_freq: 0.047188
[17:25:41.877] iteration 16172: loss: 0.053692, loss_s1: 0.031680, loss_fp: 0.001759, loss_freq: 0.031465
[17:25:42.503] iteration 16173: loss: 0.059878, loss_s1: 0.056628, loss_fp: 0.001604, loss_freq: 0.014509
[17:25:43.128] iteration 16174: loss: 0.051752, loss_s1: 0.037447, loss_fp: 0.003102, loss_freq: 0.019653
[17:25:43.751] iteration 16175: loss: 0.102246, loss_s1: 0.117421, loss_fp: 0.000966, loss_freq: 0.046650
[17:25:44.375] iteration 16176: loss: 0.071798, loss_s1: 0.057364, loss_fp: 0.002536, loss_freq: 0.027917
[17:25:44.998] iteration 16177: loss: 0.078276, loss_s1: 0.054604, loss_fp: 0.000504, loss_freq: 0.054178
[17:25:45.624] iteration 16178: loss: 0.057303, loss_s1: 0.040193, loss_fp: 0.011257, loss_freq: 0.031055
[17:25:46.250] iteration 16179: loss: 0.050649, loss_s1: 0.041271, loss_fp: 0.015593, loss_freq: 0.003891
[17:25:46.875] iteration 16180: loss: 0.065845, loss_s1: 0.039132, loss_fp: 0.004702, loss_freq: 0.041774
[17:25:47.499] iteration 16181: loss: 0.070366, loss_s1: 0.087155, loss_fp: 0.006623, loss_freq: 0.013266
[17:25:48.118] iteration 16182: loss: 0.092765, loss_s1: 0.105332, loss_fp: 0.003615, loss_freq: 0.045713
[17:25:48.746] iteration 16183: loss: 0.100852, loss_s1: 0.077844, loss_fp: 0.009750, loss_freq: 0.082798
[17:25:49.370] iteration 16184: loss: 0.080194, loss_s1: 0.073327, loss_fp: 0.003150, loss_freq: 0.031959
[17:25:49.994] iteration 16185: loss: 0.086152, loss_s1: 0.082916, loss_fp: 0.011040, loss_freq: 0.032844
[17:25:50.619] iteration 16186: loss: 0.034776, loss_s1: 0.014665, loss_fp: 0.009800, loss_freq: 0.013844
[17:25:51.248] iteration 16187: loss: 0.066710, loss_s1: 0.063667, loss_fp: 0.002484, loss_freq: 0.019624
[17:25:51.871] iteration 16188: loss: 0.048124, loss_s1: 0.030210, loss_fp: 0.000649, loss_freq: 0.012904
[17:25:52.496] iteration 16189: loss: 0.067631, loss_s1: 0.026778, loss_fp: 0.006731, loss_freq: 0.024565
[17:25:53.124] iteration 16190: loss: 0.077355, loss_s1: 0.072810, loss_fp: 0.001531, loss_freq: 0.027495
[17:25:53.786] iteration 16191: loss: 0.063601, loss_s1: 0.027446, loss_fp: 0.001886, loss_freq: 0.021764
[17:25:54.445] iteration 16192: loss: 0.074322, loss_s1: 0.048481, loss_fp: 0.001915, loss_freq: 0.012771
[17:25:55.101] iteration 16193: loss: 0.061399, loss_s1: 0.029199, loss_fp: 0.003431, loss_freq: 0.017956
[17:25:55.733] iteration 16194: loss: 0.037909, loss_s1: 0.015729, loss_fp: 0.002038, loss_freq: 0.009844
[17:25:56.359] iteration 16195: loss: 0.046388, loss_s1: 0.017001, loss_fp: 0.001099, loss_freq: 0.028382
[17:25:56.986] iteration 16196: loss: 0.035284, loss_s1: 0.013966, loss_fp: 0.004409, loss_freq: 0.019034
[17:25:57.608] iteration 16197: loss: 0.050313, loss_s1: 0.030474, loss_fp: 0.000451, loss_freq: 0.018255
[17:25:58.235] iteration 16198: loss: 0.053440, loss_s1: 0.008544, loss_fp: 0.002275, loss_freq: 0.036866
[17:25:58.861] iteration 16199: loss: 0.036883, loss_s1: 0.024069, loss_fp: 0.001072, loss_freq: 0.012309
[17:25:59.485] iteration 16200: loss: 0.054094, loss_s1: 0.049952, loss_fp: 0.007414, loss_freq: 0.016032
[17:26:02.952] iteration 16200 : mean_dice : 0.724121
[17:26:03.606] iteration 16201: loss: 0.071841, loss_s1: 0.061109, loss_fp: 0.005177, loss_freq: 0.022238
[17:26:04.228] iteration 16202: loss: 0.076878, loss_s1: 0.046408, loss_fp: 0.003701, loss_freq: 0.058058
[17:26:04.852] iteration 16203: loss: 0.095843, loss_s1: 0.087808, loss_fp: 0.003143, loss_freq: 0.043957
[17:26:05.474] iteration 16204: loss: 0.082365, loss_s1: 0.076662, loss_fp: 0.005201, loss_freq: 0.047933
[17:26:06.103] iteration 16205: loss: 0.071759, loss_s1: 0.042365, loss_fp: 0.003926, loss_freq: 0.027719
[17:26:06.726] iteration 16206: loss: 0.060425, loss_s1: 0.041454, loss_fp: 0.001722, loss_freq: 0.029662
[17:26:07.353] iteration 16207: loss: 0.040808, loss_s1: 0.020768, loss_fp: 0.000433, loss_freq: 0.006395
[17:26:07.976] iteration 16208: loss: 0.080906, loss_s1: 0.058804, loss_fp: 0.002063, loss_freq: 0.045346
[17:26:08.600] iteration 16209: loss: 0.148090, loss_s1: 0.123085, loss_fp: 0.007831, loss_freq: 0.090740
[17:26:09.224] iteration 16210: loss: 0.108902, loss_s1: 0.128895, loss_fp: 0.002848, loss_freq: 0.048386
[17:26:09.846] iteration 16211: loss: 0.049456, loss_s1: 0.014619, loss_fp: 0.009676, loss_freq: 0.026525
[17:26:10.463] iteration 16212: loss: 0.065225, loss_s1: 0.034718, loss_fp: 0.002364, loss_freq: 0.056070
[17:26:11.086] iteration 16213: loss: 0.061109, loss_s1: 0.040542, loss_fp: 0.005685, loss_freq: 0.023639
[17:26:11.711] iteration 16214: loss: 0.052354, loss_s1: 0.047080, loss_fp: 0.003861, loss_freq: 0.018843
[17:26:12.335] iteration 16215: loss: 0.043284, loss_s1: 0.030916, loss_fp: 0.002721, loss_freq: 0.010666
[17:26:12.959] iteration 16216: loss: 0.068181, loss_s1: 0.053390, loss_fp: 0.004007, loss_freq: 0.041187
[17:26:13.583] iteration 16217: loss: 0.065224, loss_s1: 0.043169, loss_fp: 0.001316, loss_freq: 0.043238
[17:26:14.207] iteration 16218: loss: 0.045249, loss_s1: 0.034445, loss_fp: 0.001882, loss_freq: 0.018617
[17:26:14.830] iteration 16219: loss: 0.087677, loss_s1: 0.064310, loss_fp: 0.001168, loss_freq: 0.065871
[17:26:15.452] iteration 16220: loss: 0.104276, loss_s1: 0.075556, loss_fp: 0.001753, loss_freq: 0.094752
[17:26:16.080] iteration 16221: loss: 0.073351, loss_s1: 0.012540, loss_fp: 0.010125, loss_freq: 0.088132
[17:26:16.706] iteration 16222: loss: 0.067293, loss_s1: 0.059063, loss_fp: 0.008527, loss_freq: 0.024331
[17:26:17.334] iteration 16223: loss: 0.092153, loss_s1: 0.095775, loss_fp: 0.001389, loss_freq: 0.039446
[17:26:17.954] iteration 16224: loss: 0.077984, loss_s1: 0.076759, loss_fp: 0.001214, loss_freq: 0.016699
[17:26:18.577] iteration 16225: loss: 0.060384, loss_s1: 0.034192, loss_fp: 0.002604, loss_freq: 0.032773
[17:26:19.202] iteration 16226: loss: 0.062806, loss_s1: 0.042794, loss_fp: 0.001164, loss_freq: 0.031296
[17:26:19.824] iteration 16227: loss: 0.052225, loss_s1: 0.031339, loss_fp: 0.004473, loss_freq: 0.013973
[17:26:20.444] iteration 16228: loss: 0.082993, loss_s1: 0.041367, loss_fp: 0.000355, loss_freq: 0.009968
[17:26:21.067] iteration 16229: loss: 0.070896, loss_s1: 0.067261, loss_fp: 0.006160, loss_freq: 0.030233
[17:26:21.691] iteration 16230: loss: 0.036425, loss_s1: 0.017412, loss_fp: 0.001839, loss_freq: 0.015492
[17:26:22.314] iteration 16231: loss: 0.093912, loss_s1: 0.044092, loss_fp: 0.012683, loss_freq: 0.094911
[17:26:22.938] iteration 16232: loss: 0.070316, loss_s1: 0.090185, loss_fp: 0.001346, loss_freq: 0.013686
[17:26:23.562] iteration 16233: loss: 0.042874, loss_s1: 0.024277, loss_fp: 0.001536, loss_freq: 0.013676
[17:26:24.185] iteration 16234: loss: 0.068124, loss_s1: 0.070110, loss_fp: 0.002459, loss_freq: 0.017557
[17:26:24.808] iteration 16235: loss: 0.081784, loss_s1: 0.058901, loss_fp: 0.006435, loss_freq: 0.048087
[17:26:25.426] iteration 16236: loss: 0.052768, loss_s1: 0.043985, loss_fp: 0.005747, loss_freq: 0.021298
[17:26:26.048] iteration 16237: loss: 0.051139, loss_s1: 0.024327, loss_fp: 0.000804, loss_freq: 0.011133
[17:26:26.671] iteration 16238: loss: 0.044381, loss_s1: 0.018275, loss_fp: 0.001126, loss_freq: 0.033427
[17:26:27.296] iteration 16239: loss: 0.052951, loss_s1: 0.031384, loss_fp: 0.007558, loss_freq: 0.014117
[17:26:27.923] iteration 16240: loss: 0.080211, loss_s1: 0.046922, loss_fp: 0.007998, loss_freq: 0.021503
[17:26:28.549] iteration 16241: loss: 0.067684, loss_s1: 0.053104, loss_fp: 0.011625, loss_freq: 0.025656
[17:26:29.175] iteration 16242: loss: 0.053008, loss_s1: 0.042780, loss_fp: 0.003308, loss_freq: 0.016352
[17:26:29.799] iteration 16243: loss: 0.083051, loss_s1: 0.078528, loss_fp: 0.002364, loss_freq: 0.037579
[17:26:30.426] iteration 16244: loss: 0.063940, loss_s1: 0.045064, loss_fp: 0.009301, loss_freq: 0.024949
[17:26:31.051] iteration 16245: loss: 0.046949, loss_s1: 0.032939, loss_fp: 0.001757, loss_freq: 0.012400
[17:26:31.718] iteration 16246: loss: 0.085165, loss_s1: 0.064068, loss_fp: 0.006837, loss_freq: 0.045679
[17:26:32.342] iteration 16247: loss: 0.085950, loss_s1: 0.057382, loss_fp: 0.004542, loss_freq: 0.074828
[17:26:32.968] iteration 16248: loss: 0.045170, loss_s1: 0.033977, loss_fp: 0.002202, loss_freq: 0.014193
[17:26:33.595] iteration 16249: loss: 0.053608, loss_s1: 0.027834, loss_fp: 0.011573, loss_freq: 0.023538
[17:26:34.246] iteration 16250: loss: 0.077943, loss_s1: 0.052180, loss_fp: 0.000634, loss_freq: 0.060492
[17:26:34.920] iteration 16251: loss: 0.066496, loss_s1: 0.045956, loss_fp: 0.007760, loss_freq: 0.022120
[17:26:35.567] iteration 16252: loss: 0.067302, loss_s1: 0.052809, loss_fp: 0.002970, loss_freq: 0.031642
[17:26:36.206] iteration 16253: loss: 0.049733, loss_s1: 0.035922, loss_fp: 0.003784, loss_freq: 0.023085
[17:26:36.849] iteration 16254: loss: 0.066873, loss_s1: 0.034276, loss_fp: 0.007114, loss_freq: 0.023918
[17:26:37.484] iteration 16255: loss: 0.038782, loss_s1: 0.029385, loss_fp: 0.002375, loss_freq: 0.016410
[17:26:38.121] iteration 16256: loss: 0.075481, loss_s1: 0.079112, loss_fp: 0.002935, loss_freq: 0.022613
[17:26:38.757] iteration 16257: loss: 0.043604, loss_s1: 0.027531, loss_fp: 0.000715, loss_freq: 0.008517
[17:26:39.394] iteration 16258: loss: 0.070511, loss_s1: 0.044707, loss_fp: 0.001250, loss_freq: 0.049108
[17:26:40.031] iteration 16259: loss: 0.087468, loss_s1: 0.066899, loss_fp: 0.004410, loss_freq: 0.055251
[17:26:40.652] iteration 16260: loss: 0.047633, loss_s1: 0.053257, loss_fp: 0.001533, loss_freq: 0.008848
[17:26:41.275] iteration 16261: loss: 0.078194, loss_s1: 0.061972, loss_fp: 0.000391, loss_freq: 0.037018
[17:26:42.257] iteration 16262: loss: 0.049056, loss_s1: 0.050119, loss_fp: 0.002725, loss_freq: 0.005574
[17:26:42.904] iteration 16263: loss: 0.090374, loss_s1: 0.102505, loss_fp: 0.005030, loss_freq: 0.026624
[17:26:43.533] iteration 16264: loss: 0.053017, loss_s1: 0.033871, loss_fp: 0.001403, loss_freq: 0.019988
[17:26:44.229] iteration 16265: loss: 0.036977, loss_s1: 0.014935, loss_fp: 0.000848, loss_freq: 0.017793
[17:26:44.899] iteration 16266: loss: 0.050611, loss_s1: 0.043533, loss_fp: 0.004136, loss_freq: 0.013902
[17:26:45.565] iteration 16267: loss: 0.131756, loss_s1: 0.111268, loss_fp: 0.007736, loss_freq: 0.061678
[17:26:46.223] iteration 16268: loss: 0.040596, loss_s1: 0.038840, loss_fp: 0.000715, loss_freq: 0.009091
[17:26:46.872] iteration 16269: loss: 0.034903, loss_s1: 0.025881, loss_fp: 0.001082, loss_freq: 0.011880
[17:26:47.502] iteration 16270: loss: 0.097044, loss_s1: 0.063480, loss_fp: 0.008455, loss_freq: 0.069067
[17:26:48.136] iteration 16271: loss: 0.058457, loss_s1: 0.055661, loss_fp: 0.006371, loss_freq: 0.016827
[17:26:48.773] iteration 16272: loss: 0.045225, loss_s1: 0.035174, loss_fp: 0.000971, loss_freq: 0.013953
[17:26:49.407] iteration 16273: loss: 0.051932, loss_s1: 0.045793, loss_fp: 0.001590, loss_freq: 0.024150
[17:26:50.046] iteration 16274: loss: 0.079111, loss_s1: 0.068111, loss_fp: 0.004920, loss_freq: 0.055879
[17:26:50.736] iteration 16275: loss: 0.075629, loss_s1: 0.051219, loss_fp: 0.001411, loss_freq: 0.049414
[17:26:51.363] iteration 16276: loss: 0.047778, loss_s1: 0.050806, loss_fp: 0.003088, loss_freq: 0.004397
[17:26:51.988] iteration 16277: loss: 0.106590, loss_s1: 0.081877, loss_fp: 0.007283, loss_freq: 0.079177
[17:26:52.614] iteration 16278: loss: 0.047130, loss_s1: 0.037898, loss_fp: 0.000758, loss_freq: 0.012492
[17:26:53.238] iteration 16279: loss: 0.059803, loss_s1: 0.037350, loss_fp: 0.005087, loss_freq: 0.033090
[17:26:53.867] iteration 16280: loss: 0.057213, loss_s1: 0.044748, loss_fp: 0.001217, loss_freq: 0.029331
[17:26:54.492] iteration 16281: loss: 0.081592, loss_s1: 0.054664, loss_fp: 0.001004, loss_freq: 0.047715
[17:26:55.125] iteration 16282: loss: 0.059965, loss_s1: 0.046895, loss_fp: 0.002408, loss_freq: 0.018717
[17:26:55.757] iteration 16283: loss: 0.048262, loss_s1: 0.020066, loss_fp: 0.003917, loss_freq: 0.026094
[17:26:56.386] iteration 16284: loss: 0.067611, loss_s1: 0.026775, loss_fp: 0.001327, loss_freq: 0.011352
[17:26:57.007] iteration 16285: loss: 0.088839, loss_s1: 0.055833, loss_fp: 0.004572, loss_freq: 0.077464
[17:26:57.636] iteration 16286: loss: 0.044172, loss_s1: 0.027877, loss_fp: 0.001276, loss_freq: 0.032091
[17:26:58.267] iteration 16287: loss: 0.068070, loss_s1: 0.028497, loss_fp: 0.002964, loss_freq: 0.070330
[17:26:58.892] iteration 16288: loss: 0.031410, loss_s1: 0.020557, loss_fp: 0.000239, loss_freq: 0.001994
[17:26:59.521] iteration 16289: loss: 0.090650, loss_s1: 0.085158, loss_fp: 0.005525, loss_freq: 0.037084
[17:27:00.145] iteration 16290: loss: 0.086581, loss_s1: 0.073268, loss_fp: 0.002959, loss_freq: 0.025975
[17:27:00.769] iteration 16291: loss: 0.040111, loss_s1: 0.032147, loss_fp: 0.001564, loss_freq: 0.011131
[17:27:01.397] iteration 16292: loss: 0.052838, loss_s1: 0.063319, loss_fp: 0.000566, loss_freq: 0.009743
[17:27:02.037] iteration 16293: loss: 0.077442, loss_s1: 0.060476, loss_fp: 0.001123, loss_freq: 0.049342
[17:27:02.663] iteration 16294: loss: 0.052191, loss_s1: 0.029262, loss_fp: 0.000937, loss_freq: 0.038825
[17:27:03.291] iteration 16295: loss: 0.041842, loss_s1: 0.035645, loss_fp: 0.002598, loss_freq: 0.013006
[17:27:03.915] iteration 16296: loss: 0.072987, loss_s1: 0.034130, loss_fp: 0.001871, loss_freq: 0.026601
[17:27:04.538] iteration 16297: loss: 0.057687, loss_s1: 0.025111, loss_fp: 0.002185, loss_freq: 0.038057
[17:27:05.163] iteration 16298: loss: 0.092232, loss_s1: 0.092725, loss_fp: 0.002105, loss_freq: 0.048212
[17:27:05.787] iteration 16299: loss: 0.056018, loss_s1: 0.024465, loss_fp: 0.004994, loss_freq: 0.032444
[17:27:06.412] iteration 16300: loss: 0.093100, loss_s1: 0.106350, loss_fp: 0.000474, loss_freq: 0.037008
[17:27:07.039] iteration 16301: loss: 0.058662, loss_s1: 0.041363, loss_fp: 0.001649, loss_freq: 0.033260
[17:27:07.662] iteration 16302: loss: 0.044246, loss_s1: 0.016567, loss_fp: 0.002392, loss_freq: 0.020789
[17:27:08.289] iteration 16303: loss: 0.064099, loss_s1: 0.066196, loss_fp: 0.001308, loss_freq: 0.029802
[17:27:08.917] iteration 16304: loss: 0.062186, loss_s1: 0.040121, loss_fp: 0.001285, loss_freq: 0.035410
[17:27:09.541] iteration 16305: loss: 0.062791, loss_s1: 0.055144, loss_fp: 0.002896, loss_freq: 0.036703
[17:27:10.163] iteration 16306: loss: 0.062781, loss_s1: 0.043872, loss_fp: 0.005846, loss_freq: 0.038759
[17:27:10.789] iteration 16307: loss: 0.047468, loss_s1: 0.041030, loss_fp: 0.002496, loss_freq: 0.008371
[17:27:11.411] iteration 16308: loss: 0.040497, loss_s1: 0.031124, loss_fp: 0.002549, loss_freq: 0.009054
[17:27:12.036] iteration 16309: loss: 0.036129, loss_s1: 0.023554, loss_fp: 0.001293, loss_freq: 0.016015
[17:27:12.660] iteration 16310: loss: 0.085037, loss_s1: 0.078498, loss_fp: 0.000556, loss_freq: 0.026863
[17:27:13.288] iteration 16311: loss: 0.056149, loss_s1: 0.033044, loss_fp: 0.000588, loss_freq: 0.047791
[17:27:13.910] iteration 16312: loss: 0.073914, loss_s1: 0.039698, loss_fp: 0.002240, loss_freq: 0.053563
[17:27:14.537] iteration 16313: loss: 0.051226, loss_s1: 0.019472, loss_fp: 0.003103, loss_freq: 0.022536
[17:27:15.192] iteration 16314: loss: 0.054034, loss_s1: 0.020979, loss_fp: 0.002306, loss_freq: 0.038952
[17:27:15.856] iteration 16315: loss: 0.075078, loss_s1: 0.038862, loss_fp: 0.004841, loss_freq: 0.053157
[17:27:16.513] iteration 16316: loss: 0.040728, loss_s1: 0.028779, loss_fp: 0.001177, loss_freq: 0.010402
[17:27:17.165] iteration 16317: loss: 0.071004, loss_s1: 0.048572, loss_fp: 0.016563, loss_freq: 0.030934
[17:27:17.798] iteration 16318: loss: 0.038701, loss_s1: 0.021313, loss_fp: 0.003831, loss_freq: 0.007099
[17:27:18.423] iteration 16319: loss: 0.057263, loss_s1: 0.036210, loss_fp: 0.001541, loss_freq: 0.022500
[17:27:19.047] iteration 16320: loss: 0.035278, loss_s1: 0.013739, loss_fp: 0.003822, loss_freq: 0.017107
[17:27:19.680] iteration 16321: loss: 0.060707, loss_s1: 0.055661, loss_fp: 0.004348, loss_freq: 0.025453
[17:27:20.308] iteration 16322: loss: 0.048925, loss_s1: 0.015740, loss_fp: 0.003018, loss_freq: 0.033742
[17:27:20.935] iteration 16323: loss: 0.037691, loss_s1: 0.022048, loss_fp: 0.001809, loss_freq: 0.013325
[17:27:21.564] iteration 16324: loss: 0.057655, loss_s1: 0.050323, loss_fp: 0.002656, loss_freq: 0.014221
[17:27:22.190] iteration 16325: loss: 0.056334, loss_s1: 0.029097, loss_fp: 0.000996, loss_freq: 0.042997
[17:27:22.813] iteration 16326: loss: 0.036018, loss_s1: 0.025135, loss_fp: 0.002546, loss_freq: 0.008943
[17:27:23.438] iteration 16327: loss: 0.068783, loss_s1: 0.045724, loss_fp: 0.009940, loss_freq: 0.050292
[17:27:24.062] iteration 16328: loss: 0.071430, loss_s1: 0.044537, loss_fp: 0.004644, loss_freq: 0.047654
[17:27:24.686] iteration 16329: loss: 0.069161, loss_s1: 0.045473, loss_fp: 0.002139, loss_freq: 0.051589
[17:27:25.311] iteration 16330: loss: 0.050133, loss_s1: 0.020960, loss_fp: 0.003994, loss_freq: 0.027023
[17:27:25.938] iteration 16331: loss: 0.074357, loss_s1: 0.058350, loss_fp: 0.001319, loss_freq: 0.042194
[17:27:26.560] iteration 16332: loss: 0.065714, loss_s1: 0.044436, loss_fp: 0.009443, loss_freq: 0.047528
[17:27:27.186] iteration 16333: loss: 0.055419, loss_s1: 0.044925, loss_fp: 0.006303, loss_freq: 0.018944
[17:27:27.813] iteration 16334: loss: 0.074865, loss_s1: 0.045640, loss_fp: 0.002047, loss_freq: 0.057850
[17:27:28.439] iteration 16335: loss: 0.040109, loss_s1: 0.012656, loss_fp: 0.004761, loss_freq: 0.012508
[17:27:29.060] iteration 16336: loss: 0.067740, loss_s1: 0.065870, loss_fp: 0.003938, loss_freq: 0.032349
[17:27:29.690] iteration 16337: loss: 0.081892, loss_s1: 0.039387, loss_fp: 0.002615, loss_freq: 0.059255
[17:27:30.318] iteration 16338: loss: 0.080287, loss_s1: 0.059315, loss_fp: 0.005455, loss_freq: 0.059171
[17:27:30.943] iteration 16339: loss: 0.041561, loss_s1: 0.031504, loss_fp: 0.001734, loss_freq: 0.011423
[17:27:31.567] iteration 16340: loss: 0.049944, loss_s1: 0.048196, loss_fp: 0.001386, loss_freq: 0.016164
[17:27:32.191] iteration 16341: loss: 0.050183, loss_s1: 0.039986, loss_fp: 0.000830, loss_freq: 0.017490
[17:27:32.817] iteration 16342: loss: 0.099921, loss_s1: 0.046917, loss_fp: 0.006259, loss_freq: 0.085979
[17:27:33.443] iteration 16343: loss: 0.109660, loss_s1: 0.120836, loss_fp: 0.013322, loss_freq: 0.055933
[17:27:34.064] iteration 16344: loss: 0.044721, loss_s1: 0.032881, loss_fp: 0.004981, loss_freq: 0.018481
[17:27:34.690] iteration 16345: loss: 0.075432, loss_s1: 0.077708, loss_fp: 0.010705, loss_freq: 0.017020
[17:27:35.318] iteration 16346: loss: 0.082562, loss_s1: 0.059515, loss_fp: 0.005847, loss_freq: 0.068866
[17:27:35.944] iteration 16347: loss: 0.059420, loss_s1: 0.051146, loss_fp: 0.002088, loss_freq: 0.024301
[17:27:36.571] iteration 16348: loss: 0.062503, loss_s1: 0.054523, loss_fp: 0.001852, loss_freq: 0.018624
[17:27:37.196] iteration 16349: loss: 0.039657, loss_s1: 0.021512, loss_fp: 0.001596, loss_freq: 0.010402
[17:27:37.818] iteration 16350: loss: 0.086084, loss_s1: 0.088857, loss_fp: 0.001188, loss_freq: 0.043544
[17:27:38.443] iteration 16351: loss: 0.055280, loss_s1: 0.028595, loss_fp: 0.003089, loss_freq: 0.027543
[17:27:39.071] iteration 16352: loss: 0.068206, loss_s1: 0.036271, loss_fp: 0.008487, loss_freq: 0.011194
[17:27:39.700] iteration 16353: loss: 0.066833, loss_s1: 0.062100, loss_fp: 0.007252, loss_freq: 0.018861
[17:27:40.335] iteration 16354: loss: 0.052086, loss_s1: 0.015879, loss_fp: 0.003794, loss_freq: 0.023824
[17:27:40.992] iteration 16355: loss: 0.044839, loss_s1: 0.022620, loss_fp: 0.000900, loss_freq: 0.025591
[17:27:41.657] iteration 16356: loss: 0.066837, loss_s1: 0.080207, loss_fp: 0.001179, loss_freq: 0.014084
[17:27:42.327] iteration 16357: loss: 0.043412, loss_s1: 0.025478, loss_fp: 0.001042, loss_freq: 0.017485
[17:27:42.987] iteration 16358: loss: 0.048884, loss_s1: 0.024118, loss_fp: 0.002569, loss_freq: 0.019276
[17:27:43.646] iteration 16359: loss: 0.055683, loss_s1: 0.028931, loss_fp: 0.001194, loss_freq: 0.024942
[17:27:44.286] iteration 16360: loss: 0.067818, loss_s1: 0.041261, loss_fp: 0.001275, loss_freq: 0.048397
[17:27:44.908] iteration 16361: loss: 0.041246, loss_s1: 0.025816, loss_fp: 0.002572, loss_freq: 0.015361
[17:27:45.534] iteration 16362: loss: 0.055706, loss_s1: 0.032969, loss_fp: 0.003755, loss_freq: 0.036257
[17:27:46.161] iteration 16363: loss: 0.081172, loss_s1: 0.039745, loss_fp: 0.001491, loss_freq: 0.047494
[17:27:46.791] iteration 16364: loss: 0.087590, loss_s1: 0.042124, loss_fp: 0.006016, loss_freq: 0.083509
[17:27:47.418] iteration 16365: loss: 0.064938, loss_s1: 0.062965, loss_fp: 0.002288, loss_freq: 0.014487
[17:27:48.041] iteration 16366: loss: 0.061330, loss_s1: 0.032229, loss_fp: 0.001944, loss_freq: 0.014686
[17:27:48.665] iteration 16367: loss: 0.043680, loss_s1: 0.036315, loss_fp: 0.002898, loss_freq: 0.013115
[17:27:49.292] iteration 16368: loss: 0.060648, loss_s1: 0.041327, loss_fp: 0.003979, loss_freq: 0.020175
[17:27:49.917] iteration 16369: loss: 0.076572, loss_s1: 0.057649, loss_fp: 0.001169, loss_freq: 0.054695
[17:27:50.541] iteration 16370: loss: 0.092469, loss_s1: 0.055996, loss_fp: 0.001811, loss_freq: 0.087028
[17:27:51.172] iteration 16371: loss: 0.069545, loss_s1: 0.071469, loss_fp: 0.001147, loss_freq: 0.019152
[17:27:51.800] iteration 16372: loss: 0.035757, loss_s1: 0.017509, loss_fp: 0.002051, loss_freq: 0.010338
[17:27:52.426] iteration 16373: loss: 0.056551, loss_s1: 0.035808, loss_fp: 0.004941, loss_freq: 0.037881
[17:27:53.049] iteration 16374: loss: 0.107967, loss_s1: 0.077592, loss_fp: 0.003711, loss_freq: 0.081192
[17:27:53.676] iteration 16375: loss: 0.050923, loss_s1: 0.040012, loss_fp: 0.005922, loss_freq: 0.016179
[17:27:54.304] iteration 16376: loss: 0.044647, loss_s1: 0.030082, loss_fp: 0.004481, loss_freq: 0.006973
[17:27:54.927] iteration 16377: loss: 0.066691, loss_s1: 0.032333, loss_fp: 0.003819, loss_freq: 0.036408
[17:27:55.550] iteration 16378: loss: 0.043980, loss_s1: 0.026598, loss_fp: 0.003482, loss_freq: 0.023157
[17:27:56.172] iteration 16379: loss: 0.043803, loss_s1: 0.026885, loss_fp: 0.004731, loss_freq: 0.012952
[17:27:56.797] iteration 16380: loss: 0.088842, loss_s1: 0.077778, loss_fp: 0.021770, loss_freq: 0.018021
[17:27:57.423] iteration 16381: loss: 0.071692, loss_s1: 0.059744, loss_fp: 0.004186, loss_freq: 0.048340
[17:27:58.048] iteration 16382: loss: 0.051414, loss_s1: 0.021080, loss_fp: 0.001790, loss_freq: 0.030588
[17:27:58.673] iteration 16383: loss: 0.083963, loss_s1: 0.033436, loss_fp: 0.002128, loss_freq: 0.058029
[17:27:59.299] iteration 16384: loss: 0.061666, loss_s1: 0.052168, loss_fp: 0.006019, loss_freq: 0.018038
[17:27:59.927] iteration 16385: loss: 0.042833, loss_s1: 0.033627, loss_fp: 0.000581, loss_freq: 0.011562
[17:28:00.557] iteration 16386: loss: 0.055410, loss_s1: 0.030085, loss_fp: 0.003799, loss_freq: 0.040522
[17:28:01.179] iteration 16387: loss: 0.059356, loss_s1: 0.038739, loss_fp: 0.002449, loss_freq: 0.022370
[17:28:01.803] iteration 16388: loss: 0.036436, loss_s1: 0.009412, loss_fp: 0.003304, loss_freq: 0.011014
[17:28:02.429] iteration 16389: loss: 0.123290, loss_s1: 0.032236, loss_fp: 0.001408, loss_freq: 0.086709
[17:28:03.053] iteration 16390: loss: 0.067093, loss_s1: 0.059382, loss_fp: 0.003573, loss_freq: 0.022521
[17:28:03.677] iteration 16391: loss: 0.049810, loss_s1: 0.047220, loss_fp: 0.007158, loss_freq: 0.004947
[17:28:04.303] iteration 16392: loss: 0.097255, loss_s1: 0.056490, loss_fp: 0.008666, loss_freq: 0.092779
[17:28:04.925] iteration 16393: loss: 0.054984, loss_s1: 0.064817, loss_fp: 0.001189, loss_freq: 0.012339
[17:28:05.548] iteration 16394: loss: 0.065048, loss_s1: 0.051721, loss_fp: 0.005705, loss_freq: 0.031137
[17:28:06.171] iteration 16395: loss: 0.047470, loss_s1: 0.039230, loss_fp: 0.001164, loss_freq: 0.016783
[17:28:06.801] iteration 16396: loss: 0.051506, loss_s1: 0.010465, loss_fp: 0.008973, loss_freq: 0.033544
[17:28:07.423] iteration 16397: loss: 0.058184, loss_s1: 0.060398, loss_fp: 0.001305, loss_freq: 0.021667
[17:28:08.045] iteration 16398: loss: 0.039336, loss_s1: 0.008513, loss_fp: 0.000629, loss_freq: 0.016466
[17:28:08.665] iteration 16399: loss: 0.073125, loss_s1: 0.043441, loss_fp: 0.002523, loss_freq: 0.040491
[17:28:09.285] iteration 16400: loss: 0.061896, loss_s1: 0.063089, loss_fp: 0.002346, loss_freq: 0.021143
[17:28:12.478] iteration 16400 : mean_dice : 0.691310
[17:28:13.116] iteration 16401: loss: 0.082180, loss_s1: 0.063216, loss_fp: 0.000799, loss_freq: 0.022690
[17:28:13.741] iteration 16402: loss: 0.089112, loss_s1: 0.084994, loss_fp: 0.009466, loss_freq: 0.039157
[17:28:14.359] iteration 16403: loss: 0.065536, loss_s1: 0.039476, loss_fp: 0.005765, loss_freq: 0.036713
[17:28:15.013] iteration 16404: loss: 0.063167, loss_s1: 0.045232, loss_fp: 0.004982, loss_freq: 0.029973
[17:28:15.639] iteration 16405: loss: 0.068379, loss_s1: 0.052940, loss_fp: 0.002695, loss_freq: 0.029986
[17:28:16.265] iteration 16406: loss: 0.053342, loss_s1: 0.044648, loss_fp: 0.005468, loss_freq: 0.014032
[17:28:16.903] iteration 16407: loss: 0.068386, loss_s1: 0.044076, loss_fp: 0.003924, loss_freq: 0.020452
[17:28:17.527] iteration 16408: loss: 0.086840, loss_s1: 0.059417, loss_fp: 0.013851, loss_freq: 0.061578
[17:28:18.150] iteration 16409: loss: 0.033455, loss_s1: 0.020514, loss_fp: 0.000726, loss_freq: 0.011258
[17:28:18.773] iteration 16410: loss: 0.043816, loss_s1: 0.020035, loss_fp: 0.010701, loss_freq: 0.016677
[17:28:19.396] iteration 16411: loss: 0.091273, loss_s1: 0.078816, loss_fp: 0.003262, loss_freq: 0.060927
[17:28:20.051] iteration 16412: loss: 0.080547, loss_s1: 0.062105, loss_fp: 0.001101, loss_freq: 0.039449
[17:28:20.674] iteration 16413: loss: 0.082537, loss_s1: 0.084741, loss_fp: 0.005278, loss_freq: 0.043512
[17:28:21.302] iteration 16414: loss: 0.059421, loss_s1: 0.041222, loss_fp: 0.007891, loss_freq: 0.024771
[17:28:21.928] iteration 16415: loss: 0.060024, loss_s1: 0.033367, loss_fp: 0.004754, loss_freq: 0.030474
[17:28:22.560] iteration 16416: loss: 0.051564, loss_s1: 0.019087, loss_fp: 0.007378, loss_freq: 0.038416
[17:28:23.184] iteration 16417: loss: 0.048520, loss_s1: 0.025300, loss_fp: 0.001203, loss_freq: 0.027124
[17:28:23.812] iteration 16418: loss: 0.042340, loss_s1: 0.022212, loss_fp: 0.002655, loss_freq: 0.007311
[17:28:24.436] iteration 16419: loss: 0.127685, loss_s1: 0.122676, loss_fp: 0.004473, loss_freq: 0.058246
[17:28:25.058] iteration 16420: loss: 0.079907, loss_s1: 0.070240, loss_fp: 0.009842, loss_freq: 0.017429
[17:28:25.682] iteration 16421: loss: 0.039805, loss_s1: 0.028554, loss_fp: 0.000581, loss_freq: 0.018476
[17:28:26.302] iteration 16422: loss: 0.053052, loss_s1: 0.034409, loss_fp: 0.006748, loss_freq: 0.022442
[17:28:27.221] iteration 16423: loss: 0.061497, loss_s1: 0.026916, loss_fp: 0.000895, loss_freq: 0.012972
[17:28:27.847] iteration 16424: loss: 0.048281, loss_s1: 0.035471, loss_fp: 0.008590, loss_freq: 0.011401
[17:28:28.472] iteration 16425: loss: 0.054547, loss_s1: 0.037236, loss_fp: 0.003247, loss_freq: 0.015862
[17:28:29.096] iteration 16426: loss: 0.046082, loss_s1: 0.032586, loss_fp: 0.000537, loss_freq: 0.009003
[17:28:29.765] iteration 16427: loss: 0.044940, loss_s1: 0.034770, loss_fp: 0.004013, loss_freq: 0.014780
[17:28:30.408] iteration 16428: loss: 0.109670, loss_s1: 0.075386, loss_fp: 0.002597, loss_freq: 0.057909
[17:28:31.053] iteration 16429: loss: 0.052825, loss_s1: 0.049269, loss_fp: 0.003635, loss_freq: 0.022103
[17:28:31.678] iteration 16430: loss: 0.038846, loss_s1: 0.024844, loss_fp: 0.001750, loss_freq: 0.014952
[17:28:32.303] iteration 16431: loss: 0.032590, loss_s1: 0.028949, loss_fp: 0.003295, loss_freq: 0.005738
[17:28:32.932] iteration 16432: loss: 0.086425, loss_s1: 0.087200, loss_fp: 0.005072, loss_freq: 0.017160
[17:28:33.557] iteration 16433: loss: 0.041566, loss_s1: 0.017336, loss_fp: 0.001164, loss_freq: 0.013717
[17:28:34.182] iteration 16434: loss: 0.052413, loss_s1: 0.034983, loss_fp: 0.005700, loss_freq: 0.011126
[17:28:34.809] iteration 16435: loss: 0.065759, loss_s1: 0.047140, loss_fp: 0.004530, loss_freq: 0.040204
[17:28:35.436] iteration 16436: loss: 0.049436, loss_s1: 0.020460, loss_fp: 0.005660, loss_freq: 0.028866
[17:28:36.063] iteration 16437: loss: 0.046495, loss_s1: 0.037293, loss_fp: 0.004060, loss_freq: 0.010442
[17:28:36.690] iteration 16438: loss: 0.139469, loss_s1: 0.100208, loss_fp: 0.007674, loss_freq: 0.131237
[17:28:37.322] iteration 16439: loss: 0.073640, loss_s1: 0.074448, loss_fp: 0.001095, loss_freq: 0.008163
[17:28:37.946] iteration 16440: loss: 0.068354, loss_s1: 0.050539, loss_fp: 0.004752, loss_freq: 0.036909
[17:28:38.572] iteration 16441: loss: 0.059178, loss_s1: 0.043071, loss_fp: 0.001780, loss_freq: 0.031455
[17:28:39.197] iteration 16442: loss: 0.050909, loss_s1: 0.034449, loss_fp: 0.001898, loss_freq: 0.019381
[17:28:39.820] iteration 16443: loss: 0.057015, loss_s1: 0.053371, loss_fp: 0.001900, loss_freq: 0.009736
[17:28:40.443] iteration 16444: loss: 0.072367, loss_s1: 0.041087, loss_fp: 0.001189, loss_freq: 0.023528
[17:28:41.070] iteration 16445: loss: 0.059098, loss_s1: 0.054136, loss_fp: 0.001445, loss_freq: 0.009258
[17:28:41.694] iteration 16446: loss: 0.111537, loss_s1: 0.094246, loss_fp: 0.001576, loss_freq: 0.094294
[17:28:42.317] iteration 16447: loss: 0.042103, loss_s1: 0.025016, loss_fp: 0.002014, loss_freq: 0.019550
[17:28:42.949] iteration 16448: loss: 0.067950, loss_s1: 0.052290, loss_fp: 0.001846, loss_freq: 0.049316
[17:28:43.576] iteration 16449: loss: 0.065057, loss_s1: 0.072697, loss_fp: 0.010356, loss_freq: 0.013203
[17:28:44.200] iteration 16450: loss: 0.099969, loss_s1: 0.062257, loss_fp: 0.014038, loss_freq: 0.051843
[17:28:44.831] iteration 16451: loss: 0.078077, loss_s1: 0.064590, loss_fp: 0.006462, loss_freq: 0.044500
[17:28:45.453] iteration 16452: loss: 0.039852, loss_s1: 0.018479, loss_fp: 0.000911, loss_freq: 0.011531
[17:28:46.077] iteration 16453: loss: 0.039682, loss_s1: 0.034340, loss_fp: 0.005149, loss_freq: 0.011451
[17:28:46.700] iteration 16454: loss: 0.059465, loss_s1: 0.059342, loss_fp: 0.008596, loss_freq: 0.013976
[17:28:47.322] iteration 16455: loss: 0.036333, loss_s1: 0.031042, loss_fp: 0.001205, loss_freq: 0.014307
[17:28:47.948] iteration 16456: loss: 0.034837, loss_s1: 0.018155, loss_fp: 0.001983, loss_freq: 0.013362
[17:28:48.573] iteration 16457: loss: 0.054579, loss_s1: 0.034909, loss_fp: 0.006065, loss_freq: 0.025625
[17:28:49.202] iteration 16458: loss: 0.107902, loss_s1: 0.097799, loss_fp: 0.003614, loss_freq: 0.060028
[17:28:49.827] iteration 16459: loss: 0.062913, loss_s1: 0.040919, loss_fp: 0.002297, loss_freq: 0.037367
[17:28:50.451] iteration 16460: loss: 0.099155, loss_s1: 0.078629, loss_fp: 0.014239, loss_freq: 0.043625
[17:28:51.085] iteration 16461: loss: 0.105391, loss_s1: 0.040576, loss_fp: 0.012281, loss_freq: 0.103177
[17:28:51.716] iteration 16462: loss: 0.064783, loss_s1: 0.057206, loss_fp: 0.001320, loss_freq: 0.032315
[17:28:52.340] iteration 16463: loss: 0.043280, loss_s1: 0.029342, loss_fp: 0.002275, loss_freq: 0.007136
[17:28:52.970] iteration 16464: loss: 0.056641, loss_s1: 0.055843, loss_fp: 0.006568, loss_freq: 0.018076
[17:28:53.600] iteration 16465: loss: 0.096416, loss_s1: 0.086678, loss_fp: 0.001305, loss_freq: 0.057235
[17:28:54.251] iteration 16466: loss: 0.054685, loss_s1: 0.027995, loss_fp: 0.005076, loss_freq: 0.043954
[17:28:54.893] iteration 16467: loss: 0.051696, loss_s1: 0.036489, loss_fp: 0.003061, loss_freq: 0.019649
[17:28:55.527] iteration 16468: loss: 0.031895, loss_s1: 0.016151, loss_fp: 0.000376, loss_freq: 0.007731
[17:28:56.257] iteration 16469: loss: 0.032640, loss_s1: 0.013884, loss_fp: 0.000694, loss_freq: 0.019747
[17:28:56.879] iteration 16470: loss: 0.043020, loss_s1: 0.035950, loss_fp: 0.003698, loss_freq: 0.014133
[17:28:57.501] iteration 16471: loss: 0.063927, loss_s1: 0.074716, loss_fp: 0.002845, loss_freq: 0.010097
[17:28:58.126] iteration 16472: loss: 0.054532, loss_s1: 0.038547, loss_fp: 0.001732, loss_freq: 0.039527
[17:28:58.747] iteration 16473: loss: 0.069289, loss_s1: 0.051014, loss_fp: 0.001751, loss_freq: 0.051439
[17:28:59.369] iteration 16474: loss: 0.063442, loss_s1: 0.025771, loss_fp: 0.012939, loss_freq: 0.038108
[17:28:59.995] iteration 16475: loss: 0.045447, loss_s1: 0.025544, loss_fp: 0.002587, loss_freq: 0.025126
[17:29:00.620] iteration 16476: loss: 0.064635, loss_s1: 0.051120, loss_fp: 0.005360, loss_freq: 0.038175
[17:29:01.243] iteration 16477: loss: 0.033027, loss_s1: 0.013793, loss_fp: 0.008247, loss_freq: 0.007696
[17:29:01.909] iteration 16478: loss: 0.092249, loss_s1: 0.092045, loss_fp: 0.002067, loss_freq: 0.048915
[17:29:02.529] iteration 16479: loss: 0.050937, loss_s1: 0.035038, loss_fp: 0.002005, loss_freq: 0.012897
[17:29:03.152] iteration 16480: loss: 0.054927, loss_s1: 0.020349, loss_fp: 0.003211, loss_freq: 0.011370
[17:29:03.774] iteration 16481: loss: 0.048936, loss_s1: 0.037044, loss_fp: 0.001100, loss_freq: 0.018657
[17:29:04.392] iteration 16482: loss: 0.037954, loss_s1: 0.025957, loss_fp: 0.001571, loss_freq: 0.015849
[17:29:05.015] iteration 16483: loss: 0.050616, loss_s1: 0.034934, loss_fp: 0.001990, loss_freq: 0.030547
[17:29:05.636] iteration 16484: loss: 0.056556, loss_s1: 0.044495, loss_fp: 0.005504, loss_freq: 0.017435
[17:29:06.258] iteration 16485: loss: 0.045065, loss_s1: 0.030053, loss_fp: 0.001481, loss_freq: 0.009848
[17:29:06.878] iteration 16486: loss: 0.048578, loss_s1: 0.047143, loss_fp: 0.002095, loss_freq: 0.017483
[17:29:07.502] iteration 16487: loss: 0.049344, loss_s1: 0.058368, loss_fp: 0.004230, loss_freq: 0.006121
[17:29:08.126] iteration 16488: loss: 0.075244, loss_s1: 0.055106, loss_fp: 0.002114, loss_freq: 0.056096
[17:29:08.748] iteration 16489: loss: 0.063889, loss_s1: 0.020428, loss_fp: 0.002023, loss_freq: 0.027033
[17:29:09.371] iteration 16490: loss: 0.058080, loss_s1: 0.056556, loss_fp: 0.001117, loss_freq: 0.025123
[17:29:10.000] iteration 16491: loss: 0.055857, loss_s1: 0.047691, loss_fp: 0.002880, loss_freq: 0.019678
[17:29:10.633] iteration 16492: loss: 0.090979, loss_s1: 0.070642, loss_fp: 0.002730, loss_freq: 0.026435
[17:29:11.325] iteration 16493: loss: 0.067544, loss_s1: 0.052929, loss_fp: 0.001352, loss_freq: 0.043308
[17:29:11.988] iteration 16494: loss: 0.040156, loss_s1: 0.015050, loss_fp: 0.007029, loss_freq: 0.018969
[17:29:12.652] iteration 16495: loss: 0.048129, loss_s1: 0.042908, loss_fp: 0.003169, loss_freq: 0.010839
[17:29:13.288] iteration 16496: loss: 0.056669, loss_s1: 0.044464, loss_fp: 0.002940, loss_freq: 0.021257
[17:29:13.921] iteration 16497: loss: 0.080560, loss_s1: 0.062112, loss_fp: 0.010379, loss_freq: 0.039385
[17:29:14.548] iteration 16498: loss: 0.067794, loss_s1: 0.039564, loss_fp: 0.002221, loss_freq: 0.042652
[17:29:15.178] iteration 16499: loss: 0.062861, loss_s1: 0.054572, loss_fp: 0.000951, loss_freq: 0.032581
[17:29:15.807] iteration 16500: loss: 0.035922, loss_s1: 0.021478, loss_fp: 0.002815, loss_freq: 0.012397
[17:29:16.439] iteration 16501: loss: 0.045613, loss_s1: 0.022256, loss_fp: 0.004754, loss_freq: 0.010695
[17:29:17.059] iteration 16502: loss: 0.071863, loss_s1: 0.047676, loss_fp: 0.002677, loss_freq: 0.054515
[17:29:17.689] iteration 16503: loss: 0.069702, loss_s1: 0.050811, loss_fp: 0.006143, loss_freq: 0.046373
[17:29:18.323] iteration 16504: loss: 0.078225, loss_s1: 0.037511, loss_fp: 0.003053, loss_freq: 0.057687
[17:29:18.952] iteration 16505: loss: 0.088529, loss_s1: 0.103008, loss_fp: 0.004396, loss_freq: 0.035931
[17:29:19.579] iteration 16506: loss: 0.052319, loss_s1: 0.030997, loss_fp: 0.003617, loss_freq: 0.023330
[17:29:20.203] iteration 16507: loss: 0.053396, loss_s1: 0.052721, loss_fp: 0.006839, loss_freq: 0.011332
[17:29:20.884] iteration 16508: loss: 0.043031, loss_s1: 0.026167, loss_fp: 0.005843, loss_freq: 0.016847
[17:29:21.545] iteration 16509: loss: 0.073413, loss_s1: 0.056651, loss_fp: 0.001087, loss_freq: 0.024101
[17:29:22.192] iteration 16510: loss: 0.064539, loss_s1: 0.065572, loss_fp: 0.005102, loss_freq: 0.015047
[17:29:22.817] iteration 16511: loss: 0.048412, loss_s1: 0.025185, loss_fp: 0.003970, loss_freq: 0.028993
[17:29:23.444] iteration 16512: loss: 0.070011, loss_s1: 0.037362, loss_fp: 0.003112, loss_freq: 0.056759
[17:29:24.069] iteration 16513: loss: 0.054759, loss_s1: 0.032220, loss_fp: 0.011139, loss_freq: 0.017933
[17:29:24.693] iteration 16514: loss: 0.045005, loss_s1: 0.030229, loss_fp: 0.001900, loss_freq: 0.020686
[17:29:25.320] iteration 16515: loss: 0.073693, loss_s1: 0.049654, loss_fp: 0.002099, loss_freq: 0.016274
[17:29:25.944] iteration 16516: loss: 0.060699, loss_s1: 0.055118, loss_fp: 0.001635, loss_freq: 0.024446
[17:29:26.577] iteration 16517: loss: 0.048379, loss_s1: 0.023570, loss_fp: 0.001610, loss_freq: 0.027558
[17:29:27.206] iteration 16518: loss: 0.048835, loss_s1: 0.027100, loss_fp: 0.004811, loss_freq: 0.030312
[17:29:27.836] iteration 16519: loss: 0.085591, loss_s1: 0.042135, loss_fp: 0.007683, loss_freq: 0.015998
[17:29:28.461] iteration 16520: loss: 0.042478, loss_s1: 0.026579, loss_fp: 0.001068, loss_freq: 0.018730
[17:29:29.087] iteration 16521: loss: 0.048827, loss_s1: 0.035033, loss_fp: 0.002446, loss_freq: 0.021192
[17:29:29.711] iteration 16522: loss: 0.074845, loss_s1: 0.066182, loss_fp: 0.000896, loss_freq: 0.032075
[17:29:30.347] iteration 16523: loss: 0.081966, loss_s1: 0.093935, loss_fp: 0.002283, loss_freq: 0.035238
[17:29:30.973] iteration 16524: loss: 0.088700, loss_s1: 0.048332, loss_fp: 0.007909, loss_freq: 0.059680
[17:29:31.603] iteration 16525: loss: 0.054544, loss_s1: 0.024027, loss_fp: 0.002039, loss_freq: 0.044306
[17:29:32.227] iteration 16526: loss: 0.050547, loss_s1: 0.028232, loss_fp: 0.003776, loss_freq: 0.028890
[17:29:32.856] iteration 16527: loss: 0.065040, loss_s1: 0.020157, loss_fp: 0.002455, loss_freq: 0.020039
[17:29:33.480] iteration 16528: loss: 0.064698, loss_s1: 0.037527, loss_fp: 0.009715, loss_freq: 0.039909
[17:29:34.106] iteration 16529: loss: 0.035360, loss_s1: 0.017776, loss_fp: 0.000438, loss_freq: 0.013119
[17:29:34.732] iteration 16530: loss: 0.098520, loss_s1: 0.111736, loss_fp: 0.000761, loss_freq: 0.033238
[17:29:35.359] iteration 16531: loss: 0.083488, loss_s1: 0.044945, loss_fp: 0.011024, loss_freq: 0.053872
[17:29:36.016] iteration 16532: loss: 0.070210, loss_s1: 0.058322, loss_fp: 0.009285, loss_freq: 0.037170
[17:29:36.680] iteration 16533: loss: 0.056065, loss_s1: 0.024166, loss_fp: 0.001395, loss_freq: 0.034789
[17:29:37.343] iteration 16534: loss: 0.063010, loss_s1: 0.038360, loss_fp: 0.005169, loss_freq: 0.032404
[17:29:38.001] iteration 16535: loss: 0.108434, loss_s1: 0.091802, loss_fp: 0.005059, loss_freq: 0.082444
[17:29:38.657] iteration 16536: loss: 0.039907, loss_s1: 0.019835, loss_fp: 0.001435, loss_freq: 0.025471
[17:29:39.307] iteration 16537: loss: 0.051106, loss_s1: 0.029333, loss_fp: 0.000978, loss_freq: 0.007950
[17:29:39.932] iteration 16538: loss: 0.067000, loss_s1: 0.040442, loss_fp: 0.009790, loss_freq: 0.036527
[17:29:40.559] iteration 16539: loss: 0.078992, loss_s1: 0.053241, loss_fp: 0.003394, loss_freq: 0.056563
[17:29:41.180] iteration 16540: loss: 0.049568, loss_s1: 0.034592, loss_fp: 0.001940, loss_freq: 0.018960
[17:29:41.804] iteration 16541: loss: 0.044085, loss_s1: 0.012703, loss_fp: 0.004535, loss_freq: 0.030717
[17:29:42.430] iteration 16542: loss: 0.139996, loss_s1: 0.141589, loss_fp: 0.006019, loss_freq: 0.098599
[17:29:43.054] iteration 16543: loss: 0.059664, loss_s1: 0.060726, loss_fp: 0.007787, loss_freq: 0.008409
[17:29:43.680] iteration 16544: loss: 0.049615, loss_s1: 0.012105, loss_fp: 0.000900, loss_freq: 0.033938
[17:29:44.305] iteration 16545: loss: 0.071001, loss_s1: 0.058590, loss_fp: 0.000702, loss_freq: 0.022713
[17:29:44.931] iteration 16546: loss: 0.044503, loss_s1: 0.029798, loss_fp: 0.001239, loss_freq: 0.013006
[17:29:45.555] iteration 16547: loss: 0.064601, loss_s1: 0.050552, loss_fp: 0.003346, loss_freq: 0.019888
[17:29:46.176] iteration 16548: loss: 0.074287, loss_s1: 0.048944, loss_fp: 0.006872, loss_freq: 0.021049
[17:29:46.813] iteration 16549: loss: 0.053869, loss_s1: 0.054266, loss_fp: 0.001576, loss_freq: 0.013243
[17:29:47.435] iteration 16550: loss: 0.113805, loss_s1: 0.089182, loss_fp: 0.005973, loss_freq: 0.057217
[17:29:48.056] iteration 16551: loss: 0.069159, loss_s1: 0.033573, loss_fp: 0.003079, loss_freq: 0.052157
[17:29:48.677] iteration 16552: loss: 0.056221, loss_s1: 0.049697, loss_fp: 0.000831, loss_freq: 0.014145
[17:29:49.298] iteration 16553: loss: 0.074467, loss_s1: 0.046262, loss_fp: 0.003532, loss_freq: 0.071265
[17:29:49.918] iteration 16554: loss: 0.087145, loss_s1: 0.113485, loss_fp: 0.001774, loss_freq: 0.022178
[17:29:50.541] iteration 16555: loss: 0.053301, loss_s1: 0.030276, loss_fp: 0.004883, loss_freq: 0.015328
[17:29:51.167] iteration 16556: loss: 0.040095, loss_s1: 0.016885, loss_fp: 0.005218, loss_freq: 0.019896
[17:29:51.789] iteration 16557: loss: 0.097078, loss_s1: 0.035369, loss_fp: 0.007328, loss_freq: 0.083198
[17:29:52.409] iteration 16558: loss: 0.078906, loss_s1: 0.066922, loss_fp: 0.008573, loss_freq: 0.042249
[17:29:53.031] iteration 16559: loss: 0.039216, loss_s1: 0.027553, loss_fp: 0.000887, loss_freq: 0.009635
[17:29:53.649] iteration 16560: loss: 0.040040, loss_s1: 0.033098, loss_fp: 0.001492, loss_freq: 0.013788
[17:29:54.272] iteration 16561: loss: 0.058385, loss_s1: 0.041373, loss_fp: 0.003456, loss_freq: 0.033623
[17:29:54.888] iteration 16562: loss: 0.083616, loss_s1: 0.031676, loss_fp: 0.017653, loss_freq: 0.042276
[17:29:55.511] iteration 16563: loss: 0.067948, loss_s1: 0.065609, loss_fp: 0.006285, loss_freq: 0.024647
[17:29:56.134] iteration 16564: loss: 0.059335, loss_s1: 0.029191, loss_fp: 0.004811, loss_freq: 0.018485
[17:29:56.756] iteration 16565: loss: 0.078015, loss_s1: 0.073472, loss_fp: 0.003072, loss_freq: 0.039889
[17:29:57.381] iteration 16566: loss: 0.082323, loss_s1: 0.082333, loss_fp: 0.006805, loss_freq: 0.011999
[17:29:58.001] iteration 16567: loss: 0.058846, loss_s1: 0.061925, loss_fp: 0.001945, loss_freq: 0.011245
[17:29:58.622] iteration 16568: loss: 0.077843, loss_s1: 0.075863, loss_fp: 0.008496, loss_freq: 0.020543
[17:29:59.244] iteration 16569: loss: 0.092079, loss_s1: 0.049204, loss_fp: 0.007381, loss_freq: 0.088608
[17:29:59.864] iteration 16570: loss: 0.044123, loss_s1: 0.027295, loss_fp: 0.001039, loss_freq: 0.014317
[17:30:00.485] iteration 16571: loss: 0.085355, loss_s1: 0.032357, loss_fp: 0.000900, loss_freq: 0.027841
[17:30:01.105] iteration 16572: loss: 0.101986, loss_s1: 0.092027, loss_fp: 0.005061, loss_freq: 0.057203
[17:30:01.724] iteration 16573: loss: 0.089259, loss_s1: 0.059868, loss_fp: 0.013968, loss_freq: 0.031379
[17:30:02.343] iteration 16574: loss: 0.084162, loss_s1: 0.067139, loss_fp: 0.001589, loss_freq: 0.039206
[17:30:02.968] iteration 16575: loss: 0.057599, loss_s1: 0.035214, loss_fp: 0.004327, loss_freq: 0.040178
[17:30:03.590] iteration 16576: loss: 0.086135, loss_s1: 0.078908, loss_fp: 0.004501, loss_freq: 0.033021
[17:30:04.213] iteration 16577: loss: 0.030020, loss_s1: 0.017889, loss_fp: 0.000496, loss_freq: 0.007983
[17:30:04.835] iteration 16578: loss: 0.036717, loss_s1: 0.029407, loss_fp: 0.000402, loss_freq: 0.004841
[17:30:05.465] iteration 16579: loss: 0.050132, loss_s1: 0.019791, loss_fp: 0.004563, loss_freq: 0.008583
[17:30:06.085] iteration 16580: loss: 0.063480, loss_s1: 0.050866, loss_fp: 0.003274, loss_freq: 0.034850
[17:30:06.706] iteration 16581: loss: 0.076300, loss_s1: 0.077896, loss_fp: 0.007127, loss_freq: 0.028029
[17:30:07.329] iteration 16582: loss: 0.038798, loss_s1: 0.023722, loss_fp: 0.001721, loss_freq: 0.012816
[17:30:07.948] iteration 16583: loss: 0.065256, loss_s1: 0.042264, loss_fp: 0.001942, loss_freq: 0.046882
[17:30:08.931] iteration 16584: loss: 0.064651, loss_s1: 0.067816, loss_fp: 0.001004, loss_freq: 0.022414
[17:30:09.598] iteration 16585: loss: 0.103988, loss_s1: 0.094302, loss_fp: 0.011277, loss_freq: 0.030067
[17:30:10.234] iteration 16586: loss: 0.038803, loss_s1: 0.010388, loss_fp: 0.001371, loss_freq: 0.014911
[17:30:10.864] iteration 16587: loss: 0.051946, loss_s1: 0.038828, loss_fp: 0.000522, loss_freq: 0.020413
[17:30:11.493] iteration 16588: loss: 0.045622, loss_s1: 0.028641, loss_fp: 0.005569, loss_freq: 0.015264
[17:30:12.119] iteration 16589: loss: 0.135300, loss_s1: 0.091574, loss_fp: 0.006719, loss_freq: 0.041250
[17:30:12.747] iteration 16590: loss: 0.046153, loss_s1: 0.046876, loss_fp: 0.000603, loss_freq: 0.005595
[17:30:13.375] iteration 16591: loss: 0.056140, loss_s1: 0.057487, loss_fp: 0.001819, loss_freq: 0.017098
[17:30:14.003] iteration 16592: loss: 0.057611, loss_s1: 0.044256, loss_fp: 0.001853, loss_freq: 0.033619
[17:30:14.663] iteration 16593: loss: 0.076276, loss_s1: 0.051732, loss_fp: 0.001734, loss_freq: 0.011488
[17:30:15.331] iteration 16594: loss: 0.035379, loss_s1: 0.022515, loss_fp: 0.001305, loss_freq: 0.007667
[17:30:15.990] iteration 16595: loss: 0.068322, loss_s1: 0.045718, loss_fp: 0.009306, loss_freq: 0.037785
[17:30:16.617] iteration 16596: loss: 0.075869, loss_s1: 0.025822, loss_fp: 0.012190, loss_freq: 0.080060
[17:30:17.255] iteration 16597: loss: 0.081260, loss_s1: 0.088583, loss_fp: 0.007319, loss_freq: 0.025074
[17:30:17.887] iteration 16598: loss: 0.058510, loss_s1: 0.047860, loss_fp: 0.003112, loss_freq: 0.022573
[17:30:18.514] iteration 16599: loss: 0.111019, loss_s1: 0.076628, loss_fp: 0.010022, loss_freq: 0.091841
[17:30:19.141] iteration 16600: loss: 0.037791, loss_s1: 0.011172, loss_fp: 0.002639, loss_freq: 0.011860
[17:30:22.332] iteration 16600 : mean_dice : 0.695314
[17:30:22.986] iteration 16601: loss: 0.087777, loss_s1: 0.063058, loss_fp: 0.012790, loss_freq: 0.054592
[17:30:23.606] iteration 16602: loss: 0.045674, loss_s1: 0.019300, loss_fp: 0.001288, loss_freq: 0.021717
[17:30:24.229] iteration 16603: loss: 0.052155, loss_s1: 0.027665, loss_fp: 0.002693, loss_freq: 0.021305
[17:30:24.850] iteration 16604: loss: 0.037918, loss_s1: 0.021686, loss_fp: 0.001533, loss_freq: 0.011942
[17:30:25.474] iteration 16605: loss: 0.061699, loss_s1: 0.042180, loss_fp: 0.000773, loss_freq: 0.017812
[17:30:26.093] iteration 16606: loss: 0.061362, loss_s1: 0.046545, loss_fp: 0.000360, loss_freq: 0.010816
[17:30:26.727] iteration 16607: loss: 0.131566, loss_s1: 0.124024, loss_fp: 0.002607, loss_freq: 0.098467
[17:30:27.343] iteration 16608: loss: 0.043260, loss_s1: 0.026410, loss_fp: 0.002135, loss_freq: 0.020880
[17:30:27.963] iteration 16609: loss: 0.071359, loss_s1: 0.061605, loss_fp: 0.001339, loss_freq: 0.047732
[17:30:28.589] iteration 16610: loss: 0.071384, loss_s1: 0.031447, loss_fp: 0.032829, loss_freq: 0.044680
[17:30:29.214] iteration 16611: loss: 0.084763, loss_s1: 0.058839, loss_fp: 0.022368, loss_freq: 0.030903
[17:30:29.836] iteration 16612: loss: 0.069834, loss_s1: 0.048489, loss_fp: 0.006775, loss_freq: 0.035313
[17:30:30.460] iteration 16613: loss: 0.035501, loss_s1: 0.018752, loss_fp: 0.002110, loss_freq: 0.012075
[17:30:31.077] iteration 16614: loss: 0.043794, loss_s1: 0.032143, loss_fp: 0.000505, loss_freq: 0.024587
[17:30:31.701] iteration 16615: loss: 0.073679, loss_s1: 0.044421, loss_fp: 0.002032, loss_freq: 0.015988
[17:30:32.324] iteration 16616: loss: 0.046782, loss_s1: 0.017901, loss_fp: 0.001495, loss_freq: 0.035761
[17:30:32.948] iteration 16617: loss: 0.039763, loss_s1: 0.029767, loss_fp: 0.005491, loss_freq: 0.006607
[17:30:33.569] iteration 16618: loss: 0.055243, loss_s1: 0.033266, loss_fp: 0.001461, loss_freq: 0.026413
[17:30:34.192] iteration 16619: loss: 0.074201, loss_s1: 0.056346, loss_fp: 0.006457, loss_freq: 0.051213
[17:30:34.813] iteration 16620: loss: 0.110418, loss_s1: 0.075770, loss_fp: 0.005027, loss_freq: 0.026319
[17:30:35.437] iteration 16621: loss: 0.055163, loss_s1: 0.045972, loss_fp: 0.002957, loss_freq: 0.026898
[17:30:36.063] iteration 16622: loss: 0.122409, loss_s1: 0.115372, loss_fp: 0.006765, loss_freq: 0.070411
[17:30:36.687] iteration 16623: loss: 0.058924, loss_s1: 0.037023, loss_fp: 0.004667, loss_freq: 0.043964
[17:30:37.312] iteration 16624: loss: 0.067788, loss_s1: 0.036961, loss_fp: 0.022938, loss_freq: 0.034430
[17:30:37.938] iteration 16625: loss: 0.103525, loss_s1: 0.118305, loss_fp: 0.005036, loss_freq: 0.043876
[17:30:38.562] iteration 16626: loss: 0.081616, loss_s1: 0.060429, loss_fp: 0.007716, loss_freq: 0.058061
[17:30:39.188] iteration 16627: loss: 0.059313, loss_s1: 0.033623, loss_fp: 0.003924, loss_freq: 0.041158
[17:30:39.813] iteration 16628: loss: 0.068642, loss_s1: 0.031514, loss_fp: 0.005226, loss_freq: 0.052210
[17:30:40.439] iteration 16629: loss: 0.046148, loss_s1: 0.043553, loss_fp: 0.002248, loss_freq: 0.004287
[17:30:41.114] iteration 16630: loss: 0.030148, loss_s1: 0.008635, loss_fp: 0.002967, loss_freq: 0.016771
[17:30:41.783] iteration 16631: loss: 0.064273, loss_s1: 0.044466, loss_fp: 0.010030, loss_freq: 0.031048
[17:30:42.406] iteration 16632: loss: 0.054270, loss_s1: 0.024927, loss_fp: 0.000208, loss_freq: 0.018037
[17:30:43.029] iteration 16633: loss: 0.064686, loss_s1: 0.052051, loss_fp: 0.005126, loss_freq: 0.040420
[17:30:43.650] iteration 16634: loss: 0.047470, loss_s1: 0.033938, loss_fp: 0.003840, loss_freq: 0.017382
[17:30:44.271] iteration 16635: loss: 0.039698, loss_s1: 0.013652, loss_fp: 0.002031, loss_freq: 0.021339
[17:30:44.897] iteration 16636: loss: 0.068279, loss_s1: 0.030142, loss_fp: 0.004117, loss_freq: 0.034331
[17:30:45.519] iteration 16637: loss: 0.055374, loss_s1: 0.043016, loss_fp: 0.004393, loss_freq: 0.029746
[17:30:46.195] iteration 16638: loss: 0.045648, loss_s1: 0.018863, loss_fp: 0.001735, loss_freq: 0.018231
[17:30:46.872] iteration 16639: loss: 0.078485, loss_s1: 0.070127, loss_fp: 0.009490, loss_freq: 0.036427
[17:30:47.528] iteration 16640: loss: 0.042658, loss_s1: 0.029064, loss_fp: 0.003073, loss_freq: 0.009646
[17:30:48.188] iteration 16641: loss: 0.087199, loss_s1: 0.068015, loss_fp: 0.002328, loss_freq: 0.044727
[17:30:48.845] iteration 16642: loss: 0.031978, loss_s1: 0.005933, loss_fp: 0.004093, loss_freq: 0.009502
[17:30:49.500] iteration 16643: loss: 0.047366, loss_s1: 0.033334, loss_fp: 0.002247, loss_freq: 0.024473
[17:30:50.143] iteration 16644: loss: 0.050447, loss_s1: 0.027595, loss_fp: 0.004062, loss_freq: 0.016455
[17:30:50.772] iteration 16645: loss: 0.036604, loss_s1: 0.022425, loss_fp: 0.002656, loss_freq: 0.012226
[17:30:51.400] iteration 16646: loss: 0.037577, loss_s1: 0.014669, loss_fp: 0.000592, loss_freq: 0.019559
[17:30:52.022] iteration 16647: loss: 0.082708, loss_s1: 0.090825, loss_fp: 0.003276, loss_freq: 0.026477
[17:30:52.645] iteration 16648: loss: 0.058081, loss_s1: 0.038057, loss_fp: 0.005919, loss_freq: 0.037251
[17:30:53.266] iteration 16649: loss: 0.054451, loss_s1: 0.041034, loss_fp: 0.002470, loss_freq: 0.033926
[17:30:53.891] iteration 16650: loss: 0.056390, loss_s1: 0.033175, loss_fp: 0.001117, loss_freq: 0.032004
[17:30:54.513] iteration 16651: loss: 0.046732, loss_s1: 0.034638, loss_fp: 0.005294, loss_freq: 0.021852
[17:30:55.136] iteration 16652: loss: 0.054595, loss_s1: 0.050028, loss_fp: 0.001765, loss_freq: 0.019072
[17:30:55.765] iteration 16653: loss: 0.068608, loss_s1: 0.043161, loss_fp: 0.000997, loss_freq: 0.023320
[17:30:56.420] iteration 16654: loss: 0.073970, loss_s1: 0.049830, loss_fp: 0.021665, loss_freq: 0.041101
[17:30:57.081] iteration 16655: loss: 0.042064, loss_s1: 0.025967, loss_fp: 0.000661, loss_freq: 0.023588
[17:30:57.738] iteration 16656: loss: 0.050754, loss_s1: 0.048605, loss_fp: 0.000437, loss_freq: 0.007168
[17:30:58.369] iteration 16657: loss: 0.036556, loss_s1: 0.022559, loss_fp: 0.000567, loss_freq: 0.005527
[17:30:58.995] iteration 16658: loss: 0.067377, loss_s1: 0.064275, loss_fp: 0.001630, loss_freq: 0.029281
[17:30:59.724] iteration 16659: loss: 0.083216, loss_s1: 0.111912, loss_fp: 0.000239, loss_freq: 0.005368
[17:31:00.386] iteration 16660: loss: 0.092369, loss_s1: 0.098220, loss_fp: 0.025126, loss_freq: 0.026974
[17:31:01.076] iteration 16661: loss: 0.054926, loss_s1: 0.039707, loss_fp: 0.002079, loss_freq: 0.030696
[17:31:01.720] iteration 16662: loss: 0.041574, loss_s1: 0.031027, loss_fp: 0.001605, loss_freq: 0.012124
[17:31:02.351] iteration 16663: loss: 0.062564, loss_s1: 0.040657, loss_fp: 0.003978, loss_freq: 0.035014
[17:31:02.971] iteration 16664: loss: 0.048396, loss_s1: 0.023003, loss_fp: 0.006803, loss_freq: 0.033665
[17:31:03.590] iteration 16665: loss: 0.066074, loss_s1: 0.071157, loss_fp: 0.012024, loss_freq: 0.017225
[17:31:04.228] iteration 16666: loss: 0.126001, loss_s1: 0.093356, loss_fp: 0.005710, loss_freq: 0.123242
[17:31:04.850] iteration 16667: loss: 0.050681, loss_s1: 0.035608, loss_fp: 0.002331, loss_freq: 0.019167
[17:31:05.475] iteration 16668: loss: 0.082270, loss_s1: 0.067741, loss_fp: 0.007838, loss_freq: 0.052356
[17:31:06.105] iteration 16669: loss: 0.049359, loss_s1: 0.051566, loss_fp: 0.003416, loss_freq: 0.013169
[17:31:06.734] iteration 16670: loss: 0.061844, loss_s1: 0.054495, loss_fp: 0.001901, loss_freq: 0.007866
[17:31:07.364] iteration 16671: loss: 0.056051, loss_s1: 0.043624, loss_fp: 0.005119, loss_freq: 0.024385
[17:31:07.990] iteration 16672: loss: 0.075415, loss_s1: 0.050663, loss_fp: 0.004192, loss_freq: 0.060927
[17:31:08.621] iteration 16673: loss: 0.067167, loss_s1: 0.042225, loss_fp: 0.004295, loss_freq: 0.044680
[17:31:09.248] iteration 16674: loss: 0.047122, loss_s1: 0.026816, loss_fp: 0.002174, loss_freq: 0.016767
[17:31:09.876] iteration 16675: loss: 0.045313, loss_s1: 0.028991, loss_fp: 0.003189, loss_freq: 0.014031
[17:31:10.507] iteration 16676: loss: 0.043512, loss_s1: 0.013417, loss_fp: 0.000323, loss_freq: 0.014494
[17:31:11.133] iteration 16677: loss: 0.047493, loss_s1: 0.021110, loss_fp: 0.001580, loss_freq: 0.017876
[17:31:11.754] iteration 16678: loss: 0.050776, loss_s1: 0.047737, loss_fp: 0.001773, loss_freq: 0.024984
[17:31:12.382] iteration 16679: loss: 0.032991, loss_s1: 0.020621, loss_fp: 0.001865, loss_freq: 0.010815
[17:31:13.007] iteration 16680: loss: 0.042854, loss_s1: 0.014209, loss_fp: 0.002765, loss_freq: 0.018677
[17:31:13.632] iteration 16681: loss: 0.069433, loss_s1: 0.027029, loss_fp: 0.002348, loss_freq: 0.045651
[17:31:14.263] iteration 16682: loss: 0.069998, loss_s1: 0.039073, loss_fp: 0.003417, loss_freq: 0.049398
[17:31:14.884] iteration 16683: loss: 0.064603, loss_s1: 0.047284, loss_fp: 0.003138, loss_freq: 0.026878
[17:31:15.513] iteration 16684: loss: 0.057351, loss_s1: 0.047204, loss_fp: 0.005194, loss_freq: 0.034150
[17:31:16.141] iteration 16685: loss: 0.048939, loss_s1: 0.024899, loss_fp: 0.001659, loss_freq: 0.023778
[17:31:16.771] iteration 16686: loss: 0.062428, loss_s1: 0.031873, loss_fp: 0.001842, loss_freq: 0.053055
[17:31:17.398] iteration 16687: loss: 0.070717, loss_s1: 0.073247, loss_fp: 0.001359, loss_freq: 0.025004
[17:31:18.021] iteration 16688: loss: 0.029232, loss_s1: 0.009211, loss_fp: 0.003062, loss_freq: 0.006971
[17:31:18.645] iteration 16689: loss: 0.055306, loss_s1: 0.030589, loss_fp: 0.002824, loss_freq: 0.029481
[17:31:19.269] iteration 16690: loss: 0.033372, loss_s1: 0.015527, loss_fp: 0.001326, loss_freq: 0.005709
[17:31:19.892] iteration 16691: loss: 0.070576, loss_s1: 0.059967, loss_fp: 0.006215, loss_freq: 0.036590
[17:31:20.517] iteration 16692: loss: 0.185618, loss_s1: 0.150910, loss_fp: 0.014360, loss_freq: 0.158728
[17:31:21.144] iteration 16693: loss: 0.071759, loss_s1: 0.056236, loss_fp: 0.001843, loss_freq: 0.039873
[17:31:21.767] iteration 16694: loss: 0.066634, loss_s1: 0.043207, loss_fp: 0.005258, loss_freq: 0.022939
[17:31:22.388] iteration 16695: loss: 0.058302, loss_s1: 0.035301, loss_fp: 0.006357, loss_freq: 0.035653
[17:31:23.053] iteration 16696: loss: 0.087519, loss_s1: 0.079297, loss_fp: 0.004788, loss_freq: 0.010035
[17:31:23.675] iteration 16697: loss: 0.037786, loss_s1: 0.022029, loss_fp: 0.000945, loss_freq: 0.012366
[17:31:24.298] iteration 16698: loss: 0.029430, loss_s1: 0.017317, loss_fp: 0.000456, loss_freq: 0.002251
[17:31:24.925] iteration 16699: loss: 0.075963, loss_s1: 0.051917, loss_fp: 0.000664, loss_freq: 0.040950
[17:31:25.551] iteration 16700: loss: 0.064208, loss_s1: 0.056431, loss_fp: 0.007375, loss_freq: 0.030102
[17:31:26.185] iteration 16701: loss: 0.033346, loss_s1: 0.028056, loss_fp: 0.000490, loss_freq: 0.007893
[17:31:26.814] iteration 16702: loss: 0.061856, loss_s1: 0.041906, loss_fp: 0.001458, loss_freq: 0.038073
[17:31:27.443] iteration 16703: loss: 0.106137, loss_s1: 0.094463, loss_fp: 0.021449, loss_freq: 0.061701
[17:31:28.076] iteration 16704: loss: 0.054107, loss_s1: 0.034017, loss_fp: 0.001789, loss_freq: 0.038523
[17:31:28.702] iteration 16705: loss: 0.061429, loss_s1: 0.028752, loss_fp: 0.006217, loss_freq: 0.015199
[17:31:29.328] iteration 16706: loss: 0.081070, loss_s1: 0.064366, loss_fp: 0.002651, loss_freq: 0.036002
[17:31:29.952] iteration 16707: loss: 0.048970, loss_s1: 0.039187, loss_fp: 0.003330, loss_freq: 0.019141
[17:31:30.577] iteration 16708: loss: 0.044962, loss_s1: 0.025612, loss_fp: 0.002796, loss_freq: 0.024528
[17:31:31.207] iteration 16709: loss: 0.074934, loss_s1: 0.066147, loss_fp: 0.002293, loss_freq: 0.031301
[17:31:31.890] iteration 16710: loss: 0.064928, loss_s1: 0.067950, loss_fp: 0.002289, loss_freq: 0.011539
[17:31:32.551] iteration 16711: loss: 0.087008, loss_s1: 0.080268, loss_fp: 0.001121, loss_freq: 0.041468
[17:31:33.211] iteration 16712: loss: 0.039111, loss_s1: 0.018252, loss_fp: 0.000355, loss_freq: 0.021085
[17:31:33.870] iteration 16713: loss: 0.068856, loss_s1: 0.078809, loss_fp: 0.004202, loss_freq: 0.019123
[17:31:34.513] iteration 16714: loss: 0.084348, loss_s1: 0.054220, loss_fp: 0.003408, loss_freq: 0.054569
[17:31:35.138] iteration 16715: loss: 0.056037, loss_s1: 0.053032, loss_fp: 0.005866, loss_freq: 0.018683
[17:31:35.753] iteration 16716: loss: 0.078660, loss_s1: 0.087962, loss_fp: 0.003823, loss_freq: 0.025285
[17:31:36.378] iteration 16717: loss: 0.049705, loss_s1: 0.031603, loss_fp: 0.004950, loss_freq: 0.021017
[17:31:37.003] iteration 16718: loss: 0.089720, loss_s1: 0.100568, loss_fp: 0.011886, loss_freq: 0.036213
[17:31:37.635] iteration 16719: loss: 0.062192, loss_s1: 0.043625, loss_fp: 0.000852, loss_freq: 0.043382
[17:31:38.262] iteration 16720: loss: 0.039991, loss_s1: 0.015525, loss_fp: 0.001635, loss_freq: 0.012096
[17:31:38.888] iteration 16721: loss: 0.038976, loss_s1: 0.027399, loss_fp: 0.003725, loss_freq: 0.015994
[17:31:39.512] iteration 16722: loss: 0.050953, loss_s1: 0.052485, loss_fp: 0.002642, loss_freq: 0.007805
[17:31:40.138] iteration 16723: loss: 0.066605, loss_s1: 0.048241, loss_fp: 0.010780, loss_freq: 0.016741
[17:31:40.762] iteration 16724: loss: 0.071534, loss_s1: 0.064986, loss_fp: 0.001121, loss_freq: 0.020047
[17:31:41.386] iteration 16725: loss: 0.046415, loss_s1: 0.024779, loss_fp: 0.003098, loss_freq: 0.029661
[17:31:42.038] iteration 16726: loss: 0.062677, loss_s1: 0.041124, loss_fp: 0.001636, loss_freq: 0.044416
[17:31:42.702] iteration 16727: loss: 0.078131, loss_s1: 0.062655, loss_fp: 0.003632, loss_freq: 0.032791
[17:31:43.326] iteration 16728: loss: 0.045175, loss_s1: 0.036079, loss_fp: 0.009098, loss_freq: 0.005117
[17:31:43.951] iteration 16729: loss: 0.073847, loss_s1: 0.058598, loss_fp: 0.005598, loss_freq: 0.025123
[17:31:44.589] iteration 16730: loss: 0.063921, loss_s1: 0.036717, loss_fp: 0.001790, loss_freq: 0.056740
[17:31:45.217] iteration 16731: loss: 0.049288, loss_s1: 0.050636, loss_fp: 0.002517, loss_freq: 0.011565
[17:31:45.842] iteration 16732: loss: 0.063555, loss_s1: 0.048268, loss_fp: 0.000894, loss_freq: 0.012507
[17:31:46.469] iteration 16733: loss: 0.091971, loss_s1: 0.068468, loss_fp: 0.005665, loss_freq: 0.068676
[17:31:47.094] iteration 16734: loss: 0.066670, loss_s1: 0.040987, loss_fp: 0.005543, loss_freq: 0.032471
[17:31:47.723] iteration 16735: loss: 0.094326, loss_s1: 0.084988, loss_fp: 0.010835, loss_freq: 0.054160
[17:31:48.380] iteration 16736: loss: 0.039393, loss_s1: 0.026063, loss_fp: 0.001594, loss_freq: 0.023049
[17:31:49.033] iteration 16737: loss: 0.045494, loss_s1: 0.025104, loss_fp: 0.010460, loss_freq: 0.014694
[17:31:49.690] iteration 16738: loss: 0.034825, loss_s1: 0.021767, loss_fp: 0.001122, loss_freq: 0.010163
[17:31:50.332] iteration 16739: loss: 0.052013, loss_s1: 0.036053, loss_fp: 0.000813, loss_freq: 0.019214
[17:31:50.956] iteration 16740: loss: 0.057611, loss_s1: 0.019632, loss_fp: 0.000300, loss_freq: 0.016927
[17:31:51.576] iteration 16741: loss: 0.065784, loss_s1: 0.050159, loss_fp: 0.003051, loss_freq: 0.030758
[17:31:52.199] iteration 16742: loss: 0.083840, loss_s1: 0.072100, loss_fp: 0.011805, loss_freq: 0.037811
[17:31:52.820] iteration 16743: loss: 0.048911, loss_s1: 0.028022, loss_fp: 0.002262, loss_freq: 0.006382
[17:31:53.441] iteration 16744: loss: 0.058636, loss_s1: 0.024279, loss_fp: 0.002265, loss_freq: 0.050636
[17:31:54.518] iteration 16745: loss: 0.044581, loss_s1: 0.035290, loss_fp: 0.001317, loss_freq: 0.020600
[17:31:55.140] iteration 16746: loss: 0.073340, loss_s1: 0.068263, loss_fp: 0.000830, loss_freq: 0.024966
[17:31:55.757] iteration 16747: loss: 0.037392, loss_s1: 0.015755, loss_fp: 0.004458, loss_freq: 0.012136
[17:31:56.385] iteration 16748: loss: 0.047766, loss_s1: 0.024684, loss_fp: 0.001029, loss_freq: 0.021372
[17:31:57.009] iteration 16749: loss: 0.076652, loss_s1: 0.058999, loss_fp: 0.000854, loss_freq: 0.044476
[17:31:57.639] iteration 16750: loss: 0.116216, loss_s1: 0.123209, loss_fp: 0.006545, loss_freq: 0.037502
[17:31:58.298] iteration 16751: loss: 0.032849, loss_s1: 0.013612, loss_fp: 0.002462, loss_freq: 0.015292
[17:31:58.955] iteration 16752: loss: 0.040319, loss_s1: 0.035381, loss_fp: 0.004439, loss_freq: 0.010025
[17:31:59.612] iteration 16753: loss: 0.062860, loss_s1: 0.054060, loss_fp: 0.001160, loss_freq: 0.042883
[17:32:00.232] iteration 16754: loss: 0.037826, loss_s1: 0.017227, loss_fp: 0.003701, loss_freq: 0.017644
[17:32:00.851] iteration 16755: loss: 0.042441, loss_s1: 0.011300, loss_fp: 0.000718, loss_freq: 0.008891
[17:32:01.474] iteration 16756: loss: 0.071449, loss_s1: 0.070342, loss_fp: 0.000151, loss_freq: 0.039213
[17:32:02.129] iteration 16757: loss: 0.059581, loss_s1: 0.024279, loss_fp: 0.004238, loss_freq: 0.057445
[17:32:02.784] iteration 16758: loss: 0.057067, loss_s1: 0.035947, loss_fp: 0.001724, loss_freq: 0.034040
[17:32:03.423] iteration 16759: loss: 0.038911, loss_s1: 0.013399, loss_fp: 0.004523, loss_freq: 0.016318
[17:32:04.051] iteration 16760: loss: 0.089645, loss_s1: 0.064317, loss_fp: 0.001383, loss_freq: 0.078362
[17:32:04.667] iteration 16761: loss: 0.041642, loss_s1: 0.033621, loss_fp: 0.001733, loss_freq: 0.005587
[17:32:05.294] iteration 16762: loss: 0.047538, loss_s1: 0.026869, loss_fp: 0.005465, loss_freq: 0.020407
[17:32:05.918] iteration 16763: loss: 0.035874, loss_s1: 0.013173, loss_fp: 0.001938, loss_freq: 0.011010
[17:32:06.544] iteration 16764: loss: 0.059030, loss_s1: 0.054640, loss_fp: 0.001833, loss_freq: 0.021909
[17:32:07.173] iteration 16765: loss: 0.053470, loss_s1: 0.041515, loss_fp: 0.001630, loss_freq: 0.005961
[17:32:07.796] iteration 16766: loss: 0.048015, loss_s1: 0.038431, loss_fp: 0.001148, loss_freq: 0.009048
[17:32:08.420] iteration 16767: loss: 0.050968, loss_s1: 0.047957, loss_fp: 0.000718, loss_freq: 0.006926
[17:32:09.045] iteration 16768: loss: 0.174097, loss_s1: 0.089577, loss_fp: 0.002778, loss_freq: 0.224387
[17:32:09.668] iteration 16769: loss: 0.043590, loss_s1: 0.034320, loss_fp: 0.001070, loss_freq: 0.018612
[17:32:10.291] iteration 16770: loss: 0.069824, loss_s1: 0.075010, loss_fp: 0.002284, loss_freq: 0.023311
[17:32:10.918] iteration 16771: loss: 0.040862, loss_s1: 0.036730, loss_fp: 0.000655, loss_freq: 0.007289
[17:32:11.543] iteration 16772: loss: 0.079660, loss_s1: 0.075171, loss_fp: 0.011831, loss_freq: 0.034899
[17:32:12.167] iteration 16773: loss: 0.070612, loss_s1: 0.047628, loss_fp: 0.006079, loss_freq: 0.045303
[17:32:12.790] iteration 16774: loss: 0.056460, loss_s1: 0.042198, loss_fp: 0.000706, loss_freq: 0.009801
[17:32:13.423] iteration 16775: loss: 0.044189, loss_s1: 0.043918, loss_fp: 0.005114, loss_freq: 0.011878
[17:32:14.048] iteration 16776: loss: 0.071363, loss_s1: 0.044143, loss_fp: 0.020682, loss_freq: 0.022152
[17:32:14.670] iteration 16777: loss: 0.046991, loss_s1: 0.032620, loss_fp: 0.001566, loss_freq: 0.021192
[17:32:15.294] iteration 16778: loss: 0.045291, loss_s1: 0.033251, loss_fp: 0.000494, loss_freq: 0.012463
[17:32:15.925] iteration 16779: loss: 0.074144, loss_s1: 0.047895, loss_fp: 0.002128, loss_freq: 0.029209
[17:32:16.549] iteration 16780: loss: 0.084441, loss_s1: 0.086193, loss_fp: 0.008552, loss_freq: 0.039919
[17:32:17.175] iteration 16781: loss: 0.063869, loss_s1: 0.043395, loss_fp: 0.003152, loss_freq: 0.031728
[17:32:17.800] iteration 16782: loss: 0.057595, loss_s1: 0.028254, loss_fp: 0.004712, loss_freq: 0.027800
[17:32:18.428] iteration 16783: loss: 0.095290, loss_s1: 0.062719, loss_fp: 0.008884, loss_freq: 0.062772
[17:32:19.058] iteration 16784: loss: 0.066195, loss_s1: 0.051366, loss_fp: 0.002712, loss_freq: 0.031283
[17:32:19.682] iteration 16785: loss: 0.057469, loss_s1: 0.039268, loss_fp: 0.002926, loss_freq: 0.016915
[17:32:20.308] iteration 16786: loss: 0.080590, loss_s1: 0.066537, loss_fp: 0.008860, loss_freq: 0.055515
[17:32:20.925] iteration 16787: loss: 0.069195, loss_s1: 0.044787, loss_fp: 0.004010, loss_freq: 0.049097
[17:32:21.546] iteration 16788: loss: 0.053182, loss_s1: 0.021074, loss_fp: 0.005367, loss_freq: 0.038727
[17:32:22.171] iteration 16789: loss: 0.067699, loss_s1: 0.016722, loss_fp: 0.004082, loss_freq: 0.069803
[17:32:22.796] iteration 16790: loss: 0.044436, loss_s1: 0.031971, loss_fp: 0.001392, loss_freq: 0.008202
[17:32:23.423] iteration 16791: loss: 0.031546, loss_s1: 0.012955, loss_fp: 0.000766, loss_freq: 0.017374
[17:32:24.051] iteration 16792: loss: 0.057192, loss_s1: 0.050488, loss_fp: 0.001804, loss_freq: 0.027234
[17:32:24.677] iteration 16793: loss: 0.115444, loss_s1: 0.123566, loss_fp: 0.006092, loss_freq: 0.031336
[17:32:25.304] iteration 16794: loss: 0.064076, loss_s1: 0.050371, loss_fp: 0.002091, loss_freq: 0.033644
[17:32:25.924] iteration 16795: loss: 0.057796, loss_s1: 0.047832, loss_fp: 0.002324, loss_freq: 0.027573
[17:32:26.550] iteration 16796: loss: 0.043699, loss_s1: 0.027267, loss_fp: 0.001728, loss_freq: 0.013489
[17:32:27.174] iteration 16797: loss: 0.076058, loss_s1: 0.058458, loss_fp: 0.003034, loss_freq: 0.055787
[17:32:27.832] iteration 16798: loss: 0.065449, loss_s1: 0.020456, loss_fp: 0.003263, loss_freq: 0.067677
[17:32:28.478] iteration 16799: loss: 0.050075, loss_s1: 0.035495, loss_fp: 0.008932, loss_freq: 0.020419
[17:32:29.105] iteration 16800: loss: 0.045901, loss_s1: 0.024577, loss_fp: 0.004089, loss_freq: 0.020248
[17:32:32.229] iteration 16800 : mean_dice : 0.703081
[17:32:32.875] iteration 16801: loss: 0.030457, loss_s1: 0.016177, loss_fp: 0.002390, loss_freq: 0.003372
[17:32:33.496] iteration 16802: loss: 0.045759, loss_s1: 0.038671, loss_fp: 0.003831, loss_freq: 0.004835
[17:32:34.123] iteration 16803: loss: 0.050774, loss_s1: 0.042121, loss_fp: 0.003418, loss_freq: 0.019451
[17:32:34.751] iteration 16804: loss: 0.054725, loss_s1: 0.050474, loss_fp: 0.001870, loss_freq: 0.023630
[17:32:35.377] iteration 16805: loss: 0.047247, loss_s1: 0.018746, loss_fp: 0.000765, loss_freq: 0.013255
[17:32:35.999] iteration 16806: loss: 0.070357, loss_s1: 0.066899, loss_fp: 0.003942, loss_freq: 0.037399
[17:32:36.624] iteration 16807: loss: 0.054244, loss_s1: 0.046470, loss_fp: 0.002749, loss_freq: 0.019271
[17:32:37.265] iteration 16808: loss: 0.054519, loss_s1: 0.053028, loss_fp: 0.003959, loss_freq: 0.021310
[17:32:37.891] iteration 16809: loss: 0.077618, loss_s1: 0.072759, loss_fp: 0.001380, loss_freq: 0.037109
[17:32:38.521] iteration 16810: loss: 0.079495, loss_s1: 0.051305, loss_fp: 0.004046, loss_freq: 0.054791
[17:32:39.140] iteration 16811: loss: 0.066219, loss_s1: 0.048508, loss_fp: 0.003833, loss_freq: 0.037562
[17:32:39.763] iteration 16812: loss: 0.066437, loss_s1: 0.049873, loss_fp: 0.011929, loss_freq: 0.033247
[17:32:40.386] iteration 16813: loss: 0.072371, loss_s1: 0.056539, loss_fp: 0.021062, loss_freq: 0.026352
[17:32:41.011] iteration 16814: loss: 0.058146, loss_s1: 0.036057, loss_fp: 0.005191, loss_freq: 0.022456
[17:32:41.636] iteration 16815: loss: 0.082054, loss_s1: 0.047045, loss_fp: 0.004950, loss_freq: 0.052520
[17:32:42.263] iteration 16816: loss: 0.051759, loss_s1: 0.047479, loss_fp: 0.001915, loss_freq: 0.018044
[17:32:42.891] iteration 16817: loss: 0.068551, loss_s1: 0.049214, loss_fp: 0.000946, loss_freq: 0.014731
[17:32:43.532] iteration 16818: loss: 0.044057, loss_s1: 0.026573, loss_fp: 0.006285, loss_freq: 0.016823
[17:32:44.175] iteration 16819: loss: 0.042476, loss_s1: 0.026106, loss_fp: 0.001395, loss_freq: 0.006069
[17:32:44.817] iteration 16820: loss: 0.077967, loss_s1: 0.058381, loss_fp: 0.015627, loss_freq: 0.028307
[17:32:45.454] iteration 16821: loss: 0.066954, loss_s1: 0.055001, loss_fp: 0.001625, loss_freq: 0.037945
[17:32:46.092] iteration 16822: loss: 0.110123, loss_s1: 0.103531, loss_fp: 0.004722, loss_freq: 0.062927
[17:32:46.730] iteration 16823: loss: 0.047826, loss_s1: 0.047524, loss_fp: 0.010808, loss_freq: 0.008009
[17:32:47.376] iteration 16824: loss: 0.054565, loss_s1: 0.042358, loss_fp: 0.001216, loss_freq: 0.016328
[17:32:48.019] iteration 16825: loss: 0.089265, loss_s1: 0.049815, loss_fp: 0.003414, loss_freq: 0.071072
[17:32:48.660] iteration 16826: loss: 0.074294, loss_s1: 0.085294, loss_fp: 0.002600, loss_freq: 0.027361
[17:32:49.294] iteration 16827: loss: 0.102606, loss_s1: 0.104060, loss_fp: 0.010265, loss_freq: 0.052671
[17:32:49.933] iteration 16828: loss: 0.055008, loss_s1: 0.053114, loss_fp: 0.002596, loss_freq: 0.013398
[17:32:50.572] iteration 16829: loss: 0.085157, loss_s1: 0.071350, loss_fp: 0.003496, loss_freq: 0.058191
[17:32:51.212] iteration 16830: loss: 0.033447, loss_s1: 0.006580, loss_fp: 0.006574, loss_freq: 0.016864
[17:32:51.860] iteration 16831: loss: 0.103029, loss_s1: 0.042229, loss_fp: 0.024295, loss_freq: 0.024602
[17:32:52.507] iteration 16832: loss: 0.040840, loss_s1: 0.020369, loss_fp: 0.003754, loss_freq: 0.018149
[17:32:53.165] iteration 16833: loss: 0.073650, loss_s1: 0.039478, loss_fp: 0.002167, loss_freq: 0.068423
[17:32:53.827] iteration 16834: loss: 0.088937, loss_s1: 0.096427, loss_fp: 0.003836, loss_freq: 0.031457
[17:32:54.489] iteration 16835: loss: 0.067090, loss_s1: 0.062880, loss_fp: 0.001474, loss_freq: 0.017994
[17:32:55.150] iteration 16836: loss: 0.055568, loss_s1: 0.021957, loss_fp: 0.002997, loss_freq: 0.025217
[17:32:55.818] iteration 16837: loss: 0.074404, loss_s1: 0.055896, loss_fp: 0.003615, loss_freq: 0.031265
[17:32:56.486] iteration 16838: loss: 0.036233, loss_s1: 0.020417, loss_fp: 0.000840, loss_freq: 0.015309
[17:32:57.128] iteration 16839: loss: 0.093087, loss_s1: 0.089216, loss_fp: 0.003335, loss_freq: 0.034759
[17:32:57.787] iteration 16840: loss: 0.056053, loss_s1: 0.048178, loss_fp: 0.001380, loss_freq: 0.030533
[17:32:58.448] iteration 16841: loss: 0.033881, loss_s1: 0.009275, loss_fp: 0.001309, loss_freq: 0.017511
[17:32:59.106] iteration 16842: loss: 0.042593, loss_s1: 0.009343, loss_fp: 0.000175, loss_freq: 0.033942
[17:32:59.764] iteration 16843: loss: 0.034327, loss_s1: 0.021736, loss_fp: 0.000933, loss_freq: 0.012675
[17:33:00.390] iteration 16844: loss: 0.043164, loss_s1: 0.031903, loss_fp: 0.004505, loss_freq: 0.008711
[17:33:01.019] iteration 16845: loss: 0.057366, loss_s1: 0.031602, loss_fp: 0.003165, loss_freq: 0.046805
[17:33:01.643] iteration 16846: loss: 0.060946, loss_s1: 0.036961, loss_fp: 0.003668, loss_freq: 0.037351
[17:33:02.268] iteration 16847: loss: 0.072774, loss_s1: 0.062929, loss_fp: 0.006544, loss_freq: 0.041904
[17:33:02.896] iteration 16848: loss: 0.062679, loss_s1: 0.052413, loss_fp: 0.001474, loss_freq: 0.034575
[17:33:03.520] iteration 16849: loss: 0.056509, loss_s1: 0.046860, loss_fp: 0.003268, loss_freq: 0.015836
[17:33:04.149] iteration 16850: loss: 0.039138, loss_s1: 0.012946, loss_fp: 0.003395, loss_freq: 0.014334
[17:33:04.784] iteration 16851: loss: 0.053258, loss_s1: 0.031714, loss_fp: 0.001925, loss_freq: 0.016413
[17:33:05.421] iteration 16852: loss: 0.054028, loss_s1: 0.026616, loss_fp: 0.001381, loss_freq: 0.027297
[17:33:06.071] iteration 16853: loss: 0.125039, loss_s1: 0.102717, loss_fp: 0.002198, loss_freq: 0.090967
[17:33:06.703] iteration 16854: loss: 0.044457, loss_s1: 0.025347, loss_fp: 0.003199, loss_freq: 0.027401
[17:33:07.328] iteration 16855: loss: 0.038309, loss_s1: 0.016209, loss_fp: 0.000383, loss_freq: 0.014748
[17:33:07.953] iteration 16856: loss: 0.081766, loss_s1: 0.049585, loss_fp: 0.009406, loss_freq: 0.067224
[17:33:08.580] iteration 16857: loss: 0.086589, loss_s1: 0.071986, loss_fp: 0.005196, loss_freq: 0.027456
[17:33:09.206] iteration 16858: loss: 0.058734, loss_s1: 0.050959, loss_fp: 0.000829, loss_freq: 0.011237
[17:33:09.829] iteration 16859: loss: 0.030392, loss_s1: 0.016584, loss_fp: 0.001431, loss_freq: 0.006891
[17:33:10.457] iteration 16860: loss: 0.049533, loss_s1: 0.037318, loss_fp: 0.002942, loss_freq: 0.018714
[17:33:11.082] iteration 16861: loss: 0.048929, loss_s1: 0.019249, loss_fp: 0.023355, loss_freq: 0.013145
[17:33:11.708] iteration 16862: loss: 0.028592, loss_s1: 0.014344, loss_fp: 0.002245, loss_freq: 0.013389
[17:33:12.335] iteration 16863: loss: 0.065202, loss_s1: 0.044371, loss_fp: 0.001080, loss_freq: 0.024453
[17:33:12.962] iteration 16864: loss: 0.075889, loss_s1: 0.045701, loss_fp: 0.003169, loss_freq: 0.066489
[17:33:13.589] iteration 16865: loss: 0.046140, loss_s1: 0.035857, loss_fp: 0.004651, loss_freq: 0.019742
[17:33:14.216] iteration 16866: loss: 0.097620, loss_s1: 0.066820, loss_fp: 0.008393, loss_freq: 0.064047
[17:33:14.839] iteration 16867: loss: 0.086039, loss_s1: 0.089680, loss_fp: 0.016501, loss_freq: 0.021004
[17:33:15.462] iteration 16868: loss: 0.062100, loss_s1: 0.075835, loss_fp: 0.002505, loss_freq: 0.009329
[17:33:16.086] iteration 16869: loss: 0.052373, loss_s1: 0.023460, loss_fp: 0.004401, loss_freq: 0.035207
[17:33:16.714] iteration 16870: loss: 0.054642, loss_s1: 0.045842, loss_fp: 0.006110, loss_freq: 0.018026
[17:33:17.340] iteration 16871: loss: 0.066925, loss_s1: 0.082889, loss_fp: 0.000566, loss_freq: 0.013186
[17:33:17.975] iteration 16872: loss: 0.120156, loss_s1: 0.118189, loss_fp: 0.003396, loss_freq: 0.056238
[17:33:18.604] iteration 16873: loss: 0.050520, loss_s1: 0.028519, loss_fp: 0.001965, loss_freq: 0.025900
[17:33:19.234] iteration 16874: loss: 0.042742, loss_s1: 0.040712, loss_fp: 0.001238, loss_freq: 0.010794
[17:33:19.858] iteration 16875: loss: 0.081228, loss_s1: 0.063088, loss_fp: 0.003704, loss_freq: 0.046862
[17:33:20.482] iteration 16876: loss: 0.105395, loss_s1: 0.100326, loss_fp: 0.000642, loss_freq: 0.042462
[17:33:21.107] iteration 16877: loss: 0.052233, loss_s1: 0.025356, loss_fp: 0.001997, loss_freq: 0.034406
[17:33:21.730] iteration 16878: loss: 0.053579, loss_s1: 0.035072, loss_fp: 0.004434, loss_freq: 0.011741
[17:33:22.366] iteration 16879: loss: 0.074202, loss_s1: 0.062169, loss_fp: 0.003519, loss_freq: 0.042660
[17:33:22.990] iteration 16880: loss: 0.063130, loss_s1: 0.058462, loss_fp: 0.001722, loss_freq: 0.036475
[17:33:23.619] iteration 16881: loss: 0.042014, loss_s1: 0.014079, loss_fp: 0.001041, loss_freq: 0.017005
[17:33:24.250] iteration 16882: loss: 0.046965, loss_s1: 0.024460, loss_fp: 0.005467, loss_freq: 0.031735
[17:33:24.891] iteration 16883: loss: 0.036050, loss_s1: 0.019808, loss_fp: 0.002637, loss_freq: 0.011330
[17:33:25.521] iteration 16884: loss: 0.085446, loss_s1: 0.037874, loss_fp: 0.003355, loss_freq: 0.056877
[17:33:26.149] iteration 16885: loss: 0.065156, loss_s1: 0.055809, loss_fp: 0.003339, loss_freq: 0.025731
[17:33:26.775] iteration 16886: loss: 0.070360, loss_s1: 0.038351, loss_fp: 0.021885, loss_freq: 0.016956
[17:33:27.408] iteration 16887: loss: 0.064137, loss_s1: 0.032182, loss_fp: 0.007210, loss_freq: 0.044352
[17:33:28.034] iteration 16888: loss: 0.076374, loss_s1: 0.085784, loss_fp: 0.001663, loss_freq: 0.018616
[17:33:28.663] iteration 16889: loss: 0.053201, loss_s1: 0.048010, loss_fp: 0.000668, loss_freq: 0.006942
[17:33:29.294] iteration 16890: loss: 0.110851, loss_s1: 0.126415, loss_fp: 0.001783, loss_freq: 0.026410
[17:33:29.922] iteration 16891: loss: 0.100930, loss_s1: 0.084452, loss_fp: 0.002443, loss_freq: 0.073543
[17:33:30.552] iteration 16892: loss: 0.034976, loss_s1: 0.020582, loss_fp: 0.001333, loss_freq: 0.010271
[17:33:31.181] iteration 16893: loss: 0.055392, loss_s1: 0.048432, loss_fp: 0.002561, loss_freq: 0.014029
[17:33:31.805] iteration 16894: loss: 0.110055, loss_s1: 0.063185, loss_fp: 0.003289, loss_freq: 0.074273
[17:33:32.467] iteration 16895: loss: 0.071236, loss_s1: 0.063058, loss_fp: 0.004327, loss_freq: 0.032324
[17:33:33.115] iteration 16896: loss: 0.089659, loss_s1: 0.064705, loss_fp: 0.008666, loss_freq: 0.066769
[17:33:33.742] iteration 16897: loss: 0.059960, loss_s1: 0.039977, loss_fp: 0.003327, loss_freq: 0.028031
[17:33:34.365] iteration 16898: loss: 0.059933, loss_s1: 0.052792, loss_fp: 0.003469, loss_freq: 0.020064
[17:33:34.991] iteration 16899: loss: 0.038305, loss_s1: 0.033833, loss_fp: 0.001544, loss_freq: 0.005426
[17:33:35.618] iteration 16900: loss: 0.044836, loss_s1: 0.031891, loss_fp: 0.001857, loss_freq: 0.019375
[17:33:36.242] iteration 16901: loss: 0.048285, loss_s1: 0.032206, loss_fp: 0.001313, loss_freq: 0.012874
[17:33:36.867] iteration 16902: loss: 0.082595, loss_s1: 0.061494, loss_fp: 0.001971, loss_freq: 0.052924
[17:33:37.529] iteration 16903: loss: 0.037656, loss_s1: 0.020403, loss_fp: 0.003533, loss_freq: 0.012823
[17:33:38.190] iteration 16904: loss: 0.064039, loss_s1: 0.053758, loss_fp: 0.001112, loss_freq: 0.029620
[17:33:38.853] iteration 16905: loss: 0.077009, loss_s1: 0.042491, loss_fp: 0.000821, loss_freq: 0.059500
[17:33:39.882] iteration 16906: loss: 0.053051, loss_s1: 0.046428, loss_fp: 0.002552, loss_freq: 0.016668
[17:33:40.542] iteration 16907: loss: 0.073723, loss_s1: 0.070442, loss_fp: 0.008064, loss_freq: 0.023509
[17:33:41.193] iteration 16908: loss: 0.044418, loss_s1: 0.026772, loss_fp: 0.000636, loss_freq: 0.014484
[17:33:41.851] iteration 16909: loss: 0.041011, loss_s1: 0.020961, loss_fp: 0.001441, loss_freq: 0.012956
[17:33:42.501] iteration 16910: loss: 0.042679, loss_s1: 0.018866, loss_fp: 0.002827, loss_freq: 0.029471
[17:33:43.131] iteration 16911: loss: 0.101003, loss_s1: 0.074994, loss_fp: 0.004615, loss_freq: 0.062363
[17:33:43.753] iteration 16912: loss: 0.045670, loss_s1: 0.038185, loss_fp: 0.002840, loss_freq: 0.020372
[17:33:44.379] iteration 16913: loss: 0.050853, loss_s1: 0.031738, loss_fp: 0.000555, loss_freq: 0.009249
[17:33:45.009] iteration 16914: loss: 0.031963, loss_s1: 0.019539, loss_fp: 0.001607, loss_freq: 0.009888
[17:33:45.634] iteration 16915: loss: 0.070558, loss_s1: 0.062582, loss_fp: 0.005387, loss_freq: 0.033336
[17:33:46.261] iteration 16916: loss: 0.030516, loss_s1: 0.012568, loss_fp: 0.002009, loss_freq: 0.006364
[17:33:46.887] iteration 16917: loss: 0.051382, loss_s1: 0.030332, loss_fp: 0.002719, loss_freq: 0.026169
[17:33:47.514] iteration 16918: loss: 0.069585, loss_s1: 0.047388, loss_fp: 0.008246, loss_freq: 0.048505
[17:33:48.163] iteration 16919: loss: 0.072817, loss_s1: 0.035547, loss_fp: 0.003518, loss_freq: 0.050618
[17:33:48.788] iteration 16920: loss: 0.057302, loss_s1: 0.058563, loss_fp: 0.002984, loss_freq: 0.012363
[17:33:49.414] iteration 16921: loss: 0.096471, loss_s1: 0.073781, loss_fp: 0.004589, loss_freq: 0.078320
[17:33:50.038] iteration 16922: loss: 0.054473, loss_s1: 0.045699, loss_fp: 0.002229, loss_freq: 0.009481
[17:33:50.659] iteration 16923: loss: 0.066555, loss_s1: 0.050740, loss_fp: 0.005954, loss_freq: 0.033071
[17:33:51.283] iteration 16924: loss: 0.036675, loss_s1: 0.009523, loss_fp: 0.006470, loss_freq: 0.020120
[17:33:51.905] iteration 16925: loss: 0.086156, loss_s1: 0.053926, loss_fp: 0.002623, loss_freq: 0.027582
[17:33:52.531] iteration 16926: loss: 0.070668, loss_s1: 0.052252, loss_fp: 0.005260, loss_freq: 0.011469
[17:33:53.156] iteration 16927: loss: 0.050170, loss_s1: 0.035989, loss_fp: 0.002190, loss_freq: 0.010275
[17:33:53.780] iteration 16928: loss: 0.071549, loss_s1: 0.015928, loss_fp: 0.004095, loss_freq: 0.010548
[17:33:54.405] iteration 16929: loss: 0.105498, loss_s1: 0.058952, loss_fp: 0.022357, loss_freq: 0.093386
[17:33:55.027] iteration 16930: loss: 0.057961, loss_s1: 0.059277, loss_fp: 0.005825, loss_freq: 0.014625
[17:33:55.649] iteration 16931: loss: 0.053281, loss_s1: 0.035372, loss_fp: 0.001038, loss_freq: 0.032130
[17:33:56.273] iteration 16932: loss: 0.038136, loss_s1: 0.030261, loss_fp: 0.000443, loss_freq: 0.005557
[17:33:56.899] iteration 16933: loss: 0.087522, loss_s1: 0.061472, loss_fp: 0.005274, loss_freq: 0.072737
[17:33:57.577] iteration 16934: loss: 0.066702, loss_s1: 0.054158, loss_fp: 0.007428, loss_freq: 0.037148
[17:33:58.202] iteration 16935: loss: 0.031636, loss_s1: 0.019849, loss_fp: 0.000990, loss_freq: 0.006282
[17:33:58.828] iteration 16936: loss: 0.038956, loss_s1: 0.024896, loss_fp: 0.002220, loss_freq: 0.013970
[17:33:59.451] iteration 16937: loss: 0.059832, loss_s1: 0.031973, loss_fp: 0.004325, loss_freq: 0.043299
[17:34:00.075] iteration 16938: loss: 0.054150, loss_s1: 0.037060, loss_fp: 0.006448, loss_freq: 0.026105
[17:34:00.699] iteration 16939: loss: 0.045461, loss_s1: 0.049008, loss_fp: 0.002273, loss_freq: 0.008523
[17:34:01.318] iteration 16940: loss: 0.059950, loss_s1: 0.037925, loss_fp: 0.006177, loss_freq: 0.019652
[17:34:01.943] iteration 16941: loss: 0.053112, loss_s1: 0.033150, loss_fp: 0.003561, loss_freq: 0.033397
[17:34:02.569] iteration 16942: loss: 0.081041, loss_s1: 0.054774, loss_fp: 0.010494, loss_freq: 0.059633
[17:34:03.192] iteration 16943: loss: 0.062637, loss_s1: 0.046577, loss_fp: 0.005602, loss_freq: 0.026194
[17:34:03.813] iteration 16944: loss: 0.090463, loss_s1: 0.066487, loss_fp: 0.001452, loss_freq: 0.059673
[17:34:04.434] iteration 16945: loss: 0.039657, loss_s1: 0.021317, loss_fp: 0.003783, loss_freq: 0.019218
[17:34:05.058] iteration 16946: loss: 0.065949, loss_s1: 0.047279, loss_fp: 0.002961, loss_freq: 0.021301
[17:34:05.681] iteration 16947: loss: 0.125651, loss_s1: 0.104716, loss_fp: 0.003201, loss_freq: 0.108974
[17:34:06.309] iteration 16948: loss: 0.059068, loss_s1: 0.030405, loss_fp: 0.006908, loss_freq: 0.043045
[17:34:06.932] iteration 16949: loss: 0.069459, loss_s1: 0.057005, loss_fp: 0.004770, loss_freq: 0.049419
[17:34:07.555] iteration 16950: loss: 0.069608, loss_s1: 0.034408, loss_fp: 0.005660, loss_freq: 0.058000
[17:34:08.181] iteration 16951: loss: 0.064346, loss_s1: 0.068225, loss_fp: 0.002138, loss_freq: 0.005134
[17:34:08.858] iteration 16952: loss: 0.038715, loss_s1: 0.034568, loss_fp: 0.000970, loss_freq: 0.009440
[17:34:09.513] iteration 16953: loss: 0.080978, loss_s1: 0.074678, loss_fp: 0.000897, loss_freq: 0.055686
[17:34:10.168] iteration 16954: loss: 0.068679, loss_s1: 0.042759, loss_fp: 0.000507, loss_freq: 0.021220
[17:34:10.830] iteration 16955: loss: 0.081096, loss_s1: 0.069616, loss_fp: 0.011800, loss_freq: 0.053208
[17:34:11.486] iteration 16956: loss: 0.067000, loss_s1: 0.082751, loss_fp: 0.009440, loss_freq: 0.009480
[17:34:12.143] iteration 16957: loss: 0.048451, loss_s1: 0.028814, loss_fp: 0.003483, loss_freq: 0.020968
[17:34:12.775] iteration 16958: loss: 0.052048, loss_s1: 0.024828, loss_fp: 0.001082, loss_freq: 0.039861
[17:34:13.406] iteration 16959: loss: 0.052956, loss_s1: 0.032862, loss_fp: 0.003771, loss_freq: 0.027914
[17:34:14.027] iteration 16960: loss: 0.039740, loss_s1: 0.014532, loss_fp: 0.001376, loss_freq: 0.007010
[17:34:14.651] iteration 16961: loss: 0.059927, loss_s1: 0.031128, loss_fp: 0.007041, loss_freq: 0.037486
[17:34:15.278] iteration 16962: loss: 0.034918, loss_s1: 0.006980, loss_fp: 0.003301, loss_freq: 0.005423
[17:34:15.908] iteration 16963: loss: 0.059584, loss_s1: 0.046530, loss_fp: 0.001763, loss_freq: 0.019246
[17:34:16.532] iteration 16964: loss: 0.033341, loss_s1: 0.009756, loss_fp: 0.002014, loss_freq: 0.010411
[17:34:17.169] iteration 16965: loss: 0.043394, loss_s1: 0.031415, loss_fp: 0.002769, loss_freq: 0.020647
[17:34:17.793] iteration 16966: loss: 0.060438, loss_s1: 0.043623, loss_fp: 0.003764, loss_freq: 0.019054
[17:34:18.420] iteration 16967: loss: 0.047843, loss_s1: 0.030467, loss_fp: 0.006514, loss_freq: 0.017636
[17:34:19.060] iteration 16968: loss: 0.068393, loss_s1: 0.040509, loss_fp: 0.004907, loss_freq: 0.040508
[17:34:19.728] iteration 16969: loss: 0.045974, loss_s1: 0.023815, loss_fp: 0.006001, loss_freq: 0.029636
[17:34:20.361] iteration 16970: loss: 0.046937, loss_s1: 0.042745, loss_fp: 0.001688, loss_freq: 0.007141
[17:34:20.996] iteration 16971: loss: 0.068091, loss_s1: 0.027207, loss_fp: 0.012395, loss_freq: 0.051771
[17:34:21.628] iteration 16972: loss: 0.052212, loss_s1: 0.040249, loss_fp: 0.002355, loss_freq: 0.021784
[17:34:22.254] iteration 16973: loss: 0.054351, loss_s1: 0.032812, loss_fp: 0.001326, loss_freq: 0.043485
[17:34:22.885] iteration 16974: loss: 0.061664, loss_s1: 0.058619, loss_fp: 0.001464, loss_freq: 0.019767
[17:34:23.516] iteration 16975: loss: 0.060953, loss_s1: 0.042997, loss_fp: 0.001402, loss_freq: 0.028042
[17:34:24.148] iteration 16976: loss: 0.087419, loss_s1: 0.051453, loss_fp: 0.008208, loss_freq: 0.068795
[17:34:24.780] iteration 16977: loss: 0.067255, loss_s1: 0.039967, loss_fp: 0.002294, loss_freq: 0.015722
[17:34:25.407] iteration 16978: loss: 0.044012, loss_s1: 0.021744, loss_fp: 0.001244, loss_freq: 0.030540
[17:34:26.039] iteration 16979: loss: 0.040938, loss_s1: 0.021122, loss_fp: 0.002516, loss_freq: 0.006932
[17:34:26.667] iteration 16980: loss: 0.054896, loss_s1: 0.050186, loss_fp: 0.002516, loss_freq: 0.011917
[17:34:27.293] iteration 16981: loss: 0.080653, loss_s1: 0.089525, loss_fp: 0.003988, loss_freq: 0.017780
[17:34:27.920] iteration 16982: loss: 0.036308, loss_s1: 0.014467, loss_fp: 0.001068, loss_freq: 0.012811
[17:34:28.549] iteration 16983: loss: 0.058270, loss_s1: 0.053342, loss_fp: 0.001574, loss_freq: 0.031076
[17:34:29.176] iteration 16984: loss: 0.044795, loss_s1: 0.031849, loss_fp: 0.002519, loss_freq: 0.007429
[17:34:29.818] iteration 16985: loss: 0.094288, loss_s1: 0.104020, loss_fp: 0.005888, loss_freq: 0.039020
[17:34:30.450] iteration 16986: loss: 0.067423, loss_s1: 0.042429, loss_fp: 0.004436, loss_freq: 0.043278
[17:34:31.075] iteration 16987: loss: 0.116044, loss_s1: 0.120038, loss_fp: 0.006105, loss_freq: 0.061796
[17:34:31.705] iteration 16988: loss: 0.102952, loss_s1: 0.134337, loss_fp: 0.010834, loss_freq: 0.026957
[17:34:32.332] iteration 16989: loss: 0.057920, loss_s1: 0.036912, loss_fp: 0.002551, loss_freq: 0.029370
[17:34:32.963] iteration 16990: loss: 0.095909, loss_s1: 0.108240, loss_fp: 0.001574, loss_freq: 0.051381
[17:34:33.588] iteration 16991: loss: 0.039813, loss_s1: 0.028995, loss_fp: 0.001904, loss_freq: 0.014837
[17:34:34.208] iteration 16992: loss: 0.042582, loss_s1: 0.027687, loss_fp: 0.004190, loss_freq: 0.005130
[17:34:34.835] iteration 16993: loss: 0.048840, loss_s1: 0.049341, loss_fp: 0.000494, loss_freq: 0.002950
[17:34:35.460] iteration 16994: loss: 0.058998, loss_s1: 0.060148, loss_fp: 0.000979, loss_freq: 0.020959
[17:34:36.088] iteration 16995: loss: 0.051456, loss_s1: 0.032082, loss_fp: 0.000401, loss_freq: 0.022158
[17:34:36.712] iteration 16996: loss: 0.063970, loss_s1: 0.065159, loss_fp: 0.006701, loss_freq: 0.017637
[17:34:37.339] iteration 16997: loss: 0.068384, loss_s1: 0.067482, loss_fp: 0.003754, loss_freq: 0.023464
[17:34:37.964] iteration 16998: loss: 0.076845, loss_s1: 0.064012, loss_fp: 0.001091, loss_freq: 0.021296
[17:34:38.587] iteration 16999: loss: 0.040890, loss_s1: 0.025097, loss_fp: 0.003395, loss_freq: 0.019356
[17:34:39.210] iteration 17000: loss: 0.063592, loss_s1: 0.065870, loss_fp: 0.006591, loss_freq: 0.025970
[17:34:42.390] iteration 17000 : mean_dice : 0.693624
[17:34:43.034] iteration 17001: loss: 0.066719, loss_s1: 0.045533, loss_fp: 0.002795, loss_freq: 0.036902
[17:34:43.663] iteration 17002: loss: 0.036874, loss_s1: 0.014048, loss_fp: 0.001339, loss_freq: 0.017365
[17:34:44.325] iteration 17003: loss: 0.049896, loss_s1: 0.018479, loss_fp: 0.001111, loss_freq: 0.028433
[17:34:44.971] iteration 17004: loss: 0.080755, loss_s1: 0.053942, loss_fp: 0.002559, loss_freq: 0.039694
[17:34:45.605] iteration 17005: loss: 0.050212, loss_s1: 0.038900, loss_fp: 0.002598, loss_freq: 0.022897
[17:34:46.231] iteration 17006: loss: 0.044219, loss_s1: 0.045846, loss_fp: 0.004223, loss_freq: 0.009746
[17:34:46.892] iteration 17007: loss: 0.096372, loss_s1: 0.051991, loss_fp: 0.006115, loss_freq: 0.081744
[17:34:47.556] iteration 17008: loss: 0.093873, loss_s1: 0.086737, loss_fp: 0.004786, loss_freq: 0.057983
[17:34:48.223] iteration 17009: loss: 0.055977, loss_s1: 0.024802, loss_fp: 0.004089, loss_freq: 0.046918
[17:34:48.875] iteration 17010: loss: 0.049410, loss_s1: 0.027427, loss_fp: 0.003675, loss_freq: 0.013279
[17:34:49.507] iteration 17011: loss: 0.054549, loss_s1: 0.029370, loss_fp: 0.002559, loss_freq: 0.044027
[17:34:50.137] iteration 17012: loss: 0.031739, loss_s1: 0.021617, loss_fp: 0.002227, loss_freq: 0.005181
[17:34:50.769] iteration 17013: loss: 0.099467, loss_s1: 0.086110, loss_fp: 0.001739, loss_freq: 0.066141
[17:34:51.395] iteration 17014: loss: 0.146329, loss_s1: 0.123327, loss_fp: 0.004630, loss_freq: 0.110404
[17:34:52.023] iteration 17015: loss: 0.064946, loss_s1: 0.039275, loss_fp: 0.016547, loss_freq: 0.038838
[17:34:52.646] iteration 17016: loss: 0.059128, loss_s1: 0.038197, loss_fp: 0.005163, loss_freq: 0.017687
[17:34:53.272] iteration 17017: loss: 0.068779, loss_s1: 0.040893, loss_fp: 0.009385, loss_freq: 0.047403
[17:34:53.902] iteration 17018: loss: 0.090382, loss_s1: 0.056356, loss_fp: 0.011919, loss_freq: 0.017460
[17:34:54.534] iteration 17019: loss: 0.055325, loss_s1: 0.037756, loss_fp: 0.002290, loss_freq: 0.027279
[17:34:55.159] iteration 17020: loss: 0.042842, loss_s1: 0.028458, loss_fp: 0.002467, loss_freq: 0.008190
[17:34:55.784] iteration 17021: loss: 0.073848, loss_s1: 0.057881, loss_fp: 0.001901, loss_freq: 0.038150
[17:34:56.410] iteration 17022: loss: 0.049116, loss_s1: 0.036408, loss_fp: 0.003607, loss_freq: 0.011936
[17:34:57.035] iteration 17023: loss: 0.058120, loss_s1: 0.032124, loss_fp: 0.001385, loss_freq: 0.045904
[17:34:57.659] iteration 17024: loss: 0.059177, loss_s1: 0.057905, loss_fp: 0.003954, loss_freq: 0.014258
[17:34:58.285] iteration 17025: loss: 0.063119, loss_s1: 0.049266, loss_fp: 0.001772, loss_freq: 0.040728
[17:34:58.907] iteration 17026: loss: 0.088509, loss_s1: 0.057170, loss_fp: 0.001531, loss_freq: 0.068951
[17:34:59.533] iteration 17027: loss: 0.065975, loss_s1: 0.045217, loss_fp: 0.011008, loss_freq: 0.012747
[17:35:00.164] iteration 17028: loss: 0.045447, loss_s1: 0.034213, loss_fp: 0.004259, loss_freq: 0.006687
[17:35:00.789] iteration 17029: loss: 0.081379, loss_s1: 0.081137, loss_fp: 0.005316, loss_freq: 0.016843
[17:35:01.416] iteration 17030: loss: 0.061710, loss_s1: 0.034538, loss_fp: 0.003055, loss_freq: 0.036196
[17:35:02.041] iteration 17031: loss: 0.087492, loss_s1: 0.076128, loss_fp: 0.002120, loss_freq: 0.043704
[17:35:02.664] iteration 17032: loss: 0.059422, loss_s1: 0.026325, loss_fp: 0.007140, loss_freq: 0.022574
[17:35:03.288] iteration 17033: loss: 0.150605, loss_s1: 0.131284, loss_fp: 0.022855, loss_freq: 0.096493
[17:35:03.912] iteration 17034: loss: 0.075307, loss_s1: 0.064157, loss_fp: 0.005826, loss_freq: 0.037931
[17:35:04.539] iteration 17035: loss: 0.056754, loss_s1: 0.053137, loss_fp: 0.002663, loss_freq: 0.020449
[17:35:05.220] iteration 17036: loss: 0.103742, loss_s1: 0.079551, loss_fp: 0.007792, loss_freq: 0.084381
[17:35:05.879] iteration 17037: loss: 0.065078, loss_s1: 0.041531, loss_fp: 0.015412, loss_freq: 0.020078
[17:35:06.536] iteration 17038: loss: 0.064360, loss_s1: 0.075300, loss_fp: 0.002387, loss_freq: 0.013769
[17:35:07.195] iteration 17039: loss: 0.052743, loss_s1: 0.049127, loss_fp: 0.004519, loss_freq: 0.021425
[17:35:07.856] iteration 17040: loss: 0.074900, loss_s1: 0.055045, loss_fp: 0.004527, loss_freq: 0.048201
[17:35:08.519] iteration 17041: loss: 0.065327, loss_s1: 0.076672, loss_fp: 0.002103, loss_freq: 0.014893
[17:35:09.183] iteration 17042: loss: 0.057301, loss_s1: 0.039474, loss_fp: 0.001209, loss_freq: 0.015705
[17:35:09.846] iteration 17043: loss: 0.041574, loss_s1: 0.021746, loss_fp: 0.003577, loss_freq: 0.017691
[17:35:10.500] iteration 17044: loss: 0.052028, loss_s1: 0.027579, loss_fp: 0.006947, loss_freq: 0.033318
[17:35:11.134] iteration 17045: loss: 0.075629, loss_s1: 0.062997, loss_fp: 0.002780, loss_freq: 0.040090
[17:35:11.765] iteration 17046: loss: 0.072725, loss_s1: 0.075075, loss_fp: 0.004766, loss_freq: 0.030334
[17:35:12.389] iteration 17047: loss: 0.070398, loss_s1: 0.060309, loss_fp: 0.008929, loss_freq: 0.025276
[17:35:13.004] iteration 17048: loss: 0.057381, loss_s1: 0.025466, loss_fp: 0.003599, loss_freq: 0.040950
[17:35:13.625] iteration 17049: loss: 0.058320, loss_s1: 0.043202, loss_fp: 0.002161, loss_freq: 0.023898
[17:35:14.248] iteration 17050: loss: 0.053476, loss_s1: 0.044221, loss_fp: 0.001711, loss_freq: 0.017670
[17:35:14.870] iteration 17051: loss: 0.072750, loss_s1: 0.038716, loss_fp: 0.010234, loss_freq: 0.029775
[17:35:15.490] iteration 17052: loss: 0.095408, loss_s1: 0.106477, loss_fp: 0.002716, loss_freq: 0.045179
[17:35:16.112] iteration 17053: loss: 0.049889, loss_s1: 0.040264, loss_fp: 0.002927, loss_freq: 0.022966
[17:35:16.733] iteration 17054: loss: 0.035596, loss_s1: 0.015233, loss_fp: 0.002858, loss_freq: 0.011174
[17:35:17.358] iteration 17055: loss: 0.076890, loss_s1: 0.069026, loss_fp: 0.001820, loss_freq: 0.043202
[17:35:17.978] iteration 17056: loss: 0.062691, loss_s1: 0.047643, loss_fp: 0.009399, loss_freq: 0.011287
[17:35:18.606] iteration 17057: loss: 0.103908, loss_s1: 0.110101, loss_fp: 0.008659, loss_freq: 0.049672
[17:35:19.232] iteration 17058: loss: 0.039138, loss_s1: 0.022259, loss_fp: 0.001983, loss_freq: 0.015972
[17:35:19.857] iteration 17059: loss: 0.082939, loss_s1: 0.063736, loss_fp: 0.008727, loss_freq: 0.024221
[17:35:20.483] iteration 17060: loss: 0.031207, loss_s1: 0.012483, loss_fp: 0.000915, loss_freq: 0.014027
[17:35:21.111] iteration 17061: loss: 0.065816, loss_s1: 0.047168, loss_fp: 0.004031, loss_freq: 0.030322
[17:35:21.736] iteration 17062: loss: 0.038581, loss_s1: 0.014825, loss_fp: 0.000540, loss_freq: 0.013927
[17:35:22.368] iteration 17063: loss: 0.057170, loss_s1: 0.045678, loss_fp: 0.002864, loss_freq: 0.022427
[17:35:22.993] iteration 17064: loss: 0.072919, loss_s1: 0.058209, loss_fp: 0.003599, loss_freq: 0.046584
[17:35:23.611] iteration 17065: loss: 0.060322, loss_s1: 0.040806, loss_fp: 0.001798, loss_freq: 0.007595
[17:35:24.231] iteration 17066: loss: 0.075232, loss_s1: 0.063158, loss_fp: 0.002733, loss_freq: 0.044057
[17:35:25.200] iteration 17067: loss: 0.046252, loss_s1: 0.028409, loss_fp: 0.003952, loss_freq: 0.018096
[17:35:25.824] iteration 17068: loss: 0.050724, loss_s1: 0.035753, loss_fp: 0.002694, loss_freq: 0.015166
[17:35:26.447] iteration 17069: loss: 0.052674, loss_s1: 0.035365, loss_fp: 0.006265, loss_freq: 0.020582
[17:35:27.074] iteration 17070: loss: 0.041906, loss_s1: 0.021756, loss_fp: 0.000239, loss_freq: 0.009019
[17:35:27.693] iteration 17071: loss: 0.051213, loss_s1: 0.046876, loss_fp: 0.002737, loss_freq: 0.012039
[17:35:28.317] iteration 17072: loss: 0.096646, loss_s1: 0.078508, loss_fp: 0.014322, loss_freq: 0.028392
[17:35:28.941] iteration 17073: loss: 0.066857, loss_s1: 0.025990, loss_fp: 0.010928, loss_freq: 0.052426
[17:35:29.562] iteration 17074: loss: 0.058245, loss_s1: 0.054039, loss_fp: 0.005422, loss_freq: 0.022556
[17:35:30.187] iteration 17075: loss: 0.076769, loss_s1: 0.043195, loss_fp: 0.010962, loss_freq: 0.066247
[17:35:30.808] iteration 17076: loss: 0.054237, loss_s1: 0.044136, loss_fp: 0.005038, loss_freq: 0.018091
[17:35:31.437] iteration 17077: loss: 0.036786, loss_s1: 0.013708, loss_fp: 0.003363, loss_freq: 0.011164
[17:35:32.063] iteration 17078: loss: 0.059789, loss_s1: 0.039402, loss_fp: 0.008793, loss_freq: 0.038156
[17:35:32.693] iteration 17079: loss: 0.071031, loss_s1: 0.050218, loss_fp: 0.001760, loss_freq: 0.054217
[17:35:33.319] iteration 17080: loss: 0.065859, loss_s1: 0.048658, loss_fp: 0.002658, loss_freq: 0.025636
[17:35:33.947] iteration 17081: loss: 0.046009, loss_s1: 0.025633, loss_fp: 0.016200, loss_freq: 0.011455
[17:35:34.571] iteration 17082: loss: 0.091012, loss_s1: 0.105094, loss_fp: 0.005212, loss_freq: 0.030098
[17:35:35.197] iteration 17083: loss: 0.040665, loss_s1: 0.032076, loss_fp: 0.004662, loss_freq: 0.005125
[17:35:35.820] iteration 17084: loss: 0.074650, loss_s1: 0.045666, loss_fp: 0.010812, loss_freq: 0.046686
[17:35:36.444] iteration 17085: loss: 0.041054, loss_s1: 0.019187, loss_fp: 0.001265, loss_freq: 0.025446
[17:35:37.066] iteration 17086: loss: 0.053255, loss_s1: 0.042192, loss_fp: 0.002754, loss_freq: 0.015369
[17:35:37.692] iteration 17087: loss: 0.039191, loss_s1: 0.009032, loss_fp: 0.001362, loss_freq: 0.007452
[17:35:38.314] iteration 17088: loss: 0.049315, loss_s1: 0.034225, loss_fp: 0.002800, loss_freq: 0.020485
[17:35:38.936] iteration 17089: loss: 0.074645, loss_s1: 0.030116, loss_fp: 0.001798, loss_freq: 0.033986
[17:35:39.565] iteration 17090: loss: 0.139814, loss_s1: 0.061156, loss_fp: 0.003588, loss_freq: 0.174542
[17:35:40.190] iteration 17091: loss: 0.054183, loss_s1: 0.050946, loss_fp: 0.005257, loss_freq: 0.020034
[17:35:40.807] iteration 17092: loss: 0.070451, loss_s1: 0.052514, loss_fp: 0.002834, loss_freq: 0.043063
[17:35:41.429] iteration 17093: loss: 0.046411, loss_s1: 0.045269, loss_fp: 0.006825, loss_freq: 0.003290
[17:35:42.052] iteration 17094: loss: 0.083333, loss_s1: 0.035313, loss_fp: 0.011199, loss_freq: 0.068335
[17:35:42.671] iteration 17095: loss: 0.062890, loss_s1: 0.037643, loss_fp: 0.004359, loss_freq: 0.051678
[17:35:43.296] iteration 17096: loss: 0.031897, loss_s1: 0.014472, loss_fp: 0.004526, loss_freq: 0.013232
[17:35:43.918] iteration 17097: loss: 0.035052, loss_s1: 0.032702, loss_fp: 0.002038, loss_freq: 0.004924
[17:35:44.542] iteration 17098: loss: 0.056198, loss_s1: 0.043374, loss_fp: 0.008343, loss_freq: 0.010650
[17:35:45.166] iteration 17099: loss: 0.049877, loss_s1: 0.025820, loss_fp: 0.008194, loss_freq: 0.021451
[17:35:45.790] iteration 17100: loss: 0.039974, loss_s1: 0.028016, loss_fp: 0.001452, loss_freq: 0.014475
[17:35:46.414] iteration 17101: loss: 0.062204, loss_s1: 0.023501, loss_fp: 0.000915, loss_freq: 0.040477
[17:35:47.041] iteration 17102: loss: 0.068050, loss_s1: 0.040050, loss_fp: 0.009157, loss_freq: 0.043969
[17:35:47.667] iteration 17103: loss: 0.069262, loss_s1: 0.053883, loss_fp: 0.003101, loss_freq: 0.039842
[17:35:48.291] iteration 17104: loss: 0.050551, loss_s1: 0.033591, loss_fp: 0.008685, loss_freq: 0.027267
[17:35:48.913] iteration 17105: loss: 0.092629, loss_s1: 0.073368, loss_fp: 0.005800, loss_freq: 0.065252
[17:35:49.539] iteration 17106: loss: 0.049489, loss_s1: 0.032503, loss_fp: 0.002759, loss_freq: 0.026661
[17:35:50.163] iteration 17107: loss: 0.044450, loss_s1: 0.032244, loss_fp: 0.001203, loss_freq: 0.007652
[17:35:50.787] iteration 17108: loss: 0.073351, loss_s1: 0.054231, loss_fp: 0.004034, loss_freq: 0.052051
[17:35:51.417] iteration 17109: loss: 0.060438, loss_s1: 0.037615, loss_fp: 0.001681, loss_freq: 0.039831
[17:35:52.040] iteration 17110: loss: 0.037797, loss_s1: 0.008386, loss_fp: 0.002038, loss_freq: 0.027865
[17:35:52.667] iteration 17111: loss: 0.058868, loss_s1: 0.051644, loss_fp: 0.004866, loss_freq: 0.021878
[17:35:53.292] iteration 17112: loss: 0.042686, loss_s1: 0.042396, loss_fp: 0.003348, loss_freq: 0.003313
[17:35:53.923] iteration 17113: loss: 0.031751, loss_s1: 0.015821, loss_fp: 0.001140, loss_freq: 0.008889
[17:35:54.544] iteration 17114: loss: 0.057406, loss_s1: 0.057410, loss_fp: 0.002454, loss_freq: 0.021172
[17:35:55.167] iteration 17115: loss: 0.071314, loss_s1: 0.057403, loss_fp: 0.002427, loss_freq: 0.027271
[17:35:55.787] iteration 17116: loss: 0.044220, loss_s1: 0.022947, loss_fp: 0.003587, loss_freq: 0.030405
[17:35:56.409] iteration 17117: loss: 0.064059, loss_s1: 0.044455, loss_fp: 0.000876, loss_freq: 0.048962
[17:35:57.034] iteration 17118: loss: 0.070757, loss_s1: 0.041617, loss_fp: 0.002674, loss_freq: 0.031772
[17:35:57.661] iteration 17119: loss: 0.064201, loss_s1: 0.055553, loss_fp: 0.002070, loss_freq: 0.034243
[17:35:58.286] iteration 17120: loss: 0.047741, loss_s1: 0.021481, loss_fp: 0.009494, loss_freq: 0.020092
[17:35:58.913] iteration 17121: loss: 0.030629, loss_s1: 0.020737, loss_fp: 0.000724, loss_freq: 0.006122
[17:35:59.537] iteration 17122: loss: 0.073005, loss_s1: 0.071632, loss_fp: 0.001197, loss_freq: 0.027640
[17:36:00.164] iteration 17123: loss: 0.057995, loss_s1: 0.061492, loss_fp: 0.000654, loss_freq: 0.007927
[17:36:00.788] iteration 17124: loss: 0.044009, loss_s1: 0.012439, loss_fp: 0.001307, loss_freq: 0.031697
[17:36:01.413] iteration 17125: loss: 0.039066, loss_s1: 0.021633, loss_fp: 0.002621, loss_freq: 0.016038
[17:36:02.037] iteration 17126: loss: 0.041936, loss_s1: 0.027640, loss_fp: 0.002767, loss_freq: 0.018465
[17:36:02.662] iteration 17127: loss: 0.066838, loss_s1: 0.064203, loss_fp: 0.000488, loss_freq: 0.033812
[17:36:03.283] iteration 17128: loss: 0.041099, loss_s1: 0.020486, loss_fp: 0.004780, loss_freq: 0.022318
[17:36:03.912] iteration 17129: loss: 0.038894, loss_s1: 0.013230, loss_fp: 0.000941, loss_freq: 0.020345
[17:36:04.544] iteration 17130: loss: 0.053681, loss_s1: 0.031888, loss_fp: 0.002208, loss_freq: 0.016964
[17:36:05.168] iteration 17131: loss: 0.064038, loss_s1: 0.025998, loss_fp: 0.001326, loss_freq: 0.064225
[17:36:05.798] iteration 17132: loss: 0.073384, loss_s1: 0.047547, loss_fp: 0.003354, loss_freq: 0.054957
[17:36:06.424] iteration 17133: loss: 0.063955, loss_s1: 0.037045, loss_fp: 0.013409, loss_freq: 0.036599
[17:36:07.045] iteration 17134: loss: 0.047355, loss_s1: 0.034738, loss_fp: 0.004736, loss_freq: 0.020825
[17:36:07.671] iteration 17135: loss: 0.058887, loss_s1: 0.048479, loss_fp: 0.004772, loss_freq: 0.027274
[17:36:08.296] iteration 17136: loss: 0.054566, loss_s1: 0.028241, loss_fp: 0.001566, loss_freq: 0.020870
[17:36:08.925] iteration 17137: loss: 0.055833, loss_s1: 0.056478, loss_fp: 0.010762, loss_freq: 0.013975
[17:36:09.551] iteration 17138: loss: 0.051007, loss_s1: 0.038913, loss_fp: 0.001219, loss_freq: 0.017746
[17:36:10.177] iteration 17139: loss: 0.036330, loss_s1: 0.019990, loss_fp: 0.002171, loss_freq: 0.008176
[17:36:10.847] iteration 17140: loss: 0.063582, loss_s1: 0.051311, loss_fp: 0.004761, loss_freq: 0.017448
[17:36:11.473] iteration 17141: loss: 0.082257, loss_s1: 0.070319, loss_fp: 0.001633, loss_freq: 0.051103
[17:36:12.092] iteration 17142: loss: 0.046059, loss_s1: 0.034795, loss_fp: 0.002533, loss_freq: 0.006198
[17:36:12.716] iteration 17143: loss: 0.070932, loss_s1: 0.031762, loss_fp: 0.006524, loss_freq: 0.064252
[17:36:13.340] iteration 17144: loss: 0.040454, loss_s1: 0.031132, loss_fp: 0.002590, loss_freq: 0.009562
[17:36:13.961] iteration 17145: loss: 0.034230, loss_s1: 0.013550, loss_fp: 0.002428, loss_freq: 0.020989
[17:36:14.587] iteration 17146: loss: 0.060347, loss_s1: 0.052800, loss_fp: 0.001184, loss_freq: 0.020767
[17:36:15.210] iteration 17147: loss: 0.075583, loss_s1: 0.044547, loss_fp: 0.005985, loss_freq: 0.068709
[17:36:15.833] iteration 17148: loss: 0.042921, loss_s1: 0.029305, loss_fp: 0.004351, loss_freq: 0.023197
[17:36:16.459] iteration 17149: loss: 0.081717, loss_s1: 0.110140, loss_fp: 0.002186, loss_freq: 0.015211
[17:36:17.081] iteration 17150: loss: 0.059199, loss_s1: 0.038348, loss_fp: 0.010397, loss_freq: 0.017963
[17:36:17.703] iteration 17151: loss: 0.054695, loss_s1: 0.053309, loss_fp: 0.002900, loss_freq: 0.024905
[17:36:18.327] iteration 17152: loss: 0.069223, loss_s1: 0.054117, loss_fp: 0.001993, loss_freq: 0.045194
[17:36:18.950] iteration 17153: loss: 0.057678, loss_s1: 0.030308, loss_fp: 0.004271, loss_freq: 0.027928
[17:36:19.577] iteration 17154: loss: 0.053796, loss_s1: 0.051295, loss_fp: 0.004103, loss_freq: 0.011279
[17:36:20.201] iteration 17155: loss: 0.092548, loss_s1: 0.055600, loss_fp: 0.003158, loss_freq: 0.070223
[17:36:20.823] iteration 17156: loss: 0.053783, loss_s1: 0.038416, loss_fp: 0.001601, loss_freq: 0.035120
[17:36:21.475] iteration 17157: loss: 0.064556, loss_s1: 0.046546, loss_fp: 0.001117, loss_freq: 0.037019
[17:36:22.137] iteration 17158: loss: 0.075020, loss_s1: 0.063678, loss_fp: 0.002616, loss_freq: 0.036973
[17:36:22.765] iteration 17159: loss: 0.064201, loss_s1: 0.033150, loss_fp: 0.006681, loss_freq: 0.024818
[17:36:23.395] iteration 17160: loss: 0.041807, loss_s1: 0.031994, loss_fp: 0.003122, loss_freq: 0.016747
[17:36:24.019] iteration 17161: loss: 0.065583, loss_s1: 0.055965, loss_fp: 0.013298, loss_freq: 0.029972
[17:36:24.641] iteration 17162: loss: 0.045044, loss_s1: 0.030770, loss_fp: 0.002324, loss_freq: 0.028772
[17:36:25.269] iteration 17163: loss: 0.045154, loss_s1: 0.021056, loss_fp: 0.004445, loss_freq: 0.019646
[17:36:25.892] iteration 17164: loss: 0.068709, loss_s1: 0.037264, loss_fp: 0.000888, loss_freq: 0.051456
[17:36:26.516] iteration 17165: loss: 0.069413, loss_s1: 0.083120, loss_fp: 0.003179, loss_freq: 0.012848
[17:36:27.138] iteration 17166: loss: 0.030990, loss_s1: 0.015593, loss_fp: 0.003397, loss_freq: 0.010689
[17:36:27.761] iteration 17167: loss: 0.072013, loss_s1: 0.066729, loss_fp: 0.001443, loss_freq: 0.040357
[17:36:28.384] iteration 17168: loss: 0.067857, loss_s1: 0.020164, loss_fp: 0.006792, loss_freq: 0.054367
[17:36:29.007] iteration 17169: loss: 0.039415, loss_s1: 0.024165, loss_fp: 0.002724, loss_freq: 0.021023
[17:36:29.632] iteration 17170: loss: 0.057330, loss_s1: 0.042590, loss_fp: 0.003034, loss_freq: 0.034406
[17:36:30.262] iteration 17171: loss: 0.065012, loss_s1: 0.023519, loss_fp: 0.005132, loss_freq: 0.034987
[17:36:30.891] iteration 17172: loss: 0.050617, loss_s1: 0.040736, loss_fp: 0.000660, loss_freq: 0.016973
[17:36:31.515] iteration 17173: loss: 0.053449, loss_s1: 0.045301, loss_fp: 0.006126, loss_freq: 0.009426
[17:36:32.138] iteration 17174: loss: 0.090698, loss_s1: 0.077300, loss_fp: 0.001539, loss_freq: 0.059408
[17:36:32.764] iteration 17175: loss: 0.113575, loss_s1: 0.049974, loss_fp: 0.008605, loss_freq: 0.118248
[17:36:33.391] iteration 17176: loss: 0.078987, loss_s1: 0.082298, loss_fp: 0.002048, loss_freq: 0.032137
[17:36:34.017] iteration 17177: loss: 0.072929, loss_s1: 0.047829, loss_fp: 0.010922, loss_freq: 0.030787
[17:36:34.640] iteration 17178: loss: 0.083386, loss_s1: 0.053230, loss_fp: 0.005410, loss_freq: 0.069592
[17:36:35.265] iteration 17179: loss: 0.041657, loss_s1: 0.031900, loss_fp: 0.001279, loss_freq: 0.020272
[17:36:35.897] iteration 17180: loss: 0.060459, loss_s1: 0.028493, loss_fp: 0.007669, loss_freq: 0.044557
[17:36:36.525] iteration 17181: loss: 0.033653, loss_s1: 0.016672, loss_fp: 0.002270, loss_freq: 0.008466
[17:36:37.150] iteration 17182: loss: 0.080361, loss_s1: 0.054914, loss_fp: 0.003675, loss_freq: 0.064091
[17:36:37.776] iteration 17183: loss: 0.043762, loss_s1: 0.039192, loss_fp: 0.002076, loss_freq: 0.013721
[17:36:38.399] iteration 17184: loss: 0.063413, loss_s1: 0.049534, loss_fp: 0.003036, loss_freq: 0.033476
[17:36:39.026] iteration 17185: loss: 0.053781, loss_s1: 0.032730, loss_fp: 0.007286, loss_freq: 0.028345
[17:36:39.653] iteration 17186: loss: 0.072934, loss_s1: 0.035857, loss_fp: 0.007487, loss_freq: 0.071228
[17:36:40.276] iteration 17187: loss: 0.034272, loss_s1: 0.009226, loss_fp: 0.000902, loss_freq: 0.020511
[17:36:40.899] iteration 17188: loss: 0.070953, loss_s1: 0.065107, loss_fp: 0.002540, loss_freq: 0.031181
[17:36:41.523] iteration 17189: loss: 0.098526, loss_s1: 0.084900, loss_fp: 0.002118, loss_freq: 0.063722
[17:36:42.144] iteration 17190: loss: 0.053372, loss_s1: 0.031627, loss_fp: 0.001263, loss_freq: 0.032521
[17:36:42.768] iteration 17191: loss: 0.076727, loss_s1: 0.050484, loss_fp: 0.002774, loss_freq: 0.044857
[17:36:43.393] iteration 17192: loss: 0.073956, loss_s1: 0.058410, loss_fp: 0.005264, loss_freq: 0.035357
[17:36:44.020] iteration 17193: loss: 0.038318, loss_s1: 0.018200, loss_fp: 0.002912, loss_freq: 0.008022
[17:36:44.645] iteration 17194: loss: 0.142571, loss_s1: 0.113016, loss_fp: 0.002001, loss_freq: 0.114419
[17:36:45.268] iteration 17195: loss: 0.096771, loss_s1: 0.109641, loss_fp: 0.014274, loss_freq: 0.036530
[17:36:45.890] iteration 17196: loss: 0.035802, loss_s1: 0.030513, loss_fp: 0.001442, loss_freq: 0.010828
[17:36:46.552] iteration 17197: loss: 0.062110, loss_s1: 0.051398, loss_fp: 0.002044, loss_freq: 0.039482
[17:36:47.199] iteration 17198: loss: 0.050912, loss_s1: 0.053595, loss_fp: 0.002267, loss_freq: 0.011041
[17:36:47.824] iteration 17199: loss: 0.075166, loss_s1: 0.078320, loss_fp: 0.006254, loss_freq: 0.017033
[17:36:48.449] iteration 17200: loss: 0.049722, loss_s1: 0.043660, loss_fp: 0.002180, loss_freq: 0.014176
[17:36:51.639] iteration 17200 : mean_dice : 0.714347
[17:36:52.293] iteration 17201: loss: 0.063216, loss_s1: 0.037507, loss_fp: 0.002893, loss_freq: 0.048437
[17:36:52.917] iteration 17202: loss: 0.058666, loss_s1: 0.044584, loss_fp: 0.005876, loss_freq: 0.030938
[17:36:53.542] iteration 17203: loss: 0.065456, loss_s1: 0.032459, loss_fp: 0.000703, loss_freq: 0.016387
[17:36:54.163] iteration 17204: loss: 0.049450, loss_s1: 0.042555, loss_fp: 0.002170, loss_freq: 0.022982
[17:36:54.788] iteration 17205: loss: 0.055846, loss_s1: 0.042685, loss_fp: 0.003545, loss_freq: 0.025648
[17:36:55.412] iteration 17206: loss: 0.080808, loss_s1: 0.039876, loss_fp: 0.007357, loss_freq: 0.035445
[17:36:56.034] iteration 17207: loss: 0.054891, loss_s1: 0.043983, loss_fp: 0.006099, loss_freq: 0.025380
[17:36:56.660] iteration 17208: loss: 0.051605, loss_s1: 0.030336, loss_fp: 0.005915, loss_freq: 0.020335
[17:36:57.285] iteration 17209: loss: 0.068540, loss_s1: 0.038904, loss_fp: 0.009926, loss_freq: 0.036378
[17:36:57.908] iteration 17210: loss: 0.072114, loss_s1: 0.069974, loss_fp: 0.002604, loss_freq: 0.017718
[17:36:58.530] iteration 17211: loss: 0.045478, loss_s1: 0.007202, loss_fp: 0.001585, loss_freq: 0.018004
[17:36:59.152] iteration 17212: loss: 0.062428, loss_s1: 0.040389, loss_fp: 0.004729, loss_freq: 0.024860
[17:36:59.774] iteration 17213: loss: 0.072192, loss_s1: 0.058660, loss_fp: 0.010717, loss_freq: 0.044175
[17:37:00.394] iteration 17214: loss: 0.043612, loss_s1: 0.014768, loss_fp: 0.008486, loss_freq: 0.016505
[17:37:01.013] iteration 17215: loss: 0.035636, loss_s1: 0.017435, loss_fp: 0.004031, loss_freq: 0.011405
[17:37:01.667] iteration 17216: loss: 0.101167, loss_s1: 0.072416, loss_fp: 0.006841, loss_freq: 0.062430
[17:37:02.342] iteration 17217: loss: 0.067946, loss_s1: 0.024175, loss_fp: 0.009330, loss_freq: 0.046368
[17:37:03.015] iteration 17218: loss: 0.113765, loss_s1: 0.129558, loss_fp: 0.007678, loss_freq: 0.061490
[17:37:03.658] iteration 17219: loss: 0.052796, loss_s1: 0.030631, loss_fp: 0.001278, loss_freq: 0.031752
[17:37:04.296] iteration 17220: loss: 0.082934, loss_s1: 0.069385, loss_fp: 0.009326, loss_freq: 0.038048
[17:37:04.936] iteration 17221: loss: 0.042274, loss_s1: 0.023142, loss_fp: 0.001471, loss_freq: 0.017691
[17:37:05.576] iteration 17222: loss: 0.058124, loss_s1: 0.050964, loss_fp: 0.003907, loss_freq: 0.019742
[17:37:06.216] iteration 17223: loss: 0.052321, loss_s1: 0.028712, loss_fp: 0.000679, loss_freq: 0.029177
[17:37:06.855] iteration 17224: loss: 0.067040, loss_s1: 0.052746, loss_fp: 0.003353, loss_freq: 0.033221
[17:37:07.496] iteration 17225: loss: 0.116760, loss_s1: 0.081430, loss_fp: 0.045500, loss_freq: 0.066831
[17:37:08.115] iteration 17226: loss: 0.040056, loss_s1: 0.028158, loss_fp: 0.001223, loss_freq: 0.010077
[17:37:08.739] iteration 17227: loss: 0.042044, loss_s1: 0.020203, loss_fp: 0.001366, loss_freq: 0.017964
[17:37:09.734] iteration 17228: loss: 0.051752, loss_s1: 0.045635, loss_fp: 0.001320, loss_freq: 0.008966
[17:37:10.359] iteration 17229: loss: 0.068498, loss_s1: 0.039121, loss_fp: 0.009972, loss_freq: 0.030245
[17:37:10.980] iteration 17230: loss: 0.056311, loss_s1: 0.040134, loss_fp: 0.003433, loss_freq: 0.016039
[17:37:11.608] iteration 17231: loss: 0.048528, loss_s1: 0.026789, loss_fp: 0.001245, loss_freq: 0.013038
[17:37:12.234] iteration 17232: loss: 0.064757, loss_s1: 0.051475, loss_fp: 0.001011, loss_freq: 0.017020
[17:37:12.968] iteration 17233: loss: 0.136304, loss_s1: 0.063254, loss_fp: 0.008228, loss_freq: 0.036374
[17:37:13.603] iteration 17234: loss: 0.095331, loss_s1: 0.124600, loss_fp: 0.001976, loss_freq: 0.027316
[17:37:14.287] iteration 17235: loss: 0.046770, loss_s1: 0.024293, loss_fp: 0.002749, loss_freq: 0.016654
[17:37:14.981] iteration 17236: loss: 0.047771, loss_s1: 0.045615, loss_fp: 0.003473, loss_freq: 0.016574
[17:37:15.607] iteration 17237: loss: 0.085742, loss_s1: 0.048444, loss_fp: 0.005760, loss_freq: 0.056391
[17:37:16.229] iteration 17238: loss: 0.036845, loss_s1: 0.012626, loss_fp: 0.003494, loss_freq: 0.018917
[17:37:16.869] iteration 17239: loss: 0.050961, loss_s1: 0.029173, loss_fp: 0.001564, loss_freq: 0.036335
[17:37:17.496] iteration 17240: loss: 0.119641, loss_s1: 0.070105, loss_fp: 0.006379, loss_freq: 0.127751
[17:37:18.124] iteration 17241: loss: 0.085279, loss_s1: 0.045851, loss_fp: 0.014924, loss_freq: 0.040572
[17:37:18.748] iteration 17242: loss: 0.050048, loss_s1: 0.039737, loss_fp: 0.001893, loss_freq: 0.026965
[17:37:19.373] iteration 17243: loss: 0.098078, loss_s1: 0.101602, loss_fp: 0.004161, loss_freq: 0.049623
[17:37:19.990] iteration 17244: loss: 0.091255, loss_s1: 0.066935, loss_fp: 0.002630, loss_freq: 0.015238
[17:37:20.615] iteration 17245: loss: 0.076006, loss_s1: 0.064927, loss_fp: 0.011204, loss_freq: 0.034313
[17:37:21.243] iteration 17246: loss: 0.050180, loss_s1: 0.020251, loss_fp: 0.003278, loss_freq: 0.025598
[17:37:21.869] iteration 17247: loss: 0.066847, loss_s1: 0.028976, loss_fp: 0.006498, loss_freq: 0.043086
[17:37:22.491] iteration 17248: loss: 0.038859, loss_s1: 0.016244, loss_fp: 0.001630, loss_freq: 0.011631
[17:37:23.116] iteration 17249: loss: 0.044156, loss_s1: 0.025317, loss_fp: 0.001408, loss_freq: 0.016529
[17:37:23.741] iteration 17250: loss: 0.079485, loss_s1: 0.063261, loss_fp: 0.001026, loss_freq: 0.034270
[17:37:24.368] iteration 17251: loss: 0.172825, loss_s1: 0.078052, loss_fp: 0.003706, loss_freq: 0.224798
[17:37:25.030] iteration 17252: loss: 0.039558, loss_s1: 0.028277, loss_fp: 0.001025, loss_freq: 0.017323
[17:37:25.663] iteration 17253: loss: 0.053030, loss_s1: 0.050253, loss_fp: 0.002883, loss_freq: 0.010357
[17:37:26.297] iteration 17254: loss: 0.048023, loss_s1: 0.028727, loss_fp: 0.000800, loss_freq: 0.020899
[17:37:26.925] iteration 17255: loss: 0.085496, loss_s1: 0.072100, loss_fp: 0.007323, loss_freq: 0.036654
[17:37:27.551] iteration 17256: loss: 0.064163, loss_s1: 0.042661, loss_fp: 0.008295, loss_freq: 0.033172
[17:37:28.189] iteration 17257: loss: 0.042635, loss_s1: 0.040513, loss_fp: 0.001060, loss_freq: 0.006618
[17:37:28.817] iteration 17258: loss: 0.034909, loss_s1: 0.030059, loss_fp: 0.001512, loss_freq: 0.006484
[17:37:29.444] iteration 17259: loss: 0.059962, loss_s1: 0.043562, loss_fp: 0.003050, loss_freq: 0.026870
[17:37:30.108] iteration 17260: loss: 0.052959, loss_s1: 0.050853, loss_fp: 0.004335, loss_freq: 0.016387
[17:37:30.773] iteration 17261: loss: 0.057421, loss_s1: 0.056830, loss_fp: 0.002614, loss_freq: 0.004829
[17:37:31.432] iteration 17262: loss: 0.077046, loss_s1: 0.045012, loss_fp: 0.002183, loss_freq: 0.040674
[17:37:32.094] iteration 17263: loss: 0.052570, loss_s1: 0.043417, loss_fp: 0.001072, loss_freq: 0.022233
[17:37:32.735] iteration 17264: loss: 0.096716, loss_s1: 0.089601, loss_fp: 0.002570, loss_freq: 0.044205
[17:37:33.360] iteration 17265: loss: 0.056604, loss_s1: 0.033240, loss_fp: 0.003047, loss_freq: 0.024033
[17:37:33.992] iteration 17266: loss: 0.082444, loss_s1: 0.058109, loss_fp: 0.001076, loss_freq: 0.054336
[17:37:34.619] iteration 17267: loss: 0.056990, loss_s1: 0.045701, loss_fp: 0.004338, loss_freq: 0.024303
[17:37:35.274] iteration 17268: loss: 0.087773, loss_s1: 0.055272, loss_fp: 0.015371, loss_freq: 0.023427
[17:37:35.948] iteration 17269: loss: 0.090130, loss_s1: 0.091536, loss_fp: 0.005836, loss_freq: 0.050698
[17:37:36.628] iteration 17270: loss: 0.094247, loss_s1: 0.098147, loss_fp: 0.002071, loss_freq: 0.053322
[17:37:37.281] iteration 17271: loss: 0.071932, loss_s1: 0.069214, loss_fp: 0.002431, loss_freq: 0.027134
[17:37:37.920] iteration 17272: loss: 0.074865, loss_s1: 0.057128, loss_fp: 0.009069, loss_freq: 0.042269
[17:37:38.551] iteration 17273: loss: 0.069497, loss_s1: 0.065051, loss_fp: 0.000738, loss_freq: 0.023486
[17:37:39.180] iteration 17274: loss: 0.035958, loss_s1: 0.030536, loss_fp: 0.003690, loss_freq: 0.007383
[17:37:39.810] iteration 17275: loss: 0.041948, loss_s1: 0.023328, loss_fp: 0.002868, loss_freq: 0.020023
[17:37:40.434] iteration 17276: loss: 0.069057, loss_s1: 0.053693, loss_fp: 0.012438, loss_freq: 0.023622
[17:37:41.061] iteration 17277: loss: 0.061395, loss_s1: 0.048070, loss_fp: 0.001848, loss_freq: 0.040863
[17:37:41.688] iteration 17278: loss: 0.058115, loss_s1: 0.035912, loss_fp: 0.004047, loss_freq: 0.043423
[17:37:42.321] iteration 17279: loss: 0.058180, loss_s1: 0.040059, loss_fp: 0.002450, loss_freq: 0.018519
[17:37:42.946] iteration 17280: loss: 0.046469, loss_s1: 0.023260, loss_fp: 0.001784, loss_freq: 0.020551
[17:37:43.574] iteration 17281: loss: 0.065817, loss_s1: 0.046748, loss_fp: 0.008293, loss_freq: 0.038046
[17:37:44.197] iteration 17282: loss: 0.053805, loss_s1: 0.018073, loss_fp: 0.001826, loss_freq: 0.037699
[17:37:44.821] iteration 17283: loss: 0.061076, loss_s1: 0.044720, loss_fp: 0.003314, loss_freq: 0.033587
[17:37:45.445] iteration 17284: loss: 0.048966, loss_s1: 0.033688, loss_fp: 0.004369, loss_freq: 0.008173
[17:37:46.071] iteration 17285: loss: 0.068725, loss_s1: 0.027975, loss_fp: 0.002884, loss_freq: 0.027711
[17:37:46.694] iteration 17286: loss: 0.035389, loss_s1: 0.019419, loss_fp: 0.006041, loss_freq: 0.007591
[17:37:47.326] iteration 17287: loss: 0.043280, loss_s1: 0.036224, loss_fp: 0.000592, loss_freq: 0.018438
[17:37:47.950] iteration 17288: loss: 0.044769, loss_s1: 0.024418, loss_fp: 0.001895, loss_freq: 0.022947
[17:37:48.576] iteration 17289: loss: 0.052437, loss_s1: 0.056670, loss_fp: 0.001473, loss_freq: 0.003898
[17:37:49.199] iteration 17290: loss: 0.041870, loss_s1: 0.037392, loss_fp: 0.000578, loss_freq: 0.007756
[17:37:49.824] iteration 17291: loss: 0.055972, loss_s1: 0.028459, loss_fp: 0.006010, loss_freq: 0.036058
[17:37:50.451] iteration 17292: loss: 0.076984, loss_s1: 0.082049, loss_fp: 0.006569, loss_freq: 0.023885
[17:37:51.076] iteration 17293: loss: 0.070816, loss_s1: 0.045541, loss_fp: 0.010741, loss_freq: 0.054608
[17:37:51.702] iteration 17294: loss: 0.096023, loss_s1: 0.046351, loss_fp: 0.011387, loss_freq: 0.087431
[17:37:52.327] iteration 17295: loss: 0.060298, loss_s1: 0.038884, loss_fp: 0.002419, loss_freq: 0.041288
[17:37:52.951] iteration 17296: loss: 0.061796, loss_s1: 0.068084, loss_fp: 0.003932, loss_freq: 0.017438
[17:37:53.579] iteration 17297: loss: 0.072987, loss_s1: 0.028847, loss_fp: 0.003297, loss_freq: 0.038166
[17:37:54.209] iteration 17298: loss: 0.102220, loss_s1: 0.076956, loss_fp: 0.011913, loss_freq: 0.028959
[17:37:54.832] iteration 17299: loss: 0.076249, loss_s1: 0.077037, loss_fp: 0.002015, loss_freq: 0.028512
[17:37:55.456] iteration 17300: loss: 0.068588, loss_s1: 0.065725, loss_fp: 0.002148, loss_freq: 0.035301
[17:37:56.079] iteration 17301: loss: 0.049119, loss_s1: 0.032395, loss_fp: 0.002359, loss_freq: 0.012766
[17:37:56.706] iteration 17302: loss: 0.056800, loss_s1: 0.044166, loss_fp: 0.004911, loss_freq: 0.029646
[17:37:57.331] iteration 17303: loss: 0.041010, loss_s1: 0.011436, loss_fp: 0.006577, loss_freq: 0.005224
[17:37:57.954] iteration 17304: loss: 0.079689, loss_s1: 0.093503, loss_fp: 0.001229, loss_freq: 0.020858
[17:37:58.577] iteration 17305: loss: 0.053089, loss_s1: 0.048443, loss_fp: 0.001768, loss_freq: 0.018704
[17:37:59.199] iteration 17306: loss: 0.044433, loss_s1: 0.040935, loss_fp: 0.003418, loss_freq: 0.009078
[17:37:59.825] iteration 17307: loss: 0.051663, loss_s1: 0.019684, loss_fp: 0.003417, loss_freq: 0.025653
[17:38:00.452] iteration 17308: loss: 0.074897, loss_s1: 0.052519, loss_fp: 0.002580, loss_freq: 0.055022
[17:38:01.072] iteration 17309: loss: 0.054886, loss_s1: 0.052386, loss_fp: 0.001030, loss_freq: 0.020718
[17:38:01.693] iteration 17310: loss: 0.096321, loss_s1: 0.064579, loss_fp: 0.009067, loss_freq: 0.065198
[17:38:02.317] iteration 17311: loss: 0.052786, loss_s1: 0.033635, loss_fp: 0.001087, loss_freq: 0.022837
[17:38:02.940] iteration 17312: loss: 0.065296, loss_s1: 0.042951, loss_fp: 0.004092, loss_freq: 0.044423
[17:38:03.563] iteration 17313: loss: 0.053720, loss_s1: 0.051423, loss_fp: 0.001627, loss_freq: 0.019984
[17:38:04.184] iteration 17314: loss: 0.057323, loss_s1: 0.022707, loss_fp: 0.002890, loss_freq: 0.017724
[17:38:04.807] iteration 17315: loss: 0.048705, loss_s1: 0.036733, loss_fp: 0.005029, loss_freq: 0.010114
[17:38:05.429] iteration 17316: loss: 0.062158, loss_s1: 0.042897, loss_fp: 0.009101, loss_freq: 0.037885
[17:38:06.053] iteration 17317: loss: 0.078638, loss_s1: 0.066510, loss_fp: 0.003615, loss_freq: 0.028309
[17:38:06.679] iteration 17318: loss: 0.061755, loss_s1: 0.026163, loss_fp: 0.003489, loss_freq: 0.037592
[17:38:07.301] iteration 17319: loss: 0.046960, loss_s1: 0.044120, loss_fp: 0.006595, loss_freq: 0.008347
[17:38:07.924] iteration 17320: loss: 0.073926, loss_s1: 0.037342, loss_fp: 0.000998, loss_freq: 0.041325
[17:38:08.546] iteration 17321: loss: 0.042234, loss_s1: 0.023914, loss_fp: 0.000671, loss_freq: 0.021084
[17:38:09.168] iteration 17322: loss: 0.070413, loss_s1: 0.038419, loss_fp: 0.000640, loss_freq: 0.063600
[17:38:09.794] iteration 17323: loss: 0.059798, loss_s1: 0.035746, loss_fp: 0.005626, loss_freq: 0.017236
[17:38:10.420] iteration 17324: loss: 0.038588, loss_s1: 0.024667, loss_fp: 0.002646, loss_freq: 0.013523
[17:38:11.043] iteration 17325: loss: 0.056648, loss_s1: 0.016526, loss_fp: 0.001454, loss_freq: 0.036287
[17:38:11.670] iteration 17326: loss: 0.049198, loss_s1: 0.013246, loss_fp: 0.004931, loss_freq: 0.029403
[17:38:12.293] iteration 17327: loss: 0.086541, loss_s1: 0.092953, loss_fp: 0.006738, loss_freq: 0.030027
[17:38:12.915] iteration 17328: loss: 0.031806, loss_s1: 0.022757, loss_fp: 0.001634, loss_freq: 0.009916
[17:38:13.572] iteration 17329: loss: 0.086407, loss_s1: 0.048359, loss_fp: 0.003675, loss_freq: 0.067375
[17:38:14.230] iteration 17330: loss: 0.071406, loss_s1: 0.052050, loss_fp: 0.002353, loss_freq: 0.019660
[17:38:14.887] iteration 17331: loss: 0.046148, loss_s1: 0.026298, loss_fp: 0.001533, loss_freq: 0.016384
[17:38:15.546] iteration 17332: loss: 0.053655, loss_s1: 0.028535, loss_fp: 0.003604, loss_freq: 0.018517
[17:38:16.194] iteration 17333: loss: 0.038078, loss_s1: 0.023602, loss_fp: 0.004235, loss_freq: 0.017785
[17:38:16.818] iteration 17334: loss: 0.041669, loss_s1: 0.020737, loss_fp: 0.000785, loss_freq: 0.021589
[17:38:17.445] iteration 17335: loss: 0.077129, loss_s1: 0.070346, loss_fp: 0.004405, loss_freq: 0.036623
[17:38:18.069] iteration 17336: loss: 0.094541, loss_s1: 0.047215, loss_fp: 0.007999, loss_freq: 0.088124
[17:38:18.691] iteration 17337: loss: 0.060478, loss_s1: 0.061147, loss_fp: 0.001653, loss_freq: 0.019365
[17:38:19.317] iteration 17338: loss: 0.066710, loss_s1: 0.058687, loss_fp: 0.007200, loss_freq: 0.019668
[17:38:19.939] iteration 17339: loss: 0.059310, loss_s1: 0.042587, loss_fp: 0.000803, loss_freq: 0.045862
[17:38:20.566] iteration 17340: loss: 0.080388, loss_s1: 0.066381, loss_fp: 0.006241, loss_freq: 0.042705
[17:38:21.221] iteration 17341: loss: 0.037823, loss_s1: 0.022358, loss_fp: 0.003098, loss_freq: 0.014952
[17:38:21.879] iteration 17342: loss: 0.036080, loss_s1: 0.026936, loss_fp: 0.001171, loss_freq: 0.004627
[17:38:22.511] iteration 17343: loss: 0.067271, loss_s1: 0.051521, loss_fp: 0.005008, loss_freq: 0.036899
[17:38:23.135] iteration 17344: loss: 0.069606, loss_s1: 0.091367, loss_fp: 0.004677, loss_freq: 0.011583
[17:38:23.759] iteration 17345: loss: 0.036292, loss_s1: 0.030097, loss_fp: 0.001076, loss_freq: 0.006092
[17:38:24.386] iteration 17346: loss: 0.045477, loss_s1: 0.028754, loss_fp: 0.005664, loss_freq: 0.017159
[17:38:25.010] iteration 17347: loss: 0.065843, loss_s1: 0.053585, loss_fp: 0.003155, loss_freq: 0.045563
[17:38:25.634] iteration 17348: loss: 0.033786, loss_s1: 0.018497, loss_fp: 0.004564, loss_freq: 0.007717
[17:38:26.258] iteration 17349: loss: 0.051479, loss_s1: 0.026284, loss_fp: 0.003859, loss_freq: 0.022724
[17:38:26.881] iteration 17350: loss: 0.070649, loss_s1: 0.081331, loss_fp: 0.005145, loss_freq: 0.015033
[17:38:27.505] iteration 17351: loss: 0.053029, loss_s1: 0.055926, loss_fp: 0.002035, loss_freq: 0.010405
[17:38:28.126] iteration 17352: loss: 0.056714, loss_s1: 0.038990, loss_fp: 0.000733, loss_freq: 0.025763
[17:38:28.753] iteration 17353: loss: 0.089813, loss_s1: 0.081989, loss_fp: 0.007036, loss_freq: 0.038798
[17:38:29.374] iteration 17354: loss: 0.043545, loss_s1: 0.030136, loss_fp: 0.004069, loss_freq: 0.005065
[17:38:29.998] iteration 17355: loss: 0.208026, loss_s1: 0.234866, loss_fp: 0.007664, loss_freq: 0.122075
[17:38:30.623] iteration 17356: loss: 0.042643, loss_s1: 0.027610, loss_fp: 0.001872, loss_freq: 0.017695
[17:38:31.250] iteration 17357: loss: 0.044121, loss_s1: 0.034326, loss_fp: 0.002076, loss_freq: 0.007587
[17:38:31.872] iteration 17358: loss: 0.084312, loss_s1: 0.103001, loss_fp: 0.002159, loss_freq: 0.031293
[17:38:32.496] iteration 17359: loss: 0.053547, loss_s1: 0.053365, loss_fp: 0.001237, loss_freq: 0.018393
[17:38:33.121] iteration 17360: loss: 0.045257, loss_s1: 0.033675, loss_fp: 0.004450, loss_freq: 0.012642
[17:38:33.747] iteration 17361: loss: 0.043666, loss_s1: 0.012461, loss_fp: 0.001164, loss_freq: 0.015207
[17:38:34.372] iteration 17362: loss: 0.084958, loss_s1: 0.052366, loss_fp: 0.002221, loss_freq: 0.071779
[17:38:34.995] iteration 17363: loss: 0.057116, loss_s1: 0.033043, loss_fp: 0.010059, loss_freq: 0.037921
[17:38:35.619] iteration 17364: loss: 0.041666, loss_s1: 0.021285, loss_fp: 0.000617, loss_freq: 0.009505
[17:38:36.240] iteration 17365: loss: 0.041915, loss_s1: 0.025443, loss_fp: 0.005653, loss_freq: 0.023221
[17:38:36.864] iteration 17366: loss: 0.032819, loss_s1: 0.016686, loss_fp: 0.004035, loss_freq: 0.012016
[17:38:37.488] iteration 17367: loss: 0.099080, loss_s1: 0.061872, loss_fp: 0.011419, loss_freq: 0.069425
[17:38:38.113] iteration 17368: loss: 0.069915, loss_s1: 0.069663, loss_fp: 0.007393, loss_freq: 0.024789
[17:38:38.737] iteration 17369: loss: 0.051153, loss_s1: 0.028867, loss_fp: 0.001553, loss_freq: 0.010595
[17:38:39.360] iteration 17370: loss: 0.068853, loss_s1: 0.040615, loss_fp: 0.011081, loss_freq: 0.034980
[17:38:39.984] iteration 17371: loss: 0.075372, loss_s1: 0.055359, loss_fp: 0.029496, loss_freq: 0.014245
[17:38:40.607] iteration 17372: loss: 0.056281, loss_s1: 0.049987, loss_fp: 0.002220, loss_freq: 0.024250
[17:38:41.229] iteration 17373: loss: 0.063342, loss_s1: 0.046827, loss_fp: 0.013295, loss_freq: 0.016762
[17:38:41.857] iteration 17374: loss: 0.081438, loss_s1: 0.050926, loss_fp: 0.010391, loss_freq: 0.068280
[17:38:42.486] iteration 17375: loss: 0.052607, loss_s1: 0.044299, loss_fp: 0.005149, loss_freq: 0.008658
[17:38:43.108] iteration 17376: loss: 0.058234, loss_s1: 0.011271, loss_fp: 0.000413, loss_freq: 0.031909
[17:38:43.733] iteration 17377: loss: 0.083267, loss_s1: 0.047298, loss_fp: 0.015223, loss_freq: 0.057632
[17:38:44.356] iteration 17378: loss: 0.089128, loss_s1: 0.062212, loss_fp: 0.001972, loss_freq: 0.022414
[17:38:44.980] iteration 17379: loss: 0.052065, loss_s1: 0.051015, loss_fp: 0.003003, loss_freq: 0.016653
[17:38:45.603] iteration 17380: loss: 0.087390, loss_s1: 0.054282, loss_fp: 0.004065, loss_freq: 0.070373
[17:38:46.226] iteration 17381: loss: 0.058162, loss_s1: 0.041973, loss_fp: 0.009648, loss_freq: 0.024293
[17:38:46.848] iteration 17382: loss: 0.033575, loss_s1: 0.018360, loss_fp: 0.001185, loss_freq: 0.015182
[17:38:47.473] iteration 17383: loss: 0.050093, loss_s1: 0.037153, loss_fp: 0.008014, loss_freq: 0.020038
[17:38:48.095] iteration 17384: loss: 0.038464, loss_s1: 0.024654, loss_fp: 0.002365, loss_freq: 0.009335
[17:38:48.720] iteration 17385: loss: 0.106300, loss_s1: 0.119788, loss_fp: 0.005362, loss_freq: 0.037479
[17:38:49.344] iteration 17386: loss: 0.113112, loss_s1: 0.108671, loss_fp: 0.003920, loss_freq: 0.059707
[17:38:49.964] iteration 17387: loss: 0.045075, loss_s1: 0.027983, loss_fp: 0.001280, loss_freq: 0.014148
[17:38:50.589] iteration 17388: loss: 0.084819, loss_s1: 0.064148, loss_fp: 0.001610, loss_freq: 0.046206
[17:38:51.559] iteration 17389: loss: 0.057677, loss_s1: 0.062171, loss_fp: 0.000279, loss_freq: 0.009346
[17:38:52.199] iteration 17390: loss: 0.050121, loss_s1: 0.013224, loss_fp: 0.004386, loss_freq: 0.036592
[17:38:52.826] iteration 17391: loss: 0.055768, loss_s1: 0.048579, loss_fp: 0.001628, loss_freq: 0.018863
[17:38:53.485] iteration 17392: loss: 0.045223, loss_s1: 0.037003, loss_fp: 0.000642, loss_freq: 0.006443
[17:38:54.142] iteration 17393: loss: 0.071373, loss_s1: 0.060834, loss_fp: 0.003441, loss_freq: 0.009700
[17:38:54.797] iteration 17394: loss: 0.105354, loss_s1: 0.087864, loss_fp: 0.004525, loss_freq: 0.056226
[17:38:55.437] iteration 17395: loss: 0.053422, loss_s1: 0.051946, loss_fp: 0.001541, loss_freq: 0.017669
[17:38:56.062] iteration 17396: loss: 0.060829, loss_s1: 0.079306, loss_fp: 0.001272, loss_freq: 0.009380
[17:38:56.689] iteration 17397: loss: 0.053104, loss_s1: 0.031279, loss_fp: 0.001189, loss_freq: 0.028999
[17:38:57.318] iteration 17398: loss: 0.072937, loss_s1: 0.076217, loss_fp: 0.005173, loss_freq: 0.023343
[17:38:57.950] iteration 17399: loss: 0.028465, loss_s1: 0.010184, loss_fp: 0.000448, loss_freq: 0.007075
[17:38:58.585] iteration 17400: loss: 0.033876, loss_s1: 0.014485, loss_fp: 0.002917, loss_freq: 0.016919
[17:39:01.660] iteration 17400 : mean_dice : 0.725723
[17:39:02.311] iteration 17401: loss: 0.080059, loss_s1: 0.053409, loss_fp: 0.007743, loss_freq: 0.066442
[17:39:02.944] iteration 17402: loss: 0.046744, loss_s1: 0.033596, loss_fp: 0.004809, loss_freq: 0.016451
[17:39:03.567] iteration 17403: loss: 0.056149, loss_s1: 0.052441, loss_fp: 0.005478, loss_freq: 0.018791
[17:39:04.190] iteration 17404: loss: 0.142602, loss_s1: 0.128504, loss_fp: 0.002610, loss_freq: 0.110304
[17:39:04.813] iteration 17405: loss: 0.063816, loss_s1: 0.044850, loss_fp: 0.001797, loss_freq: 0.010480
[17:39:05.437] iteration 17406: loss: 0.042902, loss_s1: 0.021633, loss_fp: 0.001671, loss_freq: 0.026112
[17:39:06.062] iteration 17407: loss: 0.069881, loss_s1: 0.044869, loss_fp: 0.002569, loss_freq: 0.033765
[17:39:06.684] iteration 17408: loss: 0.067323, loss_s1: 0.068741, loss_fp: 0.000539, loss_freq: 0.019760
[17:39:07.311] iteration 17409: loss: 0.041593, loss_s1: 0.025176, loss_fp: 0.004163, loss_freq: 0.012366
[17:39:07.929] iteration 17410: loss: 0.048959, loss_s1: 0.042096, loss_fp: 0.001260, loss_freq: 0.014101
[17:39:08.551] iteration 17411: loss: 0.046828, loss_s1: 0.017738, loss_fp: 0.002340, loss_freq: 0.019637
[17:39:09.174] iteration 17412: loss: 0.100350, loss_s1: 0.036443, loss_fp: 0.014188, loss_freq: 0.114087
[17:39:09.799] iteration 17413: loss: 0.065553, loss_s1: 0.073174, loss_fp: 0.005837, loss_freq: 0.022832
[17:39:10.422] iteration 17414: loss: 0.051469, loss_s1: 0.037841, loss_fp: 0.001276, loss_freq: 0.030866
[17:39:11.048] iteration 17415: loss: 0.034174, loss_s1: 0.013034, loss_fp: 0.000689, loss_freq: 0.010257
[17:39:11.677] iteration 17416: loss: 0.059160, loss_s1: 0.034030, loss_fp: 0.011495, loss_freq: 0.038797
[17:39:12.304] iteration 17417: loss: 0.080416, loss_s1: 0.052557, loss_fp: 0.009794, loss_freq: 0.045090
[17:39:12.929] iteration 17418: loss: 0.037455, loss_s1: 0.018113, loss_fp: 0.001791, loss_freq: 0.015705
[17:39:13.560] iteration 17419: loss: 0.047745, loss_s1: 0.041707, loss_fp: 0.003479, loss_freq: 0.018419
[17:39:14.185] iteration 17420: loss: 0.064790, loss_s1: 0.052038, loss_fp: 0.001803, loss_freq: 0.016135
[17:39:14.809] iteration 17421: loss: 0.068517, loss_s1: 0.044162, loss_fp: 0.004787, loss_freq: 0.045721
[17:39:15.435] iteration 17422: loss: 0.047939, loss_s1: 0.049328, loss_fp: 0.002118, loss_freq: 0.005143
[17:39:16.110] iteration 17423: loss: 0.056788, loss_s1: 0.027819, loss_fp: 0.003615, loss_freq: 0.028063
[17:39:16.984] iteration 17424: loss: 0.077947, loss_s1: 0.056402, loss_fp: 0.011385, loss_freq: 0.043962
[17:39:17.795] iteration 17425: loss: 0.085514, loss_s1: 0.076617, loss_fp: 0.008414, loss_freq: 0.042355
[17:39:18.423] iteration 17426: loss: 0.063024, loss_s1: 0.063294, loss_fp: 0.004720, loss_freq: 0.020867
[17:39:19.044] iteration 17427: loss: 0.073701, loss_s1: 0.059024, loss_fp: 0.004861, loss_freq: 0.036586
[17:39:19.665] iteration 17428: loss: 0.033643, loss_s1: 0.015191, loss_fp: 0.001129, loss_freq: 0.019179
[17:39:20.291] iteration 17429: loss: 0.066367, loss_s1: 0.028593, loss_fp: 0.001911, loss_freq: 0.047273
[17:39:20.913] iteration 17430: loss: 0.096783, loss_s1: 0.076866, loss_fp: 0.017651, loss_freq: 0.060879
[17:39:21.535] iteration 17431: loss: 0.067234, loss_s1: 0.057711, loss_fp: 0.003590, loss_freq: 0.032826
[17:39:22.156] iteration 17432: loss: 0.046136, loss_s1: 0.023743, loss_fp: 0.001142, loss_freq: 0.029294
[17:39:22.775] iteration 17433: loss: 0.057234, loss_s1: 0.019301, loss_fp: 0.002640, loss_freq: 0.052082
[17:39:23.395] iteration 17434: loss: 0.043569, loss_s1: 0.036435, loss_fp: 0.003077, loss_freq: 0.004432
[17:39:24.019] iteration 17435: loss: 0.028186, loss_s1: 0.009514, loss_fp: 0.002721, loss_freq: 0.011625
[17:39:24.641] iteration 17436: loss: 0.072879, loss_s1: 0.087007, loss_fp: 0.000554, loss_freq: 0.029158
[17:39:25.265] iteration 17437: loss: 0.076033, loss_s1: 0.086059, loss_fp: 0.002568, loss_freq: 0.020623
[17:39:25.885] iteration 17438: loss: 0.073491, loss_s1: 0.076017, loss_fp: 0.004516, loss_freq: 0.031005
[17:39:26.507] iteration 17439: loss: 0.099280, loss_s1: 0.108143, loss_fp: 0.000723, loss_freq: 0.045710
[17:39:27.128] iteration 17440: loss: 0.066314, loss_s1: 0.031578, loss_fp: 0.005545, loss_freq: 0.029529
[17:39:27.749] iteration 17441: loss: 0.052829, loss_s1: 0.034034, loss_fp: 0.004299, loss_freq: 0.027162
[17:39:28.372] iteration 17442: loss: 0.070240, loss_s1: 0.067626, loss_fp: 0.004129, loss_freq: 0.031654
[17:39:29.000] iteration 17443: loss: 0.060130, loss_s1: 0.058375, loss_fp: 0.002076, loss_freq: 0.019815
[17:39:29.628] iteration 17444: loss: 0.048478, loss_s1: 0.021239, loss_fp: 0.003361, loss_freq: 0.032034
[17:39:30.256] iteration 17445: loss: 0.039857, loss_s1: 0.024438, loss_fp: 0.004681, loss_freq: 0.009095
[17:39:30.883] iteration 17446: loss: 0.060831, loss_s1: 0.026708, loss_fp: 0.000392, loss_freq: 0.035882
[17:39:31.508] iteration 17447: loss: 0.042122, loss_s1: 0.035600, loss_fp: 0.000350, loss_freq: 0.008317
[17:39:32.133] iteration 17448: loss: 0.050831, loss_s1: 0.041936, loss_fp: 0.000982, loss_freq: 0.025291
[17:39:32.759] iteration 17449: loss: 0.067916, loss_s1: 0.050470, loss_fp: 0.002013, loss_freq: 0.025917
[17:39:33.382] iteration 17450: loss: 0.041302, loss_s1: 0.024797, loss_fp: 0.002445, loss_freq: 0.024621
[17:39:34.005] iteration 17451: loss: 0.047427, loss_s1: 0.023751, loss_fp: 0.000312, loss_freq: 0.005789
[17:39:34.631] iteration 17452: loss: 0.059592, loss_s1: 0.025313, loss_fp: 0.006140, loss_freq: 0.037035
[17:39:35.253] iteration 17453: loss: 0.067142, loss_s1: 0.068534, loss_fp: 0.002324, loss_freq: 0.018165
[17:39:35.874] iteration 17454: loss: 0.099845, loss_s1: 0.096294, loss_fp: 0.006753, loss_freq: 0.067300
[17:39:36.498] iteration 17455: loss: 0.086975, loss_s1: 0.035865, loss_fp: 0.002604, loss_freq: 0.079488
[17:39:37.119] iteration 17456: loss: 0.058971, loss_s1: 0.031133, loss_fp: 0.003356, loss_freq: 0.041866
[17:39:37.747] iteration 17457: loss: 0.044083, loss_s1: 0.030869, loss_fp: 0.007086, loss_freq: 0.014346
[17:39:38.372] iteration 17458: loss: 0.085513, loss_s1: 0.087904, loss_fp: 0.001372, loss_freq: 0.017116
[17:39:38.995] iteration 17459: loss: 0.069479, loss_s1: 0.032395, loss_fp: 0.010805, loss_freq: 0.050830
[17:39:39.615] iteration 17460: loss: 0.054170, loss_s1: 0.029653, loss_fp: 0.000365, loss_freq: 0.042796
[17:39:40.237] iteration 17461: loss: 0.049128, loss_s1: 0.013309, loss_fp: 0.000614, loss_freq: 0.037839
[17:39:40.862] iteration 17462: loss: 0.032655, loss_s1: 0.013143, loss_fp: 0.003953, loss_freq: 0.010595
[17:39:41.487] iteration 17463: loss: 0.081596, loss_s1: 0.102289, loss_fp: 0.000592, loss_freq: 0.019147
[17:39:42.121] iteration 17464: loss: 0.097348, loss_s1: 0.087501, loss_fp: 0.014993, loss_freq: 0.037116
[17:39:42.749] iteration 17465: loss: 0.090714, loss_s1: 0.060215, loss_fp: 0.003944, loss_freq: 0.061685
[17:39:43.374] iteration 17466: loss: 0.057875, loss_s1: 0.062861, loss_fp: 0.003397, loss_freq: 0.019216
[17:39:44.000] iteration 17467: loss: 0.033247, loss_s1: 0.024373, loss_fp: 0.000988, loss_freq: 0.007247
[17:39:44.622] iteration 17468: loss: 0.051619, loss_s1: 0.022397, loss_fp: 0.009878, loss_freq: 0.030912
[17:39:45.251] iteration 17469: loss: 0.062655, loss_s1: 0.037866, loss_fp: 0.015672, loss_freq: 0.038928
[17:39:45.875] iteration 17470: loss: 0.059927, loss_s1: 0.046907, loss_fp: 0.002926, loss_freq: 0.029780
[17:39:46.496] iteration 17471: loss: 0.096773, loss_s1: 0.092120, loss_fp: 0.014064, loss_freq: 0.056597
[17:39:47.122] iteration 17472: loss: 0.084766, loss_s1: 0.052665, loss_fp: 0.023054, loss_freq: 0.035157
[17:39:47.748] iteration 17473: loss: 0.066615, loss_s1: 0.049272, loss_fp: 0.001340, loss_freq: 0.052326
[17:39:48.378] iteration 17474: loss: 0.037847, loss_s1: 0.025239, loss_fp: 0.002232, loss_freq: 0.013231
[17:39:49.000] iteration 17475: loss: 0.050321, loss_s1: 0.043988, loss_fp: 0.001414, loss_freq: 0.013275
[17:39:49.628] iteration 17476: loss: 0.044791, loss_s1: 0.027361, loss_fp: 0.006265, loss_freq: 0.019328
[17:39:50.261] iteration 17477: loss: 0.041312, loss_s1: 0.031873, loss_fp: 0.004194, loss_freq: 0.008519
[17:39:50.888] iteration 17478: loss: 0.070555, loss_s1: 0.071492, loss_fp: 0.003039, loss_freq: 0.023489
[17:39:51.514] iteration 17479: loss: 0.082039, loss_s1: 0.032393, loss_fp: 0.015744, loss_freq: 0.041517
[17:39:52.139] iteration 17480: loss: 0.056416, loss_s1: 0.045044, loss_fp: 0.000764, loss_freq: 0.014061
[17:39:52.761] iteration 17481: loss: 0.075536, loss_s1: 0.030197, loss_fp: 0.006362, loss_freq: 0.043835
[17:39:53.389] iteration 17482: loss: 0.059806, loss_s1: 0.043460, loss_fp: 0.001705, loss_freq: 0.005977
[17:39:54.015] iteration 17483: loss: 0.056792, loss_s1: 0.027785, loss_fp: 0.001449, loss_freq: 0.046478
[17:39:54.640] iteration 17484: loss: 0.056713, loss_s1: 0.045081, loss_fp: 0.001533, loss_freq: 0.037565
[17:39:55.265] iteration 17485: loss: 0.036805, loss_s1: 0.011697, loss_fp: 0.001633, loss_freq: 0.023007
[17:39:55.920] iteration 17486: loss: 0.053393, loss_s1: 0.026086, loss_fp: 0.001337, loss_freq: 0.033506
[17:39:56.578] iteration 17487: loss: 0.048392, loss_s1: 0.054610, loss_fp: 0.000538, loss_freq: 0.010812
[17:39:57.239] iteration 17488: loss: 0.042162, loss_s1: 0.025450, loss_fp: 0.002686, loss_freq: 0.016859
[17:39:57.903] iteration 17489: loss: 0.065097, loss_s1: 0.075865, loss_fp: 0.002836, loss_freq: 0.016727
[17:39:58.566] iteration 17490: loss: 0.065033, loss_s1: 0.025590, loss_fp: 0.002859, loss_freq: 0.059402
[17:39:59.206] iteration 17491: loss: 0.083239, loss_s1: 0.069224, loss_fp: 0.004538, loss_freq: 0.053013
[17:39:59.831] iteration 17492: loss: 0.074915, loss_s1: 0.093423, loss_fp: 0.002469, loss_freq: 0.017642
[17:40:00.459] iteration 17493: loss: 0.053386, loss_s1: 0.037301, loss_fp: 0.001266, loss_freq: 0.015605
[17:40:01.083] iteration 17494: loss: 0.043822, loss_s1: 0.032169, loss_fp: 0.006425, loss_freq: 0.012722
[17:40:01.708] iteration 17495: loss: 0.068036, loss_s1: 0.033828, loss_fp: 0.000697, loss_freq: 0.018390
[17:40:02.332] iteration 17496: loss: 0.077087, loss_s1: 0.050993, loss_fp: 0.002172, loss_freq: 0.046556
[17:40:02.955] iteration 17497: loss: 0.153136, loss_s1: 0.101845, loss_fp: 0.005449, loss_freq: 0.146158
[17:40:03.584] iteration 17498: loss: 0.057065, loss_s1: 0.024821, loss_fp: 0.003329, loss_freq: 0.046721
[17:40:04.207] iteration 17499: loss: 0.078663, loss_s1: 0.045282, loss_fp: 0.005718, loss_freq: 0.038684
[17:40:04.834] iteration 17500: loss: 0.081331, loss_s1: 0.066767, loss_fp: 0.007237, loss_freq: 0.053925
[17:40:05.460] iteration 17501: loss: 0.073905, loss_s1: 0.073425, loss_fp: 0.003005, loss_freq: 0.023684
[17:40:06.088] iteration 17502: loss: 0.045510, loss_s1: 0.016080, loss_fp: 0.001195, loss_freq: 0.046301
[17:40:06.711] iteration 17503: loss: 0.037339, loss_s1: 0.031022, loss_fp: 0.000628, loss_freq: 0.003220
[17:40:07.335] iteration 17504: loss: 0.058406, loss_s1: 0.055057, loss_fp: 0.005711, loss_freq: 0.022226
[17:40:07.960] iteration 17505: loss: 0.050710, loss_s1: 0.044354, loss_fp: 0.008770, loss_freq: 0.014447
[17:40:08.584] iteration 17506: loss: 0.049675, loss_s1: 0.053789, loss_fp: 0.000534, loss_freq: 0.013048
[17:40:09.210] iteration 17507: loss: 0.088704, loss_s1: 0.034571, loss_fp: 0.033937, loss_freq: 0.037076
[17:40:09.836] iteration 17508: loss: 0.082743, loss_s1: 0.054884, loss_fp: 0.005061, loss_freq: 0.078499
[17:40:10.461] iteration 17509: loss: 0.076912, loss_s1: 0.046199, loss_fp: 0.004590, loss_freq: 0.064546
[17:40:11.085] iteration 17510: loss: 0.058064, loss_s1: 0.043689, loss_fp: 0.012542, loss_freq: 0.021934
[17:40:11.709] iteration 17511: loss: 0.050976, loss_s1: 0.018247, loss_fp: 0.000401, loss_freq: 0.014573
[17:40:12.331] iteration 17512: loss: 0.037284, loss_s1: 0.009990, loss_fp: 0.002728, loss_freq: 0.019778
[17:40:12.956] iteration 17513: loss: 0.050621, loss_s1: 0.049055, loss_fp: 0.001008, loss_freq: 0.019041
[17:40:13.580] iteration 17514: loss: 0.078567, loss_s1: 0.066727, loss_fp: 0.019363, loss_freq: 0.021226
[17:40:14.203] iteration 17515: loss: 0.038892, loss_s1: 0.023569, loss_fp: 0.002689, loss_freq: 0.007588
[17:40:14.823] iteration 17516: loss: 0.109557, loss_s1: 0.050061, loss_fp: 0.003512, loss_freq: 0.032675
[17:40:15.451] iteration 17517: loss: 0.053880, loss_s1: 0.018852, loss_fp: 0.004781, loss_freq: 0.042081
[17:40:16.074] iteration 17518: loss: 0.052579, loss_s1: 0.061648, loss_fp: 0.001540, loss_freq: 0.004988
[17:40:16.699] iteration 17519: loss: 0.082781, loss_s1: 0.065756, loss_fp: 0.004407, loss_freq: 0.057363
[17:40:17.316] iteration 17520: loss: 0.062744, loss_s1: 0.060534, loss_fp: 0.002764, loss_freq: 0.022907
[17:40:17.936] iteration 17521: loss: 0.073250, loss_s1: 0.049982, loss_fp: 0.005622, loss_freq: 0.012044
[17:40:18.558] iteration 17522: loss: 0.042121, loss_s1: 0.037802, loss_fp: 0.002508, loss_freq: 0.012296
[17:40:19.180] iteration 17523: loss: 0.088728, loss_s1: 0.074445, loss_fp: 0.007282, loss_freq: 0.050316
[17:40:19.799] iteration 17524: loss: 0.066336, loss_s1: 0.083251, loss_fp: 0.000734, loss_freq: 0.018952
[17:40:20.421] iteration 17525: loss: 0.051149, loss_s1: 0.014176, loss_fp: 0.002358, loss_freq: 0.028838
[17:40:21.044] iteration 17526: loss: 0.057555, loss_s1: 0.048863, loss_fp: 0.007838, loss_freq: 0.014175
[17:40:21.664] iteration 17527: loss: 0.057817, loss_s1: 0.043869, loss_fp: 0.001529, loss_freq: 0.024758
[17:40:22.287] iteration 17528: loss: 0.077385, loss_s1: 0.045176, loss_fp: 0.008698, loss_freq: 0.017288
[17:40:22.907] iteration 17529: loss: 0.068481, loss_s1: 0.071951, loss_fp: 0.005239, loss_freq: 0.025463
[17:40:23.527] iteration 17530: loss: 0.047156, loss_s1: 0.023474, loss_fp: 0.001018, loss_freq: 0.013939
[17:40:24.150] iteration 17531: loss: 0.082278, loss_s1: 0.074049, loss_fp: 0.006040, loss_freq: 0.034773
[17:40:24.770] iteration 17532: loss: 0.077102, loss_s1: 0.082912, loss_fp: 0.003000, loss_freq: 0.025033
[17:40:25.392] iteration 17533: loss: 0.066230, loss_s1: 0.069651, loss_fp: 0.000999, loss_freq: 0.015956
[17:40:26.009] iteration 17534: loss: 0.076929, loss_s1: 0.054988, loss_fp: 0.008627, loss_freq: 0.040970
[17:40:26.632] iteration 17535: loss: 0.091149, loss_s1: 0.048566, loss_fp: 0.009964, loss_freq: 0.091917
[17:40:27.257] iteration 17536: loss: 0.041299, loss_s1: 0.036347, loss_fp: 0.001261, loss_freq: 0.005043
[17:40:27.881] iteration 17537: loss: 0.037053, loss_s1: 0.018930, loss_fp: 0.007576, loss_freq: 0.007907
[17:40:28.501] iteration 17538: loss: 0.079956, loss_s1: 0.064616, loss_fp: 0.003430, loss_freq: 0.041728
[17:40:29.120] iteration 17539: loss: 0.103787, loss_s1: 0.082222, loss_fp: 0.002024, loss_freq: 0.026822
[17:40:29.778] iteration 17540: loss: 0.075585, loss_s1: 0.047012, loss_fp: 0.009274, loss_freq: 0.056386
[17:40:30.436] iteration 17541: loss: 0.065238, loss_s1: 0.057090, loss_fp: 0.006990, loss_freq: 0.026065
[17:40:31.091] iteration 17542: loss: 0.085263, loss_s1: 0.073343, loss_fp: 0.005102, loss_freq: 0.036016
[17:40:31.747] iteration 17543: loss: 0.028694, loss_s1: 0.018216, loss_fp: 0.002744, loss_freq: 0.006215
[17:40:32.390] iteration 17544: loss: 0.037291, loss_s1: 0.008443, loss_fp: 0.002289, loss_freq: 0.023739
[17:40:33.012] iteration 17545: loss: 0.062749, loss_s1: 0.016946, loss_fp: 0.000339, loss_freq: 0.011669
[17:40:33.641] iteration 17546: loss: 0.072974, loss_s1: 0.047381, loss_fp: 0.003996, loss_freq: 0.039298
[17:40:34.268] iteration 17547: loss: 0.049448, loss_s1: 0.045881, loss_fp: 0.002839, loss_freq: 0.013280
[17:40:34.889] iteration 17548: loss: 0.034598, loss_s1: 0.015315, loss_fp: 0.006224, loss_freq: 0.012406
[17:40:35.511] iteration 17549: loss: 0.058823, loss_s1: 0.054464, loss_fp: 0.002376, loss_freq: 0.020262
[17:40:36.508] iteration 17550: loss: 0.045944, loss_s1: 0.034536, loss_fp: 0.000393, loss_freq: 0.017029
[17:40:37.156] iteration 17551: loss: 0.087041, loss_s1: 0.065265, loss_fp: 0.033304, loss_freq: 0.031224
[17:40:37.797] iteration 17552: loss: 0.053548, loss_s1: 0.031880, loss_fp: 0.001003, loss_freq: 0.024407
[17:40:38.421] iteration 17553: loss: 0.055132, loss_s1: 0.038893, loss_fp: 0.000567, loss_freq: 0.025371
[17:40:39.043] iteration 17554: loss: 0.074022, loss_s1: 0.028073, loss_fp: 0.004361, loss_freq: 0.017258
[17:40:39.667] iteration 17555: loss: 0.088049, loss_s1: 0.071224, loss_fp: 0.001955, loss_freq: 0.039153
[17:40:40.291] iteration 17556: loss: 0.064102, loss_s1: 0.067528, loss_fp: 0.007948, loss_freq: 0.018938
[17:40:40.916] iteration 17557: loss: 0.060646, loss_s1: 0.064371, loss_fp: 0.002465, loss_freq: 0.018648
[17:40:41.543] iteration 17558: loss: 0.062915, loss_s1: 0.054689, loss_fp: 0.003056, loss_freq: 0.040969
[17:40:42.172] iteration 17559: loss: 0.050047, loss_s1: 0.024931, loss_fp: 0.006864, loss_freq: 0.024548
[17:40:42.800] iteration 17560: loss: 0.036384, loss_s1: 0.021477, loss_fp: 0.001417, loss_freq: 0.006701
[17:40:43.423] iteration 17561: loss: 0.046088, loss_s1: 0.038086, loss_fp: 0.006147, loss_freq: 0.018664
[17:40:44.046] iteration 17562: loss: 0.061070, loss_s1: 0.046665, loss_fp: 0.002625, loss_freq: 0.044373
[17:40:44.676] iteration 17563: loss: 0.073815, loss_s1: 0.045221, loss_fp: 0.003667, loss_freq: 0.033324
[17:40:45.302] iteration 17564: loss: 0.052138, loss_s1: 0.051493, loss_fp: 0.001213, loss_freq: 0.012024
[17:40:45.930] iteration 17565: loss: 0.092853, loss_s1: 0.124946, loss_fp: 0.003962, loss_freq: 0.014729
[17:40:46.555] iteration 17566: loss: 0.081968, loss_s1: 0.064160, loss_fp: 0.004539, loss_freq: 0.008429
[17:40:47.176] iteration 17567: loss: 0.085091, loss_s1: 0.059554, loss_fp: 0.008172, loss_freq: 0.052603
[17:40:47.800] iteration 17568: loss: 0.041861, loss_s1: 0.020998, loss_fp: 0.001020, loss_freq: 0.011942
[17:40:48.422] iteration 17569: loss: 0.050943, loss_s1: 0.041614, loss_fp: 0.002338, loss_freq: 0.012172
[17:40:49.044] iteration 17570: loss: 0.050800, loss_s1: 0.028917, loss_fp: 0.002480, loss_freq: 0.023486
[17:40:49.666] iteration 17571: loss: 0.042249, loss_s1: 0.024282, loss_fp: 0.002198, loss_freq: 0.010712
[17:40:50.286] iteration 17572: loss: 0.057476, loss_s1: 0.027769, loss_fp: 0.003895, loss_freq: 0.009227
[17:40:50.904] iteration 17573: loss: 0.096896, loss_s1: 0.044861, loss_fp: 0.005862, loss_freq: 0.109573
[17:40:51.526] iteration 17574: loss: 0.041766, loss_s1: 0.021930, loss_fp: 0.006998, loss_freq: 0.022293
[17:40:52.150] iteration 17575: loss: 0.049709, loss_s1: 0.041131, loss_fp: 0.001768, loss_freq: 0.020883
[17:40:52.772] iteration 17576: loss: 0.052945, loss_s1: 0.030405, loss_fp: 0.009298, loss_freq: 0.019463
[17:40:53.395] iteration 17577: loss: 0.063834, loss_s1: 0.038891, loss_fp: 0.005645, loss_freq: 0.034366
[17:40:54.017] iteration 17578: loss: 0.050384, loss_s1: 0.036353, loss_fp: 0.006052, loss_freq: 0.024908
[17:40:54.642] iteration 17579: loss: 0.041539, loss_s1: 0.022776, loss_fp: 0.004103, loss_freq: 0.013406
[17:40:55.268] iteration 17580: loss: 0.042318, loss_s1: 0.035202, loss_fp: 0.001234, loss_freq: 0.020709
[17:40:55.891] iteration 17581: loss: 0.045157, loss_s1: 0.035815, loss_fp: 0.002092, loss_freq: 0.013090
[17:40:56.512] iteration 17582: loss: 0.046805, loss_s1: 0.035267, loss_fp: 0.006766, loss_freq: 0.020935
[17:40:57.135] iteration 17583: loss: 0.046695, loss_s1: 0.046821, loss_fp: 0.001138, loss_freq: 0.009672
[17:40:57.756] iteration 17584: loss: 0.059312, loss_s1: 0.039816, loss_fp: 0.001988, loss_freq: 0.022608
[17:40:58.388] iteration 17585: loss: 0.068342, loss_s1: 0.035442, loss_fp: 0.003647, loss_freq: 0.043226
[17:40:59.009] iteration 17586: loss: 0.099366, loss_s1: 0.042277, loss_fp: 0.002398, loss_freq: 0.115960
[17:40:59.628] iteration 17587: loss: 0.081438, loss_s1: 0.055979, loss_fp: 0.012387, loss_freq: 0.038128
[17:41:00.248] iteration 17588: loss: 0.067273, loss_s1: 0.047031, loss_fp: 0.001110, loss_freq: 0.041331
[17:41:00.870] iteration 17589: loss: 0.087969, loss_s1: 0.070878, loss_fp: 0.002505, loss_freq: 0.072600
[17:41:01.491] iteration 17590: loss: 0.081789, loss_s1: 0.054051, loss_fp: 0.003475, loss_freq: 0.018652
[17:41:02.116] iteration 17591: loss: 0.052928, loss_s1: 0.045865, loss_fp: 0.003913, loss_freq: 0.025515
[17:41:02.737] iteration 17592: loss: 0.043879, loss_s1: 0.032294, loss_fp: 0.004162, loss_freq: 0.014450
[17:41:03.359] iteration 17593: loss: 0.049866, loss_s1: 0.023328, loss_fp: 0.003738, loss_freq: 0.038588
[17:41:03.978] iteration 17594: loss: 0.065599, loss_s1: 0.052210, loss_fp: 0.007382, loss_freq: 0.029579
[17:41:04.602] iteration 17595: loss: 0.053251, loss_s1: 0.048286, loss_fp: 0.002876, loss_freq: 0.013749
[17:41:05.225] iteration 17596: loss: 0.034660, loss_s1: 0.022384, loss_fp: 0.000705, loss_freq: 0.010732
[17:41:05.848] iteration 17597: loss: 0.051589, loss_s1: 0.057891, loss_fp: 0.001200, loss_freq: 0.010451
[17:41:06.467] iteration 17598: loss: 0.055300, loss_s1: 0.031834, loss_fp: 0.003258, loss_freq: 0.010972
[17:41:07.091] iteration 17599: loss: 0.066979, loss_s1: 0.074545, loss_fp: 0.002294, loss_freq: 0.025819
[17:41:07.711] iteration 17600: loss: 0.075302, loss_s1: 0.082750, loss_fp: 0.002553, loss_freq: 0.034119
[17:41:10.845] iteration 17600 : mean_dice : 0.718663
[17:41:11.493] iteration 17601: loss: 0.101948, loss_s1: 0.076035, loss_fp: 0.010706, loss_freq: 0.033898
[17:41:12.113] iteration 17602: loss: 0.080365, loss_s1: 0.053963, loss_fp: 0.003468, loss_freq: 0.049557
[17:41:12.733] iteration 17603: loss: 0.055049, loss_s1: 0.026467, loss_fp: 0.004116, loss_freq: 0.042501
[17:41:13.356] iteration 17604: loss: 0.031358, loss_s1: 0.014794, loss_fp: 0.001193, loss_freq: 0.015017
[17:41:13.977] iteration 17605: loss: 0.066551, loss_s1: 0.042849, loss_fp: 0.002101, loss_freq: 0.033739
[17:41:14.598] iteration 17606: loss: 0.052116, loss_s1: 0.049709, loss_fp: 0.005170, loss_freq: 0.011017
[17:41:15.219] iteration 17607: loss: 0.062990, loss_s1: 0.050164, loss_fp: 0.000554, loss_freq: 0.020714
[17:41:15.843] iteration 17608: loss: 0.033441, loss_s1: 0.022034, loss_fp: 0.002047, loss_freq: 0.011290
[17:41:16.464] iteration 17609: loss: 0.042030, loss_s1: 0.028869, loss_fp: 0.001885, loss_freq: 0.019595
[17:41:17.090] iteration 17610: loss: 0.054158, loss_s1: 0.035355, loss_fp: 0.002062, loss_freq: 0.016153
[17:41:17.711] iteration 17611: loss: 0.047062, loss_s1: 0.026000, loss_fp: 0.023493, loss_freq: 0.011623
[17:41:18.334] iteration 17612: loss: 0.055437, loss_s1: 0.040776, loss_fp: 0.002003, loss_freq: 0.019436
[17:41:18.955] iteration 17613: loss: 0.031935, loss_s1: 0.013205, loss_fp: 0.001004, loss_freq: 0.007954
[17:41:19.670] iteration 17614: loss: 0.044401, loss_s1: 0.026938, loss_fp: 0.000924, loss_freq: 0.018148
[17:41:20.403] iteration 17615: loss: 0.057463, loss_s1: 0.030491, loss_fp: 0.004161, loss_freq: 0.043708
[17:41:21.039] iteration 17616: loss: 0.061576, loss_s1: 0.040871, loss_fp: 0.003780, loss_freq: 0.033124
[17:41:21.678] iteration 17617: loss: 0.052548, loss_s1: 0.033265, loss_fp: 0.013401, loss_freq: 0.030659
[17:41:22.299] iteration 17618: loss: 0.042321, loss_s1: 0.030166, loss_fp: 0.001105, loss_freq: 0.012420
[17:41:22.919] iteration 17619: loss: 0.069846, loss_s1: 0.031228, loss_fp: 0.002054, loss_freq: 0.041539
[17:41:23.544] iteration 17620: loss: 0.074737, loss_s1: 0.029103, loss_fp: 0.010557, loss_freq: 0.078689
[17:41:24.167] iteration 17621: loss: 0.052540, loss_s1: 0.039145, loss_fp: 0.000697, loss_freq: 0.021275
[17:41:24.790] iteration 17622: loss: 0.057507, loss_s1: 0.045506, loss_fp: 0.004848, loss_freq: 0.023571
[17:41:25.411] iteration 17623: loss: 0.050327, loss_s1: 0.037356, loss_fp: 0.006183, loss_freq: 0.012792
[17:41:26.036] iteration 17624: loss: 0.065124, loss_s1: 0.063728, loss_fp: 0.002283, loss_freq: 0.028848
[17:41:26.659] iteration 17625: loss: 0.071144, loss_s1: 0.068730, loss_fp: 0.000545, loss_freq: 0.026078
[17:41:27.282] iteration 17626: loss: 0.062737, loss_s1: 0.031430, loss_fp: 0.000422, loss_freq: 0.058205
[17:41:27.903] iteration 17627: loss: 0.046612, loss_s1: 0.033412, loss_fp: 0.005496, loss_freq: 0.015529
[17:41:28.525] iteration 17628: loss: 0.047908, loss_s1: 0.045799, loss_fp: 0.002625, loss_freq: 0.004276
[17:41:29.140] iteration 17629: loss: 0.056393, loss_s1: 0.037818, loss_fp: 0.001498, loss_freq: 0.035122
[17:41:29.767] iteration 17630: loss: 0.081072, loss_s1: 0.046797, loss_fp: 0.005834, loss_freq: 0.059476
[17:41:30.389] iteration 17631: loss: 0.049619, loss_s1: 0.039100, loss_fp: 0.002074, loss_freq: 0.024186
[17:41:31.033] iteration 17632: loss: 0.192483, loss_s1: 0.172648, loss_fp: 0.001684, loss_freq: 0.176410
[17:41:31.658] iteration 17633: loss: 0.078810, loss_s1: 0.079971, loss_fp: 0.001559, loss_freq: 0.031373
[17:41:32.280] iteration 17634: loss: 0.087229, loss_s1: 0.093762, loss_fp: 0.003769, loss_freq: 0.050545
[17:41:32.900] iteration 17635: loss: 0.053172, loss_s1: 0.053054, loss_fp: 0.004105, loss_freq: 0.012165
[17:41:33.523] iteration 17636: loss: 0.084070, loss_s1: 0.096464, loss_fp: 0.004829, loss_freq: 0.025621
[17:41:34.144] iteration 17637: loss: 0.050724, loss_s1: 0.042751, loss_fp: 0.004599, loss_freq: 0.010558
[17:41:34.767] iteration 17638: loss: 0.094019, loss_s1: 0.097653, loss_fp: 0.005679, loss_freq: 0.040763
[17:41:35.390] iteration 17639: loss: 0.068131, loss_s1: 0.057457, loss_fp: 0.002188, loss_freq: 0.018261
[17:41:36.014] iteration 17640: loss: 0.065209, loss_s1: 0.035355, loss_fp: 0.002844, loss_freq: 0.035741
[17:41:36.662] iteration 17641: loss: 0.076707, loss_s1: 0.067513, loss_fp: 0.003812, loss_freq: 0.026140
[17:41:37.320] iteration 17642: loss: 0.047431, loss_s1: 0.022573, loss_fp: 0.003019, loss_freq: 0.016943
[17:41:37.986] iteration 17643: loss: 0.041003, loss_s1: 0.031649, loss_fp: 0.002093, loss_freq: 0.009605
[17:41:38.632] iteration 17644: loss: 0.055289, loss_s1: 0.057176, loss_fp: 0.005858, loss_freq: 0.016438
[17:41:39.265] iteration 17645: loss: 0.054779, loss_s1: 0.034242, loss_fp: 0.002114, loss_freq: 0.029325
[17:41:39.895] iteration 17646: loss: 0.058101, loss_s1: 0.039887, loss_fp: 0.004812, loss_freq: 0.023849
[17:41:40.529] iteration 17647: loss: 0.046262, loss_s1: 0.006757, loss_fp: 0.003772, loss_freq: 0.033446
[17:41:41.159] iteration 17648: loss: 0.085891, loss_s1: 0.075661, loss_fp: 0.004507, loss_freq: 0.049698
[17:41:41.790] iteration 17649: loss: 0.055537, loss_s1: 0.052809, loss_fp: 0.004148, loss_freq: 0.015294
[17:41:42.421] iteration 17650: loss: 0.050280, loss_s1: 0.050495, loss_fp: 0.009092, loss_freq: 0.010438
[17:41:43.050] iteration 17651: loss: 0.078866, loss_s1: 0.027368, loss_fp: 0.014426, loss_freq: 0.061314
[17:41:43.673] iteration 17652: loss: 0.051285, loss_s1: 0.032232, loss_fp: 0.004385, loss_freq: 0.027220
[17:41:44.299] iteration 17653: loss: 0.068608, loss_s1: 0.066247, loss_fp: 0.003568, loss_freq: 0.024032
[17:41:44.927] iteration 17654: loss: 0.057821, loss_s1: 0.014236, loss_fp: 0.004826, loss_freq: 0.012331
[17:41:45.552] iteration 17655: loss: 0.041811, loss_s1: 0.008627, loss_fp: 0.000570, loss_freq: 0.038807
[17:41:46.179] iteration 17656: loss: 0.037959, loss_s1: 0.021212, loss_fp: 0.002979, loss_freq: 0.015949
[17:41:46.821] iteration 17657: loss: 0.075775, loss_s1: 0.054276, loss_fp: 0.001457, loss_freq: 0.046956
[17:41:47.452] iteration 17658: loss: 0.079265, loss_s1: 0.057974, loss_fp: 0.005123, loss_freq: 0.049407
[17:41:48.082] iteration 17659: loss: 0.062759, loss_s1: 0.025477, loss_fp: 0.001689, loss_freq: 0.033935
[17:41:48.713] iteration 17660: loss: 0.064920, loss_s1: 0.039402, loss_fp: 0.003032, loss_freq: 0.033466
[17:41:49.347] iteration 17661: loss: 0.036115, loss_s1: 0.014267, loss_fp: 0.003485, loss_freq: 0.016536
[17:41:49.975] iteration 17662: loss: 0.098847, loss_s1: 0.103412, loss_fp: 0.009562, loss_freq: 0.018842
[17:41:50.603] iteration 17663: loss: 0.049961, loss_s1: 0.020456, loss_fp: 0.002552, loss_freq: 0.023288
[17:41:51.237] iteration 17664: loss: 0.032066, loss_s1: 0.020207, loss_fp: 0.001534, loss_freq: 0.004832
[17:41:51.865] iteration 17665: loss: 0.068890, loss_s1: 0.049327, loss_fp: 0.003747, loss_freq: 0.040687
[17:41:52.495] iteration 17666: loss: 0.057745, loss_s1: 0.037201, loss_fp: 0.004913, loss_freq: 0.034261
[17:41:53.123] iteration 17667: loss: 0.038749, loss_s1: 0.030714, loss_fp: 0.004210, loss_freq: 0.008072
[17:41:53.765] iteration 17668: loss: 0.075052, loss_s1: 0.028502, loss_fp: 0.011389, loss_freq: 0.065059
[17:41:54.435] iteration 17669: loss: 0.089133, loss_s1: 0.064628, loss_fp: 0.002771, loss_freq: 0.077874
[17:41:55.104] iteration 17670: loss: 0.058221, loss_s1: 0.031330, loss_fp: 0.005582, loss_freq: 0.042116
[17:41:55.773] iteration 17671: loss: 0.075170, loss_s1: 0.051768, loss_fp: 0.000875, loss_freq: 0.048044
[17:41:56.413] iteration 17672: loss: 0.141654, loss_s1: 0.215943, loss_fp: 0.008570, loss_freq: 0.020781
[17:41:57.041] iteration 17673: loss: 0.039789, loss_s1: 0.036153, loss_fp: 0.001393, loss_freq: 0.008634
[17:41:57.668] iteration 17674: loss: 0.047040, loss_s1: 0.031554, loss_fp: 0.004042, loss_freq: 0.019951
[17:41:58.298] iteration 17675: loss: 0.091482, loss_s1: 0.064301, loss_fp: 0.006221, loss_freq: 0.045063
[17:41:58.926] iteration 17676: loss: 0.064315, loss_s1: 0.057417, loss_fp: 0.003852, loss_freq: 0.017161
[17:41:59.557] iteration 17677: loss: 0.101039, loss_s1: 0.042617, loss_fp: 0.003361, loss_freq: 0.051271
[17:42:00.190] iteration 17678: loss: 0.090141, loss_s1: 0.108557, loss_fp: 0.002750, loss_freq: 0.029128
[17:42:00.825] iteration 17679: loss: 0.042931, loss_s1: 0.034856, loss_fp: 0.001003, loss_freq: 0.015931
[17:42:01.455] iteration 17680: loss: 0.078299, loss_s1: 0.049320, loss_fp: 0.011221, loss_freq: 0.058504
[17:42:02.081] iteration 17681: loss: 0.067364, loss_s1: 0.068149, loss_fp: 0.000854, loss_freq: 0.026729
[17:42:02.706] iteration 17682: loss: 0.060983, loss_s1: 0.044135, loss_fp: 0.002161, loss_freq: 0.030912
[17:42:03.332] iteration 17683: loss: 0.055248, loss_s1: 0.049553, loss_fp: 0.004315, loss_freq: 0.017865
[17:42:03.959] iteration 17684: loss: 0.057038, loss_s1: 0.038304, loss_fp: 0.001944, loss_freq: 0.039379
[17:42:04.585] iteration 17685: loss: 0.056142, loss_s1: 0.039862, loss_fp: 0.003360, loss_freq: 0.039135
[17:42:05.212] iteration 17686: loss: 0.044757, loss_s1: 0.037374, loss_fp: 0.002536, loss_freq: 0.013200
[17:42:05.838] iteration 17687: loss: 0.033463, loss_s1: 0.016527, loss_fp: 0.003038, loss_freq: 0.014208
[17:42:06.462] iteration 17688: loss: 0.036932, loss_s1: 0.026258, loss_fp: 0.002225, loss_freq: 0.007701
[17:42:07.092] iteration 17689: loss: 0.067071, loss_s1: 0.046192, loss_fp: 0.006093, loss_freq: 0.027608
[17:42:07.717] iteration 17690: loss: 0.072217, loss_s1: 0.066083, loss_fp: 0.000559, loss_freq: 0.031197
[17:42:08.340] iteration 17691: loss: 0.053030, loss_s1: 0.015359, loss_fp: 0.006794, loss_freq: 0.010564
[17:42:08.964] iteration 17692: loss: 0.077176, loss_s1: 0.059006, loss_fp: 0.009840, loss_freq: 0.035982
[17:42:09.593] iteration 17693: loss: 0.060515, loss_s1: 0.044071, loss_fp: 0.019092, loss_freq: 0.016088
[17:42:10.221] iteration 17694: loss: 0.069746, loss_s1: 0.041779, loss_fp: 0.003738, loss_freq: 0.046513
[17:42:10.851] iteration 17695: loss: 0.087340, loss_s1: 0.074809, loss_fp: 0.013382, loss_freq: 0.021700
[17:42:11.477] iteration 17696: loss: 0.089798, loss_s1: 0.046858, loss_fp: 0.004378, loss_freq: 0.090217
[17:42:12.104] iteration 17697: loss: 0.037118, loss_s1: 0.021870, loss_fp: 0.001843, loss_freq: 0.011583
[17:42:12.730] iteration 17698: loss: 0.076556, loss_s1: 0.031498, loss_fp: 0.002170, loss_freq: 0.036289
[17:42:13.358] iteration 17699: loss: 0.076623, loss_s1: 0.069114, loss_fp: 0.006822, loss_freq: 0.025229
[17:42:13.982] iteration 17700: loss: 0.074214, loss_s1: 0.060920, loss_fp: 0.006101, loss_freq: 0.030959
[17:42:14.607] iteration 17701: loss: 0.089229, loss_s1: 0.096588, loss_fp: 0.007536, loss_freq: 0.039406
[17:42:15.235] iteration 17702: loss: 0.049343, loss_s1: 0.042175, loss_fp: 0.001358, loss_freq: 0.024558
[17:42:15.858] iteration 17703: loss: 0.060883, loss_s1: 0.047497, loss_fp: 0.009907, loss_freq: 0.015748
[17:42:16.479] iteration 17704: loss: 0.065426, loss_s1: 0.033970, loss_fp: 0.002561, loss_freq: 0.052295
[17:42:17.104] iteration 17705: loss: 0.080741, loss_s1: 0.057990, loss_fp: 0.002822, loss_freq: 0.046234
[17:42:17.727] iteration 17706: loss: 0.046860, loss_s1: 0.019221, loss_fp: 0.006207, loss_freq: 0.018940
[17:42:18.356] iteration 17707: loss: 0.095365, loss_s1: 0.062547, loss_fp: 0.001381, loss_freq: 0.045357
[17:42:18.982] iteration 17708: loss: 0.119310, loss_s1: 0.144141, loss_fp: 0.001494, loss_freq: 0.054362
[17:42:19.600] iteration 17709: loss: 0.054150, loss_s1: 0.057954, loss_fp: 0.004274, loss_freq: 0.005771
[17:42:20.220] iteration 17710: loss: 0.046919, loss_s1: 0.021365, loss_fp: 0.001588, loss_freq: 0.027907
[17:42:21.158] iteration 17711: loss: 0.066098, loss_s1: 0.069753, loss_fp: 0.000301, loss_freq: 0.021391
[17:42:21.841] iteration 17712: loss: 0.067021, loss_s1: 0.057704, loss_fp: 0.001562, loss_freq: 0.026877
[17:42:22.493] iteration 17713: loss: 0.060319, loss_s1: 0.042006, loss_fp: 0.000765, loss_freq: 0.015475
[17:42:23.119] iteration 17714: loss: 0.035794, loss_s1: 0.017434, loss_fp: 0.000937, loss_freq: 0.015736
[17:42:23.745] iteration 17715: loss: 0.082725, loss_s1: 0.050825, loss_fp: 0.008764, loss_freq: 0.022856
[17:42:24.371] iteration 17716: loss: 0.080811, loss_s1: 0.048593, loss_fp: 0.002893, loss_freq: 0.046435
[17:42:24.998] iteration 17717: loss: 0.033838, loss_s1: 0.020854, loss_fp: 0.003713, loss_freq: 0.007804
[17:42:25.623] iteration 17718: loss: 0.031249, loss_s1: 0.018186, loss_fp: 0.001583, loss_freq: 0.013923
[17:42:26.250] iteration 17719: loss: 0.070083, loss_s1: 0.069187, loss_fp: 0.010229, loss_freq: 0.030491
[17:42:26.874] iteration 17720: loss: 0.085682, loss_s1: 0.114864, loss_fp: 0.002043, loss_freq: 0.020865
[17:42:27.499] iteration 17721: loss: 0.037458, loss_s1: 0.020572, loss_fp: 0.000939, loss_freq: 0.006737
[17:42:28.124] iteration 17722: loss: 0.041258, loss_s1: 0.025550, loss_fp: 0.005458, loss_freq: 0.018031
[17:42:28.748] iteration 17723: loss: 0.066556, loss_s1: 0.049957, loss_fp: 0.003430, loss_freq: 0.050550
[17:42:29.373] iteration 17724: loss: 0.059535, loss_s1: 0.030614, loss_fp: 0.002702, loss_freq: 0.037522
[17:42:30.013] iteration 17725: loss: 0.068941, loss_s1: 0.079671, loss_fp: 0.001449, loss_freq: 0.020522
[17:42:30.655] iteration 17726: loss: 0.086818, loss_s1: 0.039995, loss_fp: 0.004445, loss_freq: 0.095714
[17:42:31.294] iteration 17727: loss: 0.041149, loss_s1: 0.029144, loss_fp: 0.000818, loss_freq: 0.008991
[17:42:31.937] iteration 17728: loss: 0.074769, loss_s1: 0.058782, loss_fp: 0.007848, loss_freq: 0.038746
[17:42:32.578] iteration 17729: loss: 0.031785, loss_s1: 0.009249, loss_fp: 0.001774, loss_freq: 0.008443
[17:42:33.222] iteration 17730: loss: 0.111233, loss_s1: 0.081560, loss_fp: 0.006470, loss_freq: 0.063231
[17:42:33.861] iteration 17731: loss: 0.055005, loss_s1: 0.045414, loss_fp: 0.005257, loss_freq: 0.013477
[17:42:34.498] iteration 17732: loss: 0.067213, loss_s1: 0.052149, loss_fp: 0.003663, loss_freq: 0.016406
[17:42:35.133] iteration 17733: loss: 0.047304, loss_s1: 0.026630, loss_fp: 0.003603, loss_freq: 0.018150
[17:42:35.766] iteration 17734: loss: 0.110411, loss_s1: 0.089647, loss_fp: 0.001539, loss_freq: 0.093136
[17:42:36.406] iteration 17735: loss: 0.045617, loss_s1: 0.028079, loss_fp: 0.000291, loss_freq: 0.032876
[17:42:37.043] iteration 17736: loss: 0.066126, loss_s1: 0.061252, loss_fp: 0.002735, loss_freq: 0.024502
[17:42:37.680] iteration 17737: loss: 0.027383, loss_s1: 0.005847, loss_fp: 0.000276, loss_freq: 0.014297
[17:42:38.322] iteration 17738: loss: 0.108332, loss_s1: 0.085626, loss_fp: 0.016935, loss_freq: 0.075739
[17:42:38.959] iteration 17739: loss: 0.073708, loss_s1: 0.043398, loss_fp: 0.006432, loss_freq: 0.054333
[17:42:39.597] iteration 17740: loss: 0.083122, loss_s1: 0.107934, loss_fp: 0.003891, loss_freq: 0.015991
[17:42:40.232] iteration 17741: loss: 0.035182, loss_s1: 0.033380, loss_fp: 0.002926, loss_freq: 0.005870
[17:42:40.868] iteration 17742: loss: 0.054909, loss_s1: 0.030793, loss_fp: 0.003412, loss_freq: 0.036611
[17:42:41.536] iteration 17743: loss: 0.073623, loss_s1: 0.044245, loss_fp: 0.001052, loss_freq: 0.052453
[17:42:42.194] iteration 17744: loss: 0.051026, loss_s1: 0.036508, loss_fp: 0.003733, loss_freq: 0.007543
[17:42:42.850] iteration 17745: loss: 0.073585, loss_s1: 0.043771, loss_fp: 0.003234, loss_freq: 0.022462
[17:42:43.478] iteration 17746: loss: 0.063498, loss_s1: 0.054418, loss_fp: 0.004095, loss_freq: 0.032747
[17:42:44.105] iteration 17747: loss: 0.056939, loss_s1: 0.044125, loss_fp: 0.002191, loss_freq: 0.021728
[17:42:44.728] iteration 17748: loss: 0.066818, loss_s1: 0.055241, loss_fp: 0.005833, loss_freq: 0.028806
[17:42:45.354] iteration 17749: loss: 0.099711, loss_s1: 0.046635, loss_fp: 0.009102, loss_freq: 0.096587
[17:42:45.982] iteration 17750: loss: 0.044616, loss_s1: 0.035555, loss_fp: 0.001621, loss_freq: 0.015213
[17:42:46.605] iteration 17751: loss: 0.055368, loss_s1: 0.040883, loss_fp: 0.002378, loss_freq: 0.024309
[17:42:47.233] iteration 17752: loss: 0.072169, loss_s1: 0.039700, loss_fp: 0.003686, loss_freq: 0.060137
[17:42:47.858] iteration 17753: loss: 0.065999, loss_s1: 0.061576, loss_fp: 0.002387, loss_freq: 0.041662
[17:42:48.540] iteration 17754: loss: 0.056573, loss_s1: 0.014663, loss_fp: 0.009217, loss_freq: 0.038946
[17:42:49.196] iteration 17755: loss: 0.071677, loss_s1: 0.026176, loss_fp: 0.003078, loss_freq: 0.072210
[17:42:49.851] iteration 17756: loss: 0.058678, loss_s1: 0.054760, loss_fp: 0.002067, loss_freq: 0.014579
[17:42:50.507] iteration 17757: loss: 0.039265, loss_s1: 0.030014, loss_fp: 0.003284, loss_freq: 0.012681
[17:42:51.155] iteration 17758: loss: 0.070400, loss_s1: 0.065795, loss_fp: 0.006429, loss_freq: 0.025447
[17:42:51.781] iteration 17759: loss: 0.083278, loss_s1: 0.055903, loss_fp: 0.003116, loss_freq: 0.030549
[17:42:52.402] iteration 17760: loss: 0.049547, loss_s1: 0.037814, loss_fp: 0.002732, loss_freq: 0.030542
[17:42:53.024] iteration 17761: loss: 0.086783, loss_s1: 0.106961, loss_fp: 0.001889, loss_freq: 0.032252
[17:42:53.644] iteration 17762: loss: 0.060954, loss_s1: 0.042787, loss_fp: 0.004837, loss_freq: 0.023409
[17:42:54.268] iteration 17763: loss: 0.054888, loss_s1: 0.051395, loss_fp: 0.001407, loss_freq: 0.014846
[17:42:54.890] iteration 17764: loss: 0.077366, loss_s1: 0.055497, loss_fp: 0.004760, loss_freq: 0.039293
[17:42:55.513] iteration 17765: loss: 0.028487, loss_s1: 0.013230, loss_fp: 0.000789, loss_freq: 0.010747
[17:42:56.137] iteration 17766: loss: 0.060117, loss_s1: 0.055574, loss_fp: 0.007843, loss_freq: 0.019376
[17:42:56.769] iteration 17767: loss: 0.039486, loss_s1: 0.023188, loss_fp: 0.001762, loss_freq: 0.009635
[17:42:57.396] iteration 17768: loss: 0.063911, loss_s1: 0.051471, loss_fp: 0.002008, loss_freq: 0.016373
[17:42:58.020] iteration 17769: loss: 0.032328, loss_s1: 0.017590, loss_fp: 0.001550, loss_freq: 0.006718
[17:42:58.640] iteration 17770: loss: 0.045207, loss_s1: 0.024744, loss_fp: 0.005708, loss_freq: 0.026974
[17:42:59.270] iteration 17771: loss: 0.038526, loss_s1: 0.015806, loss_fp: 0.002176, loss_freq: 0.018934
[17:42:59.895] iteration 17772: loss: 0.042407, loss_s1: 0.023750, loss_fp: 0.002286, loss_freq: 0.020110
[17:43:00.519] iteration 17773: loss: 0.059078, loss_s1: 0.051099, loss_fp: 0.000502, loss_freq: 0.025814
[17:43:01.156] iteration 17774: loss: 0.055500, loss_s1: 0.037393, loss_fp: 0.012016, loss_freq: 0.029877
[17:43:01.796] iteration 17775: loss: 0.052178, loss_s1: 0.043180, loss_fp: 0.001354, loss_freq: 0.018636
[17:43:02.436] iteration 17776: loss: 0.094764, loss_s1: 0.068379, loss_fp: 0.001160, loss_freq: 0.085063
[17:43:03.070] iteration 17777: loss: 0.086753, loss_s1: 0.033262, loss_fp: 0.004433, loss_freq: 0.059842
[17:43:03.704] iteration 17778: loss: 0.074262, loss_s1: 0.051953, loss_fp: 0.011831, loss_freq: 0.041522
[17:43:04.344] iteration 17779: loss: 0.043667, loss_s1: 0.035331, loss_fp: 0.000780, loss_freq: 0.016962
[17:43:04.979] iteration 17780: loss: 0.066290, loss_s1: 0.064425, loss_fp: 0.002942, loss_freq: 0.020113
[17:43:05.616] iteration 17781: loss: 0.085564, loss_s1: 0.075373, loss_fp: 0.004942, loss_freq: 0.055291
[17:43:06.254] iteration 17782: loss: 0.081600, loss_s1: 0.046333, loss_fp: 0.001183, loss_freq: 0.034103
[17:43:06.963] iteration 17783: loss: 0.050764, loss_s1: 0.031276, loss_fp: 0.001078, loss_freq: 0.026142
[17:43:07.626] iteration 17784: loss: 0.047449, loss_s1: 0.034275, loss_fp: 0.000703, loss_freq: 0.018847
[17:43:08.283] iteration 17785: loss: 0.072489, loss_s1: 0.054034, loss_fp: 0.005262, loss_freq: 0.035654
[17:43:08.932] iteration 17786: loss: 0.062374, loss_s1: 0.053770, loss_fp: 0.000998, loss_freq: 0.018957
[17:43:09.557] iteration 17787: loss: 0.051975, loss_s1: 0.044595, loss_fp: 0.002258, loss_freq: 0.018337
[17:43:10.183] iteration 17788: loss: 0.042669, loss_s1: 0.038601, loss_fp: 0.001271, loss_freq: 0.019887
[17:43:10.807] iteration 17789: loss: 0.021084, loss_s1: 0.009529, loss_fp: 0.000463, loss_freq: 0.006284
[17:43:11.430] iteration 17790: loss: 0.058863, loss_s1: 0.048810, loss_fp: 0.002104, loss_freq: 0.026927
[17:43:12.055] iteration 17791: loss: 0.063591, loss_s1: 0.052134, loss_fp: 0.001345, loss_freq: 0.036279
[17:43:12.678] iteration 17792: loss: 0.059296, loss_s1: 0.023065, loss_fp: 0.014934, loss_freq: 0.035613
[17:43:13.302] iteration 17793: loss: 0.072534, loss_s1: 0.051016, loss_fp: 0.006635, loss_freq: 0.057034
[17:43:13.928] iteration 17794: loss: 0.055259, loss_s1: 0.045004, loss_fp: 0.001730, loss_freq: 0.007518
[17:43:14.554] iteration 17795: loss: 0.052788, loss_s1: 0.050220, loss_fp: 0.002157, loss_freq: 0.019024
[17:43:15.183] iteration 17796: loss: 0.040190, loss_s1: 0.033115, loss_fp: 0.006692, loss_freq: 0.007802
[17:43:15.807] iteration 17797: loss: 0.055154, loss_s1: 0.028217, loss_fp: 0.007714, loss_freq: 0.019494
[17:43:16.435] iteration 17798: loss: 0.030740, loss_s1: 0.009079, loss_fp: 0.002118, loss_freq: 0.017526
[17:43:17.064] iteration 17799: loss: 0.103503, loss_s1: 0.116367, loss_fp: 0.002566, loss_freq: 0.038995
[17:43:17.693] iteration 17800: loss: 0.069137, loss_s1: 0.039316, loss_fp: 0.008680, loss_freq: 0.033721
[17:43:20.882] iteration 17800 : mean_dice : 0.718086
[17:43:21.533] iteration 17801: loss: 0.056273, loss_s1: 0.027282, loss_fp: 0.016495, loss_freq: 0.017253
[17:43:22.157] iteration 17802: loss: 0.058120, loss_s1: 0.044178, loss_fp: 0.003163, loss_freq: 0.014171
[17:43:22.798] iteration 17803: loss: 0.098946, loss_s1: 0.051290, loss_fp: 0.002153, loss_freq: 0.027474
[17:43:23.436] iteration 17804: loss: 0.048344, loss_s1: 0.038387, loss_fp: 0.007320, loss_freq: 0.019872
[17:43:24.072] iteration 17805: loss: 0.050428, loss_s1: 0.049023, loss_fp: 0.003422, loss_freq: 0.017683
[17:43:24.704] iteration 17806: loss: 0.055512, loss_s1: 0.027718, loss_fp: 0.007800, loss_freq: 0.043945
[17:43:25.335] iteration 17807: loss: 0.034327, loss_s1: 0.012052, loss_fp: 0.000286, loss_freq: 0.018387
[17:43:26.011] iteration 17808: loss: 0.049759, loss_s1: 0.016133, loss_fp: 0.003327, loss_freq: 0.025827
[17:43:26.652] iteration 17809: loss: 0.065703, loss_s1: 0.025497, loss_fp: 0.004440, loss_freq: 0.047249
[17:43:27.274] iteration 17810: loss: 0.044710, loss_s1: 0.027488, loss_fp: 0.005591, loss_freq: 0.022725
[17:43:27.902] iteration 17811: loss: 0.086268, loss_s1: 0.097080, loss_fp: 0.008293, loss_freq: 0.018532
[17:43:28.527] iteration 17812: loss: 0.083501, loss_s1: 0.063834, loss_fp: 0.003899, loss_freq: 0.043100
[17:43:29.149] iteration 17813: loss: 0.066429, loss_s1: 0.049704, loss_fp: 0.006324, loss_freq: 0.036021
[17:43:29.773] iteration 17814: loss: 0.067363, loss_s1: 0.041222, loss_fp: 0.010275, loss_freq: 0.046582
[17:43:30.394] iteration 17815: loss: 0.065616, loss_s1: 0.058402, loss_fp: 0.001159, loss_freq: 0.022374
[17:43:31.016] iteration 17816: loss: 0.050905, loss_s1: 0.030218, loss_fp: 0.003716, loss_freq: 0.034264
[17:43:31.639] iteration 17817: loss: 0.064490, loss_s1: 0.051501, loss_fp: 0.001080, loss_freq: 0.019735
[17:43:32.267] iteration 17818: loss: 0.063464, loss_s1: 0.036370, loss_fp: 0.002975, loss_freq: 0.034622
[17:43:32.891] iteration 17819: loss: 0.163603, loss_s1: 0.132621, loss_fp: 0.004815, loss_freq: 0.132076
[17:43:33.515] iteration 17820: loss: 0.055164, loss_s1: 0.047036, loss_fp: 0.001042, loss_freq: 0.019384
[17:43:34.139] iteration 17821: loss: 0.042904, loss_s1: 0.018016, loss_fp: 0.002642, loss_freq: 0.013003
[17:43:34.763] iteration 17822: loss: 0.068391, loss_s1: 0.055135, loss_fp: 0.004429, loss_freq: 0.038446
[17:43:35.387] iteration 17823: loss: 0.054984, loss_s1: 0.033984, loss_fp: 0.013178, loss_freq: 0.026628
[17:43:36.012] iteration 17824: loss: 0.066007, loss_s1: 0.067653, loss_fp: 0.003735, loss_freq: 0.022212
[17:43:36.638] iteration 17825: loss: 0.037440, loss_s1: 0.017590, loss_fp: 0.003511, loss_freq: 0.008751
[17:43:37.266] iteration 17826: loss: 0.059685, loss_s1: 0.040659, loss_fp: 0.004247, loss_freq: 0.034656
[17:43:37.889] iteration 17827: loss: 0.043501, loss_s1: 0.033344, loss_fp: 0.000807, loss_freq: 0.007377
[17:43:38.511] iteration 17828: loss: 0.054137, loss_s1: 0.032855, loss_fp: 0.002124, loss_freq: 0.028799
[17:43:39.135] iteration 17829: loss: 0.082957, loss_s1: 0.052638, loss_fp: 0.004121, loss_freq: 0.068672
[17:43:39.767] iteration 17830: loss: 0.121379, loss_s1: 0.115550, loss_fp: 0.005416, loss_freq: 0.091062
[17:43:40.399] iteration 17831: loss: 0.035065, loss_s1: 0.028677, loss_fp: 0.001301, loss_freq: 0.004341
[17:43:41.065] iteration 17832: loss: 0.074257, loss_s1: 0.052296, loss_fp: 0.004624, loss_freq: 0.041407
[17:43:41.702] iteration 17833: loss: 0.062708, loss_s1: 0.035298, loss_fp: 0.002818, loss_freq: 0.011760
[17:43:42.332] iteration 17834: loss: 0.041483, loss_s1: 0.036183, loss_fp: 0.001176, loss_freq: 0.009695
[17:43:42.961] iteration 17835: loss: 0.071335, loss_s1: 0.037370, loss_fp: 0.000898, loss_freq: 0.025456
[17:43:43.595] iteration 17836: loss: 0.052000, loss_s1: 0.034693, loss_fp: 0.001092, loss_freq: 0.012523
[17:43:44.225] iteration 17837: loss: 0.042023, loss_s1: 0.027125, loss_fp: 0.000971, loss_freq: 0.017692
[17:43:44.860] iteration 17838: loss: 0.071191, loss_s1: 0.054127, loss_fp: 0.004647, loss_freq: 0.025901
[17:43:45.489] iteration 17839: loss: 0.065608, loss_s1: 0.057439, loss_fp: 0.010970, loss_freq: 0.029824
[17:43:46.120] iteration 17840: loss: 0.040034, loss_s1: 0.031245, loss_fp: 0.002253, loss_freq: 0.019276
[17:43:46.755] iteration 17841: loss: 0.075258, loss_s1: 0.068429, loss_fp: 0.004562, loss_freq: 0.049818
[17:43:47.418] iteration 17842: loss: 0.041028, loss_s1: 0.027641, loss_fp: 0.001674, loss_freq: 0.018528
[17:43:48.050] iteration 17843: loss: 0.051835, loss_s1: 0.020175, loss_fp: 0.005497, loss_freq: 0.017767
[17:43:48.680] iteration 17844: loss: 0.062375, loss_s1: 0.030525, loss_fp: 0.002851, loss_freq: 0.013269
[17:43:49.304] iteration 17845: loss: 0.046522, loss_s1: 0.033870, loss_fp: 0.001550, loss_freq: 0.022655
[17:43:49.933] iteration 17846: loss: 0.048613, loss_s1: 0.042265, loss_fp: 0.005296, loss_freq: 0.020731
[17:43:50.559] iteration 17847: loss: 0.038078, loss_s1: 0.009665, loss_fp: 0.001729, loss_freq: 0.009761
[17:43:51.190] iteration 17848: loss: 0.037903, loss_s1: 0.023177, loss_fp: 0.004481, loss_freq: 0.022154
[17:43:51.844] iteration 17849: loss: 0.033252, loss_s1: 0.022053, loss_fp: 0.002784, loss_freq: 0.008337
[17:43:52.468] iteration 17850: loss: 0.061721, loss_s1: 0.034910, loss_fp: 0.001809, loss_freq: 0.042761
[17:43:53.095] iteration 17851: loss: 0.062297, loss_s1: 0.058508, loss_fp: 0.001946, loss_freq: 0.031017
[17:43:53.720] iteration 17852: loss: 0.047083, loss_s1: 0.039122, loss_fp: 0.003700, loss_freq: 0.012189
[17:43:54.345] iteration 17853: loss: 0.071835, loss_s1: 0.032228, loss_fp: 0.003525, loss_freq: 0.056250
[17:43:54.971] iteration 17854: loss: 0.076387, loss_s1: 0.079174, loss_fp: 0.002169, loss_freq: 0.034527
[17:43:55.592] iteration 17855: loss: 0.036555, loss_s1: 0.019373, loss_fp: 0.005261, loss_freq: 0.011050
[17:43:56.219] iteration 17856: loss: 0.079782, loss_s1: 0.058446, loss_fp: 0.009124, loss_freq: 0.041052
[17:43:56.847] iteration 17857: loss: 0.094514, loss_s1: 0.072374, loss_fp: 0.004897, loss_freq: 0.082394
[17:43:57.476] iteration 17858: loss: 0.046211, loss_s1: 0.052711, loss_fp: 0.001082, loss_freq: 0.010261
[17:43:58.095] iteration 17859: loss: 0.041866, loss_s1: 0.020276, loss_fp: 0.002474, loss_freq: 0.015968
[17:43:58.720] iteration 17860: loss: 0.107795, loss_s1: 0.114962, loss_fp: 0.004267, loss_freq: 0.053402
[17:43:59.346] iteration 17861: loss: 0.060637, loss_s1: 0.033473, loss_fp: 0.008353, loss_freq: 0.018296
[17:43:59.972] iteration 17862: loss: 0.063831, loss_s1: 0.053858, loss_fp: 0.002200, loss_freq: 0.038360
[17:44:00.591] iteration 17863: loss: 0.042025, loss_s1: 0.022338, loss_fp: 0.002878, loss_freq: 0.023770
[17:44:01.214] iteration 17864: loss: 0.052497, loss_s1: 0.033833, loss_fp: 0.005829, loss_freq: 0.018132
[17:44:01.839] iteration 17865: loss: 0.041592, loss_s1: 0.033598, loss_fp: 0.004377, loss_freq: 0.012123
[17:44:02.462] iteration 17866: loss: 0.058819, loss_s1: 0.046233, loss_fp: 0.003158, loss_freq: 0.025109
[17:44:03.086] iteration 17867: loss: 0.053003, loss_s1: 0.038169, loss_fp: 0.000743, loss_freq: 0.017498
[17:44:03.742] iteration 17868: loss: 0.071170, loss_s1: 0.055656, loss_fp: 0.001002, loss_freq: 0.040233
[17:44:04.402] iteration 17869: loss: 0.084814, loss_s1: 0.081768, loss_fp: 0.007795, loss_freq: 0.044067
[17:44:05.042] iteration 17870: loss: 0.056201, loss_s1: 0.042434, loss_fp: 0.003283, loss_freq: 0.011432
[17:44:05.663] iteration 17871: loss: 0.044629, loss_s1: 0.019340, loss_fp: 0.002437, loss_freq: 0.018595
[17:44:06.611] iteration 17872: loss: 0.040035, loss_s1: 0.032325, loss_fp: 0.000744, loss_freq: 0.011617
[17:44:07.239] iteration 17873: loss: 0.077883, loss_s1: 0.052400, loss_fp: 0.008370, loss_freq: 0.054441
[17:44:07.859] iteration 17874: loss: 0.052186, loss_s1: 0.045518, loss_fp: 0.002023, loss_freq: 0.020984
[17:44:08.480] iteration 17875: loss: 0.038575, loss_s1: 0.020080, loss_fp: 0.001103, loss_freq: 0.008054
[17:44:09.101] iteration 17876: loss: 0.064058, loss_s1: 0.042875, loss_fp: 0.001333, loss_freq: 0.022924
[17:44:09.722] iteration 17877: loss: 0.130694, loss_s1: 0.089486, loss_fp: 0.027289, loss_freq: 0.050259
[17:44:10.343] iteration 17878: loss: 0.061289, loss_s1: 0.033564, loss_fp: 0.005292, loss_freq: 0.037221
[17:44:10.992] iteration 17879: loss: 0.042546, loss_s1: 0.039008, loss_fp: 0.001343, loss_freq: 0.009955
[17:44:11.651] iteration 17880: loss: 0.058524, loss_s1: 0.031206, loss_fp: 0.001808, loss_freq: 0.052505
[17:44:12.297] iteration 17881: loss: 0.066776, loss_s1: 0.062548, loss_fp: 0.006970, loss_freq: 0.021391
[17:44:12.925] iteration 17882: loss: 0.039735, loss_s1: 0.015887, loss_fp: 0.001572, loss_freq: 0.015593
[17:44:13.552] iteration 17883: loss: 0.045871, loss_s1: 0.029302, loss_fp: 0.003632, loss_freq: 0.023125
[17:44:14.178] iteration 17884: loss: 0.066083, loss_s1: 0.023167, loss_fp: 0.004819, loss_freq: 0.075312
[17:44:14.809] iteration 17885: loss: 0.060534, loss_s1: 0.047205, loss_fp: 0.004772, loss_freq: 0.030993
[17:44:15.435] iteration 17886: loss: 0.062012, loss_s1: 0.066862, loss_fp: 0.013133, loss_freq: 0.009481
[17:44:16.062] iteration 17887: loss: 0.124139, loss_s1: 0.102999, loss_fp: 0.007440, loss_freq: 0.102734
[17:44:16.689] iteration 17888: loss: 0.042257, loss_s1: 0.019709, loss_fp: 0.001469, loss_freq: 0.018564
[17:44:17.315] iteration 17889: loss: 0.047731, loss_s1: 0.029919, loss_fp: 0.005623, loss_freq: 0.019987
[17:44:17.943] iteration 17890: loss: 0.047424, loss_s1: 0.025792, loss_fp: 0.000370, loss_freq: 0.030153
[17:44:18.572] iteration 17891: loss: 0.059528, loss_s1: 0.053798, loss_fp: 0.002527, loss_freq: 0.023236
[17:44:19.198] iteration 17892: loss: 0.036586, loss_s1: 0.014389, loss_fp: 0.008665, loss_freq: 0.009073
[17:44:19.821] iteration 17893: loss: 0.034854, loss_s1: 0.020384, loss_fp: 0.002671, loss_freq: 0.011185
[17:44:20.444] iteration 17894: loss: 0.054267, loss_s1: 0.023414, loss_fp: 0.000766, loss_freq: 0.021106
[17:44:21.069] iteration 17895: loss: 0.057809, loss_s1: 0.033573, loss_fp: 0.001321, loss_freq: 0.042578
[17:44:21.692] iteration 17896: loss: 0.055775, loss_s1: 0.054715, loss_fp: 0.000571, loss_freq: 0.021170
[17:44:22.316] iteration 17897: loss: 0.080631, loss_s1: 0.054113, loss_fp: 0.006067, loss_freq: 0.054760
[17:44:22.944] iteration 17898: loss: 0.079326, loss_s1: 0.091349, loss_fp: 0.000455, loss_freq: 0.027398
[17:44:23.568] iteration 17899: loss: 0.068401, loss_s1: 0.054797, loss_fp: 0.007968, loss_freq: 0.027996
[17:44:24.188] iteration 17900: loss: 0.080782, loss_s1: 0.038734, loss_fp: 0.007306, loss_freq: 0.036419
[17:44:24.810] iteration 17901: loss: 0.046283, loss_s1: 0.035200, loss_fp: 0.004927, loss_freq: 0.017476
[17:44:25.471] iteration 17902: loss: 0.054579, loss_s1: 0.064007, loss_fp: 0.001604, loss_freq: 0.015024
[17:44:26.130] iteration 17903: loss: 0.060667, loss_s1: 0.035044, loss_fp: 0.005602, loss_freq: 0.014629
[17:44:26.756] iteration 17904: loss: 0.053978, loss_s1: 0.025987, loss_fp: 0.002081, loss_freq: 0.035568
[17:44:27.379] iteration 17905: loss: 0.053653, loss_s1: 0.049657, loss_fp: 0.003124, loss_freq: 0.011345
[17:44:28.002] iteration 17906: loss: 0.061478, loss_s1: 0.050976, loss_fp: 0.002666, loss_freq: 0.021033
[17:44:28.626] iteration 17907: loss: 0.062133, loss_s1: 0.065534, loss_fp: 0.007162, loss_freq: 0.021044
[17:44:29.247] iteration 17908: loss: 0.083967, loss_s1: 0.082500, loss_fp: 0.001787, loss_freq: 0.050999
[17:44:29.871] iteration 17909: loss: 0.063111, loss_s1: 0.024501, loss_fp: 0.006593, loss_freq: 0.029203
[17:44:30.496] iteration 17910: loss: 0.149652, loss_s1: 0.156046, loss_fp: 0.011248, loss_freq: 0.065750
[17:44:31.122] iteration 17911: loss: 0.051790, loss_s1: 0.032647, loss_fp: 0.004534, loss_freq: 0.029933
[17:44:31.750] iteration 17912: loss: 0.056285, loss_s1: 0.051256, loss_fp: 0.003376, loss_freq: 0.014444
[17:44:32.377] iteration 17913: loss: 0.083476, loss_s1: 0.103897, loss_fp: 0.002424, loss_freq: 0.022919
[17:44:33.000] iteration 17914: loss: 0.076028, loss_s1: 0.077083, loss_fp: 0.013827, loss_freq: 0.023404
[17:44:33.626] iteration 17915: loss: 0.046297, loss_s1: 0.027729, loss_fp: 0.003525, loss_freq: 0.034289
[17:44:34.254] iteration 17916: loss: 0.086826, loss_s1: 0.064317, loss_fp: 0.002813, loss_freq: 0.065784
[17:44:34.878] iteration 17917: loss: 0.052237, loss_s1: 0.048464, loss_fp: 0.002708, loss_freq: 0.011053
[17:44:35.496] iteration 17918: loss: 0.027432, loss_s1: 0.013983, loss_fp: 0.000627, loss_freq: 0.006480
[17:44:36.119] iteration 17919: loss: 0.034076, loss_s1: 0.019874, loss_fp: 0.004817, loss_freq: 0.016168
[17:44:36.743] iteration 17920: loss: 0.072249, loss_s1: 0.086856, loss_fp: 0.002350, loss_freq: 0.012255
[17:44:37.367] iteration 17921: loss: 0.082137, loss_s1: 0.099500, loss_fp: 0.001907, loss_freq: 0.034140
[17:44:37.995] iteration 17922: loss: 0.066188, loss_s1: 0.074425, loss_fp: 0.003881, loss_freq: 0.017410
[17:44:38.618] iteration 17923: loss: 0.042612, loss_s1: 0.020613, loss_fp: 0.004130, loss_freq: 0.015566
[17:44:39.238] iteration 17924: loss: 0.047774, loss_s1: 0.028831, loss_fp: 0.005434, loss_freq: 0.021242
[17:44:39.861] iteration 17925: loss: 0.066624, loss_s1: 0.030160, loss_fp: 0.003037, loss_freq: 0.052132
[17:44:40.483] iteration 17926: loss: 0.040767, loss_s1: 0.009759, loss_fp: 0.002261, loss_freq: 0.007422
[17:44:41.108] iteration 17927: loss: 0.062968, loss_s1: 0.052553, loss_fp: 0.011085, loss_freq: 0.020342
[17:44:41.734] iteration 17928: loss: 0.038962, loss_s1: 0.024707, loss_fp: 0.002115, loss_freq: 0.011299
[17:44:42.360] iteration 17929: loss: 0.066007, loss_s1: 0.032809, loss_fp: 0.002161, loss_freq: 0.035984
[17:44:42.981] iteration 17930: loss: 0.035546, loss_s1: 0.016783, loss_fp: 0.010690, loss_freq: 0.012184
[17:44:43.608] iteration 17931: loss: 0.055254, loss_s1: 0.040232, loss_fp: 0.004281, loss_freq: 0.021888
[17:44:44.225] iteration 17932: loss: 0.030941, loss_s1: 0.007458, loss_fp: 0.002723, loss_freq: 0.015438
[17:44:44.851] iteration 17933: loss: 0.048757, loss_s1: 0.037273, loss_fp: 0.003474, loss_freq: 0.011558
[17:44:45.470] iteration 17934: loss: 0.054264, loss_s1: 0.039238, loss_fp: 0.000793, loss_freq: 0.023559
[17:44:46.096] iteration 17935: loss: 0.049746, loss_s1: 0.033802, loss_fp: 0.004013, loss_freq: 0.021802
[17:44:46.718] iteration 17936: loss: 0.062906, loss_s1: 0.069138, loss_fp: 0.000868, loss_freq: 0.025519
[17:44:47.373] iteration 17937: loss: 0.089709, loss_s1: 0.059486, loss_fp: 0.007100, loss_freq: 0.083493
[17:44:48.016] iteration 17938: loss: 0.058509, loss_s1: 0.028292, loss_fp: 0.008522, loss_freq: 0.030160
[17:44:48.642] iteration 17939: loss: 0.051082, loss_s1: 0.037408, loss_fp: 0.010503, loss_freq: 0.023097
[17:44:49.264] iteration 17940: loss: 0.035514, loss_s1: 0.017988, loss_fp: 0.008092, loss_freq: 0.012178
[17:44:49.887] iteration 17941: loss: 0.059847, loss_s1: 0.044316, loss_fp: 0.001716, loss_freq: 0.025677
[17:44:50.510] iteration 17942: loss: 0.049475, loss_s1: 0.029833, loss_fp: 0.004913, loss_freq: 0.032529
[17:44:51.134] iteration 17943: loss: 0.059857, loss_s1: 0.052473, loss_fp: 0.003930, loss_freq: 0.022749
[17:44:51.757] iteration 17944: loss: 0.056464, loss_s1: 0.055132, loss_fp: 0.006672, loss_freq: 0.004562
[17:44:52.382] iteration 17945: loss: 0.060970, loss_s1: 0.056912, loss_fp: 0.003702, loss_freq: 0.013479
[17:44:53.009] iteration 17946: loss: 0.076061, loss_s1: 0.053888, loss_fp: 0.015842, loss_freq: 0.036123
[17:44:53.633] iteration 17947: loss: 0.059743, loss_s1: 0.054232, loss_fp: 0.000345, loss_freq: 0.004790
[17:44:54.259] iteration 17948: loss: 0.034934, loss_s1: 0.021152, loss_fp: 0.001342, loss_freq: 0.013155
[17:44:54.890] iteration 17949: loss: 0.046794, loss_s1: 0.037964, loss_fp: 0.000819, loss_freq: 0.021686
[17:44:55.511] iteration 17950: loss: 0.038591, loss_s1: 0.027024, loss_fp: 0.000472, loss_freq: 0.009486
[17:44:56.136] iteration 17951: loss: 0.051605, loss_s1: 0.044465, loss_fp: 0.005266, loss_freq: 0.016864
[17:44:56.759] iteration 17952: loss: 0.045527, loss_s1: 0.009595, loss_fp: 0.003535, loss_freq: 0.043504
[17:44:57.382] iteration 17953: loss: 0.080122, loss_s1: 0.053350, loss_fp: 0.002351, loss_freq: 0.073365
[17:44:58.003] iteration 17954: loss: 0.071095, loss_s1: 0.080612, loss_fp: 0.004549, loss_freq: 0.019747
[17:44:58.624] iteration 17955: loss: 0.053096, loss_s1: 0.044666, loss_fp: 0.001652, loss_freq: 0.021205
[17:44:59.244] iteration 17956: loss: 0.076503, loss_s1: 0.070432, loss_fp: 0.009189, loss_freq: 0.046196
[17:44:59.867] iteration 17957: loss: 0.041222, loss_s1: 0.029403, loss_fp: 0.001488, loss_freq: 0.018317
[17:45:00.491] iteration 17958: loss: 0.042214, loss_s1: 0.026857, loss_fp: 0.002945, loss_freq: 0.010414
[17:45:01.115] iteration 17959: loss: 0.054368, loss_s1: 0.028990, loss_fp: 0.007886, loss_freq: 0.011875
[17:45:01.734] iteration 17960: loss: 0.041603, loss_s1: 0.019769, loss_fp: 0.002839, loss_freq: 0.025537
[17:45:02.355] iteration 17961: loss: 0.063297, loss_s1: 0.030819, loss_fp: 0.011145, loss_freq: 0.030605
[17:45:02.977] iteration 17962: loss: 0.062774, loss_s1: 0.047434, loss_fp: 0.003577, loss_freq: 0.027906
[17:45:03.600] iteration 17963: loss: 0.059791, loss_s1: 0.044531, loss_fp: 0.004204, loss_freq: 0.019059
[17:45:04.223] iteration 17964: loss: 0.081752, loss_s1: 0.028031, loss_fp: 0.017987, loss_freq: 0.018124
[17:45:04.842] iteration 17965: loss: 0.053599, loss_s1: 0.055613, loss_fp: 0.000795, loss_freq: 0.012389
[17:45:05.463] iteration 17966: loss: 0.046863, loss_s1: 0.035807, loss_fp: 0.001558, loss_freq: 0.027476
[17:45:06.085] iteration 17967: loss: 0.043200, loss_s1: 0.021004, loss_fp: 0.000807, loss_freq: 0.035001
[17:45:06.701] iteration 17968: loss: 0.043741, loss_s1: 0.024567, loss_fp: 0.000956, loss_freq: 0.020995
[17:45:07.325] iteration 17969: loss: 0.047252, loss_s1: 0.013586, loss_fp: 0.003667, loss_freq: 0.036493
[17:45:07.948] iteration 17970: loss: 0.054940, loss_s1: 0.019903, loss_fp: 0.003637, loss_freq: 0.022123
[17:45:08.567] iteration 17971: loss: 0.049065, loss_s1: 0.051363, loss_fp: 0.003801, loss_freq: 0.005919
[17:45:09.188] iteration 17972: loss: 0.055611, loss_s1: 0.062144, loss_fp: 0.006616, loss_freq: 0.013015
[17:45:09.814] iteration 17973: loss: 0.081439, loss_s1: 0.055699, loss_fp: 0.003315, loss_freq: 0.053773
[17:45:10.441] iteration 17974: loss: 0.082481, loss_s1: 0.072330, loss_fp: 0.002642, loss_freq: 0.049583
[17:45:11.064] iteration 17975: loss: 0.052261, loss_s1: 0.044743, loss_fp: 0.005484, loss_freq: 0.022198
[17:45:11.687] iteration 17976: loss: 0.047817, loss_s1: 0.024782, loss_fp: 0.002155, loss_freq: 0.011731
[17:45:12.311] iteration 17977: loss: 0.065457, loss_s1: 0.032339, loss_fp: 0.004105, loss_freq: 0.043728
[17:45:12.935] iteration 17978: loss: 0.039686, loss_s1: 0.013802, loss_fp: 0.004202, loss_freq: 0.017258
[17:45:13.564] iteration 17979: loss: 0.070859, loss_s1: 0.074797, loss_fp: 0.000788, loss_freq: 0.016085
[17:45:14.182] iteration 17980: loss: 0.108663, loss_s1: 0.102479, loss_fp: 0.002671, loss_freq: 0.071849
[17:45:14.803] iteration 17981: loss: 0.048381, loss_s1: 0.026561, loss_fp: 0.006118, loss_freq: 0.031200
[17:45:15.424] iteration 17982: loss: 0.034961, loss_s1: 0.009727, loss_fp: 0.005667, loss_freq: 0.012580
[17:45:16.047] iteration 17983: loss: 0.055821, loss_s1: 0.040435, loss_fp: 0.001486, loss_freq: 0.035179
[17:45:16.665] iteration 17984: loss: 0.055640, loss_s1: 0.060028, loss_fp: 0.003087, loss_freq: 0.014327
[17:45:17.286] iteration 17985: loss: 0.052142, loss_s1: 0.035450, loss_fp: 0.005825, loss_freq: 0.034550
[17:45:17.905] iteration 17986: loss: 0.044509, loss_s1: 0.030668, loss_fp: 0.005928, loss_freq: 0.015924
[17:45:18.530] iteration 17987: loss: 0.095043, loss_s1: 0.082220, loss_fp: 0.016910, loss_freq: 0.049050
[17:45:19.151] iteration 17988: loss: 0.050037, loss_s1: 0.044379, loss_fp: 0.001993, loss_freq: 0.019390
[17:45:19.773] iteration 17989: loss: 0.046622, loss_s1: 0.043023, loss_fp: 0.001007, loss_freq: 0.012317
[17:45:20.397] iteration 17990: loss: 0.053672, loss_s1: 0.035292, loss_fp: 0.004874, loss_freq: 0.019550
[17:45:21.024] iteration 17991: loss: 0.068131, loss_s1: 0.049961, loss_fp: 0.005298, loss_freq: 0.049996
[17:45:21.646] iteration 17992: loss: 0.083784, loss_s1: 0.018800, loss_fp: 0.003586, loss_freq: 0.107223
[17:45:22.270] iteration 17993: loss: 0.080414, loss_s1: 0.082639, loss_fp: 0.006097, loss_freq: 0.023442
[17:45:22.895] iteration 17994: loss: 0.070980, loss_s1: 0.070450, loss_fp: 0.009903, loss_freq: 0.022678
[17:45:23.518] iteration 17995: loss: 0.053440, loss_s1: 0.047438, loss_fp: 0.001880, loss_freq: 0.019296
[17:45:24.139] iteration 17996: loss: 0.043768, loss_s1: 0.023334, loss_fp: 0.003837, loss_freq: 0.023742
[17:45:24.761] iteration 17997: loss: 0.081286, loss_s1: 0.092173, loss_fp: 0.001334, loss_freq: 0.014985
[17:45:25.383] iteration 17998: loss: 0.083600, loss_s1: 0.101044, loss_fp: 0.001379, loss_freq: 0.026332
[17:45:26.006] iteration 17999: loss: 0.076938, loss_s1: 0.037791, loss_fp: 0.002443, loss_freq: 0.036868
[17:45:26.628] iteration 18000: loss: 0.062859, loss_s1: 0.049118, loss_fp: 0.009919, loss_freq: 0.033583
[17:45:30.376] iteration 18000 : mean_dice : 0.728230
[17:45:31.205] iteration 18001: loss: 0.075315, loss_s1: 0.080317, loss_fp: 0.007207, loss_freq: 0.021609
[17:45:31.954] iteration 18002: loss: 0.088604, loss_s1: 0.035243, loss_fp: 0.005826, loss_freq: 0.098298
[17:45:32.610] iteration 18003: loss: 0.067043, loss_s1: 0.064076, loss_fp: 0.002390, loss_freq: 0.021726
[17:45:33.271] iteration 18004: loss: 0.057771, loss_s1: 0.044479, loss_fp: 0.014797, loss_freq: 0.009942
[17:45:33.968] iteration 18005: loss: 0.043414, loss_s1: 0.039321, loss_fp: 0.001979, loss_freq: 0.009832
[17:45:34.598] iteration 18006: loss: 0.044369, loss_s1: 0.022624, loss_fp: 0.004523, loss_freq: 0.028967
[17:45:35.265] iteration 18007: loss: 0.049471, loss_s1: 0.044295, loss_fp: 0.002616, loss_freq: 0.022471
[17:45:35.929] iteration 18008: loss: 0.056253, loss_s1: 0.040386, loss_fp: 0.001851, loss_freq: 0.022153
[17:45:36.597] iteration 18009: loss: 0.037424, loss_s1: 0.030137, loss_fp: 0.002869, loss_freq: 0.006483
[17:45:37.261] iteration 18010: loss: 0.062604, loss_s1: 0.047810, loss_fp: 0.005955, loss_freq: 0.029842
[17:45:37.898] iteration 18011: loss: 0.060555, loss_s1: 0.038878, loss_fp: 0.000570, loss_freq: 0.019403
[17:45:38.525] iteration 18012: loss: 0.055572, loss_s1: 0.045453, loss_fp: 0.003153, loss_freq: 0.032576
[17:45:39.152] iteration 18013: loss: 0.050668, loss_s1: 0.048261, loss_fp: 0.005175, loss_freq: 0.008907
[17:45:39.782] iteration 18014: loss: 0.071182, loss_s1: 0.046205, loss_fp: 0.003065, loss_freq: 0.028502
[17:45:40.443] iteration 18015: loss: 0.086956, loss_s1: 0.105475, loss_fp: 0.004252, loss_freq: 0.022626
[17:45:41.105] iteration 18016: loss: 0.051322, loss_s1: 0.033551, loss_fp: 0.002473, loss_freq: 0.016357
[17:45:41.774] iteration 18017: loss: 0.044321, loss_s1: 0.022137, loss_fp: 0.002099, loss_freq: 0.007286
[17:45:42.432] iteration 18018: loss: 0.054263, loss_s1: 0.031431, loss_fp: 0.002269, loss_freq: 0.048027
[17:45:43.060] iteration 18019: loss: 0.036279, loss_s1: 0.031819, loss_fp: 0.002566, loss_freq: 0.007352
[17:45:43.688] iteration 18020: loss: 0.056445, loss_s1: 0.035387, loss_fp: 0.004329, loss_freq: 0.023391
[17:45:44.314] iteration 18021: loss: 0.101514, loss_s1: 0.109723, loss_fp: 0.002480, loss_freq: 0.043595
[17:45:44.934] iteration 18022: loss: 0.050981, loss_s1: 0.044207, loss_fp: 0.001464, loss_freq: 0.019744
[17:45:45.562] iteration 18023: loss: 0.073933, loss_s1: 0.071816, loss_fp: 0.001715, loss_freq: 0.044291
[17:45:46.186] iteration 18024: loss: 0.048469, loss_s1: 0.021188, loss_fp: 0.003433, loss_freq: 0.042059
[17:45:46.812] iteration 18025: loss: 0.044996, loss_s1: 0.038658, loss_fp: 0.003468, loss_freq: 0.010916
[17:45:47.437] iteration 18026: loss: 0.035415, loss_s1: 0.020343, loss_fp: 0.004064, loss_freq: 0.018015
[17:45:48.061] iteration 18027: loss: 0.051856, loss_s1: 0.041857, loss_fp: 0.002278, loss_freq: 0.011482
[17:45:48.691] iteration 18028: loss: 0.051500, loss_s1: 0.023319, loss_fp: 0.005226, loss_freq: 0.015642
[17:45:49.316] iteration 18029: loss: 0.058318, loss_s1: 0.022056, loss_fp: 0.001642, loss_freq: 0.027919
[17:45:49.945] iteration 18030: loss: 0.054734, loss_s1: 0.043027, loss_fp: 0.006474, loss_freq: 0.019561
[17:45:50.567] iteration 18031: loss: 0.078208, loss_s1: 0.070967, loss_fp: 0.011786, loss_freq: 0.021651
[17:45:51.188] iteration 18032: loss: 0.046141, loss_s1: 0.020045, loss_fp: 0.002017, loss_freq: 0.019407
[17:45:52.164] iteration 18033: loss: 0.033551, loss_s1: 0.018750, loss_fp: 0.000327, loss_freq: 0.010051
[17:45:52.837] iteration 18034: loss: 0.061304, loss_s1: 0.051646, loss_fp: 0.006333, loss_freq: 0.026765
[17:45:53.496] iteration 18035: loss: 0.042645, loss_s1: 0.026589, loss_fp: 0.004522, loss_freq: 0.009454
[17:45:54.154] iteration 18036: loss: 0.043484, loss_s1: 0.030291, loss_fp: 0.004070, loss_freq: 0.012994
[17:45:54.811] iteration 18037: loss: 0.068305, loss_s1: 0.031097, loss_fp: 0.001787, loss_freq: 0.035610
[17:45:55.447] iteration 18038: loss: 0.084283, loss_s1: 0.068230, loss_fp: 0.009325, loss_freq: 0.041733
[17:45:56.068] iteration 18039: loss: 0.047670, loss_s1: 0.027457, loss_fp: 0.004765, loss_freq: 0.021782
[17:45:56.694] iteration 18040: loss: 0.068591, loss_s1: 0.092860, loss_fp: 0.000439, loss_freq: 0.010339
[17:45:57.319] iteration 18041: loss: 0.050128, loss_s1: 0.036946, loss_fp: 0.006391, loss_freq: 0.025987
[17:45:57.947] iteration 18042: loss: 0.084704, loss_s1: 0.095209, loss_fp: 0.002774, loss_freq: 0.020272
[17:45:58.574] iteration 18043: loss: 0.043006, loss_s1: 0.017381, loss_fp: 0.010911, loss_freq: 0.009455
[17:45:59.198] iteration 18044: loss: 0.030838, loss_s1: 0.020435, loss_fp: 0.000970, loss_freq: 0.006067
[17:45:59.823] iteration 18045: loss: 0.061427, loss_s1: 0.039879, loss_fp: 0.002155, loss_freq: 0.052023
[17:46:00.448] iteration 18046: loss: 0.053855, loss_s1: 0.038059, loss_fp: 0.003929, loss_freq: 0.033731
[17:46:01.072] iteration 18047: loss: 0.051949, loss_s1: 0.049326, loss_fp: 0.000967, loss_freq: 0.011070
[17:46:01.701] iteration 18048: loss: 0.054247, loss_s1: 0.032101, loss_fp: 0.009569, loss_freq: 0.030757
[17:46:02.325] iteration 18049: loss: 0.066127, loss_s1: 0.052911, loss_fp: 0.001590, loss_freq: 0.009386
[17:46:02.951] iteration 18050: loss: 0.064208, loss_s1: 0.062066, loss_fp: 0.007157, loss_freq: 0.023563
[17:46:03.574] iteration 18051: loss: 0.035821, loss_s1: 0.015717, loss_fp: 0.002378, loss_freq: 0.013736
[17:46:04.197] iteration 18052: loss: 0.066235, loss_s1: 0.074480, loss_fp: 0.003025, loss_freq: 0.017992
[17:46:04.824] iteration 18053: loss: 0.042756, loss_s1: 0.024796, loss_fp: 0.001058, loss_freq: 0.012290
[17:46:05.450] iteration 18054: loss: 0.047932, loss_s1: 0.037436, loss_fp: 0.000896, loss_freq: 0.014567
[17:46:06.077] iteration 18055: loss: 0.066286, loss_s1: 0.043453, loss_fp: 0.002310, loss_freq: 0.028294
[17:46:06.699] iteration 18056: loss: 0.082172, loss_s1: 0.102528, loss_fp: 0.001534, loss_freq: 0.020903
[17:46:07.330] iteration 18057: loss: 0.041088, loss_s1: 0.025299, loss_fp: 0.000733, loss_freq: 0.016791
[17:46:07.958] iteration 18058: loss: 0.060439, loss_s1: 0.012718, loss_fp: 0.004949, loss_freq: 0.050965
[17:46:08.581] iteration 18059: loss: 0.041432, loss_s1: 0.033430, loss_fp: 0.010671, loss_freq: 0.004278
[17:46:09.205] iteration 18060: loss: 0.079697, loss_s1: 0.052866, loss_fp: 0.004174, loss_freq: 0.057477
[17:46:09.828] iteration 18061: loss: 0.069625, loss_s1: 0.039289, loss_fp: 0.002655, loss_freq: 0.050982
[17:46:10.449] iteration 18062: loss: 0.047492, loss_s1: 0.035198, loss_fp: 0.002451, loss_freq: 0.009222
[17:46:11.070] iteration 18063: loss: 0.038638, loss_s1: 0.025608, loss_fp: 0.001109, loss_freq: 0.016803
[17:46:11.694] iteration 18064: loss: 0.091489, loss_s1: 0.073689, loss_fp: 0.004713, loss_freq: 0.064162
[17:46:12.317] iteration 18065: loss: 0.062793, loss_s1: 0.075563, loss_fp: 0.002266, loss_freq: 0.016945
[17:46:12.942] iteration 18066: loss: 0.050909, loss_s1: 0.046064, loss_fp: 0.004336, loss_freq: 0.017754
[17:46:13.573] iteration 18067: loss: 0.067140, loss_s1: 0.038147, loss_fp: 0.005382, loss_freq: 0.042248
[17:46:14.196] iteration 18068: loss: 0.060387, loss_s1: 0.049201, loss_fp: 0.003484, loss_freq: 0.036106
[17:46:14.819] iteration 18069: loss: 0.085882, loss_s1: 0.072475, loss_fp: 0.004088, loss_freq: 0.044507
[17:46:15.447] iteration 18070: loss: 0.060088, loss_s1: 0.018067, loss_fp: 0.003052, loss_freq: 0.017880
[17:46:16.072] iteration 18071: loss: 0.086095, loss_s1: 0.042072, loss_fp: 0.002384, loss_freq: 0.067830
[17:46:16.696] iteration 18072: loss: 0.108766, loss_s1: 0.098476, loss_fp: 0.003410, loss_freq: 0.068567
[17:46:17.319] iteration 18073: loss: 0.048562, loss_s1: 0.038027, loss_fp: 0.001027, loss_freq: 0.006756
[17:46:17.944] iteration 18074: loss: 0.050867, loss_s1: 0.030832, loss_fp: 0.003348, loss_freq: 0.029468
[17:46:18.566] iteration 18075: loss: 0.062560, loss_s1: 0.047034, loss_fp: 0.003772, loss_freq: 0.032905
[17:46:19.189] iteration 18076: loss: 0.048495, loss_s1: 0.016841, loss_fp: 0.002973, loss_freq: 0.032827
[17:46:19.813] iteration 18077: loss: 0.054731, loss_s1: 0.039101, loss_fp: 0.003931, loss_freq: 0.026672
[17:46:20.436] iteration 18078: loss: 0.060138, loss_s1: 0.065986, loss_fp: 0.002561, loss_freq: 0.011034
[17:46:21.062] iteration 18079: loss: 0.034728, loss_s1: 0.021303, loss_fp: 0.000273, loss_freq: 0.016013
[17:46:21.685] iteration 18080: loss: 0.047653, loss_s1: 0.039315, loss_fp: 0.001254, loss_freq: 0.021944
[17:46:22.308] iteration 18081: loss: 0.093699, loss_s1: 0.066145, loss_fp: 0.002344, loss_freq: 0.041399
[17:46:22.936] iteration 18082: loss: 0.062739, loss_s1: 0.050903, loss_fp: 0.001940, loss_freq: 0.020537
[17:46:23.560] iteration 18083: loss: 0.033921, loss_s1: 0.019992, loss_fp: 0.000436, loss_freq: 0.010759
[17:46:24.188] iteration 18084: loss: 0.057503, loss_s1: 0.023188, loss_fp: 0.000811, loss_freq: 0.044066
[17:46:24.813] iteration 18085: loss: 0.046512, loss_s1: 0.033706, loss_fp: 0.003039, loss_freq: 0.016507
[17:46:25.469] iteration 18086: loss: 0.055495, loss_s1: 0.036492, loss_fp: 0.007305, loss_freq: 0.024160
[17:46:26.095] iteration 18087: loss: 0.049684, loss_s1: 0.029111, loss_fp: 0.001462, loss_freq: 0.017093
[17:46:26.720] iteration 18088: loss: 0.073150, loss_s1: 0.034010, loss_fp: 0.016782, loss_freq: 0.036108
[17:46:27.346] iteration 18089: loss: 0.050468, loss_s1: 0.037788, loss_fp: 0.001276, loss_freq: 0.013789
[17:46:28.036] iteration 18090: loss: 0.064082, loss_s1: 0.041230, loss_fp: 0.001103, loss_freq: 0.027248
[17:46:28.697] iteration 18091: loss: 0.037120, loss_s1: 0.021483, loss_fp: 0.002092, loss_freq: 0.014331
[17:46:29.359] iteration 18092: loss: 0.043575, loss_s1: 0.030598, loss_fp: 0.001032, loss_freq: 0.022703
[17:46:30.020] iteration 18093: loss: 0.058714, loss_s1: 0.045360, loss_fp: 0.004169, loss_freq: 0.035885
[17:46:30.646] iteration 18094: loss: 0.040234, loss_s1: 0.024856, loss_fp: 0.003855, loss_freq: 0.014402
[17:46:31.270] iteration 18095: loss: 0.042838, loss_s1: 0.017171, loss_fp: 0.001327, loss_freq: 0.016272
[17:46:31.896] iteration 18096: loss: 0.056591, loss_s1: 0.058625, loss_fp: 0.006452, loss_freq: 0.010767
[17:46:32.521] iteration 18097: loss: 0.053679, loss_s1: 0.042726, loss_fp: 0.005421, loss_freq: 0.023094
[17:46:33.148] iteration 18098: loss: 0.075708, loss_s1: 0.034998, loss_fp: 0.008386, loss_freq: 0.075188
[17:46:33.774] iteration 18099: loss: 0.056142, loss_s1: 0.029042, loss_fp: 0.002184, loss_freq: 0.039436
[17:46:34.400] iteration 18100: loss: 0.058827, loss_s1: 0.050777, loss_fp: 0.004403, loss_freq: 0.037883
[17:46:35.023] iteration 18101: loss: 0.070102, loss_s1: 0.054379, loss_fp: 0.002792, loss_freq: 0.031868
[17:46:35.647] iteration 18102: loss: 0.085298, loss_s1: 0.061746, loss_fp: 0.005442, loss_freq: 0.027463
[17:46:36.277] iteration 18103: loss: 0.108687, loss_s1: 0.075696, loss_fp: 0.019294, loss_freq: 0.090168
[17:46:36.900] iteration 18104: loss: 0.045236, loss_s1: 0.025709, loss_fp: 0.001163, loss_freq: 0.020735
[17:46:37.529] iteration 18105: loss: 0.098518, loss_s1: 0.114742, loss_fp: 0.006587, loss_freq: 0.034111
[17:46:38.156] iteration 18106: loss: 0.053832, loss_s1: 0.042783, loss_fp: 0.000730, loss_freq: 0.017170
[17:46:38.782] iteration 18107: loss: 0.082321, loss_s1: 0.087894, loss_fp: 0.001418, loss_freq: 0.031320
[17:46:39.405] iteration 18108: loss: 0.047463, loss_s1: 0.035939, loss_fp: 0.002502, loss_freq: 0.007782
[17:46:40.029] iteration 18109: loss: 0.106640, loss_s1: 0.124874, loss_fp: 0.012375, loss_freq: 0.044609
[17:46:40.655] iteration 18110: loss: 0.050767, loss_s1: 0.059899, loss_fp: 0.004296, loss_freq: 0.009917
[17:46:41.281] iteration 18111: loss: 0.034766, loss_s1: 0.030003, loss_fp: 0.001151, loss_freq: 0.009649
[17:46:41.907] iteration 18112: loss: 0.056608, loss_s1: 0.040161, loss_fp: 0.006750, loss_freq: 0.024517
[17:46:42.532] iteration 18113: loss: 0.058891, loss_s1: 0.054265, loss_fp: 0.002862, loss_freq: 0.028404
[17:46:43.158] iteration 18114: loss: 0.053541, loss_s1: 0.038669, loss_fp: 0.018768, loss_freq: 0.022241
[17:46:43.783] iteration 18115: loss: 0.072944, loss_s1: 0.076104, loss_fp: 0.010976, loss_freq: 0.025372
[17:46:44.407] iteration 18116: loss: 0.083739, loss_s1: 0.057523, loss_fp: 0.013313, loss_freq: 0.057881
[17:46:45.034] iteration 18117: loss: 0.060269, loss_s1: 0.048152, loss_fp: 0.008670, loss_freq: 0.030810
[17:46:45.662] iteration 18118: loss: 0.059156, loss_s1: 0.046843, loss_fp: 0.003705, loss_freq: 0.038547
[17:46:46.290] iteration 18119: loss: 0.044662, loss_s1: 0.024482, loss_fp: 0.004415, loss_freq: 0.021981
[17:46:46.912] iteration 18120: loss: 0.064286, loss_s1: 0.062352, loss_fp: 0.001581, loss_freq: 0.026653
[17:46:47.536] iteration 18121: loss: 0.063794, loss_s1: 0.030972, loss_fp: 0.037399, loss_freq: 0.020371
[17:46:48.164] iteration 18122: loss: 0.071099, loss_s1: 0.058812, loss_fp: 0.003394, loss_freq: 0.036429
[17:46:48.789] iteration 18123: loss: 0.071115, loss_s1: 0.035171, loss_fp: 0.007977, loss_freq: 0.028208
[17:46:49.415] iteration 18124: loss: 0.044109, loss_s1: 0.018054, loss_fp: 0.000953, loss_freq: 0.032083
[17:46:50.038] iteration 18125: loss: 0.044615, loss_s1: 0.016858, loss_fp: 0.001286, loss_freq: 0.020126
[17:46:50.663] iteration 18126: loss: 0.049042, loss_s1: 0.043815, loss_fp: 0.002705, loss_freq: 0.016692
[17:46:51.291] iteration 18127: loss: 0.076643, loss_s1: 0.069259, loss_fp: 0.006037, loss_freq: 0.024313
[17:46:51.913] iteration 18128: loss: 0.076709, loss_s1: 0.049734, loss_fp: 0.009661, loss_freq: 0.058344
[17:46:52.536] iteration 18129: loss: 0.058374, loss_s1: 0.036756, loss_fp: 0.013315, loss_freq: 0.023297
[17:46:53.163] iteration 18130: loss: 0.043950, loss_s1: 0.017370, loss_fp: 0.000345, loss_freq: 0.024898
[17:46:53.791] iteration 18131: loss: 0.050356, loss_s1: 0.020680, loss_fp: 0.017225, loss_freq: 0.025790
[17:46:54.415] iteration 18132: loss: 0.047481, loss_s1: 0.035495, loss_fp: 0.001673, loss_freq: 0.015107
[17:46:55.040] iteration 18133: loss: 0.066309, loss_s1: 0.052521, loss_fp: 0.004121, loss_freq: 0.044613
[17:46:55.664] iteration 18134: loss: 0.079764, loss_s1: 0.057594, loss_fp: 0.002876, loss_freq: 0.050703
[17:46:56.288] iteration 18135: loss: 0.070466, loss_s1: 0.055426, loss_fp: 0.004830, loss_freq: 0.044894
[17:46:56.912] iteration 18136: loss: 0.065756, loss_s1: 0.057820, loss_fp: 0.006092, loss_freq: 0.031975
[17:46:57.537] iteration 18137: loss: 0.069457, loss_s1: 0.066692, loss_fp: 0.008577, loss_freq: 0.009117
[17:46:58.163] iteration 18138: loss: 0.057991, loss_s1: 0.038133, loss_fp: 0.005793, loss_freq: 0.037087
[17:46:58.821] iteration 18139: loss: 0.054307, loss_s1: 0.039209, loss_fp: 0.003617, loss_freq: 0.010292
[17:46:59.476] iteration 18140: loss: 0.072849, loss_s1: 0.057182, loss_fp: 0.004182, loss_freq: 0.037111
[17:47:00.132] iteration 18141: loss: 0.133983, loss_s1: 0.109629, loss_fp: 0.005595, loss_freq: 0.097720
[17:47:00.795] iteration 18142: loss: 0.058069, loss_s1: 0.054617, loss_fp: 0.004178, loss_freq: 0.017707
[17:47:01.420] iteration 18143: loss: 0.047214, loss_s1: 0.016496, loss_fp: 0.009616, loss_freq: 0.023840
[17:47:02.047] iteration 18144: loss: 0.072290, loss_s1: 0.041600, loss_fp: 0.007309, loss_freq: 0.052166
[17:47:02.675] iteration 18145: loss: 0.065092, loss_s1: 0.071119, loss_fp: 0.002028, loss_freq: 0.008994
[17:47:03.303] iteration 18146: loss: 0.035694, loss_s1: 0.015899, loss_fp: 0.002915, loss_freq: 0.012542
[17:47:03.928] iteration 18147: loss: 0.051126, loss_s1: 0.035661, loss_fp: 0.009966, loss_freq: 0.021295
[17:47:04.553] iteration 18148: loss: 0.067829, loss_s1: 0.062103, loss_fp: 0.009175, loss_freq: 0.026880
[17:47:05.178] iteration 18149: loss: 0.085045, loss_s1: 0.070455, loss_fp: 0.002732, loss_freq: 0.067323
[17:47:05.809] iteration 18150: loss: 0.040430, loss_s1: 0.028415, loss_fp: 0.005988, loss_freq: 0.015223
[17:47:06.438] iteration 18151: loss: 0.061217, loss_s1: 0.032516, loss_fp: 0.004226, loss_freq: 0.034114
[17:47:07.068] iteration 18152: loss: 0.068496, loss_s1: 0.039334, loss_fp: 0.012346, loss_freq: 0.059417
[17:47:07.699] iteration 18153: loss: 0.062516, loss_s1: 0.045807, loss_fp: 0.011975, loss_freq: 0.024427
[17:47:08.324] iteration 18154: loss: 0.071059, loss_s1: 0.045486, loss_fp: 0.005404, loss_freq: 0.028969
[17:47:08.950] iteration 18155: loss: 0.068816, loss_s1: 0.085314, loss_fp: 0.003668, loss_freq: 0.007222
[17:47:09.576] iteration 18156: loss: 0.050550, loss_s1: 0.022238, loss_fp: 0.004672, loss_freq: 0.020466
[17:47:10.202] iteration 18157: loss: 0.042196, loss_s1: 0.016921, loss_fp: 0.004198, loss_freq: 0.018694
[17:47:10.825] iteration 18158: loss: 0.044240, loss_s1: 0.015442, loss_fp: 0.009831, loss_freq: 0.013567
[17:47:11.451] iteration 18159: loss: 0.052738, loss_s1: 0.047010, loss_fp: 0.001943, loss_freq: 0.004853
[17:47:12.078] iteration 18160: loss: 0.069969, loss_s1: 0.038421, loss_fp: 0.002392, loss_freq: 0.045675
[17:47:12.700] iteration 18161: loss: 0.068365, loss_s1: 0.058298, loss_fp: 0.004323, loss_freq: 0.024869
[17:47:13.328] iteration 18162: loss: 0.045668, loss_s1: 0.037792, loss_fp: 0.002053, loss_freq: 0.017106
[17:47:13.954] iteration 18163: loss: 0.102803, loss_s1: 0.065289, loss_fp: 0.005600, loss_freq: 0.093057
[17:47:14.578] iteration 18164: loss: 0.105245, loss_s1: 0.135996, loss_fp: 0.006003, loss_freq: 0.027311
[17:47:15.198] iteration 18165: loss: 0.084431, loss_s1: 0.062929, loss_fp: 0.008149, loss_freq: 0.040045
[17:47:15.825] iteration 18166: loss: 0.052383, loss_s1: 0.037154, loss_fp: 0.000844, loss_freq: 0.018359
[17:47:16.461] iteration 18167: loss: 0.064058, loss_s1: 0.023090, loss_fp: 0.001899, loss_freq: 0.063199
[17:47:17.087] iteration 18168: loss: 0.030030, loss_s1: 0.014973, loss_fp: 0.002479, loss_freq: 0.013565
[17:47:17.712] iteration 18169: loss: 0.052939, loss_s1: 0.044369, loss_fp: 0.002225, loss_freq: 0.015289
[17:47:18.339] iteration 18170: loss: 0.060171, loss_s1: 0.038101, loss_fp: 0.011073, loss_freq: 0.031510
[17:47:18.964] iteration 18171: loss: 0.038417, loss_s1: 0.017103, loss_fp: 0.002141, loss_freq: 0.018360
[17:47:19.590] iteration 18172: loss: 0.094232, loss_s1: 0.090607, loss_fp: 0.006162, loss_freq: 0.029569
[17:47:20.221] iteration 18173: loss: 0.093852, loss_s1: 0.069785, loss_fp: 0.018651, loss_freq: 0.058963
[17:47:20.851] iteration 18174: loss: 0.046012, loss_s1: 0.020008, loss_fp: 0.007588, loss_freq: 0.025256
[17:47:21.478] iteration 18175: loss: 0.068744, loss_s1: 0.031985, loss_fp: 0.005845, loss_freq: 0.038711
[17:47:22.105] iteration 18176: loss: 0.075725, loss_s1: 0.077324, loss_fp: 0.002752, loss_freq: 0.025006
[17:47:22.728] iteration 18177: loss: 0.052519, loss_s1: 0.037175, loss_fp: 0.003408, loss_freq: 0.025017
[17:47:23.351] iteration 18178: loss: 0.067821, loss_s1: 0.051736, loss_fp: 0.005025, loss_freq: 0.016171
[17:47:23.974] iteration 18179: loss: 0.097512, loss_s1: 0.067760, loss_fp: 0.005614, loss_freq: 0.087304
[17:47:24.601] iteration 18180: loss: 0.067971, loss_s1: 0.046427, loss_fp: 0.006921, loss_freq: 0.026749
[17:47:25.231] iteration 18181: loss: 0.054463, loss_s1: 0.047036, loss_fp: 0.004109, loss_freq: 0.017892
[17:47:25.859] iteration 18182: loss: 0.087773, loss_s1: 0.083899, loss_fp: 0.010281, loss_freq: 0.034290
[17:47:26.487] iteration 18183: loss: 0.063345, loss_s1: 0.031986, loss_fp: 0.002471, loss_freq: 0.034386
[17:47:27.148] iteration 18184: loss: 0.112018, loss_s1: 0.105066, loss_fp: 0.016837, loss_freq: 0.073401
[17:47:27.808] iteration 18185: loss: 0.040969, loss_s1: 0.017151, loss_fp: 0.003985, loss_freq: 0.017912
[17:47:28.470] iteration 18186: loss: 0.063323, loss_s1: 0.039167, loss_fp: 0.006332, loss_freq: 0.036238
[17:47:29.129] iteration 18187: loss: 0.034988, loss_s1: 0.018046, loss_fp: 0.003252, loss_freq: 0.013552
[17:47:29.778] iteration 18188: loss: 0.070177, loss_s1: 0.023382, loss_fp: 0.005492, loss_freq: 0.028366
[17:47:30.407] iteration 18189: loss: 0.037512, loss_s1: 0.015862, loss_fp: 0.000754, loss_freq: 0.012019
[17:47:31.036] iteration 18190: loss: 0.056503, loss_s1: 0.036318, loss_fp: 0.002324, loss_freq: 0.035209
[17:47:31.661] iteration 18191: loss: 0.054082, loss_s1: 0.026657, loss_fp: 0.008685, loss_freq: 0.040769
[17:47:32.284] iteration 18192: loss: 0.044418, loss_s1: 0.026772, loss_fp: 0.005807, loss_freq: 0.011744
[17:47:32.906] iteration 18193: loss: 0.047620, loss_s1: 0.029999, loss_fp: 0.000999, loss_freq: 0.017785
[17:47:33.936] iteration 18194: loss: 0.034510, loss_s1: 0.020650, loss_fp: 0.002529, loss_freq: 0.014512
[17:47:34.564] iteration 18195: loss: 0.066364, loss_s1: 0.064435, loss_fp: 0.002272, loss_freq: 0.028439
[17:47:35.440] iteration 18196: loss: 0.048646, loss_s1: 0.030158, loss_fp: 0.004243, loss_freq: 0.015912
[17:47:36.216] iteration 18197: loss: 0.047391, loss_s1: 0.021913, loss_fp: 0.002064, loss_freq: 0.026348
[17:47:36.874] iteration 18198: loss: 0.050751, loss_s1: 0.028428, loss_fp: 0.006169, loss_freq: 0.030047
[17:47:37.498] iteration 18199: loss: 0.121334, loss_s1: 0.088161, loss_fp: 0.005147, loss_freq: 0.051026
[17:47:38.119] iteration 18200: loss: 0.045412, loss_s1: 0.028527, loss_fp: 0.007755, loss_freq: 0.026683
[17:47:41.319] iteration 18200 : mean_dice : 0.716659
[17:47:41.967] iteration 18201: loss: 0.039011, loss_s1: 0.026037, loss_fp: 0.001199, loss_freq: 0.022254
[17:47:42.593] iteration 18202: loss: 0.056276, loss_s1: 0.045957, loss_fp: 0.003955, loss_freq: 0.022441
[17:47:43.217] iteration 18203: loss: 0.054425, loss_s1: 0.029903, loss_fp: 0.007039, loss_freq: 0.033520
[17:47:43.842] iteration 18204: loss: 0.033603, loss_s1: 0.018883, loss_fp: 0.004676, loss_freq: 0.007233
[17:47:44.466] iteration 18205: loss: 0.056000, loss_s1: 0.045841, loss_fp: 0.005522, loss_freq: 0.023223
[17:47:45.092] iteration 18206: loss: 0.069454, loss_s1: 0.052036, loss_fp: 0.004056, loss_freq: 0.050177
[17:47:45.714] iteration 18207: loss: 0.050789, loss_s1: 0.031199, loss_fp: 0.001955, loss_freq: 0.022745
[17:47:46.336] iteration 18208: loss: 0.081603, loss_s1: 0.091357, loss_fp: 0.001761, loss_freq: 0.027557
[17:47:46.960] iteration 18209: loss: 0.045991, loss_s1: 0.034847, loss_fp: 0.007098, loss_freq: 0.010891
[17:47:47.583] iteration 18210: loss: 0.042871, loss_s1: 0.035678, loss_fp: 0.001615, loss_freq: 0.010475
[17:47:48.206] iteration 18211: loss: 0.076311, loss_s1: 0.068289, loss_fp: 0.008568, loss_freq: 0.033546
[17:47:48.829] iteration 18212: loss: 0.034718, loss_s1: 0.012965, loss_fp: 0.001096, loss_freq: 0.016370
[17:47:49.454] iteration 18213: loss: 0.056373, loss_s1: 0.055961, loss_fp: 0.002831, loss_freq: 0.021416
[17:47:50.080] iteration 18214: loss: 0.059078, loss_s1: 0.071524, loss_fp: 0.002694, loss_freq: 0.010030
[17:47:50.708] iteration 18215: loss: 0.057967, loss_s1: 0.053043, loss_fp: 0.003840, loss_freq: 0.019938
[17:47:51.335] iteration 18216: loss: 0.040367, loss_s1: 0.020522, loss_fp: 0.001882, loss_freq: 0.007780
[17:47:51.961] iteration 18217: loss: 0.082444, loss_s1: 0.075679, loss_fp: 0.005622, loss_freq: 0.041256
[17:47:52.583] iteration 18218: loss: 0.035496, loss_s1: 0.024645, loss_fp: 0.001261, loss_freq: 0.011218
[17:47:53.207] iteration 18219: loss: 0.070063, loss_s1: 0.084063, loss_fp: 0.000576, loss_freq: 0.024938
[17:47:53.829] iteration 18220: loss: 0.024716, loss_s1: 0.006744, loss_fp: 0.000462, loss_freq: 0.005376
[17:47:54.454] iteration 18221: loss: 0.092151, loss_s1: 0.116772, loss_fp: 0.004373, loss_freq: 0.024472
[17:47:55.082] iteration 18222: loss: 0.052919, loss_s1: 0.031228, loss_fp: 0.001144, loss_freq: 0.043005
[17:47:55.708] iteration 18223: loss: 0.040703, loss_s1: 0.032447, loss_fp: 0.001371, loss_freq: 0.015466
[17:47:56.334] iteration 18224: loss: 0.037495, loss_s1: 0.021985, loss_fp: 0.004521, loss_freq: 0.019329
[17:47:56.956] iteration 18225: loss: 0.047272, loss_s1: 0.036323, loss_fp: 0.003684, loss_freq: 0.011175
[17:47:57.584] iteration 18226: loss: 0.047361, loss_s1: 0.034214, loss_fp: 0.001001, loss_freq: 0.013360
[17:47:58.212] iteration 18227: loss: 0.029077, loss_s1: 0.019385, loss_fp: 0.001082, loss_freq: 0.006905
[17:47:58.836] iteration 18228: loss: 0.102539, loss_s1: 0.053461, loss_fp: 0.001846, loss_freq: 0.030978
[17:47:59.461] iteration 18229: loss: 0.071910, loss_s1: 0.075634, loss_fp: 0.002605, loss_freq: 0.028042
[17:48:00.087] iteration 18230: loss: 0.058260, loss_s1: 0.035302, loss_fp: 0.002145, loss_freq: 0.039688
[17:48:00.714] iteration 18231: loss: 0.088950, loss_s1: 0.102820, loss_fp: 0.001242, loss_freq: 0.035493
[17:48:01.340] iteration 18232: loss: 0.089545, loss_s1: 0.045414, loss_fp: 0.003460, loss_freq: 0.069089
[17:48:01.964] iteration 18233: loss: 0.061972, loss_s1: 0.035508, loss_fp: 0.001724, loss_freq: 0.046453
[17:48:02.590] iteration 18234: loss: 0.055091, loss_s1: 0.020107, loss_fp: 0.000917, loss_freq: 0.026554
[17:48:03.213] iteration 18235: loss: 0.108105, loss_s1: 0.104705, loss_fp: 0.004920, loss_freq: 0.074558
[17:48:03.831] iteration 18236: loss: 0.050269, loss_s1: 0.039396, loss_fp: 0.003894, loss_freq: 0.023995
[17:48:04.451] iteration 18237: loss: 0.044042, loss_s1: 0.016172, loss_fp: 0.007046, loss_freq: 0.036800
[17:48:05.079] iteration 18238: loss: 0.063457, loss_s1: 0.048772, loss_fp: 0.004432, loss_freq: 0.032765
[17:48:05.705] iteration 18239: loss: 0.034580, loss_s1: 0.022699, loss_fp: 0.001617, loss_freq: 0.009201
[17:48:06.331] iteration 18240: loss: 0.031449, loss_s1: 0.018267, loss_fp: 0.001740, loss_freq: 0.008349
[17:48:06.961] iteration 18241: loss: 0.052575, loss_s1: 0.050470, loss_fp: 0.001380, loss_freq: 0.012218
[17:48:07.583] iteration 18242: loss: 0.059732, loss_s1: 0.043444, loss_fp: 0.004277, loss_freq: 0.018695
[17:48:08.208] iteration 18243: loss: 0.072365, loss_s1: 0.050749, loss_fp: 0.012607, loss_freq: 0.049187
[17:48:08.835] iteration 18244: loss: 0.060952, loss_s1: 0.046827, loss_fp: 0.014253, loss_freq: 0.027782
[17:48:09.457] iteration 18245: loss: 0.042130, loss_s1: 0.029269, loss_fp: 0.002945, loss_freq: 0.008054
[17:48:10.083] iteration 18246: loss: 0.066781, loss_s1: 0.051587, loss_fp: 0.003571, loss_freq: 0.032893
[17:48:10.738] iteration 18247: loss: 0.049075, loss_s1: 0.035471, loss_fp: 0.003595, loss_freq: 0.022822
[17:48:11.396] iteration 18248: loss: 0.057642, loss_s1: 0.048707, loss_fp: 0.000977, loss_freq: 0.016536
[17:48:12.049] iteration 18249: loss: 0.108813, loss_s1: 0.132735, loss_fp: 0.002414, loss_freq: 0.020798
[17:48:12.672] iteration 18250: loss: 0.033634, loss_s1: 0.014407, loss_fp: 0.001263, loss_freq: 0.010764
[17:48:13.304] iteration 18251: loss: 0.069431, loss_s1: 0.049312, loss_fp: 0.001794, loss_freq: 0.023455
[17:48:13.930] iteration 18252: loss: 0.030545, loss_s1: 0.008911, loss_fp: 0.002372, loss_freq: 0.005440
[17:48:14.554] iteration 18253: loss: 0.048361, loss_s1: 0.027927, loss_fp: 0.002754, loss_freq: 0.027768
[17:48:15.178] iteration 18254: loss: 0.039884, loss_s1: 0.026458, loss_fp: 0.002367, loss_freq: 0.010781
[17:48:15.801] iteration 18255: loss: 0.045325, loss_s1: 0.029729, loss_fp: 0.001238, loss_freq: 0.019318
[17:48:16.428] iteration 18256: loss: 0.034596, loss_s1: 0.011742, loss_fp: 0.001253, loss_freq: 0.010088
[17:48:17.053] iteration 18257: loss: 0.054134, loss_s1: 0.050977, loss_fp: 0.004298, loss_freq: 0.021529
[17:48:17.679] iteration 18258: loss: 0.043713, loss_s1: 0.019118, loss_fp: 0.004612, loss_freq: 0.011336
[17:48:18.309] iteration 18259: loss: 0.069840, loss_s1: 0.041473, loss_fp: 0.001760, loss_freq: 0.066390
[17:48:18.935] iteration 18260: loss: 0.062301, loss_s1: 0.041755, loss_fp: 0.000342, loss_freq: 0.048618
[17:48:19.564] iteration 18261: loss: 0.085882, loss_s1: 0.104109, loss_fp: 0.003760, loss_freq: 0.032179
[17:48:20.188] iteration 18262: loss: 0.050549, loss_s1: 0.049501, loss_fp: 0.004338, loss_freq: 0.013003
[17:48:20.814] iteration 18263: loss: 0.059268, loss_s1: 0.047056, loss_fp: 0.001273, loss_freq: 0.014752
[17:48:21.444] iteration 18264: loss: 0.071678, loss_s1: 0.050842, loss_fp: 0.004959, loss_freq: 0.049974
[17:48:22.070] iteration 18265: loss: 0.045820, loss_s1: 0.035027, loss_fp: 0.001396, loss_freq: 0.011237
[17:48:22.695] iteration 18266: loss: 0.053064, loss_s1: 0.039586, loss_fp: 0.002376, loss_freq: 0.027887
[17:48:23.318] iteration 18267: loss: 0.052582, loss_s1: 0.032583, loss_fp: 0.003233, loss_freq: 0.012888
[17:48:23.945] iteration 18268: loss: 0.048741, loss_s1: 0.040807, loss_fp: 0.001178, loss_freq: 0.019117
[17:48:24.570] iteration 18269: loss: 0.039778, loss_s1: 0.016029, loss_fp: 0.001100, loss_freq: 0.012482
[17:48:25.196] iteration 18270: loss: 0.063721, loss_s1: 0.032600, loss_fp: 0.012911, loss_freq: 0.038191
[17:48:25.821] iteration 18271: loss: 0.057763, loss_s1: 0.058218, loss_fp: 0.006870, loss_freq: 0.014742
[17:48:26.446] iteration 18272: loss: 0.053882, loss_s1: 0.073330, loss_fp: 0.002008, loss_freq: 0.009661
[17:48:27.073] iteration 18273: loss: 0.051468, loss_s1: 0.031134, loss_fp: 0.003420, loss_freq: 0.026546
[17:48:27.695] iteration 18274: loss: 0.070646, loss_s1: 0.068956, loss_fp: 0.009335, loss_freq: 0.021231
[17:48:28.319] iteration 18275: loss: 0.053289, loss_s1: 0.047226, loss_fp: 0.002499, loss_freq: 0.026199
[17:48:28.940] iteration 18276: loss: 0.060892, loss_s1: 0.060892, loss_fp: 0.011907, loss_freq: 0.020380
[17:48:29.569] iteration 18277: loss: 0.048952, loss_s1: 0.032967, loss_fp: 0.003773, loss_freq: 0.018304
[17:48:30.195] iteration 18278: loss: 0.035717, loss_s1: 0.027556, loss_fp: 0.001544, loss_freq: 0.012452
[17:48:30.818] iteration 18279: loss: 0.039543, loss_s1: 0.029724, loss_fp: 0.000986, loss_freq: 0.013840
[17:48:31.441] iteration 18280: loss: 0.060696, loss_s1: 0.062177, loss_fp: 0.001507, loss_freq: 0.011258
[17:48:32.067] iteration 18281: loss: 0.044774, loss_s1: 0.028614, loss_fp: 0.004750, loss_freq: 0.014555
[17:48:32.690] iteration 18282: loss: 0.074058, loss_s1: 0.040135, loss_fp: 0.002930, loss_freq: 0.064716
[17:48:33.313] iteration 18283: loss: 0.067563, loss_s1: 0.056235, loss_fp: 0.001720, loss_freq: 0.030402
[17:48:33.939] iteration 18284: loss: 0.064743, loss_s1: 0.050022, loss_fp: 0.016910, loss_freq: 0.018523
[17:48:34.563] iteration 18285: loss: 0.053459, loss_s1: 0.046977, loss_fp: 0.002659, loss_freq: 0.009484
[17:48:35.191] iteration 18286: loss: 0.079497, loss_s1: 0.038847, loss_fp: 0.001960, loss_freq: 0.028505
[17:48:35.819] iteration 18287: loss: 0.060785, loss_s1: 0.054998, loss_fp: 0.001996, loss_freq: 0.022277
[17:48:36.448] iteration 18288: loss: 0.050458, loss_s1: 0.028445, loss_fp: 0.003260, loss_freq: 0.026966
[17:48:37.071] iteration 18289: loss: 0.045277, loss_s1: 0.039273, loss_fp: 0.002753, loss_freq: 0.021367
[17:48:37.699] iteration 18290: loss: 0.033504, loss_s1: 0.009287, loss_fp: 0.001623, loss_freq: 0.015117
[17:48:38.325] iteration 18291: loss: 0.040129, loss_s1: 0.021931, loss_fp: 0.000846, loss_freq: 0.021964
[17:48:38.950] iteration 18292: loss: 0.042694, loss_s1: 0.020236, loss_fp: 0.001498, loss_freq: 0.025715
[17:48:39.575] iteration 18293: loss: 0.043935, loss_s1: 0.030909, loss_fp: 0.004383, loss_freq: 0.019768
[17:48:40.208] iteration 18294: loss: 0.065553, loss_s1: 0.047728, loss_fp: 0.004048, loss_freq: 0.050274
[17:48:40.836] iteration 18295: loss: 0.067908, loss_s1: 0.027277, loss_fp: 0.004481, loss_freq: 0.055327
[17:48:41.463] iteration 18296: loss: 0.040743, loss_s1: 0.039101, loss_fp: 0.000970, loss_freq: 0.011104
[17:48:42.094] iteration 18297: loss: 0.064438, loss_s1: 0.058894, loss_fp: 0.014752, loss_freq: 0.016785
[17:48:42.719] iteration 18298: loss: 0.070788, loss_s1: 0.029766, loss_fp: 0.007180, loss_freq: 0.052782
[17:48:43.343] iteration 18299: loss: 0.051916, loss_s1: 0.032454, loss_fp: 0.004246, loss_freq: 0.032363
[17:48:43.967] iteration 18300: loss: 0.036322, loss_s1: 0.022751, loss_fp: 0.001174, loss_freq: 0.010336
[17:48:44.589] iteration 18301: loss: 0.086643, loss_s1: 0.083465, loss_fp: 0.001297, loss_freq: 0.040777
[17:48:45.215] iteration 18302: loss: 0.100008, loss_s1: 0.082407, loss_fp: 0.006715, loss_freq: 0.048993
[17:48:45.836] iteration 18303: loss: 0.058703, loss_s1: 0.052130, loss_fp: 0.002271, loss_freq: 0.025159
[17:48:46.458] iteration 18304: loss: 0.046764, loss_s1: 0.012242, loss_fp: 0.003533, loss_freq: 0.015761
[17:48:47.082] iteration 18305: loss: 0.061055, loss_s1: 0.030735, loss_fp: 0.006623, loss_freq: 0.052291
[17:48:47.703] iteration 18306: loss: 0.059830, loss_s1: 0.036941, loss_fp: 0.006544, loss_freq: 0.039172
[17:48:48.325] iteration 18307: loss: 0.044037, loss_s1: 0.037956, loss_fp: 0.001853, loss_freq: 0.021320
[17:48:48.948] iteration 18308: loss: 0.027997, loss_s1: 0.010104, loss_fp: 0.002829, loss_freq: 0.006552
[17:48:49.573] iteration 18309: loss: 0.068176, loss_s1: 0.046233, loss_fp: 0.001372, loss_freq: 0.035537
[17:48:50.189] iteration 18310: loss: 0.044889, loss_s1: 0.043159, loss_fp: 0.002326, loss_freq: 0.006742
[17:48:50.815] iteration 18311: loss: 0.042685, loss_s1: 0.026544, loss_fp: 0.002970, loss_freq: 0.022289
[17:48:51.443] iteration 18312: loss: 0.056590, loss_s1: 0.037518, loss_fp: 0.008555, loss_freq: 0.019418
[17:48:52.072] iteration 18313: loss: 0.095679, loss_s1: 0.117910, loss_fp: 0.005673, loss_freq: 0.031149
[17:48:52.695] iteration 18314: loss: 0.067664, loss_s1: 0.030916, loss_fp: 0.001405, loss_freq: 0.064594
[17:48:53.317] iteration 18315: loss: 0.051210, loss_s1: 0.038070, loss_fp: 0.000997, loss_freq: 0.018662
[17:48:53.939] iteration 18316: loss: 0.070430, loss_s1: 0.060712, loss_fp: 0.007440, loss_freq: 0.034634
[17:48:54.565] iteration 18317: loss: 0.049675, loss_s1: 0.037777, loss_fp: 0.000908, loss_freq: 0.025040
[17:48:55.185] iteration 18318: loss: 0.066007, loss_s1: 0.044441, loss_fp: 0.002351, loss_freq: 0.055625
[17:48:55.808] iteration 18319: loss: 0.040107, loss_s1: 0.019094, loss_fp: 0.000561, loss_freq: 0.010987
[17:48:56.433] iteration 18320: loss: 0.044648, loss_s1: 0.017715, loss_fp: 0.008527, loss_freq: 0.002830
[17:48:57.061] iteration 18321: loss: 0.107450, loss_s1: 0.027509, loss_fp: 0.000592, loss_freq: 0.096188
[17:48:57.681] iteration 18322: loss: 0.051987, loss_s1: 0.052436, loss_fp: 0.000663, loss_freq: 0.019833
[17:48:58.305] iteration 18323: loss: 0.038152, loss_s1: 0.019754, loss_fp: 0.004871, loss_freq: 0.014513
[17:48:58.928] iteration 18324: loss: 0.057015, loss_s1: 0.039066, loss_fp: 0.001572, loss_freq: 0.031679
[17:48:59.551] iteration 18325: loss: 0.090250, loss_s1: 0.114200, loss_fp: 0.002812, loss_freq: 0.028044
[17:49:00.177] iteration 18326: loss: 0.058179, loss_s1: 0.031712, loss_fp: 0.006708, loss_freq: 0.027851
[17:49:00.804] iteration 18327: loss: 0.040431, loss_s1: 0.028693, loss_fp: 0.002060, loss_freq: 0.013587
[17:49:01.433] iteration 18328: loss: 0.132705, loss_s1: 0.105695, loss_fp: 0.001548, loss_freq: 0.064893
[17:49:02.055] iteration 18329: loss: 0.041043, loss_s1: 0.032285, loss_fp: 0.007261, loss_freq: 0.013311
[17:49:02.682] iteration 18330: loss: 0.037205, loss_s1: 0.017139, loss_fp: 0.000757, loss_freq: 0.018063
[17:49:03.303] iteration 18331: loss: 0.048391, loss_s1: 0.020107, loss_fp: 0.005126, loss_freq: 0.037163
[17:49:03.924] iteration 18332: loss: 0.050291, loss_s1: 0.056546, loss_fp: 0.003755, loss_freq: 0.007586
[17:49:04.552] iteration 18333: loss: 0.063486, loss_s1: 0.037095, loss_fp: 0.007534, loss_freq: 0.021093
[17:49:05.172] iteration 18334: loss: 0.068550, loss_s1: 0.078859, loss_fp: 0.001734, loss_freq: 0.021675
[17:49:05.807] iteration 18335: loss: 0.047943, loss_s1: 0.018007, loss_fp: 0.001588, loss_freq: 0.042102
[17:49:06.432] iteration 18336: loss: 0.076018, loss_s1: 0.051127, loss_fp: 0.007508, loss_freq: 0.047847
[17:49:07.059] iteration 18337: loss: 0.065279, loss_s1: 0.060640, loss_fp: 0.001239, loss_freq: 0.016497
[17:49:07.683] iteration 18338: loss: 0.073727, loss_s1: 0.074962, loss_fp: 0.004631, loss_freq: 0.019935
[17:49:08.309] iteration 18339: loss: 0.083778, loss_s1: 0.053873, loss_fp: 0.004646, loss_freq: 0.050348
[17:49:08.937] iteration 18340: loss: 0.102017, loss_s1: 0.066741, loss_fp: 0.008345, loss_freq: 0.096150
[17:49:09.574] iteration 18341: loss: 0.066889, loss_s1: 0.072882, loss_fp: 0.002732, loss_freq: 0.028335
[17:49:10.201] iteration 18342: loss: 0.079532, loss_s1: 0.057244, loss_fp: 0.003145, loss_freq: 0.013780
[17:49:10.862] iteration 18343: loss: 0.109252, loss_s1: 0.061530, loss_fp: 0.018706, loss_freq: 0.095492
[17:49:11.525] iteration 18344: loss: 0.068092, loss_s1: 0.026024, loss_fp: 0.005077, loss_freq: 0.015917
[17:49:12.183] iteration 18345: loss: 0.103642, loss_s1: 0.098179, loss_fp: 0.005891, loss_freq: 0.073392
[17:49:12.841] iteration 18346: loss: 0.047682, loss_s1: 0.030996, loss_fp: 0.002721, loss_freq: 0.009989
[17:49:13.498] iteration 18347: loss: 0.090234, loss_s1: 0.074654, loss_fp: 0.002039, loss_freq: 0.035742
[17:49:14.140] iteration 18348: loss: 0.028727, loss_s1: 0.013566, loss_fp: 0.002489, loss_freq: 0.011882
[17:49:14.769] iteration 18349: loss: 0.037459, loss_s1: 0.015367, loss_fp: 0.005778, loss_freq: 0.009957
[17:49:15.424] iteration 18350: loss: 0.054963, loss_s1: 0.024643, loss_fp: 0.001418, loss_freq: 0.025302
[17:49:16.084] iteration 18351: loss: 0.073376, loss_s1: 0.063057, loss_fp: 0.002326, loss_freq: 0.030349
[17:49:16.739] iteration 18352: loss: 0.057083, loss_s1: 0.039265, loss_fp: 0.002276, loss_freq: 0.019952
[17:49:17.378] iteration 18353: loss: 0.050990, loss_s1: 0.045287, loss_fp: 0.001200, loss_freq: 0.012805
[17:49:18.001] iteration 18354: loss: 0.059991, loss_s1: 0.026187, loss_fp: 0.010416, loss_freq: 0.026819
[17:49:18.998] iteration 18355: loss: 0.041696, loss_s1: 0.038446, loss_fp: 0.001685, loss_freq: 0.008893
[17:49:19.634] iteration 18356: loss: 0.072977, loss_s1: 0.087690, loss_fp: 0.001635, loss_freq: 0.014004
[17:49:20.255] iteration 18357: loss: 0.043137, loss_s1: 0.015885, loss_fp: 0.002686, loss_freq: 0.021386
[17:49:20.880] iteration 18358: loss: 0.039495, loss_s1: 0.007920, loss_fp: 0.001053, loss_freq: 0.021624
[17:49:21.505] iteration 18359: loss: 0.055496, loss_s1: 0.056180, loss_fp: 0.001244, loss_freq: 0.013501
[17:49:22.132] iteration 18360: loss: 0.119795, loss_s1: 0.102744, loss_fp: 0.010432, loss_freq: 0.048024
[17:49:22.755] iteration 18361: loss: 0.034321, loss_s1: 0.021726, loss_fp: 0.001912, loss_freq: 0.013113
[17:49:23.380] iteration 18362: loss: 0.043248, loss_s1: 0.016401, loss_fp: 0.012235, loss_freq: 0.015193
[17:49:24.006] iteration 18363: loss: 0.060570, loss_s1: 0.069093, loss_fp: 0.004605, loss_freq: 0.024046
[17:49:24.635] iteration 18364: loss: 0.080270, loss_s1: 0.099912, loss_fp: 0.008929, loss_freq: 0.017090
[17:49:25.256] iteration 18365: loss: 0.037022, loss_s1: 0.026354, loss_fp: 0.001837, loss_freq: 0.007425
[17:49:25.884] iteration 18366: loss: 0.055941, loss_s1: 0.013726, loss_fp: 0.003582, loss_freq: 0.057209
[17:49:26.507] iteration 18367: loss: 0.067661, loss_s1: 0.050187, loss_fp: 0.003101, loss_freq: 0.041720
[17:49:27.132] iteration 18368: loss: 0.059257, loss_s1: 0.039813, loss_fp: 0.002966, loss_freq: 0.025743
[17:49:27.755] iteration 18369: loss: 0.120431, loss_s1: 0.108137, loss_fp: 0.015661, loss_freq: 0.086570
[17:49:28.379] iteration 18370: loss: 0.080445, loss_s1: 0.094856, loss_fp: 0.006195, loss_freq: 0.020533
[17:49:29.003] iteration 18371: loss: 0.100854, loss_s1: 0.042318, loss_fp: 0.000473, loss_freq: 0.013481
[17:49:29.627] iteration 18372: loss: 0.081789, loss_s1: 0.064298, loss_fp: 0.006578, loss_freq: 0.036311
[17:49:30.253] iteration 18373: loss: 0.048782, loss_s1: 0.019761, loss_fp: 0.000941, loss_freq: 0.016983
[17:49:30.877] iteration 18374: loss: 0.070178, loss_s1: 0.080365, loss_fp: 0.003780, loss_freq: 0.016451
[17:49:31.502] iteration 18375: loss: 0.046853, loss_s1: 0.037222, loss_fp: 0.001280, loss_freq: 0.008885
[17:49:32.123] iteration 18376: loss: 0.055299, loss_s1: 0.050881, loss_fp: 0.000821, loss_freq: 0.021378
[17:49:32.749] iteration 18377: loss: 0.057851, loss_s1: 0.007321, loss_fp: 0.008894, loss_freq: 0.018182
[17:49:33.370] iteration 18378: loss: 0.114055, loss_s1: 0.091331, loss_fp: 0.003046, loss_freq: 0.095484
[17:49:33.999] iteration 18379: loss: 0.049744, loss_s1: 0.038387, loss_fp: 0.005527, loss_freq: 0.019857
[17:49:34.661] iteration 18380: loss: 0.086647, loss_s1: 0.070351, loss_fp: 0.003379, loss_freq: 0.053227
[17:49:35.321] iteration 18381: loss: 0.044807, loss_s1: 0.035108, loss_fp: 0.000712, loss_freq: 0.015151
[17:49:35.987] iteration 18382: loss: 0.075615, loss_s1: 0.051085, loss_fp: 0.008101, loss_freq: 0.027996
[17:49:36.627] iteration 18383: loss: 0.068968, loss_s1: 0.049901, loss_fp: 0.003797, loss_freq: 0.052234
[17:49:37.255] iteration 18384: loss: 0.050390, loss_s1: 0.037105, loss_fp: 0.001336, loss_freq: 0.011964
[17:49:37.967] iteration 18385: loss: 0.048572, loss_s1: 0.044235, loss_fp: 0.006677, loss_freq: 0.016792
[17:49:38.797] iteration 18386: loss: 0.095515, loss_s1: 0.053833, loss_fp: 0.023174, loss_freq: 0.011073
[17:49:39.559] iteration 18387: loss: 0.060154, loss_s1: 0.046900, loss_fp: 0.008688, loss_freq: 0.017930
[17:49:40.261] iteration 18388: loss: 0.041110, loss_s1: 0.026626, loss_fp: 0.004064, loss_freq: 0.006790
[17:49:40.882] iteration 18389: loss: 0.075354, loss_s1: 0.049680, loss_fp: 0.006535, loss_freq: 0.028794
[17:49:41.509] iteration 18390: loss: 0.080182, loss_s1: 0.062990, loss_fp: 0.010285, loss_freq: 0.050193
[17:49:42.134] iteration 18391: loss: 0.091539, loss_s1: 0.057903, loss_fp: 0.001019, loss_freq: 0.026420
[17:49:42.757] iteration 18392: loss: 0.055036, loss_s1: 0.041967, loss_fp: 0.003484, loss_freq: 0.023814
[17:49:43.381] iteration 18393: loss: 0.085193, loss_s1: 0.075126, loss_fp: 0.003512, loss_freq: 0.049066
[17:49:44.003] iteration 18394: loss: 0.064233, loss_s1: 0.064428, loss_fp: 0.001037, loss_freq: 0.024205
[17:49:44.624] iteration 18395: loss: 0.064193, loss_s1: 0.031171, loss_fp: 0.011202, loss_freq: 0.032015
[17:49:45.247] iteration 18396: loss: 0.079812, loss_s1: 0.056848, loss_fp: 0.008464, loss_freq: 0.049900
[17:49:45.871] iteration 18397: loss: 0.098251, loss_s1: 0.109361, loss_fp: 0.009167, loss_freq: 0.039893
[17:49:46.495] iteration 18398: loss: 0.063465, loss_s1: 0.018258, loss_fp: 0.010398, loss_freq: 0.048228
[17:49:47.121] iteration 18399: loss: 0.053862, loss_s1: 0.026121, loss_fp: 0.002158, loss_freq: 0.033881
[17:49:47.743] iteration 18400: loss: 0.055976, loss_s1: 0.046327, loss_fp: 0.001066, loss_freq: 0.017791
[17:49:50.931] iteration 18400 : mean_dice : 0.730748
[17:49:51.590] iteration 18401: loss: 0.034960, loss_s1: 0.019155, loss_fp: 0.005975, loss_freq: 0.010182
[17:49:52.217] iteration 18402: loss: 0.058374, loss_s1: 0.045228, loss_fp: 0.004068, loss_freq: 0.018342
[17:49:52.842] iteration 18403: loss: 0.076995, loss_s1: 0.059001, loss_fp: 0.004112, loss_freq: 0.040249
[17:49:53.465] iteration 18404: loss: 0.060231, loss_s1: 0.064074, loss_fp: 0.003068, loss_freq: 0.021630
[17:49:54.085] iteration 18405: loss: 0.085309, loss_s1: 0.078699, loss_fp: 0.015141, loss_freq: 0.039398
[17:49:54.711] iteration 18406: loss: 0.073572, loss_s1: 0.066772, loss_fp: 0.005785, loss_freq: 0.035091
[17:49:55.339] iteration 18407: loss: 0.048298, loss_s1: 0.041473, loss_fp: 0.000516, loss_freq: 0.021920
[17:49:55.965] iteration 18408: loss: 0.055216, loss_s1: 0.028407, loss_fp: 0.001066, loss_freq: 0.038242
[17:49:56.591] iteration 18409: loss: 0.042863, loss_s1: 0.018742, loss_fp: 0.000596, loss_freq: 0.019094
[17:49:57.244] iteration 18410: loss: 0.049856, loss_s1: 0.032699, loss_fp: 0.000583, loss_freq: 0.020938
[17:49:57.908] iteration 18411: loss: 0.059692, loss_s1: 0.061686, loss_fp: 0.001001, loss_freq: 0.014785
[17:49:58.565] iteration 18412: loss: 0.048946, loss_s1: 0.023357, loss_fp: 0.001072, loss_freq: 0.013294
[17:49:59.203] iteration 18413: loss: 0.042948, loss_s1: 0.039228, loss_fp: 0.001217, loss_freq: 0.012793
[17:49:59.831] iteration 18414: loss: 0.041150, loss_s1: 0.029177, loss_fp: 0.002442, loss_freq: 0.021614
[17:50:00.449] iteration 18415: loss: 0.051358, loss_s1: 0.023483, loss_fp: 0.001957, loss_freq: 0.013065
[17:50:01.077] iteration 18416: loss: 0.045917, loss_s1: 0.034736, loss_fp: 0.002954, loss_freq: 0.009836
[17:50:01.714] iteration 18417: loss: 0.048948, loss_s1: 0.030528, loss_fp: 0.001629, loss_freq: 0.024081
[17:50:02.345] iteration 18418: loss: 0.056785, loss_s1: 0.056915, loss_fp: 0.003615, loss_freq: 0.009297
[17:50:02.973] iteration 18419: loss: 0.056873, loss_s1: 0.038602, loss_fp: 0.003522, loss_freq: 0.020884
[17:50:03.591] iteration 18420: loss: 0.073367, loss_s1: 0.030909, loss_fp: 0.004507, loss_freq: 0.072384
[17:50:04.220] iteration 18421: loss: 0.070777, loss_s1: 0.024915, loss_fp: 0.008283, loss_freq: 0.055654
[17:50:04.851] iteration 18422: loss: 0.071556, loss_s1: 0.087038, loss_fp: 0.003464, loss_freq: 0.020335
[17:50:05.482] iteration 18423: loss: 0.058517, loss_s1: 0.049586, loss_fp: 0.002234, loss_freq: 0.026692
[17:50:06.114] iteration 18424: loss: 0.070675, loss_s1: 0.049947, loss_fp: 0.000180, loss_freq: 0.022337
[17:50:06.738] iteration 18425: loss: 0.058821, loss_s1: 0.047698, loss_fp: 0.001871, loss_freq: 0.034802
[17:50:07.362] iteration 18426: loss: 0.051308, loss_s1: 0.009285, loss_fp: 0.001247, loss_freq: 0.025065
[17:50:07.987] iteration 18427: loss: 0.048123, loss_s1: 0.025814, loss_fp: 0.003251, loss_freq: 0.034003
[17:50:08.613] iteration 18428: loss: 0.047280, loss_s1: 0.035203, loss_fp: 0.003099, loss_freq: 0.014005
[17:50:09.235] iteration 18429: loss: 0.079563, loss_s1: 0.097718, loss_fp: 0.004140, loss_freq: 0.019796
[17:50:09.859] iteration 18430: loss: 0.052037, loss_s1: 0.027196, loss_fp: 0.003533, loss_freq: 0.014666
[17:50:10.487] iteration 18431: loss: 0.101328, loss_s1: 0.097324, loss_fp: 0.007832, loss_freq: 0.055547
[17:50:11.112] iteration 18432: loss: 0.057278, loss_s1: 0.063496, loss_fp: 0.004687, loss_freq: 0.009910
[17:50:11.744] iteration 18433: loss: 0.044234, loss_s1: 0.052947, loss_fp: 0.002026, loss_freq: 0.006465
[17:50:12.369] iteration 18434: loss: 0.094248, loss_s1: 0.083049, loss_fp: 0.003927, loss_freq: 0.049308
[17:50:13.002] iteration 18435: loss: 0.063763, loss_s1: 0.076478, loss_fp: 0.007250, loss_freq: 0.010137
[17:50:13.624] iteration 18436: loss: 0.089794, loss_s1: 0.090917, loss_fp: 0.005092, loss_freq: 0.053914
[17:50:14.252] iteration 18437: loss: 0.086048, loss_s1: 0.062064, loss_fp: 0.001829, loss_freq: 0.080396
[17:50:14.880] iteration 18438: loss: 0.047623, loss_s1: 0.018471, loss_fp: 0.006501, loss_freq: 0.031162
[17:50:15.508] iteration 18439: loss: 0.088543, loss_s1: 0.101222, loss_fp: 0.002623, loss_freq: 0.044899
[17:50:16.134] iteration 18440: loss: 0.042133, loss_s1: 0.014786, loss_fp: 0.001418, loss_freq: 0.027743
[17:50:16.760] iteration 18441: loss: 0.041014, loss_s1: 0.022741, loss_fp: 0.003546, loss_freq: 0.015748
[17:50:17.391] iteration 18442: loss: 0.039693, loss_s1: 0.030387, loss_fp: 0.002175, loss_freq: 0.011489
[17:50:18.012] iteration 18443: loss: 0.045025, loss_s1: 0.018761, loss_fp: 0.001690, loss_freq: 0.022296
[17:50:18.638] iteration 18444: loss: 0.077537, loss_s1: 0.035145, loss_fp: 0.004118, loss_freq: 0.046421
[17:50:19.264] iteration 18445: loss: 0.048072, loss_s1: 0.026383, loss_fp: 0.001587, loss_freq: 0.017323
[17:50:19.894] iteration 18446: loss: 0.063346, loss_s1: 0.046755, loss_fp: 0.001838, loss_freq: 0.012745
[17:50:20.524] iteration 18447: loss: 0.058425, loss_s1: 0.008369, loss_fp: 0.000673, loss_freq: 0.022669
[17:50:21.153] iteration 18448: loss: 0.037838, loss_s1: 0.018909, loss_fp: 0.003459, loss_freq: 0.008737
[17:50:21.786] iteration 18449: loss: 0.051686, loss_s1: 0.038833, loss_fp: 0.005930, loss_freq: 0.026817
[17:50:22.415] iteration 18450: loss: 0.050328, loss_s1: 0.018462, loss_fp: 0.002058, loss_freq: 0.037532
[17:50:23.039] iteration 18451: loss: 0.075263, loss_s1: 0.027302, loss_fp: 0.003712, loss_freq: 0.018147
[17:50:23.664] iteration 18452: loss: 0.066877, loss_s1: 0.062778, loss_fp: 0.001357, loss_freq: 0.013220
[17:50:24.289] iteration 18453: loss: 0.061467, loss_s1: 0.053192, loss_fp: 0.006725, loss_freq: 0.020897
[17:50:24.915] iteration 18454: loss: 0.059113, loss_s1: 0.063209, loss_fp: 0.003760, loss_freq: 0.014669
[17:50:25.585] iteration 18455: loss: 0.054051, loss_s1: 0.047665, loss_fp: 0.003528, loss_freq: 0.024020
[17:50:26.244] iteration 18456: loss: 0.081719, loss_s1: 0.055138, loss_fp: 0.002830, loss_freq: 0.068813
[17:50:26.885] iteration 18457: loss: 0.097305, loss_s1: 0.102463, loss_fp: 0.003139, loss_freq: 0.052908
[17:50:27.513] iteration 18458: loss: 0.042022, loss_s1: 0.027020, loss_fp: 0.003231, loss_freq: 0.012729
[17:50:28.135] iteration 18459: loss: 0.064714, loss_s1: 0.048922, loss_fp: 0.002244, loss_freq: 0.016301
[17:50:28.760] iteration 18460: loss: 0.043851, loss_s1: 0.023321, loss_fp: 0.004183, loss_freq: 0.031375
[17:50:29.384] iteration 18461: loss: 0.050689, loss_s1: 0.033899, loss_fp: 0.002591, loss_freq: 0.013959
[17:50:30.012] iteration 18462: loss: 0.049892, loss_s1: 0.043376, loss_fp: 0.003397, loss_freq: 0.011372
[17:50:30.639] iteration 18463: loss: 0.080262, loss_s1: 0.031799, loss_fp: 0.008140, loss_freq: 0.062543
[17:50:31.264] iteration 18464: loss: 0.053558, loss_s1: 0.045838, loss_fp: 0.002235, loss_freq: 0.026668
[17:50:31.890] iteration 18465: loss: 0.066152, loss_s1: 0.046941, loss_fp: 0.003094, loss_freq: 0.027244
[17:50:32.516] iteration 18466: loss: 0.064469, loss_s1: 0.036276, loss_fp: 0.010484, loss_freq: 0.043723
[17:50:33.142] iteration 18467: loss: 0.064975, loss_s1: 0.043462, loss_fp: 0.002750, loss_freq: 0.040411
[17:50:33.765] iteration 18468: loss: 0.049938, loss_s1: 0.017786, loss_fp: 0.000540, loss_freq: 0.024263
[17:50:34.394] iteration 18469: loss: 0.046283, loss_s1: 0.032536, loss_fp: 0.004365, loss_freq: 0.011060
[17:50:35.022] iteration 18470: loss: 0.098713, loss_s1: 0.096027, loss_fp: 0.002045, loss_freq: 0.064586
[17:50:35.651] iteration 18471: loss: 0.078032, loss_s1: 0.048184, loss_fp: 0.005914, loss_freq: 0.070303
[17:50:36.279] iteration 18472: loss: 0.043835, loss_s1: 0.041481, loss_fp: 0.003751, loss_freq: 0.006924
[17:50:36.906] iteration 18473: loss: 0.074449, loss_s1: 0.030121, loss_fp: 0.011138, loss_freq: 0.056725
[17:50:37.529] iteration 18474: loss: 0.071023, loss_s1: 0.024035, loss_fp: 0.004099, loss_freq: 0.072741
[17:50:38.155] iteration 18475: loss: 0.041256, loss_s1: 0.020060, loss_fp: 0.001736, loss_freq: 0.025157
[17:50:38.814] iteration 18476: loss: 0.063357, loss_s1: 0.042368, loss_fp: 0.006078, loss_freq: 0.028121
[17:50:39.450] iteration 18477: loss: 0.055288, loss_s1: 0.052020, loss_fp: 0.000719, loss_freq: 0.019044
[17:50:40.078] iteration 18478: loss: 0.030679, loss_s1: 0.011659, loss_fp: 0.000919, loss_freq: 0.005356
[17:50:40.709] iteration 18479: loss: 0.064920, loss_s1: 0.043918, loss_fp: 0.006757, loss_freq: 0.040094
[17:50:41.330] iteration 18480: loss: 0.052777, loss_s1: 0.045397, loss_fp: 0.001431, loss_freq: 0.018733
[17:50:41.954] iteration 18481: loss: 0.049314, loss_s1: 0.032827, loss_fp: 0.001253, loss_freq: 0.017492
[17:50:42.581] iteration 18482: loss: 0.138929, loss_s1: 0.081451, loss_fp: 0.001552, loss_freq: 0.092950
[17:50:43.210] iteration 18483: loss: 0.060617, loss_s1: 0.032788, loss_fp: 0.006942, loss_freq: 0.035615
[17:50:43.839] iteration 18484: loss: 0.045785, loss_s1: 0.041579, loss_fp: 0.001138, loss_freq: 0.010641
[17:50:44.467] iteration 18485: loss: 0.111041, loss_s1: 0.069766, loss_fp: 0.007841, loss_freq: 0.114457
[17:50:45.094] iteration 18486: loss: 0.062564, loss_s1: 0.057337, loss_fp: 0.006822, loss_freq: 0.030362
[17:50:45.725] iteration 18487: loss: 0.103627, loss_s1: 0.107672, loss_fp: 0.001506, loss_freq: 0.032427
[17:50:46.352] iteration 18488: loss: 0.052571, loss_s1: 0.047420, loss_fp: 0.004329, loss_freq: 0.014968
[17:50:46.977] iteration 18489: loss: 0.086906, loss_s1: 0.088234, loss_fp: 0.017865, loss_freq: 0.032240
[17:50:47.603] iteration 18490: loss: 0.038141, loss_s1: 0.026035, loss_fp: 0.003000, loss_freq: 0.013483
[17:50:48.228] iteration 18491: loss: 0.040434, loss_s1: 0.019419, loss_fp: 0.001310, loss_freq: 0.019078
[17:50:48.855] iteration 18492: loss: 0.063541, loss_s1: 0.037791, loss_fp: 0.032907, loss_freq: 0.025653
[17:50:49.483] iteration 18493: loss: 0.042365, loss_s1: 0.022808, loss_fp: 0.007154, loss_freq: 0.016269
[17:50:50.109] iteration 18494: loss: 0.069248, loss_s1: 0.061404, loss_fp: 0.002669, loss_freq: 0.025830
[17:50:50.742] iteration 18495: loss: 0.089335, loss_s1: 0.094713, loss_fp: 0.003549, loss_freq: 0.049405
[17:50:51.367] iteration 18496: loss: 0.062499, loss_s1: 0.024221, loss_fp: 0.001386, loss_freq: 0.032158
[17:50:51.994] iteration 18497: loss: 0.054117, loss_s1: 0.025684, loss_fp: 0.007750, loss_freq: 0.031401
[17:50:52.622] iteration 18498: loss: 0.070413, loss_s1: 0.065452, loss_fp: 0.007607, loss_freq: 0.025886
[17:50:53.250] iteration 18499: loss: 0.041035, loss_s1: 0.027410, loss_fp: 0.003998, loss_freq: 0.014107
[17:50:53.880] iteration 18500: loss: 0.059277, loss_s1: 0.043085, loss_fp: 0.002876, loss_freq: 0.027476
[17:50:54.504] iteration 18501: loss: 0.084033, loss_s1: 0.065726, loss_fp: 0.007542, loss_freq: 0.064856
[17:50:55.129] iteration 18502: loss: 0.068098, loss_s1: 0.054105, loss_fp: 0.002032, loss_freq: 0.027224
[17:50:55.758] iteration 18503: loss: 0.043623, loss_s1: 0.026502, loss_fp: 0.004395, loss_freq: 0.026201
[17:50:56.383] iteration 18504: loss: 0.094029, loss_s1: 0.086001, loss_fp: 0.004049, loss_freq: 0.044995
[17:50:57.017] iteration 18505: loss: 0.072103, loss_s1: 0.062019, loss_fp: 0.005952, loss_freq: 0.037852
[17:50:57.645] iteration 18506: loss: 0.072172, loss_s1: 0.071494, loss_fp: 0.006356, loss_freq: 0.029728
[17:50:58.276] iteration 18507: loss: 0.060981, loss_s1: 0.036961, loss_fp: 0.006212, loss_freq: 0.027162
[17:50:58.904] iteration 18508: loss: 0.077121, loss_s1: 0.072853, loss_fp: 0.002139, loss_freq: 0.024285
[17:50:59.526] iteration 18509: loss: 0.033954, loss_s1: 0.009359, loss_fp: 0.006085, loss_freq: 0.015342
[17:51:00.151] iteration 18510: loss: 0.051257, loss_s1: 0.038433, loss_fp: 0.001221, loss_freq: 0.015408
[17:51:00.775] iteration 18511: loss: 0.036967, loss_s1: 0.025743, loss_fp: 0.000347, loss_freq: 0.006097
[17:51:01.399] iteration 18512: loss: 0.072881, loss_s1: 0.060085, loss_fp: 0.003059, loss_freq: 0.022660
[17:51:02.025] iteration 18513: loss: 0.057933, loss_s1: 0.049099, loss_fp: 0.006155, loss_freq: 0.020843
[17:51:02.650] iteration 18514: loss: 0.057870, loss_s1: 0.048725, loss_fp: 0.002539, loss_freq: 0.023582
[17:51:03.273] iteration 18515: loss: 0.075084, loss_s1: 0.071425, loss_fp: 0.003604, loss_freq: 0.034657
[17:51:04.249] iteration 18516: loss: 0.038436, loss_s1: 0.027817, loss_fp: 0.000674, loss_freq: 0.010442
[17:51:04.878] iteration 18517: loss: 0.053933, loss_s1: 0.025020, loss_fp: 0.000754, loss_freq: 0.012845
[17:51:05.503] iteration 18518: loss: 0.080929, loss_s1: 0.046354, loss_fp: 0.003718, loss_freq: 0.016604
[17:51:06.131] iteration 18519: loss: 0.034765, loss_s1: 0.010547, loss_fp: 0.000685, loss_freq: 0.021545
[17:51:06.756] iteration 18520: loss: 0.046998, loss_s1: 0.018250, loss_fp: 0.002267, loss_freq: 0.029780
[17:51:07.385] iteration 18521: loss: 0.104722, loss_s1: 0.080566, loss_fp: 0.007120, loss_freq: 0.055644
[17:51:08.009] iteration 18522: loss: 0.050082, loss_s1: 0.039136, loss_fp: 0.011371, loss_freq: 0.021255
[17:51:08.635] iteration 18523: loss: 0.054589, loss_s1: 0.047489, loss_fp: 0.000650, loss_freq: 0.014146
[17:51:09.325] iteration 18524: loss: 0.050965, loss_s1: 0.039749, loss_fp: 0.005706, loss_freq: 0.025919
[17:51:09.979] iteration 18525: loss: 0.070577, loss_s1: 0.078472, loss_fp: 0.006395, loss_freq: 0.016340
[17:51:10.616] iteration 18526: loss: 0.052124, loss_s1: 0.032737, loss_fp: 0.002019, loss_freq: 0.028370
[17:51:11.239] iteration 18527: loss: 0.088689, loss_s1: 0.082008, loss_fp: 0.001884, loss_freq: 0.032405
[17:51:11.860] iteration 18528: loss: 0.074826, loss_s1: 0.043465, loss_fp: 0.001970, loss_freq: 0.070399
[17:51:12.484] iteration 18529: loss: 0.104394, loss_s1: 0.049609, loss_fp: 0.002068, loss_freq: 0.057637
[17:51:13.104] iteration 18530: loss: 0.044730, loss_s1: 0.041512, loss_fp: 0.008233, loss_freq: 0.011494
[17:51:13.762] iteration 18531: loss: 0.092393, loss_s1: 0.036914, loss_fp: 0.003673, loss_freq: 0.103439
[17:51:14.420] iteration 18532: loss: 0.053785, loss_s1: 0.046817, loss_fp: 0.003493, loss_freq: 0.011031
[17:51:15.075] iteration 18533: loss: 0.069872, loss_s1: 0.047214, loss_fp: 0.002942, loss_freq: 0.035584
[17:51:15.726] iteration 18534: loss: 0.047607, loss_s1: 0.027110, loss_fp: 0.002133, loss_freq: 0.026213
[17:51:16.352] iteration 18535: loss: 0.052252, loss_s1: 0.052898, loss_fp: 0.006660, loss_freq: 0.014820
[17:51:16.974] iteration 18536: loss: 0.056523, loss_s1: 0.053373, loss_fp: 0.000514, loss_freq: 0.015212
[17:51:17.597] iteration 18537: loss: 0.051437, loss_s1: 0.024257, loss_fp: 0.001162, loss_freq: 0.024687
[17:51:18.227] iteration 18538: loss: 0.078271, loss_s1: 0.048007, loss_fp: 0.001142, loss_freq: 0.024649
[17:51:18.850] iteration 18539: loss: 0.093706, loss_s1: 0.036604, loss_fp: 0.005201, loss_freq: 0.111957
[17:51:19.475] iteration 18540: loss: 0.047489, loss_s1: 0.038432, loss_fp: 0.000730, loss_freq: 0.026200
[17:51:20.098] iteration 18541: loss: 0.079252, loss_s1: 0.080983, loss_fp: 0.005806, loss_freq: 0.038564
[17:51:20.724] iteration 18542: loss: 0.032068, loss_s1: 0.020451, loss_fp: 0.000690, loss_freq: 0.006170
[17:51:21.347] iteration 18543: loss: 0.096751, loss_s1: 0.051475, loss_fp: 0.016311, loss_freq: 0.082560
[17:51:21.970] iteration 18544: loss: 0.058731, loss_s1: 0.028445, loss_fp: 0.005760, loss_freq: 0.041309
[17:51:22.597] iteration 18545: loss: 0.061282, loss_s1: 0.065542, loss_fp: 0.002088, loss_freq: 0.023081
[17:51:23.222] iteration 18546: loss: 0.049936, loss_s1: 0.044844, loss_fp: 0.006135, loss_freq: 0.016556
[17:51:23.847] iteration 18547: loss: 0.043263, loss_s1: 0.029429, loss_fp: 0.002677, loss_freq: 0.016332
[17:51:24.471] iteration 18548: loss: 0.040338, loss_s1: 0.024498, loss_fp: 0.003907, loss_freq: 0.022334
[17:51:25.097] iteration 18549: loss: 0.033542, loss_s1: 0.017696, loss_fp: 0.001055, loss_freq: 0.011758
[17:51:25.728] iteration 18550: loss: 0.059566, loss_s1: 0.029071, loss_fp: 0.011350, loss_freq: 0.024780
[17:51:26.352] iteration 18551: loss: 0.065282, loss_s1: 0.058563, loss_fp: 0.012196, loss_freq: 0.029626
[17:51:26.979] iteration 18552: loss: 0.058695, loss_s1: 0.042771, loss_fp: 0.001894, loss_freq: 0.020415
[17:51:27.603] iteration 18553: loss: 0.057721, loss_s1: 0.053646, loss_fp: 0.006707, loss_freq: 0.017515
[17:51:28.226] iteration 18554: loss: 0.077121, loss_s1: 0.074365, loss_fp: 0.003962, loss_freq: 0.034483
[17:51:28.851] iteration 18555: loss: 0.066210, loss_s1: 0.064616, loss_fp: 0.001364, loss_freq: 0.035521
[17:51:29.478] iteration 18556: loss: 0.047813, loss_s1: 0.021292, loss_fp: 0.001111, loss_freq: 0.020869
[17:51:30.100] iteration 18557: loss: 0.057828, loss_s1: 0.045778, loss_fp: 0.001553, loss_freq: 0.040901
[17:51:30.721] iteration 18558: loss: 0.061281, loss_s1: 0.066624, loss_fp: 0.004396, loss_freq: 0.022678
[17:51:31.344] iteration 18559: loss: 0.049972, loss_s1: 0.026164, loss_fp: 0.001459, loss_freq: 0.040264
[17:51:31.966] iteration 18560: loss: 0.045367, loss_s1: 0.015418, loss_fp: 0.008957, loss_freq: 0.020031
[17:51:32.588] iteration 18561: loss: 0.047518, loss_s1: 0.047686, loss_fp: 0.000636, loss_freq: 0.010434
[17:51:33.211] iteration 18562: loss: 0.036984, loss_s1: 0.022166, loss_fp: 0.001538, loss_freq: 0.020123
[17:51:33.843] iteration 18563: loss: 0.052175, loss_s1: 0.037140, loss_fp: 0.002177, loss_freq: 0.027464
[17:51:34.467] iteration 18564: loss: 0.046584, loss_s1: 0.040486, loss_fp: 0.000912, loss_freq: 0.012563
[17:51:35.091] iteration 18565: loss: 0.044938, loss_s1: 0.021641, loss_fp: 0.002993, loss_freq: 0.037889
[17:51:35.717] iteration 18566: loss: 0.090556, loss_s1: 0.113829, loss_fp: 0.001301, loss_freq: 0.025407
[17:51:36.343] iteration 18567: loss: 0.049776, loss_s1: 0.024496, loss_fp: 0.004689, loss_freq: 0.016437
[17:51:36.968] iteration 18568: loss: 0.047748, loss_s1: 0.022829, loss_fp: 0.003875, loss_freq: 0.027376
[17:51:37.600] iteration 18569: loss: 0.094286, loss_s1: 0.069485, loss_fp: 0.004307, loss_freq: 0.069212
[17:51:38.223] iteration 18570: loss: 0.028113, loss_s1: 0.008971, loss_fp: 0.002610, loss_freq: 0.007867
[17:51:38.847] iteration 18571: loss: 0.072835, loss_s1: 0.081336, loss_fp: 0.002319, loss_freq: 0.018820
[17:51:39.467] iteration 18572: loss: 0.043910, loss_s1: 0.028469, loss_fp: 0.008648, loss_freq: 0.011667
[17:51:40.090] iteration 18573: loss: 0.062346, loss_s1: 0.048024, loss_fp: 0.001270, loss_freq: 0.027100
[17:51:40.717] iteration 18574: loss: 0.027081, loss_s1: 0.015045, loss_fp: 0.001110, loss_freq: 0.006214
[17:51:41.345] iteration 18575: loss: 0.056927, loss_s1: 0.044981, loss_fp: 0.003531, loss_freq: 0.028650
[17:51:42.010] iteration 18576: loss: 0.068471, loss_s1: 0.047678, loss_fp: 0.006649, loss_freq: 0.037092
[17:51:42.635] iteration 18577: loss: 0.030414, loss_s1: 0.013911, loss_fp: 0.006933, loss_freq: 0.007576
[17:51:43.270] iteration 18578: loss: 0.059435, loss_s1: 0.029595, loss_fp: 0.002226, loss_freq: 0.020713
[17:51:43.955] iteration 18579: loss: 0.058637, loss_s1: 0.047495, loss_fp: 0.006330, loss_freq: 0.021645
[17:51:44.587] iteration 18580: loss: 0.044364, loss_s1: 0.036344, loss_fp: 0.000318, loss_freq: 0.019025
[17:51:45.224] iteration 18581: loss: 0.090095, loss_s1: 0.039662, loss_fp: 0.001556, loss_freq: 0.105509
[17:51:45.849] iteration 18582: loss: 0.073120, loss_s1: 0.024482, loss_fp: 0.001992, loss_freq: 0.073676
[17:51:46.473] iteration 18583: loss: 0.058693, loss_s1: 0.039043, loss_fp: 0.004066, loss_freq: 0.040751
[17:51:47.099] iteration 18584: loss: 0.064693, loss_s1: 0.071537, loss_fp: 0.003450, loss_freq: 0.022915
[17:51:47.723] iteration 18585: loss: 0.045471, loss_s1: 0.023918, loss_fp: 0.004054, loss_freq: 0.013186
[17:51:48.347] iteration 18586: loss: 0.066084, loss_s1: 0.051100, loss_fp: 0.017149, loss_freq: 0.032039
[17:51:48.967] iteration 18587: loss: 0.034832, loss_s1: 0.023254, loss_fp: 0.001795, loss_freq: 0.008793
[17:51:49.594] iteration 18588: loss: 0.065446, loss_s1: 0.036371, loss_fp: 0.004123, loss_freq: 0.043979
[17:51:50.218] iteration 18589: loss: 0.031939, loss_s1: 0.010472, loss_fp: 0.001630, loss_freq: 0.009497
[17:51:50.843] iteration 18590: loss: 0.056628, loss_s1: 0.045162, loss_fp: 0.005103, loss_freq: 0.016933
[17:51:51.468] iteration 18591: loss: 0.069878, loss_s1: 0.071172, loss_fp: 0.000506, loss_freq: 0.020449
[17:51:52.092] iteration 18592: loss: 0.050254, loss_s1: 0.027177, loss_fp: 0.007608, loss_freq: 0.024892
[17:51:52.719] iteration 18593: loss: 0.055242, loss_s1: 0.052301, loss_fp: 0.002096, loss_freq: 0.020795
[17:51:53.339] iteration 18594: loss: 0.030914, loss_s1: 0.020427, loss_fp: 0.000648, loss_freq: 0.006156
[17:51:53.963] iteration 18595: loss: 0.047507, loss_s1: 0.019997, loss_fp: 0.004607, loss_freq: 0.026612
[17:51:54.584] iteration 18596: loss: 0.071274, loss_s1: 0.058718, loss_fp: 0.008955, loss_freq: 0.019785
[17:51:55.209] iteration 18597: loss: 0.045932, loss_s1: 0.023147, loss_fp: 0.009659, loss_freq: 0.025345
[17:51:55.832] iteration 18598: loss: 0.069500, loss_s1: 0.066806, loss_fp: 0.002767, loss_freq: 0.037554
[17:51:56.451] iteration 18599: loss: 0.064468, loss_s1: 0.032984, loss_fp: 0.004333, loss_freq: 0.046048
[17:51:57.071] iteration 18600: loss: 0.066603, loss_s1: 0.056462, loss_fp: 0.002574, loss_freq: 0.038968
[17:52:00.525] iteration 18600 : mean_dice : 0.731436
[17:52:01.179] iteration 18601: loss: 0.047626, loss_s1: 0.025177, loss_fp: 0.000495, loss_freq: 0.034179
[17:52:01.805] iteration 18602: loss: 0.085961, loss_s1: 0.047447, loss_fp: 0.001570, loss_freq: 0.033786
[17:52:02.432] iteration 18603: loss: 0.043056, loss_s1: 0.033292, loss_fp: 0.001654, loss_freq: 0.010440
[17:52:03.059] iteration 18604: loss: 0.054072, loss_s1: 0.040337, loss_fp: 0.001487, loss_freq: 0.026054
[17:52:03.682] iteration 18605: loss: 0.043327, loss_s1: 0.019155, loss_fp: 0.002452, loss_freq: 0.028320
[17:52:04.304] iteration 18606: loss: 0.057376, loss_s1: 0.041665, loss_fp: 0.001699, loss_freq: 0.015167
[17:52:04.929] iteration 18607: loss: 0.062500, loss_s1: 0.056315, loss_fp: 0.003982, loss_freq: 0.024707
[17:52:05.555] iteration 18608: loss: 0.098891, loss_s1: 0.058423, loss_fp: 0.001395, loss_freq: 0.036886
[17:52:06.182] iteration 18609: loss: 0.038543, loss_s1: 0.031953, loss_fp: 0.001220, loss_freq: 0.008336
[17:52:06.813] iteration 18610: loss: 0.047517, loss_s1: 0.036342, loss_fp: 0.004791, loss_freq: 0.019579
[17:52:07.441] iteration 18611: loss: 0.077718, loss_s1: 0.056461, loss_fp: 0.002231, loss_freq: 0.062307
[17:52:08.064] iteration 18612: loss: 0.040150, loss_s1: 0.015177, loss_fp: 0.001080, loss_freq: 0.016291
[17:52:08.688] iteration 18613: loss: 0.048865, loss_s1: 0.033193, loss_fp: 0.000905, loss_freq: 0.029019
[17:52:09.316] iteration 18614: loss: 0.055004, loss_s1: 0.053706, loss_fp: 0.004039, loss_freq: 0.020659
[17:52:09.948] iteration 18615: loss: 0.060016, loss_s1: 0.062432, loss_fp: 0.006756, loss_freq: 0.018161
[17:52:10.574] iteration 18616: loss: 0.070705, loss_s1: 0.059677, loss_fp: 0.002718, loss_freq: 0.025682
[17:52:11.195] iteration 18617: loss: 0.100515, loss_s1: 0.072538, loss_fp: 0.001749, loss_freq: 0.071565
[17:52:11.823] iteration 18618: loss: 0.081192, loss_s1: 0.081112, loss_fp: 0.002409, loss_freq: 0.036753
[17:52:12.448] iteration 18619: loss: 0.068950, loss_s1: 0.060389, loss_fp: 0.002255, loss_freq: 0.035918
[17:52:13.073] iteration 18620: loss: 0.038866, loss_s1: 0.022911, loss_fp: 0.000905, loss_freq: 0.008613
[17:52:13.702] iteration 18621: loss: 0.057253, loss_s1: 0.033946, loss_fp: 0.001605, loss_freq: 0.050075
[17:52:14.329] iteration 18622: loss: 0.035941, loss_s1: 0.017861, loss_fp: 0.002352, loss_freq: 0.013202
[17:52:14.957] iteration 18623: loss: 0.112790, loss_s1: 0.115061, loss_fp: 0.001523, loss_freq: 0.074773
[17:52:15.612] iteration 18624: loss: 0.130474, loss_s1: 0.087806, loss_fp: 0.018957, loss_freq: 0.100970
[17:52:16.270] iteration 18625: loss: 0.069211, loss_s1: 0.054691, loss_fp: 0.008804, loss_freq: 0.031761
[17:52:16.931] iteration 18626: loss: 0.050726, loss_s1: 0.031876, loss_fp: 0.002984, loss_freq: 0.026707
[17:52:17.589] iteration 18627: loss: 0.053797, loss_s1: 0.028462, loss_fp: 0.001612, loss_freq: 0.041495
[17:52:18.250] iteration 18628: loss: 0.057618, loss_s1: 0.034135, loss_fp: 0.000638, loss_freq: 0.050690
[17:52:18.911] iteration 18629: loss: 0.053801, loss_s1: 0.046831, loss_fp: 0.001598, loss_freq: 0.026588
[17:52:19.556] iteration 18630: loss: 0.040181, loss_s1: 0.022650, loss_fp: 0.000293, loss_freq: 0.011601
[17:52:20.181] iteration 18631: loss: 0.057106, loss_s1: 0.036530, loss_fp: 0.004053, loss_freq: 0.036748
[17:52:20.810] iteration 18632: loss: 0.066993, loss_s1: 0.029941, loss_fp: 0.001287, loss_freq: 0.025957
[17:52:21.437] iteration 18633: loss: 0.033836, loss_s1: 0.028452, loss_fp: 0.000595, loss_freq: 0.006393
[17:52:22.060] iteration 18634: loss: 0.042196, loss_s1: 0.019095, loss_fp: 0.003662, loss_freq: 0.023399
[17:52:22.681] iteration 18635: loss: 0.080841, loss_s1: 0.050321, loss_fp: 0.010560, loss_freq: 0.070348
[17:52:23.306] iteration 18636: loss: 0.067281, loss_s1: 0.041501, loss_fp: 0.004456, loss_freq: 0.040204
[17:52:23.931] iteration 18637: loss: 0.090464, loss_s1: 0.083925, loss_fp: 0.005071, loss_freq: 0.047241
[17:52:24.555] iteration 18638: loss: 0.062903, loss_s1: 0.066135, loss_fp: 0.000556, loss_freq: 0.005574
[17:52:25.182] iteration 18639: loss: 0.040282, loss_s1: 0.032014, loss_fp: 0.002136, loss_freq: 0.014140
[17:52:25.801] iteration 18640: loss: 0.041175, loss_s1: 0.016091, loss_fp: 0.002630, loss_freq: 0.020964
[17:52:26.426] iteration 18641: loss: 0.060517, loss_s1: 0.024077, loss_fp: 0.002513, loss_freq: 0.021016
[17:52:27.052] iteration 18642: loss: 0.055775, loss_s1: 0.051712, loss_fp: 0.002544, loss_freq: 0.018672
[17:52:27.677] iteration 18643: loss: 0.109925, loss_s1: 0.113511, loss_fp: 0.000573, loss_freq: 0.028529
[17:52:28.326] iteration 18644: loss: 0.072263, loss_s1: 0.033154, loss_fp: 0.014337, loss_freq: 0.044725
[17:52:28.948] iteration 18645: loss: 0.047411, loss_s1: 0.038371, loss_fp: 0.003948, loss_freq: 0.020971
[17:52:29.570] iteration 18646: loss: 0.072690, loss_s1: 0.018664, loss_fp: 0.000732, loss_freq: 0.071999
[17:52:30.192] iteration 18647: loss: 0.063047, loss_s1: 0.078266, loss_fp: 0.002027, loss_freq: 0.010758
[17:52:30.813] iteration 18648: loss: 0.091117, loss_s1: 0.068191, loss_fp: 0.009925, loss_freq: 0.044321
[17:52:31.441] iteration 18649: loss: 0.061420, loss_s1: 0.050769, loss_fp: 0.002631, loss_freq: 0.036129
[17:52:32.062] iteration 18650: loss: 0.071968, loss_s1: 0.036320, loss_fp: 0.002033, loss_freq: 0.066028
[17:52:32.685] iteration 18651: loss: 0.053046, loss_s1: 0.048731, loss_fp: 0.006912, loss_freq: 0.019215
[17:52:33.312] iteration 18652: loss: 0.048521, loss_s1: 0.034600, loss_fp: 0.001983, loss_freq: 0.014260
[17:52:33.937] iteration 18653: loss: 0.057121, loss_s1: 0.043944, loss_fp: 0.002364, loss_freq: 0.036143
[17:52:34.558] iteration 18654: loss: 0.039972, loss_s1: 0.026609, loss_fp: 0.000465, loss_freq: 0.013821
[17:52:35.183] iteration 18655: loss: 0.055347, loss_s1: 0.034401, loss_fp: 0.002792, loss_freq: 0.024098
[17:52:35.801] iteration 18656: loss: 0.050351, loss_s1: 0.028294, loss_fp: 0.002307, loss_freq: 0.030753
[17:52:36.431] iteration 18657: loss: 0.053603, loss_s1: 0.055051, loss_fp: 0.005038, loss_freq: 0.011345
[17:52:37.054] iteration 18658: loss: 0.069729, loss_s1: 0.052395, loss_fp: 0.007189, loss_freq: 0.036038
[17:52:37.678] iteration 18659: loss: 0.047658, loss_s1: 0.021303, loss_fp: 0.006731, loss_freq: 0.019251
[17:52:38.304] iteration 18660: loss: 0.053422, loss_s1: 0.013259, loss_fp: 0.006386, loss_freq: 0.034374
[17:52:38.934] iteration 18661: loss: 0.068082, loss_s1: 0.056212, loss_fp: 0.008801, loss_freq: 0.025912
[17:52:39.557] iteration 18662: loss: 0.075480, loss_s1: 0.045349, loss_fp: 0.003603, loss_freq: 0.070507
[17:52:40.182] iteration 18663: loss: 0.036006, loss_s1: 0.032506, loss_fp: 0.001482, loss_freq: 0.006933
[17:52:40.809] iteration 18664: loss: 0.056693, loss_s1: 0.053709, loss_fp: 0.002821, loss_freq: 0.017579
[17:52:41.435] iteration 18665: loss: 0.113250, loss_s1: 0.082681, loss_fp: 0.002700, loss_freq: 0.089737
[17:52:42.060] iteration 18666: loss: 0.065875, loss_s1: 0.035520, loss_fp: 0.003536, loss_freq: 0.028549
[17:52:42.682] iteration 18667: loss: 0.075818, loss_s1: 0.085681, loss_fp: 0.000786, loss_freq: 0.033056
[17:52:43.307] iteration 18668: loss: 0.049627, loss_s1: 0.030988, loss_fp: 0.002969, loss_freq: 0.018378
[17:52:43.933] iteration 18669: loss: 0.072498, loss_s1: 0.039281, loss_fp: 0.002244, loss_freq: 0.023940
[17:52:44.560] iteration 18670: loss: 0.022715, loss_s1: 0.006842, loss_fp: 0.001668, loss_freq: 0.005433
[17:52:45.187] iteration 18671: loss: 0.055028, loss_s1: 0.041876, loss_fp: 0.003040, loss_freq: 0.020015
[17:52:45.815] iteration 18672: loss: 0.046448, loss_s1: 0.021860, loss_fp: 0.001441, loss_freq: 0.025775
[17:52:46.432] iteration 18673: loss: 0.075036, loss_s1: 0.045584, loss_fp: 0.002465, loss_freq: 0.045560
[17:52:47.058] iteration 18674: loss: 0.065994, loss_s1: 0.075333, loss_fp: 0.004998, loss_freq: 0.020513
[17:52:47.685] iteration 18675: loss: 0.050258, loss_s1: 0.019259, loss_fp: 0.005619, loss_freq: 0.024413
[17:52:48.307] iteration 18676: loss: 0.058486, loss_s1: 0.046541, loss_fp: 0.003948, loss_freq: 0.026188
[17:52:49.275] iteration 18677: loss: 0.046016, loss_s1: 0.029280, loss_fp: 0.006260, loss_freq: 0.022394
[17:52:49.990] iteration 18678: loss: 0.059334, loss_s1: 0.050300, loss_fp: 0.001815, loss_freq: 0.027126
[17:52:50.650] iteration 18679: loss: 0.058089, loss_s1: 0.056428, loss_fp: 0.000489, loss_freq: 0.014646
[17:52:51.308] iteration 18680: loss: 0.053465, loss_s1: 0.046782, loss_fp: 0.001702, loss_freq: 0.013774
[17:52:51.963] iteration 18681: loss: 0.046553, loss_s1: 0.043387, loss_fp: 0.006221, loss_freq: 0.010460
[17:52:52.623] iteration 18682: loss: 0.094560, loss_s1: 0.085559, loss_fp: 0.006984, loss_freq: 0.036938
[17:52:53.281] iteration 18683: loss: 0.070209, loss_s1: 0.074385, loss_fp: 0.001919, loss_freq: 0.006862
[17:52:53.940] iteration 18684: loss: 0.036341, loss_s1: 0.023417, loss_fp: 0.002882, loss_freq: 0.012023
[17:52:54.602] iteration 18685: loss: 0.072802, loss_s1: 0.072241, loss_fp: 0.009433, loss_freq: 0.033144
[17:52:55.222] iteration 18686: loss: 0.058490, loss_s1: 0.063620, loss_fp: 0.001889, loss_freq: 0.014657
[17:52:55.843] iteration 18687: loss: 0.050991, loss_s1: 0.031316, loss_fp: 0.002275, loss_freq: 0.005885
[17:52:56.467] iteration 18688: loss: 0.064921, loss_s1: 0.075028, loss_fp: 0.001741, loss_freq: 0.021589
[17:52:57.093] iteration 18689: loss: 0.080337, loss_s1: 0.052110, loss_fp: 0.006174, loss_freq: 0.064679
[17:52:57.716] iteration 18690: loss: 0.065802, loss_s1: 0.029601, loss_fp: 0.005447, loss_freq: 0.014623
[17:52:58.339] iteration 18691: loss: 0.044989, loss_s1: 0.029668, loss_fp: 0.001755, loss_freq: 0.019405
[17:52:58.967] iteration 18692: loss: 0.059178, loss_s1: 0.047760, loss_fp: 0.002546, loss_freq: 0.027930
[17:52:59.595] iteration 18693: loss: 0.034417, loss_s1: 0.014408, loss_fp: 0.001510, loss_freq: 0.008561
[17:53:00.214] iteration 18694: loss: 0.062115, loss_s1: 0.030711, loss_fp: 0.009235, loss_freq: 0.025316
[17:53:00.836] iteration 18695: loss: 0.043424, loss_s1: 0.016297, loss_fp: 0.001340, loss_freq: 0.018596
[17:53:01.461] iteration 18696: loss: 0.063163, loss_s1: 0.027362, loss_fp: 0.002028, loss_freq: 0.045654
[17:53:02.088] iteration 18697: loss: 0.045791, loss_s1: 0.022505, loss_fp: 0.004345, loss_freq: 0.010731
[17:53:02.712] iteration 18698: loss: 0.047282, loss_s1: 0.040499, loss_fp: 0.002905, loss_freq: 0.013257
[17:53:03.345] iteration 18699: loss: 0.062853, loss_s1: 0.032140, loss_fp: 0.005041, loss_freq: 0.024860
[17:53:03.971] iteration 18700: loss: 0.066521, loss_s1: 0.029751, loss_fp: 0.001697, loss_freq: 0.069979
[17:53:04.601] iteration 18701: loss: 0.049646, loss_s1: 0.036334, loss_fp: 0.003718, loss_freq: 0.027439
[17:53:05.284] iteration 18702: loss: 0.044009, loss_s1: 0.032922, loss_fp: 0.001544, loss_freq: 0.021923
[17:53:05.947] iteration 18703: loss: 0.029551, loss_s1: 0.016963, loss_fp: 0.000727, loss_freq: 0.008035
[17:53:06.614] iteration 18704: loss: 0.095370, loss_s1: 0.081279, loss_fp: 0.002018, loss_freq: 0.050937
[17:53:07.251] iteration 18705: loss: 0.065920, loss_s1: 0.037506, loss_fp: 0.009829, loss_freq: 0.040056
[17:53:07.875] iteration 18706: loss: 0.049545, loss_s1: 0.047164, loss_fp: 0.002673, loss_freq: 0.009845
[17:53:08.498] iteration 18707: loss: 0.043996, loss_s1: 0.023982, loss_fp: 0.007713, loss_freq: 0.027331
[17:53:09.129] iteration 18708: loss: 0.081001, loss_s1: 0.056044, loss_fp: 0.005476, loss_freq: 0.030998
[17:53:09.760] iteration 18709: loss: 0.052496, loss_s1: 0.051936, loss_fp: 0.000591, loss_freq: 0.015067
[17:53:10.389] iteration 18710: loss: 0.038956, loss_s1: 0.027312, loss_fp: 0.003551, loss_freq: 0.014008
[17:53:11.012] iteration 18711: loss: 0.066902, loss_s1: 0.034795, loss_fp: 0.008707, loss_freq: 0.037860
[17:53:11.642] iteration 18712: loss: 0.079585, loss_s1: 0.080177, loss_fp: 0.010587, loss_freq: 0.039444
[17:53:12.268] iteration 18713: loss: 0.096867, loss_s1: 0.108094, loss_fp: 0.003068, loss_freq: 0.038533
[17:53:12.902] iteration 18714: loss: 0.069483, loss_s1: 0.042145, loss_fp: 0.011469, loss_freq: 0.051039
[17:53:13.537] iteration 18715: loss: 0.063471, loss_s1: 0.022204, loss_fp: 0.001003, loss_freq: 0.060023
[17:53:14.165] iteration 18716: loss: 0.070563, loss_s1: 0.079996, loss_fp: 0.001836, loss_freq: 0.028951
[17:53:14.791] iteration 18717: loss: 0.047233, loss_s1: 0.038075, loss_fp: 0.004208, loss_freq: 0.007944
[17:53:15.418] iteration 18718: loss: 0.061357, loss_s1: 0.060411, loss_fp: 0.008506, loss_freq: 0.024477
[17:53:16.052] iteration 18719: loss: 0.083283, loss_s1: 0.058018, loss_fp: 0.033403, loss_freq: 0.043540
[17:53:16.678] iteration 18720: loss: 0.069862, loss_s1: 0.077053, loss_fp: 0.007380, loss_freq: 0.029873
[17:53:17.307] iteration 18721: loss: 0.072441, loss_s1: 0.054412, loss_fp: 0.002936, loss_freq: 0.042886
[17:53:17.932] iteration 18722: loss: 0.038449, loss_s1: 0.033397, loss_fp: 0.001823, loss_freq: 0.007706
[17:53:18.554] iteration 18723: loss: 0.045079, loss_s1: 0.037624, loss_fp: 0.000368, loss_freq: 0.026063
[17:53:19.179] iteration 18724: loss: 0.051067, loss_s1: 0.039130, loss_fp: 0.008307, loss_freq: 0.018406
[17:53:19.801] iteration 18725: loss: 0.057343, loss_s1: 0.053518, loss_fp: 0.003394, loss_freq: 0.016904
[17:53:20.425] iteration 18726: loss: 0.090180, loss_s1: 0.056146, loss_fp: 0.002595, loss_freq: 0.091111
[17:53:21.050] iteration 18727: loss: 0.047638, loss_s1: 0.033473, loss_fp: 0.004209, loss_freq: 0.020913
[17:53:21.677] iteration 18728: loss: 0.059917, loss_s1: 0.044922, loss_fp: 0.006697, loss_freq: 0.025615
[17:53:22.303] iteration 18729: loss: 0.050359, loss_s1: 0.021877, loss_fp: 0.002483, loss_freq: 0.041814
[17:53:22.923] iteration 18730: loss: 0.060169, loss_s1: 0.040764, loss_fp: 0.002938, loss_freq: 0.042899
[17:53:23.549] iteration 18731: loss: 0.050874, loss_s1: 0.028996, loss_fp: 0.006679, loss_freq: 0.025480
[17:53:24.184] iteration 18732: loss: 0.052710, loss_s1: 0.035469, loss_fp: 0.004039, loss_freq: 0.025005
[17:53:24.809] iteration 18733: loss: 0.033563, loss_s1: 0.015093, loss_fp: 0.001218, loss_freq: 0.009838
[17:53:25.440] iteration 18734: loss: 0.094904, loss_s1: 0.034600, loss_fp: 0.001786, loss_freq: 0.085257
[17:53:26.063] iteration 18735: loss: 0.046405, loss_s1: 0.041835, loss_fp: 0.001087, loss_freq: 0.005822
[17:53:26.688] iteration 18736: loss: 0.047935, loss_s1: 0.023438, loss_fp: 0.017389, loss_freq: 0.020163
[17:53:27.312] iteration 18737: loss: 0.087154, loss_s1: 0.052199, loss_fp: 0.002536, loss_freq: 0.054021
[17:53:27.936] iteration 18738: loss: 0.033661, loss_s1: 0.019265, loss_fp: 0.002322, loss_freq: 0.010229
[17:53:28.561] iteration 18739: loss: 0.049041, loss_s1: 0.029800, loss_fp: 0.001311, loss_freq: 0.029186
[17:53:29.180] iteration 18740: loss: 0.056536, loss_s1: 0.018004, loss_fp: 0.004205, loss_freq: 0.040961
[17:53:29.842] iteration 18741: loss: 0.068842, loss_s1: 0.080085, loss_fp: 0.004010, loss_freq: 0.022785
[17:53:30.497] iteration 18742: loss: 0.061793, loss_s1: 0.022920, loss_fp: 0.004254, loss_freq: 0.070339
[17:53:31.155] iteration 18743: loss: 0.046351, loss_s1: 0.027811, loss_fp: 0.001808, loss_freq: 0.022286
[17:53:31.800] iteration 18744: loss: 0.067456, loss_s1: 0.076591, loss_fp: 0.003966, loss_freq: 0.024709
[17:53:32.424] iteration 18745: loss: 0.047172, loss_s1: 0.026861, loss_fp: 0.004329, loss_freq: 0.021628
[17:53:33.048] iteration 18746: loss: 0.071368, loss_s1: 0.067363, loss_fp: 0.003384, loss_freq: 0.025846
[17:53:33.673] iteration 18747: loss: 0.057887, loss_s1: 0.045634, loss_fp: 0.007758, loss_freq: 0.032683
[17:53:34.306] iteration 18748: loss: 0.068901, loss_s1: 0.071959, loss_fp: 0.000557, loss_freq: 0.031160
[17:53:34.932] iteration 18749: loss: 0.065728, loss_s1: 0.066567, loss_fp: 0.000753, loss_freq: 0.027983
[17:53:35.561] iteration 18750: loss: 0.051943, loss_s1: 0.020957, loss_fp: 0.001238, loss_freq: 0.017637
[17:53:36.182] iteration 18751: loss: 0.072703, loss_s1: 0.082653, loss_fp: 0.005915, loss_freq: 0.017608
[17:53:36.808] iteration 18752: loss: 0.074684, loss_s1: 0.084813, loss_fp: 0.000605, loss_freq: 0.019220
[17:53:37.424] iteration 18753: loss: 0.039264, loss_s1: 0.022650, loss_fp: 0.003931, loss_freq: 0.023268
[17:53:38.050] iteration 18754: loss: 0.039329, loss_s1: 0.015567, loss_fp: 0.005477, loss_freq: 0.014279
[17:53:38.674] iteration 18755: loss: 0.035428, loss_s1: 0.024309, loss_fp: 0.000689, loss_freq: 0.007964
[17:53:39.297] iteration 18756: loss: 0.064486, loss_s1: 0.037481, loss_fp: 0.003428, loss_freq: 0.050341
[17:53:39.921] iteration 18757: loss: 0.069523, loss_s1: 0.047231, loss_fp: 0.001796, loss_freq: 0.048132
[17:53:40.550] iteration 18758: loss: 0.062192, loss_s1: 0.068161, loss_fp: 0.007898, loss_freq: 0.020036
[17:53:41.175] iteration 18759: loss: 0.092849, loss_s1: 0.086796, loss_fp: 0.022478, loss_freq: 0.036759
[17:53:41.799] iteration 18760: loss: 0.064613, loss_s1: 0.053211, loss_fp: 0.007235, loss_freq: 0.025213
[17:53:42.422] iteration 18761: loss: 0.090179, loss_s1: 0.116892, loss_fp: 0.004360, loss_freq: 0.029666
[17:53:43.041] iteration 18762: loss: 0.030250, loss_s1: 0.013949, loss_fp: 0.000664, loss_freq: 0.006928
[17:53:43.667] iteration 18763: loss: 0.041289, loss_s1: 0.023956, loss_fp: 0.001300, loss_freq: 0.008943
[17:53:44.295] iteration 18764: loss: 0.052633, loss_s1: 0.056727, loss_fp: 0.002076, loss_freq: 0.013490
[17:53:44.923] iteration 18765: loss: 0.065188, loss_s1: 0.039970, loss_fp: 0.014592, loss_freq: 0.027199
[17:53:45.546] iteration 18766: loss: 0.082977, loss_s1: 0.063034, loss_fp: 0.002772, loss_freq: 0.020747
[17:53:46.168] iteration 18767: loss: 0.041680, loss_s1: 0.022081, loss_fp: 0.005037, loss_freq: 0.018793
[17:53:46.789] iteration 18768: loss: 0.071566, loss_s1: 0.091336, loss_fp: 0.003048, loss_freq: 0.009487
[17:53:47.429] iteration 18769: loss: 0.068944, loss_s1: 0.040496, loss_fp: 0.001057, loss_freq: 0.041519
[17:53:48.050] iteration 18770: loss: 0.037024, loss_s1: 0.027893, loss_fp: 0.003731, loss_freq: 0.015481
[17:53:48.682] iteration 18771: loss: 0.042070, loss_s1: 0.041348, loss_fp: 0.000367, loss_freq: 0.014145
[17:53:49.405] iteration 18772: loss: 0.055198, loss_s1: 0.060419, loss_fp: 0.001483, loss_freq: 0.014481
[17:53:50.040] iteration 18773: loss: 0.043890, loss_s1: 0.030016, loss_fp: 0.003232, loss_freq: 0.019043
[17:53:50.685] iteration 18774: loss: 0.061353, loss_s1: 0.034310, loss_fp: 0.002670, loss_freq: 0.036106
[17:53:51.311] iteration 18775: loss: 0.053186, loss_s1: 0.027659, loss_fp: 0.002678, loss_freq: 0.021610
[17:53:51.936] iteration 18776: loss: 0.072089, loss_s1: 0.069519, loss_fp: 0.001870, loss_freq: 0.020125
[17:53:52.567] iteration 18777: loss: 0.047947, loss_s1: 0.039178, loss_fp: 0.001494, loss_freq: 0.029431
[17:53:53.198] iteration 18778: loss: 0.070764, loss_s1: 0.029231, loss_fp: 0.010558, loss_freq: 0.054308
[17:53:53.825] iteration 18779: loss: 0.092583, loss_s1: 0.067529, loss_fp: 0.001629, loss_freq: 0.055470
[17:53:54.457] iteration 18780: loss: 0.065643, loss_s1: 0.064528, loss_fp: 0.002691, loss_freq: 0.021158
[17:53:55.082] iteration 18781: loss: 0.035768, loss_s1: 0.013706, loss_fp: 0.001272, loss_freq: 0.011813
[17:53:55.708] iteration 18782: loss: 0.030412, loss_s1: 0.018498, loss_fp: 0.001791, loss_freq: 0.009121
[17:53:56.335] iteration 18783: loss: 0.055937, loss_s1: 0.019130, loss_fp: 0.001000, loss_freq: 0.013186
[17:53:56.959] iteration 18784: loss: 0.092450, loss_s1: 0.093306, loss_fp: 0.004737, loss_freq: 0.043262
[17:53:57.583] iteration 18785: loss: 0.126718, loss_s1: 0.083177, loss_fp: 0.007789, loss_freq: 0.115777
[17:53:58.212] iteration 18786: loss: 0.074423, loss_s1: 0.065850, loss_fp: 0.003944, loss_freq: 0.022285
[17:53:58.836] iteration 18787: loss: 0.045281, loss_s1: 0.023879, loss_fp: 0.001586, loss_freq: 0.020334
[17:53:59.461] iteration 18788: loss: 0.063757, loss_s1: 0.068498, loss_fp: 0.001904, loss_freq: 0.021333
[17:54:00.085] iteration 18789: loss: 0.075285, loss_s1: 0.093103, loss_fp: 0.002474, loss_freq: 0.023743
[17:54:00.711] iteration 18790: loss: 0.059574, loss_s1: 0.057623, loss_fp: 0.000862, loss_freq: 0.033269
[17:54:01.337] iteration 18791: loss: 0.042210, loss_s1: 0.027071, loss_fp: 0.001983, loss_freq: 0.008337
[17:54:01.965] iteration 18792: loss: 0.053498, loss_s1: 0.050835, loss_fp: 0.000779, loss_freq: 0.014586
[17:54:02.591] iteration 18793: loss: 0.040498, loss_s1: 0.034271, loss_fp: 0.002966, loss_freq: 0.016447
[17:54:03.219] iteration 18794: loss: 0.047413, loss_s1: 0.047586, loss_fp: 0.000505, loss_freq: 0.015891
[17:54:03.886] iteration 18795: loss: 0.063391, loss_s1: 0.041851, loss_fp: 0.004382, loss_freq: 0.027256
[17:54:04.549] iteration 18796: loss: 0.062742, loss_s1: 0.036770, loss_fp: 0.004085, loss_freq: 0.045945
[17:54:05.210] iteration 18797: loss: 0.047990, loss_s1: 0.037890, loss_fp: 0.001243, loss_freq: 0.014769
[17:54:05.875] iteration 18798: loss: 0.055449, loss_s1: 0.045551, loss_fp: 0.016228, loss_freq: 0.009477
[17:54:06.546] iteration 18799: loss: 0.051432, loss_s1: 0.044142, loss_fp: 0.009137, loss_freq: 0.007203
[17:54:07.210] iteration 18800: loss: 0.032765, loss_s1: 0.016695, loss_fp: 0.000809, loss_freq: 0.008184
[17:54:10.409] iteration 18800 : mean_dice : 0.706313
[17:54:11.052] iteration 18801: loss: 0.056742, loss_s1: 0.028256, loss_fp: 0.002143, loss_freq: 0.028504
[17:54:11.673] iteration 18802: loss: 0.063745, loss_s1: 0.049590, loss_fp: 0.006127, loss_freq: 0.017414
[17:54:12.302] iteration 18803: loss: 0.046172, loss_s1: 0.034590, loss_fp: 0.005037, loss_freq: 0.017032
[17:54:12.928] iteration 18804: loss: 0.166767, loss_s1: 0.072932, loss_fp: 0.004773, loss_freq: 0.193887
[17:54:13.555] iteration 18805: loss: 0.075611, loss_s1: 0.056585, loss_fp: 0.017394, loss_freq: 0.018297
[17:54:14.186] iteration 18806: loss: 0.079555, loss_s1: 0.104113, loss_fp: 0.001815, loss_freq: 0.006951
[17:54:14.841] iteration 18807: loss: 0.073720, loss_s1: 0.059996, loss_fp: 0.002734, loss_freq: 0.058279
[17:54:15.494] iteration 18808: loss: 0.080589, loss_s1: 0.086530, loss_fp: 0.001094, loss_freq: 0.016359
[17:54:16.121] iteration 18809: loss: 0.062175, loss_s1: 0.054642, loss_fp: 0.007066, loss_freq: 0.014283
[17:54:16.747] iteration 18810: loss: 0.087984, loss_s1: 0.078821, loss_fp: 0.004358, loss_freq: 0.007994
[17:54:17.377] iteration 18811: loss: 0.061854, loss_s1: 0.032378, loss_fp: 0.003552, loss_freq: 0.046202
[17:54:17.999] iteration 18812: loss: 0.048288, loss_s1: 0.037954, loss_fp: 0.002490, loss_freq: 0.020800
[17:54:18.624] iteration 18813: loss: 0.048258, loss_s1: 0.022153, loss_fp: 0.002057, loss_freq: 0.034820
[17:54:19.257] iteration 18814: loss: 0.051504, loss_s1: 0.036346, loss_fp: 0.013331, loss_freq: 0.019159
[17:54:19.887] iteration 18815: loss: 0.035222, loss_s1: 0.021209, loss_fp: 0.001268, loss_freq: 0.013210
[17:54:20.519] iteration 18816: loss: 0.070199, loss_s1: 0.057385, loss_fp: 0.004212, loss_freq: 0.036434
[17:54:21.147] iteration 18817: loss: 0.051291, loss_s1: 0.044061, loss_fp: 0.004958, loss_freq: 0.021194
[17:54:21.774] iteration 18818: loss: 0.072810, loss_s1: 0.048804, loss_fp: 0.009898, loss_freq: 0.053244
[17:54:22.399] iteration 18819: loss: 0.079960, loss_s1: 0.047050, loss_fp: 0.003190, loss_freq: 0.036608
[17:54:23.095] iteration 18820: loss: 0.076719, loss_s1: 0.069702, loss_fp: 0.003889, loss_freq: 0.029429
[17:54:23.771] iteration 18821: loss: 0.044484, loss_s1: 0.029523, loss_fp: 0.005776, loss_freq: 0.012680
[17:54:24.434] iteration 18822: loss: 0.060221, loss_s1: 0.027781, loss_fp: 0.006597, loss_freq: 0.034493
[17:54:25.098] iteration 18823: loss: 0.091207, loss_s1: 0.064118, loss_fp: 0.022965, loss_freq: 0.068115
[17:54:25.748] iteration 18824: loss: 0.032456, loss_s1: 0.023366, loss_fp: 0.002508, loss_freq: 0.007301
[17:54:26.379] iteration 18825: loss: 0.040976, loss_s1: 0.020398, loss_fp: 0.005691, loss_freq: 0.020265
[17:54:27.013] iteration 18826: loss: 0.154882, loss_s1: 0.147686, loss_fp: 0.010367, loss_freq: 0.054907
[17:54:27.642] iteration 18827: loss: 0.074855, loss_s1: 0.070744, loss_fp: 0.004179, loss_freq: 0.037415
[17:54:28.273] iteration 18828: loss: 0.112883, loss_s1: 0.119274, loss_fp: 0.003390, loss_freq: 0.073600
[17:54:28.898] iteration 18829: loss: 0.041977, loss_s1: 0.024400, loss_fp: 0.005177, loss_freq: 0.021385
[17:54:29.523] iteration 18830: loss: 0.062372, loss_s1: 0.057940, loss_fp: 0.003524, loss_freq: 0.027570
[17:54:30.148] iteration 18831: loss: 0.034958, loss_s1: 0.026175, loss_fp: 0.000912, loss_freq: 0.011797
[17:54:30.771] iteration 18832: loss: 0.061561, loss_s1: 0.056434, loss_fp: 0.000338, loss_freq: 0.021968
[17:54:31.394] iteration 18833: loss: 0.066665, loss_s1: 0.020354, loss_fp: 0.001521, loss_freq: 0.010519
[17:54:32.020] iteration 18834: loss: 0.052675, loss_s1: 0.026371, loss_fp: 0.003913, loss_freq: 0.029840
[17:54:32.649] iteration 18835: loss: 0.078894, loss_s1: 0.057562, loss_fp: 0.015078, loss_freq: 0.038684
[17:54:33.273] iteration 18836: loss: 0.061705, loss_s1: 0.015207, loss_fp: 0.001142, loss_freq: 0.019441
[17:54:33.895] iteration 18837: loss: 0.073131, loss_s1: 0.053151, loss_fp: 0.004782, loss_freq: 0.045135
[17:54:34.894] iteration 18838: loss: 0.039506, loss_s1: 0.027474, loss_fp: 0.001840, loss_freq: 0.011859
[17:54:35.549] iteration 18839: loss: 0.071734, loss_s1: 0.065120, loss_fp: 0.003753, loss_freq: 0.030989
[17:54:36.199] iteration 18840: loss: 0.034668, loss_s1: 0.010442, loss_fp: 0.003070, loss_freq: 0.008849
[17:54:36.819] iteration 18841: loss: 0.046024, loss_s1: 0.037990, loss_fp: 0.000710, loss_freq: 0.012808
[17:54:37.450] iteration 18842: loss: 0.055031, loss_s1: 0.054206, loss_fp: 0.001109, loss_freq: 0.016904
[17:54:38.076] iteration 18843: loss: 0.103488, loss_s1: 0.103814, loss_fp: 0.008553, loss_freq: 0.039765
[17:54:38.711] iteration 18844: loss: 0.061329, loss_s1: 0.069999, loss_fp: 0.001169, loss_freq: 0.011232
[17:54:39.336] iteration 18845: loss: 0.038530, loss_s1: 0.029681, loss_fp: 0.000612, loss_freq: 0.014066
[17:54:39.957] iteration 18846: loss: 0.064909, loss_s1: 0.048573, loss_fp: 0.000848, loss_freq: 0.040543
[17:54:40.583] iteration 18847: loss: 0.049625, loss_s1: 0.026950, loss_fp: 0.010333, loss_freq: 0.017363
[17:54:41.211] iteration 18848: loss: 0.042308, loss_s1: 0.026100, loss_fp: 0.000943, loss_freq: 0.005439
[17:54:41.845] iteration 18849: loss: 0.074409, loss_s1: 0.088578, loss_fp: 0.008511, loss_freq: 0.014505
[17:54:42.473] iteration 18850: loss: 0.097049, loss_s1: 0.049053, loss_fp: 0.009036, loss_freq: 0.107613
[17:54:43.102] iteration 18851: loss: 0.051143, loss_s1: 0.018156, loss_fp: 0.005381, loss_freq: 0.017119
[17:54:43.771] iteration 18852: loss: 0.040311, loss_s1: 0.033375, loss_fp: 0.005078, loss_freq: 0.007385
[17:54:44.399] iteration 18853: loss: 0.103066, loss_s1: 0.074407, loss_fp: 0.005309, loss_freq: 0.088359
[17:54:45.025] iteration 18854: loss: 0.049827, loss_s1: 0.037660, loss_fp: 0.001452, loss_freq: 0.015192
[17:54:45.688] iteration 18855: loss: 0.041424, loss_s1: 0.032205, loss_fp: 0.002000, loss_freq: 0.015222
[17:54:46.314] iteration 18856: loss: 0.044376, loss_s1: 0.027410, loss_fp: 0.000873, loss_freq: 0.018774
[17:54:46.939] iteration 18857: loss: 0.062376, loss_s1: 0.023830, loss_fp: 0.001314, loss_freq: 0.030047
[17:54:47.563] iteration 18858: loss: 0.057367, loss_s1: 0.064667, loss_fp: 0.000606, loss_freq: 0.008280
[17:54:48.190] iteration 18859: loss: 0.043675, loss_s1: 0.025907, loss_fp: 0.000702, loss_freq: 0.010149
[17:54:48.814] iteration 18860: loss: 0.039869, loss_s1: 0.013885, loss_fp: 0.002276, loss_freq: 0.017347
[17:54:49.441] iteration 18861: loss: 0.051478, loss_s1: 0.023329, loss_fp: 0.000487, loss_freq: 0.043620
[17:54:50.068] iteration 18862: loss: 0.042480, loss_s1: 0.032824, loss_fp: 0.002986, loss_freq: 0.019294
[17:54:50.691] iteration 18863: loss: 0.034422, loss_s1: 0.022500, loss_fp: 0.002098, loss_freq: 0.013631
[17:54:51.318] iteration 18864: loss: 0.036328, loss_s1: 0.023883, loss_fp: 0.000186, loss_freq: 0.008151
[17:54:51.944] iteration 18865: loss: 0.094302, loss_s1: 0.101336, loss_fp: 0.004717, loss_freq: 0.044659
[17:54:52.569] iteration 18866: loss: 0.052423, loss_s1: 0.029424, loss_fp: 0.007762, loss_freq: 0.023697
[17:54:53.196] iteration 18867: loss: 0.042566, loss_s1: 0.033155, loss_fp: 0.007353, loss_freq: 0.010511
[17:54:53.819] iteration 18868: loss: 0.037791, loss_s1: 0.026651, loss_fp: 0.003863, loss_freq: 0.010590
[17:54:54.444] iteration 18869: loss: 0.049239, loss_s1: 0.008405, loss_fp: 0.007255, loss_freq: 0.023277
[17:54:55.067] iteration 18870: loss: 0.059091, loss_s1: 0.034247, loss_fp: 0.002340, loss_freq: 0.035057
[17:54:55.690] iteration 18871: loss: 0.041425, loss_s1: 0.030262, loss_fp: 0.002746, loss_freq: 0.014021
[17:54:56.319] iteration 18872: loss: 0.065763, loss_s1: 0.033189, loss_fp: 0.007561, loss_freq: 0.033995
[17:54:56.941] iteration 18873: loss: 0.056128, loss_s1: 0.046954, loss_fp: 0.005575, loss_freq: 0.022873
[17:54:57.567] iteration 18874: loss: 0.098915, loss_s1: 0.099353, loss_fp: 0.009436, loss_freq: 0.034690
[17:54:58.197] iteration 18875: loss: 0.077755, loss_s1: 0.088362, loss_fp: 0.000869, loss_freq: 0.015970
[17:54:58.827] iteration 18876: loss: 0.064942, loss_s1: 0.065274, loss_fp: 0.003792, loss_freq: 0.017562
[17:54:59.449] iteration 18877: loss: 0.046447, loss_s1: 0.030635, loss_fp: 0.003791, loss_freq: 0.021890
[17:55:00.078] iteration 18878: loss: 0.037922, loss_s1: 0.020511, loss_fp: 0.004675, loss_freq: 0.012309
[17:55:00.705] iteration 18879: loss: 0.113609, loss_s1: 0.099371, loss_fp: 0.009718, loss_freq: 0.088257
[17:55:01.330] iteration 18880: loss: 0.072221, loss_s1: 0.031301, loss_fp: 0.002613, loss_freq: 0.074015
[17:55:01.960] iteration 18881: loss: 0.040344, loss_s1: 0.014018, loss_fp: 0.004474, loss_freq: 0.033354
[17:55:02.586] iteration 18882: loss: 0.049606, loss_s1: 0.043523, loss_fp: 0.002687, loss_freq: 0.013046
[17:55:03.213] iteration 18883: loss: 0.042121, loss_s1: 0.038385, loss_fp: 0.001452, loss_freq: 0.008298
[17:55:03.840] iteration 18884: loss: 0.048086, loss_s1: 0.023965, loss_fp: 0.001781, loss_freq: 0.005893
[17:55:04.465] iteration 18885: loss: 0.068397, loss_s1: 0.060632, loss_fp: 0.012791, loss_freq: 0.021782
[17:55:05.090] iteration 18886: loss: 0.046472, loss_s1: 0.038089, loss_fp: 0.001835, loss_freq: 0.013757
[17:55:05.715] iteration 18887: loss: 0.050888, loss_s1: 0.035655, loss_fp: 0.005839, loss_freq: 0.032210
[17:55:06.339] iteration 18888: loss: 0.059534, loss_s1: 0.030570, loss_fp: 0.016658, loss_freq: 0.033042
[17:55:06.961] iteration 18889: loss: 0.051578, loss_s1: 0.027764, loss_fp: 0.002394, loss_freq: 0.037803
[17:55:07.583] iteration 18890: loss: 0.038274, loss_s1: 0.022552, loss_fp: 0.002726, loss_freq: 0.017531
[17:55:08.208] iteration 18891: loss: 0.061490, loss_s1: 0.033461, loss_fp: 0.003590, loss_freq: 0.039841
[17:55:08.838] iteration 18892: loss: 0.057463, loss_s1: 0.048837, loss_fp: 0.001906, loss_freq: 0.017866
[17:55:09.464] iteration 18893: loss: 0.050087, loss_s1: 0.027238, loss_fp: 0.001675, loss_freq: 0.031566
[17:55:10.092] iteration 18894: loss: 0.039544, loss_s1: 0.043834, loss_fp: 0.001201, loss_freq: 0.003314
[17:55:10.716] iteration 18895: loss: 0.086467, loss_s1: 0.055256, loss_fp: 0.002275, loss_freq: 0.019963
[17:55:11.341] iteration 18896: loss: 0.037459, loss_s1: 0.034508, loss_fp: 0.001232, loss_freq: 0.011451
[17:55:11.964] iteration 18897: loss: 0.050180, loss_s1: 0.047830, loss_fp: 0.002512, loss_freq: 0.019426
[17:55:12.588] iteration 18898: loss: 0.053976, loss_s1: 0.049638, loss_fp: 0.004827, loss_freq: 0.016839
[17:55:13.211] iteration 18899: loss: 0.055813, loss_s1: 0.044356, loss_fp: 0.003033, loss_freq: 0.031859
[17:55:13.832] iteration 18900: loss: 0.050236, loss_s1: 0.029966, loss_fp: 0.000554, loss_freq: 0.029254
[17:55:14.455] iteration 18901: loss: 0.040601, loss_s1: 0.027725, loss_fp: 0.004242, loss_freq: 0.011971
[17:55:15.075] iteration 18902: loss: 0.038044, loss_s1: 0.022589, loss_fp: 0.001064, loss_freq: 0.022682
[17:55:15.727] iteration 18903: loss: 0.067979, loss_s1: 0.033157, loss_fp: 0.001277, loss_freq: 0.068251
[17:55:16.383] iteration 18904: loss: 0.077377, loss_s1: 0.027924, loss_fp: 0.002136, loss_freq: 0.053609
[17:55:17.048] iteration 18905: loss: 0.057275, loss_s1: 0.035900, loss_fp: 0.004832, loss_freq: 0.035568
[17:55:17.704] iteration 18906: loss: 0.046533, loss_s1: 0.027321, loss_fp: 0.007301, loss_freq: 0.023191
[17:55:18.362] iteration 18907: loss: 0.067138, loss_s1: 0.057243, loss_fp: 0.002394, loss_freq: 0.026422
[17:55:19.015] iteration 18908: loss: 0.073870, loss_s1: 0.062760, loss_fp: 0.008254, loss_freq: 0.024312
[17:55:19.648] iteration 18909: loss: 0.045512, loss_s1: 0.034535, loss_fp: 0.003944, loss_freq: 0.015776
[17:55:20.273] iteration 18910: loss: 0.046851, loss_s1: 0.024060, loss_fp: 0.006716, loss_freq: 0.011277
[17:55:20.896] iteration 18911: loss: 0.054666, loss_s1: 0.031241, loss_fp: 0.003519, loss_freq: 0.015177
[17:55:21.519] iteration 18912: loss: 0.059218, loss_s1: 0.053262, loss_fp: 0.001186, loss_freq: 0.012466
[17:55:22.141] iteration 18913: loss: 0.051590, loss_s1: 0.045466, loss_fp: 0.007249, loss_freq: 0.010127
[17:55:22.760] iteration 18914: loss: 0.062644, loss_s1: 0.067796, loss_fp: 0.002366, loss_freq: 0.026395
[17:55:23.384] iteration 18915: loss: 0.038775, loss_s1: 0.025350, loss_fp: 0.001642, loss_freq: 0.019696
[17:55:24.005] iteration 18916: loss: 0.030652, loss_s1: 0.013160, loss_fp: 0.001146, loss_freq: 0.011238
[17:55:24.631] iteration 18917: loss: 0.059909, loss_s1: 0.047691, loss_fp: 0.000840, loss_freq: 0.033896
[17:55:25.251] iteration 18918: loss: 0.048204, loss_s1: 0.035162, loss_fp: 0.004394, loss_freq: 0.016420
[17:55:25.878] iteration 18919: loss: 0.050382, loss_s1: 0.026245, loss_fp: 0.001474, loss_freq: 0.041577
[17:55:26.538] iteration 18920: loss: 0.079541, loss_s1: 0.100321, loss_fp: 0.007646, loss_freq: 0.024172
[17:55:27.196] iteration 18921: loss: 0.050803, loss_s1: 0.041161, loss_fp: 0.002969, loss_freq: 0.014215
[17:55:27.856] iteration 18922: loss: 0.090876, loss_s1: 0.082965, loss_fp: 0.005531, loss_freq: 0.063452
[17:55:28.508] iteration 18923: loss: 0.040925, loss_s1: 0.026981, loss_fp: 0.002618, loss_freq: 0.018956
[17:55:29.133] iteration 18924: loss: 0.059127, loss_s1: 0.052318, loss_fp: 0.003242, loss_freq: 0.015457
[17:55:29.761] iteration 18925: loss: 0.058515, loss_s1: 0.061180, loss_fp: 0.002090, loss_freq: 0.011047
[17:55:30.387] iteration 18926: loss: 0.079696, loss_s1: 0.032823, loss_fp: 0.007230, loss_freq: 0.080474
[17:55:31.010] iteration 18927: loss: 0.089281, loss_s1: 0.080068, loss_fp: 0.005207, loss_freq: 0.030521
[17:55:31.632] iteration 18928: loss: 0.062382, loss_s1: 0.041930, loss_fp: 0.001253, loss_freq: 0.031541
[17:55:32.260] iteration 18929: loss: 0.065488, loss_s1: 0.063124, loss_fp: 0.003061, loss_freq: 0.017006
[17:55:32.881] iteration 18930: loss: 0.046530, loss_s1: 0.031528, loss_fp: 0.001301, loss_freq: 0.013171
[17:55:33.501] iteration 18931: loss: 0.046282, loss_s1: 0.042847, loss_fp: 0.000530, loss_freq: 0.005751
[17:55:34.129] iteration 18932: loss: 0.070907, loss_s1: 0.053199, loss_fp: 0.003619, loss_freq: 0.043888
[17:55:34.761] iteration 18933: loss: 0.062915, loss_s1: 0.060387, loss_fp: 0.003326, loss_freq: 0.032342
[17:55:35.385] iteration 18934: loss: 0.052525, loss_s1: 0.038284, loss_fp: 0.002220, loss_freq: 0.024131
[17:55:36.011] iteration 18935: loss: 0.045342, loss_s1: 0.022380, loss_fp: 0.000841, loss_freq: 0.017431
[17:55:36.640] iteration 18936: loss: 0.040442, loss_s1: 0.018996, loss_fp: 0.001905, loss_freq: 0.018457
[17:55:37.268] iteration 18937: loss: 0.051577, loss_s1: 0.043502, loss_fp: 0.003108, loss_freq: 0.022232
[17:55:37.897] iteration 18938: loss: 0.050283, loss_s1: 0.038264, loss_fp: 0.006372, loss_freq: 0.023138
[17:55:38.522] iteration 18939: loss: 0.095503, loss_s1: 0.063184, loss_fp: 0.002491, loss_freq: 0.052865
[17:55:39.150] iteration 18940: loss: 0.044282, loss_s1: 0.029973, loss_fp: 0.000986, loss_freq: 0.019312
[17:55:39.774] iteration 18941: loss: 0.044958, loss_s1: 0.029332, loss_fp: 0.003502, loss_freq: 0.021916
[17:55:40.406] iteration 18942: loss: 0.076809, loss_s1: 0.033715, loss_fp: 0.001168, loss_freq: 0.016993
[17:55:41.032] iteration 18943: loss: 0.056337, loss_s1: 0.030585, loss_fp: 0.003427, loss_freq: 0.038178
[17:55:41.660] iteration 18944: loss: 0.051352, loss_s1: 0.023312, loss_fp: 0.001047, loss_freq: 0.025814
[17:55:42.322] iteration 18945: loss: 0.069767, loss_s1: 0.042845, loss_fp: 0.001473, loss_freq: 0.048295
[17:55:43.001] iteration 18946: loss: 0.106938, loss_s1: 0.061918, loss_fp: 0.007093, loss_freq: 0.088840
[17:55:43.663] iteration 18947: loss: 0.069139, loss_s1: 0.048905, loss_fp: 0.000683, loss_freq: 0.051601
[17:55:44.321] iteration 18948: loss: 0.049335, loss_s1: 0.047096, loss_fp: 0.002812, loss_freq: 0.008680
[17:55:44.981] iteration 18949: loss: 0.054404, loss_s1: 0.029691, loss_fp: 0.004467, loss_freq: 0.028188
[17:55:45.624] iteration 18950: loss: 0.077105, loss_s1: 0.063038, loss_fp: 0.013813, loss_freq: 0.029963
[17:55:46.250] iteration 18951: loss: 0.031560, loss_s1: 0.023978, loss_fp: 0.000889, loss_freq: 0.011241
[17:55:46.875] iteration 18952: loss: 0.050595, loss_s1: 0.055410, loss_fp: 0.003178, loss_freq: 0.007161
[17:55:47.503] iteration 18953: loss: 0.069527, loss_s1: 0.052386, loss_fp: 0.003943, loss_freq: 0.032663
[17:55:48.130] iteration 18954: loss: 0.063088, loss_s1: 0.030414, loss_fp: 0.014839, loss_freq: 0.036791
[17:55:48.757] iteration 18955: loss: 0.060194, loss_s1: 0.063917, loss_fp: 0.002836, loss_freq: 0.022012
[17:55:49.380] iteration 18956: loss: 0.050897, loss_s1: 0.032700, loss_fp: 0.004369, loss_freq: 0.024028
[17:55:50.007] iteration 18957: loss: 0.082311, loss_s1: 0.078485, loss_fp: 0.003569, loss_freq: 0.054572
[17:55:50.624] iteration 18958: loss: 0.071872, loss_s1: 0.040388, loss_fp: 0.002573, loss_freq: 0.063875
[17:55:51.256] iteration 18959: loss: 0.060103, loss_s1: 0.025527, loss_fp: 0.003623, loss_freq: 0.025034
[17:55:52.033] iteration 18960: loss: 0.051211, loss_s1: 0.043814, loss_fp: 0.001296, loss_freq: 0.019847
[17:55:52.693] iteration 18961: loss: 0.041578, loss_s1: 0.026543, loss_fp: 0.005214, loss_freq: 0.007347
[17:55:53.358] iteration 18962: loss: 0.042078, loss_s1: 0.021058, loss_fp: 0.007154, loss_freq: 0.020721
[17:55:54.006] iteration 18963: loss: 0.066347, loss_s1: 0.030777, loss_fp: 0.002865, loss_freq: 0.040089
[17:55:54.627] iteration 18964: loss: 0.066255, loss_s1: 0.075971, loss_fp: 0.000692, loss_freq: 0.016534
[17:55:55.254] iteration 18965: loss: 0.089840, loss_s1: 0.045093, loss_fp: 0.028357, loss_freq: 0.047020
[17:55:55.876] iteration 18966: loss: 0.043372, loss_s1: 0.027637, loss_fp: 0.002219, loss_freq: 0.024149
[17:55:56.500] iteration 18967: loss: 0.036352, loss_s1: 0.029672, loss_fp: 0.000319, loss_freq: 0.007953
[17:55:57.127] iteration 18968: loss: 0.063825, loss_s1: 0.035874, loss_fp: 0.003414, loss_freq: 0.049923
[17:55:57.756] iteration 18969: loss: 0.054080, loss_s1: 0.044365, loss_fp: 0.004837, loss_freq: 0.016229
[17:55:58.384] iteration 18970: loss: 0.062048, loss_s1: 0.055342, loss_fp: 0.004418, loss_freq: 0.021038
[17:55:59.009] iteration 18971: loss: 0.054804, loss_s1: 0.047832, loss_fp: 0.004157, loss_freq: 0.016993
[17:55:59.633] iteration 18972: loss: 0.094971, loss_s1: 0.090848, loss_fp: 0.001899, loss_freq: 0.060182
[17:56:00.262] iteration 18973: loss: 0.056339, loss_s1: 0.048825, loss_fp: 0.002524, loss_freq: 0.022509
[17:56:00.892] iteration 18974: loss: 0.056391, loss_s1: 0.032146, loss_fp: 0.000285, loss_freq: 0.041993
[17:56:01.513] iteration 18975: loss: 0.052124, loss_s1: 0.022403, loss_fp: 0.010998, loss_freq: 0.028858
[17:56:02.137] iteration 18976: loss: 0.036490, loss_s1: 0.022531, loss_fp: 0.000793, loss_freq: 0.011839
[17:56:02.761] iteration 18977: loss: 0.066539, loss_s1: 0.034172, loss_fp: 0.003387, loss_freq: 0.033591
[17:56:03.386] iteration 18978: loss: 0.064686, loss_s1: 0.060908, loss_fp: 0.002322, loss_freq: 0.022142
[17:56:04.009] iteration 18979: loss: 0.043100, loss_s1: 0.022508, loss_fp: 0.002001, loss_freq: 0.008390
[17:56:04.627] iteration 18980: loss: 0.071564, loss_s1: 0.072075, loss_fp: 0.003811, loss_freq: 0.027885
[17:56:05.258] iteration 18981: loss: 0.069119, loss_s1: 0.055520, loss_fp: 0.002940, loss_freq: 0.035202
[17:56:05.891] iteration 18982: loss: 0.060824, loss_s1: 0.043722, loss_fp: 0.013861, loss_freq: 0.028733
[17:56:06.522] iteration 18983: loss: 0.064270, loss_s1: 0.045568, loss_fp: 0.006062, loss_freq: 0.030271
[17:56:07.151] iteration 18984: loss: 0.106256, loss_s1: 0.077666, loss_fp: 0.007232, loss_freq: 0.095169
[17:56:07.781] iteration 18985: loss: 0.047209, loss_s1: 0.031164, loss_fp: 0.003040, loss_freq: 0.020589
[17:56:08.403] iteration 18986: loss: 0.058562, loss_s1: 0.057009, loss_fp: 0.004380, loss_freq: 0.020374
[17:56:09.027] iteration 18987: loss: 0.099857, loss_s1: 0.068173, loss_fp: 0.026296, loss_freq: 0.059652
[17:56:09.648] iteration 18988: loss: 0.053470, loss_s1: 0.028710, loss_fp: 0.001579, loss_freq: 0.040836
[17:56:10.270] iteration 18989: loss: 0.068907, loss_s1: 0.025206, loss_fp: 0.004377, loss_freq: 0.059159
[17:56:10.892] iteration 18990: loss: 0.051247, loss_s1: 0.048126, loss_fp: 0.001203, loss_freq: 0.021350
[17:56:11.515] iteration 18991: loss: 0.077973, loss_s1: 0.059018, loss_fp: 0.008695, loss_freq: 0.029346
[17:56:12.140] iteration 18992: loss: 0.033140, loss_s1: 0.018554, loss_fp: 0.001858, loss_freq: 0.011375
[17:56:12.764] iteration 18993: loss: 0.044506, loss_s1: 0.026812, loss_fp: 0.001423, loss_freq: 0.020309
[17:56:13.388] iteration 18994: loss: 0.064409, loss_s1: 0.031435, loss_fp: 0.002695, loss_freq: 0.028994
[17:56:14.020] iteration 18995: loss: 0.057606, loss_s1: 0.031074, loss_fp: 0.002119, loss_freq: 0.023120
[17:56:14.646] iteration 18996: loss: 0.083112, loss_s1: 0.097679, loss_fp: 0.002300, loss_freq: 0.025664
[17:56:15.264] iteration 18997: loss: 0.048514, loss_s1: 0.043378, loss_fp: 0.004416, loss_freq: 0.015573
[17:56:15.883] iteration 18998: loss: 0.067819, loss_s1: 0.040825, loss_fp: 0.006362, loss_freq: 0.049153
[17:56:16.941] iteration 18999: loss: 0.049487, loss_s1: 0.048535, loss_fp: 0.001619, loss_freq: 0.014821
[17:56:17.600] iteration 19000: loss: 0.065549, loss_s1: 0.072869, loss_fp: 0.001056, loss_freq: 0.015690
[17:56:20.952] iteration 19000 : mean_dice : 0.723956
[17:56:21.599] iteration 19001: loss: 0.040045, loss_s1: 0.024783, loss_fp: 0.001168, loss_freq: 0.010096
[17:56:22.225] iteration 19002: loss: 0.041172, loss_s1: 0.018959, loss_fp: 0.000575, loss_freq: 0.012306
[17:56:22.848] iteration 19003: loss: 0.061356, loss_s1: 0.053107, loss_fp: 0.004154, loss_freq: 0.022128
[17:56:23.471] iteration 19004: loss: 0.083063, loss_s1: 0.071236, loss_fp: 0.007372, loss_freq: 0.038880
[17:56:24.091] iteration 19005: loss: 0.062395, loss_s1: 0.048403, loss_fp: 0.001500, loss_freq: 0.031453
[17:56:24.717] iteration 19006: loss: 0.032808, loss_s1: 0.015323, loss_fp: 0.001937, loss_freq: 0.018273
[17:56:25.343] iteration 19007: loss: 0.070737, loss_s1: 0.071594, loss_fp: 0.002603, loss_freq: 0.027303
[17:56:25.967] iteration 19008: loss: 0.058851, loss_s1: 0.051268, loss_fp: 0.003715, loss_freq: 0.026798
[17:56:26.616] iteration 19009: loss: 0.034429, loss_s1: 0.022868, loss_fp: 0.001720, loss_freq: 0.006827
[17:56:27.247] iteration 19010: loss: 0.080376, loss_s1: 0.040011, loss_fp: 0.006457, loss_freq: 0.079458
[17:56:27.871] iteration 19011: loss: 0.076105, loss_s1: 0.051898, loss_fp: 0.005560, loss_freq: 0.055701
[17:56:28.496] iteration 19012: loss: 0.059427, loss_s1: 0.015490, loss_fp: 0.010957, loss_freq: 0.032025
[17:56:29.117] iteration 19013: loss: 0.061581, loss_s1: 0.061016, loss_fp: 0.006078, loss_freq: 0.027448
[17:56:29.739] iteration 19014: loss: 0.109735, loss_s1: 0.090372, loss_fp: 0.001372, loss_freq: 0.095857
[17:56:30.364] iteration 19015: loss: 0.050931, loss_s1: 0.030837, loss_fp: 0.003824, loss_freq: 0.011767
[17:56:30.989] iteration 19016: loss: 0.037951, loss_s1: 0.023728, loss_fp: 0.002356, loss_freq: 0.013746
[17:56:31.614] iteration 19017: loss: 0.061950, loss_s1: 0.058544, loss_fp: 0.001310, loss_freq: 0.025999
[17:56:32.239] iteration 19018: loss: 0.080941, loss_s1: 0.017793, loss_fp: 0.002922, loss_freq: 0.026761
[17:56:32.867] iteration 19019: loss: 0.068604, loss_s1: 0.068641, loss_fp: 0.000772, loss_freq: 0.012280
[17:56:33.487] iteration 19020: loss: 0.070933, loss_s1: 0.071730, loss_fp: 0.001632, loss_freq: 0.012852
[17:56:34.111] iteration 19021: loss: 0.047921, loss_s1: 0.018903, loss_fp: 0.001532, loss_freq: 0.017360
[17:56:34.736] iteration 19022: loss: 0.055738, loss_s1: 0.040697, loss_fp: 0.000846, loss_freq: 0.034270
[17:56:35.359] iteration 19023: loss: 0.035805, loss_s1: 0.024630, loss_fp: 0.001477, loss_freq: 0.014626
[17:56:35.984] iteration 19024: loss: 0.072036, loss_s1: 0.086867, loss_fp: 0.003270, loss_freq: 0.020155
[17:56:36.609] iteration 19025: loss: 0.042369, loss_s1: 0.022326, loss_fp: 0.001985, loss_freq: 0.024964
[17:56:37.233] iteration 19026: loss: 0.093600, loss_s1: 0.089787, loss_fp: 0.006541, loss_freq: 0.051632
[17:56:37.862] iteration 19027: loss: 0.077878, loss_s1: 0.058576, loss_fp: 0.005711, loss_freq: 0.041265
[17:56:38.488] iteration 19028: loss: 0.054627, loss_s1: 0.040563, loss_fp: 0.001834, loss_freq: 0.026853
[17:56:39.112] iteration 19029: loss: 0.052104, loss_s1: 0.046448, loss_fp: 0.002620, loss_freq: 0.023055
[17:56:39.734] iteration 19030: loss: 0.050251, loss_s1: 0.045376, loss_fp: 0.001963, loss_freq: 0.017256
[17:56:40.361] iteration 19031: loss: 0.062013, loss_s1: 0.034539, loss_fp: 0.000616, loss_freq: 0.036500
[17:56:40.984] iteration 19032: loss: 0.037873, loss_s1: 0.026625, loss_fp: 0.001963, loss_freq: 0.003988
[17:56:41.614] iteration 19033: loss: 0.067258, loss_s1: 0.031024, loss_fp: 0.003125, loss_freq: 0.037043
[17:56:42.240] iteration 19034: loss: 0.099875, loss_s1: 0.093897, loss_fp: 0.009365, loss_freq: 0.061741
[17:56:42.902] iteration 19035: loss: 0.069621, loss_s1: 0.064466, loss_fp: 0.006130, loss_freq: 0.029781
[17:56:43.567] iteration 19036: loss: 0.070108, loss_s1: 0.050114, loss_fp: 0.002644, loss_freq: 0.024068
[17:56:44.232] iteration 19037: loss: 0.099915, loss_s1: 0.093001, loss_fp: 0.004542, loss_freq: 0.054370
[17:56:44.891] iteration 19038: loss: 0.083579, loss_s1: 0.067915, loss_fp: 0.002031, loss_freq: 0.060505
[17:56:45.551] iteration 19039: loss: 0.051593, loss_s1: 0.050567, loss_fp: 0.002204, loss_freq: 0.008508
[17:56:46.179] iteration 19040: loss: 0.088055, loss_s1: 0.092716, loss_fp: 0.003120, loss_freq: 0.035026
[17:56:46.810] iteration 19041: loss: 0.057886, loss_s1: 0.033626, loss_fp: 0.003626, loss_freq: 0.044347
[17:56:47.435] iteration 19042: loss: 0.061352, loss_s1: 0.044186, loss_fp: 0.002104, loss_freq: 0.044116
[17:56:48.060] iteration 19043: loss: 0.047482, loss_s1: 0.022926, loss_fp: 0.001725, loss_freq: 0.033210
[17:56:48.683] iteration 19044: loss: 0.063999, loss_s1: 0.063545, loss_fp: 0.002391, loss_freq: 0.025719
[17:56:49.306] iteration 19045: loss: 0.046458, loss_s1: 0.028315, loss_fp: 0.003437, loss_freq: 0.029011
[17:56:49.935] iteration 19046: loss: 0.065632, loss_s1: 0.059341, loss_fp: 0.009418, loss_freq: 0.023464
[17:56:50.564] iteration 19047: loss: 0.046518, loss_s1: 0.034108, loss_fp: 0.007854, loss_freq: 0.016625
[17:56:51.193] iteration 19048: loss: 0.033695, loss_s1: 0.014955, loss_fp: 0.004994, loss_freq: 0.019468
[17:56:51.826] iteration 19049: loss: 0.087160, loss_s1: 0.072596, loss_fp: 0.008221, loss_freq: 0.054480
[17:56:52.452] iteration 19050: loss: 0.047075, loss_s1: 0.009634, loss_fp: 0.001986, loss_freq: 0.045210
[17:56:53.081] iteration 19051: loss: 0.060013, loss_s1: 0.053699, loss_fp: 0.003395, loss_freq: 0.021810
[17:56:53.713] iteration 19052: loss: 0.082850, loss_s1: 0.068756, loss_fp: 0.003349, loss_freq: 0.058232
[17:56:54.342] iteration 19053: loss: 0.032779, loss_s1: 0.012979, loss_fp: 0.001550, loss_freq: 0.009471
[17:56:54.972] iteration 19054: loss: 0.046034, loss_s1: 0.018535, loss_fp: 0.003561, loss_freq: 0.028588
[17:56:55.601] iteration 19055: loss: 0.050753, loss_s1: 0.034590, loss_fp: 0.001717, loss_freq: 0.008368
[17:56:56.241] iteration 19056: loss: 0.055787, loss_s1: 0.026784, loss_fp: 0.005586, loss_freq: 0.016106
[17:56:56.883] iteration 19057: loss: 0.033542, loss_s1: 0.029551, loss_fp: 0.002959, loss_freq: 0.006689
[17:56:57.514] iteration 19058: loss: 0.046094, loss_s1: 0.031699, loss_fp: 0.002936, loss_freq: 0.022859
[17:56:58.150] iteration 19059: loss: 0.042727, loss_s1: 0.037077, loss_fp: 0.001058, loss_freq: 0.017811
[17:56:58.784] iteration 19060: loss: 0.049845, loss_s1: 0.050047, loss_fp: 0.002550, loss_freq: 0.014042
[17:56:59.418] iteration 19061: loss: 0.038627, loss_s1: 0.025918, loss_fp: 0.000933, loss_freq: 0.015612
[17:57:00.061] iteration 19062: loss: 0.064559, loss_s1: 0.054975, loss_fp: 0.001196, loss_freq: 0.015265
[17:57:00.693] iteration 19063: loss: 0.056234, loss_s1: 0.051304, loss_fp: 0.007675, loss_freq: 0.019066
[17:57:01.328] iteration 19064: loss: 0.095891, loss_s1: 0.037420, loss_fp: 0.005882, loss_freq: 0.112141
[17:57:01.962] iteration 19065: loss: 0.070944, loss_s1: 0.050687, loss_fp: 0.002100, loss_freq: 0.040244
[17:57:02.591] iteration 19066: loss: 0.051206, loss_s1: 0.040022, loss_fp: 0.005886, loss_freq: 0.026428
[17:57:03.219] iteration 19067: loss: 0.060659, loss_s1: 0.040448, loss_fp: 0.006579, loss_freq: 0.033829
[17:57:03.849] iteration 19068: loss: 0.079497, loss_s1: 0.044935, loss_fp: 0.001766, loss_freq: 0.065907
[17:57:04.482] iteration 19069: loss: 0.091908, loss_s1: 0.079134, loss_fp: 0.006392, loss_freq: 0.043962
[17:57:05.111] iteration 19070: loss: 0.046603, loss_s1: 0.028625, loss_fp: 0.003331, loss_freq: 0.016254
[17:57:05.736] iteration 19071: loss: 0.052905, loss_s1: 0.039456, loss_fp: 0.004778, loss_freq: 0.021548
[17:57:06.362] iteration 19072: loss: 0.054675, loss_s1: 0.039711, loss_fp: 0.005754, loss_freq: 0.021642
[17:57:07.007] iteration 19073: loss: 0.054871, loss_s1: 0.049013, loss_fp: 0.001810, loss_freq: 0.017558
[17:57:07.634] iteration 19074: loss: 0.087710, loss_s1: 0.096764, loss_fp: 0.003319, loss_freq: 0.015978
[17:57:08.260] iteration 19075: loss: 0.039710, loss_s1: 0.030132, loss_fp: 0.005815, loss_freq: 0.017108
[17:57:08.887] iteration 19076: loss: 0.064727, loss_s1: 0.072483, loss_fp: 0.001730, loss_freq: 0.016468
[17:57:09.518] iteration 19077: loss: 0.034071, loss_s1: 0.009992, loss_fp: 0.013232, loss_freq: 0.010910
[17:57:10.150] iteration 19078: loss: 0.053473, loss_s1: 0.036144, loss_fp: 0.005696, loss_freq: 0.029187
[17:57:10.774] iteration 19079: loss: 0.077761, loss_s1: 0.042477, loss_fp: 0.003767, loss_freq: 0.060684
[17:57:11.396] iteration 19080: loss: 0.070783, loss_s1: 0.050388, loss_fp: 0.003001, loss_freq: 0.055439
[17:57:12.021] iteration 19081: loss: 0.102431, loss_s1: 0.132000, loss_fp: 0.012401, loss_freq: 0.029964
[17:57:12.645] iteration 19082: loss: 0.094230, loss_s1: 0.044172, loss_fp: 0.008118, loss_freq: 0.098656
[17:57:13.270] iteration 19083: loss: 0.102132, loss_s1: 0.094589, loss_fp: 0.005736, loss_freq: 0.070852
[17:57:13.893] iteration 19084: loss: 0.048813, loss_s1: 0.029342, loss_fp: 0.004368, loss_freq: 0.029018
[17:57:14.519] iteration 19085: loss: 0.063791, loss_s1: 0.064001, loss_fp: 0.004833, loss_freq: 0.015643
[17:57:15.147] iteration 19086: loss: 0.062898, loss_s1: 0.041180, loss_fp: 0.001213, loss_freq: 0.034101
[17:57:15.771] iteration 19087: loss: 0.042627, loss_s1: 0.020887, loss_fp: 0.005892, loss_freq: 0.026908
[17:57:16.399] iteration 19088: loss: 0.062908, loss_s1: 0.060315, loss_fp: 0.004460, loss_freq: 0.025664
[17:57:17.023] iteration 19089: loss: 0.052709, loss_s1: 0.029590, loss_fp: 0.002871, loss_freq: 0.021414
[17:57:17.684] iteration 19090: loss: 0.050948, loss_s1: 0.039805, loss_fp: 0.001070, loss_freq: 0.015909
[17:57:18.353] iteration 19091: loss: 0.054999, loss_s1: 0.027797, loss_fp: 0.001515, loss_freq: 0.020109
[17:57:19.016] iteration 19092: loss: 0.031613, loss_s1: 0.016938, loss_fp: 0.001378, loss_freq: 0.007988
[17:57:19.675] iteration 19093: loss: 0.051374, loss_s1: 0.046503, loss_fp: 0.002371, loss_freq: 0.023667
[17:57:20.323] iteration 19094: loss: 0.055793, loss_s1: 0.032214, loss_fp: 0.009796, loss_freq: 0.026512
[17:57:20.947] iteration 19095: loss: 0.039654, loss_s1: 0.022058, loss_fp: 0.002017, loss_freq: 0.019435
[17:57:21.573] iteration 19096: loss: 0.041778, loss_s1: 0.014941, loss_fp: 0.000457, loss_freq: 0.019603
[17:57:22.201] iteration 19097: loss: 0.029238, loss_s1: 0.015155, loss_fp: 0.000924, loss_freq: 0.010398
[17:57:22.828] iteration 19098: loss: 0.070050, loss_s1: 0.078106, loss_fp: 0.008070, loss_freq: 0.020462
[17:57:23.458] iteration 19099: loss: 0.033655, loss_s1: 0.021299, loss_fp: 0.001455, loss_freq: 0.013487
[17:57:24.084] iteration 19100: loss: 0.081232, loss_s1: 0.050681, loss_fp: 0.005144, loss_freq: 0.046188
[17:57:24.713] iteration 19101: loss: 0.053248, loss_s1: 0.036210, loss_fp: 0.002090, loss_freq: 0.030885
[17:57:25.347] iteration 19102: loss: 0.053619, loss_s1: 0.046156, loss_fp: 0.001045, loss_freq: 0.025245
[17:57:25.971] iteration 19103: loss: 0.049510, loss_s1: 0.020950, loss_fp: 0.001766, loss_freq: 0.019085
[17:57:26.594] iteration 19104: loss: 0.044032, loss_s1: 0.022653, loss_fp: 0.000932, loss_freq: 0.031144
[17:57:27.224] iteration 19105: loss: 0.024899, loss_s1: 0.011486, loss_fp: 0.001276, loss_freq: 0.003114
[17:57:27.852] iteration 19106: loss: 0.053341, loss_s1: 0.030246, loss_fp: 0.000853, loss_freq: 0.024016
[17:57:28.483] iteration 19107: loss: 0.111194, loss_s1: 0.090680, loss_fp: 0.012016, loss_freq: 0.074899
[17:57:29.113] iteration 19108: loss: 0.061727, loss_s1: 0.055119, loss_fp: 0.004163, loss_freq: 0.015929
[17:57:29.739] iteration 19109: loss: 0.062150, loss_s1: 0.042692, loss_fp: 0.002945, loss_freq: 0.032185
[17:57:30.369] iteration 19110: loss: 0.045366, loss_s1: 0.029462, loss_fp: 0.003178, loss_freq: 0.019016
[17:57:30.998] iteration 19111: loss: 0.060437, loss_s1: 0.064558, loss_fp: 0.003466, loss_freq: 0.023623
[17:57:31.624] iteration 19112: loss: 0.055647, loss_s1: 0.024856, loss_fp: 0.001603, loss_freq: 0.039953
[17:57:32.254] iteration 19113: loss: 0.036598, loss_s1: 0.012196, loss_fp: 0.002794, loss_freq: 0.017023
[17:57:32.922] iteration 19114: loss: 0.075019, loss_s1: 0.072492, loss_fp: 0.007094, loss_freq: 0.038520
[17:57:33.576] iteration 19115: loss: 0.035438, loss_s1: 0.019745, loss_fp: 0.007566, loss_freq: 0.011653
[17:57:34.233] iteration 19116: loss: 0.052740, loss_s1: 0.055578, loss_fp: 0.010547, loss_freq: 0.008945
[17:57:34.902] iteration 19117: loss: 0.066224, loss_s1: 0.073855, loss_fp: 0.003555, loss_freq: 0.018531
[17:57:35.561] iteration 19118: loss: 0.118555, loss_s1: 0.100648, loss_fp: 0.012910, loss_freq: 0.087363
[17:57:36.219] iteration 19119: loss: 0.046084, loss_s1: 0.024038, loss_fp: 0.002981, loss_freq: 0.029293
[17:57:36.881] iteration 19120: loss: 0.071512, loss_s1: 0.031585, loss_fp: 0.001480, loss_freq: 0.036544
[17:57:37.506] iteration 19121: loss: 0.059385, loss_s1: 0.047858, loss_fp: 0.005511, loss_freq: 0.026893
[17:57:38.128] iteration 19122: loss: 0.072830, loss_s1: 0.075703, loss_fp: 0.015469, loss_freq: 0.010783
[17:57:38.757] iteration 19123: loss: 0.066062, loss_s1: 0.062311, loss_fp: 0.003358, loss_freq: 0.017238
[17:57:39.382] iteration 19124: loss: 0.085004, loss_s1: 0.051621, loss_fp: 0.013355, loss_freq: 0.046411
[17:57:40.005] iteration 19125: loss: 0.057040, loss_s1: 0.066319, loss_fp: 0.003251, loss_freq: 0.005969
[17:57:40.630] iteration 19126: loss: 0.086766, loss_s1: 0.064575, loss_fp: 0.000843, loss_freq: 0.042994
[17:57:41.255] iteration 19127: loss: 0.049738, loss_s1: 0.036030, loss_fp: 0.005487, loss_freq: 0.019480
[17:57:41.879] iteration 19128: loss: 0.058868, loss_s1: 0.072138, loss_fp: 0.003139, loss_freq: 0.017436
[17:57:42.506] iteration 19129: loss: 0.087921, loss_s1: 0.048851, loss_fp: 0.002044, loss_freq: 0.086557
[17:57:43.129] iteration 19130: loss: 0.065541, loss_s1: 0.056065, loss_fp: 0.001920, loss_freq: 0.023088
[17:57:43.760] iteration 19131: loss: 0.086709, loss_s1: 0.082032, loss_fp: 0.003612, loss_freq: 0.038868
[17:57:44.386] iteration 19132: loss: 0.066397, loss_s1: 0.072192, loss_fp: 0.008295, loss_freq: 0.018951
[17:57:45.009] iteration 19133: loss: 0.084221, loss_s1: 0.081462, loss_fp: 0.001820, loss_freq: 0.048552
[17:57:45.633] iteration 19134: loss: 0.055637, loss_s1: 0.029700, loss_fp: 0.009716, loss_freq: 0.034219
[17:57:46.253] iteration 19135: loss: 0.037296, loss_s1: 0.014352, loss_fp: 0.001215, loss_freq: 0.004775
[17:57:46.877] iteration 19136: loss: 0.036864, loss_s1: 0.028833, loss_fp: 0.001043, loss_freq: 0.013541
[17:57:47.502] iteration 19137: loss: 0.038649, loss_s1: 0.025166, loss_fp: 0.004928, loss_freq: 0.011241
[17:57:48.127] iteration 19138: loss: 0.070390, loss_s1: 0.026818, loss_fp: 0.010952, loss_freq: 0.061076
[17:57:48.756] iteration 19139: loss: 0.074370, loss_s1: 0.068240, loss_fp: 0.004834, loss_freq: 0.024611
[17:57:49.382] iteration 19140: loss: 0.057273, loss_s1: 0.054730, loss_fp: 0.001850, loss_freq: 0.017454
[17:57:50.004] iteration 19141: loss: 0.081926, loss_s1: 0.075909, loss_fp: 0.011781, loss_freq: 0.032947
[17:57:50.626] iteration 19142: loss: 0.059958, loss_s1: 0.032698, loss_fp: 0.002665, loss_freq: 0.025340
[17:57:51.254] iteration 19143: loss: 0.047197, loss_s1: 0.035230, loss_fp: 0.006841, loss_freq: 0.016646
[17:57:51.937] iteration 19144: loss: 0.068387, loss_s1: 0.053230, loss_fp: 0.009395, loss_freq: 0.026201
[17:57:52.597] iteration 19145: loss: 0.064213, loss_s1: 0.032431, loss_fp: 0.007116, loss_freq: 0.056036
[17:57:53.255] iteration 19146: loss: 0.034066, loss_s1: 0.025658, loss_fp: 0.001841, loss_freq: 0.006981
[17:57:53.914] iteration 19147: loss: 0.044199, loss_s1: 0.035953, loss_fp: 0.002114, loss_freq: 0.016487
[17:57:54.677] iteration 19148: loss: 0.075532, loss_s1: 0.057431, loss_fp: 0.014987, loss_freq: 0.035343
[17:57:55.338] iteration 19149: loss: 0.072502, loss_s1: 0.026015, loss_fp: 0.002787, loss_freq: 0.068991
[17:57:56.010] iteration 19150: loss: 0.064947, loss_s1: 0.051151, loss_fp: 0.003529, loss_freq: 0.040298
[17:57:56.683] iteration 19151: loss: 0.038554, loss_s1: 0.023088, loss_fp: 0.000637, loss_freq: 0.023089
[17:57:57.327] iteration 19152: loss: 0.055518, loss_s1: 0.027398, loss_fp: 0.012071, loss_freq: 0.018257
[17:57:57.944] iteration 19153: loss: 0.031992, loss_s1: 0.021110, loss_fp: 0.002999, loss_freq: 0.011317
[17:57:58.566] iteration 19154: loss: 0.063589, loss_s1: 0.036559, loss_fp: 0.000536, loss_freq: 0.030254
[17:57:59.189] iteration 19155: loss: 0.059259, loss_s1: 0.041138, loss_fp: 0.006666, loss_freq: 0.012941
[17:57:59.810] iteration 19156: loss: 0.072990, loss_s1: 0.041554, loss_fp: 0.001786, loss_freq: 0.050257
[17:58:00.436] iteration 19157: loss: 0.056672, loss_s1: 0.056234, loss_fp: 0.003219, loss_freq: 0.019727
[17:58:01.058] iteration 19158: loss: 0.056275, loss_s1: 0.053146, loss_fp: 0.004473, loss_freq: 0.009516
[17:58:01.679] iteration 19159: loss: 0.055986, loss_s1: 0.030849, loss_fp: 0.003229, loss_freq: 0.036040
[17:58:02.657] iteration 19160: loss: 0.046269, loss_s1: 0.039520, loss_fp: 0.000498, loss_freq: 0.008959
[17:58:03.301] iteration 19161: loss: 0.082455, loss_s1: 0.051974, loss_fp: 0.004243, loss_freq: 0.034924
[17:58:03.941] iteration 19162: loss: 0.059380, loss_s1: 0.042516, loss_fp: 0.001405, loss_freq: 0.040210
[17:58:04.579] iteration 19163: loss: 0.051253, loss_s1: 0.034197, loss_fp: 0.001546, loss_freq: 0.011937
[17:58:05.217] iteration 19164: loss: 0.064670, loss_s1: 0.031671, loss_fp: 0.004551, loss_freq: 0.027359
[17:58:05.851] iteration 19165: loss: 0.109141, loss_s1: 0.068574, loss_fp: 0.015278, loss_freq: 0.030392
[17:58:06.480] iteration 19166: loss: 0.048272, loss_s1: 0.033479, loss_fp: 0.000923, loss_freq: 0.024611
[17:58:07.104] iteration 19167: loss: 0.044154, loss_s1: 0.042573, loss_fp: 0.000806, loss_freq: 0.011410
[17:58:07.728] iteration 19168: loss: 0.050368, loss_s1: 0.050613, loss_fp: 0.003610, loss_freq: 0.021529
[17:58:08.355] iteration 19169: loss: 0.075201, loss_s1: 0.056782, loss_fp: 0.008407, loss_freq: 0.040387
[17:58:08.979] iteration 19170: loss: 0.034952, loss_s1: 0.013294, loss_fp: 0.000905, loss_freq: 0.016005
[17:58:09.639] iteration 19171: loss: 0.046795, loss_s1: 0.021377, loss_fp: 0.001941, loss_freq: 0.023451
[17:58:10.332] iteration 19172: loss: 0.066751, loss_s1: 0.045094, loss_fp: 0.004289, loss_freq: 0.050162
[17:58:10.989] iteration 19173: loss: 0.036524, loss_s1: 0.021573, loss_fp: 0.000730, loss_freq: 0.016186
[17:58:11.644] iteration 19174: loss: 0.068210, loss_s1: 0.062184, loss_fp: 0.001821, loss_freq: 0.030434
[17:58:12.274] iteration 19175: loss: 0.104195, loss_s1: 0.066532, loss_fp: 0.014296, loss_freq: 0.093676
[17:58:12.899] iteration 19176: loss: 0.052032, loss_s1: 0.037893, loss_fp: 0.003270, loss_freq: 0.014597
[17:58:13.527] iteration 19177: loss: 0.047957, loss_s1: 0.041671, loss_fp: 0.003987, loss_freq: 0.019095
[17:58:14.167] iteration 19178: loss: 0.042600, loss_s1: 0.016825, loss_fp: 0.005018, loss_freq: 0.021351
[17:58:14.790] iteration 19179: loss: 0.070474, loss_s1: 0.052886, loss_fp: 0.002928, loss_freq: 0.029924
[17:58:15.417] iteration 19180: loss: 0.044427, loss_s1: 0.032124, loss_fp: 0.001301, loss_freq: 0.007440
[17:58:16.040] iteration 19181: loss: 0.039117, loss_s1: 0.013336, loss_fp: 0.002078, loss_freq: 0.016413
[17:58:16.660] iteration 19182: loss: 0.070068, loss_s1: 0.037194, loss_fp: 0.002266, loss_freq: 0.029626
[17:58:17.284] iteration 19183: loss: 0.115598, loss_s1: 0.138265, loss_fp: 0.002144, loss_freq: 0.056559
[17:58:17.909] iteration 19184: loss: 0.043987, loss_s1: 0.031247, loss_fp: 0.001025, loss_freq: 0.026973
[17:58:18.538] iteration 19185: loss: 0.052060, loss_s1: 0.045987, loss_fp: 0.003164, loss_freq: 0.023432
[17:58:19.160] iteration 19186: loss: 0.055239, loss_s1: 0.064105, loss_fp: 0.000868, loss_freq: 0.005292
[17:58:19.783] iteration 19187: loss: 0.067254, loss_s1: 0.057424, loss_fp: 0.007319, loss_freq: 0.025193
[17:58:20.406] iteration 19188: loss: 0.065996, loss_s1: 0.055636, loss_fp: 0.004341, loss_freq: 0.030182
[17:58:21.033] iteration 19189: loss: 0.052132, loss_s1: 0.045297, loss_fp: 0.002292, loss_freq: 0.007971
[17:58:21.659] iteration 19190: loss: 0.046232, loss_s1: 0.049749, loss_fp: 0.002858, loss_freq: 0.010063
[17:58:22.288] iteration 19191: loss: 0.054701, loss_s1: 0.045079, loss_fp: 0.008123, loss_freq: 0.014534
[17:58:22.966] iteration 19192: loss: 0.049903, loss_s1: 0.040138, loss_fp: 0.001128, loss_freq: 0.025472
[17:58:23.624] iteration 19193: loss: 0.030323, loss_s1: 0.021775, loss_fp: 0.001625, loss_freq: 0.006423
[17:58:24.282] iteration 19194: loss: 0.077732, loss_s1: 0.061362, loss_fp: 0.005597, loss_freq: 0.028965
[17:58:24.939] iteration 19195: loss: 0.077573, loss_s1: 0.067899, loss_fp: 0.007190, loss_freq: 0.049775
[17:58:25.575] iteration 19196: loss: 0.104153, loss_s1: 0.097515, loss_fp: 0.002798, loss_freq: 0.069480
[17:58:26.204] iteration 19197: loss: 0.075037, loss_s1: 0.088951, loss_fp: 0.000568, loss_freq: 0.026328
[17:58:26.829] iteration 19198: loss: 0.085046, loss_s1: 0.069180, loss_fp: 0.003195, loss_freq: 0.057397
[17:58:27.459] iteration 19199: loss: 0.049261, loss_s1: 0.036938, loss_fp: 0.005744, loss_freq: 0.022004
[17:58:28.085] iteration 19200: loss: 0.058381, loss_s1: 0.049411, loss_fp: 0.006004, loss_freq: 0.016228
[17:58:31.368] iteration 19200 : mean_dice : 0.737885
[17:58:32.016] iteration 19201: loss: 0.077714, loss_s1: 0.075646, loss_fp: 0.005026, loss_freq: 0.037245
[17:58:32.640] iteration 19202: loss: 0.055722, loss_s1: 0.043170, loss_fp: 0.005241, loss_freq: 0.036282
[17:58:33.265] iteration 19203: loss: 0.066568, loss_s1: 0.073541, loss_fp: 0.000721, loss_freq: 0.025005
[17:58:33.889] iteration 19204: loss: 0.045588, loss_s1: 0.027961, loss_fp: 0.003320, loss_freq: 0.021753
[17:58:34.516] iteration 19205: loss: 0.036475, loss_s1: 0.029411, loss_fp: 0.001053, loss_freq: 0.005778
[17:58:35.142] iteration 19206: loss: 0.045071, loss_s1: 0.044057, loss_fp: 0.000923, loss_freq: 0.007598
[17:58:35.768] iteration 19207: loss: 0.069833, loss_s1: 0.078297, loss_fp: 0.004159, loss_freq: 0.016542
[17:58:36.390] iteration 19208: loss: 0.074337, loss_s1: 0.058690, loss_fp: 0.001562, loss_freq: 0.047263
[17:58:37.016] iteration 19209: loss: 0.059403, loss_s1: 0.070364, loss_fp: 0.001016, loss_freq: 0.018338
[17:58:37.647] iteration 19210: loss: 0.071557, loss_s1: 0.056170, loss_fp: 0.010821, loss_freq: 0.044145
[17:58:38.273] iteration 19211: loss: 0.053066, loss_s1: 0.037683, loss_fp: 0.001866, loss_freq: 0.010963
[17:58:38.899] iteration 19212: loss: 0.063966, loss_s1: 0.063699, loss_fp: 0.001883, loss_freq: 0.027782
[17:58:39.524] iteration 19213: loss: 0.049595, loss_s1: 0.029060, loss_fp: 0.003296, loss_freq: 0.017162
[17:58:40.154] iteration 19214: loss: 0.027457, loss_s1: 0.011250, loss_fp: 0.001121, loss_freq: 0.013916
[17:58:40.780] iteration 19215: loss: 0.074064, loss_s1: 0.068563, loss_fp: 0.006437, loss_freq: 0.028151
[17:58:41.408] iteration 19216: loss: 0.055198, loss_s1: 0.026178, loss_fp: 0.005850, loss_freq: 0.014365
[17:58:42.032] iteration 19217: loss: 0.061162, loss_s1: 0.040208, loss_fp: 0.000584, loss_freq: 0.034489
[17:58:42.656] iteration 19218: loss: 0.051085, loss_s1: 0.048863, loss_fp: 0.003575, loss_freq: 0.010617
[17:58:43.284] iteration 19219: loss: 0.035493, loss_s1: 0.020989, loss_fp: 0.004780, loss_freq: 0.013263
[17:58:43.907] iteration 19220: loss: 0.064860, loss_s1: 0.030109, loss_fp: 0.003192, loss_freq: 0.027815
[17:58:44.533] iteration 19221: loss: 0.058654, loss_s1: 0.065758, loss_fp: 0.005943, loss_freq: 0.009596
[17:58:45.159] iteration 19222: loss: 0.051568, loss_s1: 0.043182, loss_fp: 0.001501, loss_freq: 0.016251
[17:58:45.785] iteration 19223: loss: 0.053798, loss_s1: 0.063846, loss_fp: 0.004506, loss_freq: 0.006914
[17:58:46.409] iteration 19224: loss: 0.052988, loss_s1: 0.024122, loss_fp: 0.003486, loss_freq: 0.041911
[17:58:47.034] iteration 19225: loss: 0.087425, loss_s1: 0.051501, loss_fp: 0.008173, loss_freq: 0.078543
[17:58:47.660] iteration 19226: loss: 0.052101, loss_s1: 0.031526, loss_fp: 0.005053, loss_freq: 0.024304
[17:58:48.283] iteration 19227: loss: 0.094948, loss_s1: 0.118574, loss_fp: 0.011944, loss_freq: 0.027395
[17:58:48.912] iteration 19228: loss: 0.040789, loss_s1: 0.034477, loss_fp: 0.001347, loss_freq: 0.010438
[17:58:49.544] iteration 19229: loss: 0.062602, loss_s1: 0.035482, loss_fp: 0.004673, loss_freq: 0.035124
[17:58:50.165] iteration 19230: loss: 0.107879, loss_s1: 0.076152, loss_fp: 0.006703, loss_freq: 0.095161
[17:58:50.790] iteration 19231: loss: 0.058480, loss_s1: 0.046261, loss_fp: 0.002477, loss_freq: 0.031726
[17:58:51.414] iteration 19232: loss: 0.057226, loss_s1: 0.037295, loss_fp: 0.007388, loss_freq: 0.033181
[17:58:52.038] iteration 19233: loss: 0.046263, loss_s1: 0.029486, loss_fp: 0.003506, loss_freq: 0.017028
[17:58:52.665] iteration 19234: loss: 0.069978, loss_s1: 0.067430, loss_fp: 0.003682, loss_freq: 0.029859
[17:58:53.289] iteration 19235: loss: 0.092643, loss_s1: 0.108868, loss_fp: 0.002822, loss_freq: 0.014266
[17:58:53.911] iteration 19236: loss: 0.062561, loss_s1: 0.058167, loss_fp: 0.003203, loss_freq: 0.020568
[17:58:54.532] iteration 19237: loss: 0.047535, loss_s1: 0.042771, loss_fp: 0.006571, loss_freq: 0.016768
[17:58:55.150] iteration 19238: loss: 0.034430, loss_s1: 0.019276, loss_fp: 0.000673, loss_freq: 0.005864
[17:58:55.772] iteration 19239: loss: 0.059405, loss_s1: 0.036395, loss_fp: 0.005495, loss_freq: 0.040124
[17:58:56.397] iteration 19240: loss: 0.086489, loss_s1: 0.065077, loss_fp: 0.000606, loss_freq: 0.053209
[17:58:57.022] iteration 19241: loss: 0.077070, loss_s1: 0.082178, loss_fp: 0.004614, loss_freq: 0.031045
[17:58:57.646] iteration 19242: loss: 0.043048, loss_s1: 0.011273, loss_fp: 0.014534, loss_freq: 0.012984
[17:58:58.272] iteration 19243: loss: 0.042203, loss_s1: 0.023647, loss_fp: 0.011509, loss_freq: 0.011730
[17:58:58.897] iteration 19244: loss: 0.071376, loss_s1: 0.052316, loss_fp: 0.014390, loss_freq: 0.048596
[17:58:59.522] iteration 19245: loss: 0.048922, loss_s1: 0.036525, loss_fp: 0.001420, loss_freq: 0.018476
[17:59:00.145] iteration 19246: loss: 0.047281, loss_s1: 0.041879, loss_fp: 0.004813, loss_freq: 0.004426
[17:59:00.765] iteration 19247: loss: 0.034768, loss_s1: 0.030324, loss_fp: 0.001223, loss_freq: 0.006050
[17:59:01.389] iteration 19248: loss: 0.071107, loss_s1: 0.070089, loss_fp: 0.005553, loss_freq: 0.028294
[17:59:02.048] iteration 19249: loss: 0.062035, loss_s1: 0.044686, loss_fp: 0.003446, loss_freq: 0.030256
[17:59:02.703] iteration 19250: loss: 0.070483, loss_s1: 0.056481, loss_fp: 0.008818, loss_freq: 0.029987
[17:59:03.364] iteration 19251: loss: 0.055625, loss_s1: 0.047765, loss_fp: 0.002905, loss_freq: 0.027105
[17:59:04.023] iteration 19252: loss: 0.037214, loss_s1: 0.013644, loss_fp: 0.001056, loss_freq: 0.011916
[17:59:04.666] iteration 19253: loss: 0.048793, loss_s1: 0.024094, loss_fp: 0.003737, loss_freq: 0.017692
[17:59:05.291] iteration 19254: loss: 0.058992, loss_s1: 0.043121, loss_fp: 0.005855, loss_freq: 0.039130
[17:59:05.917] iteration 19255: loss: 0.040287, loss_s1: 0.028746, loss_fp: 0.003551, loss_freq: 0.017550
[17:59:06.544] iteration 19256: loss: 0.039131, loss_s1: 0.017346, loss_fp: 0.000531, loss_freq: 0.016756
[17:59:07.167] iteration 19257: loss: 0.045157, loss_s1: 0.025135, loss_fp: 0.001098, loss_freq: 0.021229
[17:59:07.805] iteration 19258: loss: 0.042321, loss_s1: 0.036481, loss_fp: 0.000716, loss_freq: 0.014677
[17:59:08.431] iteration 19259: loss: 0.033677, loss_s1: 0.019080, loss_fp: 0.002534, loss_freq: 0.009937
[17:59:09.057] iteration 19260: loss: 0.052781, loss_s1: 0.044278, loss_fp: 0.005647, loss_freq: 0.014471
[17:59:09.679] iteration 19261: loss: 0.062442, loss_s1: 0.024700, loss_fp: 0.001652, loss_freq: 0.054259
[17:59:10.314] iteration 19262: loss: 0.045219, loss_s1: 0.037666, loss_fp: 0.001689, loss_freq: 0.022282
[17:59:10.940] iteration 19263: loss: 0.072193, loss_s1: 0.053912, loss_fp: 0.015305, loss_freq: 0.040134
[17:59:11.569] iteration 19264: loss: 0.040271, loss_s1: 0.008434, loss_fp: 0.000616, loss_freq: 0.012387
[17:59:12.193] iteration 19265: loss: 0.050853, loss_s1: 0.041307, loss_fp: 0.002789, loss_freq: 0.022460
[17:59:12.818] iteration 19266: loss: 0.036295, loss_s1: 0.033859, loss_fp: 0.000643, loss_freq: 0.007967
[17:59:13.444] iteration 19267: loss: 0.103668, loss_s1: 0.082734, loss_fp: 0.013410, loss_freq: 0.075433
[17:59:14.068] iteration 19268: loss: 0.080047, loss_s1: 0.061352, loss_fp: 0.003595, loss_freq: 0.049939
[17:59:14.695] iteration 19269: loss: 0.052776, loss_s1: 0.048041, loss_fp: 0.002018, loss_freq: 0.016398
[17:59:15.322] iteration 19270: loss: 0.049893, loss_s1: 0.027147, loss_fp: 0.001237, loss_freq: 0.018991
[17:59:15.948] iteration 19271: loss: 0.045873, loss_s1: 0.025660, loss_fp: 0.009895, loss_freq: 0.023936
[17:59:16.573] iteration 19272: loss: 0.064767, loss_s1: 0.063613, loss_fp: 0.004568, loss_freq: 0.026371
[17:59:17.202] iteration 19273: loss: 0.062210, loss_s1: 0.049142, loss_fp: 0.001291, loss_freq: 0.011835
[17:59:17.830] iteration 19274: loss: 0.047394, loss_s1: 0.047296, loss_fp: 0.000951, loss_freq: 0.005790
[17:59:18.458] iteration 19275: loss: 0.089512, loss_s1: 0.097607, loss_fp: 0.010242, loss_freq: 0.036987
[17:59:19.083] iteration 19276: loss: 0.056344, loss_s1: 0.049314, loss_fp: 0.001521, loss_freq: 0.026372
[17:59:19.708] iteration 19277: loss: 0.037967, loss_s1: 0.011572, loss_fp: 0.003422, loss_freq: 0.004605
[17:59:20.332] iteration 19278: loss: 0.060775, loss_s1: 0.050030, loss_fp: 0.007720, loss_freq: 0.015606
[17:59:20.960] iteration 19279: loss: 0.096277, loss_s1: 0.071598, loss_fp: 0.017469, loss_freq: 0.074675
[17:59:21.584] iteration 19280: loss: 0.046585, loss_s1: 0.035847, loss_fp: 0.010947, loss_freq: 0.011412
[17:59:22.207] iteration 19281: loss: 0.054542, loss_s1: 0.050109, loss_fp: 0.003471, loss_freq: 0.017972
[17:59:22.831] iteration 19282: loss: 0.069147, loss_s1: 0.062414, loss_fp: 0.001610, loss_freq: 0.018019
[17:59:23.454] iteration 19283: loss: 0.057794, loss_s1: 0.037984, loss_fp: 0.009186, loss_freq: 0.029504
[17:59:24.079] iteration 19284: loss: 0.061557, loss_s1: 0.057540, loss_fp: 0.005392, loss_freq: 0.025436
[17:59:24.707] iteration 19285: loss: 0.050142, loss_s1: 0.029281, loss_fp: 0.001559, loss_freq: 0.022478
[17:59:25.335] iteration 19286: loss: 0.052805, loss_s1: 0.039291, loss_fp: 0.001325, loss_freq: 0.014869
[17:59:25.964] iteration 19287: loss: 0.086077, loss_s1: 0.026567, loss_fp: 0.011513, loss_freq: 0.078165
[17:59:26.590] iteration 19288: loss: 0.058932, loss_s1: 0.057977, loss_fp: 0.006016, loss_freq: 0.022517
[17:59:27.216] iteration 19289: loss: 0.070713, loss_s1: 0.074324, loss_fp: 0.006532, loss_freq: 0.018101
[17:59:27.845] iteration 19290: loss: 0.075239, loss_s1: 0.041362, loss_fp: 0.007098, loss_freq: 0.071659
[17:59:28.468] iteration 19291: loss: 0.079471, loss_s1: 0.087982, loss_fp: 0.001276, loss_freq: 0.037324
[17:59:29.095] iteration 19292: loss: 0.057735, loss_s1: 0.056824, loss_fp: 0.006516, loss_freq: 0.014540
[17:59:29.725] iteration 19293: loss: 0.042817, loss_s1: 0.033220, loss_fp: 0.001291, loss_freq: 0.015121
[17:59:30.352] iteration 19294: loss: 0.051297, loss_s1: 0.039223, loss_fp: 0.002547, loss_freq: 0.026158
[17:59:30.976] iteration 19295: loss: 0.056340, loss_s1: 0.040657, loss_fp: 0.002852, loss_freq: 0.027090
[17:59:31.638] iteration 19296: loss: 0.044300, loss_s1: 0.031237, loss_fp: 0.004129, loss_freq: 0.012571
[17:59:32.258] iteration 19297: loss: 0.050568, loss_s1: 0.046538, loss_fp: 0.002991, loss_freq: 0.023984
[17:59:32.880] iteration 19298: loss: 0.059319, loss_s1: 0.039101, loss_fp: 0.001685, loss_freq: 0.036119
[17:59:33.501] iteration 19299: loss: 0.059968, loss_s1: 0.041297, loss_fp: 0.006205, loss_freq: 0.027051
[17:59:34.164] iteration 19300: loss: 0.073201, loss_s1: 0.062494, loss_fp: 0.007795, loss_freq: 0.047416
[17:59:34.786] iteration 19301: loss: 0.060811, loss_s1: 0.057059, loss_fp: 0.007948, loss_freq: 0.019308
[17:59:35.410] iteration 19302: loss: 0.040039, loss_s1: 0.023805, loss_fp: 0.003177, loss_freq: 0.011354
[17:59:36.040] iteration 19303: loss: 0.065848, loss_s1: 0.032891, loss_fp: 0.016254, loss_freq: 0.025037
[17:59:36.659] iteration 19304: loss: 0.044623, loss_s1: 0.027820, loss_fp: 0.003607, loss_freq: 0.017006
[17:59:37.295] iteration 19305: loss: 0.050324, loss_s1: 0.023313, loss_fp: 0.009243, loss_freq: 0.019573
[17:59:37.924] iteration 19306: loss: 0.073725, loss_s1: 0.047162, loss_fp: 0.009107, loss_freq: 0.063727
[17:59:38.548] iteration 19307: loss: 0.035441, loss_s1: 0.021416, loss_fp: 0.003979, loss_freq: 0.009476
[17:59:39.176] iteration 19308: loss: 0.041347, loss_s1: 0.033753, loss_fp: 0.000914, loss_freq: 0.015104
[17:59:39.802] iteration 19309: loss: 0.093811, loss_s1: 0.064379, loss_fp: 0.005144, loss_freq: 0.068117
[17:59:40.432] iteration 19310: loss: 0.061650, loss_s1: 0.030148, loss_fp: 0.004661, loss_freq: 0.019050
[17:59:41.054] iteration 19311: loss: 0.128032, loss_s1: 0.129190, loss_fp: 0.004494, loss_freq: 0.071010
[17:59:41.682] iteration 19312: loss: 0.050907, loss_s1: 0.052596, loss_fp: 0.002330, loss_freq: 0.019316
[17:59:42.342] iteration 19313: loss: 0.080817, loss_s1: 0.066436, loss_fp: 0.005767, loss_freq: 0.040908
[17:59:43.002] iteration 19314: loss: 0.028957, loss_s1: 0.009052, loss_fp: 0.000763, loss_freq: 0.010849
[17:59:43.660] iteration 19315: loss: 0.047299, loss_s1: 0.044946, loss_fp: 0.000813, loss_freq: 0.011705
[17:59:44.283] iteration 19316: loss: 0.046790, loss_s1: 0.013296, loss_fp: 0.002193, loss_freq: 0.018976
[17:59:44.908] iteration 19317: loss: 0.062374, loss_s1: 0.033322, loss_fp: 0.004973, loss_freq: 0.029383
[17:59:45.536] iteration 19318: loss: 0.079387, loss_s1: 0.073416, loss_fp: 0.003840, loss_freq: 0.034810
[17:59:46.159] iteration 19319: loss: 0.058804, loss_s1: 0.054194, loss_fp: 0.002067, loss_freq: 0.024776
[17:59:46.777] iteration 19320: loss: 0.055642, loss_s1: 0.050413, loss_fp: 0.002749, loss_freq: 0.021683
[17:59:47.744] iteration 19321: loss: 0.048199, loss_s1: 0.034937, loss_fp: 0.002247, loss_freq: 0.011717
[17:59:48.388] iteration 19322: loss: 0.060244, loss_s1: 0.041304, loss_fp: 0.008218, loss_freq: 0.026917
[17:59:49.039] iteration 19323: loss: 0.043768, loss_s1: 0.030128, loss_fp: 0.001314, loss_freq: 0.013321
[17:59:49.681] iteration 19324: loss: 0.056521, loss_s1: 0.048104, loss_fp: 0.000860, loss_freq: 0.022652
[17:59:50.306] iteration 19325: loss: 0.056967, loss_s1: 0.050482, loss_fp: 0.008216, loss_freq: 0.012123
[17:59:50.930] iteration 19326: loss: 0.090334, loss_s1: 0.053611, loss_fp: 0.002317, loss_freq: 0.053101
[17:59:51.554] iteration 19327: loss: 0.053635, loss_s1: 0.035693, loss_fp: 0.004732, loss_freq: 0.028357
[17:59:52.180] iteration 19328: loss: 0.034387, loss_s1: 0.027241, loss_fp: 0.002730, loss_freq: 0.009492
[17:59:52.807] iteration 19329: loss: 0.063279, loss_s1: 0.023828, loss_fp: 0.010848, loss_freq: 0.060876
[17:59:53.466] iteration 19330: loss: 0.068385, loss_s1: 0.063636, loss_fp: 0.011427, loss_freq: 0.026007
[17:59:54.116] iteration 19331: loss: 0.045973, loss_s1: 0.036011, loss_fp: 0.000276, loss_freq: 0.012458
[17:59:54.740] iteration 19332: loss: 0.094123, loss_s1: 0.078408, loss_fp: 0.004693, loss_freq: 0.063813
[17:59:55.371] iteration 19333: loss: 0.075137, loss_s1: 0.064912, loss_fp: 0.009748, loss_freq: 0.042242
[17:59:56.000] iteration 19334: loss: 0.082191, loss_s1: 0.075198, loss_fp: 0.004787, loss_freq: 0.049275
[17:59:56.628] iteration 19335: loss: 0.039004, loss_s1: 0.029645, loss_fp: 0.002803, loss_freq: 0.015711
[17:59:57.273] iteration 19336: loss: 0.084180, loss_s1: 0.095250, loss_fp: 0.001538, loss_freq: 0.027941
[17:59:57.901] iteration 19337: loss: 0.036519, loss_s1: 0.029720, loss_fp: 0.000842, loss_freq: 0.007202
[17:59:58.525] iteration 19338: loss: 0.094880, loss_s1: 0.095285, loss_fp: 0.015843, loss_freq: 0.043091
[17:59:59.151] iteration 19339: loss: 0.038402, loss_s1: 0.013212, loss_fp: 0.003170, loss_freq: 0.018708
[17:59:59.912] iteration 19340: loss: 0.069737, loss_s1: 0.049802, loss_fp: 0.003342, loss_freq: 0.010137
[18:00:00.628] iteration 19341: loss: 0.053140, loss_s1: 0.038157, loss_fp: 0.010617, loss_freq: 0.015012
[18:00:01.345] iteration 19342: loss: 0.046542, loss_s1: 0.034827, loss_fp: 0.001206, loss_freq: 0.014633
[18:00:02.009] iteration 19343: loss: 0.045831, loss_s1: 0.012019, loss_fp: 0.006951, loss_freq: 0.024229
[18:00:02.657] iteration 19344: loss: 0.109534, loss_s1: 0.061351, loss_fp: 0.022958, loss_freq: 0.099917
[18:00:03.281] iteration 19345: loss: 0.055906, loss_s1: 0.059288, loss_fp: 0.001813, loss_freq: 0.013600
[18:00:03.902] iteration 19346: loss: 0.053634, loss_s1: 0.048626, loss_fp: 0.002309, loss_freq: 0.009116
[18:00:04.526] iteration 19347: loss: 0.029126, loss_s1: 0.012400, loss_fp: 0.004768, loss_freq: 0.004208
[18:00:05.151] iteration 19348: loss: 0.074797, loss_s1: 0.053932, loss_fp: 0.011444, loss_freq: 0.041822
[18:00:05.776] iteration 19349: loss: 0.050886, loss_s1: 0.039772, loss_fp: 0.004555, loss_freq: 0.024324
[18:00:06.400] iteration 19350: loss: 0.045763, loss_s1: 0.042541, loss_fp: 0.004297, loss_freq: 0.012686
[18:00:07.025] iteration 19351: loss: 0.045730, loss_s1: 0.031254, loss_fp: 0.008548, loss_freq: 0.017545
[18:00:07.648] iteration 19352: loss: 0.045742, loss_s1: 0.026005, loss_fp: 0.001508, loss_freq: 0.015082
[18:00:08.271] iteration 19353: loss: 0.037124, loss_s1: 0.026284, loss_fp: 0.001841, loss_freq: 0.012006
[18:00:08.896] iteration 19354: loss: 0.033306, loss_s1: 0.029554, loss_fp: 0.001819, loss_freq: 0.005282
[18:00:09.525] iteration 19355: loss: 0.058256, loss_s1: 0.034368, loss_fp: 0.001212, loss_freq: 0.035130
[18:00:10.147] iteration 19356: loss: 0.067506, loss_s1: 0.069808, loss_fp: 0.006058, loss_freq: 0.031098
[18:00:10.768] iteration 19357: loss: 0.080102, loss_s1: 0.093054, loss_fp: 0.002024, loss_freq: 0.024501
[18:00:11.393] iteration 19358: loss: 0.080572, loss_s1: 0.112485, loss_fp: 0.002972, loss_freq: 0.010680
[18:00:12.015] iteration 19359: loss: 0.092651, loss_s1: 0.092463, loss_fp: 0.002890, loss_freq: 0.052147
[18:00:12.637] iteration 19360: loss: 0.069857, loss_s1: 0.064158, loss_fp: 0.001416, loss_freq: 0.040340
[18:00:13.261] iteration 19361: loss: 0.051058, loss_s1: 0.048540, loss_fp: 0.000770, loss_freq: 0.013555
[18:00:13.883] iteration 19362: loss: 0.074282, loss_s1: 0.065765, loss_fp: 0.004945, loss_freq: 0.048831
[18:00:14.507] iteration 19363: loss: 0.073460, loss_s1: 0.064752, loss_fp: 0.005635, loss_freq: 0.035559
[18:00:15.127] iteration 19364: loss: 0.053992, loss_s1: 0.039194, loss_fp: 0.006862, loss_freq: 0.035368
[18:00:15.751] iteration 19365: loss: 0.050668, loss_s1: 0.029306, loss_fp: 0.008010, loss_freq: 0.015045
[18:00:16.379] iteration 19366: loss: 0.050943, loss_s1: 0.035496, loss_fp: 0.000733, loss_freq: 0.010332
[18:00:17.003] iteration 19367: loss: 0.035484, loss_s1: 0.022641, loss_fp: 0.004574, loss_freq: 0.008677
[18:00:17.628] iteration 19368: loss: 0.059395, loss_s1: 0.064505, loss_fp: 0.002034, loss_freq: 0.014775
[18:00:18.252] iteration 19369: loss: 0.053804, loss_s1: 0.056457, loss_fp: 0.003228, loss_freq: 0.009650
[18:00:18.875] iteration 19370: loss: 0.088245, loss_s1: 0.076998, loss_fp: 0.005892, loss_freq: 0.066149
[18:00:19.503] iteration 19371: loss: 0.057897, loss_s1: 0.023041, loss_fp: 0.013213, loss_freq: 0.049433
[18:00:20.125] iteration 19372: loss: 0.059619, loss_s1: 0.038942, loss_fp: 0.001573, loss_freq: 0.029439
[18:00:20.749] iteration 19373: loss: 0.036602, loss_s1: 0.014655, loss_fp: 0.002792, loss_freq: 0.014868
[18:00:21.397] iteration 19374: loss: 0.072471, loss_s1: 0.039229, loss_fp: 0.003572, loss_freq: 0.068963
[18:00:22.049] iteration 19375: loss: 0.064326, loss_s1: 0.079626, loss_fp: 0.002409, loss_freq: 0.006190
[18:00:22.697] iteration 19376: loss: 0.076098, loss_s1: 0.076516, loss_fp: 0.002029, loss_freq: 0.024832
[18:00:23.323] iteration 19377: loss: 0.037006, loss_s1: 0.025701, loss_fp: 0.003206, loss_freq: 0.010313
[18:00:23.955] iteration 19378: loss: 0.059413, loss_s1: 0.037072, loss_fp: 0.005808, loss_freq: 0.024000
[18:00:24.580] iteration 19379: loss: 0.049161, loss_s1: 0.044824, loss_fp: 0.002476, loss_freq: 0.008358
[18:00:25.202] iteration 19380: loss: 0.045856, loss_s1: 0.021189, loss_fp: 0.003634, loss_freq: 0.029167
[18:00:25.825] iteration 19381: loss: 0.031939, loss_s1: 0.015790, loss_fp: 0.002736, loss_freq: 0.016297
[18:00:26.447] iteration 19382: loss: 0.038854, loss_s1: 0.019957, loss_fp: 0.009493, loss_freq: 0.014545
[18:00:27.068] iteration 19383: loss: 0.056907, loss_s1: 0.040164, loss_fp: 0.001098, loss_freq: 0.023218
[18:00:27.695] iteration 19384: loss: 0.052163, loss_s1: 0.020797, loss_fp: 0.011659, loss_freq: 0.033615
[18:00:28.325] iteration 19385: loss: 0.041127, loss_s1: 0.026116, loss_fp: 0.002366, loss_freq: 0.012011
[18:00:28.951] iteration 19386: loss: 0.074777, loss_s1: 0.037040, loss_fp: 0.014968, loss_freq: 0.067460
[18:00:29.576] iteration 19387: loss: 0.067282, loss_s1: 0.054338, loss_fp: 0.001469, loss_freq: 0.038999
[18:00:30.197] iteration 19388: loss: 0.075882, loss_s1: 0.061815, loss_fp: 0.002249, loss_freq: 0.033241
[18:00:30.824] iteration 19389: loss: 0.037076, loss_s1: 0.033002, loss_fp: 0.001693, loss_freq: 0.008182
[18:00:31.477] iteration 19390: loss: 0.049082, loss_s1: 0.027052, loss_fp: 0.001054, loss_freq: 0.015247
[18:00:32.135] iteration 19391: loss: 0.078852, loss_s1: 0.049353, loss_fp: 0.005129, loss_freq: 0.033377
[18:00:32.788] iteration 19392: loss: 0.056329, loss_s1: 0.030414, loss_fp: 0.001604, loss_freq: 0.025785
[18:00:33.413] iteration 19393: loss: 0.056903, loss_s1: 0.035096, loss_fp: 0.005901, loss_freq: 0.031372
[18:00:34.038] iteration 19394: loss: 0.037790, loss_s1: 0.024640, loss_fp: 0.002132, loss_freq: 0.009106
[18:00:34.665] iteration 19395: loss: 0.051583, loss_s1: 0.042642, loss_fp: 0.006060, loss_freq: 0.021933
[18:00:35.291] iteration 19396: loss: 0.076835, loss_s1: 0.054760, loss_fp: 0.001669, loss_freq: 0.052170
[18:00:35.916] iteration 19397: loss: 0.088014, loss_s1: 0.064039, loss_fp: 0.008534, loss_freq: 0.055631
[18:00:36.542] iteration 19398: loss: 0.035521, loss_s1: 0.028323, loss_fp: 0.003771, loss_freq: 0.010168
[18:00:37.173] iteration 19399: loss: 0.039143, loss_s1: 0.034790, loss_fp: 0.000221, loss_freq: 0.005625
[18:00:37.800] iteration 19400: loss: 0.085787, loss_s1: 0.065674, loss_fp: 0.011343, loss_freq: 0.047309
[18:00:40.980] iteration 19400 : mean_dice : 0.724225
[18:00:41.634] iteration 19401: loss: 0.094836, loss_s1: 0.085513, loss_fp: 0.001974, loss_freq: 0.039651
[18:00:42.259] iteration 19402: loss: 0.068529, loss_s1: 0.065877, loss_fp: 0.003613, loss_freq: 0.038747
[18:00:42.902] iteration 19403: loss: 0.109315, loss_s1: 0.063719, loss_fp: 0.014312, loss_freq: 0.109642
[18:00:43.546] iteration 19404: loss: 0.042303, loss_s1: 0.028365, loss_fp: 0.003245, loss_freq: 0.011161
[18:00:44.182] iteration 19405: loss: 0.043090, loss_s1: 0.037863, loss_fp: 0.003414, loss_freq: 0.015402
[18:00:44.823] iteration 19406: loss: 0.065714, loss_s1: 0.080438, loss_fp: 0.000985, loss_freq: 0.017127
[18:00:45.470] iteration 19407: loss: 0.082441, loss_s1: 0.022081, loss_fp: 0.009883, loss_freq: 0.024568
[18:00:46.109] iteration 19408: loss: 0.034363, loss_s1: 0.023438, loss_fp: 0.000749, loss_freq: 0.009393
[18:00:46.743] iteration 19409: loss: 0.038499, loss_s1: 0.017235, loss_fp: 0.003543, loss_freq: 0.016934
[18:00:47.386] iteration 19410: loss: 0.064143, loss_s1: 0.045307, loss_fp: 0.001787, loss_freq: 0.046856
[18:00:48.027] iteration 19411: loss: 0.065118, loss_s1: 0.061620, loss_fp: 0.005853, loss_freq: 0.023593
[18:00:48.667] iteration 19412: loss: 0.056735, loss_s1: 0.024108, loss_fp: 0.005368, loss_freq: 0.037559
[18:00:49.307] iteration 19413: loss: 0.057449, loss_s1: 0.027929, loss_fp: 0.001496, loss_freq: 0.025742
[18:00:49.946] iteration 19414: loss: 0.066425, loss_s1: 0.080215, loss_fp: 0.003784, loss_freq: 0.009839
[18:00:50.586] iteration 19415: loss: 0.063697, loss_s1: 0.049742, loss_fp: 0.003716, loss_freq: 0.019943
[18:00:51.230] iteration 19416: loss: 0.064864, loss_s1: 0.055335, loss_fp: 0.004002, loss_freq: 0.018939
[18:00:51.870] iteration 19417: loss: 0.039770, loss_s1: 0.020809, loss_fp: 0.005541, loss_freq: 0.018466
[18:00:52.514] iteration 19418: loss: 0.058002, loss_s1: 0.016364, loss_fp: 0.001361, loss_freq: 0.036251
[18:00:53.168] iteration 19419: loss: 0.083719, loss_s1: 0.035584, loss_fp: 0.002367, loss_freq: 0.039579
[18:00:53.794] iteration 19420: loss: 0.056232, loss_s1: 0.047468, loss_fp: 0.006956, loss_freq: 0.023848
[18:00:54.417] iteration 19421: loss: 0.077875, loss_s1: 0.081073, loss_fp: 0.004898, loss_freq: 0.023879
[18:00:55.040] iteration 19422: loss: 0.100969, loss_s1: 0.055381, loss_fp: 0.003971, loss_freq: 0.090789
[18:00:55.661] iteration 19423: loss: 0.098252, loss_s1: 0.083676, loss_fp: 0.007466, loss_freq: 0.056265
[18:00:56.283] iteration 19424: loss: 0.038812, loss_s1: 0.025133, loss_fp: 0.003307, loss_freq: 0.013426
[18:00:56.908] iteration 19425: loss: 0.041087, loss_s1: 0.018255, loss_fp: 0.003972, loss_freq: 0.011038
[18:00:57.536] iteration 19426: loss: 0.051868, loss_s1: 0.028458, loss_fp: 0.003473, loss_freq: 0.040552
[18:00:58.157] iteration 19427: loss: 0.071646, loss_s1: 0.025182, loss_fp: 0.004466, loss_freq: 0.011084
[18:00:58.829] iteration 19428: loss: 0.128049, loss_s1: 0.163259, loss_fp: 0.003585, loss_freq: 0.046687
[18:00:59.494] iteration 19429: loss: 0.154237, loss_s1: 0.127293, loss_fp: 0.010583, loss_freq: 0.116881
[18:01:00.159] iteration 19430: loss: 0.053866, loss_s1: 0.038091, loss_fp: 0.003477, loss_freq: 0.034574
[18:01:00.808] iteration 19431: loss: 0.045927, loss_s1: 0.030581, loss_fp: 0.004530, loss_freq: 0.011255
[18:01:01.434] iteration 19432: loss: 0.075538, loss_s1: 0.080578, loss_fp: 0.004041, loss_freq: 0.029260
[18:01:02.064] iteration 19433: loss: 0.112539, loss_s1: 0.153127, loss_fp: 0.001548, loss_freq: 0.044351
[18:01:02.696] iteration 19434: loss: 0.078794, loss_s1: 0.070252, loss_fp: 0.002634, loss_freq: 0.036805
[18:01:03.325] iteration 19435: loss: 0.067734, loss_s1: 0.073283, loss_fp: 0.003988, loss_freq: 0.012513
[18:01:03.950] iteration 19436: loss: 0.098364, loss_s1: 0.111197, loss_fp: 0.002814, loss_freq: 0.043270
[18:01:04.577] iteration 19437: loss: 0.047412, loss_s1: 0.035081, loss_fp: 0.002071, loss_freq: 0.029170
[18:01:05.203] iteration 19438: loss: 0.038217, loss_s1: 0.015172, loss_fp: 0.005528, loss_freq: 0.024256
[18:01:05.833] iteration 19439: loss: 0.073026, loss_s1: 0.039769, loss_fp: 0.002201, loss_freq: 0.053467
[18:01:06.456] iteration 19440: loss: 0.094385, loss_s1: 0.069680, loss_fp: 0.004107, loss_freq: 0.073990
[18:01:07.081] iteration 19441: loss: 0.034125, loss_s1: 0.009547, loss_fp: 0.004814, loss_freq: 0.020084
[18:01:07.705] iteration 19442: loss: 0.083602, loss_s1: 0.073308, loss_fp: 0.000897, loss_freq: 0.015842
[18:01:08.331] iteration 19443: loss: 0.038936, loss_s1: 0.025910, loss_fp: 0.001425, loss_freq: 0.007632
[18:01:08.987] iteration 19444: loss: 0.081844, loss_s1: 0.105006, loss_fp: 0.013053, loss_freq: 0.008709
[18:01:09.643] iteration 19445: loss: 0.054254, loss_s1: 0.030257, loss_fp: 0.003846, loss_freq: 0.016532
[18:01:10.301] iteration 19446: loss: 0.061577, loss_s1: 0.059608, loss_fp: 0.001690, loss_freq: 0.016481
[18:01:10.957] iteration 19447: loss: 0.048301, loss_s1: 0.032503, loss_fp: 0.003800, loss_freq: 0.007052
[18:01:11.646] iteration 19448: loss: 0.046911, loss_s1: 0.013718, loss_fp: 0.000991, loss_freq: 0.032007
[18:01:12.305] iteration 19449: loss: 0.053921, loss_s1: 0.026620, loss_fp: 0.011113, loss_freq: 0.032744
[18:01:12.962] iteration 19450: loss: 0.047924, loss_s1: 0.043700, loss_fp: 0.002332, loss_freq: 0.011572
[18:01:13.619] iteration 19451: loss: 0.099180, loss_s1: 0.075866, loss_fp: 0.005191, loss_freq: 0.086819
[18:01:14.275] iteration 19452: loss: 0.044563, loss_s1: 0.029940, loss_fp: 0.001990, loss_freq: 0.024444
[18:01:14.897] iteration 19453: loss: 0.037334, loss_s1: 0.027056, loss_fp: 0.003460, loss_freq: 0.008049
[18:01:15.519] iteration 19454: loss: 0.063846, loss_s1: 0.081035, loss_fp: 0.002121, loss_freq: 0.014486
[18:01:16.144] iteration 19455: loss: 0.065634, loss_s1: 0.069917, loss_fp: 0.006511, loss_freq: 0.022231
[18:01:16.768] iteration 19456: loss: 0.078554, loss_s1: 0.071955, loss_fp: 0.005378, loss_freq: 0.043186
[18:01:17.397] iteration 19457: loss: 0.038458, loss_s1: 0.020231, loss_fp: 0.000813, loss_freq: 0.005857
[18:01:18.021] iteration 19458: loss: 0.040298, loss_s1: 0.021471, loss_fp: 0.007766, loss_freq: 0.012167
[18:01:18.645] iteration 19459: loss: 0.050201, loss_s1: 0.035919, loss_fp: 0.002467, loss_freq: 0.011349
[18:01:19.306] iteration 19460: loss: 0.083698, loss_s1: 0.050132, loss_fp: 0.002846, loss_freq: 0.047588
[18:01:19.946] iteration 19461: loss: 0.044545, loss_s1: 0.024243, loss_fp: 0.005028, loss_freq: 0.026415
[18:01:20.604] iteration 19462: loss: 0.054231, loss_s1: 0.032305, loss_fp: 0.005369, loss_freq: 0.028663
[18:01:21.271] iteration 19463: loss: 0.051906, loss_s1: 0.033018, loss_fp: 0.000736, loss_freq: 0.027007
[18:01:21.929] iteration 19464: loss: 0.070922, loss_s1: 0.056983, loss_fp: 0.004046, loss_freq: 0.034520
[18:01:22.568] iteration 19465: loss: 0.050186, loss_s1: 0.054896, loss_fp: 0.001253, loss_freq: 0.011716
[18:01:23.196] iteration 19466: loss: 0.071095, loss_s1: 0.055692, loss_fp: 0.001898, loss_freq: 0.035388
[18:01:23.823] iteration 19467: loss: 0.091016, loss_s1: 0.081213, loss_fp: 0.007079, loss_freq: 0.060176
[18:01:24.453] iteration 19468: loss: 0.026865, loss_s1: 0.014726, loss_fp: 0.000376, loss_freq: 0.005351
[18:01:25.079] iteration 19469: loss: 0.046631, loss_s1: 0.038341, loss_fp: 0.003076, loss_freq: 0.016872
[18:01:25.704] iteration 19470: loss: 0.067021, loss_s1: 0.043337, loss_fp: 0.004332, loss_freq: 0.042263
[18:01:26.329] iteration 19471: loss: 0.065194, loss_s1: 0.054709, loss_fp: 0.004750, loss_freq: 0.021605
[18:01:26.955] iteration 19472: loss: 0.108159, loss_s1: 0.109470, loss_fp: 0.016553, loss_freq: 0.056833
[18:01:27.579] iteration 19473: loss: 0.049390, loss_s1: 0.041740, loss_fp: 0.004111, loss_freq: 0.025767
[18:01:28.203] iteration 19474: loss: 0.063731, loss_s1: 0.036375, loss_fp: 0.001801, loss_freq: 0.025953
[18:01:28.827] iteration 19475: loss: 0.040010, loss_s1: 0.020998, loss_fp: 0.000731, loss_freq: 0.031424
[18:01:29.450] iteration 19476: loss: 0.047639, loss_s1: 0.020724, loss_fp: 0.001942, loss_freq: 0.024814
[18:01:30.073] iteration 19477: loss: 0.050323, loss_s1: 0.036792, loss_fp: 0.000475, loss_freq: 0.015758
[18:01:30.704] iteration 19478: loss: 0.044615, loss_s1: 0.023074, loss_fp: 0.005082, loss_freq: 0.020795
[18:01:31.329] iteration 19479: loss: 0.079940, loss_s1: 0.078514, loss_fp: 0.006797, loss_freq: 0.039827
[18:01:31.951] iteration 19480: loss: 0.082647, loss_s1: 0.079473, loss_fp: 0.001701, loss_freq: 0.023577
[18:01:32.571] iteration 19481: loss: 0.065880, loss_s1: 0.044267, loss_fp: 0.001684, loss_freq: 0.034868
[18:01:33.595] iteration 19482: loss: 0.047668, loss_s1: 0.014364, loss_fp: 0.001234, loss_freq: 0.027063
[18:01:34.256] iteration 19483: loss: 0.082504, loss_s1: 0.089195, loss_fp: 0.003498, loss_freq: 0.028845
[18:01:34.918] iteration 19484: loss: 0.053324, loss_s1: 0.052372, loss_fp: 0.001380, loss_freq: 0.009968
[18:01:35.608] iteration 19485: loss: 0.042911, loss_s1: 0.018873, loss_fp: 0.002769, loss_freq: 0.020478
[18:01:36.244] iteration 19486: loss: 0.055474, loss_s1: 0.047449, loss_fp: 0.006019, loss_freq: 0.020147
[18:01:36.871] iteration 19487: loss: 0.102951, loss_s1: 0.048710, loss_fp: 0.002884, loss_freq: 0.078835
[18:01:37.496] iteration 19488: loss: 0.041537, loss_s1: 0.037994, loss_fp: 0.003039, loss_freq: 0.009176
[18:01:38.119] iteration 19489: loss: 0.031443, loss_s1: 0.020375, loss_fp: 0.002792, loss_freq: 0.007131
[18:01:38.744] iteration 19490: loss: 0.054726, loss_s1: 0.064512, loss_fp: 0.004845, loss_freq: 0.013516
[18:01:39.370] iteration 19491: loss: 0.047585, loss_s1: 0.023221, loss_fp: 0.005052, loss_freq: 0.022103
[18:01:40.029] iteration 19492: loss: 0.052348, loss_s1: 0.015078, loss_fp: 0.000598, loss_freq: 0.003737
[18:01:40.706] iteration 19493: loss: 0.063865, loss_s1: 0.063285, loss_fp: 0.001412, loss_freq: 0.026611
[18:01:41.373] iteration 19494: loss: 0.063735, loss_s1: 0.045530, loss_fp: 0.007739, loss_freq: 0.047923
[18:01:42.031] iteration 19495: loss: 0.065016, loss_s1: 0.052068, loss_fp: 0.005806, loss_freq: 0.036517
[18:01:42.693] iteration 19496: loss: 0.056545, loss_s1: 0.052770, loss_fp: 0.001733, loss_freq: 0.025662
[18:01:43.331] iteration 19497: loss: 0.048448, loss_s1: 0.038099, loss_fp: 0.001653, loss_freq: 0.020870
[18:01:43.952] iteration 19498: loss: 0.046443, loss_s1: 0.039537, loss_fp: 0.001790, loss_freq: 0.007139
[18:01:44.575] iteration 19499: loss: 0.049853, loss_s1: 0.019363, loss_fp: 0.007020, loss_freq: 0.035108
[18:01:45.202] iteration 19500: loss: 0.042831, loss_s1: 0.023174, loss_fp: 0.001313, loss_freq: 0.019599
[18:01:45.833] iteration 19501: loss: 0.043690, loss_s1: 0.032926, loss_fp: 0.001903, loss_freq: 0.015003
[18:01:46.463] iteration 19502: loss: 0.036816, loss_s1: 0.011382, loss_fp: 0.000603, loss_freq: 0.007734
[18:01:47.127] iteration 19503: loss: 0.034807, loss_s1: 0.012323, loss_fp: 0.000678, loss_freq: 0.011958
[18:01:47.794] iteration 19504: loss: 0.063444, loss_s1: 0.023406, loss_fp: 0.001851, loss_freq: 0.042261
[18:01:48.423] iteration 19505: loss: 0.041534, loss_s1: 0.025963, loss_fp: 0.000758, loss_freq: 0.022356
[18:01:49.053] iteration 19506: loss: 0.034933, loss_s1: 0.013250, loss_fp: 0.001382, loss_freq: 0.018166
[18:01:49.683] iteration 19507: loss: 0.055331, loss_s1: 0.050104, loss_fp: 0.007121, loss_freq: 0.027364
[18:01:50.316] iteration 19508: loss: 0.033235, loss_s1: 0.030204, loss_fp: 0.000240, loss_freq: 0.002525
[18:01:50.942] iteration 19509: loss: 0.061972, loss_s1: 0.032115, loss_fp: 0.009859, loss_freq: 0.029824
[18:01:51.573] iteration 19510: loss: 0.074473, loss_s1: 0.058716, loss_fp: 0.009320, loss_freq: 0.042432
[18:01:52.203] iteration 19511: loss: 0.035942, loss_s1: 0.025234, loss_fp: 0.000879, loss_freq: 0.005237
[18:01:52.829] iteration 19512: loss: 0.053207, loss_s1: 0.046170, loss_fp: 0.004912, loss_freq: 0.024249
[18:01:53.458] iteration 19513: loss: 0.069548, loss_s1: 0.040971, loss_fp: 0.002673, loss_freq: 0.040433
[18:01:54.084] iteration 19514: loss: 0.077466, loss_s1: 0.069207, loss_fp: 0.003798, loss_freq: 0.047942
[18:01:54.709] iteration 19515: loss: 0.035536, loss_s1: 0.025283, loss_fp: 0.002445, loss_freq: 0.014396
[18:01:55.338] iteration 19516: loss: 0.078271, loss_s1: 0.063847, loss_fp: 0.002764, loss_freq: 0.044105
[18:01:55.961] iteration 19517: loss: 0.057596, loss_s1: 0.049705, loss_fp: 0.004926, loss_freq: 0.031045
[18:01:56.588] iteration 19518: loss: 0.067869, loss_s1: 0.070601, loss_fp: 0.005808, loss_freq: 0.019562
[18:01:57.217] iteration 19519: loss: 0.058088, loss_s1: 0.040536, loss_fp: 0.007977, loss_freq: 0.028007
[18:01:57.842] iteration 19520: loss: 0.081941, loss_s1: 0.077339, loss_fp: 0.008866, loss_freq: 0.031268
[18:01:58.495] iteration 19521: loss: 0.100525, loss_s1: 0.136111, loss_fp: 0.004708, loss_freq: 0.025279
[18:01:59.161] iteration 19522: loss: 0.052958, loss_s1: 0.018377, loss_fp: 0.001077, loss_freq: 0.033443
[18:01:59.826] iteration 19523: loss: 0.129336, loss_s1: 0.128819, loss_fp: 0.003848, loss_freq: 0.098604
[18:02:00.488] iteration 19524: loss: 0.058693, loss_s1: 0.026487, loss_fp: 0.002520, loss_freq: 0.055765
[18:02:01.147] iteration 19525: loss: 0.043480, loss_s1: 0.020309, loss_fp: 0.003523, loss_freq: 0.033480
[18:02:01.775] iteration 19526: loss: 0.043249, loss_s1: 0.026030, loss_fp: 0.001038, loss_freq: 0.022878
[18:02:02.404] iteration 19527: loss: 0.056271, loss_s1: 0.049638, loss_fp: 0.004484, loss_freq: 0.008074
[18:02:03.030] iteration 19528: loss: 0.041337, loss_s1: 0.020324, loss_fp: 0.001101, loss_freq: 0.026990
[18:02:03.660] iteration 19529: loss: 0.048837, loss_s1: 0.031166, loss_fp: 0.002156, loss_freq: 0.036996
[18:02:04.290] iteration 19530: loss: 0.119431, loss_s1: 0.101493, loss_fp: 0.002561, loss_freq: 0.046413
[18:02:04.964] iteration 19531: loss: 0.073891, loss_s1: 0.058590, loss_fp: 0.001401, loss_freq: 0.045057
[18:02:05.598] iteration 19532: loss: 0.062732, loss_s1: 0.053545, loss_fp: 0.000951, loss_freq: 0.040940
[18:02:06.229] iteration 19533: loss: 0.077402, loss_s1: 0.038891, loss_fp: 0.001394, loss_freq: 0.036789
[18:02:06.864] iteration 19534: loss: 0.046661, loss_s1: 0.027894, loss_fp: 0.004075, loss_freq: 0.033181
[18:02:07.490] iteration 19535: loss: 0.073835, loss_s1: 0.043599, loss_fp: 0.005294, loss_freq: 0.065471
[18:02:08.116] iteration 19536: loss: 0.031069, loss_s1: 0.015287, loss_fp: 0.001965, loss_freq: 0.010019
[18:02:08.740] iteration 19537: loss: 0.083120, loss_s1: 0.074558, loss_fp: 0.008605, loss_freq: 0.033210
[18:02:09.362] iteration 19538: loss: 0.046755, loss_s1: 0.045463, loss_fp: 0.000891, loss_freq: 0.005663
[18:02:09.989] iteration 19539: loss: 0.055135, loss_s1: 0.048692, loss_fp: 0.000864, loss_freq: 0.012688
[18:02:10.614] iteration 19540: loss: 0.044633, loss_s1: 0.035303, loss_fp: 0.005117, loss_freq: 0.014859
[18:02:11.240] iteration 19541: loss: 0.037728, loss_s1: 0.016215, loss_fp: 0.001671, loss_freq: 0.030229
[18:02:11.865] iteration 19542: loss: 0.046322, loss_s1: 0.041763, loss_fp: 0.002239, loss_freq: 0.019262
[18:02:12.490] iteration 19543: loss: 0.034750, loss_s1: 0.022839, loss_fp: 0.003604, loss_freq: 0.012996
[18:02:13.114] iteration 19544: loss: 0.048535, loss_s1: 0.032646, loss_fp: 0.000480, loss_freq: 0.018771
[18:02:13.743] iteration 19545: loss: 0.075172, loss_s1: 0.042693, loss_fp: 0.013770, loss_freq: 0.030482
[18:02:14.367] iteration 19546: loss: 0.054860, loss_s1: 0.050576, loss_fp: 0.011637, loss_freq: 0.016186
[18:02:14.993] iteration 19547: loss: 0.058237, loss_s1: 0.022343, loss_fp: 0.003225, loss_freq: 0.058855
[18:02:15.618] iteration 19548: loss: 0.089095, loss_s1: 0.046270, loss_fp: 0.002832, loss_freq: 0.071069
[18:02:16.247] iteration 19549: loss: 0.069376, loss_s1: 0.040013, loss_fp: 0.006511, loss_freq: 0.066936
[18:02:16.870] iteration 19550: loss: 0.042592, loss_s1: 0.021783, loss_fp: 0.002347, loss_freq: 0.022709
[18:02:17.496] iteration 19551: loss: 0.062124, loss_s1: 0.029156, loss_fp: 0.000782, loss_freq: 0.035128
[18:02:18.119] iteration 19552: loss: 0.064845, loss_s1: 0.051970, loss_fp: 0.009389, loss_freq: 0.035884
[18:02:18.745] iteration 19553: loss: 0.053192, loss_s1: 0.044426, loss_fp: 0.002672, loss_freq: 0.017103
[18:02:19.373] iteration 19554: loss: 0.038292, loss_s1: 0.005198, loss_fp: 0.002655, loss_freq: 0.035052
[18:02:20.004] iteration 19555: loss: 0.041666, loss_s1: 0.032153, loss_fp: 0.001171, loss_freq: 0.011565
[18:02:20.628] iteration 19556: loss: 0.067769, loss_s1: 0.073497, loss_fp: 0.003697, loss_freq: 0.014015
[18:02:21.252] iteration 19557: loss: 0.058102, loss_s1: 0.031846, loss_fp: 0.007538, loss_freq: 0.029688
[18:02:21.874] iteration 19558: loss: 0.053374, loss_s1: 0.044245, loss_fp: 0.001652, loss_freq: 0.027935
[18:02:22.525] iteration 19559: loss: 0.032987, loss_s1: 0.029932, loss_fp: 0.000730, loss_freq: 0.007804
[18:02:23.202] iteration 19560: loss: 0.027447, loss_s1: 0.015516, loss_fp: 0.004849, loss_freq: 0.005642
[18:02:23.864] iteration 19561: loss: 0.070220, loss_s1: 0.071290, loss_fp: 0.005688, loss_freq: 0.026423
[18:02:24.527] iteration 19562: loss: 0.041946, loss_s1: 0.030569, loss_fp: 0.002814, loss_freq: 0.008854
[18:02:25.188] iteration 19563: loss: 0.054392, loss_s1: 0.040248, loss_fp: 0.003575, loss_freq: 0.035281
[18:02:25.849] iteration 19564: loss: 0.138840, loss_s1: 0.176268, loss_fp: 0.022342, loss_freq: 0.051416
[18:02:26.479] iteration 19565: loss: 0.080626, loss_s1: 0.032105, loss_fp: 0.022306, loss_freq: 0.064361
[18:02:27.123] iteration 19566: loss: 0.062033, loss_s1: 0.060275, loss_fp: 0.003107, loss_freq: 0.028636
[18:02:27.748] iteration 19567: loss: 0.045525, loss_s1: 0.047197, loss_fp: 0.001796, loss_freq: 0.011757
[18:02:28.384] iteration 19568: loss: 0.049509, loss_s1: 0.041477, loss_fp: 0.004180, loss_freq: 0.018977
[18:02:29.012] iteration 19569: loss: 0.047473, loss_s1: 0.028581, loss_fp: 0.002907, loss_freq: 0.008159
[18:02:29.640] iteration 19570: loss: 0.045760, loss_s1: 0.027767, loss_fp: 0.004205, loss_freq: 0.019849
[18:02:30.328] iteration 19571: loss: 0.082835, loss_s1: 0.077457, loss_fp: 0.001485, loss_freq: 0.048186
[18:02:30.986] iteration 19572: loss: 0.068401, loss_s1: 0.030579, loss_fp: 0.003105, loss_freq: 0.027804
[18:02:31.650] iteration 19573: loss: 0.050735, loss_s1: 0.046343, loss_fp: 0.001157, loss_freq: 0.015275
[18:02:32.301] iteration 19574: loss: 0.072086, loss_s1: 0.018864, loss_fp: 0.005153, loss_freq: 0.055036
[18:02:32.924] iteration 19575: loss: 0.055599, loss_s1: 0.037038, loss_fp: 0.000424, loss_freq: 0.030186
[18:02:33.548] iteration 19576: loss: 0.060714, loss_s1: 0.041688, loss_fp: 0.001395, loss_freq: 0.044792
[18:02:34.182] iteration 19577: loss: 0.046393, loss_s1: 0.020585, loss_fp: 0.001675, loss_freq: 0.027681
[18:02:34.805] iteration 19578: loss: 0.035954, loss_s1: 0.021212, loss_fp: 0.001749, loss_freq: 0.016605
[18:02:35.427] iteration 19579: loss: 0.045176, loss_s1: 0.020426, loss_fp: 0.001521, loss_freq: 0.034159
[18:02:36.052] iteration 19580: loss: 0.046051, loss_s1: 0.044044, loss_fp: 0.001576, loss_freq: 0.013476
[18:02:36.675] iteration 19581: loss: 0.070977, loss_s1: 0.068073, loss_fp: 0.009777, loss_freq: 0.023617
[18:02:37.306] iteration 19582: loss: 0.093675, loss_s1: 0.082292, loss_fp: 0.006408, loss_freq: 0.065325
[18:02:37.929] iteration 19583: loss: 0.088608, loss_s1: 0.046785, loss_fp: 0.005740, loss_freq: 0.071674
[18:02:38.551] iteration 19584: loss: 0.059902, loss_s1: 0.060465, loss_fp: 0.001440, loss_freq: 0.026784
[18:02:39.173] iteration 19585: loss: 0.054149, loss_s1: 0.042726, loss_fp: 0.002071, loss_freq: 0.028024
[18:02:39.807] iteration 19586: loss: 0.049295, loss_s1: 0.026496, loss_fp: 0.000932, loss_freq: 0.028250
[18:02:40.436] iteration 19587: loss: 0.082552, loss_s1: 0.049889, loss_fp: 0.008745, loss_freq: 0.047836
[18:02:41.063] iteration 19588: loss: 0.033382, loss_s1: 0.021739, loss_fp: 0.000430, loss_freq: 0.008370
[18:02:41.684] iteration 19589: loss: 0.076585, loss_s1: 0.083304, loss_fp: 0.004133, loss_freq: 0.024499
[18:02:42.308] iteration 19590: loss: 0.109881, loss_s1: 0.064283, loss_fp: 0.018514, loss_freq: 0.087733
[18:02:42.929] iteration 19591: loss: 0.055046, loss_s1: 0.034769, loss_fp: 0.001611, loss_freq: 0.037845
[18:02:43.552] iteration 19592: loss: 0.047158, loss_s1: 0.029026, loss_fp: 0.003084, loss_freq: 0.016789
[18:02:44.178] iteration 19593: loss: 0.043970, loss_s1: 0.031035, loss_fp: 0.001732, loss_freq: 0.023311
[18:02:44.821] iteration 19594: loss: 0.048131, loss_s1: 0.027401, loss_fp: 0.001088, loss_freq: 0.027854
[18:02:45.443] iteration 19595: loss: 0.040003, loss_s1: 0.028160, loss_fp: 0.001645, loss_freq: 0.008186
[18:02:46.069] iteration 19596: loss: 0.048965, loss_s1: 0.035464, loss_fp: 0.001241, loss_freq: 0.011089
[18:02:46.693] iteration 19597: loss: 0.112990, loss_s1: 0.125191, loss_fp: 0.008008, loss_freq: 0.053088
[18:02:47.317] iteration 19598: loss: 0.032785, loss_s1: 0.020590, loss_fp: 0.006540, loss_freq: 0.005542
[18:02:47.940] iteration 19599: loss: 0.042708, loss_s1: 0.031843, loss_fp: 0.003304, loss_freq: 0.011627
[18:02:48.566] iteration 19600: loss: 0.070142, loss_s1: 0.059751, loss_fp: 0.007202, loss_freq: 0.028634
[18:02:51.770] iteration 19600 : mean_dice : 0.730179
[18:02:52.416] iteration 19601: loss: 0.083212, loss_s1: 0.054022, loss_fp: 0.002759, loss_freq: 0.079020
[18:02:53.052] iteration 19602: loss: 0.040046, loss_s1: 0.022064, loss_fp: 0.006687, loss_freq: 0.013512
[18:02:53.678] iteration 19603: loss: 0.093489, loss_s1: 0.072231, loss_fp: 0.002726, loss_freq: 0.049828
[18:02:54.303] iteration 19604: loss: 0.058234, loss_s1: 0.066588, loss_fp: 0.010404, loss_freq: 0.006533
[18:02:54.954] iteration 19605: loss: 0.063443, loss_s1: 0.040885, loss_fp: 0.004096, loss_freq: 0.028024
[18:02:55.578] iteration 19606: loss: 0.060524, loss_s1: 0.032590, loss_fp: 0.001522, loss_freq: 0.023009
[18:02:56.200] iteration 19607: loss: 0.071419, loss_s1: 0.053848, loss_fp: 0.005872, loss_freq: 0.036466
[18:02:56.823] iteration 19608: loss: 0.052864, loss_s1: 0.044559, loss_fp: 0.002809, loss_freq: 0.018656
[18:02:57.451] iteration 19609: loss: 0.082518, loss_s1: 0.069496, loss_fp: 0.003703, loss_freq: 0.039589
[18:02:58.072] iteration 19610: loss: 0.061851, loss_s1: 0.039600, loss_fp: 0.003596, loss_freq: 0.036993
[18:02:58.701] iteration 19611: loss: 0.060736, loss_s1: 0.052328, loss_fp: 0.008961, loss_freq: 0.022057
[18:02:59.329] iteration 19612: loss: 0.069949, loss_s1: 0.068203, loss_fp: 0.002052, loss_freq: 0.032767
[18:02:59.958] iteration 19613: loss: 0.063242, loss_s1: 0.071266, loss_fp: 0.003472, loss_freq: 0.022181
[18:03:00.582] iteration 19614: loss: 0.044521, loss_s1: 0.032768, loss_fp: 0.008840, loss_freq: 0.006347
[18:03:01.210] iteration 19615: loss: 0.050205, loss_s1: 0.038583, loss_fp: 0.004566, loss_freq: 0.018496
[18:03:01.834] iteration 19616: loss: 0.057473, loss_s1: 0.030652, loss_fp: 0.004585, loss_freq: 0.043392
[18:03:02.459] iteration 19617: loss: 0.068021, loss_s1: 0.079963, loss_fp: 0.002813, loss_freq: 0.023261
[18:03:03.085] iteration 19618: loss: 0.046920, loss_s1: 0.018653, loss_fp: 0.004560, loss_freq: 0.023310
[18:03:03.716] iteration 19619: loss: 0.047346, loss_s1: 0.041291, loss_fp: 0.005121, loss_freq: 0.020921
[18:03:04.344] iteration 19620: loss: 0.041467, loss_s1: 0.030940, loss_fp: 0.000518, loss_freq: 0.013969
[18:03:04.967] iteration 19621: loss: 0.061759, loss_s1: 0.034952, loss_fp: 0.004732, loss_freq: 0.040484
[18:03:05.589] iteration 19622: loss: 0.096581, loss_s1: 0.133193, loss_fp: 0.004825, loss_freq: 0.018052
[18:03:06.215] iteration 19623: loss: 0.055225, loss_s1: 0.046390, loss_fp: 0.005677, loss_freq: 0.018705
[18:03:06.840] iteration 19624: loss: 0.061830, loss_s1: 0.023446, loss_fp: 0.009348, loss_freq: 0.057276
[18:03:07.466] iteration 19625: loss: 0.089953, loss_s1: 0.106757, loss_fp: 0.001862, loss_freq: 0.022966
[18:03:08.094] iteration 19626: loss: 0.036662, loss_s1: 0.025237, loss_fp: 0.004239, loss_freq: 0.009432
[18:03:08.720] iteration 19627: loss: 0.082188, loss_s1: 0.057472, loss_fp: 0.017089, loss_freq: 0.032349
[18:03:09.346] iteration 19628: loss: 0.073794, loss_s1: 0.039784, loss_fp: 0.006879, loss_freq: 0.070649
[18:03:09.969] iteration 19629: loss: 0.045514, loss_s1: 0.026636, loss_fp: 0.002116, loss_freq: 0.010978
[18:03:10.594] iteration 19630: loss: 0.040866, loss_s1: 0.029281, loss_fp: 0.001735, loss_freq: 0.016100
[18:03:11.224] iteration 19631: loss: 0.079109, loss_s1: 0.064808, loss_fp: 0.007965, loss_freq: 0.045571
[18:03:11.855] iteration 19632: loss: 0.066559, loss_s1: 0.040864, loss_fp: 0.005505, loss_freq: 0.040982
[18:03:12.480] iteration 19633: loss: 0.061110, loss_s1: 0.051799, loss_fp: 0.003952, loss_freq: 0.030231
[18:03:13.136] iteration 19634: loss: 0.041645, loss_s1: 0.037033, loss_fp: 0.004500, loss_freq: 0.015023
[18:03:13.794] iteration 19635: loss: 0.059412, loss_s1: 0.041937, loss_fp: 0.006120, loss_freq: 0.035090
[18:03:14.456] iteration 19636: loss: 0.024484, loss_s1: 0.007060, loss_fp: 0.001021, loss_freq: 0.013120
[18:03:15.120] iteration 19637: loss: 0.044439, loss_s1: 0.033399, loss_fp: 0.002567, loss_freq: 0.014909
[18:03:15.775] iteration 19638: loss: 0.048011, loss_s1: 0.023994, loss_fp: 0.001027, loss_freq: 0.015186
[18:03:16.408] iteration 19639: loss: 0.055348, loss_s1: 0.056543, loss_fp: 0.001388, loss_freq: 0.023311
[18:03:17.086] iteration 19640: loss: 0.073549, loss_s1: 0.086330, loss_fp: 0.003911, loss_freq: 0.016638
[18:03:17.717] iteration 19641: loss: 0.055824, loss_s1: 0.050148, loss_fp: 0.001955, loss_freq: 0.013841
[18:03:18.352] iteration 19642: loss: 0.057600, loss_s1: 0.032232, loss_fp: 0.002210, loss_freq: 0.034875
[18:03:19.338] iteration 19643: loss: 0.042120, loss_s1: 0.033836, loss_fp: 0.001094, loss_freq: 0.007382
[18:03:19.966] iteration 19644: loss: 0.054492, loss_s1: 0.042614, loss_fp: 0.001882, loss_freq: 0.023604
[18:03:20.591] iteration 19645: loss: 0.061889, loss_s1: 0.047430, loss_fp: 0.013282, loss_freq: 0.025231
[18:03:21.249] iteration 19646: loss: 0.041086, loss_s1: 0.018537, loss_fp: 0.001396, loss_freq: 0.020442
[18:03:21.915] iteration 19647: loss: 0.047348, loss_s1: 0.019543, loss_fp: 0.002158, loss_freq: 0.025175
[18:03:22.576] iteration 19648: loss: 0.091713, loss_s1: 0.046050, loss_fp: 0.026984, loss_freq: 0.051601
[18:03:23.241] iteration 19649: loss: 0.051551, loss_s1: 0.045752, loss_fp: 0.007390, loss_freq: 0.015200
[18:03:23.904] iteration 19650: loss: 0.056864, loss_s1: 0.071192, loss_fp: 0.000706, loss_freq: 0.013163
[18:03:24.568] iteration 19651: loss: 0.047229, loss_s1: 0.032155, loss_fp: 0.001293, loss_freq: 0.032662
[18:03:25.202] iteration 19652: loss: 0.090557, loss_s1: 0.081825, loss_fp: 0.008165, loss_freq: 0.054370
[18:03:25.830] iteration 19653: loss: 0.050989, loss_s1: 0.049906, loss_fp: 0.000703, loss_freq: 0.020307
[18:03:26.460] iteration 19654: loss: 0.061642, loss_s1: 0.013437, loss_fp: 0.010091, loss_freq: 0.048215
[18:03:27.085] iteration 19655: loss: 0.066097, loss_s1: 0.052007, loss_fp: 0.008939, loss_freq: 0.042085
[18:03:27.711] iteration 19656: loss: 0.082777, loss_s1: 0.049821, loss_fp: 0.003201, loss_freq: 0.073083
[18:03:28.341] iteration 19657: loss: 0.059607, loss_s1: 0.031534, loss_fp: 0.007614, loss_freq: 0.047252
[18:03:28.968] iteration 19658: loss: 0.068373, loss_s1: 0.037891, loss_fp: 0.011149, loss_freq: 0.046069
[18:03:29.595] iteration 19659: loss: 0.063557, loss_s1: 0.053077, loss_fp: 0.003243, loss_freq: 0.013958
[18:03:30.221] iteration 19660: loss: 0.072543, loss_s1: 0.066679, loss_fp: 0.005948, loss_freq: 0.034825
[18:03:30.881] iteration 19661: loss: 0.039379, loss_s1: 0.016737, loss_fp: 0.001052, loss_freq: 0.026009
[18:03:31.513] iteration 19662: loss: 0.059989, loss_s1: 0.045142, loss_fp: 0.001324, loss_freq: 0.036520
[18:03:32.141] iteration 19663: loss: 0.038145, loss_s1: 0.017067, loss_fp: 0.004438, loss_freq: 0.016534
[18:03:32.770] iteration 19664: loss: 0.034512, loss_s1: 0.010280, loss_fp: 0.001648, loss_freq: 0.012600
[18:03:33.399] iteration 19665: loss: 0.047492, loss_s1: 0.014005, loss_fp: 0.002116, loss_freq: 0.039914
[18:03:34.029] iteration 19666: loss: 0.177700, loss_s1: 0.159281, loss_fp: 0.001838, loss_freq: 0.158168
[18:03:34.664] iteration 19667: loss: 0.035227, loss_s1: 0.026823, loss_fp: 0.004474, loss_freq: 0.010991
[18:03:35.329] iteration 19668: loss: 0.035025, loss_s1: 0.021596, loss_fp: 0.003987, loss_freq: 0.013900
[18:03:35.990] iteration 19669: loss: 0.058341, loss_s1: 0.063477, loss_fp: 0.000659, loss_freq: 0.016307
[18:03:36.650] iteration 19670: loss: 0.081172, loss_s1: 0.087553, loss_fp: 0.007832, loss_freq: 0.028280
[18:03:37.311] iteration 19671: loss: 0.069845, loss_s1: 0.046735, loss_fp: 0.007914, loss_freq: 0.046041
[18:03:37.955] iteration 19672: loss: 0.050542, loss_s1: 0.046757, loss_fp: 0.003137, loss_freq: 0.012394
[18:03:38.580] iteration 19673: loss: 0.033245, loss_s1: 0.018837, loss_fp: 0.006197, loss_freq: 0.012783
[18:03:39.206] iteration 19674: loss: 0.057997, loss_s1: 0.039943, loss_fp: 0.005643, loss_freq: 0.032889
[18:03:39.833] iteration 19675: loss: 0.043824, loss_s1: 0.031602, loss_fp: 0.000850, loss_freq: 0.019744
[18:03:40.459] iteration 19676: loss: 0.032442, loss_s1: 0.024137, loss_fp: 0.001114, loss_freq: 0.009116
[18:03:41.089] iteration 19677: loss: 0.056811, loss_s1: 0.031531, loss_fp: 0.001413, loss_freq: 0.037019
[18:03:41.714] iteration 19678: loss: 0.063708, loss_s1: 0.059247, loss_fp: 0.009604, loss_freq: 0.025424
[18:03:42.342] iteration 19679: loss: 0.108030, loss_s1: 0.128865, loss_fp: 0.002877, loss_freq: 0.027980
[18:03:42.969] iteration 19680: loss: 0.075911, loss_s1: 0.086805, loss_fp: 0.000605, loss_freq: 0.031628
[18:03:43.601] iteration 19681: loss: 0.064851, loss_s1: 0.063886, loss_fp: 0.001260, loss_freq: 0.019506
[18:03:44.224] iteration 19682: loss: 0.062447, loss_s1: 0.064951, loss_fp: 0.004398, loss_freq: 0.021068
[18:03:44.852] iteration 19683: loss: 0.062658, loss_s1: 0.056007, loss_fp: 0.003263, loss_freq: 0.011290
[18:03:45.482] iteration 19684: loss: 0.061230, loss_s1: 0.053719, loss_fp: 0.005116, loss_freq: 0.034124
[18:03:46.111] iteration 19685: loss: 0.052080, loss_s1: 0.037400, loss_fp: 0.013764, loss_freq: 0.021063
[18:03:46.738] iteration 19686: loss: 0.057958, loss_s1: 0.024794, loss_fp: 0.003436, loss_freq: 0.047494
[18:03:47.372] iteration 19687: loss: 0.052655, loss_s1: 0.028676, loss_fp: 0.003249, loss_freq: 0.018454
[18:03:48.004] iteration 19688: loss: 0.050332, loss_s1: 0.056832, loss_fp: 0.002126, loss_freq: 0.008222
[18:03:48.632] iteration 19689: loss: 0.034885, loss_s1: 0.017105, loss_fp: 0.000506, loss_freq: 0.013773
[18:03:49.256] iteration 19690: loss: 0.057147, loss_s1: 0.059076, loss_fp: 0.001483, loss_freq: 0.019085
[18:03:49.887] iteration 19691: loss: 0.084520, loss_s1: 0.093751, loss_fp: 0.004230, loss_freq: 0.021466
[18:03:50.513] iteration 19692: loss: 0.083181, loss_s1: 0.082118, loss_fp: 0.011841, loss_freq: 0.039333
[18:03:51.177] iteration 19693: loss: 0.057234, loss_s1: 0.055250, loss_fp: 0.001038, loss_freq: 0.027007
[18:03:51.843] iteration 19694: loss: 0.053069, loss_s1: 0.015580, loss_fp: 0.003233, loss_freq: 0.030031
[18:03:52.504] iteration 19695: loss: 0.076701, loss_s1: 0.054339, loss_fp: 0.003706, loss_freq: 0.054187
[18:03:53.175] iteration 19696: loss: 0.056014, loss_s1: 0.062272, loss_fp: 0.000863, loss_freq: 0.014283
[18:03:53.808] iteration 19697: loss: 0.057485, loss_s1: 0.024150, loss_fp: 0.005617, loss_freq: 0.024726
[18:03:54.439] iteration 19698: loss: 0.097997, loss_s1: 0.055923, loss_fp: 0.003268, loss_freq: 0.041686
[18:03:55.068] iteration 19699: loss: 0.041195, loss_s1: 0.029119, loss_fp: 0.002145, loss_freq: 0.012492
[18:03:55.693] iteration 19700: loss: 0.046453, loss_s1: 0.020634, loss_fp: 0.004268, loss_freq: 0.020684
[18:03:56.324] iteration 19701: loss: 0.033277, loss_s1: 0.018304, loss_fp: 0.002361, loss_freq: 0.012168
[18:03:56.986] iteration 19702: loss: 0.052447, loss_s1: 0.042013, loss_fp: 0.013079, loss_freq: 0.025822
[18:03:57.613] iteration 19703: loss: 0.052310, loss_s1: 0.050446, loss_fp: 0.003905, loss_freq: 0.021106
[18:03:58.237] iteration 19704: loss: 0.057089, loss_s1: 0.053824, loss_fp: 0.006974, loss_freq: 0.013581
[18:03:58.863] iteration 19705: loss: 0.062257, loss_s1: 0.034173, loss_fp: 0.001021, loss_freq: 0.014105
[18:03:59.484] iteration 19706: loss: 0.070341, loss_s1: 0.045354, loss_fp: 0.006672, loss_freq: 0.027898
[18:04:00.110] iteration 19707: loss: 0.054996, loss_s1: 0.056304, loss_fp: 0.003082, loss_freq: 0.017932
[18:04:00.736] iteration 19708: loss: 0.109290, loss_s1: 0.065266, loss_fp: 0.020573, loss_freq: 0.106141
[18:04:01.363] iteration 19709: loss: 0.058078, loss_s1: 0.029308, loss_fp: 0.003870, loss_freq: 0.039231
[18:04:02.010] iteration 19710: loss: 0.073059, loss_s1: 0.068528, loss_fp: 0.006803, loss_freq: 0.039115
[18:04:02.636] iteration 19711: loss: 0.036984, loss_s1: 0.018619, loss_fp: 0.001563, loss_freq: 0.012392
[18:04:03.290] iteration 19712: loss: 0.083178, loss_s1: 0.049751, loss_fp: 0.002513, loss_freq: 0.068044
[18:04:03.919] iteration 19713: loss: 0.089760, loss_s1: 0.085296, loss_fp: 0.007370, loss_freq: 0.045548
[18:04:04.555] iteration 19714: loss: 0.073969, loss_s1: 0.075415, loss_fp: 0.003657, loss_freq: 0.027441
[18:04:05.181] iteration 19715: loss: 0.076502, loss_s1: 0.071679, loss_fp: 0.004151, loss_freq: 0.038345
[18:04:05.808] iteration 19716: loss: 0.045027, loss_s1: 0.026136, loss_fp: 0.007118, loss_freq: 0.015251
[18:04:06.437] iteration 19717: loss: 0.048259, loss_s1: 0.045619, loss_fp: 0.005697, loss_freq: 0.007515
[18:04:07.061] iteration 19718: loss: 0.041038, loss_s1: 0.020289, loss_fp: 0.001511, loss_freq: 0.006985
[18:04:07.684] iteration 19719: loss: 0.059208, loss_s1: 0.046516, loss_fp: 0.001838, loss_freq: 0.038126
[18:04:08.313] iteration 19720: loss: 0.042616, loss_s1: 0.026942, loss_fp: 0.003192, loss_freq: 0.025314
[18:04:08.942] iteration 19721: loss: 0.023476, loss_s1: 0.013353, loss_fp: 0.001473, loss_freq: 0.006385
[18:04:09.576] iteration 19722: loss: 0.042615, loss_s1: 0.027269, loss_fp: 0.003807, loss_freq: 0.014503
[18:04:10.213] iteration 19723: loss: 0.041865, loss_s1: 0.041206, loss_fp: 0.002081, loss_freq: 0.008417
[18:04:10.839] iteration 19724: loss: 0.063355, loss_s1: 0.055828, loss_fp: 0.002891, loss_freq: 0.025045
[18:04:11.468] iteration 19725: loss: 0.058474, loss_s1: 0.044942, loss_fp: 0.003008, loss_freq: 0.038365
[18:04:12.098] iteration 19726: loss: 0.038369, loss_s1: 0.020368, loss_fp: 0.000466, loss_freq: 0.011959
[18:04:12.725] iteration 19727: loss: 0.080658, loss_s1: 0.055593, loss_fp: 0.002366, loss_freq: 0.075864
[18:04:13.348] iteration 19728: loss: 0.059633, loss_s1: 0.039353, loss_fp: 0.003739, loss_freq: 0.046575
[18:04:13.974] iteration 19729: loss: 0.049911, loss_s1: 0.021675, loss_fp: 0.001698, loss_freq: 0.011853
[18:04:14.599] iteration 19730: loss: 0.050794, loss_s1: 0.017082, loss_fp: 0.001927, loss_freq: 0.011974
[18:04:15.232] iteration 19731: loss: 0.054379, loss_s1: 0.048757, loss_fp: 0.010713, loss_freq: 0.014592
[18:04:15.887] iteration 19732: loss: 0.101788, loss_s1: 0.097514, loss_fp: 0.001097, loss_freq: 0.046109
[18:04:16.547] iteration 19733: loss: 0.062435, loss_s1: 0.058844, loss_fp: 0.000762, loss_freq: 0.027586
[18:04:17.203] iteration 19734: loss: 0.050039, loss_s1: 0.027398, loss_fp: 0.004076, loss_freq: 0.022674
[18:04:17.859] iteration 19735: loss: 0.048382, loss_s1: 0.031630, loss_fp: 0.004981, loss_freq: 0.015258
[18:04:18.498] iteration 19736: loss: 0.040720, loss_s1: 0.033896, loss_fp: 0.002422, loss_freq: 0.012455
[18:04:19.143] iteration 19737: loss: 0.041066, loss_s1: 0.029731, loss_fp: 0.001433, loss_freq: 0.017893
[18:04:19.787] iteration 19738: loss: 0.071634, loss_s1: 0.027856, loss_fp: 0.041245, loss_freq: 0.042158
[18:04:20.431] iteration 19739: loss: 0.038520, loss_s1: 0.018850, loss_fp: 0.002360, loss_freq: 0.015404
[18:04:21.076] iteration 19740: loss: 0.052430, loss_s1: 0.019130, loss_fp: 0.000619, loss_freq: 0.044965
[18:04:21.716] iteration 19741: loss: 0.030872, loss_s1: 0.010291, loss_fp: 0.003587, loss_freq: 0.004664
[18:04:22.363] iteration 19742: loss: 0.055788, loss_s1: 0.041409, loss_fp: 0.004071, loss_freq: 0.020696
[18:04:23.013] iteration 19743: loss: 0.072222, loss_s1: 0.073128, loss_fp: 0.007477, loss_freq: 0.028934
[18:04:23.655] iteration 19744: loss: 0.087506, loss_s1: 0.062832, loss_fp: 0.002466, loss_freq: 0.074946
[18:04:24.292] iteration 19745: loss: 0.097763, loss_s1: 0.110348, loss_fp: 0.001714, loss_freq: 0.046777
[18:04:24.933] iteration 19746: loss: 0.057911, loss_s1: 0.035238, loss_fp: 0.007993, loss_freq: 0.033548
[18:04:25.579] iteration 19747: loss: 0.043486, loss_s1: 0.027275, loss_fp: 0.003124, loss_freq: 0.008728
[18:04:26.219] iteration 19748: loss: 0.040307, loss_s1: 0.014006, loss_fp: 0.004181, loss_freq: 0.020756
[18:04:26.859] iteration 19749: loss: 0.046641, loss_s1: 0.047058, loss_fp: 0.001419, loss_freq: 0.005361
[18:04:27.501] iteration 19750: loss: 0.066616, loss_s1: 0.055797, loss_fp: 0.005351, loss_freq: 0.029851
[18:04:28.141] iteration 19751: loss: 0.113725, loss_s1: 0.096250, loss_fp: 0.006415, loss_freq: 0.088269
[18:04:28.760] iteration 19752: loss: 0.053561, loss_s1: 0.060016, loss_fp: 0.003344, loss_freq: 0.011820
[18:04:29.388] iteration 19753: loss: 0.047533, loss_s1: 0.031560, loss_fp: 0.003140, loss_freq: 0.016653
[18:04:30.012] iteration 19754: loss: 0.048679, loss_s1: 0.023916, loss_fp: 0.004899, loss_freq: 0.038266
[18:04:30.637] iteration 19755: loss: 0.103408, loss_s1: 0.094023, loss_fp: 0.008630, loss_freq: 0.074853
[18:04:31.259] iteration 19756: loss: 0.046107, loss_s1: 0.030667, loss_fp: 0.001108, loss_freq: 0.031677
[18:04:31.884] iteration 19757: loss: 0.053371, loss_s1: 0.053763, loss_fp: 0.000989, loss_freq: 0.009456
[18:04:32.509] iteration 19758: loss: 0.081950, loss_s1: 0.051916, loss_fp: 0.003885, loss_freq: 0.071313
[18:04:33.131] iteration 19759: loss: 0.034128, loss_s1: 0.028592, loss_fp: 0.001972, loss_freq: 0.004881
[18:04:33.757] iteration 19760: loss: 0.039000, loss_s1: 0.015748, loss_fp: 0.002733, loss_freq: 0.022913
[18:04:34.380] iteration 19761: loss: 0.057613, loss_s1: 0.037959, loss_fp: 0.012656, loss_freq: 0.031588
[18:04:35.003] iteration 19762: loss: 0.080573, loss_s1: 0.034674, loss_fp: 0.005861, loss_freq: 0.090252
[18:04:35.628] iteration 19763: loss: 0.050426, loss_s1: 0.032283, loss_fp: 0.004984, loss_freq: 0.015171
[18:04:36.258] iteration 19764: loss: 0.069202, loss_s1: 0.047916, loss_fp: 0.004713, loss_freq: 0.038757
[18:04:36.954] iteration 19765: loss: 0.054827, loss_s1: 0.042308, loss_fp: 0.005640, loss_freq: 0.011547
[18:04:37.614] iteration 19766: loss: 0.042557, loss_s1: 0.028691, loss_fp: 0.006015, loss_freq: 0.010879
[18:04:38.273] iteration 19767: loss: 0.058584, loss_s1: 0.040760, loss_fp: 0.004348, loss_freq: 0.027188
[18:04:38.947] iteration 19768: loss: 0.055183, loss_s1: 0.042603, loss_fp: 0.001254, loss_freq: 0.014609
[18:04:39.621] iteration 19769: loss: 0.060523, loss_s1: 0.058390, loss_fp: 0.001637, loss_freq: 0.010543
[18:04:40.263] iteration 19770: loss: 0.111881, loss_s1: 0.047035, loss_fp: 0.007489, loss_freq: 0.072876
[18:04:40.904] iteration 19771: loss: 0.062392, loss_s1: 0.057326, loss_fp: 0.000740, loss_freq: 0.032901
[18:04:41.551] iteration 19772: loss: 0.037157, loss_s1: 0.032773, loss_fp: 0.004103, loss_freq: 0.013601
[18:04:42.194] iteration 19773: loss: 0.086512, loss_s1: 0.062527, loss_fp: 0.003956, loss_freq: 0.073558
[18:04:42.834] iteration 19774: loss: 0.075859, loss_s1: 0.097966, loss_fp: 0.002021, loss_freq: 0.022368
[18:04:43.495] iteration 19775: loss: 0.084363, loss_s1: 0.071346, loss_fp: 0.001828, loss_freq: 0.014613
[18:04:44.152] iteration 19776: loss: 0.034970, loss_s1: 0.029314, loss_fp: 0.003836, loss_freq: 0.007989
[18:04:44.807] iteration 19777: loss: 0.055390, loss_s1: 0.018008, loss_fp: 0.003014, loss_freq: 0.055720
[18:04:45.464] iteration 19778: loss: 0.056333, loss_s1: 0.059725, loss_fp: 0.003259, loss_freq: 0.017394
[18:04:46.120] iteration 19779: loss: 0.030581, loss_s1: 0.015324, loss_fp: 0.000877, loss_freq: 0.004883
[18:04:46.784] iteration 19780: loss: 0.053729, loss_s1: 0.051534, loss_fp: 0.002164, loss_freq: 0.014175
[18:04:47.415] iteration 19781: loss: 0.033981, loss_s1: 0.010917, loss_fp: 0.002228, loss_freq: 0.016412
[18:04:48.038] iteration 19782: loss: 0.076255, loss_s1: 0.051140, loss_fp: 0.007112, loss_freq: 0.027166
[18:04:48.660] iteration 19783: loss: 0.053043, loss_s1: 0.037740, loss_fp: 0.008365, loss_freq: 0.027155
[18:04:49.289] iteration 19784: loss: 0.059747, loss_s1: 0.045825, loss_fp: 0.004993, loss_freq: 0.019386
[18:04:49.916] iteration 19785: loss: 0.095180, loss_s1: 0.109717, loss_fp: 0.002089, loss_freq: 0.038183
[18:04:50.549] iteration 19786: loss: 0.050030, loss_s1: 0.036621, loss_fp: 0.006220, loss_freq: 0.018938
[18:04:51.209] iteration 19787: loss: 0.064968, loss_s1: 0.022785, loss_fp: 0.013084, loss_freq: 0.013199
[18:04:51.872] iteration 19788: loss: 0.071575, loss_s1: 0.045507, loss_fp: 0.017908, loss_freq: 0.028304
[18:04:52.537] iteration 19789: loss: 0.074582, loss_s1: 0.055270, loss_fp: 0.002339, loss_freq: 0.058288
[18:04:53.203] iteration 19790: loss: 0.033344, loss_s1: 0.022665, loss_fp: 0.003313, loss_freq: 0.008434
[18:04:53.863] iteration 19791: loss: 0.038654, loss_s1: 0.033213, loss_fp: 0.005026, loss_freq: 0.010337
[18:04:54.491] iteration 19792: loss: 0.127883, loss_s1: 0.116248, loss_fp: 0.024397, loss_freq: 0.075801
[18:04:55.122] iteration 19793: loss: 0.078417, loss_s1: 0.098351, loss_fp: 0.005929, loss_freq: 0.013128
[18:04:55.750] iteration 19794: loss: 0.124052, loss_s1: 0.145157, loss_fp: 0.004158, loss_freq: 0.057641
[18:04:56.377] iteration 19795: loss: 0.035980, loss_s1: 0.021687, loss_fp: 0.001223, loss_freq: 0.015985
[18:04:57.008] iteration 19796: loss: 0.074867, loss_s1: 0.068611, loss_fp: 0.008317, loss_freq: 0.031805
[18:04:57.636] iteration 19797: loss: 0.042706, loss_s1: 0.030681, loss_fp: 0.003004, loss_freq: 0.010594
[18:04:58.263] iteration 19798: loss: 0.053451, loss_s1: 0.043556, loss_fp: 0.001358, loss_freq: 0.017500
[18:04:58.885] iteration 19799: loss: 0.045968, loss_s1: 0.023719, loss_fp: 0.001087, loss_freq: 0.017346
[18:04:59.515] iteration 19800: loss: 0.067616, loss_s1: 0.052971, loss_fp: 0.001324, loss_freq: 0.037473
[18:05:02.763] iteration 19800 : mean_dice : 0.753019
[18:05:03.404] iteration 19801: loss: 0.085177, loss_s1: 0.064885, loss_fp: 0.006145, loss_freq: 0.053978
[18:05:04.027] iteration 19802: loss: 0.080027, loss_s1: 0.086612, loss_fp: 0.003922, loss_freq: 0.023629
[18:05:04.648] iteration 19803: loss: 0.068044, loss_s1: 0.047987, loss_fp: 0.001709, loss_freq: 0.046257
[18:05:05.658] iteration 19804: loss: 0.056140, loss_s1: 0.062054, loss_fp: 0.001470, loss_freq: 0.012205
[18:05:06.313] iteration 19805: loss: 0.082620, loss_s1: 0.091845, loss_fp: 0.002211, loss_freq: 0.022642
[18:05:06.940] iteration 19806: loss: 0.033447, loss_s1: 0.016502, loss_fp: 0.001192, loss_freq: 0.013013
[18:05:07.579] iteration 19807: loss: 0.033608, loss_s1: 0.013882, loss_fp: 0.000720, loss_freq: 0.009991
[18:05:08.205] iteration 19808: loss: 0.056109, loss_s1: 0.053301, loss_fp: 0.002350, loss_freq: 0.019193
[18:05:08.833] iteration 19809: loss: 0.094077, loss_s1: 0.070768, loss_fp: 0.014407, loss_freq: 0.044234
[18:05:09.459] iteration 19810: loss: 0.052079, loss_s1: 0.046297, loss_fp: 0.005958, loss_freq: 0.015266
[18:05:10.085] iteration 19811: loss: 0.029136, loss_s1: 0.014995, loss_fp: 0.001860, loss_freq: 0.010125
[18:05:10.710] iteration 19812: loss: 0.057316, loss_s1: 0.056025, loss_fp: 0.003350, loss_freq: 0.029357
[18:05:11.336] iteration 19813: loss: 0.068240, loss_s1: 0.062149, loss_fp: 0.005414, loss_freq: 0.026743
[18:05:11.963] iteration 19814: loss: 0.040680, loss_s1: 0.027807, loss_fp: 0.000618, loss_freq: 0.014705
[18:05:12.588] iteration 19815: loss: 0.049605, loss_s1: 0.050724, loss_fp: 0.001495, loss_freq: 0.016000
[18:05:13.212] iteration 19816: loss: 0.067472, loss_s1: 0.030929, loss_fp: 0.011918, loss_freq: 0.063066
[18:05:13.835] iteration 19817: loss: 0.108119, loss_s1: 0.107136, loss_fp: 0.003899, loss_freq: 0.064124
[18:05:14.472] iteration 19818: loss: 0.063555, loss_s1: 0.067328, loss_fp: 0.002026, loss_freq: 0.021461
[18:05:15.095] iteration 19819: loss: 0.073918, loss_s1: 0.072419, loss_fp: 0.003250, loss_freq: 0.033317
[18:05:15.722] iteration 19820: loss: 0.036064, loss_s1: 0.008449, loss_fp: 0.000677, loss_freq: 0.010874
[18:05:16.347] iteration 19821: loss: 0.067324, loss_s1: 0.043440, loss_fp: 0.003771, loss_freq: 0.041656
[18:05:16.973] iteration 19822: loss: 0.033372, loss_s1: 0.016236, loss_fp: 0.001433, loss_freq: 0.019177
[18:05:17.600] iteration 19823: loss: 0.054554, loss_s1: 0.020332, loss_fp: 0.002047, loss_freq: 0.012082
[18:05:18.255] iteration 19824: loss: 0.040478, loss_s1: 0.023048, loss_fp: 0.000396, loss_freq: 0.010276
[18:05:18.923] iteration 19825: loss: 0.046155, loss_s1: 0.044629, loss_fp: 0.001271, loss_freq: 0.010588
[18:05:19.596] iteration 19826: loss: 0.080012, loss_s1: 0.054536, loss_fp: 0.002270, loss_freq: 0.041043
[18:05:20.262] iteration 19827: loss: 0.101913, loss_s1: 0.069864, loss_fp: 0.005489, loss_freq: 0.096807
[18:05:20.905] iteration 19828: loss: 0.049675, loss_s1: 0.036950, loss_fp: 0.002710, loss_freq: 0.023013
[18:05:21.542] iteration 19829: loss: 0.052369, loss_s1: 0.045169, loss_fp: 0.003590, loss_freq: 0.020682
[18:05:22.170] iteration 19830: loss: 0.026989, loss_s1: 0.011616, loss_fp: 0.001704, loss_freq: 0.003898
[18:05:22.801] iteration 19831: loss: 0.073390, loss_s1: 0.051291, loss_fp: 0.005138, loss_freq: 0.029757
[18:05:23.435] iteration 19832: loss: 0.063451, loss_s1: 0.028412, loss_fp: 0.013901, loss_freq: 0.046810
[18:05:24.068] iteration 19833: loss: 0.038234, loss_s1: 0.039097, loss_fp: 0.001510, loss_freq: 0.004386
[18:05:24.755] iteration 19834: loss: 0.044650, loss_s1: 0.041031, loss_fp: 0.001889, loss_freq: 0.015579
[18:05:25.415] iteration 19835: loss: 0.042584, loss_s1: 0.020489, loss_fp: 0.002467, loss_freq: 0.016444
[18:05:26.076] iteration 19836: loss: 0.039008, loss_s1: 0.016384, loss_fp: 0.003686, loss_freq: 0.019731
[18:05:26.738] iteration 19837: loss: 0.042603, loss_s1: 0.039849, loss_fp: 0.002771, loss_freq: 0.009094
[18:05:27.401] iteration 19838: loss: 0.083082, loss_s1: 0.060731, loss_fp: 0.013331, loss_freq: 0.039580
[18:05:28.062] iteration 19839: loss: 0.054281, loss_s1: 0.026078, loss_fp: 0.003568, loss_freq: 0.045720
[18:05:28.735] iteration 19840: loss: 0.045114, loss_s1: 0.027304, loss_fp: 0.009491, loss_freq: 0.019664
[18:05:29.397] iteration 19841: loss: 0.072891, loss_s1: 0.062148, loss_fp: 0.000769, loss_freq: 0.046601
[18:05:30.062] iteration 19842: loss: 0.105559, loss_s1: 0.132969, loss_fp: 0.003421, loss_freq: 0.022387
[18:05:30.701] iteration 19843: loss: 0.076895, loss_s1: 0.078532, loss_fp: 0.002060, loss_freq: 0.028367
[18:05:31.353] iteration 19844: loss: 0.041567, loss_s1: 0.021196, loss_fp: 0.004584, loss_freq: 0.018838
[18:05:32.012] iteration 19845: loss: 0.055253, loss_s1: 0.025910, loss_fp: 0.004547, loss_freq: 0.047262
[18:05:32.672] iteration 19846: loss: 0.071198, loss_s1: 0.047401, loss_fp: 0.011789, loss_freq: 0.054858
[18:05:33.333] iteration 19847: loss: 0.043482, loss_s1: 0.019134, loss_fp: 0.003921, loss_freq: 0.033087
[18:05:33.987] iteration 19848: loss: 0.043972, loss_s1: 0.032130, loss_fp: 0.004341, loss_freq: 0.015514
[18:05:34.617] iteration 19849: loss: 0.026739, loss_s1: 0.009709, loss_fp: 0.002840, loss_freq: 0.003871
[18:05:35.244] iteration 19850: loss: 0.041924, loss_s1: 0.029491, loss_fp: 0.001380, loss_freq: 0.018232
[18:05:35.873] iteration 19851: loss: 0.074032, loss_s1: 0.083619, loss_fp: 0.013245, loss_freq: 0.018713
[18:05:36.495] iteration 19852: loss: 0.068906, loss_s1: 0.065317, loss_fp: 0.001073, loss_freq: 0.026323
[18:05:37.147] iteration 19853: loss: 0.076407, loss_s1: 0.090801, loss_fp: 0.007216, loss_freq: 0.027347
[18:05:37.775] iteration 19854: loss: 0.075333, loss_s1: 0.042286, loss_fp: 0.012482, loss_freq: 0.058781
[18:05:38.402] iteration 19855: loss: 0.045516, loss_s1: 0.014995, loss_fp: 0.003807, loss_freq: 0.021724
[18:05:39.031] iteration 19856: loss: 0.063147, loss_s1: 0.054300, loss_fp: 0.001949, loss_freq: 0.030799
[18:05:39.657] iteration 19857: loss: 0.072354, loss_s1: 0.048245, loss_fp: 0.001407, loss_freq: 0.056854
[18:05:40.286] iteration 19858: loss: 0.040955, loss_s1: 0.026215, loss_fp: 0.007057, loss_freq: 0.013924
[18:05:40.914] iteration 19859: loss: 0.075269, loss_s1: 0.076658, loss_fp: 0.008053, loss_freq: 0.024813
[18:05:41.539] iteration 19860: loss: 0.036887, loss_s1: 0.014662, loss_fp: 0.003760, loss_freq: 0.017521
[18:05:42.165] iteration 19861: loss: 0.074209, loss_s1: 0.066606, loss_fp: 0.001799, loss_freq: 0.031032
[18:05:42.822] iteration 19862: loss: 0.030908, loss_s1: 0.021370, loss_fp: 0.002691, loss_freq: 0.008349
[18:05:43.446] iteration 19863: loss: 0.046047, loss_s1: 0.042665, loss_fp: 0.002001, loss_freq: 0.023007
[18:05:44.072] iteration 19864: loss: 0.040742, loss_s1: 0.019158, loss_fp: 0.010525, loss_freq: 0.023879
[18:05:44.700] iteration 19865: loss: 0.030035, loss_s1: 0.013095, loss_fp: 0.004238, loss_freq: 0.011271
[18:05:45.331] iteration 19866: loss: 0.036132, loss_s1: 0.015584, loss_fp: 0.001705, loss_freq: 0.015082
[18:05:45.953] iteration 19867: loss: 0.055565, loss_s1: 0.042278, loss_fp: 0.007851, loss_freq: 0.024885
[18:05:46.583] iteration 19868: loss: 0.039751, loss_s1: 0.022831, loss_fp: 0.003969, loss_freq: 0.010992
[18:05:47.212] iteration 19869: loss: 0.058135, loss_s1: 0.044896, loss_fp: 0.003623, loss_freq: 0.035969
[18:05:47.836] iteration 19870: loss: 0.065092, loss_s1: 0.048931, loss_fp: 0.008794, loss_freq: 0.027052
[18:05:48.467] iteration 19871: loss: 0.066029, loss_s1: 0.038884, loss_fp: 0.004900, loss_freq: 0.047474
[18:05:49.091] iteration 19872: loss: 0.053106, loss_s1: 0.047413, loss_fp: 0.002744, loss_freq: 0.023701
[18:05:49.719] iteration 19873: loss: 0.068590, loss_s1: 0.062002, loss_fp: 0.000461, loss_freq: 0.026663
[18:05:50.346] iteration 19874: loss: 0.069466, loss_s1: 0.059198, loss_fp: 0.006113, loss_freq: 0.040505
[18:05:50.993] iteration 19875: loss: 0.060658, loss_s1: 0.043645, loss_fp: 0.004126, loss_freq: 0.029109
[18:05:51.663] iteration 19876: loss: 0.045188, loss_s1: 0.024711, loss_fp: 0.001721, loss_freq: 0.018302
[18:05:52.325] iteration 19877: loss: 0.050377, loss_s1: 0.042810, loss_fp: 0.011369, loss_freq: 0.008789
[18:05:52.988] iteration 19878: loss: 0.061396, loss_s1: 0.040987, loss_fp: 0.001436, loss_freq: 0.037980
[18:05:53.631] iteration 19879: loss: 0.063183, loss_s1: 0.039900, loss_fp: 0.002739, loss_freq: 0.040941
[18:05:54.286] iteration 19880: loss: 0.077187, loss_s1: 0.066001, loss_fp: 0.003136, loss_freq: 0.043598
[18:05:54.949] iteration 19881: loss: 0.042692, loss_s1: 0.028943, loss_fp: 0.008536, loss_freq: 0.017109
[18:05:55.611] iteration 19882: loss: 0.036658, loss_s1: 0.017613, loss_fp: 0.000943, loss_freq: 0.009064
[18:05:56.256] iteration 19883: loss: 0.064540, loss_s1: 0.046886, loss_fp: 0.006415, loss_freq: 0.038359
[18:05:56.896] iteration 19884: loss: 0.069423, loss_s1: 0.052584, loss_fp: 0.005492, loss_freq: 0.041316
[18:05:57.522] iteration 19885: loss: 0.119736, loss_s1: 0.127677, loss_fp: 0.001405, loss_freq: 0.049126
[18:05:58.145] iteration 19886: loss: 0.103160, loss_s1: 0.091578, loss_fp: 0.020814, loss_freq: 0.061839
[18:05:58.770] iteration 19887: loss: 0.072025, loss_s1: 0.038908, loss_fp: 0.004884, loss_freq: 0.056347
[18:05:59.395] iteration 19888: loss: 0.059792, loss_s1: 0.040676, loss_fp: 0.002448, loss_freq: 0.039853
[18:06:00.028] iteration 19889: loss: 0.031176, loss_s1: 0.018528, loss_fp: 0.001715, loss_freq: 0.010579
[18:06:00.656] iteration 19890: loss: 0.044452, loss_s1: 0.018764, loss_fp: 0.003021, loss_freq: 0.016585
[18:06:01.284] iteration 19891: loss: 0.047646, loss_s1: 0.029633, loss_fp: 0.008533, loss_freq: 0.024813
[18:06:01.910] iteration 19892: loss: 0.039344, loss_s1: 0.021093, loss_fp: 0.003754, loss_freq: 0.020303
[18:06:02.538] iteration 19893: loss: 0.066976, loss_s1: 0.055143, loss_fp: 0.003422, loss_freq: 0.037983
[18:06:03.161] iteration 19894: loss: 0.079038, loss_s1: 0.069822, loss_fp: 0.005851, loss_freq: 0.023895
[18:06:03.787] iteration 19895: loss: 0.061084, loss_s1: 0.036222, loss_fp: 0.001846, loss_freq: 0.012645
[18:06:04.414] iteration 19896: loss: 0.066258, loss_s1: 0.044473, loss_fp: 0.001568, loss_freq: 0.020766
[18:06:05.038] iteration 19897: loss: 0.047758, loss_s1: 0.034356, loss_fp: 0.000696, loss_freq: 0.017813
[18:06:05.661] iteration 19898: loss: 0.056056, loss_s1: 0.057485, loss_fp: 0.001894, loss_freq: 0.020404
[18:06:06.280] iteration 19899: loss: 0.041774, loss_s1: 0.016087, loss_fp: 0.003286, loss_freq: 0.029992
[18:06:06.904] iteration 19900: loss: 0.042319, loss_s1: 0.031002, loss_fp: 0.000779, loss_freq: 0.017270
[18:06:07.531] iteration 19901: loss: 0.043838, loss_s1: 0.024728, loss_fp: 0.001431, loss_freq: 0.014250
[18:06:08.239] iteration 19902: loss: 0.053149, loss_s1: 0.050970, loss_fp: 0.001993, loss_freq: 0.018702
[18:06:08.904] iteration 19903: loss: 0.068637, loss_s1: 0.051556, loss_fp: 0.006060, loss_freq: 0.031884
[18:06:09.539] iteration 19904: loss: 0.059071, loss_s1: 0.059274, loss_fp: 0.001009, loss_freq: 0.022057
[18:06:10.172] iteration 19905: loss: 0.059257, loss_s1: 0.031215, loss_fp: 0.002189, loss_freq: 0.047330
[18:06:10.799] iteration 19906: loss: 0.089786, loss_s1: 0.101407, loss_fp: 0.005346, loss_freq: 0.035981
[18:06:11.429] iteration 19907: loss: 0.044028, loss_s1: 0.030699, loss_fp: 0.002206, loss_freq: 0.009309
[18:06:12.052] iteration 19908: loss: 0.049879, loss_s1: 0.027005, loss_fp: 0.001057, loss_freq: 0.015879
[18:06:12.678] iteration 19909: loss: 0.045275, loss_s1: 0.031414, loss_fp: 0.005248, loss_freq: 0.024072
[18:06:13.299] iteration 19910: loss: 0.037214, loss_s1: 0.029439, loss_fp: 0.000413, loss_freq: 0.011780
[18:06:13.960] iteration 19911: loss: 0.078043, loss_s1: 0.076072, loss_fp: 0.006579, loss_freq: 0.016583
[18:06:14.882] iteration 19912: loss: 0.125232, loss_s1: 0.094075, loss_fp: 0.009961, loss_freq: 0.101798
[18:06:15.591] iteration 19913: loss: 0.048317, loss_s1: 0.035008, loss_fp: 0.003385, loss_freq: 0.021504
[18:06:16.284] iteration 19914: loss: 0.041090, loss_s1: 0.024759, loss_fp: 0.004382, loss_freq: 0.011145
[18:06:16.919] iteration 19915: loss: 0.034405, loss_s1: 0.016946, loss_fp: 0.003273, loss_freq: 0.013302
[18:06:17.534] iteration 19916: loss: 0.056107, loss_s1: 0.055225, loss_fp: 0.002834, loss_freq: 0.019860
[18:06:18.155] iteration 19917: loss: 0.052844, loss_s1: 0.028605, loss_fp: 0.002912, loss_freq: 0.046694
[18:06:18.778] iteration 19918: loss: 0.043527, loss_s1: 0.031428, loss_fp: 0.001299, loss_freq: 0.019197
[18:06:19.395] iteration 19919: loss: 0.056881, loss_s1: 0.043469, loss_fp: 0.015301, loss_freq: 0.017888
[18:06:20.015] iteration 19920: loss: 0.057606, loss_s1: 0.040017, loss_fp: 0.002880, loss_freq: 0.041350
[18:06:20.640] iteration 19921: loss: 0.041376, loss_s1: 0.022901, loss_fp: 0.003208, loss_freq: 0.024693
[18:06:21.264] iteration 19922: loss: 0.062045, loss_s1: 0.026645, loss_fp: 0.015268, loss_freq: 0.043884
[18:06:21.885] iteration 19923: loss: 0.090296, loss_s1: 0.064782, loss_fp: 0.001403, loss_freq: 0.088367
[18:06:22.503] iteration 19924: loss: 0.046864, loss_s1: 0.027786, loss_fp: 0.004148, loss_freq: 0.027392
[18:06:23.131] iteration 19925: loss: 0.060428, loss_s1: 0.025205, loss_fp: 0.003172, loss_freq: 0.039340
[18:06:23.747] iteration 19926: loss: 0.049088, loss_s1: 0.032588, loss_fp: 0.005494, loss_freq: 0.019286
[18:06:24.370] iteration 19927: loss: 0.048438, loss_s1: 0.024313, loss_fp: 0.000660, loss_freq: 0.032376
[18:06:24.995] iteration 19928: loss: 0.051483, loss_s1: 0.029253, loss_fp: 0.003365, loss_freq: 0.024625
[18:06:25.613] iteration 19929: loss: 0.049230, loss_s1: 0.022499, loss_fp: 0.008158, loss_freq: 0.019744
[18:06:26.238] iteration 19930: loss: 0.048075, loss_s1: 0.036006, loss_fp: 0.000729, loss_freq: 0.016934
[18:06:26.897] iteration 19931: loss: 0.119997, loss_s1: 0.133944, loss_fp: 0.009691, loss_freq: 0.048252
[18:06:27.559] iteration 19932: loss: 0.052497, loss_s1: 0.034494, loss_fp: 0.010462, loss_freq: 0.032358
[18:06:28.227] iteration 19933: loss: 0.029914, loss_s1: 0.013545, loss_fp: 0.000820, loss_freq: 0.013702
[18:06:28.870] iteration 19934: loss: 0.087826, loss_s1: 0.064454, loss_fp: 0.002776, loss_freq: 0.068032
[18:06:29.502] iteration 19935: loss: 0.069581, loss_s1: 0.052643, loss_fp: 0.002457, loss_freq: 0.051294
[18:06:30.129] iteration 19936: loss: 0.053472, loss_s1: 0.045034, loss_fp: 0.002989, loss_freq: 0.017418
[18:06:30.759] iteration 19937: loss: 0.046567, loss_s1: 0.024537, loss_fp: 0.006388, loss_freq: 0.014476
[18:06:31.387] iteration 19938: loss: 0.053008, loss_s1: 0.030281, loss_fp: 0.005663, loss_freq: 0.036413
[18:06:32.013] iteration 19939: loss: 0.055825, loss_s1: 0.050431, loss_fp: 0.005738, loss_freq: 0.021408
[18:06:32.639] iteration 19940: loss: 0.041837, loss_s1: 0.029355, loss_fp: 0.007105, loss_freq: 0.009162
[18:06:33.267] iteration 19941: loss: 0.044698, loss_s1: 0.024133, loss_fp: 0.007580, loss_freq: 0.024727
[18:06:33.894] iteration 19942: loss: 0.037593, loss_s1: 0.026446, loss_fp: 0.000879, loss_freq: 0.012289
[18:06:34.522] iteration 19943: loss: 0.086414, loss_s1: 0.082066, loss_fp: 0.005450, loss_freq: 0.040115
[18:06:35.148] iteration 19944: loss: 0.066200, loss_s1: 0.056566, loss_fp: 0.010859, loss_freq: 0.027621
[18:06:35.774] iteration 19945: loss: 0.046290, loss_s1: 0.028628, loss_fp: 0.002532, loss_freq: 0.019897
[18:06:36.403] iteration 19946: loss: 0.052121, loss_s1: 0.024638, loss_fp: 0.004320, loss_freq: 0.029746
[18:06:37.029] iteration 19947: loss: 0.076245, loss_s1: 0.071877, loss_fp: 0.004203, loss_freq: 0.027709
[18:06:37.654] iteration 19948: loss: 0.042987, loss_s1: 0.033836, loss_fp: 0.001812, loss_freq: 0.012323
[18:06:38.278] iteration 19949: loss: 0.071658, loss_s1: 0.040471, loss_fp: 0.024367, loss_freq: 0.040311
[18:06:38.897] iteration 19950: loss: 0.071239, loss_s1: 0.047748, loss_fp: 0.003367, loss_freq: 0.062590
[18:06:39.525] iteration 19951: loss: 0.036344, loss_s1: 0.032531, loss_fp: 0.001219, loss_freq: 0.008751
[18:06:40.154] iteration 19952: loss: 0.041091, loss_s1: 0.020598, loss_fp: 0.001734, loss_freq: 0.022020
[18:06:40.777] iteration 19953: loss: 0.075222, loss_s1: 0.046719, loss_fp: 0.001827, loss_freq: 0.058692
[18:06:41.409] iteration 19954: loss: 0.033557, loss_s1: 0.018469, loss_fp: 0.003833, loss_freq: 0.014484
[18:06:42.051] iteration 19955: loss: 0.097011, loss_s1: 0.071169, loss_fp: 0.012199, loss_freq: 0.073569
[18:06:42.683] iteration 19956: loss: 0.045166, loss_s1: 0.025586, loss_fp: 0.013899, loss_freq: 0.017812
[18:06:43.309] iteration 19957: loss: 0.080636, loss_s1: 0.062511, loss_fp: 0.009586, loss_freq: 0.027291
[18:06:43.936] iteration 19958: loss: 0.031340, loss_s1: 0.014048, loss_fp: 0.005901, loss_freq: 0.016803
[18:06:44.563] iteration 19959: loss: 0.064605, loss_s1: 0.039312, loss_fp: 0.003664, loss_freq: 0.032983
[18:06:45.198] iteration 19960: loss: 0.062382, loss_s1: 0.021419, loss_fp: 0.001383, loss_freq: 0.007041
[18:06:45.829] iteration 19961: loss: 0.064939, loss_s1: 0.054626, loss_fp: 0.010365, loss_freq: 0.020679
[18:06:46.456] iteration 19962: loss: 0.055628, loss_s1: 0.036570, loss_fp: 0.012939, loss_freq: 0.021743
[18:06:47.076] iteration 19963: loss: 0.052551, loss_s1: 0.043192, loss_fp: 0.003699, loss_freq: 0.016056
[18:06:47.698] iteration 19964: loss: 0.055798, loss_s1: 0.031261, loss_fp: 0.006059, loss_freq: 0.016471
[18:06:48.729] iteration 19965: loss: 0.052661, loss_s1: 0.059864, loss_fp: 0.002823, loss_freq: 0.007159
[18:06:49.352] iteration 19966: loss: 0.049485, loss_s1: 0.028266, loss_fp: 0.006179, loss_freq: 0.019020
[18:06:49.975] iteration 19967: loss: 0.058351, loss_s1: 0.065190, loss_fp: 0.001933, loss_freq: 0.008673
[18:06:50.601] iteration 19968: loss: 0.040824, loss_s1: 0.025346, loss_fp: 0.000574, loss_freq: 0.013133
[18:06:51.228] iteration 19969: loss: 0.064181, loss_s1: 0.037299, loss_fp: 0.000793, loss_freq: 0.019671
[18:06:51.890] iteration 19970: loss: 0.111297, loss_s1: 0.109089, loss_fp: 0.007722, loss_freq: 0.065744
[18:06:52.556] iteration 19971: loss: 0.039519, loss_s1: 0.026967, loss_fp: 0.002628, loss_freq: 0.015702
[18:06:53.195] iteration 19972: loss: 0.045634, loss_s1: 0.027638, loss_fp: 0.001894, loss_freq: 0.025017
[18:06:53.825] iteration 19973: loss: 0.054345, loss_s1: 0.044207, loss_fp: 0.004292, loss_freq: 0.033077
[18:06:54.454] iteration 19974: loss: 0.048420, loss_s1: 0.041314, loss_fp: 0.000994, loss_freq: 0.016876
[18:06:55.080] iteration 19975: loss: 0.028378, loss_s1: 0.009685, loss_fp: 0.000260, loss_freq: 0.007731
[18:06:55.712] iteration 19976: loss: 0.078640, loss_s1: 0.083883, loss_fp: 0.007172, loss_freq: 0.033269
[18:06:56.368] iteration 19977: loss: 0.089869, loss_s1: 0.067606, loss_fp: 0.005045, loss_freq: 0.079229
[18:06:57.041] iteration 19978: loss: 0.059584, loss_s1: 0.041104, loss_fp: 0.005250, loss_freq: 0.036512
[18:06:57.719] iteration 19979: loss: 0.077340, loss_s1: 0.043838, loss_fp: 0.015879, loss_freq: 0.046332
[18:06:58.346] iteration 19980: loss: 0.099435, loss_s1: 0.124272, loss_fp: 0.004347, loss_freq: 0.032696
[18:06:58.976] iteration 19981: loss: 0.038279, loss_s1: 0.026716, loss_fp: 0.001428, loss_freq: 0.012618
[18:06:59.605] iteration 19982: loss: 0.080535, loss_s1: 0.081119, loss_fp: 0.007965, loss_freq: 0.035740
[18:07:00.290] iteration 19983: loss: 0.045655, loss_s1: 0.025039, loss_fp: 0.000621, loss_freq: 0.023604
[18:07:00.922] iteration 19984: loss: 0.045542, loss_s1: 0.028712, loss_fp: 0.004395, loss_freq: 0.018200
[18:07:01.549] iteration 19985: loss: 0.043314, loss_s1: 0.042970, loss_fp: 0.001303, loss_freq: 0.005208
[18:07:02.203] iteration 19986: loss: 0.037614, loss_s1: 0.018425, loss_fp: 0.000688, loss_freq: 0.010579
[18:07:02.832] iteration 19987: loss: 0.069759, loss_s1: 0.053911, loss_fp: 0.001039, loss_freq: 0.031296
[18:07:03.452] iteration 19988: loss: 0.068772, loss_s1: 0.047008, loss_fp: 0.009946, loss_freq: 0.048294
[18:07:04.115] iteration 19989: loss: 0.062426, loss_s1: 0.052669, loss_fp: 0.001860, loss_freq: 0.028322
[18:07:04.770] iteration 19990: loss: 0.052094, loss_s1: 0.040436, loss_fp: 0.001157, loss_freq: 0.023107
[18:07:05.435] iteration 19991: loss: 0.041361, loss_s1: 0.028923, loss_fp: 0.000977, loss_freq: 0.007058
[18:07:06.064] iteration 19992: loss: 0.081943, loss_s1: 0.055861, loss_fp: 0.007239, loss_freq: 0.046689
[18:07:06.691] iteration 19993: loss: 0.064375, loss_s1: 0.039340, loss_fp: 0.011371, loss_freq: 0.047115
[18:07:07.311] iteration 19994: loss: 0.047073, loss_s1: 0.035069, loss_fp: 0.005193, loss_freq: 0.018170
[18:07:07.931] iteration 19995: loss: 0.042127, loss_s1: 0.031144, loss_fp: 0.002859, loss_freq: 0.017787
[18:07:08.551] iteration 19996: loss: 0.050069, loss_s1: 0.031706, loss_fp: 0.004262, loss_freq: 0.021521
[18:07:09.176] iteration 19997: loss: 0.052229, loss_s1: 0.039987, loss_fp: 0.003338, loss_freq: 0.028515
[18:07:09.802] iteration 19998: loss: 0.045341, loss_s1: 0.035154, loss_fp: 0.003880, loss_freq: 0.009333
[18:07:10.424] iteration 19999: loss: 0.098217, loss_s1: 0.078746, loss_fp: 0.003047, loss_freq: 0.042898
[18:07:11.052] iteration 20000: loss: 0.072557, loss_s1: 0.058332, loss_fp: 0.012437, loss_freq: 0.043552
[18:07:14.394] iteration 20000 : mean_dice : 0.707508
[18:07:15.114] iteration 20001: loss: 0.079348, loss_s1: 0.056284, loss_fp: 0.003109, loss_freq: 0.027930
[18:07:15.780] iteration 20002: loss: 0.060401, loss_s1: 0.049061, loss_fp: 0.001612, loss_freq: 0.032600
[18:07:16.403] iteration 20003: loss: 0.073019, loss_s1: 0.051890, loss_fp: 0.001417, loss_freq: 0.052203
[18:07:17.031] iteration 20004: loss: 0.068831, loss_s1: 0.064692, loss_fp: 0.011095, loss_freq: 0.028312
[18:07:17.656] iteration 20005: loss: 0.041673, loss_s1: 0.019385, loss_fp: 0.001164, loss_freq: 0.009678
[18:07:18.286] iteration 20006: loss: 0.078709, loss_s1: 0.083594, loss_fp: 0.005079, loss_freq: 0.030096
[18:07:18.917] iteration 20007: loss: 0.051566, loss_s1: 0.048128, loss_fp: 0.002103, loss_freq: 0.022679
[18:07:19.538] iteration 20008: loss: 0.046968, loss_s1: 0.041219, loss_fp: 0.002581, loss_freq: 0.020055
[18:07:20.167] iteration 20009: loss: 0.070053, loss_s1: 0.059501, loss_fp: 0.001810, loss_freq: 0.043706
[18:07:20.795] iteration 20010: loss: 0.043766, loss_s1: 0.043234, loss_fp: 0.002600, loss_freq: 0.007043
[18:07:21.429] iteration 20011: loss: 0.035013, loss_s1: 0.016784, loss_fp: 0.000587, loss_freq: 0.003592
[18:07:22.055] iteration 20012: loss: 0.050873, loss_s1: 0.031206, loss_fp: 0.004945, loss_freq: 0.038237
[18:07:22.681] iteration 20013: loss: 0.072019, loss_s1: 0.090464, loss_fp: 0.005922, loss_freq: 0.007587
[18:07:23.316] iteration 20014: loss: 0.047767, loss_s1: 0.025403, loss_fp: 0.008702, loss_freq: 0.027995
[18:07:23.940] iteration 20015: loss: 0.054488, loss_s1: 0.040097, loss_fp: 0.008373, loss_freq: 0.028048
[18:07:24.564] iteration 20016: loss: 0.069137, loss_s1: 0.062966, loss_fp: 0.009323, loss_freq: 0.022301
[18:07:25.189] iteration 20017: loss: 0.054390, loss_s1: 0.029620, loss_fp: 0.005252, loss_freq: 0.030524
[18:07:25.808] iteration 20018: loss: 0.076437, loss_s1: 0.066065, loss_fp: 0.006297, loss_freq: 0.042717
[18:07:26.436] iteration 20019: loss: 0.046803, loss_s1: 0.024118, loss_fp: 0.002962, loss_freq: 0.017094
[18:07:27.057] iteration 20020: loss: 0.082864, loss_s1: 0.083029, loss_fp: 0.004962, loss_freq: 0.034715
[18:07:27.685] iteration 20021: loss: 0.033780, loss_s1: 0.018380, loss_fp: 0.001753, loss_freq: 0.008088
[18:07:28.307] iteration 20022: loss: 0.063814, loss_s1: 0.048403, loss_fp: 0.005938, loss_freq: 0.018644
[18:07:28.928] iteration 20023: loss: 0.036804, loss_s1: 0.025567, loss_fp: 0.001744, loss_freq: 0.012021
[18:07:29.549] iteration 20024: loss: 0.049477, loss_s1: 0.029873, loss_fp: 0.004096, loss_freq: 0.030099
[18:07:30.171] iteration 20025: loss: 0.056778, loss_s1: 0.038593, loss_fp: 0.002514, loss_freq: 0.032852
[18:07:30.860] iteration 20026: loss: 0.052789, loss_s1: 0.051791, loss_fp: 0.005867, loss_freq: 0.018612
[18:07:31.501] iteration 20027: loss: 0.092128, loss_s1: 0.062946, loss_fp: 0.000889, loss_freq: 0.037316
[18:07:32.133] iteration 20028: loss: 0.085762, loss_s1: 0.095430, loss_fp: 0.001675, loss_freq: 0.040852
[18:07:32.760] iteration 20029: loss: 0.047498, loss_s1: 0.030302, loss_fp: 0.011514, loss_freq: 0.016965
[18:07:33.383] iteration 20030: loss: 0.090553, loss_s1: 0.051393, loss_fp: 0.013386, loss_freq: 0.076356
[18:07:34.010] iteration 20031: loss: 0.057683, loss_s1: 0.042817, loss_fp: 0.001340, loss_freq: 0.025671
[18:07:34.639] iteration 20032: loss: 0.069521, loss_s1: 0.055529, loss_fp: 0.002066, loss_freq: 0.052007
[18:07:35.263] iteration 20033: loss: 0.061299, loss_s1: 0.058334, loss_fp: 0.008906, loss_freq: 0.016683
[18:07:35.891] iteration 20034: loss: 0.090785, loss_s1: 0.075124, loss_fp: 0.003303, loss_freq: 0.027551
[18:07:36.522] iteration 20035: loss: 0.098887, loss_s1: 0.065094, loss_fp: 0.014911, loss_freq: 0.061647
[18:07:37.147] iteration 20036: loss: 0.057392, loss_s1: 0.052504, loss_fp: 0.003640, loss_freq: 0.027897
[18:07:37.777] iteration 20037: loss: 0.043343, loss_s1: 0.040190, loss_fp: 0.001016, loss_freq: 0.010143
[18:07:38.406] iteration 20038: loss: 0.042766, loss_s1: 0.032363, loss_fp: 0.001311, loss_freq: 0.007800
[18:07:39.038] iteration 20039: loss: 0.094573, loss_s1: 0.107918, loss_fp: 0.002585, loss_freq: 0.031704
[18:07:39.659] iteration 20040: loss: 0.045623, loss_s1: 0.019150, loss_fp: 0.008841, loss_freq: 0.018652
[18:07:40.288] iteration 20041: loss: 0.079029, loss_s1: 0.055907, loss_fp: 0.005784, loss_freq: 0.061522
[18:07:40.909] iteration 20042: loss: 0.063974, loss_s1: 0.048745, loss_fp: 0.005167, loss_freq: 0.034937
[18:07:41.538] iteration 20043: loss: 0.036633, loss_s1: 0.029828, loss_fp: 0.000707, loss_freq: 0.009259
[18:07:42.157] iteration 20044: loss: 0.054225, loss_s1: 0.036940, loss_fp: 0.004793, loss_freq: 0.031553
[18:07:42.786] iteration 20045: loss: 0.043245, loss_s1: 0.033566, loss_fp: 0.004365, loss_freq: 0.007239
[18:07:43.408] iteration 20046: loss: 0.083132, loss_s1: 0.096922, loss_fp: 0.002413, loss_freq: 0.034944
[18:07:44.035] iteration 20047: loss: 0.077174, loss_s1: 0.070144, loss_fp: 0.006229, loss_freq: 0.049000
[18:07:44.663] iteration 20048: loss: 0.072252, loss_s1: 0.051054, loss_fp: 0.003731, loss_freq: 0.056510
[18:07:45.287] iteration 20049: loss: 0.082297, loss_s1: 0.079823, loss_fp: 0.007023, loss_freq: 0.044769
[18:07:45.916] iteration 20050: loss: 0.044242, loss_s1: 0.033767, loss_fp: 0.001637, loss_freq: 0.019584
[18:07:46.536] iteration 20051: loss: 0.060006, loss_s1: 0.036231, loss_fp: 0.008763, loss_freq: 0.035916
[18:07:47.164] iteration 20052: loss: 0.044684, loss_s1: 0.035991, loss_fp: 0.002877, loss_freq: 0.011558
[18:07:47.823] iteration 20053: loss: 0.039089, loss_s1: 0.022781, loss_fp: 0.003987, loss_freq: 0.014264
[18:07:48.479] iteration 20054: loss: 0.068283, loss_s1: 0.057486, loss_fp: 0.005663, loss_freq: 0.035172
[18:07:49.144] iteration 20055: loss: 0.064679, loss_s1: 0.057031, loss_fp: 0.004330, loss_freq: 0.015579
[18:07:49.807] iteration 20056: loss: 0.069169, loss_s1: 0.054150, loss_fp: 0.000946, loss_freq: 0.031413
[18:07:50.477] iteration 20057: loss: 0.104740, loss_s1: 0.045008, loss_fp: 0.002116, loss_freq: 0.039869
[18:07:51.128] iteration 20058: loss: 0.040522, loss_s1: 0.026362, loss_fp: 0.000995, loss_freq: 0.016271
[18:07:51.762] iteration 20059: loss: 0.036491, loss_s1: 0.018616, loss_fp: 0.001067, loss_freq: 0.010736
[18:07:52.395] iteration 20060: loss: 0.052041, loss_s1: 0.032006, loss_fp: 0.004237, loss_freq: 0.039081
[18:07:53.028] iteration 20061: loss: 0.037303, loss_s1: 0.021152, loss_fp: 0.003193, loss_freq: 0.016366
[18:07:53.659] iteration 20062: loss: 0.038276, loss_s1: 0.018375, loss_fp: 0.000655, loss_freq: 0.009997
[18:07:54.288] iteration 20063: loss: 0.051962, loss_s1: 0.048353, loss_fp: 0.004017, loss_freq: 0.017132
[18:07:54.922] iteration 20064: loss: 0.050852, loss_s1: 0.049295, loss_fp: 0.002728, loss_freq: 0.016105
[18:07:55.549] iteration 20065: loss: 0.064126, loss_s1: 0.065843, loss_fp: 0.001889, loss_freq: 0.026351
[18:07:56.170] iteration 20066: loss: 0.061928, loss_s1: 0.030868, loss_fp: 0.007400, loss_freq: 0.043733
[18:07:56.804] iteration 20067: loss: 0.086451, loss_s1: 0.075320, loss_fp: 0.003020, loss_freq: 0.061486
[18:07:57.433] iteration 20068: loss: 0.071855, loss_s1: 0.071880, loss_fp: 0.003078, loss_freq: 0.021113
[18:07:58.054] iteration 20069: loss: 0.055487, loss_s1: 0.040704, loss_fp: 0.001501, loss_freq: 0.023164
[18:07:58.684] iteration 20070: loss: 0.039751, loss_s1: 0.027539, loss_fp: 0.006194, loss_freq: 0.014851
[18:07:59.313] iteration 20071: loss: 0.030549, loss_s1: 0.010118, loss_fp: 0.001938, loss_freq: 0.012566
[18:07:59.937] iteration 20072: loss: 0.058027, loss_s1: 0.047617, loss_fp: 0.001532, loss_freq: 0.023635
[18:08:00.564] iteration 20073: loss: 0.099390, loss_s1: 0.071178, loss_fp: 0.003119, loss_freq: 0.075648
[18:08:01.194] iteration 20074: loss: 0.062104, loss_s1: 0.044807, loss_fp: 0.008274, loss_freq: 0.032184
[18:08:01.821] iteration 20075: loss: 0.044870, loss_s1: 0.036309, loss_fp: 0.002000, loss_freq: 0.007722
[18:08:02.446] iteration 20076: loss: 0.069162, loss_s1: 0.051386, loss_fp: 0.007677, loss_freq: 0.042318
[18:08:03.116] iteration 20077: loss: 0.063315, loss_s1: 0.052250, loss_fp: 0.003161, loss_freq: 0.035406
[18:08:03.749] iteration 20078: loss: 0.043684, loss_s1: 0.028130, loss_fp: 0.004027, loss_freq: 0.017417
[18:08:04.375] iteration 20079: loss: 0.032648, loss_s1: 0.018414, loss_fp: 0.002593, loss_freq: 0.009006
[18:08:05.002] iteration 20080: loss: 0.087410, loss_s1: 0.073808, loss_fp: 0.002905, loss_freq: 0.056796
[18:08:05.628] iteration 20081: loss: 0.061054, loss_s1: 0.044448, loss_fp: 0.000853, loss_freq: 0.039168
[18:08:06.287] iteration 20082: loss: 0.065862, loss_s1: 0.084648, loss_fp: 0.003099, loss_freq: 0.010924
[18:08:06.950] iteration 20083: loss: 0.064318, loss_s1: 0.023238, loss_fp: 0.008788, loss_freq: 0.055643
[18:08:07.616] iteration 20084: loss: 0.070687, loss_s1: 0.057505, loss_fp: 0.003445, loss_freq: 0.051089
[18:08:08.284] iteration 20085: loss: 0.096062, loss_s1: 0.043432, loss_fp: 0.002650, loss_freq: 0.100734
[18:08:08.948] iteration 20086: loss: 0.034546, loss_s1: 0.015842, loss_fp: 0.002509, loss_freq: 0.012505
[18:08:09.580] iteration 20087: loss: 0.075347, loss_s1: 0.077555, loss_fp: 0.007100, loss_freq: 0.027325
[18:08:10.211] iteration 20088: loss: 0.027082, loss_s1: 0.012193, loss_fp: 0.001869, loss_freq: 0.002801
[18:08:10.840] iteration 20089: loss: 0.055652, loss_s1: 0.021680, loss_fp: 0.001227, loss_freq: 0.043143
[18:08:11.472] iteration 20090: loss: 0.041468, loss_s1: 0.031251, loss_fp: 0.002524, loss_freq: 0.010970
[18:08:12.100] iteration 20091: loss: 0.039227, loss_s1: 0.021766, loss_fp: 0.000822, loss_freq: 0.008528
[18:08:12.729] iteration 20092: loss: 0.079741, loss_s1: 0.056952, loss_fp: 0.000957, loss_freq: 0.009530
[18:08:13.361] iteration 20093: loss: 0.066790, loss_s1: 0.065829, loss_fp: 0.009222, loss_freq: 0.020169
[18:08:13.994] iteration 20094: loss: 0.048121, loss_s1: 0.041547, loss_fp: 0.007579, loss_freq: 0.014966
[18:08:14.628] iteration 20095: loss: 0.114726, loss_s1: 0.130939, loss_fp: 0.003743, loss_freq: 0.063953
[18:08:15.264] iteration 20096: loss: 0.062451, loss_s1: 0.071384, loss_fp: 0.002106, loss_freq: 0.022181
[18:08:15.897] iteration 20097: loss: 0.068971, loss_s1: 0.082588, loss_fp: 0.001491, loss_freq: 0.019231
[18:08:16.527] iteration 20098: loss: 0.045718, loss_s1: 0.045072, loss_fp: 0.001946, loss_freq: 0.008253
[18:08:17.343] iteration 20099: loss: 0.072377, loss_s1: 0.047605, loss_fp: 0.000977, loss_freq: 0.062712
[18:08:18.015] iteration 20100: loss: 0.054883, loss_s1: 0.053392, loss_fp: 0.002150, loss_freq: 0.023645
[18:08:18.661] iteration 20101: loss: 0.034624, loss_s1: 0.006685, loss_fp: 0.000879, loss_freq: 0.005834
[18:08:19.296] iteration 20102: loss: 0.043897, loss_s1: 0.027196, loss_fp: 0.004014, loss_freq: 0.025472
[18:08:19.920] iteration 20103: loss: 0.050260, loss_s1: 0.027160, loss_fp: 0.001827, loss_freq: 0.022996
[18:08:20.547] iteration 20104: loss: 0.059678, loss_s1: 0.045440, loss_fp: 0.002503, loss_freq: 0.019540
[18:08:21.171] iteration 20105: loss: 0.073389, loss_s1: 0.061276, loss_fp: 0.009212, loss_freq: 0.045300
[18:08:21.796] iteration 20106: loss: 0.082971, loss_s1: 0.040377, loss_fp: 0.008847, loss_freq: 0.035598
[18:08:22.414] iteration 20107: loss: 0.075981, loss_s1: 0.060981, loss_fp: 0.009599, loss_freq: 0.042729
[18:08:23.038] iteration 20108: loss: 0.080081, loss_s1: 0.084999, loss_fp: 0.003641, loss_freq: 0.028030
[18:08:23.664] iteration 20109: loss: 0.054840, loss_s1: 0.027703, loss_fp: 0.004008, loss_freq: 0.010035
[18:08:24.288] iteration 20110: loss: 0.063184, loss_s1: 0.049255, loss_fp: 0.005575, loss_freq: 0.019048
[18:08:24.908] iteration 20111: loss: 0.096530, loss_s1: 0.069765, loss_fp: 0.009200, loss_freq: 0.086043
[18:08:25.527] iteration 20112: loss: 0.064264, loss_s1: 0.040854, loss_fp: 0.005618, loss_freq: 0.015285
[18:08:26.150] iteration 20113: loss: 0.055531, loss_s1: 0.028970, loss_fp: 0.009048, loss_freq: 0.022542
[18:08:26.779] iteration 20114: loss: 0.082778, loss_s1: 0.080074, loss_fp: 0.003901, loss_freq: 0.037516
[18:08:27.402] iteration 20115: loss: 0.045390, loss_s1: 0.028406, loss_fp: 0.002026, loss_freq: 0.021359
[18:08:28.026] iteration 20116: loss: 0.061846, loss_s1: 0.026489, loss_fp: 0.003968, loss_freq: 0.054293
[18:08:28.652] iteration 20117: loss: 0.049124, loss_s1: 0.030338, loss_fp: 0.002365, loss_freq: 0.025360
[18:08:29.288] iteration 20118: loss: 0.063079, loss_s1: 0.033177, loss_fp: 0.004016, loss_freq: 0.037906
[18:08:29.925] iteration 20119: loss: 0.033738, loss_s1: 0.028663, loss_fp: 0.000489, loss_freq: 0.005494
[18:08:30.564] iteration 20120: loss: 0.051192, loss_s1: 0.045113, loss_fp: 0.002407, loss_freq: 0.016212
[18:08:31.188] iteration 20121: loss: 0.049730, loss_s1: 0.029839, loss_fp: 0.001184, loss_freq: 0.026073
[18:08:31.810] iteration 20122: loss: 0.083643, loss_s1: 0.028075, loss_fp: 0.016452, loss_freq: 0.069537
[18:08:32.432] iteration 20123: loss: 0.057346, loss_s1: 0.052852, loss_fp: 0.007405, loss_freq: 0.021084
[18:08:33.055] iteration 20124: loss: 0.063051, loss_s1: 0.068185, loss_fp: 0.002251, loss_freq: 0.023889
[18:08:33.671] iteration 20125: loss: 0.049205, loss_s1: 0.018417, loss_fp: 0.002607, loss_freq: 0.038091
[18:08:34.641] iteration 20126: loss: 0.046529, loss_s1: 0.045318, loss_fp: 0.001204, loss_freq: 0.014374
[18:08:35.271] iteration 20127: loss: 0.069908, loss_s1: 0.057945, loss_fp: 0.004828, loss_freq: 0.027615
[18:08:35.901] iteration 20128: loss: 0.033575, loss_s1: 0.022510, loss_fp: 0.002495, loss_freq: 0.005403
[18:08:36.526] iteration 20129: loss: 0.051900, loss_s1: 0.021085, loss_fp: 0.002200, loss_freq: 0.014423
[18:08:37.151] iteration 20130: loss: 0.057945, loss_s1: 0.045844, loss_fp: 0.015349, loss_freq: 0.020016
[18:08:37.777] iteration 20131: loss: 0.086213, loss_s1: 0.045305, loss_fp: 0.013084, loss_freq: 0.045903
[18:08:38.407] iteration 20132: loss: 0.040952, loss_s1: 0.031894, loss_fp: 0.002666, loss_freq: 0.008943
[18:08:39.030] iteration 20133: loss: 0.050332, loss_s1: 0.027589, loss_fp: 0.000709, loss_freq: 0.013656
[18:08:39.660] iteration 20134: loss: 0.069918, loss_s1: 0.095261, loss_fp: 0.004862, loss_freq: 0.013467
[18:08:40.290] iteration 20135: loss: 0.071757, loss_s1: 0.082001, loss_fp: 0.003226, loss_freq: 0.023346
[18:08:40.911] iteration 20136: loss: 0.038895, loss_s1: 0.029262, loss_fp: 0.001299, loss_freq: 0.008238
[18:08:41.538] iteration 20137: loss: 0.104528, loss_s1: 0.086158, loss_fp: 0.010903, loss_freq: 0.075266
[18:08:42.165] iteration 20138: loss: 0.056043, loss_s1: 0.038741, loss_fp: 0.003544, loss_freq: 0.038800
[18:08:42.787] iteration 20139: loss: 0.066409, loss_s1: 0.045071, loss_fp: 0.003581, loss_freq: 0.027963
[18:08:43.414] iteration 20140: loss: 0.051381, loss_s1: 0.043223, loss_fp: 0.002207, loss_freq: 0.027761
[18:08:44.041] iteration 20141: loss: 0.123291, loss_s1: 0.121273, loss_fp: 0.006918, loss_freq: 0.084248
[18:08:44.670] iteration 20142: loss: 0.052415, loss_s1: 0.050135, loss_fp: 0.004624, loss_freq: 0.014438
[18:08:45.297] iteration 20143: loss: 0.112594, loss_s1: 0.110529, loss_fp: 0.000740, loss_freq: 0.066849
[18:08:45.921] iteration 20144: loss: 0.038499, loss_s1: 0.014657, loss_fp: 0.000939, loss_freq: 0.026375
[18:08:46.550] iteration 20145: loss: 0.051470, loss_s1: 0.034941, loss_fp: 0.000824, loss_freq: 0.017033
[18:08:47.178] iteration 20146: loss: 0.035612, loss_s1: 0.021963, loss_fp: 0.000471, loss_freq: 0.004818
[18:08:47.807] iteration 20147: loss: 0.043642, loss_s1: 0.042558, loss_fp: 0.001726, loss_freq: 0.009858
[18:08:48.439] iteration 20148: loss: 0.069737, loss_s1: 0.042167, loss_fp: 0.001727, loss_freq: 0.036519
[18:08:49.060] iteration 20149: loss: 0.071269, loss_s1: 0.055478, loss_fp: 0.001968, loss_freq: 0.055936
[18:08:49.690] iteration 20150: loss: 0.040291, loss_s1: 0.036695, loss_fp: 0.001568, loss_freq: 0.016063
[18:08:50.319] iteration 20151: loss: 0.065426, loss_s1: 0.074570, loss_fp: 0.001383, loss_freq: 0.013999
[18:08:50.945] iteration 20152: loss: 0.035129, loss_s1: 0.025870, loss_fp: 0.000801, loss_freq: 0.002265
[18:08:51.563] iteration 20153: loss: 0.108939, loss_s1: 0.099784, loss_fp: 0.015018, loss_freq: 0.054735
[18:08:52.181] iteration 20154: loss: 0.068823, loss_s1: 0.051239, loss_fp: 0.006466, loss_freq: 0.049226
[18:08:52.846] iteration 20155: loss: 0.046973, loss_s1: 0.027882, loss_fp: 0.001370, loss_freq: 0.006761
[18:08:53.506] iteration 20156: loss: 0.036395, loss_s1: 0.029254, loss_fp: 0.000839, loss_freq: 0.014368
[18:08:54.165] iteration 20157: loss: 0.052193, loss_s1: 0.047016, loss_fp: 0.002734, loss_freq: 0.015854
[18:08:54.805] iteration 20158: loss: 0.049059, loss_s1: 0.048286, loss_fp: 0.002092, loss_freq: 0.018903
[18:08:55.438] iteration 20159: loss: 0.041252, loss_s1: 0.042348, loss_fp: 0.000942, loss_freq: 0.007332
[18:08:56.071] iteration 20160: loss: 0.055226, loss_s1: 0.040471, loss_fp: 0.006532, loss_freq: 0.022547
[18:08:56.697] iteration 20161: loss: 0.059667, loss_s1: 0.022734, loss_fp: 0.004696, loss_freq: 0.035604
[18:08:57.321] iteration 20162: loss: 0.079199, loss_s1: 0.078885, loss_fp: 0.001860, loss_freq: 0.033433
[18:08:57.946] iteration 20163: loss: 0.057182, loss_s1: 0.049630, loss_fp: 0.002033, loss_freq: 0.013705
[18:08:58.578] iteration 20164: loss: 0.068224, loss_s1: 0.081506, loss_fp: 0.000553, loss_freq: 0.010625
[18:08:59.206] iteration 20165: loss: 0.041411, loss_s1: 0.026526, loss_fp: 0.002488, loss_freq: 0.015363
[18:08:59.832] iteration 20166: loss: 0.053600, loss_s1: 0.050945, loss_fp: 0.004026, loss_freq: 0.010115
[18:09:00.468] iteration 20167: loss: 0.082703, loss_s1: 0.086728, loss_fp: 0.003103, loss_freq: 0.038064
[18:09:01.093] iteration 20168: loss: 0.073151, loss_s1: 0.061977, loss_fp: 0.017092, loss_freq: 0.037587
[18:09:01.727] iteration 20169: loss: 0.069061, loss_s1: 0.040605, loss_fp: 0.006840, loss_freq: 0.036609
[18:09:02.355] iteration 20170: loss: 0.065866, loss_s1: 0.069253, loss_fp: 0.000967, loss_freq: 0.020077
[18:09:02.979] iteration 20171: loss: 0.051349, loss_s1: 0.062503, loss_fp: 0.002283, loss_freq: 0.004380
[18:09:03.601] iteration 20172: loss: 0.027865, loss_s1: 0.019439, loss_fp: 0.000420, loss_freq: 0.007092
[18:09:04.229] iteration 20173: loss: 0.050622, loss_s1: 0.035318, loss_fp: 0.004654, loss_freq: 0.015756
[18:09:04.854] iteration 20174: loss: 0.037740, loss_s1: 0.029480, loss_fp: 0.001595, loss_freq: 0.006080
[18:09:05.484] iteration 20175: loss: 0.056924, loss_s1: 0.031955, loss_fp: 0.002268, loss_freq: 0.045947
[18:09:06.105] iteration 20176: loss: 0.080634, loss_s1: 0.070705, loss_fp: 0.005193, loss_freq: 0.054163
[18:09:06.735] iteration 20177: loss: 0.054151, loss_s1: 0.049665, loss_fp: 0.002754, loss_freq: 0.016530
[18:09:07.364] iteration 20178: loss: 0.055539, loss_s1: 0.040327, loss_fp: 0.003248, loss_freq: 0.030553
[18:09:07.996] iteration 20179: loss: 0.068204, loss_s1: 0.050873, loss_fp: 0.002203, loss_freq: 0.037379
[18:09:08.627] iteration 20180: loss: 0.037790, loss_s1: 0.017865, loss_fp: 0.001071, loss_freq: 0.019816
[18:09:09.256] iteration 20181: loss: 0.044079, loss_s1: 0.021773, loss_fp: 0.002811, loss_freq: 0.023544
[18:09:09.882] iteration 20182: loss: 0.061283, loss_s1: 0.056137, loss_fp: 0.006632, loss_freq: 0.023996
[18:09:10.506] iteration 20183: loss: 0.063692, loss_s1: 0.025042, loss_fp: 0.000606, loss_freq: 0.026209
[18:09:11.129] iteration 20184: loss: 0.045541, loss_s1: 0.040836, loss_fp: 0.004810, loss_freq: 0.015622
[18:09:11.757] iteration 20185: loss: 0.038306, loss_s1: 0.035513, loss_fp: 0.003745, loss_freq: 0.012140
[18:09:12.389] iteration 20186: loss: 0.037096, loss_s1: 0.017994, loss_fp: 0.003659, loss_freq: 0.017510
[18:09:13.013] iteration 20187: loss: 0.037674, loss_s1: 0.015422, loss_fp: 0.005431, loss_freq: 0.021822
[18:09:13.641] iteration 20188: loss: 0.047659, loss_s1: 0.017516, loss_fp: 0.004590, loss_freq: 0.032061
[18:09:14.273] iteration 20189: loss: 0.043139, loss_s1: 0.029809, loss_fp: 0.002253, loss_freq: 0.014518
[18:09:14.901] iteration 20190: loss: 0.060102, loss_s1: 0.062121, loss_fp: 0.001970, loss_freq: 0.015858
[18:09:15.527] iteration 20191: loss: 0.051393, loss_s1: 0.020079, loss_fp: 0.004288, loss_freq: 0.049093
[18:09:16.150] iteration 20192: loss: 0.058812, loss_s1: 0.051186, loss_fp: 0.004734, loss_freq: 0.024818
[18:09:16.774] iteration 20193: loss: 0.058766, loss_s1: 0.036087, loss_fp: 0.003167, loss_freq: 0.050756
[18:09:17.403] iteration 20194: loss: 0.049778, loss_s1: 0.038288, loss_fp: 0.004106, loss_freq: 0.025440
[18:09:18.029] iteration 20195: loss: 0.077655, loss_s1: 0.045383, loss_fp: 0.002617, loss_freq: 0.045344
[18:09:18.658] iteration 20196: loss: 0.095434, loss_s1: 0.077305, loss_fp: 0.015376, loss_freq: 0.023849
[18:09:19.284] iteration 20197: loss: 0.051932, loss_s1: 0.020972, loss_fp: 0.001722, loss_freq: 0.030694
[18:09:19.912] iteration 20198: loss: 0.048051, loss_s1: 0.039155, loss_fp: 0.004617, loss_freq: 0.014320
[18:09:20.544] iteration 20199: loss: 0.039567, loss_s1: 0.029538, loss_fp: 0.003851, loss_freq: 0.010989
[18:09:21.179] iteration 20200: loss: 0.055715, loss_s1: 0.064412, loss_fp: 0.000841, loss_freq: 0.013217
[18:09:24.558] iteration 20200 : mean_dice : 0.740344
[18:09:25.247] iteration 20201: loss: 0.066700, loss_s1: 0.053102, loss_fp: 0.005113, loss_freq: 0.010366
[18:09:25.904] iteration 20202: loss: 0.061804, loss_s1: 0.070394, loss_fp: 0.004601, loss_freq: 0.019968
[18:09:26.554] iteration 20203: loss: 0.046649, loss_s1: 0.029252, loss_fp: 0.015631, loss_freq: 0.012669
[18:09:27.183] iteration 20204: loss: 0.027742, loss_s1: 0.019521, loss_fp: 0.001044, loss_freq: 0.008758
[18:09:27.813] iteration 20205: loss: 0.063406, loss_s1: 0.041817, loss_fp: 0.002009, loss_freq: 0.035225
[18:09:28.433] iteration 20206: loss: 0.078031, loss_s1: 0.058637, loss_fp: 0.012541, loss_freq: 0.033893
[18:09:29.057] iteration 20207: loss: 0.053985, loss_s1: 0.067465, loss_fp: 0.002454, loss_freq: 0.011680
[18:09:29.685] iteration 20208: loss: 0.086237, loss_s1: 0.097606, loss_fp: 0.002340, loss_freq: 0.034232
[18:09:30.318] iteration 20209: loss: 0.047756, loss_s1: 0.015454, loss_fp: 0.001996, loss_freq: 0.037995
[18:09:30.950] iteration 20210: loss: 0.063287, loss_s1: 0.035665, loss_fp: 0.010047, loss_freq: 0.054539
[18:09:31.577] iteration 20211: loss: 0.034645, loss_s1: 0.018806, loss_fp: 0.007025, loss_freq: 0.012360
[18:09:32.201] iteration 20212: loss: 0.061787, loss_s1: 0.053081, loss_fp: 0.007091, loss_freq: 0.016682
[18:09:32.823] iteration 20213: loss: 0.037346, loss_s1: 0.020791, loss_fp: 0.006793, loss_freq: 0.009841
[18:09:33.449] iteration 20214: loss: 0.072166, loss_s1: 0.083651, loss_fp: 0.002438, loss_freq: 0.024923
[18:09:34.079] iteration 20215: loss: 0.075224, loss_s1: 0.044630, loss_fp: 0.002768, loss_freq: 0.039919
[18:09:34.707] iteration 20216: loss: 0.055123, loss_s1: 0.042112, loss_fp: 0.001009, loss_freq: 0.017239
[18:09:35.333] iteration 20217: loss: 0.059679, loss_s1: 0.036921, loss_fp: 0.000931, loss_freq: 0.028108
[18:09:35.955] iteration 20218: loss: 0.106224, loss_s1: 0.023517, loss_fp: 0.007789, loss_freq: 0.017070
[18:09:36.581] iteration 20219: loss: 0.053587, loss_s1: 0.017382, loss_fp: 0.001348, loss_freq: 0.047283
[18:09:37.211] iteration 20220: loss: 0.056761, loss_s1: 0.032984, loss_fp: 0.002054, loss_freq: 0.043315
[18:09:37.838] iteration 20221: loss: 0.042475, loss_s1: 0.039683, loss_fp: 0.001422, loss_freq: 0.015971
[18:09:38.462] iteration 20222: loss: 0.045049, loss_s1: 0.029562, loss_fp: 0.005361, loss_freq: 0.020949
[18:09:39.082] iteration 20223: loss: 0.042496, loss_s1: 0.021303, loss_fp: 0.000867, loss_freq: 0.014306
[18:09:39.694] iteration 20224: loss: 0.048323, loss_s1: 0.047971, loss_fp: 0.003277, loss_freq: 0.007051
[18:09:40.323] iteration 20225: loss: 0.044954, loss_s1: 0.047756, loss_fp: 0.002808, loss_freq: 0.011439
[18:09:40.948] iteration 20226: loss: 0.039878, loss_s1: 0.035642, loss_fp: 0.001866, loss_freq: 0.011054
[18:09:41.568] iteration 20227: loss: 0.084558, loss_s1: 0.040628, loss_fp: 0.004221, loss_freq: 0.077897
[18:09:42.195] iteration 20228: loss: 0.067784, loss_s1: 0.055958, loss_fp: 0.004535, loss_freq: 0.036848
[18:09:42.819] iteration 20229: loss: 0.071577, loss_s1: 0.060936, loss_fp: 0.003842, loss_freq: 0.039872
[18:09:43.447] iteration 20230: loss: 0.064149, loss_s1: 0.040832, loss_fp: 0.003729, loss_freq: 0.028393
[18:09:44.071] iteration 20231: loss: 0.075741, loss_s1: 0.074692, loss_fp: 0.004691, loss_freq: 0.034561
[18:09:44.695] iteration 20232: loss: 0.032592, loss_s1: 0.018393, loss_fp: 0.002334, loss_freq: 0.005209
[18:09:45.316] iteration 20233: loss: 0.092932, loss_s1: 0.069723, loss_fp: 0.001113, loss_freq: 0.069041
[18:09:45.936] iteration 20234: loss: 0.077407, loss_s1: 0.077994, loss_fp: 0.006406, loss_freq: 0.028706
[18:09:46.555] iteration 20235: loss: 0.045659, loss_s1: 0.032380, loss_fp: 0.001141, loss_freq: 0.025325
[18:09:47.182] iteration 20236: loss: 0.067316, loss_s1: 0.045607, loss_fp: 0.004502, loss_freq: 0.019882
[18:09:47.802] iteration 20237: loss: 0.076360, loss_s1: 0.049951, loss_fp: 0.000836, loss_freq: 0.065958
[18:09:48.423] iteration 20238: loss: 0.042653, loss_s1: 0.022350, loss_fp: 0.005705, loss_freq: 0.028660
[18:09:49.041] iteration 20239: loss: 0.033012, loss_s1: 0.025950, loss_fp: 0.000542, loss_freq: 0.010224
[18:09:49.663] iteration 20240: loss: 0.032542, loss_s1: 0.016580, loss_fp: 0.000666, loss_freq: 0.004540
[18:09:50.293] iteration 20241: loss: 0.069977, loss_s1: 0.058307, loss_fp: 0.001835, loss_freq: 0.042214
[18:09:50.916] iteration 20242: loss: 0.069337, loss_s1: 0.085267, loss_fp: 0.002285, loss_freq: 0.015106
[18:09:51.541] iteration 20243: loss: 0.060009, loss_s1: 0.063165, loss_fp: 0.002666, loss_freq: 0.016266
[18:09:52.162] iteration 20244: loss: 0.058867, loss_s1: 0.038849, loss_fp: 0.001608, loss_freq: 0.021937
[18:09:52.785] iteration 20245: loss: 0.077696, loss_s1: 0.061603, loss_fp: 0.000761, loss_freq: 0.059273
[18:09:53.408] iteration 20246: loss: 0.042765, loss_s1: 0.013993, loss_fp: 0.002719, loss_freq: 0.038776
[18:09:54.033] iteration 20247: loss: 0.068559, loss_s1: 0.051275, loss_fp: 0.014484, loss_freq: 0.033110
[18:09:54.650] iteration 20248: loss: 0.064672, loss_s1: 0.060497, loss_fp: 0.000473, loss_freq: 0.031462
[18:09:55.270] iteration 20249: loss: 0.034090, loss_s1: 0.017531, loss_fp: 0.003294, loss_freq: 0.009540
[18:09:55.891] iteration 20250: loss: 0.063550, loss_s1: 0.027443, loss_fp: 0.004934, loss_freq: 0.038585
[18:09:56.516] iteration 20251: loss: 0.059486, loss_s1: 0.039850, loss_fp: 0.003989, loss_freq: 0.021119
[18:09:57.142] iteration 20252: loss: 0.055787, loss_s1: 0.046010, loss_fp: 0.008730, loss_freq: 0.008602
[18:09:57.762] iteration 20253: loss: 0.075920, loss_s1: 0.082610, loss_fp: 0.001607, loss_freq: 0.008585
[18:09:58.388] iteration 20254: loss: 0.057464, loss_s1: 0.040978, loss_fp: 0.004291, loss_freq: 0.030790
[18:09:59.020] iteration 20255: loss: 0.059760, loss_s1: 0.055892, loss_fp: 0.004228, loss_freq: 0.014136
[18:09:59.639] iteration 20256: loss: 0.081458, loss_s1: 0.070207, loss_fp: 0.001293, loss_freq: 0.066557
[18:10:00.266] iteration 20257: loss: 0.079622, loss_s1: 0.098832, loss_fp: 0.003248, loss_freq: 0.018401
[18:10:00.885] iteration 20258: loss: 0.073388, loss_s1: 0.062709, loss_fp: 0.002608, loss_freq: 0.019363
[18:10:01.506] iteration 20259: loss: 0.070329, loss_s1: 0.080408, loss_fp: 0.003154, loss_freq: 0.019388
[18:10:02.139] iteration 20260: loss: 0.043066, loss_s1: 0.025009, loss_fp: 0.003903, loss_freq: 0.021926
[18:10:02.801] iteration 20261: loss: 0.061862, loss_s1: 0.066872, loss_fp: 0.002477, loss_freq: 0.021329
[18:10:03.470] iteration 20262: loss: 0.050916, loss_s1: 0.020284, loss_fp: 0.000812, loss_freq: 0.016674
[18:10:04.131] iteration 20263: loss: 0.051931, loss_s1: 0.039608, loss_fp: 0.008656, loss_freq: 0.020848
[18:10:04.757] iteration 20264: loss: 0.035273, loss_s1: 0.016174, loss_fp: 0.002410, loss_freq: 0.017935
[18:10:05.389] iteration 20265: loss: 0.097388, loss_s1: 0.054742, loss_fp: 0.031421, loss_freq: 0.040053
[18:10:06.021] iteration 20266: loss: 0.043423, loss_s1: 0.022827, loss_fp: 0.004301, loss_freq: 0.028723
[18:10:06.648] iteration 20267: loss: 0.047179, loss_s1: 0.030874, loss_fp: 0.005082, loss_freq: 0.016536
[18:10:07.273] iteration 20268: loss: 0.069340, loss_s1: 0.026384, loss_fp: 0.003001, loss_freq: 0.046359
[18:10:07.897] iteration 20269: loss: 0.066942, loss_s1: 0.035487, loss_fp: 0.013119, loss_freq: 0.042015
[18:10:08.517] iteration 20270: loss: 0.049879, loss_s1: 0.027888, loss_fp: 0.005139, loss_freq: 0.021437
[18:10:09.143] iteration 20271: loss: 0.120260, loss_s1: 0.120501, loss_fp: 0.012547, loss_freq: 0.038973
[18:10:09.771] iteration 20272: loss: 0.073315, loss_s1: 0.071106, loss_fp: 0.002591, loss_freq: 0.039098
[18:10:10.394] iteration 20273: loss: 0.057169, loss_s1: 0.061284, loss_fp: 0.004287, loss_freq: 0.016485
[18:10:11.021] iteration 20274: loss: 0.053212, loss_s1: 0.048851, loss_fp: 0.001423, loss_freq: 0.011600
[18:10:11.644] iteration 20275: loss: 0.072140, loss_s1: 0.030883, loss_fp: 0.009141, loss_freq: 0.061634
[18:10:12.273] iteration 20276: loss: 0.058113, loss_s1: 0.037603, loss_fp: 0.002264, loss_freq: 0.037173
[18:10:12.902] iteration 20277: loss: 0.127649, loss_s1: 0.088567, loss_fp: 0.008243, loss_freq: 0.113662
[18:10:13.520] iteration 20278: loss: 0.050307, loss_s1: 0.038884, loss_fp: 0.005196, loss_freq: 0.028515
[18:10:14.145] iteration 20279: loss: 0.051008, loss_s1: 0.035724, loss_fp: 0.006145, loss_freq: 0.016884
[18:10:14.766] iteration 20280: loss: 0.031736, loss_s1: 0.009566, loss_fp: 0.006441, loss_freq: 0.013172
[18:10:15.397] iteration 20281: loss: 0.052679, loss_s1: 0.050188, loss_fp: 0.001831, loss_freq: 0.015941
[18:10:16.017] iteration 20282: loss: 0.051441, loss_s1: 0.045889, loss_fp: 0.000846, loss_freq: 0.010065
[18:10:16.648] iteration 20283: loss: 0.080727, loss_s1: 0.042760, loss_fp: 0.001204, loss_freq: 0.053589
[18:10:17.274] iteration 20284: loss: 0.068260, loss_s1: 0.069272, loss_fp: 0.005226, loss_freq: 0.022671
[18:10:17.887] iteration 20285: loss: 0.049358, loss_s1: 0.051382, loss_fp: 0.001791, loss_freq: 0.013577
[18:10:18.518] iteration 20286: loss: 0.044592, loss_s1: 0.013856, loss_fp: 0.001917, loss_freq: 0.018056
[18:10:19.472] iteration 20287: loss: 0.047934, loss_s1: 0.031461, loss_fp: 0.006449, loss_freq: 0.022226
[18:10:20.098] iteration 20288: loss: 0.062381, loss_s1: 0.068814, loss_fp: 0.003074, loss_freq: 0.012634
[18:10:20.725] iteration 20289: loss: 0.037059, loss_s1: 0.016908, loss_fp: 0.001942, loss_freq: 0.008686
[18:10:21.415] iteration 20290: loss: 0.043411, loss_s1: 0.020578, loss_fp: 0.001736, loss_freq: 0.018900
[18:10:22.078] iteration 20291: loss: 0.042560, loss_s1: 0.027873, loss_fp: 0.001527, loss_freq: 0.011315
[18:10:22.816] iteration 20292: loss: 0.104892, loss_s1: 0.074989, loss_fp: 0.003975, loss_freq: 0.071831
[18:10:23.463] iteration 20293: loss: 0.031820, loss_s1: 0.016349, loss_fp: 0.001557, loss_freq: 0.008883
[18:10:24.094] iteration 20294: loss: 0.046572, loss_s1: 0.041424, loss_fp: 0.001596, loss_freq: 0.008464
[18:10:24.710] iteration 20295: loss: 0.064314, loss_s1: 0.062809, loss_fp: 0.010469, loss_freq: 0.020716
[18:10:25.338] iteration 20296: loss: 0.064277, loss_s1: 0.049161, loss_fp: 0.003065, loss_freq: 0.036848
[18:10:25.971] iteration 20297: loss: 0.045461, loss_s1: 0.034766, loss_fp: 0.001063, loss_freq: 0.017031
[18:10:26.606] iteration 20298: loss: 0.066500, loss_s1: 0.065096, loss_fp: 0.001275, loss_freq: 0.017104
[18:10:27.235] iteration 20299: loss: 0.071647, loss_s1: 0.046968, loss_fp: 0.003214, loss_freq: 0.062984
[18:10:27.857] iteration 20300: loss: 0.042755, loss_s1: 0.017089, loss_fp: 0.002666, loss_freq: 0.009365
[18:10:28.475] iteration 20301: loss: 0.073911, loss_s1: 0.069416, loss_fp: 0.020776, loss_freq: 0.021042
[18:10:29.104] iteration 20302: loss: 0.133161, loss_s1: 0.135443, loss_fp: 0.004882, loss_freq: 0.096540
[18:10:29.732] iteration 20303: loss: 0.086851, loss_s1: 0.038068, loss_fp: 0.000530, loss_freq: 0.012338
[18:10:30.361] iteration 20304: loss: 0.062085, loss_s1: 0.046242, loss_fp: 0.001817, loss_freq: 0.029629
[18:10:30.991] iteration 20305: loss: 0.120154, loss_s1: 0.059864, loss_fp: 0.001757, loss_freq: 0.027959
[18:10:31.619] iteration 20306: loss: 0.057490, loss_s1: 0.040816, loss_fp: 0.014522, loss_freq: 0.016387
[18:10:32.250] iteration 20307: loss: 0.054033, loss_s1: 0.053995, loss_fp: 0.009142, loss_freq: 0.010348
[18:10:32.877] iteration 20308: loss: 0.049109, loss_s1: 0.039268, loss_fp: 0.002779, loss_freq: 0.019464
[18:10:33.502] iteration 20309: loss: 0.050931, loss_s1: 0.027874, loss_fp: 0.003645, loss_freq: 0.009059
[18:10:34.120] iteration 20310: loss: 0.075115, loss_s1: 0.058367, loss_fp: 0.008965, loss_freq: 0.045617
[18:10:34.744] iteration 20311: loss: 0.051601, loss_s1: 0.037670, loss_fp: 0.001660, loss_freq: 0.019135
[18:10:35.373] iteration 20312: loss: 0.037997, loss_s1: 0.034144, loss_fp: 0.002451, loss_freq: 0.011608
[18:10:35.998] iteration 20313: loss: 0.035712, loss_s1: 0.030461, loss_fp: 0.000745, loss_freq: 0.003868
[18:10:36.622] iteration 20314: loss: 0.094800, loss_s1: 0.094506, loss_fp: 0.002504, loss_freq: 0.038226
[18:10:37.254] iteration 20315: loss: 0.054030, loss_s1: 0.027232, loss_fp: 0.010593, loss_freq: 0.029177
[18:10:37.885] iteration 20316: loss: 0.034055, loss_s1: 0.031119, loss_fp: 0.000550, loss_freq: 0.006099
[18:10:38.514] iteration 20317: loss: 0.049757, loss_s1: 0.033857, loss_fp: 0.005605, loss_freq: 0.021846
[18:10:39.141] iteration 20318: loss: 0.056444, loss_s1: 0.018656, loss_fp: 0.003083, loss_freq: 0.009926
[18:10:39.760] iteration 20319: loss: 0.046717, loss_s1: 0.037510, loss_fp: 0.002534, loss_freq: 0.023606
[18:10:40.381] iteration 20320: loss: 0.044327, loss_s1: 0.043209, loss_fp: 0.001482, loss_freq: 0.004295
[18:10:41.004] iteration 20321: loss: 0.053725, loss_s1: 0.051168, loss_fp: 0.001249, loss_freq: 0.016531
[18:10:41.625] iteration 20322: loss: 0.059943, loss_s1: 0.046368, loss_fp: 0.001583, loss_freq: 0.038097
[18:10:42.254] iteration 20323: loss: 0.055612, loss_s1: 0.043947, loss_fp: 0.003676, loss_freq: 0.022780
[18:10:42.876] iteration 20324: loss: 0.065743, loss_s1: 0.071383, loss_fp: 0.001933, loss_freq: 0.022204
[18:10:43.506] iteration 20325: loss: 0.084026, loss_s1: 0.044007, loss_fp: 0.018350, loss_freq: 0.064836
[18:10:44.124] iteration 20326: loss: 0.054242, loss_s1: 0.046591, loss_fp: 0.002336, loss_freq: 0.019996
[18:10:44.748] iteration 20327: loss: 0.064868, loss_s1: 0.044644, loss_fp: 0.015987, loss_freq: 0.023360
[18:10:45.380] iteration 20328: loss: 0.122653, loss_s1: 0.104102, loss_fp: 0.005884, loss_freq: 0.100839
[18:10:46.013] iteration 20329: loss: 0.061759, loss_s1: 0.052758, loss_fp: 0.009608, loss_freq: 0.033825
[18:10:46.642] iteration 20330: loss: 0.059162, loss_s1: 0.041570, loss_fp: 0.004302, loss_freq: 0.041604
[18:10:47.273] iteration 20331: loss: 0.048223, loss_s1: 0.036319, loss_fp: 0.000594, loss_freq: 0.018476
[18:10:47.900] iteration 20332: loss: 0.054944, loss_s1: 0.048844, loss_fp: 0.004397, loss_freq: 0.006240
[18:10:48.524] iteration 20333: loss: 0.025505, loss_s1: 0.010553, loss_fp: 0.001259, loss_freq: 0.011001
[18:10:49.152] iteration 20334: loss: 0.049235, loss_s1: 0.030126, loss_fp: 0.021903, loss_freq: 0.013122
[18:10:49.780] iteration 20335: loss: 0.096727, loss_s1: 0.067794, loss_fp: 0.008466, loss_freq: 0.045677
[18:10:50.400] iteration 20336: loss: 0.045203, loss_s1: 0.020223, loss_fp: 0.002436, loss_freq: 0.029064
[18:10:51.025] iteration 20337: loss: 0.075189, loss_s1: 0.045401, loss_fp: 0.002255, loss_freq: 0.059543
[18:10:51.648] iteration 20338: loss: 0.057242, loss_s1: 0.017392, loss_fp: 0.003432, loss_freq: 0.035536
[18:10:52.264] iteration 20339: loss: 0.059817, loss_s1: 0.024007, loss_fp: 0.004446, loss_freq: 0.036380
[18:10:52.889] iteration 20340: loss: 0.053689, loss_s1: 0.030228, loss_fp: 0.002484, loss_freq: 0.028179
[18:10:53.509] iteration 20341: loss: 0.036358, loss_s1: 0.019297, loss_fp: 0.002995, loss_freq: 0.009013
[18:10:54.137] iteration 20342: loss: 0.066881, loss_s1: 0.041978, loss_fp: 0.006802, loss_freq: 0.034457
[18:10:54.764] iteration 20343: loss: 0.042840, loss_s1: 0.028028, loss_fp: 0.003522, loss_freq: 0.016725
[18:10:55.394] iteration 20344: loss: 0.041340, loss_s1: 0.021685, loss_fp: 0.000982, loss_freq: 0.011390
[18:10:56.021] iteration 20345: loss: 0.038966, loss_s1: 0.033142, loss_fp: 0.003306, loss_freq: 0.004945
[18:10:56.645] iteration 20346: loss: 0.035887, loss_s1: 0.023303, loss_fp: 0.003741, loss_freq: 0.015350
[18:10:57.278] iteration 20347: loss: 0.053272, loss_s1: 0.035700, loss_fp: 0.011110, loss_freq: 0.033954
[18:10:57.913] iteration 20348: loss: 0.048065, loss_s1: 0.038700, loss_fp: 0.006231, loss_freq: 0.016587
[18:10:58.537] iteration 20349: loss: 0.037428, loss_s1: 0.007549, loss_fp: 0.001143, loss_freq: 0.016042
[18:10:59.154] iteration 20350: loss: 0.045283, loss_s1: 0.022970, loss_fp: 0.004741, loss_freq: 0.028396
[18:10:59.777] iteration 20351: loss: 0.045480, loss_s1: 0.026530, loss_fp: 0.008299, loss_freq: 0.013380
[18:11:00.396] iteration 20352: loss: 0.059744, loss_s1: 0.024618, loss_fp: 0.004823, loss_freq: 0.059846
[18:11:01.028] iteration 20353: loss: 0.061062, loss_s1: 0.028939, loss_fp: 0.002888, loss_freq: 0.024656
[18:11:01.658] iteration 20354: loss: 0.039374, loss_s1: 0.028739, loss_fp: 0.002145, loss_freq: 0.018156
[18:11:02.287] iteration 20355: loss: 0.047604, loss_s1: 0.045094, loss_fp: 0.003728, loss_freq: 0.013136
[18:11:02.905] iteration 20356: loss: 0.054764, loss_s1: 0.025914, loss_fp: 0.001997, loss_freq: 0.028894
[18:11:03.532] iteration 20357: loss: 0.041995, loss_s1: 0.028641, loss_fp: 0.005413, loss_freq: 0.015349
[18:11:04.162] iteration 20358: loss: 0.046307, loss_s1: 0.042450, loss_fp: 0.002612, loss_freq: 0.018309
[18:11:04.791] iteration 20359: loss: 0.046624, loss_s1: 0.017728, loss_fp: 0.008858, loss_freq: 0.013278
[18:11:05.407] iteration 20360: loss: 0.063611, loss_s1: 0.065198, loss_fp: 0.007843, loss_freq: 0.008540
[18:11:06.039] iteration 20361: loss: 0.089327, loss_s1: 0.102121, loss_fp: 0.001755, loss_freq: 0.042468
[18:11:06.665] iteration 20362: loss: 0.087725, loss_s1: 0.054059, loss_fp: 0.016622, loss_freq: 0.047882
[18:11:07.290] iteration 20363: loss: 0.063308, loss_s1: 0.041723, loss_fp: 0.003134, loss_freq: 0.046152
[18:11:07.917] iteration 20364: loss: 0.026510, loss_s1: 0.013457, loss_fp: 0.002725, loss_freq: 0.007799
[18:11:08.544] iteration 20365: loss: 0.031747, loss_s1: 0.025745, loss_fp: 0.000511, loss_freq: 0.006891
[18:11:09.179] iteration 20366: loss: 0.060154, loss_s1: 0.044571, loss_fp: 0.001316, loss_freq: 0.039093
[18:11:09.810] iteration 20367: loss: 0.047652, loss_s1: 0.038489, loss_fp: 0.004771, loss_freq: 0.008798
[18:11:10.437] iteration 20368: loss: 0.080508, loss_s1: 0.081624, loss_fp: 0.001060, loss_freq: 0.035268
[18:11:11.061] iteration 20369: loss: 0.101824, loss_s1: 0.104752, loss_fp: 0.009149, loss_freq: 0.053185
[18:11:11.687] iteration 20370: loss: 0.074652, loss_s1: 0.055934, loss_fp: 0.001961, loss_freq: 0.040700
[18:11:12.303] iteration 20371: loss: 0.119115, loss_s1: 0.117423, loss_fp: 0.008426, loss_freq: 0.079402
[18:11:12.929] iteration 20372: loss: 0.041622, loss_s1: 0.035685, loss_fp: 0.001205, loss_freq: 0.015276
[18:11:13.550] iteration 20373: loss: 0.055476, loss_s1: 0.042659, loss_fp: 0.001529, loss_freq: 0.015095
[18:11:14.170] iteration 20374: loss: 0.045664, loss_s1: 0.036452, loss_fp: 0.001021, loss_freq: 0.022231
[18:11:14.796] iteration 20375: loss: 0.051121, loss_s1: 0.047958, loss_fp: 0.001642, loss_freq: 0.015138
[18:11:15.418] iteration 20376: loss: 0.063072, loss_s1: 0.048428, loss_fp: 0.004137, loss_freq: 0.037972
[18:11:16.044] iteration 20377: loss: 0.063047, loss_s1: 0.037847, loss_fp: 0.004311, loss_freq: 0.020624
[18:11:16.663] iteration 20378: loss: 0.072632, loss_s1: 0.049023, loss_fp: 0.001422, loss_freq: 0.026741
[18:11:17.284] iteration 20379: loss: 0.064199, loss_s1: 0.044802, loss_fp: 0.009841, loss_freq: 0.022187
[18:11:17.907] iteration 20380: loss: 0.045428, loss_s1: 0.034847, loss_fp: 0.000751, loss_freq: 0.017318
[18:11:18.527] iteration 20381: loss: 0.093681, loss_s1: 0.071264, loss_fp: 0.002954, loss_freq: 0.076579
[18:11:19.149] iteration 20382: loss: 0.047806, loss_s1: 0.019218, loss_fp: 0.002921, loss_freq: 0.045158
[18:11:19.773] iteration 20383: loss: 0.047661, loss_s1: 0.026584, loss_fp: 0.001751, loss_freq: 0.022030
[18:11:20.395] iteration 20384: loss: 0.058616, loss_s1: 0.016370, loss_fp: 0.000523, loss_freq: 0.035732
[18:11:21.019] iteration 20385: loss: 0.035134, loss_s1: 0.007508, loss_fp: 0.001831, loss_freq: 0.024554
[18:11:21.643] iteration 20386: loss: 0.074948, loss_s1: 0.083293, loss_fp: 0.006684, loss_freq: 0.014311
[18:11:22.269] iteration 20387: loss: 0.041539, loss_s1: 0.028089, loss_fp: 0.004120, loss_freq: 0.013268
[18:11:22.904] iteration 20388: loss: 0.082283, loss_s1: 0.056194, loss_fp: 0.002750, loss_freq: 0.067981
[18:11:23.540] iteration 20389: loss: 0.065524, loss_s1: 0.060292, loss_fp: 0.004595, loss_freq: 0.030163
[18:11:24.179] iteration 20390: loss: 0.048257, loss_s1: 0.041593, loss_fp: 0.003283, loss_freq: 0.021051
[18:11:24.826] iteration 20391: loss: 0.045493, loss_s1: 0.005739, loss_fp: 0.008081, loss_freq: 0.009947
[18:11:25.480] iteration 20392: loss: 0.048141, loss_s1: 0.041422, loss_fp: 0.004932, loss_freq: 0.015681
[18:11:26.143] iteration 20393: loss: 0.056343, loss_s1: 0.036763, loss_fp: 0.002710, loss_freq: 0.006603
[18:11:26.769] iteration 20394: loss: 0.082636, loss_s1: 0.043503, loss_fp: 0.004875, loss_freq: 0.066034
[18:11:27.402] iteration 20395: loss: 0.104948, loss_s1: 0.093313, loss_fp: 0.012558, loss_freq: 0.057023
[18:11:28.024] iteration 20396: loss: 0.063602, loss_s1: 0.068825, loss_fp: 0.010492, loss_freq: 0.017680
[18:11:28.651] iteration 20397: loss: 0.040776, loss_s1: 0.018000, loss_fp: 0.009094, loss_freq: 0.011799
[18:11:29.282] iteration 20398: loss: 0.048339, loss_s1: 0.031008, loss_fp: 0.004391, loss_freq: 0.025550
[18:11:29.908] iteration 20399: loss: 0.074720, loss_s1: 0.059177, loss_fp: 0.001203, loss_freq: 0.051382
[18:11:30.546] iteration 20400: loss: 0.069317, loss_s1: 0.036756, loss_fp: 0.006486, loss_freq: 0.040708
[18:11:33.871] iteration 20400 : mean_dice : 0.735847
[18:11:34.531] iteration 20401: loss: 0.043039, loss_s1: 0.015878, loss_fp: 0.002085, loss_freq: 0.012750
[18:11:35.161] iteration 20402: loss: 0.061808, loss_s1: 0.044849, loss_fp: 0.005393, loss_freq: 0.026016
[18:11:35.800] iteration 20403: loss: 0.050564, loss_s1: 0.025615, loss_fp: 0.021308, loss_freq: 0.023750
[18:11:36.428] iteration 20404: loss: 0.043107, loss_s1: 0.044770, loss_fp: 0.001402, loss_freq: 0.010228
[18:11:37.055] iteration 20405: loss: 0.072397, loss_s1: 0.074363, loss_fp: 0.004081, loss_freq: 0.026951
[18:11:37.674] iteration 20406: loss: 0.068941, loss_s1: 0.057177, loss_fp: 0.002012, loss_freq: 0.043862
[18:11:38.303] iteration 20407: loss: 0.037011, loss_s1: 0.018013, loss_fp: 0.001950, loss_freq: 0.024056
[18:11:38.928] iteration 20408: loss: 0.105396, loss_s1: 0.051709, loss_fp: 0.010215, loss_freq: 0.024989
[18:11:39.608] iteration 20409: loss: 0.060935, loss_s1: 0.063611, loss_fp: 0.004383, loss_freq: 0.009798
[18:11:40.267] iteration 20410: loss: 0.056582, loss_s1: 0.063463, loss_fp: 0.005517, loss_freq: 0.005857
[18:11:40.928] iteration 20411: loss: 0.063851, loss_s1: 0.049543, loss_fp: 0.003037, loss_freq: 0.017929
[18:11:41.561] iteration 20412: loss: 0.057089, loss_s1: 0.038324, loss_fp: 0.004900, loss_freq: 0.024282
[18:11:42.193] iteration 20413: loss: 0.038936, loss_s1: 0.012394, loss_fp: 0.001061, loss_freq: 0.009577
[18:11:42.816] iteration 20414: loss: 0.066754, loss_s1: 0.039839, loss_fp: 0.008108, loss_freq: 0.026120
[18:11:43.449] iteration 20415: loss: 0.054290, loss_s1: 0.029145, loss_fp: 0.009463, loss_freq: 0.036185
[18:11:44.080] iteration 20416: loss: 0.059639, loss_s1: 0.037276, loss_fp: 0.002272, loss_freq: 0.037845
[18:11:44.715] iteration 20417: loss: 0.075605, loss_s1: 0.050579, loss_fp: 0.002220, loss_freq: 0.068340
[18:11:45.341] iteration 20418: loss: 0.099752, loss_s1: 0.130052, loss_fp: 0.002786, loss_freq: 0.018331
[18:11:45.971] iteration 20419: loss: 0.055114, loss_s1: 0.039456, loss_fp: 0.003452, loss_freq: 0.032251
[18:11:46.609] iteration 20420: loss: 0.044125, loss_s1: 0.015319, loss_fp: 0.001925, loss_freq: 0.010909
[18:11:47.237] iteration 20421: loss: 0.087865, loss_s1: 0.069485, loss_fp: 0.002020, loss_freq: 0.047141
[18:11:47.865] iteration 20422: loss: 0.049888, loss_s1: 0.046054, loss_fp: 0.002155, loss_freq: 0.019426
[18:11:48.495] iteration 20423: loss: 0.036341, loss_s1: 0.021086, loss_fp: 0.004318, loss_freq: 0.012874
[18:11:49.127] iteration 20424: loss: 0.053615, loss_s1: 0.040039, loss_fp: 0.001691, loss_freq: 0.027056
[18:11:49.754] iteration 20425: loss: 0.037562, loss_s1: 0.023696, loss_fp: 0.001337, loss_freq: 0.013149
[18:11:50.393] iteration 20426: loss: 0.071527, loss_s1: 0.018090, loss_fp: 0.008135, loss_freq: 0.026224
[18:11:51.028] iteration 20427: loss: 0.067801, loss_s1: 0.042999, loss_fp: 0.003277, loss_freq: 0.059512
[18:11:51.656] iteration 20428: loss: 0.061277, loss_s1: 0.034126, loss_fp: 0.003495, loss_freq: 0.046165
[18:11:52.288] iteration 20429: loss: 0.068959, loss_s1: 0.035667, loss_fp: 0.003360, loss_freq: 0.045181
[18:11:52.915] iteration 20430: loss: 0.066683, loss_s1: 0.069205, loss_fp: 0.001982, loss_freq: 0.018418
[18:11:53.537] iteration 20431: loss: 0.050250, loss_s1: 0.028690, loss_fp: 0.004152, loss_freq: 0.008755
[18:11:54.164] iteration 20432: loss: 0.053185, loss_s1: 0.028322, loss_fp: 0.007143, loss_freq: 0.016555
[18:11:54.787] iteration 20433: loss: 0.060091, loss_s1: 0.048071, loss_fp: 0.001523, loss_freq: 0.033282
[18:11:55.407] iteration 20434: loss: 0.048429, loss_s1: 0.036269, loss_fp: 0.006025, loss_freq: 0.014416
[18:11:56.033] iteration 20435: loss: 0.052866, loss_s1: 0.040199, loss_fp: 0.003755, loss_freq: 0.015775
[18:11:56.662] iteration 20436: loss: 0.075134, loss_s1: 0.023841, loss_fp: 0.010458, loss_freq: 0.069224
[18:11:57.288] iteration 20437: loss: 0.113357, loss_s1: 0.035163, loss_fp: 0.013296, loss_freq: 0.044885
[18:11:57.914] iteration 20438: loss: 0.092373, loss_s1: 0.081578, loss_fp: 0.007331, loss_freq: 0.056543
[18:11:58.551] iteration 20439: loss: 0.045460, loss_s1: 0.042754, loss_fp: 0.004223, loss_freq: 0.007903
[18:11:59.183] iteration 20440: loss: 0.060820, loss_s1: 0.053964, loss_fp: 0.002231, loss_freq: 0.020423
[18:11:59.816] iteration 20441: loss: 0.030806, loss_s1: 0.015740, loss_fp: 0.001247, loss_freq: 0.012735
[18:12:00.441] iteration 20442: loss: 0.059290, loss_s1: 0.038793, loss_fp: 0.009159, loss_freq: 0.030745
[18:12:01.070] iteration 20443: loss: 0.035466, loss_s1: 0.016209, loss_fp: 0.000648, loss_freq: 0.012351
[18:12:01.697] iteration 20444: loss: 0.084466, loss_s1: 0.080759, loss_fp: 0.008284, loss_freq: 0.035357
[18:12:02.386] iteration 20445: loss: 0.088955, loss_s1: 0.062587, loss_fp: 0.047914, loss_freq: 0.032423
[18:12:03.024] iteration 20446: loss: 0.058104, loss_s1: 0.053740, loss_fp: 0.001673, loss_freq: 0.006606
[18:12:03.655] iteration 20447: loss: 0.046369, loss_s1: 0.036345, loss_fp: 0.005243, loss_freq: 0.015018
[18:12:04.696] iteration 20448: loss: 0.045852, loss_s1: 0.015459, loss_fp: 0.006491, loss_freq: 0.007051
[18:12:05.324] iteration 20449: loss: 0.084629, loss_s1: 0.071139, loss_fp: 0.005965, loss_freq: 0.054215
[18:12:05.955] iteration 20450: loss: 0.044709, loss_s1: 0.020065, loss_fp: 0.003334, loss_freq: 0.027895
[18:12:06.586] iteration 20451: loss: 0.037251, loss_s1: 0.026143, loss_fp: 0.000479, loss_freq: 0.007277
[18:12:07.227] iteration 20452: loss: 0.051581, loss_s1: 0.037910, loss_fp: 0.005995, loss_freq: 0.018894
[18:12:07.859] iteration 20453: loss: 0.092639, loss_s1: 0.061968, loss_fp: 0.006112, loss_freq: 0.058939
[18:12:08.484] iteration 20454: loss: 0.050410, loss_s1: 0.040312, loss_fp: 0.001888, loss_freq: 0.024658
[18:12:09.114] iteration 20455: loss: 0.040399, loss_s1: 0.019741, loss_fp: 0.001770, loss_freq: 0.012215
[18:12:09.746] iteration 20456: loss: 0.066541, loss_s1: 0.063770, loss_fp: 0.001871, loss_freq: 0.033587
[18:12:10.379] iteration 20457: loss: 0.084714, loss_s1: 0.073322, loss_fp: 0.014593, loss_freq: 0.034200
[18:12:10.996] iteration 20458: loss: 0.038403, loss_s1: 0.018280, loss_fp: 0.001555, loss_freq: 0.018770
[18:12:11.629] iteration 20459: loss: 0.039705, loss_s1: 0.034332, loss_fp: 0.004036, loss_freq: 0.010011
[18:12:12.255] iteration 20460: loss: 0.052379, loss_s1: 0.042467, loss_fp: 0.000885, loss_freq: 0.031482
[18:12:12.883] iteration 20461: loss: 0.047350, loss_s1: 0.025464, loss_fp: 0.002641, loss_freq: 0.019742
[18:12:13.511] iteration 20462: loss: 0.054227, loss_s1: 0.043608, loss_fp: 0.003793, loss_freq: 0.023081
[18:12:14.136] iteration 20463: loss: 0.082087, loss_s1: 0.085048, loss_fp: 0.005673, loss_freq: 0.032110
[18:12:14.758] iteration 20464: loss: 0.044477, loss_s1: 0.038175, loss_fp: 0.001347, loss_freq: 0.009988
[18:12:15.387] iteration 20465: loss: 0.062990, loss_s1: 0.048535, loss_fp: 0.010593, loss_freq: 0.029651
[18:12:16.005] iteration 20466: loss: 0.052513, loss_s1: 0.026268, loss_fp: 0.000845, loss_freq: 0.037041
[18:12:16.635] iteration 20467: loss: 0.048718, loss_s1: 0.049636, loss_fp: 0.001146, loss_freq: 0.011144
[18:12:17.269] iteration 20468: loss: 0.056705, loss_s1: 0.061680, loss_fp: 0.001526, loss_freq: 0.009950
[18:12:17.907] iteration 20469: loss: 0.044283, loss_s1: 0.038823, loss_fp: 0.001081, loss_freq: 0.009286
[18:12:18.545] iteration 20470: loss: 0.079537, loss_s1: 0.091824, loss_fp: 0.001357, loss_freq: 0.020979
[18:12:19.174] iteration 20471: loss: 0.094117, loss_s1: 0.059462, loss_fp: 0.006184, loss_freq: 0.092560
[18:12:19.812] iteration 20472: loss: 0.030446, loss_s1: 0.017159, loss_fp: 0.001061, loss_freq: 0.010752
[18:12:20.443] iteration 20473: loss: 0.047726, loss_s1: 0.037400, loss_fp: 0.004270, loss_freq: 0.025491
[18:12:21.074] iteration 20474: loss: 0.045679, loss_s1: 0.045335, loss_fp: 0.000629, loss_freq: 0.007982
[18:12:21.712] iteration 20475: loss: 0.112389, loss_s1: 0.129616, loss_fp: 0.014045, loss_freq: 0.044333
[18:12:22.338] iteration 20476: loss: 0.054857, loss_s1: 0.028364, loss_fp: 0.005787, loss_freq: 0.042310
[18:12:22.953] iteration 20477: loss: 0.036289, loss_s1: 0.028418, loss_fp: 0.001344, loss_freq: 0.009305
[18:12:23.579] iteration 20478: loss: 0.033286, loss_s1: 0.019134, loss_fp: 0.002866, loss_freq: 0.015518
[18:12:24.201] iteration 20479: loss: 0.034189, loss_s1: 0.006912, loss_fp: 0.003778, loss_freq: 0.018853
[18:12:24.821] iteration 20480: loss: 0.043257, loss_s1: 0.014264, loss_fp: 0.001646, loss_freq: 0.036025
[18:12:25.447] iteration 20481: loss: 0.041988, loss_s1: 0.039774, loss_fp: 0.001774, loss_freq: 0.008363
[18:12:26.073] iteration 20482: loss: 0.074304, loss_s1: 0.036941, loss_fp: 0.004675, loss_freq: 0.035427
[18:12:26.709] iteration 20483: loss: 0.033636, loss_s1: 0.018407, loss_fp: 0.001910, loss_freq: 0.015933
[18:12:27.370] iteration 20484: loss: 0.081320, loss_s1: 0.064269, loss_fp: 0.020410, loss_freq: 0.036066
[18:12:28.014] iteration 20485: loss: 0.060950, loss_s1: 0.030159, loss_fp: 0.022716, loss_freq: 0.032898
[18:12:28.812] iteration 20486: loss: 0.090268, loss_s1: 0.078448, loss_fp: 0.004176, loss_freq: 0.051035
[18:12:29.536] iteration 20487: loss: 0.075800, loss_s1: 0.055619, loss_fp: 0.006968, loss_freq: 0.052600
[18:12:30.166] iteration 20488: loss: 0.051713, loss_s1: 0.025783, loss_fp: 0.005793, loss_freq: 0.024164
[18:12:30.787] iteration 20489: loss: 0.050828, loss_s1: 0.045045, loss_fp: 0.007736, loss_freq: 0.015906
[18:12:31.417] iteration 20490: loss: 0.044763, loss_s1: 0.024970, loss_fp: 0.002370, loss_freq: 0.019731
[18:12:32.043] iteration 20491: loss: 0.050407, loss_s1: 0.023985, loss_fp: 0.004186, loss_freq: 0.039667
[18:12:32.661] iteration 20492: loss: 0.050865, loss_s1: 0.032477, loss_fp: 0.002908, loss_freq: 0.024439
[18:12:33.283] iteration 20493: loss: 0.038728, loss_s1: 0.019627, loss_fp: 0.002305, loss_freq: 0.015724
[18:12:33.905] iteration 20494: loss: 0.027281, loss_s1: 0.011130, loss_fp: 0.001068, loss_freq: 0.011651
[18:12:34.525] iteration 20495: loss: 0.060929, loss_s1: 0.056841, loss_fp: 0.009040, loss_freq: 0.023514
[18:12:35.149] iteration 20496: loss: 0.052337, loss_s1: 0.023120, loss_fp: 0.006491, loss_freq: 0.028584
[18:12:35.774] iteration 20497: loss: 0.056294, loss_s1: 0.042284, loss_fp: 0.003430, loss_freq: 0.042422
[18:12:36.407] iteration 20498: loss: 0.060982, loss_s1: 0.046288, loss_fp: 0.004739, loss_freq: 0.036719
[18:12:37.037] iteration 20499: loss: 0.056654, loss_s1: 0.025399, loss_fp: 0.002488, loss_freq: 0.025212
[18:12:37.664] iteration 20500: loss: 0.047389, loss_s1: 0.031644, loss_fp: 0.004077, loss_freq: 0.024643
[18:12:38.292] iteration 20501: loss: 0.041633, loss_s1: 0.029662, loss_fp: 0.000806, loss_freq: 0.018570
[18:12:38.920] iteration 20502: loss: 0.030888, loss_s1: 0.013172, loss_fp: 0.002319, loss_freq: 0.013749
[18:12:39.542] iteration 20503: loss: 0.052124, loss_s1: 0.052442, loss_fp: 0.001014, loss_freq: 0.012137
[18:12:40.169] iteration 20504: loss: 0.046934, loss_s1: 0.027234, loss_fp: 0.003383, loss_freq: 0.010979
[18:12:40.795] iteration 20505: loss: 0.060205, loss_s1: 0.015871, loss_fp: 0.002666, loss_freq: 0.037277
[18:12:41.445] iteration 20506: loss: 0.035588, loss_s1: 0.030233, loss_fp: 0.000987, loss_freq: 0.007462
[18:12:42.097] iteration 20507: loss: 0.041116, loss_s1: 0.029615, loss_fp: 0.000914, loss_freq: 0.016892
[18:12:42.755] iteration 20508: loss: 0.037238, loss_s1: 0.013184, loss_fp: 0.002324, loss_freq: 0.027699
[18:12:43.371] iteration 20509: loss: 0.049758, loss_s1: 0.036817, loss_fp: 0.005876, loss_freq: 0.023297
[18:12:43.998] iteration 20510: loss: 0.050992, loss_s1: 0.037622, loss_fp: 0.003680, loss_freq: 0.011273
[18:12:44.630] iteration 20511: loss: 0.063443, loss_s1: 0.060483, loss_fp: 0.005486, loss_freq: 0.015694
[18:12:45.263] iteration 20512: loss: 0.052860, loss_s1: 0.045771, loss_fp: 0.012979, loss_freq: 0.010721
[18:12:45.896] iteration 20513: loss: 0.064125, loss_s1: 0.033747, loss_fp: 0.005834, loss_freq: 0.061427
[18:12:46.516] iteration 20514: loss: 0.056315, loss_s1: 0.029887, loss_fp: 0.000681, loss_freq: 0.043727
[18:12:47.143] iteration 20515: loss: 0.064085, loss_s1: 0.051755, loss_fp: 0.001613, loss_freq: 0.041204
[18:12:47.774] iteration 20516: loss: 0.033851, loss_s1: 0.018813, loss_fp: 0.003248, loss_freq: 0.014256
[18:12:48.405] iteration 20517: loss: 0.063373, loss_s1: 0.029760, loss_fp: 0.002846, loss_freq: 0.043313
[18:12:49.029] iteration 20518: loss: 0.072688, loss_s1: 0.034937, loss_fp: 0.002602, loss_freq: 0.073446
[18:12:49.663] iteration 20519: loss: 0.063726, loss_s1: 0.059426, loss_fp: 0.000356, loss_freq: 0.034766
[18:12:50.291] iteration 20520: loss: 0.046480, loss_s1: 0.026683, loss_fp: 0.003779, loss_freq: 0.026456
[18:12:50.970] iteration 20521: loss: 0.042878, loss_s1: 0.031113, loss_fp: 0.005345, loss_freq: 0.006426
[18:12:51.631] iteration 20522: loss: 0.079687, loss_s1: 0.075607, loss_fp: 0.002665, loss_freq: 0.044140
[18:12:52.292] iteration 20523: loss: 0.073230, loss_s1: 0.034593, loss_fp: 0.006492, loss_freq: 0.052805
[18:12:52.956] iteration 20524: loss: 0.056954, loss_s1: 0.045194, loss_fp: 0.005182, loss_freq: 0.037316
[18:12:53.591] iteration 20525: loss: 0.048712, loss_s1: 0.039707, loss_fp: 0.003968, loss_freq: 0.025731
[18:12:54.225] iteration 20526: loss: 0.053850, loss_s1: 0.056453, loss_fp: 0.004378, loss_freq: 0.013756
[18:12:54.851] iteration 20527: loss: 0.065691, loss_s1: 0.044522, loss_fp: 0.002381, loss_freq: 0.039387
[18:12:55.474] iteration 20528: loss: 0.092723, loss_s1: 0.093630, loss_fp: 0.010794, loss_freq: 0.044722
[18:12:56.113] iteration 20529: loss: 0.046433, loss_s1: 0.041714, loss_fp: 0.005607, loss_freq: 0.012503
[18:12:56.734] iteration 20530: loss: 0.091537, loss_s1: 0.126384, loss_fp: 0.002819, loss_freq: 0.023077
[18:12:57.363] iteration 20531: loss: 0.051056, loss_s1: 0.023198, loss_fp: 0.002992, loss_freq: 0.016639
[18:12:57.987] iteration 20532: loss: 0.080225, loss_s1: 0.074918, loss_fp: 0.007912, loss_freq: 0.040799
[18:12:58.613] iteration 20533: loss: 0.037707, loss_s1: 0.029150, loss_fp: 0.001188, loss_freq: 0.011719
[18:12:59.245] iteration 20534: loss: 0.073370, loss_s1: 0.052271, loss_fp: 0.005768, loss_freq: 0.032740
[18:12:59.878] iteration 20535: loss: 0.039536, loss_s1: 0.026755, loss_fp: 0.004844, loss_freq: 0.015896
[18:13:00.507] iteration 20536: loss: 0.062599, loss_s1: 0.054418, loss_fp: 0.002249, loss_freq: 0.036137
[18:13:01.129] iteration 20537: loss: 0.050734, loss_s1: 0.032320, loss_fp: 0.003778, loss_freq: 0.015994
[18:13:01.764] iteration 20538: loss: 0.056531, loss_s1: 0.045759, loss_fp: 0.011894, loss_freq: 0.016144
[18:13:02.403] iteration 20539: loss: 0.043283, loss_s1: 0.022416, loss_fp: 0.004928, loss_freq: 0.016525
[18:13:03.024] iteration 20540: loss: 0.069651, loss_s1: 0.037592, loss_fp: 0.001867, loss_freq: 0.039079
[18:13:03.650] iteration 20541: loss: 0.045832, loss_s1: 0.034426, loss_fp: 0.001380, loss_freq: 0.015678
[18:13:04.279] iteration 20542: loss: 0.062531, loss_s1: 0.037781, loss_fp: 0.007265, loss_freq: 0.034651
[18:13:04.905] iteration 20543: loss: 0.058470, loss_s1: 0.053167, loss_fp: 0.006759, loss_freq: 0.029285
[18:13:05.533] iteration 20544: loss: 0.040222, loss_s1: 0.027965, loss_fp: 0.000821, loss_freq: 0.013269
[18:13:06.153] iteration 20545: loss: 0.038466, loss_s1: 0.020338, loss_fp: 0.000523, loss_freq: 0.016613
[18:13:06.788] iteration 20546: loss: 0.041002, loss_s1: 0.015201, loss_fp: 0.007664, loss_freq: 0.008951
[18:13:07.415] iteration 20547: loss: 0.098951, loss_s1: 0.118374, loss_fp: 0.002936, loss_freq: 0.025576
[18:13:08.044] iteration 20548: loss: 0.037119, loss_s1: 0.023206, loss_fp: 0.002307, loss_freq: 0.017558
[18:13:08.671] iteration 20549: loss: 0.086731, loss_s1: 0.076873, loss_fp: 0.005386, loss_freq: 0.051741
[18:13:09.296] iteration 20550: loss: 0.050280, loss_s1: 0.039078, loss_fp: 0.003121, loss_freq: 0.030027
[18:13:09.921] iteration 20551: loss: 0.055947, loss_s1: 0.057771, loss_fp: 0.004582, loss_freq: 0.017826
[18:13:10.549] iteration 20552: loss: 0.058847, loss_s1: 0.022116, loss_fp: 0.005461, loss_freq: 0.022371
[18:13:11.178] iteration 20553: loss: 0.037370, loss_s1: 0.022860, loss_fp: 0.001958, loss_freq: 0.010961
[18:13:11.797] iteration 20554: loss: 0.060371, loss_s1: 0.071215, loss_fp: 0.000516, loss_freq: 0.012346
[18:13:12.413] iteration 20555: loss: 0.111188, loss_s1: 0.131042, loss_fp: 0.003073, loss_freq: 0.050582
[18:13:13.046] iteration 20556: loss: 0.086686, loss_s1: 0.048273, loss_fp: 0.014077, loss_freq: 0.071809
[18:13:13.672] iteration 20557: loss: 0.052251, loss_s1: 0.033532, loss_fp: 0.013563, loss_freq: 0.023297
[18:13:14.305] iteration 20558: loss: 0.084337, loss_s1: 0.062135, loss_fp: 0.001868, loss_freq: 0.032358
[18:13:14.932] iteration 20559: loss: 0.060544, loss_s1: 0.040153, loss_fp: 0.002290, loss_freq: 0.043887
[18:13:15.566] iteration 20560: loss: 0.083381, loss_s1: 0.084336, loss_fp: 0.002170, loss_freq: 0.050831
[18:13:16.192] iteration 20561: loss: 0.048610, loss_s1: 0.040449, loss_fp: 0.002375, loss_freq: 0.027457
[18:13:16.817] iteration 20562: loss: 0.040995, loss_s1: 0.025169, loss_fp: 0.003606, loss_freq: 0.011745
[18:13:17.435] iteration 20563: loss: 0.083085, loss_s1: 0.102260, loss_fp: 0.003336, loss_freq: 0.021867
[18:13:18.063] iteration 20564: loss: 0.048037, loss_s1: 0.032624, loss_fp: 0.002934, loss_freq: 0.019358
[18:13:18.685] iteration 20565: loss: 0.037970, loss_s1: 0.038267, loss_fp: 0.000730, loss_freq: 0.008793
[18:13:19.315] iteration 20566: loss: 0.063765, loss_s1: 0.050793, loss_fp: 0.007182, loss_freq: 0.020449
[18:13:19.939] iteration 20567: loss: 0.080854, loss_s1: 0.066810, loss_fp: 0.008710, loss_freq: 0.061470
[18:13:20.567] iteration 20568: loss: 0.055789, loss_s1: 0.038819, loss_fp: 0.002739, loss_freq: 0.038178
[18:13:21.196] iteration 20569: loss: 0.055522, loss_s1: 0.045302, loss_fp: 0.000839, loss_freq: 0.025620
[18:13:21.822] iteration 20570: loss: 0.088363, loss_s1: 0.092673, loss_fp: 0.003707, loss_freq: 0.006191
[18:13:22.451] iteration 20571: loss: 0.064583, loss_s1: 0.048085, loss_fp: 0.000513, loss_freq: 0.023348
[18:13:23.079] iteration 20572: loss: 0.045473, loss_s1: 0.027773, loss_fp: 0.005835, loss_freq: 0.024506
[18:13:23.715] iteration 20573: loss: 0.068387, loss_s1: 0.063693, loss_fp: 0.005751, loss_freq: 0.015208
[18:13:24.346] iteration 20574: loss: 0.046633, loss_s1: 0.041783, loss_fp: 0.003483, loss_freq: 0.014997
[18:13:24.977] iteration 20575: loss: 0.109501, loss_s1: 0.077020, loss_fp: 0.003522, loss_freq: 0.076736
[18:13:25.609] iteration 20576: loss: 0.063681, loss_s1: 0.056567, loss_fp: 0.003751, loss_freq: 0.030107
[18:13:26.237] iteration 20577: loss: 0.031924, loss_s1: 0.026441, loss_fp: 0.001064, loss_freq: 0.009596
[18:13:26.863] iteration 20578: loss: 0.067031, loss_s1: 0.051239, loss_fp: 0.007158, loss_freq: 0.045927
[18:13:27.494] iteration 20579: loss: 0.051332, loss_s1: 0.046394, loss_fp: 0.001610, loss_freq: 0.023346
[18:13:28.126] iteration 20580: loss: 0.066315, loss_s1: 0.058355, loss_fp: 0.007494, loss_freq: 0.024335
[18:13:28.754] iteration 20581: loss: 0.062124, loss_s1: 0.036752, loss_fp: 0.012563, loss_freq: 0.031550
[18:13:29.380] iteration 20582: loss: 0.121209, loss_s1: 0.137267, loss_fp: 0.014362, loss_freq: 0.054674
[18:13:30.014] iteration 20583: loss: 0.048405, loss_s1: 0.051370, loss_fp: 0.003528, loss_freq: 0.011343
[18:13:30.641] iteration 20584: loss: 0.031533, loss_s1: 0.017360, loss_fp: 0.000613, loss_freq: 0.010794
[18:13:31.266] iteration 20585: loss: 0.045455, loss_s1: 0.027595, loss_fp: 0.002893, loss_freq: 0.032220
[18:13:31.893] iteration 20586: loss: 0.034838, loss_s1: 0.011297, loss_fp: 0.002156, loss_freq: 0.013904
[18:13:32.523] iteration 20587: loss: 0.065122, loss_s1: 0.037902, loss_fp: 0.007800, loss_freq: 0.030107
[18:13:33.155] iteration 20588: loss: 0.067010, loss_s1: 0.054414, loss_fp: 0.001735, loss_freq: 0.032075
[18:13:33.783] iteration 20589: loss: 0.030429, loss_s1: 0.012140, loss_fp: 0.003412, loss_freq: 0.011379
[18:13:34.409] iteration 20590: loss: 0.050010, loss_s1: 0.033556, loss_fp: 0.010063, loss_freq: 0.022275
[18:13:35.045] iteration 20591: loss: 0.043579, loss_s1: 0.028943, loss_fp: 0.002005, loss_freq: 0.015699
[18:13:35.660] iteration 20592: loss: 0.033660, loss_s1: 0.027299, loss_fp: 0.002714, loss_freq: 0.006510
[18:13:36.290] iteration 20593: loss: 0.084651, loss_s1: 0.049116, loss_fp: 0.005552, loss_freq: 0.037632
[18:13:36.920] iteration 20594: loss: 0.072611, loss_s1: 0.061325, loss_fp: 0.004884, loss_freq: 0.049097
[18:13:37.581] iteration 20595: loss: 0.044372, loss_s1: 0.035739, loss_fp: 0.004923, loss_freq: 0.019210
[18:13:38.248] iteration 20596: loss: 0.062506, loss_s1: 0.019762, loss_fp: 0.008119, loss_freq: 0.031043
[18:13:38.910] iteration 20597: loss: 0.078373, loss_s1: 0.059117, loss_fp: 0.008976, loss_freq: 0.043771
[18:13:39.540] iteration 20598: loss: 0.061122, loss_s1: 0.035454, loss_fp: 0.005719, loss_freq: 0.020133
[18:13:40.168] iteration 20599: loss: 0.124511, loss_s1: 0.119256, loss_fp: 0.012989, loss_freq: 0.081760
[18:13:40.790] iteration 20600: loss: 0.045878, loss_s1: 0.021467, loss_fp: 0.003299, loss_freq: 0.025542
[18:13:44.132] iteration 20600 : mean_dice : 0.740139
[18:13:44.816] iteration 20601: loss: 0.059930, loss_s1: 0.053323, loss_fp: 0.005696, loss_freq: 0.022320
[18:13:45.446] iteration 20602: loss: 0.026393, loss_s1: 0.007997, loss_fp: 0.001223, loss_freq: 0.011786
[18:13:46.110] iteration 20603: loss: 0.045583, loss_s1: 0.031733, loss_fp: 0.006351, loss_freq: 0.013414
[18:13:46.786] iteration 20604: loss: 0.050228, loss_s1: 0.022787, loss_fp: 0.001181, loss_freq: 0.023059
[18:13:47.439] iteration 20605: loss: 0.087894, loss_s1: 0.071519, loss_fp: 0.003508, loss_freq: 0.030737
[18:13:48.070] iteration 20606: loss: 0.069730, loss_s1: 0.052744, loss_fp: 0.017212, loss_freq: 0.033994
[18:13:48.693] iteration 20607: loss: 0.040192, loss_s1: 0.029411, loss_fp: 0.000434, loss_freq: 0.012062
[18:13:49.318] iteration 20608: loss: 0.046699, loss_s1: 0.026521, loss_fp: 0.004807, loss_freq: 0.024648
[18:13:50.292] iteration 20609: loss: 0.068228, loss_s1: 0.063725, loss_fp: 0.001371, loss_freq: 0.037912
[18:13:50.936] iteration 20610: loss: 0.099294, loss_s1: 0.058643, loss_fp: 0.023787, loss_freq: 0.019041
[18:13:51.566] iteration 20611: loss: 0.037255, loss_s1: 0.027884, loss_fp: 0.000740, loss_freq: 0.010461
[18:13:52.194] iteration 20612: loss: 0.049133, loss_s1: 0.024087, loss_fp: 0.003831, loss_freq: 0.033442
[18:13:52.825] iteration 20613: loss: 0.054812, loss_s1: 0.046933, loss_fp: 0.007884, loss_freq: 0.019021
[18:13:53.445] iteration 20614: loss: 0.096794, loss_s1: 0.063579, loss_fp: 0.008434, loss_freq: 0.047774
[18:13:54.074] iteration 20615: loss: 0.037867, loss_s1: 0.018863, loss_fp: 0.004274, loss_freq: 0.026448
[18:13:54.708] iteration 20616: loss: 0.028583, loss_s1: 0.011910, loss_fp: 0.002975, loss_freq: 0.011187
[18:13:55.341] iteration 20617: loss: 0.054619, loss_s1: 0.031355, loss_fp: 0.003532, loss_freq: 0.030911
[18:13:55.979] iteration 20618: loss: 0.054902, loss_s1: 0.040033, loss_fp: 0.003392, loss_freq: 0.026971
[18:13:56.603] iteration 20619: loss: 0.066377, loss_s1: 0.039687, loss_fp: 0.000949, loss_freq: 0.031229
[18:13:57.235] iteration 20620: loss: 0.080190, loss_s1: 0.066331, loss_fp: 0.005835, loss_freq: 0.050672
[18:13:57.866] iteration 20621: loss: 0.051914, loss_s1: 0.019829, loss_fp: 0.002326, loss_freq: 0.053125
[18:13:58.499] iteration 20622: loss: 0.058989, loss_s1: 0.046846, loss_fp: 0.002388, loss_freq: 0.025587
[18:13:59.136] iteration 20623: loss: 0.049481, loss_s1: 0.064087, loss_fp: 0.001729, loss_freq: 0.006825
[18:13:59.765] iteration 20624: loss: 0.073884, loss_s1: 0.033449, loss_fp: 0.029911, loss_freq: 0.044631
[18:14:00.436] iteration 20625: loss: 0.042169, loss_s1: 0.033409, loss_fp: 0.008036, loss_freq: 0.009493
[18:14:01.059] iteration 20626: loss: 0.049913, loss_s1: 0.029036, loss_fp: 0.004447, loss_freq: 0.011862
[18:14:01.687] iteration 20627: loss: 0.035246, loss_s1: 0.014764, loss_fp: 0.001043, loss_freq: 0.017688
[18:14:02.316] iteration 20628: loss: 0.056638, loss_s1: 0.033558, loss_fp: 0.001048, loss_freq: 0.017492
[18:14:02.958] iteration 20629: loss: 0.048344, loss_s1: 0.044033, loss_fp: 0.001884, loss_freq: 0.008171
[18:14:03.584] iteration 20630: loss: 0.052897, loss_s1: 0.025009, loss_fp: 0.002612, loss_freq: 0.016177
[18:14:04.218] iteration 20631: loss: 0.051500, loss_s1: 0.015661, loss_fp: 0.019951, loss_freq: 0.024162
[18:14:04.892] iteration 20632: loss: 0.107370, loss_s1: 0.125001, loss_fp: 0.001202, loss_freq: 0.057145
[18:14:05.551] iteration 20633: loss: 0.091648, loss_s1: 0.134755, loss_fp: 0.001027, loss_freq: 0.018865
[18:14:06.207] iteration 20634: loss: 0.041268, loss_s1: 0.034749, loss_fp: 0.004278, loss_freq: 0.013458
[18:14:06.871] iteration 20635: loss: 0.030475, loss_s1: 0.025137, loss_fp: 0.000925, loss_freq: 0.003819
[18:14:07.531] iteration 20636: loss: 0.069203, loss_s1: 0.051905, loss_fp: 0.009749, loss_freq: 0.038625
[18:14:08.192] iteration 20637: loss: 0.084252, loss_s1: 0.075811, loss_fp: 0.001945, loss_freq: 0.057269
[18:14:08.851] iteration 20638: loss: 0.064124, loss_s1: 0.066247, loss_fp: 0.003382, loss_freq: 0.019652
[18:14:09.514] iteration 20639: loss: 0.054932, loss_s1: 0.050984, loss_fp: 0.002864, loss_freq: 0.023947
[18:14:10.173] iteration 20640: loss: 0.044046, loss_s1: 0.026822, loss_fp: 0.001263, loss_freq: 0.016039
[18:14:10.811] iteration 20641: loss: 0.066415, loss_s1: 0.038158, loss_fp: 0.016814, loss_freq: 0.037265
[18:14:11.432] iteration 20642: loss: 0.043149, loss_s1: 0.030851, loss_fp: 0.002404, loss_freq: 0.010628
[18:14:12.066] iteration 20643: loss: 0.060943, loss_s1: 0.040760, loss_fp: 0.001169, loss_freq: 0.027556
[18:14:12.697] iteration 20644: loss: 0.080386, loss_s1: 0.071051, loss_fp: 0.003129, loss_freq: 0.053555
[18:14:13.328] iteration 20645: loss: 0.101954, loss_s1: 0.091167, loss_fp: 0.007551, loss_freq: 0.040006
[18:14:13.956] iteration 20646: loss: 0.041966, loss_s1: 0.030763, loss_fp: 0.002368, loss_freq: 0.020474
[18:14:14.581] iteration 20647: loss: 0.065411, loss_s1: 0.036127, loss_fp: 0.002806, loss_freq: 0.049046
[18:14:15.211] iteration 20648: loss: 0.063800, loss_s1: 0.061487, loss_fp: 0.004920, loss_freq: 0.027755
[18:14:15.849] iteration 20649: loss: 0.045399, loss_s1: 0.036743, loss_fp: 0.001266, loss_freq: 0.010924
[18:14:16.472] iteration 20650: loss: 0.057348, loss_s1: 0.043219, loss_fp: 0.003724, loss_freq: 0.031868
[18:14:17.104] iteration 20651: loss: 0.067550, loss_s1: 0.051794, loss_fp: 0.006930, loss_freq: 0.048119
[18:14:17.733] iteration 20652: loss: 0.067067, loss_s1: 0.053021, loss_fp: 0.001589, loss_freq: 0.052782
[18:14:18.391] iteration 20653: loss: 0.084386, loss_s1: 0.067806, loss_fp: 0.006135, loss_freq: 0.053393
[18:14:19.017] iteration 20654: loss: 0.044399, loss_s1: 0.042942, loss_fp: 0.000899, loss_freq: 0.004259
[18:14:19.646] iteration 20655: loss: 0.031148, loss_s1: 0.011917, loss_fp: 0.001060, loss_freq: 0.016651
[18:14:20.276] iteration 20656: loss: 0.079955, loss_s1: 0.092975, loss_fp: 0.005928, loss_freq: 0.030029
[18:14:20.912] iteration 20657: loss: 0.071405, loss_s1: 0.048527, loss_fp: 0.002455, loss_freq: 0.025856
[18:14:21.537] iteration 20658: loss: 0.038589, loss_s1: 0.027852, loss_fp: 0.000580, loss_freq: 0.014675
[18:14:22.184] iteration 20659: loss: 0.041863, loss_s1: 0.027290, loss_fp: 0.003831, loss_freq: 0.018771
[18:14:22.811] iteration 20660: loss: 0.039178, loss_s1: 0.010960, loss_fp: 0.000749, loss_freq: 0.028716
[18:14:23.441] iteration 20661: loss: 0.064374, loss_s1: 0.039829, loss_fp: 0.002470, loss_freq: 0.051094
[18:14:24.065] iteration 20662: loss: 0.070070, loss_s1: 0.025209, loss_fp: 0.003266, loss_freq: 0.069260
[18:14:24.692] iteration 20663: loss: 0.053707, loss_s1: 0.051776, loss_fp: 0.001045, loss_freq: 0.010814
[18:14:25.360] iteration 20664: loss: 0.059710, loss_s1: 0.066847, loss_fp: 0.002691, loss_freq: 0.013216
[18:14:26.023] iteration 20665: loss: 0.048483, loss_s1: 0.047136, loss_fp: 0.000641, loss_freq: 0.017314
[18:14:26.654] iteration 20666: loss: 0.055855, loss_s1: 0.020068, loss_fp: 0.002589, loss_freq: 0.040507
[18:14:27.284] iteration 20667: loss: 0.036378, loss_s1: 0.031448, loss_fp: 0.003730, loss_freq: 0.007924
[18:14:27.905] iteration 20668: loss: 0.041533, loss_s1: 0.028714, loss_fp: 0.002278, loss_freq: 0.020302
[18:14:28.536] iteration 20669: loss: 0.032925, loss_s1: 0.013335, loss_fp: 0.003667, loss_freq: 0.018545
[18:14:29.167] iteration 20670: loss: 0.047230, loss_s1: 0.035265, loss_fp: 0.008525, loss_freq: 0.020215
[18:14:29.786] iteration 20671: loss: 0.046653, loss_s1: 0.020065, loss_fp: 0.000700, loss_freq: 0.017694
[18:14:30.416] iteration 20672: loss: 0.053130, loss_s1: 0.028865, loss_fp: 0.005978, loss_freq: 0.032267
[18:14:31.043] iteration 20673: loss: 0.039353, loss_s1: 0.026879, loss_fp: 0.000260, loss_freq: 0.012215
[18:14:31.684] iteration 20674: loss: 0.063082, loss_s1: 0.032722, loss_fp: 0.004423, loss_freq: 0.056987
[18:14:32.326] iteration 20675: loss: 0.049702, loss_s1: 0.013190, loss_fp: 0.001481, loss_freq: 0.021255
[18:14:32.994] iteration 20676: loss: 0.049223, loss_s1: 0.043266, loss_fp: 0.005808, loss_freq: 0.020055
[18:14:33.783] iteration 20677: loss: 0.055405, loss_s1: 0.049763, loss_fp: 0.014990, loss_freq: 0.013336
[18:14:34.746] iteration 20678: loss: 0.063581, loss_s1: 0.043989, loss_fp: 0.002194, loss_freq: 0.018454
[18:14:35.380] iteration 20679: loss: 0.083320, loss_s1: 0.064257, loss_fp: 0.002792, loss_freq: 0.050817
[18:14:36.013] iteration 20680: loss: 0.068126, loss_s1: 0.066456, loss_fp: 0.001080, loss_freq: 0.020437
[18:14:36.646] iteration 20681: loss: 0.051169, loss_s1: 0.045949, loss_fp: 0.000730, loss_freq: 0.014226
[18:14:37.276] iteration 20682: loss: 0.045349, loss_s1: 0.029996, loss_fp: 0.002281, loss_freq: 0.011049
[18:14:37.910] iteration 20683: loss: 0.069393, loss_s1: 0.075018, loss_fp: 0.000489, loss_freq: 0.026082
[18:14:38.538] iteration 20684: loss: 0.059917, loss_s1: 0.058491, loss_fp: 0.000396, loss_freq: 0.011100
[18:14:39.173] iteration 20685: loss: 0.067144, loss_s1: 0.079538, loss_fp: 0.004299, loss_freq: 0.017865
[18:14:39.811] iteration 20686: loss: 0.036188, loss_s1: 0.027233, loss_fp: 0.005485, loss_freq: 0.012363
[18:14:40.452] iteration 20687: loss: 0.030205, loss_s1: 0.019330, loss_fp: 0.000852, loss_freq: 0.009031
[18:14:41.079] iteration 20688: loss: 0.052888, loss_s1: 0.025676, loss_fp: 0.004928, loss_freq: 0.042682
[18:14:41.720] iteration 20689: loss: 0.058911, loss_s1: 0.051069, loss_fp: 0.002939, loss_freq: 0.028592
[18:14:42.348] iteration 20690: loss: 0.049499, loss_s1: 0.031557, loss_fp: 0.008431, loss_freq: 0.028321
[18:14:42.985] iteration 20691: loss: 0.084306, loss_s1: 0.097501, loss_fp: 0.008836, loss_freq: 0.026460
[18:14:43.609] iteration 20692: loss: 0.060218, loss_s1: 0.054899, loss_fp: 0.001768, loss_freq: 0.020939
[18:14:44.235] iteration 20693: loss: 0.079157, loss_s1: 0.065372, loss_fp: 0.013321, loss_freq: 0.037261
[18:14:44.872] iteration 20694: loss: 0.065834, loss_s1: 0.087654, loss_fp: 0.001869, loss_freq: 0.010964
[18:14:45.495] iteration 20695: loss: 0.050428, loss_s1: 0.030062, loss_fp: 0.008837, loss_freq: 0.007929
[18:14:46.122] iteration 20696: loss: 0.072337, loss_s1: 0.061826, loss_fp: 0.011726, loss_freq: 0.029333
[18:14:46.750] iteration 20697: loss: 0.056996, loss_s1: 0.055109, loss_fp: 0.006543, loss_freq: 0.011606
[18:14:47.383] iteration 20698: loss: 0.092504, loss_s1: 0.107153, loss_fp: 0.001286, loss_freq: 0.032518
[18:14:48.006] iteration 20699: loss: 0.054979, loss_s1: 0.039161, loss_fp: 0.004800, loss_freq: 0.015795
[18:14:48.632] iteration 20700: loss: 0.044884, loss_s1: 0.034971, loss_fp: 0.001683, loss_freq: 0.013800
[18:14:49.254] iteration 20701: loss: 0.046153, loss_s1: 0.031976, loss_fp: 0.001075, loss_freq: 0.012731
[18:14:49.879] iteration 20702: loss: 0.055691, loss_s1: 0.056863, loss_fp: 0.004180, loss_freq: 0.018431
[18:14:50.508] iteration 20703: loss: 0.042080, loss_s1: 0.021782, loss_fp: 0.002554, loss_freq: 0.022387
[18:14:51.141] iteration 20704: loss: 0.064151, loss_s1: 0.037515, loss_fp: 0.003652, loss_freq: 0.059724
[18:14:51.772] iteration 20705: loss: 0.037593, loss_s1: 0.013950, loss_fp: 0.002988, loss_freq: 0.013471
[18:14:52.401] iteration 20706: loss: 0.035569, loss_s1: 0.006756, loss_fp: 0.000720, loss_freq: 0.020278
[18:14:53.026] iteration 20707: loss: 0.049134, loss_s1: 0.046320, loss_fp: 0.001658, loss_freq: 0.020901
[18:14:53.651] iteration 20708: loss: 0.061996, loss_s1: 0.060778, loss_fp: 0.006186, loss_freq: 0.016112
[18:14:54.282] iteration 20709: loss: 0.054150, loss_s1: 0.043308, loss_fp: 0.007443, loss_freq: 0.023728
[18:14:54.910] iteration 20710: loss: 0.062126, loss_s1: 0.021600, loss_fp: 0.005072, loss_freq: 0.057602
[18:14:55.544] iteration 20711: loss: 0.047625, loss_s1: 0.017157, loss_fp: 0.005119, loss_freq: 0.039441
[18:14:56.173] iteration 20712: loss: 0.061240, loss_s1: 0.046904, loss_fp: 0.008179, loss_freq: 0.027301
[18:14:56.807] iteration 20713: loss: 0.065797, loss_s1: 0.039624, loss_fp: 0.010109, loss_freq: 0.008267
[18:14:57.436] iteration 20714: loss: 0.047244, loss_s1: 0.029638, loss_fp: 0.003682, loss_freq: 0.012278
[18:14:58.067] iteration 20715: loss: 0.029950, loss_s1: 0.013205, loss_fp: 0.000768, loss_freq: 0.003395
[18:14:58.699] iteration 20716: loss: 0.063615, loss_s1: 0.045085, loss_fp: 0.001435, loss_freq: 0.023067
[18:14:59.332] iteration 20717: loss: 0.106454, loss_s1: 0.057584, loss_fp: 0.011405, loss_freq: 0.106587
[18:14:59.957] iteration 20718: loss: 0.057595, loss_s1: 0.065572, loss_fp: 0.001122, loss_freq: 0.014591
[18:15:00.616] iteration 20719: loss: 0.053520, loss_s1: 0.031407, loss_fp: 0.004024, loss_freq: 0.020623
[18:15:01.290] iteration 20720: loss: 0.058598, loss_s1: 0.039008, loss_fp: 0.004476, loss_freq: 0.035081
[18:15:01.958] iteration 20721: loss: 0.039004, loss_s1: 0.027907, loss_fp: 0.004329, loss_freq: 0.011305
[18:15:02.650] iteration 20722: loss: 0.048358, loss_s1: 0.037330, loss_fp: 0.001218, loss_freq: 0.017803
[18:15:03.309] iteration 20723: loss: 0.035023, loss_s1: 0.018974, loss_fp: 0.006004, loss_freq: 0.007792
[18:15:03.929] iteration 20724: loss: 0.054954, loss_s1: 0.054031, loss_fp: 0.007463, loss_freq: 0.009547
[18:15:04.556] iteration 20725: loss: 0.038840, loss_s1: 0.020717, loss_fp: 0.002620, loss_freq: 0.019735
[18:15:05.180] iteration 20726: loss: 0.039101, loss_s1: 0.025221, loss_fp: 0.005788, loss_freq: 0.010903
[18:15:05.812] iteration 20727: loss: 0.081098, loss_s1: 0.081661, loss_fp: 0.001564, loss_freq: 0.038906
[18:15:06.438] iteration 20728: loss: 0.100997, loss_s1: 0.089109, loss_fp: 0.001873, loss_freq: 0.079908
[18:15:07.069] iteration 20729: loss: 0.116170, loss_s1: 0.053812, loss_fp: 0.000840, loss_freq: 0.141275
[18:15:07.688] iteration 20730: loss: 0.076137, loss_s1: 0.046422, loss_fp: 0.011070, loss_freq: 0.041458
[18:15:08.312] iteration 20731: loss: 0.060196, loss_s1: 0.052401, loss_fp: 0.003029, loss_freq: 0.025360
[18:15:08.943] iteration 20732: loss: 0.042694, loss_s1: 0.040039, loss_fp: 0.002747, loss_freq: 0.006982
[18:15:09.574] iteration 20733: loss: 0.040665, loss_s1: 0.017083, loss_fp: 0.002641, loss_freq: 0.014220
[18:15:10.277] iteration 20734: loss: 0.066751, loss_s1: 0.043294, loss_fp: 0.001807, loss_freq: 0.030387
[18:15:10.941] iteration 20735: loss: 0.052624, loss_s1: 0.065966, loss_fp: 0.001976, loss_freq: 0.004002
[18:15:11.567] iteration 20736: loss: 0.064071, loss_s1: 0.050976, loss_fp: 0.003451, loss_freq: 0.030390
[18:15:12.192] iteration 20737: loss: 0.059850, loss_s1: 0.050184, loss_fp: 0.002948, loss_freq: 0.037883
[18:15:12.822] iteration 20738: loss: 0.036535, loss_s1: 0.037825, loss_fp: 0.000657, loss_freq: 0.008488
[18:15:13.447] iteration 20739: loss: 0.094858, loss_s1: 0.077062, loss_fp: 0.007472, loss_freq: 0.062757
[18:15:14.078] iteration 20740: loss: 0.077573, loss_s1: 0.081480, loss_fp: 0.001301, loss_freq: 0.037995
[18:15:14.708] iteration 20741: loss: 0.052324, loss_s1: 0.037808, loss_fp: 0.007134, loss_freq: 0.016992
[18:15:15.339] iteration 20742: loss: 0.032243, loss_s1: 0.014758, loss_fp: 0.002530, loss_freq: 0.013958
[18:15:15.971] iteration 20743: loss: 0.086528, loss_s1: 0.064500, loss_fp: 0.005406, loss_freq: 0.068795
[18:15:16.603] iteration 20744: loss: 0.062005, loss_s1: 0.057197, loss_fp: 0.004831, loss_freq: 0.031209
[18:15:17.243] iteration 20745: loss: 0.040000, loss_s1: 0.022520, loss_fp: 0.001664, loss_freq: 0.013242
[18:15:17.875] iteration 20746: loss: 0.064939, loss_s1: 0.072743, loss_fp: 0.000653, loss_freq: 0.024279
[18:15:18.495] iteration 20747: loss: 0.053552, loss_s1: 0.046869, loss_fp: 0.001281, loss_freq: 0.024266
[18:15:19.119] iteration 20748: loss: 0.075548, loss_s1: 0.054984, loss_fp: 0.006442, loss_freq: 0.032016
[18:15:19.745] iteration 20749: loss: 0.050829, loss_s1: 0.017257, loss_fp: 0.011262, loss_freq: 0.027575
[18:15:20.377] iteration 20750: loss: 0.044910, loss_s1: 0.039541, loss_fp: 0.002213, loss_freq: 0.016015
[18:15:21.005] iteration 20751: loss: 0.067695, loss_s1: 0.061480, loss_fp: 0.003098, loss_freq: 0.035734
[18:15:21.636] iteration 20752: loss: 0.077725, loss_s1: 0.075638, loss_fp: 0.007759, loss_freq: 0.032547
[18:15:22.262] iteration 20753: loss: 0.055654, loss_s1: 0.067688, loss_fp: 0.005542, loss_freq: 0.005426
[18:15:22.889] iteration 20754: loss: 0.039381, loss_s1: 0.030710, loss_fp: 0.002188, loss_freq: 0.007655
[18:15:23.512] iteration 20755: loss: 0.097079, loss_s1: 0.073633, loss_fp: 0.014709, loss_freq: 0.070877
[18:15:24.145] iteration 20756: loss: 0.040474, loss_s1: 0.021707, loss_fp: 0.000531, loss_freq: 0.020785
[18:15:24.775] iteration 20757: loss: 0.042216, loss_s1: 0.034311, loss_fp: 0.004494, loss_freq: 0.008664
[18:15:25.399] iteration 20758: loss: 0.083669, loss_s1: 0.061381, loss_fp: 0.002515, loss_freq: 0.056693
[18:15:26.024] iteration 20759: loss: 0.036548, loss_s1: 0.021640, loss_fp: 0.001984, loss_freq: 0.011645
[18:15:26.642] iteration 20760: loss: 0.089245, loss_s1: 0.089296, loss_fp: 0.003108, loss_freq: 0.049991
[18:15:27.263] iteration 20761: loss: 0.039542, loss_s1: 0.030135, loss_fp: 0.001111, loss_freq: 0.020183
[18:15:27.889] iteration 20762: loss: 0.070676, loss_s1: 0.059656, loss_fp: 0.008236, loss_freq: 0.014026
[18:15:28.513] iteration 20763: loss: 0.032806, loss_s1: 0.019823, loss_fp: 0.002910, loss_freq: 0.010222
[18:15:29.136] iteration 20764: loss: 0.051084, loss_s1: 0.020648, loss_fp: 0.006449, loss_freq: 0.030359
[18:15:29.758] iteration 20765: loss: 0.046707, loss_s1: 0.036825, loss_fp: 0.000594, loss_freq: 0.019765
[18:15:30.387] iteration 20766: loss: 0.066130, loss_s1: 0.060498, loss_fp: 0.000305, loss_freq: 0.029993
[18:15:31.012] iteration 20767: loss: 0.057791, loss_s1: 0.047949, loss_fp: 0.001368, loss_freq: 0.021586
[18:15:31.638] iteration 20768: loss: 0.095404, loss_s1: 0.118242, loss_fp: 0.001874, loss_freq: 0.020546
[18:15:32.267] iteration 20769: loss: 0.062923, loss_s1: 0.039373, loss_fp: 0.002780, loss_freq: 0.044964
[18:15:33.266] iteration 20770: loss: 0.054740, loss_s1: 0.042754, loss_fp: 0.002698, loss_freq: 0.030169
[18:15:33.989] iteration 20771: loss: 0.098601, loss_s1: 0.095307, loss_fp: 0.010688, loss_freq: 0.058741
[18:15:34.656] iteration 20772: loss: 0.044790, loss_s1: 0.039618, loss_fp: 0.001581, loss_freq: 0.009447
[18:15:35.325] iteration 20773: loss: 0.039319, loss_s1: 0.021312, loss_fp: 0.001342, loss_freq: 0.016242
[18:15:35.963] iteration 20774: loss: 0.061812, loss_s1: 0.060521, loss_fp: 0.004328, loss_freq: 0.021014
[18:15:36.593] iteration 20775: loss: 0.085744, loss_s1: 0.057693, loss_fp: 0.012392, loss_freq: 0.044566
[18:15:37.221] iteration 20776: loss: 0.050986, loss_s1: 0.032727, loss_fp: 0.003085, loss_freq: 0.031489
[18:15:37.840] iteration 20777: loss: 0.034891, loss_s1: 0.013066, loss_fp: 0.002584, loss_freq: 0.020247
[18:15:38.517] iteration 20778: loss: 0.083504, loss_s1: 0.050319, loss_fp: 0.004974, loss_freq: 0.074920
[18:15:39.182] iteration 20779: loss: 0.086130, loss_s1: 0.085926, loss_fp: 0.004945, loss_freq: 0.042615
[18:15:39.840] iteration 20780: loss: 0.028147, loss_s1: 0.007243, loss_fp: 0.001474, loss_freq: 0.008460
[18:15:40.511] iteration 20781: loss: 0.061551, loss_s1: 0.030558, loss_fp: 0.000749, loss_freq: 0.059943
[18:15:41.133] iteration 20782: loss: 0.072470, loss_s1: 0.050239, loss_fp: 0.013343, loss_freq: 0.045245
[18:15:41.759] iteration 20783: loss: 0.043847, loss_s1: 0.030123, loss_fp: 0.005872, loss_freq: 0.015642
[18:15:42.392] iteration 20784: loss: 0.062979, loss_s1: 0.076900, loss_fp: 0.004433, loss_freq: 0.016832
[18:15:43.015] iteration 20785: loss: 0.058572, loss_s1: 0.052450, loss_fp: 0.004042, loss_freq: 0.025256
[18:15:43.644] iteration 20786: loss: 0.060776, loss_s1: 0.066519, loss_fp: 0.002308, loss_freq: 0.012942
[18:15:44.269] iteration 20787: loss: 0.088274, loss_s1: 0.085386, loss_fp: 0.004910, loss_freq: 0.053965
[18:15:44.893] iteration 20788: loss: 0.047318, loss_s1: 0.033496, loss_fp: 0.000972, loss_freq: 0.028821
[18:15:45.518] iteration 20789: loss: 0.038826, loss_s1: 0.019253, loss_fp: 0.002937, loss_freq: 0.016340
[18:15:46.140] iteration 20790: loss: 0.045839, loss_s1: 0.035487, loss_fp: 0.000448, loss_freq: 0.018016
[18:15:46.763] iteration 20791: loss: 0.073005, loss_s1: 0.051966, loss_fp: 0.000994, loss_freq: 0.019258
[18:15:47.389] iteration 20792: loss: 0.038448, loss_s1: 0.016769, loss_fp: 0.003182, loss_freq: 0.013394
[18:15:48.021] iteration 20793: loss: 0.102544, loss_s1: 0.134481, loss_fp: 0.004987, loss_freq: 0.031592
[18:15:48.647] iteration 20794: loss: 0.046354, loss_s1: 0.039540, loss_fp: 0.001420, loss_freq: 0.018115
[18:15:49.326] iteration 20795: loss: 0.075280, loss_s1: 0.080147, loss_fp: 0.001414, loss_freq: 0.039239
[18:15:49.985] iteration 20796: loss: 0.040928, loss_s1: 0.024712, loss_fp: 0.002036, loss_freq: 0.018206
[18:15:50.646] iteration 20797: loss: 0.068671, loss_s1: 0.062589, loss_fp: 0.007787, loss_freq: 0.021169
[18:15:51.304] iteration 20798: loss: 0.079778, loss_s1: 0.055590, loss_fp: 0.003868, loss_freq: 0.058871
[18:15:51.940] iteration 20799: loss: 0.055016, loss_s1: 0.063757, loss_fp: 0.004196, loss_freq: 0.005947
[18:15:52.644] iteration 20800: loss: 0.048950, loss_s1: 0.043550, loss_fp: 0.000998, loss_freq: 0.023472
[18:15:55.827] iteration 20800 : mean_dice : 0.727858
[18:15:56.526] iteration 20801: loss: 0.065684, loss_s1: 0.041307, loss_fp: 0.004394, loss_freq: 0.031348
[18:15:57.197] iteration 20802: loss: 0.048448, loss_s1: 0.031510, loss_fp: 0.005947, loss_freq: 0.031294
[18:15:57.854] iteration 20803: loss: 0.040414, loss_s1: 0.038239, loss_fp: 0.004170, loss_freq: 0.007965
[18:15:58.481] iteration 20804: loss: 0.063634, loss_s1: 0.022185, loss_fp: 0.005838, loss_freq: 0.016405
[18:15:59.131] iteration 20805: loss: 0.083014, loss_s1: 0.074357, loss_fp: 0.010772, loss_freq: 0.048573
[18:15:59.771] iteration 20806: loss: 0.060293, loss_s1: 0.051655, loss_fp: 0.009322, loss_freq: 0.022212
[18:16:00.428] iteration 20807: loss: 0.064641, loss_s1: 0.059788, loss_fp: 0.006468, loss_freq: 0.024815
[18:16:01.094] iteration 20808: loss: 0.088366, loss_s1: 0.058694, loss_fp: 0.002065, loss_freq: 0.076240
[18:16:01.731] iteration 20809: loss: 0.064876, loss_s1: 0.038789, loss_fp: 0.002129, loss_freq: 0.054411
[18:16:02.375] iteration 20810: loss: 0.068407, loss_s1: 0.038095, loss_fp: 0.003667, loss_freq: 0.024370
[18:16:03.021] iteration 20811: loss: 0.049308, loss_s1: 0.042058, loss_fp: 0.003650, loss_freq: 0.015184
[18:16:03.661] iteration 20812: loss: 0.047764, loss_s1: 0.019942, loss_fp: 0.005815, loss_freq: 0.041590
[18:16:04.309] iteration 20813: loss: 0.042668, loss_s1: 0.021607, loss_fp: 0.002428, loss_freq: 0.032721
[18:16:04.996] iteration 20814: loss: 0.059269, loss_s1: 0.056322, loss_fp: 0.011806, loss_freq: 0.017029
[18:16:05.637] iteration 20815: loss: 0.054438, loss_s1: 0.055536, loss_fp: 0.001145, loss_freq: 0.007059
[18:16:06.270] iteration 20816: loss: 0.044221, loss_s1: 0.015446, loss_fp: 0.001506, loss_freq: 0.013658
[18:16:06.922] iteration 20817: loss: 0.052296, loss_s1: 0.045479, loss_fp: 0.003638, loss_freq: 0.023674
[18:16:07.591] iteration 20818: loss: 0.071483, loss_s1: 0.047509, loss_fp: 0.007389, loss_freq: 0.027661
[18:16:08.261] iteration 20819: loss: 0.063023, loss_s1: 0.040648, loss_fp: 0.004495, loss_freq: 0.051918
[18:16:08.930] iteration 20820: loss: 0.053441, loss_s1: 0.025301, loss_fp: 0.003364, loss_freq: 0.041203
[18:16:09.563] iteration 20821: loss: 0.068994, loss_s1: 0.048648, loss_fp: 0.022503, loss_freq: 0.030199
[18:16:10.190] iteration 20822: loss: 0.046403, loss_s1: 0.033668, loss_fp: 0.004016, loss_freq: 0.022982
[18:16:10.814] iteration 20823: loss: 0.053682, loss_s1: 0.041220, loss_fp: 0.007066, loss_freq: 0.025351
[18:16:11.447] iteration 20824: loss: 0.058623, loss_s1: 0.057827, loss_fp: 0.005969, loss_freq: 0.011603
[18:16:12.078] iteration 20825: loss: 0.081561, loss_s1: 0.085647, loss_fp: 0.007429, loss_freq: 0.017120
[18:16:12.706] iteration 20826: loss: 0.033678, loss_s1: 0.023241, loss_fp: 0.000572, loss_freq: 0.005827
[18:16:13.339] iteration 20827: loss: 0.041624, loss_s1: 0.022783, loss_fp: 0.000906, loss_freq: 0.016384
[18:16:13.972] iteration 20828: loss: 0.032551, loss_s1: 0.020433, loss_fp: 0.005770, loss_freq: 0.008845
[18:16:14.594] iteration 20829: loss: 0.048337, loss_s1: 0.034646, loss_fp: 0.001849, loss_freq: 0.026963
[18:16:15.225] iteration 20830: loss: 0.053815, loss_s1: 0.030086, loss_fp: 0.002234, loss_freq: 0.043587
[18:16:15.848] iteration 20831: loss: 0.045699, loss_s1: 0.044204, loss_fp: 0.006624, loss_freq: 0.011044
[18:16:16.483] iteration 20832: loss: 0.038626, loss_s1: 0.028962, loss_fp: 0.001846, loss_freq: 0.005357
[18:16:17.112] iteration 20833: loss: 0.052285, loss_s1: 0.034264, loss_fp: 0.005417, loss_freq: 0.025724
[18:16:17.740] iteration 20834: loss: 0.044985, loss_s1: 0.024144, loss_fp: 0.011250, loss_freq: 0.018856
[18:16:18.375] iteration 20835: loss: 0.040712, loss_s1: 0.012885, loss_fp: 0.001746, loss_freq: 0.036654
[18:16:19.004] iteration 20836: loss: 0.055410, loss_s1: 0.027030, loss_fp: 0.001193, loss_freq: 0.040751
[18:16:19.635] iteration 20837: loss: 0.061044, loss_s1: 0.041552, loss_fp: 0.002797, loss_freq: 0.047384
[18:16:20.266] iteration 20838: loss: 0.043658, loss_s1: 0.031045, loss_fp: 0.009070, loss_freq: 0.016444
[18:16:20.887] iteration 20839: loss: 0.076803, loss_s1: 0.055112, loss_fp: 0.003197, loss_freq: 0.037467
[18:16:21.517] iteration 20840: loss: 0.080123, loss_s1: 0.078243, loss_fp: 0.010234, loss_freq: 0.040176
[18:16:22.147] iteration 20841: loss: 0.065796, loss_s1: 0.036731, loss_fp: 0.000893, loss_freq: 0.034901
[18:16:22.768] iteration 20842: loss: 0.041218, loss_s1: 0.029037, loss_fp: 0.005691, loss_freq: 0.008232
[18:16:23.389] iteration 20843: loss: 0.046029, loss_s1: 0.033918, loss_fp: 0.008834, loss_freq: 0.007971
[18:16:24.017] iteration 20844: loss: 0.059990, loss_s1: 0.069338, loss_fp: 0.003732, loss_freq: 0.010784
[18:16:24.649] iteration 20845: loss: 0.069440, loss_s1: 0.082492, loss_fp: 0.000407, loss_freq: 0.013621
[18:16:25.273] iteration 20846: loss: 0.048736, loss_s1: 0.026669, loss_fp: 0.002037, loss_freq: 0.025481
[18:16:25.907] iteration 20847: loss: 0.047168, loss_s1: 0.043933, loss_fp: 0.002681, loss_freq: 0.016054
[18:16:26.554] iteration 20848: loss: 0.053068, loss_s1: 0.062005, loss_fp: 0.004792, loss_freq: 0.011794
[18:16:27.186] iteration 20849: loss: 0.057752, loss_s1: 0.048343, loss_fp: 0.004093, loss_freq: 0.020390
[18:16:27.811] iteration 20850: loss: 0.068640, loss_s1: 0.053799, loss_fp: 0.002707, loss_freq: 0.045538
[18:16:28.438] iteration 20851: loss: 0.052848, loss_s1: 0.049321, loss_fp: 0.003894, loss_freq: 0.021343
[18:16:29.066] iteration 20852: loss: 0.070483, loss_s1: 0.061674, loss_fp: 0.012294, loss_freq: 0.035134
[18:16:29.693] iteration 20853: loss: 0.072239, loss_s1: 0.052629, loss_fp: 0.001569, loss_freq: 0.037253
[18:16:30.329] iteration 20854: loss: 0.058141, loss_s1: 0.044477, loss_fp: 0.012959, loss_freq: 0.027150
[18:16:30.959] iteration 20855: loss: 0.044985, loss_s1: 0.036113, loss_fp: 0.002790, loss_freq: 0.017838
[18:16:31.588] iteration 20856: loss: 0.050028, loss_s1: 0.033282, loss_fp: 0.001121, loss_freq: 0.017194
[18:16:32.208] iteration 20857: loss: 0.050449, loss_s1: 0.046600, loss_fp: 0.003281, loss_freq: 0.015235
[18:16:32.851] iteration 20858: loss: 0.061138, loss_s1: 0.044634, loss_fp: 0.002154, loss_freq: 0.041140
[18:16:33.520] iteration 20859: loss: 0.066262, loss_s1: 0.043528, loss_fp: 0.003101, loss_freq: 0.048162
[18:16:34.149] iteration 20860: loss: 0.076072, loss_s1: 0.053618, loss_fp: 0.002190, loss_freq: 0.045096
[18:16:34.807] iteration 20861: loss: 0.104218, loss_s1: 0.104553, loss_fp: 0.014201, loss_freq: 0.041379
[18:16:35.447] iteration 20862: loss: 0.051784, loss_s1: 0.020258, loss_fp: 0.002045, loss_freq: 0.023428
[18:16:36.069] iteration 20863: loss: 0.042539, loss_s1: 0.030392, loss_fp: 0.002632, loss_freq: 0.020300
[18:16:36.729] iteration 20864: loss: 0.035764, loss_s1: 0.014828, loss_fp: 0.004045, loss_freq: 0.023511
[18:16:37.396] iteration 20865: loss: 0.064864, loss_s1: 0.044843, loss_fp: 0.001063, loss_freq: 0.053574
[18:16:38.070] iteration 20866: loss: 0.038396, loss_s1: 0.025763, loss_fp: 0.001087, loss_freq: 0.016233
[18:16:38.750] iteration 20867: loss: 0.043812, loss_s1: 0.012680, loss_fp: 0.000515, loss_freq: 0.031774
[18:16:39.390] iteration 20868: loss: 0.051490, loss_s1: 0.038593, loss_fp: 0.002872, loss_freq: 0.022078
[18:16:40.135] iteration 20869: loss: 0.100941, loss_s1: 0.105980, loss_fp: 0.004474, loss_freq: 0.054824
[18:16:40.763] iteration 20870: loss: 0.057604, loss_s1: 0.060986, loss_fp: 0.007164, loss_freq: 0.018619
[18:16:41.388] iteration 20871: loss: 0.078357, loss_s1: 0.066369, loss_fp: 0.003264, loss_freq: 0.049603
[18:16:42.012] iteration 20872: loss: 0.077469, loss_s1: 0.059793, loss_fp: 0.006053, loss_freq: 0.054299
[18:16:42.646] iteration 20873: loss: 0.053764, loss_s1: 0.032358, loss_fp: 0.004065, loss_freq: 0.021985
[18:16:43.277] iteration 20874: loss: 0.048910, loss_s1: 0.031779, loss_fp: 0.002858, loss_freq: 0.015892
[18:16:43.909] iteration 20875: loss: 0.040103, loss_s1: 0.017511, loss_fp: 0.001177, loss_freq: 0.024763
[18:16:44.539] iteration 20876: loss: 0.042179, loss_s1: 0.041045, loss_fp: 0.001773, loss_freq: 0.006803
[18:16:45.167] iteration 20877: loss: 0.072813, loss_s1: 0.033392, loss_fp: 0.001257, loss_freq: 0.048260
[18:16:45.792] iteration 20878: loss: 0.077636, loss_s1: 0.054622, loss_fp: 0.002177, loss_freq: 0.057287
[18:16:46.420] iteration 20879: loss: 0.040181, loss_s1: 0.019516, loss_fp: 0.002459, loss_freq: 0.020122
[18:16:47.053] iteration 20880: loss: 0.042087, loss_s1: 0.031853, loss_fp: 0.001811, loss_freq: 0.006292
[18:16:47.680] iteration 20881: loss: 0.074234, loss_s1: 0.083628, loss_fp: 0.002798, loss_freq: 0.029947
[18:16:48.309] iteration 20882: loss: 0.060327, loss_s1: 0.056360, loss_fp: 0.010554, loss_freq: 0.021797
[18:16:48.936] iteration 20883: loss: 0.053955, loss_s1: 0.026108, loss_fp: 0.002327, loss_freq: 0.042058
[18:16:49.559] iteration 20884: loss: 0.036979, loss_s1: 0.019668, loss_fp: 0.002003, loss_freq: 0.013688
[18:16:50.216] iteration 20885: loss: 0.060536, loss_s1: 0.038931, loss_fp: 0.000933, loss_freq: 0.040352
[18:16:50.846] iteration 20886: loss: 0.029983, loss_s1: 0.022841, loss_fp: 0.003868, loss_freq: 0.004119
[18:16:51.465] iteration 20887: loss: 0.039119, loss_s1: 0.032483, loss_fp: 0.001005, loss_freq: 0.013849
[18:16:52.093] iteration 20888: loss: 0.063627, loss_s1: 0.048781, loss_fp: 0.003161, loss_freq: 0.026919
[18:16:52.751] iteration 20889: loss: 0.078554, loss_s1: 0.043492, loss_fp: 0.003707, loss_freq: 0.074936
[18:16:53.411] iteration 20890: loss: 0.053881, loss_s1: 0.044028, loss_fp: 0.004340, loss_freq: 0.025939
[18:16:54.076] iteration 20891: loss: 0.101980, loss_s1: 0.092442, loss_fp: 0.022608, loss_freq: 0.028294
[18:16:54.736] iteration 20892: loss: 0.100373, loss_s1: 0.135155, loss_fp: 0.005410, loss_freq: 0.017953
[18:16:55.358] iteration 20893: loss: 0.044152, loss_s1: 0.030087, loss_fp: 0.007477, loss_freq: 0.013299
[18:16:55.995] iteration 20894: loss: 0.039224, loss_s1: 0.017877, loss_fp: 0.001064, loss_freq: 0.020065
[18:16:56.636] iteration 20895: loss: 0.053481, loss_s1: 0.032857, loss_fp: 0.008216, loss_freq: 0.023521
[18:16:57.263] iteration 20896: loss: 0.050774, loss_s1: 0.048401, loss_fp: 0.001537, loss_freq: 0.010684
[18:16:57.895] iteration 20897: loss: 0.117091, loss_s1: 0.135947, loss_fp: 0.005616, loss_freq: 0.048351
[18:16:58.523] iteration 20898: loss: 0.059062, loss_s1: 0.037394, loss_fp: 0.018822, loss_freq: 0.030655
[18:16:59.147] iteration 20899: loss: 0.054408, loss_s1: 0.045294, loss_fp: 0.006685, loss_freq: 0.021406
[18:16:59.772] iteration 20900: loss: 0.089534, loss_s1: 0.095041, loss_fp: 0.013463, loss_freq: 0.037717
[18:17:00.394] iteration 20901: loss: 0.056955, loss_s1: 0.048751, loss_fp: 0.002815, loss_freq: 0.024366
[18:17:01.026] iteration 20902: loss: 0.061082, loss_s1: 0.046950, loss_fp: 0.007606, loss_freq: 0.023616
[18:17:01.661] iteration 20903: loss: 0.049100, loss_s1: 0.035338, loss_fp: 0.009717, loss_freq: 0.022478
[18:17:02.290] iteration 20904: loss: 0.064425, loss_s1: 0.064013, loss_fp: 0.002223, loss_freq: 0.028170
[18:17:02.922] iteration 20905: loss: 0.029740, loss_s1: 0.013867, loss_fp: 0.001682, loss_freq: 0.012203
[18:17:03.556] iteration 20906: loss: 0.037513, loss_s1: 0.032257, loss_fp: 0.001918, loss_freq: 0.006640
[18:17:04.190] iteration 20907: loss: 0.047040, loss_s1: 0.043875, loss_fp: 0.001960, loss_freq: 0.016390
[18:17:04.815] iteration 20908: loss: 0.054133, loss_s1: 0.040141, loss_fp: 0.006354, loss_freq: 0.025155
[18:17:05.446] iteration 20909: loss: 0.058256, loss_s1: 0.025011, loss_fp: 0.008566, loss_freq: 0.026277
[18:17:06.072] iteration 20910: loss: 0.070730, loss_s1: 0.057128, loss_fp: 0.004887, loss_freq: 0.030393
[18:17:06.691] iteration 20911: loss: 0.038928, loss_s1: 0.014473, loss_fp: 0.003044, loss_freq: 0.025867
[18:17:07.320] iteration 20912: loss: 0.081727, loss_s1: 0.082444, loss_fp: 0.005374, loss_freq: 0.041341
[18:17:07.944] iteration 20913: loss: 0.057726, loss_s1: 0.052086, loss_fp: 0.011281, loss_freq: 0.012784
[18:17:08.569] iteration 20914: loss: 0.054743, loss_s1: 0.043647, loss_fp: 0.003891, loss_freq: 0.028325
[18:17:09.190] iteration 20915: loss: 0.063163, loss_s1: 0.050211, loss_fp: 0.011399, loss_freq: 0.027643
[18:17:09.822] iteration 20916: loss: 0.092184, loss_s1: 0.063961, loss_fp: 0.006929, loss_freq: 0.086419
[18:17:10.450] iteration 20917: loss: 0.062183, loss_s1: 0.078993, loss_fp: 0.001193, loss_freq: 0.017070
[18:17:11.081] iteration 20918: loss: 0.042812, loss_s1: 0.034040, loss_fp: 0.001443, loss_freq: 0.014439
[18:17:11.731] iteration 20919: loss: 0.087188, loss_s1: 0.078541, loss_fp: 0.011511, loss_freq: 0.046907
[18:17:12.401] iteration 20920: loss: 0.050922, loss_s1: 0.024624, loss_fp: 0.002981, loss_freq: 0.036920
[18:17:13.075] iteration 20921: loss: 0.075268, loss_s1: 0.067541, loss_fp: 0.003046, loss_freq: 0.045958
[18:17:13.718] iteration 20922: loss: 0.039615, loss_s1: 0.025728, loss_fp: 0.004894, loss_freq: 0.015575
[18:17:14.350] iteration 20923: loss: 0.059086, loss_s1: 0.054201, loss_fp: 0.003346, loss_freq: 0.021107
[18:17:14.987] iteration 20924: loss: 0.033385, loss_s1: 0.028082, loss_fp: 0.000727, loss_freq: 0.009398
[18:17:15.623] iteration 20925: loss: 0.031811, loss_s1: 0.013863, loss_fp: 0.000800, loss_freq: 0.009299
[18:17:16.250] iteration 20926: loss: 0.045251, loss_s1: 0.028130, loss_fp: 0.001096, loss_freq: 0.024276
[18:17:16.880] iteration 20927: loss: 0.084293, loss_s1: 0.075149, loss_fp: 0.001070, loss_freq: 0.054935
[18:17:17.542] iteration 20928: loss: 0.044743, loss_s1: 0.036583, loss_fp: 0.003355, loss_freq: 0.015890
[18:17:18.209] iteration 20929: loss: 0.055995, loss_s1: 0.046273, loss_fp: 0.013139, loss_freq: 0.026649
[18:17:18.849] iteration 20930: loss: 0.047660, loss_s1: 0.020706, loss_fp: 0.002187, loss_freq: 0.028601
[18:17:19.821] iteration 20931: loss: 0.031927, loss_s1: 0.015122, loss_fp: 0.001306, loss_freq: 0.010846
[18:17:20.450] iteration 20932: loss: 0.065405, loss_s1: 0.043180, loss_fp: 0.012976, loss_freq: 0.026820
[18:17:21.068] iteration 20933: loss: 0.042047, loss_s1: 0.037893, loss_fp: 0.001604, loss_freq: 0.010045
[18:17:21.696] iteration 20934: loss: 0.047282, loss_s1: 0.044157, loss_fp: 0.000625, loss_freq: 0.005288
[18:17:22.325] iteration 20935: loss: 0.054444, loss_s1: 0.041796, loss_fp: 0.005172, loss_freq: 0.025878
[18:17:22.956] iteration 20936: loss: 0.073203, loss_s1: 0.061438, loss_fp: 0.002458, loss_freq: 0.043221
[18:17:23.590] iteration 20937: loss: 0.031569, loss_s1: 0.026165, loss_fp: 0.000709, loss_freq: 0.006785
[18:17:24.215] iteration 20938: loss: 0.053936, loss_s1: 0.066009, loss_fp: 0.001750, loss_freq: 0.010086
[18:17:24.852] iteration 20939: loss: 0.078990, loss_s1: 0.067203, loss_fp: 0.012542, loss_freq: 0.045432
[18:17:25.482] iteration 20940: loss: 0.086793, loss_s1: 0.067531, loss_fp: 0.004899, loss_freq: 0.060452
[18:17:26.117] iteration 20941: loss: 0.038104, loss_s1: 0.021053, loss_fp: 0.001806, loss_freq: 0.007889
[18:17:26.748] iteration 20942: loss: 0.036007, loss_s1: 0.026659, loss_fp: 0.001034, loss_freq: 0.013777
[18:17:27.416] iteration 20943: loss: 0.072249, loss_s1: 0.062903, loss_fp: 0.006789, loss_freq: 0.044333
[18:17:28.078] iteration 20944: loss: 0.060949, loss_s1: 0.045084, loss_fp: 0.001568, loss_freq: 0.022016
[18:17:28.736] iteration 20945: loss: 0.097709, loss_s1: 0.102672, loss_fp: 0.009311, loss_freq: 0.057923
[18:17:29.360] iteration 20946: loss: 0.099382, loss_s1: 0.097585, loss_fp: 0.020918, loss_freq: 0.049248
[18:17:29.994] iteration 20947: loss: 0.049612, loss_s1: 0.037381, loss_fp: 0.006705, loss_freq: 0.018145
[18:17:30.625] iteration 20948: loss: 0.065402, loss_s1: 0.059338, loss_fp: 0.005016, loss_freq: 0.029215
[18:17:31.259] iteration 20949: loss: 0.052134, loss_s1: 0.025734, loss_fp: 0.001490, loss_freq: 0.011703
[18:17:31.897] iteration 20950: loss: 0.050970, loss_s1: 0.024460, loss_fp: 0.002293, loss_freq: 0.019728
[18:17:32.530] iteration 20951: loss: 0.033233, loss_s1: 0.016535, loss_fp: 0.000622, loss_freq: 0.005839
[18:17:33.160] iteration 20952: loss: 0.041434, loss_s1: 0.024745, loss_fp: 0.003872, loss_freq: 0.011699
[18:17:33.787] iteration 20953: loss: 0.062971, loss_s1: 0.036932, loss_fp: 0.001230, loss_freq: 0.038416
[18:17:34.424] iteration 20954: loss: 0.106847, loss_s1: 0.061368, loss_fp: 0.002484, loss_freq: 0.103796
[18:17:35.054] iteration 20955: loss: 0.048191, loss_s1: 0.048878, loss_fp: 0.001922, loss_freq: 0.016697
[18:17:35.685] iteration 20956: loss: 0.050515, loss_s1: 0.030919, loss_fp: 0.001804, loss_freq: 0.037198
[18:17:36.332] iteration 20957: loss: 0.034568, loss_s1: 0.026115, loss_fp: 0.000639, loss_freq: 0.007568
[18:17:36.955] iteration 20958: loss: 0.109790, loss_s1: 0.078481, loss_fp: 0.007501, loss_freq: 0.087817
[18:17:37.587] iteration 20959: loss: 0.055434, loss_s1: 0.028224, loss_fp: 0.005007, loss_freq: 0.041938
[18:17:38.215] iteration 20960: loss: 0.041292, loss_s1: 0.031907, loss_fp: 0.001703, loss_freq: 0.014582
[18:17:38.835] iteration 20961: loss: 0.043212, loss_s1: 0.035658, loss_fp: 0.002439, loss_freq: 0.017433
[18:17:39.461] iteration 20962: loss: 0.045999, loss_s1: 0.012212, loss_fp: 0.003661, loss_freq: 0.017767
[18:17:40.090] iteration 20963: loss: 0.053784, loss_s1: 0.037047, loss_fp: 0.001884, loss_freq: 0.034380
[18:17:40.716] iteration 20964: loss: 0.038335, loss_s1: 0.027797, loss_fp: 0.002618, loss_freq: 0.014847
[18:17:41.383] iteration 20965: loss: 0.053360, loss_s1: 0.027197, loss_fp: 0.000550, loss_freq: 0.030630
[18:17:42.050] iteration 20966: loss: 0.087464, loss_s1: 0.079369, loss_fp: 0.005766, loss_freq: 0.038495
[18:17:42.721] iteration 20967: loss: 0.079747, loss_s1: 0.080527, loss_fp: 0.005320, loss_freq: 0.036947
[18:17:43.347] iteration 20968: loss: 0.065432, loss_s1: 0.049695, loss_fp: 0.002801, loss_freq: 0.040322
[18:17:43.980] iteration 20969: loss: 0.081013, loss_s1: 0.059704, loss_fp: 0.000985, loss_freq: 0.046616
[18:17:44.614] iteration 20970: loss: 0.062847, loss_s1: 0.033932, loss_fp: 0.001950, loss_freq: 0.059490
[18:17:45.252] iteration 20971: loss: 0.046393, loss_s1: 0.035680, loss_fp: 0.001999, loss_freq: 0.016230
[18:17:45.886] iteration 20972: loss: 0.058632, loss_s1: 0.047407, loss_fp: 0.006440, loss_freq: 0.033726
[18:17:46.518] iteration 20973: loss: 0.068570, loss_s1: 0.051777, loss_fp: 0.007078, loss_freq: 0.047459
[18:17:47.161] iteration 20974: loss: 0.063790, loss_s1: 0.049983, loss_fp: 0.004698, loss_freq: 0.031493
[18:17:47.799] iteration 20975: loss: 0.048050, loss_s1: 0.031560, loss_fp: 0.001095, loss_freq: 0.017346
[18:17:48.430] iteration 20976: loss: 0.044706, loss_s1: 0.040887, loss_fp: 0.000992, loss_freq: 0.008574
[18:17:49.055] iteration 20977: loss: 0.025101, loss_s1: 0.013362, loss_fp: 0.001420, loss_freq: 0.007487
[18:17:49.678] iteration 20978: loss: 0.056952, loss_s1: 0.048572, loss_fp: 0.013176, loss_freq: 0.017771
[18:17:50.311] iteration 20979: loss: 0.047775, loss_s1: 0.041078, loss_fp: 0.004995, loss_freq: 0.010677
[18:17:50.945] iteration 20980: loss: 0.061342, loss_s1: 0.048057, loss_fp: 0.003916, loss_freq: 0.039721
[18:17:51.565] iteration 20981: loss: 0.043468, loss_s1: 0.024902, loss_fp: 0.002159, loss_freq: 0.025550
[18:17:52.195] iteration 20982: loss: 0.045897, loss_s1: 0.036036, loss_fp: 0.002801, loss_freq: 0.015099
[18:17:52.825] iteration 20983: loss: 0.080717, loss_s1: 0.051004, loss_fp: 0.001777, loss_freq: 0.057442
[18:17:53.442] iteration 20984: loss: 0.076981, loss_s1: 0.062096, loss_fp: 0.007229, loss_freq: 0.049469
[18:17:54.103] iteration 20985: loss: 0.044071, loss_s1: 0.026332, loss_fp: 0.000644, loss_freq: 0.015031
[18:17:54.767] iteration 20986: loss: 0.064155, loss_s1: 0.052779, loss_fp: 0.004049, loss_freq: 0.026630
[18:17:55.425] iteration 20987: loss: 0.033505, loss_s1: 0.016462, loss_fp: 0.001470, loss_freq: 0.007005
[18:17:56.061] iteration 20988: loss: 0.061346, loss_s1: 0.038328, loss_fp: 0.002665, loss_freq: 0.036264
[18:17:56.680] iteration 20989: loss: 0.039882, loss_s1: 0.026331, loss_fp: 0.002000, loss_freq: 0.020831
[18:17:57.303] iteration 20990: loss: 0.052741, loss_s1: 0.040077, loss_fp: 0.002080, loss_freq: 0.031912
[18:17:57.930] iteration 20991: loss: 0.037921, loss_s1: 0.012823, loss_fp: 0.004003, loss_freq: 0.028758
[18:17:58.560] iteration 20992: loss: 0.034977, loss_s1: 0.017569, loss_fp: 0.010654, loss_freq: 0.006820
[18:17:59.194] iteration 20993: loss: 0.035795, loss_s1: 0.015096, loss_fp: 0.002827, loss_freq: 0.007798
[18:17:59.814] iteration 20994: loss: 0.059426, loss_s1: 0.029503, loss_fp: 0.003261, loss_freq: 0.044779
[18:18:00.454] iteration 20995: loss: 0.044330, loss_s1: 0.026380, loss_fp: 0.007135, loss_freq: 0.021468
[18:18:01.084] iteration 20996: loss: 0.058827, loss_s1: 0.047587, loss_fp: 0.003074, loss_freq: 0.037250
[18:18:01.705] iteration 20997: loss: 0.056080, loss_s1: 0.021289, loss_fp: 0.003597, loss_freq: 0.030392
[18:18:02.336] iteration 20998: loss: 0.054675, loss_s1: 0.033089, loss_fp: 0.007559, loss_freq: 0.037034
[18:18:02.955] iteration 20999: loss: 0.047669, loss_s1: 0.051450, loss_fp: 0.001347, loss_freq: 0.003525
[18:18:03.590] iteration 21000: loss: 0.058679, loss_s1: 0.031385, loss_fp: 0.011330, loss_freq: 0.018945
[18:18:06.906] iteration 21000 : mean_dice : 0.735023
[18:18:07.605] iteration 21001: loss: 0.062672, loss_s1: 0.051060, loss_fp: 0.010414, loss_freq: 0.031866
[18:18:08.264] iteration 21002: loss: 0.054462, loss_s1: 0.050801, loss_fp: 0.002414, loss_freq: 0.018040
[18:18:08.925] iteration 21003: loss: 0.048246, loss_s1: 0.028525, loss_fp: 0.001629, loss_freq: 0.025065
[18:18:09.556] iteration 21004: loss: 0.035771, loss_s1: 0.019434, loss_fp: 0.003170, loss_freq: 0.009835
[18:18:10.180] iteration 21005: loss: 0.082331, loss_s1: 0.087690, loss_fp: 0.001562, loss_freq: 0.038746
[18:18:10.810] iteration 21006: loss: 0.061576, loss_s1: 0.057290, loss_fp: 0.007063, loss_freq: 0.018564
[18:18:11.430] iteration 21007: loss: 0.069361, loss_s1: 0.049810, loss_fp: 0.003208, loss_freq: 0.046707
[18:18:12.057] iteration 21008: loss: 0.067397, loss_s1: 0.087588, loss_fp: 0.008477, loss_freq: 0.007445
[18:18:12.677] iteration 21009: loss: 0.034186, loss_s1: 0.026877, loss_fp: 0.005834, loss_freq: 0.009373
[18:18:13.383] iteration 21010: loss: 0.046964, loss_s1: 0.025713, loss_fp: 0.002812, loss_freq: 0.019164
[18:18:14.040] iteration 21011: loss: 0.066736, loss_s1: 0.037255, loss_fp: 0.000535, loss_freq: 0.055911
[18:18:14.707] iteration 21012: loss: 0.065170, loss_s1: 0.074733, loss_fp: 0.005979, loss_freq: 0.023657
[18:18:15.363] iteration 21013: loss: 0.074950, loss_s1: 0.084391, loss_fp: 0.007613, loss_freq: 0.026479
[18:18:16.027] iteration 21014: loss: 0.068639, loss_s1: 0.058263, loss_fp: 0.002951, loss_freq: 0.040833
[18:18:16.684] iteration 21015: loss: 0.067048, loss_s1: 0.076321, loss_fp: 0.002425, loss_freq: 0.026708
[18:18:17.314] iteration 21016: loss: 0.028545, loss_s1: 0.011798, loss_fp: 0.001195, loss_freq: 0.011994
[18:18:17.976] iteration 21017: loss: 0.055580, loss_s1: 0.048449, loss_fp: 0.004849, loss_freq: 0.017196
[18:18:18.630] iteration 21018: loss: 0.041370, loss_s1: 0.042323, loss_fp: 0.001073, loss_freq: 0.006757
[18:18:19.272] iteration 21019: loss: 0.056117, loss_s1: 0.036601, loss_fp: 0.017685, loss_freq: 0.022128
[18:18:19.897] iteration 21020: loss: 0.073493, loss_s1: 0.066367, loss_fp: 0.001466, loss_freq: 0.027765
[18:18:20.520] iteration 21021: loss: 0.064521, loss_s1: 0.043449, loss_fp: 0.008053, loss_freq: 0.023920
[18:18:21.194] iteration 21022: loss: 0.061005, loss_s1: 0.039230, loss_fp: 0.008025, loss_freq: 0.036992
[18:18:21.819] iteration 21023: loss: 0.063905, loss_s1: 0.030952, loss_fp: 0.000608, loss_freq: 0.017453
[18:18:22.442] iteration 21024: loss: 0.054354, loss_s1: 0.034362, loss_fp: 0.002944, loss_freq: 0.030498
[18:18:23.068] iteration 21025: loss: 0.080387, loss_s1: 0.108848, loss_fp: 0.003114, loss_freq: 0.010217
[18:18:23.695] iteration 21026: loss: 0.046593, loss_s1: 0.025407, loss_fp: 0.008222, loss_freq: 0.023230
[18:18:24.316] iteration 21027: loss: 0.033314, loss_s1: 0.014966, loss_fp: 0.002087, loss_freq: 0.018796
[18:18:24.944] iteration 21028: loss: 0.040478, loss_s1: 0.019661, loss_fp: 0.002165, loss_freq: 0.015354
[18:18:25.569] iteration 21029: loss: 0.052044, loss_s1: 0.049493, loss_fp: 0.004418, loss_freq: 0.022056
[18:18:26.198] iteration 21030: loss: 0.073599, loss_s1: 0.077366, loss_fp: 0.004285, loss_freq: 0.023644
[18:18:26.824] iteration 21031: loss: 0.063062, loss_s1: 0.072089, loss_fp: 0.004326, loss_freq: 0.017206
[18:18:27.448] iteration 21032: loss: 0.079318, loss_s1: 0.064608, loss_fp: 0.002745, loss_freq: 0.050714
[18:18:28.076] iteration 21033: loss: 0.058278, loss_s1: 0.033305, loss_fp: 0.001459, loss_freq: 0.034731
[18:18:28.699] iteration 21034: loss: 0.056915, loss_s1: 0.052740, loss_fp: 0.010240, loss_freq: 0.016526
[18:18:29.322] iteration 21035: loss: 0.062396, loss_s1: 0.046438, loss_fp: 0.002756, loss_freq: 0.022238
[18:18:29.945] iteration 21036: loss: 0.055338, loss_s1: 0.044696, loss_fp: 0.003972, loss_freq: 0.031502
[18:18:30.578] iteration 21037: loss: 0.040648, loss_s1: 0.030153, loss_fp: 0.001146, loss_freq: 0.009638
[18:18:31.197] iteration 21038: loss: 0.075695, loss_s1: 0.051291, loss_fp: 0.001762, loss_freq: 0.059301
[18:18:31.825] iteration 21039: loss: 0.114006, loss_s1: 0.082753, loss_fp: 0.008203, loss_freq: 0.092236
[18:18:32.447] iteration 21040: loss: 0.055955, loss_s1: 0.041456, loss_fp: 0.002438, loss_freq: 0.036713
[18:18:33.071] iteration 21041: loss: 0.038603, loss_s1: 0.022708, loss_fp: 0.002067, loss_freq: 0.012354
[18:18:33.688] iteration 21042: loss: 0.073280, loss_s1: 0.043629, loss_fp: 0.012657, loss_freq: 0.057111
[18:18:34.319] iteration 21043: loss: 0.039735, loss_s1: 0.032212, loss_fp: 0.001137, loss_freq: 0.010074
[18:18:34.943] iteration 21044: loss: 0.050776, loss_s1: 0.027640, loss_fp: 0.000573, loss_freq: 0.042722
[18:18:35.569] iteration 21045: loss: 0.051136, loss_s1: 0.028788, loss_fp: 0.019220, loss_freq: 0.017081
[18:18:36.201] iteration 21046: loss: 0.085852, loss_s1: 0.064533, loss_fp: 0.025355, loss_freq: 0.050243
[18:18:36.827] iteration 21047: loss: 0.071672, loss_s1: 0.048011, loss_fp: 0.007848, loss_freq: 0.058802
[18:18:37.444] iteration 21048: loss: 0.043588, loss_s1: 0.037329, loss_fp: 0.000797, loss_freq: 0.017665
[18:18:38.065] iteration 21049: loss: 0.067916, loss_s1: 0.047994, loss_fp: 0.008936, loss_freq: 0.027913
[18:18:38.696] iteration 21050: loss: 0.046661, loss_s1: 0.029799, loss_fp: 0.001100, loss_freq: 0.033924
[18:18:39.321] iteration 21051: loss: 0.052342, loss_s1: 0.027020, loss_fp: 0.014455, loss_freq: 0.030962
[18:18:39.944] iteration 21052: loss: 0.058047, loss_s1: 0.036067, loss_fp: 0.019897, loss_freq: 0.024198
[18:18:40.579] iteration 21053: loss: 0.072400, loss_s1: 0.091085, loss_fp: 0.009574, loss_freq: 0.010362
[18:18:41.206] iteration 21054: loss: 0.054593, loss_s1: 0.046181, loss_fp: 0.008988, loss_freq: 0.009993
[18:18:41.839] iteration 21055: loss: 0.064538, loss_s1: 0.061648, loss_fp: 0.005178, loss_freq: 0.016486
[18:18:42.469] iteration 21056: loss: 0.059079, loss_s1: 0.045821, loss_fp: 0.000558, loss_freq: 0.028750
[18:18:43.102] iteration 21057: loss: 0.044337, loss_s1: 0.036611, loss_fp: 0.001765, loss_freq: 0.006956
[18:18:43.785] iteration 21058: loss: 0.075963, loss_s1: 0.026584, loss_fp: 0.001513, loss_freq: 0.081412
[18:18:44.613] iteration 21059: loss: 0.074452, loss_s1: 0.069257, loss_fp: 0.004163, loss_freq: 0.040888
[18:18:45.271] iteration 21060: loss: 0.032795, loss_s1: 0.019151, loss_fp: 0.002165, loss_freq: 0.010623
[18:18:45.903] iteration 21061: loss: 0.039835, loss_s1: 0.026776, loss_fp: 0.002661, loss_freq: 0.017666
[18:18:46.563] iteration 21062: loss: 0.101443, loss_s1: 0.147944, loss_fp: 0.002483, loss_freq: 0.016204
[18:18:47.186] iteration 21063: loss: 0.065130, loss_s1: 0.043455, loss_fp: 0.005059, loss_freq: 0.016999
[18:18:47.807] iteration 21064: loss: 0.049750, loss_s1: 0.045650, loss_fp: 0.004187, loss_freq: 0.014373
[18:18:48.437] iteration 21065: loss: 0.049031, loss_s1: 0.031584, loss_fp: 0.002499, loss_freq: 0.024682
[18:18:49.054] iteration 21066: loss: 0.079110, loss_s1: 0.072172, loss_fp: 0.008379, loss_freq: 0.038032
[18:18:49.686] iteration 21067: loss: 0.038433, loss_s1: 0.022148, loss_fp: 0.003786, loss_freq: 0.012723
[18:18:50.303] iteration 21068: loss: 0.056887, loss_s1: 0.059429, loss_fp: 0.004754, loss_freq: 0.024877
[18:18:50.928] iteration 21069: loss: 0.048666, loss_s1: 0.042661, loss_fp: 0.003313, loss_freq: 0.011134
[18:18:51.555] iteration 21070: loss: 0.101410, loss_s1: 0.082981, loss_fp: 0.008815, loss_freq: 0.059163
[18:18:52.171] iteration 21071: loss: 0.030603, loss_s1: 0.012060, loss_fp: 0.006445, loss_freq: 0.013216
[18:18:52.799] iteration 21072: loss: 0.041634, loss_s1: 0.030033, loss_fp: 0.003994, loss_freq: 0.014256
[18:18:53.417] iteration 21073: loss: 0.074582, loss_s1: 0.052228, loss_fp: 0.004285, loss_freq: 0.048774
[18:18:54.043] iteration 21074: loss: 0.048062, loss_s1: 0.021646, loss_fp: 0.005582, loss_freq: 0.023289
[18:18:54.692] iteration 21075: loss: 0.046471, loss_s1: 0.029959, loss_fp: 0.002452, loss_freq: 0.015125
[18:18:55.347] iteration 21076: loss: 0.060562, loss_s1: 0.039591, loss_fp: 0.002949, loss_freq: 0.019505
[18:18:56.001] iteration 21077: loss: 0.076785, loss_s1: 0.052270, loss_fp: 0.002616, loss_freq: 0.066982
[18:18:56.655] iteration 21078: loss: 0.043534, loss_s1: 0.032795, loss_fp: 0.001492, loss_freq: 0.016370
[18:18:57.276] iteration 21079: loss: 0.042328, loss_s1: 0.035564, loss_fp: 0.009299, loss_freq: 0.016377
[18:18:57.890] iteration 21080: loss: 0.073963, loss_s1: 0.068824, loss_fp: 0.004139, loss_freq: 0.040230
[18:18:58.517] iteration 21081: loss: 0.068294, loss_s1: 0.074032, loss_fp: 0.008195, loss_freq: 0.013364
[18:18:59.141] iteration 21082: loss: 0.081966, loss_s1: 0.070398, loss_fp: 0.002784, loss_freq: 0.060289
[18:18:59.761] iteration 21083: loss: 0.056777, loss_s1: 0.062330, loss_fp: 0.004622, loss_freq: 0.020290
[18:19:00.381] iteration 21084: loss: 0.074018, loss_s1: 0.044491, loss_fp: 0.002346, loss_freq: 0.043127
[18:19:01.001] iteration 21085: loss: 0.026347, loss_s1: 0.013923, loss_fp: 0.000381, loss_freq: 0.004529
[18:19:01.625] iteration 21086: loss: 0.053336, loss_s1: 0.045199, loss_fp: 0.001005, loss_freq: 0.017253
[18:19:02.250] iteration 21087: loss: 0.037122, loss_s1: 0.027537, loss_fp: 0.000520, loss_freq: 0.008643
[18:19:02.877] iteration 21088: loss: 0.054622, loss_s1: 0.051068, loss_fp: 0.003975, loss_freq: 0.015166
[18:19:03.502] iteration 21089: loss: 0.080681, loss_s1: 0.064763, loss_fp: 0.014524, loss_freq: 0.034764
[18:19:04.119] iteration 21090: loss: 0.075007, loss_s1: 0.058250, loss_fp: 0.001679, loss_freq: 0.025624
[18:19:04.736] iteration 21091: loss: 0.065528, loss_s1: 0.029117, loss_fp: 0.002086, loss_freq: 0.041656
[18:19:05.730] iteration 21092: loss: 0.037985, loss_s1: 0.023723, loss_fp: 0.002543, loss_freq: 0.017204
[18:19:06.394] iteration 21093: loss: 0.057036, loss_s1: 0.047795, loss_fp: 0.003483, loss_freq: 0.026235
[18:19:07.031] iteration 21094: loss: 0.038891, loss_s1: 0.008950, loss_fp: 0.002811, loss_freq: 0.026133
[18:19:07.669] iteration 21095: loss: 0.039628, loss_s1: 0.018306, loss_fp: 0.000991, loss_freq: 0.015157
[18:19:08.300] iteration 21096: loss: 0.051426, loss_s1: 0.039215, loss_fp: 0.002696, loss_freq: 0.022708
[18:19:08.924] iteration 21097: loss: 0.103646, loss_s1: 0.097569, loss_fp: 0.003519, loss_freq: 0.056499
[18:19:09.542] iteration 21098: loss: 0.044585, loss_s1: 0.032017, loss_fp: 0.004513, loss_freq: 0.019800
[18:19:10.171] iteration 21099: loss: 0.040197, loss_s1: 0.015783, loss_fp: 0.002972, loss_freq: 0.014327
[18:19:10.789] iteration 21100: loss: 0.069612, loss_s1: 0.057943, loss_fp: 0.003562, loss_freq: 0.048363
[18:19:11.421] iteration 21101: loss: 0.062549, loss_s1: 0.042212, loss_fp: 0.008610, loss_freq: 0.029564
[18:19:12.038] iteration 21102: loss: 0.043041, loss_s1: 0.012619, loss_fp: 0.002930, loss_freq: 0.022622
[18:19:12.658] iteration 21103: loss: 0.041538, loss_s1: 0.028802, loss_fp: 0.005148, loss_freq: 0.016583
[18:19:13.282] iteration 21104: loss: 0.056714, loss_s1: 0.031235, loss_fp: 0.003738, loss_freq: 0.051203
[18:19:13.905] iteration 21105: loss: 0.049583, loss_s1: 0.034171, loss_fp: 0.001772, loss_freq: 0.016575
[18:19:14.531] iteration 21106: loss: 0.031917, loss_s1: 0.017780, loss_fp: 0.002717, loss_freq: 0.003522
[18:19:15.169] iteration 21107: loss: 0.103992, loss_s1: 0.098878, loss_fp: 0.009342, loss_freq: 0.068411
[18:19:15.800] iteration 21108: loss: 0.103986, loss_s1: 0.059568, loss_fp: 0.000604, loss_freq: 0.008672
[18:19:16.439] iteration 21109: loss: 0.074910, loss_s1: 0.068368, loss_fp: 0.003538, loss_freq: 0.028268
[18:19:17.078] iteration 21110: loss: 0.041333, loss_s1: 0.015813, loss_fp: 0.000111, loss_freq: 0.021405
[18:19:17.709] iteration 21111: loss: 0.042997, loss_s1: 0.023729, loss_fp: 0.002415, loss_freq: 0.026377
[18:19:18.392] iteration 21112: loss: 0.037891, loss_s1: 0.031489, loss_fp: 0.000853, loss_freq: 0.006356
[18:19:19.049] iteration 21113: loss: 0.042926, loss_s1: 0.028677, loss_fp: 0.000972, loss_freq: 0.016206
[18:19:19.703] iteration 21114: loss: 0.046898, loss_s1: 0.019136, loss_fp: 0.001366, loss_freq: 0.021328
[18:19:20.349] iteration 21115: loss: 0.065994, loss_s1: 0.063819, loss_fp: 0.001555, loss_freq: 0.035963
[18:19:20.978] iteration 21116: loss: 0.072384, loss_s1: 0.067827, loss_fp: 0.000744, loss_freq: 0.048763
[18:19:21.646] iteration 21117: loss: 0.049648, loss_s1: 0.031188, loss_fp: 0.001229, loss_freq: 0.033038
[18:19:22.311] iteration 21118: loss: 0.045125, loss_s1: 0.029360, loss_fp: 0.005943, loss_freq: 0.017270
[18:19:22.967] iteration 21119: loss: 0.094804, loss_s1: 0.115554, loss_fp: 0.002656, loss_freq: 0.036739
[18:19:23.612] iteration 21120: loss: 0.050986, loss_s1: 0.033882, loss_fp: 0.003218, loss_freq: 0.034479
[18:19:24.244] iteration 21121: loss: 0.048411, loss_s1: 0.049135, loss_fp: 0.001770, loss_freq: 0.006774
[18:19:24.866] iteration 21122: loss: 0.059140, loss_s1: 0.065100, loss_fp: 0.004031, loss_freq: 0.016390
[18:19:25.500] iteration 21123: loss: 0.040413, loss_s1: 0.013050, loss_fp: 0.004696, loss_freq: 0.016344
[18:19:26.124] iteration 21124: loss: 0.052020, loss_s1: 0.053096, loss_fp: 0.002056, loss_freq: 0.014210
[18:19:26.750] iteration 21125: loss: 0.033335, loss_s1: 0.017736, loss_fp: 0.002402, loss_freq: 0.013733
[18:19:27.382] iteration 21126: loss: 0.070588, loss_s1: 0.032077, loss_fp: 0.004752, loss_freq: 0.023788
[18:19:28.006] iteration 21127: loss: 0.064760, loss_s1: 0.066118, loss_fp: 0.003777, loss_freq: 0.026539
[18:19:28.636] iteration 21128: loss: 0.059890, loss_s1: 0.055323, loss_fp: 0.006523, loss_freq: 0.022183
[18:19:29.268] iteration 21129: loss: 0.057876, loss_s1: 0.034688, loss_fp: 0.008056, loss_freq: 0.037796
[18:19:29.900] iteration 21130: loss: 0.117794, loss_s1: 0.103095, loss_fp: 0.003621, loss_freq: 0.081969
[18:19:30.527] iteration 21131: loss: 0.065710, loss_s1: 0.058398, loss_fp: 0.011204, loss_freq: 0.024178
[18:19:31.149] iteration 21132: loss: 0.069281, loss_s1: 0.039237, loss_fp: 0.027489, loss_freq: 0.027918
[18:19:31.786] iteration 21133: loss: 0.055393, loss_s1: 0.045916, loss_fp: 0.005020, loss_freq: 0.023856
[18:19:32.407] iteration 21134: loss: 0.061788, loss_s1: 0.048299, loss_fp: 0.002331, loss_freq: 0.047246
[18:19:33.033] iteration 21135: loss: 0.048552, loss_s1: 0.023927, loss_fp: 0.001696, loss_freq: 0.044545
[18:19:33.662] iteration 21136: loss: 0.047788, loss_s1: 0.019260, loss_fp: 0.001589, loss_freq: 0.035995
[18:19:34.282] iteration 21137: loss: 0.035698, loss_s1: 0.010784, loss_fp: 0.003834, loss_freq: 0.010269
[18:19:34.907] iteration 21138: loss: 0.035426, loss_s1: 0.018736, loss_fp: 0.001302, loss_freq: 0.023184
[18:19:35.531] iteration 21139: loss: 0.037541, loss_s1: 0.017145, loss_fp: 0.008760, loss_freq: 0.017076
[18:19:36.153] iteration 21140: loss: 0.081215, loss_s1: 0.078955, loss_fp: 0.003492, loss_freq: 0.039298
[18:19:36.777] iteration 21141: loss: 0.074723, loss_s1: 0.064605, loss_fp: 0.000970, loss_freq: 0.059030
[18:19:37.405] iteration 21142: loss: 0.061866, loss_s1: 0.046612, loss_fp: 0.006017, loss_freq: 0.032172
[18:19:38.032] iteration 21143: loss: 0.058603, loss_s1: 0.032667, loss_fp: 0.000886, loss_freq: 0.023421
[18:19:38.654] iteration 21144: loss: 0.034939, loss_s1: 0.014890, loss_fp: 0.002669, loss_freq: 0.013991
[18:19:39.285] iteration 21145: loss: 0.051070, loss_s1: 0.033431, loss_fp: 0.003470, loss_freq: 0.026031
[18:19:39.909] iteration 21146: loss: 0.028061, loss_s1: 0.010455, loss_fp: 0.000771, loss_freq: 0.010793
[18:19:40.533] iteration 21147: loss: 0.079870, loss_s1: 0.048037, loss_fp: 0.007364, loss_freq: 0.017763
[18:19:41.156] iteration 21148: loss: 0.032206, loss_s1: 0.012015, loss_fp: 0.003634, loss_freq: 0.012596
[18:19:41.814] iteration 21149: loss: 0.062409, loss_s1: 0.036670, loss_fp: 0.012733, loss_freq: 0.029579
[18:19:42.472] iteration 21150: loss: 0.027270, loss_s1: 0.011831, loss_fp: 0.001075, loss_freq: 0.009425
[18:19:43.135] iteration 21151: loss: 0.033604, loss_s1: 0.012056, loss_fp: 0.002365, loss_freq: 0.013974
[18:19:43.772] iteration 21152: loss: 0.042538, loss_s1: 0.029675, loss_fp: 0.001216, loss_freq: 0.017795
[18:19:44.429] iteration 21153: loss: 0.034032, loss_s1: 0.011887, loss_fp: 0.002263, loss_freq: 0.010098
[18:19:45.088] iteration 21154: loss: 0.041781, loss_s1: 0.024862, loss_fp: 0.001235, loss_freq: 0.020725
[18:19:45.742] iteration 21155: loss: 0.063969, loss_s1: 0.040913, loss_fp: 0.002909, loss_freq: 0.041031
[18:19:46.384] iteration 21156: loss: 0.058534, loss_s1: 0.037824, loss_fp: 0.003151, loss_freq: 0.035264
[18:19:47.004] iteration 21157: loss: 0.057177, loss_s1: 0.041668, loss_fp: 0.002990, loss_freq: 0.044216
[18:19:47.626] iteration 21158: loss: 0.055342, loss_s1: 0.024144, loss_fp: 0.000451, loss_freq: 0.041182
[18:19:48.251] iteration 21159: loss: 0.070744, loss_s1: 0.042721, loss_fp: 0.009638, loss_freq: 0.048070
[18:19:48.873] iteration 21160: loss: 0.053470, loss_s1: 0.038023, loss_fp: 0.004522, loss_freq: 0.032391
[18:19:49.499] iteration 21161: loss: 0.054297, loss_s1: 0.029739, loss_fp: 0.002278, loss_freq: 0.020812
[18:19:50.123] iteration 21162: loss: 0.087543, loss_s1: 0.071840, loss_fp: 0.003860, loss_freq: 0.062048
[18:19:50.741] iteration 21163: loss: 0.036332, loss_s1: 0.017847, loss_fp: 0.001312, loss_freq: 0.021478
[18:19:51.359] iteration 21164: loss: 0.079321, loss_s1: 0.051391, loss_fp: 0.003588, loss_freq: 0.039282
[18:19:51.978] iteration 21165: loss: 0.044162, loss_s1: 0.031333, loss_fp: 0.000692, loss_freq: 0.011920
[18:19:52.598] iteration 21166: loss: 0.039113, loss_s1: 0.026117, loss_fp: 0.002068, loss_freq: 0.012008
[18:19:53.224] iteration 21167: loss: 0.076190, loss_s1: 0.074901, loss_fp: 0.001183, loss_freq: 0.018803
[18:19:53.849] iteration 21168: loss: 0.067389, loss_s1: 0.057619, loss_fp: 0.006069, loss_freq: 0.034622
[18:19:54.476] iteration 21169: loss: 0.044044, loss_s1: 0.027410, loss_fp: 0.012065, loss_freq: 0.022220
[18:19:55.103] iteration 21170: loss: 0.035086, loss_s1: 0.026841, loss_fp: 0.001573, loss_freq: 0.014608
[18:19:55.728] iteration 21171: loss: 0.060353, loss_s1: 0.046552, loss_fp: 0.003377, loss_freq: 0.032534
[18:19:56.353] iteration 21172: loss: 0.074735, loss_s1: 0.040959, loss_fp: 0.010387, loss_freq: 0.058301
[18:19:56.979] iteration 21173: loss: 0.079485, loss_s1: 0.067194, loss_fp: 0.000875, loss_freq: 0.037062
[18:19:57.607] iteration 21174: loss: 0.079782, loss_s1: 0.073965, loss_fp: 0.004413, loss_freq: 0.056302
[18:19:58.232] iteration 21175: loss: 0.051839, loss_s1: 0.030107, loss_fp: 0.003681, loss_freq: 0.038224
[18:19:58.855] iteration 21176: loss: 0.059234, loss_s1: 0.037804, loss_fp: 0.011733, loss_freq: 0.027456
[18:19:59.481] iteration 21177: loss: 0.038729, loss_s1: 0.038569, loss_fp: 0.001397, loss_freq: 0.007300
[18:20:00.115] iteration 21178: loss: 0.055431, loss_s1: 0.045799, loss_fp: 0.004636, loss_freq: 0.016257
[18:20:00.800] iteration 21179: loss: 0.056571, loss_s1: 0.063365, loss_fp: 0.007070, loss_freq: 0.009245
[18:20:01.458] iteration 21180: loss: 0.076513, loss_s1: 0.069970, loss_fp: 0.005739, loss_freq: 0.033751
[18:20:02.138] iteration 21181: loss: 0.091089, loss_s1: 0.097418, loss_fp: 0.002572, loss_freq: 0.040134
[18:20:02.791] iteration 21182: loss: 0.035642, loss_s1: 0.015028, loss_fp: 0.004344, loss_freq: 0.013665
[18:20:03.420] iteration 21183: loss: 0.069769, loss_s1: 0.060455, loss_fp: 0.008819, loss_freq: 0.033832
[18:20:04.042] iteration 21184: loss: 0.059617, loss_s1: 0.044017, loss_fp: 0.004636, loss_freq: 0.016656
[18:20:04.669] iteration 21185: loss: 0.043717, loss_s1: 0.037011, loss_fp: 0.001247, loss_freq: 0.014492
[18:20:05.286] iteration 21186: loss: 0.081113, loss_s1: 0.085204, loss_fp: 0.004447, loss_freq: 0.034166
[18:20:05.910] iteration 21187: loss: 0.052820, loss_s1: 0.033620, loss_fp: 0.001374, loss_freq: 0.028472
[18:20:06.529] iteration 21188: loss: 0.038919, loss_s1: 0.025306, loss_fp: 0.001366, loss_freq: 0.017004
[18:20:07.148] iteration 21189: loss: 0.038101, loss_s1: 0.025289, loss_fp: 0.001230, loss_freq: 0.012168
[18:20:07.778] iteration 21190: loss: 0.036757, loss_s1: 0.016949, loss_fp: 0.007249, loss_freq: 0.019049
[18:20:08.402] iteration 21191: loss: 0.041377, loss_s1: 0.030284, loss_fp: 0.005164, loss_freq: 0.013641
[18:20:09.025] iteration 21192: loss: 0.061946, loss_s1: 0.062556, loss_fp: 0.003333, loss_freq: 0.031783
[18:20:09.647] iteration 21193: loss: 0.060464, loss_s1: 0.041416, loss_fp: 0.002082, loss_freq: 0.038720
[18:20:10.272] iteration 21194: loss: 0.075661, loss_s1: 0.086796, loss_fp: 0.002493, loss_freq: 0.023620
[18:20:10.900] iteration 21195: loss: 0.048230, loss_s1: 0.039755, loss_fp: 0.001703, loss_freq: 0.012022
[18:20:11.525] iteration 21196: loss: 0.050131, loss_s1: 0.023060, loss_fp: 0.002825, loss_freq: 0.011717
[18:20:12.147] iteration 21197: loss: 0.044417, loss_s1: 0.020450, loss_fp: 0.000912, loss_freq: 0.021082
[18:20:12.763] iteration 21198: loss: 0.036988, loss_s1: 0.019058, loss_fp: 0.005945, loss_freq: 0.012633
[18:20:13.379] iteration 21199: loss: 0.071642, loss_s1: 0.070674, loss_fp: 0.002120, loss_freq: 0.037104
[18:20:13.992] iteration 21200: loss: 0.102346, loss_s1: 0.097711, loss_fp: 0.010478, loss_freq: 0.053824
[18:20:17.073] iteration 21200 : mean_dice : 0.737173
[18:20:17.719] iteration 21201: loss: 0.080461, loss_s1: 0.077616, loss_fp: 0.001121, loss_freq: 0.041647
[18:20:18.372] iteration 21202: loss: 0.047413, loss_s1: 0.034910, loss_fp: 0.004547, loss_freq: 0.010751
[18:20:19.031] iteration 21203: loss: 0.067869, loss_s1: 0.057300, loss_fp: 0.012864, loss_freq: 0.037964
[18:20:19.690] iteration 21204: loss: 0.087619, loss_s1: 0.115739, loss_fp: 0.004858, loss_freq: 0.025499
[18:20:20.350] iteration 21205: loss: 0.040758, loss_s1: 0.034286, loss_fp: 0.002441, loss_freq: 0.017241
[18:20:20.984] iteration 21206: loss: 0.040086, loss_s1: 0.029790, loss_fp: 0.002382, loss_freq: 0.010504
[18:20:21.610] iteration 21207: loss: 0.058853, loss_s1: 0.038665, loss_fp: 0.012731, loss_freq: 0.035904
[18:20:22.255] iteration 21208: loss: 0.053650, loss_s1: 0.036508, loss_fp: 0.010123, loss_freq: 0.030980
[18:20:22.944] iteration 21209: loss: 0.029291, loss_s1: 0.012673, loss_fp: 0.001917, loss_freq: 0.015116
[18:20:23.612] iteration 21210: loss: 0.062210, loss_s1: 0.029472, loss_fp: 0.005609, loss_freq: 0.053320
[18:20:24.275] iteration 21211: loss: 0.067149, loss_s1: 0.041713, loss_fp: 0.001361, loss_freq: 0.066055
[18:20:24.934] iteration 21212: loss: 0.044484, loss_s1: 0.029411, loss_fp: 0.002699, loss_freq: 0.023804
[18:20:25.569] iteration 21213: loss: 0.059663, loss_s1: 0.029846, loss_fp: 0.005277, loss_freq: 0.041364
[18:20:26.200] iteration 21214: loss: 0.056890, loss_s1: 0.051679, loss_fp: 0.000868, loss_freq: 0.024800
[18:20:26.829] iteration 21215: loss: 0.033513, loss_s1: 0.008601, loss_fp: 0.003726, loss_freq: 0.011159
[18:20:27.468] iteration 21216: loss: 0.050540, loss_s1: 0.038013, loss_fp: 0.005092, loss_freq: 0.021650
[18:20:28.095] iteration 21217: loss: 0.061385, loss_s1: 0.065036, loss_fp: 0.001061, loss_freq: 0.017258
[18:20:28.715] iteration 21218: loss: 0.037817, loss_s1: 0.019068, loss_fp: 0.002009, loss_freq: 0.007596
[18:20:29.341] iteration 21219: loss: 0.061463, loss_s1: 0.022542, loss_fp: 0.009998, loss_freq: 0.031963
[18:20:29.966] iteration 21220: loss: 0.096386, loss_s1: 0.096806, loss_fp: 0.015359, loss_freq: 0.047184
[18:20:30.616] iteration 21221: loss: 0.052251, loss_s1: 0.048214, loss_fp: 0.001735, loss_freq: 0.013882
[18:20:31.233] iteration 21222: loss: 0.047976, loss_s1: 0.041762, loss_fp: 0.002558, loss_freq: 0.026806
[18:20:31.861] iteration 21223: loss: 0.055226, loss_s1: 0.047020, loss_fp: 0.005644, loss_freq: 0.015027
[18:20:32.482] iteration 21224: loss: 0.067547, loss_s1: 0.065575, loss_fp: 0.002904, loss_freq: 0.023045
[18:20:33.105] iteration 21225: loss: 0.041435, loss_s1: 0.020709, loss_fp: 0.002389, loss_freq: 0.019218
[18:20:33.738] iteration 21226: loss: 0.046007, loss_s1: 0.030598, loss_fp: 0.003114, loss_freq: 0.018753
[18:20:34.367] iteration 21227: loss: 0.054790, loss_s1: 0.058604, loss_fp: 0.001334, loss_freq: 0.019535
[18:20:34.996] iteration 21228: loss: 0.039463, loss_s1: 0.018446, loss_fp: 0.001901, loss_freq: 0.009481
[18:20:35.629] iteration 21229: loss: 0.042685, loss_s1: 0.022237, loss_fp: 0.003839, loss_freq: 0.030493
[18:20:36.257] iteration 21230: loss: 0.035091, loss_s1: 0.015504, loss_fp: 0.004124, loss_freq: 0.019204
[18:20:36.876] iteration 21231: loss: 0.063347, loss_s1: 0.024647, loss_fp: 0.007610, loss_freq: 0.045856
[18:20:37.496] iteration 21232: loss: 0.073324, loss_s1: 0.099065, loss_fp: 0.002861, loss_freq: 0.012358
[18:20:38.164] iteration 21233: loss: 0.042776, loss_s1: 0.025357, loss_fp: 0.003352, loss_freq: 0.019709
[18:20:38.778] iteration 21234: loss: 0.069995, loss_s1: 0.058832, loss_fp: 0.002894, loss_freq: 0.038800
[18:20:39.401] iteration 21235: loss: 0.043496, loss_s1: 0.024589, loss_fp: 0.005722, loss_freq: 0.017020
[18:20:40.029] iteration 21236: loss: 0.049202, loss_s1: 0.027568, loss_fp: 0.001449, loss_freq: 0.013314
[18:20:40.655] iteration 21237: loss: 0.086968, loss_s1: 0.089064, loss_fp: 0.015829, loss_freq: 0.024497
[18:20:41.286] iteration 21238: loss: 0.066992, loss_s1: 0.046894, loss_fp: 0.001867, loss_freq: 0.051489
[18:20:41.908] iteration 21239: loss: 0.031677, loss_s1: 0.021264, loss_fp: 0.001132, loss_freq: 0.010904
[18:20:42.539] iteration 21240: loss: 0.044272, loss_s1: 0.025763, loss_fp: 0.003326, loss_freq: 0.016144
[18:20:43.165] iteration 21241: loss: 0.108359, loss_s1: 0.117391, loss_fp: 0.004313, loss_freq: 0.055878
[18:20:43.844] iteration 21242: loss: 0.038612, loss_s1: 0.024255, loss_fp: 0.005396, loss_freq: 0.010896
[18:20:44.502] iteration 21243: loss: 0.100237, loss_s1: 0.089875, loss_fp: 0.003041, loss_freq: 0.058521
[18:20:45.164] iteration 21244: loss: 0.045041, loss_s1: 0.035367, loss_fp: 0.001700, loss_freq: 0.022382
[18:20:45.827] iteration 21245: loss: 0.068860, loss_s1: 0.052956, loss_fp: 0.002132, loss_freq: 0.040985
[18:20:46.513] iteration 21246: loss: 0.031303, loss_s1: 0.024325, loss_fp: 0.001701, loss_freq: 0.008424
[18:20:47.176] iteration 21247: loss: 0.046889, loss_s1: 0.026526, loss_fp: 0.001174, loss_freq: 0.022811
[18:20:47.850] iteration 21248: loss: 0.068412, loss_s1: 0.025859, loss_fp: 0.000991, loss_freq: 0.032748
[18:20:48.517] iteration 21249: loss: 0.043792, loss_s1: 0.028765, loss_fp: 0.000706, loss_freq: 0.022057
[18:20:49.180] iteration 21250: loss: 0.041953, loss_s1: 0.021002, loss_fp: 0.011525, loss_freq: 0.019350
[18:20:49.817] iteration 21251: loss: 0.037320, loss_s1: 0.022401, loss_fp: 0.004648, loss_freq: 0.014567
[18:20:50.446] iteration 21252: loss: 0.045303, loss_s1: 0.033661, loss_fp: 0.001251, loss_freq: 0.017517
[18:20:51.440] iteration 21253: loss: 0.034918, loss_s1: 0.031775, loss_fp: 0.003756, loss_freq: 0.003786
[18:20:52.071] iteration 21254: loss: 0.068768, loss_s1: 0.041001, loss_fp: 0.026050, loss_freq: 0.023303
[18:20:52.699] iteration 21255: loss: 0.034811, loss_s1: 0.017872, loss_fp: 0.001067, loss_freq: 0.020089
[18:20:53.332] iteration 21256: loss: 0.037346, loss_s1: 0.026583, loss_fp: 0.001872, loss_freq: 0.006351
[18:20:53.979] iteration 21257: loss: 0.060885, loss_s1: 0.059676, loss_fp: 0.004279, loss_freq: 0.010304
[18:20:54.669] iteration 21258: loss: 0.091533, loss_s1: 0.066279, loss_fp: 0.011280, loss_freq: 0.059699
[18:20:55.310] iteration 21259: loss: 0.064172, loss_s1: 0.060511, loss_fp: 0.007659, loss_freq: 0.025971
[18:20:55.935] iteration 21260: loss: 0.035397, loss_s1: 0.027219, loss_fp: 0.001821, loss_freq: 0.014592
[18:20:56.562] iteration 21261: loss: 0.057559, loss_s1: 0.043543, loss_fp: 0.005385, loss_freq: 0.034829
[18:20:57.201] iteration 21262: loss: 0.048121, loss_s1: 0.038024, loss_fp: 0.005292, loss_freq: 0.015847
[18:20:57.833] iteration 21263: loss: 0.050932, loss_s1: 0.045513, loss_fp: 0.001322, loss_freq: 0.012664
[18:20:58.465] iteration 21264: loss: 0.067250, loss_s1: 0.074384, loss_fp: 0.012520, loss_freq: 0.008870
[18:20:59.087] iteration 21265: loss: 0.049510, loss_s1: 0.026987, loss_fp: 0.009836, loss_freq: 0.036256
[18:20:59.726] iteration 21266: loss: 0.067896, loss_s1: 0.043429, loss_fp: 0.008446, loss_freq: 0.041933
[18:21:00.351] iteration 21267: loss: 0.054902, loss_s1: 0.052463, loss_fp: 0.008444, loss_freq: 0.022829
[18:21:01.015] iteration 21268: loss: 0.067831, loss_s1: 0.033562, loss_fp: 0.003692, loss_freq: 0.065958
[18:21:01.645] iteration 21269: loss: 0.042807, loss_s1: 0.027896, loss_fp: 0.005982, loss_freq: 0.011346
[18:21:02.270] iteration 21270: loss: 0.066182, loss_s1: 0.052955, loss_fp: 0.002707, loss_freq: 0.039472
[18:21:02.899] iteration 21271: loss: 0.034030, loss_s1: 0.008890, loss_fp: 0.001281, loss_freq: 0.014525
[18:21:03.532] iteration 21272: loss: 0.038980, loss_s1: 0.028607, loss_fp: 0.001936, loss_freq: 0.011420
[18:21:04.160] iteration 21273: loss: 0.039169, loss_s1: 0.015940, loss_fp: 0.005842, loss_freq: 0.010760
[18:21:04.790] iteration 21274: loss: 0.043274, loss_s1: 0.032402, loss_fp: 0.001157, loss_freq: 0.012290
[18:21:05.420] iteration 21275: loss: 0.075851, loss_s1: 0.074295, loss_fp: 0.001606, loss_freq: 0.018895
[18:21:06.053] iteration 21276: loss: 0.107904, loss_s1: 0.067059, loss_fp: 0.008833, loss_freq: 0.106726
[18:21:06.686] iteration 21277: loss: 0.054154, loss_s1: 0.047614, loss_fp: 0.002864, loss_freq: 0.016328
[18:21:07.312] iteration 21278: loss: 0.050809, loss_s1: 0.040502, loss_fp: 0.004677, loss_freq: 0.023823
[18:21:07.943] iteration 21279: loss: 0.030630, loss_s1: 0.020173, loss_fp: 0.000440, loss_freq: 0.004255
[18:21:08.574] iteration 21280: loss: 0.075058, loss_s1: 0.047574, loss_fp: 0.008999, loss_freq: 0.043370
[18:21:09.204] iteration 21281: loss: 0.064002, loss_s1: 0.043686, loss_fp: 0.006225, loss_freq: 0.040220
[18:21:09.823] iteration 21282: loss: 0.045324, loss_s1: 0.036492, loss_fp: 0.001805, loss_freq: 0.016951
[18:21:10.440] iteration 21283: loss: 0.048518, loss_s1: 0.058064, loss_fp: 0.003765, loss_freq: 0.009051
[18:21:11.073] iteration 21284: loss: 0.053811, loss_s1: 0.018745, loss_fp: 0.009768, loss_freq: 0.027232
[18:21:11.701] iteration 21285: loss: 0.051878, loss_s1: 0.027079, loss_fp: 0.001514, loss_freq: 0.038998
[18:21:12.335] iteration 21286: loss: 0.054586, loss_s1: 0.053475, loss_fp: 0.012241, loss_freq: 0.015483
[18:21:12.965] iteration 21287: loss: 0.058110, loss_s1: 0.030856, loss_fp: 0.003327, loss_freq: 0.034543
[18:21:13.594] iteration 21288: loss: 0.073785, loss_s1: 0.052573, loss_fp: 0.005352, loss_freq: 0.062006
[18:21:14.222] iteration 21289: loss: 0.100060, loss_s1: 0.100806, loss_fp: 0.003001, loss_freq: 0.051553
[18:21:14.849] iteration 21290: loss: 0.052301, loss_s1: 0.037568, loss_fp: 0.002086, loss_freq: 0.025817
[18:21:15.483] iteration 21291: loss: 0.071500, loss_s1: 0.067510, loss_fp: 0.002584, loss_freq: 0.035462
[18:21:16.116] iteration 21292: loss: 0.049016, loss_s1: 0.040130, loss_fp: 0.001185, loss_freq: 0.017057
[18:21:16.749] iteration 21293: loss: 0.067848, loss_s1: 0.040669, loss_fp: 0.012756, loss_freq: 0.015559
[18:21:17.372] iteration 21294: loss: 0.076184, loss_s1: 0.067217, loss_fp: 0.008102, loss_freq: 0.042250
[18:21:18.009] iteration 21295: loss: 0.064575, loss_s1: 0.040560, loss_fp: 0.007561, loss_freq: 0.053588
[18:21:18.635] iteration 21296: loss: 0.048355, loss_s1: 0.012473, loss_fp: 0.004337, loss_freq: 0.035245
[18:21:19.263] iteration 21297: loss: 0.076732, loss_s1: 0.044111, loss_fp: 0.002900, loss_freq: 0.063590
[18:21:19.895] iteration 21298: loss: 0.053984, loss_s1: 0.062521, loss_fp: 0.002573, loss_freq: 0.005253
[18:21:20.525] iteration 21299: loss: 0.044368, loss_s1: 0.029506, loss_fp: 0.002644, loss_freq: 0.029864
[18:21:21.151] iteration 21300: loss: 0.054790, loss_s1: 0.056868, loss_fp: 0.005320, loss_freq: 0.016427
[18:21:21.784] iteration 21301: loss: 0.053497, loss_s1: 0.046256, loss_fp: 0.003984, loss_freq: 0.008543
[18:21:22.417] iteration 21302: loss: 0.055168, loss_s1: 0.058766, loss_fp: 0.002961, loss_freq: 0.016633
[18:21:23.049] iteration 21303: loss: 0.061829, loss_s1: 0.049485, loss_fp: 0.003063, loss_freq: 0.035294
[18:21:23.679] iteration 21304: loss: 0.063210, loss_s1: 0.050058, loss_fp: 0.001730, loss_freq: 0.032421
[18:21:24.346] iteration 21305: loss: 0.062182, loss_s1: 0.044934, loss_fp: 0.008060, loss_freq: 0.033149
[18:21:25.006] iteration 21306: loss: 0.055628, loss_s1: 0.032370, loss_fp: 0.001821, loss_freq: 0.028490
[18:21:25.638] iteration 21307: loss: 0.035074, loss_s1: 0.015555, loss_fp: 0.002233, loss_freq: 0.015238
[18:21:26.257] iteration 21308: loss: 0.062354, loss_s1: 0.059262, loss_fp: 0.002640, loss_freq: 0.024082
[18:21:26.881] iteration 21309: loss: 0.037305, loss_s1: 0.025365, loss_fp: 0.008462, loss_freq: 0.005767
[18:21:27.509] iteration 21310: loss: 0.044707, loss_s1: 0.018236, loss_fp: 0.001238, loss_freq: 0.021796
[18:21:28.136] iteration 21311: loss: 0.041640, loss_s1: 0.027660, loss_fp: 0.003104, loss_freq: 0.015058
[18:21:28.755] iteration 21312: loss: 0.029181, loss_s1: 0.014490, loss_fp: 0.001923, loss_freq: 0.014491
[18:21:29.374] iteration 21313: loss: 0.048600, loss_s1: 0.036022, loss_fp: 0.002195, loss_freq: 0.016963
[18:21:29.997] iteration 21314: loss: 0.046935, loss_s1: 0.033492, loss_fp: 0.007523, loss_freq: 0.019256
[18:21:30.617] iteration 21315: loss: 0.042752, loss_s1: 0.024454, loss_fp: 0.001507, loss_freq: 0.017742
[18:21:31.239] iteration 21316: loss: 0.040288, loss_s1: 0.028303, loss_fp: 0.001600, loss_freq: 0.015427
[18:21:31.867] iteration 21317: loss: 0.043486, loss_s1: 0.009745, loss_fp: 0.005539, loss_freq: 0.027809
[18:21:32.488] iteration 21318: loss: 0.097226, loss_s1: 0.069504, loss_fp: 0.003758, loss_freq: 0.082900
[18:21:33.114] iteration 21319: loss: 0.069555, loss_s1: 0.043978, loss_fp: 0.001374, loss_freq: 0.059972
[18:21:33.746] iteration 21320: loss: 0.062263, loss_s1: 0.054101, loss_fp: 0.004007, loss_freq: 0.033125
[18:21:34.378] iteration 21321: loss: 0.041098, loss_s1: 0.032496, loss_fp: 0.005668, loss_freq: 0.013192
[18:21:35.000] iteration 21322: loss: 0.094519, loss_s1: 0.072969, loss_fp: 0.006523, loss_freq: 0.035884
[18:21:35.624] iteration 21323: loss: 0.073795, loss_s1: 0.048270, loss_fp: 0.003905, loss_freq: 0.055995
[18:21:36.254] iteration 21324: loss: 0.051370, loss_s1: 0.031140, loss_fp: 0.001442, loss_freq: 0.037543
[18:21:36.878] iteration 21325: loss: 0.061047, loss_s1: 0.030339, loss_fp: 0.007979, loss_freq: 0.053132
[18:21:37.506] iteration 21326: loss: 0.048869, loss_s1: 0.037741, loss_fp: 0.007073, loss_freq: 0.012446
[18:21:38.133] iteration 21327: loss: 0.064144, loss_s1: 0.060609, loss_fp: 0.004002, loss_freq: 0.029470
[18:21:38.757] iteration 21328: loss: 0.072799, loss_s1: 0.051614, loss_fp: 0.006920, loss_freq: 0.049797
[18:21:39.382] iteration 21329: loss: 0.046551, loss_s1: 0.034189, loss_fp: 0.003541, loss_freq: 0.026430
[18:21:40.007] iteration 21330: loss: 0.044713, loss_s1: 0.041262, loss_fp: 0.001144, loss_freq: 0.016715
[18:21:40.642] iteration 21331: loss: 0.028459, loss_s1: 0.022767, loss_fp: 0.001069, loss_freq: 0.005000
[18:21:41.270] iteration 21332: loss: 0.060557, loss_s1: 0.037423, loss_fp: 0.001812, loss_freq: 0.046288
[18:21:41.899] iteration 21333: loss: 0.057407, loss_s1: 0.031655, loss_fp: 0.008998, loss_freq: 0.043082
[18:21:42.526] iteration 21334: loss: 0.041281, loss_s1: 0.020932, loss_fp: 0.003441, loss_freq: 0.031182
[18:21:43.151] iteration 21335: loss: 0.150664, loss_s1: 0.162301, loss_fp: 0.009987, loss_freq: 0.092820
[18:21:43.773] iteration 21336: loss: 0.047114, loss_s1: 0.043269, loss_fp: 0.001719, loss_freq: 0.008834
[18:21:44.397] iteration 21337: loss: 0.080678, loss_s1: 0.058858, loss_fp: 0.005873, loss_freq: 0.063247
[18:21:45.023] iteration 21338: loss: 0.057632, loss_s1: 0.060850, loss_fp: 0.001169, loss_freq: 0.018389
[18:21:45.650] iteration 21339: loss: 0.058784, loss_s1: 0.035235, loss_fp: 0.007494, loss_freq: 0.003809
[18:21:46.271] iteration 21340: loss: 0.060144, loss_s1: 0.058935, loss_fp: 0.004812, loss_freq: 0.016767
[18:21:46.894] iteration 21341: loss: 0.059122, loss_s1: 0.038130, loss_fp: 0.012999, loss_freq: 0.032766
[18:21:47.529] iteration 21342: loss: 0.052592, loss_s1: 0.030864, loss_fp: 0.004250, loss_freq: 0.028808
[18:21:48.178] iteration 21343: loss: 0.057351, loss_s1: 0.050634, loss_fp: 0.001114, loss_freq: 0.020001
[18:21:48.833] iteration 21344: loss: 0.056932, loss_s1: 0.049053, loss_fp: 0.011391, loss_freq: 0.016370
[18:21:49.460] iteration 21345: loss: 0.065598, loss_s1: 0.031940, loss_fp: 0.003519, loss_freq: 0.026566
[18:21:50.086] iteration 21346: loss: 0.048260, loss_s1: 0.042934, loss_fp: 0.005357, loss_freq: 0.013413
[18:21:50.703] iteration 21347: loss: 0.075768, loss_s1: 0.068106, loss_fp: 0.002547, loss_freq: 0.027763
[18:21:51.331] iteration 21348: loss: 0.040695, loss_s1: 0.009507, loss_fp: 0.013544, loss_freq: 0.030986
[18:21:51.960] iteration 21349: loss: 0.047623, loss_s1: 0.033736, loss_fp: 0.005081, loss_freq: 0.023940
[18:21:52.585] iteration 21350: loss: 0.036281, loss_s1: 0.011474, loss_fp: 0.002392, loss_freq: 0.015290
[18:21:53.217] iteration 21351: loss: 0.041267, loss_s1: 0.021912, loss_fp: 0.001687, loss_freq: 0.028965
[18:21:53.838] iteration 21352: loss: 0.076297, loss_s1: 0.071367, loss_fp: 0.002249, loss_freq: 0.007484
[18:21:54.458] iteration 21353: loss: 0.056415, loss_s1: 0.044936, loss_fp: 0.003710, loss_freq: 0.028770
[18:21:55.085] iteration 21354: loss: 0.076159, loss_s1: 0.050149, loss_fp: 0.003253, loss_freq: 0.059956
[18:21:55.715] iteration 21355: loss: 0.066210, loss_s1: 0.068386, loss_fp: 0.002173, loss_freq: 0.029036
[18:21:56.338] iteration 21356: loss: 0.053177, loss_s1: 0.042508, loss_fp: 0.001967, loss_freq: 0.025464
[18:21:56.959] iteration 21357: loss: 0.055402, loss_s1: 0.041920, loss_fp: 0.001303, loss_freq: 0.023656
[18:21:57.582] iteration 21358: loss: 0.030591, loss_s1: 0.015379, loss_fp: 0.002549, loss_freq: 0.014431
[18:21:58.219] iteration 21359: loss: 0.041911, loss_s1: 0.028928, loss_fp: 0.001657, loss_freq: 0.010855
[18:21:58.848] iteration 21360: loss: 0.085935, loss_s1: 0.107752, loss_fp: 0.002420, loss_freq: 0.024367
[18:21:59.482] iteration 21361: loss: 0.114201, loss_s1: 0.101892, loss_fp: 0.007442, loss_freq: 0.079802
[18:22:00.118] iteration 21362: loss: 0.058193, loss_s1: 0.040303, loss_fp: 0.002506, loss_freq: 0.032549
[18:22:00.744] iteration 21363: loss: 0.044728, loss_s1: 0.037489, loss_fp: 0.001119, loss_freq: 0.012179
[18:22:01.365] iteration 21364: loss: 0.059188, loss_s1: 0.050176, loss_fp: 0.004902, loss_freq: 0.012928
[18:22:01.988] iteration 21365: loss: 0.067117, loss_s1: 0.072397, loss_fp: 0.002573, loss_freq: 0.010337
[18:22:02.615] iteration 21366: loss: 0.038324, loss_s1: 0.033465, loss_fp: 0.003671, loss_freq: 0.013550
[18:22:03.258] iteration 21367: loss: 0.052710, loss_s1: 0.034951, loss_fp: 0.001103, loss_freq: 0.013797
[18:22:03.889] iteration 21368: loss: 0.074304, loss_s1: 0.042214, loss_fp: 0.005855, loss_freq: 0.050062
[18:22:04.519] iteration 21369: loss: 0.030428, loss_s1: 0.018021, loss_fp: 0.000886, loss_freq: 0.011708
[18:22:05.149] iteration 21370: loss: 0.034513, loss_s1: 0.034121, loss_fp: 0.001877, loss_freq: 0.005406
[18:22:05.796] iteration 21371: loss: 0.071557, loss_s1: 0.060066, loss_fp: 0.007343, loss_freq: 0.026308
[18:22:06.416] iteration 21372: loss: 0.077683, loss_s1: 0.091094, loss_fp: 0.001928, loss_freq: 0.034190
[18:22:07.030] iteration 21373: loss: 0.082325, loss_s1: 0.021295, loss_fp: 0.004893, loss_freq: 0.105737
[18:22:07.656] iteration 21374: loss: 0.069164, loss_s1: 0.046108, loss_fp: 0.018206, loss_freq: 0.027624
[18:22:08.267] iteration 21375: loss: 0.035608, loss_s1: 0.010623, loss_fp: 0.001889, loss_freq: 0.014323
[18:22:08.888] iteration 21376: loss: 0.040065, loss_s1: 0.023796, loss_fp: 0.004529, loss_freq: 0.015266
[18:22:09.500] iteration 21377: loss: 0.043547, loss_s1: 0.016332, loss_fp: 0.007763, loss_freq: 0.024207
[18:22:10.132] iteration 21378: loss: 0.066720, loss_s1: 0.047949, loss_fp: 0.002090, loss_freq: 0.035201
[18:22:10.759] iteration 21379: loss: 0.045411, loss_s1: 0.039302, loss_fp: 0.003629, loss_freq: 0.009835
[18:22:11.368] iteration 21380: loss: 0.060154, loss_s1: 0.027429, loss_fp: 0.011374, loss_freq: 0.043906
[18:22:11.989] iteration 21381: loss: 0.061832, loss_s1: 0.051739, loss_fp: 0.001966, loss_freq: 0.034279
[18:22:12.614] iteration 21382: loss: 0.041904, loss_s1: 0.029830, loss_fp: 0.010096, loss_freq: 0.007563
[18:22:13.237] iteration 21383: loss: 0.068132, loss_s1: 0.069833, loss_fp: 0.006332, loss_freq: 0.032746
[18:22:13.862] iteration 21384: loss: 0.073266, loss_s1: 0.094120, loss_fp: 0.004820, loss_freq: 0.015046
[18:22:14.482] iteration 21385: loss: 0.072448, loss_s1: 0.059464, loss_fp: 0.007587, loss_freq: 0.039001
[18:22:15.136] iteration 21386: loss: 0.057467, loss_s1: 0.049343, loss_fp: 0.004227, loss_freq: 0.019350
[18:22:15.764] iteration 21387: loss: 0.046343, loss_s1: 0.020840, loss_fp: 0.004997, loss_freq: 0.033006
[18:22:16.394] iteration 21388: loss: 0.071541, loss_s1: 0.057222, loss_fp: 0.006011, loss_freq: 0.053325
[18:22:17.016] iteration 21389: loss: 0.035089, loss_s1: 0.019980, loss_fp: 0.004041, loss_freq: 0.008360
[18:22:17.644] iteration 21390: loss: 0.036698, loss_s1: 0.010233, loss_fp: 0.002830, loss_freq: 0.031953
[18:22:18.271] iteration 21391: loss: 0.031834, loss_s1: 0.013018, loss_fp: 0.009962, loss_freq: 0.011543
[18:22:18.893] iteration 21392: loss: 0.068950, loss_s1: 0.035423, loss_fp: 0.006088, loss_freq: 0.020196
[18:22:19.521] iteration 21393: loss: 0.055065, loss_s1: 0.058005, loss_fp: 0.001639, loss_freq: 0.011031
[18:22:20.144] iteration 21394: loss: 0.045323, loss_s1: 0.026386, loss_fp: 0.002006, loss_freq: 0.029154
[18:22:20.760] iteration 21395: loss: 0.042531, loss_s1: 0.025328, loss_fp: 0.004673, loss_freq: 0.016902
[18:22:21.385] iteration 21396: loss: 0.066381, loss_s1: 0.078196, loss_fp: 0.001665, loss_freq: 0.018565
[18:22:22.005] iteration 21397: loss: 0.040105, loss_s1: 0.021424, loss_fp: 0.003074, loss_freq: 0.023685
[18:22:22.632] iteration 21398: loss: 0.045295, loss_s1: 0.032325, loss_fp: 0.001577, loss_freq: 0.014679
[18:22:23.295] iteration 21399: loss: 0.084335, loss_s1: 0.061938, loss_fp: 0.002306, loss_freq: 0.069535
[18:22:23.910] iteration 21400: loss: 0.038553, loss_s1: 0.031104, loss_fp: 0.008436, loss_freq: 0.009863
[18:22:27.163] iteration 21400 : mean_dice : 0.733896
[18:22:27.890] iteration 21401: loss: 0.039342, loss_s1: 0.025134, loss_fp: 0.003394, loss_freq: 0.021638
[18:22:28.546] iteration 21402: loss: 0.121174, loss_s1: 0.113870, loss_fp: 0.006735, loss_freq: 0.071106
[18:22:29.206] iteration 21403: loss: 0.057952, loss_s1: 0.034440, loss_fp: 0.008619, loss_freq: 0.037229
[18:22:29.845] iteration 21404: loss: 0.063155, loss_s1: 0.052871, loss_fp: 0.008239, loss_freq: 0.037751
[18:22:30.472] iteration 21405: loss: 0.061491, loss_s1: 0.075175, loss_fp: 0.002206, loss_freq: 0.012488
[18:22:31.096] iteration 21406: loss: 0.050665, loss_s1: 0.028334, loss_fp: 0.006571, loss_freq: 0.018125
[18:22:31.721] iteration 21407: loss: 0.027889, loss_s1: 0.015334, loss_fp: 0.001547, loss_freq: 0.006868
[18:22:32.343] iteration 21408: loss: 0.059983, loss_s1: 0.042638, loss_fp: 0.006836, loss_freq: 0.014185
[18:22:32.972] iteration 21409: loss: 0.033693, loss_s1: 0.010465, loss_fp: 0.001422, loss_freq: 0.016913
[18:22:33.592] iteration 21410: loss: 0.052521, loss_s1: 0.014061, loss_fp: 0.001769, loss_freq: 0.037127
[18:22:34.220] iteration 21411: loss: 0.069601, loss_s1: 0.061037, loss_fp: 0.006775, loss_freq: 0.025025
[18:22:34.841] iteration 21412: loss: 0.054972, loss_s1: 0.026266, loss_fp: 0.000946, loss_freq: 0.012148
[18:22:35.457] iteration 21413: loss: 0.072212, loss_s1: 0.038715, loss_fp: 0.002834, loss_freq: 0.052612
[18:22:36.449] iteration 21414: loss: 0.052787, loss_s1: 0.053970, loss_fp: 0.000820, loss_freq: 0.018814
[18:22:37.086] iteration 21415: loss: 0.063833, loss_s1: 0.063427, loss_fp: 0.000548, loss_freq: 0.030501
[18:22:37.720] iteration 21416: loss: 0.041288, loss_s1: 0.023743, loss_fp: 0.000790, loss_freq: 0.017347
[18:22:38.347] iteration 21417: loss: 0.057082, loss_s1: 0.042575, loss_fp: 0.000953, loss_freq: 0.030443
[18:22:38.976] iteration 21418: loss: 0.056158, loss_s1: 0.046899, loss_fp: 0.005914, loss_freq: 0.015912
[18:22:39.613] iteration 21419: loss: 0.079334, loss_s1: 0.059394, loss_fp: 0.006425, loss_freq: 0.043995
[18:22:40.277] iteration 21420: loss: 0.064735, loss_s1: 0.056112, loss_fp: 0.006472, loss_freq: 0.031929
[18:22:40.939] iteration 21421: loss: 0.043117, loss_s1: 0.030837, loss_fp: 0.001151, loss_freq: 0.014543
[18:22:41.603] iteration 21422: loss: 0.046020, loss_s1: 0.052846, loss_fp: 0.002894, loss_freq: 0.011405
[18:22:42.265] iteration 21423: loss: 0.050168, loss_s1: 0.040416, loss_fp: 0.005354, loss_freq: 0.018346
[18:22:42.932] iteration 21424: loss: 0.053267, loss_s1: 0.034797, loss_fp: 0.002015, loss_freq: 0.011967
[18:22:43.568] iteration 21425: loss: 0.038939, loss_s1: 0.018911, loss_fp: 0.002652, loss_freq: 0.024161
[18:22:44.195] iteration 21426: loss: 0.051945, loss_s1: 0.022723, loss_fp: 0.009605, loss_freq: 0.041725
[18:22:44.828] iteration 21427: loss: 0.058358, loss_s1: 0.043821, loss_fp: 0.003861, loss_freq: 0.012440
[18:22:45.452] iteration 21428: loss: 0.068909, loss_s1: 0.070365, loss_fp: 0.000892, loss_freq: 0.017652
[18:22:46.086] iteration 21429: loss: 0.092421, loss_s1: 0.060736, loss_fp: 0.006389, loss_freq: 0.080740
[18:22:46.715] iteration 21430: loss: 0.035263, loss_s1: 0.028773, loss_fp: 0.001674, loss_freq: 0.006631
[18:22:47.344] iteration 21431: loss: 0.072185, loss_s1: 0.085418, loss_fp: 0.004774, loss_freq: 0.019314
[18:22:47.968] iteration 21432: loss: 0.046009, loss_s1: 0.035781, loss_fp: 0.000423, loss_freq: 0.023184
[18:22:48.591] iteration 21433: loss: 0.029013, loss_s1: 0.005572, loss_fp: 0.001412, loss_freq: 0.012876
[18:22:49.224] iteration 21434: loss: 0.041017, loss_s1: 0.020520, loss_fp: 0.001426, loss_freq: 0.014140
[18:22:49.850] iteration 21435: loss: 0.041019, loss_s1: 0.028995, loss_fp: 0.001530, loss_freq: 0.016146
[18:22:50.471] iteration 21436: loss: 0.062724, loss_s1: 0.038315, loss_fp: 0.000917, loss_freq: 0.033524
[18:22:51.098] iteration 21437: loss: 0.081884, loss_s1: 0.043020, loss_fp: 0.004339, loss_freq: 0.073188
[18:22:51.717] iteration 21438: loss: 0.031432, loss_s1: 0.021809, loss_fp: 0.001772, loss_freq: 0.013415
[18:22:52.345] iteration 21439: loss: 0.057594, loss_s1: 0.061664, loss_fp: 0.002859, loss_freq: 0.021929
[18:22:52.964] iteration 21440: loss: 0.062295, loss_s1: 0.076997, loss_fp: 0.005496, loss_freq: 0.004402
[18:22:53.588] iteration 21441: loss: 0.077414, loss_s1: 0.051218, loss_fp: 0.004779, loss_freq: 0.057521
[18:22:54.216] iteration 21442: loss: 0.091802, loss_s1: 0.073064, loss_fp: 0.006610, loss_freq: 0.037763
[18:22:54.854] iteration 21443: loss: 0.037714, loss_s1: 0.033253, loss_fp: 0.001341, loss_freq: 0.010419
[18:22:55.492] iteration 21444: loss: 0.047171, loss_s1: 0.036006, loss_fp: 0.003838, loss_freq: 0.025256
[18:22:56.129] iteration 21445: loss: 0.048943, loss_s1: 0.043913, loss_fp: 0.001240, loss_freq: 0.013584
[18:22:56.837] iteration 21446: loss: 0.037760, loss_s1: 0.015890, loss_fp: 0.001448, loss_freq: 0.022783
[18:22:57.466] iteration 21447: loss: 0.044969, loss_s1: 0.025298, loss_fp: 0.001793, loss_freq: 0.021167
[18:22:58.092] iteration 21448: loss: 0.053997, loss_s1: 0.038081, loss_fp: 0.003862, loss_freq: 0.025828
[18:22:58.727] iteration 21449: loss: 0.061810, loss_s1: 0.042776, loss_fp: 0.005965, loss_freq: 0.038311
[18:22:59.347] iteration 21450: loss: 0.096853, loss_s1: 0.094459, loss_fp: 0.005042, loss_freq: 0.045363
[18:22:59.967] iteration 21451: loss: 0.049870, loss_s1: 0.035452, loss_fp: 0.003630, loss_freq: 0.024249
[18:23:00.594] iteration 21452: loss: 0.072329, loss_s1: 0.055317, loss_fp: 0.003333, loss_freq: 0.050264
[18:23:01.218] iteration 21453: loss: 0.046145, loss_s1: 0.040132, loss_fp: 0.001506, loss_freq: 0.018997
[18:23:01.841] iteration 21454: loss: 0.058880, loss_s1: 0.035706, loss_fp: 0.002486, loss_freq: 0.035038
[18:23:02.465] iteration 21455: loss: 0.055716, loss_s1: 0.051119, loss_fp: 0.003265, loss_freq: 0.026429
[18:23:03.093] iteration 21456: loss: 0.054317, loss_s1: 0.046308, loss_fp: 0.001770, loss_freq: 0.034315
[18:23:03.717] iteration 21457: loss: 0.052681, loss_s1: 0.031280, loss_fp: 0.001491, loss_freq: 0.041760
[18:23:04.334] iteration 21458: loss: 0.064573, loss_s1: 0.045702, loss_fp: 0.002815, loss_freq: 0.040407
[18:23:04.956] iteration 21459: loss: 0.049553, loss_s1: 0.050044, loss_fp: 0.001111, loss_freq: 0.013348
[18:23:05.584] iteration 21460: loss: 0.034338, loss_s1: 0.012439, loss_fp: 0.001410, loss_freq: 0.020558
[18:23:06.206] iteration 21461: loss: 0.053907, loss_s1: 0.053231, loss_fp: 0.003231, loss_freq: 0.020406
[18:23:06.842] iteration 21462: loss: 0.074935, loss_s1: 0.052087, loss_fp: 0.001513, loss_freq: 0.024505
[18:23:07.482] iteration 21463: loss: 0.041087, loss_s1: 0.039822, loss_fp: 0.001496, loss_freq: 0.014199
[18:23:08.107] iteration 21464: loss: 0.102932, loss_s1: 0.157686, loss_fp: 0.003400, loss_freq: 0.015658
[18:23:08.734] iteration 21465: loss: 0.043481, loss_s1: 0.014472, loss_fp: 0.001377, loss_freq: 0.021343
[18:23:09.356] iteration 21466: loss: 0.051437, loss_s1: 0.031568, loss_fp: 0.003617, loss_freq: 0.032082
[18:23:09.979] iteration 21467: loss: 0.072681, loss_s1: 0.050456, loss_fp: 0.002232, loss_freq: 0.054863
[18:23:10.599] iteration 21468: loss: 0.040444, loss_s1: 0.038081, loss_fp: 0.001732, loss_freq: 0.010138
[18:23:11.235] iteration 21469: loss: 0.040240, loss_s1: 0.021331, loss_fp: 0.001966, loss_freq: 0.018119
[18:23:11.878] iteration 21470: loss: 0.043780, loss_s1: 0.032986, loss_fp: 0.001188, loss_freq: 0.017663
[18:23:12.511] iteration 21471: loss: 0.034503, loss_s1: 0.020868, loss_fp: 0.000632, loss_freq: 0.009455
[18:23:13.152] iteration 21472: loss: 0.031370, loss_s1: 0.013419, loss_fp: 0.004403, loss_freq: 0.004524
[18:23:13.797] iteration 21473: loss: 0.040548, loss_s1: 0.022857, loss_fp: 0.001453, loss_freq: 0.030142
[18:23:14.433] iteration 21474: loss: 0.056350, loss_s1: 0.048210, loss_fp: 0.001993, loss_freq: 0.030356
[18:23:15.104] iteration 21475: loss: 0.042847, loss_s1: 0.015584, loss_fp: 0.008164, loss_freq: 0.026959
[18:23:15.775] iteration 21476: loss: 0.036574, loss_s1: 0.022598, loss_fp: 0.000811, loss_freq: 0.007563
[18:23:16.431] iteration 21477: loss: 0.038870, loss_s1: 0.012564, loss_fp: 0.003371, loss_freq: 0.025016
[18:23:17.048] iteration 21478: loss: 0.045264, loss_s1: 0.029666, loss_fp: 0.002792, loss_freq: 0.020455
[18:23:17.671] iteration 21479: loss: 0.086107, loss_s1: 0.046278, loss_fp: 0.010389, loss_freq: 0.084508
[18:23:18.297] iteration 21480: loss: 0.049528, loss_s1: 0.021945, loss_fp: 0.004456, loss_freq: 0.037347
[18:23:18.920] iteration 21481: loss: 0.068890, loss_s1: 0.046881, loss_fp: 0.004076, loss_freq: 0.052708
[18:23:19.544] iteration 21482: loss: 0.064037, loss_s1: 0.058219, loss_fp: 0.006773, loss_freq: 0.031051
[18:23:20.170] iteration 21483: loss: 0.055228, loss_s1: 0.029983, loss_fp: 0.006984, loss_freq: 0.025172
[18:23:20.795] iteration 21484: loss: 0.041039, loss_s1: 0.027715, loss_fp: 0.001814, loss_freq: 0.014899
[18:23:21.425] iteration 21485: loss: 0.044622, loss_s1: 0.026870, loss_fp: 0.001269, loss_freq: 0.024404
[18:23:22.049] iteration 21486: loss: 0.052752, loss_s1: 0.026324, loss_fp: 0.008694, loss_freq: 0.036823
[18:23:22.682] iteration 21487: loss: 0.038457, loss_s1: 0.029050, loss_fp: 0.000993, loss_freq: 0.009405
[18:23:23.307] iteration 21488: loss: 0.052879, loss_s1: 0.046706, loss_fp: 0.001904, loss_freq: 0.024340
[18:23:23.928] iteration 21489: loss: 0.051208, loss_s1: 0.038523, loss_fp: 0.000334, loss_freq: 0.010265
[18:23:24.557] iteration 21490: loss: 0.053842, loss_s1: 0.040079, loss_fp: 0.010203, loss_freq: 0.023947
[18:23:25.181] iteration 21491: loss: 0.038014, loss_s1: 0.026126, loss_fp: 0.005500, loss_freq: 0.013544
[18:23:25.798] iteration 21492: loss: 0.042983, loss_s1: 0.038610, loss_fp: 0.004413, loss_freq: 0.016565
[18:23:26.420] iteration 21493: loss: 0.052203, loss_s1: 0.020206, loss_fp: 0.002128, loss_freq: 0.037454
[18:23:27.047] iteration 21494: loss: 0.044591, loss_s1: 0.037486, loss_fp: 0.002859, loss_freq: 0.018176
[18:23:27.676] iteration 21495: loss: 0.103196, loss_s1: 0.135384, loss_fp: 0.003825, loss_freq: 0.035934
[18:23:28.296] iteration 21496: loss: 0.106514, loss_s1: 0.122541, loss_fp: 0.005109, loss_freq: 0.046294
[18:23:28.923] iteration 21497: loss: 0.063356, loss_s1: 0.048445, loss_fp: 0.013820, loss_freq: 0.029391
[18:23:29.542] iteration 21498: loss: 0.103965, loss_s1: 0.093388, loss_fp: 0.035329, loss_freq: 0.043705
[18:23:30.209] iteration 21499: loss: 0.037075, loss_s1: 0.024920, loss_fp: 0.000649, loss_freq: 0.014732
[18:23:30.870] iteration 21500: loss: 0.057982, loss_s1: 0.039936, loss_fp: 0.007575, loss_freq: 0.022822
[18:23:31.525] iteration 21501: loss: 0.048120, loss_s1: 0.031567, loss_fp: 0.003547, loss_freq: 0.012726
[18:23:32.157] iteration 21502: loss: 0.071658, loss_s1: 0.059207, loss_fp: 0.005779, loss_freq: 0.042243
[18:23:32.787] iteration 21503: loss: 0.073327, loss_s1: 0.078389, loss_fp: 0.003091, loss_freq: 0.025242
[18:23:33.416] iteration 21504: loss: 0.059139, loss_s1: 0.031868, loss_fp: 0.003797, loss_freq: 0.035426
[18:23:34.042] iteration 21505: loss: 0.088845, loss_s1: 0.075757, loss_fp: 0.010887, loss_freq: 0.037792
[18:23:34.667] iteration 21506: loss: 0.082568, loss_s1: 0.023138, loss_fp: 0.004438, loss_freq: 0.009292
[18:23:35.288] iteration 21507: loss: 0.044091, loss_s1: 0.037887, loss_fp: 0.001105, loss_freq: 0.011294
[18:23:35.918] iteration 21508: loss: 0.039276, loss_s1: 0.025621, loss_fp: 0.000697, loss_freq: 0.024580
[18:23:36.540] iteration 21509: loss: 0.050128, loss_s1: 0.034432, loss_fp: 0.004720, loss_freq: 0.031787
[18:23:37.169] iteration 21510: loss: 0.045224, loss_s1: 0.034636, loss_fp: 0.002923, loss_freq: 0.018940
[18:23:37.791] iteration 21511: loss: 0.058153, loss_s1: 0.029079, loss_fp: 0.001699, loss_freq: 0.041408
[18:23:38.416] iteration 21512: loss: 0.055914, loss_s1: 0.067239, loss_fp: 0.003411, loss_freq: 0.009662
[18:23:39.042] iteration 21513: loss: 0.045036, loss_s1: 0.033097, loss_fp: 0.005576, loss_freq: 0.013810
[18:23:39.673] iteration 21514: loss: 0.066079, loss_s1: 0.071492, loss_fp: 0.013412, loss_freq: 0.016083
[18:23:40.299] iteration 21515: loss: 0.066496, loss_s1: 0.058488, loss_fp: 0.003910, loss_freq: 0.027317
[18:23:40.925] iteration 21516: loss: 0.052184, loss_s1: 0.054062, loss_fp: 0.003113, loss_freq: 0.020924
[18:23:41.542] iteration 21517: loss: 0.052343, loss_s1: 0.037138, loss_fp: 0.003359, loss_freq: 0.027467
[18:23:42.172] iteration 21518: loss: 0.072706, loss_s1: 0.047501, loss_fp: 0.005614, loss_freq: 0.018775
[18:23:42.803] iteration 21519: loss: 0.049400, loss_s1: 0.045140, loss_fp: 0.002121, loss_freq: 0.018277
[18:23:43.436] iteration 21520: loss: 0.049919, loss_s1: 0.054372, loss_fp: 0.000735, loss_freq: 0.006223
[18:23:44.067] iteration 21521: loss: 0.055366, loss_s1: 0.038259, loss_fp: 0.003748, loss_freq: 0.028222
[18:23:44.689] iteration 21522: loss: 0.103892, loss_s1: 0.091188, loss_fp: 0.010985, loss_freq: 0.048905
[18:23:45.318] iteration 21523: loss: 0.049347, loss_s1: 0.025338, loss_fp: 0.002959, loss_freq: 0.027152
[18:23:45.948] iteration 21524: loss: 0.055347, loss_s1: 0.037346, loss_fp: 0.003143, loss_freq: 0.016127
[18:23:46.568] iteration 21525: loss: 0.076830, loss_s1: 0.044485, loss_fp: 0.006965, loss_freq: 0.065698
[18:23:47.201] iteration 21526: loss: 0.097352, loss_s1: 0.118671, loss_fp: 0.001892, loss_freq: 0.035134
[18:23:47.829] iteration 21527: loss: 0.059208, loss_s1: 0.046636, loss_fp: 0.002647, loss_freq: 0.030346
[18:23:48.463] iteration 21528: loss: 0.043214, loss_s1: 0.036060, loss_fp: 0.004453, loss_freq: 0.008772
[18:23:49.083] iteration 21529: loss: 0.064583, loss_s1: 0.048299, loss_fp: 0.008170, loss_freq: 0.028569
[18:23:49.712] iteration 21530: loss: 0.073880, loss_s1: 0.090372, loss_fp: 0.003037, loss_freq: 0.024004
[18:23:50.342] iteration 21531: loss: 0.044011, loss_s1: 0.018278, loss_fp: 0.003813, loss_freq: 0.030251
[18:23:50.972] iteration 21532: loss: 0.074407, loss_s1: 0.037558, loss_fp: 0.005357, loss_freq: 0.050008
[18:23:51.637] iteration 21533: loss: 0.094620, loss_s1: 0.091149, loss_fp: 0.003664, loss_freq: 0.066099
[18:23:52.306] iteration 21534: loss: 0.048878, loss_s1: 0.049134, loss_fp: 0.007633, loss_freq: 0.010231
[18:23:52.968] iteration 21535: loss: 0.088819, loss_s1: 0.062614, loss_fp: 0.008335, loss_freq: 0.064384
[18:23:53.629] iteration 21536: loss: 0.050116, loss_s1: 0.059347, loss_fp: 0.002034, loss_freq: 0.005766
[18:23:54.289] iteration 21537: loss: 0.037318, loss_s1: 0.020195, loss_fp: 0.001145, loss_freq: 0.012118
[18:23:54.946] iteration 21538: loss: 0.068332, loss_s1: 0.051666, loss_fp: 0.009728, loss_freq: 0.032254
[18:23:55.609] iteration 21539: loss: 0.052409, loss_s1: 0.034849, loss_fp: 0.003208, loss_freq: 0.028941
[18:23:56.263] iteration 21540: loss: 0.044655, loss_s1: 0.043342, loss_fp: 0.000633, loss_freq: 0.005049
[18:23:56.921] iteration 21541: loss: 0.088274, loss_s1: 0.056777, loss_fp: 0.009734, loss_freq: 0.054944
[18:23:57.583] iteration 21542: loss: 0.039480, loss_s1: 0.022144, loss_fp: 0.000778, loss_freq: 0.019461
[18:23:58.217] iteration 21543: loss: 0.049761, loss_s1: 0.053707, loss_fp: 0.002841, loss_freq: 0.013501
[18:23:58.878] iteration 21544: loss: 0.068183, loss_s1: 0.055455, loss_fp: 0.002937, loss_freq: 0.048730
[18:23:59.504] iteration 21545: loss: 0.045681, loss_s1: 0.032322, loss_fp: 0.001458, loss_freq: 0.013568
[18:24:00.135] iteration 21546: loss: 0.053089, loss_s1: 0.055934, loss_fp: 0.001764, loss_freq: 0.009745
[18:24:00.764] iteration 21547: loss: 0.070371, loss_s1: 0.090385, loss_fp: 0.000757, loss_freq: 0.018681
[18:24:01.397] iteration 21548: loss: 0.053921, loss_s1: 0.040984, loss_fp: 0.008584, loss_freq: 0.023095
[18:24:02.025] iteration 21549: loss: 0.048945, loss_s1: 0.048136, loss_fp: 0.001364, loss_freq: 0.021743
[18:24:02.643] iteration 21550: loss: 0.034370, loss_s1: 0.014072, loss_fp: 0.002525, loss_freq: 0.020536
[18:24:03.267] iteration 21551: loss: 0.047639, loss_s1: 0.040783, loss_fp: 0.012171, loss_freq: 0.010628
[18:24:03.895] iteration 21552: loss: 0.052511, loss_s1: 0.035874, loss_fp: 0.013836, loss_freq: 0.022337
[18:24:04.513] iteration 21553: loss: 0.092123, loss_s1: 0.082773, loss_fp: 0.004875, loss_freq: 0.041696
[18:24:05.139] iteration 21554: loss: 0.071919, loss_s1: 0.076321, loss_fp: 0.004266, loss_freq: 0.032073
[18:24:05.761] iteration 21555: loss: 0.065793, loss_s1: 0.068555, loss_fp: 0.005334, loss_freq: 0.011979
[18:24:06.386] iteration 21556: loss: 0.049342, loss_s1: 0.020548, loss_fp: 0.002123, loss_freq: 0.039136
[18:24:07.001] iteration 21557: loss: 0.096035, loss_s1: 0.085535, loss_fp: 0.003702, loss_freq: 0.046011
[18:24:07.626] iteration 21558: loss: 0.034365, loss_s1: 0.029516, loss_fp: 0.000802, loss_freq: 0.005008
[18:24:08.254] iteration 21559: loss: 0.067511, loss_s1: 0.066937, loss_fp: 0.004505, loss_freq: 0.021567
[18:24:08.879] iteration 21560: loss: 0.088182, loss_s1: 0.055688, loss_fp: 0.008717, loss_freq: 0.072248
[18:24:09.506] iteration 21561: loss: 0.039331, loss_s1: 0.029931, loss_fp: 0.002091, loss_freq: 0.012726
[18:24:10.126] iteration 21562: loss: 0.058481, loss_s1: 0.037111, loss_fp: 0.014189, loss_freq: 0.032842
[18:24:10.757] iteration 21563: loss: 0.085443, loss_s1: 0.079991, loss_fp: 0.005547, loss_freq: 0.043670
[18:24:11.390] iteration 21564: loss: 0.104074, loss_s1: 0.064012, loss_fp: 0.002697, loss_freq: 0.089437
[18:24:12.020] iteration 21565: loss: 0.115546, loss_s1: 0.091553, loss_fp: 0.003896, loss_freq: 0.097342
[18:24:12.645] iteration 21566: loss: 0.056812, loss_s1: 0.039961, loss_fp: 0.004140, loss_freq: 0.037777
[18:24:13.274] iteration 21567: loss: 0.055476, loss_s1: 0.039312, loss_fp: 0.002057, loss_freq: 0.036432
[18:24:13.895] iteration 21568: loss: 0.033767, loss_s1: 0.031548, loss_fp: 0.002207, loss_freq: 0.002920
[18:24:14.526] iteration 21569: loss: 0.056268, loss_s1: 0.033318, loss_fp: 0.000545, loss_freq: 0.041035
[18:24:15.151] iteration 21570: loss: 0.039151, loss_s1: 0.019997, loss_fp: 0.000604, loss_freq: 0.012854
[18:24:15.782] iteration 21571: loss: 0.053735, loss_s1: 0.042821, loss_fp: 0.001770, loss_freq: 0.019972
[18:24:16.408] iteration 21572: loss: 0.083374, loss_s1: 0.057602, loss_fp: 0.014959, loss_freq: 0.043738
[18:24:17.032] iteration 21573: loss: 0.037529, loss_s1: 0.014837, loss_fp: 0.004575, loss_freq: 0.020606
[18:24:17.653] iteration 21574: loss: 0.040129, loss_s1: 0.022550, loss_fp: 0.000746, loss_freq: 0.017467
[18:24:18.626] iteration 21575: loss: 0.056086, loss_s1: 0.053223, loss_fp: 0.002344, loss_freq: 0.026293
[18:24:19.256] iteration 21576: loss: 0.070764, loss_s1: 0.061789, loss_fp: 0.012643, loss_freq: 0.010031
[18:24:19.885] iteration 21577: loss: 0.035282, loss_s1: 0.009317, loss_fp: 0.000778, loss_freq: 0.019582
[18:24:20.506] iteration 21578: loss: 0.051943, loss_s1: 0.040909, loss_fp: 0.000904, loss_freq: 0.018897
[18:24:21.138] iteration 21579: loss: 0.056028, loss_s1: 0.052310, loss_fp: 0.001716, loss_freq: 0.016058
[18:24:21.767] iteration 21580: loss: 0.085545, loss_s1: 0.054524, loss_fp: 0.004411, loss_freq: 0.054844
[18:24:22.405] iteration 21581: loss: 0.048884, loss_s1: 0.051010, loss_fp: 0.003307, loss_freq: 0.012210
[18:24:23.036] iteration 21582: loss: 0.041240, loss_s1: 0.043454, loss_fp: 0.003130, loss_freq: 0.007533
[18:24:23.659] iteration 21583: loss: 0.044074, loss_s1: 0.025678, loss_fp: 0.008673, loss_freq: 0.018028
[18:24:24.292] iteration 21584: loss: 0.062692, loss_s1: 0.057736, loss_fp: 0.013819, loss_freq: 0.015569
[18:24:24.920] iteration 21585: loss: 0.031977, loss_s1: 0.007929, loss_fp: 0.002094, loss_freq: 0.016741
[18:24:25.549] iteration 21586: loss: 0.051570, loss_s1: 0.047493, loss_fp: 0.004621, loss_freq: 0.017717
[18:24:26.171] iteration 21587: loss: 0.066279, loss_s1: 0.036895, loss_fp: 0.005053, loss_freq: 0.060774
[18:24:26.805] iteration 21588: loss: 0.045231, loss_s1: 0.025890, loss_fp: 0.001597, loss_freq: 0.023394
[18:24:27.437] iteration 21589: loss: 0.036055, loss_s1: 0.030159, loss_fp: 0.000540, loss_freq: 0.013751
[18:24:28.066] iteration 21590: loss: 0.089164, loss_s1: 0.043579, loss_fp: 0.009802, loss_freq: 0.088112
[18:24:28.698] iteration 21591: loss: 0.028620, loss_s1: 0.010456, loss_fp: 0.002995, loss_freq: 0.009431
[18:24:29.325] iteration 21592: loss: 0.062233, loss_s1: 0.050629, loss_fp: 0.008793, loss_freq: 0.031487
[18:24:29.954] iteration 21593: loss: 0.037193, loss_s1: 0.018782, loss_fp: 0.001181, loss_freq: 0.020787
[18:24:30.585] iteration 21594: loss: 0.045269, loss_s1: 0.016412, loss_fp: 0.001740, loss_freq: 0.022681
[18:24:31.212] iteration 21595: loss: 0.047246, loss_s1: 0.052943, loss_fp: 0.000645, loss_freq: 0.006436
[18:24:31.833] iteration 21596: loss: 0.036134, loss_s1: 0.007857, loss_fp: 0.001985, loss_freq: 0.012996
[18:24:32.460] iteration 21597: loss: 0.055784, loss_s1: 0.047511, loss_fp: 0.004429, loss_freq: 0.011663
[18:24:33.096] iteration 21598: loss: 0.107078, loss_s1: 0.106595, loss_fp: 0.002013, loss_freq: 0.075659
[18:24:33.726] iteration 21599: loss: 0.063808, loss_s1: 0.057153, loss_fp: 0.003805, loss_freq: 0.022087
[18:24:34.350] iteration 21600: loss: 0.058321, loss_s1: 0.043209, loss_fp: 0.002289, loss_freq: 0.034401
[18:24:37.456] iteration 21600 : mean_dice : 0.728951
[18:24:38.108] iteration 21601: loss: 0.061407, loss_s1: 0.048690, loss_fp: 0.002055, loss_freq: 0.039106
[18:24:38.728] iteration 21602: loss: 0.061841, loss_s1: 0.044427, loss_fp: 0.008081, loss_freq: 0.034657
[18:24:39.364] iteration 21603: loss: 0.057972, loss_s1: 0.032151, loss_fp: 0.002226, loss_freq: 0.049483
[18:24:39.988] iteration 21604: loss: 0.056069, loss_s1: 0.045153, loss_fp: 0.002206, loss_freq: 0.010964
[18:24:40.619] iteration 21605: loss: 0.046451, loss_s1: 0.042377, loss_fp: 0.003151, loss_freq: 0.015002
[18:24:41.247] iteration 21606: loss: 0.041576, loss_s1: 0.037952, loss_fp: 0.001058, loss_freq: 0.008445
[18:24:41.870] iteration 21607: loss: 0.041412, loss_s1: 0.026399, loss_fp: 0.001034, loss_freq: 0.023454
[18:24:42.504] iteration 21608: loss: 0.030886, loss_s1: 0.022710, loss_fp: 0.004362, loss_freq: 0.006645
[18:24:43.151] iteration 21609: loss: 0.059811, loss_s1: 0.035874, loss_fp: 0.004063, loss_freq: 0.026732
[18:24:43.807] iteration 21610: loss: 0.064198, loss_s1: 0.033810, loss_fp: 0.008176, loss_freq: 0.039106
[18:24:44.480] iteration 21611: loss: 0.072512, loss_s1: 0.072734, loss_fp: 0.007009, loss_freq: 0.028378
[18:24:45.138] iteration 21612: loss: 0.057919, loss_s1: 0.049967, loss_fp: 0.004597, loss_freq: 0.028204
[18:24:45.775] iteration 21613: loss: 0.059042, loss_s1: 0.029182, loss_fp: 0.002469, loss_freq: 0.037466
[18:24:46.411] iteration 21614: loss: 0.074116, loss_s1: 0.063808, loss_fp: 0.005640, loss_freq: 0.030239
[18:24:47.055] iteration 21615: loss: 0.062371, loss_s1: 0.040287, loss_fp: 0.005214, loss_freq: 0.014509
[18:24:47.677] iteration 21616: loss: 0.099642, loss_s1: 0.085226, loss_fp: 0.013273, loss_freq: 0.067551
[18:24:48.292] iteration 21617: loss: 0.052381, loss_s1: 0.044109, loss_fp: 0.008613, loss_freq: 0.024091
[18:24:48.925] iteration 21618: loss: 0.043784, loss_s1: 0.010794, loss_fp: 0.003123, loss_freq: 0.040047
[18:24:49.564] iteration 21619: loss: 0.053230, loss_s1: 0.036972, loss_fp: 0.005338, loss_freq: 0.028335
[18:24:50.207] iteration 21620: loss: 0.062129, loss_s1: 0.055421, loss_fp: 0.002174, loss_freq: 0.016385
[18:24:50.845] iteration 21621: loss: 0.039681, loss_s1: 0.025187, loss_fp: 0.009072, loss_freq: 0.016310
[18:24:51.487] iteration 21622: loss: 0.052323, loss_s1: 0.046881, loss_fp: 0.005894, loss_freq: 0.021034
[18:24:52.133] iteration 21623: loss: 0.092560, loss_s1: 0.099858, loss_fp: 0.002338, loss_freq: 0.031575
[18:24:52.771] iteration 21624: loss: 0.080188, loss_s1: 0.067963, loss_fp: 0.005170, loss_freq: 0.059581
[18:24:53.404] iteration 21625: loss: 0.069189, loss_s1: 0.059859, loss_fp: 0.009300, loss_freq: 0.038026
[18:24:54.047] iteration 21626: loss: 0.063978, loss_s1: 0.046493, loss_fp: 0.004250, loss_freq: 0.036986
[18:24:54.690] iteration 21627: loss: 0.071592, loss_s1: 0.044946, loss_fp: 0.004823, loss_freq: 0.022412
[18:24:55.330] iteration 21628: loss: 0.076470, loss_s1: 0.057641, loss_fp: 0.002035, loss_freq: 0.055838
[18:24:55.968] iteration 21629: loss: 0.037851, loss_s1: 0.016213, loss_fp: 0.001513, loss_freq: 0.018539
[18:24:56.608] iteration 21630: loss: 0.068762, loss_s1: 0.059965, loss_fp: 0.003828, loss_freq: 0.031523
[18:24:57.238] iteration 21631: loss: 0.038842, loss_s1: 0.021777, loss_fp: 0.004054, loss_freq: 0.009275
[18:24:57.869] iteration 21632: loss: 0.036692, loss_s1: 0.015228, loss_fp: 0.003084, loss_freq: 0.013642
[18:24:58.512] iteration 21633: loss: 0.029097, loss_s1: 0.011604, loss_fp: 0.003485, loss_freq: 0.005884
[18:24:59.154] iteration 21634: loss: 0.059475, loss_s1: 0.052058, loss_fp: 0.001932, loss_freq: 0.017581
[18:24:59.912] iteration 21635: loss: 0.044984, loss_s1: 0.021253, loss_fp: 0.005863, loss_freq: 0.023572
[18:25:00.587] iteration 21636: loss: 0.051783, loss_s1: 0.033206, loss_fp: 0.000484, loss_freq: 0.040075
[18:25:01.318] iteration 21637: loss: 0.035280, loss_s1: 0.013420, loss_fp: 0.001938, loss_freq: 0.009876
[18:25:01.953] iteration 21638: loss: 0.051380, loss_s1: 0.041922, loss_fp: 0.001738, loss_freq: 0.020876
[18:25:02.582] iteration 21639: loss: 0.065878, loss_s1: 0.085748, loss_fp: 0.003313, loss_freq: 0.006152
[18:25:03.207] iteration 21640: loss: 0.108396, loss_s1: 0.064610, loss_fp: 0.001404, loss_freq: 0.107074
[18:25:03.829] iteration 21641: loss: 0.062248, loss_s1: 0.031190, loss_fp: 0.002140, loss_freq: 0.043752
[18:25:04.452] iteration 21642: loss: 0.048006, loss_s1: 0.037294, loss_fp: 0.005543, loss_freq: 0.027259
[18:25:05.102] iteration 21643: loss: 0.045577, loss_s1: 0.042987, loss_fp: 0.000959, loss_freq: 0.014954
[18:25:05.728] iteration 21644: loss: 0.066655, loss_s1: 0.050372, loss_fp: 0.001617, loss_freq: 0.029809
[18:25:06.361] iteration 21645: loss: 0.108064, loss_s1: 0.102551, loss_fp: 0.004206, loss_freq: 0.066674
[18:25:06.982] iteration 21646: loss: 0.035722, loss_s1: 0.013982, loss_fp: 0.003547, loss_freq: 0.008102
[18:25:07.609] iteration 21647: loss: 0.038854, loss_s1: 0.039374, loss_fp: 0.002048, loss_freq: 0.004097
[18:25:08.231] iteration 21648: loss: 0.046648, loss_s1: 0.047962, loss_fp: 0.002501, loss_freq: 0.008985
[18:25:08.857] iteration 21649: loss: 0.053023, loss_s1: 0.036730, loss_fp: 0.000681, loss_freq: 0.033854
[18:25:09.482] iteration 21650: loss: 0.047763, loss_s1: 0.025385, loss_fp: 0.007131, loss_freq: 0.014530
[18:25:10.108] iteration 21651: loss: 0.076438, loss_s1: 0.069520, loss_fp: 0.003639, loss_freq: 0.036147
[18:25:10.729] iteration 21652: loss: 0.046116, loss_s1: 0.049339, loss_fp: 0.001389, loss_freq: 0.012476
[18:25:11.349] iteration 21653: loss: 0.033970, loss_s1: 0.023463, loss_fp: 0.002974, loss_freq: 0.010425
[18:25:11.976] iteration 21654: loss: 0.046585, loss_s1: 0.025992, loss_fp: 0.003424, loss_freq: 0.030227
[18:25:12.601] iteration 21655: loss: 0.049480, loss_s1: 0.039866, loss_fp: 0.000879, loss_freq: 0.017314
[18:25:13.218] iteration 21656: loss: 0.080047, loss_s1: 0.076162, loss_fp: 0.001932, loss_freq: 0.051398
[18:25:13.841] iteration 21657: loss: 0.110084, loss_s1: 0.057267, loss_fp: 0.001412, loss_freq: 0.125446
[18:25:14.468] iteration 21658: loss: 0.050012, loss_s1: 0.026330, loss_fp: 0.001816, loss_freq: 0.036080
[18:25:15.092] iteration 21659: loss: 0.084815, loss_s1: 0.090495, loss_fp: 0.010033, loss_freq: 0.035992
[18:25:15.716] iteration 21660: loss: 0.056066, loss_s1: 0.053219, loss_fp: 0.003283, loss_freq: 0.020268
[18:25:16.342] iteration 21661: loss: 0.043773, loss_s1: 0.025042, loss_fp: 0.000885, loss_freq: 0.017816
[18:25:16.970] iteration 21662: loss: 0.060249, loss_s1: 0.047811, loss_fp: 0.007719, loss_freq: 0.015088
[18:25:17.599] iteration 21663: loss: 0.057540, loss_s1: 0.041871, loss_fp: 0.008052, loss_freq: 0.029587
[18:25:18.226] iteration 21664: loss: 0.084624, loss_s1: 0.076286, loss_fp: 0.002237, loss_freq: 0.053588
[18:25:18.853] iteration 21665: loss: 0.070708, loss_s1: 0.086388, loss_fp: 0.002071, loss_freq: 0.016446
[18:25:19.479] iteration 21666: loss: 0.059761, loss_s1: 0.038594, loss_fp: 0.020411, loss_freq: 0.010714
[18:25:20.101] iteration 21667: loss: 0.070816, loss_s1: 0.026744, loss_fp: 0.002050, loss_freq: 0.058697
[18:25:20.728] iteration 21668: loss: 0.037281, loss_s1: 0.018257, loss_fp: 0.000966, loss_freq: 0.025214
[18:25:21.357] iteration 21669: loss: 0.056507, loss_s1: 0.026373, loss_fp: 0.023306, loss_freq: 0.035707
[18:25:21.985] iteration 21670: loss: 0.049658, loss_s1: 0.042347, loss_fp: 0.002254, loss_freq: 0.020273
[18:25:22.613] iteration 21671: loss: 0.031383, loss_s1: 0.012921, loss_fp: 0.001235, loss_freq: 0.018224
[18:25:23.240] iteration 21672: loss: 0.034662, loss_s1: 0.003984, loss_fp: 0.001200, loss_freq: 0.019890
[18:25:23.868] iteration 21673: loss: 0.039650, loss_s1: 0.016624, loss_fp: 0.000676, loss_freq: 0.030741
[18:25:24.487] iteration 21674: loss: 0.048677, loss_s1: 0.033769, loss_fp: 0.004491, loss_freq: 0.012716
[18:25:25.112] iteration 21675: loss: 0.054160, loss_s1: 0.060163, loss_fp: 0.006569, loss_freq: 0.013110
[18:25:25.744] iteration 21676: loss: 0.053288, loss_s1: 0.038236, loss_fp: 0.003773, loss_freq: 0.025025
[18:25:26.371] iteration 21677: loss: 0.064399, loss_s1: 0.025850, loss_fp: 0.004559, loss_freq: 0.059306
[18:25:26.994] iteration 21678: loss: 0.052359, loss_s1: 0.052543, loss_fp: 0.001672, loss_freq: 0.021123
[18:25:27.616] iteration 21679: loss: 0.051000, loss_s1: 0.042079, loss_fp: 0.003964, loss_freq: 0.007680
[18:25:28.243] iteration 21680: loss: 0.065411, loss_s1: 0.047280, loss_fp: 0.006295, loss_freq: 0.035513
[18:25:28.867] iteration 21681: loss: 0.049126, loss_s1: 0.036903, loss_fp: 0.011826, loss_freq: 0.015778
[18:25:29.496] iteration 21682: loss: 0.068085, loss_s1: 0.037311, loss_fp: 0.002954, loss_freq: 0.038774
[18:25:30.129] iteration 21683: loss: 0.138958, loss_s1: 0.066609, loss_fp: 0.010538, loss_freq: 0.159378
[18:25:30.759] iteration 21684: loss: 0.060502, loss_s1: 0.042179, loss_fp: 0.001787, loss_freq: 0.043204
[18:25:31.388] iteration 21685: loss: 0.054754, loss_s1: 0.035914, loss_fp: 0.002540, loss_freq: 0.013324
[18:25:32.010] iteration 21686: loss: 0.061140, loss_s1: 0.046317, loss_fp: 0.001112, loss_freq: 0.033817
[18:25:32.638] iteration 21687: loss: 0.072206, loss_s1: 0.073476, loss_fp: 0.004961, loss_freq: 0.023283
[18:25:33.264] iteration 21688: loss: 0.053877, loss_s1: 0.045195, loss_fp: 0.003333, loss_freq: 0.032845
[18:25:33.892] iteration 21689: loss: 0.037878, loss_s1: 0.014229, loss_fp: 0.004525, loss_freq: 0.007499
[18:25:34.514] iteration 21690: loss: 0.061039, loss_s1: 0.039939, loss_fp: 0.009728, loss_freq: 0.036157
[18:25:35.134] iteration 21691: loss: 0.078937, loss_s1: 0.051214, loss_fp: 0.031437, loss_freq: 0.044398
[18:25:35.765] iteration 21692: loss: 0.030923, loss_s1: 0.015708, loss_fp: 0.003158, loss_freq: 0.011033
[18:25:36.394] iteration 21693: loss: 0.074383, loss_s1: 0.030591, loss_fp: 0.001229, loss_freq: 0.040190
[18:25:37.018] iteration 21694: loss: 0.069579, loss_s1: 0.073895, loss_fp: 0.000907, loss_freq: 0.039502
[18:25:37.648] iteration 21695: loss: 0.056993, loss_s1: 0.043673, loss_fp: 0.001814, loss_freq: 0.038538
[18:25:38.275] iteration 21696: loss: 0.062887, loss_s1: 0.046812, loss_fp: 0.005606, loss_freq: 0.015080
[18:25:38.896] iteration 21697: loss: 0.058005, loss_s1: 0.036928, loss_fp: 0.000751, loss_freq: 0.033759
[18:25:39.523] iteration 21698: loss: 0.025069, loss_s1: 0.009008, loss_fp: 0.000660, loss_freq: 0.003227
[18:25:40.145] iteration 21699: loss: 0.044506, loss_s1: 0.025925, loss_fp: 0.005341, loss_freq: 0.030820
[18:25:40.771] iteration 21700: loss: 0.075419, loss_s1: 0.044150, loss_fp: 0.028073, loss_freq: 0.033826
[18:25:41.407] iteration 21701: loss: 0.047966, loss_s1: 0.046741, loss_fp: 0.004154, loss_freq: 0.010324
[18:25:42.034] iteration 21702: loss: 0.089120, loss_s1: 0.090306, loss_fp: 0.004035, loss_freq: 0.014591
[18:25:42.662] iteration 21703: loss: 0.069670, loss_s1: 0.048242, loss_fp: 0.013470, loss_freq: 0.043789
[18:25:43.280] iteration 21704: loss: 0.031694, loss_s1: 0.015379, loss_fp: 0.002251, loss_freq: 0.012975
[18:25:43.910] iteration 21705: loss: 0.059717, loss_s1: 0.038320, loss_fp: 0.009280, loss_freq: 0.041062
[18:25:44.530] iteration 21706: loss: 0.073216, loss_s1: 0.083531, loss_fp: 0.002118, loss_freq: 0.026897
[18:25:45.198] iteration 21707: loss: 0.049056, loss_s1: 0.032643, loss_fp: 0.000707, loss_freq: 0.014239
[18:25:45.824] iteration 21708: loss: 0.050712, loss_s1: 0.053850, loss_fp: 0.002131, loss_freq: 0.008601
[18:25:46.463] iteration 21709: loss: 0.037901, loss_s1: 0.025311, loss_fp: 0.001459, loss_freq: 0.013698
[18:25:47.086] iteration 21710: loss: 0.059114, loss_s1: 0.066190, loss_fp: 0.000334, loss_freq: 0.026419
[18:25:47.715] iteration 21711: loss: 0.034141, loss_s1: 0.011861, loss_fp: 0.001267, loss_freq: 0.008844
[18:25:48.341] iteration 21712: loss: 0.043061, loss_s1: 0.036159, loss_fp: 0.002421, loss_freq: 0.013972
[18:25:48.966] iteration 21713: loss: 0.039474, loss_s1: 0.021672, loss_fp: 0.001847, loss_freq: 0.016874
[18:25:49.618] iteration 21714: loss: 0.069228, loss_s1: 0.035045, loss_fp: 0.003398, loss_freq: 0.054967
[18:25:50.258] iteration 21715: loss: 0.051805, loss_s1: 0.035999, loss_fp: 0.001019, loss_freq: 0.026455
[18:25:50.905] iteration 21716: loss: 0.033119, loss_s1: 0.015965, loss_fp: 0.001414, loss_freq: 0.014800
[18:25:51.553] iteration 21717: loss: 0.075261, loss_s1: 0.059042, loss_fp: 0.003942, loss_freq: 0.051649
[18:25:52.199] iteration 21718: loss: 0.054420, loss_s1: 0.040830, loss_fp: 0.003126, loss_freq: 0.018719
[18:25:52.846] iteration 21719: loss: 0.039112, loss_s1: 0.011033, loss_fp: 0.002702, loss_freq: 0.016119
[18:25:53.489] iteration 21720: loss: 0.060258, loss_s1: 0.062385, loss_fp: 0.001014, loss_freq: 0.015621
[18:25:54.127] iteration 21721: loss: 0.092974, loss_s1: 0.086430, loss_fp: 0.002007, loss_freq: 0.067224
[18:25:54.772] iteration 21722: loss: 0.040334, loss_s1: 0.036909, loss_fp: 0.005523, loss_freq: 0.006068
[18:25:55.408] iteration 21723: loss: 0.029674, loss_s1: 0.012384, loss_fp: 0.002495, loss_freq: 0.009961
[18:25:56.049] iteration 21724: loss: 0.089477, loss_s1: 0.033898, loss_fp: 0.002212, loss_freq: 0.068476
[18:25:56.698] iteration 21725: loss: 0.065696, loss_s1: 0.049778, loss_fp: 0.009202, loss_freq: 0.018491
[18:25:57.344] iteration 21726: loss: 0.088509, loss_s1: 0.074197, loss_fp: 0.006072, loss_freq: 0.059284
[18:25:57.986] iteration 21727: loss: 0.046935, loss_s1: 0.032480, loss_fp: 0.003401, loss_freq: 0.026516
[18:25:58.622] iteration 21728: loss: 0.063842, loss_s1: 0.049716, loss_fp: 0.002984, loss_freq: 0.011434
[18:25:59.263] iteration 21729: loss: 0.029339, loss_s1: 0.019320, loss_fp: 0.002423, loss_freq: 0.008077
[18:25:59.905] iteration 21730: loss: 0.066841, loss_s1: 0.059906, loss_fp: 0.003779, loss_freq: 0.032859
[18:26:00.554] iteration 21731: loss: 0.033616, loss_s1: 0.018205, loss_fp: 0.000997, loss_freq: 0.013314
[18:26:01.195] iteration 21732: loss: 0.037492, loss_s1: 0.012280, loss_fp: 0.000626, loss_freq: 0.024992
[18:26:01.823] iteration 21733: loss: 0.052713, loss_s1: 0.033771, loss_fp: 0.003234, loss_freq: 0.024392
[18:26:02.446] iteration 21734: loss: 0.048569, loss_s1: 0.027588, loss_fp: 0.004385, loss_freq: 0.032878
[18:26:03.073] iteration 21735: loss: 0.045003, loss_s1: 0.031159, loss_fp: 0.003234, loss_freq: 0.017659
[18:26:04.090] iteration 21736: loss: 0.038774, loss_s1: 0.019838, loss_fp: 0.008501, loss_freq: 0.016821
[18:26:04.715] iteration 21737: loss: 0.073113, loss_s1: 0.084744, loss_fp: 0.002838, loss_freq: 0.023088
[18:26:05.342] iteration 21738: loss: 0.036851, loss_s1: 0.031835, loss_fp: 0.003142, loss_freq: 0.007908
[18:26:05.997] iteration 21739: loss: 0.044556, loss_s1: 0.014616, loss_fp: 0.001819, loss_freq: 0.020276
[18:26:06.659] iteration 21740: loss: 0.060985, loss_s1: 0.069941, loss_fp: 0.004989, loss_freq: 0.016874
[18:26:07.307] iteration 21741: loss: 0.083182, loss_s1: 0.061897, loss_fp: 0.001830, loss_freq: 0.045472
[18:26:07.935] iteration 21742: loss: 0.056207, loss_s1: 0.050545, loss_fp: 0.002846, loss_freq: 0.027196
[18:26:08.567] iteration 21743: loss: 0.035460, loss_s1: 0.030674, loss_fp: 0.001734, loss_freq: 0.008282
[18:26:09.195] iteration 21744: loss: 0.101975, loss_s1: 0.082497, loss_fp: 0.006190, loss_freq: 0.053780
[18:26:09.828] iteration 21745: loss: 0.074639, loss_s1: 0.087915, loss_fp: 0.004212, loss_freq: 0.011881
[18:26:10.458] iteration 21746: loss: 0.029842, loss_s1: 0.014877, loss_fp: 0.001714, loss_freq: 0.006859
[18:26:11.082] iteration 21747: loss: 0.068446, loss_s1: 0.044633, loss_fp: 0.003513, loss_freq: 0.020269
[18:26:11.708] iteration 21748: loss: 0.080419, loss_s1: 0.062307, loss_fp: 0.007544, loss_freq: 0.061221
[18:26:12.330] iteration 21749: loss: 0.064772, loss_s1: 0.052201, loss_fp: 0.014365, loss_freq: 0.022817
[18:26:12.961] iteration 21750: loss: 0.039902, loss_s1: 0.036839, loss_fp: 0.004784, loss_freq: 0.010487
[18:26:13.587] iteration 21751: loss: 0.139886, loss_s1: 0.092081, loss_fp: 0.009414, loss_freq: 0.135530
[18:26:14.224] iteration 21752: loss: 0.045104, loss_s1: 0.028673, loss_fp: 0.004195, loss_freq: 0.006879
[18:26:14.880] iteration 21753: loss: 0.080834, loss_s1: 0.085123, loss_fp: 0.016187, loss_freq: 0.020678
[18:26:15.555] iteration 21754: loss: 0.041086, loss_s1: 0.024507, loss_fp: 0.002324, loss_freq: 0.019263
[18:26:16.227] iteration 21755: loss: 0.051551, loss_s1: 0.024264, loss_fp: 0.001685, loss_freq: 0.026977
[18:26:16.893] iteration 21756: loss: 0.034419, loss_s1: 0.012108, loss_fp: 0.000266, loss_freq: 0.020743
[18:26:17.517] iteration 21757: loss: 0.030103, loss_s1: 0.011339, loss_fp: 0.002246, loss_freq: 0.009285
[18:26:18.156] iteration 21758: loss: 0.060134, loss_s1: 0.026666, loss_fp: 0.015061, loss_freq: 0.031657
[18:26:18.797] iteration 21759: loss: 0.088310, loss_s1: 0.038964, loss_fp: 0.003529, loss_freq: 0.105266
[18:26:19.428] iteration 21760: loss: 0.047121, loss_s1: 0.042373, loss_fp: 0.001097, loss_freq: 0.014790
[18:26:20.060] iteration 21761: loss: 0.047617, loss_s1: 0.035486, loss_fp: 0.001660, loss_freq: 0.019714
[18:26:20.701] iteration 21762: loss: 0.026617, loss_s1: 0.011696, loss_fp: 0.001485, loss_freq: 0.004783
[18:26:21.331] iteration 21763: loss: 0.059905, loss_s1: 0.043487, loss_fp: 0.006319, loss_freq: 0.032949
[18:26:21.964] iteration 21764: loss: 0.071666, loss_s1: 0.059264, loss_fp: 0.004846, loss_freq: 0.044848
[18:26:22.594] iteration 21765: loss: 0.057659, loss_s1: 0.053138, loss_fp: 0.006298, loss_freq: 0.016938
[18:26:23.220] iteration 21766: loss: 0.073413, loss_s1: 0.077979, loss_fp: 0.003070, loss_freq: 0.037284
[18:26:23.849] iteration 21767: loss: 0.049135, loss_s1: 0.031300, loss_fp: 0.007907, loss_freq: 0.012623
[18:26:24.511] iteration 21768: loss: 0.052596, loss_s1: 0.025419, loss_fp: 0.005525, loss_freq: 0.042952
[18:26:25.161] iteration 21769: loss: 0.029223, loss_s1: 0.022888, loss_fp: 0.004279, loss_freq: 0.004425
[18:26:25.788] iteration 21770: loss: 0.046646, loss_s1: 0.028724, loss_fp: 0.003381, loss_freq: 0.017538
[18:26:26.420] iteration 21771: loss: 0.057971, loss_s1: 0.048951, loss_fp: 0.007431, loss_freq: 0.024195
[18:26:27.082] iteration 21772: loss: 0.100978, loss_s1: 0.105866, loss_fp: 0.006671, loss_freq: 0.030045
[18:26:27.754] iteration 21773: loss: 0.049839, loss_s1: 0.035711, loss_fp: 0.001713, loss_freq: 0.025172
[18:26:28.422] iteration 21774: loss: 0.073684, loss_s1: 0.052018, loss_fp: 0.000655, loss_freq: 0.057049
[18:26:29.056] iteration 21775: loss: 0.055581, loss_s1: 0.033496, loss_fp: 0.000649, loss_freq: 0.041000
[18:26:29.684] iteration 21776: loss: 0.058097, loss_s1: 0.044933, loss_fp: 0.001685, loss_freq: 0.020165
[18:26:30.308] iteration 21777: loss: 0.051660, loss_s1: 0.028578, loss_fp: 0.009542, loss_freq: 0.030821
[18:26:30.930] iteration 21778: loss: 0.066678, loss_s1: 0.061183, loss_fp: 0.005273, loss_freq: 0.024958
[18:26:31.570] iteration 21779: loss: 0.051242, loss_s1: 0.031663, loss_fp: 0.004247, loss_freq: 0.040190
[18:26:32.202] iteration 21780: loss: 0.061589, loss_s1: 0.066780, loss_fp: 0.001062, loss_freq: 0.020756
[18:26:32.834] iteration 21781: loss: 0.030063, loss_s1: 0.017860, loss_fp: 0.001731, loss_freq: 0.006785
[18:26:33.460] iteration 21782: loss: 0.032529, loss_s1: 0.014225, loss_fp: 0.001575, loss_freq: 0.011578
[18:26:34.083] iteration 21783: loss: 0.065851, loss_s1: 0.060642, loss_fp: 0.005992, loss_freq: 0.031664
[18:26:34.709] iteration 21784: loss: 0.076041, loss_s1: 0.090971, loss_fp: 0.001436, loss_freq: 0.020097
[18:26:35.336] iteration 21785: loss: 0.078770, loss_s1: 0.062150, loss_fp: 0.002502, loss_freq: 0.058080
[18:26:35.962] iteration 21786: loss: 0.060600, loss_s1: 0.038846, loss_fp: 0.020806, loss_freq: 0.029907
[18:26:36.593] iteration 21787: loss: 0.074897, loss_s1: 0.078032, loss_fp: 0.001309, loss_freq: 0.025435
[18:26:37.216] iteration 21788: loss: 0.052409, loss_s1: 0.018903, loss_fp: 0.006901, loss_freq: 0.030501
[18:26:37.844] iteration 21789: loss: 0.045695, loss_s1: 0.018298, loss_fp: 0.000982, loss_freq: 0.042518
[18:26:38.466] iteration 21790: loss: 0.034064, loss_s1: 0.016565, loss_fp: 0.001552, loss_freq: 0.013593
[18:26:39.105] iteration 21791: loss: 0.065049, loss_s1: 0.061750, loss_fp: 0.004562, loss_freq: 0.025468
[18:26:39.725] iteration 21792: loss: 0.041392, loss_s1: 0.019580, loss_fp: 0.001419, loss_freq: 0.026433
[18:26:40.353] iteration 21793: loss: 0.075549, loss_s1: 0.065318, loss_fp: 0.007431, loss_freq: 0.021603
[18:26:40.981] iteration 21794: loss: 0.032042, loss_s1: 0.019046, loss_fp: 0.000864, loss_freq: 0.007772
[18:26:41.617] iteration 21795: loss: 0.043552, loss_s1: 0.018213, loss_fp: 0.001608, loss_freq: 0.030924
[18:26:42.235] iteration 21796: loss: 0.044040, loss_s1: 0.041120, loss_fp: 0.003996, loss_freq: 0.014680
[18:26:42.861] iteration 21797: loss: 0.044695, loss_s1: 0.032350, loss_fp: 0.002971, loss_freq: 0.025803
[18:26:43.492] iteration 21798: loss: 0.054176, loss_s1: 0.040190, loss_fp: 0.000785, loss_freq: 0.024561
[18:26:44.112] iteration 21799: loss: 0.051457, loss_s1: 0.034602, loss_fp: 0.002777, loss_freq: 0.010276
[18:26:44.738] iteration 21800: loss: 0.055484, loss_s1: 0.051835, loss_fp: 0.000825, loss_freq: 0.022288
[18:26:47.938] iteration 21800 : mean_dice : 0.728015
[18:26:48.591] iteration 21801: loss: 0.107072, loss_s1: 0.044268, loss_fp: 0.013641, loss_freq: 0.119435
[18:26:49.222] iteration 21802: loss: 0.053027, loss_s1: 0.016914, loss_fp: 0.002252, loss_freq: 0.029361
[18:26:49.844] iteration 21803: loss: 0.066373, loss_s1: 0.061695, loss_fp: 0.004386, loss_freq: 0.038549
[18:26:50.470] iteration 21804: loss: 0.055819, loss_s1: 0.046257, loss_fp: 0.006619, loss_freq: 0.026616
[18:26:51.104] iteration 21805: loss: 0.059546, loss_s1: 0.028856, loss_fp: 0.002896, loss_freq: 0.028976
[18:26:51.724] iteration 21806: loss: 0.090233, loss_s1: 0.081030, loss_fp: 0.011008, loss_freq: 0.052008
[18:26:52.344] iteration 21807: loss: 0.048850, loss_s1: 0.029648, loss_fp: 0.001987, loss_freq: 0.021063
[18:26:52.966] iteration 21808: loss: 0.074473, loss_s1: 0.049280, loss_fp: 0.003802, loss_freq: 0.049313
[18:26:53.597] iteration 21809: loss: 0.042540, loss_s1: 0.027367, loss_fp: 0.004970, loss_freq: 0.010462
[18:26:54.219] iteration 21810: loss: 0.112754, loss_s1: 0.158355, loss_fp: 0.002167, loss_freq: 0.033039
[18:26:54.847] iteration 21811: loss: 0.055548, loss_s1: 0.058194, loss_fp: 0.002377, loss_freq: 0.008767
[18:26:55.476] iteration 21812: loss: 0.041888, loss_s1: 0.027392, loss_fp: 0.001836, loss_freq: 0.017321
[18:26:56.111] iteration 21813: loss: 0.029411, loss_s1: 0.013285, loss_fp: 0.003872, loss_freq: 0.009601
[18:26:56.735] iteration 21814: loss: 0.031791, loss_s1: 0.007691, loss_fp: 0.001356, loss_freq: 0.022910
[18:26:57.377] iteration 21815: loss: 0.061497, loss_s1: 0.044274, loss_fp: 0.002092, loss_freq: 0.042041
[18:26:58.010] iteration 21816: loss: 0.060260, loss_s1: 0.036417, loss_fp: 0.005117, loss_freq: 0.031435
[18:26:58.650] iteration 21817: loss: 0.080968, loss_s1: 0.083749, loss_fp: 0.003433, loss_freq: 0.032658
[18:26:59.286] iteration 21818: loss: 0.089271, loss_s1: 0.096997, loss_fp: 0.009831, loss_freq: 0.035509
[18:26:59.937] iteration 21819: loss: 0.064642, loss_s1: 0.038519, loss_fp: 0.002232, loss_freq: 0.048354
[18:27:00.574] iteration 21820: loss: 0.086940, loss_s1: 0.071792, loss_fp: 0.018374, loss_freq: 0.050358
[18:27:01.213] iteration 21821: loss: 0.036288, loss_s1: 0.026729, loss_fp: 0.001309, loss_freq: 0.009249
[18:27:01.853] iteration 21822: loss: 0.051825, loss_s1: 0.035829, loss_fp: 0.001476, loss_freq: 0.019683
[18:27:02.494] iteration 21823: loss: 0.067111, loss_s1: 0.083195, loss_fp: 0.002738, loss_freq: 0.010955
[18:27:03.135] iteration 21824: loss: 0.071959, loss_s1: 0.040951, loss_fp: 0.005403, loss_freq: 0.050700
[18:27:03.779] iteration 21825: loss: 0.068731, loss_s1: 0.060367, loss_fp: 0.002290, loss_freq: 0.032965
[18:27:04.420] iteration 21826: loss: 0.066577, loss_s1: 0.065516, loss_fp: 0.010724, loss_freq: 0.020671
[18:27:05.096] iteration 21827: loss: 0.052433, loss_s1: 0.024573, loss_fp: 0.002799, loss_freq: 0.033608
[18:27:06.105] iteration 21828: loss: 0.062620, loss_s1: 0.027745, loss_fp: 0.002719, loss_freq: 0.019334
[18:27:06.863] iteration 21829: loss: 0.036241, loss_s1: 0.021830, loss_fp: 0.001234, loss_freq: 0.017756
[18:27:07.500] iteration 21830: loss: 0.095712, loss_s1: 0.097999, loss_fp: 0.008706, loss_freq: 0.061607
[18:27:08.125] iteration 21831: loss: 0.061226, loss_s1: 0.043276, loss_fp: 0.002285, loss_freq: 0.045937
[18:27:08.748] iteration 21832: loss: 0.035032, loss_s1: 0.020911, loss_fp: 0.003506, loss_freq: 0.016474
[18:27:09.370] iteration 21833: loss: 0.045424, loss_s1: 0.023262, loss_fp: 0.009942, loss_freq: 0.018065
[18:27:09.993] iteration 21834: loss: 0.037259, loss_s1: 0.012175, loss_fp: 0.004351, loss_freq: 0.028849
[18:27:10.616] iteration 21835: loss: 0.069264, loss_s1: 0.095251, loss_fp: 0.002420, loss_freq: 0.006295
[18:27:11.239] iteration 21836: loss: 0.073480, loss_s1: 0.072454, loss_fp: 0.024818, loss_freq: 0.020567
[18:27:11.869] iteration 21837: loss: 0.058338, loss_s1: 0.037660, loss_fp: 0.005617, loss_freq: 0.040056
[18:27:12.492] iteration 21838: loss: 0.071073, loss_s1: 0.057342, loss_fp: 0.002540, loss_freq: 0.053838
[18:27:13.110] iteration 21839: loss: 0.056119, loss_s1: 0.060105, loss_fp: 0.001907, loss_freq: 0.013103
[18:27:13.734] iteration 21840: loss: 0.038625, loss_s1: 0.015367, loss_fp: 0.002817, loss_freq: 0.009252
[18:27:14.357] iteration 21841: loss: 0.051076, loss_s1: 0.032374, loss_fp: 0.001434, loss_freq: 0.040214
[18:27:14.988] iteration 21842: loss: 0.036052, loss_s1: 0.030826, loss_fp: 0.000770, loss_freq: 0.009891
[18:27:15.616] iteration 21843: loss: 0.062472, loss_s1: 0.058073, loss_fp: 0.000823, loss_freq: 0.021335
[18:27:16.269] iteration 21844: loss: 0.079987, loss_s1: 0.060861, loss_fp: 0.013261, loss_freq: 0.053656
[18:27:16.892] iteration 21845: loss: 0.055518, loss_s1: 0.053934, loss_fp: 0.001526, loss_freq: 0.017808
[18:27:17.521] iteration 21846: loss: 0.069969, loss_s1: 0.074055, loss_fp: 0.009162, loss_freq: 0.009872
[18:27:18.150] iteration 21847: loss: 0.046567, loss_s1: 0.023011, loss_fp: 0.005764, loss_freq: 0.028442
[18:27:18.772] iteration 21848: loss: 0.065319, loss_s1: 0.081573, loss_fp: 0.001559, loss_freq: 0.015412
[18:27:19.397] iteration 21849: loss: 0.042665, loss_s1: 0.036401, loss_fp: 0.003668, loss_freq: 0.017250
[18:27:20.026] iteration 21850: loss: 0.027910, loss_s1: 0.010843, loss_fp: 0.003539, loss_freq: 0.004370
[18:27:20.651] iteration 21851: loss: 0.050739, loss_s1: 0.039523, loss_fp: 0.004606, loss_freq: 0.022601
[18:27:21.275] iteration 21852: loss: 0.040775, loss_s1: 0.039208, loss_fp: 0.000802, loss_freq: 0.011655
[18:27:21.906] iteration 21853: loss: 0.043935, loss_s1: 0.049220, loss_fp: 0.002402, loss_freq: 0.006142
[18:27:22.531] iteration 21854: loss: 0.054019, loss_s1: 0.024488, loss_fp: 0.014298, loss_freq: 0.025895
[18:27:23.158] iteration 21855: loss: 0.092359, loss_s1: 0.069811, loss_fp: 0.003589, loss_freq: 0.082718
[18:27:23.787] iteration 21856: loss: 0.054806, loss_s1: 0.015396, loss_fp: 0.005502, loss_freq: 0.059278
[18:27:24.413] iteration 21857: loss: 0.084656, loss_s1: 0.040932, loss_fp: 0.007085, loss_freq: 0.038933
[18:27:25.039] iteration 21858: loss: 0.051497, loss_s1: 0.043709, loss_fp: 0.003236, loss_freq: 0.012132
[18:27:25.659] iteration 21859: loss: 0.039838, loss_s1: 0.024188, loss_fp: 0.001618, loss_freq: 0.015897
[18:27:26.282] iteration 21860: loss: 0.064166, loss_s1: 0.047218, loss_fp: 0.002995, loss_freq: 0.043678
[18:27:26.905] iteration 21861: loss: 0.063065, loss_s1: 0.065109, loss_fp: 0.001712, loss_freq: 0.022387
[18:27:27.528] iteration 21862: loss: 0.049151, loss_s1: 0.045858, loss_fp: 0.000766, loss_freq: 0.015134
[18:27:28.150] iteration 21863: loss: 0.051896, loss_s1: 0.023598, loss_fp: 0.001274, loss_freq: 0.016589
[18:27:28.768] iteration 21864: loss: 0.047892, loss_s1: 0.025609, loss_fp: 0.003912, loss_freq: 0.033365
[18:27:29.398] iteration 21865: loss: 0.067384, loss_s1: 0.084488, loss_fp: 0.000626, loss_freq: 0.018051
[18:27:30.032] iteration 21866: loss: 0.091130, loss_s1: 0.064026, loss_fp: 0.003461, loss_freq: 0.072393
[18:27:30.659] iteration 21867: loss: 0.052927, loss_s1: 0.050559, loss_fp: 0.000824, loss_freq: 0.026293
[18:27:31.338] iteration 21868: loss: 0.060865, loss_s1: 0.060005, loss_fp: 0.003004, loss_freq: 0.020058
[18:27:31.956] iteration 21869: loss: 0.031295, loss_s1: 0.026727, loss_fp: 0.002592, loss_freq: 0.006539
[18:27:32.575] iteration 21870: loss: 0.053647, loss_s1: 0.031375, loss_fp: 0.005375, loss_freq: 0.027265
[18:27:33.202] iteration 21871: loss: 0.065628, loss_s1: 0.057813, loss_fp: 0.003132, loss_freq: 0.038436
[18:27:33.828] iteration 21872: loss: 0.032747, loss_s1: 0.024248, loss_fp: 0.000880, loss_freq: 0.006411
[18:27:34.449] iteration 21873: loss: 0.035435, loss_s1: 0.026855, loss_fp: 0.001262, loss_freq: 0.007519
[18:27:35.077] iteration 21874: loss: 0.048466, loss_s1: 0.044165, loss_fp: 0.003089, loss_freq: 0.020547
[18:27:35.707] iteration 21875: loss: 0.087073, loss_s1: 0.070054, loss_fp: 0.001663, loss_freq: 0.023012
[18:27:36.333] iteration 21876: loss: 0.055211, loss_s1: 0.030856, loss_fp: 0.004439, loss_freq: 0.039325
[18:27:36.957] iteration 21877: loss: 0.048308, loss_s1: 0.028931, loss_fp: 0.003898, loss_freq: 0.022197
[18:27:37.581] iteration 21878: loss: 0.057600, loss_s1: 0.040890, loss_fp: 0.004845, loss_freq: 0.035366
[18:27:38.207] iteration 21879: loss: 0.060184, loss_s1: 0.055801, loss_fp: 0.004682, loss_freq: 0.024814
[18:27:38.834] iteration 21880: loss: 0.051046, loss_s1: 0.032880, loss_fp: 0.000754, loss_freq: 0.029884
[18:27:39.451] iteration 21881: loss: 0.080253, loss_s1: 0.054386, loss_fp: 0.023580, loss_freq: 0.041684
[18:27:40.075] iteration 21882: loss: 0.077560, loss_s1: 0.051672, loss_fp: 0.005112, loss_freq: 0.068068
[18:27:40.704] iteration 21883: loss: 0.039258, loss_s1: 0.040936, loss_fp: 0.002940, loss_freq: 0.007975
[18:27:41.331] iteration 21884: loss: 0.044178, loss_s1: 0.019517, loss_fp: 0.002817, loss_freq: 0.016007
[18:27:41.964] iteration 21885: loss: 0.062532, loss_s1: 0.055439, loss_fp: 0.003001, loss_freq: 0.028298
[18:27:42.583] iteration 21886: loss: 0.070056, loss_s1: 0.063902, loss_fp: 0.004740, loss_freq: 0.035667
[18:27:43.215] iteration 21887: loss: 0.086556, loss_s1: 0.087599, loss_fp: 0.003074, loss_freq: 0.040168
[18:27:43.840] iteration 21888: loss: 0.048225, loss_s1: 0.046146, loss_fp: 0.001437, loss_freq: 0.017447
[18:27:44.456] iteration 21889: loss: 0.063392, loss_s1: 0.050847, loss_fp: 0.003379, loss_freq: 0.034032
[18:27:45.075] iteration 21890: loss: 0.028262, loss_s1: 0.005931, loss_fp: 0.001202, loss_freq: 0.009087
[18:27:45.694] iteration 21891: loss: 0.054482, loss_s1: 0.026871, loss_fp: 0.005734, loss_freq: 0.039661
[18:27:46.318] iteration 21892: loss: 0.039031, loss_s1: 0.018558, loss_fp: 0.002756, loss_freq: 0.019407
[18:27:46.945] iteration 21893: loss: 0.073839, loss_s1: 0.077902, loss_fp: 0.003897, loss_freq: 0.021998
[18:27:47.566] iteration 21894: loss: 0.071455, loss_s1: 0.052665, loss_fp: 0.006225, loss_freq: 0.050682
[18:27:48.184] iteration 21895: loss: 0.071849, loss_s1: 0.075513, loss_fp: 0.007923, loss_freq: 0.025045
[18:27:48.806] iteration 21896: loss: 0.071176, loss_s1: 0.042922, loss_fp: 0.002596, loss_freq: 0.043455
[18:27:49.862] iteration 21897: loss: 0.039976, loss_s1: 0.018956, loss_fp: 0.001595, loss_freq: 0.023688
[18:27:50.523] iteration 21898: loss: 0.063773, loss_s1: 0.051865, loss_fp: 0.006452, loss_freq: 0.037438
[18:27:51.158] iteration 21899: loss: 0.029243, loss_s1: 0.011461, loss_fp: 0.002899, loss_freq: 0.011151
[18:27:51.778] iteration 21900: loss: 0.041303, loss_s1: 0.032792, loss_fp: 0.002503, loss_freq: 0.011113
[18:27:52.408] iteration 21901: loss: 0.053017, loss_s1: 0.026902, loss_fp: 0.004328, loss_freq: 0.014751
[18:27:53.037] iteration 21902: loss: 0.070902, loss_s1: 0.026727, loss_fp: 0.005734, loss_freq: 0.038778
[18:27:53.710] iteration 21903: loss: 0.039598, loss_s1: 0.026806, loss_fp: 0.006784, loss_freq: 0.012631
[18:27:54.380] iteration 21904: loss: 0.028495, loss_s1: 0.015095, loss_fp: 0.003602, loss_freq: 0.007063
[18:27:55.040] iteration 21905: loss: 0.048674, loss_s1: 0.048004, loss_fp: 0.008115, loss_freq: 0.014331
[18:27:55.703] iteration 21906: loss: 0.064408, loss_s1: 0.039487, loss_fp: 0.027323, loss_freq: 0.018554
[18:27:56.363] iteration 21907: loss: 0.038509, loss_s1: 0.020631, loss_fp: 0.003241, loss_freq: 0.012347
[18:27:56.991] iteration 21908: loss: 0.042837, loss_s1: 0.037748, loss_fp: 0.001894, loss_freq: 0.007767
[18:27:57.620] iteration 21909: loss: 0.095104, loss_s1: 0.051642, loss_fp: 0.011293, loss_freq: 0.095641
[18:27:58.260] iteration 21910: loss: 0.058704, loss_s1: 0.019677, loss_fp: 0.003021, loss_freq: 0.034557
[18:27:58.898] iteration 21911: loss: 0.034842, loss_s1: 0.025590, loss_fp: 0.002038, loss_freq: 0.007658
[18:27:59.540] iteration 21912: loss: 0.120694, loss_s1: 0.102955, loss_fp: 0.014009, loss_freq: 0.093192
[18:28:00.161] iteration 21913: loss: 0.052856, loss_s1: 0.023029, loss_fp: 0.003964, loss_freq: 0.015338
[18:28:00.784] iteration 21914: loss: 0.054246, loss_s1: 0.042213, loss_fp: 0.004288, loss_freq: 0.019402
[18:28:01.420] iteration 21915: loss: 0.057633, loss_s1: 0.031423, loss_fp: 0.002174, loss_freq: 0.022548
[18:28:02.045] iteration 21916: loss: 0.051467, loss_s1: 0.021783, loss_fp: 0.000688, loss_freq: 0.027927
[18:28:02.662] iteration 21917: loss: 0.035144, loss_s1: 0.017625, loss_fp: 0.005081, loss_freq: 0.008962
[18:28:03.284] iteration 21918: loss: 0.042851, loss_s1: 0.024473, loss_fp: 0.003961, loss_freq: 0.018363
[18:28:03.919] iteration 21919: loss: 0.039552, loss_s1: 0.018867, loss_fp: 0.003869, loss_freq: 0.010623
[18:28:04.549] iteration 21920: loss: 0.030617, loss_s1: 0.009604, loss_fp: 0.003226, loss_freq: 0.017665
[18:28:05.178] iteration 21921: loss: 0.050033, loss_s1: 0.050485, loss_fp: 0.001050, loss_freq: 0.022044
[18:28:05.805] iteration 21922: loss: 0.048021, loss_s1: 0.037924, loss_fp: 0.002386, loss_freq: 0.028768
[18:28:06.428] iteration 21923: loss: 0.053271, loss_s1: 0.048432, loss_fp: 0.000427, loss_freq: 0.023039
[18:28:07.059] iteration 21924: loss: 0.074369, loss_s1: 0.077689, loss_fp: 0.003575, loss_freq: 0.029230
[18:28:07.689] iteration 21925: loss: 0.065400, loss_s1: 0.029411, loss_fp: 0.002590, loss_freq: 0.045328
[18:28:08.311] iteration 21926: loss: 0.036502, loss_s1: 0.024844, loss_fp: 0.002283, loss_freq: 0.007925
[18:28:08.942] iteration 21927: loss: 0.029287, loss_s1: 0.012260, loss_fp: 0.001448, loss_freq: 0.010949
[18:28:09.564] iteration 21928: loss: 0.042883, loss_s1: 0.030942, loss_fp: 0.006214, loss_freq: 0.008610
[18:28:10.194] iteration 21929: loss: 0.039413, loss_s1: 0.022118, loss_fp: 0.000485, loss_freq: 0.023658
[18:28:10.826] iteration 21930: loss: 0.047544, loss_s1: 0.032959, loss_fp: 0.002648, loss_freq: 0.022316
[18:28:11.461] iteration 21931: loss: 0.058225, loss_s1: 0.029693, loss_fp: 0.003252, loss_freq: 0.034930
[18:28:12.090] iteration 21932: loss: 0.085487, loss_s1: 0.067323, loss_fp: 0.001004, loss_freq: 0.071195
[18:28:12.708] iteration 21933: loss: 0.068895, loss_s1: 0.072926, loss_fp: 0.002895, loss_freq: 0.030881
[18:28:13.333] iteration 21934: loss: 0.063827, loss_s1: 0.037089, loss_fp: 0.003599, loss_freq: 0.037510
[18:28:13.964] iteration 21935: loss: 0.096308, loss_s1: 0.094168, loss_fp: 0.002118, loss_freq: 0.052898
[18:28:14.597] iteration 21936: loss: 0.050704, loss_s1: 0.029078, loss_fp: 0.001673, loss_freq: 0.027199
[18:28:15.219] iteration 21937: loss: 0.054735, loss_s1: 0.040127, loss_fp: 0.000850, loss_freq: 0.008686
[18:28:15.845] iteration 21938: loss: 0.043783, loss_s1: 0.019832, loss_fp: 0.004332, loss_freq: 0.033821
[18:28:16.471] iteration 21939: loss: 0.066046, loss_s1: 0.044413, loss_fp: 0.014518, loss_freq: 0.035687
[18:28:17.096] iteration 21940: loss: 0.046974, loss_s1: 0.024095, loss_fp: 0.002348, loss_freq: 0.040412
[18:28:17.726] iteration 21941: loss: 0.051781, loss_s1: 0.025058, loss_fp: 0.001125, loss_freq: 0.041311
[18:28:18.355] iteration 21942: loss: 0.042291, loss_s1: 0.040068, loss_fp: 0.000909, loss_freq: 0.002428
[18:28:18.982] iteration 21943: loss: 0.025891, loss_s1: 0.015773, loss_fp: 0.000935, loss_freq: 0.005428
[18:28:19.640] iteration 21944: loss: 0.052795, loss_s1: 0.040098, loss_fp: 0.001563, loss_freq: 0.037256
[18:28:20.272] iteration 21945: loss: 0.081581, loss_s1: 0.089189, loss_fp: 0.001197, loss_freq: 0.032594
[18:28:20.896] iteration 21946: loss: 0.052053, loss_s1: 0.039360, loss_fp: 0.002001, loss_freq: 0.026610
[18:28:21.522] iteration 21947: loss: 0.057300, loss_s1: 0.029443, loss_fp: 0.003472, loss_freq: 0.045329
[18:28:22.147] iteration 21948: loss: 0.055895, loss_s1: 0.038786, loss_fp: 0.002318, loss_freq: 0.022796
[18:28:22.767] iteration 21949: loss: 0.043931, loss_s1: 0.032025, loss_fp: 0.002083, loss_freq: 0.017000
[18:28:23.390] iteration 21950: loss: 0.040384, loss_s1: 0.022380, loss_fp: 0.001012, loss_freq: 0.022253
[18:28:24.052] iteration 21951: loss: 0.033886, loss_s1: 0.019157, loss_fp: 0.001239, loss_freq: 0.013099
[18:28:24.689] iteration 21952: loss: 0.059798, loss_s1: 0.055985, loss_fp: 0.002790, loss_freq: 0.022269
[18:28:25.322] iteration 21953: loss: 0.032559, loss_s1: 0.018719, loss_fp: 0.002150, loss_freq: 0.006937
[18:28:25.940] iteration 21954: loss: 0.053673, loss_s1: 0.047722, loss_fp: 0.001421, loss_freq: 0.012086
[18:28:26.569] iteration 21955: loss: 0.039725, loss_s1: 0.028524, loss_fp: 0.011082, loss_freq: 0.011768
[18:28:27.194] iteration 21956: loss: 0.041464, loss_s1: 0.035991, loss_fp: 0.000914, loss_freq: 0.019096
[18:28:27.818] iteration 21957: loss: 0.040929, loss_s1: 0.012791, loss_fp: 0.004775, loss_freq: 0.016273
[18:28:28.442] iteration 21958: loss: 0.049961, loss_s1: 0.017940, loss_fp: 0.006421, loss_freq: 0.029196
[18:28:29.067] iteration 21959: loss: 0.047184, loss_s1: 0.042505, loss_fp: 0.000535, loss_freq: 0.014539
[18:28:29.694] iteration 21960: loss: 0.049682, loss_s1: 0.022708, loss_fp: 0.007609, loss_freq: 0.039962
[18:28:30.325] iteration 21961: loss: 0.063637, loss_s1: 0.049090, loss_fp: 0.002498, loss_freq: 0.032581
[18:28:30.954] iteration 21962: loss: 0.075968, loss_s1: 0.027536, loss_fp: 0.002076, loss_freq: 0.091052
[18:28:31.578] iteration 21963: loss: 0.059335, loss_s1: 0.052672, loss_fp: 0.002303, loss_freq: 0.023760
[18:28:32.209] iteration 21964: loss: 0.055619, loss_s1: 0.046865, loss_fp: 0.004704, loss_freq: 0.025694
[18:28:32.828] iteration 21965: loss: 0.053388, loss_s1: 0.046859, loss_fp: 0.003220, loss_freq: 0.023262
[18:28:33.453] iteration 21966: loss: 0.064717, loss_s1: 0.039453, loss_fp: 0.005340, loss_freq: 0.035998
[18:28:34.081] iteration 21967: loss: 0.122196, loss_s1: 0.117570, loss_fp: 0.003142, loss_freq: 0.082570
[18:28:34.708] iteration 21968: loss: 0.053019, loss_s1: 0.047963, loss_fp: 0.001636, loss_freq: 0.028450
[18:28:35.331] iteration 21969: loss: 0.032807, loss_s1: 0.024127, loss_fp: 0.002934, loss_freq: 0.007181
[18:28:35.954] iteration 21970: loss: 0.042941, loss_s1: 0.031595, loss_fp: 0.007127, loss_freq: 0.011469
[18:28:36.581] iteration 21971: loss: 0.065237, loss_s1: 0.050583, loss_fp: 0.002125, loss_freq: 0.023425
[18:28:37.203] iteration 21972: loss: 0.061508, loss_s1: 0.063863, loss_fp: 0.001790, loss_freq: 0.008995
[18:28:37.830] iteration 21973: loss: 0.063044, loss_s1: 0.042309, loss_fp: 0.007414, loss_freq: 0.039687
[18:28:38.461] iteration 21974: loss: 0.045767, loss_s1: 0.029462, loss_fp: 0.001818, loss_freq: 0.031408
[18:28:39.088] iteration 21975: loss: 0.033159, loss_s1: 0.027067, loss_fp: 0.002920, loss_freq: 0.012064
[18:28:39.720] iteration 21976: loss: 0.082242, loss_s1: 0.073388, loss_fp: 0.004036, loss_freq: 0.050710
[18:28:40.351] iteration 21977: loss: 0.079600, loss_s1: 0.067677, loss_fp: 0.006956, loss_freq: 0.046510
[18:28:40.979] iteration 21978: loss: 0.060994, loss_s1: 0.059372, loss_fp: 0.003620, loss_freq: 0.028129
[18:28:41.609] iteration 21979: loss: 0.074664, loss_s1: 0.065300, loss_fp: 0.008010, loss_freq: 0.046314
[18:28:42.231] iteration 21980: loss: 0.076456, loss_s1: 0.044545, loss_fp: 0.002366, loss_freq: 0.071567
[18:28:42.852] iteration 21981: loss: 0.041518, loss_s1: 0.032820, loss_fp: 0.005930, loss_freq: 0.015251
[18:28:43.476] iteration 21982: loss: 0.059607, loss_s1: 0.037785, loss_fp: 0.005098, loss_freq: 0.015997
[18:28:44.132] iteration 21983: loss: 0.040517, loss_s1: 0.023785, loss_fp: 0.005590, loss_freq: 0.008806
[18:28:44.773] iteration 21984: loss: 0.058249, loss_s1: 0.043556, loss_fp: 0.012121, loss_freq: 0.025700
[18:28:45.397] iteration 21985: loss: 0.074287, loss_s1: 0.044696, loss_fp: 0.002754, loss_freq: 0.068975
[18:28:46.019] iteration 21986: loss: 0.054363, loss_s1: 0.038174, loss_fp: 0.009157, loss_freq: 0.033910
[18:28:46.646] iteration 21987: loss: 0.060357, loss_s1: 0.033695, loss_fp: 0.002133, loss_freq: 0.041406
[18:28:47.301] iteration 21988: loss: 0.057905, loss_s1: 0.046196, loss_fp: 0.001884, loss_freq: 0.020733
[18:28:47.964] iteration 21989: loss: 0.069156, loss_s1: 0.032337, loss_fp: 0.000725, loss_freq: 0.026546
[18:28:48.630] iteration 21990: loss: 0.034838, loss_s1: 0.030791, loss_fp: 0.003480, loss_freq: 0.008776
[18:28:49.293] iteration 21991: loss: 0.063822, loss_s1: 0.058467, loss_fp: 0.004023, loss_freq: 0.035697
[18:28:49.952] iteration 21992: loss: 0.039391, loss_s1: 0.021812, loss_fp: 0.001429, loss_freq: 0.028871
[18:28:50.584] iteration 21993: loss: 0.046143, loss_s1: 0.028004, loss_fp: 0.000627, loss_freq: 0.020428
[18:28:51.214] iteration 21994: loss: 0.049522, loss_s1: 0.022249, loss_fp: 0.001614, loss_freq: 0.039435
[18:28:51.848] iteration 21995: loss: 0.023097, loss_s1: 0.006438, loss_fp: 0.000169, loss_freq: 0.008195
[18:28:52.477] iteration 21996: loss: 0.054661, loss_s1: 0.047541, loss_fp: 0.007253, loss_freq: 0.022734
[18:28:53.109] iteration 21997: loss: 0.041394, loss_s1: 0.035346, loss_fp: 0.005914, loss_freq: 0.011774
[18:28:53.732] iteration 21998: loss: 0.048741, loss_s1: 0.024926, loss_fp: 0.003973, loss_freq: 0.024788
[18:28:54.360] iteration 21999: loss: 0.105116, loss_s1: 0.124686, loss_fp: 0.003168, loss_freq: 0.037146
[18:28:54.988] iteration 22000: loss: 0.039433, loss_s1: 0.023436, loss_fp: 0.002049, loss_freq: 0.023300
[18:28:58.204] iteration 22000 : mean_dice : 0.734107
[18:28:58.855] iteration 22001: loss: 0.044418, loss_s1: 0.015260, loss_fp: 0.005358, loss_freq: 0.017369
[18:28:59.483] iteration 22002: loss: 0.043284, loss_s1: 0.018240, loss_fp: 0.003413, loss_freq: 0.030541
[18:29:00.114] iteration 22003: loss: 0.030927, loss_s1: 0.017369, loss_fp: 0.000132, loss_freq: 0.004241
[18:29:00.739] iteration 22004: loss: 0.069517, loss_s1: 0.066184, loss_fp: 0.000612, loss_freq: 0.016389
[18:29:01.364] iteration 22005: loss: 0.113054, loss_s1: 0.057286, loss_fp: 0.006061, loss_freq: 0.113958
[18:29:01.986] iteration 22006: loss: 0.050536, loss_s1: 0.030621, loss_fp: 0.007491, loss_freq: 0.029618
[18:29:02.617] iteration 22007: loss: 0.043001, loss_s1: 0.014068, loss_fp: 0.005565, loss_freq: 0.022802
[18:29:03.234] iteration 22008: loss: 0.057108, loss_s1: 0.022141, loss_fp: 0.010437, loss_freq: 0.046810
[18:29:03.862] iteration 22009: loss: 0.043724, loss_s1: 0.022974, loss_fp: 0.009194, loss_freq: 0.008879
[18:29:04.493] iteration 22010: loss: 0.065683, loss_s1: 0.064777, loss_fp: 0.000492, loss_freq: 0.042419
[18:29:05.123] iteration 22011: loss: 0.033421, loss_s1: 0.026980, loss_fp: 0.000571, loss_freq: 0.001905
[18:29:05.749] iteration 22012: loss: 0.055552, loss_s1: 0.041335, loss_fp: 0.002522, loss_freq: 0.034504
[18:29:06.372] iteration 22013: loss: 0.039779, loss_s1: 0.043021, loss_fp: 0.003108, loss_freq: 0.005677
[18:29:07.000] iteration 22014: loss: 0.053225, loss_s1: 0.055676, loss_fp: 0.001302, loss_freq: 0.016294
[18:29:07.627] iteration 22015: loss: 0.045651, loss_s1: 0.030950, loss_fp: 0.005626, loss_freq: 0.020640
[18:29:08.246] iteration 22016: loss: 0.076843, loss_s1: 0.052357, loss_fp: 0.002818, loss_freq: 0.058875
[18:29:08.966] iteration 22017: loss: 0.062816, loss_s1: 0.072720, loss_fp: 0.001772, loss_freq: 0.017997
[18:29:09.601] iteration 22018: loss: 0.061292, loss_s1: 0.022216, loss_fp: 0.000930, loss_freq: 0.063347
[18:29:10.244] iteration 22019: loss: 0.065814, loss_s1: 0.075424, loss_fp: 0.012546, loss_freq: 0.013143
[18:29:10.881] iteration 22020: loss: 0.072708, loss_s1: 0.034442, loss_fp: 0.001171, loss_freq: 0.078101
[18:29:11.506] iteration 22021: loss: 0.064741, loss_s1: 0.027243, loss_fp: 0.002558, loss_freq: 0.031306
[18:29:12.137] iteration 22022: loss: 0.059519, loss_s1: 0.034697, loss_fp: 0.001342, loss_freq: 0.029918
[18:29:12.760] iteration 22023: loss: 0.042912, loss_s1: 0.031877, loss_fp: 0.002193, loss_freq: 0.015557
[18:29:13.388] iteration 22024: loss: 0.063411, loss_s1: 0.050200, loss_fp: 0.001051, loss_freq: 0.031895
[18:29:14.018] iteration 22025: loss: 0.056938, loss_s1: 0.039199, loss_fp: 0.003923, loss_freq: 0.032919
[18:29:14.651] iteration 22026: loss: 0.030905, loss_s1: 0.027255, loss_fp: 0.001650, loss_freq: 0.005692
[18:29:15.281] iteration 22027: loss: 0.079896, loss_s1: 0.074804, loss_fp: 0.005394, loss_freq: 0.045636
[18:29:15.915] iteration 22028: loss: 0.061733, loss_s1: 0.074723, loss_fp: 0.000910, loss_freq: 0.014930
[18:29:16.543] iteration 22029: loss: 0.053164, loss_s1: 0.028198, loss_fp: 0.001649, loss_freq: 0.030936
[18:29:17.171] iteration 22030: loss: 0.035127, loss_s1: 0.022262, loss_fp: 0.002911, loss_freq: 0.017155
[18:29:17.856] iteration 22031: loss: 0.056449, loss_s1: 0.051041, loss_fp: 0.003853, loss_freq: 0.025610
[18:29:18.511] iteration 22032: loss: 0.045684, loss_s1: 0.029816, loss_fp: 0.003113, loss_freq: 0.023222
[18:29:19.179] iteration 22033: loss: 0.043022, loss_s1: 0.019359, loss_fp: 0.001685, loss_freq: 0.004625
[18:29:19.847] iteration 22034: loss: 0.029243, loss_s1: 0.014248, loss_fp: 0.003611, loss_freq: 0.014190
[18:29:20.509] iteration 22035: loss: 0.026962, loss_s1: 0.016503, loss_fp: 0.002076, loss_freq: 0.005327
[18:29:21.169] iteration 22036: loss: 0.054496, loss_s1: 0.046544, loss_fp: 0.000826, loss_freq: 0.013642
[18:29:21.828] iteration 22037: loss: 0.065664, loss_s1: 0.054746, loss_fp: 0.002501, loss_freq: 0.045422
[18:29:22.455] iteration 22038: loss: 0.045174, loss_s1: 0.017259, loss_fp: 0.004774, loss_freq: 0.035937
[18:29:23.085] iteration 22039: loss: 0.070538, loss_s1: 0.050571, loss_fp: 0.002595, loss_freq: 0.042932
[18:29:23.710] iteration 22040: loss: 0.056102, loss_s1: 0.043310, loss_fp: 0.008479, loss_freq: 0.020590
[18:29:24.332] iteration 22041: loss: 0.074429, loss_s1: 0.059554, loss_fp: 0.003723, loss_freq: 0.031151
[18:29:24.952] iteration 22042: loss: 0.051628, loss_s1: 0.033856, loss_fp: 0.002877, loss_freq: 0.019710
[18:29:25.583] iteration 22043: loss: 0.055221, loss_s1: 0.042640, loss_fp: 0.004398, loss_freq: 0.034184
[18:29:26.211] iteration 22044: loss: 0.030385, loss_s1: 0.027175, loss_fp: 0.002210, loss_freq: 0.004794
[18:29:26.901] iteration 22045: loss: 0.037045, loss_s1: 0.033189, loss_fp: 0.002250, loss_freq: 0.008725
[18:29:27.571] iteration 22046: loss: 0.059538, loss_s1: 0.027970, loss_fp: 0.006098, loss_freq: 0.044215
[18:29:28.240] iteration 22047: loss: 0.062739, loss_s1: 0.043197, loss_fp: 0.001635, loss_freq: 0.021680
[18:29:28.908] iteration 22048: loss: 0.100226, loss_s1: 0.116669, loss_fp: 0.002964, loss_freq: 0.047851
[18:29:29.542] iteration 22049: loss: 0.053780, loss_s1: 0.047539, loss_fp: 0.002531, loss_freq: 0.022134
[18:29:30.171] iteration 22050: loss: 0.068194, loss_s1: 0.030810, loss_fp: 0.011154, loss_freq: 0.054692
[18:29:30.798] iteration 22051: loss: 0.028494, loss_s1: 0.017402, loss_fp: 0.003120, loss_freq: 0.006139
[18:29:31.462] iteration 22052: loss: 0.060902, loss_s1: 0.048307, loss_fp: 0.000882, loss_freq: 0.013997
[18:29:32.125] iteration 22053: loss: 0.041886, loss_s1: 0.038867, loss_fp: 0.000543, loss_freq: 0.007605
[18:29:32.783] iteration 22054: loss: 0.044996, loss_s1: 0.026986, loss_fp: 0.004754, loss_freq: 0.026367
[18:29:33.433] iteration 22055: loss: 0.081979, loss_s1: 0.076967, loss_fp: 0.011270, loss_freq: 0.042339
[18:29:34.057] iteration 22056: loss: 0.037044, loss_s1: 0.020853, loss_fp: 0.003355, loss_freq: 0.017302
[18:29:34.682] iteration 22057: loss: 0.063727, loss_s1: 0.037841, loss_fp: 0.000563, loss_freq: 0.050274
[18:29:35.638] iteration 22058: loss: 0.031642, loss_s1: 0.023180, loss_fp: 0.001690, loss_freq: 0.009011
[18:29:36.267] iteration 22059: loss: 0.047343, loss_s1: 0.041412, loss_fp: 0.000567, loss_freq: 0.020761
[18:29:36.897] iteration 22060: loss: 0.041182, loss_s1: 0.031552, loss_fp: 0.001168, loss_freq: 0.013663
[18:29:37.521] iteration 22061: loss: 0.035621, loss_s1: 0.008851, loss_fp: 0.000442, loss_freq: 0.016410
[18:29:38.144] iteration 22062: loss: 0.051441, loss_s1: 0.052363, loss_fp: 0.004229, loss_freq: 0.015634
[18:29:38.776] iteration 22063: loss: 0.084065, loss_s1: 0.091674, loss_fp: 0.001283, loss_freq: 0.028106
[18:29:39.405] iteration 22064: loss: 0.037485, loss_s1: 0.031100, loss_fp: 0.000772, loss_freq: 0.015098
[18:29:40.039] iteration 22065: loss: 0.032062, loss_s1: 0.014945, loss_fp: 0.002605, loss_freq: 0.013383
[18:29:40.667] iteration 22066: loss: 0.057482, loss_s1: 0.040971, loss_fp: 0.011792, loss_freq: 0.032885
[18:29:41.288] iteration 22067: loss: 0.049918, loss_s1: 0.038648, loss_fp: 0.008332, loss_freq: 0.011998
[18:29:41.920] iteration 22068: loss: 0.035011, loss_s1: 0.015515, loss_fp: 0.001882, loss_freq: 0.014499
[18:29:42.567] iteration 22069: loss: 0.032496, loss_s1: 0.017835, loss_fp: 0.004507, loss_freq: 0.013095
[18:29:43.242] iteration 22070: loss: 0.074009, loss_s1: 0.047700, loss_fp: 0.007334, loss_freq: 0.065129
[18:29:43.909] iteration 22071: loss: 0.060906, loss_s1: 0.043482, loss_fp: 0.003641, loss_freq: 0.029839
[18:29:44.563] iteration 22072: loss: 0.060500, loss_s1: 0.041080, loss_fp: 0.005133, loss_freq: 0.045375
[18:29:45.199] iteration 22073: loss: 0.075208, loss_s1: 0.048979, loss_fp: 0.008958, loss_freq: 0.062738
[18:29:45.819] iteration 22074: loss: 0.048766, loss_s1: 0.035790, loss_fp: 0.002997, loss_freq: 0.009270
[18:29:46.440] iteration 22075: loss: 0.055306, loss_s1: 0.040489, loss_fp: 0.007393, loss_freq: 0.029829
[18:29:47.075] iteration 22076: loss: 0.034877, loss_s1: 0.017501, loss_fp: 0.000689, loss_freq: 0.012177
[18:29:47.705] iteration 22077: loss: 0.052643, loss_s1: 0.032136, loss_fp: 0.013299, loss_freq: 0.013261
[18:29:48.339] iteration 22078: loss: 0.033277, loss_s1: 0.014609, loss_fp: 0.001434, loss_freq: 0.007384
[18:29:48.992] iteration 22079: loss: 0.041462, loss_s1: 0.028735, loss_fp: 0.001511, loss_freq: 0.012911
[18:29:49.626] iteration 22080: loss: 0.059940, loss_s1: 0.021491, loss_fp: 0.002559, loss_freq: 0.042623
[18:29:50.254] iteration 22081: loss: 0.092901, loss_s1: 0.047040, loss_fp: 0.003233, loss_freq: 0.107656
[18:29:50.882] iteration 22082: loss: 0.056377, loss_s1: 0.042650, loss_fp: 0.004218, loss_freq: 0.031453
[18:29:51.526] iteration 22083: loss: 0.085628, loss_s1: 0.059401, loss_fp: 0.001450, loss_freq: 0.080846
[18:29:52.150] iteration 22084: loss: 0.030133, loss_s1: 0.019383, loss_fp: 0.000383, loss_freq: 0.009081
[18:29:52.782] iteration 22085: loss: 0.081132, loss_s1: 0.055765, loss_fp: 0.020877, loss_freq: 0.047265
[18:29:53.424] iteration 22086: loss: 0.038686, loss_s1: 0.013351, loss_fp: 0.011476, loss_freq: 0.021690
[18:29:54.075] iteration 22087: loss: 0.042720, loss_s1: 0.036959, loss_fp: 0.003263, loss_freq: 0.003825
[18:29:54.700] iteration 22088: loss: 0.056210, loss_s1: 0.064981, loss_fp: 0.001703, loss_freq: 0.013639
[18:29:55.339] iteration 22089: loss: 0.064509, loss_s1: 0.050225, loss_fp: 0.008757, loss_freq: 0.024304
[18:29:55.959] iteration 22090: loss: 0.040981, loss_s1: 0.028532, loss_fp: 0.002968, loss_freq: 0.017393
[18:29:56.587] iteration 22091: loss: 0.026568, loss_s1: 0.018007, loss_fp: 0.001163, loss_freq: 0.004875
[18:29:57.213] iteration 22092: loss: 0.063391, loss_s1: 0.050418, loss_fp: 0.003381, loss_freq: 0.026587
[18:29:57.846] iteration 22093: loss: 0.051596, loss_s1: 0.039409, loss_fp: 0.003340, loss_freq: 0.028437
[18:29:58.475] iteration 22094: loss: 0.054755, loss_s1: 0.044583, loss_fp: 0.000445, loss_freq: 0.022606
[18:29:59.104] iteration 22095: loss: 0.063813, loss_s1: 0.064189, loss_fp: 0.001322, loss_freq: 0.029262
[18:29:59.732] iteration 22096: loss: 0.097722, loss_s1: 0.104854, loss_fp: 0.013591, loss_freq: 0.035238
[18:30:00.361] iteration 22097: loss: 0.074394, loss_s1: 0.077718, loss_fp: 0.003910, loss_freq: 0.032364
[18:30:00.990] iteration 22098: loss: 0.049886, loss_s1: 0.025067, loss_fp: 0.017184, loss_freq: 0.019199
[18:30:01.612] iteration 22099: loss: 0.094864, loss_s1: 0.110103, loss_fp: 0.003008, loss_freq: 0.049338
[18:30:02.234] iteration 22100: loss: 0.074869, loss_s1: 0.061068, loss_fp: 0.002770, loss_freq: 0.057551
[18:30:02.869] iteration 22101: loss: 0.082242, loss_s1: 0.082921, loss_fp: 0.006432, loss_freq: 0.045371
[18:30:03.493] iteration 22102: loss: 0.052079, loss_s1: 0.027838, loss_fp: 0.007560, loss_freq: 0.027453
[18:30:04.117] iteration 22103: loss: 0.051809, loss_s1: 0.040269, loss_fp: 0.004500, loss_freq: 0.005640
[18:30:04.745] iteration 22104: loss: 0.020889, loss_s1: 0.011262, loss_fp: 0.000505, loss_freq: 0.003677
[18:30:05.375] iteration 22105: loss: 0.058000, loss_s1: 0.048377, loss_fp: 0.007564, loss_freq: 0.028340
[18:30:05.998] iteration 22106: loss: 0.060798, loss_s1: 0.063288, loss_fp: 0.001949, loss_freq: 0.012608
[18:30:06.625] iteration 22107: loss: 0.049525, loss_s1: 0.046763, loss_fp: 0.004702, loss_freq: 0.020556
[18:30:07.253] iteration 22108: loss: 0.078277, loss_s1: 0.068924, loss_fp: 0.008242, loss_freq: 0.045531
[18:30:07.872] iteration 22109: loss: 0.054601, loss_s1: 0.031710, loss_fp: 0.002765, loss_freq: 0.037838
[18:30:08.499] iteration 22110: loss: 0.054962, loss_s1: 0.030973, loss_fp: 0.002453, loss_freq: 0.042457
[18:30:09.185] iteration 22111: loss: 0.046158, loss_s1: 0.022900, loss_fp: 0.001237, loss_freq: 0.037211
[18:30:09.844] iteration 22112: loss: 0.036532, loss_s1: 0.022020, loss_fp: 0.003219, loss_freq: 0.011265
[18:30:10.505] iteration 22113: loss: 0.075683, loss_s1: 0.074707, loss_fp: 0.002653, loss_freq: 0.022009
[18:30:11.168] iteration 22114: loss: 0.038388, loss_s1: 0.021298, loss_fp: 0.000602, loss_freq: 0.014795
[18:30:11.798] iteration 22115: loss: 0.051942, loss_s1: 0.029366, loss_fp: 0.000663, loss_freq: 0.013538
[18:30:12.432] iteration 22116: loss: 0.027437, loss_s1: 0.012670, loss_fp: 0.006827, loss_freq: 0.004099
[18:30:13.055] iteration 22117: loss: 0.049778, loss_s1: 0.035387, loss_fp: 0.004792, loss_freq: 0.026969
[18:30:13.685] iteration 22118: loss: 0.068066, loss_s1: 0.020970, loss_fp: 0.000655, loss_freq: 0.016245
[18:30:14.320] iteration 22119: loss: 0.036559, loss_s1: 0.026639, loss_fp: 0.001600, loss_freq: 0.009487
[18:30:14.951] iteration 22120: loss: 0.030343, loss_s1: 0.016313, loss_fp: 0.000395, loss_freq: 0.006713
[18:30:15.579] iteration 22121: loss: 0.046654, loss_s1: 0.021208, loss_fp: 0.003764, loss_freq: 0.025980
[18:30:16.221] iteration 22122: loss: 0.038234, loss_s1: 0.023740, loss_fp: 0.000243, loss_freq: 0.018185
[18:30:16.879] iteration 22123: loss: 0.055137, loss_s1: 0.023668, loss_fp: 0.010739, loss_freq: 0.048962
[18:30:17.523] iteration 22124: loss: 0.060106, loss_s1: 0.031206, loss_fp: 0.002528, loss_freq: 0.030421
[18:30:18.161] iteration 22125: loss: 0.059939, loss_s1: 0.056090, loss_fp: 0.002945, loss_freq: 0.031104
[18:30:18.798] iteration 22126: loss: 0.058369, loss_s1: 0.060934, loss_fp: 0.002694, loss_freq: 0.024311
[18:30:19.432] iteration 22127: loss: 0.060758, loss_s1: 0.045726, loss_fp: 0.001784, loss_freq: 0.024406
[18:30:20.059] iteration 22128: loss: 0.052204, loss_s1: 0.051145, loss_fp: 0.002805, loss_freq: 0.022650
[18:30:20.689] iteration 22129: loss: 0.060482, loss_s1: 0.059941, loss_fp: 0.005982, loss_freq: 0.021836
[18:30:21.316] iteration 22130: loss: 0.053488, loss_s1: 0.043483, loss_fp: 0.006612, loss_freq: 0.008803
[18:30:21.948] iteration 22131: loss: 0.037891, loss_s1: 0.020923, loss_fp: 0.004393, loss_freq: 0.012313
[18:30:22.580] iteration 22132: loss: 0.052319, loss_s1: 0.039733, loss_fp: 0.001946, loss_freq: 0.018791
[18:30:23.209] iteration 22133: loss: 0.077789, loss_s1: 0.102919, loss_fp: 0.000728, loss_freq: 0.009507
[18:30:23.839] iteration 22134: loss: 0.084000, loss_s1: 0.078544, loss_fp: 0.000983, loss_freq: 0.060619
[18:30:24.479] iteration 22135: loss: 0.041947, loss_s1: 0.040188, loss_fp: 0.001686, loss_freq: 0.011325
[18:30:25.111] iteration 22136: loss: 0.043240, loss_s1: 0.045236, loss_fp: 0.005885, loss_freq: 0.004161
[18:30:25.734] iteration 22137: loss: 0.053589, loss_s1: 0.035941, loss_fp: 0.001280, loss_freq: 0.029794
[18:30:26.366] iteration 22138: loss: 0.066635, loss_s1: 0.052275, loss_fp: 0.002103, loss_freq: 0.027245
[18:30:26.995] iteration 22139: loss: 0.072608, loss_s1: 0.068521, loss_fp: 0.002647, loss_freq: 0.039529
[18:30:27.624] iteration 22140: loss: 0.034157, loss_s1: 0.018019, loss_fp: 0.002637, loss_freq: 0.012229
[18:30:28.265] iteration 22141: loss: 0.065849, loss_s1: 0.058251, loss_fp: 0.008663, loss_freq: 0.017967
[18:30:28.910] iteration 22142: loss: 0.088651, loss_s1: 0.086476, loss_fp: 0.004952, loss_freq: 0.057196
[18:30:29.553] iteration 22143: loss: 0.041630, loss_s1: 0.030677, loss_fp: 0.001745, loss_freq: 0.015313
[18:30:30.199] iteration 22144: loss: 0.054079, loss_s1: 0.029883, loss_fp: 0.000944, loss_freq: 0.010387
[18:30:30.841] iteration 22145: loss: 0.040108, loss_s1: 0.032198, loss_fp: 0.001933, loss_freq: 0.012571
[18:30:31.488] iteration 22146: loss: 0.058808, loss_s1: 0.054687, loss_fp: 0.003690, loss_freq: 0.025242
[18:30:32.119] iteration 22147: loss: 0.054255, loss_s1: 0.037655, loss_fp: 0.000949, loss_freq: 0.039680
[18:30:32.746] iteration 22148: loss: 0.062545, loss_s1: 0.041232, loss_fp: 0.004130, loss_freq: 0.034425
[18:30:33.377] iteration 22149: loss: 0.044503, loss_s1: 0.032415, loss_fp: 0.001917, loss_freq: 0.023085
[18:30:34.002] iteration 22150: loss: 0.039998, loss_s1: 0.021374, loss_fp: 0.000709, loss_freq: 0.014824
[18:30:34.635] iteration 22151: loss: 0.033589, loss_s1: 0.023065, loss_fp: 0.002602, loss_freq: 0.013621
[18:30:35.266] iteration 22152: loss: 0.062958, loss_s1: 0.067189, loss_fp: 0.001277, loss_freq: 0.031967
[18:30:35.888] iteration 22153: loss: 0.055139, loss_s1: 0.043742, loss_fp: 0.004669, loss_freq: 0.035837
[18:30:36.518] iteration 22154: loss: 0.030864, loss_s1: 0.010162, loss_fp: 0.001177, loss_freq: 0.017176
[18:30:37.144] iteration 22155: loss: 0.043311, loss_s1: 0.013499, loss_fp: 0.001262, loss_freq: 0.028800
[18:30:37.775] iteration 22156: loss: 0.060627, loss_s1: 0.070147, loss_fp: 0.002159, loss_freq: 0.017203
[18:30:38.405] iteration 22157: loss: 0.045216, loss_s1: 0.040994, loss_fp: 0.002076, loss_freq: 0.014021
[18:30:39.036] iteration 22158: loss: 0.045552, loss_s1: 0.045432, loss_fp: 0.003632, loss_freq: 0.019005
[18:30:39.660] iteration 22159: loss: 0.080578, loss_s1: 0.048948, loss_fp: 0.005142, loss_freq: 0.073025
[18:30:40.294] iteration 22160: loss: 0.049854, loss_s1: 0.040324, loss_fp: 0.006997, loss_freq: 0.021487
[18:30:40.972] iteration 22161: loss: 0.050354, loss_s1: 0.055700, loss_fp: 0.002663, loss_freq: 0.015014
[18:30:41.643] iteration 22162: loss: 0.061170, loss_s1: 0.056682, loss_fp: 0.001124, loss_freq: 0.011829
[18:30:42.288] iteration 22163: loss: 0.060952, loss_s1: 0.040562, loss_fp: 0.003840, loss_freq: 0.034347
[18:30:42.950] iteration 22164: loss: 0.033682, loss_s1: 0.015908, loss_fp: 0.001784, loss_freq: 0.017532
[18:30:43.580] iteration 22165: loss: 0.076845, loss_s1: 0.073869, loss_fp: 0.005942, loss_freq: 0.040004
[18:30:44.212] iteration 22166: loss: 0.096732, loss_s1: 0.082037, loss_fp: 0.009831, loss_freq: 0.064222
[18:30:44.840] iteration 22167: loss: 0.086004, loss_s1: 0.076105, loss_fp: 0.000968, loss_freq: 0.051476
[18:30:45.475] iteration 22168: loss: 0.059724, loss_s1: 0.055463, loss_fp: 0.000984, loss_freq: 0.021558
[18:30:46.109] iteration 22169: loss: 0.048313, loss_s1: 0.018645, loss_fp: 0.001071, loss_freq: 0.039750
[18:30:46.741] iteration 22170: loss: 0.053057, loss_s1: 0.053713, loss_fp: 0.004233, loss_freq: 0.012916
[18:30:47.377] iteration 22171: loss: 0.049880, loss_s1: 0.021781, loss_fp: 0.004914, loss_freq: 0.045194
[18:30:48.005] iteration 22172: loss: 0.037326, loss_s1: 0.027752, loss_fp: 0.000725, loss_freq: 0.008339
[18:30:48.639] iteration 22173: loss: 0.062436, loss_s1: 0.076695, loss_fp: 0.003196, loss_freq: 0.013968
[18:30:49.282] iteration 22174: loss: 0.053794, loss_s1: 0.056999, loss_fp: 0.001622, loss_freq: 0.018222
[18:30:49.926] iteration 22175: loss: 0.035273, loss_s1: 0.027160, loss_fp: 0.004120, loss_freq: 0.010429
[18:30:50.576] iteration 22176: loss: 0.073146, loss_s1: 0.067240, loss_fp: 0.007305, loss_freq: 0.028151
[18:30:51.221] iteration 22177: loss: 0.060081, loss_s1: 0.040766, loss_fp: 0.002110, loss_freq: 0.047452
[18:30:51.857] iteration 22178: loss: 0.046085, loss_s1: 0.052422, loss_fp: 0.007840, loss_freq: 0.004802
[18:30:52.491] iteration 22179: loss: 0.054773, loss_s1: 0.027792, loss_fp: 0.006346, loss_freq: 0.031330
[18:30:53.122] iteration 22180: loss: 0.065510, loss_s1: 0.072617, loss_fp: 0.000770, loss_freq: 0.021874
[18:30:53.756] iteration 22181: loss: 0.061706, loss_s1: 0.031566, loss_fp: 0.003011, loss_freq: 0.009733
[18:30:54.384] iteration 22182: loss: 0.043922, loss_s1: 0.020506, loss_fp: 0.003009, loss_freq: 0.030270
[18:30:55.013] iteration 22183: loss: 0.074121, loss_s1: 0.087484, loss_fp: 0.005978, loss_freq: 0.015472
[18:30:55.648] iteration 22184: loss: 0.054787, loss_s1: 0.062938, loss_fp: 0.001177, loss_freq: 0.008699
[18:30:56.278] iteration 22185: loss: 0.073747, loss_s1: 0.073093, loss_fp: 0.003735, loss_freq: 0.018977
[18:30:56.907] iteration 22186: loss: 0.042719, loss_s1: 0.035073, loss_fp: 0.002709, loss_freq: 0.019290
[18:30:57.535] iteration 22187: loss: 0.059702, loss_s1: 0.073635, loss_fp: 0.001357, loss_freq: 0.014044
[18:30:58.161] iteration 22188: loss: 0.048152, loss_s1: 0.039258, loss_fp: 0.001505, loss_freq: 0.018619
[18:30:58.791] iteration 22189: loss: 0.050454, loss_s1: 0.053172, loss_fp: 0.000964, loss_freq: 0.014204
[18:30:59.421] iteration 22190: loss: 0.066588, loss_s1: 0.042310, loss_fp: 0.004782, loss_freq: 0.014342
[18:31:00.085] iteration 22191: loss: 0.046348, loss_s1: 0.045745, loss_fp: 0.002332, loss_freq: 0.012335
[18:31:00.723] iteration 22192: loss: 0.041471, loss_s1: 0.016008, loss_fp: 0.001244, loss_freq: 0.022023
[18:31:01.371] iteration 22193: loss: 0.049812, loss_s1: 0.031091, loss_fp: 0.006891, loss_freq: 0.023433
[18:31:02.011] iteration 22194: loss: 0.031707, loss_s1: 0.014099, loss_fp: 0.001259, loss_freq: 0.010049
[18:31:02.648] iteration 22195: loss: 0.043694, loss_s1: 0.033767, loss_fp: 0.007402, loss_freq: 0.021484
[18:31:03.280] iteration 22196: loss: 0.050812, loss_s1: 0.042808, loss_fp: 0.001945, loss_freq: 0.025979
[18:31:03.918] iteration 22197: loss: 0.063487, loss_s1: 0.048164, loss_fp: 0.004694, loss_freq: 0.026453
[18:31:04.563] iteration 22198: loss: 0.060870, loss_s1: 0.063714, loss_fp: 0.001886, loss_freq: 0.028914
[18:31:05.199] iteration 22199: loss: 0.045400, loss_s1: 0.037369, loss_fp: 0.000816, loss_freq: 0.015097
[18:31:05.829] iteration 22200: loss: 0.063428, loss_s1: 0.056858, loss_fp: 0.008025, loss_freq: 0.029825
[18:31:09.053] iteration 22200 : mean_dice : 0.734190
[18:31:09.694] iteration 22201: loss: 0.048190, loss_s1: 0.031304, loss_fp: 0.005565, loss_freq: 0.018156
[18:31:10.326] iteration 22202: loss: 0.034715, loss_s1: 0.015316, loss_fp: 0.003819, loss_freq: 0.014388
[18:31:10.951] iteration 22203: loss: 0.062893, loss_s1: 0.057836, loss_fp: 0.010230, loss_freq: 0.010132
[18:31:11.575] iteration 22204: loss: 0.087814, loss_s1: 0.075271, loss_fp: 0.006745, loss_freq: 0.058112
[18:31:12.257] iteration 22205: loss: 0.044160, loss_s1: 0.046024, loss_fp: 0.001413, loss_freq: 0.008225
[18:31:12.954] iteration 22206: loss: 0.030747, loss_s1: 0.012709, loss_fp: 0.010384, loss_freq: 0.012356
[18:31:13.619] iteration 22207: loss: 0.064130, loss_s1: 0.038985, loss_fp: 0.001732, loss_freq: 0.050036
[18:31:14.277] iteration 22208: loss: 0.048365, loss_s1: 0.031403, loss_fp: 0.004422, loss_freq: 0.019888
[18:31:14.915] iteration 22209: loss: 0.092211, loss_s1: 0.082932, loss_fp: 0.004115, loss_freq: 0.061554
[18:31:15.544] iteration 22210: loss: 0.044683, loss_s1: 0.036122, loss_fp: 0.002610, loss_freq: 0.020504
[18:31:16.169] iteration 22211: loss: 0.060470, loss_s1: 0.039130, loss_fp: 0.005128, loss_freq: 0.033629
[18:31:16.792] iteration 22212: loss: 0.029608, loss_s1: 0.022210, loss_fp: 0.003131, loss_freq: 0.006967
[18:31:17.420] iteration 22213: loss: 0.050422, loss_s1: 0.039949, loss_fp: 0.001013, loss_freq: 0.017752
[18:31:18.044] iteration 22214: loss: 0.048251, loss_s1: 0.030895, loss_fp: 0.002116, loss_freq: 0.014350
[18:31:18.668] iteration 22215: loss: 0.086137, loss_s1: 0.066087, loss_fp: 0.011726, loss_freq: 0.046739
[18:31:19.293] iteration 22216: loss: 0.045381, loss_s1: 0.037688, loss_fp: 0.000949, loss_freq: 0.017512
[18:31:19.914] iteration 22217: loss: 0.064260, loss_s1: 0.055192, loss_fp: 0.007618, loss_freq: 0.028637
[18:31:20.541] iteration 22218: loss: 0.062196, loss_s1: 0.027446, loss_fp: 0.009827, loss_freq: 0.016896
[18:31:21.502] iteration 22219: loss: 0.026659, loss_s1: 0.009670, loss_fp: 0.001791, loss_freq: 0.010922
[18:31:22.156] iteration 22220: loss: 0.058180, loss_s1: 0.046303, loss_fp: 0.005620, loss_freq: 0.028756
[18:31:22.790] iteration 22221: loss: 0.040566, loss_s1: 0.035791, loss_fp: 0.001924, loss_freq: 0.013608
[18:31:23.430] iteration 22222: loss: 0.037998, loss_s1: 0.023428, loss_fp: 0.001586, loss_freq: 0.009056
[18:31:24.060] iteration 22223: loss: 0.062389, loss_s1: 0.074468, loss_fp: 0.001856, loss_freq: 0.006083
[18:31:24.688] iteration 22224: loss: 0.074042, loss_s1: 0.046552, loss_fp: 0.014420, loss_freq: 0.032735
[18:31:25.315] iteration 22225: loss: 0.054388, loss_s1: 0.043736, loss_fp: 0.004175, loss_freq: 0.028093
[18:31:25.940] iteration 22226: loss: 0.029653, loss_s1: 0.015734, loss_fp: 0.001222, loss_freq: 0.009941
[18:31:26.565] iteration 22227: loss: 0.049171, loss_s1: 0.036864, loss_fp: 0.004305, loss_freq: 0.022395
[18:31:27.188] iteration 22228: loss: 0.108318, loss_s1: 0.110477, loss_fp: 0.019124, loss_freq: 0.042978
[18:31:27.811] iteration 22229: loss: 0.040510, loss_s1: 0.023278, loss_fp: 0.005003, loss_freq: 0.010394
[18:31:28.446] iteration 22230: loss: 0.045977, loss_s1: 0.049347, loss_fp: 0.001368, loss_freq: 0.006266
[18:31:29.075] iteration 22231: loss: 0.090084, loss_s1: 0.062138, loss_fp: 0.008536, loss_freq: 0.079243
[18:31:29.712] iteration 22232: loss: 0.073042, loss_s1: 0.074819, loss_fp: 0.002693, loss_freq: 0.027772
[18:31:30.345] iteration 22233: loss: 0.044937, loss_s1: 0.032567, loss_fp: 0.001714, loss_freq: 0.025709
[18:31:30.981] iteration 22234: loss: 0.115925, loss_s1: 0.103413, loss_fp: 0.011391, loss_freq: 0.086378
[18:31:31.606] iteration 22235: loss: 0.060067, loss_s1: 0.054440, loss_fp: 0.002001, loss_freq: 0.019365
[18:31:32.234] iteration 22236: loss: 0.074941, loss_s1: 0.064114, loss_fp: 0.019215, loss_freq: 0.026790
[18:31:32.870] iteration 22237: loss: 0.050841, loss_s1: 0.031327, loss_fp: 0.002272, loss_freq: 0.031965
[18:31:33.494] iteration 22238: loss: 0.051473, loss_s1: 0.032323, loss_fp: 0.008598, loss_freq: 0.025274
[18:31:34.121] iteration 22239: loss: 0.039082, loss_s1: 0.036995, loss_fp: 0.001051, loss_freq: 0.004500
[18:31:34.749] iteration 22240: loss: 0.041001, loss_s1: 0.032556, loss_fp: 0.003704, loss_freq: 0.011173
[18:31:35.374] iteration 22241: loss: 0.047583, loss_s1: 0.021720, loss_fp: 0.004560, loss_freq: 0.020308
[18:31:35.998] iteration 22242: loss: 0.082040, loss_s1: 0.073364, loss_fp: 0.001930, loss_freq: 0.057557
[18:31:36.627] iteration 22243: loss: 0.064444, loss_s1: 0.072804, loss_fp: 0.001781, loss_freq: 0.027752
[18:31:37.250] iteration 22244: loss: 0.063981, loss_s1: 0.058949, loss_fp: 0.004703, loss_freq: 0.035995
[18:31:37.879] iteration 22245: loss: 0.034355, loss_s1: 0.033798, loss_fp: 0.000491, loss_freq: 0.002978
[18:31:38.507] iteration 22246: loss: 0.062159, loss_s1: 0.035566, loss_fp: 0.018236, loss_freq: 0.029132
[18:31:39.138] iteration 22247: loss: 0.085146, loss_s1: 0.044715, loss_fp: 0.002408, loss_freq: 0.066938
[18:31:39.761] iteration 22248: loss: 0.042249, loss_s1: 0.020276, loss_fp: 0.001360, loss_freq: 0.015808
[18:31:40.386] iteration 22249: loss: 0.053515, loss_s1: 0.043265, loss_fp: 0.001937, loss_freq: 0.023059
[18:31:41.016] iteration 22250: loss: 0.055964, loss_s1: 0.026646, loss_fp: 0.008975, loss_freq: 0.012836
[18:31:41.645] iteration 22251: loss: 0.044924, loss_s1: 0.021572, loss_fp: 0.003139, loss_freq: 0.028532
[18:31:42.279] iteration 22252: loss: 0.036490, loss_s1: 0.020371, loss_fp: 0.005651, loss_freq: 0.007487
[18:31:42.903] iteration 22253: loss: 0.082602, loss_s1: 0.072447, loss_fp: 0.002295, loss_freq: 0.023662
[18:31:43.534] iteration 22254: loss: 0.045036, loss_s1: 0.027138, loss_fp: 0.008826, loss_freq: 0.025417
[18:31:44.158] iteration 22255: loss: 0.085024, loss_s1: 0.096539, loss_fp: 0.005967, loss_freq: 0.036683
[18:31:44.785] iteration 22256: loss: 0.048100, loss_s1: 0.023537, loss_fp: 0.003086, loss_freq: 0.027804
[18:31:45.413] iteration 22257: loss: 0.102622, loss_s1: 0.081418, loss_fp: 0.003431, loss_freq: 0.075952
[18:31:46.041] iteration 22258: loss: 0.048789, loss_s1: 0.032842, loss_fp: 0.000973, loss_freq: 0.019622
[18:31:46.667] iteration 22259: loss: 0.047758, loss_s1: 0.031514, loss_fp: 0.004823, loss_freq: 0.018019
[18:31:47.296] iteration 22260: loss: 0.070781, loss_s1: 0.050699, loss_fp: 0.012063, loss_freq: 0.043767
[18:31:47.926] iteration 22261: loss: 0.041653, loss_s1: 0.025090, loss_fp: 0.001574, loss_freq: 0.029771
[18:31:48.551] iteration 22262: loss: 0.045341, loss_s1: 0.018106, loss_fp: 0.001449, loss_freq: 0.039088
[18:31:49.179] iteration 22263: loss: 0.041399, loss_s1: 0.023135, loss_fp: 0.003433, loss_freq: 0.012842
[18:31:49.808] iteration 22264: loss: 0.044717, loss_s1: 0.032793, loss_fp: 0.001045, loss_freq: 0.003020
[18:31:50.432] iteration 22265: loss: 0.027525, loss_s1: 0.013307, loss_fp: 0.002402, loss_freq: 0.007808
[18:31:51.055] iteration 22266: loss: 0.050780, loss_s1: 0.047174, loss_fp: 0.005875, loss_freq: 0.019569
[18:31:51.679] iteration 22267: loss: 0.054709, loss_s1: 0.055786, loss_fp: 0.001607, loss_freq: 0.011162
[18:31:52.304] iteration 22268: loss: 0.059230, loss_s1: 0.045450, loss_fp: 0.002876, loss_freq: 0.043667
[18:31:52.928] iteration 22269: loss: 0.074540, loss_s1: 0.063104, loss_fp: 0.005319, loss_freq: 0.041655
[18:31:53.550] iteration 22270: loss: 0.059410, loss_s1: 0.041689, loss_fp: 0.005735, loss_freq: 0.034393
[18:31:54.185] iteration 22271: loss: 0.046247, loss_s1: 0.033932, loss_fp: 0.005266, loss_freq: 0.024858
[18:31:54.813] iteration 22272: loss: 0.059508, loss_s1: 0.044624, loss_fp: 0.006477, loss_freq: 0.020466
[18:31:55.438] iteration 22273: loss: 0.057667, loss_s1: 0.010131, loss_fp: 0.002870, loss_freq: 0.052785
[18:31:56.061] iteration 22274: loss: 0.050181, loss_s1: 0.047401, loss_fp: 0.003812, loss_freq: 0.015778
[18:31:56.687] iteration 22275: loss: 0.029379, loss_s1: 0.016374, loss_fp: 0.001053, loss_freq: 0.007415
[18:31:57.317] iteration 22276: loss: 0.047279, loss_s1: 0.018053, loss_fp: 0.001906, loss_freq: 0.026408
[18:31:57.942] iteration 22277: loss: 0.047890, loss_s1: 0.040225, loss_fp: 0.006814, loss_freq: 0.015546
[18:31:58.566] iteration 22278: loss: 0.058102, loss_s1: 0.036862, loss_fp: 0.005662, loss_freq: 0.042578
[18:31:59.194] iteration 22279: loss: 0.035330, loss_s1: 0.024719, loss_fp: 0.002646, loss_freq: 0.015114
[18:31:59.822] iteration 22280: loss: 0.043943, loss_s1: 0.024596, loss_fp: 0.012294, loss_freq: 0.020033
[18:32:00.447] iteration 22281: loss: 0.052807, loss_s1: 0.030588, loss_fp: 0.002328, loss_freq: 0.021626
[18:32:01.072] iteration 22282: loss: 0.048059, loss_s1: 0.024427, loss_fp: 0.005729, loss_freq: 0.030324
[18:32:01.700] iteration 22283: loss: 0.053307, loss_s1: 0.061980, loss_fp: 0.000895, loss_freq: 0.007304
[18:32:02.327] iteration 22284: loss: 0.074674, loss_s1: 0.042281, loss_fp: 0.010215, loss_freq: 0.066303
[18:32:02.956] iteration 22285: loss: 0.054898, loss_s1: 0.029431, loss_fp: 0.008493, loss_freq: 0.035259
[18:32:03.589] iteration 22286: loss: 0.074126, loss_s1: 0.065042, loss_fp: 0.013841, loss_freq: 0.038878
[18:32:04.221] iteration 22287: loss: 0.043515, loss_s1: 0.020682, loss_fp: 0.005202, loss_freq: 0.027935
[18:32:04.850] iteration 22288: loss: 0.069274, loss_s1: 0.059826, loss_fp: 0.006574, loss_freq: 0.019862
[18:32:05.480] iteration 22289: loss: 0.050123, loss_s1: 0.034105, loss_fp: 0.005971, loss_freq: 0.025399
[18:32:06.106] iteration 22290: loss: 0.066539, loss_s1: 0.056865, loss_fp: 0.002622, loss_freq: 0.037572
[18:32:06.733] iteration 22291: loss: 0.047802, loss_s1: 0.040720, loss_fp: 0.002682, loss_freq: 0.014876
[18:32:07.359] iteration 22292: loss: 0.048415, loss_s1: 0.038416, loss_fp: 0.001164, loss_freq: 0.011913
[18:32:07.988] iteration 22293: loss: 0.047028, loss_s1: 0.043974, loss_fp: 0.001746, loss_freq: 0.010388
[18:32:08.617] iteration 22294: loss: 0.046210, loss_s1: 0.032352, loss_fp: 0.002040, loss_freq: 0.020499
[18:32:09.243] iteration 22295: loss: 0.044916, loss_s1: 0.037675, loss_fp: 0.002422, loss_freq: 0.015506
[18:32:09.871] iteration 22296: loss: 0.043608, loss_s1: 0.029202, loss_fp: 0.003996, loss_freq: 0.021392
[18:32:10.499] iteration 22297: loss: 0.037966, loss_s1: 0.029601, loss_fp: 0.001285, loss_freq: 0.010292
[18:32:11.125] iteration 22298: loss: 0.068447, loss_s1: 0.074335, loss_fp: 0.000358, loss_freq: 0.025874
[18:32:11.752] iteration 22299: loss: 0.050638, loss_s1: 0.026537, loss_fp: 0.002664, loss_freq: 0.042897
[18:32:12.378] iteration 22300: loss: 0.088810, loss_s1: 0.077937, loss_fp: 0.000649, loss_freq: 0.065778
[18:32:13.001] iteration 22301: loss: 0.112774, loss_s1: 0.109700, loss_fp: 0.016689, loss_freq: 0.068876
[18:32:13.632] iteration 22302: loss: 0.064511, loss_s1: 0.055476, loss_fp: 0.005572, loss_freq: 0.025875
[18:32:14.260] iteration 22303: loss: 0.057774, loss_s1: 0.042765, loss_fp: 0.009916, loss_freq: 0.039322
[18:32:14.890] iteration 22304: loss: 0.058677, loss_s1: 0.067098, loss_fp: 0.001090, loss_freq: 0.014907
[18:32:15.516] iteration 22305: loss: 0.080374, loss_s1: 0.096712, loss_fp: 0.001698, loss_freq: 0.015527
[18:32:16.139] iteration 22306: loss: 0.050442, loss_s1: 0.040853, loss_fp: 0.010159, loss_freq: 0.016643
[18:32:16.762] iteration 22307: loss: 0.062669, loss_s1: 0.066648, loss_fp: 0.002032, loss_freq: 0.026274
[18:32:17.388] iteration 22308: loss: 0.063673, loss_s1: 0.033941, loss_fp: 0.004049, loss_freq: 0.051091
[18:32:18.015] iteration 22309: loss: 0.069610, loss_s1: 0.048263, loss_fp: 0.009497, loss_freq: 0.039926
[18:32:18.641] iteration 22310: loss: 0.047843, loss_s1: 0.040366, loss_fp: 0.004723, loss_freq: 0.014741
[18:32:19.267] iteration 22311: loss: 0.055918, loss_s1: 0.037994, loss_fp: 0.002447, loss_freq: 0.018463
[18:32:19.895] iteration 22312: loss: 0.048692, loss_s1: 0.041599, loss_fp: 0.003103, loss_freq: 0.022772
[18:32:20.519] iteration 22313: loss: 0.045442, loss_s1: 0.032016, loss_fp: 0.000871, loss_freq: 0.030866
[18:32:21.146] iteration 22314: loss: 0.058327, loss_s1: 0.046159, loss_fp: 0.004006, loss_freq: 0.031580
[18:32:21.773] iteration 22315: loss: 0.041693, loss_s1: 0.015505, loss_fp: 0.002696, loss_freq: 0.024617
[18:32:22.398] iteration 22316: loss: 0.053514, loss_s1: 0.029495, loss_fp: 0.001078, loss_freq: 0.034602
[18:32:23.026] iteration 22317: loss: 0.063822, loss_s1: 0.060652, loss_fp: 0.005603, loss_freq: 0.029328
[18:32:23.650] iteration 22318: loss: 0.054853, loss_s1: 0.044562, loss_fp: 0.001647, loss_freq: 0.031423
[18:32:24.276] iteration 22319: loss: 0.044030, loss_s1: 0.024865, loss_fp: 0.005965, loss_freq: 0.018406
[18:32:24.903] iteration 22320: loss: 0.092852, loss_s1: 0.054833, loss_fp: 0.001066, loss_freq: 0.083734
[18:32:25.542] iteration 22321: loss: 0.062729, loss_s1: 0.060184, loss_fp: 0.002125, loss_freq: 0.027163
[18:32:26.169] iteration 22322: loss: 0.041304, loss_s1: 0.026668, loss_fp: 0.007354, loss_freq: 0.016450
[18:32:26.792] iteration 22323: loss: 0.043834, loss_s1: 0.019920, loss_fp: 0.004151, loss_freq: 0.010049
[18:32:27.415] iteration 22324: loss: 0.034958, loss_s1: 0.021673, loss_fp: 0.003416, loss_freq: 0.017567
[18:32:28.042] iteration 22325: loss: 0.026680, loss_s1: 0.012837, loss_fp: 0.000482, loss_freq: 0.006116
[18:32:28.665] iteration 22326: loss: 0.051966, loss_s1: 0.051304, loss_fp: 0.001766, loss_freq: 0.019191
[18:32:29.288] iteration 22327: loss: 0.115051, loss_s1: 0.064301, loss_fp: 0.003973, loss_freq: 0.098224
[18:32:29.910] iteration 22328: loss: 0.063918, loss_s1: 0.030407, loss_fp: 0.028122, loss_freq: 0.032709
[18:32:30.534] iteration 22329: loss: 0.041066, loss_s1: 0.024208, loss_fp: 0.002190, loss_freq: 0.013416
[18:32:31.157] iteration 22330: loss: 0.080051, loss_s1: 0.049828, loss_fp: 0.001562, loss_freq: 0.074787
[18:32:31.780] iteration 22331: loss: 0.089108, loss_s1: 0.081919, loss_fp: 0.006132, loss_freq: 0.058385
[18:32:32.407] iteration 22332: loss: 0.057979, loss_s1: 0.052045, loss_fp: 0.001975, loss_freq: 0.023563
[18:32:33.028] iteration 22333: loss: 0.043038, loss_s1: 0.033686, loss_fp: 0.000932, loss_freq: 0.018127
[18:32:33.655] iteration 22334: loss: 0.044897, loss_s1: 0.018609, loss_fp: 0.003951, loss_freq: 0.036108
[18:32:34.280] iteration 22335: loss: 0.048601, loss_s1: 0.034320, loss_fp: 0.003938, loss_freq: 0.030702
[18:32:34.905] iteration 22336: loss: 0.035663, loss_s1: 0.026764, loss_fp: 0.004048, loss_freq: 0.013749
[18:32:35.526] iteration 22337: loss: 0.074371, loss_s1: 0.074706, loss_fp: 0.002540, loss_freq: 0.028501
[18:32:36.151] iteration 22338: loss: 0.080598, loss_s1: 0.041001, loss_fp: 0.001381, loss_freq: 0.089490
[18:32:36.777] iteration 22339: loss: 0.035500, loss_s1: 0.006751, loss_fp: 0.002792, loss_freq: 0.025714
[18:32:37.403] iteration 22340: loss: 0.066222, loss_s1: 0.046644, loss_fp: 0.002177, loss_freq: 0.011279
[18:32:38.025] iteration 22341: loss: 0.055422, loss_s1: 0.069756, loss_fp: 0.002226, loss_freq: 0.003433
[18:32:38.655] iteration 22342: loss: 0.044727, loss_s1: 0.048616, loss_fp: 0.000626, loss_freq: 0.006847
[18:32:39.279] iteration 22343: loss: 0.068072, loss_s1: 0.050290, loss_fp: 0.002342, loss_freq: 0.020974
[18:32:39.905] iteration 22344: loss: 0.045958, loss_s1: 0.037922, loss_fp: 0.001638, loss_freq: 0.012585
[18:32:40.534] iteration 22345: loss: 0.037753, loss_s1: 0.024543, loss_fp: 0.002110, loss_freq: 0.015073
[18:32:41.159] iteration 22346: loss: 0.079039, loss_s1: 0.058065, loss_fp: 0.012712, loss_freq: 0.047999
[18:32:41.784] iteration 22347: loss: 0.047146, loss_s1: 0.028401, loss_fp: 0.008823, loss_freq: 0.026680
[18:32:42.407] iteration 22348: loss: 0.045055, loss_s1: 0.039261, loss_fp: 0.002676, loss_freq: 0.017429
[18:32:43.031] iteration 22349: loss: 0.056831, loss_s1: 0.039507, loss_fp: 0.004973, loss_freq: 0.039864
[18:32:43.650] iteration 22350: loss: 0.039898, loss_s1: 0.035290, loss_fp: 0.000773, loss_freq: 0.006697
[18:32:44.275] iteration 22351: loss: 0.053426, loss_s1: 0.059507, loss_fp: 0.000734, loss_freq: 0.013538
[18:32:44.896] iteration 22352: loss: 0.035211, loss_s1: 0.025692, loss_fp: 0.001367, loss_freq: 0.014404
[18:32:45.521] iteration 22353: loss: 0.054332, loss_s1: 0.049135, loss_fp: 0.001304, loss_freq: 0.024860
[18:32:46.148] iteration 22354: loss: 0.051870, loss_s1: 0.032917, loss_fp: 0.005227, loss_freq: 0.035138
[18:32:46.780] iteration 22355: loss: 0.063607, loss_s1: 0.035646, loss_fp: 0.001377, loss_freq: 0.032968
[18:32:47.403] iteration 22356: loss: 0.071347, loss_s1: 0.090266, loss_fp: 0.003186, loss_freq: 0.018914
[18:32:48.028] iteration 22357: loss: 0.043786, loss_s1: 0.014397, loss_fp: 0.004191, loss_freq: 0.020670
[18:32:48.653] iteration 22358: loss: 0.078393, loss_s1: 0.046708, loss_fp: 0.006388, loss_freq: 0.054958
[18:32:49.277] iteration 22359: loss: 0.076199, loss_s1: 0.094553, loss_fp: 0.002755, loss_freq: 0.022404
[18:32:49.902] iteration 22360: loss: 0.037294, loss_s1: 0.018337, loss_fp: 0.006555, loss_freq: 0.019660
[18:32:50.529] iteration 22361: loss: 0.061517, loss_s1: 0.045752, loss_fp: 0.003995, loss_freq: 0.030548
[18:32:51.154] iteration 22362: loss: 0.079817, loss_s1: 0.089502, loss_fp: 0.005031, loss_freq: 0.025136
[18:32:51.778] iteration 22363: loss: 0.037913, loss_s1: 0.016998, loss_fp: 0.008509, loss_freq: 0.019054
[18:32:52.405] iteration 22364: loss: 0.034226, loss_s1: 0.012836, loss_fp: 0.003320, loss_freq: 0.010562
[18:32:53.031] iteration 22365: loss: 0.081930, loss_s1: 0.061443, loss_fp: 0.003372, loss_freq: 0.053337
[18:32:53.662] iteration 22366: loss: 0.070195, loss_s1: 0.105166, loss_fp: 0.001260, loss_freq: 0.007472
[18:32:54.288] iteration 22367: loss: 0.035445, loss_s1: 0.027174, loss_fp: 0.003275, loss_freq: 0.011459
[18:32:54.915] iteration 22368: loss: 0.076491, loss_s1: 0.069940, loss_fp: 0.003459, loss_freq: 0.041014
[18:32:55.540] iteration 22369: loss: 0.071371, loss_s1: 0.053181, loss_fp: 0.005430, loss_freq: 0.044238
[18:32:56.165] iteration 22370: loss: 0.105999, loss_s1: 0.091988, loss_fp: 0.019027, loss_freq: 0.065143
[18:32:56.798] iteration 22371: loss: 0.064800, loss_s1: 0.067330, loss_fp: 0.002911, loss_freq: 0.029515
[18:32:57.424] iteration 22372: loss: 0.059091, loss_s1: 0.054483, loss_fp: 0.002580, loss_freq: 0.024097
[18:32:58.050] iteration 22373: loss: 0.039087, loss_s1: 0.023589, loss_fp: 0.001135, loss_freq: 0.004328
[18:32:58.676] iteration 22374: loss: 0.073333, loss_s1: 0.042235, loss_fp: 0.003439, loss_freq: 0.028918
[18:32:59.301] iteration 22375: loss: 0.034250, loss_s1: 0.011670, loss_fp: 0.001358, loss_freq: 0.009237
[18:32:59.928] iteration 22376: loss: 0.062250, loss_s1: 0.034117, loss_fp: 0.001456, loss_freq: 0.033311
[18:33:00.553] iteration 22377: loss: 0.072704, loss_s1: 0.057209, loss_fp: 0.002946, loss_freq: 0.044540
[18:33:01.178] iteration 22378: loss: 0.037388, loss_s1: 0.016546, loss_fp: 0.003354, loss_freq: 0.021331
[18:33:01.802] iteration 22379: loss: 0.044426, loss_s1: 0.023980, loss_fp: 0.005624, loss_freq: 0.011946
[18:33:02.772] iteration 22380: loss: 0.045662, loss_s1: 0.031929, loss_fp: 0.001433, loss_freq: 0.025680
[18:33:03.401] iteration 22381: loss: 0.058506, loss_s1: 0.048131, loss_fp: 0.005147, loss_freq: 0.026751
[18:33:04.030] iteration 22382: loss: 0.037888, loss_s1: 0.018089, loss_fp: 0.003041, loss_freq: 0.017175
[18:33:04.657] iteration 22383: loss: 0.049434, loss_s1: 0.038519, loss_fp: 0.000705, loss_freq: 0.020084
[18:33:05.295] iteration 22384: loss: 0.038660, loss_s1: 0.023832, loss_fp: 0.002383, loss_freq: 0.014070
[18:33:05.939] iteration 22385: loss: 0.093763, loss_s1: 0.060130, loss_fp: 0.004315, loss_freq: 0.062378
[18:33:06.563] iteration 22386: loss: 0.030571, loss_s1: 0.013010, loss_fp: 0.000784, loss_freq: 0.013090
[18:33:07.194] iteration 22387: loss: 0.032185, loss_s1: 0.020633, loss_fp: 0.001824, loss_freq: 0.006380
[18:33:07.818] iteration 22388: loss: 0.045082, loss_s1: 0.028602, loss_fp: 0.003605, loss_freq: 0.015738
[18:33:08.442] iteration 22389: loss: 0.076883, loss_s1: 0.056567, loss_fp: 0.007301, loss_freq: 0.043223
[18:33:09.065] iteration 22390: loss: 0.028519, loss_s1: 0.007911, loss_fp: 0.000676, loss_freq: 0.013787
[18:33:09.693] iteration 22391: loss: 0.042369, loss_s1: 0.037732, loss_fp: 0.002044, loss_freq: 0.009769
[18:33:10.318] iteration 22392: loss: 0.092207, loss_s1: 0.063268, loss_fp: 0.012187, loss_freq: 0.079691
[18:33:10.945] iteration 22393: loss: 0.048531, loss_s1: 0.034892, loss_fp: 0.008070, loss_freq: 0.007026
[18:33:11.567] iteration 22394: loss: 0.054350, loss_s1: 0.071268, loss_fp: 0.002039, loss_freq: 0.009667
[18:33:12.194] iteration 22395: loss: 0.100969, loss_s1: 0.100834, loss_fp: 0.005835, loss_freq: 0.054171
[18:33:12.821] iteration 22396: loss: 0.049870, loss_s1: 0.040772, loss_fp: 0.008472, loss_freq: 0.011353
[18:33:13.447] iteration 22397: loss: 0.079225, loss_s1: 0.062634, loss_fp: 0.005513, loss_freq: 0.055903
[18:33:14.074] iteration 22398: loss: 0.053474, loss_s1: 0.027811, loss_fp: 0.003949, loss_freq: 0.019164
[18:33:14.705] iteration 22399: loss: 0.069830, loss_s1: 0.061770, loss_fp: 0.001208, loss_freq: 0.023133
[18:33:15.335] iteration 22400: loss: 0.045509, loss_s1: 0.033179, loss_fp: 0.001004, loss_freq: 0.008802
[18:33:18.628] iteration 22400 : mean_dice : 0.725243
[18:33:19.272] iteration 22401: loss: 0.050079, loss_s1: 0.035230, loss_fp: 0.001295, loss_freq: 0.027673
[18:33:19.899] iteration 22402: loss: 0.059475, loss_s1: 0.045447, loss_fp: 0.000744, loss_freq: 0.023395
[18:33:20.529] iteration 22403: loss: 0.084368, loss_s1: 0.087941, loss_fp: 0.003297, loss_freq: 0.044905
[18:33:21.157] iteration 22404: loss: 0.076136, loss_s1: 0.031139, loss_fp: 0.003321, loss_freq: 0.084370
[18:33:21.781] iteration 22405: loss: 0.051935, loss_s1: 0.029541, loss_fp: 0.002627, loss_freq: 0.034007
[18:33:22.412] iteration 22406: loss: 0.027031, loss_s1: 0.013029, loss_fp: 0.001164, loss_freq: 0.009294
[18:33:23.048] iteration 22407: loss: 0.077444, loss_s1: 0.065525, loss_fp: 0.009538, loss_freq: 0.039740
[18:33:23.673] iteration 22408: loss: 0.061598, loss_s1: 0.031670, loss_fp: 0.002860, loss_freq: 0.055778
[18:33:24.298] iteration 22409: loss: 0.040844, loss_s1: 0.035923, loss_fp: 0.000986, loss_freq: 0.010013
[18:33:24.928] iteration 22410: loss: 0.062530, loss_s1: 0.048544, loss_fp: 0.002066, loss_freq: 0.013912
[18:33:25.559] iteration 22411: loss: 0.034202, loss_s1: 0.023218, loss_fp: 0.004565, loss_freq: 0.004857
[18:33:26.184] iteration 22412: loss: 0.036103, loss_s1: 0.025833, loss_fp: 0.001753, loss_freq: 0.011254
[18:33:26.853] iteration 22413: loss: 0.039455, loss_s1: 0.029334, loss_fp: 0.001317, loss_freq: 0.010735
[18:33:27.479] iteration 22414: loss: 0.089309, loss_s1: 0.077204, loss_fp: 0.002667, loss_freq: 0.051623
[18:33:28.106] iteration 22415: loss: 0.067494, loss_s1: 0.064807, loss_fp: 0.001016, loss_freq: 0.042696
[18:33:28.735] iteration 22416: loss: 0.080651, loss_s1: 0.055413, loss_fp: 0.012934, loss_freq: 0.060359
[18:33:29.362] iteration 22417: loss: 0.045449, loss_s1: 0.033972, loss_fp: 0.001844, loss_freq: 0.023735
[18:33:29.987] iteration 22418: loss: 0.052515, loss_s1: 0.046126, loss_fp: 0.002306, loss_freq: 0.011385
[18:33:30.611] iteration 22419: loss: 0.073939, loss_s1: 0.079762, loss_fp: 0.004793, loss_freq: 0.029350
[18:33:31.240] iteration 22420: loss: 0.043979, loss_s1: 0.040183, loss_fp: 0.001414, loss_freq: 0.011567
[18:33:31.869] iteration 22421: loss: 0.059305, loss_s1: 0.059783, loss_fp: 0.003355, loss_freq: 0.026805
[18:33:32.497] iteration 22422: loss: 0.048197, loss_s1: 0.032680, loss_fp: 0.003731, loss_freq: 0.026518
[18:33:33.123] iteration 22423: loss: 0.080048, loss_s1: 0.088081, loss_fp: 0.002144, loss_freq: 0.032939
[18:33:33.758] iteration 22424: loss: 0.048955, loss_s1: 0.035996, loss_fp: 0.001900, loss_freq: 0.022268
[18:33:34.400] iteration 22425: loss: 0.049064, loss_s1: 0.036452, loss_fp: 0.001678, loss_freq: 0.019823
[18:33:35.037] iteration 22426: loss: 0.038590, loss_s1: 0.022335, loss_fp: 0.001153, loss_freq: 0.026888
[18:33:35.659] iteration 22427: loss: 0.055382, loss_s1: 0.051611, loss_fp: 0.012658, loss_freq: 0.015035
[18:33:36.286] iteration 22428: loss: 0.043384, loss_s1: 0.027972, loss_fp: 0.003512, loss_freq: 0.022654
[18:33:36.907] iteration 22429: loss: 0.049910, loss_s1: 0.055120, loss_fp: 0.000627, loss_freq: 0.011000
[18:33:37.532] iteration 22430: loss: 0.080290, loss_s1: 0.097006, loss_fp: 0.003974, loss_freq: 0.024374
[18:33:38.156] iteration 22431: loss: 0.053278, loss_s1: 0.030762, loss_fp: 0.002893, loss_freq: 0.034862
[18:33:38.787] iteration 22432: loss: 0.046492, loss_s1: 0.027481, loss_fp: 0.007368, loss_freq: 0.017167
[18:33:39.412] iteration 22433: loss: 0.042730, loss_s1: 0.024947, loss_fp: 0.003217, loss_freq: 0.025336
[18:33:40.036] iteration 22434: loss: 0.037706, loss_s1: 0.030476, loss_fp: 0.002530, loss_freq: 0.012800
[18:33:40.665] iteration 22435: loss: 0.043975, loss_s1: 0.016168, loss_fp: 0.001192, loss_freq: 0.020272
[18:33:41.289] iteration 22436: loss: 0.033369, loss_s1: 0.013353, loss_fp: 0.000658, loss_freq: 0.013977
[18:33:41.921] iteration 22437: loss: 0.067112, loss_s1: 0.046231, loss_fp: 0.003031, loss_freq: 0.014257
[18:33:42.550] iteration 22438: loss: 0.044121, loss_s1: 0.042132, loss_fp: 0.000443, loss_freq: 0.012958
[18:33:43.178] iteration 22439: loss: 0.043893, loss_s1: 0.025586, loss_fp: 0.001175, loss_freq: 0.021882
[18:33:43.805] iteration 22440: loss: 0.038640, loss_s1: 0.018204, loss_fp: 0.004251, loss_freq: 0.019737
[18:33:44.427] iteration 22441: loss: 0.051132, loss_s1: 0.048948, loss_fp: 0.005655, loss_freq: 0.016990
[18:33:45.076] iteration 22442: loss: 0.039542, loss_s1: 0.032789, loss_fp: 0.000432, loss_freq: 0.010893
[18:33:45.700] iteration 22443: loss: 0.067581, loss_s1: 0.056386, loss_fp: 0.003693, loss_freq: 0.012390
[18:33:46.341] iteration 22444: loss: 0.038766, loss_s1: 0.025944, loss_fp: 0.009581, loss_freq: 0.008752
[18:33:46.964] iteration 22445: loss: 0.075823, loss_s1: 0.060084, loss_fp: 0.001588, loss_freq: 0.060536
[18:33:47.592] iteration 22446: loss: 0.045987, loss_s1: 0.030849, loss_fp: 0.005539, loss_freq: 0.015496
[18:33:48.214] iteration 22447: loss: 0.074340, loss_s1: 0.081863, loss_fp: 0.011062, loss_freq: 0.031556
[18:33:48.841] iteration 22448: loss: 0.047362, loss_s1: 0.038130, loss_fp: 0.010431, loss_freq: 0.010968
[18:33:49.473] iteration 22449: loss: 0.044537, loss_s1: 0.035900, loss_fp: 0.003377, loss_freq: 0.005932
[18:33:50.098] iteration 22450: loss: 0.056570, loss_s1: 0.041651, loss_fp: 0.004192, loss_freq: 0.028644
[18:33:50.725] iteration 22451: loss: 0.041192, loss_s1: 0.030914, loss_fp: 0.002859, loss_freq: 0.016213
[18:33:51.349] iteration 22452: loss: 0.052016, loss_s1: 0.029666, loss_fp: 0.005966, loss_freq: 0.031113
[18:33:52.018] iteration 22453: loss: 0.053907, loss_s1: 0.042935, loss_fp: 0.004039, loss_freq: 0.013361
[18:33:52.643] iteration 22454: loss: 0.061813, loss_s1: 0.055577, loss_fp: 0.001849, loss_freq: 0.021102
[18:33:53.269] iteration 22455: loss: 0.048886, loss_s1: 0.014842, loss_fp: 0.028393, loss_freq: 0.011737
[18:33:53.897] iteration 22456: loss: 0.047563, loss_s1: 0.032843, loss_fp: 0.001422, loss_freq: 0.026604
[18:33:54.521] iteration 22457: loss: 0.047536, loss_s1: 0.052775, loss_fp: 0.001524, loss_freq: 0.012535
[18:33:55.145] iteration 22458: loss: 0.030442, loss_s1: 0.024158, loss_fp: 0.002999, loss_freq: 0.009584
[18:33:55.770] iteration 22459: loss: 0.083012, loss_s1: 0.065116, loss_fp: 0.003959, loss_freq: 0.056297
[18:33:56.395] iteration 22460: loss: 0.076092, loss_s1: 0.039268, loss_fp: 0.001744, loss_freq: 0.079027
[18:33:57.018] iteration 22461: loss: 0.086414, loss_s1: 0.111844, loss_fp: 0.003550, loss_freq: 0.017793
[18:33:57.643] iteration 22462: loss: 0.056467, loss_s1: 0.053607, loss_fp: 0.002329, loss_freq: 0.027745
[18:33:58.268] iteration 22463: loss: 0.070479, loss_s1: 0.041392, loss_fp: 0.001610, loss_freq: 0.059248
[18:33:58.895] iteration 22464: loss: 0.058459, loss_s1: 0.058936, loss_fp: 0.002833, loss_freq: 0.023175
[18:33:59.520] iteration 22465: loss: 0.046487, loss_s1: 0.042929, loss_fp: 0.002031, loss_freq: 0.012714
[18:34:00.148] iteration 22466: loss: 0.076224, loss_s1: 0.073093, loss_fp: 0.005729, loss_freq: 0.035301
[18:34:00.776] iteration 22467: loss: 0.038840, loss_s1: 0.026561, loss_fp: 0.004781, loss_freq: 0.014360
[18:34:01.404] iteration 22468: loss: 0.059214, loss_s1: 0.037684, loss_fp: 0.004305, loss_freq: 0.031413
[18:34:02.027] iteration 22469: loss: 0.062015, loss_s1: 0.049795, loss_fp: 0.004374, loss_freq: 0.038983
[18:34:02.652] iteration 22470: loss: 0.065866, loss_s1: 0.034431, loss_fp: 0.004043, loss_freq: 0.057236
[18:34:03.273] iteration 22471: loss: 0.036063, loss_s1: 0.021230, loss_fp: 0.003515, loss_freq: 0.013238
[18:34:03.901] iteration 22472: loss: 0.074939, loss_s1: 0.026761, loss_fp: 0.003793, loss_freq: 0.013299
[18:34:04.528] iteration 22473: loss: 0.030061, loss_s1: 0.024854, loss_fp: 0.001950, loss_freq: 0.004719
[18:34:05.156] iteration 22474: loss: 0.039736, loss_s1: 0.029525, loss_fp: 0.004090, loss_freq: 0.017951
[18:34:05.781] iteration 22475: loss: 0.069341, loss_s1: 0.036685, loss_fp: 0.005788, loss_freq: 0.043833
[18:34:06.408] iteration 22476: loss: 0.044099, loss_s1: 0.037270, loss_fp: 0.002617, loss_freq: 0.016737
[18:34:07.033] iteration 22477: loss: 0.047219, loss_s1: 0.013150, loss_fp: 0.000913, loss_freq: 0.038067
[18:34:07.660] iteration 22478: loss: 0.033784, loss_s1: 0.018764, loss_fp: 0.001346, loss_freq: 0.005878
[18:34:08.284] iteration 22479: loss: 0.045008, loss_s1: 0.025864, loss_fp: 0.004875, loss_freq: 0.026901
[18:34:08.910] iteration 22480: loss: 0.061480, loss_s1: 0.059322, loss_fp: 0.003484, loss_freq: 0.030851
[18:34:09.532] iteration 22481: loss: 0.080890, loss_s1: 0.052334, loss_fp: 0.003898, loss_freq: 0.067519
[18:34:10.162] iteration 22482: loss: 0.052286, loss_s1: 0.050235, loss_fp: 0.003420, loss_freq: 0.023610
[18:34:10.803] iteration 22483: loss: 0.041021, loss_s1: 0.036099, loss_fp: 0.004485, loss_freq: 0.012599
[18:34:11.435] iteration 22484: loss: 0.045145, loss_s1: 0.023685, loss_fp: 0.002712, loss_freq: 0.010592
[18:34:12.070] iteration 22485: loss: 0.054909, loss_s1: 0.052885, loss_fp: 0.006840, loss_freq: 0.018638
[18:34:12.696] iteration 22486: loss: 0.030353, loss_s1: 0.013106, loss_fp: 0.001142, loss_freq: 0.007243
[18:34:13.328] iteration 22487: loss: 0.075941, loss_s1: 0.080005, loss_fp: 0.000875, loss_freq: 0.025059
[18:34:13.957] iteration 22488: loss: 0.078613, loss_s1: 0.044372, loss_fp: 0.007555, loss_freq: 0.058087
[18:34:14.587] iteration 22489: loss: 0.069022, loss_s1: 0.073962, loss_fp: 0.007226, loss_freq: 0.020867
[18:34:15.214] iteration 22490: loss: 0.044450, loss_s1: 0.025228, loss_fp: 0.001986, loss_freq: 0.010318
[18:34:15.843] iteration 22491: loss: 0.046348, loss_s1: 0.027214, loss_fp: 0.002724, loss_freq: 0.031021
[18:34:16.472] iteration 22492: loss: 0.054975, loss_s1: 0.022946, loss_fp: 0.011187, loss_freq: 0.047906
[18:34:17.158] iteration 22493: loss: 0.043223, loss_s1: 0.021688, loss_fp: 0.002074, loss_freq: 0.020050
[18:34:17.811] iteration 22494: loss: 0.041635, loss_s1: 0.027580, loss_fp: 0.001412, loss_freq: 0.008355
[18:34:18.458] iteration 22495: loss: 0.064010, loss_s1: 0.062159, loss_fp: 0.002118, loss_freq: 0.025505
[18:34:19.102] iteration 22496: loss: 0.041369, loss_s1: 0.020802, loss_fp: 0.003193, loss_freq: 0.021675
[18:34:19.752] iteration 22497: loss: 0.051100, loss_s1: 0.041841, loss_fp: 0.007468, loss_freq: 0.023567
[18:34:20.396] iteration 22498: loss: 0.073560, loss_s1: 0.063199, loss_fp: 0.011623, loss_freq: 0.031625
[18:34:21.043] iteration 22499: loss: 0.107758, loss_s1: 0.063715, loss_fp: 0.003162, loss_freq: 0.116632
[18:34:21.705] iteration 22500: loss: 0.064282, loss_s1: 0.033117, loss_fp: 0.007711, loss_freq: 0.058443
[18:34:22.348] iteration 22501: loss: 0.076576, loss_s1: 0.058144, loss_fp: 0.021100, loss_freq: 0.036178
[18:34:22.980] iteration 22502: loss: 0.036241, loss_s1: 0.027052, loss_fp: 0.006429, loss_freq: 0.005387
[18:34:23.615] iteration 22503: loss: 0.037726, loss_s1: 0.027083, loss_fp: 0.002931, loss_freq: 0.008679
[18:34:24.244] iteration 22504: loss: 0.069735, loss_s1: 0.061563, loss_fp: 0.004380, loss_freq: 0.031807
[18:34:24.871] iteration 22505: loss: 0.036574, loss_s1: 0.026011, loss_fp: 0.000490, loss_freq: 0.008406
[18:34:25.504] iteration 22506: loss: 0.070183, loss_s1: 0.086749, loss_fp: 0.003786, loss_freq: 0.012638
[18:34:26.125] iteration 22507: loss: 0.111852, loss_s1: 0.073558, loss_fp: 0.001109, loss_freq: 0.093924
[18:34:26.761] iteration 22508: loss: 0.057045, loss_s1: 0.030266, loss_fp: 0.013031, loss_freq: 0.038900
[18:34:27.392] iteration 22509: loss: 0.043416, loss_s1: 0.033898, loss_fp: 0.002447, loss_freq: 0.007834
[18:34:28.032] iteration 22510: loss: 0.051134, loss_s1: 0.045125, loss_fp: 0.001873, loss_freq: 0.018069
[18:34:28.663] iteration 22511: loss: 0.041974, loss_s1: 0.021900, loss_fp: 0.002131, loss_freq: 0.018769
[18:34:29.287] iteration 22512: loss: 0.097935, loss_s1: 0.136027, loss_fp: 0.001979, loss_freq: 0.015238
[18:34:29.915] iteration 22513: loss: 0.035222, loss_s1: 0.017672, loss_fp: 0.005789, loss_freq: 0.008977
[18:34:30.544] iteration 22514: loss: 0.083098, loss_s1: 0.053310, loss_fp: 0.002885, loss_freq: 0.068836
[18:34:31.181] iteration 22515: loss: 0.052519, loss_s1: 0.028584, loss_fp: 0.005039, loss_freq: 0.039871
[18:34:31.864] iteration 22516: loss: 0.027209, loss_s1: 0.012852, loss_fp: 0.001153, loss_freq: 0.005725
[18:34:32.499] iteration 22517: loss: 0.036681, loss_s1: 0.027143, loss_fp: 0.003105, loss_freq: 0.012657
[18:34:33.145] iteration 22518: loss: 0.046766, loss_s1: 0.022889, loss_fp: 0.002565, loss_freq: 0.028837
[18:34:33.786] iteration 22519: loss: 0.084085, loss_s1: 0.076810, loss_fp: 0.012149, loss_freq: 0.023789
[18:34:34.423] iteration 22520: loss: 0.058323, loss_s1: 0.047417, loss_fp: 0.004323, loss_freq: 0.029147
[18:34:35.050] iteration 22521: loss: 0.042869, loss_s1: 0.024357, loss_fp: 0.004024, loss_freq: 0.022338
[18:34:35.670] iteration 22522: loss: 0.057175, loss_s1: 0.023945, loss_fp: 0.012080, loss_freq: 0.031116
[18:34:36.298] iteration 22523: loss: 0.057761, loss_s1: 0.029422, loss_fp: 0.005779, loss_freq: 0.039962
[18:34:36.928] iteration 22524: loss: 0.055113, loss_s1: 0.039935, loss_fp: 0.005681, loss_freq: 0.028900
[18:34:37.548] iteration 22525: loss: 0.070942, loss_s1: 0.066311, loss_fp: 0.008574, loss_freq: 0.012949
[18:34:38.172] iteration 22526: loss: 0.068285, loss_s1: 0.047380, loss_fp: 0.008278, loss_freq: 0.045165
[18:34:38.798] iteration 22527: loss: 0.050081, loss_s1: 0.043950, loss_fp: 0.000966, loss_freq: 0.023078
[18:34:39.427] iteration 22528: loss: 0.036955, loss_s1: 0.029747, loss_fp: 0.001197, loss_freq: 0.015128
[18:34:40.053] iteration 22529: loss: 0.061986, loss_s1: 0.042619, loss_fp: 0.007020, loss_freq: 0.035519
[18:34:40.676] iteration 22530: loss: 0.055420, loss_s1: 0.030926, loss_fp: 0.001821, loss_freq: 0.039946
[18:34:41.305] iteration 22531: loss: 0.076239, loss_s1: 0.072452, loss_fp: 0.013415, loss_freq: 0.033260
[18:34:41.935] iteration 22532: loss: 0.044189, loss_s1: 0.035141, loss_fp: 0.002026, loss_freq: 0.018053
[18:34:42.563] iteration 22533: loss: 0.052765, loss_s1: 0.034384, loss_fp: 0.003735, loss_freq: 0.026659
[18:34:43.190] iteration 22534: loss: 0.026627, loss_s1: 0.008105, loss_fp: 0.000642, loss_freq: 0.011468
[18:34:43.823] iteration 22535: loss: 0.036631, loss_s1: 0.010237, loss_fp: 0.001837, loss_freq: 0.025704
[18:34:44.477] iteration 22536: loss: 0.043258, loss_s1: 0.032861, loss_fp: 0.001269, loss_freq: 0.012738
[18:34:45.103] iteration 22537: loss: 0.071478, loss_s1: 0.040443, loss_fp: 0.006726, loss_freq: 0.055245
[18:34:45.733] iteration 22538: loss: 0.062094, loss_s1: 0.041327, loss_fp: 0.005435, loss_freq: 0.042302
[18:34:46.355] iteration 22539: loss: 0.067450, loss_s1: 0.036850, loss_fp: 0.013957, loss_freq: 0.027646
[18:34:46.977] iteration 22540: loss: 0.054404, loss_s1: 0.038201, loss_fp: 0.000951, loss_freq: 0.026984
[18:34:47.925] iteration 22541: loss: 0.045810, loss_s1: 0.049598, loss_fp: 0.004858, loss_freq: 0.010483
[18:34:48.553] iteration 22542: loss: 0.050400, loss_s1: 0.032231, loss_fp: 0.005840, loss_freq: 0.023324
[18:34:49.181] iteration 22543: loss: 0.052986, loss_s1: 0.021986, loss_fp: 0.003397, loss_freq: 0.011894
[18:34:49.813] iteration 22544: loss: 0.049666, loss_s1: 0.023366, loss_fp: 0.002533, loss_freq: 0.022899
[18:34:50.438] iteration 22545: loss: 0.045847, loss_s1: 0.026758, loss_fp: 0.004217, loss_freq: 0.021527
[18:34:51.068] iteration 22546: loss: 0.057203, loss_s1: 0.026810, loss_fp: 0.004345, loss_freq: 0.039491
[18:34:51.698] iteration 22547: loss: 0.051010, loss_s1: 0.055166, loss_fp: 0.001174, loss_freq: 0.013486
[18:34:52.330] iteration 22548: loss: 0.036042, loss_s1: 0.026202, loss_fp: 0.002655, loss_freq: 0.014222
[18:34:52.954] iteration 22549: loss: 0.063990, loss_s1: 0.060754, loss_fp: 0.002424, loss_freq: 0.037555
[18:34:53.582] iteration 22550: loss: 0.095320, loss_s1: 0.085923, loss_fp: 0.004301, loss_freq: 0.058967
[18:34:54.211] iteration 22551: loss: 0.042961, loss_s1: 0.022495, loss_fp: 0.000389, loss_freq: 0.019789
[18:34:54.842] iteration 22552: loss: 0.084579, loss_s1: 0.082171, loss_fp: 0.002401, loss_freq: 0.053640
[18:34:55.466] iteration 22553: loss: 0.065164, loss_s1: 0.048112, loss_fp: 0.006346, loss_freq: 0.039646
[18:34:56.087] iteration 22554: loss: 0.066119, loss_s1: 0.063740, loss_fp: 0.002660, loss_freq: 0.020212
[18:34:56.715] iteration 22555: loss: 0.053368, loss_s1: 0.046204, loss_fp: 0.005800, loss_freq: 0.026065
[18:34:57.347] iteration 22556: loss: 0.105587, loss_s1: 0.124340, loss_fp: 0.009844, loss_freq: 0.047246
[18:34:57.971] iteration 22557: loss: 0.071648, loss_s1: 0.027706, loss_fp: 0.001717, loss_freq: 0.018067
[18:34:58.600] iteration 22558: loss: 0.069759, loss_s1: 0.069238, loss_fp: 0.005778, loss_freq: 0.029349
[18:34:59.227] iteration 22559: loss: 0.038615, loss_s1: 0.011117, loss_fp: 0.002470, loss_freq: 0.025552
[18:34:59.863] iteration 22560: loss: 0.045433, loss_s1: 0.024449, loss_fp: 0.001041, loss_freq: 0.013382
[18:35:00.527] iteration 22561: loss: 0.028714, loss_s1: 0.007899, loss_fp: 0.001461, loss_freq: 0.005551
[18:35:01.157] iteration 22562: loss: 0.042097, loss_s1: 0.022186, loss_fp: 0.001206, loss_freq: 0.021107
[18:35:01.800] iteration 22563: loss: 0.047516, loss_s1: 0.020518, loss_fp: 0.004974, loss_freq: 0.020770
[18:35:02.443] iteration 22564: loss: 0.075043, loss_s1: 0.023152, loss_fp: 0.001458, loss_freq: 0.092375
[18:35:03.098] iteration 22565: loss: 0.038110, loss_s1: 0.026477, loss_fp: 0.002009, loss_freq: 0.016733
[18:35:03.745] iteration 22566: loss: 0.040678, loss_s1: 0.008787, loss_fp: 0.002164, loss_freq: 0.036309
[18:35:04.383] iteration 22567: loss: 0.032920, loss_s1: 0.014008, loss_fp: 0.001071, loss_freq: 0.007011
[18:35:05.022] iteration 22568: loss: 0.148017, loss_s1: 0.170977, loss_fp: 0.028173, loss_freq: 0.048323
[18:35:05.662] iteration 22569: loss: 0.041435, loss_s1: 0.031860, loss_fp: 0.002726, loss_freq: 0.014208
[18:35:06.303] iteration 22570: loss: 0.041470, loss_s1: 0.031687, loss_fp: 0.002804, loss_freq: 0.011252
[18:35:06.935] iteration 22571: loss: 0.034180, loss_s1: 0.028541, loss_fp: 0.001675, loss_freq: 0.011373
[18:35:07.562] iteration 22572: loss: 0.050603, loss_s1: 0.031564, loss_fp: 0.001250, loss_freq: 0.034206
[18:35:08.193] iteration 22573: loss: 0.068583, loss_s1: 0.063009, loss_fp: 0.005209, loss_freq: 0.035836
[18:35:08.823] iteration 22574: loss: 0.042901, loss_s1: 0.048018, loss_fp: 0.001920, loss_freq: 0.004030
[18:35:09.451] iteration 22575: loss: 0.072723, loss_s1: 0.069204, loss_fp: 0.009540, loss_freq: 0.031148
[18:35:10.085] iteration 22576: loss: 0.078141, loss_s1: 0.078819, loss_fp: 0.015348, loss_freq: 0.033090
[18:35:10.709] iteration 22577: loss: 0.062736, loss_s1: 0.045300, loss_fp: 0.005018, loss_freq: 0.036962
[18:35:11.340] iteration 22578: loss: 0.065201, loss_s1: 0.043331, loss_fp: 0.003975, loss_freq: 0.046850
[18:35:11.967] iteration 22579: loss: 0.058600, loss_s1: 0.043572, loss_fp: 0.001442, loss_freq: 0.033889
[18:35:12.597] iteration 22580: loss: 0.049069, loss_s1: 0.027428, loss_fp: 0.000949, loss_freq: 0.035406
[18:35:13.232] iteration 22581: loss: 0.047114, loss_s1: 0.031623, loss_fp: 0.005039, loss_freq: 0.017950
[18:35:13.867] iteration 22582: loss: 0.064781, loss_s1: 0.072550, loss_fp: 0.004112, loss_freq: 0.023232
[18:35:14.493] iteration 22583: loss: 0.043148, loss_s1: 0.039826, loss_fp: 0.003004, loss_freq: 0.016816
[18:35:15.127] iteration 22584: loss: 0.045228, loss_s1: 0.029554, loss_fp: 0.002551, loss_freq: 0.031525
[18:35:15.757] iteration 22585: loss: 0.051256, loss_s1: 0.018541, loss_fp: 0.001649, loss_freq: 0.036794
[18:35:16.393] iteration 22586: loss: 0.043715, loss_s1: 0.042011, loss_fp: 0.003316, loss_freq: 0.012256
[18:35:17.027] iteration 22587: loss: 0.030793, loss_s1: 0.024077, loss_fp: 0.000428, loss_freq: 0.006736
[18:35:17.664] iteration 22588: loss: 0.049226, loss_s1: 0.046739, loss_fp: 0.005697, loss_freq: 0.010356
[18:35:18.295] iteration 22589: loss: 0.075033, loss_s1: 0.090079, loss_fp: 0.009461, loss_freq: 0.016783
[18:35:18.926] iteration 22590: loss: 0.070963, loss_s1: 0.072707, loss_fp: 0.006765, loss_freq: 0.038605
[18:35:19.569] iteration 22591: loss: 0.055627, loss_s1: 0.037443, loss_fp: 0.002006, loss_freq: 0.041454
[18:35:20.214] iteration 22592: loss: 0.064724, loss_s1: 0.027991, loss_fp: 0.005451, loss_freq: 0.055145
[18:35:20.896] iteration 22593: loss: 0.040493, loss_s1: 0.032340, loss_fp: 0.002184, loss_freq: 0.010408
[18:35:21.580] iteration 22594: loss: 0.061904, loss_s1: 0.048060, loss_fp: 0.003221, loss_freq: 0.037895
[18:35:22.227] iteration 22595: loss: 0.034686, loss_s1: 0.021863, loss_fp: 0.002509, loss_freq: 0.008648
[18:35:22.862] iteration 22596: loss: 0.061536, loss_s1: 0.055718, loss_fp: 0.002959, loss_freq: 0.024325
[18:35:23.491] iteration 22597: loss: 0.030330, loss_s1: 0.015222, loss_fp: 0.001281, loss_freq: 0.005555
[18:35:24.125] iteration 22598: loss: 0.059949, loss_s1: 0.049941, loss_fp: 0.001415, loss_freq: 0.019702
[18:35:24.754] iteration 22599: loss: 0.044733, loss_s1: 0.042573, loss_fp: 0.001598, loss_freq: 0.006675
[18:35:25.395] iteration 22600: loss: 0.050018, loss_s1: 0.028627, loss_fp: 0.011953, loss_freq: 0.027475
[18:35:28.970] iteration 22600 : mean_dice : 0.739920
[18:35:29.617] iteration 22601: loss: 0.070574, loss_s1: 0.071075, loss_fp: 0.004889, loss_freq: 0.022302
[18:35:30.246] iteration 22602: loss: 0.056031, loss_s1: 0.058892, loss_fp: 0.002116, loss_freq: 0.016926
[18:35:30.873] iteration 22603: loss: 0.048178, loss_s1: 0.028602, loss_fp: 0.000332, loss_freq: 0.029701
[18:35:31.502] iteration 22604: loss: 0.056585, loss_s1: 0.061107, loss_fp: 0.003298, loss_freq: 0.010631
[18:35:32.133] iteration 22605: loss: 0.041899, loss_s1: 0.034202, loss_fp: 0.001088, loss_freq: 0.016703
[18:35:32.764] iteration 22606: loss: 0.096691, loss_s1: 0.081871, loss_fp: 0.004064, loss_freq: 0.076120
[18:35:33.397] iteration 22607: loss: 0.081615, loss_s1: 0.065928, loss_fp: 0.004448, loss_freq: 0.037534
[18:35:34.025] iteration 22608: loss: 0.062324, loss_s1: 0.042750, loss_fp: 0.007695, loss_freq: 0.042860
[18:35:34.697] iteration 22609: loss: 0.040437, loss_s1: 0.030996, loss_fp: 0.005386, loss_freq: 0.005255
[18:35:35.348] iteration 22610: loss: 0.066987, loss_s1: 0.030901, loss_fp: 0.002407, loss_freq: 0.039359
[18:35:35.980] iteration 22611: loss: 0.049617, loss_s1: 0.019743, loss_fp: 0.007942, loss_freq: 0.038755
[18:35:36.614] iteration 22612: loss: 0.038519, loss_s1: 0.030577, loss_fp: 0.004452, loss_freq: 0.012803
[18:35:37.247] iteration 22613: loss: 0.050507, loss_s1: 0.048379, loss_fp: 0.002837, loss_freq: 0.013836
[18:35:37.880] iteration 22614: loss: 0.045313, loss_s1: 0.026831, loss_fp: 0.008292, loss_freq: 0.018613
[18:35:38.514] iteration 22615: loss: 0.045354, loss_s1: 0.040811, loss_fp: 0.002742, loss_freq: 0.011844
[18:35:39.145] iteration 22616: loss: 0.045690, loss_s1: 0.022095, loss_fp: 0.008616, loss_freq: 0.010048
[18:35:39.777] iteration 22617: loss: 0.054708, loss_s1: 0.046240, loss_fp: 0.004818, loss_freq: 0.025223
[18:35:40.410] iteration 22618: loss: 0.026655, loss_s1: 0.014187, loss_fp: 0.003591, loss_freq: 0.007418
[18:35:41.047] iteration 22619: loss: 0.028720, loss_s1: 0.019553, loss_fp: 0.000905, loss_freq: 0.006195
[18:35:41.717] iteration 22620: loss: 0.071531, loss_s1: 0.055192, loss_fp: 0.001954, loss_freq: 0.046745
[18:35:42.353] iteration 22621: loss: 0.074697, loss_s1: 0.068181, loss_fp: 0.004643, loss_freq: 0.040500
[18:35:42.995] iteration 22622: loss: 0.060967, loss_s1: 0.066441, loss_fp: 0.004526, loss_freq: 0.022851
[18:35:43.622] iteration 22623: loss: 0.067681, loss_s1: 0.060034, loss_fp: 0.007567, loss_freq: 0.034441
[18:35:44.256] iteration 22624: loss: 0.056936, loss_s1: 0.025963, loss_fp: 0.001418, loss_freq: 0.041573
[18:35:44.894] iteration 22625: loss: 0.082865, loss_s1: 0.077944, loss_fp: 0.009850, loss_freq: 0.043259
[18:35:45.527] iteration 22626: loss: 0.039550, loss_s1: 0.021472, loss_fp: 0.000753, loss_freq: 0.018185
[18:35:46.156] iteration 22627: loss: 0.034636, loss_s1: 0.020467, loss_fp: 0.000598, loss_freq: 0.009239
[18:35:46.784] iteration 22628: loss: 0.043457, loss_s1: 0.033038, loss_fp: 0.007996, loss_freq: 0.010817
[18:35:47.419] iteration 22629: loss: 0.041782, loss_s1: 0.022921, loss_fp: 0.005307, loss_freq: 0.024968
[18:35:48.049] iteration 22630: loss: 0.059898, loss_s1: 0.027865, loss_fp: 0.002268, loss_freq: 0.045098
[18:35:48.677] iteration 22631: loss: 0.062360, loss_s1: 0.058614, loss_fp: 0.001014, loss_freq: 0.013745
[18:35:49.306] iteration 22632: loss: 0.046512, loss_s1: 0.031764, loss_fp: 0.005596, loss_freq: 0.019716
[18:35:49.931] iteration 22633: loss: 0.041606, loss_s1: 0.020146, loss_fp: 0.000561, loss_freq: 0.022205
[18:35:50.564] iteration 22634: loss: 0.045637, loss_s1: 0.052542, loss_fp: 0.000917, loss_freq: 0.006145
[18:35:51.221] iteration 22635: loss: 0.096562, loss_s1: 0.113658, loss_fp: 0.001647, loss_freq: 0.041778
[18:35:51.855] iteration 22636: loss: 0.046557, loss_s1: 0.033194, loss_fp: 0.001697, loss_freq: 0.029897
[18:35:52.491] iteration 22637: loss: 0.048445, loss_s1: 0.038689, loss_fp: 0.003787, loss_freq: 0.017098
[18:35:53.117] iteration 22638: loss: 0.043328, loss_s1: 0.016933, loss_fp: 0.000885, loss_freq: 0.031074
[18:35:53.761] iteration 22639: loss: 0.049929, loss_s1: 0.055027, loss_fp: 0.001804, loss_freq: 0.014554
[18:35:54.391] iteration 22640: loss: 0.069691, loss_s1: 0.072242, loss_fp: 0.012453, loss_freq: 0.021426
[18:35:55.021] iteration 22641: loss: 0.077869, loss_s1: 0.075180, loss_fp: 0.009834, loss_freq: 0.038323
[18:35:55.659] iteration 22642: loss: 0.077106, loss_s1: 0.046359, loss_fp: 0.015254, loss_freq: 0.056967
[18:35:56.291] iteration 22643: loss: 0.074940, loss_s1: 0.082465, loss_fp: 0.004048, loss_freq: 0.029739
[18:35:56.922] iteration 22644: loss: 0.058834, loss_s1: 0.037071, loss_fp: 0.007274, loss_freq: 0.038738
[18:35:57.556] iteration 22645: loss: 0.038631, loss_s1: 0.016949, loss_fp: 0.004595, loss_freq: 0.015165
[18:35:58.189] iteration 22646: loss: 0.054354, loss_s1: 0.052765, loss_fp: 0.003402, loss_freq: 0.023058
[18:35:58.820] iteration 22647: loss: 0.034238, loss_s1: 0.025451, loss_fp: 0.004098, loss_freq: 0.005521
[18:35:59.453] iteration 22648: loss: 0.071222, loss_s1: 0.043916, loss_fp: 0.003850, loss_freq: 0.038948
[18:36:00.081] iteration 22649: loss: 0.093130, loss_s1: 0.058857, loss_fp: 0.012854, loss_freq: 0.072919
[18:36:00.715] iteration 22650: loss: 0.043988, loss_s1: 0.018099, loss_fp: 0.009512, loss_freq: 0.026711
[18:36:01.345] iteration 22651: loss: 0.046850, loss_s1: 0.041655, loss_fp: 0.003869, loss_freq: 0.006407
[18:36:01.976] iteration 22652: loss: 0.061401, loss_s1: 0.044307, loss_fp: 0.004928, loss_freq: 0.041641
[18:36:02.609] iteration 22653: loss: 0.050560, loss_s1: 0.045053, loss_fp: 0.006302, loss_freq: 0.021595
[18:36:03.238] iteration 22654: loss: 0.058459, loss_s1: 0.039700, loss_fp: 0.001213, loss_freq: 0.021820
[18:36:03.867] iteration 22655: loss: 0.040735, loss_s1: 0.035637, loss_fp: 0.001563, loss_freq: 0.010024
[18:36:04.508] iteration 22656: loss: 0.061775, loss_s1: 0.028284, loss_fp: 0.003239, loss_freq: 0.022132
[18:36:05.147] iteration 22657: loss: 0.051678, loss_s1: 0.053210, loss_fp: 0.009786, loss_freq: 0.012538
[18:36:05.779] iteration 22658: loss: 0.028444, loss_s1: 0.014972, loss_fp: 0.000402, loss_freq: 0.008190
[18:36:06.415] iteration 22659: loss: 0.061260, loss_s1: 0.052363, loss_fp: 0.006084, loss_freq: 0.026242
[18:36:07.048] iteration 22660: loss: 0.105451, loss_s1: 0.089524, loss_fp: 0.012928, loss_freq: 0.078237
[18:36:07.676] iteration 22661: loss: 0.052975, loss_s1: 0.018050, loss_fp: 0.003630, loss_freq: 0.050147
[18:36:08.303] iteration 22662: loss: 0.038452, loss_s1: 0.018854, loss_fp: 0.002526, loss_freq: 0.017040
[18:36:08.933] iteration 22663: loss: 0.071501, loss_s1: 0.071359, loss_fp: 0.000451, loss_freq: 0.029750
[18:36:09.564] iteration 22664: loss: 0.036698, loss_s1: 0.028369, loss_fp: 0.000660, loss_freq: 0.008482
[18:36:10.195] iteration 22665: loss: 0.059030, loss_s1: 0.024465, loss_fp: 0.002867, loss_freq: 0.048503
[18:36:10.825] iteration 22666: loss: 0.074316, loss_s1: 0.062752, loss_fp: 0.003841, loss_freq: 0.027978
[18:36:11.455] iteration 22667: loss: 0.051239, loss_s1: 0.023804, loss_fp: 0.022040, loss_freq: 0.020899
[18:36:12.086] iteration 22668: loss: 0.046408, loss_s1: 0.018128, loss_fp: 0.002703, loss_freq: 0.031307
[18:36:12.715] iteration 22669: loss: 0.055526, loss_s1: 0.031333, loss_fp: 0.002049, loss_freq: 0.034150
[18:36:13.341] iteration 22670: loss: 0.043005, loss_s1: 0.034846, loss_fp: 0.004909, loss_freq: 0.012315
[18:36:13.969] iteration 22671: loss: 0.080752, loss_s1: 0.081481, loss_fp: 0.005130, loss_freq: 0.043273
[18:36:14.598] iteration 22672: loss: 0.059742, loss_s1: 0.072982, loss_fp: 0.003201, loss_freq: 0.014091
[18:36:15.232] iteration 22673: loss: 0.057505, loss_s1: 0.046826, loss_fp: 0.005194, loss_freq: 0.027489
[18:36:15.861] iteration 22674: loss: 0.039248, loss_s1: 0.034859, loss_fp: 0.002104, loss_freq: 0.005327
[18:36:16.499] iteration 22675: loss: 0.059409, loss_s1: 0.026656, loss_fp: 0.009013, loss_freq: 0.050627
[18:36:17.132] iteration 22676: loss: 0.066724, loss_s1: 0.055945, loss_fp: 0.006210, loss_freq: 0.039804
[18:36:17.767] iteration 22677: loss: 0.040664, loss_s1: 0.009933, loss_fp: 0.006662, loss_freq: 0.016787
[18:36:18.396] iteration 22678: loss: 0.066744, loss_s1: 0.062452, loss_fp: 0.005668, loss_freq: 0.041411
[18:36:19.023] iteration 22679: loss: 0.053203, loss_s1: 0.062638, loss_fp: 0.001529, loss_freq: 0.010156
[18:36:19.652] iteration 22680: loss: 0.058107, loss_s1: 0.029976, loss_fp: 0.002525, loss_freq: 0.026754
[18:36:20.284] iteration 22681: loss: 0.097304, loss_s1: 0.105617, loss_fp: 0.014936, loss_freq: 0.035229
[18:36:20.915] iteration 22682: loss: 0.061575, loss_s1: 0.033898, loss_fp: 0.003053, loss_freq: 0.025065
[18:36:21.542] iteration 22683: loss: 0.062271, loss_s1: 0.027678, loss_fp: 0.004969, loss_freq: 0.042392
[18:36:22.173] iteration 22684: loss: 0.080651, loss_s1: 0.080355, loss_fp: 0.002852, loss_freq: 0.036323
[18:36:22.800] iteration 22685: loss: 0.049192, loss_s1: 0.034752, loss_fp: 0.001341, loss_freq: 0.024585
[18:36:23.430] iteration 22686: loss: 0.077223, loss_s1: 0.083792, loss_fp: 0.009334, loss_freq: 0.018759
[18:36:24.061] iteration 22687: loss: 0.054706, loss_s1: 0.034966, loss_fp: 0.007656, loss_freq: 0.039881
[18:36:24.686] iteration 22688: loss: 0.049901, loss_s1: 0.054377, loss_fp: 0.001354, loss_freq: 0.016246
[18:36:25.316] iteration 22689: loss: 0.042411, loss_s1: 0.028409, loss_fp: 0.005736, loss_freq: 0.021158
[18:36:25.940] iteration 22690: loss: 0.087295, loss_s1: 0.057758, loss_fp: 0.005641, loss_freq: 0.068066
[18:36:26.567] iteration 22691: loss: 0.055683, loss_s1: 0.049658, loss_fp: 0.004541, loss_freq: 0.021215
[18:36:27.202] iteration 22692: loss: 0.091099, loss_s1: 0.090519, loss_fp: 0.008500, loss_freq: 0.050744
[18:36:27.826] iteration 22693: loss: 0.043959, loss_s1: 0.025648, loss_fp: 0.004034, loss_freq: 0.030372
[18:36:28.493] iteration 22694: loss: 0.067463, loss_s1: 0.051119, loss_fp: 0.001968, loss_freq: 0.032644
[18:36:29.123] iteration 22695: loss: 0.028581, loss_s1: 0.019162, loss_fp: 0.000823, loss_freq: 0.014101
[18:36:29.750] iteration 22696: loss: 0.045128, loss_s1: 0.036933, loss_fp: 0.001392, loss_freq: 0.015607
[18:36:30.379] iteration 22697: loss: 0.037412, loss_s1: 0.023945, loss_fp: 0.000403, loss_freq: 0.010021
[18:36:31.011] iteration 22698: loss: 0.070439, loss_s1: 0.080177, loss_fp: 0.002734, loss_freq: 0.024318
[18:36:31.640] iteration 22699: loss: 0.051329, loss_s1: 0.020904, loss_fp: 0.002427, loss_freq: 0.022450
[18:36:32.268] iteration 22700: loss: 0.057720, loss_s1: 0.039272, loss_fp: 0.006039, loss_freq: 0.029801
[18:36:32.894] iteration 22701: loss: 0.068973, loss_s1: 0.061882, loss_fp: 0.000802, loss_freq: 0.038072
[18:36:33.843] iteration 22702: loss: 0.049100, loss_s1: 0.048253, loss_fp: 0.001383, loss_freq: 0.006946
[18:36:34.479] iteration 22703: loss: 0.063469, loss_s1: 0.067062, loss_fp: 0.004080, loss_freq: 0.021024
[18:36:35.112] iteration 22704: loss: 0.036754, loss_s1: 0.027681, loss_fp: 0.000686, loss_freq: 0.009871
[18:36:35.749] iteration 22705: loss: 0.035775, loss_s1: 0.019541, loss_fp: 0.000610, loss_freq: 0.010475
[18:36:36.387] iteration 22706: loss: 0.059139, loss_s1: 0.046861, loss_fp: 0.002179, loss_freq: 0.024952
[18:36:37.016] iteration 22707: loss: 0.109353, loss_s1: 0.095258, loss_fp: 0.014580, loss_freq: 0.053662
[18:36:37.648] iteration 22708: loss: 0.028665, loss_s1: 0.016798, loss_fp: 0.003194, loss_freq: 0.009085
[18:36:38.274] iteration 22709: loss: 0.028218, loss_s1: 0.018165, loss_fp: 0.001399, loss_freq: 0.010611
[18:36:38.904] iteration 22710: loss: 0.052986, loss_s1: 0.040119, loss_fp: 0.007114, loss_freq: 0.034280
[18:36:39.533] iteration 22711: loss: 0.078852, loss_s1: 0.070698, loss_fp: 0.004582, loss_freq: 0.044651
[18:36:40.160] iteration 22712: loss: 0.032516, loss_s1: 0.021665, loss_fp: 0.001089, loss_freq: 0.011868
[18:36:40.795] iteration 22713: loss: 0.075070, loss_s1: 0.053322, loss_fp: 0.009043, loss_freq: 0.056271
[18:36:41.423] iteration 22714: loss: 0.085093, loss_s1: 0.026857, loss_fp: 0.014552, loss_freq: 0.101464
[18:36:42.056] iteration 22715: loss: 0.050901, loss_s1: 0.031356, loss_fp: 0.000785, loss_freq: 0.030711
[18:36:42.683] iteration 22716: loss: 0.050142, loss_s1: 0.045323, loss_fp: 0.014343, loss_freq: 0.011846
[18:36:43.318] iteration 22717: loss: 0.052156, loss_s1: 0.047963, loss_fp: 0.005180, loss_freq: 0.022214
[18:36:43.945] iteration 22718: loss: 0.036264, loss_s1: 0.022515, loss_fp: 0.002194, loss_freq: 0.006710
[18:36:44.575] iteration 22719: loss: 0.046946, loss_s1: 0.034608, loss_fp: 0.004022, loss_freq: 0.024011
[18:36:45.213] iteration 22720: loss: 0.046023, loss_s1: 0.032614, loss_fp: 0.001703, loss_freq: 0.024346
[18:36:45.856] iteration 22721: loss: 0.038956, loss_s1: 0.027180, loss_fp: 0.003845, loss_freq: 0.009086
[18:36:46.495] iteration 22722: loss: 0.071628, loss_s1: 0.065571, loss_fp: 0.001051, loss_freq: 0.031274
[18:36:47.133] iteration 22723: loss: 0.048458, loss_s1: 0.044518, loss_fp: 0.001142, loss_freq: 0.010926
[18:36:47.771] iteration 22724: loss: 0.053538, loss_s1: 0.047639, loss_fp: 0.001581, loss_freq: 0.018895
[18:36:48.401] iteration 22725: loss: 0.069335, loss_s1: 0.070653, loss_fp: 0.004879, loss_freq: 0.034550
[18:36:49.029] iteration 22726: loss: 0.038694, loss_s1: 0.037629, loss_fp: 0.000353, loss_freq: 0.008623
[18:36:49.657] iteration 22727: loss: 0.039866, loss_s1: 0.024861, loss_fp: 0.007475, loss_freq: 0.011952
[18:36:50.290] iteration 22728: loss: 0.032795, loss_s1: 0.032849, loss_fp: 0.000477, loss_freq: 0.005007
[18:36:50.918] iteration 22729: loss: 0.074701, loss_s1: 0.087594, loss_fp: 0.007696, loss_freq: 0.018534
[18:36:51.545] iteration 22730: loss: 0.071095, loss_s1: 0.040034, loss_fp: 0.019621, loss_freq: 0.046289
[18:36:52.179] iteration 22731: loss: 0.048104, loss_s1: 0.046162, loss_fp: 0.003738, loss_freq: 0.009158
[18:36:52.808] iteration 22732: loss: 0.054985, loss_s1: 0.055196, loss_fp: 0.001312, loss_freq: 0.023707
[18:36:53.433] iteration 22733: loss: 0.050519, loss_s1: 0.031332, loss_fp: 0.002516, loss_freq: 0.033406
[18:36:54.061] iteration 22734: loss: 0.055939, loss_s1: 0.043977, loss_fp: 0.002818, loss_freq: 0.022519
[18:36:54.693] iteration 22735: loss: 0.041715, loss_s1: 0.044379, loss_fp: 0.001903, loss_freq: 0.003992
[18:36:55.326] iteration 22736: loss: 0.054331, loss_s1: 0.034788, loss_fp: 0.003893, loss_freq: 0.028097
[18:36:55.953] iteration 22737: loss: 0.055783, loss_s1: 0.073462, loss_fp: 0.001468, loss_freq: 0.006036
[18:36:56.581] iteration 22738: loss: 0.075753, loss_s1: 0.065251, loss_fp: 0.008480, loss_freq: 0.036034
[18:36:57.209] iteration 22739: loss: 0.047545, loss_s1: 0.051525, loss_fp: 0.001683, loss_freq: 0.010709
[18:36:57.837] iteration 22740: loss: 0.077488, loss_s1: 0.076385, loss_fp: 0.001354, loss_freq: 0.037849
[18:36:58.476] iteration 22741: loss: 0.066543, loss_s1: 0.058433, loss_fp: 0.002411, loss_freq: 0.031512
[18:36:59.109] iteration 22742: loss: 0.053299, loss_s1: 0.046865, loss_fp: 0.003857, loss_freq: 0.012528
[18:36:59.736] iteration 22743: loss: 0.077705, loss_s1: 0.066304, loss_fp: 0.001701, loss_freq: 0.060638
[18:37:00.367] iteration 22744: loss: 0.065726, loss_s1: 0.052846, loss_fp: 0.016974, loss_freq: 0.034939
[18:37:00.999] iteration 22745: loss: 0.041326, loss_s1: 0.023576, loss_fp: 0.003223, loss_freq: 0.024138
[18:37:01.626] iteration 22746: loss: 0.067936, loss_s1: 0.074282, loss_fp: 0.009496, loss_freq: 0.018159
[18:37:02.254] iteration 22747: loss: 0.043051, loss_s1: 0.047212, loss_fp: 0.000934, loss_freq: 0.003095
[18:37:02.885] iteration 22748: loss: 0.028198, loss_s1: 0.013234, loss_fp: 0.002369, loss_freq: 0.005444
[18:37:03.513] iteration 22749: loss: 0.036817, loss_s1: 0.022497, loss_fp: 0.003658, loss_freq: 0.013313
[18:37:04.139] iteration 22750: loss: 0.068146, loss_s1: 0.081749, loss_fp: 0.001463, loss_freq: 0.016100
[18:37:04.764] iteration 22751: loss: 0.045553, loss_s1: 0.036904, loss_fp: 0.001924, loss_freq: 0.015141
[18:37:05.403] iteration 22752: loss: 0.085341, loss_s1: 0.110392, loss_fp: 0.002310, loss_freq: 0.024303
[18:37:06.037] iteration 22753: loss: 0.052967, loss_s1: 0.055653, loss_fp: 0.001353, loss_freq: 0.011620
[18:37:06.677] iteration 22754: loss: 0.037398, loss_s1: 0.028738, loss_fp: 0.002659, loss_freq: 0.015045
[18:37:07.307] iteration 22755: loss: 0.047115, loss_s1: 0.030980, loss_fp: 0.016625, loss_freq: 0.014753
[18:37:07.938] iteration 22756: loss: 0.042369, loss_s1: 0.036004, loss_fp: 0.001508, loss_freq: 0.017857
[18:37:08.571] iteration 22757: loss: 0.047645, loss_s1: 0.020643, loss_fp: 0.001777, loss_freq: 0.028744
[18:37:09.200] iteration 22758: loss: 0.048937, loss_s1: 0.041229, loss_fp: 0.001402, loss_freq: 0.010826
[18:37:09.827] iteration 22759: loss: 0.063260, loss_s1: 0.057909, loss_fp: 0.002482, loss_freq: 0.012367
[18:37:10.459] iteration 22760: loss: 0.051313, loss_s1: 0.061676, loss_fp: 0.001411, loss_freq: 0.008540
[18:37:11.083] iteration 22761: loss: 0.053893, loss_s1: 0.049943, loss_fp: 0.005203, loss_freq: 0.028512
[18:37:11.715] iteration 22762: loss: 0.055573, loss_s1: 0.040817, loss_fp: 0.003703, loss_freq: 0.026198
[18:37:12.343] iteration 22763: loss: 0.059940, loss_s1: 0.072689, loss_fp: 0.003092, loss_freq: 0.014623
[18:37:12.970] iteration 22764: loss: 0.037407, loss_s1: 0.022802, loss_fp: 0.002215, loss_freq: 0.015919
[18:37:13.595] iteration 22765: loss: 0.065919, loss_s1: 0.073825, loss_fp: 0.005138, loss_freq: 0.018022
[18:37:14.228] iteration 22766: loss: 0.037005, loss_s1: 0.030810, loss_fp: 0.003931, loss_freq: 0.008362
[18:37:14.854] iteration 22767: loss: 0.091885, loss_s1: 0.055672, loss_fp: 0.003989, loss_freq: 0.097840
[18:37:15.481] iteration 22768: loss: 0.088863, loss_s1: 0.049107, loss_fp: 0.004799, loss_freq: 0.059101
[18:37:16.107] iteration 22769: loss: 0.042176, loss_s1: 0.037806, loss_fp: 0.002007, loss_freq: 0.016814
[18:37:16.736] iteration 22770: loss: 0.070107, loss_s1: 0.068573, loss_fp: 0.002920, loss_freq: 0.030870
[18:37:17.365] iteration 22771: loss: 0.033339, loss_s1: 0.015299, loss_fp: 0.001437, loss_freq: 0.010521
[18:37:17.995] iteration 22772: loss: 0.074035, loss_s1: 0.085928, loss_fp: 0.013075, loss_freq: 0.017885
[18:37:18.624] iteration 22773: loss: 0.053441, loss_s1: 0.043847, loss_fp: 0.003409, loss_freq: 0.029270
[18:37:19.257] iteration 22774: loss: 0.047542, loss_s1: 0.041484, loss_fp: 0.003215, loss_freq: 0.016419
[18:37:19.885] iteration 22775: loss: 0.049431, loss_s1: 0.042436, loss_fp: 0.001866, loss_freq: 0.020240
[18:37:20.513] iteration 22776: loss: 0.043700, loss_s1: 0.033229, loss_fp: 0.001059, loss_freq: 0.019058
[18:37:21.138] iteration 22777: loss: 0.063170, loss_s1: 0.059773, loss_fp: 0.002259, loss_freq: 0.012045
[18:37:21.766] iteration 22778: loss: 0.052759, loss_s1: 0.056404, loss_fp: 0.007746, loss_freq: 0.014614
[18:37:22.397] iteration 22779: loss: 0.037915, loss_s1: 0.035062, loss_fp: 0.004748, loss_freq: 0.003798
[18:37:23.025] iteration 22780: loss: 0.032050, loss_s1: 0.024232, loss_fp: 0.000468, loss_freq: 0.007672
[18:37:23.653] iteration 22781: loss: 0.060496, loss_s1: 0.056974, loss_fp: 0.004663, loss_freq: 0.022977
[18:37:24.285] iteration 22782: loss: 0.073827, loss_s1: 0.075126, loss_fp: 0.001708, loss_freq: 0.028124
[18:37:24.925] iteration 22783: loss: 0.055096, loss_s1: 0.046677, loss_fp: 0.000819, loss_freq: 0.029987
[18:37:25.687] iteration 22784: loss: 0.041760, loss_s1: 0.039347, loss_fp: 0.002204, loss_freq: 0.014284
[18:37:26.601] iteration 22785: loss: 0.055782, loss_s1: 0.032078, loss_fp: 0.002154, loss_freq: 0.033517
[18:37:27.247] iteration 22786: loss: 0.060445, loss_s1: 0.056963, loss_fp: 0.002626, loss_freq: 0.033766
[18:37:27.874] iteration 22787: loss: 0.047822, loss_s1: 0.050038, loss_fp: 0.000885, loss_freq: 0.010531
[18:37:28.503] iteration 22788: loss: 0.059205, loss_s1: 0.023138, loss_fp: 0.009637, loss_freq: 0.027269
[18:37:29.130] iteration 22789: loss: 0.045840, loss_s1: 0.042218, loss_fp: 0.001337, loss_freq: 0.021110
[18:37:29.761] iteration 22790: loss: 0.046015, loss_s1: 0.032696, loss_fp: 0.005739, loss_freq: 0.023923
[18:37:30.390] iteration 22791: loss: 0.065786, loss_s1: 0.053869, loss_fp: 0.003051, loss_freq: 0.039990
[18:37:31.025] iteration 22792: loss: 0.038599, loss_s1: 0.017086, loss_fp: 0.004855, loss_freq: 0.010828
[18:37:31.664] iteration 22793: loss: 0.057193, loss_s1: 0.024342, loss_fp: 0.002525, loss_freq: 0.039242
[18:37:32.297] iteration 22794: loss: 0.086759, loss_s1: 0.052628, loss_fp: 0.001864, loss_freq: 0.021229
[18:37:32.932] iteration 22795: loss: 0.024875, loss_s1: 0.009136, loss_fp: 0.002463, loss_freq: 0.011490
[18:37:33.573] iteration 22796: loss: 0.035324, loss_s1: 0.025067, loss_fp: 0.002879, loss_freq: 0.019303
[18:37:34.206] iteration 22797: loss: 0.056718, loss_s1: 0.048527, loss_fp: 0.003491, loss_freq: 0.026908
[18:37:34.838] iteration 22798: loss: 0.040461, loss_s1: 0.021826, loss_fp: 0.002384, loss_freq: 0.023135
[18:37:35.465] iteration 22799: loss: 0.034164, loss_s1: 0.018611, loss_fp: 0.000729, loss_freq: 0.008618
[18:37:36.098] iteration 22800: loss: 0.045895, loss_s1: 0.039965, loss_fp: 0.001395, loss_freq: 0.021716
[18:37:39.382] iteration 22800 : mean_dice : 0.734001
[18:37:40.065] iteration 22801: loss: 0.040252, loss_s1: 0.030588, loss_fp: 0.002600, loss_freq: 0.018749
[18:37:40.699] iteration 22802: loss: 0.039305, loss_s1: 0.035581, loss_fp: 0.001790, loss_freq: 0.012935
[18:37:41.322] iteration 22803: loss: 0.082299, loss_s1: 0.053314, loss_fp: 0.005446, loss_freq: 0.071748
[18:37:41.955] iteration 22804: loss: 0.051374, loss_s1: 0.050984, loss_fp: 0.002004, loss_freq: 0.018741
[18:37:42.588] iteration 22805: loss: 0.035043, loss_s1: 0.019943, loss_fp: 0.003171, loss_freq: 0.015420
[18:37:43.219] iteration 22806: loss: 0.043448, loss_s1: 0.021577, loss_fp: 0.003046, loss_freq: 0.015090
[18:37:43.845] iteration 22807: loss: 0.041019, loss_s1: 0.015556, loss_fp: 0.001558, loss_freq: 0.032492
[18:37:44.474] iteration 22808: loss: 0.045270, loss_s1: 0.040208, loss_fp: 0.002268, loss_freq: 0.009655
[18:37:45.158] iteration 22809: loss: 0.063789, loss_s1: 0.064326, loss_fp: 0.001343, loss_freq: 0.024069
[18:37:45.806] iteration 22810: loss: 0.113706, loss_s1: 0.148768, loss_fp: 0.003315, loss_freq: 0.038177
[18:37:46.450] iteration 22811: loss: 0.069986, loss_s1: 0.084402, loss_fp: 0.001194, loss_freq: 0.021073
[18:37:47.077] iteration 22812: loss: 0.052496, loss_s1: 0.033046, loss_fp: 0.004944, loss_freq: 0.025002
[18:37:47.707] iteration 22813: loss: 0.075333, loss_s1: 0.050538, loss_fp: 0.002772, loss_freq: 0.062193
[18:37:48.336] iteration 22814: loss: 0.061278, loss_s1: 0.045347, loss_fp: 0.003243, loss_freq: 0.045068
[18:37:48.964] iteration 22815: loss: 0.081556, loss_s1: 0.073334, loss_fp: 0.004951, loss_freq: 0.044432
[18:37:49.591] iteration 22816: loss: 0.028187, loss_s1: 0.015460, loss_fp: 0.002183, loss_freq: 0.007127
[18:37:50.222] iteration 22817: loss: 0.065742, loss_s1: 0.057317, loss_fp: 0.004406, loss_freq: 0.035299
[18:37:50.853] iteration 22818: loss: 0.036300, loss_s1: 0.023479, loss_fp: 0.004562, loss_freq: 0.017022
[18:37:51.479] iteration 22819: loss: 0.037350, loss_s1: 0.024200, loss_fp: 0.001440, loss_freq: 0.011499
[18:37:52.108] iteration 22820: loss: 0.083014, loss_s1: 0.089359, loss_fp: 0.009735, loss_freq: 0.034493
[18:37:52.738] iteration 22821: loss: 0.117209, loss_s1: 0.111154, loss_fp: 0.017925, loss_freq: 0.069831
[18:37:53.368] iteration 22822: loss: 0.054465, loss_s1: 0.049356, loss_fp: 0.007078, loss_freq: 0.013936
[18:37:53.996] iteration 22823: loss: 0.067864, loss_s1: 0.047323, loss_fp: 0.019392, loss_freq: 0.021582
[18:37:54.626] iteration 22824: loss: 0.057991, loss_s1: 0.046656, loss_fp: 0.002271, loss_freq: 0.035706
[18:37:55.251] iteration 22825: loss: 0.040103, loss_s1: 0.018352, loss_fp: 0.008087, loss_freq: 0.019277
[18:37:55.876] iteration 22826: loss: 0.037610, loss_s1: 0.020824, loss_fp: 0.000911, loss_freq: 0.021656
[18:37:56.505] iteration 22827: loss: 0.063274, loss_s1: 0.047574, loss_fp: 0.008829, loss_freq: 0.024978
[18:37:57.133] iteration 22828: loss: 0.062406, loss_s1: 0.071568, loss_fp: 0.000304, loss_freq: 0.015050
[18:37:57.762] iteration 22829: loss: 0.067592, loss_s1: 0.038779, loss_fp: 0.002459, loss_freq: 0.030012
[18:37:58.394] iteration 22830: loss: 0.045056, loss_s1: 0.036067, loss_fp: 0.006292, loss_freq: 0.019067
[18:37:59.023] iteration 22831: loss: 0.033314, loss_s1: 0.030321, loss_fp: 0.003486, loss_freq: 0.005156
[18:37:59.650] iteration 22832: loss: 0.060649, loss_s1: 0.049881, loss_fp: 0.002433, loss_freq: 0.045167
[18:38:00.280] iteration 22833: loss: 0.080427, loss_s1: 0.086414, loss_fp: 0.003329, loss_freq: 0.037060
[18:38:00.907] iteration 22834: loss: 0.054470, loss_s1: 0.043984, loss_fp: 0.005157, loss_freq: 0.017662
[18:38:01.541] iteration 22835: loss: 0.044543, loss_s1: 0.024826, loss_fp: 0.002354, loss_freq: 0.005550
[18:38:02.169] iteration 22836: loss: 0.054804, loss_s1: 0.037986, loss_fp: 0.009973, loss_freq: 0.023420
[18:38:02.795] iteration 22837: loss: 0.068856, loss_s1: 0.065803, loss_fp: 0.005576, loss_freq: 0.040872
[18:38:03.420] iteration 22838: loss: 0.027088, loss_s1: 0.014707, loss_fp: 0.001588, loss_freq: 0.004598
[18:38:04.050] iteration 22839: loss: 0.045726, loss_s1: 0.029155, loss_fp: 0.002703, loss_freq: 0.031580
[18:38:04.676] iteration 22840: loss: 0.040283, loss_s1: 0.045724, loss_fp: 0.001929, loss_freq: 0.006628
[18:38:05.304] iteration 22841: loss: 0.075535, loss_s1: 0.063291, loss_fp: 0.007634, loss_freq: 0.035766
[18:38:05.930] iteration 22842: loss: 0.060679, loss_s1: 0.064257, loss_fp: 0.001888, loss_freq: 0.028333
[18:38:06.558] iteration 22843: loss: 0.057389, loss_s1: 0.043279, loss_fp: 0.001305, loss_freq: 0.031973
[18:38:07.184] iteration 22844: loss: 0.068667, loss_s1: 0.068344, loss_fp: 0.002845, loss_freq: 0.036289
[18:38:07.810] iteration 22845: loss: 0.056488, loss_s1: 0.049972, loss_fp: 0.005851, loss_freq: 0.017718
[18:38:08.437] iteration 22846: loss: 0.053891, loss_s1: 0.060582, loss_fp: 0.002647, loss_freq: 0.012326
[18:38:09.064] iteration 22847: loss: 0.046759, loss_s1: 0.029744, loss_fp: 0.007679, loss_freq: 0.011948
[18:38:09.692] iteration 22848: loss: 0.057845, loss_s1: 0.033533, loss_fp: 0.006761, loss_freq: 0.044159
[18:38:10.321] iteration 22849: loss: 0.045948, loss_s1: 0.052088, loss_fp: 0.002524, loss_freq: 0.010985
[18:38:10.948] iteration 22850: loss: 0.049787, loss_s1: 0.025902, loss_fp: 0.008936, loss_freq: 0.032154
[18:38:11.580] iteration 22851: loss: 0.072423, loss_s1: 0.047869, loss_fp: 0.012579, loss_freq: 0.050297
[18:38:12.212] iteration 22852: loss: 0.048998, loss_s1: 0.018148, loss_fp: 0.001835, loss_freq: 0.037571
[18:38:12.845] iteration 22853: loss: 0.095406, loss_s1: 0.069768, loss_fp: 0.016925, loss_freq: 0.076557
[18:38:13.477] iteration 22854: loss: 0.043337, loss_s1: 0.038770, loss_fp: 0.004141, loss_freq: 0.013486
[18:38:14.102] iteration 22855: loss: 0.049868, loss_s1: 0.031411, loss_fp: 0.008133, loss_freq: 0.017863
[18:38:14.736] iteration 22856: loss: 0.039391, loss_s1: 0.022618, loss_fp: 0.002133, loss_freq: 0.021068
[18:38:15.364] iteration 22857: loss: 0.042354, loss_s1: 0.027202, loss_fp: 0.002627, loss_freq: 0.017804
[18:38:16.015] iteration 22858: loss: 0.041445, loss_s1: 0.027971, loss_fp: 0.000610, loss_freq: 0.013159
[18:38:16.661] iteration 22859: loss: 0.080297, loss_s1: 0.091562, loss_fp: 0.005160, loss_freq: 0.027044
[18:38:17.289] iteration 22860: loss: 0.047512, loss_s1: 0.044513, loss_fp: 0.005667, loss_freq: 0.012875
[18:38:17.912] iteration 22861: loss: 0.040595, loss_s1: 0.035915, loss_fp: 0.001423, loss_freq: 0.013715
[18:38:18.537] iteration 22862: loss: 0.048974, loss_s1: 0.039551, loss_fp: 0.002099, loss_freq: 0.018148
[18:38:19.487] iteration 22863: loss: 0.038692, loss_s1: 0.034251, loss_fp: 0.002140, loss_freq: 0.010501
[18:38:20.113] iteration 22864: loss: 0.047314, loss_s1: 0.018343, loss_fp: 0.002689, loss_freq: 0.024804
[18:38:20.772] iteration 22865: loss: 0.042522, loss_s1: 0.039761, loss_fp: 0.001855, loss_freq: 0.011661
[18:38:21.403] iteration 22866: loss: 0.041794, loss_s1: 0.024689, loss_fp: 0.007612, loss_freq: 0.017147
[18:38:22.034] iteration 22867: loss: 0.035946, loss_s1: 0.012229, loss_fp: 0.000465, loss_freq: 0.024602
[18:38:22.669] iteration 22868: loss: 0.110792, loss_s1: 0.075471, loss_fp: 0.009409, loss_freq: 0.064774
[18:38:23.298] iteration 22869: loss: 0.051221, loss_s1: 0.050923, loss_fp: 0.005566, loss_freq: 0.013906
[18:38:23.928] iteration 22870: loss: 0.051780, loss_s1: 0.055702, loss_fp: 0.004871, loss_freq: 0.011942
[18:38:24.564] iteration 22871: loss: 0.072088, loss_s1: 0.055730, loss_fp: 0.011445, loss_freq: 0.035172
[18:38:25.200] iteration 22872: loss: 0.076965, loss_s1: 0.056682, loss_fp: 0.017683, loss_freq: 0.030584
[18:38:25.834] iteration 22873: loss: 0.036841, loss_s1: 0.022167, loss_fp: 0.001310, loss_freq: 0.009175
[18:38:26.466] iteration 22874: loss: 0.055694, loss_s1: 0.037674, loss_fp: 0.002035, loss_freq: 0.038834
[18:38:27.096] iteration 22875: loss: 0.095942, loss_s1: 0.057711, loss_fp: 0.006269, loss_freq: 0.095622
[18:38:27.725] iteration 22876: loss: 0.045441, loss_s1: 0.034609, loss_fp: 0.007927, loss_freq: 0.013173
[18:38:28.359] iteration 22877: loss: 0.051738, loss_s1: 0.047100, loss_fp: 0.006325, loss_freq: 0.024160
[18:38:28.984] iteration 22878: loss: 0.059085, loss_s1: 0.035487, loss_fp: 0.011685, loss_freq: 0.037114
[18:38:29.614] iteration 22879: loss: 0.044150, loss_s1: 0.023860, loss_fp: 0.004628, loss_freq: 0.009380
[18:38:30.244] iteration 22880: loss: 0.059778, loss_s1: 0.038245, loss_fp: 0.007558, loss_freq: 0.030984
[18:38:30.872] iteration 22881: loss: 0.044701, loss_s1: 0.038537, loss_fp: 0.002850, loss_freq: 0.013404
[18:38:31.498] iteration 22882: loss: 0.056239, loss_s1: 0.052692, loss_fp: 0.001554, loss_freq: 0.019388
[18:38:32.125] iteration 22883: loss: 0.037919, loss_s1: 0.032240, loss_fp: 0.001633, loss_freq: 0.006175
[18:38:32.758] iteration 22884: loss: 0.046095, loss_s1: 0.032155, loss_fp: 0.004607, loss_freq: 0.017925
[18:38:33.383] iteration 22885: loss: 0.049581, loss_s1: 0.030806, loss_fp: 0.002915, loss_freq: 0.012170
[18:38:34.009] iteration 22886: loss: 0.074972, loss_s1: 0.078836, loss_fp: 0.005370, loss_freq: 0.037020
[18:38:34.660] iteration 22887: loss: 0.047943, loss_s1: 0.032599, loss_fp: 0.010973, loss_freq: 0.022013
[18:38:35.292] iteration 22888: loss: 0.045396, loss_s1: 0.012319, loss_fp: 0.001846, loss_freq: 0.029409
[18:38:35.922] iteration 22889: loss: 0.028090, loss_s1: 0.011706, loss_fp: 0.003040, loss_freq: 0.009936
[18:38:36.568] iteration 22890: loss: 0.091030, loss_s1: 0.080043, loss_fp: 0.024125, loss_freq: 0.038750
[18:38:37.199] iteration 22891: loss: 0.061368, loss_s1: 0.060516, loss_fp: 0.004012, loss_freq: 0.026619
[18:38:37.828] iteration 22892: loss: 0.038850, loss_s1: 0.023060, loss_fp: 0.002534, loss_freq: 0.016320
[18:38:38.454] iteration 22893: loss: 0.043084, loss_s1: 0.033598, loss_fp: 0.006767, loss_freq: 0.010697
[18:38:39.084] iteration 22894: loss: 0.046150, loss_s1: 0.033958, loss_fp: 0.001306, loss_freq: 0.008125
[18:38:39.711] iteration 22895: loss: 0.054416, loss_s1: 0.041216, loss_fp: 0.004073, loss_freq: 0.030983
[18:38:40.340] iteration 22896: loss: 0.033138, loss_s1: 0.029000, loss_fp: 0.002288, loss_freq: 0.006427
[18:38:40.966] iteration 22897: loss: 0.070845, loss_s1: 0.063898, loss_fp: 0.001756, loss_freq: 0.023953
[18:38:41.593] iteration 22898: loss: 0.049041, loss_s1: 0.042768, loss_fp: 0.004122, loss_freq: 0.023122
[18:38:42.226] iteration 22899: loss: 0.074483, loss_s1: 0.068377, loss_fp: 0.009133, loss_freq: 0.027651
[18:38:42.858] iteration 22900: loss: 0.042083, loss_s1: 0.030316, loss_fp: 0.005052, loss_freq: 0.008663
[18:38:43.495] iteration 22901: loss: 0.113618, loss_s1: 0.097545, loss_fp: 0.006820, loss_freq: 0.079910
[18:38:44.122] iteration 22902: loss: 0.052459, loss_s1: 0.042408, loss_fp: 0.001449, loss_freq: 0.027271
[18:38:44.793] iteration 22903: loss: 0.069184, loss_s1: 0.047827, loss_fp: 0.007091, loss_freq: 0.017130
[18:38:45.418] iteration 22904: loss: 0.086487, loss_s1: 0.104040, loss_fp: 0.001069, loss_freq: 0.039021
[18:38:46.048] iteration 22905: loss: 0.041907, loss_s1: 0.030709, loss_fp: 0.000356, loss_freq: 0.019470
[18:38:46.687] iteration 22906: loss: 0.037771, loss_s1: 0.013109, loss_fp: 0.001865, loss_freq: 0.034693
[18:38:47.321] iteration 22907: loss: 0.047738, loss_s1: 0.022239, loss_fp: 0.002188, loss_freq: 0.021908
[18:38:47.955] iteration 22908: loss: 0.041572, loss_s1: 0.038827, loss_fp: 0.006306, loss_freq: 0.005438
[18:38:48.591] iteration 22909: loss: 0.028333, loss_s1: 0.018417, loss_fp: 0.002371, loss_freq: 0.006565
[18:38:49.220] iteration 22910: loss: 0.048477, loss_s1: 0.037685, loss_fp: 0.003804, loss_freq: 0.023623
[18:38:49.850] iteration 22911: loss: 0.043033, loss_s1: 0.030449, loss_fp: 0.003976, loss_freq: 0.010674
[18:38:50.480] iteration 22912: loss: 0.057099, loss_s1: 0.036301, loss_fp: 0.004277, loss_freq: 0.049514
[18:38:51.109] iteration 22913: loss: 0.063967, loss_s1: 0.058815, loss_fp: 0.001727, loss_freq: 0.026450
[18:38:51.743] iteration 22914: loss: 0.077824, loss_s1: 0.079217, loss_fp: 0.003908, loss_freq: 0.025083
[18:38:52.371] iteration 22915: loss: 0.037249, loss_s1: 0.021003, loss_fp: 0.005846, loss_freq: 0.013284
[18:38:53.000] iteration 22916: loss: 0.057214, loss_s1: 0.033024, loss_fp: 0.000868, loss_freq: 0.046173
[18:38:53.634] iteration 22917: loss: 0.033692, loss_s1: 0.019005, loss_fp: 0.001559, loss_freq: 0.007304
[18:38:54.263] iteration 22918: loss: 0.072010, loss_s1: 0.077733, loss_fp: 0.007352, loss_freq: 0.019348
[18:38:54.900] iteration 22919: loss: 0.034581, loss_s1: 0.017991, loss_fp: 0.002354, loss_freq: 0.005568
[18:38:55.531] iteration 22920: loss: 0.041608, loss_s1: 0.017392, loss_fp: 0.001904, loss_freq: 0.020312
[18:38:56.164] iteration 22921: loss: 0.032867, loss_s1: 0.015388, loss_fp: 0.000771, loss_freq: 0.018457
[18:38:56.795] iteration 22922: loss: 0.033844, loss_s1: 0.016437, loss_fp: 0.001134, loss_freq: 0.021888
[18:38:57.425] iteration 22923: loss: 0.048310, loss_s1: 0.038249, loss_fp: 0.004814, loss_freq: 0.026645
[18:38:58.056] iteration 22924: loss: 0.050717, loss_s1: 0.027957, loss_fp: 0.006109, loss_freq: 0.027890
[18:38:58.686] iteration 22925: loss: 0.049630, loss_s1: 0.036059, loss_fp: 0.001201, loss_freq: 0.014671
[18:38:59.312] iteration 22926: loss: 0.061372, loss_s1: 0.070232, loss_fp: 0.003116, loss_freq: 0.021689
[18:38:59.939] iteration 22927: loss: 0.047742, loss_s1: 0.013451, loss_fp: 0.003364, loss_freq: 0.036990
[18:39:00.570] iteration 22928: loss: 0.066040, loss_s1: 0.025026, loss_fp: 0.002950, loss_freq: 0.074390
[18:39:01.196] iteration 22929: loss: 0.063870, loss_s1: 0.054800, loss_fp: 0.004911, loss_freq: 0.027617
[18:39:01.835] iteration 22930: loss: 0.065842, loss_s1: 0.060184, loss_fp: 0.003874, loss_freq: 0.035202
[18:39:02.461] iteration 22931: loss: 0.038805, loss_s1: 0.027901, loss_fp: 0.002817, loss_freq: 0.013740
[18:39:03.091] iteration 22932: loss: 0.071227, loss_s1: 0.036726, loss_fp: 0.001591, loss_freq: 0.062187
[18:39:03.717] iteration 22933: loss: 0.101892, loss_s1: 0.080348, loss_fp: 0.014372, loss_freq: 0.040597
[18:39:04.353] iteration 22934: loss: 0.042387, loss_s1: 0.027084, loss_fp: 0.001623, loss_freq: 0.020453
[18:39:04.985] iteration 22935: loss: 0.064139, loss_s1: 0.063349, loss_fp: 0.003961, loss_freq: 0.030470
[18:39:05.617] iteration 22936: loss: 0.046749, loss_s1: 0.033490, loss_fp: 0.004302, loss_freq: 0.014493
[18:39:06.253] iteration 22937: loss: 0.065794, loss_s1: 0.079683, loss_fp: 0.002409, loss_freq: 0.006265
[18:39:06.884] iteration 22938: loss: 0.045288, loss_s1: 0.040866, loss_fp: 0.001878, loss_freq: 0.005017
[18:39:07.516] iteration 22939: loss: 0.038562, loss_s1: 0.029626, loss_fp: 0.002406, loss_freq: 0.014241
[18:39:08.140] iteration 22940: loss: 0.040505, loss_s1: 0.033739, loss_fp: 0.000905, loss_freq: 0.019169
[18:39:08.767] iteration 22941: loss: 0.026649, loss_s1: 0.017252, loss_fp: 0.001046, loss_freq: 0.005451
[18:39:09.397] iteration 22942: loss: 0.059371, loss_s1: 0.048727, loss_fp: 0.003722, loss_freq: 0.029125
[18:39:10.025] iteration 22943: loss: 0.059582, loss_s1: 0.063487, loss_fp: 0.001863, loss_freq: 0.022448
[18:39:10.668] iteration 22944: loss: 0.051033, loss_s1: 0.018835, loss_fp: 0.008005, loss_freq: 0.035740
[18:39:11.296] iteration 22945: loss: 0.099236, loss_s1: 0.080078, loss_fp: 0.006098, loss_freq: 0.086404
[18:39:11.927] iteration 22946: loss: 0.074714, loss_s1: 0.030748, loss_fp: 0.008150, loss_freq: 0.042666
[18:39:12.554] iteration 22947: loss: 0.147886, loss_s1: 0.121674, loss_fp: 0.018384, loss_freq: 0.130878
[18:39:13.182] iteration 22948: loss: 0.048307, loss_s1: 0.045016, loss_fp: 0.003644, loss_freq: 0.018088
[18:39:13.812] iteration 22949: loss: 0.066792, loss_s1: 0.061567, loss_fp: 0.000664, loss_freq: 0.019786
[18:39:14.464] iteration 22950: loss: 0.032879, loss_s1: 0.016164, loss_fp: 0.004992, loss_freq: 0.012193
[18:39:15.093] iteration 22951: loss: 0.102901, loss_s1: 0.103649, loss_fp: 0.003897, loss_freq: 0.065243
[18:39:15.723] iteration 22952: loss: 0.056805, loss_s1: 0.039294, loss_fp: 0.007969, loss_freq: 0.033430
[18:39:16.349] iteration 22953: loss: 0.069581, loss_s1: 0.046282, loss_fp: 0.004788, loss_freq: 0.042364
[18:39:16.975] iteration 22954: loss: 0.057521, loss_s1: 0.026225, loss_fp: 0.006003, loss_freq: 0.036097
[18:39:17.600] iteration 22955: loss: 0.053559, loss_s1: 0.022111, loss_fp: 0.003037, loss_freq: 0.018082
[18:39:18.227] iteration 22956: loss: 0.056727, loss_s1: 0.030234, loss_fp: 0.013691, loss_freq: 0.042468
[18:39:18.854] iteration 22957: loss: 0.038880, loss_s1: 0.030096, loss_fp: 0.004007, loss_freq: 0.009695
[18:39:19.484] iteration 22958: loss: 0.050163, loss_s1: 0.039630, loss_fp: 0.005679, loss_freq: 0.027115
[18:39:20.113] iteration 22959: loss: 0.033647, loss_s1: 0.021369, loss_fp: 0.001004, loss_freq: 0.016918
[18:39:20.742] iteration 22960: loss: 0.043333, loss_s1: 0.021834, loss_fp: 0.004592, loss_freq: 0.022987
[18:39:21.368] iteration 22961: loss: 0.053739, loss_s1: 0.045487, loss_fp: 0.006972, loss_freq: 0.015350
[18:39:21.993] iteration 22962: loss: 0.047018, loss_s1: 0.031085, loss_fp: 0.011969, loss_freq: 0.013673
[18:39:22.622] iteration 22963: loss: 0.060479, loss_s1: 0.046930, loss_fp: 0.001674, loss_freq: 0.029004
[18:39:23.250] iteration 22964: loss: 0.089875, loss_s1: 0.054005, loss_fp: 0.009577, loss_freq: 0.062645
[18:39:23.879] iteration 22965: loss: 0.070135, loss_s1: 0.065920, loss_fp: 0.001014, loss_freq: 0.035854
[18:39:24.508] iteration 22966: loss: 0.068199, loss_s1: 0.032487, loss_fp: 0.008675, loss_freq: 0.035836
[18:39:25.142] iteration 22967: loss: 0.045495, loss_s1: 0.024934, loss_fp: 0.002475, loss_freq: 0.014242
[18:39:25.787] iteration 22968: loss: 0.047925, loss_s1: 0.029606, loss_fp: 0.003620, loss_freq: 0.019451
[18:39:26.414] iteration 22969: loss: 0.048925, loss_s1: 0.025711, loss_fp: 0.008000, loss_freq: 0.024825
[18:39:27.048] iteration 22970: loss: 0.101959, loss_s1: 0.059383, loss_fp: 0.001749, loss_freq: 0.104903
[18:39:27.690] iteration 22971: loss: 0.083208, loss_s1: 0.072299, loss_fp: 0.011974, loss_freq: 0.041679
[18:39:28.327] iteration 22972: loss: 0.050582, loss_s1: 0.037139, loss_fp: 0.001253, loss_freq: 0.031616
[18:39:28.961] iteration 22973: loss: 0.053213, loss_s1: 0.041377, loss_fp: 0.004701, loss_freq: 0.012550
[18:39:29.634] iteration 22974: loss: 0.082081, loss_s1: 0.074244, loss_fp: 0.014467, loss_freq: 0.043437
[18:39:30.281] iteration 22975: loss: 0.030742, loss_s1: 0.015705, loss_fp: 0.000900, loss_freq: 0.016857
[18:39:30.914] iteration 22976: loss: 0.036846, loss_s1: 0.017959, loss_fp: 0.003837, loss_freq: 0.011704
[18:39:31.542] iteration 22977: loss: 0.041359, loss_s1: 0.036909, loss_fp: 0.000680, loss_freq: 0.010435
[18:39:32.171] iteration 22978: loss: 0.060701, loss_s1: 0.047221, loss_fp: 0.004231, loss_freq: 0.019678
[18:39:32.801] iteration 22979: loss: 0.034678, loss_s1: 0.025003, loss_fp: 0.001917, loss_freq: 0.009835
[18:39:33.434] iteration 22980: loss: 0.032771, loss_s1: 0.024086, loss_fp: 0.000833, loss_freq: 0.011096
[18:39:34.060] iteration 22981: loss: 0.052561, loss_s1: 0.042420, loss_fp: 0.002607, loss_freq: 0.022063
[18:39:34.687] iteration 22982: loss: 0.072575, loss_s1: 0.033514, loss_fp: 0.011499, loss_freq: 0.073235
[18:39:35.315] iteration 22983: loss: 0.060366, loss_s1: 0.040725, loss_fp: 0.007896, loss_freq: 0.042441
[18:39:35.954] iteration 22984: loss: 0.046202, loss_s1: 0.023737, loss_fp: 0.001905, loss_freq: 0.023472
[18:39:36.585] iteration 22985: loss: 0.040365, loss_s1: 0.022896, loss_fp: 0.008272, loss_freq: 0.007475
[18:39:37.218] iteration 22986: loss: 0.055014, loss_s1: 0.053993, loss_fp: 0.006396, loss_freq: 0.017155
[18:39:37.853] iteration 22987: loss: 0.030400, loss_s1: 0.013319, loss_fp: 0.002808, loss_freq: 0.011417
[18:39:38.477] iteration 22988: loss: 0.070854, loss_s1: 0.048636, loss_fp: 0.001905, loss_freq: 0.047255
[18:39:39.102] iteration 22989: loss: 0.039599, loss_s1: 0.027426, loss_fp: 0.003261, loss_freq: 0.005990
[18:39:39.734] iteration 22990: loss: 0.109549, loss_s1: 0.099124, loss_fp: 0.004936, loss_freq: 0.063884
[18:39:40.363] iteration 22991: loss: 0.062327, loss_s1: 0.052613, loss_fp: 0.004587, loss_freq: 0.035947
[18:39:40.995] iteration 22992: loss: 0.061833, loss_s1: 0.037151, loss_fp: 0.005528, loss_freq: 0.052124
[18:39:41.625] iteration 22993: loss: 0.050436, loss_s1: 0.024886, loss_fp: 0.002358, loss_freq: 0.041151
[18:39:42.268] iteration 22994: loss: 0.060188, loss_s1: 0.051036, loss_fp: 0.003362, loss_freq: 0.029777
[18:39:42.925] iteration 22995: loss: 0.058100, loss_s1: 0.047051, loss_fp: 0.000995, loss_freq: 0.026451
[18:39:43.566] iteration 22996: loss: 0.045012, loss_s1: 0.043867, loss_fp: 0.004529, loss_freq: 0.009925
[18:39:44.206] iteration 22997: loss: 0.099668, loss_s1: 0.098726, loss_fp: 0.005981, loss_freq: 0.060724
[18:39:44.846] iteration 22998: loss: 0.037910, loss_s1: 0.023632, loss_fp: 0.003830, loss_freq: 0.016783
[18:39:45.481] iteration 22999: loss: 0.034711, loss_s1: 0.008851, loss_fp: 0.000991, loss_freq: 0.008599
[18:39:46.123] iteration 23000: loss: 0.080666, loss_s1: 0.111082, loss_fp: 0.001376, loss_freq: 0.015811
[18:39:49.286] iteration 23000 : mean_dice : 0.712286
[18:39:49.936] iteration 23001: loss: 0.041114, loss_s1: 0.032061, loss_fp: 0.007707, loss_freq: 0.011943
[18:39:50.568] iteration 23002: loss: 0.087460, loss_s1: 0.059427, loss_fp: 0.018567, loss_freq: 0.053182
[18:39:51.203] iteration 23003: loss: 0.063107, loss_s1: 0.052851, loss_fp: 0.001597, loss_freq: 0.036341
[18:39:51.835] iteration 23004: loss: 0.052647, loss_s1: 0.052544, loss_fp: 0.006726, loss_freq: 0.015103
[18:39:52.470] iteration 23005: loss: 0.069540, loss_s1: 0.041693, loss_fp: 0.004945, loss_freq: 0.043896
[18:39:53.101] iteration 23006: loss: 0.059268, loss_s1: 0.042204, loss_fp: 0.006043, loss_freq: 0.032996
[18:39:53.732] iteration 23007: loss: 0.032304, loss_s1: 0.018311, loss_fp: 0.001497, loss_freq: 0.007030
[18:39:54.365] iteration 23008: loss: 0.057954, loss_s1: 0.031327, loss_fp: 0.013664, loss_freq: 0.017000
[18:39:54.993] iteration 23009: loss: 0.067126, loss_s1: 0.033390, loss_fp: 0.007328, loss_freq: 0.061959
[18:39:55.620] iteration 23010: loss: 0.056658, loss_s1: 0.075585, loss_fp: 0.000982, loss_freq: 0.009054
[18:39:56.247] iteration 23011: loss: 0.053264, loss_s1: 0.041813, loss_fp: 0.001693, loss_freq: 0.022536
[18:39:56.884] iteration 23012: loss: 0.063752, loss_s1: 0.030746, loss_fp: 0.002722, loss_freq: 0.053476
[18:39:57.512] iteration 23013: loss: 0.077070, loss_s1: 0.056777, loss_fp: 0.005599, loss_freq: 0.040227
[18:39:58.139] iteration 23014: loss: 0.047774, loss_s1: 0.034239, loss_fp: 0.003678, loss_freq: 0.027913
[18:39:58.765] iteration 23015: loss: 0.053231, loss_s1: 0.045496, loss_fp: 0.002246, loss_freq: 0.026934
[18:39:59.393] iteration 23016: loss: 0.064158, loss_s1: 0.047573, loss_fp: 0.001951, loss_freq: 0.023773
[18:40:00.042] iteration 23017: loss: 0.033476, loss_s1: 0.020189, loss_fp: 0.003653, loss_freq: 0.012936
[18:40:00.669] iteration 23018: loss: 0.055747, loss_s1: 0.037844, loss_fp: 0.001194, loss_freq: 0.033582
[18:40:01.292] iteration 23019: loss: 0.029887, loss_s1: 0.008206, loss_fp: 0.000573, loss_freq: 0.013866
[18:40:01.921] iteration 23020: loss: 0.056858, loss_s1: 0.057145, loss_fp: 0.001308, loss_freq: 0.019032
[18:40:02.548] iteration 23021: loss: 0.065898, loss_s1: 0.060198, loss_fp: 0.009584, loss_freq: 0.022413
[18:40:03.174] iteration 23022: loss: 0.050252, loss_s1: 0.037326, loss_fp: 0.008974, loss_freq: 0.014856
[18:40:03.801] iteration 23023: loss: 0.043109, loss_s1: 0.013739, loss_fp: 0.003321, loss_freq: 0.029356
[18:40:04.773] iteration 23024: loss: 0.043414, loss_s1: 0.029338, loss_fp: 0.001977, loss_freq: 0.009642
[18:40:05.403] iteration 23025: loss: 0.037605, loss_s1: 0.019748, loss_fp: 0.002153, loss_freq: 0.018022
[18:40:06.029] iteration 23026: loss: 0.062139, loss_s1: 0.067616, loss_fp: 0.001560, loss_freq: 0.009011
[18:40:06.655] iteration 23027: loss: 0.047486, loss_s1: 0.042946, loss_fp: 0.000883, loss_freq: 0.010417
[18:40:07.287] iteration 23028: loss: 0.060121, loss_s1: 0.063116, loss_fp: 0.001320, loss_freq: 0.021607
[18:40:07.915] iteration 23029: loss: 0.099963, loss_s1: 0.079668, loss_fp: 0.031693, loss_freq: 0.030573
[18:40:08.543] iteration 23030: loss: 0.037013, loss_s1: 0.022742, loss_fp: 0.002353, loss_freq: 0.015054
[18:40:09.166] iteration 23031: loss: 0.056768, loss_s1: 0.067028, loss_fp: 0.003852, loss_freq: 0.016038
[18:40:09.797] iteration 23032: loss: 0.055672, loss_s1: 0.035166, loss_fp: 0.002131, loss_freq: 0.041578
[18:40:10.420] iteration 23033: loss: 0.073505, loss_s1: 0.073991, loss_fp: 0.002883, loss_freq: 0.025436
[18:40:11.050] iteration 23034: loss: 0.030088, loss_s1: 0.017707, loss_fp: 0.001987, loss_freq: 0.005084
[18:40:11.675] iteration 23035: loss: 0.059014, loss_s1: 0.068126, loss_fp: 0.003637, loss_freq: 0.016953
[18:40:12.302] iteration 23036: loss: 0.047275, loss_s1: 0.039825, loss_fp: 0.004697, loss_freq: 0.022812
[18:40:12.927] iteration 23037: loss: 0.049901, loss_s1: 0.029946, loss_fp: 0.004742, loss_freq: 0.026416
[18:40:13.555] iteration 23038: loss: 0.052832, loss_s1: 0.052792, loss_fp: 0.001275, loss_freq: 0.022239
[18:40:14.182] iteration 23039: loss: 0.144650, loss_s1: 0.088664, loss_fp: 0.018298, loss_freq: 0.136759
[18:40:14.811] iteration 23040: loss: 0.054786, loss_s1: 0.035125, loss_fp: 0.000951, loss_freq: 0.017772
[18:40:15.451] iteration 23041: loss: 0.068694, loss_s1: 0.057683, loss_fp: 0.003224, loss_freq: 0.044444
[18:40:16.092] iteration 23042: loss: 0.035028, loss_s1: 0.019283, loss_fp: 0.000666, loss_freq: 0.015832
[18:40:16.735] iteration 23043: loss: 0.058175, loss_s1: 0.038886, loss_fp: 0.008845, loss_freq: 0.017398
[18:40:17.364] iteration 23044: loss: 0.031979, loss_s1: 0.017333, loss_fp: 0.001489, loss_freq: 0.004558
[18:40:18.024] iteration 23045: loss: 0.042082, loss_s1: 0.024799, loss_fp: 0.005233, loss_freq: 0.017127
[18:40:18.682] iteration 23046: loss: 0.038496, loss_s1: 0.030735, loss_fp: 0.000968, loss_freq: 0.007182
[18:40:19.362] iteration 23047: loss: 0.148088, loss_s1: 0.186416, loss_fp: 0.005726, loss_freq: 0.074208
[18:40:20.072] iteration 23048: loss: 0.032031, loss_s1: 0.023779, loss_fp: 0.001715, loss_freq: 0.011532
[18:40:20.735] iteration 23049: loss: 0.057253, loss_s1: 0.055733, loss_fp: 0.004511, loss_freq: 0.025976
[18:40:21.381] iteration 23050: loss: 0.039455, loss_s1: 0.037879, loss_fp: 0.002346, loss_freq: 0.007288
[18:40:22.046] iteration 23051: loss: 0.083581, loss_s1: 0.083624, loss_fp: 0.001599, loss_freq: 0.040821
[18:40:22.703] iteration 23052: loss: 0.062647, loss_s1: 0.065107, loss_fp: 0.009055, loss_freq: 0.020251
[18:40:23.324] iteration 23053: loss: 0.063740, loss_s1: 0.079516, loss_fp: 0.004664, loss_freq: 0.009887
[18:40:23.962] iteration 23054: loss: 0.042079, loss_s1: 0.037291, loss_fp: 0.005311, loss_freq: 0.014988
[18:40:24.596] iteration 23055: loss: 0.041786, loss_s1: 0.020688, loss_fp: 0.002257, loss_freq: 0.025974
[18:40:25.226] iteration 23056: loss: 0.046054, loss_s1: 0.048464, loss_fp: 0.002019, loss_freq: 0.008813
[18:40:25.850] iteration 23057: loss: 0.035408, loss_s1: 0.021218, loss_fp: 0.002188, loss_freq: 0.008349
[18:40:26.489] iteration 23058: loss: 0.065807, loss_s1: 0.048613, loss_fp: 0.002461, loss_freq: 0.033519
[18:40:27.118] iteration 23059: loss: 0.071757, loss_s1: 0.045469, loss_fp: 0.006371, loss_freq: 0.061237
[18:40:27.744] iteration 23060: loss: 0.059122, loss_s1: 0.047238, loss_fp: 0.007940, loss_freq: 0.027566
[18:40:28.379] iteration 23061: loss: 0.069945, loss_s1: 0.043717, loss_fp: 0.005703, loss_freq: 0.052098
[18:40:29.000] iteration 23062: loss: 0.082895, loss_s1: 0.079935, loss_fp: 0.006932, loss_freq: 0.033829
[18:40:29.632] iteration 23063: loss: 0.054918, loss_s1: 0.047491, loss_fp: 0.003088, loss_freq: 0.023103
[18:40:30.253] iteration 23064: loss: 0.043946, loss_s1: 0.030114, loss_fp: 0.002390, loss_freq: 0.007939
[18:40:30.877] iteration 23065: loss: 0.044776, loss_s1: 0.040901, loss_fp: 0.002018, loss_freq: 0.017833
[18:40:31.503] iteration 23066: loss: 0.065817, loss_s1: 0.058791, loss_fp: 0.008156, loss_freq: 0.033725
[18:40:32.117] iteration 23067: loss: 0.062199, loss_s1: 0.046398, loss_fp: 0.002531, loss_freq: 0.038834
[18:40:32.747] iteration 23068: loss: 0.051423, loss_s1: 0.030166, loss_fp: 0.002749, loss_freq: 0.038418
[18:40:33.375] iteration 23069: loss: 0.062018, loss_s1: 0.061231, loss_fp: 0.003257, loss_freq: 0.013813
[18:40:34.029] iteration 23070: loss: 0.053734, loss_s1: 0.038490, loss_fp: 0.001856, loss_freq: 0.038727
[18:40:34.674] iteration 23071: loss: 0.044462, loss_s1: 0.037244, loss_fp: 0.007367, loss_freq: 0.012167
[18:40:35.303] iteration 23072: loss: 0.083910, loss_s1: 0.082752, loss_fp: 0.001860, loss_freq: 0.049518
[18:40:35.926] iteration 23073: loss: 0.043575, loss_s1: 0.047505, loss_fp: 0.003194, loss_freq: 0.013684
[18:40:36.552] iteration 23074: loss: 0.066912, loss_s1: 0.072624, loss_fp: 0.004531, loss_freq: 0.026749
[18:40:37.180] iteration 23075: loss: 0.064654, loss_s1: 0.040216, loss_fp: 0.003014, loss_freq: 0.028547
[18:40:37.802] iteration 23076: loss: 0.037658, loss_s1: 0.014220, loss_fp: 0.003085, loss_freq: 0.028358
[18:40:38.426] iteration 23077: loss: 0.066401, loss_s1: 0.029753, loss_fp: 0.009590, loss_freq: 0.058778
[18:40:39.061] iteration 23078: loss: 0.032216, loss_s1: 0.015269, loss_fp: 0.001082, loss_freq: 0.014218
[18:40:39.688] iteration 23079: loss: 0.056884, loss_s1: 0.046780, loss_fp: 0.002784, loss_freq: 0.025348
[18:40:40.311] iteration 23080: loss: 0.032066, loss_s1: 0.018300, loss_fp: 0.001334, loss_freq: 0.008389
[18:40:40.940] iteration 23081: loss: 0.056278, loss_s1: 0.014272, loss_fp: 0.000622, loss_freq: 0.015594
[18:40:41.574] iteration 23082: loss: 0.042313, loss_s1: 0.037911, loss_fp: 0.003684, loss_freq: 0.013403
[18:40:42.238] iteration 23083: loss: 0.042509, loss_s1: 0.017506, loss_fp: 0.002100, loss_freq: 0.020776
[18:40:42.897] iteration 23084: loss: 0.036107, loss_s1: 0.018585, loss_fp: 0.002517, loss_freq: 0.024675
[18:40:43.556] iteration 23085: loss: 0.062950, loss_s1: 0.064358, loss_fp: 0.001820, loss_freq: 0.028434
[18:40:44.179] iteration 23086: loss: 0.041811, loss_s1: 0.029104, loss_fp: 0.000378, loss_freq: 0.011462
[18:40:44.799] iteration 23087: loss: 0.052388, loss_s1: 0.037458, loss_fp: 0.004444, loss_freq: 0.028771
[18:40:45.419] iteration 23088: loss: 0.051458, loss_s1: 0.034779, loss_fp: 0.008652, loss_freq: 0.022844
[18:40:46.041] iteration 23089: loss: 0.062175, loss_s1: 0.038353, loss_fp: 0.003862, loss_freq: 0.055345
[18:40:46.666] iteration 23090: loss: 0.051467, loss_s1: 0.019678, loss_fp: 0.006607, loss_freq: 0.039719
[18:40:47.297] iteration 23091: loss: 0.080734, loss_s1: 0.088524, loss_fp: 0.014349, loss_freq: 0.033216
[18:40:47.927] iteration 23092: loss: 0.039091, loss_s1: 0.028776, loss_fp: 0.004147, loss_freq: 0.013006
[18:40:48.557] iteration 23093: loss: 0.048919, loss_s1: 0.028615, loss_fp: 0.000846, loss_freq: 0.028066
[18:40:49.185] iteration 23094: loss: 0.053063, loss_s1: 0.025928, loss_fp: 0.003034, loss_freq: 0.040803
[18:40:49.808] iteration 23095: loss: 0.056458, loss_s1: 0.031859, loss_fp: 0.002144, loss_freq: 0.045957
[18:40:50.436] iteration 23096: loss: 0.070307, loss_s1: 0.085809, loss_fp: 0.000856, loss_freq: 0.013152
[18:40:51.067] iteration 23097: loss: 0.057678, loss_s1: 0.049272, loss_fp: 0.005199, loss_freq: 0.011327
[18:40:51.699] iteration 23098: loss: 0.061013, loss_s1: 0.063098, loss_fp: 0.002419, loss_freq: 0.017114
[18:40:52.332] iteration 23099: loss: 0.053279, loss_s1: 0.038476, loss_fp: 0.000989, loss_freq: 0.033938
[18:40:52.957] iteration 23100: loss: 0.043975, loss_s1: 0.035348, loss_fp: 0.002267, loss_freq: 0.011579
[18:40:53.590] iteration 23101: loss: 0.056941, loss_s1: 0.074688, loss_fp: 0.004818, loss_freq: 0.008101
[18:40:54.219] iteration 23102: loss: 0.034982, loss_s1: 0.018128, loss_fp: 0.000996, loss_freq: 0.005568
[18:40:54.841] iteration 23103: loss: 0.061349, loss_s1: 0.045089, loss_fp: 0.002691, loss_freq: 0.041872
[18:40:55.472] iteration 23104: loss: 0.073411, loss_s1: 0.058103, loss_fp: 0.012238, loss_freq: 0.031114
[18:40:56.099] iteration 23105: loss: 0.064454, loss_s1: 0.059443, loss_fp: 0.005329, loss_freq: 0.022123
[18:40:56.730] iteration 23106: loss: 0.058988, loss_s1: 0.056989, loss_fp: 0.003542, loss_freq: 0.027811
[18:40:57.358] iteration 23107: loss: 0.077260, loss_s1: 0.045353, loss_fp: 0.002971, loss_freq: 0.025736
[18:40:57.992] iteration 23108: loss: 0.086161, loss_s1: 0.082124, loss_fp: 0.012982, loss_freq: 0.049577
[18:40:58.617] iteration 23109: loss: 0.047817, loss_s1: 0.048083, loss_fp: 0.003119, loss_freq: 0.011998
[18:40:59.249] iteration 23110: loss: 0.040867, loss_s1: 0.024186, loss_fp: 0.003668, loss_freq: 0.010408
[18:40:59.873] iteration 23111: loss: 0.050852, loss_s1: 0.043536, loss_fp: 0.007049, loss_freq: 0.014482
[18:41:00.499] iteration 23112: loss: 0.072138, loss_s1: 0.037483, loss_fp: 0.003575, loss_freq: 0.065567
[18:41:01.126] iteration 23113: loss: 0.067347, loss_s1: 0.068250, loss_fp: 0.004812, loss_freq: 0.029700
[18:41:01.756] iteration 23114: loss: 0.075304, loss_s1: 0.035481, loss_fp: 0.008196, loss_freq: 0.044281
[18:41:02.378] iteration 23115: loss: 0.063950, loss_s1: 0.045449, loss_fp: 0.004514, loss_freq: 0.035541
[18:41:03.003] iteration 23116: loss: 0.102087, loss_s1: 0.043393, loss_fp: 0.001445, loss_freq: 0.043317
[18:41:03.631] iteration 23117: loss: 0.034379, loss_s1: 0.016711, loss_fp: 0.002243, loss_freq: 0.005184
[18:41:04.261] iteration 23118: loss: 0.063658, loss_s1: 0.066006, loss_fp: 0.003532, loss_freq: 0.028173
[18:41:04.900] iteration 23119: loss: 0.039420, loss_s1: 0.025271, loss_fp: 0.001220, loss_freq: 0.022072
[18:41:05.527] iteration 23120: loss: 0.033978, loss_s1: 0.015075, loss_fp: 0.002069, loss_freq: 0.021884
[18:41:06.154] iteration 23121: loss: 0.056025, loss_s1: 0.036976, loss_fp: 0.001115, loss_freq: 0.031248
[18:41:06.776] iteration 23122: loss: 0.029820, loss_s1: 0.015578, loss_fp: 0.002821, loss_freq: 0.014052
[18:41:07.402] iteration 23123: loss: 0.058557, loss_s1: 0.042326, loss_fp: 0.003184, loss_freq: 0.032206
[18:41:08.026] iteration 23124: loss: 0.051428, loss_s1: 0.059756, loss_fp: 0.005699, loss_freq: 0.008620
[18:41:08.657] iteration 23125: loss: 0.084896, loss_s1: 0.080319, loss_fp: 0.003531, loss_freq: 0.038045
[18:41:09.285] iteration 23126: loss: 0.108207, loss_s1: 0.110568, loss_fp: 0.007902, loss_freq: 0.071150
[18:41:09.908] iteration 23127: loss: 0.060746, loss_s1: 0.046172, loss_fp: 0.005611, loss_freq: 0.036752
[18:41:10.541] iteration 23128: loss: 0.049365, loss_s1: 0.029621, loss_fp: 0.004916, loss_freq: 0.011932
[18:41:11.174] iteration 23129: loss: 0.041303, loss_s1: 0.018866, loss_fp: 0.002416, loss_freq: 0.026630
[18:41:11.801] iteration 23130: loss: 0.035651, loss_s1: 0.015158, loss_fp: 0.003214, loss_freq: 0.013120
[18:41:12.463] iteration 23131: loss: 0.065562, loss_s1: 0.060275, loss_fp: 0.001206, loss_freq: 0.032449
[18:41:13.123] iteration 23132: loss: 0.089593, loss_s1: 0.049612, loss_fp: 0.006194, loss_freq: 0.081864
[18:41:13.782] iteration 23133: loss: 0.045676, loss_s1: 0.025761, loss_fp: 0.003424, loss_freq: 0.026790
[18:41:14.440] iteration 23134: loss: 0.047787, loss_s1: 0.041235, loss_fp: 0.002126, loss_freq: 0.010000
[18:41:15.104] iteration 23135: loss: 0.050162, loss_s1: 0.029800, loss_fp: 0.001214, loss_freq: 0.031752
[18:41:15.743] iteration 23136: loss: 0.074390, loss_s1: 0.070313, loss_fp: 0.001720, loss_freq: 0.039274
[18:41:16.375] iteration 23137: loss: 0.055808, loss_s1: 0.033590, loss_fp: 0.001836, loss_freq: 0.046733
[18:41:17.000] iteration 23138: loss: 0.030704, loss_s1: 0.013504, loss_fp: 0.001488, loss_freq: 0.006497
[18:41:17.629] iteration 23139: loss: 0.090712, loss_s1: 0.093118, loss_fp: 0.010458, loss_freq: 0.032553
[18:41:18.257] iteration 23140: loss: 0.061598, loss_s1: 0.025189, loss_fp: 0.001415, loss_freq: 0.045582
[18:41:18.888] iteration 23141: loss: 0.042411, loss_s1: 0.027353, loss_fp: 0.002095, loss_freq: 0.030452
[18:41:19.516] iteration 23142: loss: 0.078846, loss_s1: 0.061639, loss_fp: 0.005363, loss_freq: 0.039036
[18:41:20.140] iteration 23143: loss: 0.037959, loss_s1: 0.019308, loss_fp: 0.001306, loss_freq: 0.027482
[18:41:20.768] iteration 23144: loss: 0.045777, loss_s1: 0.026569, loss_fp: 0.001526, loss_freq: 0.029266
[18:41:21.395] iteration 23145: loss: 0.062099, loss_s1: 0.052733, loss_fp: 0.007989, loss_freq: 0.019620
[18:41:22.019] iteration 23146: loss: 0.050172, loss_s1: 0.046444, loss_fp: 0.000768, loss_freq: 0.016777
[18:41:22.648] iteration 23147: loss: 0.047641, loss_s1: 0.046164, loss_fp: 0.006148, loss_freq: 0.006937
[18:41:23.276] iteration 23148: loss: 0.057049, loss_s1: 0.040831, loss_fp: 0.008975, loss_freq: 0.032199
[18:41:23.901] iteration 23149: loss: 0.052625, loss_s1: 0.047960, loss_fp: 0.002057, loss_freq: 0.021458
[18:41:24.528] iteration 23150: loss: 0.059823, loss_s1: 0.066337, loss_fp: 0.005292, loss_freq: 0.011571
[18:41:25.153] iteration 23151: loss: 0.196685, loss_s1: 0.244381, loss_fp: 0.003564, loss_freq: 0.104375
[18:41:25.777] iteration 23152: loss: 0.044656, loss_s1: 0.025039, loss_fp: 0.006358, loss_freq: 0.026439
[18:41:26.403] iteration 23153: loss: 0.043953, loss_s1: 0.050846, loss_fp: 0.001936, loss_freq: 0.007022
[18:41:27.032] iteration 23154: loss: 0.054505, loss_s1: 0.045938, loss_fp: 0.004820, loss_freq: 0.021260
[18:41:27.660] iteration 23155: loss: 0.075519, loss_s1: 0.083807, loss_fp: 0.000948, loss_freq: 0.025497
[18:41:28.316] iteration 23156: loss: 0.080165, loss_s1: 0.092723, loss_fp: 0.002142, loss_freq: 0.018523
[18:41:28.975] iteration 23157: loss: 0.034436, loss_s1: 0.030902, loss_fp: 0.002970, loss_freq: 0.006724
[18:41:29.632] iteration 23158: loss: 0.067439, loss_s1: 0.071187, loss_fp: 0.001557, loss_freq: 0.022698
[18:41:30.296] iteration 23159: loss: 0.047628, loss_s1: 0.037379, loss_fp: 0.004790, loss_freq: 0.017933
[18:41:30.933] iteration 23160: loss: 0.050152, loss_s1: 0.048142, loss_fp: 0.002008, loss_freq: 0.015162
[18:41:31.755] iteration 23161: loss: 0.043320, loss_s1: 0.038385, loss_fp: 0.002383, loss_freq: 0.013064
[18:41:32.480] iteration 23162: loss: 0.044804, loss_s1: 0.026952, loss_fp: 0.005420, loss_freq: 0.030147
[18:41:33.120] iteration 23163: loss: 0.076865, loss_s1: 0.034552, loss_fp: 0.006380, loss_freq: 0.046009
[18:41:33.750] iteration 23164: loss: 0.070030, loss_s1: 0.072406, loss_fp: 0.005582, loss_freq: 0.030268
[18:41:34.369] iteration 23165: loss: 0.042883, loss_s1: 0.023305, loss_fp: 0.012172, loss_freq: 0.019009
[18:41:34.995] iteration 23166: loss: 0.056478, loss_s1: 0.049049, loss_fp: 0.002302, loss_freq: 0.029964
[18:41:35.614] iteration 23167: loss: 0.081383, loss_s1: 0.052007, loss_fp: 0.014656, loss_freq: 0.048579
[18:41:36.238] iteration 23168: loss: 0.049112, loss_s1: 0.045743, loss_fp: 0.005255, loss_freq: 0.014505
[18:41:36.855] iteration 23169: loss: 0.056835, loss_s1: 0.049576, loss_fp: 0.007861, loss_freq: 0.020023
[18:41:37.479] iteration 23170: loss: 0.051540, loss_s1: 0.027762, loss_fp: 0.005595, loss_freq: 0.045060
[18:41:38.103] iteration 23171: loss: 0.030193, loss_s1: 0.016236, loss_fp: 0.002252, loss_freq: 0.008747
[18:41:38.718] iteration 23172: loss: 0.054722, loss_s1: 0.064957, loss_fp: 0.002904, loss_freq: 0.014572
[18:41:39.349] iteration 23173: loss: 0.079212, loss_s1: 0.076373, loss_fp: 0.007384, loss_freq: 0.033428
[18:41:39.963] iteration 23174: loss: 0.076014, loss_s1: 0.087868, loss_fp: 0.006366, loss_freq: 0.024392
[18:41:40.579] iteration 23175: loss: 0.060477, loss_s1: 0.035090, loss_fp: 0.003940, loss_freq: 0.051288
[18:41:41.193] iteration 23176: loss: 0.045168, loss_s1: 0.042948, loss_fp: 0.002902, loss_freq: 0.019090
[18:41:41.815] iteration 23177: loss: 0.090080, loss_s1: 0.081949, loss_fp: 0.003672, loss_freq: 0.034243
[18:41:42.434] iteration 23178: loss: 0.027960, loss_s1: 0.014835, loss_fp: 0.003799, loss_freq: 0.006611
[18:41:43.057] iteration 23179: loss: 0.043413, loss_s1: 0.012751, loss_fp: 0.001888, loss_freq: 0.026870
[18:41:43.677] iteration 23180: loss: 0.033375, loss_s1: 0.014464, loss_fp: 0.000997, loss_freq: 0.017125
[18:41:44.295] iteration 23181: loss: 0.125257, loss_s1: 0.099628, loss_fp: 0.006012, loss_freq: 0.101078
[18:41:44.913] iteration 23182: loss: 0.101514, loss_s1: 0.052371, loss_fp: 0.006669, loss_freq: 0.014408
[18:41:45.531] iteration 23183: loss: 0.050187, loss_s1: 0.027564, loss_fp: 0.013506, loss_freq: 0.026379
[18:41:46.156] iteration 23184: loss: 0.053472, loss_s1: 0.027472, loss_fp: 0.005569, loss_freq: 0.036948
[18:41:47.130] iteration 23185: loss: 0.072766, loss_s1: 0.084652, loss_fp: 0.002158, loss_freq: 0.022967
[18:41:47.787] iteration 23186: loss: 0.063351, loss_s1: 0.053598, loss_fp: 0.008010, loss_freq: 0.021890
[18:41:48.443] iteration 23187: loss: 0.037728, loss_s1: 0.019854, loss_fp: 0.001861, loss_freq: 0.021320
[18:41:49.102] iteration 23188: loss: 0.053034, loss_s1: 0.026127, loss_fp: 0.007315, loss_freq: 0.032244
[18:41:49.728] iteration 23189: loss: 0.077515, loss_s1: 0.078542, loss_fp: 0.004604, loss_freq: 0.036158
[18:41:50.344] iteration 23190: loss: 0.101406, loss_s1: 0.086842, loss_fp: 0.006351, loss_freq: 0.040668
[18:41:50.969] iteration 23191: loss: 0.059116, loss_s1: 0.028635, loss_fp: 0.006876, loss_freq: 0.047219
[18:41:51.593] iteration 23192: loss: 0.039775, loss_s1: 0.032471, loss_fp: 0.003202, loss_freq: 0.005802
[18:41:52.221] iteration 23193: loss: 0.054427, loss_s1: 0.032019, loss_fp: 0.005229, loss_freq: 0.046455
[18:41:52.848] iteration 23194: loss: 0.081136, loss_s1: 0.074786, loss_fp: 0.021373, loss_freq: 0.023966
[18:41:53.472] iteration 23195: loss: 0.037112, loss_s1: 0.023144, loss_fp: 0.006407, loss_freq: 0.006748
[18:41:54.085] iteration 23196: loss: 0.101699, loss_s1: 0.125941, loss_fp: 0.010378, loss_freq: 0.032442
[18:41:54.703] iteration 23197: loss: 0.074193, loss_s1: 0.056027, loss_fp: 0.003922, loss_freq: 0.061168
[18:41:55.326] iteration 23198: loss: 0.070791, loss_s1: 0.051142, loss_fp: 0.002914, loss_freq: 0.023404
[18:41:55.950] iteration 23199: loss: 0.041918, loss_s1: 0.035767, loss_fp: 0.001332, loss_freq: 0.022130
[18:41:56.565] iteration 23200: loss: 0.100162, loss_s1: 0.073541, loss_fp: 0.026208, loss_freq: 0.059692
[18:41:59.923] iteration 23200 : mean_dice : 0.723432
[18:42:00.570] iteration 23201: loss: 0.042906, loss_s1: 0.025803, loss_fp: 0.002160, loss_freq: 0.012086
[18:42:01.188] iteration 23202: loss: 0.059093, loss_s1: 0.046535, loss_fp: 0.003975, loss_freq: 0.026806
[18:42:01.808] iteration 23203: loss: 0.044634, loss_s1: 0.028508, loss_fp: 0.001171, loss_freq: 0.018769
[18:42:02.434] iteration 23204: loss: 0.058812, loss_s1: 0.031726, loss_fp: 0.002470, loss_freq: 0.016572
[18:42:03.054] iteration 23205: loss: 0.036579, loss_s1: 0.024592, loss_fp: 0.001173, loss_freq: 0.005622
[18:42:03.669] iteration 23206: loss: 0.037993, loss_s1: 0.019664, loss_fp: 0.002981, loss_freq: 0.016321
[18:42:04.294] iteration 23207: loss: 0.056487, loss_s1: 0.041008, loss_fp: 0.001989, loss_freq: 0.017807
[18:42:04.916] iteration 23208: loss: 0.059254, loss_s1: 0.030695, loss_fp: 0.003793, loss_freq: 0.045190
[18:42:05.537] iteration 23209: loss: 0.039686, loss_s1: 0.023310, loss_fp: 0.002066, loss_freq: 0.025956
[18:42:06.187] iteration 23210: loss: 0.084398, loss_s1: 0.063037, loss_fp: 0.006183, loss_freq: 0.058621
[18:42:06.850] iteration 23211: loss: 0.026191, loss_s1: 0.017372, loss_fp: 0.000298, loss_freq: 0.003389
[18:42:07.489] iteration 23212: loss: 0.095736, loss_s1: 0.074139, loss_fp: 0.017799, loss_freq: 0.063943
[18:42:08.114] iteration 23213: loss: 0.069055, loss_s1: 0.047339, loss_fp: 0.003762, loss_freq: 0.049354
[18:42:08.739] iteration 23214: loss: 0.049296, loss_s1: 0.050472, loss_fp: 0.002386, loss_freq: 0.015453
[18:42:09.354] iteration 23215: loss: 0.033806, loss_s1: 0.030759, loss_fp: 0.000553, loss_freq: 0.006366
[18:42:09.972] iteration 23216: loss: 0.038848, loss_s1: 0.032719, loss_fp: 0.002385, loss_freq: 0.011706
[18:42:10.592] iteration 23217: loss: 0.051089, loss_s1: 0.029372, loss_fp: 0.002230, loss_freq: 0.032810
[18:42:11.215] iteration 23218: loss: 0.047927, loss_s1: 0.050415, loss_fp: 0.001866, loss_freq: 0.005100
[18:42:11.838] iteration 23219: loss: 0.050384, loss_s1: 0.024073, loss_fp: 0.004822, loss_freq: 0.030648
[18:42:12.465] iteration 23220: loss: 0.054580, loss_s1: 0.029570, loss_fp: 0.002097, loss_freq: 0.044783
[18:42:13.083] iteration 23221: loss: 0.070776, loss_s1: 0.077810, loss_fp: 0.003349, loss_freq: 0.029567
[18:42:13.699] iteration 23222: loss: 0.042141, loss_s1: 0.032911, loss_fp: 0.001855, loss_freq: 0.015757
[18:42:14.332] iteration 23223: loss: 0.093409, loss_s1: 0.066831, loss_fp: 0.006836, loss_freq: 0.069779
[18:42:14.953] iteration 23224: loss: 0.053170, loss_s1: 0.032378, loss_fp: 0.004254, loss_freq: 0.037355
[18:42:15.576] iteration 23225: loss: 0.086074, loss_s1: 0.086521, loss_fp: 0.006467, loss_freq: 0.030415
[18:42:16.200] iteration 23226: loss: 0.082009, loss_s1: 0.073640, loss_fp: 0.005483, loss_freq: 0.055053
[18:42:16.823] iteration 23227: loss: 0.064306, loss_s1: 0.043657, loss_fp: 0.002770, loss_freq: 0.034272
[18:42:17.445] iteration 23228: loss: 0.067972, loss_s1: 0.074274, loss_fp: 0.001491, loss_freq: 0.037416
[18:42:18.073] iteration 23229: loss: 0.046703, loss_s1: 0.019060, loss_fp: 0.005082, loss_freq: 0.031702
[18:42:18.693] iteration 23230: loss: 0.035563, loss_s1: 0.018610, loss_fp: 0.004346, loss_freq: 0.009717
[18:42:19.317] iteration 23231: loss: 0.036167, loss_s1: 0.021314, loss_fp: 0.000436, loss_freq: 0.011126
[18:42:19.946] iteration 23232: loss: 0.061849, loss_s1: 0.049319, loss_fp: 0.024790, loss_freq: 0.021828
[18:42:20.571] iteration 23233: loss: 0.062280, loss_s1: 0.057590, loss_fp: 0.002494, loss_freq: 0.008042
[18:42:21.188] iteration 23234: loss: 0.068928, loss_s1: 0.059841, loss_fp: 0.002879, loss_freq: 0.049678
[18:42:21.806] iteration 23235: loss: 0.071191, loss_s1: 0.079938, loss_fp: 0.012542, loss_freq: 0.014410
[18:42:22.428] iteration 23236: loss: 0.061297, loss_s1: 0.057544, loss_fp: 0.002050, loss_freq: 0.026133
[18:42:23.048] iteration 23237: loss: 0.044891, loss_s1: 0.020346, loss_fp: 0.002666, loss_freq: 0.030085
[18:42:23.664] iteration 23238: loss: 0.063662, loss_s1: 0.054291, loss_fp: 0.003175, loss_freq: 0.039681
[18:42:24.317] iteration 23239: loss: 0.034578, loss_s1: 0.024295, loss_fp: 0.002564, loss_freq: 0.010515
[18:42:24.960] iteration 23240: loss: 0.068346, loss_s1: 0.045948, loss_fp: 0.002871, loss_freq: 0.027409
[18:42:25.621] iteration 23241: loss: 0.029838, loss_s1: 0.023375, loss_fp: 0.000401, loss_freq: 0.004270
[18:42:26.294] iteration 23242: loss: 0.066503, loss_s1: 0.044749, loss_fp: 0.001237, loss_freq: 0.014654
[18:42:26.953] iteration 23243: loss: 0.034250, loss_s1: 0.028173, loss_fp: 0.002592, loss_freq: 0.006146
[18:42:27.618] iteration 23244: loss: 0.039480, loss_s1: 0.022104, loss_fp: 0.001147, loss_freq: 0.021820
[18:42:28.276] iteration 23245: loss: 0.041987, loss_s1: 0.037331, loss_fp: 0.004336, loss_freq: 0.014678
[18:42:28.987] iteration 23246: loss: 0.049338, loss_s1: 0.038717, loss_fp: 0.007488, loss_freq: 0.024529
[18:42:29.663] iteration 23247: loss: 0.044742, loss_s1: 0.022098, loss_fp: 0.000760, loss_freq: 0.014074
[18:42:30.293] iteration 23248: loss: 0.045801, loss_s1: 0.035530, loss_fp: 0.002093, loss_freq: 0.022172
[18:42:30.918] iteration 23249: loss: 0.051777, loss_s1: 0.048167, loss_fp: 0.001897, loss_freq: 0.019756
[18:42:31.546] iteration 23250: loss: 0.069266, loss_s1: 0.059378, loss_fp: 0.008056, loss_freq: 0.040324
[18:42:32.171] iteration 23251: loss: 0.069882, loss_s1: 0.075473, loss_fp: 0.003079, loss_freq: 0.028411
[18:42:32.863] iteration 23252: loss: 0.082249, loss_s1: 0.062235, loss_fp: 0.004951, loss_freq: 0.069351
[18:42:33.551] iteration 23253: loss: 0.053764, loss_s1: 0.051398, loss_fp: 0.002099, loss_freq: 0.022988
[18:42:34.178] iteration 23254: loss: 0.047685, loss_s1: 0.039037, loss_fp: 0.001096, loss_freq: 0.019427
[18:42:34.800] iteration 23255: loss: 0.075098, loss_s1: 0.040604, loss_fp: 0.010435, loss_freq: 0.068611
[18:42:35.426] iteration 23256: loss: 0.035313, loss_s1: 0.018623, loss_fp: 0.001525, loss_freq: 0.016373
[18:42:36.062] iteration 23257: loss: 0.045768, loss_s1: 0.023963, loss_fp: 0.003748, loss_freq: 0.019636
[18:42:36.684] iteration 23258: loss: 0.033542, loss_s1: 0.016882, loss_fp: 0.001294, loss_freq: 0.008917
[18:42:37.312] iteration 23259: loss: 0.038740, loss_s1: 0.029667, loss_fp: 0.002120, loss_freq: 0.012209
[18:42:37.945] iteration 23260: loss: 0.040887, loss_s1: 0.029610, loss_fp: 0.005223, loss_freq: 0.011930
[18:42:38.568] iteration 23261: loss: 0.058792, loss_s1: 0.046006, loss_fp: 0.011219, loss_freq: 0.033845
[18:42:39.200] iteration 23262: loss: 0.038868, loss_s1: 0.044093, loss_fp: 0.003185, loss_freq: 0.005316
[18:42:39.832] iteration 23263: loss: 0.038448, loss_s1: 0.021547, loss_fp: 0.009517, loss_freq: 0.008799
[18:42:40.468] iteration 23264: loss: 0.050241, loss_s1: 0.034509, loss_fp: 0.001274, loss_freq: 0.026670
[18:42:41.103] iteration 23265: loss: 0.054769, loss_s1: 0.032287, loss_fp: 0.000833, loss_freq: 0.040963
[18:42:41.733] iteration 23266: loss: 0.069962, loss_s1: 0.066573, loss_fp: 0.011579, loss_freq: 0.032386
[18:42:42.360] iteration 23267: loss: 0.103500, loss_s1: 0.110857, loss_fp: 0.022450, loss_freq: 0.042663
[18:42:42.987] iteration 23268: loss: 0.055292, loss_s1: 0.055788, loss_fp: 0.002962, loss_freq: 0.017396
[18:42:43.614] iteration 23269: loss: 0.063263, loss_s1: 0.044312, loss_fp: 0.005729, loss_freq: 0.049043
[18:42:44.244] iteration 23270: loss: 0.032499, loss_s1: 0.014368, loss_fp: 0.001537, loss_freq: 0.014407
[18:42:44.872] iteration 23271: loss: 0.059645, loss_s1: 0.043571, loss_fp: 0.005404, loss_freq: 0.035068
[18:42:45.500] iteration 23272: loss: 0.069703, loss_s1: 0.051310, loss_fp: 0.007913, loss_freq: 0.047997
[18:42:46.118] iteration 23273: loss: 0.050326, loss_s1: 0.026015, loss_fp: 0.004986, loss_freq: 0.034836
[18:42:46.776] iteration 23274: loss: 0.055945, loss_s1: 0.052529, loss_fp: 0.001707, loss_freq: 0.026968
[18:42:47.434] iteration 23275: loss: 0.062419, loss_s1: 0.042454, loss_fp: 0.004928, loss_freq: 0.035643
[18:42:48.072] iteration 23276: loss: 0.060652, loss_s1: 0.058100, loss_fp: 0.003259, loss_freq: 0.021341
[18:42:48.691] iteration 23277: loss: 0.053541, loss_s1: 0.016636, loss_fp: 0.000579, loss_freq: 0.031962
[18:42:49.309] iteration 23278: loss: 0.051020, loss_s1: 0.032627, loss_fp: 0.002290, loss_freq: 0.017797
[18:42:49.931] iteration 23279: loss: 0.059923, loss_s1: 0.071851, loss_fp: 0.002992, loss_freq: 0.017514
[18:42:50.549] iteration 23280: loss: 0.041827, loss_s1: 0.016524, loss_fp: 0.003632, loss_freq: 0.030328
[18:42:51.168] iteration 23281: loss: 0.029570, loss_s1: 0.008312, loss_fp: 0.001354, loss_freq: 0.011673
[18:42:51.789] iteration 23282: loss: 0.039929, loss_s1: 0.023881, loss_fp: 0.001258, loss_freq: 0.016790
[18:42:52.411] iteration 23283: loss: 0.027696, loss_s1: 0.021281, loss_fp: 0.001793, loss_freq: 0.004231
[18:42:53.035] iteration 23284: loss: 0.078327, loss_s1: 0.090458, loss_fp: 0.005757, loss_freq: 0.030338
[18:42:53.647] iteration 23285: loss: 0.062515, loss_s1: 0.068471, loss_fp: 0.004231, loss_freq: 0.013034
[18:42:54.300] iteration 23286: loss: 0.067389, loss_s1: 0.041674, loss_fp: 0.006217, loss_freq: 0.034896
[18:42:54.932] iteration 23287: loss: 0.083149, loss_s1: 0.064066, loss_fp: 0.003817, loss_freq: 0.067622
[18:42:55.556] iteration 23288: loss: 0.060233, loss_s1: 0.045588, loss_fp: 0.009287, loss_freq: 0.028744
[18:42:56.200] iteration 23289: loss: 0.050222, loss_s1: 0.037230, loss_fp: 0.005848, loss_freq: 0.012042
[18:42:56.816] iteration 23290: loss: 0.039574, loss_s1: 0.017782, loss_fp: 0.010752, loss_freq: 0.023045
[18:42:57.440] iteration 23291: loss: 0.047976, loss_s1: 0.029979, loss_fp: 0.004944, loss_freq: 0.026288
[18:42:58.062] iteration 23292: loss: 0.059573, loss_s1: 0.046266, loss_fp: 0.003051, loss_freq: 0.037342
[18:42:58.681] iteration 23293: loss: 0.079982, loss_s1: 0.076359, loss_fp: 0.006464, loss_freq: 0.039793
[18:42:59.310] iteration 23294: loss: 0.086507, loss_s1: 0.078731, loss_fp: 0.002520, loss_freq: 0.025985
[18:42:59.933] iteration 23295: loss: 0.058160, loss_s1: 0.034412, loss_fp: 0.005102, loss_freq: 0.024228
[18:43:00.543] iteration 23296: loss: 0.065020, loss_s1: 0.056460, loss_fp: 0.002698, loss_freq: 0.039738
[18:43:01.168] iteration 23297: loss: 0.050638, loss_s1: 0.028984, loss_fp: 0.001472, loss_freq: 0.026239
[18:43:01.792] iteration 23298: loss: 0.074793, loss_s1: 0.081907, loss_fp: 0.008009, loss_freq: 0.033264
[18:43:02.418] iteration 23299: loss: 0.040588, loss_s1: 0.023028, loss_fp: 0.003690, loss_freq: 0.017815
[18:43:03.031] iteration 23300: loss: 0.055311, loss_s1: 0.042256, loss_fp: 0.002442, loss_freq: 0.035329
[18:43:03.651] iteration 23301: loss: 0.050442, loss_s1: 0.057850, loss_fp: 0.002718, loss_freq: 0.011151
[18:43:04.269] iteration 23302: loss: 0.051399, loss_s1: 0.059865, loss_fp: 0.000770, loss_freq: 0.004423
[18:43:04.889] iteration 23303: loss: 0.062855, loss_s1: 0.069560, loss_fp: 0.003255, loss_freq: 0.017629
[18:43:05.512] iteration 23304: loss: 0.100192, loss_s1: 0.091568, loss_fp: 0.001211, loss_freq: 0.075698
[18:43:06.168] iteration 23305: loss: 0.083153, loss_s1: 0.052223, loss_fp: 0.008466, loss_freq: 0.068754
[18:43:06.830] iteration 23306: loss: 0.056242, loss_s1: 0.050101, loss_fp: 0.004620, loss_freq: 0.024776
[18:43:07.488] iteration 23307: loss: 0.072216, loss_s1: 0.069726, loss_fp: 0.002478, loss_freq: 0.033172
[18:43:08.117] iteration 23308: loss: 0.043644, loss_s1: 0.036385, loss_fp: 0.004380, loss_freq: 0.010853
[18:43:08.743] iteration 23309: loss: 0.059048, loss_s1: 0.059081, loss_fp: 0.006988, loss_freq: 0.019472
[18:43:09.363] iteration 23310: loss: 0.047718, loss_s1: 0.032087, loss_fp: 0.004586, loss_freq: 0.024762
[18:43:09.984] iteration 23311: loss: 0.042764, loss_s1: 0.035138, loss_fp: 0.000780, loss_freq: 0.008764
[18:43:10.602] iteration 23312: loss: 0.073966, loss_s1: 0.043517, loss_fp: 0.003396, loss_freq: 0.037358
[18:43:11.213] iteration 23313: loss: 0.075262, loss_s1: 0.070502, loss_fp: 0.003108, loss_freq: 0.046396
[18:43:11.829] iteration 23314: loss: 0.032762, loss_s1: 0.022008, loss_fp: 0.000755, loss_freq: 0.010184
[18:43:12.442] iteration 23315: loss: 0.049056, loss_s1: 0.037761, loss_fp: 0.004766, loss_freq: 0.024762
[18:43:13.059] iteration 23316: loss: 0.049874, loss_s1: 0.037612, loss_fp: 0.006064, loss_freq: 0.013885
[18:43:13.672] iteration 23317: loss: 0.089075, loss_s1: 0.122333, loss_fp: 0.004896, loss_freq: 0.012734
[18:43:14.287] iteration 23318: loss: 0.043543, loss_s1: 0.043173, loss_fp: 0.002863, loss_freq: 0.006733
[18:43:14.905] iteration 23319: loss: 0.045798, loss_s1: 0.039016, loss_fp: 0.000728, loss_freq: 0.022462
[18:43:15.524] iteration 23320: loss: 0.054335, loss_s1: 0.039048, loss_fp: 0.009230, loss_freq: 0.030349
[18:43:16.139] iteration 23321: loss: 0.045581, loss_s1: 0.035965, loss_fp: 0.002441, loss_freq: 0.013877
[18:43:16.752] iteration 23322: loss: 0.048640, loss_s1: 0.054506, loss_fp: 0.000716, loss_freq: 0.011002
[18:43:17.363] iteration 23323: loss: 0.050016, loss_s1: 0.038183, loss_fp: 0.004559, loss_freq: 0.026333
[18:43:17.976] iteration 23324: loss: 0.090406, loss_s1: 0.056808, loss_fp: 0.009752, loss_freq: 0.041382
[18:43:18.596] iteration 23325: loss: 0.051488, loss_s1: 0.037307, loss_fp: 0.005968, loss_freq: 0.031407
[18:43:19.212] iteration 23326: loss: 0.035718, loss_s1: 0.014617, loss_fp: 0.002380, loss_freq: 0.019156
[18:43:19.826] iteration 23327: loss: 0.058870, loss_s1: 0.042505, loss_fp: 0.004314, loss_freq: 0.039559
[18:43:20.446] iteration 23328: loss: 0.056987, loss_s1: 0.047288, loss_fp: 0.005469, loss_freq: 0.023354
[18:43:21.057] iteration 23329: loss: 0.059294, loss_s1: 0.043994, loss_fp: 0.000870, loss_freq: 0.029330
[18:43:21.677] iteration 23330: loss: 0.051484, loss_s1: 0.048944, loss_fp: 0.003396, loss_freq: 0.018357
[18:43:22.293] iteration 23331: loss: 0.066348, loss_s1: 0.036161, loss_fp: 0.011491, loss_freq: 0.052120
[18:43:22.914] iteration 23332: loss: 0.041727, loss_s1: 0.032076, loss_fp: 0.002168, loss_freq: 0.016044
[18:43:23.527] iteration 23333: loss: 0.043252, loss_s1: 0.037351, loss_fp: 0.005213, loss_freq: 0.016526
[18:43:24.145] iteration 23334: loss: 0.084786, loss_s1: 0.077925, loss_fp: 0.002914, loss_freq: 0.042161
[18:43:24.757] iteration 23335: loss: 0.049381, loss_s1: 0.043732, loss_fp: 0.002730, loss_freq: 0.010586
[18:43:25.375] iteration 23336: loss: 0.091474, loss_s1: 0.069288, loss_fp: 0.002074, loss_freq: 0.082045
[18:43:25.988] iteration 23337: loss: 0.036527, loss_s1: 0.024145, loss_fp: 0.002344, loss_freq: 0.014695
[18:43:26.605] iteration 23338: loss: 0.061455, loss_s1: 0.053337, loss_fp: 0.005573, loss_freq: 0.022277
[18:43:27.224] iteration 23339: loss: 0.033882, loss_s1: 0.020482, loss_fp: 0.003701, loss_freq: 0.008666
[18:43:27.842] iteration 23340: loss: 0.045900, loss_s1: 0.041900, loss_fp: 0.000384, loss_freq: 0.015877
[18:43:28.456] iteration 23341: loss: 0.032863, loss_s1: 0.009531, loss_fp: 0.001169, loss_freq: 0.012296
[18:43:29.076] iteration 23342: loss: 0.047611, loss_s1: 0.026031, loss_fp: 0.003160, loss_freq: 0.022317
[18:43:29.689] iteration 23343: loss: 0.065598, loss_s1: 0.063140, loss_fp: 0.009318, loss_freq: 0.023804
[18:43:30.303] iteration 23344: loss: 0.091699, loss_s1: 0.115545, loss_fp: 0.005745, loss_freq: 0.025041
[18:43:30.913] iteration 23345: loss: 0.050386, loss_s1: 0.033227, loss_fp: 0.000394, loss_freq: 0.017240
[18:43:31.877] iteration 23346: loss: 0.050406, loss_s1: 0.062551, loss_fp: 0.004561, loss_freq: 0.004503
[18:43:32.496] iteration 23347: loss: 0.052436, loss_s1: 0.051498, loss_fp: 0.004798, loss_freq: 0.012129
[18:43:33.108] iteration 23348: loss: 0.043317, loss_s1: 0.038020, loss_fp: 0.000904, loss_freq: 0.020293
[18:43:33.727] iteration 23349: loss: 0.041296, loss_s1: 0.031182, loss_fp: 0.003445, loss_freq: 0.010971
[18:43:34.340] iteration 23350: loss: 0.074054, loss_s1: 0.083045, loss_fp: 0.000912, loss_freq: 0.030593
[18:43:34.962] iteration 23351: loss: 0.078341, loss_s1: 0.063381, loss_fp: 0.004855, loss_freq: 0.048075
[18:43:35.581] iteration 23352: loss: 0.047518, loss_s1: 0.022700, loss_fp: 0.010077, loss_freq: 0.028211
[18:43:36.204] iteration 23353: loss: 0.028714, loss_s1: 0.008988, loss_fp: 0.000789, loss_freq: 0.011455
[18:43:36.823] iteration 23354: loss: 0.081227, loss_s1: 0.055123, loss_fp: 0.003280, loss_freq: 0.056967
[18:43:37.450] iteration 23355: loss: 0.049943, loss_s1: 0.025153, loss_fp: 0.003720, loss_freq: 0.032282
[18:43:38.109] iteration 23356: loss: 0.035855, loss_s1: 0.028771, loss_fp: 0.000784, loss_freq: 0.007353
[18:43:38.736] iteration 23357: loss: 0.066690, loss_s1: 0.078068, loss_fp: 0.005782, loss_freq: 0.019800
[18:43:39.354] iteration 23358: loss: 0.054731, loss_s1: 0.032567, loss_fp: 0.003786, loss_freq: 0.042579
[18:43:39.974] iteration 23359: loss: 0.065641, loss_s1: 0.027553, loss_fp: 0.006389, loss_freq: 0.057876
[18:43:40.591] iteration 23360: loss: 0.039960, loss_s1: 0.029784, loss_fp: 0.001502, loss_freq: 0.017847
[18:43:41.207] iteration 23361: loss: 0.086749, loss_s1: 0.080618, loss_fp: 0.018955, loss_freq: 0.043725
[18:43:41.828] iteration 23362: loss: 0.049766, loss_s1: 0.042962, loss_fp: 0.003617, loss_freq: 0.009522
[18:43:42.447] iteration 23363: loss: 0.072043, loss_s1: 0.078933, loss_fp: 0.003077, loss_freq: 0.015690
[18:43:43.070] iteration 23364: loss: 0.034944, loss_s1: 0.013452, loss_fp: 0.001462, loss_freq: 0.019213
[18:43:43.684] iteration 23365: loss: 0.040088, loss_s1: 0.020731, loss_fp: 0.002417, loss_freq: 0.018612
[18:43:44.298] iteration 23366: loss: 0.054103, loss_s1: 0.048101, loss_fp: 0.000877, loss_freq: 0.006545
[18:43:44.908] iteration 23367: loss: 0.046412, loss_s1: 0.031954, loss_fp: 0.001182, loss_freq: 0.018070
[18:43:45.527] iteration 23368: loss: 0.043579, loss_s1: 0.024347, loss_fp: 0.002028, loss_freq: 0.012531
[18:43:46.145] iteration 23369: loss: 0.060205, loss_s1: 0.041001, loss_fp: 0.002690, loss_freq: 0.048207
[18:43:46.758] iteration 23370: loss: 0.050289, loss_s1: 0.048574, loss_fp: 0.001527, loss_freq: 0.023837
[18:43:47.379] iteration 23371: loss: 0.039872, loss_s1: 0.027590, loss_fp: 0.001257, loss_freq: 0.010534
[18:43:47.998] iteration 23372: loss: 0.040887, loss_s1: 0.042229, loss_fp: 0.000614, loss_freq: 0.010245
[18:43:48.618] iteration 23373: loss: 0.097546, loss_s1: 0.105299, loss_fp: 0.011553, loss_freq: 0.038844
[18:43:49.232] iteration 23374: loss: 0.057877, loss_s1: 0.024288, loss_fp: 0.004493, loss_freq: 0.039310
[18:43:49.851] iteration 23375: loss: 0.044421, loss_s1: 0.037401, loss_fp: 0.000656, loss_freq: 0.014290
[18:43:50.466] iteration 23376: loss: 0.043960, loss_s1: 0.046546, loss_fp: 0.002206, loss_freq: 0.013455
[18:43:51.088] iteration 23377: loss: 0.037379, loss_s1: 0.021157, loss_fp: 0.002596, loss_freq: 0.016850
[18:43:51.702] iteration 23378: loss: 0.036538, loss_s1: 0.010452, loss_fp: 0.001282, loss_freq: 0.027863
[18:43:52.327] iteration 23379: loss: 0.063295, loss_s1: 0.079328, loss_fp: 0.004828, loss_freq: 0.011433
[18:43:52.951] iteration 23380: loss: 0.060792, loss_s1: 0.032741, loss_fp: 0.016016, loss_freq: 0.028179
[18:43:53.568] iteration 23381: loss: 0.068857, loss_s1: 0.064116, loss_fp: 0.001906, loss_freq: 0.039945
[18:43:54.189] iteration 23382: loss: 0.047087, loss_s1: 0.030056, loss_fp: 0.012147, loss_freq: 0.015417
[18:43:54.813] iteration 23383: loss: 0.074421, loss_s1: 0.081450, loss_fp: 0.002625, loss_freq: 0.035954
[18:43:55.431] iteration 23384: loss: 0.076453, loss_s1: 0.024174, loss_fp: 0.004278, loss_freq: 0.084199
[18:43:56.061] iteration 23385: loss: 0.044067, loss_s1: 0.030915, loss_fp: 0.004337, loss_freq: 0.016752
[18:43:56.683] iteration 23386: loss: 0.059754, loss_s1: 0.043584, loss_fp: 0.009802, loss_freq: 0.015297
[18:43:57.302] iteration 23387: loss: 0.066834, loss_s1: 0.072340, loss_fp: 0.002976, loss_freq: 0.026549
[18:43:57.932] iteration 23388: loss: 0.052984, loss_s1: 0.035385, loss_fp: 0.008344, loss_freq: 0.030380
[18:43:58.560] iteration 23389: loss: 0.058330, loss_s1: 0.035268, loss_fp: 0.001379, loss_freq: 0.041872
[18:43:59.181] iteration 23390: loss: 0.053069, loss_s1: 0.031225, loss_fp: 0.002951, loss_freq: 0.035653
[18:43:59.810] iteration 23391: loss: 0.041193, loss_s1: 0.041852, loss_fp: 0.003075, loss_freq: 0.006513
[18:44:00.427] iteration 23392: loss: 0.038403, loss_s1: 0.028016, loss_fp: 0.000571, loss_freq: 0.017319
[18:44:01.053] iteration 23393: loss: 0.035418, loss_s1: 0.013228, loss_fp: 0.011410, loss_freq: 0.011649
[18:44:01.672] iteration 23394: loss: 0.072744, loss_s1: 0.084621, loss_fp: 0.006905, loss_freq: 0.018097
[18:44:02.292] iteration 23395: loss: 0.077495, loss_s1: 0.095483, loss_fp: 0.003536, loss_freq: 0.032573
[18:44:02.907] iteration 23396: loss: 0.069016, loss_s1: 0.073446, loss_fp: 0.000944, loss_freq: 0.030550
[18:44:03.529] iteration 23397: loss: 0.051361, loss_s1: 0.043647, loss_fp: 0.003587, loss_freq: 0.016850
[18:44:04.146] iteration 23398: loss: 0.059367, loss_s1: 0.044111, loss_fp: 0.002802, loss_freq: 0.036447
[18:44:04.774] iteration 23399: loss: 0.045302, loss_s1: 0.036178, loss_fp: 0.002118, loss_freq: 0.011114
[18:44:05.390] iteration 23400: loss: 0.027297, loss_s1: 0.012020, loss_fp: 0.000903, loss_freq: 0.011042
[18:44:08.556] iteration 23400 : mean_dice : 0.733569
[18:44:09.240] iteration 23401: loss: 0.064428, loss_s1: 0.065482, loss_fp: 0.005138, loss_freq: 0.019621
[18:44:09.894] iteration 23402: loss: 0.028417, loss_s1: 0.007657, loss_fp: 0.002802, loss_freq: 0.011542
[18:44:10.547] iteration 23403: loss: 0.063486, loss_s1: 0.046680, loss_fp: 0.016053, loss_freq: 0.013418
[18:44:11.205] iteration 23404: loss: 0.030732, loss_s1: 0.013298, loss_fp: 0.005814, loss_freq: 0.009633
[18:44:11.832] iteration 23405: loss: 0.033310, loss_s1: 0.013244, loss_fp: 0.001873, loss_freq: 0.025623
[18:44:12.451] iteration 23406: loss: 0.049215, loss_s1: 0.029095, loss_fp: 0.003327, loss_freq: 0.022920
[18:44:13.074] iteration 23407: loss: 0.036389, loss_s1: 0.024671, loss_fp: 0.001455, loss_freq: 0.019163
[18:44:13.694] iteration 23408: loss: 0.031183, loss_s1: 0.013700, loss_fp: 0.001447, loss_freq: 0.009281
[18:44:14.311] iteration 23409: loss: 0.043552, loss_s1: 0.043730, loss_fp: 0.002544, loss_freq: 0.014631
[18:44:14.930] iteration 23410: loss: 0.059796, loss_s1: 0.048651, loss_fp: 0.012977, loss_freq: 0.021615
[18:44:15.556] iteration 23411: loss: 0.072806, loss_s1: 0.028665, loss_fp: 0.004889, loss_freq: 0.084454
[18:44:16.174] iteration 23412: loss: 0.057833, loss_s1: 0.039743, loss_fp: 0.002992, loss_freq: 0.024459
[18:44:16.804] iteration 23413: loss: 0.077750, loss_s1: 0.080218, loss_fp: 0.005125, loss_freq: 0.044154
[18:44:17.426] iteration 23414: loss: 0.050443, loss_s1: 0.047598, loss_fp: 0.004316, loss_freq: 0.016756
[18:44:18.044] iteration 23415: loss: 0.066410, loss_s1: 0.034862, loss_fp: 0.002403, loss_freq: 0.036673
[18:44:18.660] iteration 23416: loss: 0.095496, loss_s1: 0.075365, loss_fp: 0.007335, loss_freq: 0.073027
[18:44:19.287] iteration 23417: loss: 0.042808, loss_s1: 0.022348, loss_fp: 0.002730, loss_freq: 0.029736
[18:44:19.902] iteration 23418: loss: 0.059723, loss_s1: 0.052879, loss_fp: 0.003381, loss_freq: 0.018405
[18:44:20.520] iteration 23419: loss: 0.055885, loss_s1: 0.046357, loss_fp: 0.004319, loss_freq: 0.014481
[18:44:21.140] iteration 23420: loss: 0.073027, loss_s1: 0.088536, loss_fp: 0.001448, loss_freq: 0.013272
[18:44:21.760] iteration 23421: loss: 0.043069, loss_s1: 0.031363, loss_fp: 0.001872, loss_freq: 0.007451
[18:44:22.388] iteration 23422: loss: 0.053784, loss_s1: 0.051612, loss_fp: 0.001808, loss_freq: 0.023718
[18:44:23.010] iteration 23423: loss: 0.058129, loss_s1: 0.074429, loss_fp: 0.000777, loss_freq: 0.007132
[18:44:23.636] iteration 23424: loss: 0.029877, loss_s1: 0.022572, loss_fp: 0.003120, loss_freq: 0.003273
[18:44:24.251] iteration 23425: loss: 0.051651, loss_s1: 0.049632, loss_fp: 0.001790, loss_freq: 0.016323
[18:44:24.864] iteration 23426: loss: 0.043585, loss_s1: 0.030648, loss_fp: 0.002368, loss_freq: 0.023309
[18:44:25.480] iteration 23427: loss: 0.051338, loss_s1: 0.047485, loss_fp: 0.001482, loss_freq: 0.027436
[18:44:26.099] iteration 23428: loss: 0.066797, loss_s1: 0.045994, loss_fp: 0.009201, loss_freq: 0.044334
[18:44:26.708] iteration 23429: loss: 0.058724, loss_s1: 0.043793, loss_fp: 0.002300, loss_freq: 0.027914
[18:44:27.324] iteration 23430: loss: 0.049336, loss_s1: 0.040043, loss_fp: 0.004660, loss_freq: 0.024052
[18:44:27.974] iteration 23431: loss: 0.048635, loss_s1: 0.027051, loss_fp: 0.001681, loss_freq: 0.027217
[18:44:28.635] iteration 23432: loss: 0.050858, loss_s1: 0.036430, loss_fp: 0.016567, loss_freq: 0.015544
[18:44:29.297] iteration 23433: loss: 0.055628, loss_s1: 0.051826, loss_fp: 0.005976, loss_freq: 0.017928
[18:44:29.959] iteration 23434: loss: 0.059697, loss_s1: 0.047830, loss_fp: 0.012050, loss_freq: 0.026275
[18:44:30.619] iteration 23435: loss: 0.067689, loss_s1: 0.064020, loss_fp: 0.007863, loss_freq: 0.031457
[18:44:31.267] iteration 23436: loss: 0.055850, loss_s1: 0.029670, loss_fp: 0.006663, loss_freq: 0.033468
[18:44:31.885] iteration 23437: loss: 0.046222, loss_s1: 0.022636, loss_fp: 0.006055, loss_freq: 0.025824
[18:44:32.506] iteration 23438: loss: 0.056523, loss_s1: 0.027682, loss_fp: 0.002822, loss_freq: 0.022993
[18:44:33.126] iteration 23439: loss: 0.031440, loss_s1: 0.014562, loss_fp: 0.002980, loss_freq: 0.014619
[18:44:33.749] iteration 23440: loss: 0.075664, loss_s1: 0.059727, loss_fp: 0.004619, loss_freq: 0.051639
[18:44:34.370] iteration 23441: loss: 0.042058, loss_s1: 0.026399, loss_fp: 0.006342, loss_freq: 0.024155
[18:44:34.989] iteration 23442: loss: 0.032086, loss_s1: 0.014782, loss_fp: 0.004351, loss_freq: 0.014642
[18:44:35.609] iteration 23443: loss: 0.041914, loss_s1: 0.019354, loss_fp: 0.001485, loss_freq: 0.020626
[18:44:36.229] iteration 23444: loss: 0.050971, loss_s1: 0.056274, loss_fp: 0.003044, loss_freq: 0.015198
[18:44:36.910] iteration 23445: loss: 0.035534, loss_s1: 0.026111, loss_fp: 0.002567, loss_freq: 0.007262
[18:44:37.538] iteration 23446: loss: 0.056876, loss_s1: 0.032109, loss_fp: 0.001518, loss_freq: 0.051386
[18:44:38.157] iteration 23447: loss: 0.076732, loss_s1: 0.063186, loss_fp: 0.001688, loss_freq: 0.048627
[18:44:38.768] iteration 23448: loss: 0.068375, loss_s1: 0.066305, loss_fp: 0.003060, loss_freq: 0.034407
[18:44:39.382] iteration 23449: loss: 0.041441, loss_s1: 0.040188, loss_fp: 0.006003, loss_freq: 0.008969
[18:44:39.999] iteration 23450: loss: 0.045912, loss_s1: 0.037051, loss_fp: 0.001391, loss_freq: 0.007961
[18:44:40.624] iteration 23451: loss: 0.035196, loss_s1: 0.023091, loss_fp: 0.002314, loss_freq: 0.012726
[18:44:41.245] iteration 23452: loss: 0.027308, loss_s1: 0.010679, loss_fp: 0.001239, loss_freq: 0.006609
[18:44:41.864] iteration 23453: loss: 0.064246, loss_s1: 0.042504, loss_fp: 0.000846, loss_freq: 0.056631
[18:44:42.485] iteration 23454: loss: 0.099350, loss_s1: 0.102187, loss_fp: 0.009106, loss_freq: 0.051887
[18:44:43.099] iteration 23455: loss: 0.047835, loss_s1: 0.036737, loss_fp: 0.001248, loss_freq: 0.026185
[18:44:43.716] iteration 23456: loss: 0.033588, loss_s1: 0.020827, loss_fp: 0.000636, loss_freq: 0.007414
[18:44:44.363] iteration 23457: loss: 0.075165, loss_s1: 0.066432, loss_fp: 0.003044, loss_freq: 0.051526
[18:44:45.016] iteration 23458: loss: 0.059387, loss_s1: 0.038129, loss_fp: 0.005353, loss_freq: 0.046974
[18:44:45.671] iteration 23459: loss: 0.046786, loss_s1: 0.035442, loss_fp: 0.000916, loss_freq: 0.028548
[18:44:46.327] iteration 23460: loss: 0.036490, loss_s1: 0.023265, loss_fp: 0.002357, loss_freq: 0.009023
[18:44:46.985] iteration 23461: loss: 0.039735, loss_s1: 0.027526, loss_fp: 0.003378, loss_freq: 0.018057
[18:44:47.610] iteration 23462: loss: 0.051835, loss_s1: 0.018741, loss_fp: 0.004657, loss_freq: 0.043233
[18:44:48.232] iteration 23463: loss: 0.025478, loss_s1: 0.008173, loss_fp: 0.000441, loss_freq: 0.012126
[18:44:48.844] iteration 23464: loss: 0.051689, loss_s1: 0.032264, loss_fp: 0.001695, loss_freq: 0.012451
[18:44:49.465] iteration 23465: loss: 0.055987, loss_s1: 0.050119, loss_fp: 0.002570, loss_freq: 0.036436
[18:44:50.085] iteration 23466: loss: 0.087078, loss_s1: 0.053334, loss_fp: 0.008231, loss_freq: 0.080502
[18:44:50.705] iteration 23467: loss: 0.092831, loss_s1: 0.083519, loss_fp: 0.000743, loss_freq: 0.054479
[18:44:51.321] iteration 23468: loss: 0.049711, loss_s1: 0.045354, loss_fp: 0.001481, loss_freq: 0.014930
[18:44:51.937] iteration 23469: loss: 0.038244, loss_s1: 0.011629, loss_fp: 0.004264, loss_freq: 0.011182
[18:44:52.554] iteration 23470: loss: 0.049622, loss_s1: 0.032240, loss_fp: 0.005512, loss_freq: 0.020352
[18:44:53.175] iteration 23471: loss: 0.039612, loss_s1: 0.013263, loss_fp: 0.001822, loss_freq: 0.028048
[18:44:53.791] iteration 23472: loss: 0.045311, loss_s1: 0.044553, loss_fp: 0.003261, loss_freq: 0.004881
[18:44:54.410] iteration 23473: loss: 0.060321, loss_s1: 0.011976, loss_fp: 0.002676, loss_freq: 0.012274
[18:44:55.026] iteration 23474: loss: 0.051175, loss_s1: 0.034245, loss_fp: 0.007263, loss_freq: 0.031813
[18:44:55.642] iteration 23475: loss: 0.073463, loss_s1: 0.053008, loss_fp: 0.002510, loss_freq: 0.045021
[18:44:56.256] iteration 23476: loss: 0.052184, loss_s1: 0.042440, loss_fp: 0.000997, loss_freq: 0.027011
[18:44:56.872] iteration 23477: loss: 0.062896, loss_s1: 0.065432, loss_fp: 0.011305, loss_freq: 0.019343
[18:44:57.489] iteration 23478: loss: 0.053215, loss_s1: 0.051830, loss_fp: 0.002709, loss_freq: 0.011038
[18:44:58.112] iteration 23479: loss: 0.066263, loss_s1: 0.061959, loss_fp: 0.006082, loss_freq: 0.014262
[18:44:58.731] iteration 23480: loss: 0.060930, loss_s1: 0.047850, loss_fp: 0.001231, loss_freq: 0.038929
[18:44:59.341] iteration 23481: loss: 0.067479, loss_s1: 0.060386, loss_fp: 0.002632, loss_freq: 0.040774
[18:44:59.955] iteration 23482: loss: 0.041842, loss_s1: 0.035446, loss_fp: 0.003235, loss_freq: 0.007987
[18:45:00.569] iteration 23483: loss: 0.045732, loss_s1: 0.031136, loss_fp: 0.001847, loss_freq: 0.027055
[18:45:01.185] iteration 23484: loss: 0.024391, loss_s1: 0.008531, loss_fp: 0.004971, loss_freq: 0.008474
[18:45:01.803] iteration 23485: loss: 0.087435, loss_s1: 0.067528, loss_fp: 0.010776, loss_freq: 0.042792
[18:45:02.426] iteration 23486: loss: 0.050242, loss_s1: 0.052146, loss_fp: 0.008618, loss_freq: 0.010759
[18:45:03.046] iteration 23487: loss: 0.065876, loss_s1: 0.054737, loss_fp: 0.003789, loss_freq: 0.041118
[18:45:03.659] iteration 23488: loss: 0.038681, loss_s1: 0.018866, loss_fp: 0.005577, loss_freq: 0.022670
[18:45:04.275] iteration 23489: loss: 0.064608, loss_s1: 0.052251, loss_fp: 0.006743, loss_freq: 0.030862
[18:45:04.890] iteration 23490: loss: 0.048450, loss_s1: 0.032097, loss_fp: 0.007448, loss_freq: 0.017193
[18:45:05.513] iteration 23491: loss: 0.055985, loss_s1: 0.042192, loss_fp: 0.005411, loss_freq: 0.014426
[18:45:06.133] iteration 23492: loss: 0.078368, loss_s1: 0.070317, loss_fp: 0.006614, loss_freq: 0.045516
[18:45:06.751] iteration 23493: loss: 0.026113, loss_s1: 0.016311, loss_fp: 0.002016, loss_freq: 0.008739
[18:45:07.368] iteration 23494: loss: 0.043469, loss_s1: 0.029557, loss_fp: 0.002115, loss_freq: 0.010961
[18:45:07.998] iteration 23495: loss: 0.112904, loss_s1: 0.086554, loss_fp: 0.017890, loss_freq: 0.070928
[18:45:08.621] iteration 23496: loss: 0.057782, loss_s1: 0.028593, loss_fp: 0.002405, loss_freq: 0.050910
[18:45:09.243] iteration 23497: loss: 0.091242, loss_s1: 0.093482, loss_fp: 0.004953, loss_freq: 0.047207
[18:45:09.857] iteration 23498: loss: 0.044388, loss_s1: 0.039058, loss_fp: 0.003212, loss_freq: 0.019332
[18:45:10.474] iteration 23499: loss: 0.048568, loss_s1: 0.033808, loss_fp: 0.007184, loss_freq: 0.018866
[18:45:11.090] iteration 23500: loss: 0.035632, loss_s1: 0.020467, loss_fp: 0.011331, loss_freq: 0.010791
[18:45:11.708] iteration 23501: loss: 0.055698, loss_s1: 0.049263, loss_fp: 0.002870, loss_freq: 0.024844
[18:45:12.326] iteration 23502: loss: 0.048190, loss_s1: 0.038669, loss_fp: 0.001520, loss_freq: 0.008632
[18:45:12.943] iteration 23503: loss: 0.068384, loss_s1: 0.063619, loss_fp: 0.005531, loss_freq: 0.032496
[18:45:13.571] iteration 23504: loss: 0.038820, loss_s1: 0.021009, loss_fp: 0.003963, loss_freq: 0.022440
[18:45:14.185] iteration 23505: loss: 0.053400, loss_s1: 0.041521, loss_fp: 0.002951, loss_freq: 0.018778
[18:45:14.801] iteration 23506: loss: 0.058037, loss_s1: 0.049556, loss_fp: 0.000567, loss_freq: 0.026523
[18:45:15.765] iteration 23507: loss: 0.040965, loss_s1: 0.037341, loss_fp: 0.003626, loss_freq: 0.011263
[18:45:16.386] iteration 23508: loss: 0.046993, loss_s1: 0.020125, loss_fp: 0.004890, loss_freq: 0.035525
[18:45:17.006] iteration 23509: loss: 0.037260, loss_s1: 0.021138, loss_fp: 0.001659, loss_freq: 0.021915
[18:45:17.627] iteration 23510: loss: 0.033145, loss_s1: 0.019188, loss_fp: 0.002382, loss_freq: 0.006679
[18:45:18.248] iteration 23511: loss: 0.044291, loss_s1: 0.029164, loss_fp: 0.002589, loss_freq: 0.016768
[18:45:18.863] iteration 23512: loss: 0.077887, loss_s1: 0.077208, loss_fp: 0.006446, loss_freq: 0.029616
[18:45:19.478] iteration 23513: loss: 0.026247, loss_s1: 0.009216, loss_fp: 0.001458, loss_freq: 0.011011
[18:45:20.098] iteration 23514: loss: 0.039677, loss_s1: 0.034315, loss_fp: 0.001726, loss_freq: 0.010626
[18:45:20.719] iteration 23515: loss: 0.067225, loss_s1: 0.057352, loss_fp: 0.006773, loss_freq: 0.032110
[18:45:21.386] iteration 23516: loss: 0.057635, loss_s1: 0.045564, loss_fp: 0.012105, loss_freq: 0.019977
[18:45:22.003] iteration 23517: loss: 0.054932, loss_s1: 0.036116, loss_fp: 0.001711, loss_freq: 0.015043
[18:45:22.627] iteration 23518: loss: 0.070967, loss_s1: 0.087306, loss_fp: 0.003478, loss_freq: 0.020381
[18:45:23.246] iteration 23519: loss: 0.061842, loss_s1: 0.043476, loss_fp: 0.006455, loss_freq: 0.047976
[18:45:23.873] iteration 23520: loss: 0.061731, loss_s1: 0.034094, loss_fp: 0.005455, loss_freq: 0.049259
[18:45:24.487] iteration 23521: loss: 0.048475, loss_s1: 0.039704, loss_fp: 0.004762, loss_freq: 0.021660
[18:45:25.111] iteration 23522: loss: 0.039788, loss_s1: 0.010118, loss_fp: 0.010612, loss_freq: 0.027748
[18:45:25.735] iteration 23523: loss: 0.052608, loss_s1: 0.040037, loss_fp: 0.002079, loss_freq: 0.017926
[18:45:26.356] iteration 23524: loss: 0.054525, loss_s1: 0.028356, loss_fp: 0.008395, loss_freq: 0.023723
[18:45:26.970] iteration 23525: loss: 0.034810, loss_s1: 0.024331, loss_fp: 0.000498, loss_freq: 0.012075
[18:45:27.584] iteration 23526: loss: 0.064970, loss_s1: 0.034785, loss_fp: 0.003389, loss_freq: 0.038817
[18:45:28.207] iteration 23527: loss: 0.036106, loss_s1: 0.025103, loss_fp: 0.000364, loss_freq: 0.008638
[18:45:28.825] iteration 23528: loss: 0.031618, loss_s1: 0.020286, loss_fp: 0.002145, loss_freq: 0.008051
[18:45:29.446] iteration 23529: loss: 0.053638, loss_s1: 0.017112, loss_fp: 0.000690, loss_freq: 0.042427
[18:45:30.064] iteration 23530: loss: 0.077226, loss_s1: 0.068677, loss_fp: 0.011955, loss_freq: 0.042331
[18:45:30.685] iteration 23531: loss: 0.030357, loss_s1: 0.017248, loss_fp: 0.001774, loss_freq: 0.016089
[18:45:31.300] iteration 23532: loss: 0.061138, loss_s1: 0.051286, loss_fp: 0.002171, loss_freq: 0.030864
[18:45:31.917] iteration 23533: loss: 0.023587, loss_s1: 0.011551, loss_fp: 0.000338, loss_freq: 0.004172
[18:45:32.536] iteration 23534: loss: 0.102840, loss_s1: 0.101033, loss_fp: 0.012030, loss_freq: 0.042575
[18:45:33.158] iteration 23535: loss: 0.063675, loss_s1: 0.061379, loss_fp: 0.002207, loss_freq: 0.027826
[18:45:33.781] iteration 23536: loss: 0.044155, loss_s1: 0.044692, loss_fp: 0.002728, loss_freq: 0.010742
[18:45:34.400] iteration 23537: loss: 0.039775, loss_s1: 0.029698, loss_fp: 0.004530, loss_freq: 0.022509
[18:45:35.018] iteration 23538: loss: 0.039869, loss_s1: 0.025425, loss_fp: 0.007218, loss_freq: 0.013158
[18:45:35.634] iteration 23539: loss: 0.045007, loss_s1: 0.029952, loss_fp: 0.005352, loss_freq: 0.024135
[18:45:36.259] iteration 23540: loss: 0.025948, loss_s1: 0.018038, loss_fp: 0.002158, loss_freq: 0.003630
[18:45:36.883] iteration 23541: loss: 0.059746, loss_s1: 0.053877, loss_fp: 0.003027, loss_freq: 0.025260
[18:45:37.502] iteration 23542: loss: 0.089671, loss_s1: 0.085286, loss_fp: 0.002982, loss_freq: 0.057158
[18:45:38.127] iteration 23543: loss: 0.076503, loss_s1: 0.047871, loss_fp: 0.010759, loss_freq: 0.026208
[18:45:38.742] iteration 23544: loss: 0.063066, loss_s1: 0.057057, loss_fp: 0.001809, loss_freq: 0.021016
[18:45:39.368] iteration 23545: loss: 0.069039, loss_s1: 0.050116, loss_fp: 0.009832, loss_freq: 0.037807
[18:45:39.989] iteration 23546: loss: 0.069856, loss_s1: 0.063882, loss_fp: 0.000657, loss_freq: 0.042168
[18:45:40.613] iteration 23547: loss: 0.033308, loss_s1: 0.020879, loss_fp: 0.002623, loss_freq: 0.006561
[18:45:41.232] iteration 23548: loss: 0.053238, loss_s1: 0.042849, loss_fp: 0.002705, loss_freq: 0.028063
[18:45:41.849] iteration 23549: loss: 0.051065, loss_s1: 0.055163, loss_fp: 0.001117, loss_freq: 0.015752
[18:45:42.473] iteration 23550: loss: 0.064722, loss_s1: 0.052458, loss_fp: 0.003587, loss_freq: 0.044808
[18:45:43.091] iteration 23551: loss: 0.052758, loss_s1: 0.020190, loss_fp: 0.002255, loss_freq: 0.041727
[18:45:43.726] iteration 23552: loss: 0.052613, loss_s1: 0.064733, loss_fp: 0.001220, loss_freq: 0.002740
[18:45:44.355] iteration 23553: loss: 0.038486, loss_s1: 0.028729, loss_fp: 0.001793, loss_freq: 0.016167
[18:45:44.983] iteration 23554: loss: 0.046538, loss_s1: 0.037632, loss_fp: 0.012722, loss_freq: 0.012712
[18:45:45.801] iteration 23555: loss: 0.057997, loss_s1: 0.050185, loss_fp: 0.002971, loss_freq: 0.034343
[18:45:46.416] iteration 23556: loss: 0.058774, loss_s1: 0.057783, loss_fp: 0.001975, loss_freq: 0.031180
[18:45:47.029] iteration 23557: loss: 0.040602, loss_s1: 0.022871, loss_fp: 0.001327, loss_freq: 0.024256
[18:45:47.647] iteration 23558: loss: 0.044651, loss_s1: 0.040854, loss_fp: 0.000749, loss_freq: 0.008945
[18:45:48.266] iteration 23559: loss: 0.065206, loss_s1: 0.044635, loss_fp: 0.002726, loss_freq: 0.032639
[18:45:48.882] iteration 23560: loss: 0.066228, loss_s1: 0.056660, loss_fp: 0.002935, loss_freq: 0.028966
[18:45:49.499] iteration 23561: loss: 0.048547, loss_s1: 0.048534, loss_fp: 0.001803, loss_freq: 0.006297
[18:45:50.119] iteration 23562: loss: 0.064576, loss_s1: 0.066848, loss_fp: 0.000561, loss_freq: 0.020919
[18:45:50.740] iteration 23563: loss: 0.031640, loss_s1: 0.016020, loss_fp: 0.001923, loss_freq: 0.007636
[18:45:51.349] iteration 23564: loss: 0.056898, loss_s1: 0.017797, loss_fp: 0.002723, loss_freq: 0.016513
[18:45:51.972] iteration 23565: loss: 0.057476, loss_s1: 0.050446, loss_fp: 0.003674, loss_freq: 0.016938
[18:45:52.597] iteration 23566: loss: 0.035950, loss_s1: 0.028313, loss_fp: 0.001975, loss_freq: 0.017317
[18:45:53.217] iteration 23567: loss: 0.046500, loss_s1: 0.043853, loss_fp: 0.001541, loss_freq: 0.019242
[18:45:53.848] iteration 23568: loss: 0.027943, loss_s1: 0.017026, loss_fp: 0.001279, loss_freq: 0.008668
[18:45:54.466] iteration 23569: loss: 0.046431, loss_s1: 0.035462, loss_fp: 0.003335, loss_freq: 0.012242
[18:45:55.081] iteration 23570: loss: 0.043282, loss_s1: 0.027003, loss_fp: 0.001783, loss_freq: 0.026924
[18:45:55.701] iteration 23571: loss: 0.047358, loss_s1: 0.040544, loss_fp: 0.002956, loss_freq: 0.018328
[18:45:56.319] iteration 23572: loss: 0.086572, loss_s1: 0.053489, loss_fp: 0.002708, loss_freq: 0.086275
[18:45:56.941] iteration 23573: loss: 0.056844, loss_s1: 0.023416, loss_fp: 0.006890, loss_freq: 0.028946
[18:45:57.556] iteration 23574: loss: 0.059859, loss_s1: 0.062346, loss_fp: 0.013676, loss_freq: 0.014865
[18:45:58.184] iteration 23575: loss: 0.051653, loss_s1: 0.036506, loss_fp: 0.003343, loss_freq: 0.034269
[18:45:58.806] iteration 23576: loss: 0.068178, loss_s1: 0.018036, loss_fp: 0.001790, loss_freq: 0.021930
[18:45:59.429] iteration 23577: loss: 0.066802, loss_s1: 0.034081, loss_fp: 0.008126, loss_freq: 0.057196
[18:46:00.049] iteration 23578: loss: 0.043824, loss_s1: 0.011542, loss_fp: 0.000384, loss_freq: 0.035484
[18:46:00.667] iteration 23579: loss: 0.038825, loss_s1: 0.030480, loss_fp: 0.003672, loss_freq: 0.013977
[18:46:01.283] iteration 23580: loss: 0.034669, loss_s1: 0.011521, loss_fp: 0.001496, loss_freq: 0.015090
[18:46:01.906] iteration 23581: loss: 0.082787, loss_s1: 0.097740, loss_fp: 0.004613, loss_freq: 0.029251
[18:46:02.525] iteration 23582: loss: 0.045104, loss_s1: 0.046727, loss_fp: 0.002004, loss_freq: 0.006919
[18:46:03.143] iteration 23583: loss: 0.057694, loss_s1: 0.058140, loss_fp: 0.004890, loss_freq: 0.028195
[18:46:03.775] iteration 23584: loss: 0.039706, loss_s1: 0.035744, loss_fp: 0.001212, loss_freq: 0.010827
[18:46:04.405] iteration 23585: loss: 0.034728, loss_s1: 0.036998, loss_fp: 0.001094, loss_freq: 0.007152
[18:46:05.026] iteration 23586: loss: 0.051367, loss_s1: 0.047206, loss_fp: 0.004589, loss_freq: 0.018598
[18:46:05.645] iteration 23587: loss: 0.062347, loss_s1: 0.026224, loss_fp: 0.005893, loss_freq: 0.062364
[18:46:06.262] iteration 23588: loss: 0.072543, loss_s1: 0.046877, loss_fp: 0.004663, loss_freq: 0.063436
[18:46:06.884] iteration 23589: loss: 0.079200, loss_s1: 0.086459, loss_fp: 0.006118, loss_freq: 0.037028
[18:46:07.508] iteration 23590: loss: 0.078525, loss_s1: 0.053092, loss_fp: 0.006812, loss_freq: 0.048183
[18:46:08.129] iteration 23591: loss: 0.062559, loss_s1: 0.040282, loss_fp: 0.004152, loss_freq: 0.050932
[18:46:08.747] iteration 23592: loss: 0.040796, loss_s1: 0.036453, loss_fp: 0.001639, loss_freq: 0.012782
[18:46:09.368] iteration 23593: loss: 0.036545, loss_s1: 0.010690, loss_fp: 0.013771, loss_freq: 0.011004
[18:46:09.986] iteration 23594: loss: 0.043005, loss_s1: 0.043657, loss_fp: 0.002498, loss_freq: 0.010207
[18:46:10.607] iteration 23595: loss: 0.033483, loss_s1: 0.019444, loss_fp: 0.001895, loss_freq: 0.011981
[18:46:11.226] iteration 23596: loss: 0.071751, loss_s1: 0.041260, loss_fp: 0.001481, loss_freq: 0.043510
[18:46:11.849] iteration 23597: loss: 0.065365, loss_s1: 0.064702, loss_fp: 0.006935, loss_freq: 0.016962
[18:46:12.472] iteration 23598: loss: 0.047949, loss_s1: 0.035922, loss_fp: 0.002118, loss_freq: 0.021381
[18:46:13.091] iteration 23599: loss: 0.071052, loss_s1: 0.075533, loss_fp: 0.000808, loss_freq: 0.020393
[18:46:13.711] iteration 23600: loss: 0.041965, loss_s1: 0.032199, loss_fp: 0.001192, loss_freq: 0.020021
[18:46:16.850] iteration 23600 : mean_dice : 0.712353
[18:46:17.488] iteration 23601: loss: 0.048081, loss_s1: 0.027499, loss_fp: 0.003914, loss_freq: 0.031869
[18:46:18.102] iteration 23602: loss: 0.050181, loss_s1: 0.025253, loss_fp: 0.007793, loss_freq: 0.036901
[18:46:18.719] iteration 23603: loss: 0.043434, loss_s1: 0.023204, loss_fp: 0.001863, loss_freq: 0.015139
[18:46:19.344] iteration 23604: loss: 0.051088, loss_s1: 0.047847, loss_fp: 0.001020, loss_freq: 0.012980
[18:46:19.965] iteration 23605: loss: 0.067021, loss_s1: 0.050210, loss_fp: 0.007741, loss_freq: 0.039273
[18:46:20.583] iteration 23606: loss: 0.036155, loss_s1: 0.022859, loss_fp: 0.001840, loss_freq: 0.018910
[18:46:21.205] iteration 23607: loss: 0.045700, loss_s1: 0.032003, loss_fp: 0.002361, loss_freq: 0.017420
[18:46:21.825] iteration 23608: loss: 0.083050, loss_s1: 0.066422, loss_fp: 0.005876, loss_freq: 0.060727
[18:46:22.447] iteration 23609: loss: 0.061072, loss_s1: 0.043450, loss_fp: 0.002326, loss_freq: 0.039923
[18:46:23.067] iteration 23610: loss: 0.058015, loss_s1: 0.040314, loss_fp: 0.009690, loss_freq: 0.032087
[18:46:23.688] iteration 23611: loss: 0.035162, loss_s1: 0.019302, loss_fp: 0.003285, loss_freq: 0.011814
[18:46:24.306] iteration 23612: loss: 0.039768, loss_s1: 0.024467, loss_fp: 0.004709, loss_freq: 0.016793
[18:46:24.923] iteration 23613: loss: 0.042918, loss_s1: 0.038973, loss_fp: 0.000164, loss_freq: 0.005335
[18:46:25.587] iteration 23614: loss: 0.088513, loss_s1: 0.087749, loss_fp: 0.003728, loss_freq: 0.041903
[18:46:26.207] iteration 23615: loss: 0.094922, loss_s1: 0.075306, loss_fp: 0.011315, loss_freq: 0.067027
[18:46:26.825] iteration 23616: loss: 0.060650, loss_s1: 0.053459, loss_fp: 0.001689, loss_freq: 0.037663
[18:46:27.439] iteration 23617: loss: 0.073781, loss_s1: 0.077071, loss_fp: 0.002963, loss_freq: 0.016777
[18:46:28.057] iteration 23618: loss: 0.041734, loss_s1: 0.013087, loss_fp: 0.004892, loss_freq: 0.030958
[18:46:28.677] iteration 23619: loss: 0.055692, loss_s1: 0.061685, loss_fp: 0.006104, loss_freq: 0.010774
[18:46:29.297] iteration 23620: loss: 0.049920, loss_s1: 0.020467, loss_fp: 0.006694, loss_freq: 0.033528
[18:46:29.910] iteration 23621: loss: 0.046844, loss_s1: 0.035890, loss_fp: 0.003464, loss_freq: 0.018923
[18:46:30.525] iteration 23622: loss: 0.055591, loss_s1: 0.046576, loss_fp: 0.001496, loss_freq: 0.029474
[18:46:31.175] iteration 23623: loss: 0.042350, loss_s1: 0.029215, loss_fp: 0.003109, loss_freq: 0.008157
[18:46:31.832] iteration 23624: loss: 0.037533, loss_s1: 0.031211, loss_fp: 0.002174, loss_freq: 0.009538
[18:46:32.486] iteration 23625: loss: 0.044733, loss_s1: 0.017186, loss_fp: 0.005526, loss_freq: 0.030472
[18:46:33.141] iteration 23626: loss: 0.093908, loss_s1: 0.078598, loss_fp: 0.001719, loss_freq: 0.079633
[18:46:33.795] iteration 23627: loss: 0.062349, loss_s1: 0.014317, loss_fp: 0.002203, loss_freq: 0.071692
[18:46:34.448] iteration 23628: loss: 0.092928, loss_s1: 0.079325, loss_fp: 0.029971, loss_freq: 0.023758
[18:46:35.068] iteration 23629: loss: 0.049010, loss_s1: 0.045655, loss_fp: 0.005964, loss_freq: 0.015097
[18:46:35.688] iteration 23630: loss: 0.044897, loss_s1: 0.026698, loss_fp: 0.006385, loss_freq: 0.012521
[18:46:36.312] iteration 23631: loss: 0.047544, loss_s1: 0.028449, loss_fp: 0.002565, loss_freq: 0.021826
[18:46:36.928] iteration 23632: loss: 0.070144, loss_s1: 0.045178, loss_fp: 0.002100, loss_freq: 0.029303
[18:46:37.544] iteration 23633: loss: 0.056957, loss_s1: 0.042275, loss_fp: 0.006807, loss_freq: 0.018418
[18:46:38.160] iteration 23634: loss: 0.071231, loss_s1: 0.054071, loss_fp: 0.003126, loss_freq: 0.038870
[18:46:38.776] iteration 23635: loss: 0.055654, loss_s1: 0.042391, loss_fp: 0.002601, loss_freq: 0.032924
[18:46:39.393] iteration 23636: loss: 0.035423, loss_s1: 0.028753, loss_fp: 0.008749, loss_freq: 0.006780
[18:46:40.009] iteration 23637: loss: 0.049179, loss_s1: 0.034048, loss_fp: 0.001712, loss_freq: 0.038179
[18:46:40.623] iteration 23638: loss: 0.062592, loss_s1: 0.064910, loss_fp: 0.002782, loss_freq: 0.028560
[18:46:41.246] iteration 23639: loss: 0.059384, loss_s1: 0.037966, loss_fp: 0.005680, loss_freq: 0.021312
[18:46:41.874] iteration 23640: loss: 0.034045, loss_s1: 0.027428, loss_fp: 0.001705, loss_freq: 0.012152
[18:46:42.524] iteration 23641: loss: 0.066138, loss_s1: 0.056841, loss_fp: 0.001811, loss_freq: 0.036779
[18:46:43.185] iteration 23642: loss: 0.062576, loss_s1: 0.070538, loss_fp: 0.003925, loss_freq: 0.021165
[18:46:43.837] iteration 23643: loss: 0.036627, loss_s1: 0.024568, loss_fp: 0.000339, loss_freq: 0.007068
[18:46:44.460] iteration 23644: loss: 0.049572, loss_s1: 0.041287, loss_fp: 0.003027, loss_freq: 0.022320
[18:46:45.085] iteration 23645: loss: 0.043276, loss_s1: 0.045496, loss_fp: 0.004555, loss_freq: 0.008857
[18:46:45.707] iteration 23646: loss: 0.064551, loss_s1: 0.044366, loss_fp: 0.003519, loss_freq: 0.031084
[18:46:46.327] iteration 23647: loss: 0.063915, loss_s1: 0.062996, loss_fp: 0.003726, loss_freq: 0.019888
[18:46:46.948] iteration 23648: loss: 0.041244, loss_s1: 0.036527, loss_fp: 0.004803, loss_freq: 0.010295
[18:46:47.569] iteration 23649: loss: 0.043328, loss_s1: 0.026549, loss_fp: 0.001942, loss_freq: 0.015267
[18:46:48.255] iteration 23650: loss: 0.063811, loss_s1: 0.059476, loss_fp: 0.004516, loss_freq: 0.023939
[18:46:48.916] iteration 23651: loss: 0.059554, loss_s1: 0.044504, loss_fp: 0.005424, loss_freq: 0.033915
[18:46:49.574] iteration 23652: loss: 0.071837, loss_s1: 0.064646, loss_fp: 0.009459, loss_freq: 0.030867
[18:46:50.239] iteration 23653: loss: 0.077502, loss_s1: 0.050214, loss_fp: 0.003392, loss_freq: 0.077427
[18:46:50.898] iteration 23654: loss: 0.034049, loss_s1: 0.025189, loss_fp: 0.000816, loss_freq: 0.010927
[18:46:51.559] iteration 23655: loss: 0.039000, loss_s1: 0.030258, loss_fp: 0.002355, loss_freq: 0.012417
[18:46:52.232] iteration 23656: loss: 0.058702, loss_s1: 0.054994, loss_fp: 0.000819, loss_freq: 0.026405
[18:46:52.874] iteration 23657: loss: 0.039519, loss_s1: 0.014748, loss_fp: 0.002952, loss_freq: 0.026532
[18:46:53.505] iteration 23658: loss: 0.076799, loss_s1: 0.092035, loss_fp: 0.007943, loss_freq: 0.023177
[18:46:54.131] iteration 23659: loss: 0.049942, loss_s1: 0.045730, loss_fp: 0.009434, loss_freq: 0.017006
[18:46:54.754] iteration 23660: loss: 0.040526, loss_s1: 0.022609, loss_fp: 0.004719, loss_freq: 0.019284
[18:46:55.372] iteration 23661: loss: 0.028541, loss_s1: 0.012662, loss_fp: 0.002820, loss_freq: 0.011917
[18:46:55.999] iteration 23662: loss: 0.053415, loss_s1: 0.052699, loss_fp: 0.000597, loss_freq: 0.015937
[18:46:56.617] iteration 23663: loss: 0.039818, loss_s1: 0.023893, loss_fp: 0.000898, loss_freq: 0.010438
[18:46:57.239] iteration 23664: loss: 0.042603, loss_s1: 0.034667, loss_fp: 0.000721, loss_freq: 0.015140
[18:46:57.876] iteration 23665: loss: 0.050399, loss_s1: 0.031854, loss_fp: 0.023021, loss_freq: 0.010532
[18:46:58.498] iteration 23666: loss: 0.048231, loss_s1: 0.015655, loss_fp: 0.008428, loss_freq: 0.032579
[18:46:59.115] iteration 23667: loss: 0.038068, loss_s1: 0.015284, loss_fp: 0.005499, loss_freq: 0.022067
[18:47:00.161] iteration 23668: loss: 0.039082, loss_s1: 0.025289, loss_fp: 0.007143, loss_freq: 0.017391
[18:47:00.818] iteration 23669: loss: 0.072374, loss_s1: 0.068435, loss_fp: 0.004421, loss_freq: 0.043154
[18:47:01.476] iteration 23670: loss: 0.034801, loss_s1: 0.022742, loss_fp: 0.000851, loss_freq: 0.015080
[18:47:02.136] iteration 23671: loss: 0.030969, loss_s1: 0.016563, loss_fp: 0.002312, loss_freq: 0.006952
[18:47:02.798] iteration 23672: loss: 0.043231, loss_s1: 0.025115, loss_fp: 0.001287, loss_freq: 0.025240
[18:47:03.456] iteration 23673: loss: 0.105598, loss_s1: 0.100745, loss_fp: 0.008569, loss_freq: 0.040627
[18:47:04.072] iteration 23674: loss: 0.034049, loss_s1: 0.022161, loss_fp: 0.001748, loss_freq: 0.009568
[18:47:04.690] iteration 23675: loss: 0.031090, loss_s1: 0.014791, loss_fp: 0.002354, loss_freq: 0.017065
[18:47:05.318] iteration 23676: loss: 0.068321, loss_s1: 0.061434, loss_fp: 0.005724, loss_freq: 0.045394
[18:47:05.949] iteration 23677: loss: 0.053733, loss_s1: 0.050633, loss_fp: 0.005976, loss_freq: 0.012476
[18:47:06.584] iteration 23678: loss: 0.037002, loss_s1: 0.026959, loss_fp: 0.000735, loss_freq: 0.011651
[18:47:07.210] iteration 23679: loss: 0.042835, loss_s1: 0.029621, loss_fp: 0.005036, loss_freq: 0.019326
[18:47:07.887] iteration 23680: loss: 0.051230, loss_s1: 0.022089, loss_fp: 0.008862, loss_freq: 0.041147
[18:47:08.519] iteration 23681: loss: 0.048209, loss_s1: 0.021247, loss_fp: 0.003814, loss_freq: 0.027163
[18:47:09.136] iteration 23682: loss: 0.045724, loss_s1: 0.033134, loss_fp: 0.006393, loss_freq: 0.017951
[18:47:09.755] iteration 23683: loss: 0.069896, loss_s1: 0.025407, loss_fp: 0.004835, loss_freq: 0.049400
[18:47:10.377] iteration 23684: loss: 0.041486, loss_s1: 0.036187, loss_fp: 0.000955, loss_freq: 0.011292
[18:47:11.005] iteration 23685: loss: 0.048824, loss_s1: 0.034043, loss_fp: 0.008898, loss_freq: 0.026066
[18:47:11.630] iteration 23686: loss: 0.048937, loss_s1: 0.029325, loss_fp: 0.003268, loss_freq: 0.026252
[18:47:12.254] iteration 23687: loss: 0.039860, loss_s1: 0.024100, loss_fp: 0.000602, loss_freq: 0.019810
[18:47:12.877] iteration 23688: loss: 0.033898, loss_s1: 0.027286, loss_fp: 0.000515, loss_freq: 0.005239
[18:47:13.499] iteration 23689: loss: 0.044716, loss_s1: 0.025304, loss_fp: 0.003456, loss_freq: 0.017308
[18:47:14.117] iteration 23690: loss: 0.065037, loss_s1: 0.035173, loss_fp: 0.002536, loss_freq: 0.034715
[18:47:14.739] iteration 23691: loss: 0.060271, loss_s1: 0.072375, loss_fp: 0.004694, loss_freq: 0.012463
[18:47:15.352] iteration 23692: loss: 0.049483, loss_s1: 0.044244, loss_fp: 0.001146, loss_freq: 0.019182
[18:47:15.974] iteration 23693: loss: 0.036384, loss_s1: 0.031676, loss_fp: 0.001425, loss_freq: 0.013726
[18:47:16.594] iteration 23694: loss: 0.025538, loss_s1: 0.009773, loss_fp: 0.000428, loss_freq: 0.003756
[18:47:17.215] iteration 23695: loss: 0.065583, loss_s1: 0.047454, loss_fp: 0.005210, loss_freq: 0.042928
[18:47:17.875] iteration 23696: loss: 0.049019, loss_s1: 0.049939, loss_fp: 0.005338, loss_freq: 0.015718
[18:47:18.529] iteration 23697: loss: 0.067701, loss_s1: 0.052195, loss_fp: 0.003884, loss_freq: 0.011685
[18:47:19.144] iteration 23698: loss: 0.055808, loss_s1: 0.052427, loss_fp: 0.002919, loss_freq: 0.027671
[18:47:19.765] iteration 23699: loss: 0.057827, loss_s1: 0.048473, loss_fp: 0.001742, loss_freq: 0.019103
[18:47:20.379] iteration 23700: loss: 0.065117, loss_s1: 0.070132, loss_fp: 0.002926, loss_freq: 0.025148
[18:47:20.999] iteration 23701: loss: 0.031576, loss_s1: 0.020405, loss_fp: 0.001572, loss_freq: 0.006365
[18:47:21.620] iteration 23702: loss: 0.072425, loss_s1: 0.079290, loss_fp: 0.006410, loss_freq: 0.021562
[18:47:22.243] iteration 23703: loss: 0.046769, loss_s1: 0.023252, loss_fp: 0.001959, loss_freq: 0.037659
[18:47:22.855] iteration 23704: loss: 0.103874, loss_s1: 0.129591, loss_fp: 0.010554, loss_freq: 0.031478
[18:47:23.480] iteration 23705: loss: 0.059085, loss_s1: 0.054234, loss_fp: 0.004812, loss_freq: 0.024860
[18:47:24.108] iteration 23706: loss: 0.084384, loss_s1: 0.074316, loss_fp: 0.002620, loss_freq: 0.043117
[18:47:24.727] iteration 23707: loss: 0.052914, loss_s1: 0.037180, loss_fp: 0.001812, loss_freq: 0.027433
[18:47:25.346] iteration 23708: loss: 0.060924, loss_s1: 0.047431, loss_fp: 0.010461, loss_freq: 0.028846
[18:47:25.970] iteration 23709: loss: 0.055369, loss_s1: 0.037258, loss_fp: 0.002177, loss_freq: 0.036530
[18:47:26.591] iteration 23710: loss: 0.093857, loss_s1: 0.083877, loss_fp: 0.014414, loss_freq: 0.039054
[18:47:27.211] iteration 23711: loss: 0.059201, loss_s1: 0.033994, loss_fp: 0.007169, loss_freq: 0.043317
[18:47:27.839] iteration 23712: loss: 0.055942, loss_s1: 0.035190, loss_fp: 0.000911, loss_freq: 0.038859
[18:47:28.458] iteration 23713: loss: 0.030752, loss_s1: 0.010442, loss_fp: 0.008235, loss_freq: 0.006518
[18:47:29.076] iteration 23714: loss: 0.024170, loss_s1: 0.013242, loss_fp: 0.000591, loss_freq: 0.006240
[18:47:29.698] iteration 23715: loss: 0.048692, loss_s1: 0.039181, loss_fp: 0.010052, loss_freq: 0.022150
[18:47:30.316] iteration 23716: loss: 0.060719, loss_s1: 0.047217, loss_fp: 0.001453, loss_freq: 0.028221
[18:47:30.932] iteration 23717: loss: 0.097540, loss_s1: 0.078604, loss_fp: 0.003332, loss_freq: 0.084562
[18:47:31.550] iteration 23718: loss: 0.055499, loss_s1: 0.035057, loss_fp: 0.002711, loss_freq: 0.038211
[18:47:32.166] iteration 23719: loss: 0.048240, loss_s1: 0.031694, loss_fp: 0.002612, loss_freq: 0.020867
[18:47:32.783] iteration 23720: loss: 0.061785, loss_s1: 0.039784, loss_fp: 0.008507, loss_freq: 0.044087
[18:47:33.409] iteration 23721: loss: 0.069200, loss_s1: 0.062989, loss_fp: 0.003131, loss_freq: 0.030773
[18:47:34.029] iteration 23722: loss: 0.031532, loss_s1: 0.013686, loss_fp: 0.002373, loss_freq: 0.015763
[18:47:34.643] iteration 23723: loss: 0.065771, loss_s1: 0.056472, loss_fp: 0.006693, loss_freq: 0.029087
[18:47:35.267] iteration 23724: loss: 0.035419, loss_s1: 0.026173, loss_fp: 0.002388, loss_freq: 0.009131
[18:47:35.885] iteration 23725: loss: 0.043272, loss_s1: 0.030704, loss_fp: 0.003616, loss_freq: 0.011096
[18:47:36.506] iteration 23726: loss: 0.044406, loss_s1: 0.039050, loss_fp: 0.007091, loss_freq: 0.013886
[18:47:37.130] iteration 23727: loss: 0.041016, loss_s1: 0.034547, loss_fp: 0.001783, loss_freq: 0.021951
[18:47:37.755] iteration 23728: loss: 0.060777, loss_s1: 0.052171, loss_fp: 0.002617, loss_freq: 0.037369
[18:47:38.377] iteration 23729: loss: 0.041591, loss_s1: 0.023883, loss_fp: 0.005322, loss_freq: 0.024063
[18:47:39.002] iteration 23730: loss: 0.041169, loss_s1: 0.020143, loss_fp: 0.002659, loss_freq: 0.020449
[18:47:39.629] iteration 23731: loss: 0.041107, loss_s1: 0.020349, loss_fp: 0.003946, loss_freq: 0.018542
[18:47:40.248] iteration 23732: loss: 0.047965, loss_s1: 0.040353, loss_fp: 0.004869, loss_freq: 0.015430
[18:47:40.873] iteration 23733: loss: 0.059976, loss_s1: 0.030114, loss_fp: 0.003716, loss_freq: 0.054805
[18:47:41.489] iteration 23734: loss: 0.045219, loss_s1: 0.037136, loss_fp: 0.001848, loss_freq: 0.016700
[18:47:42.106] iteration 23735: loss: 0.069111, loss_s1: 0.055232, loss_fp: 0.007734, loss_freq: 0.042679
[18:47:42.725] iteration 23736: loss: 0.049817, loss_s1: 0.039134, loss_fp: 0.006063, loss_freq: 0.027539
[18:47:43.344] iteration 23737: loss: 0.056071, loss_s1: 0.040944, loss_fp: 0.005328, loss_freq: 0.018568
[18:47:43.958] iteration 23738: loss: 0.056736, loss_s1: 0.040340, loss_fp: 0.007893, loss_freq: 0.040184
[18:47:44.588] iteration 23739: loss: 0.062918, loss_s1: 0.036494, loss_fp: 0.002080, loss_freq: 0.035721
[18:47:45.205] iteration 23740: loss: 0.040411, loss_s1: 0.026124, loss_fp: 0.002379, loss_freq: 0.020344
[18:47:45.824] iteration 23741: loss: 0.043962, loss_s1: 0.039009, loss_fp: 0.001984, loss_freq: 0.008518
[18:47:46.442] iteration 23742: loss: 0.053467, loss_s1: 0.035307, loss_fp: 0.007448, loss_freq: 0.036269
[18:47:47.065] iteration 23743: loss: 0.044524, loss_s1: 0.022906, loss_fp: 0.009397, loss_freq: 0.003789
[18:47:47.683] iteration 23744: loss: 0.037548, loss_s1: 0.013673, loss_fp: 0.004640, loss_freq: 0.020475
[18:47:48.305] iteration 23745: loss: 0.063360, loss_s1: 0.065736, loss_fp: 0.000748, loss_freq: 0.032116
[18:47:48.933] iteration 23746: loss: 0.039330, loss_s1: 0.029658, loss_fp: 0.005144, loss_freq: 0.010540
[18:47:49.851] iteration 23747: loss: 0.064871, loss_s1: 0.058729, loss_fp: 0.002729, loss_freq: 0.025387
[18:47:50.552] iteration 23748: loss: 0.045632, loss_s1: 0.028956, loss_fp: 0.005690, loss_freq: 0.020080
[18:47:51.179] iteration 23749: loss: 0.055871, loss_s1: 0.061062, loss_fp: 0.003536, loss_freq: 0.016911
[18:47:51.794] iteration 23750: loss: 0.052013, loss_s1: 0.064589, loss_fp: 0.001778, loss_freq: 0.007930
[18:47:52.412] iteration 23751: loss: 0.073105, loss_s1: 0.030772, loss_fp: 0.009398, loss_freq: 0.067776
[18:47:53.049] iteration 23752: loss: 0.117895, loss_s1: 0.104147, loss_fp: 0.006756, loss_freq: 0.100147
[18:47:53.667] iteration 23753: loss: 0.056628, loss_s1: 0.059531, loss_fp: 0.004963, loss_freq: 0.017015
[18:47:54.285] iteration 23754: loss: 0.055202, loss_s1: 0.040108, loss_fp: 0.003772, loss_freq: 0.025973
[18:47:54.898] iteration 23755: loss: 0.058352, loss_s1: 0.051912, loss_fp: 0.001167, loss_freq: 0.009527
[18:47:55.516] iteration 23756: loss: 0.074269, loss_s1: 0.063413, loss_fp: 0.015333, loss_freq: 0.034425
[18:47:56.136] iteration 23757: loss: 0.056451, loss_s1: 0.041849, loss_fp: 0.004615, loss_freq: 0.033807
[18:47:56.755] iteration 23758: loss: 0.058614, loss_s1: 0.036391, loss_fp: 0.010548, loss_freq: 0.028462
[18:47:57.387] iteration 23759: loss: 0.062720, loss_s1: 0.037427, loss_fp: 0.004899, loss_freq: 0.039382
[18:47:58.005] iteration 23760: loss: 0.065673, loss_s1: 0.032890, loss_fp: 0.003071, loss_freq: 0.029554
[18:47:58.696] iteration 23761: loss: 0.028565, loss_s1: 0.022552, loss_fp: 0.003669, loss_freq: 0.003963
[18:47:59.353] iteration 23762: loss: 0.049596, loss_s1: 0.033380, loss_fp: 0.001871, loss_freq: 0.036784
[18:48:00.014] iteration 23763: loss: 0.056006, loss_s1: 0.035644, loss_fp: 0.001425, loss_freq: 0.040190
[18:48:00.670] iteration 23764: loss: 0.038964, loss_s1: 0.019293, loss_fp: 0.004155, loss_freq: 0.017262
[18:48:01.321] iteration 23765: loss: 0.043257, loss_s1: 0.024188, loss_fp: 0.000829, loss_freq: 0.022945
[18:48:01.939] iteration 23766: loss: 0.047310, loss_s1: 0.041115, loss_fp: 0.002588, loss_freq: 0.009632
[18:48:02.555] iteration 23767: loss: 0.038686, loss_s1: 0.027221, loss_fp: 0.004457, loss_freq: 0.009972
[18:48:03.174] iteration 23768: loss: 0.060937, loss_s1: 0.069199, loss_fp: 0.005106, loss_freq: 0.017251
[18:48:03.791] iteration 23769: loss: 0.066359, loss_s1: 0.054502, loss_fp: 0.004749, loss_freq: 0.042921
[18:48:04.410] iteration 23770: loss: 0.057335, loss_s1: 0.038379, loss_fp: 0.003092, loss_freq: 0.034548
[18:48:05.028] iteration 23771: loss: 0.085023, loss_s1: 0.113436, loss_fp: 0.004282, loss_freq: 0.019168
[18:48:05.644] iteration 23772: loss: 0.070732, loss_s1: 0.047730, loss_fp: 0.001655, loss_freq: 0.006690
[18:48:06.273] iteration 23773: loss: 0.044887, loss_s1: 0.025976, loss_fp: 0.004863, loss_freq: 0.030923
[18:48:06.889] iteration 23774: loss: 0.062364, loss_s1: 0.046099, loss_fp: 0.003890, loss_freq: 0.038439
[18:48:07.511] iteration 23775: loss: 0.072784, loss_s1: 0.082838, loss_fp: 0.006022, loss_freq: 0.024915
[18:48:08.134] iteration 23776: loss: 0.080443, loss_s1: 0.045021, loss_fp: 0.015328, loss_freq: 0.057585
[18:48:08.750] iteration 23777: loss: 0.048356, loss_s1: 0.020393, loss_fp: 0.010655, loss_freq: 0.028323
[18:48:09.375] iteration 23778: loss: 0.051432, loss_s1: 0.038894, loss_fp: 0.002712, loss_freq: 0.024207
[18:48:09.998] iteration 23779: loss: 0.075901, loss_s1: 0.054502, loss_fp: 0.004933, loss_freq: 0.058380
[18:48:10.612] iteration 23780: loss: 0.044439, loss_s1: 0.046699, loss_fp: 0.002117, loss_freq: 0.014142
[18:48:11.228] iteration 23781: loss: 0.029012, loss_s1: 0.017152, loss_fp: 0.002061, loss_freq: 0.012415
[18:48:11.854] iteration 23782: loss: 0.031793, loss_s1: 0.021411, loss_fp: 0.003067, loss_freq: 0.005894
[18:48:12.470] iteration 23783: loss: 0.066430, loss_s1: 0.069604, loss_fp: 0.004193, loss_freq: 0.021792
[18:48:13.085] iteration 23784: loss: 0.048104, loss_s1: 0.047017, loss_fp: 0.001691, loss_freq: 0.020492
[18:48:13.703] iteration 23785: loss: 0.037886, loss_s1: 0.030493, loss_fp: 0.002279, loss_freq: 0.016926
[18:48:14.322] iteration 23786: loss: 0.059860, loss_s1: 0.045437, loss_fp: 0.004362, loss_freq: 0.034785
[18:48:14.944] iteration 23787: loss: 0.099129, loss_s1: 0.060259, loss_fp: 0.002677, loss_freq: 0.094033
[18:48:15.601] iteration 23788: loss: 0.043329, loss_s1: 0.032587, loss_fp: 0.000152, loss_freq: 0.022485
[18:48:16.236] iteration 23789: loss: 0.062370, loss_s1: 0.044998, loss_fp: 0.002902, loss_freq: 0.041822
[18:48:16.864] iteration 23790: loss: 0.047306, loss_s1: 0.040446, loss_fp: 0.004776, loss_freq: 0.011712
[18:48:17.488] iteration 23791: loss: 0.029528, loss_s1: 0.014842, loss_fp: 0.001028, loss_freq: 0.009030
[18:48:18.106] iteration 23792: loss: 0.055410, loss_s1: 0.045127, loss_fp: 0.005541, loss_freq: 0.030731
[18:48:18.735] iteration 23793: loss: 0.033466, loss_s1: 0.017285, loss_fp: 0.001178, loss_freq: 0.013213
[18:48:19.354] iteration 23794: loss: 0.044235, loss_s1: 0.034563, loss_fp: 0.004938, loss_freq: 0.011480
[18:48:19.987] iteration 23795: loss: 0.042319, loss_s1: 0.016393, loss_fp: 0.003449, loss_freq: 0.014921
[18:48:20.611] iteration 23796: loss: 0.050504, loss_s1: 0.033361, loss_fp: 0.001358, loss_freq: 0.034683
[18:48:21.277] iteration 23797: loss: 0.055706, loss_s1: 0.055487, loss_fp: 0.006619, loss_freq: 0.018408
[18:48:21.937] iteration 23798: loss: 0.058492, loss_s1: 0.046068, loss_fp: 0.003277, loss_freq: 0.030890
[18:48:22.590] iteration 23799: loss: 0.040998, loss_s1: 0.032297, loss_fp: 0.001283, loss_freq: 0.018119
[18:48:23.216] iteration 23800: loss: 0.056550, loss_s1: 0.059259, loss_fp: 0.002935, loss_freq: 0.018432
[18:48:26.409] iteration 23800 : mean_dice : 0.721003
[18:48:27.063] iteration 23801: loss: 0.040453, loss_s1: 0.021012, loss_fp: 0.001877, loss_freq: 0.027100
[18:48:27.680] iteration 23802: loss: 0.074737, loss_s1: 0.087619, loss_fp: 0.001070, loss_freq: 0.032876
[18:48:28.369] iteration 23803: loss: 0.048780, loss_s1: 0.050137, loss_fp: 0.001002, loss_freq: 0.016397
[18:48:29.038] iteration 23804: loss: 0.037162, loss_s1: 0.027042, loss_fp: 0.000906, loss_freq: 0.008170
[18:48:29.695] iteration 23805: loss: 0.035239, loss_s1: 0.029627, loss_fp: 0.001381, loss_freq: 0.009424
[18:48:30.337] iteration 23806: loss: 0.034017, loss_s1: 0.019491, loss_fp: 0.003465, loss_freq: 0.014081
[18:48:30.955] iteration 23807: loss: 0.059720, loss_s1: 0.061936, loss_fp: 0.005899, loss_freq: 0.011655
[18:48:31.580] iteration 23808: loss: 0.056345, loss_s1: 0.037099, loss_fp: 0.002882, loss_freq: 0.023552
[18:48:32.198] iteration 23809: loss: 0.052521, loss_s1: 0.047806, loss_fp: 0.001489, loss_freq: 0.026199
[18:48:32.818] iteration 23810: loss: 0.048495, loss_s1: 0.027073, loss_fp: 0.009266, loss_freq: 0.027161
[18:48:33.440] iteration 23811: loss: 0.047665, loss_s1: 0.031613, loss_fp: 0.002137, loss_freq: 0.021758
[18:48:34.058] iteration 23812: loss: 0.035626, loss_s1: 0.015080, loss_fp: 0.001602, loss_freq: 0.013222
[18:48:34.692] iteration 23813: loss: 0.063130, loss_s1: 0.047189, loss_fp: 0.009489, loss_freq: 0.022997
[18:48:35.309] iteration 23814: loss: 0.057914, loss_s1: 0.041450, loss_fp: 0.003470, loss_freq: 0.046159
[18:48:35.933] iteration 23815: loss: 0.035813, loss_s1: 0.028874, loss_fp: 0.001359, loss_freq: 0.007459
[18:48:36.593] iteration 23816: loss: 0.041096, loss_s1: 0.037434, loss_fp: 0.009364, loss_freq: 0.006669
[18:48:37.210] iteration 23817: loss: 0.058340, loss_s1: 0.048068, loss_fp: 0.001287, loss_freq: 0.026261
[18:48:37.832] iteration 23818: loss: 0.050312, loss_s1: 0.035222, loss_fp: 0.007492, loss_freq: 0.012017
[18:48:38.457] iteration 23819: loss: 0.082305, loss_s1: 0.090888, loss_fp: 0.015071, loss_freq: 0.026641
[18:48:39.076] iteration 23820: loss: 0.052219, loss_s1: 0.047842, loss_fp: 0.002593, loss_freq: 0.025396
[18:48:39.701] iteration 23821: loss: 0.059161, loss_s1: 0.051680, loss_fp: 0.010199, loss_freq: 0.017465
[18:48:40.323] iteration 23822: loss: 0.026164, loss_s1: 0.008131, loss_fp: 0.003760, loss_freq: 0.007448
[18:48:40.947] iteration 23823: loss: 0.055484, loss_s1: 0.051980, loss_fp: 0.003311, loss_freq: 0.020239
[18:48:41.579] iteration 23824: loss: 0.050466, loss_s1: 0.048830, loss_fp: 0.001277, loss_freq: 0.008390
[18:48:42.256] iteration 23825: loss: 0.061416, loss_s1: 0.033312, loss_fp: 0.004968, loss_freq: 0.029181
[18:48:42.911] iteration 23826: loss: 0.062062, loss_s1: 0.048921, loss_fp: 0.008446, loss_freq: 0.031023
[18:48:43.569] iteration 23827: loss: 0.056742, loss_s1: 0.043097, loss_fp: 0.003253, loss_freq: 0.029448
[18:48:44.223] iteration 23828: loss: 0.054889, loss_s1: 0.027231, loss_fp: 0.004973, loss_freq: 0.036435
[18:48:45.180] iteration 23829: loss: 0.042232, loss_s1: 0.036868, loss_fp: 0.002343, loss_freq: 0.011281
[18:48:45.802] iteration 23830: loss: 0.046412, loss_s1: 0.034207, loss_fp: 0.004533, loss_freq: 0.020018
[18:48:46.426] iteration 23831: loss: 0.044636, loss_s1: 0.022098, loss_fp: 0.002505, loss_freq: 0.031059
[18:48:47.045] iteration 23832: loss: 0.037458, loss_s1: 0.027348, loss_fp: 0.001441, loss_freq: 0.008209
[18:48:47.659] iteration 23833: loss: 0.044719, loss_s1: 0.032123, loss_fp: 0.000737, loss_freq: 0.022997
[18:48:48.271] iteration 23834: loss: 0.071715, loss_s1: 0.050926, loss_fp: 0.001032, loss_freq: 0.038145
[18:48:48.891] iteration 23835: loss: 0.052656, loss_s1: 0.041679, loss_fp: 0.006368, loss_freq: 0.021046
[18:48:49.509] iteration 23836: loss: 0.021283, loss_s1: 0.009910, loss_fp: 0.002138, loss_freq: 0.005260
[18:48:50.129] iteration 23837: loss: 0.046667, loss_s1: 0.040340, loss_fp: 0.005250, loss_freq: 0.015075
[18:48:50.752] iteration 23838: loss: 0.049071, loss_s1: 0.035233, loss_fp: 0.006137, loss_freq: 0.023909
[18:48:51.368] iteration 23839: loss: 0.039301, loss_s1: 0.013699, loss_fp: 0.002630, loss_freq: 0.010931
[18:48:51.983] iteration 23840: loss: 0.049962, loss_s1: 0.056453, loss_fp: 0.001162, loss_freq: 0.017754
[18:48:52.605] iteration 23841: loss: 0.062733, loss_s1: 0.033625, loss_fp: 0.011369, loss_freq: 0.055835
[18:48:53.227] iteration 23842: loss: 0.047772, loss_s1: 0.029044, loss_fp: 0.010727, loss_freq: 0.017788
[18:48:53.840] iteration 23843: loss: 0.060987, loss_s1: 0.063616, loss_fp: 0.003309, loss_freq: 0.026359
[18:48:54.457] iteration 23844: loss: 0.079059, loss_s1: 0.027356, loss_fp: 0.003430, loss_freq: 0.094405
[18:48:55.076] iteration 23845: loss: 0.044561, loss_s1: 0.018262, loss_fp: 0.006237, loss_freq: 0.021948
[18:48:55.698] iteration 23846: loss: 0.085650, loss_s1: 0.101705, loss_fp: 0.003215, loss_freq: 0.031493
[18:48:56.318] iteration 23847: loss: 0.044147, loss_s1: 0.019991, loss_fp: 0.003197, loss_freq: 0.019134
[18:48:56.940] iteration 23848: loss: 0.062374, loss_s1: 0.039543, loss_fp: 0.009409, loss_freq: 0.024165
[18:48:57.562] iteration 23849: loss: 0.032328, loss_s1: 0.014304, loss_fp: 0.002564, loss_freq: 0.014310
[18:48:58.212] iteration 23850: loss: 0.049428, loss_s1: 0.039475, loss_fp: 0.003709, loss_freq: 0.018934
[18:48:58.833] iteration 23851: loss: 0.035475, loss_s1: 0.020310, loss_fp: 0.001912, loss_freq: 0.011664
[18:48:59.449] iteration 23852: loss: 0.049210, loss_s1: 0.038669, loss_fp: 0.002542, loss_freq: 0.023625
[18:49:00.070] iteration 23853: loss: 0.047301, loss_s1: 0.035769, loss_fp: 0.008339, loss_freq: 0.024114
[18:49:00.690] iteration 23854: loss: 0.065012, loss_s1: 0.072420, loss_fp: 0.002832, loss_freq: 0.028820
[18:49:01.303] iteration 23855: loss: 0.033906, loss_s1: 0.023978, loss_fp: 0.001538, loss_freq: 0.010462
[18:49:01.918] iteration 23856: loss: 0.043114, loss_s1: 0.014755, loss_fp: 0.014763, loss_freq: 0.014744
[18:49:02.539] iteration 23857: loss: 0.060303, loss_s1: 0.045787, loss_fp: 0.001996, loss_freq: 0.044678
[18:49:03.166] iteration 23858: loss: 0.040918, loss_s1: 0.028292, loss_fp: 0.002854, loss_freq: 0.019768
[18:49:03.786] iteration 23859: loss: 0.054379, loss_s1: 0.044982, loss_fp: 0.012849, loss_freq: 0.023320
[18:49:04.408] iteration 23860: loss: 0.042060, loss_s1: 0.035183, loss_fp: 0.008861, loss_freq: 0.009002
[18:49:05.029] iteration 23861: loss: 0.042666, loss_s1: 0.034492, loss_fp: 0.001041, loss_freq: 0.017128
[18:49:05.649] iteration 23862: loss: 0.034937, loss_s1: 0.026845, loss_fp: 0.001893, loss_freq: 0.006878
[18:49:06.269] iteration 23863: loss: 0.057208, loss_s1: 0.033300, loss_fp: 0.006516, loss_freq: 0.024533
[18:49:06.884] iteration 23864: loss: 0.077598, loss_s1: 0.063768, loss_fp: 0.006974, loss_freq: 0.054834
[18:49:07.507] iteration 23865: loss: 0.114130, loss_s1: 0.102256, loss_fp: 0.005059, loss_freq: 0.049332
[18:49:08.135] iteration 23866: loss: 0.080017, loss_s1: 0.067650, loss_fp: 0.005224, loss_freq: 0.044346
[18:49:08.755] iteration 23867: loss: 0.052718, loss_s1: 0.051804, loss_fp: 0.000540, loss_freq: 0.015609
[18:49:09.374] iteration 23868: loss: 0.058578, loss_s1: 0.045995, loss_fp: 0.006780, loss_freq: 0.031766
[18:49:10.034] iteration 23869: loss: 0.046570, loss_s1: 0.028408, loss_fp: 0.001217, loss_freq: 0.025280
[18:49:10.655] iteration 23870: loss: 0.065661, loss_s1: 0.080409, loss_fp: 0.004342, loss_freq: 0.018016
[18:49:11.271] iteration 23871: loss: 0.080988, loss_s1: 0.063938, loss_fp: 0.028249, loss_freq: 0.043632
[18:49:11.887] iteration 23872: loss: 0.044882, loss_s1: 0.028253, loss_fp: 0.004387, loss_freq: 0.031614
[18:49:12.542] iteration 23873: loss: 0.051393, loss_s1: 0.044354, loss_fp: 0.002713, loss_freq: 0.016985
[18:49:13.201] iteration 23874: loss: 0.046909, loss_s1: 0.044125, loss_fp: 0.002075, loss_freq: 0.008640
[18:49:13.856] iteration 23875: loss: 0.031016, loss_s1: 0.019939, loss_fp: 0.000998, loss_freq: 0.009818
[18:49:14.484] iteration 23876: loss: 0.051004, loss_s1: 0.057384, loss_fp: 0.001658, loss_freq: 0.015583
[18:49:15.106] iteration 23877: loss: 0.070493, loss_s1: 0.095306, loss_fp: 0.001904, loss_freq: 0.012301
[18:49:15.734] iteration 23878: loss: 0.054467, loss_s1: 0.045745, loss_fp: 0.000621, loss_freq: 0.035700
[18:49:16.364] iteration 23879: loss: 0.053251, loss_s1: 0.041120, loss_fp: 0.003822, loss_freq: 0.019989
[18:49:16.993] iteration 23880: loss: 0.046604, loss_s1: 0.034147, loss_fp: 0.005811, loss_freq: 0.020146
[18:49:17.626] iteration 23881: loss: 0.062663, loss_s1: 0.042958, loss_fp: 0.010443, loss_freq: 0.025941
[18:49:18.261] iteration 23882: loss: 0.047801, loss_s1: 0.026707, loss_fp: 0.001397, loss_freq: 0.033856
[18:49:18.902] iteration 23883: loss: 0.047713, loss_s1: 0.043960, loss_fp: 0.010479, loss_freq: 0.008447
[18:49:19.528] iteration 23884: loss: 0.061884, loss_s1: 0.055024, loss_fp: 0.001553, loss_freq: 0.031453
[18:49:20.184] iteration 23885: loss: 0.031844, loss_s1: 0.019491, loss_fp: 0.001382, loss_freq: 0.006985
[18:49:20.839] iteration 23886: loss: 0.052906, loss_s1: 0.014940, loss_fp: 0.006328, loss_freq: 0.028000
[18:49:21.496] iteration 23887: loss: 0.027246, loss_s1: 0.011429, loss_fp: 0.003112, loss_freq: 0.006455
[18:49:22.152] iteration 23888: loss: 0.029639, loss_s1: 0.017405, loss_fp: 0.004213, loss_freq: 0.012441
[18:49:22.777] iteration 23889: loss: 0.048700, loss_s1: 0.029824, loss_fp: 0.005118, loss_freq: 0.018910
[18:49:23.399] iteration 23890: loss: 0.049025, loss_s1: 0.039406, loss_fp: 0.003945, loss_freq: 0.026754
[18:49:24.029] iteration 23891: loss: 0.038382, loss_s1: 0.022898, loss_fp: 0.001505, loss_freq: 0.008352
[18:49:24.652] iteration 23892: loss: 0.048015, loss_s1: 0.022677, loss_fp: 0.007921, loss_freq: 0.033083
[18:49:25.276] iteration 23893: loss: 0.050452, loss_s1: 0.042695, loss_fp: 0.006537, loss_freq: 0.022257
[18:49:25.891] iteration 23894: loss: 0.059238, loss_s1: 0.026446, loss_fp: 0.009042, loss_freq: 0.049593
[18:49:26.519] iteration 23895: loss: 0.077363, loss_s1: 0.043417, loss_fp: 0.001750, loss_freq: 0.064523
[18:49:27.147] iteration 23896: loss: 0.050139, loss_s1: 0.030261, loss_fp: 0.002461, loss_freq: 0.037591
[18:49:27.766] iteration 23897: loss: 0.058072, loss_s1: 0.051307, loss_fp: 0.002309, loss_freq: 0.027812
[18:49:28.385] iteration 23898: loss: 0.067947, loss_s1: 0.060041, loss_fp: 0.004558, loss_freq: 0.026307
[18:49:29.007] iteration 23899: loss: 0.081257, loss_s1: 0.053254, loss_fp: 0.011192, loss_freq: 0.049505
[18:49:29.633] iteration 23900: loss: 0.041003, loss_s1: 0.021051, loss_fp: 0.000750, loss_freq: 0.027888
[18:49:30.251] iteration 23901: loss: 0.071272, loss_s1: 0.075711, loss_fp: 0.004087, loss_freq: 0.027162
[18:49:30.871] iteration 23902: loss: 0.050222, loss_s1: 0.035930, loss_fp: 0.003344, loss_freq: 0.017303
[18:49:31.505] iteration 23903: loss: 0.050636, loss_s1: 0.035533, loss_fp: 0.001417, loss_freq: 0.027849
[18:49:32.135] iteration 23904: loss: 0.035518, loss_s1: 0.018563, loss_fp: 0.000697, loss_freq: 0.008543
[18:49:32.770] iteration 23905: loss: 0.089607, loss_s1: 0.111386, loss_fp: 0.006247, loss_freq: 0.033205
[18:49:33.414] iteration 23906: loss: 0.036593, loss_s1: 0.031244, loss_fp: 0.001615, loss_freq: 0.008909
[18:49:34.046] iteration 23907: loss: 0.029388, loss_s1: 0.018133, loss_fp: 0.003283, loss_freq: 0.013197
[18:49:34.677] iteration 23908: loss: 0.062103, loss_s1: 0.036848, loss_fp: 0.010708, loss_freq: 0.030575
[18:49:35.307] iteration 23909: loss: 0.077518, loss_s1: 0.053860, loss_fp: 0.006024, loss_freq: 0.056799
[18:49:35.937] iteration 23910: loss: 0.039831, loss_s1: 0.032861, loss_fp: 0.001528, loss_freq: 0.020980
[18:49:36.571] iteration 23911: loss: 0.053304, loss_s1: 0.044849, loss_fp: 0.002963, loss_freq: 0.034368
[18:49:37.206] iteration 23912: loss: 0.076041, loss_s1: 0.062881, loss_fp: 0.009569, loss_freq: 0.037336
[18:49:37.839] iteration 23913: loss: 0.055338, loss_s1: 0.034065, loss_fp: 0.006052, loss_freq: 0.042812
[18:49:38.474] iteration 23914: loss: 0.031874, loss_s1: 0.016493, loss_fp: 0.001870, loss_freq: 0.011209
[18:49:39.109] iteration 23915: loss: 0.049688, loss_s1: 0.030779, loss_fp: 0.008202, loss_freq: 0.014414
[18:49:39.741] iteration 23916: loss: 0.071049, loss_s1: 0.091243, loss_fp: 0.001811, loss_freq: 0.014819
[18:49:40.369] iteration 23917: loss: 0.038418, loss_s1: 0.023616, loss_fp: 0.005085, loss_freq: 0.015645
[18:49:40.987] iteration 23918: loss: 0.060797, loss_s1: 0.045136, loss_fp: 0.004898, loss_freq: 0.040251
[18:49:41.616] iteration 23919: loss: 0.069995, loss_s1: 0.048890, loss_fp: 0.000887, loss_freq: 0.026413
[18:49:42.232] iteration 23920: loss: 0.056964, loss_s1: 0.035832, loss_fp: 0.003419, loss_freq: 0.038709
[18:49:42.847] iteration 23921: loss: 0.066027, loss_s1: 0.050514, loss_fp: 0.001314, loss_freq: 0.030997
[18:49:43.465] iteration 23922: loss: 0.054565, loss_s1: 0.041920, loss_fp: 0.003153, loss_freq: 0.028424
[18:49:44.091] iteration 23923: loss: 0.059117, loss_s1: 0.052705, loss_fp: 0.001586, loss_freq: 0.025617
[18:49:44.714] iteration 23924: loss: 0.029728, loss_s1: 0.011895, loss_fp: 0.002781, loss_freq: 0.015992
[18:49:45.338] iteration 23925: loss: 0.038567, loss_s1: 0.017449, loss_fp: 0.001410, loss_freq: 0.016918
[18:49:45.962] iteration 23926: loss: 0.042917, loss_s1: 0.022378, loss_fp: 0.001200, loss_freq: 0.012943
[18:49:46.583] iteration 23927: loss: 0.045759, loss_s1: 0.041739, loss_fp: 0.004036, loss_freq: 0.013239
[18:49:47.207] iteration 23928: loss: 0.048519, loss_s1: 0.043854, loss_fp: 0.003959, loss_freq: 0.017981
[18:49:47.831] iteration 23929: loss: 0.054904, loss_s1: 0.044344, loss_fp: 0.003438, loss_freq: 0.031775
[18:49:48.452] iteration 23930: loss: 0.077190, loss_s1: 0.050855, loss_fp: 0.005570, loss_freq: 0.054947
[18:49:49.072] iteration 23931: loss: 0.051999, loss_s1: 0.036300, loss_fp: 0.002398, loss_freq: 0.025796
[18:49:49.695] iteration 23932: loss: 0.047017, loss_s1: 0.031966, loss_fp: 0.008069, loss_freq: 0.022759
[18:49:50.316] iteration 23933: loss: 0.040739, loss_s1: 0.023992, loss_fp: 0.005039, loss_freq: 0.015007
[18:49:50.937] iteration 23934: loss: 0.049096, loss_s1: 0.034557, loss_fp: 0.002306, loss_freq: 0.030824
[18:49:51.561] iteration 23935: loss: 0.027546, loss_s1: 0.009053, loss_fp: 0.003638, loss_freq: 0.007852
[18:49:52.184] iteration 23936: loss: 0.076897, loss_s1: 0.084904, loss_fp: 0.003543, loss_freq: 0.022933
[18:49:52.807] iteration 23937: loss: 0.115775, loss_s1: 0.074580, loss_fp: 0.013056, loss_freq: 0.091236
[18:49:53.428] iteration 23938: loss: 0.051378, loss_s1: 0.047087, loss_fp: 0.002167, loss_freq: 0.019102
[18:49:54.054] iteration 23939: loss: 0.067533, loss_s1: 0.055507, loss_fp: 0.005845, loss_freq: 0.021724
[18:49:54.682] iteration 23940: loss: 0.078175, loss_s1: 0.045215, loss_fp: 0.006787, loss_freq: 0.067636
[18:49:55.553] iteration 23941: loss: 0.048273, loss_s1: 0.026134, loss_fp: 0.008256, loss_freq: 0.036474
[18:49:56.312] iteration 23942: loss: 0.047274, loss_s1: 0.048077, loss_fp: 0.002530, loss_freq: 0.017651
[18:49:56.982] iteration 23943: loss: 0.037943, loss_s1: 0.029422, loss_fp: 0.002925, loss_freq: 0.011081
[18:49:57.601] iteration 23944: loss: 0.061979, loss_s1: 0.044146, loss_fp: 0.002834, loss_freq: 0.028131
[18:49:58.220] iteration 23945: loss: 0.045830, loss_s1: 0.022494, loss_fp: 0.001177, loss_freq: 0.040189
[18:49:58.837] iteration 23946: loss: 0.034767, loss_s1: 0.020894, loss_fp: 0.003728, loss_freq: 0.015531
[18:49:59.463] iteration 23947: loss: 0.060590, loss_s1: 0.047315, loss_fp: 0.006061, loss_freq: 0.035366
[18:50:00.082] iteration 23948: loss: 0.094950, loss_s1: 0.053583, loss_fp: 0.008777, loss_freq: 0.093600
[18:50:00.701] iteration 23949: loss: 0.036542, loss_s1: 0.028289, loss_fp: 0.003297, loss_freq: 0.010319
[18:50:01.327] iteration 23950: loss: 0.049440, loss_s1: 0.046442, loss_fp: 0.002007, loss_freq: 0.010828
[18:50:01.946] iteration 23951: loss: 0.064024, loss_s1: 0.058675, loss_fp: 0.003974, loss_freq: 0.036568
[18:50:02.591] iteration 23952: loss: 0.039999, loss_s1: 0.017686, loss_fp: 0.002907, loss_freq: 0.021524
[18:50:03.245] iteration 23953: loss: 0.040712, loss_s1: 0.030452, loss_fp: 0.002929, loss_freq: 0.011375
[18:50:03.894] iteration 23954: loss: 0.037176, loss_s1: 0.025681, loss_fp: 0.000676, loss_freq: 0.013391
[18:50:04.526] iteration 23955: loss: 0.031669, loss_s1: 0.019391, loss_fp: 0.001783, loss_freq: 0.005773
[18:50:05.142] iteration 23956: loss: 0.104455, loss_s1: 0.091689, loss_fp: 0.006895, loss_freq: 0.062999
[18:50:05.761] iteration 23957: loss: 0.066730, loss_s1: 0.043415, loss_fp: 0.005024, loss_freq: 0.028470
[18:50:06.384] iteration 23958: loss: 0.046473, loss_s1: 0.024211, loss_fp: 0.019098, loss_freq: 0.019095
[18:50:07.004] iteration 23959: loss: 0.045313, loss_s1: 0.022207, loss_fp: 0.004208, loss_freq: 0.025963
[18:50:07.621] iteration 23960: loss: 0.042544, loss_s1: 0.036445, loss_fp: 0.003569, loss_freq: 0.009444
[18:50:08.236] iteration 23961: loss: 0.052819, loss_s1: 0.026862, loss_fp: 0.004204, loss_freq: 0.024754
[18:50:08.852] iteration 23962: loss: 0.075485, loss_s1: 0.078660, loss_fp: 0.002409, loss_freq: 0.026752
[18:50:09.466] iteration 23963: loss: 0.047868, loss_s1: 0.050442, loss_fp: 0.000676, loss_freq: 0.015203
[18:50:10.082] iteration 23964: loss: 0.048244, loss_s1: 0.041541, loss_fp: 0.009532, loss_freq: 0.012789
[18:50:10.697] iteration 23965: loss: 0.048466, loss_s1: 0.027399, loss_fp: 0.000752, loss_freq: 0.021694
[18:50:11.310] iteration 23966: loss: 0.045768, loss_s1: 0.046875, loss_fp: 0.000673, loss_freq: 0.018969
[18:50:11.927] iteration 23967: loss: 0.054156, loss_s1: 0.051558, loss_fp: 0.002446, loss_freq: 0.014570
[18:50:12.545] iteration 23968: loss: 0.079344, loss_s1: 0.049723, loss_fp: 0.003088, loss_freq: 0.039855
[18:50:13.167] iteration 23969: loss: 0.077565, loss_s1: 0.108480, loss_fp: 0.003365, loss_freq: 0.014985
[18:50:13.797] iteration 23970: loss: 0.042072, loss_s1: 0.034903, loss_fp: 0.006732, loss_freq: 0.011572
[18:50:14.420] iteration 23971: loss: 0.052073, loss_s1: 0.033878, loss_fp: 0.002292, loss_freq: 0.032738
[18:50:15.038] iteration 23972: loss: 0.076265, loss_s1: 0.069871, loss_fp: 0.005378, loss_freq: 0.031248
[18:50:15.658] iteration 23973: loss: 0.036896, loss_s1: 0.016914, loss_fp: 0.004685, loss_freq: 0.020708
[18:50:16.290] iteration 23974: loss: 0.071314, loss_s1: 0.080510, loss_fp: 0.007515, loss_freq: 0.012835
[18:50:16.919] iteration 23975: loss: 0.070278, loss_s1: 0.050637, loss_fp: 0.005913, loss_freq: 0.057306
[18:50:17.547] iteration 23976: loss: 0.040223, loss_s1: 0.029834, loss_fp: 0.005041, loss_freq: 0.018343
[18:50:18.174] iteration 23977: loss: 0.060828, loss_s1: 0.050875, loss_fp: 0.005126, loss_freq: 0.019436
[18:50:18.804] iteration 23978: loss: 0.084689, loss_s1: 0.076020, loss_fp: 0.005746, loss_freq: 0.051294
[18:50:19.428] iteration 23979: loss: 0.049744, loss_s1: 0.044091, loss_fp: 0.003825, loss_freq: 0.009400
[18:50:20.055] iteration 23980: loss: 0.089331, loss_s1: 0.058753, loss_fp: 0.000967, loss_freq: 0.080798
[18:50:20.683] iteration 23981: loss: 0.046817, loss_s1: 0.041648, loss_fp: 0.002679, loss_freq: 0.019048
[18:50:21.299] iteration 23982: loss: 0.046037, loss_s1: 0.022642, loss_fp: 0.005738, loss_freq: 0.026654
[18:50:21.921] iteration 23983: loss: 0.023853, loss_s1: 0.017380, loss_fp: 0.001183, loss_freq: 0.005075
[18:50:22.542] iteration 23984: loss: 0.037554, loss_s1: 0.017374, loss_fp: 0.001347, loss_freq: 0.013966
[18:50:23.160] iteration 23985: loss: 0.034783, loss_s1: 0.019410, loss_fp: 0.001651, loss_freq: 0.007890
[18:50:23.779] iteration 23986: loss: 0.070102, loss_s1: 0.075639, loss_fp: 0.001875, loss_freq: 0.019288
[18:50:24.398] iteration 23987: loss: 0.057066, loss_s1: 0.062494, loss_fp: 0.003900, loss_freq: 0.013893
[18:50:25.009] iteration 23988: loss: 0.049817, loss_s1: 0.051594, loss_fp: 0.003267, loss_freq: 0.013765
[18:50:25.629] iteration 23989: loss: 0.059564, loss_s1: 0.044110, loss_fp: 0.005785, loss_freq: 0.025809
[18:50:26.658] iteration 23990: loss: 0.052313, loss_s1: 0.059871, loss_fp: 0.000997, loss_freq: 0.008905
[18:50:27.309] iteration 23991: loss: 0.053315, loss_s1: 0.047267, loss_fp: 0.004659, loss_freq: 0.019091
[18:50:27.932] iteration 23992: loss: 0.034835, loss_s1: 0.011585, loss_fp: 0.002945, loss_freq: 0.012544
[18:50:28.559] iteration 23993: loss: 0.038753, loss_s1: 0.018407, loss_fp: 0.001668, loss_freq: 0.018107
[18:50:29.176] iteration 23994: loss: 0.046038, loss_s1: 0.032702, loss_fp: 0.004331, loss_freq: 0.019638
[18:50:29.791] iteration 23995: loss: 0.069333, loss_s1: 0.061190, loss_fp: 0.002654, loss_freq: 0.029957
[18:50:30.412] iteration 23996: loss: 0.058943, loss_s1: 0.050526, loss_fp: 0.017027, loss_freq: 0.019259
[18:50:31.036] iteration 23997: loss: 0.033778, loss_s1: 0.020807, loss_fp: 0.004032, loss_freq: 0.014378
[18:50:31.658] iteration 23998: loss: 0.050281, loss_s1: 0.046911, loss_fp: 0.003229, loss_freq: 0.022511
[18:50:32.271] iteration 23999: loss: 0.073102, loss_s1: 0.084990, loss_fp: 0.010544, loss_freq: 0.017935
[18:50:32.885] iteration 24000: loss: 0.026007, loss_s1: 0.009883, loss_fp: 0.003109, loss_freq: 0.006318
[18:50:36.377] iteration 24000 : mean_dice : 0.725339
[18:50:37.060] iteration 24001: loss: 0.049141, loss_s1: 0.031404, loss_fp: 0.000405, loss_freq: 0.035530
[18:50:37.717] iteration 24002: loss: 0.058470, loss_s1: 0.033785, loss_fp: 0.007201, loss_freq: 0.051105
[18:50:38.372] iteration 24003: loss: 0.048154, loss_s1: 0.026672, loss_fp: 0.004424, loss_freq: 0.021761
[18:50:39.030] iteration 24004: loss: 0.043553, loss_s1: 0.049472, loss_fp: 0.000843, loss_freq: 0.007252
[18:50:39.683] iteration 24005: loss: 0.067139, loss_s1: 0.062449, loss_fp: 0.007139, loss_freq: 0.035444
[18:50:40.305] iteration 24006: loss: 0.058149, loss_s1: 0.056195, loss_fp: 0.005551, loss_freq: 0.014447
[18:50:40.926] iteration 24007: loss: 0.050267, loss_s1: 0.034351, loss_fp: 0.009757, loss_freq: 0.025216
[18:50:41.547] iteration 24008: loss: 0.037141, loss_s1: 0.011191, loss_fp: 0.002613, loss_freq: 0.028700
[18:50:42.176] iteration 24009: loss: 0.048013, loss_s1: 0.024253, loss_fp: 0.008520, loss_freq: 0.029202
[18:50:42.801] iteration 24010: loss: 0.038916, loss_s1: 0.028617, loss_fp: 0.001526, loss_freq: 0.006937
[18:50:43.421] iteration 24011: loss: 0.043587, loss_s1: 0.037270, loss_fp: 0.002578, loss_freq: 0.009879
[18:50:44.040] iteration 24012: loss: 0.039149, loss_s1: 0.019867, loss_fp: 0.000944, loss_freq: 0.009353
[18:50:44.660] iteration 24013: loss: 0.070251, loss_s1: 0.059193, loss_fp: 0.000301, loss_freq: 0.054651
[18:50:45.277] iteration 24014: loss: 0.037752, loss_s1: 0.025568, loss_fp: 0.003096, loss_freq: 0.019708
[18:50:45.895] iteration 24015: loss: 0.091001, loss_s1: 0.086104, loss_fp: 0.001754, loss_freq: 0.049819
[18:50:46.514] iteration 24016: loss: 0.027941, loss_s1: 0.007726, loss_fp: 0.001009, loss_freq: 0.016528
[18:50:47.130] iteration 24017: loss: 0.084771, loss_s1: 0.109166, loss_fp: 0.004598, loss_freq: 0.025481
[18:50:47.753] iteration 24018: loss: 0.076104, loss_s1: 0.062495, loss_fp: 0.014167, loss_freq: 0.042032
[18:50:48.368] iteration 24019: loss: 0.028843, loss_s1: 0.018948, loss_fp: 0.001571, loss_freq: 0.008022
[18:50:48.980] iteration 24020: loss: 0.049481, loss_s1: 0.041843, loss_fp: 0.001787, loss_freq: 0.024147
[18:50:49.599] iteration 24021: loss: 0.054749, loss_s1: 0.039159, loss_fp: 0.005980, loss_freq: 0.022715
[18:50:50.212] iteration 24022: loss: 0.031852, loss_s1: 0.012631, loss_fp: 0.002272, loss_freq: 0.015305
[18:50:50.830] iteration 24023: loss: 0.039413, loss_s1: 0.028476, loss_fp: 0.008432, loss_freq: 0.007300
[18:50:51.449] iteration 24024: loss: 0.065467, loss_s1: 0.021140, loss_fp: 0.005873, loss_freq: 0.047013
[18:50:52.063] iteration 24025: loss: 0.054674, loss_s1: 0.034883, loss_fp: 0.006533, loss_freq: 0.038562
[18:50:52.682] iteration 24026: loss: 0.047060, loss_s1: 0.029391, loss_fp: 0.012351, loss_freq: 0.023502
[18:50:53.296] iteration 24027: loss: 0.035897, loss_s1: 0.018279, loss_fp: 0.003367, loss_freq: 0.020744
[18:50:53.915] iteration 24028: loss: 0.083965, loss_s1: 0.051544, loss_fp: 0.006864, loss_freq: 0.070638
[18:50:54.535] iteration 24029: loss: 0.059296, loss_s1: 0.040090, loss_fp: 0.004775, loss_freq: 0.042928
[18:50:55.150] iteration 24030: loss: 0.056302, loss_s1: 0.039777, loss_fp: 0.008330, loss_freq: 0.026172
[18:50:55.769] iteration 24031: loss: 0.058368, loss_s1: 0.051339, loss_fp: 0.005554, loss_freq: 0.028906
[18:50:56.386] iteration 24032: loss: 0.072267, loss_s1: 0.076018, loss_fp: 0.007325, loss_freq: 0.036159
[18:50:57.003] iteration 24033: loss: 0.044719, loss_s1: 0.025085, loss_fp: 0.002277, loss_freq: 0.035589
[18:50:57.622] iteration 24034: loss: 0.056674, loss_s1: 0.033580, loss_fp: 0.004927, loss_freq: 0.033614
[18:50:58.253] iteration 24035: loss: 0.028276, loss_s1: 0.017799, loss_fp: 0.002533, loss_freq: 0.001791
[18:50:58.878] iteration 24036: loss: 0.028297, loss_s1: 0.017945, loss_fp: 0.005299, loss_freq: 0.006846
[18:50:59.497] iteration 24037: loss: 0.074099, loss_s1: 0.072890, loss_fp: 0.002002, loss_freq: 0.033526
[18:51:00.117] iteration 24038: loss: 0.075666, loss_s1: 0.072507, loss_fp: 0.009260, loss_freq: 0.033345
[18:51:00.736] iteration 24039: loss: 0.047520, loss_s1: 0.029062, loss_fp: 0.000633, loss_freq: 0.038777
[18:51:01.366] iteration 24040: loss: 0.059054, loss_s1: 0.043659, loss_fp: 0.007052, loss_freq: 0.036100
[18:51:01.986] iteration 24041: loss: 0.044664, loss_s1: 0.019613, loss_fp: 0.004273, loss_freq: 0.024379
[18:51:02.615] iteration 24042: loss: 0.046205, loss_s1: 0.022269, loss_fp: 0.002888, loss_freq: 0.024720
[18:51:03.228] iteration 24043: loss: 0.049375, loss_s1: 0.031202, loss_fp: 0.002357, loss_freq: 0.033081
[18:51:03.850] iteration 24044: loss: 0.027722, loss_s1: 0.013958, loss_fp: 0.001800, loss_freq: 0.009843
[18:51:04.467] iteration 24045: loss: 0.043046, loss_s1: 0.031676, loss_fp: 0.003855, loss_freq: 0.016712
[18:51:05.086] iteration 24046: loss: 0.041046, loss_s1: 0.027685, loss_fp: 0.001475, loss_freq: 0.012701
[18:51:05.707] iteration 24047: loss: 0.037356, loss_s1: 0.013809, loss_fp: 0.003579, loss_freq: 0.014605
[18:51:06.325] iteration 24048: loss: 0.032719, loss_s1: 0.019026, loss_fp: 0.001216, loss_freq: 0.008344
[18:51:06.945] iteration 24049: loss: 0.039048, loss_s1: 0.018196, loss_fp: 0.004352, loss_freq: 0.027420
[18:51:07.571] iteration 24050: loss: 0.043489, loss_s1: 0.037157, loss_fp: 0.001714, loss_freq: 0.018211
[18:51:08.197] iteration 24051: loss: 0.039221, loss_s1: 0.014110, loss_fp: 0.004912, loss_freq: 0.027323
[18:51:08.825] iteration 24052: loss: 0.033194, loss_s1: 0.009088, loss_fp: 0.005303, loss_freq: 0.012807
[18:51:09.445] iteration 24053: loss: 0.047037, loss_s1: 0.035539, loss_fp: 0.010167, loss_freq: 0.015773
[18:51:10.074] iteration 24054: loss: 0.045130, loss_s1: 0.023376, loss_fp: 0.003993, loss_freq: 0.033201
[18:51:10.701] iteration 24055: loss: 0.064195, loss_s1: 0.026295, loss_fp: 0.005261, loss_freq: 0.035228
[18:51:11.315] iteration 24056: loss: 0.048820, loss_s1: 0.019116, loss_fp: 0.002067, loss_freq: 0.037999
[18:51:11.939] iteration 24057: loss: 0.072042, loss_s1: 0.060492, loss_fp: 0.014959, loss_freq: 0.040457
[18:51:12.567] iteration 24058: loss: 0.041295, loss_s1: 0.034747, loss_fp: 0.006586, loss_freq: 0.011501
[18:51:13.241] iteration 24059: loss: 0.059270, loss_s1: 0.032711, loss_fp: 0.003867, loss_freq: 0.031960
[18:51:13.871] iteration 24060: loss: 0.096291, loss_s1: 0.097403, loss_fp: 0.007504, loss_freq: 0.060745
[18:51:14.528] iteration 24061: loss: 0.043153, loss_s1: 0.026735, loss_fp: 0.000384, loss_freq: 0.026829
[18:51:15.185] iteration 24062: loss: 0.091549, loss_s1: 0.098240, loss_fp: 0.004052, loss_freq: 0.038728
[18:51:15.847] iteration 24063: loss: 0.040132, loss_s1: 0.027582, loss_fp: 0.001192, loss_freq: 0.012898
[18:51:16.503] iteration 24064: loss: 0.050165, loss_s1: 0.033669, loss_fp: 0.001216, loss_freq: 0.029208
[18:51:17.124] iteration 24065: loss: 0.067748, loss_s1: 0.090952, loss_fp: 0.002887, loss_freq: 0.007677
[18:51:17.753] iteration 24066: loss: 0.062843, loss_s1: 0.039232, loss_fp: 0.006372, loss_freq: 0.049658
[18:51:18.379] iteration 24067: loss: 0.038242, loss_s1: 0.026887, loss_fp: 0.004103, loss_freq: 0.016469
[18:51:19.001] iteration 24068: loss: 0.043950, loss_s1: 0.038219, loss_fp: 0.007483, loss_freq: 0.014528
[18:51:19.631] iteration 24069: loss: 0.058810, loss_s1: 0.031418, loss_fp: 0.003108, loss_freq: 0.044273
[18:51:20.250] iteration 24070: loss: 0.055814, loss_s1: 0.030785, loss_fp: 0.004002, loss_freq: 0.041406
[18:51:20.877] iteration 24071: loss: 0.063008, loss_s1: 0.053707, loss_fp: 0.005275, loss_freq: 0.041440
[18:51:21.501] iteration 24072: loss: 0.053917, loss_s1: 0.033825, loss_fp: 0.008910, loss_freq: 0.033104
[18:51:22.121] iteration 24073: loss: 0.053386, loss_s1: 0.032939, loss_fp: 0.007514, loss_freq: 0.022474
[18:51:22.741] iteration 24074: loss: 0.083992, loss_s1: 0.069230, loss_fp: 0.016080, loss_freq: 0.057930
[18:51:23.364] iteration 24075: loss: 0.032463, loss_s1: 0.023320, loss_fp: 0.002150, loss_freq: 0.007777
[18:51:23.986] iteration 24076: loss: 0.035095, loss_s1: 0.011480, loss_fp: 0.003453, loss_freq: 0.017411
[18:51:24.613] iteration 24077: loss: 0.056600, loss_s1: 0.052267, loss_fp: 0.004793, loss_freq: 0.019084
[18:51:25.235] iteration 24078: loss: 0.041134, loss_s1: 0.026370, loss_fp: 0.002531, loss_freq: 0.022426
[18:51:25.863] iteration 24079: loss: 0.062094, loss_s1: 0.064287, loss_fp: 0.002620, loss_freq: 0.026859
[18:51:26.485] iteration 24080: loss: 0.056168, loss_s1: 0.047074, loss_fp: 0.004886, loss_freq: 0.023367
[18:51:27.109] iteration 24081: loss: 0.073757, loss_s1: 0.055369, loss_fp: 0.004374, loss_freq: 0.022690
[18:51:27.732] iteration 24082: loss: 0.050241, loss_s1: 0.036294, loss_fp: 0.001292, loss_freq: 0.012058
[18:51:28.358] iteration 24083: loss: 0.037367, loss_s1: 0.023288, loss_fp: 0.001403, loss_freq: 0.017959
[18:51:28.976] iteration 24084: loss: 0.073233, loss_s1: 0.076779, loss_fp: 0.021121, loss_freq: 0.023733
[18:51:29.600] iteration 24085: loss: 0.048128, loss_s1: 0.049426, loss_fp: 0.002114, loss_freq: 0.021055
[18:51:30.220] iteration 24086: loss: 0.037237, loss_s1: 0.021877, loss_fp: 0.002008, loss_freq: 0.015545
[18:51:30.845] iteration 24087: loss: 0.045663, loss_s1: 0.034571, loss_fp: 0.002937, loss_freq: 0.013639
[18:51:31.472] iteration 24088: loss: 0.035426, loss_s1: 0.019397, loss_fp: 0.001567, loss_freq: 0.017792
[18:51:32.094] iteration 24089: loss: 0.033621, loss_s1: 0.021109, loss_fp: 0.002888, loss_freq: 0.008229
[18:51:32.720] iteration 24090: loss: 0.075213, loss_s1: 0.050903, loss_fp: 0.008082, loss_freq: 0.056067
[18:51:33.349] iteration 24091: loss: 0.085225, loss_s1: 0.034492, loss_fp: 0.017257, loss_freq: 0.062927
[18:51:33.967] iteration 24092: loss: 0.067603, loss_s1: 0.048101, loss_fp: 0.003361, loss_freq: 0.051183
[18:51:34.622] iteration 24093: loss: 0.054913, loss_s1: 0.044748, loss_fp: 0.004184, loss_freq: 0.028130
[18:51:35.282] iteration 24094: loss: 0.059652, loss_s1: 0.041594, loss_fp: 0.008302, loss_freq: 0.025258
[18:51:35.941] iteration 24095: loss: 0.039145, loss_s1: 0.018973, loss_fp: 0.001564, loss_freq: 0.023895
[18:51:36.568] iteration 24096: loss: 0.051850, loss_s1: 0.035217, loss_fp: 0.002312, loss_freq: 0.013616
[18:51:37.194] iteration 24097: loss: 0.055233, loss_s1: 0.041843, loss_fp: 0.001418, loss_freq: 0.032541
[18:51:37.820] iteration 24098: loss: 0.098903, loss_s1: 0.073852, loss_fp: 0.009696, loss_freq: 0.077221
[18:51:38.444] iteration 24099: loss: 0.060704, loss_s1: 0.038767, loss_fp: 0.003417, loss_freq: 0.028754
[18:51:39.072] iteration 24100: loss: 0.080279, loss_s1: 0.040640, loss_fp: 0.002131, loss_freq: 0.045889
[18:51:39.704] iteration 24101: loss: 0.051062, loss_s1: 0.009239, loss_fp: 0.007710, loss_freq: 0.054011
[18:51:40.335] iteration 24102: loss: 0.072135, loss_s1: 0.089256, loss_fp: 0.006214, loss_freq: 0.022690
[18:51:40.963] iteration 24103: loss: 0.049652, loss_s1: 0.042953, loss_fp: 0.002105, loss_freq: 0.026699
[18:51:41.623] iteration 24104: loss: 0.037176, loss_s1: 0.030355, loss_fp: 0.000870, loss_freq: 0.008768
[18:51:42.282] iteration 24105: loss: 0.038972, loss_s1: 0.033292, loss_fp: 0.002244, loss_freq: 0.012003
[18:51:42.925] iteration 24106: loss: 0.051522, loss_s1: 0.043769, loss_fp: 0.010514, loss_freq: 0.014518
[18:51:43.547] iteration 24107: loss: 0.031368, loss_s1: 0.019759, loss_fp: 0.001242, loss_freq: 0.014268
[18:51:44.174] iteration 24108: loss: 0.053392, loss_s1: 0.044590, loss_fp: 0.004853, loss_freq: 0.024796
[18:51:44.795] iteration 24109: loss: 0.077592, loss_s1: 0.042768, loss_fp: 0.000892, loss_freq: 0.085271
[18:51:45.418] iteration 24110: loss: 0.059666, loss_s1: 0.054349, loss_fp: 0.010026, loss_freq: 0.018624
[18:51:46.037] iteration 24111: loss: 0.070917, loss_s1: 0.040085, loss_fp: 0.003830, loss_freq: 0.048937
[18:51:46.660] iteration 24112: loss: 0.024764, loss_s1: 0.014536, loss_fp: 0.001139, loss_freq: 0.005175
[18:51:47.287] iteration 24113: loss: 0.049888, loss_s1: 0.034278, loss_fp: 0.002306, loss_freq: 0.021378
[18:51:47.903] iteration 24114: loss: 0.043557, loss_s1: 0.041729, loss_fp: 0.001950, loss_freq: 0.018736
[18:51:48.523] iteration 24115: loss: 0.074221, loss_s1: 0.052395, loss_fp: 0.005613, loss_freq: 0.047376
[18:51:49.140] iteration 24116: loss: 0.055397, loss_s1: 0.057473, loss_fp: 0.003355, loss_freq: 0.017759
[18:51:49.797] iteration 24117: loss: 0.092739, loss_s1: 0.057995, loss_fp: 0.006130, loss_freq: 0.066065
[18:51:50.417] iteration 24118: loss: 0.054248, loss_s1: 0.043280, loss_fp: 0.005634, loss_freq: 0.019582
[18:51:51.075] iteration 24119: loss: 0.043187, loss_s1: 0.034198, loss_fp: 0.005136, loss_freq: 0.016596
[18:51:51.730] iteration 24120: loss: 0.053407, loss_s1: 0.025505, loss_fp: 0.003493, loss_freq: 0.050715
[18:51:52.367] iteration 24121: loss: 0.043483, loss_s1: 0.030427, loss_fp: 0.003416, loss_freq: 0.022527
[18:51:52.993] iteration 24122: loss: 0.059628, loss_s1: 0.051394, loss_fp: 0.003755, loss_freq: 0.017019
[18:51:53.613] iteration 24123: loss: 0.044980, loss_s1: 0.043613, loss_fp: 0.007522, loss_freq: 0.011069
[18:51:54.235] iteration 24124: loss: 0.083255, loss_s1: 0.084923, loss_fp: 0.002531, loss_freq: 0.052765
[18:51:54.863] iteration 24125: loss: 0.054318, loss_s1: 0.043957, loss_fp: 0.007995, loss_freq: 0.027537
[18:51:55.492] iteration 24126: loss: 0.038086, loss_s1: 0.017596, loss_fp: 0.001375, loss_freq: 0.010021
[18:51:56.112] iteration 24127: loss: 0.042555, loss_s1: 0.034936, loss_fp: 0.002233, loss_freq: 0.018467
[18:51:56.731] iteration 24128: loss: 0.043064, loss_s1: 0.035003, loss_fp: 0.001917, loss_freq: 0.021864
[18:51:57.353] iteration 24129: loss: 0.058422, loss_s1: 0.040045, loss_fp: 0.008043, loss_freq: 0.020186
[18:51:57.983] iteration 24130: loss: 0.049257, loss_s1: 0.050787, loss_fp: 0.003231, loss_freq: 0.014549
[18:51:58.608] iteration 24131: loss: 0.063039, loss_s1: 0.054328, loss_fp: 0.009949, loss_freq: 0.026183
[18:51:59.353] iteration 24132: loss: 0.060865, loss_s1: 0.048797, loss_fp: 0.005485, loss_freq: 0.031435
[18:52:00.146] iteration 24133: loss: 0.052074, loss_s1: 0.034084, loss_fp: 0.003532, loss_freq: 0.017427
[18:52:00.829] iteration 24134: loss: 0.041926, loss_s1: 0.027097, loss_fp: 0.015879, loss_freq: 0.010657
[18:52:01.629] iteration 24135: loss: 0.047516, loss_s1: 0.040272, loss_fp: 0.004860, loss_freq: 0.007063
[18:52:02.294] iteration 24136: loss: 0.058218, loss_s1: 0.045830, loss_fp: 0.003851, loss_freq: 0.034609
[18:52:02.951] iteration 24137: loss: 0.031593, loss_s1: 0.018085, loss_fp: 0.001183, loss_freq: 0.010657
[18:52:03.598] iteration 24138: loss: 0.045009, loss_s1: 0.038720, loss_fp: 0.005297, loss_freq: 0.014219
[18:52:04.230] iteration 24139: loss: 0.075195, loss_s1: 0.041837, loss_fp: 0.014337, loss_freq: 0.054179
[18:52:04.852] iteration 24140: loss: 0.043410, loss_s1: 0.038158, loss_fp: 0.002023, loss_freq: 0.009871
[18:52:05.476] iteration 24141: loss: 0.060881, loss_s1: 0.033431, loss_fp: 0.009317, loss_freq: 0.042287
[18:52:06.102] iteration 24142: loss: 0.043491, loss_s1: 0.028027, loss_fp: 0.003448, loss_freq: 0.026128
[18:52:06.731] iteration 24143: loss: 0.048529, loss_s1: 0.034069, loss_fp: 0.004432, loss_freq: 0.026722
[18:52:07.353] iteration 24144: loss: 0.025550, loss_s1: 0.009642, loss_fp: 0.000224, loss_freq: 0.005721
[18:52:07.978] iteration 24145: loss: 0.045173, loss_s1: 0.021646, loss_fp: 0.005409, loss_freq: 0.029426
[18:52:08.600] iteration 24146: loss: 0.035619, loss_s1: 0.010779, loss_fp: 0.001765, loss_freq: 0.009354
[18:52:09.220] iteration 24147: loss: 0.069630, loss_s1: 0.050936, loss_fp: 0.001887, loss_freq: 0.033668
[18:52:09.846] iteration 24148: loss: 0.059576, loss_s1: 0.056366, loss_fp: 0.007457, loss_freq: 0.022502
[18:52:10.464] iteration 24149: loss: 0.051516, loss_s1: 0.020210, loss_fp: 0.002723, loss_freq: 0.033449
[18:52:11.087] iteration 24150: loss: 0.069845, loss_s1: 0.074393, loss_fp: 0.004403, loss_freq: 0.020717
[18:52:12.080] iteration 24151: loss: 0.048369, loss_s1: 0.030615, loss_fp: 0.002845, loss_freq: 0.024348
[18:52:12.738] iteration 24152: loss: 0.045088, loss_s1: 0.035563, loss_fp: 0.003136, loss_freq: 0.020526
[18:52:13.392] iteration 24153: loss: 0.034062, loss_s1: 0.027581, loss_fp: 0.002724, loss_freq: 0.005569
[18:52:14.013] iteration 24154: loss: 0.037269, loss_s1: 0.023810, loss_fp: 0.000586, loss_freq: 0.008274
[18:52:14.636] iteration 24155: loss: 0.054328, loss_s1: 0.055634, loss_fp: 0.003005, loss_freq: 0.015771
[18:52:15.260] iteration 24156: loss: 0.088926, loss_s1: 0.067261, loss_fp: 0.014651, loss_freq: 0.051141
[18:52:15.885] iteration 24157: loss: 0.056705, loss_s1: 0.041838, loss_fp: 0.018315, loss_freq: 0.023647
[18:52:16.534] iteration 24158: loss: 0.029770, loss_s1: 0.012708, loss_fp: 0.001595, loss_freq: 0.019794
[18:52:17.194] iteration 24159: loss: 0.059401, loss_s1: 0.062944, loss_fp: 0.002248, loss_freq: 0.028985
[18:52:17.848] iteration 24160: loss: 0.057701, loss_s1: 0.047381, loss_fp: 0.007094, loss_freq: 0.021205
[18:52:18.489] iteration 24161: loss: 0.056431, loss_s1: 0.044466, loss_fp: 0.003934, loss_freq: 0.020332
[18:52:19.107] iteration 24162: loss: 0.071501, loss_s1: 0.069073, loss_fp: 0.001277, loss_freq: 0.048948
[18:52:19.729] iteration 24163: loss: 0.059002, loss_s1: 0.032577, loss_fp: 0.006177, loss_freq: 0.051899
[18:52:20.355] iteration 24164: loss: 0.074059, loss_s1: 0.059291, loss_fp: 0.001700, loss_freq: 0.031160
[18:52:20.977] iteration 24165: loss: 0.061637, loss_s1: 0.065102, loss_fp: 0.001165, loss_freq: 0.029939
[18:52:21.603] iteration 24166: loss: 0.085307, loss_s1: 0.032884, loss_fp: 0.011483, loss_freq: 0.093992
[18:52:22.239] iteration 24167: loss: 0.069481, loss_s1: 0.059576, loss_fp: 0.000544, loss_freq: 0.014159
[18:52:22.857] iteration 24168: loss: 0.077443, loss_s1: 0.049715, loss_fp: 0.003738, loss_freq: 0.053331
[18:52:23.477] iteration 24169: loss: 0.049685, loss_s1: 0.038929, loss_fp: 0.002068, loss_freq: 0.018246
[18:52:24.094] iteration 24170: loss: 0.039750, loss_s1: 0.028507, loss_fp: 0.002249, loss_freq: 0.011520
[18:52:24.711] iteration 24171: loss: 0.048933, loss_s1: 0.043901, loss_fp: 0.002966, loss_freq: 0.004684
[18:52:25.344] iteration 24172: loss: 0.044845, loss_s1: 0.037101, loss_fp: 0.002716, loss_freq: 0.015200
[18:52:25.966] iteration 24173: loss: 0.044391, loss_s1: 0.022228, loss_fp: 0.002906, loss_freq: 0.028994
[18:52:26.590] iteration 24174: loss: 0.092091, loss_s1: 0.080557, loss_fp: 0.003970, loss_freq: 0.069557
[18:52:27.207] iteration 24175: loss: 0.067041, loss_s1: 0.079147, loss_fp: 0.007611, loss_freq: 0.018061
[18:52:27.827] iteration 24176: loss: 0.064215, loss_s1: 0.059246, loss_fp: 0.001421, loss_freq: 0.041156
[18:52:28.448] iteration 24177: loss: 0.034477, loss_s1: 0.028152, loss_fp: 0.000308, loss_freq: 0.004096
[18:52:29.072] iteration 24178: loss: 0.069178, loss_s1: 0.046674, loss_fp: 0.006506, loss_freq: 0.043713
[18:52:29.695] iteration 24179: loss: 0.044817, loss_s1: 0.034033, loss_fp: 0.003086, loss_freq: 0.022255
[18:52:30.354] iteration 24180: loss: 0.062174, loss_s1: 0.037991, loss_fp: 0.004495, loss_freq: 0.022656
[18:52:31.018] iteration 24181: loss: 0.036396, loss_s1: 0.036556, loss_fp: 0.001136, loss_freq: 0.011093
[18:52:31.660] iteration 24182: loss: 0.057169, loss_s1: 0.052028, loss_fp: 0.002190, loss_freq: 0.025045
[18:52:32.290] iteration 24183: loss: 0.051386, loss_s1: 0.029695, loss_fp: 0.005003, loss_freq: 0.026669
[18:52:32.921] iteration 24184: loss: 0.038030, loss_s1: 0.039380, loss_fp: 0.001613, loss_freq: 0.008009
[18:52:33.542] iteration 24185: loss: 0.067751, loss_s1: 0.046510, loss_fp: 0.017533, loss_freq: 0.025408
[18:52:34.167] iteration 24186: loss: 0.076103, loss_s1: 0.056666, loss_fp: 0.002473, loss_freq: 0.061896
[18:52:34.795] iteration 24187: loss: 0.069610, loss_s1: 0.063000, loss_fp: 0.007960, loss_freq: 0.033950
[18:52:35.414] iteration 24188: loss: 0.074962, loss_s1: 0.046639, loss_fp: 0.003134, loss_freq: 0.044036
[18:52:36.037] iteration 24189: loss: 0.050365, loss_s1: 0.038636, loss_fp: 0.001817, loss_freq: 0.012894
[18:52:36.675] iteration 24190: loss: 0.054028, loss_s1: 0.052993, loss_fp: 0.004103, loss_freq: 0.020435
[18:52:37.287] iteration 24191: loss: 0.041439, loss_s1: 0.026245, loss_fp: 0.002570, loss_freq: 0.017814
[18:52:37.900] iteration 24192: loss: 0.078795, loss_s1: 0.058045, loss_fp: 0.003462, loss_freq: 0.067348
[18:52:38.525] iteration 24193: loss: 0.094021, loss_s1: 0.074560, loss_fp: 0.007993, loss_freq: 0.058350
[18:52:39.154] iteration 24194: loss: 0.073663, loss_s1: 0.057108, loss_fp: 0.004780, loss_freq: 0.055815
[18:52:39.813] iteration 24195: loss: 0.061394, loss_s1: 0.037900, loss_fp: 0.009838, loss_freq: 0.039245
[18:52:40.474] iteration 24196: loss: 0.054815, loss_s1: 0.037078, loss_fp: 0.006162, loss_freq: 0.006355
[18:52:41.102] iteration 24197: loss: 0.035170, loss_s1: 0.019054, loss_fp: 0.000744, loss_freq: 0.015035
[18:52:41.722] iteration 24198: loss: 0.051017, loss_s1: 0.042246, loss_fp: 0.001013, loss_freq: 0.027102
[18:52:42.342] iteration 24199: loss: 0.061988, loss_s1: 0.052152, loss_fp: 0.004348, loss_freq: 0.024204
[18:52:43.009] iteration 24200: loss: 0.072926, loss_s1: 0.048626, loss_fp: 0.001229, loss_freq: 0.061364
[18:52:46.320] iteration 24200 : mean_dice : 0.729800
[18:52:46.956] iteration 24201: loss: 0.066003, loss_s1: 0.056086, loss_fp: 0.001644, loss_freq: 0.037697
[18:52:47.574] iteration 24202: loss: 0.056178, loss_s1: 0.031243, loss_fp: 0.012685, loss_freq: 0.024352
[18:52:48.191] iteration 24203: loss: 0.045551, loss_s1: 0.013240, loss_fp: 0.003253, loss_freq: 0.025996
[18:52:48.819] iteration 24204: loss: 0.069119, loss_s1: 0.053186, loss_fp: 0.001979, loss_freq: 0.048718
[18:52:49.448] iteration 24205: loss: 0.032207, loss_s1: 0.013179, loss_fp: 0.000875, loss_freq: 0.017993
[18:52:50.077] iteration 24206: loss: 0.046076, loss_s1: 0.035248, loss_fp: 0.002297, loss_freq: 0.014766
[18:52:50.707] iteration 24207: loss: 0.026933, loss_s1: 0.010734, loss_fp: 0.001200, loss_freq: 0.009160
[18:52:51.328] iteration 24208: loss: 0.060735, loss_s1: 0.050600, loss_fp: 0.001296, loss_freq: 0.014920
[18:52:51.950] iteration 24209: loss: 0.038308, loss_s1: 0.026084, loss_fp: 0.004474, loss_freq: 0.015371
[18:52:52.581] iteration 24210: loss: 0.032081, loss_s1: 0.019480, loss_fp: 0.004241, loss_freq: 0.017021
[18:52:53.212] iteration 24211: loss: 0.046341, loss_s1: 0.025110, loss_fp: 0.002023, loss_freq: 0.010707
[18:52:53.831] iteration 24212: loss: 0.029801, loss_s1: 0.012624, loss_fp: 0.002663, loss_freq: 0.015767
[18:52:54.467] iteration 24213: loss: 0.034551, loss_s1: 0.014214, loss_fp: 0.001405, loss_freq: 0.007139
[18:52:55.134] iteration 24214: loss: 0.067605, loss_s1: 0.063038, loss_fp: 0.005571, loss_freq: 0.032161
[18:52:55.793] iteration 24215: loss: 0.049074, loss_s1: 0.046295, loss_fp: 0.001895, loss_freq: 0.014948
[18:52:56.454] iteration 24216: loss: 0.061733, loss_s1: 0.041434, loss_fp: 0.003609, loss_freq: 0.049635
[18:52:57.121] iteration 24217: loss: 0.040651, loss_s1: 0.017102, loss_fp: 0.002195, loss_freq: 0.019634
[18:52:57.788] iteration 24218: loss: 0.052110, loss_s1: 0.057183, loss_fp: 0.004640, loss_freq: 0.017984
[18:52:58.421] iteration 24219: loss: 0.049582, loss_s1: 0.044306, loss_fp: 0.013100, loss_freq: 0.006854
[18:52:59.049] iteration 24220: loss: 0.082242, loss_s1: 0.062004, loss_fp: 0.003458, loss_freq: 0.031698
[18:52:59.683] iteration 24221: loss: 0.079720, loss_s1: 0.070001, loss_fp: 0.007165, loss_freq: 0.048163
[18:53:00.321] iteration 24222: loss: 0.060377, loss_s1: 0.059565, loss_fp: 0.001454, loss_freq: 0.019420
[18:53:00.951] iteration 24223: loss: 0.055432, loss_s1: 0.037349, loss_fp: 0.003376, loss_freq: 0.025707
[18:53:01.580] iteration 24224: loss: 0.037666, loss_s1: 0.030824, loss_fp: 0.001859, loss_freq: 0.008014
[18:53:02.211] iteration 24225: loss: 0.048439, loss_s1: 0.028821, loss_fp: 0.003543, loss_freq: 0.022545
[18:53:02.872] iteration 24226: loss: 0.044446, loss_s1: 0.020987, loss_fp: 0.002636, loss_freq: 0.019165
[18:53:03.501] iteration 24227: loss: 0.055827, loss_s1: 0.054592, loss_fp: 0.001692, loss_freq: 0.019527
[18:53:04.132] iteration 24228: loss: 0.035932, loss_s1: 0.022173, loss_fp: 0.002020, loss_freq: 0.018903
[18:53:04.758] iteration 24229: loss: 0.022056, loss_s1: 0.013874, loss_fp: 0.002206, loss_freq: 0.004578
[18:53:05.391] iteration 24230: loss: 0.054422, loss_s1: 0.035033, loss_fp: 0.001617, loss_freq: 0.035618
[18:53:06.019] iteration 24231: loss: 0.055581, loss_s1: 0.046044, loss_fp: 0.004669, loss_freq: 0.026242
[18:53:06.647] iteration 24232: loss: 0.064082, loss_s1: 0.041005, loss_fp: 0.003654, loss_freq: 0.052071
[18:53:07.348] iteration 24233: loss: 0.050762, loss_s1: 0.056417, loss_fp: 0.001843, loss_freq: 0.016731
[18:53:08.001] iteration 24234: loss: 0.063625, loss_s1: 0.051298, loss_fp: 0.006921, loss_freq: 0.015974
[18:53:08.660] iteration 24235: loss: 0.067075, loss_s1: 0.051610, loss_fp: 0.011763, loss_freq: 0.040139
[18:53:09.290] iteration 24236: loss: 0.038759, loss_s1: 0.025702, loss_fp: 0.001724, loss_freq: 0.014995
[18:53:09.912] iteration 24237: loss: 0.068236, loss_s1: 0.047307, loss_fp: 0.005172, loss_freq: 0.022071
[18:53:10.561] iteration 24238: loss: 0.028867, loss_s1: 0.013614, loss_fp: 0.004379, loss_freq: 0.006914
[18:53:11.188] iteration 24239: loss: 0.047410, loss_s1: 0.026485, loss_fp: 0.003407, loss_freq: 0.032451
[18:53:11.805] iteration 24240: loss: 0.063544, loss_s1: 0.051555, loss_fp: 0.003783, loss_freq: 0.031803
[18:53:12.426] iteration 24241: loss: 0.062699, loss_s1: 0.047480, loss_fp: 0.005392, loss_freq: 0.020188
[18:53:13.046] iteration 24242: loss: 0.055004, loss_s1: 0.035078, loss_fp: 0.004437, loss_freq: 0.019287
[18:53:13.661] iteration 24243: loss: 0.053019, loss_s1: 0.039070, loss_fp: 0.002083, loss_freq: 0.011307
[18:53:14.274] iteration 24244: loss: 0.032700, loss_s1: 0.026167, loss_fp: 0.001301, loss_freq: 0.008684
[18:53:14.893] iteration 24245: loss: 0.054584, loss_s1: 0.038956, loss_fp: 0.002296, loss_freq: 0.037544
[18:53:15.511] iteration 24246: loss: 0.038724, loss_s1: 0.035514, loss_fp: 0.004024, loss_freq: 0.009994
[18:53:16.132] iteration 24247: loss: 0.045109, loss_s1: 0.026954, loss_fp: 0.000841, loss_freq: 0.020184
[18:53:16.750] iteration 24248: loss: 0.052817, loss_s1: 0.055110, loss_fp: 0.000856, loss_freq: 0.015155
[18:53:17.369] iteration 24249: loss: 0.042100, loss_s1: 0.023275, loss_fp: 0.001089, loss_freq: 0.021803
[18:53:17.982] iteration 24250: loss: 0.052967, loss_s1: 0.031484, loss_fp: 0.010312, loss_freq: 0.017725
[18:53:18.597] iteration 24251: loss: 0.051071, loss_s1: 0.055610, loss_fp: 0.005934, loss_freq: 0.014595
[18:53:19.210] iteration 24252: loss: 0.074836, loss_s1: 0.038966, loss_fp: 0.013462, loss_freq: 0.042392
[18:53:19.828] iteration 24253: loss: 0.050259, loss_s1: 0.035338, loss_fp: 0.005755, loss_freq: 0.031087
[18:53:20.449] iteration 24254: loss: 0.066380, loss_s1: 0.066564, loss_fp: 0.006754, loss_freq: 0.027677
[18:53:21.077] iteration 24255: loss: 0.047653, loss_s1: 0.014770, loss_fp: 0.009453, loss_freq: 0.013538
[18:53:21.693] iteration 24256: loss: 0.045066, loss_s1: 0.030142, loss_fp: 0.004439, loss_freq: 0.024290
[18:53:22.312] iteration 24257: loss: 0.037342, loss_s1: 0.037274, loss_fp: 0.000255, loss_freq: 0.003928
[18:53:22.941] iteration 24258: loss: 0.051769, loss_s1: 0.039190, loss_fp: 0.004516, loss_freq: 0.014908
[18:53:23.589] iteration 24259: loss: 0.081815, loss_s1: 0.048382, loss_fp: 0.007905, loss_freq: 0.070499
[18:53:24.248] iteration 24260: loss: 0.060135, loss_s1: 0.049027, loss_fp: 0.007951, loss_freq: 0.028321
[18:53:24.908] iteration 24261: loss: 0.067681, loss_s1: 0.069616, loss_fp: 0.003042, loss_freq: 0.016967
[18:53:25.533] iteration 24262: loss: 0.036370, loss_s1: 0.023608, loss_fp: 0.002715, loss_freq: 0.018109
[18:53:26.182] iteration 24263: loss: 0.055091, loss_s1: 0.067347, loss_fp: 0.001655, loss_freq: 0.016576
[18:53:26.844] iteration 24264: loss: 0.069363, loss_s1: 0.092275, loss_fp: 0.001301, loss_freq: 0.018014
[18:53:27.500] iteration 24265: loss: 0.027616, loss_s1: 0.015764, loss_fp: 0.000707, loss_freq: 0.005230
[18:53:28.119] iteration 24266: loss: 0.070906, loss_s1: 0.049267, loss_fp: 0.005045, loss_freq: 0.046385
[18:53:28.750] iteration 24267: loss: 0.063160, loss_s1: 0.066956, loss_fp: 0.004666, loss_freq: 0.018867
[18:53:29.376] iteration 24268: loss: 0.039323, loss_s1: 0.033616, loss_fp: 0.002175, loss_freq: 0.007328
[18:53:30.002] iteration 24269: loss: 0.043276, loss_s1: 0.027926, loss_fp: 0.009441, loss_freq: 0.016249
[18:53:30.629] iteration 24270: loss: 0.067776, loss_s1: 0.059531, loss_fp: 0.003285, loss_freq: 0.049739
[18:53:31.248] iteration 24271: loss: 0.066610, loss_s1: 0.039185, loss_fp: 0.003541, loss_freq: 0.059489
[18:53:31.879] iteration 24272: loss: 0.061861, loss_s1: 0.021649, loss_fp: 0.004920, loss_freq: 0.058679
[18:53:32.511] iteration 24273: loss: 0.058639, loss_s1: 0.064872, loss_fp: 0.002351, loss_freq: 0.020158
[18:53:33.151] iteration 24274: loss: 0.031406, loss_s1: 0.022446, loss_fp: 0.000545, loss_freq: 0.007131
[18:53:33.779] iteration 24275: loss: 0.063942, loss_s1: 0.055808, loss_fp: 0.004264, loss_freq: 0.041973
[18:53:34.403] iteration 24276: loss: 0.061943, loss_s1: 0.036789, loss_fp: 0.007898, loss_freq: 0.034099
[18:53:35.031] iteration 24277: loss: 0.053514, loss_s1: 0.032020, loss_fp: 0.019826, loss_freq: 0.007974
[18:53:35.660] iteration 24278: loss: 0.056079, loss_s1: 0.031435, loss_fp: 0.000864, loss_freq: 0.017564
[18:53:36.287] iteration 24279: loss: 0.077971, loss_s1: 0.063792, loss_fp: 0.006760, loss_freq: 0.057301
[18:53:36.915] iteration 24280: loss: 0.040146, loss_s1: 0.033298, loss_fp: 0.004090, loss_freq: 0.010939
[18:53:37.541] iteration 24281: loss: 0.059053, loss_s1: 0.058031, loss_fp: 0.002752, loss_freq: 0.027135
[18:53:38.160] iteration 24282: loss: 0.080523, loss_s1: 0.105100, loss_fp: 0.003928, loss_freq: 0.017191
[18:53:38.787] iteration 24283: loss: 0.057670, loss_s1: 0.054355, loss_fp: 0.004353, loss_freq: 0.018185
[18:53:39.418] iteration 24284: loss: 0.036963, loss_s1: 0.023659, loss_fp: 0.002522, loss_freq: 0.014584
[18:53:40.047] iteration 24285: loss: 0.049994, loss_s1: 0.036650, loss_fp: 0.003576, loss_freq: 0.024941
[18:53:40.686] iteration 24286: loss: 0.057661, loss_s1: 0.069673, loss_fp: 0.001789, loss_freq: 0.016872
[18:53:41.359] iteration 24287: loss: 0.031569, loss_s1: 0.020701, loss_fp: 0.000473, loss_freq: 0.005917
[18:53:42.027] iteration 24288: loss: 0.040780, loss_s1: 0.040469, loss_fp: 0.000968, loss_freq: 0.013206
[18:53:42.697] iteration 24289: loss: 0.034857, loss_s1: 0.027095, loss_fp: 0.002521, loss_freq: 0.011448
[18:53:43.331] iteration 24290: loss: 0.056479, loss_s1: 0.038483, loss_fp: 0.003322, loss_freq: 0.030590
[18:53:43.965] iteration 24291: loss: 0.097750, loss_s1: 0.113894, loss_fp: 0.002907, loss_freq: 0.045976
[18:53:44.600] iteration 24292: loss: 0.037062, loss_s1: 0.021816, loss_fp: 0.002034, loss_freq: 0.017912
[18:53:45.224] iteration 24293: loss: 0.073646, loss_s1: 0.044990, loss_fp: 0.012278, loss_freq: 0.050799
[18:53:45.846] iteration 24294: loss: 0.058394, loss_s1: 0.050631, loss_fp: 0.004214, loss_freq: 0.024724
[18:53:46.476] iteration 24295: loss: 0.047651, loss_s1: 0.041463, loss_fp: 0.004000, loss_freq: 0.017629
[18:53:47.105] iteration 24296: loss: 0.032397, loss_s1: 0.018456, loss_fp: 0.002776, loss_freq: 0.005410
[18:53:47.727] iteration 24297: loss: 0.073102, loss_s1: 0.059993, loss_fp: 0.013691, loss_freq: 0.041690
[18:53:48.356] iteration 24298: loss: 0.043577, loss_s1: 0.050066, loss_fp: 0.000746, loss_freq: 0.007667
[18:53:48.980] iteration 24299: loss: 0.031218, loss_s1: 0.016395, loss_fp: 0.003479, loss_freq: 0.011057
[18:53:49.608] iteration 24300: loss: 0.092938, loss_s1: 0.105741, loss_fp: 0.004380, loss_freq: 0.041128
[18:53:50.234] iteration 24301: loss: 0.054099, loss_s1: 0.027792, loss_fp: 0.008678, loss_freq: 0.035408
[18:53:50.860] iteration 24302: loss: 0.068098, loss_s1: 0.057115, loss_fp: 0.008816, loss_freq: 0.040090
[18:53:51.484] iteration 24303: loss: 0.042662, loss_s1: 0.029523, loss_fp: 0.002962, loss_freq: 0.024496
[18:53:52.112] iteration 24304: loss: 0.049541, loss_s1: 0.030308, loss_fp: 0.003812, loss_freq: 0.021602
[18:53:52.758] iteration 24305: loss: 0.030494, loss_s1: 0.022501, loss_fp: 0.002594, loss_freq: 0.010277
[18:53:53.385] iteration 24306: loss: 0.052709, loss_s1: 0.042712, loss_fp: 0.004475, loss_freq: 0.024642
[18:53:54.009] iteration 24307: loss: 0.045680, loss_s1: 0.032517, loss_fp: 0.001536, loss_freq: 0.015698
[18:53:54.639] iteration 24308: loss: 0.050352, loss_s1: 0.023629, loss_fp: 0.001719, loss_freq: 0.039492
[18:53:55.259] iteration 24309: loss: 0.057741, loss_s1: 0.059097, loss_fp: 0.007973, loss_freq: 0.011928
[18:53:55.885] iteration 24310: loss: 0.050545, loss_s1: 0.021467, loss_fp: 0.001893, loss_freq: 0.042700
[18:53:56.510] iteration 24311: loss: 0.079665, loss_s1: 0.080539, loss_fp: 0.004243, loss_freq: 0.036226
[18:53:57.500] iteration 24312: loss: 0.047341, loss_s1: 0.040261, loss_fp: 0.001920, loss_freq: 0.004790
[18:53:58.178] iteration 24313: loss: 0.052858, loss_s1: 0.040040, loss_fp: 0.008406, loss_freq: 0.025323
[18:53:58.841] iteration 24314: loss: 0.037784, loss_s1: 0.025972, loss_fp: 0.002334, loss_freq: 0.012489
[18:53:59.488] iteration 24315: loss: 0.042050, loss_s1: 0.034126, loss_fp: 0.000985, loss_freq: 0.006461
[18:54:00.112] iteration 24316: loss: 0.060081, loss_s1: 0.057115, loss_fp: 0.004674, loss_freq: 0.023521
[18:54:00.771] iteration 24317: loss: 0.077631, loss_s1: 0.057479, loss_fp: 0.002437, loss_freq: 0.036610
[18:54:01.436] iteration 24318: loss: 0.049467, loss_s1: 0.048360, loss_fp: 0.002123, loss_freq: 0.021566
[18:54:02.098] iteration 24319: loss: 0.037057, loss_s1: 0.031007, loss_fp: 0.003409, loss_freq: 0.012699
[18:54:02.741] iteration 24320: loss: 0.054311, loss_s1: 0.033398, loss_fp: 0.005298, loss_freq: 0.044947
[18:54:03.369] iteration 24321: loss: 0.045713, loss_s1: 0.022663, loss_fp: 0.002577, loss_freq: 0.024739
[18:54:03.988] iteration 24322: loss: 0.030453, loss_s1: 0.011982, loss_fp: 0.000935, loss_freq: 0.012349
[18:54:04.651] iteration 24323: loss: 0.053252, loss_s1: 0.025121, loss_fp: 0.001869, loss_freq: 0.045000
[18:54:05.345] iteration 24324: loss: 0.061061, loss_s1: 0.036040, loss_fp: 0.001269, loss_freq: 0.057692
[18:54:06.010] iteration 24325: loss: 0.049169, loss_s1: 0.016294, loss_fp: 0.003572, loss_freq: 0.022627
[18:54:06.675] iteration 24326: loss: 0.044428, loss_s1: 0.047810, loss_fp: 0.004374, loss_freq: 0.009896
[18:54:07.338] iteration 24327: loss: 0.098681, loss_s1: 0.083916, loss_fp: 0.009028, loss_freq: 0.065949
[18:54:07.994] iteration 24328: loss: 0.035164, loss_s1: 0.017684, loss_fp: 0.003205, loss_freq: 0.007382
[18:54:08.629] iteration 24329: loss: 0.055865, loss_s1: 0.042757, loss_fp: 0.004335, loss_freq: 0.032699
[18:54:09.256] iteration 24330: loss: 0.045666, loss_s1: 0.043985, loss_fp: 0.002216, loss_freq: 0.010991
[18:54:09.883] iteration 24331: loss: 0.046366, loss_s1: 0.033646, loss_fp: 0.006138, loss_freq: 0.021014
[18:54:10.502] iteration 24332: loss: 0.034070, loss_s1: 0.019788, loss_fp: 0.001191, loss_freq: 0.010047
[18:54:11.124] iteration 24333: loss: 0.049669, loss_s1: 0.039411, loss_fp: 0.003168, loss_freq: 0.013917
[18:54:11.744] iteration 24334: loss: 0.055855, loss_s1: 0.049799, loss_fp: 0.003113, loss_freq: 0.006510
[18:54:12.364] iteration 24335: loss: 0.085680, loss_s1: 0.118426, loss_fp: 0.003181, loss_freq: 0.020785
[18:54:12.985] iteration 24336: loss: 0.040340, loss_s1: 0.028804, loss_fp: 0.001257, loss_freq: 0.022084
[18:54:13.613] iteration 24337: loss: 0.060449, loss_s1: 0.049126, loss_fp: 0.001182, loss_freq: 0.035121
[18:54:14.234] iteration 24338: loss: 0.021436, loss_s1: 0.008008, loss_fp: 0.001308, loss_freq: 0.003002
[18:54:14.860] iteration 24339: loss: 0.083901, loss_s1: 0.077497, loss_fp: 0.022652, loss_freq: 0.029657
[18:54:15.477] iteration 24340: loss: 0.067630, loss_s1: 0.043292, loss_fp: 0.002049, loss_freq: 0.042551
[18:54:16.112] iteration 24341: loss: 0.059104, loss_s1: 0.048812, loss_fp: 0.004241, loss_freq: 0.025589
[18:54:16.738] iteration 24342: loss: 0.057783, loss_s1: 0.039304, loss_fp: 0.001563, loss_freq: 0.043225
[18:54:17.362] iteration 24343: loss: 0.053980, loss_s1: 0.046345, loss_fp: 0.002529, loss_freq: 0.024395
[18:54:17.987] iteration 24344: loss: 0.054761, loss_s1: 0.032682, loss_fp: 0.002569, loss_freq: 0.043158
[18:54:18.616] iteration 24345: loss: 0.036157, loss_s1: 0.035191, loss_fp: 0.000763, loss_freq: 0.009388
[18:54:19.239] iteration 24346: loss: 0.061990, loss_s1: 0.027612, loss_fp: 0.003781, loss_freq: 0.018588
[18:54:19.864] iteration 24347: loss: 0.058318, loss_s1: 0.039882, loss_fp: 0.005912, loss_freq: 0.034929
[18:54:20.485] iteration 24348: loss: 0.069762, loss_s1: 0.052380, loss_fp: 0.003471, loss_freq: 0.030001
[18:54:21.116] iteration 24349: loss: 0.075693, loss_s1: 0.090248, loss_fp: 0.002788, loss_freq: 0.026797
[18:54:21.738] iteration 24350: loss: 0.090530, loss_s1: 0.083378, loss_fp: 0.002065, loss_freq: 0.055328
[18:54:22.364] iteration 24351: loss: 0.053963, loss_s1: 0.054726, loss_fp: 0.000346, loss_freq: 0.020345
[18:54:22.993] iteration 24352: loss: 0.047214, loss_s1: 0.030141, loss_fp: 0.004118, loss_freq: 0.014985
[18:54:23.614] iteration 24353: loss: 0.057572, loss_s1: 0.034281, loss_fp: 0.005637, loss_freq: 0.050106
[18:54:24.241] iteration 24354: loss: 0.080089, loss_s1: 0.088554, loss_fp: 0.003492, loss_freq: 0.044505
[18:54:24.873] iteration 24355: loss: 0.062820, loss_s1: 0.043609, loss_fp: 0.001807, loss_freq: 0.052776
[18:54:25.494] iteration 24356: loss: 0.039920, loss_s1: 0.022441, loss_fp: 0.005517, loss_freq: 0.012760
[18:54:26.122] iteration 24357: loss: 0.055134, loss_s1: 0.061349, loss_fp: 0.002202, loss_freq: 0.007942
[18:54:26.748] iteration 24358: loss: 0.031576, loss_s1: 0.015322, loss_fp: 0.002530, loss_freq: 0.016338
[18:54:27.371] iteration 24359: loss: 0.049548, loss_s1: 0.041764, loss_fp: 0.007053, loss_freq: 0.019486
[18:54:27.998] iteration 24360: loss: 0.064904, loss_s1: 0.058775, loss_fp: 0.002447, loss_freq: 0.019162
[18:54:28.625] iteration 24361: loss: 0.046267, loss_s1: 0.044441, loss_fp: 0.001145, loss_freq: 0.016499
[18:54:29.252] iteration 24362: loss: 0.052181, loss_s1: 0.034632, loss_fp: 0.001543, loss_freq: 0.039219
[18:54:29.875] iteration 24363: loss: 0.062190, loss_s1: 0.047967, loss_fp: 0.002250, loss_freq: 0.032000
[18:54:30.509] iteration 24364: loss: 0.049976, loss_s1: 0.038473, loss_fp: 0.004462, loss_freq: 0.029678
[18:54:31.136] iteration 24365: loss: 0.066936, loss_s1: 0.054837, loss_fp: 0.001638, loss_freq: 0.037132
[18:54:31.763] iteration 24366: loss: 0.029544, loss_s1: 0.022297, loss_fp: 0.001044, loss_freq: 0.007581
[18:54:32.396] iteration 24367: loss: 0.054138, loss_s1: 0.040890, loss_fp: 0.004088, loss_freq: 0.024848
[18:54:33.023] iteration 24368: loss: 0.039109, loss_s1: 0.025400, loss_fp: 0.001984, loss_freq: 0.014766
[18:54:33.652] iteration 24369: loss: 0.044860, loss_s1: 0.023630, loss_fp: 0.005577, loss_freq: 0.022734
[18:54:34.283] iteration 24370: loss: 0.041795, loss_s1: 0.044644, loss_fp: 0.001368, loss_freq: 0.004020
[18:54:34.936] iteration 24371: loss: 0.035522, loss_s1: 0.015579, loss_fp: 0.002597, loss_freq: 0.026355
[18:54:35.566] iteration 24372: loss: 0.045408, loss_s1: 0.031510, loss_fp: 0.005570, loss_freq: 0.027683
[18:54:36.197] iteration 24373: loss: 0.069721, loss_s1: 0.062758, loss_fp: 0.014372, loss_freq: 0.013534
[18:54:36.823] iteration 24374: loss: 0.044240, loss_s1: 0.026358, loss_fp: 0.001048, loss_freq: 0.011221
[18:54:37.490] iteration 24375: loss: 0.029031, loss_s1: 0.016641, loss_fp: 0.002343, loss_freq: 0.010006
[18:54:38.152] iteration 24376: loss: 0.066542, loss_s1: 0.061314, loss_fp: 0.003977, loss_freq: 0.015429
[18:54:38.793] iteration 24377: loss: 0.054391, loss_s1: 0.033298, loss_fp: 0.008568, loss_freq: 0.037542
[18:54:39.426] iteration 24378: loss: 0.054725, loss_s1: 0.032340, loss_fp: 0.000474, loss_freq: 0.038935
[18:54:40.048] iteration 24379: loss: 0.061736, loss_s1: 0.052561, loss_fp: 0.003602, loss_freq: 0.032834
[18:54:40.683] iteration 24380: loss: 0.054557, loss_s1: 0.042518, loss_fp: 0.001298, loss_freq: 0.033345
[18:54:41.333] iteration 24381: loss: 0.051899, loss_s1: 0.027519, loss_fp: 0.008596, loss_freq: 0.029357
[18:54:41.991] iteration 24382: loss: 0.075049, loss_s1: 0.043737, loss_fp: 0.013401, loss_freq: 0.057033
[18:54:42.646] iteration 24383: loss: 0.039220, loss_s1: 0.019724, loss_fp: 0.000607, loss_freq: 0.025166
[18:54:43.299] iteration 24384: loss: 0.053439, loss_s1: 0.041759, loss_fp: 0.003051, loss_freq: 0.016378
[18:54:43.921] iteration 24385: loss: 0.033034, loss_s1: 0.018649, loss_fp: 0.006916, loss_freq: 0.006328
[18:54:44.550] iteration 24386: loss: 0.074037, loss_s1: 0.078986, loss_fp: 0.004476, loss_freq: 0.020733
[18:54:45.170] iteration 24387: loss: 0.061424, loss_s1: 0.066439, loss_fp: 0.001787, loss_freq: 0.015084
[18:54:45.798] iteration 24388: loss: 0.050593, loss_s1: 0.048110, loss_fp: 0.003018, loss_freq: 0.024563
[18:54:46.422] iteration 24389: loss: 0.052909, loss_s1: 0.060173, loss_fp: 0.004046, loss_freq: 0.011382
[18:54:47.054] iteration 24390: loss: 0.024270, loss_s1: 0.010314, loss_fp: 0.001170, loss_freq: 0.011288
[18:54:47.673] iteration 24391: loss: 0.043016, loss_s1: 0.028459, loss_fp: 0.000850, loss_freq: 0.015752
[18:54:48.303] iteration 24392: loss: 0.067857, loss_s1: 0.043146, loss_fp: 0.004434, loss_freq: 0.043991
[18:54:48.926] iteration 24393: loss: 0.042248, loss_s1: 0.033745, loss_fp: 0.004874, loss_freq: 0.015403
[18:54:49.550] iteration 24394: loss: 0.051091, loss_s1: 0.042789, loss_fp: 0.003698, loss_freq: 0.022617
[18:54:50.174] iteration 24395: loss: 0.039260, loss_s1: 0.016350, loss_fp: 0.002927, loss_freq: 0.015018
[18:54:50.790] iteration 24396: loss: 0.080963, loss_s1: 0.067369, loss_fp: 0.004515, loss_freq: 0.056892
[18:54:51.415] iteration 24397: loss: 0.057984, loss_s1: 0.053131, loss_fp: 0.005755, loss_freq: 0.027056
[18:54:52.049] iteration 24398: loss: 0.073154, loss_s1: 0.031234, loss_fp: 0.003891, loss_freq: 0.010132
[18:54:52.672] iteration 24399: loss: 0.038069, loss_s1: 0.024022, loss_fp: 0.003633, loss_freq: 0.010424
[18:54:53.303] iteration 24400: loss: 0.052061, loss_s1: 0.045049, loss_fp: 0.004417, loss_freq: 0.020529
[18:54:56.569] iteration 24400 : mean_dice : 0.722876
[18:54:57.215] iteration 24401: loss: 0.053697, loss_s1: 0.044572, loss_fp: 0.007137, loss_freq: 0.026234
[18:54:57.839] iteration 24402: loss: 0.048816, loss_s1: 0.034184, loss_fp: 0.002908, loss_freq: 0.018721
[18:54:58.463] iteration 24403: loss: 0.056119, loss_s1: 0.048277, loss_fp: 0.001912, loss_freq: 0.024208
[18:54:59.089] iteration 24404: loss: 0.078667, loss_s1: 0.037353, loss_fp: 0.002088, loss_freq: 0.047266
[18:54:59.738] iteration 24405: loss: 0.036593, loss_s1: 0.018494, loss_fp: 0.000593, loss_freq: 0.015230
[18:55:00.371] iteration 24406: loss: 0.049856, loss_s1: 0.034819, loss_fp: 0.005358, loss_freq: 0.027394
[18:55:01.001] iteration 24407: loss: 0.058999, loss_s1: 0.046365, loss_fp: 0.006302, loss_freq: 0.035413
[18:55:01.631] iteration 24408: loss: 0.042346, loss_s1: 0.029928, loss_fp: 0.000782, loss_freq: 0.022183
[18:55:02.264] iteration 24409: loss: 0.055842, loss_s1: 0.013609, loss_fp: 0.001318, loss_freq: 0.048276
[18:55:02.886] iteration 24410: loss: 0.034812, loss_s1: 0.014818, loss_fp: 0.001520, loss_freq: 0.026351
[18:55:03.514] iteration 24411: loss: 0.031358, loss_s1: 0.022335, loss_fp: 0.003761, loss_freq: 0.008290
[18:55:04.141] iteration 24412: loss: 0.052423, loss_s1: 0.057537, loss_fp: 0.000829, loss_freq: 0.013414
[18:55:04.772] iteration 24413: loss: 0.058471, loss_s1: 0.012063, loss_fp: 0.002278, loss_freq: 0.066095
[18:55:05.397] iteration 24414: loss: 0.060352, loss_s1: 0.020099, loss_fp: 0.002484, loss_freq: 0.055971
[18:55:06.033] iteration 24415: loss: 0.059936, loss_s1: 0.059255, loss_fp: 0.009633, loss_freq: 0.018690
[18:55:06.663] iteration 24416: loss: 0.056810, loss_s1: 0.047199, loss_fp: 0.001008, loss_freq: 0.010491
[18:55:07.302] iteration 24417: loss: 0.054087, loss_s1: 0.043265, loss_fp: 0.005532, loss_freq: 0.025914
[18:55:07.944] iteration 24418: loss: 0.026167, loss_s1: 0.013281, loss_fp: 0.005109, loss_freq: 0.003099
[18:55:08.569] iteration 24419: loss: 0.082549, loss_s1: 0.075195, loss_fp: 0.001360, loss_freq: 0.051068
[18:55:09.190] iteration 24420: loss: 0.079144, loss_s1: 0.057242, loss_fp: 0.011546, loss_freq: 0.039133
[18:55:09.849] iteration 24421: loss: 0.075620, loss_s1: 0.070184, loss_fp: 0.003744, loss_freq: 0.023462
[18:55:10.506] iteration 24422: loss: 0.044372, loss_s1: 0.022784, loss_fp: 0.007420, loss_freq: 0.014586
[18:55:11.169] iteration 24423: loss: 0.062896, loss_s1: 0.042074, loss_fp: 0.003609, loss_freq: 0.045044
[18:55:11.831] iteration 24424: loss: 0.049786, loss_s1: 0.045630, loss_fp: 0.003705, loss_freq: 0.020145
[18:55:12.454] iteration 24425: loss: 0.048222, loss_s1: 0.024770, loss_fp: 0.004022, loss_freq: 0.032438
[18:55:13.076] iteration 24426: loss: 0.062627, loss_s1: 0.062688, loss_fp: 0.000684, loss_freq: 0.012802
[18:55:13.703] iteration 24427: loss: 0.063236, loss_s1: 0.057425, loss_fp: 0.004270, loss_freq: 0.016166
[18:55:14.331] iteration 24428: loss: 0.050305, loss_s1: 0.025832, loss_fp: 0.003607, loss_freq: 0.035466
[18:55:14.953] iteration 24429: loss: 0.022007, loss_s1: 0.006192, loss_fp: 0.001605, loss_freq: 0.008416
[18:55:15.579] iteration 24430: loss: 0.054843, loss_s1: 0.037235, loss_fp: 0.005132, loss_freq: 0.030514
[18:55:16.241] iteration 24431: loss: 0.075800, loss_s1: 0.042926, loss_fp: 0.010970, loss_freq: 0.071912
[18:55:16.891] iteration 24432: loss: 0.059146, loss_s1: 0.031902, loss_fp: 0.008199, loss_freq: 0.043474
[18:55:17.516] iteration 24433: loss: 0.066587, loss_s1: 0.045065, loss_fp: 0.004373, loss_freq: 0.026461
[18:55:18.142] iteration 24434: loss: 0.054781, loss_s1: 0.049937, loss_fp: 0.001423, loss_freq: 0.026570
[18:55:18.768] iteration 24435: loss: 0.068499, loss_s1: 0.055218, loss_fp: 0.001374, loss_freq: 0.021219
[18:55:19.395] iteration 24436: loss: 0.039422, loss_s1: 0.023608, loss_fp: 0.001221, loss_freq: 0.016985
[18:55:20.013] iteration 24437: loss: 0.033535, loss_s1: 0.012203, loss_fp: 0.002050, loss_freq: 0.017592
[18:55:20.670] iteration 24438: loss: 0.038882, loss_s1: 0.029100, loss_fp: 0.005960, loss_freq: 0.005448
[18:55:21.332] iteration 24439: loss: 0.111623, loss_s1: 0.069565, loss_fp: 0.017692, loss_freq: 0.069524
[18:55:21.987] iteration 24440: loss: 0.054304, loss_s1: 0.037163, loss_fp: 0.008315, loss_freq: 0.033726
[18:55:22.645] iteration 24441: loss: 0.043215, loss_s1: 0.050778, loss_fp: 0.004975, loss_freq: 0.007180
[18:55:23.261] iteration 24442: loss: 0.085207, loss_s1: 0.088637, loss_fp: 0.002494, loss_freq: 0.050894
[18:55:23.892] iteration 24443: loss: 0.036266, loss_s1: 0.032610, loss_fp: 0.001083, loss_freq: 0.009793
[18:55:24.550] iteration 24444: loss: 0.050208, loss_s1: 0.035643, loss_fp: 0.004928, loss_freq: 0.012863
[18:55:25.223] iteration 24445: loss: 0.045259, loss_s1: 0.034346, loss_fp: 0.007476, loss_freq: 0.020518
[18:55:25.879] iteration 24446: loss: 0.042074, loss_s1: 0.018842, loss_fp: 0.002479, loss_freq: 0.029519
[18:55:26.502] iteration 24447: loss: 0.053031, loss_s1: 0.044346, loss_fp: 0.002274, loss_freq: 0.031931
[18:55:27.134] iteration 24448: loss: 0.054196, loss_s1: 0.028648, loss_fp: 0.003016, loss_freq: 0.033255
[18:55:27.773] iteration 24449: loss: 0.037140, loss_s1: 0.032172, loss_fp: 0.001357, loss_freq: 0.010162
[18:55:28.401] iteration 24450: loss: 0.032281, loss_s1: 0.021130, loss_fp: 0.003681, loss_freq: 0.006890
[18:55:29.032] iteration 24451: loss: 0.064994, loss_s1: 0.055519, loss_fp: 0.003729, loss_freq: 0.027286
[18:55:29.661] iteration 24452: loss: 0.046856, loss_s1: 0.042568, loss_fp: 0.006089, loss_freq: 0.016611
[18:55:30.292] iteration 24453: loss: 0.048669, loss_s1: 0.025142, loss_fp: 0.001179, loss_freq: 0.025400
[18:55:30.910] iteration 24454: loss: 0.043838, loss_s1: 0.031679, loss_fp: 0.002772, loss_freq: 0.018622
[18:55:31.531] iteration 24455: loss: 0.075454, loss_s1: 0.092889, loss_fp: 0.002446, loss_freq: 0.014123
[18:55:32.152] iteration 24456: loss: 0.051383, loss_s1: 0.022823, loss_fp: 0.006688, loss_freq: 0.036829
[18:55:32.776] iteration 24457: loss: 0.068288, loss_s1: 0.050940, loss_fp: 0.024918, loss_freq: 0.015475
[18:55:33.395] iteration 24458: loss: 0.082004, loss_s1: 0.058155, loss_fp: 0.010173, loss_freq: 0.066669
[18:55:34.017] iteration 24459: loss: 0.032712, loss_s1: 0.028793, loss_fp: 0.001254, loss_freq: 0.005330
[18:55:34.637] iteration 24460: loss: 0.055038, loss_s1: 0.044209, loss_fp: 0.004241, loss_freq: 0.015202
[18:55:35.272] iteration 24461: loss: 0.059627, loss_s1: 0.044890, loss_fp: 0.005228, loss_freq: 0.028993
[18:55:35.898] iteration 24462: loss: 0.042389, loss_s1: 0.028002, loss_fp: 0.001036, loss_freq: 0.022347
[18:55:36.515] iteration 24463: loss: 0.076669, loss_s1: 0.044206, loss_fp: 0.010992, loss_freq: 0.062613
[18:55:37.142] iteration 24464: loss: 0.057226, loss_s1: 0.054077, loss_fp: 0.001415, loss_freq: 0.018997
[18:55:37.768] iteration 24465: loss: 0.069595, loss_s1: 0.073611, loss_fp: 0.002216, loss_freq: 0.021628
[18:55:38.397] iteration 24466: loss: 0.028321, loss_s1: 0.016395, loss_fp: 0.000550, loss_freq: 0.009490
[18:55:39.023] iteration 24467: loss: 0.043437, loss_s1: 0.029701, loss_fp: 0.002922, loss_freq: 0.013009
[18:55:39.642] iteration 24468: loss: 0.036180, loss_s1: 0.025630, loss_fp: 0.004078, loss_freq: 0.004978
[18:55:40.271] iteration 24469: loss: 0.061543, loss_s1: 0.034485, loss_fp: 0.003191, loss_freq: 0.030496
[18:55:40.897] iteration 24470: loss: 0.046171, loss_s1: 0.029347, loss_fp: 0.006643, loss_freq: 0.020530
[18:55:41.524] iteration 24471: loss: 0.056265, loss_s1: 0.052885, loss_fp: 0.006902, loss_freq: 0.020654
[18:55:42.140] iteration 24472: loss: 0.058407, loss_s1: 0.047662, loss_fp: 0.001648, loss_freq: 0.021744
[18:55:43.113] iteration 24473: loss: 0.034024, loss_s1: 0.013124, loss_fp: 0.012842, loss_freq: 0.012399
[18:55:43.735] iteration 24474: loss: 0.048948, loss_s1: 0.038398, loss_fp: 0.003808, loss_freq: 0.015083
[18:55:44.362] iteration 24475: loss: 0.042769, loss_s1: 0.025511, loss_fp: 0.000980, loss_freq: 0.014949
[18:55:44.980] iteration 24476: loss: 0.033576, loss_s1: 0.019808, loss_fp: 0.000979, loss_freq: 0.007850
[18:55:45.609] iteration 24477: loss: 0.047739, loss_s1: 0.048245, loss_fp: 0.001143, loss_freq: 0.007796
[18:55:46.237] iteration 24478: loss: 0.121706, loss_s1: 0.088800, loss_fp: 0.008731, loss_freq: 0.056612
[18:55:46.889] iteration 24479: loss: 0.053249, loss_s1: 0.047018, loss_fp: 0.002710, loss_freq: 0.021396
[18:55:47.516] iteration 24480: loss: 0.029117, loss_s1: 0.016065, loss_fp: 0.002112, loss_freq: 0.008761
[18:55:48.186] iteration 24481: loss: 0.059986, loss_s1: 0.038880, loss_fp: 0.004850, loss_freq: 0.048300
[18:55:48.817] iteration 24482: loss: 0.070369, loss_s1: 0.059453, loss_fp: 0.006510, loss_freq: 0.032377
[18:55:49.445] iteration 24483: loss: 0.043785, loss_s1: 0.032784, loss_fp: 0.003397, loss_freq: 0.005187
[18:55:50.070] iteration 24484: loss: 0.039089, loss_s1: 0.019871, loss_fp: 0.002898, loss_freq: 0.026642
[18:55:50.691] iteration 24485: loss: 0.062434, loss_s1: 0.050502, loss_fp: 0.003923, loss_freq: 0.044994
[18:55:51.317] iteration 24486: loss: 0.090384, loss_s1: 0.055330, loss_fp: 0.008471, loss_freq: 0.063027
[18:55:51.947] iteration 24487: loss: 0.071278, loss_s1: 0.028163, loss_fp: 0.059621, loss_freq: 0.027743
[18:55:52.565] iteration 24488: loss: 0.085347, loss_s1: 0.052157, loss_fp: 0.012127, loss_freq: 0.067890
[18:55:53.193] iteration 24489: loss: 0.055392, loss_s1: 0.052507, loss_fp: 0.005644, loss_freq: 0.017552
[18:55:53.818] iteration 24490: loss: 0.044387, loss_s1: 0.027196, loss_fp: 0.016655, loss_freq: 0.014258
[18:55:54.445] iteration 24491: loss: 0.034346, loss_s1: 0.010391, loss_fp: 0.003248, loss_freq: 0.011992
[18:55:55.064] iteration 24492: loss: 0.063883, loss_s1: 0.065887, loss_fp: 0.000784, loss_freq: 0.027217
[18:55:55.689] iteration 24493: loss: 0.025567, loss_s1: 0.011903, loss_fp: 0.000584, loss_freq: 0.005233
[18:55:56.310] iteration 24494: loss: 0.039101, loss_s1: 0.028305, loss_fp: 0.001124, loss_freq: 0.014724
[18:55:56.941] iteration 24495: loss: 0.061428, loss_s1: 0.053250, loss_fp: 0.001187, loss_freq: 0.004982
[18:55:57.562] iteration 24496: loss: 0.107261, loss_s1: 0.077369, loss_fp: 0.003540, loss_freq: 0.102708
[18:55:58.188] iteration 24497: loss: 0.036562, loss_s1: 0.028926, loss_fp: 0.002396, loss_freq: 0.013737
[18:55:58.806] iteration 24498: loss: 0.036579, loss_s1: 0.023913, loss_fp: 0.003090, loss_freq: 0.024081
[18:55:59.428] iteration 24499: loss: 0.037223, loss_s1: 0.009625, loss_fp: 0.000432, loss_freq: 0.034728
[18:56:00.051] iteration 24500: loss: 0.070573, loss_s1: 0.061652, loss_fp: 0.015143, loss_freq: 0.027482
[18:56:00.673] iteration 24501: loss: 0.072026, loss_s1: 0.050960, loss_fp: 0.005361, loss_freq: 0.050961
[18:56:01.296] iteration 24502: loss: 0.052052, loss_s1: 0.046227, loss_fp: 0.002438, loss_freq: 0.019567
[18:56:01.915] iteration 24503: loss: 0.033895, loss_s1: 0.024132, loss_fp: 0.003384, loss_freq: 0.015709
[18:56:02.567] iteration 24504: loss: 0.060019, loss_s1: 0.052441, loss_fp: 0.002382, loss_freq: 0.023547
[18:56:03.227] iteration 24505: loss: 0.028240, loss_s1: 0.022911, loss_fp: 0.000659, loss_freq: 0.008457
[18:56:03.884] iteration 24506: loss: 0.032464, loss_s1: 0.026596, loss_fp: 0.001096, loss_freq: 0.003675
[18:56:04.499] iteration 24507: loss: 0.042444, loss_s1: 0.028097, loss_fp: 0.003084, loss_freq: 0.013802
[18:56:05.122] iteration 24508: loss: 0.064506, loss_s1: 0.070958, loss_fp: 0.004025, loss_freq: 0.026166
[18:56:05.737] iteration 24509: loss: 0.061688, loss_s1: 0.041380, loss_fp: 0.009653, loss_freq: 0.037587
[18:56:06.363] iteration 24510: loss: 0.059604, loss_s1: 0.049217, loss_fp: 0.006890, loss_freq: 0.027727
[18:56:06.984] iteration 24511: loss: 0.104652, loss_s1: 0.075737, loss_fp: 0.025992, loss_freq: 0.068277
[18:56:07.600] iteration 24512: loss: 0.072197, loss_s1: 0.072511, loss_fp: 0.004055, loss_freq: 0.025800
[18:56:08.218] iteration 24513: loss: 0.047264, loss_s1: 0.027793, loss_fp: 0.002268, loss_freq: 0.011835
[18:56:08.839] iteration 24514: loss: 0.087971, loss_s1: 0.093543, loss_fp: 0.006323, loss_freq: 0.047684
[18:56:09.469] iteration 24515: loss: 0.078428, loss_s1: 0.081078, loss_fp: 0.002495, loss_freq: 0.036424
[18:56:10.095] iteration 24516: loss: 0.060955, loss_s1: 0.035730, loss_fp: 0.005928, loss_freq: 0.042624
[18:56:10.952] iteration 24517: loss: 0.061691, loss_s1: 0.045835, loss_fp: 0.011662, loss_freq: 0.026258
[18:56:11.803] iteration 24518: loss: 0.043234, loss_s1: 0.034131, loss_fp: 0.000539, loss_freq: 0.004682
[18:56:12.431] iteration 24519: loss: 0.040999, loss_s1: 0.024241, loss_fp: 0.000498, loss_freq: 0.028169
[18:56:13.053] iteration 24520: loss: 0.041321, loss_s1: 0.030090, loss_fp: 0.006351, loss_freq: 0.020312
[18:56:13.674] iteration 24521: loss: 0.077458, loss_s1: 0.070041, loss_fp: 0.005242, loss_freq: 0.038462
[18:56:14.295] iteration 24522: loss: 0.043954, loss_s1: 0.033829, loss_fp: 0.002735, loss_freq: 0.022042
[18:56:14.922] iteration 24523: loss: 0.061907, loss_s1: 0.049370, loss_fp: 0.002090, loss_freq: 0.039504
[18:56:15.554] iteration 24524: loss: 0.052480, loss_s1: 0.048918, loss_fp: 0.002469, loss_freq: 0.017733
[18:56:16.185] iteration 24525: loss: 0.044757, loss_s1: 0.022046, loss_fp: 0.005882, loss_freq: 0.022199
[18:56:16.815] iteration 24526: loss: 0.047877, loss_s1: 0.045847, loss_fp: 0.003453, loss_freq: 0.018248
[18:56:17.443] iteration 24527: loss: 0.046414, loss_s1: 0.049890, loss_fp: 0.001000, loss_freq: 0.014126
[18:56:18.061] iteration 24528: loss: 0.082959, loss_s1: 0.078529, loss_fp: 0.010822, loss_freq: 0.031810
[18:56:18.684] iteration 24529: loss: 0.045601, loss_s1: 0.037898, loss_fp: 0.006102, loss_freq: 0.007118
[18:56:19.304] iteration 24530: loss: 0.054187, loss_s1: 0.040329, loss_fp: 0.002096, loss_freq: 0.012686
[18:56:19.930] iteration 24531: loss: 0.051829, loss_s1: 0.055219, loss_fp: 0.004243, loss_freq: 0.013196
[18:56:20.558] iteration 24532: loss: 0.052200, loss_s1: 0.044105, loss_fp: 0.006280, loss_freq: 0.023419
[18:56:21.184] iteration 24533: loss: 0.059138, loss_s1: 0.058641, loss_fp: 0.003616, loss_freq: 0.032796
[18:56:21.813] iteration 24534: loss: 0.053210, loss_s1: 0.063108, loss_fp: 0.002178, loss_freq: 0.011781
[18:56:22.437] iteration 24535: loss: 0.033616, loss_s1: 0.013488, loss_fp: 0.001264, loss_freq: 0.009807
[18:56:23.060] iteration 24536: loss: 0.041408, loss_s1: 0.031073, loss_fp: 0.004679, loss_freq: 0.011499
[18:56:23.696] iteration 24537: loss: 0.068328, loss_s1: 0.061562, loss_fp: 0.003395, loss_freq: 0.039002
[18:56:24.316] iteration 24538: loss: 0.094796, loss_s1: 0.073180, loss_fp: 0.004744, loss_freq: 0.081701
[18:56:24.939] iteration 24539: loss: 0.055935, loss_s1: 0.026793, loss_fp: 0.000889, loss_freq: 0.048361
[18:56:25.563] iteration 24540: loss: 0.064796, loss_s1: 0.058367, loss_fp: 0.005244, loss_freq: 0.033769
[18:56:26.186] iteration 24541: loss: 0.048006, loss_s1: 0.032164, loss_fp: 0.005372, loss_freq: 0.014609
[18:56:26.804] iteration 24542: loss: 0.057175, loss_s1: 0.025224, loss_fp: 0.006091, loss_freq: 0.042843
[18:56:27.427] iteration 24543: loss: 0.066864, loss_s1: 0.060349, loss_fp: 0.005645, loss_freq: 0.039905
[18:56:28.044] iteration 24544: loss: 0.042369, loss_s1: 0.026469, loss_fp: 0.001439, loss_freq: 0.023547
[18:56:28.667] iteration 24545: loss: 0.048323, loss_s1: 0.011074, loss_fp: 0.003915, loss_freq: 0.031259
[18:56:29.288] iteration 24546: loss: 0.049463, loss_s1: 0.032652, loss_fp: 0.006792, loss_freq: 0.022988
[18:56:29.918] iteration 24547: loss: 0.046735, loss_s1: 0.039324, loss_fp: 0.004530, loss_freq: 0.018116
[18:56:30.542] iteration 24548: loss: 0.044825, loss_s1: 0.026930, loss_fp: 0.006545, loss_freq: 0.007023
[18:56:31.169] iteration 24549: loss: 0.055219, loss_s1: 0.056998, loss_fp: 0.003107, loss_freq: 0.019655
[18:56:31.791] iteration 24550: loss: 0.046835, loss_s1: 0.049744, loss_fp: 0.004651, loss_freq: 0.012172
[18:56:32.423] iteration 24551: loss: 0.035344, loss_s1: 0.036128, loss_fp: 0.001577, loss_freq: 0.004719
[18:56:33.055] iteration 24552: loss: 0.099426, loss_s1: 0.102145, loss_fp: 0.002904, loss_freq: 0.055098
[18:56:33.679] iteration 24553: loss: 0.074573, loss_s1: 0.059486, loss_fp: 0.002864, loss_freq: 0.048215
[18:56:34.316] iteration 24554: loss: 0.059674, loss_s1: 0.057419, loss_fp: 0.002313, loss_freq: 0.028861
[18:56:34.945] iteration 24555: loss: 0.089073, loss_s1: 0.045530, loss_fp: 0.012327, loss_freq: 0.088837
[18:56:35.573] iteration 24556: loss: 0.058516, loss_s1: 0.050719, loss_fp: 0.002850, loss_freq: 0.026570
[18:56:36.203] iteration 24557: loss: 0.059436, loss_s1: 0.060543, loss_fp: 0.004041, loss_freq: 0.020506
[18:56:36.828] iteration 24558: loss: 0.038843, loss_s1: 0.023363, loss_fp: 0.007340, loss_freq: 0.017838
[18:56:37.461] iteration 24559: loss: 0.039765, loss_s1: 0.024215, loss_fp: 0.002565, loss_freq: 0.013181
[18:56:38.083] iteration 24560: loss: 0.045611, loss_s1: 0.040624, loss_fp: 0.003100, loss_freq: 0.013281
[18:56:38.711] iteration 24561: loss: 0.059219, loss_s1: 0.067448, loss_fp: 0.005944, loss_freq: 0.008377
[18:56:39.334] iteration 24562: loss: 0.063932, loss_s1: 0.056279, loss_fp: 0.009506, loss_freq: 0.034148
[18:56:39.955] iteration 24563: loss: 0.060704, loss_s1: 0.052945, loss_fp: 0.004649, loss_freq: 0.021661
[18:56:40.577] iteration 24564: loss: 0.059414, loss_s1: 0.047120, loss_fp: 0.001777, loss_freq: 0.037341
[18:56:41.203] iteration 24565: loss: 0.084375, loss_s1: 0.034506, loss_fp: 0.008825, loss_freq: 0.037930
[18:56:41.825] iteration 24566: loss: 0.053099, loss_s1: 0.048703, loss_fp: 0.010986, loss_freq: 0.018863
[18:56:42.447] iteration 24567: loss: 0.034684, loss_s1: 0.018542, loss_fp: 0.007539, loss_freq: 0.014625
[18:56:43.069] iteration 24568: loss: 0.057935, loss_s1: 0.029251, loss_fp: 0.009931, loss_freq: 0.049266
[18:56:43.699] iteration 24569: loss: 0.039186, loss_s1: 0.021609, loss_fp: 0.001764, loss_freq: 0.021171
[18:56:44.322] iteration 24570: loss: 0.048968, loss_s1: 0.014989, loss_fp: 0.001029, loss_freq: 0.045667
[18:56:44.958] iteration 24571: loss: 0.038675, loss_s1: 0.019582, loss_fp: 0.002718, loss_freq: 0.026371
[18:56:45.577] iteration 24572: loss: 0.052247, loss_s1: 0.048326, loss_fp: 0.002105, loss_freq: 0.013221
[18:56:46.206] iteration 24573: loss: 0.068916, loss_s1: 0.080615, loss_fp: 0.000943, loss_freq: 0.026383
[18:56:46.826] iteration 24574: loss: 0.070845, loss_s1: 0.037484, loss_fp: 0.006331, loss_freq: 0.064344
[18:56:47.452] iteration 24575: loss: 0.089965, loss_s1: 0.085392, loss_fp: 0.007263, loss_freq: 0.056818
[18:56:48.083] iteration 24576: loss: 0.046314, loss_s1: 0.045861, loss_fp: 0.004664, loss_freq: 0.012895
[18:56:48.704] iteration 24577: loss: 0.050748, loss_s1: 0.017576, loss_fp: 0.001670, loss_freq: 0.015951
[18:56:49.335] iteration 24578: loss: 0.039061, loss_s1: 0.022710, loss_fp: 0.001374, loss_freq: 0.020478
[18:56:49.959] iteration 24579: loss: 0.038823, loss_s1: 0.037750, loss_fp: 0.001311, loss_freq: 0.007045
[18:56:50.587] iteration 24580: loss: 0.090726, loss_s1: 0.105205, loss_fp: 0.004053, loss_freq: 0.038887
[18:56:51.213] iteration 24581: loss: 0.116086, loss_s1: 0.120845, loss_fp: 0.019826, loss_freq: 0.053504
[18:56:51.832] iteration 24582: loss: 0.067146, loss_s1: 0.064278, loss_fp: 0.001376, loss_freq: 0.039332
[18:56:52.449] iteration 24583: loss: 0.032466, loss_s1: 0.008240, loss_fp: 0.002389, loss_freq: 0.015573
[18:56:53.076] iteration 24584: loss: 0.064921, loss_s1: 0.034830, loss_fp: 0.016470, loss_freq: 0.040717
[18:56:53.703] iteration 24585: loss: 0.077559, loss_s1: 0.089051, loss_fp: 0.006641, loss_freq: 0.031143
[18:56:54.332] iteration 24586: loss: 0.077331, loss_s1: 0.092680, loss_fp: 0.001980, loss_freq: 0.023227
[18:56:54.960] iteration 24587: loss: 0.024681, loss_s1: 0.008337, loss_fp: 0.001034, loss_freq: 0.004957
[18:56:55.586] iteration 24588: loss: 0.033581, loss_s1: 0.023742, loss_fp: 0.003821, loss_freq: 0.009091
[18:56:56.212] iteration 24589: loss: 0.060081, loss_s1: 0.031809, loss_fp: 0.004414, loss_freq: 0.054184
[18:56:56.832] iteration 24590: loss: 0.035678, loss_s1: 0.013938, loss_fp: 0.003916, loss_freq: 0.015635
[18:56:57.456] iteration 24591: loss: 0.040760, loss_s1: 0.020923, loss_fp: 0.001881, loss_freq: 0.025433
[18:56:58.084] iteration 24592: loss: 0.056403, loss_s1: 0.022875, loss_fp: 0.008187, loss_freq: 0.050565
[18:56:58.709] iteration 24593: loss: 0.065117, loss_s1: 0.055707, loss_fp: 0.002027, loss_freq: 0.034509
[18:56:59.334] iteration 24594: loss: 0.044765, loss_s1: 0.034956, loss_fp: 0.004266, loss_freq: 0.007982
[18:56:59.958] iteration 24595: loss: 0.062083, loss_s1: 0.077949, loss_fp: 0.004643, loss_freq: 0.011129
[18:57:00.576] iteration 24596: loss: 0.038295, loss_s1: 0.032852, loss_fp: 0.006739, loss_freq: 0.005123
[18:57:01.204] iteration 24597: loss: 0.053743, loss_s1: 0.028164, loss_fp: 0.004339, loss_freq: 0.034066
[18:57:01.830] iteration 24598: loss: 0.051088, loss_s1: 0.025692, loss_fp: 0.003004, loss_freq: 0.026997
[18:57:02.452] iteration 24599: loss: 0.034759, loss_s1: 0.027628, loss_fp: 0.000820, loss_freq: 0.006973
[18:57:03.070] iteration 24600: loss: 0.061217, loss_s1: 0.033494, loss_fp: 0.002922, loss_freq: 0.030817
[18:57:06.209] iteration 24600 : mean_dice : 0.735102
[18:57:06.866] iteration 24601: loss: 0.052724, loss_s1: 0.037838, loss_fp: 0.004836, loss_freq: 0.018780
[18:57:07.494] iteration 24602: loss: 0.046911, loss_s1: 0.045323, loss_fp: 0.001042, loss_freq: 0.017944
[18:57:08.121] iteration 24603: loss: 0.091474, loss_s1: 0.045612, loss_fp: 0.005793, loss_freq: 0.089515
[18:57:08.747] iteration 24604: loss: 0.075567, loss_s1: 0.070174, loss_fp: 0.005453, loss_freq: 0.043797
[18:57:09.365] iteration 24605: loss: 0.038175, loss_s1: 0.026939, loss_fp: 0.001376, loss_freq: 0.015731
[18:57:09.988] iteration 24606: loss: 0.038259, loss_s1: 0.029252, loss_fp: 0.006492, loss_freq: 0.006377
[18:57:10.613] iteration 24607: loss: 0.044172, loss_s1: 0.030438, loss_fp: 0.002068, loss_freq: 0.025070
[18:57:11.230] iteration 24608: loss: 0.044283, loss_s1: 0.036367, loss_fp: 0.001223, loss_freq: 0.022667
[18:57:11.850] iteration 24609: loss: 0.027840, loss_s1: 0.010285, loss_fp: 0.000330, loss_freq: 0.009283
[18:57:12.476] iteration 24610: loss: 0.032113, loss_s1: 0.017325, loss_fp: 0.001862, loss_freq: 0.014841
[18:57:13.101] iteration 24611: loss: 0.033289, loss_s1: 0.016883, loss_fp: 0.001500, loss_freq: 0.017808
[18:57:13.725] iteration 24612: loss: 0.081468, loss_s1: 0.054826, loss_fp: 0.003003, loss_freq: 0.038334
[18:57:14.351] iteration 24613: loss: 0.051183, loss_s1: 0.020294, loss_fp: 0.007804, loss_freq: 0.035737
[18:57:14.972] iteration 24614: loss: 0.032811, loss_s1: 0.019173, loss_fp: 0.001628, loss_freq: 0.010651
[18:57:15.599] iteration 24615: loss: 0.034346, loss_s1: 0.025829, loss_fp: 0.003483, loss_freq: 0.013681
[18:57:16.226] iteration 24616: loss: 0.045480, loss_s1: 0.036260, loss_fp: 0.001975, loss_freq: 0.012156
[18:57:16.846] iteration 24617: loss: 0.044623, loss_s1: 0.019659, loss_fp: 0.004387, loss_freq: 0.023525
[18:57:17.468] iteration 24618: loss: 0.083509, loss_s1: 0.056108, loss_fp: 0.005924, loss_freq: 0.023345
[18:57:18.098] iteration 24619: loss: 0.077860, loss_s1: 0.055758, loss_fp: 0.004132, loss_freq: 0.069655
[18:57:18.727] iteration 24620: loss: 0.037732, loss_s1: 0.035083, loss_fp: 0.002191, loss_freq: 0.012107
[18:57:19.349] iteration 24621: loss: 0.030606, loss_s1: 0.017633, loss_fp: 0.002323, loss_freq: 0.017089
[18:57:19.975] iteration 24622: loss: 0.054204, loss_s1: 0.041358, loss_fp: 0.001186, loss_freq: 0.035360
[18:57:20.604] iteration 24623: loss: 0.054687, loss_s1: 0.027621, loss_fp: 0.003549, loss_freq: 0.047408
[18:57:21.224] iteration 24624: loss: 0.056839, loss_s1: 0.049240, loss_fp: 0.008280, loss_freq: 0.032506
[18:57:21.849] iteration 24625: loss: 0.040329, loss_s1: 0.031602, loss_fp: 0.004698, loss_freq: 0.018530
[18:57:22.473] iteration 24626: loss: 0.050075, loss_s1: 0.032629, loss_fp: 0.002786, loss_freq: 0.030410
[18:57:23.097] iteration 24627: loss: 0.021131, loss_s1: 0.010421, loss_fp: 0.000644, loss_freq: 0.004492
[18:57:23.718] iteration 24628: loss: 0.056684, loss_s1: 0.061161, loss_fp: 0.000634, loss_freq: 0.012539
[18:57:24.348] iteration 24629: loss: 0.035047, loss_s1: 0.004805, loss_fp: 0.005771, loss_freq: 0.014198
[18:57:24.975] iteration 24630: loss: 0.062785, loss_s1: 0.049764, loss_fp: 0.001598, loss_freq: 0.021492
[18:57:25.598] iteration 24631: loss: 0.042798, loss_s1: 0.032149, loss_fp: 0.005285, loss_freq: 0.012260
[18:57:26.222] iteration 24632: loss: 0.052832, loss_s1: 0.044149, loss_fp: 0.006166, loss_freq: 0.018602
[18:57:26.841] iteration 24633: loss: 0.042448, loss_s1: 0.038583, loss_fp: 0.001018, loss_freq: 0.009809
[18:57:27.820] iteration 24634: loss: 0.043467, loss_s1: 0.038319, loss_fp: 0.002332, loss_freq: 0.014832
[18:57:28.476] iteration 24635: loss: 0.054420, loss_s1: 0.034624, loss_fp: 0.008994, loss_freq: 0.023526
[18:57:29.136] iteration 24636: loss: 0.039095, loss_s1: 0.021284, loss_fp: 0.002946, loss_freq: 0.009615
[18:57:29.774] iteration 24637: loss: 0.038201, loss_s1: 0.015832, loss_fp: 0.001265, loss_freq: 0.006317
[18:57:30.401] iteration 24638: loss: 0.052203, loss_s1: 0.035408, loss_fp: 0.006576, loss_freq: 0.022111
[18:57:31.062] iteration 24639: loss: 0.056820, loss_s1: 0.044804, loss_fp: 0.007980, loss_freq: 0.011796
[18:57:31.678] iteration 24640: loss: 0.050280, loss_s1: 0.050867, loss_fp: 0.003621, loss_freq: 0.016843
[18:57:32.338] iteration 24641: loss: 0.028368, loss_s1: 0.010349, loss_fp: 0.001591, loss_freq: 0.017863
[18:57:32.993] iteration 24642: loss: 0.051594, loss_s1: 0.036668, loss_fp: 0.002153, loss_freq: 0.040588
[18:57:33.650] iteration 24643: loss: 0.071637, loss_s1: 0.079349, loss_fp: 0.007553, loss_freq: 0.019592
[18:57:34.302] iteration 24644: loss: 0.054767, loss_s1: 0.017688, loss_fp: 0.003546, loss_freq: 0.031242
[18:57:34.962] iteration 24645: loss: 0.040900, loss_s1: 0.023496, loss_fp: 0.000582, loss_freq: 0.029129
[18:57:35.625] iteration 24646: loss: 0.089538, loss_s1: 0.056520, loss_fp: 0.018400, loss_freq: 0.077180
[18:57:36.289] iteration 24647: loss: 0.060042, loss_s1: 0.057439, loss_fp: 0.003940, loss_freq: 0.024537
[18:57:36.951] iteration 24648: loss: 0.058584, loss_s1: 0.065822, loss_fp: 0.007649, loss_freq: 0.015725
[18:57:37.614] iteration 24649: loss: 0.073279, loss_s1: 0.059123, loss_fp: 0.005313, loss_freq: 0.050509
[18:57:38.276] iteration 24650: loss: 0.040194, loss_s1: 0.027646, loss_fp: 0.003699, loss_freq: 0.014741
[18:57:38.939] iteration 24651: loss: 0.060549, loss_s1: 0.049078, loss_fp: 0.004621, loss_freq: 0.037511
[18:57:39.572] iteration 24652: loss: 0.039888, loss_s1: 0.016488, loss_fp: 0.001129, loss_freq: 0.033324
[18:57:40.200] iteration 24653: loss: 0.080980, loss_s1: 0.028321, loss_fp: 0.005445, loss_freq: 0.047521
[18:57:40.827] iteration 24654: loss: 0.038690, loss_s1: 0.031607, loss_fp: 0.000438, loss_freq: 0.010983
[18:57:41.455] iteration 24655: loss: 0.045665, loss_s1: 0.023076, loss_fp: 0.007565, loss_freq: 0.019588
[18:57:42.083] iteration 24656: loss: 0.041949, loss_s1: 0.025212, loss_fp: 0.003790, loss_freq: 0.008618
[18:57:42.703] iteration 24657: loss: 0.087173, loss_s1: 0.081890, loss_fp: 0.005789, loss_freq: 0.061558
[18:57:43.332] iteration 24658: loss: 0.049604, loss_s1: 0.043635, loss_fp: 0.001029, loss_freq: 0.016547
[18:57:43.959] iteration 24659: loss: 0.041069, loss_s1: 0.031031, loss_fp: 0.001851, loss_freq: 0.018348
[18:57:44.581] iteration 24660: loss: 0.032866, loss_s1: 0.030433, loss_fp: 0.000488, loss_freq: 0.002819
[18:57:45.205] iteration 24661: loss: 0.083243, loss_s1: 0.061433, loss_fp: 0.018559, loss_freq: 0.037792
[18:57:45.832] iteration 24662: loss: 0.064312, loss_s1: 0.041964, loss_fp: 0.004232, loss_freq: 0.051157
[18:57:46.478] iteration 24663: loss: 0.044807, loss_s1: 0.036519, loss_fp: 0.000652, loss_freq: 0.014753
[18:57:47.114] iteration 24664: loss: 0.041280, loss_s1: 0.030258, loss_fp: 0.007045, loss_freq: 0.016955
[18:57:47.736] iteration 24665: loss: 0.043080, loss_s1: 0.031899, loss_fp: 0.003210, loss_freq: 0.013943
[18:57:48.356] iteration 24666: loss: 0.063956, loss_s1: 0.054811, loss_fp: 0.002379, loss_freq: 0.033850
[18:57:49.010] iteration 24667: loss: 0.030927, loss_s1: 0.027217, loss_fp: 0.001162, loss_freq: 0.009366
[18:57:49.658] iteration 24668: loss: 0.082811, loss_s1: 0.088976, loss_fp: 0.009505, loss_freq: 0.023426
[18:57:50.299] iteration 24669: loss: 0.063614, loss_s1: 0.058889, loss_fp: 0.005803, loss_freq: 0.030165
[18:57:50.944] iteration 24670: loss: 0.058549, loss_s1: 0.061144, loss_fp: 0.002491, loss_freq: 0.021604
[18:57:51.580] iteration 24671: loss: 0.049246, loss_s1: 0.037286, loss_fp: 0.002652, loss_freq: 0.023518
[18:57:52.213] iteration 24672: loss: 0.076873, loss_s1: 0.072464, loss_fp: 0.007830, loss_freq: 0.029819
[18:57:52.846] iteration 24673: loss: 0.049574, loss_s1: 0.047984, loss_fp: 0.001419, loss_freq: 0.018515
[18:57:53.494] iteration 24674: loss: 0.055466, loss_s1: 0.056128, loss_fp: 0.000934, loss_freq: 0.019494
[18:57:54.136] iteration 24675: loss: 0.055987, loss_s1: 0.053277, loss_fp: 0.004842, loss_freq: 0.027217
[18:57:54.779] iteration 24676: loss: 0.063243, loss_s1: 0.068038, loss_fp: 0.008200, loss_freq: 0.024450
[18:57:55.413] iteration 24677: loss: 0.053235, loss_s1: 0.044333, loss_fp: 0.000712, loss_freq: 0.038457
[18:57:56.045] iteration 24678: loss: 0.054994, loss_s1: 0.036028, loss_fp: 0.003720, loss_freq: 0.025136
[18:57:56.676] iteration 24679: loss: 0.039897, loss_s1: 0.027370, loss_fp: 0.000613, loss_freq: 0.008644
[18:57:57.308] iteration 24680: loss: 0.025556, loss_s1: 0.006612, loss_fp: 0.001467, loss_freq: 0.003768
[18:57:57.959] iteration 24681: loss: 0.045635, loss_s1: 0.028576, loss_fp: 0.011776, loss_freq: 0.015878
[18:57:58.595] iteration 24682: loss: 0.065282, loss_s1: 0.062742, loss_fp: 0.003861, loss_freq: 0.028494
[18:57:59.234] iteration 24683: loss: 0.033016, loss_s1: 0.021859, loss_fp: 0.001324, loss_freq: 0.012833
[18:57:59.881] iteration 24684: loss: 0.070788, loss_s1: 0.085518, loss_fp: 0.001984, loss_freq: 0.022693
[18:58:00.536] iteration 24685: loss: 0.055759, loss_s1: 0.035494, loss_fp: 0.003891, loss_freq: 0.039494
[18:58:01.168] iteration 24686: loss: 0.039826, loss_s1: 0.029780, loss_fp: 0.005134, loss_freq: 0.011314
[18:58:01.796] iteration 24687: loss: 0.052501, loss_s1: 0.037084, loss_fp: 0.001589, loss_freq: 0.032285
[18:58:02.420] iteration 24688: loss: 0.044796, loss_s1: 0.034551, loss_fp: 0.002209, loss_freq: 0.013304
[18:58:03.049] iteration 24689: loss: 0.036558, loss_s1: 0.020626, loss_fp: 0.003021, loss_freq: 0.017109
[18:58:03.674] iteration 24690: loss: 0.035410, loss_s1: 0.014164, loss_fp: 0.003255, loss_freq: 0.017564
[18:58:04.304] iteration 24691: loss: 0.039023, loss_s1: 0.020972, loss_fp: 0.003070, loss_freq: 0.017528
[18:58:04.930] iteration 24692: loss: 0.040068, loss_s1: 0.032216, loss_fp: 0.001857, loss_freq: 0.012898
[18:58:05.557] iteration 24693: loss: 0.042576, loss_s1: 0.030452, loss_fp: 0.003819, loss_freq: 0.026231
[18:58:06.186] iteration 24694: loss: 0.040843, loss_s1: 0.019025, loss_fp: 0.009435, loss_freq: 0.016567
[18:58:06.814] iteration 24695: loss: 0.061433, loss_s1: 0.070014, loss_fp: 0.002079, loss_freq: 0.021139
[18:58:07.439] iteration 24696: loss: 0.048349, loss_s1: 0.039803, loss_fp: 0.002507, loss_freq: 0.006585
[18:58:08.066] iteration 24697: loss: 0.040496, loss_s1: 0.033830, loss_fp: 0.004959, loss_freq: 0.008239
[18:58:08.705] iteration 24698: loss: 0.064462, loss_s1: 0.077436, loss_fp: 0.002560, loss_freq: 0.020221
[18:58:09.332] iteration 24699: loss: 0.054264, loss_s1: 0.049811, loss_fp: 0.001879, loss_freq: 0.030322
[18:58:09.964] iteration 24700: loss: 0.055153, loss_s1: 0.040429, loss_fp: 0.011905, loss_freq: 0.025163
[18:58:10.588] iteration 24701: loss: 0.059134, loss_s1: 0.046162, loss_fp: 0.013355, loss_freq: 0.035330
[18:58:11.219] iteration 24702: loss: 0.085469, loss_s1: 0.077410, loss_fp: 0.010640, loss_freq: 0.051047
[18:58:11.847] iteration 24703: loss: 0.050103, loss_s1: 0.017446, loss_fp: 0.003329, loss_freq: 0.028707
[18:58:12.479] iteration 24704: loss: 0.061792, loss_s1: 0.033758, loss_fp: 0.005818, loss_freq: 0.043405
[18:58:13.102] iteration 24705: loss: 0.041777, loss_s1: 0.033438, loss_fp: 0.000225, loss_freq: 0.020258
[18:58:13.730] iteration 24706: loss: 0.068700, loss_s1: 0.033257, loss_fp: 0.025892, loss_freq: 0.048956
[18:58:14.362] iteration 24707: loss: 0.041503, loss_s1: 0.028711, loss_fp: 0.001841, loss_freq: 0.014102
[18:58:14.997] iteration 24708: loss: 0.073176, loss_s1: 0.067192, loss_fp: 0.014668, loss_freq: 0.026332
[18:58:15.630] iteration 24709: loss: 0.052559, loss_s1: 0.051229, loss_fp: 0.000532, loss_freq: 0.011050
[18:58:16.381] iteration 24710: loss: 0.051206, loss_s1: 0.038090, loss_fp: 0.002550, loss_freq: 0.021597
[18:58:17.056] iteration 24711: loss: 0.028854, loss_s1: 0.018168, loss_fp: 0.002201, loss_freq: 0.006674
[18:58:17.705] iteration 24712: loss: 0.025617, loss_s1: 0.014257, loss_fp: 0.001760, loss_freq: 0.011115
[18:58:18.352] iteration 24713: loss: 0.064002, loss_s1: 0.054584, loss_fp: 0.006385, loss_freq: 0.028295
[18:58:18.984] iteration 24714: loss: 0.058945, loss_s1: 0.053370, loss_fp: 0.001632, loss_freq: 0.033073
[18:58:19.619] iteration 24715: loss: 0.060950, loss_s1: 0.062491, loss_fp: 0.004147, loss_freq: 0.024792
[18:58:20.248] iteration 24716: loss: 0.046894, loss_s1: 0.029539, loss_fp: 0.020187, loss_freq: 0.014778
[18:58:20.872] iteration 24717: loss: 0.053948, loss_s1: 0.047676, loss_fp: 0.006215, loss_freq: 0.018833
[18:58:21.508] iteration 24718: loss: 0.051006, loss_s1: 0.037628, loss_fp: 0.005601, loss_freq: 0.034682
[18:58:22.141] iteration 24719: loss: 0.054716, loss_s1: 0.057902, loss_fp: 0.002782, loss_freq: 0.014932
[18:58:22.771] iteration 24720: loss: 0.051769, loss_s1: 0.052661, loss_fp: 0.001070, loss_freq: 0.006191
[18:58:23.413] iteration 24721: loss: 0.062227, loss_s1: 0.078000, loss_fp: 0.002171, loss_freq: 0.011898
[18:58:24.040] iteration 24722: loss: 0.055065, loss_s1: 0.023639, loss_fp: 0.005771, loss_freq: 0.018266
[18:58:24.667] iteration 24723: loss: 0.048373, loss_s1: 0.033543, loss_fp: 0.002726, loss_freq: 0.021792
[18:58:25.298] iteration 24724: loss: 0.053251, loss_s1: 0.026881, loss_fp: 0.019269, loss_freq: 0.016046
[18:58:25.925] iteration 24725: loss: 0.054138, loss_s1: 0.039528, loss_fp: 0.007705, loss_freq: 0.018578
[18:58:26.550] iteration 24726: loss: 0.051235, loss_s1: 0.020520, loss_fp: 0.001661, loss_freq: 0.014865
[18:58:27.186] iteration 24727: loss: 0.043982, loss_s1: 0.030675, loss_fp: 0.004927, loss_freq: 0.006063
[18:58:27.817] iteration 24728: loss: 0.124842, loss_s1: 0.162273, loss_fp: 0.001891, loss_freq: 0.053808
[18:58:28.480] iteration 24729: loss: 0.063595, loss_s1: 0.047973, loss_fp: 0.002271, loss_freq: 0.046749
[18:58:29.117] iteration 24730: loss: 0.036998, loss_s1: 0.022689, loss_fp: 0.000479, loss_freq: 0.014721
[18:58:29.764] iteration 24731: loss: 0.039639, loss_s1: 0.019792, loss_fp: 0.001745, loss_freq: 0.019095
[18:58:30.410] iteration 24732: loss: 0.031570, loss_s1: 0.014971, loss_fp: 0.002685, loss_freq: 0.006328
[18:58:31.037] iteration 24733: loss: 0.043947, loss_s1: 0.031404, loss_fp: 0.006110, loss_freq: 0.018266
[18:58:31.669] iteration 24734: loss: 0.037446, loss_s1: 0.023440, loss_fp: 0.002973, loss_freq: 0.019753
[18:58:32.297] iteration 24735: loss: 0.080056, loss_s1: 0.052015, loss_fp: 0.002599, loss_freq: 0.052803
[18:58:32.927] iteration 24736: loss: 0.060782, loss_s1: 0.019662, loss_fp: 0.005088, loss_freq: 0.070823
[18:58:33.552] iteration 24737: loss: 0.058368, loss_s1: 0.018890, loss_fp: 0.002231, loss_freq: 0.027101
[18:58:34.184] iteration 24738: loss: 0.040751, loss_s1: 0.023255, loss_fp: 0.001850, loss_freq: 0.009438
[18:58:34.814] iteration 24739: loss: 0.043397, loss_s1: 0.027464, loss_fp: 0.001356, loss_freq: 0.024059
[18:58:35.448] iteration 24740: loss: 0.040487, loss_s1: 0.015578, loss_fp: 0.004934, loss_freq: 0.026191
[18:58:36.113] iteration 24741: loss: 0.057144, loss_s1: 0.068418, loss_fp: 0.002202, loss_freq: 0.009957
[18:58:36.738] iteration 24742: loss: 0.106068, loss_s1: 0.075245, loss_fp: 0.006424, loss_freq: 0.090838
[18:58:37.367] iteration 24743: loss: 0.057783, loss_s1: 0.044157, loss_fp: 0.004472, loss_freq: 0.034211
[18:58:37.996] iteration 24744: loss: 0.048343, loss_s1: 0.040404, loss_fp: 0.001500, loss_freq: 0.010818
[18:58:38.625] iteration 24745: loss: 0.046294, loss_s1: 0.025159, loss_fp: 0.003921, loss_freq: 0.031663
[18:58:39.249] iteration 24746: loss: 0.099741, loss_s1: 0.140482, loss_fp: 0.001982, loss_freq: 0.028711
[18:58:39.879] iteration 24747: loss: 0.054355, loss_s1: 0.047164, loss_fp: 0.001621, loss_freq: 0.020484
[18:58:40.504] iteration 24748: loss: 0.034649, loss_s1: 0.018859, loss_fp: 0.003241, loss_freq: 0.007279
[18:58:41.132] iteration 24749: loss: 0.056066, loss_s1: 0.052080, loss_fp: 0.004097, loss_freq: 0.014832
[18:58:41.758] iteration 24750: loss: 0.045995, loss_s1: 0.013349, loss_fp: 0.000981, loss_freq: 0.043268
[18:58:42.389] iteration 24751: loss: 0.028085, loss_s1: 0.019955, loss_fp: 0.001823, loss_freq: 0.005386
[18:58:43.016] iteration 24752: loss: 0.051736, loss_s1: 0.006850, loss_fp: 0.002196, loss_freq: 0.024787
[18:58:43.637] iteration 24753: loss: 0.060676, loss_s1: 0.042997, loss_fp: 0.004125, loss_freq: 0.046781
[18:58:44.263] iteration 24754: loss: 0.046511, loss_s1: 0.020571, loss_fp: 0.002016, loss_freq: 0.036980
[18:58:44.887] iteration 24755: loss: 0.063367, loss_s1: 0.037007, loss_fp: 0.015805, loss_freq: 0.025769
[18:58:45.536] iteration 24756: loss: 0.064884, loss_s1: 0.064333, loss_fp: 0.001152, loss_freq: 0.033832
[18:58:46.168] iteration 24757: loss: 0.031569, loss_s1: 0.021987, loss_fp: 0.000573, loss_freq: 0.008737
[18:58:46.797] iteration 24758: loss: 0.037588, loss_s1: 0.013069, loss_fp: 0.002874, loss_freq: 0.020794
[18:58:47.424] iteration 24759: loss: 0.065839, loss_s1: 0.042466, loss_fp: 0.004043, loss_freq: 0.037769
[18:58:48.054] iteration 24760: loss: 0.040844, loss_s1: 0.036218, loss_fp: 0.003141, loss_freq: 0.004715
[18:58:48.687] iteration 24761: loss: 0.111892, loss_s1: 0.083147, loss_fp: 0.010205, loss_freq: 0.091419
[18:58:49.322] iteration 24762: loss: 0.050571, loss_s1: 0.037282, loss_fp: 0.005474, loss_freq: 0.027155
[18:58:49.943] iteration 24763: loss: 0.029967, loss_s1: 0.016303, loss_fp: 0.002413, loss_freq: 0.011122
[18:58:50.567] iteration 24764: loss: 0.047776, loss_s1: 0.028449, loss_fp: 0.005981, loss_freq: 0.034357
[18:58:51.197] iteration 24765: loss: 0.073766, loss_s1: 0.088415, loss_fp: 0.000810, loss_freq: 0.017781
[18:58:51.831] iteration 24766: loss: 0.079641, loss_s1: 0.068748, loss_fp: 0.001259, loss_freq: 0.025705
[18:58:52.470] iteration 24767: loss: 0.037444, loss_s1: 0.031072, loss_fp: 0.000552, loss_freq: 0.011763
[18:58:53.123] iteration 24768: loss: 0.057749, loss_s1: 0.038185, loss_fp: 0.001033, loss_freq: 0.044293
[18:58:53.768] iteration 24769: loss: 0.068902, loss_s1: 0.082493, loss_fp: 0.003252, loss_freq: 0.025635
[18:58:54.417] iteration 24770: loss: 0.031341, loss_s1: 0.013695, loss_fp: 0.000777, loss_freq: 0.008938
[18:58:55.052] iteration 24771: loss: 0.062774, loss_s1: 0.045337, loss_fp: 0.001894, loss_freq: 0.046688
[18:58:55.684] iteration 24772: loss: 0.047985, loss_s1: 0.037794, loss_fp: 0.001850, loss_freq: 0.019191
[18:58:56.311] iteration 24773: loss: 0.053149, loss_s1: 0.046505, loss_fp: 0.003075, loss_freq: 0.017196
[18:58:56.941] iteration 24774: loss: 0.092191, loss_s1: 0.098517, loss_fp: 0.006947, loss_freq: 0.049013
[18:58:57.570] iteration 24775: loss: 0.043467, loss_s1: 0.024864, loss_fp: 0.002298, loss_freq: 0.016549
[18:58:58.200] iteration 24776: loss: 0.053100, loss_s1: 0.023276, loss_fp: 0.002581, loss_freq: 0.038074
[18:58:58.831] iteration 24777: loss: 0.051182, loss_s1: 0.030698, loss_fp: 0.008359, loss_freq: 0.022672
[18:58:59.461] iteration 24778: loss: 0.053310, loss_s1: 0.028412, loss_fp: 0.004430, loss_freq: 0.043334
[18:59:00.086] iteration 24779: loss: 0.036935, loss_s1: 0.019455, loss_fp: 0.006530, loss_freq: 0.009583
[18:59:00.713] iteration 24780: loss: 0.081764, loss_s1: 0.058719, loss_fp: 0.014289, loss_freq: 0.059169
[18:59:01.344] iteration 24781: loss: 0.051586, loss_s1: 0.062104, loss_fp: 0.000852, loss_freq: 0.012586
[18:59:01.969] iteration 24782: loss: 0.036946, loss_s1: 0.026883, loss_fp: 0.002543, loss_freq: 0.010676
[18:59:02.592] iteration 24783: loss: 0.072128, loss_s1: 0.057814, loss_fp: 0.003602, loss_freq: 0.048262
[18:59:03.226] iteration 24784: loss: 0.052447, loss_s1: 0.043129, loss_fp: 0.009532, loss_freq: 0.015688
[18:59:03.854] iteration 24785: loss: 0.070034, loss_s1: 0.049230, loss_fp: 0.009295, loss_freq: 0.041779
[18:59:04.491] iteration 24786: loss: 0.052714, loss_s1: 0.035596, loss_fp: 0.008224, loss_freq: 0.032328
[18:59:05.120] iteration 24787: loss: 0.048224, loss_s1: 0.032548, loss_fp: 0.003365, loss_freq: 0.024216
[18:59:05.755] iteration 24788: loss: 0.021946, loss_s1: 0.007364, loss_fp: 0.000569, loss_freq: 0.009012
[18:59:06.384] iteration 24789: loss: 0.033011, loss_s1: 0.017775, loss_fp: 0.003340, loss_freq: 0.009050
[18:59:07.016] iteration 24790: loss: 0.047022, loss_s1: 0.038112, loss_fp: 0.000667, loss_freq: 0.010687
[18:59:07.643] iteration 24791: loss: 0.056168, loss_s1: 0.043003, loss_fp: 0.003829, loss_freq: 0.033001
[18:59:08.275] iteration 24792: loss: 0.053342, loss_s1: 0.045837, loss_fp: 0.001620, loss_freq: 0.021580
[18:59:08.904] iteration 24793: loss: 0.043356, loss_s1: 0.034898, loss_fp: 0.003262, loss_freq: 0.015314
[18:59:09.532] iteration 24794: loss: 0.064757, loss_s1: 0.048494, loss_fp: 0.004026, loss_freq: 0.041531
[18:59:10.454] iteration 24795: loss: 0.038088, loss_s1: 0.022850, loss_fp: 0.003745, loss_freq: 0.016054
[18:59:11.085] iteration 24796: loss: 0.056412, loss_s1: 0.036182, loss_fp: 0.007987, loss_freq: 0.022651
[18:59:11.722] iteration 24797: loss: 0.048839, loss_s1: 0.020153, loss_fp: 0.004075, loss_freq: 0.017485
[18:59:12.370] iteration 24798: loss: 0.034406, loss_s1: 0.011991, loss_fp: 0.002805, loss_freq: 0.014507
[18:59:13.013] iteration 24799: loss: 0.051298, loss_s1: 0.048728, loss_fp: 0.002954, loss_freq: 0.014696
[18:59:13.649] iteration 24800: loss: 0.054778, loss_s1: 0.026481, loss_fp: 0.002293, loss_freq: 0.031332
[18:59:16.878] iteration 24800 : mean_dice : 0.737603
[18:59:17.534] iteration 24801: loss: 0.042860, loss_s1: 0.025011, loss_fp: 0.002836, loss_freq: 0.026415
[18:59:18.167] iteration 24802: loss: 0.031778, loss_s1: 0.022232, loss_fp: 0.005012, loss_freq: 0.007208
[18:59:18.797] iteration 24803: loss: 0.082627, loss_s1: 0.067510, loss_fp: 0.002823, loss_freq: 0.070330
[18:59:19.425] iteration 24804: loss: 0.053139, loss_s1: 0.046899, loss_fp: 0.004518, loss_freq: 0.014804
[18:59:20.054] iteration 24805: loss: 0.033576, loss_s1: 0.015932, loss_fp: 0.001927, loss_freq: 0.006370
[18:59:20.700] iteration 24806: loss: 0.046684, loss_s1: 0.049171, loss_fp: 0.003338, loss_freq: 0.013113
[18:59:21.337] iteration 24807: loss: 0.075976, loss_s1: 0.057782, loss_fp: 0.005393, loss_freq: 0.058226
[18:59:21.983] iteration 24808: loss: 0.060122, loss_s1: 0.061385, loss_fp: 0.008358, loss_freq: 0.014276
[18:59:22.624] iteration 24809: loss: 0.035980, loss_s1: 0.030579, loss_fp: 0.001600, loss_freq: 0.012526
[18:59:23.259] iteration 24810: loss: 0.151960, loss_s1: 0.139041, loss_fp: 0.002186, loss_freq: 0.128189
[18:59:23.892] iteration 24811: loss: 0.038177, loss_s1: 0.019345, loss_fp: 0.010018, loss_freq: 0.012720
[18:59:24.529] iteration 24812: loss: 0.064090, loss_s1: 0.044697, loss_fp: 0.004861, loss_freq: 0.022203
[18:59:25.161] iteration 24813: loss: 0.035494, loss_s1: 0.018897, loss_fp: 0.001329, loss_freq: 0.012299
[18:59:25.796] iteration 24814: loss: 0.067340, loss_s1: 0.043557, loss_fp: 0.001837, loss_freq: 0.033476
[18:59:26.431] iteration 24815: loss: 0.030729, loss_s1: 0.014513, loss_fp: 0.000651, loss_freq: 0.007493
[18:59:27.064] iteration 24816: loss: 0.055407, loss_s1: 0.049129, loss_fp: 0.004997, loss_freq: 0.020608
[18:59:27.700] iteration 24817: loss: 0.055126, loss_s1: 0.039296, loss_fp: 0.001496, loss_freq: 0.022278
[18:59:28.336] iteration 24818: loss: 0.102660, loss_s1: 0.078561, loss_fp: 0.009267, loss_freq: 0.092334
[18:59:28.970] iteration 24819: loss: 0.046118, loss_s1: 0.041745, loss_fp: 0.001946, loss_freq: 0.023021
[18:59:29.602] iteration 24820: loss: 0.052712, loss_s1: 0.051519, loss_fp: 0.001264, loss_freq: 0.012854
[18:59:30.234] iteration 24821: loss: 0.037127, loss_s1: 0.024257, loss_fp: 0.002639, loss_freq: 0.012398
[18:59:30.862] iteration 24822: loss: 0.098442, loss_s1: 0.116535, loss_fp: 0.002049, loss_freq: 0.045667
[18:59:31.490] iteration 24823: loss: 0.048942, loss_s1: 0.037067, loss_fp: 0.003580, loss_freq: 0.022168
[18:59:32.122] iteration 24824: loss: 0.049221, loss_s1: 0.049741, loss_fp: 0.002274, loss_freq: 0.013933
[18:59:32.783] iteration 24825: loss: 0.063934, loss_s1: 0.048356, loss_fp: 0.002098, loss_freq: 0.044008
[18:59:33.413] iteration 24826: loss: 0.060591, loss_s1: 0.050960, loss_fp: 0.005069, loss_freq: 0.022636
[18:59:34.043] iteration 24827: loss: 0.055378, loss_s1: 0.053129, loss_fp: 0.001200, loss_freq: 0.023674
[18:59:34.674] iteration 24828: loss: 0.039711, loss_s1: 0.038916, loss_fp: 0.003488, loss_freq: 0.003916
[18:59:35.312] iteration 24829: loss: 0.066824, loss_s1: 0.058977, loss_fp: 0.014932, loss_freq: 0.021851
[18:59:35.945] iteration 24830: loss: 0.072829, loss_s1: 0.070894, loss_fp: 0.001848, loss_freq: 0.047684
[18:59:36.575] iteration 24831: loss: 0.044804, loss_s1: 0.037473, loss_fp: 0.001686, loss_freq: 0.017080
[18:59:37.201] iteration 24832: loss: 0.059510, loss_s1: 0.045447, loss_fp: 0.012180, loss_freq: 0.024779
[18:59:37.826] iteration 24833: loss: 0.088087, loss_s1: 0.076243, loss_fp: 0.009544, loss_freq: 0.055054
[18:59:38.454] iteration 24834: loss: 0.046463, loss_s1: 0.036545, loss_fp: 0.001638, loss_freq: 0.025411
[18:59:39.080] iteration 24835: loss: 0.066965, loss_s1: 0.057163, loss_fp: 0.006852, loss_freq: 0.018345
[18:59:39.710] iteration 24836: loss: 0.038769, loss_s1: 0.029740, loss_fp: 0.005426, loss_freq: 0.016260
[18:59:40.336] iteration 24837: loss: 0.083050, loss_s1: 0.084102, loss_fp: 0.014023, loss_freq: 0.039304
[18:59:40.963] iteration 24838: loss: 0.075662, loss_s1: 0.043811, loss_fp: 0.012333, loss_freq: 0.057054
[18:59:41.587] iteration 24839: loss: 0.040441, loss_s1: 0.021739, loss_fp: 0.009353, loss_freq: 0.012614
[18:59:42.216] iteration 24840: loss: 0.053453, loss_s1: 0.052567, loss_fp: 0.000903, loss_freq: 0.004564
[18:59:42.841] iteration 24841: loss: 0.034849, loss_s1: 0.031840, loss_fp: 0.002659, loss_freq: 0.008909
[18:59:43.470] iteration 24842: loss: 0.043163, loss_s1: 0.030494, loss_fp: 0.005796, loss_freq: 0.015284
[18:59:44.099] iteration 24843: loss: 0.075269, loss_s1: 0.084862, loss_fp: 0.001400, loss_freq: 0.022365
[18:59:44.731] iteration 24844: loss: 0.056921, loss_s1: 0.053801, loss_fp: 0.001472, loss_freq: 0.033389
[18:59:45.364] iteration 24845: loss: 0.054730, loss_s1: 0.052904, loss_fp: 0.002743, loss_freq: 0.025568
[18:59:45.998] iteration 24846: loss: 0.047431, loss_s1: 0.021658, loss_fp: 0.002001, loss_freq: 0.021857
[18:59:46.645] iteration 24847: loss: 0.047640, loss_s1: 0.038534, loss_fp: 0.004058, loss_freq: 0.011463
[18:59:47.281] iteration 24848: loss: 0.058847, loss_s1: 0.035997, loss_fp: 0.003117, loss_freq: 0.047153
[18:59:47.913] iteration 24849: loss: 0.043956, loss_s1: 0.030163, loss_fp: 0.000691, loss_freq: 0.015293
[18:59:48.546] iteration 24850: loss: 0.069766, loss_s1: 0.071606, loss_fp: 0.002974, loss_freq: 0.028725
[18:59:49.175] iteration 24851: loss: 0.039287, loss_s1: 0.037987, loss_fp: 0.001348, loss_freq: 0.006502
[18:59:49.803] iteration 24852: loss: 0.064087, loss_s1: 0.034099, loss_fp: 0.004266, loss_freq: 0.051287
[18:59:50.429] iteration 24853: loss: 0.026568, loss_s1: 0.010187, loss_fp: 0.005072, loss_freq: 0.006980
[18:59:51.060] iteration 24854: loss: 0.046483, loss_s1: 0.025298, loss_fp: 0.003327, loss_freq: 0.035648
[18:59:51.686] iteration 24855: loss: 0.059035, loss_s1: 0.062649, loss_fp: 0.007360, loss_freq: 0.023838
[18:59:52.312] iteration 24856: loss: 0.037649, loss_s1: 0.022667, loss_fp: 0.015694, loss_freq: 0.007226
[18:59:52.942] iteration 24857: loss: 0.039682, loss_s1: 0.017307, loss_fp: 0.003310, loss_freq: 0.014730
[18:59:53.578] iteration 24858: loss: 0.052696, loss_s1: 0.044161, loss_fp: 0.007184, loss_freq: 0.028337
[18:59:54.203] iteration 24859: loss: 0.034703, loss_s1: 0.016880, loss_fp: 0.002929, loss_freq: 0.015487
[18:59:54.828] iteration 24860: loss: 0.075888, loss_s1: 0.055627, loss_fp: 0.003109, loss_freq: 0.066555
[18:59:55.455] iteration 24861: loss: 0.033267, loss_s1: 0.012877, loss_fp: 0.002686, loss_freq: 0.015059
[18:59:56.084] iteration 24862: loss: 0.068309, loss_s1: 0.058971, loss_fp: 0.007840, loss_freq: 0.040245
[18:59:56.711] iteration 24863: loss: 0.050384, loss_s1: 0.035224, loss_fp: 0.005675, loss_freq: 0.028756
[18:59:57.338] iteration 24864: loss: 0.061421, loss_s1: 0.052528, loss_fp: 0.002901, loss_freq: 0.025282
[18:59:57.965] iteration 24865: loss: 0.069844, loss_s1: 0.041505, loss_fp: 0.003263, loss_freq: 0.066886
[18:59:58.593] iteration 24866: loss: 0.038839, loss_s1: 0.013870, loss_fp: 0.001631, loss_freq: 0.025616
[18:59:59.223] iteration 24867: loss: 0.038204, loss_s1: 0.021601, loss_fp: 0.005581, loss_freq: 0.014417
[18:59:59.843] iteration 24868: loss: 0.049830, loss_s1: 0.037132, loss_fp: 0.001879, loss_freq: 0.017609
[19:00:00.468] iteration 24869: loss: 0.071241, loss_s1: 0.074836, loss_fp: 0.000978, loss_freq: 0.037065
[19:00:01.093] iteration 24870: loss: 0.064772, loss_s1: 0.046810, loss_fp: 0.013562, loss_freq: 0.020774
[19:00:01.722] iteration 24871: loss: 0.067543, loss_s1: 0.078576, loss_fp: 0.001667, loss_freq: 0.012089
[19:00:02.348] iteration 24872: loss: 0.044766, loss_s1: 0.037872, loss_fp: 0.001743, loss_freq: 0.017178
[19:00:02.975] iteration 24873: loss: 0.028677, loss_s1: 0.013038, loss_fp: 0.001356, loss_freq: 0.008306
[19:00:03.602] iteration 24874: loss: 0.041793, loss_s1: 0.012013, loss_fp: 0.003093, loss_freq: 0.025598
[19:00:04.244] iteration 24875: loss: 0.059342, loss_s1: 0.049783, loss_fp: 0.005057, loss_freq: 0.028496
[19:00:04.876] iteration 24876: loss: 0.076181, loss_s1: 0.088682, loss_fp: 0.005970, loss_freq: 0.023683
[19:00:05.502] iteration 24877: loss: 0.100173, loss_s1: 0.074583, loss_fp: 0.003168, loss_freq: 0.096711
[19:00:06.131] iteration 24878: loss: 0.063381, loss_s1: 0.047980, loss_fp: 0.008348, loss_freq: 0.022422
[19:00:06.757] iteration 24879: loss: 0.056907, loss_s1: 0.057918, loss_fp: 0.005673, loss_freq: 0.019050
[19:00:07.384] iteration 24880: loss: 0.055688, loss_s1: 0.060135, loss_fp: 0.002243, loss_freq: 0.011904
[19:00:08.013] iteration 24881: loss: 0.037642, loss_s1: 0.017983, loss_fp: 0.001365, loss_freq: 0.016283
[19:00:08.644] iteration 24882: loss: 0.058050, loss_s1: 0.060554, loss_fp: 0.003693, loss_freq: 0.012621
[19:00:09.274] iteration 24883: loss: 0.075578, loss_s1: 0.035377, loss_fp: 0.005962, loss_freq: 0.077232
[19:00:09.904] iteration 24884: loss: 0.067435, loss_s1: 0.064623, loss_fp: 0.003123, loss_freq: 0.023738
[19:00:10.527] iteration 24885: loss: 0.054825, loss_s1: 0.052819, loss_fp: 0.003097, loss_freq: 0.016382
[19:00:11.156] iteration 24886: loss: 0.052506, loss_s1: 0.049010, loss_fp: 0.004509, loss_freq: 0.015915
[19:00:11.780] iteration 24887: loss: 0.048572, loss_s1: 0.012988, loss_fp: 0.000821, loss_freq: 0.023715
[19:00:12.414] iteration 24888: loss: 0.048545, loss_s1: 0.051209, loss_fp: 0.003450, loss_freq: 0.007421
[19:00:13.042] iteration 24889: loss: 0.040366, loss_s1: 0.045139, loss_fp: 0.001426, loss_freq: 0.007694
[19:00:13.671] iteration 24890: loss: 0.042120, loss_s1: 0.032704, loss_fp: 0.001561, loss_freq: 0.023797
[19:00:14.294] iteration 24891: loss: 0.036671, loss_s1: 0.028476, loss_fp: 0.000974, loss_freq: 0.014504
[19:00:14.922] iteration 24892: loss: 0.033697, loss_s1: 0.014710, loss_fp: 0.000814, loss_freq: 0.015921
[19:00:15.566] iteration 24893: loss: 0.026298, loss_s1: 0.009956, loss_fp: 0.001461, loss_freq: 0.007580
[19:00:16.201] iteration 24894: loss: 0.051278, loss_s1: 0.044728, loss_fp: 0.005023, loss_freq: 0.020478
[19:00:16.827] iteration 24895: loss: 0.038203, loss_s1: 0.039681, loss_fp: 0.000605, loss_freq: 0.012018
[19:00:17.456] iteration 24896: loss: 0.046478, loss_s1: 0.022047, loss_fp: 0.002433, loss_freq: 0.023594
[19:00:18.090] iteration 24897: loss: 0.068919, loss_s1: 0.072421, loss_fp: 0.004901, loss_freq: 0.032371
[19:00:18.721] iteration 24898: loss: 0.071200, loss_s1: 0.085957, loss_fp: 0.004837, loss_freq: 0.018268
[19:00:19.348] iteration 24899: loss: 0.041861, loss_s1: 0.022700, loss_fp: 0.001623, loss_freq: 0.015832
[19:00:20.041] iteration 24900: loss: 0.042663, loss_s1: 0.014850, loss_fp: 0.001499, loss_freq: 0.032465
[19:00:20.672] iteration 24901: loss: 0.036461, loss_s1: 0.014476, loss_fp: 0.001228, loss_freq: 0.005685
[19:00:21.311] iteration 24902: loss: 0.050644, loss_s1: 0.050565, loss_fp: 0.003916, loss_freq: 0.009845
[19:00:21.945] iteration 24903: loss: 0.120440, loss_s1: 0.090714, loss_fp: 0.021780, loss_freq: 0.088698
[19:00:22.595] iteration 24904: loss: 0.038403, loss_s1: 0.019273, loss_fp: 0.003340, loss_freq: 0.018270
[19:00:23.219] iteration 24905: loss: 0.031014, loss_s1: 0.012788, loss_fp: 0.005665, loss_freq: 0.004250
[19:00:23.846] iteration 24906: loss: 0.051626, loss_s1: 0.032587, loss_fp: 0.006290, loss_freq: 0.030640
[19:00:24.471] iteration 24907: loss: 0.042865, loss_s1: 0.036980, loss_fp: 0.010411, loss_freq: 0.010161
[19:00:25.102] iteration 24908: loss: 0.063146, loss_s1: 0.048234, loss_fp: 0.001724, loss_freq: 0.043734
[19:00:25.735] iteration 24909: loss: 0.034358, loss_s1: 0.015778, loss_fp: 0.004386, loss_freq: 0.009869
[19:00:26.363] iteration 24910: loss: 0.066612, loss_s1: 0.077386, loss_fp: 0.007365, loss_freq: 0.015588
[19:00:26.995] iteration 24911: loss: 0.052623, loss_s1: 0.050831, loss_fp: 0.007658, loss_freq: 0.011969
[19:00:27.626] iteration 24912: loss: 0.033458, loss_s1: 0.019767, loss_fp: 0.001453, loss_freq: 0.017628
[19:00:28.260] iteration 24913: loss: 0.064286, loss_s1: 0.041222, loss_fp: 0.003858, loss_freq: 0.045268
[19:00:28.887] iteration 24914: loss: 0.062252, loss_s1: 0.030833, loss_fp: 0.001927, loss_freq: 0.064407
[19:00:29.511] iteration 24915: loss: 0.044645, loss_s1: 0.023410, loss_fp: 0.009382, loss_freq: 0.018386
[19:00:30.137] iteration 24916: loss: 0.042090, loss_s1: 0.030344, loss_fp: 0.003698, loss_freq: 0.017117
[19:00:30.764] iteration 24917: loss: 0.067912, loss_s1: 0.068241, loss_fp: 0.004045, loss_freq: 0.020505
[19:00:31.388] iteration 24918: loss: 0.047975, loss_s1: 0.047313, loss_fp: 0.001761, loss_freq: 0.014195
[19:00:32.012] iteration 24919: loss: 0.046375, loss_s1: 0.029201, loss_fp: 0.003755, loss_freq: 0.018256
[19:00:32.649] iteration 24920: loss: 0.072099, loss_s1: 0.055985, loss_fp: 0.005740, loss_freq: 0.041920
[19:00:33.282] iteration 24921: loss: 0.042308, loss_s1: 0.043488, loss_fp: 0.002727, loss_freq: 0.006639
[19:00:33.924] iteration 24922: loss: 0.090422, loss_s1: 0.102011, loss_fp: 0.000971, loss_freq: 0.024330
[19:00:34.557] iteration 24923: loss: 0.075898, loss_s1: 0.047294, loss_fp: 0.021095, loss_freq: 0.054562
[19:00:35.194] iteration 24924: loss: 0.039946, loss_s1: 0.031990, loss_fp: 0.003432, loss_freq: 0.016712
[19:00:35.836] iteration 24925: loss: 0.050255, loss_s1: 0.028016, loss_fp: 0.013839, loss_freq: 0.029769
[19:00:36.472] iteration 24926: loss: 0.038284, loss_s1: 0.031181, loss_fp: 0.000989, loss_freq: 0.008026
[19:00:37.101] iteration 24927: loss: 0.053486, loss_s1: 0.054210, loss_fp: 0.002064, loss_freq: 0.013404
[19:00:37.737] iteration 24928: loss: 0.042797, loss_s1: 0.026327, loss_fp: 0.002889, loss_freq: 0.008353
[19:00:38.365] iteration 24929: loss: 0.056086, loss_s1: 0.048759, loss_fp: 0.004514, loss_freq: 0.030174
[19:00:38.993] iteration 24930: loss: 0.104022, loss_s1: 0.139162, loss_fp: 0.011500, loss_freq: 0.029004
[19:00:39.617] iteration 24931: loss: 0.051005, loss_s1: 0.051899, loss_fp: 0.000900, loss_freq: 0.004778
[19:00:40.245] iteration 24932: loss: 0.043809, loss_s1: 0.035589, loss_fp: 0.001694, loss_freq: 0.021295
[19:00:40.878] iteration 24933: loss: 0.045819, loss_s1: 0.032020, loss_fp: 0.007775, loss_freq: 0.019975
[19:00:41.507] iteration 24934: loss: 0.054498, loss_s1: 0.023466, loss_fp: 0.002262, loss_freq: 0.037580
[19:00:42.128] iteration 24935: loss: 0.066183, loss_s1: 0.032069, loss_fp: 0.004615, loss_freq: 0.019280
[19:00:42.757] iteration 24936: loss: 0.058954, loss_s1: 0.042439, loss_fp: 0.001582, loss_freq: 0.043854
[19:00:43.385] iteration 24937: loss: 0.075873, loss_s1: 0.072273, loss_fp: 0.004862, loss_freq: 0.040527
[19:00:44.009] iteration 24938: loss: 0.058824, loss_s1: 0.041948, loss_fp: 0.004280, loss_freq: 0.025490
[19:00:44.635] iteration 24939: loss: 0.032363, loss_s1: 0.015878, loss_fp: 0.008120, loss_freq: 0.009075
[19:00:45.260] iteration 24940: loss: 0.052935, loss_s1: 0.042973, loss_fp: 0.004511, loss_freq: 0.018186
[19:00:45.891] iteration 24941: loss: 0.064518, loss_s1: 0.048959, loss_fp: 0.010169, loss_freq: 0.043890
[19:00:46.524] iteration 24942: loss: 0.036825, loss_s1: 0.033871, loss_fp: 0.000651, loss_freq: 0.011400
[19:00:47.145] iteration 24943: loss: 0.031629, loss_s1: 0.016324, loss_fp: 0.010879, loss_freq: 0.012561
[19:00:47.769] iteration 24944: loss: 0.088415, loss_s1: 0.080366, loss_fp: 0.003792, loss_freq: 0.056038
[19:00:48.399] iteration 24945: loss: 0.039432, loss_s1: 0.022030, loss_fp: 0.003662, loss_freq: 0.022366
[19:00:49.023] iteration 24946: loss: 0.077049, loss_s1: 0.055141, loss_fp: 0.006372, loss_freq: 0.057024
[19:00:49.649] iteration 24947: loss: 0.035376, loss_s1: 0.019218, loss_fp: 0.004588, loss_freq: 0.018750
[19:00:50.274] iteration 24948: loss: 0.066754, loss_s1: 0.025726, loss_fp: 0.003835, loss_freq: 0.030413
[19:00:50.901] iteration 24949: loss: 0.032914, loss_s1: 0.033235, loss_fp: 0.004462, loss_freq: 0.003081
[19:00:51.527] iteration 24950: loss: 0.061344, loss_s1: 0.052698, loss_fp: 0.003192, loss_freq: 0.030472
[19:00:52.157] iteration 24951: loss: 0.040852, loss_s1: 0.005234, loss_fp: 0.001376, loss_freq: 0.027138
[19:00:52.781] iteration 24952: loss: 0.075986, loss_s1: 0.065450, loss_fp: 0.002358, loss_freq: 0.043820
[19:00:53.413] iteration 24953: loss: 0.087710, loss_s1: 0.054924, loss_fp: 0.013386, loss_freq: 0.057400
[19:00:54.042] iteration 24954: loss: 0.052633, loss_s1: 0.037961, loss_fp: 0.003220, loss_freq: 0.030505
[19:00:54.665] iteration 24955: loss: 0.048798, loss_s1: 0.031166, loss_fp: 0.003162, loss_freq: 0.021266
[19:00:55.680] iteration 24956: loss: 0.043478, loss_s1: 0.034099, loss_fp: 0.003149, loss_freq: 0.021546
[19:00:56.321] iteration 24957: loss: 0.074856, loss_s1: 0.076526, loss_fp: 0.001654, loss_freq: 0.030461
[19:00:56.956] iteration 24958: loss: 0.028797, loss_s1: 0.019857, loss_fp: 0.001863, loss_freq: 0.008165
[19:00:57.588] iteration 24959: loss: 0.034059, loss_s1: 0.021121, loss_fp: 0.000655, loss_freq: 0.009742
[19:00:58.217] iteration 24960: loss: 0.034683, loss_s1: 0.015317, loss_fp: 0.002956, loss_freq: 0.014936
[19:00:58.845] iteration 24961: loss: 0.090004, loss_s1: 0.068579, loss_fp: 0.005428, loss_freq: 0.036287
[19:00:59.475] iteration 24962: loss: 0.039835, loss_s1: 0.036487, loss_fp: 0.001626, loss_freq: 0.013530
[19:01:00.106] iteration 24963: loss: 0.036753, loss_s1: 0.033940, loss_fp: 0.000918, loss_freq: 0.012972
[19:01:00.731] iteration 24964: loss: 0.058738, loss_s1: 0.060370, loss_fp: 0.003820, loss_freq: 0.020604
[19:01:01.358] iteration 24965: loss: 0.049007, loss_s1: 0.025429, loss_fp: 0.002842, loss_freq: 0.030170
[19:01:01.984] iteration 24966: loss: 0.030637, loss_s1: 0.016348, loss_fp: 0.003099, loss_freq: 0.003768
[19:01:02.612] iteration 24967: loss: 0.033260, loss_s1: 0.006117, loss_fp: 0.003705, loss_freq: 0.028777
[19:01:03.239] iteration 24968: loss: 0.084627, loss_s1: 0.056363, loss_fp: 0.006837, loss_freq: 0.075948
[19:01:03.864] iteration 24969: loss: 0.058490, loss_s1: 0.035487, loss_fp: 0.002951, loss_freq: 0.039648
[19:01:04.488] iteration 24970: loss: 0.041529, loss_s1: 0.031911, loss_fp: 0.006388, loss_freq: 0.018386
[19:01:05.117] iteration 24971: loss: 0.076447, loss_s1: 0.044186, loss_fp: 0.004924, loss_freq: 0.072409
[19:01:05.749] iteration 24972: loss: 0.064478, loss_s1: 0.084849, loss_fp: 0.001458, loss_freq: 0.006630
[19:01:06.373] iteration 24973: loss: 0.089946, loss_s1: 0.102110, loss_fp: 0.006754, loss_freq: 0.034447
[19:01:07.005] iteration 24974: loss: 0.048101, loss_s1: 0.039402, loss_fp: 0.001130, loss_freq: 0.022674
[19:01:07.651] iteration 24975: loss: 0.042494, loss_s1: 0.030395, loss_fp: 0.002785, loss_freq: 0.023533
[19:01:08.279] iteration 24976: loss: 0.033020, loss_s1: 0.021276, loss_fp: 0.002442, loss_freq: 0.006236
[19:01:08.913] iteration 24977: loss: 0.053681, loss_s1: 0.046148, loss_fp: 0.003160, loss_freq: 0.017979
[19:01:09.548] iteration 24978: loss: 0.058389, loss_s1: 0.051161, loss_fp: 0.001451, loss_freq: 0.014355
[19:01:10.183] iteration 24979: loss: 0.079353, loss_s1: 0.028946, loss_fp: 0.009132, loss_freq: 0.077726
[19:01:10.814] iteration 24980: loss: 0.032645, loss_s1: 0.021523, loss_fp: 0.001229, loss_freq: 0.017749
[19:01:11.442] iteration 24981: loss: 0.047254, loss_s1: 0.047222, loss_fp: 0.002472, loss_freq: 0.016904
[19:01:12.068] iteration 24982: loss: 0.021892, loss_s1: 0.005711, loss_fp: 0.000439, loss_freq: 0.006348
[19:01:12.690] iteration 24983: loss: 0.081079, loss_s1: 0.063366, loss_fp: 0.013572, loss_freq: 0.046770
[19:01:13.315] iteration 24984: loss: 0.056956, loss_s1: 0.044115, loss_fp: 0.006396, loss_freq: 0.032451
[19:01:13.937] iteration 24985: loss: 0.041429, loss_s1: 0.038856, loss_fp: 0.002041, loss_freq: 0.007316
[19:01:14.571] iteration 24986: loss: 0.044180, loss_s1: 0.027203, loss_fp: 0.002854, loss_freq: 0.030064
[19:01:15.195] iteration 24987: loss: 0.038885, loss_s1: 0.014112, loss_fp: 0.005602, loss_freq: 0.021912
[19:01:15.822] iteration 24988: loss: 0.048709, loss_s1: 0.021206, loss_fp: 0.002077, loss_freq: 0.037111
[19:01:16.444] iteration 24989: loss: 0.036715, loss_s1: 0.031639, loss_fp: 0.002811, loss_freq: 0.006374
[19:01:17.070] iteration 24990: loss: 0.060776, loss_s1: 0.054388, loss_fp: 0.001711, loss_freq: 0.018738
[19:01:17.699] iteration 24991: loss: 0.065812, loss_s1: 0.059773, loss_fp: 0.006349, loss_freq: 0.026534
[19:01:18.336] iteration 24992: loss: 0.052621, loss_s1: 0.025958, loss_fp: 0.003227, loss_freq: 0.030757
[19:01:18.962] iteration 24993: loss: 0.054814, loss_s1: 0.052849, loss_fp: 0.002744, loss_freq: 0.010710
[19:01:19.591] iteration 24994: loss: 0.075503, loss_s1: 0.066434, loss_fp: 0.004303, loss_freq: 0.043579
[19:01:20.215] iteration 24995: loss: 0.062854, loss_s1: 0.068401, loss_fp: 0.005657, loss_freq: 0.020776
[19:01:20.844] iteration 24996: loss: 0.044700, loss_s1: 0.030268, loss_fp: 0.000993, loss_freq: 0.021117
[19:01:21.469] iteration 24997: loss: 0.111158, loss_s1: 0.123068, loss_fp: 0.002590, loss_freq: 0.062937
[19:01:22.094] iteration 24998: loss: 0.067913, loss_s1: 0.049569, loss_fp: 0.017809, loss_freq: 0.042310
[19:01:22.716] iteration 24999: loss: 0.061594, loss_s1: 0.061805, loss_fp: 0.003023, loss_freq: 0.027598
[19:01:23.347] iteration 25000: loss: 0.034938, loss_s1: 0.021622, loss_fp: 0.002610, loss_freq: 0.012718
[19:01:26.626] iteration 25000 : mean_dice : 0.734173
[19:01:27.271] iteration 25001: loss: 0.040100, loss_s1: 0.026319, loss_fp: 0.002597, loss_freq: 0.003097
[19:01:27.897] iteration 25002: loss: 0.027964, loss_s1: 0.017282, loss_fp: 0.001329, loss_freq: 0.010718
[19:01:28.530] iteration 25003: loss: 0.034474, loss_s1: 0.020543, loss_fp: 0.007641, loss_freq: 0.016015
[19:01:29.159] iteration 25004: loss: 0.086855, loss_s1: 0.095334, loss_fp: 0.009855, loss_freq: 0.025426
[19:01:29.790] iteration 25005: loss: 0.058003, loss_s1: 0.047554, loss_fp: 0.004614, loss_freq: 0.035861
[19:01:30.418] iteration 25006: loss: 0.069079, loss_s1: 0.062214, loss_fp: 0.001414, loss_freq: 0.031892
[19:01:31.044] iteration 25007: loss: 0.055964, loss_s1: 0.049140, loss_fp: 0.001392, loss_freq: 0.025023
[19:01:31.668] iteration 25008: loss: 0.047246, loss_s1: 0.033119, loss_fp: 0.001649, loss_freq: 0.019991
[19:01:32.297] iteration 25009: loss: 0.048788, loss_s1: 0.028927, loss_fp: 0.002037, loss_freq: 0.034410
[19:01:32.945] iteration 25010: loss: 0.047920, loss_s1: 0.042193, loss_fp: 0.002455, loss_freq: 0.019971
[19:01:33.571] iteration 25011: loss: 0.066154, loss_s1: 0.058625, loss_fp: 0.006650, loss_freq: 0.029998
[19:01:34.199] iteration 25012: loss: 0.038819, loss_s1: 0.031337, loss_fp: 0.001138, loss_freq: 0.009209
[19:01:34.824] iteration 25013: loss: 0.048987, loss_s1: 0.022133, loss_fp: 0.005008, loss_freq: 0.029182
[19:01:35.448] iteration 25014: loss: 0.034823, loss_s1: 0.029091, loss_fp: 0.001027, loss_freq: 0.006873
[19:01:36.077] iteration 25015: loss: 0.047535, loss_s1: 0.039412, loss_fp: 0.004280, loss_freq: 0.022540
[19:01:36.708] iteration 25016: loss: 0.030474, loss_s1: 0.017417, loss_fp: 0.000383, loss_freq: 0.016019
[19:01:37.336] iteration 25017: loss: 0.047450, loss_s1: 0.033632, loss_fp: 0.002361, loss_freq: 0.015796
[19:01:37.971] iteration 25018: loss: 0.046035, loss_s1: 0.036999, loss_fp: 0.002245, loss_freq: 0.015525
[19:01:38.604] iteration 25019: loss: 0.045322, loss_s1: 0.039379, loss_fp: 0.005425, loss_freq: 0.015599
[19:01:39.231] iteration 25020: loss: 0.054659, loss_s1: 0.067701, loss_fp: 0.003000, loss_freq: 0.009980
[19:01:39.861] iteration 25021: loss: 0.106272, loss_s1: 0.070811, loss_fp: 0.004078, loss_freq: 0.106152
[19:01:40.484] iteration 25022: loss: 0.048163, loss_s1: 0.023626, loss_fp: 0.004588, loss_freq: 0.029803
[19:01:41.114] iteration 25023: loss: 0.080728, loss_s1: 0.075930, loss_fp: 0.002972, loss_freq: 0.051440
[19:01:41.744] iteration 25024: loss: 0.052757, loss_s1: 0.062042, loss_fp: 0.002724, loss_freq: 0.011367
[19:01:42.372] iteration 25025: loss: 0.064552, loss_s1: 0.034698, loss_fp: 0.001435, loss_freq: 0.049729
[19:01:42.994] iteration 25026: loss: 0.057338, loss_s1: 0.038239, loss_fp: 0.011476, loss_freq: 0.026407
[19:01:43.621] iteration 25027: loss: 0.054844, loss_s1: 0.043327, loss_fp: 0.002712, loss_freq: 0.028810
[19:01:44.247] iteration 25028: loss: 0.069986, loss_s1: 0.086624, loss_fp: 0.002050, loss_freq: 0.022603
[19:01:44.882] iteration 25029: loss: 0.028562, loss_s1: 0.015840, loss_fp: 0.001629, loss_freq: 0.008175
[19:01:45.512] iteration 25030: loss: 0.086798, loss_s1: 0.105679, loss_fp: 0.000780, loss_freq: 0.031078
[19:01:46.140] iteration 25031: loss: 0.061542, loss_s1: 0.072432, loss_fp: 0.000555, loss_freq: 0.015786
[19:01:46.769] iteration 25032: loss: 0.054886, loss_s1: 0.048814, loss_fp: 0.004148, loss_freq: 0.016835
[19:01:47.396] iteration 25033: loss: 0.040082, loss_s1: 0.030920, loss_fp: 0.002758, loss_freq: 0.019925
[19:01:48.021] iteration 25034: loss: 0.029370, loss_s1: 0.020454, loss_fp: 0.000797, loss_freq: 0.010169
[19:01:48.645] iteration 25035: loss: 0.052737, loss_s1: 0.049867, loss_fp: 0.001423, loss_freq: 0.018314
[19:01:49.279] iteration 25036: loss: 0.047086, loss_s1: 0.034965, loss_fp: 0.003654, loss_freq: 0.024959
[19:01:49.903] iteration 25037: loss: 0.048011, loss_s1: 0.044845, loss_fp: 0.001680, loss_freq: 0.016025
[19:01:50.531] iteration 25038: loss: 0.051141, loss_s1: 0.042368, loss_fp: 0.003742, loss_freq: 0.025248
[19:01:51.170] iteration 25039: loss: 0.042721, loss_s1: 0.029896, loss_fp: 0.001402, loss_freq: 0.017698
[19:01:51.796] iteration 25040: loss: 0.099870, loss_s1: 0.097714, loss_fp: 0.005029, loss_freq: 0.068555
[19:01:52.421] iteration 25041: loss: 0.039303, loss_s1: 0.030069, loss_fp: 0.001233, loss_freq: 0.016821
[19:01:53.048] iteration 25042: loss: 0.068404, loss_s1: 0.083630, loss_fp: 0.000384, loss_freq: 0.009271
[19:01:53.683] iteration 25043: loss: 0.044491, loss_s1: 0.035956, loss_fp: 0.002767, loss_freq: 0.014122
[19:01:54.309] iteration 25044: loss: 0.039939, loss_s1: 0.028950, loss_fp: 0.001113, loss_freq: 0.013223
[19:01:54.930] iteration 25045: loss: 0.061527, loss_s1: 0.054211, loss_fp: 0.001330, loss_freq: 0.029139
[19:01:55.557] iteration 25046: loss: 0.052723, loss_s1: 0.044582, loss_fp: 0.003173, loss_freq: 0.017159
[19:01:56.181] iteration 25047: loss: 0.076691, loss_s1: 0.060422, loss_fp: 0.014907, loss_freq: 0.040607
[19:01:56.807] iteration 25048: loss: 0.055118, loss_s1: 0.035550, loss_fp: 0.003423, loss_freq: 0.010394
[19:01:57.436] iteration 25049: loss: 0.037758, loss_s1: 0.035106, loss_fp: 0.001551, loss_freq: 0.008279
[19:01:58.068] iteration 25050: loss: 0.064424, loss_s1: 0.038622, loss_fp: 0.007571, loss_freq: 0.049122
[19:01:58.696] iteration 25051: loss: 0.043910, loss_s1: 0.029928, loss_fp: 0.001430, loss_freq: 0.025106
[19:01:59.328] iteration 25052: loss: 0.039169, loss_s1: 0.025784, loss_fp: 0.003251, loss_freq: 0.016945
[19:01:59.978] iteration 25053: loss: 0.052174, loss_s1: 0.034909, loss_fp: 0.003816, loss_freq: 0.015367
[19:02:00.609] iteration 25054: loss: 0.074723, loss_s1: 0.072729, loss_fp: 0.005451, loss_freq: 0.032878
[19:02:01.238] iteration 25055: loss: 0.051725, loss_s1: 0.053036, loss_fp: 0.001896, loss_freq: 0.017476
[19:02:01.867] iteration 25056: loss: 0.041824, loss_s1: 0.038477, loss_fp: 0.002149, loss_freq: 0.018204
[19:02:02.494] iteration 25057: loss: 0.092909, loss_s1: 0.085320, loss_fp: 0.003226, loss_freq: 0.030587
[19:02:03.124] iteration 25058: loss: 0.051832, loss_s1: 0.042409, loss_fp: 0.005460, loss_freq: 0.029339
[19:02:03.752] iteration 25059: loss: 0.052449, loss_s1: 0.048751, loss_fp: 0.003384, loss_freq: 0.021186
[19:02:04.376] iteration 25060: loss: 0.049538, loss_s1: 0.032239, loss_fp: 0.002967, loss_freq: 0.006874
[19:02:05.004] iteration 25061: loss: 0.040864, loss_s1: 0.021431, loss_fp: 0.003018, loss_freq: 0.024807
[19:02:05.627] iteration 25062: loss: 0.037510, loss_s1: 0.038688, loss_fp: 0.001123, loss_freq: 0.002088
[19:02:06.253] iteration 25063: loss: 0.052038, loss_s1: 0.032365, loss_fp: 0.000496, loss_freq: 0.029736
[19:02:06.884] iteration 25064: loss: 0.110914, loss_s1: 0.075981, loss_fp: 0.003058, loss_freq: 0.100842
[19:02:07.509] iteration 25065: loss: 0.040467, loss_s1: 0.030341, loss_fp: 0.000622, loss_freq: 0.021497
[19:02:08.128] iteration 25066: loss: 0.033600, loss_s1: 0.008564, loss_fp: 0.003374, loss_freq: 0.015702
[19:02:08.753] iteration 25067: loss: 0.051291, loss_s1: 0.026142, loss_fp: 0.003748, loss_freq: 0.043653
[19:02:09.380] iteration 25068: loss: 0.071786, loss_s1: 0.067298, loss_fp: 0.001744, loss_freq: 0.048853
[19:02:10.007] iteration 25069: loss: 0.052722, loss_s1: 0.036655, loss_fp: 0.005226, loss_freq: 0.033258
[19:02:10.630] iteration 25070: loss: 0.031979, loss_s1: 0.016783, loss_fp: 0.001657, loss_freq: 0.016021
[19:02:11.256] iteration 25071: loss: 0.043681, loss_s1: 0.039983, loss_fp: 0.001718, loss_freq: 0.016148
[19:02:11.880] iteration 25072: loss: 0.047754, loss_s1: 0.035756, loss_fp: 0.007353, loss_freq: 0.012190
[19:02:12.499] iteration 25073: loss: 0.040131, loss_s1: 0.041574, loss_fp: 0.001662, loss_freq: 0.008275
[19:02:13.123] iteration 25074: loss: 0.051412, loss_s1: 0.035727, loss_fp: 0.004290, loss_freq: 0.030784
[19:02:13.747] iteration 25075: loss: 0.082005, loss_s1: 0.089980, loss_fp: 0.008140, loss_freq: 0.038836
[19:02:14.374] iteration 25076: loss: 0.086783, loss_s1: 0.110589, loss_fp: 0.003994, loss_freq: 0.023667
[19:02:14.996] iteration 25077: loss: 0.050653, loss_s1: 0.035666, loss_fp: 0.002997, loss_freq: 0.028318
[19:02:15.625] iteration 25078: loss: 0.059563, loss_s1: 0.068931, loss_fp: 0.001836, loss_freq: 0.015963
[19:02:16.252] iteration 25079: loss: 0.026020, loss_s1: 0.015230, loss_fp: 0.001915, loss_freq: 0.004862
[19:02:16.882] iteration 25080: loss: 0.042183, loss_s1: 0.016681, loss_fp: 0.005510, loss_freq: 0.017840
[19:02:17.509] iteration 25081: loss: 0.072478, loss_s1: 0.041374, loss_fp: 0.002487, loss_freq: 0.039305
[19:02:18.135] iteration 25082: loss: 0.033047, loss_s1: 0.018480, loss_fp: 0.002569, loss_freq: 0.005623
[19:02:18.760] iteration 25083: loss: 0.058097, loss_s1: 0.039735, loss_fp: 0.003694, loss_freq: 0.027503
[19:02:19.387] iteration 25084: loss: 0.052153, loss_s1: 0.047331, loss_fp: 0.002901, loss_freq: 0.027746
[19:02:20.011] iteration 25085: loss: 0.036230, loss_s1: 0.025450, loss_fp: 0.002555, loss_freq: 0.013252
[19:02:20.647] iteration 25086: loss: 0.068027, loss_s1: 0.051617, loss_fp: 0.003834, loss_freq: 0.039162
[19:02:21.274] iteration 25087: loss: 0.059547, loss_s1: 0.053763, loss_fp: 0.006925, loss_freq: 0.025788
[19:02:21.898] iteration 25088: loss: 0.055231, loss_s1: 0.049869, loss_fp: 0.006597, loss_freq: 0.018667
[19:02:22.525] iteration 25089: loss: 0.039739, loss_s1: 0.033885, loss_fp: 0.001976, loss_freq: 0.015841
[19:02:23.150] iteration 25090: loss: 0.045482, loss_s1: 0.044950, loss_fp: 0.003313, loss_freq: 0.013904
[19:02:23.772] iteration 25091: loss: 0.034049, loss_s1: 0.020578, loss_fp: 0.011002, loss_freq: 0.012280
[19:02:24.414] iteration 25092: loss: 0.027881, loss_s1: 0.006629, loss_fp: 0.003226, loss_freq: 0.006553
[19:02:25.261] iteration 25093: loss: 0.045591, loss_s1: 0.021443, loss_fp: 0.006076, loss_freq: 0.031032
[19:02:25.924] iteration 25094: loss: 0.038282, loss_s1: 0.015033, loss_fp: 0.002277, loss_freq: 0.027990
[19:02:26.567] iteration 25095: loss: 0.107669, loss_s1: 0.028838, loss_fp: 0.008288, loss_freq: 0.077248
[19:02:27.193] iteration 25096: loss: 0.058467, loss_s1: 0.046721, loss_fp: 0.002602, loss_freq: 0.016991
[19:02:27.817] iteration 25097: loss: 0.045766, loss_s1: 0.039448, loss_fp: 0.002499, loss_freq: 0.014283
[19:02:28.437] iteration 25098: loss: 0.038464, loss_s1: 0.030746, loss_fp: 0.001933, loss_freq: 0.014456
[19:02:29.059] iteration 25099: loss: 0.067349, loss_s1: 0.056053, loss_fp: 0.004762, loss_freq: 0.030707
[19:02:29.686] iteration 25100: loss: 0.031907, loss_s1: 0.016365, loss_fp: 0.005207, loss_freq: 0.010039
[19:02:30.315] iteration 25101: loss: 0.072220, loss_s1: 0.053839, loss_fp: 0.011129, loss_freq: 0.044223
[19:02:30.949] iteration 25102: loss: 0.069873, loss_s1: 0.065077, loss_fp: 0.004382, loss_freq: 0.043525
[19:02:31.574] iteration 25103: loss: 0.038302, loss_s1: 0.040344, loss_fp: 0.001907, loss_freq: 0.011643
[19:02:32.198] iteration 25104: loss: 0.035399, loss_s1: 0.016231, loss_fp: 0.008921, loss_freq: 0.020268
[19:02:32.820] iteration 25105: loss: 0.067097, loss_s1: 0.057210, loss_fp: 0.001194, loss_freq: 0.041000
[19:02:33.444] iteration 25106: loss: 0.043358, loss_s1: 0.023146, loss_fp: 0.005580, loss_freq: 0.009880
[19:02:34.070] iteration 25107: loss: 0.066674, loss_s1: 0.056652, loss_fp: 0.004752, loss_freq: 0.040207
[19:02:34.693] iteration 25108: loss: 0.033051, loss_s1: 0.025908, loss_fp: 0.000941, loss_freq: 0.012095
[19:02:35.324] iteration 25109: loss: 0.040180, loss_s1: 0.026224, loss_fp: 0.001615, loss_freq: 0.013225
[19:02:35.949] iteration 25110: loss: 0.029907, loss_s1: 0.016525, loss_fp: 0.002088, loss_freq: 0.007047
[19:02:36.577] iteration 25111: loss: 0.063845, loss_s1: 0.051965, loss_fp: 0.003495, loss_freq: 0.031166
[19:02:37.201] iteration 25112: loss: 0.034903, loss_s1: 0.016738, loss_fp: 0.001203, loss_freq: 0.010254
[19:02:37.828] iteration 25113: loss: 0.067135, loss_s1: 0.025060, loss_fp: 0.006612, loss_freq: 0.064911
[19:02:38.488] iteration 25114: loss: 0.041042, loss_s1: 0.020521, loss_fp: 0.003731, loss_freq: 0.021356
[19:02:39.111] iteration 25115: loss: 0.051652, loss_s1: 0.038208, loss_fp: 0.005397, loss_freq: 0.026434
[19:02:39.734] iteration 25116: loss: 0.056101, loss_s1: 0.028967, loss_fp: 0.001420, loss_freq: 0.046266
[19:02:40.749] iteration 25117: loss: 0.026362, loss_s1: 0.015253, loss_fp: 0.002299, loss_freq: 0.004895
[19:02:41.377] iteration 25118: loss: 0.093639, loss_s1: 0.096721, loss_fp: 0.018262, loss_freq: 0.035491
[19:02:42.023] iteration 25119: loss: 0.030065, loss_s1: 0.018028, loss_fp: 0.001509, loss_freq: 0.008927
[19:02:42.659] iteration 25120: loss: 0.048866, loss_s1: 0.038939, loss_fp: 0.003706, loss_freq: 0.013745
[19:02:43.292] iteration 25121: loss: 0.045164, loss_s1: 0.026483, loss_fp: 0.004233, loss_freq: 0.025613
[19:02:43.933] iteration 25122: loss: 0.052986, loss_s1: 0.042311, loss_fp: 0.003420, loss_freq: 0.028660
[19:02:44.559] iteration 25123: loss: 0.055887, loss_s1: 0.047037, loss_fp: 0.002025, loss_freq: 0.032583
[19:02:45.187] iteration 25124: loss: 0.027855, loss_s1: 0.015723, loss_fp: 0.004099, loss_freq: 0.011523
[19:02:45.815] iteration 25125: loss: 0.060035, loss_s1: 0.063606, loss_fp: 0.001570, loss_freq: 0.029597
[19:02:46.445] iteration 25126: loss: 0.047503, loss_s1: 0.018861, loss_fp: 0.005728, loss_freq: 0.034236
[19:02:47.077] iteration 25127: loss: 0.028452, loss_s1: 0.018926, loss_fp: 0.001585, loss_freq: 0.007091
[19:02:47.703] iteration 25128: loss: 0.033773, loss_s1: 0.014328, loss_fp: 0.003969, loss_freq: 0.023143
[19:02:48.327] iteration 25129: loss: 0.087120, loss_s1: 0.056254, loss_fp: 0.005069, loss_freq: 0.077853
[19:02:48.958] iteration 25130: loss: 0.052206, loss_s1: 0.038715, loss_fp: 0.002465, loss_freq: 0.016830
[19:02:49.580] iteration 25131: loss: 0.048401, loss_s1: 0.041994, loss_fp: 0.001477, loss_freq: 0.021376
[19:02:50.208] iteration 25132: loss: 0.088123, loss_s1: 0.090343, loss_fp: 0.009919, loss_freq: 0.038962
[19:02:50.830] iteration 25133: loss: 0.031747, loss_s1: 0.016889, loss_fp: 0.002758, loss_freq: 0.010792
[19:02:51.453] iteration 25134: loss: 0.050619, loss_s1: 0.025221, loss_fp: 0.007910, loss_freq: 0.033735
[19:02:52.087] iteration 25135: loss: 0.056745, loss_s1: 0.045965, loss_fp: 0.007621, loss_freq: 0.025468
[19:02:52.712] iteration 25136: loss: 0.053782, loss_s1: 0.031305, loss_fp: 0.002831, loss_freq: 0.028275
[19:02:53.341] iteration 25137: loss: 0.042197, loss_s1: 0.026659, loss_fp: 0.000589, loss_freq: 0.018033
[19:02:53.969] iteration 25138: loss: 0.034438, loss_s1: 0.014993, loss_fp: 0.002732, loss_freq: 0.016727
[19:02:54.590] iteration 25139: loss: 0.034302, loss_s1: 0.014114, loss_fp: 0.002273, loss_freq: 0.011599
[19:02:55.218] iteration 25140: loss: 0.048129, loss_s1: 0.051735, loss_fp: 0.002433, loss_freq: 0.012150
[19:02:55.845] iteration 25141: loss: 0.041334, loss_s1: 0.029342, loss_fp: 0.005636, loss_freq: 0.018336
[19:02:56.472] iteration 25142: loss: 0.073880, loss_s1: 0.059200, loss_fp: 0.017937, loss_freq: 0.045962
[19:02:57.103] iteration 25143: loss: 0.052310, loss_s1: 0.059748, loss_fp: 0.000358, loss_freq: 0.014053
[19:02:57.725] iteration 25144: loss: 0.068172, loss_s1: 0.040629, loss_fp: 0.012446, loss_freq: 0.048829
[19:02:58.349] iteration 25145: loss: 0.085989, loss_s1: 0.076710, loss_fp: 0.008137, loss_freq: 0.054339
[19:02:58.975] iteration 25146: loss: 0.048445, loss_s1: 0.052731, loss_fp: 0.002231, loss_freq: 0.012430
[19:02:59.594] iteration 25147: loss: 0.049091, loss_s1: 0.037325, loss_fp: 0.005530, loss_freq: 0.029990
[19:03:00.220] iteration 25148: loss: 0.030839, loss_s1: 0.009362, loss_fp: 0.003433, loss_freq: 0.011116
[19:03:00.845] iteration 25149: loss: 0.031616, loss_s1: 0.017242, loss_fp: 0.000880, loss_freq: 0.016300
[19:03:01.479] iteration 25150: loss: 0.034010, loss_s1: 0.028329, loss_fp: 0.004417, loss_freq: 0.006143
[19:03:02.102] iteration 25151: loss: 0.060928, loss_s1: 0.032878, loss_fp: 0.005191, loss_freq: 0.029000
[19:03:02.731] iteration 25152: loss: 0.060816, loss_s1: 0.067540, loss_fp: 0.006338, loss_freq: 0.022092
[19:03:03.357] iteration 25153: loss: 0.090723, loss_s1: 0.066232, loss_fp: 0.037404, loss_freq: 0.036172
[19:03:03.983] iteration 25154: loss: 0.057594, loss_s1: 0.050010, loss_fp: 0.000890, loss_freq: 0.018620
[19:03:04.608] iteration 25155: loss: 0.056616, loss_s1: 0.060111, loss_fp: 0.001860, loss_freq: 0.009030
[19:03:05.237] iteration 25156: loss: 0.056562, loss_s1: 0.054648, loss_fp: 0.001691, loss_freq: 0.012777
[19:03:05.866] iteration 25157: loss: 0.050371, loss_s1: 0.028766, loss_fp: 0.003554, loss_freq: 0.021631
[19:03:06.494] iteration 25158: loss: 0.079242, loss_s1: 0.094945, loss_fp: 0.006769, loss_freq: 0.022020
[19:03:07.118] iteration 25159: loss: 0.058825, loss_s1: 0.044518, loss_fp: 0.004014, loss_freq: 0.037413
[19:03:07.744] iteration 25160: loss: 0.045144, loss_s1: 0.018749, loss_fp: 0.000881, loss_freq: 0.043606
[19:03:08.373] iteration 25161: loss: 0.058171, loss_s1: 0.048566, loss_fp: 0.004978, loss_freq: 0.022233
[19:03:08.996] iteration 25162: loss: 0.038608, loss_s1: 0.039271, loss_fp: 0.001625, loss_freq: 0.004273
[19:03:09.622] iteration 25163: loss: 0.028054, loss_s1: 0.010848, loss_fp: 0.000634, loss_freq: 0.014012
[19:03:10.245] iteration 25164: loss: 0.032996, loss_s1: 0.021427, loss_fp: 0.003371, loss_freq: 0.012800
[19:03:10.868] iteration 25165: loss: 0.090814, loss_s1: 0.096532, loss_fp: 0.004698, loss_freq: 0.035988
[19:03:11.497] iteration 25166: loss: 0.045546, loss_s1: 0.032258, loss_fp: 0.012131, loss_freq: 0.017058
[19:03:12.120] iteration 25167: loss: 0.071327, loss_s1: 0.070779, loss_fp: 0.007282, loss_freq: 0.035191
[19:03:12.745] iteration 25168: loss: 0.040446, loss_s1: 0.023107, loss_fp: 0.004831, loss_freq: 0.015271
[19:03:13.375] iteration 25169: loss: 0.055862, loss_s1: 0.043673, loss_fp: 0.003906, loss_freq: 0.024736
[19:03:14.084] iteration 25170: loss: 0.051000, loss_s1: 0.042611, loss_fp: 0.002938, loss_freq: 0.023479
[19:03:14.709] iteration 25171: loss: 0.041160, loss_s1: 0.015462, loss_fp: 0.001727, loss_freq: 0.009390
[19:03:15.334] iteration 25172: loss: 0.049067, loss_s1: 0.024862, loss_fp: 0.007034, loss_freq: 0.026935
[19:03:15.956] iteration 25173: loss: 0.063784, loss_s1: 0.046054, loss_fp: 0.004370, loss_freq: 0.021408
[19:03:16.580] iteration 25174: loss: 0.038268, loss_s1: 0.022009, loss_fp: 0.003106, loss_freq: 0.009864
[19:03:17.203] iteration 25175: loss: 0.042432, loss_s1: 0.045003, loss_fp: 0.006732, loss_freq: 0.005072
[19:03:17.831] iteration 25176: loss: 0.043913, loss_s1: 0.024791, loss_fp: 0.004780, loss_freq: 0.024038
[19:03:18.454] iteration 25177: loss: 0.054634, loss_s1: 0.055803, loss_fp: 0.004923, loss_freq: 0.019782
[19:03:19.082] iteration 25178: loss: 0.039823, loss_s1: 0.029238, loss_fp: 0.004406, loss_freq: 0.015855
[19:03:19.711] iteration 25179: loss: 0.056409, loss_s1: 0.040841, loss_fp: 0.000659, loss_freq: 0.031283
[19:03:20.339] iteration 25180: loss: 0.044886, loss_s1: 0.037847, loss_fp: 0.005147, loss_freq: 0.016457
[19:03:20.967] iteration 25181: loss: 0.055816, loss_s1: 0.028499, loss_fp: 0.001847, loss_freq: 0.025587
[19:03:21.592] iteration 25182: loss: 0.100215, loss_s1: 0.076994, loss_fp: 0.012361, loss_freq: 0.082029
[19:03:22.217] iteration 25183: loss: 0.046600, loss_s1: 0.027339, loss_fp: 0.002356, loss_freq: 0.031721
[19:03:22.850] iteration 25184: loss: 0.077691, loss_s1: 0.076462, loss_fp: 0.004320, loss_freq: 0.048911
[19:03:23.491] iteration 25185: loss: 0.054902, loss_s1: 0.058099, loss_fp: 0.002932, loss_freq: 0.016697
[19:03:24.119] iteration 25186: loss: 0.057536, loss_s1: 0.028228, loss_fp: 0.009368, loss_freq: 0.022419
[19:03:24.743] iteration 25187: loss: 0.087367, loss_s1: 0.076370, loss_fp: 0.007235, loss_freq: 0.050300
[19:03:25.371] iteration 25188: loss: 0.045281, loss_s1: 0.035201, loss_fp: 0.000976, loss_freq: 0.015825
[19:03:25.994] iteration 25189: loss: 0.053558, loss_s1: 0.053545, loss_fp: 0.006729, loss_freq: 0.016742
[19:03:26.624] iteration 25190: loss: 0.048029, loss_s1: 0.038620, loss_fp: 0.001901, loss_freq: 0.016888
[19:03:27.250] iteration 25191: loss: 0.053740, loss_s1: 0.059793, loss_fp: 0.001277, loss_freq: 0.012924
[19:03:27.874] iteration 25192: loss: 0.073740, loss_s1: 0.072381, loss_fp: 0.005202, loss_freq: 0.024625
[19:03:28.495] iteration 25193: loss: 0.063214, loss_s1: 0.067125, loss_fp: 0.001048, loss_freq: 0.016744
[19:03:29.123] iteration 25194: loss: 0.039976, loss_s1: 0.040060, loss_fp: 0.001185, loss_freq: 0.012044
[19:03:29.776] iteration 25195: loss: 0.036760, loss_s1: 0.016177, loss_fp: 0.001009, loss_freq: 0.017639
[19:03:30.409] iteration 25196: loss: 0.057655, loss_s1: 0.031341, loss_fp: 0.008776, loss_freq: 0.040243
[19:03:31.031] iteration 25197: loss: 0.066469, loss_s1: 0.042618, loss_fp: 0.015904, loss_freq: 0.030280
[19:03:31.659] iteration 25198: loss: 0.038208, loss_s1: 0.022837, loss_fp: 0.006864, loss_freq: 0.015370
[19:03:32.371] iteration 25199: loss: 0.106237, loss_s1: 0.116325, loss_fp: 0.018740, loss_freq: 0.052268
[19:03:33.013] iteration 25200: loss: 0.089735, loss_s1: 0.064375, loss_fp: 0.008917, loss_freq: 0.046769
[19:03:36.301] iteration 25200 : mean_dice : 0.706933
[19:03:36.945] iteration 25201: loss: 0.069528, loss_s1: 0.071649, loss_fp: 0.008688, loss_freq: 0.034664
[19:03:37.570] iteration 25202: loss: 0.032106, loss_s1: 0.017129, loss_fp: 0.005034, loss_freq: 0.010640
[19:03:38.195] iteration 25203: loss: 0.056385, loss_s1: 0.045577, loss_fp: 0.004296, loss_freq: 0.021198
[19:03:38.819] iteration 25204: loss: 0.040036, loss_s1: 0.035688, loss_fp: 0.002509, loss_freq: 0.010081
[19:03:39.440] iteration 25205: loss: 0.092147, loss_s1: 0.082441, loss_fp: 0.008293, loss_freq: 0.054333
[19:03:40.066] iteration 25206: loss: 0.076514, loss_s1: 0.060606, loss_fp: 0.014524, loss_freq: 0.031461
[19:03:40.689] iteration 25207: loss: 0.053906, loss_s1: 0.036007, loss_fp: 0.002450, loss_freq: 0.023308
[19:03:41.317] iteration 25208: loss: 0.052697, loss_s1: 0.032127, loss_fp: 0.003434, loss_freq: 0.032191
[19:03:41.943] iteration 25209: loss: 0.055562, loss_s1: 0.048005, loss_fp: 0.001036, loss_freq: 0.021157
[19:03:42.573] iteration 25210: loss: 0.046407, loss_s1: 0.044164, loss_fp: 0.002971, loss_freq: 0.006081
[19:03:43.192] iteration 25211: loss: 0.056489, loss_s1: 0.056471, loss_fp: 0.015233, loss_freq: 0.014846
[19:03:43.815] iteration 25212: loss: 0.049363, loss_s1: 0.026243, loss_fp: 0.006216, loss_freq: 0.033534
[19:03:44.445] iteration 25213: loss: 0.032515, loss_s1: 0.009156, loss_fp: 0.006613, loss_freq: 0.017524
[19:03:45.069] iteration 25214: loss: 0.051275, loss_s1: 0.022215, loss_fp: 0.000849, loss_freq: 0.034389
[19:03:45.717] iteration 25215: loss: 0.058023, loss_s1: 0.054655, loss_fp: 0.002921, loss_freq: 0.017271
[19:03:46.351] iteration 25216: loss: 0.065622, loss_s1: 0.077361, loss_fp: 0.002277, loss_freq: 0.015285
[19:03:46.982] iteration 25217: loss: 0.041883, loss_s1: 0.033075, loss_fp: 0.002070, loss_freq: 0.016482
[19:03:47.607] iteration 25218: loss: 0.085363, loss_s1: 0.051243, loss_fp: 0.007927, loss_freq: 0.070640
[19:03:48.253] iteration 25219: loss: 0.060941, loss_s1: 0.060660, loss_fp: 0.003682, loss_freq: 0.024090
[19:03:48.886] iteration 25220: loss: 0.054843, loss_s1: 0.056543, loss_fp: 0.001273, loss_freq: 0.023090
[19:03:49.516] iteration 25221: loss: 0.040284, loss_s1: 0.018799, loss_fp: 0.001393, loss_freq: 0.013718
[19:03:50.161] iteration 25222: loss: 0.025557, loss_s1: 0.016507, loss_fp: 0.002944, loss_freq: 0.006075
[19:03:50.812] iteration 25223: loss: 0.038894, loss_s1: 0.039863, loss_fp: 0.001557, loss_freq: 0.007407
[19:03:51.445] iteration 25224: loss: 0.048136, loss_s1: 0.020213, loss_fp: 0.001813, loss_freq: 0.018855
[19:03:52.090] iteration 25225: loss: 0.072064, loss_s1: 0.030736, loss_fp: 0.002410, loss_freq: 0.071314
[19:03:52.719] iteration 25226: loss: 0.067949, loss_s1: 0.038576, loss_fp: 0.002799, loss_freq: 0.059176
[19:03:53.352] iteration 25227: loss: 0.042175, loss_s1: 0.029233, loss_fp: 0.001306, loss_freq: 0.015041
[19:03:53.979] iteration 25228: loss: 0.048997, loss_s1: 0.045876, loss_fp: 0.006746, loss_freq: 0.017689
[19:03:54.610] iteration 25229: loss: 0.071296, loss_s1: 0.076502, loss_fp: 0.004689, loss_freq: 0.031486
[19:03:55.261] iteration 25230: loss: 0.054976, loss_s1: 0.052381, loss_fp: 0.001546, loss_freq: 0.019676
[19:03:55.887] iteration 25231: loss: 0.035422, loss_s1: 0.023135, loss_fp: 0.001291, loss_freq: 0.009354
[19:03:56.520] iteration 25232: loss: 0.040703, loss_s1: 0.030097, loss_fp: 0.000727, loss_freq: 0.018757
[19:03:57.150] iteration 25233: loss: 0.075999, loss_s1: 0.103532, loss_fp: 0.003391, loss_freq: 0.016183
[19:03:57.775] iteration 25234: loss: 0.041279, loss_s1: 0.041705, loss_fp: 0.003645, loss_freq: 0.011440
[19:03:58.402] iteration 25235: loss: 0.049122, loss_s1: 0.033743, loss_fp: 0.003964, loss_freq: 0.019979
[19:03:59.035] iteration 25236: loss: 0.062986, loss_s1: 0.062140, loss_fp: 0.003473, loss_freq: 0.031830
[19:03:59.663] iteration 25237: loss: 0.042540, loss_s1: 0.040009, loss_fp: 0.001953, loss_freq: 0.010171
[19:04:00.295] iteration 25238: loss: 0.062174, loss_s1: 0.030928, loss_fp: 0.012466, loss_freq: 0.033319
[19:04:00.927] iteration 25239: loss: 0.060871, loss_s1: 0.058914, loss_fp: 0.004294, loss_freq: 0.014140
[19:04:01.558] iteration 25240: loss: 0.055472, loss_s1: 0.073581, loss_fp: 0.001224, loss_freq: 0.005225
[19:04:02.201] iteration 25241: loss: 0.053288, loss_s1: 0.026499, loss_fp: 0.003466, loss_freq: 0.041880
[19:04:02.824] iteration 25242: loss: 0.030872, loss_s1: 0.012201, loss_fp: 0.000966, loss_freq: 0.011475
[19:04:03.453] iteration 25243: loss: 0.075978, loss_s1: 0.073796, loss_fp: 0.005076, loss_freq: 0.033226
[19:04:04.088] iteration 25244: loss: 0.079853, loss_s1: 0.083957, loss_fp: 0.012675, loss_freq: 0.009554
[19:04:04.724] iteration 25245: loss: 0.070671, loss_s1: 0.062706, loss_fp: 0.009290, loss_freq: 0.042851
[19:04:05.350] iteration 25246: loss: 0.062678, loss_s1: 0.065058, loss_fp: 0.005430, loss_freq: 0.021714
[19:04:05.994] iteration 25247: loss: 0.064955, loss_s1: 0.069177, loss_fp: 0.002662, loss_freq: 0.031026
[19:04:06.620] iteration 25248: loss: 0.067448, loss_s1: 0.051543, loss_fp: 0.003008, loss_freq: 0.039155
[19:04:07.250] iteration 25249: loss: 0.063908, loss_s1: 0.050747, loss_fp: 0.009187, loss_freq: 0.022029
[19:04:07.880] iteration 25250: loss: 0.045579, loss_s1: 0.033401, loss_fp: 0.004561, loss_freq: 0.022568
[19:04:08.513] iteration 25251: loss: 0.046391, loss_s1: 0.046314, loss_fp: 0.001160, loss_freq: 0.016189
[19:04:09.139] iteration 25252: loss: 0.065071, loss_s1: 0.073926, loss_fp: 0.005376, loss_freq: 0.022964
[19:04:09.770] iteration 25253: loss: 0.036979, loss_s1: 0.010001, loss_fp: 0.002074, loss_freq: 0.024259
[19:04:10.408] iteration 25254: loss: 0.045152, loss_s1: 0.049940, loss_fp: 0.001545, loss_freq: 0.012180
[19:04:11.056] iteration 25255: loss: 0.043415, loss_s1: 0.035894, loss_fp: 0.005628, loss_freq: 0.006112
[19:04:11.686] iteration 25256: loss: 0.063943, loss_s1: 0.035173, loss_fp: 0.016692, loss_freq: 0.033093
[19:04:12.315] iteration 25257: loss: 0.043604, loss_s1: 0.041538, loss_fp: 0.001895, loss_freq: 0.017794
[19:04:12.940] iteration 25258: loss: 0.034961, loss_s1: 0.029980, loss_fp: 0.000738, loss_freq: 0.009567
[19:04:13.565] iteration 25259: loss: 0.074306, loss_s1: 0.057097, loss_fp: 0.007070, loss_freq: 0.041139
[19:04:14.183] iteration 25260: loss: 0.054450, loss_s1: 0.024942, loss_fp: 0.004953, loss_freq: 0.022654
[19:04:14.811] iteration 25261: loss: 0.064977, loss_s1: 0.053829, loss_fp: 0.000930, loss_freq: 0.027741
[19:04:15.439] iteration 25262: loss: 0.072317, loss_s1: 0.077832, loss_fp: 0.002778, loss_freq: 0.029247
[19:04:16.071] iteration 25263: loss: 0.099268, loss_s1: 0.091089, loss_fp: 0.005337, loss_freq: 0.076500
[19:04:16.696] iteration 25264: loss: 0.042032, loss_s1: 0.046456, loss_fp: 0.000990, loss_freq: 0.011083
[19:04:17.325] iteration 25265: loss: 0.037323, loss_s1: 0.043660, loss_fp: 0.002335, loss_freq: 0.004501
[19:04:17.952] iteration 25266: loss: 0.088774, loss_s1: 0.066337, loss_fp: 0.009461, loss_freq: 0.066215
[19:04:18.586] iteration 25267: loss: 0.045148, loss_s1: 0.027373, loss_fp: 0.003829, loss_freq: 0.020418
[19:04:19.215] iteration 25268: loss: 0.078449, loss_s1: 0.092693, loss_fp: 0.001709, loss_freq: 0.034125
[19:04:19.843] iteration 25269: loss: 0.033951, loss_s1: 0.024737, loss_fp: 0.001663, loss_freq: 0.010120
[19:04:20.469] iteration 25270: loss: 0.086830, loss_s1: 0.081292, loss_fp: 0.005155, loss_freq: 0.053323
[19:04:21.097] iteration 25271: loss: 0.022074, loss_s1: 0.011571, loss_fp: 0.000874, loss_freq: 0.004634
[19:04:21.728] iteration 25272: loss: 0.061285, loss_s1: 0.054881, loss_fp: 0.001049, loss_freq: 0.027376
[19:04:22.355] iteration 25273: loss: 0.031232, loss_s1: 0.014531, loss_fp: 0.000822, loss_freq: 0.011972
[19:04:23.006] iteration 25274: loss: 0.054023, loss_s1: 0.045638, loss_fp: 0.002802, loss_freq: 0.027095
[19:04:23.632] iteration 25275: loss: 0.052491, loss_s1: 0.051207, loss_fp: 0.000973, loss_freq: 0.020870
[19:04:24.257] iteration 25276: loss: 0.045035, loss_s1: 0.020331, loss_fp: 0.008392, loss_freq: 0.016298
[19:04:24.885] iteration 25277: loss: 0.037871, loss_s1: 0.016554, loss_fp: 0.004529, loss_freq: 0.019948
[19:04:25.834] iteration 25278: loss: 0.042109, loss_s1: 0.042451, loss_fp: 0.000887, loss_freq: 0.013669
[19:04:26.465] iteration 25279: loss: 0.054453, loss_s1: 0.050467, loss_fp: 0.007308, loss_freq: 0.016935
[19:04:27.109] iteration 25280: loss: 0.034728, loss_s1: 0.017291, loss_fp: 0.002650, loss_freq: 0.019305
[19:04:27.770] iteration 25281: loss: 0.039097, loss_s1: 0.025022, loss_fp: 0.000801, loss_freq: 0.017766
[19:04:28.398] iteration 25282: loss: 0.046527, loss_s1: 0.033473, loss_fp: 0.008529, loss_freq: 0.022896
[19:04:29.204] iteration 25283: loss: 0.075384, loss_s1: 0.058373, loss_fp: 0.016183, loss_freq: 0.041183
[19:04:29.837] iteration 25284: loss: 0.031174, loss_s1: 0.021774, loss_fp: 0.005554, loss_freq: 0.010069
[19:04:30.471] iteration 25285: loss: 0.029655, loss_s1: 0.017649, loss_fp: 0.000825, loss_freq: 0.015632
[19:04:31.099] iteration 25286: loss: 0.038247, loss_s1: 0.018245, loss_fp: 0.009128, loss_freq: 0.016949
[19:04:31.720] iteration 25287: loss: 0.080213, loss_s1: 0.045987, loss_fp: 0.006934, loss_freq: 0.069716
[19:04:32.344] iteration 25288: loss: 0.047124, loss_s1: 0.031908, loss_fp: 0.001994, loss_freq: 0.025333
[19:04:32.973] iteration 25289: loss: 0.057839, loss_s1: 0.051595, loss_fp: 0.008553, loss_freq: 0.025132
[19:04:33.597] iteration 25290: loss: 0.078910, loss_s1: 0.063077, loss_fp: 0.010606, loss_freq: 0.060558
[19:04:34.213] iteration 25291: loss: 0.049761, loss_s1: 0.038535, loss_fp: 0.004577, loss_freq: 0.017286
[19:04:34.843] iteration 25292: loss: 0.069370, loss_s1: 0.066955, loss_fp: 0.002224, loss_freq: 0.035928
[19:04:35.472] iteration 25293: loss: 0.084663, loss_s1: 0.040640, loss_fp: 0.002287, loss_freq: 0.092473
[19:04:36.095] iteration 25294: loss: 0.049050, loss_s1: 0.044159, loss_fp: 0.007676, loss_freq: 0.012070
[19:04:36.725] iteration 25295: loss: 0.049504, loss_s1: 0.045581, loss_fp: 0.004342, loss_freq: 0.017175
[19:04:37.353] iteration 25296: loss: 0.045436, loss_s1: 0.017711, loss_fp: 0.000953, loss_freq: 0.027788
[19:04:37.981] iteration 25297: loss: 0.046129, loss_s1: 0.038013, loss_fp: 0.001374, loss_freq: 0.013723
[19:04:38.611] iteration 25298: loss: 0.046615, loss_s1: 0.050699, loss_fp: 0.000180, loss_freq: 0.006426
[19:04:39.234] iteration 25299: loss: 0.055169, loss_s1: 0.049535, loss_fp: 0.003811, loss_freq: 0.022705
[19:04:39.860] iteration 25300: loss: 0.059996, loss_s1: 0.045771, loss_fp: 0.001314, loss_freq: 0.023847
[19:04:40.489] iteration 25301: loss: 0.070759, loss_s1: 0.054715, loss_fp: 0.001370, loss_freq: 0.050025
[19:04:41.118] iteration 25302: loss: 0.038528, loss_s1: 0.029055, loss_fp: 0.003686, loss_freq: 0.019528
[19:04:41.754] iteration 25303: loss: 0.054903, loss_s1: 0.060780, loss_fp: 0.004703, loss_freq: 0.019415
[19:04:42.379] iteration 25304: loss: 0.045419, loss_s1: 0.041344, loss_fp: 0.002108, loss_freq: 0.004061
[19:04:43.010] iteration 25305: loss: 0.083028, loss_s1: 0.093981, loss_fp: 0.008101, loss_freq: 0.029602
[19:04:43.644] iteration 25306: loss: 0.053379, loss_s1: 0.042963, loss_fp: 0.004876, loss_freq: 0.028205
[19:04:44.275] iteration 25307: loss: 0.043756, loss_s1: 0.037487, loss_fp: 0.006010, loss_freq: 0.012267
[19:04:44.900] iteration 25308: loss: 0.048992, loss_s1: 0.031428, loss_fp: 0.009384, loss_freq: 0.028402
[19:04:45.529] iteration 25309: loss: 0.032791, loss_s1: 0.007723, loss_fp: 0.001202, loss_freq: 0.015489
[19:04:46.154] iteration 25310: loss: 0.039548, loss_s1: 0.031501, loss_fp: 0.001890, loss_freq: 0.015243
[19:04:46.779] iteration 25311: loss: 0.033637, loss_s1: 0.022804, loss_fp: 0.002973, loss_freq: 0.010214
[19:04:47.411] iteration 25312: loss: 0.064663, loss_s1: 0.038394, loss_fp: 0.002360, loss_freq: 0.023623
[19:04:48.052] iteration 25313: loss: 0.072885, loss_s1: 0.056500, loss_fp: 0.004653, loss_freq: 0.046854
[19:04:48.689] iteration 25314: loss: 0.053518, loss_s1: 0.052664, loss_fp: 0.003265, loss_freq: 0.018954
[19:04:49.325] iteration 25315: loss: 0.066811, loss_s1: 0.072825, loss_fp: 0.001723, loss_freq: 0.025890
[19:04:49.964] iteration 25316: loss: 0.093091, loss_s1: 0.067325, loss_fp: 0.004595, loss_freq: 0.072119
[19:04:50.593] iteration 25317: loss: 0.038535, loss_s1: 0.034915, loss_fp: 0.002043, loss_freq: 0.010373
[19:04:51.223] iteration 25318: loss: 0.038436, loss_s1: 0.018986, loss_fp: 0.005852, loss_freq: 0.013869
[19:04:51.852] iteration 25319: loss: 0.098755, loss_s1: 0.115434, loss_fp: 0.004325, loss_freq: 0.054160
[19:04:52.484] iteration 25320: loss: 0.061669, loss_s1: 0.039154, loss_fp: 0.001996, loss_freq: 0.032025
[19:04:53.114] iteration 25321: loss: 0.045308, loss_s1: 0.030871, loss_fp: 0.002565, loss_freq: 0.033056
[19:04:53.780] iteration 25322: loss: 0.042927, loss_s1: 0.019034, loss_fp: 0.011468, loss_freq: 0.011926
[19:04:54.423] iteration 25323: loss: 0.035241, loss_s1: 0.022946, loss_fp: 0.000846, loss_freq: 0.002777
[19:04:55.080] iteration 25324: loss: 0.027336, loss_s1: 0.013931, loss_fp: 0.000847, loss_freq: 0.009477
[19:04:55.727] iteration 25325: loss: 0.063965, loss_s1: 0.072066, loss_fp: 0.005830, loss_freq: 0.017085
[19:04:56.375] iteration 25326: loss: 0.105634, loss_s1: 0.131002, loss_fp: 0.005841, loss_freq: 0.034947
[19:04:57.020] iteration 25327: loss: 0.071485, loss_s1: 0.061949, loss_fp: 0.003469, loss_freq: 0.052846
[19:04:57.643] iteration 25328: loss: 0.056664, loss_s1: 0.047941, loss_fp: 0.001628, loss_freq: 0.036490
[19:04:58.279] iteration 25329: loss: 0.040277, loss_s1: 0.021852, loss_fp: 0.006435, loss_freq: 0.016272
[19:04:58.908] iteration 25330: loss: 0.051902, loss_s1: 0.041337, loss_fp: 0.000830, loss_freq: 0.027514
[19:04:59.532] iteration 25331: loss: 0.031557, loss_s1: 0.015841, loss_fp: 0.002603, loss_freq: 0.016494
[19:05:00.160] iteration 25332: loss: 0.038770, loss_s1: 0.019679, loss_fp: 0.002454, loss_freq: 0.016868
[19:05:00.809] iteration 25333: loss: 0.073332, loss_s1: 0.047912, loss_fp: 0.004115, loss_freq: 0.055609
[19:05:01.442] iteration 25334: loss: 0.042576, loss_s1: 0.027411, loss_fp: 0.004425, loss_freq: 0.012400
[19:05:02.067] iteration 25335: loss: 0.046544, loss_s1: 0.020219, loss_fp: 0.004270, loss_freq: 0.026748
[19:05:02.693] iteration 25336: loss: 0.038017, loss_s1: 0.026512, loss_fp: 0.001820, loss_freq: 0.010584
[19:05:03.319] iteration 25337: loss: 0.050222, loss_s1: 0.024648, loss_fp: 0.008580, loss_freq: 0.036890
[19:05:03.945] iteration 25338: loss: 0.038749, loss_s1: 0.023241, loss_fp: 0.002548, loss_freq: 0.022667
[19:05:04.568] iteration 25339: loss: 0.034583, loss_s1: 0.015610, loss_fp: 0.013660, loss_freq: 0.009356
[19:05:05.195] iteration 25340: loss: 0.041989, loss_s1: 0.027418, loss_fp: 0.000610, loss_freq: 0.015397
[19:05:05.821] iteration 25341: loss: 0.060258, loss_s1: 0.062839, loss_fp: 0.002643, loss_freq: 0.025385
[19:05:06.451] iteration 25342: loss: 0.045250, loss_s1: 0.023711, loss_fp: 0.006323, loss_freq: 0.017698
[19:05:07.083] iteration 25343: loss: 0.047538, loss_s1: 0.022316, loss_fp: 0.005339, loss_freq: 0.042395
[19:05:07.718] iteration 25344: loss: 0.068201, loss_s1: 0.040592, loss_fp: 0.004215, loss_freq: 0.059302
[19:05:08.347] iteration 25345: loss: 0.055956, loss_s1: 0.053462, loss_fp: 0.004928, loss_freq: 0.026115
[19:05:08.976] iteration 25346: loss: 0.041510, loss_s1: 0.038477, loss_fp: 0.002313, loss_freq: 0.008754
[19:05:09.605] iteration 25347: loss: 0.070531, loss_s1: 0.037098, loss_fp: 0.005708, loss_freq: 0.010146
[19:05:10.229] iteration 25348: loss: 0.099109, loss_s1: 0.080591, loss_fp: 0.015064, loss_freq: 0.073733
[19:05:10.853] iteration 25349: loss: 0.067643, loss_s1: 0.049977, loss_fp: 0.002179, loss_freq: 0.034410
[19:05:11.482] iteration 25350: loss: 0.058702, loss_s1: 0.050212, loss_fp: 0.002338, loss_freq: 0.027067
[19:05:12.112] iteration 25351: loss: 0.063250, loss_s1: 0.068615, loss_fp: 0.003625, loss_freq: 0.016678
[19:05:12.761] iteration 25352: loss: 0.062136, loss_s1: 0.071455, loss_fp: 0.001177, loss_freq: 0.018762
[19:05:13.398] iteration 25353: loss: 0.074686, loss_s1: 0.078753, loss_fp: 0.007476, loss_freq: 0.014105
[19:05:14.028] iteration 25354: loss: 0.102385, loss_s1: 0.108940, loss_fp: 0.007262, loss_freq: 0.055162
[19:05:14.659] iteration 25355: loss: 0.040331, loss_s1: 0.025266, loss_fp: 0.007570, loss_freq: 0.019961
[19:05:15.299] iteration 25356: loss: 0.040115, loss_s1: 0.035716, loss_fp: 0.001684, loss_freq: 0.010591
[19:05:15.928] iteration 25357: loss: 0.058421, loss_s1: 0.040267, loss_fp: 0.003246, loss_freq: 0.034553
[19:05:16.560] iteration 25358: loss: 0.086273, loss_s1: 0.080319, loss_fp: 0.001568, loss_freq: 0.014165
[19:05:17.193] iteration 25359: loss: 0.052976, loss_s1: 0.046330, loss_fp: 0.002234, loss_freq: 0.031541
[19:05:17.825] iteration 25360: loss: 0.048844, loss_s1: 0.031129, loss_fp: 0.010666, loss_freq: 0.024807
[19:05:18.449] iteration 25361: loss: 0.075571, loss_s1: 0.086622, loss_fp: 0.005637, loss_freq: 0.017038
[19:05:19.093] iteration 25362: loss: 0.060665, loss_s1: 0.044906, loss_fp: 0.004672, loss_freq: 0.044488
[19:05:19.723] iteration 25363: loss: 0.031540, loss_s1: 0.019524, loss_fp: 0.000851, loss_freq: 0.010451
[19:05:20.357] iteration 25364: loss: 0.045020, loss_s1: 0.024406, loss_fp: 0.004095, loss_freq: 0.021184
[19:05:20.985] iteration 25365: loss: 0.045070, loss_s1: 0.034518, loss_fp: 0.009880, loss_freq: 0.016397
[19:05:21.617] iteration 25366: loss: 0.078093, loss_s1: 0.075176, loss_fp: 0.012390, loss_freq: 0.039109
[19:05:22.244] iteration 25367: loss: 0.070678, loss_s1: 0.081102, loss_fp: 0.001031, loss_freq: 0.029559
[19:05:22.876] iteration 25368: loss: 0.081539, loss_s1: 0.092900, loss_fp: 0.000704, loss_freq: 0.018221
[19:05:23.503] iteration 25369: loss: 0.051325, loss_s1: 0.045206, loss_fp: 0.003931, loss_freq: 0.019407
[19:05:24.125] iteration 25370: loss: 0.031774, loss_s1: 0.010841, loss_fp: 0.001082, loss_freq: 0.008791
[19:05:24.760] iteration 25371: loss: 0.044360, loss_s1: 0.036192, loss_fp: 0.005435, loss_freq: 0.014787
[19:05:25.393] iteration 25372: loss: 0.048482, loss_s1: 0.039831, loss_fp: 0.006890, loss_freq: 0.022741
[19:05:26.016] iteration 25373: loss: 0.050203, loss_s1: 0.023240, loss_fp: 0.013175, loss_freq: 0.032001
[19:05:26.644] iteration 25374: loss: 0.042529, loss_s1: 0.024733, loss_fp: 0.001979, loss_freq: 0.014161
[19:05:27.274] iteration 25375: loss: 0.036400, loss_s1: 0.020267, loss_fp: 0.001800, loss_freq: 0.011710
[19:05:27.904] iteration 25376: loss: 0.050468, loss_s1: 0.051023, loss_fp: 0.001181, loss_freq: 0.011296
[19:05:28.532] iteration 25377: loss: 0.044529, loss_s1: 0.043508, loss_fp: 0.004677, loss_freq: 0.010335
[19:05:29.166] iteration 25378: loss: 0.048450, loss_s1: 0.039511, loss_fp: 0.003676, loss_freq: 0.025248
[19:05:29.807] iteration 25379: loss: 0.048418, loss_s1: 0.026895, loss_fp: 0.000916, loss_freq: 0.038243
[19:05:30.438] iteration 25380: loss: 0.077224, loss_s1: 0.052021, loss_fp: 0.003659, loss_freq: 0.061886
[19:05:31.066] iteration 25381: loss: 0.046791, loss_s1: 0.047248, loss_fp: 0.001355, loss_freq: 0.009935
[19:05:31.699] iteration 25382: loss: 0.058072, loss_s1: 0.021197, loss_fp: 0.003225, loss_freq: 0.008492
[19:05:32.327] iteration 25383: loss: 0.037539, loss_s1: 0.016766, loss_fp: 0.001541, loss_freq: 0.017832
[19:05:32.967] iteration 25384: loss: 0.039965, loss_s1: 0.035520, loss_fp: 0.005014, loss_freq: 0.006362
[19:05:33.590] iteration 25385: loss: 0.087007, loss_s1: 0.075968, loss_fp: 0.015064, loss_freq: 0.027204
[19:05:34.221] iteration 25386: loss: 0.093449, loss_s1: 0.093410, loss_fp: 0.006951, loss_freq: 0.049648
[19:05:34.857] iteration 25387: loss: 0.044204, loss_s1: 0.032918, loss_fp: 0.004596, loss_freq: 0.018010
[19:05:35.481] iteration 25388: loss: 0.079767, loss_s1: 0.047936, loss_fp: 0.002685, loss_freq: 0.022184
[19:05:36.104] iteration 25389: loss: 0.060387, loss_s1: 0.045838, loss_fp: 0.002176, loss_freq: 0.030135
[19:05:36.729] iteration 25390: loss: 0.065525, loss_s1: 0.082039, loss_fp: 0.001626, loss_freq: 0.014275
[19:05:37.362] iteration 25391: loss: 0.050302, loss_s1: 0.041440, loss_fp: 0.002743, loss_freq: 0.019567
[19:05:37.987] iteration 25392: loss: 0.043210, loss_s1: 0.028578, loss_fp: 0.002333, loss_freq: 0.016979
[19:05:38.618] iteration 25393: loss: 0.082062, loss_s1: 0.108178, loss_fp: 0.003149, loss_freq: 0.016145
[19:05:39.239] iteration 25394: loss: 0.047774, loss_s1: 0.033134, loss_fp: 0.002584, loss_freq: 0.031200
[19:05:39.867] iteration 25395: loss: 0.048742, loss_s1: 0.045930, loss_fp: 0.002884, loss_freq: 0.018400
[19:05:40.514] iteration 25396: loss: 0.072576, loss_s1: 0.074806, loss_fp: 0.003254, loss_freq: 0.036390
[19:05:41.150] iteration 25397: loss: 0.063375, loss_s1: 0.033781, loss_fp: 0.002679, loss_freq: 0.057703
[19:05:41.776] iteration 25398: loss: 0.062192, loss_s1: 0.064306, loss_fp: 0.005489, loss_freq: 0.023855
[19:05:42.399] iteration 25399: loss: 0.066459, loss_s1: 0.071147, loss_fp: 0.003087, loss_freq: 0.020985
[19:05:43.027] iteration 25400: loss: 0.041948, loss_s1: 0.034047, loss_fp: 0.001070, loss_freq: 0.013741
[19:05:46.531] iteration 25400 : mean_dice : 0.738921
[19:05:47.169] iteration 25401: loss: 0.047126, loss_s1: 0.040432, loss_fp: 0.002169, loss_freq: 0.008437
[19:05:47.795] iteration 25402: loss: 0.053078, loss_s1: 0.044160, loss_fp: 0.002119, loss_freq: 0.023653
[19:05:48.420] iteration 25403: loss: 0.047710, loss_s1: 0.032418, loss_fp: 0.001302, loss_freq: 0.030384
[19:05:49.044] iteration 25404: loss: 0.054910, loss_s1: 0.063455, loss_fp: 0.001197, loss_freq: 0.011245
[19:05:49.671] iteration 25405: loss: 0.092533, loss_s1: 0.060446, loss_fp: 0.003323, loss_freq: 0.077919
[19:05:50.302] iteration 25406: loss: 0.041420, loss_s1: 0.021768, loss_fp: 0.007339, loss_freq: 0.017603
[19:05:50.928] iteration 25407: loss: 0.037977, loss_s1: 0.035352, loss_fp: 0.002613, loss_freq: 0.010849
[19:05:51.557] iteration 25408: loss: 0.067896, loss_s1: 0.055751, loss_fp: 0.024773, loss_freq: 0.024684
[19:05:52.185] iteration 25409: loss: 0.062694, loss_s1: 0.061422, loss_fp: 0.002838, loss_freq: 0.022146
[19:05:52.811] iteration 25410: loss: 0.049498, loss_s1: 0.041833, loss_fp: 0.004861, loss_freq: 0.010865
[19:05:53.439] iteration 25411: loss: 0.049587, loss_s1: 0.046468, loss_fp: 0.004840, loss_freq: 0.016115
[19:05:54.064] iteration 25412: loss: 0.060485, loss_s1: 0.043074, loss_fp: 0.000509, loss_freq: 0.047325
[19:05:54.688] iteration 25413: loss: 0.042252, loss_s1: 0.026022, loss_fp: 0.007925, loss_freq: 0.021559
[19:05:55.309] iteration 25414: loss: 0.028182, loss_s1: 0.012842, loss_fp: 0.003353, loss_freq: 0.006415
[19:05:55.935] iteration 25415: loss: 0.066260, loss_s1: 0.071959, loss_fp: 0.001170, loss_freq: 0.028744
[19:05:56.566] iteration 25416: loss: 0.035833, loss_s1: 0.021634, loss_fp: 0.002640, loss_freq: 0.015817
[19:05:57.193] iteration 25417: loss: 0.083429, loss_s1: 0.092593, loss_fp: 0.005305, loss_freq: 0.029937
[19:05:57.820] iteration 25418: loss: 0.090539, loss_s1: 0.112254, loss_fp: 0.004946, loss_freq: 0.034168
[19:05:58.445] iteration 25419: loss: 0.064603, loss_s1: 0.069935, loss_fp: 0.002580, loss_freq: 0.027096
[19:05:59.072] iteration 25420: loss: 0.047228, loss_s1: 0.033786, loss_fp: 0.003485, loss_freq: 0.020524
[19:05:59.698] iteration 25421: loss: 0.047164, loss_s1: 0.043940, loss_fp: 0.002414, loss_freq: 0.015066
[19:06:00.323] iteration 25422: loss: 0.043222, loss_s1: 0.040410, loss_fp: 0.000622, loss_freq: 0.010830
[19:06:00.953] iteration 25423: loss: 0.056198, loss_s1: 0.056563, loss_fp: 0.006592, loss_freq: 0.012252
[19:06:01.578] iteration 25424: loss: 0.057121, loss_s1: 0.046229, loss_fp: 0.002008, loss_freq: 0.032464
[19:06:02.201] iteration 25425: loss: 0.042576, loss_s1: 0.047421, loss_fp: 0.001423, loss_freq: 0.008605
[19:06:02.827] iteration 25426: loss: 0.047546, loss_s1: 0.032144, loss_fp: 0.011540, loss_freq: 0.006064
[19:06:03.452] iteration 25427: loss: 0.098273, loss_s1: 0.103221, loss_fp: 0.003545, loss_freq: 0.055568
[19:06:04.083] iteration 25428: loss: 0.062889, loss_s1: 0.064551, loss_fp: 0.005099, loss_freq: 0.023481
[19:06:04.711] iteration 25429: loss: 0.065111, loss_s1: 0.056408, loss_fp: 0.009075, loss_freq: 0.032848
[19:06:05.344] iteration 25430: loss: 0.049973, loss_s1: 0.046672, loss_fp: 0.002502, loss_freq: 0.021724
[19:06:05.974] iteration 25431: loss: 0.062054, loss_s1: 0.045869, loss_fp: 0.004158, loss_freq: 0.039007
[19:06:06.607] iteration 25432: loss: 0.027063, loss_s1: 0.009282, loss_fp: 0.002974, loss_freq: 0.013463
[19:06:07.238] iteration 25433: loss: 0.038617, loss_s1: 0.019817, loss_fp: 0.002156, loss_freq: 0.017646
[19:06:07.869] iteration 25434: loss: 0.031376, loss_s1: 0.013541, loss_fp: 0.001617, loss_freq: 0.010351
[19:06:08.494] iteration 25435: loss: 0.042993, loss_s1: 0.013523, loss_fp: 0.005775, loss_freq: 0.022438
[19:06:09.118] iteration 25436: loss: 0.066473, loss_s1: 0.043342, loss_fp: 0.002143, loss_freq: 0.037319
[19:06:09.742] iteration 25437: loss: 0.047709, loss_s1: 0.042393, loss_fp: 0.001791, loss_freq: 0.022230
[19:06:10.368] iteration 25438: loss: 0.042639, loss_s1: 0.028052, loss_fp: 0.000963, loss_freq: 0.019092
[19:06:11.307] iteration 25439: loss: 0.028853, loss_s1: 0.018577, loss_fp: 0.001278, loss_freq: 0.009866
[19:06:11.935] iteration 25440: loss: 0.072855, loss_s1: 0.059324, loss_fp: 0.005473, loss_freq: 0.049254
[19:06:12.594] iteration 25441: loss: 0.039092, loss_s1: 0.032943, loss_fp: 0.000470, loss_freq: 0.011495
[19:06:13.233] iteration 25442: loss: 0.048636, loss_s1: 0.036289, loss_fp: 0.000778, loss_freq: 0.022529
[19:06:13.875] iteration 25443: loss: 0.036931, loss_s1: 0.024229, loss_fp: 0.002877, loss_freq: 0.013116
[19:06:14.508] iteration 25444: loss: 0.037877, loss_s1: 0.015158, loss_fp: 0.004059, loss_freq: 0.017662
[19:06:15.167] iteration 25445: loss: 0.050353, loss_s1: 0.053022, loss_fp: 0.003963, loss_freq: 0.020110
[19:06:15.791] iteration 25446: loss: 0.029906, loss_s1: 0.016809, loss_fp: 0.003257, loss_freq: 0.012435
[19:06:16.422] iteration 25447: loss: 0.064507, loss_s1: 0.043320, loss_fp: 0.005446, loss_freq: 0.053395
[19:06:17.044] iteration 25448: loss: 0.068421, loss_s1: 0.066129, loss_fp: 0.015518, loss_freq: 0.017815
[19:06:17.676] iteration 25449: loss: 0.048948, loss_s1: 0.023993, loss_fp: 0.004144, loss_freq: 0.021105
[19:06:18.302] iteration 25450: loss: 0.048686, loss_s1: 0.043367, loss_fp: 0.002713, loss_freq: 0.018546
[19:06:18.929] iteration 25451: loss: 0.062161, loss_s1: 0.031851, loss_fp: 0.003814, loss_freq: 0.055831
[19:06:19.557] iteration 25452: loss: 0.067699, loss_s1: 0.045449, loss_fp: 0.007662, loss_freq: 0.021924
[19:06:20.183] iteration 25453: loss: 0.047681, loss_s1: 0.042664, loss_fp: 0.012749, loss_freq: 0.013292
[19:06:20.812] iteration 25454: loss: 0.059814, loss_s1: 0.060601, loss_fp: 0.004088, loss_freq: 0.020068
[19:06:21.436] iteration 25455: loss: 0.046032, loss_s1: 0.042696, loss_fp: 0.003157, loss_freq: 0.011867
[19:06:22.063] iteration 25456: loss: 0.073579, loss_s1: 0.065870, loss_fp: 0.005949, loss_freq: 0.041490
[19:06:22.684] iteration 25457: loss: 0.033204, loss_s1: 0.019763, loss_fp: 0.004077, loss_freq: 0.011343
[19:06:23.310] iteration 25458: loss: 0.047598, loss_s1: 0.025959, loss_fp: 0.005384, loss_freq: 0.019442
[19:06:23.933] iteration 25459: loss: 0.035689, loss_s1: 0.021670, loss_fp: 0.001003, loss_freq: 0.005668
[19:06:24.559] iteration 25460: loss: 0.042468, loss_s1: 0.016511, loss_fp: 0.001733, loss_freq: 0.024579
[19:06:25.183] iteration 25461: loss: 0.061135, loss_s1: 0.022939, loss_fp: 0.000911, loss_freq: 0.029249
[19:06:25.808] iteration 25462: loss: 0.071824, loss_s1: 0.079896, loss_fp: 0.001125, loss_freq: 0.036848
[19:06:26.435] iteration 25463: loss: 0.040891, loss_s1: 0.043673, loss_fp: 0.001181, loss_freq: 0.012644
[19:06:27.061] iteration 25464: loss: 0.029163, loss_s1: 0.022074, loss_fp: 0.001615, loss_freq: 0.011297
[19:06:27.689] iteration 25465: loss: 0.024375, loss_s1: 0.006806, loss_fp: 0.001130, loss_freq: 0.004975
[19:06:28.316] iteration 25466: loss: 0.068977, loss_s1: 0.047626, loss_fp: 0.006073, loss_freq: 0.047836
[19:06:28.942] iteration 25467: loss: 0.050214, loss_s1: 0.035906, loss_fp: 0.005619, loss_freq: 0.029865
[19:06:29.569] iteration 25468: loss: 0.038135, loss_s1: 0.035110, loss_fp: 0.002738, loss_freq: 0.011453
[19:06:30.193] iteration 25469: loss: 0.054401, loss_s1: 0.054427, loss_fp: 0.015484, loss_freq: 0.013495
[19:06:30.819] iteration 25470: loss: 0.042371, loss_s1: 0.024336, loss_fp: 0.002938, loss_freq: 0.016436
[19:06:31.441] iteration 25471: loss: 0.047968, loss_s1: 0.051234, loss_fp: 0.001448, loss_freq: 0.011388
[19:06:32.062] iteration 25472: loss: 0.034310, loss_s1: 0.021309, loss_fp: 0.003469, loss_freq: 0.009776
[19:06:32.747] iteration 25473: loss: 0.090907, loss_s1: 0.043729, loss_fp: 0.004001, loss_freq: 0.036686
[19:06:33.386] iteration 25474: loss: 0.061273, loss_s1: 0.055846, loss_fp: 0.002849, loss_freq: 0.025675
[19:06:34.018] iteration 25475: loss: 0.088958, loss_s1: 0.109102, loss_fp: 0.002578, loss_freq: 0.036680
[19:06:34.654] iteration 25476: loss: 0.063804, loss_s1: 0.067688, loss_fp: 0.003503, loss_freq: 0.024508
[19:06:35.283] iteration 25477: loss: 0.055994, loss_s1: 0.034370, loss_fp: 0.005732, loss_freq: 0.032733
[19:06:35.912] iteration 25478: loss: 0.041765, loss_s1: 0.034969, loss_fp: 0.002726, loss_freq: 0.016361
[19:06:36.535] iteration 25479: loss: 0.074345, loss_s1: 0.067199, loss_fp: 0.004580, loss_freq: 0.018721
[19:06:37.166] iteration 25480: loss: 0.068913, loss_s1: 0.072249, loss_fp: 0.006603, loss_freq: 0.032063
[19:06:37.792] iteration 25481: loss: 0.064564, loss_s1: 0.046500, loss_fp: 0.009439, loss_freq: 0.037732
[19:06:38.424] iteration 25482: loss: 0.051199, loss_s1: 0.032587, loss_fp: 0.001512, loss_freq: 0.031518
[19:06:39.051] iteration 25483: loss: 0.061170, loss_s1: 0.027501, loss_fp: 0.001573, loss_freq: 0.056531
[19:06:39.678] iteration 25484: loss: 0.034569, loss_s1: 0.019450, loss_fp: 0.000704, loss_freq: 0.007544
[19:06:40.301] iteration 25485: loss: 0.023119, loss_s1: 0.008417, loss_fp: 0.000913, loss_freq: 0.006948
[19:06:40.927] iteration 25486: loss: 0.065801, loss_s1: 0.047896, loss_fp: 0.030648, loss_freq: 0.015988
[19:06:41.558] iteration 25487: loss: 0.068127, loss_s1: 0.098642, loss_fp: 0.000865, loss_freq: 0.007565
[19:06:42.182] iteration 25488: loss: 0.044655, loss_s1: 0.028234, loss_fp: 0.002819, loss_freq: 0.030348
[19:06:42.811] iteration 25489: loss: 0.062770, loss_s1: 0.057334, loss_fp: 0.007895, loss_freq: 0.031713
[19:06:43.441] iteration 25490: loss: 0.062708, loss_s1: 0.028676, loss_fp: 0.007934, loss_freq: 0.051398
[19:06:44.081] iteration 25491: loss: 0.060349, loss_s1: 0.046448, loss_fp: 0.002908, loss_freq: 0.034577
[19:06:44.703] iteration 25492: loss: 0.041222, loss_s1: 0.017126, loss_fp: 0.000967, loss_freq: 0.021462
[19:06:45.324] iteration 25493: loss: 0.029130, loss_s1: 0.016629, loss_fp: 0.001133, loss_freq: 0.010706
[19:06:45.947] iteration 25494: loss: 0.061255, loss_s1: 0.055917, loss_fp: 0.000525, loss_freq: 0.017236
[19:06:46.574] iteration 25495: loss: 0.040290, loss_s1: 0.035764, loss_fp: 0.001410, loss_freq: 0.005518
[19:06:47.200] iteration 25496: loss: 0.040227, loss_s1: 0.029179, loss_fp: 0.004721, loss_freq: 0.008221
[19:06:47.824] iteration 25497: loss: 0.051033, loss_s1: 0.043183, loss_fp: 0.001766, loss_freq: 0.017431
[19:06:48.449] iteration 25498: loss: 0.037713, loss_s1: 0.021825, loss_fp: 0.002212, loss_freq: 0.027361
[19:06:49.077] iteration 25499: loss: 0.043158, loss_s1: 0.022771, loss_fp: 0.005783, loss_freq: 0.029328
[19:06:49.705] iteration 25500: loss: 0.051535, loss_s1: 0.024987, loss_fp: 0.008417, loss_freq: 0.041335
[19:06:50.335] iteration 25501: loss: 0.041157, loss_s1: 0.017898, loss_fp: 0.001789, loss_freq: 0.008994
[19:06:50.962] iteration 25502: loss: 0.059398, loss_s1: 0.056218, loss_fp: 0.007059, loss_freq: 0.017398
[19:06:51.598] iteration 25503: loss: 0.066297, loss_s1: 0.060327, loss_fp: 0.004486, loss_freq: 0.027084
[19:06:52.225] iteration 25504: loss: 0.073711, loss_s1: 0.039227, loss_fp: 0.000832, loss_freq: 0.047421
[19:06:52.850] iteration 25505: loss: 0.044365, loss_s1: 0.019632, loss_fp: 0.002906, loss_freq: 0.020180
[19:06:53.475] iteration 25506: loss: 0.054177, loss_s1: 0.029886, loss_fp: 0.002572, loss_freq: 0.051322
[19:06:54.096] iteration 25507: loss: 0.061660, loss_s1: 0.052544, loss_fp: 0.015078, loss_freq: 0.021283
[19:06:54.720] iteration 25508: loss: 0.067705, loss_s1: 0.056762, loss_fp: 0.002750, loss_freq: 0.024996
[19:06:55.342] iteration 25509: loss: 0.070228, loss_s1: 0.050790, loss_fp: 0.009822, loss_freq: 0.051438
[19:06:55.969] iteration 25510: loss: 0.059025, loss_s1: 0.018861, loss_fp: 0.002389, loss_freq: 0.027040
[19:06:56.590] iteration 25511: loss: 0.073694, loss_s1: 0.077129, loss_fp: 0.008320, loss_freq: 0.026427
[19:06:57.213] iteration 25512: loss: 0.049345, loss_s1: 0.034501, loss_fp: 0.007233, loss_freq: 0.015505
[19:06:57.839] iteration 25513: loss: 0.064401, loss_s1: 0.040429, loss_fp: 0.001760, loss_freq: 0.012384
[19:06:58.464] iteration 25514: loss: 0.054454, loss_s1: 0.036866, loss_fp: 0.003401, loss_freq: 0.029373
[19:06:59.091] iteration 25515: loss: 0.038238, loss_s1: 0.025761, loss_fp: 0.002284, loss_freq: 0.014717
[19:06:59.716] iteration 25516: loss: 0.059971, loss_s1: 0.070242, loss_fp: 0.001451, loss_freq: 0.009023
[19:07:00.342] iteration 25517: loss: 0.030734, loss_s1: 0.014419, loss_fp: 0.001695, loss_freq: 0.019727
[19:07:00.964] iteration 25518: loss: 0.064568, loss_s1: 0.059185, loss_fp: 0.000436, loss_freq: 0.031557
[19:07:01.590] iteration 25519: loss: 0.080049, loss_s1: 0.052145, loss_fp: 0.006751, loss_freq: 0.071471
[19:07:02.210] iteration 25520: loss: 0.044536, loss_s1: 0.054050, loss_fp: 0.001438, loss_freq: 0.009747
[19:07:02.840] iteration 25521: loss: 0.062477, loss_s1: 0.061419, loss_fp: 0.006481, loss_freq: 0.030773
[19:07:03.468] iteration 25522: loss: 0.045248, loss_s1: 0.025007, loss_fp: 0.003839, loss_freq: 0.030419
[19:07:04.099] iteration 25523: loss: 0.089997, loss_s1: 0.103503, loss_fp: 0.006801, loss_freq: 0.041338
[19:07:04.727] iteration 25524: loss: 0.046672, loss_s1: 0.013524, loss_fp: 0.001859, loss_freq: 0.022741
[19:07:05.354] iteration 25525: loss: 0.042891, loss_s1: 0.032899, loss_fp: 0.001174, loss_freq: 0.012664
[19:07:05.980] iteration 25526: loss: 0.035874, loss_s1: 0.030938, loss_fp: 0.001794, loss_freq: 0.006021
[19:07:06.604] iteration 25527: loss: 0.075463, loss_s1: 0.088098, loss_fp: 0.001383, loss_freq: 0.018648
[19:07:07.229] iteration 25528: loss: 0.054671, loss_s1: 0.048956, loss_fp: 0.004212, loss_freq: 0.029521
[19:07:07.845] iteration 25529: loss: 0.084347, loss_s1: 0.066263, loss_fp: 0.005150, loss_freq: 0.032104
[19:07:08.473] iteration 25530: loss: 0.057066, loss_s1: 0.033140, loss_fp: 0.011489, loss_freq: 0.029959
[19:07:09.107] iteration 25531: loss: 0.064528, loss_s1: 0.038302, loss_fp: 0.001611, loss_freq: 0.022887
[19:07:09.732] iteration 25532: loss: 0.046845, loss_s1: 0.045186, loss_fp: 0.000733, loss_freq: 0.019164
[19:07:10.357] iteration 25533: loss: 0.060404, loss_s1: 0.039144, loss_fp: 0.006380, loss_freq: 0.052000
[19:07:10.987] iteration 25534: loss: 0.071929, loss_s1: 0.031966, loss_fp: 0.004138, loss_freq: 0.081442
[19:07:11.613] iteration 25535: loss: 0.029672, loss_s1: 0.012218, loss_fp: 0.001421, loss_freq: 0.013650
[19:07:12.233] iteration 25536: loss: 0.051688, loss_s1: 0.027161, loss_fp: 0.004030, loss_freq: 0.027213
[19:07:12.854] iteration 25537: loss: 0.056331, loss_s1: 0.055854, loss_fp: 0.002414, loss_freq: 0.016554
[19:07:13.479] iteration 25538: loss: 0.064964, loss_s1: 0.058259, loss_fp: 0.001950, loss_freq: 0.024166
[19:07:14.108] iteration 25539: loss: 0.062648, loss_s1: 0.072494, loss_fp: 0.000986, loss_freq: 0.026343
[19:07:14.743] iteration 25540: loss: 0.065246, loss_s1: 0.042432, loss_fp: 0.005009, loss_freq: 0.040582
[19:07:15.371] iteration 25541: loss: 0.058434, loss_s1: 0.036522, loss_fp: 0.006942, loss_freq: 0.038990
[19:07:15.999] iteration 25542: loss: 0.044028, loss_s1: 0.033172, loss_fp: 0.003650, loss_freq: 0.022971
[19:07:16.623] iteration 25543: loss: 0.038188, loss_s1: 0.011472, loss_fp: 0.003211, loss_freq: 0.011977
[19:07:17.247] iteration 25544: loss: 0.041961, loss_s1: 0.029890, loss_fp: 0.002155, loss_freq: 0.023681
[19:07:17.875] iteration 25545: loss: 0.023727, loss_s1: 0.008886, loss_fp: 0.000977, loss_freq: 0.004930
[19:07:18.501] iteration 25546: loss: 0.112082, loss_s1: 0.106475, loss_fp: 0.001021, loss_freq: 0.079841
[19:07:19.123] iteration 25547: loss: 0.072718, loss_s1: 0.044980, loss_fp: 0.007507, loss_freq: 0.049193
[19:07:19.749] iteration 25548: loss: 0.047134, loss_s1: 0.040275, loss_fp: 0.004467, loss_freq: 0.012119
[19:07:20.370] iteration 25549: loss: 0.043920, loss_s1: 0.032037, loss_fp: 0.002577, loss_freq: 0.020942
[19:07:20.995] iteration 25550: loss: 0.052436, loss_s1: 0.047165, loss_fp: 0.002476, loss_freq: 0.025725
[19:07:21.627] iteration 25551: loss: 0.061425, loss_s1: 0.069260, loss_fp: 0.005225, loss_freq: 0.022195
[19:07:22.256] iteration 25552: loss: 0.034077, loss_s1: 0.020374, loss_fp: 0.002736, loss_freq: 0.016635
[19:07:22.888] iteration 25553: loss: 0.035027, loss_s1: 0.025197, loss_fp: 0.000312, loss_freq: 0.002677
[19:07:23.517] iteration 25554: loss: 0.051802, loss_s1: 0.043935, loss_fp: 0.005809, loss_freq: 0.025854
[19:07:24.146] iteration 25555: loss: 0.036475, loss_s1: 0.016947, loss_fp: 0.004501, loss_freq: 0.024026
[19:07:24.773] iteration 25556: loss: 0.036265, loss_s1: 0.036099, loss_fp: 0.002525, loss_freq: 0.005882
[19:07:25.398] iteration 25557: loss: 0.039140, loss_s1: 0.027203, loss_fp: 0.003377, loss_freq: 0.018608
[19:07:26.029] iteration 25558: loss: 0.086790, loss_s1: 0.118306, loss_fp: 0.002674, loss_freq: 0.031313
[19:07:26.656] iteration 25559: loss: 0.048032, loss_s1: 0.053420, loss_fp: 0.004675, loss_freq: 0.008000
[19:07:27.281] iteration 25560: loss: 0.049671, loss_s1: 0.040877, loss_fp: 0.009395, loss_freq: 0.012035
[19:07:27.903] iteration 25561: loss: 0.055048, loss_s1: 0.053124, loss_fp: 0.005023, loss_freq: 0.020324
[19:07:28.528] iteration 25562: loss: 0.051305, loss_s1: 0.049700, loss_fp: 0.001729, loss_freq: 0.013010
[19:07:29.155] iteration 25563: loss: 0.068034, loss_s1: 0.052523, loss_fp: 0.006208, loss_freq: 0.033183
[19:07:29.784] iteration 25564: loss: 0.037397, loss_s1: 0.018482, loss_fp: 0.001062, loss_freq: 0.010372
[19:07:30.411] iteration 25565: loss: 0.036697, loss_s1: 0.034812, loss_fp: 0.001534, loss_freq: 0.002057
[19:07:31.035] iteration 25566: loss: 0.063103, loss_s1: 0.031988, loss_fp: 0.008435, loss_freq: 0.017264
[19:07:31.663] iteration 25567: loss: 0.064363, loss_s1: 0.072603, loss_fp: 0.001160, loss_freq: 0.028969
[19:07:32.290] iteration 25568: loss: 0.036494, loss_s1: 0.022158, loss_fp: 0.001481, loss_freq: 0.019123
[19:07:32.910] iteration 25569: loss: 0.041636, loss_s1: 0.026321, loss_fp: 0.001612, loss_freq: 0.026807
[19:07:33.539] iteration 25570: loss: 0.046943, loss_s1: 0.040693, loss_fp: 0.006776, loss_freq: 0.013929
[19:07:34.158] iteration 25571: loss: 0.051099, loss_s1: 0.049857, loss_fp: 0.003074, loss_freq: 0.009293
[19:07:34.780] iteration 25572: loss: 0.035592, loss_s1: 0.030006, loss_fp: 0.001155, loss_freq: 0.012923
[19:07:35.407] iteration 25573: loss: 0.042686, loss_s1: 0.024436, loss_fp: 0.001548, loss_freq: 0.028737
[19:07:36.033] iteration 25574: loss: 0.061286, loss_s1: 0.066316, loss_fp: 0.003655, loss_freq: 0.022915
[19:07:36.658] iteration 25575: loss: 0.039344, loss_s1: 0.017067, loss_fp: 0.001581, loss_freq: 0.015533
[19:07:37.282] iteration 25576: loss: 0.045072, loss_s1: 0.028448, loss_fp: 0.002661, loss_freq: 0.025228
[19:07:37.909] iteration 25577: loss: 0.052228, loss_s1: 0.029829, loss_fp: 0.002242, loss_freq: 0.018047
[19:07:38.573] iteration 25578: loss: 0.078632, loss_s1: 0.047737, loss_fp: 0.023975, loss_freq: 0.030240
[19:07:39.208] iteration 25579: loss: 0.052876, loss_s1: 0.047265, loss_fp: 0.005255, loss_freq: 0.024396
[19:07:39.844] iteration 25580: loss: 0.048778, loss_s1: 0.037632, loss_fp: 0.001569, loss_freq: 0.025705
[19:07:40.470] iteration 25581: loss: 0.066192, loss_s1: 0.052352, loss_fp: 0.006948, loss_freq: 0.043131
[19:07:41.099] iteration 25582: loss: 0.071698, loss_s1: 0.074305, loss_fp: 0.004464, loss_freq: 0.025668
[19:07:41.729] iteration 25583: loss: 0.030924, loss_s1: 0.025339, loss_fp: 0.004297, loss_freq: 0.001626
[19:07:42.359] iteration 25584: loss: 0.075070, loss_s1: 0.082285, loss_fp: 0.002721, loss_freq: 0.019744
[19:07:42.986] iteration 25585: loss: 0.061765, loss_s1: 0.050831, loss_fp: 0.003226, loss_freq: 0.040794
[19:07:43.649] iteration 25586: loss: 0.032083, loss_s1: 0.029235, loss_fp: 0.003115, loss_freq: 0.004498
[19:07:44.290] iteration 25587: loss: 0.045348, loss_s1: 0.049910, loss_fp: 0.001939, loss_freq: 0.009328
[19:07:44.937] iteration 25588: loss: 0.081935, loss_s1: 0.084397, loss_fp: 0.013096, loss_freq: 0.031501
[19:07:45.572] iteration 25589: loss: 0.053477, loss_s1: 0.041147, loss_fp: 0.005136, loss_freq: 0.010389
[19:07:46.206] iteration 25590: loss: 0.084639, loss_s1: 0.073801, loss_fp: 0.009864, loss_freq: 0.055721
[19:07:46.837] iteration 25591: loss: 0.040209, loss_s1: 0.024727, loss_fp: 0.002821, loss_freq: 0.020863
[19:07:47.505] iteration 25592: loss: 0.066397, loss_s1: 0.060768, loss_fp: 0.003664, loss_freq: 0.023848
[19:07:48.157] iteration 25593: loss: 0.023870, loss_s1: 0.017707, loss_fp: 0.002842, loss_freq: 0.004828
[19:07:48.794] iteration 25594: loss: 0.047820, loss_s1: 0.032728, loss_fp: 0.002699, loss_freq: 0.022791
[19:07:49.416] iteration 25595: loss: 0.045936, loss_s1: 0.019408, loss_fp: 0.000870, loss_freq: 0.021521
[19:07:50.049] iteration 25596: loss: 0.045148, loss_s1: 0.030297, loss_fp: 0.001880, loss_freq: 0.022856
[19:07:50.677] iteration 25597: loss: 0.083425, loss_s1: 0.081549, loss_fp: 0.012261, loss_freq: 0.037584
[19:07:51.305] iteration 25598: loss: 0.042429, loss_s1: 0.023675, loss_fp: 0.003262, loss_freq: 0.021060
[19:07:51.934] iteration 25599: loss: 0.043238, loss_s1: 0.020004, loss_fp: 0.004735, loss_freq: 0.022882
[19:07:52.893] iteration 25600: loss: 0.037256, loss_s1: 0.032940, loss_fp: 0.000886, loss_freq: 0.010488
[19:07:55.953] iteration 25600 : mean_dice : 0.729929
[19:07:56.599] iteration 25601: loss: 0.075778, loss_s1: 0.049729, loss_fp: 0.012073, loss_freq: 0.054053
[19:07:57.229] iteration 25602: loss: 0.035491, loss_s1: 0.016026, loss_fp: 0.005105, loss_freq: 0.011485
[19:07:57.859] iteration 25603: loss: 0.045868, loss_s1: 0.037565, loss_fp: 0.000262, loss_freq: 0.013010
[19:07:58.489] iteration 25604: loss: 0.051118, loss_s1: 0.053962, loss_fp: 0.003692, loss_freq: 0.011216
[19:07:59.114] iteration 25605: loss: 0.064820, loss_s1: 0.036716, loss_fp: 0.005303, loss_freq: 0.045004
[19:07:59.738] iteration 25606: loss: 0.026281, loss_s1: 0.009650, loss_fp: 0.001161, loss_freq: 0.008270
[19:08:00.367] iteration 25607: loss: 0.039373, loss_s1: 0.043337, loss_fp: 0.002601, loss_freq: 0.005426
[19:08:00.994] iteration 25608: loss: 0.063963, loss_s1: 0.053619, loss_fp: 0.003173, loss_freq: 0.036367
[19:08:01.616] iteration 25609: loss: 0.058362, loss_s1: 0.048136, loss_fp: 0.002885, loss_freq: 0.029768
[19:08:02.273] iteration 25610: loss: 0.040873, loss_s1: 0.027513, loss_fp: 0.002045, loss_freq: 0.020547
[19:08:02.898] iteration 25611: loss: 0.057991, loss_s1: 0.067396, loss_fp: 0.002881, loss_freq: 0.015856
[19:08:03.524] iteration 25612: loss: 0.080952, loss_s1: 0.061279, loss_fp: 0.004387, loss_freq: 0.065166
[19:08:04.152] iteration 25613: loss: 0.054160, loss_s1: 0.026564, loss_fp: 0.013656, loss_freq: 0.025064
[19:08:04.784] iteration 25614: loss: 0.045890, loss_s1: 0.037048, loss_fp: 0.001978, loss_freq: 0.021767
[19:08:05.411] iteration 25615: loss: 0.092496, loss_s1: 0.094291, loss_fp: 0.009582, loss_freq: 0.047210
[19:08:06.036] iteration 25616: loss: 0.050228, loss_s1: 0.047655, loss_fp: 0.001893, loss_freq: 0.015083
[19:08:06.687] iteration 25617: loss: 0.043956, loss_s1: 0.027029, loss_fp: 0.011210, loss_freq: 0.022692
[19:08:07.331] iteration 25618: loss: 0.034341, loss_s1: 0.020244, loss_fp: 0.000636, loss_freq: 0.010877
[19:08:07.997] iteration 25619: loss: 0.040411, loss_s1: 0.025499, loss_fp: 0.005234, loss_freq: 0.020772
[19:08:08.632] iteration 25620: loss: 0.041103, loss_s1: 0.017157, loss_fp: 0.001874, loss_freq: 0.017288
[19:08:09.275] iteration 25621: loss: 0.046543, loss_s1: 0.027258, loss_fp: 0.004443, loss_freq: 0.022856
[19:08:09.947] iteration 25622: loss: 0.041116, loss_s1: 0.025409, loss_fp: 0.003243, loss_freq: 0.015080
[19:08:10.580] iteration 25623: loss: 0.033820, loss_s1: 0.017006, loss_fp: 0.008175, loss_freq: 0.014743
[19:08:11.210] iteration 25624: loss: 0.035475, loss_s1: 0.024221, loss_fp: 0.004518, loss_freq: 0.017260
[19:08:11.838] iteration 25625: loss: 0.054847, loss_s1: 0.063780, loss_fp: 0.002024, loss_freq: 0.022000
[19:08:12.462] iteration 25626: loss: 0.024082, loss_s1: 0.012622, loss_fp: 0.000468, loss_freq: 0.007267
[19:08:13.092] iteration 25627: loss: 0.074952, loss_s1: 0.081568, loss_fp: 0.004951, loss_freq: 0.024563
[19:08:13.718] iteration 25628: loss: 0.056847, loss_s1: 0.033472, loss_fp: 0.003801, loss_freq: 0.044028
[19:08:14.344] iteration 25629: loss: 0.035454, loss_s1: 0.018242, loss_fp: 0.005841, loss_freq: 0.010754
[19:08:14.974] iteration 25630: loss: 0.038479, loss_s1: 0.029118, loss_fp: 0.006325, loss_freq: 0.017529
[19:08:15.598] iteration 25631: loss: 0.033759, loss_s1: 0.015810, loss_fp: 0.001051, loss_freq: 0.020948
[19:08:16.224] iteration 25632: loss: 0.037824, loss_s1: 0.019240, loss_fp: 0.003816, loss_freq: 0.026016
[19:08:16.856] iteration 25633: loss: 0.038766, loss_s1: 0.038731, loss_fp: 0.002412, loss_freq: 0.011100
[19:08:17.481] iteration 25634: loss: 0.057470, loss_s1: 0.027232, loss_fp: 0.001799, loss_freq: 0.030052
[19:08:18.106] iteration 25635: loss: 0.085851, loss_s1: 0.084726, loss_fp: 0.003919, loss_freq: 0.048688
[19:08:18.731] iteration 25636: loss: 0.071692, loss_s1: 0.084938, loss_fp: 0.009752, loss_freq: 0.021531
[19:08:19.360] iteration 25637: loss: 0.043796, loss_s1: 0.023952, loss_fp: 0.002653, loss_freq: 0.024778
[19:08:19.986] iteration 25638: loss: 0.068433, loss_s1: 0.043942, loss_fp: 0.010606, loss_freq: 0.040366
[19:08:20.617] iteration 25639: loss: 0.044715, loss_s1: 0.032566, loss_fp: 0.002348, loss_freq: 0.022020
[19:08:21.243] iteration 25640: loss: 0.061151, loss_s1: 0.036736, loss_fp: 0.005860, loss_freq: 0.030970
[19:08:21.870] iteration 25641: loss: 0.054637, loss_s1: 0.056158, loss_fp: 0.003998, loss_freq: 0.018022
[19:08:22.495] iteration 25642: loss: 0.058194, loss_s1: 0.063620, loss_fp: 0.003955, loss_freq: 0.019500
[19:08:23.121] iteration 25643: loss: 0.054378, loss_s1: 0.025654, loss_fp: 0.005126, loss_freq: 0.053259
[19:08:23.749] iteration 25644: loss: 0.033912, loss_s1: 0.014307, loss_fp: 0.001676, loss_freq: 0.016626
[19:08:24.374] iteration 25645: loss: 0.028004, loss_s1: 0.017944, loss_fp: 0.001823, loss_freq: 0.003746
[19:08:25.002] iteration 25646: loss: 0.024804, loss_s1: 0.014289, loss_fp: 0.000341, loss_freq: 0.007394
[19:08:25.628] iteration 25647: loss: 0.057133, loss_s1: 0.042523, loss_fp: 0.009623, loss_freq: 0.025127
[19:08:26.255] iteration 25648: loss: 0.045436, loss_s1: 0.043079, loss_fp: 0.004615, loss_freq: 0.008128
[19:08:26.876] iteration 25649: loss: 0.046945, loss_s1: 0.037252, loss_fp: 0.003072, loss_freq: 0.026544
[19:08:27.510] iteration 25650: loss: 0.068588, loss_s1: 0.039447, loss_fp: 0.016452, loss_freq: 0.051058
[19:08:28.152] iteration 25651: loss: 0.055645, loss_s1: 0.044553, loss_fp: 0.002183, loss_freq: 0.023642
[19:08:28.780] iteration 25652: loss: 0.046768, loss_s1: 0.040053, loss_fp: 0.002047, loss_freq: 0.023169
[19:08:29.416] iteration 25653: loss: 0.048406, loss_s1: 0.030517, loss_fp: 0.004835, loss_freq: 0.031290
[19:08:30.047] iteration 25654: loss: 0.036878, loss_s1: 0.024761, loss_fp: 0.003322, loss_freq: 0.017150
[19:08:30.673] iteration 25655: loss: 0.063154, loss_s1: 0.063712, loss_fp: 0.005888, loss_freq: 0.015696
[19:08:31.300] iteration 25656: loss: 0.036167, loss_s1: 0.016836, loss_fp: 0.002707, loss_freq: 0.020896
[19:08:31.923] iteration 25657: loss: 0.053372, loss_s1: 0.045829, loss_fp: 0.001515, loss_freq: 0.017188
[19:08:32.551] iteration 25658: loss: 0.034025, loss_s1: 0.022564, loss_fp: 0.001948, loss_freq: 0.014958
[19:08:33.189] iteration 25659: loss: 0.041946, loss_s1: 0.035532, loss_fp: 0.001752, loss_freq: 0.020447
[19:08:33.820] iteration 25660: loss: 0.039363, loss_s1: 0.031903, loss_fp: 0.001711, loss_freq: 0.018735
[19:08:34.451] iteration 25661: loss: 0.044645, loss_s1: 0.043001, loss_fp: 0.004901, loss_freq: 0.013293
[19:08:35.076] iteration 25662: loss: 0.044589, loss_s1: 0.029962, loss_fp: 0.002905, loss_freq: 0.022389
[19:08:35.699] iteration 25663: loss: 0.049799, loss_s1: 0.055260, loss_fp: 0.003448, loss_freq: 0.014134
[19:08:36.327] iteration 25664: loss: 0.062678, loss_s1: 0.069391, loss_fp: 0.008702, loss_freq: 0.014767
[19:08:36.947] iteration 25665: loss: 0.073517, loss_s1: 0.043359, loss_fp: 0.012176, loss_freq: 0.063172
[19:08:37.572] iteration 25666: loss: 0.060610, loss_s1: 0.047512, loss_fp: 0.004563, loss_freq: 0.030486
[19:08:38.204] iteration 25667: loss: 0.078514, loss_s1: 0.079653, loss_fp: 0.003915, loss_freq: 0.046718
[19:08:38.891] iteration 25668: loss: 0.048253, loss_s1: 0.044047, loss_fp: 0.003142, loss_freq: 0.015850
[19:08:39.671] iteration 25669: loss: 0.075094, loss_s1: 0.054823, loss_fp: 0.004547, loss_freq: 0.048073
[19:08:40.330] iteration 25670: loss: 0.065515, loss_s1: 0.065907, loss_fp: 0.012086, loss_freq: 0.022117
[19:08:40.957] iteration 25671: loss: 0.037524, loss_s1: 0.035560, loss_fp: 0.001686, loss_freq: 0.008680
[19:08:41.590] iteration 25672: loss: 0.044458, loss_s1: 0.037437, loss_fp: 0.006148, loss_freq: 0.009694
[19:08:42.220] iteration 25673: loss: 0.029274, loss_s1: 0.014181, loss_fp: 0.001813, loss_freq: 0.006554
[19:08:42.846] iteration 25674: loss: 0.047227, loss_s1: 0.029831, loss_fp: 0.006142, loss_freq: 0.030611
[19:08:43.481] iteration 25675: loss: 0.098981, loss_s1: 0.120154, loss_fp: 0.004949, loss_freq: 0.029534
[19:08:44.115] iteration 25676: loss: 0.037299, loss_s1: 0.022747, loss_fp: 0.001744, loss_freq: 0.020490
[19:08:44.746] iteration 25677: loss: 0.035610, loss_s1: 0.025628, loss_fp: 0.004460, loss_freq: 0.017886
[19:08:45.371] iteration 25678: loss: 0.041530, loss_s1: 0.040948, loss_fp: 0.001719, loss_freq: 0.008192
[19:08:45.999] iteration 25679: loss: 0.046195, loss_s1: 0.028521, loss_fp: 0.001406, loss_freq: 0.033286
[19:08:46.624] iteration 25680: loss: 0.058715, loss_s1: 0.043672, loss_fp: 0.008292, loss_freq: 0.033799
[19:08:47.252] iteration 25681: loss: 0.051030, loss_s1: 0.052114, loss_fp: 0.001381, loss_freq: 0.018154
[19:08:47.885] iteration 25682: loss: 0.088108, loss_s1: 0.064298, loss_fp: 0.017684, loss_freq: 0.056412
[19:08:48.508] iteration 25683: loss: 0.068407, loss_s1: 0.086397, loss_fp: 0.004035, loss_freq: 0.012534
[19:08:49.155] iteration 25684: loss: 0.062963, loss_s1: 0.073886, loss_fp: 0.003628, loss_freq: 0.024020
[19:08:49.784] iteration 25685: loss: 0.044513, loss_s1: 0.037139, loss_fp: 0.007253, loss_freq: 0.015677
[19:08:50.414] iteration 25686: loss: 0.059786, loss_s1: 0.058300, loss_fp: 0.011077, loss_freq: 0.006079
[19:08:51.038] iteration 25687: loss: 0.053862, loss_s1: 0.049253, loss_fp: 0.011480, loss_freq: 0.014636
[19:08:51.670] iteration 25688: loss: 0.036130, loss_s1: 0.020806, loss_fp: 0.011400, loss_freq: 0.005762
[19:08:52.301] iteration 25689: loss: 0.045716, loss_s1: 0.039210, loss_fp: 0.000724, loss_freq: 0.016182
[19:08:52.953] iteration 25690: loss: 0.072621, loss_s1: 0.074645, loss_fp: 0.001811, loss_freq: 0.026688
[19:08:53.591] iteration 25691: loss: 0.061081, loss_s1: 0.045777, loss_fp: 0.007634, loss_freq: 0.024711
[19:08:54.222] iteration 25692: loss: 0.068932, loss_s1: 0.025604, loss_fp: 0.001539, loss_freq: 0.017132
[19:08:54.853] iteration 25693: loss: 0.030949, loss_s1: 0.014482, loss_fp: 0.002228, loss_freq: 0.015569
[19:08:55.484] iteration 25694: loss: 0.043579, loss_s1: 0.038560, loss_fp: 0.006188, loss_freq: 0.019954
[19:08:56.110] iteration 25695: loss: 0.052212, loss_s1: 0.014681, loss_fp: 0.010988, loss_freq: 0.047052
[19:08:56.743] iteration 25696: loss: 0.036821, loss_s1: 0.023290, loss_fp: 0.002650, loss_freq: 0.018074
[19:08:57.373] iteration 25697: loss: 0.059292, loss_s1: 0.042644, loss_fp: 0.002183, loss_freq: 0.031026
[19:08:58.001] iteration 25698: loss: 0.044553, loss_s1: 0.037790, loss_fp: 0.001233, loss_freq: 0.019633
[19:08:58.631] iteration 25699: loss: 0.074390, loss_s1: 0.098094, loss_fp: 0.001451, loss_freq: 0.019205
[19:08:59.260] iteration 25700: loss: 0.044972, loss_s1: 0.031664, loss_fp: 0.005966, loss_freq: 0.023460
[19:08:59.895] iteration 25701: loss: 0.100104, loss_s1: 0.057219, loss_fp: 0.008306, loss_freq: 0.076841
[19:09:00.525] iteration 25702: loss: 0.062599, loss_s1: 0.052905, loss_fp: 0.001379, loss_freq: 0.029960
[19:09:01.152] iteration 25703: loss: 0.066064, loss_s1: 0.064865, loss_fp: 0.002168, loss_freq: 0.034477
[19:09:01.779] iteration 25704: loss: 0.065977, loss_s1: 0.051120, loss_fp: 0.004077, loss_freq: 0.018494
[19:09:02.406] iteration 25705: loss: 0.047040, loss_s1: 0.032977, loss_fp: 0.003283, loss_freq: 0.020070
[19:09:03.037] iteration 25706: loss: 0.032398, loss_s1: 0.024802, loss_fp: 0.001732, loss_freq: 0.006848
[19:09:03.668] iteration 25707: loss: 0.060333, loss_s1: 0.061235, loss_fp: 0.001316, loss_freq: 0.026480
[19:09:04.298] iteration 25708: loss: 0.092666, loss_s1: 0.066811, loss_fp: 0.005868, loss_freq: 0.071627
[19:09:04.926] iteration 25709: loss: 0.055078, loss_s1: 0.061072, loss_fp: 0.002150, loss_freq: 0.017345
[19:09:05.553] iteration 25710: loss: 0.063078, loss_s1: 0.052886, loss_fp: 0.009174, loss_freq: 0.026984
[19:09:06.179] iteration 25711: loss: 0.044231, loss_s1: 0.028219, loss_fp: 0.003216, loss_freq: 0.027517
[19:09:06.804] iteration 25712: loss: 0.039656, loss_s1: 0.021348, loss_fp: 0.004517, loss_freq: 0.023464
[19:09:07.432] iteration 25713: loss: 0.048162, loss_s1: 0.033145, loss_fp: 0.003242, loss_freq: 0.029027
[19:09:08.058] iteration 25714: loss: 0.031795, loss_s1: 0.018671, loss_fp: 0.000698, loss_freq: 0.005970
[19:09:08.680] iteration 25715: loss: 0.072379, loss_s1: 0.075560, loss_fp: 0.004741, loss_freq: 0.033249
[19:09:09.309] iteration 25716: loss: 0.024060, loss_s1: 0.007649, loss_fp: 0.004239, loss_freq: 0.010197
[19:09:09.935] iteration 25717: loss: 0.055387, loss_s1: 0.062724, loss_fp: 0.004311, loss_freq: 0.015548
[19:09:10.564] iteration 25718: loss: 0.052952, loss_s1: 0.033103, loss_fp: 0.004197, loss_freq: 0.035672
[19:09:11.187] iteration 25719: loss: 0.099657, loss_s1: 0.088786, loss_fp: 0.013298, loss_freq: 0.071092
[19:09:11.813] iteration 25720: loss: 0.039621, loss_s1: 0.016455, loss_fp: 0.016611, loss_freq: 0.017062
[19:09:12.442] iteration 25721: loss: 0.058908, loss_s1: 0.039969, loss_fp: 0.007331, loss_freq: 0.036696
[19:09:13.067] iteration 25722: loss: 0.077450, loss_s1: 0.078937, loss_fp: 0.008165, loss_freq: 0.024670
[19:09:13.745] iteration 25723: loss: 0.046313, loss_s1: 0.029876, loss_fp: 0.004290, loss_freq: 0.009747
[19:09:14.383] iteration 25724: loss: 0.042388, loss_s1: 0.030631, loss_fp: 0.002618, loss_freq: 0.020632
[19:09:15.012] iteration 25725: loss: 0.039052, loss_s1: 0.023934, loss_fp: 0.009796, loss_freq: 0.009963
[19:09:15.644] iteration 25726: loss: 0.040690, loss_s1: 0.025487, loss_fp: 0.001006, loss_freq: 0.024324
[19:09:16.271] iteration 25727: loss: 0.106978, loss_s1: 0.087457, loss_fp: 0.005309, loss_freq: 0.082964
[19:09:16.903] iteration 25728: loss: 0.058334, loss_s1: 0.037602, loss_fp: 0.018213, loss_freq: 0.030984
[19:09:17.534] iteration 25729: loss: 0.054977, loss_s1: 0.054383, loss_fp: 0.003364, loss_freq: 0.017752
[19:09:18.168] iteration 25730: loss: 0.062717, loss_s1: 0.066858, loss_fp: 0.002377, loss_freq: 0.031661
[19:09:18.801] iteration 25731: loss: 0.070022, loss_s1: 0.074652, loss_fp: 0.004405, loss_freq: 0.018978
[19:09:19.434] iteration 25732: loss: 0.052637, loss_s1: 0.040175, loss_fp: 0.003980, loss_freq: 0.019114
[19:09:20.060] iteration 25733: loss: 0.055031, loss_s1: 0.048928, loss_fp: 0.003136, loss_freq: 0.019480
[19:09:20.692] iteration 25734: loss: 0.047122, loss_s1: 0.033231, loss_fp: 0.006599, loss_freq: 0.028889
[19:09:21.318] iteration 25735: loss: 0.050889, loss_s1: 0.053577, loss_fp: 0.004339, loss_freq: 0.013911
[19:09:21.944] iteration 25736: loss: 0.037279, loss_s1: 0.012251, loss_fp: 0.000661, loss_freq: 0.015237
[19:09:22.566] iteration 25737: loss: 0.049221, loss_s1: 0.033481, loss_fp: 0.002703, loss_freq: 0.034066
[19:09:23.195] iteration 25738: loss: 0.053347, loss_s1: 0.049960, loss_fp: 0.001638, loss_freq: 0.028221
[19:09:23.821] iteration 25739: loss: 0.084926, loss_s1: 0.109164, loss_fp: 0.002502, loss_freq: 0.017560
[19:09:24.457] iteration 25740: loss: 0.042297, loss_s1: 0.030118, loss_fp: 0.003709, loss_freq: 0.022835
[19:09:25.083] iteration 25741: loss: 0.038399, loss_s1: 0.024792, loss_fp: 0.002013, loss_freq: 0.021049
[19:09:25.715] iteration 25742: loss: 0.072756, loss_s1: 0.073985, loss_fp: 0.005212, loss_freq: 0.009847
[19:09:26.345] iteration 25743: loss: 0.051515, loss_s1: 0.044283, loss_fp: 0.002494, loss_freq: 0.017187
[19:09:26.977] iteration 25744: loss: 0.039977, loss_s1: 0.034768, loss_fp: 0.001960, loss_freq: 0.009513
[19:09:27.608] iteration 25745: loss: 0.071870, loss_s1: 0.048500, loss_fp: 0.008951, loss_freq: 0.053555
[19:09:28.235] iteration 25746: loss: 0.071464, loss_s1: 0.061225, loss_fp: 0.015203, loss_freq: 0.034702
[19:09:28.859] iteration 25747: loss: 0.030396, loss_s1: 0.021886, loss_fp: 0.001598, loss_freq: 0.007239
[19:09:29.486] iteration 25748: loss: 0.029269, loss_s1: 0.015736, loss_fp: 0.002912, loss_freq: 0.017263
[19:09:30.113] iteration 25749: loss: 0.055106, loss_s1: 0.028325, loss_fp: 0.006414, loss_freq: 0.039334
[19:09:30.742] iteration 25750: loss: 0.077191, loss_s1: 0.065932, loss_fp: 0.005696, loss_freq: 0.048314
[19:09:31.377] iteration 25751: loss: 0.044900, loss_s1: 0.033277, loss_fp: 0.004427, loss_freq: 0.024840
[19:09:32.004] iteration 25752: loss: 0.051965, loss_s1: 0.042504, loss_fp: 0.002506, loss_freq: 0.032535
[19:09:32.633] iteration 25753: loss: 0.046728, loss_s1: 0.037605, loss_fp: 0.005768, loss_freq: 0.017288
[19:09:33.262] iteration 25754: loss: 0.029918, loss_s1: 0.018726, loss_fp: 0.003343, loss_freq: 0.006861
[19:09:33.895] iteration 25755: loss: 0.045650, loss_s1: 0.037308, loss_fp: 0.002744, loss_freq: 0.012017
[19:09:34.518] iteration 25756: loss: 0.029089, loss_s1: 0.007999, loss_fp: 0.000726, loss_freq: 0.010876
[19:09:35.139] iteration 25757: loss: 0.037260, loss_s1: 0.009105, loss_fp: 0.007295, loss_freq: 0.022547
[19:09:35.767] iteration 25758: loss: 0.069503, loss_s1: 0.071300, loss_fp: 0.007439, loss_freq: 0.026395
[19:09:36.396] iteration 25759: loss: 0.058512, loss_s1: 0.028602, loss_fp: 0.003417, loss_freq: 0.055524
[19:09:37.027] iteration 25760: loss: 0.029245, loss_s1: 0.014945, loss_fp: 0.000719, loss_freq: 0.010616
[19:09:37.976] iteration 25761: loss: 0.035407, loss_s1: 0.033022, loss_fp: 0.001424, loss_freq: 0.005308
[19:09:38.624] iteration 25762: loss: 0.091971, loss_s1: 0.092455, loss_fp: 0.011377, loss_freq: 0.047504
[19:09:39.259] iteration 25763: loss: 0.044715, loss_s1: 0.023421, loss_fp: 0.000809, loss_freq: 0.012878
[19:09:39.890] iteration 25764: loss: 0.057940, loss_s1: 0.031757, loss_fp: 0.017151, loss_freq: 0.029355
[19:09:40.519] iteration 25765: loss: 0.065381, loss_s1: 0.064447, loss_fp: 0.001930, loss_freq: 0.031997
[19:09:41.148] iteration 25766: loss: 0.069792, loss_s1: 0.046328, loss_fp: 0.013255, loss_freq: 0.043215
[19:09:41.778] iteration 25767: loss: 0.040579, loss_s1: 0.023651, loss_fp: 0.006828, loss_freq: 0.014115
[19:09:42.412] iteration 25768: loss: 0.043980, loss_s1: 0.045666, loss_fp: 0.000867, loss_freq: 0.012446
[19:09:43.042] iteration 25769: loss: 0.063591, loss_s1: 0.057741, loss_fp: 0.001258, loss_freq: 0.040449
[19:09:43.670] iteration 25770: loss: 0.087191, loss_s1: 0.087655, loss_fp: 0.010581, loss_freq: 0.041009
[19:09:44.315] iteration 25771: loss: 0.033509, loss_s1: 0.018726, loss_fp: 0.002064, loss_freq: 0.011876
[19:09:44.956] iteration 25772: loss: 0.056422, loss_s1: 0.060166, loss_fp: 0.003956, loss_freq: 0.020447
[19:09:45.602] iteration 25773: loss: 0.063404, loss_s1: 0.044264, loss_fp: 0.004139, loss_freq: 0.047197
[19:09:46.249] iteration 25774: loss: 0.059527, loss_s1: 0.021000, loss_fp: 0.011221, loss_freq: 0.033141
[19:09:46.892] iteration 25775: loss: 0.052447, loss_s1: 0.040135, loss_fp: 0.004982, loss_freq: 0.027026
[19:09:47.533] iteration 25776: loss: 0.063424, loss_s1: 0.047277, loss_fp: 0.001124, loss_freq: 0.045175
[19:09:48.168] iteration 25777: loss: 0.048465, loss_s1: 0.044386, loss_fp: 0.002471, loss_freq: 0.011957
[19:09:48.811] iteration 25778: loss: 0.051266, loss_s1: 0.040778, loss_fp: 0.001672, loss_freq: 0.022757
[19:09:49.449] iteration 25779: loss: 0.038566, loss_s1: 0.025258, loss_fp: 0.001634, loss_freq: 0.016076
[19:09:50.088] iteration 25780: loss: 0.047338, loss_s1: 0.038241, loss_fp: 0.001382, loss_freq: 0.023668
[19:09:50.723] iteration 25781: loss: 0.031461, loss_s1: 0.006826, loss_fp: 0.003559, loss_freq: 0.014417
[19:09:51.348] iteration 25782: loss: 0.054776, loss_s1: 0.015262, loss_fp: 0.001345, loss_freq: 0.016459
[19:09:51.972] iteration 25783: loss: 0.047298, loss_s1: 0.024495, loss_fp: 0.000618, loss_freq: 0.022449
[19:09:52.600] iteration 25784: loss: 0.045979, loss_s1: 0.029529, loss_fp: 0.005297, loss_freq: 0.020166
[19:09:53.222] iteration 25785: loss: 0.047417, loss_s1: 0.038638, loss_fp: 0.001158, loss_freq: 0.031326
[19:09:53.845] iteration 25786: loss: 0.089189, loss_s1: 0.083763, loss_fp: 0.005368, loss_freq: 0.042475
[19:09:54.473] iteration 25787: loss: 0.033609, loss_s1: 0.020034, loss_fp: 0.002497, loss_freq: 0.003693
[19:09:55.099] iteration 25788: loss: 0.051943, loss_s1: 0.045033, loss_fp: 0.005537, loss_freq: 0.022318
[19:09:55.726] iteration 25789: loss: 0.054634, loss_s1: 0.029746, loss_fp: 0.003793, loss_freq: 0.042085
[19:09:56.350] iteration 25790: loss: 0.039010, loss_s1: 0.034640, loss_fp: 0.004259, loss_freq: 0.011242
[19:09:56.980] iteration 25791: loss: 0.054581, loss_s1: 0.056522, loss_fp: 0.003947, loss_freq: 0.023832
[19:09:57.611] iteration 25792: loss: 0.033896, loss_s1: 0.021383, loss_fp: 0.006512, loss_freq: 0.006215
[19:09:58.236] iteration 25793: loss: 0.042206, loss_s1: 0.024357, loss_fp: 0.000625, loss_freq: 0.031388
[19:09:58.864] iteration 25794: loss: 0.032971, loss_s1: 0.032535, loss_fp: 0.000722, loss_freq: 0.005711
[19:09:59.488] iteration 25795: loss: 0.045817, loss_s1: 0.022420, loss_fp: 0.001610, loss_freq: 0.014560
[19:10:00.118] iteration 25796: loss: 0.041460, loss_s1: 0.022544, loss_fp: 0.006127, loss_freq: 0.023204
[19:10:00.740] iteration 25797: loss: 0.062732, loss_s1: 0.037308, loss_fp: 0.015329, loss_freq: 0.022430
[19:10:01.371] iteration 25798: loss: 0.035658, loss_s1: 0.024691, loss_fp: 0.001190, loss_freq: 0.015615
[19:10:02.001] iteration 25799: loss: 0.074100, loss_s1: 0.084483, loss_fp: 0.007092, loss_freq: 0.016319
[19:10:02.637] iteration 25800: loss: 0.038896, loss_s1: 0.026569, loss_fp: 0.000936, loss_freq: 0.010722
[19:10:05.770] iteration 25800 : mean_dice : 0.737049
[19:10:06.422] iteration 25801: loss: 0.040600, loss_s1: 0.034287, loss_fp: 0.003271, loss_freq: 0.006202
[19:10:07.045] iteration 25802: loss: 0.085251, loss_s1: 0.095905, loss_fp: 0.003711, loss_freq: 0.045786
[19:10:07.667] iteration 25803: loss: 0.073340, loss_s1: 0.081624, loss_fp: 0.007164, loss_freq: 0.027865
[19:10:08.289] iteration 25804: loss: 0.060125, loss_s1: 0.037011, loss_fp: 0.002284, loss_freq: 0.048953
[19:10:08.914] iteration 25805: loss: 0.049420, loss_s1: 0.032193, loss_fp: 0.004744, loss_freq: 0.028451
[19:10:09.539] iteration 25806: loss: 0.044375, loss_s1: 0.040983, loss_fp: 0.001733, loss_freq: 0.005992
[19:10:10.213] iteration 25807: loss: 0.027245, loss_s1: 0.017102, loss_fp: 0.001843, loss_freq: 0.005398
[19:10:10.845] iteration 25808: loss: 0.045601, loss_s1: 0.038651, loss_fp: 0.007896, loss_freq: 0.016845
[19:10:11.474] iteration 25809: loss: 0.064377, loss_s1: 0.045465, loss_fp: 0.001258, loss_freq: 0.038467
[19:10:12.107] iteration 25810: loss: 0.040200, loss_s1: 0.023295, loss_fp: 0.004080, loss_freq: 0.021952
[19:10:12.740] iteration 25811: loss: 0.036454, loss_s1: 0.022971, loss_fp: 0.002445, loss_freq: 0.020704
[19:10:13.378] iteration 25812: loss: 0.068821, loss_s1: 0.082791, loss_fp: 0.001887, loss_freq: 0.016693
[19:10:14.013] iteration 25813: loss: 0.057985, loss_s1: 0.037130, loss_fp: 0.004425, loss_freq: 0.047794
[19:10:14.647] iteration 25814: loss: 0.067085, loss_s1: 0.033231, loss_fp: 0.006038, loss_freq: 0.049240
[19:10:15.288] iteration 25815: loss: 0.050240, loss_s1: 0.046562, loss_fp: 0.003291, loss_freq: 0.010101
[19:10:15.931] iteration 25816: loss: 0.046258, loss_s1: 0.032599, loss_fp: 0.003513, loss_freq: 0.020724
[19:10:16.578] iteration 25817: loss: 0.031932, loss_s1: 0.016132, loss_fp: 0.001297, loss_freq: 0.009767
[19:10:17.208] iteration 25818: loss: 0.055561, loss_s1: 0.044535, loss_fp: 0.001393, loss_freq: 0.015467
[19:10:17.843] iteration 25819: loss: 0.028672, loss_s1: 0.023655, loss_fp: 0.002157, loss_freq: 0.004948
[19:10:18.476] iteration 25820: loss: 0.046035, loss_s1: 0.038170, loss_fp: 0.011081, loss_freq: 0.020558
[19:10:19.113] iteration 25821: loss: 0.038987, loss_s1: 0.028870, loss_fp: 0.001987, loss_freq: 0.022644
[19:10:19.742] iteration 25822: loss: 0.044253, loss_s1: 0.015340, loss_fp: 0.012286, loss_freq: 0.031640
[19:10:20.373] iteration 25823: loss: 0.031172, loss_s1: 0.014299, loss_fp: 0.000350, loss_freq: 0.007627
[19:10:21.004] iteration 25824: loss: 0.044038, loss_s1: 0.026573, loss_fp: 0.002718, loss_freq: 0.018783
[19:10:21.632] iteration 25825: loss: 0.035651, loss_s1: 0.020178, loss_fp: 0.000287, loss_freq: 0.023002
[19:10:22.264] iteration 25826: loss: 0.066629, loss_s1: 0.029388, loss_fp: 0.010018, loss_freq: 0.063567
[19:10:22.889] iteration 25827: loss: 0.055423, loss_s1: 0.034283, loss_fp: 0.002384, loss_freq: 0.031682
[19:10:23.546] iteration 25828: loss: 0.060938, loss_s1: 0.057370, loss_fp: 0.001814, loss_freq: 0.035560
[19:10:24.180] iteration 25829: loss: 0.050090, loss_s1: 0.043839, loss_fp: 0.005706, loss_freq: 0.023469
[19:10:24.804] iteration 25830: loss: 0.038110, loss_s1: 0.024218, loss_fp: 0.005723, loss_freq: 0.008832
[19:10:25.427] iteration 25831: loss: 0.097190, loss_s1: 0.067815, loss_fp: 0.007008, loss_freq: 0.069583
[19:10:26.055] iteration 25832: loss: 0.064452, loss_s1: 0.058590, loss_fp: 0.010651, loss_freq: 0.028738
[19:10:26.680] iteration 25833: loss: 0.062736, loss_s1: 0.063318, loss_fp: 0.012134, loss_freq: 0.019267
[19:10:27.308] iteration 25834: loss: 0.041933, loss_s1: 0.030617, loss_fp: 0.005934, loss_freq: 0.009225
[19:10:27.932] iteration 25835: loss: 0.067470, loss_s1: 0.078457, loss_fp: 0.001300, loss_freq: 0.021228
[19:10:28.559] iteration 25836: loss: 0.044119, loss_s1: 0.026640, loss_fp: 0.012400, loss_freq: 0.013705
[19:10:29.183] iteration 25837: loss: 0.045321, loss_s1: 0.029880, loss_fp: 0.003478, loss_freq: 0.022707
[19:10:29.807] iteration 25838: loss: 0.039188, loss_s1: 0.021920, loss_fp: 0.005184, loss_freq: 0.014193
[19:10:30.442] iteration 25839: loss: 0.038509, loss_s1: 0.026875, loss_fp: 0.003247, loss_freq: 0.023768
[19:10:31.073] iteration 25840: loss: 0.055542, loss_s1: 0.041330, loss_fp: 0.010585, loss_freq: 0.021087
[19:10:31.707] iteration 25841: loss: 0.042551, loss_s1: 0.035648, loss_fp: 0.007030, loss_freq: 0.011427
[19:10:32.339] iteration 25842: loss: 0.064950, loss_s1: 0.078941, loss_fp: 0.000748, loss_freq: 0.026866
[19:10:32.967] iteration 25843: loss: 0.077839, loss_s1: 0.096985, loss_fp: 0.005389, loss_freq: 0.026265
[19:10:33.598] iteration 25844: loss: 0.072406, loss_s1: 0.062025, loss_fp: 0.004308, loss_freq: 0.050538
[19:10:34.243] iteration 25845: loss: 0.082791, loss_s1: 0.091517, loss_fp: 0.003660, loss_freq: 0.039424
[19:10:34.870] iteration 25846: loss: 0.041530, loss_s1: 0.029957, loss_fp: 0.003052, loss_freq: 0.020296
[19:10:35.503] iteration 25847: loss: 0.073565, loss_s1: 0.075726, loss_fp: 0.003094, loss_freq: 0.014847
[19:10:36.127] iteration 25848: loss: 0.055727, loss_s1: 0.053631, loss_fp: 0.005677, loss_freq: 0.021237
[19:10:36.756] iteration 25849: loss: 0.071079, loss_s1: 0.042879, loss_fp: 0.019262, loss_freq: 0.046258
[19:10:37.393] iteration 25850: loss: 0.069379, loss_s1: 0.050491, loss_fp: 0.002656, loss_freq: 0.039746
[19:10:38.031] iteration 25851: loss: 0.062543, loss_s1: 0.048021, loss_fp: 0.006500, loss_freq: 0.028197
[19:10:38.661] iteration 25852: loss: 0.063616, loss_s1: 0.064021, loss_fp: 0.002819, loss_freq: 0.022839
[19:10:39.287] iteration 25853: loss: 0.058955, loss_s1: 0.024387, loss_fp: 0.004521, loss_freq: 0.018638
[19:10:39.917] iteration 25854: loss: 0.034576, loss_s1: 0.022921, loss_fp: 0.002603, loss_freq: 0.017896
[19:10:40.547] iteration 25855: loss: 0.054447, loss_s1: 0.046363, loss_fp: 0.000808, loss_freq: 0.026703
[19:10:41.179] iteration 25856: loss: 0.035648, loss_s1: 0.014785, loss_fp: 0.001092, loss_freq: 0.027107
[19:10:41.806] iteration 25857: loss: 0.036837, loss_s1: 0.011157, loss_fp: 0.001196, loss_freq: 0.018748
[19:10:42.431] iteration 25858: loss: 0.053207, loss_s1: 0.024618, loss_fp: 0.002129, loss_freq: 0.043535
[19:10:43.060] iteration 25859: loss: 0.032039, loss_s1: 0.016710, loss_fp: 0.005848, loss_freq: 0.015100
[19:10:43.744] iteration 25860: loss: 0.060696, loss_s1: 0.075279, loss_fp: 0.002967, loss_freq: 0.011813
[19:10:44.384] iteration 25861: loss: 0.057300, loss_s1: 0.053925, loss_fp: 0.003678, loss_freq: 0.030772
[19:10:45.036] iteration 25862: loss: 0.064541, loss_s1: 0.043417, loss_fp: 0.004830, loss_freq: 0.050508
[19:10:45.668] iteration 25863: loss: 0.051472, loss_s1: 0.034337, loss_fp: 0.002974, loss_freq: 0.030841
[19:10:46.296] iteration 25864: loss: 0.050490, loss_s1: 0.048638, loss_fp: 0.002650, loss_freq: 0.016671
[19:10:46.922] iteration 25865: loss: 0.040742, loss_s1: 0.023461, loss_fp: 0.001194, loss_freq: 0.019144
[19:10:47.548] iteration 25866: loss: 0.041350, loss_s1: 0.031971, loss_fp: 0.010836, loss_freq: 0.012569
[19:10:48.175] iteration 25867: loss: 0.029090, loss_s1: 0.026237, loss_fp: 0.000793, loss_freq: 0.002954
[19:10:48.807] iteration 25868: loss: 0.051172, loss_s1: 0.037790, loss_fp: 0.000887, loss_freq: 0.030619
[19:10:49.436] iteration 25869: loss: 0.073929, loss_s1: 0.058674, loss_fp: 0.006452, loss_freq: 0.049226
[19:10:50.069] iteration 25870: loss: 0.051296, loss_s1: 0.045665, loss_fp: 0.003405, loss_freq: 0.024874
[19:10:50.701] iteration 25871: loss: 0.049379, loss_s1: 0.037933, loss_fp: 0.002480, loss_freq: 0.017037
[19:10:51.332] iteration 25872: loss: 0.053193, loss_s1: 0.024806, loss_fp: 0.008873, loss_freq: 0.037391
[19:10:51.960] iteration 25873: loss: 0.039086, loss_s1: 0.035171, loss_fp: 0.003758, loss_freq: 0.012975
[19:10:52.588] iteration 25874: loss: 0.045711, loss_s1: 0.024067, loss_fp: 0.002978, loss_freq: 0.028487
[19:10:53.211] iteration 25875: loss: 0.038068, loss_s1: 0.028826, loss_fp: 0.003377, loss_freq: 0.009139
[19:10:53.841] iteration 25876: loss: 0.069077, loss_s1: 0.046827, loss_fp: 0.008366, loss_freq: 0.051228
[19:10:54.473] iteration 25877: loss: 0.041936, loss_s1: 0.033466, loss_fp: 0.001974, loss_freq: 0.013229
[19:10:55.140] iteration 25878: loss: 0.032512, loss_s1: 0.024877, loss_fp: 0.002450, loss_freq: 0.011795
[19:10:55.771] iteration 25879: loss: 0.043278, loss_s1: 0.023448, loss_fp: 0.002310, loss_freq: 0.032447
[19:10:56.413] iteration 25880: loss: 0.076317, loss_s1: 0.042563, loss_fp: 0.002210, loss_freq: 0.079648
[19:10:57.046] iteration 25881: loss: 0.063702, loss_s1: 0.063253, loss_fp: 0.001753, loss_freq: 0.026339
[19:10:57.685] iteration 25882: loss: 0.061701, loss_s1: 0.057896, loss_fp: 0.010432, loss_freq: 0.019784
[19:10:58.311] iteration 25883: loss: 0.036624, loss_s1: 0.033355, loss_fp: 0.001417, loss_freq: 0.008296
[19:10:58.939] iteration 25884: loss: 0.047973, loss_s1: 0.040191, loss_fp: 0.001745, loss_freq: 0.019781
[19:10:59.567] iteration 25885: loss: 0.047808, loss_s1: 0.042699, loss_fp: 0.003085, loss_freq: 0.024087
[19:11:00.193] iteration 25886: loss: 0.041540, loss_s1: 0.019517, loss_fp: 0.000866, loss_freq: 0.019225
[19:11:00.823] iteration 25887: loss: 0.049361, loss_s1: 0.044982, loss_fp: 0.007506, loss_freq: 0.009022
[19:11:01.451] iteration 25888: loss: 0.087920, loss_s1: 0.071418, loss_fp: 0.002453, loss_freq: 0.058698
[19:11:02.082] iteration 25889: loss: 0.083768, loss_s1: 0.071847, loss_fp: 0.009337, loss_freq: 0.060098
[19:11:02.706] iteration 25890: loss: 0.047089, loss_s1: 0.053489, loss_fp: 0.003191, loss_freq: 0.009102
[19:11:03.327] iteration 25891: loss: 0.047367, loss_s1: 0.051571, loss_fp: 0.001632, loss_freq: 0.014083
[19:11:03.959] iteration 25892: loss: 0.065818, loss_s1: 0.063496, loss_fp: 0.002696, loss_freq: 0.035746
[19:11:04.586] iteration 25893: loss: 0.047402, loss_s1: 0.049929, loss_fp: 0.001412, loss_freq: 0.011504
[19:11:05.209] iteration 25894: loss: 0.037440, loss_s1: 0.025947, loss_fp: 0.004993, loss_freq: 0.008992
[19:11:05.841] iteration 25895: loss: 0.058150, loss_s1: 0.049040, loss_fp: 0.004565, loss_freq: 0.033564
[19:11:06.466] iteration 25896: loss: 0.071362, loss_s1: 0.070473, loss_fp: 0.005540, loss_freq: 0.037392
[19:11:07.096] iteration 25897: loss: 0.053425, loss_s1: 0.045611, loss_fp: 0.001493, loss_freq: 0.019819
[19:11:07.719] iteration 25898: loss: 0.036640, loss_s1: 0.032827, loss_fp: 0.001603, loss_freq: 0.014233
[19:11:08.344] iteration 25899: loss: 0.039171, loss_s1: 0.026099, loss_fp: 0.004589, loss_freq: 0.019583
[19:11:08.970] iteration 25900: loss: 0.054214, loss_s1: 0.025973, loss_fp: 0.004860, loss_freq: 0.032407
[19:11:09.628] iteration 25901: loss: 0.036057, loss_s1: 0.019169, loss_fp: 0.002982, loss_freq: 0.013418
[19:11:10.259] iteration 25902: loss: 0.049384, loss_s1: 0.040191, loss_fp: 0.003423, loss_freq: 0.024311
[19:11:10.901] iteration 25903: loss: 0.052195, loss_s1: 0.029595, loss_fp: 0.008871, loss_freq: 0.036774
[19:11:11.530] iteration 25904: loss: 0.052303, loss_s1: 0.049900, loss_fp: 0.002302, loss_freq: 0.013127
[19:11:12.152] iteration 25905: loss: 0.027010, loss_s1: 0.009283, loss_fp: 0.001981, loss_freq: 0.010365
[19:11:12.777] iteration 25906: loss: 0.046687, loss_s1: 0.032915, loss_fp: 0.006010, loss_freq: 0.012396
[19:11:13.402] iteration 25907: loss: 0.056592, loss_s1: 0.027388, loss_fp: 0.007777, loss_freq: 0.049636
[19:11:14.026] iteration 25908: loss: 0.029202, loss_s1: 0.012968, loss_fp: 0.002423, loss_freq: 0.011382
[19:11:14.652] iteration 25909: loss: 0.041391, loss_s1: 0.039820, loss_fp: 0.006817, loss_freq: 0.010674
[19:11:15.272] iteration 25910: loss: 0.088424, loss_s1: 0.071876, loss_fp: 0.004020, loss_freq: 0.065829
[19:11:15.903] iteration 25911: loss: 0.057737, loss_s1: 0.039727, loss_fp: 0.002051, loss_freq: 0.041983
[19:11:16.537] iteration 25912: loss: 0.059606, loss_s1: 0.032729, loss_fp: 0.007582, loss_freq: 0.049561
[19:11:17.157] iteration 25913: loss: 0.048676, loss_s1: 0.050004, loss_fp: 0.005085, loss_freq: 0.014800
[19:11:17.784] iteration 25914: loss: 0.062648, loss_s1: 0.075396, loss_fp: 0.004352, loss_freq: 0.013952
[19:11:18.411] iteration 25915: loss: 0.028089, loss_s1: 0.018582, loss_fp: 0.001507, loss_freq: 0.002840
[19:11:19.089] iteration 25916: loss: 0.037505, loss_s1: 0.034135, loss_fp: 0.002088, loss_freq: 0.004806
[19:11:19.726] iteration 25917: loss: 0.031243, loss_s1: 0.011522, loss_fp: 0.000564, loss_freq: 0.011524
[19:11:20.360] iteration 25918: loss: 0.051041, loss_s1: 0.045808, loss_fp: 0.002023, loss_freq: 0.010278
[19:11:21.006] iteration 25919: loss: 0.063663, loss_s1: 0.053928, loss_fp: 0.006830, loss_freq: 0.030205
[19:11:21.632] iteration 25920: loss: 0.066444, loss_s1: 0.069401, loss_fp: 0.004234, loss_freq: 0.031935
[19:11:22.255] iteration 25921: loss: 0.047444, loss_s1: 0.030164, loss_fp: 0.001687, loss_freq: 0.023329
[19:11:23.230] iteration 25922: loss: 0.032455, loss_s1: 0.013469, loss_fp: 0.003418, loss_freq: 0.010286
[19:11:23.863] iteration 25923: loss: 0.092016, loss_s1: 0.101597, loss_fp: 0.010324, loss_freq: 0.041332
[19:11:24.490] iteration 25924: loss: 0.036109, loss_s1: 0.019992, loss_fp: 0.000669, loss_freq: 0.015316
[19:11:25.129] iteration 25925: loss: 0.061398, loss_s1: 0.037666, loss_fp: 0.014549, loss_freq: 0.032385
[19:11:25.770] iteration 25926: loss: 0.052727, loss_s1: 0.031250, loss_fp: 0.004140, loss_freq: 0.034765
[19:11:26.432] iteration 25927: loss: 0.079774, loss_s1: 0.044886, loss_fp: 0.004691, loss_freq: 0.055121
[19:11:27.079] iteration 25928: loss: 0.026375, loss_s1: 0.013744, loss_fp: 0.002786, loss_freq: 0.011648
[19:11:27.721] iteration 25929: loss: 0.040461, loss_s1: 0.024831, loss_fp: 0.001711, loss_freq: 0.025795
[19:11:28.354] iteration 25930: loss: 0.038882, loss_s1: 0.022960, loss_fp: 0.003420, loss_freq: 0.021789
[19:11:29.013] iteration 25931: loss: 0.062067, loss_s1: 0.025019, loss_fp: 0.003986, loss_freq: 0.060274
[19:11:29.653] iteration 25932: loss: 0.046001, loss_s1: 0.022768, loss_fp: 0.001128, loss_freq: 0.036689
[19:11:30.297] iteration 25933: loss: 0.043182, loss_s1: 0.042026, loss_fp: 0.001373, loss_freq: 0.016592
[19:11:30.939] iteration 25934: loss: 0.057456, loss_s1: 0.039184, loss_fp: 0.012637, loss_freq: 0.033311
[19:11:31.568] iteration 25935: loss: 0.062577, loss_s1: 0.034781, loss_fp: 0.007705, loss_freq: 0.040933
[19:11:32.200] iteration 25936: loss: 0.052342, loss_s1: 0.055119, loss_fp: 0.000739, loss_freq: 0.021479
[19:11:32.832] iteration 25937: loss: 0.096493, loss_s1: 0.077618, loss_fp: 0.004983, loss_freq: 0.082977
[19:11:33.461] iteration 25938: loss: 0.042500, loss_s1: 0.032835, loss_fp: 0.004434, loss_freq: 0.009399
[19:11:34.085] iteration 25939: loss: 0.056738, loss_s1: 0.040325, loss_fp: 0.010599, loss_freq: 0.034298
[19:11:34.711] iteration 25940: loss: 0.029991, loss_s1: 0.014938, loss_fp: 0.000831, loss_freq: 0.010083
[19:11:35.338] iteration 25941: loss: 0.052653, loss_s1: 0.026818, loss_fp: 0.003880, loss_freq: 0.040399
[19:11:35.965] iteration 25942: loss: 0.044505, loss_s1: 0.044269, loss_fp: 0.000375, loss_freq: 0.006250
[19:11:36.589] iteration 25943: loss: 0.060671, loss_s1: 0.045047, loss_fp: 0.005968, loss_freq: 0.037481
[19:11:37.223] iteration 25944: loss: 0.047645, loss_s1: 0.018198, loss_fp: 0.002573, loss_freq: 0.026781
[19:11:37.846] iteration 25945: loss: 0.058801, loss_s1: 0.052295, loss_fp: 0.004948, loss_freq: 0.031405
[19:11:38.476] iteration 25946: loss: 0.033124, loss_s1: 0.021560, loss_fp: 0.003477, loss_freq: 0.015006
[19:11:39.100] iteration 25947: loss: 0.054210, loss_s1: 0.036671, loss_fp: 0.002292, loss_freq: 0.042054
[19:11:39.730] iteration 25948: loss: 0.020142, loss_s1: 0.002791, loss_fp: 0.001714, loss_freq: 0.005791
[19:11:40.362] iteration 25949: loss: 0.063756, loss_s1: 0.052045, loss_fp: 0.023412, loss_freq: 0.017041
[19:11:40.997] iteration 25950: loss: 0.052004, loss_s1: 0.016773, loss_fp: 0.001657, loss_freq: 0.052670
[19:11:41.626] iteration 25951: loss: 0.034168, loss_s1: 0.022268, loss_fp: 0.005184, loss_freq: 0.010582
[19:11:42.251] iteration 25952: loss: 0.062329, loss_s1: 0.073568, loss_fp: 0.007192, loss_freq: 0.017040
[19:11:42.877] iteration 25953: loss: 0.040500, loss_s1: 0.021338, loss_fp: 0.006097, loss_freq: 0.018175
[19:11:43.509] iteration 25954: loss: 0.051460, loss_s1: 0.040319, loss_fp: 0.000920, loss_freq: 0.032513
[19:11:44.134] iteration 25955: loss: 0.033689, loss_s1: 0.027514, loss_fp: 0.001023, loss_freq: 0.003725
[19:11:44.770] iteration 25956: loss: 0.071894, loss_s1: 0.049717, loss_fp: 0.008696, loss_freq: 0.042011
[19:11:45.444] iteration 25957: loss: 0.099993, loss_s1: 0.084373, loss_fp: 0.006207, loss_freq: 0.065861
[19:11:46.088] iteration 25958: loss: 0.085619, loss_s1: 0.108440, loss_fp: 0.010891, loss_freq: 0.015524
[19:11:46.714] iteration 25959: loss: 0.056349, loss_s1: 0.048651, loss_fp: 0.007547, loss_freq: 0.022225
[19:11:47.340] iteration 25960: loss: 0.081764, loss_s1: 0.077250, loss_fp: 0.000461, loss_freq: 0.049202
[19:11:47.969] iteration 25961: loss: 0.050123, loss_s1: 0.046622, loss_fp: 0.003486, loss_freq: 0.016851
[19:11:48.597] iteration 25962: loss: 0.037533, loss_s1: 0.027782, loss_fp: 0.005026, loss_freq: 0.010390
[19:11:49.242] iteration 25963: loss: 0.090343, loss_s1: 0.085952, loss_fp: 0.004235, loss_freq: 0.054031
[19:11:49.873] iteration 25964: loss: 0.043640, loss_s1: 0.039098, loss_fp: 0.002631, loss_freq: 0.019042
[19:11:50.500] iteration 25965: loss: 0.046206, loss_s1: 0.028522, loss_fp: 0.001562, loss_freq: 0.026392
[19:11:51.147] iteration 25966: loss: 0.048544, loss_s1: 0.024019, loss_fp: 0.008231, loss_freq: 0.025572
[19:11:51.781] iteration 25967: loss: 0.031438, loss_s1: 0.020541, loss_fp: 0.005577, loss_freq: 0.004078
[19:11:52.417] iteration 25968: loss: 0.029888, loss_s1: 0.018666, loss_fp: 0.000783, loss_freq: 0.009951
[19:11:53.057] iteration 25969: loss: 0.056179, loss_s1: 0.048496, loss_fp: 0.001321, loss_freq: 0.028393
[19:11:53.703] iteration 25970: loss: 0.050670, loss_s1: 0.045094, loss_fp: 0.000453, loss_freq: 0.021094
[19:11:54.339] iteration 25971: loss: 0.048416, loss_s1: 0.033349, loss_fp: 0.005819, loss_freq: 0.030876
[19:11:54.968] iteration 25972: loss: 0.084347, loss_s1: 0.083383, loss_fp: 0.006270, loss_freq: 0.034772
[19:11:55.598] iteration 25973: loss: 0.051905, loss_s1: 0.040153, loss_fp: 0.000970, loss_freq: 0.022582
[19:11:56.223] iteration 25974: loss: 0.062653, loss_s1: 0.047638, loss_fp: 0.003095, loss_freq: 0.033528
[19:11:56.852] iteration 25975: loss: 0.044928, loss_s1: 0.037027, loss_fp: 0.001548, loss_freq: 0.011740
[19:11:57.476] iteration 25976: loss: 0.027747, loss_s1: 0.016071, loss_fp: 0.000914, loss_freq: 0.008823
[19:11:58.109] iteration 25977: loss: 0.052615, loss_s1: 0.025006, loss_fp: 0.006714, loss_freq: 0.033500
[19:11:58.735] iteration 25978: loss: 0.039328, loss_s1: 0.024314, loss_fp: 0.004170, loss_freq: 0.006301
[19:11:59.369] iteration 25979: loss: 0.051120, loss_s1: 0.022371, loss_fp: 0.001604, loss_freq: 0.029983
[19:11:59.999] iteration 25980: loss: 0.032021, loss_s1: 0.025809, loss_fp: 0.005987, loss_freq: 0.004888
[19:12:00.625] iteration 25981: loss: 0.042262, loss_s1: 0.018021, loss_fp: 0.003725, loss_freq: 0.030194
[19:12:01.253] iteration 25982: loss: 0.039720, loss_s1: 0.027355, loss_fp: 0.003637, loss_freq: 0.017630
[19:12:01.878] iteration 25983: loss: 0.074632, loss_s1: 0.099684, loss_fp: 0.011152, loss_freq: 0.009709
[19:12:02.501] iteration 25984: loss: 0.039230, loss_s1: 0.035235, loss_fp: 0.001322, loss_freq: 0.005125
[19:12:03.125] iteration 25985: loss: 0.054977, loss_s1: 0.031904, loss_fp: 0.012903, loss_freq: 0.018733
[19:12:03.751] iteration 25986: loss: 0.046680, loss_s1: 0.030965, loss_fp: 0.008101, loss_freq: 0.016482
[19:12:04.378] iteration 25987: loss: 0.073291, loss_s1: 0.047676, loss_fp: 0.004698, loss_freq: 0.069312
[19:12:05.007] iteration 25988: loss: 0.037711, loss_s1: 0.020674, loss_fp: 0.002305, loss_freq: 0.019234
[19:12:05.636] iteration 25989: loss: 0.049231, loss_s1: 0.041900, loss_fp: 0.006931, loss_freq: 0.020477
[19:12:06.263] iteration 25990: loss: 0.048278, loss_s1: 0.047665, loss_fp: 0.002289, loss_freq: 0.016924
[19:12:06.893] iteration 25991: loss: 0.074376, loss_s1: 0.079537, loss_fp: 0.004915, loss_freq: 0.024715
[19:12:07.523] iteration 25992: loss: 0.058818, loss_s1: 0.053870, loss_fp: 0.008680, loss_freq: 0.024670
[19:12:08.150] iteration 25993: loss: 0.033625, loss_s1: 0.017150, loss_fp: 0.003473, loss_freq: 0.016133
[19:12:08.791] iteration 25994: loss: 0.054178, loss_s1: 0.031701, loss_fp: 0.004185, loss_freq: 0.044129
[19:12:09.424] iteration 25995: loss: 0.035974, loss_s1: 0.026099, loss_fp: 0.002092, loss_freq: 0.008440
[19:12:10.053] iteration 25996: loss: 0.045510, loss_s1: 0.030342, loss_fp: 0.002906, loss_freq: 0.012226
[19:12:10.681] iteration 25997: loss: 0.050305, loss_s1: 0.040909, loss_fp: 0.004947, loss_freq: 0.010226
[19:12:11.311] iteration 25998: loss: 0.060693, loss_s1: 0.078814, loss_fp: 0.005731, loss_freq: 0.011754
[19:12:11.936] iteration 25999: loss: 0.033619, loss_s1: 0.017416, loss_fp: 0.007880, loss_freq: 0.015712
[19:12:12.569] iteration 26000: loss: 0.035793, loss_s1: 0.020476, loss_fp: 0.001153, loss_freq: 0.014216
[19:12:15.932] iteration 26000 : mean_dice : 0.734278
[19:12:16.601] iteration 26001: loss: 0.053201, loss_s1: 0.041396, loss_fp: 0.003106, loss_freq: 0.026676
[19:12:17.237] iteration 26002: loss: 0.056528, loss_s1: 0.046474, loss_fp: 0.008120, loss_freq: 0.028186
[19:12:17.878] iteration 26003: loss: 0.048340, loss_s1: 0.039143, loss_fp: 0.002403, loss_freq: 0.027158
[19:12:18.507] iteration 26004: loss: 0.092880, loss_s1: 0.096860, loss_fp: 0.002790, loss_freq: 0.060027
[19:12:19.145] iteration 26005: loss: 0.040316, loss_s1: 0.021619, loss_fp: 0.006935, loss_freq: 0.021530
[19:12:19.777] iteration 26006: loss: 0.062957, loss_s1: 0.044290, loss_fp: 0.012514, loss_freq: 0.041086
[19:12:20.403] iteration 26007: loss: 0.046448, loss_s1: 0.028447, loss_fp: 0.001743, loss_freq: 0.025650
[19:12:21.026] iteration 26008: loss: 0.071150, loss_s1: 0.059973, loss_fp: 0.008589, loss_freq: 0.038075
[19:12:21.650] iteration 26009: loss: 0.041192, loss_s1: 0.026868, loss_fp: 0.001852, loss_freq: 0.022184
[19:12:22.291] iteration 26010: loss: 0.052520, loss_s1: 0.024597, loss_fp: 0.003945, loss_freq: 0.036066
[19:12:22.947] iteration 26011: loss: 0.089675, loss_s1: 0.099717, loss_fp: 0.002453, loss_freq: 0.042067
[19:12:23.603] iteration 26012: loss: 0.050892, loss_s1: 0.052020, loss_fp: 0.001449, loss_freq: 0.015149
[19:12:24.243] iteration 26013: loss: 0.060489, loss_s1: 0.025347, loss_fp: 0.002391, loss_freq: 0.050775
[19:12:24.880] iteration 26014: loss: 0.047240, loss_s1: 0.028798, loss_fp: 0.001864, loss_freq: 0.017379
[19:12:25.523] iteration 26015: loss: 0.048879, loss_s1: 0.037838, loss_fp: 0.001421, loss_freq: 0.032072
[19:12:26.164] iteration 26016: loss: 0.078659, loss_s1: 0.088984, loss_fp: 0.007367, loss_freq: 0.038231
[19:12:26.803] iteration 26017: loss: 0.050045, loss_s1: 0.029507, loss_fp: 0.004514, loss_freq: 0.037210
[19:12:27.435] iteration 26018: loss: 0.031700, loss_s1: 0.016408, loss_fp: 0.005169, loss_freq: 0.014322
[19:12:28.070] iteration 26019: loss: 0.030197, loss_s1: 0.010246, loss_fp: 0.002401, loss_freq: 0.016064
[19:12:28.706] iteration 26020: loss: 0.030580, loss_s1: 0.018113, loss_fp: 0.001199, loss_freq: 0.010707
[19:12:29.342] iteration 26021: loss: 0.052653, loss_s1: 0.035722, loss_fp: 0.002460, loss_freq: 0.039481
[19:12:29.981] iteration 26022: loss: 0.049027, loss_s1: 0.028548, loss_fp: 0.004736, loss_freq: 0.038754
[19:12:30.607] iteration 26023: loss: 0.062756, loss_s1: 0.024597, loss_fp: 0.006804, loss_freq: 0.030089
[19:12:31.236] iteration 26024: loss: 0.045962, loss_s1: 0.041412, loss_fp: 0.004980, loss_freq: 0.020027
[19:12:31.864] iteration 26025: loss: 0.051012, loss_s1: 0.040017, loss_fp: 0.003736, loss_freq: 0.023937
[19:12:32.499] iteration 26026: loss: 0.072276, loss_s1: 0.051890, loss_fp: 0.005029, loss_freq: 0.022113
[19:12:33.155] iteration 26027: loss: 0.036411, loss_s1: 0.013632, loss_fp: 0.005290, loss_freq: 0.016787
[19:12:33.792] iteration 26028: loss: 0.025794, loss_s1: 0.016317, loss_fp: 0.000614, loss_freq: 0.006164
[19:12:34.429] iteration 26029: loss: 0.080004, loss_s1: 0.048338, loss_fp: 0.001405, loss_freq: 0.081040
[19:12:35.063] iteration 26030: loss: 0.057792, loss_s1: 0.028840, loss_fp: 0.011999, loss_freq: 0.042242
[19:12:35.700] iteration 26031: loss: 0.051114, loss_s1: 0.031677, loss_fp: 0.002351, loss_freq: 0.030429
[19:12:36.329] iteration 26032: loss: 0.050242, loss_s1: 0.017564, loss_fp: 0.000888, loss_freq: 0.030965
[19:12:36.955] iteration 26033: loss: 0.065600, loss_s1: 0.068738, loss_fp: 0.001997, loss_freq: 0.028884
[19:12:37.588] iteration 26034: loss: 0.063383, loss_s1: 0.079423, loss_fp: 0.001667, loss_freq: 0.018167
[19:12:38.220] iteration 26035: loss: 0.056995, loss_s1: 0.056789, loss_fp: 0.001042, loss_freq: 0.034314
[19:12:38.862] iteration 26036: loss: 0.030019, loss_s1: 0.021086, loss_fp: 0.001282, loss_freq: 0.004569
[19:12:39.493] iteration 26037: loss: 0.061832, loss_s1: 0.049680, loss_fp: 0.003379, loss_freq: 0.034974
[19:12:40.129] iteration 26038: loss: 0.036049, loss_s1: 0.034752, loss_fp: 0.003051, loss_freq: 0.010146
[19:12:40.754] iteration 26039: loss: 0.020022, loss_s1: 0.008422, loss_fp: 0.000537, loss_freq: 0.004004
[19:12:41.388] iteration 26040: loss: 0.068283, loss_s1: 0.042743, loss_fp: 0.004892, loss_freq: 0.058949
[19:12:42.015] iteration 26041: loss: 0.081728, loss_s1: 0.050257, loss_fp: 0.001333, loss_freq: 0.082433
[19:12:42.650] iteration 26042: loss: 0.047356, loss_s1: 0.037335, loss_fp: 0.014383, loss_freq: 0.009084
[19:12:43.276] iteration 26043: loss: 0.074967, loss_s1: 0.085143, loss_fp: 0.008909, loss_freq: 0.024029
[19:12:43.911] iteration 26044: loss: 0.033488, loss_s1: 0.023550, loss_fp: 0.001313, loss_freq: 0.009149
[19:12:44.538] iteration 26045: loss: 0.049687, loss_s1: 0.025177, loss_fp: 0.005599, loss_freq: 0.030335
[19:12:45.162] iteration 26046: loss: 0.047148, loss_s1: 0.025045, loss_fp: 0.003255, loss_freq: 0.022901
[19:12:45.797] iteration 26047: loss: 0.035952, loss_s1: 0.015567, loss_fp: 0.002725, loss_freq: 0.016576
[19:12:46.428] iteration 26048: loss: 0.048462, loss_s1: 0.054595, loss_fp: 0.001173, loss_freq: 0.006275
[19:12:47.058] iteration 26049: loss: 0.068965, loss_s1: 0.071531, loss_fp: 0.002012, loss_freq: 0.027315
[19:12:47.688] iteration 26050: loss: 0.069453, loss_s1: 0.041656, loss_fp: 0.026930, loss_freq: 0.040793
[19:12:48.419] iteration 26051: loss: 0.041978, loss_s1: 0.022480, loss_fp: 0.011640, loss_freq: 0.026940
[19:12:49.113] iteration 26052: loss: 0.070143, loss_s1: 0.056714, loss_fp: 0.004059, loss_freq: 0.036947
[19:12:49.767] iteration 26053: loss: 0.052792, loss_s1: 0.056345, loss_fp: 0.003235, loss_freq: 0.017702
[19:12:50.401] iteration 26054: loss: 0.067261, loss_s1: 0.052547, loss_fp: 0.007804, loss_freq: 0.035846
[19:12:51.028] iteration 26055: loss: 0.039152, loss_s1: 0.038195, loss_fp: 0.002715, loss_freq: 0.010217
[19:12:51.655] iteration 26056: loss: 0.071660, loss_s1: 0.075325, loss_fp: 0.001787, loss_freq: 0.029441
[19:12:52.289] iteration 26057: loss: 0.065950, loss_s1: 0.044990, loss_fp: 0.004181, loss_freq: 0.044295
[19:12:52.914] iteration 26058: loss: 0.050335, loss_s1: 0.039096, loss_fp: 0.002249, loss_freq: 0.005266
[19:12:53.539] iteration 26059: loss: 0.078052, loss_s1: 0.092240, loss_fp: 0.008197, loss_freq: 0.029576
[19:12:54.164] iteration 26060: loss: 0.032454, loss_s1: 0.013833, loss_fp: 0.001891, loss_freq: 0.021566
[19:12:54.783] iteration 26061: loss: 0.050892, loss_s1: 0.032765, loss_fp: 0.002063, loss_freq: 0.018969
[19:12:55.407] iteration 26062: loss: 0.075152, loss_s1: 0.097351, loss_fp: 0.004014, loss_freq: 0.018619
[19:12:56.037] iteration 26063: loss: 0.035087, loss_s1: 0.018891, loss_fp: 0.004815, loss_freq: 0.018535
[19:12:56.668] iteration 26064: loss: 0.061070, loss_s1: 0.055621, loss_fp: 0.004669, loss_freq: 0.027987
[19:12:57.300] iteration 26065: loss: 0.052401, loss_s1: 0.034953, loss_fp: 0.004088, loss_freq: 0.027929
[19:12:57.938] iteration 26066: loss: 0.028205, loss_s1: 0.016741, loss_fp: 0.004205, loss_freq: 0.006360
[19:12:58.566] iteration 26067: loss: 0.038296, loss_s1: 0.021218, loss_fp: 0.006872, loss_freq: 0.014779
[19:12:59.195] iteration 26068: loss: 0.083230, loss_s1: 0.055207, loss_fp: 0.004164, loss_freq: 0.078159
[19:12:59.823] iteration 26069: loss: 0.042951, loss_s1: 0.042979, loss_fp: 0.001152, loss_freq: 0.015880
[19:13:00.448] iteration 26070: loss: 0.032197, loss_s1: 0.021535, loss_fp: 0.001066, loss_freq: 0.010888
[19:13:01.080] iteration 26071: loss: 0.084293, loss_s1: 0.073389, loss_fp: 0.006552, loss_freq: 0.053573
[19:13:01.702] iteration 26072: loss: 0.050053, loss_s1: 0.043664, loss_fp: 0.001795, loss_freq: 0.018181
[19:13:02.326] iteration 26073: loss: 0.102703, loss_s1: 0.083017, loss_fp: 0.010291, loss_freq: 0.074722
[19:13:02.957] iteration 26074: loss: 0.070979, loss_s1: 0.077560, loss_fp: 0.011115, loss_freq: 0.020782
[19:13:03.588] iteration 26075: loss: 0.058714, loss_s1: 0.032989, loss_fp: 0.010318, loss_freq: 0.043506
[19:13:04.215] iteration 26076: loss: 0.032747, loss_s1: 0.021974, loss_fp: 0.005655, loss_freq: 0.015086
[19:13:04.843] iteration 26077: loss: 0.038364, loss_s1: 0.028096, loss_fp: 0.000830, loss_freq: 0.011770
[19:13:05.471] iteration 26078: loss: 0.037454, loss_s1: 0.035546, loss_fp: 0.001086, loss_freq: 0.007451
[19:13:06.130] iteration 26079: loss: 0.046798, loss_s1: 0.022295, loss_fp: 0.003737, loss_freq: 0.029296
[19:13:06.759] iteration 26080: loss: 0.051453, loss_s1: 0.036670, loss_fp: 0.001591, loss_freq: 0.024663
[19:13:07.385] iteration 26081: loss: 0.052314, loss_s1: 0.038114, loss_fp: 0.001866, loss_freq: 0.035728
[19:13:08.011] iteration 26082: loss: 0.059477, loss_s1: 0.045528, loss_fp: 0.001234, loss_freq: 0.034001
[19:13:08.977] iteration 26083: loss: 0.035450, loss_s1: 0.031247, loss_fp: 0.001733, loss_freq: 0.006858
[19:13:09.615] iteration 26084: loss: 0.077572, loss_s1: 0.045801, loss_fp: 0.021857, loss_freq: 0.021502
[19:13:10.257] iteration 26085: loss: 0.057547, loss_s1: 0.066418, loss_fp: 0.001647, loss_freq: 0.010174
[19:13:10.894] iteration 26086: loss: 0.041201, loss_s1: 0.025918, loss_fp: 0.006867, loss_freq: 0.013615
[19:13:11.530] iteration 26087: loss: 0.060779, loss_s1: 0.049320, loss_fp: 0.002748, loss_freq: 0.028328
[19:13:12.172] iteration 26088: loss: 0.074688, loss_s1: 0.064379, loss_fp: 0.002550, loss_freq: 0.037942
[19:13:12.803] iteration 26089: loss: 0.058278, loss_s1: 0.061586, loss_fp: 0.007083, loss_freq: 0.020352
[19:13:13.439] iteration 26090: loss: 0.028698, loss_s1: 0.015744, loss_fp: 0.001687, loss_freq: 0.010353
[19:13:14.077] iteration 26091: loss: 0.042668, loss_s1: 0.032912, loss_fp: 0.008593, loss_freq: 0.022178
[19:13:14.709] iteration 26092: loss: 0.054708, loss_s1: 0.030167, loss_fp: 0.004304, loss_freq: 0.027833
[19:13:15.341] iteration 26093: loss: 0.039680, loss_s1: 0.024449, loss_fp: 0.002736, loss_freq: 0.019644
[19:13:15.976] iteration 26094: loss: 0.039431, loss_s1: 0.034823, loss_fp: 0.005944, loss_freq: 0.009471
[19:13:16.612] iteration 26095: loss: 0.065389, loss_s1: 0.045135, loss_fp: 0.005233, loss_freq: 0.054778
[19:13:17.243] iteration 26096: loss: 0.052201, loss_s1: 0.024302, loss_fp: 0.006071, loss_freq: 0.038125
[19:13:17.873] iteration 26097: loss: 0.070453, loss_s1: 0.068105, loss_fp: 0.008679, loss_freq: 0.017257
[19:13:18.496] iteration 26098: loss: 0.092118, loss_s1: 0.050545, loss_fp: 0.017906, loss_freq: 0.079859
[19:13:19.124] iteration 26099: loss: 0.038982, loss_s1: 0.018038, loss_fp: 0.009415, loss_freq: 0.013210
[19:13:19.752] iteration 26100: loss: 0.067682, loss_s1: 0.047886, loss_fp: 0.023671, loss_freq: 0.032019
[19:13:20.380] iteration 26101: loss: 0.040353, loss_s1: 0.025049, loss_fp: 0.000901, loss_freq: 0.025081
[19:13:21.010] iteration 26102: loss: 0.037400, loss_s1: 0.018998, loss_fp: 0.002866, loss_freq: 0.023239
[19:13:21.641] iteration 26103: loss: 0.049500, loss_s1: 0.022399, loss_fp: 0.017126, loss_freq: 0.009063
[19:13:22.281] iteration 26104: loss: 0.042436, loss_s1: 0.017374, loss_fp: 0.008700, loss_freq: 0.017548
[19:13:22.914] iteration 26105: loss: 0.069792, loss_s1: 0.055544, loss_fp: 0.003468, loss_freq: 0.015434
[19:13:23.544] iteration 26106: loss: 0.067445, loss_s1: 0.081005, loss_fp: 0.011568, loss_freq: 0.018627
[19:13:24.169] iteration 26107: loss: 0.044055, loss_s1: 0.047031, loss_fp: 0.004126, loss_freq: 0.011659
[19:13:24.801] iteration 26108: loss: 0.032482, loss_s1: 0.022137, loss_fp: 0.001501, loss_freq: 0.018011
[19:13:25.435] iteration 26109: loss: 0.035533, loss_s1: 0.022576, loss_fp: 0.000637, loss_freq: 0.013901
[19:13:26.062] iteration 26110: loss: 0.089099, loss_s1: 0.092104, loss_fp: 0.004761, loss_freq: 0.046788
[19:13:26.696] iteration 26111: loss: 0.084467, loss_s1: 0.070929, loss_fp: 0.014630, loss_freq: 0.049550
[19:13:27.327] iteration 26112: loss: 0.031931, loss_s1: 0.017406, loss_fp: 0.004842, loss_freq: 0.007111
[19:13:27.961] iteration 26113: loss: 0.069807, loss_s1: 0.086796, loss_fp: 0.003850, loss_freq: 0.021400
[19:13:28.593] iteration 26114: loss: 0.049295, loss_s1: 0.037960, loss_fp: 0.002630, loss_freq: 0.029895
[19:13:29.225] iteration 26115: loss: 0.046008, loss_s1: 0.037150, loss_fp: 0.002664, loss_freq: 0.022213
[19:13:29.858] iteration 26116: loss: 0.031160, loss_s1: 0.021616, loss_fp: 0.002003, loss_freq: 0.010758
[19:13:30.502] iteration 26117: loss: 0.050237, loss_s1: 0.019409, loss_fp: 0.002348, loss_freq: 0.022788
[19:13:31.140] iteration 26118: loss: 0.076164, loss_s1: 0.065172, loss_fp: 0.003263, loss_freq: 0.052375
[19:13:31.780] iteration 26119: loss: 0.086883, loss_s1: 0.077015, loss_fp: 0.003377, loss_freq: 0.053173
[19:13:32.420] iteration 26120: loss: 0.043615, loss_s1: 0.029173, loss_fp: 0.001608, loss_freq: 0.020605
[19:13:33.044] iteration 26121: loss: 0.051960, loss_s1: 0.028532, loss_fp: 0.000977, loss_freq: 0.036576
[19:13:33.673] iteration 26122: loss: 0.085546, loss_s1: 0.110252, loss_fp: 0.002511, loss_freq: 0.026616
[19:13:34.299] iteration 26123: loss: 0.060486, loss_s1: 0.045203, loss_fp: 0.013089, loss_freq: 0.018772
[19:13:34.930] iteration 26124: loss: 0.055518, loss_s1: 0.039661, loss_fp: 0.002904, loss_freq: 0.044373
[19:13:35.560] iteration 26125: loss: 0.048637, loss_s1: 0.044952, loss_fp: 0.003444, loss_freq: 0.017845
[19:13:36.198] iteration 26126: loss: 0.059393, loss_s1: 0.046055, loss_fp: 0.003726, loss_freq: 0.039683
[19:13:36.836] iteration 26127: loss: 0.062033, loss_s1: 0.037056, loss_fp: 0.006585, loss_freq: 0.040427
[19:13:37.463] iteration 26128: loss: 0.049649, loss_s1: 0.042159, loss_fp: 0.000973, loss_freq: 0.007501
[19:13:38.091] iteration 26129: loss: 0.033091, loss_s1: 0.028237, loss_fp: 0.002328, loss_freq: 0.009817
[19:13:38.716] iteration 26130: loss: 0.050961, loss_s1: 0.054846, loss_fp: 0.004862, loss_freq: 0.016766
[19:13:39.346] iteration 26131: loss: 0.076242, loss_s1: 0.059893, loss_fp: 0.003805, loss_freq: 0.052327
[19:13:39.975] iteration 26132: loss: 0.053596, loss_s1: 0.045020, loss_fp: 0.001897, loss_freq: 0.032395
[19:13:40.601] iteration 26133: loss: 0.064080, loss_s1: 0.028007, loss_fp: 0.002416, loss_freq: 0.064676
[19:13:41.229] iteration 26134: loss: 0.038467, loss_s1: 0.015116, loss_fp: 0.002207, loss_freq: 0.018609
[19:13:41.854] iteration 26135: loss: 0.089755, loss_s1: 0.066695, loss_fp: 0.001303, loss_freq: 0.074798
[19:13:42.483] iteration 26136: loss: 0.045978, loss_s1: 0.029890, loss_fp: 0.007896, loss_freq: 0.021019
[19:13:43.123] iteration 26137: loss: 0.037446, loss_s1: 0.022979, loss_fp: 0.003777, loss_freq: 0.017425
[19:13:43.745] iteration 26138: loss: 0.050189, loss_s1: 0.023120, loss_fp: 0.007416, loss_freq: 0.032553
[19:13:44.375] iteration 26139: loss: 0.030677, loss_s1: 0.007974, loss_fp: 0.000624, loss_freq: 0.018998
[19:13:45.053] iteration 26140: loss: 0.046173, loss_s1: 0.029659, loss_fp: 0.003477, loss_freq: 0.015180
[19:13:45.679] iteration 26141: loss: 0.031625, loss_s1: 0.030248, loss_fp: 0.001040, loss_freq: 0.004616
[19:13:46.305] iteration 26142: loss: 0.040879, loss_s1: 0.033846, loss_fp: 0.001134, loss_freq: 0.016846
[19:13:46.933] iteration 26143: loss: 0.044012, loss_s1: 0.027242, loss_fp: 0.004616, loss_freq: 0.019823
[19:13:47.562] iteration 26144: loss: 0.056221, loss_s1: 0.058170, loss_fp: 0.004111, loss_freq: 0.019475
[19:13:48.188] iteration 26145: loss: 0.041714, loss_s1: 0.025414, loss_fp: 0.004009, loss_freq: 0.010990
[19:13:48.814] iteration 26146: loss: 0.081698, loss_s1: 0.061406, loss_fp: 0.004886, loss_freq: 0.040276
[19:13:49.447] iteration 26147: loss: 0.052769, loss_s1: 0.040481, loss_fp: 0.007470, loss_freq: 0.022879
[19:13:50.071] iteration 26148: loss: 0.058372, loss_s1: 0.034926, loss_fp: 0.002156, loss_freq: 0.050164
[19:13:50.700] iteration 26149: loss: 0.048374, loss_s1: 0.023868, loss_fp: 0.004544, loss_freq: 0.023101
[19:13:51.325] iteration 26150: loss: 0.057232, loss_s1: 0.063233, loss_fp: 0.002045, loss_freq: 0.021658
[19:13:51.949] iteration 26151: loss: 0.041949, loss_s1: 0.033467, loss_fp: 0.005778, loss_freq: 0.017049
[19:13:52.580] iteration 26152: loss: 0.082283, loss_s1: 0.084516, loss_fp: 0.011323, loss_freq: 0.029873
[19:13:53.211] iteration 26153: loss: 0.074004, loss_s1: 0.059635, loss_fp: 0.013776, loss_freq: 0.045384
[19:13:53.842] iteration 26154: loss: 0.045568, loss_s1: 0.038258, loss_fp: 0.002185, loss_freq: 0.022652
[19:13:54.468] iteration 26155: loss: 0.044461, loss_s1: 0.038317, loss_fp: 0.004529, loss_freq: 0.013841
[19:13:55.098] iteration 26156: loss: 0.048398, loss_s1: 0.034729, loss_fp: 0.002570, loss_freq: 0.012802
[19:13:55.726] iteration 26157: loss: 0.069873, loss_s1: 0.052601, loss_fp: 0.001470, loss_freq: 0.041221
[19:13:56.356] iteration 26158: loss: 0.053343, loss_s1: 0.046028, loss_fp: 0.009136, loss_freq: 0.012433
[19:13:56.980] iteration 26159: loss: 0.035453, loss_s1: 0.025111, loss_fp: 0.005667, loss_freq: 0.016442
[19:13:57.603] iteration 26160: loss: 0.031198, loss_s1: 0.020890, loss_fp: 0.003172, loss_freq: 0.011741
[19:13:58.229] iteration 26161: loss: 0.049427, loss_s1: 0.048332, loss_fp: 0.002114, loss_freq: 0.012712
[19:13:58.855] iteration 26162: loss: 0.054303, loss_s1: 0.038147, loss_fp: 0.003824, loss_freq: 0.028533
[19:13:59.487] iteration 26163: loss: 0.038163, loss_s1: 0.026808, loss_fp: 0.003896, loss_freq: 0.015337
[19:14:00.116] iteration 26164: loss: 0.056811, loss_s1: 0.074304, loss_fp: 0.003874, loss_freq: 0.011237
[19:14:00.750] iteration 26165: loss: 0.057755, loss_s1: 0.067964, loss_fp: 0.007003, loss_freq: 0.012891
[19:14:01.378] iteration 26166: loss: 0.059063, loss_s1: 0.026375, loss_fp: 0.002253, loss_freq: 0.044964
[19:14:02.007] iteration 26167: loss: 0.064301, loss_s1: 0.053625, loss_fp: 0.014446, loss_freq: 0.032564
[19:14:02.634] iteration 26168: loss: 0.040807, loss_s1: 0.030165, loss_fp: 0.001342, loss_freq: 0.013866
[19:14:03.264] iteration 26169: loss: 0.054216, loss_s1: 0.035527, loss_fp: 0.007791, loss_freq: 0.030691
[19:14:03.899] iteration 26170: loss: 0.048951, loss_s1: 0.052673, loss_fp: 0.001144, loss_freq: 0.011461
[19:14:04.536] iteration 26171: loss: 0.075587, loss_s1: 0.066043, loss_fp: 0.004181, loss_freq: 0.046750
[19:14:05.169] iteration 26172: loss: 0.046243, loss_s1: 0.039091, loss_fp: 0.001952, loss_freq: 0.018498
[19:14:05.803] iteration 26173: loss: 0.043468, loss_s1: 0.034550, loss_fp: 0.002283, loss_freq: 0.015333
[19:14:06.430] iteration 26174: loss: 0.057539, loss_s1: 0.059028, loss_fp: 0.004464, loss_freq: 0.016624
[19:14:07.055] iteration 26175: loss: 0.043109, loss_s1: 0.022607, loss_fp: 0.002134, loss_freq: 0.015562
[19:14:07.683] iteration 26176: loss: 0.043363, loss_s1: 0.032416, loss_fp: 0.005148, loss_freq: 0.018707
[19:14:08.310] iteration 26177: loss: 0.064101, loss_s1: 0.050556, loss_fp: 0.005091, loss_freq: 0.043226
[19:14:08.942] iteration 26178: loss: 0.056673, loss_s1: 0.047320, loss_fp: 0.000809, loss_freq: 0.031502
[19:14:09.566] iteration 26179: loss: 0.039652, loss_s1: 0.016989, loss_fp: 0.001492, loss_freq: 0.024654
[19:14:10.189] iteration 26180: loss: 0.050914, loss_s1: 0.042080, loss_fp: 0.002741, loss_freq: 0.020204
[19:14:10.810] iteration 26181: loss: 0.041006, loss_s1: 0.030148, loss_fp: 0.000971, loss_freq: 0.009088
[19:14:11.436] iteration 26182: loss: 0.036304, loss_s1: 0.023837, loss_fp: 0.002642, loss_freq: 0.008428
[19:14:12.062] iteration 26183: loss: 0.046009, loss_s1: 0.043898, loss_fp: 0.001190, loss_freq: 0.012886
[19:14:12.691] iteration 26184: loss: 0.057741, loss_s1: 0.014914, loss_fp: 0.006304, loss_freq: 0.048990
[19:14:13.319] iteration 26185: loss: 0.051968, loss_s1: 0.050178, loss_fp: 0.003130, loss_freq: 0.025211
[19:14:13.945] iteration 26186: loss: 0.048698, loss_s1: 0.044041, loss_fp: 0.004164, loss_freq: 0.018248
[19:14:14.589] iteration 26187: loss: 0.038938, loss_s1: 0.011037, loss_fp: 0.002436, loss_freq: 0.023313
[19:14:15.221] iteration 26188: loss: 0.039791, loss_s1: 0.017190, loss_fp: 0.002985, loss_freq: 0.014945
[19:14:15.851] iteration 26189: loss: 0.037452, loss_s1: 0.040945, loss_fp: 0.000882, loss_freq: 0.003537
[19:14:16.478] iteration 26190: loss: 0.050347, loss_s1: 0.047782, loss_fp: 0.002292, loss_freq: 0.016231
[19:14:17.104] iteration 26191: loss: 0.083865, loss_s1: 0.046771, loss_fp: 0.014877, loss_freq: 0.067016
[19:14:17.738] iteration 26192: loss: 0.065951, loss_s1: 0.044268, loss_fp: 0.001642, loss_freq: 0.054446
[19:14:18.367] iteration 26193: loss: 0.052999, loss_s1: 0.049039, loss_fp: 0.000862, loss_freq: 0.018972
[19:14:18.995] iteration 26194: loss: 0.040249, loss_s1: 0.008586, loss_fp: 0.002108, loss_freq: 0.038297
[19:14:19.628] iteration 26195: loss: 0.067390, loss_s1: 0.073590, loss_fp: 0.004165, loss_freq: 0.027175
[19:14:20.255] iteration 26196: loss: 0.026878, loss_s1: 0.020863, loss_fp: 0.001682, loss_freq: 0.007005
[19:14:20.880] iteration 26197: loss: 0.027606, loss_s1: 0.011037, loss_fp: 0.005523, loss_freq: 0.005836
[19:14:21.508] iteration 26198: loss: 0.054456, loss_s1: 0.044166, loss_fp: 0.003382, loss_freq: 0.025200
[19:14:22.134] iteration 26199: loss: 0.044570, loss_s1: 0.031168, loss_fp: 0.004199, loss_freq: 0.010179
[19:14:22.757] iteration 26200: loss: 0.022629, loss_s1: 0.005933, loss_fp: 0.001925, loss_freq: 0.010420
[19:14:26.085] iteration 26200 : mean_dice : 0.735761
[19:14:26.748] iteration 26201: loss: 0.056322, loss_s1: 0.044967, loss_fp: 0.005172, loss_freq: 0.028880
[19:14:27.379] iteration 26202: loss: 0.070344, loss_s1: 0.057148, loss_fp: 0.001114, loss_freq: 0.048987
[19:14:28.007] iteration 26203: loss: 0.031225, loss_s1: 0.014762, loss_fp: 0.001773, loss_freq: 0.009370
[19:14:28.637] iteration 26204: loss: 0.076433, loss_s1: 0.070184, loss_fp: 0.007087, loss_freq: 0.039753
[19:14:29.264] iteration 26205: loss: 0.053805, loss_s1: 0.047977, loss_fp: 0.002624, loss_freq: 0.020936
[19:14:29.888] iteration 26206: loss: 0.043531, loss_s1: 0.037382, loss_fp: 0.010516, loss_freq: 0.009378
[19:14:30.512] iteration 26207: loss: 0.053742, loss_s1: 0.038364, loss_fp: 0.004521, loss_freq: 0.031905
[19:14:31.136] iteration 26208: loss: 0.045800, loss_s1: 0.021513, loss_fp: 0.002490, loss_freq: 0.034990
[19:14:31.766] iteration 26209: loss: 0.065168, loss_s1: 0.068688, loss_fp: 0.002927, loss_freq: 0.013198
[19:14:32.394] iteration 26210: loss: 0.149860, loss_s1: 0.102226, loss_fp: 0.000794, loss_freq: 0.149263
[19:14:33.023] iteration 26211: loss: 0.054117, loss_s1: 0.045895, loss_fp: 0.002134, loss_freq: 0.032646
[19:14:33.650] iteration 26212: loss: 0.062487, loss_s1: 0.060204, loss_fp: 0.005287, loss_freq: 0.016802
[19:14:34.278] iteration 26213: loss: 0.076024, loss_s1: 0.042756, loss_fp: 0.004833, loss_freq: 0.056582
[19:14:34.907] iteration 26214: loss: 0.037245, loss_s1: 0.031958, loss_fp: 0.001255, loss_freq: 0.007985
[19:14:35.534] iteration 26215: loss: 0.047655, loss_s1: 0.025672, loss_fp: 0.005548, loss_freq: 0.029055
[19:14:36.162] iteration 26216: loss: 0.038095, loss_s1: 0.026087, loss_fp: 0.006759, loss_freq: 0.009838
[19:14:36.788] iteration 26217: loss: 0.061891, loss_s1: 0.048417, loss_fp: 0.002779, loss_freq: 0.036551
[19:14:37.419] iteration 26218: loss: 0.038087, loss_s1: 0.034588, loss_fp: 0.002984, loss_freq: 0.013791
[19:14:38.045] iteration 26219: loss: 0.039734, loss_s1: 0.016677, loss_fp: 0.002353, loss_freq: 0.009912
[19:14:38.674] iteration 26220: loss: 0.029655, loss_s1: 0.015374, loss_fp: 0.002378, loss_freq: 0.015560
[19:14:39.300] iteration 26221: loss: 0.042072, loss_s1: 0.023372, loss_fp: 0.000762, loss_freq: 0.016835
[19:14:39.930] iteration 26222: loss: 0.090075, loss_s1: 0.087778, loss_fp: 0.004751, loss_freq: 0.029892
[19:14:40.565] iteration 26223: loss: 0.092762, loss_s1: 0.104728, loss_fp: 0.002218, loss_freq: 0.037764
[19:14:41.204] iteration 26224: loss: 0.044710, loss_s1: 0.033231, loss_fp: 0.005869, loss_freq: 0.012600
[19:14:41.855] iteration 26225: loss: 0.057584, loss_s1: 0.056008, loss_fp: 0.008180, loss_freq: 0.021778
[19:14:42.504] iteration 26226: loss: 0.085983, loss_s1: 0.083372, loss_fp: 0.007320, loss_freq: 0.043241
[19:14:43.153] iteration 26227: loss: 0.058226, loss_s1: 0.032287, loss_fp: 0.004056, loss_freq: 0.030380
[19:14:43.794] iteration 26228: loss: 0.085340, loss_s1: 0.074962, loss_fp: 0.001096, loss_freq: 0.015928
[19:14:44.426] iteration 26229: loss: 0.058652, loss_s1: 0.044348, loss_fp: 0.003578, loss_freq: 0.041418
[19:14:45.061] iteration 26230: loss: 0.035589, loss_s1: 0.038232, loss_fp: 0.000604, loss_freq: 0.010178
[19:14:45.691] iteration 26231: loss: 0.040148, loss_s1: 0.030904, loss_fp: 0.002029, loss_freq: 0.023724
[19:14:46.344] iteration 26232: loss: 0.064021, loss_s1: 0.033035, loss_fp: 0.011707, loss_freq: 0.043256
[19:14:46.988] iteration 26233: loss: 0.039394, loss_s1: 0.021809, loss_fp: 0.003265, loss_freq: 0.022018
[19:14:47.626] iteration 26234: loss: 0.083030, loss_s1: 0.076738, loss_fp: 0.003925, loss_freq: 0.053503
[19:14:48.261] iteration 26235: loss: 0.039966, loss_s1: 0.017603, loss_fp: 0.002783, loss_freq: 0.025800
[19:14:48.894] iteration 26236: loss: 0.050496, loss_s1: 0.041899, loss_fp: 0.005581, loss_freq: 0.018786
[19:14:49.529] iteration 26237: loss: 0.026647, loss_s1: 0.008438, loss_fp: 0.002768, loss_freq: 0.007020
[19:14:50.159] iteration 26238: loss: 0.051220, loss_s1: 0.048244, loss_fp: 0.001093, loss_freq: 0.018091
[19:14:50.785] iteration 26239: loss: 0.027444, loss_s1: 0.009733, loss_fp: 0.001812, loss_freq: 0.006227
[19:14:51.417] iteration 26240: loss: 0.036803, loss_s1: 0.023715, loss_fp: 0.005125, loss_freq: 0.009286
[19:14:52.045] iteration 26241: loss: 0.065484, loss_s1: 0.061313, loss_fp: 0.011918, loss_freq: 0.025275
[19:14:52.669] iteration 26242: loss: 0.084892, loss_s1: 0.102782, loss_fp: 0.000943, loss_freq: 0.013970
[19:14:53.328] iteration 26243: loss: 0.039452, loss_s1: 0.027534, loss_fp: 0.002300, loss_freq: 0.008744
[19:14:54.328] iteration 26244: loss: 0.043968, loss_s1: 0.038911, loss_fp: 0.002317, loss_freq: 0.013455
[19:14:54.966] iteration 26245: loss: 0.064583, loss_s1: 0.059894, loss_fp: 0.009058, loss_freq: 0.026244
[19:14:55.603] iteration 26246: loss: 0.051928, loss_s1: 0.046164, loss_fp: 0.001496, loss_freq: 0.011512
[19:14:56.249] iteration 26247: loss: 0.041546, loss_s1: 0.025547, loss_fp: 0.005962, loss_freq: 0.010977
[19:14:57.000] iteration 26248: loss: 0.031071, loss_s1: 0.023443, loss_fp: 0.002945, loss_freq: 0.006711
[19:14:57.639] iteration 26249: loss: 0.071087, loss_s1: 0.045570, loss_fp: 0.013611, loss_freq: 0.035765
[19:14:58.271] iteration 26250: loss: 0.036232, loss_s1: 0.012122, loss_fp: 0.004311, loss_freq: 0.021576
[19:14:58.902] iteration 26251: loss: 0.024983, loss_s1: 0.013876, loss_fp: 0.001357, loss_freq: 0.008917
[19:14:59.529] iteration 26252: loss: 0.086953, loss_s1: 0.086517, loss_fp: 0.009339, loss_freq: 0.046082
[19:15:00.160] iteration 26253: loss: 0.061312, loss_s1: 0.053182, loss_fp: 0.005352, loss_freq: 0.025268
[19:15:00.799] iteration 26254: loss: 0.046477, loss_s1: 0.039275, loss_fp: 0.005957, loss_freq: 0.014205
[19:15:01.428] iteration 26255: loss: 0.056112, loss_s1: 0.065719, loss_fp: 0.002465, loss_freq: 0.005743
[19:15:02.062] iteration 26256: loss: 0.059574, loss_s1: 0.032084, loss_fp: 0.007809, loss_freq: 0.052795
[19:15:02.694] iteration 26257: loss: 0.051445, loss_s1: 0.027327, loss_fp: 0.004450, loss_freq: 0.023060
[19:15:03.328] iteration 26258: loss: 0.043028, loss_s1: 0.024179, loss_fp: 0.018775, loss_freq: 0.019832
[19:15:03.959] iteration 26259: loss: 0.066907, loss_s1: 0.022307, loss_fp: 0.002234, loss_freq: 0.066935
[19:15:04.589] iteration 26260: loss: 0.047376, loss_s1: 0.041257, loss_fp: 0.000895, loss_freq: 0.019783
[19:15:05.220] iteration 26261: loss: 0.074012, loss_s1: 0.051035, loss_fp: 0.007413, loss_freq: 0.059251
[19:15:05.864] iteration 26262: loss: 0.050602, loss_s1: 0.020710, loss_fp: 0.001232, loss_freq: 0.013327
[19:15:06.492] iteration 26263: loss: 0.036897, loss_s1: 0.013393, loss_fp: 0.002839, loss_freq: 0.028419
[19:15:07.139] iteration 26264: loss: 0.046985, loss_s1: 0.033558, loss_fp: 0.001140, loss_freq: 0.013185
[19:15:07.763] iteration 26265: loss: 0.034871, loss_s1: 0.010609, loss_fp: 0.001517, loss_freq: 0.025222
[19:15:08.395] iteration 26266: loss: 0.054421, loss_s1: 0.031837, loss_fp: 0.012710, loss_freq: 0.012043
[19:15:09.024] iteration 26267: loss: 0.048206, loss_s1: 0.028318, loss_fp: 0.000942, loss_freq: 0.041637
[19:15:09.647] iteration 26268: loss: 0.046593, loss_s1: 0.031910, loss_fp: 0.003540, loss_freq: 0.028684
[19:15:10.277] iteration 26269: loss: 0.042376, loss_s1: 0.042418, loss_fp: 0.001370, loss_freq: 0.011931
[19:15:10.907] iteration 26270: loss: 0.032930, loss_s1: 0.028444, loss_fp: 0.000511, loss_freq: 0.006832
[19:15:11.541] iteration 26271: loss: 0.079108, loss_s1: 0.099960, loss_fp: 0.009991, loss_freq: 0.019249
[19:15:12.171] iteration 26272: loss: 0.067253, loss_s1: 0.049288, loss_fp: 0.004979, loss_freq: 0.045462
[19:15:12.822] iteration 26273: loss: 0.044731, loss_s1: 0.034965, loss_fp: 0.004616, loss_freq: 0.011926
[19:15:13.466] iteration 26274: loss: 0.061125, loss_s1: 0.064672, loss_fp: 0.002578, loss_freq: 0.026333
[19:15:14.104] iteration 26275: loss: 0.045228, loss_s1: 0.033904, loss_fp: 0.003514, loss_freq: 0.016315
[19:15:14.730] iteration 26276: loss: 0.038194, loss_s1: 0.035181, loss_fp: 0.001573, loss_freq: 0.011805
[19:15:15.358] iteration 26277: loss: 0.032292, loss_s1: 0.028256, loss_fp: 0.001056, loss_freq: 0.009815
[19:15:15.980] iteration 26278: loss: 0.052419, loss_s1: 0.030585, loss_fp: 0.003840, loss_freq: 0.023781
[19:15:16.608] iteration 26279: loss: 0.055380, loss_s1: 0.054455, loss_fp: 0.004059, loss_freq: 0.024368
[19:15:17.232] iteration 26280: loss: 0.081834, loss_s1: 0.082308, loss_fp: 0.003495, loss_freq: 0.048663
[19:15:17.905] iteration 26281: loss: 0.052366, loss_s1: 0.025265, loss_fp: 0.002930, loss_freq: 0.031476
[19:15:18.536] iteration 26282: loss: 0.057491, loss_s1: 0.041069, loss_fp: 0.003674, loss_freq: 0.035470
[19:15:19.169] iteration 26283: loss: 0.039416, loss_s1: 0.034081, loss_fp: 0.004007, loss_freq: 0.013711
[19:15:19.794] iteration 26284: loss: 0.055948, loss_s1: 0.030373, loss_fp: 0.014963, loss_freq: 0.031489
[19:15:20.423] iteration 26285: loss: 0.049969, loss_s1: 0.032229, loss_fp: 0.007752, loss_freq: 0.034138
[19:15:21.048] iteration 26286: loss: 0.057226, loss_s1: 0.032675, loss_fp: 0.015684, loss_freq: 0.032936
[19:15:21.675] iteration 26287: loss: 0.053586, loss_s1: 0.043824, loss_fp: 0.001210, loss_freq: 0.037566
[19:15:22.300] iteration 26288: loss: 0.036546, loss_s1: 0.022062, loss_fp: 0.000752, loss_freq: 0.011236
[19:15:22.927] iteration 26289: loss: 0.041288, loss_s1: 0.031406, loss_fp: 0.000593, loss_freq: 0.017930
[19:15:23.555] iteration 26290: loss: 0.048896, loss_s1: 0.039292, loss_fp: 0.002421, loss_freq: 0.005172
[19:15:24.187] iteration 26291: loss: 0.039839, loss_s1: 0.026449, loss_fp: 0.004235, loss_freq: 0.012113
[19:15:24.816] iteration 26292: loss: 0.060448, loss_s1: 0.061296, loss_fp: 0.001160, loss_freq: 0.025864
[19:15:25.446] iteration 26293: loss: 0.047472, loss_s1: 0.038332, loss_fp: 0.010461, loss_freq: 0.016571
[19:15:26.077] iteration 26294: loss: 0.054872, loss_s1: 0.045488, loss_fp: 0.007560, loss_freq: 0.025660
[19:15:26.704] iteration 26295: loss: 0.041504, loss_s1: 0.026339, loss_fp: 0.005982, loss_freq: 0.010245
[19:15:27.330] iteration 26296: loss: 0.052589, loss_s1: 0.029029, loss_fp: 0.001946, loss_freq: 0.041901
[19:15:27.956] iteration 26297: loss: 0.038098, loss_s1: 0.018759, loss_fp: 0.001850, loss_freq: 0.018893
[19:15:28.582] iteration 26298: loss: 0.040241, loss_s1: 0.038195, loss_fp: 0.006433, loss_freq: 0.009991
[19:15:29.210] iteration 26299: loss: 0.057516, loss_s1: 0.047270, loss_fp: 0.002359, loss_freq: 0.027974
[19:15:29.844] iteration 26300: loss: 0.028636, loss_s1: 0.007855, loss_fp: 0.006933, loss_freq: 0.007874
[19:15:30.471] iteration 26301: loss: 0.039994, loss_s1: 0.020067, loss_fp: 0.001689, loss_freq: 0.015271
[19:15:31.132] iteration 26302: loss: 0.025704, loss_s1: 0.016055, loss_fp: 0.000634, loss_freq: 0.006859
[19:15:31.757] iteration 26303: loss: 0.033835, loss_s1: 0.026191, loss_fp: 0.001816, loss_freq: 0.016524
[19:15:32.381] iteration 26304: loss: 0.031733, loss_s1: 0.014233, loss_fp: 0.003064, loss_freq: 0.017925
[19:15:33.011] iteration 26305: loss: 0.043011, loss_s1: 0.037304, loss_fp: 0.002059, loss_freq: 0.017360
[19:15:33.639] iteration 26306: loss: 0.033878, loss_s1: 0.014113, loss_fp: 0.001108, loss_freq: 0.014721
[19:15:34.268] iteration 26307: loss: 0.039696, loss_s1: 0.024923, loss_fp: 0.003355, loss_freq: 0.014228
[19:15:34.892] iteration 26308: loss: 0.048786, loss_s1: 0.036612, loss_fp: 0.004542, loss_freq: 0.021112
[19:15:35.520] iteration 26309: loss: 0.078480, loss_s1: 0.042349, loss_fp: 0.002368, loss_freq: 0.060283
[19:15:36.149] iteration 26310: loss: 0.056297, loss_s1: 0.041760, loss_fp: 0.001050, loss_freq: 0.026182
[19:15:36.797] iteration 26311: loss: 0.073537, loss_s1: 0.067949, loss_fp: 0.006680, loss_freq: 0.047037
[19:15:37.439] iteration 26312: loss: 0.054741, loss_s1: 0.062757, loss_fp: 0.000711, loss_freq: 0.011433
[19:15:38.091] iteration 26313: loss: 0.042292, loss_s1: 0.008804, loss_fp: 0.001662, loss_freq: 0.024704
[19:15:38.737] iteration 26314: loss: 0.075430, loss_s1: 0.051440, loss_fp: 0.010821, loss_freq: 0.053634
[19:15:39.374] iteration 26315: loss: 0.054507, loss_s1: 0.042427, loss_fp: 0.001365, loss_freq: 0.038260
[19:15:40.007] iteration 26316: loss: 0.075624, loss_s1: 0.052720, loss_fp: 0.009399, loss_freq: 0.048364
[19:15:40.640] iteration 26317: loss: 0.039424, loss_s1: 0.033858, loss_fp: 0.002292, loss_freq: 0.007143
[19:15:41.272] iteration 26318: loss: 0.040745, loss_s1: 0.039640, loss_fp: 0.002648, loss_freq: 0.010015
[19:15:41.899] iteration 26319: loss: 0.065739, loss_s1: 0.081420, loss_fp: 0.003825, loss_freq: 0.007502
[19:15:42.561] iteration 26320: loss: 0.059660, loss_s1: 0.061972, loss_fp: 0.010665, loss_freq: 0.018386
[19:15:43.242] iteration 26321: loss: 0.036652, loss_s1: 0.029969, loss_fp: 0.004036, loss_freq: 0.009171
[19:15:43.894] iteration 26322: loss: 0.028895, loss_s1: 0.024846, loss_fp: 0.001256, loss_freq: 0.006043
[19:15:44.537] iteration 26323: loss: 0.042591, loss_s1: 0.013043, loss_fp: 0.005679, loss_freq: 0.027283
[19:15:45.182] iteration 26324: loss: 0.066685, loss_s1: 0.021827, loss_fp: 0.002953, loss_freq: 0.067624
[19:15:45.818] iteration 26325: loss: 0.058332, loss_s1: 0.062454, loss_fp: 0.003446, loss_freq: 0.020056
[19:15:46.448] iteration 26326: loss: 0.046718, loss_s1: 0.040427, loss_fp: 0.007157, loss_freq: 0.014448
[19:15:47.070] iteration 26327: loss: 0.041501, loss_s1: 0.025465, loss_fp: 0.002533, loss_freq: 0.017128
[19:15:47.698] iteration 26328: loss: 0.073881, loss_s1: 0.077861, loss_fp: 0.002609, loss_freq: 0.037452
[19:15:48.325] iteration 26329: loss: 0.053778, loss_s1: 0.060217, loss_fp: 0.001061, loss_freq: 0.018074
[19:15:48.954] iteration 26330: loss: 0.035421, loss_s1: 0.019796, loss_fp: 0.004258, loss_freq: 0.007142
[19:15:49.581] iteration 26331: loss: 0.040590, loss_s1: 0.040208, loss_fp: 0.001539, loss_freq: 0.003308
[19:15:50.213] iteration 26332: loss: 0.055299, loss_s1: 0.032227, loss_fp: 0.010732, loss_freq: 0.031665
[19:15:50.844] iteration 26333: loss: 0.081470, loss_s1: 0.089723, loss_fp: 0.013216, loss_freq: 0.025308
[19:15:51.474] iteration 26334: loss: 0.070357, loss_s1: 0.049039, loss_fp: 0.003114, loss_freq: 0.032444
[19:15:52.115] iteration 26335: loss: 0.041647, loss_s1: 0.035604, loss_fp: 0.000666, loss_freq: 0.012782
[19:15:52.753] iteration 26336: loss: 0.048592, loss_s1: 0.013793, loss_fp: 0.002174, loss_freq: 0.035133
[19:15:53.384] iteration 26337: loss: 0.044622, loss_s1: 0.034089, loss_fp: 0.001468, loss_freq: 0.024177
[19:15:54.014] iteration 26338: loss: 0.066429, loss_s1: 0.083529, loss_fp: 0.002217, loss_freq: 0.024079
[19:15:54.644] iteration 26339: loss: 0.043676, loss_s1: 0.041839, loss_fp: 0.000838, loss_freq: 0.020121
[19:15:55.271] iteration 26340: loss: 0.037434, loss_s1: 0.024030, loss_fp: 0.000882, loss_freq: 0.013172
[19:15:55.900] iteration 26341: loss: 0.035464, loss_s1: 0.017480, loss_fp: 0.000313, loss_freq: 0.015089
[19:15:56.530] iteration 26342: loss: 0.049762, loss_s1: 0.022225, loss_fp: 0.002984, loss_freq: 0.043530
[19:15:57.157] iteration 26343: loss: 0.044134, loss_s1: 0.029333, loss_fp: 0.003290, loss_freq: 0.021703
[19:15:57.791] iteration 26344: loss: 0.044790, loss_s1: 0.035162, loss_fp: 0.003236, loss_freq: 0.022008
[19:15:58.422] iteration 26345: loss: 0.062418, loss_s1: 0.054036, loss_fp: 0.001336, loss_freq: 0.033057
[19:15:59.050] iteration 26346: loss: 0.060641, loss_s1: 0.059250, loss_fp: 0.004095, loss_freq: 0.035470
[19:15:59.688] iteration 26347: loss: 0.037171, loss_s1: 0.022282, loss_fp: 0.007416, loss_freq: 0.015666
[19:16:00.314] iteration 26348: loss: 0.044583, loss_s1: 0.016083, loss_fp: 0.002001, loss_freq: 0.016945
[19:16:00.945] iteration 26349: loss: 0.038493, loss_s1: 0.023426, loss_fp: 0.003569, loss_freq: 0.024953
[19:16:01.574] iteration 26350: loss: 0.034164, loss_s1: 0.023185, loss_fp: 0.002557, loss_freq: 0.004877
[19:16:02.214] iteration 26351: loss: 0.052868, loss_s1: 0.030791, loss_fp: 0.006425, loss_freq: 0.027236
[19:16:02.858] iteration 26352: loss: 0.089244, loss_s1: 0.074045, loss_fp: 0.004451, loss_freq: 0.059446
[19:16:03.499] iteration 26353: loss: 0.045817, loss_s1: 0.040082, loss_fp: 0.002092, loss_freq: 0.020364
[19:16:04.136] iteration 26354: loss: 0.057949, loss_s1: 0.040659, loss_fp: 0.005864, loss_freq: 0.033625
[19:16:04.767] iteration 26355: loss: 0.056999, loss_s1: 0.027485, loss_fp: 0.007875, loss_freq: 0.053438
[19:16:05.393] iteration 26356: loss: 0.064620, loss_s1: 0.075405, loss_fp: 0.018317, loss_freq: 0.009951
[19:16:06.018] iteration 26357: loss: 0.028756, loss_s1: 0.017306, loss_fp: 0.003326, loss_freq: 0.011755
[19:16:06.638] iteration 26358: loss: 0.035472, loss_s1: 0.013027, loss_fp: 0.000750, loss_freq: 0.019900
[19:16:07.264] iteration 26359: loss: 0.071698, loss_s1: 0.084172, loss_fp: 0.003845, loss_freq: 0.026532
[19:16:07.889] iteration 26360: loss: 0.050184, loss_s1: 0.059837, loss_fp: 0.000593, loss_freq: 0.012666
[19:16:08.513] iteration 26361: loss: 0.031727, loss_s1: 0.027124, loss_fp: 0.001904, loss_freq: 0.007595
[19:16:09.140] iteration 26362: loss: 0.048897, loss_s1: 0.025681, loss_fp: 0.002897, loss_freq: 0.037613
[19:16:09.768] iteration 26363: loss: 0.084721, loss_s1: 0.077948, loss_fp: 0.005033, loss_freq: 0.061940
[19:16:10.405] iteration 26364: loss: 0.046455, loss_s1: 0.030179, loss_fp: 0.004043, loss_freq: 0.028721
[19:16:11.026] iteration 26365: loss: 0.046150, loss_s1: 0.030985, loss_fp: 0.004065, loss_freq: 0.022510
[19:16:11.656] iteration 26366: loss: 0.093685, loss_s1: 0.135749, loss_fp: 0.001400, loss_freq: 0.019918
[19:16:12.279] iteration 26367: loss: 0.054226, loss_s1: 0.065578, loss_fp: 0.004463, loss_freq: 0.007513
[19:16:12.906] iteration 26368: loss: 0.041074, loss_s1: 0.029563, loss_fp: 0.005004, loss_freq: 0.018658
[19:16:13.539] iteration 26369: loss: 0.056060, loss_s1: 0.052152, loss_fp: 0.004831, loss_freq: 0.018857
[19:16:14.170] iteration 26370: loss: 0.043820, loss_s1: 0.031352, loss_fp: 0.002532, loss_freq: 0.010828
[19:16:14.799] iteration 26371: loss: 0.063819, loss_s1: 0.040032, loss_fp: 0.000788, loss_freq: 0.038261
[19:16:15.422] iteration 26372: loss: 0.032297, loss_s1: 0.021032, loss_fp: 0.001944, loss_freq: 0.018440
[19:16:16.044] iteration 26373: loss: 0.045361, loss_s1: 0.023087, loss_fp: 0.005284, loss_freq: 0.039746
[19:16:16.672] iteration 26374: loss: 0.053344, loss_s1: 0.038975, loss_fp: 0.003041, loss_freq: 0.041640
[19:16:17.303] iteration 26375: loss: 0.061004, loss_s1: 0.059812, loss_fp: 0.002268, loss_freq: 0.016667
[19:16:17.934] iteration 26376: loss: 0.054171, loss_s1: 0.025823, loss_fp: 0.009924, loss_freq: 0.036470
[19:16:18.571] iteration 26377: loss: 0.036461, loss_s1: 0.013560, loss_fp: 0.001627, loss_freq: 0.016143
[19:16:19.203] iteration 26378: loss: 0.066544, loss_s1: 0.054342, loss_fp: 0.004754, loss_freq: 0.017793
[19:16:19.831] iteration 26379: loss: 0.052842, loss_s1: 0.036935, loss_fp: 0.005184, loss_freq: 0.024898
[19:16:20.458] iteration 26380: loss: 0.040466, loss_s1: 0.023845, loss_fp: 0.002213, loss_freq: 0.010117
[19:16:21.082] iteration 26381: loss: 0.048723, loss_s1: 0.047459, loss_fp: 0.002415, loss_freq: 0.014905
[19:16:21.706] iteration 26382: loss: 0.029545, loss_s1: 0.020829, loss_fp: 0.000560, loss_freq: 0.007804
[19:16:22.331] iteration 26383: loss: 0.078521, loss_s1: 0.058297, loss_fp: 0.007197, loss_freq: 0.033051
[19:16:22.962] iteration 26384: loss: 0.039403, loss_s1: 0.024247, loss_fp: 0.005694, loss_freq: 0.018531
[19:16:23.587] iteration 26385: loss: 0.057364, loss_s1: 0.049511, loss_fp: 0.003412, loss_freq: 0.033678
[19:16:24.208] iteration 26386: loss: 0.039663, loss_s1: 0.018310, loss_fp: 0.005495, loss_freq: 0.024106
[19:16:24.833] iteration 26387: loss: 0.054721, loss_s1: 0.035088, loss_fp: 0.007528, loss_freq: 0.025947
[19:16:25.466] iteration 26388: loss: 0.040318, loss_s1: 0.025154, loss_fp: 0.005424, loss_freq: 0.018948
[19:16:26.093] iteration 26389: loss: 0.066454, loss_s1: 0.076318, loss_fp: 0.005236, loss_freq: 0.014339
[19:16:26.717] iteration 26390: loss: 0.076194, loss_s1: 0.065241, loss_fp: 0.006845, loss_freq: 0.054604
[19:16:27.341] iteration 26391: loss: 0.033853, loss_s1: 0.031287, loss_fp: 0.002287, loss_freq: 0.010670
[19:16:27.960] iteration 26392: loss: 0.031743, loss_s1: 0.024270, loss_fp: 0.002457, loss_freq: 0.012562
[19:16:28.585] iteration 26393: loss: 0.066542, loss_s1: 0.045823, loss_fp: 0.007242, loss_freq: 0.045413
[19:16:29.213] iteration 26394: loss: 0.043702, loss_s1: 0.038248, loss_fp: 0.003715, loss_freq: 0.014451
[19:16:29.839] iteration 26395: loss: 0.072750, loss_s1: 0.037848, loss_fp: 0.014166, loss_freq: 0.061096
[19:16:30.465] iteration 26396: loss: 0.045913, loss_s1: 0.030965, loss_fp: 0.003701, loss_freq: 0.023570
[19:16:31.098] iteration 26397: loss: 0.074348, loss_s1: 0.051743, loss_fp: 0.004488, loss_freq: 0.029732
[19:16:31.731] iteration 26398: loss: 0.036369, loss_s1: 0.033073, loss_fp: 0.006259, loss_freq: 0.010277
[19:16:32.378] iteration 26399: loss: 0.046131, loss_s1: 0.044243, loss_fp: 0.001068, loss_freq: 0.011195
[19:16:33.018] iteration 26400: loss: 0.033862, loss_s1: 0.014027, loss_fp: 0.001202, loss_freq: 0.013732
[19:16:36.223] iteration 26400 : mean_dice : 0.744026
[19:16:36.866] iteration 26401: loss: 0.044543, loss_s1: 0.035591, loss_fp: 0.001009, loss_freq: 0.013595
[19:16:37.498] iteration 26402: loss: 0.052051, loss_s1: 0.052848, loss_fp: 0.002162, loss_freq: 0.019018
[19:16:38.123] iteration 26403: loss: 0.051065, loss_s1: 0.039447, loss_fp: 0.002863, loss_freq: 0.025914
[19:16:38.743] iteration 26404: loss: 0.043414, loss_s1: 0.014568, loss_fp: 0.002963, loss_freq: 0.032731
[19:16:39.751] iteration 26405: loss: 0.032254, loss_s1: 0.027967, loss_fp: 0.001336, loss_freq: 0.005125
[19:16:40.392] iteration 26406: loss: 0.063473, loss_s1: 0.036416, loss_fp: 0.005345, loss_freq: 0.045234
[19:16:41.019] iteration 26407: loss: 0.043306, loss_s1: 0.044730, loss_fp: 0.001353, loss_freq: 0.011358
[19:16:41.648] iteration 26408: loss: 0.055353, loss_s1: 0.029767, loss_fp: 0.000963, loss_freq: 0.026462
[19:16:42.280] iteration 26409: loss: 0.046380, loss_s1: 0.027287, loss_fp: 0.001749, loss_freq: 0.026773
[19:16:42.905] iteration 26410: loss: 0.074459, loss_s1: 0.040149, loss_fp: 0.019190, loss_freq: 0.048295
[19:16:43.522] iteration 26411: loss: 0.065195, loss_s1: 0.068784, loss_fp: 0.003104, loss_freq: 0.022900
[19:16:44.146] iteration 26412: loss: 0.027915, loss_s1: 0.018513, loss_fp: 0.001794, loss_freq: 0.010923
[19:16:44.770] iteration 26413: loss: 0.050662, loss_s1: 0.045054, loss_fp: 0.004707, loss_freq: 0.023328
[19:16:45.395] iteration 26414: loss: 0.108183, loss_s1: 0.154611, loss_fp: 0.011487, loss_freq: 0.011903
[19:16:46.018] iteration 26415: loss: 0.032178, loss_s1: 0.006951, loss_fp: 0.000300, loss_freq: 0.017319
[19:16:46.645] iteration 26416: loss: 0.065189, loss_s1: 0.069856, loss_fp: 0.003485, loss_freq: 0.022911
[19:16:47.271] iteration 26417: loss: 0.094775, loss_s1: 0.067104, loss_fp: 0.004716, loss_freq: 0.091657
[19:16:47.905] iteration 26418: loss: 0.065138, loss_s1: 0.046951, loss_fp: 0.005185, loss_freq: 0.031322
[19:16:48.548] iteration 26419: loss: 0.036361, loss_s1: 0.035093, loss_fp: 0.001344, loss_freq: 0.010785
[19:16:49.191] iteration 26420: loss: 0.059941, loss_s1: 0.042445, loss_fp: 0.003113, loss_freq: 0.040902
[19:16:49.826] iteration 26421: loss: 0.048910, loss_s1: 0.040364, loss_fp: 0.005215, loss_freq: 0.017127
[19:16:50.462] iteration 26422: loss: 0.042334, loss_s1: 0.025616, loss_fp: 0.002817, loss_freq: 0.030128
[19:16:51.094] iteration 26423: loss: 0.036806, loss_s1: 0.013662, loss_fp: 0.004274, loss_freq: 0.023250
[19:16:51.737] iteration 26424: loss: 0.053738, loss_s1: 0.044446, loss_fp: 0.003639, loss_freq: 0.018703
[19:16:52.381] iteration 26425: loss: 0.049567, loss_s1: 0.051403, loss_fp: 0.000456, loss_freq: 0.013822
[19:16:53.012] iteration 26426: loss: 0.050552, loss_s1: 0.026799, loss_fp: 0.001213, loss_freq: 0.024943
[19:16:53.637] iteration 26427: loss: 0.068413, loss_s1: 0.050830, loss_fp: 0.005682, loss_freq: 0.032994
[19:16:54.274] iteration 26428: loss: 0.053208, loss_s1: 0.042727, loss_fp: 0.003073, loss_freq: 0.029966
[19:16:54.909] iteration 26429: loss: 0.072251, loss_s1: 0.082024, loss_fp: 0.003469, loss_freq: 0.029364
[19:16:55.556] iteration 26430: loss: 0.052059, loss_s1: 0.052475, loss_fp: 0.003457, loss_freq: 0.023233
[19:16:56.185] iteration 26431: loss: 0.037758, loss_s1: 0.017767, loss_fp: 0.004917, loss_freq: 0.022745
[19:16:56.815] iteration 26432: loss: 0.042319, loss_s1: 0.031291, loss_fp: 0.012447, loss_freq: 0.010167
[19:16:57.446] iteration 26433: loss: 0.055655, loss_s1: 0.028114, loss_fp: 0.005030, loss_freq: 0.049179
[19:16:58.074] iteration 26434: loss: 0.042675, loss_s1: 0.044567, loss_fp: 0.002790, loss_freq: 0.006172
[19:16:58.698] iteration 26435: loss: 0.071781, loss_s1: 0.068891, loss_fp: 0.007976, loss_freq: 0.039214
[19:16:59.365] iteration 26436: loss: 0.067593, loss_s1: 0.057605, loss_fp: 0.000890, loss_freq: 0.032357
[19:17:00.016] iteration 26437: loss: 0.056811, loss_s1: 0.060264, loss_fp: 0.003408, loss_freq: 0.024922
[19:17:00.665] iteration 26438: loss: 0.045085, loss_s1: 0.049237, loss_fp: 0.001423, loss_freq: 0.004886
[19:17:01.307] iteration 26439: loss: 0.083659, loss_s1: 0.068243, loss_fp: 0.014495, loss_freq: 0.033534
[19:17:01.941] iteration 26440: loss: 0.060534, loss_s1: 0.051135, loss_fp: 0.011125, loss_freq: 0.031622
[19:17:02.580] iteration 26441: loss: 0.055264, loss_s1: 0.027252, loss_fp: 0.019449, loss_freq: 0.026968
[19:17:03.198] iteration 26442: loss: 0.052764, loss_s1: 0.028087, loss_fp: 0.009609, loss_freq: 0.037247
[19:17:03.822] iteration 26443: loss: 0.055332, loss_s1: 0.042215, loss_fp: 0.003137, loss_freq: 0.022095
[19:17:04.451] iteration 26444: loss: 0.044529, loss_s1: 0.023746, loss_fp: 0.003621, loss_freq: 0.025827
[19:17:05.076] iteration 26445: loss: 0.036235, loss_s1: 0.023087, loss_fp: 0.001783, loss_freq: 0.014127
[19:17:05.703] iteration 26446: loss: 0.095054, loss_s1: 0.087625, loss_fp: 0.004097, loss_freq: 0.073056
[19:17:06.329] iteration 26447: loss: 0.072547, loss_s1: 0.080189, loss_fp: 0.010030, loss_freq: 0.025715
[19:17:06.957] iteration 26448: loss: 0.029544, loss_s1: 0.010511, loss_fp: 0.001916, loss_freq: 0.020771
[19:17:07.589] iteration 26449: loss: 0.048380, loss_s1: 0.049857, loss_fp: 0.002137, loss_freq: 0.011503
[19:17:08.215] iteration 26450: loss: 0.045514, loss_s1: 0.037395, loss_fp: 0.001382, loss_freq: 0.010643
[19:17:08.836] iteration 26451: loss: 0.035248, loss_s1: 0.024900, loss_fp: 0.002327, loss_freq: 0.012743
[19:17:09.461] iteration 26452: loss: 0.030702, loss_s1: 0.021664, loss_fp: 0.002658, loss_freq: 0.012237
[19:17:10.097] iteration 26453: loss: 0.061824, loss_s1: 0.074539, loss_fp: 0.006943, loss_freq: 0.009636
[19:17:10.736] iteration 26454: loss: 0.077451, loss_s1: 0.093028, loss_fp: 0.001612, loss_freq: 0.034476
[19:17:11.367] iteration 26455: loss: 0.054597, loss_s1: 0.054482, loss_fp: 0.005439, loss_freq: 0.014138
[19:17:11.995] iteration 26456: loss: 0.046728, loss_s1: 0.015712, loss_fp: 0.000745, loss_freq: 0.032689
[19:17:12.627] iteration 26457: loss: 0.066019, loss_s1: 0.046927, loss_fp: 0.002129, loss_freq: 0.053279
[19:17:13.262] iteration 26458: loss: 0.038273, loss_s1: 0.021600, loss_fp: 0.003280, loss_freq: 0.019785
[19:17:13.894] iteration 26459: loss: 0.035861, loss_s1: 0.023450, loss_fp: 0.002851, loss_freq: 0.021635
[19:17:14.542] iteration 26460: loss: 0.052833, loss_s1: 0.047413, loss_fp: 0.004293, loss_freq: 0.020650
[19:17:15.165] iteration 26461: loss: 0.041504, loss_s1: 0.036580, loss_fp: 0.003913, loss_freq: 0.002797
[19:17:15.791] iteration 26462: loss: 0.050055, loss_s1: 0.026977, loss_fp: 0.006344, loss_freq: 0.020794
[19:17:16.418] iteration 26463: loss: 0.034719, loss_s1: 0.027054, loss_fp: 0.002094, loss_freq: 0.013249
[19:17:17.053] iteration 26464: loss: 0.054124, loss_s1: 0.038728, loss_fp: 0.004032, loss_freq: 0.036184
[19:17:17.683] iteration 26465: loss: 0.040254, loss_s1: 0.033405, loss_fp: 0.000760, loss_freq: 0.021242
[19:17:18.307] iteration 26466: loss: 0.044108, loss_s1: 0.023426, loss_fp: 0.006810, loss_freq: 0.025362
[19:17:18.937] iteration 26467: loss: 0.037538, loss_s1: 0.025229, loss_fp: 0.000310, loss_freq: 0.008624
[19:17:19.574] iteration 26468: loss: 0.036030, loss_s1: 0.028817, loss_fp: 0.002396, loss_freq: 0.006685
[19:17:20.211] iteration 26469: loss: 0.050760, loss_s1: 0.043259, loss_fp: 0.008547, loss_freq: 0.020967
[19:17:20.835] iteration 26470: loss: 0.058124, loss_s1: 0.058174, loss_fp: 0.002536, loss_freq: 0.024172
[19:17:21.458] iteration 26471: loss: 0.054362, loss_s1: 0.032511, loss_fp: 0.003533, loss_freq: 0.037457
[19:17:22.084] iteration 26472: loss: 0.071920, loss_s1: 0.082043, loss_fp: 0.007206, loss_freq: 0.028305
[19:17:22.703] iteration 26473: loss: 0.040455, loss_s1: 0.025812, loss_fp: 0.006147, loss_freq: 0.017938
[19:17:23.329] iteration 26474: loss: 0.053462, loss_s1: 0.047032, loss_fp: 0.003594, loss_freq: 0.014753
[19:17:23.952] iteration 26475: loss: 0.101757, loss_s1: 0.105371, loss_fp: 0.006976, loss_freq: 0.052728
[19:17:24.572] iteration 26476: loss: 0.045858, loss_s1: 0.023064, loss_fp: 0.007325, loss_freq: 0.029497
[19:17:25.200] iteration 26477: loss: 0.052810, loss_s1: 0.051044, loss_fp: 0.002816, loss_freq: 0.019148
[19:17:25.846] iteration 26478: loss: 0.048856, loss_s1: 0.039941, loss_fp: 0.001887, loss_freq: 0.007267
[19:17:26.484] iteration 26479: loss: 0.057696, loss_s1: 0.041199, loss_fp: 0.003005, loss_freq: 0.040010
[19:17:27.126] iteration 26480: loss: 0.045536, loss_s1: 0.021463, loss_fp: 0.004149, loss_freq: 0.023024
[19:17:27.759] iteration 26481: loss: 0.040303, loss_s1: 0.020401, loss_fp: 0.002229, loss_freq: 0.028030
[19:17:28.404] iteration 26482: loss: 0.035754, loss_s1: 0.033124, loss_fp: 0.003549, loss_freq: 0.008459
[19:17:29.041] iteration 26483: loss: 0.019067, loss_s1: 0.008235, loss_fp: 0.001485, loss_freq: 0.005221
[19:17:29.673] iteration 26484: loss: 0.049506, loss_s1: 0.031123, loss_fp: 0.003798, loss_freq: 0.023840
[19:17:30.296] iteration 26485: loss: 0.078484, loss_s1: 0.066406, loss_fp: 0.002678, loss_freq: 0.037774
[19:17:30.922] iteration 26486: loss: 0.086354, loss_s1: 0.099547, loss_fp: 0.004870, loss_freq: 0.038212
[19:17:31.547] iteration 26487: loss: 0.041613, loss_s1: 0.034334, loss_fp: 0.004387, loss_freq: 0.018034
[19:17:32.178] iteration 26488: loss: 0.061252, loss_s1: 0.066795, loss_fp: 0.001481, loss_freq: 0.023307
[19:17:32.802] iteration 26489: loss: 0.084701, loss_s1: 0.088350, loss_fp: 0.014551, loss_freq: 0.040395
[19:17:33.440] iteration 26490: loss: 0.030991, loss_s1: 0.017486, loss_fp: 0.001833, loss_freq: 0.014587
[19:17:34.068] iteration 26491: loss: 0.055348, loss_s1: 0.041689, loss_fp: 0.002611, loss_freq: 0.020171
[19:17:34.692] iteration 26492: loss: 0.054169, loss_s1: 0.035801, loss_fp: 0.005270, loss_freq: 0.021587
[19:17:35.344] iteration 26493: loss: 0.048421, loss_s1: 0.018501, loss_fp: 0.009863, loss_freq: 0.039227
[19:17:35.970] iteration 26494: loss: 0.053949, loss_s1: 0.036664, loss_fp: 0.003917, loss_freq: 0.024673
[19:17:36.611] iteration 26495: loss: 0.061925, loss_s1: 0.033119, loss_fp: 0.001543, loss_freq: 0.016984
[19:17:37.245] iteration 26496: loss: 0.060226, loss_s1: 0.053944, loss_fp: 0.008245, loss_freq: 0.025102
[19:17:37.891] iteration 26497: loss: 0.060720, loss_s1: 0.036622, loss_fp: 0.005653, loss_freq: 0.033494
[19:17:38.527] iteration 26498: loss: 0.044093, loss_s1: 0.034896, loss_fp: 0.006565, loss_freq: 0.014951
[19:17:39.163] iteration 26499: loss: 0.025944, loss_s1: 0.015324, loss_fp: 0.001815, loss_freq: 0.010359
[19:17:39.793] iteration 26500: loss: 0.070196, loss_s1: 0.052170, loss_fp: 0.008478, loss_freq: 0.054084
[19:17:40.436] iteration 26501: loss: 0.033180, loss_s1: 0.017148, loss_fp: 0.002983, loss_freq: 0.015217
[19:17:41.062] iteration 26502: loss: 0.033171, loss_s1: 0.021121, loss_fp: 0.000351, loss_freq: 0.008977
[19:17:41.687] iteration 26503: loss: 0.048867, loss_s1: 0.059628, loss_fp: 0.001988, loss_freq: 0.008984
[19:17:42.312] iteration 26504: loss: 0.046892, loss_s1: 0.040306, loss_fp: 0.002476, loss_freq: 0.011451
[19:17:42.942] iteration 26505: loss: 0.045023, loss_s1: 0.039721, loss_fp: 0.001319, loss_freq: 0.017578
[19:17:43.571] iteration 26506: loss: 0.069980, loss_s1: 0.055543, loss_fp: 0.001505, loss_freq: 0.036671
[19:17:44.202] iteration 26507: loss: 0.048305, loss_s1: 0.040954, loss_fp: 0.001551, loss_freq: 0.025743
[19:17:44.864] iteration 26508: loss: 0.077264, loss_s1: 0.087036, loss_fp: 0.002583, loss_freq: 0.035975
[19:17:45.500] iteration 26509: loss: 0.048022, loss_s1: 0.032495, loss_fp: 0.005645, loss_freq: 0.015156
[19:17:46.147] iteration 26510: loss: 0.049287, loss_s1: 0.030840, loss_fp: 0.001340, loss_freq: 0.011204
[19:17:46.772] iteration 26511: loss: 0.028375, loss_s1: 0.024637, loss_fp: 0.001847, loss_freq: 0.001597
[19:17:47.394] iteration 26512: loss: 0.039809, loss_s1: 0.023162, loss_fp: 0.000982, loss_freq: 0.019534
[19:17:48.021] iteration 26513: loss: 0.060538, loss_s1: 0.053422, loss_fp: 0.006270, loss_freq: 0.026752
[19:17:48.651] iteration 26514: loss: 0.044129, loss_s1: 0.009904, loss_fp: 0.004298, loss_freq: 0.034837
[19:17:49.282] iteration 26515: loss: 0.045042, loss_s1: 0.033411, loss_fp: 0.002962, loss_freq: 0.017166
[19:17:49.908] iteration 26516: loss: 0.074066, loss_s1: 0.060427, loss_fp: 0.004902, loss_freq: 0.047719
[19:17:50.589] iteration 26517: loss: 0.059776, loss_s1: 0.052992, loss_fp: 0.001806, loss_freq: 0.033771
[19:17:51.220] iteration 26518: loss: 0.035107, loss_s1: 0.034242, loss_fp: 0.000760, loss_freq: 0.009316
[19:17:51.860] iteration 26519: loss: 0.039789, loss_s1: 0.028903, loss_fp: 0.002326, loss_freq: 0.014597
[19:17:52.492] iteration 26520: loss: 0.084947, loss_s1: 0.073375, loss_fp: 0.004059, loss_freq: 0.055101
[19:17:53.136] iteration 26521: loss: 0.039698, loss_s1: 0.046905, loss_fp: 0.002389, loss_freq: 0.004815
[19:17:53.762] iteration 26522: loss: 0.035463, loss_s1: 0.025304, loss_fp: 0.001821, loss_freq: 0.017231
[19:17:54.387] iteration 26523: loss: 0.043739, loss_s1: 0.010349, loss_fp: 0.003378, loss_freq: 0.035265
[19:17:55.012] iteration 26524: loss: 0.092334, loss_s1: 0.046092, loss_fp: 0.005846, loss_freq: 0.107342
[19:17:55.643] iteration 26525: loss: 0.043460, loss_s1: 0.044675, loss_fp: 0.001967, loss_freq: 0.006823
[19:17:56.270] iteration 26526: loss: 0.086496, loss_s1: 0.039312, loss_fp: 0.003174, loss_freq: 0.061576
[19:17:56.892] iteration 26527: loss: 0.052999, loss_s1: 0.059403, loss_fp: 0.000952, loss_freq: 0.015467
[19:17:57.527] iteration 26528: loss: 0.037983, loss_s1: 0.020342, loss_fp: 0.004035, loss_freq: 0.014831
[19:17:58.155] iteration 26529: loss: 0.044198, loss_s1: 0.024475, loss_fp: 0.002494, loss_freq: 0.032571
[19:17:58.802] iteration 26530: loss: 0.040237, loss_s1: 0.025635, loss_fp: 0.001935, loss_freq: 0.017677
[19:17:59.434] iteration 26531: loss: 0.037276, loss_s1: 0.025520, loss_fp: 0.002157, loss_freq: 0.007834
[19:18:00.061] iteration 26532: loss: 0.076976, loss_s1: 0.024523, loss_fp: 0.012175, loss_freq: 0.055083
[19:18:00.686] iteration 26533: loss: 0.059208, loss_s1: 0.050894, loss_fp: 0.007080, loss_freq: 0.032119
[19:18:01.314] iteration 26534: loss: 0.030814, loss_s1: 0.014734, loss_fp: 0.011211, loss_freq: 0.009022
[19:18:01.939] iteration 26535: loss: 0.039051, loss_s1: 0.031191, loss_fp: 0.001507, loss_freq: 0.018341
[19:18:02.564] iteration 26536: loss: 0.048577, loss_s1: 0.051229, loss_fp: 0.003128, loss_freq: 0.011525
[19:18:03.189] iteration 26537: loss: 0.065515, loss_s1: 0.064085, loss_fp: 0.003095, loss_freq: 0.033987
[19:18:03.809] iteration 26538: loss: 0.043851, loss_s1: 0.023934, loss_fp: 0.003618, loss_freq: 0.019344
[19:18:04.435] iteration 26539: loss: 0.043157, loss_s1: 0.031419, loss_fp: 0.006132, loss_freq: 0.019343
[19:18:05.064] iteration 26540: loss: 0.053900, loss_s1: 0.032652, loss_fp: 0.012013, loss_freq: 0.035242
[19:18:05.702] iteration 26541: loss: 0.034560, loss_s1: 0.019468, loss_fp: 0.004000, loss_freq: 0.005562
[19:18:06.322] iteration 26542: loss: 0.045363, loss_s1: 0.036996, loss_fp: 0.002984, loss_freq: 0.021795
[19:18:06.942] iteration 26543: loss: 0.046404, loss_s1: 0.042838, loss_fp: 0.001232, loss_freq: 0.009710
[19:18:07.568] iteration 26544: loss: 0.063597, loss_s1: 0.060001, loss_fp: 0.005587, loss_freq: 0.017561
[19:18:08.195] iteration 26545: loss: 0.067925, loss_s1: 0.074470, loss_fp: 0.002955, loss_freq: 0.022268
[19:18:08.825] iteration 26546: loss: 0.030425, loss_s1: 0.017174, loss_fp: 0.001346, loss_freq: 0.008103
[19:18:09.447] iteration 26547: loss: 0.055842, loss_s1: 0.046035, loss_fp: 0.003884, loss_freq: 0.032060
[19:18:10.078] iteration 26548: loss: 0.065653, loss_s1: 0.067930, loss_fp: 0.008036, loss_freq: 0.019311
[19:18:10.754] iteration 26549: loss: 0.028321, loss_s1: 0.015091, loss_fp: 0.002942, loss_freq: 0.011509
[19:18:11.400] iteration 26550: loss: 0.036414, loss_s1: 0.028670, loss_fp: 0.001535, loss_freq: 0.006536
[19:18:12.041] iteration 26551: loss: 0.078885, loss_s1: 0.062952, loss_fp: 0.012850, loss_freq: 0.054715
[19:18:12.666] iteration 26552: loss: 0.035094, loss_s1: 0.032003, loss_fp: 0.002442, loss_freq: 0.011264
[19:18:13.291] iteration 26553: loss: 0.029925, loss_s1: 0.018869, loss_fp: 0.001879, loss_freq: 0.011124
[19:18:13.921] iteration 26554: loss: 0.060927, loss_s1: 0.031306, loss_fp: 0.005597, loss_freq: 0.040111
[19:18:14.544] iteration 26555: loss: 0.067714, loss_s1: 0.066001, loss_fp: 0.002693, loss_freq: 0.037109
[19:18:15.172] iteration 26556: loss: 0.096196, loss_s1: 0.053641, loss_fp: 0.011240, loss_freq: 0.089713
[19:18:15.795] iteration 26557: loss: 0.045619, loss_s1: 0.037287, loss_fp: 0.003992, loss_freq: 0.017788
[19:18:16.430] iteration 26558: loss: 0.057932, loss_s1: 0.034313, loss_fp: 0.003600, loss_freq: 0.042586
[19:18:17.054] iteration 26559: loss: 0.032748, loss_s1: 0.016427, loss_fp: 0.003097, loss_freq: 0.011033
[19:18:17.679] iteration 26560: loss: 0.041267, loss_s1: 0.031474, loss_fp: 0.001298, loss_freq: 0.019682
[19:18:18.326] iteration 26561: loss: 0.058626, loss_s1: 0.025068, loss_fp: 0.000829, loss_freq: 0.012256
[19:18:18.966] iteration 26562: loss: 0.035090, loss_s1: 0.017187, loss_fp: 0.002856, loss_freq: 0.015033
[19:18:19.592] iteration 26563: loss: 0.065367, loss_s1: 0.030454, loss_fp: 0.021011, loss_freq: 0.039290
[19:18:20.214] iteration 26564: loss: 0.073011, loss_s1: 0.058619, loss_fp: 0.006901, loss_freq: 0.029296
[19:18:20.840] iteration 26565: loss: 0.060959, loss_s1: 0.057307, loss_fp: 0.005026, loss_freq: 0.021315
[19:18:21.814] iteration 26566: loss: 0.030310, loss_s1: 0.014605, loss_fp: 0.002391, loss_freq: 0.019764
[19:18:22.449] iteration 26567: loss: 0.050499, loss_s1: 0.045435, loss_fp: 0.013149, loss_freq: 0.015416
[19:18:23.109] iteration 26568: loss: 0.047326, loss_s1: 0.050052, loss_fp: 0.001079, loss_freq: 0.007558
[19:18:23.738] iteration 26569: loss: 0.046086, loss_s1: 0.038897, loss_fp: 0.002467, loss_freq: 0.014080
[19:18:24.371] iteration 26570: loss: 0.065953, loss_s1: 0.047629, loss_fp: 0.003421, loss_freq: 0.046319
[19:18:24.994] iteration 26571: loss: 0.081110, loss_s1: 0.072417, loss_fp: 0.010558, loss_freq: 0.040447
[19:18:25.621] iteration 26572: loss: 0.077907, loss_s1: 0.060742, loss_fp: 0.009993, loss_freq: 0.054263
[19:18:26.254] iteration 26573: loss: 0.038444, loss_s1: 0.023161, loss_fp: 0.005451, loss_freq: 0.022482
[19:18:26.885] iteration 26574: loss: 0.063320, loss_s1: 0.060741, loss_fp: 0.013158, loss_freq: 0.014914
[19:18:27.535] iteration 26575: loss: 0.060202, loss_s1: 0.056843, loss_fp: 0.005817, loss_freq: 0.019077
[19:18:28.172] iteration 26576: loss: 0.038503, loss_s1: 0.026454, loss_fp: 0.002322, loss_freq: 0.013120
[19:18:28.811] iteration 26577: loss: 0.042404, loss_s1: 0.032005, loss_fp: 0.010878, loss_freq: 0.011612
[19:18:29.441] iteration 26578: loss: 0.058292, loss_s1: 0.053115, loss_fp: 0.004301, loss_freq: 0.031889
[19:18:30.072] iteration 26579: loss: 0.054015, loss_s1: 0.023032, loss_fp: 0.002279, loss_freq: 0.017217
[19:18:30.701] iteration 26580: loss: 0.039157, loss_s1: 0.033232, loss_fp: 0.006319, loss_freq: 0.013109
[19:18:31.329] iteration 26581: loss: 0.098405, loss_s1: 0.103162, loss_fp: 0.003652, loss_freq: 0.054703
[19:18:31.954] iteration 26582: loss: 0.036485, loss_s1: 0.017495, loss_fp: 0.005372, loss_freq: 0.015391
[19:18:32.583] iteration 26583: loss: 0.055698, loss_s1: 0.053962, loss_fp: 0.005160, loss_freq: 0.024366
[19:18:33.213] iteration 26584: loss: 0.032049, loss_s1: 0.006202, loss_fp: 0.000656, loss_freq: 0.017912
[19:18:33.847] iteration 26585: loss: 0.049692, loss_s1: 0.038727, loss_fp: 0.003908, loss_freq: 0.024990
[19:18:34.478] iteration 26586: loss: 0.034813, loss_s1: 0.030017, loss_fp: 0.001483, loss_freq: 0.002793
[19:18:35.107] iteration 26587: loss: 0.046463, loss_s1: 0.029550, loss_fp: 0.003786, loss_freq: 0.013374
[19:18:35.781] iteration 26588: loss: 0.042827, loss_s1: 0.035451, loss_fp: 0.000583, loss_freq: 0.011802
[19:18:36.423] iteration 26589: loss: 0.052903, loss_s1: 0.034299, loss_fp: 0.011720, loss_freq: 0.032440
[19:18:37.064] iteration 26590: loss: 0.034670, loss_s1: 0.024179, loss_fp: 0.002634, loss_freq: 0.009937
[19:18:37.698] iteration 26591: loss: 0.044252, loss_s1: 0.037713, loss_fp: 0.006654, loss_freq: 0.012544
[19:18:38.334] iteration 26592: loss: 0.022823, loss_s1: 0.008776, loss_fp: 0.004318, loss_freq: 0.003375
[19:18:38.960] iteration 26593: loss: 0.075881, loss_s1: 0.079105, loss_fp: 0.011253, loss_freq: 0.023159
[19:18:39.585] iteration 26594: loss: 0.078245, loss_s1: 0.069363, loss_fp: 0.005114, loss_freq: 0.055741
[19:18:40.211] iteration 26595: loss: 0.043012, loss_s1: 0.043049, loss_fp: 0.002460, loss_freq: 0.014788
[19:18:40.833] iteration 26596: loss: 0.045031, loss_s1: 0.016140, loss_fp: 0.001674, loss_freq: 0.041998
[19:18:41.461] iteration 26597: loss: 0.031680, loss_s1: 0.023236, loss_fp: 0.004057, loss_freq: 0.006638
[19:18:42.091] iteration 26598: loss: 0.039118, loss_s1: 0.026486, loss_fp: 0.001071, loss_freq: 0.017895
[19:18:42.714] iteration 26599: loss: 0.053708, loss_s1: 0.043344, loss_fp: 0.001524, loss_freq: 0.010990
[19:18:43.342] iteration 26600: loss: 0.067947, loss_s1: 0.052474, loss_fp: 0.009592, loss_freq: 0.030756
[19:18:46.534] iteration 26600 : mean_dice : 0.728302
[19:18:47.175] iteration 26601: loss: 0.071125, loss_s1: 0.053246, loss_fp: 0.002460, loss_freq: 0.059434
[19:18:47.813] iteration 26602: loss: 0.062970, loss_s1: 0.053137, loss_fp: 0.002956, loss_freq: 0.029914
[19:18:48.474] iteration 26603: loss: 0.052818, loss_s1: 0.030618, loss_fp: 0.004282, loss_freq: 0.038401
[19:18:49.096] iteration 26604: loss: 0.064335, loss_s1: 0.044462, loss_fp: 0.001749, loss_freq: 0.042911
[19:18:49.723] iteration 26605: loss: 0.046497, loss_s1: 0.037880, loss_fp: 0.002881, loss_freq: 0.015053
[19:18:50.349] iteration 26606: loss: 0.057174, loss_s1: 0.057822, loss_fp: 0.005680, loss_freq: 0.010769
[19:18:50.982] iteration 26607: loss: 0.121993, loss_s1: 0.150999, loss_fp: 0.010033, loss_freq: 0.053318
[19:18:51.608] iteration 26608: loss: 0.054070, loss_s1: 0.056832, loss_fp: 0.002764, loss_freq: 0.024073
[19:18:52.237] iteration 26609: loss: 0.082542, loss_s1: 0.080429, loss_fp: 0.008949, loss_freq: 0.045396
[19:18:52.867] iteration 26610: loss: 0.050320, loss_s1: 0.032195, loss_fp: 0.002190, loss_freq: 0.026447
[19:18:53.498] iteration 26611: loss: 0.028070, loss_s1: 0.015531, loss_fp: 0.002067, loss_freq: 0.007028
[19:18:54.127] iteration 26612: loss: 0.025107, loss_s1: 0.009833, loss_fp: 0.000982, loss_freq: 0.007181
[19:18:54.758] iteration 26613: loss: 0.048296, loss_s1: 0.034024, loss_fp: 0.005314, loss_freq: 0.020826
[19:18:55.383] iteration 26614: loss: 0.065769, loss_s1: 0.070722, loss_fp: 0.013305, loss_freq: 0.013119
[19:18:56.010] iteration 26615: loss: 0.041702, loss_s1: 0.037300, loss_fp: 0.003296, loss_freq: 0.016290
[19:18:56.634] iteration 26616: loss: 0.064010, loss_s1: 0.056794, loss_fp: 0.003828, loss_freq: 0.035099
[19:18:57.256] iteration 26617: loss: 0.042416, loss_s1: 0.032560, loss_fp: 0.003407, loss_freq: 0.019339
[19:18:57.887] iteration 26618: loss: 0.044111, loss_s1: 0.017340, loss_fp: 0.003499, loss_freq: 0.030035
[19:18:58.511] iteration 26619: loss: 0.054786, loss_s1: 0.042004, loss_fp: 0.002298, loss_freq: 0.036155
[19:18:59.138] iteration 26620: loss: 0.032425, loss_s1: 0.015566, loss_fp: 0.005978, loss_freq: 0.012138
[19:18:59.766] iteration 26621: loss: 0.047273, loss_s1: 0.033284, loss_fp: 0.004015, loss_freq: 0.018079
[19:19:00.388] iteration 26622: loss: 0.039183, loss_s1: 0.029205, loss_fp: 0.001111, loss_freq: 0.005163
[19:19:01.012] iteration 26623: loss: 0.054998, loss_s1: 0.050516, loss_fp: 0.001611, loss_freq: 0.019640
[19:19:01.635] iteration 26624: loss: 0.027902, loss_s1: 0.019787, loss_fp: 0.001903, loss_freq: 0.006440
[19:19:02.260] iteration 26625: loss: 0.025780, loss_s1: 0.012025, loss_fp: 0.002318, loss_freq: 0.012947
[19:19:02.881] iteration 26626: loss: 0.039464, loss_s1: 0.027343, loss_fp: 0.006836, loss_freq: 0.015864
[19:19:03.504] iteration 26627: loss: 0.041620, loss_s1: 0.029648, loss_fp: 0.001734, loss_freq: 0.022648
[19:19:04.133] iteration 26628: loss: 0.042849, loss_s1: 0.024859, loss_fp: 0.001509, loss_freq: 0.020448
[19:19:04.765] iteration 26629: loss: 0.054227, loss_s1: 0.063155, loss_fp: 0.003310, loss_freq: 0.014314
[19:19:05.630] iteration 26630: loss: 0.039235, loss_s1: 0.030151, loss_fp: 0.003579, loss_freq: 0.015885
[19:19:06.301] iteration 26631: loss: 0.066151, loss_s1: 0.051419, loss_fp: 0.005003, loss_freq: 0.044615
[19:19:06.940] iteration 26632: loss: 0.052851, loss_s1: 0.037876, loss_fp: 0.003027, loss_freq: 0.021833
[19:19:07.570] iteration 26633: loss: 0.060068, loss_s1: 0.058308, loss_fp: 0.005839, loss_freq: 0.028395
[19:19:08.200] iteration 26634: loss: 0.034920, loss_s1: 0.023274, loss_fp: 0.004237, loss_freq: 0.012558
[19:19:08.836] iteration 26635: loss: 0.058288, loss_s1: 0.041054, loss_fp: 0.006831, loss_freq: 0.015987
[19:19:09.467] iteration 26636: loss: 0.056325, loss_s1: 0.068271, loss_fp: 0.002836, loss_freq: 0.014682
[19:19:10.095] iteration 26637: loss: 0.033140, loss_s1: 0.008024, loss_fp: 0.000817, loss_freq: 0.023866
[19:19:10.720] iteration 26638: loss: 0.038259, loss_s1: 0.023610, loss_fp: 0.003527, loss_freq: 0.013159
[19:19:11.352] iteration 26639: loss: 0.052006, loss_s1: 0.051489, loss_fp: 0.001695, loss_freq: 0.013089
[19:19:11.983] iteration 26640: loss: 0.062658, loss_s1: 0.063288, loss_fp: 0.007621, loss_freq: 0.021184
[19:19:12.611] iteration 26641: loss: 0.045217, loss_s1: 0.017960, loss_fp: 0.010228, loss_freq: 0.018846
[19:19:13.238] iteration 26642: loss: 0.045670, loss_s1: 0.042382, loss_fp: 0.004348, loss_freq: 0.021307
[19:19:13.865] iteration 26643: loss: 0.040971, loss_s1: 0.044975, loss_fp: 0.001259, loss_freq: 0.009290
[19:19:14.493] iteration 26644: loss: 0.029245, loss_s1: 0.026422, loss_fp: 0.001432, loss_freq: 0.008015
[19:19:15.119] iteration 26645: loss: 0.049037, loss_s1: 0.027379, loss_fp: 0.009499, loss_freq: 0.021674
[19:19:15.749] iteration 26646: loss: 0.042935, loss_s1: 0.021524, loss_fp: 0.003177, loss_freq: 0.023790
[19:19:16.401] iteration 26647: loss: 0.063315, loss_s1: 0.060280, loss_fp: 0.003948, loss_freq: 0.032802
[19:19:17.036] iteration 26648: loss: 0.112317, loss_s1: 0.119987, loss_fp: 0.011332, loss_freq: 0.060088
[19:19:17.669] iteration 26649: loss: 0.077991, loss_s1: 0.088217, loss_fp: 0.001166, loss_freq: 0.034460
[19:19:18.294] iteration 26650: loss: 0.063474, loss_s1: 0.074267, loss_fp: 0.004525, loss_freq: 0.020780
[19:19:18.930] iteration 26651: loss: 0.044275, loss_s1: 0.037315, loss_fp: 0.001970, loss_freq: 0.019508
[19:19:19.562] iteration 26652: loss: 0.045664, loss_s1: 0.026879, loss_fp: 0.005414, loss_freq: 0.022063
[19:19:20.195] iteration 26653: loss: 0.039079, loss_s1: 0.036783, loss_fp: 0.001176, loss_freq: 0.010661
[19:19:20.825] iteration 26654: loss: 0.057860, loss_s1: 0.039998, loss_fp: 0.007502, loss_freq: 0.017116
[19:19:21.449] iteration 26655: loss: 0.071136, loss_s1: 0.049282, loss_fp: 0.006016, loss_freq: 0.052350
[19:19:22.074] iteration 26656: loss: 0.061561, loss_s1: 0.042483, loss_fp: 0.006341, loss_freq: 0.037699
[19:19:22.700] iteration 26657: loss: 0.062349, loss_s1: 0.049284, loss_fp: 0.007666, loss_freq: 0.029417
[19:19:23.325] iteration 26658: loss: 0.049719, loss_s1: 0.033935, loss_fp: 0.003302, loss_freq: 0.017514
[19:19:23.970] iteration 26659: loss: 0.053704, loss_s1: 0.058404, loss_fp: 0.002776, loss_freq: 0.018764
[19:19:24.603] iteration 26660: loss: 0.048718, loss_s1: 0.044778, loss_fp: 0.004362, loss_freq: 0.021123
[19:19:25.234] iteration 26661: loss: 0.043438, loss_s1: 0.032496, loss_fp: 0.005735, loss_freq: 0.019043
[19:19:25.874] iteration 26662: loss: 0.036632, loss_s1: 0.021123, loss_fp: 0.003169, loss_freq: 0.021141
[19:19:26.507] iteration 26663: loss: 0.031567, loss_s1: 0.014013, loss_fp: 0.000730, loss_freq: 0.017229
[19:19:27.148] iteration 26664: loss: 0.041351, loss_s1: 0.039039, loss_fp: 0.002235, loss_freq: 0.010462
[19:19:27.786] iteration 26665: loss: 0.039067, loss_s1: 0.035850, loss_fp: 0.001769, loss_freq: 0.009929
[19:19:28.423] iteration 26666: loss: 0.045468, loss_s1: 0.039379, loss_fp: 0.002751, loss_freq: 0.022718
[19:19:29.051] iteration 26667: loss: 0.053155, loss_s1: 0.017745, loss_fp: 0.013163, loss_freq: 0.036394
[19:19:29.671] iteration 26668: loss: 0.052826, loss_s1: 0.052598, loss_fp: 0.005029, loss_freq: 0.020222
[19:19:30.295] iteration 26669: loss: 0.036597, loss_s1: 0.025728, loss_fp: 0.000682, loss_freq: 0.011330
[19:19:30.924] iteration 26670: loss: 0.041071, loss_s1: 0.027859, loss_fp: 0.002558, loss_freq: 0.014511
[19:19:31.553] iteration 26671: loss: 0.047194, loss_s1: 0.032795, loss_fp: 0.001172, loss_freq: 0.035506
[19:19:32.183] iteration 26672: loss: 0.030778, loss_s1: 0.019124, loss_fp: 0.000797, loss_freq: 0.007434
[19:19:32.807] iteration 26673: loss: 0.041549, loss_s1: 0.024717, loss_fp: 0.007253, loss_freq: 0.019656
[19:19:33.429] iteration 26674: loss: 0.096894, loss_s1: 0.079029, loss_fp: 0.011780, loss_freq: 0.061193
[19:19:34.057] iteration 26675: loss: 0.042913, loss_s1: 0.029878, loss_fp: 0.005846, loss_freq: 0.017202
[19:19:34.681] iteration 26676: loss: 0.041895, loss_s1: 0.022672, loss_fp: 0.001761, loss_freq: 0.015545
[19:19:35.300] iteration 26677: loss: 0.044437, loss_s1: 0.014303, loss_fp: 0.003709, loss_freq: 0.036744
[19:19:35.928] iteration 26678: loss: 0.036833, loss_s1: 0.026635, loss_fp: 0.004022, loss_freq: 0.017035
[19:19:36.549] iteration 26679: loss: 0.048463, loss_s1: 0.032871, loss_fp: 0.002752, loss_freq: 0.028676
[19:19:37.176] iteration 26680: loss: 0.038293, loss_s1: 0.019189, loss_fp: 0.002795, loss_freq: 0.019125
[19:19:37.803] iteration 26681: loss: 0.047856, loss_s1: 0.018223, loss_fp: 0.008656, loss_freq: 0.034445
[19:19:38.427] iteration 26682: loss: 0.036904, loss_s1: 0.022173, loss_fp: 0.005980, loss_freq: 0.016464
[19:19:39.054] iteration 26683: loss: 0.030918, loss_s1: 0.018754, loss_fp: 0.001468, loss_freq: 0.016535
[19:19:39.680] iteration 26684: loss: 0.067993, loss_s1: 0.046158, loss_fp: 0.003580, loss_freq: 0.044664
[19:19:40.316] iteration 26685: loss: 0.107861, loss_s1: 0.052256, loss_fp: 0.000805, loss_freq: 0.126109
[19:19:40.944] iteration 26686: loss: 0.046149, loss_s1: 0.035957, loss_fp: 0.010561, loss_freq: 0.013315
[19:19:41.571] iteration 26687: loss: 0.060771, loss_s1: 0.062015, loss_fp: 0.003983, loss_freq: 0.013478
[19:19:42.193] iteration 26688: loss: 0.052674, loss_s1: 0.064360, loss_fp: 0.004550, loss_freq: 0.008023
[19:19:42.818] iteration 26689: loss: 0.039244, loss_s1: 0.037597, loss_fp: 0.001316, loss_freq: 0.009443
[19:19:43.451] iteration 26690: loss: 0.049373, loss_s1: 0.032722, loss_fp: 0.008446, loss_freq: 0.025744
[19:19:44.081] iteration 26691: loss: 0.038615, loss_s1: 0.016081, loss_fp: 0.000770, loss_freq: 0.020869
[19:19:44.707] iteration 26692: loss: 0.067506, loss_s1: 0.084323, loss_fp: 0.001611, loss_freq: 0.019211
[19:19:45.333] iteration 26693: loss: 0.056407, loss_s1: 0.036041, loss_fp: 0.007444, loss_freq: 0.023344
[19:19:45.960] iteration 26694: loss: 0.086112, loss_s1: 0.067202, loss_fp: 0.009656, loss_freq: 0.067472
[19:19:46.586] iteration 26695: loss: 0.040807, loss_s1: 0.036336, loss_fp: 0.005746, loss_freq: 0.006468
[19:19:47.212] iteration 26696: loss: 0.054237, loss_s1: 0.047299, loss_fp: 0.004864, loss_freq: 0.031895
[19:19:47.838] iteration 26697: loss: 0.051492, loss_s1: 0.058216, loss_fp: 0.001848, loss_freq: 0.012689
[19:19:48.465] iteration 26698: loss: 0.058056, loss_s1: 0.047729, loss_fp: 0.004262, loss_freq: 0.024185
[19:19:49.091] iteration 26699: loss: 0.039103, loss_s1: 0.024429, loss_fp: 0.002783, loss_freq: 0.017873
[19:19:49.713] iteration 26700: loss: 0.051149, loss_s1: 0.030069, loss_fp: 0.005753, loss_freq: 0.021766
[19:19:50.338] iteration 26701: loss: 0.045822, loss_s1: 0.045310, loss_fp: 0.002322, loss_freq: 0.019121
[19:19:50.988] iteration 26702: loss: 0.039953, loss_s1: 0.026069, loss_fp: 0.002222, loss_freq: 0.009083
[19:19:51.630] iteration 26703: loss: 0.042014, loss_s1: 0.041117, loss_fp: 0.001789, loss_freq: 0.014105
[19:19:52.260] iteration 26704: loss: 0.043349, loss_s1: 0.027023, loss_fp: 0.006259, loss_freq: 0.020674
[19:19:52.892] iteration 26705: loss: 0.078166, loss_s1: 0.063431, loss_fp: 0.008532, loss_freq: 0.024878
[19:19:53.522] iteration 26706: loss: 0.078458, loss_s1: 0.059670, loss_fp: 0.004927, loss_freq: 0.065097
[19:19:54.145] iteration 26707: loss: 0.034252, loss_s1: 0.025835, loss_fp: 0.001884, loss_freq: 0.008918
[19:19:54.776] iteration 26708: loss: 0.053369, loss_s1: 0.034923, loss_fp: 0.009499, loss_freq: 0.032465
[19:19:55.397] iteration 26709: loss: 0.066491, loss_s1: 0.075605, loss_fp: 0.008261, loss_freq: 0.011104
[19:19:56.023] iteration 26710: loss: 0.051509, loss_s1: 0.023850, loss_fp: 0.003482, loss_freq: 0.028568
[19:19:56.650] iteration 26711: loss: 0.067913, loss_s1: 0.058257, loss_fp: 0.009698, loss_freq: 0.013606
[19:19:57.275] iteration 26712: loss: 0.072716, loss_s1: 0.034739, loss_fp: 0.004100, loss_freq: 0.078070
[19:19:57.902] iteration 26713: loss: 0.050189, loss_s1: 0.050354, loss_fp: 0.002953, loss_freq: 0.006317
[19:19:58.528] iteration 26714: loss: 0.042351, loss_s1: 0.023843, loss_fp: 0.001340, loss_freq: 0.027404
[19:19:59.152] iteration 26715: loss: 0.091938, loss_s1: 0.048079, loss_fp: 0.006007, loss_freq: 0.088304
[19:19:59.775] iteration 26716: loss: 0.042426, loss_s1: 0.033560, loss_fp: 0.004433, loss_freq: 0.018551
[19:20:00.404] iteration 26717: loss: 0.080644, loss_s1: 0.072835, loss_fp: 0.007550, loss_freq: 0.048200
[19:20:01.044] iteration 26718: loss: 0.051060, loss_s1: 0.032633, loss_fp: 0.007984, loss_freq: 0.027463
[19:20:01.672] iteration 26719: loss: 0.073963, loss_s1: 0.090776, loss_fp: 0.007521, loss_freq: 0.022259
[19:20:02.302] iteration 26720: loss: 0.037231, loss_s1: 0.027008, loss_fp: 0.005700, loss_freq: 0.012663
[19:20:02.929] iteration 26721: loss: 0.043358, loss_s1: 0.034169, loss_fp: 0.000758, loss_freq: 0.010782
[19:20:03.559] iteration 26722: loss: 0.031427, loss_s1: 0.021912, loss_fp: 0.000989, loss_freq: 0.005957
[19:20:04.184] iteration 26723: loss: 0.055423, loss_s1: 0.032584, loss_fp: 0.006123, loss_freq: 0.030109
[19:20:04.811] iteration 26724: loss: 0.080283, loss_s1: 0.033142, loss_fp: 0.008281, loss_freq: 0.061344
[19:20:05.435] iteration 26725: loss: 0.046478, loss_s1: 0.017329, loss_fp: 0.009171, loss_freq: 0.027155
[19:20:06.063] iteration 26726: loss: 0.037124, loss_s1: 0.018850, loss_fp: 0.002577, loss_freq: 0.017181
[19:20:07.091] iteration 26727: loss: 0.028495, loss_s1: 0.010903, loss_fp: 0.000950, loss_freq: 0.015846
[19:20:07.751] iteration 26728: loss: 0.051888, loss_s1: 0.030930, loss_fp: 0.006058, loss_freq: 0.032041
[19:20:08.413] iteration 26729: loss: 0.032448, loss_s1: 0.021982, loss_fp: 0.002274, loss_freq: 0.009484
[19:20:09.065] iteration 26730: loss: 0.035401, loss_s1: 0.017893, loss_fp: 0.001154, loss_freq: 0.011908
[19:20:09.721] iteration 26731: loss: 0.043572, loss_s1: 0.020323, loss_fp: 0.011264, loss_freq: 0.025542
[19:20:10.385] iteration 26732: loss: 0.093612, loss_s1: 0.053586, loss_fp: 0.003009, loss_freq: 0.055515
[19:20:11.039] iteration 26733: loss: 0.043283, loss_s1: 0.036939, loss_fp: 0.004278, loss_freq: 0.020606
[19:20:11.693] iteration 26734: loss: 0.031121, loss_s1: 0.018119, loss_fp: 0.003747, loss_freq: 0.013339
[19:20:12.331] iteration 26735: loss: 0.051315, loss_s1: 0.044387, loss_fp: 0.006118, loss_freq: 0.025405
[19:20:12.957] iteration 26736: loss: 0.041956, loss_s1: 0.023443, loss_fp: 0.005160, loss_freq: 0.020746
[19:20:13.581] iteration 26737: loss: 0.029799, loss_s1: 0.015189, loss_fp: 0.000915, loss_freq: 0.007418
[19:20:14.203] iteration 26738: loss: 0.039999, loss_s1: 0.020396, loss_fp: 0.002988, loss_freq: 0.020789
[19:20:14.824] iteration 26739: loss: 0.063633, loss_s1: 0.037563, loss_fp: 0.009238, loss_freq: 0.049304
[19:20:15.454] iteration 26740: loss: 0.058311, loss_s1: 0.046785, loss_fp: 0.001461, loss_freq: 0.011685
[19:20:16.084] iteration 26741: loss: 0.030658, loss_s1: 0.017212, loss_fp: 0.001876, loss_freq: 0.012026
[19:20:16.729] iteration 26742: loss: 0.083641, loss_s1: 0.057238, loss_fp: 0.010080, loss_freq: 0.069336
[19:20:17.375] iteration 26743: loss: 0.040842, loss_s1: 0.026847, loss_fp: 0.006480, loss_freq: 0.011943
[19:20:18.017] iteration 26744: loss: 0.062569, loss_s1: 0.047719, loss_fp: 0.004145, loss_freq: 0.042042
[19:20:18.660] iteration 26745: loss: 0.034636, loss_s1: 0.007740, loss_fp: 0.004697, loss_freq: 0.025100
[19:20:19.298] iteration 26746: loss: 0.055490, loss_s1: 0.039385, loss_fp: 0.003296, loss_freq: 0.031116
[19:20:19.942] iteration 26747: loss: 0.060508, loss_s1: 0.070778, loss_fp: 0.000685, loss_freq: 0.008602
[19:20:20.584] iteration 26748: loss: 0.068669, loss_s1: 0.064203, loss_fp: 0.003086, loss_freq: 0.033962
[19:20:21.228] iteration 26749: loss: 0.057591, loss_s1: 0.047984, loss_fp: 0.000838, loss_freq: 0.023942
[19:20:21.885] iteration 26750: loss: 0.110119, loss_s1: 0.072017, loss_fp: 0.004469, loss_freq: 0.103750
[19:20:22.527] iteration 26751: loss: 0.047488, loss_s1: 0.048290, loss_fp: 0.001104, loss_freq: 0.015596
[19:20:23.185] iteration 26752: loss: 0.043489, loss_s1: 0.020082, loss_fp: 0.008052, loss_freq: 0.035075
[19:20:23.815] iteration 26753: loss: 0.049169, loss_s1: 0.035726, loss_fp: 0.003518, loss_freq: 0.021522
[19:20:24.444] iteration 26754: loss: 0.069582, loss_s1: 0.052189, loss_fp: 0.014525, loss_freq: 0.038263
[19:20:25.065] iteration 26755: loss: 0.102916, loss_s1: 0.120068, loss_fp: 0.010478, loss_freq: 0.040994
[19:20:25.693] iteration 26756: loss: 0.033764, loss_s1: 0.018579, loss_fp: 0.000684, loss_freq: 0.011276
[19:20:26.320] iteration 26757: loss: 0.043491, loss_s1: 0.027783, loss_fp: 0.001467, loss_freq: 0.032212
[19:20:26.947] iteration 26758: loss: 0.038186, loss_s1: 0.035256, loss_fp: 0.001646, loss_freq: 0.008982
[19:20:27.574] iteration 26759: loss: 0.042475, loss_s1: 0.042823, loss_fp: 0.000757, loss_freq: 0.012090
[19:20:28.196] iteration 26760: loss: 0.045157, loss_s1: 0.051782, loss_fp: 0.000774, loss_freq: 0.007697
[19:20:28.819] iteration 26761: loss: 0.039745, loss_s1: 0.021501, loss_fp: 0.003822, loss_freq: 0.014774
[19:20:29.447] iteration 26762: loss: 0.049286, loss_s1: 0.048757, loss_fp: 0.004696, loss_freq: 0.020267
[19:20:30.072] iteration 26763: loss: 0.064510, loss_s1: 0.058592, loss_fp: 0.006240, loss_freq: 0.026400
[19:20:30.695] iteration 26764: loss: 0.042469, loss_s1: 0.029795, loss_fp: 0.007668, loss_freq: 0.012754
[19:20:31.324] iteration 26765: loss: 0.080174, loss_s1: 0.081204, loss_fp: 0.006701, loss_freq: 0.027030
[19:20:31.948] iteration 26766: loss: 0.061551, loss_s1: 0.048994, loss_fp: 0.003688, loss_freq: 0.033973
[19:20:32.581] iteration 26767: loss: 0.047184, loss_s1: 0.028610, loss_fp: 0.002807, loss_freq: 0.028481
[19:20:33.206] iteration 26768: loss: 0.066647, loss_s1: 0.080193, loss_fp: 0.005595, loss_freq: 0.022617
[19:20:33.838] iteration 26769: loss: 0.055096, loss_s1: 0.036571, loss_fp: 0.004847, loss_freq: 0.042207
[19:20:34.462] iteration 26770: loss: 0.066966, loss_s1: 0.043849, loss_fp: 0.007773, loss_freq: 0.051937
[19:20:35.093] iteration 26771: loss: 0.043638, loss_s1: 0.036930, loss_fp: 0.003352, loss_freq: 0.009356
[19:20:35.720] iteration 26772: loss: 0.029560, loss_s1: 0.013848, loss_fp: 0.000758, loss_freq: 0.007961
[19:20:36.381] iteration 26773: loss: 0.025888, loss_s1: 0.015599, loss_fp: 0.001337, loss_freq: 0.008509
[19:20:37.018] iteration 26774: loss: 0.053229, loss_s1: 0.051190, loss_fp: 0.004502, loss_freq: 0.025485
[19:20:37.665] iteration 26775: loss: 0.048304, loss_s1: 0.041624, loss_fp: 0.005578, loss_freq: 0.013908
[19:20:38.304] iteration 26776: loss: 0.055753, loss_s1: 0.040254, loss_fp: 0.001285, loss_freq: 0.039401
[19:20:38.951] iteration 26777: loss: 0.070148, loss_s1: 0.066711, loss_fp: 0.003318, loss_freq: 0.033534
[19:20:39.601] iteration 26778: loss: 0.065625, loss_s1: 0.040807, loss_fp: 0.009087, loss_freq: 0.043221
[19:20:40.234] iteration 26779: loss: 0.064030, loss_s1: 0.034007, loss_fp: 0.003488, loss_freq: 0.045255
[19:20:40.864] iteration 26780: loss: 0.066198, loss_s1: 0.039110, loss_fp: 0.009923, loss_freq: 0.046587
[19:20:41.499] iteration 26781: loss: 0.025076, loss_s1: 0.009465, loss_fp: 0.000675, loss_freq: 0.010527
[19:20:42.131] iteration 26782: loss: 0.050737, loss_s1: 0.037452, loss_fp: 0.002524, loss_freq: 0.024204
[19:20:42.761] iteration 26783: loss: 0.046754, loss_s1: 0.046325, loss_fp: 0.001561, loss_freq: 0.007755
[19:20:43.400] iteration 26784: loss: 0.059436, loss_s1: 0.033903, loss_fp: 0.004935, loss_freq: 0.032114
[19:20:44.030] iteration 26785: loss: 0.029203, loss_s1: 0.017205, loss_fp: 0.001879, loss_freq: 0.012486
[19:20:44.662] iteration 26786: loss: 0.041854, loss_s1: 0.022182, loss_fp: 0.013154, loss_freq: 0.025630
[19:20:45.291] iteration 26787: loss: 0.038679, loss_s1: 0.020373, loss_fp: 0.007629, loss_freq: 0.021166
[19:20:45.939] iteration 26788: loss: 0.055188, loss_s1: 0.037400, loss_fp: 0.004981, loss_freq: 0.027471
[19:20:46.569] iteration 26789: loss: 0.041063, loss_s1: 0.019864, loss_fp: 0.000512, loss_freq: 0.009883
[19:20:47.205] iteration 26790: loss: 0.046559, loss_s1: 0.031641, loss_fp: 0.001754, loss_freq: 0.015127
[19:20:47.845] iteration 26791: loss: 0.060305, loss_s1: 0.051921, loss_fp: 0.014034, loss_freq: 0.021604
[19:20:48.479] iteration 26792: loss: 0.074392, loss_s1: 0.085171, loss_fp: 0.002997, loss_freq: 0.034324
[19:20:49.117] iteration 26793: loss: 0.042268, loss_s1: 0.019619, loss_fp: 0.001289, loss_freq: 0.022732
[19:20:49.744] iteration 26794: loss: 0.053641, loss_s1: 0.039813, loss_fp: 0.003041, loss_freq: 0.033593
[19:20:50.374] iteration 26795: loss: 0.035151, loss_s1: 0.031840, loss_fp: 0.002203, loss_freq: 0.007537
[19:20:50.999] iteration 26796: loss: 0.082467, loss_s1: 0.035681, loss_fp: 0.001019, loss_freq: 0.069578
[19:20:51.626] iteration 26797: loss: 0.057732, loss_s1: 0.054036, loss_fp: 0.009142, loss_freq: 0.023306
[19:20:52.253] iteration 26798: loss: 0.035801, loss_s1: 0.022422, loss_fp: 0.000821, loss_freq: 0.019610
[19:20:52.880] iteration 26799: loss: 0.041792, loss_s1: 0.026776, loss_fp: 0.004216, loss_freq: 0.016773
[19:20:53.514] iteration 26800: loss: 0.044126, loss_s1: 0.030838, loss_fp: 0.005052, loss_freq: 0.014454
[19:20:56.683] iteration 26800 : mean_dice : 0.744390
[19:20:57.329] iteration 26801: loss: 0.074057, loss_s1: 0.084836, loss_fp: 0.003094, loss_freq: 0.019829
[19:20:57.952] iteration 26802: loss: 0.064743, loss_s1: 0.050636, loss_fp: 0.002160, loss_freq: 0.042784
[19:20:58.574] iteration 26803: loss: 0.049627, loss_s1: 0.034229, loss_fp: 0.000489, loss_freq: 0.030469
[19:20:59.200] iteration 26804: loss: 0.022827, loss_s1: 0.011583, loss_fp: 0.001471, loss_freq: 0.007102
[19:20:59.823] iteration 26805: loss: 0.031738, loss_s1: 0.031752, loss_fp: 0.003182, loss_freq: 0.003540
[19:21:00.453] iteration 26806: loss: 0.054023, loss_s1: 0.035195, loss_fp: 0.005581, loss_freq: 0.033901
[19:21:01.080] iteration 26807: loss: 0.097187, loss_s1: 0.097436, loss_fp: 0.001921, loss_freq: 0.057749
[19:21:01.741] iteration 26808: loss: 0.058086, loss_s1: 0.066766, loss_fp: 0.003622, loss_freq: 0.018338
[19:21:02.368] iteration 26809: loss: 0.086552, loss_s1: 0.049587, loss_fp: 0.004246, loss_freq: 0.082933
[19:21:03.001] iteration 26810: loss: 0.054908, loss_s1: 0.047841, loss_fp: 0.003419, loss_freq: 0.022251
[19:21:03.630] iteration 26811: loss: 0.068771, loss_s1: 0.060348, loss_fp: 0.004588, loss_freq: 0.043423
[19:21:04.269] iteration 26812: loss: 0.058854, loss_s1: 0.073742, loss_fp: 0.000628, loss_freq: 0.011437
[19:21:04.901] iteration 26813: loss: 0.046389, loss_s1: 0.025990, loss_fp: 0.010052, loss_freq: 0.020528
[19:21:05.532] iteration 26814: loss: 0.064165, loss_s1: 0.067800, loss_fp: 0.015319, loss_freq: 0.011054
[19:21:06.178] iteration 26815: loss: 0.066689, loss_s1: 0.057832, loss_fp: 0.005757, loss_freq: 0.033463
[19:21:06.807] iteration 26816: loss: 0.060640, loss_s1: 0.045096, loss_fp: 0.001467, loss_freq: 0.044136
[19:21:07.441] iteration 26817: loss: 0.061297, loss_s1: 0.035744, loss_fp: 0.003661, loss_freq: 0.050762
[19:21:08.072] iteration 26818: loss: 0.065094, loss_s1: 0.061960, loss_fp: 0.004480, loss_freq: 0.031022
[19:21:08.696] iteration 26819: loss: 0.041660, loss_s1: 0.024433, loss_fp: 0.002246, loss_freq: 0.016891
[19:21:09.325] iteration 26820: loss: 0.066043, loss_s1: 0.053532, loss_fp: 0.002645, loss_freq: 0.051087
[19:21:10.095] iteration 26821: loss: 0.040956, loss_s1: 0.026081, loss_fp: 0.004450, loss_freq: 0.024847
[19:21:10.755] iteration 26822: loss: 0.063768, loss_s1: 0.042111, loss_fp: 0.001320, loss_freq: 0.056134
[19:21:11.390] iteration 26823: loss: 0.035980, loss_s1: 0.022458, loss_fp: 0.003178, loss_freq: 0.018214
[19:21:12.034] iteration 26824: loss: 0.053033, loss_s1: 0.041075, loss_fp: 0.001516, loss_freq: 0.032596
[19:21:12.670] iteration 26825: loss: 0.039323, loss_s1: 0.024590, loss_fp: 0.001704, loss_freq: 0.025277
[19:21:13.306] iteration 26826: loss: 0.046936, loss_s1: 0.047628, loss_fp: 0.004062, loss_freq: 0.010826
[19:21:13.936] iteration 26827: loss: 0.049672, loss_s1: 0.033477, loss_fp: 0.007199, loss_freq: 0.029421
[19:21:14.564] iteration 26828: loss: 0.063434, loss_s1: 0.047572, loss_fp: 0.009468, loss_freq: 0.033516
[19:21:15.186] iteration 26829: loss: 0.053855, loss_s1: 0.044458, loss_fp: 0.001368, loss_freq: 0.027468
[19:21:15.811] iteration 26830: loss: 0.035187, loss_s1: 0.024118, loss_fp: 0.001637, loss_freq: 0.016000
[19:21:16.438] iteration 26831: loss: 0.050434, loss_s1: 0.047740, loss_fp: 0.003825, loss_freq: 0.007886
[19:21:17.070] iteration 26832: loss: 0.041953, loss_s1: 0.030040, loss_fp: 0.001957, loss_freq: 0.021027
[19:21:17.696] iteration 26833: loss: 0.051035, loss_s1: 0.055391, loss_fp: 0.001471, loss_freq: 0.010341
[19:21:18.326] iteration 26834: loss: 0.055007, loss_s1: 0.054847, loss_fp: 0.002240, loss_freq: 0.013086
[19:21:18.952] iteration 26835: loss: 0.095140, loss_s1: 0.041201, loss_fp: 0.012678, loss_freq: 0.097441
[19:21:19.579] iteration 26836: loss: 0.044107, loss_s1: 0.033069, loss_fp: 0.001027, loss_freq: 0.024239
[19:21:20.205] iteration 26837: loss: 0.069238, loss_s1: 0.053349, loss_fp: 0.001009, loss_freq: 0.024757
[19:21:20.830] iteration 26838: loss: 0.060544, loss_s1: 0.044232, loss_fp: 0.001464, loss_freq: 0.038768
[19:21:21.513] iteration 26839: loss: 0.060135, loss_s1: 0.069728, loss_fp: 0.007346, loss_freq: 0.018819
[19:21:22.151] iteration 26840: loss: 0.046453, loss_s1: 0.052008, loss_fp: 0.002851, loss_freq: 0.006183
[19:21:22.798] iteration 26841: loss: 0.046205, loss_s1: 0.040805, loss_fp: 0.002836, loss_freq: 0.010046
[19:21:23.434] iteration 26842: loss: 0.041550, loss_s1: 0.027003, loss_fp: 0.005850, loss_freq: 0.013983
[19:21:24.067] iteration 26843: loss: 0.044496, loss_s1: 0.052773, loss_fp: 0.002585, loss_freq: 0.008213
[19:21:24.691] iteration 26844: loss: 0.034594, loss_s1: 0.027497, loss_fp: 0.004296, loss_freq: 0.003725
[19:21:25.349] iteration 26845: loss: 0.069674, loss_s1: 0.070082, loss_fp: 0.001537, loss_freq: 0.032881
[19:21:25.977] iteration 26846: loss: 0.075235, loss_s1: 0.068924, loss_fp: 0.001073, loss_freq: 0.054193
[19:21:26.601] iteration 26847: loss: 0.029791, loss_s1: 0.010458, loss_fp: 0.004615, loss_freq: 0.013630
[19:21:27.234] iteration 26848: loss: 0.052538, loss_s1: 0.031280, loss_fp: 0.010528, loss_freq: 0.030742
[19:21:27.869] iteration 26849: loss: 0.030261, loss_s1: 0.005275, loss_fp: 0.005577, loss_freq: 0.017419
[19:21:28.507] iteration 26850: loss: 0.046446, loss_s1: 0.036562, loss_fp: 0.001011, loss_freq: 0.012528
[19:21:29.142] iteration 26851: loss: 0.047967, loss_s1: 0.038281, loss_fp: 0.007264, loss_freq: 0.020895
[19:21:29.763] iteration 26852: loss: 0.048634, loss_s1: 0.020307, loss_fp: 0.010560, loss_freq: 0.030768
[19:21:30.387] iteration 26853: loss: 0.071229, loss_s1: 0.082526, loss_fp: 0.013235, loss_freq: 0.014154
[19:21:31.013] iteration 26854: loss: 0.082267, loss_s1: 0.068370, loss_fp: 0.033544, loss_freq: 0.016012
[19:21:31.710] iteration 26855: loss: 0.057608, loss_s1: 0.047193, loss_fp: 0.001724, loss_freq: 0.036992
[19:21:32.349] iteration 26856: loss: 0.036961, loss_s1: 0.020097, loss_fp: 0.006470, loss_freq: 0.006471
[19:21:32.988] iteration 26857: loss: 0.047245, loss_s1: 0.043098, loss_fp: 0.002509, loss_freq: 0.025122
[19:21:33.611] iteration 26858: loss: 0.056802, loss_s1: 0.050954, loss_fp: 0.003756, loss_freq: 0.029575
[19:21:34.234] iteration 26859: loss: 0.051514, loss_s1: 0.041525, loss_fp: 0.002033, loss_freq: 0.019063
[19:21:34.858] iteration 26860: loss: 0.045077, loss_s1: 0.040263, loss_fp: 0.000908, loss_freq: 0.016959
[19:21:35.485] iteration 26861: loss: 0.082497, loss_s1: 0.079248, loss_fp: 0.003098, loss_freq: 0.050472
[19:21:36.113] iteration 26862: loss: 0.048351, loss_s1: 0.055847, loss_fp: 0.003297, loss_freq: 0.009774
[19:21:36.735] iteration 26863: loss: 0.029093, loss_s1: 0.009060, loss_fp: 0.004409, loss_freq: 0.005902
[19:21:37.371] iteration 26864: loss: 0.029417, loss_s1: 0.019813, loss_fp: 0.003956, loss_freq: 0.011834
[19:21:38.016] iteration 26865: loss: 0.054170, loss_s1: 0.039968, loss_fp: 0.002947, loss_freq: 0.015044
[19:21:38.648] iteration 26866: loss: 0.068707, loss_s1: 0.046099, loss_fp: 0.005311, loss_freq: 0.035750
[19:21:39.287] iteration 26867: loss: 0.044147, loss_s1: 0.042011, loss_fp: 0.003597, loss_freq: 0.012613
[19:21:39.927] iteration 26868: loss: 0.037954, loss_s1: 0.031911, loss_fp: 0.002823, loss_freq: 0.008267
[19:21:40.556] iteration 26869: loss: 0.058600, loss_s1: 0.047033, loss_fp: 0.012858, loss_freq: 0.027778
[19:21:41.181] iteration 26870: loss: 0.087701, loss_s1: 0.103475, loss_fp: 0.008413, loss_freq: 0.025104
[19:21:41.807] iteration 26871: loss: 0.034936, loss_s1: 0.022341, loss_fp: 0.003949, loss_freq: 0.008196
[19:21:42.434] iteration 26872: loss: 0.056962, loss_s1: 0.033881, loss_fp: 0.010369, loss_freq: 0.035484
[19:21:43.062] iteration 26873: loss: 0.092062, loss_s1: 0.088732, loss_fp: 0.016171, loss_freq: 0.050038
[19:21:43.687] iteration 26874: loss: 0.033151, loss_s1: 0.025440, loss_fp: 0.003613, loss_freq: 0.011327
[19:21:44.312] iteration 26875: loss: 0.033879, loss_s1: 0.023960, loss_fp: 0.007235, loss_freq: 0.012245
[19:21:44.938] iteration 26876: loss: 0.078027, loss_s1: 0.076906, loss_fp: 0.000981, loss_freq: 0.042069
[19:21:45.565] iteration 26877: loss: 0.058981, loss_s1: 0.033033, loss_fp: 0.005752, loss_freq: 0.045548
[19:21:46.197] iteration 26878: loss: 0.065855, loss_s1: 0.065409, loss_fp: 0.002321, loss_freq: 0.033302
[19:21:46.820] iteration 26879: loss: 0.029626, loss_s1: 0.015071, loss_fp: 0.001721, loss_freq: 0.012538
[19:21:47.447] iteration 26880: loss: 0.056932, loss_s1: 0.051263, loss_fp: 0.006249, loss_freq: 0.018172
[19:21:48.075] iteration 26881: loss: 0.032801, loss_s1: 0.022654, loss_fp: 0.002691, loss_freq: 0.013540
[19:21:48.700] iteration 26882: loss: 0.040241, loss_s1: 0.027407, loss_fp: 0.000542, loss_freq: 0.017829
[19:21:49.320] iteration 26883: loss: 0.031542, loss_s1: 0.014233, loss_fp: 0.001242, loss_freq: 0.011183
[19:21:49.949] iteration 26884: loss: 0.050071, loss_s1: 0.031054, loss_fp: 0.002478, loss_freq: 0.021833
[19:21:50.575] iteration 26885: loss: 0.037257, loss_s1: 0.020908, loss_fp: 0.005953, loss_freq: 0.016445
[19:21:51.201] iteration 26886: loss: 0.054655, loss_s1: 0.038116, loss_fp: 0.004578, loss_freq: 0.040058
[19:21:51.823] iteration 26887: loss: 0.074327, loss_s1: 0.078761, loss_fp: 0.004149, loss_freq: 0.020374
[19:21:52.807] iteration 26888: loss: 0.040951, loss_s1: 0.033906, loss_fp: 0.001417, loss_freq: 0.015863
[19:21:53.445] iteration 26889: loss: 0.070013, loss_s1: 0.038425, loss_fp: 0.026915, loss_freq: 0.038901
[19:21:54.092] iteration 26890: loss: 0.035596, loss_s1: 0.020683, loss_fp: 0.001926, loss_freq: 0.007016
[19:21:54.728] iteration 26891: loss: 0.034123, loss_s1: 0.006078, loss_fp: 0.001814, loss_freq: 0.020089
[19:21:55.365] iteration 26892: loss: 0.031913, loss_s1: 0.014858, loss_fp: 0.004494, loss_freq: 0.012531
[19:21:55.994] iteration 26893: loss: 0.086417, loss_s1: 0.072958, loss_fp: 0.023173, loss_freq: 0.035061
[19:21:56.638] iteration 26894: loss: 0.038055, loss_s1: 0.028584, loss_fp: 0.002552, loss_freq: 0.017124
[19:21:57.264] iteration 26895: loss: 0.043443, loss_s1: 0.040581, loss_fp: 0.002812, loss_freq: 0.017102
[19:21:57.939] iteration 26896: loss: 0.061676, loss_s1: 0.063649, loss_fp: 0.001892, loss_freq: 0.031373
[19:21:58.601] iteration 26897: loss: 0.070722, loss_s1: 0.060100, loss_fp: 0.010151, loss_freq: 0.034824
[19:21:59.234] iteration 26898: loss: 0.031298, loss_s1: 0.019660, loss_fp: 0.006148, loss_freq: 0.005772
[19:21:59.869] iteration 26899: loss: 0.054036, loss_s1: 0.058902, loss_fp: 0.002815, loss_freq: 0.013651
[19:22:00.500] iteration 26900: loss: 0.058781, loss_s1: 0.031778, loss_fp: 0.004249, loss_freq: 0.052488
[19:22:01.129] iteration 26901: loss: 0.060590, loss_s1: 0.025039, loss_fp: 0.005307, loss_freq: 0.049797
[19:22:01.760] iteration 26902: loss: 0.058732, loss_s1: 0.067658, loss_fp: 0.009292, loss_freq: 0.015455
[19:22:02.390] iteration 26903: loss: 0.072005, loss_s1: 0.063485, loss_fp: 0.019519, loss_freq: 0.025658
[19:22:03.021] iteration 26904: loss: 0.044256, loss_s1: 0.045947, loss_fp: 0.003267, loss_freq: 0.006595
[19:22:03.649] iteration 26905: loss: 0.087285, loss_s1: 0.089280, loss_fp: 0.009359, loss_freq: 0.037498
[19:22:04.281] iteration 26906: loss: 0.047116, loss_s1: 0.034954, loss_fp: 0.001635, loss_freq: 0.023930
[19:22:04.910] iteration 26907: loss: 0.043866, loss_s1: 0.016476, loss_fp: 0.010455, loss_freq: 0.022806
[19:22:05.542] iteration 26908: loss: 0.028222, loss_s1: 0.009888, loss_fp: 0.003554, loss_freq: 0.005998
[19:22:06.171] iteration 26909: loss: 0.043589, loss_s1: 0.026966, loss_fp: 0.001773, loss_freq: 0.025522
[19:22:06.796] iteration 26910: loss: 0.044331, loss_s1: 0.025603, loss_fp: 0.001889, loss_freq: 0.008237
[19:22:07.446] iteration 26911: loss: 0.092079, loss_s1: 0.049062, loss_fp: 0.004547, loss_freq: 0.102104
[19:22:08.082] iteration 26912: loss: 0.029412, loss_s1: 0.019331, loss_fp: 0.001380, loss_freq: 0.012248
[19:22:08.707] iteration 26913: loss: 0.051884, loss_s1: 0.051487, loss_fp: 0.004137, loss_freq: 0.018019
[19:22:09.332] iteration 26914: loss: 0.033589, loss_s1: 0.019258, loss_fp: 0.007008, loss_freq: 0.007849
[19:22:09.958] iteration 26915: loss: 0.074552, loss_s1: 0.060982, loss_fp: 0.016746, loss_freq: 0.036717
[19:22:10.590] iteration 26916: loss: 0.083402, loss_s1: 0.060457, loss_fp: 0.006013, loss_freq: 0.054441
[19:22:11.220] iteration 26917: loss: 0.039222, loss_s1: 0.027522, loss_fp: 0.006881, loss_freq: 0.012477
[19:22:11.851] iteration 26918: loss: 0.043302, loss_s1: 0.033958, loss_fp: 0.001303, loss_freq: 0.028017
[19:22:12.478] iteration 26919: loss: 0.044752, loss_s1: 0.028139, loss_fp: 0.009885, loss_freq: 0.015315
[19:22:13.106] iteration 26920: loss: 0.064185, loss_s1: 0.067501, loss_fp: 0.002263, loss_freq: 0.028987
[19:22:13.745] iteration 26921: loss: 0.026771, loss_s1: 0.019478, loss_fp: 0.001913, loss_freq: 0.006005
[19:22:14.367] iteration 26922: loss: 0.054814, loss_s1: 0.030571, loss_fp: 0.003037, loss_freq: 0.026477
[19:22:14.992] iteration 26923: loss: 0.089603, loss_s1: 0.070056, loss_fp: 0.001731, loss_freq: 0.076663
[19:22:15.620] iteration 26924: loss: 0.094722, loss_s1: 0.080934, loss_fp: 0.009056, loss_freq: 0.066794
[19:22:16.246] iteration 26925: loss: 0.063664, loss_s1: 0.061587, loss_fp: 0.010558, loss_freq: 0.017057
[19:22:16.871] iteration 26926: loss: 0.045445, loss_s1: 0.031427, loss_fp: 0.008452, loss_freq: 0.015600
[19:22:17.500] iteration 26927: loss: 0.080856, loss_s1: 0.097553, loss_fp: 0.004194, loss_freq: 0.025524
[19:22:18.123] iteration 26928: loss: 0.058925, loss_s1: 0.045083, loss_fp: 0.004472, loss_freq: 0.032175
[19:22:18.747] iteration 26929: loss: 0.072246, loss_s1: 0.060651, loss_fp: 0.009622, loss_freq: 0.049652
[19:22:19.370] iteration 26930: loss: 0.097469, loss_s1: 0.107827, loss_fp: 0.010650, loss_freq: 0.051304
[19:22:20.011] iteration 26931: loss: 0.042336, loss_s1: 0.023413, loss_fp: 0.002183, loss_freq: 0.033638
[19:22:20.656] iteration 26932: loss: 0.063634, loss_s1: 0.053253, loss_fp: 0.008046, loss_freq: 0.030776
[19:22:21.288] iteration 26933: loss: 0.054603, loss_s1: 0.060549, loss_fp: 0.000580, loss_freq: 0.006568
[19:22:21.924] iteration 26934: loss: 0.022805, loss_s1: 0.006249, loss_fp: 0.000832, loss_freq: 0.011169
[19:22:22.551] iteration 26935: loss: 0.047932, loss_s1: 0.033702, loss_fp: 0.011511, loss_freq: 0.024307
[19:22:23.183] iteration 26936: loss: 0.075992, loss_s1: 0.096474, loss_fp: 0.002020, loss_freq: 0.021704
[19:22:23.813] iteration 26937: loss: 0.034882, loss_s1: 0.025695, loss_fp: 0.000886, loss_freq: 0.016266
[19:22:24.451] iteration 26938: loss: 0.050575, loss_s1: 0.037695, loss_fp: 0.006176, loss_freq: 0.026599
[19:22:25.094] iteration 26939: loss: 0.051239, loss_s1: 0.036827, loss_fp: 0.000766, loss_freq: 0.030281
[19:22:25.734] iteration 26940: loss: 0.070489, loss_s1: 0.046385, loss_fp: 0.007204, loss_freq: 0.046595
[19:22:26.374] iteration 26941: loss: 0.037451, loss_s1: 0.018946, loss_fp: 0.001489, loss_freq: 0.020644
[19:22:27.005] iteration 26942: loss: 0.042417, loss_s1: 0.035577, loss_fp: 0.002629, loss_freq: 0.011271
[19:22:27.638] iteration 26943: loss: 0.036604, loss_s1: 0.021827, loss_fp: 0.002175, loss_freq: 0.014040
[19:22:28.276] iteration 26944: loss: 0.047532, loss_s1: 0.012682, loss_fp: 0.002338, loss_freq: 0.010158
[19:22:28.907] iteration 26945: loss: 0.054403, loss_s1: 0.039049, loss_fp: 0.001224, loss_freq: 0.025933
[19:22:29.533] iteration 26946: loss: 0.037398, loss_s1: 0.014434, loss_fp: 0.003258, loss_freq: 0.028465
[19:22:30.162] iteration 26947: loss: 0.046396, loss_s1: 0.037837, loss_fp: 0.002137, loss_freq: 0.024586
[19:22:30.788] iteration 26948: loss: 0.048493, loss_s1: 0.029316, loss_fp: 0.007362, loss_freq: 0.020530
[19:22:31.413] iteration 26949: loss: 0.057519, loss_s1: 0.054375, loss_fp: 0.003543, loss_freq: 0.029078
[19:22:32.035] iteration 26950: loss: 0.037465, loss_s1: 0.028291, loss_fp: 0.001898, loss_freq: 0.010206
[19:22:32.664] iteration 26951: loss: 0.032242, loss_s1: 0.022847, loss_fp: 0.002747, loss_freq: 0.010217
[19:22:33.294] iteration 26952: loss: 0.055161, loss_s1: 0.030455, loss_fp: 0.025386, loss_freq: 0.012263
[19:22:33.919] iteration 26953: loss: 0.061950, loss_s1: 0.040669, loss_fp: 0.010618, loss_freq: 0.047081
[19:22:34.549] iteration 26954: loss: 0.047253, loss_s1: 0.033973, loss_fp: 0.001114, loss_freq: 0.022952
[19:22:35.180] iteration 26955: loss: 0.063270, loss_s1: 0.047026, loss_fp: 0.002148, loss_freq: 0.051351
[19:22:35.809] iteration 26956: loss: 0.043632, loss_s1: 0.036919, loss_fp: 0.003292, loss_freq: 0.018383
[19:22:36.440] iteration 26957: loss: 0.064194, loss_s1: 0.043063, loss_fp: 0.001704, loss_freq: 0.035391
[19:22:37.070] iteration 26958: loss: 0.061121, loss_s1: 0.048418, loss_fp: 0.004086, loss_freq: 0.029736
[19:22:37.697] iteration 26959: loss: 0.047058, loss_s1: 0.041094, loss_fp: 0.001071, loss_freq: 0.018332
[19:22:38.321] iteration 26960: loss: 0.059207, loss_s1: 0.074366, loss_fp: 0.004478, loss_freq: 0.008400
[19:22:38.949] iteration 26961: loss: 0.040024, loss_s1: 0.037132, loss_fp: 0.002153, loss_freq: 0.008331
[19:22:39.584] iteration 26962: loss: 0.064667, loss_s1: 0.056209, loss_fp: 0.002322, loss_freq: 0.024836
[19:22:40.214] iteration 26963: loss: 0.052504, loss_s1: 0.029046, loss_fp: 0.006886, loss_freq: 0.030238
[19:22:40.842] iteration 26964: loss: 0.039338, loss_s1: 0.027749, loss_fp: 0.001978, loss_freq: 0.023916
[19:22:41.476] iteration 26965: loss: 0.049946, loss_s1: 0.047954, loss_fp: 0.002454, loss_freq: 0.015800
[19:22:42.105] iteration 26966: loss: 0.026796, loss_s1: 0.016610, loss_fp: 0.004319, loss_freq: 0.003362
[19:22:42.735] iteration 26967: loss: 0.053889, loss_s1: 0.027006, loss_fp: 0.007928, loss_freq: 0.036964
[19:22:43.375] iteration 26968: loss: 0.048773, loss_s1: 0.045905, loss_fp: 0.008341, loss_freq: 0.011102
[19:22:44.000] iteration 26969: loss: 0.069199, loss_s1: 0.073531, loss_fp: 0.003685, loss_freq: 0.025892
[19:22:44.630] iteration 26970: loss: 0.050260, loss_s1: 0.066659, loss_fp: 0.003918, loss_freq: 0.006302
[19:22:45.254] iteration 26971: loss: 0.062510, loss_s1: 0.046723, loss_fp: 0.001644, loss_freq: 0.041105
[19:22:45.876] iteration 26972: loss: 0.088933, loss_s1: 0.089975, loss_fp: 0.001701, loss_freq: 0.052188
[19:22:46.498] iteration 26973: loss: 0.037434, loss_s1: 0.033106, loss_fp: 0.002469, loss_freq: 0.012800
[19:22:47.125] iteration 26974: loss: 0.049347, loss_s1: 0.031767, loss_fp: 0.001984, loss_freq: 0.019053
[19:22:47.751] iteration 26975: loss: 0.055940, loss_s1: 0.050734, loss_fp: 0.012343, loss_freq: 0.018195
[19:22:48.375] iteration 26976: loss: 0.056881, loss_s1: 0.050789, loss_fp: 0.005056, loss_freq: 0.023760
[19:22:49.013] iteration 26977: loss: 0.059668, loss_s1: 0.056459, loss_fp: 0.001653, loss_freq: 0.033918
[19:22:49.637] iteration 26978: loss: 0.086276, loss_s1: 0.102699, loss_fp: 0.010457, loss_freq: 0.024053
[19:22:50.262] iteration 26979: loss: 0.073766, loss_s1: 0.056811, loss_fp: 0.006624, loss_freq: 0.052132
[19:22:50.884] iteration 26980: loss: 0.065205, loss_s1: 0.036147, loss_fp: 0.004246, loss_freq: 0.020091
[19:22:51.507] iteration 26981: loss: 0.044134, loss_s1: 0.041109, loss_fp: 0.010347, loss_freq: 0.008473
[19:22:52.131] iteration 26982: loss: 0.028770, loss_s1: 0.017023, loss_fp: 0.002951, loss_freq: 0.007665
[19:22:52.751] iteration 26983: loss: 0.047467, loss_s1: 0.024861, loss_fp: 0.002552, loss_freq: 0.039991
[19:22:53.376] iteration 26984: loss: 0.040060, loss_s1: 0.023400, loss_fp: 0.002261, loss_freq: 0.015428
[19:22:53.997] iteration 26985: loss: 0.033922, loss_s1: 0.007753, loss_fp: 0.000885, loss_freq: 0.018121
[19:22:54.625] iteration 26986: loss: 0.037450, loss_s1: 0.011791, loss_fp: 0.001185, loss_freq: 0.029638
[19:22:55.255] iteration 26987: loss: 0.042213, loss_s1: 0.027301, loss_fp: 0.001408, loss_freq: 0.026431
[19:22:55.887] iteration 26988: loss: 0.050415, loss_s1: 0.040552, loss_fp: 0.009071, loss_freq: 0.025938
[19:22:56.512] iteration 26989: loss: 0.060671, loss_s1: 0.062541, loss_fp: 0.003696, loss_freq: 0.019965
[19:22:57.144] iteration 26990: loss: 0.047510, loss_s1: 0.039371, loss_fp: 0.004258, loss_freq: 0.026528
[19:22:57.773] iteration 26991: loss: 0.054410, loss_s1: 0.039599, loss_fp: 0.011569, loss_freq: 0.022933
[19:22:58.399] iteration 26992: loss: 0.057187, loss_s1: 0.047185, loss_fp: 0.006711, loss_freq: 0.012693
[19:22:59.025] iteration 26993: loss: 0.046733, loss_s1: 0.039506, loss_fp: 0.000758, loss_freq: 0.014359
[19:22:59.679] iteration 26994: loss: 0.030937, loss_s1: 0.016819, loss_fp: 0.001861, loss_freq: 0.014079
[19:23:00.313] iteration 26995: loss: 0.046917, loss_s1: 0.031263, loss_fp: 0.002507, loss_freq: 0.028555
[19:23:00.957] iteration 26996: loss: 0.073351, loss_s1: 0.052790, loss_fp: 0.005760, loss_freq: 0.052134
[19:23:01.599] iteration 26997: loss: 0.035958, loss_s1: 0.017846, loss_fp: 0.003723, loss_freq: 0.020470
[19:23:02.247] iteration 26998: loss: 0.057242, loss_s1: 0.048748, loss_fp: 0.001773, loss_freq: 0.008494
[19:23:02.882] iteration 26999: loss: 0.057690, loss_s1: 0.049375, loss_fp: 0.002721, loss_freq: 0.034266
[19:23:03.521] iteration 27000: loss: 0.033936, loss_s1: 0.018189, loss_fp: 0.003686, loss_freq: 0.016005
[19:23:06.648] iteration 27000 : mean_dice : 0.741362
[19:23:07.294] iteration 27001: loss: 0.055692, loss_s1: 0.054512, loss_fp: 0.004277, loss_freq: 0.027770
[19:23:07.920] iteration 27002: loss: 0.034432, loss_s1: 0.028395, loss_fp: 0.000964, loss_freq: 0.005482
[19:23:08.550] iteration 27003: loss: 0.049732, loss_s1: 0.051062, loss_fp: 0.001329, loss_freq: 0.012366
[19:23:09.179] iteration 27004: loss: 0.035308, loss_s1: 0.018370, loss_fp: 0.002337, loss_freq: 0.023566
[19:23:09.805] iteration 27005: loss: 0.039023, loss_s1: 0.030769, loss_fp: 0.009630, loss_freq: 0.016441
[19:23:10.431] iteration 27006: loss: 0.070259, loss_s1: 0.061407, loss_fp: 0.005060, loss_freq: 0.025089
[19:23:11.051] iteration 27007: loss: 0.113376, loss_s1: 0.121835, loss_fp: 0.001264, loss_freq: 0.064888
[19:23:11.680] iteration 27008: loss: 0.041502, loss_s1: 0.015459, loss_fp: 0.002458, loss_freq: 0.031260
[19:23:12.304] iteration 27009: loss: 0.060272, loss_s1: 0.054911, loss_fp: 0.009481, loss_freq: 0.019430
[19:23:12.921] iteration 27010: loss: 0.072870, loss_s1: 0.089562, loss_fp: 0.002598, loss_freq: 0.011323
[19:23:13.546] iteration 27011: loss: 0.032830, loss_s1: 0.031783, loss_fp: 0.000367, loss_freq: 0.004775
[19:23:14.175] iteration 27012: loss: 0.051397, loss_s1: 0.026131, loss_fp: 0.007608, loss_freq: 0.038683
[19:23:14.809] iteration 27013: loss: 0.046722, loss_s1: 0.033629, loss_fp: 0.000919, loss_freq: 0.025839
[19:23:15.489] iteration 27014: loss: 0.069663, loss_s1: 0.074270, loss_fp: 0.002362, loss_freq: 0.023020
[19:23:16.130] iteration 27015: loss: 0.091227, loss_s1: 0.100096, loss_fp: 0.001646, loss_freq: 0.030350
[19:23:16.762] iteration 27016: loss: 0.084155, loss_s1: 0.068522, loss_fp: 0.007062, loss_freq: 0.063587
[19:23:17.390] iteration 27017: loss: 0.035099, loss_s1: 0.030586, loss_fp: 0.003276, loss_freq: 0.010471
[19:23:18.014] iteration 27018: loss: 0.040113, loss_s1: 0.027033, loss_fp: 0.003439, loss_freq: 0.019839
[19:23:18.637] iteration 27019: loss: 0.047739, loss_s1: 0.032980, loss_fp: 0.000750, loss_freq: 0.034576
[19:23:19.261] iteration 27020: loss: 0.050994, loss_s1: 0.039699, loss_fp: 0.001512, loss_freq: 0.023841
[19:23:19.886] iteration 27021: loss: 0.045890, loss_s1: 0.047685, loss_fp: 0.000579, loss_freq: 0.012076
[19:23:20.517] iteration 27022: loss: 0.043751, loss_s1: 0.026937, loss_fp: 0.001148, loss_freq: 0.033968
[19:23:21.181] iteration 27023: loss: 0.047285, loss_s1: 0.031030, loss_fp: 0.003318, loss_freq: 0.036175
[19:23:21.802] iteration 27024: loss: 0.034446, loss_s1: 0.019849, loss_fp: 0.001070, loss_freq: 0.012088
[19:23:22.422] iteration 27025: loss: 0.038798, loss_s1: 0.023286, loss_fp: 0.002053, loss_freq: 0.023637
[19:23:23.042] iteration 27026: loss: 0.050821, loss_s1: 0.038416, loss_fp: 0.006522, loss_freq: 0.029898
[19:23:23.678] iteration 27027: loss: 0.081262, loss_s1: 0.051969, loss_fp: 0.015100, loss_freq: 0.055586
[19:23:24.311] iteration 27028: loss: 0.058910, loss_s1: 0.064071, loss_fp: 0.002811, loss_freq: 0.022462
[19:23:24.935] iteration 27029: loss: 0.042009, loss_s1: 0.033399, loss_fp: 0.001019, loss_freq: 0.017128
[19:23:25.557] iteration 27030: loss: 0.041122, loss_s1: 0.034906, loss_fp: 0.009461, loss_freq: 0.010634
[19:23:26.179] iteration 27031: loss: 0.061899, loss_s1: 0.056485, loss_fp: 0.004477, loss_freq: 0.023229
[19:23:26.802] iteration 27032: loss: 0.047245, loss_s1: 0.047268, loss_fp: 0.003773, loss_freq: 0.014039
[19:23:27.429] iteration 27033: loss: 0.058758, loss_s1: 0.056898, loss_fp: 0.002273, loss_freq: 0.018039
[19:23:28.049] iteration 27034: loss: 0.068375, loss_s1: 0.064869, loss_fp: 0.003639, loss_freq: 0.044510
[19:23:28.677] iteration 27035: loss: 0.029776, loss_s1: 0.016918, loss_fp: 0.003119, loss_freq: 0.009089
[19:23:29.299] iteration 27036: loss: 0.042480, loss_s1: 0.038410, loss_fp: 0.002305, loss_freq: 0.013129
[19:23:29.917] iteration 27037: loss: 0.124534, loss_s1: 0.140747, loss_fp: 0.015057, loss_freq: 0.056695
[19:23:30.542] iteration 27038: loss: 0.031902, loss_s1: 0.012018, loss_fp: 0.007118, loss_freq: 0.013306
[19:23:31.175] iteration 27039: loss: 0.095659, loss_s1: 0.078325, loss_fp: 0.015905, loss_freq: 0.066104
[19:23:31.799] iteration 27040: loss: 0.038562, loss_s1: 0.020922, loss_fp: 0.004051, loss_freq: 0.023557
[19:23:32.427] iteration 27041: loss: 0.073220, loss_s1: 0.055863, loss_fp: 0.003136, loss_freq: 0.044621
[19:23:33.051] iteration 27042: loss: 0.027989, loss_s1: 0.017422, loss_fp: 0.000525, loss_freq: 0.008304
[19:23:33.674] iteration 27043: loss: 0.030599, loss_s1: 0.018147, loss_fp: 0.000705, loss_freq: 0.012343
[19:23:34.316] iteration 27044: loss: 0.038719, loss_s1: 0.024370, loss_fp: 0.001906, loss_freq: 0.015528
[19:23:34.957] iteration 27045: loss: 0.044692, loss_s1: 0.037513, loss_fp: 0.002357, loss_freq: 0.012835
[19:23:35.586] iteration 27046: loss: 0.063579, loss_s1: 0.069139, loss_fp: 0.002991, loss_freq: 0.023810
[19:23:36.213] iteration 27047: loss: 0.058401, loss_s1: 0.037321, loss_fp: 0.001680, loss_freq: 0.032094
[19:23:36.840] iteration 27048: loss: 0.047194, loss_s1: 0.033892, loss_fp: 0.012562, loss_freq: 0.013685
[19:23:37.804] iteration 27049: loss: 0.049853, loss_s1: 0.051579, loss_fp: 0.002898, loss_freq: 0.011501
[19:23:38.442] iteration 27050: loss: 0.070132, loss_s1: 0.044146, loss_fp: 0.003731, loss_freq: 0.024667
[19:23:39.078] iteration 27051: loss: 0.035688, loss_s1: 0.019352, loss_fp: 0.005590, loss_freq: 0.009883
[19:23:39.714] iteration 27052: loss: 0.046165, loss_s1: 0.038549, loss_fp: 0.003640, loss_freq: 0.016924
[19:23:40.342] iteration 27053: loss: 0.049741, loss_s1: 0.033575, loss_fp: 0.003001, loss_freq: 0.033123
[19:23:40.975] iteration 27054: loss: 0.074021, loss_s1: 0.055321, loss_fp: 0.014334, loss_freq: 0.036916
[19:23:41.638] iteration 27055: loss: 0.064118, loss_s1: 0.029873, loss_fp: 0.002144, loss_freq: 0.060615
[19:23:42.284] iteration 27056: loss: 0.037885, loss_s1: 0.038560, loss_fp: 0.001764, loss_freq: 0.007143
[19:23:42.914] iteration 27057: loss: 0.063750, loss_s1: 0.055194, loss_fp: 0.006828, loss_freq: 0.030075
[19:23:43.538] iteration 27058: loss: 0.071048, loss_s1: 0.083967, loss_fp: 0.010752, loss_freq: 0.006489
[19:23:44.170] iteration 27059: loss: 0.026277, loss_s1: 0.014351, loss_fp: 0.001134, loss_freq: 0.007306
[19:23:44.800] iteration 27060: loss: 0.040799, loss_s1: 0.018723, loss_fp: 0.013842, loss_freq: 0.018186
[19:23:45.423] iteration 27061: loss: 0.061790, loss_s1: 0.033057, loss_fp: 0.007394, loss_freq: 0.057287
[19:23:46.052] iteration 27062: loss: 0.044175, loss_s1: 0.024282, loss_fp: 0.002666, loss_freq: 0.028129
[19:23:46.681] iteration 27063: loss: 0.030461, loss_s1: 0.022757, loss_fp: 0.005266, loss_freq: 0.009618
[19:23:47.314] iteration 27064: loss: 0.108391, loss_s1: 0.051452, loss_fp: 0.002047, loss_freq: 0.127409
[19:23:47.945] iteration 27065: loss: 0.045204, loss_s1: 0.033183, loss_fp: 0.003099, loss_freq: 0.015417
[19:23:48.567] iteration 27066: loss: 0.063390, loss_s1: 0.032959, loss_fp: 0.010224, loss_freq: 0.034368
[19:23:49.189] iteration 27067: loss: 0.053511, loss_s1: 0.038602, loss_fp: 0.001334, loss_freq: 0.027413
[19:23:49.814] iteration 27068: loss: 0.058462, loss_s1: 0.034496, loss_fp: 0.003508, loss_freq: 0.033571
[19:23:50.443] iteration 27069: loss: 0.034287, loss_s1: 0.024791, loss_fp: 0.000532, loss_freq: 0.008410
[19:23:51.078] iteration 27070: loss: 0.035576, loss_s1: 0.023694, loss_fp: 0.000834, loss_freq: 0.013668
[19:23:51.704] iteration 27071: loss: 0.050407, loss_s1: 0.038122, loss_fp: 0.003281, loss_freq: 0.011611
[19:23:52.332] iteration 27072: loss: 0.052811, loss_s1: 0.039011, loss_fp: 0.002126, loss_freq: 0.039751
[19:23:52.967] iteration 27073: loss: 0.043090, loss_s1: 0.043711, loss_fp: 0.000650, loss_freq: 0.013593
[19:23:53.595] iteration 27074: loss: 0.053225, loss_s1: 0.033477, loss_fp: 0.005621, loss_freq: 0.036901
[19:23:54.222] iteration 27075: loss: 0.039711, loss_s1: 0.033385, loss_fp: 0.000727, loss_freq: 0.007456
[19:23:54.851] iteration 27076: loss: 0.064430, loss_s1: 0.040832, loss_fp: 0.009135, loss_freq: 0.044806
[19:23:55.481] iteration 27077: loss: 0.063170, loss_s1: 0.041131, loss_fp: 0.009793, loss_freq: 0.040740
[19:23:56.107] iteration 27078: loss: 0.032160, loss_s1: 0.022401, loss_fp: 0.001042, loss_freq: 0.009268
[19:23:56.732] iteration 27079: loss: 0.046541, loss_s1: 0.040459, loss_fp: 0.006281, loss_freq: 0.021660
[19:23:57.356] iteration 27080: loss: 0.035285, loss_s1: 0.019915, loss_fp: 0.003994, loss_freq: 0.009228
[19:23:57.984] iteration 27081: loss: 0.050353, loss_s1: 0.036032, loss_fp: 0.002873, loss_freq: 0.033680
[19:23:58.612] iteration 27082: loss: 0.046951, loss_s1: 0.037002, loss_fp: 0.003749, loss_freq: 0.021315
[19:23:59.247] iteration 27083: loss: 0.048528, loss_s1: 0.039935, loss_fp: 0.005633, loss_freq: 0.013097
[19:23:59.878] iteration 27084: loss: 0.059790, loss_s1: 0.050559, loss_fp: 0.005778, loss_freq: 0.036938
[19:24:00.514] iteration 27085: loss: 0.099739, loss_s1: 0.124471, loss_fp: 0.003804, loss_freq: 0.038575
[19:24:01.155] iteration 27086: loss: 0.069584, loss_s1: 0.041391, loss_fp: 0.001853, loss_freq: 0.030648
[19:24:01.785] iteration 27087: loss: 0.097127, loss_s1: 0.090496, loss_fp: 0.003116, loss_freq: 0.052413
[19:24:02.423] iteration 27088: loss: 0.049027, loss_s1: 0.034895, loss_fp: 0.001659, loss_freq: 0.030924
[19:24:03.050] iteration 27089: loss: 0.043467, loss_s1: 0.033351, loss_fp: 0.003241, loss_freq: 0.013664
[19:24:03.674] iteration 27090: loss: 0.065973, loss_s1: 0.080265, loss_fp: 0.002014, loss_freq: 0.022955
[19:24:04.295] iteration 27091: loss: 0.074335, loss_s1: 0.051175, loss_fp: 0.009882, loss_freq: 0.060176
[19:24:04.921] iteration 27092: loss: 0.049667, loss_s1: 0.013886, loss_fp: 0.001985, loss_freq: 0.049380
[19:24:05.549] iteration 27093: loss: 0.072124, loss_s1: 0.042525, loss_fp: 0.001887, loss_freq: 0.059645
[19:24:06.173] iteration 27094: loss: 0.055324, loss_s1: 0.045979, loss_fp: 0.010351, loss_freq: 0.002562
[19:24:06.812] iteration 27095: loss: 0.028757, loss_s1: 0.025238, loss_fp: 0.000330, loss_freq: 0.003438
[19:24:07.438] iteration 27096: loss: 0.081830, loss_s1: 0.052162, loss_fp: 0.008132, loss_freq: 0.075213
[19:24:08.075] iteration 27097: loss: 0.061973, loss_s1: 0.059242, loss_fp: 0.003342, loss_freq: 0.030069
[19:24:08.701] iteration 27098: loss: 0.037126, loss_s1: 0.033565, loss_fp: 0.000827, loss_freq: 0.015773
[19:24:09.327] iteration 27099: loss: 0.034147, loss_s1: 0.022104, loss_fp: 0.001534, loss_freq: 0.010819
[19:24:09.948] iteration 27100: loss: 0.038343, loss_s1: 0.031736, loss_fp: 0.004088, loss_freq: 0.009839
[19:24:10.571] iteration 27101: loss: 0.049976, loss_s1: 0.030422, loss_fp: 0.004530, loss_freq: 0.015293
[19:24:11.200] iteration 27102: loss: 0.047378, loss_s1: 0.034690, loss_fp: 0.002800, loss_freq: 0.025075
[19:24:11.828] iteration 27103: loss: 0.033675, loss_s1: 0.031376, loss_fp: 0.000657, loss_freq: 0.009728
[19:24:12.461] iteration 27104: loss: 0.065048, loss_s1: 0.048526, loss_fp: 0.011019, loss_freq: 0.033939
[19:24:13.103] iteration 27105: loss: 0.039724, loss_s1: 0.021358, loss_fp: 0.008768, loss_freq: 0.016852
[19:24:13.744] iteration 27106: loss: 0.063421, loss_s1: 0.029701, loss_fp: 0.001661, loss_freq: 0.026369
[19:24:14.383] iteration 27107: loss: 0.029356, loss_s1: 0.019043, loss_fp: 0.002750, loss_freq: 0.010244
[19:24:15.019] iteration 27108: loss: 0.054647, loss_s1: 0.046217, loss_fp: 0.004026, loss_freq: 0.030759
[19:24:15.657] iteration 27109: loss: 0.034670, loss_s1: 0.013453, loss_fp: 0.002072, loss_freq: 0.020414
[19:24:16.285] iteration 27110: loss: 0.049999, loss_s1: 0.045987, loss_fp: 0.001759, loss_freq: 0.022537
[19:24:16.913] iteration 27111: loss: 0.042382, loss_s1: 0.033918, loss_fp: 0.000765, loss_freq: 0.013905
[19:24:17.537] iteration 27112: loss: 0.048391, loss_s1: 0.044913, loss_fp: 0.004103, loss_freq: 0.007495
[19:24:18.169] iteration 27113: loss: 0.034016, loss_s1: 0.016305, loss_fp: 0.003490, loss_freq: 0.009006
[19:24:18.795] iteration 27114: loss: 0.043363, loss_s1: 0.023547, loss_fp: 0.007069, loss_freq: 0.027543
[19:24:19.422] iteration 27115: loss: 0.049101, loss_s1: 0.015653, loss_fp: 0.014829, loss_freq: 0.032168
[19:24:20.050] iteration 27116: loss: 0.059008, loss_s1: 0.055083, loss_fp: 0.010331, loss_freq: 0.026756
[19:24:20.681] iteration 27117: loss: 0.047661, loss_s1: 0.028220, loss_fp: 0.008076, loss_freq: 0.030846
[19:24:21.312] iteration 27118: loss: 0.047620, loss_s1: 0.020026, loss_fp: 0.001828, loss_freq: 0.020182
[19:24:21.942] iteration 27119: loss: 0.067215, loss_s1: 0.063709, loss_fp: 0.008092, loss_freq: 0.032037
[19:24:22.575] iteration 27120: loss: 0.058308, loss_s1: 0.046474, loss_fp: 0.001968, loss_freq: 0.028182
[19:24:23.206] iteration 27121: loss: 0.050821, loss_s1: 0.026503, loss_fp: 0.003609, loss_freq: 0.039600
[19:24:23.837] iteration 27122: loss: 0.060989, loss_s1: 0.045746, loss_fp: 0.007598, loss_freq: 0.027914
[19:24:24.471] iteration 27123: loss: 0.053633, loss_s1: 0.046210, loss_fp: 0.002228, loss_freq: 0.021724
[19:24:25.095] iteration 27124: loss: 0.084663, loss_s1: 0.060416, loss_fp: 0.013591, loss_freq: 0.040287
[19:24:25.729] iteration 27125: loss: 0.037364, loss_s1: 0.032798, loss_fp: 0.002432, loss_freq: 0.009909
[19:24:26.353] iteration 27126: loss: 0.041288, loss_s1: 0.033631, loss_fp: 0.001993, loss_freq: 0.012633
[19:24:26.991] iteration 27127: loss: 0.020189, loss_s1: 0.008771, loss_fp: 0.001070, loss_freq: 0.006638
[19:24:27.629] iteration 27128: loss: 0.077090, loss_s1: 0.075389, loss_fp: 0.004424, loss_freq: 0.027745
[19:24:28.275] iteration 27129: loss: 0.066793, loss_s1: 0.051500, loss_fp: 0.002459, loss_freq: 0.039322
[19:24:28.928] iteration 27130: loss: 0.064878, loss_s1: 0.058346, loss_fp: 0.002555, loss_freq: 0.037999
[19:24:29.564] iteration 27131: loss: 0.047036, loss_s1: 0.046551, loss_fp: 0.003401, loss_freq: 0.019588
[19:24:30.206] iteration 27132: loss: 0.058622, loss_s1: 0.055633, loss_fp: 0.001044, loss_freq: 0.026885
[19:24:30.850] iteration 27133: loss: 0.068532, loss_s1: 0.061398, loss_fp: 0.002874, loss_freq: 0.041660
[19:24:31.491] iteration 27134: loss: 0.029598, loss_s1: 0.017304, loss_fp: 0.002775, loss_freq: 0.010627
[19:24:32.133] iteration 27135: loss: 0.034544, loss_s1: 0.023706, loss_fp: 0.002014, loss_freq: 0.009952
[19:24:32.779] iteration 27136: loss: 0.047539, loss_s1: 0.033635, loss_fp: 0.003707, loss_freq: 0.026708
[19:24:33.419] iteration 27137: loss: 0.054834, loss_s1: 0.040693, loss_fp: 0.003272, loss_freq: 0.034975
[19:24:34.062] iteration 27138: loss: 0.053578, loss_s1: 0.021277, loss_fp: 0.002289, loss_freq: 0.029017
[19:24:34.707] iteration 27139: loss: 0.066437, loss_s1: 0.058086, loss_fp: 0.003480, loss_freq: 0.026092
[19:24:35.335] iteration 27140: loss: 0.056295, loss_s1: 0.039409, loss_fp: 0.006896, loss_freq: 0.033763
[19:24:35.997] iteration 27141: loss: 0.043724, loss_s1: 0.013016, loss_fp: 0.000535, loss_freq: 0.029231
[19:24:36.628] iteration 27142: loss: 0.042341, loss_s1: 0.043674, loss_fp: 0.000291, loss_freq: 0.012268
[19:24:37.266] iteration 27143: loss: 0.063510, loss_s1: 0.032323, loss_fp: 0.012689, loss_freq: 0.049454
[19:24:37.897] iteration 27144: loss: 0.036933, loss_s1: 0.031900, loss_fp: 0.004796, loss_freq: 0.013976
[19:24:38.520] iteration 27145: loss: 0.029895, loss_s1: 0.011600, loss_fp: 0.000655, loss_freq: 0.019166
[19:24:39.144] iteration 27146: loss: 0.031497, loss_s1: 0.016898, loss_fp: 0.005348, loss_freq: 0.005526
[19:24:39.769] iteration 27147: loss: 0.059138, loss_s1: 0.068916, loss_fp: 0.002055, loss_freq: 0.017219
[19:24:40.397] iteration 27148: loss: 0.040213, loss_s1: 0.033989, loss_fp: 0.007255, loss_freq: 0.010235
[19:24:41.021] iteration 27149: loss: 0.071760, loss_s1: 0.086658, loss_fp: 0.002665, loss_freq: 0.024541
[19:24:41.658] iteration 27150: loss: 0.069356, loss_s1: 0.062970, loss_fp: 0.003307, loss_freq: 0.041506
[19:24:42.294] iteration 27151: loss: 0.039151, loss_s1: 0.028188, loss_fp: 0.003273, loss_freq: 0.021061
[19:24:42.925] iteration 27152: loss: 0.060428, loss_s1: 0.064921, loss_fp: 0.001922, loss_freq: 0.018023
[19:24:43.564] iteration 27153: loss: 0.041082, loss_s1: 0.019078, loss_fp: 0.005934, loss_freq: 0.009223
[19:24:44.190] iteration 27154: loss: 0.029063, loss_s1: 0.012154, loss_fp: 0.001543, loss_freq: 0.016178
[19:24:44.833] iteration 27155: loss: 0.027454, loss_s1: 0.011807, loss_fp: 0.002022, loss_freq: 0.011315
[19:24:45.459] iteration 27156: loss: 0.059885, loss_s1: 0.057250, loss_fp: 0.001043, loss_freq: 0.020120
[19:24:46.085] iteration 27157: loss: 0.065268, loss_s1: 0.031477, loss_fp: 0.002478, loss_freq: 0.063851
[19:24:46.710] iteration 27158: loss: 0.064569, loss_s1: 0.055160, loss_fp: 0.005202, loss_freq: 0.035657
[19:24:47.335] iteration 27159: loss: 0.035281, loss_s1: 0.018963, loss_fp: 0.001796, loss_freq: 0.010782
[19:24:47.957] iteration 27160: loss: 0.049035, loss_s1: 0.041866, loss_fp: 0.000979, loss_freq: 0.021931
[19:24:48.605] iteration 27161: loss: 0.038647, loss_s1: 0.020453, loss_fp: 0.004015, loss_freq: 0.017739
[19:24:49.237] iteration 27162: loss: 0.038229, loss_s1: 0.028456, loss_fp: 0.002566, loss_freq: 0.017389
[19:24:49.876] iteration 27163: loss: 0.033745, loss_s1: 0.019844, loss_fp: 0.001325, loss_freq: 0.013621
[19:24:50.510] iteration 27164: loss: 0.066699, loss_s1: 0.083794, loss_fp: 0.001954, loss_freq: 0.015928
[19:24:51.150] iteration 27165: loss: 0.042441, loss_s1: 0.031829, loss_fp: 0.002058, loss_freq: 0.020171
[19:24:51.784] iteration 27166: loss: 0.038597, loss_s1: 0.025439, loss_fp: 0.003873, loss_freq: 0.019866
[19:24:52.412] iteration 27167: loss: 0.049640, loss_s1: 0.035663, loss_fp: 0.002112, loss_freq: 0.025824
[19:24:53.039] iteration 27168: loss: 0.102337, loss_s1: 0.086641, loss_fp: 0.002670, loss_freq: 0.088547
[19:24:53.676] iteration 27169: loss: 0.040523, loss_s1: 0.036041, loss_fp: 0.002098, loss_freq: 0.012841
[19:24:54.305] iteration 27170: loss: 0.087824, loss_s1: 0.060848, loss_fp: 0.003928, loss_freq: 0.025425
[19:24:54.937] iteration 27171: loss: 0.046352, loss_s1: 0.053122, loss_fp: 0.002036, loss_freq: 0.008391
[19:24:55.598] iteration 27172: loss: 0.052731, loss_s1: 0.035726, loss_fp: 0.001006, loss_freq: 0.016966
[19:24:56.225] iteration 27173: loss: 0.057102, loss_s1: 0.042307, loss_fp: 0.006304, loss_freq: 0.037391
[19:24:56.854] iteration 27174: loss: 0.041935, loss_s1: 0.030682, loss_fp: 0.000950, loss_freq: 0.013751
[19:24:57.487] iteration 27175: loss: 0.052717, loss_s1: 0.060216, loss_fp: 0.003364, loss_freq: 0.007941
[19:24:58.122] iteration 27176: loss: 0.072802, loss_s1: 0.055888, loss_fp: 0.001347, loss_freq: 0.039488
[19:24:58.748] iteration 27177: loss: 0.058356, loss_s1: 0.043449, loss_fp: 0.009362, loss_freq: 0.036153
[19:24:59.377] iteration 27178: loss: 0.040020, loss_s1: 0.042268, loss_fp: 0.002360, loss_freq: 0.010784
[19:25:00.006] iteration 27179: loss: 0.050257, loss_s1: 0.038037, loss_fp: 0.003263, loss_freq: 0.031584
[19:25:00.632] iteration 27180: loss: 0.047136, loss_s1: 0.042276, loss_fp: 0.003233, loss_freq: 0.015640
[19:25:01.256] iteration 27181: loss: 0.068188, loss_s1: 0.057196, loss_fp: 0.003901, loss_freq: 0.032256
[19:25:01.879] iteration 27182: loss: 0.039971, loss_s1: 0.033141, loss_fp: 0.002441, loss_freq: 0.007391
[19:25:02.508] iteration 27183: loss: 0.053416, loss_s1: 0.027266, loss_fp: 0.005265, loss_freq: 0.033186
[19:25:03.130] iteration 27184: loss: 0.043228, loss_s1: 0.046248, loss_fp: 0.001463, loss_freq: 0.014285
[19:25:03.757] iteration 27185: loss: 0.048097, loss_s1: 0.042674, loss_fp: 0.000960, loss_freq: 0.011660
[19:25:04.383] iteration 27186: loss: 0.029842, loss_s1: 0.012211, loss_fp: 0.002932, loss_freq: 0.012495
[19:25:05.008] iteration 27187: loss: 0.036248, loss_s1: 0.020279, loss_fp: 0.009376, loss_freq: 0.007362
[19:25:05.641] iteration 27188: loss: 0.074882, loss_s1: 0.064600, loss_fp: 0.003065, loss_freq: 0.039391
[19:25:06.265] iteration 27189: loss: 0.090427, loss_s1: 0.124262, loss_fp: 0.001185, loss_freq: 0.026541
[19:25:06.888] iteration 27190: loss: 0.045847, loss_s1: 0.028547, loss_fp: 0.012021, loss_freq: 0.023004
[19:25:07.512] iteration 27191: loss: 0.072130, loss_s1: 0.042311, loss_fp: 0.006279, loss_freq: 0.065657
[19:25:08.135] iteration 27192: loss: 0.067651, loss_s1: 0.063688, loss_fp: 0.007712, loss_freq: 0.023811
[19:25:08.755] iteration 27193: loss: 0.035231, loss_s1: 0.014390, loss_fp: 0.002507, loss_freq: 0.022713
[19:25:09.377] iteration 27194: loss: 0.060373, loss_s1: 0.066613, loss_fp: 0.003108, loss_freq: 0.013902
[19:25:10.006] iteration 27195: loss: 0.073855, loss_s1: 0.074213, loss_fp: 0.009250, loss_freq: 0.036173
[19:25:10.638] iteration 27196: loss: 0.036779, loss_s1: 0.029911, loss_fp: 0.000718, loss_freq: 0.016259
[19:25:11.265] iteration 27197: loss: 0.043123, loss_s1: 0.037102, loss_fp: 0.005603, loss_freq: 0.020656
[19:25:11.892] iteration 27198: loss: 0.072502, loss_s1: 0.042913, loss_fp: 0.004633, loss_freq: 0.059447
[19:25:12.518] iteration 27199: loss: 0.055070, loss_s1: 0.054770, loss_fp: 0.002619, loss_freq: 0.022929
[19:25:13.147] iteration 27200: loss: 0.047930, loss_s1: 0.024317, loss_fp: 0.011539, loss_freq: 0.028648
[19:25:16.340] iteration 27200 : mean_dice : 0.738637
[19:25:17.001] iteration 27201: loss: 0.049493, loss_s1: 0.047562, loss_fp: 0.005050, loss_freq: 0.020226
[19:25:17.732] iteration 27202: loss: 0.062316, loss_s1: 0.046000, loss_fp: 0.003569, loss_freq: 0.030687
[19:25:18.434] iteration 27203: loss: 0.022250, loss_s1: 0.012746, loss_fp: 0.002251, loss_freq: 0.005999
[19:25:19.142] iteration 27204: loss: 0.033074, loss_s1: 0.015983, loss_fp: 0.000422, loss_freq: 0.021127
[19:25:19.802] iteration 27205: loss: 0.045783, loss_s1: 0.045545, loss_fp: 0.001018, loss_freq: 0.013017
[19:25:20.462] iteration 27206: loss: 0.069889, loss_s1: 0.053166, loss_fp: 0.002878, loss_freq: 0.042696
[19:25:21.086] iteration 27207: loss: 0.049460, loss_s1: 0.033499, loss_fp: 0.007201, loss_freq: 0.028173
[19:25:21.709] iteration 27208: loss: 0.056936, loss_s1: 0.050173, loss_fp: 0.005177, loss_freq: 0.027875
[19:25:22.336] iteration 27209: loss: 0.062522, loss_s1: 0.047877, loss_fp: 0.007079, loss_freq: 0.032233
[19:25:23.304] iteration 27210: loss: 0.030636, loss_s1: 0.020441, loss_fp: 0.003064, loss_freq: 0.005597
[19:25:23.930] iteration 27211: loss: 0.069896, loss_s1: 0.067910, loss_fp: 0.001935, loss_freq: 0.032278
[19:25:24.558] iteration 27212: loss: 0.042615, loss_s1: 0.026459, loss_fp: 0.007022, loss_freq: 0.021921
[19:25:25.199] iteration 27213: loss: 0.029451, loss_s1: 0.014797, loss_fp: 0.001869, loss_freq: 0.008107
[19:25:25.829] iteration 27214: loss: 0.052259, loss_s1: 0.060034, loss_fp: 0.002246, loss_freq: 0.011730
[19:25:26.461] iteration 27215: loss: 0.087208, loss_s1: 0.066106, loss_fp: 0.006748, loss_freq: 0.053931
[19:25:27.087] iteration 27216: loss: 0.048198, loss_s1: 0.027683, loss_fp: 0.001962, loss_freq: 0.037324
[19:25:27.730] iteration 27217: loss: 0.029282, loss_s1: 0.026815, loss_fp: 0.001530, loss_freq: 0.005673
[19:25:28.367] iteration 27218: loss: 0.055960, loss_s1: 0.030803, loss_fp: 0.003391, loss_freq: 0.045823
[19:25:28.996] iteration 27219: loss: 0.114637, loss_s1: 0.143554, loss_fp: 0.006611, loss_freq: 0.045419
[19:25:29.636] iteration 27220: loss: 0.039669, loss_s1: 0.015459, loss_fp: 0.001383, loss_freq: 0.011169
[19:25:30.264] iteration 27221: loss: 0.043799, loss_s1: 0.039518, loss_fp: 0.006569, loss_freq: 0.010869
[19:25:30.910] iteration 27222: loss: 0.057434, loss_s1: 0.043870, loss_fp: 0.005941, loss_freq: 0.037986
[19:25:31.545] iteration 27223: loss: 0.045155, loss_s1: 0.027465, loss_fp: 0.006466, loss_freq: 0.023071
[19:25:32.178] iteration 27224: loss: 0.049170, loss_s1: 0.019878, loss_fp: 0.000823, loss_freq: 0.054984
[19:25:32.803] iteration 27225: loss: 0.081725, loss_s1: 0.102153, loss_fp: 0.004165, loss_freq: 0.020605
[19:25:33.451] iteration 27226: loss: 0.039991, loss_s1: 0.020958, loss_fp: 0.003201, loss_freq: 0.013377
[19:25:34.092] iteration 27227: loss: 0.061172, loss_s1: 0.054576, loss_fp: 0.005293, loss_freq: 0.026990
[19:25:34.727] iteration 27228: loss: 0.034885, loss_s1: 0.019629, loss_fp: 0.001968, loss_freq: 0.016261
[19:25:35.364] iteration 27229: loss: 0.037156, loss_s1: 0.024491, loss_fp: 0.001961, loss_freq: 0.018902
[19:25:35.993] iteration 27230: loss: 0.047420, loss_s1: 0.050811, loss_fp: 0.006050, loss_freq: 0.006954
[19:25:36.618] iteration 27231: loss: 0.052518, loss_s1: 0.046360, loss_fp: 0.002252, loss_freq: 0.026431
[19:25:37.252] iteration 27232: loss: 0.064965, loss_s1: 0.058889, loss_fp: 0.004958, loss_freq: 0.025471
[19:25:37.881] iteration 27233: loss: 0.072979, loss_s1: 0.062189, loss_fp: 0.002003, loss_freq: 0.055480
[19:25:38.511] iteration 27234: loss: 0.055295, loss_s1: 0.049478, loss_fp: 0.006507, loss_freq: 0.019212
[19:25:39.159] iteration 27235: loss: 0.056778, loss_s1: 0.057717, loss_fp: 0.005685, loss_freq: 0.023971
[19:25:39.791] iteration 27236: loss: 0.056761, loss_s1: 0.070195, loss_fp: 0.001016, loss_freq: 0.005551
[19:25:40.423] iteration 27237: loss: 0.076676, loss_s1: 0.093969, loss_fp: 0.015091, loss_freq: 0.012225
[19:25:41.053] iteration 27238: loss: 0.071849, loss_s1: 0.033500, loss_fp: 0.009959, loss_freq: 0.056733
[19:25:41.687] iteration 27239: loss: 0.048455, loss_s1: 0.051446, loss_fp: 0.002601, loss_freq: 0.015570
[19:25:42.314] iteration 27240: loss: 0.049711, loss_s1: 0.048071, loss_fp: 0.006272, loss_freq: 0.020879
[19:25:42.945] iteration 27241: loss: 0.047314, loss_s1: 0.034291, loss_fp: 0.007392, loss_freq: 0.021783
[19:25:43.571] iteration 27242: loss: 0.049138, loss_s1: 0.048704, loss_fp: 0.002092, loss_freq: 0.016833
[19:25:44.196] iteration 27243: loss: 0.056666, loss_s1: 0.055126, loss_fp: 0.002754, loss_freq: 0.029257
[19:25:44.852] iteration 27244: loss: 0.054531, loss_s1: 0.038962, loss_fp: 0.001839, loss_freq: 0.031252
[19:25:45.492] iteration 27245: loss: 0.078559, loss_s1: 0.079675, loss_fp: 0.011884, loss_freq: 0.040403
[19:25:46.121] iteration 27246: loss: 0.082029, loss_s1: 0.078861, loss_fp: 0.009019, loss_freq: 0.037920
[19:25:46.746] iteration 27247: loss: 0.052316, loss_s1: 0.030161, loss_fp: 0.004068, loss_freq: 0.040813
[19:25:47.374] iteration 27248: loss: 0.066093, loss_s1: 0.065206, loss_fp: 0.000477, loss_freq: 0.029161
[19:25:48.008] iteration 27249: loss: 0.051979, loss_s1: 0.041082, loss_fp: 0.003658, loss_freq: 0.017464
[19:25:48.655] iteration 27250: loss: 0.040131, loss_s1: 0.026250, loss_fp: 0.002332, loss_freq: 0.010763
[19:25:49.313] iteration 27251: loss: 0.060061, loss_s1: 0.053373, loss_fp: 0.005610, loss_freq: 0.023618
[19:25:49.951] iteration 27252: loss: 0.050278, loss_s1: 0.040912, loss_fp: 0.003808, loss_freq: 0.026860
[19:25:50.584] iteration 27253: loss: 0.049324, loss_s1: 0.027130, loss_fp: 0.001863, loss_freq: 0.040898
[19:25:51.211] iteration 27254: loss: 0.059042, loss_s1: 0.059762, loss_fp: 0.002965, loss_freq: 0.021960
[19:25:51.861] iteration 27255: loss: 0.039934, loss_s1: 0.036989, loss_fp: 0.001214, loss_freq: 0.006273
[19:25:52.492] iteration 27256: loss: 0.043685, loss_s1: 0.026987, loss_fp: 0.004363, loss_freq: 0.024105
[19:25:53.122] iteration 27257: loss: 0.071339, loss_s1: 0.056953, loss_fp: 0.004375, loss_freq: 0.051672
[19:25:53.748] iteration 27258: loss: 0.040313, loss_s1: 0.031497, loss_fp: 0.002853, loss_freq: 0.014670
[19:25:54.381] iteration 27259: loss: 0.066463, loss_s1: 0.063822, loss_fp: 0.007519, loss_freq: 0.034214
[19:25:55.008] iteration 27260: loss: 0.079710, loss_s1: 0.118174, loss_fp: 0.001572, loss_freq: 0.010254
[19:25:55.638] iteration 27261: loss: 0.063204, loss_s1: 0.056626, loss_fp: 0.002510, loss_freq: 0.025628
[19:25:56.274] iteration 27262: loss: 0.048147, loss_s1: 0.040119, loss_fp: 0.002263, loss_freq: 0.023115
[19:25:56.915] iteration 27263: loss: 0.046135, loss_s1: 0.042181, loss_fp: 0.001081, loss_freq: 0.018089
[19:25:57.552] iteration 27264: loss: 0.031759, loss_s1: 0.017845, loss_fp: 0.004003, loss_freq: 0.015391
[19:25:58.184] iteration 27265: loss: 0.047876, loss_s1: 0.034681, loss_fp: 0.001956, loss_freq: 0.019086
[19:25:58.816] iteration 27266: loss: 0.026292, loss_s1: 0.007810, loss_fp: 0.000924, loss_freq: 0.008641
[19:25:59.451] iteration 27267: loss: 0.043108, loss_s1: 0.020333, loss_fp: 0.002366, loss_freq: 0.020473
[19:26:00.087] iteration 27268: loss: 0.023283, loss_s1: 0.013945, loss_fp: 0.001563, loss_freq: 0.005588
[19:26:00.719] iteration 27269: loss: 0.048817, loss_s1: 0.042874, loss_fp: 0.000546, loss_freq: 0.028183
[19:26:01.345] iteration 27270: loss: 0.042835, loss_s1: 0.021831, loss_fp: 0.008409, loss_freq: 0.028223
[19:26:01.975] iteration 27271: loss: 0.031823, loss_s1: 0.013890, loss_fp: 0.005033, loss_freq: 0.016814
[19:26:02.600] iteration 27272: loss: 0.036173, loss_s1: 0.013844, loss_fp: 0.001811, loss_freq: 0.008132
[19:26:03.226] iteration 27273: loss: 0.053779, loss_s1: 0.053261, loss_fp: 0.005457, loss_freq: 0.021956
[19:26:03.852] iteration 27274: loss: 0.042053, loss_s1: 0.026030, loss_fp: 0.012629, loss_freq: 0.015195
[19:26:04.478] iteration 27275: loss: 0.046662, loss_s1: 0.019457, loss_fp: 0.003119, loss_freq: 0.044253
[19:26:05.104] iteration 27276: loss: 0.047125, loss_s1: 0.021430, loss_fp: 0.015618, loss_freq: 0.022613
[19:26:05.733] iteration 27277: loss: 0.051186, loss_s1: 0.041262, loss_fp: 0.003628, loss_freq: 0.033551
[19:26:06.369] iteration 27278: loss: 0.037854, loss_s1: 0.030806, loss_fp: 0.003021, loss_freq: 0.012648
[19:26:07.000] iteration 27279: loss: 0.071710, loss_s1: 0.039240, loss_fp: 0.006722, loss_freq: 0.049030
[19:26:07.628] iteration 27280: loss: 0.082651, loss_s1: 0.060999, loss_fp: 0.002525, loss_freq: 0.069368
[19:26:08.260] iteration 27281: loss: 0.042377, loss_s1: 0.023843, loss_fp: 0.002900, loss_freq: 0.021409
[19:26:08.898] iteration 27282: loss: 0.032599, loss_s1: 0.014193, loss_fp: 0.000455, loss_freq: 0.020163
[19:26:09.526] iteration 27283: loss: 0.036103, loss_s1: 0.020445, loss_fp: 0.002491, loss_freq: 0.008878
[19:26:10.152] iteration 27284: loss: 0.087369, loss_s1: 0.087897, loss_fp: 0.004256, loss_freq: 0.047039
[19:26:10.780] iteration 27285: loss: 0.075883, loss_s1: 0.100107, loss_fp: 0.001260, loss_freq: 0.006374
[19:26:11.417] iteration 27286: loss: 0.060348, loss_s1: 0.037943, loss_fp: 0.006296, loss_freq: 0.042200
[19:26:12.049] iteration 27287: loss: 0.073540, loss_s1: 0.094427, loss_fp: 0.003541, loss_freq: 0.024190
[19:26:12.681] iteration 27288: loss: 0.032339, loss_s1: 0.016658, loss_fp: 0.001453, loss_freq: 0.003569
[19:26:13.307] iteration 27289: loss: 0.045964, loss_s1: 0.025296, loss_fp: 0.003667, loss_freq: 0.026040
[19:26:13.937] iteration 27290: loss: 0.047816, loss_s1: 0.037721, loss_fp: 0.015479, loss_freq: 0.012770
[19:26:14.566] iteration 27291: loss: 0.050080, loss_s1: 0.048716, loss_fp: 0.003437, loss_freq: 0.024117
[19:26:15.192] iteration 27292: loss: 0.034991, loss_s1: 0.015994, loss_fp: 0.005810, loss_freq: 0.015163
[19:26:15.819] iteration 27293: loss: 0.058999, loss_s1: 0.038228, loss_fp: 0.011849, loss_freq: 0.024070
[19:26:16.448] iteration 27294: loss: 0.082842, loss_s1: 0.096900, loss_fp: 0.008612, loss_freq: 0.028826
[19:26:17.078] iteration 27295: loss: 0.038348, loss_s1: 0.028434, loss_fp: 0.004736, loss_freq: 0.014518
[19:26:17.708] iteration 27296: loss: 0.049217, loss_s1: 0.048710, loss_fp: 0.003856, loss_freq: 0.009501
[19:26:18.332] iteration 27297: loss: 0.051489, loss_s1: 0.039764, loss_fp: 0.001871, loss_freq: 0.014320
[19:26:18.966] iteration 27298: loss: 0.070332, loss_s1: 0.050007, loss_fp: 0.002769, loss_freq: 0.020928
[19:26:19.589] iteration 27299: loss: 0.060637, loss_s1: 0.055276, loss_fp: 0.005033, loss_freq: 0.028077
[19:26:20.216] iteration 27300: loss: 0.070813, loss_s1: 0.061498, loss_fp: 0.002452, loss_freq: 0.029538
[19:26:20.842] iteration 27301: loss: 0.065505, loss_s1: 0.043367, loss_fp: 0.004644, loss_freq: 0.049994
[19:26:21.472] iteration 27302: loss: 0.045794, loss_s1: 0.018946, loss_fp: 0.003176, loss_freq: 0.016726
[19:26:22.097] iteration 27303: loss: 0.041736, loss_s1: 0.036974, loss_fp: 0.004263, loss_freq: 0.011980
[19:26:22.726] iteration 27304: loss: 0.061382, loss_s1: 0.064828, loss_fp: 0.004992, loss_freq: 0.021784
[19:26:23.357] iteration 27305: loss: 0.046740, loss_s1: 0.032820, loss_fp: 0.002747, loss_freq: 0.031425
[19:26:23.985] iteration 27306: loss: 0.032957, loss_s1: 0.011965, loss_fp: 0.005341, loss_freq: 0.021416
[19:26:24.609] iteration 27307: loss: 0.052287, loss_s1: 0.025541, loss_fp: 0.002203, loss_freq: 0.016762
[19:26:25.237] iteration 27308: loss: 0.066095, loss_s1: 0.071853, loss_fp: 0.001938, loss_freq: 0.020826
[19:26:25.865] iteration 27309: loss: 0.047275, loss_s1: 0.026146, loss_fp: 0.008901, loss_freq: 0.030233
[19:26:26.500] iteration 27310: loss: 0.056917, loss_s1: 0.047126, loss_fp: 0.001936, loss_freq: 0.030657
[19:26:27.129] iteration 27311: loss: 0.050373, loss_s1: 0.029258, loss_fp: 0.010148, loss_freq: 0.023543
[19:26:27.757] iteration 27312: loss: 0.041220, loss_s1: 0.033390, loss_fp: 0.001590, loss_freq: 0.020736
[19:26:28.385] iteration 27313: loss: 0.043555, loss_s1: 0.024335, loss_fp: 0.005557, loss_freq: 0.024051
[19:26:29.014] iteration 27314: loss: 0.059257, loss_s1: 0.016482, loss_fp: 0.004545, loss_freq: 0.008298
[19:26:29.657] iteration 27315: loss: 0.045912, loss_s1: 0.020618, loss_fp: 0.004903, loss_freq: 0.018885
[19:26:30.284] iteration 27316: loss: 0.034238, loss_s1: 0.027691, loss_fp: 0.000992, loss_freq: 0.010216
[19:26:30.914] iteration 27317: loss: 0.066348, loss_s1: 0.062322, loss_fp: 0.002531, loss_freq: 0.036968
[19:26:31.540] iteration 27318: loss: 0.078992, loss_s1: 0.045720, loss_fp: 0.005696, loss_freq: 0.068371
[19:26:32.162] iteration 27319: loss: 0.046058, loss_s1: 0.024812, loss_fp: 0.001731, loss_freq: 0.031291
[19:26:32.786] iteration 27320: loss: 0.053637, loss_s1: 0.040840, loss_fp: 0.001863, loss_freq: 0.016094
[19:26:33.415] iteration 27321: loss: 0.060339, loss_s1: 0.048626, loss_fp: 0.006263, loss_freq: 0.037826
[19:26:34.039] iteration 27322: loss: 0.060862, loss_s1: 0.049008, loss_fp: 0.011671, loss_freq: 0.022951
[19:26:34.665] iteration 27323: loss: 0.051251, loss_s1: 0.033961, loss_fp: 0.004638, loss_freq: 0.031068
[19:26:35.297] iteration 27324: loss: 0.052022, loss_s1: 0.047577, loss_fp: 0.008130, loss_freq: 0.015031
[19:26:35.923] iteration 27325: loss: 0.055392, loss_s1: 0.058800, loss_fp: 0.003673, loss_freq: 0.018384
[19:26:36.558] iteration 27326: loss: 0.066645, loss_s1: 0.066768, loss_fp: 0.006954, loss_freq: 0.029278
[19:26:37.197] iteration 27327: loss: 0.040749, loss_s1: 0.030904, loss_fp: 0.002102, loss_freq: 0.016623
[19:26:37.831] iteration 27328: loss: 0.064161, loss_s1: 0.079332, loss_fp: 0.004430, loss_freq: 0.011586
[19:26:38.495] iteration 27329: loss: 0.101522, loss_s1: 0.072794, loss_fp: 0.011107, loss_freq: 0.090452
[19:26:39.164] iteration 27330: loss: 0.044487, loss_s1: 0.022244, loss_fp: 0.002673, loss_freq: 0.032407
[19:26:39.791] iteration 27331: loss: 0.051700, loss_s1: 0.037472, loss_fp: 0.005174, loss_freq: 0.025889
[19:26:40.421] iteration 27332: loss: 0.050531, loss_s1: 0.044232, loss_fp: 0.018449, loss_freq: 0.007048
[19:26:41.049] iteration 27333: loss: 0.029390, loss_s1: 0.006334, loss_fp: 0.014062, loss_freq: 0.005816
[19:26:41.712] iteration 27334: loss: 0.048501, loss_s1: 0.033585, loss_fp: 0.003997, loss_freq: 0.014983
[19:26:42.352] iteration 27335: loss: 0.067061, loss_s1: 0.044227, loss_fp: 0.002444, loss_freq: 0.052934
[19:26:42.982] iteration 27336: loss: 0.049531, loss_s1: 0.042529, loss_fp: 0.003223, loss_freq: 0.013129
[19:26:43.617] iteration 27337: loss: 0.102257, loss_s1: 0.058940, loss_fp: 0.004839, loss_freq: 0.094694
[19:26:44.244] iteration 27338: loss: 0.068377, loss_s1: 0.064549, loss_fp: 0.008541, loss_freq: 0.035439
[19:26:44.875] iteration 27339: loss: 0.048601, loss_s1: 0.055853, loss_fp: 0.005409, loss_freq: 0.010802
[19:26:45.501] iteration 27340: loss: 0.053947, loss_s1: 0.035330, loss_fp: 0.003478, loss_freq: 0.041246
[19:26:46.131] iteration 27341: loss: 0.058059, loss_s1: 0.046384, loss_fp: 0.004956, loss_freq: 0.032281
[19:26:46.757] iteration 27342: loss: 0.073370, loss_s1: 0.075398, loss_fp: 0.005595, loss_freq: 0.025400
[19:26:47.385] iteration 27343: loss: 0.028344, loss_s1: 0.019800, loss_fp: 0.003493, loss_freq: 0.007832
[19:26:48.012] iteration 27344: loss: 0.034968, loss_s1: 0.021499, loss_fp: 0.001401, loss_freq: 0.010728
[19:26:48.635] iteration 27345: loss: 0.056410, loss_s1: 0.040335, loss_fp: 0.004435, loss_freq: 0.037955
[19:26:49.264] iteration 27346: loss: 0.051155, loss_s1: 0.045222, loss_fp: 0.004547, loss_freq: 0.014739
[19:26:49.893] iteration 27347: loss: 0.056404, loss_s1: 0.058467, loss_fp: 0.002071, loss_freq: 0.027772
[19:26:50.574] iteration 27348: loss: 0.030171, loss_s1: 0.007584, loss_fp: 0.004259, loss_freq: 0.019769
[19:26:51.207] iteration 27349: loss: 0.083094, loss_s1: 0.061971, loss_fp: 0.017503, loss_freq: 0.027126
[19:26:51.838] iteration 27350: loss: 0.047081, loss_s1: 0.042411, loss_fp: 0.000607, loss_freq: 0.023741
[19:26:52.475] iteration 27351: loss: 0.035036, loss_s1: 0.022132, loss_fp: 0.003133, loss_freq: 0.004984
[19:26:53.107] iteration 27352: loss: 0.078635, loss_s1: 0.071896, loss_fp: 0.008580, loss_freq: 0.039704
[19:26:53.736] iteration 27353: loss: 0.057354, loss_s1: 0.062104, loss_fp: 0.003257, loss_freq: 0.017564
[19:26:54.373] iteration 27354: loss: 0.037673, loss_s1: 0.029569, loss_fp: 0.001949, loss_freq: 0.002352
[19:26:55.027] iteration 27355: loss: 0.057212, loss_s1: 0.047860, loss_fp: 0.008650, loss_freq: 0.013440
[19:26:55.671] iteration 27356: loss: 0.056777, loss_s1: 0.043094, loss_fp: 0.004773, loss_freq: 0.037115
[19:26:56.317] iteration 27357: loss: 0.042594, loss_s1: 0.042198, loss_fp: 0.000598, loss_freq: 0.017640
[19:26:56.959] iteration 27358: loss: 0.043784, loss_s1: 0.032941, loss_fp: 0.004818, loss_freq: 0.016257
[19:26:57.590] iteration 27359: loss: 0.077679, loss_s1: 0.074249, loss_fp: 0.004656, loss_freq: 0.040582
[19:26:58.227] iteration 27360: loss: 0.041310, loss_s1: 0.034386, loss_fp: 0.002578, loss_freq: 0.017754
[19:26:58.851] iteration 27361: loss: 0.068973, loss_s1: 0.040535, loss_fp: 0.005360, loss_freq: 0.051100
[19:26:59.478] iteration 27362: loss: 0.037546, loss_s1: 0.021854, loss_fp: 0.000736, loss_freq: 0.019266
[19:27:00.107] iteration 27363: loss: 0.062239, loss_s1: 0.062437, loss_fp: 0.009568, loss_freq: 0.015624
[19:27:00.736] iteration 27364: loss: 0.019384, loss_s1: 0.006811, loss_fp: 0.001265, loss_freq: 0.005569
[19:27:01.370] iteration 27365: loss: 0.039553, loss_s1: 0.024302, loss_fp: 0.002065, loss_freq: 0.014451
[19:27:02.009] iteration 27366: loss: 0.038598, loss_s1: 0.027899, loss_fp: 0.001923, loss_freq: 0.006818
[19:27:02.637] iteration 27367: loss: 0.035852, loss_s1: 0.020453, loss_fp: 0.003801, loss_freq: 0.016871
[19:27:03.261] iteration 27368: loss: 0.079999, loss_s1: 0.090855, loss_fp: 0.006381, loss_freq: 0.030876
[19:27:03.886] iteration 27369: loss: 0.058442, loss_s1: 0.051724, loss_fp: 0.008161, loss_freq: 0.019985
[19:27:04.518] iteration 27370: loss: 0.042812, loss_s1: 0.031440, loss_fp: 0.001487, loss_freq: 0.019203
[19:27:05.528] iteration 27371: loss: 0.033629, loss_s1: 0.016525, loss_fp: 0.003608, loss_freq: 0.011156
[19:27:06.158] iteration 27372: loss: 0.070089, loss_s1: 0.069261, loss_fp: 0.015340, loss_freq: 0.025736
[19:27:06.800] iteration 27373: loss: 0.027988, loss_s1: 0.011018, loss_fp: 0.001544, loss_freq: 0.007668
[19:27:07.450] iteration 27374: loss: 0.053063, loss_s1: 0.037912, loss_fp: 0.002074, loss_freq: 0.027280
[19:27:08.080] iteration 27375: loss: 0.052233, loss_s1: 0.052892, loss_fp: 0.002218, loss_freq: 0.017872
[19:27:08.716] iteration 27376: loss: 0.061665, loss_s1: 0.040312, loss_fp: 0.004191, loss_freq: 0.042424
[19:27:09.360] iteration 27377: loss: 0.039652, loss_s1: 0.035354, loss_fp: 0.002900, loss_freq: 0.015413
[19:27:09.994] iteration 27378: loss: 0.038509, loss_s1: 0.022840, loss_fp: 0.003506, loss_freq: 0.026378
[19:27:10.633] iteration 27379: loss: 0.053632, loss_s1: 0.032829, loss_fp: 0.008577, loss_freq: 0.040042
[19:27:11.271] iteration 27380: loss: 0.094998, loss_s1: 0.125343, loss_fp: 0.006445, loss_freq: 0.016792
[19:27:11.904] iteration 27381: loss: 0.024732, loss_s1: 0.003630, loss_fp: 0.004170, loss_freq: 0.005679
[19:27:12.543] iteration 27382: loss: 0.032856, loss_s1: 0.011084, loss_fp: 0.008659, loss_freq: 0.015693
[19:27:13.174] iteration 27383: loss: 0.056226, loss_s1: 0.026022, loss_fp: 0.003892, loss_freq: 0.056984
[19:27:13.804] iteration 27384: loss: 0.058587, loss_s1: 0.062614, loss_fp: 0.005154, loss_freq: 0.015523
[19:27:14.430] iteration 27385: loss: 0.053422, loss_s1: 0.062644, loss_fp: 0.001775, loss_freq: 0.013981
[19:27:15.059] iteration 27386: loss: 0.129887, loss_s1: 0.078105, loss_fp: 0.007559, loss_freq: 0.144990
[19:27:15.688] iteration 27387: loss: 0.036908, loss_s1: 0.022330, loss_fp: 0.001097, loss_freq: 0.009454
[19:27:16.313] iteration 27388: loss: 0.035859, loss_s1: 0.014802, loss_fp: 0.006673, loss_freq: 0.019443
[19:27:16.938] iteration 27389: loss: 0.048789, loss_s1: 0.035950, loss_fp: 0.000824, loss_freq: 0.029874
[19:27:17.566] iteration 27390: loss: 0.049103, loss_s1: 0.040779, loss_fp: 0.002071, loss_freq: 0.025227
[19:27:18.195] iteration 27391: loss: 0.043015, loss_s1: 0.031410, loss_fp: 0.001725, loss_freq: 0.014707
[19:27:18.820] iteration 27392: loss: 0.048901, loss_s1: 0.036004, loss_fp: 0.003931, loss_freq: 0.017104
[19:27:19.446] iteration 27393: loss: 0.035286, loss_s1: 0.030237, loss_fp: 0.001508, loss_freq: 0.002607
[19:27:20.072] iteration 27394: loss: 0.040855, loss_s1: 0.023283, loss_fp: 0.005717, loss_freq: 0.010259
[19:27:20.698] iteration 27395: loss: 0.031162, loss_s1: 0.024317, loss_fp: 0.001200, loss_freq: 0.010053
[19:27:21.322] iteration 27396: loss: 0.041699, loss_s1: 0.035595, loss_fp: 0.001099, loss_freq: 0.023417
[19:27:21.969] iteration 27397: loss: 0.026788, loss_s1: 0.016456, loss_fp: 0.000443, loss_freq: 0.003823
[19:27:22.600] iteration 27398: loss: 0.060679, loss_s1: 0.057093, loss_fp: 0.003122, loss_freq: 0.029871
[19:27:23.226] iteration 27399: loss: 0.028141, loss_s1: 0.016218, loss_fp: 0.003989, loss_freq: 0.009132
[19:27:23.863] iteration 27400: loss: 0.035425, loss_s1: 0.021286, loss_fp: 0.003281, loss_freq: 0.013343
[19:27:27.106] iteration 27400 : mean_dice : 0.730213
[19:27:27.760] iteration 27401: loss: 0.040163, loss_s1: 0.026904, loss_fp: 0.008697, loss_freq: 0.016618
[19:27:28.392] iteration 27402: loss: 0.029331, loss_s1: 0.020370, loss_fp: 0.001044, loss_freq: 0.007843
[19:27:29.016] iteration 27403: loss: 0.032642, loss_s1: 0.028607, loss_fp: 0.002790, loss_freq: 0.008487
[19:27:29.640] iteration 27404: loss: 0.041348, loss_s1: 0.031229, loss_fp: 0.003124, loss_freq: 0.013610
[19:27:30.278] iteration 27405: loss: 0.069457, loss_s1: 0.042054, loss_fp: 0.006586, loss_freq: 0.041875
[19:27:30.913] iteration 27406: loss: 0.077385, loss_s1: 0.068771, loss_fp: 0.002867, loss_freq: 0.057569
[19:27:31.546] iteration 27407: loss: 0.105181, loss_s1: 0.142622, loss_fp: 0.013095, loss_freq: 0.023119
[19:27:32.183] iteration 27408: loss: 0.086527, loss_s1: 0.096139, loss_fp: 0.004549, loss_freq: 0.045269
[19:27:32.820] iteration 27409: loss: 0.068116, loss_s1: 0.042696, loss_fp: 0.004424, loss_freq: 0.047080
[19:27:33.450] iteration 27410: loss: 0.052172, loss_s1: 0.040420, loss_fp: 0.003530, loss_freq: 0.028252
[19:27:34.074] iteration 27411: loss: 0.036388, loss_s1: 0.023841, loss_fp: 0.003183, loss_freq: 0.009767
[19:27:34.707] iteration 27412: loss: 0.066996, loss_s1: 0.062248, loss_fp: 0.004726, loss_freq: 0.040272
[19:27:35.339] iteration 27413: loss: 0.063352, loss_s1: 0.061441, loss_fp: 0.008767, loss_freq: 0.024592
[19:27:35.966] iteration 27414: loss: 0.048606, loss_s1: 0.026004, loss_fp: 0.002318, loss_freq: 0.043601
[19:27:36.598] iteration 27415: loss: 0.087135, loss_s1: 0.070247, loss_fp: 0.006708, loss_freq: 0.060864
[19:27:37.228] iteration 27416: loss: 0.034442, loss_s1: 0.033110, loss_fp: 0.000950, loss_freq: 0.004785
[19:27:37.868] iteration 27417: loss: 0.021240, loss_s1: 0.012518, loss_fp: 0.000282, loss_freq: 0.003136
[19:27:38.501] iteration 27418: loss: 0.047226, loss_s1: 0.042031, loss_fp: 0.002825, loss_freq: 0.017304
[19:27:39.124] iteration 27419: loss: 0.059493, loss_s1: 0.061655, loss_fp: 0.002442, loss_freq: 0.020187
[19:27:39.754] iteration 27420: loss: 0.038753, loss_s1: 0.027230, loss_fp: 0.002497, loss_freq: 0.023302
[19:27:40.380] iteration 27421: loss: 0.051552, loss_s1: 0.040919, loss_fp: 0.005746, loss_freq: 0.025622
[19:27:41.005] iteration 27422: loss: 0.063716, loss_s1: 0.042008, loss_fp: 0.009542, loss_freq: 0.039337
[19:27:41.639] iteration 27423: loss: 0.049897, loss_s1: 0.038747, loss_fp: 0.003855, loss_freq: 0.027843
[19:27:42.263] iteration 27424: loss: 0.046468, loss_s1: 0.026455, loss_fp: 0.003944, loss_freq: 0.033092
[19:27:42.905] iteration 27425: loss: 0.033832, loss_s1: 0.013306, loss_fp: 0.003291, loss_freq: 0.010339
[19:27:43.543] iteration 27426: loss: 0.052245, loss_s1: 0.042804, loss_fp: 0.000756, loss_freq: 0.023362
[19:27:44.169] iteration 27427: loss: 0.039965, loss_s1: 0.032349, loss_fp: 0.004885, loss_freq: 0.004615
[19:27:44.798] iteration 27428: loss: 0.038517, loss_s1: 0.016393, loss_fp: 0.000948, loss_freq: 0.016752
[19:27:45.425] iteration 27429: loss: 0.033781, loss_s1: 0.022702, loss_fp: 0.002442, loss_freq: 0.009751
[19:27:46.049] iteration 27430: loss: 0.028150, loss_s1: 0.010290, loss_fp: 0.001401, loss_freq: 0.020133
[19:27:46.678] iteration 27431: loss: 0.045922, loss_s1: 0.042592, loss_fp: 0.002218, loss_freq: 0.019960
[19:27:47.301] iteration 27432: loss: 0.041742, loss_s1: 0.045326, loss_fp: 0.002089, loss_freq: 0.007161
[19:27:47.930] iteration 27433: loss: 0.039144, loss_s1: 0.014645, loss_fp: 0.001303, loss_freq: 0.025548
[19:27:48.559] iteration 27434: loss: 0.037400, loss_s1: 0.020939, loss_fp: 0.001753, loss_freq: 0.017684
[19:27:49.183] iteration 27435: loss: 0.055354, loss_s1: 0.055419, loss_fp: 0.001164, loss_freq: 0.021553
[19:27:49.812] iteration 27436: loss: 0.059097, loss_s1: 0.033497, loss_fp: 0.000609, loss_freq: 0.056580
[19:27:50.436] iteration 27437: loss: 0.040732, loss_s1: 0.039918, loss_fp: 0.001266, loss_freq: 0.012026
[19:27:51.058] iteration 27438: loss: 0.068399, loss_s1: 0.076084, loss_fp: 0.006452, loss_freq: 0.021758
[19:27:51.682] iteration 27439: loss: 0.052462, loss_s1: 0.058397, loss_fp: 0.003060, loss_freq: 0.016524
[19:27:52.309] iteration 27440: loss: 0.041366, loss_s1: 0.007345, loss_fp: 0.000717, loss_freq: 0.027150
[19:27:52.933] iteration 27441: loss: 0.052183, loss_s1: 0.029487, loss_fp: 0.015416, loss_freq: 0.032970
[19:27:53.563] iteration 27442: loss: 0.044559, loss_s1: 0.039422, loss_fp: 0.002516, loss_freq: 0.018532
[19:27:54.188] iteration 27443: loss: 0.063221, loss_s1: 0.065362, loss_fp: 0.004426, loss_freq: 0.024917
[19:27:54.816] iteration 27444: loss: 0.059613, loss_s1: 0.068859, loss_fp: 0.001637, loss_freq: 0.009739
[19:27:55.444] iteration 27445: loss: 0.056433, loss_s1: 0.044157, loss_fp: 0.009986, loss_freq: 0.024525
[19:27:56.066] iteration 27446: loss: 0.085352, loss_s1: 0.106390, loss_fp: 0.021464, loss_freq: 0.005441
[19:27:56.690] iteration 27447: loss: 0.039685, loss_s1: 0.033555, loss_fp: 0.004083, loss_freq: 0.015274
[19:27:57.314] iteration 27448: loss: 0.030789, loss_s1: 0.008927, loss_fp: 0.003508, loss_freq: 0.016066
[19:27:57.942] iteration 27449: loss: 0.026030, loss_s1: 0.020965, loss_fp: 0.004268, loss_freq: 0.003230
[19:27:58.570] iteration 27450: loss: 0.050739, loss_s1: 0.033082, loss_fp: 0.002645, loss_freq: 0.031612
[19:27:59.194] iteration 27451: loss: 0.080651, loss_s1: 0.087763, loss_fp: 0.004224, loss_freq: 0.023493
[19:27:59.820] iteration 27452: loss: 0.056795, loss_s1: 0.044090, loss_fp: 0.002944, loss_freq: 0.032091
[19:28:00.448] iteration 27453: loss: 0.058966, loss_s1: 0.065779, loss_fp: 0.007957, loss_freq: 0.021334
[19:28:01.071] iteration 27454: loss: 0.052886, loss_s1: 0.034383, loss_fp: 0.005031, loss_freq: 0.036755
[19:28:01.692] iteration 27455: loss: 0.067847, loss_s1: 0.065055, loss_fp: 0.004925, loss_freq: 0.043973
[19:28:02.315] iteration 27456: loss: 0.040364, loss_s1: 0.013562, loss_fp: 0.003048, loss_freq: 0.031916
[19:28:02.940] iteration 27457: loss: 0.040305, loss_s1: 0.033367, loss_fp: 0.003500, loss_freq: 0.008438
[19:28:03.567] iteration 27458: loss: 0.046635, loss_s1: 0.046865, loss_fp: 0.003622, loss_freq: 0.008344
[19:28:04.195] iteration 27459: loss: 0.056842, loss_s1: 0.061966, loss_fp: 0.009818, loss_freq: 0.011580
[19:28:04.821] iteration 27460: loss: 0.047490, loss_s1: 0.028973, loss_fp: 0.008970, loss_freq: 0.025785
[19:28:05.452] iteration 27461: loss: 0.063787, loss_s1: 0.041891, loss_fp: 0.012276, loss_freq: 0.030541
[19:28:06.079] iteration 27462: loss: 0.058895, loss_s1: 0.049737, loss_fp: 0.002548, loss_freq: 0.028071
[19:28:06.702] iteration 27463: loss: 0.045433, loss_s1: 0.024818, loss_fp: 0.002137, loss_freq: 0.018774
[19:28:07.343] iteration 27464: loss: 0.034811, loss_s1: 0.030635, loss_fp: 0.001219, loss_freq: 0.011071
[19:28:07.991] iteration 27465: loss: 0.061116, loss_s1: 0.054803, loss_fp: 0.001013, loss_freq: 0.041364
[19:28:08.616] iteration 27466: loss: 0.051700, loss_s1: 0.034943, loss_fp: 0.004899, loss_freq: 0.027549
[19:28:09.240] iteration 27467: loss: 0.028807, loss_s1: 0.015355, loss_fp: 0.000653, loss_freq: 0.014973
[19:28:09.862] iteration 27468: loss: 0.035357, loss_s1: 0.012252, loss_fp: 0.004214, loss_freq: 0.011487
[19:28:10.493] iteration 27469: loss: 0.024393, loss_s1: 0.010311, loss_fp: 0.004050, loss_freq: 0.009045
[19:28:11.123] iteration 27470: loss: 0.044483, loss_s1: 0.041961, loss_fp: 0.005523, loss_freq: 0.012050
[19:28:11.747] iteration 27471: loss: 0.051372, loss_s1: 0.059857, loss_fp: 0.004007, loss_freq: 0.013063
[19:28:12.398] iteration 27472: loss: 0.065939, loss_s1: 0.043635, loss_fp: 0.012191, loss_freq: 0.038879
[19:28:13.037] iteration 27473: loss: 0.045410, loss_s1: 0.034413, loss_fp: 0.009728, loss_freq: 0.021948
[19:28:13.669] iteration 27474: loss: 0.046983, loss_s1: 0.052554, loss_fp: 0.002067, loss_freq: 0.007077
[19:28:14.309] iteration 27475: loss: 0.050152, loss_s1: 0.027416, loss_fp: 0.002408, loss_freq: 0.013026
[19:28:14.992] iteration 27476: loss: 0.044258, loss_s1: 0.024015, loss_fp: 0.008511, loss_freq: 0.023127
[19:28:15.627] iteration 27477: loss: 0.032232, loss_s1: 0.004603, loss_fp: 0.000541, loss_freq: 0.006016
[19:28:16.268] iteration 27478: loss: 0.045115, loss_s1: 0.041850, loss_fp: 0.003075, loss_freq: 0.015569
[19:28:16.904] iteration 27479: loss: 0.083775, loss_s1: 0.063388, loss_fp: 0.011892, loss_freq: 0.053898
[19:28:17.541] iteration 27480: loss: 0.049267, loss_s1: 0.034782, loss_fp: 0.001386, loss_freq: 0.017041
[19:28:18.180] iteration 27481: loss: 0.040288, loss_s1: 0.020983, loss_fp: 0.006294, loss_freq: 0.006619
[19:28:18.808] iteration 27482: loss: 0.066508, loss_s1: 0.073609, loss_fp: 0.003558, loss_freq: 0.022674
[19:28:19.432] iteration 27483: loss: 0.049960, loss_s1: 0.057076, loss_fp: 0.006912, loss_freq: 0.008211
[19:28:20.058] iteration 27484: loss: 0.035224, loss_s1: 0.020885, loss_fp: 0.006658, loss_freq: 0.012568
[19:28:20.683] iteration 27485: loss: 0.075186, loss_s1: 0.092070, loss_fp: 0.003986, loss_freq: 0.021251
[19:28:21.320] iteration 27486: loss: 0.060794, loss_s1: 0.041606, loss_fp: 0.006754, loss_freq: 0.030373
[19:28:21.947] iteration 27487: loss: 0.052969, loss_s1: 0.011702, loss_fp: 0.004267, loss_freq: 0.057324
[19:28:22.579] iteration 27488: loss: 0.060103, loss_s1: 0.061546, loss_fp: 0.003377, loss_freq: 0.030253
[19:28:23.214] iteration 27489: loss: 0.065899, loss_s1: 0.051338, loss_fp: 0.012577, loss_freq: 0.023061
[19:28:23.847] iteration 27490: loss: 0.133079, loss_s1: 0.100096, loss_fp: 0.003540, loss_freq: 0.133162
[19:28:24.481] iteration 27491: loss: 0.043457, loss_s1: 0.034308, loss_fp: 0.009221, loss_freq: 0.011741
[19:28:25.129] iteration 27492: loss: 0.053396, loss_s1: 0.030334, loss_fp: 0.001999, loss_freq: 0.030352
[19:28:25.769] iteration 27493: loss: 0.049487, loss_s1: 0.039363, loss_fp: 0.003476, loss_freq: 0.019749
[19:28:26.410] iteration 27494: loss: 0.048339, loss_s1: 0.044389, loss_fp: 0.001997, loss_freq: 0.018789
[19:28:27.045] iteration 27495: loss: 0.039272, loss_s1: 0.022594, loss_fp: 0.004642, loss_freq: 0.014094
[19:28:27.680] iteration 27496: loss: 0.062372, loss_s1: 0.034432, loss_fp: 0.003228, loss_freq: 0.044824
[19:28:28.310] iteration 27497: loss: 0.064436, loss_s1: 0.055942, loss_fp: 0.007965, loss_freq: 0.010509
[19:28:28.934] iteration 27498: loss: 0.113452, loss_s1: 0.117336, loss_fp: 0.005741, loss_freq: 0.067798
[19:28:29.568] iteration 27499: loss: 0.088147, loss_s1: 0.074977, loss_fp: 0.006178, loss_freq: 0.064669
[19:28:30.202] iteration 27500: loss: 0.059774, loss_s1: 0.065203, loss_fp: 0.002478, loss_freq: 0.025185
[19:28:30.831] iteration 27501: loss: 0.041199, loss_s1: 0.033801, loss_fp: 0.003085, loss_freq: 0.020398
[19:28:31.455] iteration 27502: loss: 0.059413, loss_s1: 0.063460, loss_fp: 0.000861, loss_freq: 0.023281
[19:28:32.081] iteration 27503: loss: 0.061589, loss_s1: 0.049816, loss_fp: 0.006883, loss_freq: 0.027086
[19:28:32.707] iteration 27504: loss: 0.041630, loss_s1: 0.034407, loss_fp: 0.001370, loss_freq: 0.009754
[19:28:33.332] iteration 27505: loss: 0.063991, loss_s1: 0.043441, loss_fp: 0.002518, loss_freq: 0.048355
[19:28:33.957] iteration 27506: loss: 0.049436, loss_s1: 0.044602, loss_fp: 0.004776, loss_freq: 0.020435
[19:28:34.586] iteration 27507: loss: 0.038881, loss_s1: 0.027291, loss_fp: 0.002632, loss_freq: 0.010076
[19:28:35.213] iteration 27508: loss: 0.052135, loss_s1: 0.062378, loss_fp: 0.002434, loss_freq: 0.015535
[19:28:35.850] iteration 27509: loss: 0.041742, loss_s1: 0.044884, loss_fp: 0.002833, loss_freq: 0.008530
[19:28:36.476] iteration 27510: loss: 0.055092, loss_s1: 0.035807, loss_fp: 0.003901, loss_freq: 0.016788
[19:28:37.101] iteration 27511: loss: 0.043727, loss_s1: 0.037526, loss_fp: 0.000705, loss_freq: 0.018934
[19:28:37.730] iteration 27512: loss: 0.040361, loss_s1: 0.034582, loss_fp: 0.001119, loss_freq: 0.010498
[19:28:38.358] iteration 27513: loss: 0.052082, loss_s1: 0.035595, loss_fp: 0.006360, loss_freq: 0.030140
[19:28:38.983] iteration 27514: loss: 0.049739, loss_s1: 0.022188, loss_fp: 0.006202, loss_freq: 0.029018
[19:28:39.606] iteration 27515: loss: 0.038712, loss_s1: 0.020763, loss_fp: 0.003913, loss_freq: 0.013206
[19:28:40.230] iteration 27516: loss: 0.063362, loss_s1: 0.052561, loss_fp: 0.009819, loss_freq: 0.030672
[19:28:40.855] iteration 27517: loss: 0.073974, loss_s1: 0.037392, loss_fp: 0.003416, loss_freq: 0.073820
[19:28:41.484] iteration 27518: loss: 0.030756, loss_s1: 0.026223, loss_fp: 0.003147, loss_freq: 0.005383
[19:28:42.115] iteration 27519: loss: 0.029481, loss_s1: 0.012882, loss_fp: 0.002178, loss_freq: 0.008988
[19:28:42.744] iteration 27520: loss: 0.094354, loss_s1: 0.105813, loss_fp: 0.004117, loss_freq: 0.041961
[19:28:43.376] iteration 27521: loss: 0.052447, loss_s1: 0.030512, loss_fp: 0.013450, loss_freq: 0.026270
[19:28:44.004] iteration 27522: loss: 0.062388, loss_s1: 0.021690, loss_fp: 0.005780, loss_freq: 0.064309
[19:28:44.633] iteration 27523: loss: 0.030937, loss_s1: 0.024346, loss_fp: 0.006274, loss_freq: 0.008186
[19:28:45.257] iteration 27524: loss: 0.056268, loss_s1: 0.061583, loss_fp: 0.005767, loss_freq: 0.015670
[19:28:45.888] iteration 27525: loss: 0.030912, loss_s1: 0.019308, loss_fp: 0.002232, loss_freq: 0.016529
[19:28:46.520] iteration 27526: loss: 0.043264, loss_s1: 0.032903, loss_fp: 0.000892, loss_freq: 0.013622
[19:28:47.158] iteration 27527: loss: 0.026571, loss_s1: 0.007109, loss_fp: 0.000916, loss_freq: 0.006538
[19:28:47.793] iteration 27528: loss: 0.065092, loss_s1: 0.054044, loss_fp: 0.005537, loss_freq: 0.036040
[19:28:48.425] iteration 27529: loss: 0.055196, loss_s1: 0.047523, loss_fp: 0.006096, loss_freq: 0.022221
[19:28:49.056] iteration 27530: loss: 0.050838, loss_s1: 0.037191, loss_fp: 0.007929, loss_freq: 0.026400
[19:28:49.690] iteration 27531: loss: 0.049131, loss_s1: 0.029944, loss_fp: 0.001863, loss_freq: 0.032619
[19:28:50.615] iteration 27532: loss: 0.035412, loss_s1: 0.030963, loss_fp: 0.001176, loss_freq: 0.009420
[19:28:51.272] iteration 27533: loss: 0.052608, loss_s1: 0.033722, loss_fp: 0.007175, loss_freq: 0.022542
[19:28:51.896] iteration 27534: loss: 0.038785, loss_s1: 0.019700, loss_fp: 0.002772, loss_freq: 0.013042
[19:28:52.526] iteration 27535: loss: 0.040618, loss_s1: 0.021931, loss_fp: 0.011523, loss_freq: 0.014229
[19:28:53.150] iteration 27536: loss: 0.042683, loss_s1: 0.024933, loss_fp: 0.005459, loss_freq: 0.025172
[19:28:53.777] iteration 27537: loss: 0.084558, loss_s1: 0.057665, loss_fp: 0.009579, loss_freq: 0.050713
[19:28:54.401] iteration 27538: loss: 0.041365, loss_s1: 0.023527, loss_fp: 0.009581, loss_freq: 0.020183
[19:28:55.023] iteration 27539: loss: 0.030889, loss_s1: 0.015828, loss_fp: 0.004963, loss_freq: 0.013389
[19:28:55.650] iteration 27540: loss: 0.076982, loss_s1: 0.066569, loss_fp: 0.004237, loss_freq: 0.054164
[19:28:56.275] iteration 27541: loss: 0.045504, loss_s1: 0.041846, loss_fp: 0.004419, loss_freq: 0.012995
[19:28:56.916] iteration 27542: loss: 0.035038, loss_s1: 0.029873, loss_fp: 0.001734, loss_freq: 0.007266
[19:28:57.553] iteration 27543: loss: 0.049793, loss_s1: 0.016816, loss_fp: 0.007343, loss_freq: 0.025937
[19:28:58.180] iteration 27544: loss: 0.047371, loss_s1: 0.021325, loss_fp: 0.005167, loss_freq: 0.042089
[19:28:58.805] iteration 27545: loss: 0.061944, loss_s1: 0.041698, loss_fp: 0.005125, loss_freq: 0.027084
[19:28:59.430] iteration 27546: loss: 0.070109, loss_s1: 0.066839, loss_fp: 0.018333, loss_freq: 0.031667
[19:29:00.054] iteration 27547: loss: 0.059196, loss_s1: 0.035125, loss_fp: 0.004885, loss_freq: 0.032713
[19:29:00.679] iteration 27548: loss: 0.060008, loss_s1: 0.057294, loss_fp: 0.009903, loss_freq: 0.022016
[19:29:01.308] iteration 27549: loss: 0.061824, loss_s1: 0.047383, loss_fp: 0.003402, loss_freq: 0.030331
[19:29:01.959] iteration 27550: loss: 0.039548, loss_s1: 0.016150, loss_fp: 0.003847, loss_freq: 0.019241
[19:29:02.589] iteration 27551: loss: 0.038326, loss_s1: 0.015672, loss_fp: 0.006927, loss_freq: 0.024620
[19:29:03.219] iteration 27552: loss: 0.031274, loss_s1: 0.010210, loss_fp: 0.000490, loss_freq: 0.016860
[19:29:03.841] iteration 27553: loss: 0.044049, loss_s1: 0.033762, loss_fp: 0.002414, loss_freq: 0.015685
[19:29:04.468] iteration 27554: loss: 0.059226, loss_s1: 0.026938, loss_fp: 0.011177, loss_freq: 0.036761
[19:29:05.099] iteration 27555: loss: 0.033787, loss_s1: 0.011980, loss_fp: 0.002792, loss_freq: 0.024476
[19:29:05.736] iteration 27556: loss: 0.047140, loss_s1: 0.040346, loss_fp: 0.005197, loss_freq: 0.021949
[19:29:06.357] iteration 27557: loss: 0.050964, loss_s1: 0.046942, loss_fp: 0.002424, loss_freq: 0.018343
[19:29:06.991] iteration 27558: loss: 0.025781, loss_s1: 0.013453, loss_fp: 0.001147, loss_freq: 0.003790
[19:29:07.621] iteration 27559: loss: 0.078016, loss_s1: 0.077231, loss_fp: 0.013676, loss_freq: 0.027985
[19:29:08.249] iteration 27560: loss: 0.065056, loss_s1: 0.036560, loss_fp: 0.011465, loss_freq: 0.054221
[19:29:08.879] iteration 27561: loss: 0.036665, loss_s1: 0.021935, loss_fp: 0.006253, loss_freq: 0.010941
[19:29:09.507] iteration 27562: loss: 0.048229, loss_s1: 0.042562, loss_fp: 0.009568, loss_freq: 0.020672
[19:29:10.135] iteration 27563: loss: 0.051342, loss_s1: 0.048738, loss_fp: 0.003868, loss_freq: 0.016701
[19:29:10.764] iteration 27564: loss: 0.049724, loss_s1: 0.044144, loss_fp: 0.004260, loss_freq: 0.027449
[19:29:11.389] iteration 27565: loss: 0.038996, loss_s1: 0.032768, loss_fp: 0.002789, loss_freq: 0.009592
[19:29:12.013] iteration 27566: loss: 0.042757, loss_s1: 0.025935, loss_fp: 0.003171, loss_freq: 0.021846
[19:29:12.644] iteration 27567: loss: 0.069175, loss_s1: 0.046798, loss_fp: 0.011269, loss_freq: 0.035118
[19:29:13.283] iteration 27568: loss: 0.090694, loss_s1: 0.109448, loss_fp: 0.003400, loss_freq: 0.038904
[19:29:13.922] iteration 27569: loss: 0.055914, loss_s1: 0.041210, loss_fp: 0.009798, loss_freq: 0.029497
[19:29:14.558] iteration 27570: loss: 0.064616, loss_s1: 0.061915, loss_fp: 0.006313, loss_freq: 0.027830
[19:29:15.196] iteration 27571: loss: 0.045113, loss_s1: 0.033561, loss_fp: 0.004712, loss_freq: 0.018570
[19:29:15.824] iteration 27572: loss: 0.059047, loss_s1: 0.048888, loss_fp: 0.007795, loss_freq: 0.020726
[19:29:16.451] iteration 27573: loss: 0.087893, loss_s1: 0.075203, loss_fp: 0.009235, loss_freq: 0.065770
[19:29:17.074] iteration 27574: loss: 0.057824, loss_s1: 0.051416, loss_fp: 0.006413, loss_freq: 0.030911
[19:29:17.709] iteration 27575: loss: 0.037335, loss_s1: 0.012512, loss_fp: 0.004565, loss_freq: 0.033005
[19:29:18.339] iteration 27576: loss: 0.040553, loss_s1: 0.029125, loss_fp: 0.003923, loss_freq: 0.013259
[19:29:18.968] iteration 27577: loss: 0.041285, loss_s1: 0.037277, loss_fp: 0.001900, loss_freq: 0.014972
[19:29:19.596] iteration 27578: loss: 0.028808, loss_s1: 0.014476, loss_fp: 0.001332, loss_freq: 0.016539
[19:29:20.222] iteration 27579: loss: 0.026427, loss_s1: 0.014815, loss_fp: 0.002737, loss_freq: 0.009897
[19:29:20.848] iteration 27580: loss: 0.042482, loss_s1: 0.023179, loss_fp: 0.004001, loss_freq: 0.009971
[19:29:21.474] iteration 27581: loss: 0.045201, loss_s1: 0.035901, loss_fp: 0.001801, loss_freq: 0.021905
[19:29:22.100] iteration 27582: loss: 0.050008, loss_s1: 0.042446, loss_fp: 0.001333, loss_freq: 0.027846
[19:29:22.732] iteration 27583: loss: 0.036717, loss_s1: 0.018652, loss_fp: 0.003662, loss_freq: 0.020520
[19:29:23.362] iteration 27584: loss: 0.058532, loss_s1: 0.036908, loss_fp: 0.003358, loss_freq: 0.042148
[19:29:23.993] iteration 27585: loss: 0.059572, loss_s1: 0.055511, loss_fp: 0.002797, loss_freq: 0.030930
[19:29:24.622] iteration 27586: loss: 0.045110, loss_s1: 0.040793, loss_fp: 0.002268, loss_freq: 0.011832
[19:29:25.244] iteration 27587: loss: 0.047945, loss_s1: 0.028662, loss_fp: 0.001289, loss_freq: 0.031611
[19:29:25.871] iteration 27588: loss: 0.027970, loss_s1: 0.009395, loss_fp: 0.002151, loss_freq: 0.004538
[19:29:26.495] iteration 27589: loss: 0.054779, loss_s1: 0.048414, loss_fp: 0.001313, loss_freq: 0.011211
[19:29:27.127] iteration 27590: loss: 0.038882, loss_s1: 0.032788, loss_fp: 0.002992, loss_freq: 0.014844
[19:29:27.817] iteration 27591: loss: 0.051501, loss_s1: 0.037666, loss_fp: 0.012422, loss_freq: 0.029146
[19:29:28.462] iteration 27592: loss: 0.041652, loss_s1: 0.035795, loss_fp: 0.003213, loss_freq: 0.015447
[19:29:29.087] iteration 27593: loss: 0.034827, loss_s1: 0.016690, loss_fp: 0.002917, loss_freq: 0.021345
[19:29:29.724] iteration 27594: loss: 0.036665, loss_s1: 0.023046, loss_fp: 0.001125, loss_freq: 0.014790
[19:29:30.357] iteration 27595: loss: 0.042982, loss_s1: 0.029580, loss_fp: 0.007946, loss_freq: 0.015868
[19:29:30.986] iteration 27596: loss: 0.038671, loss_s1: 0.018527, loss_fp: 0.005617, loss_freq: 0.015731
[19:29:31.607] iteration 27597: loss: 0.051422, loss_s1: 0.031925, loss_fp: 0.001400, loss_freq: 0.040179
[19:29:32.238] iteration 27598: loss: 0.040434, loss_s1: 0.017863, loss_fp: 0.002598, loss_freq: 0.029185
[19:29:32.864] iteration 27599: loss: 0.062167, loss_s1: 0.045723, loss_fp: 0.009605, loss_freq: 0.039930
[19:29:33.491] iteration 27600: loss: 0.037020, loss_s1: 0.027493, loss_fp: 0.007130, loss_freq: 0.013241
[19:29:36.631] iteration 27600 : mean_dice : 0.733117
[19:29:37.267] iteration 27601: loss: 0.065014, loss_s1: 0.044130, loss_fp: 0.001826, loss_freq: 0.048234
[19:29:37.892] iteration 27602: loss: 0.080793, loss_s1: 0.071796, loss_fp: 0.006150, loss_freq: 0.043545
[19:29:38.519] iteration 27603: loss: 0.049020, loss_s1: 0.044009, loss_fp: 0.001667, loss_freq: 0.019810
[19:29:39.147] iteration 27604: loss: 0.037396, loss_s1: 0.020800, loss_fp: 0.002410, loss_freq: 0.018861
[19:29:39.769] iteration 27605: loss: 0.047859, loss_s1: 0.030566, loss_fp: 0.002325, loss_freq: 0.018451
[19:29:40.393] iteration 27606: loss: 0.072621, loss_s1: 0.087273, loss_fp: 0.010476, loss_freq: 0.020431
[19:29:41.020] iteration 27607: loss: 0.063209, loss_s1: 0.076030, loss_fp: 0.000351, loss_freq: 0.002331
[19:29:41.650] iteration 27608: loss: 0.035195, loss_s1: 0.031274, loss_fp: 0.001702, loss_freq: 0.012392
[19:29:42.281] iteration 27609: loss: 0.035035, loss_s1: 0.024251, loss_fp: 0.000471, loss_freq: 0.013145
[19:29:42.913] iteration 27610: loss: 0.036250, loss_s1: 0.038933, loss_fp: 0.003093, loss_freq: 0.008884
[19:29:43.535] iteration 27611: loss: 0.054920, loss_s1: 0.046936, loss_fp: 0.002072, loss_freq: 0.023222
[19:29:44.165] iteration 27612: loss: 0.057770, loss_s1: 0.051218, loss_fp: 0.004093, loss_freq: 0.027018
[19:29:44.786] iteration 27613: loss: 0.043331, loss_s1: 0.036570, loss_fp: 0.002429, loss_freq: 0.023644
[19:29:45.409] iteration 27614: loss: 0.060108, loss_s1: 0.054194, loss_fp: 0.006962, loss_freq: 0.034535
[19:29:46.036] iteration 27615: loss: 0.051207, loss_s1: 0.035004, loss_fp: 0.002251, loss_freq: 0.020613
[19:29:46.662] iteration 27616: loss: 0.064691, loss_s1: 0.044456, loss_fp: 0.021410, loss_freq: 0.037910
[19:29:47.289] iteration 27617: loss: 0.038227, loss_s1: 0.017726, loss_fp: 0.004765, loss_freq: 0.012753
[19:29:47.915] iteration 27618: loss: 0.047163, loss_s1: 0.027124, loss_fp: 0.011870, loss_freq: 0.019683
[19:29:48.542] iteration 27619: loss: 0.041573, loss_s1: 0.040076, loss_fp: 0.003400, loss_freq: 0.010092
[19:29:49.181] iteration 27620: loss: 0.049277, loss_s1: 0.044183, loss_fp: 0.003388, loss_freq: 0.011759
[19:29:49.830] iteration 27621: loss: 0.072419, loss_s1: 0.057040, loss_fp: 0.002630, loss_freq: 0.054816
[19:29:50.480] iteration 27622: loss: 0.056264, loss_s1: 0.043483, loss_fp: 0.007540, loss_freq: 0.015592
[19:29:51.120] iteration 27623: loss: 0.061723, loss_s1: 0.027842, loss_fp: 0.009192, loss_freq: 0.044888
[19:29:51.744] iteration 27624: loss: 0.043084, loss_s1: 0.026319, loss_fp: 0.003110, loss_freq: 0.017577
[19:29:52.366] iteration 27625: loss: 0.043572, loss_s1: 0.051701, loss_fp: 0.001384, loss_freq: 0.004468
[19:29:52.993] iteration 27626: loss: 0.062329, loss_s1: 0.043814, loss_fp: 0.003785, loss_freq: 0.049614
[19:29:53.618] iteration 27627: loss: 0.048301, loss_s1: 0.047840, loss_fp: 0.004021, loss_freq: 0.022799
[19:29:54.243] iteration 27628: loss: 0.042637, loss_s1: 0.023938, loss_fp: 0.003678, loss_freq: 0.020827
[19:29:54.872] iteration 27629: loss: 0.041518, loss_s1: 0.019861, loss_fp: 0.002158, loss_freq: 0.026670
[19:29:55.495] iteration 27630: loss: 0.025106, loss_s1: 0.011756, loss_fp: 0.001756, loss_freq: 0.010531
[19:29:56.117] iteration 27631: loss: 0.050334, loss_s1: 0.053532, loss_fp: 0.003135, loss_freq: 0.014328
[19:29:56.736] iteration 27632: loss: 0.037682, loss_s1: 0.026591, loss_fp: 0.007705, loss_freq: 0.011183
[19:29:57.360] iteration 27633: loss: 0.074199, loss_s1: 0.058122, loss_fp: 0.005158, loss_freq: 0.048296
[19:29:57.984] iteration 27634: loss: 0.092519, loss_s1: 0.076098, loss_fp: 0.004883, loss_freq: 0.077925
[19:29:58.607] iteration 27635: loss: 0.041081, loss_s1: 0.032897, loss_fp: 0.003328, loss_freq: 0.020183
[19:29:59.233] iteration 27636: loss: 0.063219, loss_s1: 0.066089, loss_fp: 0.001888, loss_freq: 0.016990
[19:29:59.860] iteration 27637: loss: 0.032921, loss_s1: 0.024369, loss_fp: 0.001120, loss_freq: 0.013421
[19:30:00.489] iteration 27638: loss: 0.029035, loss_s1: 0.022395, loss_fp: 0.002145, loss_freq: 0.003838
[19:30:01.172] iteration 27639: loss: 0.071994, loss_s1: 0.082056, loss_fp: 0.008656, loss_freq: 0.014815
[19:30:01.811] iteration 27640: loss: 0.070095, loss_s1: 0.054790, loss_fp: 0.000775, loss_freq: 0.044250
[19:30:02.460] iteration 27641: loss: 0.050356, loss_s1: 0.037088, loss_fp: 0.000989, loss_freq: 0.033869
[19:30:03.098] iteration 27642: loss: 0.048689, loss_s1: 0.038680, loss_fp: 0.005051, loss_freq: 0.019750
[19:30:03.728] iteration 27643: loss: 0.052942, loss_s1: 0.029973, loss_fp: 0.003674, loss_freq: 0.042920
[19:30:04.357] iteration 27644: loss: 0.051311, loss_s1: 0.046791, loss_fp: 0.001791, loss_freq: 0.010159
[19:30:04.989] iteration 27645: loss: 0.045275, loss_s1: 0.035362, loss_fp: 0.005406, loss_freq: 0.025561
[19:30:05.619] iteration 27646: loss: 0.043102, loss_s1: 0.029127, loss_fp: 0.002324, loss_freq: 0.021032
[19:30:06.255] iteration 27647: loss: 0.045769, loss_s1: 0.023615, loss_fp: 0.006203, loss_freq: 0.028972
[19:30:06.884] iteration 27648: loss: 0.038985, loss_s1: 0.045916, loss_fp: 0.000639, loss_freq: 0.007453
[19:30:07.510] iteration 27649: loss: 0.031384, loss_s1: 0.023275, loss_fp: 0.002092, loss_freq: 0.012881
[19:30:08.142] iteration 27650: loss: 0.051280, loss_s1: 0.045571, loss_fp: 0.002908, loss_freq: 0.027136
[19:30:08.772] iteration 27651: loss: 0.119143, loss_s1: 0.077585, loss_fp: 0.002573, loss_freq: 0.126977
[19:30:09.404] iteration 27652: loss: 0.028613, loss_s1: 0.009139, loss_fp: 0.014297, loss_freq: 0.005834
[19:30:10.042] iteration 27653: loss: 0.047649, loss_s1: 0.030349, loss_fp: 0.002219, loss_freq: 0.029280
[19:30:10.679] iteration 27654: loss: 0.063994, loss_s1: 0.026035, loss_fp: 0.007140, loss_freq: 0.062488
[19:30:11.310] iteration 27655: loss: 0.040273, loss_s1: 0.018257, loss_fp: 0.002045, loss_freq: 0.012368
[19:30:11.952] iteration 27656: loss: 0.057315, loss_s1: 0.028981, loss_fp: 0.006688, loss_freq: 0.042309
[19:30:12.587] iteration 27657: loss: 0.040622, loss_s1: 0.028987, loss_fp: 0.002385, loss_freq: 0.017862
[19:30:13.220] iteration 27658: loss: 0.057377, loss_s1: 0.068187, loss_fp: 0.003208, loss_freq: 0.009706
[19:30:13.852] iteration 27659: loss: 0.031568, loss_s1: 0.008686, loss_fp: 0.000794, loss_freq: 0.015670
[19:30:14.481] iteration 27660: loss: 0.054895, loss_s1: 0.041268, loss_fp: 0.002351, loss_freq: 0.037331
[19:30:15.105] iteration 27661: loss: 0.060406, loss_s1: 0.064742, loss_fp: 0.005940, loss_freq: 0.022917
[19:30:15.733] iteration 27662: loss: 0.056236, loss_s1: 0.046595, loss_fp: 0.003117, loss_freq: 0.023664
[19:30:16.358] iteration 27663: loss: 0.055386, loss_s1: 0.052839, loss_fp: 0.010927, loss_freq: 0.018684
[19:30:16.989] iteration 27664: loss: 0.048623, loss_s1: 0.038446, loss_fp: 0.003147, loss_freq: 0.018524
[19:30:17.615] iteration 27665: loss: 0.044590, loss_s1: 0.013303, loss_fp: 0.009064, loss_freq: 0.011533
[19:30:18.245] iteration 27666: loss: 0.046902, loss_s1: 0.039589, loss_fp: 0.001164, loss_freq: 0.015793
[19:30:18.873] iteration 27667: loss: 0.051558, loss_s1: 0.041536, loss_fp: 0.007863, loss_freq: 0.022361
[19:30:19.498] iteration 27668: loss: 0.036498, loss_s1: 0.020419, loss_fp: 0.001863, loss_freq: 0.014254
[19:30:20.125] iteration 27669: loss: 0.034450, loss_s1: 0.033901, loss_fp: 0.001541, loss_freq: 0.008114
[19:30:20.751] iteration 27670: loss: 0.041325, loss_s1: 0.025941, loss_fp: 0.001687, loss_freq: 0.021284
[19:30:21.377] iteration 27671: loss: 0.058916, loss_s1: 0.054716, loss_fp: 0.005510, loss_freq: 0.012781
[19:30:22.000] iteration 27672: loss: 0.075573, loss_s1: 0.095552, loss_fp: 0.002453, loss_freq: 0.025078
[19:30:22.632] iteration 27673: loss: 0.057764, loss_s1: 0.033167, loss_fp: 0.006543, loss_freq: 0.047359
[19:30:23.261] iteration 27674: loss: 0.057655, loss_s1: 0.053737, loss_fp: 0.001341, loss_freq: 0.034224
[19:30:23.891] iteration 27675: loss: 0.047333, loss_s1: 0.041128, loss_fp: 0.002856, loss_freq: 0.013630
[19:30:24.520] iteration 27676: loss: 0.043444, loss_s1: 0.040849, loss_fp: 0.000832, loss_freq: 0.003785
[19:30:25.144] iteration 27677: loss: 0.050678, loss_s1: 0.023859, loss_fp: 0.003104, loss_freq: 0.029256
[19:30:25.769] iteration 27678: loss: 0.068559, loss_s1: 0.067093, loss_fp: 0.004052, loss_freq: 0.042622
[19:30:26.394] iteration 27679: loss: 0.041670, loss_s1: 0.043387, loss_fp: 0.002234, loss_freq: 0.008056
[19:30:27.023] iteration 27680: loss: 0.045692, loss_s1: 0.024783, loss_fp: 0.005903, loss_freq: 0.010187
[19:30:27.647] iteration 27681: loss: 0.089214, loss_s1: 0.078650, loss_fp: 0.001896, loss_freq: 0.061487
[19:30:28.270] iteration 27682: loss: 0.032980, loss_s1: 0.017044, loss_fp: 0.001615, loss_freq: 0.014933
[19:30:28.899] iteration 27683: loss: 0.071375, loss_s1: 0.043372, loss_fp: 0.006134, loss_freq: 0.064740
[19:30:29.526] iteration 27684: loss: 0.044235, loss_s1: 0.036406, loss_fp: 0.003421, loss_freq: 0.019688
[19:30:30.147] iteration 27685: loss: 0.046326, loss_s1: 0.032408, loss_fp: 0.006203, loss_freq: 0.021662
[19:30:30.769] iteration 27686: loss: 0.036656, loss_s1: 0.023016, loss_fp: 0.006321, loss_freq: 0.013320
[19:30:31.397] iteration 27687: loss: 0.033235, loss_s1: 0.021534, loss_fp: 0.001623, loss_freq: 0.007866
[19:30:32.020] iteration 27688: loss: 0.027713, loss_s1: 0.016148, loss_fp: 0.001419, loss_freq: 0.008046
[19:30:32.646] iteration 27689: loss: 0.038984, loss_s1: 0.022539, loss_fp: 0.001535, loss_freq: 0.013297
[19:30:33.268] iteration 27690: loss: 0.040731, loss_s1: 0.021761, loss_fp: 0.003115, loss_freq: 0.017759
[19:30:33.890] iteration 27691: loss: 0.040044, loss_s1: 0.015251, loss_fp: 0.002428, loss_freq: 0.029562
[19:30:34.511] iteration 27692: loss: 0.050342, loss_s1: 0.036744, loss_fp: 0.001725, loss_freq: 0.023540
[19:30:35.499] iteration 27693: loss: 0.031350, loss_s1: 0.022913, loss_fp: 0.001430, loss_freq: 0.008328
[19:30:36.135] iteration 27694: loss: 0.060413, loss_s1: 0.067855, loss_fp: 0.004420, loss_freq: 0.015772
[19:30:36.770] iteration 27695: loss: 0.037519, loss_s1: 0.029945, loss_fp: 0.002527, loss_freq: 0.012680
[19:30:37.420] iteration 27696: loss: 0.032595, loss_s1: 0.012980, loss_fp: 0.001894, loss_freq: 0.012096
[19:30:38.049] iteration 27697: loss: 0.049810, loss_s1: 0.048481, loss_fp: 0.005266, loss_freq: 0.012314
[19:30:38.684] iteration 27698: loss: 0.064765, loss_s1: 0.040285, loss_fp: 0.004333, loss_freq: 0.043596
[19:30:39.310] iteration 27699: loss: 0.038622, loss_s1: 0.025216, loss_fp: 0.000655, loss_freq: 0.022062
[19:30:39.938] iteration 27700: loss: 0.031926, loss_s1: 0.019328, loss_fp: 0.001224, loss_freq: 0.016335
[19:30:40.561] iteration 27701: loss: 0.067635, loss_s1: 0.072059, loss_fp: 0.004593, loss_freq: 0.034908
[19:30:41.189] iteration 27702: loss: 0.077921, loss_s1: 0.076297, loss_fp: 0.014662, loss_freq: 0.031702
[19:30:41.826] iteration 27703: loss: 0.028106, loss_s1: 0.017753, loss_fp: 0.000449, loss_freq: 0.007573
[19:30:42.464] iteration 27704: loss: 0.032393, loss_s1: 0.019042, loss_fp: 0.004856, loss_freq: 0.016078
[19:30:43.097] iteration 27705: loss: 0.068287, loss_s1: 0.047756, loss_fp: 0.005656, loss_freq: 0.059119
[19:30:43.720] iteration 27706: loss: 0.051125, loss_s1: 0.035189, loss_fp: 0.006764, loss_freq: 0.021435
[19:30:44.349] iteration 27707: loss: 0.053414, loss_s1: 0.040354, loss_fp: 0.007661, loss_freq: 0.029702
[19:30:44.976] iteration 27708: loss: 0.122511, loss_s1: 0.118943, loss_fp: 0.005168, loss_freq: 0.088933
[19:30:45.599] iteration 27709: loss: 0.037898, loss_s1: 0.026152, loss_fp: 0.003300, loss_freq: 0.012267
[19:30:46.226] iteration 27710: loss: 0.059716, loss_s1: 0.038421, loss_fp: 0.006200, loss_freq: 0.043589
[19:30:46.847] iteration 27711: loss: 0.035301, loss_s1: 0.019082, loss_fp: 0.001017, loss_freq: 0.019767
[19:30:47.482] iteration 27712: loss: 0.058488, loss_s1: 0.055576, loss_fp: 0.006343, loss_freq: 0.023557
[19:30:48.108] iteration 27713: loss: 0.029843, loss_s1: 0.012482, loss_fp: 0.006803, loss_freq: 0.003917
[19:30:48.744] iteration 27714: loss: 0.048221, loss_s1: 0.022850, loss_fp: 0.003717, loss_freq: 0.035029
[19:30:49.370] iteration 27715: loss: 0.032630, loss_s1: 0.020325, loss_fp: 0.001270, loss_freq: 0.007392
[19:30:49.999] iteration 27716: loss: 0.049025, loss_s1: 0.027718, loss_fp: 0.008555, loss_freq: 0.029989
[19:30:50.624] iteration 27717: loss: 0.038141, loss_s1: 0.031633, loss_fp: 0.002951, loss_freq: 0.012096
[19:30:51.251] iteration 27718: loss: 0.067964, loss_s1: 0.083499, loss_fp: 0.005376, loss_freq: 0.016234
[19:30:51.885] iteration 27719: loss: 0.028110, loss_s1: 0.014792, loss_fp: 0.000749, loss_freq: 0.008664
[19:30:52.514] iteration 27720: loss: 0.062081, loss_s1: 0.065728, loss_fp: 0.007065, loss_freq: 0.017105
[19:30:53.143] iteration 27721: loss: 0.054758, loss_s1: 0.043029, loss_fp: 0.006207, loss_freq: 0.032905
[19:30:53.788] iteration 27722: loss: 0.046461, loss_s1: 0.053938, loss_fp: 0.002180, loss_freq: 0.004743
[19:30:54.426] iteration 27723: loss: 0.038453, loss_s1: 0.031245, loss_fp: 0.002376, loss_freq: 0.017859
[19:30:55.061] iteration 27724: loss: 0.041324, loss_s1: 0.021253, loss_fp: 0.004979, loss_freq: 0.019813
[19:30:55.688] iteration 27725: loss: 0.037299, loss_s1: 0.039410, loss_fp: 0.003920, loss_freq: 0.006866
[19:30:56.310] iteration 27726: loss: 0.023411, loss_s1: 0.009006, loss_fp: 0.002310, loss_freq: 0.005548
[19:30:56.938] iteration 27727: loss: 0.062063, loss_s1: 0.064389, loss_fp: 0.001316, loss_freq: 0.013355
[19:30:57.562] iteration 27728: loss: 0.050203, loss_s1: 0.050010, loss_fp: 0.004480, loss_freq: 0.019950
[19:30:58.193] iteration 27729: loss: 0.049284, loss_s1: 0.029341, loss_fp: 0.012081, loss_freq: 0.022674
[19:30:58.819] iteration 27730: loss: 0.067297, loss_s1: 0.065629, loss_fp: 0.004047, loss_freq: 0.037999
[19:30:59.451] iteration 27731: loss: 0.071862, loss_s1: 0.067645, loss_fp: 0.001154, loss_freq: 0.035452
[19:31:00.079] iteration 27732: loss: 0.048424, loss_s1: 0.039556, loss_fp: 0.003367, loss_freq: 0.024702
[19:31:00.705] iteration 27733: loss: 0.053482, loss_s1: 0.058941, loss_fp: 0.002035, loss_freq: 0.009257
[19:31:01.326] iteration 27734: loss: 0.050268, loss_s1: 0.049013, loss_fp: 0.006782, loss_freq: 0.019254
[19:31:01.956] iteration 27735: loss: 0.093667, loss_s1: 0.113451, loss_fp: 0.008960, loss_freq: 0.038577
[19:31:02.590] iteration 27736: loss: 0.058512, loss_s1: 0.033084, loss_fp: 0.005647, loss_freq: 0.044354
[19:31:03.216] iteration 27737: loss: 0.043401, loss_s1: 0.015126, loss_fp: 0.003079, loss_freq: 0.030067
[19:31:03.889] iteration 27738: loss: 0.045235, loss_s1: 0.049635, loss_fp: 0.001314, loss_freq: 0.002701
[19:31:04.516] iteration 27739: loss: 0.044202, loss_s1: 0.018119, loss_fp: 0.001717, loss_freq: 0.040392
[19:31:05.140] iteration 27740: loss: 0.033947, loss_s1: 0.015410, loss_fp: 0.002065, loss_freq: 0.017664
[19:31:05.776] iteration 27741: loss: 0.055055, loss_s1: 0.059316, loss_fp: 0.003622, loss_freq: 0.014397
[19:31:06.406] iteration 27742: loss: 0.049492, loss_s1: 0.039145, loss_fp: 0.003271, loss_freq: 0.031983
[19:31:07.084] iteration 27743: loss: 0.044010, loss_s1: 0.024769, loss_fp: 0.001651, loss_freq: 0.024414
[19:31:07.703] iteration 27744: loss: 0.044625, loss_s1: 0.034662, loss_fp: 0.004982, loss_freq: 0.013671
[19:31:08.329] iteration 27745: loss: 0.053285, loss_s1: 0.037140, loss_fp: 0.001148, loss_freq: 0.037737
[19:31:08.957] iteration 27746: loss: 0.040379, loss_s1: 0.032973, loss_fp: 0.001220, loss_freq: 0.020274
[19:31:09.615] iteration 27747: loss: 0.036038, loss_s1: 0.012521, loss_fp: 0.002940, loss_freq: 0.010705
[19:31:10.249] iteration 27748: loss: 0.079316, loss_s1: 0.078685, loss_fp: 0.005691, loss_freq: 0.029583
[19:31:10.873] iteration 27749: loss: 0.037884, loss_s1: 0.021135, loss_fp: 0.008647, loss_freq: 0.010514
[19:31:11.505] iteration 27750: loss: 0.052627, loss_s1: 0.029776, loss_fp: 0.015303, loss_freq: 0.019899
[19:31:12.140] iteration 27751: loss: 0.040245, loss_s1: 0.033175, loss_fp: 0.001330, loss_freq: 0.016712
[19:31:12.767] iteration 27752: loss: 0.028325, loss_s1: 0.011055, loss_fp: 0.004916, loss_freq: 0.016351
[19:31:13.402] iteration 27753: loss: 0.032026, loss_s1: 0.010998, loss_fp: 0.004275, loss_freq: 0.018754
[19:31:14.065] iteration 27754: loss: 0.035099, loss_s1: 0.018478, loss_fp: 0.005467, loss_freq: 0.015521
[19:31:14.692] iteration 27755: loss: 0.038720, loss_s1: 0.012062, loss_fp: 0.003546, loss_freq: 0.023924
[19:31:15.322] iteration 27756: loss: 0.028372, loss_s1: 0.024991, loss_fp: 0.000926, loss_freq: 0.005365
[19:31:15.950] iteration 27757: loss: 0.051521, loss_s1: 0.036744, loss_fp: 0.001349, loss_freq: 0.038372
[19:31:16.576] iteration 27758: loss: 0.058962, loss_s1: 0.016763, loss_fp: 0.004288, loss_freq: 0.063256
[19:31:17.203] iteration 27759: loss: 0.050822, loss_s1: 0.024433, loss_fp: 0.002336, loss_freq: 0.036952
[19:31:17.830] iteration 27760: loss: 0.058681, loss_s1: 0.061889, loss_fp: 0.003467, loss_freq: 0.020346
[19:31:18.456] iteration 27761: loss: 0.039448, loss_s1: 0.036950, loss_fp: 0.003939, loss_freq: 0.010524
[19:31:19.082] iteration 27762: loss: 0.074468, loss_s1: 0.031448, loss_fp: 0.003226, loss_freq: 0.026715
[19:31:19.710] iteration 27763: loss: 0.086247, loss_s1: 0.077796, loss_fp: 0.015696, loss_freq: 0.050869
[19:31:20.339] iteration 27764: loss: 0.059423, loss_s1: 0.037865, loss_fp: 0.002336, loss_freq: 0.048009
[19:31:20.960] iteration 27765: loss: 0.057064, loss_s1: 0.031024, loss_fp: 0.005513, loss_freq: 0.038506
[19:31:21.588] iteration 27766: loss: 0.038125, loss_s1: 0.020976, loss_fp: 0.009058, loss_freq: 0.009539
[19:31:22.214] iteration 27767: loss: 0.069679, loss_s1: 0.090859, loss_fp: 0.001240, loss_freq: 0.011825
[19:31:22.835] iteration 27768: loss: 0.054286, loss_s1: 0.039512, loss_fp: 0.001860, loss_freq: 0.023685
[19:31:23.464] iteration 27769: loss: 0.070769, loss_s1: 0.093955, loss_fp: 0.000579, loss_freq: 0.017435
[19:31:24.083] iteration 27770: loss: 0.035290, loss_s1: 0.031606, loss_fp: 0.002860, loss_freq: 0.008784
[19:31:24.704] iteration 27771: loss: 0.030452, loss_s1: 0.023816, loss_fp: 0.000703, loss_freq: 0.007532
[19:31:25.327] iteration 27772: loss: 0.058168, loss_s1: 0.033850, loss_fp: 0.002433, loss_freq: 0.028492
[19:31:25.962] iteration 27773: loss: 0.058025, loss_s1: 0.057505, loss_fp: 0.009012, loss_freq: 0.020357
[19:31:26.603] iteration 27774: loss: 0.076442, loss_s1: 0.097529, loss_fp: 0.001668, loss_freq: 0.025830
[19:31:27.263] iteration 27775: loss: 0.061368, loss_s1: 0.059826, loss_fp: 0.018038, loss_freq: 0.018145
[19:31:27.906] iteration 27776: loss: 0.041920, loss_s1: 0.029428, loss_fp: 0.000944, loss_freq: 0.019802
[19:31:28.537] iteration 27777: loss: 0.090043, loss_s1: 0.100868, loss_fp: 0.006278, loss_freq: 0.042920
[19:31:29.170] iteration 27778: loss: 0.030301, loss_s1: 0.016432, loss_fp: 0.000777, loss_freq: 0.012617
[19:31:29.805] iteration 27779: loss: 0.059315, loss_s1: 0.063348, loss_fp: 0.001359, loss_freq: 0.010058
[19:31:30.443] iteration 27780: loss: 0.060274, loss_s1: 0.059363, loss_fp: 0.002051, loss_freq: 0.028936
[19:31:31.071] iteration 27781: loss: 0.052336, loss_s1: 0.030731, loss_fp: 0.008684, loss_freq: 0.026375
[19:31:31.702] iteration 27782: loss: 0.052276, loss_s1: 0.042315, loss_fp: 0.001455, loss_freq: 0.026918
[19:31:32.341] iteration 27783: loss: 0.062708, loss_s1: 0.041839, loss_fp: 0.003075, loss_freq: 0.042835
[19:31:32.976] iteration 27784: loss: 0.061726, loss_s1: 0.054248, loss_fp: 0.003755, loss_freq: 0.032689
[19:31:33.683] iteration 27785: loss: 0.071678, loss_s1: 0.040594, loss_fp: 0.001964, loss_freq: 0.046035
[19:31:34.362] iteration 27786: loss: 0.037893, loss_s1: 0.034683, loss_fp: 0.004745, loss_freq: 0.010379
[19:31:35.042] iteration 27787: loss: 0.050815, loss_s1: 0.059117, loss_fp: 0.005717, loss_freq: 0.012485
[19:31:35.673] iteration 27788: loss: 0.034921, loss_s1: 0.017367, loss_fp: 0.003311, loss_freq: 0.024803
[19:31:36.301] iteration 27789: loss: 0.031828, loss_s1: 0.013709, loss_fp: 0.004181, loss_freq: 0.016046
[19:31:36.926] iteration 27790: loss: 0.033041, loss_s1: 0.017988, loss_fp: 0.000787, loss_freq: 0.012905
[19:31:37.556] iteration 27791: loss: 0.032057, loss_s1: 0.013515, loss_fp: 0.004084, loss_freq: 0.016603
[19:31:38.189] iteration 27792: loss: 0.058386, loss_s1: 0.027408, loss_fp: 0.003802, loss_freq: 0.025607
[19:31:38.813] iteration 27793: loss: 0.059725, loss_s1: 0.060231, loss_fp: 0.002016, loss_freq: 0.033796
[19:31:39.445] iteration 27794: loss: 0.064962, loss_s1: 0.038531, loss_fp: 0.004060, loss_freq: 0.052688
[19:31:40.074] iteration 27795: loss: 0.054795, loss_s1: 0.044962, loss_fp: 0.001594, loss_freq: 0.034876
[19:31:40.711] iteration 27796: loss: 0.041118, loss_s1: 0.031833, loss_fp: 0.001884, loss_freq: 0.018473
[19:31:41.377] iteration 27797: loss: 0.044371, loss_s1: 0.022023, loss_fp: 0.012623, loss_freq: 0.019581
[19:31:42.004] iteration 27798: loss: 0.030401, loss_s1: 0.008884, loss_fp: 0.000468, loss_freq: 0.023167
[19:31:42.629] iteration 27799: loss: 0.032450, loss_s1: 0.013381, loss_fp: 0.005174, loss_freq: 0.008827
[19:31:43.258] iteration 27800: loss: 0.054012, loss_s1: 0.048302, loss_fp: 0.002775, loss_freq: 0.024856
[19:31:46.419] iteration 27800 : mean_dice : 0.719614
[19:31:47.062] iteration 27801: loss: 0.083262, loss_s1: 0.047537, loss_fp: 0.003738, loss_freq: 0.082147
[19:31:47.690] iteration 27802: loss: 0.043400, loss_s1: 0.022330, loss_fp: 0.004412, loss_freq: 0.022386
[19:31:48.331] iteration 27803: loss: 0.044055, loss_s1: 0.029335, loss_fp: 0.002134, loss_freq: 0.020555
[19:31:48.971] iteration 27804: loss: 0.055050, loss_s1: 0.050893, loss_fp: 0.008264, loss_freq: 0.016767
[19:31:49.602] iteration 27805: loss: 0.053465, loss_s1: 0.044994, loss_fp: 0.001690, loss_freq: 0.025163
[19:31:50.227] iteration 27806: loss: 0.054213, loss_s1: 0.040209, loss_fp: 0.005168, loss_freq: 0.031344
[19:31:50.857] iteration 27807: loss: 0.037663, loss_s1: 0.024570, loss_fp: 0.004558, loss_freq: 0.007117
[19:31:51.486] iteration 27808: loss: 0.066598, loss_s1: 0.079905, loss_fp: 0.005269, loss_freq: 0.018411
[19:31:52.107] iteration 27809: loss: 0.039983, loss_s1: 0.028170, loss_fp: 0.004522, loss_freq: 0.016621
[19:31:52.731] iteration 27810: loss: 0.036992, loss_s1: 0.036559, loss_fp: 0.001491, loss_freq: 0.005117
[19:31:53.363] iteration 27811: loss: 0.050226, loss_s1: 0.036740, loss_fp: 0.003785, loss_freq: 0.020342
[19:31:53.986] iteration 27812: loss: 0.116853, loss_s1: 0.114286, loss_fp: 0.001732, loss_freq: 0.092927
[19:31:54.616] iteration 27813: loss: 0.038731, loss_s1: 0.025751, loss_fp: 0.007151, loss_freq: 0.009028
[19:31:55.252] iteration 27814: loss: 0.058809, loss_s1: 0.054300, loss_fp: 0.005575, loss_freq: 0.019129
[19:31:55.887] iteration 27815: loss: 0.039886, loss_s1: 0.031456, loss_fp: 0.002340, loss_freq: 0.009063
[19:31:56.516] iteration 27816: loss: 0.027148, loss_s1: 0.010471, loss_fp: 0.000521, loss_freq: 0.011382
[19:31:57.145] iteration 27817: loss: 0.037876, loss_s1: 0.025427, loss_fp: 0.002015, loss_freq: 0.019133
[19:31:57.772] iteration 27818: loss: 0.077180, loss_s1: 0.052672, loss_fp: 0.005893, loss_freq: 0.060475
[19:31:58.399] iteration 27819: loss: 0.053934, loss_s1: 0.067777, loss_fp: 0.000897, loss_freq: 0.006633
[19:31:59.030] iteration 27820: loss: 0.071103, loss_s1: 0.054283, loss_fp: 0.004388, loss_freq: 0.043961
[19:31:59.660] iteration 27821: loss: 0.038889, loss_s1: 0.022694, loss_fp: 0.001735, loss_freq: 0.022097
[19:32:00.290] iteration 27822: loss: 0.049459, loss_s1: 0.056608, loss_fp: 0.001493, loss_freq: 0.015394
[19:32:00.932] iteration 27823: loss: 0.037322, loss_s1: 0.030939, loss_fp: 0.002834, loss_freq: 0.017399
[19:32:01.562] iteration 27824: loss: 0.058271, loss_s1: 0.060892, loss_fp: 0.001086, loss_freq: 0.022279
[19:32:02.189] iteration 27825: loss: 0.058870, loss_s1: 0.052758, loss_fp: 0.003573, loss_freq: 0.024701
[19:32:02.821] iteration 27826: loss: 0.061233, loss_s1: 0.040799, loss_fp: 0.007356, loss_freq: 0.034020
[19:32:03.451] iteration 27827: loss: 0.059104, loss_s1: 0.054419, loss_fp: 0.003228, loss_freq: 0.028737
[19:32:04.078] iteration 27828: loss: 0.061476, loss_s1: 0.052005, loss_fp: 0.010866, loss_freq: 0.034003
[19:32:04.706] iteration 27829: loss: 0.039246, loss_s1: 0.029388, loss_fp: 0.004084, loss_freq: 0.016394
[19:32:05.335] iteration 27830: loss: 0.036398, loss_s1: 0.032331, loss_fp: 0.003203, loss_freq: 0.010705
[19:32:05.969] iteration 27831: loss: 0.033681, loss_s1: 0.014480, loss_fp: 0.007823, loss_freq: 0.019010
[19:32:06.596] iteration 27832: loss: 0.068746, loss_s1: 0.053021, loss_fp: 0.001360, loss_freq: 0.045886
[19:32:07.223] iteration 27833: loss: 0.094488, loss_s1: 0.126349, loss_fp: 0.007065, loss_freq: 0.023011
[19:32:07.852] iteration 27834: loss: 0.036736, loss_s1: 0.018202, loss_fp: 0.007343, loss_freq: 0.011186
[19:32:08.480] iteration 27835: loss: 0.076199, loss_s1: 0.070768, loss_fp: 0.006835, loss_freq: 0.042488
[19:32:09.104] iteration 27836: loss: 0.062137, loss_s1: 0.055342, loss_fp: 0.006694, loss_freq: 0.025097
[19:32:09.729] iteration 27837: loss: 0.046737, loss_s1: 0.036372, loss_fp: 0.006285, loss_freq: 0.017715
[19:32:10.358] iteration 27838: loss: 0.054207, loss_s1: 0.050853, loss_fp: 0.006833, loss_freq: 0.006367
[19:32:10.990] iteration 27839: loss: 0.066372, loss_s1: 0.043201, loss_fp: 0.006305, loss_freq: 0.056308
[19:32:11.617] iteration 27840: loss: 0.070766, loss_s1: 0.100651, loss_fp: 0.002519, loss_freq: 0.006777
[19:32:12.247] iteration 27841: loss: 0.035451, loss_s1: 0.031905, loss_fp: 0.002356, loss_freq: 0.010294
[19:32:12.882] iteration 27842: loss: 0.111614, loss_s1: 0.121677, loss_fp: 0.001636, loss_freq: 0.057713
[19:32:13.508] iteration 27843: loss: 0.062041, loss_s1: 0.042194, loss_fp: 0.006827, loss_freq: 0.033146
[19:32:14.139] iteration 27844: loss: 0.070956, loss_s1: 0.056495, loss_fp: 0.006576, loss_freq: 0.052834
[19:32:14.767] iteration 27845: loss: 0.045486, loss_s1: 0.031821, loss_fp: 0.003640, loss_freq: 0.026207
[19:32:15.396] iteration 27846: loss: 0.048463, loss_s1: 0.026677, loss_fp: 0.005657, loss_freq: 0.021573
[19:32:16.032] iteration 27847: loss: 0.024407, loss_s1: 0.013222, loss_fp: 0.004453, loss_freq: 0.005999
[19:32:16.665] iteration 27848: loss: 0.050484, loss_s1: 0.040742, loss_fp: 0.005042, loss_freq: 0.015205
[19:32:17.313] iteration 27849: loss: 0.036847, loss_s1: 0.024045, loss_fp: 0.000852, loss_freq: 0.017676
[19:32:17.944] iteration 27850: loss: 0.050308, loss_s1: 0.032483, loss_fp: 0.005522, loss_freq: 0.013572
[19:32:18.570] iteration 27851: loss: 0.074321, loss_s1: 0.036807, loss_fp: 0.003351, loss_freq: 0.060620
[19:32:19.200] iteration 27852: loss: 0.074334, loss_s1: 0.081301, loss_fp: 0.003777, loss_freq: 0.036031
[19:32:19.828] iteration 27853: loss: 0.056608, loss_s1: 0.046090, loss_fp: 0.002285, loss_freq: 0.027129
[19:32:20.818] iteration 27854: loss: 0.046001, loss_s1: 0.042770, loss_fp: 0.001017, loss_freq: 0.014276
[19:32:21.452] iteration 27855: loss: 0.062294, loss_s1: 0.063328, loss_fp: 0.004398, loss_freq: 0.021720
[19:32:22.081] iteration 27856: loss: 0.034807, loss_s1: 0.025110, loss_fp: 0.003489, loss_freq: 0.010626
[19:32:22.708] iteration 27857: loss: 0.037113, loss_s1: 0.016019, loss_fp: 0.004755, loss_freq: 0.010232
[19:32:23.332] iteration 27858: loss: 0.039502, loss_s1: 0.023305, loss_fp: 0.001660, loss_freq: 0.019058
[19:32:23.962] iteration 27859: loss: 0.076592, loss_s1: 0.065453, loss_fp: 0.003896, loss_freq: 0.049894
[19:32:24.590] iteration 27860: loss: 0.047603, loss_s1: 0.042249, loss_fp: 0.007365, loss_freq: 0.020561
[19:32:25.214] iteration 27861: loss: 0.024357, loss_s1: 0.011301, loss_fp: 0.002481, loss_freq: 0.009432
[19:32:25.836] iteration 27862: loss: 0.066972, loss_s1: 0.077206, loss_fp: 0.003428, loss_freq: 0.029861
[19:32:26.467] iteration 27863: loss: 0.095864, loss_s1: 0.106764, loss_fp: 0.007677, loss_freq: 0.040479
[19:32:27.094] iteration 27864: loss: 0.024752, loss_s1: 0.010054, loss_fp: 0.000702, loss_freq: 0.005823
[19:32:27.723] iteration 27865: loss: 0.042617, loss_s1: 0.034274, loss_fp: 0.003630, loss_freq: 0.019791
[19:32:28.353] iteration 27866: loss: 0.076514, loss_s1: 0.067514, loss_fp: 0.002951, loss_freq: 0.048725
[19:32:28.992] iteration 27867: loss: 0.065843, loss_s1: 0.035727, loss_fp: 0.001220, loss_freq: 0.040214
[19:32:29.617] iteration 27868: loss: 0.048690, loss_s1: 0.057674, loss_fp: 0.005901, loss_freq: 0.007702
[19:32:30.249] iteration 27869: loss: 0.129755, loss_s1: 0.093477, loss_fp: 0.008677, loss_freq: 0.129053
[19:32:30.873] iteration 27870: loss: 0.035813, loss_s1: 0.014714, loss_fp: 0.001707, loss_freq: 0.010589
[19:32:31.505] iteration 27871: loss: 0.061001, loss_s1: 0.058875, loss_fp: 0.006155, loss_freq: 0.019163
[19:32:32.131] iteration 27872: loss: 0.026967, loss_s1: 0.008867, loss_fp: 0.000197, loss_freq: 0.012013
[19:32:32.761] iteration 27873: loss: 0.059668, loss_s1: 0.056821, loss_fp: 0.005686, loss_freq: 0.027408
[19:32:33.440] iteration 27874: loss: 0.044505, loss_s1: 0.042268, loss_fp: 0.001824, loss_freq: 0.008165
[19:32:34.062] iteration 27875: loss: 0.041392, loss_s1: 0.031392, loss_fp: 0.001347, loss_freq: 0.018569
[19:32:34.686] iteration 27876: loss: 0.061116, loss_s1: 0.061645, loss_fp: 0.002890, loss_freq: 0.014618
[19:32:35.312] iteration 27877: loss: 0.051387, loss_s1: 0.038199, loss_fp: 0.002634, loss_freq: 0.029711
[19:32:35.947] iteration 27878: loss: 0.057253, loss_s1: 0.068701, loss_fp: 0.002194, loss_freq: 0.012572
[19:32:36.572] iteration 27879: loss: 0.057683, loss_s1: 0.058536, loss_fp: 0.001227, loss_freq: 0.030051
[19:32:37.218] iteration 27880: loss: 0.037627, loss_s1: 0.037157, loss_fp: 0.002381, loss_freq: 0.005407
[19:32:37.850] iteration 27881: loss: 0.115098, loss_s1: 0.123434, loss_fp: 0.014505, loss_freq: 0.049308
[19:32:38.479] iteration 27882: loss: 0.050806, loss_s1: 0.029016, loss_fp: 0.013190, loss_freq: 0.032484
[19:32:39.109] iteration 27883: loss: 0.041104, loss_s1: 0.029632, loss_fp: 0.004566, loss_freq: 0.017169
[19:32:39.736] iteration 27884: loss: 0.065925, loss_s1: 0.070169, loss_fp: 0.002996, loss_freq: 0.036436
[19:32:40.359] iteration 27885: loss: 0.047507, loss_s1: 0.050052, loss_fp: 0.004470, loss_freq: 0.011390
[19:32:40.979] iteration 27886: loss: 0.058657, loss_s1: 0.055922, loss_fp: 0.003513, loss_freq: 0.030989
[19:32:41.606] iteration 27887: loss: 0.028962, loss_s1: 0.013855, loss_fp: 0.004276, loss_freq: 0.010517
[19:32:42.233] iteration 27888: loss: 0.045192, loss_s1: 0.020442, loss_fp: 0.004860, loss_freq: 0.023578
[19:32:42.860] iteration 27889: loss: 0.086047, loss_s1: 0.086296, loss_fp: 0.003484, loss_freq: 0.055200
[19:32:43.484] iteration 27890: loss: 0.063418, loss_s1: 0.068442, loss_fp: 0.002310, loss_freq: 0.019086
[19:32:44.115] iteration 27891: loss: 0.055725, loss_s1: 0.042371, loss_fp: 0.002271, loss_freq: 0.035107
[19:32:44.739] iteration 27892: loss: 0.064783, loss_s1: 0.038943, loss_fp: 0.005485, loss_freq: 0.044968
[19:32:45.363] iteration 27893: loss: 0.040552, loss_s1: 0.022138, loss_fp: 0.002867, loss_freq: 0.021873
[19:32:45.989] iteration 27894: loss: 0.046099, loss_s1: 0.042124, loss_fp: 0.000439, loss_freq: 0.011303
[19:32:46.613] iteration 27895: loss: 0.080437, loss_s1: 0.055779, loss_fp: 0.008469, loss_freq: 0.066155
[19:32:47.238] iteration 27896: loss: 0.055947, loss_s1: 0.054364, loss_fp: 0.004322, loss_freq: 0.027733
[19:32:47.874] iteration 27897: loss: 0.044432, loss_s1: 0.029120, loss_fp: 0.002120, loss_freq: 0.034249
[19:32:48.507] iteration 27898: loss: 0.038342, loss_s1: 0.020771, loss_fp: 0.004600, loss_freq: 0.019590
[19:32:49.137] iteration 27899: loss: 0.030034, loss_s1: 0.017436, loss_fp: 0.001701, loss_freq: 0.009271
[19:32:49.764] iteration 27900: loss: 0.030055, loss_s1: 0.019318, loss_fp: 0.002539, loss_freq: 0.010703
[19:32:50.391] iteration 27901: loss: 0.051473, loss_s1: 0.052963, loss_fp: 0.002988, loss_freq: 0.019598
[19:32:51.024] iteration 27902: loss: 0.065335, loss_s1: 0.065348, loss_fp: 0.001481, loss_freq: 0.030198
[19:32:51.652] iteration 27903: loss: 0.043895, loss_s1: 0.048800, loss_fp: 0.000547, loss_freq: 0.015293
[19:32:52.278] iteration 27904: loss: 0.068413, loss_s1: 0.051399, loss_fp: 0.001306, loss_freq: 0.055521
[19:32:52.907] iteration 27905: loss: 0.035086, loss_s1: 0.017261, loss_fp: 0.003115, loss_freq: 0.014250
[19:32:53.535] iteration 27906: loss: 0.061825, loss_s1: 0.019909, loss_fp: 0.003924, loss_freq: 0.058011
[19:32:54.178] iteration 27907: loss: 0.035453, loss_s1: 0.012307, loss_fp: 0.007741, loss_freq: 0.021801
[19:32:54.820] iteration 27908: loss: 0.031415, loss_s1: 0.014655, loss_fp: 0.004143, loss_freq: 0.009127
[19:32:55.466] iteration 27909: loss: 0.059973, loss_s1: 0.037508, loss_fp: 0.009469, loss_freq: 0.031691
[19:32:56.107] iteration 27910: loss: 0.039826, loss_s1: 0.033710, loss_fp: 0.003645, loss_freq: 0.009820
[19:32:56.729] iteration 27911: loss: 0.045480, loss_s1: 0.032905, loss_fp: 0.001027, loss_freq: 0.014415
[19:32:57.370] iteration 27912: loss: 0.032537, loss_s1: 0.018081, loss_fp: 0.003347, loss_freq: 0.011986
[19:32:58.009] iteration 27913: loss: 0.035548, loss_s1: 0.026068, loss_fp: 0.002501, loss_freq: 0.015409
[19:32:58.631] iteration 27914: loss: 0.027076, loss_s1: 0.007443, loss_fp: 0.002027, loss_freq: 0.018113
[19:32:59.252] iteration 27915: loss: 0.037053, loss_s1: 0.023552, loss_fp: 0.007050, loss_freq: 0.012102
[19:32:59.875] iteration 27916: loss: 0.038692, loss_s1: 0.021090, loss_fp: 0.000824, loss_freq: 0.014416
[19:33:00.504] iteration 27917: loss: 0.029430, loss_s1: 0.013216, loss_fp: 0.001463, loss_freq: 0.019774
[19:33:01.133] iteration 27918: loss: 0.047897, loss_s1: 0.047536, loss_fp: 0.001709, loss_freq: 0.013078
[19:33:01.765] iteration 27919: loss: 0.053135, loss_s1: 0.037162, loss_fp: 0.001020, loss_freq: 0.043178
[19:33:02.399] iteration 27920: loss: 0.052489, loss_s1: 0.020429, loss_fp: 0.001035, loss_freq: 0.051981
[19:33:03.029] iteration 27921: loss: 0.073134, loss_s1: 0.070225, loss_fp: 0.007291, loss_freq: 0.038209
[19:33:03.667] iteration 27922: loss: 0.047955, loss_s1: 0.052331, loss_fp: 0.001906, loss_freq: 0.011336
[19:33:04.288] iteration 27923: loss: 0.058708, loss_s1: 0.035422, loss_fp: 0.000581, loss_freq: 0.035074
[19:33:04.913] iteration 27924: loss: 0.060425, loss_s1: 0.035546, loss_fp: 0.002510, loss_freq: 0.054178
[19:33:05.536] iteration 27925: loss: 0.039872, loss_s1: 0.029830, loss_fp: 0.001209, loss_freq: 0.015108
[19:33:06.155] iteration 27926: loss: 0.045545, loss_s1: 0.030924, loss_fp: 0.000918, loss_freq: 0.024028
[19:33:06.781] iteration 27927: loss: 0.044405, loss_s1: 0.030050, loss_fp: 0.005090, loss_freq: 0.011793
[19:33:07.406] iteration 27928: loss: 0.065207, loss_s1: 0.076934, loss_fp: 0.002351, loss_freq: 0.015350
[19:33:08.033] iteration 27929: loss: 0.055573, loss_s1: 0.015802, loss_fp: 0.005852, loss_freq: 0.049171
[19:33:08.678] iteration 27930: loss: 0.036338, loss_s1: 0.022156, loss_fp: 0.001454, loss_freq: 0.023940
[19:33:09.312] iteration 27931: loss: 0.028672, loss_s1: 0.018634, loss_fp: 0.001243, loss_freq: 0.011974
[19:33:09.943] iteration 27932: loss: 0.024583, loss_s1: 0.017539, loss_fp: 0.001190, loss_freq: 0.004885
[19:33:10.578] iteration 27933: loss: 0.051459, loss_s1: 0.044558, loss_fp: 0.005069, loss_freq: 0.019544
[19:33:11.205] iteration 27934: loss: 0.066611, loss_s1: 0.056092, loss_fp: 0.006413, loss_freq: 0.038059
[19:33:11.835] iteration 27935: loss: 0.065647, loss_s1: 0.085172, loss_fp: 0.004033, loss_freq: 0.015162
[19:33:12.462] iteration 27936: loss: 0.095081, loss_s1: 0.105044, loss_fp: 0.006457, loss_freq: 0.044545
[19:33:13.090] iteration 27937: loss: 0.047942, loss_s1: 0.032227, loss_fp: 0.002854, loss_freq: 0.029159
[19:33:13.719] iteration 27938: loss: 0.096469, loss_s1: 0.103570, loss_fp: 0.007995, loss_freq: 0.053967
[19:33:14.357] iteration 27939: loss: 0.041609, loss_s1: 0.017231, loss_fp: 0.001249, loss_freq: 0.023666
[19:33:14.985] iteration 27940: loss: 0.067514, loss_s1: 0.063238, loss_fp: 0.005550, loss_freq: 0.020676
[19:33:15.612] iteration 27941: loss: 0.047008, loss_s1: 0.041517, loss_fp: 0.008772, loss_freq: 0.018197
[19:33:16.242] iteration 27942: loss: 0.048801, loss_s1: 0.048718, loss_fp: 0.003380, loss_freq: 0.015852
[19:33:16.879] iteration 27943: loss: 0.060395, loss_s1: 0.054857, loss_fp: 0.002602, loss_freq: 0.029285
[19:33:17.510] iteration 27944: loss: 0.047804, loss_s1: 0.037699, loss_fp: 0.005289, loss_freq: 0.011718
[19:33:18.135] iteration 27945: loss: 0.086632, loss_s1: 0.072923, loss_fp: 0.002780, loss_freq: 0.054654
[19:33:18.766] iteration 27946: loss: 0.053301, loss_s1: 0.021970, loss_fp: 0.005325, loss_freq: 0.025608
[19:33:19.403] iteration 27947: loss: 0.027405, loss_s1: 0.010530, loss_fp: 0.000467, loss_freq: 0.012545
[19:33:20.034] iteration 27948: loss: 0.059831, loss_s1: 0.080672, loss_fp: 0.001655, loss_freq: 0.010074
[19:33:20.666] iteration 27949: loss: 0.051222, loss_s1: 0.030062, loss_fp: 0.003034, loss_freq: 0.043303
[19:33:21.289] iteration 27950: loss: 0.037025, loss_s1: 0.017620, loss_fp: 0.000600, loss_freq: 0.017641
[19:33:21.917] iteration 27951: loss: 0.047869, loss_s1: 0.026979, loss_fp: 0.002423, loss_freq: 0.031305
[19:33:22.542] iteration 27952: loss: 0.055679, loss_s1: 0.061648, loss_fp: 0.002753, loss_freq: 0.013791
[19:33:23.178] iteration 27953: loss: 0.053857, loss_s1: 0.035574, loss_fp: 0.003650, loss_freq: 0.037835
[19:33:23.819] iteration 27954: loss: 0.046296, loss_s1: 0.052545, loss_fp: 0.000967, loss_freq: 0.009958
[19:33:24.455] iteration 27955: loss: 0.050767, loss_s1: 0.035846, loss_fp: 0.002473, loss_freq: 0.027345
[19:33:25.091] iteration 27956: loss: 0.065992, loss_s1: 0.050603, loss_fp: 0.019481, loss_freq: 0.034636
[19:33:25.730] iteration 27957: loss: 0.033573, loss_s1: 0.026432, loss_fp: 0.003168, loss_freq: 0.008258
[19:33:26.359] iteration 27958: loss: 0.042647, loss_s1: 0.025634, loss_fp: 0.003716, loss_freq: 0.008852
[19:33:27.025] iteration 27959: loss: 0.040870, loss_s1: 0.034029, loss_fp: 0.001866, loss_freq: 0.012924
[19:33:27.665] iteration 27960: loss: 0.027684, loss_s1: 0.006351, loss_fp: 0.000988, loss_freq: 0.011234
[19:33:28.307] iteration 27961: loss: 0.052650, loss_s1: 0.049924, loss_fp: 0.002657, loss_freq: 0.011522
[19:33:28.952] iteration 27962: loss: 0.093652, loss_s1: 0.050661, loss_fp: 0.016434, loss_freq: 0.074456
[19:33:29.588] iteration 27963: loss: 0.046517, loss_s1: 0.033825, loss_fp: 0.002345, loss_freq: 0.024502
[19:33:30.217] iteration 27964: loss: 0.040187, loss_s1: 0.035282, loss_fp: 0.003426, loss_freq: 0.013000
[19:33:30.846] iteration 27965: loss: 0.055873, loss_s1: 0.041457, loss_fp: 0.003164, loss_freq: 0.041011
[19:33:31.468] iteration 27966: loss: 0.041729, loss_s1: 0.038412, loss_fp: 0.002200, loss_freq: 0.018890
[19:33:32.097] iteration 27967: loss: 0.049636, loss_s1: 0.041696, loss_fp: 0.001497, loss_freq: 0.024484
[19:33:32.736] iteration 27968: loss: 0.033304, loss_s1: 0.008236, loss_fp: 0.002081, loss_freq: 0.009735
[19:33:33.378] iteration 27969: loss: 0.059793, loss_s1: 0.052148, loss_fp: 0.002617, loss_freq: 0.028415
[19:33:34.016] iteration 27970: loss: 0.049355, loss_s1: 0.044364, loss_fp: 0.003987, loss_freq: 0.023727
[19:33:34.668] iteration 27971: loss: 0.052308, loss_s1: 0.047268, loss_fp: 0.004277, loss_freq: 0.017780
[19:33:35.301] iteration 27972: loss: 0.064237, loss_s1: 0.051512, loss_fp: 0.001187, loss_freq: 0.020443
[19:33:35.923] iteration 27973: loss: 0.101171, loss_s1: 0.085998, loss_fp: 0.011027, loss_freq: 0.082565
[19:33:36.551] iteration 27974: loss: 0.036598, loss_s1: 0.023460, loss_fp: 0.003224, loss_freq: 0.016071
[19:33:37.176] iteration 27975: loss: 0.074823, loss_s1: 0.059154, loss_fp: 0.007562, loss_freq: 0.020137
[19:33:37.808] iteration 27976: loss: 0.072865, loss_s1: 0.101642, loss_fp: 0.001217, loss_freq: 0.012993
[19:33:38.468] iteration 27977: loss: 0.055836, loss_s1: 0.043751, loss_fp: 0.001960, loss_freq: 0.019999
[19:33:39.135] iteration 27978: loss: 0.052728, loss_s1: 0.035651, loss_fp: 0.004198, loss_freq: 0.035091
[19:33:39.807] iteration 27979: loss: 0.036131, loss_s1: 0.019324, loss_fp: 0.001126, loss_freq: 0.017546
[19:33:40.472] iteration 27980: loss: 0.054318, loss_s1: 0.039967, loss_fp: 0.017725, loss_freq: 0.017808
[19:33:41.120] iteration 27981: loss: 0.055598, loss_s1: 0.064442, loss_fp: 0.002079, loss_freq: 0.010485
[19:33:41.745] iteration 27982: loss: 0.065927, loss_s1: 0.064496, loss_fp: 0.004806, loss_freq: 0.032248
[19:33:42.392] iteration 27983: loss: 0.032588, loss_s1: 0.030325, loss_fp: 0.002602, loss_freq: 0.010043
[19:33:43.020] iteration 27984: loss: 0.056481, loss_s1: 0.046582, loss_fp: 0.002580, loss_freq: 0.034950
[19:33:43.645] iteration 27985: loss: 0.055241, loss_s1: 0.048208, loss_fp: 0.003550, loss_freq: 0.016817
[19:33:44.274] iteration 27986: loss: 0.060907, loss_s1: 0.039859, loss_fp: 0.004241, loss_freq: 0.040489
[19:33:44.903] iteration 27987: loss: 0.049872, loss_s1: 0.052099, loss_fp: 0.003316, loss_freq: 0.018392
[19:33:45.531] iteration 27988: loss: 0.060988, loss_s1: 0.055066, loss_fp: 0.001966, loss_freq: 0.032719
[19:33:46.159] iteration 27989: loss: 0.049904, loss_s1: 0.048443, loss_fp: 0.001236, loss_freq: 0.018528
[19:33:46.788] iteration 27990: loss: 0.034533, loss_s1: 0.030195, loss_fp: 0.001213, loss_freq: 0.007300
[19:33:47.410] iteration 27991: loss: 0.041023, loss_s1: 0.032802, loss_fp: 0.004176, loss_freq: 0.019702
[19:33:48.050] iteration 27992: loss: 0.035213, loss_s1: 0.015540, loss_fp: 0.005008, loss_freq: 0.022271
[19:33:48.696] iteration 27993: loss: 0.060077, loss_s1: 0.045378, loss_fp: 0.004028, loss_freq: 0.023191
[19:33:49.332] iteration 27994: loss: 0.047410, loss_s1: 0.040021, loss_fp: 0.008098, loss_freq: 0.016315
[19:33:49.963] iteration 27995: loss: 0.042439, loss_s1: 0.030790, loss_fp: 0.002283, loss_freq: 0.013902
[19:33:50.596] iteration 27996: loss: 0.043194, loss_s1: 0.017802, loss_fp: 0.007942, loss_freq: 0.028434
[19:33:51.227] iteration 27997: loss: 0.053719, loss_s1: 0.033028, loss_fp: 0.002251, loss_freq: 0.022717
[19:33:51.850] iteration 27998: loss: 0.044010, loss_s1: 0.033455, loss_fp: 0.005041, loss_freq: 0.015991
[19:33:52.478] iteration 27999: loss: 0.056625, loss_s1: 0.040363, loss_fp: 0.008504, loss_freq: 0.009411
[19:33:53.111] iteration 28000: loss: 0.048327, loss_s1: 0.014259, loss_fp: 0.003117, loss_freq: 0.046784
[19:33:56.304] iteration 28000 : mean_dice : 0.733293
[19:33:56.953] iteration 28001: loss: 0.026308, loss_s1: 0.018165, loss_fp: 0.001163, loss_freq: 0.006444
[19:33:57.581] iteration 28002: loss: 0.036954, loss_s1: 0.032014, loss_fp: 0.002535, loss_freq: 0.006511
[19:33:58.203] iteration 28003: loss: 0.055718, loss_s1: 0.046267, loss_fp: 0.007757, loss_freq: 0.021588
[19:33:58.825] iteration 28004: loss: 0.052634, loss_s1: 0.032632, loss_fp: 0.008054, loss_freq: 0.035443
[19:33:59.451] iteration 28005: loss: 0.083924, loss_s1: 0.070504, loss_fp: 0.004315, loss_freq: 0.069059
[19:34:00.082] iteration 28006: loss: 0.044849, loss_s1: 0.033630, loss_fp: 0.005023, loss_freq: 0.021184
[19:34:00.716] iteration 28007: loss: 0.049667, loss_s1: 0.034278, loss_fp: 0.002648, loss_freq: 0.021782
[19:34:01.364] iteration 28008: loss: 0.024109, loss_s1: 0.008209, loss_fp: 0.000725, loss_freq: 0.002691
[19:34:02.003] iteration 28009: loss: 0.047842, loss_s1: 0.040492, loss_fp: 0.001229, loss_freq: 0.013703
[19:34:02.635] iteration 28010: loss: 0.037957, loss_s1: 0.023675, loss_fp: 0.000525, loss_freq: 0.015957
[19:34:03.268] iteration 28011: loss: 0.045724, loss_s1: 0.039955, loss_fp: 0.000345, loss_freq: 0.015762
[19:34:03.897] iteration 28012: loss: 0.069726, loss_s1: 0.049551, loss_fp: 0.019155, loss_freq: 0.039270
[19:34:04.519] iteration 28013: loss: 0.062471, loss_s1: 0.051173, loss_fp: 0.006304, loss_freq: 0.039724
[19:34:05.153] iteration 28014: loss: 0.043073, loss_s1: 0.032389, loss_fp: 0.001367, loss_freq: 0.016918
[19:34:06.107] iteration 28015: loss: 0.045305, loss_s1: 0.021122, loss_fp: 0.005346, loss_freq: 0.031490
[19:34:06.734] iteration 28016: loss: 0.077959, loss_s1: 0.083131, loss_fp: 0.001443, loss_freq: 0.029856
[19:34:07.368] iteration 28017: loss: 0.031593, loss_s1: 0.017641, loss_fp: 0.001381, loss_freq: 0.011375
[19:34:08.017] iteration 28018: loss: 0.035852, loss_s1: 0.012801, loss_fp: 0.005735, loss_freq: 0.014690
[19:34:08.661] iteration 28019: loss: 0.056127, loss_s1: 0.070848, loss_fp: 0.001905, loss_freq: 0.009712
[19:34:09.301] iteration 28020: loss: 0.088356, loss_s1: 0.058822, loss_fp: 0.008694, loss_freq: 0.045853
[19:34:09.942] iteration 28021: loss: 0.048509, loss_s1: 0.040011, loss_fp: 0.002149, loss_freq: 0.025349
[19:34:10.590] iteration 28022: loss: 0.052280, loss_s1: 0.054130, loss_fp: 0.004242, loss_freq: 0.019500
[19:34:11.228] iteration 28023: loss: 0.045106, loss_s1: 0.051419, loss_fp: 0.002620, loss_freq: 0.012767
[19:34:11.877] iteration 28024: loss: 0.037584, loss_s1: 0.021124, loss_fp: 0.006260, loss_freq: 0.014097
[19:34:12.518] iteration 28025: loss: 0.039630, loss_s1: 0.042641, loss_fp: 0.000678, loss_freq: 0.007965
[19:34:13.169] iteration 28026: loss: 0.058293, loss_s1: 0.041988, loss_fp: 0.008562, loss_freq: 0.026454
[19:34:13.799] iteration 28027: loss: 0.078680, loss_s1: 0.079987, loss_fp: 0.003879, loss_freq: 0.047769
[19:34:14.430] iteration 28028: loss: 0.050681, loss_s1: 0.024256, loss_fp: 0.006561, loss_freq: 0.029715
[19:34:15.052] iteration 28029: loss: 0.070063, loss_s1: 0.100886, loss_fp: 0.002870, loss_freq: 0.010248
[19:34:15.682] iteration 28030: loss: 0.074647, loss_s1: 0.050117, loss_fp: 0.004166, loss_freq: 0.065039
[19:34:16.313] iteration 28031: loss: 0.026694, loss_s1: 0.009218, loss_fp: 0.004757, loss_freq: 0.006077
[19:34:16.947] iteration 28032: loss: 0.052878, loss_s1: 0.055220, loss_fp: 0.002052, loss_freq: 0.020083
[19:34:17.576] iteration 28033: loss: 0.037007, loss_s1: 0.016729, loss_fp: 0.000990, loss_freq: 0.023523
[19:34:18.220] iteration 28034: loss: 0.061545, loss_s1: 0.034363, loss_fp: 0.009730, loss_freq: 0.036202
[19:34:18.854] iteration 28035: loss: 0.032771, loss_s1: 0.021584, loss_fp: 0.000642, loss_freq: 0.007675
[19:34:19.487] iteration 28036: loss: 0.037132, loss_s1: 0.013693, loss_fp: 0.005560, loss_freq: 0.018200
[19:34:20.110] iteration 28037: loss: 0.045136, loss_s1: 0.013464, loss_fp: 0.002688, loss_freq: 0.009094
[19:34:20.739] iteration 28038: loss: 0.048529, loss_s1: 0.042316, loss_fp: 0.001888, loss_freq: 0.020200
[19:34:21.367] iteration 28039: loss: 0.034770, loss_s1: 0.027599, loss_fp: 0.001676, loss_freq: 0.014374
[19:34:21.999] iteration 28040: loss: 0.060965, loss_s1: 0.024716, loss_fp: 0.000939, loss_freq: 0.072217
[19:34:22.650] iteration 28041: loss: 0.022517, loss_s1: 0.004953, loss_fp: 0.000165, loss_freq: 0.011548
[19:34:23.292] iteration 28042: loss: 0.065708, loss_s1: 0.066571, loss_fp: 0.008176, loss_freq: 0.023574
[19:34:23.926] iteration 28043: loss: 0.056093, loss_s1: 0.030283, loss_fp: 0.008400, loss_freq: 0.048927
[19:34:24.561] iteration 28044: loss: 0.042840, loss_s1: 0.031174, loss_fp: 0.004605, loss_freq: 0.006901
[19:34:25.190] iteration 28045: loss: 0.066229, loss_s1: 0.074137, loss_fp: 0.009403, loss_freq: 0.023016
[19:34:25.819] iteration 28046: loss: 0.035008, loss_s1: 0.015409, loss_fp: 0.003140, loss_freq: 0.017412
[19:34:26.447] iteration 28047: loss: 0.036635, loss_s1: 0.036501, loss_fp: 0.001456, loss_freq: 0.009989
[19:34:27.077] iteration 28048: loss: 0.025963, loss_s1: 0.009371, loss_fp: 0.000943, loss_freq: 0.008474
[19:34:27.711] iteration 28049: loss: 0.045202, loss_s1: 0.030044, loss_fp: 0.001567, loss_freq: 0.017118
[19:34:28.341] iteration 28050: loss: 0.054189, loss_s1: 0.053307, loss_fp: 0.005380, loss_freq: 0.022916
[19:34:28.971] iteration 28051: loss: 0.054915, loss_s1: 0.032624, loss_fp: 0.003536, loss_freq: 0.029810
[19:34:29.600] iteration 28052: loss: 0.069029, loss_s1: 0.058151, loss_fp: 0.009543, loss_freq: 0.040150
[19:34:30.227] iteration 28053: loss: 0.066658, loss_s1: 0.081553, loss_fp: 0.001514, loss_freq: 0.014189
[19:34:30.855] iteration 28054: loss: 0.062644, loss_s1: 0.070269, loss_fp: 0.008705, loss_freq: 0.014940
[19:34:31.483] iteration 28055: loss: 0.051079, loss_s1: 0.022358, loss_fp: 0.008047, loss_freq: 0.022490
[19:34:32.114] iteration 28056: loss: 0.056273, loss_s1: 0.048445, loss_fp: 0.009045, loss_freq: 0.029877
[19:34:32.750] iteration 28057: loss: 0.062968, loss_s1: 0.063103, loss_fp: 0.001748, loss_freq: 0.034814
[19:34:33.378] iteration 28058: loss: 0.040537, loss_s1: 0.025085, loss_fp: 0.003504, loss_freq: 0.028949
[19:34:34.002] iteration 28059: loss: 0.034887, loss_s1: 0.020126, loss_fp: 0.002149, loss_freq: 0.015876
[19:34:34.630] iteration 28060: loss: 0.033564, loss_s1: 0.025373, loss_fp: 0.002230, loss_freq: 0.004445
[19:34:35.258] iteration 28061: loss: 0.037745, loss_s1: 0.043999, loss_fp: 0.000484, loss_freq: 0.004997
[19:34:35.884] iteration 28062: loss: 0.055296, loss_s1: 0.057872, loss_fp: 0.003166, loss_freq: 0.024201
[19:34:36.515] iteration 28063: loss: 0.069983, loss_s1: 0.061172, loss_fp: 0.002633, loss_freq: 0.014100
[19:34:37.139] iteration 28064: loss: 0.050646, loss_s1: 0.033887, loss_fp: 0.005141, loss_freq: 0.034924
[19:34:37.768] iteration 28065: loss: 0.052062, loss_s1: 0.054804, loss_fp: 0.000571, loss_freq: 0.019640
[19:34:38.393] iteration 28066: loss: 0.043886, loss_s1: 0.032821, loss_fp: 0.000844, loss_freq: 0.022930
[19:34:39.019] iteration 28067: loss: 0.052809, loss_s1: 0.037355, loss_fp: 0.003511, loss_freq: 0.029953
[19:34:39.647] iteration 28068: loss: 0.072924, loss_s1: 0.044731, loss_fp: 0.005436, loss_freq: 0.047694
[19:34:40.274] iteration 28069: loss: 0.033399, loss_s1: 0.016142, loss_fp: 0.000827, loss_freq: 0.009236
[19:34:40.896] iteration 28070: loss: 0.078741, loss_s1: 0.062441, loss_fp: 0.008485, loss_freq: 0.045068
[19:34:41.521] iteration 28071: loss: 0.038740, loss_s1: 0.030353, loss_fp: 0.003216, loss_freq: 0.011118
[19:34:42.149] iteration 28072: loss: 0.037849, loss_s1: 0.010848, loss_fp: 0.004489, loss_freq: 0.011290
[19:34:42.814] iteration 28073: loss: 0.035449, loss_s1: 0.024387, loss_fp: 0.000491, loss_freq: 0.016070
[19:34:43.458] iteration 28074: loss: 0.031502, loss_s1: 0.014463, loss_fp: 0.002491, loss_freq: 0.016102
[19:34:44.106] iteration 28075: loss: 0.044959, loss_s1: 0.037267, loss_fp: 0.001183, loss_freq: 0.023695
[19:34:44.739] iteration 28076: loss: 0.035187, loss_s1: 0.024039, loss_fp: 0.008263, loss_freq: 0.010545
[19:34:45.405] iteration 28077: loss: 0.051974, loss_s1: 0.043487, loss_fp: 0.003005, loss_freq: 0.021373
[19:34:46.055] iteration 28078: loss: 0.072800, loss_s1: 0.085876, loss_fp: 0.011993, loss_freq: 0.012250
[19:34:46.684] iteration 28079: loss: 0.052574, loss_s1: 0.058131, loss_fp: 0.002948, loss_freq: 0.011008
[19:34:47.306] iteration 28080: loss: 0.057674, loss_s1: 0.025621, loss_fp: 0.013465, loss_freq: 0.040941
[19:34:47.929] iteration 28081: loss: 0.054494, loss_s1: 0.021004, loss_fp: 0.003851, loss_freq: 0.019910
[19:34:48.558] iteration 28082: loss: 0.053399, loss_s1: 0.039711, loss_fp: 0.013107, loss_freq: 0.030528
[19:34:49.183] iteration 28083: loss: 0.044175, loss_s1: 0.034024, loss_fp: 0.003354, loss_freq: 0.023905
[19:34:49.810] iteration 28084: loss: 0.047190, loss_s1: 0.019418, loss_fp: 0.001892, loss_freq: 0.018973
[19:34:50.438] iteration 28085: loss: 0.056433, loss_s1: 0.021767, loss_fp: 0.006741, loss_freq: 0.056872
[19:34:51.064] iteration 28086: loss: 0.048523, loss_s1: 0.036596, loss_fp: 0.002109, loss_freq: 0.029561
[19:34:51.688] iteration 28087: loss: 0.041730, loss_s1: 0.034474, loss_fp: 0.004463, loss_freq: 0.014857
[19:34:52.319] iteration 28088: loss: 0.040151, loss_s1: 0.033580, loss_fp: 0.000892, loss_freq: 0.008157
[19:34:52.938] iteration 28089: loss: 0.049911, loss_s1: 0.025995, loss_fp: 0.006353, loss_freq: 0.032428
[19:34:53.568] iteration 28090: loss: 0.077617, loss_s1: 0.102681, loss_fp: 0.004351, loss_freq: 0.004088
[19:34:54.193] iteration 28091: loss: 0.055019, loss_s1: 0.043857, loss_fp: 0.005155, loss_freq: 0.022987
[19:34:54.821] iteration 28092: loss: 0.050662, loss_s1: 0.064564, loss_fp: 0.000702, loss_freq: 0.010695
[19:34:55.486] iteration 28093: loss: 0.025175, loss_s1: 0.014778, loss_fp: 0.001971, loss_freq: 0.010961
[19:34:56.110] iteration 28094: loss: 0.049626, loss_s1: 0.032810, loss_fp: 0.001953, loss_freq: 0.033617
[19:34:56.739] iteration 28095: loss: 0.049325, loss_s1: 0.034108, loss_fp: 0.001668, loss_freq: 0.020190
[19:34:57.363] iteration 28096: loss: 0.065886, loss_s1: 0.077534, loss_fp: 0.004000, loss_freq: 0.017386
[19:34:57.989] iteration 28097: loss: 0.082312, loss_s1: 0.091581, loss_fp: 0.008125, loss_freq: 0.036446
[19:34:58.615] iteration 28098: loss: 0.048445, loss_s1: 0.045450, loss_fp: 0.003650, loss_freq: 0.007628
[19:34:59.241] iteration 28099: loss: 0.110177, loss_s1: 0.119702, loss_fp: 0.004289, loss_freq: 0.066771
[19:34:59.875] iteration 28100: loss: 0.032405, loss_s1: 0.013664, loss_fp: 0.000478, loss_freq: 0.014757
[19:35:00.505] iteration 28101: loss: 0.042947, loss_s1: 0.032262, loss_fp: 0.004513, loss_freq: 0.009224
[19:35:01.131] iteration 28102: loss: 0.030736, loss_s1: 0.022045, loss_fp: 0.005598, loss_freq: 0.006935
[19:35:01.760] iteration 28103: loss: 0.036772, loss_s1: 0.017245, loss_fp: 0.004715, loss_freq: 0.018128
[19:35:02.387] iteration 28104: loss: 0.055345, loss_s1: 0.040250, loss_fp: 0.005736, loss_freq: 0.034230
[19:35:03.012] iteration 28105: loss: 0.065969, loss_s1: 0.057510, loss_fp: 0.017282, loss_freq: 0.018004
[19:35:03.644] iteration 28106: loss: 0.074060, loss_s1: 0.049633, loss_fp: 0.017208, loss_freq: 0.046724
[19:35:04.285] iteration 28107: loss: 0.047072, loss_s1: 0.025876, loss_fp: 0.001376, loss_freq: 0.017791
[19:35:04.955] iteration 28108: loss: 0.047034, loss_s1: 0.033659, loss_fp: 0.002022, loss_freq: 0.023756
[19:35:05.593] iteration 28109: loss: 0.064576, loss_s1: 0.046416, loss_fp: 0.001478, loss_freq: 0.056427
[19:35:06.240] iteration 28110: loss: 0.054434, loss_s1: 0.022856, loss_fp: 0.013064, loss_freq: 0.047707
[19:35:06.868] iteration 28111: loss: 0.029139, loss_s1: 0.008634, loss_fp: 0.005966, loss_freq: 0.015882
[19:35:07.499] iteration 28112: loss: 0.038643, loss_s1: 0.017305, loss_fp: 0.002210, loss_freq: 0.022051
[19:35:08.129] iteration 28113: loss: 0.051637, loss_s1: 0.034771, loss_fp: 0.001158, loss_freq: 0.038836
[19:35:08.766] iteration 28114: loss: 0.051825, loss_s1: 0.040815, loss_fp: 0.002985, loss_freq: 0.020862
[19:35:09.394] iteration 28115: loss: 0.043407, loss_s1: 0.029894, loss_fp: 0.001851, loss_freq: 0.031439
[19:35:10.021] iteration 28116: loss: 0.096082, loss_s1: 0.082292, loss_fp: 0.005382, loss_freq: 0.061694
[19:35:10.652] iteration 28117: loss: 0.050170, loss_s1: 0.031389, loss_fp: 0.002545, loss_freq: 0.034186
[19:35:11.277] iteration 28118: loss: 0.047157, loss_s1: 0.049221, loss_fp: 0.001279, loss_freq: 0.017140
[19:35:11.899] iteration 28119: loss: 0.066109, loss_s1: 0.034068, loss_fp: 0.009033, loss_freq: 0.019793
[19:35:12.523] iteration 28120: loss: 0.042878, loss_s1: 0.045675, loss_fp: 0.005117, loss_freq: 0.007497
[19:35:13.147] iteration 28121: loss: 0.023421, loss_s1: 0.013430, loss_fp: 0.002996, loss_freq: 0.002767
[19:35:13.778] iteration 28122: loss: 0.052912, loss_s1: 0.053328, loss_fp: 0.000947, loss_freq: 0.018765
[19:35:14.406] iteration 28123: loss: 0.122263, loss_s1: 0.073088, loss_fp: 0.011371, loss_freq: 0.124549
[19:35:15.030] iteration 28124: loss: 0.057405, loss_s1: 0.047645, loss_fp: 0.004218, loss_freq: 0.033298
[19:35:15.655] iteration 28125: loss: 0.069604, loss_s1: 0.058642, loss_fp: 0.003265, loss_freq: 0.022717
[19:35:16.279] iteration 28126: loss: 0.052685, loss_s1: 0.045015, loss_fp: 0.005061, loss_freq: 0.021517
[19:35:16.907] iteration 28127: loss: 0.033311, loss_s1: 0.027762, loss_fp: 0.001734, loss_freq: 0.012599
[19:35:17.534] iteration 28128: loss: 0.044960, loss_s1: 0.034455, loss_fp: 0.002973, loss_freq: 0.019369
[19:35:18.159] iteration 28129: loss: 0.037437, loss_s1: 0.029267, loss_fp: 0.001860, loss_freq: 0.004636
[19:35:18.786] iteration 28130: loss: 0.063232, loss_s1: 0.048610, loss_fp: 0.004171, loss_freq: 0.038118
[19:35:19.411] iteration 28131: loss: 0.079106, loss_s1: 0.076402, loss_fp: 0.003472, loss_freq: 0.049272
[19:35:20.041] iteration 28132: loss: 0.053353, loss_s1: 0.049801, loss_fp: 0.007985, loss_freq: 0.020714
[19:35:20.663] iteration 28133: loss: 0.059880, loss_s1: 0.050727, loss_fp: 0.004014, loss_freq: 0.028750
[19:35:21.293] iteration 28134: loss: 0.075073, loss_s1: 0.051741, loss_fp: 0.004653, loss_freq: 0.062682
[19:35:21.918] iteration 28135: loss: 0.059350, loss_s1: 0.032987, loss_fp: 0.000776, loss_freq: 0.056579
[19:35:22.545] iteration 28136: loss: 0.049078, loss_s1: 0.042309, loss_fp: 0.004891, loss_freq: 0.012248
[19:35:23.174] iteration 28137: loss: 0.055069, loss_s1: 0.029818, loss_fp: 0.001895, loss_freq: 0.044142
[19:35:23.805] iteration 28138: loss: 0.052016, loss_s1: 0.065042, loss_fp: 0.003086, loss_freq: 0.002351
[19:35:24.436] iteration 28139: loss: 0.040021, loss_s1: 0.020273, loss_fp: 0.002478, loss_freq: 0.016945
[19:35:25.065] iteration 28140: loss: 0.058822, loss_s1: 0.071885, loss_fp: 0.004797, loss_freq: 0.007154
[19:35:25.691] iteration 28141: loss: 0.055352, loss_s1: 0.050882, loss_fp: 0.007888, loss_freq: 0.007319
[19:35:26.316] iteration 28142: loss: 0.049577, loss_s1: 0.019984, loss_fp: 0.008493, loss_freq: 0.019825
[19:35:26.939] iteration 28143: loss: 0.061412, loss_s1: 0.052321, loss_fp: 0.004605, loss_freq: 0.039263
[19:35:27.563] iteration 28144: loss: 0.036716, loss_s1: 0.018488, loss_fp: 0.008129, loss_freq: 0.020111
[19:35:28.188] iteration 28145: loss: 0.039037, loss_s1: 0.027159, loss_fp: 0.003852, loss_freq: 0.020381
[19:35:28.814] iteration 28146: loss: 0.072766, loss_s1: 0.093931, loss_fp: 0.003081, loss_freq: 0.020553
[19:35:29.437] iteration 28147: loss: 0.033060, loss_s1: 0.018514, loss_fp: 0.001400, loss_freq: 0.011203
[19:35:30.068] iteration 28148: loss: 0.040464, loss_s1: 0.023204, loss_fp: 0.001922, loss_freq: 0.026251
[19:35:30.694] iteration 28149: loss: 0.037091, loss_s1: 0.015736, loss_fp: 0.004067, loss_freq: 0.019332
[19:35:31.318] iteration 28150: loss: 0.036834, loss_s1: 0.021809, loss_fp: 0.007104, loss_freq: 0.017250
[19:35:31.947] iteration 28151: loss: 0.027441, loss_s1: 0.020709, loss_fp: 0.001035, loss_freq: 0.005366
[19:35:32.579] iteration 28152: loss: 0.035143, loss_s1: 0.027830, loss_fp: 0.004275, loss_freq: 0.012320
[19:35:33.205] iteration 28153: loss: 0.045088, loss_s1: 0.033306, loss_fp: 0.002358, loss_freq: 0.022294
[19:35:33.831] iteration 28154: loss: 0.098082, loss_s1: 0.092967, loss_fp: 0.005844, loss_freq: 0.049042
[19:35:34.453] iteration 28155: loss: 0.050644, loss_s1: 0.049319, loss_fp: 0.002070, loss_freq: 0.021456
[19:35:35.075] iteration 28156: loss: 0.040737, loss_s1: 0.028574, loss_fp: 0.001277, loss_freq: 0.022295
[19:35:35.706] iteration 28157: loss: 0.058044, loss_s1: 0.059660, loss_fp: 0.009649, loss_freq: 0.013160
[19:35:36.328] iteration 28158: loss: 0.069936, loss_s1: 0.069342, loss_fp: 0.006806, loss_freq: 0.028008
[19:35:36.951] iteration 28159: loss: 0.044296, loss_s1: 0.045347, loss_fp: 0.002434, loss_freq: 0.009598
[19:35:37.579] iteration 28160: loss: 0.039471, loss_s1: 0.026436, loss_fp: 0.001266, loss_freq: 0.016303
[19:35:38.217] iteration 28161: loss: 0.077311, loss_s1: 0.072882, loss_fp: 0.005329, loss_freq: 0.049054
[19:35:38.844] iteration 28162: loss: 0.031950, loss_s1: 0.010332, loss_fp: 0.003828, loss_freq: 0.008346
[19:35:39.465] iteration 28163: loss: 0.046369, loss_s1: 0.044603, loss_fp: 0.002512, loss_freq: 0.015942
[19:35:40.091] iteration 28164: loss: 0.070821, loss_s1: 0.051267, loss_fp: 0.002482, loss_freq: 0.048854
[19:35:40.714] iteration 28165: loss: 0.059550, loss_s1: 0.044799, loss_fp: 0.007256, loss_freq: 0.026638
[19:35:41.358] iteration 28166: loss: 0.058340, loss_s1: 0.057948, loss_fp: 0.002936, loss_freq: 0.021327
[19:35:41.983] iteration 28167: loss: 0.051651, loss_s1: 0.038436, loss_fp: 0.002382, loss_freq: 0.031450
[19:35:42.607] iteration 28168: loss: 0.047643, loss_s1: 0.024681, loss_fp: 0.001377, loss_freq: 0.024537
[19:35:43.232] iteration 28169: loss: 0.034897, loss_s1: 0.027078, loss_fp: 0.000689, loss_freq: 0.009983
[19:35:43.881] iteration 28170: loss: 0.054351, loss_s1: 0.054655, loss_fp: 0.001503, loss_freq: 0.014336
[19:35:44.514] iteration 28171: loss: 0.040987, loss_s1: 0.023548, loss_fp: 0.004037, loss_freq: 0.019904
[19:35:45.166] iteration 28172: loss: 0.048953, loss_s1: 0.039161, loss_fp: 0.003522, loss_freq: 0.020860
[19:35:45.839] iteration 28173: loss: 0.078885, loss_s1: 0.072159, loss_fp: 0.004528, loss_freq: 0.034928
[19:35:46.476] iteration 28174: loss: 0.047285, loss_s1: 0.037779, loss_fp: 0.011836, loss_freq: 0.019244
[19:35:47.102] iteration 28175: loss: 0.057618, loss_s1: 0.042652, loss_fp: 0.002289, loss_freq: 0.032614
[19:35:48.071] iteration 28176: loss: 0.048725, loss_s1: 0.025829, loss_fp: 0.001218, loss_freq: 0.031311
[19:35:48.714] iteration 28177: loss: 0.058677, loss_s1: 0.071695, loss_fp: 0.001432, loss_freq: 0.015513
[19:35:49.351] iteration 28178: loss: 0.038519, loss_s1: 0.038348, loss_fp: 0.002446, loss_freq: 0.004941
[19:35:49.999] iteration 28179: loss: 0.045910, loss_s1: 0.025724, loss_fp: 0.001698, loss_freq: 0.020749
[19:35:50.637] iteration 28180: loss: 0.045442, loss_s1: 0.024939, loss_fp: 0.003886, loss_freq: 0.024471
[19:35:51.266] iteration 28181: loss: 0.093711, loss_s1: 0.071509, loss_fp: 0.010284, loss_freq: 0.042193
[19:35:51.891] iteration 28182: loss: 0.042012, loss_s1: 0.040311, loss_fp: 0.002018, loss_freq: 0.017035
[19:35:52.520] iteration 28183: loss: 0.026886, loss_s1: 0.007198, loss_fp: 0.007975, loss_freq: 0.010483
[19:35:53.146] iteration 28184: loss: 0.038492, loss_s1: 0.025633, loss_fp: 0.003452, loss_freq: 0.017412
[19:35:53.773] iteration 28185: loss: 0.039446, loss_s1: 0.016303, loss_fp: 0.001891, loss_freq: 0.019645
[19:35:54.400] iteration 28186: loss: 0.045672, loss_s1: 0.045603, loss_fp: 0.001266, loss_freq: 0.014137
[19:35:55.027] iteration 28187: loss: 0.054908, loss_s1: 0.061863, loss_fp: 0.000980, loss_freq: 0.021497
[19:35:55.656] iteration 28188: loss: 0.067317, loss_s1: 0.048353, loss_fp: 0.002666, loss_freq: 0.057386
[19:35:56.287] iteration 28189: loss: 0.055101, loss_s1: 0.042091, loss_fp: 0.003468, loss_freq: 0.033162
[19:35:56.917] iteration 28190: loss: 0.040900, loss_s1: 0.028149, loss_fp: 0.004834, loss_freq: 0.017918
[19:35:57.544] iteration 28191: loss: 0.070114, loss_s1: 0.034125, loss_fp: 0.004720, loss_freq: 0.072898
[19:35:58.171] iteration 28192: loss: 0.034917, loss_s1: 0.024651, loss_fp: 0.002723, loss_freq: 0.008988
[19:35:58.801] iteration 28193: loss: 0.042929, loss_s1: 0.027324, loss_fp: 0.004778, loss_freq: 0.023952
[19:35:59.432] iteration 28194: loss: 0.039322, loss_s1: 0.021642, loss_fp: 0.005017, loss_freq: 0.020017
[19:36:00.064] iteration 28195: loss: 0.041241, loss_s1: 0.036696, loss_fp: 0.002943, loss_freq: 0.013797
[19:36:00.699] iteration 28196: loss: 0.057531, loss_s1: 0.066608, loss_fp: 0.001358, loss_freq: 0.010891
[19:36:01.329] iteration 28197: loss: 0.056677, loss_s1: 0.042304, loss_fp: 0.002482, loss_freq: 0.036198
[19:36:01.962] iteration 28198: loss: 0.039351, loss_s1: 0.021519, loss_fp: 0.002401, loss_freq: 0.011179
[19:36:02.599] iteration 28199: loss: 0.069528, loss_s1: 0.089647, loss_fp: 0.006582, loss_freq: 0.015364
[19:36:03.226] iteration 28200: loss: 0.038143, loss_s1: 0.035268, loss_fp: 0.002815, loss_freq: 0.016188
[19:36:06.401] iteration 28200 : mean_dice : 0.737001
[19:36:07.064] iteration 28201: loss: 0.034922, loss_s1: 0.030743, loss_fp: 0.005105, loss_freq: 0.008300
[19:36:07.690] iteration 28202: loss: 0.027921, loss_s1: 0.018752, loss_fp: 0.000952, loss_freq: 0.006950
[19:36:08.319] iteration 28203: loss: 0.064471, loss_s1: 0.050215, loss_fp: 0.012048, loss_freq: 0.025259
[19:36:08.945] iteration 28204: loss: 0.052780, loss_s1: 0.039671, loss_fp: 0.005797, loss_freq: 0.028064
[19:36:09.573] iteration 28205: loss: 0.044592, loss_s1: 0.031861, loss_fp: 0.005665, loss_freq: 0.022168
[19:36:10.200] iteration 28206: loss: 0.033116, loss_s1: 0.025577, loss_fp: 0.002067, loss_freq: 0.012830
[19:36:10.828] iteration 28207: loss: 0.044749, loss_s1: 0.022712, loss_fp: 0.001645, loss_freq: 0.014051
[19:36:11.459] iteration 28208: loss: 0.025905, loss_s1: 0.014604, loss_fp: 0.000332, loss_freq: 0.012106
[19:36:12.095] iteration 28209: loss: 0.039981, loss_s1: 0.039299, loss_fp: 0.000535, loss_freq: 0.008633
[19:36:12.728] iteration 28210: loss: 0.053857, loss_s1: 0.034762, loss_fp: 0.008207, loss_freq: 0.024401
[19:36:13.353] iteration 28211: loss: 0.054553, loss_s1: 0.033450, loss_fp: 0.007228, loss_freq: 0.036129
[19:36:13.973] iteration 28212: loss: 0.078869, loss_s1: 0.039529, loss_fp: 0.004979, loss_freq: 0.061627
[19:36:14.598] iteration 28213: loss: 0.055504, loss_s1: 0.053650, loss_fp: 0.002845, loss_freq: 0.026416
[19:36:15.223] iteration 28214: loss: 0.070781, loss_s1: 0.042660, loss_fp: 0.003488, loss_freq: 0.060982
[19:36:15.850] iteration 28215: loss: 0.038695, loss_s1: 0.016641, loss_fp: 0.001447, loss_freq: 0.028035
[19:36:16.479] iteration 28216: loss: 0.040450, loss_s1: 0.016408, loss_fp: 0.003979, loss_freq: 0.015199
[19:36:17.104] iteration 28217: loss: 0.060581, loss_s1: 0.072165, loss_fp: 0.002320, loss_freq: 0.021439
[19:36:17.755] iteration 28218: loss: 0.057905, loss_s1: 0.063571, loss_fp: 0.004214, loss_freq: 0.015532
[19:36:18.389] iteration 28219: loss: 0.060387, loss_s1: 0.046656, loss_fp: 0.002303, loss_freq: 0.040302
[19:36:19.016] iteration 28220: loss: 0.055567, loss_s1: 0.031425, loss_fp: 0.003268, loss_freq: 0.042999
[19:36:19.648] iteration 28221: loss: 0.037517, loss_s1: 0.032799, loss_fp: 0.004121, loss_freq: 0.004546
[19:36:20.276] iteration 28222: loss: 0.035360, loss_s1: 0.035181, loss_fp: 0.003452, loss_freq: 0.007630
[19:36:20.907] iteration 28223: loss: 0.027911, loss_s1: 0.015459, loss_fp: 0.005517, loss_freq: 0.009188
[19:36:21.545] iteration 28224: loss: 0.059665, loss_s1: 0.042807, loss_fp: 0.004485, loss_freq: 0.033219
[19:36:22.180] iteration 28225: loss: 0.049169, loss_s1: 0.037341, loss_fp: 0.003922, loss_freq: 0.034115
[19:36:22.815] iteration 28226: loss: 0.034139, loss_s1: 0.010152, loss_fp: 0.004737, loss_freq: 0.019537
[19:36:23.457] iteration 28227: loss: 0.058808, loss_s1: 0.041129, loss_fp: 0.001492, loss_freq: 0.025049
[19:36:24.095] iteration 28228: loss: 0.041433, loss_s1: 0.023749, loss_fp: 0.002814, loss_freq: 0.025322
[19:36:24.726] iteration 28229: loss: 0.066870, loss_s1: 0.043609, loss_fp: 0.006311, loss_freq: 0.050670
[19:36:25.354] iteration 28230: loss: 0.041132, loss_s1: 0.037428, loss_fp: 0.001167, loss_freq: 0.013307
[19:36:25.982] iteration 28231: loss: 0.047451, loss_s1: 0.036828, loss_fp: 0.002509, loss_freq: 0.022955
[19:36:26.615] iteration 28232: loss: 0.040557, loss_s1: 0.029884, loss_fp: 0.003198, loss_freq: 0.011429
[19:36:27.247] iteration 28233: loss: 0.042425, loss_s1: 0.024637, loss_fp: 0.000969, loss_freq: 0.012985
[19:36:27.880] iteration 28234: loss: 0.021819, loss_s1: 0.011914, loss_fp: 0.000382, loss_freq: 0.003293
[19:36:28.518] iteration 28235: loss: 0.036039, loss_s1: 0.025812, loss_fp: 0.002103, loss_freq: 0.016805
[19:36:29.148] iteration 28236: loss: 0.031039, loss_s1: 0.023489, loss_fp: 0.000556, loss_freq: 0.015610
[19:36:29.777] iteration 28237: loss: 0.066262, loss_s1: 0.054424, loss_fp: 0.004321, loss_freq: 0.033871
[19:36:30.410] iteration 28238: loss: 0.037212, loss_s1: 0.018636, loss_fp: 0.000609, loss_freq: 0.023297
[19:36:31.045] iteration 28239: loss: 0.040560, loss_s1: 0.023507, loss_fp: 0.002216, loss_freq: 0.013621
[19:36:31.681] iteration 28240: loss: 0.029544, loss_s1: 0.018371, loss_fp: 0.004436, loss_freq: 0.007052
[19:36:32.316] iteration 28241: loss: 0.039568, loss_s1: 0.013135, loss_fp: 0.002876, loss_freq: 0.035325
[19:36:32.940] iteration 28242: loss: 0.042705, loss_s1: 0.022124, loss_fp: 0.001119, loss_freq: 0.019447
[19:36:33.567] iteration 28243: loss: 0.058561, loss_s1: 0.039586, loss_fp: 0.009886, loss_freq: 0.039920
[19:36:34.199] iteration 28244: loss: 0.038978, loss_s1: 0.027872, loss_fp: 0.003612, loss_freq: 0.011473
[19:36:34.825] iteration 28245: loss: 0.045772, loss_s1: 0.030746, loss_fp: 0.001856, loss_freq: 0.017676
[19:36:35.451] iteration 28246: loss: 0.066639, loss_s1: 0.029051, loss_fp: 0.007895, loss_freq: 0.062380
[19:36:36.080] iteration 28247: loss: 0.055657, loss_s1: 0.071502, loss_fp: 0.001837, loss_freq: 0.008096
[19:36:36.710] iteration 28248: loss: 0.038081, loss_s1: 0.025304, loss_fp: 0.001175, loss_freq: 0.014762
[19:36:37.342] iteration 28249: loss: 0.041323, loss_s1: 0.022133, loss_fp: 0.003864, loss_freq: 0.013838
[19:36:37.974] iteration 28250: loss: 0.057597, loss_s1: 0.047969, loss_fp: 0.006944, loss_freq: 0.027482
[19:36:38.625] iteration 28251: loss: 0.052883, loss_s1: 0.043697, loss_fp: 0.001541, loss_freq: 0.014180
[19:36:39.256] iteration 28252: loss: 0.054487, loss_s1: 0.043266, loss_fp: 0.004594, loss_freq: 0.032449
[19:36:39.888] iteration 28253: loss: 0.039227, loss_s1: 0.031254, loss_fp: 0.004854, loss_freq: 0.008867
[19:36:40.516] iteration 28254: loss: 0.025296, loss_s1: 0.015834, loss_fp: 0.000482, loss_freq: 0.008692
[19:36:41.148] iteration 28255: loss: 0.076940, loss_s1: 0.064713, loss_fp: 0.012805, loss_freq: 0.039706
[19:36:41.783] iteration 28256: loss: 0.052010, loss_s1: 0.038991, loss_fp: 0.004658, loss_freq: 0.017342
[19:36:42.415] iteration 28257: loss: 0.058061, loss_s1: 0.040162, loss_fp: 0.003275, loss_freq: 0.044484
[19:36:43.060] iteration 28258: loss: 0.066483, loss_s1: 0.068487, loss_fp: 0.018843, loss_freq: 0.017031
[19:36:43.702] iteration 28259: loss: 0.070374, loss_s1: 0.067624, loss_fp: 0.002308, loss_freq: 0.036753
[19:36:44.336] iteration 28260: loss: 0.092240, loss_s1: 0.107689, loss_fp: 0.009978, loss_freq: 0.043866
[19:36:44.965] iteration 28261: loss: 0.061507, loss_s1: 0.076580, loss_fp: 0.000734, loss_freq: 0.016248
[19:36:45.595] iteration 28262: loss: 0.084757, loss_s1: 0.042614, loss_fp: 0.007245, loss_freq: 0.073201
[19:36:46.221] iteration 28263: loss: 0.068722, loss_s1: 0.051530, loss_fp: 0.003276, loss_freq: 0.032558
[19:36:46.850] iteration 28264: loss: 0.055056, loss_s1: 0.041276, loss_fp: 0.007480, loss_freq: 0.026490
[19:36:47.480] iteration 28265: loss: 0.048528, loss_s1: 0.040311, loss_fp: 0.003517, loss_freq: 0.021673
[19:36:48.109] iteration 28266: loss: 0.067577, loss_s1: 0.060026, loss_fp: 0.006619, loss_freq: 0.028398
[19:36:48.744] iteration 28267: loss: 0.078248, loss_s1: 0.063171, loss_fp: 0.009369, loss_freq: 0.046058
[19:36:49.393] iteration 28268: loss: 0.035851, loss_s1: 0.015562, loss_fp: 0.000466, loss_freq: 0.011269
[19:36:50.024] iteration 28269: loss: 0.029066, loss_s1: 0.018013, loss_fp: 0.003351, loss_freq: 0.008605
[19:36:50.653] iteration 28270: loss: 0.055006, loss_s1: 0.050230, loss_fp: 0.003841, loss_freq: 0.028471
[19:36:51.288] iteration 28271: loss: 0.039756, loss_s1: 0.022860, loss_fp: 0.003760, loss_freq: 0.028996
[19:36:51.923] iteration 28272: loss: 0.031938, loss_s1: 0.009750, loss_fp: 0.004595, loss_freq: 0.020314
[19:36:52.552] iteration 28273: loss: 0.045276, loss_s1: 0.013067, loss_fp: 0.002214, loss_freq: 0.038078
[19:36:53.180] iteration 28274: loss: 0.061539, loss_s1: 0.058483, loss_fp: 0.001030, loss_freq: 0.037625
[19:36:53.808] iteration 28275: loss: 0.066722, loss_s1: 0.060278, loss_fp: 0.002291, loss_freq: 0.034663
[19:36:54.437] iteration 28276: loss: 0.062029, loss_s1: 0.067834, loss_fp: 0.004034, loss_freq: 0.025804
[19:36:55.075] iteration 28277: loss: 0.070993, loss_s1: 0.054306, loss_fp: 0.011535, loss_freq: 0.036329
[19:36:55.704] iteration 28278: loss: 0.092555, loss_s1: 0.085897, loss_fp: 0.015533, loss_freq: 0.050278
[19:36:56.360] iteration 28279: loss: 0.045739, loss_s1: 0.040992, loss_fp: 0.005377, loss_freq: 0.012242
[19:36:56.991] iteration 28280: loss: 0.029915, loss_s1: 0.012801, loss_fp: 0.002491, loss_freq: 0.009451
[19:36:57.632] iteration 28281: loss: 0.035635, loss_s1: 0.013482, loss_fp: 0.002704, loss_freq: 0.026732
[19:36:58.273] iteration 28282: loss: 0.034836, loss_s1: 0.031408, loss_fp: 0.001302, loss_freq: 0.004594
[19:36:58.912] iteration 28283: loss: 0.063629, loss_s1: 0.073860, loss_fp: 0.002710, loss_freq: 0.016971
[19:36:59.577] iteration 28284: loss: 0.105225, loss_s1: 0.083924, loss_fp: 0.014944, loss_freq: 0.073410
[19:37:00.203] iteration 28285: loss: 0.052753, loss_s1: 0.026174, loss_fp: 0.001623, loss_freq: 0.027729
[19:37:00.831] iteration 28286: loss: 0.038560, loss_s1: 0.029600, loss_fp: 0.002919, loss_freq: 0.007303
[19:37:01.456] iteration 28287: loss: 0.041374, loss_s1: 0.024345, loss_fp: 0.002269, loss_freq: 0.024400
[19:37:02.079] iteration 28288: loss: 0.044711, loss_s1: 0.029045, loss_fp: 0.002429, loss_freq: 0.026648
[19:37:02.707] iteration 28289: loss: 0.039930, loss_s1: 0.030476, loss_fp: 0.001402, loss_freq: 0.027828
[19:37:03.336] iteration 28290: loss: 0.026724, loss_s1: 0.012327, loss_fp: 0.001198, loss_freq: 0.006527
[19:37:03.960] iteration 28291: loss: 0.048120, loss_s1: 0.041255, loss_fp: 0.003311, loss_freq: 0.018938
[19:37:04.584] iteration 28292: loss: 0.041484, loss_s1: 0.044569, loss_fp: 0.000703, loss_freq: 0.008682
[19:37:05.209] iteration 28293: loss: 0.032230, loss_s1: 0.031252, loss_fp: 0.001712, loss_freq: 0.009481
[19:37:05.836] iteration 28294: loss: 0.065455, loss_s1: 0.066198, loss_fp: 0.008682, loss_freq: 0.026211
[19:37:06.461] iteration 28295: loss: 0.079405, loss_s1: 0.041359, loss_fp: 0.006578, loss_freq: 0.078124
[19:37:07.085] iteration 28296: loss: 0.035211, loss_s1: 0.026806, loss_fp: 0.001095, loss_freq: 0.009639
[19:37:07.712] iteration 28297: loss: 0.054512, loss_s1: 0.043283, loss_fp: 0.001789, loss_freq: 0.024515
[19:37:08.346] iteration 28298: loss: 0.086426, loss_s1: 0.071588, loss_fp: 0.005838, loss_freq: 0.067556
[19:37:08.970] iteration 28299: loss: 0.030897, loss_s1: 0.023340, loss_fp: 0.001231, loss_freq: 0.007842
[19:37:09.592] iteration 28300: loss: 0.052131, loss_s1: 0.034957, loss_fp: 0.003073, loss_freq: 0.035192
[19:37:10.220] iteration 28301: loss: 0.050657, loss_s1: 0.056112, loss_fp: 0.002155, loss_freq: 0.011828
[19:37:10.851] iteration 28302: loss: 0.055568, loss_s1: 0.047137, loss_fp: 0.001424, loss_freq: 0.028100
[19:37:11.485] iteration 28303: loss: 0.064002, loss_s1: 0.067913, loss_fp: 0.001757, loss_freq: 0.016613
[19:37:12.119] iteration 28304: loss: 0.063932, loss_s1: 0.066663, loss_fp: 0.002188, loss_freq: 0.033021
[19:37:12.756] iteration 28305: loss: 0.044210, loss_s1: 0.032979, loss_fp: 0.002600, loss_freq: 0.027785
[19:37:13.393] iteration 28306: loss: 0.053415, loss_s1: 0.050626, loss_fp: 0.004974, loss_freq: 0.026051
[19:37:14.020] iteration 28307: loss: 0.066666, loss_s1: 0.086233, loss_fp: 0.003934, loss_freq: 0.013991
[19:37:14.645] iteration 28308: loss: 0.065811, loss_s1: 0.059652, loss_fp: 0.004052, loss_freq: 0.029337
[19:37:15.276] iteration 28309: loss: 0.028735, loss_s1: 0.023918, loss_fp: 0.001766, loss_freq: 0.005688
[19:37:15.903] iteration 28310: loss: 0.040985, loss_s1: 0.026743, loss_fp: 0.002869, loss_freq: 0.023771
[19:37:16.527] iteration 28311: loss: 0.038294, loss_s1: 0.030218, loss_fp: 0.001847, loss_freq: 0.015703
[19:37:17.171] iteration 28312: loss: 0.039857, loss_s1: 0.022267, loss_fp: 0.005768, loss_freq: 0.008193
[19:37:17.802] iteration 28313: loss: 0.035301, loss_s1: 0.029687, loss_fp: 0.003494, loss_freq: 0.014049
[19:37:18.446] iteration 28314: loss: 0.040478, loss_s1: 0.026715, loss_fp: 0.002438, loss_freq: 0.023716
[19:37:19.087] iteration 28315: loss: 0.065249, loss_s1: 0.059130, loss_fp: 0.007567, loss_freq: 0.026990
[19:37:19.720] iteration 28316: loss: 0.042511, loss_s1: 0.040124, loss_fp: 0.002744, loss_freq: 0.014301
[19:37:20.342] iteration 28317: loss: 0.033747, loss_s1: 0.020853, loss_fp: 0.002639, loss_freq: 0.006746
[19:37:20.970] iteration 28318: loss: 0.062971, loss_s1: 0.049523, loss_fp: 0.001511, loss_freq: 0.043353
[19:37:21.596] iteration 28319: loss: 0.041734, loss_s1: 0.035949, loss_fp: 0.003746, loss_freq: 0.010368
[19:37:22.227] iteration 28320: loss: 0.069676, loss_s1: 0.039742, loss_fp: 0.001579, loss_freq: 0.018288
[19:37:22.854] iteration 28321: loss: 0.056140, loss_s1: 0.025755, loss_fp: 0.012163, loss_freq: 0.039514
[19:37:23.483] iteration 28322: loss: 0.064614, loss_s1: 0.050564, loss_fp: 0.004267, loss_freq: 0.045005
[19:37:24.107] iteration 28323: loss: 0.026797, loss_s1: 0.010814, loss_fp: 0.000703, loss_freq: 0.009817
[19:37:24.734] iteration 28324: loss: 0.031254, loss_s1: 0.015665, loss_fp: 0.000770, loss_freq: 0.014015
[19:37:25.360] iteration 28325: loss: 0.045508, loss_s1: 0.016951, loss_fp: 0.002526, loss_freq: 0.036549
[19:37:26.033] iteration 28326: loss: 0.055012, loss_s1: 0.041298, loss_fp: 0.003070, loss_freq: 0.038678
[19:37:26.687] iteration 28327: loss: 0.076497, loss_s1: 0.064704, loss_fp: 0.001865, loss_freq: 0.062291
[19:37:27.320] iteration 28328: loss: 0.057199, loss_s1: 0.060867, loss_fp: 0.003117, loss_freq: 0.014471
[19:37:27.956] iteration 28329: loss: 0.050933, loss_s1: 0.043510, loss_fp: 0.001504, loss_freq: 0.015577
[19:37:28.618] iteration 28330: loss: 0.021487, loss_s1: 0.006355, loss_fp: 0.001770, loss_freq: 0.008384
[19:37:29.252] iteration 28331: loss: 0.051098, loss_s1: 0.059092, loss_fp: 0.002374, loss_freq: 0.007347
[19:37:29.884] iteration 28332: loss: 0.036366, loss_s1: 0.018031, loss_fp: 0.001050, loss_freq: 0.014067
[19:37:30.517] iteration 28333: loss: 0.042431, loss_s1: 0.018003, loss_fp: 0.001000, loss_freq: 0.026419
[19:37:31.157] iteration 28334: loss: 0.081204, loss_s1: 0.078083, loss_fp: 0.025155, loss_freq: 0.030065
[19:37:31.789] iteration 28335: loss: 0.068340, loss_s1: 0.066901, loss_fp: 0.008360, loss_freq: 0.031549
[19:37:32.418] iteration 28336: loss: 0.059309, loss_s1: 0.047429, loss_fp: 0.001321, loss_freq: 0.035524
[19:37:33.400] iteration 28337: loss: 0.040903, loss_s1: 0.024817, loss_fp: 0.001628, loss_freq: 0.031865
[19:37:34.032] iteration 28338: loss: 0.055404, loss_s1: 0.039098, loss_fp: 0.008563, loss_freq: 0.027455
[19:37:34.695] iteration 28339: loss: 0.036971, loss_s1: 0.036895, loss_fp: 0.003871, loss_freq: 0.005627
[19:37:35.327] iteration 28340: loss: 0.041982, loss_s1: 0.028696, loss_fp: 0.001811, loss_freq: 0.019492
[19:37:35.959] iteration 28341: loss: 0.049181, loss_s1: 0.033434, loss_fp: 0.005455, loss_freq: 0.031826
[19:37:36.591] iteration 28342: loss: 0.084720, loss_s1: 0.048257, loss_fp: 0.003333, loss_freq: 0.048032
[19:37:37.225] iteration 28343: loss: 0.048853, loss_s1: 0.047644, loss_fp: 0.005044, loss_freq: 0.015954
[19:37:37.861] iteration 28344: loss: 0.039315, loss_s1: 0.027892, loss_fp: 0.006540, loss_freq: 0.008712
[19:37:38.490] iteration 28345: loss: 0.060750, loss_s1: 0.060221, loss_fp: 0.002205, loss_freq: 0.037063
[19:37:39.121] iteration 28346: loss: 0.083828, loss_s1: 0.107932, loss_fp: 0.005159, loss_freq: 0.019064
[19:37:39.756] iteration 28347: loss: 0.038276, loss_s1: 0.015407, loss_fp: 0.001169, loss_freq: 0.026970
[19:37:40.416] iteration 28348: loss: 0.066381, loss_s1: 0.081531, loss_fp: 0.002692, loss_freq: 0.022333
[19:37:41.058] iteration 28349: loss: 0.064657, loss_s1: 0.041093, loss_fp: 0.007627, loss_freq: 0.053660
[19:37:41.696] iteration 28350: loss: 0.047142, loss_s1: 0.037160, loss_fp: 0.009736, loss_freq: 0.011278
[19:37:42.325] iteration 28351: loss: 0.057740, loss_s1: 0.065328, loss_fp: 0.002818, loss_freq: 0.019643
[19:37:42.961] iteration 28352: loss: 0.098397, loss_s1: 0.044069, loss_fp: 0.011797, loss_freq: 0.109525
[19:37:43.590] iteration 28353: loss: 0.060610, loss_s1: 0.060067, loss_fp: 0.004264, loss_freq: 0.021890
[19:37:44.220] iteration 28354: loss: 0.053792, loss_s1: 0.031372, loss_fp: 0.002152, loss_freq: 0.039711
[19:37:44.851] iteration 28355: loss: 0.041727, loss_s1: 0.018905, loss_fp: 0.000656, loss_freq: 0.021721
[19:37:45.479] iteration 28356: loss: 0.043746, loss_s1: 0.038146, loss_fp: 0.001045, loss_freq: 0.020038
[19:37:46.110] iteration 28357: loss: 0.025878, loss_s1: 0.010486, loss_fp: 0.000916, loss_freq: 0.005678
[19:37:46.742] iteration 28358: loss: 0.050376, loss_s1: 0.037909, loss_fp: 0.001568, loss_freq: 0.023490
[19:37:47.372] iteration 28359: loss: 0.038861, loss_s1: 0.018347, loss_fp: 0.000560, loss_freq: 0.021607
[19:37:48.090] iteration 28360: loss: 0.054251, loss_s1: 0.036109, loss_fp: 0.006112, loss_freq: 0.039563
[19:37:48.780] iteration 28361: loss: 0.043264, loss_s1: 0.035490, loss_fp: 0.001503, loss_freq: 0.016443
[19:37:49.418] iteration 28362: loss: 0.087254, loss_s1: 0.103238, loss_fp: 0.003520, loss_freq: 0.016922
[19:37:50.057] iteration 28363: loss: 0.041635, loss_s1: 0.044384, loss_fp: 0.001315, loss_freq: 0.003929
[19:37:50.743] iteration 28364: loss: 0.076286, loss_s1: 0.064711, loss_fp: 0.003157, loss_freq: 0.051725
[19:37:51.364] iteration 28365: loss: 0.061795, loss_s1: 0.047724, loss_fp: 0.002481, loss_freq: 0.044888
[19:37:51.984] iteration 28366: loss: 0.035415, loss_s1: 0.019065, loss_fp: 0.002092, loss_freq: 0.016171
[19:37:52.608] iteration 28367: loss: 0.046253, loss_s1: 0.043848, loss_fp: 0.002327, loss_freq: 0.017057
[19:37:53.234] iteration 28368: loss: 0.034030, loss_s1: 0.020383, loss_fp: 0.003983, loss_freq: 0.011184
[19:37:53.861] iteration 28369: loss: 0.047455, loss_s1: 0.039814, loss_fp: 0.002095, loss_freq: 0.024722
[19:37:54.493] iteration 28370: loss: 0.051452, loss_s1: 0.063018, loss_fp: 0.001664, loss_freq: 0.005989
[19:37:55.122] iteration 28371: loss: 0.072706, loss_s1: 0.055331, loss_fp: 0.007052, loss_freq: 0.045487
[19:37:55.753] iteration 28372: loss: 0.061479, loss_s1: 0.031693, loss_fp: 0.003988, loss_freq: 0.060436
[19:37:56.377] iteration 28373: loss: 0.059237, loss_s1: 0.053418, loss_fp: 0.004792, loss_freq: 0.027569
[19:37:57.005] iteration 28374: loss: 0.057805, loss_s1: 0.050631, loss_fp: 0.000786, loss_freq: 0.018893
[19:37:57.628] iteration 28375: loss: 0.053491, loss_s1: 0.052797, loss_fp: 0.002565, loss_freq: 0.014667
[19:37:58.258] iteration 28376: loss: 0.055658, loss_s1: 0.049592, loss_fp: 0.003496, loss_freq: 0.021152
[19:37:58.888] iteration 28377: loss: 0.037798, loss_s1: 0.017719, loss_fp: 0.003456, loss_freq: 0.013311
[19:37:59.550] iteration 28378: loss: 0.091381, loss_s1: 0.111157, loss_fp: 0.007261, loss_freq: 0.027141
[19:38:00.211] iteration 28379: loss: 0.067836, loss_s1: 0.064806, loss_fp: 0.003449, loss_freq: 0.037903
[19:38:00.874] iteration 28380: loss: 0.043707, loss_s1: 0.022811, loss_fp: 0.001429, loss_freq: 0.023894
[19:38:01.530] iteration 28381: loss: 0.059894, loss_s1: 0.027847, loss_fp: 0.004435, loss_freq: 0.053120
[19:38:02.170] iteration 28382: loss: 0.046629, loss_s1: 0.048281, loss_fp: 0.003383, loss_freq: 0.005498
[19:38:02.801] iteration 28383: loss: 0.036069, loss_s1: 0.038278, loss_fp: 0.000722, loss_freq: 0.006692
[19:38:03.435] iteration 28384: loss: 0.031120, loss_s1: 0.020489, loss_fp: 0.001379, loss_freq: 0.015268
[19:38:04.059] iteration 28385: loss: 0.075937, loss_s1: 0.087447, loss_fp: 0.002326, loss_freq: 0.027790
[19:38:04.689] iteration 28386: loss: 0.042020, loss_s1: 0.014094, loss_fp: 0.001092, loss_freq: 0.046474
[19:38:05.318] iteration 28387: loss: 0.076479, loss_s1: 0.060585, loss_fp: 0.006540, loss_freq: 0.058324
[19:38:05.946] iteration 28388: loss: 0.043216, loss_s1: 0.027744, loss_fp: 0.000884, loss_freq: 0.024033
[19:38:06.574] iteration 28389: loss: 0.046897, loss_s1: 0.040037, loss_fp: 0.002607, loss_freq: 0.021210
[19:38:07.207] iteration 28390: loss: 0.061388, loss_s1: 0.029443, loss_fp: 0.004138, loss_freq: 0.057787
[19:38:07.837] iteration 28391: loss: 0.025630, loss_s1: 0.007925, loss_fp: 0.001147, loss_freq: 0.014137
[19:38:08.464] iteration 28392: loss: 0.069464, loss_s1: 0.051818, loss_fp: 0.010802, loss_freq: 0.040269
[19:38:09.091] iteration 28393: loss: 0.048587, loss_s1: 0.044107, loss_fp: 0.007658, loss_freq: 0.011270
[19:38:09.720] iteration 28394: loss: 0.065249, loss_s1: 0.032264, loss_fp: 0.002206, loss_freq: 0.057972
[19:38:10.343] iteration 28395: loss: 0.029892, loss_s1: 0.022596, loss_fp: 0.001957, loss_freq: 0.005246
[19:38:10.972] iteration 28396: loss: 0.043893, loss_s1: 0.035635, loss_fp: 0.000789, loss_freq: 0.021365
[19:38:11.599] iteration 28397: loss: 0.039962, loss_s1: 0.030789, loss_fp: 0.000941, loss_freq: 0.021860
[19:38:12.225] iteration 28398: loss: 0.038145, loss_s1: 0.022624, loss_fp: 0.002868, loss_freq: 0.015962
[19:38:12.857] iteration 28399: loss: 0.032311, loss_s1: 0.007905, loss_fp: 0.001622, loss_freq: 0.013339
[19:38:13.486] iteration 28400: loss: 0.046393, loss_s1: 0.034249, loss_fp: 0.007899, loss_freq: 0.017540
[19:38:16.811] iteration 28400 : mean_dice : 0.733023
[19:38:17.474] iteration 28401: loss: 0.043897, loss_s1: 0.033390, loss_fp: 0.007213, loss_freq: 0.012663
[19:38:18.103] iteration 28402: loss: 0.054021, loss_s1: 0.028531, loss_fp: 0.005791, loss_freq: 0.050686
[19:38:18.732] iteration 28403: loss: 0.046163, loss_s1: 0.034749, loss_fp: 0.001866, loss_freq: 0.019517
[19:38:19.367] iteration 28404: loss: 0.063855, loss_s1: 0.059583, loss_fp: 0.009235, loss_freq: 0.035011
[19:38:19.993] iteration 28405: loss: 0.046221, loss_s1: 0.030908, loss_fp: 0.013507, loss_freq: 0.021582
[19:38:20.618] iteration 28406: loss: 0.037850, loss_s1: 0.029236, loss_fp: 0.001613, loss_freq: 0.006030
[19:38:21.243] iteration 28407: loss: 0.070819, loss_s1: 0.046224, loss_fp: 0.009420, loss_freq: 0.054793
[19:38:21.873] iteration 28408: loss: 0.054624, loss_s1: 0.049045, loss_fp: 0.003075, loss_freq: 0.022565
[19:38:22.502] iteration 28409: loss: 0.038963, loss_s1: 0.027973, loss_fp: 0.001990, loss_freq: 0.006537
[19:38:23.130] iteration 28410: loss: 0.034645, loss_s1: 0.016177, loss_fp: 0.002087, loss_freq: 0.012891
[19:38:23.756] iteration 28411: loss: 0.056319, loss_s1: 0.041258, loss_fp: 0.004313, loss_freq: 0.031515
[19:38:24.385] iteration 28412: loss: 0.088875, loss_s1: 0.106263, loss_fp: 0.011656, loss_freq: 0.015844
[19:38:25.016] iteration 28413: loss: 0.055719, loss_s1: 0.065396, loss_fp: 0.002467, loss_freq: 0.018745
[19:38:25.651] iteration 28414: loss: 0.040992, loss_s1: 0.038026, loss_fp: 0.004024, loss_freq: 0.017018
[19:38:26.281] iteration 28415: loss: 0.030913, loss_s1: 0.025035, loss_fp: 0.004123, loss_freq: 0.005543
[19:38:26.907] iteration 28416: loss: 0.058272, loss_s1: 0.063036, loss_fp: 0.004269, loss_freq: 0.018137
[19:38:27.531] iteration 28417: loss: 0.056669, loss_s1: 0.038905, loss_fp: 0.002255, loss_freq: 0.027775
[19:38:28.154] iteration 28418: loss: 0.059310, loss_s1: 0.054247, loss_fp: 0.003961, loss_freq: 0.028358
[19:38:28.778] iteration 28419: loss: 0.058090, loss_s1: 0.043213, loss_fp: 0.006882, loss_freq: 0.039171
[19:38:29.403] iteration 28420: loss: 0.048868, loss_s1: 0.036793, loss_fp: 0.011271, loss_freq: 0.018576
[19:38:30.028] iteration 28421: loss: 0.071354, loss_s1: 0.075139, loss_fp: 0.007337, loss_freq: 0.029465
[19:38:30.655] iteration 28422: loss: 0.057553, loss_s1: 0.063046, loss_fp: 0.002309, loss_freq: 0.012768
[19:38:31.282] iteration 28423: loss: 0.035976, loss_s1: 0.020293, loss_fp: 0.001794, loss_freq: 0.014428
[19:38:31.906] iteration 28424: loss: 0.046753, loss_s1: 0.035406, loss_fp: 0.006939, loss_freq: 0.019700
[19:38:32.592] iteration 28425: loss: 0.081053, loss_s1: 0.076558, loss_fp: 0.005730, loss_freq: 0.049797
[19:38:33.218] iteration 28426: loss: 0.047744, loss_s1: 0.037091, loss_fp: 0.001878, loss_freq: 0.028184
[19:38:33.848] iteration 28427: loss: 0.046937, loss_s1: 0.038769, loss_fp: 0.001197, loss_freq: 0.019418
[19:38:34.476] iteration 28428: loss: 0.063425, loss_s1: 0.033641, loss_fp: 0.010768, loss_freq: 0.041211
[19:38:35.098] iteration 28429: loss: 0.055568, loss_s1: 0.014536, loss_fp: 0.001201, loss_freq: 0.022802
[19:38:35.723] iteration 28430: loss: 0.039890, loss_s1: 0.032704, loss_fp: 0.000672, loss_freq: 0.017928
[19:38:36.353] iteration 28431: loss: 0.070761, loss_s1: 0.067658, loss_fp: 0.001294, loss_freq: 0.041544
[19:38:36.991] iteration 28432: loss: 0.053713, loss_s1: 0.040324, loss_fp: 0.006998, loss_freq: 0.037390
[19:38:37.620] iteration 28433: loss: 0.047577, loss_s1: 0.039402, loss_fp: 0.001187, loss_freq: 0.021884
[19:38:38.250] iteration 28434: loss: 0.051697, loss_s1: 0.020514, loss_fp: 0.001682, loss_freq: 0.048772
[19:38:38.890] iteration 28435: loss: 0.036261, loss_s1: 0.029760, loss_fp: 0.001120, loss_freq: 0.017022
[19:38:39.538] iteration 28436: loss: 0.033146, loss_s1: 0.017268, loss_fp: 0.002283, loss_freq: 0.015661
[19:38:40.184] iteration 28437: loss: 0.035131, loss_s1: 0.019004, loss_fp: 0.006415, loss_freq: 0.019954
[19:38:40.811] iteration 28438: loss: 0.054017, loss_s1: 0.040185, loss_fp: 0.006350, loss_freq: 0.032677
[19:38:41.438] iteration 28439: loss: 0.059170, loss_s1: 0.058248, loss_fp: 0.005881, loss_freq: 0.021529
[19:38:42.063] iteration 28440: loss: 0.031486, loss_s1: 0.019664, loss_fp: 0.003483, loss_freq: 0.011531
[19:38:42.691] iteration 28441: loss: 0.041843, loss_s1: 0.028665, loss_fp: 0.004586, loss_freq: 0.011451
[19:38:43.317] iteration 28442: loss: 0.039167, loss_s1: 0.019426, loss_fp: 0.001332, loss_freq: 0.024733
[19:38:43.941] iteration 28443: loss: 0.025924, loss_s1: 0.005733, loss_fp: 0.000759, loss_freq: 0.007493
[19:38:44.574] iteration 28444: loss: 0.089258, loss_s1: 0.091045, loss_fp: 0.004358, loss_freq: 0.047942
[19:38:45.198] iteration 28445: loss: 0.071795, loss_s1: 0.057025, loss_fp: 0.012160, loss_freq: 0.042321
[19:38:45.821] iteration 28446: loss: 0.036049, loss_s1: 0.017656, loss_fp: 0.006338, loss_freq: 0.019372
[19:38:46.446] iteration 28447: loss: 0.056676, loss_s1: 0.039923, loss_fp: 0.001798, loss_freq: 0.031333
[19:38:47.068] iteration 28448: loss: 0.034629, loss_s1: 0.024238, loss_fp: 0.004371, loss_freq: 0.014447
[19:38:47.694] iteration 28449: loss: 0.048413, loss_s1: 0.028573, loss_fp: 0.006839, loss_freq: 0.033278
[19:38:48.316] iteration 28450: loss: 0.031961, loss_s1: 0.017507, loss_fp: 0.001964, loss_freq: 0.020672
[19:38:48.941] iteration 28451: loss: 0.046555, loss_s1: 0.041623, loss_fp: 0.001308, loss_freq: 0.013570
[19:38:49.607] iteration 28452: loss: 0.028586, loss_s1: 0.016436, loss_fp: 0.001318, loss_freq: 0.011034
[19:38:50.242] iteration 28453: loss: 0.025012, loss_s1: 0.007717, loss_fp: 0.002626, loss_freq: 0.008607
[19:38:50.886] iteration 28454: loss: 0.036993, loss_s1: 0.033336, loss_fp: 0.001460, loss_freq: 0.014061
[19:38:51.524] iteration 28455: loss: 0.056761, loss_s1: 0.053179, loss_fp: 0.002787, loss_freq: 0.018136
[19:38:52.152] iteration 28456: loss: 0.071399, loss_s1: 0.036131, loss_fp: 0.002376, loss_freq: 0.080771
[19:38:52.801] iteration 28457: loss: 0.028313, loss_s1: 0.019306, loss_fp: 0.000822, loss_freq: 0.008490
[19:38:53.434] iteration 28458: loss: 0.050927, loss_s1: 0.041777, loss_fp: 0.005630, loss_freq: 0.019966
[19:38:54.065] iteration 28459: loss: 0.039626, loss_s1: 0.035004, loss_fp: 0.002012, loss_freq: 0.013244
[19:38:54.694] iteration 28460: loss: 0.047051, loss_s1: 0.035500, loss_fp: 0.001030, loss_freq: 0.011831
[19:38:55.329] iteration 28461: loss: 0.056522, loss_s1: 0.052771, loss_fp: 0.003893, loss_freq: 0.016257
[19:38:55.959] iteration 28462: loss: 0.033489, loss_s1: 0.021761, loss_fp: 0.000985, loss_freq: 0.010796
[19:38:56.586] iteration 28463: loss: 0.039997, loss_s1: 0.020129, loss_fp: 0.005789, loss_freq: 0.020307
[19:38:57.210] iteration 28464: loss: 0.078571, loss_s1: 0.078504, loss_fp: 0.004584, loss_freq: 0.009759
[19:38:57.832] iteration 28465: loss: 0.054419, loss_s1: 0.045580, loss_fp: 0.002648, loss_freq: 0.034759
[19:38:58.481] iteration 28466: loss: 0.028542, loss_s1: 0.021304, loss_fp: 0.002578, loss_freq: 0.010517
[19:38:59.108] iteration 28467: loss: 0.037034, loss_s1: 0.024317, loss_fp: 0.008791, loss_freq: 0.013704
[19:38:59.736] iteration 28468: loss: 0.051917, loss_s1: 0.036079, loss_fp: 0.003450, loss_freq: 0.032645
[19:39:00.359] iteration 28469: loss: 0.045370, loss_s1: 0.032020, loss_fp: 0.002105, loss_freq: 0.019521
[19:39:00.985] iteration 28470: loss: 0.039053, loss_s1: 0.029937, loss_fp: 0.002069, loss_freq: 0.012932
[19:39:01.610] iteration 28471: loss: 0.040146, loss_s1: 0.038290, loss_fp: 0.001491, loss_freq: 0.013023
[19:39:02.234] iteration 28472: loss: 0.050076, loss_s1: 0.043508, loss_fp: 0.003442, loss_freq: 0.022296
[19:39:02.860] iteration 28473: loss: 0.037668, loss_s1: 0.031607, loss_fp: 0.001077, loss_freq: 0.011507
[19:39:03.491] iteration 28474: loss: 0.052370, loss_s1: 0.057650, loss_fp: 0.003811, loss_freq: 0.013331
[19:39:04.143] iteration 28475: loss: 0.028745, loss_s1: 0.014801, loss_fp: 0.000458, loss_freq: 0.010555
[19:39:04.786] iteration 28476: loss: 0.077559, loss_s1: 0.060323, loss_fp: 0.008082, loss_freq: 0.041526
[19:39:05.428] iteration 28477: loss: 0.084718, loss_s1: 0.101353, loss_fp: 0.012125, loss_freq: 0.025034
[19:39:06.062] iteration 28478: loss: 0.039870, loss_s1: 0.030418, loss_fp: 0.001184, loss_freq: 0.010625
[19:39:06.706] iteration 28479: loss: 0.061316, loss_s1: 0.043030, loss_fp: 0.001675, loss_freq: 0.038149
[19:39:07.337] iteration 28480: loss: 0.041345, loss_s1: 0.024748, loss_fp: 0.003342, loss_freq: 0.017511
[19:39:07.981] iteration 28481: loss: 0.043340, loss_s1: 0.031957, loss_fp: 0.007926, loss_freq: 0.012398
[19:39:08.620] iteration 28482: loss: 0.053201, loss_s1: 0.043094, loss_fp: 0.005793, loss_freq: 0.015239
[19:39:09.250] iteration 28483: loss: 0.051118, loss_s1: 0.038223, loss_fp: 0.004349, loss_freq: 0.036080
[19:39:09.874] iteration 28484: loss: 0.033729, loss_s1: 0.020062, loss_fp: 0.003217, loss_freq: 0.016349
[19:39:10.506] iteration 28485: loss: 0.028353, loss_s1: 0.013266, loss_fp: 0.004593, loss_freq: 0.010868
[19:39:11.130] iteration 28486: loss: 0.082787, loss_s1: 0.054950, loss_fp: 0.009952, loss_freq: 0.063729
[19:39:11.754] iteration 28487: loss: 0.042885, loss_s1: 0.030617, loss_fp: 0.009816, loss_freq: 0.010831
[19:39:12.385] iteration 28488: loss: 0.073387, loss_s1: 0.074204, loss_fp: 0.003079, loss_freq: 0.044305
[19:39:13.010] iteration 28489: loss: 0.043722, loss_s1: 0.043894, loss_fp: 0.001854, loss_freq: 0.011469
[19:39:13.635] iteration 28490: loss: 0.037144, loss_s1: 0.018612, loss_fp: 0.001003, loss_freq: 0.019176
[19:39:14.270] iteration 28491: loss: 0.027651, loss_s1: 0.019295, loss_fp: 0.001422, loss_freq: 0.005515
[19:39:14.899] iteration 28492: loss: 0.037119, loss_s1: 0.027642, loss_fp: 0.001225, loss_freq: 0.013153
[19:39:15.532] iteration 28493: loss: 0.037886, loss_s1: 0.017660, loss_fp: 0.001695, loss_freq: 0.020003
[19:39:16.165] iteration 28494: loss: 0.080180, loss_s1: 0.084226, loss_fp: 0.002894, loss_freq: 0.035894
[19:39:16.788] iteration 28495: loss: 0.040653, loss_s1: 0.030484, loss_fp: 0.001837, loss_freq: 0.010872
[19:39:17.412] iteration 28496: loss: 0.052424, loss_s1: 0.044756, loss_fp: 0.002623, loss_freq: 0.023225
[19:39:18.037] iteration 28497: loss: 0.055912, loss_s1: 0.040522, loss_fp: 0.002685, loss_freq: 0.032125
[19:39:19.029] iteration 28498: loss: 0.051463, loss_s1: 0.046020, loss_fp: 0.000860, loss_freq: 0.025119
[19:39:19.652] iteration 28499: loss: 0.054395, loss_s1: 0.052990, loss_fp: 0.003401, loss_freq: 0.018815
[19:39:20.278] iteration 28500: loss: 0.052130, loss_s1: 0.032807, loss_fp: 0.001798, loss_freq: 0.015742
[19:39:20.902] iteration 28501: loss: 0.066210, loss_s1: 0.058660, loss_fp: 0.004696, loss_freq: 0.030183
[19:39:21.531] iteration 28502: loss: 0.039774, loss_s1: 0.019119, loss_fp: 0.004135, loss_freq: 0.025575
[19:39:22.150] iteration 28503: loss: 0.095970, loss_s1: 0.046137, loss_fp: 0.013253, loss_freq: 0.044120
[19:39:22.779] iteration 28504: loss: 0.047994, loss_s1: 0.025506, loss_fp: 0.004255, loss_freq: 0.037543
[19:39:23.409] iteration 28505: loss: 0.049446, loss_s1: 0.029375, loss_fp: 0.002319, loss_freq: 0.015774
[19:39:24.046] iteration 28506: loss: 0.049744, loss_s1: 0.024314, loss_fp: 0.002672, loss_freq: 0.039184
[19:39:24.691] iteration 28507: loss: 0.057339, loss_s1: 0.061853, loss_fp: 0.008220, loss_freq: 0.012276
[19:39:25.317] iteration 28508: loss: 0.039219, loss_s1: 0.037462, loss_fp: 0.003240, loss_freq: 0.008253
[19:39:25.940] iteration 28509: loss: 0.027852, loss_s1: 0.021356, loss_fp: 0.003834, loss_freq: 0.004466
[19:39:26.576] iteration 28510: loss: 0.081849, loss_s1: 0.064057, loss_fp: 0.003585, loss_freq: 0.068280
[19:39:27.206] iteration 28511: loss: 0.043461, loss_s1: 0.024954, loss_fp: 0.001405, loss_freq: 0.020501
[19:39:27.833] iteration 28512: loss: 0.040759, loss_s1: 0.041066, loss_fp: 0.006253, loss_freq: 0.007530
[19:39:28.466] iteration 28513: loss: 0.096799, loss_s1: 0.058156, loss_fp: 0.010081, loss_freq: 0.080069
[19:39:29.100] iteration 28514: loss: 0.044243, loss_s1: 0.036742, loss_fp: 0.003986, loss_freq: 0.013823
[19:39:29.729] iteration 28515: loss: 0.058629, loss_s1: 0.059600, loss_fp: 0.006533, loss_freq: 0.023826
[19:39:30.358] iteration 28516: loss: 0.057522, loss_s1: 0.039961, loss_fp: 0.002338, loss_freq: 0.027398
[19:39:30.993] iteration 28517: loss: 0.036228, loss_s1: 0.021086, loss_fp: 0.003616, loss_freq: 0.023236
[19:39:31.627] iteration 28518: loss: 0.046817, loss_s1: 0.044745, loss_fp: 0.000245, loss_freq: 0.006470
[19:39:32.260] iteration 28519: loss: 0.043460, loss_s1: 0.027452, loss_fp: 0.002159, loss_freq: 0.022988
[19:39:32.884] iteration 28520: loss: 0.052521, loss_s1: 0.037902, loss_fp: 0.002336, loss_freq: 0.021866
[19:39:33.511] iteration 28521: loss: 0.108682, loss_s1: 0.104478, loss_fp: 0.003135, loss_freq: 0.079229
[19:39:34.143] iteration 28522: loss: 0.050326, loss_s1: 0.054275, loss_fp: 0.001729, loss_freq: 0.016700
[19:39:34.770] iteration 28523: loss: 0.038736, loss_s1: 0.023738, loss_fp: 0.002779, loss_freq: 0.016156
[19:39:35.427] iteration 28524: loss: 0.025984, loss_s1: 0.011026, loss_fp: 0.000386, loss_freq: 0.002657
[19:39:36.058] iteration 28525: loss: 0.090136, loss_s1: 0.120271, loss_fp: 0.005988, loss_freq: 0.022455
[19:39:36.685] iteration 28526: loss: 0.073291, loss_s1: 0.039280, loss_fp: 0.008031, loss_freq: 0.071937
[19:39:37.316] iteration 28527: loss: 0.048525, loss_s1: 0.039852, loss_fp: 0.007798, loss_freq: 0.017014
[19:39:37.944] iteration 28528: loss: 0.030570, loss_s1: 0.017773, loss_fp: 0.006080, loss_freq: 0.011694
[19:39:38.569] iteration 28529: loss: 0.030151, loss_s1: 0.013221, loss_fp: 0.002467, loss_freq: 0.007524
[19:39:39.192] iteration 28530: loss: 0.041102, loss_s1: 0.031374, loss_fp: 0.003618, loss_freq: 0.021955
[19:39:39.817] iteration 28531: loss: 0.028437, loss_s1: 0.016547, loss_fp: 0.001559, loss_freq: 0.006521
[19:39:40.445] iteration 28532: loss: 0.042212, loss_s1: 0.017166, loss_fp: 0.003966, loss_freq: 0.021309
[19:39:41.068] iteration 28533: loss: 0.062255, loss_s1: 0.048739, loss_fp: 0.010569, loss_freq: 0.020496
[19:39:41.693] iteration 28534: loss: 0.064426, loss_s1: 0.073192, loss_fp: 0.002624, loss_freq: 0.019602
[19:39:42.319] iteration 28535: loss: 0.048825, loss_s1: 0.050533, loss_fp: 0.000284, loss_freq: 0.015732
[19:39:42.949] iteration 28536: loss: 0.071233, loss_s1: 0.078885, loss_fp: 0.001877, loss_freq: 0.019202
[19:39:43.578] iteration 28537: loss: 0.056358, loss_s1: 0.056290, loss_fp: 0.003799, loss_freq: 0.024485
[19:39:44.203] iteration 28538: loss: 0.062421, loss_s1: 0.062713, loss_fp: 0.007096, loss_freq: 0.018663
[19:39:44.829] iteration 28539: loss: 0.053296, loss_s1: 0.052687, loss_fp: 0.004002, loss_freq: 0.021703
[19:39:45.462] iteration 28540: loss: 0.056344, loss_s1: 0.063360, loss_fp: 0.003196, loss_freq: 0.019781
[19:39:46.095] iteration 28541: loss: 0.046374, loss_s1: 0.016906, loss_fp: 0.003136, loss_freq: 0.048082
[19:39:46.726] iteration 28542: loss: 0.075453, loss_s1: 0.027136, loss_fp: 0.002115, loss_freq: 0.083697
[19:39:47.347] iteration 28543: loss: 0.035197, loss_s1: 0.030504, loss_fp: 0.006489, loss_freq: 0.004080
[19:39:47.977] iteration 28544: loss: 0.035349, loss_s1: 0.031089, loss_fp: 0.003029, loss_freq: 0.009661
[19:39:48.605] iteration 28545: loss: 0.029669, loss_s1: 0.013494, loss_fp: 0.004498, loss_freq: 0.016306
[19:39:49.233] iteration 28546: loss: 0.049998, loss_s1: 0.038965, loss_fp: 0.007725, loss_freq: 0.020647
[19:39:49.857] iteration 28547: loss: 0.037339, loss_s1: 0.023305, loss_fp: 0.002203, loss_freq: 0.021601
[19:39:50.485] iteration 28548: loss: 0.053682, loss_s1: 0.048168, loss_fp: 0.001317, loss_freq: 0.026530
[19:39:51.107] iteration 28549: loss: 0.036278, loss_s1: 0.022110, loss_fp: 0.005731, loss_freq: 0.006493
[19:39:51.732] iteration 28550: loss: 0.051946, loss_s1: 0.030774, loss_fp: 0.006020, loss_freq: 0.030682
[19:39:52.360] iteration 28551: loss: 0.050128, loss_s1: 0.047834, loss_fp: 0.001442, loss_freq: 0.018666
[19:39:52.996] iteration 28552: loss: 0.044483, loss_s1: 0.037502, loss_fp: 0.003704, loss_freq: 0.012144
[19:39:53.645] iteration 28553: loss: 0.053706, loss_s1: 0.046905, loss_fp: 0.004339, loss_freq: 0.018983
[19:39:54.288] iteration 28554: loss: 0.046087, loss_s1: 0.034421, loss_fp: 0.001404, loss_freq: 0.026020
[19:39:54.981] iteration 28555: loss: 0.035453, loss_s1: 0.017879, loss_fp: 0.001086, loss_freq: 0.017378
[19:39:55.670] iteration 28556: loss: 0.031763, loss_s1: 0.020211, loss_fp: 0.002791, loss_freq: 0.009200
[19:39:56.359] iteration 28557: loss: 0.055425, loss_s1: 0.046083, loss_fp: 0.010683, loss_freq: 0.026134
[19:39:57.012] iteration 28558: loss: 0.050562, loss_s1: 0.011481, loss_fp: 0.007628, loss_freq: 0.027392
[19:39:57.649] iteration 28559: loss: 0.043342, loss_s1: 0.033996, loss_fp: 0.005070, loss_freq: 0.015093
[19:39:58.287] iteration 28560: loss: 0.041811, loss_s1: 0.020476, loss_fp: 0.000679, loss_freq: 0.026285
[19:39:58.912] iteration 28561: loss: 0.024777, loss_s1: 0.007247, loss_fp: 0.006295, loss_freq: 0.005284
[19:39:59.536] iteration 28562: loss: 0.047221, loss_s1: 0.044079, loss_fp: 0.002046, loss_freq: 0.015885
[19:40:00.162] iteration 28563: loss: 0.084370, loss_s1: 0.033031, loss_fp: 0.003469, loss_freq: 0.104159
[19:40:00.791] iteration 28564: loss: 0.043121, loss_s1: 0.016557, loss_fp: 0.005766, loss_freq: 0.027803
[19:40:01.421] iteration 28565: loss: 0.061033, loss_s1: 0.059970, loss_fp: 0.002460, loss_freq: 0.031753
[19:40:02.048] iteration 28566: loss: 0.052304, loss_s1: 0.022790, loss_fp: 0.015603, loss_freq: 0.039581
[19:40:02.673] iteration 28567: loss: 0.043541, loss_s1: 0.027747, loss_fp: 0.001515, loss_freq: 0.015552
[19:40:03.295] iteration 28568: loss: 0.064944, loss_s1: 0.053650, loss_fp: 0.003948, loss_freq: 0.045232
[19:40:03.920] iteration 28569: loss: 0.033293, loss_s1: 0.017352, loss_fp: 0.001667, loss_freq: 0.016256
[19:40:04.543] iteration 28570: loss: 0.060113, loss_s1: 0.044824, loss_fp: 0.002914, loss_freq: 0.039880
[19:40:05.175] iteration 28571: loss: 0.037404, loss_s1: 0.015559, loss_fp: 0.002325, loss_freq: 0.022425
[19:40:05.806] iteration 28572: loss: 0.032604, loss_s1: 0.026479, loss_fp: 0.001579, loss_freq: 0.007097
[19:40:06.429] iteration 28573: loss: 0.034805, loss_s1: 0.021171, loss_fp: 0.002858, loss_freq: 0.006248
[19:40:07.051] iteration 28574: loss: 0.038258, loss_s1: 0.026629, loss_fp: 0.002147, loss_freq: 0.019289
[19:40:07.681] iteration 28575: loss: 0.025756, loss_s1: 0.011088, loss_fp: 0.002222, loss_freq: 0.009233
[19:40:08.309] iteration 28576: loss: 0.029706, loss_s1: 0.015915, loss_fp: 0.000928, loss_freq: 0.015432
[19:40:08.947] iteration 28577: loss: 0.059953, loss_s1: 0.053762, loss_fp: 0.002455, loss_freq: 0.028686
[19:40:09.580] iteration 28578: loss: 0.067909, loss_s1: 0.064150, loss_fp: 0.003424, loss_freq: 0.034977
[19:40:10.212] iteration 28579: loss: 0.067969, loss_s1: 0.070616, loss_fp: 0.007731, loss_freq: 0.027838
[19:40:10.844] iteration 28580: loss: 0.033288, loss_s1: 0.024681, loss_fp: 0.002563, loss_freq: 0.011125
[19:40:11.474] iteration 28581: loss: 0.042306, loss_s1: 0.038766, loss_fp: 0.004084, loss_freq: 0.012955
[19:40:12.106] iteration 28582: loss: 0.065197, loss_s1: 0.062426, loss_fp: 0.005404, loss_freq: 0.027107
[19:40:12.734] iteration 28583: loss: 0.051938, loss_s1: 0.046461, loss_fp: 0.005094, loss_freq: 0.015630
[19:40:13.358] iteration 28584: loss: 0.042388, loss_s1: 0.037533, loss_fp: 0.002404, loss_freq: 0.011841
[19:40:13.989] iteration 28585: loss: 0.051940, loss_s1: 0.049322, loss_fp: 0.000878, loss_freq: 0.027288
[19:40:14.617] iteration 28586: loss: 0.045395, loss_s1: 0.036755, loss_fp: 0.002793, loss_freq: 0.017793
[19:40:15.242] iteration 28587: loss: 0.086978, loss_s1: 0.077481, loss_fp: 0.002724, loss_freq: 0.059137
[19:40:15.866] iteration 28588: loss: 0.048216, loss_s1: 0.036619, loss_fp: 0.005936, loss_freq: 0.017992
[19:40:16.491] iteration 28589: loss: 0.058745, loss_s1: 0.032160, loss_fp: 0.005520, loss_freq: 0.044275
[19:40:17.113] iteration 28590: loss: 0.060259, loss_s1: 0.024282, loss_fp: 0.001360, loss_freq: 0.029674
[19:40:17.740] iteration 28591: loss: 0.045685, loss_s1: 0.032254, loss_fp: 0.004797, loss_freq: 0.023689
[19:40:18.364] iteration 28592: loss: 0.054808, loss_s1: 0.036818, loss_fp: 0.005430, loss_freq: 0.044937
[19:40:18.994] iteration 28593: loss: 0.037319, loss_s1: 0.021152, loss_fp: 0.000864, loss_freq: 0.017010
[19:40:19.636] iteration 28594: loss: 0.039480, loss_s1: 0.026564, loss_fp: 0.001057, loss_freq: 0.016299
[19:40:20.262] iteration 28595: loss: 0.043490, loss_s1: 0.026803, loss_fp: 0.001155, loss_freq: 0.020757
[19:40:20.888] iteration 28596: loss: 0.049886, loss_s1: 0.051167, loss_fp: 0.000885, loss_freq: 0.017025
[19:40:21.519] iteration 28597: loss: 0.067036, loss_s1: 0.084721, loss_fp: 0.001912, loss_freq: 0.015758
[19:40:22.146] iteration 28598: loss: 0.038049, loss_s1: 0.032264, loss_fp: 0.002158, loss_freq: 0.015889
[19:40:22.770] iteration 28599: loss: 0.051226, loss_s1: 0.025359, loss_fp: 0.005267, loss_freq: 0.035771
[19:40:23.397] iteration 28600: loss: 0.057493, loss_s1: 0.048776, loss_fp: 0.009345, loss_freq: 0.034509
[19:40:26.494] iteration 28600 : mean_dice : 0.733848
[19:40:27.143] iteration 28601: loss: 0.055370, loss_s1: 0.033758, loss_fp: 0.011881, loss_freq: 0.030295
[19:40:27.775] iteration 28602: loss: 0.035747, loss_s1: 0.022371, loss_fp: 0.003068, loss_freq: 0.007947
[19:40:28.402] iteration 28603: loss: 0.041886, loss_s1: 0.031240, loss_fp: 0.003431, loss_freq: 0.022239
[19:40:29.028] iteration 28604: loss: 0.030768, loss_s1: 0.019404, loss_fp: 0.001045, loss_freq: 0.005582
[19:40:29.667] iteration 28605: loss: 0.061987, loss_s1: 0.069428, loss_fp: 0.000523, loss_freq: 0.019876
[19:40:30.302] iteration 28606: loss: 0.094343, loss_s1: 0.072132, loss_fp: 0.005249, loss_freq: 0.064234
[19:40:30.928] iteration 28607: loss: 0.066615, loss_s1: 0.057149, loss_fp: 0.001538, loss_freq: 0.043629
[19:40:31.559] iteration 28608: loss: 0.038161, loss_s1: 0.022861, loss_fp: 0.001255, loss_freq: 0.012859
[19:40:32.188] iteration 28609: loss: 0.042761, loss_s1: 0.034507, loss_fp: 0.001846, loss_freq: 0.020267
[19:40:32.817] iteration 28610: loss: 0.044863, loss_s1: 0.037262, loss_fp: 0.007835, loss_freq: 0.011609
[19:40:33.446] iteration 28611: loss: 0.054222, loss_s1: 0.039465, loss_fp: 0.003584, loss_freq: 0.034451
[19:40:34.076] iteration 28612: loss: 0.049888, loss_s1: 0.048541, loss_fp: 0.005225, loss_freq: 0.005343
[19:40:34.702] iteration 28613: loss: 0.045038, loss_s1: 0.018229, loss_fp: 0.003989, loss_freq: 0.033355
[19:40:35.330] iteration 28614: loss: 0.028767, loss_s1: 0.015458, loss_fp: 0.000901, loss_freq: 0.013115
[19:40:35.960] iteration 28615: loss: 0.023736, loss_s1: 0.011844, loss_fp: 0.000524, loss_freq: 0.012689
[19:40:36.591] iteration 28616: loss: 0.064662, loss_s1: 0.040552, loss_fp: 0.005282, loss_freq: 0.050680
[19:40:37.219] iteration 28617: loss: 0.062882, loss_s1: 0.053719, loss_fp: 0.004327, loss_freq: 0.033459
[19:40:37.848] iteration 28618: loss: 0.048195, loss_s1: 0.034038, loss_fp: 0.010412, loss_freq: 0.019889
[19:40:38.476] iteration 28619: loss: 0.049639, loss_s1: 0.044882, loss_fp: 0.011127, loss_freq: 0.008021
[19:40:39.108] iteration 28620: loss: 0.059044, loss_s1: 0.054530, loss_fp: 0.005309, loss_freq: 0.026029
[19:40:39.733] iteration 28621: loss: 0.037020, loss_s1: 0.017551, loss_fp: 0.001193, loss_freq: 0.013706
[19:40:40.367] iteration 28622: loss: 0.043069, loss_s1: 0.031041, loss_fp: 0.004363, loss_freq: 0.022896
[19:40:40.991] iteration 28623: loss: 0.034252, loss_s1: 0.014142, loss_fp: 0.002074, loss_freq: 0.013367
[19:40:41.623] iteration 28624: loss: 0.051192, loss_s1: 0.057191, loss_fp: 0.004138, loss_freq: 0.003668
[19:40:42.250] iteration 28625: loss: 0.088319, loss_s1: 0.101842, loss_fp: 0.006844, loss_freq: 0.021580
[19:40:42.879] iteration 28626: loss: 0.040163, loss_s1: 0.028211, loss_fp: 0.001304, loss_freq: 0.020642
[19:40:43.507] iteration 28627: loss: 0.050112, loss_s1: 0.059805, loss_fp: 0.001539, loss_freq: 0.010116
[19:40:44.135] iteration 28628: loss: 0.072243, loss_s1: 0.086449, loss_fp: 0.008522, loss_freq: 0.024314
[19:40:44.762] iteration 28629: loss: 0.037101, loss_s1: 0.025359, loss_fp: 0.001817, loss_freq: 0.016358
[19:40:45.394] iteration 28630: loss: 0.049151, loss_s1: 0.028269, loss_fp: 0.003937, loss_freq: 0.025898
[19:40:46.018] iteration 28631: loss: 0.033870, loss_s1: 0.020579, loss_fp: 0.000820, loss_freq: 0.011377
[19:40:46.648] iteration 28632: loss: 0.058209, loss_s1: 0.056295, loss_fp: 0.006296, loss_freq: 0.023310
[19:40:47.275] iteration 28633: loss: 0.056100, loss_s1: 0.058437, loss_fp: 0.001314, loss_freq: 0.023520
[19:40:47.908] iteration 28634: loss: 0.046818, loss_s1: 0.019317, loss_fp: 0.000311, loss_freq: 0.029059
[19:40:48.540] iteration 28635: loss: 0.041209, loss_s1: 0.029493, loss_fp: 0.003948, loss_freq: 0.022702
[19:40:49.165] iteration 28636: loss: 0.035074, loss_s1: 0.018601, loss_fp: 0.008391, loss_freq: 0.014969
[19:40:49.794] iteration 28637: loss: 0.069382, loss_s1: 0.049050, loss_fp: 0.000347, loss_freq: 0.054094
[19:40:50.430] iteration 28638: loss: 0.040887, loss_s1: 0.016598, loss_fp: 0.004734, loss_freq: 0.033229
[19:40:51.062] iteration 28639: loss: 0.030724, loss_s1: 0.018710, loss_fp: 0.001099, loss_freq: 0.007615
[19:40:51.686] iteration 28640: loss: 0.071417, loss_s1: 0.053818, loss_fp: 0.004845, loss_freq: 0.044805
[19:40:52.313] iteration 28641: loss: 0.043502, loss_s1: 0.023234, loss_fp: 0.006526, loss_freq: 0.021289
[19:40:52.939] iteration 28642: loss: 0.054017, loss_s1: 0.038777, loss_fp: 0.002450, loss_freq: 0.018607
[19:40:53.576] iteration 28643: loss: 0.049213, loss_s1: 0.035170, loss_fp: 0.005505, loss_freq: 0.016682
[19:40:54.201] iteration 28644: loss: 0.085824, loss_s1: 0.079719, loss_fp: 0.005496, loss_freq: 0.056402
[19:40:54.822] iteration 28645: loss: 0.035927, loss_s1: 0.027490, loss_fp: 0.003894, loss_freq: 0.013637
[19:40:55.448] iteration 28646: loss: 0.032390, loss_s1: 0.018913, loss_fp: 0.001367, loss_freq: 0.010086
[19:40:56.070] iteration 28647: loss: 0.071496, loss_s1: 0.068195, loss_fp: 0.010157, loss_freq: 0.032427
[19:40:56.694] iteration 28648: loss: 0.054727, loss_s1: 0.037180, loss_fp: 0.005450, loss_freq: 0.032171
[19:40:57.313] iteration 28649: loss: 0.091783, loss_s1: 0.059436, loss_fp: 0.002754, loss_freq: 0.082562
[19:40:57.940] iteration 28650: loss: 0.036830, loss_s1: 0.028051, loss_fp: 0.001387, loss_freq: 0.021533
[19:40:58.572] iteration 28651: loss: 0.058255, loss_s1: 0.023048, loss_fp: 0.005095, loss_freq: 0.034134
[19:40:59.198] iteration 28652: loss: 0.019590, loss_s1: 0.008628, loss_fp: 0.001621, loss_freq: 0.004578
[19:40:59.822] iteration 28653: loss: 0.032011, loss_s1: 0.019535, loss_fp: 0.000917, loss_freq: 0.007773
[19:41:00.451] iteration 28654: loss: 0.041096, loss_s1: 0.030027, loss_fp: 0.000517, loss_freq: 0.012928
[19:41:01.081] iteration 28655: loss: 0.070976, loss_s1: 0.085434, loss_fp: 0.001404, loss_freq: 0.024037
[19:41:01.710] iteration 28656: loss: 0.043423, loss_s1: 0.030164, loss_fp: 0.005458, loss_freq: 0.016128
[19:41:02.342] iteration 28657: loss: 0.067319, loss_s1: 0.037215, loss_fp: 0.009823, loss_freq: 0.020254
[19:41:02.966] iteration 28658: loss: 0.030172, loss_s1: 0.009264, loss_fp: 0.000358, loss_freq: 0.014858
[19:41:03.901] iteration 28659: loss: 0.048961, loss_s1: 0.037028, loss_fp: 0.000822, loss_freq: 0.033152
[19:41:04.533] iteration 28660: loss: 0.053006, loss_s1: 0.052906, loss_fp: 0.002144, loss_freq: 0.015687
[19:41:05.172] iteration 28661: loss: 0.034743, loss_s1: 0.023471, loss_fp: 0.000536, loss_freq: 0.011564
[19:41:05.817] iteration 28662: loss: 0.047927, loss_s1: 0.029307, loss_fp: 0.006307, loss_freq: 0.027332
[19:41:06.463] iteration 28663: loss: 0.059523, loss_s1: 0.069322, loss_fp: 0.000706, loss_freq: 0.019709
[19:41:07.100] iteration 28664: loss: 0.071582, loss_s1: 0.063082, loss_fp: 0.001910, loss_freq: 0.040257
[19:41:07.744] iteration 28665: loss: 0.066993, loss_s1: 0.065799, loss_fp: 0.009341, loss_freq: 0.029198
[19:41:08.386] iteration 28666: loss: 0.038298, loss_s1: 0.020235, loss_fp: 0.005882, loss_freq: 0.022349
[19:41:09.022] iteration 28667: loss: 0.051113, loss_s1: 0.048006, loss_fp: 0.012624, loss_freq: 0.019937
[19:41:09.661] iteration 28668: loss: 0.044366, loss_s1: 0.033881, loss_fp: 0.006647, loss_freq: 0.016792
[19:41:10.293] iteration 28669: loss: 0.029584, loss_s1: 0.015532, loss_fp: 0.002134, loss_freq: 0.004435
[19:41:10.962] iteration 28670: loss: 0.036129, loss_s1: 0.021326, loss_fp: 0.005724, loss_freq: 0.011888
[19:41:11.588] iteration 28671: loss: 0.069654, loss_s1: 0.056040, loss_fp: 0.009582, loss_freq: 0.050525
[19:41:12.210] iteration 28672: loss: 0.046371, loss_s1: 0.026374, loss_fp: 0.001242, loss_freq: 0.025084
[19:41:12.831] iteration 28673: loss: 0.053239, loss_s1: 0.044476, loss_fp: 0.002211, loss_freq: 0.029375
[19:41:13.461] iteration 28674: loss: 0.065069, loss_s1: 0.041400, loss_fp: 0.001815, loss_freq: 0.058245
[19:41:14.081] iteration 28675: loss: 0.036064, loss_s1: 0.023866, loss_fp: 0.001459, loss_freq: 0.008143
[19:41:14.703] iteration 28676: loss: 0.054144, loss_s1: 0.050821, loss_fp: 0.004780, loss_freq: 0.027457
[19:41:15.327] iteration 28677: loss: 0.050253, loss_s1: 0.028300, loss_fp: 0.001088, loss_freq: 0.031382
[19:41:15.949] iteration 28678: loss: 0.058240, loss_s1: 0.040301, loss_fp: 0.006652, loss_freq: 0.040147
[19:41:16.572] iteration 28679: loss: 0.026614, loss_s1: 0.004763, loss_fp: 0.005418, loss_freq: 0.008573
[19:41:17.202] iteration 28680: loss: 0.028074, loss_s1: 0.013977, loss_fp: 0.002947, loss_freq: 0.010203
[19:41:17.827] iteration 28681: loss: 0.036003, loss_s1: 0.019214, loss_fp: 0.001072, loss_freq: 0.014108
[19:41:18.449] iteration 28682: loss: 0.065454, loss_s1: 0.052374, loss_fp: 0.006871, loss_freq: 0.043529
[19:41:19.074] iteration 28683: loss: 0.035635, loss_s1: 0.030957, loss_fp: 0.000911, loss_freq: 0.012301
[19:41:19.693] iteration 28684: loss: 0.041585, loss_s1: 0.036061, loss_fp: 0.002899, loss_freq: 0.012639
[19:41:20.317] iteration 28685: loss: 0.035300, loss_s1: 0.031092, loss_fp: 0.000588, loss_freq: 0.008034
[19:41:20.940] iteration 28686: loss: 0.090088, loss_s1: 0.099657, loss_fp: 0.009540, loss_freq: 0.032920
[19:41:21.562] iteration 28687: loss: 0.045457, loss_s1: 0.025719, loss_fp: 0.007024, loss_freq: 0.030476
[19:41:22.194] iteration 28688: loss: 0.049144, loss_s1: 0.039945, loss_fp: 0.007636, loss_freq: 0.013295
[19:41:22.825] iteration 28689: loss: 0.041653, loss_s1: 0.041573, loss_fp: 0.003143, loss_freq: 0.013782
[19:41:23.455] iteration 28690: loss: 0.052798, loss_s1: 0.043286, loss_fp: 0.002540, loss_freq: 0.029266
[19:41:24.084] iteration 28691: loss: 0.057949, loss_s1: 0.074361, loss_fp: 0.001367, loss_freq: 0.013605
[19:41:24.712] iteration 28692: loss: 0.051942, loss_s1: 0.055874, loss_fp: 0.004162, loss_freq: 0.017444
[19:41:25.345] iteration 28693: loss: 0.043222, loss_s1: 0.018470, loss_fp: 0.006263, loss_freq: 0.021853
[19:41:25.975] iteration 28694: loss: 0.074388, loss_s1: 0.061986, loss_fp: 0.006593, loss_freq: 0.046944
[19:41:26.598] iteration 28695: loss: 0.081161, loss_s1: 0.099461, loss_fp: 0.007065, loss_freq: 0.013997
[19:41:27.219] iteration 28696: loss: 0.058598, loss_s1: 0.057236, loss_fp: 0.004122, loss_freq: 0.028898
[19:41:27.839] iteration 28697: loss: 0.065381, loss_s1: 0.058487, loss_fp: 0.001914, loss_freq: 0.032894
[19:41:28.460] iteration 28698: loss: 0.053689, loss_s1: 0.044694, loss_fp: 0.005216, loss_freq: 0.025637
[19:41:29.082] iteration 28699: loss: 0.065764, loss_s1: 0.068334, loss_fp: 0.002799, loss_freq: 0.026111
[19:41:29.707] iteration 28700: loss: 0.096174, loss_s1: 0.095458, loss_fp: 0.008133, loss_freq: 0.054189
[19:41:30.327] iteration 28701: loss: 0.054958, loss_s1: 0.060726, loss_fp: 0.006558, loss_freq: 0.017879
[19:41:30.948] iteration 28702: loss: 0.038701, loss_s1: 0.015978, loss_fp: 0.008893, loss_freq: 0.030473
[19:41:31.566] iteration 28703: loss: 0.027069, loss_s1: 0.011912, loss_fp: 0.001233, loss_freq: 0.008400
[19:41:32.189] iteration 28704: loss: 0.047218, loss_s1: 0.047392, loss_fp: 0.001748, loss_freq: 0.007382
[19:41:32.814] iteration 28705: loss: 0.028472, loss_s1: 0.021444, loss_fp: 0.001042, loss_freq: 0.007272
[19:41:33.437] iteration 28706: loss: 0.038594, loss_s1: 0.035227, loss_fp: 0.001648, loss_freq: 0.012602
[19:41:34.061] iteration 28707: loss: 0.072412, loss_s1: 0.045273, loss_fp: 0.001112, loss_freq: 0.058801
[19:41:34.685] iteration 28708: loss: 0.051780, loss_s1: 0.039311, loss_fp: 0.007023, loss_freq: 0.024752
[19:41:35.328] iteration 28709: loss: 0.056544, loss_s1: 0.051058, loss_fp: 0.002846, loss_freq: 0.033330
[19:41:35.953] iteration 28710: loss: 0.046800, loss_s1: 0.037217, loss_fp: 0.003109, loss_freq: 0.016790
[19:41:36.588] iteration 28711: loss: 0.042905, loss_s1: 0.021867, loss_fp: 0.004332, loss_freq: 0.023961
[19:41:37.215] iteration 28712: loss: 0.043070, loss_s1: 0.037200, loss_fp: 0.001139, loss_freq: 0.011991
[19:41:37.842] iteration 28713: loss: 0.032556, loss_s1: 0.024035, loss_fp: 0.000565, loss_freq: 0.011328
[19:41:38.471] iteration 28714: loss: 0.063006, loss_s1: 0.044238, loss_fp: 0.000641, loss_freq: 0.045857
[19:41:39.098] iteration 28715: loss: 0.026590, loss_s1: 0.015851, loss_fp: 0.001181, loss_freq: 0.007055
[19:41:39.728] iteration 28716: loss: 0.042835, loss_s1: 0.017905, loss_fp: 0.001459, loss_freq: 0.016339
[19:41:40.355] iteration 28717: loss: 0.041091, loss_s1: 0.038846, loss_fp: 0.005645, loss_freq: 0.010082
[19:41:40.982] iteration 28718: loss: 0.036018, loss_s1: 0.025214, loss_fp: 0.004706, loss_freq: 0.011420
[19:41:41.613] iteration 28719: loss: 0.027248, loss_s1: 0.010669, loss_fp: 0.001926, loss_freq: 0.015182
[19:41:42.241] iteration 28720: loss: 0.044556, loss_s1: 0.012387, loss_fp: 0.003714, loss_freq: 0.037672
[19:41:42.873] iteration 28721: loss: 0.041828, loss_s1: 0.026727, loss_fp: 0.000479, loss_freq: 0.023834
[19:41:43.499] iteration 28722: loss: 0.055247, loss_s1: 0.044517, loss_fp: 0.006460, loss_freq: 0.030101
[19:41:44.124] iteration 28723: loss: 0.038434, loss_s1: 0.033990, loss_fp: 0.004678, loss_freq: 0.007031
[19:41:44.750] iteration 28724: loss: 0.058166, loss_s1: 0.040048, loss_fp: 0.001565, loss_freq: 0.043998
[19:41:45.377] iteration 28725: loss: 0.039632, loss_s1: 0.022022, loss_fp: 0.000794, loss_freq: 0.030488
[19:41:45.997] iteration 28726: loss: 0.078543, loss_s1: 0.087182, loss_fp: 0.006819, loss_freq: 0.037214
[19:41:46.626] iteration 28727: loss: 0.031845, loss_s1: 0.026743, loss_fp: 0.001655, loss_freq: 0.009651
[19:41:47.252] iteration 28728: loss: 0.073654, loss_s1: 0.058559, loss_fp: 0.001325, loss_freq: 0.034558
[19:41:47.879] iteration 28729: loss: 0.048268, loss_s1: 0.036462, loss_fp: 0.004690, loss_freq: 0.021862
[19:41:48.551] iteration 28730: loss: 0.044505, loss_s1: 0.029644, loss_fp: 0.001012, loss_freq: 0.028202
[19:41:49.190] iteration 28731: loss: 0.046875, loss_s1: 0.038119, loss_fp: 0.004903, loss_freq: 0.011031
[19:41:49.833] iteration 28732: loss: 0.061512, loss_s1: 0.052748, loss_fp: 0.001513, loss_freq: 0.030001
[19:41:50.478] iteration 28733: loss: 0.059597, loss_s1: 0.069904, loss_fp: 0.001866, loss_freq: 0.012257
[19:41:51.120] iteration 28734: loss: 0.051409, loss_s1: 0.053478, loss_fp: 0.001127, loss_freq: 0.013622
[19:41:51.756] iteration 28735: loss: 0.052722, loss_s1: 0.070886, loss_fp: 0.001672, loss_freq: 0.009223
[19:41:52.397] iteration 28736: loss: 0.041543, loss_s1: 0.032897, loss_fp: 0.010246, loss_freq: 0.016331
[19:41:53.023] iteration 28737: loss: 0.026480, loss_s1: 0.023487, loss_fp: 0.001359, loss_freq: 0.003573
[19:41:53.655] iteration 28738: loss: 0.064303, loss_s1: 0.040939, loss_fp: 0.003520, loss_freq: 0.052969
[19:41:54.281] iteration 28739: loss: 0.044229, loss_s1: 0.022880, loss_fp: 0.004833, loss_freq: 0.025442
[19:41:54.912] iteration 28740: loss: 0.046981, loss_s1: 0.027510, loss_fp: 0.002562, loss_freq: 0.029916
[19:41:55.537] iteration 28741: loss: 0.045814, loss_s1: 0.042138, loss_fp: 0.002630, loss_freq: 0.014461
[19:41:56.164] iteration 28742: loss: 0.051683, loss_s1: 0.027909, loss_fp: 0.006059, loss_freq: 0.035564
[19:41:56.791] iteration 28743: loss: 0.077789, loss_s1: 0.090355, loss_fp: 0.002812, loss_freq: 0.040581
[19:41:57.420] iteration 28744: loss: 0.041180, loss_s1: 0.033356, loss_fp: 0.004423, loss_freq: 0.012634
[19:41:58.066] iteration 28745: loss: 0.061462, loss_s1: 0.031417, loss_fp: 0.010183, loss_freq: 0.045907
[19:41:58.709] iteration 28746: loss: 0.044120, loss_s1: 0.033986, loss_fp: 0.002551, loss_freq: 0.006842
[19:41:59.352] iteration 28747: loss: 0.063251, loss_s1: 0.053330, loss_fp: 0.008141, loss_freq: 0.034192
[19:41:59.987] iteration 28748: loss: 0.061477, loss_s1: 0.052520, loss_fp: 0.006297, loss_freq: 0.030155
[19:42:00.624] iteration 28749: loss: 0.059840, loss_s1: 0.045174, loss_fp: 0.010328, loss_freq: 0.026367
[19:42:01.281] iteration 28750: loss: 0.055091, loss_s1: 0.034647, loss_fp: 0.004868, loss_freq: 0.041404
[19:42:01.917] iteration 28751: loss: 0.056452, loss_s1: 0.037544, loss_fp: 0.000559, loss_freq: 0.034209
[19:42:02.559] iteration 28752: loss: 0.044709, loss_s1: 0.036370, loss_fp: 0.007155, loss_freq: 0.015586
[19:42:03.198] iteration 28753: loss: 0.085785, loss_s1: 0.083400, loss_fp: 0.011200, loss_freq: 0.036881
[19:42:03.839] iteration 28754: loss: 0.052058, loss_s1: 0.051754, loss_fp: 0.002586, loss_freq: 0.024171
[19:42:04.474] iteration 28755: loss: 0.043693, loss_s1: 0.031262, loss_fp: 0.002383, loss_freq: 0.015958
[19:42:05.107] iteration 28756: loss: 0.041208, loss_s1: 0.036988, loss_fp: 0.000485, loss_freq: 0.012390
[19:42:05.738] iteration 28757: loss: 0.038236, loss_s1: 0.024867, loss_fp: 0.002421, loss_freq: 0.020640
[19:42:06.368] iteration 28758: loss: 0.057908, loss_s1: 0.047597, loss_fp: 0.002876, loss_freq: 0.032166
[19:42:06.992] iteration 28759: loss: 0.053349, loss_s1: 0.058132, loss_fp: 0.001965, loss_freq: 0.023322
[19:42:07.620] iteration 28760: loss: 0.058887, loss_s1: 0.045252, loss_fp: 0.006822, loss_freq: 0.031527
[19:42:08.250] iteration 28761: loss: 0.055212, loss_s1: 0.050348, loss_fp: 0.004373, loss_freq: 0.024577
[19:42:08.872] iteration 28762: loss: 0.040054, loss_s1: 0.033030, loss_fp: 0.001444, loss_freq: 0.018125
[19:42:09.503] iteration 28763: loss: 0.042049, loss_s1: 0.023717, loss_fp: 0.002461, loss_freq: 0.015300
[19:42:10.132] iteration 28764: loss: 0.038405, loss_s1: 0.029064, loss_fp: 0.004628, loss_freq: 0.010313
[19:42:10.756] iteration 28765: loss: 0.026423, loss_s1: 0.011953, loss_fp: 0.001043, loss_freq: 0.010816
[19:42:11.380] iteration 28766: loss: 0.048738, loss_s1: 0.030077, loss_fp: 0.000864, loss_freq: 0.015698
[19:42:12.002] iteration 28767: loss: 0.076899, loss_s1: 0.062045, loss_fp: 0.009171, loss_freq: 0.045912
[19:42:12.626] iteration 28768: loss: 0.085425, loss_s1: 0.107220, loss_fp: 0.003817, loss_freq: 0.025260
[19:42:13.250] iteration 28769: loss: 0.062663, loss_s1: 0.048958, loss_fp: 0.003275, loss_freq: 0.010085
[19:42:13.879] iteration 28770: loss: 0.038728, loss_s1: 0.035966, loss_fp: 0.001469, loss_freq: 0.015446
[19:42:14.508] iteration 28771: loss: 0.038514, loss_s1: 0.043451, loss_fp: 0.001746, loss_freq: 0.005674
[19:42:15.137] iteration 28772: loss: 0.033517, loss_s1: 0.030858, loss_fp: 0.001847, loss_freq: 0.011809
[19:42:15.759] iteration 28773: loss: 0.031124, loss_s1: 0.010922, loss_fp: 0.000574, loss_freq: 0.005706
[19:42:16.382] iteration 28774: loss: 0.080067, loss_s1: 0.068051, loss_fp: 0.006012, loss_freq: 0.051300
[19:42:17.013] iteration 28775: loss: 0.056075, loss_s1: 0.038682, loss_fp: 0.002325, loss_freq: 0.039705
[19:42:17.638] iteration 28776: loss: 0.027056, loss_s1: 0.012624, loss_fp: 0.002427, loss_freq: 0.009210
[19:42:18.265] iteration 28777: loss: 0.066955, loss_s1: 0.064023, loss_fp: 0.001939, loss_freq: 0.028349
[19:42:18.896] iteration 28778: loss: 0.050712, loss_s1: 0.038460, loss_fp: 0.005864, loss_freq: 0.036080
[19:42:19.524] iteration 28779: loss: 0.034809, loss_s1: 0.027327, loss_fp: 0.005504, loss_freq: 0.010190
[19:42:20.151] iteration 28780: loss: 0.059752, loss_s1: 0.045168, loss_fp: 0.005212, loss_freq: 0.027348
[19:42:20.780] iteration 28781: loss: 0.041452, loss_s1: 0.040561, loss_fp: 0.002019, loss_freq: 0.007582
[19:42:21.414] iteration 28782: loss: 0.031142, loss_s1: 0.018806, loss_fp: 0.002568, loss_freq: 0.009875
[19:42:22.054] iteration 28783: loss: 0.046475, loss_s1: 0.032101, loss_fp: 0.008992, loss_freq: 0.016196
[19:42:22.689] iteration 28784: loss: 0.043468, loss_s1: 0.025763, loss_fp: 0.004594, loss_freq: 0.022635
[19:42:23.332] iteration 28785: loss: 0.040773, loss_s1: 0.017826, loss_fp: 0.005603, loss_freq: 0.025919
[19:42:23.966] iteration 28786: loss: 0.046928, loss_s1: 0.019852, loss_fp: 0.003154, loss_freq: 0.014992
[19:42:24.595] iteration 28787: loss: 0.060571, loss_s1: 0.057675, loss_fp: 0.003353, loss_freq: 0.031132
[19:42:25.229] iteration 28788: loss: 0.031862, loss_s1: 0.017415, loss_fp: 0.000932, loss_freq: 0.012859
[19:42:25.857] iteration 28789: loss: 0.044592, loss_s1: 0.022075, loss_fp: 0.001048, loss_freq: 0.027391
[19:42:26.482] iteration 28790: loss: 0.055025, loss_s1: 0.050433, loss_fp: 0.002689, loss_freq: 0.024424
[19:42:27.113] iteration 28791: loss: 0.068466, loss_s1: 0.082299, loss_fp: 0.001784, loss_freq: 0.011112
[19:42:27.765] iteration 28792: loss: 0.043458, loss_s1: 0.044803, loss_fp: 0.000840, loss_freq: 0.015854
[19:42:28.385] iteration 28793: loss: 0.044654, loss_s1: 0.022357, loss_fp: 0.000676, loss_freq: 0.034726
[19:42:29.013] iteration 28794: loss: 0.042181, loss_s1: 0.036238, loss_fp: 0.004531, loss_freq: 0.015745
[19:42:29.641] iteration 28795: loss: 0.028391, loss_s1: 0.012422, loss_fp: 0.002559, loss_freq: 0.009250
[19:42:30.267] iteration 28796: loss: 0.033505, loss_s1: 0.023996, loss_fp: 0.001651, loss_freq: 0.014104
[19:42:30.889] iteration 28797: loss: 0.037727, loss_s1: 0.032368, loss_fp: 0.001747, loss_freq: 0.012114
[19:42:31.517] iteration 28798: loss: 0.052283, loss_s1: 0.042470, loss_fp: 0.003286, loss_freq: 0.016020
[19:42:32.147] iteration 28799: loss: 0.033133, loss_s1: 0.018306, loss_fp: 0.002540, loss_freq: 0.018426
[19:42:32.780] iteration 28800: loss: 0.046942, loss_s1: 0.046071, loss_fp: 0.006209, loss_freq: 0.007296
[19:42:35.974] iteration 28800 : mean_dice : 0.722405
[19:42:36.610] iteration 28801: loss: 0.048047, loss_s1: 0.041668, loss_fp: 0.005056, loss_freq: 0.016567
[19:42:37.229] iteration 28802: loss: 0.075130, loss_s1: 0.060766, loss_fp: 0.005634, loss_freq: 0.049832
[19:42:37.857] iteration 28803: loss: 0.036069, loss_s1: 0.020061, loss_fp: 0.004273, loss_freq: 0.015165
[19:42:38.489] iteration 28804: loss: 0.058395, loss_s1: 0.063050, loss_fp: 0.007335, loss_freq: 0.007168
[19:42:39.115] iteration 28805: loss: 0.078528, loss_s1: 0.071656, loss_fp: 0.008436, loss_freq: 0.054318
[19:42:39.743] iteration 28806: loss: 0.038249, loss_s1: 0.045518, loss_fp: 0.001162, loss_freq: 0.005961
[19:42:40.364] iteration 28807: loss: 0.037188, loss_s1: 0.039139, loss_fp: 0.002580, loss_freq: 0.010778
[19:42:40.998] iteration 28808: loss: 0.071955, loss_s1: 0.046536, loss_fp: 0.009573, loss_freq: 0.055540
[19:42:41.666] iteration 28809: loss: 0.058594, loss_s1: 0.041466, loss_fp: 0.006032, loss_freq: 0.037051
[19:42:42.306] iteration 28810: loss: 0.076752, loss_s1: 0.092285, loss_fp: 0.002953, loss_freq: 0.029902
[19:42:42.947] iteration 28811: loss: 0.050178, loss_s1: 0.045546, loss_fp: 0.004337, loss_freq: 0.022594
[19:42:43.578] iteration 28812: loss: 0.072509, loss_s1: 0.078166, loss_fp: 0.008129, loss_freq: 0.026581
[19:42:44.205] iteration 28813: loss: 0.019425, loss_s1: 0.005488, loss_fp: 0.002057, loss_freq: 0.006048
[19:42:44.833] iteration 28814: loss: 0.028604, loss_s1: 0.016608, loss_fp: 0.002976, loss_freq: 0.009186
[19:42:45.472] iteration 28815: loss: 0.050156, loss_s1: 0.032292, loss_fp: 0.003026, loss_freq: 0.016066
[19:42:46.127] iteration 28816: loss: 0.062923, loss_s1: 0.073258, loss_fp: 0.001065, loss_freq: 0.011093
[19:42:46.762] iteration 28817: loss: 0.051196, loss_s1: 0.029621, loss_fp: 0.014572, loss_freq: 0.025447
[19:42:47.390] iteration 28818: loss: 0.069329, loss_s1: 0.074641, loss_fp: 0.009168, loss_freq: 0.027815
[19:42:48.020] iteration 28819: loss: 0.039224, loss_s1: 0.026251, loss_fp: 0.002794, loss_freq: 0.014253
[19:42:49.026] iteration 28820: loss: 0.031521, loss_s1: 0.016896, loss_fp: 0.001657, loss_freq: 0.012785
[19:42:49.651] iteration 28821: loss: 0.065100, loss_s1: 0.075455, loss_fp: 0.001815, loss_freq: 0.020551
[19:42:50.276] iteration 28822: loss: 0.039451, loss_s1: 0.028540, loss_fp: 0.001170, loss_freq: 0.019733
[19:42:50.900] iteration 28823: loss: 0.034566, loss_s1: 0.016734, loss_fp: 0.001864, loss_freq: 0.013609
[19:42:51.531] iteration 28824: loss: 0.038539, loss_s1: 0.016204, loss_fp: 0.002803, loss_freq: 0.017434
[19:42:52.167] iteration 28825: loss: 0.069771, loss_s1: 0.059501, loss_fp: 0.003447, loss_freq: 0.042496
[19:42:52.796] iteration 28826: loss: 0.037530, loss_s1: 0.018794, loss_fp: 0.003923, loss_freq: 0.025720
[19:42:53.421] iteration 28827: loss: 0.031950, loss_s1: 0.020402, loss_fp: 0.002400, loss_freq: 0.013918
[19:42:54.048] iteration 28828: loss: 0.061062, loss_s1: 0.040980, loss_fp: 0.005319, loss_freq: 0.054150
[19:42:54.671] iteration 28829: loss: 0.043198, loss_s1: 0.026554, loss_fp: 0.009449, loss_freq: 0.015068
[19:42:55.300] iteration 28830: loss: 0.023269, loss_s1: 0.006725, loss_fp: 0.001031, loss_freq: 0.010463
[19:42:55.929] iteration 28831: loss: 0.028341, loss_s1: 0.020353, loss_fp: 0.002086, loss_freq: 0.007569
[19:42:56.556] iteration 28832: loss: 0.068796, loss_s1: 0.051575, loss_fp: 0.012477, loss_freq: 0.047434
[19:42:57.187] iteration 28833: loss: 0.055283, loss_s1: 0.026844, loss_fp: 0.006761, loss_freq: 0.036515
[19:42:57.813] iteration 28834: loss: 0.070937, loss_s1: 0.062879, loss_fp: 0.004509, loss_freq: 0.048425
[19:42:58.443] iteration 28835: loss: 0.072938, loss_s1: 0.064756, loss_fp: 0.004857, loss_freq: 0.042053
[19:42:59.073] iteration 28836: loss: 0.049280, loss_s1: 0.049569, loss_fp: 0.002962, loss_freq: 0.012909
[19:42:59.697] iteration 28837: loss: 0.064891, loss_s1: 0.050232, loss_fp: 0.009951, loss_freq: 0.039214
[19:43:00.328] iteration 28838: loss: 0.031255, loss_s1: 0.017879, loss_fp: 0.002216, loss_freq: 0.010327
[19:43:00.955] iteration 28839: loss: 0.053623, loss_s1: 0.039004, loss_fp: 0.004324, loss_freq: 0.026976
[19:43:01.585] iteration 28840: loss: 0.049455, loss_s1: 0.057155, loss_fp: 0.001230, loss_freq: 0.002955
[19:43:02.212] iteration 28841: loss: 0.039135, loss_s1: 0.018380, loss_fp: 0.004595, loss_freq: 0.018915
[19:43:02.845] iteration 28842: loss: 0.046426, loss_s1: 0.035955, loss_fp: 0.001310, loss_freq: 0.014141
[19:43:03.471] iteration 28843: loss: 0.112264, loss_s1: 0.048065, loss_fp: 0.009556, loss_freq: 0.135039
[19:43:04.103] iteration 28844: loss: 0.031225, loss_s1: 0.021980, loss_fp: 0.002581, loss_freq: 0.007367
[19:43:04.731] iteration 28845: loss: 0.056184, loss_s1: 0.072092, loss_fp: 0.002249, loss_freq: 0.008862
[19:43:05.363] iteration 28846: loss: 0.028203, loss_s1: 0.021024, loss_fp: 0.002176, loss_freq: 0.005257
[19:43:05.993] iteration 28847: loss: 0.051636, loss_s1: 0.035979, loss_fp: 0.013106, loss_freq: 0.019814
[19:43:06.622] iteration 28848: loss: 0.064701, loss_s1: 0.054949, loss_fp: 0.004824, loss_freq: 0.041772
[19:43:07.256] iteration 28849: loss: 0.050589, loss_s1: 0.028148, loss_fp: 0.008105, loss_freq: 0.025834
[19:43:07.884] iteration 28850: loss: 0.071056, loss_s1: 0.054914, loss_fp: 0.010804, loss_freq: 0.049175
[19:43:08.510] iteration 28851: loss: 0.058722, loss_s1: 0.059707, loss_fp: 0.002394, loss_freq: 0.020112
[19:43:09.131] iteration 28852: loss: 0.037287, loss_s1: 0.030703, loss_fp: 0.002136, loss_freq: 0.018824
[19:43:09.759] iteration 28853: loss: 0.028330, loss_s1: 0.014225, loss_fp: 0.003109, loss_freq: 0.007932
[19:43:10.379] iteration 28854: loss: 0.046670, loss_s1: 0.026406, loss_fp: 0.006493, loss_freq: 0.014317
[19:43:11.006] iteration 28855: loss: 0.023275, loss_s1: 0.011404, loss_fp: 0.003467, loss_freq: 0.006446
[19:43:11.627] iteration 28856: loss: 0.056973, loss_s1: 0.060004, loss_fp: 0.006064, loss_freq: 0.017181
[19:43:12.251] iteration 28857: loss: 0.050269, loss_s1: 0.034008, loss_fp: 0.007618, loss_freq: 0.029036
[19:43:12.872] iteration 28858: loss: 0.048097, loss_s1: 0.036027, loss_fp: 0.000894, loss_freq: 0.023001
[19:43:13.498] iteration 28859: loss: 0.080832, loss_s1: 0.061626, loss_fp: 0.003359, loss_freq: 0.041368
[19:43:14.124] iteration 28860: loss: 0.038615, loss_s1: 0.032483, loss_fp: 0.002835, loss_freq: 0.009640
[19:43:14.749] iteration 28861: loss: 0.060654, loss_s1: 0.047436, loss_fp: 0.008900, loss_freq: 0.040528
[19:43:15.418] iteration 28862: loss: 0.063554, loss_s1: 0.049647, loss_fp: 0.003815, loss_freq: 0.039145
[19:43:16.042] iteration 28863: loss: 0.041278, loss_s1: 0.017245, loss_fp: 0.001555, loss_freq: 0.038853
[19:43:16.673] iteration 28864: loss: 0.060017, loss_s1: 0.030433, loss_fp: 0.002334, loss_freq: 0.048820
[19:43:17.294] iteration 28865: loss: 0.042926, loss_s1: 0.048409, loss_fp: 0.005292, loss_freq: 0.002363
[19:43:17.955] iteration 28866: loss: 0.024446, loss_s1: 0.012042, loss_fp: 0.000630, loss_freq: 0.010601
[19:43:18.578] iteration 28867: loss: 0.050855, loss_s1: 0.035201, loss_fp: 0.000909, loss_freq: 0.034972
[19:43:19.203] iteration 28868: loss: 0.068578, loss_s1: 0.074442, loss_fp: 0.001467, loss_freq: 0.013295
[19:43:19.828] iteration 28869: loss: 0.042980, loss_s1: 0.029086, loss_fp: 0.006308, loss_freq: 0.022692
[19:43:20.455] iteration 28870: loss: 0.033075, loss_s1: 0.011604, loss_fp: 0.003658, loss_freq: 0.018738
[19:43:21.078] iteration 28871: loss: 0.039470, loss_s1: 0.014195, loss_fp: 0.003707, loss_freq: 0.016000
[19:43:21.703] iteration 28872: loss: 0.059130, loss_s1: 0.051579, loss_fp: 0.003702, loss_freq: 0.031564
[19:43:22.325] iteration 28873: loss: 0.051710, loss_s1: 0.034179, loss_fp: 0.002346, loss_freq: 0.034619
[19:43:22.952] iteration 28874: loss: 0.034900, loss_s1: 0.008642, loss_fp: 0.001151, loss_freq: 0.016703
[19:43:23.577] iteration 28875: loss: 0.064330, loss_s1: 0.054720, loss_fp: 0.002075, loss_freq: 0.033929
[19:43:24.200] iteration 28876: loss: 0.043994, loss_s1: 0.035929, loss_fp: 0.002831, loss_freq: 0.017279
[19:43:24.821] iteration 28877: loss: 0.049364, loss_s1: 0.024851, loss_fp: 0.002432, loss_freq: 0.014098
[19:43:25.447] iteration 28878: loss: 0.028599, loss_s1: 0.023318, loss_fp: 0.001634, loss_freq: 0.007330
[19:43:26.071] iteration 28879: loss: 0.042118, loss_s1: 0.029190, loss_fp: 0.001310, loss_freq: 0.021369
[19:43:26.696] iteration 28880: loss: 0.043729, loss_s1: 0.037532, loss_fp: 0.002748, loss_freq: 0.021505
[19:43:27.321] iteration 28881: loss: 0.050550, loss_s1: 0.036451, loss_fp: 0.001504, loss_freq: 0.021374
[19:43:27.944] iteration 28882: loss: 0.031438, loss_s1: 0.015406, loss_fp: 0.000677, loss_freq: 0.006480
[19:43:28.573] iteration 28883: loss: 0.058497, loss_s1: 0.060680, loss_fp: 0.001305, loss_freq: 0.017976
[19:43:29.200] iteration 28884: loss: 0.076611, loss_s1: 0.059585, loss_fp: 0.003197, loss_freq: 0.050543
[19:43:29.828] iteration 28885: loss: 0.073146, loss_s1: 0.029425, loss_fp: 0.001517, loss_freq: 0.094234
[19:43:30.459] iteration 28886: loss: 0.049018, loss_s1: 0.024347, loss_fp: 0.002245, loss_freq: 0.038801
[19:43:31.083] iteration 28887: loss: 0.067073, loss_s1: 0.069868, loss_fp: 0.007192, loss_freq: 0.032673
[19:43:31.708] iteration 28888: loss: 0.047321, loss_s1: 0.032586, loss_fp: 0.009032, loss_freq: 0.026260
[19:43:32.334] iteration 28889: loss: 0.057099, loss_s1: 0.032929, loss_fp: 0.002980, loss_freq: 0.022220
[19:43:32.960] iteration 28890: loss: 0.070557, loss_s1: 0.041139, loss_fp: 0.014966, loss_freq: 0.059900
[19:43:33.588] iteration 28891: loss: 0.038390, loss_s1: 0.018695, loss_fp: 0.005462, loss_freq: 0.022242
[19:43:34.214] iteration 28892: loss: 0.031359, loss_s1: 0.022618, loss_fp: 0.001068, loss_freq: 0.008697
[19:43:34.843] iteration 28893: loss: 0.045997, loss_s1: 0.025820, loss_fp: 0.002576, loss_freq: 0.022350
[19:43:35.469] iteration 28894: loss: 0.044785, loss_s1: 0.025878, loss_fp: 0.001281, loss_freq: 0.010258
[19:43:36.094] iteration 28895: loss: 0.033770, loss_s1: 0.015665, loss_fp: 0.001285, loss_freq: 0.004612
[19:43:36.715] iteration 28896: loss: 0.028359, loss_s1: 0.017216, loss_fp: 0.000651, loss_freq: 0.008154
[19:43:37.346] iteration 28897: loss: 0.031110, loss_s1: 0.015557, loss_fp: 0.008645, loss_freq: 0.010120
[19:43:37.974] iteration 28898: loss: 0.037829, loss_s1: 0.035761, loss_fp: 0.000953, loss_freq: 0.008279
[19:43:38.608] iteration 28899: loss: 0.062865, loss_s1: 0.041077, loss_fp: 0.007084, loss_freq: 0.046696
[19:43:39.232] iteration 28900: loss: 0.055539, loss_s1: 0.052958, loss_fp: 0.002080, loss_freq: 0.018641
[19:43:39.861] iteration 28901: loss: 0.075652, loss_s1: 0.084821, loss_fp: 0.001753, loss_freq: 0.034120
[19:43:40.507] iteration 28902: loss: 0.051142, loss_s1: 0.042048, loss_fp: 0.011642, loss_freq: 0.020082
[19:43:41.145] iteration 28903: loss: 0.049401, loss_s1: 0.019397, loss_fp: 0.005348, loss_freq: 0.043958
[19:43:41.781] iteration 28904: loss: 0.087079, loss_s1: 0.090884, loss_fp: 0.010084, loss_freq: 0.048638
[19:43:42.416] iteration 28905: loss: 0.057791, loss_s1: 0.056958, loss_fp: 0.001985, loss_freq: 0.025051
[19:43:43.045] iteration 28906: loss: 0.048819, loss_s1: 0.041262, loss_fp: 0.003248, loss_freq: 0.004375
[19:43:43.671] iteration 28907: loss: 0.030756, loss_s1: 0.016758, loss_fp: 0.002207, loss_freq: 0.013129
[19:43:44.295] iteration 28908: loss: 0.049786, loss_s1: 0.047550, loss_fp: 0.004719, loss_freq: 0.016789
[19:43:44.920] iteration 28909: loss: 0.060642, loss_s1: 0.064300, loss_fp: 0.001101, loss_freq: 0.029176
[19:43:45.544] iteration 28910: loss: 0.053573, loss_s1: 0.035196, loss_fp: 0.003533, loss_freq: 0.028413
[19:43:46.168] iteration 28911: loss: 0.062941, loss_s1: 0.039421, loss_fp: 0.003827, loss_freq: 0.052139
[19:43:46.799] iteration 28912: loss: 0.039262, loss_s1: 0.021937, loss_fp: 0.003638, loss_freq: 0.011653
[19:43:47.426] iteration 28913: loss: 0.035588, loss_s1: 0.009208, loss_fp: 0.003309, loss_freq: 0.025558
[19:43:48.052] iteration 28914: loss: 0.043237, loss_s1: 0.030110, loss_fp: 0.005137, loss_freq: 0.030032
[19:43:48.675] iteration 28915: loss: 0.046502, loss_s1: 0.037445, loss_fp: 0.000821, loss_freq: 0.027872
[19:43:49.313] iteration 28916: loss: 0.028277, loss_s1: 0.007901, loss_fp: 0.001241, loss_freq: 0.019748
[19:43:49.941] iteration 28917: loss: 0.037795, loss_s1: 0.016086, loss_fp: 0.001104, loss_freq: 0.015383
[19:43:50.565] iteration 28918: loss: 0.041958, loss_s1: 0.044987, loss_fp: 0.000846, loss_freq: 0.011476
[19:43:51.188] iteration 28919: loss: 0.040248, loss_s1: 0.034978, loss_fp: 0.005777, loss_freq: 0.011389
[19:43:51.811] iteration 28920: loss: 0.053382, loss_s1: 0.062631, loss_fp: 0.001984, loss_freq: 0.012886
[19:43:52.431] iteration 28921: loss: 0.060351, loss_s1: 0.041591, loss_fp: 0.003369, loss_freq: 0.035569
[19:43:53.058] iteration 28922: loss: 0.042571, loss_s1: 0.036753, loss_fp: 0.001111, loss_freq: 0.019456
[19:43:53.686] iteration 28923: loss: 0.046981, loss_s1: 0.046972, loss_fp: 0.007051, loss_freq: 0.009258
[19:43:54.353] iteration 28924: loss: 0.060847, loss_s1: 0.057311, loss_fp: 0.004639, loss_freq: 0.007495
[19:43:54.996] iteration 28925: loss: 0.034583, loss_s1: 0.027276, loss_fp: 0.002561, loss_freq: 0.012549
[19:43:55.642] iteration 28926: loss: 0.017712, loss_s1: 0.003488, loss_fp: 0.000453, loss_freq: 0.002421
[19:43:56.284] iteration 28927: loss: 0.057282, loss_s1: 0.065429, loss_fp: 0.001901, loss_freq: 0.019704
[19:43:56.926] iteration 28928: loss: 0.060709, loss_s1: 0.030514, loss_fp: 0.007338, loss_freq: 0.048392
[19:43:57.557] iteration 28929: loss: 0.051333, loss_s1: 0.040955, loss_fp: 0.000840, loss_freq: 0.016391
[19:43:58.189] iteration 28930: loss: 0.062153, loss_s1: 0.061467, loss_fp: 0.008558, loss_freq: 0.015070
[19:43:58.817] iteration 28931: loss: 0.064067, loss_s1: 0.053556, loss_fp: 0.005799, loss_freq: 0.037469
[19:43:59.448] iteration 28932: loss: 0.053995, loss_s1: 0.047980, loss_fp: 0.002525, loss_freq: 0.024739
[19:44:00.078] iteration 28933: loss: 0.036408, loss_s1: 0.022056, loss_fp: 0.003005, loss_freq: 0.023684
[19:44:00.708] iteration 28934: loss: 0.034605, loss_s1: 0.016471, loss_fp: 0.002137, loss_freq: 0.009960
[19:44:01.341] iteration 28935: loss: 0.073863, loss_s1: 0.089705, loss_fp: 0.012272, loss_freq: 0.017561
[19:44:01.974] iteration 28936: loss: 0.033191, loss_s1: 0.029241, loss_fp: 0.001348, loss_freq: 0.009750
[19:44:02.607] iteration 28937: loss: 0.042305, loss_s1: 0.038304, loss_fp: 0.015902, loss_freq: 0.005000
[19:44:03.240] iteration 28938: loss: 0.054073, loss_s1: 0.044581, loss_fp: 0.005614, loss_freq: 0.024607
[19:44:03.876] iteration 28939: loss: 0.047101, loss_s1: 0.021796, loss_fp: 0.002805, loss_freq: 0.043113
[19:44:04.516] iteration 28940: loss: 0.039005, loss_s1: 0.021540, loss_fp: 0.009684, loss_freq: 0.020032
[19:44:05.189] iteration 28941: loss: 0.055988, loss_s1: 0.043691, loss_fp: 0.003526, loss_freq: 0.025320
[19:44:05.896] iteration 28942: loss: 0.052288, loss_s1: 0.056869, loss_fp: 0.004319, loss_freq: 0.009762
[19:44:06.548] iteration 28943: loss: 0.024874, loss_s1: 0.018113, loss_fp: 0.000315, loss_freq: 0.002439
[19:44:07.175] iteration 28944: loss: 0.034894, loss_s1: 0.013485, loss_fp: 0.004651, loss_freq: 0.025614
[19:44:07.799] iteration 28945: loss: 0.033619, loss_s1: 0.026517, loss_fp: 0.000588, loss_freq: 0.007452
[19:44:08.430] iteration 28946: loss: 0.050662, loss_s1: 0.048333, loss_fp: 0.004456, loss_freq: 0.012573
[19:44:09.056] iteration 28947: loss: 0.105491, loss_s1: 0.094020, loss_fp: 0.030961, loss_freq: 0.046043
[19:44:09.688] iteration 28948: loss: 0.059282, loss_s1: 0.043438, loss_fp: 0.007931, loss_freq: 0.038493
[19:44:10.348] iteration 28949: loss: 0.054827, loss_s1: 0.059350, loss_fp: 0.002880, loss_freq: 0.018495
[19:44:10.976] iteration 28950: loss: 0.070484, loss_s1: 0.054857, loss_fp: 0.009802, loss_freq: 0.051487
[19:44:11.600] iteration 28951: loss: 0.045115, loss_s1: 0.041367, loss_fp: 0.001015, loss_freq: 0.014089
[19:44:12.228] iteration 28952: loss: 0.072922, loss_s1: 0.081544, loss_fp: 0.003947, loss_freq: 0.027520
[19:44:12.859] iteration 28953: loss: 0.049262, loss_s1: 0.050877, loss_fp: 0.006927, loss_freq: 0.015754
[19:44:13.498] iteration 28954: loss: 0.045992, loss_s1: 0.043151, loss_fp: 0.002471, loss_freq: 0.014941
[19:44:14.130] iteration 28955: loss: 0.040080, loss_s1: 0.042034, loss_fp: 0.004888, loss_freq: 0.010289
[19:44:14.760] iteration 28956: loss: 0.045809, loss_s1: 0.019033, loss_fp: 0.002731, loss_freq: 0.014094
[19:44:15.384] iteration 28957: loss: 0.040725, loss_s1: 0.041157, loss_fp: 0.002289, loss_freq: 0.010632
[19:44:16.012] iteration 28958: loss: 0.033740, loss_s1: 0.023655, loss_fp: 0.002198, loss_freq: 0.010971
[19:44:16.643] iteration 28959: loss: 0.092568, loss_s1: 0.096245, loss_fp: 0.002017, loss_freq: 0.043372
[19:44:17.277] iteration 28960: loss: 0.041201, loss_s1: 0.028453, loss_fp: 0.003532, loss_freq: 0.017880
[19:44:17.903] iteration 28961: loss: 0.047691, loss_s1: 0.032680, loss_fp: 0.002565, loss_freq: 0.030819
[19:44:18.533] iteration 28962: loss: 0.048874, loss_s1: 0.030841, loss_fp: 0.005055, loss_freq: 0.027548
[19:44:19.157] iteration 28963: loss: 0.063524, loss_s1: 0.057871, loss_fp: 0.002631, loss_freq: 0.023870
[19:44:19.799] iteration 28964: loss: 0.032273, loss_s1: 0.019654, loss_fp: 0.004976, loss_freq: 0.008183
[19:44:20.426] iteration 28965: loss: 0.073477, loss_s1: 0.072706, loss_fp: 0.018939, loss_freq: 0.012553
[19:44:21.050] iteration 28966: loss: 0.063803, loss_s1: 0.042509, loss_fp: 0.005427, loss_freq: 0.053397
[19:44:21.681] iteration 28967: loss: 0.039200, loss_s1: 0.034873, loss_fp: 0.006444, loss_freq: 0.010914
[19:44:22.307] iteration 28968: loss: 0.042112, loss_s1: 0.028624, loss_fp: 0.004470, loss_freq: 0.027403
[19:44:22.936] iteration 28969: loss: 0.125755, loss_s1: 0.134613, loss_fp: 0.002308, loss_freq: 0.075865
[19:44:23.564] iteration 28970: loss: 0.043749, loss_s1: 0.021589, loss_fp: 0.003583, loss_freq: 0.025417
[19:44:24.187] iteration 28971: loss: 0.058262, loss_s1: 0.058698, loss_fp: 0.003214, loss_freq: 0.031260
[19:44:24.821] iteration 28972: loss: 0.045593, loss_s1: 0.035456, loss_fp: 0.003966, loss_freq: 0.014009
[19:44:25.446] iteration 28973: loss: 0.055480, loss_s1: 0.029355, loss_fp: 0.007577, loss_freq: 0.036094
[19:44:26.077] iteration 28974: loss: 0.035671, loss_s1: 0.025873, loss_fp: 0.002953, loss_freq: 0.016727
[19:44:26.707] iteration 28975: loss: 0.040104, loss_s1: 0.036794, loss_fp: 0.001364, loss_freq: 0.007893
[19:44:27.337] iteration 28976: loss: 0.032926, loss_s1: 0.015663, loss_fp: 0.000393, loss_freq: 0.011586
[19:44:27.963] iteration 28977: loss: 0.081805, loss_s1: 0.082311, loss_fp: 0.011196, loss_freq: 0.041229
[19:44:28.593] iteration 28978: loss: 0.049821, loss_s1: 0.042884, loss_fp: 0.000662, loss_freq: 0.024804
[19:44:29.221] iteration 28979: loss: 0.047118, loss_s1: 0.030217, loss_fp: 0.001183, loss_freq: 0.025324
[19:44:29.843] iteration 28980: loss: 0.048795, loss_s1: 0.012257, loss_fp: 0.004573, loss_freq: 0.039326
[19:44:30.777] iteration 28981: loss: 0.043746, loss_s1: 0.040531, loss_fp: 0.001084, loss_freq: 0.012016
[19:44:31.424] iteration 28982: loss: 0.097781, loss_s1: 0.124780, loss_fp: 0.003520, loss_freq: 0.019890
[19:44:32.048] iteration 28983: loss: 0.033722, loss_s1: 0.021259, loss_fp: 0.002005, loss_freq: 0.010573
[19:44:32.712] iteration 28984: loss: 0.034913, loss_s1: 0.020474, loss_fp: 0.001909, loss_freq: 0.011061
[19:44:33.351] iteration 28985: loss: 0.051891, loss_s1: 0.043552, loss_fp: 0.008151, loss_freq: 0.021527
[19:44:33.997] iteration 28986: loss: 0.090011, loss_s1: 0.071202, loss_fp: 0.014878, loss_freq: 0.039261
[19:44:34.628] iteration 28987: loss: 0.045389, loss_s1: 0.024570, loss_fp: 0.001850, loss_freq: 0.038123
[19:44:35.287] iteration 28988: loss: 0.029279, loss_s1: 0.015771, loss_fp: 0.001607, loss_freq: 0.011803
[19:44:35.925] iteration 28989: loss: 0.041254, loss_s1: 0.027692, loss_fp: 0.005515, loss_freq: 0.027565
[19:44:36.568] iteration 28990: loss: 0.079979, loss_s1: 0.077778, loss_fp: 0.010622, loss_freq: 0.032765
[19:44:37.200] iteration 28991: loss: 0.025891, loss_s1: 0.013270, loss_fp: 0.003694, loss_freq: 0.003263
[19:44:37.842] iteration 28992: loss: 0.034301, loss_s1: 0.021502, loss_fp: 0.002059, loss_freq: 0.014120
[19:44:38.472] iteration 28993: loss: 0.060837, loss_s1: 0.028454, loss_fp: 0.006150, loss_freq: 0.060802
[19:44:39.104] iteration 28994: loss: 0.053795, loss_s1: 0.035051, loss_fp: 0.002609, loss_freq: 0.029179
[19:44:39.730] iteration 28995: loss: 0.042899, loss_s1: 0.044829, loss_fp: 0.001408, loss_freq: 0.014394
[19:44:40.369] iteration 28996: loss: 0.078797, loss_s1: 0.053069, loss_fp: 0.020217, loss_freq: 0.055637
[19:44:40.996] iteration 28997: loss: 0.047239, loss_s1: 0.046055, loss_fp: 0.001534, loss_freq: 0.017330
[19:44:41.629] iteration 28998: loss: 0.045677, loss_s1: 0.023492, loss_fp: 0.003102, loss_freq: 0.030819
[19:44:42.255] iteration 28999: loss: 0.038715, loss_s1: 0.009714, loss_fp: 0.000920, loss_freq: 0.027493
[19:44:42.883] iteration 29000: loss: 0.057730, loss_s1: 0.039179, loss_fp: 0.004039, loss_freq: 0.038775
[19:44:45.963] iteration 29000 : mean_dice : 0.731465
[19:44:46.609] iteration 29001: loss: 0.029649, loss_s1: 0.011256, loss_fp: 0.003842, loss_freq: 0.006006
[19:44:47.234] iteration 29002: loss: 0.058727, loss_s1: 0.050438, loss_fp: 0.003721, loss_freq: 0.031314
[19:44:47.864] iteration 29003: loss: 0.042660, loss_s1: 0.035561, loss_fp: 0.001204, loss_freq: 0.012512
[19:44:48.498] iteration 29004: loss: 0.079232, loss_s1: 0.073459, loss_fp: 0.007848, loss_freq: 0.050201
[19:44:49.125] iteration 29005: loss: 0.041980, loss_s1: 0.030992, loss_fp: 0.004984, loss_freq: 0.020415
[19:44:49.750] iteration 29006: loss: 0.055160, loss_s1: 0.042344, loss_fp: 0.003000, loss_freq: 0.027575
[19:44:50.379] iteration 29007: loss: 0.046666, loss_s1: 0.039666, loss_fp: 0.000749, loss_freq: 0.007211
[19:44:51.002] iteration 29008: loss: 0.065097, loss_s1: 0.051079, loss_fp: 0.014797, loss_freq: 0.026667
[19:44:51.628] iteration 29009: loss: 0.059290, loss_s1: 0.045736, loss_fp: 0.009712, loss_freq: 0.034979
[19:44:52.260] iteration 29010: loss: 0.032477, loss_s1: 0.007913, loss_fp: 0.002896, loss_freq: 0.025962
[19:44:52.915] iteration 29011: loss: 0.045624, loss_s1: 0.026085, loss_fp: 0.005879, loss_freq: 0.033035
[19:44:53.552] iteration 29012: loss: 0.033141, loss_s1: 0.022817, loss_fp: 0.003589, loss_freq: 0.008930
[19:44:54.191] iteration 29013: loss: 0.053621, loss_s1: 0.062667, loss_fp: 0.003228, loss_freq: 0.009150
[19:44:54.824] iteration 29014: loss: 0.039553, loss_s1: 0.035842, loss_fp: 0.002280, loss_freq: 0.015270
[19:44:55.453] iteration 29015: loss: 0.062610, loss_s1: 0.040565, loss_fp: 0.007182, loss_freq: 0.043981
[19:44:56.081] iteration 29016: loss: 0.072720, loss_s1: 0.056665, loss_fp: 0.009339, loss_freq: 0.052656
[19:44:56.709] iteration 29017: loss: 0.044087, loss_s1: 0.019060, loss_fp: 0.008448, loss_freq: 0.017420
[19:44:57.334] iteration 29018: loss: 0.041989, loss_s1: 0.034296, loss_fp: 0.001147, loss_freq: 0.021758
[19:44:57.957] iteration 29019: loss: 0.045824, loss_s1: 0.034740, loss_fp: 0.003343, loss_freq: 0.021103
[19:44:58.588] iteration 29020: loss: 0.067836, loss_s1: 0.080344, loss_fp: 0.002724, loss_freq: 0.023560
[19:44:59.214] iteration 29021: loss: 0.034993, loss_s1: 0.019211, loss_fp: 0.001008, loss_freq: 0.007730
[19:44:59.842] iteration 29022: loss: 0.105881, loss_s1: 0.088282, loss_fp: 0.010398, loss_freq: 0.083252
[19:45:00.466] iteration 29023: loss: 0.056823, loss_s1: 0.062517, loss_fp: 0.000975, loss_freq: 0.025695
[19:45:01.089] iteration 29024: loss: 0.049125, loss_s1: 0.032641, loss_fp: 0.002275, loss_freq: 0.041981
[19:45:01.716] iteration 29025: loss: 0.078483, loss_s1: 0.069496, loss_fp: 0.028547, loss_freq: 0.023173
[19:45:02.338] iteration 29026: loss: 0.036284, loss_s1: 0.022973, loss_fp: 0.001500, loss_freq: 0.003434
[19:45:02.961] iteration 29027: loss: 0.054942, loss_s1: 0.057881, loss_fp: 0.000464, loss_freq: 0.016697
[19:45:03.588] iteration 29028: loss: 0.061614, loss_s1: 0.065670, loss_fp: 0.003564, loss_freq: 0.024369
[19:45:04.211] iteration 29029: loss: 0.049373, loss_s1: 0.052024, loss_fp: 0.004767, loss_freq: 0.013553
[19:45:04.843] iteration 29030: loss: 0.053501, loss_s1: 0.044252, loss_fp: 0.004099, loss_freq: 0.028587
[19:45:05.491] iteration 29031: loss: 0.041651, loss_s1: 0.024133, loss_fp: 0.005747, loss_freq: 0.023665
[19:45:06.132] iteration 29032: loss: 0.062190, loss_s1: 0.055196, loss_fp: 0.002694, loss_freq: 0.024852
[19:45:06.775] iteration 29033: loss: 0.055861, loss_s1: 0.029501, loss_fp: 0.001769, loss_freq: 0.042178
[19:45:07.400] iteration 29034: loss: 0.045266, loss_s1: 0.029737, loss_fp: 0.001063, loss_freq: 0.023356
[19:45:08.024] iteration 29035: loss: 0.037760, loss_s1: 0.020600, loss_fp: 0.006922, loss_freq: 0.018235
[19:45:08.652] iteration 29036: loss: 0.057702, loss_s1: 0.046850, loss_fp: 0.004140, loss_freq: 0.021870
[19:45:09.275] iteration 29037: loss: 0.042556, loss_s1: 0.039646, loss_fp: 0.000636, loss_freq: 0.009718
[19:45:09.904] iteration 29038: loss: 0.038317, loss_s1: 0.012962, loss_fp: 0.000846, loss_freq: 0.018467
[19:45:10.533] iteration 29039: loss: 0.029437, loss_s1: 0.014332, loss_fp: 0.001602, loss_freq: 0.015571
[19:45:11.169] iteration 29040: loss: 0.059020, loss_s1: 0.062481, loss_fp: 0.003671, loss_freq: 0.029286
[19:45:11.800] iteration 29041: loss: 0.037367, loss_s1: 0.028311, loss_fp: 0.000359, loss_freq: 0.019879
[19:45:12.435] iteration 29042: loss: 0.049615, loss_s1: 0.050545, loss_fp: 0.003889, loss_freq: 0.014175
[19:45:13.071] iteration 29043: loss: 0.050278, loss_s1: 0.038662, loss_fp: 0.001990, loss_freq: 0.021099
[19:45:13.698] iteration 29044: loss: 0.063975, loss_s1: 0.079157, loss_fp: 0.003779, loss_freq: 0.015118
[19:45:14.328] iteration 29045: loss: 0.033794, loss_s1: 0.027105, loss_fp: 0.004013, loss_freq: 0.008068
[19:45:14.954] iteration 29046: loss: 0.065185, loss_s1: 0.042693, loss_fp: 0.004392, loss_freq: 0.048478
[19:45:15.576] iteration 29047: loss: 0.051037, loss_s1: 0.012049, loss_fp: 0.009790, loss_freq: 0.038982
[19:45:16.205] iteration 29048: loss: 0.050875, loss_s1: 0.031063, loss_fp: 0.004517, loss_freq: 0.043792
[19:45:16.832] iteration 29049: loss: 0.043563, loss_s1: 0.020843, loss_fp: 0.005462, loss_freq: 0.026897
[19:45:17.464] iteration 29050: loss: 0.055746, loss_s1: 0.053661, loss_fp: 0.007206, loss_freq: 0.013072
[19:45:18.089] iteration 29051: loss: 0.057546, loss_s1: 0.038863, loss_fp: 0.004444, loss_freq: 0.037644
[19:45:18.715] iteration 29052: loss: 0.044545, loss_s1: 0.040127, loss_fp: 0.001215, loss_freq: 0.020041
[19:45:19.349] iteration 29053: loss: 0.068726, loss_s1: 0.047164, loss_fp: 0.002767, loss_freq: 0.016523
[19:45:19.976] iteration 29054: loss: 0.049461, loss_s1: 0.043619, loss_fp: 0.003146, loss_freq: 0.019223
[19:45:20.605] iteration 29055: loss: 0.047292, loss_s1: 0.035354, loss_fp: 0.001990, loss_freq: 0.022457
[19:45:21.232] iteration 29056: loss: 0.048638, loss_s1: 0.049382, loss_fp: 0.001435, loss_freq: 0.005956
[19:45:21.861] iteration 29057: loss: 0.029540, loss_s1: 0.018573, loss_fp: 0.003822, loss_freq: 0.009689
[19:45:22.490] iteration 29058: loss: 0.037390, loss_s1: 0.029459, loss_fp: 0.002933, loss_freq: 0.007143
[19:45:23.115] iteration 29059: loss: 0.033572, loss_s1: 0.022870, loss_fp: 0.001807, loss_freq: 0.015307
[19:45:23.759] iteration 29060: loss: 0.050162, loss_s1: 0.038987, loss_fp: 0.003216, loss_freq: 0.023937
[19:45:24.405] iteration 29061: loss: 0.057101, loss_s1: 0.057041, loss_fp: 0.002684, loss_freq: 0.025779
[19:45:25.044] iteration 29062: loss: 0.047852, loss_s1: 0.044683, loss_fp: 0.006838, loss_freq: 0.015475
[19:45:25.696] iteration 29063: loss: 0.093101, loss_s1: 0.072838, loss_fp: 0.017629, loss_freq: 0.064738
[19:45:26.335] iteration 29064: loss: 0.045035, loss_s1: 0.040793, loss_fp: 0.003350, loss_freq: 0.012439
[19:45:26.964] iteration 29065: loss: 0.055712, loss_s1: 0.065041, loss_fp: 0.001679, loss_freq: 0.020469
[19:45:27.590] iteration 29066: loss: 0.056092, loss_s1: 0.070007, loss_fp: 0.001157, loss_freq: 0.012403
[19:45:28.214] iteration 29067: loss: 0.063420, loss_s1: 0.044073, loss_fp: 0.011333, loss_freq: 0.028706
[19:45:28.861] iteration 29068: loss: 0.072343, loss_s1: 0.072660, loss_fp: 0.003698, loss_freq: 0.022166
[19:45:29.491] iteration 29069: loss: 0.072340, loss_s1: 0.055477, loss_fp: 0.003237, loss_freq: 0.047991
[19:45:30.122] iteration 29070: loss: 0.045235, loss_s1: 0.034403, loss_fp: 0.009689, loss_freq: 0.017978
[19:45:30.748] iteration 29071: loss: 0.066935, loss_s1: 0.071075, loss_fp: 0.005053, loss_freq: 0.025024
[19:45:31.379] iteration 29072: loss: 0.059534, loss_s1: 0.039357, loss_fp: 0.004184, loss_freq: 0.042654
[19:45:32.006] iteration 29073: loss: 0.037800, loss_s1: 0.022187, loss_fp: 0.001778, loss_freq: 0.009718
[19:45:32.633] iteration 29074: loss: 0.032342, loss_s1: 0.023610, loss_fp: 0.003211, loss_freq: 0.010914
[19:45:33.257] iteration 29075: loss: 0.044656, loss_s1: 0.038069, loss_fp: 0.006268, loss_freq: 0.014896
[19:45:33.880] iteration 29076: loss: 0.070062, loss_s1: 0.046329, loss_fp: 0.005706, loss_freq: 0.051872
[19:45:34.546] iteration 29077: loss: 0.032397, loss_s1: 0.011097, loss_fp: 0.003322, loss_freq: 0.020996
[19:45:35.181] iteration 29078: loss: 0.031733, loss_s1: 0.008762, loss_fp: 0.002046, loss_freq: 0.014419
[19:45:35.817] iteration 29079: loss: 0.031638, loss_s1: 0.015116, loss_fp: 0.003837, loss_freq: 0.010566
[19:45:36.452] iteration 29080: loss: 0.063658, loss_s1: 0.050566, loss_fp: 0.005881, loss_freq: 0.017606
[19:45:37.077] iteration 29081: loss: 0.092934, loss_s1: 0.085589, loss_fp: 0.005529, loss_freq: 0.065464
[19:45:37.703] iteration 29082: loss: 0.078435, loss_s1: 0.053159, loss_fp: 0.006783, loss_freq: 0.059343
[19:45:38.332] iteration 29083: loss: 0.058916, loss_s1: 0.065211, loss_fp: 0.002727, loss_freq: 0.022211
[19:45:38.957] iteration 29084: loss: 0.055103, loss_s1: 0.058879, loss_fp: 0.003675, loss_freq: 0.019958
[19:45:39.583] iteration 29085: loss: 0.043430, loss_s1: 0.015693, loss_fp: 0.003203, loss_freq: 0.009596
[19:45:40.209] iteration 29086: loss: 0.054968, loss_s1: 0.049924, loss_fp: 0.005986, loss_freq: 0.024201
[19:45:40.833] iteration 29087: loss: 0.041632, loss_s1: 0.025865, loss_fp: 0.000636, loss_freq: 0.010182
[19:45:41.459] iteration 29088: loss: 0.049858, loss_s1: 0.032807, loss_fp: 0.001935, loss_freq: 0.034445
[19:45:42.087] iteration 29089: loss: 0.078392, loss_s1: 0.043553, loss_fp: 0.017094, loss_freq: 0.058646
[19:45:42.714] iteration 29090: loss: 0.056825, loss_s1: 0.045183, loss_fp: 0.004735, loss_freq: 0.031624
[19:45:43.347] iteration 29091: loss: 0.049815, loss_s1: 0.030546, loss_fp: 0.001499, loss_freq: 0.022690
[19:45:43.980] iteration 29092: loss: 0.073581, loss_s1: 0.056873, loss_fp: 0.008722, loss_freq: 0.055071
[19:45:44.617] iteration 29093: loss: 0.069310, loss_s1: 0.053774, loss_fp: 0.008650, loss_freq: 0.034696
[19:45:45.240] iteration 29094: loss: 0.030141, loss_s1: 0.013582, loss_fp: 0.002292, loss_freq: 0.015731
[19:45:45.864] iteration 29095: loss: 0.028859, loss_s1: 0.012220, loss_fp: 0.002740, loss_freq: 0.005553
[19:45:46.489] iteration 29096: loss: 0.041374, loss_s1: 0.027441, loss_fp: 0.005718, loss_freq: 0.016261
[19:45:47.118] iteration 29097: loss: 0.039718, loss_s1: 0.017339, loss_fp: 0.002968, loss_freq: 0.029099
[19:45:47.743] iteration 29098: loss: 0.029508, loss_s1: 0.015543, loss_fp: 0.002357, loss_freq: 0.014054
[19:45:48.369] iteration 29099: loss: 0.062930, loss_s1: 0.045565, loss_fp: 0.006842, loss_freq: 0.031688
[19:45:48.996] iteration 29100: loss: 0.097940, loss_s1: 0.056234, loss_fp: 0.001969, loss_freq: 0.110875
[19:45:49.623] iteration 29101: loss: 0.040969, loss_s1: 0.028258, loss_fp: 0.003779, loss_freq: 0.022316
[19:45:50.251] iteration 29102: loss: 0.071926, loss_s1: 0.089562, loss_fp: 0.002949, loss_freq: 0.019413
[19:45:50.877] iteration 29103: loss: 0.045173, loss_s1: 0.041681, loss_fp: 0.002879, loss_freq: 0.019505
[19:45:51.505] iteration 29104: loss: 0.036408, loss_s1: 0.021347, loss_fp: 0.005677, loss_freq: 0.017785
[19:45:52.134] iteration 29105: loss: 0.036289, loss_s1: 0.019468, loss_fp: 0.003229, loss_freq: 0.015563
[19:45:52.784] iteration 29106: loss: 0.038039, loss_s1: 0.021153, loss_fp: 0.002220, loss_freq: 0.017197
[19:45:53.413] iteration 29107: loss: 0.042237, loss_s1: 0.041413, loss_fp: 0.001301, loss_freq: 0.008640
[19:45:54.037] iteration 29108: loss: 0.072846, loss_s1: 0.052607, loss_fp: 0.000134, loss_freq: 0.052465
[19:45:54.663] iteration 29109: loss: 0.058400, loss_s1: 0.041493, loss_fp: 0.020748, loss_freq: 0.027157
[19:45:55.299] iteration 29110: loss: 0.040572, loss_s1: 0.031317, loss_fp: 0.004886, loss_freq: 0.012737
[19:45:55.923] iteration 29111: loss: 0.057080, loss_s1: 0.040676, loss_fp: 0.004162, loss_freq: 0.047744
[19:45:56.552] iteration 29112: loss: 0.060101, loss_s1: 0.072012, loss_fp: 0.001350, loss_freq: 0.019382
[19:45:57.182] iteration 29113: loss: 0.060177, loss_s1: 0.053976, loss_fp: 0.001556, loss_freq: 0.026723
[19:45:57.813] iteration 29114: loss: 0.045874, loss_s1: 0.032173, loss_fp: 0.004594, loss_freq: 0.029895
[19:45:58.438] iteration 29115: loss: 0.035996, loss_s1: 0.024170, loss_fp: 0.001463, loss_freq: 0.015706
[19:45:59.064] iteration 29116: loss: 0.043657, loss_s1: 0.031159, loss_fp: 0.004036, loss_freq: 0.025569
[19:45:59.691] iteration 29117: loss: 0.037549, loss_s1: 0.013006, loss_fp: 0.001997, loss_freq: 0.031292
[19:46:00.322] iteration 29118: loss: 0.044744, loss_s1: 0.045766, loss_fp: 0.003354, loss_freq: 0.014752
[19:46:00.950] iteration 29119: loss: 0.039797, loss_s1: 0.028514, loss_fp: 0.008571, loss_freq: 0.013613
[19:46:01.589] iteration 29120: loss: 0.072037, loss_s1: 0.059260, loss_fp: 0.003148, loss_freq: 0.022434
[19:46:02.235] iteration 29121: loss: 0.048244, loss_s1: 0.041173, loss_fp: 0.002303, loss_freq: 0.018266
[19:46:02.884] iteration 29122: loss: 0.034304, loss_s1: 0.019766, loss_fp: 0.003557, loss_freq: 0.010395
[19:46:03.516] iteration 29123: loss: 0.048137, loss_s1: 0.028060, loss_fp: 0.003587, loss_freq: 0.036764
[19:46:04.150] iteration 29124: loss: 0.033904, loss_s1: 0.019532, loss_fp: 0.002383, loss_freq: 0.010421
[19:46:04.786] iteration 29125: loss: 0.034863, loss_s1: 0.026230, loss_fp: 0.002163, loss_freq: 0.008867
[19:46:05.431] iteration 29126: loss: 0.049824, loss_s1: 0.036030, loss_fp: 0.006173, loss_freq: 0.019068
[19:46:06.067] iteration 29127: loss: 0.086088, loss_s1: 0.095015, loss_fp: 0.006463, loss_freq: 0.045792
[19:46:06.697] iteration 29128: loss: 0.035823, loss_s1: 0.037939, loss_fp: 0.001463, loss_freq: 0.006652
[19:46:07.323] iteration 29129: loss: 0.031736, loss_s1: 0.027711, loss_fp: 0.002536, loss_freq: 0.012152
[19:46:07.955] iteration 29130: loss: 0.090435, loss_s1: 0.094015, loss_fp: 0.006691, loss_freq: 0.043566
[19:46:08.587] iteration 29131: loss: 0.038472, loss_s1: 0.018277, loss_fp: 0.005961, loss_freq: 0.020390
[19:46:09.217] iteration 29132: loss: 0.045462, loss_s1: 0.025185, loss_fp: 0.004892, loss_freq: 0.036078
[19:46:09.937] iteration 29133: loss: 0.056306, loss_s1: 0.057050, loss_fp: 0.004680, loss_freq: 0.020844
[19:46:10.647] iteration 29134: loss: 0.045774, loss_s1: 0.033527, loss_fp: 0.001857, loss_freq: 0.018799
[19:46:11.290] iteration 29135: loss: 0.035065, loss_s1: 0.037587, loss_fp: 0.001263, loss_freq: 0.002915
[19:46:11.927] iteration 29136: loss: 0.042450, loss_s1: 0.041557, loss_fp: 0.001063, loss_freq: 0.010574
[19:46:12.554] iteration 29137: loss: 0.024763, loss_s1: 0.012749, loss_fp: 0.000282, loss_freq: 0.005846
[19:46:13.186] iteration 29138: loss: 0.045273, loss_s1: 0.027559, loss_fp: 0.000758, loss_freq: 0.020045
[19:46:13.807] iteration 29139: loss: 0.073944, loss_s1: 0.074501, loss_fp: 0.004176, loss_freq: 0.034195
[19:46:14.432] iteration 29140: loss: 0.027795, loss_s1: 0.011304, loss_fp: 0.001424, loss_freq: 0.016125
[19:46:15.069] iteration 29141: loss: 0.070732, loss_s1: 0.061344, loss_fp: 0.003642, loss_freq: 0.038117
[19:46:16.043] iteration 29142: loss: 0.031377, loss_s1: 0.027807, loss_fp: 0.004319, loss_freq: 0.006240
[19:46:16.671] iteration 29143: loss: 0.041946, loss_s1: 0.029053, loss_fp: 0.002569, loss_freq: 0.018178
[19:46:17.303] iteration 29144: loss: 0.048522, loss_s1: 0.039505, loss_fp: 0.002978, loss_freq: 0.015493
[19:46:17.928] iteration 29145: loss: 0.037501, loss_s1: 0.022273, loss_fp: 0.003052, loss_freq: 0.016191
[19:46:18.553] iteration 29146: loss: 0.047245, loss_s1: 0.039537, loss_fp: 0.007516, loss_freq: 0.014899
[19:46:19.179] iteration 29147: loss: 0.069121, loss_s1: 0.032842, loss_fp: 0.008062, loss_freq: 0.047842
[19:46:19.802] iteration 29148: loss: 0.045697, loss_s1: 0.037196, loss_fp: 0.001609, loss_freq: 0.026532
[19:46:20.435] iteration 29149: loss: 0.041283, loss_s1: 0.035057, loss_fp: 0.000473, loss_freq: 0.016568
[19:46:21.076] iteration 29150: loss: 0.049305, loss_s1: 0.043255, loss_fp: 0.003494, loss_freq: 0.026266
[19:46:21.712] iteration 29151: loss: 0.044634, loss_s1: 0.037743, loss_fp: 0.003850, loss_freq: 0.017161
[19:46:22.360] iteration 29152: loss: 0.020962, loss_s1: 0.007321, loss_fp: 0.000666, loss_freq: 0.005388
[19:46:23.021] iteration 29153: loss: 0.043446, loss_s1: 0.036746, loss_fp: 0.003361, loss_freq: 0.015977
[19:46:23.658] iteration 29154: loss: 0.069407, loss_s1: 0.038483, loss_fp: 0.001875, loss_freq: 0.070869
[19:46:24.289] iteration 29155: loss: 0.048605, loss_s1: 0.043811, loss_fp: 0.003327, loss_freq: 0.016841
[19:46:24.922] iteration 29156: loss: 0.034090, loss_s1: 0.035667, loss_fp: 0.001403, loss_freq: 0.007905
[19:46:25.556] iteration 29157: loss: 0.130334, loss_s1: 0.102544, loss_fp: 0.005932, loss_freq: 0.119176
[19:46:26.187] iteration 29158: loss: 0.035013, loss_s1: 0.012592, loss_fp: 0.004719, loss_freq: 0.006780
[19:46:26.821] iteration 29159: loss: 0.044425, loss_s1: 0.026275, loss_fp: 0.007080, loss_freq: 0.027313
[19:46:27.454] iteration 29160: loss: 0.039113, loss_s1: 0.022405, loss_fp: 0.005981, loss_freq: 0.011868
[19:46:28.087] iteration 29161: loss: 0.045353, loss_s1: 0.028388, loss_fp: 0.003260, loss_freq: 0.027162
[19:46:28.729] iteration 29162: loss: 0.039319, loss_s1: 0.016155, loss_fp: 0.002736, loss_freq: 0.015025
[19:46:29.371] iteration 29163: loss: 0.048264, loss_s1: 0.026291, loss_fp: 0.003416, loss_freq: 0.033606
[19:46:30.018] iteration 29164: loss: 0.048298, loss_s1: 0.042609, loss_fp: 0.005489, loss_freq: 0.003161
[19:46:30.652] iteration 29165: loss: 0.041379, loss_s1: 0.041680, loss_fp: 0.005047, loss_freq: 0.009911
[19:46:31.283] iteration 29166: loss: 0.032939, loss_s1: 0.019916, loss_fp: 0.002701, loss_freq: 0.015214
[19:46:31.914] iteration 29167: loss: 0.054806, loss_s1: 0.047576, loss_fp: 0.000774, loss_freq: 0.034915
[19:46:32.551] iteration 29168: loss: 0.046819, loss_s1: 0.048466, loss_fp: 0.003314, loss_freq: 0.009465
[19:46:33.174] iteration 29169: loss: 0.060091, loss_s1: 0.052073, loss_fp: 0.006589, loss_freq: 0.026138
[19:46:33.803] iteration 29170: loss: 0.064676, loss_s1: 0.063054, loss_fp: 0.004712, loss_freq: 0.033071
[19:46:34.429] iteration 29171: loss: 0.026783, loss_s1: 0.019186, loss_fp: 0.001948, loss_freq: 0.004993
[19:46:35.057] iteration 29172: loss: 0.038079, loss_s1: 0.024283, loss_fp: 0.005111, loss_freq: 0.020022
[19:46:35.690] iteration 29173: loss: 0.043587, loss_s1: 0.023135, loss_fp: 0.006778, loss_freq: 0.023430
[19:46:36.319] iteration 29174: loss: 0.050386, loss_s1: 0.018472, loss_fp: 0.002400, loss_freq: 0.049509
[19:46:36.946] iteration 29175: loss: 0.034469, loss_s1: 0.031648, loss_fp: 0.003990, loss_freq: 0.004817
[19:46:37.579] iteration 29176: loss: 0.053740, loss_s1: 0.038820, loss_fp: 0.003385, loss_freq: 0.029189
[19:46:38.208] iteration 29177: loss: 0.056559, loss_s1: 0.043622, loss_fp: 0.005049, loss_freq: 0.024452
[19:46:38.839] iteration 29178: loss: 0.096567, loss_s1: 0.070660, loss_fp: 0.002836, loss_freq: 0.057237
[19:46:39.479] iteration 29179: loss: 0.043419, loss_s1: 0.020216, loss_fp: 0.005449, loss_freq: 0.025700
[19:46:40.108] iteration 29180: loss: 0.046328, loss_s1: 0.052145, loss_fp: 0.001312, loss_freq: 0.005553
[19:46:40.730] iteration 29181: loss: 0.063978, loss_s1: 0.059909, loss_fp: 0.003031, loss_freq: 0.025693
[19:46:41.355] iteration 29182: loss: 0.040859, loss_s1: 0.023508, loss_fp: 0.003040, loss_freq: 0.023670
[19:46:41.979] iteration 29183: loss: 0.054801, loss_s1: 0.027894, loss_fp: 0.004536, loss_freq: 0.050479
[19:46:42.608] iteration 29184: loss: 0.043139, loss_s1: 0.031913, loss_fp: 0.005710, loss_freq: 0.025731
[19:46:43.232] iteration 29185: loss: 0.042148, loss_s1: 0.024235, loss_fp: 0.005320, loss_freq: 0.026229
[19:46:43.863] iteration 29186: loss: 0.041094, loss_s1: 0.014171, loss_fp: 0.001383, loss_freq: 0.033736
[19:46:44.492] iteration 29187: loss: 0.042719, loss_s1: 0.044063, loss_fp: 0.003946, loss_freq: 0.004184
[19:46:45.123] iteration 29188: loss: 0.029124, loss_s1: 0.022439, loss_fp: 0.001096, loss_freq: 0.008259
[19:46:45.751] iteration 29189: loss: 0.053983, loss_s1: 0.041018, loss_fp: 0.008136, loss_freq: 0.027887
[19:46:46.383] iteration 29190: loss: 0.059313, loss_s1: 0.053766, loss_fp: 0.006810, loss_freq: 0.028012
[19:46:47.011] iteration 29191: loss: 0.040944, loss_s1: 0.039180, loss_fp: 0.002249, loss_freq: 0.014554
[19:46:47.648] iteration 29192: loss: 0.049003, loss_s1: 0.029962, loss_fp: 0.005743, loss_freq: 0.030325
[19:46:48.285] iteration 29193: loss: 0.032620, loss_s1: 0.022374, loss_fp: 0.002701, loss_freq: 0.011701
[19:46:48.924] iteration 29194: loss: 0.056718, loss_s1: 0.046810, loss_fp: 0.007509, loss_freq: 0.030111
[19:46:49.554] iteration 29195: loss: 0.066758, loss_s1: 0.046978, loss_fp: 0.005393, loss_freq: 0.048366
[19:46:50.184] iteration 29196: loss: 0.030243, loss_s1: 0.022375, loss_fp: 0.001446, loss_freq: 0.013069
[19:46:50.811] iteration 29197: loss: 0.044667, loss_s1: 0.027515, loss_fp: 0.002717, loss_freq: 0.024889
[19:46:51.444] iteration 29198: loss: 0.029090, loss_s1: 0.008605, loss_fp: 0.003348, loss_freq: 0.004945
[19:46:52.073] iteration 29199: loss: 0.042874, loss_s1: 0.026478, loss_fp: 0.000434, loss_freq: 0.014764
[19:46:52.740] iteration 29200: loss: 0.030419, loss_s1: 0.012183, loss_fp: 0.004147, loss_freq: 0.011438
[19:46:56.224] iteration 29200 : mean_dice : 0.738767
[19:46:56.903] iteration 29201: loss: 0.036186, loss_s1: 0.019819, loss_fp: 0.001769, loss_freq: 0.027996
[19:46:57.536] iteration 29202: loss: 0.031929, loss_s1: 0.014819, loss_fp: 0.001844, loss_freq: 0.019298
[19:46:58.169] iteration 29203: loss: 0.039304, loss_s1: 0.031958, loss_fp: 0.008336, loss_freq: 0.008424
[19:46:58.811] iteration 29204: loss: 0.047869, loss_s1: 0.030667, loss_fp: 0.002643, loss_freq: 0.024692
[19:46:59.456] iteration 29205: loss: 0.037350, loss_s1: 0.033567, loss_fp: 0.002113, loss_freq: 0.009791
[19:47:00.131] iteration 29206: loss: 0.028827, loss_s1: 0.019284, loss_fp: 0.001861, loss_freq: 0.005915
[19:47:00.778] iteration 29207: loss: 0.054673, loss_s1: 0.024685, loss_fp: 0.013874, loss_freq: 0.037427
[19:47:01.418] iteration 29208: loss: 0.033614, loss_s1: 0.017685, loss_fp: 0.001922, loss_freq: 0.018106
[19:47:02.056] iteration 29209: loss: 0.046429, loss_s1: 0.015349, loss_fp: 0.004384, loss_freq: 0.045851
[19:47:02.694] iteration 29210: loss: 0.042520, loss_s1: 0.023591, loss_fp: 0.009130, loss_freq: 0.014128
[19:47:03.336] iteration 29211: loss: 0.061696, loss_s1: 0.038163, loss_fp: 0.005730, loss_freq: 0.030768
[19:47:03.974] iteration 29212: loss: 0.064560, loss_s1: 0.068707, loss_fp: 0.005458, loss_freq: 0.022118
[19:47:04.630] iteration 29213: loss: 0.041401, loss_s1: 0.026147, loss_fp: 0.001875, loss_freq: 0.023063
[19:47:05.269] iteration 29214: loss: 0.049106, loss_s1: 0.054053, loss_fp: 0.005378, loss_freq: 0.008999
[19:47:05.907] iteration 29215: loss: 0.039021, loss_s1: 0.027309, loss_fp: 0.005873, loss_freq: 0.011824
[19:47:06.542] iteration 29216: loss: 0.066523, loss_s1: 0.031339, loss_fp: 0.012456, loss_freq: 0.054964
[19:47:07.170] iteration 29217: loss: 0.040211, loss_s1: 0.033792, loss_fp: 0.003727, loss_freq: 0.009916
[19:47:07.806] iteration 29218: loss: 0.050922, loss_s1: 0.053098, loss_fp: 0.003598, loss_freq: 0.019084
[19:47:08.442] iteration 29219: loss: 0.029483, loss_s1: 0.012047, loss_fp: 0.003269, loss_freq: 0.014023
[19:47:09.075] iteration 29220: loss: 0.035250, loss_s1: 0.024518, loss_fp: 0.002053, loss_freq: 0.013260
[19:47:09.709] iteration 29221: loss: 0.057429, loss_s1: 0.036875, loss_fp: 0.007927, loss_freq: 0.037766
[19:47:10.340] iteration 29222: loss: 0.047999, loss_s1: 0.041166, loss_fp: 0.001729, loss_freq: 0.011770
[19:47:10.966] iteration 29223: loss: 0.049125, loss_s1: 0.043419, loss_fp: 0.011241, loss_freq: 0.017761
[19:47:11.596] iteration 29224: loss: 0.042307, loss_s1: 0.023560, loss_fp: 0.007765, loss_freq: 0.018874
[19:47:12.229] iteration 29225: loss: 0.054616, loss_s1: 0.047975, loss_fp: 0.006765, loss_freq: 0.020067
[19:47:12.860] iteration 29226: loss: 0.064216, loss_s1: 0.048794, loss_fp: 0.003542, loss_freq: 0.049937
[19:47:13.484] iteration 29227: loss: 0.044925, loss_s1: 0.047991, loss_fp: 0.002209, loss_freq: 0.008836
[19:47:14.112] iteration 29228: loss: 0.042842, loss_s1: 0.020786, loss_fp: 0.002615, loss_freq: 0.014028
[19:47:14.741] iteration 29229: loss: 0.058857, loss_s1: 0.055762, loss_fp: 0.011943, loss_freq: 0.018524
[19:47:15.366] iteration 29230: loss: 0.074655, loss_s1: 0.079613, loss_fp: 0.011235, loss_freq: 0.026580
[19:47:15.994] iteration 29231: loss: 0.060262, loss_s1: 0.060413, loss_fp: 0.002856, loss_freq: 0.025367
[19:47:16.627] iteration 29232: loss: 0.061592, loss_s1: 0.056172, loss_fp: 0.004929, loss_freq: 0.025563
[19:47:17.276] iteration 29233: loss: 0.087796, loss_s1: 0.074781, loss_fp: 0.002827, loss_freq: 0.057001
[19:47:17.906] iteration 29234: loss: 0.064083, loss_s1: 0.049646, loss_fp: 0.003792, loss_freq: 0.034989
[19:47:18.540] iteration 29235: loss: 0.038433, loss_s1: 0.030294, loss_fp: 0.002049, loss_freq: 0.017228
[19:47:19.176] iteration 29236: loss: 0.057389, loss_s1: 0.049569, loss_fp: 0.002896, loss_freq: 0.035444
[19:47:19.804] iteration 29237: loss: 0.074484, loss_s1: 0.067967, loss_fp: 0.010366, loss_freq: 0.040536
[19:47:20.433] iteration 29238: loss: 0.035974, loss_s1: 0.024339, loss_fp: 0.002019, loss_freq: 0.016264
[19:47:21.059] iteration 29239: loss: 0.042295, loss_s1: 0.019033, loss_fp: 0.001302, loss_freq: 0.025150
[19:47:21.689] iteration 29240: loss: 0.056936, loss_s1: 0.059779, loss_fp: 0.008397, loss_freq: 0.017394
[19:47:22.312] iteration 29241: loss: 0.038383, loss_s1: 0.028689, loss_fp: 0.002165, loss_freq: 0.015395
[19:47:22.939] iteration 29242: loss: 0.064205, loss_s1: 0.073616, loss_fp: 0.001026, loss_freq: 0.031262
[19:47:23.567] iteration 29243: loss: 0.052201, loss_s1: 0.029460, loss_fp: 0.003691, loss_freq: 0.024654
[19:47:24.195] iteration 29244: loss: 0.049894, loss_s1: 0.043206, loss_fp: 0.002860, loss_freq: 0.018860
[19:47:24.827] iteration 29245: loss: 0.052140, loss_s1: 0.054009, loss_fp: 0.001989, loss_freq: 0.012685
[19:47:25.450] iteration 29246: loss: 0.044706, loss_s1: 0.029683, loss_fp: 0.002457, loss_freq: 0.010720
[19:47:26.077] iteration 29247: loss: 0.049802, loss_s1: 0.040171, loss_fp: 0.003432, loss_freq: 0.022033
[19:47:26.704] iteration 29248: loss: 0.031291, loss_s1: 0.028263, loss_fp: 0.001229, loss_freq: 0.003910
[19:47:27.332] iteration 29249: loss: 0.066564, loss_s1: 0.063421, loss_fp: 0.002717, loss_freq: 0.029834
[19:47:27.963] iteration 29250: loss: 0.101228, loss_s1: 0.073098, loss_fp: 0.004241, loss_freq: 0.092795
[19:47:28.594] iteration 29251: loss: 0.079098, loss_s1: 0.073430, loss_fp: 0.016365, loss_freq: 0.037109
[19:47:29.225] iteration 29252: loss: 0.042048, loss_s1: 0.027153, loss_fp: 0.002341, loss_freq: 0.016016
[19:47:29.860] iteration 29253: loss: 0.045981, loss_s1: 0.026158, loss_fp: 0.003573, loss_freq: 0.030764
[19:47:30.490] iteration 29254: loss: 0.028612, loss_s1: 0.013405, loss_fp: 0.003233, loss_freq: 0.012882
[19:47:31.117] iteration 29255: loss: 0.042848, loss_s1: 0.039204, loss_fp: 0.003223, loss_freq: 0.017185
[19:47:31.743] iteration 29256: loss: 0.037163, loss_s1: 0.029413, loss_fp: 0.001166, loss_freq: 0.010025
[19:47:32.369] iteration 29257: loss: 0.139501, loss_s1: 0.168597, loss_fp: 0.001900, loss_freq: 0.061268
[19:47:32.995] iteration 29258: loss: 0.052248, loss_s1: 0.051703, loss_fp: 0.002828, loss_freq: 0.023756
[19:47:33.618] iteration 29259: loss: 0.042725, loss_s1: 0.045307, loss_fp: 0.001017, loss_freq: 0.011566
[19:47:34.244] iteration 29260: loss: 0.042931, loss_s1: 0.028217, loss_fp: 0.002511, loss_freq: 0.020650
[19:47:34.869] iteration 29261: loss: 0.061721, loss_s1: 0.050002, loss_fp: 0.001540, loss_freq: 0.048329
[19:47:35.497] iteration 29262: loss: 0.034229, loss_s1: 0.028090, loss_fp: 0.000272, loss_freq: 0.010456
[19:47:36.127] iteration 29263: loss: 0.054108, loss_s1: 0.035900, loss_fp: 0.004880, loss_freq: 0.024525
[19:47:36.753] iteration 29264: loss: 0.050870, loss_s1: 0.043423, loss_fp: 0.002889, loss_freq: 0.025897
[19:47:37.382] iteration 29265: loss: 0.046265, loss_s1: 0.032598, loss_fp: 0.002402, loss_freq: 0.025054
[19:47:38.015] iteration 29266: loss: 0.036383, loss_s1: 0.018997, loss_fp: 0.001282, loss_freq: 0.020235
[19:47:38.645] iteration 29267: loss: 0.058579, loss_s1: 0.036341, loss_fp: 0.003917, loss_freq: 0.034578
[19:47:39.274] iteration 29268: loss: 0.046499, loss_s1: 0.048156, loss_fp: 0.002020, loss_freq: 0.007955
[19:47:39.900] iteration 29269: loss: 0.051212, loss_s1: 0.030626, loss_fp: 0.004112, loss_freq: 0.028758
[19:47:40.536] iteration 29270: loss: 0.054758, loss_s1: 0.034304, loss_fp: 0.006186, loss_freq: 0.041942
[19:47:41.210] iteration 29271: loss: 0.046154, loss_s1: 0.045335, loss_fp: 0.005348, loss_freq: 0.014846
[19:47:41.842] iteration 29272: loss: 0.056661, loss_s1: 0.067868, loss_fp: 0.001180, loss_freq: 0.020489
[19:47:42.497] iteration 29273: loss: 0.059395, loss_s1: 0.073400, loss_fp: 0.001796, loss_freq: 0.014739
[19:47:43.132] iteration 29274: loss: 0.068241, loss_s1: 0.073261, loss_fp: 0.004360, loss_freq: 0.024032
[19:47:43.767] iteration 29275: loss: 0.032841, loss_s1: 0.021862, loss_fp: 0.001169, loss_freq: 0.010175
[19:47:44.407] iteration 29276: loss: 0.048685, loss_s1: 0.035512, loss_fp: 0.002734, loss_freq: 0.029824
[19:47:45.035] iteration 29277: loss: 0.076204, loss_s1: 0.084705, loss_fp: 0.006813, loss_freq: 0.033949
[19:47:45.662] iteration 29278: loss: 0.035546, loss_s1: 0.028442, loss_fp: 0.001617, loss_freq: 0.011939
[19:47:46.283] iteration 29279: loss: 0.032012, loss_s1: 0.021126, loss_fp: 0.002104, loss_freq: 0.013389
[19:47:46.913] iteration 29280: loss: 0.027511, loss_s1: 0.010532, loss_fp: 0.004739, loss_freq: 0.007630
[19:47:47.543] iteration 29281: loss: 0.067552, loss_s1: 0.072221, loss_fp: 0.003464, loss_freq: 0.023488
[19:47:48.178] iteration 29282: loss: 0.068213, loss_s1: 0.058654, loss_fp: 0.001607, loss_freq: 0.029513
[19:47:48.808] iteration 29283: loss: 0.036762, loss_s1: 0.020488, loss_fp: 0.004044, loss_freq: 0.016504
[19:47:49.430] iteration 29284: loss: 0.046738, loss_s1: 0.033553, loss_fp: 0.009273, loss_freq: 0.019235
[19:47:50.053] iteration 29285: loss: 0.043355, loss_s1: 0.024963, loss_fp: 0.001005, loss_freq: 0.024092
[19:47:50.689] iteration 29286: loss: 0.038402, loss_s1: 0.019149, loss_fp: 0.002044, loss_freq: 0.015626
[19:47:51.311] iteration 29287: loss: 0.050579, loss_s1: 0.038652, loss_fp: 0.010097, loss_freq: 0.020507
[19:47:51.938] iteration 29288: loss: 0.061200, loss_s1: 0.044023, loss_fp: 0.005815, loss_freq: 0.044888
[19:47:52.560] iteration 29289: loss: 0.035181, loss_s1: 0.036151, loss_fp: 0.001500, loss_freq: 0.011427
[19:47:53.181] iteration 29290: loss: 0.028488, loss_s1: 0.018145, loss_fp: 0.002734, loss_freq: 0.007099
[19:47:53.804] iteration 29291: loss: 0.090880, loss_s1: 0.043988, loss_fp: 0.020109, loss_freq: 0.080533
[19:47:54.432] iteration 29292: loss: 0.044678, loss_s1: 0.018754, loss_fp: 0.003499, loss_freq: 0.028792
[19:47:55.062] iteration 29293: loss: 0.067776, loss_s1: 0.038504, loss_fp: 0.009149, loss_freq: 0.061577
[19:47:55.693] iteration 29294: loss: 0.040690, loss_s1: 0.035650, loss_fp: 0.005016, loss_freq: 0.016189
[19:47:56.319] iteration 29295: loss: 0.065772, loss_s1: 0.075789, loss_fp: 0.003733, loss_freq: 0.019432
[19:47:56.944] iteration 29296: loss: 0.025949, loss_s1: 0.014472, loss_fp: 0.001115, loss_freq: 0.010305
[19:47:57.579] iteration 29297: loss: 0.054773, loss_s1: 0.061023, loss_fp: 0.001292, loss_freq: 0.015907
[19:47:58.210] iteration 29298: loss: 0.034282, loss_s1: 0.019238, loss_fp: 0.002228, loss_freq: 0.015370
[19:47:58.848] iteration 29299: loss: 0.050965, loss_s1: 0.018980, loss_fp: 0.000857, loss_freq: 0.037112
[19:47:59.484] iteration 29300: loss: 0.066899, loss_s1: 0.081487, loss_fp: 0.006286, loss_freq: 0.015072
[19:48:00.112] iteration 29301: loss: 0.070502, loss_s1: 0.058415, loss_fp: 0.000534, loss_freq: 0.043577
[19:48:00.736] iteration 29302: loss: 0.040116, loss_s1: 0.026741, loss_fp: 0.002108, loss_freq: 0.013220
[19:48:01.674] iteration 29303: loss: 0.028799, loss_s1: 0.013999, loss_fp: 0.001788, loss_freq: 0.010677
[19:48:02.302] iteration 29304: loss: 0.055909, loss_s1: 0.059299, loss_fp: 0.002100, loss_freq: 0.018141
[19:48:02.933] iteration 29305: loss: 0.034105, loss_s1: 0.021262, loss_fp: 0.003708, loss_freq: 0.012173
[19:48:03.568] iteration 29306: loss: 0.027615, loss_s1: 0.015586, loss_fp: 0.001378, loss_freq: 0.007550
[19:48:04.201] iteration 29307: loss: 0.032534, loss_s1: 0.024912, loss_fp: 0.003075, loss_freq: 0.006338
[19:48:04.829] iteration 29308: loss: 0.064422, loss_s1: 0.038175, loss_fp: 0.008923, loss_freq: 0.038927
[19:48:05.462] iteration 29309: loss: 0.038719, loss_s1: 0.031885, loss_fp: 0.010599, loss_freq: 0.010938
[19:48:06.090] iteration 29310: loss: 0.035701, loss_s1: 0.020184, loss_fp: 0.001585, loss_freq: 0.022947
[19:48:06.723] iteration 29311: loss: 0.046273, loss_s1: 0.037874, loss_fp: 0.008248, loss_freq: 0.018502
[19:48:07.347] iteration 29312: loss: 0.042592, loss_s1: 0.026004, loss_fp: 0.001831, loss_freq: 0.019716
[19:48:07.977] iteration 29313: loss: 0.032957, loss_s1: 0.016121, loss_fp: 0.002941, loss_freq: 0.009283
[19:48:08.602] iteration 29314: loss: 0.026432, loss_s1: 0.009975, loss_fp: 0.001581, loss_freq: 0.012241
[19:48:09.231] iteration 29315: loss: 0.055019, loss_s1: 0.048491, loss_fp: 0.005916, loss_freq: 0.028916
[19:48:09.858] iteration 29316: loss: 0.047606, loss_s1: 0.035689, loss_fp: 0.007769, loss_freq: 0.022213
[19:48:10.490] iteration 29317: loss: 0.029985, loss_s1: 0.016024, loss_fp: 0.003401, loss_freq: 0.018578
[19:48:11.115] iteration 29318: loss: 0.091035, loss_s1: 0.067109, loss_fp: 0.008870, loss_freq: 0.074808
[19:48:11.743] iteration 29319: loss: 0.042071, loss_s1: 0.034290, loss_fp: 0.000949, loss_freq: 0.013469
[19:48:12.369] iteration 29320: loss: 0.055534, loss_s1: 0.034007, loss_fp: 0.005007, loss_freq: 0.034348
[19:48:12.989] iteration 29321: loss: 0.032125, loss_s1: 0.017875, loss_fp: 0.003706, loss_freq: 0.013745
[19:48:13.614] iteration 29322: loss: 0.038411, loss_s1: 0.017547, loss_fp: 0.002162, loss_freq: 0.016996
[19:48:14.289] iteration 29323: loss: 0.042211, loss_s1: 0.033216, loss_fp: 0.000802, loss_freq: 0.013914
[19:48:14.937] iteration 29324: loss: 0.044919, loss_s1: 0.034495, loss_fp: 0.004403, loss_freq: 0.017862
[19:48:15.639] iteration 29325: loss: 0.047450, loss_s1: 0.037922, loss_fp: 0.001556, loss_freq: 0.017159
[19:48:16.282] iteration 29326: loss: 0.055576, loss_s1: 0.058264, loss_fp: 0.008178, loss_freq: 0.016404
[19:48:16.925] iteration 29327: loss: 0.052539, loss_s1: 0.046174, loss_fp: 0.005841, loss_freq: 0.017784
[19:48:17.592] iteration 29328: loss: 0.081005, loss_s1: 0.102549, loss_fp: 0.001596, loss_freq: 0.033786
[19:48:18.230] iteration 29329: loss: 0.025222, loss_s1: 0.013617, loss_fp: 0.001596, loss_freq: 0.008121
[19:48:18.866] iteration 29330: loss: 0.072242, loss_s1: 0.083981, loss_fp: 0.001918, loss_freq: 0.023240
[19:48:19.504] iteration 29331: loss: 0.051867, loss_s1: 0.036629, loss_fp: 0.001602, loss_freq: 0.037854
[19:48:20.142] iteration 29332: loss: 0.051146, loss_s1: 0.025336, loss_fp: 0.004647, loss_freq: 0.020998
[19:48:20.787] iteration 29333: loss: 0.032587, loss_s1: 0.019488, loss_fp: 0.006323, loss_freq: 0.011726
[19:48:21.431] iteration 29334: loss: 0.057703, loss_s1: 0.052444, loss_fp: 0.002467, loss_freq: 0.022408
[19:48:22.064] iteration 29335: loss: 0.040829, loss_s1: 0.037244, loss_fp: 0.003857, loss_freq: 0.010930
[19:48:22.721] iteration 29336: loss: 0.027352, loss_s1: 0.017709, loss_fp: 0.002215, loss_freq: 0.008729
[19:48:23.343] iteration 29337: loss: 0.059710, loss_s1: 0.046411, loss_fp: 0.004306, loss_freq: 0.028221
[19:48:23.972] iteration 29338: loss: 0.057592, loss_s1: 0.044626, loss_fp: 0.003137, loss_freq: 0.040746
[19:48:24.595] iteration 29339: loss: 0.079612, loss_s1: 0.073544, loss_fp: 0.003333, loss_freq: 0.033757
[19:48:25.220] iteration 29340: loss: 0.040813, loss_s1: 0.031916, loss_fp: 0.002360, loss_freq: 0.018124
[19:48:25.842] iteration 29341: loss: 0.048702, loss_s1: 0.026151, loss_fp: 0.005673, loss_freq: 0.029486
[19:48:26.469] iteration 29342: loss: 0.061516, loss_s1: 0.055989, loss_fp: 0.002735, loss_freq: 0.032874
[19:48:27.098] iteration 29343: loss: 0.049376, loss_s1: 0.034323, loss_fp: 0.002545, loss_freq: 0.013029
[19:48:27.723] iteration 29344: loss: 0.067774, loss_s1: 0.062846, loss_fp: 0.002035, loss_freq: 0.045611
[19:48:28.349] iteration 29345: loss: 0.066610, loss_s1: 0.060621, loss_fp: 0.014018, loss_freq: 0.029189
[19:48:28.975] iteration 29346: loss: 0.049580, loss_s1: 0.037236, loss_fp: 0.005278, loss_freq: 0.035560
[19:48:29.604] iteration 29347: loss: 0.049743, loss_s1: 0.027461, loss_fp: 0.011280, loss_freq: 0.027165
[19:48:30.233] iteration 29348: loss: 0.038558, loss_s1: 0.025851, loss_fp: 0.008737, loss_freq: 0.004758
[19:48:30.859] iteration 29349: loss: 0.031256, loss_s1: 0.022878, loss_fp: 0.000357, loss_freq: 0.008334
[19:48:31.485] iteration 29350: loss: 0.032917, loss_s1: 0.023137, loss_fp: 0.001285, loss_freq: 0.014277
[19:48:32.111] iteration 29351: loss: 0.057008, loss_s1: 0.055486, loss_fp: 0.005051, loss_freq: 0.016805
[19:48:32.744] iteration 29352: loss: 0.046568, loss_s1: 0.032864, loss_fp: 0.003032, loss_freq: 0.030791
[19:48:33.374] iteration 29353: loss: 0.042265, loss_s1: 0.036679, loss_fp: 0.005045, loss_freq: 0.014617
[19:48:34.001] iteration 29354: loss: 0.036920, loss_s1: 0.027215, loss_fp: 0.003772, loss_freq: 0.012169
[19:48:34.629] iteration 29355: loss: 0.041475, loss_s1: 0.018457, loss_fp: 0.004636, loss_freq: 0.026116
[19:48:35.257] iteration 29356: loss: 0.034415, loss_s1: 0.020840, loss_fp: 0.002092, loss_freq: 0.014088
[19:48:35.885] iteration 29357: loss: 0.043890, loss_s1: 0.038833, loss_fp: 0.005973, loss_freq: 0.013973
[19:48:36.512] iteration 29358: loss: 0.046146, loss_s1: 0.028856, loss_fp: 0.009359, loss_freq: 0.019404
[19:48:37.133] iteration 29359: loss: 0.034622, loss_s1: 0.020194, loss_fp: 0.005794, loss_freq: 0.004357
[19:48:37.763] iteration 29360: loss: 0.045072, loss_s1: 0.033738, loss_fp: 0.001416, loss_freq: 0.019730
[19:48:38.387] iteration 29361: loss: 0.032561, loss_s1: 0.021823, loss_fp: 0.001958, loss_freq: 0.016425
[19:48:39.018] iteration 29362: loss: 0.043123, loss_s1: 0.033804, loss_fp: 0.004518, loss_freq: 0.023027
[19:48:39.643] iteration 29363: loss: 0.027114, loss_s1: 0.014035, loss_fp: 0.003172, loss_freq: 0.014340
[19:48:40.269] iteration 29364: loss: 0.058811, loss_s1: 0.047361, loss_fp: 0.009201, loss_freq: 0.033807
[19:48:40.894] iteration 29365: loss: 0.053729, loss_s1: 0.040216, loss_fp: 0.003086, loss_freq: 0.019744
[19:48:41.526] iteration 29366: loss: 0.034922, loss_s1: 0.017739, loss_fp: 0.001624, loss_freq: 0.020318
[19:48:42.150] iteration 29367: loss: 0.057700, loss_s1: 0.067480, loss_fp: 0.002976, loss_freq: 0.011907
[19:48:42.779] iteration 29368: loss: 0.061292, loss_s1: 0.028107, loss_fp: 0.016636, loss_freq: 0.047345
[19:48:43.401] iteration 29369: loss: 0.061564, loss_s1: 0.020066, loss_fp: 0.013790, loss_freq: 0.057236
[19:48:44.026] iteration 29370: loss: 0.077257, loss_s1: 0.067784, loss_fp: 0.003621, loss_freq: 0.057452
[19:48:44.648] iteration 29371: loss: 0.055148, loss_s1: 0.071991, loss_fp: 0.001750, loss_freq: 0.008823
[19:48:45.271] iteration 29372: loss: 0.049982, loss_s1: 0.035479, loss_fp: 0.002564, loss_freq: 0.022445
[19:48:45.896] iteration 29373: loss: 0.059785, loss_s1: 0.032925, loss_fp: 0.009399, loss_freq: 0.049300
[19:48:46.535] iteration 29374: loss: 0.039850, loss_s1: 0.017432, loss_fp: 0.001221, loss_freq: 0.032437
[19:48:47.166] iteration 29375: loss: 0.044334, loss_s1: 0.031845, loss_fp: 0.005161, loss_freq: 0.015214
[19:48:47.804] iteration 29376: loss: 0.046371, loss_s1: 0.038962, loss_fp: 0.000719, loss_freq: 0.016905
[19:48:48.431] iteration 29377: loss: 0.049197, loss_s1: 0.047190, loss_fp: 0.000834, loss_freq: 0.015254
[19:48:49.055] iteration 29378: loss: 0.054979, loss_s1: 0.064037, loss_fp: 0.004827, loss_freq: 0.006470
[19:48:49.681] iteration 29379: loss: 0.045922, loss_s1: 0.037037, loss_fp: 0.003817, loss_freq: 0.016759
[19:48:50.305] iteration 29380: loss: 0.057509, loss_s1: 0.077901, loss_fp: 0.002117, loss_freq: 0.008619
[19:48:50.930] iteration 29381: loss: 0.026986, loss_s1: 0.014217, loss_fp: 0.001936, loss_freq: 0.006077
[19:48:51.556] iteration 29382: loss: 0.049262, loss_s1: 0.025683, loss_fp: 0.004190, loss_freq: 0.033599
[19:48:52.182] iteration 29383: loss: 0.045577, loss_s1: 0.024373, loss_fp: 0.008857, loss_freq: 0.029765
[19:48:52.808] iteration 29384: loss: 0.051645, loss_s1: 0.057857, loss_fp: 0.006221, loss_freq: 0.015958
[19:48:53.438] iteration 29385: loss: 0.050579, loss_s1: 0.037969, loss_fp: 0.003763, loss_freq: 0.035472
[19:48:54.070] iteration 29386: loss: 0.072224, loss_s1: 0.040662, loss_fp: 0.005981, loss_freq: 0.054552
[19:48:54.695] iteration 29387: loss: 0.135745, loss_s1: 0.144073, loss_fp: 0.011689, loss_freq: 0.092945
[19:48:55.321] iteration 29388: loss: 0.050992, loss_s1: 0.049769, loss_fp: 0.001489, loss_freq: 0.017309
[19:48:55.952] iteration 29389: loss: 0.045224, loss_s1: 0.041691, loss_fp: 0.005579, loss_freq: 0.009857
[19:48:56.586] iteration 29390: loss: 0.040350, loss_s1: 0.032300, loss_fp: 0.004269, loss_freq: 0.015127
[19:48:57.224] iteration 29391: loss: 0.049587, loss_s1: 0.032069, loss_fp: 0.005076, loss_freq: 0.031387
[19:48:57.847] iteration 29392: loss: 0.043550, loss_s1: 0.021170, loss_fp: 0.002515, loss_freq: 0.037249
[19:48:58.474] iteration 29393: loss: 0.048734, loss_s1: 0.026651, loss_fp: 0.001518, loss_freq: 0.035699
[19:48:59.096] iteration 29394: loss: 0.050340, loss_s1: 0.038830, loss_fp: 0.004800, loss_freq: 0.018700
[19:48:59.720] iteration 29395: loss: 0.052843, loss_s1: 0.026315, loss_fp: 0.001252, loss_freq: 0.026158
[19:49:00.343] iteration 29396: loss: 0.045662, loss_s1: 0.026373, loss_fp: 0.010189, loss_freq: 0.028155
[19:49:00.966] iteration 29397: loss: 0.053083, loss_s1: 0.059023, loss_fp: 0.002298, loss_freq: 0.018236
[19:49:01.589] iteration 29398: loss: 0.060273, loss_s1: 0.050768, loss_fp: 0.007933, loss_freq: 0.036132
[19:49:02.217] iteration 29399: loss: 0.034747, loss_s1: 0.013897, loss_fp: 0.001189, loss_freq: 0.021029
[19:49:02.939] iteration 29400: loss: 0.038395, loss_s1: 0.021988, loss_fp: 0.001299, loss_freq: 0.016133
[19:49:05.994] iteration 29400 : mean_dice : 0.730889
[19:49:06.633] iteration 29401: loss: 0.047673, loss_s1: 0.039250, loss_fp: 0.003844, loss_freq: 0.025322
[19:49:07.266] iteration 29402: loss: 0.058352, loss_s1: 0.054636, loss_fp: 0.001908, loss_freq: 0.026627
[19:49:07.895] iteration 29403: loss: 0.060577, loss_s1: 0.065016, loss_fp: 0.005712, loss_freq: 0.020856
[19:49:08.530] iteration 29404: loss: 0.044805, loss_s1: 0.030713, loss_fp: 0.004137, loss_freq: 0.022001
[19:49:09.160] iteration 29405: loss: 0.052277, loss_s1: 0.030165, loss_fp: 0.008407, loss_freq: 0.037389
[19:49:09.796] iteration 29406: loss: 0.040777, loss_s1: 0.017462, loss_fp: 0.005422, loss_freq: 0.025780
[19:49:10.427] iteration 29407: loss: 0.055846, loss_s1: 0.045641, loss_fp: 0.002106, loss_freq: 0.011473
[19:49:11.051] iteration 29408: loss: 0.043134, loss_s1: 0.047520, loss_fp: 0.001098, loss_freq: 0.008883
[19:49:11.696] iteration 29409: loss: 0.039619, loss_s1: 0.036993, loss_fp: 0.005512, loss_freq: 0.006534
[19:49:12.339] iteration 29410: loss: 0.060405, loss_s1: 0.044517, loss_fp: 0.002641, loss_freq: 0.021563
[19:49:12.970] iteration 29411: loss: 0.095883, loss_s1: 0.065713, loss_fp: 0.016353, loss_freq: 0.075108
[19:49:13.598] iteration 29412: loss: 0.049327, loss_s1: 0.037694, loss_fp: 0.001923, loss_freq: 0.026665
[19:49:14.230] iteration 29413: loss: 0.062781, loss_s1: 0.040065, loss_fp: 0.008468, loss_freq: 0.031741
[19:49:14.894] iteration 29414: loss: 0.044681, loss_s1: 0.038447, loss_fp: 0.003018, loss_freq: 0.022681
[19:49:15.555] iteration 29415: loss: 0.027468, loss_s1: 0.017661, loss_fp: 0.003091, loss_freq: 0.005228
[19:49:16.195] iteration 29416: loss: 0.034937, loss_s1: 0.019382, loss_fp: 0.001516, loss_freq: 0.022624
[19:49:16.825] iteration 29417: loss: 0.038681, loss_s1: 0.024742, loss_fp: 0.003159, loss_freq: 0.005659
[19:49:17.464] iteration 29418: loss: 0.043731, loss_s1: 0.030565, loss_fp: 0.000808, loss_freq: 0.024626
[19:49:18.095] iteration 29419: loss: 0.057976, loss_s1: 0.032907, loss_fp: 0.002406, loss_freq: 0.049997
[19:49:18.723] iteration 29420: loss: 0.045683, loss_s1: 0.031712, loss_fp: 0.010986, loss_freq: 0.022596
[19:49:19.352] iteration 29421: loss: 0.039879, loss_s1: 0.019212, loss_fp: 0.003113, loss_freq: 0.028456
[19:49:19.976] iteration 29422: loss: 0.131985, loss_s1: 0.090095, loss_fp: 0.013213, loss_freq: 0.131277
[19:49:20.603] iteration 29423: loss: 0.063374, loss_s1: 0.034319, loss_fp: 0.003532, loss_freq: 0.061458
[19:49:21.231] iteration 29424: loss: 0.079969, loss_s1: 0.046728, loss_fp: 0.003365, loss_freq: 0.077762
[19:49:21.856] iteration 29425: loss: 0.037958, loss_s1: 0.039305, loss_fp: 0.000992, loss_freq: 0.007480
[19:49:22.482] iteration 29426: loss: 0.034336, loss_s1: 0.028316, loss_fp: 0.000812, loss_freq: 0.005825
[19:49:23.106] iteration 29427: loss: 0.035793, loss_s1: 0.018125, loss_fp: 0.003014, loss_freq: 0.013546
[19:49:23.732] iteration 29428: loss: 0.071964, loss_s1: 0.045173, loss_fp: 0.006011, loss_freq: 0.021447
[19:49:24.357] iteration 29429: loss: 0.038046, loss_s1: 0.035125, loss_fp: 0.001641, loss_freq: 0.006185
[19:49:25.001] iteration 29430: loss: 0.058033, loss_s1: 0.059928, loss_fp: 0.001327, loss_freq: 0.015784
[19:49:25.625] iteration 29431: loss: 0.057437, loss_s1: 0.045232, loss_fp: 0.010511, loss_freq: 0.032014
[19:49:26.254] iteration 29432: loss: 0.063534, loss_s1: 0.081649, loss_fp: 0.003770, loss_freq: 0.017190
[19:49:26.898] iteration 29433: loss: 0.060556, loss_s1: 0.064920, loss_fp: 0.000695, loss_freq: 0.030787
[19:49:27.532] iteration 29434: loss: 0.052087, loss_s1: 0.052311, loss_fp: 0.008368, loss_freq: 0.018413
[19:49:28.157] iteration 29435: loss: 0.063069, loss_s1: 0.066559, loss_fp: 0.001530, loss_freq: 0.023480
[19:49:28.784] iteration 29436: loss: 0.045105, loss_s1: 0.036736, loss_fp: 0.002956, loss_freq: 0.008472
[19:49:29.410] iteration 29437: loss: 0.055670, loss_s1: 0.055325, loss_fp: 0.001867, loss_freq: 0.021211
[19:49:30.036] iteration 29438: loss: 0.082485, loss_s1: 0.096752, loss_fp: 0.006860, loss_freq: 0.036902
[19:49:30.664] iteration 29439: loss: 0.031051, loss_s1: 0.014859, loss_fp: 0.001297, loss_freq: 0.006427
[19:49:31.292] iteration 29440: loss: 0.043009, loss_s1: 0.047608, loss_fp: 0.001587, loss_freq: 0.011506
[19:49:31.920] iteration 29441: loss: 0.044241, loss_s1: 0.029448, loss_fp: 0.001250, loss_freq: 0.024669
[19:49:32.555] iteration 29442: loss: 0.068679, loss_s1: 0.038932, loss_fp: 0.002816, loss_freq: 0.029781
[19:49:33.194] iteration 29443: loss: 0.037282, loss_s1: 0.024229, loss_fp: 0.001743, loss_freq: 0.018599
[19:49:33.820] iteration 29444: loss: 0.047897, loss_s1: 0.023813, loss_fp: 0.004647, loss_freq: 0.013832
[19:49:34.445] iteration 29445: loss: 0.092807, loss_s1: 0.136040, loss_fp: 0.003443, loss_freq: 0.020072
[19:49:35.070] iteration 29446: loss: 0.053989, loss_s1: 0.047950, loss_fp: 0.001807, loss_freq: 0.024975
[19:49:35.701] iteration 29447: loss: 0.035873, loss_s1: 0.015407, loss_fp: 0.006652, loss_freq: 0.021752
[19:49:36.324] iteration 29448: loss: 0.056082, loss_s1: 0.060350, loss_fp: 0.004382, loss_freq: 0.008383
[19:49:36.947] iteration 29449: loss: 0.064581, loss_s1: 0.054988, loss_fp: 0.008429, loss_freq: 0.035204
[19:49:37.573] iteration 29450: loss: 0.047387, loss_s1: 0.060384, loss_fp: 0.003270, loss_freq: 0.006891
[19:49:38.195] iteration 29451: loss: 0.036087, loss_s1: 0.012029, loss_fp: 0.018590, loss_freq: 0.012657
[19:49:38.825] iteration 29452: loss: 0.079062, loss_s1: 0.067602, loss_fp: 0.008789, loss_freq: 0.046436
[19:49:39.449] iteration 29453: loss: 0.051873, loss_s1: 0.047612, loss_fp: 0.002410, loss_freq: 0.020104
[19:49:40.076] iteration 29454: loss: 0.047392, loss_s1: 0.031744, loss_fp: 0.003822, loss_freq: 0.034781
[19:49:40.706] iteration 29455: loss: 0.030648, loss_s1: 0.017821, loss_fp: 0.006242, loss_freq: 0.010700
[19:49:41.331] iteration 29456: loss: 0.060469, loss_s1: 0.055625, loss_fp: 0.006285, loss_freq: 0.027225
[19:49:41.957] iteration 29457: loss: 0.029486, loss_s1: 0.020089, loss_fp: 0.002777, loss_freq: 0.014089
[19:49:42.583] iteration 29458: loss: 0.028926, loss_s1: 0.013073, loss_fp: 0.001043, loss_freq: 0.010626
[19:49:43.204] iteration 29459: loss: 0.033511, loss_s1: 0.023448, loss_fp: 0.000877, loss_freq: 0.008743
[19:49:43.828] iteration 29460: loss: 0.053799, loss_s1: 0.030839, loss_fp: 0.000800, loss_freq: 0.045138
[19:49:44.451] iteration 29461: loss: 0.067357, loss_s1: 0.079655, loss_fp: 0.001440, loss_freq: 0.023740
[19:49:45.073] iteration 29462: loss: 0.048650, loss_s1: 0.039027, loss_fp: 0.002504, loss_freq: 0.032436
[19:49:45.699] iteration 29463: loss: 0.037773, loss_s1: 0.012795, loss_fp: 0.002601, loss_freq: 0.020994
[19:49:46.679] iteration 29464: loss: 0.038701, loss_s1: 0.034679, loss_fp: 0.001992, loss_freq: 0.011933
[19:49:47.315] iteration 29465: loss: 0.039296, loss_s1: 0.038235, loss_fp: 0.001208, loss_freq: 0.007514
[19:49:47.950] iteration 29466: loss: 0.032202, loss_s1: 0.016545, loss_fp: 0.000715, loss_freq: 0.009189
[19:49:48.582] iteration 29467: loss: 0.042627, loss_s1: 0.034404, loss_fp: 0.000948, loss_freq: 0.012567
[19:49:49.215] iteration 29468: loss: 0.037581, loss_s1: 0.028293, loss_fp: 0.004379, loss_freq: 0.011479
[19:49:49.840] iteration 29469: loss: 0.080015, loss_s1: 0.061184, loss_fp: 0.006430, loss_freq: 0.051848
[19:49:50.469] iteration 29470: loss: 0.035997, loss_s1: 0.020055, loss_fp: 0.001248, loss_freq: 0.019805
[19:49:51.101] iteration 29471: loss: 0.028780, loss_s1: 0.021913, loss_fp: 0.002084, loss_freq: 0.009171
[19:49:51.727] iteration 29472: loss: 0.070049, loss_s1: 0.073461, loss_fp: 0.003585, loss_freq: 0.033998
[19:49:52.356] iteration 29473: loss: 0.053567, loss_s1: 0.031337, loss_fp: 0.013272, loss_freq: 0.026779
[19:49:52.988] iteration 29474: loss: 0.027496, loss_s1: 0.015933, loss_fp: 0.001241, loss_freq: 0.007266
[19:49:53.621] iteration 29475: loss: 0.029029, loss_s1: 0.014577, loss_fp: 0.001554, loss_freq: 0.005813
[19:49:54.276] iteration 29476: loss: 0.059990, loss_s1: 0.033800, loss_fp: 0.015230, loss_freq: 0.043110
[19:49:54.934] iteration 29477: loss: 0.047520, loss_s1: 0.027698, loss_fp: 0.006756, loss_freq: 0.021135
[19:49:55.587] iteration 29478: loss: 0.046351, loss_s1: 0.057267, loss_fp: 0.004781, loss_freq: 0.006006
[19:49:56.227] iteration 29479: loss: 0.092375, loss_s1: 0.073815, loss_fp: 0.006741, loss_freq: 0.067398
[19:49:56.874] iteration 29480: loss: 0.050612, loss_s1: 0.041313, loss_fp: 0.001820, loss_freq: 0.008001
[19:49:57.507] iteration 29481: loss: 0.037845, loss_s1: 0.025661, loss_fp: 0.004358, loss_freq: 0.018743
[19:49:58.144] iteration 29482: loss: 0.038630, loss_s1: 0.023868, loss_fp: 0.001301, loss_freq: 0.016192
[19:49:58.783] iteration 29483: loss: 0.044044, loss_s1: 0.030795, loss_fp: 0.003747, loss_freq: 0.029192
[19:49:59.418] iteration 29484: loss: 0.037853, loss_s1: 0.032239, loss_fp: 0.001230, loss_freq: 0.010085
[19:50:00.049] iteration 29485: loss: 0.036150, loss_s1: 0.018612, loss_fp: 0.001947, loss_freq: 0.016134
[19:50:00.678] iteration 29486: loss: 0.057506, loss_s1: 0.029588, loss_fp: 0.009170, loss_freq: 0.036413
[19:50:01.301] iteration 29487: loss: 0.103582, loss_s1: 0.137902, loss_fp: 0.000969, loss_freq: 0.043335
[19:50:01.928] iteration 29488: loss: 0.039376, loss_s1: 0.032168, loss_fp: 0.006077, loss_freq: 0.012542
[19:50:02.553] iteration 29489: loss: 0.039653, loss_s1: 0.028373, loss_fp: 0.005088, loss_freq: 0.021547
[19:50:03.177] iteration 29490: loss: 0.020061, loss_s1: 0.003366, loss_fp: 0.002280, loss_freq: 0.004044
[19:50:03.800] iteration 29491: loss: 0.043409, loss_s1: 0.023768, loss_fp: 0.014676, loss_freq: 0.018406
[19:50:04.427] iteration 29492: loss: 0.078259, loss_s1: 0.065731, loss_fp: 0.007355, loss_freq: 0.047328
[19:50:05.059] iteration 29493: loss: 0.039431, loss_s1: 0.028967, loss_fp: 0.002271, loss_freq: 0.019121
[19:50:05.685] iteration 29494: loss: 0.032613, loss_s1: 0.020782, loss_fp: 0.004865, loss_freq: 0.015823
[19:50:06.307] iteration 29495: loss: 0.047511, loss_s1: 0.042143, loss_fp: 0.001628, loss_freq: 0.016826
[19:50:06.932] iteration 29496: loss: 0.033688, loss_s1: 0.021983, loss_fp: 0.004291, loss_freq: 0.016785
[19:50:07.560] iteration 29497: loss: 0.029429, loss_s1: 0.019650, loss_fp: 0.001937, loss_freq: 0.011969
[19:50:08.183] iteration 29498: loss: 0.064892, loss_s1: 0.048271, loss_fp: 0.012814, loss_freq: 0.022241
[19:50:08.803] iteration 29499: loss: 0.063311, loss_s1: 0.066768, loss_fp: 0.010580, loss_freq: 0.016661
[19:50:09.431] iteration 29500: loss: 0.102415, loss_s1: 0.095137, loss_fp: 0.011452, loss_freq: 0.040990
[19:50:10.055] iteration 29501: loss: 0.040919, loss_s1: 0.027278, loss_fp: 0.001010, loss_freq: 0.025566
[19:50:10.684] iteration 29502: loss: 0.052240, loss_s1: 0.046542, loss_fp: 0.006468, loss_freq: 0.014099
[19:50:11.313] iteration 29503: loss: 0.059161, loss_s1: 0.046645, loss_fp: 0.001555, loss_freq: 0.041434
[19:50:11.945] iteration 29504: loss: 0.070004, loss_s1: 0.054917, loss_fp: 0.003435, loss_freq: 0.017594
[19:50:12.574] iteration 29505: loss: 0.056763, loss_s1: 0.052102, loss_fp: 0.005036, loss_freq: 0.028807
[19:50:13.205] iteration 29506: loss: 0.074780, loss_s1: 0.083185, loss_fp: 0.009340, loss_freq: 0.029835
[19:50:13.835] iteration 29507: loss: 0.037833, loss_s1: 0.017854, loss_fp: 0.001963, loss_freq: 0.029101
[19:50:14.466] iteration 29508: loss: 0.038770, loss_s1: 0.024445, loss_fp: 0.007779, loss_freq: 0.011427
[19:50:15.100] iteration 29509: loss: 0.051750, loss_s1: 0.063822, loss_fp: 0.003411, loss_freq: 0.004174
[19:50:15.725] iteration 29510: loss: 0.030004, loss_s1: 0.020599, loss_fp: 0.000433, loss_freq: 0.008296
[19:50:16.347] iteration 29511: loss: 0.075815, loss_s1: 0.077943, loss_fp: 0.004627, loss_freq: 0.040974
[19:50:16.983] iteration 29512: loss: 0.058775, loss_s1: 0.057492, loss_fp: 0.006402, loss_freq: 0.023166
[19:50:17.673] iteration 29513: loss: 0.040609, loss_s1: 0.028084, loss_fp: 0.001741, loss_freq: 0.023141
[19:50:18.306] iteration 29514: loss: 0.047722, loss_s1: 0.047453, loss_fp: 0.001641, loss_freq: 0.015450
[19:50:18.940] iteration 29515: loss: 0.036944, loss_s1: 0.028169, loss_fp: 0.002017, loss_freq: 0.009858
[19:50:19.574] iteration 29516: loss: 0.072116, loss_s1: 0.057441, loss_fp: 0.003002, loss_freq: 0.046503
[19:50:20.265] iteration 29517: loss: 0.054363, loss_s1: 0.042109, loss_fp: 0.006938, loss_freq: 0.027731
[19:50:20.895] iteration 29518: loss: 0.037612, loss_s1: 0.024074, loss_fp: 0.005195, loss_freq: 0.018256
[19:50:21.518] iteration 29519: loss: 0.046153, loss_s1: 0.028316, loss_fp: 0.004549, loss_freq: 0.025501
[19:50:22.139] iteration 29520: loss: 0.044066, loss_s1: 0.038070, loss_fp: 0.004930, loss_freq: 0.011828
[19:50:22.790] iteration 29521: loss: 0.051834, loss_s1: 0.032005, loss_fp: 0.000854, loss_freq: 0.024478
[19:50:23.417] iteration 29522: loss: 0.040254, loss_s1: 0.031713, loss_fp: 0.002649, loss_freq: 0.018029
[19:50:24.040] iteration 29523: loss: 0.039312, loss_s1: 0.017273, loss_fp: 0.005070, loss_freq: 0.029658
[19:50:24.677] iteration 29524: loss: 0.050823, loss_s1: 0.040417, loss_fp: 0.002646, loss_freq: 0.024757
[19:50:25.307] iteration 29525: loss: 0.038169, loss_s1: 0.012091, loss_fp: 0.012031, loss_freq: 0.020806
[19:50:25.928] iteration 29526: loss: 0.035822, loss_s1: 0.013322, loss_fp: 0.001774, loss_freq: 0.009304
[19:50:26.549] iteration 29527: loss: 0.045057, loss_s1: 0.029550, loss_fp: 0.002626, loss_freq: 0.031255
[19:50:27.175] iteration 29528: loss: 0.040334, loss_s1: 0.032227, loss_fp: 0.006311, loss_freq: 0.011027
[19:50:27.794] iteration 29529: loss: 0.047196, loss_s1: 0.031744, loss_fp: 0.002137, loss_freq: 0.031603
[19:50:28.421] iteration 29530: loss: 0.099649, loss_s1: 0.067556, loss_fp: 0.008725, loss_freq: 0.068575
[19:50:29.052] iteration 29531: loss: 0.048547, loss_s1: 0.037619, loss_fp: 0.001826, loss_freq: 0.031657
[19:50:29.684] iteration 29532: loss: 0.043107, loss_s1: 0.033355, loss_fp: 0.008873, loss_freq: 0.015231
[19:50:30.314] iteration 29533: loss: 0.063932, loss_s1: 0.076056, loss_fp: 0.002352, loss_freq: 0.008168
[19:50:30.959] iteration 29534: loss: 0.100546, loss_s1: 0.052344, loss_fp: 0.005825, loss_freq: 0.104124
[19:50:31.601] iteration 29535: loss: 0.046133, loss_s1: 0.043495, loss_fp: 0.001068, loss_freq: 0.019769
[19:50:32.235] iteration 29536: loss: 0.067783, loss_s1: 0.063556, loss_fp: 0.001440, loss_freq: 0.031076
[19:50:32.872] iteration 29537: loss: 0.051527, loss_s1: 0.044907, loss_fp: 0.007926, loss_freq: 0.015352
[19:50:33.512] iteration 29538: loss: 0.048572, loss_s1: 0.043651, loss_fp: 0.004132, loss_freq: 0.015948
[19:50:34.153] iteration 29539: loss: 0.059327, loss_s1: 0.037831, loss_fp: 0.001953, loss_freq: 0.026731
[19:50:34.793] iteration 29540: loss: 0.047216, loss_s1: 0.036474, loss_fp: 0.001467, loss_freq: 0.024573
[19:50:35.425] iteration 29541: loss: 0.034590, loss_s1: 0.026128, loss_fp: 0.006497, loss_freq: 0.011424
[19:50:36.056] iteration 29542: loss: 0.023851, loss_s1: 0.010790, loss_fp: 0.004451, loss_freq: 0.009432
[19:50:36.690] iteration 29543: loss: 0.052503, loss_s1: 0.043186, loss_fp: 0.003942, loss_freq: 0.024215
[19:50:37.323] iteration 29544: loss: 0.030313, loss_s1: 0.014077, loss_fp: 0.007377, loss_freq: 0.009537
[19:50:37.952] iteration 29545: loss: 0.051267, loss_s1: 0.051364, loss_fp: 0.005186, loss_freq: 0.022151
[19:50:38.591] iteration 29546: loss: 0.078464, loss_s1: 0.066389, loss_fp: 0.017390, loss_freq: 0.042403
[19:50:39.220] iteration 29547: loss: 0.051242, loss_s1: 0.045367, loss_fp: 0.006535, loss_freq: 0.021931
[19:50:39.860] iteration 29548: loss: 0.062910, loss_s1: 0.051146, loss_fp: 0.001838, loss_freq: 0.041074
[19:50:40.497] iteration 29549: loss: 0.029985, loss_s1: 0.015007, loss_fp: 0.003592, loss_freq: 0.008231
[19:50:41.135] iteration 29550: loss: 0.071349, loss_s1: 0.058019, loss_fp: 0.012138, loss_freq: 0.036840
[19:50:41.772] iteration 29551: loss: 0.043344, loss_s1: 0.032356, loss_fp: 0.002434, loss_freq: 0.016851
[19:50:42.399] iteration 29552: loss: 0.065097, loss_s1: 0.074654, loss_fp: 0.010737, loss_freq: 0.012078
[19:50:43.034] iteration 29553: loss: 0.056328, loss_s1: 0.053257, loss_fp: 0.004951, loss_freq: 0.024078
[19:50:43.664] iteration 29554: loss: 0.060737, loss_s1: 0.061798, loss_fp: 0.002519, loss_freq: 0.022389
[19:50:44.349] iteration 29555: loss: 0.069131, loss_s1: 0.049406, loss_fp: 0.003081, loss_freq: 0.049880
[19:50:44.984] iteration 29556: loss: 0.042465, loss_s1: 0.026356, loss_fp: 0.000493, loss_freq: 0.009888
[19:50:45.618] iteration 29557: loss: 0.035302, loss_s1: 0.035030, loss_fp: 0.004896, loss_freq: 0.006657
[19:50:46.247] iteration 29558: loss: 0.081533, loss_s1: 0.074700, loss_fp: 0.009985, loss_freq: 0.053597
[19:50:46.895] iteration 29559: loss: 0.058120, loss_s1: 0.027377, loss_fp: 0.002742, loss_freq: 0.059745
[19:50:47.526] iteration 29560: loss: 0.043410, loss_s1: 0.041598, loss_fp: 0.003089, loss_freq: 0.013725
[19:50:48.154] iteration 29561: loss: 0.040732, loss_s1: 0.030834, loss_fp: 0.002768, loss_freq: 0.010031
[19:50:48.784] iteration 29562: loss: 0.037814, loss_s1: 0.016430, loss_fp: 0.005360, loss_freq: 0.025273
[19:50:49.422] iteration 29563: loss: 0.041975, loss_s1: 0.040739, loss_fp: 0.002200, loss_freq: 0.012742
[19:50:50.055] iteration 29564: loss: 0.051488, loss_s1: 0.035740, loss_fp: 0.002096, loss_freq: 0.038787
[19:50:50.680] iteration 29565: loss: 0.067845, loss_s1: 0.060844, loss_fp: 0.005464, loss_freq: 0.028860
[19:50:51.310] iteration 29566: loss: 0.050659, loss_s1: 0.055312, loss_fp: 0.000962, loss_freq: 0.019394
[19:50:51.937] iteration 29567: loss: 0.037536, loss_s1: 0.032331, loss_fp: 0.003854, loss_freq: 0.009026
[19:50:52.570] iteration 29568: loss: 0.032496, loss_s1: 0.018082, loss_fp: 0.001480, loss_freq: 0.007580
[19:50:53.201] iteration 29569: loss: 0.034113, loss_s1: 0.020749, loss_fp: 0.002575, loss_freq: 0.015472
[19:50:53.830] iteration 29570: loss: 0.028899, loss_s1: 0.014449, loss_fp: 0.000765, loss_freq: 0.009781
[19:50:54.455] iteration 29571: loss: 0.045461, loss_s1: 0.032586, loss_fp: 0.001542, loss_freq: 0.021378
[19:50:55.090] iteration 29572: loss: 0.082985, loss_s1: 0.056041, loss_fp: 0.005918, loss_freq: 0.063000
[19:50:55.718] iteration 29573: loss: 0.052994, loss_s1: 0.043258, loss_fp: 0.006724, loss_freq: 0.022523
[19:50:56.347] iteration 29574: loss: 0.043140, loss_s1: 0.024291, loss_fp: 0.002579, loss_freq: 0.020791
[19:50:56.981] iteration 29575: loss: 0.071272, loss_s1: 0.045577, loss_fp: 0.003584, loss_freq: 0.062218
[19:50:57.613] iteration 29576: loss: 0.056974, loss_s1: 0.036230, loss_fp: 0.000983, loss_freq: 0.040267
[19:50:58.238] iteration 29577: loss: 0.035779, loss_s1: 0.022440, loss_fp: 0.003375, loss_freq: 0.019719
[19:50:58.863] iteration 29578: loss: 0.040258, loss_s1: 0.020151, loss_fp: 0.003200, loss_freq: 0.012098
[19:50:59.494] iteration 29579: loss: 0.042436, loss_s1: 0.027941, loss_fp: 0.002135, loss_freq: 0.023788
[19:51:00.119] iteration 29580: loss: 0.048640, loss_s1: 0.019171, loss_fp: 0.003201, loss_freq: 0.047599
[19:51:00.745] iteration 29581: loss: 0.042901, loss_s1: 0.036503, loss_fp: 0.012116, loss_freq: 0.013246
[19:51:01.370] iteration 29582: loss: 0.061879, loss_s1: 0.052816, loss_fp: 0.002115, loss_freq: 0.024923
[19:51:01.997] iteration 29583: loss: 0.094826, loss_s1: 0.081494, loss_fp: 0.010938, loss_freq: 0.067815
[19:51:02.630] iteration 29584: loss: 0.023426, loss_s1: 0.007855, loss_fp: 0.003020, loss_freq: 0.008909
[19:51:03.258] iteration 29585: loss: 0.045856, loss_s1: 0.037723, loss_fp: 0.005815, loss_freq: 0.014683
[19:51:03.884] iteration 29586: loss: 0.058048, loss_s1: 0.054525, loss_fp: 0.004496, loss_freq: 0.025091
[19:51:04.514] iteration 29587: loss: 0.043176, loss_s1: 0.045753, loss_fp: 0.000976, loss_freq: 0.003351
[19:51:05.143] iteration 29588: loss: 0.051232, loss_s1: 0.028690, loss_fp: 0.010351, loss_freq: 0.032914
[19:51:05.771] iteration 29589: loss: 0.032079, loss_s1: 0.017914, loss_fp: 0.000621, loss_freq: 0.012523
[19:51:06.393] iteration 29590: loss: 0.039529, loss_s1: 0.034027, loss_fp: 0.002221, loss_freq: 0.010724
[19:51:07.022] iteration 29591: loss: 0.057121, loss_s1: 0.036122, loss_fp: 0.001511, loss_freq: 0.039159
[19:51:07.652] iteration 29592: loss: 0.059199, loss_s1: 0.041874, loss_fp: 0.007668, loss_freq: 0.036327
[19:51:08.284] iteration 29593: loss: 0.051566, loss_s1: 0.067383, loss_fp: 0.001624, loss_freq: 0.008751
[19:51:08.914] iteration 29594: loss: 0.068307, loss_s1: 0.071585, loss_fp: 0.008641, loss_freq: 0.031893
[19:51:09.539] iteration 29595: loss: 0.097760, loss_s1: 0.120895, loss_fp: 0.009709, loss_freq: 0.027752
[19:51:10.176] iteration 29596: loss: 0.039095, loss_s1: 0.024956, loss_fp: 0.002004, loss_freq: 0.019061
[19:51:10.808] iteration 29597: loss: 0.041403, loss_s1: 0.037368, loss_fp: 0.005404, loss_freq: 0.014324
[19:51:11.438] iteration 29598: loss: 0.044080, loss_s1: 0.033649, loss_fp: 0.004561, loss_freq: 0.021178
[19:51:12.065] iteration 29599: loss: 0.050171, loss_s1: 0.045008, loss_fp: 0.003707, loss_freq: 0.024424
[19:51:12.691] iteration 29600: loss: 0.035398, loss_s1: 0.011043, loss_fp: 0.000626, loss_freq: 0.013207
[19:51:15.802] iteration 29600 : mean_dice : 0.735158
[19:51:16.444] iteration 29601: loss: 0.020735, loss_s1: 0.009877, loss_fp: 0.001394, loss_freq: 0.006374
[19:51:17.106] iteration 29602: loss: 0.028258, loss_s1: 0.014520, loss_fp: 0.002286, loss_freq: 0.006197
[19:51:17.742] iteration 29603: loss: 0.050535, loss_s1: 0.029964, loss_fp: 0.003842, loss_freq: 0.025693
[19:51:18.372] iteration 29604: loss: 0.034615, loss_s1: 0.024497, loss_fp: 0.001803, loss_freq: 0.013531
[19:51:19.004] iteration 29605: loss: 0.043435, loss_s1: 0.027364, loss_fp: 0.003125, loss_freq: 0.020038
[19:51:19.646] iteration 29606: loss: 0.090725, loss_s1: 0.059266, loss_fp: 0.005525, loss_freq: 0.069819
[19:51:20.280] iteration 29607: loss: 0.075987, loss_s1: 0.082046, loss_fp: 0.005966, loss_freq: 0.028336
[19:51:20.907] iteration 29608: loss: 0.042288, loss_s1: 0.037143, loss_fp: 0.004570, loss_freq: 0.012325
[19:51:21.535] iteration 29609: loss: 0.056149, loss_s1: 0.057527, loss_fp: 0.007236, loss_freq: 0.012436
[19:51:22.160] iteration 29610: loss: 0.070123, loss_s1: 0.038903, loss_fp: 0.001669, loss_freq: 0.069033
[19:51:22.784] iteration 29611: loss: 0.030789, loss_s1: 0.024471, loss_fp: 0.000480, loss_freq: 0.008208
[19:51:23.405] iteration 29612: loss: 0.045896, loss_s1: 0.027873, loss_fp: 0.001761, loss_freq: 0.019818
[19:51:24.049] iteration 29613: loss: 0.069246, loss_s1: 0.052772, loss_fp: 0.009004, loss_freq: 0.048228
[19:51:24.671] iteration 29614: loss: 0.070480, loss_s1: 0.070008, loss_fp: 0.005227, loss_freq: 0.038437
[19:51:25.291] iteration 29615: loss: 0.094686, loss_s1: 0.095527, loss_fp: 0.012827, loss_freq: 0.055463
[19:51:25.916] iteration 29616: loss: 0.050569, loss_s1: 0.040049, loss_fp: 0.003350, loss_freq: 0.028790
[19:51:26.542] iteration 29617: loss: 0.057720, loss_s1: 0.044032, loss_fp: 0.009540, loss_freq: 0.032367
[19:51:27.182] iteration 29618: loss: 0.023970, loss_s1: 0.011623, loss_fp: 0.001318, loss_freq: 0.011227
[19:51:27.805] iteration 29619: loss: 0.045409, loss_s1: 0.031504, loss_fp: 0.000593, loss_freq: 0.016055
[19:51:28.429] iteration 29620: loss: 0.033690, loss_s1: 0.029852, loss_fp: 0.000738, loss_freq: 0.002625
[19:51:29.056] iteration 29621: loss: 0.042185, loss_s1: 0.033338, loss_fp: 0.002775, loss_freq: 0.017694
[19:51:29.683] iteration 29622: loss: 0.052530, loss_s1: 0.050554, loss_fp: 0.002383, loss_freq: 0.021877
[19:51:30.312] iteration 29623: loss: 0.047008, loss_s1: 0.023673, loss_fp: 0.005895, loss_freq: 0.030069
[19:51:30.939] iteration 29624: loss: 0.041355, loss_s1: 0.035048, loss_fp: 0.000466, loss_freq: 0.010298
[19:51:31.847] iteration 29625: loss: 0.031296, loss_s1: 0.021221, loss_fp: 0.002857, loss_freq: 0.011316
[19:51:32.471] iteration 29626: loss: 0.066029, loss_s1: 0.072507, loss_fp: 0.003319, loss_freq: 0.013738
[19:51:33.100] iteration 29627: loss: 0.029346, loss_s1: 0.020805, loss_fp: 0.001244, loss_freq: 0.008789
[19:51:33.729] iteration 29628: loss: 0.036899, loss_s1: 0.016807, loss_fp: 0.001363, loss_freq: 0.020624
[19:51:34.362] iteration 29629: loss: 0.042297, loss_s1: 0.011987, loss_fp: 0.004636, loss_freq: 0.029189
[19:51:35.013] iteration 29630: loss: 0.077370, loss_s1: 0.058165, loss_fp: 0.005435, loss_freq: 0.056200
[19:51:35.641] iteration 29631: loss: 0.042015, loss_s1: 0.032604, loss_fp: 0.001583, loss_freq: 0.023430
[19:51:36.269] iteration 29632: loss: 0.040933, loss_s1: 0.017509, loss_fp: 0.003271, loss_freq: 0.014517
[19:51:36.893] iteration 29633: loss: 0.059223, loss_s1: 0.063946, loss_fp: 0.005594, loss_freq: 0.020606
[19:51:37.524] iteration 29634: loss: 0.064271, loss_s1: 0.070657, loss_fp: 0.011214, loss_freq: 0.012225
[19:51:38.149] iteration 29635: loss: 0.041379, loss_s1: 0.026079, loss_fp: 0.001401, loss_freq: 0.019268
[19:51:38.775] iteration 29636: loss: 0.044493, loss_s1: 0.041517, loss_fp: 0.004940, loss_freq: 0.012575
[19:51:39.399] iteration 29637: loss: 0.057550, loss_s1: 0.027008, loss_fp: 0.004131, loss_freq: 0.059261
[19:51:40.033] iteration 29638: loss: 0.042576, loss_s1: 0.022249, loss_fp: 0.001458, loss_freq: 0.026471
[19:51:40.656] iteration 29639: loss: 0.054884, loss_s1: 0.054328, loss_fp: 0.009483, loss_freq: 0.018661
[19:51:41.281] iteration 29640: loss: 0.056737, loss_s1: 0.035482, loss_fp: 0.013819, loss_freq: 0.031491
[19:51:41.915] iteration 29641: loss: 0.027581, loss_s1: 0.018193, loss_fp: 0.001654, loss_freq: 0.006227
[19:51:42.551] iteration 29642: loss: 0.062045, loss_s1: 0.049504, loss_fp: 0.003893, loss_freq: 0.036940
[19:51:43.178] iteration 29643: loss: 0.056776, loss_s1: 0.033233, loss_fp: 0.002215, loss_freq: 0.048232
[19:51:43.809] iteration 29644: loss: 0.031079, loss_s1: 0.012891, loss_fp: 0.000819, loss_freq: 0.015202
[19:51:44.437] iteration 29645: loss: 0.031177, loss_s1: 0.014830, loss_fp: 0.000957, loss_freq: 0.010643
[19:51:45.067] iteration 29646: loss: 0.058063, loss_s1: 0.034637, loss_fp: 0.003396, loss_freq: 0.047445
[19:51:45.701] iteration 29647: loss: 0.045688, loss_s1: 0.039879, loss_fp: 0.002212, loss_freq: 0.010289
[19:51:46.326] iteration 29648: loss: 0.077817, loss_s1: 0.054006, loss_fp: 0.005901, loss_freq: 0.065648
[19:51:46.952] iteration 29649: loss: 0.037113, loss_s1: 0.033436, loss_fp: 0.001138, loss_freq: 0.013929
[19:51:47.586] iteration 29650: loss: 0.063658, loss_s1: 0.072679, loss_fp: 0.001949, loss_freq: 0.022642
[19:51:48.212] iteration 29651: loss: 0.030411, loss_s1: 0.022636, loss_fp: 0.001527, loss_freq: 0.006861
[19:51:48.840] iteration 29652: loss: 0.051550, loss_s1: 0.037221, loss_fp: 0.006620, loss_freq: 0.026659
[19:51:49.461] iteration 29653: loss: 0.060015, loss_s1: 0.041067, loss_fp: 0.002990, loss_freq: 0.045030
[19:51:50.094] iteration 29654: loss: 0.033798, loss_s1: 0.021533, loss_fp: 0.004474, loss_freq: 0.012915
[19:51:50.720] iteration 29655: loss: 0.048782, loss_s1: 0.046867, loss_fp: 0.005024, loss_freq: 0.022713
[19:51:51.349] iteration 29656: loss: 0.030008, loss_s1: 0.012725, loss_fp: 0.001547, loss_freq: 0.012229
[19:51:51.984] iteration 29657: loss: 0.037328, loss_s1: 0.024955, loss_fp: 0.001958, loss_freq: 0.020422
[19:51:52.612] iteration 29658: loss: 0.036280, loss_s1: 0.020940, loss_fp: 0.005238, loss_freq: 0.009695
[19:51:53.244] iteration 29659: loss: 0.039362, loss_s1: 0.016495, loss_fp: 0.001607, loss_freq: 0.014955
[19:51:53.878] iteration 29660: loss: 0.087495, loss_s1: 0.076478, loss_fp: 0.011731, loss_freq: 0.050020
[19:51:54.520] iteration 29661: loss: 0.077902, loss_s1: 0.089010, loss_fp: 0.006791, loss_freq: 0.020342
[19:51:55.164] iteration 29662: loss: 0.062942, loss_s1: 0.067421, loss_fp: 0.004985, loss_freq: 0.020052
[19:51:55.803] iteration 29663: loss: 0.060554, loss_s1: 0.064166, loss_fp: 0.000655, loss_freq: 0.019940
[19:51:56.433] iteration 29664: loss: 0.064369, loss_s1: 0.052814, loss_fp: 0.001503, loss_freq: 0.048167
[19:51:57.065] iteration 29665: loss: 0.050546, loss_s1: 0.053556, loss_fp: 0.000673, loss_freq: 0.009883
[19:51:57.689] iteration 29666: loss: 0.056509, loss_s1: 0.040036, loss_fp: 0.004245, loss_freq: 0.041566
[19:51:58.315] iteration 29667: loss: 0.059098, loss_s1: 0.036980, loss_fp: 0.010042, loss_freq: 0.043384
[19:51:58.941] iteration 29668: loss: 0.053693, loss_s1: 0.034191, loss_fp: 0.003084, loss_freq: 0.040937
[19:51:59.569] iteration 29669: loss: 0.035433, loss_s1: 0.019950, loss_fp: 0.003846, loss_freq: 0.013188
[19:52:00.197] iteration 29670: loss: 0.026967, loss_s1: 0.019852, loss_fp: 0.000608, loss_freq: 0.003304
[19:52:00.855] iteration 29671: loss: 0.028615, loss_s1: 0.023501, loss_fp: 0.001100, loss_freq: 0.010871
[19:52:01.521] iteration 29672: loss: 0.046676, loss_s1: 0.040562, loss_fp: 0.006610, loss_freq: 0.019857
[19:52:02.159] iteration 29673: loss: 0.060647, loss_s1: 0.069552, loss_fp: 0.004274, loss_freq: 0.012122
[19:52:02.799] iteration 29674: loss: 0.049219, loss_s1: 0.033268, loss_fp: 0.010210, loss_freq: 0.032161
[19:52:03.429] iteration 29675: loss: 0.044820, loss_s1: 0.030755, loss_fp: 0.006422, loss_freq: 0.022672
[19:52:04.063] iteration 29676: loss: 0.036047, loss_s1: 0.020816, loss_fp: 0.002036, loss_freq: 0.013842
[19:52:04.696] iteration 29677: loss: 0.057855, loss_s1: 0.042423, loss_fp: 0.004645, loss_freq: 0.032085
[19:52:05.335] iteration 29678: loss: 0.059834, loss_s1: 0.070234, loss_fp: 0.001137, loss_freq: 0.016699
[19:52:05.980] iteration 29679: loss: 0.038197, loss_s1: 0.033995, loss_fp: 0.001828, loss_freq: 0.015346
[19:52:06.618] iteration 29680: loss: 0.041451, loss_s1: 0.033635, loss_fp: 0.002067, loss_freq: 0.010693
[19:52:07.265] iteration 29681: loss: 0.020507, loss_s1: 0.008067, loss_fp: 0.001241, loss_freq: 0.001595
[19:52:07.915] iteration 29682: loss: 0.035822, loss_s1: 0.022905, loss_fp: 0.000695, loss_freq: 0.011821
[19:52:08.559] iteration 29683: loss: 0.041594, loss_s1: 0.023473, loss_fp: 0.003134, loss_freq: 0.014807
[19:52:09.200] iteration 29684: loss: 0.049875, loss_s1: 0.040567, loss_fp: 0.008636, loss_freq: 0.025004
[19:52:09.843] iteration 29685: loss: 0.031454, loss_s1: 0.020011, loss_fp: 0.002333, loss_freq: 0.016975
[19:52:10.475] iteration 29686: loss: 0.040389, loss_s1: 0.032252, loss_fp: 0.008166, loss_freq: 0.013883
[19:52:11.108] iteration 29687: loss: 0.033775, loss_s1: 0.019248, loss_fp: 0.000280, loss_freq: 0.014303
[19:52:11.740] iteration 29688: loss: 0.032202, loss_s1: 0.010000, loss_fp: 0.006472, loss_freq: 0.021453
[19:52:12.370] iteration 29689: loss: 0.042234, loss_s1: 0.034711, loss_fp: 0.007306, loss_freq: 0.009745
[19:52:13.007] iteration 29690: loss: 0.064334, loss_s1: 0.036659, loss_fp: 0.007198, loss_freq: 0.059168
[19:52:13.639] iteration 29691: loss: 0.040211, loss_s1: 0.019309, loss_fp: 0.002001, loss_freq: 0.021444
[19:52:14.280] iteration 29692: loss: 0.065333, loss_s1: 0.056695, loss_fp: 0.007622, loss_freq: 0.042437
[19:52:14.906] iteration 29693: loss: 0.036068, loss_s1: 0.028038, loss_fp: 0.004898, loss_freq: 0.011036
[19:52:15.534] iteration 29694: loss: 0.045740, loss_s1: 0.024286, loss_fp: 0.000972, loss_freq: 0.015011
[19:52:16.168] iteration 29695: loss: 0.052198, loss_s1: 0.040398, loss_fp: 0.007877, loss_freq: 0.029569
[19:52:16.803] iteration 29696: loss: 0.035918, loss_s1: 0.021116, loss_fp: 0.001235, loss_freq: 0.020094
[19:52:17.433] iteration 29697: loss: 0.036919, loss_s1: 0.020009, loss_fp: 0.005907, loss_freq: 0.011439
[19:52:18.064] iteration 29698: loss: 0.039383, loss_s1: 0.024225, loss_fp: 0.004117, loss_freq: 0.013454
[19:52:18.688] iteration 29699: loss: 0.089637, loss_s1: 0.096900, loss_fp: 0.002790, loss_freq: 0.047735
[19:52:19.320] iteration 29700: loss: 0.080307, loss_s1: 0.090903, loss_fp: 0.008185, loss_freq: 0.017381
[19:52:19.952] iteration 29701: loss: 0.072226, loss_s1: 0.087873, loss_fp: 0.002116, loss_freq: 0.030447
[19:52:20.587] iteration 29702: loss: 0.040165, loss_s1: 0.038618, loss_fp: 0.003708, loss_freq: 0.010377
[19:52:21.221] iteration 29703: loss: 0.023783, loss_s1: 0.013709, loss_fp: 0.001959, loss_freq: 0.006754
[19:52:21.846] iteration 29704: loss: 0.061175, loss_s1: 0.069177, loss_fp: 0.000866, loss_freq: 0.021380
[19:52:22.483] iteration 29705: loss: 0.059858, loss_s1: 0.050989, loss_fp: 0.014912, loss_freq: 0.020108
[19:52:23.127] iteration 29706: loss: 0.066831, loss_s1: 0.069205, loss_fp: 0.002121, loss_freq: 0.034477
[19:52:23.813] iteration 29707: loss: 0.046683, loss_s1: 0.033448, loss_fp: 0.009511, loss_freq: 0.021727
[19:52:24.443] iteration 29708: loss: 0.062947, loss_s1: 0.047227, loss_fp: 0.004980, loss_freq: 0.038010
[19:52:25.075] iteration 29709: loss: 0.047399, loss_s1: 0.031495, loss_fp: 0.012865, loss_freq: 0.024849
[19:52:25.706] iteration 29710: loss: 0.064203, loss_s1: 0.066831, loss_fp: 0.003170, loss_freq: 0.032140
[19:52:26.331] iteration 29711: loss: 0.075733, loss_s1: 0.094621, loss_fp: 0.003090, loss_freq: 0.013958
[19:52:26.963] iteration 29712: loss: 0.070618, loss_s1: 0.065128, loss_fp: 0.003061, loss_freq: 0.039825
[19:52:27.596] iteration 29713: loss: 0.057792, loss_s1: 0.055732, loss_fp: 0.014709, loss_freq: 0.012067
[19:52:28.222] iteration 29714: loss: 0.051455, loss_s1: 0.042814, loss_fp: 0.001897, loss_freq: 0.030591
[19:52:28.850] iteration 29715: loss: 0.055156, loss_s1: 0.026184, loss_fp: 0.006467, loss_freq: 0.036744
[19:52:29.477] iteration 29716: loss: 0.057712, loss_s1: 0.031964, loss_fp: 0.003443, loss_freq: 0.036536
[19:52:30.105] iteration 29717: loss: 0.051485, loss_s1: 0.048451, loss_fp: 0.003463, loss_freq: 0.011068
[19:52:30.774] iteration 29718: loss: 0.034298, loss_s1: 0.019084, loss_fp: 0.005661, loss_freq: 0.011820
[19:52:31.426] iteration 29719: loss: 0.053516, loss_s1: 0.058718, loss_fp: 0.006194, loss_freq: 0.016747
[19:52:32.080] iteration 29720: loss: 0.041089, loss_s1: 0.029274, loss_fp: 0.001731, loss_freq: 0.021559
[19:52:32.731] iteration 29721: loss: 0.036745, loss_s1: 0.027275, loss_fp: 0.003080, loss_freq: 0.015432
[19:52:33.370] iteration 29722: loss: 0.031643, loss_s1: 0.009232, loss_fp: 0.000592, loss_freq: 0.006008
[19:52:34.018] iteration 29723: loss: 0.051483, loss_s1: 0.033294, loss_fp: 0.002253, loss_freq: 0.026834
[19:52:34.663] iteration 29724: loss: 0.059246, loss_s1: 0.051741, loss_fp: 0.005238, loss_freq: 0.030329
[19:52:35.306] iteration 29725: loss: 0.041594, loss_s1: 0.035925, loss_fp: 0.003084, loss_freq: 0.015113
[19:52:35.947] iteration 29726: loss: 0.058968, loss_s1: 0.046530, loss_fp: 0.006990, loss_freq: 0.018830
[19:52:36.585] iteration 29727: loss: 0.062323, loss_s1: 0.062125, loss_fp: 0.002103, loss_freq: 0.034091
[19:52:37.223] iteration 29728: loss: 0.072367, loss_s1: 0.069433, loss_fp: 0.007003, loss_freq: 0.032863
[19:52:37.861] iteration 29729: loss: 0.032546, loss_s1: 0.009000, loss_fp: 0.004706, loss_freq: 0.015459
[19:52:38.538] iteration 29730: loss: 0.040396, loss_s1: 0.012178, loss_fp: 0.001526, loss_freq: 0.030632
[19:52:39.179] iteration 29731: loss: 0.043869, loss_s1: 0.028512, loss_fp: 0.002303, loss_freq: 0.011375
[19:52:39.813] iteration 29732: loss: 0.074496, loss_s1: 0.058803, loss_fp: 0.003249, loss_freq: 0.049156
[19:52:40.452] iteration 29733: loss: 0.095431, loss_s1: 0.074307, loss_fp: 0.005619, loss_freq: 0.075025
[19:52:41.081] iteration 29734: loss: 0.062143, loss_s1: 0.058670, loss_fp: 0.002424, loss_freq: 0.021438
[19:52:41.712] iteration 29735: loss: 0.049912, loss_s1: 0.030755, loss_fp: 0.007680, loss_freq: 0.020827
[19:52:42.349] iteration 29736: loss: 0.045178, loss_s1: 0.039083, loss_fp: 0.003798, loss_freq: 0.020834
[19:52:42.973] iteration 29737: loss: 0.056884, loss_s1: 0.057549, loss_fp: 0.006282, loss_freq: 0.023378
[19:52:43.601] iteration 29738: loss: 0.042186, loss_s1: 0.045775, loss_fp: 0.002672, loss_freq: 0.006625
[19:52:44.234] iteration 29739: loss: 0.037267, loss_s1: 0.022885, loss_fp: 0.003679, loss_freq: 0.011273
[19:52:44.865] iteration 29740: loss: 0.030751, loss_s1: 0.014551, loss_fp: 0.004675, loss_freq: 0.008943
[19:52:45.486] iteration 29741: loss: 0.047929, loss_s1: 0.031676, loss_fp: 0.014403, loss_freq: 0.017304
[19:52:46.122] iteration 29742: loss: 0.055744, loss_s1: 0.044099, loss_fp: 0.004043, loss_freq: 0.033817
[19:52:46.760] iteration 29743: loss: 0.065458, loss_s1: 0.059465, loss_fp: 0.009919, loss_freq: 0.026013
[19:52:47.398] iteration 29744: loss: 0.077935, loss_s1: 0.096187, loss_fp: 0.010657, loss_freq: 0.024142
[19:52:48.022] iteration 29745: loss: 0.051803, loss_s1: 0.068696, loss_fp: 0.001117, loss_freq: 0.005109
[19:52:48.649] iteration 29746: loss: 0.056134, loss_s1: 0.026894, loss_fp: 0.001919, loss_freq: 0.052559
[19:52:49.272] iteration 29747: loss: 0.058146, loss_s1: 0.058579, loss_fp: 0.011991, loss_freq: 0.012232
[19:52:49.904] iteration 29748: loss: 0.029907, loss_s1: 0.021039, loss_fp: 0.001095, loss_freq: 0.007716
[19:52:50.535] iteration 29749: loss: 0.047713, loss_s1: 0.029714, loss_fp: 0.006246, loss_freq: 0.034080
[19:52:51.160] iteration 29750: loss: 0.051717, loss_s1: 0.039822, loss_fp: 0.001514, loss_freq: 0.027444
[19:52:51.784] iteration 29751: loss: 0.044250, loss_s1: 0.047418, loss_fp: 0.001132, loss_freq: 0.006730
[19:52:52.415] iteration 29752: loss: 0.044320, loss_s1: 0.018904, loss_fp: 0.004980, loss_freq: 0.022686
[19:52:53.040] iteration 29753: loss: 0.063320, loss_s1: 0.053048, loss_fp: 0.006570, loss_freq: 0.039161
[19:52:53.669] iteration 29754: loss: 0.033118, loss_s1: 0.016772, loss_fp: 0.006611, loss_freq: 0.014247
[19:52:54.296] iteration 29755: loss: 0.055382, loss_s1: 0.024760, loss_fp: 0.004147, loss_freq: 0.049103
[19:52:54.924] iteration 29756: loss: 0.054583, loss_s1: 0.064434, loss_fp: 0.002628, loss_freq: 0.014289
[19:52:55.553] iteration 29757: loss: 0.066591, loss_s1: 0.077794, loss_fp: 0.003686, loss_freq: 0.019204
[19:52:56.187] iteration 29758: loss: 0.035339, loss_s1: 0.028506, loss_fp: 0.006541, loss_freq: 0.005026
[19:52:56.813] iteration 29759: loss: 0.038614, loss_s1: 0.030219, loss_fp: 0.000431, loss_freq: 0.017418
[19:52:57.442] iteration 29760: loss: 0.037613, loss_s1: 0.030381, loss_fp: 0.001223, loss_freq: 0.012324
[19:52:58.071] iteration 29761: loss: 0.025911, loss_s1: 0.009788, loss_fp: 0.001480, loss_freq: 0.006962
[19:52:58.700] iteration 29762: loss: 0.036167, loss_s1: 0.031367, loss_fp: 0.002920, loss_freq: 0.010671
[19:52:59.324] iteration 29763: loss: 0.037777, loss_s1: 0.020219, loss_fp: 0.005169, loss_freq: 0.024663
[19:52:59.943] iteration 29764: loss: 0.115011, loss_s1: 0.110533, loss_fp: 0.018999, loss_freq: 0.060027
[19:53:00.574] iteration 29765: loss: 0.053533, loss_s1: 0.056968, loss_fp: 0.007515, loss_freq: 0.014941
[19:53:01.196] iteration 29766: loss: 0.052595, loss_s1: 0.035941, loss_fp: 0.001886, loss_freq: 0.033364
[19:53:01.818] iteration 29767: loss: 0.059611, loss_s1: 0.061673, loss_fp: 0.001885, loss_freq: 0.013710
[19:53:02.445] iteration 29768: loss: 0.050059, loss_s1: 0.028109, loss_fp: 0.003717, loss_freq: 0.032018
[19:53:03.069] iteration 29769: loss: 0.039000, loss_s1: 0.031580, loss_fp: 0.003697, loss_freq: 0.010144
[19:53:03.692] iteration 29770: loss: 0.066769, loss_s1: 0.059279, loss_fp: 0.001603, loss_freq: 0.027409
[19:53:04.315] iteration 29771: loss: 0.069504, loss_s1: 0.047414, loss_fp: 0.008389, loss_freq: 0.048763
[19:53:04.944] iteration 29772: loss: 0.035063, loss_s1: 0.034474, loss_fp: 0.001830, loss_freq: 0.010612
[19:53:05.581] iteration 29773: loss: 0.028484, loss_s1: 0.021084, loss_fp: 0.002002, loss_freq: 0.010722
[19:53:06.205] iteration 29774: loss: 0.072243, loss_s1: 0.056312, loss_fp: 0.003469, loss_freq: 0.042652
[19:53:06.830] iteration 29775: loss: 0.041410, loss_s1: 0.034421, loss_fp: 0.003507, loss_freq: 0.012779
[19:53:07.459] iteration 29776: loss: 0.041826, loss_s1: 0.023089, loss_fp: 0.002564, loss_freq: 0.032279
[19:53:08.085] iteration 29777: loss: 0.051320, loss_s1: 0.054771, loss_fp: 0.003411, loss_freq: 0.021541
[19:53:08.708] iteration 29778: loss: 0.034786, loss_s1: 0.011296, loss_fp: 0.011406, loss_freq: 0.014616
[19:53:09.330] iteration 29779: loss: 0.031239, loss_s1: 0.023524, loss_fp: 0.004319, loss_freq: 0.010748
[19:53:09.953] iteration 29780: loss: 0.039421, loss_s1: 0.033528, loss_fp: 0.005149, loss_freq: 0.005706
[19:53:10.581] iteration 29781: loss: 0.046228, loss_s1: 0.034302, loss_fp: 0.000510, loss_freq: 0.025261
[19:53:11.212] iteration 29782: loss: 0.045827, loss_s1: 0.047697, loss_fp: 0.001788, loss_freq: 0.011816
[19:53:11.837] iteration 29783: loss: 0.060813, loss_s1: 0.054159, loss_fp: 0.003456, loss_freq: 0.035865
[19:53:12.460] iteration 29784: loss: 0.034260, loss_s1: 0.012099, loss_fp: 0.002753, loss_freq: 0.024649
[19:53:13.084] iteration 29785: loss: 0.059312, loss_s1: 0.059415, loss_fp: 0.005196, loss_freq: 0.010991
[19:53:14.098] iteration 29786: loss: 0.034429, loss_s1: 0.023516, loss_fp: 0.003814, loss_freq: 0.012534
[19:53:14.748] iteration 29787: loss: 0.041666, loss_s1: 0.040236, loss_fp: 0.003419, loss_freq: 0.009801
[19:53:15.371] iteration 29788: loss: 0.044130, loss_s1: 0.040595, loss_fp: 0.001731, loss_freq: 0.011792
[19:53:16.012] iteration 29789: loss: 0.046366, loss_s1: 0.027396, loss_fp: 0.001441, loss_freq: 0.015542
[19:53:16.670] iteration 29790: loss: 0.038263, loss_s1: 0.009066, loss_fp: 0.009945, loss_freq: 0.017841
[19:53:17.309] iteration 29791: loss: 0.092047, loss_s1: 0.084158, loss_fp: 0.009097, loss_freq: 0.038179
[19:53:17.940] iteration 29792: loss: 0.054290, loss_s1: 0.015764, loss_fp: 0.006673, loss_freq: 0.059968
[19:53:18.567] iteration 29793: loss: 0.026235, loss_s1: 0.018449, loss_fp: 0.002851, loss_freq: 0.007281
[19:53:19.206] iteration 29794: loss: 0.050230, loss_s1: 0.033580, loss_fp: 0.017290, loss_freq: 0.028599
[19:53:19.840] iteration 29795: loss: 0.056475, loss_s1: 0.050555, loss_fp: 0.009103, loss_freq: 0.020959
[19:53:20.471] iteration 29796: loss: 0.025503, loss_s1: 0.008748, loss_fp: 0.002787, loss_freq: 0.010492
[19:53:21.104] iteration 29797: loss: 0.034493, loss_s1: 0.032580, loss_fp: 0.003381, loss_freq: 0.008943
[19:53:21.736] iteration 29798: loss: 0.087186, loss_s1: 0.056627, loss_fp: 0.001622, loss_freq: 0.089131
[19:53:22.365] iteration 29799: loss: 0.071876, loss_s1: 0.076648, loss_fp: 0.004508, loss_freq: 0.026086
[19:53:22.998] iteration 29800: loss: 0.050474, loss_s1: 0.041031, loss_fp: 0.012081, loss_freq: 0.020710
[19:53:26.034] iteration 29800 : mean_dice : 0.730889
[19:53:26.677] iteration 29801: loss: 0.079076, loss_s1: 0.058768, loss_fp: 0.006160, loss_freq: 0.064754
[19:53:27.306] iteration 29802: loss: 0.062852, loss_s1: 0.057651, loss_fp: 0.007121, loss_freq: 0.009897
[19:53:27.928] iteration 29803: loss: 0.054271, loss_s1: 0.042692, loss_fp: 0.004356, loss_freq: 0.022986
[19:53:28.560] iteration 29804: loss: 0.033475, loss_s1: 0.009665, loss_fp: 0.002081, loss_freq: 0.025700
[19:53:29.188] iteration 29805: loss: 0.043242, loss_s1: 0.032682, loss_fp: 0.003129, loss_freq: 0.014326
[19:53:29.814] iteration 29806: loss: 0.027442, loss_s1: 0.020891, loss_fp: 0.001220, loss_freq: 0.003308
[19:53:30.440] iteration 29807: loss: 0.041293, loss_s1: 0.020198, loss_fp: 0.004597, loss_freq: 0.022710
[19:53:31.072] iteration 29808: loss: 0.048317, loss_s1: 0.029895, loss_fp: 0.002648, loss_freq: 0.018430
[19:53:31.700] iteration 29809: loss: 0.069091, loss_s1: 0.048791, loss_fp: 0.013905, loss_freq: 0.046210
[19:53:32.329] iteration 29810: loss: 0.051781, loss_s1: 0.047658, loss_fp: 0.003322, loss_freq: 0.028366
[19:53:32.960] iteration 29811: loss: 0.069025, loss_s1: 0.060286, loss_fp: 0.007593, loss_freq: 0.038077
[19:53:33.590] iteration 29812: loss: 0.026311, loss_s1: 0.008764, loss_fp: 0.002225, loss_freq: 0.005689
[19:53:34.219] iteration 29813: loss: 0.071452, loss_s1: 0.054937, loss_fp: 0.008802, loss_freq: 0.045952
[19:53:34.845] iteration 29814: loss: 0.066659, loss_s1: 0.034831, loss_fp: 0.020711, loss_freq: 0.044719
[19:53:35.472] iteration 29815: loss: 0.041299, loss_s1: 0.034615, loss_fp: 0.004623, loss_freq: 0.012562
[19:53:36.097] iteration 29816: loss: 0.052644, loss_s1: 0.046594, loss_fp: 0.009026, loss_freq: 0.020275
[19:53:36.727] iteration 29817: loss: 0.036333, loss_s1: 0.023975, loss_fp: 0.003442, loss_freq: 0.009215
[19:53:37.403] iteration 29818: loss: 0.041421, loss_s1: 0.030543, loss_fp: 0.005296, loss_freq: 0.017796
[19:53:38.039] iteration 29819: loss: 0.029715, loss_s1: 0.026697, loss_fp: 0.002944, loss_freq: 0.005493
[19:53:38.675] iteration 29820: loss: 0.056664, loss_s1: 0.051905, loss_fp: 0.003641, loss_freq: 0.019247
[19:53:39.309] iteration 29821: loss: 0.065865, loss_s1: 0.050062, loss_fp: 0.008868, loss_freq: 0.040681
[19:53:39.937] iteration 29822: loss: 0.041784, loss_s1: 0.032058, loss_fp: 0.004644, loss_freq: 0.017773
[19:53:40.561] iteration 29823: loss: 0.032279, loss_s1: 0.017335, loss_fp: 0.001877, loss_freq: 0.018191
[19:53:41.189] iteration 29824: loss: 0.075992, loss_s1: 0.080855, loss_fp: 0.003340, loss_freq: 0.028286
[19:53:41.823] iteration 29825: loss: 0.047574, loss_s1: 0.053798, loss_fp: 0.005813, loss_freq: 0.008724
[19:53:42.461] iteration 29826: loss: 0.055203, loss_s1: 0.060514, loss_fp: 0.000439, loss_freq: 0.010959
[19:53:43.093] iteration 29827: loss: 0.084022, loss_s1: 0.078281, loss_fp: 0.003912, loss_freq: 0.063772
[19:53:43.728] iteration 29828: loss: 0.058353, loss_s1: 0.048416, loss_fp: 0.007682, loss_freq: 0.033691
[19:53:44.363] iteration 29829: loss: 0.049044, loss_s1: 0.019738, loss_fp: 0.002755, loss_freq: 0.044413
[19:53:45.001] iteration 29830: loss: 0.062210, loss_s1: 0.045910, loss_fp: 0.011306, loss_freq: 0.033793
[19:53:45.637] iteration 29831: loss: 0.029359, loss_s1: 0.025348, loss_fp: 0.002219, loss_freq: 0.004842
[19:53:46.279] iteration 29832: loss: 0.025128, loss_s1: 0.014999, loss_fp: 0.001833, loss_freq: 0.004163
[19:53:46.953] iteration 29833: loss: 0.044059, loss_s1: 0.034105, loss_fp: 0.018576, loss_freq: 0.011230
[19:53:47.597] iteration 29834: loss: 0.076888, loss_s1: 0.075606, loss_fp: 0.002806, loss_freq: 0.043672
[19:53:48.237] iteration 29835: loss: 0.038711, loss_s1: 0.021105, loss_fp: 0.003310, loss_freq: 0.026625
[19:53:48.866] iteration 29836: loss: 0.051315, loss_s1: 0.042570, loss_fp: 0.003309, loss_freq: 0.022407
[19:53:49.502] iteration 29837: loss: 0.044532, loss_s1: 0.025648, loss_fp: 0.002550, loss_freq: 0.029990
[19:53:50.128] iteration 29838: loss: 0.048602, loss_s1: 0.031273, loss_fp: 0.003740, loss_freq: 0.033333
[19:53:50.762] iteration 29839: loss: 0.052847, loss_s1: 0.036660, loss_fp: 0.004588, loss_freq: 0.034553
[19:53:51.389] iteration 29840: loss: 0.036866, loss_s1: 0.022685, loss_fp: 0.003525, loss_freq: 0.017032
[19:53:52.024] iteration 29841: loss: 0.039630, loss_s1: 0.022884, loss_fp: 0.003124, loss_freq: 0.016294
[19:53:52.648] iteration 29842: loss: 0.034413, loss_s1: 0.019743, loss_fp: 0.000922, loss_freq: 0.008209
[19:53:53.277] iteration 29843: loss: 0.049654, loss_s1: 0.027597, loss_fp: 0.002384, loss_freq: 0.011820
[19:53:53.906] iteration 29844: loss: 0.029932, loss_s1: 0.021878, loss_fp: 0.001497, loss_freq: 0.008823
[19:53:54.532] iteration 29845: loss: 0.029521, loss_s1: 0.017708, loss_fp: 0.004950, loss_freq: 0.011888
[19:53:55.160] iteration 29846: loss: 0.055642, loss_s1: 0.052352, loss_fp: 0.003783, loss_freq: 0.015326
[19:53:55.786] iteration 29847: loss: 0.050060, loss_s1: 0.042828, loss_fp: 0.002195, loss_freq: 0.027724
[19:53:56.412] iteration 29848: loss: 0.049880, loss_s1: 0.045194, loss_fp: 0.001425, loss_freq: 0.017094
[19:53:57.041] iteration 29849: loss: 0.048971, loss_s1: 0.028623, loss_fp: 0.001245, loss_freq: 0.033207
[19:53:57.669] iteration 29850: loss: 0.043701, loss_s1: 0.016811, loss_fp: 0.023935, loss_freq: 0.019366
[19:53:58.305] iteration 29851: loss: 0.094354, loss_s1: 0.061394, loss_fp: 0.003160, loss_freq: 0.097487
[19:53:58.937] iteration 29852: loss: 0.058877, loss_s1: 0.036622, loss_fp: 0.005580, loss_freq: 0.032423
[19:53:59.577] iteration 29853: loss: 0.046683, loss_s1: 0.040839, loss_fp: 0.003035, loss_freq: 0.022014
[19:54:00.206] iteration 29854: loss: 0.043041, loss_s1: 0.028199, loss_fp: 0.003015, loss_freq: 0.017382
[19:54:00.840] iteration 29855: loss: 0.057218, loss_s1: 0.040574, loss_fp: 0.005338, loss_freq: 0.022288
[19:54:01.479] iteration 29856: loss: 0.088518, loss_s1: 0.065087, loss_fp: 0.017989, loss_freq: 0.041121
[19:54:02.120] iteration 29857: loss: 0.028040, loss_s1: 0.015788, loss_fp: 0.000322, loss_freq: 0.011782
[19:54:02.772] iteration 29858: loss: 0.061808, loss_s1: 0.073020, loss_fp: 0.002047, loss_freq: 0.013394
[19:54:03.403] iteration 29859: loss: 0.043306, loss_s1: 0.031746, loss_fp: 0.001541, loss_freq: 0.017369
[19:54:04.033] iteration 29860: loss: 0.046237, loss_s1: 0.033723, loss_fp: 0.002329, loss_freq: 0.010085
[19:54:04.686] iteration 29861: loss: 0.039028, loss_s1: 0.031590, loss_fp: 0.001691, loss_freq: 0.006837
[19:54:05.337] iteration 29862: loss: 0.057887, loss_s1: 0.054082, loss_fp: 0.005436, loss_freq: 0.016404
[19:54:05.968] iteration 29863: loss: 0.026763, loss_s1: 0.017192, loss_fp: 0.000921, loss_freq: 0.006780
[19:54:06.599] iteration 29864: loss: 0.036820, loss_s1: 0.012889, loss_fp: 0.001651, loss_freq: 0.008656
[19:54:07.231] iteration 29865: loss: 0.048294, loss_s1: 0.037644, loss_fp: 0.003573, loss_freq: 0.022282
[19:54:07.861] iteration 29866: loss: 0.054724, loss_s1: 0.028230, loss_fp: 0.003652, loss_freq: 0.034470
[19:54:08.497] iteration 29867: loss: 0.066664, loss_s1: 0.061996, loss_fp: 0.004376, loss_freq: 0.036428
[19:54:09.122] iteration 29868: loss: 0.027074, loss_s1: 0.014009, loss_fp: 0.003648, loss_freq: 0.012934
[19:54:09.747] iteration 29869: loss: 0.039576, loss_s1: 0.030872, loss_fp: 0.003841, loss_freq: 0.012040
[19:54:10.372] iteration 29870: loss: 0.093879, loss_s1: 0.065277, loss_fp: 0.014130, loss_freq: 0.083951
[19:54:10.997] iteration 29871: loss: 0.026885, loss_s1: 0.008014, loss_fp: 0.002906, loss_freq: 0.007967
[19:54:11.644] iteration 29872: loss: 0.046234, loss_s1: 0.045349, loss_fp: 0.001191, loss_freq: 0.013215
[19:54:12.316] iteration 29873: loss: 0.055419, loss_s1: 0.042247, loss_fp: 0.007433, loss_freq: 0.024647
[19:54:12.949] iteration 29874: loss: 0.088577, loss_s1: 0.054385, loss_fp: 0.008622, loss_freq: 0.082060
[19:54:13.586] iteration 29875: loss: 0.062823, loss_s1: 0.069471, loss_fp: 0.005128, loss_freq: 0.024144
[19:54:14.220] iteration 29876: loss: 0.045971, loss_s1: 0.038919, loss_fp: 0.006207, loss_freq: 0.012875
[19:54:14.847] iteration 29877: loss: 0.070836, loss_s1: 0.052410, loss_fp: 0.003772, loss_freq: 0.052721
[19:54:15.483] iteration 29878: loss: 0.036541, loss_s1: 0.011235, loss_fp: 0.001096, loss_freq: 0.009609
[19:54:16.115] iteration 29879: loss: 0.039805, loss_s1: 0.035249, loss_fp: 0.003140, loss_freq: 0.005385
[19:54:16.744] iteration 29880: loss: 0.043188, loss_s1: 0.017264, loss_fp: 0.003806, loss_freq: 0.035519
[19:54:17.375] iteration 29881: loss: 0.049955, loss_s1: 0.032869, loss_fp: 0.004770, loss_freq: 0.033138
[19:54:18.005] iteration 29882: loss: 0.038926, loss_s1: 0.020942, loss_fp: 0.005850, loss_freq: 0.020217
[19:54:18.637] iteration 29883: loss: 0.044826, loss_s1: 0.039257, loss_fp: 0.000516, loss_freq: 0.016454
[19:54:19.290] iteration 29884: loss: 0.025689, loss_s1: 0.015526, loss_fp: 0.003261, loss_freq: 0.003425
[19:54:19.944] iteration 29885: loss: 0.050009, loss_s1: 0.031971, loss_fp: 0.007677, loss_freq: 0.023722
[19:54:20.585] iteration 29886: loss: 0.045916, loss_s1: 0.025520, loss_fp: 0.009685, loss_freq: 0.031505
[19:54:21.245] iteration 29887: loss: 0.080902, loss_s1: 0.051671, loss_fp: 0.003065, loss_freq: 0.062673
[19:54:21.875] iteration 29888: loss: 0.050555, loss_s1: 0.037908, loss_fp: 0.002875, loss_freq: 0.030393
[19:54:22.501] iteration 29889: loss: 0.042480, loss_s1: 0.038467, loss_fp: 0.003580, loss_freq: 0.015611
[19:54:23.138] iteration 29890: loss: 0.034069, loss_s1: 0.021996, loss_fp: 0.007053, loss_freq: 0.006303
[19:54:23.764] iteration 29891: loss: 0.040869, loss_s1: 0.017407, loss_fp: 0.003302, loss_freq: 0.032534
[19:54:24.391] iteration 29892: loss: 0.035277, loss_s1: 0.026778, loss_fp: 0.000440, loss_freq: 0.005232
[19:54:25.019] iteration 29893: loss: 0.061379, loss_s1: 0.055285, loss_fp: 0.001184, loss_freq: 0.030616
[19:54:25.648] iteration 29894: loss: 0.089387, loss_s1: 0.054131, loss_fp: 0.012889, loss_freq: 0.073690
[19:54:26.275] iteration 29895: loss: 0.052814, loss_s1: 0.056753, loss_fp: 0.003440, loss_freq: 0.014388
[19:54:26.908] iteration 29896: loss: 0.051168, loss_s1: 0.041112, loss_fp: 0.002310, loss_freq: 0.005420
[19:54:27.577] iteration 29897: loss: 0.040379, loss_s1: 0.024612, loss_fp: 0.003590, loss_freq: 0.024220
[19:54:28.241] iteration 29898: loss: 0.053339, loss_s1: 0.046785, loss_fp: 0.011803, loss_freq: 0.020287
[19:54:28.908] iteration 29899: loss: 0.049257, loss_s1: 0.043118, loss_fp: 0.000336, loss_freq: 0.031211
[19:54:29.609] iteration 29900: loss: 0.039184, loss_s1: 0.036851, loss_fp: 0.002787, loss_freq: 0.001828
[19:54:30.244] iteration 29901: loss: 0.063279, loss_s1: 0.047283, loss_fp: 0.004331, loss_freq: 0.039654
[19:54:30.884] iteration 29902: loss: 0.050817, loss_s1: 0.045526, loss_fp: 0.001924, loss_freq: 0.027657
[19:54:31.523] iteration 29903: loss: 0.022682, loss_s1: 0.011087, loss_fp: 0.001276, loss_freq: 0.005702
[19:54:32.151] iteration 29904: loss: 0.069258, loss_s1: 0.069584, loss_fp: 0.007709, loss_freq: 0.030686
[19:54:32.780] iteration 29905: loss: 0.086955, loss_s1: 0.083482, loss_fp: 0.005232, loss_freq: 0.059584
[19:54:33.409] iteration 29906: loss: 0.050144, loss_s1: 0.036535, loss_fp: 0.010294, loss_freq: 0.022763
[19:54:34.036] iteration 29907: loss: 0.054364, loss_s1: 0.054980, loss_fp: 0.007694, loss_freq: 0.012408
[19:54:34.665] iteration 29908: loss: 0.039880, loss_s1: 0.033738, loss_fp: 0.004232, loss_freq: 0.008774
[19:54:35.293] iteration 29909: loss: 0.065547, loss_s1: 0.078754, loss_fp: 0.002940, loss_freq: 0.018988
[19:54:35.927] iteration 29910: loss: 0.032087, loss_s1: 0.018611, loss_fp: 0.002838, loss_freq: 0.011561
[19:54:36.555] iteration 29911: loss: 0.044045, loss_s1: 0.041684, loss_fp: 0.002472, loss_freq: 0.007776
[19:54:37.188] iteration 29912: loss: 0.049378, loss_s1: 0.046772, loss_fp: 0.006820, loss_freq: 0.007618
[19:54:37.817] iteration 29913: loss: 0.043212, loss_s1: 0.022051, loss_fp: 0.000957, loss_freq: 0.024992
[19:54:38.450] iteration 29914: loss: 0.050555, loss_s1: 0.037738, loss_fp: 0.004024, loss_freq: 0.031507
[19:54:39.106] iteration 29915: loss: 0.047232, loss_s1: 0.049072, loss_fp: 0.003057, loss_freq: 0.019250
[19:54:39.731] iteration 29916: loss: 0.072576, loss_s1: 0.042149, loss_fp: 0.017203, loss_freq: 0.062544
[19:54:40.360] iteration 29917: loss: 0.040049, loss_s1: 0.037017, loss_fp: 0.002637, loss_freq: 0.009839
[19:54:40.990] iteration 29918: loss: 0.064934, loss_s1: 0.044825, loss_fp: 0.014185, loss_freq: 0.035612
[19:54:41.619] iteration 29919: loss: 0.035491, loss_s1: 0.017482, loss_fp: 0.001115, loss_freq: 0.024002
[19:54:42.248] iteration 29920: loss: 0.042547, loss_s1: 0.028293, loss_fp: 0.002832, loss_freq: 0.015348
[19:54:42.874] iteration 29921: loss: 0.046974, loss_s1: 0.048380, loss_fp: 0.004659, loss_freq: 0.012283
[19:54:43.509] iteration 29922: loss: 0.036802, loss_s1: 0.016785, loss_fp: 0.000655, loss_freq: 0.010727
[19:54:44.137] iteration 29923: loss: 0.048053, loss_s1: 0.032193, loss_fp: 0.004090, loss_freq: 0.035436
[19:54:44.769] iteration 29924: loss: 0.027818, loss_s1: 0.021486, loss_fp: 0.001717, loss_freq: 0.004562
[19:54:45.395] iteration 29925: loss: 0.093117, loss_s1: 0.064535, loss_fp: 0.021120, loss_freq: 0.059695
[19:54:46.026] iteration 29926: loss: 0.047469, loss_s1: 0.046167, loss_fp: 0.007882, loss_freq: 0.014063
[19:54:46.652] iteration 29927: loss: 0.031109, loss_s1: 0.012917, loss_fp: 0.004786, loss_freq: 0.015217
[19:54:47.284] iteration 29928: loss: 0.038809, loss_s1: 0.023548, loss_fp: 0.004753, loss_freq: 0.020670
[19:54:47.909] iteration 29929: loss: 0.066139, loss_s1: 0.066132, loss_fp: 0.003533, loss_freq: 0.025647
[19:54:48.536] iteration 29930: loss: 0.035029, loss_s1: 0.021577, loss_fp: 0.003854, loss_freq: 0.007795
[19:54:49.166] iteration 29931: loss: 0.055044, loss_s1: 0.039540, loss_fp: 0.006755, loss_freq: 0.030577
[19:54:49.789] iteration 29932: loss: 0.075154, loss_s1: 0.061078, loss_fp: 0.009757, loss_freq: 0.053812
[19:54:50.416] iteration 29933: loss: 0.021837, loss_s1: 0.012047, loss_fp: 0.001028, loss_freq: 0.006577
[19:54:51.048] iteration 29934: loss: 0.030007, loss_s1: 0.018753, loss_fp: 0.003164, loss_freq: 0.012734
[19:54:51.676] iteration 29935: loss: 0.099571, loss_s1: 0.110895, loss_fp: 0.006037, loss_freq: 0.043906
[19:54:52.303] iteration 29936: loss: 0.052934, loss_s1: 0.043484, loss_fp: 0.002442, loss_freq: 0.024576
[19:54:52.931] iteration 29937: loss: 0.057892, loss_s1: 0.028881, loss_fp: 0.017655, loss_freq: 0.042445
[19:54:53.568] iteration 29938: loss: 0.051716, loss_s1: 0.045968, loss_fp: 0.004295, loss_freq: 0.025835
[19:54:54.198] iteration 29939: loss: 0.049358, loss_s1: 0.027940, loss_fp: 0.009756, loss_freq: 0.029866
[19:54:54.829] iteration 29940: loss: 0.020104, loss_s1: 0.008780, loss_fp: 0.000796, loss_freq: 0.009884
[19:54:55.458] iteration 29941: loss: 0.031680, loss_s1: 0.023188, loss_fp: 0.000919, loss_freq: 0.008655
[19:54:56.087] iteration 29942: loss: 0.033786, loss_s1: 0.019864, loss_fp: 0.000903, loss_freq: 0.014376
[19:54:56.717] iteration 29943: loss: 0.077572, loss_s1: 0.082634, loss_fp: 0.002230, loss_freq: 0.036219
[19:54:57.342] iteration 29944: loss: 0.056300, loss_s1: 0.055051, loss_fp: 0.008808, loss_freq: 0.016948
[19:54:57.964] iteration 29945: loss: 0.056807, loss_s1: 0.057019, loss_fp: 0.006348, loss_freq: 0.019575
[19:54:58.583] iteration 29946: loss: 0.049791, loss_s1: 0.048890, loss_fp: 0.002948, loss_freq: 0.011739
[19:54:59.582] iteration 29947: loss: 0.034952, loss_s1: 0.016353, loss_fp: 0.003169, loss_freq: 0.015048
[19:55:00.223] iteration 29948: loss: 0.074634, loss_s1: 0.049566, loss_fp: 0.003195, loss_freq: 0.046187
[19:55:00.869] iteration 29949: loss: 0.029437, loss_s1: 0.013165, loss_fp: 0.001959, loss_freq: 0.008946
[19:55:01.543] iteration 29950: loss: 0.039082, loss_s1: 0.030941, loss_fp: 0.003781, loss_freq: 0.009228
[19:55:02.181] iteration 29951: loss: 0.055247, loss_s1: 0.054996, loss_fp: 0.002737, loss_freq: 0.024635
[19:55:02.836] iteration 29952: loss: 0.087292, loss_s1: 0.093332, loss_fp: 0.001069, loss_freq: 0.036344
[19:55:03.492] iteration 29953: loss: 0.053096, loss_s1: 0.047656, loss_fp: 0.007931, loss_freq: 0.025281
[19:55:04.151] iteration 29954: loss: 0.062932, loss_s1: 0.089445, loss_fp: 0.004630, loss_freq: 0.008061
[19:55:04.795] iteration 29955: loss: 0.043962, loss_s1: 0.041450, loss_fp: 0.002546, loss_freq: 0.020378
[19:55:05.434] iteration 29956: loss: 0.053240, loss_s1: 0.048845, loss_fp: 0.005871, loss_freq: 0.020045
[19:55:06.079] iteration 29957: loss: 0.026437, loss_s1: 0.014091, loss_fp: 0.001337, loss_freq: 0.005961
[19:55:06.719] iteration 29958: loss: 0.034531, loss_s1: 0.016120, loss_fp: 0.000734, loss_freq: 0.017714
[19:55:07.363] iteration 29959: loss: 0.068687, loss_s1: 0.030167, loss_fp: 0.022996, loss_freq: 0.056087
[19:55:08.004] iteration 29960: loss: 0.038233, loss_s1: 0.030046, loss_fp: 0.002071, loss_freq: 0.011044
[19:55:08.644] iteration 29961: loss: 0.033112, loss_s1: 0.020510, loss_fp: 0.001255, loss_freq: 0.019423
[19:55:09.283] iteration 29962: loss: 0.063447, loss_s1: 0.034099, loss_fp: 0.005258, loss_freq: 0.055158
[19:55:09.940] iteration 29963: loss: 0.071539, loss_s1: 0.071313, loss_fp: 0.007232, loss_freq: 0.027918
[19:55:10.573] iteration 29964: loss: 0.056177, loss_s1: 0.045159, loss_fp: 0.003038, loss_freq: 0.027642
[19:55:11.214] iteration 29965: loss: 0.045805, loss_s1: 0.025725, loss_fp: 0.001352, loss_freq: 0.025270
[19:55:11.855] iteration 29966: loss: 0.082241, loss_s1: 0.085784, loss_fp: 0.006460, loss_freq: 0.030861
[19:55:12.497] iteration 29967: loss: 0.039370, loss_s1: 0.030565, loss_fp: 0.000460, loss_freq: 0.014775
[19:55:13.130] iteration 29968: loss: 0.047472, loss_s1: 0.034682, loss_fp: 0.001423, loss_freq: 0.019082
[19:55:13.768] iteration 29969: loss: 0.038409, loss_s1: 0.023702, loss_fp: 0.006139, loss_freq: 0.013263
[19:55:14.405] iteration 29970: loss: 0.038101, loss_s1: 0.010483, loss_fp: 0.002878, loss_freq: 0.031550
[19:55:15.042] iteration 29971: loss: 0.037016, loss_s1: 0.029003, loss_fp: 0.001351, loss_freq: 0.020095
[19:55:15.682] iteration 29972: loss: 0.042129, loss_s1: 0.040085, loss_fp: 0.005785, loss_freq: 0.013402
[19:55:16.320] iteration 29973: loss: 0.023531, loss_s1: 0.007103, loss_fp: 0.001709, loss_freq: 0.004011
[19:55:16.957] iteration 29974: loss: 0.057907, loss_s1: 0.047320, loss_fp: 0.006804, loss_freq: 0.024277
[19:55:17.597] iteration 29975: loss: 0.062586, loss_s1: 0.047061, loss_fp: 0.006274, loss_freq: 0.045314
[19:55:18.235] iteration 29976: loss: 0.034157, loss_s1: 0.023757, loss_fp: 0.003626, loss_freq: 0.011452
[19:55:18.870] iteration 29977: loss: 0.073357, loss_s1: 0.047287, loss_fp: 0.009390, loss_freq: 0.061094
[19:55:19.505] iteration 29978: loss: 0.032327, loss_s1: 0.023586, loss_fp: 0.004776, loss_freq: 0.007111
[19:55:20.156] iteration 29979: loss: 0.042710, loss_s1: 0.029278, loss_fp: 0.001415, loss_freq: 0.024819
[19:55:20.784] iteration 29980: loss: 0.033426, loss_s1: 0.031009, loss_fp: 0.003803, loss_freq: 0.007794
[19:55:21.415] iteration 29981: loss: 0.056329, loss_s1: 0.040271, loss_fp: 0.002974, loss_freq: 0.021826
[19:55:22.048] iteration 29982: loss: 0.073632, loss_s1: 0.051616, loss_fp: 0.006295, loss_freq: 0.058242
[19:55:22.670] iteration 29983: loss: 0.060536, loss_s1: 0.040037, loss_fp: 0.009934, loss_freq: 0.039760
[19:55:23.295] iteration 29984: loss: 0.053715, loss_s1: 0.050641, loss_fp: 0.002816, loss_freq: 0.028207
[19:55:23.927] iteration 29985: loss: 0.074079, loss_s1: 0.088739, loss_fp: 0.007018, loss_freq: 0.011759
[19:55:24.552] iteration 29986: loss: 0.063030, loss_s1: 0.043219, loss_fp: 0.012800, loss_freq: 0.032833
[19:55:25.180] iteration 29987: loss: 0.042314, loss_s1: 0.020881, loss_fp: 0.002760, loss_freq: 0.016597
[19:55:25.811] iteration 29988: loss: 0.059512, loss_s1: 0.059572, loss_fp: 0.004436, loss_freq: 0.031113
[19:55:26.435] iteration 29989: loss: 0.036762, loss_s1: 0.021196, loss_fp: 0.001783, loss_freq: 0.026475
[19:55:27.062] iteration 29990: loss: 0.043619, loss_s1: 0.021610, loss_fp: 0.001310, loss_freq: 0.038135
[19:55:27.688] iteration 29991: loss: 0.029721, loss_s1: 0.010114, loss_fp: 0.005994, loss_freq: 0.009824
[19:55:28.314] iteration 29992: loss: 0.044598, loss_s1: 0.043537, loss_fp: 0.000768, loss_freq: 0.008789
[19:55:28.942] iteration 29993: loss: 0.024947, loss_s1: 0.014312, loss_fp: 0.003242, loss_freq: 0.005635
[19:55:29.566] iteration 29994: loss: 0.045522, loss_s1: 0.036071, loss_fp: 0.009679, loss_freq: 0.022173
[19:55:30.191] iteration 29995: loss: 0.078657, loss_s1: 0.070955, loss_fp: 0.001909, loss_freq: 0.052432
[19:55:30.824] iteration 29996: loss: 0.050477, loss_s1: 0.044545, loss_fp: 0.006259, loss_freq: 0.025399
[19:55:31.464] iteration 29997: loss: 0.049966, loss_s1: 0.060287, loss_fp: 0.001024, loss_freq: 0.009841
[19:55:32.098] iteration 29998: loss: 0.044282, loss_s1: 0.011565, loss_fp: 0.009538, loss_freq: 0.023125
[19:55:32.735] iteration 29999: loss: 0.054787, loss_s1: 0.050961, loss_fp: 0.004645, loss_freq: 0.025902
[19:55:33.363] iteration 30000: loss: 0.036157, loss_s1: 0.023732, loss_fp: 0.001656, loss_freq: 0.017877
[19:55:36.689] iteration 30000 : mean_dice : 0.734056
