[11:53:48.839] Namespace(config='/home/wth/My_codes/SSL_MIS_Exps/Freq_adaptive_modulation/configs/kvasir.yaml', labeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/20%_labeled.txt', unlabeled_id_path='/home/wth/My_codes/SSL_MIS_Exps/polyp/20%_unlabeled.txt', save_path='/home/wth/My_codes/SSL_MIS_Exps/models/KVASIR', seed=1337, deterministic=1, local_rank=0, port=None)
[11:53:52.442] iteration 1: loss: 0.842410, loss_s1: 0.130121, loss_fp: 0.203273, loss_freq: 0.087414
[11:53:53.107] iteration 2: loss: 1.315711, loss_s1: 0.505949, loss_fp: 0.500435, loss_freq: 0.501654
[11:53:53.729] iteration 3: loss: 1.282031, loss_s1: 0.508636, loss_fp: 0.501199, loss_freq: 0.512732
[11:53:54.393] iteration 4: loss: 1.237211, loss_s1: 0.503336, loss_fp: 0.500419, loss_freq: 0.506653
[11:53:55.051] iteration 5: loss: 1.197473, loss_s1: 0.507171, loss_fp: 0.500312, loss_freq: 0.502772
[11:53:55.719] iteration 6: loss: 1.154072, loss_s1: 0.506749, loss_fp: 0.500396, loss_freq: 0.504289
[11:53:56.376] iteration 7: loss: 1.109047, loss_s1: 0.504461, loss_fp: 0.500193, loss_freq: 0.501418
[11:53:57.026] iteration 8: loss: 1.087400, loss_s1: 0.501861, loss_fp: 0.500124, loss_freq: 0.501483
[11:53:58.206] iteration 9: loss: 1.048227, loss_s1: 0.500851, loss_fp: 0.501057, loss_freq: 0.501275
[11:53:58.824] iteration 10: loss: 1.229010, loss_s1: 0.500695, loss_fp: 0.501004, loss_freq: 0.501237
[11:53:59.463] iteration 11: loss: 1.052378, loss_s1: 0.501406, loss_fp: 0.501190, loss_freq: 0.500642
[11:54:00.084] iteration 12: loss: 1.117066, loss_s1: 0.500839, loss_fp: 0.500304, loss_freq: 0.500691
[11:54:00.711] iteration 13: loss: 1.114131, loss_s1: 0.501212, loss_fp: 0.500650, loss_freq: 0.501233
[11:54:01.343] iteration 14: loss: 1.088049, loss_s1: 0.501444, loss_fp: 0.500443, loss_freq: 0.500670
[11:54:01.977] iteration 15: loss: 1.115351, loss_s1: 0.502411, loss_fp: 0.500460, loss_freq: 0.500748
[11:54:02.601] iteration 16: loss: 1.115332, loss_s1: 0.500626, loss_fp: 0.500656, loss_freq: 0.501363
[11:54:03.223] iteration 17: loss: 1.112596, loss_s1: 0.507375, loss_fp: 0.500187, loss_freq: 0.501237
[11:54:03.875] iteration 18: loss: 1.088775, loss_s1: 0.501966, loss_fp: 0.500153, loss_freq: 0.502364
[11:54:04.526] iteration 19: loss: 1.068667, loss_s1: 0.503081, loss_fp: 0.500314, loss_freq: 0.501084
[11:54:05.177] iteration 20: loss: 1.021995, loss_s1: 0.501046, loss_fp: 0.501412, loss_freq: 0.500952
[11:54:05.832] iteration 21: loss: 1.065910, loss_s1: 0.503000, loss_fp: 0.501000, loss_freq: 0.501329
[11:54:06.487] iteration 22: loss: 1.075933, loss_s1: 0.501958, loss_fp: 0.500192, loss_freq: 0.501120
[11:54:07.142] iteration 23: loss: 1.047335, loss_s1: 0.501077, loss_fp: 0.500635, loss_freq: 0.501094
[11:54:07.790] iteration 24: loss: 1.071852, loss_s1: 0.502209, loss_fp: 0.500488, loss_freq: 0.501071
[11:54:08.411] iteration 25: loss: 1.048683, loss_s1: 0.500890, loss_fp: 0.500328, loss_freq: 0.500806
[11:54:09.029] iteration 26: loss: 1.075006, loss_s1: 0.500240, loss_fp: 0.500314, loss_freq: 0.500849
[11:54:09.657] iteration 27: loss: 1.073296, loss_s1: 0.501924, loss_fp: 0.500352, loss_freq: 0.501628
[11:54:10.281] iteration 28: loss: 1.019739, loss_s1: 0.500540, loss_fp: 0.501143, loss_freq: 0.500930
[11:54:10.908] iteration 29: loss: 1.175735, loss_s1: 0.500239, loss_fp: 0.500132, loss_freq: 0.500983
[11:54:11.536] iteration 30: loss: 1.054358, loss_s1: 0.500257, loss_fp: 0.500326, loss_freq: 0.500709
[11:54:12.196] iteration 31: loss: 1.009432, loss_s1: 0.500234, loss_fp: 0.500059, loss_freq: 0.500354
[11:54:12.833] iteration 32: loss: 1.022304, loss_s1: 0.500354, loss_fp: 0.500358, loss_freq: 0.500962
[11:54:13.512] iteration 33: loss: 1.044111, loss_s1: 0.500116, loss_fp: 0.500065, loss_freq: 0.500393
[11:54:14.129] iteration 34: loss: 1.024570, loss_s1: 0.500052, loss_fp: 0.500139, loss_freq: 0.500296
[11:54:14.746] iteration 35: loss: 1.070901, loss_s1: 0.500710, loss_fp: 0.500172, loss_freq: 0.501047
[11:54:15.390] iteration 36: loss: 1.079235, loss_s1: 0.500259, loss_fp: 0.500344, loss_freq: 0.500857
[11:54:16.050] iteration 37: loss: 1.110049, loss_s1: 0.500437, loss_fp: 0.501652, loss_freq: 0.501126
[11:54:16.691] iteration 38: loss: 1.062224, loss_s1: 0.500577, loss_fp: 0.500132, loss_freq: 0.500933
[11:54:17.310] iteration 39: loss: 1.121482, loss_s1: 0.501579, loss_fp: 0.500656, loss_freq: 0.501242
[11:54:17.972] iteration 40: loss: 1.061744, loss_s1: 0.501558, loss_fp: 0.501046, loss_freq: 0.501993
[11:54:18.625] iteration 41: loss: 1.064336, loss_s1: 0.502394, loss_fp: 0.500458, loss_freq: 0.502539
[11:54:19.258] iteration 42: loss: 1.087693, loss_s1: 0.502999, loss_fp: 0.500584, loss_freq: 0.501552
[11:54:19.893] iteration 43: loss: 1.060446, loss_s1: 0.501595, loss_fp: 0.500426, loss_freq: 0.501206
[11:54:20.546] iteration 44: loss: 0.998198, loss_s1: 0.501173, loss_fp: 0.500762, loss_freq: 0.501859
[11:54:21.198] iteration 45: loss: 1.174348, loss_s1: 0.501211, loss_fp: 0.500459, loss_freq: 0.501586
[11:54:21.866] iteration 46: loss: 1.018680, loss_s1: 0.501419, loss_fp: 0.500473, loss_freq: 0.500968
[11:54:22.522] iteration 47: loss: 1.065676, loss_s1: 0.501623, loss_fp: 0.501055, loss_freq: 0.502164
[11:54:23.197] iteration 48: loss: 1.107375, loss_s1: 0.501858, loss_fp: 0.500812, loss_freq: 0.501362
[11:54:23.875] iteration 49: loss: 1.084141, loss_s1: 0.501140, loss_fp: 0.500927, loss_freq: 0.500839
[11:54:24.541] iteration 50: loss: 1.129317, loss_s1: 0.501613, loss_fp: 0.500505, loss_freq: 0.501490
[11:54:25.173] iteration 51: loss: 1.099505, loss_s1: 0.505169, loss_fp: 0.500271, loss_freq: 0.501363
[11:54:25.807] iteration 52: loss: 1.118431, loss_s1: 0.501892, loss_fp: 0.500265, loss_freq: 0.500904
[11:54:26.436] iteration 53: loss: 1.070961, loss_s1: 0.500836, loss_fp: 0.500245, loss_freq: 0.501114
[11:54:27.070] iteration 54: loss: 1.048110, loss_s1: 0.500119, loss_fp: 0.500054, loss_freq: 0.500462
[11:54:27.708] iteration 55: loss: 1.028351, loss_s1: 0.500118, loss_fp: 0.500013, loss_freq: 0.500963
[11:54:28.354] iteration 56: loss: 1.066301, loss_s1: 0.500269, loss_fp: 0.500032, loss_freq: 0.500578
[11:54:28.973] iteration 57: loss: 1.090411, loss_s1: 0.500058, loss_fp: 0.500299, loss_freq: 0.500627
[11:54:29.603] iteration 58: loss: 1.071320, loss_s1: 0.500459, loss_fp: 0.500287, loss_freq: 0.501001
[11:54:30.259] iteration 59: loss: 1.065266, loss_s1: 0.500626, loss_fp: 0.500600, loss_freq: 0.500561
[11:54:30.915] iteration 60: loss: 1.037492, loss_s1: 0.500241, loss_fp: 0.500291, loss_freq: 0.500726
[11:54:31.571] iteration 61: loss: 1.056707, loss_s1: 0.500263, loss_fp: 0.500058, loss_freq: 0.500604
[11:54:32.214] iteration 62: loss: 1.073351, loss_s1: 0.500232, loss_fp: 0.500183, loss_freq: 0.500850
[11:54:32.850] iteration 63: loss: 1.024552, loss_s1: 0.500212, loss_fp: 0.500142, loss_freq: 0.500853
[11:54:33.471] iteration 64: loss: 1.152133, loss_s1: 0.500223, loss_fp: 0.500208, loss_freq: 0.500788
[11:54:34.104] iteration 65: loss: 1.050522, loss_s1: 0.500148, loss_fp: 0.500048, loss_freq: 0.500535
[11:54:34.742] iteration 66: loss: 1.002954, loss_s1: 0.500325, loss_fp: 0.500100, loss_freq: 0.500507
[11:54:35.385] iteration 67: loss: 1.032718, loss_s1: 0.500674, loss_fp: 0.500325, loss_freq: 0.500984
[11:54:36.025] iteration 68: loss: 1.044339, loss_s1: 0.500999, loss_fp: 0.500149, loss_freq: 0.501514
[11:54:36.657] iteration 69: loss: 1.024467, loss_s1: 0.500197, loss_fp: 0.500306, loss_freq: 0.501077
[11:54:37.281] iteration 70: loss: 1.070863, loss_s1: 0.500132, loss_fp: 0.500093, loss_freq: 0.500344
[11:54:37.896] iteration 71: loss: 1.067930, loss_s1: 0.500168, loss_fp: 0.500111, loss_freq: 0.500503
[11:54:38.516] iteration 72: loss: 1.113466, loss_s1: 0.500324, loss_fp: 0.500111, loss_freq: 0.500469
[11:54:39.133] iteration 73: loss: 1.072993, loss_s1: 0.500776, loss_fp: 0.500592, loss_freq: 0.500700
[11:54:39.749] iteration 74: loss: 1.114269, loss_s1: 0.500694, loss_fp: 0.500455, loss_freq: 0.501695
[11:54:40.359] iteration 75: loss: 1.044558, loss_s1: 0.500372, loss_fp: 0.500338, loss_freq: 0.500447
[11:54:40.995] iteration 76: loss: 1.041188, loss_s1: 0.501681, loss_fp: 0.500236, loss_freq: 0.500689
[11:54:41.620] iteration 77: loss: 1.071221, loss_s1: 0.500233, loss_fp: 0.500218, loss_freq: 0.500653
[11:54:42.243] iteration 78: loss: 1.060243, loss_s1: 0.500622, loss_fp: 0.500375, loss_freq: 0.500753
[11:54:42.867] iteration 79: loss: 1.023354, loss_s1: 0.500728, loss_fp: 0.500114, loss_freq: 0.500585
[11:54:43.495] iteration 80: loss: 1.228120, loss_s1: 0.500584, loss_fp: 0.500258, loss_freq: 0.501326
[11:54:44.115] iteration 81: loss: 1.024008, loss_s1: 0.500667, loss_fp: 0.500187, loss_freq: 0.500439
[11:54:44.738] iteration 82: loss: 1.043923, loss_s1: 0.500913, loss_fp: 0.500399, loss_freq: 0.500582
[11:54:45.361] iteration 83: loss: 1.095700, loss_s1: 0.503084, loss_fp: 0.500554, loss_freq: 0.500834
[11:54:46.008] iteration 84: loss: 1.061658, loss_s1: 0.501228, loss_fp: 0.500395, loss_freq: 0.500620
[11:54:46.633] iteration 85: loss: 1.110358, loss_s1: 0.501210, loss_fp: 0.500180, loss_freq: 0.500671
[11:54:47.287] iteration 86: loss: 1.089208, loss_s1: 0.502405, loss_fp: 0.500169, loss_freq: 0.501783
[11:54:47.955] iteration 87: loss: 1.078725, loss_s1: 0.500616, loss_fp: 0.500167, loss_freq: 0.501527
[11:54:48.605] iteration 88: loss: 1.076806, loss_s1: 0.501401, loss_fp: 0.500528, loss_freq: 0.501859
[11:54:49.235] iteration 89: loss: 1.047967, loss_s1: 0.500831, loss_fp: 0.500492, loss_freq: 0.501134
[11:54:49.872] iteration 90: loss: 1.046114, loss_s1: 0.500818, loss_fp: 0.500210, loss_freq: 0.501562
[11:54:50.499] iteration 91: loss: 1.056545, loss_s1: 0.500725, loss_fp: 0.500277, loss_freq: 0.500911
[11:54:51.122] iteration 92: loss: 1.093678, loss_s1: 0.500445, loss_fp: 0.500598, loss_freq: 0.501513
[11:54:51.736] iteration 93: loss: 1.062122, loss_s1: 0.500526, loss_fp: 0.500124, loss_freq: 0.501373
[11:54:52.358] iteration 94: loss: 1.063765, loss_s1: 0.501099, loss_fp: 0.500160, loss_freq: 0.501027
[11:54:52.977] iteration 95: loss: 1.027998, loss_s1: 0.500341, loss_fp: 0.500411, loss_freq: 0.500387
[11:54:53.596] iteration 96: loss: 1.051976, loss_s1: 0.500546, loss_fp: 0.500201, loss_freq: 0.501252
[11:54:54.220] iteration 97: loss: 1.079360, loss_s1: 0.500930, loss_fp: 0.500208, loss_freq: 0.501351
[11:54:54.845] iteration 98: loss: 1.030891, loss_s1: 0.500377, loss_fp: 0.500220, loss_freq: 0.501389
[11:54:55.468] iteration 99: loss: 1.154657, loss_s1: 0.500286, loss_fp: 0.500145, loss_freq: 0.501487
[11:54:56.093] iteration 100: loss: 1.051002, loss_s1: 0.500494, loss_fp: 0.500135, loss_freq: 0.501036
[11:54:56.712] iteration 101: loss: 1.010507, loss_s1: 0.500130, loss_fp: 0.500030, loss_freq: 0.500576
[11:54:57.333] iteration 102: loss: 1.022952, loss_s1: 0.501397, loss_fp: 0.500135, loss_freq: 0.500868
[11:54:57.952] iteration 103: loss: 1.037447, loss_s1: 0.500244, loss_fp: 0.500201, loss_freq: 0.500271
[11:54:58.568] iteration 104: loss: 1.019103, loss_s1: 0.500216, loss_fp: 0.500205, loss_freq: 0.500615
[11:54:59.186] iteration 105: loss: 1.071229, loss_s1: 0.501758, loss_fp: 0.500210, loss_freq: 0.501021
[11:54:59.804] iteration 106: loss: 1.077960, loss_s1: 0.501569, loss_fp: 0.501090, loss_freq: 0.502051
[11:55:00.426] iteration 107: loss: 1.091598, loss_s1: 0.501661, loss_fp: 0.500616, loss_freq: 0.501386
[11:55:01.049] iteration 108: loss: 1.071842, loss_s1: 0.500740, loss_fp: 0.500324, loss_freq: 0.501136
[11:55:01.672] iteration 109: loss: 1.110292, loss_s1: 0.500546, loss_fp: 0.500244, loss_freq: 0.500957
[11:55:02.290] iteration 110: loss: 1.049649, loss_s1: 0.500959, loss_fp: 0.500499, loss_freq: 0.501614
[11:55:02.908] iteration 111: loss: 1.043736, loss_s1: 0.501550, loss_fp: 0.500259, loss_freq: 0.501216
[11:55:03.526] iteration 112: loss: 1.066652, loss_s1: 0.500757, loss_fp: 0.500557, loss_freq: 0.501122
[11:55:04.141] iteration 113: loss: 1.052957, loss_s1: 0.501190, loss_fp: 0.500269, loss_freq: 0.500625
[11:55:04.765] iteration 114: loss: 1.008582, loss_s1: 0.501354, loss_fp: 0.500326, loss_freq: 0.500515
[11:55:05.390] iteration 115: loss: 1.198118, loss_s1: 0.500883, loss_fp: 0.500359, loss_freq: 0.501266
[11:55:06.017] iteration 116: loss: 1.002408, loss_s1: 0.500850, loss_fp: 0.500262, loss_freq: 0.501920
[11:55:06.632] iteration 117: loss: 1.039272, loss_s1: 0.502467, loss_fp: 0.500148, loss_freq: 0.501130
[11:55:07.252] iteration 118: loss: 1.095654, loss_s1: 0.500970, loss_fp: 0.500206, loss_freq: 0.501669
[11:55:07.862] iteration 119: loss: 1.056700, loss_s1: 0.501087, loss_fp: 0.500362, loss_freq: 0.500585
[11:55:08.478] iteration 120: loss: 1.104399, loss_s1: 0.503044, loss_fp: 0.500265, loss_freq: 0.501480
[11:55:09.098] iteration 121: loss: 1.082793, loss_s1: 0.502725, loss_fp: 0.500327, loss_freq: 0.501909
[11:55:09.713] iteration 122: loss: 1.092606, loss_s1: 0.500710, loss_fp: 0.500155, loss_freq: 0.501672
[11:55:10.336] iteration 123: loss: 1.086295, loss_s1: 0.500745, loss_fp: 0.500442, loss_freq: 0.500845
[11:55:10.946] iteration 124: loss: 1.040296, loss_s1: 0.500735, loss_fp: 0.500305, loss_freq: 0.500947
[11:55:11.569] iteration 125: loss: 1.036547, loss_s1: 0.500187, loss_fp: 0.500127, loss_freq: 0.500646
[11:55:12.180] iteration 126: loss: 1.057029, loss_s1: 0.500126, loss_fp: 0.500160, loss_freq: 0.501253
[11:55:12.788] iteration 127: loss: 1.098977, loss_s1: 0.500194, loss_fp: 0.500041, loss_freq: 0.501118
[11:55:13.410] iteration 128: loss: 1.055048, loss_s1: 0.500525, loss_fp: 0.500317, loss_freq: 0.500646
[11:55:14.030] iteration 129: loss: 1.056219, loss_s1: 0.500507, loss_fp: 0.500509, loss_freq: 0.500623
[11:55:14.650] iteration 130: loss: 1.032334, loss_s1: 0.500199, loss_fp: 0.500253, loss_freq: 0.501002
[11:55:15.299] iteration 131: loss: 1.049458, loss_s1: 0.500113, loss_fp: 0.500063, loss_freq: 0.500595
[11:55:15.913] iteration 132: loss: 1.081905, loss_s1: 0.500973, loss_fp: 0.500123, loss_freq: 0.500987
[11:55:16.530] iteration 133: loss: 1.025997, loss_s1: 0.500293, loss_fp: 0.500116, loss_freq: 0.500913
[11:55:17.152] iteration 134: loss: 1.149574, loss_s1: 0.500107, loss_fp: 0.500155, loss_freq: 0.500833
[11:55:17.772] iteration 135: loss: 1.046113, loss_s1: 0.500274, loss_fp: 0.500242, loss_freq: 0.500910
[11:55:18.391] iteration 136: loss: 0.994038, loss_s1: 0.500134, loss_fp: 0.500135, loss_freq: 0.500528
[11:55:19.071] iteration 137: loss: 1.021703, loss_s1: 0.500266, loss_fp: 0.500090, loss_freq: 0.500683
[11:55:19.685] iteration 138: loss: 1.037011, loss_s1: 0.500232, loss_fp: 0.500020, loss_freq: 0.500555
[11:55:20.307] iteration 139: loss: 1.010739, loss_s1: 0.500073, loss_fp: 0.500118, loss_freq: 0.500382
[11:55:20.931] iteration 140: loss: 1.052912, loss_s1: 0.500111, loss_fp: 0.500091, loss_freq: 0.500573
[11:55:21.557] iteration 141: loss: 1.078058, loss_s1: 0.500218, loss_fp: 0.500235, loss_freq: 0.500596
[11:55:22.168] iteration 142: loss: 1.077125, loss_s1: 0.500467, loss_fp: 0.500053, loss_freq: 0.500576
[11:55:22.782] iteration 143: loss: 1.065099, loss_s1: 0.500403, loss_fp: 0.500137, loss_freq: 0.500686
[11:55:23.718] iteration 144: loss: 1.070207, loss_s1: 0.500367, loss_fp: 0.500116, loss_freq: 0.501001
[11:55:24.341] iteration 145: loss: 1.069636, loss_s1: 0.502786, loss_fp: 0.500379, loss_freq: 0.500569
[11:55:24.959] iteration 146: loss: 1.052156, loss_s1: 0.500434, loss_fp: 0.500175, loss_freq: 0.501118
[11:55:25.574] iteration 147: loss: 1.100610, loss_s1: 0.500526, loss_fp: 0.500279, loss_freq: 0.500709
[11:55:26.195] iteration 148: loss: 1.047321, loss_s1: 0.500459, loss_fp: 0.500172, loss_freq: 0.500928
[11:55:26.823] iteration 149: loss: 1.040676, loss_s1: 0.501517, loss_fp: 0.500373, loss_freq: 0.500731
[11:55:27.445] iteration 150: loss: 1.052231, loss_s1: 0.501467, loss_fp: 0.500403, loss_freq: 0.500950
[11:55:28.064] iteration 151: loss: 1.056213, loss_s1: 0.500664, loss_fp: 0.500379, loss_freq: 0.500486
[11:55:28.686] iteration 152: loss: 1.013521, loss_s1: 0.500589, loss_fp: 0.500494, loss_freq: 0.500856
[11:55:29.308] iteration 153: loss: 1.173685, loss_s1: 0.500734, loss_fp: 0.500311, loss_freq: 0.501169
[11:55:29.967] iteration 154: loss: 1.025275, loss_s1: 0.500917, loss_fp: 0.500280, loss_freq: 0.501406
[11:55:30.584] iteration 155: loss: 1.027295, loss_s1: 0.502251, loss_fp: 0.500291, loss_freq: 0.500777
[11:55:31.207] iteration 156: loss: 1.099088, loss_s1: 0.502611, loss_fp: 0.500211, loss_freq: 0.501794
[11:55:31.830] iteration 157: loss: 1.059967, loss_s1: 0.502060, loss_fp: 0.500094, loss_freq: 0.500556
[11:55:32.453] iteration 158: loss: 1.106477, loss_s1: 0.501087, loss_fp: 0.500407, loss_freq: 0.500933
[11:55:33.108] iteration 159: loss: 1.085919, loss_s1: 0.503010, loss_fp: 0.500328, loss_freq: 0.501665
[11:55:33.764] iteration 160: loss: 1.120112, loss_s1: 0.501066, loss_fp: 0.500456, loss_freq: 0.501164
[11:55:34.423] iteration 161: loss: 1.080034, loss_s1: 0.501305, loss_fp: 0.500256, loss_freq: 0.502267
[11:55:35.083] iteration 162: loss: 1.043046, loss_s1: 0.503455, loss_fp: 0.500115, loss_freq: 0.500817
[11:55:35.739] iteration 163: loss: 1.035053, loss_s1: 0.503047, loss_fp: 0.500130, loss_freq: 0.500499
[11:55:36.401] iteration 164: loss: 1.053151, loss_s1: 0.501322, loss_fp: 0.500163, loss_freq: 0.501097
[11:55:37.050] iteration 165: loss: 1.087913, loss_s1: 0.500725, loss_fp: 0.500287, loss_freq: 0.501267
[11:55:37.697] iteration 166: loss: 1.056961, loss_s1: 0.502836, loss_fp: 0.500178, loss_freq: 0.500896
[11:55:38.362] iteration 167: loss: 1.059783, loss_s1: 0.500826, loss_fp: 0.500398, loss_freq: 0.500875
[11:55:39.008] iteration 168: loss: 1.023440, loss_s1: 0.500949, loss_fp: 0.500203, loss_freq: 0.500970
[11:55:39.685] iteration 169: loss: 1.045620, loss_s1: 0.500302, loss_fp: 0.500280, loss_freq: 0.500367
[11:55:40.332] iteration 170: loss: 1.072281, loss_s1: 0.501011, loss_fp: 0.500645, loss_freq: 0.501748
[11:55:40.971] iteration 171: loss: 1.010499, loss_s1: 0.500678, loss_fp: 0.500587, loss_freq: 0.500865
[11:55:41.589] iteration 172: loss: 1.149680, loss_s1: 0.500214, loss_fp: 0.500297, loss_freq: 0.500865
[11:55:42.207] iteration 173: loss: 1.040388, loss_s1: 0.500467, loss_fp: 0.500232, loss_freq: 0.500889
[11:55:42.825] iteration 174: loss: 1.001471, loss_s1: 0.500246, loss_fp: 0.500148, loss_freq: 0.500349
[11:55:43.443] iteration 175: loss: 1.014937, loss_s1: 0.500978, loss_fp: 0.500061, loss_freq: 0.500804
[11:55:44.097] iteration 176: loss: 1.018968, loss_s1: 0.500119, loss_fp: 0.500269, loss_freq: 0.500315
[11:55:44.721] iteration 177: loss: 1.011076, loss_s1: 0.500165, loss_fp: 0.500276, loss_freq: 0.500204
[11:55:45.384] iteration 178: loss: 1.058091, loss_s1: 0.500687, loss_fp: 0.500284, loss_freq: 0.501002
[11:55:46.037] iteration 179: loss: 1.080993, loss_s1: 0.500816, loss_fp: 0.500103, loss_freq: 0.500840
[11:55:46.690] iteration 180: loss: 1.094596, loss_s1: 0.501793, loss_fp: 0.500267, loss_freq: 0.500993
[11:55:47.360] iteration 181: loss: 1.052177, loss_s1: 0.501241, loss_fp: 0.500203, loss_freq: 0.500897
[11:55:48.004] iteration 182: loss: 1.106050, loss_s1: 0.500594, loss_fp: 0.500169, loss_freq: 0.500793
[11:55:48.625] iteration 183: loss: 1.055532, loss_s1: 0.500738, loss_fp: 0.500223, loss_freq: 0.501237
[11:55:49.255] iteration 184: loss: 1.048827, loss_s1: 0.503197, loss_fp: 0.500534, loss_freq: 0.502635
[11:55:49.887] iteration 185: loss: 1.062751, loss_s1: 0.503739, loss_fp: 0.500301, loss_freq: 0.502035
[11:55:50.605] iteration 186: loss: 1.057453, loss_s1: 0.502277, loss_fp: 0.500162, loss_freq: 0.501300
[11:55:51.549] iteration 187: loss: 0.998804, loss_s1: 0.502268, loss_fp: 0.500526, loss_freq: 0.501877
[11:55:52.255] iteration 188: loss: 1.137380, loss_s1: 0.502589, loss_fp: 0.500213, loss_freq: 0.501526
[11:55:52.880] iteration 189: loss: 0.994068, loss_s1: 0.501110, loss_fp: 0.500224, loss_freq: 0.501153
[11:55:53.504] iteration 190: loss: 1.040481, loss_s1: 0.501416, loss_fp: 0.500206, loss_freq: 0.501889
[11:55:54.127] iteration 191: loss: 1.077599, loss_s1: 0.502406, loss_fp: 0.500441, loss_freq: 0.500637
[11:55:54.751] iteration 192: loss: 1.055369, loss_s1: 0.503416, loss_fp: 0.500428, loss_freq: 0.500932
[11:55:55.376] iteration 193: loss: 1.119418, loss_s1: 0.502071, loss_fp: 0.500417, loss_freq: 0.501399
[11:55:56.009] iteration 194: loss: 1.078180, loss_s1: 0.505095, loss_fp: 0.500430, loss_freq: 0.501429
[11:55:56.626] iteration 195: loss: 1.088271, loss_s1: 0.503009, loss_fp: 0.500208, loss_freq: 0.500778
[11:55:57.245] iteration 196: loss: 1.100887, loss_s1: 0.504377, loss_fp: 0.500152, loss_freq: 0.501173
[11:55:57.864] iteration 197: loss: 1.032847, loss_s1: 0.503360, loss_fp: 0.500276, loss_freq: 0.500770
[11:55:58.476] iteration 198: loss: 1.052015, loss_s1: 0.501677, loss_fp: 0.500170, loss_freq: 0.501381
[11:55:59.092] iteration 199: loss: 1.031510, loss_s1: 0.502675, loss_fp: 0.500322, loss_freq: 0.500865
[11:55:59.722] iteration 200: loss: 1.084278, loss_s1: 0.504713, loss_fp: 0.500299, loss_freq: 0.500831
[11:56:01.823] iteration 200 : mean_dice : 0.000000
[11:56:02.524] iteration 201: loss: 1.056508, loss_s1: 0.501418, loss_fp: 0.500122, loss_freq: 0.501083
[11:56:03.181] iteration 202: loss: 1.049876, loss_s1: 0.501975, loss_fp: 0.500222, loss_freq: 0.500608
[11:56:03.831] iteration 203: loss: 1.017912, loss_s1: 0.501665, loss_fp: 0.500152, loss_freq: 0.500724
[11:56:04.476] iteration 204: loss: 1.049940, loss_s1: 0.501100, loss_fp: 0.500279, loss_freq: 0.500757
[11:56:05.102] iteration 205: loss: 1.064305, loss_s1: 0.501881, loss_fp: 0.500470, loss_freq: 0.501115
[11:56:05.726] iteration 206: loss: 1.006394, loss_s1: 0.500508, loss_fp: 0.500195, loss_freq: 0.500686
[11:56:06.368] iteration 207: loss: 1.154560, loss_s1: 0.501345, loss_fp: 0.500185, loss_freq: 0.500728
[11:56:07.003] iteration 208: loss: 1.041803, loss_s1: 0.502768, loss_fp: 0.500147, loss_freq: 0.500896
[11:56:07.636] iteration 209: loss: 0.998004, loss_s1: 0.501235, loss_fp: 0.500194, loss_freq: 0.500416
[11:56:08.289] iteration 210: loss: 1.021083, loss_s1: 0.501051, loss_fp: 0.500108, loss_freq: 0.500771
[11:56:08.938] iteration 211: loss: 1.022710, loss_s1: 0.501685, loss_fp: 0.500157, loss_freq: 0.501402
[11:56:09.580] iteration 212: loss: 1.026492, loss_s1: 0.501452, loss_fp: 0.500132, loss_freq: 0.501584
[11:56:10.217] iteration 213: loss: 1.054785, loss_s1: 0.502895, loss_fp: 0.500173, loss_freq: 0.500689
[11:56:10.846] iteration 214: loss: 1.066405, loss_s1: 0.502106, loss_fp: 0.500245, loss_freq: 0.500839
[11:56:11.478] iteration 215: loss: 1.086327, loss_s1: 0.502407, loss_fp: 0.500153, loss_freq: 0.500534
[11:56:12.117] iteration 216: loss: 1.051797, loss_s1: 0.503032, loss_fp: 0.500280, loss_freq: 0.501086
[11:56:12.747] iteration 217: loss: 1.127267, loss_s1: 0.505150, loss_fp: 0.500249, loss_freq: 0.502467
[11:56:13.384] iteration 218: loss: 1.063219, loss_s1: 0.500768, loss_fp: 0.500161, loss_freq: 0.500510
[11:56:14.022] iteration 219: loss: 1.031839, loss_s1: 0.502045, loss_fp: 0.500197, loss_freq: 0.500597
[11:56:14.663] iteration 220: loss: 1.067100, loss_s1: 0.502708, loss_fp: 0.500367, loss_freq: 0.501177
[11:56:15.306] iteration 221: loss: 1.035005, loss_s1: 0.502885, loss_fp: 0.500226, loss_freq: 0.501476
[11:56:15.935] iteration 222: loss: 1.003224, loss_s1: 0.501449, loss_fp: 0.500136, loss_freq: 0.500430
[11:56:16.574] iteration 223: loss: 1.186411, loss_s1: 0.504324, loss_fp: 0.500174, loss_freq: 0.502133
[11:56:17.211] iteration 224: loss: 0.996981, loss_s1: 0.502274, loss_fp: 0.500137, loss_freq: 0.500491
[11:56:17.846] iteration 225: loss: 1.042892, loss_s1: 0.501440, loss_fp: 0.500252, loss_freq: 0.500628
[11:56:18.478] iteration 226: loss: 1.085476, loss_s1: 0.504590, loss_fp: 0.500310, loss_freq: 0.500725
[11:56:19.114] iteration 227: loss: 1.049081, loss_s1: 0.503733, loss_fp: 0.500241, loss_freq: 0.500711
[11:56:19.759] iteration 228: loss: 1.109948, loss_s1: 0.504254, loss_fp: 0.500166, loss_freq: 0.500745
[11:56:20.404] iteration 229: loss: 1.085880, loss_s1: 0.503422, loss_fp: 0.500261, loss_freq: 0.501907
[11:56:21.025] iteration 230: loss: 1.089915, loss_s1: 0.502391, loss_fp: 0.500156, loss_freq: 0.501430
[11:56:21.650] iteration 231: loss: 1.103996, loss_s1: 0.504512, loss_fp: 0.500273, loss_freq: 0.501639
[11:56:22.271] iteration 232: loss: 1.034191, loss_s1: 0.501317, loss_fp: 0.500099, loss_freq: 0.501052
[11:56:22.908] iteration 233: loss: 1.037027, loss_s1: 0.501354, loss_fp: 0.500021, loss_freq: 0.500976
[11:56:23.536] iteration 234: loss: 1.046731, loss_s1: 0.501110, loss_fp: 0.500168, loss_freq: 0.501294
[11:56:24.165] iteration 235: loss: 1.089719, loss_s1: 0.501868, loss_fp: 0.500167, loss_freq: 0.501331
[11:56:24.808] iteration 236: loss: 1.045184, loss_s1: 0.500542, loss_fp: 0.500298, loss_freq: 0.501017
[11:56:25.448] iteration 237: loss: 1.044638, loss_s1: 0.500437, loss_fp: 0.500163, loss_freq: 0.501049
[11:56:26.094] iteration 238: loss: 1.020296, loss_s1: 0.502785, loss_fp: 0.500316, loss_freq: 0.500432
[11:56:26.718] iteration 239: loss: 1.042594, loss_s1: 0.500499, loss_fp: 0.500092, loss_freq: 0.501172
[11:56:27.345] iteration 240: loss: 1.065437, loss_s1: 0.500742, loss_fp: 0.500220, loss_freq: 0.501175
[11:56:27.970] iteration 241: loss: 1.006732, loss_s1: 0.501480, loss_fp: 0.500240, loss_freq: 0.501577
[11:56:28.592] iteration 242: loss: 1.136981, loss_s1: 0.500372, loss_fp: 0.500265, loss_freq: 0.501306
[11:56:29.217] iteration 243: loss: 1.030701, loss_s1: 0.501074, loss_fp: 0.500154, loss_freq: 0.501328
[11:56:29.839] iteration 244: loss: 0.994717, loss_s1: 0.500971, loss_fp: 0.500401, loss_freq: 0.500505
[11:56:30.488] iteration 245: loss: 0.998595, loss_s1: 0.501393, loss_fp: 0.500219, loss_freq: 0.501165
[11:56:31.115] iteration 246: loss: 1.020772, loss_s1: 0.500703, loss_fp: 0.500252, loss_freq: 0.500303
[11:56:31.747] iteration 247: loss: 1.006241, loss_s1: 0.500832, loss_fp: 0.500256, loss_freq: 0.500912
[11:56:32.382] iteration 248: loss: 1.071442, loss_s1: 0.500835, loss_fp: 0.500339, loss_freq: 0.500992
[11:56:33.007] iteration 249: loss: 1.071141, loss_s1: 0.501594, loss_fp: 0.500339, loss_freq: 0.501506
[11:56:33.630] iteration 250: loss: 1.061638, loss_s1: 0.502472, loss_fp: 0.500283, loss_freq: 0.501276
[11:56:34.252] iteration 251: loss: 1.046223, loss_s1: 0.500815, loss_fp: 0.500169, loss_freq: 0.501592
[11:56:34.872] iteration 252: loss: 1.109254, loss_s1: 0.501357, loss_fp: 0.500250, loss_freq: 0.500896
[11:56:35.508] iteration 253: loss: 1.056744, loss_s1: 0.503241, loss_fp: 0.500227, loss_freq: 0.501770
[11:56:36.131] iteration 254: loss: 1.018108, loss_s1: 0.504871, loss_fp: 0.500186, loss_freq: 0.501636
[11:56:36.771] iteration 255: loss: 1.028940, loss_s1: 0.502189, loss_fp: 0.500185, loss_freq: 0.501414
[11:56:37.408] iteration 256: loss: 1.031352, loss_s1: 0.503038, loss_fp: 0.500322, loss_freq: 0.500931
[11:56:38.059] iteration 257: loss: 0.976895, loss_s1: 0.504620, loss_fp: 0.500673, loss_freq: 0.500701
[11:56:38.678] iteration 258: loss: 1.178969, loss_s1: 0.505130, loss_fp: 0.500521, loss_freq: 0.502663
[11:56:39.297] iteration 259: loss: 0.985207, loss_s1: 0.504244, loss_fp: 0.500847, loss_freq: 0.502639
[11:56:39.916] iteration 260: loss: 1.011193, loss_s1: 0.503906, loss_fp: 0.500604, loss_freq: 0.501858
[11:56:40.562] iteration 261: loss: 1.081827, loss_s1: 0.504568, loss_fp: 0.500380, loss_freq: 0.502114
[11:56:41.211] iteration 262: loss: 1.043370, loss_s1: 0.504503, loss_fp: 0.500266, loss_freq: 0.500935
[11:56:41.840] iteration 263: loss: 1.075490, loss_s1: 0.504692, loss_fp: 0.500196, loss_freq: 0.501733
[11:56:42.478] iteration 264: loss: 1.077424, loss_s1: 0.506081, loss_fp: 0.500456, loss_freq: 0.501381
[11:56:43.105] iteration 265: loss: 1.072448, loss_s1: 0.502542, loss_fp: 0.500513, loss_freq: 0.501377
[11:56:43.753] iteration 266: loss: 1.076403, loss_s1: 0.504470, loss_fp: 0.501010, loss_freq: 0.502397
[11:56:44.387] iteration 267: loss: 1.007331, loss_s1: 0.504647, loss_fp: 0.500525, loss_freq: 0.501489
[11:56:45.011] iteration 268: loss: 1.005707, loss_s1: 0.505146, loss_fp: 0.500256, loss_freq: 0.500466
[11:56:45.644] iteration 269: loss: 1.004003, loss_s1: 0.506253, loss_fp: 0.500250, loss_freq: 0.503129
[11:56:46.289] iteration 270: loss: 1.058534, loss_s1: 0.504054, loss_fp: 0.500266, loss_freq: 0.501374
[11:56:46.924] iteration 271: loss: 1.022307, loss_s1: 0.503044, loss_fp: 0.500252, loss_freq: 0.500851
[11:56:47.564] iteration 272: loss: 1.042988, loss_s1: 0.505554, loss_fp: 0.500833, loss_freq: 0.502322
[11:56:48.191] iteration 273: loss: 1.004066, loss_s1: 0.502963, loss_fp: 0.500240, loss_freq: 0.500946
[11:56:48.832] iteration 274: loss: 1.044043, loss_s1: 0.502723, loss_fp: 0.500307, loss_freq: 0.500707
[11:56:49.490] iteration 275: loss: 1.073833, loss_s1: 0.507202, loss_fp: 0.500221, loss_freq: 0.500858
[11:56:50.127] iteration 276: loss: 0.989224, loss_s1: 0.504904, loss_fp: 0.500197, loss_freq: 0.501373
[11:56:50.755] iteration 277: loss: 1.119780, loss_s1: 0.508150, loss_fp: 0.500201, loss_freq: 0.502539
[11:56:51.388] iteration 278: loss: 1.020211, loss_s1: 0.504025, loss_fp: 0.500462, loss_freq: 0.500900
[11:56:52.018] iteration 279: loss: 0.987320, loss_s1: 0.505818, loss_fp: 0.500924, loss_freq: 0.500937
[11:56:52.671] iteration 280: loss: 1.054782, loss_s1: 0.505707, loss_fp: 0.500514, loss_freq: 0.500686
[11:56:53.303] iteration 281: loss: 1.026319, loss_s1: 0.504141, loss_fp: 0.501498, loss_freq: 0.500414
[11:56:53.923] iteration 282: loss: 0.985042, loss_s1: 0.504113, loss_fp: 0.500696, loss_freq: 0.500798
[11:56:54.558] iteration 283: loss: 1.037307, loss_s1: 0.505266, loss_fp: 0.500469, loss_freq: 0.500689
[11:56:55.191] iteration 284: loss: 1.090559, loss_s1: 0.502500, loss_fp: 0.500581, loss_freq: 0.501112
[11:56:55.821] iteration 285: loss: 1.041704, loss_s1: 0.503591, loss_fp: 0.500196, loss_freq: 0.500791
[11:56:56.439] iteration 286: loss: 1.044958, loss_s1: 0.502178, loss_fp: 0.500108, loss_freq: 0.500775
[11:56:57.429] iteration 287: loss: 1.090470, loss_s1: 0.502353, loss_fp: 0.500109, loss_freq: 0.500777
[11:56:58.065] iteration 288: loss: 1.032787, loss_s1: 0.502549, loss_fp: 0.500154, loss_freq: 0.500379
[11:56:58.690] iteration 289: loss: 1.040080, loss_s1: 0.503029, loss_fp: 0.500322, loss_freq: 0.501777
[11:56:59.324] iteration 290: loss: 1.088000, loss_s1: 0.505552, loss_fp: 0.500195, loss_freq: 0.500621
[11:56:59.953] iteration 291: loss: 1.062805, loss_s1: 0.503185, loss_fp: 0.500115, loss_freq: 0.500763
[11:57:00.598] iteration 292: loss: 1.013770, loss_s1: 0.504571, loss_fp: 0.500282, loss_freq: 0.501402
[11:57:01.231] iteration 293: loss: 1.038247, loss_s1: 0.500588, loss_fp: 0.500260, loss_freq: 0.501052
[11:57:01.863] iteration 294: loss: 1.032930, loss_s1: 0.501892, loss_fp: 0.500165, loss_freq: 0.500267
[11:57:02.488] iteration 295: loss: 0.980402, loss_s1: 0.503776, loss_fp: 0.500280, loss_freq: 0.500695
[11:57:03.114] iteration 296: loss: 1.154154, loss_s1: 0.504367, loss_fp: 0.500360, loss_freq: 0.501542
[11:57:03.745] iteration 297: loss: 0.991059, loss_s1: 0.502719, loss_fp: 0.500502, loss_freq: 0.501104
[11:57:04.376] iteration 298: loss: 0.980334, loss_s1: 0.502316, loss_fp: 0.500147, loss_freq: 0.501368
[11:57:05.005] iteration 299: loss: 1.083949, loss_s1: 0.502341, loss_fp: 0.500500, loss_freq: 0.501553
[11:57:05.696] iteration 300: loss: 1.049776, loss_s1: 0.500613, loss_fp: 0.500211, loss_freq: 0.500456
[11:57:06.363] iteration 301: loss: 1.085755, loss_s1: 0.502828, loss_fp: 0.500512, loss_freq: 0.500746
[11:57:07.026] iteration 302: loss: 1.068820, loss_s1: 0.502510, loss_fp: 0.500187, loss_freq: 0.501455
[11:57:07.694] iteration 303: loss: 1.099314, loss_s1: 0.501752, loss_fp: 0.500416, loss_freq: 0.500659
[11:57:08.329] iteration 304: loss: 1.111043, loss_s1: 0.501301, loss_fp: 0.500337, loss_freq: 0.502035
[11:57:08.952] iteration 305: loss: 1.034341, loss_s1: 0.505432, loss_fp: 0.500381, loss_freq: 0.500794
[11:57:09.580] iteration 306: loss: 1.017502, loss_s1: 0.502989, loss_fp: 0.500099, loss_freq: 0.500457
[11:57:10.230] iteration 307: loss: 1.005482, loss_s1: 0.501984, loss_fp: 0.500444, loss_freq: 0.500679
[11:57:10.857] iteration 308: loss: 1.075700, loss_s1: 0.504110, loss_fp: 0.500645, loss_freq: 0.501243
[11:57:11.483] iteration 309: loss: 1.020223, loss_s1: 0.504021, loss_fp: 0.500326, loss_freq: 0.500581
[11:57:12.115] iteration 310: loss: 1.044571, loss_s1: 0.500839, loss_fp: 0.500354, loss_freq: 0.500620
[11:57:12.750] iteration 311: loss: 1.001607, loss_s1: 0.502390, loss_fp: 0.500110, loss_freq: 0.500534
[11:57:13.379] iteration 312: loss: 1.037638, loss_s1: 0.501000, loss_fp: 0.500069, loss_freq: 0.500343
[11:57:14.002] iteration 313: loss: 1.050128, loss_s1: 0.501303, loss_fp: 0.500145, loss_freq: 0.501024
[11:57:14.623] iteration 314: loss: 0.969853, loss_s1: 0.502016, loss_fp: 0.500668, loss_freq: 0.500459
[11:57:15.247] iteration 315: loss: 1.116048, loss_s1: 0.501546, loss_fp: 0.500198, loss_freq: 0.500601
[11:57:15.881] iteration 316: loss: 1.025707, loss_s1: 0.501729, loss_fp: 0.500352, loss_freq: 0.500329
[11:57:16.514] iteration 317: loss: 0.988540, loss_s1: 0.501985, loss_fp: 0.500201, loss_freq: 0.500572
[11:57:17.152] iteration 318: loss: 1.012467, loss_s1: 0.502741, loss_fp: 0.500314, loss_freq: 0.500948
[11:57:17.790] iteration 319: loss: 1.017636, loss_s1: 0.503973, loss_fp: 0.500313, loss_freq: 0.500576
[11:57:18.422] iteration 320: loss: 0.991035, loss_s1: 0.507007, loss_fp: 0.500375, loss_freq: 0.500715
[11:57:19.046] iteration 321: loss: 1.052539, loss_s1: 0.502776, loss_fp: 0.500224, loss_freq: 0.500683
[11:57:19.677] iteration 322: loss: 1.057553, loss_s1: 0.504649, loss_fp: 0.500206, loss_freq: 0.501289
[11:57:20.301] iteration 323: loss: 1.036739, loss_s1: 0.502833, loss_fp: 0.500129, loss_freq: 0.501043
[11:57:20.927] iteration 324: loss: 1.010756, loss_s1: 0.502314, loss_fp: 0.500354, loss_freq: 0.500943
[11:57:21.548] iteration 325: loss: 1.067651, loss_s1: 0.502355, loss_fp: 0.500503, loss_freq: 0.501363
[11:57:22.172] iteration 326: loss: 1.036484, loss_s1: 0.503007, loss_fp: 0.500230, loss_freq: 0.501517
[11:57:22.810] iteration 327: loss: 1.000112, loss_s1: 0.505990, loss_fp: 0.500343, loss_freq: 0.502893
[11:57:23.441] iteration 328: loss: 0.986357, loss_s1: 0.502973, loss_fp: 0.500540, loss_freq: 0.502320
[11:57:24.084] iteration 329: loss: 1.001750, loss_s1: 0.502311, loss_fp: 0.501095, loss_freq: 0.502134
[11:57:24.715] iteration 330: loss: 0.961129, loss_s1: 0.505925, loss_fp: 0.501774, loss_freq: 0.503076
[11:57:25.336] iteration 331: loss: 1.147634, loss_s1: 0.504574, loss_fp: 0.500499, loss_freq: 0.503466
[11:57:25.980] iteration 332: loss: 1.003016, loss_s1: 0.502101, loss_fp: 0.502552, loss_freq: 0.501699
[11:57:26.637] iteration 333: loss: 1.042201, loss_s1: 0.501675, loss_fp: 0.501233, loss_freq: 0.502423
[11:57:27.289] iteration 334: loss: 1.064534, loss_s1: 0.505066, loss_fp: 0.500848, loss_freq: 0.501414
[11:57:27.927] iteration 335: loss: 1.033278, loss_s1: 0.501641, loss_fp: 0.500480, loss_freq: 0.501136
[11:57:28.666] iteration 336: loss: 1.062434, loss_s1: 0.504343, loss_fp: 0.500394, loss_freq: 0.500887
[11:57:29.321] iteration 337: loss: 1.089716, loss_s1: 0.504966, loss_fp: 0.500172, loss_freq: 0.501499
[11:57:29.967] iteration 338: loss: 1.079769, loss_s1: 0.502862, loss_fp: 0.500152, loss_freq: 0.501162
[11:57:30.605] iteration 339: loss: 1.051268, loss_s1: 0.503693, loss_fp: 0.500831, loss_freq: 0.501732
[11:57:31.233] iteration 340: loss: 1.043047, loss_s1: 0.505019, loss_fp: 0.500354, loss_freq: 0.500746
[11:57:31.866] iteration 341: loss: 1.002549, loss_s1: 0.503591, loss_fp: 0.500593, loss_freq: 0.501599
[11:57:32.492] iteration 342: loss: 1.025344, loss_s1: 0.504691, loss_fp: 0.500112, loss_freq: 0.500832
[11:57:33.128] iteration 343: loss: 1.068098, loss_s1: 0.507451, loss_fp: 0.500931, loss_freq: 0.501570
[11:57:33.757] iteration 344: loss: 1.048221, loss_s1: 0.506021, loss_fp: 0.500329, loss_freq: 0.501629
[11:57:34.382] iteration 345: loss: 1.031399, loss_s1: 0.501412, loss_fp: 0.500160, loss_freq: 0.500507
[11:57:35.008] iteration 346: loss: 0.998174, loss_s1: 0.502492, loss_fp: 0.500355, loss_freq: 0.501421
[11:57:35.644] iteration 347: loss: 1.019202, loss_s1: 0.501918, loss_fp: 0.500261, loss_freq: 0.500705
[11:57:36.269] iteration 348: loss: 1.030511, loss_s1: 0.504096, loss_fp: 0.500430, loss_freq: 0.500998
[11:57:36.911] iteration 349: loss: 0.987825, loss_s1: 0.502783, loss_fp: 0.500636, loss_freq: 0.500773
[11:57:37.539] iteration 350: loss: 1.128433, loss_s1: 0.501635, loss_fp: 0.500300, loss_freq: 0.500864
[11:57:38.170] iteration 351: loss: 1.011613, loss_s1: 0.503907, loss_fp: 0.500608, loss_freq: 0.502867
[11:57:38.793] iteration 352: loss: 0.979998, loss_s1: 0.503919, loss_fp: 0.500529, loss_freq: 0.501874
[11:57:39.430] iteration 353: loss: 1.022791, loss_s1: 0.504534, loss_fp: 0.500366, loss_freq: 0.501620
[11:57:40.059] iteration 354: loss: 1.002896, loss_s1: 0.504023, loss_fp: 0.500338, loss_freq: 0.501233
[11:57:40.683] iteration 355: loss: 1.007390, loss_s1: 0.504441, loss_fp: 0.500717, loss_freq: 0.502568
[11:57:41.310] iteration 356: loss: 1.046332, loss_s1: 0.503540, loss_fp: 0.500812, loss_freq: 0.502156
[11:57:41.946] iteration 357: loss: 1.081691, loss_s1: 0.503903, loss_fp: 0.500317, loss_freq: 0.503515
[11:57:42.594] iteration 358: loss: 1.045294, loss_s1: 0.502627, loss_fp: 0.500248, loss_freq: 0.500771
[11:57:43.217] iteration 359: loss: 1.043638, loss_s1: 0.504989, loss_fp: 0.500488, loss_freq: 0.503486
[11:57:43.855] iteration 360: loss: 1.101294, loss_s1: 0.506650, loss_fp: 0.500179, loss_freq: 0.502861
[11:57:44.482] iteration 361: loss: 1.067488, loss_s1: 0.504102, loss_fp: 0.500224, loss_freq: 0.500902
[11:57:45.119] iteration 362: loss: 1.007736, loss_s1: 0.504755, loss_fp: 0.500138, loss_freq: 0.500802
[11:57:45.753] iteration 363: loss: 1.026587, loss_s1: 0.504345, loss_fp: 0.500373, loss_freq: 0.502043
[11:57:46.388] iteration 364: loss: 1.019282, loss_s1: 0.505760, loss_fp: 0.500237, loss_freq: 0.502614
[11:57:47.015] iteration 365: loss: 0.954633, loss_s1: 0.506328, loss_fp: 0.500389, loss_freq: 0.501011
[11:57:47.652] iteration 366: loss: 1.186679, loss_s1: 0.504710, loss_fp: 0.500430, loss_freq: 0.502638
[11:57:48.293] iteration 367: loss: 0.986608, loss_s1: 0.502480, loss_fp: 0.500629, loss_freq: 0.500939
[11:57:48.927] iteration 368: loss: 1.009488, loss_s1: 0.504036, loss_fp: 0.500307, loss_freq: 0.501810
[11:57:49.560] iteration 369: loss: 1.071897, loss_s1: 0.504980, loss_fp: 0.500364, loss_freq: 0.500937
[11:57:50.184] iteration 370: loss: 1.022325, loss_s1: 0.502108, loss_fp: 0.500558, loss_freq: 0.500595
[11:57:50.814] iteration 371: loss: 1.054504, loss_s1: 0.502779, loss_fp: 0.500452, loss_freq: 0.500920
[11:57:51.441] iteration 372: loss: 1.066412, loss_s1: 0.503748, loss_fp: 0.500193, loss_freq: 0.501467
[11:57:52.065] iteration 373: loss: 1.102692, loss_s1: 0.505777, loss_fp: 0.500170, loss_freq: 0.501796
[11:57:52.688] iteration 374: loss: 1.101625, loss_s1: 0.503088, loss_fp: 0.500319, loss_freq: 0.501916
[11:57:53.326] iteration 375: loss: 1.001746, loss_s1: 0.506419, loss_fp: 0.500489, loss_freq: 0.501522
[11:57:53.979] iteration 376: loss: 1.002208, loss_s1: 0.505561, loss_fp: 0.500276, loss_freq: 0.501307
[11:57:54.626] iteration 377: loss: 1.004246, loss_s1: 0.504080, loss_fp: 0.500379, loss_freq: 0.501107
[11:57:55.418] iteration 378: loss: 1.048938, loss_s1: 0.503862, loss_fp: 0.500353, loss_freq: 0.502215
[11:57:56.159] iteration 379: loss: 1.000510, loss_s1: 0.502016, loss_fp: 0.500167, loss_freq: 0.500622
[11:57:56.797] iteration 380: loss: 1.014272, loss_s1: 0.503752, loss_fp: 0.500247, loss_freq: 0.500635
[11:57:57.455] iteration 381: loss: 0.998060, loss_s1: 0.502602, loss_fp: 0.500561, loss_freq: 0.500272
[11:57:58.093] iteration 382: loss: 1.022038, loss_s1: 0.501404, loss_fp: 0.500395, loss_freq: 0.500551
[11:57:58.725] iteration 383: loss: 1.041525, loss_s1: 0.503514, loss_fp: 0.500203, loss_freq: 0.501110
[11:57:59.355] iteration 384: loss: 0.975867, loss_s1: 0.503369, loss_fp: 0.500368, loss_freq: 0.501748
[11:58:00.036] iteration 385: loss: 1.129096, loss_s1: 0.502371, loss_fp: 0.500241, loss_freq: 0.501383
[11:58:00.723] iteration 386: loss: 1.013344, loss_s1: 0.501987, loss_fp: 0.501093, loss_freq: 0.501155
[11:58:01.357] iteration 387: loss: 0.995229, loss_s1: 0.502052, loss_fp: 0.500196, loss_freq: 0.500760
[11:58:02.006] iteration 388: loss: 0.998312, loss_s1: 0.502306, loss_fp: 0.500506, loss_freq: 0.501132
[11:58:02.632] iteration 389: loss: 1.006634, loss_s1: 0.501529, loss_fp: 0.500248, loss_freq: 0.500378
[11:58:03.263] iteration 390: loss: 0.992689, loss_s1: 0.504514, loss_fp: 0.500186, loss_freq: 0.500854
[11:58:03.906] iteration 391: loss: 1.040730, loss_s1: 0.502765, loss_fp: 0.500172, loss_freq: 0.500698
[11:58:04.542] iteration 392: loss: 1.056615, loss_s1: 0.503103, loss_fp: 0.500417, loss_freq: 0.501797
[11:58:05.195] iteration 393: loss: 1.043813, loss_s1: 0.503061, loss_fp: 0.500133, loss_freq: 0.501563
[11:58:05.831] iteration 394: loss: 1.003785, loss_s1: 0.503706, loss_fp: 0.500321, loss_freq: 0.501804
[11:58:06.474] iteration 395: loss: 1.082290, loss_s1: 0.504877, loss_fp: 0.500285, loss_freq: 0.501049
[11:58:07.101] iteration 396: loss: 1.026465, loss_s1: 0.503271, loss_fp: 0.500198, loss_freq: 0.501948
[11:58:07.740] iteration 397: loss: 0.991130, loss_s1: 0.501825, loss_fp: 0.500514, loss_freq: 0.502061
[11:58:08.369] iteration 398: loss: 0.977866, loss_s1: 0.503649, loss_fp: 0.500454, loss_freq: 0.502107
[11:58:09.000] iteration 399: loss: 0.991425, loss_s1: 0.502090, loss_fp: 0.500202, loss_freq: 0.500609
[11:58:09.630] iteration 400: loss: 0.949541, loss_s1: 0.502147, loss_fp: 0.500146, loss_freq: 0.500628
[11:58:11.919] iteration 400 : mean_dice : 0.024305
[11:58:12.584] iteration 401: loss: 1.143595, loss_s1: 0.502198, loss_fp: 0.500434, loss_freq: 0.502648
[11:58:13.244] iteration 402: loss: 0.977774, loss_s1: 0.504611, loss_fp: 0.501018, loss_freq: 0.502120
[11:58:13.879] iteration 403: loss: 0.974661, loss_s1: 0.504368, loss_fp: 0.500400, loss_freq: 0.501659
[11:58:14.520] iteration 404: loss: 1.080705, loss_s1: 0.506769, loss_fp: 0.500413, loss_freq: 0.502562
[11:58:15.190] iteration 405: loss: 1.017284, loss_s1: 0.503593, loss_fp: 0.500209, loss_freq: 0.501402
[11:58:15.865] iteration 406: loss: 1.057575, loss_s1: 0.503906, loss_fp: 0.500347, loss_freq: 0.501274
[11:58:16.527] iteration 407: loss: 1.038637, loss_s1: 0.507801, loss_fp: 0.500262, loss_freq: 0.501568
[11:58:17.207] iteration 408: loss: 1.060718, loss_s1: 0.504920, loss_fp: 0.500229, loss_freq: 0.502066
[11:58:17.877] iteration 409: loss: 1.112757, loss_s1: 0.501961, loss_fp: 0.500249, loss_freq: 0.501995
[11:58:18.504] iteration 410: loss: 1.022664, loss_s1: 0.504337, loss_fp: 0.500727, loss_freq: 0.501448
[11:58:19.150] iteration 411: loss: 1.000552, loss_s1: 0.503563, loss_fp: 0.500224, loss_freq: 0.500611
[11:58:19.779] iteration 412: loss: 0.995868, loss_s1: 0.505979, loss_fp: 0.500460, loss_freq: 0.502858
[11:58:20.426] iteration 413: loss: 1.062860, loss_s1: 0.505094, loss_fp: 0.500260, loss_freq: 0.501463
[11:58:21.095] iteration 414: loss: 0.986983, loss_s1: 0.504635, loss_fp: 0.500364, loss_freq: 0.501015
[11:58:21.777] iteration 415: loss: 1.026631, loss_s1: 0.501776, loss_fp: 0.500294, loss_freq: 0.501358
[11:58:22.436] iteration 416: loss: 0.993059, loss_s1: 0.504503, loss_fp: 0.500763, loss_freq: 0.501319
[11:58:23.074] iteration 417: loss: 1.020332, loss_s1: 0.502342, loss_fp: 0.500255, loss_freq: 0.500647
[11:58:23.749] iteration 418: loss: 1.049945, loss_s1: 0.504605, loss_fp: 0.500203, loss_freq: 0.500853
[11:58:24.414] iteration 419: loss: 0.976540, loss_s1: 0.502684, loss_fp: 0.500557, loss_freq: 0.501065
[11:58:25.087] iteration 420: loss: 1.096359, loss_s1: 0.507278, loss_fp: 0.500584, loss_freq: 0.502392
[11:58:25.749] iteration 421: loss: 1.002260, loss_s1: 0.504335, loss_fp: 0.500398, loss_freq: 0.501203
[11:58:26.439] iteration 422: loss: 0.988841, loss_s1: 0.504328, loss_fp: 0.500536, loss_freq: 0.501396
[11:58:27.113] iteration 423: loss: 1.032819, loss_s1: 0.503850, loss_fp: 0.500151, loss_freq: 0.500520
[11:58:27.793] iteration 424: loss: 1.002906, loss_s1: 0.502144, loss_fp: 0.500281, loss_freq: 0.501021
[11:58:28.470] iteration 425: loss: 0.977200, loss_s1: 0.505152, loss_fp: 0.500337, loss_freq: 0.500799
[11:58:29.099] iteration 426: loss: 1.030252, loss_s1: 0.506668, loss_fp: 0.500341, loss_freq: 0.500939
[11:58:29.737] iteration 427: loss: 1.041150, loss_s1: 0.504252, loss_fp: 0.500788, loss_freq: 0.500917
[11:58:30.372] iteration 428: loss: 1.011833, loss_s1: 0.504227, loss_fp: 0.500459, loss_freq: 0.500903
[11:58:31.005] iteration 429: loss: 1.007838, loss_s1: 0.501930, loss_fp: 0.500259, loss_freq: 0.500860
[11:58:31.969] iteration 430: loss: 1.036155, loss_s1: 0.504217, loss_fp: 0.500515, loss_freq: 0.501405
[11:58:32.637] iteration 431: loss: 1.005341, loss_s1: 0.502529, loss_fp: 0.500849, loss_freq: 0.500665
[11:58:33.279] iteration 432: loss: 1.005629, loss_s1: 0.502559, loss_fp: 0.500197, loss_freq: 0.501922
[11:58:33.926] iteration 433: loss: 1.048766, loss_s1: 0.502459, loss_fp: 0.500599, loss_freq: 0.500561
[11:58:34.572] iteration 434: loss: 1.011491, loss_s1: 0.505036, loss_fp: 0.500294, loss_freq: 0.501462
[11:58:35.234] iteration 435: loss: 0.994206, loss_s1: 0.504750, loss_fp: 0.500431, loss_freq: 0.501015
[11:58:35.900] iteration 436: loss: 0.990052, loss_s1: 0.503456, loss_fp: 0.500371, loss_freq: 0.501358
[11:58:36.579] iteration 437: loss: 1.020691, loss_s1: 0.502623, loss_fp: 0.500470, loss_freq: 0.501568
[11:58:37.273] iteration 438: loss: 0.957308, loss_s1: 0.502953, loss_fp: 0.500271, loss_freq: 0.501424
[11:58:37.910] iteration 439: loss: 1.124024, loss_s1: 0.503394, loss_fp: 0.500577, loss_freq: 0.502009
[11:58:38.555] iteration 440: loss: 0.970967, loss_s1: 0.503302, loss_fp: 0.500323, loss_freq: 0.501539
[11:58:39.190] iteration 441: loss: 0.951998, loss_s1: 0.503422, loss_fp: 0.500759, loss_freq: 0.501935
[11:58:39.849] iteration 442: loss: 1.051510, loss_s1: 0.503204, loss_fp: 0.500182, loss_freq: 0.502266
[11:58:40.485] iteration 443: loss: 0.998238, loss_s1: 0.502367, loss_fp: 0.500392, loss_freq: 0.500814
[11:58:41.116] iteration 444: loss: 1.043395, loss_s1: 0.504031, loss_fp: 0.500435, loss_freq: 0.500801
[11:58:41.747] iteration 445: loss: 1.055287, loss_s1: 0.502542, loss_fp: 0.500648, loss_freq: 0.501058
[11:58:42.371] iteration 446: loss: 1.097050, loss_s1: 0.504253, loss_fp: 0.500244, loss_freq: 0.500887
[11:58:42.998] iteration 447: loss: 1.036605, loss_s1: 0.504929, loss_fp: 0.500408, loss_freq: 0.502717
[11:58:43.623] iteration 448: loss: 0.993800, loss_s1: 0.505219, loss_fp: 0.500252, loss_freq: 0.501291
[11:58:44.242] iteration 449: loss: 0.972990, loss_s1: 0.501461, loss_fp: 0.500319, loss_freq: 0.501318
[11:58:44.869] iteration 450: loss: 0.988510, loss_s1: 0.502239, loss_fp: 0.500301, loss_freq: 0.500690
[11:58:45.523] iteration 451: loss: 1.002462, loss_s1: 0.503053, loss_fp: 0.500222, loss_freq: 0.501637
[11:58:46.162] iteration 452: loss: 0.989200, loss_s1: 0.504075, loss_fp: 0.500999, loss_freq: 0.501464
[11:58:46.807] iteration 453: loss: 0.980122, loss_s1: 0.501133, loss_fp: 0.500166, loss_freq: 0.500442
[11:58:47.447] iteration 454: loss: 0.982913, loss_s1: 0.504605, loss_fp: 0.500568, loss_freq: 0.500968
[11:58:48.084] iteration 455: loss: 1.003400, loss_s1: 0.502665, loss_fp: 0.500692, loss_freq: 0.500764
[11:58:48.716] iteration 456: loss: 1.056427, loss_s1: 0.502660, loss_fp: 0.500673, loss_freq: 0.501814
[11:58:49.339] iteration 457: loss: 0.959732, loss_s1: 0.503636, loss_fp: 0.500328, loss_freq: 0.501567
[11:58:50.002] iteration 458: loss: 1.096062, loss_s1: 0.505291, loss_fp: 0.500337, loss_freq: 0.503621
[11:58:50.651] iteration 459: loss: 1.002745, loss_s1: 0.501836, loss_fp: 0.501004, loss_freq: 0.501713
[11:58:51.309] iteration 460: loss: 0.999720, loss_s1: 0.504238, loss_fp: 0.500652, loss_freq: 0.502246
[11:58:51.958] iteration 461: loss: 0.995590, loss_s1: 0.503906, loss_fp: 0.500385, loss_freq: 0.501304
[11:58:52.602] iteration 462: loss: 0.986863, loss_s1: 0.502297, loss_fp: 0.500740, loss_freq: 0.500757
[11:58:53.246] iteration 463: loss: 0.944313, loss_s1: 0.503441, loss_fp: 0.501307, loss_freq: 0.501985
[11:58:53.893] iteration 464: loss: 1.027798, loss_s1: 0.505981, loss_fp: 0.500115, loss_freq: 0.502491
[11:58:54.543] iteration 465: loss: 1.095358, loss_s1: 0.504938, loss_fp: 0.500312, loss_freq: 0.505507
[11:58:55.203] iteration 466: loss: 1.004021, loss_s1: 0.504561, loss_fp: 0.500278, loss_freq: 0.502095
[11:58:55.868] iteration 467: loss: 1.011780, loss_s1: 0.503053, loss_fp: 0.500530, loss_freq: 0.501702
[11:58:56.513] iteration 468: loss: 1.072403, loss_s1: 0.507397, loss_fp: 0.500761, loss_freq: 0.502171
[11:58:57.147] iteration 469: loss: 1.035235, loss_s1: 0.507736, loss_fp: 0.500318, loss_freq: 0.502824
[11:58:57.785] iteration 470: loss: 1.005054, loss_s1: 0.506020, loss_fp: 0.500275, loss_freq: 0.504168
[11:58:58.427] iteration 471: loss: 1.022518, loss_s1: 0.506551, loss_fp: 0.500428, loss_freq: 0.502856
[11:58:59.075] iteration 472: loss: 1.013427, loss_s1: 0.504558, loss_fp: 0.500152, loss_freq: 0.503359
[11:58:59.695] iteration 473: loss: 0.938089, loss_s1: 0.504042, loss_fp: 0.500197, loss_freq: 0.503461
[11:59:00.312] iteration 474: loss: 1.148607, loss_s1: 0.505420, loss_fp: 0.500411, loss_freq: 0.504916
[11:59:00.924] iteration 475: loss: 0.971121, loss_s1: 0.507606, loss_fp: 0.500308, loss_freq: 0.502303
[11:59:01.545] iteration 476: loss: 0.973930, loss_s1: 0.502304, loss_fp: 0.500511, loss_freq: 0.502538
[11:59:02.178] iteration 477: loss: 1.022696, loss_s1: 0.501300, loss_fp: 0.500734, loss_freq: 0.501089
[11:59:02.805] iteration 478: loss: 1.013160, loss_s1: 0.501020, loss_fp: 0.500344, loss_freq: 0.501138
[11:59:03.429] iteration 479: loss: 1.043666, loss_s1: 0.505190, loss_fp: 0.500404, loss_freq: 0.501530
[11:59:04.049] iteration 480: loss: 1.062937, loss_s1: 0.506272, loss_fp: 0.500155, loss_freq: 0.501382
[11:59:04.680] iteration 481: loss: 1.061820, loss_s1: 0.503115, loss_fp: 0.500203, loss_freq: 0.501568
[11:59:05.307] iteration 482: loss: 1.054419, loss_s1: 0.505014, loss_fp: 0.500232, loss_freq: 0.502107
[11:59:05.943] iteration 483: loss: 0.963679, loss_s1: 0.502227, loss_fp: 0.500165, loss_freq: 0.501058
[11:59:06.571] iteration 484: loss: 0.999003, loss_s1: 0.502994, loss_fp: 0.500268, loss_freq: 0.501968
[11:59:07.204] iteration 485: loss: 0.996371, loss_s1: 0.506030, loss_fp: 0.500351, loss_freq: 0.501192
[11:59:07.836] iteration 486: loss: 1.060056, loss_s1: 0.504584, loss_fp: 0.500318, loss_freq: 0.501762
[11:59:08.484] iteration 487: loss: 0.999087, loss_s1: 0.503055, loss_fp: 0.500221, loss_freq: 0.501891
[11:59:09.108] iteration 488: loss: 0.996795, loss_s1: 0.504604, loss_fp: 0.500347, loss_freq: 0.500615
[11:59:09.741] iteration 489: loss: 0.981283, loss_s1: 0.502158, loss_fp: 0.500263, loss_freq: 0.500898
[11:59:10.369] iteration 490: loss: 1.008015, loss_s1: 0.502266, loss_fp: 0.500224, loss_freq: 0.500937
[11:59:11.000] iteration 491: loss: 1.040538, loss_s1: 0.507036, loss_fp: 0.500183, loss_freq: 0.502045
[11:59:11.635] iteration 492: loss: 0.976201, loss_s1: 0.505296, loss_fp: 0.500318, loss_freq: 0.501184
[11:59:12.271] iteration 493: loss: 1.129631, loss_s1: 0.501760, loss_fp: 0.500289, loss_freq: 0.500917
[11:59:12.902] iteration 494: loss: 1.003883, loss_s1: 0.501775, loss_fp: 0.500468, loss_freq: 0.501110
[11:59:13.526] iteration 495: loss: 0.984961, loss_s1: 0.507735, loss_fp: 0.501152, loss_freq: 0.501218
[11:59:14.146] iteration 496: loss: 0.999554, loss_s1: 0.502087, loss_fp: 0.500265, loss_freq: 0.501248
[11:59:14.793] iteration 497: loss: 0.992256, loss_s1: 0.504351, loss_fp: 0.500486, loss_freq: 0.500694
[11:59:15.431] iteration 498: loss: 0.990042, loss_s1: 0.502669, loss_fp: 0.500470, loss_freq: 0.501399
[11:59:16.053] iteration 499: loss: 1.010785, loss_s1: 0.502600, loss_fp: 0.500328, loss_freq: 0.500692
[11:59:16.682] iteration 500: loss: 1.040365, loss_s1: 0.502569, loss_fp: 0.500366, loss_freq: 0.501716
[11:59:17.309] iteration 501: loss: 1.025905, loss_s1: 0.501527, loss_fp: 0.500196, loss_freq: 0.500432
[11:59:17.955] iteration 502: loss: 0.975379, loss_s1: 0.503655, loss_fp: 0.500189, loss_freq: 0.501522
[11:59:18.606] iteration 503: loss: 1.070746, loss_s1: 0.503268, loss_fp: 0.500365, loss_freq: 0.503106
[11:59:19.237] iteration 504: loss: 1.006088, loss_s1: 0.504169, loss_fp: 0.500253, loss_freq: 0.501001
[11:59:19.871] iteration 505: loss: 0.996047, loss_s1: 0.502504, loss_fp: 0.500152, loss_freq: 0.500821
[11:59:20.514] iteration 506: loss: 1.011545, loss_s1: 0.501461, loss_fp: 0.500576, loss_freq: 0.502108
[11:59:21.150] iteration 507: loss: 0.998212, loss_s1: 0.501808, loss_fp: 0.500386, loss_freq: 0.502140
[11:59:21.779] iteration 508: loss: 0.937905, loss_s1: 0.503099, loss_fp: 0.500211, loss_freq: 0.501060
[11:59:22.412] iteration 509: loss: 1.141287, loss_s1: 0.501596, loss_fp: 0.500378, loss_freq: 0.502059
[11:59:23.056] iteration 510: loss: 0.949413, loss_s1: 0.500832, loss_fp: 0.500709, loss_freq: 0.501141
[11:59:23.694] iteration 511: loss: 0.989323, loss_s1: 0.502309, loss_fp: 0.500292, loss_freq: 0.502062
[11:59:24.333] iteration 512: loss: 1.045784, loss_s1: 0.500808, loss_fp: 0.500333, loss_freq: 0.500691
[11:59:24.972] iteration 513: loss: 0.992712, loss_s1: 0.502858, loss_fp: 0.500261, loss_freq: 0.500648
[11:59:25.604] iteration 514: loss: 1.009362, loss_s1: 0.503355, loss_fp: 0.500423, loss_freq: 0.501406
[11:59:26.245] iteration 515: loss: 1.028023, loss_s1: 0.504583, loss_fp: 0.500274, loss_freq: 0.501149
[11:59:26.888] iteration 516: loss: 1.079558, loss_s1: 0.503513, loss_fp: 0.500360, loss_freq: 0.501470
[11:59:27.539] iteration 517: loss: 1.064033, loss_s1: 0.504966, loss_fp: 0.500355, loss_freq: 0.503157
[11:59:28.213] iteration 518: loss: 1.015766, loss_s1: 0.506724, loss_fp: 0.500473, loss_freq: 0.501831
[11:59:28.889] iteration 519: loss: 0.962049, loss_s1: 0.504700, loss_fp: 0.500485, loss_freq: 0.501378
[11:59:29.553] iteration 520: loss: 0.987529, loss_s1: 0.503047, loss_fp: 0.500220, loss_freq: 0.501747
[11:59:30.252] iteration 521: loss: 1.041145, loss_s1: 0.508296, loss_fp: 0.500261, loss_freq: 0.503332
[11:59:30.917] iteration 522: loss: 0.985803, loss_s1: 0.505140, loss_fp: 0.500250, loss_freq: 0.500793
[11:59:31.585] iteration 523: loss: 1.019699, loss_s1: 0.504695, loss_fp: 0.500282, loss_freq: 0.501103
[11:59:32.249] iteration 524: loss: 0.966419, loss_s1: 0.504410, loss_fp: 0.500236, loss_freq: 0.500372
[11:59:32.915] iteration 525: loss: 1.021439, loss_s1: 0.505446, loss_fp: 0.500202, loss_freq: 0.500890
[11:59:33.556] iteration 526: loss: 1.010420, loss_s1: 0.505284, loss_fp: 0.500430, loss_freq: 0.501469
[11:59:34.181] iteration 527: loss: 0.963990, loss_s1: 0.501308, loss_fp: 0.500336, loss_freq: 0.501453
[11:59:34.808] iteration 528: loss: 1.125127, loss_s1: 0.501770, loss_fp: 0.500409, loss_freq: 0.501450
[11:59:35.440] iteration 529: loss: 1.025012, loss_s1: 0.504074, loss_fp: 0.500332, loss_freq: 0.501354
[11:59:36.080] iteration 530: loss: 0.975999, loss_s1: 0.507596, loss_fp: 0.500179, loss_freq: 0.501722
[11:59:36.715] iteration 531: loss: 0.986253, loss_s1: 0.504826, loss_fp: 0.500381, loss_freq: 0.500961
[11:59:37.350] iteration 532: loss: 0.996427, loss_s1: 0.504684, loss_fp: 0.500404, loss_freq: 0.500663
[11:59:37.970] iteration 533: loss: 0.988725, loss_s1: 0.504151, loss_fp: 0.500192, loss_freq: 0.502089
[11:59:38.591] iteration 534: loss: 1.023802, loss_s1: 0.504213, loss_fp: 0.500226, loss_freq: 0.501310
[11:59:39.211] iteration 535: loss: 1.049947, loss_s1: 0.505351, loss_fp: 0.500544, loss_freq: 0.503235
[11:59:39.832] iteration 536: loss: 0.986626, loss_s1: 0.502990, loss_fp: 0.500226, loss_freq: 0.501969
[11:59:40.451] iteration 537: loss: 0.986274, loss_s1: 0.502962, loss_fp: 0.500284, loss_freq: 0.501364
[11:59:41.066] iteration 538: loss: 1.079017, loss_s1: 0.504092, loss_fp: 0.500213, loss_freq: 0.500663
[11:59:41.684] iteration 539: loss: 0.999879, loss_s1: 0.504389, loss_fp: 0.500265, loss_freq: 0.501759
[11:59:42.303] iteration 540: loss: 0.984442, loss_s1: 0.503569, loss_fp: 0.500473, loss_freq: 0.502301
[11:59:42.935] iteration 541: loss: 0.963104, loss_s1: 0.502247, loss_fp: 0.500265, loss_freq: 0.501994
[11:59:43.569] iteration 542: loss: 0.979614, loss_s1: 0.504060, loss_fp: 0.500329, loss_freq: 0.500965
[11:59:44.208] iteration 543: loss: 0.948320, loss_s1: 0.503742, loss_fp: 0.500307, loss_freq: 0.501275
[11:59:44.847] iteration 544: loss: 1.128529, loss_s1: 0.502415, loss_fp: 0.500464, loss_freq: 0.503824
[11:59:45.473] iteration 545: loss: 0.945518, loss_s1: 0.503433, loss_fp: 0.500140, loss_freq: 0.501919
[11:59:46.083] iteration 546: loss: 0.963662, loss_s1: 0.504521, loss_fp: 0.500270, loss_freq: 0.501602
[11:59:46.698] iteration 547: loss: 1.052302, loss_s1: 0.503862, loss_fp: 0.500202, loss_freq: 0.503212
[11:59:47.353] iteration 548: loss: 1.003986, loss_s1: 0.503917, loss_fp: 0.500382, loss_freq: 0.501104
[11:59:47.963] iteration 549: loss: 1.008213, loss_s1: 0.501999, loss_fp: 0.500510, loss_freq: 0.501329
[11:59:48.575] iteration 550: loss: 1.040977, loss_s1: 0.505079, loss_fp: 0.500193, loss_freq: 0.501371
[11:59:49.191] iteration 551: loss: 1.047753, loss_s1: 0.505408, loss_fp: 0.500258, loss_freq: 0.502797
[11:59:49.828] iteration 552: loss: 1.055345, loss_s1: 0.504344, loss_fp: 0.500205, loss_freq: 0.502627
[11:59:50.441] iteration 553: loss: 0.942356, loss_s1: 0.502181, loss_fp: 0.500240, loss_freq: 0.501126
[11:59:51.051] iteration 554: loss: 0.950546, loss_s1: 0.503898, loss_fp: 0.500221, loss_freq: 0.500771
[11:59:51.692] iteration 555: loss: 0.998720, loss_s1: 0.503112, loss_fp: 0.500923, loss_freq: 0.503414
[11:59:52.305] iteration 556: loss: 1.060629, loss_s1: 0.508687, loss_fp: 0.500481, loss_freq: 0.502313
[11:59:52.935] iteration 557: loss: 0.954894, loss_s1: 0.502415, loss_fp: 0.500731, loss_freq: 0.500682
[11:59:53.543] iteration 558: loss: 0.966665, loss_s1: 0.503986, loss_fp: 0.500174, loss_freq: 0.501314
[11:59:54.159] iteration 559: loss: 0.954341, loss_s1: 0.505481, loss_fp: 0.500460, loss_freq: 0.502725
[11:59:54.801] iteration 560: loss: 1.008354, loss_s1: 0.502158, loss_fp: 0.500501, loss_freq: 0.501733
[11:59:55.428] iteration 561: loss: 1.045704, loss_s1: 0.503500, loss_fp: 0.500240, loss_freq: 0.501227
[11:59:56.039] iteration 562: loss: 0.960637, loss_s1: 0.507628, loss_fp: 0.500358, loss_freq: 0.501417
[11:59:56.655] iteration 563: loss: 1.068610, loss_s1: 0.505166, loss_fp: 0.500456, loss_freq: 0.505224
[11:59:57.286] iteration 564: loss: 1.004854, loss_s1: 0.510431, loss_fp: 0.500963, loss_freq: 0.501217
[11:59:58.138] iteration 565: loss: 0.993844, loss_s1: 0.506505, loss_fp: 0.500343, loss_freq: 0.502476
[11:59:58.861] iteration 566: loss: 1.000025, loss_s1: 0.503287, loss_fp: 0.500803, loss_freq: 0.501421
[11:59:59.517] iteration 567: loss: 0.996364, loss_s1: 0.508788, loss_fp: 0.500236, loss_freq: 0.501761
[12:00:00.152] iteration 568: loss: 0.977445, loss_s1: 0.508406, loss_fp: 0.500508, loss_freq: 0.501310
[12:00:00.759] iteration 569: loss: 1.018074, loss_s1: 0.505883, loss_fp: 0.500175, loss_freq: 0.500767
[12:00:01.370] iteration 570: loss: 1.057472, loss_s1: 0.504331, loss_fp: 0.500225, loss_freq: 0.501189
[12:00:01.983] iteration 571: loss: 1.008502, loss_s1: 0.506221, loss_fp: 0.500241, loss_freq: 0.501697
[12:00:02.635] iteration 572: loss: 0.993917, loss_s1: 0.506406, loss_fp: 0.500250, loss_freq: 0.501996
[12:00:03.572] iteration 573: loss: 1.066994, loss_s1: 0.508104, loss_fp: 0.500510, loss_freq: 0.501838
[12:00:04.188] iteration 574: loss: 0.996248, loss_s1: 0.503181, loss_fp: 0.500145, loss_freq: 0.500467
[12:00:04.852] iteration 575: loss: 0.975585, loss_s1: 0.503662, loss_fp: 0.500650, loss_freq: 0.503731
[12:00:05.520] iteration 576: loss: 1.058651, loss_s1: 0.506594, loss_fp: 0.500403, loss_freq: 0.500814
[12:00:06.172] iteration 577: loss: 1.017636, loss_s1: 0.506119, loss_fp: 0.500316, loss_freq: 0.501297
[12:00:06.819] iteration 578: loss: 0.977568, loss_s1: 0.501737, loss_fp: 0.500340, loss_freq: 0.501627
[12:00:07.505] iteration 579: loss: 0.995457, loss_s1: 0.504448, loss_fp: 0.500744, loss_freq: 0.501365
[12:00:08.161] iteration 580: loss: 1.027084, loss_s1: 0.508540, loss_fp: 0.500466, loss_freq: 0.501320
[12:00:08.779] iteration 581: loss: 0.948323, loss_s1: 0.503236, loss_fp: 0.500288, loss_freq: 0.502109
[12:00:09.399] iteration 582: loss: 1.114546, loss_s1: 0.504637, loss_fp: 0.500417, loss_freq: 0.503281
[12:00:10.021] iteration 583: loss: 0.955901, loss_s1: 0.506607, loss_fp: 0.500339, loss_freq: 0.501685
[12:00:10.641] iteration 584: loss: 0.961068, loss_s1: 0.504540, loss_fp: 0.500266, loss_freq: 0.501673
[12:00:11.260] iteration 585: loss: 1.054338, loss_s1: 0.502353, loss_fp: 0.500380, loss_freq: 0.502289
[12:00:11.871] iteration 586: loss: 1.003600, loss_s1: 0.504969, loss_fp: 0.500408, loss_freq: 0.501002
[12:00:12.483] iteration 587: loss: 1.029836, loss_s1: 0.501765, loss_fp: 0.500386, loss_freq: 0.501096
[12:00:13.107] iteration 588: loss: 1.036545, loss_s1: 0.502923, loss_fp: 0.500325, loss_freq: 0.501380
[12:00:13.717] iteration 589: loss: 1.110031, loss_s1: 0.502295, loss_fp: 0.500512, loss_freq: 0.500952
[12:00:14.335] iteration 590: loss: 1.047297, loss_s1: 0.503088, loss_fp: 0.500241, loss_freq: 0.502426
[12:00:14.949] iteration 591: loss: 1.004380, loss_s1: 0.502772, loss_fp: 0.500236, loss_freq: 0.501931
[12:00:15.561] iteration 592: loss: 0.964670, loss_s1: 0.503670, loss_fp: 0.500144, loss_freq: 0.501646
[12:00:16.174] iteration 593: loss: 0.996636, loss_s1: 0.505348, loss_fp: 0.500254, loss_freq: 0.501709
[12:00:16.793] iteration 594: loss: 1.003671, loss_s1: 0.502205, loss_fp: 0.500318, loss_freq: 0.502516
[12:00:17.406] iteration 595: loss: 0.967802, loss_s1: 0.505072, loss_fp: 0.500265, loss_freq: 0.501299
[12:00:18.022] iteration 596: loss: 0.978309, loss_s1: 0.502042, loss_fp: 0.500251, loss_freq: 0.501866
[12:00:18.637] iteration 597: loss: 0.983814, loss_s1: 0.503302, loss_fp: 0.500423, loss_freq: 0.501496
[12:00:19.249] iteration 598: loss: 1.010190, loss_s1: 0.502371, loss_fp: 0.500302, loss_freq: 0.500747
[12:00:19.871] iteration 599: loss: 1.045921, loss_s1: 0.502458, loss_fp: 0.500604, loss_freq: 0.501403
[12:00:20.486] iteration 600: loss: 0.951622, loss_s1: 0.503917, loss_fp: 0.500533, loss_freq: 0.502942
[12:00:22.812] iteration 600 : mean_dice : 0.045664
[12:00:23.462] iteration 601: loss: 1.041683, loss_s1: 0.504992, loss_fp: 0.500420, loss_freq: 0.502152
[12:00:24.092] iteration 602: loss: 1.013305, loss_s1: 0.503038, loss_fp: 0.500204, loss_freq: 0.500654
[12:00:24.720] iteration 603: loss: 0.961298, loss_s1: 0.503178, loss_fp: 0.500381, loss_freq: 0.501603
[12:00:25.337] iteration 604: loss: 0.984476, loss_s1: 0.505347, loss_fp: 0.500119, loss_freq: 0.501572
[12:00:25.958] iteration 605: loss: 0.984522, loss_s1: 0.502486, loss_fp: 0.500435, loss_freq: 0.501161
[12:00:26.574] iteration 606: loss: 0.960726, loss_s1: 0.502847, loss_fp: 0.500283, loss_freq: 0.501799
[12:00:27.198] iteration 607: loss: 1.005197, loss_s1: 0.505066, loss_fp: 0.500240, loss_freq: 0.502360
[12:00:27.815] iteration 608: loss: 1.070661, loss_s1: 0.505377, loss_fp: 0.500199, loss_freq: 0.503602
[12:00:28.436] iteration 609: loss: 0.981589, loss_s1: 0.504830, loss_fp: 0.500157, loss_freq: 0.501711
[12:00:29.078] iteration 610: loss: 0.953849, loss_s1: 0.505412, loss_fp: 0.500656, loss_freq: 0.500890
[12:00:29.708] iteration 611: loss: 1.034029, loss_s1: 0.503304, loss_fp: 0.500307, loss_freq: 0.501918
[12:00:30.333] iteration 612: loss: 0.990510, loss_s1: 0.506531, loss_fp: 0.500259, loss_freq: 0.501816
[12:00:30.945] iteration 613: loss: 0.987030, loss_s1: 0.505248, loss_fp: 0.500170, loss_freq: 0.503707
[12:00:31.555] iteration 614: loss: 0.985687, loss_s1: 0.503678, loss_fp: 0.500215, loss_freq: 0.504418
[12:00:32.200] iteration 615: loss: 0.980938, loss_s1: 0.506322, loss_fp: 0.500171, loss_freq: 0.502431
[12:00:32.878] iteration 616: loss: 0.946626, loss_s1: 0.505927, loss_fp: 0.500515, loss_freq: 0.503927
[12:00:33.504] iteration 617: loss: 1.090904, loss_s1: 0.503104, loss_fp: 0.500418, loss_freq: 0.503778
[12:00:34.121] iteration 618: loss: 0.954542, loss_s1: 0.505233, loss_fp: 0.500119, loss_freq: 0.502771
[12:00:34.752] iteration 619: loss: 0.966100, loss_s1: 0.502940, loss_fp: 0.500230, loss_freq: 0.501348
[12:00:35.380] iteration 620: loss: 1.073169, loss_s1: 0.501728, loss_fp: 0.500425, loss_freq: 0.501113
[12:00:36.007] iteration 621: loss: 0.985972, loss_s1: 0.502773, loss_fp: 0.500267, loss_freq: 0.501454
[12:00:36.637] iteration 622: loss: 0.993300, loss_s1: 0.503454, loss_fp: 0.500218, loss_freq: 0.501926
[12:00:37.284] iteration 623: loss: 1.025582, loss_s1: 0.506813, loss_fp: 0.500335, loss_freq: 0.501483
[12:00:37.903] iteration 624: loss: 1.100797, loss_s1: 0.505200, loss_fp: 0.500143, loss_freq: 0.500856
[12:00:38.530] iteration 625: loss: 1.061148, loss_s1: 0.505047, loss_fp: 0.500244, loss_freq: 0.501999
[12:00:39.239] iteration 626: loss: 0.978902, loss_s1: 0.505468, loss_fp: 0.500536, loss_freq: 0.500785
[12:00:39.860] iteration 627: loss: 0.971865, loss_s1: 0.506841, loss_fp: 0.500723, loss_freq: 0.503346
[12:00:40.473] iteration 628: loss: 0.993108, loss_s1: 0.503703, loss_fp: 0.500182, loss_freq: 0.501555
[12:00:41.085] iteration 629: loss: 1.045526, loss_s1: 0.505962, loss_fp: 0.500145, loss_freq: 0.501996
[12:00:41.740] iteration 630: loss: 0.961828, loss_s1: 0.504048, loss_fp: 0.500221, loss_freq: 0.501679
[12:00:42.408] iteration 631: loss: 0.988430, loss_s1: 0.503945, loss_fp: 0.500610, loss_freq: 0.501152
[12:00:43.055] iteration 632: loss: 0.953519, loss_s1: 0.501783, loss_fp: 0.500430, loss_freq: 0.501455
[12:00:43.703] iteration 633: loss: 0.998774, loss_s1: 0.501781, loss_fp: 0.500810, loss_freq: 0.501180
[12:00:44.412] iteration 634: loss: 1.036786, loss_s1: 0.505320, loss_fp: 0.500228, loss_freq: 0.501344
[12:00:45.027] iteration 635: loss: 0.966731, loss_s1: 0.505050, loss_fp: 0.500559, loss_freq: 0.502328
[12:00:45.661] iteration 636: loss: 1.049684, loss_s1: 0.504252, loss_fp: 0.500312, loss_freq: 0.502211
[12:00:46.287] iteration 637: loss: 0.980667, loss_s1: 0.505521, loss_fp: 0.500355, loss_freq: 0.502400
[12:00:46.939] iteration 638: loss: 0.987153, loss_s1: 0.506814, loss_fp: 0.500722, loss_freq: 0.502840
[12:00:47.557] iteration 639: loss: 0.980638, loss_s1: 0.504070, loss_fp: 0.500238, loss_freq: 0.502559
[12:00:48.175] iteration 640: loss: 0.975247, loss_s1: 0.504639, loss_fp: 0.500324, loss_freq: 0.501374
[12:00:48.795] iteration 641: loss: 0.982130, loss_s1: 0.503809, loss_fp: 0.500253, loss_freq: 0.501708
[12:00:49.500] iteration 642: loss: 0.987998, loss_s1: 0.503021, loss_fp: 0.500325, loss_freq: 0.501247
[12:00:50.115] iteration 643: loss: 1.035130, loss_s1: 0.504501, loss_fp: 0.500632, loss_freq: 0.502418
[12:00:50.731] iteration 644: loss: 0.968458, loss_s1: 0.502682, loss_fp: 0.500054, loss_freq: 0.501602
[12:00:51.355] iteration 645: loss: 0.964912, loss_s1: 0.506871, loss_fp: 0.500117, loss_freq: 0.501961
[12:00:51.977] iteration 646: loss: 1.031320, loss_s1: 0.504953, loss_fp: 0.500366, loss_freq: 0.504176
[12:00:52.594] iteration 647: loss: 0.989101, loss_s1: 0.506736, loss_fp: 0.500343, loss_freq: 0.501843
[12:00:53.216] iteration 648: loss: 0.961070, loss_s1: 0.507833, loss_fp: 0.500435, loss_freq: 0.501760
[12:00:53.847] iteration 649: loss: 0.979104, loss_s1: 0.506160, loss_fp: 0.500488, loss_freq: 0.502798
[12:00:54.465] iteration 650: loss: 0.971731, loss_s1: 0.506742, loss_fp: 0.500661, loss_freq: 0.504360
[12:00:55.120] iteration 651: loss: 0.963133, loss_s1: 0.504423, loss_fp: 0.500689, loss_freq: 0.504061
[12:00:55.737] iteration 652: loss: 1.142531, loss_s1: 0.503915, loss_fp: 0.500830, loss_freq: 0.504520
[12:00:56.353] iteration 653: loss: 0.938325, loss_s1: 0.506395, loss_fp: 0.500346, loss_freq: 0.504036
[12:00:57.022] iteration 654: loss: 0.947428, loss_s1: 0.505168, loss_fp: 0.500429, loss_freq: 0.503061
[12:00:57.667] iteration 655: loss: 1.020094, loss_s1: 0.506570, loss_fp: 0.500551, loss_freq: 0.501900
[12:00:58.292] iteration 656: loss: 0.990671, loss_s1: 0.504498, loss_fp: 0.500437, loss_freq: 0.501485
[12:00:58.908] iteration 657: loss: 0.993107, loss_s1: 0.508232, loss_fp: 0.502514, loss_freq: 0.501284
[12:00:59.524] iteration 658: loss: 1.022593, loss_s1: 0.502828, loss_fp: 0.500158, loss_freq: 0.501591
[12:01:00.162] iteration 659: loss: 1.046454, loss_s1: 0.506406, loss_fp: 0.500378, loss_freq: 0.501935
[12:01:00.772] iteration 660: loss: 1.027840, loss_s1: 0.505852, loss_fp: 0.500221, loss_freq: 0.502395
[12:01:01.381] iteration 661: loss: 0.966371, loss_s1: 0.503702, loss_fp: 0.500262, loss_freq: 0.502545
[12:01:02.044] iteration 662: loss: 0.947135, loss_s1: 0.508977, loss_fp: 0.500753, loss_freq: 0.501370
[12:01:02.666] iteration 663: loss: 0.972245, loss_s1: 0.504291, loss_fp: 0.500135, loss_freq: 0.501586
[12:01:03.291] iteration 664: loss: 1.012294, loss_s1: 0.505892, loss_fp: 0.500233, loss_freq: 0.502859
[12:01:03.911] iteration 665: loss: 0.965671, loss_s1: 0.502148, loss_fp: 0.500300, loss_freq: 0.500859
[12:01:04.526] iteration 666: loss: 0.993636, loss_s1: 0.504893, loss_fp: 0.500187, loss_freq: 0.500917
[12:01:05.163] iteration 667: loss: 0.941546, loss_s1: 0.508313, loss_fp: 0.500282, loss_freq: 0.500763
[12:01:05.779] iteration 668: loss: 0.979805, loss_s1: 0.502331, loss_fp: 0.500091, loss_freq: 0.500930
[12:01:06.400] iteration 669: loss: 1.001474, loss_s1: 0.505415, loss_fp: 0.500801, loss_freq: 0.501225
[12:01:07.034] iteration 670: loss: 0.957030, loss_s1: 0.503009, loss_fp: 0.500405, loss_freq: 0.502227
[12:01:07.653] iteration 671: loss: 1.073644, loss_s1: 0.506421, loss_fp: 0.500328, loss_freq: 0.502445
[12:01:08.278] iteration 672: loss: 0.996384, loss_s1: 0.504844, loss_fp: 0.500751, loss_freq: 0.502466
[12:01:08.889] iteration 673: loss: 0.973104, loss_s1: 0.507281, loss_fp: 0.500260, loss_freq: 0.505928
[12:01:09.499] iteration 674: loss: 1.003930, loss_s1: 0.503810, loss_fp: 0.500493, loss_freq: 0.501371
[12:01:10.186] iteration 675: loss: 0.968246, loss_s1: 0.502710, loss_fp: 0.500404, loss_freq: 0.501169
[12:01:10.805] iteration 676: loss: 0.919631, loss_s1: 0.504888, loss_fp: 0.500284, loss_freq: 0.502766
[12:01:11.412] iteration 677: loss: 1.005483, loss_s1: 0.505905, loss_fp: 0.500156, loss_freq: 0.500946
[12:01:12.074] iteration 678: loss: 1.011076, loss_s1: 0.502995, loss_fp: 0.500148, loss_freq: 0.502958
[12:01:12.745] iteration 679: loss: 0.965585, loss_s1: 0.505020, loss_fp: 0.500442, loss_freq: 0.501294
[12:01:13.389] iteration 680: loss: 0.964357, loss_s1: 0.504364, loss_fp: 0.500348, loss_freq: 0.500874
[12:01:14.054] iteration 681: loss: 1.032948, loss_s1: 0.504995, loss_fp: 0.500699, loss_freq: 0.500695
[12:01:14.685] iteration 682: loss: 0.972105, loss_s1: 0.503739, loss_fp: 0.500337, loss_freq: 0.501553
[12:01:15.300] iteration 683: loss: 0.945920, loss_s1: 0.504226, loss_fp: 0.500229, loss_freq: 0.501943
[12:01:15.909] iteration 684: loss: 0.950095, loss_s1: 0.504189, loss_fp: 0.500523, loss_freq: 0.503046
[12:01:16.518] iteration 685: loss: 0.984360, loss_s1: 0.501333, loss_fp: 0.500144, loss_freq: 0.500863
[12:01:17.211] iteration 686: loss: 0.937205, loss_s1: 0.502893, loss_fp: 0.500300, loss_freq: 0.501987
[12:01:17.827] iteration 687: loss: 1.109716, loss_s1: 0.505047, loss_fp: 0.500450, loss_freq: 0.504032
[12:01:18.441] iteration 688: loss: 0.934641, loss_s1: 0.504887, loss_fp: 0.500311, loss_freq: 0.501893
[12:01:19.055] iteration 689: loss: 0.972214, loss_s1: 0.504814, loss_fp: 0.500581, loss_freq: 0.503184
[12:01:19.677] iteration 690: loss: 1.062292, loss_s1: 0.506588, loss_fp: 0.500232, loss_freq: 0.503138
[12:01:20.290] iteration 691: loss: 1.005067, loss_s1: 0.507231, loss_fp: 0.500269, loss_freq: 0.500711
[12:01:20.899] iteration 692: loss: 1.022712, loss_s1: 0.506546, loss_fp: 0.500148, loss_freq: 0.502087
[12:01:21.520] iteration 693: loss: 1.004076, loss_s1: 0.501746, loss_fp: 0.500176, loss_freq: 0.503029
[12:01:22.208] iteration 694: loss: 1.062098, loss_s1: 0.505098, loss_fp: 0.500668, loss_freq: 0.502874
[12:01:22.879] iteration 695: loss: 1.042171, loss_s1: 0.505177, loss_fp: 0.500217, loss_freq: 0.502508
[12:01:23.550] iteration 696: loss: 0.975684, loss_s1: 0.504368, loss_fp: 0.500154, loss_freq: 0.500923
[12:01:24.220] iteration 697: loss: 0.936127, loss_s1: 0.507387, loss_fp: 0.500390, loss_freq: 0.500774
[12:01:24.888] iteration 698: loss: 0.974371, loss_s1: 0.503529, loss_fp: 0.500423, loss_freq: 0.503900
[12:01:25.581] iteration 699: loss: 1.024625, loss_s1: 0.506943, loss_fp: 0.500403, loss_freq: 0.501757
[12:01:26.228] iteration 700: loss: 0.951464, loss_s1: 0.505585, loss_fp: 0.500707, loss_freq: 0.501315
[12:01:26.939] iteration 701: loss: 0.990041, loss_s1: 0.501368, loss_fp: 0.500506, loss_freq: 0.501550
[12:01:27.644] iteration 702: loss: 0.945593, loss_s1: 0.504983, loss_fp: 0.500293, loss_freq: 0.502610
[12:01:28.305] iteration 703: loss: 0.987594, loss_s1: 0.504308, loss_fp: 0.500626, loss_freq: 0.501219
[12:01:28.952] iteration 704: loss: 1.008319, loss_s1: 0.504967, loss_fp: 0.500310, loss_freq: 0.501362
[12:01:29.602] iteration 705: loss: 0.948886, loss_s1: 0.505847, loss_fp: 0.500600, loss_freq: 0.501824
[12:01:30.256] iteration 706: loss: 1.066028, loss_s1: 0.503452, loss_fp: 0.500271, loss_freq: 0.502998
[12:01:30.898] iteration 707: loss: 0.988000, loss_s1: 0.502695, loss_fp: 0.500348, loss_freq: 0.501826
[12:01:31.544] iteration 708: loss: 0.958223, loss_s1: 0.507815, loss_fp: 0.500239, loss_freq: 0.501931
[12:01:32.185] iteration 709: loss: 0.975329, loss_s1: 0.501943, loss_fp: 0.500522, loss_freq: 0.501112
[12:01:32.798] iteration 710: loss: 0.960439, loss_s1: 0.507927, loss_fp: 0.500437, loss_freq: 0.503132
[12:01:33.410] iteration 711: loss: 0.942032, loss_s1: 0.501098, loss_fp: 0.501282, loss_freq: 0.502103
[12:01:34.039] iteration 712: loss: 0.985439, loss_s1: 0.506182, loss_fp: 0.500440, loss_freq: 0.501681
[12:01:34.673] iteration 713: loss: 1.029456, loss_s1: 0.504161, loss_fp: 0.500521, loss_freq: 0.502073
[12:01:35.278] iteration 714: loss: 0.964843, loss_s1: 0.502204, loss_fp: 0.500381, loss_freq: 0.502417
[12:01:35.886] iteration 715: loss: 0.958706, loss_s1: 0.504891, loss_fp: 0.500808, loss_freq: 0.504283
[12:01:36.815] iteration 716: loss: 1.029451, loss_s1: 0.505764, loss_fp: 0.500240, loss_freq: 0.502149
[12:01:37.431] iteration 717: loss: 0.957146, loss_s1: 0.504862, loss_fp: 0.500490, loss_freq: 0.502174
[12:01:38.048] iteration 718: loss: 0.913059, loss_s1: 0.504574, loss_fp: 0.500356, loss_freq: 0.504094
[12:01:38.661] iteration 719: loss: 1.012850, loss_s1: 0.504803, loss_fp: 0.500184, loss_freq: 0.501110
[12:01:39.330] iteration 720: loss: 0.993981, loss_s1: 0.504290, loss_fp: 0.500322, loss_freq: 0.501837
[12:01:39.979] iteration 721: loss: 0.969742, loss_s1: 0.502150, loss_fp: 0.500451, loss_freq: 0.502228
[12:01:40.636] iteration 722: loss: 0.948823, loss_s1: 0.505378, loss_fp: 0.500246, loss_freq: 0.502722
[12:01:41.294] iteration 723: loss: 0.971663, loss_s1: 0.505142, loss_fp: 0.500658, loss_freq: 0.503324
[12:01:41.935] iteration 724: loss: 0.923135, loss_s1: 0.501865, loss_fp: 0.500294, loss_freq: 0.503484
[12:01:42.593] iteration 725: loss: 1.108979, loss_s1: 0.505066, loss_fp: 0.500260, loss_freq: 0.505099
[12:01:43.246] iteration 726: loss: 0.944149, loss_s1: 0.505585, loss_fp: 0.500333, loss_freq: 0.501404
[12:01:43.860] iteration 727: loss: 0.927035, loss_s1: 0.504022, loss_fp: 0.500181, loss_freq: 0.502945
[12:01:44.493] iteration 728: loss: 0.990481, loss_s1: 0.505434, loss_fp: 0.500529, loss_freq: 0.502035
[12:01:45.140] iteration 729: loss: 0.977789, loss_s1: 0.502980, loss_fp: 0.500177, loss_freq: 0.500943
[12:01:45.750] iteration 730: loss: 0.991044, loss_s1: 0.502231, loss_fp: 0.500331, loss_freq: 0.501128
[12:01:46.398] iteration 731: loss: 0.996551, loss_s1: 0.503950, loss_fp: 0.500141, loss_freq: 0.501055
[12:01:47.017] iteration 732: loss: 1.113963, loss_s1: 0.505038, loss_fp: 0.500115, loss_freq: 0.501271
[12:01:47.638] iteration 733: loss: 1.022914, loss_s1: 0.505207, loss_fp: 0.500221, loss_freq: 0.502246
[12:01:48.283] iteration 734: loss: 0.943095, loss_s1: 0.505592, loss_fp: 0.500306, loss_freq: 0.502324
[12:01:48.903] iteration 735: loss: 0.982509, loss_s1: 0.504101, loss_fp: 0.500380, loss_freq: 0.500488
[12:01:49.519] iteration 736: loss: 0.971335, loss_s1: 0.504860, loss_fp: 0.500118, loss_freq: 0.502421
[12:01:50.140] iteration 737: loss: 1.003489, loss_s1: 0.507745, loss_fp: 0.500364, loss_freq: 0.503319
[12:01:50.755] iteration 738: loss: 0.953491, loss_s1: 0.503599, loss_fp: 0.500274, loss_freq: 0.502513
[12:01:51.375] iteration 739: loss: 0.976007, loss_s1: 0.503068, loss_fp: 0.500545, loss_freq: 0.502662
[12:01:51.989] iteration 740: loss: 0.945944, loss_s1: 0.502356, loss_fp: 0.501009, loss_freq: 0.502063
[12:01:52.605] iteration 741: loss: 0.971005, loss_s1: 0.502613, loss_fp: 0.500350, loss_freq: 0.501059
[12:01:53.220] iteration 742: loss: 1.011356, loss_s1: 0.505246, loss_fp: 0.500333, loss_freq: 0.501950
[12:01:53.839] iteration 743: loss: 0.930315, loss_s1: 0.503971, loss_fp: 0.500275, loss_freq: 0.502995
[12:01:54.453] iteration 744: loss: 1.027561, loss_s1: 0.502767, loss_fp: 0.500616, loss_freq: 0.503380
[12:01:55.071] iteration 745: loss: 0.986104, loss_s1: 0.503121, loss_fp: 0.500335, loss_freq: 0.500529
[12:01:55.689] iteration 746: loss: 0.965098, loss_s1: 0.506646, loss_fp: 0.500195, loss_freq: 0.501469
[12:01:56.310] iteration 747: loss: 0.952532, loss_s1: 0.501169, loss_fp: 0.500337, loss_freq: 0.501704
[12:01:56.923] iteration 748: loss: 0.964438, loss_s1: 0.501791, loss_fp: 0.500364, loss_freq: 0.501328
[12:01:57.543] iteration 749: loss: 0.944618, loss_s1: 0.505306, loss_fp: 0.500191, loss_freq: 0.501877
[12:01:58.168] iteration 750: loss: 1.000481, loss_s1: 0.504886, loss_fp: 0.500239, loss_freq: 0.501395
[12:01:58.825] iteration 751: loss: 1.028159, loss_s1: 0.502500, loss_fp: 0.500147, loss_freq: 0.502047
[12:01:59.453] iteration 752: loss: 0.961432, loss_s1: 0.505668, loss_fp: 0.500086, loss_freq: 0.501799
[12:02:00.072] iteration 753: loss: 0.923265, loss_s1: 0.505878, loss_fp: 0.500191, loss_freq: 0.500922
[12:02:00.735] iteration 754: loss: 1.057634, loss_s1: 0.506166, loss_fp: 0.500396, loss_freq: 0.503258
[12:02:01.373] iteration 755: loss: 0.961867, loss_s1: 0.502968, loss_fp: 0.500547, loss_freq: 0.501753
[12:02:02.091] iteration 756: loss: 0.961595, loss_s1: 0.504994, loss_fp: 0.500785, loss_freq: 0.503127
[12:02:02.831] iteration 757: loss: 0.979301, loss_s1: 0.506435, loss_fp: 0.500159, loss_freq: 0.504325
[12:02:03.499] iteration 758: loss: 0.963711, loss_s1: 0.502925, loss_fp: 0.500189, loss_freq: 0.503774
[12:02:04.174] iteration 759: loss: 0.905537, loss_s1: 0.504835, loss_fp: 0.500269, loss_freq: 0.503025
[12:02:04.903] iteration 760: loss: 1.080809, loss_s1: 0.503055, loss_fp: 0.500212, loss_freq: 0.504335
[12:02:05.543] iteration 761: loss: 0.944561, loss_s1: 0.506834, loss_fp: 0.500478, loss_freq: 0.501752
[12:02:06.166] iteration 762: loss: 0.971259, loss_s1: 0.502425, loss_fp: 0.500194, loss_freq: 0.502948
[12:02:06.796] iteration 763: loss: 1.005955, loss_s1: 0.502428, loss_fp: 0.500122, loss_freq: 0.501003
[12:02:07.444] iteration 764: loss: 0.938743, loss_s1: 0.504593, loss_fp: 0.500139, loss_freq: 0.501271
[12:02:08.056] iteration 765: loss: 0.962159, loss_s1: 0.501584, loss_fp: 0.500239, loss_freq: 0.501881
[12:02:08.681] iteration 766: loss: 0.996972, loss_s1: 0.503907, loss_fp: 0.500153, loss_freq: 0.501505
[12:02:09.300] iteration 767: loss: 1.078824, loss_s1: 0.503518, loss_fp: 0.500103, loss_freq: 0.500960
[12:02:09.923] iteration 768: loss: 1.008649, loss_s1: 0.501857, loss_fp: 0.500211, loss_freq: 0.501711
[12:02:10.538] iteration 769: loss: 0.957398, loss_s1: 0.503061, loss_fp: 0.500108, loss_freq: 0.501019
[12:02:11.152] iteration 770: loss: 0.939032, loss_s1: 0.504346, loss_fp: 0.500186, loss_freq: 0.501905
[12:02:11.766] iteration 771: loss: 0.980133, loss_s1: 0.504766, loss_fp: 0.500096, loss_freq: 0.501391
[12:02:12.390] iteration 772: loss: 1.024486, loss_s1: 0.508195, loss_fp: 0.500307, loss_freq: 0.502879
[12:02:13.006] iteration 773: loss: 0.941285, loss_s1: 0.506356, loss_fp: 0.500116, loss_freq: 0.501363
[12:02:13.619] iteration 774: loss: 0.972368, loss_s1: 0.502126, loss_fp: 0.500250, loss_freq: 0.500868
[12:02:14.262] iteration 775: loss: 0.958030, loss_s1: 0.501947, loss_fp: 0.500218, loss_freq: 0.501495
[12:02:14.877] iteration 776: loss: 0.971056, loss_s1: 0.502974, loss_fp: 0.500144, loss_freq: 0.500633
[12:02:15.506] iteration 777: loss: 1.019275, loss_s1: 0.502781, loss_fp: 0.500463, loss_freq: 0.501550
[12:02:16.120] iteration 778: loss: 0.945679, loss_s1: 0.503506, loss_fp: 0.500338, loss_freq: 0.502786
[12:02:16.730] iteration 779: loss: 1.012878, loss_s1: 0.502900, loss_fp: 0.500747, loss_freq: 0.501535
[12:02:17.349] iteration 780: loss: 0.972846, loss_s1: 0.504661, loss_fp: 0.504766, loss_freq: 0.501821
[12:02:17.962] iteration 781: loss: 0.946080, loss_s1: 0.503872, loss_fp: 0.500288, loss_freq: 0.501251
[12:02:18.582] iteration 782: loss: 0.978290, loss_s1: 0.504231, loss_fp: 0.500280, loss_freq: 0.502127
[12:02:19.193] iteration 783: loss: 0.962141, loss_s1: 0.502555, loss_fp: 0.500207, loss_freq: 0.500844
[12:02:19.816] iteration 784: loss: 0.951328, loss_s1: 0.502331, loss_fp: 0.500160, loss_freq: 0.501847
[12:02:20.431] iteration 785: loss: 1.016096, loss_s1: 0.502252, loss_fp: 0.500435, loss_freq: 0.501726
[12:02:21.043] iteration 786: loss: 1.002831, loss_s1: 0.503028, loss_fp: 0.500160, loss_freq: 0.501836
[12:02:21.659] iteration 787: loss: 0.967102, loss_s1: 0.501346, loss_fp: 0.500113, loss_freq: 0.501067
[12:02:22.278] iteration 788: loss: 0.947473, loss_s1: 0.504557, loss_fp: 0.500167, loss_freq: 0.501951
[12:02:22.931] iteration 789: loss: 1.043838, loss_s1: 0.504040, loss_fp: 0.500100, loss_freq: 0.501889
[12:02:23.586] iteration 790: loss: 0.966103, loss_s1: 0.503566, loss_fp: 0.500128, loss_freq: 0.501681
[12:02:24.235] iteration 791: loss: 0.965660, loss_s1: 0.501732, loss_fp: 0.500214, loss_freq: 0.500552
[12:02:24.885] iteration 792: loss: 0.964485, loss_s1: 0.504084, loss_fp: 0.500200, loss_freq: 0.502059
[12:02:25.536] iteration 793: loss: 0.948811, loss_s1: 0.502776, loss_fp: 0.500958, loss_freq: 0.502021
[12:02:26.174] iteration 794: loss: 0.906895, loss_s1: 0.504317, loss_fp: 0.500270, loss_freq: 0.502540
[12:02:26.790] iteration 795: loss: 1.123619, loss_s1: 0.502997, loss_fp: 0.500181, loss_freq: 0.503606
[12:02:27.405] iteration 796: loss: 0.925102, loss_s1: 0.506911, loss_fp: 0.500480, loss_freq: 0.502656
[12:02:28.020] iteration 797: loss: 0.969099, loss_s1: 0.503909, loss_fp: 0.500480, loss_freq: 0.501197
[12:02:28.637] iteration 798: loss: 1.016698, loss_s1: 0.506245, loss_fp: 0.500159, loss_freq: 0.500960
[12:02:29.252] iteration 799: loss: 0.948914, loss_s1: 0.505322, loss_fp: 0.500348, loss_freq: 0.501016
[12:02:29.867] iteration 800: loss: 0.983118, loss_s1: 0.504526, loss_fp: 0.500086, loss_freq: 0.501089
[12:02:31.903] iteration 800 : mean_dice : 0.027681
[12:02:32.558] iteration 801: loss: 0.972614, loss_s1: 0.503726, loss_fp: 0.500166, loss_freq: 0.501749
[12:02:33.175] iteration 802: loss: 1.054764, loss_s1: 0.505193, loss_fp: 0.500254, loss_freq: 0.502495
[12:02:33.787] iteration 803: loss: 0.995221, loss_s1: 0.503020, loss_fp: 0.500221, loss_freq: 0.503841
[12:02:34.403] iteration 804: loss: 0.942647, loss_s1: 0.503718, loss_fp: 0.500203, loss_freq: 0.503604
[12:02:35.017] iteration 805: loss: 0.928422, loss_s1: 0.502495, loss_fp: 0.500457, loss_freq: 0.501123
[12:02:35.636] iteration 806: loss: 0.946909, loss_s1: 0.504440, loss_fp: 0.500137, loss_freq: 0.501027
[12:02:36.267] iteration 807: loss: 0.982233, loss_s1: 0.502955, loss_fp: 0.500153, loss_freq: 0.503453
[12:02:36.892] iteration 808: loss: 0.941332, loss_s1: 0.502590, loss_fp: 0.500250, loss_freq: 0.500650
[12:02:37.513] iteration 809: loss: 0.962967, loss_s1: 0.504654, loss_fp: 0.500191, loss_freq: 0.500890
[12:02:38.136] iteration 810: loss: 0.945100, loss_s1: 0.501163, loss_fp: 0.500343, loss_freq: 0.500658
[12:02:38.757] iteration 811: loss: 0.969579, loss_s1: 0.505453, loss_fp: 0.500180, loss_freq: 0.501100
[12:02:39.385] iteration 812: loss: 0.972711, loss_s1: 0.502782, loss_fp: 0.500300, loss_freq: 0.501922
[12:02:40.009] iteration 813: loss: 0.939648, loss_s1: 0.505518, loss_fp: 0.500456, loss_freq: 0.504579
[12:02:40.628] iteration 814: loss: 1.042573, loss_s1: 0.501974, loss_fp: 0.500602, loss_freq: 0.501840
[12:02:41.243] iteration 815: loss: 0.976461, loss_s1: 0.505876, loss_fp: 0.500142, loss_freq: 0.503059
[12:02:41.865] iteration 816: loss: 0.958585, loss_s1: 0.503504, loss_fp: 0.500733, loss_freq: 0.504246
[12:02:42.486] iteration 817: loss: 0.983917, loss_s1: 0.503585, loss_fp: 0.500476, loss_freq: 0.502019
[12:02:43.110] iteration 818: loss: 0.973075, loss_s1: 0.503417, loss_fp: 0.500363, loss_freq: 0.501907
[12:02:43.734] iteration 819: loss: 0.926794, loss_s1: 0.503278, loss_fp: 0.500167, loss_freq: 0.502639
[12:02:44.360] iteration 820: loss: 1.015497, loss_s1: 0.504476, loss_fp: 0.500616, loss_freq: 0.500916
[12:02:44.984] iteration 821: loss: 1.010252, loss_s1: 0.503410, loss_fp: 0.500145, loss_freq: 0.502859
[12:02:45.604] iteration 822: loss: 0.957184, loss_s1: 0.502508, loss_fp: 0.500261, loss_freq: 0.501527
[12:02:46.215] iteration 823: loss: 0.934764, loss_s1: 0.502421, loss_fp: 0.500436, loss_freq: 0.502216
[12:02:46.827] iteration 824: loss: 0.999229, loss_s1: 0.501387, loss_fp: 0.500193, loss_freq: 0.500609
[12:02:47.440] iteration 825: loss: 0.966111, loss_s1: 0.504345, loss_fp: 0.500663, loss_freq: 0.501484
[12:02:48.055] iteration 826: loss: 0.952494, loss_s1: 0.505364, loss_fp: 0.500136, loss_freq: 0.501892
[12:02:48.667] iteration 827: loss: 0.935942, loss_s1: 0.501438, loss_fp: 0.500246, loss_freq: 0.502522
[12:02:49.279] iteration 828: loss: 0.954480, loss_s1: 0.502642, loss_fp: 0.500168, loss_freq: 0.500758
[12:02:49.933] iteration 829: loss: 0.920642, loss_s1: 0.505145, loss_fp: 0.500267, loss_freq: 0.501889
[12:02:50.595] iteration 830: loss: 1.118562, loss_s1: 0.504438, loss_fp: 0.500208, loss_freq: 0.505379
[12:02:51.257] iteration 831: loss: 0.923245, loss_s1: 0.502686, loss_fp: 0.500167, loss_freq: 0.502154
[12:02:51.915] iteration 832: loss: 0.937242, loss_s1: 0.502669, loss_fp: 0.500208, loss_freq: 0.502598
[12:02:52.552] iteration 833: loss: 1.030740, loss_s1: 0.505102, loss_fp: 0.500329, loss_freq: 0.502601
[12:02:53.208] iteration 834: loss: 0.942580, loss_s1: 0.504271, loss_fp: 0.500389, loss_freq: 0.501916
[12:02:53.864] iteration 835: loss: 0.954766, loss_s1: 0.505437, loss_fp: 0.500175, loss_freq: 0.501686
[12:02:54.518] iteration 836: loss: 0.953443, loss_s1: 0.503021, loss_fp: 0.500134, loss_freq: 0.502941
[12:02:55.172] iteration 837: loss: 1.055252, loss_s1: 0.505341, loss_fp: 0.500296, loss_freq: 0.502933
[12:02:55.799] iteration 838: loss: 1.023120, loss_s1: 0.505813, loss_fp: 0.500240, loss_freq: 0.502498
[12:02:56.415] iteration 839: loss: 0.924372, loss_s1: 0.503938, loss_fp: 0.500183, loss_freq: 0.500894
[12:02:57.042] iteration 840: loss: 0.966078, loss_s1: 0.505447, loss_fp: 0.500187, loss_freq: 0.500348
[12:02:57.690] iteration 841: loss: 0.943361, loss_s1: 0.503059, loss_fp: 0.500255, loss_freq: 0.501907
[12:02:58.347] iteration 842: loss: 0.999342, loss_s1: 0.504730, loss_fp: 0.500128, loss_freq: 0.501810
[12:02:58.961] iteration 843: loss: 0.942141, loss_s1: 0.505690, loss_fp: 0.500251, loss_freq: 0.501618
[12:02:59.572] iteration 844: loss: 0.968359, loss_s1: 0.504381, loss_fp: 0.500071, loss_freq: 0.501464
[12:03:00.194] iteration 845: loss: 0.958609, loss_s1: 0.504876, loss_fp: 0.500198, loss_freq: 0.503856
[12:03:00.816] iteration 846: loss: 0.973280, loss_s1: 0.504267, loss_fp: 0.500418, loss_freq: 0.502072
[12:03:01.433] iteration 847: loss: 1.000095, loss_s1: 0.501338, loss_fp: 0.500204, loss_freq: 0.500790
[12:03:02.058] iteration 848: loss: 0.939408, loss_s1: 0.507602, loss_fp: 0.500224, loss_freq: 0.500881
[12:03:02.696] iteration 849: loss: 1.052556, loss_s1: 0.508019, loss_fp: 0.500189, loss_freq: 0.502889
[12:03:03.313] iteration 850: loss: 0.970466, loss_s1: 0.504365, loss_fp: 0.500143, loss_freq: 0.501859
[12:03:03.933] iteration 851: loss: 0.929859, loss_s1: 0.505240, loss_fp: 0.500421, loss_freq: 0.502164
[12:03:04.547] iteration 852: loss: 0.938599, loss_s1: 0.504210, loss_fp: 0.500204, loss_freq: 0.500636
[12:03:05.166] iteration 853: loss: 0.951921, loss_s1: 0.503906, loss_fp: 0.500578, loss_freq: 0.502473
[12:03:05.830] iteration 854: loss: 0.919565, loss_s1: 0.504101, loss_fp: 0.500077, loss_freq: 0.500653
[12:03:06.458] iteration 855: loss: 0.976410, loss_s1: 0.504344, loss_fp: 0.500089, loss_freq: 0.501057
[12:03:07.097] iteration 856: loss: 1.012239, loss_s1: 0.503317, loss_fp: 0.500151, loss_freq: 0.500734
[12:03:07.740] iteration 857: loss: 0.940375, loss_s1: 0.505620, loss_fp: 0.500353, loss_freq: 0.501547
[12:03:08.367] iteration 858: loss: 0.931650, loss_s1: 0.504226, loss_fp: 0.500265, loss_freq: 0.505102
[12:03:09.375] iteration 859: loss: 1.001128, loss_s1: 0.501693, loss_fp: 0.500223, loss_freq: 0.501625
[12:03:09.987] iteration 860: loss: 0.948279, loss_s1: 0.504886, loss_fp: 0.500150, loss_freq: 0.501346
[12:03:10.605] iteration 861: loss: 0.910642, loss_s1: 0.501897, loss_fp: 0.500358, loss_freq: 0.504802
[12:03:11.234] iteration 862: loss: 0.977791, loss_s1: 0.502953, loss_fp: 0.500217, loss_freq: 0.501168
[12:03:11.864] iteration 863: loss: 0.922208, loss_s1: 0.502664, loss_fp: 0.500323, loss_freq: 0.502251
[12:03:12.513] iteration 864: loss: 0.953586, loss_s1: 0.502554, loss_fp: 0.500319, loss_freq: 0.502628
[12:03:13.170] iteration 865: loss: 0.944013, loss_s1: 0.502248, loss_fp: 0.500318, loss_freq: 0.502388
[12:03:13.797] iteration 866: loss: 0.993496, loss_s1: 0.506463, loss_fp: 0.500744, loss_freq: 0.503851
[12:03:14.424] iteration 867: loss: 0.904561, loss_s1: 0.505190, loss_fp: 0.500529, loss_freq: 0.503674
[12:03:15.044] iteration 868: loss: 1.080303, loss_s1: 0.505906, loss_fp: 0.500183, loss_freq: 0.506246
[12:03:15.720] iteration 869: loss: 0.940385, loss_s1: 0.503390, loss_fp: 0.500288, loss_freq: 0.501956
[12:03:16.371] iteration 870: loss: 0.931281, loss_s1: 0.503246, loss_fp: 0.500435, loss_freq: 0.503805
[12:03:17.025] iteration 871: loss: 1.006416, loss_s1: 0.505784, loss_fp: 0.500270, loss_freq: 0.504350
[12:03:17.677] iteration 872: loss: 0.949861, loss_s1: 0.504844, loss_fp: 0.500314, loss_freq: 0.501239
[12:03:18.333] iteration 873: loss: 0.997476, loss_s1: 0.505131, loss_fp: 0.500234, loss_freq: 0.501493
[12:03:18.983] iteration 874: loss: 0.981718, loss_s1: 0.502100, loss_fp: 0.500284, loss_freq: 0.501279
[12:03:19.628] iteration 875: loss: 1.109537, loss_s1: 0.501940, loss_fp: 0.500487, loss_freq: 0.501085
[12:03:20.244] iteration 876: loss: 1.037645, loss_s1: 0.502208, loss_fp: 0.500271, loss_freq: 0.502680
[12:03:20.857] iteration 877: loss: 0.936281, loss_s1: 0.508547, loss_fp: 0.500320, loss_freq: 0.502814
[12:03:21.522] iteration 878: loss: 0.962558, loss_s1: 0.504587, loss_fp: 0.500093, loss_freq: 0.500850
[12:03:22.174] iteration 879: loss: 1.016350, loss_s1: 0.504715, loss_fp: 0.500316, loss_freq: 0.501600
[12:03:22.829] iteration 880: loss: 0.961131, loss_s1: 0.505718, loss_fp: 0.500188, loss_freq: 0.503362
[12:03:23.482] iteration 881: loss: 0.956779, loss_s1: 0.504809, loss_fp: 0.500406, loss_freq: 0.502013
[12:03:24.131] iteration 882: loss: 0.966072, loss_s1: 0.503187, loss_fp: 0.500148, loss_freq: 0.500497
[12:03:24.748] iteration 883: loss: 0.929416, loss_s1: 0.505089, loss_fp: 0.500230, loss_freq: 0.500659
[12:03:25.363] iteration 884: loss: 0.984188, loss_s1: 0.504132, loss_fp: 0.500131, loss_freq: 0.500358
[12:03:25.980] iteration 885: loss: 0.977512, loss_s1: 0.502230, loss_fp: 0.500191, loss_freq: 0.500562
[12:03:26.588] iteration 886: loss: 0.932323, loss_s1: 0.506138, loss_fp: 0.500173, loss_freq: 0.500947
[12:03:27.206] iteration 887: loss: 1.114655, loss_s1: 0.504370, loss_fp: 0.500239, loss_freq: 0.501920
[12:03:27.828] iteration 888: loss: 0.975920, loss_s1: 0.505662, loss_fp: 0.500584, loss_freq: 0.501403
[12:03:28.445] iteration 889: loss: 0.938254, loss_s1: 0.502545, loss_fp: 0.500266, loss_freq: 0.501007
[12:03:29.059] iteration 890: loss: 0.939376, loss_s1: 0.502433, loss_fp: 0.500146, loss_freq: 0.500787
[12:03:29.685] iteration 891: loss: 0.950522, loss_s1: 0.503670, loss_fp: 0.500381, loss_freq: 0.500873
[12:03:30.305] iteration 892: loss: 0.950916, loss_s1: 0.504022, loss_fp: 0.500179, loss_freq: 0.500642
[12:03:30.933] iteration 893: loss: 0.998100, loss_s1: 0.503853, loss_fp: 0.500112, loss_freq: 0.501080
[12:03:31.570] iteration 894: loss: 1.019736, loss_s1: 0.502597, loss_fp: 0.500248, loss_freq: 0.501013
[12:03:32.227] iteration 895: loss: 0.968666, loss_s1: 0.505853, loss_fp: 0.500128, loss_freq: 0.501195
[12:03:32.890] iteration 896: loss: 0.915057, loss_s1: 0.504616, loss_fp: 0.500150, loss_freq: 0.500325
[12:03:33.547] iteration 897: loss: 0.995164, loss_s1: 0.502828, loss_fp: 0.500287, loss_freq: 0.501632
[12:03:34.200] iteration 898: loss: 0.967073, loss_s1: 0.502775, loss_fp: 0.500284, loss_freq: 0.502054
[12:03:34.862] iteration 899: loss: 0.942607, loss_s1: 0.503851, loss_fp: 0.500226, loss_freq: 0.502200
[12:03:35.520] iteration 900: loss: 0.952213, loss_s1: 0.502241, loss_fp: 0.500160, loss_freq: 0.503671
[12:03:36.146] iteration 901: loss: 0.977024, loss_s1: 0.504036, loss_fp: 0.500456, loss_freq: 0.501505
[12:03:36.765] iteration 902: loss: 0.910658, loss_s1: 0.505274, loss_fp: 0.500230, loss_freq: 0.501709
[12:03:37.392] iteration 903: loss: 1.066206, loss_s1: 0.504573, loss_fp: 0.500153, loss_freq: 0.502977
[12:03:38.014] iteration 904: loss: 0.940171, loss_s1: 0.504034, loss_fp: 0.500216, loss_freq: 0.502060
[12:03:38.641] iteration 905: loss: 0.943831, loss_s1: 0.504988, loss_fp: 0.500140, loss_freq: 0.502935
[12:03:39.294] iteration 906: loss: 0.998379, loss_s1: 0.501239, loss_fp: 0.500081, loss_freq: 0.500577
[12:03:39.921] iteration 907: loss: 0.950797, loss_s1: 0.503912, loss_fp: 0.500193, loss_freq: 0.501224
[12:03:40.549] iteration 908: loss: 0.961649, loss_s1: 0.506558, loss_fp: 0.500127, loss_freq: 0.501825
[12:03:41.179] iteration 909: loss: 1.032563, loss_s1: 0.506726, loss_fp: 0.500227, loss_freq: 0.502410
[12:03:41.796] iteration 910: loss: 1.086746, loss_s1: 0.506478, loss_fp: 0.500449, loss_freq: 0.501792
[12:03:42.414] iteration 911: loss: 0.994635, loss_s1: 0.509988, loss_fp: 0.500172, loss_freq: 0.501338
[12:03:43.038] iteration 912: loss: 0.933471, loss_s1: 0.503970, loss_fp: 0.500228, loss_freq: 0.501991
[12:03:43.657] iteration 913: loss: 0.970837, loss_s1: 0.508343, loss_fp: 0.500568, loss_freq: 0.503028
[12:03:44.272] iteration 914: loss: 0.969572, loss_s1: 0.508346, loss_fp: 0.500429, loss_freq: 0.501596
[12:03:44.895] iteration 915: loss: 0.953260, loss_s1: 0.505989, loss_fp: 0.500458, loss_freq: 0.505396
[12:03:45.507] iteration 916: loss: 0.939956, loss_s1: 0.504869, loss_fp: 0.500191, loss_freq: 0.501594
[12:03:46.121] iteration 917: loss: 1.006477, loss_s1: 0.504810, loss_fp: 0.500226, loss_freq: 0.501119
[12:03:46.763] iteration 918: loss: 0.963557, loss_s1: 0.503706, loss_fp: 0.500141, loss_freq: 0.500898
[12:03:47.408] iteration 919: loss: 0.951531, loss_s1: 0.506211, loss_fp: 0.500296, loss_freq: 0.500949
[12:03:48.018] iteration 920: loss: 1.022007, loss_s1: 0.500855, loss_fp: 0.500096, loss_freq: 0.502953
[12:03:48.639] iteration 921: loss: 0.956219, loss_s1: 0.502641, loss_fp: 0.500248, loss_freq: 0.501695
[12:03:49.260] iteration 922: loss: 1.080264, loss_s1: 0.502730, loss_fp: 0.500763, loss_freq: 0.501816
[12:03:49.873] iteration 923: loss: 1.012811, loss_s1: 0.503731, loss_fp: 0.500716, loss_freq: 0.503897
[12:03:50.489] iteration 924: loss: 0.967294, loss_s1: 0.503080, loss_fp: 0.500346, loss_freq: 0.501917
[12:03:51.107] iteration 925: loss: 1.000157, loss_s1: 0.507181, loss_fp: 0.500239, loss_freq: 0.503621
[12:03:51.727] iteration 926: loss: 0.951370, loss_s1: 0.503294, loss_fp: 0.500667, loss_freq: 0.502639
[12:03:52.349] iteration 927: loss: 0.944694, loss_s1: 0.503787, loss_fp: 0.500163, loss_freq: 0.502581
[12:03:52.983] iteration 928: loss: 0.970508, loss_s1: 0.501939, loss_fp: 0.500293, loss_freq: 0.500996
[12:03:53.601] iteration 929: loss: 1.022824, loss_s1: 0.501695, loss_fp: 0.500167, loss_freq: 0.502943
[12:03:54.252] iteration 930: loss: 0.956761, loss_s1: 0.502743, loss_fp: 0.500117, loss_freq: 0.500866
[12:03:54.871] iteration 931: loss: 0.917892, loss_s1: 0.504662, loss_fp: 0.500318, loss_freq: 0.502712
[12:03:55.493] iteration 932: loss: 1.006827, loss_s1: 0.503791, loss_fp: 0.500407, loss_freq: 0.501426
[12:03:56.114] iteration 933: loss: 0.931806, loss_s1: 0.506200, loss_fp: 0.500185, loss_freq: 0.500739
[12:03:56.735] iteration 934: loss: 0.940834, loss_s1: 0.503524, loss_fp: 0.500235, loss_freq: 0.500814
[12:03:57.356] iteration 935: loss: 0.938786, loss_s1: 0.504040, loss_fp: 0.500253, loss_freq: 0.501305
[12:03:57.971] iteration 936: loss: 0.946890, loss_s1: 0.504321, loss_fp: 0.500133, loss_freq: 0.501416
[12:03:58.591] iteration 937: loss: 0.886670, loss_s1: 0.500755, loss_fp: 0.500109, loss_freq: 0.502578
[12:03:59.216] iteration 938: loss: 1.103755, loss_s1: 0.503415, loss_fp: 0.500172, loss_freq: 0.501366
[12:03:59.831] iteration 939: loss: 0.914670, loss_s1: 0.503276, loss_fp: 0.500324, loss_freq: 0.502766
[12:04:00.444] iteration 940: loss: 0.950111, loss_s1: 0.504534, loss_fp: 0.500090, loss_freq: 0.502074
[12:04:01.084] iteration 941: loss: 1.050609, loss_s1: 0.502701, loss_fp: 0.500268, loss_freq: 0.501016
[12:04:01.711] iteration 942: loss: 0.963592, loss_s1: 0.505641, loss_fp: 0.500272, loss_freq: 0.500463
[12:04:02.327] iteration 943: loss: 0.927947, loss_s1: 0.505043, loss_fp: 0.500183, loss_freq: 0.502615
[12:04:02.942] iteration 944: loss: 0.995497, loss_s1: 0.503176, loss_fp: 0.500213, loss_freq: 0.501460
[12:04:03.559] iteration 945: loss: 1.046106, loss_s1: 0.509996, loss_fp: 0.500192, loss_freq: 0.501386
[12:04:04.171] iteration 946: loss: 0.981900, loss_s1: 0.504237, loss_fp: 0.500125, loss_freq: 0.504177
[12:04:04.797] iteration 947: loss: 0.936231, loss_s1: 0.505168, loss_fp: 0.500151, loss_freq: 0.503911
[12:04:05.441] iteration 948: loss: 0.951254, loss_s1: 0.506326, loss_fp: 0.500169, loss_freq: 0.501193
[12:04:06.103] iteration 949: loss: 0.952719, loss_s1: 0.507638, loss_fp: 0.500252, loss_freq: 0.500833
[12:04:06.847] iteration 950: loss: 0.976795, loss_s1: 0.505575, loss_fp: 0.500298, loss_freq: 0.505266
[12:04:07.536] iteration 951: loss: 0.913566, loss_s1: 0.503560, loss_fp: 0.500292, loss_freq: 0.500847
[12:04:08.201] iteration 952: loss: 0.951540, loss_s1: 0.502551, loss_fp: 0.500413, loss_freq: 0.501476
[12:04:08.853] iteration 953: loss: 0.899822, loss_s1: 0.504634, loss_fp: 0.500267, loss_freq: 0.500299
[12:04:09.515] iteration 954: loss: 0.960813, loss_s1: 0.501833, loss_fp: 0.500320, loss_freq: 0.501026
[12:04:10.174] iteration 955: loss: 0.976871, loss_s1: 0.501852, loss_fp: 0.500190, loss_freq: 0.501501
[12:04:10.786] iteration 956: loss: 0.922164, loss_s1: 0.506286, loss_fp: 0.500194, loss_freq: 0.502478
[12:04:11.396] iteration 957: loss: 1.037390, loss_s1: 0.503808, loss_fp: 0.500100, loss_freq: 0.502238
[12:04:12.014] iteration 958: loss: 1.018056, loss_s1: 0.503681, loss_fp: 0.500222, loss_freq: 0.501264
[12:04:12.635] iteration 959: loss: 0.999215, loss_s1: 0.506380, loss_fp: 0.500265, loss_freq: 0.504374
[12:04:13.248] iteration 960: loss: 0.975223, loss_s1: 0.502900, loss_fp: 0.500631, loss_freq: 0.501917
[12:04:13.867] iteration 961: loss: 0.974442, loss_s1: 0.503270, loss_fp: 0.500292, loss_freq: 0.502399
[12:04:14.489] iteration 962: loss: 0.941965, loss_s1: 0.506875, loss_fp: 0.500625, loss_freq: 0.503134
[12:04:15.113] iteration 963: loss: 1.025743, loss_s1: 0.504296, loss_fp: 0.500153, loss_freq: 0.501763
[12:04:15.734] iteration 964: loss: 1.047937, loss_s1: 0.507385, loss_fp: 0.500262, loss_freq: 0.504351
[12:04:16.361] iteration 965: loss: 0.933059, loss_s1: 0.503059, loss_fp: 0.500381, loss_freq: 0.501547
[12:04:16.976] iteration 966: loss: 0.925163, loss_s1: 0.502617, loss_fp: 0.500205, loss_freq: 0.501820
[12:04:17.590] iteration 967: loss: 1.018423, loss_s1: 0.502230, loss_fp: 0.500202, loss_freq: 0.500767
[12:04:18.205] iteration 968: loss: 0.943340, loss_s1: 0.503261, loss_fp: 0.500203, loss_freq: 0.501318
[12:04:18.823] iteration 969: loss: 0.928191, loss_s1: 0.502494, loss_fp: 0.500311, loss_freq: 0.502363
[12:04:19.441] iteration 970: loss: 0.915887, loss_s1: 0.503133, loss_fp: 0.500199, loss_freq: 0.502361
[12:04:20.067] iteration 971: loss: 0.944206, loss_s1: 0.501633, loss_fp: 0.500181, loss_freq: 0.501334
[12:04:20.690] iteration 972: loss: 0.871048, loss_s1: 0.501019, loss_fp: 0.500245, loss_freq: 0.500822
[12:04:21.314] iteration 973: loss: 1.086784, loss_s1: 0.501989, loss_fp: 0.500226, loss_freq: 0.503363
[12:04:21.935] iteration 974: loss: 0.912127, loss_s1: 0.502755, loss_fp: 0.500109, loss_freq: 0.501604
[12:04:22.556] iteration 975: loss: 0.959138, loss_s1: 0.500470, loss_fp: 0.500182, loss_freq: 0.503227
[12:04:23.169] iteration 976: loss: 1.018674, loss_s1: 0.502711, loss_fp: 0.500197, loss_freq: 0.501865
[12:04:23.800] iteration 977: loss: 0.943458, loss_s1: 0.504022, loss_fp: 0.500210, loss_freq: 0.501348
[12:04:24.415] iteration 978: loss: 0.948527, loss_s1: 0.503255, loss_fp: 0.500400, loss_freq: 0.502819
[12:04:25.029] iteration 979: loss: 0.976607, loss_s1: 0.507145, loss_fp: 0.500328, loss_freq: 0.503182
[12:04:25.641] iteration 980: loss: 1.052516, loss_s1: 0.503977, loss_fp: 0.501100, loss_freq: 0.502562
[12:04:26.255] iteration 981: loss: 1.004094, loss_s1: 0.502458, loss_fp: 0.500217, loss_freq: 0.502428
[12:04:26.865] iteration 982: loss: 0.962232, loss_s1: 0.504865, loss_fp: 0.500198, loss_freq: 0.501309
[12:04:27.477] iteration 983: loss: 0.935388, loss_s1: 0.506533, loss_fp: 0.500166, loss_freq: 0.501320
[12:04:28.093] iteration 984: loss: 0.967734, loss_s1: 0.502689, loss_fp: 0.500381, loss_freq: 0.503084
[12:04:28.705] iteration 985: loss: 0.990513, loss_s1: 0.503342, loss_fp: 0.500330, loss_freq: 0.503174
[12:04:29.351] iteration 986: loss: 0.905371, loss_s1: 0.501138, loss_fp: 0.500202, loss_freq: 0.500851
[12:04:30.002] iteration 987: loss: 0.948541, loss_s1: 0.502503, loss_fp: 0.500115, loss_freq: 0.501806
[12:04:30.654] iteration 988: loss: 0.908269, loss_s1: 0.502466, loss_fp: 0.500328, loss_freq: 0.501459
[12:04:31.308] iteration 989: loss: 0.976906, loss_s1: 0.502040, loss_fp: 0.500216, loss_freq: 0.501638
[12:04:31.919] iteration 990: loss: 0.985093, loss_s1: 0.503057, loss_fp: 0.500217, loss_freq: 0.501107
[12:04:32.533] iteration 991: loss: 0.921983, loss_s1: 0.504553, loss_fp: 0.500253, loss_freq: 0.500949
[12:04:33.184] iteration 992: loss: 1.044957, loss_s1: 0.502615, loss_fp: 0.500245, loss_freq: 0.502258
[12:04:33.796] iteration 993: loss: 0.993955, loss_s1: 0.504329, loss_fp: 0.500408, loss_freq: 0.501009
[12:04:34.416] iteration 994: loss: 0.914167, loss_s1: 0.500797, loss_fp: 0.500712, loss_freq: 0.501182
[12:04:35.029] iteration 995: loss: 0.943415, loss_s1: 0.503227, loss_fp: 0.500119, loss_freq: 0.500763
[12:04:35.643] iteration 996: loss: 0.954535, loss_s1: 0.503318, loss_fp: 0.500382, loss_freq: 0.503645
[12:04:36.261] iteration 997: loss: 0.905531, loss_s1: 0.505850, loss_fp: 0.500998, loss_freq: 0.501522
[12:04:36.888] iteration 998: loss: 0.977739, loss_s1: 0.505395, loss_fp: 0.500448, loss_freq: 0.501223
[12:04:37.511] iteration 999: loss: 1.015008, loss_s1: 0.500457, loss_fp: 0.500323, loss_freq: 0.500829
[12:04:38.128] iteration 1000: loss: 0.934526, loss_s1: 0.506129, loss_fp: 0.500425, loss_freq: 0.503128
[12:04:40.706] iteration 1000 : mean_dice : 0.182401
[12:04:41.351] iteration 1001: loss: 0.924336, loss_s1: 0.501703, loss_fp: 0.500336, loss_freq: 0.504184
[12:04:42.294] iteration 1002: loss: 0.995832, loss_s1: 0.505147, loss_fp: 0.500179, loss_freq: 0.500841
[12:04:42.948] iteration 1003: loss: 0.898648, loss_s1: 0.502929, loss_fp: 0.501537, loss_freq: 0.501059
[12:04:43.610] iteration 1004: loss: 0.902366, loss_s1: 0.501713, loss_fp: 0.500457, loss_freq: 0.503155
[12:04:44.276] iteration 1005: loss: 0.953807, loss_s1: 0.505879, loss_fp: 0.500148, loss_freq: 0.500881
[12:04:44.923] iteration 1006: loss: 0.987766, loss_s1: 0.502192, loss_fp: 0.500229, loss_freq: 0.501894
[12:04:45.557] iteration 1007: loss: 0.932241, loss_s1: 0.503631, loss_fp: 0.500269, loss_freq: 0.501973
[12:04:46.173] iteration 1008: loss: 0.957727, loss_s1: 0.503525, loss_fp: 0.500689, loss_freq: 0.501957
[12:04:46.792] iteration 1009: loss: 0.970451, loss_s1: 0.505767, loss_fp: 0.500613, loss_freq: 0.503737
[12:04:47.405] iteration 1010: loss: 0.909362, loss_s1: 0.505661, loss_fp: 0.500323, loss_freq: 0.504757
[12:04:48.029] iteration 1011: loss: 1.042886, loss_s1: 0.504541, loss_fp: 0.500146, loss_freq: 0.505414
[12:04:48.653] iteration 1012: loss: 0.895125, loss_s1: 0.505195, loss_fp: 0.500429, loss_freq: 0.501385
[12:04:49.331] iteration 1013: loss: 0.896607, loss_s1: 0.503157, loss_fp: 0.500460, loss_freq: 0.503015
[12:04:49.974] iteration 1014: loss: 0.971938, loss_s1: 0.503171, loss_fp: 0.500418, loss_freq: 0.503737
[12:04:50.591] iteration 1015: loss: 0.922964, loss_s1: 0.503789, loss_fp: 0.500377, loss_freq: 0.501146
[12:04:51.223] iteration 1016: loss: 0.934941, loss_s1: 0.503084, loss_fp: 0.500295, loss_freq: 0.501213
[12:04:51.834] iteration 1017: loss: 0.965468, loss_s1: 0.505405, loss_fp: 0.500227, loss_freq: 0.501363
[12:04:52.455] iteration 1018: loss: 1.121076, loss_s1: 0.502025, loss_fp: 0.500452, loss_freq: 0.501549
[12:04:53.081] iteration 1019: loss: 1.028521, loss_s1: 0.501808, loss_fp: 0.500223, loss_freq: 0.502881
[12:04:53.700] iteration 1020: loss: 0.915224, loss_s1: 0.502802, loss_fp: 0.500062, loss_freq: 0.503040
[12:04:54.365] iteration 1021: loss: 0.949865, loss_s1: 0.501650, loss_fp: 0.500365, loss_freq: 0.501961
[12:04:55.071] iteration 1022: loss: 0.944423, loss_s1: 0.501624, loss_fp: 0.500326, loss_freq: 0.501972
[12:04:55.727] iteration 1023: loss: 0.903289, loss_s1: 0.501439, loss_fp: 0.500549, loss_freq: 0.505095
[12:04:56.384] iteration 1024: loss: 0.927653, loss_s1: 0.504205, loss_fp: 0.500282, loss_freq: 0.502666
[12:04:57.041] iteration 1025: loss: 0.920710, loss_s1: 0.502843, loss_fp: 0.500160, loss_freq: 0.502231
[12:04:57.714] iteration 1026: loss: 0.874158, loss_s1: 0.501487, loss_fp: 0.500232, loss_freq: 0.501421
[12:04:58.381] iteration 1027: loss: 0.954922, loss_s1: 0.501336, loss_fp: 0.500298, loss_freq: 0.500421
[12:04:58.999] iteration 1028: loss: 1.004097, loss_s1: 0.501389, loss_fp: 0.500185, loss_freq: 0.501152
[12:04:59.679] iteration 1029: loss: 0.922247, loss_s1: 0.502803, loss_fp: 0.500205, loss_freq: 0.502546
[12:05:00.296] iteration 1030: loss: 1.068383, loss_s1: 0.502476, loss_fp: 0.500348, loss_freq: 0.502000
[12:05:00.913] iteration 1031: loss: 0.999442, loss_s1: 0.503091, loss_fp: 0.500346, loss_freq: 0.500425
[12:05:01.540] iteration 1032: loss: 0.935882, loss_s1: 0.502642, loss_fp: 0.500326, loss_freq: 0.501295
[12:05:02.211] iteration 1033: loss: 0.983567, loss_s1: 0.503507, loss_fp: 0.500269, loss_freq: 0.500870
[12:05:02.869] iteration 1034: loss: 0.938979, loss_s1: 0.500562, loss_fp: 0.500177, loss_freq: 0.501649
[12:05:03.532] iteration 1035: loss: 0.921367, loss_s1: 0.502763, loss_fp: 0.500304, loss_freq: 0.500475
[12:05:04.185] iteration 1036: loss: 0.978546, loss_s1: 0.503691, loss_fp: 0.500181, loss_freq: 0.500588
[12:05:04.815] iteration 1037: loss: 1.023114, loss_s1: 0.506598, loss_fp: 0.500161, loss_freq: 0.501545
[12:05:05.430] iteration 1038: loss: 0.920047, loss_s1: 0.501581, loss_fp: 0.500175, loss_freq: 0.502079
[12:05:06.052] iteration 1039: loss: 0.922883, loss_s1: 0.500893, loss_fp: 0.500213, loss_freq: 0.501313
[12:05:06.679] iteration 1040: loss: 0.959461, loss_s1: 0.503990, loss_fp: 0.500129, loss_freq: 0.501856
[12:05:07.294] iteration 1041: loss: 0.919029, loss_s1: 0.502300, loss_fp: 0.500120, loss_freq: 0.501734
[12:05:07.910] iteration 1042: loss: 0.947395, loss_s1: 0.510303, loss_fp: 0.500219, loss_freq: 0.503343
[12:05:08.530] iteration 1043: loss: 0.936711, loss_s1: 0.504915, loss_fp: 0.500347, loss_freq: 0.502788
[12:05:09.144] iteration 1044: loss: 0.912973, loss_s1: 0.502809, loss_fp: 0.500264, loss_freq: 0.502875
[12:05:09.759] iteration 1045: loss: 0.880693, loss_s1: 0.502089, loss_fp: 0.500167, loss_freq: 0.503036
[12:05:10.375] iteration 1046: loss: 1.077965, loss_s1: 0.503853, loss_fp: 0.500305, loss_freq: 0.504578
[12:05:10.999] iteration 1047: loss: 0.904574, loss_s1: 0.504285, loss_fp: 0.500546, loss_freq: 0.501845
[12:05:11.622] iteration 1048: loss: 0.935713, loss_s1: 0.500823, loss_fp: 0.500187, loss_freq: 0.503297
[12:05:12.256] iteration 1049: loss: 0.972094, loss_s1: 0.502144, loss_fp: 0.500273, loss_freq: 0.501663
[12:05:12.886] iteration 1050: loss: 0.955924, loss_s1: 0.503648, loss_fp: 0.500388, loss_freq: 0.501994
[12:05:13.550] iteration 1051: loss: 0.947974, loss_s1: 0.503484, loss_fp: 0.500321, loss_freq: 0.502606
[12:05:14.211] iteration 1052: loss: 0.948897, loss_s1: 0.504795, loss_fp: 0.500201, loss_freq: 0.503066
[12:05:14.867] iteration 1053: loss: 1.060452, loss_s1: 0.508113, loss_fp: 0.500442, loss_freq: 0.500772
[12:05:15.498] iteration 1054: loss: 0.992868, loss_s1: 0.502335, loss_fp: 0.500281, loss_freq: 0.504363
[12:05:16.115] iteration 1055: loss: 0.914746, loss_s1: 0.503521, loss_fp: 0.500176, loss_freq: 0.500599
[12:05:16.735] iteration 1056: loss: 0.934799, loss_s1: 0.504209, loss_fp: 0.500376, loss_freq: 0.503226
[12:05:17.354] iteration 1057: loss: 0.966065, loss_s1: 0.501854, loss_fp: 0.500098, loss_freq: 0.500992
[12:05:17.988] iteration 1058: loss: 0.950379, loss_s1: 0.507521, loss_fp: 0.500198, loss_freq: 0.502077
[12:05:18.612] iteration 1059: loss: 0.914634, loss_s1: 0.501055, loss_fp: 0.500200, loss_freq: 0.500507
[12:05:19.231] iteration 1060: loss: 0.992754, loss_s1: 0.501910, loss_fp: 0.500134, loss_freq: 0.501173
[12:05:19.864] iteration 1061: loss: 0.929261, loss_s1: 0.502301, loss_fp: 0.500292, loss_freq: 0.500730
[12:05:20.484] iteration 1062: loss: 0.952433, loss_s1: 0.502218, loss_fp: 0.500242, loss_freq: 0.500455
[12:05:21.104] iteration 1063: loss: 0.993860, loss_s1: 0.505029, loss_fp: 0.500079, loss_freq: 0.501733
[12:05:21.740] iteration 1064: loss: 0.909739, loss_s1: 0.506023, loss_fp: 0.500357, loss_freq: 0.502579
[12:05:22.405] iteration 1065: loss: 1.013236, loss_s1: 0.502542, loss_fp: 0.500192, loss_freq: 0.501672
[12:05:23.077] iteration 1066: loss: 0.969243, loss_s1: 0.504264, loss_fp: 0.500140, loss_freq: 0.502513
[12:05:23.746] iteration 1067: loss: 0.949540, loss_s1: 0.501763, loss_fp: 0.500370, loss_freq: 0.502860
[12:05:24.416] iteration 1068: loss: 0.975392, loss_s1: 0.504847, loss_fp: 0.500205, loss_freq: 0.501823
[12:05:25.050] iteration 1069: loss: 0.949575, loss_s1: 0.501427, loss_fp: 0.500424, loss_freq: 0.501771
[12:05:25.681] iteration 1070: loss: 0.954497, loss_s1: 0.505086, loss_fp: 0.500286, loss_freq: 0.502515
[12:05:26.315] iteration 1071: loss: 0.971467, loss_s1: 0.502294, loss_fp: 0.500149, loss_freq: 0.502224
[12:05:26.954] iteration 1072: loss: 1.022459, loss_s1: 0.503860, loss_fp: 0.500303, loss_freq: 0.501706
[12:05:27.613] iteration 1073: loss: 0.935410, loss_s1: 0.501603, loss_fp: 0.500174, loss_freq: 0.500729
[12:05:28.235] iteration 1074: loss: 0.887566, loss_s1: 0.504637, loss_fp: 0.500229, loss_freq: 0.501680
[12:05:28.844] iteration 1075: loss: 1.007836, loss_s1: 0.503290, loss_fp: 0.500078, loss_freq: 0.501378
[12:05:29.464] iteration 1076: loss: 0.895718, loss_s1: 0.501821, loss_fp: 0.500277, loss_freq: 0.500869
[12:05:30.076] iteration 1077: loss: 0.929840, loss_s1: 0.504557, loss_fp: 0.500282, loss_freq: 0.501081
[12:05:30.696] iteration 1078: loss: 0.907495, loss_s1: 0.502898, loss_fp: 0.500305, loss_freq: 0.501628
[12:05:31.310] iteration 1079: loss: 0.964184, loss_s1: 0.500744, loss_fp: 0.500300, loss_freq: 0.501775
[12:05:31.938] iteration 1080: loss: 0.910010, loss_s1: 0.503729, loss_fp: 0.500549, loss_freq: 0.503225
[12:05:32.557] iteration 1081: loss: 1.098682, loss_s1: 0.501135, loss_fp: 0.500344, loss_freq: 0.502456
[12:05:33.173] iteration 1082: loss: 0.926418, loss_s1: 0.501560, loss_fp: 0.500189, loss_freq: 0.503149
[12:05:33.792] iteration 1083: loss: 0.941338, loss_s1: 0.504834, loss_fp: 0.500173, loss_freq: 0.501911
[12:05:34.408] iteration 1084: loss: 0.988037, loss_s1: 0.500686, loss_fp: 0.500205, loss_freq: 0.500507
[12:05:35.023] iteration 1085: loss: 0.930774, loss_s1: 0.503829, loss_fp: 0.500267, loss_freq: 0.501019
[12:05:35.660] iteration 1086: loss: 0.955444, loss_s1: 0.502712, loss_fp: 0.500314, loss_freq: 0.502371
[12:05:36.276] iteration 1087: loss: 0.952164, loss_s1: 0.504776, loss_fp: 0.500206, loss_freq: 0.502496
[12:05:36.891] iteration 1088: loss: 1.028442, loss_s1: 0.501257, loss_fp: 0.500195, loss_freq: 0.501697
[12:05:37.512] iteration 1089: loss: 1.012710, loss_s1: 0.505358, loss_fp: 0.500273, loss_freq: 0.503719
[12:05:38.164] iteration 1090: loss: 0.919886, loss_s1: 0.503979, loss_fp: 0.500185, loss_freq: 0.506371
[12:05:38.783] iteration 1091: loss: 0.959640, loss_s1: 0.503804, loss_fp: 0.500297, loss_freq: 0.500846
[12:05:39.404] iteration 1092: loss: 0.968270, loss_s1: 0.508870, loss_fp: 0.500127, loss_freq: 0.500934
[12:05:40.028] iteration 1093: loss: 0.997450, loss_s1: 0.505811, loss_fp: 0.500091, loss_freq: 0.504702
[12:05:40.647] iteration 1094: loss: 0.917205, loss_s1: 0.501855, loss_fp: 0.500106, loss_freq: 0.500463
[12:05:41.268] iteration 1095: loss: 0.963277, loss_s1: 0.503757, loss_fp: 0.500110, loss_freq: 0.500742
[12:05:41.888] iteration 1096: loss: 0.917204, loss_s1: 0.503074, loss_fp: 0.500208, loss_freq: 0.500214
[12:05:42.513] iteration 1097: loss: 0.956319, loss_s1: 0.501919, loss_fp: 0.500148, loss_freq: 0.500820
[12:05:43.137] iteration 1098: loss: 0.943725, loss_s1: 0.506854, loss_fp: 0.500334, loss_freq: 0.501843
[12:05:43.758] iteration 1099: loss: 0.922802, loss_s1: 0.502636, loss_fp: 0.500292, loss_freq: 0.502224
[12:05:44.378] iteration 1100: loss: 1.087116, loss_s1: 0.503462, loss_fp: 0.500103, loss_freq: 0.501559
[12:05:44.982] iteration 1101: loss: 0.970324, loss_s1: 0.505020, loss_fp: 0.500179, loss_freq: 0.502121
[12:05:45.599] iteration 1102: loss: 0.995104, loss_s1: 0.506380, loss_fp: 0.500301, loss_freq: 0.504911
[12:05:46.211] iteration 1103: loss: 0.957533, loss_s1: 0.501845, loss_fp: 0.500293, loss_freq: 0.501497
[12:05:46.841] iteration 1104: loss: 0.943900, loss_s1: 0.503872, loss_fp: 0.500242, loss_freq: 0.501607
[12:05:47.465] iteration 1105: loss: 0.914308, loss_s1: 0.503625, loss_fp: 0.500357, loss_freq: 0.503179
[12:05:48.096] iteration 1106: loss: 0.993182, loss_s1: 0.501172, loss_fp: 0.500160, loss_freq: 0.500664
[12:05:48.726] iteration 1107: loss: 0.995137, loss_s1: 0.502680, loss_fp: 0.500113, loss_freq: 0.501618
[12:05:49.353] iteration 1108: loss: 0.907653, loss_s1: 0.503810, loss_fp: 0.500419, loss_freq: 0.501301
[12:05:49.985] iteration 1109: loss: 0.897878, loss_s1: 0.501819, loss_fp: 0.500269, loss_freq: 0.501058
[12:05:50.612] iteration 1110: loss: 0.972170, loss_s1: 0.503422, loss_fp: 0.500335, loss_freq: 0.501572
[12:05:51.276] iteration 1111: loss: 0.939187, loss_s1: 0.504265, loss_fp: 0.500129, loss_freq: 0.500797
[12:05:51.933] iteration 1112: loss: 0.937402, loss_s1: 0.502334, loss_fp: 0.500077, loss_freq: 0.502457
[12:05:52.552] iteration 1113: loss: 0.889295, loss_s1: 0.502920, loss_fp: 0.500136, loss_freq: 0.501301
[12:05:53.169] iteration 1114: loss: 0.923325, loss_s1: 0.504979, loss_fp: 0.500277, loss_freq: 0.500936
[12:05:53.788] iteration 1115: loss: 0.862662, loss_s1: 0.503501, loss_fp: 0.500505, loss_freq: 0.501417
[12:05:54.438] iteration 1116: loss: 1.076005, loss_s1: 0.503824, loss_fp: 0.500161, loss_freq: 0.504476
[12:05:55.089] iteration 1117: loss: 0.877711, loss_s1: 0.501430, loss_fp: 0.500182, loss_freq: 0.501586
[12:05:55.720] iteration 1118: loss: 0.927215, loss_s1: 0.502305, loss_fp: 0.500154, loss_freq: 0.502943
[12:05:56.344] iteration 1119: loss: 0.980611, loss_s1: 0.504333, loss_fp: 0.500144, loss_freq: 0.503099
[12:05:56.965] iteration 1120: loss: 0.921101, loss_s1: 0.504166, loss_fp: 0.500281, loss_freq: 0.505031
[12:05:57.585] iteration 1121: loss: 0.933195, loss_s1: 0.504206, loss_fp: 0.500339, loss_freq: 0.503070
[12:05:58.200] iteration 1122: loss: 0.972740, loss_s1: 0.505614, loss_fp: 0.500174, loss_freq: 0.503126
[12:05:58.813] iteration 1123: loss: 1.088509, loss_s1: 0.504536, loss_fp: 0.500128, loss_freq: 0.505129
[12:05:59.422] iteration 1124: loss: 1.015391, loss_s1: 0.500759, loss_fp: 0.500134, loss_freq: 0.502025
[12:06:00.042] iteration 1125: loss: 0.869468, loss_s1: 0.505303, loss_fp: 0.500193, loss_freq: 0.501267
[12:06:00.673] iteration 1126: loss: 0.957742, loss_s1: 0.505001, loss_fp: 0.500794, loss_freq: 0.500963
[12:06:01.288] iteration 1127: loss: 0.952018, loss_s1: 0.507052, loss_fp: 0.500105, loss_freq: 0.504235
[12:06:01.920] iteration 1128: loss: 0.991613, loss_s1: 0.504265, loss_fp: 0.500356, loss_freq: 0.502214
[12:06:02.590] iteration 1129: loss: 0.895100, loss_s1: 0.504037, loss_fp: 0.500184, loss_freq: 0.501325
[12:06:03.241] iteration 1130: loss: 0.930106, loss_s1: 0.503623, loss_fp: 0.500110, loss_freq: 0.502637
[12:06:03.892] iteration 1131: loss: 0.911866, loss_s1: 0.504957, loss_fp: 0.500165, loss_freq: 0.502942
[12:06:04.544] iteration 1132: loss: 0.954214, loss_s1: 0.503137, loss_fp: 0.500088, loss_freq: 0.501894
[12:06:05.198] iteration 1133: loss: 0.963303, loss_s1: 0.503078, loss_fp: 0.500180, loss_freq: 0.501715
[12:06:05.863] iteration 1134: loss: 0.946880, loss_s1: 0.506231, loss_fp: 0.500366, loss_freq: 0.501187
[12:06:06.509] iteration 1135: loss: 1.028785, loss_s1: 0.506141, loss_fp: 0.500293, loss_freq: 0.501712
[12:06:07.128] iteration 1136: loss: 1.006930, loss_s1: 0.502754, loss_fp: 0.500198, loss_freq: 0.501082
[12:06:07.751] iteration 1137: loss: 0.943042, loss_s1: 0.503532, loss_fp: 0.500269, loss_freq: 0.502045
[12:06:08.375] iteration 1138: loss: 0.935226, loss_s1: 0.502491, loss_fp: 0.500206, loss_freq: 0.500423
[12:06:08.998] iteration 1139: loss: 0.957917, loss_s1: 0.504922, loss_fp: 0.500359, loss_freq: 0.502055
[12:06:09.912] iteration 1140: loss: 0.918949, loss_s1: 0.502868, loss_fp: 0.500226, loss_freq: 0.501385
[12:06:10.728] iteration 1141: loss: 0.963114, loss_s1: 0.503476, loss_fp: 0.500177, loss_freq: 0.502738
[12:06:11.483] iteration 1142: loss: 0.991833, loss_s1: 0.502410, loss_fp: 0.500105, loss_freq: 0.501125
[12:06:12.126] iteration 1143: loss: 0.909462, loss_s1: 0.505110, loss_fp: 0.500197, loss_freq: 0.503889
[12:06:12.730] iteration 1144: loss: 0.899441, loss_s1: 0.502156, loss_fp: 0.500196, loss_freq: 0.504091
[12:06:13.649] iteration 1145: loss: 0.966527, loss_s1: 0.504516, loss_fp: 0.500242, loss_freq: 0.500850
[12:06:14.270] iteration 1146: loss: 0.913419, loss_s1: 0.505158, loss_fp: 0.500247, loss_freq: 0.501560
[12:06:14.890] iteration 1147: loss: 0.874040, loss_s1: 0.501366, loss_fp: 0.500442, loss_freq: 0.504170
[12:06:15.567] iteration 1148: loss: 0.969760, loss_s1: 0.508571, loss_fp: 0.500586, loss_freq: 0.501135
[12:06:16.218] iteration 1149: loss: 0.917034, loss_s1: 0.502811, loss_fp: 0.500135, loss_freq: 0.501547
[12:06:16.872] iteration 1150: loss: 0.925369, loss_s1: 0.503207, loss_fp: 0.500286, loss_freq: 0.501775
[12:06:17.508] iteration 1151: loss: 0.862614, loss_s1: 0.502112, loss_fp: 0.500161, loss_freq: 0.503486
[12:06:18.134] iteration 1152: loss: 0.955924, loss_s1: 0.504072, loss_fp: 0.500505, loss_freq: 0.502460
[12:06:18.752] iteration 1153: loss: 0.886452, loss_s1: 0.502932, loss_fp: 0.500450, loss_freq: 0.503365
[12:06:19.371] iteration 1154: loss: 1.041593, loss_s1: 0.504231, loss_fp: 0.500157, loss_freq: 0.503780
[12:06:19.987] iteration 1155: loss: 0.903075, loss_s1: 0.503158, loss_fp: 0.500202, loss_freq: 0.501063
[12:06:20.609] iteration 1156: loss: 0.925971, loss_s1: 0.506201, loss_fp: 0.500181, loss_freq: 0.501546
[12:06:21.226] iteration 1157: loss: 0.958022, loss_s1: 0.502866, loss_fp: 0.500088, loss_freq: 0.501843
[12:06:21.849] iteration 1158: loss: 0.903186, loss_s1: 0.504400, loss_fp: 0.500250, loss_freq: 0.501426
[12:06:22.470] iteration 1159: loss: 0.932566, loss_s1: 0.503165, loss_fp: 0.500566, loss_freq: 0.500589
[12:06:23.093] iteration 1160: loss: 0.941791, loss_s1: 0.505731, loss_fp: 0.500145, loss_freq: 0.501483
[12:06:23.713] iteration 1161: loss: 1.139577, loss_s1: 0.505277, loss_fp: 0.500374, loss_freq: 0.501361
[12:06:24.329] iteration 1162: loss: 1.005131, loss_s1: 0.502203, loss_fp: 0.500081, loss_freq: 0.502899
[12:06:24.942] iteration 1163: loss: 0.866598, loss_s1: 0.504061, loss_fp: 0.500336, loss_freq: 0.502311
[12:06:25.586] iteration 1164: loss: 0.938406, loss_s1: 0.506218, loss_fp: 0.500335, loss_freq: 0.500894
[12:06:26.268] iteration 1165: loss: 0.965283, loss_s1: 0.505213, loss_fp: 0.500114, loss_freq: 0.502679
[12:06:26.933] iteration 1166: loss: 0.969928, loss_s1: 0.506098, loss_fp: 0.500550, loss_freq: 0.502809
[12:06:27.593] iteration 1167: loss: 0.904579, loss_s1: 0.502742, loss_fp: 0.500266, loss_freq: 0.502794
[12:06:28.228] iteration 1168: loss: 0.934629, loss_s1: 0.502437, loss_fp: 0.500182, loss_freq: 0.500880
[12:06:28.841] iteration 1169: loss: 0.898471, loss_s1: 0.503226, loss_fp: 0.500254, loss_freq: 0.501331
[12:06:29.452] iteration 1170: loss: 0.938750, loss_s1: 0.507961, loss_fp: 0.500180, loss_freq: 0.500648
[12:06:30.066] iteration 1171: loss: 0.958052, loss_s1: 0.501936, loss_fp: 0.500089, loss_freq: 0.501707
[12:06:30.688] iteration 1172: loss: 0.910219, loss_s1: 0.502767, loss_fp: 0.500254, loss_freq: 0.501924
[12:06:31.306] iteration 1173: loss: 1.056656, loss_s1: 0.503850, loss_fp: 0.500172, loss_freq: 0.502039
[12:06:31.923] iteration 1174: loss: 0.953829, loss_s1: 0.504710, loss_fp: 0.500177, loss_freq: 0.501064
[12:06:32.536] iteration 1175: loss: 0.962043, loss_s1: 0.504791, loss_fp: 0.500167, loss_freq: 0.501406
[12:06:33.154] iteration 1176: loss: 0.971726, loss_s1: 0.502804, loss_fp: 0.500159, loss_freq: 0.501412
[12:06:33.773] iteration 1177: loss: 0.955156, loss_s1: 0.505254, loss_fp: 0.500143, loss_freq: 0.501787
[12:06:34.385] iteration 1178: loss: 0.917942, loss_s1: 0.502319, loss_fp: 0.500460, loss_freq: 0.501522
[12:06:35.002] iteration 1179: loss: 0.979264, loss_s1: 0.504873, loss_fp: 0.500264, loss_freq: 0.501616
[12:06:35.617] iteration 1180: loss: 0.992371, loss_s1: 0.503624, loss_fp: 0.500190, loss_freq: 0.501772
[12:06:36.253] iteration 1181: loss: 0.905208, loss_s1: 0.503658, loss_fp: 0.500110, loss_freq: 0.501775
[12:06:36.938] iteration 1182: loss: 0.897757, loss_s1: 0.503234, loss_fp: 0.500117, loss_freq: 0.501986
[12:06:37.628] iteration 1183: loss: 1.000185, loss_s1: 0.504499, loss_fp: 0.500063, loss_freq: 0.501905
[12:06:38.277] iteration 1184: loss: 0.943973, loss_s1: 0.506517, loss_fp: 0.500171, loss_freq: 0.501728
[12:06:38.933] iteration 1185: loss: 0.941021, loss_s1: 0.506970, loss_fp: 0.500265, loss_freq: 0.504993
[12:06:39.595] iteration 1186: loss: 0.910961, loss_s1: 0.504885, loss_fp: 0.500452, loss_freq: 0.502798
[12:06:40.251] iteration 1187: loss: 0.928936, loss_s1: 0.501871, loss_fp: 0.500153, loss_freq: 0.502160
[12:06:40.907] iteration 1188: loss: 0.899696, loss_s1: 0.502473, loss_fp: 0.500300, loss_freq: 0.502608
[12:06:41.562] iteration 1189: loss: 1.059047, loss_s1: 0.503491, loss_fp: 0.500102, loss_freq: 0.502233
[12:06:42.217] iteration 1190: loss: 0.914955, loss_s1: 0.501890, loss_fp: 0.500165, loss_freq: 0.501582
[12:06:42.835] iteration 1191: loss: 0.950902, loss_s1: 0.502407, loss_fp: 0.500091, loss_freq: 0.501923
[12:06:43.453] iteration 1192: loss: 0.995454, loss_s1: 0.502468, loss_fp: 0.500255, loss_freq: 0.500972
[12:06:44.092] iteration 1193: loss: 0.929111, loss_s1: 0.501702, loss_fp: 0.500265, loss_freq: 0.500954
[12:06:44.717] iteration 1194: loss: 0.922871, loss_s1: 0.505116, loss_fp: 0.500138, loss_freq: 0.501899
[12:06:45.339] iteration 1195: loss: 0.971572, loss_s1: 0.505074, loss_fp: 0.500216, loss_freq: 0.502604
[12:06:45.960] iteration 1196: loss: 1.038546, loss_s1: 0.502572, loss_fp: 0.500160, loss_freq: 0.501610
[12:06:46.592] iteration 1197: loss: 0.992944, loss_s1: 0.506106, loss_fp: 0.500145, loss_freq: 0.502903
[12:06:47.247] iteration 1198: loss: 0.901740, loss_s1: 0.502819, loss_fp: 0.500099, loss_freq: 0.500658
[12:06:47.878] iteration 1199: loss: 0.939364, loss_s1: 0.505057, loss_fp: 0.500177, loss_freq: 0.503066
[12:06:48.507] iteration 1200: loss: 0.958485, loss_s1: 0.504877, loss_fp: 0.500236, loss_freq: 0.501358
[12:06:51.257] iteration 1200 : mean_dice : 0.156243
[12:06:51.927] iteration 1201: loss: 0.997340, loss_s1: 0.507577, loss_fp: 0.500292, loss_freq: 0.503009
[12:06:52.590] iteration 1202: loss: 0.901734, loss_s1: 0.505438, loss_fp: 0.500171, loss_freq: 0.501163
[12:06:53.247] iteration 1203: loss: 0.990996, loss_s1: 0.501596, loss_fp: 0.500214, loss_freq: 0.500521
[12:06:53.908] iteration 1204: loss: 0.888638, loss_s1: 0.506210, loss_fp: 0.500278, loss_freq: 0.502375
[12:06:54.570] iteration 1205: loss: 0.931309, loss_s1: 0.502136, loss_fp: 0.500093, loss_freq: 0.500277
[12:06:55.228] iteration 1206: loss: 0.995715, loss_s1: 0.501355, loss_fp: 0.500155, loss_freq: 0.501885
[12:06:55.863] iteration 1207: loss: 0.948555, loss_s1: 0.504279, loss_fp: 0.500171, loss_freq: 0.501724
[12:06:56.487] iteration 1208: loss: 1.012644, loss_s1: 0.501481, loss_fp: 0.500145, loss_freq: 0.500907
[12:06:57.107] iteration 1209: loss: 0.934873, loss_s1: 0.504675, loss_fp: 0.500435, loss_freq: 0.501547
[12:06:57.724] iteration 1210: loss: 0.938685, loss_s1: 0.503674, loss_fp: 0.500315, loss_freq: 0.501264
[12:06:58.333] iteration 1211: loss: 0.962400, loss_s1: 0.504302, loss_fp: 0.500208, loss_freq: 0.500993
[12:06:58.945] iteration 1212: loss: 0.953287, loss_s1: 0.502686, loss_fp: 0.500248, loss_freq: 0.501033
[12:06:59.557] iteration 1213: loss: 0.913074, loss_s1: 0.500973, loss_fp: 0.500126, loss_freq: 0.501416
[12:07:00.170] iteration 1214: loss: 0.960004, loss_s1: 0.501409, loss_fp: 0.500632, loss_freq: 0.500614
[12:07:00.781] iteration 1215: loss: 0.981302, loss_s1: 0.501713, loss_fp: 0.500215, loss_freq: 0.501141
[12:07:01.396] iteration 1216: loss: 0.906889, loss_s1: 0.500628, loss_fp: 0.500142, loss_freq: 0.500704
[12:07:02.053] iteration 1217: loss: 0.885706, loss_s1: 0.502035, loss_fp: 0.500192, loss_freq: 0.501099
[12:07:02.691] iteration 1218: loss: 0.981708, loss_s1: 0.503033, loss_fp: 0.500117, loss_freq: 0.502456
[12:07:03.310] iteration 1219: loss: 0.907529, loss_s1: 0.503751, loss_fp: 0.500194, loss_freq: 0.501604
[12:07:03.927] iteration 1220: loss: 0.914326, loss_s1: 0.501984, loss_fp: 0.500315, loss_freq: 0.500328
[12:07:04.565] iteration 1221: loss: 0.884324, loss_s1: 0.502588, loss_fp: 0.500162, loss_freq: 0.501298
[12:07:05.175] iteration 1222: loss: 0.935732, loss_s1: 0.502756, loss_fp: 0.500226, loss_freq: 0.501985
[12:07:05.793] iteration 1223: loss: 0.891522, loss_s1: 0.504225, loss_fp: 0.501301, loss_freq: 0.503244
[12:07:06.409] iteration 1224: loss: 1.095877, loss_s1: 0.500726, loss_fp: 0.500107, loss_freq: 0.501375
[12:07:07.020] iteration 1225: loss: 0.911752, loss_s1: 0.502192, loss_fp: 0.500182, loss_freq: 0.502605
[12:07:07.640] iteration 1226: loss: 0.920042, loss_s1: 0.505293, loss_fp: 0.500190, loss_freq: 0.501893
[12:07:08.262] iteration 1227: loss: 0.945724, loss_s1: 0.503195, loss_fp: 0.500271, loss_freq: 0.500582
[12:07:08.871] iteration 1228: loss: 0.906570, loss_s1: 0.506879, loss_fp: 0.500224, loss_freq: 0.501381
[12:07:09.480] iteration 1229: loss: 0.970545, loss_s1: 0.501491, loss_fp: 0.500801, loss_freq: 0.501082
[12:07:10.097] iteration 1230: loss: 0.941478, loss_s1: 0.502941, loss_fp: 0.500415, loss_freq: 0.501091
[12:07:10.722] iteration 1231: loss: 1.020403, loss_s1: 0.505243, loss_fp: 0.500214, loss_freq: 0.501414
[12:07:11.340] iteration 1232: loss: 0.963607, loss_s1: 0.505278, loss_fp: 0.500178, loss_freq: 0.502328
[12:07:11.997] iteration 1233: loss: 0.886700, loss_s1: 0.508432, loss_fp: 0.500285, loss_freq: 0.505438
[12:07:12.617] iteration 1234: loss: 0.920164, loss_s1: 0.501599, loss_fp: 0.500102, loss_freq: 0.500901
[12:07:13.234] iteration 1235: loss: 0.960274, loss_s1: 0.504574, loss_fp: 0.500074, loss_freq: 0.501323
[12:07:13.849] iteration 1236: loss: 0.971987, loss_s1: 0.504225, loss_fp: 0.500373, loss_freq: 0.504737
[12:07:14.469] iteration 1237: loss: 0.921619, loss_s1: 0.504762, loss_fp: 0.500228, loss_freq: 0.501106
[12:07:15.085] iteration 1238: loss: 0.950713, loss_s1: 0.502877, loss_fp: 0.500120, loss_freq: 0.500930
[12:07:15.706] iteration 1239: loss: 0.907072, loss_s1: 0.502386, loss_fp: 0.500292, loss_freq: 0.500476
[12:07:16.328] iteration 1240: loss: 0.946043, loss_s1: 0.502772, loss_fp: 0.500301, loss_freq: 0.500878
[12:07:16.953] iteration 1241: loss: 0.954184, loss_s1: 0.508493, loss_fp: 0.500180, loss_freq: 0.502568
[12:07:17.571] iteration 1242: loss: 0.957884, loss_s1: 0.502062, loss_fp: 0.500152, loss_freq: 0.502568
[12:07:18.190] iteration 1243: loss: 0.992610, loss_s1: 0.501949, loss_fp: 0.500120, loss_freq: 0.501669
[12:07:18.805] iteration 1244: loss: 1.015332, loss_s1: 0.504250, loss_fp: 0.500149, loss_freq: 0.503558
[12:07:19.424] iteration 1245: loss: 0.962458, loss_s1: 0.502550, loss_fp: 0.500282, loss_freq: 0.503725
[12:07:20.040] iteration 1246: loss: 0.945284, loss_s1: 0.503781, loss_fp: 0.500471, loss_freq: 0.501264
[12:07:20.658] iteration 1247: loss: 0.970320, loss_s1: 0.501381, loss_fp: 0.500263, loss_freq: 0.501507
[12:07:21.274] iteration 1248: loss: 0.914294, loss_s1: 0.501237, loss_fp: 0.500147, loss_freq: 0.501327
[12:07:21.898] iteration 1249: loss: 0.992827, loss_s1: 0.501670, loss_fp: 0.500241, loss_freq: 0.500765
[12:07:22.520] iteration 1250: loss: 1.029453, loss_s1: 0.504128, loss_fp: 0.500070, loss_freq: 0.502944
[12:07:23.140] iteration 1251: loss: 0.901083, loss_s1: 0.503089, loss_fp: 0.500115, loss_freq: 0.500870
[12:07:23.758] iteration 1252: loss: 0.896761, loss_s1: 0.500736, loss_fp: 0.500193, loss_freq: 0.501117
[12:07:24.381] iteration 1253: loss: 0.981485, loss_s1: 0.502972, loss_fp: 0.500192, loss_freq: 0.500861
[12:07:25.002] iteration 1254: loss: 0.905489, loss_s1: 0.501914, loss_fp: 0.500200, loss_freq: 0.500356
[12:07:25.674] iteration 1255: loss: 0.938564, loss_s1: 0.504281, loss_fp: 0.500200, loss_freq: 0.501578
[12:07:26.331] iteration 1256: loss: 0.924646, loss_s1: 0.503345, loss_fp: 0.500072, loss_freq: 0.502223
[12:07:26.990] iteration 1257: loss: 0.933673, loss_s1: 0.503147, loss_fp: 0.500267, loss_freq: 0.501347
[12:07:27.657] iteration 1258: loss: 0.862318, loss_s1: 0.501159, loss_fp: 0.500511, loss_freq: 0.502223
[12:07:28.311] iteration 1259: loss: 1.054637, loss_s1: 0.502306, loss_fp: 0.500212, loss_freq: 0.503424
[12:07:28.966] iteration 1260: loss: 0.911521, loss_s1: 0.502477, loss_fp: 0.500318, loss_freq: 0.501747
[12:07:29.625] iteration 1261: loss: 0.931967, loss_s1: 0.501672, loss_fp: 0.500108, loss_freq: 0.503144
[12:07:30.283] iteration 1262: loss: 0.962701, loss_s1: 0.504478, loss_fp: 0.500234, loss_freq: 0.503175
[12:07:30.940] iteration 1263: loss: 0.913926, loss_s1: 0.505304, loss_fp: 0.500162, loss_freq: 0.501960
[12:07:31.594] iteration 1264: loss: 0.943928, loss_s1: 0.504636, loss_fp: 0.500273, loss_freq: 0.501322
[12:07:32.210] iteration 1265: loss: 0.955165, loss_s1: 0.505827, loss_fp: 0.500459, loss_freq: 0.503965
[12:07:32.825] iteration 1266: loss: 1.010977, loss_s1: 0.507651, loss_fp: 0.500204, loss_freq: 0.502854
[12:07:33.470] iteration 1267: loss: 1.004301, loss_s1: 0.503758, loss_fp: 0.500206, loss_freq: 0.501660
[12:07:34.126] iteration 1268: loss: 0.910783, loss_s1: 0.505637, loss_fp: 0.500150, loss_freq: 0.501026
[12:07:34.779] iteration 1269: loss: 0.886030, loss_s1: 0.505294, loss_fp: 0.500573, loss_freq: 0.501225
[12:07:35.434] iteration 1270: loss: 0.954411, loss_s1: 0.505318, loss_fp: 0.500196, loss_freq: 0.502979
[12:07:36.056] iteration 1271: loss: 0.995291, loss_s1: 0.503043, loss_fp: 0.500174, loss_freq: 0.502718
[12:07:36.681] iteration 1272: loss: 0.905210, loss_s1: 0.502421, loss_fp: 0.500274, loss_freq: 0.500326
[12:07:37.293] iteration 1273: loss: 0.910073, loss_s1: 0.500557, loss_fp: 0.500083, loss_freq: 0.501556
[12:07:37.906] iteration 1274: loss: 0.874748, loss_s1: 0.503772, loss_fp: 0.500279, loss_freq: 0.503106
[12:07:38.535] iteration 1275: loss: 0.932680, loss_s1: 0.502881, loss_fp: 0.500107, loss_freq: 0.500990
[12:07:39.196] iteration 1276: loss: 0.943528, loss_s1: 0.501785, loss_fp: 0.500156, loss_freq: 0.502455
[12:07:39.856] iteration 1277: loss: 0.899841, loss_s1: 0.501100, loss_fp: 0.500094, loss_freq: 0.500564
[12:07:40.511] iteration 1278: loss: 0.981595, loss_s1: 0.502767, loss_fp: 0.500342, loss_freq: 0.502550
[12:07:41.166] iteration 1279: loss: 0.996121, loss_s1: 0.503096, loss_fp: 0.500214, loss_freq: 0.501055
[12:07:41.824] iteration 1280: loss: 0.952209, loss_s1: 0.504864, loss_fp: 0.500179, loss_freq: 0.500866
[12:07:42.516] iteration 1281: loss: 0.949984, loss_s1: 0.501356, loss_fp: 0.500190, loss_freq: 0.501522
[12:07:43.138] iteration 1282: loss: 0.936133, loss_s1: 0.503503, loss_fp: 0.500342, loss_freq: 0.501904
[12:07:43.753] iteration 1283: loss: 0.928676, loss_s1: 0.503670, loss_fp: 0.500193, loss_freq: 0.501758
[12:07:44.372] iteration 1284: loss: 0.970685, loss_s1: 0.505774, loss_fp: 0.500162, loss_freq: 0.501029
[12:07:44.990] iteration 1285: loss: 0.956619, loss_s1: 0.501152, loss_fp: 0.500098, loss_freq: 0.500361
[12:07:45.608] iteration 1286: loss: 0.887259, loss_s1: 0.509502, loss_fp: 0.500220, loss_freq: 0.501789
[12:07:46.254] iteration 1287: loss: 0.895049, loss_s1: 0.502025, loss_fp: 0.500209, loss_freq: 0.501632
[12:07:47.234] iteration 1288: loss: 0.966442, loss_s1: 0.503887, loss_fp: 0.500423, loss_freq: 0.500723
[12:07:47.848] iteration 1289: loss: 0.879043, loss_s1: 0.505239, loss_fp: 0.500133, loss_freq: 0.500692
[12:07:48.475] iteration 1290: loss: 0.864682, loss_s1: 0.503076, loss_fp: 0.500150, loss_freq: 0.502904
[12:07:49.110] iteration 1291: loss: 0.972378, loss_s1: 0.504266, loss_fp: 0.500245, loss_freq: 0.500344
[12:07:49.735] iteration 1292: loss: 0.898552, loss_s1: 0.501816, loss_fp: 0.500329, loss_freq: 0.500835
[12:07:50.352] iteration 1293: loss: 0.928331, loss_s1: 0.503831, loss_fp: 0.500513, loss_freq: 0.501817
[12:07:50.975] iteration 1294: loss: 0.906402, loss_s1: 0.502962, loss_fp: 0.500135, loss_freq: 0.501543
[12:07:51.590] iteration 1295: loss: 0.964105, loss_s1: 0.503821, loss_fp: 0.500498, loss_freq: 0.501420
[12:07:52.206] iteration 1296: loss: 0.865695, loss_s1: 0.502504, loss_fp: 0.500126, loss_freq: 0.504015
[12:07:52.826] iteration 1297: loss: 1.033231, loss_s1: 0.503810, loss_fp: 0.500285, loss_freq: 0.505922
[12:07:53.442] iteration 1298: loss: 0.915459, loss_s1: 0.506824, loss_fp: 0.500203, loss_freq: 0.501008
[12:07:54.089] iteration 1299: loss: 0.924931, loss_s1: 0.503591, loss_fp: 0.500282, loss_freq: 0.502203
[12:07:54.719] iteration 1300: loss: 0.955640, loss_s1: 0.504095, loss_fp: 0.500138, loss_freq: 0.502282
[12:07:55.334] iteration 1301: loss: 0.891180, loss_s1: 0.504150, loss_fp: 0.500299, loss_freq: 0.501431
[12:07:55.954] iteration 1302: loss: 0.927857, loss_s1: 0.504795, loss_fp: 0.500260, loss_freq: 0.500798
[12:07:56.643] iteration 1303: loss: 0.920737, loss_s1: 0.502281, loss_fp: 0.500142, loss_freq: 0.502337
[12:07:57.299] iteration 1304: loss: 1.111386, loss_s1: 0.502861, loss_fp: 0.500169, loss_freq: 0.501573
[12:07:57.909] iteration 1305: loss: 0.992085, loss_s1: 0.503970, loss_fp: 0.500103, loss_freq: 0.502333
[12:07:58.525] iteration 1306: loss: 0.876160, loss_s1: 0.503276, loss_fp: 0.500264, loss_freq: 0.501521
[12:07:59.140] iteration 1307: loss: 0.925003, loss_s1: 0.506271, loss_fp: 0.500208, loss_freq: 0.501287
[12:07:59.756] iteration 1308: loss: 0.964608, loss_s1: 0.503919, loss_fp: 0.500192, loss_freq: 0.501056
[12:08:00.373] iteration 1309: loss: 1.004923, loss_s1: 0.506364, loss_fp: 0.500143, loss_freq: 0.503621
[12:08:00.987] iteration 1310: loss: 0.920718, loss_s1: 0.502091, loss_fp: 0.500456, loss_freq: 0.501719
[12:08:01.610] iteration 1311: loss: 0.954574, loss_s1: 0.503662, loss_fp: 0.500260, loss_freq: 0.500598
[12:08:02.282] iteration 1312: loss: 0.890654, loss_s1: 0.501238, loss_fp: 0.500167, loss_freq: 0.500473
[12:08:02.933] iteration 1313: loss: 0.954826, loss_s1: 0.501581, loss_fp: 0.500126, loss_freq: 0.500428
[12:08:03.587] iteration 1314: loss: 0.946236, loss_s1: 0.501169, loss_fp: 0.500094, loss_freq: 0.500542
[12:08:04.232] iteration 1315: loss: 0.896634, loss_s1: 0.500996, loss_fp: 0.500160, loss_freq: 0.500675
[12:08:04.856] iteration 1316: loss: 1.054120, loss_s1: 0.503327, loss_fp: 0.500224, loss_freq: 0.501922
[12:08:05.471] iteration 1317: loss: 0.959232, loss_s1: 0.501942, loss_fp: 0.500185, loss_freq: 0.500877
[12:08:06.097] iteration 1318: loss: 0.919007, loss_s1: 0.500943, loss_fp: 0.500167, loss_freq: 0.500608
[12:08:06.726] iteration 1319: loss: 0.935339, loss_s1: 0.501119, loss_fp: 0.500330, loss_freq: 0.501360
[12:08:07.341] iteration 1320: loss: 0.926819, loss_s1: 0.502947, loss_fp: 0.500446, loss_freq: 0.500408
[12:08:07.970] iteration 1321: loss: 0.892819, loss_s1: 0.504286, loss_fp: 0.500176, loss_freq: 0.501051
[12:08:08.592] iteration 1322: loss: 0.937576, loss_s1: 0.503209, loss_fp: 0.500312, loss_freq: 0.501278
[12:08:09.204] iteration 1323: loss: 0.927914, loss_s1: 0.502887, loss_fp: 0.500139, loss_freq: 0.501115
[12:08:09.824] iteration 1324: loss: 0.887365, loss_s1: 0.507890, loss_fp: 0.500427, loss_freq: 0.500539
[12:08:10.447] iteration 1325: loss: 0.874587, loss_s1: 0.501461, loss_fp: 0.500135, loss_freq: 0.500633
[12:08:11.064] iteration 1326: loss: 0.953103, loss_s1: 0.503233, loss_fp: 0.500236, loss_freq: 0.502071
[12:08:11.680] iteration 1327: loss: 0.930544, loss_s1: 0.503558, loss_fp: 0.500305, loss_freq: 0.501684
[12:08:12.311] iteration 1328: loss: 0.909245, loss_s1: 0.502622, loss_fp: 0.500220, loss_freq: 0.503225
[12:08:12.931] iteration 1329: loss: 0.910225, loss_s1: 0.504663, loss_fp: 0.500288, loss_freq: 0.502490
[12:08:13.546] iteration 1330: loss: 0.923549, loss_s1: 0.502754, loss_fp: 0.500295, loss_freq: 0.502582
[12:08:14.168] iteration 1331: loss: 0.886547, loss_s1: 0.503915, loss_fp: 0.500293, loss_freq: 0.503830
[12:08:14.836] iteration 1332: loss: 0.999475, loss_s1: 0.505499, loss_fp: 0.500059, loss_freq: 0.502703
[12:08:15.804] iteration 1333: loss: 0.869656, loss_s1: 0.506670, loss_fp: 0.500636, loss_freq: 0.502640
[12:08:16.755] iteration 1334: loss: 0.901264, loss_s1: 0.504080, loss_fp: 0.500104, loss_freq: 0.503197
[12:08:17.401] iteration 1335: loss: 0.928055, loss_s1: 0.504530, loss_fp: 0.500123, loss_freq: 0.500422
[12:08:18.008] iteration 1336: loss: 0.915984, loss_s1: 0.501546, loss_fp: 0.500131, loss_freq: 0.501104
[12:08:18.624] iteration 1337: loss: 0.903028, loss_s1: 0.506568, loss_fp: 0.500138, loss_freq: 0.503086
[12:08:19.238] iteration 1338: loss: 0.908457, loss_s1: 0.503146, loss_fp: 0.500593, loss_freq: 0.501808
[12:08:19.856] iteration 1339: loss: 1.020355, loss_s1: 0.507584, loss_fp: 0.500368, loss_freq: 0.500578
[12:08:20.475] iteration 1340: loss: 0.951878, loss_s1: 0.507135, loss_fp: 0.500082, loss_freq: 0.501796
[12:08:21.087] iteration 1341: loss: 0.868354, loss_s1: 0.502117, loss_fp: 0.500145, loss_freq: 0.500241
[12:08:21.716] iteration 1342: loss: 0.899875, loss_s1: 0.504808, loss_fp: 0.500129, loss_freq: 0.503943
[12:08:22.336] iteration 1343: loss: 0.950581, loss_s1: 0.506285, loss_fp: 0.500356, loss_freq: 0.501082
[12:08:22.953] iteration 1344: loss: 0.932974, loss_s1: 0.504968, loss_fp: 0.500204, loss_freq: 0.501761
[12:08:23.596] iteration 1345: loss: 0.895525, loss_s1: 0.504172, loss_fp: 0.500125, loss_freq: 0.501190
[12:08:24.266] iteration 1346: loss: 0.912454, loss_s1: 0.501558, loss_fp: 0.500057, loss_freq: 0.501690
[12:08:24.893] iteration 1347: loss: 0.922892, loss_s1: 0.500344, loss_fp: 0.500075, loss_freq: 0.500887
[12:08:25.512] iteration 1348: loss: 0.931796, loss_s1: 0.503120, loss_fp: 0.500104, loss_freq: 0.500207
[12:08:26.134] iteration 1349: loss: 0.945585, loss_s1: 0.503547, loss_fp: 0.500074, loss_freq: 0.503016
[12:08:26.774] iteration 1350: loss: 0.923375, loss_s1: 0.506309, loss_fp: 0.500206, loss_freq: 0.502533
[12:08:27.407] iteration 1351: loss: 1.063130, loss_s1: 0.504323, loss_fp: 0.500091, loss_freq: 0.500972
[12:08:28.034] iteration 1352: loss: 0.949478, loss_s1: 0.500820, loss_fp: 0.500155, loss_freq: 0.501405
[12:08:28.658] iteration 1353: loss: 0.900330, loss_s1: 0.502682, loss_fp: 0.500127, loss_freq: 0.501270
[12:08:29.286] iteration 1354: loss: 0.893005, loss_s1: 0.502912, loss_fp: 0.500175, loss_freq: 0.501387
[12:08:29.913] iteration 1355: loss: 0.938162, loss_s1: 0.506423, loss_fp: 0.500163, loss_freq: 0.500754
[12:08:30.535] iteration 1356: loss: 0.924101, loss_s1: 0.501673, loss_fp: 0.500133, loss_freq: 0.500453
[12:08:31.158] iteration 1357: loss: 0.977422, loss_s1: 0.503081, loss_fp: 0.500198, loss_freq: 0.501342
[12:08:31.777] iteration 1358: loss: 0.992317, loss_s1: 0.502914, loss_fp: 0.500108, loss_freq: 0.502174
[12:08:32.398] iteration 1359: loss: 0.885374, loss_s1: 0.500425, loss_fp: 0.500100, loss_freq: 0.500205
[12:08:33.016] iteration 1360: loss: 0.891547, loss_s1: 0.503329, loss_fp: 0.500173, loss_freq: 0.502188
[12:08:33.634] iteration 1361: loss: 0.944426, loss_s1: 0.502294, loss_fp: 0.500199, loss_freq: 0.501951
[12:08:34.248] iteration 1362: loss: 0.919404, loss_s1: 0.503545, loss_fp: 0.500205, loss_freq: 0.500683
[12:08:34.860] iteration 1363: loss: 0.926763, loss_s1: 0.501878, loss_fp: 0.500163, loss_freq: 0.500798
[12:08:35.476] iteration 1364: loss: 0.895103, loss_s1: 0.500942, loss_fp: 0.500082, loss_freq: 0.501113
[12:08:36.099] iteration 1365: loss: 0.930885, loss_s1: 0.502579, loss_fp: 0.500266, loss_freq: 0.500679
[12:08:36.712] iteration 1366: loss: 0.913638, loss_s1: 0.501501, loss_fp: 0.500175, loss_freq: 0.501953
[12:08:37.337] iteration 1367: loss: 1.094658, loss_s1: 0.503280, loss_fp: 0.500135, loss_freq: 0.500990
[12:08:37.960] iteration 1368: loss: 0.913758, loss_s1: 0.502678, loss_fp: 0.500638, loss_freq: 0.501739
[12:08:38.575] iteration 1369: loss: 0.930895, loss_s1: 0.502307, loss_fp: 0.500118, loss_freq: 0.500923
[12:08:39.199] iteration 1370: loss: 1.029741, loss_s1: 0.502990, loss_fp: 0.500508, loss_freq: 0.500551
[12:08:39.818] iteration 1371: loss: 0.897248, loss_s1: 0.501563, loss_fp: 0.500102, loss_freq: 0.501224
[12:08:40.474] iteration 1372: loss: 0.901926, loss_s1: 0.500954, loss_fp: 0.500369, loss_freq: 0.501141
[12:08:41.125] iteration 1373: loss: 0.901413, loss_s1: 0.506715, loss_fp: 0.500104, loss_freq: 0.501612
[12:08:41.783] iteration 1374: loss: 1.010315, loss_s1: 0.505214, loss_fp: 0.500080, loss_freq: 0.501784
[12:08:42.442] iteration 1375: loss: 0.967703, loss_s1: 0.502493, loss_fp: 0.500135, loss_freq: 0.501866
[12:08:43.052] iteration 1376: loss: 0.906938, loss_s1: 0.504391, loss_fp: 0.500233, loss_freq: 0.502826
[12:08:43.677] iteration 1377: loss: 0.930415, loss_s1: 0.505955, loss_fp: 0.500171, loss_freq: 0.500793
[12:08:44.299] iteration 1378: loss: 0.953124, loss_s1: 0.503949, loss_fp: 0.500293, loss_freq: 0.501722
[12:08:44.945] iteration 1379: loss: 0.984769, loss_s1: 0.506323, loss_fp: 0.500160, loss_freq: 0.504673
[12:08:45.567] iteration 1380: loss: 0.909974, loss_s1: 0.502653, loss_fp: 0.500195, loss_freq: 0.500636
[12:08:46.186] iteration 1381: loss: 0.955412, loss_s1: 0.502126, loss_fp: 0.500101, loss_freq: 0.501027
[12:08:46.812] iteration 1382: loss: 0.899615, loss_s1: 0.507635, loss_fp: 0.500136, loss_freq: 0.500430
[12:08:47.436] iteration 1383: loss: 0.941541, loss_s1: 0.507069, loss_fp: 0.500107, loss_freq: 0.501992
[12:08:48.059] iteration 1384: loss: 0.948668, loss_s1: 0.507417, loss_fp: 0.500080, loss_freq: 0.502638
[12:08:48.682] iteration 1385: loss: 0.917299, loss_s1: 0.507331, loss_fp: 0.500105, loss_freq: 0.502950
[12:08:49.308] iteration 1386: loss: 1.031875, loss_s1: 0.504149, loss_fp: 0.500246, loss_freq: 0.501039
[12:08:49.922] iteration 1387: loss: 0.967117, loss_s1: 0.505574, loss_fp: 0.500093, loss_freq: 0.501574
[12:08:50.541] iteration 1388: loss: 0.902847, loss_s1: 0.501655, loss_fp: 0.500098, loss_freq: 0.502763
[12:08:51.164] iteration 1389: loss: 0.935513, loss_s1: 0.501043, loss_fp: 0.500122, loss_freq: 0.501108
[12:08:51.776] iteration 1390: loss: 0.920714, loss_s1: 0.503002, loss_fp: 0.500257, loss_freq: 0.501632
[12:08:52.391] iteration 1391: loss: 0.890320, loss_s1: 0.504112, loss_fp: 0.500848, loss_freq: 0.501647
[12:08:53.004] iteration 1392: loss: 0.943106, loss_s1: 0.504107, loss_fp: 0.500364, loss_freq: 0.501094
[12:08:53.625] iteration 1393: loss: 0.936944, loss_s1: 0.503631, loss_fp: 0.500210, loss_freq: 0.501625
[12:08:54.245] iteration 1394: loss: 0.880510, loss_s1: 0.508252, loss_fp: 0.500232, loss_freq: 0.501224
[12:08:54.861] iteration 1395: loss: 0.866722, loss_s1: 0.503693, loss_fp: 0.500293, loss_freq: 0.501065
[12:08:55.477] iteration 1396: loss: 0.962648, loss_s1: 0.502023, loss_fp: 0.500228, loss_freq: 0.500555
[12:08:56.098] iteration 1397: loss: 0.872649, loss_s1: 0.501935, loss_fp: 0.500326, loss_freq: 0.500546
[12:08:56.713] iteration 1398: loss: 0.907412, loss_s1: 0.502793, loss_fp: 0.500189, loss_freq: 0.500774
[12:08:57.334] iteration 1399: loss: 0.861281, loss_s1: 0.503472, loss_fp: 0.500175, loss_freq: 0.501141
[12:08:57.959] iteration 1400: loss: 0.885672, loss_s1: 0.502174, loss_fp: 0.500222, loss_freq: 0.500648
[12:09:00.662] iteration 1400 : mean_dice : 0.231315
[12:09:01.301] iteration 1401: loss: 0.864949, loss_s1: 0.502913, loss_fp: 0.500100, loss_freq: 0.501756
[12:09:01.927] iteration 1402: loss: 1.046991, loss_s1: 0.503598, loss_fp: 0.500105, loss_freq: 0.503367
[12:09:02.605] iteration 1403: loss: 0.887478, loss_s1: 0.501368, loss_fp: 0.500150, loss_freq: 0.500910
[12:09:03.273] iteration 1404: loss: 0.925911, loss_s1: 0.503773, loss_fp: 0.500167, loss_freq: 0.504125
[12:09:03.924] iteration 1405: loss: 0.981073, loss_s1: 0.506007, loss_fp: 0.500190, loss_freq: 0.502646
[12:09:04.567] iteration 1406: loss: 0.872311, loss_s1: 0.502359, loss_fp: 0.500481, loss_freq: 0.502952
[12:09:05.225] iteration 1407: loss: 0.940548, loss_s1: 0.502768, loss_fp: 0.500307, loss_freq: 0.501375
[12:09:05.884] iteration 1408: loss: 0.959431, loss_s1: 0.501884, loss_fp: 0.500242, loss_freq: 0.504945
[12:09:06.536] iteration 1409: loss: 1.022022, loss_s1: 0.508238, loss_fp: 0.500545, loss_freq: 0.503151
[12:09:07.193] iteration 1410: loss: 0.985108, loss_s1: 0.506449, loss_fp: 0.500129, loss_freq: 0.502383
[12:09:07.828] iteration 1411: loss: 0.861321, loss_s1: 0.502084, loss_fp: 0.500090, loss_freq: 0.501731
[12:09:08.441] iteration 1412: loss: 0.889899, loss_s1: 0.507193, loss_fp: 0.500129, loss_freq: 0.501593
[12:09:09.062] iteration 1413: loss: 0.919856, loss_s1: 0.501086, loss_fp: 0.500086, loss_freq: 0.502649
[12:09:09.675] iteration 1414: loss: 0.931199, loss_s1: 0.503604, loss_fp: 0.500128, loss_freq: 0.502211
[12:09:10.297] iteration 1415: loss: 0.879007, loss_s1: 0.503011, loss_fp: 0.500212, loss_freq: 0.500810
[12:09:10.921] iteration 1416: loss: 0.969822, loss_s1: 0.501692, loss_fp: 0.500133, loss_freq: 0.502255
[12:09:11.539] iteration 1417: loss: 0.900566, loss_s1: 0.503162, loss_fp: 0.500120, loss_freq: 0.503468
[12:09:12.151] iteration 1418: loss: 0.924240, loss_s1: 0.502746, loss_fp: 0.500117, loss_freq: 0.500468
[12:09:12.765] iteration 1419: loss: 0.972153, loss_s1: 0.503448, loss_fp: 0.500233, loss_freq: 0.500821
[12:09:13.374] iteration 1420: loss: 0.906458, loss_s1: 0.504827, loss_fp: 0.500118, loss_freq: 0.500369
[12:09:13.985] iteration 1421: loss: 0.967576, loss_s1: 0.502194, loss_fp: 0.500167, loss_freq: 0.500694
[12:09:14.608] iteration 1422: loss: 0.954453, loss_s1: 0.502002, loss_fp: 0.500493, loss_freq: 0.501748
[12:09:15.224] iteration 1423: loss: 0.916838, loss_s1: 0.505127, loss_fp: 0.500489, loss_freq: 0.501112
[12:09:15.841] iteration 1424: loss: 0.967578, loss_s1: 0.506356, loss_fp: 0.500059, loss_freq: 0.501347
[12:09:16.450] iteration 1425: loss: 0.927170, loss_s1: 0.505242, loss_fp: 0.500112, loss_freq: 0.501348
[12:09:17.092] iteration 1426: loss: 0.943568, loss_s1: 0.502859, loss_fp: 0.500452, loss_freq: 0.501413
[12:09:17.715] iteration 1427: loss: 0.969343, loss_s1: 0.505261, loss_fp: 0.500125, loss_freq: 0.501492
[12:09:18.343] iteration 1428: loss: 0.996199, loss_s1: 0.501658, loss_fp: 0.500130, loss_freq: 0.500584
[12:09:18.960] iteration 1429: loss: 0.897597, loss_s1: 0.505119, loss_fp: 0.500167, loss_freq: 0.500560
[12:09:19.628] iteration 1430: loss: 0.907469, loss_s1: 0.502872, loss_fp: 0.500151, loss_freq: 0.501319
[12:09:20.687] iteration 1431: loss: 0.980359, loss_s1: 0.503820, loss_fp: 0.500373, loss_freq: 0.500581
[12:09:21.368] iteration 1432: loss: 0.896606, loss_s1: 0.501415, loss_fp: 0.500232, loss_freq: 0.500416
[12:09:22.043] iteration 1433: loss: 0.879054, loss_s1: 0.502378, loss_fp: 0.500169, loss_freq: 0.501724
[12:09:22.753] iteration 1434: loss: 0.940674, loss_s1: 0.500780, loss_fp: 0.500146, loss_freq: 0.500249
[12:09:23.442] iteration 1435: loss: 0.933385, loss_s1: 0.501709, loss_fp: 0.500267, loss_freq: 0.500315
[12:09:24.094] iteration 1436: loss: 0.935735, loss_s1: 0.501133, loss_fp: 0.500177, loss_freq: 0.501009
[12:09:24.767] iteration 1437: loss: 0.902321, loss_s1: 0.502535, loss_fp: 0.500187, loss_freq: 0.501331
[12:09:25.429] iteration 1438: loss: 0.934970, loss_s1: 0.505865, loss_fp: 0.500232, loss_freq: 0.502557
[12:09:26.069] iteration 1439: loss: 0.637839, loss_s1: 0.456570, loss_fp: 0.112569, loss_freq: 0.424391
[12:09:26.710] iteration 1440: loss: 0.998235, loss_s1: 0.503151, loss_fp: 0.500297, loss_freq: 0.503894
[12:09:27.335] iteration 1441: loss: 0.867401, loss_s1: 0.503063, loss_fp: 0.500116, loss_freq: 0.500893
[12:09:27.984] iteration 1442: loss: 0.924195, loss_s1: 0.505072, loss_fp: 0.500126, loss_freq: 0.502387
[12:09:28.626] iteration 1443: loss: 0.959247, loss_s1: 0.503636, loss_fp: 0.500212, loss_freq: 0.500910
[12:09:29.252] iteration 1444: loss: 0.881919, loss_s1: 0.500527, loss_fp: 0.500085, loss_freq: 0.500633
[12:09:29.882] iteration 1445: loss: 0.897820, loss_s1: 0.500812, loss_fp: 0.500105, loss_freq: 0.500395
[12:09:30.536] iteration 1446: loss: 0.937557, loss_s1: 0.500506, loss_fp: 0.500077, loss_freq: 0.500719
[12:09:31.167] iteration 1447: loss: 1.077318, loss_s1: 0.500727, loss_fp: 0.500084, loss_freq: 0.500664
[12:09:31.791] iteration 1448: loss: 0.987469, loss_s1: 0.505183, loss_fp: 0.500087, loss_freq: 0.502098
[12:09:32.426] iteration 1449: loss: 0.876377, loss_s1: 0.502219, loss_fp: 0.500094, loss_freq: 0.500741
[12:09:33.060] iteration 1450: loss: 0.987755, loss_s1: 0.504342, loss_fp: 0.500082, loss_freq: 0.500274
[12:09:33.690] iteration 1451: loss: 0.963160, loss_s1: 0.504074, loss_fp: 0.500081, loss_freq: 0.501342
[12:09:34.367] iteration 1452: loss: 0.893799, loss_s1: 0.506759, loss_fp: 0.500052, loss_freq: 0.503138
[12:09:35.029] iteration 1453: loss: 0.915238, loss_s1: 0.505929, loss_fp: 0.500098, loss_freq: 0.501705
[12:09:35.698] iteration 1454: loss: 0.963214, loss_s1: 0.502625, loss_fp: 0.500113, loss_freq: 0.500738
[12:09:36.354] iteration 1455: loss: 0.878805, loss_s1: 0.502256, loss_fp: 0.500148, loss_freq: 0.501356
[12:09:37.017] iteration 1456: loss: 0.947522, loss_s1: 0.502210, loss_fp: 0.500084, loss_freq: 0.500656
[12:09:37.678] iteration 1457: loss: 0.930715, loss_s1: 0.501894, loss_fp: 0.500066, loss_freq: 0.502558
[12:09:38.324] iteration 1458: loss: 0.919782, loss_s1: 0.501841, loss_fp: 0.500149, loss_freq: 0.501696
[12:09:38.956] iteration 1459: loss: 1.069827, loss_s1: 0.502234, loss_fp: 0.500127, loss_freq: 0.500829
[12:09:39.585] iteration 1460: loss: 0.993241, loss_s1: 0.501585, loss_fp: 0.500081, loss_freq: 0.500770
[12:09:40.214] iteration 1461: loss: 0.881829, loss_s1: 0.502919, loss_fp: 0.500093, loss_freq: 0.500900
[12:09:40.841] iteration 1462: loss: 0.929643, loss_s1: 0.501508, loss_fp: 0.500053, loss_freq: 0.501078
[12:09:41.484] iteration 1463: loss: 0.911849, loss_s1: 0.501920, loss_fp: 0.500114, loss_freq: 0.500989
[12:09:42.104] iteration 1464: loss: 0.912347, loss_s1: 0.504150, loss_fp: 0.500153, loss_freq: 0.500708
[12:09:42.741] iteration 1465: loss: 0.970826, loss_s1: 0.503946, loss_fp: 0.500080, loss_freq: 0.500695
[12:09:43.359] iteration 1466: loss: 0.958015, loss_s1: 0.507323, loss_fp: 0.500206, loss_freq: 0.502073
[12:09:43.998] iteration 1467: loss: 0.885257, loss_s1: 0.501643, loss_fp: 0.500052, loss_freq: 0.502106
[12:09:44.628] iteration 1468: loss: 0.873423, loss_s1: 0.502820, loss_fp: 0.500212, loss_freq: 0.501517
[12:09:45.266] iteration 1469: loss: 0.954113, loss_s1: 0.502447, loss_fp: 0.500098, loss_freq: 0.502847
[12:09:45.918] iteration 1470: loss: 0.907686, loss_s1: 0.503982, loss_fp: 0.500141, loss_freq: 0.502168
[12:09:46.576] iteration 1471: loss: 0.905729, loss_s1: 0.501733, loss_fp: 0.500096, loss_freq: 0.502218
[12:09:47.202] iteration 1472: loss: 0.886891, loss_s1: 0.501966, loss_fp: 0.500122, loss_freq: 0.502287
[12:09:47.839] iteration 1473: loss: 0.894647, loss_s1: 0.501764, loss_fp: 0.500167, loss_freq: 0.501567
[12:09:48.468] iteration 1474: loss: 0.857647, loss_s1: 0.504934, loss_fp: 0.500092, loss_freq: 0.501676
[12:09:49.095] iteration 1475: loss: 1.045267, loss_s1: 0.505785, loss_fp: 0.500084, loss_freq: 0.501458
[12:09:49.729] iteration 1476: loss: 0.888530, loss_s1: 0.501165, loss_fp: 0.500090, loss_freq: 0.500838
[12:09:50.363] iteration 1477: loss: 0.922224, loss_s1: 0.502647, loss_fp: 0.500136, loss_freq: 0.501198
[12:09:50.981] iteration 1478: loss: 0.940900, loss_s1: 0.504064, loss_fp: 0.500090, loss_freq: 0.500552
[12:09:51.611] iteration 1479: loss: 0.866069, loss_s1: 0.500857, loss_fp: 0.500058, loss_freq: 0.501298
[12:09:52.236] iteration 1480: loss: 0.899579, loss_s1: 0.503911, loss_fp: 0.500073, loss_freq: 0.501214
[12:09:52.888] iteration 1481: loss: 0.939026, loss_s1: 0.502468, loss_fp: 0.500099, loss_freq: 0.502078
[12:09:53.515] iteration 1482: loss: 1.059262, loss_s1: 0.506851, loss_fp: 0.500222, loss_freq: 0.500721
[12:09:54.156] iteration 1483: loss: 0.948794, loss_s1: 0.503026, loss_fp: 0.500211, loss_freq: 0.502753
[12:09:54.778] iteration 1484: loss: 0.878462, loss_s1: 0.503117, loss_fp: 0.500163, loss_freq: 0.500423
[12:09:55.398] iteration 1485: loss: 0.973416, loss_s1: 0.503317, loss_fp: 0.500143, loss_freq: 0.504182
[12:09:56.031] iteration 1486: loss: 0.957033, loss_s1: 0.501694, loss_fp: 0.500161, loss_freq: 0.501496
[12:09:56.669] iteration 1487: loss: 0.896711, loss_s1: 0.502971, loss_fp: 0.500244, loss_freq: 0.503103
[12:09:57.336] iteration 1488: loss: 0.863368, loss_s1: 0.502262, loss_fp: 0.500053, loss_freq: 0.500423
[12:09:57.989] iteration 1489: loss: 1.004198, loss_s1: 0.503519, loss_fp: 0.500184, loss_freq: 0.501038
[12:09:58.647] iteration 1490: loss: 0.885299, loss_s1: 0.500896, loss_fp: 0.500080, loss_freq: 0.501738
[12:09:59.284] iteration 1491: loss: 0.909996, loss_s1: 0.501813, loss_fp: 0.500088, loss_freq: 0.500113
[12:09:59.923] iteration 1492: loss: 0.946150, loss_s1: 0.503668, loss_fp: 0.500098, loss_freq: 0.500959
[12:10:00.559] iteration 1493: loss: 0.921599, loss_s1: 0.504736, loss_fp: 0.500087, loss_freq: 0.502120
[12:10:01.228] iteration 1494: loss: 1.047326, loss_s1: 0.502115, loss_fp: 0.500080, loss_freq: 0.500968
[12:10:01.853] iteration 1495: loss: 0.939374, loss_s1: 0.503210, loss_fp: 0.500121, loss_freq: 0.500885
[12:10:02.484] iteration 1496: loss: 0.911157, loss_s1: 0.502444, loss_fp: 0.500210, loss_freq: 0.501143
[12:10:03.109] iteration 1497: loss: 0.909562, loss_s1: 0.503875, loss_fp: 0.500150, loss_freq: 0.500787
[12:10:03.738] iteration 1498: loss: 0.892871, loss_s1: 0.501562, loss_fp: 0.500079, loss_freq: 0.500720
[12:10:04.373] iteration 1499: loss: 0.919174, loss_s1: 0.503348, loss_fp: 0.500054, loss_freq: 0.501141
[12:10:05.012] iteration 1500: loss: 0.939976, loss_s1: 0.503379, loss_fp: 0.500114, loss_freq: 0.501813
[12:10:05.640] iteration 1501: loss: 0.958485, loss_s1: 0.501947, loss_fp: 0.500137, loss_freq: 0.501238
[12:10:06.270] iteration 1502: loss: 0.872972, loss_s1: 0.501279, loss_fp: 0.500184, loss_freq: 0.500529
[12:10:06.894] iteration 1503: loss: 0.834120, loss_s1: 0.500841, loss_fp: 0.500282, loss_freq: 0.503074
[12:10:07.533] iteration 1504: loss: 0.988914, loss_s1: 0.504583, loss_fp: 0.500137, loss_freq: 0.502390
[12:10:08.181] iteration 1505: loss: 0.893083, loss_s1: 0.503567, loss_fp: 0.500133, loss_freq: 0.501284
[12:10:08.825] iteration 1506: loss: 0.868983, loss_s1: 0.501229, loss_fp: 0.500168, loss_freq: 0.500460
[12:10:09.449] iteration 1507: loss: 0.877694, loss_s1: 0.504509, loss_fp: 0.500147, loss_freq: 0.501427
[12:10:10.083] iteration 1508: loss: 0.923050, loss_s1: 0.500304, loss_fp: 0.500157, loss_freq: 0.501100
[12:10:10.773] iteration 1509: loss: 0.866943, loss_s1: 0.503366, loss_fp: 0.500111, loss_freq: 0.504247
[12:10:11.447] iteration 1510: loss: 1.068747, loss_s1: 0.503306, loss_fp: 0.500105, loss_freq: 0.502000
[12:10:12.147] iteration 1511: loss: 0.888714, loss_s1: 0.503545, loss_fp: 0.500126, loss_freq: 0.502673
[12:10:12.819] iteration 1512: loss: 0.873771, loss_s1: 0.502671, loss_fp: 0.500056, loss_freq: 0.502439
[12:10:13.494] iteration 1513: loss: 0.963381, loss_s1: 0.500800, loss_fp: 0.500136, loss_freq: 0.500425
[12:10:14.175] iteration 1514: loss: 0.882046, loss_s1: 0.502728, loss_fp: 0.500127, loss_freq: 0.502315
[12:10:14.845] iteration 1515: loss: 0.913315, loss_s1: 0.501995, loss_fp: 0.500209, loss_freq: 0.501038
[12:10:15.488] iteration 1516: loss: 0.919990, loss_s1: 0.504990, loss_fp: 0.500221, loss_freq: 0.502931
[12:10:16.132] iteration 1517: loss: 1.018559, loss_s1: 0.506563, loss_fp: 0.500165, loss_freq: 0.501114
[12:10:16.823] iteration 1518: loss: 0.959566, loss_s1: 0.502102, loss_fp: 0.500124, loss_freq: 0.501296
[12:10:17.741] iteration 1519: loss: 0.897223, loss_s1: 0.504986, loss_fp: 0.500097, loss_freq: 0.505258
[12:10:18.569] iteration 1520: loss: 0.880144, loss_s1: 0.505215, loss_fp: 0.500173, loss_freq: 0.500682
[12:10:19.420] iteration 1521: loss: 0.934086, loss_s1: 0.509080, loss_fp: 0.500056, loss_freq: 0.502227
[12:10:20.139] iteration 1522: loss: 0.876721, loss_s1: 0.505172, loss_fp: 0.500110, loss_freq: 0.504720
[12:10:20.778] iteration 1523: loss: 0.900924, loss_s1: 0.502430, loss_fp: 0.500045, loss_freq: 0.500417
[12:10:21.411] iteration 1524: loss: 0.934488, loss_s1: 0.502191, loss_fp: 0.500110, loss_freq: 0.500687
[12:10:22.047] iteration 1525: loss: 0.858812, loss_s1: 0.506354, loss_fp: 0.500106, loss_freq: 0.500815
[12:10:22.681] iteration 1526: loss: 0.917162, loss_s1: 0.501669, loss_fp: 0.500045, loss_freq: 0.503129
[12:10:23.318] iteration 1527: loss: 0.979547, loss_s1: 0.503952, loss_fp: 0.500035, loss_freq: 0.502346
[12:10:23.962] iteration 1528: loss: 0.925382, loss_s1: 0.504981, loss_fp: 0.500149, loss_freq: 0.503058
[12:10:24.604] iteration 1529: loss: 1.071064, loss_s1: 0.502959, loss_fp: 0.500093, loss_freq: 0.502674
[12:10:25.237] iteration 1530: loss: 0.969221, loss_s1: 0.501707, loss_fp: 0.500147, loss_freq: 0.503282
[12:10:25.952] iteration 1531: loss: 0.965313, loss_s1: 0.502876, loss_fp: 0.500116, loss_freq: 0.504920
[12:10:26.616] iteration 1532: loss: 0.900897, loss_s1: 0.503268, loss_fp: 0.500163, loss_freq: 0.501202
[12:10:27.308] iteration 1533: loss: 0.949314, loss_s1: 0.504593, loss_fp: 0.500167, loss_freq: 0.500756
[12:10:27.997] iteration 1534: loss: 0.903380, loss_s1: 0.502067, loss_fp: 0.500107, loss_freq: 0.502918
[12:10:28.675] iteration 1535: loss: 0.956154, loss_s1: 0.502048, loss_fp: 0.500134, loss_freq: 0.501533
[12:10:29.339] iteration 1536: loss: 0.943525, loss_s1: 0.503447, loss_fp: 0.500070, loss_freq: 0.501021
[12:10:29.981] iteration 1537: loss: 0.855441, loss_s1: 0.503379, loss_fp: 0.500201, loss_freq: 0.501851
[12:10:30.631] iteration 1538: loss: 0.861509, loss_s1: 0.502666, loss_fp: 0.500126, loss_freq: 0.500927
[12:10:31.291] iteration 1539: loss: 0.949136, loss_s1: 0.501178, loss_fp: 0.500149, loss_freq: 0.501825
[12:10:31.922] iteration 1540: loss: 0.882232, loss_s1: 0.501512, loss_fp: 0.500092, loss_freq: 0.501262
[12:10:32.567] iteration 1541: loss: 0.907518, loss_s1: 0.503886, loss_fp: 0.500665, loss_freq: 0.502863
[12:10:33.209] iteration 1542: loss: 0.898045, loss_s1: 0.504505, loss_fp: 0.500144, loss_freq: 0.501640
[12:10:33.840] iteration 1543: loss: 0.899072, loss_s1: 0.505153, loss_fp: 0.500246, loss_freq: 0.501173
[12:10:34.482] iteration 1544: loss: 0.848221, loss_s1: 0.504583, loss_fp: 0.500275, loss_freq: 0.503015
[12:10:35.125] iteration 1545: loss: 1.053240, loss_s1: 0.502637, loss_fp: 0.500148, loss_freq: 0.504924
[12:10:35.746] iteration 1546: loss: 0.880293, loss_s1: 0.503714, loss_fp: 0.500104, loss_freq: 0.500525
[12:10:36.426] iteration 1547: loss: 0.897519, loss_s1: 0.504673, loss_fp: 0.500109, loss_freq: 0.502910
[12:10:37.047] iteration 1548: loss: 0.912364, loss_s1: 0.503660, loss_fp: 0.500274, loss_freq: 0.504569
[12:10:37.697] iteration 1549: loss: 0.878350, loss_s1: 0.503260, loss_fp: 0.500087, loss_freq: 0.502375
[12:10:38.369] iteration 1550: loss: 0.914716, loss_s1: 0.503619, loss_fp: 0.500591, loss_freq: 0.501552
[12:10:39.045] iteration 1551: loss: 0.905375, loss_s1: 0.503073, loss_fp: 0.500280, loss_freq: 0.502708
[12:10:39.708] iteration 1552: loss: 1.017429, loss_s1: 0.504559, loss_fp: 0.500115, loss_freq: 0.506396
[12:10:40.393] iteration 1553: loss: 0.966519, loss_s1: 0.502787, loss_fp: 0.500132, loss_freq: 0.501592
[12:10:41.070] iteration 1554: loss: 0.851434, loss_s1: 0.505063, loss_fp: 0.500057, loss_freq: 0.501739
[12:10:41.732] iteration 1555: loss: 0.888891, loss_s1: 0.502442, loss_fp: 0.500087, loss_freq: 0.501478
[12:10:42.398] iteration 1556: loss: 0.926117, loss_s1: 0.503902, loss_fp: 0.500073, loss_freq: 0.501910
[12:10:43.056] iteration 1557: loss: 0.912631, loss_s1: 0.504581, loss_fp: 0.500209, loss_freq: 0.500792
[12:10:43.742] iteration 1558: loss: 0.925364, loss_s1: 0.504439, loss_fp: 0.500247, loss_freq: 0.501022
[12:10:44.406] iteration 1559: loss: 0.918209, loss_s1: 0.505482, loss_fp: 0.500067, loss_freq: 0.500908
[12:10:45.092] iteration 1560: loss: 0.872856, loss_s1: 0.502496, loss_fp: 0.500116, loss_freq: 0.503294
[12:10:45.729] iteration 1561: loss: 0.938219, loss_s1: 0.503604, loss_fp: 0.500229, loss_freq: 0.503135
[12:10:46.353] iteration 1562: loss: 0.948554, loss_s1: 0.503160, loss_fp: 0.500119, loss_freq: 0.501458
[12:10:46.988] iteration 1563: loss: 0.925994, loss_s1: 0.503334, loss_fp: 0.500121, loss_freq: 0.501145
[12:10:47.661] iteration 1564: loss: 0.991759, loss_s1: 0.503677, loss_fp: 0.500188, loss_freq: 0.501020
[12:10:48.331] iteration 1565: loss: 0.920707, loss_s1: 0.503309, loss_fp: 0.500130, loss_freq: 0.500963
[12:10:48.994] iteration 1566: loss: 0.900309, loss_s1: 0.502988, loss_fp: 0.500136, loss_freq: 0.500710
[12:10:49.625] iteration 1567: loss: 0.906407, loss_s1: 0.502630, loss_fp: 0.500214, loss_freq: 0.500544
[12:10:50.263] iteration 1568: loss: 0.918584, loss_s1: 0.502767, loss_fp: 0.500131, loss_freq: 0.501281
[12:10:50.899] iteration 1569: loss: 0.911245, loss_s1: 0.502965, loss_fp: 0.500120, loss_freq: 0.501511
[12:10:51.526] iteration 1570: loss: 0.966601, loss_s1: 0.506035, loss_fp: 0.500051, loss_freq: 0.502676
[12:10:52.159] iteration 1571: loss: 0.950656, loss_s1: 0.500637, loss_fp: 0.500115, loss_freq: 0.500568
[12:10:52.777] iteration 1572: loss: 0.902777, loss_s1: 0.503820, loss_fp: 0.500232, loss_freq: 0.501491
[12:10:53.403] iteration 1573: loss: 0.871315, loss_s1: 0.502900, loss_fp: 0.500076, loss_freq: 0.502266
[12:10:54.404] iteration 1574: loss: 0.954540, loss_s1: 0.504302, loss_fp: 0.500077, loss_freq: 0.501270
[12:10:55.056] iteration 1575: loss: 0.875859, loss_s1: 0.501050, loss_fp: 0.500182, loss_freq: 0.500844
[12:10:55.692] iteration 1576: loss: 0.861890, loss_s1: 0.500486, loss_fp: 0.500061, loss_freq: 0.502119
[12:10:56.321] iteration 1577: loss: 0.957523, loss_s1: 0.503153, loss_fp: 0.500058, loss_freq: 0.500715
[12:10:56.992] iteration 1578: loss: 0.910491, loss_s1: 0.501058, loss_fp: 0.500087, loss_freq: 0.501374
[12:10:57.634] iteration 1579: loss: 0.909657, loss_s1: 0.506293, loss_fp: 0.500115, loss_freq: 0.502775
[12:10:58.277] iteration 1580: loss: 0.835283, loss_s1: 0.503206, loss_fp: 0.500076, loss_freq: 0.502817
[12:10:58.905] iteration 1581: loss: 0.969125, loss_s1: 0.503118, loss_fp: 0.500127, loss_freq: 0.503945
[12:10:59.546] iteration 1582: loss: 0.862079, loss_s1: 0.502267, loss_fp: 0.500139, loss_freq: 0.503031
[12:11:00.186] iteration 1583: loss: 1.058946, loss_s1: 0.502940, loss_fp: 0.500144, loss_freq: 0.504227
[12:11:00.810] iteration 1584: loss: 0.885563, loss_s1: 0.501187, loss_fp: 0.500061, loss_freq: 0.501811
[12:11:01.455] iteration 1585: loss: 0.895639, loss_s1: 0.503760, loss_fp: 0.500178, loss_freq: 0.501694
[12:11:02.094] iteration 1586: loss: 0.980230, loss_s1: 0.504605, loss_fp: 0.500076, loss_freq: 0.501374
[12:11:02.756] iteration 1587: loss: 0.865836, loss_s1: 0.505211, loss_fp: 0.500079, loss_freq: 0.500980
[12:11:03.381] iteration 1588: loss: 0.891037, loss_s1: 0.505552, loss_fp: 0.500237, loss_freq: 0.500373
[12:11:04.131] iteration 1589: loss: 0.945107, loss_s1: 0.502311, loss_fp: 0.500053, loss_freq: 0.500923
[12:11:04.798] iteration 1590: loss: 1.043027, loss_s1: 0.504934, loss_fp: 0.500116, loss_freq: 0.500894
[12:11:05.428] iteration 1591: loss: 0.950570, loss_s1: 0.503240, loss_fp: 0.500037, loss_freq: 0.502989
[12:11:06.061] iteration 1592: loss: 0.871842, loss_s1: 0.504308, loss_fp: 0.500047, loss_freq: 0.501527
[12:11:06.684] iteration 1593: loss: 0.958218, loss_s1: 0.502534, loss_fp: 0.500158, loss_freq: 0.501147
[12:11:07.309] iteration 1594: loss: 0.952539, loss_s1: 0.502229, loss_fp: 0.500154, loss_freq: 0.501873
[12:11:07.928] iteration 1595: loss: 0.955065, loss_s1: 0.505575, loss_fp: 0.500083, loss_freq: 0.502512
[12:11:08.549] iteration 1596: loss: 0.920771, loss_s1: 0.506884, loss_fp: 0.500076, loss_freq: 0.501237
[12:11:09.174] iteration 1597: loss: 0.958673, loss_s1: 0.502864, loss_fp: 0.500175, loss_freq: 0.500329
[12:11:09.804] iteration 1598: loss: 0.887248, loss_s1: 0.507560, loss_fp: 0.500115, loss_freq: 0.500890
[12:11:10.441] iteration 1599: loss: 0.958312, loss_s1: 0.502042, loss_fp: 0.500053, loss_freq: 0.501164
[12:11:11.083] iteration 1600: loss: 0.967959, loss_s1: 0.500732, loss_fp: 0.500091, loss_freq: 0.500329
[12:11:14.284] iteration 1600 : mean_dice : 0.284146
[12:11:14.970] iteration 1601: loss: 0.897524, loss_s1: 0.502747, loss_fp: 0.500069, loss_freq: 0.500720
[12:11:15.680] iteration 1602: loss: 1.029403, loss_s1: 0.503919, loss_fp: 0.500134, loss_freq: 0.501032
[12:11:16.339] iteration 1603: loss: 1.008857, loss_s1: 0.500527, loss_fp: 0.500098, loss_freq: 0.500309
[12:11:17.006] iteration 1604: loss: 0.906671, loss_s1: 0.503229, loss_fp: 0.500211, loss_freq: 0.500474
[12:11:17.669] iteration 1605: loss: 0.906897, loss_s1: 0.500956, loss_fp: 0.500073, loss_freq: 0.500749
[12:11:18.329] iteration 1606: loss: 0.932111, loss_s1: 0.501474, loss_fp: 0.500227, loss_freq: 0.500598
[12:11:18.986] iteration 1607: loss: 0.895543, loss_s1: 0.505847, loss_fp: 0.500170, loss_freq: 0.500548
[12:11:19.624] iteration 1608: loss: 0.924286, loss_s1: 0.503300, loss_fp: 0.500154, loss_freq: 0.501647
[12:11:20.260] iteration 1609: loss: 0.947363, loss_s1: 0.501212, loss_fp: 0.500135, loss_freq: 0.501055
[12:11:20.892] iteration 1610: loss: 0.866158, loss_s1: 0.503886, loss_fp: 0.500341, loss_freq: 0.500766
[12:11:21.522] iteration 1611: loss: 0.846303, loss_s1: 0.504453, loss_fp: 0.500160, loss_freq: 0.500800
[12:11:22.157] iteration 1612: loss: 0.915019, loss_s1: 0.502537, loss_fp: 0.500123, loss_freq: 0.500952
[12:11:22.777] iteration 1613: loss: 0.929524, loss_s1: 0.502667, loss_fp: 0.500231, loss_freq: 0.501257
[12:11:23.398] iteration 1614: loss: 0.887368, loss_s1: 0.502025, loss_fp: 0.500146, loss_freq: 0.502025
[12:11:24.065] iteration 1615: loss: 0.868473, loss_s1: 0.503408, loss_fp: 0.500357, loss_freq: 0.501462
[12:11:24.735] iteration 1616: loss: 0.916487, loss_s1: 0.502240, loss_fp: 0.500072, loss_freq: 0.501232
[12:11:25.420] iteration 1617: loss: 0.806357, loss_s1: 0.457635, loss_fp: 0.449876, loss_freq: 0.501458
[12:11:26.088] iteration 1618: loss: 1.026036, loss_s1: 0.503084, loss_fp: 0.500076, loss_freq: 0.503267
[12:11:26.760] iteration 1619: loss: 0.896414, loss_s1: 0.501433, loss_fp: 0.500151, loss_freq: 0.501553
[12:11:27.446] iteration 1620: loss: 0.876700, loss_s1: 0.501357, loss_fp: 0.500095, loss_freq: 0.501526
[12:11:28.086] iteration 1621: loss: 0.971663, loss_s1: 0.500873, loss_fp: 0.500084, loss_freq: 0.500329
[12:11:28.714] iteration 1622: loss: 0.915451, loss_s1: 0.501837, loss_fp: 0.500170, loss_freq: 0.500937
[12:11:29.344] iteration 1623: loss: 0.867317, loss_s1: 0.501308, loss_fp: 0.500032, loss_freq: 0.501725
[12:11:29.972] iteration 1624: loss: 0.944496, loss_s1: 0.503701, loss_fp: 0.500284, loss_freq: 0.502372
[12:11:30.621] iteration 1625: loss: 0.984281, loss_s1: 0.503958, loss_fp: 0.500061, loss_freq: 0.500434
[12:11:31.267] iteration 1626: loss: 0.950090, loss_s1: 0.502398, loss_fp: 0.500101, loss_freq: 0.501662
[12:11:31.922] iteration 1627: loss: 0.829432, loss_s1: 0.503348, loss_fp: 0.500401, loss_freq: 0.500815
[12:11:32.610] iteration 1628: loss: 0.901765, loss_s1: 0.500877, loss_fp: 0.500064, loss_freq: 0.502262
[12:11:33.252] iteration 1629: loss: 0.916454, loss_s1: 0.505860, loss_fp: 0.500144, loss_freq: 0.500766
[12:11:33.866] iteration 1630: loss: 0.958577, loss_s1: 0.506214, loss_fp: 0.500111, loss_freq: 0.502807
[12:11:34.495] iteration 1631: loss: 0.854970, loss_s1: 0.502812, loss_fp: 0.500176, loss_freq: 0.500929
[12:11:35.109] iteration 1632: loss: 0.951519, loss_s1: 0.504990, loss_fp: 0.500068, loss_freq: 0.501210
[12:11:35.716] iteration 1633: loss: 0.884336, loss_s1: 0.504665, loss_fp: 0.500054, loss_freq: 0.502467
[12:11:36.373] iteration 1634: loss: 0.930911, loss_s1: 0.500787, loss_fp: 0.500072, loss_freq: 0.500322
[12:11:37.065] iteration 1635: loss: 0.927805, loss_s1: 0.503779, loss_fp: 0.500105, loss_freq: 0.501882
[12:11:37.733] iteration 1636: loss: 0.889923, loss_s1: 0.504904, loss_fp: 0.500147, loss_freq: 0.503347
[12:11:38.408] iteration 1637: loss: 1.006024, loss_s1: 0.503760, loss_fp: 0.500134, loss_freq: 0.502622
[12:11:39.074] iteration 1638: loss: 0.961654, loss_s1: 0.503290, loss_fp: 0.500065, loss_freq: 0.501380
[12:11:39.732] iteration 1639: loss: 0.904308, loss_s1: 0.501730, loss_fp: 0.500169, loss_freq: 0.501588
[12:11:40.387] iteration 1640: loss: 0.891394, loss_s1: 0.503056, loss_fp: 0.500144, loss_freq: 0.501218
[12:11:41.017] iteration 1641: loss: 0.906147, loss_s1: 0.505285, loss_fp: 0.500099, loss_freq: 0.500977
[12:11:41.627] iteration 1642: loss: 0.891376, loss_s1: 0.500757, loss_fp: 0.500055, loss_freq: 0.500396
[12:11:42.250] iteration 1643: loss: 0.924492, loss_s1: 0.500715, loss_fp: 0.503448, loss_freq: 0.500873
[12:11:42.869] iteration 1644: loss: 0.928246, loss_s1: 0.502556, loss_fp: 0.500066, loss_freq: 0.501401
[12:11:43.483] iteration 1645: loss: 0.891900, loss_s1: 0.503720, loss_fp: 0.500063, loss_freq: 0.500228
[12:11:44.089] iteration 1646: loss: 0.853745, loss_s1: 0.501262, loss_fp: 0.500113, loss_freq: 0.500645
[12:11:44.699] iteration 1647: loss: 0.905459, loss_s1: 0.502658, loss_fp: 0.500051, loss_freq: 0.501855
[12:11:45.320] iteration 1648: loss: 0.906270, loss_s1: 0.503616, loss_fp: 0.500176, loss_freq: 0.500735
[12:11:45.939] iteration 1649: loss: 0.909262, loss_s1: 0.501664, loss_fp: 0.500196, loss_freq: 0.500412
[12:11:46.554] iteration 1650: loss: 0.865842, loss_s1: 0.503645, loss_fp: 0.500130, loss_freq: 0.502439
[12:11:47.173] iteration 1651: loss: 0.711089, loss_s1: 0.417578, loss_fp: 0.239551, loss_freq: 0.452453
[12:11:47.792] iteration 1652: loss: 0.840876, loss_s1: 0.502077, loss_fp: 0.500059, loss_freq: 0.503009
[12:11:48.405] iteration 1653: loss: 1.126822, loss_s1: 0.500556, loss_fp: 0.500041, loss_freq: 0.501020
[12:11:49.020] iteration 1654: loss: 0.893638, loss_s1: 0.502095, loss_fp: 0.500114, loss_freq: 0.501420
[12:11:49.639] iteration 1655: loss: 0.912539, loss_s1: 0.503668, loss_fp: 0.500042, loss_freq: 0.500897
[12:11:50.254] iteration 1656: loss: 0.979404, loss_s1: 0.500656, loss_fp: 0.500172, loss_freq: 0.500340
[12:11:50.873] iteration 1657: loss: 0.847487, loss_s1: 0.501784, loss_fp: 0.500036, loss_freq: 0.501212
[12:11:51.490] iteration 1658: loss: 0.926234, loss_s1: 0.500527, loss_fp: 0.500110, loss_freq: 0.501699
[12:11:52.105] iteration 1659: loss: 0.889871, loss_s1: 0.502105, loss_fp: 0.500022, loss_freq: 0.501734
[12:11:52.720] iteration 1660: loss: 1.007071, loss_s1: 0.504818, loss_fp: 0.500082, loss_freq: 0.501199
[12:11:53.346] iteration 1661: loss: 0.976286, loss_s1: 0.503270, loss_fp: 0.500011, loss_freq: 0.503383
[12:11:53.965] iteration 1662: loss: 0.840789, loss_s1: 0.502642, loss_fp: 0.500079, loss_freq: 0.504220
[12:11:54.624] iteration 1663: loss: 0.893230, loss_s1: 0.502719, loss_fp: 0.500028, loss_freq: 0.500324
[12:11:55.275] iteration 1664: loss: 0.956720, loss_s1: 0.504056, loss_fp: 0.500142, loss_freq: 0.501204
[12:11:55.927] iteration 1665: loss: 0.949656, loss_s1: 0.503833, loss_fp: 0.500040, loss_freq: 0.503200
[12:11:56.568] iteration 1666: loss: 0.901937, loss_s1: 0.501260, loss_fp: 0.500017, loss_freq: 0.500243
[12:11:57.186] iteration 1667: loss: 0.996617, loss_s1: 0.502592, loss_fp: 0.500057, loss_freq: 0.501004
[12:11:57.804] iteration 1668: loss: 0.892654, loss_s1: 0.501009, loss_fp: 0.500031, loss_freq: 0.500118
[12:11:58.419] iteration 1669: loss: 0.934271, loss_s1: 0.504763, loss_fp: 0.500070, loss_freq: 0.500264
[12:11:59.036] iteration 1670: loss: 0.919577, loss_s1: 0.505942, loss_fp: 0.500009, loss_freq: 0.501324
[12:11:59.649] iteration 1671: loss: 0.891747, loss_s1: 0.500872, loss_fp: 0.500030, loss_freq: 0.500825
[12:12:00.263] iteration 1672: loss: 0.823617, loss_s1: 0.481144, loss_fp: 0.107485, loss_freq: 0.412677
[12:12:00.875] iteration 1673: loss: 0.974857, loss_s1: 0.501708, loss_fp: 0.500024, loss_freq: 0.501010
[12:12:01.491] iteration 1674: loss: 0.900201, loss_s1: 0.501888, loss_fp: 0.500036, loss_freq: 0.502433
[12:12:02.110] iteration 1675: loss: 0.910820, loss_s1: 0.501627, loss_fp: 0.500076, loss_freq: 0.500289
[12:12:02.727] iteration 1676: loss: 0.912948, loss_s1: 0.501923, loss_fp: 0.500023, loss_freq: 0.500873
[12:12:03.341] iteration 1677: loss: 0.902061, loss_s1: 0.504072, loss_fp: 0.500076, loss_freq: 0.501429
[12:12:03.961] iteration 1678: loss: 0.957945, loss_s1: 0.501023, loss_fp: 0.500093, loss_freq: 0.500983
[12:12:04.582] iteration 1679: loss: 0.945194, loss_s1: 0.501344, loss_fp: 0.500062, loss_freq: 0.500923
[12:12:05.200] iteration 1680: loss: 0.875982, loss_s1: 0.504048, loss_fp: 0.500213, loss_freq: 0.502094
[12:12:05.824] iteration 1681: loss: 0.851456, loss_s1: 0.502340, loss_fp: 0.500049, loss_freq: 0.501095
[12:12:06.445] iteration 1682: loss: 0.954229, loss_s1: 0.502723, loss_fp: 0.500144, loss_freq: 0.501163
[12:12:07.065] iteration 1683: loss: 0.885479, loss_s1: 0.503083, loss_fp: 0.500037, loss_freq: 0.501409
[12:12:07.677] iteration 1684: loss: 0.896214, loss_s1: 0.502804, loss_fp: 0.500035, loss_freq: 0.503028
[12:12:08.295] iteration 1685: loss: 0.884835, loss_s1: 0.504507, loss_fp: 0.500043, loss_freq: 0.502058
[12:12:08.915] iteration 1686: loss: 0.884711, loss_s1: 0.502047, loss_fp: 0.500038, loss_freq: 0.500778
[12:12:09.524] iteration 1687: loss: 0.836631, loss_s1: 0.502553, loss_fp: 0.500078, loss_freq: 0.502381
[12:12:10.140] iteration 1688: loss: 1.045526, loss_s1: 0.503173, loss_fp: 0.500036, loss_freq: 0.503917
[12:12:10.761] iteration 1689: loss: 0.901255, loss_s1: 0.503220, loss_fp: 0.500026, loss_freq: 0.501956
[12:12:11.375] iteration 1690: loss: 0.904808, loss_s1: 0.503348, loss_fp: 0.500033, loss_freq: 0.501373
[12:12:11.992] iteration 1691: loss: 0.965167, loss_s1: 0.504232, loss_fp: 0.500086, loss_freq: 0.501958
[12:12:12.619] iteration 1692: loss: 0.860515, loss_s1: 0.505743, loss_fp: 0.500034, loss_freq: 0.501255
[12:12:13.234] iteration 1693: loss: 0.896277, loss_s1: 0.508783, loss_fp: 0.500045, loss_freq: 0.501363
[12:12:13.854] iteration 1694: loss: 0.686875, loss_s1: 0.475482, loss_fp: 0.081849, loss_freq: 0.424651
[12:12:14.471] iteration 1695: loss: 1.018517, loss_s1: 0.501068, loss_fp: 0.500067, loss_freq: 0.502045
[12:12:15.081] iteration 1696: loss: 0.961350, loss_s1: 0.504059, loss_fp: 0.500017, loss_freq: 0.503031
[12:12:15.702] iteration 1697: loss: 0.856207, loss_s1: 0.501977, loss_fp: 0.500141, loss_freq: 0.501165
[12:12:16.326] iteration 1698: loss: 0.912715, loss_s1: 0.503717, loss_fp: 0.500108, loss_freq: 0.501940
[12:12:16.943] iteration 1699: loss: 0.913002, loss_s1: 0.502963, loss_fp: 0.500038, loss_freq: 0.502646
[12:12:17.566] iteration 1700: loss: 0.904602, loss_s1: 0.501863, loss_fp: 0.500045, loss_freq: 0.502370
[12:12:18.188] iteration 1701: loss: 0.847995, loss_s1: 0.502811, loss_fp: 0.500092, loss_freq: 0.500564
[12:12:18.806] iteration 1702: loss: 0.927568, loss_s1: 0.502684, loss_fp: 0.500070, loss_freq: 0.501688
[12:12:19.432] iteration 1703: loss: 0.866128, loss_s1: 0.503603, loss_fp: 0.500031, loss_freq: 0.501748
[12:12:20.057] iteration 1704: loss: 0.937581, loss_s1: 0.500572, loss_fp: 0.500049, loss_freq: 0.500310
[12:12:20.674] iteration 1705: loss: 0.917858, loss_s1: 0.500790, loss_fp: 0.500030, loss_freq: 0.501849
[12:12:21.300] iteration 1706: loss: 0.869906, loss_s1: 0.505074, loss_fp: 0.500042, loss_freq: 0.500410
[12:12:21.913] iteration 1707: loss: 0.977391, loss_s1: 0.502907, loss_fp: 0.500015, loss_freq: 0.501188
[12:12:22.529] iteration 1708: loss: 0.959410, loss_s1: 0.503718, loss_fp: 0.500046, loss_freq: 0.501206
[12:12:23.248] iteration 1709: loss: 0.884243, loss_s1: 0.505163, loss_fp: 0.500042, loss_freq: 0.501242
[12:12:23.878] iteration 1710: loss: 0.908143, loss_s1: 0.500794, loss_fp: 0.500122, loss_freq: 0.500739
[12:12:24.512] iteration 1711: loss: 0.893818, loss_s1: 0.505757, loss_fp: 0.500027, loss_freq: 0.500868
[12:12:25.145] iteration 1712: loss: 0.893012, loss_s1: 0.504525, loss_fp: 0.500034, loss_freq: 0.501136
[12:12:25.760] iteration 1713: loss: 0.926059, loss_s1: 0.503986, loss_fp: 0.500035, loss_freq: 0.501179
[12:12:26.431] iteration 1714: loss: 0.985189, loss_s1: 0.501607, loss_fp: 0.500020, loss_freq: 0.500151
[12:12:27.035] iteration 1715: loss: 0.890493, loss_s1: 0.501779, loss_fp: 0.500067, loss_freq: 0.501475
[12:12:27.642] iteration 1716: loss: 0.857613, loss_s1: 0.502952, loss_fp: 0.500040, loss_freq: 0.501013
[12:12:28.651] iteration 1717: loss: 0.957647, loss_s1: 0.500740, loss_fp: 0.500077, loss_freq: 0.500970
[12:12:29.278] iteration 1718: loss: 0.869538, loss_s1: 0.503095, loss_fp: 0.500055, loss_freq: 0.500684
[12:12:29.893] iteration 1719: loss: 0.855776, loss_s1: 0.503470, loss_fp: 0.500059, loss_freq: 0.500769
[12:12:30.510] iteration 1720: loss: 0.905309, loss_s1: 0.501319, loss_fp: 0.500039, loss_freq: 0.500189
[12:12:31.129] iteration 1721: loss: 0.888714, loss_s1: 0.501256, loss_fp: 0.500056, loss_freq: 0.500610
[12:12:31.753] iteration 1722: loss: 0.896476, loss_s1: 0.502497, loss_fp: 0.500042, loss_freq: 0.501219
[12:12:32.406] iteration 1723: loss: 0.880818, loss_s1: 0.506174, loss_fp: 0.500019, loss_freq: 0.502049
[12:12:33.028] iteration 1724: loss: 0.951705, loss_s1: 0.506046, loss_fp: 0.500055, loss_freq: 0.502327
[12:12:33.653] iteration 1725: loss: 0.488332, loss_s1: 0.367309, loss_fp: 0.063735, loss_freq: 0.333685
[12:12:34.278] iteration 1726: loss: 1.019879, loss_s1: 0.500767, loss_fp: 0.500035, loss_freq: 0.502762
[12:12:34.905] iteration 1727: loss: 0.867414, loss_s1: 0.501346, loss_fp: 0.500027, loss_freq: 0.500434
[12:12:35.520] iteration 1728: loss: 0.898308, loss_s1: 0.501583, loss_fp: 0.500028, loss_freq: 0.500674
[12:12:36.143] iteration 1729: loss: 0.975594, loss_s1: 0.501127, loss_fp: 0.500040, loss_freq: 0.500756
[12:12:36.763] iteration 1730: loss: 0.852538, loss_s1: 0.500986, loss_fp: 0.500059, loss_freq: 0.500122
[12:12:37.390] iteration 1731: loss: 1.000506, loss_s1: 0.501219, loss_fp: 0.500017, loss_freq: 0.500260
[12:12:38.019] iteration 1732: loss: 0.912825, loss_s1: 0.500983, loss_fp: 0.500013, loss_freq: 0.500337
[12:12:38.646] iteration 1733: loss: 1.028428, loss_s1: 0.500518, loss_fp: 0.500023, loss_freq: 0.500237
[12:12:39.270] iteration 1734: loss: 0.961911, loss_s1: 0.500802, loss_fp: 0.500017, loss_freq: 0.500235
[12:12:39.896] iteration 1735: loss: 0.875246, loss_s1: 0.504985, loss_fp: 0.500016, loss_freq: 0.501021
[12:12:40.515] iteration 1736: loss: 0.951667, loss_s1: 0.504120, loss_fp: 0.500028, loss_freq: 0.500825
[12:12:41.128] iteration 1737: loss: 0.959907, loss_s1: 0.502543, loss_fp: 0.500027, loss_freq: 0.500574
[12:12:41.752] iteration 1738: loss: 0.911610, loss_s1: 0.507608, loss_fp: 0.500045, loss_freq: 0.502837
[12:12:42.373] iteration 1739: loss: 0.888785, loss_s1: 0.503123, loss_fp: 0.500089, loss_freq: 0.500609
[12:12:43.034] iteration 1740: loss: 0.956196, loss_s1: 0.501171, loss_fp: 0.500008, loss_freq: 0.500272
[12:12:43.688] iteration 1741: loss: 0.863348, loss_s1: 0.502172, loss_fp: 0.500039, loss_freq: 0.500813
[12:12:44.344] iteration 1742: loss: 0.943714, loss_s1: 0.501341, loss_fp: 0.500043, loss_freq: 0.500467
[12:12:45.005] iteration 1743: loss: 0.938155, loss_s1: 0.500829, loss_fp: 0.500018, loss_freq: 0.500600
[12:12:45.634] iteration 1744: loss: 0.860845, loss_s1: 0.501610, loss_fp: 0.500021, loss_freq: 0.500552
[12:12:46.279] iteration 1745: loss: 1.037446, loss_s1: 0.504298, loss_fp: 0.500028, loss_freq: 0.500346
[12:12:46.945] iteration 1746: loss: 0.977522, loss_s1: 0.501416, loss_fp: 0.500019, loss_freq: 0.500421
[12:12:47.598] iteration 1747: loss: 0.508601, loss_s1: 0.369390, loss_fp: 0.053308, loss_freq: 0.343775
[12:12:48.219] iteration 1748: loss: 0.888631, loss_s1: 0.502361, loss_fp: 0.500017, loss_freq: 0.500245
[12:12:48.837] iteration 1749: loss: 0.934811, loss_s1: 0.502834, loss_fp: 0.500053, loss_freq: 0.500203
[12:12:49.453] iteration 1750: loss: 0.876793, loss_s1: 0.503105, loss_fp: 0.500043, loss_freq: 0.500170
[12:12:50.072] iteration 1751: loss: 1.023687, loss_s1: 0.501410, loss_fp: 0.500022, loss_freq: 0.500687
[12:12:50.695] iteration 1752: loss: 0.967288, loss_s1: 0.501582, loss_fp: 0.500018, loss_freq: 0.501325
[12:12:51.319] iteration 1753: loss: 0.907864, loss_s1: 0.500642, loss_fp: 0.500023, loss_freq: 0.500538
[12:12:51.945] iteration 1754: loss: 0.879797, loss_s1: 0.500768, loss_fp: 0.500021, loss_freq: 0.500100
[12:12:52.574] iteration 1755: loss: 0.947615, loss_s1: 0.501264, loss_fp: 0.500015, loss_freq: 0.501016
[12:12:53.195] iteration 1756: loss: 0.936237, loss_s1: 0.500478, loss_fp: 0.500020, loss_freq: 0.500136
[12:12:53.818] iteration 1757: loss: 0.884295, loss_s1: 0.466061, loss_fp: 0.500031, loss_freq: 0.502369
[12:12:54.447] iteration 1758: loss: 0.876736, loss_s1: 0.502778, loss_fp: 0.500024, loss_freq: 0.500462
[12:12:55.092] iteration 1759: loss: 0.885430, loss_s1: 0.501697, loss_fp: 0.500017, loss_freq: 0.500291
[12:12:55.734] iteration 1760: loss: 0.835909, loss_s1: 0.501922, loss_fp: 0.500019, loss_freq: 0.501310
[12:12:56.362] iteration 1761: loss: 1.017155, loss_s1: 0.504160, loss_fp: 0.500010, loss_freq: 0.501111
[12:12:56.984] iteration 1762: loss: 0.882246, loss_s1: 0.502318, loss_fp: 0.500027, loss_freq: 0.501222
[12:12:57.594] iteration 1763: loss: 0.872512, loss_s1: 0.503214, loss_fp: 0.500029, loss_freq: 0.501793
[12:12:58.223] iteration 1764: loss: 0.948966, loss_s1: 0.502182, loss_fp: 0.500042, loss_freq: 0.500219
[12:12:58.849] iteration 1765: loss: 0.860027, loss_s1: 0.501555, loss_fp: 0.500042, loss_freq: 0.500507
[12:12:59.479] iteration 1766: loss: 0.860486, loss_s1: 0.502778, loss_fp: 0.500055, loss_freq: 0.500883
[12:13:00.122] iteration 1767: loss: 0.899112, loss_s1: 0.505223, loss_fp: 0.500021, loss_freq: 0.500763
[12:13:00.744] iteration 1768: loss: 1.001390, loss_s1: 0.502681, loss_fp: 0.500051, loss_freq: 0.501960
[12:13:01.366] iteration 1769: loss: 0.948872, loss_s1: 0.502246, loss_fp: 0.500035, loss_freq: 0.502731
[12:13:01.992] iteration 1770: loss: 0.842018, loss_s1: 0.503119, loss_fp: 0.500049, loss_freq: 0.500346
[12:13:02.613] iteration 1771: loss: 0.910614, loss_s1: 0.500969, loss_fp: 0.500068, loss_freq: 0.501244
[12:13:03.226] iteration 1772: loss: 0.909362, loss_s1: 0.500331, loss_fp: 0.500011, loss_freq: 0.500539
[12:13:03.842] iteration 1773: loss: 0.880411, loss_s1: 0.507456, loss_fp: 0.500018, loss_freq: 0.501859
[12:13:04.492] iteration 1774: loss: 0.833759, loss_s1: 0.501644, loss_fp: 0.500011, loss_freq: 0.500560
[12:13:05.173] iteration 1775: loss: 0.962119, loss_s1: 0.505182, loss_fp: 0.500019, loss_freq: 0.500775
[12:13:05.825] iteration 1776: loss: 0.861171, loss_s1: 0.501588, loss_fp: 0.500026, loss_freq: 0.500216
[12:13:06.443] iteration 1777: loss: 0.901787, loss_s1: 0.501900, loss_fp: 0.500025, loss_freq: 0.500410
[12:13:07.063] iteration 1778: loss: 0.912653, loss_s1: 0.501620, loss_fp: 0.500009, loss_freq: 0.500478
[12:13:07.681] iteration 1779: loss: 0.884401, loss_s1: 0.507641, loss_fp: 0.500040, loss_freq: 0.502420
[12:13:08.342] iteration 1780: loss: 0.954663, loss_s1: 0.503434, loss_fp: 0.500022, loss_freq: 0.501337
[12:13:08.999] iteration 1781: loss: 0.938416, loss_s1: 0.507413, loss_fp: 0.500031, loss_freq: 0.501218
[12:13:09.639] iteration 1782: loss: 0.910420, loss_s1: 0.505609, loss_fp: 0.500084, loss_freq: 0.501832
[12:13:10.251] iteration 1783: loss: 0.858843, loss_s1: 0.501793, loss_fp: 0.500021, loss_freq: 0.501007
[12:13:10.868] iteration 1784: loss: 0.909698, loss_s1: 0.503850, loss_fp: 0.500032, loss_freq: 0.500800
[12:13:11.502] iteration 1785: loss: 0.898877, loss_s1: 0.503660, loss_fp: 0.500008, loss_freq: 0.500433
[12:13:12.161] iteration 1786: loss: 0.929104, loss_s1: 0.502163, loss_fp: 0.500030, loss_freq: 0.500833
[12:13:12.815] iteration 1787: loss: 0.968757, loss_s1: 0.502129, loss_fp: 0.500018, loss_freq: 0.500877
[12:13:13.469] iteration 1788: loss: 0.884004, loss_s1: 0.501353, loss_fp: 0.500026, loss_freq: 0.500145
[12:13:14.127] iteration 1789: loss: 0.841827, loss_s1: 0.504912, loss_fp: 0.500036, loss_freq: 0.501109
[12:13:14.756] iteration 1790: loss: 0.946656, loss_s1: 0.504741, loss_fp: 0.500017, loss_freq: 0.503351
[12:13:15.374] iteration 1791: loss: 0.886568, loss_s1: 0.504804, loss_fp: 0.500034, loss_freq: 0.500288
[12:13:15.991] iteration 1792: loss: 0.929644, loss_s1: 0.500549, loss_fp: 0.500032, loss_freq: 0.500116
[12:13:16.640] iteration 1793: loss: 0.824936, loss_s1: 0.502443, loss_fp: 0.500023, loss_freq: 0.500829
[12:13:17.254] iteration 1794: loss: 0.457541, loss_s1: 0.364391, loss_fp: 0.011670, loss_freq: 0.213821
[12:13:17.875] iteration 1795: loss: 0.862958, loss_s1: 0.503412, loss_fp: 0.500073, loss_freq: 0.504668
[12:13:18.497] iteration 1796: loss: 0.975812, loss_s1: 0.366477, loss_fp: 0.500014, loss_freq: 0.500198
[12:13:19.118] iteration 1797: loss: 0.456582, loss_s1: 0.445824, loss_fp: 0.048600, loss_freq: 0.176188
[12:13:19.736] iteration 1798: loss: 0.884134, loss_s1: 0.502523, loss_fp: 0.500042, loss_freq: 0.500232
[12:13:20.413] iteration 1799: loss: 1.034062, loss_s1: 0.501775, loss_fp: 0.500033, loss_freq: 0.500302
[12:13:21.090] iteration 1800: loss: 0.882818, loss_s1: 0.503836, loss_fp: 0.500023, loss_freq: 0.500233
[12:13:23.226] iteration 1800 : mean_dice : 0.012838
[12:13:23.919] iteration 1801: loss: 0.934591, loss_s1: 0.502535, loss_fp: 0.500022, loss_freq: 0.500429
[12:13:24.563] iteration 1802: loss: 0.909799, loss_s1: 0.501405, loss_fp: 0.500030, loss_freq: 0.501726
[12:13:25.183] iteration 1803: loss: 0.898550, loss_s1: 0.501003, loss_fp: 0.245932, loss_freq: 0.484500
[12:13:25.826] iteration 1804: loss: 1.014441, loss_s1: 0.501294, loss_fp: 0.500005, loss_freq: 0.500353
[12:13:26.486] iteration 1805: loss: 0.684199, loss_s1: 0.500473, loss_fp: 0.156902, loss_freq: 0.484048
[12:13:27.146] iteration 1806: loss: 0.924181, loss_s1: 0.500570, loss_fp: 0.500009, loss_freq: 0.500269
[12:13:27.768] iteration 1807: loss: 0.909428, loss_s1: 0.501124, loss_fp: 0.500004, loss_freq: 0.500207
[12:13:28.389] iteration 1808: loss: 0.948784, loss_s1: 0.502116, loss_fp: 0.500032, loss_freq: 0.500563
[12:13:29.010] iteration 1809: loss: 0.875050, loss_s1: 0.501154, loss_fp: 0.500000, loss_freq: 0.500147
[12:13:29.640] iteration 1810: loss: 0.990810, loss_s1: 0.501266, loss_fp: 0.500038, loss_freq: 0.500431
[12:13:30.259] iteration 1811: loss: 0.925440, loss_s1: 0.500654, loss_fp: 0.500002, loss_freq: 0.500076
[12:13:30.881] iteration 1812: loss: 0.991736, loss_s1: 0.501871, loss_fp: 0.500005, loss_freq: 0.501210
[12:13:31.509] iteration 1813: loss: 1.018987, loss_s1: 0.503788, loss_fp: 0.500003, loss_freq: 0.500992
[12:13:32.126] iteration 1814: loss: 0.916220, loss_s1: 0.504148, loss_fp: 0.500002, loss_freq: 0.500409
[12:13:32.740] iteration 1815: loss: 1.056681, loss_s1: 0.501333, loss_fp: 0.500006, loss_freq: 0.501937
[12:13:33.356] iteration 1816: loss: 0.977889, loss_s1: 0.504076, loss_fp: 0.500000, loss_freq: 0.500510
[12:13:33.982] iteration 1817: loss: 0.930950, loss_s1: 0.502364, loss_fp: 0.500019, loss_freq: 0.502472
[12:13:34.597] iteration 1818: loss: 0.955201, loss_s1: 0.502585, loss_fp: 0.500003, loss_freq: 0.500298
[12:13:35.209] iteration 1819: loss: 0.980834, loss_s1: 0.502076, loss_fp: 0.500006, loss_freq: 0.500335
[12:13:35.826] iteration 1820: loss: 0.990977, loss_s1: 0.504465, loss_fp: 0.500011, loss_freq: 0.500963
[12:13:36.450] iteration 1821: loss: 1.006029, loss_s1: 0.502401, loss_fp: 0.500035, loss_freq: 0.500580
[12:13:37.069] iteration 1822: loss: 1.016279, loss_s1: 0.501911, loss_fp: 0.499997, loss_freq: 0.501875
[12:13:37.693] iteration 1823: loss: 0.911278, loss_s1: 0.502473, loss_fp: 0.500015, loss_freq: 0.500910
[12:13:38.312] iteration 1824: loss: 0.906013, loss_s1: 0.504123, loss_fp: 0.500012, loss_freq: 0.500207
[12:13:38.928] iteration 1825: loss: 1.057531, loss_s1: 0.502067, loss_fp: 0.500022, loss_freq: 0.500364
[12:13:39.590] iteration 1826: loss: 0.936832, loss_s1: 0.502972, loss_fp: 0.500009, loss_freq: 0.500607
[12:13:40.214] iteration 1827: loss: 0.946928, loss_s1: 0.503733, loss_fp: 0.500027, loss_freq: 0.500927
[12:13:40.835] iteration 1828: loss: 0.898842, loss_s1: 0.502130, loss_fp: 0.500029, loss_freq: 0.500708
[12:13:41.523] iteration 1829: loss: 0.934156, loss_s1: 0.500817, loss_fp: 0.500018, loss_freq: 0.500721
[12:13:42.153] iteration 1830: loss: 0.841444, loss_s1: 0.500450, loss_fp: 0.500054, loss_freq: 0.500385
[12:13:42.774] iteration 1831: loss: 1.108974, loss_s1: 0.501651, loss_fp: 0.500020, loss_freq: 0.501394
[12:13:43.388] iteration 1832: loss: 0.919184, loss_s1: 0.501681, loss_fp: 0.500016, loss_freq: 0.500364
[12:13:44.010] iteration 1833: loss: 0.941199, loss_s1: 0.502048, loss_fp: 0.500048, loss_freq: 0.500879
[12:13:44.626] iteration 1834: loss: 0.990678, loss_s1: 0.503542, loss_fp: 0.500019, loss_freq: 0.501333
[12:13:45.237] iteration 1835: loss: 0.899863, loss_s1: 0.503286, loss_fp: 0.500020, loss_freq: 0.501294
[12:13:45.855] iteration 1836: loss: 0.970809, loss_s1: 0.504827, loss_fp: 0.500017, loss_freq: 0.500621
[12:13:46.518] iteration 1837: loss: 0.938248, loss_s1: 0.504070, loss_fp: 0.500051, loss_freq: 0.500884
[12:13:47.171] iteration 1838: loss: 1.031045, loss_s1: 0.506241, loss_fp: 0.500015, loss_freq: 0.501867
[12:13:47.804] iteration 1839: loss: 0.979179, loss_s1: 0.503595, loss_fp: 0.500022, loss_freq: 0.500881
[12:13:48.458] iteration 1840: loss: 0.877699, loss_s1: 0.501716, loss_fp: 0.500014, loss_freq: 0.500510
[12:13:49.108] iteration 1841: loss: 0.948169, loss_s1: 0.503822, loss_fp: 0.500012, loss_freq: 0.500970
[12:13:49.721] iteration 1842: loss: 0.910827, loss_s1: 0.504101, loss_fp: 0.500009, loss_freq: 0.501063
[12:13:50.339] iteration 1843: loss: 0.944244, loss_s1: 0.504971, loss_fp: 0.500004, loss_freq: 0.501539
[12:13:50.958] iteration 1844: loss: 0.888146, loss_s1: 0.504746, loss_fp: 0.500016, loss_freq: 0.500312
[12:13:51.581] iteration 1845: loss: 1.002591, loss_s1: 0.502529, loss_fp: 0.500005, loss_freq: 0.501137
[12:13:52.196] iteration 1846: loss: 0.898529, loss_s1: 0.501103, loss_fp: 0.500032, loss_freq: 0.500988
[12:13:52.809] iteration 1847: loss: 0.937363, loss_s1: 0.500989, loss_fp: 0.500008, loss_freq: 0.500284
[12:13:53.423] iteration 1848: loss: 0.959820, loss_s1: 0.504049, loss_fp: 0.500028, loss_freq: 0.501020
[12:13:54.081] iteration 1849: loss: 0.891069, loss_s1: 0.503914, loss_fp: 0.500032, loss_freq: 0.500413
[12:13:54.732] iteration 1850: loss: 1.006044, loss_s1: 0.503148, loss_fp: 0.500008, loss_freq: 0.500911
[12:13:55.384] iteration 1851: loss: 0.959863, loss_s1: 0.506225, loss_fp: 0.500010, loss_freq: 0.500660
[12:13:56.003] iteration 1852: loss: 0.911617, loss_s1: 0.504877, loss_fp: 0.500014, loss_freq: 0.500351
[12:13:56.624] iteration 1853: loss: 0.869973, loss_s1: 0.501507, loss_fp: 0.500007, loss_freq: 0.500481
[12:13:57.244] iteration 1854: loss: 0.926546, loss_s1: 0.503800, loss_fp: 0.500049, loss_freq: 0.501795
[12:13:57.858] iteration 1855: loss: 0.922758, loss_s1: 0.502026, loss_fp: 0.500021, loss_freq: 0.500412
[12:13:58.477] iteration 1856: loss: 0.952108, loss_s1: 0.507743, loss_fp: 0.500011, loss_freq: 0.501334
[12:13:59.095] iteration 1857: loss: 0.929538, loss_s1: 0.501840, loss_fp: 0.500028, loss_freq: 0.500147
[12:13:59.706] iteration 1858: loss: 0.864617, loss_s1: 0.502121, loss_fp: 0.500023, loss_freq: 0.500683
[12:14:00.316] iteration 1859: loss: 0.861072, loss_s1: 0.504491, loss_fp: 0.500015, loss_freq: 0.500859
[12:14:01.215] iteration 1860: loss: 0.969326, loss_s1: 0.503434, loss_fp: 0.500087, loss_freq: 0.500691
[12:14:01.842] iteration 1861: loss: 0.873900, loss_s1: 0.504733, loss_fp: 0.500009, loss_freq: 0.500190
[12:14:02.465] iteration 1862: loss: 0.843453, loss_s1: 0.501938, loss_fp: 0.500030, loss_freq: 0.502066
[12:14:03.089] iteration 1863: loss: 0.915768, loss_s1: 0.502350, loss_fp: 0.500025, loss_freq: 0.500156
[12:14:03.702] iteration 1864: loss: 0.883554, loss_s1: 0.500814, loss_fp: 0.500051, loss_freq: 0.501319
[12:14:04.323] iteration 1865: loss: 0.899695, loss_s1: 0.503105, loss_fp: 0.500013, loss_freq: 0.500862
[12:14:04.937] iteration 1866: loss: 0.896377, loss_s1: 0.503282, loss_fp: 0.500017, loss_freq: 0.501471
[12:14:05.545] iteration 1867: loss: 0.901539, loss_s1: 0.501278, loss_fp: 0.500239, loss_freq: 0.501813
[12:14:06.164] iteration 1868: loss: 0.497997, loss_s1: 0.472683, loss_fp: 0.008233, loss_freq: 0.346898
[12:14:06.787] iteration 1869: loss: 1.018895, loss_s1: 0.501689, loss_fp: 0.500016, loss_freq: 0.504248
[12:14:07.407] iteration 1870: loss: 0.863311, loss_s1: 0.503463, loss_fp: 0.500014, loss_freq: 0.500544
[12:14:08.024] iteration 1871: loss: 0.908669, loss_s1: 0.504254, loss_fp: 0.500019, loss_freq: 0.501491
[12:14:08.647] iteration 1872: loss: 0.929325, loss_s1: 0.504755, loss_fp: 0.500008, loss_freq: 0.500913
[12:14:09.265] iteration 1873: loss: 0.888802, loss_s1: 0.500582, loss_fp: 0.500069, loss_freq: 0.500448
[12:14:09.878] iteration 1874: loss: 0.447646, loss_s1: 0.452207, loss_fp: 0.013718, loss_freq: 0.113708
[12:14:10.497] iteration 1875: loss: 0.898435, loss_s1: 0.501859, loss_fp: 0.500014, loss_freq: 0.500426
[12:14:11.113] iteration 1876: loss: 1.049355, loss_s1: 0.504489, loss_fp: 0.500010, loss_freq: 0.500471
[12:14:11.731] iteration 1877: loss: 0.987653, loss_s1: 0.502401, loss_fp: 0.500006, loss_freq: 0.501649
[12:14:12.341] iteration 1878: loss: 0.849452, loss_s1: 0.502702, loss_fp: 0.500014, loss_freq: 0.500401
[12:14:12.955] iteration 1879: loss: 0.969551, loss_s1: 0.500627, loss_fp: 0.500006, loss_freq: 0.500298
[12:14:13.572] iteration 1880: loss: 0.944635, loss_s1: 0.503945, loss_fp: 0.500004, loss_freq: 0.500405
[12:14:14.185] iteration 1881: loss: 0.896245, loss_s1: 0.502741, loss_fp: 0.500012, loss_freq: 0.502192
[12:14:14.803] iteration 1882: loss: 0.871308, loss_s1: 0.502422, loss_fp: 0.500018, loss_freq: 0.500261
[12:14:15.423] iteration 1883: loss: 0.949388, loss_s1: 0.500714, loss_fp: 0.500005, loss_freq: 0.500572
[12:14:16.036] iteration 1884: loss: 0.855907, loss_s1: 0.502592, loss_fp: 0.500008, loss_freq: 0.500162
[12:14:16.649] iteration 1885: loss: 0.936737, loss_s1: 0.502370, loss_fp: 0.500010, loss_freq: 0.500635
[12:14:17.263] iteration 1886: loss: 0.926555, loss_s1: 0.500593, loss_fp: 0.500004, loss_freq: 0.500208
[12:14:17.881] iteration 1887: loss: 0.858899, loss_s1: 0.501508, loss_fp: 0.500013, loss_freq: 0.500481
[12:14:18.500] iteration 1888: loss: 1.005740, loss_s1: 0.502112, loss_fp: 0.500010, loss_freq: 0.500728
[12:14:19.169] iteration 1889: loss: 0.942724, loss_s1: 0.500321, loss_fp: 0.500011, loss_freq: 0.500069
[12:14:19.816] iteration 1890: loss: 0.895634, loss_s1: 0.501377, loss_fp: 0.500012, loss_freq: 0.500134
[12:14:20.470] iteration 1891: loss: 0.892405, loss_s1: 0.500782, loss_fp: 0.500022, loss_freq: 0.500836
[12:14:21.118] iteration 1892: loss: 0.876964, loss_s1: 0.502284, loss_fp: 0.500000, loss_freq: 0.500206
[12:14:21.770] iteration 1893: loss: 0.883835, loss_s1: 0.501269, loss_fp: 0.500010, loss_freq: 0.501169
[12:14:22.425] iteration 1894: loss: 0.931753, loss_s1: 0.503559, loss_fp: 0.500012, loss_freq: 0.500298
[12:14:23.043] iteration 1895: loss: 0.968501, loss_s1: 0.502938, loss_fp: 0.500009, loss_freq: 0.500487
[12:14:23.657] iteration 1896: loss: 0.872677, loss_s1: 0.502249, loss_fp: 0.500013, loss_freq: 0.501518
[12:14:24.271] iteration 1897: loss: 0.862544, loss_s1: 0.502951, loss_fp: 0.500029, loss_freq: 0.500412
[12:14:24.884] iteration 1898: loss: 0.923514, loss_s1: 0.503872, loss_fp: 0.500010, loss_freq: 0.501018
[12:14:25.502] iteration 1899: loss: 0.876420, loss_s1: 0.500600, loss_fp: 0.500020, loss_freq: 0.500543
[12:14:26.119] iteration 1900: loss: 0.893993, loss_s1: 0.501339, loss_fp: 0.500013, loss_freq: 0.501120
[12:14:26.735] iteration 1901: loss: 0.927574, loss_s1: 0.502358, loss_fp: 0.500015, loss_freq: 0.501474
[12:14:27.354] iteration 1902: loss: 0.894614, loss_s1: 0.504263, loss_fp: 0.500007, loss_freq: 0.501085
[12:14:28.032] iteration 1903: loss: 0.842040, loss_s1: 0.501281, loss_fp: 0.500013, loss_freq: 0.502159
[12:14:28.817] iteration 1904: loss: 1.000266, loss_s1: 0.503190, loss_fp: 0.500010, loss_freq: 0.501943
[12:14:29.540] iteration 1905: loss: 0.886776, loss_s1: 0.502635, loss_fp: 0.500014, loss_freq: 0.500595
[12:14:30.229] iteration 1906: loss: 0.872977, loss_s1: 0.501239, loss_fp: 0.500008, loss_freq: 0.501397
[12:14:30.882] iteration 1907: loss: 0.931537, loss_s1: 0.501567, loss_fp: 0.500015, loss_freq: 0.500213
[12:14:31.537] iteration 1908: loss: 0.859865, loss_s1: 0.502944, loss_fp: 0.500042, loss_freq: 0.501714
[12:14:32.188] iteration 1909: loss: 0.872410, loss_s1: 0.469474, loss_fp: 0.500010, loss_freq: 0.502773
[12:14:32.863] iteration 1910: loss: 0.911509, loss_s1: 0.508466, loss_fp: 0.500027, loss_freq: 0.500961
[12:14:33.602] iteration 1911: loss: 0.999718, loss_s1: 0.507365, loss_fp: 0.500017, loss_freq: 0.501336
[12:14:34.265] iteration 1912: loss: 0.988932, loss_s1: 0.501786, loss_fp: 0.500053, loss_freq: 0.500796
[12:14:34.928] iteration 1913: loss: 0.845400, loss_s1: 0.502393, loss_fp: 0.500029, loss_freq: 0.500055
[12:14:35.586] iteration 1914: loss: 0.915614, loss_s1: 0.503739, loss_fp: 0.500076, loss_freq: 0.503011
[12:14:36.240] iteration 1915: loss: 0.887584, loss_s1: 0.501461, loss_fp: 0.500012, loss_freq: 0.500452
[12:14:36.897] iteration 1916: loss: 0.846106, loss_s1: 0.502536, loss_fp: 0.500005, loss_freq: 0.501501
[12:14:37.556] iteration 1917: loss: 0.876708, loss_s1: 0.503388, loss_fp: 0.500010, loss_freq: 0.500327
[12:14:38.178] iteration 1918: loss: 0.920482, loss_s1: 0.503648, loss_fp: 0.500019, loss_freq: 0.500436
[12:14:38.801] iteration 1919: loss: 0.853973, loss_s1: 0.500670, loss_fp: 0.500007, loss_freq: 0.500392
[12:14:39.417] iteration 1920: loss: 0.931858, loss_s1: 0.504144, loss_fp: 0.500006, loss_freq: 0.500308
[12:14:40.032] iteration 1921: loss: 0.958274, loss_s1: 0.502755, loss_fp: 0.500006, loss_freq: 0.501205
[12:14:40.642] iteration 1922: loss: 0.893104, loss_s1: 0.504943, loss_fp: 0.500010, loss_freq: 0.501256
[12:14:41.257] iteration 1923: loss: 0.992904, loss_s1: 0.501307, loss_fp: 0.500033, loss_freq: 0.501000
[12:14:41.866] iteration 1924: loss: 0.994370, loss_s1: 0.500393, loss_fp: 0.500023, loss_freq: 0.500546
[12:14:42.476] iteration 1925: loss: 0.908961, loss_s1: 0.501848, loss_fp: 0.500029, loss_freq: 0.500770
[12:14:43.101] iteration 1926: loss: 0.864022, loss_s1: 0.504839, loss_fp: 0.500024, loss_freq: 0.500674
[12:14:43.732] iteration 1927: loss: 0.913477, loss_s1: 0.504541, loss_fp: 0.500017, loss_freq: 0.500662
[12:14:44.350] iteration 1928: loss: 0.883568, loss_s1: 0.502140, loss_fp: 0.500013, loss_freq: 0.500490
[12:14:44.963] iteration 1929: loss: 0.945675, loss_s1: 0.502760, loss_fp: 0.500006, loss_freq: 0.500328
[12:14:45.580] iteration 1930: loss: 0.937720, loss_s1: 0.502280, loss_fp: 0.500013, loss_freq: 0.500436
[12:14:46.195] iteration 1931: loss: 0.874219, loss_s1: 0.500481, loss_fp: 0.500017, loss_freq: 0.500239
[12:14:46.814] iteration 1932: loss: 0.848492, loss_s1: 0.503641, loss_fp: 0.500024, loss_freq: 0.501526
[12:14:47.429] iteration 1933: loss: 0.955361, loss_s1: 0.503321, loss_fp: 0.500007, loss_freq: 0.500842
[12:14:48.052] iteration 1934: loss: 0.865529, loss_s1: 0.502609, loss_fp: 0.500015, loss_freq: 0.501452
[12:14:48.676] iteration 1935: loss: 0.866893, loss_s1: 0.501993, loss_fp: 0.500075, loss_freq: 0.501074
[12:14:49.304] iteration 1936: loss: 0.865722, loss_s1: 0.504402, loss_fp: 0.500028, loss_freq: 0.500654
[12:14:49.931] iteration 1937: loss: 0.880240, loss_s1: 0.501214, loss_fp: 0.500017, loss_freq: 0.500477
[12:14:50.589] iteration 1938: loss: 0.824071, loss_s1: 0.503906, loss_fp: 0.500018, loss_freq: 0.501495
[12:14:51.273] iteration 1939: loss: 0.962564, loss_s1: 0.307462, loss_fp: 0.500011, loss_freq: 0.500503
[12:14:51.962] iteration 1940: loss: 0.760808, loss_s1: 0.308800, loss_fp: 0.500062, loss_freq: 0.500326
[12:14:52.613] iteration 1941: loss: 0.912506, loss_s1: 0.501444, loss_fp: 0.500020, loss_freq: 0.500806
[12:14:53.264] iteration 1942: loss: 0.968977, loss_s1: 0.500518, loss_fp: 0.500019, loss_freq: 0.500104
[12:14:53.916] iteration 1943: loss: 0.837431, loss_s1: 0.499274, loss_fp: 0.500019, loss_freq: 0.500305
[12:14:54.573] iteration 1944: loss: 0.559657, loss_s1: 0.355245, loss_fp: 0.046230, loss_freq: 0.400282
[12:14:55.228] iteration 1945: loss: 0.836754, loss_s1: 0.497030, loss_fp: 0.337280, loss_freq: 0.493853
[12:14:55.870] iteration 1946: loss: 0.511817, loss_s1: 0.271229, loss_fp: 0.005822, loss_freq: 0.182024
[12:14:56.486] iteration 1947: loss: 0.998622, loss_s1: 0.502265, loss_fp: 0.500009, loss_freq: 0.500265
[12:14:57.096] iteration 1948: loss: 0.880226, loss_s1: 0.501833, loss_fp: 0.500008, loss_freq: 0.500305
[12:14:57.714] iteration 1949: loss: 0.302426, loss_s1: 0.179903, loss_fp: 0.005043, loss_freq: 0.101541
[12:14:58.333] iteration 1950: loss: 0.216573, loss_s1: 0.047532, loss_fp: 0.025437, loss_freq: 0.022260
[12:14:58.948] iteration 1951: loss: 0.975519, loss_s1: 0.501256, loss_fp: 0.499999, loss_freq: 0.500284
[12:14:59.556] iteration 1952: loss: 0.870282, loss_s1: 0.500071, loss_fp: 0.500006, loss_freq: 0.500030
[12:15:00.169] iteration 1953: loss: 0.514607, loss_s1: 0.500348, loss_fp: 0.028304, loss_freq: 0.096007
[12:15:00.783] iteration 1954: loss: 0.747130, loss_s1: 0.180022, loss_fp: 0.500001, loss_freq: 0.500009
[12:15:01.407] iteration 1955: loss: 1.054836, loss_s1: 0.500368, loss_fp: 0.500015, loss_freq: 0.500085
[12:15:02.025] iteration 1956: loss: 1.060375, loss_s1: 0.500571, loss_fp: 0.500004, loss_freq: 0.500201
[12:15:02.645] iteration 1957: loss: 0.947803, loss_s1: 0.500117, loss_fp: 0.500007, loss_freq: 0.500166
[12:15:03.258] iteration 1958: loss: 1.063322, loss_s1: 0.472816, loss_fp: 0.500004, loss_freq: 0.500112
[12:15:03.876] iteration 1959: loss: 0.972411, loss_s1: 0.501670, loss_fp: 0.500008, loss_freq: 0.500174
[12:15:04.494] iteration 1960: loss: 0.888216, loss_s1: 0.501330, loss_fp: 0.500004, loss_freq: 0.500692
[12:15:05.103] iteration 1961: loss: 0.875108, loss_s1: 0.501939, loss_fp: 0.500005, loss_freq: 0.500060
[12:15:05.720] iteration 1962: loss: 0.946938, loss_s1: 0.501180, loss_fp: 0.500004, loss_freq: 0.500558
[12:15:06.331] iteration 1963: loss: 0.935411, loss_s1: 0.501396, loss_fp: 0.500023, loss_freq: 0.501862
[12:15:06.949] iteration 1964: loss: 0.951340, loss_s1: 0.502383, loss_fp: 0.500003, loss_freq: 0.500397
[12:15:07.563] iteration 1965: loss: 1.026057, loss_s1: 0.502204, loss_fp: 0.499998, loss_freq: 0.500775
[12:15:08.181] iteration 1966: loss: 0.905790, loss_s1: 0.502390, loss_fp: 0.500005, loss_freq: 0.502082
[12:15:08.790] iteration 1967: loss: 0.858914, loss_s1: 0.503846, loss_fp: 0.500023, loss_freq: 0.500185
[12:15:09.408] iteration 1968: loss: 0.863647, loss_s1: 0.241626, loss_fp: 0.500009, loss_freq: 0.500271
[12:15:10.029] iteration 1969: loss: 0.924890, loss_s1: 0.504236, loss_fp: 0.500004, loss_freq: 0.500452
[12:15:10.646] iteration 1970: loss: 0.917714, loss_s1: 0.501683, loss_fp: 0.500003, loss_freq: 0.500789
[12:15:11.262] iteration 1971: loss: 0.843026, loss_s1: 0.502210, loss_fp: 0.500003, loss_freq: 0.500191
[12:15:11.883] iteration 1972: loss: 0.896904, loss_s1: 0.501870, loss_fp: 0.500009, loss_freq: 0.500573
[12:15:12.503] iteration 1973: loss: 0.852324, loss_s1: 0.502856, loss_fp: 0.500009, loss_freq: 0.500349
[12:15:13.128] iteration 1974: loss: 1.086042, loss_s1: 0.500812, loss_fp: 0.500034, loss_freq: 0.501177
[12:15:13.757] iteration 1975: loss: 0.884787, loss_s1: 0.500692, loss_fp: 0.500020, loss_freq: 0.500161
[12:15:14.428] iteration 1976: loss: 0.904810, loss_s1: 0.502150, loss_fp: 0.500008, loss_freq: 0.501441
[12:15:15.088] iteration 1977: loss: 0.941772, loss_s1: 0.502203, loss_fp: 0.500011, loss_freq: 0.500560
[12:15:15.706] iteration 1978: loss: 0.871976, loss_s1: 0.504308, loss_fp: 0.500013, loss_freq: 0.500603
[12:15:16.327] iteration 1979: loss: 0.943616, loss_s1: 0.503399, loss_fp: 0.500012, loss_freq: 0.500719
[12:15:16.967] iteration 1980: loss: 0.442833, loss_s1: 0.384001, loss_fp: 0.009416, loss_freq: 0.196872
[12:15:17.643] iteration 1981: loss: 0.623461, loss_s1: 0.403381, loss_fp: 0.006786, loss_freq: 0.214614
[12:15:18.302] iteration 1982: loss: 1.007797, loss_s1: 0.502511, loss_fp: 0.500009, loss_freq: 0.500234
[12:15:18.978] iteration 1983: loss: 0.847621, loss_s1: 0.500563, loss_fp: 0.500006, loss_freq: 0.500150
[12:15:19.592] iteration 1984: loss: 0.892337, loss_s1: 0.496179, loss_fp: 0.500009, loss_freq: 0.500256
[12:15:20.208] iteration 1985: loss: 0.914162, loss_s1: 0.501632, loss_fp: 0.500004, loss_freq: 0.500109
[12:15:20.828] iteration 1986: loss: 0.961898, loss_s1: 0.500095, loss_fp: 0.500011, loss_freq: 0.500311
[12:15:21.444] iteration 1987: loss: 0.889360, loss_s1: 0.500947, loss_fp: 0.500007, loss_freq: 0.500029
[12:15:22.059] iteration 1988: loss: 0.471966, loss_s1: 0.289770, loss_fp: 0.008260, loss_freq: 0.135266
[12:15:22.673] iteration 1989: loss: 0.916499, loss_s1: 0.500736, loss_fp: 0.500010, loss_freq: 0.500063
[12:15:23.285] iteration 1990: loss: 0.407812, loss_s1: 0.094906, loss_fp: 0.070830, loss_freq: 0.200009
[12:15:23.913] iteration 1991: loss: 0.612177, loss_s1: 0.498024, loss_fp: 0.026902, loss_freq: 0.202188
[12:15:24.527] iteration 1992: loss: 0.892660, loss_s1: 0.500084, loss_fp: 0.500006, loss_freq: 0.500071
[12:15:25.149] iteration 1993: loss: 0.901557, loss_s1: 0.491561, loss_fp: 0.154795, loss_freq: 0.305946
[12:15:25.756] iteration 1994: loss: 1.035138, loss_s1: 0.500799, loss_fp: 0.500005, loss_freq: 0.500633
[12:15:26.432] iteration 1995: loss: 0.960901, loss_s1: 0.500036, loss_fp: 0.500012, loss_freq: 0.500017
[12:15:27.104] iteration 1996: loss: 0.914387, loss_s1: 0.500411, loss_fp: 0.499999, loss_freq: 0.500035
[12:15:27.794] iteration 1997: loss: 0.987633, loss_s1: 0.500965, loss_fp: 0.500005, loss_freq: 0.500028
[12:15:28.476] iteration 1998: loss: 0.932171, loss_s1: 0.500762, loss_fp: 0.499999, loss_freq: 0.500013
[12:15:29.135] iteration 1999: loss: 1.057024, loss_s1: 0.500697, loss_fp: 0.500050, loss_freq: 0.500572
[12:15:29.787] iteration 2000: loss: 0.992485, loss_s1: 0.500004, loss_fp: 0.500001, loss_freq: 0.500101
[12:15:32.799] iteration 2000 : mean_dice : 0.245608
[12:15:33.469] iteration 2001: loss: 0.935200, loss_s1: 0.500891, loss_fp: 0.500008, loss_freq: 0.500580
[12:15:34.118] iteration 2002: loss: 0.928235, loss_s1: 0.500021, loss_fp: 0.500009, loss_freq: 0.500051
[12:15:35.080] iteration 2003: loss: 0.940064, loss_s1: 0.502571, loss_fp: 0.500007, loss_freq: 0.500439
[12:15:35.701] iteration 2004: loss: 0.907725, loss_s1: 0.502516, loss_fp: 0.499997, loss_freq: 0.500265
[12:15:36.323] iteration 2005: loss: 0.865483, loss_s1: 0.501038, loss_fp: 0.500001, loss_freq: 0.501704
[12:15:36.977] iteration 2006: loss: 0.989657, loss_s1: 0.505066, loss_fp: 0.500006, loss_freq: 0.500246
[12:15:37.630] iteration 2007: loss: 0.918532, loss_s1: 0.501332, loss_fp: 0.500014, loss_freq: 0.500638
[12:15:38.284] iteration 2008: loss: 0.940606, loss_s1: 0.501010, loss_fp: 0.500007, loss_freq: 0.500263
[12:15:38.960] iteration 2009: loss: 0.901745, loss_s1: 0.502707, loss_fp: 0.500017, loss_freq: 0.500137
[12:15:39.609] iteration 2010: loss: 0.962830, loss_s1: 0.502841, loss_fp: 0.500002, loss_freq: 0.500416
[12:15:40.258] iteration 2011: loss: 0.362926, loss_s1: 0.305013, loss_fp: 0.005190, loss_freq: 0.126934
[12:15:40.906] iteration 2012: loss: 1.049242, loss_s1: 0.501575, loss_fp: 0.500001, loss_freq: 0.501173
[12:15:41.547] iteration 2013: loss: 0.882784, loss_s1: 0.500058, loss_fp: 0.500001, loss_freq: 0.500088
[12:15:42.180] iteration 2014: loss: 0.894308, loss_s1: 0.502751, loss_fp: 0.500004, loss_freq: 0.500395
[12:15:42.794] iteration 2015: loss: 0.952743, loss_s1: 0.501046, loss_fp: 0.500003, loss_freq: 0.500130
[12:15:43.449] iteration 2016: loss: 0.886488, loss_s1: 0.503693, loss_fp: 0.500019, loss_freq: 0.500020
[12:15:44.075] iteration 2017: loss: 0.985998, loss_s1: 0.501530, loss_fp: 0.500023, loss_freq: 0.500111
[12:15:44.705] iteration 2018: loss: 0.922976, loss_s1: 0.500545, loss_fp: 0.500001, loss_freq: 0.500124
[12:15:45.319] iteration 2019: loss: 1.038222, loss_s1: 0.497049, loss_fp: 0.500003, loss_freq: 0.500346
[12:15:45.954] iteration 2020: loss: 0.960035, loss_s1: 0.439730, loss_fp: 0.500000, loss_freq: 0.500114
[12:15:46.571] iteration 2021: loss: 0.849566, loss_s1: 0.504189, loss_fp: 0.500003, loss_freq: 0.500086
[12:15:47.187] iteration 2022: loss: 0.956597, loss_s1: 0.500059, loss_fp: 0.500000, loss_freq: 0.500036
[12:15:47.802] iteration 2023: loss: 0.664899, loss_s1: 0.500505, loss_fp: 0.353585, loss_freq: 0.124692
[12:15:48.494] iteration 2024: loss: 0.559400, loss_s1: 0.467990, loss_fp: 0.012441, loss_freq: 0.246910
[12:15:49.157] iteration 2025: loss: 0.887254, loss_s1: 0.477822, loss_fp: 0.500009, loss_freq: 0.500354
[12:15:49.824] iteration 2026: loss: 1.103221, loss_s1: 0.502017, loss_fp: 0.500004, loss_freq: 0.500017
[12:15:50.468] iteration 2027: loss: 0.864758, loss_s1: 0.323685, loss_fp: 0.500003, loss_freq: 0.500910
[12:15:51.093] iteration 2028: loss: 0.986925, loss_s1: 0.462276, loss_fp: 0.500004, loss_freq: 0.500643
[12:15:51.716] iteration 2029: loss: 1.212382, loss_s1: 0.364795, loss_fp: 0.500003, loss_freq: 0.500227
[12:15:52.334] iteration 2030: loss: 0.927008, loss_s1: 0.500299, loss_fp: 0.500006, loss_freq: 0.500362
[12:15:52.962] iteration 2031: loss: 1.162399, loss_s1: 0.500219, loss_fp: 0.500004, loss_freq: 0.500263
[12:15:53.593] iteration 2032: loss: 1.076607, loss_s1: 0.500302, loss_fp: 0.500004, loss_freq: 0.500038
[12:15:54.252] iteration 2033: loss: 0.910325, loss_s1: 0.500110, loss_fp: 0.500000, loss_freq: 0.500019
[12:15:54.889] iteration 2034: loss: 1.026601, loss_s1: 0.500324, loss_fp: 0.500004, loss_freq: 0.500274
[12:15:55.513] iteration 2035: loss: 0.931214, loss_s1: 0.501284, loss_fp: 0.500005, loss_freq: 0.500055
[12:15:56.131] iteration 2036: loss: 0.897599, loss_s1: 0.501633, loss_fp: 0.500002, loss_freq: 0.500119
[12:15:56.784] iteration 2037: loss: 1.041070, loss_s1: 0.501509, loss_fp: 0.500001, loss_freq: 0.500693
[12:15:57.400] iteration 2038: loss: 1.018773, loss_s1: 0.502900, loss_fp: 0.500002, loss_freq: 0.500485
[12:15:58.016] iteration 2039: loss: 0.913719, loss_s1: 0.502943, loss_fp: 0.500005, loss_freq: 0.500962
[12:15:58.628] iteration 2040: loss: 0.909738, loss_s1: 0.504836, loss_fp: 0.500000, loss_freq: 0.500076
[12:15:59.245] iteration 2041: loss: 0.997209, loss_s1: 0.503777, loss_fp: 0.500005, loss_freq: 0.500286
[12:15:59.857] iteration 2042: loss: 0.940713, loss_s1: 0.504360, loss_fp: 0.500026, loss_freq: 0.500221
[12:16:00.471] iteration 2043: loss: 0.969838, loss_s1: 0.506330, loss_fp: 0.500007, loss_freq: 0.501489
[12:16:01.082] iteration 2044: loss: 0.930825, loss_s1: 0.504316, loss_fp: 0.500036, loss_freq: 0.500992
[12:16:01.695] iteration 2045: loss: 0.952247, loss_s1: 0.502916, loss_fp: 0.500026, loss_freq: 0.501000
[12:16:02.312] iteration 2046: loss: 0.523337, loss_s1: 0.491201, loss_fp: 0.019744, loss_freq: 0.332536
[12:16:02.938] iteration 2047: loss: 1.038606, loss_s1: 0.452875, loss_fp: 0.500015, loss_freq: 0.501149
[12:16:03.564] iteration 2048: loss: 0.915049, loss_s1: 0.495150, loss_fp: 0.500014, loss_freq: 0.500564
[12:16:04.188] iteration 2049: loss: 0.969656, loss_s1: 0.466482, loss_fp: 0.500041, loss_freq: 0.500120
[12:16:04.812] iteration 2050: loss: 0.914790, loss_s1: 0.389831, loss_fp: 0.500008, loss_freq: 0.500121
[12:16:05.434] iteration 2051: loss: 0.537420, loss_s1: 0.303818, loss_fp: 0.402450, loss_freq: 0.085527
[12:16:06.060] iteration 2052: loss: 0.693123, loss_s1: 0.474206, loss_fp: 0.069861, loss_freq: 0.436774
[12:16:06.689] iteration 2053: loss: 0.976202, loss_s1: 0.501586, loss_fp: 0.500007, loss_freq: 0.500195
[12:16:07.319] iteration 2054: loss: 1.122669, loss_s1: 0.500509, loss_fp: 0.500010, loss_freq: 0.500329
[12:16:07.950] iteration 2055: loss: 1.107067, loss_s1: 0.500882, loss_fp: 0.500007, loss_freq: 0.500216
[12:16:08.633] iteration 2056: loss: 0.967964, loss_s1: 0.501863, loss_fp: 0.500008, loss_freq: 0.500136
[12:16:09.290] iteration 2057: loss: 0.946707, loss_s1: 0.501923, loss_fp: 0.500006, loss_freq: 0.500272
[12:16:09.945] iteration 2058: loss: 0.953746, loss_s1: 0.502355, loss_fp: 0.500007, loss_freq: 0.500039
[12:16:10.572] iteration 2059: loss: 0.992246, loss_s1: 0.501354, loss_fp: 0.500020, loss_freq: 0.500593
[12:16:11.193] iteration 2060: loss: 0.891239, loss_s1: 0.500343, loss_fp: 0.500023, loss_freq: 0.500086
[12:16:11.810] iteration 2061: loss: 0.995271, loss_s1: 0.501862, loss_fp: 0.500003, loss_freq: 0.500168
[12:16:12.424] iteration 2062: loss: 0.929840, loss_s1: 0.500580, loss_fp: 0.500013, loss_freq: 0.500034
[12:16:13.042] iteration 2063: loss: 0.969137, loss_s1: 0.501009, loss_fp: 0.500032, loss_freq: 0.500015
[12:16:13.665] iteration 2064: loss: 0.689641, loss_s1: 0.464099, loss_fp: 0.041865, loss_freq: 0.333617
[12:16:14.277] iteration 2065: loss: 0.894790, loss_s1: 0.500461, loss_fp: 0.500007, loss_freq: 0.500283
[12:16:14.893] iteration 2066: loss: 1.043649, loss_s1: 0.500839, loss_fp: 0.500004, loss_freq: 0.500300
[12:16:15.509] iteration 2067: loss: 0.673836, loss_s1: 0.429921, loss_fp: 0.081778, loss_freq: 0.326364
[12:16:16.131] iteration 2068: loss: 0.907153, loss_s1: 0.501767, loss_fp: 0.500009, loss_freq: 0.500068
[12:16:16.744] iteration 2069: loss: 0.901527, loss_s1: 0.500438, loss_fp: 0.500044, loss_freq: 0.500085
[12:16:17.360] iteration 2070: loss: 0.940354, loss_s1: 0.501297, loss_fp: 0.500000, loss_freq: 0.500137
[12:16:17.972] iteration 2071: loss: 0.765864, loss_s1: 0.228670, loss_fp: 0.500014, loss_freq: 0.500227
[12:16:18.588] iteration 2072: loss: 1.022321, loss_s1: 0.501051, loss_fp: 0.500032, loss_freq: 0.500035
[12:16:19.201] iteration 2073: loss: 1.015883, loss_s1: 0.500809, loss_fp: 0.500018, loss_freq: 0.500257
[12:16:19.822] iteration 2074: loss: 0.983671, loss_s1: 0.500145, loss_fp: 0.500005, loss_freq: 0.500027
[12:16:20.436] iteration 2075: loss: 0.907194, loss_s1: 0.502302, loss_fp: 0.500014, loss_freq: 0.500150
[12:16:21.047] iteration 2076: loss: 1.027387, loss_s1: 0.502618, loss_fp: 0.500017, loss_freq: 0.500426
[12:16:21.664] iteration 2077: loss: 0.951480, loss_s1: 0.504572, loss_fp: 0.500015, loss_freq: 0.500031
[12:16:22.279] iteration 2078: loss: 0.945139, loss_s1: 0.500157, loss_fp: 0.500019, loss_freq: 0.500085
[12:16:22.901] iteration 2079: loss: 0.907844, loss_s1: 0.502223, loss_fp: 0.500014, loss_freq: 0.500119
[12:16:23.515] iteration 2080: loss: 0.905209, loss_s1: 0.501702, loss_fp: 0.500016, loss_freq: 0.500055
[12:16:24.127] iteration 2081: loss: 0.869682, loss_s1: 0.501238, loss_fp: 0.500009, loss_freq: 0.500190
[12:16:24.748] iteration 2082: loss: 1.092772, loss_s1: 0.501485, loss_fp: 0.500004, loss_freq: 0.500259
[12:16:25.369] iteration 2083: loss: 0.887218, loss_s1: 0.500966, loss_fp: 0.500009, loss_freq: 0.500199
[12:16:25.985] iteration 2084: loss: 0.901688, loss_s1: 0.501983, loss_fp: 0.500018, loss_freq: 0.500260
[12:16:26.601] iteration 2085: loss: 0.954053, loss_s1: 0.501779, loss_fp: 0.500064, loss_freq: 0.500042
[12:16:27.219] iteration 2086: loss: 0.872085, loss_s1: 0.502751, loss_fp: 0.500009, loss_freq: 0.500356
[12:16:27.837] iteration 2087: loss: 0.960846, loss_s1: 0.503073, loss_fp: 0.500010, loss_freq: 0.500165
[12:16:28.454] iteration 2088: loss: 0.937865, loss_s1: 0.503364, loss_fp: 0.500006, loss_freq: 0.500947
[12:16:29.078] iteration 2089: loss: 1.059594, loss_s1: 0.504183, loss_fp: 0.500012, loss_freq: 0.501119
[12:16:29.695] iteration 2090: loss: 1.061759, loss_s1: 0.502380, loss_fp: 0.500042, loss_freq: 0.500477
[12:16:30.373] iteration 2091: loss: 0.903239, loss_s1: 0.501387, loss_fp: 0.500018, loss_freq: 0.501647
[12:16:31.037] iteration 2092: loss: 0.929699, loss_s1: 0.501213, loss_fp: 0.500019, loss_freq: 0.500124
[12:16:31.692] iteration 2093: loss: 0.957959, loss_s1: 0.501883, loss_fp: 0.500022, loss_freq: 0.500726
[12:16:32.341] iteration 2094: loss: 0.886659, loss_s1: 0.503322, loss_fp: 0.500018, loss_freq: 0.500626
[12:16:33.232] iteration 2095: loss: 0.855590, loss_s1: 0.500735, loss_fp: 0.500012, loss_freq: 0.500201
[12:16:33.894] iteration 2096: loss: 0.977510, loss_s1: 0.502089, loss_fp: 0.500003, loss_freq: 0.500411
[12:16:34.667] iteration 2097: loss: 0.892689, loss_s1: 0.500550, loss_fp: 0.500033, loss_freq: 0.500062
[12:16:35.366] iteration 2098: loss: 0.922205, loss_s1: 0.501793, loss_fp: 0.500059, loss_freq: 0.500250
[12:16:35.974] iteration 2099: loss: 0.916651, loss_s1: 0.501073, loss_fp: 0.500022, loss_freq: 0.500210
[12:16:36.588] iteration 2100: loss: 0.905391, loss_s1: 0.501732, loss_fp: 0.500014, loss_freq: 0.500119
[12:16:37.215] iteration 2101: loss: 1.032612, loss_s1: 0.503202, loss_fp: 0.500027, loss_freq: 0.500869
[12:16:37.820] iteration 2102: loss: 0.960378, loss_s1: 0.501606, loss_fp: 0.500008, loss_freq: 0.501106
[12:16:38.442] iteration 2103: loss: 0.891704, loss_s1: 0.502011, loss_fp: 0.500028, loss_freq: 0.501193
[12:16:39.059] iteration 2104: loss: 0.906928, loss_s1: 0.501081, loss_fp: 0.500011, loss_freq: 0.500207
[12:16:39.665] iteration 2105: loss: 0.901264, loss_s1: 0.500275, loss_fp: 0.500019, loss_freq: 0.500040
[12:16:40.266] iteration 2106: loss: 0.886402, loss_s1: 0.501835, loss_fp: 0.500013, loss_freq: 0.500660
[12:16:40.871] iteration 2107: loss: 0.969108, loss_s1: 0.501576, loss_fp: 0.500032, loss_freq: 0.500098
[12:16:41.485] iteration 2108: loss: 0.938646, loss_s1: 0.500387, loss_fp: 0.500015, loss_freq: 0.500280
[12:16:42.100] iteration 2109: loss: 0.864047, loss_s1: 0.502340, loss_fp: 0.500022, loss_freq: 0.500828
[12:16:42.711] iteration 2110: loss: 0.843308, loss_s1: 0.502404, loss_fp: 0.500014, loss_freq: 0.500676
[12:16:43.322] iteration 2111: loss: 0.926817, loss_s1: 0.394977, loss_fp: 0.500028, loss_freq: 0.500689
[12:16:43.934] iteration 2112: loss: 0.892320, loss_s1: 0.501774, loss_fp: 0.500021, loss_freq: 0.500220
[12:16:44.592] iteration 2113: loss: 0.888118, loss_s1: 0.500749, loss_fp: 0.500134, loss_freq: 0.500483
[12:16:45.243] iteration 2114: loss: 0.881329, loss_s1: 0.503002, loss_fp: 0.500018, loss_freq: 0.500166
[12:16:45.892] iteration 2115: loss: 0.937250, loss_s1: 0.504132, loss_fp: 0.500010, loss_freq: 0.500263
[12:16:46.522] iteration 2116: loss: 0.835414, loss_s1: 0.502319, loss_fp: 0.500017, loss_freq: 0.500293
[12:16:47.135] iteration 2117: loss: 1.032936, loss_s1: 0.500699, loss_fp: 0.500009, loss_freq: 0.502499
[12:16:47.761] iteration 2118: loss: 0.856348, loss_s1: 0.500843, loss_fp: 0.500040, loss_freq: 0.500150
[12:16:48.383] iteration 2119: loss: 0.906424, loss_s1: 0.502784, loss_fp: 0.500011, loss_freq: 0.500707
[12:16:48.998] iteration 2120: loss: 0.988564, loss_s1: 0.501204, loss_fp: 0.500021, loss_freq: 0.500177
[12:16:49.620] iteration 2121: loss: 0.880348, loss_s1: 0.503176, loss_fp: 0.500022, loss_freq: 0.501234
[12:16:50.239] iteration 2122: loss: 0.918657, loss_s1: 0.503535, loss_fp: 0.500015, loss_freq: 0.501688
[12:16:50.862] iteration 2123: loss: 0.922581, loss_s1: 0.502090, loss_fp: 0.500033, loss_freq: 0.501239
[12:16:51.478] iteration 2124: loss: 1.026568, loss_s1: 0.504217, loss_fp: 0.500024, loss_freq: 0.501047
[12:16:52.104] iteration 2125: loss: 0.997108, loss_s1: 0.502838, loss_fp: 0.500031, loss_freq: 0.501548
[12:16:52.796] iteration 2126: loss: 0.837649, loss_s1: 0.503642, loss_fp: 0.500027, loss_freq: 0.500629
[12:16:53.413] iteration 2127: loss: 0.901731, loss_s1: 0.502862, loss_fp: 0.500016, loss_freq: 0.501269
[12:16:54.073] iteration 2128: loss: 0.928757, loss_s1: 0.504417, loss_fp: 0.500028, loss_freq: 0.500554
[12:16:54.688] iteration 2129: loss: 0.787822, loss_s1: 0.492816, loss_fp: 0.191743, loss_freq: 0.493926
[12:16:55.294] iteration 2130: loss: 0.869900, loss_s1: 0.501376, loss_fp: 0.500025, loss_freq: 0.500207
[12:16:55.916] iteration 2131: loss: 0.929496, loss_s1: 0.504454, loss_fp: 0.500019, loss_freq: 0.500670
[12:16:56.541] iteration 2132: loss: 0.862695, loss_s1: 0.501897, loss_fp: 0.500008, loss_freq: 0.501144
[12:16:57.165] iteration 2133: loss: 0.895346, loss_s1: 0.469488, loss_fp: 0.500013, loss_freq: 0.500358
[12:16:57.782] iteration 2134: loss: 0.915858, loss_s1: 0.503502, loss_fp: 0.500003, loss_freq: 0.500736
[12:16:58.396] iteration 2135: loss: 0.907514, loss_s1: 0.502088, loss_fp: 0.500013, loss_freq: 0.500344
[12:16:59.022] iteration 2136: loss: 0.988675, loss_s1: 0.501962, loss_fp: 0.500019, loss_freq: 0.500249
[12:16:59.643] iteration 2137: loss: 0.986563, loss_s1: 0.503031, loss_fp: 0.500016, loss_freq: 0.501554
[12:17:00.266] iteration 2138: loss: 0.885069, loss_s1: 0.502055, loss_fp: 0.500016, loss_freq: 0.500203
[12:17:00.890] iteration 2139: loss: 0.904670, loss_s1: 0.500485, loss_fp: 0.500014, loss_freq: 0.500246
[12:17:01.514] iteration 2140: loss: 0.928347, loss_s1: 0.504180, loss_fp: 0.500008, loss_freq: 0.500723
[12:17:02.125] iteration 2141: loss: 0.911898, loss_s1: 0.501034, loss_fp: 0.500000, loss_freq: 0.500213
[12:17:02.765] iteration 2142: loss: 0.917677, loss_s1: 0.507184, loss_fp: 0.500009, loss_freq: 0.500390
[12:17:03.390] iteration 2143: loss: 0.928267, loss_s1: 0.502049, loss_fp: 0.500004, loss_freq: 0.500068
[12:17:04.004] iteration 2144: loss: 0.873904, loss_s1: 0.503496, loss_fp: 0.500003, loss_freq: 0.500453
[12:17:04.626] iteration 2145: loss: 0.852884, loss_s1: 0.500918, loss_fp: 0.500008, loss_freq: 0.500263
[12:17:05.656] iteration 2146: loss: 0.920749, loss_s1: 0.475334, loss_fp: 0.500021, loss_freq: 0.500054
[12:17:06.288] iteration 2147: loss: 0.854564, loss_s1: 0.503467, loss_fp: 0.500006, loss_freq: 0.500154
[12:17:06.909] iteration 2148: loss: 0.847692, loss_s1: 0.502325, loss_fp: 0.500005, loss_freq: 0.500354
[12:17:07.530] iteration 2149: loss: 0.955065, loss_s1: 0.501580, loss_fp: 0.500002, loss_freq: 0.500169
[12:17:08.147] iteration 2150: loss: 0.866482, loss_s1: 0.500597, loss_fp: 0.500004, loss_freq: 0.500043
[12:17:08.767] iteration 2151: loss: 0.869811, loss_s1: 0.500614, loss_fp: 0.500004, loss_freq: 0.500107
[12:17:09.384] iteration 2152: loss: 0.866681, loss_s1: 0.501666, loss_fp: 0.500004, loss_freq: 0.500121
[12:17:10.007] iteration 2153: loss: 0.930594, loss_s1: 0.501669, loss_fp: 0.500004, loss_freq: 0.500350
[12:17:10.642] iteration 2154: loss: 0.335944, loss_s1: 0.248660, loss_fp: 0.004836, loss_freq: 0.231499
[12:17:11.267] iteration 2155: loss: 1.023233, loss_s1: 0.500225, loss_fp: 0.500003, loss_freq: 0.500826
[12:17:11.918] iteration 2156: loss: 0.882890, loss_s1: 0.501710, loss_fp: 0.500003, loss_freq: 0.500096
[12:17:12.639] iteration 2157: loss: 0.893756, loss_s1: 0.500790, loss_fp: 0.500003, loss_freq: 0.500483
[12:17:13.302] iteration 2158: loss: 0.948848, loss_s1: 0.500506, loss_fp: 0.500006, loss_freq: 0.500234
[12:17:13.961] iteration 2159: loss: 0.881439, loss_s1: 0.500583, loss_fp: 0.500006, loss_freq: 0.500084
[12:17:14.614] iteration 2160: loss: 0.302251, loss_s1: 0.219925, loss_fp: 0.004631, loss_freq: 0.013169
[12:17:15.271] iteration 2161: loss: 0.931989, loss_s1: 0.500931, loss_fp: 0.500001, loss_freq: 0.500016
[12:17:15.928] iteration 2162: loss: 1.109323, loss_s1: 0.500406, loss_fp: 0.500009, loss_freq: 0.500190
[12:17:16.581] iteration 2163: loss: 1.013428, loss_s1: 0.501327, loss_fp: 0.500018, loss_freq: 0.500136
[12:17:17.202] iteration 2164: loss: 0.849717, loss_s1: 0.500775, loss_fp: 0.500005, loss_freq: 0.500206
[12:17:17.817] iteration 2165: loss: 0.937482, loss_s1: 0.500164, loss_fp: 0.500012, loss_freq: 0.500112
[12:17:18.442] iteration 2166: loss: 0.908052, loss_s1: 0.500547, loss_fp: 0.500006, loss_freq: 0.500285
[12:17:19.060] iteration 2167: loss: 0.876751, loss_s1: 0.500684, loss_fp: 0.500013, loss_freq: 0.500164
[12:17:19.686] iteration 2168: loss: 0.881935, loss_s1: 0.501699, loss_fp: 0.500007, loss_freq: 0.500142
[12:17:20.315] iteration 2169: loss: 0.965775, loss_s1: 0.500320, loss_fp: 0.500002, loss_freq: 0.500039
[12:17:20.944] iteration 2170: loss: 0.859904, loss_s1: 0.503316, loss_fp: 0.500009, loss_freq: 0.500127
[12:17:21.572] iteration 2171: loss: 0.912934, loss_s1: 0.501904, loss_fp: 0.500005, loss_freq: 0.500072
[12:17:22.205] iteration 2172: loss: 0.909031, loss_s1: 0.500371, loss_fp: 0.500000, loss_freq: 0.500094
[12:17:22.849] iteration 2173: loss: 0.901868, loss_s1: 0.500278, loss_fp: 0.500005, loss_freq: 0.500048
[12:17:23.486] iteration 2174: loss: 1.025318, loss_s1: 0.501771, loss_fp: 0.500005, loss_freq: 0.500086
[12:17:24.166] iteration 2175: loss: 0.923361, loss_s1: 0.500261, loss_fp: 0.500005, loss_freq: 0.500009
[12:17:24.781] iteration 2176: loss: 0.913347, loss_s1: 0.501104, loss_fp: 0.500012, loss_freq: 0.500031
[12:17:25.401] iteration 2177: loss: 0.882761, loss_s1: 0.500994, loss_fp: 0.500005, loss_freq: 0.500350
[12:17:26.017] iteration 2178: loss: 0.895071, loss_s1: 0.500114, loss_fp: 0.500007, loss_freq: 0.500058
[12:17:26.642] iteration 2179: loss: 0.880953, loss_s1: 0.500742, loss_fp: 0.500018, loss_freq: 0.500384
[12:17:27.265] iteration 2180: loss: 0.922386, loss_s1: 0.501165, loss_fp: 0.500007, loss_freq: 0.500108
[12:17:27.883] iteration 2181: loss: 0.864958, loss_s1: 0.438637, loss_fp: 0.500015, loss_freq: 0.500070
[12:17:28.540] iteration 2182: loss: 0.865338, loss_s1: 0.500896, loss_fp: 0.500002, loss_freq: 0.500112
[12:17:29.157] iteration 2183: loss: 0.824880, loss_s1: 0.500560, loss_fp: 0.500006, loss_freq: 0.500054
[12:17:29.776] iteration 2184: loss: 0.951327, loss_s1: 0.503421, loss_fp: 0.500013, loss_freq: 0.500256
[12:17:30.393] iteration 2185: loss: 0.888792, loss_s1: 0.500554, loss_fp: 0.500023, loss_freq: 0.500033
[12:17:31.004] iteration 2186: loss: 0.868729, loss_s1: 0.503383, loss_fp: 0.500009, loss_freq: 0.500651
[12:17:31.613] iteration 2187: loss: 0.843738, loss_s1: 0.501596, loss_fp: 0.500006, loss_freq: 0.500134
[12:17:32.235] iteration 2188: loss: 0.633205, loss_s1: 0.493842, loss_fp: 0.008976, loss_freq: 0.416227
[12:17:32.847] iteration 2189: loss: 0.242607, loss_s1: 0.320033, loss_fp: 0.002761, loss_freq: 0.015357
[12:17:33.505] iteration 2190: loss: 1.053273, loss_s1: 0.501481, loss_fp: 0.499999, loss_freq: 0.501039
[12:17:34.123] iteration 2191: loss: 0.861672, loss_s1: 0.500583, loss_fp: 0.500006, loss_freq: 0.500398
[12:17:34.741] iteration 2192: loss: 0.867278, loss_s1: 0.501000, loss_fp: 0.500015, loss_freq: 0.500851
[12:17:35.356] iteration 2193: loss: 0.949416, loss_s1: 0.501249, loss_fp: 0.500004, loss_freq: 0.500326
[12:17:35.977] iteration 2194: loss: 0.860333, loss_s1: 0.502935, loss_fp: 0.500005, loss_freq: 0.500191
[12:17:36.590] iteration 2195: loss: 0.586193, loss_s1: 0.489545, loss_fp: 0.030115, loss_freq: 0.323780
[12:17:37.203] iteration 2196: loss: 0.918315, loss_s1: 0.500693, loss_fp: 0.500003, loss_freq: 0.500082
[12:17:37.821] iteration 2197: loss: 1.006575, loss_s1: 0.501820, loss_fp: 0.500012, loss_freq: 0.500202
[12:17:38.443] iteration 2198: loss: 0.963031, loss_s1: 0.500204, loss_fp: 0.500001, loss_freq: 0.500135
[12:17:39.071] iteration 2199: loss: 0.838010, loss_s1: 0.501402, loss_fp: 0.499999, loss_freq: 0.500009
[12:17:39.721] iteration 2200: loss: 0.916686, loss_s1: 0.500310, loss_fp: 0.500001, loss_freq: 0.500038
[12:17:42.894] iteration 2200 : mean_dice : 0.312482
[12:17:43.539] iteration 2201: loss: 0.880882, loss_s1: 0.502361, loss_fp: 0.500002, loss_freq: 0.500052
[12:17:44.154] iteration 2202: loss: 0.905192, loss_s1: 0.501909, loss_fp: 0.500003, loss_freq: 0.500242
[12:17:44.772] iteration 2203: loss: 0.888049, loss_s1: 0.500572, loss_fp: 0.499999, loss_freq: 0.500023
[12:17:45.390] iteration 2204: loss: 0.977224, loss_s1: 0.501394, loss_fp: 0.500010, loss_freq: 0.500344
[12:17:46.007] iteration 2205: loss: 0.892618, loss_s1: 0.500648, loss_fp: 0.500000, loss_freq: 0.500087
[12:17:46.623] iteration 2206: loss: 0.923332, loss_s1: 0.500658, loss_fp: 0.500002, loss_freq: 0.500065
[12:17:47.237] iteration 2207: loss: 0.939185, loss_s1: 0.500848, loss_fp: 0.500002, loss_freq: 0.500182
[12:17:47.853] iteration 2208: loss: 0.971964, loss_s1: 0.502871, loss_fp: 0.500003, loss_freq: 0.500650
[12:17:48.465] iteration 2209: loss: 1.038558, loss_s1: 0.501897, loss_fp: 0.499998, loss_freq: 0.501217
[12:17:49.079] iteration 2210: loss: 1.002417, loss_s1: 0.500988, loss_fp: 0.500004, loss_freq: 0.500720
[12:17:49.742] iteration 2211: loss: 0.899824, loss_s1: 0.503034, loss_fp: 0.500001, loss_freq: 0.500314
[12:17:50.390] iteration 2212: loss: 0.904367, loss_s1: 0.503597, loss_fp: 0.499994, loss_freq: 0.500268
[12:17:51.035] iteration 2213: loss: 0.908931, loss_s1: 0.500149, loss_fp: 0.500007, loss_freq: 0.500134
[12:17:51.685] iteration 2214: loss: 0.894582, loss_s1: 0.500584, loss_fp: 0.500001, loss_freq: 0.500196
[12:17:52.332] iteration 2215: loss: 0.940925, loss_s1: 0.500516, loss_fp: 0.500031, loss_freq: 0.500177
[12:17:52.947] iteration 2216: loss: 0.973527, loss_s1: 0.501438, loss_fp: 0.500002, loss_freq: 0.500105
[12:17:53.571] iteration 2217: loss: 0.886014, loss_s1: 0.500126, loss_fp: 0.500018, loss_freq: 0.500044
[12:17:54.191] iteration 2218: loss: 0.848502, loss_s1: 0.501251, loss_fp: 0.500004, loss_freq: 0.500113
[12:17:54.808] iteration 2219: loss: 0.941695, loss_s1: 0.501126, loss_fp: 0.500009, loss_freq: 0.500290
[12:17:55.429] iteration 2220: loss: 0.909802, loss_s1: 0.502075, loss_fp: 0.500001, loss_freq: 0.500031
[12:17:56.053] iteration 2221: loss: 0.887270, loss_s1: 0.502415, loss_fp: 0.500000, loss_freq: 0.500324
[12:17:56.667] iteration 2222: loss: 0.881821, loss_s1: 0.500357, loss_fp: 0.500002, loss_freq: 0.500047
[12:17:57.286] iteration 2223: loss: 0.902572, loss_s1: 0.500851, loss_fp: 0.500006, loss_freq: 0.500036
[12:17:57.896] iteration 2224: loss: 0.876740, loss_s1: 0.500549, loss_fp: 0.500013, loss_freq: 0.500150
[12:17:58.506] iteration 2225: loss: 1.061919, loss_s1: 0.502057, loss_fp: 0.500000, loss_freq: 0.500053
[12:17:59.120] iteration 2226: loss: 0.877729, loss_s1: 0.500108, loss_fp: 0.500006, loss_freq: 0.500040
[12:17:59.735] iteration 2227: loss: 0.883625, loss_s1: 0.502411, loss_fp: 0.500007, loss_freq: 0.500381
[12:18:00.402] iteration 2228: loss: 0.957105, loss_s1: 0.501757, loss_fp: 0.500023, loss_freq: 0.500028
[12:18:01.059] iteration 2229: loss: 0.871439, loss_s1: 0.501928, loss_fp: 0.500001, loss_freq: 0.500049
[12:18:01.718] iteration 2230: loss: 0.909791, loss_s1: 0.500236, loss_fp: 0.500034, loss_freq: 0.501022
[12:18:02.367] iteration 2231: loss: 0.931981, loss_s1: 0.504465, loss_fp: 0.500012, loss_freq: 0.502174
[12:18:02.985] iteration 2232: loss: 0.995377, loss_s1: 0.502216, loss_fp: 0.500008, loss_freq: 0.500300
[12:18:03.603] iteration 2233: loss: 0.930187, loss_s1: 0.506695, loss_fp: 0.500031, loss_freq: 0.500849
[12:18:04.217] iteration 2234: loss: 0.834359, loss_s1: 0.506938, loss_fp: 0.500000, loss_freq: 0.502648
[12:18:04.945] iteration 2235: loss: 0.929205, loss_s1: 0.503880, loss_fp: 0.500004, loss_freq: 0.500203
[12:18:05.601] iteration 2236: loss: 0.456773, loss_s1: 0.436885, loss_fp: 0.006620, loss_freq: 0.116960
[12:18:06.260] iteration 2237: loss: 0.925739, loss_s1: 0.505495, loss_fp: 0.500006, loss_freq: 0.501483
[12:18:06.917] iteration 2238: loss: 0.846724, loss_s1: 0.500970, loss_fp: 0.500015, loss_freq: 0.500108
[12:18:07.559] iteration 2239: loss: 0.920103, loss_s1: 0.502220, loss_fp: 0.500000, loss_freq: 0.500865
[12:18:08.191] iteration 2240: loss: 0.851680, loss_s1: 0.500419, loss_fp: 0.500006, loss_freq: 0.500054
[12:18:08.837] iteration 2241: loss: 0.927665, loss_s1: 0.500107, loss_fp: 0.500007, loss_freq: 0.500211
[12:18:09.542] iteration 2242: loss: 0.905487, loss_s1: 0.501163, loss_fp: 0.500019, loss_freq: 0.501873
[12:18:10.198] iteration 2243: loss: 0.829034, loss_s1: 0.438988, loss_fp: 0.500005, loss_freq: 0.500302
[12:18:10.833] iteration 2244: loss: 0.353688, loss_s1: 0.089453, loss_fp: 0.003489, loss_freq: 0.011073
[12:18:11.457] iteration 2245: loss: 0.951339, loss_s1: 0.502738, loss_fp: 0.500001, loss_freq: 0.500147
[12:18:12.082] iteration 2246: loss: 0.872580, loss_s1: 0.501542, loss_fp: 0.500007, loss_freq: 0.500606
[12:18:12.709] iteration 2247: loss: 0.918723, loss_s1: 0.500672, loss_fp: 0.500006, loss_freq: 0.500019
[12:18:13.327] iteration 2248: loss: 0.926167, loss_s1: 0.501146, loss_fp: 0.500026, loss_freq: 0.500294
[12:18:13.942] iteration 2249: loss: 0.653718, loss_s1: 0.484792, loss_fp: 0.038971, loss_freq: 0.477286
[12:18:14.564] iteration 2250: loss: 0.944323, loss_s1: 0.479260, loss_fp: 0.500001, loss_freq: 0.500194
[12:18:15.190] iteration 2251: loss: 0.440974, loss_s1: 0.334816, loss_fp: 0.010882, loss_freq: 0.244570
[12:18:15.814] iteration 2252: loss: 0.867224, loss_s1: 0.502409, loss_fp: 0.500039, loss_freq: 0.500642
[12:18:16.421] iteration 2253: loss: 0.866165, loss_s1: 0.501433, loss_fp: 0.500007, loss_freq: 0.500028
[12:18:17.038] iteration 2254: loss: 0.967278, loss_s1: 0.438481, loss_fp: 0.500011, loss_freq: 0.500021
[12:18:17.718] iteration 2255: loss: 0.882551, loss_s1: 0.483376, loss_fp: 0.500004, loss_freq: 0.500006
[12:18:18.373] iteration 2256: loss: 0.824940, loss_s1: 0.410518, loss_fp: 0.500001, loss_freq: 0.500019
[12:18:19.032] iteration 2257: loss: 0.911958, loss_s1: 0.500386, loss_fp: 0.500018, loss_freq: 0.500061
[12:18:19.688] iteration 2258: loss: 0.888770, loss_s1: 0.500112, loss_fp: 0.500007, loss_freq: 0.500056
[12:18:20.346] iteration 2259: loss: 0.173550, loss_s1: 0.169465, loss_fp: 0.008750, loss_freq: 0.003021
[12:18:21.005] iteration 2260: loss: 1.104128, loss_s1: 0.500121, loss_fp: 0.500000, loss_freq: 0.500205
[12:18:21.654] iteration 2261: loss: 0.890534, loss_s1: 0.500018, loss_fp: 0.500001, loss_freq: 0.500007
[12:18:22.309] iteration 2262: loss: 0.905679, loss_s1: 0.501419, loss_fp: 0.500002, loss_freq: 0.500249
[12:18:22.926] iteration 2263: loss: 0.951360, loss_s1: 0.500753, loss_fp: 0.500006, loss_freq: 0.500110
[12:18:23.545] iteration 2264: loss: 0.852252, loss_s1: 0.500234, loss_fp: 0.500002, loss_freq: 0.500106
[12:18:24.160] iteration 2265: loss: 0.952656, loss_s1: 0.500713, loss_fp: 0.499997, loss_freq: 0.500310
[12:18:24.769] iteration 2266: loss: 0.424082, loss_s1: 0.361421, loss_fp: 0.004974, loss_freq: 0.173623
[12:18:25.378] iteration 2267: loss: 0.978522, loss_s1: 0.501145, loss_fp: 0.500003, loss_freq: 0.501897
[12:18:25.990] iteration 2268: loss: 0.999546, loss_s1: 0.500768, loss_fp: 0.500005, loss_freq: 0.501190
[12:18:26.603] iteration 2269: loss: 0.858300, loss_s1: 0.500528, loss_fp: 0.499999, loss_freq: 0.500135
[12:18:27.208] iteration 2270: loss: 0.909005, loss_s1: 0.500493, loss_fp: 0.500020, loss_freq: 0.500299
[12:18:27.826] iteration 2271: loss: 0.967000, loss_s1: 0.502675, loss_fp: 0.500013, loss_freq: 0.500407
[12:18:28.437] iteration 2272: loss: 0.891135, loss_s1: 0.500462, loss_fp: 0.500002, loss_freq: 0.500141
[12:18:29.047] iteration 2273: loss: 0.848073, loss_s1: 0.500894, loss_fp: 0.500001, loss_freq: 0.500106
[12:18:29.662] iteration 2274: loss: 0.954398, loss_s1: 0.501891, loss_fp: 0.500002, loss_freq: 0.500101
[12:18:30.288] iteration 2275: loss: 0.868389, loss_s1: 0.500914, loss_fp: 0.500006, loss_freq: 0.500363
[12:18:30.907] iteration 2276: loss: 0.748508, loss_s1: 0.161295, loss_fp: 0.500000, loss_freq: 0.500045
[12:18:31.521] iteration 2277: loss: 0.936448, loss_s1: 0.500499, loss_fp: 0.500002, loss_freq: 0.500481
[12:18:32.134] iteration 2278: loss: 0.845212, loss_s1: 0.500263, loss_fp: 0.500006, loss_freq: 0.500264
[12:18:32.751] iteration 2279: loss: 0.306966, loss_s1: 0.086118, loss_fp: 0.007691, loss_freq: 0.078650
[12:18:33.363] iteration 2280: loss: 0.919961, loss_s1: 0.501253, loss_fp: 0.500004, loss_freq: 0.500066
[12:18:33.983] iteration 2281: loss: 0.815297, loss_s1: 0.397211, loss_fp: 0.500009, loss_freq: 0.500097
[12:18:34.597] iteration 2282: loss: 0.902251, loss_s1: 0.500047, loss_fp: 0.500005, loss_freq: 0.500007
[12:18:35.215] iteration 2283: loss: 0.890195, loss_s1: 0.500091, loss_fp: 0.500001, loss_freq: 0.500040
[12:18:35.832] iteration 2284: loss: 0.877343, loss_s1: 0.500211, loss_fp: 0.500003, loss_freq: 0.500008
[12:18:36.443] iteration 2285: loss: 0.957816, loss_s1: 0.500759, loss_fp: 0.500002, loss_freq: 0.500116
[12:18:37.055] iteration 2286: loss: 1.005062, loss_s1: 0.500227, loss_fp: 0.500002, loss_freq: 0.500004
[12:18:37.668] iteration 2287: loss: 0.860559, loss_s1: 0.500232, loss_fp: 0.500003, loss_freq: 0.500040
[12:18:38.280] iteration 2288: loss: 0.877705, loss_s1: 0.500083, loss_fp: 0.500002, loss_freq: 0.500026
[12:18:39.634] iteration 2289: loss: 0.919743, loss_s1: 0.500718, loss_fp: 0.500009, loss_freq: 0.500086
[12:18:40.396] iteration 2290: loss: 0.863600, loss_s1: 0.502536, loss_fp: 0.500011, loss_freq: 0.500006
[12:18:41.140] iteration 2291: loss: 0.851598, loss_s1: 0.501365, loss_fp: 0.500001, loss_freq: 0.501323
[12:18:41.757] iteration 2292: loss: 0.917222, loss_s1: 0.501234, loss_fp: 0.500002, loss_freq: 0.500017
[12:18:42.373] iteration 2293: loss: 0.880563, loss_s1: 0.502787, loss_fp: 0.500007, loss_freq: 0.500140
[12:18:42.985] iteration 2294: loss: 0.894293, loss_s1: 0.500894, loss_fp: 0.500003, loss_freq: 0.500252
[12:18:43.607] iteration 2295: loss: 0.850467, loss_s1: 0.500431, loss_fp: 0.500052, loss_freq: 0.500149
[12:18:44.230] iteration 2296: loss: 0.973919, loss_s1: 0.503983, loss_fp: 0.500025, loss_freq: 0.501079
[12:18:44.849] iteration 2297: loss: 0.165649, loss_s1: 0.052030, loss_fp: 0.002860, loss_freq: 0.048377
[12:18:45.470] iteration 2298: loss: 1.016541, loss_s1: 0.481056, loss_fp: 0.500007, loss_freq: 0.502505
[12:18:46.090] iteration 2299: loss: 0.774225, loss_s1: 0.327254, loss_fp: 0.500007, loss_freq: 0.500020
[12:18:46.703] iteration 2300: loss: 0.906202, loss_s1: 0.501203, loss_fp: 0.500004, loss_freq: 0.500214
[12:18:47.333] iteration 2301: loss: 0.898467, loss_s1: 0.502122, loss_fp: 0.500004, loss_freq: 0.500429
[12:18:47.951] iteration 2302: loss: 0.816711, loss_s1: 0.410407, loss_fp: 0.500022, loss_freq: 0.500129
[12:18:48.574] iteration 2303: loss: 0.219931, loss_s1: 0.069218, loss_fp: 0.001605, loss_freq: 0.015676
[12:18:49.217] iteration 2304: loss: 0.937244, loss_s1: 0.500528, loss_fp: 0.500003, loss_freq: 0.500019
[12:18:49.850] iteration 2305: loss: 1.015003, loss_s1: 0.500219, loss_fp: 0.500002, loss_freq: 0.500063
[12:18:50.469] iteration 2306: loss: 0.459814, loss_s1: 0.440718, loss_fp: 0.009171, loss_freq: 0.011560
[12:18:51.099] iteration 2307: loss: 0.852745, loss_s1: 0.500196, loss_fp: 0.500008, loss_freq: 0.500030
[12:18:51.759] iteration 2308: loss: 0.927648, loss_s1: 0.500328, loss_fp: 0.500003, loss_freq: 0.500019
[12:18:52.415] iteration 2309: loss: 0.922313, loss_s1: 0.500043, loss_fp: 0.500001, loss_freq: 0.500015
[12:18:53.067] iteration 2310: loss: 0.321093, loss_s1: 0.365183, loss_fp: 0.004702, loss_freq: 0.009805
[12:18:53.681] iteration 2311: loss: 0.865853, loss_s1: 0.500227, loss_fp: 0.500006, loss_freq: 0.500023
[12:18:54.295] iteration 2312: loss: 0.911082, loss_s1: 0.500200, loss_fp: 0.500002, loss_freq: 0.500006
[12:18:54.907] iteration 2313: loss: 0.855166, loss_s1: 0.478582, loss_fp: 0.500002, loss_freq: 0.500022
[12:18:55.523] iteration 2314: loss: 0.913065, loss_s1: 0.500372, loss_fp: 0.500017, loss_freq: 0.500008
[12:18:56.142] iteration 2315: loss: 0.935621, loss_s1: 0.500075, loss_fp: 0.499999, loss_freq: 0.500020
[12:18:56.780] iteration 2316: loss: 0.850254, loss_s1: 0.502137, loss_fp: 0.500007, loss_freq: 0.500045
[12:18:57.405] iteration 2317: loss: 0.660792, loss_s1: 0.475531, loss_fp: 0.116268, loss_freq: 0.142970
[12:18:58.023] iteration 2318: loss: 0.216746, loss_s1: 0.035202, loss_fp: 0.002197, loss_freq: 0.036509
[12:18:58.649] iteration 2319: loss: 0.350878, loss_s1: 0.286669, loss_fp: 0.169198, loss_freq: 0.016697
[12:18:59.291] iteration 2320: loss: 0.234613, loss_s1: 0.018009, loss_fp: 0.005235, loss_freq: 0.156392
[12:18:59.948] iteration 2321: loss: 0.928039, loss_s1: 0.500066, loss_fp: 0.500006, loss_freq: 0.500037
[12:19:00.605] iteration 2322: loss: 0.940054, loss_s1: 0.500138, loss_fp: 0.500003, loss_freq: 0.500139
[12:19:01.261] iteration 2323: loss: 1.059460, loss_s1: 0.500601, loss_fp: 0.500000, loss_freq: 0.500016
[12:19:01.880] iteration 2324: loss: 0.455012, loss_s1: 0.480413, loss_fp: 0.007543, loss_freq: 0.008499
[12:19:02.512] iteration 2325: loss: 0.955938, loss_s1: 0.500895, loss_fp: 0.500012, loss_freq: 0.500149
[12:19:03.125] iteration 2326: loss: 0.892472, loss_s1: 0.500124, loss_fp: 0.500054, loss_freq: 0.500013
[12:19:03.753] iteration 2327: loss: 0.555391, loss_s1: 0.497966, loss_fp: 0.027553, loss_freq: 0.097287
[12:19:04.365] iteration 2328: loss: 0.913297, loss_s1: 0.500407, loss_fp: 0.500216, loss_freq: 0.500020
[12:19:04.979] iteration 2329: loss: 0.951734, loss_s1: 0.496884, loss_fp: 0.500018, loss_freq: 0.501437
[12:19:05.591] iteration 2330: loss: 0.327436, loss_s1: 0.060853, loss_fp: 0.344024, loss_freq: 0.010220
[12:19:06.204] iteration 2331: loss: 0.242857, loss_s1: 0.112516, loss_fp: 0.002877, loss_freq: 0.008624
[12:19:06.865] iteration 2332: loss: 0.173026, loss_s1: 0.130941, loss_fp: 0.003150, loss_freq: 0.021502
[12:19:07.535] iteration 2333: loss: 1.087778, loss_s1: 0.500792, loss_fp: 0.499999, loss_freq: 0.500044
[12:19:08.158] iteration 2334: loss: 0.848039, loss_s1: 0.500978, loss_fp: 0.500009, loss_freq: 0.500183
[12:19:08.773] iteration 2335: loss: 0.366219, loss_s1: 0.181223, loss_fp: 0.032510, loss_freq: 0.104534
[12:19:09.398] iteration 2336: loss: 1.005602, loss_s1: 0.500061, loss_fp: 0.500016, loss_freq: 0.500004
[12:19:10.044] iteration 2337: loss: 0.286752, loss_s1: 0.092192, loss_fp: 0.004002, loss_freq: 0.003685
[12:19:10.698] iteration 2338: loss: 0.986497, loss_s1: 0.501060, loss_fp: 0.500002, loss_freq: 0.500005
[12:19:11.357] iteration 2339: loss: 0.272545, loss_s1: 0.076029, loss_fp: 0.006100, loss_freq: 0.005193
[12:19:11.973] iteration 2340: loss: 0.439409, loss_s1: 0.265252, loss_fp: 0.002325, loss_freq: 0.001978
[12:19:12.595] iteration 2341: loss: 1.041029, loss_s1: 0.500877, loss_fp: 0.500011, loss_freq: 0.500009
[12:19:13.217] iteration 2342: loss: 0.421726, loss_s1: 0.456867, loss_fp: 0.087359, loss_freq: 0.006131
[12:19:13.835] iteration 2343: loss: 0.247284, loss_s1: 0.132350, loss_fp: 0.002099, loss_freq: 0.002878
[12:19:14.457] iteration 2344: loss: 0.888333, loss_s1: 0.376876, loss_fp: 0.500046, loss_freq: 0.500004
[12:19:15.072] iteration 2345: loss: 0.965540, loss_s1: 0.500299, loss_fp: 0.500011, loss_freq: 0.500010
[12:19:15.695] iteration 2346: loss: 0.697896, loss_s1: 0.103719, loss_fp: 0.500003, loss_freq: 0.500101
[12:19:16.316] iteration 2347: loss: 0.742275, loss_s1: 0.252034, loss_fp: 0.281324, loss_freq: 0.408032
[12:19:16.929] iteration 2348: loss: 0.730517, loss_s1: 0.184774, loss_fp: 0.500011, loss_freq: 0.500022
[12:19:17.544] iteration 2349: loss: 0.509468, loss_s1: 0.340610, loss_fp: 0.048615, loss_freq: 0.170044
[12:19:18.162] iteration 2350: loss: 1.051792, loss_s1: 0.439215, loss_fp: 0.500055, loss_freq: 0.500574
[12:19:18.777] iteration 2351: loss: 0.960021, loss_s1: 0.503377, loss_fp: 0.500065, loss_freq: 0.500779
[12:19:19.409] iteration 2352: loss: 0.669763, loss_s1: 0.501746, loss_fp: 0.007925, loss_freq: 0.168840
[12:19:20.061] iteration 2353: loss: 0.898324, loss_s1: 0.478920, loss_fp: 0.212275, loss_freq: 0.418337
[12:19:20.713] iteration 2354: loss: 0.586340, loss_s1: 0.433928, loss_fp: 0.015283, loss_freq: 0.214179
[12:19:21.367] iteration 2355: loss: 0.902389, loss_s1: 0.410025, loss_fp: 0.334907, loss_freq: 0.499659
[12:19:22.021] iteration 2356: loss: 0.936661, loss_s1: 0.371485, loss_fp: 0.500007, loss_freq: 0.501940
[12:19:22.669] iteration 2357: loss: 0.787927, loss_s1: 0.244876, loss_fp: 0.500027, loss_freq: 0.502161
[12:19:23.295] iteration 2358: loss: 0.734470, loss_s1: 0.253919, loss_fp: 0.060168, loss_freq: 0.392365
[12:19:23.950] iteration 2359: loss: 0.753660, loss_s1: 0.500811, loss_fp: 0.004325, loss_freq: 0.384869
[12:19:24.602] iteration 2360: loss: 1.030197, loss_s1: 0.495857, loss_fp: 0.500004, loss_freq: 0.500085
[12:19:25.254] iteration 2361: loss: 0.990493, loss_s1: 0.502790, loss_fp: 0.500016, loss_freq: 0.501215
[12:19:25.923] iteration 2362: loss: 1.083019, loss_s1: 0.499513, loss_fp: 0.500016, loss_freq: 0.500809
[12:19:26.596] iteration 2363: loss: 0.982416, loss_s1: 0.456122, loss_fp: 0.500016, loss_freq: 0.500067
[12:19:27.218] iteration 2364: loss: 0.956812, loss_s1: 0.500958, loss_fp: 0.500003, loss_freq: 0.500191
[12:19:27.834] iteration 2365: loss: 0.965645, loss_s1: 0.502326, loss_fp: 0.500005, loss_freq: 0.500160
[12:19:28.443] iteration 2366: loss: 0.946252, loss_s1: 0.500871, loss_fp: 0.500008, loss_freq: 0.500118
[12:19:29.060] iteration 2367: loss: 0.910132, loss_s1: 0.502198, loss_fp: 0.500026, loss_freq: 0.500065
[12:19:29.684] iteration 2368: loss: 1.259395, loss_s1: 0.495506, loss_fp: 0.500032, loss_freq: 0.500413
[12:19:30.328] iteration 2369: loss: 0.945326, loss_s1: 0.449980, loss_fp: 0.500025, loss_freq: 0.500432
[12:19:30.946] iteration 2370: loss: 1.017952, loss_s1: 0.501714, loss_fp: 0.500030, loss_freq: 0.500238
[12:19:31.567] iteration 2371: loss: 1.058053, loss_s1: 0.500806, loss_fp: 0.500029, loss_freq: 0.500094
[12:19:32.184] iteration 2372: loss: 0.971357, loss_s1: 0.501301, loss_fp: 0.500062, loss_freq: 0.500052
[12:19:32.804] iteration 2373: loss: 1.051590, loss_s1: 0.504431, loss_fp: 0.500060, loss_freq: 0.500744
[12:19:33.421] iteration 2374: loss: 0.973231, loss_s1: 0.500306, loss_fp: 0.500026, loss_freq: 0.500115
[12:19:34.035] iteration 2375: loss: 1.029790, loss_s1: 0.500507, loss_fp: 0.500030, loss_freq: 0.500587
[12:19:34.656] iteration 2376: loss: 1.012283, loss_s1: 0.501144, loss_fp: 0.500048, loss_freq: 0.500210
[12:19:35.272] iteration 2377: loss: 0.963814, loss_s1: 0.500721, loss_fp: 0.500034, loss_freq: 0.500457
[12:19:35.885] iteration 2378: loss: 0.963184, loss_s1: 0.502499, loss_fp: 0.500020, loss_freq: 0.500080
[12:19:36.507] iteration 2379: loss: 1.009717, loss_s1: 0.500307, loss_fp: 0.500071, loss_freq: 0.500145
[12:19:37.130] iteration 2380: loss: 1.037177, loss_s1: 0.500779, loss_fp: 0.500081, loss_freq: 0.500433
[12:19:37.752] iteration 2381: loss: 0.903487, loss_s1: 0.500721, loss_fp: 0.500099, loss_freq: 0.500209
[12:19:38.373] iteration 2382: loss: 0.993831, loss_s1: 0.501094, loss_fp: 0.500054, loss_freq: 0.500239
[12:19:38.998] iteration 2383: loss: 0.899665, loss_s1: 0.500535, loss_fp: 0.500150, loss_freq: 0.500148
[12:19:39.623] iteration 2384: loss: 0.961680, loss_s1: 0.501684, loss_fp: 0.500054, loss_freq: 0.500418
[12:19:40.237] iteration 2385: loss: 0.986398, loss_s1: 0.501550, loss_fp: 0.500067, loss_freq: 0.500507
[12:19:40.859] iteration 2386: loss: 0.924685, loss_s1: 0.500272, loss_fp: 0.500036, loss_freq: 0.500268
[12:19:41.477] iteration 2387: loss: 1.031227, loss_s1: 0.501947, loss_fp: 0.500098, loss_freq: 0.501090
[12:19:42.093] iteration 2388: loss: 0.941290, loss_s1: 0.500273, loss_fp: 0.500078, loss_freq: 0.500983
[12:19:42.713] iteration 2389: loss: 0.966271, loss_s1: 0.503148, loss_fp: 0.500116, loss_freq: 0.500402
[12:19:43.333] iteration 2390: loss: 0.984257, loss_s1: 0.500154, loss_fp: 0.500129, loss_freq: 0.500222
[12:19:43.956] iteration 2391: loss: 0.948689, loss_s1: 0.503765, loss_fp: 0.500275, loss_freq: 0.500058
[12:19:44.575] iteration 2392: loss: 0.886613, loss_s1: 0.503184, loss_fp: 0.500092, loss_freq: 0.500504
[12:19:45.193] iteration 2393: loss: 1.054808, loss_s1: 0.501256, loss_fp: 0.500024, loss_freq: 0.500354
[12:19:45.810] iteration 2394: loss: 0.946292, loss_s1: 0.500548, loss_fp: 0.500040, loss_freq: 0.500158
[12:19:46.429] iteration 2395: loss: 0.909495, loss_s1: 0.504732, loss_fp: 0.500042, loss_freq: 0.500902
[12:19:47.046] iteration 2396: loss: 0.879804, loss_s1: 0.503222, loss_fp: 0.500055, loss_freq: 0.500098
[12:19:47.661] iteration 2397: loss: 0.966573, loss_s1: 0.500972, loss_fp: 0.500021, loss_freq: 0.500091
[12:19:48.283] iteration 2398: loss: 0.919159, loss_s1: 0.501917, loss_fp: 0.500106, loss_freq: 0.500269
[12:19:48.918] iteration 2399: loss: 0.900545, loss_s1: 0.500275, loss_fp: 0.500086, loss_freq: 0.500112
[12:19:49.549] iteration 2400: loss: 0.851887, loss_s1: 0.434668, loss_fp: 0.500044, loss_freq: 0.500542
[12:19:52.604] iteration 2400 : mean_dice : 0.373049
[12:19:53.254] iteration 2401: loss: 0.925525, loss_s1: 0.500321, loss_fp: 0.500030, loss_freq: 0.500069
[12:19:53.883] iteration 2402: loss: 0.855614, loss_s1: 0.500806, loss_fp: 0.500046, loss_freq: 0.500211
[12:19:54.514] iteration 2403: loss: 1.073631, loss_s1: 0.502434, loss_fp: 0.500033, loss_freq: 0.502016
[12:19:55.136] iteration 2404: loss: 0.884856, loss_s1: 0.500266, loss_fp: 0.500046, loss_freq: 0.500618
[12:19:55.757] iteration 2405: loss: 0.897887, loss_s1: 0.502700, loss_fp: 0.500052, loss_freq: 0.500213
[12:19:56.372] iteration 2406: loss: 0.960183, loss_s1: 0.500769, loss_fp: 0.500031, loss_freq: 0.500345
[12:19:57.013] iteration 2407: loss: 0.864941, loss_s1: 0.502145, loss_fp: 0.500094, loss_freq: 0.500286
[12:19:57.667] iteration 2408: loss: 0.933160, loss_s1: 0.501499, loss_fp: 0.500017, loss_freq: 0.501534
[12:19:58.323] iteration 2409: loss: 0.949284, loss_s1: 0.503401, loss_fp: 0.500044, loss_freq: 0.500622
[12:19:58.974] iteration 2410: loss: 1.061009, loss_s1: 0.503633, loss_fp: 0.500039, loss_freq: 0.501564
[12:19:59.614] iteration 2411: loss: 1.005680, loss_s1: 0.501172, loss_fp: 0.500022, loss_freq: 0.500523
[12:20:00.234] iteration 2412: loss: 0.906570, loss_s1: 0.502785, loss_fp: 0.500037, loss_freq: 0.500774
[12:20:00.845] iteration 2413: loss: 0.907682, loss_s1: 0.501115, loss_fp: 0.500028, loss_freq: 0.500614
[12:20:01.469] iteration 2414: loss: 0.959866, loss_s1: 0.501880, loss_fp: 0.500036, loss_freq: 0.500788
[12:20:02.094] iteration 2415: loss: 0.973688, loss_s1: 0.501966, loss_fp: 0.500013, loss_freq: 0.502604
[12:20:02.746] iteration 2416: loss: 0.851277, loss_s1: 0.500736, loss_fp: 0.500029, loss_freq: 0.500049
[12:20:03.399] iteration 2417: loss: 0.942290, loss_s1: 0.501335, loss_fp: 0.500009, loss_freq: 0.500452
[12:20:04.051] iteration 2418: loss: 0.874819, loss_s1: 0.500200, loss_fp: 0.500036, loss_freq: 0.500205
[12:20:04.700] iteration 2419: loss: 0.934404, loss_s1: 0.500954, loss_fp: 0.500023, loss_freq: 0.500387
[12:20:05.349] iteration 2420: loss: 0.894183, loss_s1: 0.501366, loss_fp: 0.500036, loss_freq: 0.500308
[12:20:05.969] iteration 2421: loss: 0.898900, loss_s1: 0.501002, loss_fp: 0.500017, loss_freq: 0.500727
[12:20:06.586] iteration 2422: loss: 1.062733, loss_s1: 0.502726, loss_fp: 0.500034, loss_freq: 0.500156
[12:20:07.202] iteration 2423: loss: 0.972426, loss_s1: 0.502929, loss_fp: 0.500023, loss_freq: 0.502044
[12:20:07.820] iteration 2424: loss: 0.901050, loss_s1: 0.501597, loss_fp: 0.500066, loss_freq: 0.501731
[12:20:08.446] iteration 2425: loss: 0.924516, loss_s1: 0.501275, loss_fp: 0.500043, loss_freq: 0.500100
[12:20:09.061] iteration 2426: loss: 0.946695, loss_s1: 0.501913, loss_fp: 0.500061, loss_freq: 0.500311
[12:20:09.774] iteration 2427: loss: 0.867983, loss_s1: 0.500772, loss_fp: 0.500057, loss_freq: 0.500191
[12:20:10.399] iteration 2428: loss: 0.985637, loss_s1: 0.500887, loss_fp: 0.500068, loss_freq: 0.500144
[12:20:11.017] iteration 2429: loss: 0.984250, loss_s1: 0.500495, loss_fp: 0.500045, loss_freq: 0.500098
[12:20:11.632] iteration 2430: loss: 0.878729, loss_s1: 0.506415, loss_fp: 0.500044, loss_freq: 0.500500
[12:20:12.246] iteration 2431: loss: 0.878023, loss_s1: 0.501142, loss_fp: 0.500030, loss_freq: 0.500355
[12:20:13.167] iteration 2432: loss: 0.963103, loss_s1: 0.503208, loss_fp: 0.500097, loss_freq: 0.500142
[12:20:13.806] iteration 2433: loss: 0.869767, loss_s1: 0.502635, loss_fp: 0.500029, loss_freq: 0.500108
[12:20:14.439] iteration 2434: loss: 0.840510, loss_s1: 0.501448, loss_fp: 0.500090, loss_freq: 0.500131
[12:20:15.061] iteration 2435: loss: 0.957074, loss_s1: 0.501801, loss_fp: 0.500076, loss_freq: 0.500141
[12:20:15.673] iteration 2436: loss: 0.903284, loss_s1: 0.501663, loss_fp: 0.500099, loss_freq: 0.500150
[12:20:16.285] iteration 2437: loss: 0.894955, loss_s1: 0.500884, loss_fp: 0.500050, loss_freq: 0.500332
[12:20:16.902] iteration 2438: loss: 0.885106, loss_s1: 0.500276, loss_fp: 0.500027, loss_freq: 0.500200
[12:20:17.515] iteration 2439: loss: 0.938848, loss_s1: 0.502341, loss_fp: 0.500099, loss_freq: 0.500259
[12:20:18.128] iteration 2440: loss: 0.853988, loss_s1: 0.500769, loss_fp: 0.500066, loss_freq: 0.500191
[12:20:18.750] iteration 2441: loss: 1.037792, loss_s1: 0.504388, loss_fp: 0.500012, loss_freq: 0.500968
[12:20:19.425] iteration 2442: loss: 0.869622, loss_s1: 0.500892, loss_fp: 0.500035, loss_freq: 0.500083
[12:20:20.072] iteration 2443: loss: 0.861858, loss_s1: 0.501354, loss_fp: 0.500047, loss_freq: 0.500625
[12:20:20.724] iteration 2444: loss: 0.946707, loss_s1: 0.503161, loss_fp: 0.500021, loss_freq: 0.500916
[12:20:21.360] iteration 2445: loss: 0.846831, loss_s1: 0.504093, loss_fp: 0.500020, loss_freq: 0.500168
[12:20:21.977] iteration 2446: loss: 0.366427, loss_s1: 0.256280, loss_fp: 0.014224, loss_freq: 0.083047
[12:20:22.588] iteration 2447: loss: 0.887462, loss_s1: 0.501548, loss_fp: 0.500042, loss_freq: 0.500051
[12:20:23.209] iteration 2448: loss: 0.989080, loss_s1: 0.402995, loss_fp: 0.500058, loss_freq: 0.500022
[12:20:23.821] iteration 2449: loss: 1.025092, loss_s1: 0.500323, loss_fp: 0.500007, loss_freq: 0.500162
[12:20:24.521] iteration 2450: loss: 0.886840, loss_s1: 0.500775, loss_fp: 0.500016, loss_freq: 0.500739
[12:20:25.193] iteration 2451: loss: 0.898688, loss_s1: 0.500739, loss_fp: 0.500018, loss_freq: 0.500209
[12:20:25.846] iteration 2452: loss: 0.960064, loss_s1: 0.500628, loss_fp: 0.500031, loss_freq: 0.500180
[12:20:26.498] iteration 2453: loss: 0.858928, loss_s1: 0.502151, loss_fp: 0.500019, loss_freq: 0.500416
[12:20:27.135] iteration 2454: loss: 0.875538, loss_s1: 0.502564, loss_fp: 0.500020, loss_freq: 0.501498
[12:20:27.745] iteration 2455: loss: 0.940874, loss_s1: 0.501283, loss_fp: 0.500023, loss_freq: 0.501028
[12:20:28.394] iteration 2456: loss: 0.880085, loss_s1: 0.502909, loss_fp: 0.500017, loss_freq: 0.500444
[12:20:29.024] iteration 2457: loss: 0.940779, loss_s1: 0.501605, loss_fp: 0.500034, loss_freq: 0.500388
[12:20:29.656] iteration 2458: loss: 0.928396, loss_s1: 0.500859, loss_fp: 0.500029, loss_freq: 0.500377
[12:20:30.291] iteration 2459: loss: 0.866482, loss_s1: 0.500329, loss_fp: 0.500009, loss_freq: 0.500122
[12:20:30.924] iteration 2460: loss: 1.047258, loss_s1: 0.502510, loss_fp: 0.500014, loss_freq: 0.502048
[12:20:31.545] iteration 2461: loss: 0.982907, loss_s1: 0.500295, loss_fp: 0.500012, loss_freq: 0.500160
[12:20:32.175] iteration 2462: loss: 0.795408, loss_s1: 0.484459, loss_fp: 0.338389, loss_freq: 0.488306
[12:20:32.803] iteration 2463: loss: 0.885515, loss_s1: 0.502542, loss_fp: 0.500003, loss_freq: 0.501719
[12:20:33.434] iteration 2464: loss: 0.911756, loss_s1: 0.500066, loss_fp: 0.500019, loss_freq: 0.500178
[12:20:34.059] iteration 2465: loss: 0.915243, loss_s1: 0.504625, loss_fp: 0.500010, loss_freq: 0.500385
[12:20:34.692] iteration 2466: loss: 0.965074, loss_s1: 0.502817, loss_fp: 0.500004, loss_freq: 0.500739
[12:20:35.324] iteration 2467: loss: 0.935963, loss_s1: 0.501247, loss_fp: 0.500011, loss_freq: 0.500433
[12:20:35.958] iteration 2468: loss: 0.875167, loss_s1: 0.500599, loss_fp: 0.500006, loss_freq: 0.500944
[12:20:36.591] iteration 2469: loss: 0.882054, loss_s1: 0.501370, loss_fp: 0.500010, loss_freq: 0.500371
[12:20:37.214] iteration 2470: loss: 0.946535, loss_s1: 0.501119, loss_fp: 0.500007, loss_freq: 0.501408
[12:20:37.831] iteration 2471: loss: 0.904579, loss_s1: 0.501174, loss_fp: 0.500006, loss_freq: 0.500356
[12:20:38.451] iteration 2472: loss: 0.885153, loss_s1: 0.501254, loss_fp: 0.500016, loss_freq: 0.500316
[12:20:39.069] iteration 2473: loss: 0.932082, loss_s1: 0.501425, loss_fp: 0.500000, loss_freq: 0.501270
[12:20:39.683] iteration 2474: loss: 0.921690, loss_s1: 0.500999, loss_fp: 0.500008, loss_freq: 0.500706
[12:20:40.316] iteration 2475: loss: 0.354896, loss_s1: 0.407343, loss_fp: 0.012880, loss_freq: 0.102300
[12:20:40.932] iteration 2476: loss: 1.030382, loss_s1: 0.500688, loss_fp: 0.500000, loss_freq: 0.501000
[12:20:41.550] iteration 2477: loss: 0.859721, loss_s1: 0.502298, loss_fp: 0.500011, loss_freq: 0.500163
[12:20:42.178] iteration 2478: loss: 0.891437, loss_s1: 0.500101, loss_fp: 0.500007, loss_freq: 0.500140
[12:20:42.798] iteration 2479: loss: 0.955474, loss_s1: 0.501374, loss_fp: 0.500002, loss_freq: 0.500014
[12:20:43.413] iteration 2480: loss: 0.846904, loss_s1: 0.500219, loss_fp: 0.500005, loss_freq: 0.500045
[12:20:44.025] iteration 2481: loss: 0.926398, loss_s1: 0.436649, loss_fp: 0.500004, loss_freq: 0.500281
[12:20:44.640] iteration 2482: loss: 0.895351, loss_s1: 0.502494, loss_fp: 0.500006, loss_freq: 0.500240
[12:20:45.342] iteration 2483: loss: 1.085240, loss_s1: 0.500541, loss_fp: 0.500034, loss_freq: 0.500491
[12:20:46.015] iteration 2484: loss: 0.967090, loss_s1: 0.500586, loss_fp: 0.500002, loss_freq: 0.500133
[12:20:46.727] iteration 2485: loss: 0.840687, loss_s1: 0.500755, loss_fp: 0.500006, loss_freq: 0.500150
[12:20:47.391] iteration 2486: loss: 0.877298, loss_s1: 0.500158, loss_fp: 0.500016, loss_freq: 0.500181
[12:20:48.028] iteration 2487: loss: 0.875825, loss_s1: 0.500085, loss_fp: 0.500034, loss_freq: 0.500019
[12:20:48.644] iteration 2488: loss: 0.865396, loss_s1: 0.503101, loss_fp: 0.500028, loss_freq: 0.500716
[12:20:49.262] iteration 2489: loss: 0.852103, loss_s1: 0.500695, loss_fp: 0.500006, loss_freq: 0.500185
[12:20:49.873] iteration 2490: loss: 0.953776, loss_s1: 0.500608, loss_fp: 0.500003, loss_freq: 0.500207
[12:20:50.487] iteration 2491: loss: 0.868265, loss_s1: 0.500990, loss_fp: 0.500000, loss_freq: 0.501019
[12:20:51.104] iteration 2492: loss: 0.911631, loss_s1: 0.502262, loss_fp: 0.500008, loss_freq: 0.500005
[12:20:51.724] iteration 2493: loss: 0.530728, loss_s1: 0.485523, loss_fp: 0.020901, loss_freq: 0.254778
[12:20:52.337] iteration 2494: loss: 0.903240, loss_s1: 0.506477, loss_fp: 0.500007, loss_freq: 0.501035
[12:20:52.954] iteration 2495: loss: 1.074791, loss_s1: 0.501272, loss_fp: 0.500003, loss_freq: 0.500263
[12:20:53.569] iteration 2496: loss: 0.988036, loss_s1: 0.501140, loss_fp: 0.500005, loss_freq: 0.500050
[12:20:54.185] iteration 2497: loss: 0.442508, loss_s1: 0.465637, loss_fp: 0.014465, loss_freq: 0.123100
[12:20:54.805] iteration 2498: loss: 0.872275, loss_s1: 0.503067, loss_fp: 0.500005, loss_freq: 0.500043
[12:20:55.425] iteration 2499: loss: 0.880134, loss_s1: 0.461829, loss_fp: 0.500004, loss_freq: 0.500339
[12:20:56.051] iteration 2500: loss: 0.599363, loss_s1: 0.446404, loss_fp: 0.017635, loss_freq: 0.398524
[12:20:56.679] iteration 2501: loss: 0.979039, loss_s1: 0.470785, loss_fp: 0.500004, loss_freq: 0.500048
[12:20:57.305] iteration 2502: loss: 0.897043, loss_s1: 0.500058, loss_fp: 0.500008, loss_freq: 0.500166
[12:20:57.932] iteration 2503: loss: 0.901738, loss_s1: 0.500529, loss_fp: 0.500008, loss_freq: 0.500024
[12:20:58.547] iteration 2504: loss: 0.858001, loss_s1: 0.500674, loss_fp: 0.500003, loss_freq: 0.500226
[12:20:59.172] iteration 2505: loss: 0.918446, loss_s1: 0.500088, loss_fp: 0.500006, loss_freq: 0.500758
[12:20:59.789] iteration 2506: loss: 0.920138, loss_s1: 0.500005, loss_fp: 0.500017, loss_freq: 0.500158
[12:21:00.431] iteration 2507: loss: 0.899530, loss_s1: 0.501472, loss_fp: 0.500011, loss_freq: 0.500053
[12:21:01.043] iteration 2508: loss: 0.839370, loss_s1: 0.500222, loss_fp: 0.500010, loss_freq: 0.500023
[12:21:01.653] iteration 2509: loss: 0.731335, loss_s1: 0.139329, loss_fp: 0.500007, loss_freq: 0.500016
[12:21:02.267] iteration 2510: loss: 0.525614, loss_s1: 0.479292, loss_fp: 0.031359, loss_freq: 0.340264
[12:21:02.882] iteration 2511: loss: 1.108185, loss_s1: 0.500066, loss_fp: 0.500008, loss_freq: 0.500022
[12:21:03.502] iteration 2512: loss: 0.535146, loss_s1: 0.433273, loss_fp: 0.161791, loss_freq: 0.204174
[12:21:04.142] iteration 2513: loss: 0.932809, loss_s1: 0.500437, loss_fp: 0.500008, loss_freq: 0.500017
[12:21:04.809] iteration 2514: loss: 0.995799, loss_s1: 0.470899, loss_fp: 0.500008, loss_freq: 0.500019
[12:21:05.478] iteration 2515: loss: 0.954417, loss_s1: 0.500952, loss_fp: 0.500007, loss_freq: 0.500002
[12:21:06.152] iteration 2516: loss: 1.070025, loss_s1: 0.501703, loss_fp: 0.500001, loss_freq: 0.500006
[12:21:06.785] iteration 2517: loss: 0.978152, loss_s1: 0.500472, loss_fp: 0.500010, loss_freq: 0.500095
[12:21:07.421] iteration 2518: loss: 1.023723, loss_s1: 0.501658, loss_fp: 0.500002, loss_freq: 0.500018
[12:21:08.086] iteration 2519: loss: 1.027101, loss_s1: 0.500048, loss_fp: 0.500001, loss_freq: 0.500019
[12:21:08.744] iteration 2520: loss: 0.953884, loss_s1: 0.500390, loss_fp: 0.499999, loss_freq: 0.500091
[12:21:09.409] iteration 2521: loss: 0.945005, loss_s1: 0.500318, loss_fp: 0.500005, loss_freq: 0.500007
[12:21:10.056] iteration 2522: loss: 0.915423, loss_s1: 0.500275, loss_fp: 0.499998, loss_freq: 0.500029
[12:21:10.709] iteration 2523: loss: 1.013188, loss_s1: 0.500356, loss_fp: 0.500015, loss_freq: 0.500261
[12:21:11.346] iteration 2524: loss: 0.888782, loss_s1: 0.500146, loss_fp: 0.500001, loss_freq: 0.500015
[12:21:12.003] iteration 2525: loss: 0.983627, loss_s1: 0.500659, loss_fp: 0.499998, loss_freq: 0.500081
[12:21:12.657] iteration 2526: loss: 0.873456, loss_s1: 0.500026, loss_fp: 0.500000, loss_freq: 0.500013
[12:21:13.313] iteration 2527: loss: 0.889257, loss_s1: 0.425905, loss_fp: 0.500005, loss_freq: 0.500117
[12:21:13.938] iteration 2528: loss: 0.923763, loss_s1: 0.502402, loss_fp: 0.500004, loss_freq: 0.500954
[12:21:14.554] iteration 2529: loss: 0.885791, loss_s1: 0.500620, loss_fp: 0.500001, loss_freq: 0.500301
[12:21:15.166] iteration 2530: loss: 0.914307, loss_s1: 0.239037, loss_fp: 0.500004, loss_freq: 0.500185
[12:21:15.834] iteration 2531: loss: 1.013470, loss_s1: 0.501613, loss_fp: 0.500007, loss_freq: 0.500699
[12:21:16.483] iteration 2532: loss: 0.918130, loss_s1: 0.500360, loss_fp: 0.500010, loss_freq: 0.500560
[12:21:17.115] iteration 2533: loss: 0.901950, loss_s1: 0.500642, loss_fp: 0.500015, loss_freq: 0.500053
[12:21:17.738] iteration 2534: loss: 0.961642, loss_s1: 0.500322, loss_fp: 0.500004, loss_freq: 0.500030
[12:21:18.367] iteration 2535: loss: 0.927728, loss_s1: 0.500932, loss_fp: 0.500008, loss_freq: 0.501906
[12:21:18.982] iteration 2536: loss: 1.031094, loss_s1: 0.500587, loss_fp: 0.500009, loss_freq: 0.500064
[12:21:19.607] iteration 2537: loss: 0.366552, loss_s1: 0.184282, loss_fp: 0.008340, loss_freq: 0.141734
[12:21:20.227] iteration 2538: loss: 0.883513, loss_s1: 0.501499, loss_fp: 0.500010, loss_freq: 0.500831
[12:21:20.847] iteration 2539: loss: 0.871732, loss_s1: 0.500626, loss_fp: 0.500007, loss_freq: 0.500213
[12:21:21.469] iteration 2540: loss: 1.001589, loss_s1: 0.499500, loss_fp: 0.500009, loss_freq: 0.500016
[12:21:22.080] iteration 2541: loss: 0.918328, loss_s1: 0.500853, loss_fp: 0.500011, loss_freq: 0.500144
[12:21:22.704] iteration 2542: loss: 0.911797, loss_s1: 0.500252, loss_fp: 0.500007, loss_freq: 0.500068
[12:21:23.382] iteration 2543: loss: 0.926312, loss_s1: 0.500357, loss_fp: 0.500013, loss_freq: 0.500090
[12:21:24.045] iteration 2544: loss: 0.908488, loss_s1: 0.500940, loss_fp: 0.500004, loss_freq: 0.500212
[12:21:24.701] iteration 2545: loss: 0.835235, loss_s1: 0.396094, loss_fp: 0.500008, loss_freq: 0.500008
[12:21:25.363] iteration 2546: loss: 1.062441, loss_s1: 0.500690, loss_fp: 0.500010, loss_freq: 0.500661
[12:21:26.014] iteration 2547: loss: 0.869111, loss_s1: 0.500085, loss_fp: 0.500025, loss_freq: 0.500010
[12:21:26.667] iteration 2548: loss: 0.939897, loss_s1: 0.500231, loss_fp: 0.500004, loss_freq: 0.500010
[12:21:27.322] iteration 2549: loss: 0.962010, loss_s1: 0.500124, loss_fp: 0.500004, loss_freq: 0.500068
[12:21:27.967] iteration 2550: loss: 0.859863, loss_s1: 0.500191, loss_fp: 0.500025, loss_freq: 0.500007
[12:21:28.580] iteration 2551: loss: 0.974454, loss_s1: 0.500441, loss_fp: 0.500009, loss_freq: 0.500032
[12:21:29.201] iteration 2552: loss: 0.936795, loss_s1: 0.500074, loss_fp: 0.500033, loss_freq: 0.500026
[12:21:29.812] iteration 2553: loss: 1.005095, loss_s1: 0.500048, loss_fp: 0.500060, loss_freq: 0.500097
[12:21:30.429] iteration 2554: loss: 1.013717, loss_s1: 0.500873, loss_fp: 0.500002, loss_freq: 0.500025
[12:21:31.045] iteration 2555: loss: 0.881006, loss_s1: 0.500011, loss_fp: 0.500009, loss_freq: 0.500029
[12:21:31.655] iteration 2556: loss: 0.903077, loss_s1: 0.502947, loss_fp: 0.500010, loss_freq: 0.500055
[12:21:32.274] iteration 2557: loss: 0.940227, loss_s1: 0.500591, loss_fp: 0.500001, loss_freq: 0.500006
[12:21:32.900] iteration 2558: loss: 0.913046, loss_s1: 0.500265, loss_fp: 0.500010, loss_freq: 0.500322
[12:21:33.521] iteration 2559: loss: 0.870817, loss_s1: 0.500773, loss_fp: 0.500031, loss_freq: 0.500005
[12:21:34.139] iteration 2560: loss: 0.940796, loss_s1: 0.500757, loss_fp: 0.500004, loss_freq: 0.500030
[12:21:34.757] iteration 2561: loss: 0.863748, loss_s1: 0.502127, loss_fp: 0.500005, loss_freq: 0.500079
[12:21:35.371] iteration 2562: loss: 0.941955, loss_s1: 0.500042, loss_fp: 0.500008, loss_freq: 0.500016
[12:21:35.987] iteration 2563: loss: 0.952263, loss_s1: 0.500533, loss_fp: 0.500021, loss_freq: 0.500069
[12:21:36.616] iteration 2564: loss: 0.861331, loss_s1: 0.500399, loss_fp: 0.500000, loss_freq: 0.500021
[12:21:37.235] iteration 2565: loss: 1.039691, loss_s1: 0.502683, loss_fp: 0.500020, loss_freq: 0.500077
[12:21:37.850] iteration 2566: loss: 0.992484, loss_s1: 0.505497, loss_fp: 0.500000, loss_freq: 0.500175
[12:21:38.467] iteration 2567: loss: 0.885885, loss_s1: 0.500217, loss_fp: 0.500034, loss_freq: 0.500045
[12:21:39.133] iteration 2568: loss: 0.898829, loss_s1: 0.500616, loss_fp: 0.500029, loss_freq: 0.500002
[12:21:39.764] iteration 2569: loss: 0.938505, loss_s1: 0.501435, loss_fp: 0.500004, loss_freq: 0.500154
[12:21:40.374] iteration 2570: loss: 0.879322, loss_s1: 0.501718, loss_fp: 0.500004, loss_freq: 0.500459
[12:21:40.985] iteration 2571: loss: 0.898872, loss_s1: 0.500463, loss_fp: 0.500006, loss_freq: 0.500272
[12:21:41.599] iteration 2572: loss: 0.883758, loss_s1: 0.501416, loss_fp: 0.500006, loss_freq: 0.500012
[12:21:42.218] iteration 2573: loss: 0.855651, loss_s1: 0.503196, loss_fp: 0.500012, loss_freq: 0.500519
[12:21:42.826] iteration 2574: loss: 0.681883, loss_s1: 0.182760, loss_fp: 0.500010, loss_freq: 0.500110
[12:21:43.771] iteration 2575: loss: 0.780523, loss_s1: 0.297624, loss_fp: 0.500015, loss_freq: 0.500136
[12:21:44.391] iteration 2576: loss: 0.847845, loss_s1: 0.501385, loss_fp: 0.500006, loss_freq: 0.500006
[12:21:45.004] iteration 2577: loss: 0.836436, loss_s1: 0.501211, loss_fp: 0.500003, loss_freq: 0.500242
[12:21:45.690] iteration 2578: loss: 0.940812, loss_s1: 0.486974, loss_fp: 0.500004, loss_freq: 0.500034
[12:21:46.332] iteration 2579: loss: 0.914948, loss_s1: 0.500685, loss_fp: 0.500003, loss_freq: 0.500000
[12:21:46.945] iteration 2580: loss: 0.905486, loss_s1: 0.500329, loss_fp: 0.500011, loss_freq: 0.500003
[12:21:47.560] iteration 2581: loss: 0.903068, loss_s1: 0.500001, loss_fp: 0.500005, loss_freq: 0.500006
[12:21:48.174] iteration 2582: loss: 0.929484, loss_s1: 0.501015, loss_fp: 0.500016, loss_freq: 0.500021
[12:21:48.797] iteration 2583: loss: 0.333446, loss_s1: 0.398744, loss_fp: 0.038903, loss_freq: 0.003493
[12:21:49.415] iteration 2584: loss: 1.030503, loss_s1: 0.500479, loss_fp: 0.500035, loss_freq: 0.500668
[12:21:50.035] iteration 2585: loss: 0.866780, loss_s1: 0.500060, loss_fp: 0.500014, loss_freq: 0.500006
[12:21:50.659] iteration 2586: loss: 0.868976, loss_s1: 0.501641, loss_fp: 0.500015, loss_freq: 0.500363
[12:21:51.274] iteration 2587: loss: 0.929280, loss_s1: 0.500667, loss_fp: 0.500001, loss_freq: 0.500012
[12:21:51.891] iteration 2588: loss: 0.844365, loss_s1: 0.501413, loss_fp: 0.499999, loss_freq: 0.500099
[12:21:52.508] iteration 2589: loss: 0.246372, loss_s1: 0.060371, loss_fp: 0.003458, loss_freq: 0.003668
[12:21:53.121] iteration 2590: loss: 0.924838, loss_s1: 0.500634, loss_fp: 0.500005, loss_freq: 0.500021
[12:21:53.736] iteration 2591: loss: 1.067507, loss_s1: 0.500514, loss_fp: 0.500016, loss_freq: 0.500023
[12:21:54.363] iteration 2592: loss: 0.960829, loss_s1: 0.500024, loss_fp: 0.500000, loss_freq: 0.500027
[12:21:54.981] iteration 2593: loss: 0.843249, loss_s1: 0.500273, loss_fp: 0.500005, loss_freq: 0.500007
[12:21:55.641] iteration 2594: loss: 0.915383, loss_s1: 0.500183, loss_fp: 0.500006, loss_freq: 0.500434
[12:21:56.259] iteration 2595: loss: 0.918156, loss_s1: 0.500801, loss_fp: 0.500034, loss_freq: 0.500013
[12:21:56.877] iteration 2596: loss: 0.917082, loss_s1: 0.500312, loss_fp: 0.500004, loss_freq: 0.500531
[12:21:57.502] iteration 2597: loss: 0.857027, loss_s1: 0.501985, loss_fp: 0.500005, loss_freq: 0.500148
[12:21:58.123] iteration 2598: loss: 0.371264, loss_s1: 0.305133, loss_fp: 0.010595, loss_freq: 0.012921
[12:21:58.745] iteration 2599: loss: 0.847259, loss_s1: 0.500699, loss_fp: 0.500016, loss_freq: 0.500511
[12:21:59.369] iteration 2600: loss: 0.929672, loss_s1: 0.500677, loss_fp: 0.500003, loss_freq: 0.500208
[12:22:02.445] iteration 2600 : mean_dice : 0.394754
[12:22:03.086] iteration 2601: loss: 0.923554, loss_s1: 0.500126, loss_fp: 0.500009, loss_freq: 0.500021
[12:22:03.707] iteration 2602: loss: 0.895764, loss_s1: 0.501431, loss_fp: 0.500006, loss_freq: 0.500072
[12:22:04.335] iteration 2603: loss: 1.024242, loss_s1: 0.500394, loss_fp: 0.500004, loss_freq: 0.500103
[12:22:04.968] iteration 2604: loss: 0.948272, loss_s1: 0.500660, loss_fp: 0.500001, loss_freq: 0.500062
[12:22:05.579] iteration 2605: loss: 0.258921, loss_s1: 0.220471, loss_fp: 0.019279, loss_freq: 0.003916
[12:22:06.193] iteration 2606: loss: 0.908142, loss_s1: 0.475775, loss_fp: 0.500007, loss_freq: 0.500024
[12:22:06.805] iteration 2607: loss: 0.919816, loss_s1: 0.500002, loss_fp: 0.500002, loss_freq: 0.500019
[12:22:07.421] iteration 2608: loss: 0.861992, loss_s1: 0.500204, loss_fp: 0.500002, loss_freq: 0.500076
[12:22:08.033] iteration 2609: loss: 0.942049, loss_s1: 0.500042, loss_fp: 0.500013, loss_freq: 0.500074
[12:22:08.642] iteration 2610: loss: 0.936162, loss_s1: 0.500131, loss_fp: 0.500005, loss_freq: 0.500006
[12:22:09.251] iteration 2611: loss: 0.872229, loss_s1: 0.500028, loss_fp: 0.500020, loss_freq: 0.500009
[12:22:09.861] iteration 2612: loss: 0.847340, loss_s1: 0.500014, loss_fp: 0.500010, loss_freq: 0.500017
[12:22:10.474] iteration 2613: loss: 0.946669, loss_s1: 0.500013, loss_fp: 0.500008, loss_freq: 0.500046
[12:22:11.080] iteration 2614: loss: 0.903308, loss_s1: 0.500017, loss_fp: 0.500003, loss_freq: 0.500002
[12:22:11.694] iteration 2615: loss: 0.894544, loss_s1: 0.500256, loss_fp: 0.500005, loss_freq: 0.500014
[12:22:12.311] iteration 2616: loss: 0.863010, loss_s1: 0.500106, loss_fp: 0.500006, loss_freq: 0.500015
[12:22:12.931] iteration 2617: loss: 0.917685, loss_s1: 0.500202, loss_fp: 0.500011, loss_freq: 0.500013
[12:22:13.547] iteration 2618: loss: 0.830454, loss_s1: 0.500020, loss_fp: 0.500003, loss_freq: 0.499996
[12:22:14.170] iteration 2619: loss: 0.997188, loss_s1: 0.500554, loss_fp: 0.500003, loss_freq: 0.500343
[12:22:14.786] iteration 2620: loss: 0.881365, loss_s1: 0.500170, loss_fp: 0.500001, loss_freq: 0.500102
[12:22:15.406] iteration 2621: loss: 0.865555, loss_s1: 0.500049, loss_fp: 0.500005, loss_freq: 0.500059
[12:22:16.022] iteration 2622: loss: 0.925214, loss_s1: 0.500256, loss_fp: 0.500007, loss_freq: 0.500004
[12:22:16.631] iteration 2623: loss: 0.856946, loss_s1: 0.500164, loss_fp: 0.500010, loss_freq: 0.500108
[12:22:17.243] iteration 2624: loss: 0.925037, loss_s1: 0.502370, loss_fp: 0.500006, loss_freq: 0.500038
[12:22:17.859] iteration 2625: loss: 0.932778, loss_s1: 0.501280, loss_fp: 0.500004, loss_freq: 0.500259
[12:22:18.472] iteration 2626: loss: 0.989575, loss_s1: 0.501833, loss_fp: 0.500008, loss_freq: 0.500092
[12:22:19.127] iteration 2627: loss: 0.938131, loss_s1: 0.501024, loss_fp: 0.500006, loss_freq: 0.500554
[12:22:19.862] iteration 2628: loss: 0.835326, loss_s1: 0.501317, loss_fp: 0.500003, loss_freq: 0.500004
[12:22:20.542] iteration 2629: loss: 0.860868, loss_s1: 0.501572, loss_fp: 0.500011, loss_freq: 0.500315
[12:22:21.262] iteration 2630: loss: 0.746045, loss_s1: 0.114884, loss_fp: 0.500011, loss_freq: 0.500003
[12:22:21.925] iteration 2631: loss: 0.855099, loss_s1: 0.502159, loss_fp: 0.500007, loss_freq: 0.500273
[12:22:22.585] iteration 2632: loss: 0.262236, loss_s1: 0.254941, loss_fp: 0.013815, loss_freq: 0.066253
[12:22:23.241] iteration 2633: loss: 0.920957, loss_s1: 0.500008, loss_fp: 0.500007, loss_freq: 0.500023
[12:22:23.874] iteration 2634: loss: 0.860571, loss_s1: 0.500028, loss_fp: 0.500006, loss_freq: 0.500015
[12:22:24.495] iteration 2635: loss: 0.962788, loss_s1: 0.500011, loss_fp: 0.500004, loss_freq: 0.499998
[12:22:25.139] iteration 2636: loss: 0.400763, loss_s1: 0.249128, loss_fp: 0.012417, loss_freq: 0.022320
[12:22:25.816] iteration 2637: loss: 0.879437, loss_s1: 0.500890, loss_fp: 0.500003, loss_freq: 0.500043
[12:22:26.488] iteration 2638: loss: 0.998920, loss_s1: 0.500150, loss_fp: 0.500005, loss_freq: 0.500011
[12:22:27.160] iteration 2639: loss: 0.995640, loss_s1: 0.500070, loss_fp: 0.500003, loss_freq: 0.500000
[12:22:27.782] iteration 2640: loss: 0.894228, loss_s1: 0.500017, loss_fp: 0.500002, loss_freq: 0.500002
[12:22:28.413] iteration 2641: loss: 0.912842, loss_s1: 0.500018, loss_fp: 0.500012, loss_freq: 0.500014
[12:22:29.046] iteration 2642: loss: 0.913650, loss_s1: 0.500003, loss_fp: 0.500004, loss_freq: 0.500084
[12:22:29.680] iteration 2643: loss: 0.946219, loss_s1: 0.500005, loss_fp: 0.500018, loss_freq: 0.500016
[12:22:30.315] iteration 2644: loss: 1.049285, loss_s1: 0.500009, loss_fp: 0.500008, loss_freq: 0.500002
[12:22:30.947] iteration 2645: loss: 0.950507, loss_s1: 0.500168, loss_fp: 0.500001, loss_freq: 0.500002
[12:22:31.580] iteration 2646: loss: 0.899548, loss_s1: 0.500027, loss_fp: 0.500011, loss_freq: 0.500008
[12:22:32.218] iteration 2647: loss: 0.855267, loss_s1: 0.500193, loss_fp: 0.500005, loss_freq: 0.500029
[12:22:32.847] iteration 2648: loss: 0.974448, loss_s1: 0.500476, loss_fp: 0.500004, loss_freq: 0.500051
[12:22:33.474] iteration 2649: loss: 0.910982, loss_s1: 0.500038, loss_fp: 0.500013, loss_freq: 0.500038
[12:22:34.100] iteration 2650: loss: 0.921787, loss_s1: 0.500885, loss_fp: 0.500082, loss_freq: 0.500023
[12:22:34.723] iteration 2651: loss: 0.872910, loss_s1: 0.501695, loss_fp: 0.500008, loss_freq: 0.500039
[12:22:35.348] iteration 2652: loss: 0.935135, loss_s1: 0.500044, loss_fp: 0.500010, loss_freq: 0.500064
[12:22:35.968] iteration 2653: loss: 0.913367, loss_s1: 0.500179, loss_fp: 0.500008, loss_freq: 0.500087
[12:22:36.579] iteration 2654: loss: 0.897225, loss_s1: 0.246688, loss_fp: 0.500005, loss_freq: 0.500151
[12:22:37.188] iteration 2655: loss: 0.201749, loss_s1: 0.070805, loss_fp: 0.002981, loss_freq: 0.032454
[12:22:37.795] iteration 2656: loss: 0.917045, loss_s1: 0.500254, loss_fp: 0.500008, loss_freq: 0.500129
[12:22:38.407] iteration 2657: loss: 0.712321, loss_s1: 0.004432, loss_fp: 0.500002, loss_freq: 0.500032
[12:22:39.025] iteration 2658: loss: 0.691764, loss_s1: 0.437191, loss_fp: 0.282701, loss_freq: 0.412364
[12:22:39.634] iteration 2659: loss: 0.946729, loss_s1: 0.500216, loss_fp: 0.500006, loss_freq: 0.500009
[12:22:40.244] iteration 2660: loss: 0.894468, loss_s1: 0.500910, loss_fp: 0.500003, loss_freq: 0.500068
[12:22:40.856] iteration 2661: loss: 0.364766, loss_s1: 0.222362, loss_fp: 0.001603, loss_freq: 0.002681
[12:22:41.470] iteration 2662: loss: 0.988347, loss_s1: 0.482625, loss_fp: 0.500004, loss_freq: 0.500000
[12:22:42.087] iteration 2663: loss: 0.397366, loss_s1: 0.426199, loss_fp: 0.010085, loss_freq: 0.032637
[12:22:42.700] iteration 2664: loss: 0.891672, loss_s1: 0.385456, loss_fp: 0.464404, loss_freq: 0.460679
[12:22:43.319] iteration 2665: loss: 0.936451, loss_s1: 0.500006, loss_fp: 0.500004, loss_freq: 0.499999
[12:22:43.937] iteration 2666: loss: 0.993225, loss_s1: 0.500055, loss_fp: 0.500002, loss_freq: 0.500002
[12:22:44.552] iteration 2667: loss: 0.895996, loss_s1: 0.500007, loss_fp: 0.500015, loss_freq: 0.500010
[12:22:45.213] iteration 2668: loss: 0.954094, loss_s1: 0.500009, loss_fp: 0.500000, loss_freq: 0.499999
[12:22:45.831] iteration 2669: loss: 0.945704, loss_s1: 0.500003, loss_fp: 0.500001, loss_freq: 0.499998
[12:22:46.450] iteration 2670: loss: 0.986097, loss_s1: 0.500001, loss_fp: 0.500000, loss_freq: 0.500004
[12:22:47.073] iteration 2671: loss: 0.984110, loss_s1: 0.500037, loss_fp: 0.499994, loss_freq: 0.500005
[12:22:47.697] iteration 2672: loss: 0.917152, loss_s1: 0.499550, loss_fp: 0.500007, loss_freq: 0.500000
[12:22:48.316] iteration 2673: loss: 1.088658, loss_s1: 0.500132, loss_fp: 0.499998, loss_freq: 0.500025
[12:22:48.938] iteration 2674: loss: 0.642385, loss_s1: 0.455355, loss_fp: 0.009184, loss_freq: 0.288644
[12:22:49.565] iteration 2675: loss: 0.952316, loss_s1: 0.500048, loss_fp: 0.500004, loss_freq: 0.500013
[12:22:50.198] iteration 2676: loss: 0.879212, loss_s1: 0.500037, loss_fp: 0.500009, loss_freq: 0.500005
[12:22:50.836] iteration 2677: loss: 0.924925, loss_s1: 0.500004, loss_fp: 0.499996, loss_freq: 0.500006
[12:22:51.477] iteration 2678: loss: 0.880661, loss_s1: 0.500012, loss_fp: 0.500002, loss_freq: 0.500010
[12:22:52.097] iteration 2679: loss: 0.951761, loss_s1: 0.499695, loss_fp: 0.499998, loss_freq: 0.500001
[12:22:52.739] iteration 2680: loss: 0.205270, loss_s1: 0.063693, loss_fp: 0.001449, loss_freq: 0.013588
[12:22:53.373] iteration 2681: loss: 0.925635, loss_s1: 0.500116, loss_fp: 0.500010, loss_freq: 0.500008
[12:22:53.997] iteration 2682: loss: 0.748165, loss_s1: 0.277639, loss_fp: 0.500001, loss_freq: 0.500010
[12:22:54.613] iteration 2683: loss: 0.971541, loss_s1: 0.499912, loss_fp: 0.499997, loss_freq: 0.500000
[12:22:55.233] iteration 2684: loss: 0.975317, loss_s1: 0.500122, loss_fp: 0.500002, loss_freq: 0.500004
[12:22:55.853] iteration 2685: loss: 0.719158, loss_s1: 0.102426, loss_fp: 0.500001, loss_freq: 0.500001
[12:22:56.473] iteration 2686: loss: 0.242786, loss_s1: 0.235892, loss_fp: 0.002375, loss_freq: 0.004252
[12:22:57.100] iteration 2687: loss: 0.405502, loss_s1: 0.177152, loss_fp: 0.155937, loss_freq: 0.124578
[12:22:57.718] iteration 2688: loss: 0.448873, loss_s1: 0.314065, loss_fp: 0.066141, loss_freq: 0.349179
[12:22:58.338] iteration 2689: loss: 0.677783, loss_s1: 0.442264, loss_fp: 0.012988, loss_freq: 0.251343
[12:22:58.960] iteration 2690: loss: 0.185413, loss_s1: 0.059478, loss_fp: 0.003038, loss_freq: 0.001852
[12:22:59.582] iteration 2691: loss: 0.924043, loss_s1: 0.500249, loss_fp: 0.499994, loss_freq: 0.500006
[12:23:00.197] iteration 2692: loss: 1.029400, loss_s1: 0.500099, loss_fp: 0.500001, loss_freq: 0.500014
[12:23:00.814] iteration 2693: loss: 0.221055, loss_s1: 0.058221, loss_fp: 0.004053, loss_freq: 0.070667
[12:23:01.513] iteration 2694: loss: 0.524718, loss_s1: 0.472241, loss_fp: 0.001390, loss_freq: 0.023277
[12:23:02.194] iteration 2695: loss: 0.382847, loss_s1: 0.411118, loss_fp: 0.001563, loss_freq: 0.002469
[12:23:02.855] iteration 2696: loss: 1.117633, loss_s1: 0.500059, loss_fp: 0.499997, loss_freq: 0.500110
[12:23:03.517] iteration 2697: loss: 0.581142, loss_s1: 0.440695, loss_fp: 0.002208, loss_freq: 0.138773
[12:23:04.147] iteration 2698: loss: 0.251729, loss_s1: 0.172778, loss_fp: 0.003319, loss_freq: 0.024544
[12:23:04.766] iteration 2699: loss: 0.972726, loss_s1: 0.500111, loss_fp: 0.499995, loss_freq: 0.500007
[12:23:05.386] iteration 2700: loss: 0.982890, loss_s1: 0.491814, loss_fp: 0.500004, loss_freq: 0.500000
[12:23:06.024] iteration 2701: loss: 0.448862, loss_s1: 0.327295, loss_fp: 0.006229, loss_freq: 0.012916
[12:23:06.642] iteration 2702: loss: 0.445431, loss_s1: 0.415185, loss_fp: 0.006325, loss_freq: 0.136601
[12:23:07.251] iteration 2703: loss: 0.349301, loss_s1: 0.097553, loss_fp: 0.009655, loss_freq: 0.021433
[12:23:07.864] iteration 2704: loss: 0.885680, loss_s1: 0.499629, loss_fp: 0.499998, loss_freq: 0.500014
[12:23:08.505] iteration 2705: loss: 0.976441, loss_s1: 0.500021, loss_fp: 0.500000, loss_freq: 0.500147
[12:23:09.130] iteration 2706: loss: 0.493118, loss_s1: 0.460512, loss_fp: 0.001712, loss_freq: 0.003725
[12:23:09.742] iteration 2707: loss: 0.199518, loss_s1: 0.023722, loss_fp: 0.001777, loss_freq: 0.008570
[12:23:10.356] iteration 2708: loss: 0.563207, loss_s1: 0.364962, loss_fp: 0.001840, loss_freq: 0.046779
[12:23:10.981] iteration 2709: loss: 0.384020, loss_s1: 0.257802, loss_fp: 0.001945, loss_freq: 0.034809
[12:23:11.600] iteration 2710: loss: 0.339488, loss_s1: 0.278854, loss_fp: 0.006195, loss_freq: 0.006974
[12:23:12.232] iteration 2711: loss: 0.308879, loss_s1: 0.274086, loss_fp: 0.007968, loss_freq: 0.001199
[12:23:12.897] iteration 2712: loss: 0.971131, loss_s1: 0.500013, loss_fp: 0.500006, loss_freq: 0.499989
[12:23:13.520] iteration 2713: loss: 0.905443, loss_s1: 0.500008, loss_fp: 0.500000, loss_freq: 0.500016
[12:23:14.141] iteration 2714: loss: 0.988257, loss_s1: 0.500003, loss_fp: 0.499997, loss_freq: 0.500001
[12:23:14.759] iteration 2715: loss: 0.967760, loss_s1: 0.499997, loss_fp: 0.500000, loss_freq: 0.499961
[12:23:15.380] iteration 2716: loss: 0.912247, loss_s1: 0.500016, loss_fp: 0.500000, loss_freq: 0.499992
[12:23:16.009] iteration 2717: loss: 0.916130, loss_s1: 0.499999, loss_fp: 0.499997, loss_freq: 0.499983
[12:23:16.961] iteration 2718: loss: 0.953606, loss_s1: 0.500005, loss_fp: 0.500005, loss_freq: 0.499988
[12:23:17.585] iteration 2719: loss: 0.929863, loss_s1: 0.500001, loss_fp: 0.500003, loss_freq: 0.499981
[12:23:18.204] iteration 2720: loss: 0.920129, loss_s1: 0.500025, loss_fp: 0.499998, loss_freq: 0.499997
[12:23:18.828] iteration 2721: loss: 1.004631, loss_s1: 0.500000, loss_fp: 0.500005, loss_freq: 0.499989
[12:23:19.450] iteration 2722: loss: 0.954140, loss_s1: 0.500119, loss_fp: 0.499998, loss_freq: 0.499984
[12:23:20.072] iteration 2723: loss: 0.955275, loss_s1: 0.500004, loss_fp: 0.500002, loss_freq: 0.499993
[12:23:20.698] iteration 2724: loss: 0.933394, loss_s1: 0.500300, loss_fp: 0.499998, loss_freq: 0.500001
[12:23:21.316] iteration 2725: loss: 0.920796, loss_s1: 0.501173, loss_fp: 0.500002, loss_freq: 0.500029
[12:23:21.979] iteration 2726: loss: 0.172035, loss_s1: 0.104210, loss_fp: 0.006313, loss_freq: 0.000981
[12:23:22.638] iteration 2727: loss: 0.918322, loss_s1: 0.076792, loss_fp: 0.499995, loss_freq: 0.500298
[12:23:23.294] iteration 2728: loss: 0.885048, loss_s1: 0.500362, loss_fp: 0.500008, loss_freq: 0.499992
[12:23:23.950] iteration 2729: loss: 0.899462, loss_s1: 0.500190, loss_fp: 0.500005, loss_freq: 0.500022
[12:23:24.608] iteration 2730: loss: 0.854813, loss_s1: 0.290972, loss_fp: 0.499999, loss_freq: 0.500001
[12:23:25.263] iteration 2731: loss: 0.263368, loss_s1: 0.255533, loss_fp: 0.002684, loss_freq: 0.001705
[12:23:25.916] iteration 2732: loss: 0.231489, loss_s1: 0.006264, loss_fp: 0.000844, loss_freq: 0.000736
[12:23:26.578] iteration 2733: loss: 0.910338, loss_s1: 0.500851, loss_fp: 0.500000, loss_freq: 0.500000
[12:23:27.237] iteration 2734: loss: 1.046475, loss_s1: 0.500297, loss_fp: 0.500002, loss_freq: 0.500002
[12:23:27.902] iteration 2735: loss: 0.943312, loss_s1: 0.500271, loss_fp: 0.500070, loss_freq: 0.500031
[12:23:28.520] iteration 2736: loss: 0.909033, loss_s1: 0.500122, loss_fp: 0.500004, loss_freq: 0.500000
[12:23:29.136] iteration 2737: loss: 0.925496, loss_s1: 0.500003, loss_fp: 0.500004, loss_freq: 0.500058
[12:23:29.754] iteration 2738: loss: 0.947407, loss_s1: 0.500649, loss_fp: 0.500016, loss_freq: 0.500012
[12:23:30.369] iteration 2739: loss: 0.898693, loss_s1: 0.500033, loss_fp: 0.500044, loss_freq: 0.500014
[12:23:30.987] iteration 2740: loss: 0.688713, loss_s1: 0.166281, loss_fp: 0.500017, loss_freq: 0.500025
[12:23:31.610] iteration 2741: loss: 0.926262, loss_s1: 0.500006, loss_fp: 0.500029, loss_freq: 0.499999
[12:23:32.259] iteration 2742: loss: 0.869911, loss_s1: 0.500120, loss_fp: 0.500014, loss_freq: 0.500000
[12:23:32.881] iteration 2743: loss: 0.939488, loss_s1: 0.500318, loss_fp: 0.500001, loss_freq: 0.500004
[12:23:33.501] iteration 2744: loss: 0.937256, loss_s1: 0.500130, loss_fp: 0.500008, loss_freq: 0.500000
[12:23:34.125] iteration 2745: loss: 0.898273, loss_s1: 0.500125, loss_fp: 0.500001, loss_freq: 0.500003
[12:23:34.740] iteration 2746: loss: 1.026393, loss_s1: 0.500162, loss_fp: 0.500003, loss_freq: 0.500013
[12:23:35.361] iteration 2747: loss: 0.740208, loss_s1: 0.132484, loss_fp: 0.499998, loss_freq: 0.499996
[12:23:35.982] iteration 2748: loss: 0.334491, loss_s1: 0.375618, loss_fp: 0.003580, loss_freq: 0.008612
[12:23:36.605] iteration 2749: loss: 0.198349, loss_s1: 0.001092, loss_fp: 0.004965, loss_freq: 0.002017
[12:23:37.224] iteration 2750: loss: 0.921146, loss_s1: 0.500033, loss_fp: 0.500011, loss_freq: 0.499993
[12:23:37.849] iteration 2751: loss: 0.882050, loss_s1: 0.500243, loss_fp: 0.500008, loss_freq: 0.500204
[12:23:38.465] iteration 2752: loss: 0.977703, loss_s1: 0.500874, loss_fp: 0.500005, loss_freq: 0.500014
[12:23:39.090] iteration 2753: loss: 0.388332, loss_s1: 0.205393, loss_fp: 0.001707, loss_freq: 0.007009
[12:23:39.756] iteration 2754: loss: 0.881246, loss_s1: 0.500071, loss_fp: 0.500006, loss_freq: 0.500044
[12:23:40.410] iteration 2755: loss: 0.837776, loss_s1: 0.453690, loss_fp: 0.500018, loss_freq: 0.500199
[12:23:41.033] iteration 2756: loss: 0.965934, loss_s1: 0.500831, loss_fp: 0.500035, loss_freq: 0.501231
[12:23:41.660] iteration 2757: loss: 0.409139, loss_s1: 0.329925, loss_fp: 0.010725, loss_freq: 0.118371
[12:23:42.284] iteration 2758: loss: 0.484707, loss_s1: 0.431638, loss_fp: 0.065224, loss_freq: 0.190923
[12:23:42.911] iteration 2759: loss: 0.197656, loss_s1: 0.135066, loss_fp: 0.001677, loss_freq: 0.001249
[12:23:43.531] iteration 2760: loss: 0.255436, loss_s1: 0.014952, loss_fp: 0.002131, loss_freq: 0.026600
[12:23:44.159] iteration 2761: loss: 0.291320, loss_s1: 0.087091, loss_fp: 0.004259, loss_freq: 0.162384
[12:23:44.777] iteration 2762: loss: 0.673198, loss_s1: 0.501556, loss_fp: 0.002896, loss_freq: 0.118494
[12:23:45.429] iteration 2763: loss: 0.559566, loss_s1: 0.428399, loss_fp: 0.009670, loss_freq: 0.377990
[12:23:46.040] iteration 2764: loss: 0.201928, loss_s1: 0.026070, loss_fp: 0.002616, loss_freq: 0.027838
[12:23:46.650] iteration 2765: loss: 0.398441, loss_s1: 0.178756, loss_fp: 0.002475, loss_freq: 0.005196
[12:23:47.273] iteration 2766: loss: 0.298305, loss_s1: 0.375499, loss_fp: 0.001693, loss_freq: 0.000621
[12:23:47.882] iteration 2767: loss: 0.329079, loss_s1: 0.121649, loss_fp: 0.002042, loss_freq: 0.010423
[12:23:48.497] iteration 2768: loss: 0.201353, loss_s1: 0.002890, loss_fp: 0.004988, loss_freq: 0.002220
[12:23:49.109] iteration 2769: loss: 0.422610, loss_s1: 0.292571, loss_fp: 0.006699, loss_freq: 0.000810
[12:23:49.722] iteration 2770: loss: 0.952289, loss_s1: 0.500105, loss_fp: 0.500134, loss_freq: 0.500001
[12:23:50.332] iteration 2771: loss: 0.934105, loss_s1: 0.500114, loss_fp: 0.499995, loss_freq: 0.500003
[12:23:50.944] iteration 2772: loss: 0.252259, loss_s1: 0.136399, loss_fp: 0.002292, loss_freq: 0.000740
[12:23:51.560] iteration 2773: loss: 0.377091, loss_s1: 0.394490, loss_fp: 0.013680, loss_freq: 0.009534
[12:23:52.173] iteration 2774: loss: 1.012257, loss_s1: 0.500090, loss_fp: 0.500003, loss_freq: 0.500003
[12:23:52.786] iteration 2775: loss: 0.869913, loss_s1: 0.500012, loss_fp: 0.499995, loss_freq: 0.499999
[12:23:53.399] iteration 2776: loss: 0.280422, loss_s1: 0.029356, loss_fp: 0.001053, loss_freq: 0.004166
[12:23:54.009] iteration 2777: loss: 0.889355, loss_s1: 0.500774, loss_fp: 0.499999, loss_freq: 0.500841
[12:23:54.622] iteration 2778: loss: 0.959594, loss_s1: 0.500001, loss_fp: 0.500002, loss_freq: 0.499990
[12:23:55.267] iteration 2779: loss: 0.327352, loss_s1: 0.272104, loss_fp: 0.005084, loss_freq: 0.002517
[12:23:55.913] iteration 2780: loss: 0.918099, loss_s1: 0.500309, loss_fp: 0.499997, loss_freq: 0.500004
[12:23:56.526] iteration 2781: loss: 1.024616, loss_s1: 0.456644, loss_fp: 0.499999, loss_freq: 0.500022
[12:23:57.172] iteration 2782: loss: 0.379397, loss_s1: 0.332490, loss_fp: 0.004034, loss_freq: 0.020011
[12:23:57.820] iteration 2783: loss: 0.304974, loss_s1: 0.237437, loss_fp: 0.006200, loss_freq: 0.017911
[12:23:58.472] iteration 2784: loss: 0.931418, loss_s1: 0.500631, loss_fp: 0.499997, loss_freq: 0.500032
[12:23:59.121] iteration 2785: loss: 0.827485, loss_s1: 0.306473, loss_fp: 0.500014, loss_freq: 0.500232
[12:23:59.759] iteration 2786: loss: 0.215342, loss_s1: 0.082847, loss_fp: 0.004545, loss_freq: 0.034375
[12:24:00.372] iteration 2787: loss: 0.260925, loss_s1: 0.044268, loss_fp: 0.023752, loss_freq: 0.001502
[12:24:00.983] iteration 2788: loss: 0.311025, loss_s1: 0.291210, loss_fp: 0.003584, loss_freq: 0.021465
[12:24:01.594] iteration 2789: loss: 0.919760, loss_s1: 0.500384, loss_fp: 0.500009, loss_freq: 0.499980
[12:24:02.205] iteration 2790: loss: 0.883398, loss_s1: 0.500441, loss_fp: 0.500000, loss_freq: 0.499999
[12:24:02.816] iteration 2791: loss: 0.962809, loss_s1: 0.500214, loss_fp: 0.500008, loss_freq: 0.500002
[12:24:03.434] iteration 2792: loss: 0.920314, loss_s1: 0.475347, loss_fp: 0.500002, loss_freq: 0.500021
[12:24:04.047] iteration 2793: loss: 0.941276, loss_s1: 0.499653, loss_fp: 0.500002, loss_freq: 0.499991
[12:24:04.663] iteration 2794: loss: 0.654637, loss_s1: 0.092312, loss_fp: 0.500002, loss_freq: 0.499996
[12:24:05.276] iteration 2795: loss: 0.164753, loss_s1: 0.010143, loss_fp: 0.005371, loss_freq: 0.006939
[12:24:05.889] iteration 2796: loss: 0.830715, loss_s1: 0.500009, loss_fp: 0.500007, loss_freq: 0.500003
[12:24:06.508] iteration 2797: loss: 1.151599, loss_s1: 0.419069, loss_fp: 0.499998, loss_freq: 0.499994
[12:24:07.124] iteration 2798: loss: 0.239669, loss_s1: 0.093967, loss_fp: 0.012177, loss_freq: 0.130544
[12:24:07.744] iteration 2799: loss: 0.261722, loss_s1: 0.052799, loss_fp: 0.128269, loss_freq: 0.055121
[12:24:08.363] iteration 2800: loss: 0.285198, loss_s1: 0.001603, loss_fp: 0.001293, loss_freq: 0.001291
[12:24:10.881] iteration 2800 : mean_dice : 0.142120
[12:24:11.563] iteration 2801: loss: 0.325968, loss_s1: 0.263561, loss_fp: 0.071712, loss_freq: 0.008442
[12:24:12.218] iteration 2802: loss: 0.375354, loss_s1: 0.196777, loss_fp: 0.001268, loss_freq: 0.033803
[12:24:12.850] iteration 2803: loss: 0.234666, loss_s1: 0.144398, loss_fp: 0.003175, loss_freq: 0.007309
[12:24:13.470] iteration 2804: loss: 0.382175, loss_s1: 0.107965, loss_fp: 0.000901, loss_freq: 0.001431
[12:24:14.093] iteration 2805: loss: 0.377606, loss_s1: 0.201767, loss_fp: 0.001320, loss_freq: 0.082007
[12:24:14.720] iteration 2806: loss: 0.229840, loss_s1: 0.072409, loss_fp: 0.001846, loss_freq: 0.002478
[12:24:15.366] iteration 2807: loss: 0.302275, loss_s1: 0.297504, loss_fp: 0.002079, loss_freq: 0.003394
[12:24:15.985] iteration 2808: loss: 0.258925, loss_s1: 0.100471, loss_fp: 0.001531, loss_freq: 0.002587
[12:24:16.607] iteration 2809: loss: 0.422356, loss_s1: 0.441517, loss_fp: 0.001626, loss_freq: 0.035425
[12:24:17.227] iteration 2810: loss: 0.300470, loss_s1: 0.347514, loss_fp: 0.001511, loss_freq: 0.000662
[12:24:17.845] iteration 2811: loss: 0.496602, loss_s1: 0.440542, loss_fp: 0.001151, loss_freq: 0.050399
[12:24:18.499] iteration 2812: loss: 0.188451, loss_s1: 0.030665, loss_fp: 0.001998, loss_freq: 0.001030
[12:24:19.146] iteration 2813: loss: 0.349704, loss_s1: 0.228148, loss_fp: 0.001945, loss_freq: 0.001740
[12:24:19.767] iteration 2814: loss: 0.961107, loss_s1: 0.501189, loss_fp: 0.500002, loss_freq: 0.500443
[12:24:20.387] iteration 2815: loss: 0.215701, loss_s1: 0.097632, loss_fp: 0.001097, loss_freq: 0.021358
[12:24:21.011] iteration 2816: loss: 0.412094, loss_s1: 0.209997, loss_fp: 0.001894, loss_freq: 0.021344
[12:24:21.687] iteration 2817: loss: 0.313603, loss_s1: 0.149221, loss_fp: 0.000562, loss_freq: 0.007722
[12:24:22.310] iteration 2818: loss: 0.907273, loss_s1: 0.500237, loss_fp: 0.499998, loss_freq: 0.501295
[12:24:22.924] iteration 2819: loss: 0.214757, loss_s1: 0.128588, loss_fp: 0.002398, loss_freq: 0.040069
[12:24:23.550] iteration 2820: loss: 0.233975, loss_s1: 0.006296, loss_fp: 0.008822, loss_freq: 0.060930
[12:24:24.171] iteration 2821: loss: 0.297847, loss_s1: 0.085911, loss_fp: 0.001024, loss_freq: 0.177750
[12:24:24.789] iteration 2822: loss: 0.462235, loss_s1: 0.107239, loss_fp: 0.025641, loss_freq: 0.188266
[12:24:25.408] iteration 2823: loss: 0.254516, loss_s1: 0.075792, loss_fp: 0.000822, loss_freq: 0.003573
[12:24:26.029] iteration 2824: loss: 0.936905, loss_s1: 0.500010, loss_fp: 0.500003, loss_freq: 0.500262
[12:24:26.648] iteration 2825: loss: 0.319581, loss_s1: 0.320608, loss_fp: 0.007080, loss_freq: 0.024244
[12:24:27.276] iteration 2826: loss: 0.262261, loss_s1: 0.028710, loss_fp: 0.001503, loss_freq: 0.001527
[12:24:27.894] iteration 2827: loss: 0.484048, loss_s1: 0.492976, loss_fp: 0.002139, loss_freq: 0.012882
[12:24:28.514] iteration 2828: loss: 0.216387, loss_s1: 0.037638, loss_fp: 0.002214, loss_freq: 0.005290
[12:24:29.181] iteration 2829: loss: 0.375431, loss_s1: 0.440111, loss_fp: 0.006610, loss_freq: 0.006637
[12:24:29.829] iteration 2830: loss: 0.217180, loss_s1: 0.114785, loss_fp: 0.002943, loss_freq: 0.002358
[12:24:30.479] iteration 2831: loss: 0.183221, loss_s1: 0.095257, loss_fp: 0.000962, loss_freq: 0.020515
[12:24:31.138] iteration 2832: loss: 1.096934, loss_s1: 0.495016, loss_fp: 0.499999, loss_freq: 0.500002
[12:24:31.792] iteration 2833: loss: 0.197287, loss_s1: 0.131213, loss_fp: 0.000622, loss_freq: 0.000849
[12:24:32.450] iteration 2834: loss: 0.675301, loss_s1: 0.031948, loss_fp: 0.500001, loss_freq: 0.500025
[12:24:33.093] iteration 2835: loss: 1.011550, loss_s1: 0.500377, loss_fp: 0.500002, loss_freq: 0.500173
[12:24:33.743] iteration 2836: loss: 0.236031, loss_s1: 0.195499, loss_fp: 0.001182, loss_freq: 0.041612
[12:24:34.364] iteration 2837: loss: 0.389338, loss_s1: 0.369470, loss_fp: 0.001777, loss_freq: 0.001154
[12:24:34.975] iteration 2838: loss: 0.230888, loss_s1: 0.101307, loss_fp: 0.000783, loss_freq: 0.000550
[12:24:35.586] iteration 2839: loss: 1.036509, loss_s1: 0.500809, loss_fp: 0.499997, loss_freq: 0.500010
[12:24:36.198] iteration 2840: loss: 0.314206, loss_s1: 0.247453, loss_fp: 0.006325, loss_freq: 0.002788
[12:24:36.813] iteration 2841: loss: 0.220801, loss_s1: 0.072729, loss_fp: 0.002309, loss_freq: 0.000672
[12:24:37.430] iteration 2842: loss: 0.286393, loss_s1: 0.327329, loss_fp: 0.006966, loss_freq: 0.003122
[12:24:38.053] iteration 2843: loss: 0.280542, loss_s1: 0.232588, loss_fp: 0.002297, loss_freq: 0.001800
[12:24:38.677] iteration 2844: loss: 0.146381, loss_s1: 0.005051, loss_fp: 0.001444, loss_freq: 0.001245
[12:24:39.299] iteration 2845: loss: 0.247305, loss_s1: 0.258152, loss_fp: 0.001082, loss_freq: 0.031092
[12:24:39.921] iteration 2846: loss: 0.308885, loss_s1: 0.122458, loss_fp: 0.000988, loss_freq: 0.088593
[12:24:40.537] iteration 2847: loss: 0.131631, loss_s1: 0.049188, loss_fp: 0.002080, loss_freq: 0.001409
[12:24:41.149] iteration 2848: loss: 0.198233, loss_s1: 0.004793, loss_fp: 0.001487, loss_freq: 0.005074
[12:24:41.771] iteration 2849: loss: 0.208170, loss_s1: 0.001841, loss_fp: 0.027584, loss_freq: 0.027715
[12:24:42.384] iteration 2850: loss: 0.181846, loss_s1: 0.031408, loss_fp: 0.001119, loss_freq: 0.015143
[12:24:42.994] iteration 2851: loss: 0.336031, loss_s1: 0.087247, loss_fp: 0.000922, loss_freq: 0.004251
[12:24:43.610] iteration 2852: loss: 0.589424, loss_s1: 0.241094, loss_fp: 0.004768, loss_freq: 0.441110
[12:24:44.221] iteration 2853: loss: 0.208500, loss_s1: 0.071175, loss_fp: 0.001259, loss_freq: 0.014846
[12:24:44.830] iteration 2854: loss: 0.896055, loss_s1: 0.500002, loss_fp: 0.500017, loss_freq: 0.499993
[12:24:45.442] iteration 2855: loss: 0.268925, loss_s1: 0.127611, loss_fp: 0.003569, loss_freq: 0.004603
[12:24:46.052] iteration 2856: loss: 0.353183, loss_s1: 0.298564, loss_fp: 0.001195, loss_freq: 0.072274
[12:24:46.666] iteration 2857: loss: 0.345967, loss_s1: 0.094682, loss_fp: 0.001724, loss_freq: 0.101091
[12:24:47.284] iteration 2858: loss: 0.976118, loss_s1: 0.500021, loss_fp: 0.500043, loss_freq: 0.500014
[12:24:47.897] iteration 2859: loss: 0.209757, loss_s1: 0.095508, loss_fp: 0.002308, loss_freq: 0.022793
[12:24:48.515] iteration 2860: loss: 0.232762, loss_s1: 0.154591, loss_fp: 0.000985, loss_freq: 0.045445
[12:24:49.522] iteration 2861: loss: 0.253502, loss_s1: 0.116182, loss_fp: 0.001530, loss_freq: 0.004791
[12:24:50.181] iteration 2862: loss: 0.172725, loss_s1: 0.010460, loss_fp: 0.008207, loss_freq: 0.005044
[12:24:50.837] iteration 2863: loss: 0.652986, loss_s1: 0.048808, loss_fp: 0.500000, loss_freq: 0.500004
[12:24:51.484] iteration 2864: loss: 0.210796, loss_s1: 0.011595, loss_fp: 0.009452, loss_freq: 0.002455
[12:24:52.120] iteration 2865: loss: 0.275391, loss_s1: 0.084003, loss_fp: 0.001204, loss_freq: 0.110470
[12:24:52.741] iteration 2866: loss: 0.206747, loss_s1: 0.046448, loss_fp: 0.001633, loss_freq: 0.041098
[12:24:53.359] iteration 2867: loss: 0.145990, loss_s1: 0.068721, loss_fp: 0.001124, loss_freq: 0.003288
[12:24:53.981] iteration 2868: loss: 0.358457, loss_s1: 0.205767, loss_fp: 0.013515, loss_freq: 0.041389
[12:24:54.670] iteration 2869: loss: 0.163505, loss_s1: 0.065326, loss_fp: 0.000803, loss_freq: 0.016193
[12:24:55.458] iteration 2870: loss: 0.426535, loss_s1: 0.140685, loss_fp: 0.001554, loss_freq: 0.070805
[12:24:56.177] iteration 2871: loss: 0.158528, loss_s1: 0.045343, loss_fp: 0.001999, loss_freq: 0.010367
[12:24:56.801] iteration 2872: loss: 0.233217, loss_s1: 0.158396, loss_fp: 0.000910, loss_freq: 0.008145
[12:24:57.414] iteration 2873: loss: 0.242557, loss_s1: 0.131760, loss_fp: 0.001381, loss_freq: 0.003872
[12:24:58.027] iteration 2874: loss: 0.144867, loss_s1: 0.033491, loss_fp: 0.004420, loss_freq: 0.000861
[12:24:58.638] iteration 2875: loss: 0.267536, loss_s1: 0.130964, loss_fp: 0.000525, loss_freq: 0.004036
[12:24:59.252] iteration 2876: loss: 0.384608, loss_s1: 0.382879, loss_fp: 0.038278, loss_freq: 0.001019
[12:24:59.864] iteration 2877: loss: 0.352674, loss_s1: 0.065608, loss_fp: 0.000884, loss_freq: 0.008178
[12:25:00.502] iteration 2878: loss: 0.998859, loss_s1: 0.500537, loss_fp: 0.499995, loss_freq: 0.500041
[12:25:01.122] iteration 2879: loss: 0.755405, loss_s1: 0.188604, loss_fp: 0.500003, loss_freq: 0.499994
[12:25:01.736] iteration 2880: loss: 0.906823, loss_s1: 0.500000, loss_fp: 0.500000, loss_freq: 0.499997
[12:25:02.348] iteration 2881: loss: 0.196671, loss_s1: 0.041386, loss_fp: 0.004034, loss_freq: 0.001918
[12:25:02.973] iteration 2882: loss: 0.151510, loss_s1: 0.004758, loss_fp: 0.005414, loss_freq: 0.001290
[12:25:03.592] iteration 2883: loss: 0.158265, loss_s1: 0.049544, loss_fp: 0.001042, loss_freq: 0.001324
[12:25:04.215] iteration 2884: loss: 0.497871, loss_s1: 0.127297, loss_fp: 0.240892, loss_freq: 0.265375
[12:25:04.839] iteration 2885: loss: 0.177593, loss_s1: 0.108204, loss_fp: 0.001139, loss_freq: 0.001067
[12:25:05.456] iteration 2886: loss: 0.970176, loss_s1: 0.500042, loss_fp: 0.500000, loss_freq: 0.500002
[12:25:06.077] iteration 2887: loss: 0.206218, loss_s1: 0.012145, loss_fp: 0.001136, loss_freq: 0.002093
[12:25:06.698] iteration 2888: loss: 0.167937, loss_s1: 0.043910, loss_fp: 0.004737, loss_freq: 0.009452
[12:25:07.323] iteration 2889: loss: 0.339174, loss_s1: 0.015586, loss_fp: 0.001386, loss_freq: 0.055177
[12:25:07.938] iteration 2890: loss: 0.575483, loss_s1: 0.381428, loss_fp: 0.001378, loss_freq: 0.278847
[12:25:08.555] iteration 2891: loss: 0.295773, loss_s1: 0.196774, loss_fp: 0.002107, loss_freq: 0.025142
[12:25:09.173] iteration 2892: loss: 0.394388, loss_s1: 0.362129, loss_fp: 0.001638, loss_freq: 0.003114
[12:25:09.782] iteration 2893: loss: 0.275225, loss_s1: 0.137028, loss_fp: 0.001144, loss_freq: 0.012922
[12:25:10.409] iteration 2894: loss: 0.325269, loss_s1: 0.321420, loss_fp: 0.002713, loss_freq: 0.039508
[12:25:11.027] iteration 2895: loss: 0.237180, loss_s1: 0.072015, loss_fp: 0.000928, loss_freq: 0.002491
[12:25:11.644] iteration 2896: loss: 0.262002, loss_s1: 0.147385, loss_fp: 0.001078, loss_freq: 0.009380
[12:25:12.258] iteration 2897: loss: 0.248025, loss_s1: 0.170011, loss_fp: 0.004209, loss_freq: 0.005586
[12:25:12.875] iteration 2898: loss: 0.139311, loss_s1: 0.037133, loss_fp: 0.001369, loss_freq: 0.001117
[12:25:13.501] iteration 2899: loss: 0.430835, loss_s1: 0.149657, loss_fp: 0.001260, loss_freq: 0.251959
[12:25:14.151] iteration 2900: loss: 0.191801, loss_s1: 0.048353, loss_fp: 0.001427, loss_freq: 0.001688
[12:25:14.798] iteration 2901: loss: 0.225763, loss_s1: 0.116818, loss_fp: 0.001629, loss_freq: 0.020271
[12:25:15.439] iteration 2902: loss: 0.141343, loss_s1: 0.012131, loss_fp: 0.000533, loss_freq: 0.000651
[12:25:16.069] iteration 2903: loss: 0.280803, loss_s1: 0.090583, loss_fp: 0.000822, loss_freq: 0.054164
[12:25:16.706] iteration 2904: loss: 0.159004, loss_s1: 0.033445, loss_fp: 0.001166, loss_freq: 0.052908
[12:25:17.338] iteration 2905: loss: 1.109853, loss_s1: 0.421367, loss_fp: 0.499999, loss_freq: 0.500052
[12:25:17.959] iteration 2906: loss: 0.218114, loss_s1: 0.140991, loss_fp: 0.002114, loss_freq: 0.002628
[12:25:18.583] iteration 2907: loss: 0.295977, loss_s1: 0.204010, loss_fp: 0.003929, loss_freq: 0.000958
[12:25:19.200] iteration 2908: loss: 0.360576, loss_s1: 0.181639, loss_fp: 0.000521, loss_freq: 0.001304
[12:25:19.838] iteration 2909: loss: 0.178540, loss_s1: 0.040702, loss_fp: 0.001049, loss_freq: 0.000735
[12:25:20.487] iteration 2910: loss: 0.346159, loss_s1: 0.175166, loss_fp: 0.000700, loss_freq: 0.003325
[12:25:21.147] iteration 2911: loss: 0.237504, loss_s1: 0.034459, loss_fp: 0.006178, loss_freq: 0.002866
[12:25:21.802] iteration 2912: loss: 0.372327, loss_s1: 0.185151, loss_fp: 0.001109, loss_freq: 0.001005
[12:25:22.444] iteration 2913: loss: 0.556509, loss_s1: 0.479284, loss_fp: 0.004736, loss_freq: 0.236716
[12:25:23.071] iteration 2914: loss: 0.303803, loss_s1: 0.278923, loss_fp: 0.004341, loss_freq: 0.001954
[12:25:23.691] iteration 2915: loss: 0.189368, loss_s1: 0.105282, loss_fp: 0.002601, loss_freq: 0.001218
[12:25:24.309] iteration 2916: loss: 0.249916, loss_s1: 0.064257, loss_fp: 0.001962, loss_freq: 0.079194
[12:25:24.955] iteration 2917: loss: 0.321522, loss_s1: 0.287508, loss_fp: 0.002146, loss_freq: 0.007752
[12:25:25.587] iteration 2918: loss: 0.156065, loss_s1: 0.091971, loss_fp: 0.000688, loss_freq: 0.022033
[12:25:26.223] iteration 2919: loss: 0.286059, loss_s1: 0.163591, loss_fp: 0.004194, loss_freq: 0.012280
[12:25:26.854] iteration 2920: loss: 0.910331, loss_s1: 0.500687, loss_fp: 0.499996, loss_freq: 0.500058
[12:25:27.497] iteration 2921: loss: 0.212938, loss_s1: 0.052304, loss_fp: 0.001416, loss_freq: 0.007017
[12:25:28.132] iteration 2922: loss: 0.241818, loss_s1: 0.033595, loss_fp: 0.000565, loss_freq: 0.061914
[12:25:28.763] iteration 2923: loss: 0.407964, loss_s1: 0.404667, loss_fp: 0.003102, loss_freq: 0.112520
[12:25:29.393] iteration 2924: loss: 0.433020, loss_s1: 0.016702, loss_fp: 0.002218, loss_freq: 0.385048
[12:25:30.052] iteration 2925: loss: 0.200473, loss_s1: 0.009050, loss_fp: 0.000799, loss_freq: 0.016471
[12:25:30.718] iteration 2926: loss: 0.155932, loss_s1: 0.003366, loss_fp: 0.001778, loss_freq: 0.001528
[12:25:31.371] iteration 2927: loss: 0.191330, loss_s1: 0.007866, loss_fp: 0.002033, loss_freq: 0.106694
[12:25:32.020] iteration 2928: loss: 0.874488, loss_s1: 0.441053, loss_fp: 0.499999, loss_freq: 0.500113
[12:25:32.676] iteration 2929: loss: 0.149334, loss_s1: 0.029955, loss_fp: 0.001332, loss_freq: 0.002967
[12:25:33.335] iteration 2930: loss: 0.985462, loss_s1: 0.491070, loss_fp: 0.499997, loss_freq: 0.499996
[12:25:33.989] iteration 2931: loss: 0.242749, loss_s1: 0.068335, loss_fp: 0.068404, loss_freq: 0.003042
[12:25:34.615] iteration 2932: loss: 0.757715, loss_s1: 0.200063, loss_fp: 0.499999, loss_freq: 0.499960
[12:25:35.237] iteration 2933: loss: 0.384262, loss_s1: 0.500014, loss_fp: 0.029130, loss_freq: 0.027153
[12:25:35.860] iteration 2934: loss: 0.932474, loss_s1: 0.500135, loss_fp: 0.500174, loss_freq: 0.500010
[12:25:36.478] iteration 2935: loss: 0.377522, loss_s1: 0.170144, loss_fp: 0.003941, loss_freq: 0.225435
[12:25:37.102] iteration 2936: loss: 0.408792, loss_s1: 0.500042, loss_fp: 0.032657, loss_freq: 0.004562
[12:25:37.733] iteration 2937: loss: 0.165603, loss_s1: 0.037775, loss_fp: 0.001808, loss_freq: 0.000465
[12:25:38.353] iteration 2938: loss: 0.337795, loss_s1: 0.140441, loss_fp: 0.002087, loss_freq: 0.161473
[12:25:38.974] iteration 2939: loss: 0.482939, loss_s1: 0.497019, loss_fp: 0.082249, loss_freq: 0.227563
[12:25:39.601] iteration 2940: loss: 1.192899, loss_s1: 0.500011, loss_fp: 0.499996, loss_freq: 0.499980
[12:25:40.216] iteration 2941: loss: 1.008435, loss_s1: 0.499996, loss_fp: 0.500188, loss_freq: 0.499993
[12:25:40.833] iteration 2942: loss: 1.139360, loss_s1: 0.499998, loss_fp: 0.500211, loss_freq: 0.499999
[12:25:41.443] iteration 2943: loss: 1.089254, loss_s1: 0.499997, loss_fp: 0.499999, loss_freq: 0.499996
[12:25:42.065] iteration 2944: loss: 1.013157, loss_s1: 0.500022, loss_fp: 0.500130, loss_freq: 0.499998
[12:25:42.685] iteration 2945: loss: 1.034083, loss_s1: 0.500029, loss_fp: 0.500002, loss_freq: 0.500004
[12:25:43.305] iteration 2946: loss: 1.077717, loss_s1: 0.500370, loss_fp: 0.499991, loss_freq: 0.500018
[12:25:43.926] iteration 2947: loss: 1.012536, loss_s1: 0.500185, loss_fp: 0.499993, loss_freq: 0.499986
[12:25:44.558] iteration 2948: loss: 0.994033, loss_s1: 0.500045, loss_fp: 0.499992, loss_freq: 0.499992
[12:25:45.177] iteration 2949: loss: 0.995142, loss_s1: 0.500192, loss_fp: 0.499994, loss_freq: 0.499997
[12:25:45.800] iteration 2950: loss: 0.902925, loss_s1: 0.500836, loss_fp: 0.500003, loss_freq: 0.499961
[12:25:46.420] iteration 2951: loss: 0.921552, loss_s1: 0.500102, loss_fp: 0.499995, loss_freq: 0.500011
[12:25:47.048] iteration 2952: loss: 0.968056, loss_s1: 0.500291, loss_fp: 0.499965, loss_freq: 0.500094
[12:25:47.706] iteration 2953: loss: 0.880077, loss_s1: 0.500037, loss_fp: 0.499994, loss_freq: 0.499995
[12:25:48.364] iteration 2954: loss: 1.007427, loss_s1: 0.500228, loss_fp: 0.499997, loss_freq: 0.500004
[12:25:49.008] iteration 2955: loss: 0.899219, loss_s1: 0.500187, loss_fp: 0.499987, loss_freq: 0.499974
[12:25:49.623] iteration 2956: loss: 0.963415, loss_s1: 0.500081, loss_fp: 0.500000, loss_freq: 0.500001
[12:25:50.250] iteration 2957: loss: 0.966013, loss_s1: 0.500140, loss_fp: 0.500002, loss_freq: 0.500471
[12:25:50.874] iteration 2958: loss: 0.798244, loss_s1: 0.498745, loss_fp: 0.351185, loss_freq: 0.449396
[12:25:51.517] iteration 2959: loss: 0.363313, loss_s1: 0.004233, loss_fp: 0.000800, loss_freq: 0.015289
[12:25:52.202] iteration 2960: loss: 0.369824, loss_s1: 0.209973, loss_fp: 0.008939, loss_freq: 0.017781
[12:25:52.854] iteration 2961: loss: 0.906744, loss_s1: 0.500021, loss_fp: 0.499997, loss_freq: 0.499998
[12:25:53.513] iteration 2962: loss: 0.946496, loss_s1: 0.500004, loss_fp: 0.500004, loss_freq: 0.499998
[12:25:54.170] iteration 2963: loss: 0.959636, loss_s1: 0.500002, loss_fp: 0.500005, loss_freq: 0.499994
[12:25:54.826] iteration 2964: loss: 0.895805, loss_s1: 0.499999, loss_fp: 0.499997, loss_freq: 0.499996
[12:25:55.480] iteration 2965: loss: 1.065837, loss_s1: 0.500001, loss_fp: 0.500000, loss_freq: 0.499994
[12:25:56.141] iteration 2966: loss: 0.962123, loss_s1: 0.500000, loss_fp: 0.499995, loss_freq: 0.499993
[12:25:56.772] iteration 2967: loss: 0.919205, loss_s1: 0.500027, loss_fp: 0.499998, loss_freq: 0.500003
[12:25:57.392] iteration 2968: loss: 0.919417, loss_s1: 0.500004, loss_fp: 0.499998, loss_freq: 0.499994
[12:25:58.019] iteration 2969: loss: 0.991340, loss_s1: 0.500210, loss_fp: 0.499991, loss_freq: 0.499999
[12:25:58.642] iteration 2970: loss: 0.952935, loss_s1: 0.502203, loss_fp: 0.500011, loss_freq: 0.500035
[12:25:59.261] iteration 2971: loss: 0.963114, loss_s1: 0.500263, loss_fp: 0.499999, loss_freq: 0.500617
[12:25:59.872] iteration 2972: loss: 0.866148, loss_s1: 0.500756, loss_fp: 0.499987, loss_freq: 0.500605
[12:26:00.490] iteration 2973: loss: 0.940613, loss_s1: 0.501652, loss_fp: 0.499998, loss_freq: 0.500291
[12:26:01.111] iteration 2974: loss: 0.858024, loss_s1: 0.500779, loss_fp: 0.500006, loss_freq: 0.500270
[12:26:01.733] iteration 2975: loss: 1.072994, loss_s1: 0.503208, loss_fp: 0.500008, loss_freq: 0.503968
[12:26:02.386] iteration 2976: loss: 0.904722, loss_s1: 0.502234, loss_fp: 0.500004, loss_freq: 0.500794
[12:26:03.046] iteration 2977: loss: 0.931361, loss_s1: 0.503058, loss_fp: 0.499997, loss_freq: 0.500585
[12:26:03.701] iteration 2978: loss: 0.958001, loss_s1: 0.503604, loss_fp: 0.499998, loss_freq: 0.502398
[12:26:04.331] iteration 2979: loss: 0.850858, loss_s1: 0.501414, loss_fp: 0.499998, loss_freq: 0.500892
[12:26:04.955] iteration 2980: loss: 0.985021, loss_s1: 0.502038, loss_fp: 0.500000, loss_freq: 0.500871
[12:26:05.574] iteration 2981: loss: 0.484338, loss_s1: 0.490798, loss_fp: 0.006698, loss_freq: 0.084271
[12:26:06.190] iteration 2982: loss: 1.040475, loss_s1: 0.500247, loss_fp: 0.499998, loss_freq: 0.500302
[12:26:06.817] iteration 2983: loss: 0.406264, loss_s1: 0.383219, loss_fp: 0.005384, loss_freq: 0.005702
[12:26:07.442] iteration 2984: loss: 0.360301, loss_s1: 0.373579, loss_fp: 0.041688, loss_freq: 0.001482
[12:26:08.065] iteration 2985: loss: 0.931193, loss_s1: 0.500738, loss_fp: 0.500015, loss_freq: 0.500004
[12:26:08.687] iteration 2986: loss: 0.237773, loss_s1: 0.120565, loss_fp: 0.010401, loss_freq: 0.008384
[12:26:09.309] iteration 2987: loss: 0.328984, loss_s1: 0.208107, loss_fp: 0.001314, loss_freq: 0.064015
[12:26:09.920] iteration 2988: loss: 0.297227, loss_s1: 0.163271, loss_fp: 0.187982, loss_freq: 0.013207
[12:26:10.546] iteration 2989: loss: 0.900689, loss_s1: 0.457313, loss_fp: 0.500009, loss_freq: 0.500030
[12:26:11.163] iteration 2990: loss: 0.909301, loss_s1: 0.371056, loss_fp: 0.500019, loss_freq: 0.499993
[12:26:11.782] iteration 2991: loss: 0.334266, loss_s1: 0.212003, loss_fp: 0.000751, loss_freq: 0.000595
[12:26:12.395] iteration 2992: loss: 1.037354, loss_s1: 0.452404, loss_fp: 0.499998, loss_freq: 0.499999
[12:26:13.008] iteration 2993: loss: 0.275090, loss_s1: 0.217452, loss_fp: 0.077341, loss_freq: 0.002567
[12:26:13.619] iteration 2994: loss: 0.599373, loss_s1: 0.221682, loss_fp: 0.000735, loss_freq: 0.279447
[12:26:14.236] iteration 2995: loss: 0.452304, loss_s1: 0.079824, loss_fp: 0.002064, loss_freq: 0.427961
[12:26:14.852] iteration 2996: loss: 0.180586, loss_s1: 0.078505, loss_fp: 0.000757, loss_freq: 0.006412
[12:26:15.470] iteration 2997: loss: 0.226865, loss_s1: 0.183939, loss_fp: 0.001804, loss_freq: 0.000911
[12:26:16.089] iteration 2998: loss: 0.225674, loss_s1: 0.110956, loss_fp: 0.001137, loss_freq: 0.003936
[12:26:16.771] iteration 2999: loss: 0.213896, loss_s1: 0.111394, loss_fp: 0.001263, loss_freq: 0.013932
[12:26:17.423] iteration 3000: loss: 0.343913, loss_s1: 0.217168, loss_fp: 0.000727, loss_freq: 0.000701
[12:26:20.623] iteration 3000 : mean_dice : 0.361642
[12:26:21.270] iteration 3001: loss: 0.134417, loss_s1: 0.005888, loss_fp: 0.001359, loss_freq: 0.001104
[12:26:21.883] iteration 3002: loss: 0.331894, loss_s1: 0.291538, loss_fp: 0.008033, loss_freq: 0.082769
[12:26:22.503] iteration 3003: loss: 0.149909, loss_s1: 0.063740, loss_fp: 0.001244, loss_freq: 0.001820
[12:26:23.437] iteration 3004: loss: 0.232288, loss_s1: 0.149686, loss_fp: 0.000857, loss_freq: 0.001576
[12:26:24.082] iteration 3005: loss: 0.898992, loss_s1: 0.500003, loss_fp: 0.499977, loss_freq: 0.499997
[12:26:24.731] iteration 3006: loss: 0.602167, loss_s1: 0.012919, loss_fp: 0.499984, loss_freq: 0.500002
[12:26:25.385] iteration 3007: loss: 0.467054, loss_s1: 0.414085, loss_fp: 0.006020, loss_freq: 0.023517
[12:26:26.034] iteration 3008: loss: 0.252224, loss_s1: 0.153355, loss_fp: 0.001415, loss_freq: 0.021790
[12:26:26.694] iteration 3009: loss: 0.283407, loss_s1: 0.117773, loss_fp: 0.001058, loss_freq: 0.125560
[12:26:27.356] iteration 3010: loss: 0.159980, loss_s1: 0.044246, loss_fp: 0.000843, loss_freq: 0.000365
[12:26:27.997] iteration 3011: loss: 0.430040, loss_s1: 0.256395, loss_fp: 0.001488, loss_freq: 0.056428
[12:26:28.615] iteration 3012: loss: 0.214314, loss_s1: 0.194070, loss_fp: 0.001931, loss_freq: 0.000696
[12:26:29.227] iteration 3013: loss: 0.434750, loss_s1: 0.076505, loss_fp: 0.001013, loss_freq: 0.007227
[12:26:29.842] iteration 3014: loss: 0.201288, loss_s1: 0.106250, loss_fp: 0.000673, loss_freq: 0.000646
[12:26:30.469] iteration 3015: loss: 0.464420, loss_s1: 0.492030, loss_fp: 0.000646, loss_freq: 0.067917
[12:26:31.115] iteration 3016: loss: 0.294112, loss_s1: 0.122352, loss_fp: 0.000654, loss_freq: 0.004825
[12:26:31.792] iteration 3017: loss: 0.150526, loss_s1: 0.087585, loss_fp: 0.001207, loss_freq: 0.001000
[12:26:32.458] iteration 3018: loss: 0.279746, loss_s1: 0.144952, loss_fp: 0.001343, loss_freq: 0.000705
[12:26:33.102] iteration 3019: loss: 0.250955, loss_s1: 0.154001, loss_fp: 0.000750, loss_freq: 0.001548
[12:26:33.726] iteration 3020: loss: 0.320714, loss_s1: 0.066767, loss_fp: 0.000590, loss_freq: 0.003642
[12:26:34.357] iteration 3021: loss: 0.325335, loss_s1: 0.127718, loss_fp: 0.005650, loss_freq: 0.064792
[12:26:35.034] iteration 3022: loss: 0.146566, loss_s1: 0.017204, loss_fp: 0.001038, loss_freq: 0.001021
[12:26:35.690] iteration 3023: loss: 0.195470, loss_s1: 0.009268, loss_fp: 0.000801, loss_freq: 0.043363
[12:26:36.344] iteration 3024: loss: 0.303818, loss_s1: 0.085816, loss_fp: 0.000973, loss_freq: 0.032095
[12:26:37.002] iteration 3025: loss: 0.158115, loss_s1: 0.002606, loss_fp: 0.000375, loss_freq: 0.000823
[12:26:37.642] iteration 3026: loss: 0.799965, loss_s1: 0.384897, loss_fp: 0.500000, loss_freq: 0.500003
[12:26:38.257] iteration 3027: loss: 0.224077, loss_s1: 0.054407, loss_fp: 0.001592, loss_freq: 0.001765
[12:26:38.884] iteration 3028: loss: 0.143887, loss_s1: 0.026362, loss_fp: 0.000593, loss_freq: 0.000603
[12:26:39.498] iteration 3029: loss: 0.391114, loss_s1: 0.424546, loss_fp: 0.037841, loss_freq: 0.018077
[12:26:40.106] iteration 3030: loss: 0.272491, loss_s1: 0.090725, loss_fp: 0.000721, loss_freq: 0.076172
[12:26:40.743] iteration 3031: loss: 0.175434, loss_s1: 0.095578, loss_fp: 0.000920, loss_freq: 0.001652
[12:26:41.353] iteration 3032: loss: 0.400970, loss_s1: 0.211929, loss_fp: 0.000951, loss_freq: 0.023199
[12:26:41.967] iteration 3033: loss: 0.433052, loss_s1: 0.311089, loss_fp: 0.000939, loss_freq: 0.005318
[12:26:42.594] iteration 3034: loss: 0.193154, loss_s1: 0.037248, loss_fp: 0.000691, loss_freq: 0.009504
[12:26:43.212] iteration 3035: loss: 0.146820, loss_s1: 0.057349, loss_fp: 0.000978, loss_freq: 0.000605
[12:26:43.837] iteration 3036: loss: 0.196547, loss_s1: 0.016970, loss_fp: 0.000523, loss_freq: 0.000834
[12:26:44.450] iteration 3037: loss: 0.373630, loss_s1: 0.346344, loss_fp: 0.001334, loss_freq: 0.038683
[12:26:45.066] iteration 3038: loss: 0.434108, loss_s1: 0.299094, loss_fp: 0.000589, loss_freq: 0.002500
[12:26:45.682] iteration 3039: loss: 0.277446, loss_s1: 0.146712, loss_fp: 0.001015, loss_freq: 0.001032
[12:26:46.297] iteration 3040: loss: 0.289673, loss_s1: 0.267460, loss_fp: 0.001992, loss_freq: 0.041703
[12:26:46.916] iteration 3041: loss: 0.172225, loss_s1: 0.077218, loss_fp: 0.000668, loss_freq: 0.001954
[12:26:47.567] iteration 3042: loss: 0.261926, loss_s1: 0.052286, loss_fp: 0.000653, loss_freq: 0.009553
[12:26:48.177] iteration 3043: loss: 0.216818, loss_s1: 0.011484, loss_fp: 0.000982, loss_freq: 0.001017
[12:26:48.795] iteration 3044: loss: 0.262357, loss_s1: 0.080602, loss_fp: 0.002353, loss_freq: 0.061272
[12:26:49.418] iteration 3045: loss: 0.171596, loss_s1: 0.088870, loss_fp: 0.000958, loss_freq: 0.009377
[12:26:50.134] iteration 3046: loss: 0.218481, loss_s1: 0.008006, loss_fp: 0.000761, loss_freq: 0.000576
[12:26:50.783] iteration 3047: loss: 0.188280, loss_s1: 0.126913, loss_fp: 0.000639, loss_freq: 0.002487
[12:26:51.433] iteration 3048: loss: 1.006365, loss_s1: 0.286301, loss_fp: 0.499998, loss_freq: 0.500503
[12:26:52.054] iteration 3049: loss: 0.203067, loss_s1: 0.047902, loss_fp: 0.002213, loss_freq: 0.003876
[12:26:52.675] iteration 3050: loss: 0.189296, loss_s1: 0.007142, loss_fp: 0.001156, loss_freq: 0.007099
[12:26:53.293] iteration 3051: loss: 0.310642, loss_s1: 0.073173, loss_fp: 0.001047, loss_freq: 0.097540
[12:26:53.918] iteration 3052: loss: 0.153208, loss_s1: 0.020126, loss_fp: 0.001459, loss_freq: 0.000788
[12:26:54.558] iteration 3053: loss: 0.217677, loss_s1: 0.023490, loss_fp: 0.000832, loss_freq: 0.017497
[12:26:55.207] iteration 3054: loss: 0.182228, loss_s1: 0.010559, loss_fp: 0.000883, loss_freq: 0.000962
[12:26:55.861] iteration 3055: loss: 0.341863, loss_s1: 0.132314, loss_fp: 0.018573, loss_freq: 0.006767
[12:26:56.513] iteration 3056: loss: 0.278808, loss_s1: 0.161581, loss_fp: 0.003928, loss_freq: 0.006401
[12:26:57.164] iteration 3057: loss: 0.221398, loss_s1: 0.137203, loss_fp: 0.000602, loss_freq: 0.001903
[12:26:57.801] iteration 3058: loss: 0.195373, loss_s1: 0.145836, loss_fp: 0.000640, loss_freq: 0.014925
[12:26:58.410] iteration 3059: loss: 0.184590, loss_s1: 0.002151, loss_fp: 0.000480, loss_freq: 0.000691
[12:26:59.031] iteration 3060: loss: 0.169608, loss_s1: 0.018022, loss_fp: 0.002532, loss_freq: 0.017496
[12:26:59.896] iteration 3061: loss: 0.149599, loss_s1: 0.098940, loss_fp: 0.000833, loss_freq: 0.036882
[12:27:00.931] iteration 3062: loss: 0.260170, loss_s1: 0.103737, loss_fp: 0.001015, loss_freq: 0.053776
[12:27:01.811] iteration 3063: loss: 0.182358, loss_s1: 0.059522, loss_fp: 0.000792, loss_freq: 0.058235
[12:27:02.463] iteration 3064: loss: 0.170152, loss_s1: 0.016445, loss_fp: 0.000768, loss_freq: 0.012952
[12:27:03.111] iteration 3065: loss: 0.273017, loss_s1: 0.146380, loss_fp: 0.001197, loss_freq: 0.005793
[12:27:03.732] iteration 3066: loss: 0.719663, loss_s1: 0.493131, loss_fp: 0.271139, loss_freq: 0.417089
[12:27:04.356] iteration 3067: loss: 0.324760, loss_s1: 0.171276, loss_fp: 0.001108, loss_freq: 0.029109
[12:27:04.982] iteration 3068: loss: 0.229182, loss_s1: 0.023706, loss_fp: 0.004055, loss_freq: 0.007178
[12:27:05.596] iteration 3069: loss: 0.193221, loss_s1: 0.011876, loss_fp: 0.055518, loss_freq: 0.003562
[12:27:06.223] iteration 3070: loss: 0.895515, loss_s1: 0.500047, loss_fp: 0.499943, loss_freq: 0.500055
[12:27:06.867] iteration 3071: loss: 0.952194, loss_s1: 0.500136, loss_fp: 0.500001, loss_freq: 0.500057
[12:27:07.526] iteration 3072: loss: 0.221299, loss_s1: 0.037768, loss_fp: 0.001037, loss_freq: 0.083178
[12:27:08.179] iteration 3073: loss: 0.309346, loss_s1: 0.019262, loss_fp: 0.019620, loss_freq: 0.021978
[12:27:08.828] iteration 3074: loss: 1.010191, loss_s1: 0.498587, loss_fp: 0.499993, loss_freq: 0.500003
[12:27:09.478] iteration 3075: loss: 0.290799, loss_s1: 0.124542, loss_fp: 0.004637, loss_freq: 0.006448
[12:27:10.114] iteration 3076: loss: 0.312945, loss_s1: 0.219069, loss_fp: 0.000798, loss_freq: 0.105827
[12:27:10.737] iteration 3077: loss: 0.840997, loss_s1: 0.242092, loss_fp: 0.500001, loss_freq: 0.499998
[12:27:11.353] iteration 3078: loss: 0.935424, loss_s1: 0.500199, loss_fp: 0.500162, loss_freq: 0.500049
[12:27:11.973] iteration 3079: loss: 0.936872, loss_s1: 0.496379, loss_fp: 0.500000, loss_freq: 0.499996
[12:27:12.588] iteration 3080: loss: 0.220035, loss_s1: 0.173231, loss_fp: 0.006024, loss_freq: 0.002187
[12:27:13.209] iteration 3081: loss: 0.400492, loss_s1: 0.447098, loss_fp: 0.001857, loss_freq: 0.023705
[12:27:13.821] iteration 3082: loss: 0.880215, loss_s1: 0.500807, loss_fp: 0.499999, loss_freq: 0.500180
[12:27:14.434] iteration 3083: loss: 0.478267, loss_s1: 0.213264, loss_fp: 0.004868, loss_freq: 0.022267
[12:27:15.051] iteration 3084: loss: 0.157670, loss_s1: 0.076529, loss_fp: 0.001441, loss_freq: 0.002226
[12:27:15.730] iteration 3085: loss: 0.963793, loss_s1: 0.500228, loss_fp: 0.500013, loss_freq: 0.500285
[12:27:16.386] iteration 3086: loss: 0.637814, loss_s1: 0.411098, loss_fp: 0.006315, loss_freq: 0.099749
[12:27:17.042] iteration 3087: loss: 0.487798, loss_s1: 0.415300, loss_fp: 0.007623, loss_freq: 0.032540
[12:27:17.706] iteration 3088: loss: 1.070427, loss_s1: 0.500105, loss_fp: 0.499999, loss_freq: 0.499987
[12:27:18.341] iteration 3089: loss: 0.318860, loss_s1: 0.098651, loss_fp: 0.003391, loss_freq: 0.065734
[12:27:18.955] iteration 3090: loss: 0.932914, loss_s1: 0.469255, loss_fp: 0.385282, loss_freq: 0.450545
[12:27:19.575] iteration 3091: loss: 0.509743, loss_s1: 0.360608, loss_fp: 0.001973, loss_freq: 0.008816
[12:27:20.196] iteration 3092: loss: 0.982718, loss_s1: 0.500015, loss_fp: 0.500006, loss_freq: 0.499995
[12:27:20.810] iteration 3093: loss: 0.993620, loss_s1: 0.499997, loss_fp: 0.499991, loss_freq: 0.499974
[12:27:21.424] iteration 3094: loss: 0.963571, loss_s1: 0.500000, loss_fp: 0.499995, loss_freq: 0.499994
[12:27:22.042] iteration 3095: loss: 0.963172, loss_s1: 0.500000, loss_fp: 0.499995, loss_freq: 0.499999
[12:27:22.666] iteration 3096: loss: 0.930972, loss_s1: 0.500000, loss_fp: 0.499989, loss_freq: 0.499999
[12:27:23.292] iteration 3097: loss: 0.973421, loss_s1: 0.500003, loss_fp: 0.499988, loss_freq: 0.500000
[12:27:23.912] iteration 3098: loss: 0.923596, loss_s1: 0.500010, loss_fp: 0.500009, loss_freq: 0.499997
[12:27:24.535] iteration 3099: loss: 0.983591, loss_s1: 0.500004, loss_fp: 0.499994, loss_freq: 0.500005
[12:27:25.159] iteration 3100: loss: 0.984820, loss_s1: 0.500001, loss_fp: 0.500000, loss_freq: 0.500006
[12:27:25.780] iteration 3101: loss: 0.936286, loss_s1: 0.500011, loss_fp: 0.499998, loss_freq: 0.500005
[12:27:26.400] iteration 3102: loss: 1.101523, loss_s1: 0.500007, loss_fp: 0.500009, loss_freq: 0.500000
[12:27:27.020] iteration 3103: loss: 1.002577, loss_s1: 0.500004, loss_fp: 0.499993, loss_freq: 0.499999
[12:27:27.644] iteration 3104: loss: 0.950132, loss_s1: 0.500003, loss_fp: 0.500012, loss_freq: 0.500005
[12:27:28.269] iteration 3105: loss: 0.948101, loss_s1: 0.500006, loss_fp: 0.500000, loss_freq: 0.499998
[12:27:28.895] iteration 3106: loss: 0.960012, loss_s1: 0.500000, loss_fp: 0.500010, loss_freq: 0.499993
[12:27:29.522] iteration 3107: loss: 0.962455, loss_s1: 0.500029, loss_fp: 0.500002, loss_freq: 0.499997
[12:27:30.155] iteration 3108: loss: 1.002494, loss_s1: 0.500003, loss_fp: 0.500018, loss_freq: 0.499996
[12:27:30.771] iteration 3109: loss: 0.970706, loss_s1: 0.499997, loss_fp: 0.500005, loss_freq: 0.499991
[12:27:31.388] iteration 3110: loss: 0.937331, loss_s1: 0.500105, loss_fp: 0.500004, loss_freq: 0.499998
[12:27:32.005] iteration 3111: loss: 0.905560, loss_s1: 0.500001, loss_fp: 0.499993, loss_freq: 0.499985
[12:27:32.629] iteration 3112: loss: 1.000358, loss_s1: 0.500001, loss_fp: 0.500003, loss_freq: 0.499992
[12:27:33.252] iteration 3113: loss: 0.914908, loss_s1: 0.499997, loss_fp: 0.500003, loss_freq: 0.499989
[12:27:33.875] iteration 3114: loss: 0.937688, loss_s1: 0.500002, loss_fp: 0.500020, loss_freq: 0.499986
[12:27:34.548] iteration 3115: loss: 0.889259, loss_s1: 0.499997, loss_fp: 0.500004, loss_freq: 0.499991
[12:27:35.205] iteration 3116: loss: 0.888091, loss_s1: 0.499995, loss_fp: 0.500002, loss_freq: 0.499987
[12:27:35.859] iteration 3117: loss: 0.866675, loss_s1: 0.500004, loss_fp: 0.500002, loss_freq: 0.499980
[12:27:36.515] iteration 3118: loss: 1.073768, loss_s1: 0.499994, loss_fp: 0.500000, loss_freq: 0.499991
[12:27:37.167] iteration 3119: loss: 0.886508, loss_s1: 0.500025, loss_fp: 0.499997, loss_freq: 0.499976
[12:27:37.811] iteration 3120: loss: 0.961572, loss_s1: 0.499999, loss_fp: 0.500003, loss_freq: 0.499996
[12:27:38.442] iteration 3121: loss: 1.003080, loss_s1: 0.500008, loss_fp: 0.500003, loss_freq: 0.500000
[12:27:39.056] iteration 3122: loss: 0.220598, loss_s1: 0.160245, loss_fp: 0.011409, loss_freq: 0.010579
[12:27:39.668] iteration 3123: loss: 1.001985, loss_s1: 0.500181, loss_fp: 0.500009, loss_freq: 0.500005
[12:27:40.292] iteration 3124: loss: 0.213374, loss_s1: 0.026912, loss_fp: 0.002533, loss_freq: 0.003698
[12:27:40.911] iteration 3125: loss: 1.066459, loss_s1: 0.500233, loss_fp: 0.500002, loss_freq: 0.500002
[12:27:41.530] iteration 3126: loss: 0.927722, loss_s1: 0.500107, loss_fp: 0.500031, loss_freq: 0.500035
[12:27:42.151] iteration 3127: loss: 0.729355, loss_s1: 0.470906, loss_fp: 0.424993, loss_freq: 0.174146
[12:27:42.766] iteration 3128: loss: 0.867284, loss_s1: 0.500349, loss_fp: 0.500001, loss_freq: 0.499997
[12:27:43.386] iteration 3129: loss: 0.916998, loss_s1: 0.501357, loss_fp: 0.500004, loss_freq: 0.499969
[12:27:44.000] iteration 3130: loss: 0.905506, loss_s1: 0.500056, loss_fp: 0.500000, loss_freq: 0.499996
[12:27:44.611] iteration 3131: loss: 0.698604, loss_s1: 0.191987, loss_fp: 0.500017, loss_freq: 0.499974
[12:27:45.231] iteration 3132: loss: 0.893896, loss_s1: 0.341403, loss_fp: 0.500001, loss_freq: 0.499956
[12:27:45.852] iteration 3133: loss: 0.605100, loss_s1: 0.006663, loss_fp: 0.500003, loss_freq: 0.499981
[12:27:46.470] iteration 3134: loss: 0.265804, loss_s1: 0.040778, loss_fp: 0.001512, loss_freq: 0.014309
[12:27:47.084] iteration 3135: loss: 0.303870, loss_s1: 0.008364, loss_fp: 0.020415, loss_freq: 0.009059
[12:27:47.699] iteration 3136: loss: 0.226145, loss_s1: 0.133541, loss_fp: 0.003455, loss_freq: 0.008695
[12:27:48.322] iteration 3137: loss: 0.459212, loss_s1: 0.040895, loss_fp: 0.003482, loss_freq: 0.002358
[12:27:48.938] iteration 3138: loss: 0.360393, loss_s1: 0.092102, loss_fp: 0.007307, loss_freq: 0.091347
[12:27:49.551] iteration 3139: loss: 0.303546, loss_s1: 0.088631, loss_fp: 0.002324, loss_freq: 0.125598
[12:27:50.166] iteration 3140: loss: 0.302313, loss_s1: 0.261503, loss_fp: 0.002556, loss_freq: 0.000925
[12:27:50.778] iteration 3141: loss: 0.704300, loss_s1: 0.491756, loss_fp: 0.241257, loss_freq: 0.228647
[12:27:51.398] iteration 3142: loss: 0.243136, loss_s1: 0.184884, loss_fp: 0.001645, loss_freq: 0.021459
[12:27:52.017] iteration 3143: loss: 0.993379, loss_s1: 0.500162, loss_fp: 0.500005, loss_freq: 0.499992
[12:27:52.667] iteration 3144: loss: 0.376343, loss_s1: 0.264265, loss_fp: 0.006574, loss_freq: 0.000966
[12:27:53.283] iteration 3145: loss: 0.293940, loss_s1: 0.185212, loss_fp: 0.013926, loss_freq: 0.004632
[12:27:53.898] iteration 3146: loss: 0.964954, loss_s1: 0.500004, loss_fp: 0.499999, loss_freq: 0.499987
[12:27:54.896] iteration 3147: loss: 0.263148, loss_s1: 0.065594, loss_fp: 0.001575, loss_freq: 0.000817
[12:27:55.515] iteration 3148: loss: 0.498581, loss_s1: 0.496435, loss_fp: 0.038788, loss_freq: 0.115696
[12:27:56.137] iteration 3149: loss: 0.119748, loss_s1: 0.002831, loss_fp: 0.001867, loss_freq: 0.002584
[12:27:56.755] iteration 3150: loss: 0.468098, loss_s1: 0.277199, loss_fp: 0.006000, loss_freq: 0.128467
[12:27:57.367] iteration 3151: loss: 0.619451, loss_s1: 0.321975, loss_fp: 0.008024, loss_freq: 0.495583
[12:27:57.987] iteration 3152: loss: 0.513803, loss_s1: 0.460747, loss_fp: 0.104277, loss_freq: 0.033844
[12:27:58.673] iteration 3153: loss: 0.871610, loss_s1: 0.499999, loss_fp: 0.500003, loss_freq: 0.499988
[12:27:59.340] iteration 3154: loss: 0.962574, loss_s1: 0.500006, loss_fp: 0.499991, loss_freq: 0.500006
[12:28:00.007] iteration 3155: loss: 0.157271, loss_s1: 0.070440, loss_fp: 0.001675, loss_freq: 0.002644
[12:28:00.625] iteration 3156: loss: 1.152824, loss_s1: 0.499995, loss_fp: 0.499999, loss_freq: 0.499994
[12:28:01.245] iteration 3157: loss: 0.881661, loss_s1: 0.499994, loss_fp: 0.500024, loss_freq: 0.499989
[12:28:01.866] iteration 3158: loss: 0.942176, loss_s1: 0.500002, loss_fp: 0.499999, loss_freq: 0.499996
[12:28:02.493] iteration 3159: loss: 1.034803, loss_s1: 0.499990, loss_fp: 0.500000, loss_freq: 0.499988
[12:28:03.118] iteration 3160: loss: 0.255659, loss_s1: 0.126906, loss_fp: 0.029578, loss_freq: 0.000969
[12:28:03.736] iteration 3161: loss: 0.268608, loss_s1: 0.077732, loss_fp: 0.000889, loss_freq: 0.000865
[12:28:04.352] iteration 3162: loss: 0.291822, loss_s1: 0.153128, loss_fp: 0.003908, loss_freq: 0.009108
[12:28:04.968] iteration 3163: loss: 0.360946, loss_s1: 0.058412, loss_fp: 0.001095, loss_freq: 0.000953
[12:28:05.586] iteration 3164: loss: 0.458811, loss_s1: 0.358728, loss_fp: 0.006953, loss_freq: 0.180290
[12:28:06.199] iteration 3165: loss: 0.895582, loss_s1: 0.387325, loss_fp: 0.499999, loss_freq: 0.499993
[12:28:06.808] iteration 3166: loss: 0.551628, loss_s1: 0.385295, loss_fp: 0.374795, loss_freq: 0.135863
[12:28:07.424] iteration 3167: loss: 0.210206, loss_s1: 0.049171, loss_fp: 0.002575, loss_freq: 0.001815
[12:28:08.042] iteration 3168: loss: 0.284345, loss_s1: 0.172525, loss_fp: 0.000890, loss_freq: 0.001019
[12:28:08.666] iteration 3169: loss: 0.171166, loss_s1: 0.023559, loss_fp: 0.001933, loss_freq: 0.000915
[12:28:09.277] iteration 3170: loss: 0.257076, loss_s1: 0.082194, loss_fp: 0.001018, loss_freq: 0.024083
[12:28:09.896] iteration 3171: loss: 0.190676, loss_s1: 0.190515, loss_fp: 0.000924, loss_freq: 0.000890
[12:28:10.520] iteration 3172: loss: 0.882500, loss_s1: 0.409563, loss_fp: 0.499996, loss_freq: 0.500002
[12:28:11.139] iteration 3173: loss: 0.278835, loss_s1: 0.053677, loss_fp: 0.001375, loss_freq: 0.013531
[12:28:11.759] iteration 3174: loss: 0.284795, loss_s1: 0.274613, loss_fp: 0.002597, loss_freq: 0.002728
[12:28:12.408] iteration 3175: loss: 0.384272, loss_s1: 0.061978, loss_fp: 0.003159, loss_freq: 0.055027
[12:28:13.060] iteration 3176: loss: 0.233303, loss_s1: 0.063983, loss_fp: 0.003032, loss_freq: 0.010006
[12:28:13.715] iteration 3177: loss: 0.234859, loss_s1: 0.095365, loss_fp: 0.001151, loss_freq: 0.021040
[12:28:14.410] iteration 3178: loss: 0.164384, loss_s1: 0.051418, loss_fp: 0.000764, loss_freq: 0.014464
[12:28:15.092] iteration 3179: loss: 0.278525, loss_s1: 0.120385, loss_fp: 0.003094, loss_freq: 0.001174
[12:28:15.716] iteration 3180: loss: 0.340379, loss_s1: 0.402461, loss_fp: 0.007380, loss_freq: 0.009296
[12:28:16.333] iteration 3181: loss: 0.493574, loss_s1: 0.411581, loss_fp: 0.013754, loss_freq: 0.121206
[12:28:16.953] iteration 3182: loss: 0.257775, loss_s1: 0.081125, loss_fp: 0.000677, loss_freq: 0.000744
[12:28:17.573] iteration 3183: loss: 0.896259, loss_s1: 0.499010, loss_fp: 0.499995, loss_freq: 0.500000
[12:28:18.185] iteration 3184: loss: 0.161032, loss_s1: 0.019137, loss_fp: 0.000585, loss_freq: 0.000654
[12:28:18.836] iteration 3185: loss: 0.357566, loss_s1: 0.262236, loss_fp: 0.010537, loss_freq: 0.002768
[12:28:19.478] iteration 3186: loss: 0.289837, loss_s1: 0.186534, loss_fp: 0.001262, loss_freq: 0.011453
[12:28:20.100] iteration 3187: loss: 0.186328, loss_s1: 0.000653, loss_fp: 0.000784, loss_freq: 0.000708
[12:28:20.732] iteration 3188: loss: 0.246711, loss_s1: 0.175334, loss_fp: 0.003743, loss_freq: 0.027747
[12:28:21.355] iteration 3189: loss: 0.280705, loss_s1: 0.019604, loss_fp: 0.008304, loss_freq: 0.216671
[12:28:21.982] iteration 3190: loss: 0.298193, loss_s1: 0.150495, loss_fp: 0.000909, loss_freq: 0.133451
[12:28:22.601] iteration 3191: loss: 0.507384, loss_s1: 0.306600, loss_fp: 0.042149, loss_freq: 0.020497
[12:28:23.226] iteration 3192: loss: 0.242464, loss_s1: 0.059494, loss_fp: 0.045325, loss_freq: 0.020361
[12:28:23.869] iteration 3193: loss: 0.203385, loss_s1: 0.016992, loss_fp: 0.019464, loss_freq: 0.000931
[12:28:24.482] iteration 3194: loss: 0.197049, loss_s1: 0.052910, loss_fp: 0.001000, loss_freq: 0.001440
[12:28:25.094] iteration 3195: loss: 0.237997, loss_s1: 0.181108, loss_fp: 0.000840, loss_freq: 0.001234
[12:28:25.713] iteration 3196: loss: 0.281185, loss_s1: 0.099732, loss_fp: 0.000733, loss_freq: 0.005035
[12:28:26.334] iteration 3197: loss: 0.352572, loss_s1: 0.265935, loss_fp: 0.000716, loss_freq: 0.013533
[12:28:26.950] iteration 3198: loss: 0.483231, loss_s1: 0.195250, loss_fp: 0.001663, loss_freq: 0.005918
[12:28:27.565] iteration 3199: loss: 0.276818, loss_s1: 0.119394, loss_fp: 0.001625, loss_freq: 0.001468
[12:28:28.183] iteration 3200: loss: 0.427528, loss_s1: 0.417409, loss_fp: 0.001959, loss_freq: 0.069651
[12:28:30.996] iteration 3200 : mean_dice : 0.293970
[12:28:31.638] iteration 3201: loss: 0.225709, loss_s1: 0.040476, loss_fp: 0.001699, loss_freq: 0.028380
[12:28:32.256] iteration 3202: loss: 0.258739, loss_s1: 0.078978, loss_fp: 0.000985, loss_freq: 0.001086
[12:28:32.875] iteration 3203: loss: 0.331264, loss_s1: 0.190369, loss_fp: 0.021769, loss_freq: 0.026366
[12:28:33.494] iteration 3204: loss: 0.135627, loss_s1: 0.005861, loss_fp: 0.002561, loss_freq: 0.012572
[12:28:34.115] iteration 3205: loss: 0.291104, loss_s1: 0.147622, loss_fp: 0.000988, loss_freq: 0.017759
[12:28:34.732] iteration 3206: loss: 0.221226, loss_s1: 0.036285, loss_fp: 0.002517, loss_freq: 0.096942
[12:28:35.356] iteration 3207: loss: 0.239447, loss_s1: 0.008019, loss_fp: 0.000861, loss_freq: 0.034717
[12:28:35.973] iteration 3208: loss: 0.394084, loss_s1: 0.107511, loss_fp: 0.002129, loss_freq: 0.229538
[12:28:36.591] iteration 3209: loss: 0.391119, loss_s1: 0.474720, loss_fp: 0.002872, loss_freq: 0.028704
[12:28:37.209] iteration 3210: loss: 0.318107, loss_s1: 0.038993, loss_fp: 0.005125, loss_freq: 0.014998
[12:28:37.831] iteration 3211: loss: 0.192917, loss_s1: 0.017656, loss_fp: 0.000649, loss_freq: 0.000634
[12:28:38.455] iteration 3212: loss: 0.196518, loss_s1: 0.049013, loss_fp: 0.000936, loss_freq: 0.020406
[12:28:39.087] iteration 3213: loss: 0.889647, loss_s1: 0.500663, loss_fp: 0.500002, loss_freq: 0.500218
[12:28:39.749] iteration 3214: loss: 0.217259, loss_s1: 0.052900, loss_fp: 0.003909, loss_freq: 0.027738
[12:28:40.410] iteration 3215: loss: 0.198419, loss_s1: 0.047658, loss_fp: 0.002153, loss_freq: 0.015181
[12:28:41.080] iteration 3216: loss: 0.289493, loss_s1: 0.013928, loss_fp: 0.001541, loss_freq: 0.044542
[12:28:41.737] iteration 3217: loss: 0.243237, loss_s1: 0.115501, loss_fp: 0.004342, loss_freq: 0.000559
[12:28:42.400] iteration 3218: loss: 0.178287, loss_s1: 0.029866, loss_fp: 0.009926, loss_freq: 0.000756
[12:28:43.055] iteration 3219: loss: 0.880516, loss_s1: 0.502286, loss_fp: 0.500000, loss_freq: 0.500001
[12:28:43.693] iteration 3220: loss: 0.963083, loss_s1: 0.500028, loss_fp: 0.500009, loss_freq: 0.499998
[12:28:44.318] iteration 3221: loss: 0.223897, loss_s1: 0.111218, loss_fp: 0.002240, loss_freq: 0.020232
[12:28:44.944] iteration 3222: loss: 0.247988, loss_s1: 0.104078, loss_fp: 0.004197, loss_freq: 0.044619
[12:28:45.561] iteration 3223: loss: 0.170195, loss_s1: 0.094963, loss_fp: 0.001165, loss_freq: 0.000645
[12:28:46.182] iteration 3224: loss: 0.176010, loss_s1: 0.033478, loss_fp: 0.001311, loss_freq: 0.001089
[12:28:46.801] iteration 3225: loss: 0.260628, loss_s1: 0.232445, loss_fp: 0.005824, loss_freq: 0.026484
[12:28:47.425] iteration 3226: loss: 0.499188, loss_s1: 0.234362, loss_fp: 0.007208, loss_freq: 0.004099
[12:28:48.051] iteration 3227: loss: 0.175108, loss_s1: 0.062988, loss_fp: 0.001761, loss_freq: 0.007464
[12:28:48.679] iteration 3228: loss: 0.267844, loss_s1: 0.049643, loss_fp: 0.008254, loss_freq: 0.001724
[12:28:49.307] iteration 3229: loss: 0.237694, loss_s1: 0.003897, loss_fp: 0.002557, loss_freq: 0.000724
[12:28:49.934] iteration 3230: loss: 0.203573, loss_s1: 0.092153, loss_fp: 0.083493, loss_freq: 0.017803
[12:28:50.558] iteration 3231: loss: 0.421472, loss_s1: 0.178180, loss_fp: 0.002899, loss_freq: 0.191206
[12:28:51.191] iteration 3232: loss: 0.941029, loss_s1: 0.500098, loss_fp: 0.500000, loss_freq: 0.500003
[12:28:51.814] iteration 3233: loss: 0.285994, loss_s1: 0.000768, loss_fp: 0.000638, loss_freq: 0.000701
[12:28:52.457] iteration 3234: loss: 0.309336, loss_s1: 0.047258, loss_fp: 0.001988, loss_freq: 0.011186
[12:28:53.084] iteration 3235: loss: 0.239630, loss_s1: 0.195132, loss_fp: 0.001080, loss_freq: 0.022904
[12:28:53.722] iteration 3236: loss: 0.616807, loss_s1: 0.390383, loss_fp: 0.459696, loss_freq: 0.092378
[12:28:54.371] iteration 3237: loss: 0.206946, loss_s1: 0.006477, loss_fp: 0.006050, loss_freq: 0.002883
[12:28:55.071] iteration 3238: loss: 0.312972, loss_s1: 0.311184, loss_fp: 0.001319, loss_freq: 0.010051
[12:28:55.731] iteration 3239: loss: 0.179056, loss_s1: 0.147024, loss_fp: 0.000886, loss_freq: 0.005385
[12:28:56.394] iteration 3240: loss: 0.204871, loss_s1: 0.019509, loss_fp: 0.000329, loss_freq: 0.001886
[12:28:57.038] iteration 3241: loss: 0.138689, loss_s1: 0.031274, loss_fp: 0.000611, loss_freq: 0.000582
[12:28:57.664] iteration 3242: loss: 0.316985, loss_s1: 0.249087, loss_fp: 0.001538, loss_freq: 0.014210
[12:28:58.292] iteration 3243: loss: 0.578398, loss_s1: 0.500247, loss_fp: 0.008341, loss_freq: 0.351368
[12:28:58.912] iteration 3244: loss: 0.176335, loss_s1: 0.029229, loss_fp: 0.000668, loss_freq: 0.065725
[12:28:59.536] iteration 3245: loss: 0.385693, loss_s1: 0.091107, loss_fp: 0.000476, loss_freq: 0.071486
[12:29:00.160] iteration 3246: loss: 0.275822, loss_s1: 0.070066, loss_fp: 0.002047, loss_freq: 0.011451
[12:29:00.784] iteration 3247: loss: 0.304820, loss_s1: 0.059870, loss_fp: 0.002081, loss_freq: 0.233292
[12:29:01.431] iteration 3248: loss: 0.163042, loss_s1: 0.086253, loss_fp: 0.001575, loss_freq: 0.001041
[12:29:02.082] iteration 3249: loss: 0.193810, loss_s1: 0.041296, loss_fp: 0.000533, loss_freq: 0.008207
[12:29:02.735] iteration 3250: loss: 0.399194, loss_s1: 0.197263, loss_fp: 0.002087, loss_freq: 0.335968
[12:29:03.372] iteration 3251: loss: 0.396336, loss_s1: 0.267269, loss_fp: 0.000846, loss_freq: 0.017496
[12:29:04.018] iteration 3252: loss: 0.173511, loss_s1: 0.005468, loss_fp: 0.001028, loss_freq: 0.000445
[12:29:04.652] iteration 3253: loss: 0.619200, loss_s1: 0.500466, loss_fp: 0.039853, loss_freq: 0.434928
[12:29:05.413] iteration 3254: loss: 0.144412, loss_s1: 0.065860, loss_fp: 0.001157, loss_freq: 0.000733
[12:29:06.064] iteration 3255: loss: 0.236201, loss_s1: 0.044858, loss_fp: 0.001324, loss_freq: 0.000488
[12:29:06.678] iteration 3256: loss: 0.154138, loss_s1: 0.002785, loss_fp: 0.005946, loss_freq: 0.000511
[12:29:07.301] iteration 3257: loss: 0.170296, loss_s1: 0.003827, loss_fp: 0.001280, loss_freq: 0.002883
[12:29:07.918] iteration 3258: loss: 0.148300, loss_s1: 0.011430, loss_fp: 0.001181, loss_freq: 0.000441
[12:29:08.539] iteration 3259: loss: 0.318000, loss_s1: 0.253217, loss_fp: 0.001026, loss_freq: 0.003540
[12:29:09.163] iteration 3260: loss: 0.222109, loss_s1: 0.014296, loss_fp: 0.002765, loss_freq: 0.193771
[12:29:09.784] iteration 3261: loss: 0.391931, loss_s1: 0.039791, loss_fp: 0.000497, loss_freq: 0.000911
[12:29:10.420] iteration 3262: loss: 0.175886, loss_s1: 0.082127, loss_fp: 0.000645, loss_freq: 0.000499
[12:29:11.067] iteration 3263: loss: 0.382886, loss_s1: 0.156199, loss_fp: 0.001098, loss_freq: 0.098407
[12:29:11.705] iteration 3264: loss: 0.290164, loss_s1: 0.119443, loss_fp: 0.001790, loss_freq: 0.012743
[12:29:12.339] iteration 3265: loss: 0.133910, loss_s1: 0.034812, loss_fp: 0.000781, loss_freq: 0.011401
[12:29:12.975] iteration 3266: loss: 0.338343, loss_s1: 0.230430, loss_fp: 0.008640, loss_freq: 0.000729
[12:29:13.611] iteration 3267: loss: 0.175245, loss_s1: 0.018195, loss_fp: 0.000590, loss_freq: 0.002084
[12:29:14.246] iteration 3268: loss: 0.380603, loss_s1: 0.181082, loss_fp: 0.001632, loss_freq: 0.009654
[12:29:14.906] iteration 3269: loss: 0.179520, loss_s1: 0.004928, loss_fp: 0.000957, loss_freq: 0.001659
[12:29:15.523] iteration 3270: loss: 0.190589, loss_s1: 0.046193, loss_fp: 0.004126, loss_freq: 0.001130
[12:29:16.138] iteration 3271: loss: 0.886972, loss_s1: 0.500198, loss_fp: 0.499981, loss_freq: 0.499999
[12:29:16.758] iteration 3272: loss: 0.307616, loss_s1: 0.183804, loss_fp: 0.001566, loss_freq: 0.014181
[12:29:17.378] iteration 3273: loss: 0.228108, loss_s1: 0.011412, loss_fp: 0.001374, loss_freq: 0.040011
[12:29:18.001] iteration 3274: loss: 0.201788, loss_s1: 0.148963, loss_fp: 0.002385, loss_freq: 0.035189
[12:29:18.614] iteration 3275: loss: 0.455561, loss_s1: 0.281944, loss_fp: 0.000658, loss_freq: 0.176681
[12:29:19.229] iteration 3276: loss: 0.864062, loss_s1: 0.500013, loss_fp: 0.500001, loss_freq: 0.499998
[12:29:19.848] iteration 3277: loss: 0.182135, loss_s1: 0.004024, loss_fp: 0.000903, loss_freq: 0.000941
[12:29:20.464] iteration 3278: loss: 0.672825, loss_s1: 0.002074, loss_fp: 0.499996, loss_freq: 0.499994
[12:29:21.080] iteration 3279: loss: 0.135462, loss_s1: 0.023550, loss_fp: 0.000916, loss_freq: 0.002319
[12:29:21.700] iteration 3280: loss: 0.307126, loss_s1: 0.036386, loss_fp: 0.000782, loss_freq: 0.001994
[12:29:22.318] iteration 3281: loss: 0.328020, loss_s1: 0.076074, loss_fp: 0.000778, loss_freq: 0.146604
[12:29:22.935] iteration 3282: loss: 0.165266, loss_s1: 0.023109, loss_fp: 0.014471, loss_freq: 0.004209
[12:29:23.553] iteration 3283: loss: 0.158201, loss_s1: 0.089395, loss_fp: 0.001366, loss_freq: 0.000467
[12:29:24.169] iteration 3284: loss: 0.180323, loss_s1: 0.080213, loss_fp: 0.000841, loss_freq: 0.012531
[12:29:24.817] iteration 3285: loss: 0.234401, loss_s1: 0.131021, loss_fp: 0.000802, loss_freq: 0.016685
[12:29:25.472] iteration 3286: loss: 0.246176, loss_s1: 0.063755, loss_fp: 0.000718, loss_freq: 0.012057
[12:29:26.122] iteration 3287: loss: 0.194135, loss_s1: 0.036773, loss_fp: 0.001007, loss_freq: 0.001241
[12:29:26.770] iteration 3288: loss: 0.214078, loss_s1: 0.103152, loss_fp: 0.003191, loss_freq: 0.077622
[12:29:27.417] iteration 3289: loss: 0.211585, loss_s1: 0.146137, loss_fp: 0.000520, loss_freq: 0.000604
[12:29:28.396] iteration 3290: loss: 0.185204, loss_s1: 0.034597, loss_fp: 0.000739, loss_freq: 0.001657
[12:29:29.088] iteration 3291: loss: 0.224585, loss_s1: 0.106678, loss_fp: 0.004920, loss_freq: 0.106163
[12:29:29.741] iteration 3292: loss: 0.188972, loss_s1: 0.134451, loss_fp: 0.001093, loss_freq: 0.009959
[12:29:30.380] iteration 3293: loss: 0.191251, loss_s1: 0.082679, loss_fp: 0.001366, loss_freq: 0.000814
[12:29:31.036] iteration 3294: loss: 0.362626, loss_s1: 0.182346, loss_fp: 0.000623, loss_freq: 0.172841
[12:29:31.695] iteration 3295: loss: 0.231355, loss_s1: 0.088439, loss_fp: 0.000625, loss_freq: 0.052398
[12:29:32.314] iteration 3296: loss: 0.419414, loss_s1: 0.081678, loss_fp: 0.143263, loss_freq: 0.410976
[12:29:32.935] iteration 3297: loss: 0.264267, loss_s1: 0.069786, loss_fp: 0.029258, loss_freq: 0.121870
[12:29:33.558] iteration 3298: loss: 0.140319, loss_s1: 0.081962, loss_fp: 0.001413, loss_freq: 0.000577
[12:29:34.181] iteration 3299: loss: 0.318579, loss_s1: 0.000756, loss_fp: 0.000626, loss_freq: 0.002824
[12:29:34.803] iteration 3300: loss: 0.165259, loss_s1: 0.115797, loss_fp: 0.001197, loss_freq: 0.006127
[12:29:35.423] iteration 3301: loss: 0.151141, loss_s1: 0.013724, loss_fp: 0.003135, loss_freq: 0.011328
[12:29:36.043] iteration 3302: loss: 0.307752, loss_s1: 0.144495, loss_fp: 0.003705, loss_freq: 0.041837
[12:29:36.665] iteration 3303: loss: 0.214647, loss_s1: 0.035377, loss_fp: 0.000908, loss_freq: 0.144729
[12:29:37.285] iteration 3304: loss: 0.361218, loss_s1: 0.238927, loss_fp: 0.000439, loss_freq: 0.005833
[12:29:37.903] iteration 3305: loss: 0.255081, loss_s1: 0.036862, loss_fp: 0.001140, loss_freq: 0.055819
[12:29:38.524] iteration 3306: loss: 0.463059, loss_s1: 0.144339, loss_fp: 0.001944, loss_freq: 0.132832
[12:29:39.143] iteration 3307: loss: 0.355999, loss_s1: 0.064864, loss_fp: 0.003032, loss_freq: 0.017781
[12:29:39.767] iteration 3308: loss: 0.187990, loss_s1: 0.068974, loss_fp: 0.001023, loss_freq: 0.001287
[12:29:40.393] iteration 3309: loss: 0.279273, loss_s1: 0.228936, loss_fp: 0.002344, loss_freq: 0.029961
[12:29:41.007] iteration 3310: loss: 0.214229, loss_s1: 0.003566, loss_fp: 0.000599, loss_freq: 0.001343
[12:29:41.628] iteration 3311: loss: 0.182597, loss_s1: 0.015039, loss_fp: 0.001291, loss_freq: 0.002905
[12:29:42.244] iteration 3312: loss: 0.162232, loss_s1: 0.010680, loss_fp: 0.001146, loss_freq: 0.004939
[12:29:42.895] iteration 3313: loss: 0.247438, loss_s1: 0.154337, loss_fp: 0.001845, loss_freq: 0.002440
[12:29:43.543] iteration 3314: loss: 0.174919, loss_s1: 0.045518, loss_fp: 0.000892, loss_freq: 0.008342
[12:29:44.192] iteration 3315: loss: 0.354558, loss_s1: 0.210708, loss_fp: 0.005323, loss_freq: 0.071803
[12:29:44.812] iteration 3316: loss: 0.188231, loss_s1: 0.005970, loss_fp: 0.000517, loss_freq: 0.005403
[12:29:45.427] iteration 3317: loss: 0.216315, loss_s1: 0.099309, loss_fp: 0.001123, loss_freq: 0.001731
[12:29:46.068] iteration 3318: loss: 0.432021, loss_s1: 0.047351, loss_fp: 0.000495, loss_freq: 0.054282
[12:29:46.699] iteration 3319: loss: 0.363403, loss_s1: 0.239819, loss_fp: 0.001020, loss_freq: 0.015407
[12:29:47.337] iteration 3320: loss: 0.170416, loss_s1: 0.012925, loss_fp: 0.000940, loss_freq: 0.011457
[12:29:47.972] iteration 3321: loss: 0.204289, loss_s1: 0.041633, loss_fp: 0.000984, loss_freq: 0.000621
[12:29:48.593] iteration 3322: loss: 0.186245, loss_s1: 0.057254, loss_fp: 0.001310, loss_freq: 0.001870
[12:29:49.219] iteration 3323: loss: 0.225084, loss_s1: 0.127047, loss_fp: 0.002392, loss_freq: 0.051843
[12:29:49.854] iteration 3324: loss: 0.253423, loss_s1: 0.047903, loss_fp: 0.000724, loss_freq: 0.022740
[12:29:50.490] iteration 3325: loss: 0.279091, loss_s1: 0.103172, loss_fp: 0.000872, loss_freq: 0.000983
[12:29:51.164] iteration 3326: loss: 0.138349, loss_s1: 0.039171, loss_fp: 0.002343, loss_freq: 0.001156
[12:29:51.797] iteration 3327: loss: 0.136464, loss_s1: 0.052760, loss_fp: 0.000525, loss_freq: 0.003002
[12:29:52.425] iteration 3328: loss: 0.271628, loss_s1: 0.100017, loss_fp: 0.003209, loss_freq: 0.000877
[12:29:53.054] iteration 3329: loss: 0.187070, loss_s1: 0.078307, loss_fp: 0.000947, loss_freq: 0.001459
[12:29:53.695] iteration 3330: loss: 0.183600, loss_s1: 0.050367, loss_fp: 0.000926, loss_freq: 0.020080
[12:29:54.320] iteration 3331: loss: 0.207408, loss_s1: 0.164657, loss_fp: 0.000658, loss_freq: 0.007696
[12:29:54.950] iteration 3332: loss: 0.220321, loss_s1: 0.026823, loss_fp: 0.000602, loss_freq: 0.033270
[12:29:55.575] iteration 3333: loss: 0.088952, loss_s1: 0.041046, loss_fp: 0.001835, loss_freq: 0.001979
[12:29:56.212] iteration 3334: loss: 0.491501, loss_s1: 0.251825, loss_fp: 0.000752, loss_freq: 0.078829
[12:29:56.859] iteration 3335: loss: 0.212749, loss_s1: 0.163505, loss_fp: 0.000763, loss_freq: 0.002253
[12:29:57.507] iteration 3336: loss: 0.201416, loss_s1: 0.073630, loss_fp: 0.001457, loss_freq: 0.059872
[12:29:58.137] iteration 3337: loss: 0.227917, loss_s1: 0.046166, loss_fp: 0.001242, loss_freq: 0.060923
[12:29:58.773] iteration 3338: loss: 0.115651, loss_s1: 0.008953, loss_fp: 0.001197, loss_freq: 0.009975
[12:29:59.408] iteration 3339: loss: 0.227633, loss_s1: 0.055245, loss_fp: 0.000529, loss_freq: 0.002645
[12:30:00.036] iteration 3340: loss: 0.180271, loss_s1: 0.024858, loss_fp: 0.000818, loss_freq: 0.001261
[12:30:00.667] iteration 3341: loss: 0.346430, loss_s1: 0.135507, loss_fp: 0.000626, loss_freq: 0.000372
[12:30:01.298] iteration 3342: loss: 0.258756, loss_s1: 0.117055, loss_fp: 0.005947, loss_freq: 0.001267
[12:30:01.930] iteration 3343: loss: 0.160514, loss_s1: 0.070660, loss_fp: 0.000500, loss_freq: 0.001251
[12:30:02.595] iteration 3344: loss: 0.189767, loss_s1: 0.027516, loss_fp: 0.000762, loss_freq: 0.030655
[12:30:03.237] iteration 3345: loss: 0.192380, loss_s1: 0.010551, loss_fp: 0.001614, loss_freq: 0.008127
[12:30:03.878] iteration 3346: loss: 0.240653, loss_s1: 0.107799, loss_fp: 0.000728, loss_freq: 0.007937
[12:30:04.516] iteration 3347: loss: 0.110264, loss_s1: 0.064393, loss_fp: 0.000559, loss_freq: 0.000739
[12:30:05.135] iteration 3348: loss: 0.175563, loss_s1: 0.027149, loss_fp: 0.001281, loss_freq: 0.037176
[12:30:05.791] iteration 3349: loss: 0.193303, loss_s1: 0.049813, loss_fp: 0.001565, loss_freq: 0.156970
[12:30:06.416] iteration 3350: loss: 0.176475, loss_s1: 0.029554, loss_fp: 0.000543, loss_freq: 0.030907
[12:30:07.047] iteration 3351: loss: 0.244275, loss_s1: 0.124542, loss_fp: 0.000862, loss_freq: 0.010045
[12:30:07.680] iteration 3352: loss: 0.296491, loss_s1: 0.304596, loss_fp: 0.000827, loss_freq: 0.036617
[12:30:08.314] iteration 3353: loss: 0.387472, loss_s1: 0.230840, loss_fp: 0.001093, loss_freq: 0.020297
[12:30:08.957] iteration 3354: loss: 0.240405, loss_s1: 0.102288, loss_fp: 0.000565, loss_freq: 0.021074
[12:30:09.597] iteration 3355: loss: 0.189743, loss_s1: 0.084772, loss_fp: 0.000721, loss_freq: 0.015487
[12:30:10.237] iteration 3356: loss: 0.162512, loss_s1: 0.062829, loss_fp: 0.001893, loss_freq: 0.000842
[12:30:10.861] iteration 3357: loss: 0.167011, loss_s1: 0.017821, loss_fp: 0.006856, loss_freq: 0.007789
[12:30:11.502] iteration 3358: loss: 0.167122, loss_s1: 0.018921, loss_fp: 0.001109, loss_freq: 0.012328
[12:30:12.130] iteration 3359: loss: 0.224229, loss_s1: 0.053999, loss_fp: 0.000756, loss_freq: 0.024467
[12:30:12.758] iteration 3360: loss: 0.240640, loss_s1: 0.157174, loss_fp: 0.000965, loss_freq: 0.019778
[12:30:13.388] iteration 3361: loss: 0.135221, loss_s1: 0.046549, loss_fp: 0.002180, loss_freq: 0.000271
[12:30:14.052] iteration 3362: loss: 0.100076, loss_s1: 0.016403, loss_fp: 0.002084, loss_freq: 0.001741
[12:30:14.695] iteration 3363: loss: 0.191788, loss_s1: 0.067295, loss_fp: 0.001456, loss_freq: 0.000292
[12:30:15.343] iteration 3364: loss: 0.190936, loss_s1: 0.103820, loss_fp: 0.000600, loss_freq: 0.012343
[12:30:15.969] iteration 3365: loss: 0.169249, loss_s1: 0.085053, loss_fp: 0.000705, loss_freq: 0.000586
[12:30:16.656] iteration 3366: loss: 0.109926, loss_s1: 0.054795, loss_fp: 0.000639, loss_freq: 0.003782
[12:30:17.327] iteration 3367: loss: 0.169276, loss_s1: 0.060599, loss_fp: 0.000829, loss_freq: 0.000703
[12:30:17.968] iteration 3368: loss: 0.140762, loss_s1: 0.110151, loss_fp: 0.000988, loss_freq: 0.009420
[12:30:18.597] iteration 3369: loss: 0.426315, loss_s1: 0.075268, loss_fp: 0.000764, loss_freq: 0.002298
[12:30:19.226] iteration 3370: loss: 0.177079, loss_s1: 0.042253, loss_fp: 0.000732, loss_freq: 0.000456
[12:30:19.868] iteration 3371: loss: 0.233618, loss_s1: 0.147919, loss_fp: 0.000640, loss_freq: 0.012625
[12:30:20.489] iteration 3372: loss: 0.168226, loss_s1: 0.028299, loss_fp: 0.007354, loss_freq: 0.000422
[12:30:21.111] iteration 3373: loss: 0.087647, loss_s1: 0.031081, loss_fp: 0.001044, loss_freq: 0.004365
[12:30:21.735] iteration 3374: loss: 0.265135, loss_s1: 0.058025, loss_fp: 0.000667, loss_freq: 0.067396
[12:30:22.361] iteration 3375: loss: 0.214125, loss_s1: 0.173256, loss_fp: 0.000661, loss_freq: 0.002382
[12:30:22.984] iteration 3376: loss: 0.247152, loss_s1: 0.050613, loss_fp: 0.000717, loss_freq: 0.001617
[12:30:23.607] iteration 3377: loss: 0.242700, loss_s1: 0.143412, loss_fp: 0.000810, loss_freq: 0.004106
[12:30:24.234] iteration 3378: loss: 0.174416, loss_s1: 0.116341, loss_fp: 0.000606, loss_freq: 0.001086
[12:30:24.858] iteration 3379: loss: 0.169924, loss_s1: 0.134747, loss_fp: 0.000566, loss_freq: 0.000518
[12:30:25.481] iteration 3380: loss: 0.176194, loss_s1: 0.031351, loss_fp: 0.000686, loss_freq: 0.002108
[12:30:26.112] iteration 3381: loss: 0.191642, loss_s1: 0.034220, loss_fp: 0.000603, loss_freq: 0.053433
[12:30:26.733] iteration 3382: loss: 0.083385, loss_s1: 0.007547, loss_fp: 0.001329, loss_freq: 0.001813
[12:30:27.359] iteration 3383: loss: 0.206408, loss_s1: 0.056870, loss_fp: 0.000546, loss_freq: 0.025131
[12:30:27.980] iteration 3384: loss: 0.103308, loss_s1: 0.036334, loss_fp: 0.000757, loss_freq: 0.002383
[12:30:28.642] iteration 3385: loss: 0.168401, loss_s1: 0.012785, loss_fp: 0.000937, loss_freq: 0.005746
[12:30:29.268] iteration 3386: loss: 0.365353, loss_s1: 0.379433, loss_fp: 0.000538, loss_freq: 0.052436
[12:30:29.891] iteration 3387: loss: 0.132053, loss_s1: 0.004489, loss_fp: 0.000586, loss_freq: 0.030127
[12:30:30.511] iteration 3388: loss: 0.312532, loss_s1: 0.037908, loss_fp: 0.000653, loss_freq: 0.000991
[12:30:31.153] iteration 3389: loss: 0.184048, loss_s1: 0.030729, loss_fp: 0.000600, loss_freq: 0.002779
[12:30:31.779] iteration 3390: loss: 0.510517, loss_s1: 0.379291, loss_fp: 0.001636, loss_freq: 0.357853
[12:30:32.402] iteration 3391: loss: 0.127943, loss_s1: 0.032146, loss_fp: 0.000631, loss_freq: 0.000621
[12:30:33.025] iteration 3392: loss: 0.180519, loss_s1: 0.070643, loss_fp: 0.000717, loss_freq: 0.004028
[12:30:33.653] iteration 3393: loss: 0.142130, loss_s1: 0.026358, loss_fp: 0.026859, loss_freq: 0.006749
[12:30:34.275] iteration 3394: loss: 0.218245, loss_s1: 0.032385, loss_fp: 0.002825, loss_freq: 0.009910
[12:30:34.901] iteration 3395: loss: 0.143630, loss_s1: 0.028918, loss_fp: 0.000573, loss_freq: 0.004161
[12:30:35.524] iteration 3396: loss: 0.172045, loss_s1: 0.121739, loss_fp: 0.011804, loss_freq: 0.003132
[12:30:36.144] iteration 3397: loss: 0.118652, loss_s1: 0.089206, loss_fp: 0.000545, loss_freq: 0.000649
[12:30:36.767] iteration 3398: loss: 0.225247, loss_s1: 0.073400, loss_fp: 0.000523, loss_freq: 0.000507
[12:30:37.415] iteration 3399: loss: 0.172250, loss_s1: 0.031780, loss_fp: 0.000752, loss_freq: 0.000239
[12:30:38.034] iteration 3400: loss: 0.136022, loss_s1: 0.035718, loss_fp: 0.000529, loss_freq: 0.003466
[12:30:41.185] iteration 3400 : mean_dice : 0.429132
[12:30:41.820] iteration 3401: loss: 0.095157, loss_s1: 0.001995, loss_fp: 0.001383, loss_freq: 0.021632
[12:30:42.434] iteration 3402: loss: 0.162672, loss_s1: 0.033621, loss_fp: 0.000717, loss_freq: 0.014701
[12:30:43.054] iteration 3403: loss: 0.129104, loss_s1: 0.049446, loss_fp: 0.000949, loss_freq: 0.046469
[12:30:43.677] iteration 3404: loss: 0.405103, loss_s1: 0.089030, loss_fp: 0.000651, loss_freq: 0.065591
[12:30:44.303] iteration 3405: loss: 0.141834, loss_s1: 0.042901, loss_fp: 0.000599, loss_freq: 0.003282
[12:30:44.935] iteration 3406: loss: 0.221174, loss_s1: 0.110183, loss_fp: 0.001599, loss_freq: 0.009922
[12:30:45.556] iteration 3407: loss: 0.251964, loss_s1: 0.155067, loss_fp: 0.001067, loss_freq: 0.000804
[12:30:46.187] iteration 3408: loss: 0.112676, loss_s1: 0.056741, loss_fp: 0.001441, loss_freq: 0.010446
[12:30:46.811] iteration 3409: loss: 0.286396, loss_s1: 0.281834, loss_fp: 0.005200, loss_freq: 0.019340
[12:30:47.427] iteration 3410: loss: 0.173551, loss_s1: 0.042827, loss_fp: 0.003111, loss_freq: 0.000559
[12:30:48.047] iteration 3411: loss: 0.320934, loss_s1: 0.143950, loss_fp: 0.001926, loss_freq: 0.001337
[12:30:48.694] iteration 3412: loss: 0.218919, loss_s1: 0.121540, loss_fp: 0.000697, loss_freq: 0.000827
[12:30:49.377] iteration 3413: loss: 0.140819, loss_s1: 0.072483, loss_fp: 0.000682, loss_freq: 0.000550
[12:30:49.999] iteration 3414: loss: 0.162128, loss_s1: 0.060066, loss_fp: 0.000993, loss_freq: 0.021852
[12:30:50.622] iteration 3415: loss: 0.241196, loss_s1: 0.077000, loss_fp: 0.004818, loss_freq: 0.000563
[12:30:51.248] iteration 3416: loss: 0.203663, loss_s1: 0.062528, loss_fp: 0.000678, loss_freq: 0.062166
[12:30:51.863] iteration 3417: loss: 0.106698, loss_s1: 0.048551, loss_fp: 0.000893, loss_freq: 0.007729
[12:30:52.485] iteration 3418: loss: 0.273270, loss_s1: 0.061221, loss_fp: 0.001163, loss_freq: 0.112901
[12:30:53.105] iteration 3419: loss: 0.100875, loss_s1: 0.010955, loss_fp: 0.001015, loss_freq: 0.002688
[12:30:53.723] iteration 3420: loss: 0.157417, loss_s1: 0.011411, loss_fp: 0.000889, loss_freq: 0.003573
[12:30:54.346] iteration 3421: loss: 0.180600, loss_s1: 0.011625, loss_fp: 0.001433, loss_freq: 0.000495
[12:30:54.969] iteration 3422: loss: 0.131825, loss_s1: 0.038915, loss_fp: 0.000858, loss_freq: 0.002068
[12:30:55.593] iteration 3423: loss: 0.224795, loss_s1: 0.001409, loss_fp: 0.000617, loss_freq: 0.007960
[12:30:56.216] iteration 3424: loss: 0.238768, loss_s1: 0.069216, loss_fp: 0.000735, loss_freq: 0.120167
[12:30:56.838] iteration 3425: loss: 0.122827, loss_s1: 0.057364, loss_fp: 0.000536, loss_freq: 0.001247
[12:30:57.481] iteration 3426: loss: 0.149757, loss_s1: 0.075460, loss_fp: 0.003424, loss_freq: 0.001388
[12:30:58.101] iteration 3427: loss: 0.152960, loss_s1: 0.035171, loss_fp: 0.018047, loss_freq: 0.001658
[12:30:58.722] iteration 3428: loss: 0.167178, loss_s1: 0.040782, loss_fp: 0.001446, loss_freq: 0.020188
[12:30:59.344] iteration 3429: loss: 0.203971, loss_s1: 0.046641, loss_fp: 0.001285, loss_freq: 0.002874
[12:30:59.966] iteration 3430: loss: 0.160865, loss_s1: 0.034872, loss_fp: 0.001172, loss_freq: 0.029703
[12:31:00.583] iteration 3431: loss: 0.222345, loss_s1: 0.186626, loss_fp: 0.012341, loss_freq: 0.056584
[12:31:01.203] iteration 3432: loss: 0.145355, loss_s1: 0.131353, loss_fp: 0.001304, loss_freq: 0.001498
[12:31:02.247] iteration 3433: loss: 0.164456, loss_s1: 0.046637, loss_fp: 0.000496, loss_freq: 0.000599
[12:31:02.873] iteration 3434: loss: 0.091631, loss_s1: 0.005110, loss_fp: 0.001404, loss_freq: 0.003696
[12:31:03.501] iteration 3435: loss: 0.106945, loss_s1: 0.006470, loss_fp: 0.000927, loss_freq: 0.025062
[12:31:04.138] iteration 3436: loss: 0.146510, loss_s1: 0.005416, loss_fp: 0.001272, loss_freq: 0.000737
[12:31:04.796] iteration 3437: loss: 0.281855, loss_s1: 0.026217, loss_fp: 0.002003, loss_freq: 0.260828
[12:31:05.451] iteration 3438: loss: 0.146886, loss_s1: 0.047901, loss_fp: 0.000607, loss_freq: 0.000564
[12:31:06.106] iteration 3439: loss: 0.087418, loss_s1: 0.023438, loss_fp: 0.000795, loss_freq: 0.001998
[12:31:06.736] iteration 3440: loss: 0.189357, loss_s1: 0.056009, loss_fp: 0.001665, loss_freq: 0.010725
[12:31:07.701] iteration 3441: loss: 0.155440, loss_s1: 0.054495, loss_fp: 0.000626, loss_freq: 0.028841
[12:31:08.643] iteration 3442: loss: 0.392412, loss_s1: 0.059802, loss_fp: 0.002653, loss_freq: 0.005303
[12:31:09.405] iteration 3443: loss: 0.147569, loss_s1: 0.019541, loss_fp: 0.000808, loss_freq: 0.001288
[12:31:10.026] iteration 3444: loss: 0.148627, loss_s1: 0.000926, loss_fp: 0.000576, loss_freq: 0.082674
[12:31:10.649] iteration 3445: loss: 0.201572, loss_s1: 0.046438, loss_fp: 0.000678, loss_freq: 0.000510
[12:31:11.271] iteration 3446: loss: 0.085224, loss_s1: 0.002662, loss_fp: 0.000719, loss_freq: 0.003682
[12:31:11.890] iteration 3447: loss: 0.180343, loss_s1: 0.008787, loss_fp: 0.000529, loss_freq: 0.004173
[12:31:12.540] iteration 3448: loss: 0.162086, loss_s1: 0.116904, loss_fp: 0.002044, loss_freq: 0.005115
[12:31:13.159] iteration 3449: loss: 0.306123, loss_s1: 0.066660, loss_fp: 0.000865, loss_freq: 0.022517
[12:31:13.780] iteration 3450: loss: 0.204397, loss_s1: 0.004322, loss_fp: 0.002995, loss_freq: 0.040818
[12:31:14.403] iteration 3451: loss: 0.182848, loss_s1: 0.023831, loss_fp: 0.000807, loss_freq: 0.000670
[12:31:15.025] iteration 3452: loss: 0.150811, loss_s1: 0.021736, loss_fp: 0.001462, loss_freq: 0.002578
[12:31:15.648] iteration 3453: loss: 0.229453, loss_s1: 0.045461, loss_fp: 0.026445, loss_freq: 0.000848
[12:31:16.268] iteration 3454: loss: 0.182980, loss_s1: 0.072303, loss_fp: 0.001093, loss_freq: 0.001157
[12:31:16.891] iteration 3455: loss: 0.132872, loss_s1: 0.057703, loss_fp: 0.000975, loss_freq: 0.007563
[12:31:17.511] iteration 3456: loss: 0.178391, loss_s1: 0.102216, loss_fp: 0.000554, loss_freq: 0.001454
[12:31:18.128] iteration 3457: loss: 0.087954, loss_s1: 0.008472, loss_fp: 0.000666, loss_freq: 0.003671
[12:31:18.745] iteration 3458: loss: 0.335467, loss_s1: 0.337736, loss_fp: 0.001883, loss_freq: 0.002042
[12:31:19.366] iteration 3459: loss: 0.170736, loss_s1: 0.058181, loss_fp: 0.001324, loss_freq: 0.003305
[12:31:19.982] iteration 3460: loss: 0.124358, loss_s1: 0.033414, loss_fp: 0.000635, loss_freq: 0.002453
[12:31:20.599] iteration 3461: loss: 0.347987, loss_s1: 0.057152, loss_fp: 0.001234, loss_freq: 0.006951
[12:31:21.218] iteration 3462: loss: 0.202591, loss_s1: 0.028767, loss_fp: 0.000583, loss_freq: 0.004137
[12:31:21.841] iteration 3463: loss: 0.140309, loss_s1: 0.029029, loss_fp: 0.000420, loss_freq: 0.000799
[12:31:22.464] iteration 3464: loss: 0.144031, loss_s1: 0.088804, loss_fp: 0.000437, loss_freq: 0.000602
[12:31:23.087] iteration 3465: loss: 0.191114, loss_s1: 0.162241, loss_fp: 0.000748, loss_freq: 0.001070
[12:31:23.761] iteration 3466: loss: 0.273491, loss_s1: 0.208219, loss_fp: 0.001049, loss_freq: 0.105059
[12:31:24.388] iteration 3467: loss: 0.207688, loss_s1: 0.055072, loss_fp: 0.000763, loss_freq: 0.011455
[12:31:25.014] iteration 3468: loss: 0.182864, loss_s1: 0.043410, loss_fp: 0.004123, loss_freq: 0.012843
[12:31:25.635] iteration 3469: loss: 0.139822, loss_s1: 0.052459, loss_fp: 0.001043, loss_freq: 0.000573
[12:31:26.257] iteration 3470: loss: 0.133709, loss_s1: 0.059009, loss_fp: 0.000841, loss_freq: 0.018564
[12:31:26.878] iteration 3471: loss: 0.161007, loss_s1: 0.000925, loss_fp: 0.000623, loss_freq: 0.000783
[12:31:27.503] iteration 3472: loss: 0.177895, loss_s1: 0.017679, loss_fp: 0.000516, loss_freq: 0.004445
[12:31:28.126] iteration 3473: loss: 0.129629, loss_s1: 0.017855, loss_fp: 0.000687, loss_freq: 0.004710
[12:31:28.752] iteration 3474: loss: 0.149817, loss_s1: 0.008780, loss_fp: 0.000506, loss_freq: 0.034629
[12:31:29.402] iteration 3475: loss: 0.215669, loss_s1: 0.048398, loss_fp: 0.000666, loss_freq: 0.010502
[12:31:30.030] iteration 3476: loss: 0.096289, loss_s1: 0.040090, loss_fp: 0.000718, loss_freq: 0.004386
[12:31:30.652] iteration 3477: loss: 0.398682, loss_s1: 0.187151, loss_fp: 0.000578, loss_freq: 0.070287
[12:31:31.271] iteration 3478: loss: 0.174576, loss_s1: 0.036127, loss_fp: 0.000617, loss_freq: 0.030722
[12:31:31.892] iteration 3479: loss: 0.150616, loss_s1: 0.009697, loss_fp: 0.002079, loss_freq: 0.035815
[12:31:32.512] iteration 3480: loss: 0.180384, loss_s1: 0.095716, loss_fp: 0.001218, loss_freq: 0.017774
[12:31:33.129] iteration 3481: loss: 0.100658, loss_s1: 0.032534, loss_fp: 0.000594, loss_freq: 0.002616
[12:31:33.749] iteration 3482: loss: 0.168104, loss_s1: 0.003954, loss_fp: 0.000586, loss_freq: 0.002056
[12:31:34.367] iteration 3483: loss: 0.148852, loss_s1: 0.001246, loss_fp: 0.000642, loss_freq: 0.002015
[12:31:34.993] iteration 3484: loss: 0.244293, loss_s1: 0.044410, loss_fp: 0.000494, loss_freq: 0.004477
[12:31:35.615] iteration 3485: loss: 0.184109, loss_s1: 0.085775, loss_fp: 0.001063, loss_freq: 0.007728
[12:31:36.237] iteration 3486: loss: 0.162139, loss_s1: 0.047042, loss_fp: 0.000680, loss_freq: 0.029202
[12:31:36.857] iteration 3487: loss: 0.151701, loss_s1: 0.062705, loss_fp: 0.000901, loss_freq: 0.047725
[12:31:37.472] iteration 3488: loss: 0.225171, loss_s1: 0.041493, loss_fp: 0.000850, loss_freq: 0.067201
[12:31:38.088] iteration 3489: loss: 0.224384, loss_s1: 0.197452, loss_fp: 0.001271, loss_freq: 0.036446
[12:31:38.706] iteration 3490: loss: 0.124650, loss_s1: 0.061226, loss_fp: 0.000680, loss_freq: 0.031016
[12:31:39.329] iteration 3491: loss: 0.212062, loss_s1: 0.014940, loss_fp: 0.000997, loss_freq: 0.031167
[12:31:39.946] iteration 3492: loss: 0.187561, loss_s1: 0.054720, loss_fp: 0.000588, loss_freq: 0.150954
[12:31:40.568] iteration 3493: loss: 0.209295, loss_s1: 0.118786, loss_fp: 0.000844, loss_freq: 0.003076
[12:31:41.185] iteration 3494: loss: 0.205676, loss_s1: 0.084693, loss_fp: 0.000546, loss_freq: 0.001611
[12:31:41.805] iteration 3495: loss: 0.176772, loss_s1: 0.075545, loss_fp: 0.001666, loss_freq: 0.028153
[12:31:42.426] iteration 3496: loss: 0.361031, loss_s1: 0.258736, loss_fp: 0.000557, loss_freq: 0.022197
[12:31:43.045] iteration 3497: loss: 0.172447, loss_s1: 0.026996, loss_fp: 0.000361, loss_freq: 0.003214
[12:31:43.662] iteration 3498: loss: 0.160558, loss_s1: 0.007732, loss_fp: 0.000516, loss_freq: 0.004939
[12:31:44.285] iteration 3499: loss: 0.181320, loss_s1: 0.085740, loss_fp: 0.003308, loss_freq: 0.092251
[12:31:44.907] iteration 3500: loss: 0.254905, loss_s1: 0.166617, loss_fp: 0.001940, loss_freq: 0.070633
[12:31:45.525] iteration 3501: loss: 0.176146, loss_s1: 0.104509, loss_fp: 0.000985, loss_freq: 0.024950
[12:31:46.142] iteration 3502: loss: 0.214688, loss_s1: 0.049125, loss_fp: 0.001285, loss_freq: 0.012903
[12:31:46.783] iteration 3503: loss: 0.150588, loss_s1: 0.056996, loss_fp: 0.000653, loss_freq: 0.001098
[12:31:47.436] iteration 3504: loss: 0.160312, loss_s1: 0.037933, loss_fp: 0.000723, loss_freq: 0.001598
[12:31:48.094] iteration 3505: loss: 0.121596, loss_s1: 0.044976, loss_fp: 0.001696, loss_freq: 0.001684
[12:31:48.719] iteration 3506: loss: 0.166982, loss_s1: 0.013532, loss_fp: 0.001840, loss_freq: 0.028777
[12:31:49.343] iteration 3507: loss: 0.199877, loss_s1: 0.054028, loss_fp: 0.000535, loss_freq: 0.024879
[12:31:49.973] iteration 3508: loss: 0.144677, loss_s1: 0.049582, loss_fp: 0.001225, loss_freq: 0.020984
[12:31:50.596] iteration 3509: loss: 0.137483, loss_s1: 0.094780, loss_fp: 0.000641, loss_freq: 0.000721
[12:31:51.212] iteration 3510: loss: 0.136228, loss_s1: 0.028918, loss_fp: 0.000661, loss_freq: 0.013525
[12:31:51.872] iteration 3511: loss: 0.220196, loss_s1: 0.221870, loss_fp: 0.000555, loss_freq: 0.016986
[12:31:52.496] iteration 3512: loss: 0.375484, loss_s1: 0.030144, loss_fp: 0.000973, loss_freq: 0.001476
[12:31:53.110] iteration 3513: loss: 0.146423, loss_s1: 0.010295, loss_fp: 0.000593, loss_freq: 0.001050
[12:31:53.734] iteration 3514: loss: 0.198231, loss_s1: 0.045932, loss_fp: 0.000669, loss_freq: 0.047450
[12:31:54.358] iteration 3515: loss: 0.258685, loss_s1: 0.071947, loss_fp: 0.000514, loss_freq: 0.044758
[12:31:54.977] iteration 3516: loss: 0.114782, loss_s1: 0.037349, loss_fp: 0.001257, loss_freq: 0.008808
[12:31:55.596] iteration 3517: loss: 0.304173, loss_s1: 0.091922, loss_fp: 0.000634, loss_freq: 0.146604
[12:31:56.214] iteration 3518: loss: 0.266627, loss_s1: 0.107738, loss_fp: 0.013738, loss_freq: 0.057146
[12:31:56.841] iteration 3519: loss: 0.219440, loss_s1: 0.039295, loss_fp: 0.002620, loss_freq: 0.012036
[12:31:57.495] iteration 3520: loss: 0.224099, loss_s1: 0.140001, loss_fp: 0.000650, loss_freq: 0.001572
[12:31:58.153] iteration 3521: loss: 0.190486, loss_s1: 0.043337, loss_fp: 0.000759, loss_freq: 0.000528
[12:31:58.816] iteration 3522: loss: 0.113151, loss_s1: 0.049821, loss_fp: 0.000855, loss_freq: 0.009697
[12:31:59.468] iteration 3523: loss: 0.182814, loss_s1: 0.042629, loss_fp: 0.000495, loss_freq: 0.000790
[12:32:00.089] iteration 3524: loss: 0.147771, loss_s1: 0.013531, loss_fp: 0.000653, loss_freq: 0.018516
[12:32:00.710] iteration 3525: loss: 0.146398, loss_s1: 0.097472, loss_fp: 0.001324, loss_freq: 0.001507
[12:32:01.330] iteration 3526: loss: 0.247841, loss_s1: 0.059170, loss_fp: 0.000928, loss_freq: 0.037151
[12:32:01.954] iteration 3527: loss: 0.107198, loss_s1: 0.055386, loss_fp: 0.000491, loss_freq: 0.001037
[12:32:02.572] iteration 3528: loss: 0.169011, loss_s1: 0.083005, loss_fp: 0.000862, loss_freq: 0.000720
[12:32:03.199] iteration 3529: loss: 0.290439, loss_s1: 0.140648, loss_fp: 0.000970, loss_freq: 0.198831
[12:32:03.820] iteration 3530: loss: 0.099673, loss_s1: 0.014110, loss_fp: 0.000690, loss_freq: 0.006197
[12:32:04.481] iteration 3531: loss: 0.215093, loss_s1: 0.020936, loss_fp: 0.000466, loss_freq: 0.002352
[12:32:05.105] iteration 3532: loss: 0.129953, loss_s1: 0.015819, loss_fp: 0.000433, loss_freq: 0.002616
[12:32:05.726] iteration 3533: loss: 0.264008, loss_s1: 0.110070, loss_fp: 0.000638, loss_freq: 0.161864
[12:32:06.350] iteration 3534: loss: 0.147705, loss_s1: 0.120138, loss_fp: 0.000952, loss_freq: 0.001200
[12:32:06.969] iteration 3535: loss: 0.137874, loss_s1: 0.023137, loss_fp: 0.000687, loss_freq: 0.010671
[12:32:07.595] iteration 3536: loss: 0.237899, loss_s1: 0.135006, loss_fp: 0.001441, loss_freq: 0.036890
[12:32:08.224] iteration 3537: loss: 0.257521, loss_s1: 0.114969, loss_fp: 0.001944, loss_freq: 0.021947
[12:32:08.844] iteration 3538: loss: 0.185922, loss_s1: 0.052527, loss_fp: 0.000718, loss_freq: 0.004416
[12:32:09.474] iteration 3539: loss: 0.340356, loss_s1: 0.186774, loss_fp: 0.001028, loss_freq: 0.287932
[12:32:10.097] iteration 3540: loss: 0.113927, loss_s1: 0.088457, loss_fp: 0.008468, loss_freq: 0.005459
[12:32:10.720] iteration 3541: loss: 0.165408, loss_s1: 0.023546, loss_fp: 0.000405, loss_freq: 0.006330
[12:32:11.343] iteration 3542: loss: 0.157098, loss_s1: 0.022105, loss_fp: 0.000489, loss_freq: 0.018843
[12:32:11.962] iteration 3543: loss: 0.152851, loss_s1: 0.026391, loss_fp: 0.000741, loss_freq: 0.000414
[12:32:12.598] iteration 3544: loss: 0.131359, loss_s1: 0.000523, loss_fp: 0.000255, loss_freq: 0.012863
[12:32:13.225] iteration 3545: loss: 0.258422, loss_s1: 0.174498, loss_fp: 0.000836, loss_freq: 0.028928
[12:32:13.848] iteration 3546: loss: 0.096503, loss_s1: 0.038242, loss_fp: 0.000665, loss_freq: 0.024711
[12:32:14.476] iteration 3547: loss: 0.363751, loss_s1: 0.151401, loss_fp: 0.000761, loss_freq: 0.004486
[12:32:15.095] iteration 3548: loss: 0.138422, loss_s1: 0.066010, loss_fp: 0.000739, loss_freq: 0.001207
[12:32:15.719] iteration 3549: loss: 0.145889, loss_s1: 0.042593, loss_fp: 0.000494, loss_freq: 0.000775
[12:32:16.342] iteration 3550: loss: 0.178726, loss_s1: 0.047797, loss_fp: 0.001177, loss_freq: 0.009677
[12:32:16.961] iteration 3551: loss: 0.066651, loss_s1: 0.011795, loss_fp: 0.002068, loss_freq: 0.002608
[12:32:17.596] iteration 3552: loss: 0.216671, loss_s1: 0.092974, loss_fp: 0.001134, loss_freq: 0.028006
[12:32:18.214] iteration 3553: loss: 0.177406, loss_s1: 0.048243, loss_fp: 0.000706, loss_freq: 0.026221
[12:32:18.833] iteration 3554: loss: 0.206037, loss_s1: 0.016879, loss_fp: 0.001611, loss_freq: 0.000838
[12:32:19.444] iteration 3555: loss: 0.230371, loss_s1: 0.073972, loss_fp: 0.001224, loss_freq: 0.000431
[12:32:20.075] iteration 3556: loss: 0.104473, loss_s1: 0.060903, loss_fp: 0.000591, loss_freq: 0.000527
[12:32:20.757] iteration 3557: loss: 0.114639, loss_s1: 0.014335, loss_fp: 0.000482, loss_freq: 0.001462
[12:32:21.409] iteration 3558: loss: 0.197749, loss_s1: 0.080068, loss_fp: 0.001119, loss_freq: 0.000797
[12:32:22.065] iteration 3559: loss: 0.157809, loss_s1: 0.055606, loss_fp: 0.000539, loss_freq: 0.025138
[12:32:22.739] iteration 3560: loss: 0.086136, loss_s1: 0.019119, loss_fp: 0.000598, loss_freq: 0.001036
[12:32:23.352] iteration 3561: loss: 0.255333, loss_s1: 0.152772, loss_fp: 0.009037, loss_freq: 0.062923
[12:32:23.972] iteration 3562: loss: 0.117220, loss_s1: 0.059040, loss_fp: 0.001532, loss_freq: 0.007836
[12:32:24.585] iteration 3563: loss: 0.137594, loss_s1: 0.035357, loss_fp: 0.000710, loss_freq: 0.000659
[12:32:25.234] iteration 3564: loss: 0.251065, loss_s1: 0.076422, loss_fp: 0.000909, loss_freq: 0.109992
[12:32:25.861] iteration 3565: loss: 0.138988, loss_s1: 0.035799, loss_fp: 0.000649, loss_freq: 0.002438
[12:32:26.471] iteration 3566: loss: 0.258761, loss_s1: 0.068916, loss_fp: 0.000693, loss_freq: 0.002137
[12:32:27.092] iteration 3567: loss: 0.183118, loss_s1: 0.060611, loss_fp: 0.005085, loss_freq: 0.024949
[12:32:27.721] iteration 3568: loss: 0.117937, loss_s1: 0.045378, loss_fp: 0.001041, loss_freq: 0.001147
[12:32:28.331] iteration 3569: loss: 0.132599, loss_s1: 0.044807, loss_fp: 0.000822, loss_freq: 0.015123
[12:32:28.952] iteration 3570: loss: 0.186895, loss_s1: 0.104213, loss_fp: 0.000783, loss_freq: 0.001477
[12:32:29.569] iteration 3571: loss: 0.121438, loss_s1: 0.075811, loss_fp: 0.001104, loss_freq: 0.008045
[12:32:30.183] iteration 3572: loss: 0.180654, loss_s1: 0.055680, loss_fp: 0.000704, loss_freq: 0.000868
[12:32:30.807] iteration 3573: loss: 0.180192, loss_s1: 0.025947, loss_fp: 0.000629, loss_freq: 0.014389
[12:32:31.421] iteration 3574: loss: 0.249571, loss_s1: 0.195670, loss_fp: 0.000875, loss_freq: 0.120073
[12:32:32.035] iteration 3575: loss: 0.076494, loss_s1: 0.015819, loss_fp: 0.000720, loss_freq: 0.006906
[12:32:33.039] iteration 3576: loss: 0.142497, loss_s1: 0.014603, loss_fp: 0.000761, loss_freq: 0.001169
[12:32:33.691] iteration 3577: loss: 0.156905, loss_s1: 0.140014, loss_fp: 0.000713, loss_freq: 0.017521
[12:32:34.338] iteration 3578: loss: 0.073906, loss_s1: 0.019131, loss_fp: 0.000648, loss_freq: 0.001673
[12:32:34.963] iteration 3579: loss: 0.158630, loss_s1: 0.019011, loss_fp: 0.000654, loss_freq: 0.001164
[12:32:35.573] iteration 3580: loss: 0.166425, loss_s1: 0.038294, loss_fp: 0.000824, loss_freq: 0.048477
[12:32:36.193] iteration 3581: loss: 0.147304, loss_s1: 0.071486, loss_fp: 0.000891, loss_freq: 0.007086
[12:32:36.816] iteration 3582: loss: 0.156548, loss_s1: 0.052051, loss_fp: 0.001740, loss_freq: 0.107636
[12:32:37.430] iteration 3583: loss: 0.316226, loss_s1: 0.085829, loss_fp: 0.000956, loss_freq: 0.075171
[12:32:38.049] iteration 3584: loss: 0.080980, loss_s1: 0.022024, loss_fp: 0.000497, loss_freq: 0.005883
[12:32:38.671] iteration 3585: loss: 0.395426, loss_s1: 0.052322, loss_fp: 0.000787, loss_freq: 0.006991
[12:32:39.326] iteration 3586: loss: 0.158937, loss_s1: 0.056764, loss_fp: 0.000756, loss_freq: 0.004717
[12:32:39.982] iteration 3587: loss: 0.140553, loss_s1: 0.005945, loss_fp: 0.001036, loss_freq: 0.018506
[12:32:40.646] iteration 3588: loss: 0.162664, loss_s1: 0.069516, loss_fp: 0.000864, loss_freq: 0.000836
[12:32:41.284] iteration 3589: loss: 0.073270, loss_s1: 0.008463, loss_fp: 0.000751, loss_freq: 0.022609
[12:32:41.901] iteration 3590: loss: 0.175273, loss_s1: 0.068613, loss_fp: 0.000627, loss_freq: 0.016352
[12:32:42.519] iteration 3591: loss: 0.130480, loss_s1: 0.007297, loss_fp: 0.000583, loss_freq: 0.002904
[12:32:43.151] iteration 3592: loss: 0.272569, loss_s1: 0.043522, loss_fp: 0.000629, loss_freq: 0.030340
[12:32:43.761] iteration 3593: loss: 0.179981, loss_s1: 0.010324, loss_fp: 0.002089, loss_freq: 0.010537
[12:32:44.421] iteration 3594: loss: 0.114976, loss_s1: 0.003574, loss_fp: 0.000572, loss_freq: 0.001142
[12:32:45.078] iteration 3595: loss: 0.147077, loss_s1: 0.038691, loss_fp: 0.000836, loss_freq: 0.003128
[12:32:45.735] iteration 3596: loss: 0.173293, loss_s1: 0.007559, loss_fp: 0.000873, loss_freq: 0.002547
[12:32:46.400] iteration 3597: loss: 0.141794, loss_s1: 0.027413, loss_fp: 0.001270, loss_freq: 0.001590
[12:32:47.052] iteration 3598: loss: 0.168588, loss_s1: 0.113806, loss_fp: 0.010012, loss_freq: 0.015298
[12:32:47.702] iteration 3599: loss: 0.142387, loss_s1: 0.016907, loss_fp: 0.000728, loss_freq: 0.004577
[12:32:48.332] iteration 3600: loss: 0.087601, loss_s1: 0.026299, loss_fp: 0.001245, loss_freq: 0.001965
[12:32:51.466] iteration 3600 : mean_dice : 0.512564
[12:32:52.166] iteration 3601: loss: 0.276044, loss_s1: 0.292851, loss_fp: 0.000522, loss_freq: 0.018581
[12:32:52.795] iteration 3602: loss: 0.190938, loss_s1: 0.088329, loss_fp: 0.000533, loss_freq: 0.000825
[12:32:53.422] iteration 3603: loss: 0.106959, loss_s1: 0.025802, loss_fp: 0.000895, loss_freq: 0.012695
[12:32:54.046] iteration 3604: loss: 0.238330, loss_s1: 0.017921, loss_fp: 0.000604, loss_freq: 0.006784
[12:32:54.671] iteration 3605: loss: 0.159744, loss_s1: 0.040621, loss_fp: 0.000612, loss_freq: 0.007732
[12:32:55.290] iteration 3606: loss: 0.122500, loss_s1: 0.042504, loss_fp: 0.000641, loss_freq: 0.000503
[12:32:55.942] iteration 3607: loss: 0.117278, loss_s1: 0.068481, loss_fp: 0.000490, loss_freq: 0.001782
[12:32:56.565] iteration 3608: loss: 0.143814, loss_s1: 0.011577, loss_fp: 0.000586, loss_freq: 0.000468
[12:32:57.184] iteration 3609: loss: 0.181421, loss_s1: 0.155537, loss_fp: 0.001083, loss_freq: 0.043547
[12:32:57.798] iteration 3610: loss: 0.243381, loss_s1: 0.110786, loss_fp: 0.000594, loss_freq: 0.013365
[12:32:58.422] iteration 3611: loss: 0.176943, loss_s1: 0.044077, loss_fp: 0.002854, loss_freq: 0.004967
[12:32:59.041] iteration 3612: loss: 0.215908, loss_s1: 0.181605, loss_fp: 0.001234, loss_freq: 0.049840
[12:32:59.668] iteration 3613: loss: 0.083564, loss_s1: 0.035030, loss_fp: 0.000648, loss_freq: 0.002266
[12:33:00.288] iteration 3614: loss: 0.156586, loss_s1: 0.050129, loss_fp: 0.000555, loss_freq: 0.009113
[12:33:00.912] iteration 3615: loss: 0.113918, loss_s1: 0.001721, loss_fp: 0.000401, loss_freq: 0.000844
[12:33:01.525] iteration 3616: loss: 0.129684, loss_s1: 0.015935, loss_fp: 0.000595, loss_freq: 0.002122
[12:33:02.139] iteration 3617: loss: 0.075024, loss_s1: 0.031797, loss_fp: 0.000621, loss_freq: 0.002818
[12:33:02.750] iteration 3618: loss: 0.161959, loss_s1: 0.069293, loss_fp: 0.000730, loss_freq: 0.001345
[12:33:03.371] iteration 3619: loss: 0.094541, loss_s1: 0.024743, loss_fp: 0.000624, loss_freq: 0.011815
[12:33:03.993] iteration 3620: loss: 0.339451, loss_s1: 0.047196, loss_fp: 0.000990, loss_freq: 0.061171
[12:33:04.611] iteration 3621: loss: 0.129235, loss_s1: 0.022303, loss_fp: 0.000641, loss_freq: 0.011247
[12:33:05.232] iteration 3622: loss: 0.160911, loss_s1: 0.008567, loss_fp: 0.000573, loss_freq: 0.049328
[12:33:05.846] iteration 3623: loss: 0.188409, loss_s1: 0.036036, loss_fp: 0.000784, loss_freq: 0.004879
[12:33:06.458] iteration 3624: loss: 0.098317, loss_s1: 0.097743, loss_fp: 0.000695, loss_freq: 0.002166
[12:33:07.072] iteration 3625: loss: 0.189237, loss_s1: 0.065995, loss_fp: 0.000768, loss_freq: 0.016787
[12:33:07.691] iteration 3626: loss: 0.132413, loss_s1: 0.023341, loss_fp: 0.001958, loss_freq: 0.002659
[12:33:08.310] iteration 3627: loss: 0.246462, loss_s1: 0.045991, loss_fp: 0.000878, loss_freq: 0.027399
[12:33:08.932] iteration 3628: loss: 0.138986, loss_s1: 0.031638, loss_fp: 0.002607, loss_freq: 0.003223
[12:33:09.546] iteration 3629: loss: 0.189771, loss_s1: 0.108160, loss_fp: 0.004179, loss_freq: 0.004019
[12:33:10.168] iteration 3630: loss: 0.153038, loss_s1: 0.062880, loss_fp: 0.000719, loss_freq: 0.007622
[12:33:10.793] iteration 3631: loss: 0.239222, loss_s1: 0.165015, loss_fp: 0.000818, loss_freq: 0.024812
[12:33:11.584] iteration 3632: loss: 0.232940, loss_s1: 0.100406, loss_fp: 0.000616, loss_freq: 0.145541
[12:33:12.459] iteration 3633: loss: 0.093817, loss_s1: 0.011341, loss_fp: 0.000811, loss_freq: 0.020954
[12:33:13.219] iteration 3634: loss: 0.187226, loss_s1: 0.051284, loss_fp: 0.000653, loss_freq: 0.044276
[12:33:13.943] iteration 3635: loss: 0.170220, loss_s1: 0.072835, loss_fp: 0.000752, loss_freq: 0.097606
[12:33:14.553] iteration 3636: loss: 0.156483, loss_s1: 0.039372, loss_fp: 0.000531, loss_freq: 0.028049
[12:33:15.169] iteration 3637: loss: 0.209838, loss_s1: 0.168508, loss_fp: 0.000520, loss_freq: 0.000806
[12:33:15.785] iteration 3638: loss: 0.237393, loss_s1: 0.198792, loss_fp: 0.000744, loss_freq: 0.047221
[12:33:16.409] iteration 3639: loss: 0.332809, loss_s1: 0.126421, loss_fp: 0.000648, loss_freq: 0.006482
[12:33:17.030] iteration 3640: loss: 0.213890, loss_s1: 0.044054, loss_fp: 0.000661, loss_freq: 0.008247
[12:33:17.649] iteration 3641: loss: 0.159231, loss_s1: 0.070773, loss_fp: 0.000692, loss_freq: 0.005484
[12:33:18.297] iteration 3642: loss: 0.195860, loss_s1: 0.126303, loss_fp: 0.003565, loss_freq: 0.000992
[12:33:18.953] iteration 3643: loss: 0.173026, loss_s1: 0.060087, loss_fp: 0.000870, loss_freq: 0.009293
[12:33:19.563] iteration 3644: loss: 0.128309, loss_s1: 0.062555, loss_fp: 0.000466, loss_freq: 0.027082
[12:33:20.178] iteration 3645: loss: 0.177712, loss_s1: 0.032813, loss_fp: 0.001654, loss_freq: 0.011364
[12:33:20.786] iteration 3646: loss: 0.151566, loss_s1: 0.026381, loss_fp: 0.000853, loss_freq: 0.014735
[12:33:21.397] iteration 3647: loss: 0.132197, loss_s1: 0.083294, loss_fp: 0.001176, loss_freq: 0.000801
[12:33:22.008] iteration 3648: loss: 0.141506, loss_s1: 0.059469, loss_fp: 0.001744, loss_freq: 0.092964
[12:33:22.620] iteration 3649: loss: 0.212613, loss_s1: 0.120529, loss_fp: 0.000827, loss_freq: 0.038788
[12:33:23.241] iteration 3650: loss: 0.189477, loss_s1: 0.048582, loss_fp: 0.001250, loss_freq: 0.105152
[12:33:23.848] iteration 3651: loss: 0.133291, loss_s1: 0.021609, loss_fp: 0.000597, loss_freq: 0.002033
[12:33:24.473] iteration 3652: loss: 0.099962, loss_s1: 0.031957, loss_fp: 0.001034, loss_freq: 0.000833
[12:33:25.122] iteration 3653: loss: 0.135096, loss_s1: 0.030493, loss_fp: 0.000638, loss_freq: 0.003017
[12:33:25.784] iteration 3654: loss: 0.169321, loss_s1: 0.111274, loss_fp: 0.001306, loss_freq: 0.028799
[12:33:26.442] iteration 3655: loss: 0.321761, loss_s1: 0.042715, loss_fp: 0.000698, loss_freq: 0.001629
[12:33:27.080] iteration 3656: loss: 0.156614, loss_s1: 0.021878, loss_fp: 0.001027, loss_freq: 0.002221
[12:33:27.687] iteration 3657: loss: 0.192762, loss_s1: 0.025033, loss_fp: 0.000558, loss_freq: 0.061481
[12:33:28.308] iteration 3658: loss: 0.156918, loss_s1: 0.005106, loss_fp: 0.001403, loss_freq: 0.005826
[12:33:28.928] iteration 3659: loss: 0.071714, loss_s1: 0.028896, loss_fp: 0.000879, loss_freq: 0.000686
[12:33:29.547] iteration 3660: loss: 0.244817, loss_s1: 0.131412, loss_fp: 0.000990, loss_freq: 0.042258
[12:33:30.170] iteration 3661: loss: 0.177902, loss_s1: 0.069432, loss_fp: 0.001465, loss_freq: 0.028468
[12:33:30.795] iteration 3662: loss: 0.202911, loss_s1: 0.021394, loss_fp: 0.000533, loss_freq: 0.001013
[12:33:31.415] iteration 3663: loss: 0.131001, loss_s1: 0.007704, loss_fp: 0.000864, loss_freq: 0.002706
[12:33:32.027] iteration 3664: loss: 0.148175, loss_s1: 0.032294, loss_fp: 0.001680, loss_freq: 0.000608
[12:33:32.643] iteration 3665: loss: 0.125633, loss_s1: 0.020327, loss_fp: 0.000643, loss_freq: 0.006723
[12:33:33.259] iteration 3666: loss: 0.177302, loss_s1: 0.019676, loss_fp: 0.000944, loss_freq: 0.000583
[12:33:33.873] iteration 3667: loss: 0.221177, loss_s1: 0.227156, loss_fp: 0.000526, loss_freq: 0.020378
[12:33:34.490] iteration 3668: loss: 0.063945, loss_s1: 0.011126, loss_fp: 0.000687, loss_freq: 0.002883
[12:33:35.108] iteration 3669: loss: 0.211894, loss_s1: 0.112104, loss_fp: 0.000502, loss_freq: 0.022714
[12:33:35.722] iteration 3670: loss: 0.093994, loss_s1: 0.030975, loss_fp: 0.000856, loss_freq: 0.000919
[12:33:36.341] iteration 3671: loss: 0.140623, loss_s1: 0.045360, loss_fp: 0.000811, loss_freq: 0.005818
[12:33:36.958] iteration 3672: loss: 0.417494, loss_s1: 0.415089, loss_fp: 0.000677, loss_freq: 0.122124
[12:33:37.572] iteration 3673: loss: 0.116651, loss_s1: 0.012460, loss_fp: 0.000810, loss_freq: 0.038158
[12:33:38.189] iteration 3674: loss: 0.246044, loss_s1: 0.079777, loss_fp: 0.001217, loss_freq: 0.013111
[12:33:38.800] iteration 3675: loss: 0.175960, loss_s1: 0.025085, loss_fp: 0.001971, loss_freq: 0.019549
[12:33:39.414] iteration 3676: loss: 0.264190, loss_s1: 0.064401, loss_fp: 0.001554, loss_freq: 0.211819
[12:33:40.037] iteration 3677: loss: 0.120289, loss_s1: 0.001933, loss_fp: 0.000776, loss_freq: 0.001398
[12:33:40.660] iteration 3678: loss: 0.204872, loss_s1: 0.106487, loss_fp: 0.000815, loss_freq: 0.031753
[12:33:41.284] iteration 3679: loss: 0.196755, loss_s1: 0.010957, loss_fp: 0.002464, loss_freq: 0.080371
[12:33:41.903] iteration 3680: loss: 0.222529, loss_s1: 0.036831, loss_fp: 0.001217, loss_freq: 0.014422
[12:33:42.514] iteration 3681: loss: 0.213648, loss_s1: 0.058793, loss_fp: 0.000788, loss_freq: 0.000484
[12:33:43.134] iteration 3682: loss: 0.247608, loss_s1: 0.116194, loss_fp: 0.003254, loss_freq: 0.192241
[12:33:43.749] iteration 3683: loss: 0.095679, loss_s1: 0.032452, loss_fp: 0.000678, loss_freq: 0.004168
[12:33:44.358] iteration 3684: loss: 0.227285, loss_s1: 0.112503, loss_fp: 0.000612, loss_freq: 0.000482
[12:33:44.973] iteration 3685: loss: 0.171402, loss_s1: 0.108730, loss_fp: 0.000598, loss_freq: 0.003596
[12:33:45.590] iteration 3686: loss: 0.194295, loss_s1: 0.114665, loss_fp: 0.000636, loss_freq: 0.000825
[12:33:46.211] iteration 3687: loss: 0.139896, loss_s1: 0.051122, loss_fp: 0.000365, loss_freq: 0.018624
[12:33:46.896] iteration 3688: loss: 0.198961, loss_s1: 0.082797, loss_fp: 0.000536, loss_freq: 0.005074
[12:33:47.563] iteration 3689: loss: 0.092451, loss_s1: 0.030258, loss_fp: 0.001292, loss_freq: 0.012400
[12:33:48.212] iteration 3690: loss: 0.287474, loss_s1: 0.022333, loss_fp: 0.000896, loss_freq: 0.006238
[12:33:48.839] iteration 3691: loss: 0.134143, loss_s1: 0.110604, loss_fp: 0.000631, loss_freq: 0.011297
[12:33:49.465] iteration 3692: loss: 0.179445, loss_s1: 0.120579, loss_fp: 0.004653, loss_freq: 0.003162
[12:33:50.092] iteration 3693: loss: 0.163480, loss_s1: 0.077693, loss_fp: 0.000634, loss_freq: 0.018330
[12:33:50.713] iteration 3694: loss: 0.080917, loss_s1: 0.032580, loss_fp: 0.000929, loss_freq: 0.000624
[12:33:51.337] iteration 3695: loss: 0.173655, loss_s1: 0.056094, loss_fp: 0.000481, loss_freq: 0.013533
[12:33:51.960] iteration 3696: loss: 0.164503, loss_s1: 0.006970, loss_fp: 0.000711, loss_freq: 0.013467
[12:33:52.583] iteration 3697: loss: 0.254905, loss_s1: 0.035990, loss_fp: 0.000844, loss_freq: 0.034964
[12:33:53.209] iteration 3698: loss: 0.138825, loss_s1: 0.032163, loss_fp: 0.000585, loss_freq: 0.004067
[12:33:53.833] iteration 3699: loss: 0.152995, loss_s1: 0.085849, loss_fp: 0.001270, loss_freq: 0.018898
[12:33:54.460] iteration 3700: loss: 0.190264, loss_s1: 0.068031, loss_fp: 0.000735, loss_freq: 0.042343
[12:33:55.085] iteration 3701: loss: 0.270033, loss_s1: 0.130125, loss_fp: 0.001347, loss_freq: 0.032825
[12:33:55.727] iteration 3702: loss: 0.132508, loss_s1: 0.013720, loss_fp: 0.000611, loss_freq: 0.032349
[12:33:56.373] iteration 3703: loss: 0.096548, loss_s1: 0.070733, loss_fp: 0.000715, loss_freq: 0.007679
[12:33:57.027] iteration 3704: loss: 0.211766, loss_s1: 0.182088, loss_fp: 0.000912, loss_freq: 0.008538
[12:33:57.683] iteration 3705: loss: 0.091537, loss_s1: 0.029093, loss_fp: 0.000897, loss_freq: 0.004638
[12:33:58.309] iteration 3706: loss: 0.187177, loss_s1: 0.042242, loss_fp: 0.000973, loss_freq: 0.041312
[12:33:58.923] iteration 3707: loss: 0.203750, loss_s1: 0.013698, loss_fp: 0.001196, loss_freq: 0.043522
[12:33:59.551] iteration 3708: loss: 0.109703, loss_s1: 0.016407, loss_fp: 0.000558, loss_freq: 0.003319
[12:34:00.180] iteration 3709: loss: 0.268868, loss_s1: 0.030070, loss_fp: 0.001042, loss_freq: 0.013598
[12:34:00.812] iteration 3710: loss: 0.310880, loss_s1: 0.145608, loss_fp: 0.000575, loss_freq: 0.037651
[12:34:01.492] iteration 3711: loss: 0.129002, loss_s1: 0.087816, loss_fp: 0.000835, loss_freq: 0.001167
[12:34:02.159] iteration 3712: loss: 0.149682, loss_s1: 0.099444, loss_fp: 0.000840, loss_freq: 0.000594
[12:34:02.817] iteration 3713: loss: 0.191769, loss_s1: 0.122035, loss_fp: 0.001358, loss_freq: 0.001236
[12:34:03.482] iteration 3714: loss: 0.157898, loss_s1: 0.066835, loss_fp: 0.000741, loss_freq: 0.034797
[12:34:04.141] iteration 3715: loss: 0.180951, loss_s1: 0.041200, loss_fp: 0.000532, loss_freq: 0.002821
[12:34:04.800] iteration 3716: loss: 0.155167, loss_s1: 0.061905, loss_fp: 0.001123, loss_freq: 0.007600
[12:34:05.454] iteration 3717: loss: 0.164414, loss_s1: 0.156371, loss_fp: 0.001663, loss_freq: 0.002589
[12:34:06.074] iteration 3718: loss: 0.076807, loss_s1: 0.015651, loss_fp: 0.000614, loss_freq: 0.004306
[12:34:07.133] iteration 3719: loss: 0.178005, loss_s1: 0.018286, loss_fp: 0.000534, loss_freq: 0.002901
[12:34:07.797] iteration 3720: loss: 0.094598, loss_s1: 0.031153, loss_fp: 0.000642, loss_freq: 0.007155
[12:34:08.463] iteration 3721: loss: 0.066321, loss_s1: 0.011587, loss_fp: 0.000631, loss_freq: 0.003608
[12:34:09.116] iteration 3722: loss: 0.159491, loss_s1: 0.035697, loss_fp: 0.000732, loss_freq: 0.001145
[12:34:09.760] iteration 3723: loss: 0.184136, loss_s1: 0.075687, loss_fp: 0.003352, loss_freq: 0.021119
[12:34:10.388] iteration 3724: loss: 0.137013, loss_s1: 0.047044, loss_fp: 0.000779, loss_freq: 0.018417
[12:34:11.051] iteration 3725: loss: 0.121271, loss_s1: 0.082681, loss_fp: 0.000850, loss_freq: 0.031642
[12:34:11.661] iteration 3726: loss: 0.252513, loss_s1: 0.152593, loss_fp: 0.000753, loss_freq: 0.018008
[12:34:12.280] iteration 3727: loss: 0.088839, loss_s1: 0.009916, loss_fp: 0.000552, loss_freq: 0.010594
[12:34:12.895] iteration 3728: loss: 0.287754, loss_s1: 0.049005, loss_fp: 0.000439, loss_freq: 0.016179
[12:34:13.515] iteration 3729: loss: 0.162668, loss_s1: 0.088848, loss_fp: 0.000630, loss_freq: 0.016960
[12:34:14.144] iteration 3730: loss: 0.126736, loss_s1: 0.035378, loss_fp: 0.000549, loss_freq: 0.063380
[12:34:14.768] iteration 3731: loss: 0.156520, loss_s1: 0.097066, loss_fp: 0.000667, loss_freq: 0.008122
[12:34:15.396] iteration 3732: loss: 0.057440, loss_s1: 0.001351, loss_fp: 0.001566, loss_freq: 0.001407
[12:34:16.024] iteration 3733: loss: 0.180553, loss_s1: 0.081904, loss_fp: 0.000555, loss_freq: 0.004511
[12:34:16.649] iteration 3734: loss: 0.155771, loss_s1: 0.048214, loss_fp: 0.003132, loss_freq: 0.047909
[12:34:17.284] iteration 3735: loss: 0.288844, loss_s1: 0.025955, loss_fp: 0.000728, loss_freq: 0.051955
[12:34:17.903] iteration 3736: loss: 0.219686, loss_s1: 0.059429, loss_fp: 0.000787, loss_freq: 0.040384
[12:34:18.536] iteration 3737: loss: 0.084659, loss_s1: 0.015867, loss_fp: 0.001532, loss_freq: 0.001319
[12:34:19.159] iteration 3738: loss: 0.180609, loss_s1: 0.062932, loss_fp: 0.000736, loss_freq: 0.010078
[12:34:19.783] iteration 3739: loss: 0.182760, loss_s1: 0.019529, loss_fp: 0.000707, loss_freq: 0.000962
[12:34:20.410] iteration 3740: loss: 0.102130, loss_s1: 0.017596, loss_fp: 0.000616, loss_freq: 0.018812
[12:34:21.037] iteration 3741: loss: 0.068307, loss_s1: 0.011150, loss_fp: 0.001312, loss_freq: 0.000695
[12:34:21.669] iteration 3742: loss: 0.140643, loss_s1: 0.028623, loss_fp: 0.002758, loss_freq: 0.002746
[12:34:22.296] iteration 3743: loss: 0.100953, loss_s1: 0.044535, loss_fp: 0.001581, loss_freq: 0.002159
[12:34:22.924] iteration 3744: loss: 0.151283, loss_s1: 0.044714, loss_fp: 0.003071, loss_freq: 0.007537
[12:34:23.546] iteration 3745: loss: 0.210318, loss_s1: 0.107772, loss_fp: 0.001186, loss_freq: 0.009559
[12:34:24.166] iteration 3746: loss: 0.133052, loss_s1: 0.052302, loss_fp: 0.000799, loss_freq: 0.001797
[12:34:24.827] iteration 3747: loss: 0.255506, loss_s1: 0.046798, loss_fp: 0.000501, loss_freq: 0.001652
[12:34:25.454] iteration 3748: loss: 0.218444, loss_s1: 0.048212, loss_fp: 0.001652, loss_freq: 0.013041
[12:34:26.080] iteration 3749: loss: 0.102906, loss_s1: 0.039594, loss_fp: 0.000658, loss_freq: 0.000700
[12:34:26.705] iteration 3750: loss: 0.101019, loss_s1: 0.029956, loss_fp: 0.000583, loss_freq: 0.007351
[12:34:27.337] iteration 3751: loss: 0.185482, loss_s1: 0.139654, loss_fp: 0.000764, loss_freq: 0.003721
[12:34:27.957] iteration 3752: loss: 0.137993, loss_s1: 0.100226, loss_fp: 0.003462, loss_freq: 0.005466
[12:34:28.573] iteration 3753: loss: 0.218534, loss_s1: 0.106530, loss_fp: 0.000705, loss_freq: 0.015370
[12:34:29.227] iteration 3754: loss: 0.181266, loss_s1: 0.051356, loss_fp: 0.000733, loss_freq: 0.003248
[12:34:29.847] iteration 3755: loss: 0.174640, loss_s1: 0.149673, loss_fp: 0.000784, loss_freq: 0.006689
[12:34:30.465] iteration 3756: loss: 0.078906, loss_s1: 0.015589, loss_fp: 0.002410, loss_freq: 0.014207
[12:34:31.085] iteration 3757: loss: 0.160732, loss_s1: 0.045945, loss_fp: 0.000951, loss_freq: 0.007962
[12:34:31.696] iteration 3758: loss: 0.142191, loss_s1: 0.056055, loss_fp: 0.000644, loss_freq: 0.004839
[12:34:32.307] iteration 3759: loss: 0.164376, loss_s1: 0.057415, loss_fp: 0.000571, loss_freq: 0.003463
[12:34:32.932] iteration 3760: loss: 0.128770, loss_s1: 0.140411, loss_fp: 0.002324, loss_freq: 0.006560
[12:34:33.561] iteration 3761: loss: 0.152548, loss_s1: 0.049105, loss_fp: 0.000936, loss_freq: 0.026058
[12:34:34.181] iteration 3762: loss: 0.112231, loss_s1: 0.100711, loss_fp: 0.001111, loss_freq: 0.009397
[12:34:34.797] iteration 3763: loss: 0.287565, loss_s1: 0.024366, loss_fp: 0.000550, loss_freq: 0.003891
[12:34:35.410] iteration 3764: loss: 0.154374, loss_s1: 0.084046, loss_fp: 0.000550, loss_freq: 0.009107
[12:34:36.025] iteration 3765: loss: 0.154743, loss_s1: 0.120085, loss_fp: 0.000653, loss_freq: 0.003652
[12:34:36.663] iteration 3766: loss: 0.128276, loss_s1: 0.009701, loss_fp: 0.000645, loss_freq: 0.004397
[12:34:37.278] iteration 3767: loss: 0.073483, loss_s1: 0.028556, loss_fp: 0.001210, loss_freq: 0.003097
[12:34:37.897] iteration 3768: loss: 0.150972, loss_s1: 0.045432, loss_fp: 0.008303, loss_freq: 0.011917
[12:34:38.513] iteration 3769: loss: 0.174513, loss_s1: 0.082274, loss_fp: 0.000852, loss_freq: 0.020668
[12:34:39.141] iteration 3770: loss: 0.246953, loss_s1: 0.022268, loss_fp: 0.001549, loss_freq: 0.043187
[12:34:39.770] iteration 3771: loss: 0.164263, loss_s1: 0.097554, loss_fp: 0.001686, loss_freq: 0.027376
[12:34:40.388] iteration 3772: loss: 0.180830, loss_s1: 0.161985, loss_fp: 0.002960, loss_freq: 0.015584
[12:34:41.008] iteration 3773: loss: 0.135694, loss_s1: 0.067494, loss_fp: 0.000646, loss_freq: 0.007360
[12:34:41.631] iteration 3774: loss: 0.188949, loss_s1: 0.104249, loss_fp: 0.000621, loss_freq: 0.014253
[12:34:42.307] iteration 3775: loss: 0.257980, loss_s1: 0.229618, loss_fp: 0.000802, loss_freq: 0.073721
[12:34:42.961] iteration 3776: loss: 0.081020, loss_s1: 0.015413, loss_fp: 0.000548, loss_freq: 0.018480
[12:34:43.612] iteration 3777: loss: 0.172686, loss_s1: 0.034770, loss_fp: 0.000732, loss_freq: 0.037362
[12:34:44.261] iteration 3778: loss: 0.259483, loss_s1: 0.076383, loss_fp: 0.000776, loss_freq: 0.243691
[12:34:44.900] iteration 3779: loss: 0.155257, loss_s1: 0.038564, loss_fp: 0.000762, loss_freq: 0.003917
[12:34:45.520] iteration 3780: loss: 0.126452, loss_s1: 0.004656, loss_fp: 0.002852, loss_freq: 0.009575
[12:34:46.148] iteration 3781: loss: 0.159589, loss_s1: 0.062829, loss_fp: 0.000557, loss_freq: 0.067564
[12:34:46.773] iteration 3782: loss: 0.227103, loss_s1: 0.073201, loss_fp: 0.004058, loss_freq: 0.014879
[12:34:47.396] iteration 3783: loss: 0.141701, loss_s1: 0.028151, loss_fp: 0.000323, loss_freq: 0.001439
[12:34:48.020] iteration 3784: loss: 0.166592, loss_s1: 0.074874, loss_fp: 0.000513, loss_freq: 0.041724
[12:34:48.643] iteration 3785: loss: 0.154354, loss_s1: 0.082956, loss_fp: 0.001337, loss_freq: 0.043421
[12:34:49.264] iteration 3786: loss: 0.251220, loss_s1: 0.119471, loss_fp: 0.001265, loss_freq: 0.133342
[12:34:49.878] iteration 3787: loss: 0.170890, loss_s1: 0.038569, loss_fp: 0.001626, loss_freq: 0.045275
[12:34:50.492] iteration 3788: loss: 0.163642, loss_s1: 0.014377, loss_fp: 0.000583, loss_freq: 0.005234
[12:34:51.115] iteration 3789: loss: 0.139310, loss_s1: 0.086370, loss_fp: 0.000589, loss_freq: 0.010390
[12:34:51.727] iteration 3790: loss: 0.119846, loss_s1: 0.061669, loss_fp: 0.000566, loss_freq: 0.002801
[12:34:52.366] iteration 3791: loss: 0.124733, loss_s1: 0.083097, loss_fp: 0.001863, loss_freq: 0.037393
[12:34:52.992] iteration 3792: loss: 0.243470, loss_s1: 0.150820, loss_fp: 0.003890, loss_freq: 0.057357
[12:34:53.606] iteration 3793: loss: 0.175356, loss_s1: 0.091401, loss_fp: 0.000693, loss_freq: 0.040475
[12:34:54.225] iteration 3794: loss: 0.133729, loss_s1: 0.059409, loss_fp: 0.001555, loss_freq: 0.008781
[12:34:54.846] iteration 3795: loss: 0.103558, loss_s1: 0.049905, loss_fp: 0.001122, loss_freq: 0.005476
[12:34:55.477] iteration 3796: loss: 0.169343, loss_s1: 0.059489, loss_fp: 0.002525, loss_freq: 0.005428
[12:34:56.109] iteration 3797: loss: 0.142101, loss_s1: 0.097906, loss_fp: 0.003292, loss_freq: 0.012039
[12:34:56.734] iteration 3798: loss: 0.309118, loss_s1: 0.022138, loss_fp: 0.000699, loss_freq: 0.017661
[12:34:57.366] iteration 3799: loss: 0.119629, loss_s1: 0.009380, loss_fp: 0.000603, loss_freq: 0.000783
[12:34:58.021] iteration 3800: loss: 0.154133, loss_s1: 0.021847, loss_fp: 0.002012, loss_freq: 0.018388
[12:35:01.115] iteration 3800 : mean_dice : 0.503722
[12:35:01.831] iteration 3801: loss: 0.190705, loss_s1: 0.094125, loss_fp: 0.000969, loss_freq: 0.001961
[12:35:02.446] iteration 3802: loss: 0.084240, loss_s1: 0.023536, loss_fp: 0.000585, loss_freq: 0.004039
[12:35:03.068] iteration 3803: loss: 0.183089, loss_s1: 0.024047, loss_fp: 0.000643, loss_freq: 0.068724
[12:35:03.690] iteration 3804: loss: 0.179807, loss_s1: 0.115485, loss_fp: 0.001038, loss_freq: 0.017511
[12:35:04.306] iteration 3805: loss: 0.236456, loss_s1: 0.072772, loss_fp: 0.001021, loss_freq: 0.002992
[12:35:04.919] iteration 3806: loss: 0.125891, loss_s1: 0.011998, loss_fp: 0.000563, loss_freq: 0.003371
[12:35:05.540] iteration 3807: loss: 0.125526, loss_s1: 0.018276, loss_fp: 0.000539, loss_freq: 0.022585
[12:35:06.162] iteration 3808: loss: 0.122026, loss_s1: 0.052369, loss_fp: 0.002119, loss_freq: 0.006548
[12:35:06.810] iteration 3809: loss: 0.157238, loss_s1: 0.058467, loss_fp: 0.005089, loss_freq: 0.008604
[12:35:07.468] iteration 3810: loss: 0.101468, loss_s1: 0.020754, loss_fp: 0.000758, loss_freq: 0.019601
[12:35:08.129] iteration 3811: loss: 0.094500, loss_s1: 0.058539, loss_fp: 0.000482, loss_freq: 0.011368
[12:35:08.744] iteration 3812: loss: 0.175750, loss_s1: 0.046822, loss_fp: 0.000543, loss_freq: 0.033970
[12:35:09.365] iteration 3813: loss: 0.079468, loss_s1: 0.036401, loss_fp: 0.000899, loss_freq: 0.001116
[12:35:09.986] iteration 3814: loss: 0.149842, loss_s1: 0.044800, loss_fp: 0.001947, loss_freq: 0.001078
[12:35:10.606] iteration 3815: loss: 0.194890, loss_s1: 0.117959, loss_fp: 0.000959, loss_freq: 0.048282
[12:35:11.223] iteration 3816: loss: 0.104171, loss_s1: 0.025843, loss_fp: 0.000597, loss_freq: 0.015209
[12:35:11.848] iteration 3817: loss: 0.209474, loss_s1: 0.058726, loss_fp: 0.001478, loss_freq: 0.029309
[12:35:12.465] iteration 3818: loss: 0.141012, loss_s1: 0.017886, loss_fp: 0.000569, loss_freq: 0.002325
[12:35:13.075] iteration 3819: loss: 0.204477, loss_s1: 0.082561, loss_fp: 0.003105, loss_freq: 0.100776
[12:35:13.699] iteration 3820: loss: 0.088076, loss_s1: 0.005022, loss_fp: 0.000903, loss_freq: 0.005704
[12:35:14.322] iteration 3821: loss: 0.151084, loss_s1: 0.042262, loss_fp: 0.001197, loss_freq: 0.007598
[12:35:15.062] iteration 3822: loss: 0.155739, loss_s1: 0.073528, loss_fp: 0.002778, loss_freq: 0.067163
[12:35:15.731] iteration 3823: loss: 0.191833, loss_s1: 0.022375, loss_fp: 0.003095, loss_freq: 0.062350
[12:35:16.431] iteration 3824: loss: 0.186639, loss_s1: 0.151488, loss_fp: 0.001068, loss_freq: 0.001978
[12:35:17.089] iteration 3825: loss: 0.205168, loss_s1: 0.183598, loss_fp: 0.000581, loss_freq: 0.038426
[12:35:17.713] iteration 3826: loss: 0.053024, loss_s1: 0.013309, loss_fp: 0.000950, loss_freq: 0.002055
[12:35:18.329] iteration 3827: loss: 0.156461, loss_s1: 0.034350, loss_fp: 0.000612, loss_freq: 0.002216
[12:35:18.981] iteration 3828: loss: 0.106746, loss_s1: 0.000926, loss_fp: 0.001675, loss_freq: 0.052770
[12:35:19.600] iteration 3829: loss: 0.133436, loss_s1: 0.020969, loss_fp: 0.000423, loss_freq: 0.004405
[12:35:20.218] iteration 3830: loss: 0.101171, loss_s1: 0.083810, loss_fp: 0.001297, loss_freq: 0.013971
[12:35:20.835] iteration 3831: loss: 0.164334, loss_s1: 0.049659, loss_fp: 0.000663, loss_freq: 0.009681
[12:35:21.454] iteration 3832: loss: 0.083252, loss_s1: 0.016940, loss_fp: 0.000817, loss_freq: 0.023699
[12:35:22.138] iteration 3833: loss: 0.322534, loss_s1: 0.083090, loss_fp: 0.000913, loss_freq: 0.018630
[12:35:22.813] iteration 3834: loss: 0.134434, loss_s1: 0.026641, loss_fp: 0.003880, loss_freq: 0.005120
[12:35:23.467] iteration 3835: loss: 0.114279, loss_s1: 0.018723, loss_fp: 0.000618, loss_freq: 0.009717
[12:35:24.137] iteration 3836: loss: 0.263750, loss_s1: 0.142982, loss_fp: 0.019595, loss_freq: 0.166403
[12:35:24.757] iteration 3837: loss: 0.116226, loss_s1: 0.086543, loss_fp: 0.001422, loss_freq: 0.003997
[12:35:25.379] iteration 3838: loss: 0.211988, loss_s1: 0.030630, loss_fp: 0.001465, loss_freq: 0.034971
[12:35:25.994] iteration 3839: loss: 0.141197, loss_s1: 0.023958, loss_fp: 0.000794, loss_freq: 0.028921
[12:35:26.625] iteration 3840: loss: 0.280402, loss_s1: 0.068432, loss_fp: 0.000663, loss_freq: 0.010411
[12:35:27.245] iteration 3841: loss: 0.164071, loss_s1: 0.059936, loss_fp: 0.000532, loss_freq: 0.006656
[12:35:27.863] iteration 3842: loss: 0.116807, loss_s1: 0.052288, loss_fp: 0.000740, loss_freq: 0.006487
[12:35:28.487] iteration 3843: loss: 0.221668, loss_s1: 0.201865, loss_fp: 0.001091, loss_freq: 0.025772
[12:35:29.187] iteration 3844: loss: 0.210065, loss_s1: 0.035954, loss_fp: 0.001162, loss_freq: 0.002760
[12:35:29.848] iteration 3845: loss: 0.179467, loss_s1: 0.066216, loss_fp: 0.001194, loss_freq: 0.067567
[12:35:30.502] iteration 3846: loss: 0.106899, loss_s1: 0.076415, loss_fp: 0.001071, loss_freq: 0.015554
[12:35:31.156] iteration 3847: loss: 0.160944, loss_s1: 0.059910, loss_fp: 0.000757, loss_freq: 0.019906
[12:35:31.785] iteration 3848: loss: 0.136691, loss_s1: 0.125876, loss_fp: 0.001005, loss_freq: 0.003896
[12:35:32.409] iteration 3849: loss: 0.154945, loss_s1: 0.037991, loss_fp: 0.000482, loss_freq: 0.003850
[12:35:33.036] iteration 3850: loss: 0.207080, loss_s1: 0.079661, loss_fp: 0.000784, loss_freq: 0.044875
[12:35:33.658] iteration 3851: loss: 0.084127, loss_s1: 0.015900, loss_fp: 0.000621, loss_freq: 0.001540
[12:35:34.278] iteration 3852: loss: 0.224163, loss_s1: 0.056671, loss_fp: 0.000887, loss_freq: 0.001495
[12:35:34.936] iteration 3853: loss: 0.205719, loss_s1: 0.054274, loss_fp: 0.000473, loss_freq: 0.020275
[12:35:35.593] iteration 3854: loss: 0.119281, loss_s1: 0.054899, loss_fp: 0.000667, loss_freq: 0.017280
[12:35:36.223] iteration 3855: loss: 0.146131, loss_s1: 0.148659, loss_fp: 0.000867, loss_freq: 0.006846
[12:35:36.852] iteration 3856: loss: 0.155018, loss_s1: 0.030944, loss_fp: 0.000564, loss_freq: 0.032454
[12:35:37.478] iteration 3857: loss: 0.160024, loss_s1: 0.062841, loss_fp: 0.001094, loss_freq: 0.019454
[12:35:38.103] iteration 3858: loss: 0.240387, loss_s1: 0.046755, loss_fp: 0.000799, loss_freq: 0.041292
[12:35:38.731] iteration 3859: loss: 0.215272, loss_s1: 0.104579, loss_fp: 0.000901, loss_freq: 0.021270
[12:35:39.366] iteration 3860: loss: 0.159364, loss_s1: 0.121718, loss_fp: 0.000813, loss_freq: 0.038257
[12:35:39.981] iteration 3861: loss: 0.085717, loss_s1: 0.051010, loss_fp: 0.000599, loss_freq: 0.009457
[12:35:40.966] iteration 3862: loss: 0.172198, loss_s1: 0.055196, loss_fp: 0.000750, loss_freq: 0.003049
[12:35:41.613] iteration 3863: loss: 0.172632, loss_s1: 0.179334, loss_fp: 0.000694, loss_freq: 0.002817
[12:35:42.239] iteration 3864: loss: 0.093936, loss_s1: 0.017649, loss_fp: 0.000579, loss_freq: 0.016514
[12:35:42.865] iteration 3865: loss: 0.157717, loss_s1: 0.030160, loss_fp: 0.000859, loss_freq: 0.017432
[12:35:43.495] iteration 3866: loss: 0.140878, loss_s1: 0.014549, loss_fp: 0.000573, loss_freq: 0.055113
[12:35:44.137] iteration 3867: loss: 0.129006, loss_s1: 0.010677, loss_fp: 0.000741, loss_freq: 0.000886
[12:35:44.757] iteration 3868: loss: 0.145708, loss_s1: 0.047615, loss_fp: 0.003212, loss_freq: 0.067377
[12:35:45.386] iteration 3869: loss: 0.223841, loss_s1: 0.139254, loss_fp: 0.001833, loss_freq: 0.011394
[12:35:46.008] iteration 3870: loss: 0.136789, loss_s1: 0.033473, loss_fp: 0.000724, loss_freq: 0.027371
[12:35:46.630] iteration 3871: loss: 0.263532, loss_s1: 0.060406, loss_fp: 0.000567, loss_freq: 0.002658
[12:35:47.246] iteration 3872: loss: 0.147521, loss_s1: 0.034433, loss_fp: 0.001114, loss_freq: 0.001473
[12:35:47.903] iteration 3873: loss: 0.154894, loss_s1: 0.040154, loss_fp: 0.002102, loss_freq: 0.053541
[12:35:48.563] iteration 3874: loss: 0.131389, loss_s1: 0.006454, loss_fp: 0.000961, loss_freq: 0.004422
[12:35:49.227] iteration 3875: loss: 0.075331, loss_s1: 0.009594, loss_fp: 0.001824, loss_freq: 0.021775
[12:35:49.891] iteration 3876: loss: 0.163152, loss_s1: 0.059492, loss_fp: 0.002487, loss_freq: 0.043800
[12:35:50.546] iteration 3877: loss: 0.154045, loss_s1: 0.078934, loss_fp: 0.000979, loss_freq: 0.006629
[12:35:51.185] iteration 3878: loss: 0.256057, loss_s1: 0.030228, loss_fp: 0.000610, loss_freq: 0.020514
[12:35:51.843] iteration 3879: loss: 0.140847, loss_s1: 0.032742, loss_fp: 0.000654, loss_freq: 0.005690
[12:35:52.498] iteration 3880: loss: 0.118696, loss_s1: 0.023677, loss_fp: 0.000678, loss_freq: 0.000897
[12:35:53.123] iteration 3881: loss: 0.114539, loss_s1: 0.030086, loss_fp: 0.004334, loss_freq: 0.011808
[12:35:53.745] iteration 3882: loss: 0.196191, loss_s1: 0.016714, loss_fp: 0.000562, loss_freq: 0.004500
[12:35:54.398] iteration 3883: loss: 0.120344, loss_s1: 0.081701, loss_fp: 0.001705, loss_freq: 0.002242
[12:35:55.016] iteration 3884: loss: 0.218541, loss_s1: 0.182774, loss_fp: 0.000840, loss_freq: 0.118807
[12:35:55.639] iteration 3885: loss: 0.188922, loss_s1: 0.046121, loss_fp: 0.001503, loss_freq: 0.037995
[12:35:56.259] iteration 3886: loss: 0.123635, loss_s1: 0.074350, loss_fp: 0.000582, loss_freq: 0.003612
[12:35:56.887] iteration 3887: loss: 0.153530, loss_s1: 0.056930, loss_fp: 0.000508, loss_freq: 0.005999
[12:35:57.518] iteration 3888: loss: 0.173966, loss_s1: 0.046019, loss_fp: 0.000722, loss_freq: 0.015820
[12:35:58.139] iteration 3889: loss: 0.102371, loss_s1: 0.043924, loss_fp: 0.001082, loss_freq: 0.002667
[12:35:58.764] iteration 3890: loss: 0.240427, loss_s1: 0.056575, loss_fp: 0.001431, loss_freq: 0.012323
[12:35:59.378] iteration 3891: loss: 0.155189, loss_s1: 0.038763, loss_fp: 0.000607, loss_freq: 0.017794
[12:36:00.000] iteration 3892: loss: 0.149162, loss_s1: 0.064419, loss_fp: 0.000678, loss_freq: 0.000815
[12:36:00.626] iteration 3893: loss: 0.070296, loss_s1: 0.023299, loss_fp: 0.003696, loss_freq: 0.001547
[12:36:01.239] iteration 3894: loss: 0.091143, loss_s1: 0.017535, loss_fp: 0.000758, loss_freq: 0.023862
[12:36:01.860] iteration 3895: loss: 0.225893, loss_s1: 0.191966, loss_fp: 0.001707, loss_freq: 0.070644
[12:36:02.482] iteration 3896: loss: 0.174953, loss_s1: 0.022223, loss_fp: 0.001094, loss_freq: 0.024366
[12:36:03.109] iteration 3897: loss: 0.191371, loss_s1: 0.087925, loss_fp: 0.000493, loss_freq: 0.017780
[12:36:03.731] iteration 3898: loss: 0.146540, loss_s1: 0.088149, loss_fp: 0.000951, loss_freq: 0.034838
[12:36:04.382] iteration 3899: loss: 0.096374, loss_s1: 0.051417, loss_fp: 0.000464, loss_freq: 0.008726
[12:36:05.038] iteration 3900: loss: 0.165967, loss_s1: 0.029295, loss_fp: 0.000888, loss_freq: 0.035737
[12:36:05.691] iteration 3901: loss: 0.131853, loss_s1: 0.038837, loss_fp: 0.001672, loss_freq: 0.010011
[12:36:06.333] iteration 3902: loss: 0.169997, loss_s1: 0.103399, loss_fp: 0.000678, loss_freq: 0.005048
[12:36:06.960] iteration 3903: loss: 0.077658, loss_s1: 0.005200, loss_fp: 0.000663, loss_freq: 0.000696
[12:36:07.576] iteration 3904: loss: 0.148003, loss_s1: 0.012777, loss_fp: 0.001368, loss_freq: 0.048875
[12:36:08.190] iteration 3905: loss: 0.091963, loss_s1: 0.039979, loss_fp: 0.000647, loss_freq: 0.028009
[12:36:08.807] iteration 3906: loss: 0.252782, loss_s1: 0.006368, loss_fp: 0.001074, loss_freq: 0.019820
[12:36:09.427] iteration 3907: loss: 0.154436, loss_s1: 0.084963, loss_fp: 0.000575, loss_freq: 0.004196
[12:36:10.051] iteration 3908: loss: 0.102232, loss_s1: 0.020644, loss_fp: 0.001041, loss_freq: 0.009615
[12:36:10.669] iteration 3909: loss: 0.167293, loss_s1: 0.041028, loss_fp: 0.002495, loss_freq: 0.031816
[12:36:11.294] iteration 3910: loss: 0.127370, loss_s1: 0.096520, loss_fp: 0.001230, loss_freq: 0.052612
[12:36:11.919] iteration 3911: loss: 0.153411, loss_s1: 0.068578, loss_fp: 0.002472, loss_freq: 0.032786
[12:36:12.544] iteration 3912: loss: 0.141392, loss_s1: 0.035910, loss_fp: 0.000508, loss_freq: 0.011645
[12:36:13.168] iteration 3913: loss: 0.233140, loss_s1: 0.033875, loss_fp: 0.000752, loss_freq: 0.054904
[12:36:13.791] iteration 3914: loss: 0.173676, loss_s1: 0.049400, loss_fp: 0.000882, loss_freq: 0.008359
[12:36:14.409] iteration 3915: loss: 0.147643, loss_s1: 0.064414, loss_fp: 0.000720, loss_freq: 0.032974
[12:36:15.025] iteration 3916: loss: 0.131813, loss_s1: 0.083341, loss_fp: 0.000989, loss_freq: 0.002837
[12:36:15.641] iteration 3917: loss: 0.185637, loss_s1: 0.030089, loss_fp: 0.000704, loss_freq: 0.029328
[12:36:16.264] iteration 3918: loss: 0.199370, loss_s1: 0.137394, loss_fp: 0.002504, loss_freq: 0.059908
[12:36:16.879] iteration 3919: loss: 0.110722, loss_s1: 0.068199, loss_fp: 0.000580, loss_freq: 0.029795
[12:36:17.495] iteration 3920: loss: 0.229271, loss_s1: 0.045703, loss_fp: 0.001085, loss_freq: 0.053274
[12:36:18.112] iteration 3921: loss: 0.097657, loss_s1: 0.040877, loss_fp: 0.000881, loss_freq: 0.027036
[12:36:18.733] iteration 3922: loss: 0.163687, loss_s1: 0.021881, loss_fp: 0.000667, loss_freq: 0.031361
[12:36:19.349] iteration 3923: loss: 0.129140, loss_s1: 0.035228, loss_fp: 0.003111, loss_freq: 0.019610
[12:36:19.967] iteration 3924: loss: 0.135595, loss_s1: 0.037992, loss_fp: 0.000933, loss_freq: 0.016174
[12:36:20.582] iteration 3925: loss: 0.220852, loss_s1: 0.094904, loss_fp: 0.000561, loss_freq: 0.004244
[12:36:21.199] iteration 3926: loss: 0.150396, loss_s1: 0.042148, loss_fp: 0.000776, loss_freq: 0.001707
[12:36:21.818] iteration 3927: loss: 0.140092, loss_s1: 0.042167, loss_fp: 0.000956, loss_freq: 0.007727
[12:36:22.441] iteration 3928: loss: 0.089427, loss_s1: 0.004510, loss_fp: 0.000626, loss_freq: 0.025624
[12:36:23.058] iteration 3929: loss: 0.165602, loss_s1: 0.034908, loss_fp: 0.001024, loss_freq: 0.026940
[12:36:23.672] iteration 3930: loss: 0.156463, loss_s1: 0.024311, loss_fp: 0.000983, loss_freq: 0.027032
[12:36:24.289] iteration 3931: loss: 0.197285, loss_s1: 0.075088, loss_fp: 0.001168, loss_freq: 0.043063
[12:36:24.902] iteration 3932: loss: 0.118607, loss_s1: 0.039727, loss_fp: 0.000547, loss_freq: 0.001454
[12:36:25.514] iteration 3933: loss: 0.129636, loss_s1: 0.065103, loss_fp: 0.001612, loss_freq: 0.007903
[12:36:26.162] iteration 3934: loss: 0.129768, loss_s1: 0.057991, loss_fp: 0.001731, loss_freq: 0.043088
[12:36:26.821] iteration 3935: loss: 0.207348, loss_s1: 0.149742, loss_fp: 0.001167, loss_freq: 0.031399
[12:36:27.471] iteration 3936: loss: 0.128872, loss_s1: 0.030162, loss_fp: 0.004073, loss_freq: 0.033466
[12:36:28.137] iteration 3937: loss: 0.124972, loss_s1: 0.021485, loss_fp: 0.001214, loss_freq: 0.009526
[12:36:28.772] iteration 3938: loss: 0.106085, loss_s1: 0.020440, loss_fp: 0.000921, loss_freq: 0.009017
[12:36:29.397] iteration 3939: loss: 0.145809, loss_s1: 0.040617, loss_fp: 0.002714, loss_freq: 0.006036
[12:36:30.013] iteration 3940: loss: 0.179125, loss_s1: 0.075026, loss_fp: 0.000636, loss_freq: 0.091873
[12:36:30.632] iteration 3941: loss: 0.317359, loss_s1: 0.003582, loss_fp: 0.000416, loss_freq: 0.002371
[12:36:31.251] iteration 3942: loss: 0.116834, loss_s1: 0.012653, loss_fp: 0.001523, loss_freq: 0.014570
[12:36:31.876] iteration 3943: loss: 0.100086, loss_s1: 0.015435, loss_fp: 0.000933, loss_freq: 0.010820
[12:36:32.499] iteration 3944: loss: 0.123259, loss_s1: 0.021818, loss_fp: 0.001441, loss_freq: 0.006450
[12:36:33.163] iteration 3945: loss: 0.064979, loss_s1: 0.009038, loss_fp: 0.000965, loss_freq: 0.003064
[12:36:33.823] iteration 3946: loss: 0.201398, loss_s1: 0.047071, loss_fp: 0.000977, loss_freq: 0.036346
[12:36:34.489] iteration 3947: loss: 0.165405, loss_s1: 0.100735, loss_fp: 0.001614, loss_freq: 0.041650
[12:36:35.121] iteration 3948: loss: 0.241574, loss_s1: 0.055953, loss_fp: 0.000606, loss_freq: 0.026308
[12:36:35.738] iteration 3949: loss: 0.180485, loss_s1: 0.066807, loss_fp: 0.000820, loss_freq: 0.010955
[12:36:36.359] iteration 3950: loss: 0.103808, loss_s1: 0.017575, loss_fp: 0.000553, loss_freq: 0.023429
[12:36:36.981] iteration 3951: loss: 0.107301, loss_s1: 0.041018, loss_fp: 0.000722, loss_freq: 0.001893
[12:36:37.598] iteration 3952: loss: 0.160511, loss_s1: 0.031984, loss_fp: 0.002316, loss_freq: 0.001611
[12:36:38.259] iteration 3953: loss: 0.118811, loss_s1: 0.019900, loss_fp: 0.001585, loss_freq: 0.077219
[12:36:38.919] iteration 3954: loss: 0.068156, loss_s1: 0.017337, loss_fp: 0.000663, loss_freq: 0.001980
[12:36:39.575] iteration 3955: loss: 0.237213, loss_s1: 0.086643, loss_fp: 0.001216, loss_freq: 0.074581
[12:36:40.229] iteration 3956: loss: 0.089325, loss_s1: 0.039051, loss_fp: 0.000790, loss_freq: 0.001898
[12:36:40.857] iteration 3957: loss: 0.142861, loss_s1: 0.067624, loss_fp: 0.002283, loss_freq: 0.013638
[12:36:41.482] iteration 3958: loss: 0.249769, loss_s1: 0.098618, loss_fp: 0.001283, loss_freq: 0.158006
[12:36:42.108] iteration 3959: loss: 0.126923, loss_s1: 0.007238, loss_fp: 0.010053, loss_freq: 0.061597
[12:36:42.734] iteration 3960: loss: 0.149588, loss_s1: 0.002328, loss_fp: 0.000399, loss_freq: 0.013004
[12:36:43.355] iteration 3961: loss: 0.180590, loss_s1: 0.145208, loss_fp: 0.001881, loss_freq: 0.013841
[12:36:43.983] iteration 3962: loss: 0.202737, loss_s1: 0.105223, loss_fp: 0.002540, loss_freq: 0.086640
[12:36:44.609] iteration 3963: loss: 0.101853, loss_s1: 0.051143, loss_fp: 0.000592, loss_freq: 0.010657
[12:36:45.226] iteration 3964: loss: 0.130864, loss_s1: 0.021752, loss_fp: 0.000660, loss_freq: 0.004261
[12:36:45.848] iteration 3965: loss: 0.151980, loss_s1: 0.010174, loss_fp: 0.002515, loss_freq: 0.062416
[12:36:46.473] iteration 3966: loss: 0.191405, loss_s1: 0.041304, loss_fp: 0.000587, loss_freq: 0.075007
[12:36:47.099] iteration 3967: loss: 0.126174, loss_s1: 0.026105, loss_fp: 0.003198, loss_freq: 0.003252
[12:36:47.721] iteration 3968: loss: 0.176648, loss_s1: 0.070106, loss_fp: 0.001078, loss_freq: 0.130982
[12:36:48.346] iteration 3969: loss: 0.081334, loss_s1: 0.021517, loss_fp: 0.000733, loss_freq: 0.013793
[12:36:48.977] iteration 3970: loss: 0.132302, loss_s1: 0.025171, loss_fp: 0.001177, loss_freq: 0.001264
[12:36:49.594] iteration 3971: loss: 0.116395, loss_s1: 0.021639, loss_fp: 0.000852, loss_freq: 0.030072
[12:36:50.214] iteration 3972: loss: 0.127618, loss_s1: 0.039624, loss_fp: 0.000496, loss_freq: 0.001444
[12:36:50.843] iteration 3973: loss: 0.104202, loss_s1: 0.056413, loss_fp: 0.000664, loss_freq: 0.018860
[12:36:51.467] iteration 3974: loss: 0.157081, loss_s1: 0.050390, loss_fp: 0.003252, loss_freq: 0.014299
[12:36:52.107] iteration 3975: loss: 0.115715, loss_s1: 0.077447, loss_fp: 0.000562, loss_freq: 0.003350
[12:36:52.769] iteration 3976: loss: 0.332412, loss_s1: 0.087722, loss_fp: 0.000509, loss_freq: 0.010655
[12:36:53.424] iteration 3977: loss: 0.148599, loss_s1: 0.062249, loss_fp: 0.006275, loss_freq: 0.003177
[12:36:54.046] iteration 3978: loss: 0.160182, loss_s1: 0.088259, loss_fp: 0.000973, loss_freq: 0.005908
[12:36:54.668] iteration 3979: loss: 0.155880, loss_s1: 0.065762, loss_fp: 0.003786, loss_freq: 0.014520
[12:36:55.285] iteration 3980: loss: 0.049097, loss_s1: 0.002982, loss_fp: 0.001097, loss_freq: 0.010627
[12:36:55.927] iteration 3981: loss: 0.178250, loss_s1: 0.031426, loss_fp: 0.001228, loss_freq: 0.044400
[12:36:56.547] iteration 3982: loss: 0.142983, loss_s1: 0.045040, loss_fp: 0.000941, loss_freq: 0.047620
[12:36:57.169] iteration 3983: loss: 0.240992, loss_s1: 0.038799, loss_fp: 0.000867, loss_freq: 0.064511
[12:36:57.794] iteration 3984: loss: 0.118211, loss_s1: 0.025814, loss_fp: 0.000870, loss_freq: 0.009359
[12:36:58.424] iteration 3985: loss: 0.089480, loss_s1: 0.025557, loss_fp: 0.000426, loss_freq: 0.014150
[12:36:59.053] iteration 3986: loss: 0.146153, loss_s1: 0.038151, loss_fp: 0.001628, loss_freq: 0.052461
[12:36:59.676] iteration 3987: loss: 0.195808, loss_s1: 0.068662, loss_fp: 0.003002, loss_freq: 0.017620
[12:37:00.301] iteration 3988: loss: 0.188133, loss_s1: 0.035942, loss_fp: 0.001009, loss_freq: 0.079928
[12:37:00.928] iteration 3989: loss: 0.071831, loss_s1: 0.009759, loss_fp: 0.001287, loss_freq: 0.009650
[12:37:01.558] iteration 3990: loss: 0.255024, loss_s1: 0.084967, loss_fp: 0.001019, loss_freq: 0.022474
[12:37:02.184] iteration 3991: loss: 0.103082, loss_s1: 0.039599, loss_fp: 0.002650, loss_freq: 0.012990
[12:37:02.814] iteration 3992: loss: 0.179234, loss_s1: 0.033987, loss_fp: 0.000504, loss_freq: 0.031786
[12:37:03.452] iteration 3993: loss: 0.207892, loss_s1: 0.070618, loss_fp: 0.004032, loss_freq: 0.044225
[12:37:04.078] iteration 3994: loss: 0.092062, loss_s1: 0.023664, loss_fp: 0.001254, loss_freq: 0.009124
[12:37:04.705] iteration 3995: loss: 0.195628, loss_s1: 0.014821, loss_fp: 0.003240, loss_freq: 0.019310
[12:37:05.331] iteration 3996: loss: 0.176236, loss_s1: 0.033184, loss_fp: 0.004285, loss_freq: 0.028733
[12:37:05.964] iteration 3997: loss: 0.100775, loss_s1: 0.031736, loss_fp: 0.000589, loss_freq: 0.007943
[12:37:06.614] iteration 3998: loss: 0.124088, loss_s1: 0.082943, loss_fp: 0.001015, loss_freq: 0.008165
[12:37:07.274] iteration 3999: loss: 0.139263, loss_s1: 0.045291, loss_fp: 0.003740, loss_freq: 0.010304
[12:37:07.927] iteration 4000: loss: 0.117723, loss_s1: 0.059958, loss_fp: 0.001078, loss_freq: 0.027258
[12:37:11.144] iteration 4000 : mean_dice : 0.593859
[12:37:11.794] iteration 4001: loss: 0.154142, loss_s1: 0.026418, loss_fp: 0.000618, loss_freq: 0.015619
[12:37:12.424] iteration 4002: loss: 0.134728, loss_s1: 0.020675, loss_fp: 0.001417, loss_freq: 0.021985
[12:37:13.043] iteration 4003: loss: 0.148115, loss_s1: 0.038729, loss_fp: 0.000773, loss_freq: 0.100363
[12:37:13.662] iteration 4004: loss: 0.089830, loss_s1: 0.037169, loss_fp: 0.001531, loss_freq: 0.004975
[12:37:14.617] iteration 4005: loss: 0.132939, loss_s1: 0.037450, loss_fp: 0.000622, loss_freq: 0.019834
[12:37:15.299] iteration 4006: loss: 0.132334, loss_s1: 0.127393, loss_fp: 0.001575, loss_freq: 0.001358
[12:37:15.952] iteration 4007: loss: 0.079720, loss_s1: 0.037289, loss_fp: 0.000703, loss_freq: 0.006847
[12:37:16.606] iteration 4008: loss: 0.160078, loss_s1: 0.077814, loss_fp: 0.001274, loss_freq: 0.017244
[12:37:17.260] iteration 4009: loss: 0.145781, loss_s1: 0.035693, loss_fp: 0.000886, loss_freq: 0.021107
[12:37:17.900] iteration 4010: loss: 0.103613, loss_s1: 0.011772, loss_fp: 0.001052, loss_freq: 0.003381
[12:37:18.525] iteration 4011: loss: 0.103104, loss_s1: 0.034270, loss_fp: 0.000587, loss_freq: 0.047727
[12:37:19.152] iteration 4012: loss: 0.180911, loss_s1: 0.027882, loss_fp: 0.001595, loss_freq: 0.055968
[12:37:19.866] iteration 4013: loss: 0.094594, loss_s1: 0.038418, loss_fp: 0.001174, loss_freq: 0.013278
[12:37:20.495] iteration 4014: loss: 0.306531, loss_s1: 0.027813, loss_fp: 0.000958, loss_freq: 0.036544
[12:37:21.131] iteration 4015: loss: 0.135718, loss_s1: 0.055358, loss_fp: 0.000800, loss_freq: 0.002344
[12:37:21.759] iteration 4016: loss: 0.106595, loss_s1: 0.026138, loss_fp: 0.000780, loss_freq: 0.040246
[12:37:22.387] iteration 4017: loss: 0.166105, loss_s1: 0.051066, loss_fp: 0.003053, loss_freq: 0.006671
[12:37:23.004] iteration 4018: loss: 0.077324, loss_s1: 0.047393, loss_fp: 0.000818, loss_freq: 0.009251
[12:37:23.627] iteration 4019: loss: 0.150734, loss_s1: 0.030020, loss_fp: 0.000445, loss_freq: 0.049103
[12:37:24.245] iteration 4020: loss: 0.102128, loss_s1: 0.038204, loss_fp: 0.001019, loss_freq: 0.015736
[12:37:24.872] iteration 4021: loss: 0.245497, loss_s1: 0.065287, loss_fp: 0.000762, loss_freq: 0.019601
[12:37:25.512] iteration 4022: loss: 0.154381, loss_s1: 0.023192, loss_fp: 0.000851, loss_freq: 0.019839
[12:37:26.141] iteration 4023: loss: 0.102583, loss_s1: 0.013947, loss_fp: 0.004034, loss_freq: 0.004140
[12:37:26.762] iteration 4024: loss: 0.135742, loss_s1: 0.070407, loss_fp: 0.000752, loss_freq: 0.013806
[12:37:27.386] iteration 4025: loss: 0.180065, loss_s1: 0.048110, loss_fp: 0.000570, loss_freq: 0.011912
[12:37:28.016] iteration 4026: loss: 0.099074, loss_s1: 0.040384, loss_fp: 0.000999, loss_freq: 0.003275
[12:37:28.633] iteration 4027: loss: 0.101152, loss_s1: 0.021639, loss_fp: 0.004691, loss_freq: 0.049791
[12:37:29.261] iteration 4028: loss: 0.191667, loss_s1: 0.072036, loss_fp: 0.002197, loss_freq: 0.010330
[12:37:29.886] iteration 4029: loss: 0.115965, loss_s1: 0.084750, loss_fp: 0.001268, loss_freq: 0.020604
[12:37:30.510] iteration 4030: loss: 0.187071, loss_s1: 0.079534, loss_fp: 0.001023, loss_freq: 0.028766
[12:37:31.129] iteration 4031: loss: 0.150246, loss_s1: 0.020709, loss_fp: 0.000617, loss_freq: 0.010045
[12:37:31.750] iteration 4032: loss: 0.074705, loss_s1: 0.008458, loss_fp: 0.000590, loss_freq: 0.007056
[12:37:32.389] iteration 4033: loss: 0.227686, loss_s1: 0.089772, loss_fp: 0.000674, loss_freq: 0.017217
[12:37:33.003] iteration 4034: loss: 0.177609, loss_s1: 0.069967, loss_fp: 0.000943, loss_freq: 0.035836
[12:37:33.618] iteration 4035: loss: 0.126518, loss_s1: 0.043803, loss_fp: 0.001594, loss_freq: 0.001519
[12:37:34.235] iteration 4036: loss: 0.137598, loss_s1: 0.096280, loss_fp: 0.000558, loss_freq: 0.014773
[12:37:34.854] iteration 4037: loss: 0.089118, loss_s1: 0.033894, loss_fp: 0.000717, loss_freq: 0.004968
[12:37:35.477] iteration 4038: loss: 0.171409, loss_s1: 0.082471, loss_fp: 0.004237, loss_freq: 0.061267
[12:37:36.100] iteration 4039: loss: 0.195642, loss_s1: 0.026901, loss_fp: 0.000557, loss_freq: 0.024746
[12:37:36.710] iteration 4040: loss: 0.174886, loss_s1: 0.103142, loss_fp: 0.000836, loss_freq: 0.034507
[12:37:37.324] iteration 4041: loss: 0.167087, loss_s1: 0.122475, loss_fp: 0.000860, loss_freq: 0.075603
[12:37:37.940] iteration 4042: loss: 0.076298, loss_s1: 0.022546, loss_fp: 0.004464, loss_freq: 0.016832
[12:37:38.560] iteration 4043: loss: 0.125427, loss_s1: 0.009877, loss_fp: 0.001811, loss_freq: 0.049157
[12:37:39.178] iteration 4044: loss: 0.139961, loss_s1: 0.045416, loss_fp: 0.000530, loss_freq: 0.013374
[12:37:39.790] iteration 4045: loss: 0.153704, loss_s1: 0.116020, loss_fp: 0.002775, loss_freq: 0.002171
[12:37:40.402] iteration 4046: loss: 0.081006, loss_s1: 0.047437, loss_fp: 0.000735, loss_freq: 0.013460
[12:37:41.011] iteration 4047: loss: 0.126865, loss_s1: 0.036579, loss_fp: 0.000620, loss_freq: 0.005857
[12:37:41.625] iteration 4048: loss: 0.091396, loss_s1: 0.042884, loss_fp: 0.002099, loss_freq: 0.025232
[12:37:42.239] iteration 4049: loss: 0.262341, loss_s1: 0.066101, loss_fp: 0.001292, loss_freq: 0.037568
[12:37:42.854] iteration 4050: loss: 0.131800, loss_s1: 0.017761, loss_fp: 0.000741, loss_freq: 0.034251
[12:37:43.482] iteration 4051: loss: 0.100557, loss_s1: 0.015683, loss_fp: 0.003682, loss_freq: 0.014577
[12:37:44.101] iteration 4052: loss: 0.132848, loss_s1: 0.025442, loss_fp: 0.001244, loss_freq: 0.006964
[12:37:44.714] iteration 4053: loss: 0.085284, loss_s1: 0.053403, loss_fp: 0.000819, loss_freq: 0.006563
[12:37:45.328] iteration 4054: loss: 0.123260, loss_s1: 0.023078, loss_fp: 0.003540, loss_freq: 0.022044
[12:37:45.944] iteration 4055: loss: 0.150725, loss_s1: 0.078592, loss_fp: 0.001676, loss_freq: 0.004116
[12:37:46.557] iteration 4056: loss: 0.223820, loss_s1: 0.061475, loss_fp: 0.003324, loss_freq: 0.033638
[12:37:47.168] iteration 4057: loss: 0.148441, loss_s1: 0.046052, loss_fp: 0.001185, loss_freq: 0.002617
[12:37:47.778] iteration 4058: loss: 0.138825, loss_s1: 0.016273, loss_fp: 0.000941, loss_freq: 0.005574
[12:37:48.394] iteration 4059: loss: 0.114612, loss_s1: 0.044892, loss_fp: 0.000909, loss_freq: 0.009312
[12:37:49.010] iteration 4060: loss: 0.201739, loss_s1: 0.074198, loss_fp: 0.001052, loss_freq: 0.023409
[12:37:49.625] iteration 4061: loss: 0.179429, loss_s1: 0.102740, loss_fp: 0.004803, loss_freq: 0.024559
[12:37:50.238] iteration 4062: loss: 0.060922, loss_s1: 0.022881, loss_fp: 0.000847, loss_freq: 0.004369
[12:37:50.851] iteration 4063: loss: 0.141856, loss_s1: 0.073616, loss_fp: 0.000580, loss_freq: 0.010452
[12:37:51.469] iteration 4064: loss: 0.085262, loss_s1: 0.040150, loss_fp: 0.000875, loss_freq: 0.005781
[12:37:52.085] iteration 4065: loss: 0.176621, loss_s1: 0.092338, loss_fp: 0.000930, loss_freq: 0.021870
[12:37:52.704] iteration 4066: loss: 0.132932, loss_s1: 0.022564, loss_fp: 0.000382, loss_freq: 0.006171
[12:37:53.317] iteration 4067: loss: 0.127725, loss_s1: 0.060275, loss_fp: 0.001181, loss_freq: 0.018713
[12:37:53.926] iteration 4068: loss: 0.267172, loss_s1: 0.048656, loss_fp: 0.000804, loss_freq: 0.011415
[12:37:54.546] iteration 4069: loss: 0.141715, loss_s1: 0.033781, loss_fp: 0.004479, loss_freq: 0.004943
[12:37:55.170] iteration 4070: loss: 0.132879, loss_s1: 0.030691, loss_fp: 0.003391, loss_freq: 0.017455
[12:37:55.793] iteration 4071: loss: 0.098875, loss_s1: 0.029140, loss_fp: 0.009023, loss_freq: 0.008769
[12:37:56.448] iteration 4072: loss: 0.145735, loss_s1: 0.007589, loss_fp: 0.000707, loss_freq: 0.057940
[12:37:57.104] iteration 4073: loss: 0.106141, loss_s1: 0.025409, loss_fp: 0.001944, loss_freq: 0.022310
[12:37:57.729] iteration 4074: loss: 0.143470, loss_s1: 0.006026, loss_fp: 0.000915, loss_freq: 0.004994
[12:37:58.356] iteration 4075: loss: 0.126045, loss_s1: 0.037250, loss_fp: 0.000581, loss_freq: 0.006748
[12:37:58.977] iteration 4076: loss: 0.086431, loss_s1: 0.026674, loss_fp: 0.000460, loss_freq: 0.006012
[12:37:59.600] iteration 4077: loss: 0.145054, loss_s1: 0.126963, loss_fp: 0.000819, loss_freq: 0.034988
[12:38:00.218] iteration 4078: loss: 0.169005, loss_s1: 0.044196, loss_fp: 0.001271, loss_freq: 0.044708
[12:38:00.826] iteration 4079: loss: 0.130826, loss_s1: 0.038678, loss_fp: 0.009046, loss_freq: 0.041633
[12:38:01.446] iteration 4080: loss: 0.105231, loss_s1: 0.041173, loss_fp: 0.000627, loss_freq: 0.004342
[12:38:02.062] iteration 4081: loss: 0.090516, loss_s1: 0.043941, loss_fp: 0.001090, loss_freq: 0.016289
[12:38:02.676] iteration 4082: loss: 0.159980, loss_s1: 0.063188, loss_fp: 0.000547, loss_freq: 0.009987
[12:38:03.287] iteration 4083: loss: 0.179547, loss_s1: 0.168698, loss_fp: 0.001006, loss_freq: 0.015974
[12:38:03.899] iteration 4084: loss: 0.341417, loss_s1: 0.027614, loss_fp: 0.000472, loss_freq: 0.004225
[12:38:04.513] iteration 4085: loss: 0.111956, loss_s1: 0.002515, loss_fp: 0.001618, loss_freq: 0.008486
[12:38:05.126] iteration 4086: loss: 0.120742, loss_s1: 0.011597, loss_fp: 0.000561, loss_freq: 0.030992
[12:38:05.750] iteration 4087: loss: 0.147877, loss_s1: 0.072101, loss_fp: 0.001136, loss_freq: 0.013732
[12:38:06.369] iteration 4088: loss: 0.055201, loss_s1: 0.018836, loss_fp: 0.000914, loss_freq: 0.006668
[12:38:06.987] iteration 4089: loss: 0.252241, loss_s1: 0.093753, loss_fp: 0.004011, loss_freq: 0.093555
[12:38:07.603] iteration 4090: loss: 0.120528, loss_s1: 0.055877, loss_fp: 0.000721, loss_freq: 0.032580
[12:38:08.219] iteration 4091: loss: 0.239770, loss_s1: 0.016312, loss_fp: 0.001857, loss_freq: 0.033219
[12:38:08.837] iteration 4092: loss: 0.134522, loss_s1: 0.016865, loss_fp: 0.000887, loss_freq: 0.018185
[12:38:09.460] iteration 4093: loss: 0.111088, loss_s1: 0.056759, loss_fp: 0.001589, loss_freq: 0.009716
[12:38:10.080] iteration 4094: loss: 0.120069, loss_s1: 0.027143, loss_fp: 0.007470, loss_freq: 0.024557
[12:38:10.692] iteration 4095: loss: 0.151779, loss_s1: 0.046835, loss_fp: 0.001850, loss_freq: 0.009999
[12:38:11.308] iteration 4096: loss: 0.148419, loss_s1: 0.037372, loss_fp: 0.000615, loss_freq: 0.081167
[12:38:11.927] iteration 4097: loss: 0.073096, loss_s1: 0.015232, loss_fp: 0.000687, loss_freq: 0.005325
[12:38:12.554] iteration 4098: loss: 0.151250, loss_s1: 0.042715, loss_fp: 0.001346, loss_freq: 0.051871
[12:38:13.166] iteration 4099: loss: 0.084720, loss_s1: 0.035918, loss_fp: 0.006882, loss_freq: 0.004853
[12:38:13.779] iteration 4100: loss: 0.154308, loss_s1: 0.064871, loss_fp: 0.000827, loss_freq: 0.002582
[12:38:14.397] iteration 4101: loss: 0.331910, loss_s1: 0.266526, loss_fp: 0.001882, loss_freq: 0.193154
[12:38:15.012] iteration 4102: loss: 0.128012, loss_s1: 0.049326, loss_fp: 0.008730, loss_freq: 0.023680
[12:38:15.622] iteration 4103: loss: 0.211156, loss_s1: 0.026565, loss_fp: 0.000418, loss_freq: 0.066439
[12:38:16.231] iteration 4104: loss: 0.165223, loss_s1: 0.088052, loss_fp: 0.002040, loss_freq: 0.032337
[12:38:16.842] iteration 4105: loss: 0.194983, loss_s1: 0.084670, loss_fp: 0.000763, loss_freq: 0.067561
[12:38:17.451] iteration 4106: loss: 0.076917, loss_s1: 0.002153, loss_fp: 0.000435, loss_freq: 0.005779
[12:38:18.066] iteration 4107: loss: 0.130762, loss_s1: 0.019367, loss_fp: 0.005003, loss_freq: 0.005702
[12:38:18.683] iteration 4108: loss: 0.184583, loss_s1: 0.078071, loss_fp: 0.007369, loss_freq: 0.081979
[12:38:19.304] iteration 4109: loss: 0.225320, loss_s1: 0.068470, loss_fp: 0.000743, loss_freq: 0.023305
[12:38:19.916] iteration 4110: loss: 0.112461, loss_s1: 0.044031, loss_fp: 0.000873, loss_freq: 0.010235
[12:38:20.529] iteration 4111: loss: 0.173160, loss_s1: 0.104875, loss_fp: 0.001179, loss_freq: 0.070031
[12:38:21.144] iteration 4112: loss: 0.092709, loss_s1: 0.047713, loss_fp: 0.000616, loss_freq: 0.005549
[12:38:21.759] iteration 4113: loss: 0.151083, loss_s1: 0.028875, loss_fp: 0.000846, loss_freq: 0.022592
[12:38:22.434] iteration 4114: loss: 0.121824, loss_s1: 0.012912, loss_fp: 0.000627, loss_freq: 0.037455
[12:38:23.058] iteration 4115: loss: 0.136854, loss_s1: 0.037319, loss_fp: 0.000607, loss_freq: 0.006686
[12:38:23.676] iteration 4116: loss: 0.096988, loss_s1: 0.050316, loss_fp: 0.000589, loss_freq: 0.036776
[12:38:24.334] iteration 4117: loss: 0.167349, loss_s1: 0.066670, loss_fp: 0.000500, loss_freq: 0.015353
[12:38:25.003] iteration 4118: loss: 0.108271, loss_s1: 0.075643, loss_fp: 0.002651, loss_freq: 0.002322
[12:38:25.667] iteration 4119: loss: 0.289540, loss_s1: 0.045265, loss_fp: 0.001427, loss_freq: 0.019530
[12:38:26.284] iteration 4120: loss: 0.158935, loss_s1: 0.077569, loss_fp: 0.003875, loss_freq: 0.009111
[12:38:26.902] iteration 4121: loss: 0.171701, loss_s1: 0.065851, loss_fp: 0.000940, loss_freq: 0.036720
[12:38:27.530] iteration 4122: loss: 0.134086, loss_s1: 0.034512, loss_fp: 0.005612, loss_freq: 0.033895
[12:38:28.157] iteration 4123: loss: 0.071295, loss_s1: 0.028565, loss_fp: 0.000939, loss_freq: 0.005818
[12:38:28.776] iteration 4124: loss: 0.152114, loss_s1: 0.129001, loss_fp: 0.001256, loss_freq: 0.006873
[12:38:29.393] iteration 4125: loss: 0.171612, loss_s1: 0.063161, loss_fp: 0.000726, loss_freq: 0.055671
[12:38:30.018] iteration 4126: loss: 0.207836, loss_s1: 0.023471, loss_fp: 0.003783, loss_freq: 0.029503
[12:38:30.670] iteration 4127: loss: 0.127768, loss_s1: 0.025181, loss_fp: 0.000774, loss_freq: 0.001483
[12:38:31.294] iteration 4128: loss: 0.093441, loss_s1: 0.010882, loss_fp: 0.000784, loss_freq: 0.018968
[12:38:31.911] iteration 4129: loss: 0.119188, loss_s1: 0.057862, loss_fp: 0.002157, loss_freq: 0.011683
[12:38:32.557] iteration 4130: loss: 0.217347, loss_s1: 0.107984, loss_fp: 0.001311, loss_freq: 0.033675
[12:38:33.182] iteration 4131: loss: 0.144839, loss_s1: 0.071303, loss_fp: 0.001268, loss_freq: 0.028857
[12:38:33.802] iteration 4132: loss: 0.065484, loss_s1: 0.025669, loss_fp: 0.000602, loss_freq: 0.001642
[12:38:34.421] iteration 4133: loss: 0.204803, loss_s1: 0.102025, loss_fp: 0.001394, loss_freq: 0.023844
[12:38:35.044] iteration 4134: loss: 0.086576, loss_s1: 0.035972, loss_fp: 0.003051, loss_freq: 0.014060
[12:38:35.662] iteration 4135: loss: 0.159870, loss_s1: 0.029377, loss_fp: 0.002134, loss_freq: 0.036265
[12:38:36.276] iteration 4136: loss: 0.206448, loss_s1: 0.097788, loss_fp: 0.001419, loss_freq: 0.012749
[12:38:36.899] iteration 4137: loss: 0.110950, loss_s1: 0.039169, loss_fp: 0.001717, loss_freq: 0.028315
[12:38:37.516] iteration 4138: loss: 0.255950, loss_s1: 0.143250, loss_fp: 0.000588, loss_freq: 0.013121
[12:38:38.142] iteration 4139: loss: 0.152462, loss_s1: 0.031948, loss_fp: 0.000808, loss_freq: 0.052938
[12:38:38.763] iteration 4140: loss: 0.113634, loss_s1: 0.035190, loss_fp: 0.001270, loss_freq: 0.011486
[12:38:39.375] iteration 4141: loss: 0.074539, loss_s1: 0.013690, loss_fp: 0.013369, loss_freq: 0.013790
[12:38:40.065] iteration 4142: loss: 0.146674, loss_s1: 0.037471, loss_fp: 0.005654, loss_freq: 0.007402
[12:38:40.715] iteration 4143: loss: 0.115164, loss_s1: 0.033647, loss_fp: 0.001174, loss_freq: 0.014264
[12:38:41.372] iteration 4144: loss: 0.151701, loss_s1: 0.031122, loss_fp: 0.001459, loss_freq: 0.020553
[12:38:42.024] iteration 4145: loss: 0.117307, loss_s1: 0.043694, loss_fp: 0.000992, loss_freq: 0.002324
[12:38:42.637] iteration 4146: loss: 0.108962, loss_s1: 0.044441, loss_fp: 0.003086, loss_freq: 0.043635
[12:38:43.246] iteration 4147: loss: 0.082287, loss_s1: 0.027552, loss_fp: 0.000616, loss_freq: 0.011954
[12:38:44.183] iteration 4148: loss: 0.107474, loss_s1: 0.019360, loss_fp: 0.002098, loss_freq: 0.006221
[12:38:44.813] iteration 4149: loss: 0.076651, loss_s1: 0.036887, loss_fp: 0.001994, loss_freq: 0.001743
[12:38:45.468] iteration 4150: loss: 0.117805, loss_s1: 0.074274, loss_fp: 0.000741, loss_freq: 0.018222
[12:38:46.116] iteration 4151: loss: 0.156547, loss_s1: 0.033090, loss_fp: 0.000631, loss_freq: 0.027630
[12:38:46.777] iteration 4152: loss: 0.158453, loss_s1: 0.066260, loss_fp: 0.006774, loss_freq: 0.036046
[12:38:47.401] iteration 4153: loss: 0.119901, loss_s1: 0.021835, loss_fp: 0.013200, loss_freq: 0.002019
[12:38:48.094] iteration 4154: loss: 0.097047, loss_s1: 0.062309, loss_fp: 0.000518, loss_freq: 0.057684
[12:38:48.768] iteration 4155: loss: 0.194567, loss_s1: 0.052264, loss_fp: 0.000650, loss_freq: 0.039473
[12:38:49.396] iteration 4156: loss: 0.112239, loss_s1: 0.074337, loss_fp: 0.000517, loss_freq: 0.014652
[12:38:50.013] iteration 4157: loss: 0.254963, loss_s1: 0.044564, loss_fp: 0.000692, loss_freq: 0.009037
[12:38:50.638] iteration 4158: loss: 0.150789, loss_s1: 0.079585, loss_fp: 0.000443, loss_freq: 0.009606
[12:38:51.261] iteration 4159: loss: 0.178453, loss_s1: 0.146852, loss_fp: 0.001879, loss_freq: 0.072291
[12:38:51.882] iteration 4160: loss: 0.141417, loss_s1: 0.016486, loss_fp: 0.000491, loss_freq: 0.014760
[12:38:52.499] iteration 4161: loss: 0.079820, loss_s1: 0.047600, loss_fp: 0.001223, loss_freq: 0.029460
[12:38:53.185] iteration 4162: loss: 0.187562, loss_s1: 0.078337, loss_fp: 0.001163, loss_freq: 0.027434
[12:38:53.855] iteration 4163: loss: 0.134175, loss_s1: 0.100497, loss_fp: 0.003268, loss_freq: 0.007863
[12:38:54.527] iteration 4164: loss: 0.220932, loss_s1: 0.017215, loss_fp: 0.000493, loss_freq: 0.035042
[12:38:55.197] iteration 4165: loss: 0.176271, loss_s1: 0.126706, loss_fp: 0.000832, loss_freq: 0.004194
[12:38:55.860] iteration 4166: loss: 0.102279, loss_s1: 0.064306, loss_fp: 0.001119, loss_freq: 0.004226
[12:38:56.521] iteration 4167: loss: 0.127791, loss_s1: 0.062851, loss_fp: 0.000972, loss_freq: 0.009721
[12:38:57.150] iteration 4168: loss: 0.164937, loss_s1: 0.041701, loss_fp: 0.000926, loss_freq: 0.005049
[12:38:57.778] iteration 4169: loss: 0.113397, loss_s1: 0.018876, loss_fp: 0.000602, loss_freq: 0.005699
[12:38:58.403] iteration 4170: loss: 0.099175, loss_s1: 0.042268, loss_fp: 0.000834, loss_freq: 0.018218
[12:38:59.026] iteration 4171: loss: 0.162194, loss_s1: 0.013229, loss_fp: 0.014056, loss_freq: 0.023346
[12:38:59.651] iteration 4172: loss: 0.105513, loss_s1: 0.047392, loss_fp: 0.001230, loss_freq: 0.021892
[12:39:00.307] iteration 4173: loss: 0.142073, loss_s1: 0.040037, loss_fp: 0.050746, loss_freq: 0.003858
[12:39:00.960] iteration 4174: loss: 0.148252, loss_s1: 0.042110, loss_fp: 0.000743, loss_freq: 0.014937
[12:39:01.603] iteration 4175: loss: 0.086121, loss_s1: 0.032125, loss_fp: 0.001865, loss_freq: 0.008023
[12:39:02.215] iteration 4176: loss: 0.179654, loss_s1: 0.028907, loss_fp: 0.000845, loss_freq: 0.008566
[12:39:02.831] iteration 4177: loss: 0.176434, loss_s1: 0.045001, loss_fp: 0.001103, loss_freq: 0.054557
[12:39:03.446] iteration 4178: loss: 0.093059, loss_s1: 0.007670, loss_fp: 0.001251, loss_freq: 0.014665
[12:39:04.059] iteration 4179: loss: 0.086844, loss_s1: 0.026578, loss_fp: 0.000507, loss_freq: 0.006965
[12:39:04.672] iteration 4180: loss: 0.117361, loss_s1: 0.049450, loss_fp: 0.000744, loss_freq: 0.007952
[12:39:05.301] iteration 4181: loss: 0.119509, loss_s1: 0.050750, loss_fp: 0.000987, loss_freq: 0.011975
[12:39:05.917] iteration 4182: loss: 0.219132, loss_s1: 0.055896, loss_fp: 0.001111, loss_freq: 0.024834
[12:39:06.540] iteration 4183: loss: 0.164318, loss_s1: 0.108011, loss_fp: 0.003060, loss_freq: 0.043942
[12:39:07.163] iteration 4184: loss: 0.154603, loss_s1: 0.091979, loss_fp: 0.002030, loss_freq: 0.062452
[12:39:07.779] iteration 4185: loss: 0.101853, loss_s1: 0.061227, loss_fp: 0.001281, loss_freq: 0.003156
[12:39:08.396] iteration 4186: loss: 0.140589, loss_s1: 0.040027, loss_fp: 0.000778, loss_freq: 0.041051
[12:39:09.070] iteration 4187: loss: 0.167680, loss_s1: 0.091397, loss_fp: 0.001163, loss_freq: 0.009669
[12:39:09.734] iteration 4188: loss: 0.128570, loss_s1: 0.016948, loss_fp: 0.001477, loss_freq: 0.021040
[12:39:10.390] iteration 4189: loss: 0.090447, loss_s1: 0.008699, loss_fp: 0.006121, loss_freq: 0.012637
[12:39:11.006] iteration 4190: loss: 0.146893, loss_s1: 0.039572, loss_fp: 0.000582, loss_freq: 0.018457
[12:39:11.623] iteration 4191: loss: 0.100615, loss_s1: 0.050724, loss_fp: 0.004495, loss_freq: 0.021099
[12:39:12.247] iteration 4192: loss: 0.297810, loss_s1: 0.103836, loss_fp: 0.003484, loss_freq: 0.041106
[12:39:12.869] iteration 4193: loss: 0.183878, loss_s1: 0.150366, loss_fp: 0.001174, loss_freq: 0.013556
[12:39:13.490] iteration 4194: loss: 0.081722, loss_s1: 0.007334, loss_fp: 0.002074, loss_freq: 0.006586
[12:39:14.118] iteration 4195: loss: 0.138841, loss_s1: 0.026070, loss_fp: 0.004678, loss_freq: 0.033263
[12:39:14.739] iteration 4196: loss: 0.124172, loss_s1: 0.119795, loss_fp: 0.001155, loss_freq: 0.018121
[12:39:15.364] iteration 4197: loss: 0.153288, loss_s1: 0.042979, loss_fp: 0.001281, loss_freq: 0.037259
[12:39:16.022] iteration 4198: loss: 0.124699, loss_s1: 0.006702, loss_fp: 0.001959, loss_freq: 0.011588
[12:39:16.679] iteration 4199: loss: 0.172328, loss_s1: 0.028251, loss_fp: 0.001374, loss_freq: 0.042283
[12:39:17.308] iteration 4200: loss: 0.147083, loss_s1: 0.068201, loss_fp: 0.001196, loss_freq: 0.006830
[12:39:20.637] iteration 4200 : mean_dice : 0.617169
[12:39:21.284] iteration 4201: loss: 0.121275, loss_s1: 0.015849, loss_fp: 0.001384, loss_freq: 0.018724
[12:39:21.901] iteration 4202: loss: 0.095178, loss_s1: 0.044507, loss_fp: 0.001178, loss_freq: 0.006844
[12:39:22.574] iteration 4203: loss: 0.176478, loss_s1: 0.062953, loss_fp: 0.001730, loss_freq: 0.021356
[12:39:23.241] iteration 4204: loss: 0.138595, loss_s1: 0.092896, loss_fp: 0.002047, loss_freq: 0.041827
[12:39:23.936] iteration 4205: loss: 0.088873, loss_s1: 0.018692, loss_fp: 0.000626, loss_freq: 0.014794
[12:39:24.829] iteration 4206: loss: 0.148576, loss_s1: 0.034413, loss_fp: 0.001123, loss_freq: 0.023304
[12:39:25.448] iteration 4207: loss: 0.092940, loss_s1: 0.033279, loss_fp: 0.004509, loss_freq: 0.031182
[12:39:26.068] iteration 4208: loss: 0.148846, loss_s1: 0.044586, loss_fp: 0.001127, loss_freq: 0.004308
[12:39:26.688] iteration 4209: loss: 0.155762, loss_s1: 0.053176, loss_fp: 0.000945, loss_freq: 0.043646
[12:39:27.311] iteration 4210: loss: 0.137272, loss_s1: 0.128840, loss_fp: 0.000630, loss_freq: 0.025297
[12:39:27.932] iteration 4211: loss: 0.263175, loss_s1: 0.083834, loss_fp: 0.000645, loss_freq: 0.032626
[12:39:28.550] iteration 4212: loss: 0.183708, loss_s1: 0.059416, loss_fp: 0.004530, loss_freq: 0.019842
[12:39:29.171] iteration 4213: loss: 0.132488, loss_s1: 0.007032, loss_fp: 0.001541, loss_freq: 0.012939
[12:39:29.794] iteration 4214: loss: 0.122730, loss_s1: 0.070182, loss_fp: 0.004616, loss_freq: 0.027461
[12:39:30.430] iteration 4215: loss: 0.138624, loss_s1: 0.050785, loss_fp: 0.001509, loss_freq: 0.042125
[12:39:31.058] iteration 4216: loss: 0.110468, loss_s1: 0.076791, loss_fp: 0.000886, loss_freq: 0.015256
[12:39:31.712] iteration 4217: loss: 0.151845, loss_s1: 0.017513, loss_fp: 0.001688, loss_freq: 0.015065
[12:39:32.368] iteration 4218: loss: 0.136822, loss_s1: 0.030073, loss_fp: 0.003679, loss_freq: 0.009966
[12:39:33.015] iteration 4219: loss: 0.095944, loss_s1: 0.040874, loss_fp: 0.000891, loss_freq: 0.007932
[12:39:33.646] iteration 4220: loss: 0.109119, loss_s1: 0.029589, loss_fp: 0.004019, loss_freq: 0.042846
[12:39:34.319] iteration 4221: loss: 0.116291, loss_s1: 0.018426, loss_fp: 0.002324, loss_freq: 0.011799
[12:39:34.948] iteration 4222: loss: 0.146375, loss_s1: 0.069724, loss_fp: 0.000837, loss_freq: 0.034302
[12:39:35.574] iteration 4223: loss: 0.092063, loss_s1: 0.018081, loss_fp: 0.001269, loss_freq: 0.008679
[12:39:36.205] iteration 4224: loss: 0.069596, loss_s1: 0.033976, loss_fp: 0.000915, loss_freq: 0.016964
[12:39:36.828] iteration 4225: loss: 0.143802, loss_s1: 0.040707, loss_fp: 0.001800, loss_freq: 0.014410
[12:39:37.475] iteration 4226: loss: 0.165321, loss_s1: 0.103213, loss_fp: 0.002314, loss_freq: 0.087867
[12:39:38.122] iteration 4227: loss: 0.270187, loss_s1: 0.060205, loss_fp: 0.001153, loss_freq: 0.011849
[12:39:38.825] iteration 4228: loss: 0.140475, loss_s1: 0.048296, loss_fp: 0.001372, loss_freq: 0.028814
[12:39:39.478] iteration 4229: loss: 0.101221, loss_s1: 0.034011, loss_fp: 0.006266, loss_freq: 0.035488
[12:39:40.100] iteration 4230: loss: 0.143965, loss_s1: 0.028529, loss_fp: 0.001183, loss_freq: 0.017807
[12:39:40.719] iteration 4231: loss: 0.072792, loss_s1: 0.040721, loss_fp: 0.001164, loss_freq: 0.004089
[12:39:41.345] iteration 4232: loss: 0.179588, loss_s1: 0.109063, loss_fp: 0.000627, loss_freq: 0.021167
[12:39:41.953] iteration 4233: loss: 0.130052, loss_s1: 0.072221, loss_fp: 0.001344, loss_freq: 0.042093
[12:39:42.570] iteration 4234: loss: 0.153361, loss_s1: 0.025716, loss_fp: 0.001155, loss_freq: 0.005093
[12:39:43.187] iteration 4235: loss: 0.125944, loss_s1: 0.021241, loss_fp: 0.001420, loss_freq: 0.016014
[12:39:43.809] iteration 4236: loss: 0.096737, loss_s1: 0.006005, loss_fp: 0.002963, loss_freq: 0.022718
[12:39:44.422] iteration 4237: loss: 0.124070, loss_s1: 0.024361, loss_fp: 0.000513, loss_freq: 0.021080
[12:39:45.046] iteration 4238: loss: 0.164313, loss_s1: 0.078019, loss_fp: 0.000603, loss_freq: 0.008381
[12:39:45.671] iteration 4239: loss: 0.170020, loss_s1: 0.100996, loss_fp: 0.002212, loss_freq: 0.027276
[12:39:46.290] iteration 4240: loss: 0.050126, loss_s1: 0.020429, loss_fp: 0.001107, loss_freq: 0.004916
[12:39:46.907] iteration 4241: loss: 0.186660, loss_s1: 0.043360, loss_fp: 0.001137, loss_freq: 0.037981
[12:39:47.527] iteration 4242: loss: 0.102262, loss_s1: 0.045078, loss_fp: 0.001872, loss_freq: 0.029153
[12:39:48.144] iteration 4243: loss: 0.130963, loss_s1: 0.039854, loss_fp: 0.000626, loss_freq: 0.011717
[12:39:48.767] iteration 4244: loss: 0.164725, loss_s1: 0.055996, loss_fp: 0.001221, loss_freq: 0.079465
[12:39:49.390] iteration 4245: loss: 0.119804, loss_s1: 0.035330, loss_fp: 0.001007, loss_freq: 0.010496
[12:39:50.011] iteration 4246: loss: 0.205580, loss_s1: 0.041049, loss_fp: 0.000608, loss_freq: 0.013666
[12:39:50.631] iteration 4247: loss: 0.126315, loss_s1: 0.016319, loss_fp: 0.004831, loss_freq: 0.026536
[12:39:51.255] iteration 4248: loss: 0.172587, loss_s1: 0.047506, loss_fp: 0.002296, loss_freq: 0.094611
[12:39:51.878] iteration 4249: loss: 0.076026, loss_s1: 0.023683, loss_fp: 0.000475, loss_freq: 0.006416
[12:39:52.505] iteration 4250: loss: 0.102030, loss_s1: 0.031682, loss_fp: 0.004213, loss_freq: 0.007955
[12:39:53.135] iteration 4251: loss: 0.170994, loss_s1: 0.077579, loss_fp: 0.001612, loss_freq: 0.051717
[12:39:53.751] iteration 4252: loss: 0.209205, loss_s1: 0.063551, loss_fp: 0.003101, loss_freq: 0.048058
[12:39:54.378] iteration 4253: loss: 0.115750, loss_s1: 0.058363, loss_fp: 0.006248, loss_freq: 0.023139
[12:39:55.004] iteration 4254: loss: 0.144930, loss_s1: 0.070288, loss_fp: 0.001805, loss_freq: 0.061499
[12:39:55.621] iteration 4255: loss: 0.127029, loss_s1: 0.069593, loss_fp: 0.000700, loss_freq: 0.045282
[12:39:56.242] iteration 4256: loss: 0.168012, loss_s1: 0.020865, loss_fp: 0.001212, loss_freq: 0.001399
[12:39:56.865] iteration 4257: loss: 0.149056, loss_s1: 0.081131, loss_fp: 0.000785, loss_freq: 0.060884
[12:39:57.488] iteration 4258: loss: 0.138526, loss_s1: 0.030324, loss_fp: 0.001872, loss_freq: 0.009925
[12:39:58.114] iteration 4259: loss: 0.081385, loss_s1: 0.062424, loss_fp: 0.003796, loss_freq: 0.010348
[12:39:58.731] iteration 4260: loss: 0.143663, loss_s1: 0.040892, loss_fp: 0.001652, loss_freq: 0.015598
[12:39:59.354] iteration 4261: loss: 0.125813, loss_s1: 0.056055, loss_fp: 0.000592, loss_freq: 0.031962
[12:39:59.973] iteration 4262: loss: 0.306618, loss_s1: 0.014922, loss_fp: 0.000591, loss_freq: 0.049778
[12:40:00.589] iteration 4263: loss: 0.138610, loss_s1: 0.052514, loss_fp: 0.005250, loss_freq: 0.012116
[12:40:01.201] iteration 4264: loss: 0.193197, loss_s1: 0.026779, loss_fp: 0.001034, loss_freq: 0.011654
[12:40:01.817] iteration 4265: loss: 0.166176, loss_s1: 0.108854, loss_fp: 0.000973, loss_freq: 0.075001
[12:40:02.429] iteration 4266: loss: 0.117059, loss_s1: 0.108571, loss_fp: 0.006839, loss_freq: 0.047403
[12:40:03.042] iteration 4267: loss: 0.127134, loss_s1: 0.045027, loss_fp: 0.002846, loss_freq: 0.026770
[12:40:03.661] iteration 4268: loss: 0.172247, loss_s1: 0.112478, loss_fp: 0.001311, loss_freq: 0.043942
[12:40:04.278] iteration 4269: loss: 0.307220, loss_s1: 0.124819, loss_fp: 0.001085, loss_freq: 0.050554
[12:40:04.891] iteration 4270: loss: 0.163722, loss_s1: 0.025634, loss_fp: 0.007255, loss_freq: 0.015959
[12:40:05.507] iteration 4271: loss: 0.135648, loss_s1: 0.062035, loss_fp: 0.001083, loss_freq: 0.014031
[12:40:06.131] iteration 4272: loss: 0.216807, loss_s1: 0.108029, loss_fp: 0.000975, loss_freq: 0.068126
[12:40:06.756] iteration 4273: loss: 0.225077, loss_s1: 0.104413, loss_fp: 0.000627, loss_freq: 0.081269
[12:40:07.378] iteration 4274: loss: 0.126491, loss_s1: 0.057322, loss_fp: 0.002182, loss_freq: 0.045392
[12:40:08.004] iteration 4275: loss: 0.072480, loss_s1: 0.038793, loss_fp: 0.000572, loss_freq: 0.009118
[12:40:08.628] iteration 4276: loss: 0.177460, loss_s1: 0.093135, loss_fp: 0.003784, loss_freq: 0.031819
[12:40:09.246] iteration 4277: loss: 0.112775, loss_s1: 0.029561, loss_fp: 0.001027, loss_freq: 0.003391
[12:40:09.872] iteration 4278: loss: 0.135696, loss_s1: 0.074029, loss_fp: 0.002395, loss_freq: 0.002409
[12:40:10.489] iteration 4279: loss: 0.248388, loss_s1: 0.088951, loss_fp: 0.004713, loss_freq: 0.021374
[12:40:11.109] iteration 4280: loss: 0.105162, loss_s1: 0.038208, loss_fp: 0.005896, loss_freq: 0.016706
[12:40:11.728] iteration 4281: loss: 0.174165, loss_s1: 0.051576, loss_fp: 0.002053, loss_freq: 0.004727
[12:40:12.351] iteration 4282: loss: 0.153932, loss_s1: 0.010341, loss_fp: 0.002264, loss_freq: 0.038783
[12:40:12.972] iteration 4283: loss: 0.131320, loss_s1: 0.053439, loss_fp: 0.001602, loss_freq: 0.016133
[12:40:13.595] iteration 4284: loss: 0.118226, loss_s1: 0.051116, loss_fp: 0.011130, loss_freq: 0.014636
[12:40:14.220] iteration 4285: loss: 0.135413, loss_s1: 0.093046, loss_fp: 0.002459, loss_freq: 0.003274
[12:40:14.838] iteration 4286: loss: 0.166681, loss_s1: 0.063243, loss_fp: 0.004710, loss_freq: 0.034704
[12:40:15.511] iteration 4287: loss: 0.188239, loss_s1: 0.067759, loss_fp: 0.000939, loss_freq: 0.026957
[12:40:16.159] iteration 4288: loss: 0.164307, loss_s1: 0.077324, loss_fp: 0.001101, loss_freq: 0.023949
[12:40:16.807] iteration 4289: loss: 0.120028, loss_s1: 0.089762, loss_fp: 0.000729, loss_freq: 0.018082
[12:40:17.459] iteration 4290: loss: 0.078701, loss_s1: 0.023486, loss_fp: 0.001132, loss_freq: 0.022509
[12:40:18.408] iteration 4291: loss: 0.103148, loss_s1: 0.008568, loss_fp: 0.000690, loss_freq: 0.018116
[12:40:19.086] iteration 4292: loss: 0.094316, loss_s1: 0.037488, loss_fp: 0.000591, loss_freq: 0.022869
[12:40:19.738] iteration 4293: loss: 0.106931, loss_s1: 0.054894, loss_fp: 0.001322, loss_freq: 0.016656
[12:40:20.424] iteration 4294: loss: 0.137482, loss_s1: 0.008024, loss_fp: 0.002580, loss_freq: 0.028507
[12:40:21.038] iteration 4295: loss: 0.156761, loss_s1: 0.072183, loss_fp: 0.001814, loss_freq: 0.038334
[12:40:21.652] iteration 4296: loss: 0.094493, loss_s1: 0.008687, loss_fp: 0.000898, loss_freq: 0.004890
[12:40:22.266] iteration 4297: loss: 0.116471, loss_s1: 0.061602, loss_fp: 0.009834, loss_freq: 0.057467
[12:40:22.973] iteration 4298: loss: 0.187011, loss_s1: 0.053053, loss_fp: 0.000697, loss_freq: 0.031317
[12:40:23.621] iteration 4299: loss: 0.094494, loss_s1: 0.019018, loss_fp: 0.000926, loss_freq: 0.019902
[12:40:24.275] iteration 4300: loss: 0.201237, loss_s1: 0.010704, loss_fp: 0.004209, loss_freq: 0.006273
[12:40:24.921] iteration 4301: loss: 0.102745, loss_s1: 0.037897, loss_fp: 0.001059, loss_freq: 0.007463
[12:40:25.547] iteration 4302: loss: 0.115344, loss_s1: 0.048929, loss_fp: 0.001399, loss_freq: 0.044429
[12:40:26.176] iteration 4303: loss: 0.114948, loss_s1: 0.073348, loss_fp: 0.023299, loss_freq: 0.028151
[12:40:26.811] iteration 4304: loss: 0.083664, loss_s1: 0.039459, loss_fp: 0.001673, loss_freq: 0.002281
[12:40:27.446] iteration 4305: loss: 0.130443, loss_s1: 0.041011, loss_fp: 0.000940, loss_freq: 0.030179
[12:40:28.078] iteration 4306: loss: 0.165481, loss_s1: 0.051973, loss_fp: 0.002333, loss_freq: 0.018785
[12:40:28.704] iteration 4307: loss: 0.255472, loss_s1: 0.090559, loss_fp: 0.002293, loss_freq: 0.007794
[12:40:29.337] iteration 4308: loss: 0.123229, loss_s1: 0.017543, loss_fp: 0.000606, loss_freq: 0.034001
[12:40:29.971] iteration 4309: loss: 0.063665, loss_s1: 0.012757, loss_fp: 0.000826, loss_freq: 0.022202
[12:40:30.598] iteration 4310: loss: 0.117916, loss_s1: 0.072698, loss_fp: 0.000996, loss_freq: 0.009511
[12:40:31.224] iteration 4311: loss: 0.189291, loss_s1: 0.032568, loss_fp: 0.000575, loss_freq: 0.036363
[12:40:31.851] iteration 4312: loss: 0.087405, loss_s1: 0.009769, loss_fp: 0.000643, loss_freq: 0.010974
[12:40:32.481] iteration 4313: loss: 0.197882, loss_s1: 0.150744, loss_fp: 0.000655, loss_freq: 0.072182
[12:40:33.105] iteration 4314: loss: 0.170017, loss_s1: 0.066757, loss_fp: 0.009770, loss_freq: 0.016283
[12:40:33.741] iteration 4315: loss: 0.129500, loss_s1: 0.053904, loss_fp: 0.000545, loss_freq: 0.049694
[12:40:34.361] iteration 4316: loss: 0.150390, loss_s1: 0.045345, loss_fp: 0.001202, loss_freq: 0.031723
[12:40:34.993] iteration 4317: loss: 0.153683, loss_s1: 0.073698, loss_fp: 0.000911, loss_freq: 0.036898
[12:40:35.626] iteration 4318: loss: 0.098592, loss_s1: 0.045577, loss_fp: 0.001076, loss_freq: 0.012610
[12:40:36.251] iteration 4319: loss: 0.233541, loss_s1: 0.031811, loss_fp: 0.000579, loss_freq: 0.061663
[12:40:36.877] iteration 4320: loss: 0.155968, loss_s1: 0.044089, loss_fp: 0.001721, loss_freq: 0.018992
[12:40:37.500] iteration 4321: loss: 0.099477, loss_s1: 0.022649, loss_fp: 0.000616, loss_freq: 0.006031
[12:40:38.131] iteration 4322: loss: 0.076335, loss_s1: 0.016126, loss_fp: 0.002253, loss_freq: 0.017122
[12:40:38.758] iteration 4323: loss: 0.125018, loss_s1: 0.026928, loss_fp: 0.001155, loss_freq: 0.018586
[12:40:39.392] iteration 4324: loss: 0.131138, loss_s1: 0.098404, loss_fp: 0.001526, loss_freq: 0.031260
[12:40:40.023] iteration 4325: loss: 0.185601, loss_s1: 0.032614, loss_fp: 0.001355, loss_freq: 0.012998
[12:40:40.646] iteration 4326: loss: 0.180337, loss_s1: 0.044075, loss_fp: 0.000812, loss_freq: 0.049815
[12:40:41.270] iteration 4327: loss: 0.140978, loss_s1: 0.059356, loss_fp: 0.006113, loss_freq: 0.050554
[12:40:41.894] iteration 4328: loss: 0.073838, loss_s1: 0.061845, loss_fp: 0.001670, loss_freq: 0.006897
[12:40:42.518] iteration 4329: loss: 0.131452, loss_s1: 0.057248, loss_fp: 0.001525, loss_freq: 0.037258
[12:40:43.140] iteration 4330: loss: 0.136830, loss_s1: 0.036353, loss_fp: 0.007457, loss_freq: 0.041856
[12:40:43.769] iteration 4331: loss: 0.163119, loss_s1: 0.055090, loss_fp: 0.000946, loss_freq: 0.016758
[12:40:44.399] iteration 4332: loss: 0.074853, loss_s1: 0.049261, loss_fp: 0.002005, loss_freq: 0.021453
[12:40:45.027] iteration 4333: loss: 0.140764, loss_s1: 0.033930, loss_fp: 0.001422, loss_freq: 0.031350
[12:40:45.660] iteration 4334: loss: 0.103690, loss_s1: 0.062598, loss_fp: 0.003309, loss_freq: 0.021153
[12:40:46.307] iteration 4335: loss: 0.242402, loss_s1: 0.024419, loss_fp: 0.002065, loss_freq: 0.013596
[12:40:46.942] iteration 4336: loss: 0.126581, loss_s1: 0.056918, loss_fp: 0.000897, loss_freq: 0.003786
[12:40:47.582] iteration 4337: loss: 0.116986, loss_s1: 0.053528, loss_fp: 0.001540, loss_freq: 0.013839
[12:40:48.223] iteration 4338: loss: 0.103609, loss_s1: 0.010646, loss_fp: 0.001779, loss_freq: 0.027803
[12:40:48.855] iteration 4339: loss: 0.070616, loss_s1: 0.043241, loss_fp: 0.007205, loss_freq: 0.019296
[12:40:49.490] iteration 4340: loss: 0.166564, loss_s1: 0.108813, loss_fp: 0.005329, loss_freq: 0.056238
[12:40:50.103] iteration 4341: loss: 0.149785, loss_s1: 0.065023, loss_fp: 0.008598, loss_freq: 0.004735
[12:40:50.722] iteration 4342: loss: 0.241647, loss_s1: 0.020453, loss_fp: 0.000683, loss_freq: 0.062066
[12:40:51.345] iteration 4343: loss: 0.132565, loss_s1: 0.043805, loss_fp: 0.001224, loss_freq: 0.007066
[12:40:51.962] iteration 4344: loss: 0.099355, loss_s1: 0.044462, loss_fp: 0.002823, loss_freq: 0.005259
[12:40:52.582] iteration 4345: loss: 0.127150, loss_s1: 0.077951, loss_fp: 0.001162, loss_freq: 0.014835
[12:40:53.209] iteration 4346: loss: 0.156235, loss_s1: 0.032282, loss_fp: 0.000895, loss_freq: 0.018021
[12:40:53.828] iteration 4347: loss: 0.132124, loss_s1: 0.100858, loss_fp: 0.000962, loss_freq: 0.033858
[12:40:54.468] iteration 4348: loss: 0.076955, loss_s1: 0.059022, loss_fp: 0.001334, loss_freq: 0.001891
[12:40:55.102] iteration 4349: loss: 0.159694, loss_s1: 0.061960, loss_fp: 0.000744, loss_freq: 0.027514
[12:40:55.739] iteration 4350: loss: 0.090035, loss_s1: 0.034329, loss_fp: 0.012578, loss_freq: 0.016882
[12:40:56.390] iteration 4351: loss: 0.132520, loss_s1: 0.063676, loss_fp: 0.001022, loss_freq: 0.008370
[12:40:57.031] iteration 4352: loss: 0.149777, loss_s1: 0.034905, loss_fp: 0.002116, loss_freq: 0.008144
[12:40:57.669] iteration 4353: loss: 0.150042, loss_s1: 0.090200, loss_fp: 0.008350, loss_freq: 0.027662
[12:40:58.286] iteration 4354: loss: 0.144884, loss_s1: 0.021620, loss_fp: 0.001502, loss_freq: 0.018399
[12:40:58.906] iteration 4355: loss: 0.125875, loss_s1: 0.052416, loss_fp: 0.001455, loss_freq: 0.019770
[12:40:59.530] iteration 4356: loss: 0.150807, loss_s1: 0.045593, loss_fp: 0.003015, loss_freq: 0.015793
[12:41:00.154] iteration 4357: loss: 0.100352, loss_s1: 0.039905, loss_fp: 0.000524, loss_freq: 0.014012
[12:41:00.775] iteration 4358: loss: 0.181619, loss_s1: 0.154928, loss_fp: 0.002332, loss_freq: 0.050906
[12:41:01.391] iteration 4359: loss: 0.187086, loss_s1: 0.086251, loss_fp: 0.004554, loss_freq: 0.029768
[12:41:02.013] iteration 4360: loss: 0.172662, loss_s1: 0.052488, loss_fp: 0.004134, loss_freq: 0.011151
[12:41:02.640] iteration 4361: loss: 0.135907, loss_s1: 0.025771, loss_fp: 0.002370, loss_freq: 0.026695
[12:41:03.256] iteration 4362: loss: 0.071186, loss_s1: 0.021906, loss_fp: 0.001907, loss_freq: 0.001683
[12:41:03.880] iteration 4363: loss: 0.154266, loss_s1: 0.095728, loss_fp: 0.001007, loss_freq: 0.068505
[12:41:04.497] iteration 4364: loss: 0.196152, loss_s1: 0.153743, loss_fp: 0.050827, loss_freq: 0.014399
[12:41:05.157] iteration 4365: loss: 0.168826, loss_s1: 0.116868, loss_fp: 0.003112, loss_freq: 0.064857
[12:41:05.782] iteration 4366: loss: 0.138180, loss_s1: 0.095674, loss_fp: 0.000994, loss_freq: 0.010356
[12:41:06.443] iteration 4367: loss: 0.099715, loss_s1: 0.069008, loss_fp: 0.015323, loss_freq: 0.031125
[12:41:07.112] iteration 4368: loss: 0.133599, loss_s1: 0.030204, loss_fp: 0.001225, loss_freq: 0.008959
[12:41:07.789] iteration 4369: loss: 0.151772, loss_s1: 0.107576, loss_fp: 0.007690, loss_freq: 0.046127
[12:41:08.469] iteration 4370: loss: 0.271067, loss_s1: 0.047326, loss_fp: 0.001938, loss_freq: 0.029739
[12:41:09.128] iteration 4371: loss: 0.147356, loss_s1: 0.058551, loss_fp: 0.002989, loss_freq: 0.021079
[12:41:09.784] iteration 4372: loss: 0.091835, loss_s1: 0.032156, loss_fp: 0.001249, loss_freq: 0.010617
[12:41:10.441] iteration 4373: loss: 0.122131, loss_s1: 0.030658, loss_fp: 0.000521, loss_freq: 0.021192
[12:41:11.097] iteration 4374: loss: 0.063319, loss_s1: 0.031933, loss_fp: 0.006295, loss_freq: 0.014813
[12:41:11.748] iteration 4375: loss: 0.102624, loss_s1: 0.043653, loss_fp: 0.001960, loss_freq: 0.012082
[12:41:12.404] iteration 4376: loss: 0.150598, loss_s1: 0.064399, loss_fp: 0.001708, loss_freq: 0.061144
[12:41:13.057] iteration 4377: loss: 0.179885, loss_s1: 0.024848, loss_fp: 0.001523, loss_freq: 0.014302
[12:41:13.677] iteration 4378: loss: 0.117415, loss_s1: 0.033901, loss_fp: 0.001548, loss_freq: 0.007979
[12:41:14.291] iteration 4379: loss: 0.097165, loss_s1: 0.046142, loss_fp: 0.000877, loss_freq: 0.007501
[12:41:14.916] iteration 4380: loss: 0.092636, loss_s1: 0.037439, loss_fp: 0.003996, loss_freq: 0.015229
[12:41:15.541] iteration 4381: loss: 0.139601, loss_s1: 0.017977, loss_fp: 0.002609, loss_freq: 0.003082
[12:41:16.167] iteration 4382: loss: 0.171910, loss_s1: 0.077204, loss_fp: 0.004020, loss_freq: 0.050873
[12:41:16.789] iteration 4383: loss: 0.089911, loss_s1: 0.060181, loss_fp: 0.001795, loss_freq: 0.003731
[12:41:17.448] iteration 4384: loss: 0.140290, loss_s1: 0.017720, loss_fp: 0.000745, loss_freq: 0.046281
[12:41:18.109] iteration 4385: loss: 0.100128, loss_s1: 0.024144, loss_fp: 0.004120, loss_freq: 0.002512
[12:41:18.768] iteration 4386: loss: 0.123253, loss_s1: 0.041799, loss_fp: 0.000539, loss_freq: 0.013655
[12:41:19.397] iteration 4387: loss: 0.179491, loss_s1: 0.111008, loss_fp: 0.001991, loss_freq: 0.089113
[12:41:20.020] iteration 4388: loss: 0.110800, loss_s1: 0.028181, loss_fp: 0.000806, loss_freq: 0.049595
[12:41:20.659] iteration 4389: loss: 0.191838, loss_s1: 0.052574, loss_fp: 0.000575, loss_freq: 0.030894
[12:41:21.282] iteration 4390: loss: 0.180975, loss_s1: 0.039217, loss_fp: 0.002911, loss_freq: 0.112365
[12:41:21.909] iteration 4391: loss: 0.183287, loss_s1: 0.037560, loss_fp: 0.002723, loss_freq: 0.114076
[12:41:22.531] iteration 4392: loss: 0.092416, loss_s1: 0.019441, loss_fp: 0.001196, loss_freq: 0.017867
[12:41:23.154] iteration 4393: loss: 0.129329, loss_s1: 0.021869, loss_fp: 0.001561, loss_freq: 0.007088
[12:41:23.779] iteration 4394: loss: 0.116851, loss_s1: 0.024979, loss_fp: 0.002775, loss_freq: 0.030823
[12:41:24.406] iteration 4395: loss: 0.173997, loss_s1: 0.046259, loss_fp: 0.000787, loss_freq: 0.028689
[12:41:25.032] iteration 4396: loss: 0.114238, loss_s1: 0.018653, loss_fp: 0.001428, loss_freq: 0.019187
[12:41:25.657] iteration 4397: loss: 0.117580, loss_s1: 0.025315, loss_fp: 0.000867, loss_freq: 0.064456
[12:41:26.344] iteration 4398: loss: 0.096667, loss_s1: 0.057129, loss_fp: 0.001137, loss_freq: 0.012245
[12:41:26.966] iteration 4399: loss: 0.160199, loss_s1: 0.049667, loss_fp: 0.000931, loss_freq: 0.007838
[12:41:27.668] iteration 4400: loss: 0.165448, loss_s1: 0.117366, loss_fp: 0.002786, loss_freq: 0.035224
[12:41:30.985] iteration 4400 : mean_dice : 0.647895
[12:41:31.640] iteration 4401: loss: 0.154624, loss_s1: 0.071466, loss_fp: 0.000653, loss_freq: 0.014690
[12:41:32.253] iteration 4402: loss: 0.118711, loss_s1: 0.072441, loss_fp: 0.002446, loss_freq: 0.035146
[12:41:32.876] iteration 4403: loss: 0.144551, loss_s1: 0.062288, loss_fp: 0.000933, loss_freq: 0.018514
[12:41:33.503] iteration 4404: loss: 0.112281, loss_s1: 0.072808, loss_fp: 0.005662, loss_freq: 0.022548
[12:41:34.131] iteration 4405: loss: 0.285656, loss_s1: 0.068203, loss_fp: 0.000865, loss_freq: 0.045307
[12:41:34.748] iteration 4406: loss: 0.175501, loss_s1: 0.102096, loss_fp: 0.003970, loss_freq: 0.022433
[12:41:35.368] iteration 4407: loss: 0.108645, loss_s1: 0.040652, loss_fp: 0.003690, loss_freq: 0.029945
[12:41:35.986] iteration 4408: loss: 0.124538, loss_s1: 0.037697, loss_fp: 0.001746, loss_freq: 0.034618
[12:41:36.609] iteration 4409: loss: 0.061087, loss_s1: 0.015661, loss_fp: 0.005131, loss_freq: 0.004381
[12:41:37.245] iteration 4410: loss: 0.113194, loss_s1: 0.073257, loss_fp: 0.001163, loss_freq: 0.032126
[12:41:37.870] iteration 4411: loss: 0.195758, loss_s1: 0.072755, loss_fp: 0.000739, loss_freq: 0.083457
[12:41:38.488] iteration 4412: loss: 0.243925, loss_s1: 0.141184, loss_fp: 0.000855, loss_freq: 0.018686
[12:41:39.111] iteration 4413: loss: 0.127962, loss_s1: 0.051925, loss_fp: 0.001531, loss_freq: 0.017855
[12:41:39.739] iteration 4414: loss: 0.139484, loss_s1: 0.092746, loss_fp: 0.008114, loss_freq: 0.041744
[12:41:40.363] iteration 4415: loss: 0.120979, loss_s1: 0.054221, loss_fp: 0.000875, loss_freq: 0.051581
[12:41:40.980] iteration 4416: loss: 0.138675, loss_s1: 0.019300, loss_fp: 0.000630, loss_freq: 0.011913
[12:41:41.595] iteration 4417: loss: 0.109795, loss_s1: 0.007862, loss_fp: 0.000970, loss_freq: 0.038969
[12:41:42.214] iteration 4418: loss: 0.097109, loss_s1: 0.042996, loss_fp: 0.000956, loss_freq: 0.014618
[12:41:42.840] iteration 4419: loss: 0.167686, loss_s1: 0.110388, loss_fp: 0.004056, loss_freq: 0.034474
[12:41:43.463] iteration 4420: loss: 0.071565, loss_s1: 0.039253, loss_fp: 0.001101, loss_freq: 0.002359
[12:41:44.088] iteration 4421: loss: 0.143723, loss_s1: 0.078765, loss_fp: 0.001223, loss_freq: 0.011560
[12:41:44.714] iteration 4422: loss: 0.224358, loss_s1: 0.070393, loss_fp: 0.002192, loss_freq: 0.047627
[12:41:45.337] iteration 4423: loss: 0.090814, loss_s1: 0.024709, loss_fp: 0.000783, loss_freq: 0.017353
[12:41:45.957] iteration 4424: loss: 0.169339, loss_s1: 0.028080, loss_fp: 0.001142, loss_freq: 0.013272
[12:41:46.576] iteration 4425: loss: 0.163750, loss_s1: 0.025899, loss_fp: 0.002385, loss_freq: 0.053263
[12:41:47.207] iteration 4426: loss: 0.111985, loss_s1: 0.049935, loss_fp: 0.000636, loss_freq: 0.018694
[12:41:47.865] iteration 4427: loss: 0.116346, loss_s1: 0.060731, loss_fp: 0.002031, loss_freq: 0.021749
[12:41:48.519] iteration 4428: loss: 0.141701, loss_s1: 0.051021, loss_fp: 0.005703, loss_freq: 0.031961
[12:41:49.175] iteration 4429: loss: 0.135571, loss_s1: 0.045995, loss_fp: 0.013759, loss_freq: 0.049149
[12:41:49.832] iteration 4430: loss: 0.141429, loss_s1: 0.050992, loss_fp: 0.001135, loss_freq: 0.013993
[12:41:50.492] iteration 4431: loss: 0.186534, loss_s1: 0.076405, loss_fp: 0.003328, loss_freq: 0.039524
[12:41:51.135] iteration 4432: loss: 0.159743, loss_s1: 0.133332, loss_fp: 0.002100, loss_freq: 0.045508
[12:41:51.743] iteration 4433: loss: 0.067299, loss_s1: 0.016161, loss_fp: 0.001124, loss_freq: 0.026359
[12:41:52.680] iteration 4434: loss: 0.091303, loss_s1: 0.022947, loss_fp: 0.000845, loss_freq: 0.007895
[12:41:53.290] iteration 4435: loss: 0.083233, loss_s1: 0.023807, loss_fp: 0.009847, loss_freq: 0.016984
[12:41:53.906] iteration 4436: loss: 0.096734, loss_s1: 0.040171, loss_fp: 0.001228, loss_freq: 0.033881
[12:41:54.534] iteration 4437: loss: 0.089004, loss_s1: 0.007141, loss_fp: 0.001167, loss_freq: 0.012577
[12:41:55.146] iteration 4438: loss: 0.122602, loss_s1: 0.030802, loss_fp: 0.000961, loss_freq: 0.051291
[12:41:55.761] iteration 4439: loss: 0.127399, loss_s1: 0.067776, loss_fp: 0.000830, loss_freq: 0.002698
[12:41:56.384] iteration 4440: loss: 0.115721, loss_s1: 0.055215, loss_fp: 0.000728, loss_freq: 0.093106
[12:41:56.999] iteration 4441: loss: 0.197281, loss_s1: 0.099496, loss_fp: 0.005183, loss_freq: 0.025486
[12:41:57.617] iteration 4442: loss: 0.091593, loss_s1: 0.036338, loss_fp: 0.005212, loss_freq: 0.031330
[12:41:58.230] iteration 4443: loss: 0.220139, loss_s1: 0.029845, loss_fp: 0.001894, loss_freq: 0.021003
[12:41:58.845] iteration 4444: loss: 0.131005, loss_s1: 0.052937, loss_fp: 0.001266, loss_freq: 0.035253
[12:41:59.462] iteration 4445: loss: 0.149443, loss_s1: 0.095112, loss_fp: 0.001325, loss_freq: 0.066620
[12:42:00.076] iteration 4446: loss: 0.150645, loss_s1: 0.038329, loss_fp: 0.003410, loss_freq: 0.028709
[12:42:00.696] iteration 4447: loss: 0.061193, loss_s1: 0.038580, loss_fp: 0.001014, loss_freq: 0.008761
[12:42:01.317] iteration 4448: loss: 0.119711, loss_s1: 0.034249, loss_fp: 0.001614, loss_freq: 0.034002
[12:42:01.938] iteration 4449: loss: 0.127899, loss_s1: 0.021235, loss_fp: 0.001469, loss_freq: 0.044914
[12:42:02.562] iteration 4450: loss: 0.229617, loss_s1: 0.019281, loss_fp: 0.000361, loss_freq: 0.014369
[12:42:03.182] iteration 4451: loss: 0.166676, loss_s1: 0.024500, loss_fp: 0.000886, loss_freq: 0.016702
[12:42:03.806] iteration 4452: loss: 0.115824, loss_s1: 0.041982, loss_fp: 0.002498, loss_freq: 0.016862
[12:42:04.432] iteration 4453: loss: 0.132273, loss_s1: 0.064291, loss_fp: 0.000824, loss_freq: 0.024845
[12:42:05.051] iteration 4454: loss: 0.168681, loss_s1: 0.057061, loss_fp: 0.001820, loss_freq: 0.048579
[12:42:05.681] iteration 4455: loss: 0.110301, loss_s1: 0.024089, loss_fp: 0.000337, loss_freq: 0.022405
[12:42:06.305] iteration 4456: loss: 0.086168, loss_s1: 0.039578, loss_fp: 0.002038, loss_freq: 0.017231
[12:42:06.923] iteration 4457: loss: 0.182114, loss_s1: 0.023419, loss_fp: 0.003847, loss_freq: 0.016962
[12:42:07.542] iteration 4458: loss: 0.091107, loss_s1: 0.017456, loss_fp: 0.000891, loss_freq: 0.033840
[12:42:08.174] iteration 4459: loss: 0.142493, loss_s1: 0.022444, loss_fp: 0.000644, loss_freq: 0.025948
[12:42:08.799] iteration 4460: loss: 0.206649, loss_s1: 0.095821, loss_fp: 0.005036, loss_freq: 0.042743
[12:42:09.419] iteration 4461: loss: 0.098836, loss_s1: 0.050375, loss_fp: 0.002943, loss_freq: 0.009300
[12:42:10.039] iteration 4462: loss: 0.222567, loss_s1: 0.102966, loss_fp: 0.004901, loss_freq: 0.064018
[12:42:10.653] iteration 4463: loss: 0.149702, loss_s1: 0.032090, loss_fp: 0.000764, loss_freq: 0.029511
[12:42:11.271] iteration 4464: loss: 0.094991, loss_s1: 0.018612, loss_fp: 0.001714, loss_freq: 0.012581
[12:42:11.892] iteration 4465: loss: 0.090816, loss_s1: 0.061559, loss_fp: 0.001206, loss_freq: 0.007198
[12:42:12.511] iteration 4466: loss: 0.095718, loss_s1: 0.034608, loss_fp: 0.001468, loss_freq: 0.035641
[12:42:13.131] iteration 4467: loss: 0.110099, loss_s1: 0.034411, loss_fp: 0.002661, loss_freq: 0.043956
[12:42:13.744] iteration 4468: loss: 0.155910, loss_s1: 0.040628, loss_fp: 0.002071, loss_freq: 0.014266
[12:42:14.361] iteration 4469: loss: 0.146506, loss_s1: 0.060947, loss_fp: 0.001079, loss_freq: 0.022996
[12:42:15.010] iteration 4470: loss: 0.123107, loss_s1: 0.076346, loss_fp: 0.000860, loss_freq: 0.041178
[12:42:15.623] iteration 4471: loss: 0.078651, loss_s1: 0.018859, loss_fp: 0.001903, loss_freq: 0.019801
[12:42:16.239] iteration 4472: loss: 0.133625, loss_s1: 0.014175, loss_fp: 0.003984, loss_freq: 0.055592
[12:42:16.850] iteration 4473: loss: 0.148520, loss_s1: 0.071954, loss_fp: 0.002539, loss_freq: 0.017079
[12:42:17.460] iteration 4474: loss: 0.124340, loss_s1: 0.035569, loss_fp: 0.007753, loss_freq: 0.039379
[12:42:18.079] iteration 4475: loss: 0.091075, loss_s1: 0.036532, loss_fp: 0.000648, loss_freq: 0.029343
[12:42:18.729] iteration 4476: loss: 0.116973, loss_s1: 0.041012, loss_fp: 0.002559, loss_freq: 0.015806
[12:42:19.352] iteration 4477: loss: 0.103470, loss_s1: 0.086050, loss_fp: 0.002567, loss_freq: 0.030679
[12:42:19.995] iteration 4478: loss: 0.259108, loss_s1: 0.084967, loss_fp: 0.002851, loss_freq: 0.066811
[12:42:20.633] iteration 4479: loss: 0.160232, loss_s1: 0.089433, loss_fp: 0.000588, loss_freq: 0.040979
[12:42:21.265] iteration 4480: loss: 0.159139, loss_s1: 0.057271, loss_fp: 0.001602, loss_freq: 0.017334
[12:42:21.889] iteration 4481: loss: 0.090973, loss_s1: 0.044458, loss_fp: 0.002063, loss_freq: 0.014780
[12:42:22.507] iteration 4482: loss: 0.084914, loss_s1: 0.072234, loss_fp: 0.002555, loss_freq: 0.017783
[12:42:23.133] iteration 4483: loss: 0.155384, loss_s1: 0.087651, loss_fp: 0.005213, loss_freq: 0.048590
[12:42:23.747] iteration 4484: loss: 0.134815, loss_s1: 0.050181, loss_fp: 0.000561, loss_freq: 0.018925
[12:42:24.366] iteration 4485: loss: 0.203354, loss_s1: 0.046882, loss_fp: 0.005453, loss_freq: 0.047843
[12:42:24.988] iteration 4486: loss: 0.100702, loss_s1: 0.030451, loss_fp: 0.001709, loss_freq: 0.008225
[12:42:25.604] iteration 4487: loss: 0.125201, loss_s1: 0.048557, loss_fp: 0.001210, loss_freq: 0.023526
[12:42:26.221] iteration 4488: loss: 0.093655, loss_s1: 0.052467, loss_fp: 0.001488, loss_freq: 0.021865
[12:42:26.842] iteration 4489: loss: 0.155250, loss_s1: 0.031294, loss_fp: 0.005769, loss_freq: 0.022985
[12:42:27.458] iteration 4490: loss: 0.169852, loss_s1: 0.128825, loss_fp: 0.001617, loss_freq: 0.051529
[12:42:28.088] iteration 4491: loss: 0.081129, loss_s1: 0.052538, loss_fp: 0.000783, loss_freq: 0.017113
[12:42:28.712] iteration 4492: loss: 0.190331, loss_s1: 0.078276, loss_fp: 0.001264, loss_freq: 0.019238
[12:42:29.327] iteration 4493: loss: 0.114358, loss_s1: 0.064564, loss_fp: 0.002965, loss_freq: 0.031518
[12:42:29.957] iteration 4494: loss: 0.136909, loss_s1: 0.029277, loss_fp: 0.004560, loss_freq: 0.012732
[12:42:30.571] iteration 4495: loss: 0.164229, loss_s1: 0.040902, loss_fp: 0.003098, loss_freq: 0.045092
[12:42:31.189] iteration 4496: loss: 0.141191, loss_s1: 0.062584, loss_fp: 0.002779, loss_freq: 0.033163
[12:42:31.836] iteration 4497: loss: 0.214451, loss_s1: 0.068006, loss_fp: 0.001686, loss_freq: 0.032130
[12:42:32.490] iteration 4498: loss: 0.118436, loss_s1: 0.027022, loss_fp: 0.001497, loss_freq: 0.022759
[12:42:33.112] iteration 4499: loss: 0.115960, loss_s1: 0.026449, loss_fp: 0.000948, loss_freq: 0.007630
[12:42:33.730] iteration 4500: loss: 0.105991, loss_s1: 0.076376, loss_fp: 0.002223, loss_freq: 0.022221
[12:42:34.345] iteration 4501: loss: 0.149797, loss_s1: 0.089786, loss_fp: 0.001915, loss_freq: 0.029851
[12:42:34.967] iteration 4502: loss: 0.144946, loss_s1: 0.133000, loss_fp: 0.001182, loss_freq: 0.020710
[12:42:35.644] iteration 4503: loss: 0.186151, loss_s1: 0.078772, loss_fp: 0.001319, loss_freq: 0.014742
[12:42:36.294] iteration 4504: loss: 0.107387, loss_s1: 0.035386, loss_fp: 0.003063, loss_freq: 0.005921
[12:42:36.943] iteration 4505: loss: 0.123346, loss_s1: 0.085341, loss_fp: 0.001752, loss_freq: 0.031124
[12:42:37.605] iteration 4506: loss: 0.138522, loss_s1: 0.063431, loss_fp: 0.001299, loss_freq: 0.103168
[12:42:38.258] iteration 4507: loss: 0.186758, loss_s1: 0.069406, loss_fp: 0.004506, loss_freq: 0.127918
[12:42:38.901] iteration 4508: loss: 0.175240, loss_s1: 0.081666, loss_fp: 0.017236, loss_freq: 0.050276
[12:42:39.521] iteration 4509: loss: 0.143010, loss_s1: 0.087860, loss_fp: 0.002063, loss_freq: 0.007385
[12:42:40.132] iteration 4510: loss: 0.091243, loss_s1: 0.038038, loss_fp: 0.001673, loss_freq: 0.030090
[12:42:40.742] iteration 4511: loss: 0.132574, loss_s1: 0.031814, loss_fp: 0.000460, loss_freq: 0.017043
[12:42:41.364] iteration 4512: loss: 0.178503, loss_s1: 0.116569, loss_fp: 0.003297, loss_freq: 0.109613
[12:42:41.982] iteration 4513: loss: 0.296896, loss_s1: 0.068359, loss_fp: 0.003017, loss_freq: 0.013767
[12:42:42.630] iteration 4514: loss: 0.104602, loss_s1: 0.011968, loss_fp: 0.000903, loss_freq: 0.006020
[12:42:43.282] iteration 4515: loss: 0.113388, loss_s1: 0.043844, loss_fp: 0.002645, loss_freq: 0.041960
[12:42:43.959] iteration 4516: loss: 0.149758, loss_s1: 0.033474, loss_fp: 0.003032, loss_freq: 0.005268
[12:42:44.654] iteration 4517: loss: 0.060486, loss_s1: 0.023191, loss_fp: 0.000835, loss_freq: 0.019391
[12:42:45.313] iteration 4518: loss: 0.121463, loss_s1: 0.035725, loss_fp: 0.000689, loss_freq: 0.018408
[12:42:45.968] iteration 4519: loss: 0.160733, loss_s1: 0.085579, loss_fp: 0.004310, loss_freq: 0.032117
[12:42:46.631] iteration 4520: loss: 0.241428, loss_s1: 0.026921, loss_fp: 0.000906, loss_freq: 0.015750
[12:42:47.308] iteration 4521: loss: 0.130593, loss_s1: 0.030677, loss_fp: 0.001048, loss_freq: 0.014731
[12:42:47.989] iteration 4522: loss: 0.145248, loss_s1: 0.048749, loss_fp: 0.000856, loss_freq: 0.018148
[12:42:48.661] iteration 4523: loss: 0.126449, loss_s1: 0.059436, loss_fp: 0.001233, loss_freq: 0.008555
[12:42:49.292] iteration 4524: loss: 0.130665, loss_s1: 0.022204, loss_fp: 0.001258, loss_freq: 0.012446
[12:42:49.972] iteration 4525: loss: 0.119541, loss_s1: 0.037124, loss_fp: 0.000681, loss_freq: 0.034618
[12:42:50.626] iteration 4526: loss: 0.073540, loss_s1: 0.049150, loss_fp: 0.001267, loss_freq: 0.004140
[12:42:51.277] iteration 4527: loss: 0.133071, loss_s1: 0.015988, loss_fp: 0.008216, loss_freq: 0.043972
[12:42:51.936] iteration 4528: loss: 0.089175, loss_s1: 0.037996, loss_fp: 0.001115, loss_freq: 0.006757
[12:42:52.582] iteration 4529: loss: 0.127609, loss_s1: 0.020595, loss_fp: 0.000918, loss_freq: 0.021703
[12:42:53.200] iteration 4530: loss: 0.167134, loss_s1: 0.047148, loss_fp: 0.000742, loss_freq: 0.110388
[12:42:53.813] iteration 4531: loss: 0.113948, loss_s1: 0.046074, loss_fp: 0.001357, loss_freq: 0.066944
[12:42:54.437] iteration 4532: loss: 0.208199, loss_s1: 0.042976, loss_fp: 0.001934, loss_freq: 0.041834
[12:42:55.062] iteration 4533: loss: 0.170804, loss_s1: 0.044478, loss_fp: 0.001963, loss_freq: 0.061755
[12:42:55.681] iteration 4534: loss: 0.249870, loss_s1: 0.189082, loss_fp: 0.024562, loss_freq: 0.084214
[12:42:56.339] iteration 4535: loss: 0.061501, loss_s1: 0.014488, loss_fp: 0.000746, loss_freq: 0.002659
[12:42:57.000] iteration 4536: loss: 0.105663, loss_s1: 0.018885, loss_fp: 0.001390, loss_freq: 0.012618
[12:42:57.661] iteration 4537: loss: 0.176315, loss_s1: 0.120379, loss_fp: 0.001717, loss_freq: 0.078917
[12:42:58.326] iteration 4538: loss: 0.221513, loss_s1: 0.055651, loss_fp: 0.004698, loss_freq: 0.057502
[12:42:58.951] iteration 4539: loss: 0.106037, loss_s1: 0.026325, loss_fp: 0.001322, loss_freq: 0.027819
[12:42:59.580] iteration 4540: loss: 0.204397, loss_s1: 0.158825, loss_fp: 0.002185, loss_freq: 0.123448
[12:43:00.217] iteration 4541: loss: 0.104727, loss_s1: 0.086921, loss_fp: 0.002462, loss_freq: 0.018456
[12:43:00.844] iteration 4542: loss: 0.145561, loss_s1: 0.014194, loss_fp: 0.001019, loss_freq: 0.001388
[12:43:01.472] iteration 4543: loss: 0.098241, loss_s1: 0.064258, loss_fp: 0.001046, loss_freq: 0.007780
[12:43:02.098] iteration 4544: loss: 0.113786, loss_s1: 0.032974, loss_fp: 0.002947, loss_freq: 0.006877
[12:43:02.725] iteration 4545: loss: 0.060875, loss_s1: 0.032616, loss_fp: 0.001230, loss_freq: 0.026177
[12:43:03.349] iteration 4546: loss: 0.129058, loss_s1: 0.034385, loss_fp: 0.000979, loss_freq: 0.014827
[12:43:03.975] iteration 4547: loss: 0.101595, loss_s1: 0.037695, loss_fp: 0.002960, loss_freq: 0.041848
[12:43:04.616] iteration 4548: loss: 0.332991, loss_s1: 0.079364, loss_fp: 0.004450, loss_freq: 0.018048
[12:43:05.258] iteration 4549: loss: 0.136942, loss_s1: 0.096859, loss_fp: 0.000785, loss_freq: 0.026820
[12:43:05.881] iteration 4550: loss: 0.150706, loss_s1: 0.104023, loss_fp: 0.002309, loss_freq: 0.059468
[12:43:06.509] iteration 4551: loss: 0.141443, loss_s1: 0.055871, loss_fp: 0.007517, loss_freq: 0.057708
[12:43:07.131] iteration 4552: loss: 0.123138, loss_s1: 0.083692, loss_fp: 0.015009, loss_freq: 0.047591
[12:43:07.756] iteration 4553: loss: 0.165034, loss_s1: 0.090653, loss_fp: 0.001621, loss_freq: 0.029067
[12:43:08.379] iteration 4554: loss: 0.140959, loss_s1: 0.042607, loss_fp: 0.001267, loss_freq: 0.106020
[12:43:09.004] iteration 4555: loss: 0.211786, loss_s1: 0.103262, loss_fp: 0.000894, loss_freq: 0.018252
[12:43:09.635] iteration 4556: loss: 0.118099, loss_s1: 0.059955, loss_fp: 0.002450, loss_freq: 0.021085
[12:43:10.263] iteration 4557: loss: 0.105174, loss_s1: 0.046981, loss_fp: 0.003313, loss_freq: 0.045748
[12:43:10.897] iteration 4558: loss: 0.125170, loss_s1: 0.009677, loss_fp: 0.001537, loss_freq: 0.020238
[12:43:11.522] iteration 4559: loss: 0.161236, loss_s1: 0.079814, loss_fp: 0.003708, loss_freq: 0.027518
[12:43:12.152] iteration 4560: loss: 0.126153, loss_s1: 0.022645, loss_fp: 0.001886, loss_freq: 0.054733
[12:43:12.774] iteration 4561: loss: 0.087273, loss_s1: 0.025988, loss_fp: 0.000611, loss_freq: 0.009692
[12:43:13.401] iteration 4562: loss: 0.179850, loss_s1: 0.048340, loss_fp: 0.002504, loss_freq: 0.022459
[12:43:14.029] iteration 4563: loss: 0.094383, loss_s1: 0.026946, loss_fp: 0.002333, loss_freq: 0.006792
[12:43:14.659] iteration 4564: loss: 0.152713, loss_s1: 0.038638, loss_fp: 0.004522, loss_freq: 0.004238
[12:43:15.288] iteration 4565: loss: 0.199169, loss_s1: 0.057401, loss_fp: 0.005482, loss_freq: 0.023144
[12:43:15.912] iteration 4566: loss: 0.110759, loss_s1: 0.036694, loss_fp: 0.012056, loss_freq: 0.009221
[12:43:16.535] iteration 4567: loss: 0.173403, loss_s1: 0.030944, loss_fp: 0.001331, loss_freq: 0.016296
[12:43:17.161] iteration 4568: loss: 0.182775, loss_s1: 0.055297, loss_fp: 0.001699, loss_freq: 0.053070
[12:43:17.788] iteration 4569: loss: 0.136061, loss_s1: 0.044900, loss_fp: 0.002792, loss_freq: 0.018987
[12:43:18.410] iteration 4570: loss: 0.115958, loss_s1: 0.084343, loss_fp: 0.009434, loss_freq: 0.014012
[12:43:19.040] iteration 4571: loss: 0.155065, loss_s1: 0.041320, loss_fp: 0.001461, loss_freq: 0.042090
[12:43:19.667] iteration 4572: loss: 0.113542, loss_s1: 0.060402, loss_fp: 0.001920, loss_freq: 0.022784
[12:43:20.295] iteration 4573: loss: 0.188517, loss_s1: 0.084460, loss_fp: 0.001260, loss_freq: 0.027587
[12:43:20.922] iteration 4574: loss: 0.099394, loss_s1: 0.043422, loss_fp: 0.002586, loss_freq: 0.026259
[12:43:21.544] iteration 4575: loss: 0.151894, loss_s1: 0.132640, loss_fp: 0.003936, loss_freq: 0.028788
[12:43:22.166] iteration 4576: loss: 0.095105, loss_s1: 0.024557, loss_fp: 0.002978, loss_freq: 0.030138
[12:43:23.099] iteration 4577: loss: 0.094853, loss_s1: 0.051155, loss_fp: 0.000826, loss_freq: 0.007024
[12:43:23.718] iteration 4578: loss: 0.108060, loss_s1: 0.059807, loss_fp: 0.001140, loss_freq: 0.025644
[12:43:24.342] iteration 4579: loss: 0.098034, loss_s1: 0.060929, loss_fp: 0.001696, loss_freq: 0.022720
[12:43:24.966] iteration 4580: loss: 0.142738, loss_s1: 0.064909, loss_fp: 0.008337, loss_freq: 0.011237
[12:43:25.587] iteration 4581: loss: 0.128659, loss_s1: 0.086312, loss_fp: 0.006192, loss_freq: 0.044778
[12:43:26.213] iteration 4582: loss: 0.119631, loss_s1: 0.039352, loss_fp: 0.010568, loss_freq: 0.012444
[12:43:26.830] iteration 4583: loss: 0.087866, loss_s1: 0.049479, loss_fp: 0.004393, loss_freq: 0.034562
[12:43:27.449] iteration 4584: loss: 0.195846, loss_s1: 0.081058, loss_fp: 0.016360, loss_freq: 0.028761
[12:43:28.073] iteration 4585: loss: 0.100848, loss_s1: 0.042357, loss_fp: 0.001007, loss_freq: 0.045174
[12:43:28.696] iteration 4586: loss: 0.230122, loss_s1: 0.033068, loss_fp: 0.001273, loss_freq: 0.023925
[12:43:29.497] iteration 4587: loss: 0.108948, loss_s1: 0.040651, loss_fp: 0.000578, loss_freq: 0.005176
[12:43:30.408] iteration 4588: loss: 0.124059, loss_s1: 0.085361, loss_fp: 0.000891, loss_freq: 0.037555
[12:43:31.050] iteration 4589: loss: 0.182254, loss_s1: 0.105372, loss_fp: 0.004164, loss_freq: 0.048805
[12:43:31.807] iteration 4590: loss: 0.068844, loss_s1: 0.025530, loss_fp: 0.006006, loss_freq: 0.006423
[12:43:32.431] iteration 4591: loss: 0.158331, loss_s1: 0.113076, loss_fp: 0.001707, loss_freq: 0.034034
[12:43:33.043] iteration 4592: loss: 0.076946, loss_s1: 0.028058, loss_fp: 0.000972, loss_freq: 0.016375
[12:43:33.653] iteration 4593: loss: 0.292113, loss_s1: 0.071646, loss_fp: 0.000697, loss_freq: 0.020560
[12:43:34.276] iteration 4594: loss: 0.164998, loss_s1: 0.065034, loss_fp: 0.001018, loss_freq: 0.010069
[12:43:34.894] iteration 4595: loss: 0.097831, loss_s1: 0.055300, loss_fp: 0.001791, loss_freq: 0.020975
[12:43:35.515] iteration 4596: loss: 0.183022, loss_s1: 0.045745, loss_fp: 0.000766, loss_freq: 0.049224
[12:43:36.136] iteration 4597: loss: 0.166290, loss_s1: 0.018392, loss_fp: 0.003530, loss_freq: 0.025903
[12:43:36.750] iteration 4598: loss: 0.172463, loss_s1: 0.134093, loss_fp: 0.003033, loss_freq: 0.031056
[12:43:37.370] iteration 4599: loss: 0.076283, loss_s1: 0.024657, loss_fp: 0.001772, loss_freq: 0.012826
[12:43:37.996] iteration 4600: loss: 0.125727, loss_s1: 0.024499, loss_fp: 0.001695, loss_freq: 0.028447
[12:43:41.360] iteration 4600 : mean_dice : 0.654212
[12:43:42.045] iteration 4601: loss: 0.094009, loss_s1: 0.023425, loss_fp: 0.001830, loss_freq: 0.024813
[12:43:42.742] iteration 4602: loss: 0.172961, loss_s1: 0.075358, loss_fp: 0.001911, loss_freq: 0.032215
[12:43:43.402] iteration 4603: loss: 0.185676, loss_s1: 0.084121, loss_fp: 0.001463, loss_freq: 0.026262
[12:43:44.065] iteration 4604: loss: 0.076049, loss_s1: 0.024553, loss_fp: 0.001072, loss_freq: 0.005176
[12:43:44.722] iteration 4605: loss: 0.247645, loss_s1: 0.059191, loss_fp: 0.000930, loss_freq: 0.015173
[12:43:45.373] iteration 4606: loss: 0.169915, loss_s1: 0.043855, loss_fp: 0.001785, loss_freq: 0.015311
[12:43:46.031] iteration 4607: loss: 0.126892, loss_s1: 0.043841, loss_fp: 0.000989, loss_freq: 0.003010
[12:43:46.682] iteration 4608: loss: 0.070803, loss_s1: 0.020151, loss_fp: 0.001176, loss_freq: 0.013346
[12:43:47.297] iteration 4609: loss: 0.124521, loss_s1: 0.021843, loss_fp: 0.000857, loss_freq: 0.013883
[12:43:47.912] iteration 4610: loss: 0.131103, loss_s1: 0.044700, loss_fp: 0.004577, loss_freq: 0.056627
[12:43:48.596] iteration 4611: loss: 0.169045, loss_s1: 0.063976, loss_fp: 0.001689, loss_freq: 0.007299
[12:43:49.252] iteration 4612: loss: 0.179552, loss_s1: 0.061220, loss_fp: 0.000774, loss_freq: 0.046006
[12:43:49.892] iteration 4613: loss: 0.143410, loss_s1: 0.053748, loss_fp: 0.001500, loss_freq: 0.110212
[12:43:50.521] iteration 4614: loss: 0.076076, loss_s1: 0.033617, loss_fp: 0.005755, loss_freq: 0.008203
[12:43:51.144] iteration 4615: loss: 0.143293, loss_s1: 0.072467, loss_fp: 0.002253, loss_freq: 0.040325
[12:43:51.796] iteration 4616: loss: 0.110856, loss_s1: 0.043131, loss_fp: 0.000772, loss_freq: 0.018764
[12:43:52.457] iteration 4617: loss: 0.130047, loss_s1: 0.029238, loss_fp: 0.004834, loss_freq: 0.052667
[12:43:53.093] iteration 4618: loss: 0.073474, loss_s1: 0.038212, loss_fp: 0.000916, loss_freq: 0.014639
[12:43:53.755] iteration 4619: loss: 0.142391, loss_s1: 0.083185, loss_fp: 0.001131, loss_freq: 0.027088
[12:43:54.404] iteration 4620: loss: 0.094389, loss_s1: 0.078577, loss_fp: 0.001580, loss_freq: 0.008130
[12:43:55.024] iteration 4621: loss: 0.236741, loss_s1: 0.036350, loss_fp: 0.002225, loss_freq: 0.064187
[12:43:55.650] iteration 4622: loss: 0.126255, loss_s1: 0.028903, loss_fp: 0.001279, loss_freq: 0.028591
[12:43:56.275] iteration 4623: loss: 0.092271, loss_s1: 0.016673, loss_fp: 0.001258, loss_freq: 0.053674
[12:43:56.901] iteration 4624: loss: 0.120225, loss_s1: 0.090416, loss_fp: 0.000801, loss_freq: 0.010454
[12:43:57.514] iteration 4625: loss: 0.057300, loss_s1: 0.024936, loss_fp: 0.001224, loss_freq: 0.006539
[12:43:58.133] iteration 4626: loss: 0.116371, loss_s1: 0.092308, loss_fp: 0.000934, loss_freq: 0.026786
[12:43:58.758] iteration 4627: loss: 0.110300, loss_s1: 0.075911, loss_fp: 0.001073, loss_freq: 0.014097
[12:43:59.377] iteration 4628: loss: 0.158875, loss_s1: 0.028954, loss_fp: 0.001409, loss_freq: 0.019292
[12:44:00.034] iteration 4629: loss: 0.112986, loss_s1: 0.012751, loss_fp: 0.001231, loss_freq: 0.012313
[12:44:00.691] iteration 4630: loss: 0.094289, loss_s1: 0.058620, loss_fp: 0.000651, loss_freq: 0.008047
[12:44:01.356] iteration 4631: loss: 0.123269, loss_s1: 0.036582, loss_fp: 0.001114, loss_freq: 0.030143
[12:44:02.009] iteration 4632: loss: 0.184441, loss_s1: 0.104185, loss_fp: 0.000874, loss_freq: 0.010211
[12:44:02.663] iteration 4633: loss: 0.144973, loss_s1: 0.106036, loss_fp: 0.002577, loss_freq: 0.053563
[12:44:03.300] iteration 4634: loss: 0.099917, loss_s1: 0.067404, loss_fp: 0.001905, loss_freq: 0.016296
[12:44:03.950] iteration 4635: loss: 0.191013, loss_s1: 0.044108, loss_fp: 0.002539, loss_freq: 0.088707
[12:44:04.598] iteration 4636: loss: 0.098463, loss_s1: 0.025981, loss_fp: 0.024047, loss_freq: 0.020312
[12:44:05.256] iteration 4637: loss: 0.165589, loss_s1: 0.048425, loss_fp: 0.003345, loss_freq: 0.018577
[12:44:05.914] iteration 4638: loss: 0.159570, loss_s1: 0.060573, loss_fp: 0.001976, loss_freq: 0.030387
[12:44:06.548] iteration 4639: loss: 0.102541, loss_s1: 0.038500, loss_fp: 0.006299, loss_freq: 0.022344
[12:44:07.167] iteration 4640: loss: 0.186961, loss_s1: 0.046624, loss_fp: 0.001229, loss_freq: 0.028108
[12:44:07.789] iteration 4641: loss: 0.166216, loss_s1: 0.061984, loss_fp: 0.001649, loss_freq: 0.008101
[12:44:08.404] iteration 4642: loss: 0.136829, loss_s1: 0.016128, loss_fp: 0.003262, loss_freq: 0.023190
[12:44:09.028] iteration 4643: loss: 0.104826, loss_s1: 0.057998, loss_fp: 0.016649, loss_freq: 0.016895
[12:44:09.652] iteration 4644: loss: 0.133787, loss_s1: 0.048283, loss_fp: 0.009905, loss_freq: 0.033483
[12:44:10.272] iteration 4645: loss: 0.109530, loss_s1: 0.049816, loss_fp: 0.001342, loss_freq: 0.009778
[12:44:10.890] iteration 4646: loss: 0.140106, loss_s1: 0.026705, loss_fp: 0.003120, loss_freq: 0.007719
[12:44:11.505] iteration 4647: loss: 0.114966, loss_s1: 0.059042, loss_fp: 0.001529, loss_freq: 0.011634
[12:44:12.125] iteration 4648: loss: 0.111246, loss_s1: 0.009991, loss_fp: 0.002472, loss_freq: 0.053324
[12:44:12.748] iteration 4649: loss: 0.092712, loss_s1: 0.046712, loss_fp: 0.001049, loss_freq: 0.047924
[12:44:13.370] iteration 4650: loss: 0.173388, loss_s1: 0.068685, loss_fp: 0.004423, loss_freq: 0.055699
[12:44:14.039] iteration 4651: loss: 0.138223, loss_s1: 0.068506, loss_fp: 0.001715, loss_freq: 0.067121
[12:44:14.707] iteration 4652: loss: 0.108102, loss_s1: 0.078899, loss_fp: 0.004355, loss_freq: 0.002587
[12:44:15.367] iteration 4653: loss: 0.050717, loss_s1: 0.009108, loss_fp: 0.002712, loss_freq: 0.010722
[12:44:16.029] iteration 4654: loss: 0.126709, loss_s1: 0.046578, loss_fp: 0.000904, loss_freq: 0.007110
[12:44:16.689] iteration 4655: loss: 0.162718, loss_s1: 0.132163, loss_fp: 0.001193, loss_freq: 0.063590
[12:44:17.348] iteration 4656: loss: 0.260528, loss_s1: 0.050185, loss_fp: 0.003568, loss_freq: 0.028522
[12:44:17.998] iteration 4657: loss: 0.124845, loss_s1: 0.018465, loss_fp: 0.004029, loss_freq: 0.017434
[12:44:18.624] iteration 4658: loss: 0.125372, loss_s1: 0.050571, loss_fp: 0.007365, loss_freq: 0.041871
[12:44:19.248] iteration 4659: loss: 0.119807, loss_s1: 0.031682, loss_fp: 0.003247, loss_freq: 0.025866
[12:44:19.877] iteration 4660: loss: 0.043259, loss_s1: 0.010317, loss_fp: 0.002631, loss_freq: 0.003371
[12:44:20.531] iteration 4661: loss: 0.141591, loss_s1: 0.061161, loss_fp: 0.003567, loss_freq: 0.011325
[12:44:21.195] iteration 4662: loss: 0.202203, loss_s1: 0.107633, loss_fp: 0.005290, loss_freq: 0.075986
[12:44:21.854] iteration 4663: loss: 0.163323, loss_s1: 0.036886, loss_fp: 0.001349, loss_freq: 0.017864
[12:44:22.525] iteration 4664: loss: 0.103614, loss_s1: 0.006104, loss_fp: 0.002657, loss_freq: 0.004972
[12:44:23.179] iteration 4665: loss: 0.084073, loss_s1: 0.030838, loss_fp: 0.001652, loss_freq: 0.043021
[12:44:23.845] iteration 4666: loss: 0.101657, loss_s1: 0.038091, loss_fp: 0.004787, loss_freq: 0.017542
[12:44:24.509] iteration 4667: loss: 0.168586, loss_s1: 0.079056, loss_fp: 0.000846, loss_freq: 0.018079
[12:44:25.172] iteration 4668: loss: 0.134244, loss_s1: 0.108188, loss_fp: 0.002377, loss_freq: 0.035259
[12:44:25.824] iteration 4669: loss: 0.062982, loss_s1: 0.029930, loss_fp: 0.000489, loss_freq: 0.003566
[12:44:26.467] iteration 4670: loss: 0.166606, loss_s1: 0.075927, loss_fp: 0.007372, loss_freq: 0.054801
[12:44:27.095] iteration 4671: loss: 0.086606, loss_s1: 0.040453, loss_fp: 0.002039, loss_freq: 0.007920
[12:44:27.721] iteration 4672: loss: 0.101160, loss_s1: 0.021081, loss_fp: 0.004447, loss_freq: 0.006977
[12:44:28.382] iteration 4673: loss: 0.145721, loss_s1: 0.047699, loss_fp: 0.000987, loss_freq: 0.026619
[12:44:29.044] iteration 4674: loss: 0.109024, loss_s1: 0.053595, loss_fp: 0.002346, loss_freq: 0.051146
[12:44:29.708] iteration 4675: loss: 0.200101, loss_s1: 0.036779, loss_fp: 0.002303, loss_freq: 0.063825
[12:44:30.370] iteration 4676: loss: 0.142344, loss_s1: 0.031975, loss_fp: 0.004715, loss_freq: 0.045214
[12:44:30.995] iteration 4677: loss: 0.197234, loss_s1: 0.105844, loss_fp: 0.000743, loss_freq: 0.105157
[12:44:31.619] iteration 4678: loss: 0.079853, loss_s1: 0.014997, loss_fp: 0.000926, loss_freq: 0.012022
[12:44:32.240] iteration 4679: loss: 0.144848, loss_s1: 0.023928, loss_fp: 0.004842, loss_freq: 0.024229
[12:44:32.855] iteration 4680: loss: 0.162164, loss_s1: 0.062596, loss_fp: 0.001782, loss_freq: 0.078455
[12:44:33.473] iteration 4681: loss: 0.205136, loss_s1: 0.051528, loss_fp: 0.000898, loss_freq: 0.044061
[12:44:34.097] iteration 4682: loss: 0.097732, loss_s1: 0.044378, loss_fp: 0.001253, loss_freq: 0.047153
[12:44:34.712] iteration 4683: loss: 0.224785, loss_s1: 0.191831, loss_fp: 0.001117, loss_freq: 0.133925
[12:44:35.336] iteration 4684: loss: 0.070800, loss_s1: 0.017672, loss_fp: 0.003429, loss_freq: 0.022249
[12:44:35.949] iteration 4685: loss: 0.106043, loss_s1: 0.018715, loss_fp: 0.001535, loss_freq: 0.003010
[12:44:36.558] iteration 4686: loss: 0.142022, loss_s1: 0.093521, loss_fp: 0.001842, loss_freq: 0.035391
[12:44:37.171] iteration 4687: loss: 0.140187, loss_s1: 0.023948, loss_fp: 0.001326, loss_freq: 0.004282
[12:44:37.793] iteration 4688: loss: 0.120649, loss_s1: 0.058292, loss_fp: 0.000793, loss_freq: 0.076772
[12:44:38.476] iteration 4689: loss: 0.110713, loss_s1: 0.031868, loss_fp: 0.003759, loss_freq: 0.010216
[12:44:39.122] iteration 4690: loss: 0.103937, loss_s1: 0.050037, loss_fp: 0.001516, loss_freq: 0.046854
[12:44:39.808] iteration 4691: loss: 0.266997, loss_s1: 0.077720, loss_fp: 0.001993, loss_freq: 0.032214
[12:44:40.470] iteration 4692: loss: 0.133082, loss_s1: 0.092905, loss_fp: 0.002342, loss_freq: 0.013689
[12:44:41.134] iteration 4693: loss: 0.166359, loss_s1: 0.063372, loss_fp: 0.001460, loss_freq: 0.046388
[12:44:41.784] iteration 4694: loss: 0.145563, loss_s1: 0.053674, loss_fp: 0.012545, loss_freq: 0.042272
[12:44:42.402] iteration 4695: loss: 0.113620, loss_s1: 0.124119, loss_fp: 0.003057, loss_freq: 0.007871
[12:44:43.025] iteration 4696: loss: 0.097180, loss_s1: 0.026305, loss_fp: 0.000723, loss_freq: 0.047627
[12:44:43.648] iteration 4697: loss: 0.162107, loss_s1: 0.088854, loss_fp: 0.001609, loss_freq: 0.075512
[12:44:44.270] iteration 4698: loss: 0.171582, loss_s1: 0.051062, loss_fp: 0.001079, loss_freq: 0.026212
[12:44:44.901] iteration 4699: loss: 0.143230, loss_s1: 0.053158, loss_fp: 0.000759, loss_freq: 0.014553
[12:44:45.531] iteration 4700: loss: 0.129461, loss_s1: 0.041680, loss_fp: 0.002438, loss_freq: 0.048757
[12:44:46.207] iteration 4701: loss: 0.173781, loss_s1: 0.051051, loss_fp: 0.000534, loss_freq: 0.069523
[12:44:46.858] iteration 4702: loss: 0.214013, loss_s1: 0.146733, loss_fp: 0.002295, loss_freq: 0.023139
[12:44:47.510] iteration 4703: loss: 0.125066, loss_s1: 0.059121, loss_fp: 0.000849, loss_freq: 0.058565
[12:44:48.157] iteration 4704: loss: 0.085937, loss_s1: 0.044286, loss_fp: 0.001349, loss_freq: 0.015795
[12:44:48.807] iteration 4705: loss: 0.133885, loss_s1: 0.064246, loss_fp: 0.000788, loss_freq: 0.052190
[12:44:49.462] iteration 4706: loss: 0.092512, loss_s1: 0.036174, loss_fp: 0.002046, loss_freq: 0.005925
[12:44:50.116] iteration 4707: loss: 0.171092, loss_s1: 0.035171, loss_fp: 0.002418, loss_freq: 0.003596
[12:44:50.771] iteration 4708: loss: 0.212844, loss_s1: 0.087747, loss_fp: 0.005625, loss_freq: 0.053667
[12:44:51.419] iteration 4709: loss: 0.092848, loss_s1: 0.032069, loss_fp: 0.002483, loss_freq: 0.019794
[12:44:52.036] iteration 4710: loss: 0.158386, loss_s1: 0.017693, loss_fp: 0.001606, loss_freq: 0.012956
[12:44:52.656] iteration 4711: loss: 0.168619, loss_s1: 0.024235, loss_fp: 0.004098, loss_freq: 0.049238
[12:44:53.278] iteration 4712: loss: 0.154219, loss_s1: 0.118596, loss_fp: 0.002888, loss_freq: 0.014731
[12:44:53.903] iteration 4713: loss: 0.154363, loss_s1: 0.110245, loss_fp: 0.001352, loss_freq: 0.020912
[12:44:54.516] iteration 4714: loss: 0.160554, loss_s1: 0.064439, loss_fp: 0.006031, loss_freq: 0.043183
[12:44:55.138] iteration 4715: loss: 0.099520, loss_s1: 0.073433, loss_fp: 0.002160, loss_freq: 0.025758
[12:44:55.761] iteration 4716: loss: 0.179614, loss_s1: 0.075203, loss_fp: 0.001135, loss_freq: 0.047176
[12:44:56.411] iteration 4717: loss: 0.131361, loss_s1: 0.041855, loss_fp: 0.001619, loss_freq: 0.027249
[12:44:57.027] iteration 4718: loss: 0.119670, loss_s1: 0.049345, loss_fp: 0.000739, loss_freq: 0.049286
[12:44:57.645] iteration 4719: loss: 0.076607, loss_s1: 0.034550, loss_fp: 0.000892, loss_freq: 0.008207
[12:44:58.617] iteration 4720: loss: 0.123975, loss_s1: 0.047340, loss_fp: 0.001850, loss_freq: 0.014805
[12:44:59.237] iteration 4721: loss: 0.097239, loss_s1: 0.072356, loss_fp: 0.003911, loss_freq: 0.007398
[12:44:59.864] iteration 4722: loss: 0.096965, loss_s1: 0.057111, loss_fp: 0.002850, loss_freq: 0.042453
[12:45:00.472] iteration 4723: loss: 0.128745, loss_s1: 0.018965, loss_fp: 0.001263, loss_freq: 0.014035
[12:45:01.080] iteration 4724: loss: 0.097983, loss_s1: 0.036128, loss_fp: 0.006942, loss_freq: 0.020602
[12:45:01.697] iteration 4725: loss: 0.114776, loss_s1: 0.041760, loss_fp: 0.002000, loss_freq: 0.004088
[12:45:02.315] iteration 4726: loss: 0.137592, loss_s1: 0.113641, loss_fp: 0.002490, loss_freq: 0.078142
[12:45:02.926] iteration 4727: loss: 0.216033, loss_s1: 0.076319, loss_fp: 0.002483, loss_freq: 0.073546
[12:45:03.546] iteration 4728: loss: 0.111086, loss_s1: 0.072916, loss_fp: 0.000871, loss_freq: 0.022225
[12:45:04.168] iteration 4729: loss: 0.227565, loss_s1: 0.055336, loss_fp: 0.003748, loss_freq: 0.040043
[12:45:04.785] iteration 4730: loss: 0.096657, loss_s1: 0.018106, loss_fp: 0.003402, loss_freq: 0.010603
[12:45:05.407] iteration 4731: loss: 0.108798, loss_s1: 0.038009, loss_fp: 0.000908, loss_freq: 0.056185
[12:45:06.026] iteration 4732: loss: 0.114324, loss_s1: 0.043817, loss_fp: 0.000977, loss_freq: 0.015524
[12:45:06.655] iteration 4733: loss: 0.067705, loss_s1: 0.027551, loss_fp: 0.000675, loss_freq: 0.025016
[12:45:07.273] iteration 4734: loss: 0.145288, loss_s1: 0.050991, loss_fp: 0.002320, loss_freq: 0.088415
[12:45:07.885] iteration 4735: loss: 0.104858, loss_s1: 0.059120, loss_fp: 0.002245, loss_freq: 0.027219
[12:45:08.509] iteration 4736: loss: 0.202470, loss_s1: 0.014487, loss_fp: 0.000934, loss_freq: 0.011176
[12:45:09.126] iteration 4737: loss: 0.224285, loss_s1: 0.119097, loss_fp: 0.001015, loss_freq: 0.005735
[12:45:09.749] iteration 4738: loss: 0.103358, loss_s1: 0.038587, loss_fp: 0.001079, loss_freq: 0.010864
[12:45:10.364] iteration 4739: loss: 0.083206, loss_s1: 0.027784, loss_fp: 0.000631, loss_freq: 0.005882
[12:45:10.999] iteration 4740: loss: 0.153547, loss_s1: 0.045166, loss_fp: 0.002858, loss_freq: 0.042727
[12:45:11.631] iteration 4741: loss: 0.099779, loss_s1: 0.025847, loss_fp: 0.001062, loss_freq: 0.017593
[12:45:12.288] iteration 4742: loss: 0.110547, loss_s1: 0.094754, loss_fp: 0.000996, loss_freq: 0.015176
[12:45:12.905] iteration 4743: loss: 0.140245, loss_s1: 0.016683, loss_fp: 0.003546, loss_freq: 0.027196
[12:45:13.525] iteration 4744: loss: 0.122563, loss_s1: 0.056610, loss_fp: 0.000880, loss_freq: 0.042283
[12:45:14.145] iteration 4745: loss: 0.164700, loss_s1: 0.096111, loss_fp: 0.001350, loss_freq: 0.039444
[12:45:14.766] iteration 4746: loss: 0.167634, loss_s1: 0.041767, loss_fp: 0.000655, loss_freq: 0.021329
[12:45:15.396] iteration 4747: loss: 0.109899, loss_s1: 0.061421, loss_fp: 0.000781, loss_freq: 0.028357
[12:45:16.017] iteration 4748: loss: 0.195970, loss_s1: 0.030701, loss_fp: 0.000576, loss_freq: 0.022641
[12:45:16.639] iteration 4749: loss: 0.137965, loss_s1: 0.063124, loss_fp: 0.000949, loss_freq: 0.015364
[12:45:17.256] iteration 4750: loss: 0.110323, loss_s1: 0.040029, loss_fp: 0.000685, loss_freq: 0.005461
[12:45:17.884] iteration 4751: loss: 0.098042, loss_s1: 0.028049, loss_fp: 0.001641, loss_freq: 0.048515
[12:45:18.503] iteration 4752: loss: 0.101061, loss_s1: 0.037656, loss_fp: 0.001779, loss_freq: 0.013263
[12:45:19.123] iteration 4753: loss: 0.173098, loss_s1: 0.070917, loss_fp: 0.020244, loss_freq: 0.100681
[12:45:19.762] iteration 4754: loss: 0.192217, loss_s1: 0.067337, loss_fp: 0.002567, loss_freq: 0.019855
[12:45:20.434] iteration 4755: loss: 0.161371, loss_s1: 0.072794, loss_fp: 0.001863, loss_freq: 0.025720
[12:45:21.095] iteration 4756: loss: 0.120983, loss_s1: 0.080878, loss_fp: 0.001151, loss_freq: 0.040211
[12:45:21.734] iteration 4757: loss: 0.064690, loss_s1: 0.017726, loss_fp: 0.001346, loss_freq: 0.015474
[12:45:22.344] iteration 4758: loss: 0.105268, loss_s1: 0.022707, loss_fp: 0.001661, loss_freq: 0.036686
[12:45:22.977] iteration 4759: loss: 0.136319, loss_s1: 0.057734, loss_fp: 0.001130, loss_freq: 0.014522
[12:45:23.641] iteration 4760: loss: 0.112655, loss_s1: 0.045679, loss_fp: 0.000855, loss_freq: 0.031310
[12:45:24.289] iteration 4761: loss: 0.090209, loss_s1: 0.029225, loss_fp: 0.008760, loss_freq: 0.042443
[12:45:24.941] iteration 4762: loss: 0.124012, loss_s1: 0.036206, loss_fp: 0.000360, loss_freq: 0.017694
[12:45:25.598] iteration 4763: loss: 0.086519, loss_s1: 0.042246, loss_fp: 0.003931, loss_freq: 0.026775
[12:45:26.231] iteration 4764: loss: 0.252883, loss_s1: 0.056025, loss_fp: 0.001371, loss_freq: 0.057279
[12:45:26.856] iteration 4765: loss: 0.155365, loss_s1: 0.103255, loss_fp: 0.000770, loss_freq: 0.023793
[12:45:27.502] iteration 4766: loss: 0.110174, loss_s1: 0.055478, loss_fp: 0.005175, loss_freq: 0.055976
[12:45:28.124] iteration 4767: loss: 0.083179, loss_s1: 0.037318, loss_fp: 0.006597, loss_freq: 0.006517
[12:45:28.751] iteration 4768: loss: 0.084380, loss_s1: 0.046839, loss_fp: 0.001438, loss_freq: 0.020746
[12:45:29.374] iteration 4769: loss: 0.173503, loss_s1: 0.098032, loss_fp: 0.001214, loss_freq: 0.053135
[12:45:30.006] iteration 4770: loss: 0.112204, loss_s1: 0.084098, loss_fp: 0.001154, loss_freq: 0.015885
[12:45:30.620] iteration 4771: loss: 0.242079, loss_s1: 0.018120, loss_fp: 0.001584, loss_freq: 0.085256
[12:45:31.245] iteration 4772: loss: 0.110027, loss_s1: 0.042998, loss_fp: 0.001102, loss_freq: 0.005318
[12:45:31.870] iteration 4773: loss: 0.072842, loss_s1: 0.030585, loss_fp: 0.001825, loss_freq: 0.007578
[12:45:32.503] iteration 4774: loss: 0.080361, loss_s1: 0.070361, loss_fp: 0.001904, loss_freq: 0.010764
[12:45:33.133] iteration 4775: loss: 0.186509, loss_s1: 0.065986, loss_fp: 0.003843, loss_freq: 0.016936
[12:45:33.891] iteration 4776: loss: 0.176559, loss_s1: 0.164207, loss_fp: 0.001839, loss_freq: 0.064052
[12:45:34.822] iteration 4777: loss: 0.085154, loss_s1: 0.046271, loss_fp: 0.006850, loss_freq: 0.009354
[12:45:35.749] iteration 4778: loss: 0.189596, loss_s1: 0.057244, loss_fp: 0.001657, loss_freq: 0.050575
[12:45:36.544] iteration 4779: loss: 0.107817, loss_s1: 0.068268, loss_fp: 0.003741, loss_freq: 0.019918
[12:45:37.197] iteration 4780: loss: 0.152335, loss_s1: 0.024049, loss_fp: 0.002635, loss_freq: 0.011196
[12:45:37.855] iteration 4781: loss: 0.128604, loss_s1: 0.052475, loss_fp: 0.003381, loss_freq: 0.006079
[12:45:38.489] iteration 4782: loss: 0.101921, loss_s1: 0.061797, loss_fp: 0.001233, loss_freq: 0.016906
[12:45:39.113] iteration 4783: loss: 0.152305, loss_s1: 0.027131, loss_fp: 0.001448, loss_freq: 0.023465
[12:45:39.732] iteration 4784: loss: 0.153430, loss_s1: 0.091183, loss_fp: 0.003420, loss_freq: 0.034427
[12:45:40.358] iteration 4785: loss: 0.140093, loss_s1: 0.057389, loss_fp: 0.000710, loss_freq: 0.018083
[12:45:40.978] iteration 4786: loss: 0.125076, loss_s1: 0.061312, loss_fp: 0.002347, loss_freq: 0.069244
[12:45:41.588] iteration 4787: loss: 0.106176, loss_s1: 0.043251, loss_fp: 0.006016, loss_freq: 0.023688
[12:45:42.261] iteration 4788: loss: 0.126406, loss_s1: 0.029687, loss_fp: 0.003852, loss_freq: 0.015541
[12:45:42.887] iteration 4789: loss: 0.162770, loss_s1: 0.047683, loss_fp: 0.000908, loss_freq: 0.004929
[12:45:43.508] iteration 4790: loss: 0.147543, loss_s1: 0.076348, loss_fp: 0.001113, loss_freq: 0.014579
[12:45:44.182] iteration 4791: loss: 0.142880, loss_s1: 0.143366, loss_fp: 0.000987, loss_freq: 0.019446
[12:45:44.827] iteration 4792: loss: 0.117226, loss_s1: 0.042134, loss_fp: 0.000653, loss_freq: 0.089206
[12:45:45.452] iteration 4793: loss: 0.182501, loss_s1: 0.134901, loss_fp: 0.001206, loss_freq: 0.099797
[12:45:46.066] iteration 4794: loss: 0.125359, loss_s1: 0.064254, loss_fp: 0.001973, loss_freq: 0.078056
[12:45:46.690] iteration 4795: loss: 0.125415, loss_s1: 0.043478, loss_fp: 0.003608, loss_freq: 0.019163
[12:45:47.310] iteration 4796: loss: 0.058169, loss_s1: 0.037732, loss_fp: 0.001209, loss_freq: 0.008157
[12:45:47.932] iteration 4797: loss: 0.144840, loss_s1: 0.095609, loss_fp: 0.002528, loss_freq: 0.016151
[12:45:48.557] iteration 4798: loss: 0.111287, loss_s1: 0.048940, loss_fp: 0.003728, loss_freq: 0.049066
[12:45:49.177] iteration 4799: loss: 0.257035, loss_s1: 0.029473, loss_fp: 0.001688, loss_freq: 0.036729
[12:45:49.797] iteration 4800: loss: 0.126424, loss_s1: 0.056248, loss_fp: 0.001130, loss_freq: 0.019732
[12:45:53.212] iteration 4800 : mean_dice : 0.676352
[12:45:53.893] iteration 4801: loss: 0.200986, loss_s1: 0.067109, loss_fp: 0.022161, loss_freq: 0.051816
[12:45:54.550] iteration 4802: loss: 0.142779, loss_s1: 0.055014, loss_fp: 0.001063, loss_freq: 0.047060
[12:45:55.199] iteration 4803: loss: 0.049691, loss_s1: 0.025256, loss_fp: 0.001622, loss_freq: 0.009246
[12:45:55.827] iteration 4804: loss: 0.104462, loss_s1: 0.032538, loss_fp: 0.002716, loss_freq: 0.019252
[12:45:56.450] iteration 4805: loss: 0.236758, loss_s1: 0.139253, loss_fp: 0.004741, loss_freq: 0.143179
[12:45:57.073] iteration 4806: loss: 0.169000, loss_s1: 0.038339, loss_fp: 0.003649, loss_freq: 0.018900
[12:45:57.713] iteration 4807: loss: 0.093313, loss_s1: 0.005622, loss_fp: 0.000559, loss_freq: 0.019877
[12:45:58.343] iteration 4808: loss: 0.147115, loss_s1: 0.096145, loss_fp: 0.000825, loss_freq: 0.012541
[12:45:58.979] iteration 4809: loss: 0.102632, loss_s1: 0.033568, loss_fp: 0.001571, loss_freq: 0.066625
[12:45:59.604] iteration 4810: loss: 0.134124, loss_s1: 0.035249, loss_fp: 0.001371, loss_freq: 0.010384
[12:46:00.225] iteration 4811: loss: 0.167213, loss_s1: 0.032157, loss_fp: 0.001111, loss_freq: 0.106380
[12:46:00.889] iteration 4812: loss: 0.065624, loss_s1: 0.029789, loss_fp: 0.001978, loss_freq: 0.007861
[12:46:01.539] iteration 4813: loss: 0.140101, loss_s1: 0.066439, loss_fp: 0.002845, loss_freq: 0.029007
[12:46:02.230] iteration 4814: loss: 0.087765, loss_s1: 0.051209, loss_fp: 0.005133, loss_freq: 0.010417
[12:46:02.900] iteration 4815: loss: 0.119674, loss_s1: 0.045329, loss_fp: 0.001286, loss_freq: 0.033102
[12:46:03.562] iteration 4816: loss: 0.177335, loss_s1: 0.120839, loss_fp: 0.005984, loss_freq: 0.093882
[12:46:04.216] iteration 4817: loss: 0.109682, loss_s1: 0.058085, loss_fp: 0.001419, loss_freq: 0.028958
[12:46:04.875] iteration 4818: loss: 0.182407, loss_s1: 0.064109, loss_fp: 0.002666, loss_freq: 0.044606
[12:46:05.532] iteration 4819: loss: 0.161830, loss_s1: 0.057228, loss_fp: 0.016730, loss_freq: 0.082912
[12:46:06.185] iteration 4820: loss: 0.132654, loss_s1: 0.036616, loss_fp: 0.001729, loss_freq: 0.037332
[12:46:06.796] iteration 4821: loss: 0.088302, loss_s1: 0.017866, loss_fp: 0.001568, loss_freq: 0.013465
[12:46:07.409] iteration 4822: loss: 0.121129, loss_s1: 0.027519, loss_fp: 0.001743, loss_freq: 0.028888
[12:46:08.037] iteration 4823: loss: 0.151202, loss_s1: 0.051297, loss_fp: 0.004753, loss_freq: 0.073108
[12:46:08.658] iteration 4824: loss: 0.177882, loss_s1: 0.045568, loss_fp: 0.003068, loss_freq: 0.077668
[12:46:09.275] iteration 4825: loss: 0.157445, loss_s1: 0.040540, loss_fp: 0.001028, loss_freq: 0.064969
[12:46:09.899] iteration 4826: loss: 0.202768, loss_s1: 0.131433, loss_fp: 0.001387, loss_freq: 0.146807
[12:46:10.512] iteration 4827: loss: 0.087226, loss_s1: 0.052291, loss_fp: 0.001687, loss_freq: 0.022066
[12:46:11.129] iteration 4828: loss: 0.143463, loss_s1: 0.047056, loss_fp: 0.000446, loss_freq: 0.004375
[12:46:11.741] iteration 4829: loss: 0.115021, loss_s1: 0.034091, loss_fp: 0.000934, loss_freq: 0.038245
[12:46:12.368] iteration 4830: loss: 0.150209, loss_s1: 0.059674, loss_fp: 0.000559, loss_freq: 0.013728
[12:46:12.982] iteration 4831: loss: 0.097676, loss_s1: 0.043549, loss_fp: 0.001581, loss_freq: 0.019782
[12:46:13.592] iteration 4832: loss: 0.131397, loss_s1: 0.069369, loss_fp: 0.000386, loss_freq: 0.012875
[12:46:14.215] iteration 4833: loss: 0.068497, loss_s1: 0.016449, loss_fp: 0.003308, loss_freq: 0.010191
[12:46:14.835] iteration 4834: loss: 0.321676, loss_s1: 0.084350, loss_fp: 0.000665, loss_freq: 0.064819
[12:46:15.453] iteration 4835: loss: 0.121751, loss_s1: 0.030575, loss_fp: 0.000918, loss_freq: 0.005486
[12:46:16.096] iteration 4836: loss: 0.131506, loss_s1: 0.010080, loss_fp: 0.000558, loss_freq: 0.056781
[12:46:16.724] iteration 4837: loss: 0.195038, loss_s1: 0.081695, loss_fp: 0.021996, loss_freq: 0.087895
[12:46:17.387] iteration 4838: loss: 0.063114, loss_s1: 0.034212, loss_fp: 0.002008, loss_freq: 0.013220
[12:46:18.046] iteration 4839: loss: 0.085453, loss_s1: 0.021977, loss_fp: 0.003228, loss_freq: 0.022199
[12:46:18.708] iteration 4840: loss: 0.185838, loss_s1: 0.059382, loss_fp: 0.003389, loss_freq: 0.128887
[12:46:19.340] iteration 4841: loss: 0.182276, loss_s1: 0.020191, loss_fp: 0.003439, loss_freq: 0.030115
[12:46:19.977] iteration 4842: loss: 0.093807, loss_s1: 0.021858, loss_fp: 0.001232, loss_freq: 0.009176
[12:46:20.597] iteration 4843: loss: 0.153619, loss_s1: 0.106340, loss_fp: 0.002691, loss_freq: 0.025493
[12:46:21.228] iteration 4844: loss: 0.137774, loss_s1: 0.046970, loss_fp: 0.001854, loss_freq: 0.037692
[12:46:21.850] iteration 4845: loss: 0.141094, loss_s1: 0.011700, loss_fp: 0.005859, loss_freq: 0.024078
[12:46:22.481] iteration 4846: loss: 0.108897, loss_s1: 0.035753, loss_fp: 0.000520, loss_freq: 0.069144
[12:46:23.102] iteration 4847: loss: 0.085325, loss_s1: 0.054487, loss_fp: 0.000791, loss_freq: 0.013398
[12:46:23.735] iteration 4848: loss: 0.173993, loss_s1: 0.076191, loss_fp: 0.013685, loss_freq: 0.045224
[12:46:24.369] iteration 4849: loss: 0.071768, loss_s1: 0.033553, loss_fp: 0.001564, loss_freq: 0.002740
[12:46:24.998] iteration 4850: loss: 0.135827, loss_s1: 0.043645, loss_fp: 0.001402, loss_freq: 0.012341
[12:46:25.621] iteration 4851: loss: 0.162440, loss_s1: 0.055272, loss_fp: 0.011410, loss_freq: 0.017029
[12:46:26.240] iteration 4852: loss: 0.093361, loss_s1: 0.012426, loss_fp: 0.002151, loss_freq: 0.014141
[12:46:26.857] iteration 4853: loss: 0.169283, loss_s1: 0.035029, loss_fp: 0.004132, loss_freq: 0.045797
[12:46:27.467] iteration 4854: loss: 0.125284, loss_s1: 0.029537, loss_fp: 0.001272, loss_freq: 0.011108
[12:46:28.087] iteration 4855: loss: 0.121345, loss_s1: 0.040271, loss_fp: 0.001584, loss_freq: 0.020556
[12:46:28.707] iteration 4856: loss: 0.144071, loss_s1: 0.145392, loss_fp: 0.006695, loss_freq: 0.021773
[12:46:29.318] iteration 4857: loss: 0.102976, loss_s1: 0.011477, loss_fp: 0.010372, loss_freq: 0.003996
[12:46:29.939] iteration 4858: loss: 0.104014, loss_s1: 0.036510, loss_fp: 0.001275, loss_freq: 0.022096
[12:46:30.580] iteration 4859: loss: 0.175485, loss_s1: 0.029378, loss_fp: 0.000830, loss_freq: 0.016529
[12:46:31.209] iteration 4860: loss: 0.140075, loss_s1: 0.038176, loss_fp: 0.025892, loss_freq: 0.021643
[12:46:31.820] iteration 4861: loss: 0.247845, loss_s1: 0.280945, loss_fp: 0.004701, loss_freq: 0.081499
[12:46:32.435] iteration 4862: loss: 0.086467, loss_s1: 0.034364, loss_fp: 0.001362, loss_freq: 0.036067
[12:46:33.396] iteration 4863: loss: 0.120946, loss_s1: 0.017872, loss_fp: 0.000718, loss_freq: 0.015331
[12:46:34.057] iteration 4864: loss: 0.091454, loss_s1: 0.019789, loss_fp: 0.000964, loss_freq: 0.022933
[12:46:34.711] iteration 4865: loss: 0.087382, loss_s1: 0.054855, loss_fp: 0.001563, loss_freq: 0.031717
[12:46:35.363] iteration 4866: loss: 0.103213, loss_s1: 0.032507, loss_fp: 0.000679, loss_freq: 0.004912
[12:46:36.000] iteration 4867: loss: 0.139274, loss_s1: 0.080923, loss_fp: 0.001818, loss_freq: 0.037990
[12:46:36.632] iteration 4868: loss: 0.098328, loss_s1: 0.026062, loss_fp: 0.001871, loss_freq: 0.005257
[12:46:37.262] iteration 4869: loss: 0.143460, loss_s1: 0.092871, loss_fp: 0.002268, loss_freq: 0.085535
[12:46:37.900] iteration 4870: loss: 0.184185, loss_s1: 0.050040, loss_fp: 0.002866, loss_freq: 0.049750
[12:46:38.527] iteration 4871: loss: 0.106507, loss_s1: 0.025647, loss_fp: 0.000665, loss_freq: 0.043017
[12:46:39.158] iteration 4872: loss: 0.240751, loss_s1: 0.028820, loss_fp: 0.001080, loss_freq: 0.018187
[12:46:39.786] iteration 4873: loss: 0.105160, loss_s1: 0.036596, loss_fp: 0.001173, loss_freq: 0.027382
[12:46:40.411] iteration 4874: loss: 0.099334, loss_s1: 0.046882, loss_fp: 0.001587, loss_freq: 0.044746
[12:46:41.050] iteration 4875: loss: 0.110602, loss_s1: 0.058327, loss_fp: 0.012335, loss_freq: 0.009301
[12:46:41.666] iteration 4876: loss: 0.078697, loss_s1: 0.033456, loss_fp: 0.001847, loss_freq: 0.023230
[12:46:42.365] iteration 4877: loss: 0.160884, loss_s1: 0.116617, loss_fp: 0.001434, loss_freq: 0.068026
[12:46:43.014] iteration 4878: loss: 0.095995, loss_s1: 0.045216, loss_fp: 0.003926, loss_freq: 0.017300
[12:46:43.670] iteration 4879: loss: 0.171084, loss_s1: 0.045106, loss_fp: 0.000944, loss_freq: 0.016237
[12:46:44.330] iteration 4880: loss: 0.141124, loss_s1: 0.029004, loss_fp: 0.001334, loss_freq: 0.012615
[12:46:44.961] iteration 4881: loss: 0.084240, loss_s1: 0.014278, loss_fp: 0.001251, loss_freq: 0.013606
[12:46:45.571] iteration 4882: loss: 0.104763, loss_s1: 0.051829, loss_fp: 0.000696, loss_freq: 0.032131
[12:46:46.181] iteration 4883: loss: 0.142167, loss_s1: 0.029273, loss_fp: 0.001602, loss_freq: 0.019358
[12:46:46.797] iteration 4884: loss: 0.078039, loss_s1: 0.020183, loss_fp: 0.001038, loss_freq: 0.016190
[12:46:47.474] iteration 4885: loss: 0.101635, loss_s1: 0.045443, loss_fp: 0.009790, loss_freq: 0.022913
[12:46:48.144] iteration 4886: loss: 0.104715, loss_s1: 0.033917, loss_fp: 0.000924, loss_freq: 0.006147
[12:46:48.797] iteration 4887: loss: 0.095995, loss_s1: 0.039207, loss_fp: 0.001011, loss_freq: 0.021252
[12:46:49.453] iteration 4888: loss: 0.104076, loss_s1: 0.013271, loss_fp: 0.001538, loss_freq: 0.022630
[12:46:50.087] iteration 4889: loss: 0.166345, loss_s1: 0.050679, loss_fp: 0.001037, loss_freq: 0.046112
[12:46:50.706] iteration 4890: loss: 0.110271, loss_s1: 0.079497, loss_fp: 0.001202, loss_freq: 0.004117
[12:46:51.340] iteration 4891: loss: 0.188465, loss_s1: 0.011502, loss_fp: 0.002036, loss_freq: 0.045770
[12:46:51.959] iteration 4892: loss: 0.170089, loss_s1: 0.040697, loss_fp: 0.001736, loss_freq: 0.024040
[12:46:52.582] iteration 4893: loss: 0.098612, loss_s1: 0.022661, loss_fp: 0.001130, loss_freq: 0.011958
[12:46:53.202] iteration 4894: loss: 0.085407, loss_s1: 0.032570, loss_fp: 0.001566, loss_freq: 0.025252
[12:46:53.810] iteration 4895: loss: 0.110572, loss_s1: 0.040414, loss_fp: 0.001828, loss_freq: 0.015176
[12:46:54.437] iteration 4896: loss: 0.119011, loss_s1: 0.040021, loss_fp: 0.003611, loss_freq: 0.036219
[12:46:55.070] iteration 4897: loss: 0.154607, loss_s1: 0.027517, loss_fp: 0.002506, loss_freq: 0.029924
[12:46:55.699] iteration 4898: loss: 0.174705, loss_s1: 0.121826, loss_fp: 0.003388, loss_freq: 0.050478
[12:46:56.333] iteration 4899: loss: 0.183785, loss_s1: 0.128729, loss_fp: 0.002846, loss_freq: 0.098130
[12:46:56.973] iteration 4900: loss: 0.077040, loss_s1: 0.043504, loss_fp: 0.002065, loss_freq: 0.012108
[12:46:57.607] iteration 4901: loss: 0.098939, loss_s1: 0.015978, loss_fp: 0.002095, loss_freq: 0.035203
[12:46:58.234] iteration 4902: loss: 0.117778, loss_s1: 0.053511, loss_fp: 0.001503, loss_freq: 0.014554
[12:46:58.902] iteration 4903: loss: 0.120022, loss_s1: 0.079930, loss_fp: 0.001245, loss_freq: 0.005857
[12:46:59.520] iteration 4904: loss: 0.093308, loss_s1: 0.036685, loss_fp: 0.001194, loss_freq: 0.010522
[12:47:00.131] iteration 4905: loss: 0.120291, loss_s1: 0.024100, loss_fp: 0.001305, loss_freq: 0.008042
[12:47:00.745] iteration 4906: loss: 0.117438, loss_s1: 0.090160, loss_fp: 0.004794, loss_freq: 0.024145
[12:47:01.355] iteration 4907: loss: 0.246119, loss_s1: 0.070450, loss_fp: 0.004650, loss_freq: 0.046970
[12:47:01.975] iteration 4908: loss: 0.133939, loss_s1: 0.072140, loss_fp: 0.004789, loss_freq: 0.040418
[12:47:02.587] iteration 4909: loss: 0.098575, loss_s1: 0.011016, loss_fp: 0.013364, loss_freq: 0.025589
[12:47:03.259] iteration 4910: loss: 0.128003, loss_s1: 0.031029, loss_fp: 0.000689, loss_freq: 0.018475
[12:47:03.932] iteration 4911: loss: 0.085219, loss_s1: 0.075179, loss_fp: 0.002701, loss_freq: 0.017575
[12:47:04.602] iteration 4912: loss: 0.197752, loss_s1: 0.113186, loss_fp: 0.003548, loss_freq: 0.043985
[12:47:05.237] iteration 4913: loss: 0.089917, loss_s1: 0.041283, loss_fp: 0.004392, loss_freq: 0.011003
[12:47:05.851] iteration 4914: loss: 0.233728, loss_s1: 0.107651, loss_fp: 0.002124, loss_freq: 0.052198
[12:47:06.468] iteration 4915: loss: 0.106098, loss_s1: 0.040217, loss_fp: 0.001626, loss_freq: 0.009560
[12:47:07.083] iteration 4916: loss: 0.097237, loss_s1: 0.052523, loss_fp: 0.009532, loss_freq: 0.011926
[12:47:07.695] iteration 4917: loss: 0.149941, loss_s1: 0.056267, loss_fp: 0.001279, loss_freq: 0.031904
[12:47:08.314] iteration 4918: loss: 0.172225, loss_s1: 0.033799, loss_fp: 0.001419, loss_freq: 0.006330
[12:47:08.941] iteration 4919: loss: 0.162352, loss_s1: 0.157326, loss_fp: 0.001656, loss_freq: 0.035434
[12:47:09.560] iteration 4920: loss: 0.079554, loss_s1: 0.028086, loss_fp: 0.002983, loss_freq: 0.021135
[12:47:10.178] iteration 4921: loss: 0.188852, loss_s1: 0.052070, loss_fp: 0.017722, loss_freq: 0.090233
[12:47:10.806] iteration 4922: loss: 0.098975, loss_s1: 0.047587, loss_fp: 0.009775, loss_freq: 0.011804
[12:47:11.425] iteration 4923: loss: 0.178464, loss_s1: 0.058231, loss_fp: 0.004203, loss_freq: 0.030028
[12:47:12.057] iteration 4924: loss: 0.126454, loss_s1: 0.044144, loss_fp: 0.003730, loss_freq: 0.023666
[12:47:12.691] iteration 4925: loss: 0.130565, loss_s1: 0.073057, loss_fp: 0.005723, loss_freq: 0.026959
[12:47:13.325] iteration 4926: loss: 0.215691, loss_s1: 0.119965, loss_fp: 0.001179, loss_freq: 0.034429
[12:47:13.956] iteration 4927: loss: 0.168839, loss_s1: 0.058539, loss_fp: 0.002542, loss_freq: 0.013158
[12:47:14.587] iteration 4928: loss: 0.128878, loss_s1: 0.050532, loss_fp: 0.000582, loss_freq: 0.019544
[12:47:15.212] iteration 4929: loss: 0.107873, loss_s1: 0.018842, loss_fp: 0.007937, loss_freq: 0.019686
[12:47:15.835] iteration 4930: loss: 0.141638, loss_s1: 0.024025, loss_fp: 0.000708, loss_freq: 0.047131
[12:47:16.462] iteration 4931: loss: 0.106645, loss_s1: 0.042416, loss_fp: 0.002439, loss_freq: 0.018311
[12:47:17.091] iteration 4932: loss: 0.204636, loss_s1: 0.091018, loss_fp: 0.001015, loss_freq: 0.013073
[12:47:17.720] iteration 4933: loss: 0.109407, loss_s1: 0.024785, loss_fp: 0.000860, loss_freq: 0.013880
[12:47:18.342] iteration 4934: loss: 0.087056, loss_s1: 0.022924, loss_fp: 0.001212, loss_freq: 0.028852
[12:47:18.972] iteration 4935: loss: 0.092723, loss_s1: 0.026628, loss_fp: 0.004297, loss_freq: 0.039388
[12:47:19.601] iteration 4936: loss: 0.133469, loss_s1: 0.074658, loss_fp: 0.003307, loss_freq: 0.027269
[12:47:20.232] iteration 4937: loss: 0.134138, loss_s1: 0.054429, loss_fp: 0.002219, loss_freq: 0.037727
[12:47:20.868] iteration 4938: loss: 0.114041, loss_s1: 0.026006, loss_fp: 0.001372, loss_freq: 0.006903
[12:47:21.506] iteration 4939: loss: 0.098474, loss_s1: 0.010468, loss_fp: 0.001289, loss_freq: 0.024065
[12:47:22.140] iteration 4940: loss: 0.154486, loss_s1: 0.051713, loss_fp: 0.001295, loss_freq: 0.017173
[12:47:22.770] iteration 4941: loss: 0.150005, loss_s1: 0.080141, loss_fp: 0.002543, loss_freq: 0.078947
[12:47:23.398] iteration 4942: loss: 0.283557, loss_s1: 0.053433, loss_fp: 0.002782, loss_freq: 0.052653
[12:47:24.027] iteration 4943: loss: 0.132815, loss_s1: 0.068173, loss_fp: 0.001083, loss_freq: 0.021004
[12:47:24.656] iteration 4944: loss: 0.102220, loss_s1: 0.044391, loss_fp: 0.002027, loss_freq: 0.023909
[12:47:25.289] iteration 4945: loss: 0.126474, loss_s1: 0.052831, loss_fp: 0.001191, loss_freq: 0.009470
[12:47:25.921] iteration 4946: loss: 0.082826, loss_s1: 0.062163, loss_fp: 0.001692, loss_freq: 0.023972
[12:47:26.553] iteration 4947: loss: 0.102114, loss_s1: 0.065384, loss_fp: 0.002326, loss_freq: 0.009067
[12:47:27.196] iteration 4948: loss: 0.181490, loss_s1: 0.123974, loss_fp: 0.003380, loss_freq: 0.084893
[12:47:27.830] iteration 4949: loss: 0.173774, loss_s1: 0.047469, loss_fp: 0.000943, loss_freq: 0.008288
[12:47:28.461] iteration 4950: loss: 0.169065, loss_s1: 0.024503, loss_fp: 0.001003, loss_freq: 0.010144
[12:47:29.099] iteration 4951: loss: 0.118707, loss_s1: 0.018079, loss_fp: 0.003209, loss_freq: 0.016199
[12:47:29.716] iteration 4952: loss: 0.096248, loss_s1: 0.065652, loss_fp: 0.001078, loss_freq: 0.019462
[12:47:30.339] iteration 4953: loss: 0.173593, loss_s1: 0.027974, loss_fp: 0.000904, loss_freq: 0.009557
[12:47:30.965] iteration 4954: loss: 0.130231, loss_s1: 0.093837, loss_fp: 0.003736, loss_freq: 0.053052
[12:47:31.594] iteration 4955: loss: 0.094364, loss_s1: 0.085413, loss_fp: 0.000600, loss_freq: 0.008689
[12:47:32.237] iteration 4956: loss: 0.141749, loss_s1: 0.044024, loss_fp: 0.001760, loss_freq: 0.030482
[12:47:32.888] iteration 4957: loss: 0.079940, loss_s1: 0.023148, loss_fp: 0.002141, loss_freq: 0.009523
[12:47:33.535] iteration 4958: loss: 0.138298, loss_s1: 0.024870, loss_fp: 0.001225, loss_freq: 0.023840
[12:47:34.169] iteration 4959: loss: 0.233557, loss_s1: 0.074315, loss_fp: 0.001342, loss_freq: 0.097475
[12:47:34.785] iteration 4960: loss: 0.075050, loss_s1: 0.019829, loss_fp: 0.000698, loss_freq: 0.018719
[12:47:35.419] iteration 4961: loss: 0.163852, loss_s1: 0.025031, loss_fp: 0.001092, loss_freq: 0.040498
[12:47:36.052] iteration 4962: loss: 0.184408, loss_s1: 0.134415, loss_fp: 0.010459, loss_freq: 0.049961
[12:47:36.692] iteration 4963: loss: 0.117557, loss_s1: 0.010110, loss_fp: 0.006034, loss_freq: 0.051261
[12:47:37.325] iteration 4964: loss: 0.083779, loss_s1: 0.054393, loss_fp: 0.001657, loss_freq: 0.010119
[12:47:37.962] iteration 4965: loss: 0.107193, loss_s1: 0.055972, loss_fp: 0.001923, loss_freq: 0.009118
[12:47:38.591] iteration 4966: loss: 0.170704, loss_s1: 0.090408, loss_fp: 0.001120, loss_freq: 0.067249
[12:47:39.311] iteration 4967: loss: 0.151130, loss_s1: 0.019371, loss_fp: 0.002120, loss_freq: 0.023895
[12:47:39.940] iteration 4968: loss: 0.136212, loss_s1: 0.051195, loss_fp: 0.004126, loss_freq: 0.015800
[12:47:40.591] iteration 4969: loss: 0.193565, loss_s1: 0.093880, loss_fp: 0.001731, loss_freq: 0.193128
[12:47:41.235] iteration 4970: loss: 0.081363, loss_s1: 0.022035, loss_fp: 0.002278, loss_freq: 0.029658
[12:47:41.880] iteration 4971: loss: 0.111921, loss_s1: 0.034563, loss_fp: 0.000812, loss_freq: 0.018209
[12:47:42.518] iteration 4972: loss: 0.127731, loss_s1: 0.081672, loss_fp: 0.000836, loss_freq: 0.032999
[12:47:43.141] iteration 4973: loss: 0.138653, loss_s1: 0.076279, loss_fp: 0.000691, loss_freq: 0.018312
[12:47:43.762] iteration 4974: loss: 0.082693, loss_s1: 0.037727, loss_fp: 0.000639, loss_freq: 0.033044
[12:47:44.373] iteration 4975: loss: 0.109026, loss_s1: 0.041288, loss_fp: 0.000573, loss_freq: 0.011094
[12:47:44.991] iteration 4976: loss: 0.102778, loss_s1: 0.053261, loss_fp: 0.004228, loss_freq: 0.011601
[12:47:45.619] iteration 4977: loss: 0.239545, loss_s1: 0.021652, loss_fp: 0.000825, loss_freq: 0.067659
[12:47:46.239] iteration 4978: loss: 0.122529, loss_s1: 0.033373, loss_fp: 0.001169, loss_freq: 0.010698
[12:47:46.854] iteration 4979: loss: 0.111210, loss_s1: 0.060081, loss_fp: 0.003778, loss_freq: 0.038208
[12:47:47.477] iteration 4980: loss: 0.180041, loss_s1: 0.090091, loss_fp: 0.001917, loss_freq: 0.043182
[12:47:48.101] iteration 4981: loss: 0.071911, loss_s1: 0.057064, loss_fp: 0.002680, loss_freq: 0.017109
[12:47:48.720] iteration 4982: loss: 0.128307, loss_s1: 0.081089, loss_fp: 0.001541, loss_freq: 0.035095
[12:47:49.336] iteration 4983: loss: 0.171455, loss_s1: 0.108697, loss_fp: 0.001471, loss_freq: 0.108360
[12:47:49.947] iteration 4984: loss: 0.224596, loss_s1: 0.120846, loss_fp: 0.001734, loss_freq: 0.015139
[12:47:50.567] iteration 4985: loss: 0.100177, loss_s1: 0.055168, loss_fp: 0.000854, loss_freq: 0.002984
[12:47:51.190] iteration 4986: loss: 0.074006, loss_s1: 0.034364, loss_fp: 0.001864, loss_freq: 0.010183
[12:47:51.818] iteration 4987: loss: 0.116952, loss_s1: 0.100402, loss_fp: 0.001508, loss_freq: 0.053988
[12:47:52.439] iteration 4988: loss: 0.168783, loss_s1: 0.063725, loss_fp: 0.001653, loss_freq: 0.034033
[12:47:53.051] iteration 4989: loss: 0.102652, loss_s1: 0.033187, loss_fp: 0.001038, loss_freq: 0.060177
[12:47:53.666] iteration 4990: loss: 0.074242, loss_s1: 0.031206, loss_fp: 0.001350, loss_freq: 0.022393
[12:47:54.326] iteration 4991: loss: 0.170431, loss_s1: 0.082267, loss_fp: 0.004528, loss_freq: 0.013132
[12:47:54.981] iteration 4992: loss: 0.078065, loss_s1: 0.020803, loss_fp: 0.000935, loss_freq: 0.008693
[12:47:55.631] iteration 4993: loss: 0.186303, loss_s1: 0.058136, loss_fp: 0.003061, loss_freq: 0.009037
[12:47:56.287] iteration 4994: loss: 0.213246, loss_s1: 0.078012, loss_fp: 0.007319, loss_freq: 0.055567
[12:47:56.951] iteration 4995: loss: 0.082289, loss_s1: 0.031969, loss_fp: 0.001054, loss_freq: 0.014399
[12:47:57.575] iteration 4996: loss: 0.213879, loss_s1: 0.060089, loss_fp: 0.000771, loss_freq: 0.081521
[12:47:58.198] iteration 4997: loss: 0.156099, loss_s1: 0.030539, loss_fp: 0.002638, loss_freq: 0.025709
[12:47:58.813] iteration 4998: loss: 0.101612, loss_s1: 0.037605, loss_fp: 0.001794, loss_freq: 0.027071
[12:47:59.436] iteration 4999: loss: 0.098528, loss_s1: 0.087817, loss_fp: 0.006390, loss_freq: 0.017770
[12:48:00.053] iteration 5000: loss: 0.137715, loss_s1: 0.031893, loss_fp: 0.002202, loss_freq: 0.013817
[12:48:03.335] iteration 5000 : mean_dice : 0.684023
[12:48:03.984] iteration 5001: loss: 0.090320, loss_s1: 0.016739, loss_fp: 0.001477, loss_freq: 0.019008
[12:48:04.611] iteration 5002: loss: 0.148397, loss_s1: 0.057497, loss_fp: 0.006319, loss_freq: 0.036616
[12:48:05.237] iteration 5003: loss: 0.116149, loss_s1: 0.076755, loss_fp: 0.004791, loss_freq: 0.007142
[12:48:05.849] iteration 5004: loss: 0.198192, loss_s1: 0.208688, loss_fp: 0.002765, loss_freq: 0.071245
[12:48:06.462] iteration 5005: loss: 0.077527, loss_s1: 0.041501, loss_fp: 0.001055, loss_freq: 0.014818
[12:48:07.443] iteration 5006: loss: 0.121194, loss_s1: 0.060013, loss_fp: 0.001063, loss_freq: 0.035896
[12:48:08.061] iteration 5007: loss: 0.089707, loss_s1: 0.048529, loss_fp: 0.000894, loss_freq: 0.017255
[12:48:08.684] iteration 5008: loss: 0.097991, loss_s1: 0.076217, loss_fp: 0.001074, loss_freq: 0.035310
[12:48:09.307] iteration 5009: loss: 0.112991, loss_s1: 0.039821, loss_fp: 0.002090, loss_freq: 0.029474
[12:48:09.934] iteration 5010: loss: 0.100832, loss_s1: 0.043705, loss_fp: 0.001458, loss_freq: 0.029975
[12:48:10.553] iteration 5011: loss: 0.086366, loss_s1: 0.015978, loss_fp: 0.001164, loss_freq: 0.009214
[12:48:11.172] iteration 5012: loss: 0.131134, loss_s1: 0.116186, loss_fp: 0.001443, loss_freq: 0.079928
[12:48:11.788] iteration 5013: loss: 0.218512, loss_s1: 0.140886, loss_fp: 0.001160, loss_freq: 0.035367
[12:48:12.445] iteration 5014: loss: 0.077867, loss_s1: 0.020818, loss_fp: 0.000658, loss_freq: 0.025383
[12:48:13.099] iteration 5015: loss: 0.199638, loss_s1: 0.068093, loss_fp: 0.002012, loss_freq: 0.022892
[12:48:13.735] iteration 5016: loss: 0.072307, loss_s1: 0.020511, loss_fp: 0.000969, loss_freq: 0.021395
[12:48:14.360] iteration 5017: loss: 0.095835, loss_s1: 0.028692, loss_fp: 0.002683, loss_freq: 0.050163
[12:48:14.981] iteration 5018: loss: 0.102603, loss_s1: 0.078687, loss_fp: 0.000578, loss_freq: 0.014055
[12:48:15.635] iteration 5019: loss: 0.087276, loss_s1: 0.063976, loss_fp: 0.001135, loss_freq: 0.023379
[12:48:16.286] iteration 5020: loss: 0.104806, loss_s1: 0.039060, loss_fp: 0.001258, loss_freq: 0.031543
[12:48:16.920] iteration 5021: loss: 0.125739, loss_s1: 0.043881, loss_fp: 0.005698, loss_freq: 0.032783
[12:48:17.551] iteration 5022: loss: 0.186743, loss_s1: 0.028540, loss_fp: 0.001988, loss_freq: 0.012932
[12:48:18.173] iteration 5023: loss: 0.160623, loss_s1: 0.068585, loss_fp: 0.001426, loss_freq: 0.013061
[12:48:18.798] iteration 5024: loss: 0.098853, loss_s1: 0.027884, loss_fp: 0.003378, loss_freq: 0.020433
[12:48:19.422] iteration 5025: loss: 0.106610, loss_s1: 0.049157, loss_fp: 0.004190, loss_freq: 0.025401
[12:48:20.039] iteration 5026: loss: 0.151319, loss_s1: 0.038578, loss_fp: 0.001660, loss_freq: 0.030024
[12:48:20.663] iteration 5027: loss: 0.114420, loss_s1: 0.092249, loss_fp: 0.000787, loss_freq: 0.032466
[12:48:21.284] iteration 5028: loss: 0.103581, loss_s1: 0.051416, loss_fp: 0.000652, loss_freq: 0.053913
[12:48:21.914] iteration 5029: loss: 0.131363, loss_s1: 0.041862, loss_fp: 0.004251, loss_freq: 0.020971
[12:48:22.539] iteration 5030: loss: 0.140953, loss_s1: 0.078740, loss_fp: 0.000705, loss_freq: 0.099141
[12:48:23.160] iteration 5031: loss: 0.125410, loss_s1: 0.040321, loss_fp: 0.000972, loss_freq: 0.028482
[12:48:23.826] iteration 5032: loss: 0.132849, loss_s1: 0.023205, loss_fp: 0.002024, loss_freq: 0.041066
[12:48:24.454] iteration 5033: loss: 0.080518, loss_s1: 0.028216, loss_fp: 0.002469, loss_freq: 0.009424
[12:48:25.083] iteration 5034: loss: 0.136787, loss_s1: 0.068033, loss_fp: 0.001468, loss_freq: 0.015223
[12:48:25.717] iteration 5035: loss: 0.162415, loss_s1: 0.040151, loss_fp: 0.019967, loss_freq: 0.063209
[12:48:26.330] iteration 5036: loss: 0.134935, loss_s1: 0.035942, loss_fp: 0.001345, loss_freq: 0.013224
[12:48:26.946] iteration 5037: loss: 0.069540, loss_s1: 0.026431, loss_fp: 0.000826, loss_freq: 0.010991
[12:48:27.574] iteration 5038: loss: 0.118019, loss_s1: 0.033071, loss_fp: 0.006124, loss_freq: 0.016147
[12:48:28.200] iteration 5039: loss: 0.086824, loss_s1: 0.034736, loss_fp: 0.002667, loss_freq: 0.022968
[12:48:28.815] iteration 5040: loss: 0.135404, loss_s1: 0.030401, loss_fp: 0.002083, loss_freq: 0.008240
[12:48:29.425] iteration 5041: loss: 0.147917, loss_s1: 0.099922, loss_fp: 0.001342, loss_freq: 0.049150
[12:48:30.044] iteration 5042: loss: 0.132469, loss_s1: 0.084621, loss_fp: 0.001588, loss_freq: 0.024509
[12:48:30.664] iteration 5043: loss: 0.087473, loss_s1: 0.041984, loss_fp: 0.000884, loss_freq: 0.023795
[12:48:31.286] iteration 5044: loss: 0.122114, loss_s1: 0.016039, loss_fp: 0.002420, loss_freq: 0.026357
[12:48:31.903] iteration 5045: loss: 0.090784, loss_s1: 0.029017, loss_fp: 0.001086, loss_freq: 0.013589
[12:48:32.561] iteration 5046: loss: 0.118395, loss_s1: 0.070625, loss_fp: 0.001283, loss_freq: 0.008702
[12:48:33.219] iteration 5047: loss: 0.078794, loss_s1: 0.038876, loss_fp: 0.000397, loss_freq: 0.030375
[12:48:33.856] iteration 5048: loss: 0.122323, loss_s1: 0.030016, loss_fp: 0.000808, loss_freq: 0.010597
[12:48:34.475] iteration 5049: loss: 0.091276, loss_s1: 0.027885, loss_fp: 0.012249, loss_freq: 0.037786
[12:48:35.096] iteration 5050: loss: 0.225698, loss_s1: 0.091344, loss_fp: 0.001992, loss_freq: 0.070877
[12:48:35.718] iteration 5051: loss: 0.106146, loss_s1: 0.044506, loss_fp: 0.006869, loss_freq: 0.029447
[12:48:36.348] iteration 5052: loss: 0.078396, loss_s1: 0.027399, loss_fp: 0.003931, loss_freq: 0.030078
[12:48:36.963] iteration 5053: loss: 0.098089, loss_s1: 0.016581, loss_fp: 0.014705, loss_freq: 0.025558
[12:48:37.575] iteration 5054: loss: 0.091802, loss_s1: 0.084715, loss_fp: 0.000755, loss_freq: 0.019142
[12:48:38.194] iteration 5055: loss: 0.109044, loss_s1: 0.050636, loss_fp: 0.002950, loss_freq: 0.029796
[12:48:38.812] iteration 5056: loss: 0.143441, loss_s1: 0.050856, loss_fp: 0.005836, loss_freq: 0.024747
[12:48:39.427] iteration 5057: loss: 0.213624, loss_s1: 0.060430, loss_fp: 0.003152, loss_freq: 0.027042
[12:48:40.052] iteration 5058: loss: 0.125324, loss_s1: 0.077721, loss_fp: 0.002675, loss_freq: 0.022541
[12:48:40.671] iteration 5059: loss: 0.074361, loss_s1: 0.041035, loss_fp: 0.002316, loss_freq: 0.009679
[12:48:41.284] iteration 5060: loss: 0.110159, loss_s1: 0.043738, loss_fp: 0.005320, loss_freq: 0.029601
[12:48:41.902] iteration 5061: loss: 0.156571, loss_s1: 0.083623, loss_fp: 0.000936, loss_freq: 0.017771
[12:48:42.533] iteration 5062: loss: 0.143013, loss_s1: 0.097806, loss_fp: 0.029414, loss_freq: 0.016541
[12:48:43.150] iteration 5063: loss: 0.075167, loss_s1: 0.048947, loss_fp: 0.001949, loss_freq: 0.018976
[12:48:43.767] iteration 5064: loss: 0.162766, loss_s1: 0.053649, loss_fp: 0.001324, loss_freq: 0.044048
[12:48:44.379] iteration 5065: loss: 0.085232, loss_s1: 0.061669, loss_fp: 0.004101, loss_freq: 0.012196
[12:48:44.994] iteration 5066: loss: 0.147859, loss_s1: 0.053128, loss_fp: 0.000739, loss_freq: 0.006697
[12:48:45.614] iteration 5067: loss: 0.164246, loss_s1: 0.052634, loss_fp: 0.000859, loss_freq: 0.009520
[12:48:46.232] iteration 5068: loss: 0.139145, loss_s1: 0.052979, loss_fp: 0.002759, loss_freq: 0.048973
[12:48:46.851] iteration 5069: loss: 0.192933, loss_s1: 0.080274, loss_fp: 0.002116, loss_freq: 0.019654
[12:48:47.470] iteration 5070: loss: 0.147039, loss_s1: 0.088077, loss_fp: 0.002450, loss_freq: 0.027409
[12:48:48.117] iteration 5071: loss: 0.151346, loss_s1: 0.035767, loss_fp: 0.001360, loss_freq: 0.020027
[12:48:48.744] iteration 5072: loss: 0.124878, loss_s1: 0.064482, loss_fp: 0.000809, loss_freq: 0.051391
[12:48:49.370] iteration 5073: loss: 0.179528, loss_s1: 0.062785, loss_fp: 0.001941, loss_freq: 0.037205
[12:48:49.991] iteration 5074: loss: 0.077373, loss_s1: 0.036751, loss_fp: 0.001664, loss_freq: 0.013038
[12:48:50.615] iteration 5075: loss: 0.143206, loss_s1: 0.045627, loss_fp: 0.002016, loss_freq: 0.005906
[12:48:51.239] iteration 5076: loss: 0.178215, loss_s1: 0.047236, loss_fp: 0.001409, loss_freq: 0.006313
[12:48:51.870] iteration 5077: loss: 0.082606, loss_s1: 0.034068, loss_fp: 0.001963, loss_freq: 0.014457
[12:48:52.495] iteration 5078: loss: 0.065116, loss_s1: 0.004653, loss_fp: 0.000932, loss_freq: 0.023694
[12:48:53.128] iteration 5079: loss: 0.133947, loss_s1: 0.076979, loss_fp: 0.000983, loss_freq: 0.013193
[12:48:53.746] iteration 5080: loss: 0.148776, loss_s1: 0.074874, loss_fp: 0.001770, loss_freq: 0.058772
[12:48:54.371] iteration 5081: loss: 0.086400, loss_s1: 0.018208, loss_fp: 0.001049, loss_freq: 0.007206
[12:48:55.017] iteration 5082: loss: 0.064589, loss_s1: 0.028346, loss_fp: 0.000989, loss_freq: 0.020094
[12:48:55.646] iteration 5083: loss: 0.120221, loss_s1: 0.027366, loss_fp: 0.000854, loss_freq: 0.026136
[12:48:56.281] iteration 5084: loss: 0.190249, loss_s1: 0.149797, loss_fp: 0.002428, loss_freq: 0.123256
[12:48:56.914] iteration 5085: loss: 0.260839, loss_s1: 0.069812, loss_fp: 0.001569, loss_freq: 0.018609
[12:48:57.551] iteration 5086: loss: 0.124636, loss_s1: 0.041916, loss_fp: 0.003686, loss_freq: 0.017710
[12:48:58.175] iteration 5087: loss: 0.107473, loss_s1: 0.055919, loss_fp: 0.000736, loss_freq: 0.029812
[12:48:58.802] iteration 5088: loss: 0.127082, loss_s1: 0.014642, loss_fp: 0.000730, loss_freq: 0.023048
[12:48:59.423] iteration 5089: loss: 0.048957, loss_s1: 0.026038, loss_fp: 0.001966, loss_freq: 0.002376
[12:49:00.055] iteration 5090: loss: 0.104634, loss_s1: 0.042535, loss_fp: 0.001089, loss_freq: 0.026158
[12:49:00.698] iteration 5091: loss: 0.109347, loss_s1: 0.087067, loss_fp: 0.002967, loss_freq: 0.035423
[12:49:01.317] iteration 5092: loss: 0.129433, loss_s1: 0.020250, loss_fp: 0.004116, loss_freq: 0.011310
[12:49:01.975] iteration 5093: loss: 0.108620, loss_s1: 0.020813, loss_fp: 0.001495, loss_freq: 0.010563
[12:49:02.636] iteration 5094: loss: 0.096736, loss_s1: 0.057533, loss_fp: 0.005112, loss_freq: 0.018224
[12:49:03.299] iteration 5095: loss: 0.093309, loss_s1: 0.073648, loss_fp: 0.004494, loss_freq: 0.032932
[12:49:03.966] iteration 5096: loss: 0.140100, loss_s1: 0.023717, loss_fp: 0.001870, loss_freq: 0.028197
[12:49:04.624] iteration 5097: loss: 0.141344, loss_s1: 0.071127, loss_fp: 0.001119, loss_freq: 0.099355
[12:49:05.266] iteration 5098: loss: 0.066517, loss_s1: 0.032221, loss_fp: 0.002110, loss_freq: 0.007393
[12:49:05.887] iteration 5099: loss: 0.121732, loss_s1: 0.037611, loss_fp: 0.001875, loss_freq: 0.022166
[12:49:06.514] iteration 5100: loss: 0.070805, loss_s1: 0.022213, loss_fp: 0.000977, loss_freq: 0.028005
[12:49:07.128] iteration 5101: loss: 0.172386, loss_s1: 0.107986, loss_fp: 0.011009, loss_freq: 0.051246
[12:49:07.748] iteration 5102: loss: 0.263393, loss_s1: 0.173659, loss_fp: 0.003021, loss_freq: 0.196834
[12:49:08.367] iteration 5103: loss: 0.102091, loss_s1: 0.028183, loss_fp: 0.013044, loss_freq: 0.045761
[12:49:08.989] iteration 5104: loss: 0.174720, loss_s1: 0.054068, loss_fp: 0.002063, loss_freq: 0.078284
[12:49:09.615] iteration 5105: loss: 0.165810, loss_s1: 0.048315, loss_fp: 0.004625, loss_freq: 0.084920
[12:49:10.239] iteration 5106: loss: 0.154257, loss_s1: 0.112375, loss_fp: 0.004146, loss_freq: 0.023600
[12:49:10.860] iteration 5107: loss: 0.110636, loss_s1: 0.025591, loss_fp: 0.037369, loss_freq: 0.026612
[12:49:11.479] iteration 5108: loss: 0.097433, loss_s1: 0.044367, loss_fp: 0.000850, loss_freq: 0.007437
[12:49:12.135] iteration 5109: loss: 0.142140, loss_s1: 0.086029, loss_fp: 0.003650, loss_freq: 0.085527
[12:49:12.791] iteration 5110: loss: 0.196021, loss_s1: 0.034141, loss_fp: 0.002178, loss_freq: 0.075815
[12:49:13.456] iteration 5111: loss: 0.125862, loss_s1: 0.033648, loss_fp: 0.000984, loss_freq: 0.037974
[12:49:14.132] iteration 5112: loss: 0.168163, loss_s1: 0.112156, loss_fp: 0.001307, loss_freq: 0.103758
[12:49:14.750] iteration 5113: loss: 0.117020, loss_s1: 0.105417, loss_fp: 0.001466, loss_freq: 0.028222
[12:49:15.365] iteration 5114: loss: 0.119504, loss_s1: 0.033056, loss_fp: 0.001542, loss_freq: 0.005677
[12:49:16.038] iteration 5115: loss: 0.100499, loss_s1: 0.059532, loss_fp: 0.000607, loss_freq: 0.030085
[12:49:16.702] iteration 5116: loss: 0.123326, loss_s1: 0.064550, loss_fp: 0.000439, loss_freq: 0.021930
[12:49:17.367] iteration 5117: loss: 0.080223, loss_s1: 0.018492, loss_fp: 0.002544, loss_freq: 0.046082
[12:49:17.992] iteration 5118: loss: 0.135791, loss_s1: 0.054221, loss_fp: 0.001494, loss_freq: 0.013324
[12:49:18.612] iteration 5119: loss: 0.103447, loss_s1: 0.100201, loss_fp: 0.002338, loss_freq: 0.017397
[12:49:19.235] iteration 5120: loss: 0.346958, loss_s1: 0.084914, loss_fp: 0.000925, loss_freq: 0.022207
[12:49:19.852] iteration 5121: loss: 0.092925, loss_s1: 0.053339, loss_fp: 0.001279, loss_freq: 0.014841
[12:49:20.463] iteration 5122: loss: 0.108136, loss_s1: 0.018552, loss_fp: 0.003668, loss_freq: 0.057263
[12:49:21.077] iteration 5123: loss: 0.169194, loss_s1: 0.048437, loss_fp: 0.005584, loss_freq: 0.086328
[12:49:21.702] iteration 5124: loss: 0.059746, loss_s1: 0.033545, loss_fp: 0.001865, loss_freq: 0.008936
[12:49:22.353] iteration 5125: loss: 0.134575, loss_s1: 0.040110, loss_fp: 0.002043, loss_freq: 0.048460
[12:49:22.971] iteration 5126: loss: 0.138615, loss_s1: 0.059786, loss_fp: 0.001373, loss_freq: 0.119806
[12:49:23.589] iteration 5127: loss: 0.216414, loss_s1: 0.069343, loss_fp: 0.001830, loss_freq: 0.078586
[12:49:24.214] iteration 5128: loss: 0.126068, loss_s1: 0.029741, loss_fp: 0.001482, loss_freq: 0.011875
[12:49:24.831] iteration 5129: loss: 0.134617, loss_s1: 0.068103, loss_fp: 0.005908, loss_freq: 0.056767
[12:49:25.449] iteration 5130: loss: 0.141247, loss_s1: 0.078640, loss_fp: 0.000425, loss_freq: 0.058729
[12:49:26.070] iteration 5131: loss: 0.218894, loss_s1: 0.092742, loss_fp: 0.007229, loss_freq: 0.048348
[12:49:26.682] iteration 5132: loss: 0.147200, loss_s1: 0.056976, loss_fp: 0.001116, loss_freq: 0.037800
[12:49:27.300] iteration 5133: loss: 0.078490, loss_s1: 0.043459, loss_fp: 0.000980, loss_freq: 0.024972
[12:49:27.918] iteration 5134: loss: 0.144631, loss_s1: 0.089787, loss_fp: 0.000753, loss_freq: 0.015328
[12:49:28.536] iteration 5135: loss: 0.066356, loss_s1: 0.018020, loss_fp: 0.000509, loss_freq: 0.005422
[12:49:29.168] iteration 5136: loss: 0.146464, loss_s1: 0.049461, loss_fp: 0.000984, loss_freq: 0.005543
[12:49:29.793] iteration 5137: loss: 0.175570, loss_s1: 0.029591, loss_fp: 0.000988, loss_freq: 0.007779
[12:49:30.406] iteration 5138: loss: 0.104143, loss_s1: 0.018788, loss_fp: 0.001094, loss_freq: 0.022964
[12:49:31.032] iteration 5139: loss: 0.137830, loss_s1: 0.009692, loss_fp: 0.000419, loss_freq: 0.035981
[12:49:31.658] iteration 5140: loss: 0.140247, loss_s1: 0.064856, loss_fp: 0.002550, loss_freq: 0.032741
[12:49:32.279] iteration 5141: loss: 0.096777, loss_s1: 0.034013, loss_fp: 0.001047, loss_freq: 0.013080
[12:49:32.935] iteration 5142: loss: 0.159505, loss_s1: 0.123182, loss_fp: 0.001301, loss_freq: 0.030427
[12:49:33.628] iteration 5143: loss: 0.080112, loss_s1: 0.011036, loss_fp: 0.001070, loss_freq: 0.021282
[12:49:34.282] iteration 5144: loss: 0.109335, loss_s1: 0.054490, loss_fp: 0.002354, loss_freq: 0.031876
[12:49:34.935] iteration 5145: loss: 0.121378, loss_s1: 0.025473, loss_fp: 0.000976, loss_freq: 0.007492
[12:49:35.587] iteration 5146: loss: 0.135890, loss_s1: 0.022346, loss_fp: 0.001524, loss_freq: 0.031580
[12:49:36.235] iteration 5147: loss: 0.113903, loss_s1: 0.063962, loss_fp: 0.001125, loss_freq: 0.034279
[12:49:36.886] iteration 5148: loss: 0.096821, loss_s1: 0.046792, loss_fp: 0.001638, loss_freq: 0.048918
[12:49:37.840] iteration 5149: loss: 0.120002, loss_s1: 0.064007, loss_fp: 0.000700, loss_freq: 0.030934
[12:49:38.518] iteration 5150: loss: 0.126533, loss_s1: 0.058228, loss_fp: 0.002354, loss_freq: 0.063916
[12:49:39.186] iteration 5151: loss: 0.084969, loss_s1: 0.041361, loss_fp: 0.002355, loss_freq: 0.032890
[12:49:39.833] iteration 5152: loss: 0.092669, loss_s1: 0.027149, loss_fp: 0.001667, loss_freq: 0.017813
[12:49:40.485] iteration 5153: loss: 0.139663, loss_s1: 0.020547, loss_fp: 0.005399, loss_freq: 0.042810
[12:49:41.147] iteration 5154: loss: 0.084873, loss_s1: 0.011767, loss_fp: 0.000886, loss_freq: 0.007317
[12:49:41.783] iteration 5155: loss: 0.080579, loss_s1: 0.042101, loss_fp: 0.003585, loss_freq: 0.052073
[12:49:42.401] iteration 5156: loss: 0.172161, loss_s1: 0.094692, loss_fp: 0.001758, loss_freq: 0.012082
[12:49:43.014] iteration 5157: loss: 0.100156, loss_s1: 0.024843, loss_fp: 0.001594, loss_freq: 0.024220
[12:49:43.631] iteration 5158: loss: 0.180023, loss_s1: 0.032912, loss_fp: 0.000903, loss_freq: 0.014349
[12:49:44.244] iteration 5159: loss: 0.127135, loss_s1: 0.077451, loss_fp: 0.002829, loss_freq: 0.058104
[12:49:44.948] iteration 5160: loss: 0.102633, loss_s1: 0.041651, loss_fp: 0.001471, loss_freq: 0.054481
[12:49:45.825] iteration 5161: loss: 0.119446, loss_s1: 0.059206, loss_fp: 0.000856, loss_freq: 0.054157
[12:49:46.636] iteration 5162: loss: 0.063875, loss_s1: 0.034559, loss_fp: 0.000642, loss_freq: 0.013713
[12:49:47.253] iteration 5163: loss: 0.121597, loss_s1: 0.045585, loss_fp: 0.002735, loss_freq: 0.023862
[12:49:47.872] iteration 5164: loss: 0.110448, loss_s1: 0.039489, loss_fp: 0.000797, loss_freq: 0.027650
[12:49:48.483] iteration 5165: loss: 0.189116, loss_s1: 0.021699, loss_fp: 0.001443, loss_freq: 0.024621
[12:49:49.098] iteration 5166: loss: 0.149872, loss_s1: 0.038480, loss_fp: 0.002192, loss_freq: 0.019642
[12:49:49.725] iteration 5167: loss: 0.090102, loss_s1: 0.039484, loss_fp: 0.000697, loss_freq: 0.018597
[12:49:50.358] iteration 5168: loss: 0.107258, loss_s1: 0.054198, loss_fp: 0.000943, loss_freq: 0.021142
[12:49:50.980] iteration 5169: loss: 0.168990, loss_s1: 0.062232, loss_fp: 0.002755, loss_freq: 0.038975
[12:49:51.600] iteration 5170: loss: 0.081832, loss_s1: 0.032700, loss_fp: 0.000368, loss_freq: 0.009408
[12:49:52.267] iteration 5171: loss: 0.105075, loss_s1: 0.069869, loss_fp: 0.000660, loss_freq: 0.018417
[12:49:52.878] iteration 5172: loss: 0.160999, loss_s1: 0.091385, loss_fp: 0.001414, loss_freq: 0.035315
[12:49:53.492] iteration 5173: loss: 0.084934, loss_s1: 0.047708, loss_fp: 0.004900, loss_freq: 0.017193
[12:49:54.115] iteration 5174: loss: 0.127000, loss_s1: 0.070521, loss_fp: 0.000505, loss_freq: 0.016572
[12:49:54.738] iteration 5175: loss: 0.120032, loss_s1: 0.024026, loss_fp: 0.001383, loss_freq: 0.031073
[12:49:55.372] iteration 5176: loss: 0.075248, loss_s1: 0.018718, loss_fp: 0.001712, loss_freq: 0.011057
[12:49:55.986] iteration 5177: loss: 0.157851, loss_s1: 0.036283, loss_fp: 0.000722, loss_freq: 0.036392
[12:49:56.603] iteration 5178: loss: 0.140698, loss_s1: 0.043360, loss_fp: 0.001228, loss_freq: 0.017783
[12:49:57.226] iteration 5179: loss: 0.098535, loss_s1: 0.022144, loss_fp: 0.000845, loss_freq: 0.009507
[12:49:57.841] iteration 5180: loss: 0.089726, loss_s1: 0.037968, loss_fp: 0.000862, loss_freq: 0.035700
[12:49:58.465] iteration 5181: loss: 0.104732, loss_s1: 0.032688, loss_fp: 0.001039, loss_freq: 0.018764
[12:49:59.088] iteration 5182: loss: 0.071106, loss_s1: 0.048044, loss_fp: 0.002781, loss_freq: 0.011412
[12:49:59.707] iteration 5183: loss: 0.133408, loss_s1: 0.079844, loss_fp: 0.001575, loss_freq: 0.015835
[12:50:00.391] iteration 5184: loss: 0.146649, loss_s1: 0.064998, loss_fp: 0.004017, loss_freq: 0.023138
[12:50:01.044] iteration 5185: loss: 0.172098, loss_s1: 0.137424, loss_fp: 0.000831, loss_freq: 0.100063
[12:50:01.686] iteration 5186: loss: 0.109728, loss_s1: 0.073652, loss_fp: 0.002228, loss_freq: 0.057774
[12:50:02.331] iteration 5187: loss: 0.169656, loss_s1: 0.083053, loss_fp: 0.001208, loss_freq: 0.065506
[12:50:02.948] iteration 5188: loss: 0.176541, loss_s1: 0.073463, loss_fp: 0.003801, loss_freq: 0.044197
[12:50:03.567] iteration 5189: loss: 0.135606, loss_s1: 0.073938, loss_fp: 0.001300, loss_freq: 0.011014
[12:50:04.182] iteration 5190: loss: 0.072739, loss_s1: 0.038263, loss_fp: 0.002365, loss_freq: 0.010910
[12:50:04.796] iteration 5191: loss: 0.109816, loss_s1: 0.048889, loss_fp: 0.000649, loss_freq: 0.012525
[12:50:05.409] iteration 5192: loss: 0.103197, loss_s1: 0.072985, loss_fp: 0.003076, loss_freq: 0.030684
[12:50:06.022] iteration 5193: loss: 0.218755, loss_s1: 0.036715, loss_fp: 0.001989, loss_freq: 0.029872
[12:50:06.634] iteration 5194: loss: 0.096549, loss_s1: 0.047957, loss_fp: 0.001300, loss_freq: 0.017065
[12:50:07.251] iteration 5195: loss: 0.138800, loss_s1: 0.022819, loss_fp: 0.002687, loss_freq: 0.020178
[12:50:07.913] iteration 5196: loss: 0.135108, loss_s1: 0.044841, loss_fp: 0.007534, loss_freq: 0.074878
[12:50:08.578] iteration 5197: loss: 0.078224, loss_s1: 0.042108, loss_fp: 0.023479, loss_freq: 0.005398
[12:50:09.236] iteration 5198: loss: 0.168484, loss_s1: 0.113179, loss_fp: 0.005211, loss_freq: 0.035932
[12:50:09.898] iteration 5199: loss: 0.106071, loss_s1: 0.049464, loss_fp: 0.000537, loss_freq: 0.030508
[12:50:10.523] iteration 5200: loss: 0.176031, loss_s1: 0.071373, loss_fp: 0.001612, loss_freq: 0.016702
[12:50:13.787] iteration 5200 : mean_dice : 0.682401
[12:50:14.430] iteration 5201: loss: 0.078398, loss_s1: 0.039896, loss_fp: 0.002328, loss_freq: 0.006261
[12:50:15.050] iteration 5202: loss: 0.096286, loss_s1: 0.082218, loss_fp: 0.000996, loss_freq: 0.008787
[12:50:15.661] iteration 5203: loss: 0.096331, loss_s1: 0.032730, loss_fp: 0.003904, loss_freq: 0.013318
[12:50:16.270] iteration 5204: loss: 0.151735, loss_s1: 0.021392, loss_fp: 0.003794, loss_freq: 0.008744
[12:50:16.885] iteration 5205: loss: 0.136638, loss_s1: 0.137626, loss_fp: 0.007690, loss_freq: 0.014484
[12:50:17.493] iteration 5206: loss: 0.094041, loss_s1: 0.042469, loss_fp: 0.000538, loss_freq: 0.035089
[12:50:18.102] iteration 5207: loss: 0.138277, loss_s1: 0.041739, loss_fp: 0.001798, loss_freq: 0.035430
[12:50:18.718] iteration 5208: loss: 0.091512, loss_s1: 0.036981, loss_fp: 0.003606, loss_freq: 0.059335
[12:50:19.328] iteration 5209: loss: 0.124871, loss_s1: 0.036289, loss_fp: 0.000683, loss_freq: 0.033088
[12:50:19.944] iteration 5210: loss: 0.142999, loss_s1: 0.048178, loss_fp: 0.003382, loss_freq: 0.017496
[12:50:20.563] iteration 5211: loss: 0.119950, loss_s1: 0.083324, loss_fp: 0.003606, loss_freq: 0.026311
[12:50:21.182] iteration 5212: loss: 0.169355, loss_s1: 0.033391, loss_fp: 0.001647, loss_freq: 0.027592
[12:50:21.851] iteration 5213: loss: 0.150203, loss_s1: 0.086343, loss_fp: 0.002804, loss_freq: 0.024849
[12:50:22.510] iteration 5214: loss: 0.174036, loss_s1: 0.055867, loss_fp: 0.001171, loss_freq: 0.044496
[12:50:23.167] iteration 5215: loss: 0.136537, loss_s1: 0.101838, loss_fp: 0.001553, loss_freq: 0.023097
[12:50:23.804] iteration 5216: loss: 0.138548, loss_s1: 0.030961, loss_fp: 0.000721, loss_freq: 0.017824
[12:50:24.420] iteration 5217: loss: 0.120771, loss_s1: 0.081175, loss_fp: 0.001555, loss_freq: 0.012734
[12:50:25.048] iteration 5218: loss: 0.127502, loss_s1: 0.043906, loss_fp: 0.001063, loss_freq: 0.009650
[12:50:25.676] iteration 5219: loss: 0.167454, loss_s1: 0.064393, loss_fp: 0.001278, loss_freq: 0.022755
[12:50:26.305] iteration 5220: loss: 0.099357, loss_s1: 0.051493, loss_fp: 0.002863, loss_freq: 0.031677
[12:50:26.939] iteration 5221: loss: 0.120368, loss_s1: 0.053917, loss_fp: 0.002133, loss_freq: 0.087342
[12:50:27.560] iteration 5222: loss: 0.133477, loss_s1: 0.023722, loss_fp: 0.002496, loss_freq: 0.047949
[12:50:28.187] iteration 5223: loss: 0.095722, loss_s1: 0.037442, loss_fp: 0.004041, loss_freq: 0.047430
[12:50:28.805] iteration 5224: loss: 0.144255, loss_s1: 0.133828, loss_fp: 0.005096, loss_freq: 0.013603
[12:50:29.420] iteration 5225: loss: 0.076332, loss_s1: 0.009989, loss_fp: 0.001587, loss_freq: 0.022430
[12:50:30.057] iteration 5226: loss: 0.102760, loss_s1: 0.016849, loss_fp: 0.000868, loss_freq: 0.007378
[12:50:30.684] iteration 5227: loss: 0.097940, loss_s1: 0.029033, loss_fp: 0.003508, loss_freq: 0.068522
[12:50:31.311] iteration 5228: loss: 0.244833, loss_s1: 0.021803, loss_fp: 0.001013, loss_freq: 0.045203
[12:50:31.943] iteration 5229: loss: 0.089142, loss_s1: 0.022533, loss_fp: 0.000917, loss_freq: 0.020441
[12:50:32.556] iteration 5230: loss: 0.090965, loss_s1: 0.045886, loss_fp: 0.003970, loss_freq: 0.032627
[12:50:33.199] iteration 5231: loss: 0.108976, loss_s1: 0.064653, loss_fp: 0.001203, loss_freq: 0.034948
[12:50:33.820] iteration 5232: loss: 0.098425, loss_s1: 0.061064, loss_fp: 0.001659, loss_freq: 0.054815
[12:50:34.441] iteration 5233: loss: 0.092556, loss_s1: 0.028947, loss_fp: 0.001368, loss_freq: 0.024748
[12:50:35.065] iteration 5234: loss: 0.154699, loss_s1: 0.079627, loss_fp: 0.002925, loss_freq: 0.066023
[12:50:35.677] iteration 5235: loss: 0.155608, loss_s1: 0.034213, loss_fp: 0.000569, loss_freq: 0.009193
[12:50:36.290] iteration 5236: loss: 0.113876, loss_s1: 0.063346, loss_fp: 0.001535, loss_freq: 0.019915
[12:50:36.907] iteration 5237: loss: 0.089310, loss_s1: 0.040370, loss_fp: 0.000997, loss_freq: 0.016934
[12:50:37.520] iteration 5238: loss: 0.077594, loss_s1: 0.052842, loss_fp: 0.002356, loss_freq: 0.010160
[12:50:38.137] iteration 5239: loss: 0.145088, loss_s1: 0.016179, loss_fp: 0.004878, loss_freq: 0.036113
[12:50:38.755] iteration 5240: loss: 0.104711, loss_s1: 0.015026, loss_fp: 0.001868, loss_freq: 0.075149
[12:50:39.374] iteration 5241: loss: 0.089695, loss_s1: 0.071065, loss_fp: 0.011907, loss_freq: 0.011565
[12:50:39.993] iteration 5242: loss: 0.150836, loss_s1: 0.069657, loss_fp: 0.003366, loss_freq: 0.053613
[12:50:40.614] iteration 5243: loss: 0.088820, loss_s1: 0.039938, loss_fp: 0.001128, loss_freq: 0.020064
[12:50:41.232] iteration 5244: loss: 0.137713, loss_s1: 0.053873, loss_fp: 0.000456, loss_freq: 0.031866
[12:50:41.847] iteration 5245: loss: 0.175380, loss_s1: 0.064163, loss_fp: 0.001616, loss_freq: 0.095393
[12:50:42.468] iteration 5246: loss: 0.123321, loss_s1: 0.051280, loss_fp: 0.000955, loss_freq: 0.050065
[12:50:43.085] iteration 5247: loss: 0.144093, loss_s1: 0.029564, loss_fp: 0.001487, loss_freq: 0.056653
[12:50:43.698] iteration 5248: loss: 0.146051, loss_s1: 0.077260, loss_fp: 0.002299, loss_freq: 0.073879
[12:50:44.327] iteration 5249: loss: 0.154815, loss_s1: 0.081049, loss_fp: 0.001406, loss_freq: 0.066620
[12:50:44.945] iteration 5250: loss: 0.078108, loss_s1: 0.021765, loss_fp: 0.000423, loss_freq: 0.009972
[12:50:45.632] iteration 5251: loss: 0.125275, loss_s1: 0.047578, loss_fp: 0.000646, loss_freq: 0.013957
[12:50:46.286] iteration 5252: loss: 0.140279, loss_s1: 0.079787, loss_fp: 0.001602, loss_freq: 0.042856
[12:50:46.940] iteration 5253: loss: 0.160183, loss_s1: 0.027693, loss_fp: 0.001123, loss_freq: 0.031570
[12:50:47.598] iteration 5254: loss: 0.091973, loss_s1: 0.029685, loss_fp: 0.000616, loss_freq: 0.028139
[12:50:48.250] iteration 5255: loss: 0.140169, loss_s1: 0.056399, loss_fp: 0.000965, loss_freq: 0.102449
[12:50:48.877] iteration 5256: loss: 0.065869, loss_s1: 0.019379, loss_fp: 0.002897, loss_freq: 0.026127
[12:50:49.495] iteration 5257: loss: 0.149315, loss_s1: 0.058465, loss_fp: 0.000547, loss_freq: 0.002053
[12:50:50.111] iteration 5258: loss: 0.128386, loss_s1: 0.074159, loss_fp: 0.001326, loss_freq: 0.026015
[12:50:50.729] iteration 5259: loss: 0.085618, loss_s1: 0.017680, loss_fp: 0.001326, loss_freq: 0.007802
[12:50:51.347] iteration 5260: loss: 0.060044, loss_s1: 0.038867, loss_fp: 0.001554, loss_freq: 0.017127
[12:50:51.961] iteration 5261: loss: 0.127819, loss_s1: 0.061036, loss_fp: 0.002759, loss_freq: 0.017289
[12:50:52.578] iteration 5262: loss: 0.095054, loss_s1: 0.056074, loss_fp: 0.004093, loss_freq: 0.035891
[12:50:53.202] iteration 5263: loss: 0.271322, loss_s1: 0.068467, loss_fp: 0.000642, loss_freq: 0.043322
[12:50:53.827] iteration 5264: loss: 0.135962, loss_s1: 0.033688, loss_fp: 0.001929, loss_freq: 0.030032
[12:50:54.439] iteration 5265: loss: 0.112860, loss_s1: 0.072088, loss_fp: 0.000617, loss_freq: 0.027692
[12:50:55.060] iteration 5266: loss: 0.159886, loss_s1: 0.057417, loss_fp: 0.000834, loss_freq: 0.075140
[12:50:55.664] iteration 5267: loss: 0.070987, loss_s1: 0.052821, loss_fp: 0.001819, loss_freq: 0.010288
[12:50:56.274] iteration 5268: loss: 0.095692, loss_s1: 0.018680, loss_fp: 0.004126, loss_freq: 0.032230
[12:50:56.891] iteration 5269: loss: 0.201865, loss_s1: 0.115153, loss_fp: 0.002349, loss_freq: 0.120678
[12:50:57.502] iteration 5270: loss: 0.163760, loss_s1: 0.035058, loss_fp: 0.001283, loss_freq: 0.028078
[12:50:58.115] iteration 5271: loss: 0.130695, loss_s1: 0.032026, loss_fp: 0.000847, loss_freq: 0.018143
[12:50:58.730] iteration 5272: loss: 0.102108, loss_s1: 0.051518, loss_fp: 0.001282, loss_freq: 0.024056
[12:50:59.351] iteration 5273: loss: 0.111145, loss_s1: 0.104149, loss_fp: 0.005249, loss_freq: 0.033400
[12:51:00.040] iteration 5274: loss: 0.137500, loss_s1: 0.044579, loss_fp: 0.002052, loss_freq: 0.025938
[12:51:00.688] iteration 5275: loss: 0.105415, loss_s1: 0.012988, loss_fp: 0.000873, loss_freq: 0.067161
[12:51:01.344] iteration 5276: loss: 0.092580, loss_s1: 0.067119, loss_fp: 0.001537, loss_freq: 0.015506
[12:51:02.001] iteration 5277: loss: 0.160348, loss_s1: 0.069172, loss_fp: 0.006900, loss_freq: 0.034399
[12:51:02.660] iteration 5278: loss: 0.091567, loss_s1: 0.037052, loss_fp: 0.001139, loss_freq: 0.015816
[12:51:03.287] iteration 5279: loss: 0.105665, loss_s1: 0.020931, loss_fp: 0.002991, loss_freq: 0.012629
[12:51:03.901] iteration 5280: loss: 0.206828, loss_s1: 0.056429, loss_fp: 0.002133, loss_freq: 0.030461
[12:51:04.516] iteration 5281: loss: 0.102423, loss_s1: 0.009329, loss_fp: 0.000667, loss_freq: 0.011326
[12:51:05.153] iteration 5282: loss: 0.183008, loss_s1: 0.062352, loss_fp: 0.000655, loss_freq: 0.033538
[12:51:05.770] iteration 5283: loss: 0.151938, loss_s1: 0.034682, loss_fp: 0.007054, loss_freq: 0.029203
[12:51:06.381] iteration 5284: loss: 0.093836, loss_s1: 0.023921, loss_fp: 0.003016, loss_freq: 0.010008
[12:51:06.997] iteration 5285: loss: 0.101045, loss_s1: 0.080676, loss_fp: 0.002127, loss_freq: 0.017650
[12:51:07.615] iteration 5286: loss: 0.149793, loss_s1: 0.043542, loss_fp: 0.002265, loss_freq: 0.022321
[12:51:08.267] iteration 5287: loss: 0.102522, loss_s1: 0.035728, loss_fp: 0.002891, loss_freq: 0.017267
[12:51:08.919] iteration 5288: loss: 0.178660, loss_s1: 0.055128, loss_fp: 0.000824, loss_freq: 0.013366
[12:51:09.564] iteration 5289: loss: 0.123618, loss_s1: 0.085953, loss_fp: 0.001897, loss_freq: 0.007339
[12:51:10.177] iteration 5290: loss: 0.093390, loss_s1: 0.045472, loss_fp: 0.003858, loss_freq: 0.017024
[12:51:10.788] iteration 5291: loss: 0.096199, loss_s1: 0.054763, loss_fp: 0.000589, loss_freq: 0.042983
[12:51:11.766] iteration 5292: loss: 0.142817, loss_s1: 0.076384, loss_fp: 0.002131, loss_freq: 0.017421
[12:51:12.394] iteration 5293: loss: 0.109176, loss_s1: 0.067474, loss_fp: 0.009785, loss_freq: 0.022576
[12:51:13.038] iteration 5294: loss: 0.104435, loss_s1: 0.068920, loss_fp: 0.001592, loss_freq: 0.035959
[12:51:13.652] iteration 5295: loss: 0.099021, loss_s1: 0.067956, loss_fp: 0.002233, loss_freq: 0.009558
[12:51:14.271] iteration 5296: loss: 0.162278, loss_s1: 0.094785, loss_fp: 0.002792, loss_freq: 0.089362
[12:51:14.889] iteration 5297: loss: 0.090793, loss_s1: 0.010293, loss_fp: 0.001156, loss_freq: 0.013370
[12:51:15.505] iteration 5298: loss: 0.118071, loss_s1: 0.077794, loss_fp: 0.003159, loss_freq: 0.076435
[12:51:16.125] iteration 5299: loss: 0.171961, loss_s1: 0.070090, loss_fp: 0.002991, loss_freq: 0.027262
[12:51:16.747] iteration 5300: loss: 0.090245, loss_s1: 0.040851, loss_fp: 0.001259, loss_freq: 0.025834
[12:51:17.380] iteration 5301: loss: 0.174913, loss_s1: 0.018704, loss_fp: 0.001344, loss_freq: 0.010868
[12:51:17.999] iteration 5302: loss: 0.144878, loss_s1: 0.069264, loss_fp: 0.001545, loss_freq: 0.024685
[12:51:18.617] iteration 5303: loss: 0.109882, loss_s1: 0.025285, loss_fp: 0.001693, loss_freq: 0.073618
[12:51:19.228] iteration 5304: loss: 0.083161, loss_s1: 0.027410, loss_fp: 0.001393, loss_freq: 0.008971
[12:51:19.849] iteration 5305: loss: 0.069275, loss_s1: 0.050478, loss_fp: 0.003078, loss_freq: 0.016590
[12:51:20.501] iteration 5306: loss: 0.087943, loss_s1: 0.060989, loss_fp: 0.001133, loss_freq: 0.024875
[12:51:21.157] iteration 5307: loss: 0.085651, loss_s1: 0.034442, loss_fp: 0.002750, loss_freq: 0.018909
[12:51:21.767] iteration 5308: loss: 0.215804, loss_s1: 0.011561, loss_fp: 0.001485, loss_freq: 0.015359
[12:51:22.381] iteration 5309: loss: 0.114975, loss_s1: 0.032827, loss_fp: 0.001078, loss_freq: 0.013816
[12:51:23.001] iteration 5310: loss: 0.104589, loss_s1: 0.043849, loss_fp: 0.001488, loss_freq: 0.016089
[12:51:23.626] iteration 5311: loss: 0.101557, loss_s1: 0.035999, loss_fp: 0.002609, loss_freq: 0.015326
[12:51:24.243] iteration 5312: loss: 0.152957, loss_s1: 0.051380, loss_fp: 0.001648, loss_freq: 0.049125
[12:51:24.864] iteration 5313: loss: 0.114127, loss_s1: 0.065723, loss_fp: 0.001818, loss_freq: 0.045824
[12:51:25.479] iteration 5314: loss: 0.128660, loss_s1: 0.087390, loss_fp: 0.003200, loss_freq: 0.053696
[12:51:26.099] iteration 5315: loss: 0.147945, loss_s1: 0.083819, loss_fp: 0.002729, loss_freq: 0.027790
[12:51:26.719] iteration 5316: loss: 0.088050, loss_s1: 0.021497, loss_fp: 0.000891, loss_freq: 0.040035
[12:51:27.337] iteration 5317: loss: 0.095466, loss_s1: 0.007038, loss_fp: 0.002359, loss_freq: 0.038613
[12:51:27.971] iteration 5318: loss: 0.114113, loss_s1: 0.027523, loss_fp: 0.000871, loss_freq: 0.045962
[12:51:28.591] iteration 5319: loss: 0.094973, loss_s1: 0.070970, loss_fp: 0.003164, loss_freq: 0.008328
[12:51:29.201] iteration 5320: loss: 0.178496, loss_s1: 0.045927, loss_fp: 0.001623, loss_freq: 0.056978
[12:51:29.826] iteration 5321: loss: 0.113278, loss_s1: 0.044920, loss_fp: 0.005591, loss_freq: 0.022011
[12:51:30.447] iteration 5322: loss: 0.084392, loss_s1: 0.040086, loss_fp: 0.001907, loss_freq: 0.002407
[12:51:31.069] iteration 5323: loss: 0.115079, loss_s1: 0.071098, loss_fp: 0.000823, loss_freq: 0.051809
[12:51:31.692] iteration 5324: loss: 0.076227, loss_s1: 0.029836, loss_fp: 0.000700, loss_freq: 0.016726
[12:51:32.310] iteration 5325: loss: 0.158905, loss_s1: 0.118180, loss_fp: 0.003062, loss_freq: 0.099329
[12:51:32.924] iteration 5326: loss: 0.173083, loss_s1: 0.015299, loss_fp: 0.002317, loss_freq: 0.016967
[12:51:33.544] iteration 5327: loss: 0.132601, loss_s1: 0.080799, loss_fp: 0.001754, loss_freq: 0.046256
[12:51:34.161] iteration 5328: loss: 0.097355, loss_s1: 0.045907, loss_fp: 0.001949, loss_freq: 0.012807
[12:51:34.785] iteration 5329: loss: 0.063068, loss_s1: 0.028632, loss_fp: 0.006315, loss_freq: 0.015412
[12:51:35.398] iteration 5330: loss: 0.133086, loss_s1: 0.033260, loss_fp: 0.006890, loss_freq: 0.060679
[12:51:36.023] iteration 5331: loss: 0.137843, loss_s1: 0.059017, loss_fp: 0.001959, loss_freq: 0.026068
[12:51:36.645] iteration 5332: loss: 0.094841, loss_s1: 0.050797, loss_fp: 0.001939, loss_freq: 0.020641
[12:51:37.270] iteration 5333: loss: 0.062580, loss_s1: 0.015232, loss_fp: 0.000682, loss_freq: 0.020247
[12:51:37.936] iteration 5334: loss: 0.138792, loss_s1: 0.053130, loss_fp: 0.001258, loss_freq: 0.007910
[12:51:38.558] iteration 5335: loss: 0.068647, loss_s1: 0.027569, loss_fp: 0.002270, loss_freq: 0.019738
[12:51:39.180] iteration 5336: loss: 0.207078, loss_s1: 0.032288, loss_fp: 0.000630, loss_freq: 0.048559
[12:51:39.807] iteration 5337: loss: 0.140669, loss_s1: 0.098077, loss_fp: 0.001237, loss_freq: 0.024401
[12:51:40.429] iteration 5338: loss: 0.080214, loss_s1: 0.025140, loss_fp: 0.004600, loss_freq: 0.027293
[12:51:41.045] iteration 5339: loss: 0.134461, loss_s1: 0.039604, loss_fp: 0.002378, loss_freq: 0.024081
[12:51:41.659] iteration 5340: loss: 0.073906, loss_s1: 0.049646, loss_fp: 0.004091, loss_freq: 0.014875
[12:51:42.269] iteration 5341: loss: 0.109526, loss_s1: 0.050479, loss_fp: 0.005170, loss_freq: 0.061188
[12:51:42.891] iteration 5342: loss: 0.116315, loss_s1: 0.046076, loss_fp: 0.002962, loss_freq: 0.004988
[12:51:43.507] iteration 5343: loss: 0.181128, loss_s1: 0.037507, loss_fp: 0.002637, loss_freq: 0.074273
[12:51:44.128] iteration 5344: loss: 0.095092, loss_s1: 0.039694, loss_fp: 0.002752, loss_freq: 0.009576
[12:51:44.764] iteration 5345: loss: 0.109176, loss_s1: 0.085390, loss_fp: 0.006637, loss_freq: 0.014640
[12:51:45.435] iteration 5346: loss: 0.072567, loss_s1: 0.020646, loss_fp: 0.003666, loss_freq: 0.022960
[12:51:46.093] iteration 5347: loss: 0.183075, loss_s1: 0.053450, loss_fp: 0.003238, loss_freq: 0.012340
[12:51:46.749] iteration 5348: loss: 0.147317, loss_s1: 0.094434, loss_fp: 0.002797, loss_freq: 0.046689
[12:51:47.391] iteration 5349: loss: 0.051948, loss_s1: 0.005347, loss_fp: 0.000617, loss_freq: 0.010681
[12:51:48.024] iteration 5350: loss: 0.135043, loss_s1: 0.040140, loss_fp: 0.002197, loss_freq: 0.043474
[12:51:48.641] iteration 5351: loss: 0.094785, loss_s1: 0.046079, loss_fp: 0.002814, loss_freq: 0.027522
[12:51:49.269] iteration 5352: loss: 0.151711, loss_s1: 0.033700, loss_fp: 0.002017, loss_freq: 0.024544
[12:51:50.027] iteration 5353: loss: 0.081940, loss_s1: 0.008701, loss_fp: 0.002167, loss_freq: 0.004100
[12:51:50.743] iteration 5354: loss: 0.130222, loss_s1: 0.094136, loss_fp: 0.000992, loss_freq: 0.033864
[12:51:51.509] iteration 5355: loss: 0.149639, loss_s1: 0.066895, loss_fp: 0.001021, loss_freq: 0.014523
[12:51:52.166] iteration 5356: loss: 0.120967, loss_s1: 0.041479, loss_fp: 0.004614, loss_freq: 0.013175
[12:51:52.782] iteration 5357: loss: 0.105535, loss_s1: 0.038591, loss_fp: 0.001123, loss_freq: 0.004812
[12:51:53.405] iteration 5358: loss: 0.108038, loss_s1: 0.045882, loss_fp: 0.001239, loss_freq: 0.061267
[12:51:54.026] iteration 5359: loss: 0.118172, loss_s1: 0.068202, loss_fp: 0.006313, loss_freq: 0.010403
[12:51:54.647] iteration 5360: loss: 0.095520, loss_s1: 0.020099, loss_fp: 0.002265, loss_freq: 0.023064
[12:51:55.280] iteration 5361: loss: 0.172286, loss_s1: 0.087100, loss_fp: 0.006422, loss_freq: 0.040019
[12:51:55.907] iteration 5362: loss: 0.166346, loss_s1: 0.062013, loss_fp: 0.001086, loss_freq: 0.022229
[12:51:56.523] iteration 5363: loss: 0.108129, loss_s1: 0.055507, loss_fp: 0.001092, loss_freq: 0.067024
[12:51:57.143] iteration 5364: loss: 0.093193, loss_s1: 0.027756, loss_fp: 0.002392, loss_freq: 0.057259
[12:51:57.772] iteration 5365: loss: 0.158570, loss_s1: 0.080383, loss_fp: 0.004912, loss_freq: 0.103928
[12:51:58.391] iteration 5366: loss: 0.134584, loss_s1: 0.043565, loss_fp: 0.000529, loss_freq: 0.091235
[12:51:59.005] iteration 5367: loss: 0.125541, loss_s1: 0.051447, loss_fp: 0.001578, loss_freq: 0.014323
[12:51:59.627] iteration 5368: loss: 0.067704, loss_s1: 0.041665, loss_fp: 0.000779, loss_freq: 0.027687
[12:52:00.254] iteration 5369: loss: 0.089663, loss_s1: 0.026902, loss_fp: 0.000945, loss_freq: 0.014369
[12:52:00.869] iteration 5370: loss: 0.173349, loss_s1: 0.095659, loss_fp: 0.001729, loss_freq: 0.142839
[12:52:01.487] iteration 5371: loss: 0.220055, loss_s1: 0.040761, loss_fp: 0.006273, loss_freq: 0.011913
[12:52:02.112] iteration 5372: loss: 0.093760, loss_s1: 0.022672, loss_fp: 0.000739, loss_freq: 0.035025
[12:52:02.734] iteration 5373: loss: 0.087746, loss_s1: 0.023662, loss_fp: 0.002145, loss_freq: 0.036607
[12:52:03.351] iteration 5374: loss: 0.156345, loss_s1: 0.037945, loss_fp: 0.001871, loss_freq: 0.029002
[12:52:03.969] iteration 5375: loss: 0.101342, loss_s1: 0.100054, loss_fp: 0.000813, loss_freq: 0.029652
[12:52:04.587] iteration 5376: loss: 0.179534, loss_s1: 0.053230, loss_fp: 0.002771, loss_freq: 0.020270
[12:52:05.204] iteration 5377: loss: 0.149995, loss_s1: 0.096070, loss_fp: 0.001550, loss_freq: 0.085484
[12:52:05.828] iteration 5378: loss: 0.124825, loss_s1: 0.010234, loss_fp: 0.001423, loss_freq: 0.022929
[12:52:06.456] iteration 5379: loss: 0.128256, loss_s1: 0.045239, loss_fp: 0.000802, loss_freq: 0.013046
[12:52:07.070] iteration 5380: loss: 0.099128, loss_s1: 0.046100, loss_fp: 0.001802, loss_freq: 0.009197
[12:52:07.736] iteration 5381: loss: 0.093720, loss_s1: 0.024264, loss_fp: 0.002442, loss_freq: 0.018871
[12:52:08.407] iteration 5382: loss: 0.140121, loss_s1: 0.046800, loss_fp: 0.002391, loss_freq: 0.010768
[12:52:09.034] iteration 5383: loss: 0.106633, loss_s1: 0.021502, loss_fp: 0.001017, loss_freq: 0.057956
[12:52:09.673] iteration 5384: loss: 0.095790, loss_s1: 0.101477, loss_fp: 0.001527, loss_freq: 0.006815
[12:52:10.331] iteration 5385: loss: 0.141330, loss_s1: 0.040082, loss_fp: 0.006358, loss_freq: 0.064196
[12:52:10.985] iteration 5386: loss: 0.060666, loss_s1: 0.027418, loss_fp: 0.003015, loss_freq: 0.008605
[12:52:11.642] iteration 5387: loss: 0.132380, loss_s1: 0.085211, loss_fp: 0.003473, loss_freq: 0.016959
[12:52:12.306] iteration 5388: loss: 0.177529, loss_s1: 0.094429, loss_fp: 0.001725, loss_freq: 0.057985
[12:52:12.959] iteration 5389: loss: 0.138635, loss_s1: 0.116328, loss_fp: 0.000924, loss_freq: 0.039517
[12:52:13.615] iteration 5390: loss: 0.218706, loss_s1: 0.047922, loss_fp: 0.003085, loss_freq: 0.029493
[12:52:14.251] iteration 5391: loss: 0.120364, loss_s1: 0.057535, loss_fp: 0.001402, loss_freq: 0.031315
[12:52:14.875] iteration 5392: loss: 0.152079, loss_s1: 0.063608, loss_fp: 0.001834, loss_freq: 0.079070
[12:52:15.505] iteration 5393: loss: 0.077670, loss_s1: 0.024626, loss_fp: 0.001773, loss_freq: 0.021399
[12:52:16.134] iteration 5394: loss: 0.093369, loss_s1: 0.038023, loss_fp: 0.000756, loss_freq: 0.014188
[12:52:16.771] iteration 5395: loss: 0.101790, loss_s1: 0.022524, loss_fp: 0.002965, loss_freq: 0.053860
[12:52:17.397] iteration 5396: loss: 0.175947, loss_s1: 0.054879, loss_fp: 0.001480, loss_freq: 0.066535
[12:52:18.021] iteration 5397: loss: 0.125574, loss_s1: 0.030006, loss_fp: 0.001053, loss_freq: 0.031699
[12:52:18.645] iteration 5398: loss: 0.224720, loss_s1: 0.137761, loss_fp: 0.003598, loss_freq: 0.180841
[12:52:19.263] iteration 5399: loss: 0.091096, loss_s1: 0.031435, loss_fp: 0.006573, loss_freq: 0.057525
[12:52:19.892] iteration 5400: loss: 0.111960, loss_s1: 0.044646, loss_fp: 0.000624, loss_freq: 0.005943
[12:52:23.108] iteration 5400 : mean_dice : 0.687243
[12:52:23.753] iteration 5401: loss: 0.136230, loss_s1: 0.078785, loss_fp: 0.000568, loss_freq: 0.041564
[12:52:24.382] iteration 5402: loss: 0.122385, loss_s1: 0.030656, loss_fp: 0.001180, loss_freq: 0.042139
[12:52:25.018] iteration 5403: loss: 0.092746, loss_s1: 0.072630, loss_fp: 0.000443, loss_freq: 0.025321
[12:52:25.651] iteration 5404: loss: 0.120754, loss_s1: 0.072191, loss_fp: 0.001590, loss_freq: 0.019181
[12:52:26.290] iteration 5405: loss: 0.104449, loss_s1: 0.057285, loss_fp: 0.003712, loss_freq: 0.050405
[12:52:26.924] iteration 5406: loss: 0.225956, loss_s1: 0.044767, loss_fp: 0.000989, loss_freq: 0.063254
[12:52:27.563] iteration 5407: loss: 0.083498, loss_s1: 0.076910, loss_fp: 0.002237, loss_freq: 0.008022
[12:52:28.187] iteration 5408: loss: 0.105570, loss_s1: 0.037286, loss_fp: 0.001939, loss_freq: 0.055209
[12:52:28.839] iteration 5409: loss: 0.111191, loss_s1: 0.066252, loss_fp: 0.002960, loss_freq: 0.025500
[12:52:29.491] iteration 5410: loss: 0.090826, loss_s1: 0.075512, loss_fp: 0.011465, loss_freq: 0.026826
[12:52:30.148] iteration 5411: loss: 0.103144, loss_s1: 0.067650, loss_fp: 0.006159, loss_freq: 0.039135
[12:52:30.804] iteration 5412: loss: 0.081889, loss_s1: 0.038356, loss_fp: 0.001202, loss_freq: 0.050302
[12:52:31.424] iteration 5413: loss: 0.211699, loss_s1: 0.053537, loss_fp: 0.001351, loss_freq: 0.029046
[12:52:32.056] iteration 5414: loss: 0.125093, loss_s1: 0.023160, loss_fp: 0.000422, loss_freq: 0.001688
[12:52:32.698] iteration 5415: loss: 0.104054, loss_s1: 0.037151, loss_fp: 0.004353, loss_freq: 0.045119
[12:52:33.316] iteration 5416: loss: 0.100194, loss_s1: 0.072836, loss_fp: 0.002604, loss_freq: 0.042226
[12:52:33.938] iteration 5417: loss: 0.124707, loss_s1: 0.021636, loss_fp: 0.029606, loss_freq: 0.039947
[12:52:34.556] iteration 5418: loss: 0.149642, loss_s1: 0.092905, loss_fp: 0.000665, loss_freq: 0.090420
[12:52:35.169] iteration 5419: loss: 0.072688, loss_s1: 0.028157, loss_fp: 0.001440, loss_freq: 0.037343
[12:52:35.787] iteration 5420: loss: 0.148676, loss_s1: 0.096501, loss_fp: 0.001341, loss_freq: 0.021869
[12:52:36.409] iteration 5421: loss: 0.075471, loss_s1: 0.007745, loss_fp: 0.003313, loss_freq: 0.011887
[12:52:37.036] iteration 5422: loss: 0.124487, loss_s1: 0.040612, loss_fp: 0.002671, loss_freq: 0.018309
[12:52:37.660] iteration 5423: loss: 0.233004, loss_s1: 0.115021, loss_fp: 0.000996, loss_freq: 0.027204
[12:52:38.280] iteration 5424: loss: 0.114895, loss_s1: 0.093963, loss_fp: 0.000957, loss_freq: 0.012132
[12:52:38.889] iteration 5425: loss: 0.123064, loss_s1: 0.034057, loss_fp: 0.001391, loss_freq: 0.028351
[12:52:39.510] iteration 5426: loss: 0.138482, loss_s1: 0.052091, loss_fp: 0.001786, loss_freq: 0.052279
[12:52:40.131] iteration 5427: loss: 0.102582, loss_s1: 0.050272, loss_fp: 0.001567, loss_freq: 0.025371
[12:52:40.756] iteration 5428: loss: 0.106255, loss_s1: 0.063244, loss_fp: 0.010621, loss_freq: 0.024474
[12:52:41.380] iteration 5429: loss: 0.097703, loss_s1: 0.030343, loss_fp: 0.005176, loss_freq: 0.016841
[12:52:42.037] iteration 5430: loss: 0.121475, loss_s1: 0.072971, loss_fp: 0.002908, loss_freq: 0.034836
[12:52:42.698] iteration 5431: loss: 0.145949, loss_s1: 0.023694, loss_fp: 0.001683, loss_freq: 0.020924
[12:52:43.337] iteration 5432: loss: 0.131125, loss_s1: 0.073220, loss_fp: 0.002156, loss_freq: 0.021682
[12:52:43.957] iteration 5433: loss: 0.151388, loss_s1: 0.145616, loss_fp: 0.005187, loss_freq: 0.036351
[12:52:44.575] iteration 5434: loss: 0.064484, loss_s1: 0.022401, loss_fp: 0.002145, loss_freq: 0.015322
[12:52:45.587] iteration 5435: loss: 0.104757, loss_s1: 0.030044, loss_fp: 0.000648, loss_freq: 0.015370
[12:52:46.213] iteration 5436: loss: 0.100171, loss_s1: 0.075168, loss_fp: 0.001577, loss_freq: 0.026480
[12:52:46.837] iteration 5437: loss: 0.061387, loss_s1: 0.018665, loss_fp: 0.000362, loss_freq: 0.036430
[12:52:47.514] iteration 5438: loss: 0.083953, loss_s1: 0.010331, loss_fp: 0.001440, loss_freq: 0.012542
[12:52:48.145] iteration 5439: loss: 0.153640, loss_s1: 0.115465, loss_fp: 0.002410, loss_freq: 0.059675
[12:52:48.776] iteration 5440: loss: 0.096325, loss_s1: 0.023872, loss_fp: 0.001023, loss_freq: 0.002409
[12:52:49.399] iteration 5441: loss: 0.087466, loss_s1: 0.036834, loss_fp: 0.010313, loss_freq: 0.056518
[12:52:50.018] iteration 5442: loss: 0.187217, loss_s1: 0.102059, loss_fp: 0.003769, loss_freq: 0.037679
[12:52:50.634] iteration 5443: loss: 0.117934, loss_s1: 0.078112, loss_fp: 0.002684, loss_freq: 0.028936
[12:52:51.248] iteration 5444: loss: 0.163233, loss_s1: 0.022184, loss_fp: 0.000860, loss_freq: 0.035272
[12:52:51.869] iteration 5445: loss: 0.129315, loss_s1: 0.040945, loss_fp: 0.001433, loss_freq: 0.029878
[12:52:52.482] iteration 5446: loss: 0.114344, loss_s1: 0.058077, loss_fp: 0.000467, loss_freq: 0.077133
[12:52:53.107] iteration 5447: loss: 0.112089, loss_s1: 0.057419, loss_fp: 0.000643, loss_freq: 0.012200
[12:52:53.723] iteration 5448: loss: 0.073991, loss_s1: 0.035579, loss_fp: 0.001501, loss_freq: 0.017624
[12:52:54.337] iteration 5449: loss: 0.128374, loss_s1: 0.081769, loss_fp: 0.001803, loss_freq: 0.055956
[12:52:54.957] iteration 5450: loss: 0.097087, loss_s1: 0.059757, loss_fp: 0.005021, loss_freq: 0.034709
[12:52:55.577] iteration 5451: loss: 0.205678, loss_s1: 0.061920, loss_fp: 0.001980, loss_freq: 0.035523
[12:52:56.204] iteration 5452: loss: 0.127975, loss_s1: 0.027392, loss_fp: 0.000982, loss_freq: 0.013309
[12:52:56.817] iteration 5453: loss: 0.091139, loss_s1: 0.043226, loss_fp: 0.001310, loss_freq: 0.020068
[12:52:57.429] iteration 5454: loss: 0.142768, loss_s1: 0.071551, loss_fp: 0.001392, loss_freq: 0.013414
[12:52:58.053] iteration 5455: loss: 0.163505, loss_s1: 0.074865, loss_fp: 0.003374, loss_freq: 0.043546
[12:52:58.663] iteration 5456: loss: 0.097998, loss_s1: 0.020968, loss_fp: 0.001855, loss_freq: 0.053763
[12:52:59.277] iteration 5457: loss: 0.091089, loss_s1: 0.043013, loss_fp: 0.000876, loss_freq: 0.046240
[12:52:59.889] iteration 5458: loss: 0.159574, loss_s1: 0.038563, loss_fp: 0.004097, loss_freq: 0.014455
[12:53:00.511] iteration 5459: loss: 0.137914, loss_s1: 0.101036, loss_fp: 0.002724, loss_freq: 0.048817
[12:53:01.125] iteration 5460: loss: 0.110619, loss_s1: 0.015628, loss_fp: 0.002415, loss_freq: 0.047673
[12:53:01.738] iteration 5461: loss: 0.136505, loss_s1: 0.032337, loss_fp: 0.001550, loss_freq: 0.038602
[12:53:02.359] iteration 5462: loss: 0.108308, loss_s1: 0.042077, loss_fp: 0.000912, loss_freq: 0.014041
[12:53:02.981] iteration 5463: loss: 0.199827, loss_s1: 0.082876, loss_fp: 0.001379, loss_freq: 0.069746
[12:53:03.633] iteration 5464: loss: 0.102801, loss_s1: 0.013431, loss_fp: 0.000600, loss_freq: 0.017433
[12:53:04.250] iteration 5465: loss: 0.078093, loss_s1: 0.028151, loss_fp: 0.001931, loss_freq: 0.003713
[12:53:04.866] iteration 5466: loss: 0.104402, loss_s1: 0.012477, loss_fp: 0.000888, loss_freq: 0.030262
[12:53:05.486] iteration 5467: loss: 0.095888, loss_s1: 0.034737, loss_fp: 0.000891, loss_freq: 0.033269
[12:53:06.102] iteration 5468: loss: 0.136730, loss_s1: 0.133770, loss_fp: 0.006313, loss_freq: 0.040222
[12:53:06.721] iteration 5469: loss: 0.154923, loss_s1: 0.022238, loss_fp: 0.004468, loss_freq: 0.035166
[12:53:07.345] iteration 5470: loss: 0.130523, loss_s1: 0.055604, loss_fp: 0.001950, loss_freq: 0.033413
[12:53:07.959] iteration 5471: loss: 0.095463, loss_s1: 0.039422, loss_fp: 0.001946, loss_freq: 0.046120
[12:53:08.577] iteration 5472: loss: 0.069133, loss_s1: 0.019943, loss_fp: 0.002673, loss_freq: 0.040174
[12:53:09.201] iteration 5473: loss: 0.107025, loss_s1: 0.046312, loss_fp: 0.004716, loss_freq: 0.045387
[12:53:09.822] iteration 5474: loss: 0.080199, loss_s1: 0.040154, loss_fp: 0.000762, loss_freq: 0.009619
[12:53:10.439] iteration 5475: loss: 0.122767, loss_s1: 0.017657, loss_fp: 0.002136, loss_freq: 0.012329
[12:53:11.089] iteration 5476: loss: 0.082500, loss_s1: 0.075835, loss_fp: 0.001014, loss_freq: 0.012056
[12:53:11.739] iteration 5477: loss: 0.125511, loss_s1: 0.053149, loss_fp: 0.000741, loss_freq: 0.020231
[12:53:12.392] iteration 5478: loss: 0.092435, loss_s1: 0.061311, loss_fp: 0.004413, loss_freq: 0.027340
[12:53:13.049] iteration 5479: loss: 0.203579, loss_s1: 0.063498, loss_fp: 0.000842, loss_freq: 0.075453
[12:53:13.695] iteration 5480: loss: 0.156539, loss_s1: 0.084583, loss_fp: 0.002231, loss_freq: 0.023673
[12:53:14.310] iteration 5481: loss: 0.080411, loss_s1: 0.020503, loss_fp: 0.005062, loss_freq: 0.047026
[12:53:14.952] iteration 5482: loss: 0.116775, loss_s1: 0.021865, loss_fp: 0.001222, loss_freq: 0.023831
[12:53:15.559] iteration 5483: loss: 0.051907, loss_s1: 0.026390, loss_fp: 0.001284, loss_freq: 0.007539
[12:53:16.180] iteration 5484: loss: 0.080452, loss_s1: 0.030557, loss_fp: 0.004417, loss_freq: 0.017592
[12:53:16.797] iteration 5485: loss: 0.107543, loss_s1: 0.069337, loss_fp: 0.002446, loss_freq: 0.025119
[12:53:17.414] iteration 5486: loss: 0.175536, loss_s1: 0.037516, loss_fp: 0.001806, loss_freq: 0.033299
[12:53:18.037] iteration 5487: loss: 0.083495, loss_s1: 0.039338, loss_fp: 0.002010, loss_freq: 0.005767
[12:53:18.656] iteration 5488: loss: 0.105043, loss_s1: 0.079876, loss_fp: 0.001577, loss_freq: 0.014026
[12:53:19.274] iteration 5489: loss: 0.086257, loss_s1: 0.058261, loss_fp: 0.005252, loss_freq: 0.012578
[12:53:19.909] iteration 5490: loss: 0.109313, loss_s1: 0.028285, loss_fp: 0.003616, loss_freq: 0.019653
[12:53:20.522] iteration 5491: loss: 0.170076, loss_s1: 0.109549, loss_fp: 0.001641, loss_freq: 0.090984
[12:53:21.151] iteration 5492: loss: 0.078373, loss_s1: 0.022855, loss_fp: 0.003696, loss_freq: 0.019517
[12:53:21.777] iteration 5493: loss: 0.121703, loss_s1: 0.037176, loss_fp: 0.011398, loss_freq: 0.028435
[12:53:22.395] iteration 5494: loss: 0.121562, loss_s1: 0.059165, loss_fp: 0.001374, loss_freq: 0.048170
[12:53:23.075] iteration 5495: loss: 0.088460, loss_s1: 0.029331, loss_fp: 0.002349, loss_freq: 0.013183
[12:53:23.726] iteration 5496: loss: 0.161829, loss_s1: 0.026769, loss_fp: 0.002771, loss_freq: 0.024455
[12:53:24.379] iteration 5497: loss: 0.089157, loss_s1: 0.046959, loss_fp: 0.003736, loss_freq: 0.021864
[12:53:25.033] iteration 5498: loss: 0.187317, loss_s1: 0.051847, loss_fp: 0.001341, loss_freq: 0.014262
[12:53:25.679] iteration 5499: loss: 0.132339, loss_s1: 0.060092, loss_fp: 0.002492, loss_freq: 0.051111
[12:53:26.333] iteration 5500: loss: 0.149726, loss_s1: 0.030989, loss_fp: 0.006360, loss_freq: 0.022180
[12:53:26.990] iteration 5501: loss: 0.125028, loss_s1: 0.050956, loss_fp: 0.001808, loss_freq: 0.090690
[12:53:27.643] iteration 5502: loss: 0.143652, loss_s1: 0.079595, loss_fp: 0.001576, loss_freq: 0.026795
[12:53:28.297] iteration 5503: loss: 0.087077, loss_s1: 0.068489, loss_fp: 0.001756, loss_freq: 0.019101
[12:53:28.954] iteration 5504: loss: 0.161303, loss_s1: 0.029917, loss_fp: 0.001941, loss_freq: 0.014866
[12:53:29.592] iteration 5505: loss: 0.105348, loss_s1: 0.067752, loss_fp: 0.001318, loss_freq: 0.008323
[12:53:30.220] iteration 5506: loss: 0.088314, loss_s1: 0.059780, loss_fp: 0.000888, loss_freq: 0.018878
[12:53:30.835] iteration 5507: loss: 0.088386, loss_s1: 0.043599, loss_fp: 0.000758, loss_freq: 0.048967
[12:53:31.444] iteration 5508: loss: 0.145179, loss_s1: 0.083456, loss_fp: 0.008794, loss_freq: 0.017797
[12:53:32.059] iteration 5509: loss: 0.093042, loss_s1: 0.025988, loss_fp: 0.003012, loss_freq: 0.065260
[12:53:32.675] iteration 5510: loss: 0.113635, loss_s1: 0.074046, loss_fp: 0.004098, loss_freq: 0.009937
[12:53:33.289] iteration 5511: loss: 0.063088, loss_s1: 0.030116, loss_fp: 0.001303, loss_freq: 0.015195
[12:53:33.899] iteration 5512: loss: 0.112493, loss_s1: 0.038779, loss_fp: 0.000417, loss_freq: 0.009026
[12:53:34.512] iteration 5513: loss: 0.144633, loss_s1: 0.092593, loss_fp: 0.001607, loss_freq: 0.085729
[12:53:35.129] iteration 5514: loss: 0.199886, loss_s1: 0.028602, loss_fp: 0.001070, loss_freq: 0.025455
[12:53:35.741] iteration 5515: loss: 0.086566, loss_s1: 0.036061, loss_fp: 0.000799, loss_freq: 0.037234
[12:53:36.359] iteration 5516: loss: 0.118968, loss_s1: 0.081300, loss_fp: 0.004498, loss_freq: 0.054458
[12:53:36.975] iteration 5517: loss: 0.135813, loss_s1: 0.082752, loss_fp: 0.002164, loss_freq: 0.019185
[12:53:37.602] iteration 5518: loss: 0.071311, loss_s1: 0.042421, loss_fp: 0.000744, loss_freq: 0.019265
[12:53:38.216] iteration 5519: loss: 0.111669, loss_s1: 0.021417, loss_fp: 0.001150, loss_freq: 0.026880
[12:53:38.833] iteration 5520: loss: 0.119792, loss_s1: 0.026755, loss_fp: 0.003128, loss_freq: 0.058914
[12:53:39.453] iteration 5521: loss: 0.204503, loss_s1: 0.030330, loss_fp: 0.000381, loss_freq: 0.022209
[12:53:40.080] iteration 5522: loss: 0.100792, loss_s1: 0.034384, loss_fp: 0.000507, loss_freq: 0.012062
[12:53:40.705] iteration 5523: loss: 0.098697, loss_s1: 0.054279, loss_fp: 0.001976, loss_freq: 0.012934
[12:53:41.328] iteration 5524: loss: 0.119846, loss_s1: 0.049743, loss_fp: 0.002638, loss_freq: 0.036531
[12:53:41.948] iteration 5525: loss: 0.120759, loss_s1: 0.038321, loss_fp: 0.001052, loss_freq: 0.016263
[12:53:42.565] iteration 5526: loss: 0.111311, loss_s1: 0.068311, loss_fp: 0.001627, loss_freq: 0.056478
[12:53:43.179] iteration 5527: loss: 0.068106, loss_s1: 0.056116, loss_fp: 0.002077, loss_freq: 0.004523
[12:53:43.799] iteration 5528: loss: 0.124321, loss_s1: 0.031598, loss_fp: 0.003435, loss_freq: 0.031738
[12:53:44.422] iteration 5529: loss: 0.082335, loss_s1: 0.041315, loss_fp: 0.002400, loss_freq: 0.011512
[12:53:45.036] iteration 5530: loss: 0.166324, loss_s1: 0.111086, loss_fp: 0.001373, loss_freq: 0.054881
[12:53:45.651] iteration 5531: loss: 0.164481, loss_s1: 0.089796, loss_fp: 0.016717, loss_freq: 0.069966
[12:53:46.289] iteration 5532: loss: 0.084382, loss_s1: 0.060916, loss_fp: 0.001188, loss_freq: 0.016670
[12:53:46.923] iteration 5533: loss: 0.188965, loss_s1: 0.054768, loss_fp: 0.001672, loss_freq: 0.072280
[12:53:47.550] iteration 5534: loss: 0.146935, loss_s1: 0.036829, loss_fp: 0.000897, loss_freq: 0.048481
[12:53:48.188] iteration 5535: loss: 0.139846, loss_s1: 0.077657, loss_fp: 0.002629, loss_freq: 0.044828
[12:53:48.815] iteration 5536: loss: 0.077473, loss_s1: 0.029247, loss_fp: 0.000561, loss_freq: 0.022879
[12:53:49.465] iteration 5537: loss: 0.159143, loss_s1: 0.105990, loss_fp: 0.003882, loss_freq: 0.026320
[12:53:50.083] iteration 5538: loss: 0.215612, loss_s1: 0.179701, loss_fp: 0.001876, loss_freq: 0.097960
[12:53:50.703] iteration 5539: loss: 0.162521, loss_s1: 0.034843, loss_fp: 0.000948, loss_freq: 0.050024
[12:53:51.386] iteration 5540: loss: 0.107922, loss_s1: 0.025868, loss_fp: 0.000818, loss_freq: 0.047005
[12:53:52.048] iteration 5541: loss: 0.139095, loss_s1: 0.108376, loss_fp: 0.001072, loss_freq: 0.074481
[12:53:52.712] iteration 5542: loss: 0.100811, loss_s1: 0.042891, loss_fp: 0.002414, loss_freq: 0.054697
[12:53:53.373] iteration 5543: loss: 0.115135, loss_s1: 0.015895, loss_fp: 0.001553, loss_freq: 0.008543
[12:53:54.023] iteration 5544: loss: 0.105863, loss_s1: 0.031524, loss_fp: 0.001072, loss_freq: 0.025594
[12:53:54.674] iteration 5545: loss: 0.129096, loss_s1: 0.090274, loss_fp: 0.001054, loss_freq: 0.009990
[12:53:55.395] iteration 5546: loss: 0.071008, loss_s1: 0.037454, loss_fp: 0.001071, loss_freq: 0.040825
[12:53:56.116] iteration 5547: loss: 0.116159, loss_s1: 0.059228, loss_fp: 0.002469, loss_freq: 0.013082
[12:53:56.837] iteration 5548: loss: 0.087260, loss_s1: 0.042428, loss_fp: 0.005751, loss_freq: 0.022840
[12:53:57.490] iteration 5549: loss: 0.227135, loss_s1: 0.050932, loss_fp: 0.001664, loss_freq: 0.085618
[12:53:58.127] iteration 5550: loss: 0.144529, loss_s1: 0.085802, loss_fp: 0.004283, loss_freq: 0.003995
[12:53:58.747] iteration 5551: loss: 0.166179, loss_s1: 0.042646, loss_fp: 0.000877, loss_freq: 0.049353
[12:53:59.369] iteration 5552: loss: 0.127763, loss_s1: 0.060915, loss_fp: 0.006345, loss_freq: 0.021124
[12:53:59.987] iteration 5553: loss: 0.077770, loss_s1: 0.050165, loss_fp: 0.003594, loss_freq: 0.020775
[12:54:00.604] iteration 5554: loss: 0.114915, loss_s1: 0.077449, loss_fp: 0.003049, loss_freq: 0.050204
[12:54:01.226] iteration 5555: loss: 0.140098, loss_s1: 0.035837, loss_fp: 0.002128, loss_freq: 0.097766
[12:54:01.852] iteration 5556: loss: 0.273605, loss_s1: 0.102060, loss_fp: 0.001081, loss_freq: 0.041151
[12:54:02.472] iteration 5557: loss: 0.143403, loss_s1: 0.077142, loss_fp: 0.002596, loss_freq: 0.012529
[12:54:03.096] iteration 5558: loss: 0.124293, loss_s1: 0.067991, loss_fp: 0.001183, loss_freq: 0.029469
[12:54:03.719] iteration 5559: loss: 0.155764, loss_s1: 0.121925, loss_fp: 0.002493, loss_freq: 0.038744
[12:54:04.337] iteration 5560: loss: 0.150129, loss_s1: 0.068246, loss_fp: 0.000642, loss_freq: 0.037227
[12:54:04.954] iteration 5561: loss: 0.125633, loss_s1: 0.081432, loss_fp: 0.000910, loss_freq: 0.068421
[12:54:05.580] iteration 5562: loss: 0.089776, loss_s1: 0.069861, loss_fp: 0.000927, loss_freq: 0.015662
[12:54:06.201] iteration 5563: loss: 0.141215, loss_s1: 0.108097, loss_fp: 0.003581, loss_freq: 0.036720
[12:54:06.814] iteration 5564: loss: 0.093247, loss_s1: 0.041509, loss_fp: 0.028174, loss_freq: 0.006777
[12:54:07.432] iteration 5565: loss: 0.169435, loss_s1: 0.113446, loss_fp: 0.001671, loss_freq: 0.011789
[12:54:08.046] iteration 5566: loss: 0.213740, loss_s1: 0.088155, loss_fp: 0.001395, loss_freq: 0.064119
[12:54:08.661] iteration 5567: loss: 0.098857, loss_s1: 0.030166, loss_fp: 0.002448, loss_freq: 0.029545
[12:54:09.281] iteration 5568: loss: 0.155818, loss_s1: 0.076557, loss_fp: 0.001410, loss_freq: 0.051432
[12:54:09.896] iteration 5569: loss: 0.181122, loss_s1: 0.088698, loss_fp: 0.003569, loss_freq: 0.032087
[12:54:10.510] iteration 5570: loss: 0.137369, loss_s1: 0.100897, loss_fp: 0.002610, loss_freq: 0.024608
[12:54:11.124] iteration 5571: loss: 0.089202, loss_s1: 0.062162, loss_fp: 0.007749, loss_freq: 0.015621
[12:54:11.743] iteration 5572: loss: 0.127769, loss_s1: 0.027828, loss_fp: 0.002799, loss_freq: 0.047248
[12:54:12.369] iteration 5573: loss: 0.122583, loss_s1: 0.081746, loss_fp: 0.001551, loss_freq: 0.026091
[12:54:12.983] iteration 5574: loss: 0.142862, loss_s1: 0.039994, loss_fp: 0.000857, loss_freq: 0.019030
[12:54:13.590] iteration 5575: loss: 0.129312, loss_s1: 0.041523, loss_fp: 0.001653, loss_freq: 0.045874
[12:54:14.206] iteration 5576: loss: 0.154037, loss_s1: 0.103488, loss_fp: 0.008840, loss_freq: 0.088564
[12:54:14.820] iteration 5577: loss: 0.064774, loss_s1: 0.034688, loss_fp: 0.003268, loss_freq: 0.021476
[12:54:15.786] iteration 5578: loss: 0.114619, loss_s1: 0.035022, loss_fp: 0.003206, loss_freq: 0.023282
[12:54:16.432] iteration 5579: loss: 0.074068, loss_s1: 0.029796, loss_fp: 0.002360, loss_freq: 0.008075
[12:54:17.078] iteration 5580: loss: 0.069696, loss_s1: 0.032627, loss_fp: 0.004121, loss_freq: 0.026346
[12:54:17.770] iteration 5581: loss: 0.152359, loss_s1: 0.035565, loss_fp: 0.003636, loss_freq: 0.022329
[12:54:18.484] iteration 5582: loss: 0.135038, loss_s1: 0.052338, loss_fp: 0.001687, loss_freq: 0.060108
[12:54:19.157] iteration 5583: loss: 0.114556, loss_s1: 0.006557, loss_fp: 0.001482, loss_freq: 0.009446
[12:54:19.816] iteration 5584: loss: 0.132296, loss_s1: 0.109571, loss_fp: 0.007037, loss_freq: 0.070446
[12:54:20.473] iteration 5585: loss: 0.136438, loss_s1: 0.037736, loss_fp: 0.001950, loss_freq: 0.011320
[12:54:21.130] iteration 5586: loss: 0.086517, loss_s1: 0.064631, loss_fp: 0.002068, loss_freq: 0.012964
[12:54:21.790] iteration 5587: loss: 0.170223, loss_s1: 0.021020, loss_fp: 0.002338, loss_freq: 0.007322
[12:54:22.441] iteration 5588: loss: 0.124179, loss_s1: 0.066619, loss_fp: 0.001259, loss_freq: 0.016349
[12:54:23.068] iteration 5589: loss: 0.097727, loss_s1: 0.034237, loss_fp: 0.001981, loss_freq: 0.054095
[12:54:23.690] iteration 5590: loss: 0.094024, loss_s1: 0.064850, loss_fp: 0.001706, loss_freq: 0.029894
[12:54:24.308] iteration 5591: loss: 0.048068, loss_s1: 0.022841, loss_fp: 0.000883, loss_freq: 0.005920
[12:54:24.929] iteration 5592: loss: 0.130407, loss_s1: 0.090967, loss_fp: 0.001528, loss_freq: 0.060007
[12:54:25.549] iteration 5593: loss: 0.083354, loss_s1: 0.063172, loss_fp: 0.004462, loss_freq: 0.016813
[12:54:26.212] iteration 5594: loss: 0.179209, loss_s1: 0.028171, loss_fp: 0.001577, loss_freq: 0.015187
[12:54:26.867] iteration 5595: loss: 0.173377, loss_s1: 0.047000, loss_fp: 0.002529, loss_freq: 0.025408
[12:54:27.503] iteration 5596: loss: 0.064486, loss_s1: 0.030510, loss_fp: 0.001622, loss_freq: 0.029090
[12:54:28.124] iteration 5597: loss: 0.086408, loss_s1: 0.060713, loss_fp: 0.003628, loss_freq: 0.015668
[12:54:28.745] iteration 5598: loss: 0.161357, loss_s1: 0.039808, loss_fp: 0.001116, loss_freq: 0.057970
[12:54:29.371] iteration 5599: loss: 0.102488, loss_s1: 0.061907, loss_fp: 0.001056, loss_freq: 0.041203
[12:54:29.991] iteration 5600: loss: 0.094414, loss_s1: 0.041189, loss_fp: 0.001414, loss_freq: 0.028670
[12:54:33.375] iteration 5600 : mean_dice : 0.693220
[12:54:34.052] iteration 5601: loss: 0.121268, loss_s1: 0.062772, loss_fp: 0.000674, loss_freq: 0.033786
[12:54:34.709] iteration 5602: loss: 0.096548, loss_s1: 0.056712, loss_fp: 0.001177, loss_freq: 0.035263
[12:54:35.367] iteration 5603: loss: 0.151913, loss_s1: 0.094724, loss_fp: 0.005064, loss_freq: 0.042328
[12:54:36.029] iteration 5604: loss: 0.110893, loss_s1: 0.035776, loss_fp: 0.001564, loss_freq: 0.043727
[12:54:36.704] iteration 5605: loss: 0.095292, loss_s1: 0.052148, loss_fp: 0.007533, loss_freq: 0.032419
[12:54:37.354] iteration 5606: loss: 0.161157, loss_s1: 0.063989, loss_fp: 0.002067, loss_freq: 0.060787
[12:54:37.998] iteration 5607: loss: 0.185737, loss_s1: 0.041861, loss_fp: 0.001027, loss_freq: 0.028185
[12:54:38.618] iteration 5608: loss: 0.097485, loss_s1: 0.026031, loss_fp: 0.001658, loss_freq: 0.013218
[12:54:39.235] iteration 5609: loss: 0.090462, loss_s1: 0.032824, loss_fp: 0.001460, loss_freq: 0.023696
[12:54:39.861] iteration 5610: loss: 0.100540, loss_s1: 0.050106, loss_fp: 0.001021, loss_freq: 0.005840
[12:54:40.488] iteration 5611: loss: 0.138574, loss_s1: 0.109432, loss_fp: 0.001576, loss_freq: 0.073297
[12:54:41.117] iteration 5612: loss: 0.131226, loss_s1: 0.031553, loss_fp: 0.002671, loss_freq: 0.033855
[12:54:41.744] iteration 5613: loss: 0.110964, loss_s1: 0.068715, loss_fp: 0.000742, loss_freq: 0.033018
[12:54:42.362] iteration 5614: loss: 0.148156, loss_s1: 0.129857, loss_fp: 0.001014, loss_freq: 0.052295
[12:54:42.982] iteration 5615: loss: 0.085865, loss_s1: 0.051713, loss_fp: 0.001883, loss_freq: 0.032146
[12:54:43.609] iteration 5616: loss: 0.106073, loss_s1: 0.044857, loss_fp: 0.002197, loss_freq: 0.046608
[12:54:44.261] iteration 5617: loss: 0.117177, loss_s1: 0.067639, loss_fp: 0.001185, loss_freq: 0.026355
[12:54:44.884] iteration 5618: loss: 0.086529, loss_s1: 0.032014, loss_fp: 0.000636, loss_freq: 0.021423
[12:54:45.511] iteration 5619: loss: 0.046939, loss_s1: 0.019138, loss_fp: 0.000780, loss_freq: 0.007736
[12:54:46.132] iteration 5620: loss: 0.113958, loss_s1: 0.050022, loss_fp: 0.001620, loss_freq: 0.006907
[12:54:46.753] iteration 5621: loss: 0.096896, loss_s1: 0.054926, loss_fp: 0.007932, loss_freq: 0.047258
[12:54:47.370] iteration 5622: loss: 0.195306, loss_s1: 0.038379, loss_fp: 0.003164, loss_freq: 0.058658
[12:54:47.995] iteration 5623: loss: 0.101010, loss_s1: 0.031268, loss_fp: 0.000949, loss_freq: 0.026693
[12:54:48.617] iteration 5624: loss: 0.078115, loss_s1: 0.028397, loss_fp: 0.004738, loss_freq: 0.028263
[12:54:49.239] iteration 5625: loss: 0.086707, loss_s1: 0.026663, loss_fp: 0.002221, loss_freq: 0.037252
[12:54:49.860] iteration 5626: loss: 0.073131, loss_s1: 0.021751, loss_fp: 0.001181, loss_freq: 0.036823
[12:54:50.487] iteration 5627: loss: 0.118909, loss_s1: 0.044376, loss_fp: 0.001882, loss_freq: 0.071523
[12:54:51.106] iteration 5628: loss: 0.070100, loss_s1: 0.026300, loss_fp: 0.000644, loss_freq: 0.013235
[12:54:51.737] iteration 5629: loss: 0.147886, loss_s1: 0.031861, loss_fp: 0.002795, loss_freq: 0.064279
[12:54:52.355] iteration 5630: loss: 0.088679, loss_s1: 0.022996, loss_fp: 0.002906, loss_freq: 0.011375
[12:54:52.970] iteration 5631: loss: 0.068536, loss_s1: 0.026403, loss_fp: 0.001812, loss_freq: 0.018813
[12:54:53.587] iteration 5632: loss: 0.066609, loss_s1: 0.028399, loss_fp: 0.004320, loss_freq: 0.021180
[12:54:54.212] iteration 5633: loss: 0.142736, loss_s1: 0.063488, loss_fp: 0.001937, loss_freq: 0.009183
[12:54:54.826] iteration 5634: loss: 0.100329, loss_s1: 0.058024, loss_fp: 0.001636, loss_freq: 0.053501
[12:54:55.441] iteration 5635: loss: 0.093278, loss_s1: 0.066589, loss_fp: 0.000722, loss_freq: 0.023641
[12:54:56.062] iteration 5636: loss: 0.161235, loss_s1: 0.075479, loss_fp: 0.001315, loss_freq: 0.041001
[12:54:56.682] iteration 5637: loss: 0.084790, loss_s1: 0.059648, loss_fp: 0.002311, loss_freq: 0.017125
[12:54:57.305] iteration 5638: loss: 0.108305, loss_s1: 0.041098, loss_fp: 0.001981, loss_freq: 0.013561
[12:54:57.920] iteration 5639: loss: 0.127725, loss_s1: 0.082416, loss_fp: 0.003531, loss_freq: 0.026902
[12:54:58.536] iteration 5640: loss: 0.136222, loss_s1: 0.096149, loss_fp: 0.003487, loss_freq: 0.015497
[12:54:59.173] iteration 5641: loss: 0.117460, loss_s1: 0.019362, loss_fp: 0.003120, loss_freq: 0.031281
[12:54:59.787] iteration 5642: loss: 0.112837, loss_s1: 0.047398, loss_fp: 0.001306, loss_freq: 0.029676
[12:55:00.401] iteration 5643: loss: 0.180626, loss_s1: 0.115030, loss_fp: 0.000987, loss_freq: 0.019895
[12:55:01.023] iteration 5644: loss: 0.160050, loss_s1: 0.158548, loss_fp: 0.002570, loss_freq: 0.059693
[12:55:01.644] iteration 5645: loss: 0.121013, loss_s1: 0.052872, loss_fp: 0.001249, loss_freq: 0.013314
[12:55:02.267] iteration 5646: loss: 0.111452, loss_s1: 0.048537, loss_fp: 0.001313, loss_freq: 0.034076
[12:55:02.882] iteration 5647: loss: 0.138024, loss_s1: 0.047206, loss_fp: 0.002265, loss_freq: 0.004671
[12:55:03.504] iteration 5648: loss: 0.077056, loss_s1: 0.043449, loss_fp: 0.002011, loss_freq: 0.019247
[12:55:04.135] iteration 5649: loss: 0.082051, loss_s1: 0.011807, loss_fp: 0.000394, loss_freq: 0.036025
[12:55:04.765] iteration 5650: loss: 0.101743, loss_s1: 0.037425, loss_fp: 0.008977, loss_freq: 0.052236
[12:55:05.383] iteration 5651: loss: 0.098888, loss_s1: 0.036595, loss_fp: 0.001396, loss_freq: 0.025029
[12:55:05.994] iteration 5652: loss: 0.113298, loss_s1: 0.074597, loss_fp: 0.001034, loss_freq: 0.061187
[12:55:06.616] iteration 5653: loss: 0.088713, loss_s1: 0.047168, loss_fp: 0.001230, loss_freq: 0.012066
[12:55:07.238] iteration 5654: loss: 0.055177, loss_s1: 0.012232, loss_fp: 0.001150, loss_freq: 0.017847
[12:55:07.887] iteration 5655: loss: 0.101328, loss_s1: 0.019496, loss_fp: 0.002867, loss_freq: 0.016713
[12:55:08.508] iteration 5656: loss: 0.117618, loss_s1: 0.065414, loss_fp: 0.005557, loss_freq: 0.073739
[12:55:09.157] iteration 5657: loss: 0.275519, loss_s1: 0.061707, loss_fp: 0.001008, loss_freq: 0.037658
[12:55:09.814] iteration 5658: loss: 0.115057, loss_s1: 0.027462, loss_fp: 0.001852, loss_freq: 0.022914
[12:55:10.505] iteration 5659: loss: 0.136208, loss_s1: 0.078860, loss_fp: 0.003167, loss_freq: 0.036885
[12:55:11.158] iteration 5660: loss: 0.094767, loss_s1: 0.061963, loss_fp: 0.009338, loss_freq: 0.012470
[12:55:11.807] iteration 5661: loss: 0.057969, loss_s1: 0.047510, loss_fp: 0.001463, loss_freq: 0.012357
[12:55:12.464] iteration 5662: loss: 0.098500, loss_s1: 0.051591, loss_fp: 0.001565, loss_freq: 0.014300
[12:55:13.078] iteration 5663: loss: 0.156219, loss_s1: 0.133099, loss_fp: 0.001968, loss_freq: 0.050325
[12:55:13.685] iteration 5664: loss: 0.162978, loss_s1: 0.032575, loss_fp: 0.001313, loss_freq: 0.007461
[12:55:14.304] iteration 5665: loss: 0.095734, loss_s1: 0.035701, loss_fp: 0.001831, loss_freq: 0.019206
[12:55:14.916] iteration 5666: loss: 0.090313, loss_s1: 0.083219, loss_fp: 0.000744, loss_freq: 0.017100
[12:55:15.542] iteration 5667: loss: 0.187475, loss_s1: 0.109606, loss_fp: 0.001757, loss_freq: 0.056928
[12:55:16.160] iteration 5668: loss: 0.140213, loss_s1: 0.059393, loss_fp: 0.000611, loss_freq: 0.018217
[12:55:16.778] iteration 5669: loss: 0.082137, loss_s1: 0.022668, loss_fp: 0.004993, loss_freq: 0.036462
[12:55:17.393] iteration 5670: loss: 0.062610, loss_s1: 0.031623, loss_fp: 0.001629, loss_freq: 0.012524
[12:55:18.019] iteration 5671: loss: 0.125466, loss_s1: 0.036506, loss_fp: 0.008772, loss_freq: 0.035232
[12:55:18.635] iteration 5672: loss: 0.089499, loss_s1: 0.043426, loss_fp: 0.002723, loss_freq: 0.023387
[12:55:19.287] iteration 5673: loss: 0.117103, loss_s1: 0.047991, loss_fp: 0.000922, loss_freq: 0.030742
[12:55:19.946] iteration 5674: loss: 0.184184, loss_s1: 0.145455, loss_fp: 0.002578, loss_freq: 0.084022
[12:55:20.637] iteration 5675: loss: 0.091495, loss_s1: 0.036587, loss_fp: 0.003497, loss_freq: 0.038654
[12:55:21.286] iteration 5676: loss: 0.123440, loss_s1: 0.018665, loss_fp: 0.001144, loss_freq: 0.038404
[12:55:21.942] iteration 5677: loss: 0.224316, loss_s1: 0.209063, loss_fp: 0.004821, loss_freq: 0.034244
[12:55:22.594] iteration 5678: loss: 0.138550, loss_s1: 0.053481, loss_fp: 0.000974, loss_freq: 0.029550
[12:55:23.264] iteration 5679: loss: 0.087606, loss_s1: 0.032376, loss_fp: 0.001413, loss_freq: 0.004877
[12:55:23.935] iteration 5680: loss: 0.106571, loss_s1: 0.048580, loss_fp: 0.001716, loss_freq: 0.012743
[12:55:24.589] iteration 5681: loss: 0.174595, loss_s1: 0.052420, loss_fp: 0.010856, loss_freq: 0.086154
[12:55:25.246] iteration 5682: loss: 0.159880, loss_s1: 0.020542, loss_fp: 0.008172, loss_freq: 0.057570
[12:55:25.925] iteration 5683: loss: 0.092203, loss_s1: 0.037020, loss_fp: 0.002230, loss_freq: 0.026004
[12:55:26.557] iteration 5684: loss: 0.177006, loss_s1: 0.119047, loss_fp: 0.001984, loss_freq: 0.099757
[12:55:27.174] iteration 5685: loss: 0.068462, loss_s1: 0.035086, loss_fp: 0.004768, loss_freq: 0.007132
[12:55:27.793] iteration 5686: loss: 0.115918, loss_s1: 0.022780, loss_fp: 0.001587, loss_freq: 0.003701
[12:55:28.415] iteration 5687: loss: 0.087367, loss_s1: 0.028834, loss_fp: 0.000561, loss_freq: 0.063928
[12:55:29.032] iteration 5688: loss: 0.109503, loss_s1: 0.081510, loss_fp: 0.000582, loss_freq: 0.005602
[12:55:29.649] iteration 5689: loss: 0.060245, loss_s1: 0.035845, loss_fp: 0.001003, loss_freq: 0.019841
[12:55:30.301] iteration 5690: loss: 0.131627, loss_s1: 0.065449, loss_fp: 0.001708, loss_freq: 0.018311
[12:55:30.919] iteration 5691: loss: 0.104700, loss_s1: 0.107564, loss_fp: 0.005384, loss_freq: 0.013207
[12:55:31.527] iteration 5692: loss: 0.250419, loss_s1: 0.051262, loss_fp: 0.001028, loss_freq: 0.047876
[12:55:32.138] iteration 5693: loss: 0.095084, loss_s1: 0.045037, loss_fp: 0.002054, loss_freq: 0.017854
[12:55:32.759] iteration 5694: loss: 0.185882, loss_s1: 0.083405, loss_fp: 0.002273, loss_freq: 0.078906
[12:55:33.373] iteration 5695: loss: 0.150559, loss_s1: 0.128135, loss_fp: 0.003280, loss_freq: 0.048425
[12:55:33.994] iteration 5696: loss: 0.074492, loss_s1: 0.037746, loss_fp: 0.008612, loss_freq: 0.043739
[12:55:34.609] iteration 5697: loss: 0.085000, loss_s1: 0.029234, loss_fp: 0.002462, loss_freq: 0.033909
[12:55:35.224] iteration 5698: loss: 0.132182, loss_s1: 0.105961, loss_fp: 0.002128, loss_freq: 0.056668
[12:55:35.836] iteration 5699: loss: 0.190940, loss_s1: 0.048218, loss_fp: 0.001540, loss_freq: 0.048415
[12:55:36.503] iteration 5700: loss: 0.102830, loss_s1: 0.016484, loss_fp: 0.000421, loss_freq: 0.038383
[12:55:37.129] iteration 5701: loss: 0.104501, loss_s1: 0.072374, loss_fp: 0.001792, loss_freq: 0.049581
[12:55:37.744] iteration 5702: loss: 0.175079, loss_s1: 0.117609, loss_fp: 0.004654, loss_freq: 0.062676
[12:55:38.408] iteration 5703: loss: 0.137442, loss_s1: 0.058325, loss_fp: 0.003653, loss_freq: 0.045803
[12:55:39.058] iteration 5704: loss: 0.082604, loss_s1: 0.017711, loss_fp: 0.000946, loss_freq: 0.046431
[12:55:39.715] iteration 5705: loss: 0.072625, loss_s1: 0.031344, loss_fp: 0.001519, loss_freq: 0.020019
[12:55:40.328] iteration 5706: loss: 0.108320, loss_s1: 0.059266, loss_fp: 0.006738, loss_freq: 0.016418
[12:55:40.944] iteration 5707: loss: 0.057138, loss_s1: 0.006566, loss_fp: 0.001072, loss_freq: 0.012759
[12:55:41.571] iteration 5708: loss: 0.113858, loss_s1: 0.043146, loss_fp: 0.001294, loss_freq: 0.026607
[12:55:42.183] iteration 5709: loss: 0.181352, loss_s1: 0.070766, loss_fp: 0.001066, loss_freq: 0.046005
[12:55:42.791] iteration 5710: loss: 0.096730, loss_s1: 0.046383, loss_fp: 0.003439, loss_freq: 0.028886
[12:55:43.411] iteration 5711: loss: 0.131764, loss_s1: 0.049542, loss_fp: 0.001103, loss_freq: 0.056013
[12:55:44.026] iteration 5712: loss: 0.103791, loss_s1: 0.026126, loss_fp: 0.002337, loss_freq: 0.032897
[12:55:44.644] iteration 5713: loss: 0.129365, loss_s1: 0.022962, loss_fp: 0.001673, loss_freq: 0.012827
[12:55:45.256] iteration 5714: loss: 0.130108, loss_s1: 0.083370, loss_fp: 0.007765, loss_freq: 0.013428
[12:55:45.870] iteration 5715: loss: 0.138447, loss_s1: 0.029039, loss_fp: 0.001686, loss_freq: 0.024551
[12:55:46.491] iteration 5716: loss: 0.077877, loss_s1: 0.031701, loss_fp: 0.003920, loss_freq: 0.020716
[12:55:47.171] iteration 5717: loss: 0.142967, loss_s1: 0.012332, loss_fp: 0.003746, loss_freq: 0.014017
[12:55:47.786] iteration 5718: loss: 0.082566, loss_s1: 0.036862, loss_fp: 0.001178, loss_freq: 0.028297
[12:55:48.400] iteration 5719: loss: 0.152560, loss_s1: 0.122337, loss_fp: 0.022207, loss_freq: 0.037224
[12:55:49.014] iteration 5720: loss: 0.077942, loss_s1: 0.015993, loss_fp: 0.002892, loss_freq: 0.054600
[12:55:49.967] iteration 5721: loss: 0.112740, loss_s1: 0.053314, loss_fp: 0.001190, loss_freq: 0.041056
[12:55:50.591] iteration 5722: loss: 0.098512, loss_s1: 0.070977, loss_fp: 0.009712, loss_freq: 0.024886
[12:55:51.241] iteration 5723: loss: 0.072454, loss_s1: 0.037550, loss_fp: 0.002470, loss_freq: 0.030497
[12:55:51.890] iteration 5724: loss: 0.123660, loss_s1: 0.066360, loss_fp: 0.001928, loss_freq: 0.023562
[12:55:52.519] iteration 5725: loss: 0.146297, loss_s1: 0.127370, loss_fp: 0.001036, loss_freq: 0.054652
[12:55:53.135] iteration 5726: loss: 0.133495, loss_s1: 0.087630, loss_fp: 0.001473, loss_freq: 0.007532
[12:55:53.762] iteration 5727: loss: 0.091226, loss_s1: 0.067590, loss_fp: 0.004162, loss_freq: 0.050101
[12:55:54.387] iteration 5728: loss: 0.219541, loss_s1: 0.100837, loss_fp: 0.001461, loss_freq: 0.056572
[12:55:55.020] iteration 5729: loss: 0.080363, loss_s1: 0.054444, loss_fp: 0.000869, loss_freq: 0.018169
[12:55:55.634] iteration 5730: loss: 0.179186, loss_s1: 0.054535, loss_fp: 0.002174, loss_freq: 0.006753
[12:55:56.254] iteration 5731: loss: 0.128129, loss_s1: 0.051509, loss_fp: 0.005753, loss_freq: 0.031616
[12:55:56.872] iteration 5732: loss: 0.109408, loss_s1: 0.082697, loss_fp: 0.000774, loss_freq: 0.052438
[12:55:57.519] iteration 5733: loss: 0.102555, loss_s1: 0.033713, loss_fp: 0.003463, loss_freq: 0.024138
[12:55:58.309] iteration 5734: loss: 0.057346, loss_s1: 0.011993, loss_fp: 0.000394, loss_freq: 0.029638
[12:55:58.943] iteration 5735: loss: 0.138037, loss_s1: 0.057378, loss_fp: 0.002807, loss_freq: 0.043429
[12:55:59.618] iteration 5736: loss: 0.089740, loss_s1: 0.039315, loss_fp: 0.000840, loss_freq: 0.011624
[12:56:00.294] iteration 5737: loss: 0.215117, loss_s1: 0.025800, loss_fp: 0.000615, loss_freq: 0.042727
[12:56:00.916] iteration 5738: loss: 0.133247, loss_s1: 0.055385, loss_fp: 0.001637, loss_freq: 0.029884
[12:56:01.539] iteration 5739: loss: 0.064635, loss_s1: 0.033043, loss_fp: 0.003842, loss_freq: 0.002705
[12:56:02.163] iteration 5740: loss: 0.104793, loss_s1: 0.039540, loss_fp: 0.000571, loss_freq: 0.016260
[12:56:02.776] iteration 5741: loss: 0.147068, loss_s1: 0.053384, loss_fp: 0.002130, loss_freq: 0.077688
[12:56:03.393] iteration 5742: loss: 0.089619, loss_s1: 0.058850, loss_fp: 0.000927, loss_freq: 0.019418
[12:56:04.012] iteration 5743: loss: 0.124278, loss_s1: 0.077442, loss_fp: 0.001472, loss_freq: 0.057841
[12:56:04.635] iteration 5744: loss: 0.139018, loss_s1: 0.030833, loss_fp: 0.000722, loss_freq: 0.016285
[12:56:05.275] iteration 5745: loss: 0.079363, loss_s1: 0.038845, loss_fp: 0.001326, loss_freq: 0.030402
[12:56:05.898] iteration 5746: loss: 0.132067, loss_s1: 0.062776, loss_fp: 0.001865, loss_freq: 0.017150
[12:56:06.519] iteration 5747: loss: 0.127883, loss_s1: 0.051130, loss_fp: 0.003276, loss_freq: 0.059059
[12:56:07.138] iteration 5748: loss: 0.079243, loss_s1: 0.022770, loss_fp: 0.002516, loss_freq: 0.029433
[12:56:07.756] iteration 5749: loss: 0.173538, loss_s1: 0.122994, loss_fp: 0.001374, loss_freq: 0.049635
[12:56:08.373] iteration 5750: loss: 0.123098, loss_s1: 0.092806, loss_fp: 0.000968, loss_freq: 0.010719
[12:56:08.995] iteration 5751: loss: 0.083664, loss_s1: 0.062114, loss_fp: 0.003985, loss_freq: 0.004012
[12:56:09.611] iteration 5752: loss: 0.072528, loss_s1: 0.036603, loss_fp: 0.001964, loss_freq: 0.018260
[12:56:10.231] iteration 5753: loss: 0.076258, loss_s1: 0.027435, loss_fp: 0.005180, loss_freq: 0.012152
[12:56:10.850] iteration 5754: loss: 0.193701, loss_s1: 0.196325, loss_fp: 0.003624, loss_freq: 0.062249
[12:56:11.463] iteration 5755: loss: 0.137569, loss_s1: 0.054841, loss_fp: 0.002049, loss_freq: 0.019013
[12:56:12.079] iteration 5756: loss: 0.102956, loss_s1: 0.045230, loss_fp: 0.001343, loss_freq: 0.016071
[12:56:12.693] iteration 5757: loss: 0.130225, loss_s1: 0.109715, loss_fp: 0.001399, loss_freq: 0.031962
[12:56:13.308] iteration 5758: loss: 0.086174, loss_s1: 0.034300, loss_fp: 0.000805, loss_freq: 0.062787
[12:56:13.925] iteration 5759: loss: 0.101554, loss_s1: 0.046456, loss_fp: 0.001513, loss_freq: 0.024899
[12:56:14.546] iteration 5760: loss: 0.088755, loss_s1: 0.042304, loss_fp: 0.001991, loss_freq: 0.014724
[12:56:15.161] iteration 5761: loss: 0.115775, loss_s1: 0.064067, loss_fp: 0.002179, loss_freq: 0.013769
[12:56:15.773] iteration 5762: loss: 0.077937, loss_s1: 0.048864, loss_fp: 0.001035, loss_freq: 0.019280
[12:56:16.395] iteration 5763: loss: 0.102005, loss_s1: 0.025085, loss_fp: 0.000462, loss_freq: 0.008944
[12:56:17.007] iteration 5764: loss: 0.077485, loss_s1: 0.040876, loss_fp: 0.002013, loss_freq: 0.018857
[12:56:17.625] iteration 5765: loss: 0.227538, loss_s1: 0.036940, loss_fp: 0.001512, loss_freq: 0.032300
[12:56:18.248] iteration 5766: loss: 0.117883, loss_s1: 0.089952, loss_fp: 0.000822, loss_freq: 0.017539
[12:56:18.865] iteration 5767: loss: 0.098645, loss_s1: 0.043782, loss_fp: 0.012208, loss_freq: 0.032972
[12:56:19.478] iteration 5768: loss: 0.109666, loss_s1: 0.050942, loss_fp: 0.004953, loss_freq: 0.036767
[12:56:20.093] iteration 5769: loss: 0.079397, loss_s1: 0.051278, loss_fp: 0.002762, loss_freq: 0.029523
[12:56:20.712] iteration 5770: loss: 0.096366, loss_s1: 0.050243, loss_fp: 0.001783, loss_freq: 0.031352
[12:56:21.327] iteration 5771: loss: 0.092260, loss_s1: 0.020912, loss_fp: 0.001456, loss_freq: 0.017728
[12:56:21.938] iteration 5772: loss: 0.195101, loss_s1: 0.065110, loss_fp: 0.006663, loss_freq: 0.044274
[12:56:22.553] iteration 5773: loss: 0.123977, loss_s1: 0.023486, loss_fp: 0.000603, loss_freq: 0.015280
[12:56:23.165] iteration 5774: loss: 0.080919, loss_s1: 0.055901, loss_fp: 0.001004, loss_freq: 0.008428
[12:56:23.780] iteration 5775: loss: 0.064129, loss_s1: 0.020381, loss_fp: 0.002785, loss_freq: 0.006284
[12:56:24.395] iteration 5776: loss: 0.091546, loss_s1: 0.032009, loss_fp: 0.000982, loss_freq: 0.012252
[12:56:25.019] iteration 5777: loss: 0.123309, loss_s1: 0.085785, loss_fp: 0.002711, loss_freq: 0.025573
[12:56:25.634] iteration 5778: loss: 0.073004, loss_s1: 0.020095, loss_fp: 0.000960, loss_freq: 0.025530
[12:56:26.248] iteration 5779: loss: 0.126425, loss_s1: 0.023414, loss_fp: 0.003380, loss_freq: 0.061073
[12:56:26.870] iteration 5780: loss: 0.093116, loss_s1: 0.049129, loss_fp: 0.002692, loss_freq: 0.016336
[12:56:27.490] iteration 5781: loss: 0.122108, loss_s1: 0.083853, loss_fp: 0.002218, loss_freq: 0.010618
[12:56:28.104] iteration 5782: loss: 0.145433, loss_s1: 0.053026, loss_fp: 0.001614, loss_freq: 0.023056
[12:56:28.721] iteration 5783: loss: 0.091766, loss_s1: 0.029869, loss_fp: 0.003003, loss_freq: 0.013208
[12:56:29.339] iteration 5784: loss: 0.171647, loss_s1: 0.092112, loss_fp: 0.000999, loss_freq: 0.016944
[12:56:29.958] iteration 5785: loss: 0.151664, loss_s1: 0.109853, loss_fp: 0.001819, loss_freq: 0.040648
[12:56:30.578] iteration 5786: loss: 0.181183, loss_s1: 0.081222, loss_fp: 0.000562, loss_freq: 0.025661
[12:56:31.208] iteration 5787: loss: 0.127541, loss_s1: 0.094354, loss_fp: 0.002725, loss_freq: 0.028332
[12:56:31.819] iteration 5788: loss: 0.138943, loss_s1: 0.054446, loss_fp: 0.000985, loss_freq: 0.016887
[12:56:32.436] iteration 5789: loss: 0.091542, loss_s1: 0.062286, loss_fp: 0.001310, loss_freq: 0.016919
[12:56:33.048] iteration 5790: loss: 0.140610, loss_s1: 0.060687, loss_fp: 0.001297, loss_freq: 0.027272
[12:56:33.663] iteration 5791: loss: 0.080156, loss_s1: 0.014963, loss_fp: 0.000725, loss_freq: 0.010042
[12:56:34.279] iteration 5792: loss: 0.090377, loss_s1: 0.037579, loss_fp: 0.001572, loss_freq: 0.021662
[12:56:34.893] iteration 5793: loss: 0.088936, loss_s1: 0.031176, loss_fp: 0.000757, loss_freq: 0.053673
[12:56:35.505] iteration 5794: loss: 0.159025, loss_s1: 0.130514, loss_fp: 0.002872, loss_freq: 0.043694
[12:56:36.114] iteration 5795: loss: 0.152357, loss_s1: 0.091343, loss_fp: 0.009119, loss_freq: 0.074453
[12:56:36.728] iteration 5796: loss: 0.141431, loss_s1: 0.062506, loss_fp: 0.002862, loss_freq: 0.032713
[12:56:37.343] iteration 5797: loss: 0.067268, loss_s1: 0.021897, loss_fp: 0.001081, loss_freq: 0.019782
[12:56:37.963] iteration 5798: loss: 0.090851, loss_s1: 0.041365, loss_fp: 0.000732, loss_freq: 0.006482
[12:56:38.578] iteration 5799: loss: 0.110796, loss_s1: 0.045765, loss_fp: 0.007635, loss_freq: 0.041982
[12:56:39.195] iteration 5800: loss: 0.252592, loss_s1: 0.085160, loss_fp: 0.000470, loss_freq: 0.048658
[12:56:42.333] iteration 5800 : mean_dice : 0.672852
[12:56:43.003] iteration 5801: loss: 0.090342, loss_s1: 0.022131, loss_fp: 0.002069, loss_freq: 0.034635
[12:56:43.654] iteration 5802: loss: 0.135478, loss_s1: 0.049488, loss_fp: 0.004384, loss_freq: 0.071658
[12:56:44.310] iteration 5803: loss: 0.076163, loss_s1: 0.020380, loss_fp: 0.000356, loss_freq: 0.014495
[12:56:44.964] iteration 5804: loss: 0.096272, loss_s1: 0.091519, loss_fp: 0.001667, loss_freq: 0.023050
[12:56:45.619] iteration 5805: loss: 0.121002, loss_s1: 0.035454, loss_fp: 0.000687, loss_freq: 0.006667
[12:56:46.275] iteration 5806: loss: 0.106946, loss_s1: 0.037622, loss_fp: 0.004744, loss_freq: 0.049397
[12:56:46.926] iteration 5807: loss: 0.153396, loss_s1: 0.038110, loss_fp: 0.001910, loss_freq: 0.009435
[12:56:47.552] iteration 5808: loss: 0.108055, loss_s1: 0.016460, loss_fp: 0.000656, loss_freq: 0.008758
[12:56:48.182] iteration 5809: loss: 0.109186, loss_s1: 0.098286, loss_fp: 0.001580, loss_freq: 0.014439
[12:56:48.809] iteration 5810: loss: 0.136697, loss_s1: 0.055244, loss_fp: 0.001932, loss_freq: 0.022342
[12:56:49.424] iteration 5811: loss: 0.101379, loss_s1: 0.021838, loss_fp: 0.000821, loss_freq: 0.020451
[12:56:50.050] iteration 5812: loss: 0.115780, loss_s1: 0.028398, loss_fp: 0.001659, loss_freq: 0.109393
[12:56:50.664] iteration 5813: loss: 0.072558, loss_s1: 0.037649, loss_fp: 0.000744, loss_freq: 0.004597
[12:56:51.272] iteration 5814: loss: 0.115092, loss_s1: 0.015917, loss_fp: 0.004075, loss_freq: 0.033652
[12:56:51.877] iteration 5815: loss: 0.058127, loss_s1: 0.009568, loss_fp: 0.000794, loss_freq: 0.009276
[12:56:52.494] iteration 5816: loss: 0.136665, loss_s1: 0.050834, loss_fp: 0.001546, loss_freq: 0.045791
[12:56:53.114] iteration 5817: loss: 0.109536, loss_s1: 0.031560, loss_fp: 0.005378, loss_freq: 0.042657
[12:56:53.732] iteration 5818: loss: 0.093548, loss_s1: 0.036057, loss_fp: 0.002692, loss_freq: 0.029292
[12:56:54.371] iteration 5819: loss: 0.113561, loss_s1: 0.035643, loss_fp: 0.001608, loss_freq: 0.031453
[12:56:55.019] iteration 5820: loss: 0.138312, loss_s1: 0.074687, loss_fp: 0.003236, loss_freq: 0.044357
[12:56:55.674] iteration 5821: loss: 0.139825, loss_s1: 0.070970, loss_fp: 0.001087, loss_freq: 0.042793
[12:56:56.327] iteration 5822: loss: 0.082267, loss_s1: 0.056285, loss_fp: 0.001069, loss_freq: 0.010613
[12:56:56.973] iteration 5823: loss: 0.091363, loss_s1: 0.036169, loss_fp: 0.000455, loss_freq: 0.011449
[12:56:57.602] iteration 5824: loss: 0.120212, loss_s1: 0.063071, loss_fp: 0.003850, loss_freq: 0.038546
[12:56:58.222] iteration 5825: loss: 0.148799, loss_s1: 0.030699, loss_fp: 0.001991, loss_freq: 0.018085
[12:56:58.834] iteration 5826: loss: 0.148025, loss_s1: 0.033407, loss_fp: 0.001586, loss_freq: 0.027440
[12:56:59.454] iteration 5827: loss: 0.168430, loss_s1: 0.140985, loss_fp: 0.000588, loss_freq: 0.098762
[12:57:00.071] iteration 5828: loss: 0.116476, loss_s1: 0.073767, loss_fp: 0.005923, loss_freq: 0.065257
[12:57:00.690] iteration 5829: loss: 0.115490, loss_s1: 0.024728, loss_fp: 0.001055, loss_freq: 0.006929
[12:57:01.304] iteration 5830: loss: 0.106626, loss_s1: 0.064655, loss_fp: 0.000761, loss_freq: 0.051404
[12:57:01.917] iteration 5831: loss: 0.098847, loss_s1: 0.043407, loss_fp: 0.012048, loss_freq: 0.009797
[12:57:02.526] iteration 5832: loss: 0.061993, loss_s1: 0.019753, loss_fp: 0.004219, loss_freq: 0.025501
[12:57:03.136] iteration 5833: loss: 0.109509, loss_s1: 0.052861, loss_fp: 0.008719, loss_freq: 0.014690
[12:57:03.748] iteration 5834: loss: 0.073640, loss_s1: 0.017689, loss_fp: 0.001137, loss_freq: 0.032375
[12:57:04.361] iteration 5835: loss: 0.199453, loss_s1: 0.050177, loss_fp: 0.001212, loss_freq: 0.053643
[12:57:04.966] iteration 5836: loss: 0.079186, loss_s1: 0.053966, loss_fp: 0.000393, loss_freq: 0.010028
[12:57:05.586] iteration 5837: loss: 0.098705, loss_s1: 0.011535, loss_fp: 0.003132, loss_freq: 0.051871
[12:57:06.199] iteration 5838: loss: 0.142075, loss_s1: 0.123042, loss_fp: 0.001054, loss_freq: 0.026920
[12:57:06.815] iteration 5839: loss: 0.086715, loss_s1: 0.083386, loss_fp: 0.005876, loss_freq: 0.023534
[12:57:07.426] iteration 5840: loss: 0.081835, loss_s1: 0.028251, loss_fp: 0.001815, loss_freq: 0.038049
[12:57:08.042] iteration 5841: loss: 0.159386, loss_s1: 0.083280, loss_fp: 0.000704, loss_freq: 0.081052
[12:57:08.657] iteration 5842: loss: 0.162275, loss_s1: 0.054939, loss_fp: 0.003088, loss_freq: 0.037150
[12:57:09.267] iteration 5843: loss: 0.097048, loss_s1: 0.040231, loss_fp: 0.001890, loss_freq: 0.011212
[12:57:09.880] iteration 5844: loss: 0.083893, loss_s1: 0.045561, loss_fp: 0.001732, loss_freq: 0.030101
[12:57:10.492] iteration 5845: loss: 0.112534, loss_s1: 0.105844, loss_fp: 0.000976, loss_freq: 0.044715
[12:57:11.116] iteration 5846: loss: 0.134266, loss_s1: 0.040177, loss_fp: 0.003177, loss_freq: 0.022668
[12:57:11.735] iteration 5847: loss: 0.071881, loss_s1: 0.020951, loss_fp: 0.000897, loss_freq: 0.027299
[12:57:12.348] iteration 5848: loss: 0.085091, loss_s1: 0.088044, loss_fp: 0.002634, loss_freq: 0.016852
[12:57:12.961] iteration 5849: loss: 0.133191, loss_s1: 0.066954, loss_fp: 0.000394, loss_freq: 0.028809
[12:57:13.581] iteration 5850: loss: 0.056087, loss_s1: 0.005483, loss_fp: 0.000548, loss_freq: 0.009910
[12:57:14.194] iteration 5851: loss: 0.116549, loss_s1: 0.051712, loss_fp: 0.001927, loss_freq: 0.008724
[12:57:14.806] iteration 5852: loss: 0.170209, loss_s1: 0.102300, loss_fp: 0.004311, loss_freq: 0.037537
[12:57:15.413] iteration 5853: loss: 0.078593, loss_s1: 0.042253, loss_fp: 0.003244, loss_freq: 0.015515
[12:57:16.039] iteration 5854: loss: 0.221941, loss_s1: 0.124030, loss_fp: 0.001944, loss_freq: 0.050735
[12:57:16.651] iteration 5855: loss: 0.203399, loss_s1: 0.026642, loss_fp: 0.002018, loss_freq: 0.022475
[12:57:17.264] iteration 5856: loss: 0.101930, loss_s1: 0.062147, loss_fp: 0.000650, loss_freq: 0.014786
[12:57:17.875] iteration 5857: loss: 0.114525, loss_s1: 0.103764, loss_fp: 0.028642, loss_freq: 0.016680
[12:57:18.486] iteration 5858: loss: 0.134822, loss_s1: 0.033926, loss_fp: 0.000797, loss_freq: 0.027733
[12:57:19.103] iteration 5859: loss: 0.067060, loss_s1: 0.029219, loss_fp: 0.002811, loss_freq: 0.010818
[12:57:19.718] iteration 5860: loss: 0.141643, loss_s1: 0.059891, loss_fp: 0.004186, loss_freq: 0.047478
[12:57:20.338] iteration 5861: loss: 0.143827, loss_s1: 0.058103, loss_fp: 0.001671, loss_freq: 0.033007
[12:57:20.953] iteration 5862: loss: 0.119889, loss_s1: 0.108346, loss_fp: 0.002216, loss_freq: 0.027151
[12:57:21.562] iteration 5863: loss: 0.057243, loss_s1: 0.020306, loss_fp: 0.008007, loss_freq: 0.015528
[12:57:22.562] iteration 5864: loss: 0.109968, loss_s1: 0.078218, loss_fp: 0.005745, loss_freq: 0.020241
[12:57:23.214] iteration 5865: loss: 0.114137, loss_s1: 0.089739, loss_fp: 0.005303, loss_freq: 0.036234
[12:57:23.840] iteration 5866: loss: 0.084977, loss_s1: 0.053791, loss_fp: 0.001237, loss_freq: 0.044919
[12:57:24.457] iteration 5867: loss: 0.098577, loss_s1: 0.042050, loss_fp: 0.001294, loss_freq: 0.031605
[12:57:25.087] iteration 5868: loss: 0.099806, loss_s1: 0.041834, loss_fp: 0.002154, loss_freq: 0.054992
[12:57:25.730] iteration 5869: loss: 0.102014, loss_s1: 0.024930, loss_fp: 0.000448, loss_freq: 0.004037
[12:57:26.346] iteration 5870: loss: 0.093277, loss_s1: 0.071327, loss_fp: 0.010389, loss_freq: 0.034526
[12:57:26.965] iteration 5871: loss: 0.159832, loss_s1: 0.048816, loss_fp: 0.000831, loss_freq: 0.059800
[12:57:27.586] iteration 5872: loss: 0.089619, loss_s1: 0.031683, loss_fp: 0.003972, loss_freq: 0.024555
[12:57:28.204] iteration 5873: loss: 0.160234, loss_s1: 0.040326, loss_fp: 0.000686, loss_freq: 0.013729
[12:57:28.821] iteration 5874: loss: 0.107384, loss_s1: 0.036827, loss_fp: 0.001231, loss_freq: 0.040026
[12:57:29.447] iteration 5875: loss: 0.088969, loss_s1: 0.043821, loss_fp: 0.003673, loss_freq: 0.036986
[12:57:30.071] iteration 5876: loss: 0.139015, loss_s1: 0.060138, loss_fp: 0.022896, loss_freq: 0.058912
[12:57:30.773] iteration 5877: loss: 0.069006, loss_s1: 0.024440, loss_fp: 0.001085, loss_freq: 0.025592
[12:57:31.431] iteration 5878: loss: 0.088136, loss_s1: 0.025017, loss_fp: 0.000985, loss_freq: 0.026419
[12:57:32.099] iteration 5879: loss: 0.073476, loss_s1: 0.044754, loss_fp: 0.001225, loss_freq: 0.018692
[12:57:32.750] iteration 5880: loss: 0.217847, loss_s1: 0.024809, loss_fp: 0.005066, loss_freq: 0.019378
[12:57:33.406] iteration 5881: loss: 0.130075, loss_s1: 0.044963, loss_fp: 0.003748, loss_freq: 0.021298
[12:57:34.061] iteration 5882: loss: 0.061255, loss_s1: 0.027618, loss_fp: 0.001421, loss_freq: 0.015569
[12:57:34.702] iteration 5883: loss: 0.086339, loss_s1: 0.063667, loss_fp: 0.007725, loss_freq: 0.016545
[12:57:35.355] iteration 5884: loss: 0.147106, loss_s1: 0.054283, loss_fp: 0.001872, loss_freq: 0.063252
[12:57:36.005] iteration 5885: loss: 0.091716, loss_s1: 0.013716, loss_fp: 0.001187, loss_freq: 0.042579
[12:57:36.658] iteration 5886: loss: 0.094024, loss_s1: 0.066967, loss_fp: 0.003018, loss_freq: 0.025924
[12:57:37.311] iteration 5887: loss: 0.100854, loss_s1: 0.050782, loss_fp: 0.001469, loss_freq: 0.028768
[12:57:37.963] iteration 5888: loss: 0.089037, loss_s1: 0.052697, loss_fp: 0.002112, loss_freq: 0.013952
[12:57:38.616] iteration 5889: loss: 0.123361, loss_s1: 0.019014, loss_fp: 0.003240, loss_freq: 0.074625
[12:57:39.255] iteration 5890: loss: 0.145204, loss_s1: 0.053041, loss_fp: 0.002800, loss_freq: 0.071546
[12:57:39.879] iteration 5891: loss: 0.098501, loss_s1: 0.072187, loss_fp: 0.004760, loss_freq: 0.020488
[12:57:40.498] iteration 5892: loss: 0.172865, loss_s1: 0.097248, loss_fp: 0.000759, loss_freq: 0.024908
[12:57:41.145] iteration 5893: loss: 0.120598, loss_s1: 0.026813, loss_fp: 0.003926, loss_freq: 0.030479
[12:57:41.803] iteration 5894: loss: 0.100830, loss_s1: 0.045159, loss_fp: 0.000755, loss_freq: 0.018332
[12:57:42.467] iteration 5895: loss: 0.079569, loss_s1: 0.027076, loss_fp: 0.003182, loss_freq: 0.025487
[12:57:43.167] iteration 5896: loss: 0.079744, loss_s1: 0.033284, loss_fp: 0.001629, loss_freq: 0.015565
[12:57:43.815] iteration 5897: loss: 0.131821, loss_s1: 0.074802, loss_fp: 0.022432, loss_freq: 0.064393
[12:57:44.438] iteration 5898: loss: 0.154883, loss_s1: 0.025654, loss_fp: 0.000944, loss_freq: 0.025067
[12:57:45.053] iteration 5899: loss: 0.160392, loss_s1: 0.118806, loss_fp: 0.001983, loss_freq: 0.028215
[12:57:45.671] iteration 5900: loss: 0.135154, loss_s1: 0.094627, loss_fp: 0.001496, loss_freq: 0.062747
[12:57:46.292] iteration 5901: loss: 0.070263, loss_s1: 0.047001, loss_fp: 0.002598, loss_freq: 0.020827
[12:57:46.910] iteration 5902: loss: 0.104327, loss_s1: 0.034514, loss_fp: 0.001013, loss_freq: 0.043261
[12:57:47.537] iteration 5903: loss: 0.093438, loss_s1: 0.038124, loss_fp: 0.001602, loss_freq: 0.018279
[12:57:48.150] iteration 5904: loss: 0.110751, loss_s1: 0.052295, loss_fp: 0.001184, loss_freq: 0.018424
[12:57:48.764] iteration 5905: loss: 0.077935, loss_s1: 0.051432, loss_fp: 0.000419, loss_freq: 0.027294
[12:57:49.383] iteration 5906: loss: 0.128200, loss_s1: 0.029287, loss_fp: 0.000535, loss_freq: 0.007561
[12:57:50.001] iteration 5907: loss: 0.095597, loss_s1: 0.054627, loss_fp: 0.007230, loss_freq: 0.042379
[12:57:50.622] iteration 5908: loss: 0.203196, loss_s1: 0.044868, loss_fp: 0.000816, loss_freq: 0.035924
[12:57:51.242] iteration 5909: loss: 0.141811, loss_s1: 0.049234, loss_fp: 0.000977, loss_freq: 0.036166
[12:57:51.855] iteration 5910: loss: 0.082677, loss_s1: 0.053381, loss_fp: 0.000756, loss_freq: 0.015521
[12:57:52.468] iteration 5911: loss: 0.107738, loss_s1: 0.035489, loss_fp: 0.000668, loss_freq: 0.028309
[12:57:53.082] iteration 5912: loss: 0.064010, loss_s1: 0.048388, loss_fp: 0.001361, loss_freq: 0.018702
[12:57:53.694] iteration 5913: loss: 0.097439, loss_s1: 0.069142, loss_fp: 0.001222, loss_freq: 0.036999
[12:57:54.304] iteration 5914: loss: 0.172320, loss_s1: 0.088078, loss_fp: 0.002573, loss_freq: 0.046377
[12:57:54.916] iteration 5915: loss: 0.171250, loss_s1: 0.033934, loss_fp: 0.000484, loss_freq: 0.039564
[12:57:55.536] iteration 5916: loss: 0.083162, loss_s1: 0.022625, loss_fp: 0.000645, loss_freq: 0.006938
[12:57:56.152] iteration 5917: loss: 0.102742, loss_s1: 0.049378, loss_fp: 0.001473, loss_freq: 0.010806
[12:57:56.768] iteration 5918: loss: 0.091006, loss_s1: 0.071503, loss_fp: 0.000389, loss_freq: 0.038667
[12:57:57.380] iteration 5919: loss: 0.100938, loss_s1: 0.043077, loss_fp: 0.002449, loss_freq: 0.025586
[12:57:57.993] iteration 5920: loss: 0.144841, loss_s1: 0.132392, loss_fp: 0.011048, loss_freq: 0.048765
[12:57:58.614] iteration 5921: loss: 0.089996, loss_s1: 0.048757, loss_fp: 0.001735, loss_freq: 0.026734
[12:57:59.226] iteration 5922: loss: 0.127273, loss_s1: 0.060643, loss_fp: 0.003662, loss_freq: 0.028754
[12:57:59.845] iteration 5923: loss: 0.083106, loss_s1: 0.058543, loss_fp: 0.002222, loss_freq: 0.021314
[12:58:00.465] iteration 5924: loss: 0.121967, loss_s1: 0.074828, loss_fp: 0.006447, loss_freq: 0.015941
[12:58:01.135] iteration 5925: loss: 0.151701, loss_s1: 0.045494, loss_fp: 0.007431, loss_freq: 0.023884
[12:58:01.796] iteration 5926: loss: 0.099045, loss_s1: 0.059610, loss_fp: 0.002081, loss_freq: 0.034612
[12:58:02.600] iteration 5927: loss: 0.169458, loss_s1: 0.075978, loss_fp: 0.003400, loss_freq: 0.028695
[12:58:03.320] iteration 5928: loss: 0.140601, loss_s1: 0.065977, loss_fp: 0.002620, loss_freq: 0.029680
[12:58:03.997] iteration 5929: loss: 0.162619, loss_s1: 0.038022, loss_fp: 0.024999, loss_freq: 0.021142
[12:58:04.607] iteration 5930: loss: 0.117986, loss_s1: 0.083076, loss_fp: 0.000617, loss_freq: 0.045946
[12:58:05.223] iteration 5931: loss: 0.136768, loss_s1: 0.029264, loss_fp: 0.001724, loss_freq: 0.011743
[12:58:05.841] iteration 5932: loss: 0.119886, loss_s1: 0.051692, loss_fp: 0.001760, loss_freq: 0.017389
[12:58:06.460] iteration 5933: loss: 0.092615, loss_s1: 0.016573, loss_fp: 0.003645, loss_freq: 0.013741
[12:58:07.078] iteration 5934: loss: 0.120808, loss_s1: 0.025610, loss_fp: 0.002030, loss_freq: 0.028006
[12:58:07.691] iteration 5935: loss: 0.110090, loss_s1: 0.089157, loss_fp: 0.004025, loss_freq: 0.009943
[12:58:08.307] iteration 5936: loss: 0.085122, loss_s1: 0.008632, loss_fp: 0.004140, loss_freq: 0.074259
[12:58:08.931] iteration 5937: loss: 0.114813, loss_s1: 0.028192, loss_fp: 0.007784, loss_freq: 0.028987
[12:58:09.544] iteration 5938: loss: 0.082488, loss_s1: 0.044957, loss_fp: 0.001283, loss_freq: 0.047502
[12:58:10.158] iteration 5939: loss: 0.101562, loss_s1: 0.039158, loss_fp: 0.002253, loss_freq: 0.020186
[12:58:10.781] iteration 5940: loss: 0.068722, loss_s1: 0.047124, loss_fp: 0.001171, loss_freq: 0.016847
[12:58:11.452] iteration 5941: loss: 0.095777, loss_s1: 0.026459, loss_fp: 0.000957, loss_freq: 0.013261
[12:58:12.065] iteration 5942: loss: 0.142179, loss_s1: 0.091679, loss_fp: 0.002086, loss_freq: 0.080387
[12:58:12.679] iteration 5943: loss: 0.218738, loss_s1: 0.046599, loss_fp: 0.000797, loss_freq: 0.035750
[12:58:13.291] iteration 5944: loss: 0.113921, loss_s1: 0.037368, loss_fp: 0.002891, loss_freq: 0.042845
[12:58:13.903] iteration 5945: loss: 0.115262, loss_s1: 0.079208, loss_fp: 0.002229, loss_freq: 0.057961
[12:58:14.525] iteration 5946: loss: 0.100520, loss_s1: 0.021233, loss_fp: 0.001748, loss_freq: 0.030674
[12:58:15.143] iteration 5947: loss: 0.052196, loss_s1: 0.023323, loss_fp: 0.001677, loss_freq: 0.006102
[12:58:15.761] iteration 5948: loss: 0.077658, loss_s1: 0.041611, loss_fp: 0.003591, loss_freq: 0.007931
[12:58:16.380] iteration 5949: loss: 0.124564, loss_s1: 0.063612, loss_fp: 0.008696, loss_freq: 0.060168
[12:58:17.000] iteration 5950: loss: 0.162750, loss_s1: 0.049902, loss_fp: 0.001392, loss_freq: 0.011221
[12:58:17.623] iteration 5951: loss: 0.105074, loss_s1: 0.034592, loss_fp: 0.001846, loss_freq: 0.032724
[12:58:18.243] iteration 5952: loss: 0.069303, loss_s1: 0.020202, loss_fp: 0.001628, loss_freq: 0.030965
[12:58:18.867] iteration 5953: loss: 0.078949, loss_s1: 0.059074, loss_fp: 0.006797, loss_freq: 0.029351
[12:58:19.484] iteration 5954: loss: 0.162455, loss_s1: 0.012769, loss_fp: 0.000552, loss_freq: 0.028650
[12:58:20.149] iteration 5955: loss: 0.123153, loss_s1: 0.077537, loss_fp: 0.001371, loss_freq: 0.053161
[12:58:20.766] iteration 5956: loss: 0.073237, loss_s1: 0.064093, loss_fp: 0.001220, loss_freq: 0.006833
[12:58:21.425] iteration 5957: loss: 0.150521, loss_s1: 0.038894, loss_fp: 0.001225, loss_freq: 0.046376
[12:58:22.049] iteration 5958: loss: 0.103351, loss_s1: 0.055539, loss_fp: 0.001432, loss_freq: 0.022721
[12:58:22.661] iteration 5959: loss: 0.107547, loss_s1: 0.035488, loss_fp: 0.000409, loss_freq: 0.057690
[12:58:23.270] iteration 5960: loss: 0.164466, loss_s1: 0.066202, loss_fp: 0.001749, loss_freq: 0.099940
[12:58:23.889] iteration 5961: loss: 0.079443, loss_s1: 0.033884, loss_fp: 0.000547, loss_freq: 0.037088
[12:58:24.514] iteration 5962: loss: 0.185233, loss_s1: 0.083291, loss_fp: 0.002675, loss_freq: 0.019395
[12:58:25.137] iteration 5963: loss: 0.172397, loss_s1: 0.089706, loss_fp: 0.004837, loss_freq: 0.092678
[12:58:25.751] iteration 5964: loss: 0.146860, loss_s1: 0.067113, loss_fp: 0.001080, loss_freq: 0.051409
[12:58:26.374] iteration 5965: loss: 0.096698, loss_s1: 0.046840, loss_fp: 0.003596, loss_freq: 0.014959
[12:58:26.991] iteration 5966: loss: 0.109984, loss_s1: 0.086313, loss_fp: 0.001593, loss_freq: 0.005367
[12:58:27.614] iteration 5967: loss: 0.143110, loss_s1: 0.058368, loss_fp: 0.000444, loss_freq: 0.054827
[12:58:28.235] iteration 5968: loss: 0.156669, loss_s1: 0.046067, loss_fp: 0.000736, loss_freq: 0.050223
[12:58:28.852] iteration 5969: loss: 0.085908, loss_s1: 0.075044, loss_fp: 0.002874, loss_freq: 0.009181
[12:58:29.474] iteration 5970: loss: 0.151401, loss_s1: 0.125723, loss_fp: 0.003211, loss_freq: 0.068327
[12:58:30.102] iteration 5971: loss: 0.068536, loss_s1: 0.041839, loss_fp: 0.002391, loss_freq: 0.023702
[12:58:30.724] iteration 5972: loss: 0.110167, loss_s1: 0.050612, loss_fp: 0.001207, loss_freq: 0.011562
[12:58:31.346] iteration 5973: loss: 0.096927, loss_s1: 0.038599, loss_fp: 0.004795, loss_freq: 0.057589
[12:58:31.964] iteration 5974: loss: 0.115740, loss_s1: 0.046133, loss_fp: 0.000975, loss_freq: 0.006128
[12:58:32.587] iteration 5975: loss: 0.071504, loss_s1: 0.067979, loss_fp: 0.005771, loss_freq: 0.014611
[12:58:33.203] iteration 5976: loss: 0.147394, loss_s1: 0.094712, loss_fp: 0.001467, loss_freq: 0.039915
[12:58:33.815] iteration 5977: loss: 0.101430, loss_s1: 0.105120, loss_fp: 0.001297, loss_freq: 0.010537
[12:58:34.429] iteration 5978: loss: 0.257476, loss_s1: 0.045689, loss_fp: 0.002386, loss_freq: 0.035622
[12:58:35.080] iteration 5979: loss: 0.141144, loss_s1: 0.097418, loss_fp: 0.003559, loss_freq: 0.014257
[12:58:35.736] iteration 5980: loss: 0.161252, loss_s1: 0.148534, loss_fp: 0.000612, loss_freq: 0.070729
[12:58:36.351] iteration 5981: loss: 0.101614, loss_s1: 0.064141, loss_fp: 0.002047, loss_freq: 0.033232
[12:58:37.031] iteration 5982: loss: 0.080495, loss_s1: 0.040880, loss_fp: 0.001677, loss_freq: 0.058765
[12:58:37.658] iteration 5983: loss: 0.082756, loss_s1: 0.030955, loss_fp: 0.002352, loss_freq: 0.035474
[12:58:38.277] iteration 5984: loss: 0.152571, loss_s1: 0.048872, loss_fp: 0.000803, loss_freq: 0.116558
[12:58:38.905] iteration 5985: loss: 0.139063, loss_s1: 0.053688, loss_fp: 0.001265, loss_freq: 0.032039
[12:58:39.527] iteration 5986: loss: 0.095481, loss_s1: 0.059929, loss_fp: 0.000470, loss_freq: 0.025171
[12:58:40.151] iteration 5987: loss: 0.072227, loss_s1: 0.029987, loss_fp: 0.002306, loss_freq: 0.016485
[12:58:40.774] iteration 5988: loss: 0.103096, loss_s1: 0.041841, loss_fp: 0.001251, loss_freq: 0.057791
[12:58:41.396] iteration 5989: loss: 0.100691, loss_s1: 0.030556, loss_fp: 0.001774, loss_freq: 0.011974
[12:58:42.022] iteration 5990: loss: 0.111943, loss_s1: 0.057112, loss_fp: 0.000537, loss_freq: 0.076280
[12:58:42.644] iteration 5991: loss: 0.079848, loss_s1: 0.035048, loss_fp: 0.006768, loss_freq: 0.022295
[12:58:43.278] iteration 5992: loss: 0.121918, loss_s1: 0.069896, loss_fp: 0.004650, loss_freq: 0.039807
[12:58:43.899] iteration 5993: loss: 0.066085, loss_s1: 0.023459, loss_fp: 0.002033, loss_freq: 0.012941
[12:58:44.520] iteration 5994: loss: 0.092413, loss_s1: 0.030082, loss_fp: 0.003185, loss_freq: 0.006092
[12:58:45.146] iteration 5995: loss: 0.172997, loss_s1: 0.066332, loss_fp: 0.009102, loss_freq: 0.035022
[12:58:45.775] iteration 5996: loss: 0.093941, loss_s1: 0.019525, loss_fp: 0.001622, loss_freq: 0.030655
[12:58:46.423] iteration 5997: loss: 0.117190, loss_s1: 0.025749, loss_fp: 0.001573, loss_freq: 0.048297
[12:58:47.033] iteration 5998: loss: 0.127382, loss_s1: 0.042804, loss_fp: 0.007816, loss_freq: 0.058789
[12:58:47.651] iteration 5999: loss: 0.104373, loss_s1: 0.048042, loss_fp: 0.001544, loss_freq: 0.025901
[12:58:48.275] iteration 6000: loss: 0.123013, loss_s1: 0.106183, loss_fp: 0.002974, loss_freq: 0.032934
[12:58:51.623] iteration 6000 : mean_dice : 0.709145
[12:58:52.266] iteration 6001: loss: 0.108426, loss_s1: 0.031861, loss_fp: 0.001365, loss_freq: 0.025345
[12:58:52.887] iteration 6002: loss: 0.073279, loss_s1: 0.023527, loss_fp: 0.000634, loss_freq: 0.030873
[12:58:53.509] iteration 6003: loss: 0.176074, loss_s1: 0.064784, loss_fp: 0.003866, loss_freq: 0.011968
[12:58:54.136] iteration 6004: loss: 0.107268, loss_s1: 0.086388, loss_fp: 0.002411, loss_freq: 0.034217
[12:58:54.753] iteration 6005: loss: 0.113247, loss_s1: 0.062633, loss_fp: 0.001334, loss_freq: 0.051360
[12:58:55.364] iteration 6006: loss: 0.079442, loss_s1: 0.060591, loss_fp: 0.000859, loss_freq: 0.013694
[12:58:56.356] iteration 6007: loss: 0.064946, loss_s1: 0.027259, loss_fp: 0.001974, loss_freq: 0.017474
[12:58:57.008] iteration 6008: loss: 0.100674, loss_s1: 0.074572, loss_fp: 0.005333, loss_freq: 0.023214
[12:58:57.666] iteration 6009: loss: 0.093853, loss_s1: 0.049534, loss_fp: 0.005546, loss_freq: 0.059585
[12:58:58.318] iteration 6010: loss: 0.097850, loss_s1: 0.040229, loss_fp: 0.001171, loss_freq: 0.026560
[12:58:58.925] iteration 6011: loss: 0.150900, loss_s1: 0.057553, loss_fp: 0.000938, loss_freq: 0.084952
[12:58:59.543] iteration 6012: loss: 0.096261, loss_s1: 0.025390, loss_fp: 0.000499, loss_freq: 0.006242
[12:59:00.166] iteration 6013: loss: 0.118254, loss_s1: 0.056279, loss_fp: 0.001284, loss_freq: 0.093572
[12:59:00.776] iteration 6014: loss: 0.163502, loss_s1: 0.063620, loss_fp: 0.006720, loss_freq: 0.032110
[12:59:01.395] iteration 6015: loss: 0.090651, loss_s1: 0.043305, loss_fp: 0.000696, loss_freq: 0.035374
[12:59:02.007] iteration 6016: loss: 0.158818, loss_s1: 0.049179, loss_fp: 0.002133, loss_freq: 0.024019
[12:59:02.635] iteration 6017: loss: 0.104100, loss_s1: 0.065159, loss_fp: 0.004077, loss_freq: 0.028796
[12:59:03.299] iteration 6018: loss: 0.092144, loss_s1: 0.028950, loss_fp: 0.002412, loss_freq: 0.051285
[12:59:03.946] iteration 6019: loss: 0.100606, loss_s1: 0.032526, loss_fp: 0.003170, loss_freq: 0.013589
[12:59:04.606] iteration 6020: loss: 0.065141, loss_s1: 0.029081, loss_fp: 0.001063, loss_freq: 0.026038
[12:59:05.257] iteration 6021: loss: 0.149729, loss_s1: 0.084482, loss_fp: 0.005701, loss_freq: 0.077142
[12:59:05.888] iteration 6022: loss: 0.106468, loss_s1: 0.047918, loss_fp: 0.002427, loss_freq: 0.032441
[12:59:06.514] iteration 6023: loss: 0.125730, loss_s1: 0.014818, loss_fp: 0.001748, loss_freq: 0.023877
[12:59:07.135] iteration 6024: loss: 0.091217, loss_s1: 0.022901, loss_fp: 0.005929, loss_freq: 0.006362
[12:59:07.763] iteration 6025: loss: 0.065489, loss_s1: 0.026993, loss_fp: 0.003121, loss_freq: 0.016649
[12:59:08.390] iteration 6026: loss: 0.098738, loss_s1: 0.040403, loss_fp: 0.003049, loss_freq: 0.024638
[12:59:09.007] iteration 6027: loss: 0.146216, loss_s1: 0.057461, loss_fp: 0.001402, loss_freq: 0.076476
[12:59:09.646] iteration 6028: loss: 0.058862, loss_s1: 0.021477, loss_fp: 0.001005, loss_freq: 0.009778
[12:59:10.265] iteration 6029: loss: 0.081116, loss_s1: 0.026561, loss_fp: 0.000598, loss_freq: 0.033181
[12:59:10.878] iteration 6030: loss: 0.106382, loss_s1: 0.043061, loss_fp: 0.000811, loss_freq: 0.022739
[12:59:11.493] iteration 6031: loss: 0.116743, loss_s1: 0.054308, loss_fp: 0.004651, loss_freq: 0.040586
[12:59:12.110] iteration 6032: loss: 0.131379, loss_s1: 0.062965, loss_fp: 0.001360, loss_freq: 0.032756
[12:59:12.725] iteration 6033: loss: 0.131556, loss_s1: 0.033114, loss_fp: 0.000401, loss_freq: 0.041982
[12:59:13.338] iteration 6034: loss: 0.077546, loss_s1: 0.040584, loss_fp: 0.003761, loss_freq: 0.022621
[12:59:13.952] iteration 6035: loss: 0.144159, loss_s1: 0.090932, loss_fp: 0.001740, loss_freq: 0.046790
[12:59:14.570] iteration 6036: loss: 0.180817, loss_s1: 0.051262, loss_fp: 0.000990, loss_freq: 0.035046
[12:59:15.178] iteration 6037: loss: 0.081283, loss_s1: 0.024049, loss_fp: 0.000600, loss_freq: 0.008987
[12:59:15.839] iteration 6038: loss: 0.100781, loss_s1: 0.085260, loss_fp: 0.001791, loss_freq: 0.032347
[12:59:16.491] iteration 6039: loss: 0.078373, loss_s1: 0.045123, loss_fp: 0.010420, loss_freq: 0.013053
[12:59:17.118] iteration 6040: loss: 0.138512, loss_s1: 0.103496, loss_fp: 0.005605, loss_freq: 0.064618
[12:59:17.745] iteration 6041: loss: 0.165688, loss_s1: 0.065304, loss_fp: 0.003087, loss_freq: 0.031226
[12:59:18.382] iteration 6042: loss: 0.162685, loss_s1: 0.123048, loss_fp: 0.000863, loss_freq: 0.043293
[12:59:19.006] iteration 6043: loss: 0.144709, loss_s1: 0.146338, loss_fp: 0.006719, loss_freq: 0.043380
[12:59:19.623] iteration 6044: loss: 0.092177, loss_s1: 0.086722, loss_fp: 0.001507, loss_freq: 0.026053
[12:59:20.237] iteration 6045: loss: 0.123871, loss_s1: 0.039459, loss_fp: 0.002904, loss_freq: 0.030630
[12:59:20.853] iteration 6046: loss: 0.074791, loss_s1: 0.033797, loss_fp: 0.001496, loss_freq: 0.013201
[12:59:21.472] iteration 6047: loss: 0.098957, loss_s1: 0.040148, loss_fp: 0.004473, loss_freq: 0.010693
[12:59:22.090] iteration 6048: loss: 0.069088, loss_s1: 0.053511, loss_fp: 0.000395, loss_freq: 0.019202
[12:59:22.705] iteration 6049: loss: 0.098209, loss_s1: 0.033549, loss_fp: 0.001646, loss_freq: 0.037364
[12:59:23.327] iteration 6050: loss: 0.086776, loss_s1: 0.056974, loss_fp: 0.001774, loss_freq: 0.042350
[12:59:23.951] iteration 6051: loss: 0.212443, loss_s1: 0.092846, loss_fp: 0.001519, loss_freq: 0.030208
[12:59:24.575] iteration 6052: loss: 0.165727, loss_s1: 0.071669, loss_fp: 0.001522, loss_freq: 0.033274
[12:59:25.198] iteration 6053: loss: 0.077247, loss_s1: 0.019105, loss_fp: 0.000908, loss_freq: 0.023908
[12:59:25.880] iteration 6054: loss: 0.103935, loss_s1: 0.026814, loss_fp: 0.001077, loss_freq: 0.025197
[12:59:26.532] iteration 6055: loss: 0.089861, loss_s1: 0.037421, loss_fp: 0.001397, loss_freq: 0.051927
[12:59:27.215] iteration 6056: loss: 0.091446, loss_s1: 0.049266, loss_fp: 0.000787, loss_freq: 0.040170
[12:59:27.869] iteration 6057: loss: 0.092056, loss_s1: 0.046110, loss_fp: 0.002964, loss_freq: 0.016179
[12:59:28.526] iteration 6058: loss: 0.098409, loss_s1: 0.018995, loss_fp: 0.003664, loss_freq: 0.026678
[12:59:29.205] iteration 6059: loss: 0.068910, loss_s1: 0.022102, loss_fp: 0.001806, loss_freq: 0.003285
[12:59:29.862] iteration 6060: loss: 0.096696, loss_s1: 0.033951, loss_fp: 0.001076, loss_freq: 0.012515
[12:59:30.519] iteration 6061: loss: 0.094557, loss_s1: 0.038769, loss_fp: 0.000813, loss_freq: 0.017844
[12:59:31.181] iteration 6062: loss: 0.156433, loss_s1: 0.044496, loss_fp: 0.002696, loss_freq: 0.016204
[12:59:31.837] iteration 6063: loss: 0.122675, loss_s1: 0.118694, loss_fp: 0.001506, loss_freq: 0.027787
[12:59:32.509] iteration 6064: loss: 0.055367, loss_s1: 0.015025, loss_fp: 0.002036, loss_freq: 0.018134
[12:59:33.178] iteration 6065: loss: 0.182018, loss_s1: 0.107252, loss_fp: 0.001050, loss_freq: 0.054817
[12:59:33.820] iteration 6066: loss: 0.094702, loss_s1: 0.035300, loss_fp: 0.001737, loss_freq: 0.064678
[12:59:34.451] iteration 6067: loss: 0.120061, loss_s1: 0.039908, loss_fp: 0.001804, loss_freq: 0.008043
[12:59:35.082] iteration 6068: loss: 0.171396, loss_s1: 0.090618, loss_fp: 0.001325, loss_freq: 0.040284
[12:59:35.700] iteration 6069: loss: 0.131433, loss_s1: 0.066760, loss_fp: 0.009973, loss_freq: 0.063832
[12:59:36.324] iteration 6070: loss: 0.122212, loss_s1: 0.061701, loss_fp: 0.000478, loss_freq: 0.016540
[12:59:37.044] iteration 6071: loss: 0.118169, loss_s1: 0.030857, loss_fp: 0.002369, loss_freq: 0.025243
[12:59:37.691] iteration 6072: loss: 0.134037, loss_s1: 0.050364, loss_fp: 0.002309, loss_freq: 0.018818
[12:59:38.318] iteration 6073: loss: 0.127630, loss_s1: 0.083236, loss_fp: 0.001730, loss_freq: 0.081246
[12:59:38.940] iteration 6074: loss: 0.143890, loss_s1: 0.077904, loss_fp: 0.000657, loss_freq: 0.025619
[12:59:39.555] iteration 6075: loss: 0.083343, loss_s1: 0.069408, loss_fp: 0.004318, loss_freq: 0.023907
[12:59:40.170] iteration 6076: loss: 0.155567, loss_s1: 0.053138, loss_fp: 0.001661, loss_freq: 0.042884
[12:59:40.821] iteration 6077: loss: 0.085322, loss_s1: 0.017507, loss_fp: 0.000680, loss_freq: 0.005557
[12:59:41.446] iteration 6078: loss: 0.145632, loss_s1: 0.113263, loss_fp: 0.002687, loss_freq: 0.060567
[12:59:42.127] iteration 6079: loss: 0.133992, loss_s1: 0.105473, loss_fp: 0.001553, loss_freq: 0.079532
[12:59:42.790] iteration 6080: loss: 0.088055, loss_s1: 0.027823, loss_fp: 0.001224, loss_freq: 0.061738
[12:59:43.409] iteration 6081: loss: 0.103081, loss_s1: 0.034889, loss_fp: 0.001421, loss_freq: 0.072609
[12:59:44.072] iteration 6082: loss: 0.090545, loss_s1: 0.058665, loss_fp: 0.001579, loss_freq: 0.007619
[12:59:44.730] iteration 6083: loss: 0.092190, loss_s1: 0.100332, loss_fp: 0.002112, loss_freq: 0.008816
[12:59:45.348] iteration 6084: loss: 0.112284, loss_s1: 0.042565, loss_fp: 0.002909, loss_freq: 0.014512
[12:59:45.964] iteration 6085: loss: 0.114313, loss_s1: 0.061415, loss_fp: 0.003612, loss_freq: 0.081176
[12:59:46.584] iteration 6086: loss: 0.244369, loss_s1: 0.045361, loss_fp: 0.002340, loss_freq: 0.033129
[12:59:47.199] iteration 6087: loss: 0.092899, loss_s1: 0.032574, loss_fp: 0.001804, loss_freq: 0.044340
[12:59:47.826] iteration 6088: loss: 0.091129, loss_s1: 0.053153, loss_fp: 0.004183, loss_freq: 0.041712
[12:59:48.450] iteration 6089: loss: 0.117108, loss_s1: 0.046835, loss_fp: 0.001972, loss_freq: 0.059767
[12:59:49.076] iteration 6090: loss: 0.056662, loss_s1: 0.021652, loss_fp: 0.001149, loss_freq: 0.019087
[12:59:49.699] iteration 6091: loss: 0.091808, loss_s1: 0.073067, loss_fp: 0.002652, loss_freq: 0.011701
[12:59:50.325] iteration 6092: loss: 0.090905, loss_s1: 0.049881, loss_fp: 0.002232, loss_freq: 0.055579
[12:59:50.943] iteration 6093: loss: 0.118897, loss_s1: 0.031981, loss_fp: 0.000856, loss_freq: 0.017912
[12:59:51.563] iteration 6094: loss: 0.153679, loss_s1: 0.059085, loss_fp: 0.000725, loss_freq: 0.021054
[12:59:52.183] iteration 6095: loss: 0.080576, loss_s1: 0.025687, loss_fp: 0.001299, loss_freq: 0.007300
[12:59:52.800] iteration 6096: loss: 0.126770, loss_s1: 0.051462, loss_fp: 0.003017, loss_freq: 0.042523
[12:59:53.416] iteration 6097: loss: 0.132580, loss_s1: 0.044753, loss_fp: 0.003813, loss_freq: 0.017338
[12:59:54.040] iteration 6098: loss: 0.088980, loss_s1: 0.056262, loss_fp: 0.001931, loss_freq: 0.041655
[12:59:54.659] iteration 6099: loss: 0.060128, loss_s1: 0.018872, loss_fp: 0.000698, loss_freq: 0.012443
[12:59:55.280] iteration 6100: loss: 0.139771, loss_s1: 0.080291, loss_fp: 0.003297, loss_freq: 0.049433
[12:59:55.901] iteration 6101: loss: 0.073909, loss_s1: 0.015067, loss_fp: 0.001680, loss_freq: 0.004618
[12:59:56.535] iteration 6102: loss: 0.129489, loss_s1: 0.044586, loss_fp: 0.003575, loss_freq: 0.051967
[12:59:57.155] iteration 6103: loss: 0.233066, loss_s1: 0.147650, loss_fp: 0.000651, loss_freq: 0.198470
[12:59:57.779] iteration 6104: loss: 0.078205, loss_s1: 0.023109, loss_fp: 0.001255, loss_freq: 0.047165
[12:59:58.408] iteration 6105: loss: 0.104306, loss_s1: 0.053071, loss_fp: 0.001060, loss_freq: 0.023628
[12:59:59.037] iteration 6106: loss: 0.175883, loss_s1: 0.105178, loss_fp: 0.003074, loss_freq: 0.051413
[12:59:59.660] iteration 6107: loss: 0.145925, loss_s1: 0.052494, loss_fp: 0.011482, loss_freq: 0.053662
[13:00:00.273] iteration 6108: loss: 0.077147, loss_s1: 0.032367, loss_fp: 0.001572, loss_freq: 0.011401
[13:00:00.897] iteration 6109: loss: 0.109318, loss_s1: 0.030789, loss_fp: 0.004663, loss_freq: 0.003135
[13:00:01.519] iteration 6110: loss: 0.159491, loss_s1: 0.054604, loss_fp: 0.001940, loss_freq: 0.060038
[13:00:02.135] iteration 6111: loss: 0.150094, loss_s1: 0.058891, loss_fp: 0.002060, loss_freq: 0.030333
[13:00:02.767] iteration 6112: loss: 0.092011, loss_s1: 0.048846, loss_fp: 0.002207, loss_freq: 0.025367
[13:00:03.395] iteration 6113: loss: 0.098587, loss_s1: 0.077118, loss_fp: 0.001017, loss_freq: 0.025220
[13:00:04.016] iteration 6114: loss: 0.067436, loss_s1: 0.057764, loss_fp: 0.002743, loss_freq: 0.012794
[13:00:04.639] iteration 6115: loss: 0.110831, loss_s1: 0.028293, loss_fp: 0.000567, loss_freq: 0.005092
[13:00:05.306] iteration 6116: loss: 0.078329, loss_s1: 0.045484, loss_fp: 0.001474, loss_freq: 0.021169
[13:00:06.230] iteration 6117: loss: 0.099100, loss_s1: 0.024316, loss_fp: 0.005143, loss_freq: 0.017774
[13:00:06.986] iteration 6118: loss: 0.070408, loss_s1: 0.053609, loss_fp: 0.000933, loss_freq: 0.033064
[13:00:07.613] iteration 6119: loss: 0.113198, loss_s1: 0.050037, loss_fp: 0.001470, loss_freq: 0.021063
[13:00:08.230] iteration 6120: loss: 0.095318, loss_s1: 0.054575, loss_fp: 0.005172, loss_freq: 0.038390
[13:00:08.850] iteration 6121: loss: 0.201609, loss_s1: 0.050434, loss_fp: 0.000811, loss_freq: 0.046579
[13:00:09.466] iteration 6122: loss: 0.117018, loss_s1: 0.051911, loss_fp: 0.002989, loss_freq: 0.012926
[13:00:10.086] iteration 6123: loss: 0.129093, loss_s1: 0.055056, loss_fp: 0.001074, loss_freq: 0.035728
[13:00:10.717] iteration 6124: loss: 0.103615, loss_s1: 0.082373, loss_fp: 0.001160, loss_freq: 0.037978
[13:00:11.343] iteration 6125: loss: 0.063581, loss_s1: 0.032705, loss_fp: 0.001945, loss_freq: 0.021890
[13:00:11.976] iteration 6126: loss: 0.106249, loss_s1: 0.045138, loss_fp: 0.003369, loss_freq: 0.087288
[13:00:12.598] iteration 6127: loss: 0.102773, loss_s1: 0.023336, loss_fp: 0.001376, loss_freq: 0.101028
[13:00:13.218] iteration 6128: loss: 0.182106, loss_s1: 0.070819, loss_fp: 0.003163, loss_freq: 0.014808
[13:00:13.839] iteration 6129: loss: 0.096584, loss_s1: 0.059212, loss_fp: 0.001624, loss_freq: 0.004566
[13:00:14.455] iteration 6130: loss: 0.093864, loss_s1: 0.064390, loss_fp: 0.001732, loss_freq: 0.036571
[13:00:15.076] iteration 6131: loss: 0.113786, loss_s1: 0.040135, loss_fp: 0.004938, loss_freq: 0.010972
[13:00:15.701] iteration 6132: loss: 0.098825, loss_s1: 0.030322, loss_fp: 0.001313, loss_freq: 0.024007
[13:00:16.321] iteration 6133: loss: 0.079846, loss_s1: 0.029274, loss_fp: 0.003538, loss_freq: 0.049706
[13:00:16.952] iteration 6134: loss: 0.082184, loss_s1: 0.026468, loss_fp: 0.004390, loss_freq: 0.048118
[13:00:17.578] iteration 6135: loss: 0.116488, loss_s1: 0.090591, loss_fp: 0.003073, loss_freq: 0.012039
[13:00:18.209] iteration 6136: loss: 0.083862, loss_s1: 0.017301, loss_fp: 0.000881, loss_freq: 0.007449
[13:00:18.842] iteration 6137: loss: 0.105700, loss_s1: 0.048046, loss_fp: 0.003159, loss_freq: 0.005342
[13:00:19.468] iteration 6138: loss: 0.237077, loss_s1: 0.071029, loss_fp: 0.002626, loss_freq: 0.028439
[13:00:20.098] iteration 6139: loss: 0.089930, loss_s1: 0.026671, loss_fp: 0.001712, loss_freq: 0.014175
[13:00:20.718] iteration 6140: loss: 0.162586, loss_s1: 0.124088, loss_fp: 0.001283, loss_freq: 0.050012
[13:00:21.348] iteration 6141: loss: 0.138871, loss_s1: 0.027756, loss_fp: 0.001391, loss_freq: 0.050157
[13:00:21.972] iteration 6142: loss: 0.088208, loss_s1: 0.047460, loss_fp: 0.000995, loss_freq: 0.013437
[13:00:22.609] iteration 6143: loss: 0.086338, loss_s1: 0.077409, loss_fp: 0.005144, loss_freq: 0.010799
[13:00:23.235] iteration 6144: loss: 0.094788, loss_s1: 0.036307, loss_fp: 0.001035, loss_freq: 0.018010
[13:00:23.862] iteration 6145: loss: 0.061468, loss_s1: 0.026213, loss_fp: 0.000953, loss_freq: 0.017421
[13:00:24.483] iteration 6146: loss: 0.147524, loss_s1: 0.065117, loss_fp: 0.002389, loss_freq: 0.016829
[13:00:25.106] iteration 6147: loss: 0.126463, loss_s1: 0.061826, loss_fp: 0.008542, loss_freq: 0.029519
[13:00:25.733] iteration 6148: loss: 0.149890, loss_s1: 0.173114, loss_fp: 0.003843, loss_freq: 0.012586
[13:00:26.340] iteration 6149: loss: 0.070826, loss_s1: 0.036920, loss_fp: 0.001687, loss_freq: 0.034103
[13:00:27.297] iteration 6150: loss: 0.113576, loss_s1: 0.039988, loss_fp: 0.001192, loss_freq: 0.013674
[13:00:27.920] iteration 6151: loss: 0.076581, loss_s1: 0.047374, loss_fp: 0.002598, loss_freq: 0.019464
[13:00:28.563] iteration 6152: loss: 0.094080, loss_s1: 0.043131, loss_fp: 0.003485, loss_freq: 0.047162
[13:00:29.184] iteration 6153: loss: 0.086744, loss_s1: 0.040388, loss_fp: 0.001025, loss_freq: 0.020993
[13:00:29.809] iteration 6154: loss: 0.085941, loss_s1: 0.031817, loss_fp: 0.002851, loss_freq: 0.055213
[13:00:30.436] iteration 6155: loss: 0.143299, loss_s1: 0.065412, loss_fp: 0.001613, loss_freq: 0.006610
[13:00:31.055] iteration 6156: loss: 0.059499, loss_s1: 0.012337, loss_fp: 0.000823, loss_freq: 0.043355
[13:00:31.675] iteration 6157: loss: 0.139966, loss_s1: 0.082766, loss_fp: 0.002198, loss_freq: 0.019765
[13:00:32.295] iteration 6158: loss: 0.106551, loss_s1: 0.063099, loss_fp: 0.003201, loss_freq: 0.050090
[13:00:32.914] iteration 6159: loss: 0.148914, loss_s1: 0.015863, loss_fp: 0.001922, loss_freq: 0.045416
[13:00:33.538] iteration 6160: loss: 0.129323, loss_s1: 0.069807, loss_fp: 0.003906, loss_freq: 0.047453
[13:00:34.196] iteration 6161: loss: 0.088829, loss_s1: 0.042109, loss_fp: 0.000697, loss_freq: 0.041529
[13:00:34.858] iteration 6162: loss: 0.114727, loss_s1: 0.067452, loss_fp: 0.002476, loss_freq: 0.015664
[13:00:35.511] iteration 6163: loss: 0.049425, loss_s1: 0.010116, loss_fp: 0.002052, loss_freq: 0.023407
[13:00:36.155] iteration 6164: loss: 0.138998, loss_s1: 0.117729, loss_fp: 0.009362, loss_freq: 0.072504
[13:00:36.784] iteration 6165: loss: 0.077696, loss_s1: 0.029977, loss_fp: 0.001177, loss_freq: 0.022103
[13:00:37.410] iteration 6166: loss: 0.129909, loss_s1: 0.008606, loss_fp: 0.002879, loss_freq: 0.030364
[13:00:38.037] iteration 6167: loss: 0.103269, loss_s1: 0.014259, loss_fp: 0.001940, loss_freq: 0.009884
[13:00:38.714] iteration 6168: loss: 0.068182, loss_s1: 0.031513, loss_fp: 0.002723, loss_freq: 0.014167
[13:00:39.333] iteration 6169: loss: 0.079213, loss_s1: 0.027566, loss_fp: 0.002198, loss_freq: 0.020846
[13:00:40.031] iteration 6170: loss: 0.147595, loss_s1: 0.019195, loss_fp: 0.003940, loss_freq: 0.061179
[13:00:40.694] iteration 6171: loss: 0.058312, loss_s1: 0.018003, loss_fp: 0.000940, loss_freq: 0.007782
[13:00:41.347] iteration 6172: loss: 0.073556, loss_s1: 0.048306, loss_fp: 0.001507, loss_freq: 0.026449
[13:00:42.015] iteration 6173: loss: 0.127247, loss_s1: 0.052529, loss_fp: 0.005910, loss_freq: 0.017874
[13:00:42.656] iteration 6174: loss: 0.102221, loss_s1: 0.036730, loss_fp: 0.004246, loss_freq: 0.051081
[13:00:43.276] iteration 6175: loss: 0.126893, loss_s1: 0.066528, loss_fp: 0.001578, loss_freq: 0.022705
[13:00:43.896] iteration 6176: loss: 0.150503, loss_s1: 0.052781, loss_fp: 0.001569, loss_freq: 0.039650
[13:00:44.517] iteration 6177: loss: 0.081435, loss_s1: 0.026044, loss_fp: 0.002209, loss_freq: 0.022252
[13:00:45.141] iteration 6178: loss: 0.162673, loss_s1: 0.062537, loss_fp: 0.005436, loss_freq: 0.036258
[13:00:45.769] iteration 6179: loss: 0.098606, loss_s1: 0.057297, loss_fp: 0.002213, loss_freq: 0.008506
[13:00:46.384] iteration 6180: loss: 0.094516, loss_s1: 0.042344, loss_fp: 0.004606, loss_freq: 0.006593
[13:00:46.995] iteration 6181: loss: 0.110051, loss_s1: 0.058468, loss_fp: 0.001342, loss_freq: 0.017865
[13:00:47.614] iteration 6182: loss: 0.065299, loss_s1: 0.035719, loss_fp: 0.001451, loss_freq: 0.017148
[13:00:48.228] iteration 6183: loss: 0.135826, loss_s1: 0.097020, loss_fp: 0.002148, loss_freq: 0.058573
[13:00:48.870] iteration 6184: loss: 0.154578, loss_s1: 0.039815, loss_fp: 0.004438, loss_freq: 0.024129
[13:00:49.490] iteration 6185: loss: 0.121223, loss_s1: 0.087791, loss_fp: 0.001559, loss_freq: 0.036180
[13:00:50.113] iteration 6186: loss: 0.123925, loss_s1: 0.071183, loss_fp: 0.000880, loss_freq: 0.027466
[13:00:50.723] iteration 6187: loss: 0.062090, loss_s1: 0.031737, loss_fp: 0.001236, loss_freq: 0.015255
[13:00:51.343] iteration 6188: loss: 0.116759, loss_s1: 0.060471, loss_fp: 0.006493, loss_freq: 0.028800
[13:00:51.962] iteration 6189: loss: 0.099600, loss_s1: 0.037632, loss_fp: 0.002753, loss_freq: 0.017368
[13:00:52.579] iteration 6190: loss: 0.076694, loss_s1: 0.019658, loss_fp: 0.002929, loss_freq: 0.009878
[13:00:53.198] iteration 6191: loss: 0.064387, loss_s1: 0.048599, loss_fp: 0.001703, loss_freq: 0.023923
[13:00:53.815] iteration 6192: loss: 0.089955, loss_s1: 0.024210, loss_fp: 0.001338, loss_freq: 0.025484
[13:00:54.434] iteration 6193: loss: 0.094120, loss_s1: 0.088645, loss_fp: 0.002187, loss_freq: 0.020244
[13:00:55.057] iteration 6194: loss: 0.172552, loss_s1: 0.044954, loss_fp: 0.001500, loss_freq: 0.026284
[13:00:55.711] iteration 6195: loss: 0.114800, loss_s1: 0.080019, loss_fp: 0.002783, loss_freq: 0.032132
[13:00:56.365] iteration 6196: loss: 0.098600, loss_s1: 0.057683, loss_fp: 0.001276, loss_freq: 0.040362
[13:00:57.022] iteration 6197: loss: 0.101604, loss_s1: 0.025427, loss_fp: 0.002528, loss_freq: 0.056740
[13:00:57.675] iteration 6198: loss: 0.070602, loss_s1: 0.040193, loss_fp: 0.005696, loss_freq: 0.014675
[13:00:58.316] iteration 6199: loss: 0.115584, loss_s1: 0.075863, loss_fp: 0.001835, loss_freq: 0.033272
[13:00:58.935] iteration 6200: loss: 0.078031, loss_s1: 0.058694, loss_fp: 0.001186, loss_freq: 0.009798
[13:01:02.130] iteration 6200 : mean_dice : 0.708114
[13:01:02.770] iteration 6201: loss: 0.238376, loss_s1: 0.045765, loss_fp: 0.001534, loss_freq: 0.071481
[13:01:03.391] iteration 6202: loss: 0.081169, loss_s1: 0.036744, loss_fp: 0.002071, loss_freq: 0.003583
[13:01:04.008] iteration 6203: loss: 0.074417, loss_s1: 0.045089, loss_fp: 0.001141, loss_freq: 0.021413
[13:01:04.624] iteration 6204: loss: 0.123078, loss_s1: 0.066075, loss_fp: 0.002564, loss_freq: 0.039093
[13:01:05.240] iteration 6205: loss: 0.145283, loss_s1: 0.057557, loss_fp: 0.000949, loss_freq: 0.009636
[13:01:05.884] iteration 6206: loss: 0.152142, loss_s1: 0.080515, loss_fp: 0.007616, loss_freq: 0.047758
[13:01:06.535] iteration 6207: loss: 0.064754, loss_s1: 0.017942, loss_fp: 0.001580, loss_freq: 0.010222
[13:01:07.184] iteration 6208: loss: 0.121650, loss_s1: 0.033064, loss_fp: 0.003773, loss_freq: 0.025583
[13:01:07.832] iteration 6209: loss: 0.067854, loss_s1: 0.023125, loss_fp: 0.001323, loss_freq: 0.019743
[13:01:08.483] iteration 6210: loss: 0.134697, loss_s1: 0.062150, loss_fp: 0.001121, loss_freq: 0.016264
[13:01:09.134] iteration 6211: loss: 0.096065, loss_s1: 0.045590, loss_fp: 0.002401, loss_freq: 0.026982
[13:01:09.793] iteration 6212: loss: 0.103504, loss_s1: 0.042177, loss_fp: 0.001326, loss_freq: 0.041968
[13:01:10.440] iteration 6213: loss: 0.166301, loss_s1: 0.049057, loss_fp: 0.000690, loss_freq: 0.016659
[13:01:11.055] iteration 6214: loss: 0.139198, loss_s1: 0.039339, loss_fp: 0.016673, loss_freq: 0.031569
[13:01:11.676] iteration 6215: loss: 0.108711, loss_s1: 0.050496, loss_fp: 0.001520, loss_freq: 0.005586
[13:01:12.299] iteration 6216: loss: 0.104748, loss_s1: 0.025677, loss_fp: 0.000674, loss_freq: 0.097621
[13:01:12.922] iteration 6217: loss: 0.142935, loss_s1: 0.011683, loss_fp: 0.002440, loss_freq: 0.047157
[13:01:13.544] iteration 6218: loss: 0.087478, loss_s1: 0.063950, loss_fp: 0.002164, loss_freq: 0.018338
[13:01:14.162] iteration 6219: loss: 0.127720, loss_s1: 0.055454, loss_fp: 0.000953, loss_freq: 0.008626
[13:01:14.780] iteration 6220: loss: 0.070375, loss_s1: 0.037983, loss_fp: 0.001085, loss_freq: 0.013275
[13:01:15.406] iteration 6221: loss: 0.071327, loss_s1: 0.034014, loss_fp: 0.001232, loss_freq: 0.012663
[13:01:16.021] iteration 6222: loss: 0.111048, loss_s1: 0.033366, loss_fp: 0.007671, loss_freq: 0.069841
[13:01:16.640] iteration 6223: loss: 0.160272, loss_s1: 0.102930, loss_fp: 0.002278, loss_freq: 0.076003
[13:01:17.255] iteration 6224: loss: 0.077020, loss_s1: 0.020813, loss_fp: 0.000833, loss_freq: 0.058624
[13:01:17.872] iteration 6225: loss: 0.099344, loss_s1: 0.061175, loss_fp: 0.003285, loss_freq: 0.009194
[13:01:18.515] iteration 6226: loss: 0.069951, loss_s1: 0.051778, loss_fp: 0.001915, loss_freq: 0.019387
[13:01:19.137] iteration 6227: loss: 0.114856, loss_s1: 0.052318, loss_fp: 0.000953, loss_freq: 0.028516
[13:01:19.754] iteration 6228: loss: 0.116664, loss_s1: 0.058212, loss_fp: 0.007544, loss_freq: 0.077474
[13:01:20.422] iteration 6229: loss: 0.231331, loss_s1: 0.043070, loss_fp: 0.002676, loss_freq: 0.040642
[13:01:21.042] iteration 6230: loss: 0.134847, loss_s1: 0.079756, loss_fp: 0.002464, loss_freq: 0.021141
[13:01:21.681] iteration 6231: loss: 0.098139, loss_s1: 0.046602, loss_fp: 0.002152, loss_freq: 0.042772
[13:01:22.304] iteration 6232: loss: 0.096823, loss_s1: 0.051227, loss_fp: 0.000618, loss_freq: 0.007143
[13:01:22.929] iteration 6233: loss: 0.082725, loss_s1: 0.048086, loss_fp: 0.003449, loss_freq: 0.025639
[13:01:23.554] iteration 6234: loss: 0.091695, loss_s1: 0.026345, loss_fp: 0.000660, loss_freq: 0.022884
[13:01:24.175] iteration 6235: loss: 0.135580, loss_s1: 0.079913, loss_fp: 0.002490, loss_freq: 0.066794
[13:01:24.801] iteration 6236: loss: 0.116513, loss_s1: 0.043165, loss_fp: 0.000984, loss_freq: 0.004839
[13:01:25.420] iteration 6237: loss: 0.126965, loss_s1: 0.037121, loss_fp: 0.001262, loss_freq: 0.028345
[13:01:26.032] iteration 6238: loss: 0.076681, loss_s1: 0.018515, loss_fp: 0.010780, loss_freq: 0.033307
[13:01:26.652] iteration 6239: loss: 0.127797, loss_s1: 0.081648, loss_fp: 0.002751, loss_freq: 0.021970
[13:01:27.270] iteration 6240: loss: 0.125696, loss_s1: 0.026253, loss_fp: 0.002701, loss_freq: 0.026821
[13:01:27.890] iteration 6241: loss: 0.114432, loss_s1: 0.080414, loss_fp: 0.002477, loss_freq: 0.061039
[13:01:28.589] iteration 6242: loss: 0.061840, loss_s1: 0.047090, loss_fp: 0.002362, loss_freq: 0.010431
[13:01:29.247] iteration 6243: loss: 0.126480, loss_s1: 0.072012, loss_fp: 0.001777, loss_freq: 0.027652
[13:01:29.903] iteration 6244: loss: 0.076071, loss_s1: 0.043356, loss_fp: 0.001729, loss_freq: 0.010718
[13:01:30.562] iteration 6245: loss: 0.171245, loss_s1: 0.100401, loss_fp: 0.004973, loss_freq: 0.037319
[13:01:31.200] iteration 6246: loss: 0.137348, loss_s1: 0.040220, loss_fp: 0.001976, loss_freq: 0.084980
[13:01:31.851] iteration 6247: loss: 0.113651, loss_s1: 0.067564, loss_fp: 0.013571, loss_freq: 0.043117
[13:01:32.507] iteration 6248: loss: 0.131025, loss_s1: 0.037092, loss_fp: 0.003543, loss_freq: 0.082747
[13:01:33.167] iteration 6249: loss: 0.138283, loss_s1: 0.060383, loss_fp: 0.011546, loss_freq: 0.061665
[13:01:33.820] iteration 6250: loss: 0.148948, loss_s1: 0.036426, loss_fp: 0.006572, loss_freq: 0.050495
[13:01:34.476] iteration 6251: loss: 0.055871, loss_s1: 0.017615, loss_fp: 0.000930, loss_freq: 0.013851
[13:01:35.106] iteration 6252: loss: 0.086333, loss_s1: 0.026236, loss_fp: 0.001496, loss_freq: 0.010186
[13:01:35.727] iteration 6253: loss: 0.160343, loss_s1: 0.074595, loss_fp: 0.019155, loss_freq: 0.091998
[13:01:36.346] iteration 6254: loss: 0.221501, loss_s1: 0.066154, loss_fp: 0.001615, loss_freq: 0.117899
[13:01:36.968] iteration 6255: loss: 0.116761, loss_s1: 0.036180, loss_fp: 0.001262, loss_freq: 0.020737
[13:01:37.587] iteration 6256: loss: 0.164186, loss_s1: 0.157489, loss_fp: 0.001000, loss_freq: 0.071526
[13:01:38.213] iteration 6257: loss: 0.071083, loss_s1: 0.043543, loss_fp: 0.002340, loss_freq: 0.030655
[13:01:38.830] iteration 6258: loss: 0.105325, loss_s1: 0.027802, loss_fp: 0.000658, loss_freq: 0.004499
[13:01:39.460] iteration 6259: loss: 0.085833, loss_s1: 0.037551, loss_fp: 0.006046, loss_freq: 0.023717
[13:01:40.077] iteration 6260: loss: 0.072066, loss_s1: 0.026945, loss_fp: 0.001434, loss_freq: 0.003725
[13:01:40.725] iteration 6261: loss: 0.058960, loss_s1: 0.022503, loss_fp: 0.000867, loss_freq: 0.034900
[13:01:41.341] iteration 6262: loss: 0.108022, loss_s1: 0.053527, loss_fp: 0.000870, loss_freq: 0.028433
[13:01:41.958] iteration 6263: loss: 0.091906, loss_s1: 0.087653, loss_fp: 0.001475, loss_freq: 0.012730
[13:01:42.583] iteration 6264: loss: 0.244885, loss_s1: 0.024418, loss_fp: 0.000680, loss_freq: 0.033139
[13:01:43.212] iteration 6265: loss: 0.155802, loss_s1: 0.111619, loss_fp: 0.001092, loss_freq: 0.012367
[13:01:43.834] iteration 6266: loss: 0.148311, loss_s1: 0.033661, loss_fp: 0.012534, loss_freq: 0.096221
[13:01:44.453] iteration 6267: loss: 0.093129, loss_s1: 0.029716, loss_fp: 0.000985, loss_freq: 0.029188
[13:01:45.072] iteration 6268: loss: 0.074551, loss_s1: 0.060861, loss_fp: 0.002932, loss_freq: 0.022416
[13:01:45.690] iteration 6269: loss: 0.095428, loss_s1: 0.045179, loss_fp: 0.000935, loss_freq: 0.068623
[13:01:46.302] iteration 6270: loss: 0.116894, loss_s1: 0.035457, loss_fp: 0.002652, loss_freq: 0.077717
[13:01:46.923] iteration 6271: loss: 0.129393, loss_s1: 0.078520, loss_fp: 0.002200, loss_freq: 0.024788
[13:01:47.541] iteration 6272: loss: 0.064414, loss_s1: 0.032453, loss_fp: 0.003060, loss_freq: 0.005915
[13:01:48.153] iteration 6273: loss: 0.089004, loss_s1: 0.055920, loss_fp: 0.005087, loss_freq: 0.025556
[13:01:48.769] iteration 6274: loss: 0.127530, loss_s1: 0.109226, loss_fp: 0.007848, loss_freq: 0.039530
[13:01:49.390] iteration 6275: loss: 0.220714, loss_s1: 0.057682, loss_fp: 0.015266, loss_freq: 0.029060
[13:01:50.015] iteration 6276: loss: 0.126728, loss_s1: 0.041652, loss_fp: 0.003240, loss_freq: 0.071373
[13:01:50.636] iteration 6277: loss: 0.071571, loss_s1: 0.033911, loss_fp: 0.001741, loss_freq: 0.008607
[13:01:51.251] iteration 6278: loss: 0.165482, loss_s1: 0.099651, loss_fp: 0.006168, loss_freq: 0.070355
[13:01:51.861] iteration 6279: loss: 0.082654, loss_s1: 0.055374, loss_fp: 0.001326, loss_freq: 0.007185
[13:01:52.485] iteration 6280: loss: 0.100148, loss_s1: 0.029432, loss_fp: 0.004242, loss_freq: 0.016807
[13:01:53.099] iteration 6281: loss: 0.170912, loss_s1: 0.063003, loss_fp: 0.006966, loss_freq: 0.037785
[13:01:53.718] iteration 6282: loss: 0.083261, loss_s1: 0.010307, loss_fp: 0.007163, loss_freq: 0.022363
[13:01:54.346] iteration 6283: loss: 0.116552, loss_s1: 0.056153, loss_fp: 0.001725, loss_freq: 0.030926
[13:01:54.966] iteration 6284: loss: 0.098340, loss_s1: 0.022174, loss_fp: 0.001765, loss_freq: 0.045915
[13:01:55.583] iteration 6285: loss: 0.106474, loss_s1: 0.070405, loss_fp: 0.002533, loss_freq: 0.013840
[13:01:56.199] iteration 6286: loss: 0.107821, loss_s1: 0.097699, loss_fp: 0.003059, loss_freq: 0.026311
[13:01:56.841] iteration 6287: loss: 0.125018, loss_s1: 0.015237, loss_fp: 0.007790, loss_freq: 0.026941
[13:01:57.517] iteration 6288: loss: 0.088920, loss_s1: 0.043385, loss_fp: 0.002531, loss_freq: 0.024514
[13:01:58.177] iteration 6289: loss: 0.178518, loss_s1: 0.038020, loss_fp: 0.007168, loss_freq: 0.030559
[13:01:58.835] iteration 6290: loss: 0.107642, loss_s1: 0.070546, loss_fp: 0.001874, loss_freq: 0.024857
[13:01:59.494] iteration 6291: loss: 0.128286, loss_s1: 0.046135, loss_fp: 0.031341, loss_freq: 0.040141
[13:02:00.130] iteration 6292: loss: 0.069598, loss_s1: 0.032237, loss_fp: 0.001558, loss_freq: 0.010625
[13:02:01.038] iteration 6293: loss: 0.063169, loss_s1: 0.015811, loss_fp: 0.001630, loss_freq: 0.005168
[13:02:01.660] iteration 6294: loss: 0.091621, loss_s1: 0.045096, loss_fp: 0.001360, loss_freq: 0.015139
[13:02:02.280] iteration 6295: loss: 0.079702, loss_s1: 0.016018, loss_fp: 0.001533, loss_freq: 0.048439
[13:02:02.907] iteration 6296: loss: 0.114365, loss_s1: 0.028808, loss_fp: 0.004001, loss_freq: 0.016061
[13:02:03.533] iteration 6297: loss: 0.098807, loss_s1: 0.078100, loss_fp: 0.003673, loss_freq: 0.041313
[13:02:04.148] iteration 6298: loss: 0.089980, loss_s1: 0.030257, loss_fp: 0.000311, loss_freq: 0.004767
[13:02:04.759] iteration 6299: loss: 0.072103, loss_s1: 0.042974, loss_fp: 0.001484, loss_freq: 0.033781
[13:02:05.377] iteration 6300: loss: 0.149981, loss_s1: 0.079601, loss_fp: 0.002957, loss_freq: 0.054600
[13:02:05.996] iteration 6301: loss: 0.107833, loss_s1: 0.047950, loss_fp: 0.000770, loss_freq: 0.048864
[13:02:06.614] iteration 6302: loss: 0.145847, loss_s1: 0.027830, loss_fp: 0.001861, loss_freq: 0.019151
[13:02:07.239] iteration 6303: loss: 0.125414, loss_s1: 0.034022, loss_fp: 0.005221, loss_freq: 0.031933
[13:02:07.859] iteration 6304: loss: 0.087768, loss_s1: 0.055521, loss_fp: 0.000873, loss_freq: 0.044122
[13:02:08.473] iteration 6305: loss: 0.120152, loss_s1: 0.070118, loss_fp: 0.001920, loss_freq: 0.041657
[13:02:09.088] iteration 6306: loss: 0.121990, loss_s1: 0.061701, loss_fp: 0.000572, loss_freq: 0.074851
[13:02:09.727] iteration 6307: loss: 0.157898, loss_s1: 0.145868, loss_fp: 0.002305, loss_freq: 0.056746
[13:02:10.347] iteration 6308: loss: 0.079968, loss_s1: 0.056950, loss_fp: 0.000590, loss_freq: 0.030529
[13:02:11.047] iteration 6309: loss: 0.197621, loss_s1: 0.026910, loss_fp: 0.000480, loss_freq: 0.011987
[13:02:11.722] iteration 6310: loss: 0.146219, loss_s1: 0.101704, loss_fp: 0.008794, loss_freq: 0.027089
[13:02:12.341] iteration 6311: loss: 0.067596, loss_s1: 0.025289, loss_fp: 0.001385, loss_freq: 0.027872
[13:02:12.973] iteration 6312: loss: 0.106354, loss_s1: 0.040087, loss_fp: 0.003075, loss_freq: 0.014371
[13:02:13.588] iteration 6313: loss: 0.125260, loss_s1: 0.048307, loss_fp: 0.001261, loss_freq: 0.049295
[13:02:14.206] iteration 6314: loss: 0.059809, loss_s1: 0.024315, loss_fp: 0.001035, loss_freq: 0.018196
[13:02:14.827] iteration 6315: loss: 0.050753, loss_s1: 0.029725, loss_fp: 0.000784, loss_freq: 0.011102
[13:02:15.443] iteration 6316: loss: 0.152014, loss_s1: 0.013968, loss_fp: 0.001219, loss_freq: 0.032128
[13:02:16.064] iteration 6317: loss: 0.066648, loss_s1: 0.018773, loss_fp: 0.000915, loss_freq: 0.021918
[13:02:16.680] iteration 6318: loss: 0.117813, loss_s1: 0.045837, loss_fp: 0.005223, loss_freq: 0.043780
[13:02:17.306] iteration 6319: loss: 0.108719, loss_s1: 0.053507, loss_fp: 0.000540, loss_freq: 0.029011
[13:02:17.928] iteration 6320: loss: 0.109481, loss_s1: 0.052516, loss_fp: 0.002642, loss_freq: 0.013607
[13:02:18.552] iteration 6321: loss: 0.173470, loss_s1: 0.035264, loss_fp: 0.001515, loss_freq: 0.052170
[13:02:19.168] iteration 6322: loss: 0.115917, loss_s1: 0.039494, loss_fp: 0.004148, loss_freq: 0.012797
[13:02:19.784] iteration 6323: loss: 0.088525, loss_s1: 0.038331, loss_fp: 0.002359, loss_freq: 0.014362
[13:02:20.411] iteration 6324: loss: 0.083630, loss_s1: 0.022242, loss_fp: 0.002256, loss_freq: 0.017540
[13:02:21.037] iteration 6325: loss: 0.077193, loss_s1: 0.032931, loss_fp: 0.002516, loss_freq: 0.015562
[13:02:21.652] iteration 6326: loss: 0.083694, loss_s1: 0.035758, loss_fp: 0.006553, loss_freq: 0.052080
[13:02:22.270] iteration 6327: loss: 0.114771, loss_s1: 0.036458, loss_fp: 0.001723, loss_freq: 0.027620
[13:02:22.888] iteration 6328: loss: 0.087825, loss_s1: 0.033901, loss_fp: 0.001798, loss_freq: 0.037824
[13:02:23.507] iteration 6329: loss: 0.076151, loss_s1: 0.022956, loss_fp: 0.001766, loss_freq: 0.019812
[13:02:24.124] iteration 6330: loss: 0.075225, loss_s1: 0.048327, loss_fp: 0.004470, loss_freq: 0.016291
[13:02:24.739] iteration 6331: loss: 0.180508, loss_s1: 0.113399, loss_fp: 0.011343, loss_freq: 0.038456
[13:02:25.354] iteration 6332: loss: 0.092821, loss_s1: 0.022557, loss_fp: 0.002611, loss_freq: 0.004349
[13:02:25.978] iteration 6333: loss: 0.108323, loss_s1: 0.060537, loss_fp: 0.001579, loss_freq: 0.009936
[13:02:26.633] iteration 6334: loss: 0.057898, loss_s1: 0.029464, loss_fp: 0.000820, loss_freq: 0.035810
[13:02:27.288] iteration 6335: loss: 0.142290, loss_s1: 0.049719, loss_fp: 0.002103, loss_freq: 0.010858
[13:02:27.945] iteration 6336: loss: 0.099331, loss_s1: 0.083166, loss_fp: 0.002492, loss_freq: 0.037333
[13:02:28.603] iteration 6337: loss: 0.147323, loss_s1: 0.029321, loss_fp: 0.002334, loss_freq: 0.050665
[13:02:29.263] iteration 6338: loss: 0.138049, loss_s1: 0.093512, loss_fp: 0.000687, loss_freq: 0.043757
[13:02:29.887] iteration 6339: loss: 0.088650, loss_s1: 0.051678, loss_fp: 0.001500, loss_freq: 0.021917
[13:02:30.506] iteration 6340: loss: 0.101687, loss_s1: 0.045333, loss_fp: 0.001466, loss_freq: 0.028083
[13:02:31.133] iteration 6341: loss: 0.072752, loss_s1: 0.063105, loss_fp: 0.003285, loss_freq: 0.008869
[13:02:31.754] iteration 6342: loss: 0.131541, loss_s1: 0.064789, loss_fp: 0.004370, loss_freq: 0.061414
[13:02:32.377] iteration 6343: loss: 0.091757, loss_s1: 0.032515, loss_fp: 0.002273, loss_freq: 0.050381
[13:02:32.991] iteration 6344: loss: 0.158931, loss_s1: 0.017559, loss_fp: 0.002700, loss_freq: 0.035596
[13:02:33.607] iteration 6345: loss: 0.063211, loss_s1: 0.020520, loss_fp: 0.000552, loss_freq: 0.007603
[13:02:34.224] iteration 6346: loss: 0.084798, loss_s1: 0.051940, loss_fp: 0.000919, loss_freq: 0.012189
[13:02:34.837] iteration 6347: loss: 0.050659, loss_s1: 0.021346, loss_fp: 0.001423, loss_freq: 0.016143
[13:02:35.457] iteration 6348: loss: 0.103597, loss_s1: 0.047152, loss_fp: 0.005427, loss_freq: 0.013779
[13:02:36.072] iteration 6349: loss: 0.137675, loss_s1: 0.099573, loss_fp: 0.001630, loss_freq: 0.058382
[13:02:36.702] iteration 6350: loss: 0.103170, loss_s1: 0.017730, loss_fp: 0.006597, loss_freq: 0.094055
[13:02:37.320] iteration 6351: loss: 0.185795, loss_s1: 0.036999, loss_fp: 0.002273, loss_freq: 0.100519
[13:02:37.936] iteration 6352: loss: 0.077139, loss_s1: 0.018251, loss_fp: 0.003357, loss_freq: 0.027621
[13:02:38.559] iteration 6353: loss: 0.143455, loss_s1: 0.082790, loss_fp: 0.003475, loss_freq: 0.050271
[13:02:39.221] iteration 6354: loss: 0.136028, loss_s1: 0.068108, loss_fp: 0.004439, loss_freq: 0.035883
[13:02:39.837] iteration 6355: loss: 0.089707, loss_s1: 0.070528, loss_fp: 0.003640, loss_freq: 0.011560
[13:02:40.472] iteration 6356: loss: 0.105854, loss_s1: 0.015211, loss_fp: 0.003119, loss_freq: 0.051557
[13:02:41.144] iteration 6357: loss: 0.111482, loss_s1: 0.033961, loss_fp: 0.001682, loss_freq: 0.016477
[13:02:41.770] iteration 6358: loss: 0.102282, loss_s1: 0.013180, loss_fp: 0.001270, loss_freq: 0.013589
[13:02:42.401] iteration 6359: loss: 0.096099, loss_s1: 0.054847, loss_fp: 0.000861, loss_freq: 0.048179
[13:02:43.030] iteration 6360: loss: 0.104992, loss_s1: 0.008402, loss_fp: 0.000560, loss_freq: 0.044918
[13:02:43.657] iteration 6361: loss: 0.100337, loss_s1: 0.070729, loss_fp: 0.002911, loss_freq: 0.013960
[13:02:44.287] iteration 6362: loss: 0.148852, loss_s1: 0.040836, loss_fp: 0.001235, loss_freq: 0.039400
[13:02:44.910] iteration 6363: loss: 0.087519, loss_s1: 0.035345, loss_fp: 0.001804, loss_freq: 0.020651
[13:02:45.533] iteration 6364: loss: 0.086654, loss_s1: 0.067055, loss_fp: 0.002811, loss_freq: 0.022160
[13:02:46.156] iteration 6365: loss: 0.087220, loss_s1: 0.011577, loss_fp: 0.001169, loss_freq: 0.070389
[13:02:46.780] iteration 6366: loss: 0.151315, loss_s1: 0.101947, loss_fp: 0.007370, loss_freq: 0.048128
[13:02:47.407] iteration 6367: loss: 0.137895, loss_s1: 0.055624, loss_fp: 0.001119, loss_freq: 0.083016
[13:02:48.033] iteration 6368: loss: 0.107732, loss_s1: 0.029112, loss_fp: 0.003219, loss_freq: 0.022364
[13:02:48.655] iteration 6369: loss: 0.109382, loss_s1: 0.060963, loss_fp: 0.001564, loss_freq: 0.062743
[13:02:49.285] iteration 6370: loss: 0.093338, loss_s1: 0.031492, loss_fp: 0.003623, loss_freq: 0.018711
[13:02:49.908] iteration 6371: loss: 0.123963, loss_s1: 0.077531, loss_fp: 0.013145, loss_freq: 0.059730
[13:02:50.537] iteration 6372: loss: 0.209223, loss_s1: 0.100429, loss_fp: 0.004088, loss_freq: 0.040383
[13:02:51.188] iteration 6373: loss: 0.097093, loss_s1: 0.020526, loss_fp: 0.001215, loss_freq: 0.031056
[13:02:51.844] iteration 6374: loss: 0.095530, loss_s1: 0.040938, loss_fp: 0.003009, loss_freq: 0.041645
[13:02:52.520] iteration 6375: loss: 0.070211, loss_s1: 0.011446, loss_fp: 0.006118, loss_freq: 0.018465
[13:02:53.171] iteration 6376: loss: 0.076191, loss_s1: 0.054462, loss_fp: 0.002412, loss_freq: 0.020022
[13:02:53.799] iteration 6377: loss: 0.114346, loss_s1: 0.076156, loss_fp: 0.000966, loss_freq: 0.018606
[13:02:54.453] iteration 6378: loss: 0.088751, loss_s1: 0.029961, loss_fp: 0.002757, loss_freq: 0.056126
[13:02:55.110] iteration 6379: loss: 0.118480, loss_s1: 0.048995, loss_fp: 0.000750, loss_freq: 0.013173
[13:02:55.771] iteration 6380: loss: 0.117244, loss_s1: 0.026179, loss_fp: 0.000772, loss_freq: 0.030716
[13:02:56.397] iteration 6381: loss: 0.118349, loss_s1: 0.136373, loss_fp: 0.000620, loss_freq: 0.027144
[13:02:57.018] iteration 6382: loss: 0.085799, loss_s1: 0.067526, loss_fp: 0.001513, loss_freq: 0.025478
[13:02:57.646] iteration 6383: loss: 0.104600, loss_s1: 0.014694, loss_fp: 0.001385, loss_freq: 0.008014
[13:02:58.272] iteration 6384: loss: 0.112239, loss_s1: 0.086327, loss_fp: 0.002005, loss_freq: 0.052347
[13:02:58.899] iteration 6385: loss: 0.075099, loss_s1: 0.033447, loss_fp: 0.000662, loss_freq: 0.030910
[13:02:59.523] iteration 6386: loss: 0.130703, loss_s1: 0.065233, loss_fp: 0.002962, loss_freq: 0.019094
[13:03:00.182] iteration 6387: loss: 0.073485, loss_s1: 0.035793, loss_fp: 0.000530, loss_freq: 0.010468
[13:03:00.843] iteration 6388: loss: 0.126370, loss_s1: 0.065045, loss_fp: 0.009298, loss_freq: 0.049224
[13:03:01.495] iteration 6389: loss: 0.168068, loss_s1: 0.108261, loss_fp: 0.006498, loss_freq: 0.121383
[13:03:02.118] iteration 6390: loss: 0.096976, loss_s1: 0.048055, loss_fp: 0.002149, loss_freq: 0.046978
[13:03:02.735] iteration 6391: loss: 0.136628, loss_s1: 0.033784, loss_fp: 0.002914, loss_freq: 0.068037
[13:03:03.360] iteration 6392: loss: 0.126183, loss_s1: 0.050170, loss_fp: 0.003653, loss_freq: 0.036036
[13:03:03.996] iteration 6393: loss: 0.170943, loss_s1: 0.073750, loss_fp: 0.001777, loss_freq: 0.061610
[13:03:04.653] iteration 6394: loss: 0.080990, loss_s1: 0.050366, loss_fp: 0.001481, loss_freq: 0.009674
[13:03:05.288] iteration 6395: loss: 0.096342, loss_s1: 0.046800, loss_fp: 0.000815, loss_freq: 0.008233
[13:03:05.908] iteration 6396: loss: 0.124869, loss_s1: 0.080006, loss_fp: 0.007658, loss_freq: 0.060802
[13:03:06.525] iteration 6397: loss: 0.176120, loss_s1: 0.054754, loss_fp: 0.001609, loss_freq: 0.043193
[13:03:07.146] iteration 6398: loss: 0.081132, loss_s1: 0.050745, loss_fp: 0.002223, loss_freq: 0.022618
[13:03:07.764] iteration 6399: loss: 0.145774, loss_s1: 0.139201, loss_fp: 0.001180, loss_freq: 0.069836
[13:03:08.393] iteration 6400: loss: 0.081098, loss_s1: 0.036822, loss_fp: 0.003022, loss_freq: 0.038107
[13:03:11.744] iteration 6400 : mean_dice : 0.725114
[13:03:12.428] iteration 6401: loss: 0.120223, loss_s1: 0.037020, loss_fp: 0.001267, loss_freq: 0.007005
[13:03:13.086] iteration 6402: loss: 0.091784, loss_s1: 0.023941, loss_fp: 0.001944, loss_freq: 0.035671
[13:03:13.754] iteration 6403: loss: 0.083405, loss_s1: 0.015663, loss_fp: 0.001836, loss_freq: 0.012658
[13:03:14.407] iteration 6404: loss: 0.064177, loss_s1: 0.023337, loss_fp: 0.000684, loss_freq: 0.048649
[13:03:15.066] iteration 6405: loss: 0.101141, loss_s1: 0.032780, loss_fp: 0.001359, loss_freq: 0.027842
[13:03:15.687] iteration 6406: loss: 0.068290, loss_s1: 0.048203, loss_fp: 0.000775, loss_freq: 0.016375
[13:03:16.307] iteration 6407: loss: 0.208376, loss_s1: 0.036055, loss_fp: 0.001754, loss_freq: 0.033769
[13:03:16.933] iteration 6408: loss: 0.127677, loss_s1: 0.086397, loss_fp: 0.004083, loss_freq: 0.012022
[13:03:17.545] iteration 6409: loss: 0.092328, loss_s1: 0.046674, loss_fp: 0.000663, loss_freq: 0.046954
[13:03:18.162] iteration 6410: loss: 0.085049, loss_s1: 0.047707, loss_fp: 0.003391, loss_freq: 0.041013
[13:03:18.820] iteration 6411: loss: 0.065140, loss_s1: 0.034457, loss_fp: 0.011653, loss_freq: 0.016619
[13:03:19.470] iteration 6412: loss: 0.098975, loss_s1: 0.059276, loss_fp: 0.000944, loss_freq: 0.056731
[13:03:20.128] iteration 6413: loss: 0.145166, loss_s1: 0.092983, loss_fp: 0.002570, loss_freq: 0.103518
[13:03:20.783] iteration 6414: loss: 0.151245, loss_s1: 0.046389, loss_fp: 0.002705, loss_freq: 0.017250
[13:03:21.400] iteration 6415: loss: 0.090532, loss_s1: 0.024357, loss_fp: 0.000491, loss_freq: 0.003671
[13:03:22.028] iteration 6416: loss: 0.120089, loss_s1: 0.079815, loss_fp: 0.001852, loss_freq: 0.067684
[13:03:22.653] iteration 6417: loss: 0.109336, loss_s1: 0.072833, loss_fp: 0.001374, loss_freq: 0.020262
[13:03:23.267] iteration 6418: loss: 0.137365, loss_s1: 0.057691, loss_fp: 0.001682, loss_freq: 0.020250
[13:03:23.880] iteration 6419: loss: 0.098007, loss_s1: 0.040680, loss_fp: 0.000867, loss_freq: 0.052091
[13:03:24.503] iteration 6420: loss: 0.081066, loss_s1: 0.035624, loss_fp: 0.002143, loss_freq: 0.032790
[13:03:25.158] iteration 6421: loss: 0.117557, loss_s1: 0.067533, loss_fp: 0.003864, loss_freq: 0.014370
[13:03:25.809] iteration 6422: loss: 0.058346, loss_s1: 0.015823, loss_fp: 0.002171, loss_freq: 0.018857
[13:03:26.471] iteration 6423: loss: 0.093982, loss_s1: 0.027541, loss_fp: 0.001921, loss_freq: 0.007373
[13:03:27.118] iteration 6424: loss: 0.133468, loss_s1: 0.058361, loss_fp: 0.003001, loss_freq: 0.025711
[13:03:27.738] iteration 6425: loss: 0.122580, loss_s1: 0.060282, loss_fp: 0.000613, loss_freq: 0.025335
[13:03:28.352] iteration 6426: loss: 0.135998, loss_s1: 0.049105, loss_fp: 0.003148, loss_freq: 0.058388
[13:03:28.995] iteration 6427: loss: 0.096028, loss_s1: 0.019533, loss_fp: 0.000990, loss_freq: 0.022588
[13:03:29.658] iteration 6428: loss: 0.119659, loss_s1: 0.065642, loss_fp: 0.002668, loss_freq: 0.028273
[13:03:30.307] iteration 6429: loss: 0.097304, loss_s1: 0.071963, loss_fp: 0.015823, loss_freq: 0.008693
[13:03:30.960] iteration 6430: loss: 0.133529, loss_s1: 0.033142, loss_fp: 0.004478, loss_freq: 0.021981
[13:03:31.609] iteration 6431: loss: 0.079289, loss_s1: 0.030362, loss_fp: 0.001186, loss_freq: 0.017358
[13:03:32.255] iteration 6432: loss: 0.130434, loss_s1: 0.064061, loss_fp: 0.002073, loss_freq: 0.008492
[13:03:32.914] iteration 6433: loss: 0.130705, loss_s1: 0.049650, loss_fp: 0.003475, loss_freq: 0.060513
[13:03:33.573] iteration 6434: loss: 0.133106, loss_s1: 0.044191, loss_fp: 0.001499, loss_freq: 0.105802
[13:03:34.212] iteration 6435: loss: 0.072571, loss_s1: 0.029498, loss_fp: 0.001760, loss_freq: 0.021025
[13:03:35.151] iteration 6436: loss: 0.131320, loss_s1: 0.058138, loss_fp: 0.014206, loss_freq: 0.022002
[13:03:35.770] iteration 6437: loss: 0.094743, loss_s1: 0.069321, loss_fp: 0.000736, loss_freq: 0.019945
[13:03:36.404] iteration 6438: loss: 0.110193, loss_s1: 0.098998, loss_fp: 0.001330, loss_freq: 0.038157
[13:03:37.024] iteration 6439: loss: 0.143703, loss_s1: 0.080557, loss_fp: 0.004488, loss_freq: 0.034661
[13:03:37.644] iteration 6440: loss: 0.103523, loss_s1: 0.070047, loss_fp: 0.001213, loss_freq: 0.068443
[13:03:38.267] iteration 6441: loss: 0.107457, loss_s1: 0.025960, loss_fp: 0.003064, loss_freq: 0.003529
[13:03:38.895] iteration 6442: loss: 0.072346, loss_s1: 0.019139, loss_fp: 0.001337, loss_freq: 0.065769
[13:03:39.521] iteration 6443: loss: 0.115921, loss_s1: 0.032365, loss_fp: 0.003302, loss_freq: 0.046243
[13:03:40.135] iteration 6444: loss: 0.074153, loss_s1: 0.032329, loss_fp: 0.002245, loss_freq: 0.008175
[13:03:40.761] iteration 6445: loss: 0.157252, loss_s1: 0.028086, loss_fp: 0.001451, loss_freq: 0.017850
[13:03:41.388] iteration 6446: loss: 0.118722, loss_s1: 0.047694, loss_fp: 0.005047, loss_freq: 0.043950
[13:03:42.006] iteration 6447: loss: 0.102876, loss_s1: 0.046569, loss_fp: 0.000806, loss_freq: 0.046190
[13:03:42.631] iteration 6448: loss: 0.117866, loss_s1: 0.102143, loss_fp: 0.002937, loss_freq: 0.010510
[13:03:43.258] iteration 6449: loss: 0.073765, loss_s1: 0.042199, loss_fp: 0.002935, loss_freq: 0.033804
[13:03:43.874] iteration 6450: loss: 0.083405, loss_s1: 0.067197, loss_fp: 0.002318, loss_freq: 0.012382
[13:03:44.489] iteration 6451: loss: 0.091838, loss_s1: 0.042249, loss_fp: 0.001053, loss_freq: 0.032827
[13:03:45.100] iteration 6452: loss: 0.130568, loss_s1: 0.017108, loss_fp: 0.002234, loss_freq: 0.047709
[13:03:45.725] iteration 6453: loss: 0.111818, loss_s1: 0.029401, loss_fp: 0.008778, loss_freq: 0.011080
[13:03:46.345] iteration 6454: loss: 0.060934, loss_s1: 0.029564, loss_fp: 0.000894, loss_freq: 0.011746
[13:03:46.964] iteration 6455: loss: 0.110037, loss_s1: 0.113151, loss_fp: 0.001916, loss_freq: 0.017550
[13:03:47.588] iteration 6456: loss: 0.199831, loss_s1: 0.064461, loss_fp: 0.001402, loss_freq: 0.083595
[13:03:48.212] iteration 6457: loss: 0.098695, loss_s1: 0.079574, loss_fp: 0.000535, loss_freq: 0.026734
[13:03:48.833] iteration 6458: loss: 0.109402, loss_s1: 0.054089, loss_fp: 0.003771, loss_freq: 0.073049
[13:03:49.456] iteration 6459: loss: 0.096593, loss_s1: 0.021214, loss_fp: 0.000862, loss_freq: 0.012927
[13:03:50.088] iteration 6460: loss: 0.079393, loss_s1: 0.030948, loss_fp: 0.008841, loss_freq: 0.017681
[13:03:50.718] iteration 6461: loss: 0.162955, loss_s1: 0.115440, loss_fp: 0.021836, loss_freq: 0.065264
[13:03:51.340] iteration 6462: loss: 0.093729, loss_s1: 0.016796, loss_fp: 0.002255, loss_freq: 0.046203
[13:03:52.037] iteration 6463: loss: 0.067091, loss_s1: 0.024327, loss_fp: 0.001349, loss_freq: 0.009847
[13:03:52.730] iteration 6464: loss: 0.130936, loss_s1: 0.015918, loss_fp: 0.001778, loss_freq: 0.036761
[13:03:53.395] iteration 6465: loss: 0.165340, loss_s1: 0.047008, loss_fp: 0.002529, loss_freq: 0.016624
[13:03:54.066] iteration 6466: loss: 0.080589, loss_s1: 0.021802, loss_fp: 0.005493, loss_freq: 0.011377
[13:03:54.731] iteration 6467: loss: 0.068329, loss_s1: 0.042518, loss_fp: 0.001469, loss_freq: 0.013184
[13:03:55.394] iteration 6468: loss: 0.112413, loss_s1: 0.079250, loss_fp: 0.000680, loss_freq: 0.024213
[13:03:56.033] iteration 6469: loss: 0.128601, loss_s1: 0.083039, loss_fp: 0.042048, loss_freq: 0.048944
[13:03:56.660] iteration 6470: loss: 0.123379, loss_s1: 0.060434, loss_fp: 0.003050, loss_freq: 0.031840
[13:03:57.287] iteration 6471: loss: 0.095944, loss_s1: 0.030842, loss_fp: 0.004271, loss_freq: 0.028453
[13:03:57.916] iteration 6472: loss: 0.124502, loss_s1: 0.059862, loss_fp: 0.001435, loss_freq: 0.087525
[13:03:58.547] iteration 6473: loss: 0.069901, loss_s1: 0.043727, loss_fp: 0.001028, loss_freq: 0.017175
[13:03:59.198] iteration 6474: loss: 0.115343, loss_s1: 0.069949, loss_fp: 0.004201, loss_freq: 0.034150
[13:03:59.871] iteration 6475: loss: 0.102836, loss_s1: 0.039196, loss_fp: 0.001288, loss_freq: 0.009432
[13:04:00.537] iteration 6476: loss: 0.107631, loss_s1: 0.030545, loss_fp: 0.003082, loss_freq: 0.018485
[13:04:01.224] iteration 6477: loss: 0.069676, loss_s1: 0.024782, loss_fp: 0.001638, loss_freq: 0.024209
[13:04:01.889] iteration 6478: loss: 0.126639, loss_s1: 0.089451, loss_fp: 0.003180, loss_freq: 0.041476
[13:04:02.546] iteration 6479: loss: 0.084422, loss_s1: 0.030631, loss_fp: 0.011409, loss_freq: 0.052158
[13:04:03.172] iteration 6480: loss: 0.197860, loss_s1: 0.038649, loss_fp: 0.002030, loss_freq: 0.067379
[13:04:03.805] iteration 6481: loss: 0.103346, loss_s1: 0.086919, loss_fp: 0.016908, loss_freq: 0.025222
[13:04:04.425] iteration 6482: loss: 0.126358, loss_s1: 0.081100, loss_fp: 0.001624, loss_freq: 0.033449
[13:04:05.045] iteration 6483: loss: 0.096211, loss_s1: 0.028976, loss_fp: 0.001510, loss_freq: 0.045541
[13:04:05.666] iteration 6484: loss: 0.105817, loss_s1: 0.091670, loss_fp: 0.001233, loss_freq: 0.042101
[13:04:06.304] iteration 6485: loss: 0.166758, loss_s1: 0.090482, loss_fp: 0.003342, loss_freq: 0.076242
[13:04:06.938] iteration 6486: loss: 0.091104, loss_s1: 0.044832, loss_fp: 0.009092, loss_freq: 0.022686
[13:04:07.577] iteration 6487: loss: 0.173056, loss_s1: 0.013834, loss_fp: 0.000854, loss_freq: 0.072544
[13:04:08.207] iteration 6488: loss: 0.080179, loss_s1: 0.048322, loss_fp: 0.001323, loss_freq: 0.003163
[13:04:08.835] iteration 6489: loss: 0.115734, loss_s1: 0.037769, loss_fp: 0.000625, loss_freq: 0.008380
[13:04:09.463] iteration 6490: loss: 0.074927, loss_s1: 0.065456, loss_fp: 0.001077, loss_freq: 0.012599
[13:04:10.092] iteration 6491: loss: 0.170978, loss_s1: 0.103903, loss_fp: 0.001565, loss_freq: 0.018562
[13:04:10.773] iteration 6492: loss: 0.103659, loss_s1: 0.069517, loss_fp: 0.006769, loss_freq: 0.036216
[13:04:11.414] iteration 6493: loss: 0.100251, loss_s1: 0.050201, loss_fp: 0.001543, loss_freq: 0.016609
[13:04:12.057] iteration 6494: loss: 0.153650, loss_s1: 0.064382, loss_fp: 0.006253, loss_freq: 0.045606
[13:04:12.720] iteration 6495: loss: 0.078150, loss_s1: 0.046485, loss_fp: 0.002255, loss_freq: 0.034355
[13:04:13.421] iteration 6496: loss: 0.098440, loss_s1: 0.022791, loss_fp: 0.003114, loss_freq: 0.032675
[13:04:14.128] iteration 6497: loss: 0.126163, loss_s1: 0.053333, loss_fp: 0.011265, loss_freq: 0.031836
[13:04:14.800] iteration 6498: loss: 0.112897, loss_s1: 0.089810, loss_fp: 0.002386, loss_freq: 0.025287
[13:04:15.446] iteration 6499: loss: 0.167443, loss_s1: 0.048741, loss_fp: 0.000671, loss_freq: 0.031497
[13:04:16.075] iteration 6500: loss: 0.107988, loss_s1: 0.042252, loss_fp: 0.003279, loss_freq: 0.021136
[13:04:16.714] iteration 6501: loss: 0.137931, loss_s1: 0.037233, loss_fp: 0.001641, loss_freq: 0.016607
[13:04:17.369] iteration 6502: loss: 0.122370, loss_s1: 0.042215, loss_fp: 0.001110, loss_freq: 0.068139
[13:04:18.034] iteration 6503: loss: 0.100065, loss_s1: 0.042403, loss_fp: 0.001586, loss_freq: 0.018810
[13:04:18.755] iteration 6504: loss: 0.081137, loss_s1: 0.055804, loss_fp: 0.000888, loss_freq: 0.016112
[13:04:19.460] iteration 6505: loss: 0.153387, loss_s1: 0.084087, loss_fp: 0.001397, loss_freq: 0.027411
[13:04:20.122] iteration 6506: loss: 0.095716, loss_s1: 0.031388, loss_fp: 0.002718, loss_freq: 0.011723
[13:04:20.850] iteration 6507: loss: 0.078011, loss_s1: 0.018302, loss_fp: 0.005144, loss_freq: 0.016746
[13:04:21.526] iteration 6508: loss: 0.075000, loss_s1: 0.024061, loss_fp: 0.007458, loss_freq: 0.026503
[13:04:22.219] iteration 6509: loss: 0.108141, loss_s1: 0.034982, loss_fp: 0.000952, loss_freq: 0.048788
[13:04:22.922] iteration 6510: loss: 0.103612, loss_s1: 0.059854, loss_fp: 0.002649, loss_freq: 0.050962
[13:04:23.678] iteration 6511: loss: 0.108303, loss_s1: 0.047296, loss_fp: 0.001104, loss_freq: 0.016951
[13:04:24.360] iteration 6512: loss: 0.086495, loss_s1: 0.090150, loss_fp: 0.001820, loss_freq: 0.025297
[13:04:25.078] iteration 6513: loss: 0.105578, loss_s1: 0.065836, loss_fp: 0.001073, loss_freq: 0.005865
[13:04:25.719] iteration 6514: loss: 0.108395, loss_s1: 0.067085, loss_fp: 0.003077, loss_freq: 0.072374
[13:04:26.430] iteration 6515: loss: 0.292681, loss_s1: 0.120899, loss_fp: 0.002919, loss_freq: 0.036816
[13:04:27.173] iteration 6516: loss: 0.109405, loss_s1: 0.085914, loss_fp: 0.002085, loss_freq: 0.044840
[13:04:27.980] iteration 6517: loss: 0.101661, loss_s1: 0.087245, loss_fp: 0.001238, loss_freq: 0.031075
[13:04:28.691] iteration 6518: loss: 0.138355, loss_s1: 0.065573, loss_fp: 0.000380, loss_freq: 0.002706
[13:04:29.393] iteration 6519: loss: 0.072722, loss_s1: 0.046656, loss_fp: 0.003456, loss_freq: 0.026790
[13:04:30.062] iteration 6520: loss: 0.107445, loss_s1: 0.041721, loss_fp: 0.000821, loss_freq: 0.026788
[13:04:30.767] iteration 6521: loss: 0.086307, loss_s1: 0.049655, loss_fp: 0.001026, loss_freq: 0.038004
[13:04:31.406] iteration 6522: loss: 0.113953, loss_s1: 0.036803, loss_fp: 0.000418, loss_freq: 0.011173
[13:04:32.133] iteration 6523: loss: 0.126026, loss_s1: 0.022206, loss_fp: 0.003243, loss_freq: 0.025915
[13:04:32.886] iteration 6524: loss: 0.084982, loss_s1: 0.050455, loss_fp: 0.002561, loss_freq: 0.007572
[13:04:33.624] iteration 6525: loss: 0.099905, loss_s1: 0.060952, loss_fp: 0.001584, loss_freq: 0.017687
[13:04:34.373] iteration 6526: loss: 0.148489, loss_s1: 0.024088, loss_fp: 0.001246, loss_freq: 0.020426
[13:04:35.087] iteration 6527: loss: 0.104962, loss_s1: 0.042886, loss_fp: 0.004141, loss_freq: 0.060673
[13:04:35.787] iteration 6528: loss: 0.079147, loss_s1: 0.083346, loss_fp: 0.000979, loss_freq: 0.007172
[13:04:36.482] iteration 6529: loss: 0.122054, loss_s1: 0.022211, loss_fp: 0.002370, loss_freq: 0.032304
[13:04:37.165] iteration 6530: loss: 0.051920, loss_s1: 0.015434, loss_fp: 0.001663, loss_freq: 0.011277
[13:04:37.827] iteration 6531: loss: 0.113130, loss_s1: 0.049961, loss_fp: 0.001168, loss_freq: 0.013118
[13:04:38.465] iteration 6532: loss: 0.153567, loss_s1: 0.101772, loss_fp: 0.004272, loss_freq: 0.105247
[13:04:39.161] iteration 6533: loss: 0.110874, loss_s1: 0.067783, loss_fp: 0.001153, loss_freq: 0.020280
[13:04:39.813] iteration 6534: loss: 0.155427, loss_s1: 0.078212, loss_fp: 0.002609, loss_freq: 0.066386
[13:04:40.483] iteration 6535: loss: 0.110575, loss_s1: 0.050467, loss_fp: 0.001565, loss_freq: 0.025527
[13:04:41.129] iteration 6536: loss: 0.109293, loss_s1: 0.048335, loss_fp: 0.001119, loss_freq: 0.046957
[13:04:41.788] iteration 6537: loss: 0.090931, loss_s1: 0.046023, loss_fp: 0.007323, loss_freq: 0.008942
[13:04:42.423] iteration 6538: loss: 0.127250, loss_s1: 0.042762, loss_fp: 0.010596, loss_freq: 0.009877
[13:04:43.075] iteration 6539: loss: 0.140874, loss_s1: 0.076255, loss_fp: 0.002780, loss_freq: 0.070227
[13:04:43.718] iteration 6540: loss: 0.193365, loss_s1: 0.048359, loss_fp: 0.002177, loss_freq: 0.091529
[13:04:44.364] iteration 6541: loss: 0.089312, loss_s1: 0.038822, loss_fp: 0.001881, loss_freq: 0.024448
[13:04:45.014] iteration 6542: loss: 0.198138, loss_s1: 0.178777, loss_fp: 0.011376, loss_freq: 0.116940
[13:04:45.661] iteration 6543: loss: 0.093643, loss_s1: 0.067761, loss_fp: 0.000871, loss_freq: 0.040141
[13:04:46.311] iteration 6544: loss: 0.111435, loss_s1: 0.051006, loss_fp: 0.004265, loss_freq: 0.004854
[13:04:46.968] iteration 6545: loss: 0.143886, loss_s1: 0.112725, loss_fp: 0.003514, loss_freq: 0.097302
[13:04:47.601] iteration 6546: loss: 0.085075, loss_s1: 0.036501, loss_fp: 0.000836, loss_freq: 0.005538
[13:04:48.251] iteration 6547: loss: 0.091658, loss_s1: 0.082479, loss_fp: 0.000256, loss_freq: 0.043000
[13:04:48.876] iteration 6548: loss: 0.100831, loss_s1: 0.048316, loss_fp: 0.000797, loss_freq: 0.017567
[13:04:49.499] iteration 6549: loss: 0.074949, loss_s1: 0.029381, loss_fp: 0.002439, loss_freq: 0.026094
[13:04:50.122] iteration 6550: loss: 0.192201, loss_s1: 0.031560, loss_fp: 0.001835, loss_freq: 0.020224
[13:04:50.747] iteration 6551: loss: 0.134227, loss_s1: 0.099699, loss_fp: 0.001239, loss_freq: 0.011833
[13:04:51.371] iteration 6552: loss: 0.130480, loss_s1: 0.097733, loss_fp: 0.004469, loss_freq: 0.065679
[13:04:52.015] iteration 6553: loss: 0.101510, loss_s1: 0.042073, loss_fp: 0.001591, loss_freq: 0.034796
[13:04:52.663] iteration 6554: loss: 0.075017, loss_s1: 0.049930, loss_fp: 0.004169, loss_freq: 0.022309
[13:04:53.327] iteration 6555: loss: 0.097259, loss_s1: 0.085886, loss_fp: 0.009980, loss_freq: 0.021237
[13:04:53.964] iteration 6556: loss: 0.107398, loss_s1: 0.042998, loss_fp: 0.001846, loss_freq: 0.062179
[13:04:54.602] iteration 6557: loss: 0.098105, loss_s1: 0.050809, loss_fp: 0.002252, loss_freq: 0.011567
[13:04:55.240] iteration 6558: loss: 0.090141, loss_s1: 0.035680, loss_fp: 0.001087, loss_freq: 0.011820
[13:04:55.866] iteration 6559: loss: 0.074937, loss_s1: 0.022497, loss_fp: 0.003929, loss_freq: 0.041164
[13:04:56.496] iteration 6560: loss: 0.099608, loss_s1: 0.044938, loss_fp: 0.003352, loss_freq: 0.032270
[13:04:57.143] iteration 6561: loss: 0.098855, loss_s1: 0.027072, loss_fp: 0.000502, loss_freq: 0.042907
[13:04:57.778] iteration 6562: loss: 0.069218, loss_s1: 0.013889, loss_fp: 0.003151, loss_freq: 0.021286
[13:04:58.418] iteration 6563: loss: 0.063140, loss_s1: 0.048456, loss_fp: 0.003320, loss_freq: 0.009903
[13:04:59.049] iteration 6564: loss: 0.157002, loss_s1: 0.107343, loss_fp: 0.001024, loss_freq: 0.023316
[13:04:59.667] iteration 6565: loss: 0.082418, loss_s1: 0.042747, loss_fp: 0.001431, loss_freq: 0.026846
[13:05:00.297] iteration 6566: loss: 0.092791, loss_s1: 0.052114, loss_fp: 0.001130, loss_freq: 0.006955
[13:05:00.921] iteration 6567: loss: 0.217261, loss_s1: 0.130707, loss_fp: 0.005397, loss_freq: 0.053237
[13:05:01.542] iteration 6568: loss: 0.092785, loss_s1: 0.065116, loss_fp: 0.002755, loss_freq: 0.016964
[13:05:02.163] iteration 6569: loss: 0.111521, loss_s1: 0.034154, loss_fp: 0.006880, loss_freq: 0.053126
[13:05:02.784] iteration 6570: loss: 0.122012, loss_s1: 0.029805, loss_fp: 0.006085, loss_freq: 0.044077
[13:05:03.406] iteration 6571: loss: 0.088018, loss_s1: 0.013533, loss_fp: 0.002790, loss_freq: 0.015560
[13:05:04.034] iteration 6572: loss: 0.093995, loss_s1: 0.059207, loss_fp: 0.003949, loss_freq: 0.013283
[13:05:04.654] iteration 6573: loss: 0.087742, loss_s1: 0.029842, loss_fp: 0.002893, loss_freq: 0.014094
[13:05:05.273] iteration 6574: loss: 0.082347, loss_s1: 0.026253, loss_fp: 0.002685, loss_freq: 0.022501
[13:05:05.898] iteration 6575: loss: 0.135216, loss_s1: 0.033480, loss_fp: 0.001624, loss_freq: 0.012747
[13:05:06.532] iteration 6576: loss: 0.105887, loss_s1: 0.090693, loss_fp: 0.002488, loss_freq: 0.018897
[13:05:07.143] iteration 6577: loss: 0.081569, loss_s1: 0.040034, loss_fp: 0.007439, loss_freq: 0.032692
[13:05:07.745] iteration 6578: loss: 0.078647, loss_s1: 0.019289, loss_fp: 0.001692, loss_freq: 0.046529
[13:05:08.773] iteration 6579: loss: 0.055428, loss_s1: 0.018075, loss_fp: 0.000623, loss_freq: 0.006266
[13:05:09.431] iteration 6580: loss: 0.079369, loss_s1: 0.041653, loss_fp: 0.003947, loss_freq: 0.011556
[13:05:10.095] iteration 6581: loss: 0.065738, loss_s1: 0.021339, loss_fp: 0.005030, loss_freq: 0.033453
[13:05:10.717] iteration 6582: loss: 0.083193, loss_s1: 0.041639, loss_fp: 0.001064, loss_freq: 0.013580
[13:05:11.336] iteration 6583: loss: 0.103581, loss_s1: 0.082433, loss_fp: 0.001752, loss_freq: 0.040546
[13:05:11.962] iteration 6584: loss: 0.102598, loss_s1: 0.025068, loss_fp: 0.001534, loss_freq: 0.008411
[13:05:12.589] iteration 6585: loss: 0.084444, loss_s1: 0.071388, loss_fp: 0.002205, loss_freq: 0.040348
[13:05:13.205] iteration 6586: loss: 0.151626, loss_s1: 0.091242, loss_fp: 0.005495, loss_freq: 0.030664
[13:05:13.823] iteration 6587: loss: 0.079775, loss_s1: 0.034897, loss_fp: 0.003793, loss_freq: 0.024824
[13:05:14.441] iteration 6588: loss: 0.151721, loss_s1: 0.030392, loss_fp: 0.001889, loss_freq: 0.043063
[13:05:15.094] iteration 6589: loss: 0.088724, loss_s1: 0.057306, loss_fp: 0.003747, loss_freq: 0.035148
[13:05:15.744] iteration 6590: loss: 0.071042, loss_s1: 0.040558, loss_fp: 0.000767, loss_freq: 0.023551
[13:05:16.369] iteration 6591: loss: 0.098965, loss_s1: 0.041046, loss_fp: 0.005350, loss_freq: 0.014559
[13:05:17.020] iteration 6592: loss: 0.061690, loss_s1: 0.031821, loss_fp: 0.003180, loss_freq: 0.006771
[13:05:17.678] iteration 6593: loss: 0.130977, loss_s1: 0.070044, loss_fp: 0.003585, loss_freq: 0.072560
[13:05:18.291] iteration 6594: loss: 0.088223, loss_s1: 0.053238, loss_fp: 0.002905, loss_freq: 0.040958
[13:05:18.902] iteration 6595: loss: 0.175410, loss_s1: 0.027065, loss_fp: 0.001384, loss_freq: 0.013314
[13:05:19.514] iteration 6596: loss: 0.110236, loss_s1: 0.029078, loss_fp: 0.000825, loss_freq: 0.007891
[13:05:20.140] iteration 6597: loss: 0.072904, loss_s1: 0.055265, loss_fp: 0.000400, loss_freq: 0.019999
[13:05:20.748] iteration 6598: loss: 0.051381, loss_s1: 0.015009, loss_fp: 0.000731, loss_freq: 0.008521
[13:05:21.355] iteration 6599: loss: 0.226476, loss_s1: 0.029675, loss_fp: 0.004591, loss_freq: 0.097028
[13:05:21.966] iteration 6600: loss: 0.127582, loss_s1: 0.087402, loss_fp: 0.001464, loss_freq: 0.023094
[13:05:25.055] iteration 6600 : mean_dice : 0.729104
[13:05:25.682] iteration 6601: loss: 0.118410, loss_s1: 0.117758, loss_fp: 0.001601, loss_freq: 0.025207
[13:05:26.291] iteration 6602: loss: 0.133015, loss_s1: 0.030378, loss_fp: 0.003493, loss_freq: 0.014356
[13:05:26.897] iteration 6603: loss: 0.067008, loss_s1: 0.021544, loss_fp: 0.002725, loss_freq: 0.025315
[13:05:27.506] iteration 6604: loss: 0.111687, loss_s1: 0.022908, loss_fp: 0.004132, loss_freq: 0.036788
[13:05:28.121] iteration 6605: loss: 0.087214, loss_s1: 0.024745, loss_fp: 0.000636, loss_freq: 0.046149
[13:05:28.743] iteration 6606: loss: 0.086840, loss_s1: 0.036113, loss_fp: 0.001393, loss_freq: 0.016892
[13:05:29.352] iteration 6607: loss: 0.140305, loss_s1: 0.059991, loss_fp: 0.003343, loss_freq: 0.092032
[13:05:29.960] iteration 6608: loss: 0.102609, loss_s1: 0.020418, loss_fp: 0.000835, loss_freq: 0.012262
[13:05:30.572] iteration 6609: loss: 0.095431, loss_s1: 0.045603, loss_fp: 0.001735, loss_freq: 0.019259
[13:05:31.180] iteration 6610: loss: 0.079746, loss_s1: 0.017575, loss_fp: 0.001434, loss_freq: 0.028921
[13:05:31.796] iteration 6611: loss: 0.100836, loss_s1: 0.026632, loss_fp: 0.003070, loss_freq: 0.005762
[13:05:32.405] iteration 6612: loss: 0.063900, loss_s1: 0.022804, loss_fp: 0.001774, loss_freq: 0.023443
[13:05:33.013] iteration 6613: loss: 0.114834, loss_s1: 0.047877, loss_fp: 0.002569, loss_freq: 0.015379
[13:05:33.627] iteration 6614: loss: 0.074897, loss_s1: 0.030138, loss_fp: 0.001365, loss_freq: 0.029014
[13:05:34.235] iteration 6615: loss: 0.096043, loss_s1: 0.046165, loss_fp: 0.001297, loss_freq: 0.043825
[13:05:34.855] iteration 6616: loss: 0.074260, loss_s1: 0.035257, loss_fp: 0.000975, loss_freq: 0.052572
[13:05:35.505] iteration 6617: loss: 0.144767, loss_s1: 0.089743, loss_fp: 0.002075, loss_freq: 0.051149
[13:05:36.131] iteration 6618: loss: 0.109479, loss_s1: 0.065756, loss_fp: 0.001624, loss_freq: 0.027322
[13:05:36.745] iteration 6619: loss: 0.108502, loss_s1: 0.052351, loss_fp: 0.003311, loss_freq: 0.033959
[13:05:37.363] iteration 6620: loss: 0.063211, loss_s1: 0.049059, loss_fp: 0.003368, loss_freq: 0.010553
[13:05:37.983] iteration 6621: loss: 0.096741, loss_s1: 0.026227, loss_fp: 0.002373, loss_freq: 0.007869
[13:05:38.591] iteration 6622: loss: 0.100627, loss_s1: 0.070804, loss_fp: 0.003981, loss_freq: 0.042421
[13:05:39.204] iteration 6623: loss: 0.153913, loss_s1: 0.026506, loss_fp: 0.001989, loss_freq: 0.019177
[13:05:39.816] iteration 6624: loss: 0.115410, loss_s1: 0.090351, loss_fp: 0.002971, loss_freq: 0.027626
[13:05:40.430] iteration 6625: loss: 0.074513, loss_s1: 0.023317, loss_fp: 0.001951, loss_freq: 0.048534
[13:05:41.052] iteration 6626: loss: 0.114254, loss_s1: 0.048389, loss_fp: 0.005412, loss_freq: 0.054493
[13:05:41.665] iteration 6627: loss: 0.103937, loss_s1: 0.085851, loss_fp: 0.001435, loss_freq: 0.017226
[13:05:42.278] iteration 6628: loss: 0.083277, loss_s1: 0.041303, loss_fp: 0.001403, loss_freq: 0.038651
[13:05:42.887] iteration 6629: loss: 0.106441, loss_s1: 0.064390, loss_fp: 0.003006, loss_freq: 0.014247
[13:05:43.502] iteration 6630: loss: 0.194935, loss_s1: 0.026425, loss_fp: 0.011288, loss_freq: 0.045940
[13:05:44.119] iteration 6631: loss: 0.060760, loss_s1: 0.014419, loss_fp: 0.000859, loss_freq: 0.019242
[13:05:44.734] iteration 6632: loss: 0.059335, loss_s1: 0.034792, loss_fp: 0.001280, loss_freq: 0.011590
[13:05:45.366] iteration 6633: loss: 0.105640, loss_s1: 0.056289, loss_fp: 0.003274, loss_freq: 0.019414
[13:05:45.980] iteration 6634: loss: 0.091935, loss_s1: 0.039241, loss_fp: 0.003991, loss_freq: 0.007155
[13:05:46.602] iteration 6635: loss: 0.109472, loss_s1: 0.059526, loss_fp: 0.002469, loss_freq: 0.063392
[13:05:47.233] iteration 6636: loss: 0.062197, loss_s1: 0.018976, loss_fp: 0.001582, loss_freq: 0.012163
[13:05:47.854] iteration 6637: loss: 0.115508, loss_s1: 0.041765, loss_fp: 0.002266, loss_freq: 0.042161
[13:05:48.478] iteration 6638: loss: 0.058222, loss_s1: 0.014437, loss_fp: 0.006500, loss_freq: 0.023687
[13:05:49.101] iteration 6639: loss: 0.095262, loss_s1: 0.034551, loss_fp: 0.006224, loss_freq: 0.023398
[13:05:49.733] iteration 6640: loss: 0.113087, loss_s1: 0.061935, loss_fp: 0.008422, loss_freq: 0.030060
[13:05:50.362] iteration 6641: loss: 0.084319, loss_s1: 0.058162, loss_fp: 0.001229, loss_freq: 0.027071
[13:05:50.990] iteration 6642: loss: 0.198679, loss_s1: 0.019614, loss_fp: 0.001319, loss_freq: 0.019779
[13:05:51.630] iteration 6643: loss: 0.093406, loss_s1: 0.062551, loss_fp: 0.002225, loss_freq: 0.013684
[13:05:52.278] iteration 6644: loss: 0.118654, loss_s1: 0.065738, loss_fp: 0.003211, loss_freq: 0.016590
[13:05:52.905] iteration 6645: loss: 0.136012, loss_s1: 0.064307, loss_fp: 0.001835, loss_freq: 0.085609
[13:05:53.544] iteration 6646: loss: 0.114286, loss_s1: 0.100125, loss_fp: 0.001091, loss_freq: 0.029403
[13:05:54.176] iteration 6647: loss: 0.113372, loss_s1: 0.056677, loss_fp: 0.001987, loss_freq: 0.019968
[13:05:54.809] iteration 6648: loss: 0.149537, loss_s1: 0.043954, loss_fp: 0.001138, loss_freq: 0.028639
[13:05:55.443] iteration 6649: loss: 0.081845, loss_s1: 0.052850, loss_fp: 0.001036, loss_freq: 0.027121
[13:05:56.111] iteration 6650: loss: 0.085319, loss_s1: 0.046192, loss_fp: 0.001932, loss_freq: 0.027316
[13:05:56.740] iteration 6651: loss: 0.131666, loss_s1: 0.071816, loss_fp: 0.007236, loss_freq: 0.114719
[13:05:57.379] iteration 6652: loss: 0.104789, loss_s1: 0.047128, loss_fp: 0.004781, loss_freq: 0.029329
[13:05:58.074] iteration 6653: loss: 0.079352, loss_s1: 0.030964, loss_fp: 0.002341, loss_freq: 0.044446
[13:05:58.747] iteration 6654: loss: 0.081830, loss_s1: 0.016167, loss_fp: 0.003610, loss_freq: 0.011013
[13:05:59.426] iteration 6655: loss: 0.070575, loss_s1: 0.058921, loss_fp: 0.001310, loss_freq: 0.019647
[13:06:00.090] iteration 6656: loss: 0.168371, loss_s1: 0.080382, loss_fp: 0.005049, loss_freq: 0.017132
[13:06:00.730] iteration 6657: loss: 0.123766, loss_s1: 0.104141, loss_fp: 0.011133, loss_freq: 0.049056
[13:06:01.367] iteration 6658: loss: 0.235885, loss_s1: 0.063200, loss_fp: 0.010574, loss_freq: 0.071787
[13:06:02.002] iteration 6659: loss: 0.141109, loss_s1: 0.093837, loss_fp: 0.002112, loss_freq: 0.037480
[13:06:02.670] iteration 6660: loss: 0.094585, loss_s1: 0.080558, loss_fp: 0.001738, loss_freq: 0.017526
[13:06:03.361] iteration 6661: loss: 0.110380, loss_s1: 0.046750, loss_fp: 0.003730, loss_freq: 0.038889
[13:06:04.054] iteration 6662: loss: 0.084524, loss_s1: 0.079238, loss_fp: 0.000942, loss_freq: 0.016585
[13:06:04.740] iteration 6663: loss: 0.119915, loss_s1: 0.083100, loss_fp: 0.004859, loss_freq: 0.009403
[13:06:05.436] iteration 6664: loss: 0.101886, loss_s1: 0.051769, loss_fp: 0.003812, loss_freq: 0.060205
[13:06:06.090] iteration 6665: loss: 0.103987, loss_s1: 0.022166, loss_fp: 0.001146, loss_freq: 0.012576
[13:06:06.743] iteration 6666: loss: 0.135367, loss_s1: 0.027847, loss_fp: 0.000484, loss_freq: 0.046725
[13:06:07.387] iteration 6667: loss: 0.093907, loss_s1: 0.081487, loss_fp: 0.000699, loss_freq: 0.013227
[13:06:08.042] iteration 6668: loss: 0.120933, loss_s1: 0.069041, loss_fp: 0.002545, loss_freq: 0.030024
[13:06:08.674] iteration 6669: loss: 0.163796, loss_s1: 0.041196, loss_fp: 0.001997, loss_freq: 0.024278
[13:06:09.304] iteration 6670: loss: 0.139855, loss_s1: 0.089796, loss_fp: 0.001886, loss_freq: 0.079673
[13:06:09.954] iteration 6671: loss: 0.068745, loss_s1: 0.051371, loss_fp: 0.002164, loss_freq: 0.012110
[13:06:10.615] iteration 6672: loss: 0.119496, loss_s1: 0.086582, loss_fp: 0.002059, loss_freq: 0.038705
[13:06:11.266] iteration 6673: loss: 0.068746, loss_s1: 0.053099, loss_fp: 0.001440, loss_freq: 0.012067
[13:06:11.893] iteration 6674: loss: 0.096278, loss_s1: 0.036931, loss_fp: 0.002305, loss_freq: 0.053481
[13:06:12.526] iteration 6675: loss: 0.192208, loss_s1: 0.152808, loss_fp: 0.001399, loss_freq: 0.138606
[13:06:13.169] iteration 6676: loss: 0.115977, loss_s1: 0.057379, loss_fp: 0.000641, loss_freq: 0.036865
[13:06:13.797] iteration 6677: loss: 0.136947, loss_s1: 0.044362, loss_fp: 0.002631, loss_freq: 0.030816
[13:06:14.422] iteration 6678: loss: 0.119115, loss_s1: 0.067338, loss_fp: 0.002546, loss_freq: 0.045804
[13:06:15.054] iteration 6679: loss: 0.121794, loss_s1: 0.058552, loss_fp: 0.001957, loss_freq: 0.021623
[13:06:15.718] iteration 6680: loss: 0.090714, loss_s1: 0.055700, loss_fp: 0.002414, loss_freq: 0.013255
[13:06:16.349] iteration 6681: loss: 0.088710, loss_s1: 0.020688, loss_fp: 0.000899, loss_freq: 0.024043
[13:06:17.030] iteration 6682: loss: 0.120242, loss_s1: 0.107688, loss_fp: 0.004961, loss_freq: 0.038721
[13:06:17.837] iteration 6683: loss: 0.115903, loss_s1: 0.021383, loss_fp: 0.000812, loss_freq: 0.049529
[13:06:18.622] iteration 6684: loss: 0.074883, loss_s1: 0.028846, loss_fp: 0.001200, loss_freq: 0.022743
[13:06:19.318] iteration 6685: loss: 0.187625, loss_s1: 0.124407, loss_fp: 0.001177, loss_freq: 0.123455
[13:06:19.981] iteration 6686: loss: 0.067543, loss_s1: 0.042014, loss_fp: 0.001483, loss_freq: 0.031410
[13:06:20.612] iteration 6687: loss: 0.089070, loss_s1: 0.016481, loss_fp: 0.001539, loss_freq: 0.005676
[13:06:21.241] iteration 6688: loss: 0.109938, loss_s1: 0.064522, loss_fp: 0.001334, loss_freq: 0.045177
[13:06:21.877] iteration 6689: loss: 0.076018, loss_s1: 0.009603, loss_fp: 0.000939, loss_freq: 0.027638
[13:06:22.527] iteration 6690: loss: 0.098254, loss_s1: 0.054198, loss_fp: 0.002505, loss_freq: 0.039239
[13:06:23.157] iteration 6691: loss: 0.108934, loss_s1: 0.038361, loss_fp: 0.001256, loss_freq: 0.036433
[13:06:23.809] iteration 6692: loss: 0.103840, loss_s1: 0.114047, loss_fp: 0.002155, loss_freq: 0.015878
[13:06:24.438] iteration 6693: loss: 0.228954, loss_s1: 0.064545, loss_fp: 0.003836, loss_freq: 0.056916
[13:06:25.068] iteration 6694: loss: 0.090933, loss_s1: 0.083734, loss_fp: 0.000940, loss_freq: 0.021217
[13:06:25.699] iteration 6695: loss: 0.118777, loss_s1: 0.093146, loss_fp: 0.002795, loss_freq: 0.036849
[13:06:26.330] iteration 6696: loss: 0.123204, loss_s1: 0.083357, loss_fp: 0.000944, loss_freq: 0.061941
[13:06:26.960] iteration 6697: loss: 0.091622, loss_s1: 0.077422, loss_fp: 0.006328, loss_freq: 0.008159
[13:06:27.605] iteration 6698: loss: 0.069107, loss_s1: 0.024812, loss_fp: 0.000912, loss_freq: 0.040176
[13:06:28.246] iteration 6699: loss: 0.099448, loss_s1: 0.028853, loss_fp: 0.001397, loss_freq: 0.102884
[13:06:28.874] iteration 6700: loss: 0.169681, loss_s1: 0.060009, loss_fp: 0.001397, loss_freq: 0.044883
[13:06:29.537] iteration 6701: loss: 0.076864, loss_s1: 0.053533, loss_fp: 0.001083, loss_freq: 0.016460
[13:06:30.168] iteration 6702: loss: 0.123375, loss_s1: 0.096734, loss_fp: 0.000734, loss_freq: 0.019910
[13:06:30.796] iteration 6703: loss: 0.084800, loss_s1: 0.046020, loss_fp: 0.002197, loss_freq: 0.040643
[13:06:31.438] iteration 6704: loss: 0.134650, loss_s1: 0.045620, loss_fp: 0.000660, loss_freq: 0.052915
[13:06:32.079] iteration 6705: loss: 0.068585, loss_s1: 0.041665, loss_fp: 0.000474, loss_freq: 0.031032
[13:06:32.712] iteration 6706: loss: 0.062917, loss_s1: 0.014406, loss_fp: 0.001002, loss_freq: 0.006634
[13:06:33.341] iteration 6707: loss: 0.204126, loss_s1: 0.121218, loss_fp: 0.001145, loss_freq: 0.028236
[13:06:33.981] iteration 6708: loss: 0.084941, loss_s1: 0.013674, loss_fp: 0.001240, loss_freq: 0.030922
[13:06:34.623] iteration 6709: loss: 0.123346, loss_s1: 0.023139, loss_fp: 0.003063, loss_freq: 0.021747
[13:06:35.265] iteration 6710: loss: 0.199466, loss_s1: 0.074127, loss_fp: 0.002902, loss_freq: 0.030453
[13:06:35.895] iteration 6711: loss: 0.122785, loss_s1: 0.079946, loss_fp: 0.004432, loss_freq: 0.026373
[13:06:36.527] iteration 6712: loss: 0.202405, loss_s1: 0.098779, loss_fp: 0.002890, loss_freq: 0.044716
[13:06:37.156] iteration 6713: loss: 0.114868, loss_s1: 0.015592, loss_fp: 0.001276, loss_freq: 0.032201
[13:06:37.803] iteration 6714: loss: 0.103257, loss_s1: 0.052130, loss_fp: 0.000670, loss_freq: 0.010489
[13:06:38.471] iteration 6715: loss: 0.105200, loss_s1: 0.087087, loss_fp: 0.007297, loss_freq: 0.031989
[13:06:39.104] iteration 6716: loss: 0.133620, loss_s1: 0.023132, loss_fp: 0.001329, loss_freq: 0.021038
[13:06:39.731] iteration 6717: loss: 0.120534, loss_s1: 0.053735, loss_fp: 0.005574, loss_freq: 0.068212
[13:06:40.366] iteration 6718: loss: 0.124558, loss_s1: 0.030871, loss_fp: 0.001721, loss_freq: 0.025033
[13:06:41.005] iteration 6719: loss: 0.105539, loss_s1: 0.075005, loss_fp: 0.001175, loss_freq: 0.017301
[13:06:41.633] iteration 6720: loss: 0.138278, loss_s1: 0.070673, loss_fp: 0.003709, loss_freq: 0.070808
[13:06:42.257] iteration 6721: loss: 0.089546, loss_s1: 0.042338, loss_fp: 0.001873, loss_freq: 0.033451
[13:06:43.219] iteration 6722: loss: 0.098851, loss_s1: 0.030967, loss_fp: 0.001957, loss_freq: 0.040758
[13:06:43.849] iteration 6723: loss: 0.072492, loss_s1: 0.031869, loss_fp: 0.002259, loss_freq: 0.011291
[13:06:44.479] iteration 6724: loss: 0.063524, loss_s1: 0.024006, loss_fp: 0.003227, loss_freq: 0.036333
[13:06:45.104] iteration 6725: loss: 0.124993, loss_s1: 0.068172, loss_fp: 0.000748, loss_freq: 0.028033
[13:06:45.738] iteration 6726: loss: 0.134449, loss_s1: 0.083826, loss_fp: 0.001747, loss_freq: 0.084400
[13:06:46.380] iteration 6727: loss: 0.095557, loss_s1: 0.055685, loss_fp: 0.003272, loss_freq: 0.003748
[13:06:47.017] iteration 6728: loss: 0.073714, loss_s1: 0.028823, loss_fp: 0.001412, loss_freq: 0.054292
[13:06:47.657] iteration 6729: loss: 0.130251, loss_s1: 0.039282, loss_fp: 0.001665, loss_freq: 0.055566
[13:06:48.284] iteration 6730: loss: 0.101822, loss_s1: 0.058856, loss_fp: 0.000603, loss_freq: 0.039054
[13:06:48.919] iteration 6731: loss: 0.158538, loss_s1: 0.003441, loss_fp: 0.001525, loss_freq: 0.012463
[13:06:49.564] iteration 6732: loss: 0.086614, loss_s1: 0.048856, loss_fp: 0.001374, loss_freq: 0.021080
[13:06:50.198] iteration 6733: loss: 0.104318, loss_s1: 0.051475, loss_fp: 0.001109, loss_freq: 0.063498
[13:06:50.830] iteration 6734: loss: 0.078888, loss_s1: 0.042365, loss_fp: 0.003999, loss_freq: 0.024234
[13:06:51.471] iteration 6735: loss: 0.079217, loss_s1: 0.027632, loss_fp: 0.002128, loss_freq: 0.025873
[13:06:52.107] iteration 6736: loss: 0.095488, loss_s1: 0.069157, loss_fp: 0.002337, loss_freq: 0.044016
[13:06:52.748] iteration 6737: loss: 0.123342, loss_s1: 0.057397, loss_fp: 0.001628, loss_freq: 0.016373
[13:06:53.382] iteration 6738: loss: 0.138835, loss_s1: 0.038859, loss_fp: 0.000780, loss_freq: 0.018764
[13:06:54.021] iteration 6739: loss: 0.154207, loss_s1: 0.055710, loss_fp: 0.002082, loss_freq: 0.014679
[13:06:54.652] iteration 6740: loss: 0.075376, loss_s1: 0.037782, loss_fp: 0.006301, loss_freq: 0.046178
[13:06:55.277] iteration 6741: loss: 0.135456, loss_s1: 0.054773, loss_fp: 0.001106, loss_freq: 0.013139
[13:06:55.912] iteration 6742: loss: 0.230326, loss_s1: 0.040659, loss_fp: 0.005524, loss_freq: 0.069238
[13:06:56.544] iteration 6743: loss: 0.077909, loss_s1: 0.016952, loss_fp: 0.000773, loss_freq: 0.039055
[13:06:57.184] iteration 6744: loss: 0.090355, loss_s1: 0.054776, loss_fp: 0.004041, loss_freq: 0.039690
[13:06:57.822] iteration 6745: loss: 0.099587, loss_s1: 0.045016, loss_fp: 0.003380, loss_freq: 0.032460
[13:06:58.494] iteration 6746: loss: 0.059611, loss_s1: 0.012983, loss_fp: 0.000463, loss_freq: 0.020894
[13:06:59.121] iteration 6747: loss: 0.126031, loss_s1: 0.041445, loss_fp: 0.038557, loss_freq: 0.022297
[13:06:59.756] iteration 6748: loss: 0.111092, loss_s1: 0.051008, loss_fp: 0.001503, loss_freq: 0.046429
[13:07:00.394] iteration 6749: loss: 0.081779, loss_s1: 0.047018, loss_fp: 0.004722, loss_freq: 0.019597
[13:07:01.030] iteration 6750: loss: 0.145852, loss_s1: 0.080913, loss_fp: 0.001214, loss_freq: 0.058492
[13:07:01.661] iteration 6751: loss: 0.153969, loss_s1: 0.105356, loss_fp: 0.001996, loss_freq: 0.021688
[13:07:02.308] iteration 6752: loss: 0.095784, loss_s1: 0.051969, loss_fp: 0.000997, loss_freq: 0.007827
[13:07:02.943] iteration 6753: loss: 0.086081, loss_s1: 0.025614, loss_fp: 0.000490, loss_freq: 0.024485
[13:07:03.575] iteration 6754: loss: 0.060076, loss_s1: 0.039405, loss_fp: 0.000585, loss_freq: 0.009682
[13:07:04.221] iteration 6755: loss: 0.114816, loss_s1: 0.062266, loss_fp: 0.002441, loss_freq: 0.059377
[13:07:04.910] iteration 6756: loss: 0.136106, loss_s1: 0.027657, loss_fp: 0.003481, loss_freq: 0.036810
[13:07:05.561] iteration 6757: loss: 0.131929, loss_s1: 0.073372, loss_fp: 0.001997, loss_freq: 0.039072
[13:07:06.204] iteration 6758: loss: 0.089896, loss_s1: 0.062006, loss_fp: 0.001511, loss_freq: 0.020461
[13:07:06.839] iteration 6759: loss: 0.072554, loss_s1: 0.033069, loss_fp: 0.000917, loss_freq: 0.026970
[13:07:07.517] iteration 6760: loss: 0.105819, loss_s1: 0.061061, loss_fp: 0.008819, loss_freq: 0.054685
[13:07:08.187] iteration 6761: loss: 0.088046, loss_s1: 0.052997, loss_fp: 0.002602, loss_freq: 0.022381
[13:07:08.820] iteration 6762: loss: 0.157544, loss_s1: 0.047129, loss_fp: 0.005482, loss_freq: 0.050783
[13:07:09.478] iteration 6763: loss: 0.053036, loss_s1: 0.026806, loss_fp: 0.000421, loss_freq: 0.005538
[13:07:10.152] iteration 6764: loss: 0.108708, loss_s1: 0.013846, loss_fp: 0.001333, loss_freq: 0.019796
[13:07:10.826] iteration 6765: loss: 0.104023, loss_s1: 0.064885, loss_fp: 0.001217, loss_freq: 0.067512
[13:07:11.505] iteration 6766: loss: 0.132042, loss_s1: 0.015747, loss_fp: 0.000486, loss_freq: 0.021628
[13:07:12.166] iteration 6767: loss: 0.082738, loss_s1: 0.052732, loss_fp: 0.000984, loss_freq: 0.030741
[13:07:12.805] iteration 6768: loss: 0.083983, loss_s1: 0.051579, loss_fp: 0.002413, loss_freq: 0.028029
[13:07:13.438] iteration 6769: loss: 0.075087, loss_s1: 0.049976, loss_fp: 0.001962, loss_freq: 0.018410
[13:07:14.077] iteration 6770: loss: 0.045582, loss_s1: 0.020168, loss_fp: 0.000991, loss_freq: 0.011859
[13:07:14.713] iteration 6771: loss: 0.084518, loss_s1: 0.058034, loss_fp: 0.004739, loss_freq: 0.013545
[13:07:15.354] iteration 6772: loss: 0.081366, loss_s1: 0.042432, loss_fp: 0.002377, loss_freq: 0.007471
[13:07:16.020] iteration 6773: loss: 0.171421, loss_s1: 0.014897, loss_fp: 0.003056, loss_freq: 0.067198
[13:07:16.685] iteration 6774: loss: 0.062752, loss_s1: 0.027791, loss_fp: 0.001309, loss_freq: 0.006003
[13:07:17.357] iteration 6775: loss: 0.076347, loss_s1: 0.032853, loss_fp: 0.005240, loss_freq: 0.016171
[13:07:18.033] iteration 6776: loss: 0.095868, loss_s1: 0.061550, loss_fp: 0.012978, loss_freq: 0.037534
[13:07:18.675] iteration 6777: loss: 0.100244, loss_s1: 0.015481, loss_fp: 0.002156, loss_freq: 0.010552
[13:07:19.314] iteration 6778: loss: 0.071612, loss_s1: 0.035156, loss_fp: 0.001235, loss_freq: 0.034155
[13:07:19.955] iteration 6779: loss: 0.074234, loss_s1: 0.036270, loss_fp: 0.004797, loss_freq: 0.034739
[13:07:20.597] iteration 6780: loss: 0.136532, loss_s1: 0.030543, loss_fp: 0.001360, loss_freq: 0.046398
[13:07:21.237] iteration 6781: loss: 0.108798, loss_s1: 0.047505, loss_fp: 0.007417, loss_freq: 0.041377
[13:07:21.883] iteration 6782: loss: 0.076906, loss_s1: 0.022724, loss_fp: 0.001357, loss_freq: 0.019020
[13:07:22.516] iteration 6783: loss: 0.081588, loss_s1: 0.041926, loss_fp: 0.014891, loss_freq: 0.011175
[13:07:23.155] iteration 6784: loss: 0.137442, loss_s1: 0.056869, loss_fp: 0.007277, loss_freq: 0.040546
[13:07:23.796] iteration 6785: loss: 0.120162, loss_s1: 0.038316, loss_fp: 0.002471, loss_freq: 0.014574
[13:07:24.436] iteration 6786: loss: 0.095441, loss_s1: 0.063999, loss_fp: 0.001820, loss_freq: 0.022406
[13:07:25.077] iteration 6787: loss: 0.124965, loss_s1: 0.035943, loss_fp: 0.000854, loss_freq: 0.021734
[13:07:25.719] iteration 6788: loss: 0.099422, loss_s1: 0.034909, loss_fp: 0.002183, loss_freq: 0.043999
[13:07:26.355] iteration 6789: loss: 0.129529, loss_s1: 0.030575, loss_fp: 0.005504, loss_freq: 0.023672
[13:07:26.994] iteration 6790: loss: 0.099370, loss_s1: 0.034102, loss_fp: 0.009057, loss_freq: 0.016615
[13:07:27.634] iteration 6791: loss: 0.108404, loss_s1: 0.056366, loss_fp: 0.001300, loss_freq: 0.019015
[13:07:28.275] iteration 6792: loss: 0.069109, loss_s1: 0.029830, loss_fp: 0.002922, loss_freq: 0.014034
[13:07:28.921] iteration 6793: loss: 0.111730, loss_s1: 0.104458, loss_fp: 0.003140, loss_freq: 0.025186
[13:07:29.562] iteration 6794: loss: 0.090043, loss_s1: 0.024331, loss_fp: 0.001060, loss_freq: 0.083159
[13:07:30.228] iteration 6795: loss: 0.099783, loss_s1: 0.021717, loss_fp: 0.002407, loss_freq: 0.065578
[13:07:30.866] iteration 6796: loss: 0.081539, loss_s1: 0.062900, loss_fp: 0.003181, loss_freq: 0.035471
[13:07:31.504] iteration 6797: loss: 0.079710, loss_s1: 0.027987, loss_fp: 0.001973, loss_freq: 0.008751
[13:07:32.142] iteration 6798: loss: 0.075178, loss_s1: 0.039351, loss_fp: 0.001824, loss_freq: 0.037047
[13:07:32.789] iteration 6799: loss: 0.089014, loss_s1: 0.029625, loss_fp: 0.003405, loss_freq: 0.015733
[13:07:33.422] iteration 6800: loss: 0.134669, loss_s1: 0.102606, loss_fp: 0.000742, loss_freq: 0.081125
[13:07:36.682] iteration 6800 : mean_dice : 0.730137
[13:07:37.336] iteration 6801: loss: 0.260679, loss_s1: 0.027544, loss_fp: 0.001979, loss_freq: 0.049501
[13:07:37.967] iteration 6802: loss: 0.115383, loss_s1: 0.026645, loss_fp: 0.004434, loss_freq: 0.042276
[13:07:38.604] iteration 6803: loss: 0.107339, loss_s1: 0.052269, loss_fp: 0.003768, loss_freq: 0.049400
[13:07:39.240] iteration 6804: loss: 0.093065, loss_s1: 0.025517, loss_fp: 0.001032, loss_freq: 0.025448
[13:07:39.879] iteration 6805: loss: 0.073567, loss_s1: 0.056470, loss_fp: 0.000647, loss_freq: 0.026019
[13:07:40.516] iteration 6806: loss: 0.158858, loss_s1: 0.045961, loss_fp: 0.002061, loss_freq: 0.047994
[13:07:41.169] iteration 6807: loss: 0.094791, loss_s1: 0.045430, loss_fp: 0.002411, loss_freq: 0.058903
[13:07:41.825] iteration 6808: loss: 0.132420, loss_s1: 0.066537, loss_fp: 0.001727, loss_freq: 0.016040
[13:07:42.507] iteration 6809: loss: 0.133764, loss_s1: 0.040354, loss_fp: 0.000476, loss_freq: 0.009882
[13:07:43.195] iteration 6810: loss: 0.091577, loss_s1: 0.063459, loss_fp: 0.001917, loss_freq: 0.021149
[13:07:43.834] iteration 6811: loss: 0.064797, loss_s1: 0.028633, loss_fp: 0.001471, loss_freq: 0.017387
[13:07:44.508] iteration 6812: loss: 0.111114, loss_s1: 0.041262, loss_fp: 0.000420, loss_freq: 0.024215
[13:07:45.182] iteration 6813: loss: 0.104792, loss_s1: 0.082656, loss_fp: 0.005679, loss_freq: 0.046763
[13:07:45.856] iteration 6814: loss: 0.075770, loss_s1: 0.071674, loss_fp: 0.001569, loss_freq: 0.006468
[13:07:46.495] iteration 6815: loss: 0.115686, loss_s1: 0.046642, loss_fp: 0.004662, loss_freq: 0.053876
[13:07:47.156] iteration 6816: loss: 0.067324, loss_s1: 0.047952, loss_fp: 0.001591, loss_freq: 0.010976
[13:07:47.806] iteration 6817: loss: 0.113941, loss_s1: 0.033902, loss_fp: 0.000947, loss_freq: 0.031104
[13:07:48.447] iteration 6818: loss: 0.190998, loss_s1: 0.058026, loss_fp: 0.000621, loss_freq: 0.113367
[13:07:49.087] iteration 6819: loss: 0.071778, loss_s1: 0.021225, loss_fp: 0.002071, loss_freq: 0.041678
[13:07:49.746] iteration 6820: loss: 0.111179, loss_s1: 0.049329, loss_fp: 0.001153, loss_freq: 0.041187
[13:07:50.413] iteration 6821: loss: 0.153329, loss_s1: 0.064804, loss_fp: 0.005268, loss_freq: 0.051402
[13:07:51.041] iteration 6822: loss: 0.168215, loss_s1: 0.065712, loss_fp: 0.001846, loss_freq: 0.050752
[13:07:51.675] iteration 6823: loss: 0.049754, loss_s1: 0.020709, loss_fp: 0.002716, loss_freq: 0.004676
[13:07:52.314] iteration 6824: loss: 0.097378, loss_s1: 0.089434, loss_fp: 0.002569, loss_freq: 0.006062
[13:07:52.951] iteration 6825: loss: 0.125596, loss_s1: 0.066171, loss_fp: 0.001978, loss_freq: 0.071982
[13:07:53.598] iteration 6826: loss: 0.096827, loss_s1: 0.027824, loss_fp: 0.000614, loss_freq: 0.031944
[13:07:54.231] iteration 6827: loss: 0.108998, loss_s1: 0.027076, loss_fp: 0.002328, loss_freq: 0.038460
[13:07:54.866] iteration 6828: loss: 0.129748, loss_s1: 0.067448, loss_fp: 0.002546, loss_freq: 0.098580
[13:07:55.499] iteration 6829: loss: 0.080901, loss_s1: 0.062940, loss_fp: 0.003490, loss_freq: 0.024471
[13:07:56.132] iteration 6830: loss: 0.155611, loss_s1: 0.034537, loss_fp: 0.003680, loss_freq: 0.004411
[13:07:56.806] iteration 6831: loss: 0.075050, loss_s1: 0.046125, loss_fp: 0.001360, loss_freq: 0.019491
[13:07:57.474] iteration 6832: loss: 0.131485, loss_s1: 0.095300, loss_fp: 0.003624, loss_freq: 0.012163
[13:07:58.159] iteration 6833: loss: 0.085510, loss_s1: 0.040162, loss_fp: 0.002919, loss_freq: 0.015196
[13:07:58.836] iteration 6834: loss: 0.111082, loss_s1: 0.068704, loss_fp: 0.001109, loss_freq: 0.012397
[13:07:59.518] iteration 6835: loss: 0.076855, loss_s1: 0.040186, loss_fp: 0.003971, loss_freq: 0.035859
[13:08:00.188] iteration 6836: loss: 0.209524, loss_s1: 0.080187, loss_fp: 0.000262, loss_freq: 0.041870
[13:08:00.831] iteration 6837: loss: 0.105096, loss_s1: 0.041243, loss_fp: 0.001214, loss_freq: 0.014103
[13:08:01.472] iteration 6838: loss: 0.112810, loss_s1: 0.073666, loss_fp: 0.005587, loss_freq: 0.061814
[13:08:02.112] iteration 6839: loss: 0.126201, loss_s1: 0.067786, loss_fp: 0.005090, loss_freq: 0.063184
[13:08:02.750] iteration 6840: loss: 0.055087, loss_s1: 0.044958, loss_fp: 0.001479, loss_freq: 0.012579
[13:08:03.392] iteration 6841: loss: 0.077086, loss_s1: 0.020845, loss_fp: 0.006597, loss_freq: 0.037069
[13:08:04.039] iteration 6842: loss: 0.102745, loss_s1: 0.023728, loss_fp: 0.003402, loss_freq: 0.091187
[13:08:04.684] iteration 6843: loss: 0.178850, loss_s1: 0.034946, loss_fp: 0.002039, loss_freq: 0.021255
[13:08:05.331] iteration 6844: loss: 0.129243, loss_s1: 0.062844, loss_fp: 0.003205, loss_freq: 0.019028
[13:08:05.973] iteration 6845: loss: 0.114115, loss_s1: 0.102616, loss_fp: 0.002071, loss_freq: 0.044389
[13:08:06.609] iteration 6846: loss: 0.148219, loss_s1: 0.122619, loss_fp: 0.004616, loss_freq: 0.023996
[13:08:07.244] iteration 6847: loss: 0.166912, loss_s1: 0.088311, loss_fp: 0.001597, loss_freq: 0.014915
[13:08:07.881] iteration 6848: loss: 0.077660, loss_s1: 0.038754, loss_fp: 0.002289, loss_freq: 0.041762
[13:08:08.520] iteration 6849: loss: 0.046715, loss_s1: 0.004007, loss_fp: 0.000688, loss_freq: 0.015009
[13:08:09.160] iteration 6850: loss: 0.101874, loss_s1: 0.045805, loss_fp: 0.004783, loss_freq: 0.031182
[13:08:09.799] iteration 6851: loss: 0.062690, loss_s1: 0.018736, loss_fp: 0.001577, loss_freq: 0.023839
[13:08:10.440] iteration 6852: loss: 0.131196, loss_s1: 0.088824, loss_fp: 0.003000, loss_freq: 0.016704
[13:08:11.082] iteration 6853: loss: 0.128613, loss_s1: 0.054367, loss_fp: 0.005482, loss_freq: 0.031372
[13:08:11.725] iteration 6854: loss: 0.065258, loss_s1: 0.035880, loss_fp: 0.002899, loss_freq: 0.008482
[13:08:12.380] iteration 6855: loss: 0.155503, loss_s1: 0.035259, loss_fp: 0.000919, loss_freq: 0.049253
[13:08:13.014] iteration 6856: loss: 0.122310, loss_s1: 0.023854, loss_fp: 0.002641, loss_freq: 0.036169
[13:08:13.644] iteration 6857: loss: 0.090965, loss_s1: 0.040394, loss_fp: 0.001311, loss_freq: 0.013987
[13:08:14.285] iteration 6858: loss: 0.107428, loss_s1: 0.108839, loss_fp: 0.001609, loss_freq: 0.016806
[13:08:14.926] iteration 6859: loss: 0.113248, loss_s1: 0.028413, loss_fp: 0.004772, loss_freq: 0.013721
[13:08:15.557] iteration 6860: loss: 0.087182, loss_s1: 0.063936, loss_fp: 0.001234, loss_freq: 0.023842
[13:08:16.198] iteration 6861: loss: 0.098517, loss_s1: 0.040821, loss_fp: 0.000840, loss_freq: 0.019358
[13:08:16.845] iteration 6862: loss: 0.099925, loss_s1: 0.033847, loss_fp: 0.000761, loss_freq: 0.026435
[13:08:17.522] iteration 6863: loss: 0.131136, loss_s1: 0.124536, loss_fp: 0.003297, loss_freq: 0.037904
[13:08:18.185] iteration 6864: loss: 0.068727, loss_s1: 0.039328, loss_fp: 0.002604, loss_freq: 0.025622
[13:08:19.138] iteration 6865: loss: 0.081784, loss_s1: 0.024630, loss_fp: 0.000822, loss_freq: 0.010366
[13:08:19.781] iteration 6866: loss: 0.136765, loss_s1: 0.061826, loss_fp: 0.021383, loss_freq: 0.041164
[13:08:20.417] iteration 6867: loss: 0.062007, loss_s1: 0.020450, loss_fp: 0.001115, loss_freq: 0.029127
[13:08:21.046] iteration 6868: loss: 0.093935, loss_s1: 0.064293, loss_fp: 0.003366, loss_freq: 0.013396
[13:08:21.689] iteration 6869: loss: 0.117581, loss_s1: 0.078439, loss_fp: 0.004061, loss_freq: 0.074399
[13:08:22.324] iteration 6870: loss: 0.098175, loss_s1: 0.014013, loss_fp: 0.000438, loss_freq: 0.006384
[13:08:23.005] iteration 6871: loss: 0.072292, loss_s1: 0.029296, loss_fp: 0.002478, loss_freq: 0.038924
[13:08:23.996] iteration 6872: loss: 0.150344, loss_s1: 0.041520, loss_fp: 0.003549, loss_freq: 0.025160
[13:08:24.873] iteration 6873: loss: 0.093480, loss_s1: 0.052406, loss_fp: 0.001829, loss_freq: 0.059458
[13:08:25.669] iteration 6874: loss: 0.162520, loss_s1: 0.034042, loss_fp: 0.000698, loss_freq: 0.042088
[13:08:26.306] iteration 6875: loss: 0.087187, loss_s1: 0.035465, loss_fp: 0.002736, loss_freq: 0.044563
[13:08:26.946] iteration 6876: loss: 0.083220, loss_s1: 0.030950, loss_fp: 0.001125, loss_freq: 0.052151
[13:08:27.587] iteration 6877: loss: 0.112092, loss_s1: 0.061726, loss_fp: 0.000927, loss_freq: 0.014944
[13:08:28.223] iteration 6878: loss: 0.049298, loss_s1: 0.023927, loss_fp: 0.000986, loss_freq: 0.010019
[13:08:28.861] iteration 6879: loss: 0.088512, loss_s1: 0.037649, loss_fp: 0.001510, loss_freq: 0.053070
[13:08:29.508] iteration 6880: loss: 0.087186, loss_s1: 0.046391, loss_fp: 0.003662, loss_freq: 0.035497
[13:08:30.142] iteration 6881: loss: 0.191416, loss_s1: 0.046924, loss_fp: 0.001286, loss_freq: 0.035679
[13:08:30.808] iteration 6882: loss: 0.125707, loss_s1: 0.047333, loss_fp: 0.011571, loss_freq: 0.031162
[13:08:31.444] iteration 6883: loss: 0.064786, loss_s1: 0.032836, loss_fp: 0.003149, loss_freq: 0.019705
[13:08:32.084] iteration 6884: loss: 0.082069, loss_s1: 0.047780, loss_fp: 0.000652, loss_freq: 0.044732
[13:08:32.721] iteration 6885: loss: 0.127887, loss_s1: 0.051914, loss_fp: 0.001220, loss_freq: 0.063109
[13:08:33.388] iteration 6886: loss: 0.106791, loss_s1: 0.082762, loss_fp: 0.003775, loss_freq: 0.043899
[13:08:34.012] iteration 6887: loss: 0.088667, loss_s1: 0.030825, loss_fp: 0.005240, loss_freq: 0.047979
[13:08:34.686] iteration 6888: loss: 0.139400, loss_s1: 0.053841, loss_fp: 0.000513, loss_freq: 0.023139
[13:08:35.348] iteration 6889: loss: 0.067704, loss_s1: 0.048795, loss_fp: 0.000575, loss_freq: 0.013055
[13:08:36.007] iteration 6890: loss: 0.141565, loss_s1: 0.070432, loss_fp: 0.001095, loss_freq: 0.061770
[13:08:36.667] iteration 6891: loss: 0.130868, loss_s1: 0.086847, loss_fp: 0.000940, loss_freq: 0.044024
[13:08:37.305] iteration 6892: loss: 0.060086, loss_s1: 0.024711, loss_fp: 0.004431, loss_freq: 0.010775
[13:08:37.945] iteration 6893: loss: 0.129630, loss_s1: 0.075357, loss_fp: 0.004319, loss_freq: 0.051540
[13:08:38.588] iteration 6894: loss: 0.113729, loss_s1: 0.038911, loss_fp: 0.000784, loss_freq: 0.015443
[13:08:39.237] iteration 6895: loss: 0.071381, loss_s1: 0.032215, loss_fp: 0.002182, loss_freq: 0.005121
[13:08:39.879] iteration 6896: loss: 0.073007, loss_s1: 0.014753, loss_fp: 0.001549, loss_freq: 0.013980
[13:08:40.527] iteration 6897: loss: 0.105675, loss_s1: 0.043990, loss_fp: 0.000836, loss_freq: 0.018929
[13:08:41.172] iteration 6898: loss: 0.128299, loss_s1: 0.114551, loss_fp: 0.005467, loss_freq: 0.060714
[13:08:41.829] iteration 6899: loss: 0.139204, loss_s1: 0.032543, loss_fp: 0.001757, loss_freq: 0.023533
[13:08:42.470] iteration 6900: loss: 0.186794, loss_s1: 0.137871, loss_fp: 0.002823, loss_freq: 0.042636
[13:08:43.120] iteration 6901: loss: 0.091889, loss_s1: 0.061126, loss_fp: 0.001896, loss_freq: 0.035331
[13:08:43.759] iteration 6902: loss: 0.049598, loss_s1: 0.034678, loss_fp: 0.001734, loss_freq: 0.006916
[13:08:44.407] iteration 6903: loss: 0.119916, loss_s1: 0.035295, loss_fp: 0.012366, loss_freq: 0.059228
[13:08:45.049] iteration 6904: loss: 0.083954, loss_s1: 0.057109, loss_fp: 0.002716, loss_freq: 0.010629
[13:08:45.688] iteration 6905: loss: 0.135540, loss_s1: 0.057724, loss_fp: 0.002432, loss_freq: 0.019642
[13:08:46.348] iteration 6906: loss: 0.064338, loss_s1: 0.024947, loss_fp: 0.001006, loss_freq: 0.044444
[13:08:46.988] iteration 6907: loss: 0.118529, loss_s1: 0.064265, loss_fp: 0.004578, loss_freq: 0.015493
[13:08:47.650] iteration 6908: loss: 0.085102, loss_s1: 0.049339, loss_fp: 0.001034, loss_freq: 0.027484
[13:08:48.284] iteration 6909: loss: 0.154624, loss_s1: 0.051608, loss_fp: 0.000937, loss_freq: 0.032926
[13:08:48.918] iteration 6910: loss: 0.157739, loss_s1: 0.132875, loss_fp: 0.002181, loss_freq: 0.042431
[13:08:49.553] iteration 6911: loss: 0.084959, loss_s1: 0.023298, loss_fp: 0.004022, loss_freq: 0.052103
[13:08:50.190] iteration 6912: loss: 0.114328, loss_s1: 0.047562, loss_fp: 0.004764, loss_freq: 0.045612
[13:08:50.831] iteration 6913: loss: 0.062464, loss_s1: 0.032912, loss_fp: 0.001241, loss_freq: 0.032357
[13:08:51.462] iteration 6914: loss: 0.129112, loss_s1: 0.051401, loss_fp: 0.001634, loss_freq: 0.076891
[13:08:52.100] iteration 6915: loss: 0.070660, loss_s1: 0.038320, loss_fp: 0.003678, loss_freq: 0.015341
[13:08:52.737] iteration 6916: loss: 0.098546, loss_s1: 0.014939, loss_fp: 0.003134, loss_freq: 0.035187
[13:08:53.369] iteration 6917: loss: 0.099693, loss_s1: 0.030413, loss_fp: 0.001719, loss_freq: 0.009437
[13:08:54.012] iteration 6918: loss: 0.095585, loss_s1: 0.056326, loss_fp: 0.004189, loss_freq: 0.019241
[13:08:54.693] iteration 6919: loss: 0.069828, loss_s1: 0.048888, loss_fp: 0.000843, loss_freq: 0.027861
[13:08:55.383] iteration 6920: loss: 0.181386, loss_s1: 0.052790, loss_fp: 0.000838, loss_freq: 0.011613
[13:08:56.086] iteration 6921: loss: 0.117615, loss_s1: 0.038559, loss_fp: 0.002353, loss_freq: 0.038377
[13:08:56.771] iteration 6922: loss: 0.070940, loss_s1: 0.026715, loss_fp: 0.001169, loss_freq: 0.033510
[13:08:57.439] iteration 6923: loss: 0.135298, loss_s1: 0.057433, loss_fp: 0.007601, loss_freq: 0.073184
[13:08:58.103] iteration 6924: loss: 0.082885, loss_s1: 0.033887, loss_fp: 0.003239, loss_freq: 0.018711
[13:08:58.772] iteration 6925: loss: 0.086101, loss_s1: 0.013636, loss_fp: 0.001344, loss_freq: 0.023075
[13:08:59.434] iteration 6926: loss: 0.080635, loss_s1: 0.027039, loss_fp: 0.001992, loss_freq: 0.024474
[13:09:00.078] iteration 6927: loss: 0.105683, loss_s1: 0.056110, loss_fp: 0.000851, loss_freq: 0.036754
[13:09:00.715] iteration 6928: loss: 0.078120, loss_s1: 0.015377, loss_fp: 0.000415, loss_freq: 0.018113
[13:09:01.356] iteration 6929: loss: 0.093628, loss_s1: 0.048216, loss_fp: 0.004531, loss_freq: 0.035762
[13:09:01.989] iteration 6930: loss: 0.118012, loss_s1: 0.049043, loss_fp: 0.001430, loss_freq: 0.016896
[13:09:02.624] iteration 6931: loss: 0.142991, loss_s1: 0.085517, loss_fp: 0.008810, loss_freq: 0.078689
[13:09:03.255] iteration 6932: loss: 0.058272, loss_s1: 0.018239, loss_fp: 0.002094, loss_freq: 0.008435
[13:09:03.889] iteration 6933: loss: 0.080529, loss_s1: 0.069191, loss_fp: 0.004188, loss_freq: 0.019984
[13:09:04.550] iteration 6934: loss: 0.135139, loss_s1: 0.028469, loss_fp: 0.010148, loss_freq: 0.020487
[13:09:05.231] iteration 6935: loss: 0.075739, loss_s1: 0.034720, loss_fp: 0.003544, loss_freq: 0.028098
[13:09:05.910] iteration 6936: loss: 0.073483, loss_s1: 0.013718, loss_fp: 0.005635, loss_freq: 0.027943
[13:09:06.578] iteration 6937: loss: 0.092757, loss_s1: 0.046175, loss_fp: 0.007257, loss_freq: 0.062043
[13:09:07.244] iteration 6938: loss: 0.172314, loss_s1: 0.163204, loss_fp: 0.006874, loss_freq: 0.079440
[13:09:07.894] iteration 6939: loss: 0.187405, loss_s1: 0.126660, loss_fp: 0.036024, loss_freq: 0.106729
[13:09:08.524] iteration 6940: loss: 0.115022, loss_s1: 0.081550, loss_fp: 0.001340, loss_freq: 0.014907
[13:09:09.157] iteration 6941: loss: 0.082112, loss_s1: 0.081248, loss_fp: 0.011532, loss_freq: 0.017561
[13:09:09.866] iteration 6942: loss: 0.078201, loss_s1: 0.029014, loss_fp: 0.000989, loss_freq: 0.006190
[13:09:10.536] iteration 6943: loss: 0.080442, loss_s1: 0.043461, loss_fp: 0.002951, loss_freq: 0.028156
[13:09:11.215] iteration 6944: loss: 0.208283, loss_s1: 0.042191, loss_fp: 0.002750, loss_freq: 0.067743
[13:09:11.856] iteration 6945: loss: 0.092283, loss_s1: 0.038604, loss_fp: 0.001029, loss_freq: 0.016042
[13:09:12.501] iteration 6946: loss: 0.094154, loss_s1: 0.052487, loss_fp: 0.002313, loss_freq: 0.050154
[13:09:13.167] iteration 6947: loss: 0.111649, loss_s1: 0.071815, loss_fp: 0.001879, loss_freq: 0.008687
[13:09:13.824] iteration 6948: loss: 0.076511, loss_s1: 0.061572, loss_fp: 0.001896, loss_freq: 0.027537
[13:09:14.472] iteration 6949: loss: 0.095860, loss_s1: 0.056485, loss_fp: 0.001294, loss_freq: 0.010728
[13:09:15.119] iteration 6950: loss: 0.104668, loss_s1: 0.078724, loss_fp: 0.000880, loss_freq: 0.068646
[13:09:15.769] iteration 6951: loss: 0.113504, loss_s1: 0.034473, loss_fp: 0.001609, loss_freq: 0.013059
[13:09:16.414] iteration 6952: loss: 0.119160, loss_s1: 0.020770, loss_fp: 0.001030, loss_freq: 0.023281
[13:09:17.069] iteration 6953: loss: 0.076829, loss_s1: 0.018758, loss_fp: 0.001562, loss_freq: 0.011684
[13:09:17.720] iteration 6954: loss: 0.111133, loss_s1: 0.057694, loss_fp: 0.004314, loss_freq: 0.054044
[13:09:18.382] iteration 6955: loss: 0.160318, loss_s1: 0.084469, loss_fp: 0.001083, loss_freq: 0.035914
[13:09:19.052] iteration 6956: loss: 0.106735, loss_s1: 0.097839, loss_fp: 0.001696, loss_freq: 0.032598
[13:09:19.697] iteration 6957: loss: 0.085534, loss_s1: 0.078476, loss_fp: 0.000960, loss_freq: 0.006636
[13:09:20.333] iteration 6958: loss: 0.103439, loss_s1: 0.048821, loss_fp: 0.000868, loss_freq: 0.039213
[13:09:20.965] iteration 6959: loss: 0.063967, loss_s1: 0.012888, loss_fp: 0.000517, loss_freq: 0.007407
[13:09:21.604] iteration 6960: loss: 0.124196, loss_s1: 0.050079, loss_fp: 0.000681, loss_freq: 0.053657
[13:09:22.240] iteration 6961: loss: 0.213154, loss_s1: 0.135135, loss_fp: 0.008779, loss_freq: 0.159955
[13:09:22.878] iteration 6962: loss: 0.103420, loss_s1: 0.029737, loss_fp: 0.002985, loss_freq: 0.064294
[13:09:23.529] iteration 6963: loss: 0.208104, loss_s1: 0.018763, loss_fp: 0.000962, loss_freq: 0.039492
[13:09:24.185] iteration 6964: loss: 0.186558, loss_s1: 0.052998, loss_fp: 0.005775, loss_freq: 0.067773
[13:09:24.824] iteration 6965: loss: 0.101948, loss_s1: 0.031593, loss_fp: 0.000551, loss_freq: 0.031995
[13:09:25.474] iteration 6966: loss: 0.063323, loss_s1: 0.040456, loss_fp: 0.001618, loss_freq: 0.014593
[13:09:26.109] iteration 6967: loss: 0.096999, loss_s1: 0.011047, loss_fp: 0.002009, loss_freq: 0.018838
[13:09:26.741] iteration 6968: loss: 0.088009, loss_s1: 0.051740, loss_fp: 0.002036, loss_freq: 0.025664
[13:09:27.395] iteration 6969: loss: 0.094687, loss_s1: 0.028663, loss_fp: 0.004211, loss_freq: 0.029207
[13:09:28.035] iteration 6970: loss: 0.080269, loss_s1: 0.031864, loss_fp: 0.000547, loss_freq: 0.032677
[13:09:28.674] iteration 6971: loss: 0.185491, loss_s1: 0.107963, loss_fp: 0.006779, loss_freq: 0.180443
[13:09:29.370] iteration 6972: loss: 0.120384, loss_s1: 0.101100, loss_fp: 0.000921, loss_freq: 0.058660
[13:09:30.019] iteration 6973: loss: 0.100469, loss_s1: 0.030955, loss_fp: 0.000958, loss_freq: 0.009887
[13:09:30.651] iteration 6974: loss: 0.092367, loss_s1: 0.037052, loss_fp: 0.010800, loss_freq: 0.016199
[13:09:31.332] iteration 6975: loss: 0.092694, loss_s1: 0.055585, loss_fp: 0.006270, loss_freq: 0.004383
[13:09:32.001] iteration 6976: loss: 0.077494, loss_s1: 0.017473, loss_fp: 0.001464, loss_freq: 0.044403
[13:09:32.667] iteration 6977: loss: 0.103540, loss_s1: 0.043420, loss_fp: 0.002490, loss_freq: 0.028052
[13:09:33.346] iteration 6978: loss: 0.096039, loss_s1: 0.080031, loss_fp: 0.005774, loss_freq: 0.020719
[13:09:34.008] iteration 6979: loss: 0.192022, loss_s1: 0.036314, loss_fp: 0.000472, loss_freq: 0.047959
[13:09:34.665] iteration 6980: loss: 0.111367, loss_s1: 0.065448, loss_fp: 0.003655, loss_freq: 0.017128
[13:09:35.301] iteration 6981: loss: 0.107024, loss_s1: 0.072385, loss_fp: 0.002795, loss_freq: 0.046443
[13:09:35.942] iteration 6982: loss: 0.081424, loss_s1: 0.030962, loss_fp: 0.001338, loss_freq: 0.025251
[13:09:36.587] iteration 6983: loss: 0.057867, loss_s1: 0.042473, loss_fp: 0.001236, loss_freq: 0.017884
[13:09:37.226] iteration 6984: loss: 0.096567, loss_s1: 0.040231, loss_fp: 0.015235, loss_freq: 0.044311
[13:09:37.866] iteration 6985: loss: 0.137455, loss_s1: 0.103106, loss_fp: 0.007586, loss_freq: 0.092644
[13:09:38.532] iteration 6986: loss: 0.141871, loss_s1: 0.050640, loss_fp: 0.002343, loss_freq: 0.009423
[13:09:39.171] iteration 6987: loss: 0.090350, loss_s1: 0.006639, loss_fp: 0.000452, loss_freq: 0.001923
[13:09:39.869] iteration 6988: loss: 0.090998, loss_s1: 0.033635, loss_fp: 0.005538, loss_freq: 0.066974
[13:09:40.528] iteration 6989: loss: 0.073587, loss_s1: 0.050344, loss_fp: 0.004632, loss_freq: 0.029415
[13:09:41.178] iteration 6990: loss: 0.093204, loss_s1: 0.038065, loss_fp: 0.000603, loss_freq: 0.021798
[13:09:41.832] iteration 6991: loss: 0.071566, loss_s1: 0.021580, loss_fp: 0.001331, loss_freq: 0.038293
[13:09:42.487] iteration 6992: loss: 0.060126, loss_s1: 0.029347, loss_fp: 0.000813, loss_freq: 0.017052
[13:09:43.148] iteration 6993: loss: 0.129518, loss_s1: 0.089524, loss_fp: 0.003657, loss_freq: 0.021126
[13:09:43.837] iteration 6994: loss: 0.067279, loss_s1: 0.027487, loss_fp: 0.002297, loss_freq: 0.009978
[13:09:44.486] iteration 6995: loss: 0.120039, loss_s1: 0.040991, loss_fp: 0.003208, loss_freq: 0.019101
[13:09:45.126] iteration 6996: loss: 0.120397, loss_s1: 0.062516, loss_fp: 0.005384, loss_freq: 0.027399
[13:09:45.756] iteration 6997: loss: 0.110031, loss_s1: 0.065092, loss_fp: 0.003026, loss_freq: 0.019796
[13:09:46.394] iteration 6998: loss: 0.168627, loss_s1: 0.103659, loss_fp: 0.001443, loss_freq: 0.098291
[13:09:47.036] iteration 6999: loss: 0.117329, loss_s1: 0.051961, loss_fp: 0.007234, loss_freq: 0.052988
[13:09:47.674] iteration 7000: loss: 0.099940, loss_s1: 0.041894, loss_fp: 0.003318, loss_freq: 0.014296
[13:09:50.970] iteration 7000 : mean_dice : 0.706912
[13:09:51.628] iteration 7001: loss: 0.101365, loss_s1: 0.068094, loss_fp: 0.000675, loss_freq: 0.019371
[13:09:52.269] iteration 7002: loss: 0.113857, loss_s1: 0.011843, loss_fp: 0.001480, loss_freq: 0.017111
[13:09:52.907] iteration 7003: loss: 0.055052, loss_s1: 0.020742, loss_fp: 0.003675, loss_freq: 0.016168
[13:09:53.556] iteration 7004: loss: 0.103361, loss_s1: 0.035269, loss_fp: 0.001036, loss_freq: 0.010162
[13:09:54.203] iteration 7005: loss: 0.092213, loss_s1: 0.036374, loss_fp: 0.001667, loss_freq: 0.027587
[13:09:54.841] iteration 7006: loss: 0.101802, loss_s1: 0.074411, loss_fp: 0.035517, loss_freq: 0.009658
[13:09:55.509] iteration 7007: loss: 0.064186, loss_s1: 0.030421, loss_fp: 0.001397, loss_freq: 0.019604
[13:09:56.496] iteration 7008: loss: 0.084574, loss_s1: 0.047373, loss_fp: 0.002354, loss_freq: 0.017402
[13:09:57.132] iteration 7009: loss: 0.086725, loss_s1: 0.064449, loss_fp: 0.000697, loss_freq: 0.012913
[13:09:57.775] iteration 7010: loss: 0.076982, loss_s1: 0.043583, loss_fp: 0.001507, loss_freq: 0.033872
[13:09:58.407] iteration 7011: loss: 0.120454, loss_s1: 0.082000, loss_fp: 0.001504, loss_freq: 0.030316
[13:09:59.063] iteration 7012: loss: 0.098314, loss_s1: 0.089299, loss_fp: 0.001096, loss_freq: 0.034294
[13:09:59.701] iteration 7013: loss: 0.081629, loss_s1: 0.028474, loss_fp: 0.001041, loss_freq: 0.003632
[13:10:00.346] iteration 7014: loss: 0.099519, loss_s1: 0.043476, loss_fp: 0.005656, loss_freq: 0.063828
[13:10:01.065] iteration 7015: loss: 0.168604, loss_s1: 0.053871, loss_fp: 0.005601, loss_freq: 0.028370
[13:10:01.739] iteration 7016: loss: 0.077514, loss_s1: 0.031902, loss_fp: 0.005060, loss_freq: 0.038285
[13:10:02.391] iteration 7017: loss: 0.165622, loss_s1: 0.043336, loss_fp: 0.001902, loss_freq: 0.025384
[13:10:03.028] iteration 7018: loss: 0.097425, loss_s1: 0.055624, loss_fp: 0.007905, loss_freq: 0.055357
[13:10:03.669] iteration 7019: loss: 0.093940, loss_s1: 0.045302, loss_fp: 0.000408, loss_freq: 0.044340
[13:10:04.307] iteration 7020: loss: 0.071176, loss_s1: 0.028804, loss_fp: 0.000957, loss_freq: 0.011853
[13:10:04.960] iteration 7021: loss: 0.048932, loss_s1: 0.011704, loss_fp: 0.000701, loss_freq: 0.022657
[13:10:05.617] iteration 7022: loss: 0.145609, loss_s1: 0.175460, loss_fp: 0.002062, loss_freq: 0.025906
[13:10:06.258] iteration 7023: loss: 0.083930, loss_s1: 0.023301, loss_fp: 0.004207, loss_freq: 0.030984
[13:10:06.896] iteration 7024: loss: 0.115634, loss_s1: 0.037613, loss_fp: 0.001030, loss_freq: 0.019361
[13:10:07.539] iteration 7025: loss: 0.135820, loss_s1: 0.053255, loss_fp: 0.004716, loss_freq: 0.031246
[13:10:08.184] iteration 7026: loss: 0.061954, loss_s1: 0.036458, loss_fp: 0.006191, loss_freq: 0.013669
[13:10:08.824] iteration 7027: loss: 0.122706, loss_s1: 0.115771, loss_fp: 0.002455, loss_freq: 0.029982
[13:10:09.463] iteration 7028: loss: 0.165365, loss_s1: 0.029884, loss_fp: 0.004456, loss_freq: 0.083222
[13:10:10.110] iteration 7029: loss: 0.093584, loss_s1: 0.026090, loss_fp: 0.001743, loss_freq: 0.028585
[13:10:10.744] iteration 7030: loss: 0.082540, loss_s1: 0.064303, loss_fp: 0.001844, loss_freq: 0.043019
[13:10:11.383] iteration 7031: loss: 0.076591, loss_s1: 0.019220, loss_fp: 0.001211, loss_freq: 0.013586
[13:10:12.024] iteration 7032: loss: 0.090473, loss_s1: 0.040735, loss_fp: 0.000670, loss_freq: 0.018575
[13:10:12.658] iteration 7033: loss: 0.106718, loss_s1: 0.040028, loss_fp: 0.001911, loss_freq: 0.035714
[13:10:13.293] iteration 7034: loss: 0.168395, loss_s1: 0.019690, loss_fp: 0.001027, loss_freq: 0.074281
[13:10:13.929] iteration 7035: loss: 0.069685, loss_s1: 0.047007, loss_fp: 0.002020, loss_freq: 0.016581
[13:10:14.560] iteration 7036: loss: 0.132991, loss_s1: 0.039627, loss_fp: 0.001880, loss_freq: 0.069369
[13:10:15.189] iteration 7037: loss: 0.086785, loss_s1: 0.037515, loss_fp: 0.001312, loss_freq: 0.010969
[13:10:15.833] iteration 7038: loss: 0.130819, loss_s1: 0.096254, loss_fp: 0.000982, loss_freq: 0.009831
[13:10:16.467] iteration 7039: loss: 0.073125, loss_s1: 0.033940, loss_fp: 0.003512, loss_freq: 0.027196
[13:10:17.098] iteration 7040: loss: 0.066963, loss_s1: 0.052498, loss_fp: 0.001457, loss_freq: 0.009739
[13:10:17.731] iteration 7041: loss: 0.107059, loss_s1: 0.100607, loss_fp: 0.017699, loss_freq: 0.031210
[13:10:18.375] iteration 7042: loss: 0.162577, loss_s1: 0.081465, loss_fp: 0.002920, loss_freq: 0.025699
[13:10:19.009] iteration 7043: loss: 0.128847, loss_s1: 0.035722, loss_fp: 0.001678, loss_freq: 0.046125
[13:10:19.647] iteration 7044: loss: 0.104868, loss_s1: 0.080226, loss_fp: 0.001035, loss_freq: 0.037474
[13:10:20.323] iteration 7045: loss: 0.060244, loss_s1: 0.024709, loss_fp: 0.002497, loss_freq: 0.021554
[13:10:21.009] iteration 7046: loss: 0.124489, loss_s1: 0.050339, loss_fp: 0.002934, loss_freq: 0.048008
[13:10:21.698] iteration 7047: loss: 0.087237, loss_s1: 0.039697, loss_fp: 0.001709, loss_freq: 0.017247
[13:10:22.391] iteration 7048: loss: 0.104692, loss_s1: 0.025277, loss_fp: 0.001474, loss_freq: 0.032831
[13:10:23.091] iteration 7049: loss: 0.064536, loss_s1: 0.033370, loss_fp: 0.004288, loss_freq: 0.033816
[13:10:23.779] iteration 7050: loss: 0.066351, loss_s1: 0.023283, loss_fp: 0.000795, loss_freq: 0.006305
[13:10:24.467] iteration 7051: loss: 0.082985, loss_s1: 0.066772, loss_fp: 0.008742, loss_freq: 0.020357
[13:10:25.118] iteration 7052: loss: 0.146832, loss_s1: 0.018457, loss_fp: 0.000812, loss_freq: 0.037771
[13:10:25.776] iteration 7053: loss: 0.069220, loss_s1: 0.024336, loss_fp: 0.001154, loss_freq: 0.029906
[13:10:26.412] iteration 7054: loss: 0.066938, loss_s1: 0.031142, loss_fp: 0.000685, loss_freq: 0.013637
[13:10:27.055] iteration 7055: loss: 0.086065, loss_s1: 0.041297, loss_fp: 0.002988, loss_freq: 0.030686
[13:10:27.695] iteration 7056: loss: 0.048735, loss_s1: 0.030204, loss_fp: 0.002522, loss_freq: 0.009624
[13:10:28.393] iteration 7057: loss: 0.079448, loss_s1: 0.025027, loss_fp: 0.008826, loss_freq: 0.036661
[13:10:29.103] iteration 7058: loss: 0.083054, loss_s1: 0.047356, loss_fp: 0.002637, loss_freq: 0.012247
[13:10:29.808] iteration 7059: loss: 0.196401, loss_s1: 0.030845, loss_fp: 0.000552, loss_freq: 0.053872
[13:10:30.577] iteration 7060: loss: 0.092719, loss_s1: 0.061650, loss_fp: 0.000592, loss_freq: 0.003512
[13:10:31.325] iteration 7061: loss: 0.055845, loss_s1: 0.041775, loss_fp: 0.002853, loss_freq: 0.007596
[13:10:31.995] iteration 7062: loss: 0.076928, loss_s1: 0.044400, loss_fp: 0.000899, loss_freq: 0.030738
[13:10:32.661] iteration 7063: loss: 0.165478, loss_s1: 0.038210, loss_fp: 0.001772, loss_freq: 0.023903
[13:10:33.298] iteration 7064: loss: 0.166350, loss_s1: 0.081201, loss_fp: 0.005240, loss_freq: 0.074890
[13:10:33.990] iteration 7065: loss: 0.069064, loss_s1: 0.023587, loss_fp: 0.000791, loss_freq: 0.027084
[13:10:34.634] iteration 7066: loss: 0.105784, loss_s1: 0.031235, loss_fp: 0.002959, loss_freq: 0.066167
[13:10:35.269] iteration 7067: loss: 0.083058, loss_s1: 0.030236, loss_fp: 0.000738, loss_freq: 0.017102
[13:10:35.909] iteration 7068: loss: 0.096981, loss_s1: 0.048028, loss_fp: 0.003806, loss_freq: 0.013453
[13:10:36.556] iteration 7069: loss: 0.106156, loss_s1: 0.062533, loss_fp: 0.005283, loss_freq: 0.045325
[13:10:37.207] iteration 7070: loss: 0.115328, loss_s1: 0.091478, loss_fp: 0.002660, loss_freq: 0.031412
[13:10:37.857] iteration 7071: loss: 0.135494, loss_s1: 0.032468, loss_fp: 0.001934, loss_freq: 0.020968
[13:10:38.551] iteration 7072: loss: 0.121492, loss_s1: 0.079865, loss_fp: 0.000971, loss_freq: 0.019325
[13:10:39.261] iteration 7073: loss: 0.105959, loss_s1: 0.031454, loss_fp: 0.006392, loss_freq: 0.019607
[13:10:39.941] iteration 7074: loss: 0.098952, loss_s1: 0.053624, loss_fp: 0.002388, loss_freq: 0.022077
[13:10:40.615] iteration 7075: loss: 0.084871, loss_s1: 0.026486, loss_fp: 0.001884, loss_freq: 0.038745
[13:10:41.302] iteration 7076: loss: 0.083727, loss_s1: 0.055571, loss_fp: 0.001794, loss_freq: 0.008014
[13:10:41.975] iteration 7077: loss: 0.133547, loss_s1: 0.021369, loss_fp: 0.003297, loss_freq: 0.017293
[13:10:42.628] iteration 7078: loss: 0.106515, loss_s1: 0.063419, loss_fp: 0.001647, loss_freq: 0.017387
[13:10:43.270] iteration 7079: loss: 0.073271, loss_s1: 0.026030, loss_fp: 0.003320, loss_freq: 0.047033
[13:10:43.914] iteration 7080: loss: 0.084155, loss_s1: 0.016022, loss_fp: 0.012347, loss_freq: 0.044195
[13:10:44.555] iteration 7081: loss: 0.162952, loss_s1: 0.103451, loss_fp: 0.006361, loss_freq: 0.078900
[13:10:45.190] iteration 7082: loss: 0.124791, loss_s1: 0.056916, loss_fp: 0.003229, loss_freq: 0.080308
[13:10:45.830] iteration 7083: loss: 0.114324, loss_s1: 0.099268, loss_fp: 0.002180, loss_freq: 0.013020
[13:10:46.462] iteration 7084: loss: 0.060574, loss_s1: 0.023097, loss_fp: 0.002399, loss_freq: 0.030446
[13:10:47.101] iteration 7085: loss: 0.101177, loss_s1: 0.025103, loss_fp: 0.002272, loss_freq: 0.015460
[13:10:47.730] iteration 7086: loss: 0.106938, loss_s1: 0.037324, loss_fp: 0.006193, loss_freq: 0.077593
[13:10:48.391] iteration 7087: loss: 0.150633, loss_s1: 0.046989, loss_fp: 0.009348, loss_freq: 0.021086
[13:10:49.047] iteration 7088: loss: 0.094304, loss_s1: 0.043958, loss_fp: 0.001545, loss_freq: 0.027206
[13:10:49.779] iteration 7089: loss: 0.125136, loss_s1: 0.098328, loss_fp: 0.002318, loss_freq: 0.040628
[13:10:50.425] iteration 7090: loss: 0.116600, loss_s1: 0.103833, loss_fp: 0.000569, loss_freq: 0.019868
[13:10:51.054] iteration 7091: loss: 0.057299, loss_s1: 0.034188, loss_fp: 0.000946, loss_freq: 0.013613
[13:10:51.684] iteration 7092: loss: 0.082452, loss_s1: 0.046018, loss_fp: 0.001265, loss_freq: 0.022019
[13:10:52.317] iteration 7093: loss: 0.097194, loss_s1: 0.052246, loss_fp: 0.002737, loss_freq: 0.051512
[13:10:52.949] iteration 7094: loss: 0.181794, loss_s1: 0.049027, loss_fp: 0.003981, loss_freq: 0.019033
[13:10:53.586] iteration 7095: loss: 0.113254, loss_s1: 0.046079, loss_fp: 0.001410, loss_freq: 0.025910
[13:10:54.230] iteration 7096: loss: 0.073141, loss_s1: 0.029349, loss_fp: 0.001459, loss_freq: 0.008819
[13:10:54.877] iteration 7097: loss: 0.076297, loss_s1: 0.079379, loss_fp: 0.003433, loss_freq: 0.013103
[13:10:55.502] iteration 7098: loss: 0.147772, loss_s1: 0.030125, loss_fp: 0.001797, loss_freq: 0.020885
[13:10:56.127] iteration 7099: loss: 0.074791, loss_s1: 0.020122, loss_fp: 0.002358, loss_freq: 0.048327
[13:10:56.751] iteration 7100: loss: 0.055701, loss_s1: 0.019943, loss_fp: 0.001036, loss_freq: 0.024615
[13:10:57.382] iteration 7101: loss: 0.118507, loss_s1: 0.045292, loss_fp: 0.003287, loss_freq: 0.027113
[13:10:58.017] iteration 7102: loss: 0.060552, loss_s1: 0.017358, loss_fp: 0.001045, loss_freq: 0.013708
[13:10:58.653] iteration 7103: loss: 0.092954, loss_s1: 0.022011, loss_fp: 0.004571, loss_freq: 0.024558
[13:10:59.283] iteration 7104: loss: 0.150082, loss_s1: 0.061448, loss_fp: 0.002788, loss_freq: 0.134859
[13:10:59.923] iteration 7105: loss: 0.096247, loss_s1: 0.022669, loss_fp: 0.005402, loss_freq: 0.069876
[13:11:00.575] iteration 7106: loss: 0.107339, loss_s1: 0.035503, loss_fp: 0.001739, loss_freq: 0.024570
[13:11:01.223] iteration 7107: loss: 0.130695, loss_s1: 0.040582, loss_fp: 0.002586, loss_freq: 0.028460
[13:11:01.861] iteration 7108: loss: 0.128970, loss_s1: 0.053620, loss_fp: 0.002589, loss_freq: 0.068819
[13:11:02.495] iteration 7109: loss: 0.064468, loss_s1: 0.019800, loss_fp: 0.003447, loss_freq: 0.011837
[13:11:03.148] iteration 7110: loss: 0.086243, loss_s1: 0.023625, loss_fp: 0.001963, loss_freq: 0.019930
[13:11:03.790] iteration 7111: loss: 0.093126, loss_s1: 0.045133, loss_fp: 0.003034, loss_freq: 0.038902
[13:11:04.424] iteration 7112: loss: 0.112092, loss_s1: 0.039144, loss_fp: 0.001127, loss_freq: 0.059271
[13:11:05.087] iteration 7113: loss: 0.060227, loss_s1: 0.016969, loss_fp: 0.000760, loss_freq: 0.028667
[13:11:05.747] iteration 7114: loss: 0.123086, loss_s1: 0.058518, loss_fp: 0.002047, loss_freq: 0.094724
[13:11:06.404] iteration 7115: loss: 0.082581, loss_s1: 0.069298, loss_fp: 0.002934, loss_freq: 0.030609
[13:11:07.071] iteration 7116: loss: 0.085483, loss_s1: 0.030580, loss_fp: 0.001203, loss_freq: 0.002907
[13:11:07.727] iteration 7117: loss: 0.106226, loss_s1: 0.036493, loss_fp: 0.002413, loss_freq: 0.042034
[13:11:08.422] iteration 7118: loss: 0.090369, loss_s1: 0.052203, loss_fp: 0.001378, loss_freq: 0.009939
[13:11:09.079] iteration 7119: loss: 0.096216, loss_s1: 0.083393, loss_fp: 0.001190, loss_freq: 0.048894
[13:11:09.726] iteration 7120: loss: 0.075402, loss_s1: 0.023701, loss_fp: 0.002368, loss_freq: 0.012007
[13:11:10.385] iteration 7121: loss: 0.094826, loss_s1: 0.078076, loss_fp: 0.001203, loss_freq: 0.034769
[13:11:11.025] iteration 7122: loss: 0.207621, loss_s1: 0.047251, loss_fp: 0.002889, loss_freq: 0.083010
[13:11:11.669] iteration 7123: loss: 0.056264, loss_s1: 0.035453, loss_fp: 0.001134, loss_freq: 0.003128
[13:11:12.308] iteration 7124: loss: 0.094859, loss_s1: 0.048966, loss_fp: 0.005005, loss_freq: 0.028586
[13:11:12.944] iteration 7125: loss: 0.094009, loss_s1: 0.044509, loss_fp: 0.002772, loss_freq: 0.023291
[13:11:13.583] iteration 7126: loss: 0.081588, loss_s1: 0.084935, loss_fp: 0.002372, loss_freq: 0.011089
[13:11:14.228] iteration 7127: loss: 0.118492, loss_s1: 0.059207, loss_fp: 0.003094, loss_freq: 0.087734
[13:11:14.859] iteration 7128: loss: 0.122451, loss_s1: 0.042259, loss_fp: 0.000863, loss_freq: 0.059826
[13:11:15.498] iteration 7129: loss: 0.087291, loss_s1: 0.037685, loss_fp: 0.004396, loss_freq: 0.022579
[13:11:16.132] iteration 7130: loss: 0.101394, loss_s1: 0.036144, loss_fp: 0.001793, loss_freq: 0.017243
[13:11:16.768] iteration 7131: loss: 0.075438, loss_s1: 0.034433, loss_fp: 0.000823, loss_freq: 0.016055
[13:11:17.397] iteration 7132: loss: 0.079145, loss_s1: 0.064600, loss_fp: 0.004438, loss_freq: 0.019237
[13:11:18.031] iteration 7133: loss: 0.107056, loss_s1: 0.046020, loss_fp: 0.012041, loss_freq: 0.029989
[13:11:18.674] iteration 7134: loss: 0.069040, loss_s1: 0.033851, loss_fp: 0.001940, loss_freq: 0.035978
[13:11:19.310] iteration 7135: loss: 0.080889, loss_s1: 0.032449, loss_fp: 0.006729, loss_freq: 0.020230
[13:11:19.943] iteration 7136: loss: 0.111664, loss_s1: 0.056359, loss_fp: 0.001316, loss_freq: 0.026493
[13:11:20.580] iteration 7137: loss: 0.052879, loss_s1: 0.008389, loss_fp: 0.000772, loss_freq: 0.009876
[13:11:21.212] iteration 7138: loss: 0.090730, loss_s1: 0.035654, loss_fp: 0.003834, loss_freq: 0.005739
[13:11:21.837] iteration 7139: loss: 0.110321, loss_s1: 0.048865, loss_fp: 0.003031, loss_freq: 0.044109
[13:11:22.461] iteration 7140: loss: 0.090958, loss_s1: 0.033760, loss_fp: 0.003191, loss_freq: 0.042891
[13:11:23.088] iteration 7141: loss: 0.145390, loss_s1: 0.064575, loss_fp: 0.001101, loss_freq: 0.059398
[13:11:23.718] iteration 7142: loss: 0.132799, loss_s1: 0.056311, loss_fp: 0.002729, loss_freq: 0.038752
[13:11:24.358] iteration 7143: loss: 0.088316, loss_s1: 0.045848, loss_fp: 0.002192, loss_freq: 0.011144
[13:11:24.998] iteration 7144: loss: 0.106032, loss_s1: 0.060002, loss_fp: 0.004736, loss_freq: 0.010629
[13:11:25.640] iteration 7145: loss: 0.083158, loss_s1: 0.028275, loss_fp: 0.001001, loss_freq: 0.018653
[13:11:26.271] iteration 7146: loss: 0.083851, loss_s1: 0.061914, loss_fp: 0.005861, loss_freq: 0.023208
[13:11:26.901] iteration 7147: loss: 0.122795, loss_s1: 0.011646, loss_fp: 0.008101, loss_freq: 0.019796
[13:11:27.536] iteration 7148: loss: 0.111068, loss_s1: 0.077147, loss_fp: 0.002037, loss_freq: 0.050248
[13:11:28.164] iteration 7149: loss: 0.122560, loss_s1: 0.115743, loss_fp: 0.005690, loss_freq: 0.029562
[13:11:28.793] iteration 7150: loss: 0.111339, loss_s1: 0.116792, loss_fp: 0.003860, loss_freq: 0.040324
[13:11:29.767] iteration 7151: loss: 0.073788, loss_s1: 0.032301, loss_fp: 0.001715, loss_freq: 0.026612
[13:11:30.449] iteration 7152: loss: 0.103161, loss_s1: 0.086147, loss_fp: 0.006995, loss_freq: 0.029558
[13:11:31.154] iteration 7153: loss: 0.074091, loss_s1: 0.021475, loss_fp: 0.002669, loss_freq: 0.046070
[13:11:31.814] iteration 7154: loss: 0.127040, loss_s1: 0.079992, loss_fp: 0.004984, loss_freq: 0.030758
[13:11:32.442] iteration 7155: loss: 0.129042, loss_s1: 0.052856, loss_fp: 0.004120, loss_freq: 0.047110
[13:11:33.126] iteration 7156: loss: 0.114025, loss_s1: 0.054118, loss_fp: 0.002797, loss_freq: 0.008657
[13:11:33.801] iteration 7157: loss: 0.084537, loss_s1: 0.096552, loss_fp: 0.000721, loss_freq: 0.021700
[13:11:34.468] iteration 7158: loss: 0.138498, loss_s1: 0.031139, loss_fp: 0.006408, loss_freq: 0.040471
[13:11:35.134] iteration 7159: loss: 0.082184, loss_s1: 0.046068, loss_fp: 0.001026, loss_freq: 0.043165
[13:11:35.806] iteration 7160: loss: 0.131850, loss_s1: 0.032450, loss_fp: 0.002682, loss_freq: 0.031513
[13:11:36.486] iteration 7161: loss: 0.104487, loss_s1: 0.029399, loss_fp: 0.003588, loss_freq: 0.043564
[13:11:37.137] iteration 7162: loss: 0.076872, loss_s1: 0.017613, loss_fp: 0.000775, loss_freq: 0.050819
[13:11:37.807] iteration 7163: loss: 0.094448, loss_s1: 0.075162, loss_fp: 0.004896, loss_freq: 0.021717
[13:11:38.448] iteration 7164: loss: 0.064102, loss_s1: 0.028956, loss_fp: 0.002345, loss_freq: 0.025042
[13:11:39.087] iteration 7165: loss: 0.128900, loss_s1: 0.153817, loss_fp: 0.000983, loss_freq: 0.024913
[13:11:39.720] iteration 7166: loss: 0.126547, loss_s1: 0.067407, loss_fp: 0.001856, loss_freq: 0.015114
[13:11:40.359] iteration 7167: loss: 0.215688, loss_s1: 0.027619, loss_fp: 0.000842, loss_freq: 0.024128
[13:11:40.997] iteration 7168: loss: 0.127707, loss_s1: 0.043568, loss_fp: 0.000987, loss_freq: 0.021519
[13:11:41.658] iteration 7169: loss: 0.076985, loss_s1: 0.057133, loss_fp: 0.001743, loss_freq: 0.027449
[13:11:42.320] iteration 7170: loss: 0.137205, loss_s1: 0.048490, loss_fp: 0.005026, loss_freq: 0.026193
[13:11:42.957] iteration 7171: loss: 0.139096, loss_s1: 0.058560, loss_fp: 0.005593, loss_freq: 0.053269
[13:11:43.599] iteration 7172: loss: 0.091086, loss_s1: 0.035046, loss_fp: 0.000298, loss_freq: 0.044280
[13:11:44.234] iteration 7173: loss: 0.068208, loss_s1: 0.036483, loss_fp: 0.001020, loss_freq: 0.025661
[13:11:44.870] iteration 7174: loss: 0.115053, loss_s1: 0.090621, loss_fp: 0.000566, loss_freq: 0.029005
[13:11:45.505] iteration 7175: loss: 0.067492, loss_s1: 0.027681, loss_fp: 0.001905, loss_freq: 0.016670
[13:11:46.142] iteration 7176: loss: 0.113898, loss_s1: 0.033722, loss_fp: 0.011688, loss_freq: 0.043476
[13:11:46.779] iteration 7177: loss: 0.123092, loss_s1: 0.045986, loss_fp: 0.000761, loss_freq: 0.048218
[13:11:47.419] iteration 7178: loss: 0.082717, loss_s1: 0.021111, loss_fp: 0.000998, loss_freq: 0.010765
[13:11:48.058] iteration 7179: loss: 0.133793, loss_s1: 0.063517, loss_fp: 0.002651, loss_freq: 0.042109
[13:11:48.746] iteration 7180: loss: 0.102327, loss_s1: 0.070798, loss_fp: 0.001191, loss_freq: 0.020627
[13:11:49.390] iteration 7181: loss: 0.098738, loss_s1: 0.048941, loss_fp: 0.013531, loss_freq: 0.023252
[13:11:50.032] iteration 7182: loss: 0.093615, loss_s1: 0.038977, loss_fp: 0.005030, loss_freq: 0.026239
[13:11:50.671] iteration 7183: loss: 0.132744, loss_s1: 0.096399, loss_fp: 0.002252, loss_freq: 0.019272
[13:11:51.305] iteration 7184: loss: 0.093363, loss_s1: 0.054860, loss_fp: 0.003378, loss_freq: 0.056137
[13:11:51.942] iteration 7185: loss: 0.165131, loss_s1: 0.087910, loss_fp: 0.002432, loss_freq: 0.027679
[13:11:52.585] iteration 7186: loss: 0.139221, loss_s1: 0.080086, loss_fp: 0.002806, loss_freq: 0.054480
[13:11:53.238] iteration 7187: loss: 0.097546, loss_s1: 0.048436, loss_fp: 0.003324, loss_freq: 0.039083
[13:11:53.914] iteration 7188: loss: 0.054421, loss_s1: 0.020223, loss_fp: 0.001915, loss_freq: 0.018654
[13:11:54.555] iteration 7189: loss: 0.133453, loss_s1: 0.070754, loss_fp: 0.007549, loss_freq: 0.042183
[13:11:55.187] iteration 7190: loss: 0.082470, loss_s1: 0.061859, loss_fp: 0.003148, loss_freq: 0.008663
[13:11:55.829] iteration 7191: loss: 0.109312, loss_s1: 0.080029, loss_fp: 0.002532, loss_freq: 0.017186
[13:11:56.473] iteration 7192: loss: 0.055011, loss_s1: 0.028899, loss_fp: 0.001918, loss_freq: 0.010059
[13:11:57.114] iteration 7193: loss: 0.083249, loss_s1: 0.043007, loss_fp: 0.000384, loss_freq: 0.009864
[13:11:57.789] iteration 7194: loss: 0.085041, loss_s1: 0.056704, loss_fp: 0.002391, loss_freq: 0.030936
[13:11:58.459] iteration 7195: loss: 0.181334, loss_s1: 0.072346, loss_fp: 0.001916, loss_freq: 0.051814
[13:11:59.131] iteration 7196: loss: 0.152837, loss_s1: 0.083957, loss_fp: 0.000936, loss_freq: 0.062719
[13:11:59.768] iteration 7197: loss: 0.074191, loss_s1: 0.026634, loss_fp: 0.001934, loss_freq: 0.040949
[13:12:00.401] iteration 7198: loss: 0.093948, loss_s1: 0.021979, loss_fp: 0.001362, loss_freq: 0.054936
[13:12:01.036] iteration 7199: loss: 0.079371, loss_s1: 0.069163, loss_fp: 0.004637, loss_freq: 0.019516
[13:12:01.710] iteration 7200: loss: 0.086868, loss_s1: 0.037776, loss_fp: 0.002060, loss_freq: 0.033330
[13:12:05.109] iteration 7200 : mean_dice : 0.712783
[13:12:05.808] iteration 7201: loss: 0.091429, loss_s1: 0.071071, loss_fp: 0.001412, loss_freq: 0.032406
[13:12:06.482] iteration 7202: loss: 0.149581, loss_s1: 0.015294, loss_fp: 0.001055, loss_freq: 0.098724
[13:12:07.152] iteration 7203: loss: 0.106722, loss_s1: 0.028367, loss_fp: 0.002211, loss_freq: 0.012396
[13:12:07.824] iteration 7204: loss: 0.064407, loss_s1: 0.055045, loss_fp: 0.003855, loss_freq: 0.009014
[13:12:08.498] iteration 7205: loss: 0.064425, loss_s1: 0.043947, loss_fp: 0.000641, loss_freq: 0.005054
[13:12:09.152] iteration 7206: loss: 0.095740, loss_s1: 0.044626, loss_fp: 0.001347, loss_freq: 0.017890
[13:12:09.810] iteration 7207: loss: 0.082541, loss_s1: 0.067311, loss_fp: 0.002969, loss_freq: 0.018234
[13:12:10.461] iteration 7208: loss: 0.083869, loss_s1: 0.027625, loss_fp: 0.001193, loss_freq: 0.042410
[13:12:11.117] iteration 7209: loss: 0.159174, loss_s1: 0.072884, loss_fp: 0.002016, loss_freq: 0.119250
[13:12:11.758] iteration 7210: loss: 0.069187, loss_s1: 0.021507, loss_fp: 0.009601, loss_freq: 0.041938
[13:12:12.395] iteration 7211: loss: 0.122356, loss_s1: 0.044906, loss_fp: 0.001084, loss_freq: 0.016560
[13:12:13.047] iteration 7212: loss: 0.147275, loss_s1: 0.045174, loss_fp: 0.000935, loss_freq: 0.025674
[13:12:13.691] iteration 7213: loss: 0.085068, loss_s1: 0.031929, loss_fp: 0.001628, loss_freq: 0.033223
[13:12:14.331] iteration 7214: loss: 0.136643, loss_s1: 0.020441, loss_fp: 0.001944, loss_freq: 0.034921
[13:12:14.968] iteration 7215: loss: 0.118770, loss_s1: 0.045587, loss_fp: 0.000810, loss_freq: 0.035053
[13:12:15.616] iteration 7216: loss: 0.108535, loss_s1: 0.019048, loss_fp: 0.002244, loss_freq: 0.014831
[13:12:16.261] iteration 7217: loss: 0.135653, loss_s1: 0.073383, loss_fp: 0.001264, loss_freq: 0.080935
[13:12:16.902] iteration 7218: loss: 0.077718, loss_s1: 0.029621, loss_fp: 0.000901, loss_freq: 0.029389
[13:12:17.546] iteration 7219: loss: 0.073015, loss_s1: 0.016908, loss_fp: 0.004567, loss_freq: 0.018189
[13:12:18.191] iteration 7220: loss: 0.130532, loss_s1: 0.012747, loss_fp: 0.000619, loss_freq: 0.045284
[13:12:18.850] iteration 7221: loss: 0.091292, loss_s1: 0.066486, loss_fp: 0.001732, loss_freq: 0.026179
[13:12:19.482] iteration 7222: loss: 0.073856, loss_s1: 0.030543, loss_fp: 0.009633, loss_freq: 0.024238
[13:12:20.121] iteration 7223: loss: 0.080569, loss_s1: 0.029362, loss_fp: 0.002947, loss_freq: 0.062175
[13:12:20.754] iteration 7224: loss: 0.133431, loss_s1: 0.144608, loss_fp: 0.002222, loss_freq: 0.020132
[13:12:21.395] iteration 7225: loss: 0.110744, loss_s1: 0.075034, loss_fp: 0.002757, loss_freq: 0.075490
[13:12:22.027] iteration 7226: loss: 0.096675, loss_s1: 0.055594, loss_fp: 0.000892, loss_freq: 0.015371
[13:12:22.673] iteration 7227: loss: 0.066147, loss_s1: 0.067668, loss_fp: 0.001687, loss_freq: 0.011830
[13:12:23.315] iteration 7228: loss: 0.107638, loss_s1: 0.039562, loss_fp: 0.000759, loss_freq: 0.011684
[13:12:23.952] iteration 7229: loss: 0.112011, loss_s1: 0.073811, loss_fp: 0.007582, loss_freq: 0.053504
[13:12:24.600] iteration 7230: loss: 0.253574, loss_s1: 0.046982, loss_fp: 0.001190, loss_freq: 0.080364
[13:12:25.246] iteration 7231: loss: 0.079802, loss_s1: 0.047771, loss_fp: 0.001270, loss_freq: 0.014946
[13:12:25.882] iteration 7232: loss: 0.097821, loss_s1: 0.074664, loss_fp: 0.001313, loss_freq: 0.038487
[13:12:26.527] iteration 7233: loss: 0.097362, loss_s1: 0.032965, loss_fp: 0.001010, loss_freq: 0.013450
[13:12:27.158] iteration 7234: loss: 0.053979, loss_s1: 0.041084, loss_fp: 0.000967, loss_freq: 0.011250
[13:12:27.796] iteration 7235: loss: 0.123946, loss_s1: 0.077659, loss_fp: 0.002636, loss_freq: 0.025743
[13:12:28.443] iteration 7236: loss: 0.089314, loss_s1: 0.054048, loss_fp: 0.001528, loss_freq: 0.058574
[13:12:29.088] iteration 7237: loss: 0.113635, loss_s1: 0.033593, loss_fp: 0.010681, loss_freq: 0.030820
[13:12:29.727] iteration 7238: loss: 0.084635, loss_s1: 0.017581, loss_fp: 0.000557, loss_freq: 0.007034
[13:12:30.362] iteration 7239: loss: 0.114305, loss_s1: 0.052847, loss_fp: 0.001249, loss_freq: 0.037815
[13:12:31.015] iteration 7240: loss: 0.075053, loss_s1: 0.031984, loss_fp: 0.004877, loss_freq: 0.040472
[13:12:31.658] iteration 7241: loss: 0.109017, loss_s1: 0.026250, loss_fp: 0.001266, loss_freq: 0.023925
[13:12:32.293] iteration 7242: loss: 0.119733, loss_s1: 0.061823, loss_fp: 0.001281, loss_freq: 0.075933
[13:12:32.927] iteration 7243: loss: 0.069765, loss_s1: 0.047345, loss_fp: 0.002460, loss_freq: 0.027370
[13:12:33.557] iteration 7244: loss: 0.088346, loss_s1: 0.039420, loss_fp: 0.001620, loss_freq: 0.019881
[13:12:34.201] iteration 7245: loss: 0.071144, loss_s1: 0.013902, loss_fp: 0.000678, loss_freq: 0.029808
[13:12:34.881] iteration 7246: loss: 0.075269, loss_s1: 0.010559, loss_fp: 0.000959, loss_freq: 0.020351
[13:12:35.673] iteration 7247: loss: 0.122113, loss_s1: 0.096406, loss_fp: 0.003604, loss_freq: 0.056301
[13:12:36.376] iteration 7248: loss: 0.070324, loss_s1: 0.045369, loss_fp: 0.012337, loss_freq: 0.016972
[13:12:37.060] iteration 7249: loss: 0.106794, loss_s1: 0.032659, loss_fp: 0.001574, loss_freq: 0.050498
[13:12:37.705] iteration 7250: loss: 0.115923, loss_s1: 0.050938, loss_fp: 0.001752, loss_freq: 0.067895
[13:12:38.352] iteration 7251: loss: 0.183351, loss_s1: 0.069593, loss_fp: 0.003216, loss_freq: 0.111305
[13:12:39.002] iteration 7252: loss: 0.069716, loss_s1: 0.023447, loss_fp: 0.001860, loss_freq: 0.017670
[13:12:39.683] iteration 7253: loss: 0.064929, loss_s1: 0.021536, loss_fp: 0.000558, loss_freq: 0.014291
[13:12:40.317] iteration 7254: loss: 0.090588, loss_s1: 0.061347, loss_fp: 0.005411, loss_freq: 0.028333
[13:12:40.992] iteration 7255: loss: 0.140866, loss_s1: 0.043496, loss_fp: 0.003598, loss_freq: 0.042105
[13:12:41.625] iteration 7256: loss: 0.080769, loss_s1: 0.048450, loss_fp: 0.002136, loss_freq: 0.021699
[13:12:42.260] iteration 7257: loss: 0.191106, loss_s1: 0.155691, loss_fp: 0.013271, loss_freq: 0.127250
[13:12:42.897] iteration 7258: loss: 0.096603, loss_s1: 0.056387, loss_fp: 0.001527, loss_freq: 0.045491
[13:12:43.556] iteration 7259: loss: 0.083999, loss_s1: 0.028730, loss_fp: 0.000575, loss_freq: 0.006387
[13:12:44.192] iteration 7260: loss: 0.156940, loss_s1: 0.107713, loss_fp: 0.025739, loss_freq: 0.084656
[13:12:44.840] iteration 7261: loss: 0.122787, loss_s1: 0.045759, loss_fp: 0.000995, loss_freq: 0.062969
[13:12:45.502] iteration 7262: loss: 0.063010, loss_s1: 0.037591, loss_fp: 0.001331, loss_freq: 0.027458
[13:12:46.159] iteration 7263: loss: 0.116945, loss_s1: 0.072211, loss_fp: 0.003397, loss_freq: 0.010958
[13:12:46.797] iteration 7264: loss: 0.095409, loss_s1: 0.099614, loss_fp: 0.003835, loss_freq: 0.009632
[13:12:47.432] iteration 7265: loss: 0.227083, loss_s1: 0.105393, loss_fp: 0.003678, loss_freq: 0.058139
[13:12:48.073] iteration 7266: loss: 0.062903, loss_s1: 0.039831, loss_fp: 0.001449, loss_freq: 0.014612
[13:12:48.730] iteration 7267: loss: 0.133292, loss_s1: 0.026111, loss_fp: 0.003492, loss_freq: 0.063744
[13:12:49.369] iteration 7268: loss: 0.105588, loss_s1: 0.036899, loss_fp: 0.001386, loss_freq: 0.037636
[13:12:50.025] iteration 7269: loss: 0.154360, loss_s1: 0.206085, loss_fp: 0.001162, loss_freq: 0.036119
[13:12:50.664] iteration 7270: loss: 0.073603, loss_s1: 0.030282, loss_fp: 0.000455, loss_freq: 0.023499
[13:12:51.314] iteration 7271: loss: 0.115635, loss_s1: 0.073782, loss_fp: 0.001546, loss_freq: 0.059986
[13:12:51.963] iteration 7272: loss: 0.143238, loss_s1: 0.091775, loss_fp: 0.002206, loss_freq: 0.020515
[13:12:52.605] iteration 7273: loss: 0.089043, loss_s1: 0.018583, loss_fp: 0.001834, loss_freq: 0.018667
[13:12:53.244] iteration 7274: loss: 0.091095, loss_s1: 0.067468, loss_fp: 0.002586, loss_freq: 0.036498
[13:12:53.880] iteration 7275: loss: 0.086389, loss_s1: 0.045668, loss_fp: 0.003676, loss_freq: 0.044679
[13:12:54.528] iteration 7276: loss: 0.097947, loss_s1: 0.030773, loss_fp: 0.000753, loss_freq: 0.021968
[13:12:55.167] iteration 7277: loss: 0.076923, loss_s1: 0.050954, loss_fp: 0.000869, loss_freq: 0.022083
[13:12:55.816] iteration 7278: loss: 0.059207, loss_s1: 0.035245, loss_fp: 0.005491, loss_freq: 0.026212
[13:12:56.494] iteration 7279: loss: 0.139005, loss_s1: 0.091896, loss_fp: 0.003258, loss_freq: 0.033627
[13:12:57.170] iteration 7280: loss: 0.053177, loss_s1: 0.022367, loss_fp: 0.000872, loss_freq: 0.009497
[13:12:57.839] iteration 7281: loss: 0.094275, loss_s1: 0.041502, loss_fp: 0.033081, loss_freq: 0.012084
[13:12:58.516] iteration 7282: loss: 0.153757, loss_s1: 0.095601, loss_fp: 0.008420, loss_freq: 0.041738
[13:12:59.193] iteration 7283: loss: 0.109918, loss_s1: 0.089764, loss_fp: 0.001305, loss_freq: 0.019508
[13:12:59.867] iteration 7284: loss: 0.127993, loss_s1: 0.027664, loss_fp: 0.001485, loss_freq: 0.053633
[13:13:00.505] iteration 7285: loss: 0.112312, loss_s1: 0.037676, loss_fp: 0.002176, loss_freq: 0.030109
[13:13:01.146] iteration 7286: loss: 0.094067, loss_s1: 0.034249, loss_fp: 0.002716, loss_freq: 0.011909
[13:13:01.775] iteration 7287: loss: 0.066084, loss_s1: 0.035752, loss_fp: 0.003740, loss_freq: 0.015433
[13:13:02.406] iteration 7288: loss: 0.075497, loss_s1: 0.020544, loss_fp: 0.001345, loss_freq: 0.007307
[13:13:03.080] iteration 7289: loss: 0.080541, loss_s1: 0.037626, loss_fp: 0.001754, loss_freq: 0.026923
[13:13:03.707] iteration 7290: loss: 0.134850, loss_s1: 0.033538, loss_fp: 0.001678, loss_freq: 0.019910
[13:13:04.334] iteration 7291: loss: 0.092227, loss_s1: 0.054658, loss_fp: 0.002752, loss_freq: 0.031229
[13:13:04.958] iteration 7292: loss: 0.087755, loss_s1: 0.033856, loss_fp: 0.023193, loss_freq: 0.028352
[13:13:05.591] iteration 7293: loss: 0.066153, loss_s1: 0.033571, loss_fp: 0.003092, loss_freq: 0.028298
[13:13:06.623] iteration 7294: loss: 0.072027, loss_s1: 0.044620, loss_fp: 0.003582, loss_freq: 0.009557
[13:13:07.256] iteration 7295: loss: 0.092968, loss_s1: 0.052180, loss_fp: 0.006779, loss_freq: 0.039073
[13:13:07.891] iteration 7296: loss: 0.067384, loss_s1: 0.020733, loss_fp: 0.001377, loss_freq: 0.033260
[13:13:08.527] iteration 7297: loss: 0.091210, loss_s1: 0.046391, loss_fp: 0.002526, loss_freq: 0.019834
[13:13:09.175] iteration 7298: loss: 0.080636, loss_s1: 0.047835, loss_fp: 0.008162, loss_freq: 0.029511
[13:13:09.817] iteration 7299: loss: 0.107483, loss_s1: 0.021622, loss_fp: 0.001375, loss_freq: 0.004411
[13:13:10.457] iteration 7300: loss: 0.099309, loss_s1: 0.097899, loss_fp: 0.006811, loss_freq: 0.051473
[13:13:11.108] iteration 7301: loss: 0.128080, loss_s1: 0.055333, loss_fp: 0.001416, loss_freq: 0.032716
[13:13:11.740] iteration 7302: loss: 0.097750, loss_s1: 0.050640, loss_fp: 0.003169, loss_freq: 0.038633
[13:13:12.373] iteration 7303: loss: 0.149441, loss_s1: 0.078700, loss_fp: 0.001646, loss_freq: 0.050940
[13:13:13.006] iteration 7304: loss: 0.123234, loss_s1: 0.052095, loss_fp: 0.001345, loss_freq: 0.059688
[13:13:13.642] iteration 7305: loss: 0.115941, loss_s1: 0.084163, loss_fp: 0.001716, loss_freq: 0.061319
[13:13:14.276] iteration 7306: loss: 0.075127, loss_s1: 0.053724, loss_fp: 0.001406, loss_freq: 0.004482
[13:13:14.914] iteration 7307: loss: 0.067194, loss_s1: 0.025600, loss_fp: 0.007262, loss_freq: 0.012815
[13:13:15.557] iteration 7308: loss: 0.093365, loss_s1: 0.073218, loss_fp: 0.001037, loss_freq: 0.022864
[13:13:16.194] iteration 7309: loss: 0.076435, loss_s1: 0.032147, loss_fp: 0.000896, loss_freq: 0.021886
[13:13:16.886] iteration 7310: loss: 0.102862, loss_s1: 0.040283, loss_fp: 0.002203, loss_freq: 0.018291
[13:13:17.569] iteration 7311: loss: 0.108132, loss_s1: 0.031691, loss_fp: 0.005477, loss_freq: 0.005782
[13:13:18.204] iteration 7312: loss: 0.101790, loss_s1: 0.063380, loss_fp: 0.002226, loss_freq: 0.045314
[13:13:18.839] iteration 7313: loss: 0.091824, loss_s1: 0.041173, loss_fp: 0.001267, loss_freq: 0.022302
[13:13:19.476] iteration 7314: loss: 0.151247, loss_s1: 0.048740, loss_fp: 0.001632, loss_freq: 0.102696
[13:13:20.111] iteration 7315: loss: 0.113771, loss_s1: 0.069219, loss_fp: 0.001833, loss_freq: 0.027703
[13:13:20.755] iteration 7316: loss: 0.088484, loss_s1: 0.065050, loss_fp: 0.006674, loss_freq: 0.035222
[13:13:21.397] iteration 7317: loss: 0.103067, loss_s1: 0.048608, loss_fp: 0.003607, loss_freq: 0.011653
[13:13:22.036] iteration 7318: loss: 0.079183, loss_s1: 0.040000, loss_fp: 0.003542, loss_freq: 0.035179
[13:13:22.692] iteration 7319: loss: 0.124869, loss_s1: 0.077194, loss_fp: 0.006773, loss_freq: 0.015790
[13:13:23.341] iteration 7320: loss: 0.117210, loss_s1: 0.041882, loss_fp: 0.000879, loss_freq: 0.048112
[13:13:23.999] iteration 7321: loss: 0.072731, loss_s1: 0.043871, loss_fp: 0.003673, loss_freq: 0.018600
[13:13:24.638] iteration 7322: loss: 0.189541, loss_s1: 0.098182, loss_fp: 0.003270, loss_freq: 0.082209
[13:13:25.293] iteration 7323: loss: 0.111066, loss_s1: 0.026055, loss_fp: 0.001468, loss_freq: 0.019432
[13:13:25.953] iteration 7324: loss: 0.078405, loss_s1: 0.028989, loss_fp: 0.006488, loss_freq: 0.012110
[13:13:26.586] iteration 7325: loss: 0.077799, loss_s1: 0.044983, loss_fp: 0.003518, loss_freq: 0.017151
[13:13:27.252] iteration 7326: loss: 0.098493, loss_s1: 0.067043, loss_fp: 0.000901, loss_freq: 0.018047
[13:13:27.880] iteration 7327: loss: 0.068038, loss_s1: 0.032550, loss_fp: 0.005238, loss_freq: 0.032126
[13:13:28.512] iteration 7328: loss: 0.123909, loss_s1: 0.049987, loss_fp: 0.001685, loss_freq: 0.030985
[13:13:29.147] iteration 7329: loss: 0.127303, loss_s1: 0.075089, loss_fp: 0.004056, loss_freq: 0.041791
[13:13:29.786] iteration 7330: loss: 0.096349, loss_s1: 0.069874, loss_fp: 0.008002, loss_freq: 0.031541
[13:13:30.423] iteration 7331: loss: 0.070997, loss_s1: 0.024426, loss_fp: 0.003247, loss_freq: 0.017874
[13:13:31.058] iteration 7332: loss: 0.130266, loss_s1: 0.047865, loss_fp: 0.003646, loss_freq: 0.048966
[13:13:31.691] iteration 7333: loss: 0.077165, loss_s1: 0.040838, loss_fp: 0.001623, loss_freq: 0.012704
[13:13:32.327] iteration 7334: loss: 0.137898, loss_s1: 0.076706, loss_fp: 0.009611, loss_freq: 0.052511
[13:13:32.967] iteration 7335: loss: 0.058418, loss_s1: 0.028707, loss_fp: 0.001433, loss_freq: 0.027195
[13:13:33.610] iteration 7336: loss: 0.100050, loss_s1: 0.024108, loss_fp: 0.002288, loss_freq: 0.011357
[13:13:34.281] iteration 7337: loss: 0.067833, loss_s1: 0.053254, loss_fp: 0.005327, loss_freq: 0.015860
[13:13:34.954] iteration 7338: loss: 0.147202, loss_s1: 0.030640, loss_fp: 0.001376, loss_freq: 0.066753
[13:13:35.631] iteration 7339: loss: 0.079653, loss_s1: 0.036887, loss_fp: 0.004008, loss_freq: 0.027250
[13:13:36.279] iteration 7340: loss: 0.081727, loss_s1: 0.050902, loss_fp: 0.000733, loss_freq: 0.030603
[13:13:36.907] iteration 7341: loss: 0.109490, loss_s1: 0.057738, loss_fp: 0.004316, loss_freq: 0.044281
[13:13:37.538] iteration 7342: loss: 0.052896, loss_s1: 0.030009, loss_fp: 0.000843, loss_freq: 0.021338
[13:13:38.164] iteration 7343: loss: 0.117384, loss_s1: 0.083628, loss_fp: 0.003570, loss_freq: 0.067461
[13:13:38.799] iteration 7344: loss: 0.066711, loss_s1: 0.021678, loss_fp: 0.006614, loss_freq: 0.018508
[13:13:39.463] iteration 7345: loss: 0.188103, loss_s1: 0.037017, loss_fp: 0.001471, loss_freq: 0.038656
[13:13:40.101] iteration 7346: loss: 0.079676, loss_s1: 0.046088, loss_fp: 0.000264, loss_freq: 0.006669
[13:13:40.732] iteration 7347: loss: 0.067409, loss_s1: 0.051710, loss_fp: 0.002209, loss_freq: 0.007247
[13:13:41.372] iteration 7348: loss: 0.076496, loss_s1: 0.036760, loss_fp: 0.001501, loss_freq: 0.055312
[13:13:42.000] iteration 7349: loss: 0.177924, loss_s1: 0.061239, loss_fp: 0.002377, loss_freq: 0.019782
[13:13:42.633] iteration 7350: loss: 0.078253, loss_s1: 0.073909, loss_fp: 0.001450, loss_freq: 0.021947
[13:13:43.275] iteration 7351: loss: 0.078770, loss_s1: 0.040675, loss_fp: 0.016126, loss_freq: 0.022806
[13:13:43.908] iteration 7352: loss: 0.106445, loss_s1: 0.044856, loss_fp: 0.001677, loss_freq: 0.080493
[13:13:44.543] iteration 7353: loss: 0.071250, loss_s1: 0.032575, loss_fp: 0.002133, loss_freq: 0.019117
[13:13:45.184] iteration 7354: loss: 0.090693, loss_s1: 0.057925, loss_fp: 0.005525, loss_freq: 0.010249
[13:13:45.821] iteration 7355: loss: 0.078616, loss_s1: 0.058008, loss_fp: 0.006456, loss_freq: 0.013231
[13:13:46.462] iteration 7356: loss: 0.123287, loss_s1: 0.055983, loss_fp: 0.003004, loss_freq: 0.067104
[13:13:47.100] iteration 7357: loss: 0.096100, loss_s1: 0.032328, loss_fp: 0.001060, loss_freq: 0.023454
[13:13:47.737] iteration 7358: loss: 0.096239, loss_s1: 0.032938, loss_fp: 0.005150, loss_freq: 0.029046
[13:13:48.392] iteration 7359: loss: 0.152050, loss_s1: 0.089796, loss_fp: 0.005791, loss_freq: 0.015124
[13:13:49.022] iteration 7360: loss: 0.187425, loss_s1: 0.173039, loss_fp: 0.002094, loss_freq: 0.064761
[13:13:49.655] iteration 7361: loss: 0.064899, loss_s1: 0.032232, loss_fp: 0.001995, loss_freq: 0.015978
[13:13:50.333] iteration 7362: loss: 0.098108, loss_s1: 0.060590, loss_fp: 0.001710, loss_freq: 0.016567
[13:13:50.969] iteration 7363: loss: 0.163036, loss_s1: 0.045934, loss_fp: 0.004386, loss_freq: 0.011721
[13:13:51.623] iteration 7364: loss: 0.084462, loss_s1: 0.011087, loss_fp: 0.001476, loss_freq: 0.029260
[13:13:52.262] iteration 7365: loss: 0.123398, loss_s1: 0.110124, loss_fp: 0.001488, loss_freq: 0.045759
[13:13:52.895] iteration 7366: loss: 0.102279, loss_s1: 0.042529, loss_fp: 0.000905, loss_freq: 0.081003
[13:13:53.551] iteration 7367: loss: 0.115225, loss_s1: 0.046976, loss_fp: 0.001157, loss_freq: 0.029381
[13:13:54.214] iteration 7368: loss: 0.089479, loss_s1: 0.031151, loss_fp: 0.007767, loss_freq: 0.039070
[13:13:54.883] iteration 7369: loss: 0.108833, loss_s1: 0.062990, loss_fp: 0.010866, loss_freq: 0.007608
[13:13:55.565] iteration 7370: loss: 0.053775, loss_s1: 0.026881, loss_fp: 0.003667, loss_freq: 0.015414
[13:13:56.254] iteration 7371: loss: 0.134949, loss_s1: 0.072091, loss_fp: 0.002341, loss_freq: 0.037203
[13:13:56.923] iteration 7372: loss: 0.076592, loss_s1: 0.048878, loss_fp: 0.003660, loss_freq: 0.034514
[13:13:57.625] iteration 7373: loss: 0.261323, loss_s1: 0.074914, loss_fp: 0.003215, loss_freq: 0.080521
[13:13:58.334] iteration 7374: loss: 0.080633, loss_s1: 0.045491, loss_fp: 0.005270, loss_freq: 0.023251
[13:13:59.023] iteration 7375: loss: 0.100782, loss_s1: 0.067597, loss_fp: 0.002763, loss_freq: 0.029053
[13:13:59.704] iteration 7376: loss: 0.139575, loss_s1: 0.056932, loss_fp: 0.001184, loss_freq: 0.018892
[13:14:00.394] iteration 7377: loss: 0.050336, loss_s1: 0.026905, loss_fp: 0.002241, loss_freq: 0.010982
[13:14:01.055] iteration 7378: loss: 0.105174, loss_s1: 0.042640, loss_fp: 0.000939, loss_freq: 0.019453
[13:14:01.694] iteration 7379: loss: 0.112873, loss_s1: 0.062208, loss_fp: 0.003286, loss_freq: 0.047377
[13:14:02.343] iteration 7380: loss: 0.122402, loss_s1: 0.041559, loss_fp: 0.009026, loss_freq: 0.015744
[13:14:02.988] iteration 7381: loss: 0.077850, loss_s1: 0.024204, loss_fp: 0.000738, loss_freq: 0.021123
[13:14:03.632] iteration 7382: loss: 0.067725, loss_s1: 0.033858, loss_fp: 0.003167, loss_freq: 0.020715
[13:14:04.270] iteration 7383: loss: 0.111125, loss_s1: 0.086999, loss_fp: 0.007106, loss_freq: 0.054586
[13:14:04.914] iteration 7384: loss: 0.111116, loss_s1: 0.010879, loss_fp: 0.001294, loss_freq: 0.032289
[13:14:05.560] iteration 7385: loss: 0.100451, loss_s1: 0.055883, loss_fp: 0.006820, loss_freq: 0.041278
[13:14:06.202] iteration 7386: loss: 0.060260, loss_s1: 0.034845, loss_fp: 0.006210, loss_freq: 0.013885
[13:14:06.845] iteration 7387: loss: 0.142936, loss_s1: 0.042439, loss_fp: 0.001241, loss_freq: 0.025733
[13:14:07.510] iteration 7388: loss: 0.063293, loss_s1: 0.030134, loss_fp: 0.000663, loss_freq: 0.017624
[13:14:08.175] iteration 7389: loss: 0.098169, loss_s1: 0.045960, loss_fp: 0.002049, loss_freq: 0.033547
[13:14:08.857] iteration 7390: loss: 0.170168, loss_s1: 0.136679, loss_fp: 0.001830, loss_freq: 0.066990
[13:14:09.556] iteration 7391: loss: 0.119990, loss_s1: 0.037438, loss_fp: 0.001425, loss_freq: 0.064651
[13:14:10.203] iteration 7392: loss: 0.086649, loss_s1: 0.031534, loss_fp: 0.000806, loss_freq: 0.037306
[13:14:10.871] iteration 7393: loss: 0.122878, loss_s1: 0.072046, loss_fp: 0.004010, loss_freq: 0.058472
[13:14:11.590] iteration 7394: loss: 0.156770, loss_s1: 0.106224, loss_fp: 0.001679, loss_freq: 0.089790
[13:14:12.288] iteration 7395: loss: 0.073153, loss_s1: 0.018109, loss_fp: 0.000915, loss_freq: 0.010068
[13:14:12.976] iteration 7396: loss: 0.105497, loss_s1: 0.067091, loss_fp: 0.001268, loss_freq: 0.009665
[13:14:13.674] iteration 7397: loss: 0.092989, loss_s1: 0.034652, loss_fp: 0.002950, loss_freq: 0.032460
[13:14:14.337] iteration 7398: loss: 0.109749, loss_s1: 0.022420, loss_fp: 0.008479, loss_freq: 0.036596
[13:14:15.056] iteration 7399: loss: 0.073626, loss_s1: 0.036196, loss_fp: 0.002542, loss_freq: 0.022790
[13:14:15.758] iteration 7400: loss: 0.192513, loss_s1: 0.156323, loss_fp: 0.004544, loss_freq: 0.132520
[13:14:19.088] iteration 7400 : mean_dice : 0.742606
[13:14:19.796] iteration 7401: loss: 0.059770, loss_s1: 0.019022, loss_fp: 0.004876, loss_freq: 0.018764
[13:14:20.486] iteration 7402: loss: 0.078712, loss_s1: 0.023546, loss_fp: 0.001348, loss_freq: 0.005255
[13:14:21.154] iteration 7403: loss: 0.103702, loss_s1: 0.034706, loss_fp: 0.003670, loss_freq: 0.020587
[13:14:21.823] iteration 7404: loss: 0.081975, loss_s1: 0.026906, loss_fp: 0.000694, loss_freq: 0.008046
[13:14:22.465] iteration 7405: loss: 0.058332, loss_s1: 0.009972, loss_fp: 0.002016, loss_freq: 0.050901
[13:14:23.112] iteration 7406: loss: 0.082144, loss_s1: 0.023330, loss_fp: 0.000772, loss_freq: 0.017479
[13:14:23.750] iteration 7407: loss: 0.073433, loss_s1: 0.050991, loss_fp: 0.001918, loss_freq: 0.026827
[13:14:24.383] iteration 7408: loss: 0.183932, loss_s1: 0.053293, loss_fp: 0.001098, loss_freq: 0.076312
[13:14:25.014] iteration 7409: loss: 0.065684, loss_s1: 0.043123, loss_fp: 0.003450, loss_freq: 0.010716
[13:14:25.657] iteration 7410: loss: 0.088234, loss_s1: 0.063471, loss_fp: 0.005281, loss_freq: 0.022927
[13:14:26.336] iteration 7411: loss: 0.113713, loss_s1: 0.105320, loss_fp: 0.005646, loss_freq: 0.027495
[13:14:27.008] iteration 7412: loss: 0.091665, loss_s1: 0.049356, loss_fp: 0.013989, loss_freq: 0.067063
[13:14:27.683] iteration 7413: loss: 0.083395, loss_s1: 0.033743, loss_fp: 0.005261, loss_freq: 0.054005
[13:14:28.360] iteration 7414: loss: 0.130580, loss_s1: 0.080117, loss_fp: 0.001212, loss_freq: 0.049855
[13:14:29.029] iteration 7415: loss: 0.146016, loss_s1: 0.066644, loss_fp: 0.007497, loss_freq: 0.024004
[13:14:29.703] iteration 7416: loss: 0.104271, loss_s1: 0.001969, loss_fp: 0.003542, loss_freq: 0.012391
[13:14:30.384] iteration 7417: loss: 0.072025, loss_s1: 0.028046, loss_fp: 0.006612, loss_freq: 0.023759
[13:14:31.030] iteration 7418: loss: 0.065712, loss_s1: 0.040855, loss_fp: 0.014277, loss_freq: 0.028692
[13:14:31.678] iteration 7419: loss: 0.218918, loss_s1: 0.086143, loss_fp: 0.004129, loss_freq: 0.031567
[13:14:32.343] iteration 7420: loss: 0.088053, loss_s1: 0.024327, loss_fp: 0.000834, loss_freq: 0.060480
[13:14:32.981] iteration 7421: loss: 0.057215, loss_s1: 0.034717, loss_fp: 0.000645, loss_freq: 0.008344
[13:14:33.627] iteration 7422: loss: 0.121847, loss_s1: 0.058081, loss_fp: 0.000930, loss_freq: 0.043257
[13:14:34.291] iteration 7423: loss: 0.078360, loss_s1: 0.058043, loss_fp: 0.004103, loss_freq: 0.014504
[13:14:34.932] iteration 7424: loss: 0.128624, loss_s1: 0.055732, loss_fp: 0.003405, loss_freq: 0.009536
[13:14:35.585] iteration 7425: loss: 0.140900, loss_s1: 0.057857, loss_fp: 0.002974, loss_freq: 0.019210
[13:14:36.226] iteration 7426: loss: 0.071293, loss_s1: 0.041379, loss_fp: 0.001601, loss_freq: 0.020733
[13:14:36.862] iteration 7427: loss: 0.123545, loss_s1: 0.026143, loss_fp: 0.005255, loss_freq: 0.080196
[13:14:37.501] iteration 7428: loss: 0.165237, loss_s1: 0.069260, loss_fp: 0.002041, loss_freq: 0.031507
[13:14:38.137] iteration 7429: loss: 0.096357, loss_s1: 0.090729, loss_fp: 0.000950, loss_freq: 0.014880
[13:14:38.776] iteration 7430: loss: 0.103647, loss_s1: 0.093799, loss_fp: 0.003022, loss_freq: 0.018512
[13:14:39.440] iteration 7431: loss: 0.107543, loss_s1: 0.012348, loss_fp: 0.000948, loss_freq: 0.013590
[13:14:40.130] iteration 7432: loss: 0.065500, loss_s1: 0.038165, loss_fp: 0.001683, loss_freq: 0.019451
[13:14:40.896] iteration 7433: loss: 0.125868, loss_s1: 0.067819, loss_fp: 0.001375, loss_freq: 0.027018
[13:14:41.573] iteration 7434: loss: 0.099103, loss_s1: 0.062654, loss_fp: 0.002490, loss_freq: 0.032867
[13:14:42.211] iteration 7435: loss: 0.134966, loss_s1: 0.129559, loss_fp: 0.012797, loss_freq: 0.028990
[13:14:42.845] iteration 7436: loss: 0.066432, loss_s1: 0.025649, loss_fp: 0.002446, loss_freq: 0.035047
[13:14:43.785] iteration 7437: loss: 0.065089, loss_s1: 0.026478, loss_fp: 0.000662, loss_freq: 0.010343
[13:14:44.427] iteration 7438: loss: 0.096427, loss_s1: 0.046723, loss_fp: 0.007903, loss_freq: 0.030592
[13:14:45.073] iteration 7439: loss: 0.074311, loss_s1: 0.037898, loss_fp: 0.001269, loss_freq: 0.036542
[13:14:45.718] iteration 7440: loss: 0.126252, loss_s1: 0.119844, loss_fp: 0.001341, loss_freq: 0.023468
[13:14:46.348] iteration 7441: loss: 0.105568, loss_s1: 0.074886, loss_fp: 0.001676, loss_freq: 0.046739
[13:14:46.989] iteration 7442: loss: 0.093879, loss_s1: 0.025703, loss_fp: 0.001052, loss_freq: 0.001534
[13:14:47.624] iteration 7443: loss: 0.071044, loss_s1: 0.032982, loss_fp: 0.003074, loss_freq: 0.053416
[13:14:48.255] iteration 7444: loss: 0.140567, loss_s1: 0.063752, loss_fp: 0.001510, loss_freq: 0.024463
[13:14:48.893] iteration 7445: loss: 0.109794, loss_s1: 0.067015, loss_fp: 0.002038, loss_freq: 0.055487
[13:14:49.534] iteration 7446: loss: 0.138380, loss_s1: 0.027346, loss_fp: 0.001444, loss_freq: 0.015509
[13:14:50.174] iteration 7447: loss: 0.114941, loss_s1: 0.030524, loss_fp: 0.001702, loss_freq: 0.067527
[13:14:50.809] iteration 7448: loss: 0.085450, loss_s1: 0.026186, loss_fp: 0.001232, loss_freq: 0.065871
[13:14:51.462] iteration 7449: loss: 0.096272, loss_s1: 0.077017, loss_fp: 0.000807, loss_freq: 0.020593
[13:14:52.103] iteration 7450: loss: 0.041510, loss_s1: 0.013579, loss_fp: 0.002727, loss_freq: 0.011852
[13:14:52.781] iteration 7451: loss: 0.084806, loss_s1: 0.056865, loss_fp: 0.000653, loss_freq: 0.049802
[13:14:53.426] iteration 7452: loss: 0.079012, loss_s1: 0.054009, loss_fp: 0.000664, loss_freq: 0.028459
[13:14:54.071] iteration 7453: loss: 0.114850, loss_s1: 0.014322, loss_fp: 0.000789, loss_freq: 0.029568
[13:14:54.707] iteration 7454: loss: 0.119075, loss_s1: 0.071328, loss_fp: 0.002805, loss_freq: 0.020531
[13:14:55.344] iteration 7455: loss: 0.066665, loss_s1: 0.028564, loss_fp: 0.000902, loss_freq: 0.012328
[13:14:55.980] iteration 7456: loss: 0.076551, loss_s1: 0.039960, loss_fp: 0.000967, loss_freq: 0.040172
[13:14:56.615] iteration 7457: loss: 0.158626, loss_s1: 0.028594, loss_fp: 0.003230, loss_freq: 0.018029
[13:14:57.257] iteration 7458: loss: 0.064543, loss_s1: 0.028449, loss_fp: 0.003300, loss_freq: 0.021872
[13:14:57.891] iteration 7459: loss: 0.077963, loss_s1: 0.078140, loss_fp: 0.002324, loss_freq: 0.012412
[13:14:58.524] iteration 7460: loss: 0.081626, loss_s1: 0.029175, loss_fp: 0.002041, loss_freq: 0.014753
[13:14:59.173] iteration 7461: loss: 0.090249, loss_s1: 0.029889, loss_fp: 0.001384, loss_freq: 0.065252
[13:14:59.817] iteration 7462: loss: 0.101827, loss_s1: 0.056183, loss_fp: 0.021491, loss_freq: 0.030302
[13:15:00.454] iteration 7463: loss: 0.077581, loss_s1: 0.025299, loss_fp: 0.004993, loss_freq: 0.045386
[13:15:01.088] iteration 7464: loss: 0.094552, loss_s1: 0.052390, loss_fp: 0.000697, loss_freq: 0.013037
[13:15:01.737] iteration 7465: loss: 0.102164, loss_s1: 0.022649, loss_fp: 0.002599, loss_freq: 0.031931
[13:15:02.395] iteration 7466: loss: 0.080312, loss_s1: 0.024430, loss_fp: 0.001119, loss_freq: 0.014673
[13:15:03.035] iteration 7467: loss: 0.079392, loss_s1: 0.011482, loss_fp: 0.003542, loss_freq: 0.020450
[13:15:03.681] iteration 7468: loss: 0.084464, loss_s1: 0.055773, loss_fp: 0.000665, loss_freq: 0.023325
[13:15:04.364] iteration 7469: loss: 0.064760, loss_s1: 0.018688, loss_fp: 0.002339, loss_freq: 0.021717
[13:15:05.007] iteration 7470: loss: 0.078583, loss_s1: 0.043793, loss_fp: 0.004078, loss_freq: 0.046608
[13:15:05.646] iteration 7471: loss: 0.116594, loss_s1: 0.041386, loss_fp: 0.002290, loss_freq: 0.041757
[13:15:06.294] iteration 7472: loss: 0.101637, loss_s1: 0.102859, loss_fp: 0.001660, loss_freq: 0.021453
[13:15:06.933] iteration 7473: loss: 0.097567, loss_s1: 0.069479, loss_fp: 0.004813, loss_freq: 0.034491
[13:15:07.599] iteration 7474: loss: 0.089623, loss_s1: 0.061044, loss_fp: 0.002232, loss_freq: 0.049493
[13:15:08.243] iteration 7475: loss: 0.151670, loss_s1: 0.065625, loss_fp: 0.003021, loss_freq: 0.028657
[13:15:08.910] iteration 7476: loss: 0.087617, loss_s1: 0.054019, loss_fp: 0.002502, loss_freq: 0.017785
[13:15:09.583] iteration 7477: loss: 0.132442, loss_s1: 0.049764, loss_fp: 0.003993, loss_freq: 0.050037
[13:15:10.258] iteration 7478: loss: 0.045586, loss_s1: 0.030534, loss_fp: 0.000438, loss_freq: 0.010516
[13:15:10.941] iteration 7479: loss: 0.094131, loss_s1: 0.045880, loss_fp: 0.001596, loss_freq: 0.007126
[13:15:11.606] iteration 7480: loss: 0.096621, loss_s1: 0.064764, loss_fp: 0.006861, loss_freq: 0.048923
[13:15:12.260] iteration 7481: loss: 0.154866, loss_s1: 0.093999, loss_fp: 0.000682, loss_freq: 0.045380
[13:15:12.899] iteration 7482: loss: 0.130698, loss_s1: 0.053402, loss_fp: 0.000795, loss_freq: 0.035814
[13:15:13.548] iteration 7483: loss: 0.076320, loss_s1: 0.020169, loss_fp: 0.004330, loss_freq: 0.044754
[13:15:14.187] iteration 7484: loss: 0.115993, loss_s1: 0.060746, loss_fp: 0.004471, loss_freq: 0.029384
[13:15:14.905] iteration 7485: loss: 0.045745, loss_s1: 0.036032, loss_fp: 0.002284, loss_freq: 0.005792
[13:15:15.595] iteration 7486: loss: 0.077430, loss_s1: 0.039563, loss_fp: 0.001148, loss_freq: 0.021783
[13:15:16.277] iteration 7487: loss: 0.059729, loss_s1: 0.026305, loss_fp: 0.001235, loss_freq: 0.022072
[13:15:16.968] iteration 7488: loss: 0.133381, loss_s1: 0.067097, loss_fp: 0.002827, loss_freq: 0.043830
[13:15:17.639] iteration 7489: loss: 0.078196, loss_s1: 0.035193, loss_fp: 0.009267, loss_freq: 0.006314
[13:15:18.284] iteration 7490: loss: 0.078294, loss_s1: 0.026862, loss_fp: 0.001397, loss_freq: 0.013214
[13:15:18.926] iteration 7491: loss: 0.062732, loss_s1: 0.035475, loss_fp: 0.002774, loss_freq: 0.040147
[13:15:19.611] iteration 7492: loss: 0.119159, loss_s1: 0.051297, loss_fp: 0.002451, loss_freq: 0.005843
[13:15:20.274] iteration 7493: loss: 0.050903, loss_s1: 0.013640, loss_fp: 0.002263, loss_freq: 0.011362
[13:15:20.946] iteration 7494: loss: 0.076239, loss_s1: 0.007233, loss_fp: 0.003493, loss_freq: 0.053630
[13:15:21.614] iteration 7495: loss: 0.100778, loss_s1: 0.061784, loss_fp: 0.003359, loss_freq: 0.029441
[13:15:22.279] iteration 7496: loss: 0.091272, loss_s1: 0.037014, loss_fp: 0.001504, loss_freq: 0.041461
[13:15:22.978] iteration 7497: loss: 0.078733, loss_s1: 0.037465, loss_fp: 0.003355, loss_freq: 0.013788
[13:15:23.655] iteration 7498: loss: 0.110661, loss_s1: 0.104046, loss_fp: 0.003146, loss_freq: 0.047062
[13:15:24.331] iteration 7499: loss: 0.099562, loss_s1: 0.027385, loss_fp: 0.002583, loss_freq: 0.089743
[13:15:25.011] iteration 7500: loss: 0.099964, loss_s1: 0.049767, loss_fp: 0.004257, loss_freq: 0.016026
[13:15:25.660] iteration 7501: loss: 0.087372, loss_s1: 0.031388, loss_fp: 0.002097, loss_freq: 0.020046
[13:15:26.295] iteration 7502: loss: 0.085573, loss_s1: 0.026569, loss_fp: 0.006224, loss_freq: 0.013964
[13:15:26.938] iteration 7503: loss: 0.161003, loss_s1: 0.159374, loss_fp: 0.002895, loss_freq: 0.052870
[13:15:27.572] iteration 7504: loss: 0.115260, loss_s1: 0.069957, loss_fp: 0.001686, loss_freq: 0.023585
[13:15:28.212] iteration 7505: loss: 0.107966, loss_s1: 0.129567, loss_fp: 0.006807, loss_freq: 0.015855
[13:15:28.848] iteration 7506: loss: 0.093524, loss_s1: 0.038735, loss_fp: 0.001412, loss_freq: 0.043844
[13:15:29.484] iteration 7507: loss: 0.094138, loss_s1: 0.061416, loss_fp: 0.002095, loss_freq: 0.025344
[13:15:30.119] iteration 7508: loss: 0.102724, loss_s1: 0.022543, loss_fp: 0.002489, loss_freq: 0.060405
[13:15:30.756] iteration 7509: loss: 0.083449, loss_s1: 0.045909, loss_fp: 0.003036, loss_freq: 0.042358
[13:15:31.391] iteration 7510: loss: 0.145974, loss_s1: 0.065260, loss_fp: 0.004179, loss_freq: 0.059345
[13:15:32.024] iteration 7511: loss: 0.085659, loss_s1: 0.047481, loss_fp: 0.002820, loss_freq: 0.042129
[13:15:32.668] iteration 7512: loss: 0.089381, loss_s1: 0.035840, loss_fp: 0.001916, loss_freq: 0.023813
[13:15:33.360] iteration 7513: loss: 0.084992, loss_s1: 0.063918, loss_fp: 0.001718, loss_freq: 0.016492
[13:15:34.004] iteration 7514: loss: 0.096489, loss_s1: 0.047413, loss_fp: 0.004250, loss_freq: 0.014334
[13:15:34.645] iteration 7515: loss: 0.073221, loss_s1: 0.045663, loss_fp: 0.004632, loss_freq: 0.021915
[13:15:35.293] iteration 7516: loss: 0.233611, loss_s1: 0.061560, loss_fp: 0.001794, loss_freq: 0.051266
[13:15:35.929] iteration 7517: loss: 0.086390, loss_s1: 0.065526, loss_fp: 0.000473, loss_freq: 0.022933
[13:15:36.570] iteration 7518: loss: 0.098786, loss_s1: 0.056676, loss_fp: 0.006940, loss_freq: 0.041629
[13:15:37.203] iteration 7519: loss: 0.101334, loss_s1: 0.014516, loss_fp: 0.001061, loss_freq: 0.024098
[13:15:37.839] iteration 7520: loss: 0.066265, loss_s1: 0.045166, loss_fp: 0.000338, loss_freq: 0.021053
[13:15:38.505] iteration 7521: loss: 0.081923, loss_s1: 0.041935, loss_fp: 0.001020, loss_freq: 0.021209
[13:15:39.181] iteration 7522: loss: 0.103114, loss_s1: 0.066659, loss_fp: 0.001633, loss_freq: 0.058755
[13:15:39.873] iteration 7523: loss: 0.152385, loss_s1: 0.020057, loss_fp: 0.002100, loss_freq: 0.025029
[13:15:40.542] iteration 7524: loss: 0.114002, loss_s1: 0.030773, loss_fp: 0.001647, loss_freq: 0.021332
[13:15:41.181] iteration 7525: loss: 0.072622, loss_s1: 0.041832, loss_fp: 0.001081, loss_freq: 0.024905
[13:15:41.812] iteration 7526: loss: 0.077949, loss_s1: 0.061485, loss_fp: 0.001346, loss_freq: 0.016267
[13:15:42.443] iteration 7527: loss: 0.084903, loss_s1: 0.029383, loss_fp: 0.002243, loss_freq: 0.017885
[13:15:43.074] iteration 7528: loss: 0.084072, loss_s1: 0.034207, loss_fp: 0.014315, loss_freq: 0.044002
[13:15:43.711] iteration 7529: loss: 0.058662, loss_s1: 0.040103, loss_fp: 0.000490, loss_freq: 0.007972
[13:15:44.335] iteration 7530: loss: 0.115979, loss_s1: 0.053066, loss_fp: 0.002493, loss_freq: 0.028069
[13:15:44.990] iteration 7531: loss: 0.062610, loss_s1: 0.016041, loss_fp: 0.001623, loss_freq: 0.012415
[13:15:45.618] iteration 7532: loss: 0.090794, loss_s1: 0.021986, loss_fp: 0.000555, loss_freq: 0.024116
[13:15:46.258] iteration 7533: loss: 0.101498, loss_s1: 0.061431, loss_fp: 0.002390, loss_freq: 0.038597
[13:15:46.893] iteration 7534: loss: 0.083573, loss_s1: 0.063518, loss_fp: 0.000811, loss_freq: 0.024769
[13:15:47.526] iteration 7535: loss: 0.110001, loss_s1: 0.030191, loss_fp: 0.003617, loss_freq: 0.044912
[13:15:48.178] iteration 7536: loss: 0.134424, loss_s1: 0.075150, loss_fp: 0.002847, loss_freq: 0.039482
[13:15:48.873] iteration 7537: loss: 0.099692, loss_s1: 0.020684, loss_fp: 0.001374, loss_freq: 0.054617
[13:15:49.509] iteration 7538: loss: 0.107198, loss_s1: 0.039819, loss_fp: 0.001067, loss_freq: 0.010586
[13:15:50.144] iteration 7539: loss: 0.141077, loss_s1: 0.058164, loss_fp: 0.001321, loss_freq: 0.025594
[13:15:50.785] iteration 7540: loss: 0.094876, loss_s1: 0.051184, loss_fp: 0.001758, loss_freq: 0.033380
[13:15:51.432] iteration 7541: loss: 0.084789, loss_s1: 0.023016, loss_fp: 0.002796, loss_freq: 0.025832
[13:15:52.074] iteration 7542: loss: 0.056777, loss_s1: 0.019445, loss_fp: 0.001030, loss_freq: 0.026011
[13:15:52.710] iteration 7543: loss: 0.102587, loss_s1: 0.054713, loss_fp: 0.004771, loss_freq: 0.055436
[13:15:53.348] iteration 7544: loss: 0.096168, loss_s1: 0.070615, loss_fp: 0.005443, loss_freq: 0.041941
[13:15:53.983] iteration 7545: loss: 0.103882, loss_s1: 0.072366, loss_fp: 0.005698, loss_freq: 0.004284
[13:15:54.622] iteration 7546: loss: 0.078366, loss_s1: 0.046825, loss_fp: 0.004846, loss_freq: 0.014514
[13:15:55.266] iteration 7547: loss: 0.113855, loss_s1: 0.058819, loss_fp: 0.006297, loss_freq: 0.020376
[13:15:55.895] iteration 7548: loss: 0.060243, loss_s1: 0.044069, loss_fp: 0.000701, loss_freq: 0.029323
[13:15:56.530] iteration 7549: loss: 0.095078, loss_s1: 0.046062, loss_fp: 0.001440, loss_freq: 0.011524
[13:15:57.168] iteration 7550: loss: 0.076434, loss_s1: 0.056320, loss_fp: 0.010449, loss_freq: 0.014657
[13:15:57.807] iteration 7551: loss: 0.161928, loss_s1: 0.048119, loss_fp: 0.000334, loss_freq: 0.027707
[13:15:58.456] iteration 7552: loss: 0.106000, loss_s1: 0.042100, loss_fp: 0.006938, loss_freq: 0.023799
[13:15:59.106] iteration 7553: loss: 0.124132, loss_s1: 0.060712, loss_fp: 0.002077, loss_freq: 0.066642
[13:15:59.779] iteration 7554: loss: 0.109507, loss_s1: 0.097442, loss_fp: 0.000867, loss_freq: 0.018602
[13:16:00.455] iteration 7555: loss: 0.080274, loss_s1: 0.068732, loss_fp: 0.001730, loss_freq: 0.041222
[13:16:01.127] iteration 7556: loss: 0.057420, loss_s1: 0.032464, loss_fp: 0.001459, loss_freq: 0.022381
[13:16:01.799] iteration 7557: loss: 0.164877, loss_s1: 0.152094, loss_fp: 0.003137, loss_freq: 0.080931
[13:16:02.486] iteration 7558: loss: 0.096932, loss_s1: 0.049382, loss_fp: 0.003078, loss_freq: 0.031454
[13:16:03.172] iteration 7559: loss: 0.093190, loss_s1: 0.041868, loss_fp: 0.004339, loss_freq: 0.049202
[13:16:03.828] iteration 7560: loss: 0.078457, loss_s1: 0.028951, loss_fp: 0.007314, loss_freq: 0.033722
[13:16:04.481] iteration 7561: loss: 0.152224, loss_s1: 0.058949, loss_fp: 0.004502, loss_freq: 0.107642
[13:16:05.135] iteration 7562: loss: 0.126723, loss_s1: 0.086370, loss_fp: 0.002341, loss_freq: 0.029391
[13:16:05.777] iteration 7563: loss: 0.079459, loss_s1: 0.042399, loss_fp: 0.001264, loss_freq: 0.017478
[13:16:06.422] iteration 7564: loss: 0.092650, loss_s1: 0.077332, loss_fp: 0.002560, loss_freq: 0.015850
[13:16:07.114] iteration 7565: loss: 0.132768, loss_s1: 0.029456, loss_fp: 0.002604, loss_freq: 0.019498
[13:16:07.811] iteration 7566: loss: 0.065169, loss_s1: 0.022021, loss_fp: 0.001462, loss_freq: 0.009605
[13:16:08.500] iteration 7567: loss: 0.091295, loss_s1: 0.058505, loss_fp: 0.004965, loss_freq: 0.018453
[13:16:09.172] iteration 7568: loss: 0.123790, loss_s1: 0.028004, loss_fp: 0.001984, loss_freq: 0.021268
[13:16:09.822] iteration 7569: loss: 0.069746, loss_s1: 0.016396, loss_fp: 0.014627, loss_freq: 0.025324
[13:16:10.481] iteration 7570: loss: 0.162264, loss_s1: 0.055330, loss_fp: 0.002222, loss_freq: 0.075859
[13:16:11.126] iteration 7571: loss: 0.139587, loss_s1: 0.077723, loss_fp: 0.003359, loss_freq: 0.030889
[13:16:11.778] iteration 7572: loss: 0.111719, loss_s1: 0.063152, loss_fp: 0.001422, loss_freq: 0.019490
[13:16:12.422] iteration 7573: loss: 0.105638, loss_s1: 0.087063, loss_fp: 0.006082, loss_freq: 0.016918
[13:16:13.066] iteration 7574: loss: 0.073989, loss_s1: 0.011690, loss_fp: 0.002211, loss_freq: 0.012044
[13:16:13.721] iteration 7575: loss: 0.066253, loss_s1: 0.037968, loss_fp: 0.003669, loss_freq: 0.014336
[13:16:14.372] iteration 7576: loss: 0.105749, loss_s1: 0.070359, loss_fp: 0.003402, loss_freq: 0.010072
[13:16:15.019] iteration 7577: loss: 0.090479, loss_s1: 0.047054, loss_fp: 0.001634, loss_freq: 0.047567
[13:16:15.675] iteration 7578: loss: 0.142159, loss_s1: 0.132076, loss_fp: 0.006083, loss_freq: 0.023199
[13:16:16.323] iteration 7579: loss: 0.065006, loss_s1: 0.014062, loss_fp: 0.001389, loss_freq: 0.041873
[13:16:17.293] iteration 7580: loss: 0.097148, loss_s1: 0.056832, loss_fp: 0.001220, loss_freq: 0.035770
[13:16:17.939] iteration 7581: loss: 0.066544, loss_s1: 0.028338, loss_fp: 0.003998, loss_freq: 0.021591
[13:16:18.585] iteration 7582: loss: 0.059616, loss_s1: 0.024345, loss_fp: 0.001804, loss_freq: 0.025988
[13:16:19.226] iteration 7583: loss: 0.113910, loss_s1: 0.087912, loss_fp: 0.003439, loss_freq: 0.025177
[13:16:19.862] iteration 7584: loss: 0.125468, loss_s1: 0.088810, loss_fp: 0.003843, loss_freq: 0.065876
[13:16:20.503] iteration 7585: loss: 0.091125, loss_s1: 0.017213, loss_fp: 0.001323, loss_freq: 0.007928
[13:16:21.140] iteration 7586: loss: 0.056135, loss_s1: 0.030606, loss_fp: 0.004048, loss_freq: 0.030090
[13:16:21.776] iteration 7587: loss: 0.146560, loss_s1: 0.063389, loss_fp: 0.002229, loss_freq: 0.033555
[13:16:22.427] iteration 7588: loss: 0.092626, loss_s1: 0.069258, loss_fp: 0.000801, loss_freq: 0.017425
[13:16:23.072] iteration 7589: loss: 0.140051, loss_s1: 0.029651, loss_fp: 0.000447, loss_freq: 0.056291
[13:16:23.720] iteration 7590: loss: 0.081828, loss_s1: 0.040771, loss_fp: 0.005999, loss_freq: 0.035818
[13:16:24.364] iteration 7591: loss: 0.077063, loss_s1: 0.022070, loss_fp: 0.002350, loss_freq: 0.034287
[13:16:25.002] iteration 7592: loss: 0.075777, loss_s1: 0.027235, loss_fp: 0.010081, loss_freq: 0.009317
[13:16:25.637] iteration 7593: loss: 0.048238, loss_s1: 0.023178, loss_fp: 0.000648, loss_freq: 0.012453
[13:16:26.306] iteration 7594: loss: 0.087499, loss_s1: 0.084236, loss_fp: 0.002234, loss_freq: 0.032985
[13:16:27.012] iteration 7595: loss: 0.075309, loss_s1: 0.033414, loss_fp: 0.002729, loss_freq: 0.017431
[13:16:27.682] iteration 7596: loss: 0.190536, loss_s1: 0.018664, loss_fp: 0.002426, loss_freq: 0.030428
[13:16:28.343] iteration 7597: loss: 0.121311, loss_s1: 0.074370, loss_fp: 0.004446, loss_freq: 0.022545
[13:16:28.974] iteration 7598: loss: 0.067822, loss_s1: 0.033929, loss_fp: 0.002546, loss_freq: 0.023103
[13:16:29.623] iteration 7599: loss: 0.062339, loss_s1: 0.038597, loss_fp: 0.005658, loss_freq: 0.032947
[13:16:30.326] iteration 7600: loss: 0.099577, loss_s1: 0.013211, loss_fp: 0.002236, loss_freq: 0.050275
[13:16:33.724] iteration 7600 : mean_dice : 0.696666
[13:16:34.424] iteration 7601: loss: 0.071440, loss_s1: 0.042306, loss_fp: 0.001308, loss_freq: 0.022002
[13:16:35.093] iteration 7602: loss: 0.072264, loss_s1: 0.056552, loss_fp: 0.001812, loss_freq: 0.009233
[13:16:35.758] iteration 7603: loss: 0.093721, loss_s1: 0.039536, loss_fp: 0.000938, loss_freq: 0.014951
[13:16:36.430] iteration 7604: loss: 0.085296, loss_s1: 0.027666, loss_fp: 0.003987, loss_freq: 0.048028
[13:16:37.117] iteration 7605: loss: 0.118149, loss_s1: 0.073340, loss_fp: 0.007973, loss_freq: 0.057518
[13:16:37.786] iteration 7606: loss: 0.123648, loss_s1: 0.047650, loss_fp: 0.000747, loss_freq: 0.054249
[13:16:38.470] iteration 7607: loss: 0.067608, loss_s1: 0.034055, loss_fp: 0.001099, loss_freq: 0.014182
[13:16:39.146] iteration 7608: loss: 0.102571, loss_s1: 0.035034, loss_fp: 0.002807, loss_freq: 0.049153
[13:16:39.781] iteration 7609: loss: 0.098398, loss_s1: 0.045148, loss_fp: 0.003089, loss_freq: 0.008101
[13:16:40.422] iteration 7610: loss: 0.054477, loss_s1: 0.035005, loss_fp: 0.002824, loss_freq: 0.013431
[13:16:41.082] iteration 7611: loss: 0.093615, loss_s1: 0.029243, loss_fp: 0.011794, loss_freq: 0.014464
[13:16:41.728] iteration 7612: loss: 0.078174, loss_s1: 0.029166, loss_fp: 0.004644, loss_freq: 0.021192
[13:16:42.364] iteration 7613: loss: 0.131623, loss_s1: 0.065426, loss_fp: 0.008395, loss_freq: 0.107606
[13:16:43.056] iteration 7614: loss: 0.109893, loss_s1: 0.055182, loss_fp: 0.003315, loss_freq: 0.023235
[13:16:43.734] iteration 7615: loss: 0.091526, loss_s1: 0.042973, loss_fp: 0.001076, loss_freq: 0.052706
[13:16:44.421] iteration 7616: loss: 0.111586, loss_s1: 0.059049, loss_fp: 0.011120, loss_freq: 0.029925
[13:16:45.120] iteration 7617: loss: 0.054915, loss_s1: 0.018743, loss_fp: 0.001746, loss_freq: 0.030261
[13:16:45.844] iteration 7618: loss: 0.114956, loss_s1: 0.076176, loss_fp: 0.002544, loss_freq: 0.042815
[13:16:46.824] iteration 7619: loss: 0.073246, loss_s1: 0.037383, loss_fp: 0.002080, loss_freq: 0.004679
[13:16:47.457] iteration 7620: loss: 0.079514, loss_s1: 0.019633, loss_fp: 0.002463, loss_freq: 0.016916
[13:16:48.094] iteration 7621: loss: 0.051107, loss_s1: 0.023656, loss_fp: 0.002276, loss_freq: 0.025172
[13:16:48.728] iteration 7622: loss: 0.111686, loss_s1: 0.047172, loss_fp: 0.001358, loss_freq: 0.014872
[13:16:49.372] iteration 7623: loss: 0.107066, loss_s1: 0.105960, loss_fp: 0.001350, loss_freq: 0.042911
[13:16:50.005] iteration 7624: loss: 0.119365, loss_s1: 0.031565, loss_fp: 0.001574, loss_freq: 0.032544
[13:16:50.645] iteration 7625: loss: 0.143221, loss_s1: 0.067549, loss_fp: 0.004279, loss_freq: 0.070656
[13:16:51.291] iteration 7626: loss: 0.068113, loss_s1: 0.026742, loss_fp: 0.005341, loss_freq: 0.010109
[13:16:51.922] iteration 7627: loss: 0.073050, loss_s1: 0.023294, loss_fp: 0.001624, loss_freq: 0.017985
[13:16:52.560] iteration 7628: loss: 0.067915, loss_s1: 0.063333, loss_fp: 0.003290, loss_freq: 0.006529
[13:16:53.192] iteration 7629: loss: 0.069221, loss_s1: 0.033876, loss_fp: 0.002871, loss_freq: 0.034214
[13:16:53.839] iteration 7630: loss: 0.070745, loss_s1: 0.041252, loss_fp: 0.004821, loss_freq: 0.012412
[13:16:54.479] iteration 7631: loss: 0.106800, loss_s1: 0.030318, loss_fp: 0.001406, loss_freq: 0.054233
[13:16:55.114] iteration 7632: loss: 0.079053, loss_s1: 0.043858, loss_fp: 0.002776, loss_freq: 0.006944
[13:16:55.748] iteration 7633: loss: 0.070141, loss_s1: 0.053588, loss_fp: 0.001518, loss_freq: 0.024230
[13:16:56.383] iteration 7634: loss: 0.065140, loss_s1: 0.043613, loss_fp: 0.001709, loss_freq: 0.018366
[13:16:57.025] iteration 7635: loss: 0.124219, loss_s1: 0.055926, loss_fp: 0.001432, loss_freq: 0.004942
[13:16:57.664] iteration 7636: loss: 0.106567, loss_s1: 0.098628, loss_fp: 0.002515, loss_freq: 0.024846
[13:16:58.307] iteration 7637: loss: 0.056391, loss_s1: 0.042088, loss_fp: 0.000337, loss_freq: 0.012078
[13:16:58.938] iteration 7638: loss: 0.131367, loss_s1: 0.044717, loss_fp: 0.002454, loss_freq: 0.070667
[13:16:59.610] iteration 7639: loss: 0.072462, loss_s1: 0.047774, loss_fp: 0.002589, loss_freq: 0.023023
[13:17:00.270] iteration 7640: loss: 0.114145, loss_s1: 0.026794, loss_fp: 0.007100, loss_freq: 0.026973
[13:17:00.939] iteration 7641: loss: 0.099859, loss_s1: 0.034835, loss_fp: 0.001829, loss_freq: 0.054596
[13:17:01.579] iteration 7642: loss: 0.124558, loss_s1: 0.113766, loss_fp: 0.002822, loss_freq: 0.033459
[13:17:02.220] iteration 7643: loss: 0.082656, loss_s1: 0.043644, loss_fp: 0.001435, loss_freq: 0.012750
[13:17:02.855] iteration 7644: loss: 0.142618, loss_s1: 0.121510, loss_fp: 0.001243, loss_freq: 0.022167
[13:17:03.494] iteration 7645: loss: 0.117026, loss_s1: 0.038511, loss_fp: 0.005368, loss_freq: 0.017334
[13:17:04.137] iteration 7646: loss: 0.154030, loss_s1: 0.060827, loss_fp: 0.005156, loss_freq: 0.137826
[13:17:04.771] iteration 7647: loss: 0.126931, loss_s1: 0.020124, loss_fp: 0.010249, loss_freq: 0.037112
[13:17:05.410] iteration 7648: loss: 0.060171, loss_s1: 0.030809, loss_fp: 0.002736, loss_freq: 0.014612
[13:17:06.055] iteration 7649: loss: 0.128779, loss_s1: 0.068143, loss_fp: 0.003590, loss_freq: 0.023043
[13:17:06.695] iteration 7650: loss: 0.111249, loss_s1: 0.094173, loss_fp: 0.003453, loss_freq: 0.030321
[13:17:07.340] iteration 7651: loss: 0.094167, loss_s1: 0.071955, loss_fp: 0.003086, loss_freq: 0.009734
[13:17:08.011] iteration 7652: loss: 0.092037, loss_s1: 0.036102, loss_fp: 0.010609, loss_freq: 0.079748
[13:17:08.649] iteration 7653: loss: 0.129742, loss_s1: 0.102761, loss_fp: 0.015161, loss_freq: 0.021555
[13:17:09.279] iteration 7654: loss: 0.114380, loss_s1: 0.050326, loss_fp: 0.008302, loss_freq: 0.095835
[13:17:09.920] iteration 7655: loss: 0.102078, loss_s1: 0.050792, loss_fp: 0.002427, loss_freq: 0.014234
[13:17:10.552] iteration 7656: loss: 0.078293, loss_s1: 0.078453, loss_fp: 0.001137, loss_freq: 0.015690
[13:17:11.201] iteration 7657: loss: 0.090172, loss_s1: 0.029604, loss_fp: 0.002307, loss_freq: 0.022430
[13:17:11.833] iteration 7658: loss: 0.101970, loss_s1: 0.057512, loss_fp: 0.003802, loss_freq: 0.052866
[13:17:12.481] iteration 7659: loss: 0.231794, loss_s1: 0.053234, loss_fp: 0.012290, loss_freq: 0.019762
[13:17:13.125] iteration 7660: loss: 0.063877, loss_s1: 0.022195, loss_fp: 0.001520, loss_freq: 0.014370
[13:17:13.765] iteration 7661: loss: 0.104959, loss_s1: 0.060949, loss_fp: 0.001598, loss_freq: 0.025148
[13:17:14.408] iteration 7662: loss: 0.085107, loss_s1: 0.038017, loss_fp: 0.002411, loss_freq: 0.018505
[13:17:15.043] iteration 7663: loss: 0.070166, loss_s1: 0.067485, loss_fp: 0.001417, loss_freq: 0.021784
[13:17:15.678] iteration 7664: loss: 0.097822, loss_s1: 0.060527, loss_fp: 0.000610, loss_freq: 0.003355
[13:17:16.315] iteration 7665: loss: 0.108230, loss_s1: 0.059062, loss_fp: 0.000843, loss_freq: 0.053521
[13:17:16.990] iteration 7666: loss: 0.108154, loss_s1: 0.061482, loss_fp: 0.000555, loss_freq: 0.013870
[13:17:17.629] iteration 7667: loss: 0.068175, loss_s1: 0.018442, loss_fp: 0.000666, loss_freq: 0.018054
[13:17:18.273] iteration 7668: loss: 0.068333, loss_s1: 0.039506, loss_fp: 0.000447, loss_freq: 0.009055
[13:17:18.916] iteration 7669: loss: 0.077586, loss_s1: 0.051158, loss_fp: 0.003546, loss_freq: 0.031553
[13:17:19.555] iteration 7670: loss: 0.109365, loss_s1: 0.032744, loss_fp: 0.002573, loss_freq: 0.020191
[13:17:20.234] iteration 7671: loss: 0.089963, loss_s1: 0.038367, loss_fp: 0.001361, loss_freq: 0.063053
[13:17:20.916] iteration 7672: loss: 0.055089, loss_s1: 0.027236, loss_fp: 0.006051, loss_freq: 0.009878
[13:17:21.597] iteration 7673: loss: 0.095391, loss_s1: 0.020332, loss_fp: 0.007464, loss_freq: 0.041372
[13:17:22.274] iteration 7674: loss: 0.062058, loss_s1: 0.019410, loss_fp: 0.002149, loss_freq: 0.030106
[13:17:22.952] iteration 7675: loss: 0.108926, loss_s1: 0.061514, loss_fp: 0.001598, loss_freq: 0.066265
[13:17:23.634] iteration 7676: loss: 0.105307, loss_s1: 0.040870, loss_fp: 0.003631, loss_freq: 0.068677
[13:17:24.309] iteration 7677: loss: 0.074871, loss_s1: 0.031427, loss_fp: 0.002213, loss_freq: 0.037296
[13:17:24.946] iteration 7678: loss: 0.151702, loss_s1: 0.043772, loss_fp: 0.000642, loss_freq: 0.059590
[13:17:25.589] iteration 7679: loss: 0.093005, loss_s1: 0.045482, loss_fp: 0.002452, loss_freq: 0.050406
[13:17:26.235] iteration 7680: loss: 0.107119, loss_s1: 0.056764, loss_fp: 0.006176, loss_freq: 0.046903
[13:17:26.887] iteration 7681: loss: 0.093139, loss_s1: 0.053087, loss_fp: 0.002849, loss_freq: 0.017778
[13:17:27.522] iteration 7682: loss: 0.065859, loss_s1: 0.035185, loss_fp: 0.001409, loss_freq: 0.015521
[13:17:28.156] iteration 7683: loss: 0.156915, loss_s1: 0.130094, loss_fp: 0.003145, loss_freq: 0.076647
[13:17:28.803] iteration 7684: loss: 0.179033, loss_s1: 0.154563, loss_fp: 0.008504, loss_freq: 0.053500
[13:17:29.509] iteration 7685: loss: 0.078530, loss_s1: 0.041694, loss_fp: 0.000828, loss_freq: 0.021452
[13:17:30.171] iteration 7686: loss: 0.142373, loss_s1: 0.051320, loss_fp: 0.001176, loss_freq: 0.130831
[13:17:30.804] iteration 7687: loss: 0.067147, loss_s1: 0.032592, loss_fp: 0.003692, loss_freq: 0.037283
[13:17:31.445] iteration 7688: loss: 0.074602, loss_s1: 0.036938, loss_fp: 0.001303, loss_freq: 0.004394
[13:17:32.079] iteration 7689: loss: 0.119592, loss_s1: 0.107030, loss_fp: 0.000652, loss_freq: 0.057231
[13:17:32.704] iteration 7690: loss: 0.098787, loss_s1: 0.055269, loss_fp: 0.002953, loss_freq: 0.008626
[13:17:33.332] iteration 7691: loss: 0.067942, loss_s1: 0.048085, loss_fp: 0.001553, loss_freq: 0.032741
[13:17:33.957] iteration 7692: loss: 0.110712, loss_s1: 0.055159, loss_fp: 0.001155, loss_freq: 0.013820
[13:17:34.585] iteration 7693: loss: 0.106369, loss_s1: 0.078923, loss_fp: 0.001529, loss_freq: 0.054890
[13:17:35.276] iteration 7694: loss: 0.144441, loss_s1: 0.026540, loss_fp: 0.001080, loss_freq: 0.053108
[13:17:35.964] iteration 7695: loss: 0.115276, loss_s1: 0.070816, loss_fp: 0.002250, loss_freq: 0.008251
[13:17:36.638] iteration 7696: loss: 0.066215, loss_s1: 0.011851, loss_fp: 0.003610, loss_freq: 0.024428
[13:17:37.308] iteration 7697: loss: 0.105809, loss_s1: 0.061317, loss_fp: 0.003411, loss_freq: 0.049424
[13:17:37.986] iteration 7698: loss: 0.105072, loss_s1: 0.072476, loss_fp: 0.001111, loss_freq: 0.057873
[13:17:38.659] iteration 7699: loss: 0.088727, loss_s1: 0.069402, loss_fp: 0.005596, loss_freq: 0.026134
[13:17:39.320] iteration 7700: loss: 0.092868, loss_s1: 0.024878, loss_fp: 0.000500, loss_freq: 0.084428
[13:17:39.956] iteration 7701: loss: 0.191722, loss_s1: 0.042152, loss_fp: 0.002386, loss_freq: 0.013904
[13:17:40.591] iteration 7702: loss: 0.057134, loss_s1: 0.015712, loss_fp: 0.002016, loss_freq: 0.006436
[13:17:41.228] iteration 7703: loss: 0.071896, loss_s1: 0.042766, loss_fp: 0.002596, loss_freq: 0.039769
[13:17:41.870] iteration 7704: loss: 0.083515, loss_s1: 0.064337, loss_fp: 0.001537, loss_freq: 0.020325
[13:17:42.510] iteration 7705: loss: 0.157342, loss_s1: 0.069727, loss_fp: 0.002408, loss_freq: 0.017883
[13:17:43.146] iteration 7706: loss: 0.089261, loss_s1: 0.060800, loss_fp: 0.000812, loss_freq: 0.055286
[13:17:43.789] iteration 7707: loss: 0.076490, loss_s1: 0.052975, loss_fp: 0.002213, loss_freq: 0.028272
[13:17:44.451] iteration 7708: loss: 0.118743, loss_s1: 0.049210, loss_fp: 0.001322, loss_freq: 0.021692
[13:17:45.091] iteration 7709: loss: 0.078985, loss_s1: 0.011012, loss_fp: 0.002747, loss_freq: 0.021054
[13:17:45.737] iteration 7710: loss: 0.081240, loss_s1: 0.015587, loss_fp: 0.001462, loss_freq: 0.003001
[13:17:46.385] iteration 7711: loss: 0.142223, loss_s1: 0.062467, loss_fp: 0.002944, loss_freq: 0.005629
[13:17:47.023] iteration 7712: loss: 0.063255, loss_s1: 0.011438, loss_fp: 0.000423, loss_freq: 0.032957
[13:17:47.664] iteration 7713: loss: 0.117911, loss_s1: 0.034880, loss_fp: 0.001099, loss_freq: 0.028689
[13:17:48.305] iteration 7714: loss: 0.100334, loss_s1: 0.039573, loss_fp: 0.002623, loss_freq: 0.052298
[13:17:48.950] iteration 7715: loss: 0.104873, loss_s1: 0.048327, loss_fp: 0.001392, loss_freq: 0.028756
[13:17:49.596] iteration 7716: loss: 0.082660, loss_s1: 0.050827, loss_fp: 0.001409, loss_freq: 0.030453
[13:17:50.249] iteration 7717: loss: 0.131749, loss_s1: 0.020975, loss_fp: 0.002294, loss_freq: 0.064790
[13:17:50.883] iteration 7718: loss: 0.081063, loss_s1: 0.028244, loss_fp: 0.007073, loss_freq: 0.017447
[13:17:51.520] iteration 7719: loss: 0.078902, loss_s1: 0.031544, loss_fp: 0.001295, loss_freq: 0.015234
[13:17:52.154] iteration 7720: loss: 0.090119, loss_s1: 0.038162, loss_fp: 0.006072, loss_freq: 0.025222
[13:17:52.793] iteration 7721: loss: 0.124915, loss_s1: 0.094526, loss_fp: 0.003072, loss_freq: 0.053352
[13:17:53.423] iteration 7722: loss: 0.059751, loss_s1: 0.031585, loss_fp: 0.004754, loss_freq: 0.016360
[13:17:54.448] iteration 7723: loss: 0.071060, loss_s1: 0.025075, loss_fp: 0.001612, loss_freq: 0.008559
[13:17:55.127] iteration 7724: loss: 0.101373, loss_s1: 0.070508, loss_fp: 0.001492, loss_freq: 0.050029
[13:17:55.799] iteration 7725: loss: 0.069191, loss_s1: 0.045387, loss_fp: 0.002925, loss_freq: 0.026514
[13:17:56.470] iteration 7726: loss: 0.104865, loss_s1: 0.026740, loss_fp: 0.001279, loss_freq: 0.028005
[13:17:57.137] iteration 7727: loss: 0.098258, loss_s1: 0.048383, loss_fp: 0.001889, loss_freq: 0.081137
[13:17:57.792] iteration 7728: loss: 0.072113, loss_s1: 0.023679, loss_fp: 0.002137, loss_freq: 0.005399
[13:17:58.435] iteration 7729: loss: 0.079178, loss_s1: 0.086627, loss_fp: 0.001546, loss_freq: 0.022709
[13:17:59.071] iteration 7730: loss: 0.193310, loss_s1: 0.097122, loss_fp: 0.008929, loss_freq: 0.024490
[13:17:59.706] iteration 7731: loss: 0.070642, loss_s1: 0.019623, loss_fp: 0.000926, loss_freq: 0.028746
[13:18:00.358] iteration 7732: loss: 0.169432, loss_s1: 0.040369, loss_fp: 0.000671, loss_freq: 0.011315
[13:18:01.001] iteration 7733: loss: 0.109560, loss_s1: 0.048098, loss_fp: 0.003129, loss_freq: 0.048188
[13:18:01.642] iteration 7734: loss: 0.074403, loss_s1: 0.033122, loss_fp: 0.001407, loss_freq: 0.033199
[13:18:02.281] iteration 7735: loss: 0.099899, loss_s1: 0.058451, loss_fp: 0.006151, loss_freq: 0.048191
[13:18:02.923] iteration 7736: loss: 0.069430, loss_s1: 0.036036, loss_fp: 0.002481, loss_freq: 0.041510
[13:18:03.576] iteration 7737: loss: 0.101987, loss_s1: 0.038689, loss_fp: 0.002917, loss_freq: 0.090747
[13:18:04.215] iteration 7738: loss: 0.096514, loss_s1: 0.085021, loss_fp: 0.001536, loss_freq: 0.019639
[13:18:04.857] iteration 7739: loss: 0.146509, loss_s1: 0.010561, loss_fp: 0.001067, loss_freq: 0.008184
[13:18:05.499] iteration 7740: loss: 0.087687, loss_s1: 0.051576, loss_fp: 0.001424, loss_freq: 0.017545
[13:18:06.150] iteration 7741: loss: 0.057617, loss_s1: 0.034703, loss_fp: 0.000768, loss_freq: 0.007556
[13:18:06.784] iteration 7742: loss: 0.078757, loss_s1: 0.077691, loss_fp: 0.000730, loss_freq: 0.012207
[13:18:07.428] iteration 7743: loss: 0.105402, loss_s1: 0.034815, loss_fp: 0.002516, loss_freq: 0.058133
[13:18:08.066] iteration 7744: loss: 0.062731, loss_s1: 0.030361, loss_fp: 0.001701, loss_freq: 0.028880
[13:18:08.708] iteration 7745: loss: 0.077986, loss_s1: 0.048627, loss_fp: 0.001429, loss_freq: 0.048151
[13:18:09.351] iteration 7746: loss: 0.137348, loss_s1: 0.024722, loss_fp: 0.003913, loss_freq: 0.048988
[13:18:09.987] iteration 7747: loss: 0.077248, loss_s1: 0.030646, loss_fp: 0.000382, loss_freq: 0.043097
[13:18:10.653] iteration 7748: loss: 0.179708, loss_s1: 0.102162, loss_fp: 0.002071, loss_freq: 0.083290
[13:18:11.323] iteration 7749: loss: 0.117615, loss_s1: 0.023369, loss_fp: 0.002601, loss_freq: 0.062682
[13:18:11.963] iteration 7750: loss: 0.088938, loss_s1: 0.035462, loss_fp: 0.008788, loss_freq: 0.021260
[13:18:12.599] iteration 7751: loss: 0.103186, loss_s1: 0.025235, loss_fp: 0.002368, loss_freq: 0.067826
[13:18:13.232] iteration 7752: loss: 0.139278, loss_s1: 0.080125, loss_fp: 0.001509, loss_freq: 0.045858
[13:18:13.869] iteration 7753: loss: 0.067409, loss_s1: 0.022440, loss_fp: 0.001421, loss_freq: 0.008973
[13:18:14.506] iteration 7754: loss: 0.095080, loss_s1: 0.057458, loss_fp: 0.002739, loss_freq: 0.029045
[13:18:15.164] iteration 7755: loss: 0.046801, loss_s1: 0.032172, loss_fp: 0.001462, loss_freq: 0.009108
[13:18:15.806] iteration 7756: loss: 0.076702, loss_s1: 0.034189, loss_fp: 0.008420, loss_freq: 0.039450
[13:18:16.455] iteration 7757: loss: 0.158895, loss_s1: 0.035943, loss_fp: 0.002663, loss_freq: 0.038833
[13:18:17.112] iteration 7758: loss: 0.152884, loss_s1: 0.089538, loss_fp: 0.001448, loss_freq: 0.039085
[13:18:17.768] iteration 7759: loss: 0.079039, loss_s1: 0.036167, loss_fp: 0.002354, loss_freq: 0.025116
[13:18:18.419] iteration 7760: loss: 0.055028, loss_s1: 0.019004, loss_fp: 0.001936, loss_freq: 0.030095
[13:18:19.071] iteration 7761: loss: 0.098774, loss_s1: 0.033121, loss_fp: 0.003075, loss_freq: 0.045547
[13:18:19.729] iteration 7762: loss: 0.093298, loss_s1: 0.030586, loss_fp: 0.005798, loss_freq: 0.025786
[13:18:20.367] iteration 7763: loss: 0.131067, loss_s1: 0.052009, loss_fp: 0.001866, loss_freq: 0.015438
[13:18:21.015] iteration 7764: loss: 0.057591, loss_s1: 0.026034, loss_fp: 0.000934, loss_freq: 0.008446
[13:18:21.676] iteration 7765: loss: 0.100360, loss_s1: 0.042649, loss_fp: 0.003284, loss_freq: 0.035980
[13:18:22.352] iteration 7766: loss: 0.083277, loss_s1: 0.049107, loss_fp: 0.002460, loss_freq: 0.040638
[13:18:23.056] iteration 7767: loss: 0.176695, loss_s1: 0.068633, loss_fp: 0.001889, loss_freq: 0.043140
[13:18:23.703] iteration 7768: loss: 0.103015, loss_s1: 0.087519, loss_fp: 0.001550, loss_freq: 0.041351
[13:18:24.350] iteration 7769: loss: 0.095864, loss_s1: 0.030602, loss_fp: 0.005219, loss_freq: 0.024855
[13:18:24.985] iteration 7770: loss: 0.085381, loss_s1: 0.025124, loss_fp: 0.003184, loss_freq: 0.040943
[13:18:25.626] iteration 7771: loss: 0.091641, loss_s1: 0.056433, loss_fp: 0.001341, loss_freq: 0.047391
[13:18:26.307] iteration 7772: loss: 0.086116, loss_s1: 0.086305, loss_fp: 0.000661, loss_freq: 0.013609
[13:18:26.978] iteration 7773: loss: 0.086382, loss_s1: 0.067423, loss_fp: 0.008645, loss_freq: 0.013139
[13:18:27.611] iteration 7774: loss: 0.108809, loss_s1: 0.036210, loss_fp: 0.004392, loss_freq: 0.034345
[13:18:28.243] iteration 7775: loss: 0.051986, loss_s1: 0.034684, loss_fp: 0.001465, loss_freq: 0.006810
[13:18:28.877] iteration 7776: loss: 0.068433, loss_s1: 0.045875, loss_fp: 0.007432, loss_freq: 0.012565
[13:18:29.513] iteration 7777: loss: 0.099036, loss_s1: 0.083273, loss_fp: 0.005491, loss_freq: 0.029967
[13:18:30.148] iteration 7778: loss: 0.092651, loss_s1: 0.057890, loss_fp: 0.001428, loss_freq: 0.009526
[13:18:30.781] iteration 7779: loss: 0.107239, loss_s1: 0.091426, loss_fp: 0.002237, loss_freq: 0.022315
[13:18:31.413] iteration 7780: loss: 0.076082, loss_s1: 0.044684, loss_fp: 0.003290, loss_freq: 0.033737
[13:18:32.056] iteration 7781: loss: 0.136765, loss_s1: 0.050647, loss_fp: 0.005732, loss_freq: 0.056373
[13:18:32.702] iteration 7782: loss: 0.090758, loss_s1: 0.036573, loss_fp: 0.005919, loss_freq: 0.040622
[13:18:33.337] iteration 7783: loss: 0.074046, loss_s1: 0.030096, loss_fp: 0.001484, loss_freq: 0.010011
[13:18:33.973] iteration 7784: loss: 0.115900, loss_s1: 0.053044, loss_fp: 0.000998, loss_freq: 0.029689
[13:18:34.606] iteration 7785: loss: 0.077477, loss_s1: 0.045684, loss_fp: 0.005331, loss_freq: 0.022760
[13:18:35.241] iteration 7786: loss: 0.090368, loss_s1: 0.023913, loss_fp: 0.002792, loss_freq: 0.013084
[13:18:35.877] iteration 7787: loss: 0.099791, loss_s1: 0.041865, loss_fp: 0.008667, loss_freq: 0.019535
[13:18:36.509] iteration 7788: loss: 0.086887, loss_s1: 0.024853, loss_fp: 0.001430, loss_freq: 0.013826
[13:18:37.139] iteration 7789: loss: 0.153927, loss_s1: 0.064408, loss_fp: 0.002426, loss_freq: 0.065216
[13:18:37.786] iteration 7790: loss: 0.085733, loss_s1: 0.026257, loss_fp: 0.003408, loss_freq: 0.025857
[13:18:38.420] iteration 7791: loss: 0.075181, loss_s1: 0.059185, loss_fp: 0.004891, loss_freq: 0.018154
[13:18:39.054] iteration 7792: loss: 0.126496, loss_s1: 0.030138, loss_fp: 0.010095, loss_freq: 0.065826
[13:18:39.688] iteration 7793: loss: 0.095412, loss_s1: 0.038265, loss_fp: 0.001621, loss_freq: 0.032621
[13:18:40.319] iteration 7794: loss: 0.095090, loss_s1: 0.065899, loss_fp: 0.001848, loss_freq: 0.029975
[13:18:40.961] iteration 7795: loss: 0.090576, loss_s1: 0.018218, loss_fp: 0.000837, loss_freq: 0.085147
[13:18:41.594] iteration 7796: loss: 0.103385, loss_s1: 0.067590, loss_fp: 0.002460, loss_freq: 0.035828
[13:18:42.234] iteration 7797: loss: 0.085156, loss_s1: 0.071429, loss_fp: 0.002741, loss_freq: 0.033555
[13:18:42.872] iteration 7798: loss: 0.089442, loss_s1: 0.035678, loss_fp: 0.002394, loss_freq: 0.008731
[13:18:43.507] iteration 7799: loss: 0.069311, loss_s1: 0.062450, loss_fp: 0.000606, loss_freq: 0.011528
[13:18:44.147] iteration 7800: loss: 0.128544, loss_s1: 0.036824, loss_fp: 0.000574, loss_freq: 0.013877
[13:18:47.293] iteration 7800 : mean_dice : 0.712946
[13:18:47.962] iteration 7801: loss: 0.088571, loss_s1: 0.034781, loss_fp: 0.015568, loss_freq: 0.043208
[13:18:48.598] iteration 7802: loss: 0.237574, loss_s1: 0.104720, loss_fp: 0.003733, loss_freq: 0.069942
[13:18:49.236] iteration 7803: loss: 0.088678, loss_s1: 0.038213, loss_fp: 0.004238, loss_freq: 0.049396
[13:18:49.930] iteration 7804: loss: 0.091063, loss_s1: 0.045524, loss_fp: 0.000591, loss_freq: 0.038294
[13:18:50.642] iteration 7805: loss: 0.131686, loss_s1: 0.061737, loss_fp: 0.000761, loss_freq: 0.058378
[13:18:51.356] iteration 7806: loss: 0.064916, loss_s1: 0.058668, loss_fp: 0.001826, loss_freq: 0.017235
[13:18:52.016] iteration 7807: loss: 0.076182, loss_s1: 0.034066, loss_fp: 0.002490, loss_freq: 0.017873
[13:18:52.678] iteration 7808: loss: 0.100969, loss_s1: 0.034157, loss_fp: 0.001928, loss_freq: 0.052319
[13:18:53.321] iteration 7809: loss: 0.132646, loss_s1: 0.089138, loss_fp: 0.003060, loss_freq: 0.029068
[13:18:53.970] iteration 7810: loss: 0.089889, loss_s1: 0.024740, loss_fp: 0.000300, loss_freq: 0.025055
[13:18:54.608] iteration 7811: loss: 0.084411, loss_s1: 0.057602, loss_fp: 0.009283, loss_freq: 0.012070
[13:18:55.246] iteration 7812: loss: 0.098453, loss_s1: 0.049887, loss_fp: 0.006334, loss_freq: 0.050097
[13:18:55.880] iteration 7813: loss: 0.106531, loss_s1: 0.071973, loss_fp: 0.000955, loss_freq: 0.033196
[13:18:56.566] iteration 7814: loss: 0.072525, loss_s1: 0.025189, loss_fp: 0.001734, loss_freq: 0.037831
[13:18:57.245] iteration 7815: loss: 0.073922, loss_s1: 0.049468, loss_fp: 0.001094, loss_freq: 0.013939
[13:18:57.919] iteration 7816: loss: 0.088793, loss_s1: 0.053840, loss_fp: 0.001342, loss_freq: 0.033125
[13:18:58.584] iteration 7817: loss: 0.082266, loss_s1: 0.045218, loss_fp: 0.001916, loss_freq: 0.019219
[13:18:59.247] iteration 7818: loss: 0.136956, loss_s1: 0.036969, loss_fp: 0.008987, loss_freq: 0.063274
[13:18:59.907] iteration 7819: loss: 0.118156, loss_s1: 0.070442, loss_fp: 0.005104, loss_freq: 0.052552
[13:19:00.552] iteration 7820: loss: 0.073851, loss_s1: 0.028912, loss_fp: 0.003812, loss_freq: 0.042179
[13:19:01.199] iteration 7821: loss: 0.135638, loss_s1: 0.031303, loss_fp: 0.003333, loss_freq: 0.038875
[13:19:01.842] iteration 7822: loss: 0.129137, loss_s1: 0.034343, loss_fp: 0.003718, loss_freq: 0.040797
[13:19:02.496] iteration 7823: loss: 0.131863, loss_s1: 0.043637, loss_fp: 0.001729, loss_freq: 0.085627
[13:19:03.143] iteration 7824: loss: 0.075032, loss_s1: 0.033242, loss_fp: 0.002156, loss_freq: 0.027932
[13:19:03.792] iteration 7825: loss: 0.071688, loss_s1: 0.052133, loss_fp: 0.008643, loss_freq: 0.016389
[13:19:04.428] iteration 7826: loss: 0.124360, loss_s1: 0.070867, loss_fp: 0.000903, loss_freq: 0.084590
[13:19:05.086] iteration 7827: loss: 0.125384, loss_s1: 0.021947, loss_fp: 0.004451, loss_freq: 0.028044
[13:19:05.766] iteration 7828: loss: 0.074015, loss_s1: 0.037205, loss_fp: 0.001730, loss_freq: 0.024361
[13:19:06.452] iteration 7829: loss: 0.137537, loss_s1: 0.078428, loss_fp: 0.002848, loss_freq: 0.099457
[13:19:07.154] iteration 7830: loss: 0.100548, loss_s1: 0.079113, loss_fp: 0.001435, loss_freq: 0.020476
[13:19:07.818] iteration 7831: loss: 0.094518, loss_s1: 0.053269, loss_fp: 0.000760, loss_freq: 0.003520
[13:19:08.488] iteration 7832: loss: 0.091028, loss_s1: 0.056612, loss_fp: 0.002367, loss_freq: 0.026641
[13:19:09.158] iteration 7833: loss: 0.100328, loss_s1: 0.054953, loss_fp: 0.002986, loss_freq: 0.010355
[13:19:09.830] iteration 7834: loss: 0.080350, loss_s1: 0.059758, loss_fp: 0.005951, loss_freq: 0.039074
[13:19:10.498] iteration 7835: loss: 0.100123, loss_s1: 0.049669, loss_fp: 0.000831, loss_freq: 0.011369
[13:19:11.134] iteration 7836: loss: 0.061431, loss_s1: 0.029893, loss_fp: 0.003907, loss_freq: 0.017507
[13:19:11.769] iteration 7837: loss: 0.178737, loss_s1: 0.031944, loss_fp: 0.002237, loss_freq: 0.023088
[13:19:12.399] iteration 7838: loss: 0.079801, loss_s1: 0.030219, loss_fp: 0.005703, loss_freq: 0.012144
[13:19:13.044] iteration 7839: loss: 0.098330, loss_s1: 0.033354, loss_fp: 0.012588, loss_freq: 0.039917
[13:19:13.683] iteration 7840: loss: 0.171355, loss_s1: 0.090580, loss_fp: 0.001758, loss_freq: 0.165613
[13:19:14.357] iteration 7841: loss: 0.061901, loss_s1: 0.040990, loss_fp: 0.001372, loss_freq: 0.021323
[13:19:15.027] iteration 7842: loss: 0.054111, loss_s1: 0.017771, loss_fp: 0.006735, loss_freq: 0.025224
[13:19:15.665] iteration 7843: loss: 0.087385, loss_s1: 0.035810, loss_fp: 0.001637, loss_freq: 0.042134
[13:19:16.297] iteration 7844: loss: 0.153702, loss_s1: 0.052673, loss_fp: 0.003069, loss_freq: 0.034241
[13:19:16.925] iteration 7845: loss: 0.096667, loss_s1: 0.031892, loss_fp: 0.002647, loss_freq: 0.013494
[13:19:17.554] iteration 7846: loss: 0.072628, loss_s1: 0.044880, loss_fp: 0.003668, loss_freq: 0.037203
[13:19:18.179] iteration 7847: loss: 0.146373, loss_s1: 0.072142, loss_fp: 0.003096, loss_freq: 0.046237
[13:19:18.858] iteration 7848: loss: 0.081469, loss_s1: 0.028453, loss_fp: 0.000991, loss_freq: 0.013652
[13:19:19.522] iteration 7849: loss: 0.114121, loss_s1: 0.025716, loss_fp: 0.006569, loss_freq: 0.048563
[13:19:20.203] iteration 7850: loss: 0.055513, loss_s1: 0.019907, loss_fp: 0.001475, loss_freq: 0.014533
[13:19:20.840] iteration 7851: loss: 0.115587, loss_s1: 0.078931, loss_fp: 0.001371, loss_freq: 0.017901
[13:19:21.518] iteration 7852: loss: 0.061041, loss_s1: 0.017501, loss_fp: 0.001143, loss_freq: 0.015968
[13:19:22.167] iteration 7853: loss: 0.081559, loss_s1: 0.037851, loss_fp: 0.001059, loss_freq: 0.005065
[13:19:22.831] iteration 7854: loss: 0.145493, loss_s1: 0.066643, loss_fp: 0.004620, loss_freq: 0.014532
[13:19:23.473] iteration 7855: loss: 0.069470, loss_s1: 0.034609, loss_fp: 0.000888, loss_freq: 0.028481
[13:19:24.127] iteration 7856: loss: 0.123576, loss_s1: 0.046972, loss_fp: 0.002112, loss_freq: 0.046009
[13:19:24.767] iteration 7857: loss: 0.083977, loss_s1: 0.040230, loss_fp: 0.007210, loss_freq: 0.011492
[13:19:25.421] iteration 7858: loss: 0.078248, loss_s1: 0.029257, loss_fp: 0.002308, loss_freq: 0.022356
[13:19:26.064] iteration 7859: loss: 0.098570, loss_s1: 0.090487, loss_fp: 0.002248, loss_freq: 0.008399
[13:19:26.717] iteration 7860: loss: 0.132149, loss_s1: 0.030582, loss_fp: 0.002349, loss_freq: 0.040004
[13:19:27.371] iteration 7861: loss: 0.056031, loss_s1: 0.026120, loss_fp: 0.002364, loss_freq: 0.012469
[13:19:28.012] iteration 7862: loss: 0.103075, loss_s1: 0.038932, loss_fp: 0.004275, loss_freq: 0.016888
[13:19:28.656] iteration 7863: loss: 0.089395, loss_s1: 0.055257, loss_fp: 0.003745, loss_freq: 0.025884
[13:19:29.297] iteration 7864: loss: 0.079669, loss_s1: 0.069755, loss_fp: 0.004193, loss_freq: 0.012107
[13:19:29.936] iteration 7865: loss: 0.064260, loss_s1: 0.029111, loss_fp: 0.002375, loss_freq: 0.032292
[13:19:30.911] iteration 7866: loss: 0.085133, loss_s1: 0.044055, loss_fp: 0.000779, loss_freq: 0.014619
[13:19:31.589] iteration 7867: loss: 0.111217, loss_s1: 0.090368, loss_fp: 0.002907, loss_freq: 0.022852
[13:19:32.302] iteration 7868: loss: 0.071016, loss_s1: 0.029449, loss_fp: 0.000379, loss_freq: 0.043224
[13:19:32.966] iteration 7869: loss: 0.103405, loss_s1: 0.040466, loss_fp: 0.001922, loss_freq: 0.017939
[13:19:33.631] iteration 7870: loss: 0.108050, loss_s1: 0.054484, loss_fp: 0.002660, loss_freq: 0.060396
[13:19:34.259] iteration 7871: loss: 0.103645, loss_s1: 0.031502, loss_fp: 0.000758, loss_freq: 0.004963
[13:19:34.912] iteration 7872: loss: 0.070491, loss_s1: 0.042712, loss_fp: 0.006022, loss_freq: 0.039333
[13:19:35.543] iteration 7873: loss: 0.122814, loss_s1: 0.026777, loss_fp: 0.003847, loss_freq: 0.017728
[13:19:36.172] iteration 7874: loss: 0.081580, loss_s1: 0.027545, loss_fp: 0.000883, loss_freq: 0.047082
[13:19:36.807] iteration 7875: loss: 0.100237, loss_s1: 0.029177, loss_fp: 0.010832, loss_freq: 0.019494
[13:19:37.441] iteration 7876: loss: 0.121168, loss_s1: 0.070663, loss_fp: 0.003303, loss_freq: 0.075712
[13:19:38.092] iteration 7877: loss: 0.076497, loss_s1: 0.039331, loss_fp: 0.000799, loss_freq: 0.040504
[13:19:38.732] iteration 7878: loss: 0.090902, loss_s1: 0.048852, loss_fp: 0.000857, loss_freq: 0.039451
[13:19:39.366] iteration 7879: loss: 0.053246, loss_s1: 0.031992, loss_fp: 0.000784, loss_freq: 0.010215
[13:19:40.002] iteration 7880: loss: 0.105393, loss_s1: 0.111691, loss_fp: 0.001342, loss_freq: 0.034396
[13:19:40.638] iteration 7881: loss: 0.070704, loss_s1: 0.042639, loss_fp: 0.001234, loss_freq: 0.038350
[13:19:41.274] iteration 7882: loss: 0.142137, loss_s1: 0.020582, loss_fp: 0.001148, loss_freq: 0.031987
[13:19:41.914] iteration 7883: loss: 0.115267, loss_s1: 0.052864, loss_fp: 0.001493, loss_freq: 0.013637
[13:19:42.552] iteration 7884: loss: 0.055666, loss_s1: 0.031096, loss_fp: 0.002580, loss_freq: 0.015946
[13:19:43.190] iteration 7885: loss: 0.054189, loss_s1: 0.034343, loss_fp: 0.001609, loss_freq: 0.020676
[13:19:43.830] iteration 7886: loss: 0.143504, loss_s1: 0.032988, loss_fp: 0.002839, loss_freq: 0.077901
[13:19:44.471] iteration 7887: loss: 0.091355, loss_s1: 0.034413, loss_fp: 0.001457, loss_freq: 0.037499
[13:19:45.096] iteration 7888: loss: 0.077999, loss_s1: 0.055810, loss_fp: 0.008800, loss_freq: 0.013605
[13:19:45.765] iteration 7889: loss: 0.092838, loss_s1: 0.038690, loss_fp: 0.006229, loss_freq: 0.028831
[13:19:46.408] iteration 7890: loss: 0.087144, loss_s1: 0.052715, loss_fp: 0.001739, loss_freq: 0.045968
[13:19:47.050] iteration 7891: loss: 0.077308, loss_s1: 0.016325, loss_fp: 0.005610, loss_freq: 0.012876
[13:19:47.718] iteration 7892: loss: 0.139183, loss_s1: 0.050352, loss_fp: 0.002368, loss_freq: 0.043907
[13:19:48.402] iteration 7893: loss: 0.059493, loss_s1: 0.025111, loss_fp: 0.008149, loss_freq: 0.017700
[13:19:49.072] iteration 7894: loss: 0.122970, loss_s1: 0.113081, loss_fp: 0.002740, loss_freq: 0.038986
[13:19:49.715] iteration 7895: loss: 0.097622, loss_s1: 0.022967, loss_fp: 0.000764, loss_freq: 0.019638
[13:19:50.368] iteration 7896: loss: 0.077317, loss_s1: 0.023702, loss_fp: 0.000835, loss_freq: 0.015652
[13:19:51.016] iteration 7897: loss: 0.106073, loss_s1: 0.073066, loss_fp: 0.000867, loss_freq: 0.025301
[13:19:51.665] iteration 7898: loss: 0.098423, loss_s1: 0.049622, loss_fp: 0.001819, loss_freq: 0.010777
[13:19:52.307] iteration 7899: loss: 0.103540, loss_s1: 0.079829, loss_fp: 0.002700, loss_freq: 0.058510
[13:19:52.952] iteration 7900: loss: 0.151605, loss_s1: 0.043902, loss_fp: 0.003076, loss_freq: 0.019198
[13:19:53.588] iteration 7901: loss: 0.094301, loss_s1: 0.052353, loss_fp: 0.002403, loss_freq: 0.048104
[13:19:54.252] iteration 7902: loss: 0.119285, loss_s1: 0.085257, loss_fp: 0.001310, loss_freq: 0.046579
[13:19:54.922] iteration 7903: loss: 0.090741, loss_s1: 0.033881, loss_fp: 0.016089, loss_freq: 0.051253
[13:19:55.593] iteration 7904: loss: 0.088855, loss_s1: 0.031813, loss_fp: 0.002604, loss_freq: 0.022245
[13:19:56.263] iteration 7905: loss: 0.126613, loss_s1: 0.042545, loss_fp: 0.002152, loss_freq: 0.019092
[13:19:56.949] iteration 7906: loss: 0.090235, loss_s1: 0.046680, loss_fp: 0.003109, loss_freq: 0.015518
[13:19:57.634] iteration 7907: loss: 0.056849, loss_s1: 0.043310, loss_fp: 0.001901, loss_freq: 0.019118
[13:19:58.304] iteration 7908: loss: 0.113012, loss_s1: 0.053646, loss_fp: 0.002820, loss_freq: 0.024216
[13:19:58.950] iteration 7909: loss: 0.112961, loss_s1: 0.112809, loss_fp: 0.001714, loss_freq: 0.045742
[13:19:59.596] iteration 7910: loss: 0.105547, loss_s1: 0.026547, loss_fp: 0.000938, loss_freq: 0.010224
[13:20:00.242] iteration 7911: loss: 0.120525, loss_s1: 0.105343, loss_fp: 0.000584, loss_freq: 0.027471
[13:20:00.886] iteration 7912: loss: 0.071897, loss_s1: 0.019871, loss_fp: 0.007370, loss_freq: 0.023563
[13:20:01.540] iteration 7913: loss: 0.060215, loss_s1: 0.017397, loss_fp: 0.003823, loss_freq: 0.022337
[13:20:02.195] iteration 7914: loss: 0.058592, loss_s1: 0.057550, loss_fp: 0.001020, loss_freq: 0.007240
[13:20:02.847] iteration 7915: loss: 0.129917, loss_s1: 0.117702, loss_fp: 0.005626, loss_freq: 0.054673
[13:20:03.495] iteration 7916: loss: 0.094985, loss_s1: 0.038176, loss_fp: 0.001350, loss_freq: 0.015837
[13:20:04.149] iteration 7917: loss: 0.130654, loss_s1: 0.024793, loss_fp: 0.001897, loss_freq: 0.051765
[13:20:04.791] iteration 7918: loss: 0.093722, loss_s1: 0.108896, loss_fp: 0.002217, loss_freq: 0.012889
[13:20:05.435] iteration 7919: loss: 0.062921, loss_s1: 0.034630, loss_fp: 0.000848, loss_freq: 0.008021
[13:20:06.097] iteration 7920: loss: 0.055944, loss_s1: 0.039438, loss_fp: 0.001196, loss_freq: 0.020559
[13:20:06.733] iteration 7921: loss: 0.094824, loss_s1: 0.044933, loss_fp: 0.001774, loss_freq: 0.016690
[13:20:07.386] iteration 7922: loss: 0.110485, loss_s1: 0.099836, loss_fp: 0.002301, loss_freq: 0.034920
[13:20:08.035] iteration 7923: loss: 0.070422, loss_s1: 0.024632, loss_fp: 0.002570, loss_freq: 0.026410
[13:20:08.689] iteration 7924: loss: 0.183399, loss_s1: 0.098859, loss_fp: 0.002766, loss_freq: 0.112205
[13:20:09.339] iteration 7925: loss: 0.067726, loss_s1: 0.024789, loss_fp: 0.000962, loss_freq: 0.025640
[13:20:09.993] iteration 7926: loss: 0.117584, loss_s1: 0.044399, loss_fp: 0.002483, loss_freq: 0.012772
[13:20:10.636] iteration 7927: loss: 0.064011, loss_s1: 0.044144, loss_fp: 0.001686, loss_freq: 0.012645
[13:20:11.279] iteration 7928: loss: 0.076064, loss_s1: 0.040586, loss_fp: 0.002205, loss_freq: 0.024969
[13:20:11.918] iteration 7929: loss: 0.073486, loss_s1: 0.009509, loss_fp: 0.002132, loss_freq: 0.017828
[13:20:12.564] iteration 7930: loss: 0.112009, loss_s1: 0.064823, loss_fp: 0.001481, loss_freq: 0.028846
[13:20:13.208] iteration 7931: loss: 0.102861, loss_s1: 0.041268, loss_fp: 0.004192, loss_freq: 0.026648
[13:20:13.851] iteration 7932: loss: 0.115062, loss_s1: 0.072243, loss_fp: 0.002355, loss_freq: 0.064218
[13:20:14.500] iteration 7933: loss: 0.127398, loss_s1: 0.063612, loss_fp: 0.001212, loss_freq: 0.062525
[13:20:15.215] iteration 7934: loss: 0.107964, loss_s1: 0.067822, loss_fp: 0.004325, loss_freq: 0.019723
[13:20:15.908] iteration 7935: loss: 0.097800, loss_s1: 0.047849, loss_fp: 0.002281, loss_freq: 0.010477
[13:20:16.594] iteration 7936: loss: 0.065954, loss_s1: 0.036350, loss_fp: 0.004395, loss_freq: 0.021163
[13:20:17.287] iteration 7937: loss: 0.106759, loss_s1: 0.099741, loss_fp: 0.003804, loss_freq: 0.041417
[13:20:17.975] iteration 7938: loss: 0.055878, loss_s1: 0.034132, loss_fp: 0.003868, loss_freq: 0.021449
[13:20:18.625] iteration 7939: loss: 0.164173, loss_s1: 0.085584, loss_fp: 0.003480, loss_freq: 0.097567
[13:20:19.267] iteration 7940: loss: 0.147303, loss_s1: 0.161593, loss_fp: 0.006496, loss_freq: 0.054851
[13:20:19.906] iteration 7941: loss: 0.083832, loss_s1: 0.038288, loss_fp: 0.000849, loss_freq: 0.022329
[13:20:20.615] iteration 7942: loss: 0.055216, loss_s1: 0.042258, loss_fp: 0.007432, loss_freq: 0.016018
[13:20:21.298] iteration 7943: loss: 0.093946, loss_s1: 0.043241, loss_fp: 0.001378, loss_freq: 0.014710
[13:20:21.986] iteration 7944: loss: 0.118869, loss_s1: 0.054483, loss_fp: 0.034569, loss_freq: 0.078902
[13:20:22.646] iteration 7945: loss: 0.193736, loss_s1: 0.059230, loss_fp: 0.004301, loss_freq: 0.074903
[13:20:23.304] iteration 7946: loss: 0.118640, loss_s1: 0.073459, loss_fp: 0.001405, loss_freq: 0.048385
[13:20:23.964] iteration 7947: loss: 0.118523, loss_s1: 0.070481, loss_fp: 0.001596, loss_freq: 0.042770
[13:20:24.636] iteration 7948: loss: 0.100995, loss_s1: 0.066334, loss_fp: 0.000863, loss_freq: 0.030243
[13:20:25.307] iteration 7949: loss: 0.061772, loss_s1: 0.049892, loss_fp: 0.001764, loss_freq: 0.026711
[13:20:25.972] iteration 7950: loss: 0.075889, loss_s1: 0.044360, loss_fp: 0.003382, loss_freq: 0.003677
[13:20:26.636] iteration 7951: loss: 0.086611, loss_s1: 0.052979, loss_fp: 0.015588, loss_freq: 0.045225
[13:20:27.303] iteration 7952: loss: 0.127492, loss_s1: 0.023698, loss_fp: 0.001147, loss_freq: 0.005308
[13:20:27.963] iteration 7953: loss: 0.093320, loss_s1: 0.006962, loss_fp: 0.000511, loss_freq: 0.028225
[13:20:28.628] iteration 7954: loss: 0.071762, loss_s1: 0.033383, loss_fp: 0.001078, loss_freq: 0.026675
[13:20:29.293] iteration 7955: loss: 0.082490, loss_s1: 0.041536, loss_fp: 0.003888, loss_freq: 0.050154
[13:20:29.946] iteration 7956: loss: 0.121235, loss_s1: 0.046940, loss_fp: 0.000623, loss_freq: 0.027213
[13:20:30.582] iteration 7957: loss: 0.116396, loss_s1: 0.088926, loss_fp: 0.002734, loss_freq: 0.066370
[13:20:31.222] iteration 7958: loss: 0.047331, loss_s1: 0.012174, loss_fp: 0.001759, loss_freq: 0.005924
[13:20:31.863] iteration 7959: loss: 0.091370, loss_s1: 0.048978, loss_fp: 0.003403, loss_freq: 0.020592
[13:20:32.504] iteration 7960: loss: 0.064679, loss_s1: 0.036844, loss_fp: 0.001589, loss_freq: 0.010898
[13:20:33.151] iteration 7961: loss: 0.088957, loss_s1: 0.060542, loss_fp: 0.001554, loss_freq: 0.033868
[13:20:33.800] iteration 7962: loss: 0.137254, loss_s1: 0.086216, loss_fp: 0.008835, loss_freq: 0.069260
[13:20:34.431] iteration 7963: loss: 0.067719, loss_s1: 0.042483, loss_fp: 0.004226, loss_freq: 0.018021
[13:20:35.063] iteration 7964: loss: 0.075464, loss_s1: 0.020301, loss_fp: 0.001359, loss_freq: 0.016065
[13:20:35.732] iteration 7965: loss: 0.115574, loss_s1: 0.075701, loss_fp: 0.005517, loss_freq: 0.047062
[13:20:36.370] iteration 7966: loss: 0.090061, loss_s1: 0.029473, loss_fp: 0.001819, loss_freq: 0.026521
[13:20:37.002] iteration 7967: loss: 0.065786, loss_s1: 0.019361, loss_fp: 0.005509, loss_freq: 0.024022
[13:20:37.640] iteration 7968: loss: 0.092348, loss_s1: 0.105272, loss_fp: 0.002403, loss_freq: 0.005582
[13:20:38.279] iteration 7969: loss: 0.107150, loss_s1: 0.058180, loss_fp: 0.002622, loss_freq: 0.064652
[13:20:38.925] iteration 7970: loss: 0.131528, loss_s1: 0.072068, loss_fp: 0.001897, loss_freq: 0.038550
[13:20:39.557] iteration 7971: loss: 0.100606, loss_s1: 0.018212, loss_fp: 0.002611, loss_freq: 0.042494
[13:20:40.200] iteration 7972: loss: 0.154323, loss_s1: 0.100542, loss_fp: 0.001238, loss_freq: 0.118352
[13:20:40.839] iteration 7973: loss: 0.051908, loss_s1: 0.029188, loss_fp: 0.004467, loss_freq: 0.009796
[13:20:41.483] iteration 7974: loss: 0.100637, loss_s1: 0.054338, loss_fp: 0.002640, loss_freq: 0.011062
[13:20:42.121] iteration 7975: loss: 0.115073, loss_s1: 0.057631, loss_fp: 0.008483, loss_freq: 0.059596
[13:20:42.757] iteration 7976: loss: 0.089702, loss_s1: 0.026603, loss_fp: 0.000654, loss_freq: 0.047159
[13:20:43.407] iteration 7977: loss: 0.073340, loss_s1: 0.048600, loss_fp: 0.001078, loss_freq: 0.042719
[13:20:44.046] iteration 7978: loss: 0.082505, loss_s1: 0.033678, loss_fp: 0.000957, loss_freq: 0.019397
[13:20:44.689] iteration 7979: loss: 0.102216, loss_s1: 0.083534, loss_fp: 0.010070, loss_freq: 0.022514
[13:20:45.331] iteration 7980: loss: 0.174942, loss_s1: 0.062394, loss_fp: 0.001105, loss_freq: 0.021358
[13:20:45.984] iteration 7981: loss: 0.106799, loss_s1: 0.058955, loss_fp: 0.001546, loss_freq: 0.021046
[13:20:46.625] iteration 7982: loss: 0.115605, loss_s1: 0.109064, loss_fp: 0.001198, loss_freq: 0.041250
[13:20:47.262] iteration 7983: loss: 0.123592, loss_s1: 0.086039, loss_fp: 0.010368, loss_freq: 0.010331
[13:20:47.895] iteration 7984: loss: 0.084195, loss_s1: 0.066634, loss_fp: 0.001555, loss_freq: 0.055371
[13:20:48.581] iteration 7985: loss: 0.082563, loss_s1: 0.051081, loss_fp: 0.001296, loss_freq: 0.024814
[13:20:49.247] iteration 7986: loss: 0.112301, loss_s1: 0.077721, loss_fp: 0.007058, loss_freq: 0.062585
[13:20:49.894] iteration 7987: loss: 0.178034, loss_s1: 0.110610, loss_fp: 0.001620, loss_freq: 0.036092
[13:20:50.532] iteration 7988: loss: 0.068572, loss_s1: 0.046719, loss_fp: 0.001579, loss_freq: 0.018783
[13:20:51.175] iteration 7989: loss: 0.072182, loss_s1: 0.041254, loss_fp: 0.000938, loss_freq: 0.048518
[13:20:51.813] iteration 7990: loss: 0.088725, loss_s1: 0.065240, loss_fp: 0.004123, loss_freq: 0.031071
[13:20:52.458] iteration 7991: loss: 0.163743, loss_s1: 0.057693, loss_fp: 0.003890, loss_freq: 0.051475
[13:20:53.097] iteration 7992: loss: 0.100391, loss_s1: 0.038452, loss_fp: 0.004934, loss_freq: 0.042216
[13:20:53.733] iteration 7993: loss: 0.072047, loss_s1: 0.032015, loss_fp: 0.001087, loss_freq: 0.019329
[13:20:54.665] iteration 7994: loss: 0.097512, loss_s1: 0.067429, loss_fp: 0.002451, loss_freq: 0.016247
[13:20:55.422] iteration 7995: loss: 0.060295, loss_s1: 0.042722, loss_fp: 0.001219, loss_freq: 0.007528
[13:20:56.139] iteration 7996: loss: 0.126839, loss_s1: 0.037254, loss_fp: 0.001196, loss_freq: 0.018473
[13:20:56.840] iteration 7997: loss: 0.180074, loss_s1: 0.045234, loss_fp: 0.003441, loss_freq: 0.034681
[13:20:57.495] iteration 7998: loss: 0.113700, loss_s1: 0.032599, loss_fp: 0.001676, loss_freq: 0.044894
[13:20:58.147] iteration 7999: loss: 0.101888, loss_s1: 0.035422, loss_fp: 0.001257, loss_freq: 0.029992
[13:20:58.800] iteration 8000: loss: 0.094955, loss_s1: 0.046504, loss_fp: 0.004504, loss_freq: 0.023576
[13:21:02.175] iteration 8000 : mean_dice : 0.725840
[13:21:02.835] iteration 8001: loss: 0.105986, loss_s1: 0.089053, loss_fp: 0.000764, loss_freq: 0.033968
[13:21:03.482] iteration 8002: loss: 0.083297, loss_s1: 0.091071, loss_fp: 0.003217, loss_freq: 0.010544
[13:21:04.124] iteration 8003: loss: 0.066915, loss_s1: 0.037011, loss_fp: 0.003194, loss_freq: 0.015119
[13:21:04.815] iteration 8004: loss: 0.055894, loss_s1: 0.034354, loss_fp: 0.003367, loss_freq: 0.018015
[13:21:05.495] iteration 8005: loss: 0.082743, loss_s1: 0.027965, loss_fp: 0.000724, loss_freq: 0.013597
[13:21:06.173] iteration 8006: loss: 0.100380, loss_s1: 0.064919, loss_fp: 0.005023, loss_freq: 0.033713
[13:21:06.846] iteration 8007: loss: 0.117662, loss_s1: 0.122474, loss_fp: 0.003571, loss_freq: 0.020775
[13:21:07.520] iteration 8008: loss: 0.053322, loss_s1: 0.019209, loss_fp: 0.000477, loss_freq: 0.030001
[13:21:08.513] iteration 8009: loss: 0.052678, loss_s1: 0.019945, loss_fp: 0.003586, loss_freq: 0.009687
[13:21:09.184] iteration 8010: loss: 0.063125, loss_s1: 0.027217, loss_fp: 0.001364, loss_freq: 0.008593
[13:21:09.863] iteration 8011: loss: 0.071919, loss_s1: 0.044016, loss_fp: 0.000973, loss_freq: 0.032526
[13:21:10.545] iteration 8012: loss: 0.110621, loss_s1: 0.047138, loss_fp: 0.002143, loss_freq: 0.037375
[13:21:11.223] iteration 8013: loss: 0.099011, loss_s1: 0.043804, loss_fp: 0.001026, loss_freq: 0.063474
[13:21:11.895] iteration 8014: loss: 0.080914, loss_s1: 0.023246, loss_fp: 0.000657, loss_freq: 0.009579
[13:21:12.577] iteration 8015: loss: 0.056210, loss_s1: 0.045089, loss_fp: 0.002870, loss_freq: 0.017163
[13:21:13.255] iteration 8016: loss: 0.110122, loss_s1: 0.056469, loss_fp: 0.002774, loss_freq: 0.028962
[13:21:13.921] iteration 8017: loss: 0.085248, loss_s1: 0.048234, loss_fp: 0.000466, loss_freq: 0.016029
[13:21:14.591] iteration 8018: loss: 0.110194, loss_s1: 0.027634, loss_fp: 0.000502, loss_freq: 0.010133
[13:21:15.272] iteration 8019: loss: 0.111144, loss_s1: 0.056287, loss_fp: 0.004533, loss_freq: 0.051092
[13:21:15.919] iteration 8020: loss: 0.082409, loss_s1: 0.071511, loss_fp: 0.001382, loss_freq: 0.024683
[13:21:16.564] iteration 8021: loss: 0.071662, loss_s1: 0.045057, loss_fp: 0.002168, loss_freq: 0.020380
[13:21:17.206] iteration 8022: loss: 0.053760, loss_s1: 0.026481, loss_fp: 0.000546, loss_freq: 0.032720
[13:21:17.844] iteration 8023: loss: 0.092167, loss_s1: 0.079496, loss_fp: 0.005821, loss_freq: 0.020227
[13:21:18.484] iteration 8024: loss: 0.048106, loss_s1: 0.016551, loss_fp: 0.002210, loss_freq: 0.016246
[13:21:19.123] iteration 8025: loss: 0.167001, loss_s1: 0.072345, loss_fp: 0.002382, loss_freq: 0.020284
[13:21:19.760] iteration 8026: loss: 0.121698, loss_s1: 0.029246, loss_fp: 0.000812, loss_freq: 0.021237
[13:21:20.400] iteration 8027: loss: 0.069436, loss_s1: 0.013607, loss_fp: 0.002489, loss_freq: 0.025403
[13:21:21.040] iteration 8028: loss: 0.056853, loss_s1: 0.040369, loss_fp: 0.001413, loss_freq: 0.017693
[13:21:21.691] iteration 8029: loss: 0.119066, loss_s1: 0.041037, loss_fp: 0.001632, loss_freq: 0.044871
[13:21:22.340] iteration 8030: loss: 0.086383, loss_s1: 0.020992, loss_fp: 0.003179, loss_freq: 0.030260
[13:21:22.979] iteration 8031: loss: 0.106984, loss_s1: 0.037084, loss_fp: 0.000952, loss_freq: 0.074428
[13:21:23.634] iteration 8032: loss: 0.076983, loss_s1: 0.021830, loss_fp: 0.001590, loss_freq: 0.026887
[13:21:24.331] iteration 8033: loss: 0.080585, loss_s1: 0.073445, loss_fp: 0.001257, loss_freq: 0.011254
[13:21:24.988] iteration 8034: loss: 0.124253, loss_s1: 0.046037, loss_fp: 0.002204, loss_freq: 0.036583
[13:21:25.661] iteration 8035: loss: 0.090760, loss_s1: 0.027472, loss_fp: 0.002306, loss_freq: 0.045172
[13:21:26.312] iteration 8036: loss: 0.083291, loss_s1: 0.047080, loss_fp: 0.003642, loss_freq: 0.017796
[13:21:26.955] iteration 8037: loss: 0.143662, loss_s1: 0.062552, loss_fp: 0.004734, loss_freq: 0.045624
[13:21:27.617] iteration 8038: loss: 0.116332, loss_s1: 0.044339, loss_fp: 0.001845, loss_freq: 0.019146
[13:21:28.269] iteration 8039: loss: 0.123059, loss_s1: 0.078758, loss_fp: 0.005514, loss_freq: 0.025952
[13:21:28.918] iteration 8040: loss: 0.101445, loss_s1: 0.047289, loss_fp: 0.006918, loss_freq: 0.038747
[13:21:29.570] iteration 8041: loss: 0.091860, loss_s1: 0.052945, loss_fp: 0.004643, loss_freq: 0.015118
[13:21:30.248] iteration 8042: loss: 0.101692, loss_s1: 0.030926, loss_fp: 0.010954, loss_freq: 0.050538
[13:21:30.938] iteration 8043: loss: 0.077747, loss_s1: 0.029812, loss_fp: 0.004288, loss_freq: 0.014852
[13:21:31.619] iteration 8044: loss: 0.101202, loss_s1: 0.044192, loss_fp: 0.002093, loss_freq: 0.064110
[13:21:32.309] iteration 8045: loss: 0.095305, loss_s1: 0.083502, loss_fp: 0.002229, loss_freq: 0.031501
[13:21:33.013] iteration 8046: loss: 0.077076, loss_s1: 0.019720, loss_fp: 0.001403, loss_freq: 0.020055
[13:21:33.744] iteration 8047: loss: 0.105609, loss_s1: 0.059185, loss_fp: 0.002360, loss_freq: 0.034483
[13:21:34.416] iteration 8048: loss: 0.073044, loss_s1: 0.037066, loss_fp: 0.001538, loss_freq: 0.018453
[13:21:35.090] iteration 8049: loss: 0.092382, loss_s1: 0.031548, loss_fp: 0.001742, loss_freq: 0.009457
[13:21:35.745] iteration 8050: loss: 0.085573, loss_s1: 0.067059, loss_fp: 0.002899, loss_freq: 0.047623
[13:21:36.386] iteration 8051: loss: 0.095732, loss_s1: 0.042662, loss_fp: 0.000686, loss_freq: 0.020196
[13:21:37.024] iteration 8052: loss: 0.081068, loss_s1: 0.025325, loss_fp: 0.010605, loss_freq: 0.064119
[13:21:37.663] iteration 8053: loss: 0.098897, loss_s1: 0.022432, loss_fp: 0.000534, loss_freq: 0.025709
[13:21:38.305] iteration 8054: loss: 0.108733, loss_s1: 0.051825, loss_fp: 0.005410, loss_freq: 0.063734
[13:21:38.944] iteration 8055: loss: 0.057987, loss_s1: 0.013394, loss_fp: 0.000681, loss_freq: 0.024443
[13:21:39.599] iteration 8056: loss: 0.053030, loss_s1: 0.015085, loss_fp: 0.000601, loss_freq: 0.016430
[13:21:40.241] iteration 8057: loss: 0.078029, loss_s1: 0.053343, loss_fp: 0.001820, loss_freq: 0.023843
[13:21:40.885] iteration 8058: loss: 0.052674, loss_s1: 0.017409, loss_fp: 0.000861, loss_freq: 0.021368
[13:21:41.551] iteration 8059: loss: 0.066516, loss_s1: 0.026056, loss_fp: 0.002709, loss_freq: 0.025505
[13:21:42.221] iteration 8060: loss: 0.122060, loss_s1: 0.042067, loss_fp: 0.002598, loss_freq: 0.030562
[13:21:42.890] iteration 8061: loss: 0.063482, loss_s1: 0.031508, loss_fp: 0.001545, loss_freq: 0.006541
[13:21:43.554] iteration 8062: loss: 0.057341, loss_s1: 0.021269, loss_fp: 0.001631, loss_freq: 0.014720
[13:21:44.181] iteration 8063: loss: 0.074040, loss_s1: 0.058995, loss_fp: 0.005828, loss_freq: 0.031948
[13:21:44.816] iteration 8064: loss: 0.095916, loss_s1: 0.062033, loss_fp: 0.000971, loss_freq: 0.014187
[13:21:45.523] iteration 8065: loss: 0.111027, loss_s1: 0.096890, loss_fp: 0.002175, loss_freq: 0.036520
[13:21:46.195] iteration 8066: loss: 0.067391, loss_s1: 0.002038, loss_fp: 0.007045, loss_freq: 0.053282
[13:21:46.879] iteration 8067: loss: 0.229017, loss_s1: 0.062748, loss_fp: 0.001901, loss_freq: 0.143860
[13:21:47.521] iteration 8068: loss: 0.075875, loss_s1: 0.034448, loss_fp: 0.003361, loss_freq: 0.053024
[13:21:48.165] iteration 8069: loss: 0.098027, loss_s1: 0.056184, loss_fp: 0.005656, loss_freq: 0.024068
[13:21:48.825] iteration 8070: loss: 0.106973, loss_s1: 0.047121, loss_fp: 0.001096, loss_freq: 0.038742
[13:21:49.478] iteration 8071: loss: 0.073824, loss_s1: 0.015292, loss_fp: 0.001159, loss_freq: 0.023252
[13:21:50.130] iteration 8072: loss: 0.075063, loss_s1: 0.015258, loss_fp: 0.006715, loss_freq: 0.034190
[13:21:50.776] iteration 8073: loss: 0.144358, loss_s1: 0.053510, loss_fp: 0.006355, loss_freq: 0.056325
[13:21:51.439] iteration 8074: loss: 0.159488, loss_s1: 0.048843, loss_fp: 0.001038, loss_freq: 0.045360
[13:21:52.087] iteration 8075: loss: 0.117519, loss_s1: 0.066317, loss_fp: 0.001894, loss_freq: 0.059174
[13:21:52.739] iteration 8076: loss: 0.141235, loss_s1: 0.083247, loss_fp: 0.002160, loss_freq: 0.011591
[13:21:53.384] iteration 8077: loss: 0.107362, loss_s1: 0.078724, loss_fp: 0.003107, loss_freq: 0.038099
[13:21:54.035] iteration 8078: loss: 0.115884, loss_s1: 0.066482, loss_fp: 0.004632, loss_freq: 0.032569
[13:21:54.679] iteration 8079: loss: 0.078165, loss_s1: 0.039414, loss_fp: 0.001294, loss_freq: 0.019545
[13:21:55.337] iteration 8080: loss: 0.060520, loss_s1: 0.012349, loss_fp: 0.001186, loss_freq: 0.011475
[13:21:55.990] iteration 8081: loss: 0.069286, loss_s1: 0.010501, loss_fp: 0.001245, loss_freq: 0.063306
[13:21:56.654] iteration 8082: loss: 0.118990, loss_s1: 0.088187, loss_fp: 0.001563, loss_freq: 0.010095
[13:21:57.338] iteration 8083: loss: 0.109926, loss_s1: 0.063861, loss_fp: 0.005084, loss_freq: 0.063137
[13:21:57.986] iteration 8084: loss: 0.083089, loss_s1: 0.030562, loss_fp: 0.004459, loss_freq: 0.010268
[13:21:58.619] iteration 8085: loss: 0.092422, loss_s1: 0.059795, loss_fp: 0.001799, loss_freq: 0.045847
[13:21:59.251] iteration 8086: loss: 0.092917, loss_s1: 0.031233, loss_fp: 0.001752, loss_freq: 0.038536
[13:21:59.914] iteration 8087: loss: 0.113537, loss_s1: 0.075150, loss_fp: 0.004945, loss_freq: 0.069804
[13:22:00.551] iteration 8088: loss: 0.186811, loss_s1: 0.127935, loss_fp: 0.002616, loss_freq: 0.023637
[13:22:01.203] iteration 8089: loss: 0.089935, loss_s1: 0.037406, loss_fp: 0.001594, loss_freq: 0.021206
[13:22:01.852] iteration 8090: loss: 0.118018, loss_s1: 0.086017, loss_fp: 0.013154, loss_freq: 0.043524
[13:22:02.495] iteration 8091: loss: 0.082386, loss_s1: 0.036865, loss_fp: 0.000522, loss_freq: 0.024553
[13:22:03.147] iteration 8092: loss: 0.099900, loss_s1: 0.090646, loss_fp: 0.005286, loss_freq: 0.037033
[13:22:03.788] iteration 8093: loss: 0.111770, loss_s1: 0.082974, loss_fp: 0.001400, loss_freq: 0.028764
[13:22:04.436] iteration 8094: loss: 0.101210, loss_s1: 0.029683, loss_fp: 0.002809, loss_freq: 0.075472
[13:22:05.086] iteration 8095: loss: 0.112615, loss_s1: 0.031822, loss_fp: 0.003464, loss_freq: 0.012597
[13:22:05.741] iteration 8096: loss: 0.058628, loss_s1: 0.012870, loss_fp: 0.000726, loss_freq: 0.027199
[13:22:06.383] iteration 8097: loss: 0.082866, loss_s1: 0.075149, loss_fp: 0.001216, loss_freq: 0.014338
[13:22:07.065] iteration 8098: loss: 0.068271, loss_s1: 0.075141, loss_fp: 0.001964, loss_freq: 0.007732
[13:22:07.721] iteration 8099: loss: 0.111516, loss_s1: 0.020612, loss_fp: 0.000979, loss_freq: 0.020061
[13:22:08.374] iteration 8100: loss: 0.067160, loss_s1: 0.042383, loss_fp: 0.003518, loss_freq: 0.016032
[13:22:09.031] iteration 8101: loss: 0.048696, loss_s1: 0.010776, loss_fp: 0.002228, loss_freq: 0.015067
[13:22:09.678] iteration 8102: loss: 0.133351, loss_s1: 0.072432, loss_fp: 0.010142, loss_freq: 0.020660
[13:22:10.340] iteration 8103: loss: 0.055063, loss_s1: 0.034148, loss_fp: 0.006876, loss_freq: 0.008424
[13:22:10.994] iteration 8104: loss: 0.133226, loss_s1: 0.115859, loss_fp: 0.003173, loss_freq: 0.072844
[13:22:11.655] iteration 8105: loss: 0.090549, loss_s1: 0.033954, loss_fp: 0.002498, loss_freq: 0.039329
[13:22:12.305] iteration 8106: loss: 0.095686, loss_s1: 0.051406, loss_fp: 0.001022, loss_freq: 0.058717
[13:22:12.947] iteration 8107: loss: 0.156399, loss_s1: 0.081182, loss_fp: 0.003673, loss_freq: 0.030957
[13:22:13.590] iteration 8108: loss: 0.105726, loss_s1: 0.057548, loss_fp: 0.002462, loss_freq: 0.062178
[13:22:14.226] iteration 8109: loss: 0.089798, loss_s1: 0.014947, loss_fp: 0.001439, loss_freq: 0.025654
[13:22:14.863] iteration 8110: loss: 0.076508, loss_s1: 0.056413, loss_fp: 0.001470, loss_freq: 0.012294
[13:22:15.507] iteration 8111: loss: 0.084512, loss_s1: 0.079192, loss_fp: 0.000463, loss_freq: 0.017215
[13:22:16.140] iteration 8112: loss: 0.105541, loss_s1: 0.047538, loss_fp: 0.000671, loss_freq: 0.024305
[13:22:16.774] iteration 8113: loss: 0.111657, loss_s1: 0.044180, loss_fp: 0.002267, loss_freq: 0.020472
[13:22:17.419] iteration 8114: loss: 0.080094, loss_s1: 0.034451, loss_fp: 0.003531, loss_freq: 0.018095
[13:22:18.117] iteration 8115: loss: 0.123578, loss_s1: 0.089321, loss_fp: 0.000515, loss_freq: 0.071643
[13:22:18.787] iteration 8116: loss: 0.057515, loss_s1: 0.014274, loss_fp: 0.001198, loss_freq: 0.026383
[13:22:19.469] iteration 8117: loss: 0.066849, loss_s1: 0.036342, loss_fp: 0.002214, loss_freq: 0.019953
[13:22:20.140] iteration 8118: loss: 0.101750, loss_s1: 0.103152, loss_fp: 0.001727, loss_freq: 0.041462
[13:22:20.820] iteration 8119: loss: 0.091647, loss_s1: 0.040926, loss_fp: 0.000727, loss_freq: 0.008460
[13:22:21.499] iteration 8120: loss: 0.055340, loss_s1: 0.033281, loss_fp: 0.001414, loss_freq: 0.024897
[13:22:22.167] iteration 8121: loss: 0.091553, loss_s1: 0.069972, loss_fp: 0.001009, loss_freq: 0.009350
[13:22:22.864] iteration 8122: loss: 0.061196, loss_s1: 0.021393, loss_fp: 0.002679, loss_freq: 0.017374
[13:22:23.515] iteration 8123: loss: 0.166511, loss_s1: 0.025149, loss_fp: 0.001326, loss_freq: 0.020200
[13:22:24.156] iteration 8124: loss: 0.075313, loss_s1: 0.035953, loss_fp: 0.001278, loss_freq: 0.006797
[13:22:24.807] iteration 8125: loss: 0.167597, loss_s1: 0.059570, loss_fp: 0.003481, loss_freq: 0.024332
[13:22:25.440] iteration 8126: loss: 0.110845, loss_s1: 0.044968, loss_fp: 0.001335, loss_freq: 0.067670
[13:22:26.074] iteration 8127: loss: 0.077183, loss_s1: 0.077036, loss_fp: 0.001165, loss_freq: 0.029902
[13:22:26.705] iteration 8128: loss: 0.066167, loss_s1: 0.053880, loss_fp: 0.001579, loss_freq: 0.023201
[13:22:27.353] iteration 8129: loss: 0.076529, loss_s1: 0.031735, loss_fp: 0.001561, loss_freq: 0.056408
[13:22:28.025] iteration 8130: loss: 0.191314, loss_s1: 0.072133, loss_fp: 0.001461, loss_freq: 0.017782
[13:22:28.665] iteration 8131: loss: 0.063557, loss_s1: 0.029840, loss_fp: 0.001747, loss_freq: 0.011066
[13:22:29.308] iteration 8132: loss: 0.073742, loss_s1: 0.023450, loss_fp: 0.001886, loss_freq: 0.045387
[13:22:29.944] iteration 8133: loss: 0.092748, loss_s1: 0.071716, loss_fp: 0.001237, loss_freq: 0.051295
[13:22:30.588] iteration 8134: loss: 0.123391, loss_s1: 0.022625, loss_fp: 0.003038, loss_freq: 0.031060
[13:22:31.227] iteration 8135: loss: 0.067326, loss_s1: 0.035902, loss_fp: 0.009671, loss_freq: 0.020278
[13:22:31.863] iteration 8136: loss: 0.087072, loss_s1: 0.037999, loss_fp: 0.000787, loss_freq: 0.026176
[13:22:32.507] iteration 8137: loss: 0.129407, loss_s1: 0.077570, loss_fp: 0.015080, loss_freq: 0.014063
[13:22:33.148] iteration 8138: loss: 0.060193, loss_s1: 0.015253, loss_fp: 0.001234, loss_freq: 0.002679
[13:22:33.799] iteration 8139: loss: 0.076071, loss_s1: 0.021989, loss_fp: 0.000918, loss_freq: 0.008544
[13:22:34.436] iteration 8140: loss: 0.180800, loss_s1: 0.110017, loss_fp: 0.006267, loss_freq: 0.035992
[13:22:35.071] iteration 8141: loss: 0.089594, loss_s1: 0.066993, loss_fp: 0.003547, loss_freq: 0.027017
[13:22:35.707] iteration 8142: loss: 0.121939, loss_s1: 0.040261, loss_fp: 0.004176, loss_freq: 0.055258
[13:22:36.346] iteration 8143: loss: 0.110646, loss_s1: 0.047478, loss_fp: 0.001910, loss_freq: 0.025006
[13:22:36.987] iteration 8144: loss: 0.092959, loss_s1: 0.035191, loss_fp: 0.004242, loss_freq: 0.027271
[13:22:37.627] iteration 8145: loss: 0.083117, loss_s1: 0.040745, loss_fp: 0.004940, loss_freq: 0.013817
[13:22:38.266] iteration 8146: loss: 0.080590, loss_s1: 0.074352, loss_fp: 0.003945, loss_freq: 0.016594
[13:22:38.904] iteration 8147: loss: 0.102751, loss_s1: 0.059739, loss_fp: 0.001183, loss_freq: 0.014684
[13:22:39.555] iteration 8148: loss: 0.066209, loss_s1: 0.020896, loss_fp: 0.001159, loss_freq: 0.014897
[13:22:40.256] iteration 8149: loss: 0.107841, loss_s1: 0.067574, loss_fp: 0.005166, loss_freq: 0.035569
[13:22:40.922] iteration 8150: loss: 0.137199, loss_s1: 0.133390, loss_fp: 0.001465, loss_freq: 0.055076
[13:22:41.585] iteration 8151: loss: 0.074240, loss_s1: 0.049907, loss_fp: 0.002489, loss_freq: 0.024306
[13:22:42.603] iteration 8152: loss: 0.057146, loss_s1: 0.027418, loss_fp: 0.000801, loss_freq: 0.008439
[13:22:43.286] iteration 8153: loss: 0.089030, loss_s1: 0.041175, loss_fp: 0.004720, loss_freq: 0.037339
[13:22:43.995] iteration 8154: loss: 0.068256, loss_s1: 0.038683, loss_fp: 0.001053, loss_freq: 0.034060
[13:22:44.671] iteration 8155: loss: 0.126745, loss_s1: 0.101799, loss_fp: 0.005847, loss_freq: 0.020739
[13:22:45.353] iteration 8156: loss: 0.127797, loss_s1: 0.058691, loss_fp: 0.004000, loss_freq: 0.041189
[13:22:46.016] iteration 8157: loss: 0.078521, loss_s1: 0.014596, loss_fp: 0.001469, loss_freq: 0.003127
[13:22:46.651] iteration 8158: loss: 0.065536, loss_s1: 0.047847, loss_fp: 0.011522, loss_freq: 0.025480
[13:22:47.316] iteration 8159: loss: 0.187835, loss_s1: 0.140014, loss_fp: 0.004317, loss_freq: 0.017442
[13:22:47.983] iteration 8160: loss: 0.056612, loss_s1: 0.013111, loss_fp: 0.000830, loss_freq: 0.035219
[13:22:48.663] iteration 8161: loss: 0.110418, loss_s1: 0.034248, loss_fp: 0.000930, loss_freq: 0.012953
[13:22:49.338] iteration 8162: loss: 0.111874, loss_s1: 0.066420, loss_fp: 0.001999, loss_freq: 0.036838
[13:22:50.008] iteration 8163: loss: 0.060974, loss_s1: 0.020463, loss_fp: 0.000936, loss_freq: 0.030884
[13:22:50.647] iteration 8164: loss: 0.074992, loss_s1: 0.073048, loss_fp: 0.001190, loss_freq: 0.010763
[13:22:51.289] iteration 8165: loss: 0.050820, loss_s1: 0.020487, loss_fp: 0.003256, loss_freq: 0.019635
[13:22:51.923] iteration 8166: loss: 0.068877, loss_s1: 0.037009, loss_fp: 0.001959, loss_freq: 0.034291
[13:22:52.565] iteration 8167: loss: 0.074729, loss_s1: 0.054835, loss_fp: 0.007266, loss_freq: 0.019022
[13:22:53.202] iteration 8168: loss: 0.181140, loss_s1: 0.009793, loss_fp: 0.000423, loss_freq: 0.028579
[13:22:53.842] iteration 8169: loss: 0.108517, loss_s1: 0.031194, loss_fp: 0.000795, loss_freq: 0.011791
[13:22:54.483] iteration 8170: loss: 0.066232, loss_s1: 0.049099, loss_fp: 0.000529, loss_freq: 0.017608
[13:22:55.129] iteration 8171: loss: 0.060000, loss_s1: 0.043863, loss_fp: 0.000488, loss_freq: 0.014061
[13:22:55.765] iteration 8172: loss: 0.147491, loss_s1: 0.088349, loss_fp: 0.005496, loss_freq: 0.077965
[13:22:56.407] iteration 8173: loss: 0.095746, loss_s1: 0.064381, loss_fp: 0.002366, loss_freq: 0.041086
[13:22:57.039] iteration 8174: loss: 0.066711, loss_s1: 0.032785, loss_fp: 0.001657, loss_freq: 0.027623
[13:22:57.672] iteration 8175: loss: 0.068211, loss_s1: 0.020478, loss_fp: 0.001897, loss_freq: 0.027178
[13:22:58.395] iteration 8176: loss: 0.066175, loss_s1: 0.032872, loss_fp: 0.003509, loss_freq: 0.036191
[13:22:59.072] iteration 8177: loss: 0.076296, loss_s1: 0.047439, loss_fp: 0.001488, loss_freq: 0.023390
[13:22:59.753] iteration 8178: loss: 0.099714, loss_s1: 0.053566, loss_fp: 0.000964, loss_freq: 0.071919
[13:23:00.505] iteration 8179: loss: 0.071984, loss_s1: 0.032453, loss_fp: 0.000583, loss_freq: 0.014382
[13:23:01.339] iteration 8180: loss: 0.136274, loss_s1: 0.076437, loss_fp: 0.001190, loss_freq: 0.073440
[13:23:02.032] iteration 8181: loss: 0.090853, loss_s1: 0.030181, loss_fp: 0.000529, loss_freq: 0.013947
[13:23:02.668] iteration 8182: loss: 0.088950, loss_s1: 0.042670, loss_fp: 0.001717, loss_freq: 0.012738
[13:23:03.356] iteration 8183: loss: 0.057319, loss_s1: 0.015981, loss_fp: 0.000508, loss_freq: 0.015055
[13:23:04.028] iteration 8184: loss: 0.122776, loss_s1: 0.120200, loss_fp: 0.004202, loss_freq: 0.013540
[13:23:04.703] iteration 8185: loss: 0.112569, loss_s1: 0.098096, loss_fp: 0.007092, loss_freq: 0.069475
[13:23:05.366] iteration 8186: loss: 0.149734, loss_s1: 0.068706, loss_fp: 0.000948, loss_freq: 0.041470
[13:23:06.060] iteration 8187: loss: 0.113995, loss_s1: 0.050116, loss_fp: 0.002144, loss_freq: 0.045953
[13:23:06.713] iteration 8188: loss: 0.129144, loss_s1: 0.073355, loss_fp: 0.004079, loss_freq: 0.061837
[13:23:07.366] iteration 8189: loss: 0.071338, loss_s1: 0.023241, loss_fp: 0.003814, loss_freq: 0.049096
[13:23:08.000] iteration 8190: loss: 0.109348, loss_s1: 0.049200, loss_fp: 0.002421, loss_freq: 0.069328
[13:23:08.636] iteration 8191: loss: 0.078242, loss_s1: 0.044139, loss_fp: 0.001117, loss_freq: 0.020190
[13:23:09.273] iteration 8192: loss: 0.125294, loss_s1: 0.103474, loss_fp: 0.005794, loss_freq: 0.006516
[13:23:09.909] iteration 8193: loss: 0.072733, loss_s1: 0.077632, loss_fp: 0.001561, loss_freq: 0.015503
[13:23:10.544] iteration 8194: loss: 0.104451, loss_s1: 0.040045, loss_fp: 0.001401, loss_freq: 0.024193
[13:23:11.177] iteration 8195: loss: 0.061034, loss_s1: 0.046570, loss_fp: 0.001344, loss_freq: 0.012791
[13:23:11.834] iteration 8196: loss: 0.180696, loss_s1: 0.050363, loss_fp: 0.001495, loss_freq: 0.045194
[13:23:12.475] iteration 8197: loss: 0.092126, loss_s1: 0.046399, loss_fp: 0.001395, loss_freq: 0.055817
[13:23:13.136] iteration 8198: loss: 0.072339, loss_s1: 0.035090, loss_fp: 0.006589, loss_freq: 0.034711
[13:23:13.772] iteration 8199: loss: 0.063266, loss_s1: 0.017542, loss_fp: 0.001834, loss_freq: 0.019911
[13:23:14.415] iteration 8200: loss: 0.062814, loss_s1: 0.032912, loss_fp: 0.001315, loss_freq: 0.019909
[13:23:17.640] iteration 8200 : mean_dice : 0.702839
[13:23:18.314] iteration 8201: loss: 0.105633, loss_s1: 0.054453, loss_fp: 0.002999, loss_freq: 0.042799
[13:23:18.973] iteration 8202: loss: 0.068535, loss_s1: 0.053179, loss_fp: 0.004508, loss_freq: 0.015847
[13:23:19.614] iteration 8203: loss: 0.152641, loss_s1: 0.021587, loss_fp: 0.001730, loss_freq: 0.026089
[13:23:20.272] iteration 8204: loss: 0.075567, loss_s1: 0.034930, loss_fp: 0.003608, loss_freq: 0.010651
[13:23:20.937] iteration 8205: loss: 0.042622, loss_s1: 0.014354, loss_fp: 0.001849, loss_freq: 0.014537
[13:23:21.589] iteration 8206: loss: 0.055278, loss_s1: 0.040537, loss_fp: 0.001102, loss_freq: 0.017663
[13:23:22.227] iteration 8207: loss: 0.107166, loss_s1: 0.023395, loss_fp: 0.001027, loss_freq: 0.014136
[13:23:22.862] iteration 8208: loss: 0.076547, loss_s1: 0.021877, loss_fp: 0.002428, loss_freq: 0.060963
[13:23:23.588] iteration 8209: loss: 0.056896, loss_s1: 0.024695, loss_fp: 0.007147, loss_freq: 0.007607
[13:23:24.265] iteration 8210: loss: 0.187318, loss_s1: 0.098724, loss_fp: 0.010144, loss_freq: 0.070917
[13:23:24.938] iteration 8211: loss: 0.056666, loss_s1: 0.029673, loss_fp: 0.002175, loss_freq: 0.014605
[13:23:25.635] iteration 8212: loss: 0.069106, loss_s1: 0.014918, loss_fp: 0.003931, loss_freq: 0.010605
[13:23:26.306] iteration 8213: loss: 0.112660, loss_s1: 0.040157, loss_fp: 0.013343, loss_freq: 0.030085
[13:23:26.975] iteration 8214: loss: 0.088604, loss_s1: 0.078682, loss_fp: 0.002923, loss_freq: 0.009912
[13:23:27.637] iteration 8215: loss: 0.085458, loss_s1: 0.013509, loss_fp: 0.001269, loss_freq: 0.016129
[13:23:28.274] iteration 8216: loss: 0.123651, loss_s1: 0.070702, loss_fp: 0.006765, loss_freq: 0.018585
[13:23:28.907] iteration 8217: loss: 0.108649, loss_s1: 0.044297, loss_fp: 0.006782, loss_freq: 0.015770
[13:23:29.542] iteration 8218: loss: 0.149014, loss_s1: 0.077475, loss_fp: 0.004940, loss_freq: 0.067335
[13:23:30.176] iteration 8219: loss: 0.109786, loss_s1: 0.011453, loss_fp: 0.001886, loss_freq: 0.025828
[13:23:30.820] iteration 8220: loss: 0.071136, loss_s1: 0.037852, loss_fp: 0.002900, loss_freq: 0.010087
[13:23:31.456] iteration 8221: loss: 0.143388, loss_s1: 0.067196, loss_fp: 0.005300, loss_freq: 0.041466
[13:23:32.101] iteration 8222: loss: 0.134947, loss_s1: 0.082355, loss_fp: 0.002203, loss_freq: 0.021539
[13:23:32.742] iteration 8223: loss: 0.104521, loss_s1: 0.075700, loss_fp: 0.001383, loss_freq: 0.046379
[13:23:33.380] iteration 8224: loss: 0.075328, loss_s1: 0.057871, loss_fp: 0.000556, loss_freq: 0.027378
[13:23:34.014] iteration 8225: loss: 0.111358, loss_s1: 0.068951, loss_fp: 0.016363, loss_freq: 0.048024
[13:23:34.657] iteration 8226: loss: 0.109827, loss_s1: 0.076988, loss_fp: 0.001524, loss_freq: 0.046346
[13:23:35.295] iteration 8227: loss: 0.100463, loss_s1: 0.058269, loss_fp: 0.000648, loss_freq: 0.026786
[13:23:35.933] iteration 8228: loss: 0.059727, loss_s1: 0.019776, loss_fp: 0.001349, loss_freq: 0.006813
[13:23:36.576] iteration 8229: loss: 0.103507, loss_s1: 0.045798, loss_fp: 0.001238, loss_freq: 0.005940
[13:23:37.222] iteration 8230: loss: 0.078685, loss_s1: 0.047072, loss_fp: 0.001700, loss_freq: 0.041221
[13:23:37.867] iteration 8231: loss: 0.193099, loss_s1: 0.070036, loss_fp: 0.000849, loss_freq: 0.038968
[13:23:38.502] iteration 8232: loss: 0.083769, loss_s1: 0.042730, loss_fp: 0.003658, loss_freq: 0.029427
[13:23:39.139] iteration 8233: loss: 0.113735, loss_s1: 0.081629, loss_fp: 0.002408, loss_freq: 0.033120
[13:23:39.804] iteration 8234: loss: 0.111485, loss_s1: 0.084383, loss_fp: 0.000518, loss_freq: 0.014532
[13:23:40.466] iteration 8235: loss: 0.054345, loss_s1: 0.045497, loss_fp: 0.001155, loss_freq: 0.004322
[13:23:41.130] iteration 8236: loss: 0.091343, loss_s1: 0.015562, loss_fp: 0.000518, loss_freq: 0.019710
[13:23:41.805] iteration 8237: loss: 0.115160, loss_s1: 0.088538, loss_fp: 0.001330, loss_freq: 0.064452
[13:23:42.448] iteration 8238: loss: 0.156778, loss_s1: 0.050783, loss_fp: 0.000941, loss_freq: 0.023594
[13:23:43.092] iteration 8239: loss: 0.113814, loss_s1: 0.047351, loss_fp: 0.000735, loss_freq: 0.015719
[13:23:43.734] iteration 8240: loss: 0.047534, loss_s1: 0.020386, loss_fp: 0.001189, loss_freq: 0.012393
[13:23:44.382] iteration 8241: loss: 0.113471, loss_s1: 0.055448, loss_fp: 0.002624, loss_freq: 0.009082
[13:23:45.014] iteration 8242: loss: 0.092930, loss_s1: 0.033031, loss_fp: 0.001054, loss_freq: 0.021737
[13:23:45.668] iteration 8243: loss: 0.117851, loss_s1: 0.105653, loss_fp: 0.006336, loss_freq: 0.054564
[13:23:46.306] iteration 8244: loss: 0.079132, loss_s1: 0.078019, loss_fp: 0.001254, loss_freq: 0.007499
[13:23:46.973] iteration 8245: loss: 0.118538, loss_s1: 0.060465, loss_fp: 0.011958, loss_freq: 0.049976
[13:23:47.638] iteration 8246: loss: 0.075268, loss_s1: 0.036235, loss_fp: 0.000795, loss_freq: 0.034520
[13:23:48.310] iteration 8247: loss: 0.085418, loss_s1: 0.050787, loss_fp: 0.001000, loss_freq: 0.024718
[13:23:48.998] iteration 8248: loss: 0.136285, loss_s1: 0.057144, loss_fp: 0.001358, loss_freq: 0.125575
[13:23:49.659] iteration 8249: loss: 0.093847, loss_s1: 0.073444, loss_fp: 0.001175, loss_freq: 0.017003
[13:23:50.297] iteration 8250: loss: 0.134326, loss_s1: 0.041172, loss_fp: 0.000725, loss_freq: 0.045345
[13:23:50.934] iteration 8251: loss: 0.115599, loss_s1: 0.065839, loss_fp: 0.004760, loss_freq: 0.049092
[13:23:51.579] iteration 8252: loss: 0.099840, loss_s1: 0.061473, loss_fp: 0.003756, loss_freq: 0.026681
[13:23:52.217] iteration 8253: loss: 0.057739, loss_s1: 0.024979, loss_fp: 0.002700, loss_freq: 0.016148
[13:23:52.884] iteration 8254: loss: 0.091971, loss_s1: 0.096538, loss_fp: 0.000463, loss_freq: 0.010098
[13:23:53.567] iteration 8255: loss: 0.078102, loss_s1: 0.042341, loss_fp: 0.000897, loss_freq: 0.033582
[13:23:54.247] iteration 8256: loss: 0.129083, loss_s1: 0.058773, loss_fp: 0.001212, loss_freq: 0.019135
[13:23:54.903] iteration 8257: loss: 0.085667, loss_s1: 0.045947, loss_fp: 0.002030, loss_freq: 0.018338
[13:23:55.539] iteration 8258: loss: 0.170523, loss_s1: 0.107255, loss_fp: 0.002499, loss_freq: 0.115430
[13:23:56.170] iteration 8259: loss: 0.107266, loss_s1: 0.094112, loss_fp: 0.008971, loss_freq: 0.039821
[13:23:56.860] iteration 8260: loss: 0.072696, loss_s1: 0.025748, loss_fp: 0.002857, loss_freq: 0.005444
[13:23:57.504] iteration 8261: loss: 0.083233, loss_s1: 0.058439, loss_fp: 0.003144, loss_freq: 0.022303
[13:23:58.141] iteration 8262: loss: 0.089102, loss_s1: 0.025470, loss_fp: 0.001014, loss_freq: 0.014909
[13:23:58.782] iteration 8263: loss: 0.074986, loss_s1: 0.061161, loss_fp: 0.002410, loss_freq: 0.023682
[13:23:59.415] iteration 8264: loss: 0.114626, loss_s1: 0.071681, loss_fp: 0.002155, loss_freq: 0.021505
[13:24:00.052] iteration 8265: loss: 0.110315, loss_s1: 0.077561, loss_fp: 0.008771, loss_freq: 0.050882
[13:24:00.695] iteration 8266: loss: 0.195790, loss_s1: 0.018430, loss_fp: 0.002828, loss_freq: 0.047890
[13:24:01.334] iteration 8267: loss: 0.114774, loss_s1: 0.100122, loss_fp: 0.002682, loss_freq: 0.015417
[13:24:01.971] iteration 8268: loss: 0.105749, loss_s1: 0.056372, loss_fp: 0.004325, loss_freq: 0.055073
[13:24:02.606] iteration 8269: loss: 0.074646, loss_s1: 0.056569, loss_fp: 0.001231, loss_freq: 0.013382
[13:24:03.239] iteration 8270: loss: 0.079339, loss_s1: 0.069574, loss_fp: 0.005436, loss_freq: 0.031168
[13:24:03.907] iteration 8271: loss: 0.162911, loss_s1: 0.104506, loss_fp: 0.008411, loss_freq: 0.080490
[13:24:04.548] iteration 8272: loss: 0.092405, loss_s1: 0.037018, loss_fp: 0.007000, loss_freq: 0.078909
[13:24:05.179] iteration 8273: loss: 0.131498, loss_s1: 0.059104, loss_fp: 0.001289, loss_freq: 0.054775
[13:24:05.815] iteration 8274: loss: 0.052622, loss_s1: 0.042476, loss_fp: 0.002991, loss_freq: 0.002867
[13:24:06.450] iteration 8275: loss: 0.094855, loss_s1: 0.072674, loss_fp: 0.003843, loss_freq: 0.046884
[13:24:07.088] iteration 8276: loss: 0.110773, loss_s1: 0.084991, loss_fp: 0.000803, loss_freq: 0.061631
[13:24:07.725] iteration 8277: loss: 0.100702, loss_s1: 0.048268, loss_fp: 0.002218, loss_freq: 0.027499
[13:24:08.359] iteration 8278: loss: 0.059885, loss_s1: 0.039890, loss_fp: 0.000686, loss_freq: 0.020844
[13:24:09.049] iteration 8279: loss: 0.071912, loss_s1: 0.040679, loss_fp: 0.000868, loss_freq: 0.011012
[13:24:09.724] iteration 8280: loss: 0.117764, loss_s1: 0.062016, loss_fp: 0.008563, loss_freq: 0.025884
[13:24:10.361] iteration 8281: loss: 0.054682, loss_s1: 0.028210, loss_fp: 0.002401, loss_freq: 0.004252
[13:24:10.988] iteration 8282: loss: 0.082530, loss_s1: 0.017462, loss_fp: 0.000476, loss_freq: 0.011492
[13:24:11.640] iteration 8283: loss: 0.165959, loss_s1: 0.071816, loss_fp: 0.002289, loss_freq: 0.022584
[13:24:12.321] iteration 8284: loss: 0.109120, loss_s1: 0.080034, loss_fp: 0.001359, loss_freq: 0.045896
[13:24:12.981] iteration 8285: loss: 0.130872, loss_s1: 0.038736, loss_fp: 0.009147, loss_freq: 0.069529
[13:24:13.643] iteration 8286: loss: 0.132797, loss_s1: 0.055810, loss_fp: 0.001832, loss_freq: 0.042919
[13:24:14.283] iteration 8287: loss: 0.091037, loss_s1: 0.047090, loss_fp: 0.001380, loss_freq: 0.027805
[13:24:14.915] iteration 8288: loss: 0.100567, loss_s1: 0.101002, loss_fp: 0.007494, loss_freq: 0.011223
[13:24:15.546] iteration 8289: loss: 0.140283, loss_s1: 0.042352, loss_fp: 0.000989, loss_freq: 0.015108
[13:24:16.187] iteration 8290: loss: 0.104322, loss_s1: 0.052372, loss_fp: 0.003117, loss_freq: 0.024386
[13:24:16.822] iteration 8291: loss: 0.109115, loss_s1: 0.069191, loss_fp: 0.002704, loss_freq: 0.017214
[13:24:17.457] iteration 8292: loss: 0.079939, loss_s1: 0.040731, loss_fp: 0.013498, loss_freq: 0.029871
[13:24:18.093] iteration 8293: loss: 0.159339, loss_s1: 0.131621, loss_fp: 0.007307, loss_freq: 0.082709
[13:24:18.738] iteration 8294: loss: 0.054351, loss_s1: 0.035687, loss_fp: 0.002054, loss_freq: 0.009625
[13:24:19.721] iteration 8295: loss: 0.059430, loss_s1: 0.042446, loss_fp: 0.001084, loss_freq: 0.015332
[13:24:20.359] iteration 8296: loss: 0.073382, loss_s1: 0.050019, loss_fp: 0.002850, loss_freq: 0.010118
[13:24:20.993] iteration 8297: loss: 0.061321, loss_s1: 0.035906, loss_fp: 0.002193, loss_freq: 0.034654
[13:24:21.637] iteration 8298: loss: 0.084499, loss_s1: 0.055681, loss_fp: 0.001560, loss_freq: 0.015227
[13:24:22.271] iteration 8299: loss: 0.104408, loss_s1: 0.077558, loss_fp: 0.002966, loss_freq: 0.051237
[13:24:22.946] iteration 8300: loss: 0.068854, loss_s1: 0.027657, loss_fp: 0.003493, loss_freq: 0.004825
[13:24:23.586] iteration 8301: loss: 0.089215, loss_s1: 0.060581, loss_fp: 0.006494, loss_freq: 0.052071
[13:24:24.260] iteration 8302: loss: 0.173092, loss_s1: 0.097379, loss_fp: 0.022957, loss_freq: 0.030648
[13:24:24.935] iteration 8303: loss: 0.077253, loss_s1: 0.037524, loss_fp: 0.001241, loss_freq: 0.037312
[13:24:25.589] iteration 8304: loss: 0.087659, loss_s1: 0.025423, loss_fp: 0.000745, loss_freq: 0.011160
[13:24:26.233] iteration 8305: loss: 0.124869, loss_s1: 0.080492, loss_fp: 0.001838, loss_freq: 0.054328
[13:24:26.883] iteration 8306: loss: 0.079011, loss_s1: 0.041953, loss_fp: 0.002348, loss_freq: 0.038891
[13:24:27.531] iteration 8307: loss: 0.080306, loss_s1: 0.041396, loss_fp: 0.000798, loss_freq: 0.040880
[13:24:28.172] iteration 8308: loss: 0.051733, loss_s1: 0.032440, loss_fp: 0.002238, loss_freq: 0.020221
[13:24:28.812] iteration 8309: loss: 0.070416, loss_s1: 0.070125, loss_fp: 0.000684, loss_freq: 0.016524
[13:24:29.452] iteration 8310: loss: 0.064623, loss_s1: 0.052692, loss_fp: 0.001349, loss_freq: 0.009668
[13:24:30.143] iteration 8311: loss: 0.191171, loss_s1: 0.038859, loss_fp: 0.001004, loss_freq: 0.044726
[13:24:30.843] iteration 8312: loss: 0.101513, loss_s1: 0.041512, loss_fp: 0.002414, loss_freq: 0.023342
[13:24:31.485] iteration 8313: loss: 0.057112, loss_s1: 0.025011, loss_fp: 0.004037, loss_freq: 0.027833
[13:24:32.135] iteration 8314: loss: 0.064594, loss_s1: 0.047574, loss_fp: 0.002911, loss_freq: 0.023548
[13:24:32.787] iteration 8315: loss: 0.158595, loss_s1: 0.074767, loss_fp: 0.001521, loss_freq: 0.040404
[13:24:33.434] iteration 8316: loss: 0.073517, loss_s1: 0.043845, loss_fp: 0.012782, loss_freq: 0.036538
[13:24:34.066] iteration 8317: loss: 0.077727, loss_s1: 0.074844, loss_fp: 0.001262, loss_freq: 0.015946
[13:24:34.709] iteration 8318: loss: 0.077702, loss_s1: 0.055614, loss_fp: 0.003216, loss_freq: 0.015968
[13:24:35.365] iteration 8319: loss: 0.075951, loss_s1: 0.038791, loss_fp: 0.000318, loss_freq: 0.039330
[13:24:36.014] iteration 8320: loss: 0.107895, loss_s1: 0.043897, loss_fp: 0.003808, loss_freq: 0.056559
[13:24:36.660] iteration 8321: loss: 0.105024, loss_s1: 0.049904, loss_fp: 0.002014, loss_freq: 0.055228
[13:24:37.303] iteration 8322: loss: 0.062534, loss_s1: 0.029252, loss_fp: 0.007156, loss_freq: 0.016639
[13:24:37.949] iteration 8323: loss: 0.147773, loss_s1: 0.078705, loss_fp: 0.004047, loss_freq: 0.045836
[13:24:38.594] iteration 8324: loss: 0.119356, loss_s1: 0.054494, loss_fp: 0.001794, loss_freq: 0.027301
[13:24:39.240] iteration 8325: loss: 0.106476, loss_s1: 0.058119, loss_fp: 0.001248, loss_freq: 0.014479
[13:24:39.877] iteration 8326: loss: 0.092826, loss_s1: 0.034950, loss_fp: 0.001212, loss_freq: 0.074089
[13:24:40.518] iteration 8327: loss: 0.060995, loss_s1: 0.009791, loss_fp: 0.003456, loss_freq: 0.013456
[13:24:41.158] iteration 8328: loss: 0.095165, loss_s1: 0.053094, loss_fp: 0.024177, loss_freq: 0.048971
[13:24:41.796] iteration 8329: loss: 0.125355, loss_s1: 0.068331, loss_fp: 0.002700, loss_freq: 0.025292
[13:24:42.457] iteration 8330: loss: 0.093250, loss_s1: 0.031399, loss_fp: 0.002717, loss_freq: 0.054023
[13:24:43.128] iteration 8331: loss: 0.073566, loss_s1: 0.046051, loss_fp: 0.000750, loss_freq: 0.009237
[13:24:43.796] iteration 8332: loss: 0.054791, loss_s1: 0.036293, loss_fp: 0.001015, loss_freq: 0.018075
[13:24:44.501] iteration 8333: loss: 0.088788, loss_s1: 0.036386, loss_fp: 0.003623, loss_freq: 0.030614
[13:24:45.175] iteration 8334: loss: 0.059405, loss_s1: 0.039308, loss_fp: 0.001448, loss_freq: 0.011759
[13:24:45.834] iteration 8335: loss: 0.076738, loss_s1: 0.032314, loss_fp: 0.002632, loss_freq: 0.011216
[13:24:46.473] iteration 8336: loss: 0.039934, loss_s1: 0.014804, loss_fp: 0.000576, loss_freq: 0.015047
[13:24:47.108] iteration 8337: loss: 0.126184, loss_s1: 0.041121, loss_fp: 0.002440, loss_freq: 0.012807
[13:24:47.742] iteration 8338: loss: 0.088408, loss_s1: 0.082493, loss_fp: 0.005556, loss_freq: 0.024287
[13:24:48.402] iteration 8339: loss: 0.129266, loss_s1: 0.016501, loss_fp: 0.002489, loss_freq: 0.009856
[13:24:49.071] iteration 8340: loss: 0.134200, loss_s1: 0.138944, loss_fp: 0.001164, loss_freq: 0.052635
[13:24:49.744] iteration 8341: loss: 0.066620, loss_s1: 0.026557, loss_fp: 0.001638, loss_freq: 0.024719
[13:24:50.417] iteration 8342: loss: 0.101741, loss_s1: 0.025764, loss_fp: 0.002797, loss_freq: 0.089048
[13:24:51.047] iteration 8343: loss: 0.064905, loss_s1: 0.041238, loss_fp: 0.003929, loss_freq: 0.016851
[13:24:51.679] iteration 8344: loss: 0.090067, loss_s1: 0.075513, loss_fp: 0.004436, loss_freq: 0.015851
[13:24:52.314] iteration 8345: loss: 0.070080, loss_s1: 0.012256, loss_fp: 0.007810, loss_freq: 0.011665
[13:24:52.946] iteration 8346: loss: 0.148317, loss_s1: 0.036951, loss_fp: 0.001441, loss_freq: 0.033262
[13:24:53.590] iteration 8347: loss: 0.077564, loss_s1: 0.039498, loss_fp: 0.000646, loss_freq: 0.002748
[13:24:54.232] iteration 8348: loss: 0.044116, loss_s1: 0.015236, loss_fp: 0.003350, loss_freq: 0.004466
[13:24:54.861] iteration 8349: loss: 0.053742, loss_s1: 0.016618, loss_fp: 0.000977, loss_freq: 0.021239
[13:24:55.493] iteration 8350: loss: 0.092863, loss_s1: 0.032446, loss_fp: 0.001217, loss_freq: 0.005093
[13:24:56.131] iteration 8351: loss: 0.081945, loss_s1: 0.064196, loss_fp: 0.002789, loss_freq: 0.033622
[13:24:56.768] iteration 8352: loss: 0.086600, loss_s1: 0.062546, loss_fp: 0.000695, loss_freq: 0.011542
[13:24:57.410] iteration 8353: loss: 0.109900, loss_s1: 0.073377, loss_fp: 0.003087, loss_freq: 0.032139
[13:24:58.044] iteration 8354: loss: 0.097402, loss_s1: 0.074042, loss_fp: 0.002372, loss_freq: 0.038417
[13:24:58.679] iteration 8355: loss: 0.102270, loss_s1: 0.060107, loss_fp: 0.000543, loss_freq: 0.026011
[13:24:59.315] iteration 8356: loss: 0.092615, loss_s1: 0.048202, loss_fp: 0.007498, loss_freq: 0.024474
[13:24:59.958] iteration 8357: loss: 0.151957, loss_s1: 0.052799, loss_fp: 0.003796, loss_freq: 0.056482
[13:25:00.596] iteration 8358: loss: 0.112209, loss_s1: 0.062947, loss_fp: 0.001417, loss_freq: 0.023951
[13:25:01.222] iteration 8359: loss: 0.114956, loss_s1: 0.062939, loss_fp: 0.002204, loss_freq: 0.024220
[13:25:01.849] iteration 8360: loss: 0.114594, loss_s1: 0.072399, loss_fp: 0.002077, loss_freq: 0.013678
[13:25:02.476] iteration 8361: loss: 0.078355, loss_s1: 0.033137, loss_fp: 0.002404, loss_freq: 0.032670
[13:25:03.105] iteration 8362: loss: 0.077268, loss_s1: 0.006638, loss_fp: 0.007425, loss_freq: 0.035959
[13:25:03.756] iteration 8363: loss: 0.061948, loss_s1: 0.045709, loss_fp: 0.005820, loss_freq: 0.011606
[13:25:04.452] iteration 8364: loss: 0.096286, loss_s1: 0.060186, loss_fp: 0.000902, loss_freq: 0.038345
[13:25:05.152] iteration 8365: loss: 0.108491, loss_s1: 0.037214, loss_fp: 0.003293, loss_freq: 0.061448
[13:25:05.938] iteration 8366: loss: 0.087827, loss_s1: 0.047786, loss_fp: 0.002906, loss_freq: 0.027761
[13:25:06.680] iteration 8367: loss: 0.085566, loss_s1: 0.037429, loss_fp: 0.000651, loss_freq: 0.068216
[13:25:07.352] iteration 8368: loss: 0.092859, loss_s1: 0.083338, loss_fp: 0.006178, loss_freq: 0.018639
[13:25:08.010] iteration 8369: loss: 0.071060, loss_s1: 0.059228, loss_fp: 0.004957, loss_freq: 0.027957
[13:25:08.645] iteration 8370: loss: 0.081500, loss_s1: 0.042103, loss_fp: 0.001204, loss_freq: 0.016561
[13:25:09.279] iteration 8371: loss: 0.056627, loss_s1: 0.015806, loss_fp: 0.007953, loss_freq: 0.018190
[13:25:09.916] iteration 8372: loss: 0.115416, loss_s1: 0.011876, loss_fp: 0.002495, loss_freq: 0.019120
[13:25:10.608] iteration 8373: loss: 0.090576, loss_s1: 0.063305, loss_fp: 0.003247, loss_freq: 0.046720
[13:25:11.287] iteration 8374: loss: 0.191985, loss_s1: 0.054554, loss_fp: 0.001816, loss_freq: 0.036830
[13:25:11.960] iteration 8375: loss: 0.093786, loss_s1: 0.045906, loss_fp: 0.005401, loss_freq: 0.057793
[13:25:12.634] iteration 8376: loss: 0.130188, loss_s1: 0.044964, loss_fp: 0.001479, loss_freq: 0.035113
[13:25:13.312] iteration 8377: loss: 0.103010, loss_s1: 0.016247, loss_fp: 0.001234, loss_freq: 0.021144
[13:25:13.955] iteration 8378: loss: 0.044701, loss_s1: 0.030372, loss_fp: 0.001810, loss_freq: 0.006114
[13:25:14.597] iteration 8379: loss: 0.131772, loss_s1: 0.093521, loss_fp: 0.000659, loss_freq: 0.063097
[13:25:15.239] iteration 8380: loss: 0.088742, loss_s1: 0.054070, loss_fp: 0.002441, loss_freq: 0.055338
[13:25:15.875] iteration 8381: loss: 0.184576, loss_s1: 0.053315, loss_fp: 0.001350, loss_freq: 0.006002
[13:25:16.517] iteration 8382: loss: 0.061366, loss_s1: 0.012338, loss_fp: 0.001316, loss_freq: 0.023434
[13:25:17.164] iteration 8383: loss: 0.065298, loss_s1: 0.031872, loss_fp: 0.001940, loss_freq: 0.023200
[13:25:17.811] iteration 8384: loss: 0.132551, loss_s1: 0.094386, loss_fp: 0.002968, loss_freq: 0.061304
[13:25:18.454] iteration 8385: loss: 0.082664, loss_s1: 0.042174, loss_fp: 0.000549, loss_freq: 0.018038
[13:25:19.109] iteration 8386: loss: 0.111106, loss_s1: 0.043644, loss_fp: 0.002280, loss_freq: 0.048011
[13:25:19.758] iteration 8387: loss: 0.054001, loss_s1: 0.032162, loss_fp: 0.000582, loss_freq: 0.010275
[13:25:20.412] iteration 8388: loss: 0.148016, loss_s1: 0.107722, loss_fp: 0.003291, loss_freq: 0.037440
[13:25:21.044] iteration 8389: loss: 0.055243, loss_s1: 0.014939, loss_fp: 0.003165, loss_freq: 0.016713
[13:25:21.702] iteration 8390: loss: 0.127540, loss_s1: 0.038196, loss_fp: 0.001972, loss_freq: 0.059346
[13:25:22.370] iteration 8391: loss: 0.168550, loss_s1: 0.090564, loss_fp: 0.001941, loss_freq: 0.080094
[13:25:23.031] iteration 8392: loss: 0.094397, loss_s1: 0.042607, loss_fp: 0.003672, loss_freq: 0.015946
[13:25:23.690] iteration 8393: loss: 0.097337, loss_s1: 0.029997, loss_fp: 0.003354, loss_freq: 0.046807
[13:25:24.344] iteration 8394: loss: 0.120359, loss_s1: 0.049006, loss_fp: 0.000827, loss_freq: 0.050831
[13:25:24.993] iteration 8395: loss: 0.135662, loss_s1: 0.085015, loss_fp: 0.006004, loss_freq: 0.044871
[13:25:25.643] iteration 8396: loss: 0.078968, loss_s1: 0.045375, loss_fp: 0.003008, loss_freq: 0.032197
[13:25:26.288] iteration 8397: loss: 0.089968, loss_s1: 0.038593, loss_fp: 0.001486, loss_freq: 0.016681
[13:25:26.919] iteration 8398: loss: 0.128686, loss_s1: 0.064035, loss_fp: 0.003596, loss_freq: 0.058846
[13:25:27.563] iteration 8399: loss: 0.090938, loss_s1: 0.025429, loss_fp: 0.004554, loss_freq: 0.037831
[13:25:28.219] iteration 8400: loss: 0.060764, loss_s1: 0.030630, loss_fp: 0.000728, loss_freq: 0.018214
[13:25:31.785] iteration 8400 : mean_dice : 0.729028
[13:25:32.490] iteration 8401: loss: 0.198567, loss_s1: 0.189372, loss_fp: 0.000671, loss_freq: 0.130011
[13:25:33.160] iteration 8402: loss: 0.115272, loss_s1: 0.113588, loss_fp: 0.001400, loss_freq: 0.040337
[13:25:33.845] iteration 8403: loss: 0.093743, loss_s1: 0.039083, loss_fp: 0.001376, loss_freq: 0.010535
[13:25:34.491] iteration 8404: loss: 0.074608, loss_s1: 0.059532, loss_fp: 0.001181, loss_freq: 0.013573
[13:25:35.133] iteration 8405: loss: 0.089020, loss_s1: 0.046121, loss_fp: 0.002522, loss_freq: 0.018954
[13:25:35.772] iteration 8406: loss: 0.053348, loss_s1: 0.024805, loss_fp: 0.001491, loss_freq: 0.034679
[13:25:36.443] iteration 8407: loss: 0.083571, loss_s1: 0.031450, loss_fp: 0.001253, loss_freq: 0.009785
[13:25:37.126] iteration 8408: loss: 0.050453, loss_s1: 0.013317, loss_fp: 0.005279, loss_freq: 0.014648
[13:25:37.794] iteration 8409: loss: 0.187663, loss_s1: 0.037429, loss_fp: 0.003779, loss_freq: 0.043559
[13:25:38.445] iteration 8410: loss: 0.098563, loss_s1: 0.103291, loss_fp: 0.000650, loss_freq: 0.017685
[13:25:39.093] iteration 8411: loss: 0.085474, loss_s1: 0.036456, loss_fp: 0.002377, loss_freq: 0.039489
[13:25:39.736] iteration 8412: loss: 0.085937, loss_s1: 0.032191, loss_fp: 0.002247, loss_freq: 0.026559
[13:25:40.373] iteration 8413: loss: 0.075326, loss_s1: 0.063495, loss_fp: 0.006760, loss_freq: 0.024099
[13:25:41.025] iteration 8414: loss: 0.112120, loss_s1: 0.056787, loss_fp: 0.000823, loss_freq: 0.086848
[13:25:41.678] iteration 8415: loss: 0.075642, loss_s1: 0.041711, loss_fp: 0.003340, loss_freq: 0.034376
[13:25:42.331] iteration 8416: loss: 0.224323, loss_s1: 0.103491, loss_fp: 0.001999, loss_freq: 0.025545
[13:25:42.985] iteration 8417: loss: 0.082134, loss_s1: 0.020794, loss_fp: 0.003451, loss_freq: 0.014456
[13:25:43.622] iteration 8418: loss: 0.083495, loss_s1: 0.036927, loss_fp: 0.002445, loss_freq: 0.043263
[13:25:44.262] iteration 8419: loss: 0.076518, loss_s1: 0.044430, loss_fp: 0.001415, loss_freq: 0.014203
[13:25:44.896] iteration 8420: loss: 0.135817, loss_s1: 0.036664, loss_fp: 0.001744, loss_freq: 0.029732
[13:25:45.533] iteration 8421: loss: 0.077904, loss_s1: 0.050590, loss_fp: 0.001304, loss_freq: 0.043782
[13:25:46.173] iteration 8422: loss: 0.061329, loss_s1: 0.032426, loss_fp: 0.001177, loss_freq: 0.029047
[13:25:46.824] iteration 8423: loss: 0.102230, loss_s1: 0.052957, loss_fp: 0.001262, loss_freq: 0.011573
[13:25:47.511] iteration 8424: loss: 0.062228, loss_s1: 0.033687, loss_fp: 0.002806, loss_freq: 0.006953
[13:25:48.152] iteration 8425: loss: 0.155117, loss_s1: 0.171104, loss_fp: 0.001980, loss_freq: 0.010539
[13:25:48.804] iteration 8426: loss: 0.138249, loss_s1: 0.058600, loss_fp: 0.002572, loss_freq: 0.029080
[13:25:49.453] iteration 8427: loss: 0.051742, loss_s1: 0.006882, loss_fp: 0.000908, loss_freq: 0.024417
[13:25:50.114] iteration 8428: loss: 0.124222, loss_s1: 0.089054, loss_fp: 0.002217, loss_freq: 0.051623
[13:25:50.756] iteration 8429: loss: 0.106657, loss_s1: 0.037103, loss_fp: 0.002247, loss_freq: 0.045139
[13:25:51.398] iteration 8430: loss: 0.136227, loss_s1: 0.070824, loss_fp: 0.004992, loss_freq: 0.010799
[13:25:52.043] iteration 8431: loss: 0.082366, loss_s1: 0.062533, loss_fp: 0.005593, loss_freq: 0.020695
[13:25:52.700] iteration 8432: loss: 0.105862, loss_s1: 0.047724, loss_fp: 0.001273, loss_freq: 0.019718
[13:25:53.356] iteration 8433: loss: 0.083432, loss_s1: 0.047936, loss_fp: 0.004450, loss_freq: 0.033697
[13:25:54.004] iteration 8434: loss: 0.085575, loss_s1: 0.038411, loss_fp: 0.000690, loss_freq: 0.022381
[13:25:54.642] iteration 8435: loss: 0.127225, loss_s1: 0.039146, loss_fp: 0.003833, loss_freq: 0.027092
[13:25:55.287] iteration 8436: loss: 0.072798, loss_s1: 0.039805, loss_fp: 0.003384, loss_freq: 0.011683
[13:25:55.931] iteration 8437: loss: 0.060364, loss_s1: 0.032260, loss_fp: 0.001945, loss_freq: 0.016021
[13:25:56.931] iteration 8438: loss: 0.058761, loss_s1: 0.026191, loss_fp: 0.001049, loss_freq: 0.014397
[13:25:57.610] iteration 8439: loss: 0.087855, loss_s1: 0.068531, loss_fp: 0.001513, loss_freq: 0.037776
[13:25:58.275] iteration 8440: loss: 0.060204, loss_s1: 0.039811, loss_fp: 0.000385, loss_freq: 0.016196
[13:25:58.941] iteration 8441: loss: 0.065733, loss_s1: 0.018334, loss_fp: 0.008252, loss_freq: 0.007926
[13:25:59.636] iteration 8442: loss: 0.083928, loss_s1: 0.049284, loss_fp: 0.000774, loss_freq: 0.049638
[13:26:00.317] iteration 8443: loss: 0.072617, loss_s1: 0.017739, loss_fp: 0.000970, loss_freq: 0.006410
[13:26:00.987] iteration 8444: loss: 0.085671, loss_s1: 0.064759, loss_fp: 0.001869, loss_freq: 0.057135
[13:26:01.669] iteration 8445: loss: 0.143309, loss_s1: 0.058884, loss_fp: 0.002753, loss_freq: 0.060035
[13:26:02.329] iteration 8446: loss: 0.083702, loss_s1: 0.063413, loss_fp: 0.002735, loss_freq: 0.023160
[13:26:02.963] iteration 8447: loss: 0.082406, loss_s1: 0.027847, loss_fp: 0.000766, loss_freq: 0.003911
[13:26:03.665] iteration 8448: loss: 0.108246, loss_s1: 0.071235, loss_fp: 0.007726, loss_freq: 0.061631
[13:26:04.323] iteration 8449: loss: 0.097844, loss_s1: 0.063416, loss_fp: 0.002745, loss_freq: 0.059349
[13:26:04.958] iteration 8450: loss: 0.088862, loss_s1: 0.099369, loss_fp: 0.000658, loss_freq: 0.005781
[13:26:05.595] iteration 8451: loss: 0.056205, loss_s1: 0.021701, loss_fp: 0.002720, loss_freq: 0.018206
[13:26:06.229] iteration 8452: loss: 0.099920, loss_s1: 0.015122, loss_fp: 0.005238, loss_freq: 0.070106
[13:26:06.868] iteration 8453: loss: 0.047679, loss_s1: 0.014029, loss_fp: 0.004549, loss_freq: 0.015338
[13:26:07.502] iteration 8454: loss: 0.126894, loss_s1: 0.017925, loss_fp: 0.009824, loss_freq: 0.037377
[13:26:08.142] iteration 8455: loss: 0.140875, loss_s1: 0.055674, loss_fp: 0.003415, loss_freq: 0.026807
[13:26:08.775] iteration 8456: loss: 0.079970, loss_s1: 0.072309, loss_fp: 0.002644, loss_freq: 0.021834
[13:26:09.419] iteration 8457: loss: 0.115770, loss_s1: 0.026498, loss_fp: 0.002450, loss_freq: 0.017878
[13:26:10.049] iteration 8458: loss: 0.120419, loss_s1: 0.042807, loss_fp: 0.001452, loss_freq: 0.047257
[13:26:10.734] iteration 8459: loss: 0.077675, loss_s1: 0.027940, loss_fp: 0.002777, loss_freq: 0.035379
[13:26:11.417] iteration 8460: loss: 0.066384, loss_s1: 0.046857, loss_fp: 0.000868, loss_freq: 0.017029
[13:26:12.105] iteration 8461: loss: 0.131377, loss_s1: 0.046048, loss_fp: 0.001969, loss_freq: 0.017034
[13:26:12.783] iteration 8462: loss: 0.083459, loss_s1: 0.084534, loss_fp: 0.002040, loss_freq: 0.012568
[13:26:13.453] iteration 8463: loss: 0.224405, loss_s1: 0.288764, loss_fp: 0.003570, loss_freq: 0.028858
[13:26:14.127] iteration 8464: loss: 0.076172, loss_s1: 0.038666, loss_fp: 0.001282, loss_freq: 0.034109
[13:26:14.794] iteration 8465: loss: 0.067322, loss_s1: 0.073897, loss_fp: 0.000514, loss_freq: 0.005286
[13:26:15.460] iteration 8466: loss: 0.110466, loss_s1: 0.060529, loss_fp: 0.001107, loss_freq: 0.053247
[13:26:16.136] iteration 8467: loss: 0.149348, loss_s1: 0.052999, loss_fp: 0.003131, loss_freq: 0.012683
[13:26:16.805] iteration 8468: loss: 0.051280, loss_s1: 0.023113, loss_fp: 0.001384, loss_freq: 0.010836
[13:26:17.475] iteration 8469: loss: 0.083446, loss_s1: 0.040402, loss_fp: 0.007302, loss_freq: 0.023769
[13:26:18.141] iteration 8470: loss: 0.085660, loss_s1: 0.036624, loss_fp: 0.010818, loss_freq: 0.039877
[13:26:18.836] iteration 8471: loss: 0.084477, loss_s1: 0.057441, loss_fp: 0.001441, loss_freq: 0.036651
[13:26:19.521] iteration 8472: loss: 0.161476, loss_s1: 0.092805, loss_fp: 0.001688, loss_freq: 0.024166
[13:26:20.215] iteration 8473: loss: 0.113635, loss_s1: 0.059864, loss_fp: 0.002229, loss_freq: 0.044106
[13:26:20.913] iteration 8474: loss: 0.121068, loss_s1: 0.085780, loss_fp: 0.000921, loss_freq: 0.061261
[13:26:21.575] iteration 8475: loss: 0.059805, loss_s1: 0.026916, loss_fp: 0.002743, loss_freq: 0.012639
[13:26:22.208] iteration 8476: loss: 0.122171, loss_s1: 0.033719, loss_fp: 0.006209, loss_freq: 0.048690
[13:26:22.889] iteration 8477: loss: 0.100119, loss_s1: 0.072274, loss_fp: 0.001052, loss_freq: 0.010546
[13:26:23.566] iteration 8478: loss: 0.091700, loss_s1: 0.032874, loss_fp: 0.003309, loss_freq: 0.012081
[13:26:24.239] iteration 8479: loss: 0.040879, loss_s1: 0.014280, loss_fp: 0.000573, loss_freq: 0.011966
[13:26:24.869] iteration 8480: loss: 0.086995, loss_s1: 0.028505, loss_fp: 0.001843, loss_freq: 0.021571
[13:26:25.515] iteration 8481: loss: 0.083044, loss_s1: 0.065038, loss_fp: 0.002366, loss_freq: 0.039056
[13:26:26.180] iteration 8482: loss: 0.147994, loss_s1: 0.038606, loss_fp: 0.001071, loss_freq: 0.024053
[13:26:26.826] iteration 8483: loss: 0.085475, loss_s1: 0.068782, loss_fp: 0.000799, loss_freq: 0.038164
[13:26:27.453] iteration 8484: loss: 0.090951, loss_s1: 0.070463, loss_fp: 0.000725, loss_freq: 0.018635
[13:26:28.083] iteration 8485: loss: 0.090723, loss_s1: 0.055297, loss_fp: 0.002555, loss_freq: 0.033950
[13:26:28.715] iteration 8486: loss: 0.063070, loss_s1: 0.046476, loss_fp: 0.004412, loss_freq: 0.018069
[13:26:29.345] iteration 8487: loss: 0.070729, loss_s1: 0.046526, loss_fp: 0.001241, loss_freq: 0.029848
[13:26:29.971] iteration 8488: loss: 0.086262, loss_s1: 0.064799, loss_fp: 0.004297, loss_freq: 0.022589
[13:26:30.609] iteration 8489: loss: 0.103118, loss_s1: 0.026136, loss_fp: 0.001988, loss_freq: 0.068025
[13:26:31.234] iteration 8490: loss: 0.072689, loss_s1: 0.029577, loss_fp: 0.000738, loss_freq: 0.004949
[13:26:31.876] iteration 8491: loss: 0.070848, loss_s1: 0.033212, loss_fp: 0.001321, loss_freq: 0.006914
[13:26:32.510] iteration 8492: loss: 0.045639, loss_s1: 0.019149, loss_fp: 0.002160, loss_freq: 0.013160
[13:26:33.149] iteration 8493: loss: 0.124872, loss_s1: 0.081767, loss_fp: 0.000555, loss_freq: 0.011537
[13:26:33.788] iteration 8494: loss: 0.126090, loss_s1: 0.108777, loss_fp: 0.003637, loss_freq: 0.063643
[13:26:34.419] iteration 8495: loss: 0.066784, loss_s1: 0.032309, loss_fp: 0.003795, loss_freq: 0.012049
[13:26:35.060] iteration 8496: loss: 0.112344, loss_s1: 0.029762, loss_fp: 0.001405, loss_freq: 0.090349
[13:26:35.701] iteration 8497: loss: 0.077212, loss_s1: 0.043687, loss_fp: 0.005808, loss_freq: 0.043915
[13:26:36.332] iteration 8498: loss: 0.098724, loss_s1: 0.034649, loss_fp: 0.001243, loss_freq: 0.006763
[13:26:36.962] iteration 8499: loss: 0.100962, loss_s1: 0.047153, loss_fp: 0.017563, loss_freq: 0.024407
[13:26:37.592] iteration 8500: loss: 0.057050, loss_s1: 0.029568, loss_fp: 0.001774, loss_freq: 0.016498
[13:26:38.230] iteration 8501: loss: 0.129595, loss_s1: 0.028152, loss_fp: 0.001286, loss_freq: 0.024372
[13:26:38.868] iteration 8502: loss: 0.129766, loss_s1: 0.036942, loss_fp: 0.001713, loss_freq: 0.109715
[13:26:39.502] iteration 8503: loss: 0.069978, loss_s1: 0.018840, loss_fp: 0.001676, loss_freq: 0.019631
[13:26:40.141] iteration 8504: loss: 0.093974, loss_s1: 0.022399, loss_fp: 0.008353, loss_freq: 0.060454
[13:26:40.792] iteration 8505: loss: 0.068337, loss_s1: 0.040389, loss_fp: 0.006910, loss_freq: 0.022060
[13:26:41.424] iteration 8506: loss: 0.076043, loss_s1: 0.032052, loss_fp: 0.003150, loss_freq: 0.014256
[13:26:42.057] iteration 8507: loss: 0.093032, loss_s1: 0.050410, loss_fp: 0.009906, loss_freq: 0.008409
[13:26:42.690] iteration 8508: loss: 0.105937, loss_s1: 0.070410, loss_fp: 0.001829, loss_freq: 0.024104
[13:26:43.327] iteration 8509: loss: 0.137905, loss_s1: 0.169911, loss_fp: 0.001712, loss_freq: 0.037616
[13:26:43.983] iteration 8510: loss: 0.087077, loss_s1: 0.018994, loss_fp: 0.001320, loss_freq: 0.080619
[13:26:44.648] iteration 8511: loss: 0.102431, loss_s1: 0.101571, loss_fp: 0.003764, loss_freq: 0.030722
[13:26:45.290] iteration 8512: loss: 0.068334, loss_s1: 0.034050, loss_fp: 0.003301, loss_freq: 0.034629
[13:26:45.942] iteration 8513: loss: 0.100172, loss_s1: 0.033613, loss_fp: 0.001245, loss_freq: 0.018034
[13:26:46.595] iteration 8514: loss: 0.041589, loss_s1: 0.017008, loss_fp: 0.004635, loss_freq: 0.011804
[13:26:47.288] iteration 8515: loss: 0.077977, loss_s1: 0.040802, loss_fp: 0.004542, loss_freq: 0.019690
[13:26:47.966] iteration 8516: loss: 0.085913, loss_s1: 0.024394, loss_fp: 0.008716, loss_freq: 0.074309
[13:26:48.621] iteration 8517: loss: 0.210342, loss_s1: 0.113540, loss_fp: 0.001707, loss_freq: 0.048570
[13:26:49.270] iteration 8518: loss: 0.100639, loss_s1: 0.058803, loss_fp: 0.000591, loss_freq: 0.053335
[13:26:49.917] iteration 8519: loss: 0.087375, loss_s1: 0.037082, loss_fp: 0.001172, loss_freq: 0.060800
[13:26:50.575] iteration 8520: loss: 0.091941, loss_s1: 0.043740, loss_fp: 0.000644, loss_freq: 0.047548
[13:26:51.231] iteration 8521: loss: 0.049840, loss_s1: 0.023786, loss_fp: 0.001296, loss_freq: 0.015646
[13:26:51.877] iteration 8522: loss: 0.068484, loss_s1: 0.028019, loss_fp: 0.007127, loss_freq: 0.024017
[13:26:52.562] iteration 8523: loss: 0.080160, loss_s1: 0.018173, loss_fp: 0.005046, loss_freq: 0.059701
[13:26:53.246] iteration 8524: loss: 0.134660, loss_s1: 0.040395, loss_fp: 0.000725, loss_freq: 0.010717
[13:26:53.912] iteration 8525: loss: 0.110919, loss_s1: 0.041849, loss_fp: 0.000784, loss_freq: 0.029372
[13:26:54.579] iteration 8526: loss: 0.054040, loss_s1: 0.025607, loss_fp: 0.002463, loss_freq: 0.010300
[13:26:55.230] iteration 8527: loss: 0.096045, loss_s1: 0.046320, loss_fp: 0.002679, loss_freq: 0.034741
[13:26:55.859] iteration 8528: loss: 0.126815, loss_s1: 0.011497, loss_fp: 0.002750, loss_freq: 0.021899
[13:26:56.497] iteration 8529: loss: 0.096139, loss_s1: 0.071203, loss_fp: 0.004452, loss_freq: 0.043683
[13:26:57.135] iteration 8530: loss: 0.051566, loss_s1: 0.038694, loss_fp: 0.001175, loss_freq: 0.009170
[13:26:57.771] iteration 8531: loss: 0.071651, loss_s1: 0.030347, loss_fp: 0.001925, loss_freq: 0.018016
[13:26:58.404] iteration 8532: loss: 0.061890, loss_s1: 0.054414, loss_fp: 0.000373, loss_freq: 0.010624
[13:26:59.072] iteration 8533: loss: 0.079358, loss_s1: 0.053450, loss_fp: 0.000594, loss_freq: 0.032287
[13:26:59.794] iteration 8534: loss: 0.160749, loss_s1: 0.113816, loss_fp: 0.006052, loss_freq: 0.112632
[13:27:00.430] iteration 8535: loss: 0.075039, loss_s1: 0.048098, loss_fp: 0.002513, loss_freq: 0.027536
[13:27:01.074] iteration 8536: loss: 0.106881, loss_s1: 0.024882, loss_fp: 0.001946, loss_freq: 0.044165
[13:27:01.711] iteration 8537: loss: 0.095809, loss_s1: 0.037704, loss_fp: 0.000960, loss_freq: 0.048169
[13:27:02.354] iteration 8538: loss: 0.087867, loss_s1: 0.057560, loss_fp: 0.002063, loss_freq: 0.033273
[13:27:02.993] iteration 8539: loss: 0.088400, loss_s1: 0.040646, loss_fp: 0.000691, loss_freq: 0.039430
[13:27:03.628] iteration 8540: loss: 0.100010, loss_s1: 0.021685, loss_fp: 0.004138, loss_freq: 0.016674
[13:27:04.266] iteration 8541: loss: 0.074267, loss_s1: 0.063873, loss_fp: 0.001976, loss_freq: 0.020469
[13:27:04.904] iteration 8542: loss: 0.134226, loss_s1: 0.083506, loss_fp: 0.003242, loss_freq: 0.012386
[13:27:05.549] iteration 8543: loss: 0.075836, loss_s1: 0.018286, loss_fp: 0.002111, loss_freq: 0.023604
[13:27:06.187] iteration 8544: loss: 0.121266, loss_s1: 0.095450, loss_fp: 0.002523, loss_freq: 0.057340
[13:27:06.824] iteration 8545: loss: 0.059551, loss_s1: 0.010681, loss_fp: 0.000784, loss_freq: 0.039237
[13:27:07.458] iteration 8546: loss: 0.062822, loss_s1: 0.033659, loss_fp: 0.001899, loss_freq: 0.006754
[13:27:08.095] iteration 8547: loss: 0.089178, loss_s1: 0.075194, loss_fp: 0.002808, loss_freq: 0.019723
[13:27:08.735] iteration 8548: loss: 0.090875, loss_s1: 0.044119, loss_fp: 0.001589, loss_freq: 0.010594
[13:27:09.587] iteration 8549: loss: 0.043868, loss_s1: 0.015295, loss_fp: 0.002841, loss_freq: 0.029493
[13:27:10.292] iteration 8550: loss: 0.095734, loss_s1: 0.068998, loss_fp: 0.000655, loss_freq: 0.012341
[13:27:11.293] iteration 8551: loss: 0.090070, loss_s1: 0.060750, loss_fp: 0.004265, loss_freq: 0.037510
[13:27:12.057] iteration 8552: loss: 0.156316, loss_s1: 0.057981, loss_fp: 0.001300, loss_freq: 0.032109
[13:27:12.694] iteration 8553: loss: 0.083073, loss_s1: 0.060768, loss_fp: 0.001941, loss_freq: 0.015335
[13:27:13.333] iteration 8554: loss: 0.132014, loss_s1: 0.109114, loss_fp: 0.002901, loss_freq: 0.035486
[13:27:13.967] iteration 8555: loss: 0.164704, loss_s1: 0.174858, loss_fp: 0.001292, loss_freq: 0.074067
[13:27:14.606] iteration 8556: loss: 0.078511, loss_s1: 0.062577, loss_fp: 0.001583, loss_freq: 0.029329
[13:27:15.253] iteration 8557: loss: 0.077314, loss_s1: 0.029382, loss_fp: 0.003645, loss_freq: 0.051570
[13:27:15.901] iteration 8558: loss: 0.106360, loss_s1: 0.090805, loss_fp: 0.001560, loss_freq: 0.049405
[13:27:16.533] iteration 8559: loss: 0.096650, loss_s1: 0.054427, loss_fp: 0.002885, loss_freq: 0.024474
[13:27:17.178] iteration 8560: loss: 0.055664, loss_s1: 0.029962, loss_fp: 0.001019, loss_freq: 0.006736
[13:27:17.806] iteration 8561: loss: 0.113242, loss_s1: 0.067547, loss_fp: 0.008383, loss_freq: 0.054015
[13:27:18.432] iteration 8562: loss: 0.061075, loss_s1: 0.035133, loss_fp: 0.000786, loss_freq: 0.029789
[13:27:19.060] iteration 8563: loss: 0.147288, loss_s1: 0.063668, loss_fp: 0.003344, loss_freq: 0.033141
[13:27:19.687] iteration 8564: loss: 0.072118, loss_s1: 0.041222, loss_fp: 0.002000, loss_freq: 0.023183
[13:27:20.313] iteration 8565: loss: 0.062398, loss_s1: 0.035113, loss_fp: 0.001576, loss_freq: 0.023730
[13:27:20.942] iteration 8566: loss: 0.104858, loss_s1: 0.082282, loss_fp: 0.002824, loss_freq: 0.012257
[13:27:21.569] iteration 8567: loss: 0.057324, loss_s1: 0.036586, loss_fp: 0.003405, loss_freq: 0.007744
[13:27:22.202] iteration 8568: loss: 0.073881, loss_s1: 0.057149, loss_fp: 0.003242, loss_freq: 0.011231
[13:27:22.852] iteration 8569: loss: 0.178894, loss_s1: 0.080780, loss_fp: 0.004597, loss_freq: 0.040503
[13:27:23.490] iteration 8570: loss: 0.105409, loss_s1: 0.024700, loss_fp: 0.001142, loss_freq: 0.028255
[13:27:24.124] iteration 8571: loss: 0.175055, loss_s1: 0.132217, loss_fp: 0.001127, loss_freq: 0.068473
[13:27:24.752] iteration 8572: loss: 0.143649, loss_s1: 0.068982, loss_fp: 0.003793, loss_freq: 0.052903
[13:27:25.381] iteration 8573: loss: 0.104259, loss_s1: 0.060033, loss_fp: 0.004378, loss_freq: 0.017956
[13:27:26.003] iteration 8574: loss: 0.074494, loss_s1: 0.064705, loss_fp: 0.005041, loss_freq: 0.018946
[13:27:26.629] iteration 8575: loss: 0.094712, loss_s1: 0.003303, loss_fp: 0.005289, loss_freq: 0.011884
[13:27:27.258] iteration 8576: loss: 0.050374, loss_s1: 0.012224, loss_fp: 0.001395, loss_freq: 0.015263
[13:27:27.883] iteration 8577: loss: 0.104040, loss_s1: 0.044662, loss_fp: 0.008270, loss_freq: 0.028476
[13:27:28.505] iteration 8578: loss: 0.080080, loss_s1: 0.048116, loss_fp: 0.003859, loss_freq: 0.037821
[13:27:29.124] iteration 8579: loss: 0.114264, loss_s1: 0.087480, loss_fp: 0.010972, loss_freq: 0.035874
[13:27:29.742] iteration 8580: loss: 0.100714, loss_s1: 0.078052, loss_fp: 0.001875, loss_freq: 0.027244
[13:27:30.758] iteration 8581: loss: 0.103983, loss_s1: 0.068433, loss_fp: 0.001613, loss_freq: 0.019927
[13:27:31.426] iteration 8582: loss: 0.091013, loss_s1: 0.053574, loss_fp: 0.002522, loss_freq: 0.021304
[13:27:32.086] iteration 8583: loss: 0.080356, loss_s1: 0.028311, loss_fp: 0.001184, loss_freq: 0.042540
[13:27:32.738] iteration 8584: loss: 0.123448, loss_s1: 0.077661, loss_fp: 0.001451, loss_freq: 0.028138
[13:27:33.412] iteration 8585: loss: 0.148186, loss_s1: 0.061362, loss_fp: 0.001975, loss_freq: 0.059748
[13:27:34.037] iteration 8586: loss: 0.069987, loss_s1: 0.014993, loss_fp: 0.001163, loss_freq: 0.009543
[13:27:34.683] iteration 8587: loss: 0.054547, loss_s1: 0.047447, loss_fp: 0.001962, loss_freq: 0.012759
[13:27:35.334] iteration 8588: loss: 0.122252, loss_s1: 0.058271, loss_fp: 0.007474, loss_freq: 0.034574
[13:27:35.979] iteration 8589: loss: 0.069555, loss_s1: 0.028607, loss_fp: 0.001235, loss_freq: 0.032856
[13:27:36.609] iteration 8590: loss: 0.105869, loss_s1: 0.009492, loss_fp: 0.000727, loss_freq: 0.013301
[13:27:37.242] iteration 8591: loss: 0.130176, loss_s1: 0.080215, loss_fp: 0.001728, loss_freq: 0.063240
[13:27:37.870] iteration 8592: loss: 0.062838, loss_s1: 0.037332, loss_fp: 0.001928, loss_freq: 0.019430
[13:27:38.509] iteration 8593: loss: 0.066006, loss_s1: 0.021347, loss_fp: 0.004706, loss_freq: 0.012353
[13:27:39.161] iteration 8594: loss: 0.070298, loss_s1: 0.043057, loss_fp: 0.000949, loss_freq: 0.036906
[13:27:39.804] iteration 8595: loss: 0.083028, loss_s1: 0.070002, loss_fp: 0.000796, loss_freq: 0.029305
[13:27:40.435] iteration 8596: loss: 0.061255, loss_s1: 0.018411, loss_fp: 0.001918, loss_freq: 0.015712
[13:27:41.072] iteration 8597: loss: 0.104136, loss_s1: 0.008350, loss_fp: 0.000709, loss_freq: 0.017575
[13:27:41.708] iteration 8598: loss: 0.093450, loss_s1: 0.015260, loss_fp: 0.001027, loss_freq: 0.018579
[13:27:42.445] iteration 8599: loss: 0.070168, loss_s1: 0.058401, loss_fp: 0.000670, loss_freq: 0.017406
[13:27:43.116] iteration 8600: loss: 0.059132, loss_s1: 0.037455, loss_fp: 0.002668, loss_freq: 0.013302
[13:27:46.728] iteration 8600 : mean_dice : 0.673976
[13:27:47.448] iteration 8601: loss: 0.149709, loss_s1: 0.047235, loss_fp: 0.010771, loss_freq: 0.063076
[13:27:48.098] iteration 8602: loss: 0.101378, loss_s1: 0.052190, loss_fp: 0.001235, loss_freq: 0.060674
[13:27:48.735] iteration 8603: loss: 0.066118, loss_s1: 0.040774, loss_fp: 0.000812, loss_freq: 0.023379
[13:27:49.369] iteration 8604: loss: 0.080675, loss_s1: 0.029497, loss_fp: 0.000968, loss_freq: 0.024496
[13:27:50.000] iteration 8605: loss: 0.087796, loss_s1: 0.042412, loss_fp: 0.004471, loss_freq: 0.029765
[13:27:50.636] iteration 8606: loss: 0.098649, loss_s1: 0.050469, loss_fp: 0.006499, loss_freq: 0.050082
[13:27:51.276] iteration 8607: loss: 0.132133, loss_s1: 0.061282, loss_fp: 0.002701, loss_freq: 0.064856
[13:27:51.915] iteration 8608: loss: 0.053884, loss_s1: 0.033594, loss_fp: 0.000975, loss_freq: 0.010806
[13:27:52.555] iteration 8609: loss: 0.108243, loss_s1: 0.043174, loss_fp: 0.001654, loss_freq: 0.078991
[13:27:53.193] iteration 8610: loss: 0.198758, loss_s1: 0.077559, loss_fp: 0.001877, loss_freq: 0.034434
[13:27:53.831] iteration 8611: loss: 0.064721, loss_s1: 0.023556, loss_fp: 0.000829, loss_freq: 0.021178
[13:27:54.463] iteration 8612: loss: 0.094475, loss_s1: 0.059862, loss_fp: 0.001908, loss_freq: 0.018671
[13:27:55.097] iteration 8613: loss: 0.056805, loss_s1: 0.021657, loss_fp: 0.005401, loss_freq: 0.013327
[13:27:55.730] iteration 8614: loss: 0.120499, loss_s1: 0.107421, loss_fp: 0.005701, loss_freq: 0.069014
[13:27:56.365] iteration 8615: loss: 0.135076, loss_s1: 0.032148, loss_fp: 0.001827, loss_freq: 0.028686
[13:27:57.001] iteration 8616: loss: 0.139154, loss_s1: 0.031965, loss_fp: 0.003275, loss_freq: 0.066668
[13:27:57.655] iteration 8617: loss: 0.070992, loss_s1: 0.044905, loss_fp: 0.000781, loss_freq: 0.029979
[13:27:58.290] iteration 8618: loss: 0.078659, loss_s1: 0.063830, loss_fp: 0.001244, loss_freq: 0.036677
[13:27:58.920] iteration 8619: loss: 0.079247, loss_s1: 0.039467, loss_fp: 0.003707, loss_freq: 0.045553
[13:27:59.563] iteration 8620: loss: 0.083139, loss_s1: 0.049521, loss_fp: 0.003412, loss_freq: 0.016939
[13:28:00.198] iteration 8621: loss: 0.122265, loss_s1: 0.057589, loss_fp: 0.005597, loss_freq: 0.037707
[13:28:00.828] iteration 8622: loss: 0.043863, loss_s1: 0.034717, loss_fp: 0.001859, loss_freq: 0.009273
[13:28:01.461] iteration 8623: loss: 0.079922, loss_s1: 0.020507, loss_fp: 0.003372, loss_freq: 0.019004
[13:28:02.094] iteration 8624: loss: 0.071539, loss_s1: 0.061114, loss_fp: 0.002243, loss_freq: 0.028278
[13:28:02.726] iteration 8625: loss: 0.105601, loss_s1: 0.034107, loss_fp: 0.000573, loss_freq: 0.025690
[13:28:03.375] iteration 8626: loss: 0.082511, loss_s1: 0.014764, loss_fp: 0.001096, loss_freq: 0.041460
[13:28:04.007] iteration 8627: loss: 0.083278, loss_s1: 0.033144, loss_fp: 0.002334, loss_freq: 0.057776
[13:28:04.642] iteration 8628: loss: 0.065684, loss_s1: 0.026031, loss_fp: 0.002873, loss_freq: 0.023009
[13:28:05.276] iteration 8629: loss: 0.067570, loss_s1: 0.065990, loss_fp: 0.001625, loss_freq: 0.024525
[13:28:05.908] iteration 8630: loss: 0.071632, loss_s1: 0.047176, loss_fp: 0.002697, loss_freq: 0.026620
[13:28:06.542] iteration 8631: loss: 0.073767, loss_s1: 0.025556, loss_fp: 0.001881, loss_freq: 0.016426
[13:28:07.176] iteration 8632: loss: 0.091299, loss_s1: 0.044972, loss_fp: 0.001451, loss_freq: 0.025746
[13:28:07.816] iteration 8633: loss: 0.057778, loss_s1: 0.011006, loss_fp: 0.000859, loss_freq: 0.010767
[13:28:08.447] iteration 8634: loss: 0.056859, loss_s1: 0.040658, loss_fp: 0.001466, loss_freq: 0.004584
[13:28:09.089] iteration 8635: loss: 0.102783, loss_s1: 0.034386, loss_fp: 0.000769, loss_freq: 0.035138
[13:28:09.768] iteration 8636: loss: 0.067411, loss_s1: 0.025118, loss_fp: 0.000557, loss_freq: 0.007745
[13:28:10.434] iteration 8637: loss: 0.108131, loss_s1: 0.158804, loss_fp: 0.001965, loss_freq: 0.005141
[13:28:11.098] iteration 8638: loss: 0.056827, loss_s1: 0.023515, loss_fp: 0.003053, loss_freq: 0.015263
[13:28:11.777] iteration 8639: loss: 0.090814, loss_s1: 0.030779, loss_fp: 0.002738, loss_freq: 0.045190
[13:28:12.444] iteration 8640: loss: 0.063108, loss_s1: 0.009919, loss_fp: 0.002197, loss_freq: 0.023420
[13:28:13.087] iteration 8641: loss: 0.069821, loss_s1: 0.035704, loss_fp: 0.005393, loss_freq: 0.018513
[13:28:13.717] iteration 8642: loss: 0.059590, loss_s1: 0.033960, loss_fp: 0.002828, loss_freq: 0.009963
[13:28:14.351] iteration 8643: loss: 0.073704, loss_s1: 0.058431, loss_fp: 0.005273, loss_freq: 0.022513
[13:28:14.995] iteration 8644: loss: 0.077573, loss_s1: 0.015597, loss_fp: 0.001774, loss_freq: 0.012138
[13:28:15.624] iteration 8645: loss: 0.098896, loss_s1: 0.085650, loss_fp: 0.003654, loss_freq: 0.024489
[13:28:16.256] iteration 8646: loss: 0.101257, loss_s1: 0.034526, loss_fp: 0.003365, loss_freq: 0.025011
[13:28:16.886] iteration 8647: loss: 0.106610, loss_s1: 0.061006, loss_fp: 0.003151, loss_freq: 0.062612
[13:28:17.539] iteration 8648: loss: 0.116713, loss_s1: 0.030281, loss_fp: 0.019716, loss_freq: 0.041349
[13:28:18.169] iteration 8649: loss: 0.090386, loss_s1: 0.079019, loss_fp: 0.005787, loss_freq: 0.015607
[13:28:18.803] iteration 8650: loss: 0.111297, loss_s1: 0.052527, loss_fp: 0.004357, loss_freq: 0.010245
[13:28:19.452] iteration 8651: loss: 0.097217, loss_s1: 0.045843, loss_fp: 0.002014, loss_freq: 0.018759
[13:28:20.170] iteration 8652: loss: 0.087611, loss_s1: 0.048520, loss_fp: 0.002738, loss_freq: 0.060184
[13:28:20.821] iteration 8653: loss: 0.088818, loss_s1: 0.036675, loss_fp: 0.004009, loss_freq: 0.040381
[13:28:21.452] iteration 8654: loss: 0.102522, loss_s1: 0.068326, loss_fp: 0.005213, loss_freq: 0.049424
[13:28:22.085] iteration 8655: loss: 0.067233, loss_s1: 0.030834, loss_fp: 0.002604, loss_freq: 0.053925
[13:28:22.724] iteration 8656: loss: 0.087176, loss_s1: 0.033329, loss_fp: 0.003054, loss_freq: 0.029683
[13:28:23.355] iteration 8657: loss: 0.072930, loss_s1: 0.048053, loss_fp: 0.001718, loss_freq: 0.020134
[13:28:24.023] iteration 8658: loss: 0.089347, loss_s1: 0.022115, loss_fp: 0.001201, loss_freq: 0.006269
[13:28:24.696] iteration 8659: loss: 0.073636, loss_s1: 0.035680, loss_fp: 0.010785, loss_freq: 0.027958
[13:28:25.383] iteration 8660: loss: 0.237040, loss_s1: 0.118403, loss_fp: 0.004837, loss_freq: 0.061997
[13:28:26.058] iteration 8661: loss: 0.063199, loss_s1: 0.025076, loss_fp: 0.000610, loss_freq: 0.027707
[13:28:26.731] iteration 8662: loss: 0.096141, loss_s1: 0.036888, loss_fp: 0.001719, loss_freq: 0.065014
[13:28:27.399] iteration 8663: loss: 0.152258, loss_s1: 0.112338, loss_fp: 0.010222, loss_freq: 0.061674
[13:28:28.063] iteration 8664: loss: 0.068907, loss_s1: 0.026792, loss_fp: 0.002608, loss_freq: 0.043146
[13:28:28.724] iteration 8665: loss: 0.125267, loss_s1: 0.106265, loss_fp: 0.002409, loss_freq: 0.040631
[13:28:29.389] iteration 8666: loss: 0.088061, loss_s1: 0.034939, loss_fp: 0.001628, loss_freq: 0.051797
[13:28:30.068] iteration 8667: loss: 0.091256, loss_s1: 0.042608, loss_fp: 0.002690, loss_freq: 0.022016
[13:28:30.718] iteration 8668: loss: 0.101836, loss_s1: 0.031791, loss_fp: 0.001914, loss_freq: 0.031012
[13:28:31.356] iteration 8669: loss: 0.077826, loss_s1: 0.049036, loss_fp: 0.002152, loss_freq: 0.040117
[13:28:31.985] iteration 8670: loss: 0.125178, loss_s1: 0.033719, loss_fp: 0.003495, loss_freq: 0.053412
[13:28:32.621] iteration 8671: loss: 0.081756, loss_s1: 0.021879, loss_fp: 0.003500, loss_freq: 0.009038
[13:28:33.252] iteration 8672: loss: 0.092300, loss_s1: 0.064787, loss_fp: 0.007477, loss_freq: 0.020268
[13:28:33.884] iteration 8673: loss: 0.070441, loss_s1: 0.054285, loss_fp: 0.005680, loss_freq: 0.016947
[13:28:34.511] iteration 8674: loss: 0.092330, loss_s1: 0.023178, loss_fp: 0.004581, loss_freq: 0.039904
[13:28:35.156] iteration 8675: loss: 0.063861, loss_s1: 0.035221, loss_fp: 0.001264, loss_freq: 0.014646
[13:28:35.804] iteration 8676: loss: 0.097756, loss_s1: 0.088721, loss_fp: 0.000932, loss_freq: 0.021539
[13:28:36.475] iteration 8677: loss: 0.148155, loss_s1: 0.117568, loss_fp: 0.013779, loss_freq: 0.090407
[13:28:37.160] iteration 8678: loss: 0.116817, loss_s1: 0.058204, loss_fp: 0.004951, loss_freq: 0.068991
[13:28:37.849] iteration 8679: loss: 0.081379, loss_s1: 0.036312, loss_fp: 0.001827, loss_freq: 0.019217
[13:28:38.497] iteration 8680: loss: 0.109401, loss_s1: 0.054653, loss_fp: 0.006370, loss_freq: 0.030329
[13:28:39.152] iteration 8681: loss: 0.065507, loss_s1: 0.029881, loss_fp: 0.004476, loss_freq: 0.032326
[13:28:39.795] iteration 8682: loss: 0.069679, loss_s1: 0.026042, loss_fp: 0.002819, loss_freq: 0.016351
[13:28:40.423] iteration 8683: loss: 0.078006, loss_s1: 0.086753, loss_fp: 0.001597, loss_freq: 0.006762
[13:28:41.057] iteration 8684: loss: 0.119250, loss_s1: 0.087903, loss_fp: 0.003054, loss_freq: 0.074997
[13:28:41.685] iteration 8685: loss: 0.108546, loss_s1: 0.031166, loss_fp: 0.017438, loss_freq: 0.022680
[13:28:42.314] iteration 8686: loss: 0.053925, loss_s1: 0.009203, loss_fp: 0.001601, loss_freq: 0.023121
[13:28:42.942] iteration 8687: loss: 0.155371, loss_s1: 0.147441, loss_fp: 0.001905, loss_freq: 0.087258
[13:28:43.587] iteration 8688: loss: 0.075603, loss_s1: 0.066325, loss_fp: 0.002124, loss_freq: 0.030350
[13:28:44.216] iteration 8689: loss: 0.072801, loss_s1: 0.025102, loss_fp: 0.000817, loss_freq: 0.015738
[13:28:44.846] iteration 8690: loss: 0.116240, loss_s1: 0.070420, loss_fp: 0.002076, loss_freq: 0.061518
[13:28:45.487] iteration 8691: loss: 0.088053, loss_s1: 0.025966, loss_fp: 0.001599, loss_freq: 0.020873
[13:28:46.116] iteration 8692: loss: 0.098929, loss_s1: 0.092317, loss_fp: 0.001562, loss_freq: 0.048289
[13:28:46.746] iteration 8693: loss: 0.093776, loss_s1: 0.059920, loss_fp: 0.002777, loss_freq: 0.028942
[13:28:47.374] iteration 8694: loss: 0.107248, loss_s1: 0.104425, loss_fp: 0.003609, loss_freq: 0.030618
[13:28:48.017] iteration 8695: loss: 0.157226, loss_s1: 0.082109, loss_fp: 0.003635, loss_freq: 0.011553
[13:28:48.670] iteration 8696: loss: 0.076728, loss_s1: 0.062080, loss_fp: 0.001462, loss_freq: 0.003966
[13:28:49.300] iteration 8697: loss: 0.136223, loss_s1: 0.097511, loss_fp: 0.003637, loss_freq: 0.089715
[13:28:49.959] iteration 8698: loss: 0.164957, loss_s1: 0.121945, loss_fp: 0.002472, loss_freq: 0.065319
[13:28:50.618] iteration 8699: loss: 0.045718, loss_s1: 0.028412, loss_fp: 0.003115, loss_freq: 0.007179
[13:28:51.288] iteration 8700: loss: 0.081540, loss_s1: 0.043714, loss_fp: 0.005688, loss_freq: 0.029318
[13:28:51.942] iteration 8701: loss: 0.090347, loss_s1: 0.068870, loss_fp: 0.001359, loss_freq: 0.049026
[13:28:52.574] iteration 8702: loss: 0.126581, loss_s1: 0.035580, loss_fp: 0.005965, loss_freq: 0.017933
[13:28:53.207] iteration 8703: loss: 0.040379, loss_s1: 0.012588, loss_fp: 0.000944, loss_freq: 0.008382
[13:28:53.841] iteration 8704: loss: 0.065943, loss_s1: 0.034058, loss_fp: 0.001924, loss_freq: 0.034926
[13:28:54.493] iteration 8705: loss: 0.067192, loss_s1: 0.041761, loss_fp: 0.004331, loss_freq: 0.028458
[13:28:55.126] iteration 8706: loss: 0.108032, loss_s1: 0.036538, loss_fp: 0.002714, loss_freq: 0.053740
[13:28:55.760] iteration 8707: loss: 0.078835, loss_s1: 0.015986, loss_fp: 0.000484, loss_freq: 0.052735
[13:28:56.390] iteration 8708: loss: 0.083842, loss_s1: 0.068319, loss_fp: 0.001971, loss_freq: 0.024061
[13:28:57.016] iteration 8709: loss: 0.110793, loss_s1: 0.043696, loss_fp: 0.002770, loss_freq: 0.029589
[13:28:57.664] iteration 8710: loss: 0.066375, loss_s1: 0.031896, loss_fp: 0.002459, loss_freq: 0.022009
[13:28:58.317] iteration 8711: loss: 0.097430, loss_s1: 0.045735, loss_fp: 0.002681, loss_freq: 0.020121
[13:28:58.962] iteration 8712: loss: 0.164465, loss_s1: 0.056952, loss_fp: 0.011737, loss_freq: 0.059946
[13:28:59.616] iteration 8713: loss: 0.066282, loss_s1: 0.040398, loss_fp: 0.001951, loss_freq: 0.018264
[13:29:00.268] iteration 8714: loss: 0.099857, loss_s1: 0.045912, loss_fp: 0.002103, loss_freq: 0.056026
[13:29:00.922] iteration 8715: loss: 0.117951, loss_s1: 0.043956, loss_fp: 0.004142, loss_freq: 0.027495
[13:29:01.569] iteration 8716: loss: 0.109368, loss_s1: 0.065404, loss_fp: 0.005356, loss_freq: 0.016079
[13:29:02.223] iteration 8717: loss: 0.073665, loss_s1: 0.053313, loss_fp: 0.001223, loss_freq: 0.027098
[13:29:02.851] iteration 8718: loss: 0.086747, loss_s1: 0.009885, loss_fp: 0.003030, loss_freq: 0.024433
[13:29:03.470] iteration 8719: loss: 0.047563, loss_s1: 0.014590, loss_fp: 0.001319, loss_freq: 0.015055
[13:29:04.098] iteration 8720: loss: 0.086772, loss_s1: 0.024656, loss_fp: 0.000962, loss_freq: 0.011450
[13:29:04.727] iteration 8721: loss: 0.087598, loss_s1: 0.049546, loss_fp: 0.003876, loss_freq: 0.045356
[13:29:05.352] iteration 8722: loss: 0.106146, loss_s1: 0.057731, loss_fp: 0.005074, loss_freq: 0.030375
[13:29:05.976] iteration 8723: loss: 0.048055, loss_s1: 0.012965, loss_fp: 0.000830, loss_freq: 0.012224
[13:29:06.916] iteration 8724: loss: 0.076770, loss_s1: 0.031845, loss_fp: 0.000431, loss_freq: 0.020947
[13:29:07.587] iteration 8725: loss: 0.077972, loss_s1: 0.039993, loss_fp: 0.000612, loss_freq: 0.030807
[13:29:08.252] iteration 8726: loss: 0.044637, loss_s1: 0.016732, loss_fp: 0.001129, loss_freq: 0.024582
[13:29:08.923] iteration 8727: loss: 0.093732, loss_s1: 0.076712, loss_fp: 0.004095, loss_freq: 0.025665
[13:29:09.597] iteration 8728: loss: 0.089197, loss_s1: 0.080901, loss_fp: 0.002901, loss_freq: 0.041769
[13:29:10.261] iteration 8729: loss: 0.085263, loss_s1: 0.042012, loss_fp: 0.001138, loss_freq: 0.010156
[13:29:10.899] iteration 8730: loss: 0.080865, loss_s1: 0.081504, loss_fp: 0.002850, loss_freq: 0.032394
[13:29:11.535] iteration 8731: loss: 0.146027, loss_s1: 0.096454, loss_fp: 0.007789, loss_freq: 0.036548
[13:29:12.168] iteration 8732: loss: 0.121451, loss_s1: 0.079082, loss_fp: 0.001611, loss_freq: 0.082243
[13:29:12.936] iteration 8733: loss: 0.094472, loss_s1: 0.009008, loss_fp: 0.001996, loss_freq: 0.020209
[13:29:13.787] iteration 8734: loss: 0.066411, loss_s1: 0.044561, loss_fp: 0.001704, loss_freq: 0.026117
[13:29:14.497] iteration 8735: loss: 0.062929, loss_s1: 0.027818, loss_fp: 0.002576, loss_freq: 0.016979
[13:29:15.194] iteration 8736: loss: 0.082725, loss_s1: 0.066059, loss_fp: 0.002561, loss_freq: 0.012523
[13:29:15.881] iteration 8737: loss: 0.038578, loss_s1: 0.013163, loss_fp: 0.000880, loss_freq: 0.010460
[13:29:16.543] iteration 8738: loss: 0.099713, loss_s1: 0.127348, loss_fp: 0.000753, loss_freq: 0.009588
[13:29:17.230] iteration 8739: loss: 0.071582, loss_s1: 0.037414, loss_fp: 0.004152, loss_freq: 0.040603
[13:29:17.883] iteration 8740: loss: 0.131586, loss_s1: 0.048200, loss_fp: 0.000881, loss_freq: 0.011700
[13:29:18.556] iteration 8741: loss: 0.103400, loss_s1: 0.040309, loss_fp: 0.003767, loss_freq: 0.016985
[13:29:19.196] iteration 8742: loss: 0.068405, loss_s1: 0.046454, loss_fp: 0.001694, loss_freq: 0.014087
[13:29:19.869] iteration 8743: loss: 0.055411, loss_s1: 0.027706, loss_fp: 0.002510, loss_freq: 0.032113
[13:29:20.540] iteration 8744: loss: 0.135233, loss_s1: 0.032959, loss_fp: 0.002292, loss_freq: 0.082787
[13:29:21.224] iteration 8745: loss: 0.070079, loss_s1: 0.035272, loss_fp: 0.002343, loss_freq: 0.038486
[13:29:21.883] iteration 8746: loss: 0.081900, loss_s1: 0.061939, loss_fp: 0.003547, loss_freq: 0.032350
[13:29:22.546] iteration 8747: loss: 0.102705, loss_s1: 0.086060, loss_fp: 0.005517, loss_freq: 0.022279
[13:29:23.212] iteration 8748: loss: 0.049353, loss_s1: 0.026591, loss_fp: 0.000839, loss_freq: 0.008794
[13:29:23.889] iteration 8749: loss: 0.097899, loss_s1: 0.045906, loss_fp: 0.005064, loss_freq: 0.048797
[13:29:24.567] iteration 8750: loss: 0.128965, loss_s1: 0.060589, loss_fp: 0.001956, loss_freq: 0.059738
[13:29:25.227] iteration 8751: loss: 0.070961, loss_s1: 0.036380, loss_fp: 0.002136, loss_freq: 0.038655
[13:29:25.864] iteration 8752: loss: 0.115568, loss_s1: 0.088241, loss_fp: 0.002806, loss_freq: 0.052012
[13:29:26.496] iteration 8753: loss: 0.090472, loss_s1: 0.035625, loss_fp: 0.002784, loss_freq: 0.032852
[13:29:27.133] iteration 8754: loss: 0.097611, loss_s1: 0.063312, loss_fp: 0.007157, loss_freq: 0.009327
[13:29:27.771] iteration 8755: loss: 0.085348, loss_s1: 0.039281, loss_fp: 0.005424, loss_freq: 0.031650
[13:29:28.398] iteration 8756: loss: 0.079494, loss_s1: 0.061046, loss_fp: 0.014564, loss_freq: 0.012952
[13:29:29.025] iteration 8757: loss: 0.108536, loss_s1: 0.044344, loss_fp: 0.002796, loss_freq: 0.072178
[13:29:29.654] iteration 8758: loss: 0.153863, loss_s1: 0.059029, loss_fp: 0.004039, loss_freq: 0.018940
[13:29:30.285] iteration 8759: loss: 0.140327, loss_s1: 0.059643, loss_fp: 0.002399, loss_freq: 0.053177
[13:29:30.915] iteration 8760: loss: 0.107081, loss_s1: 0.064235, loss_fp: 0.002200, loss_freq: 0.049351
[13:29:31.547] iteration 8761: loss: 0.047406, loss_s1: 0.028094, loss_fp: 0.001454, loss_freq: 0.013402
[13:29:32.183] iteration 8762: loss: 0.104349, loss_s1: 0.069172, loss_fp: 0.002696, loss_freq: 0.043942
[13:29:32.818] iteration 8763: loss: 0.052231, loss_s1: 0.019478, loss_fp: 0.000885, loss_freq: 0.007966
[13:29:33.462] iteration 8764: loss: 0.090875, loss_s1: 0.033852, loss_fp: 0.001219, loss_freq: 0.014041
[13:29:34.092] iteration 8765: loss: 0.054816, loss_s1: 0.030488, loss_fp: 0.000864, loss_freq: 0.020488
[13:29:34.726] iteration 8766: loss: 0.105774, loss_s1: 0.047099, loss_fp: 0.000918, loss_freq: 0.012260
[13:29:35.371] iteration 8767: loss: 0.089055, loss_s1: 0.045515, loss_fp: 0.006440, loss_freq: 0.054718
[13:29:35.998] iteration 8768: loss: 0.138355, loss_s1: 0.056925, loss_fp: 0.005787, loss_freq: 0.038140
[13:29:36.632] iteration 8769: loss: 0.151679, loss_s1: 0.087829, loss_fp: 0.001071, loss_freq: 0.046586
[13:29:37.262] iteration 8770: loss: 0.100355, loss_s1: 0.018249, loss_fp: 0.002829, loss_freq: 0.039737
[13:29:37.925] iteration 8771: loss: 0.103533, loss_s1: 0.059224, loss_fp: 0.001901, loss_freq: 0.040800
[13:29:38.565] iteration 8772: loss: 0.059481, loss_s1: 0.032960, loss_fp: 0.000909, loss_freq: 0.018783
[13:29:39.192] iteration 8773: loss: 0.072234, loss_s1: 0.033342, loss_fp: 0.001615, loss_freq: 0.038078
[13:29:39.820] iteration 8774: loss: 0.083373, loss_s1: 0.057549, loss_fp: 0.001895, loss_freq: 0.037660
[13:29:40.447] iteration 8775: loss: 0.163144, loss_s1: 0.030823, loss_fp: 0.002278, loss_freq: 0.025735
[13:29:41.092] iteration 8776: loss: 0.063276, loss_s1: 0.017386, loss_fp: 0.000956, loss_freq: 0.005240
[13:29:41.720] iteration 8777: loss: 0.067967, loss_s1: 0.032876, loss_fp: 0.000765, loss_freq: 0.016845
[13:29:42.350] iteration 8778: loss: 0.048326, loss_s1: 0.040595, loss_fp: 0.001538, loss_freq: 0.005851
[13:29:42.984] iteration 8779: loss: 0.146014, loss_s1: 0.061636, loss_fp: 0.001131, loss_freq: 0.010345
[13:29:43.613] iteration 8780: loss: 0.121820, loss_s1: 0.094616, loss_fp: 0.000791, loss_freq: 0.056165
[13:29:44.247] iteration 8781: loss: 0.061129, loss_s1: 0.025478, loss_fp: 0.001859, loss_freq: 0.027004
[13:29:44.889] iteration 8782: loss: 0.097658, loss_s1: 0.044471, loss_fp: 0.000755, loss_freq: 0.044444
[13:29:45.522] iteration 8783: loss: 0.061908, loss_s1: 0.018274, loss_fp: 0.007422, loss_freq: 0.026166
[13:29:46.151] iteration 8784: loss: 0.086499, loss_s1: 0.037842, loss_fp: 0.003182, loss_freq: 0.028090
[13:29:46.787] iteration 8785: loss: 0.095337, loss_s1: 0.058220, loss_fp: 0.001793, loss_freq: 0.039816
[13:29:47.432] iteration 8786: loss: 0.087069, loss_s1: 0.052013, loss_fp: 0.003530, loss_freq: 0.055274
[13:29:48.063] iteration 8787: loss: 0.076420, loss_s1: 0.033945, loss_fp: 0.000488, loss_freq: 0.017232
[13:29:48.693] iteration 8788: loss: 0.110232, loss_s1: 0.078094, loss_fp: 0.013629, loss_freq: 0.009666
[13:29:49.324] iteration 8789: loss: 0.133200, loss_s1: 0.069897, loss_fp: 0.003208, loss_freq: 0.020807
[13:29:49.961] iteration 8790: loss: 0.115465, loss_s1: 0.047791, loss_fp: 0.002652, loss_freq: 0.066209
[13:29:50.594] iteration 8791: loss: 0.079631, loss_s1: 0.023075, loss_fp: 0.001662, loss_freq: 0.017787
[13:29:51.228] iteration 8792: loss: 0.072817, loss_s1: 0.055266, loss_fp: 0.005442, loss_freq: 0.025064
[13:29:51.857] iteration 8793: loss: 0.144358, loss_s1: 0.036366, loss_fp: 0.013010, loss_freq: 0.029693
[13:29:52.494] iteration 8794: loss: 0.106122, loss_s1: 0.041908, loss_fp: 0.002805, loss_freq: 0.030066
[13:29:53.127] iteration 8795: loss: 0.113237, loss_s1: 0.083124, loss_fp: 0.015021, loss_freq: 0.052852
[13:29:53.761] iteration 8796: loss: 0.105660, loss_s1: 0.054512, loss_fp: 0.001801, loss_freq: 0.075530
[13:29:54.407] iteration 8797: loss: 0.110673, loss_s1: 0.104506, loss_fp: 0.002690, loss_freq: 0.041090
[13:29:55.040] iteration 8798: loss: 0.111019, loss_s1: 0.083709, loss_fp: 0.001166, loss_freq: 0.077436
[13:29:55.675] iteration 8799: loss: 0.090729, loss_s1: 0.053980, loss_fp: 0.004451, loss_freq: 0.013087
[13:29:56.309] iteration 8800: loss: 0.082171, loss_s1: 0.048587, loss_fp: 0.003064, loss_freq: 0.047039
[13:29:59.603] iteration 8800 : mean_dice : 0.737866
[13:30:00.270] iteration 8801: loss: 0.079284, loss_s1: 0.029172, loss_fp: 0.001805, loss_freq: 0.017353
[13:30:00.902] iteration 8802: loss: 0.108072, loss_s1: 0.048451, loss_fp: 0.038212, loss_freq: 0.058106
[13:30:01.532] iteration 8803: loss: 0.179606, loss_s1: 0.081948, loss_fp: 0.000824, loss_freq: 0.035850
[13:30:02.162] iteration 8804: loss: 0.082100, loss_s1: 0.079960, loss_fp: 0.001501, loss_freq: 0.020363
[13:30:02.806] iteration 8805: loss: 0.102369, loss_s1: 0.071487, loss_fp: 0.001084, loss_freq: 0.040483
[13:30:03.442] iteration 8806: loss: 0.072052, loss_s1: 0.020285, loss_fp: 0.001602, loss_freq: 0.025464
[13:30:04.074] iteration 8807: loss: 0.055557, loss_s1: 0.036303, loss_fp: 0.001100, loss_freq: 0.004368
[13:30:04.711] iteration 8808: loss: 0.058240, loss_s1: 0.035422, loss_fp: 0.001809, loss_freq: 0.015083
[13:30:05.377] iteration 8809: loss: 0.099037, loss_s1: 0.055596, loss_fp: 0.002332, loss_freq: 0.076375
[13:30:06.051] iteration 8810: loss: 0.106586, loss_s1: 0.035258, loss_fp: 0.001430, loss_freq: 0.020072
[13:30:06.722] iteration 8811: loss: 0.052036, loss_s1: 0.018522, loss_fp: 0.000790, loss_freq: 0.018674
[13:30:07.389] iteration 8812: loss: 0.053438, loss_s1: 0.026002, loss_fp: 0.000618, loss_freq: 0.012520
[13:30:08.071] iteration 8813: loss: 0.086534, loss_s1: 0.024639, loss_fp: 0.001548, loss_freq: 0.032847
[13:30:08.748] iteration 8814: loss: 0.099965, loss_s1: 0.031670, loss_fp: 0.002120, loss_freq: 0.010545
[13:30:09.413] iteration 8815: loss: 0.088561, loss_s1: 0.047877, loss_fp: 0.002145, loss_freq: 0.054876
[13:30:10.068] iteration 8816: loss: 0.063559, loss_s1: 0.047072, loss_fp: 0.001097, loss_freq: 0.004134
[13:30:10.703] iteration 8817: loss: 0.113724, loss_s1: 0.052868, loss_fp: 0.002826, loss_freq: 0.041132
[13:30:11.332] iteration 8818: loss: 0.059762, loss_s1: 0.025512, loss_fp: 0.003017, loss_freq: 0.027572
[13:30:11.959] iteration 8819: loss: 0.116986, loss_s1: 0.071962, loss_fp: 0.002046, loss_freq: 0.035604
[13:30:12.583] iteration 8820: loss: 0.177059, loss_s1: 0.096287, loss_fp: 0.004721, loss_freq: 0.125080
[13:30:13.209] iteration 8821: loss: 0.094881, loss_s1: 0.073512, loss_fp: 0.001761, loss_freq: 0.026451
[13:30:13.831] iteration 8822: loss: 0.067300, loss_s1: 0.020014, loss_fp: 0.002475, loss_freq: 0.025366
[13:30:14.463] iteration 8823: loss: 0.098305, loss_s1: 0.058696, loss_fp: 0.001796, loss_freq: 0.039474
[13:30:15.087] iteration 8824: loss: 0.110424, loss_s1: 0.069787, loss_fp: 0.002841, loss_freq: 0.064070
[13:30:15.712] iteration 8825: loss: 0.053567, loss_s1: 0.008584, loss_fp: 0.002443, loss_freq: 0.014365
[13:30:16.334] iteration 8826: loss: 0.089900, loss_s1: 0.019941, loss_fp: 0.003359, loss_freq: 0.005430
[13:30:16.956] iteration 8827: loss: 0.070849, loss_s1: 0.034255, loss_fp: 0.003330, loss_freq: 0.030361
[13:30:17.602] iteration 8828: loss: 0.116473, loss_s1: 0.053765, loss_fp: 0.002151, loss_freq: 0.018503
[13:30:18.239] iteration 8829: loss: 0.056904, loss_s1: 0.032839, loss_fp: 0.002097, loss_freq: 0.023044
[13:30:18.869] iteration 8830: loss: 0.103121, loss_s1: 0.064145, loss_fp: 0.001647, loss_freq: 0.054469
[13:30:19.491] iteration 8831: loss: 0.060828, loss_s1: 0.025490, loss_fp: 0.001635, loss_freq: 0.034234
[13:30:20.113] iteration 8832: loss: 0.079418, loss_s1: 0.028040, loss_fp: 0.001593, loss_freq: 0.021263
[13:30:20.762] iteration 8833: loss: 0.082803, loss_s1: 0.055499, loss_fp: 0.004895, loss_freq: 0.035010
[13:30:21.427] iteration 8834: loss: 0.092660, loss_s1: 0.036466, loss_fp: 0.000415, loss_freq: 0.009239
[13:30:22.082] iteration 8835: loss: 0.088472, loss_s1: 0.085931, loss_fp: 0.006447, loss_freq: 0.029107
[13:30:22.706] iteration 8836: loss: 0.085581, loss_s1: 0.026934, loss_fp: 0.001032, loss_freq: 0.021091
[13:30:23.330] iteration 8837: loss: 0.090574, loss_s1: 0.043544, loss_fp: 0.001327, loss_freq: 0.046487
[13:30:23.954] iteration 8838: loss: 0.189582, loss_s1: 0.101450, loss_fp: 0.004084, loss_freq: 0.036147
[13:30:24.575] iteration 8839: loss: 0.060484, loss_s1: 0.048701, loss_fp: 0.002391, loss_freq: 0.009947
[13:30:25.198] iteration 8840: loss: 0.151029, loss_s1: 0.069483, loss_fp: 0.002381, loss_freq: 0.044567
[13:30:25.823] iteration 8841: loss: 0.097234, loss_s1: 0.050906, loss_fp: 0.002159, loss_freq: 0.039399
[13:30:26.442] iteration 8842: loss: 0.081772, loss_s1: 0.067573, loss_fp: 0.001953, loss_freq: 0.041254
[13:30:27.066] iteration 8843: loss: 0.119903, loss_s1: 0.071319, loss_fp: 0.005609, loss_freq: 0.061170
[13:30:27.696] iteration 8844: loss: 0.090194, loss_s1: 0.016340, loss_fp: 0.001375, loss_freq: 0.100850
[13:30:28.317] iteration 8845: loss: 0.146714, loss_s1: 0.040559, loss_fp: 0.002164, loss_freq: 0.020393
[13:30:28.938] iteration 8846: loss: 0.080890, loss_s1: 0.011882, loss_fp: 0.004111, loss_freq: 0.007404
[13:30:29.583] iteration 8847: loss: 0.075612, loss_s1: 0.060547, loss_fp: 0.001272, loss_freq: 0.033965
[13:30:30.220] iteration 8848: loss: 0.090498, loss_s1: 0.068658, loss_fp: 0.006567, loss_freq: 0.042103
[13:30:30.856] iteration 8849: loss: 0.128443, loss_s1: 0.067696, loss_fp: 0.003515, loss_freq: 0.033571
[13:30:31.498] iteration 8850: loss: 0.111324, loss_s1: 0.023004, loss_fp: 0.002533, loss_freq: 0.080618
[13:30:32.138] iteration 8851: loss: 0.051442, loss_s1: 0.024244, loss_fp: 0.002384, loss_freq: 0.022385
[13:30:32.775] iteration 8852: loss: 0.132176, loss_s1: 0.076052, loss_fp: 0.010547, loss_freq: 0.016964
[13:30:33.413] iteration 8853: loss: 0.053354, loss_s1: 0.022725, loss_fp: 0.002861, loss_freq: 0.014974
[13:30:34.051] iteration 8854: loss: 0.080741, loss_s1: 0.027634, loss_fp: 0.001921, loss_freq: 0.052993
[13:30:34.690] iteration 8855: loss: 0.111789, loss_s1: 0.051942, loss_fp: 0.004084, loss_freq: 0.025943
[13:30:35.328] iteration 8856: loss: 0.078710, loss_s1: 0.056266, loss_fp: 0.002787, loss_freq: 0.015470
[13:30:35.973] iteration 8857: loss: 0.130009, loss_s1: 0.115596, loss_fp: 0.002549, loss_freq: 0.041168
[13:30:36.625] iteration 8858: loss: 0.117165, loss_s1: 0.046307, loss_fp: 0.003272, loss_freq: 0.063124
[13:30:37.247] iteration 8859: loss: 0.102460, loss_s1: 0.010784, loss_fp: 0.002174, loss_freq: 0.037867
[13:30:37.871] iteration 8860: loss: 0.088906, loss_s1: 0.078614, loss_fp: 0.003205, loss_freq: 0.012488
[13:30:38.495] iteration 8861: loss: 0.058490, loss_s1: 0.006775, loss_fp: 0.001680, loss_freq: 0.021272
[13:30:39.116] iteration 8862: loss: 0.056938, loss_s1: 0.033492, loss_fp: 0.000614, loss_freq: 0.020271
[13:30:39.744] iteration 8863: loss: 0.116340, loss_s1: 0.063947, loss_fp: 0.001549, loss_freq: 0.018908
[13:30:40.364] iteration 8864: loss: 0.140329, loss_s1: 0.031789, loss_fp: 0.002105, loss_freq: 0.044585
[13:30:40.984] iteration 8865: loss: 0.135892, loss_s1: 0.131314, loss_fp: 0.002381, loss_freq: 0.034943
[13:30:41.600] iteration 8866: loss: 0.073839, loss_s1: 0.037320, loss_fp: 0.001445, loss_freq: 0.031164
[13:30:42.582] iteration 8867: loss: 0.061790, loss_s1: 0.038101, loss_fp: 0.001729, loss_freq: 0.013673
[13:30:43.258] iteration 8868: loss: 0.081077, loss_s1: 0.054334, loss_fp: 0.001839, loss_freq: 0.024557
[13:30:43.914] iteration 8869: loss: 0.046783, loss_s1: 0.028676, loss_fp: 0.000957, loss_freq: 0.013406
[13:30:44.568] iteration 8870: loss: 0.112931, loss_s1: 0.050812, loss_fp: 0.000569, loss_freq: 0.041938
[13:30:45.258] iteration 8871: loss: 0.098422, loss_s1: 0.069082, loss_fp: 0.002145, loss_freq: 0.053204
[13:30:45.919] iteration 8872: loss: 0.088235, loss_s1: 0.023691, loss_fp: 0.000641, loss_freq: 0.003813
[13:30:46.546] iteration 8873: loss: 0.048952, loss_s1: 0.032022, loss_fp: 0.001663, loss_freq: 0.023455
[13:30:47.203] iteration 8874: loss: 0.169411, loss_s1: 0.090087, loss_fp: 0.005444, loss_freq: 0.038137
[13:30:47.857] iteration 8875: loss: 0.080641, loss_s1: 0.042475, loss_fp: 0.003389, loss_freq: 0.028741
[13:30:48.479] iteration 8876: loss: 0.089852, loss_s1: 0.018824, loss_fp: 0.000829, loss_freq: 0.014775
[13:30:49.102] iteration 8877: loss: 0.114981, loss_s1: 0.064296, loss_fp: 0.004088, loss_freq: 0.037954
[13:30:49.724] iteration 8878: loss: 0.111637, loss_s1: 0.054272, loss_fp: 0.001422, loss_freq: 0.061026
[13:30:50.346] iteration 8879: loss: 0.068946, loss_s1: 0.041692, loss_fp: 0.001244, loss_freq: 0.025596
[13:30:50.968] iteration 8880: loss: 0.050844, loss_s1: 0.030456, loss_fp: 0.001520, loss_freq: 0.013294
[13:30:51.592] iteration 8881: loss: 0.109311, loss_s1: 0.110776, loss_fp: 0.000603, loss_freq: 0.034070
[13:30:52.218] iteration 8882: loss: 0.078969, loss_s1: 0.055600, loss_fp: 0.000978, loss_freq: 0.024729
[13:30:52.847] iteration 8883: loss: 0.132292, loss_s1: 0.017157, loss_fp: 0.001330, loss_freq: 0.032845
[13:30:53.472] iteration 8884: loss: 0.084969, loss_s1: 0.042575, loss_fp: 0.001624, loss_freq: 0.015357
[13:30:54.102] iteration 8885: loss: 0.048989, loss_s1: 0.040466, loss_fp: 0.000408, loss_freq: 0.009380
[13:30:54.725] iteration 8886: loss: 0.112327, loss_s1: 0.071652, loss_fp: 0.002420, loss_freq: 0.036673
[13:30:55.347] iteration 8887: loss: 0.130250, loss_s1: 0.039564, loss_fp: 0.000618, loss_freq: 0.036144
[13:30:55.976] iteration 8888: loss: 0.066784, loss_s1: 0.027720, loss_fp: 0.000799, loss_freq: 0.030030
[13:30:56.663] iteration 8889: loss: 0.062550, loss_s1: 0.024974, loss_fp: 0.001080, loss_freq: 0.027433
[13:30:57.320] iteration 8890: loss: 0.084878, loss_s1: 0.027996, loss_fp: 0.003094, loss_freq: 0.024132
[13:30:57.976] iteration 8891: loss: 0.063430, loss_s1: 0.013726, loss_fp: 0.001344, loss_freq: 0.039941
[13:30:58.649] iteration 8892: loss: 0.096329, loss_s1: 0.052635, loss_fp: 0.009528, loss_freq: 0.039297
[13:30:59.298] iteration 8893: loss: 0.105328, loss_s1: 0.039833, loss_fp: 0.002797, loss_freq: 0.070889
[13:30:59.920] iteration 8894: loss: 0.107546, loss_s1: 0.063918, loss_fp: 0.001907, loss_freq: 0.056060
[13:31:00.542] iteration 8895: loss: 0.115960, loss_s1: 0.027563, loss_fp: 0.005477, loss_freq: 0.081358
[13:31:01.168] iteration 8896: loss: 0.079389, loss_s1: 0.036812, loss_fp: 0.001897, loss_freq: 0.018135
[13:31:01.791] iteration 8897: loss: 0.065732, loss_s1: 0.047177, loss_fp: 0.000878, loss_freq: 0.016989
[13:31:02.416] iteration 8898: loss: 0.079770, loss_s1: 0.029417, loss_fp: 0.005270, loss_freq: 0.023628
[13:31:03.038] iteration 8899: loss: 0.059324, loss_s1: 0.052340, loss_fp: 0.000875, loss_freq: 0.009050
[13:31:03.662] iteration 8900: loss: 0.095020, loss_s1: 0.068544, loss_fp: 0.017917, loss_freq: 0.044118
[13:31:04.285] iteration 8901: loss: 0.115800, loss_s1: 0.058058, loss_fp: 0.001419, loss_freq: 0.030528
[13:31:04.906] iteration 8902: loss: 0.083935, loss_s1: 0.061795, loss_fp: 0.002410, loss_freq: 0.032693
[13:31:05.526] iteration 8903: loss: 0.069732, loss_s1: 0.034607, loss_fp: 0.001327, loss_freq: 0.020510
[13:31:06.152] iteration 8904: loss: 0.080258, loss_s1: 0.071102, loss_fp: 0.001476, loss_freq: 0.038978
[13:31:06.781] iteration 8905: loss: 0.111066, loss_s1: 0.051327, loss_fp: 0.003377, loss_freq: 0.014379
[13:31:07.401] iteration 8906: loss: 0.072668, loss_s1: 0.044185, loss_fp: 0.005024, loss_freq: 0.022746
[13:31:08.023] iteration 8907: loss: 0.108693, loss_s1: 0.038256, loss_fp: 0.001872, loss_freq: 0.032860
[13:31:08.645] iteration 8908: loss: 0.070535, loss_s1: 0.055678, loss_fp: 0.001565, loss_freq: 0.027043
[13:31:09.306] iteration 8909: loss: 0.091964, loss_s1: 0.046868, loss_fp: 0.000575, loss_freq: 0.006535
[13:31:09.962] iteration 8910: loss: 0.109953, loss_s1: 0.104613, loss_fp: 0.002123, loss_freq: 0.038328
[13:31:10.605] iteration 8911: loss: 0.086632, loss_s1: 0.036554, loss_fp: 0.001175, loss_freq: 0.021559
[13:31:11.230] iteration 8912: loss: 0.120160, loss_s1: 0.048084, loss_fp: 0.001096, loss_freq: 0.074463
[13:31:11.853] iteration 8913: loss: 0.063219, loss_s1: 0.015732, loss_fp: 0.002578, loss_freq: 0.039656
[13:31:12.474] iteration 8914: loss: 0.079820, loss_s1: 0.074344, loss_fp: 0.001710, loss_freq: 0.017358
[13:31:13.095] iteration 8915: loss: 0.070891, loss_s1: 0.079812, loss_fp: 0.003784, loss_freq: 0.016990
[13:31:13.714] iteration 8916: loss: 0.065636, loss_s1: 0.049224, loss_fp: 0.001358, loss_freq: 0.019476
[13:31:14.334] iteration 8917: loss: 0.085319, loss_s1: 0.080788, loss_fp: 0.007280, loss_freq: 0.023196
[13:31:14.956] iteration 8918: loss: 0.093944, loss_s1: 0.029534, loss_fp: 0.000682, loss_freq: 0.037787
[13:31:15.582] iteration 8919: loss: 0.103434, loss_s1: 0.054201, loss_fp: 0.000881, loss_freq: 0.002946
[13:31:16.203] iteration 8920: loss: 0.044841, loss_s1: 0.015564, loss_fp: 0.007978, loss_freq: 0.010708
[13:31:16.830] iteration 8921: loss: 0.081355, loss_s1: 0.054350, loss_fp: 0.002841, loss_freq: 0.035852
[13:31:17.521] iteration 8922: loss: 0.113927, loss_s1: 0.041595, loss_fp: 0.001418, loss_freq: 0.007849
[13:31:18.466] iteration 8923: loss: 0.083565, loss_s1: 0.056215, loss_fp: 0.001772, loss_freq: 0.029145
[13:31:19.414] iteration 8924: loss: 0.083125, loss_s1: 0.060826, loss_fp: 0.005354, loss_freq: 0.044522
[13:31:20.245] iteration 8925: loss: 0.103525, loss_s1: 0.034890, loss_fp: 0.002731, loss_freq: 0.058294
[13:31:20.899] iteration 8926: loss: 0.080914, loss_s1: 0.033464, loss_fp: 0.001610, loss_freq: 0.039253
[13:31:21.551] iteration 8927: loss: 0.124923, loss_s1: 0.023674, loss_fp: 0.002858, loss_freq: 0.013072
[13:31:22.177] iteration 8928: loss: 0.109521, loss_s1: 0.043846, loss_fp: 0.006995, loss_freq: 0.021441
[13:31:22.800] iteration 8929: loss: 0.076430, loss_s1: 0.049698, loss_fp: 0.001349, loss_freq: 0.024523
[13:31:23.420] iteration 8930: loss: 0.076145, loss_s1: 0.024415, loss_fp: 0.001042, loss_freq: 0.007904
[13:31:24.041] iteration 8931: loss: 0.093844, loss_s1: 0.030241, loss_fp: 0.008472, loss_freq: 0.025674
[13:31:24.661] iteration 8932: loss: 0.091020, loss_s1: 0.040978, loss_fp: 0.003865, loss_freq: 0.009620
[13:31:25.281] iteration 8933: loss: 0.107796, loss_s1: 0.091490, loss_fp: 0.001139, loss_freq: 0.039034
[13:31:25.903] iteration 8934: loss: 0.061139, loss_s1: 0.022498, loss_fp: 0.000401, loss_freq: 0.015232
[13:31:26.560] iteration 8935: loss: 0.069015, loss_s1: 0.018061, loss_fp: 0.005952, loss_freq: 0.011896
[13:31:27.181] iteration 8936: loss: 0.083131, loss_s1: 0.032573, loss_fp: 0.002304, loss_freq: 0.030880
[13:31:27.806] iteration 8937: loss: 0.093049, loss_s1: 0.057692, loss_fp: 0.002359, loss_freq: 0.033529
[13:31:28.432] iteration 8938: loss: 0.085039, loss_s1: 0.060755, loss_fp: 0.001170, loss_freq: 0.034234
[13:31:29.053] iteration 8939: loss: 0.079850, loss_s1: 0.026018, loss_fp: 0.001454, loss_freq: 0.034727
[13:31:29.672] iteration 8940: loss: 0.092765, loss_s1: 0.062850, loss_fp: 0.004238, loss_freq: 0.012898
[13:31:30.299] iteration 8941: loss: 0.108921, loss_s1: 0.085463, loss_fp: 0.003207, loss_freq: 0.038594
[13:31:30.922] iteration 8942: loss: 0.097081, loss_s1: 0.076721, loss_fp: 0.000937, loss_freq: 0.006486
[13:31:31.545] iteration 8943: loss: 0.085920, loss_s1: 0.047021, loss_fp: 0.001078, loss_freq: 0.042156
[13:31:32.165] iteration 8944: loss: 0.085599, loss_s1: 0.033213, loss_fp: 0.000251, loss_freq: 0.027880
[13:31:32.783] iteration 8945: loss: 0.115713, loss_s1: 0.094020, loss_fp: 0.003020, loss_freq: 0.053275
[13:31:33.402] iteration 8946: loss: 0.190158, loss_s1: 0.057345, loss_fp: 0.003585, loss_freq: 0.042429
[13:31:34.021] iteration 8947: loss: 0.097420, loss_s1: 0.036470, loss_fp: 0.000564, loss_freq: 0.052280
[13:31:34.642] iteration 8948: loss: 0.101573, loss_s1: 0.060322, loss_fp: 0.002602, loss_freq: 0.049255
[13:31:35.295] iteration 8949: loss: 0.081636, loss_s1: 0.059874, loss_fp: 0.003849, loss_freq: 0.008345
[13:31:35.913] iteration 8950: loss: 0.040190, loss_s1: 0.020055, loss_fp: 0.000518, loss_freq: 0.012222
[13:31:36.535] iteration 8951: loss: 0.072671, loss_s1: 0.049264, loss_fp: 0.002566, loss_freq: 0.010397
[13:31:37.156] iteration 8952: loss: 0.094324, loss_s1: 0.044465, loss_fp: 0.001324, loss_freq: 0.050166
[13:31:37.777] iteration 8953: loss: 0.138735, loss_s1: 0.024886, loss_fp: 0.004037, loss_freq: 0.012716
[13:31:38.400] iteration 8954: loss: 0.056211, loss_s1: 0.012843, loss_fp: 0.004116, loss_freq: 0.008855
[13:31:39.019] iteration 8955: loss: 0.049681, loss_s1: 0.024241, loss_fp: 0.002589, loss_freq: 0.014248
[13:31:39.640] iteration 8956: loss: 0.128645, loss_s1: 0.088452, loss_fp: 0.008866, loss_freq: 0.043932
[13:31:40.262] iteration 8957: loss: 0.092313, loss_s1: 0.024805, loss_fp: 0.001010, loss_freq: 0.020150
[13:31:40.882] iteration 8958: loss: 0.102398, loss_s1: 0.053097, loss_fp: 0.005082, loss_freq: 0.058357
[13:31:41.502] iteration 8959: loss: 0.072236, loss_s1: 0.046592, loss_fp: 0.003120, loss_freq: 0.015553
[13:31:42.122] iteration 8960: loss: 0.087344, loss_s1: 0.044063, loss_fp: 0.003766, loss_freq: 0.047044
[13:31:42.749] iteration 8961: loss: 0.053087, loss_s1: 0.016239, loss_fp: 0.000963, loss_freq: 0.013213
[13:31:43.373] iteration 8962: loss: 0.102536, loss_s1: 0.054427, loss_fp: 0.000940, loss_freq: 0.023766
[13:31:44.002] iteration 8963: loss: 0.152588, loss_s1: 0.065048, loss_fp: 0.003471, loss_freq: 0.110688
[13:31:44.631] iteration 8964: loss: 0.086907, loss_s1: 0.055485, loss_fp: 0.003842, loss_freq: 0.045589
[13:31:45.251] iteration 8965: loss: 0.155854, loss_s1: 0.071066, loss_fp: 0.001705, loss_freq: 0.045287
[13:31:45.873] iteration 8966: loss: 0.089887, loss_s1: 0.042601, loss_fp: 0.003017, loss_freq: 0.050154
[13:31:46.495] iteration 8967: loss: 0.117668, loss_s1: 0.109129, loss_fp: 0.005726, loss_freq: 0.033019
[13:31:47.118] iteration 8968: loss: 0.054789, loss_s1: 0.017150, loss_fp: 0.001211, loss_freq: 0.016431
[13:31:47.738] iteration 8969: loss: 0.072808, loss_s1: 0.036026, loss_fp: 0.004423, loss_freq: 0.018136
[13:31:48.360] iteration 8970: loss: 0.053068, loss_s1: 0.017126, loss_fp: 0.004077, loss_freq: 0.018354
[13:31:48.981] iteration 8971: loss: 0.129441, loss_s1: 0.041631, loss_fp: 0.003102, loss_freq: 0.018128
[13:31:49.604] iteration 8972: loss: 0.048171, loss_s1: 0.011494, loss_fp: 0.002172, loss_freq: 0.016005
[13:31:50.230] iteration 8973: loss: 0.172182, loss_s1: 0.129162, loss_fp: 0.002786, loss_freq: 0.145108
[13:31:50.856] iteration 8974: loss: 0.102432, loss_s1: 0.071622, loss_fp: 0.011010, loss_freq: 0.057989
[13:31:51.475] iteration 8975: loss: 0.098257, loss_s1: 0.040933, loss_fp: 0.002675, loss_freq: 0.031300
[13:31:52.102] iteration 8976: loss: 0.092772, loss_s1: 0.041163, loss_fp: 0.001490, loss_freq: 0.089965
[13:31:52.725] iteration 8977: loss: 0.103537, loss_s1: 0.059910, loss_fp: 0.002385, loss_freq: 0.022276
[13:31:53.346] iteration 8978: loss: 0.083768, loss_s1: 0.033295, loss_fp: 0.001620, loss_freq: 0.071865
[13:31:53.968] iteration 8979: loss: 0.086957, loss_s1: 0.044868, loss_fp: 0.000867, loss_freq: 0.010508
[13:31:54.589] iteration 8980: loss: 0.093124, loss_s1: 0.065555, loss_fp: 0.002097, loss_freq: 0.042676
[13:31:55.248] iteration 8981: loss: 0.138934, loss_s1: 0.044695, loss_fp: 0.001621, loss_freq: 0.062818
[13:31:55.884] iteration 8982: loss: 0.061943, loss_s1: 0.045296, loss_fp: 0.002415, loss_freq: 0.019607
[13:31:56.505] iteration 8983: loss: 0.070169, loss_s1: 0.021247, loss_fp: 0.000606, loss_freq: 0.044976
[13:31:57.123] iteration 8984: loss: 0.131660, loss_s1: 0.082938, loss_fp: 0.001328, loss_freq: 0.036646
[13:31:57.746] iteration 8985: loss: 0.092196, loss_s1: 0.067570, loss_fp: 0.000942, loss_freq: 0.069363
[13:31:58.369] iteration 8986: loss: 0.082634, loss_s1: 0.029393, loss_fp: 0.005771, loss_freq: 0.048463
[13:31:58.999] iteration 8987: loss: 0.082521, loss_s1: 0.044053, loss_fp: 0.003752, loss_freq: 0.054509
[13:31:59.629] iteration 8988: loss: 0.146388, loss_s1: 0.069403, loss_fp: 0.003217, loss_freq: 0.017155
[13:32:00.261] iteration 8989: loss: 0.055626, loss_s1: 0.013425, loss_fp: 0.000444, loss_freq: 0.002720
[13:32:00.883] iteration 8990: loss: 0.061765, loss_s1: 0.017915, loss_fp: 0.001587, loss_freq: 0.025049
[13:32:01.503] iteration 8991: loss: 0.079528, loss_s1: 0.043982, loss_fp: 0.011587, loss_freq: 0.059025
[13:32:02.144] iteration 8992: loss: 0.169085, loss_s1: 0.107418, loss_fp: 0.002870, loss_freq: 0.038112
[13:32:02.767] iteration 8993: loss: 0.072067, loss_s1: 0.051584, loss_fp: 0.000661, loss_freq: 0.021557
[13:32:03.385] iteration 8994: loss: 0.059063, loss_s1: 0.019670, loss_fp: 0.000457, loss_freq: 0.024229
[13:32:04.011] iteration 8995: loss: 0.158529, loss_s1: 0.097225, loss_fp: 0.007951, loss_freq: 0.033464
[13:32:04.633] iteration 8996: loss: 0.056730, loss_s1: 0.016283, loss_fp: 0.002529, loss_freq: 0.009602
[13:32:05.259] iteration 8997: loss: 0.090655, loss_s1: 0.063570, loss_fp: 0.001737, loss_freq: 0.018818
[13:32:05.905] iteration 8998: loss: 0.114460, loss_s1: 0.037259, loss_fp: 0.004596, loss_freq: 0.028608
[13:32:06.527] iteration 8999: loss: 0.117618, loss_s1: 0.068071, loss_fp: 0.002212, loss_freq: 0.055141
[13:32:07.155] iteration 9000: loss: 0.142622, loss_s1: 0.084501, loss_fp: 0.005116, loss_freq: 0.061905
[13:32:10.612] iteration 9000 : mean_dice : 0.735699
[13:32:11.308] iteration 9001: loss: 0.118692, loss_s1: 0.065792, loss_fp: 0.000465, loss_freq: 0.046084
[13:32:11.965] iteration 9002: loss: 0.094712, loss_s1: 0.065935, loss_fp: 0.003601, loss_freq: 0.027359
[13:32:12.626] iteration 9003: loss: 0.088768, loss_s1: 0.073677, loss_fp: 0.013543, loss_freq: 0.010521
[13:32:13.286] iteration 9004: loss: 0.058639, loss_s1: 0.017939, loss_fp: 0.006980, loss_freq: 0.031100
[13:32:13.940] iteration 9005: loss: 0.065832, loss_s1: 0.039453, loss_fp: 0.000848, loss_freq: 0.020669
[13:32:14.610] iteration 9006: loss: 0.097287, loss_s1: 0.022702, loss_fp: 0.001764, loss_freq: 0.031600
[13:32:15.265] iteration 9007: loss: 0.100141, loss_s1: 0.057082, loss_fp: 0.000808, loss_freq: 0.036775
[13:32:15.917] iteration 9008: loss: 0.114005, loss_s1: 0.085858, loss_fp: 0.001962, loss_freq: 0.039587
[13:32:16.543] iteration 9009: loss: 0.069979, loss_s1: 0.042733, loss_fp: 0.000839, loss_freq: 0.034240
[13:32:17.471] iteration 9010: loss: 0.063579, loss_s1: 0.021713, loss_fp: 0.018340, loss_freq: 0.013015
[13:32:18.094] iteration 9011: loss: 0.103783, loss_s1: 0.095206, loss_fp: 0.002884, loss_freq: 0.032367
[13:32:18.719] iteration 9012: loss: 0.060098, loss_s1: 0.023027, loss_fp: 0.003144, loss_freq: 0.033331
[13:32:19.350] iteration 9013: loss: 0.074973, loss_s1: 0.040905, loss_fp: 0.001347, loss_freq: 0.020963
[13:32:19.974] iteration 9014: loss: 0.121714, loss_s1: 0.126224, loss_fp: 0.000758, loss_freq: 0.036330
[13:32:20.595] iteration 9015: loss: 0.084796, loss_s1: 0.009019, loss_fp: 0.000950, loss_freq: 0.011200
[13:32:21.213] iteration 9016: loss: 0.056066, loss_s1: 0.034064, loss_fp: 0.004275, loss_freq: 0.024302
[13:32:21.836] iteration 9017: loss: 0.166208, loss_s1: 0.108845, loss_fp: 0.017773, loss_freq: 0.026152
[13:32:22.470] iteration 9018: loss: 0.096195, loss_s1: 0.038209, loss_fp: 0.005887, loss_freq: 0.069090
[13:32:23.105] iteration 9019: loss: 0.087454, loss_s1: 0.026640, loss_fp: 0.000777, loss_freq: 0.011101
[13:32:23.724] iteration 9020: loss: 0.077941, loss_s1: 0.036099, loss_fp: 0.013658, loss_freq: 0.049127
[13:32:24.378] iteration 9021: loss: 0.067617, loss_s1: 0.024707, loss_fp: 0.004580, loss_freq: 0.028134
[13:32:25.037] iteration 9022: loss: 0.103398, loss_s1: 0.103306, loss_fp: 0.005155, loss_freq: 0.011683
[13:32:25.685] iteration 9023: loss: 0.069811, loss_s1: 0.032915, loss_fp: 0.001081, loss_freq: 0.020004
[13:32:26.306] iteration 9024: loss: 0.075992, loss_s1: 0.055332, loss_fp: 0.001862, loss_freq: 0.028199
[13:32:26.928] iteration 9025: loss: 0.061178, loss_s1: 0.019955, loss_fp: 0.001119, loss_freq: 0.018203
[13:32:27.552] iteration 9026: loss: 0.176762, loss_s1: 0.047026, loss_fp: 0.001292, loss_freq: 0.026838
[13:32:28.202] iteration 9027: loss: 0.150453, loss_s1: 0.121480, loss_fp: 0.001244, loss_freq: 0.018115
[13:32:28.861] iteration 9028: loss: 0.066297, loss_s1: 0.037899, loss_fp: 0.001672, loss_freq: 0.023103
[13:32:29.513] iteration 9029: loss: 0.057715, loss_s1: 0.013356, loss_fp: 0.001907, loss_freq: 0.010360
[13:32:30.164] iteration 9030: loss: 0.184392, loss_s1: 0.045448, loss_fp: 0.002234, loss_freq: 0.048554
[13:32:30.791] iteration 9031: loss: 0.059663, loss_s1: 0.018628, loss_fp: 0.000823, loss_freq: 0.030536
[13:32:31.413] iteration 9032: loss: 0.068140, loss_s1: 0.047708, loss_fp: 0.016154, loss_freq: 0.010813
[13:32:32.045] iteration 9033: loss: 0.063545, loss_s1: 0.017111, loss_fp: 0.002341, loss_freq: 0.006288
[13:32:32.714] iteration 9034: loss: 0.064939, loss_s1: 0.044815, loss_fp: 0.004092, loss_freq: 0.019317
[13:32:33.336] iteration 9035: loss: 0.140855, loss_s1: 0.083829, loss_fp: 0.005667, loss_freq: 0.055878
[13:32:33.957] iteration 9036: loss: 0.167867, loss_s1: 0.073697, loss_fp: 0.001215, loss_freq: 0.064313
[13:32:34.584] iteration 9037: loss: 0.062096, loss_s1: 0.051991, loss_fp: 0.001018, loss_freq: 0.012260
[13:32:35.209] iteration 9038: loss: 0.113866, loss_s1: 0.067546, loss_fp: 0.001709, loss_freq: 0.063744
[13:32:35.840] iteration 9039: loss: 0.123898, loss_s1: 0.037111, loss_fp: 0.001519, loss_freq: 0.011572
[13:32:36.461] iteration 9040: loss: 0.055464, loss_s1: 0.045526, loss_fp: 0.003534, loss_freq: 0.008384
[13:32:37.089] iteration 9041: loss: 0.058198, loss_s1: 0.020020, loss_fp: 0.001712, loss_freq: 0.012822
[13:32:37.713] iteration 9042: loss: 0.077031, loss_s1: 0.046363, loss_fp: 0.000926, loss_freq: 0.014907
[13:32:38.336] iteration 9043: loss: 0.100714, loss_s1: 0.059837, loss_fp: 0.003551, loss_freq: 0.060282
[13:32:38.959] iteration 9044: loss: 0.109014, loss_s1: 0.015621, loss_fp: 0.001698, loss_freq: 0.029465
[13:32:39.581] iteration 9045: loss: 0.101984, loss_s1: 0.089572, loss_fp: 0.003038, loss_freq: 0.031828
[13:32:40.202] iteration 9046: loss: 0.076452, loss_s1: 0.030591, loss_fp: 0.003749, loss_freq: 0.019073
[13:32:40.825] iteration 9047: loss: 0.092365, loss_s1: 0.062776, loss_fp: 0.003376, loss_freq: 0.023539
[13:32:41.443] iteration 9048: loss: 0.107035, loss_s1: 0.045384, loss_fp: 0.007643, loss_freq: 0.055089
[13:32:42.065] iteration 9049: loss: 0.087205, loss_s1: 0.041743, loss_fp: 0.004384, loss_freq: 0.013099
[13:32:42.694] iteration 9050: loss: 0.096590, loss_s1: 0.022881, loss_fp: 0.001192, loss_freq: 0.012160
[13:32:43.322] iteration 9051: loss: 0.058689, loss_s1: 0.045528, loss_fp: 0.004464, loss_freq: 0.017937
[13:32:43.949] iteration 9052: loss: 0.090761, loss_s1: 0.056932, loss_fp: 0.000920, loss_freq: 0.017241
[13:32:44.570] iteration 9053: loss: 0.085213, loss_s1: 0.037576, loss_fp: 0.003025, loss_freq: 0.068418
[13:32:45.198] iteration 9054: loss: 0.072304, loss_s1: 0.014913, loss_fp: 0.002144, loss_freq: 0.016466
[13:32:45.823] iteration 9055: loss: 0.096539, loss_s1: 0.038652, loss_fp: 0.000789, loss_freq: 0.024478
[13:32:46.447] iteration 9056: loss: 0.085622, loss_s1: 0.036363, loss_fp: 0.013171, loss_freq: 0.039654
[13:32:47.069] iteration 9057: loss: 0.085049, loss_s1: 0.048967, loss_fp: 0.006165, loss_freq: 0.033814
[13:32:47.701] iteration 9058: loss: 0.058133, loss_s1: 0.048227, loss_fp: 0.006023, loss_freq: 0.016282
[13:32:48.319] iteration 9059: loss: 0.044457, loss_s1: 0.022267, loss_fp: 0.002133, loss_freq: 0.013982
[13:32:48.981] iteration 9060: loss: 0.071110, loss_s1: 0.040290, loss_fp: 0.003532, loss_freq: 0.014417
[13:32:49.639] iteration 9061: loss: 0.141661, loss_s1: 0.016938, loss_fp: 0.002782, loss_freq: 0.018696
[13:32:50.282] iteration 9062: loss: 0.040472, loss_s1: 0.015661, loss_fp: 0.001210, loss_freq: 0.007209
[13:32:50.958] iteration 9063: loss: 0.073551, loss_s1: 0.029901, loss_fp: 0.001289, loss_freq: 0.004277
[13:32:51.584] iteration 9064: loss: 0.054034, loss_s1: 0.022451, loss_fp: 0.000944, loss_freq: 0.016455
[13:32:52.206] iteration 9065: loss: 0.104713, loss_s1: 0.045155, loss_fp: 0.001534, loss_freq: 0.015983
[13:32:52.877] iteration 9066: loss: 0.070541, loss_s1: 0.023086, loss_fp: 0.003471, loss_freq: 0.032868
[13:32:53.517] iteration 9067: loss: 0.055570, loss_s1: 0.028997, loss_fp: 0.000470, loss_freq: 0.016789
[13:32:54.137] iteration 9068: loss: 0.129913, loss_s1: 0.070129, loss_fp: 0.002043, loss_freq: 0.064081
[13:32:54.761] iteration 9069: loss: 0.085928, loss_s1: 0.049138, loss_fp: 0.008780, loss_freq: 0.024816
[13:32:55.379] iteration 9070: loss: 0.119739, loss_s1: 0.039571, loss_fp: 0.001722, loss_freq: 0.028011
[13:32:55.998] iteration 9071: loss: 0.092043, loss_s1: 0.104882, loss_fp: 0.003940, loss_freq: 0.009032
[13:32:56.620] iteration 9072: loss: 0.096325, loss_s1: 0.072482, loss_fp: 0.001296, loss_freq: 0.040572
[13:32:57.244] iteration 9073: loss: 0.104584, loss_s1: 0.030136, loss_fp: 0.003753, loss_freq: 0.029996
[13:32:57.869] iteration 9074: loss: 0.065445, loss_s1: 0.035360, loss_fp: 0.001404, loss_freq: 0.009485
[13:32:58.516] iteration 9075: loss: 0.112857, loss_s1: 0.069762, loss_fp: 0.013104, loss_freq: 0.029928
[13:32:59.154] iteration 9076: loss: 0.095403, loss_s1: 0.035311, loss_fp: 0.009308, loss_freq: 0.055925
[13:32:59.778] iteration 9077: loss: 0.060247, loss_s1: 0.039589, loss_fp: 0.001225, loss_freq: 0.016021
[13:33:00.400] iteration 9078: loss: 0.050939, loss_s1: 0.029412, loss_fp: 0.002316, loss_freq: 0.010628
[13:33:01.023] iteration 9079: loss: 0.093858, loss_s1: 0.041233, loss_fp: 0.004321, loss_freq: 0.005264
[13:33:01.651] iteration 9080: loss: 0.089259, loss_s1: 0.047001, loss_fp: 0.001746, loss_freq: 0.022682
[13:33:02.276] iteration 9081: loss: 0.075886, loss_s1: 0.033454, loss_fp: 0.003336, loss_freq: 0.051606
[13:33:02.903] iteration 9082: loss: 0.059815, loss_s1: 0.017416, loss_fp: 0.001091, loss_freq: 0.045837
[13:33:03.582] iteration 9083: loss: 0.129927, loss_s1: 0.068207, loss_fp: 0.003223, loss_freq: 0.095361
[13:33:04.239] iteration 9084: loss: 0.086567, loss_s1: 0.050965, loss_fp: 0.001574, loss_freq: 0.062643
[13:33:04.896] iteration 9085: loss: 0.089641, loss_s1: 0.058471, loss_fp: 0.001701, loss_freq: 0.009963
[13:33:05.558] iteration 9086: loss: 0.074864, loss_s1: 0.054754, loss_fp: 0.007068, loss_freq: 0.042102
[13:33:06.213] iteration 9087: loss: 0.085878, loss_s1: 0.035986, loss_fp: 0.000888, loss_freq: 0.025140
[13:33:06.876] iteration 9088: loss: 0.092183, loss_s1: 0.063136, loss_fp: 0.008947, loss_freq: 0.051032
[13:33:07.502] iteration 9089: loss: 0.152260, loss_s1: 0.046204, loss_fp: 0.002276, loss_freq: 0.034529
[13:33:08.124] iteration 9090: loss: 0.091469, loss_s1: 0.031376, loss_fp: 0.001394, loss_freq: 0.040266
[13:33:08.768] iteration 9091: loss: 0.095764, loss_s1: 0.041902, loss_fp: 0.004148, loss_freq: 0.036402
[13:33:09.387] iteration 9092: loss: 0.089641, loss_s1: 0.035356, loss_fp: 0.002200, loss_freq: 0.028202
[13:33:10.007] iteration 9093: loss: 0.053762, loss_s1: 0.030363, loss_fp: 0.003738, loss_freq: 0.019859
[13:33:10.628] iteration 9094: loss: 0.088660, loss_s1: 0.064202, loss_fp: 0.000846, loss_freq: 0.037478
[13:33:11.270] iteration 9095: loss: 0.099735, loss_s1: 0.030595, loss_fp: 0.001779, loss_freq: 0.038933
[13:33:11.899] iteration 9096: loss: 0.109899, loss_s1: 0.028467, loss_fp: 0.005712, loss_freq: 0.016821
[13:33:12.523] iteration 9097: loss: 0.117950, loss_s1: 0.046165, loss_fp: 0.000464, loss_freq: 0.010581
[13:33:13.152] iteration 9098: loss: 0.067988, loss_s1: 0.040986, loss_fp: 0.001618, loss_freq: 0.025706
[13:33:13.776] iteration 9099: loss: 0.079880, loss_s1: 0.051626, loss_fp: 0.003837, loss_freq: 0.036381
[13:33:14.397] iteration 9100: loss: 0.063396, loss_s1: 0.020076, loss_fp: 0.000776, loss_freq: 0.010225
[13:33:15.019] iteration 9101: loss: 0.079784, loss_s1: 0.054817, loss_fp: 0.001363, loss_freq: 0.051918
[13:33:15.646] iteration 9102: loss: 0.078997, loss_s1: 0.053322, loss_fp: 0.000674, loss_freq: 0.013795
[13:33:16.262] iteration 9103: loss: 0.087313, loss_s1: 0.042639, loss_fp: 0.009627, loss_freq: 0.038547
[13:33:16.888] iteration 9104: loss: 0.062372, loss_s1: 0.038645, loss_fp: 0.000888, loss_freq: 0.008088
[13:33:17.503] iteration 9105: loss: 0.056886, loss_s1: 0.020217, loss_fp: 0.000617, loss_freq: 0.018777
[13:33:18.130] iteration 9106: loss: 0.130927, loss_s1: 0.130499, loss_fp: 0.003962, loss_freq: 0.051138
[13:33:18.754] iteration 9107: loss: 0.055110, loss_s1: 0.019817, loss_fp: 0.006397, loss_freq: 0.021197
[13:33:19.368] iteration 9108: loss: 0.108328, loss_s1: 0.052924, loss_fp: 0.007115, loss_freq: 0.063691
[13:33:19.986] iteration 9109: loss: 0.103433, loss_s1: 0.063564, loss_fp: 0.001208, loss_freq: 0.038775
[13:33:20.608] iteration 9110: loss: 0.099494, loss_s1: 0.045052, loss_fp: 0.001783, loss_freq: 0.018993
[13:33:21.218] iteration 9111: loss: 0.111713, loss_s1: 0.091916, loss_fp: 0.002372, loss_freq: 0.047258
[13:33:21.884] iteration 9112: loss: 0.094779, loss_s1: 0.085590, loss_fp: 0.006160, loss_freq: 0.014552
[13:33:22.542] iteration 9113: loss: 0.087493, loss_s1: 0.045006, loss_fp: 0.007934, loss_freq: 0.045696
[13:33:23.182] iteration 9114: loss: 0.079385, loss_s1: 0.048017, loss_fp: 0.005232, loss_freq: 0.030332
[13:33:23.826] iteration 9115: loss: 0.088506, loss_s1: 0.046625, loss_fp: 0.001924, loss_freq: 0.034604
[13:33:24.607] iteration 9116: loss: 0.125609, loss_s1: 0.102964, loss_fp: 0.002130, loss_freq: 0.076882
[13:33:25.368] iteration 9117: loss: 0.088655, loss_s1: 0.090590, loss_fp: 0.002396, loss_freq: 0.030748
[13:33:26.011] iteration 9118: loss: 0.067331, loss_s1: 0.035292, loss_fp: 0.004870, loss_freq: 0.013250
[13:33:26.634] iteration 9119: loss: 0.065972, loss_s1: 0.046329, loss_fp: 0.001999, loss_freq: 0.014398
[13:33:27.255] iteration 9120: loss: 0.074631, loss_s1: 0.034546, loss_fp: 0.012888, loss_freq: 0.005598
[13:33:27.879] iteration 9121: loss: 0.061973, loss_s1: 0.057744, loss_fp: 0.002513, loss_freq: 0.022767
[13:33:28.505] iteration 9122: loss: 0.084507, loss_s1: 0.028651, loss_fp: 0.002798, loss_freq: 0.025014
[13:33:29.130] iteration 9123: loss: 0.111265, loss_s1: 0.074598, loss_fp: 0.020733, loss_freq: 0.067804
[13:33:29.757] iteration 9124: loss: 0.104219, loss_s1: 0.017796, loss_fp: 0.001949, loss_freq: 0.045602
[13:33:30.379] iteration 9125: loss: 0.089416, loss_s1: 0.052181, loss_fp: 0.003766, loss_freq: 0.017819
[13:33:31.003] iteration 9126: loss: 0.146294, loss_s1: 0.085204, loss_fp: 0.000259, loss_freq: 0.035918
[13:33:31.635] iteration 9127: loss: 0.135181, loss_s1: 0.114666, loss_fp: 0.005146, loss_freq: 0.028569
[13:33:32.266] iteration 9128: loss: 0.069996, loss_s1: 0.051189, loss_fp: 0.004518, loss_freq: 0.021417
[13:33:32.888] iteration 9129: loss: 0.080239, loss_s1: 0.032034, loss_fp: 0.005148, loss_freq: 0.049411
[13:33:33.514] iteration 9130: loss: 0.126140, loss_s1: 0.090655, loss_fp: 0.002572, loss_freq: 0.099094
[13:33:34.141] iteration 9131: loss: 0.095659, loss_s1: 0.020144, loss_fp: 0.002089, loss_freq: 0.050257
[13:33:34.769] iteration 9132: loss: 0.038888, loss_s1: 0.009902, loss_fp: 0.005263, loss_freq: 0.009476
[13:33:35.390] iteration 9133: loss: 0.062195, loss_s1: 0.035830, loss_fp: 0.002846, loss_freq: 0.036646
[13:33:36.016] iteration 9134: loss: 0.080754, loss_s1: 0.059739, loss_fp: 0.002077, loss_freq: 0.036904
[13:33:36.640] iteration 9135: loss: 0.112465, loss_s1: 0.045866, loss_fp: 0.003847, loss_freq: 0.030505
[13:33:37.269] iteration 9136: loss: 0.090871, loss_s1: 0.074643, loss_fp: 0.008529, loss_freq: 0.026438
[13:33:37.891] iteration 9137: loss: 0.075448, loss_s1: 0.038230, loss_fp: 0.001198, loss_freq: 0.053158
[13:33:38.512] iteration 9138: loss: 0.106354, loss_s1: 0.080290, loss_fp: 0.008255, loss_freq: 0.016176
[13:33:39.133] iteration 9139: loss: 0.045558, loss_s1: 0.025438, loss_fp: 0.001143, loss_freq: 0.007051
[13:33:39.757] iteration 9140: loss: 0.113578, loss_s1: 0.046408, loss_fp: 0.018571, loss_freq: 0.023707
[13:33:40.383] iteration 9141: loss: 0.123250, loss_s1: 0.068353, loss_fp: 0.003626, loss_freq: 0.040080
[13:33:41.006] iteration 9142: loss: 0.084673, loss_s1: 0.053487, loss_fp: 0.001812, loss_freq: 0.026541
[13:33:41.630] iteration 9143: loss: 0.114388, loss_s1: 0.092400, loss_fp: 0.005822, loss_freq: 0.052104
[13:33:42.253] iteration 9144: loss: 0.081234, loss_s1: 0.024951, loss_fp: 0.002926, loss_freq: 0.022974
[13:33:42.879] iteration 9145: loss: 0.094064, loss_s1: 0.047641, loss_fp: 0.011586, loss_freq: 0.036889
[13:33:43.505] iteration 9146: loss: 0.095184, loss_s1: 0.077906, loss_fp: 0.004115, loss_freq: 0.005029
[13:33:44.128] iteration 9147: loss: 0.095718, loss_s1: 0.041053, loss_fp: 0.002597, loss_freq: 0.015728
[13:33:44.750] iteration 9148: loss: 0.053358, loss_s1: 0.019570, loss_fp: 0.003433, loss_freq: 0.025843
[13:33:45.383] iteration 9149: loss: 0.114738, loss_s1: 0.035517, loss_fp: 0.001900, loss_freq: 0.010960
[13:33:46.012] iteration 9150: loss: 0.087116, loss_s1: 0.071822, loss_fp: 0.007051, loss_freq: 0.043777
[13:33:46.632] iteration 9151: loss: 0.144928, loss_s1: 0.103819, loss_fp: 0.021019, loss_freq: 0.042039
[13:33:47.250] iteration 9152: loss: 0.064154, loss_s1: 0.045839, loss_fp: 0.001771, loss_freq: 0.023007
[13:33:48.268] iteration 9153: loss: 0.054035, loss_s1: 0.026278, loss_fp: 0.002793, loss_freq: 0.005042
[13:33:48.938] iteration 9154: loss: 0.110508, loss_s1: 0.078961, loss_fp: 0.004144, loss_freq: 0.022915
[13:33:49.603] iteration 9155: loss: 0.084284, loss_s1: 0.057655, loss_fp: 0.002159, loss_freq: 0.046391
[13:33:50.239] iteration 9156: loss: 0.132369, loss_s1: 0.061776, loss_fp: 0.000810, loss_freq: 0.014401
[13:33:50.861] iteration 9157: loss: 0.083471, loss_s1: 0.045180, loss_fp: 0.002990, loss_freq: 0.052061
[13:33:51.491] iteration 9158: loss: 0.084524, loss_s1: 0.037672, loss_fp: 0.000989, loss_freq: 0.005191
[13:33:52.119] iteration 9159: loss: 0.059308, loss_s1: 0.038840, loss_fp: 0.001080, loss_freq: 0.035268
[13:33:52.749] iteration 9160: loss: 0.133760, loss_s1: 0.087686, loss_fp: 0.002906, loss_freq: 0.021549
[13:33:53.399] iteration 9161: loss: 0.058512, loss_s1: 0.018801, loss_fp: 0.001101, loss_freq: 0.004830
[13:33:54.024] iteration 9162: loss: 0.100060, loss_s1: 0.024456, loss_fp: 0.001848, loss_freq: 0.019840
[13:33:54.682] iteration 9163: loss: 0.095424, loss_s1: 0.068407, loss_fp: 0.005384, loss_freq: 0.035731
[13:33:55.335] iteration 9164: loss: 0.104557, loss_s1: 0.098868, loss_fp: 0.000833, loss_freq: 0.033404
[13:33:55.959] iteration 9165: loss: 0.057601, loss_s1: 0.041021, loss_fp: 0.000660, loss_freq: 0.010084
[13:33:56.581] iteration 9166: loss: 0.053155, loss_s1: 0.017185, loss_fp: 0.002080, loss_freq: 0.034865
[13:33:57.203] iteration 9167: loss: 0.102603, loss_s1: 0.096777, loss_fp: 0.001702, loss_freq: 0.043135
[13:33:57.829] iteration 9168: loss: 0.051871, loss_s1: 0.017691, loss_fp: 0.001683, loss_freq: 0.016478
[13:33:58.451] iteration 9169: loss: 0.146071, loss_s1: 0.026422, loss_fp: 0.004528, loss_freq: 0.024600
[13:33:59.100] iteration 9170: loss: 0.114749, loss_s1: 0.030150, loss_fp: 0.001416, loss_freq: 0.030571
[13:33:59.758] iteration 9171: loss: 0.093727, loss_s1: 0.045147, loss_fp: 0.004795, loss_freq: 0.036532
[13:34:00.421] iteration 9172: loss: 0.094876, loss_s1: 0.085884, loss_fp: 0.001632, loss_freq: 0.036260
[13:34:01.073] iteration 9173: loss: 0.115377, loss_s1: 0.033250, loss_fp: 0.000966, loss_freq: 0.094676
[13:34:01.729] iteration 9174: loss: 0.070114, loss_s1: 0.056272, loss_fp: 0.002157, loss_freq: 0.022512
[13:34:02.392] iteration 9175: loss: 0.075231, loss_s1: 0.045364, loss_fp: 0.000514, loss_freq: 0.031654
[13:34:03.051] iteration 9176: loss: 0.082476, loss_s1: 0.017454, loss_fp: 0.001818, loss_freq: 0.042019
[13:34:03.708] iteration 9177: loss: 0.104567, loss_s1: 0.054222, loss_fp: 0.004499, loss_freq: 0.086408
[13:34:04.378] iteration 9178: loss: 0.087732, loss_s1: 0.039136, loss_fp: 0.003073, loss_freq: 0.058274
[13:34:05.031] iteration 9179: loss: 0.117864, loss_s1: 0.058724, loss_fp: 0.003023, loss_freq: 0.050039
[13:34:05.653] iteration 9180: loss: 0.072695, loss_s1: 0.027249, loss_fp: 0.001262, loss_freq: 0.014222
[13:34:06.281] iteration 9181: loss: 0.128180, loss_s1: 0.063804, loss_fp: 0.001834, loss_freq: 0.072003
[13:34:06.938] iteration 9182: loss: 0.189295, loss_s1: 0.047424, loss_fp: 0.001986, loss_freq: 0.009519
[13:34:07.565] iteration 9183: loss: 0.068857, loss_s1: 0.032203, loss_fp: 0.005983, loss_freq: 0.011706
[13:34:08.191] iteration 9184: loss: 0.065842, loss_s1: 0.032939, loss_fp: 0.004084, loss_freq: 0.026276
[13:34:08.820] iteration 9185: loss: 0.072585, loss_s1: 0.038665, loss_fp: 0.004766, loss_freq: 0.014163
[13:34:09.447] iteration 9186: loss: 0.117830, loss_s1: 0.065707, loss_fp: 0.003635, loss_freq: 0.084583
[13:34:10.070] iteration 9187: loss: 0.124582, loss_s1: 0.066700, loss_fp: 0.009600, loss_freq: 0.035331
[13:34:10.696] iteration 9188: loss: 0.098943, loss_s1: 0.058800, loss_fp: 0.002923, loss_freq: 0.033773
[13:34:11.321] iteration 9189: loss: 0.101980, loss_s1: 0.108123, loss_fp: 0.000962, loss_freq: 0.031065
[13:34:11.944] iteration 9190: loss: 0.083596, loss_s1: 0.083883, loss_fp: 0.003092, loss_freq: 0.029366
[13:34:12.573] iteration 9191: loss: 0.080319, loss_s1: 0.023787, loss_fp: 0.002255, loss_freq: 0.028943
[13:34:13.199] iteration 9192: loss: 0.059206, loss_s1: 0.054639, loss_fp: 0.002281, loss_freq: 0.007580
[13:34:13.827] iteration 9193: loss: 0.097280, loss_s1: 0.052039, loss_fp: 0.003638, loss_freq: 0.016025
[13:34:14.449] iteration 9194: loss: 0.064596, loss_s1: 0.038625, loss_fp: 0.003434, loss_freq: 0.036994
[13:34:15.072] iteration 9195: loss: 0.079413, loss_s1: 0.031109, loss_fp: 0.000669, loss_freq: 0.034889
[13:34:15.696] iteration 9196: loss: 0.063729, loss_s1: 0.035416, loss_fp: 0.006878, loss_freq: 0.031523
[13:34:16.324] iteration 9197: loss: 0.124445, loss_s1: 0.075728, loss_fp: 0.001147, loss_freq: 0.014540
[13:34:16.950] iteration 9198: loss: 0.151078, loss_s1: 0.094875, loss_fp: 0.002572, loss_freq: 0.084838
[13:34:17.577] iteration 9199: loss: 0.066144, loss_s1: 0.020555, loss_fp: 0.001272, loss_freq: 0.030287
[13:34:18.196] iteration 9200: loss: 0.077662, loss_s1: 0.023479, loss_fp: 0.001256, loss_freq: 0.018913
[13:34:21.374] iteration 9200 : mean_dice : 0.742324
[13:34:22.027] iteration 9201: loss: 0.056708, loss_s1: 0.029927, loss_fp: 0.001860, loss_freq: 0.027546
[13:34:22.646] iteration 9202: loss: 0.044421, loss_s1: 0.020307, loss_fp: 0.003918, loss_freq: 0.014838
[13:34:23.270] iteration 9203: loss: 0.068587, loss_s1: 0.026479, loss_fp: 0.003922, loss_freq: 0.028408
[13:34:23.895] iteration 9204: loss: 0.096644, loss_s1: 0.041141, loss_fp: 0.002903, loss_freq: 0.038593
[13:34:24.517] iteration 9205: loss: 0.045177, loss_s1: 0.025314, loss_fp: 0.003255, loss_freq: 0.006911
[13:34:25.144] iteration 9206: loss: 0.056560, loss_s1: 0.031481, loss_fp: 0.001165, loss_freq: 0.022470
[13:34:25.782] iteration 9207: loss: 0.049420, loss_s1: 0.023592, loss_fp: 0.002409, loss_freq: 0.013188
[13:34:26.419] iteration 9208: loss: 0.074310, loss_s1: 0.021998, loss_fp: 0.000765, loss_freq: 0.011669
[13:34:27.057] iteration 9209: loss: 0.101160, loss_s1: 0.080851, loss_fp: 0.004803, loss_freq: 0.047355
[13:34:27.698] iteration 9210: loss: 0.065638, loss_s1: 0.041791, loss_fp: 0.000792, loss_freq: 0.026695
[13:34:28.338] iteration 9211: loss: 0.138013, loss_s1: 0.105176, loss_fp: 0.005284, loss_freq: 0.056282
[13:34:28.974] iteration 9212: loss: 0.076901, loss_s1: 0.037068, loss_fp: 0.004555, loss_freq: 0.031098
[13:34:29.601] iteration 9213: loss: 0.072796, loss_s1: 0.039812, loss_fp: 0.003095, loss_freq: 0.011220
[13:34:30.248] iteration 9214: loss: 0.112096, loss_s1: 0.091801, loss_fp: 0.009480, loss_freq: 0.036858
[13:34:30.875] iteration 9215: loss: 0.074199, loss_s1: 0.029027, loss_fp: 0.001142, loss_freq: 0.050681
[13:34:31.506] iteration 9216: loss: 0.070019, loss_s1: 0.031092, loss_fp: 0.002472, loss_freq: 0.023428
[13:34:32.124] iteration 9217: loss: 0.138171, loss_s1: 0.052275, loss_fp: 0.006152, loss_freq: 0.043181
[13:34:32.750] iteration 9218: loss: 0.078805, loss_s1: 0.036458, loss_fp: 0.000876, loss_freq: 0.041429
[13:34:33.371] iteration 9219: loss: 0.109705, loss_s1: 0.073559, loss_fp: 0.010816, loss_freq: 0.054196
[13:34:33.992] iteration 9220: loss: 0.085122, loss_s1: 0.025349, loss_fp: 0.005229, loss_freq: 0.025133
[13:34:34.612] iteration 9221: loss: 0.116524, loss_s1: 0.056275, loss_fp: 0.009366, loss_freq: 0.042627
[13:34:35.232] iteration 9222: loss: 0.102923, loss_s1: 0.022482, loss_fp: 0.002892, loss_freq: 0.007074
[13:34:35.852] iteration 9223: loss: 0.053659, loss_s1: 0.029144, loss_fp: 0.003080, loss_freq: 0.010165
[13:34:36.471] iteration 9224: loss: 0.080388, loss_s1: 0.010558, loss_fp: 0.003905, loss_freq: 0.067764
[13:34:37.094] iteration 9225: loss: 0.098530, loss_s1: 0.056049, loss_fp: 0.000704, loss_freq: 0.087709
[13:34:37.718] iteration 9226: loss: 0.126503, loss_s1: 0.120317, loss_fp: 0.006448, loss_freq: 0.041609
[13:34:38.342] iteration 9227: loss: 0.104341, loss_s1: 0.034295, loss_fp: 0.010595, loss_freq: 0.092333
[13:34:38.964] iteration 9228: loss: 0.095271, loss_s1: 0.067477, loss_fp: 0.003776, loss_freq: 0.013538
[13:34:39.587] iteration 9229: loss: 0.118923, loss_s1: 0.132330, loss_fp: 0.009799, loss_freq: 0.036336
[13:34:40.208] iteration 9230: loss: 0.096127, loss_s1: 0.081521, loss_fp: 0.001708, loss_freq: 0.014805
[13:34:40.825] iteration 9231: loss: 0.124982, loss_s1: 0.122530, loss_fp: 0.005042, loss_freq: 0.056788
[13:34:41.449] iteration 9232: loss: 0.146065, loss_s1: 0.072049, loss_fp: 0.000772, loss_freq: 0.066991
[13:34:42.071] iteration 9233: loss: 0.108415, loss_s1: 0.014467, loss_fp: 0.001983, loss_freq: 0.067214
[13:34:42.693] iteration 9234: loss: 0.098238, loss_s1: 0.081598, loss_fp: 0.004869, loss_freq: 0.040531
[13:34:43.316] iteration 9235: loss: 0.063160, loss_s1: 0.021968, loss_fp: 0.001466, loss_freq: 0.028021
[13:34:43.938] iteration 9236: loss: 0.051179, loss_s1: 0.023550, loss_fp: 0.000821, loss_freq: 0.029554
[13:34:44.563] iteration 9237: loss: 0.072890, loss_s1: 0.053981, loss_fp: 0.000702, loss_freq: 0.010190
[13:34:45.185] iteration 9238: loss: 0.105509, loss_s1: 0.083667, loss_fp: 0.001636, loss_freq: 0.064352
[13:34:45.810] iteration 9239: loss: 0.099351, loss_s1: 0.041264, loss_fp: 0.000774, loss_freq: 0.017638
[13:34:46.430] iteration 9240: loss: 0.085251, loss_s1: 0.053799, loss_fp: 0.001086, loss_freq: 0.021501
[13:34:47.052] iteration 9241: loss: 0.063605, loss_s1: 0.047201, loss_fp: 0.001800, loss_freq: 0.026815
[13:34:47.668] iteration 9242: loss: 0.097095, loss_s1: 0.092962, loss_fp: 0.003499, loss_freq: 0.026806
[13:34:48.292] iteration 9243: loss: 0.110560, loss_s1: 0.027089, loss_fp: 0.001943, loss_freq: 0.022150
[13:34:48.911] iteration 9244: loss: 0.085155, loss_s1: 0.061970, loss_fp: 0.001823, loss_freq: 0.053755
[13:34:49.533] iteration 9245: loss: 0.084450, loss_s1: 0.061245, loss_fp: 0.000669, loss_freq: 0.020739
[13:34:50.156] iteration 9246: loss: 0.091576, loss_s1: 0.073766, loss_fp: 0.001254, loss_freq: 0.025065
[13:34:50.812] iteration 9247: loss: 0.063789, loss_s1: 0.036934, loss_fp: 0.000708, loss_freq: 0.010603
[13:34:51.472] iteration 9248: loss: 0.072855, loss_s1: 0.033331, loss_fp: 0.001369, loss_freq: 0.028865
[13:34:52.126] iteration 9249: loss: 0.138314, loss_s1: 0.130217, loss_fp: 0.002336, loss_freq: 0.071029
[13:34:52.751] iteration 9250: loss: 0.056595, loss_s1: 0.031715, loss_fp: 0.002365, loss_freq: 0.013241
[13:34:53.379] iteration 9251: loss: 0.071197, loss_s1: 0.009169, loss_fp: 0.000578, loss_freq: 0.049329
[13:34:54.006] iteration 9252: loss: 0.086240, loss_s1: 0.055092, loss_fp: 0.004418, loss_freq: 0.024801
[13:34:54.626] iteration 9253: loss: 0.072383, loss_s1: 0.031101, loss_fp: 0.001419, loss_freq: 0.030152
[13:34:55.248] iteration 9254: loss: 0.065415, loss_s1: 0.018510, loss_fp: 0.008835, loss_freq: 0.032199
[13:34:55.870] iteration 9255: loss: 0.056172, loss_s1: 0.028139, loss_fp: 0.002838, loss_freq: 0.004045
[13:34:56.495] iteration 9256: loss: 0.147789, loss_s1: 0.162030, loss_fp: 0.004070, loss_freq: 0.031577
[13:34:57.123] iteration 9257: loss: 0.121960, loss_s1: 0.059017, loss_fp: 0.001804, loss_freq: 0.026248
[13:34:57.746] iteration 9258: loss: 0.091310, loss_s1: 0.038346, loss_fp: 0.005543, loss_freq: 0.061231
[13:34:58.372] iteration 9259: loss: 0.104643, loss_s1: 0.077472, loss_fp: 0.000780, loss_freq: 0.047202
[13:34:58.992] iteration 9260: loss: 0.082571, loss_s1: 0.046979, loss_fp: 0.011186, loss_freq: 0.037098
[13:34:59.616] iteration 9261: loss: 0.093901, loss_s1: 0.018376, loss_fp: 0.000549, loss_freq: 0.016199
[13:35:00.235] iteration 9262: loss: 0.096901, loss_s1: 0.123928, loss_fp: 0.001359, loss_freq: 0.016074
[13:35:00.859] iteration 9263: loss: 0.086790, loss_s1: 0.049615, loss_fp: 0.000487, loss_freq: 0.008759
[13:35:01.489] iteration 9264: loss: 0.068713, loss_s1: 0.033368, loss_fp: 0.002351, loss_freq: 0.048017
[13:35:02.109] iteration 9265: loss: 0.065887, loss_s1: 0.031177, loss_fp: 0.002632, loss_freq: 0.012956
[13:35:02.735] iteration 9266: loss: 0.094650, loss_s1: 0.072925, loss_fp: 0.010506, loss_freq: 0.023847
[13:35:03.399] iteration 9267: loss: 0.150422, loss_s1: 0.058929, loss_fp: 0.002164, loss_freq: 0.032526
[13:35:04.087] iteration 9268: loss: 0.071213, loss_s1: 0.064482, loss_fp: 0.003210, loss_freq: 0.017163
[13:35:04.721] iteration 9269: loss: 0.093582, loss_s1: 0.029023, loss_fp: 0.002196, loss_freq: 0.045954
[13:35:05.341] iteration 9270: loss: 0.091943, loss_s1: 0.063147, loss_fp: 0.016232, loss_freq: 0.033685
[13:35:05.971] iteration 9271: loss: 0.079305, loss_s1: 0.067989, loss_fp: 0.007513, loss_freq: 0.028749
[13:35:06.594] iteration 9272: loss: 0.063409, loss_s1: 0.049039, loss_fp: 0.003882, loss_freq: 0.016262
[13:35:07.245] iteration 9273: loss: 0.109596, loss_s1: 0.053494, loss_fp: 0.004549, loss_freq: 0.089574
[13:35:07.898] iteration 9274: loss: 0.089076, loss_s1: 0.045506, loss_fp: 0.006224, loss_freq: 0.011746
[13:35:08.578] iteration 9275: loss: 0.081220, loss_s1: 0.008703, loss_fp: 0.001385, loss_freq: 0.004737
[13:35:09.219] iteration 9276: loss: 0.085023, loss_s1: 0.053729, loss_fp: 0.004255, loss_freq: 0.038054
[13:35:09.856] iteration 9277: loss: 0.128413, loss_s1: 0.130169, loss_fp: 0.001438, loss_freq: 0.063516
[13:35:10.476] iteration 9278: loss: 0.100758, loss_s1: 0.066442, loss_fp: 0.001702, loss_freq: 0.034283
[13:35:11.103] iteration 9279: loss: 0.065623, loss_s1: 0.029780, loss_fp: 0.002805, loss_freq: 0.048269
[13:35:11.721] iteration 9280: loss: 0.045612, loss_s1: 0.013645, loss_fp: 0.001508, loss_freq: 0.022834
[13:35:12.341] iteration 9281: loss: 0.088561, loss_s1: 0.059251, loss_fp: 0.006005, loss_freq: 0.019044
[13:35:12.961] iteration 9282: loss: 0.047283, loss_s1: 0.026477, loss_fp: 0.002670, loss_freq: 0.009623
[13:35:13.583] iteration 9283: loss: 0.061509, loss_s1: 0.018725, loss_fp: 0.001591, loss_freq: 0.010998
[13:35:14.207] iteration 9284: loss: 0.115663, loss_s1: 0.053427, loss_fp: 0.001900, loss_freq: 0.040635
[13:35:14.829] iteration 9285: loss: 0.100609, loss_s1: 0.078605, loss_fp: 0.001598, loss_freq: 0.037423
[13:35:15.451] iteration 9286: loss: 0.075620, loss_s1: 0.025981, loss_fp: 0.001243, loss_freq: 0.047669
[13:35:16.072] iteration 9287: loss: 0.105833, loss_s1: 0.041089, loss_fp: 0.005609, loss_freq: 0.036165
[13:35:16.691] iteration 9288: loss: 0.097678, loss_s1: 0.056845, loss_fp: 0.004334, loss_freq: 0.009172
[13:35:17.316] iteration 9289: loss: 0.109701, loss_s1: 0.041753, loss_fp: 0.004471, loss_freq: 0.026059
[13:35:17.940] iteration 9290: loss: 0.066848, loss_s1: 0.029792, loss_fp: 0.003431, loss_freq: 0.010147
[13:35:18.571] iteration 9291: loss: 0.082149, loss_s1: 0.044657, loss_fp: 0.007468, loss_freq: 0.057047
[13:35:19.229] iteration 9292: loss: 0.067970, loss_s1: 0.027005, loss_fp: 0.004217, loss_freq: 0.012381
[13:35:19.897] iteration 9293: loss: 0.109119, loss_s1: 0.061537, loss_fp: 0.005935, loss_freq: 0.035450
[13:35:20.556] iteration 9294: loss: 0.108167, loss_s1: 0.101745, loss_fp: 0.003544, loss_freq: 0.042465
[13:35:21.208] iteration 9295: loss: 0.060658, loss_s1: 0.027032, loss_fp: 0.000841, loss_freq: 0.033951
[13:35:22.303] iteration 9296: loss: 0.065246, loss_s1: 0.036458, loss_fp: 0.001226, loss_freq: 0.028567
[13:35:22.960] iteration 9297: loss: 0.083401, loss_s1: 0.063536, loss_fp: 0.003566, loss_freq: 0.023620
[13:35:23.610] iteration 9298: loss: 0.062165, loss_s1: 0.038764, loss_fp: 0.000738, loss_freq: 0.027709
[13:35:24.264] iteration 9299: loss: 0.145575, loss_s1: 0.072340, loss_fp: 0.003493, loss_freq: 0.028951
[13:35:24.922] iteration 9300: loss: 0.103227, loss_s1: 0.084567, loss_fp: 0.005866, loss_freq: 0.050875
[13:35:25.576] iteration 9301: loss: 0.095747, loss_s1: 0.015778, loss_fp: 0.003431, loss_freq: 0.002969
[13:35:26.202] iteration 9302: loss: 0.079712, loss_s1: 0.098624, loss_fp: 0.001452, loss_freq: 0.016374
[13:35:26.833] iteration 9303: loss: 0.122599, loss_s1: 0.059344, loss_fp: 0.007131, loss_freq: 0.053090
[13:35:27.486] iteration 9304: loss: 0.099594, loss_s1: 0.081125, loss_fp: 0.004167, loss_freq: 0.055100
[13:35:28.146] iteration 9305: loss: 0.091495, loss_s1: 0.011632, loss_fp: 0.000600, loss_freq: 0.014852
[13:35:29.105] iteration 9306: loss: 0.115566, loss_s1: 0.086578, loss_fp: 0.001472, loss_freq: 0.057615
[13:35:30.074] iteration 9307: loss: 0.074028, loss_s1: 0.041765, loss_fp: 0.002662, loss_freq: 0.020285
[13:35:30.959] iteration 9308: loss: 0.095131, loss_s1: 0.075820, loss_fp: 0.001769, loss_freq: 0.014707
[13:35:31.582] iteration 9309: loss: 0.048618, loss_s1: 0.025217, loss_fp: 0.001252, loss_freq: 0.020674
[13:35:32.206] iteration 9310: loss: 0.067999, loss_s1: 0.041484, loss_fp: 0.003471, loss_freq: 0.030756
[13:35:32.825] iteration 9311: loss: 0.065812, loss_s1: 0.028059, loss_fp: 0.004856, loss_freq: 0.029784
[13:35:33.448] iteration 9312: loss: 0.144572, loss_s1: 0.031584, loss_fp: 0.003357, loss_freq: 0.026358
[13:35:34.074] iteration 9313: loss: 0.136805, loss_s1: 0.071529, loss_fp: 0.002738, loss_freq: 0.015509
[13:35:34.700] iteration 9314: loss: 0.062798, loss_s1: 0.042602, loss_fp: 0.002106, loss_freq: 0.014640
[13:35:35.326] iteration 9315: loss: 0.093079, loss_s1: 0.063687, loss_fp: 0.001416, loss_freq: 0.009618
[13:35:35.955] iteration 9316: loss: 0.145643, loss_s1: 0.049682, loss_fp: 0.004136, loss_freq: 0.060827
[13:35:36.577] iteration 9317: loss: 0.087671, loss_s1: 0.052552, loss_fp: 0.000968, loss_freq: 0.035532
[13:35:37.207] iteration 9318: loss: 0.065591, loss_s1: 0.033441, loss_fp: 0.001876, loss_freq: 0.024882
[13:35:37.836] iteration 9319: loss: 0.076378, loss_s1: 0.062463, loss_fp: 0.001375, loss_freq: 0.014734
[13:35:38.463] iteration 9320: loss: 0.065181, loss_s1: 0.015977, loss_fp: 0.006361, loss_freq: 0.009722
[13:35:39.086] iteration 9321: loss: 0.098000, loss_s1: 0.093474, loss_fp: 0.012087, loss_freq: 0.016074
[13:35:39.714] iteration 9322: loss: 0.096984, loss_s1: 0.056471, loss_fp: 0.007356, loss_freq: 0.052165
[13:35:40.340] iteration 9323: loss: 0.045311, loss_s1: 0.025148, loss_fp: 0.004334, loss_freq: 0.006258
[13:35:40.966] iteration 9324: loss: 0.060659, loss_s1: 0.017087, loss_fp: 0.002121, loss_freq: 0.023337
[13:35:41.595] iteration 9325: loss: 0.095801, loss_s1: 0.045386, loss_fp: 0.003115, loss_freq: 0.016416
[13:35:42.218] iteration 9326: loss: 0.054878, loss_s1: 0.051218, loss_fp: 0.002952, loss_freq: 0.002782
[13:35:42.837] iteration 9327: loss: 0.087157, loss_s1: 0.050531, loss_fp: 0.020196, loss_freq: 0.019950
[13:35:43.461] iteration 9328: loss: 0.137450, loss_s1: 0.097477, loss_fp: 0.004763, loss_freq: 0.102249
[13:35:44.117] iteration 9329: loss: 0.073064, loss_s1: 0.022851, loss_fp: 0.011600, loss_freq: 0.043431
[13:35:44.788] iteration 9330: loss: 0.066890, loss_s1: 0.024452, loss_fp: 0.000899, loss_freq: 0.020106
[13:35:45.413] iteration 9331: loss: 0.075754, loss_s1: 0.034227, loss_fp: 0.003582, loss_freq: 0.042839
[13:35:46.034] iteration 9332: loss: 0.086672, loss_s1: 0.059134, loss_fp: 0.002073, loss_freq: 0.026407
[13:35:46.662] iteration 9333: loss: 0.051215, loss_s1: 0.036091, loss_fp: 0.002337, loss_freq: 0.011025
[13:35:47.292] iteration 9334: loss: 0.094128, loss_s1: 0.053510, loss_fp: 0.001668, loss_freq: 0.022516
[13:35:47.917] iteration 9335: loss: 0.084567, loss_s1: 0.074296, loss_fp: 0.002954, loss_freq: 0.007677
[13:35:48.540] iteration 9336: loss: 0.080005, loss_s1: 0.024537, loss_fp: 0.001495, loss_freq: 0.029507
[13:35:49.173] iteration 9337: loss: 0.047786, loss_s1: 0.018815, loss_fp: 0.001184, loss_freq: 0.015716
[13:35:49.799] iteration 9338: loss: 0.059449, loss_s1: 0.017451, loss_fp: 0.000332, loss_freq: 0.004624
[13:35:50.431] iteration 9339: loss: 0.080861, loss_s1: 0.056418, loss_fp: 0.003162, loss_freq: 0.040772
[13:35:51.052] iteration 9340: loss: 0.119770, loss_s1: 0.039311, loss_fp: 0.000563, loss_freq: 0.020501
[13:35:51.683] iteration 9341: loss: 0.117372, loss_s1: 0.098085, loss_fp: 0.000662, loss_freq: 0.039876
[13:35:52.302] iteration 9342: loss: 0.086653, loss_s1: 0.033404, loss_fp: 0.007885, loss_freq: 0.063019
[13:35:52.927] iteration 9343: loss: 0.066282, loss_s1: 0.038964, loss_fp: 0.012623, loss_freq: 0.023926
[13:35:53.549] iteration 9344: loss: 0.083721, loss_s1: 0.077541, loss_fp: 0.002848, loss_freq: 0.028337
[13:35:54.174] iteration 9345: loss: 0.064130, loss_s1: 0.051279, loss_fp: 0.002378, loss_freq: 0.016659
[13:35:54.794] iteration 9346: loss: 0.046348, loss_s1: 0.010800, loss_fp: 0.002046, loss_freq: 0.027737
[13:35:55.419] iteration 9347: loss: 0.142294, loss_s1: 0.055002, loss_fp: 0.006015, loss_freq: 0.027544
[13:35:56.043] iteration 9348: loss: 0.047053, loss_s1: 0.020523, loss_fp: 0.001983, loss_freq: 0.006256
[13:35:56.664] iteration 9349: loss: 0.061267, loss_s1: 0.061738, loss_fp: 0.003213, loss_freq: 0.006002
[13:35:57.285] iteration 9350: loss: 0.106831, loss_s1: 0.064368, loss_fp: 0.001785, loss_freq: 0.016667
[13:35:57.908] iteration 9351: loss: 0.065754, loss_s1: 0.023701, loss_fp: 0.003264, loss_freq: 0.021031
[13:35:58.533] iteration 9352: loss: 0.088097, loss_s1: 0.061832, loss_fp: 0.001960, loss_freq: 0.053634
[13:35:59.162] iteration 9353: loss: 0.072280, loss_s1: 0.040320, loss_fp: 0.000745, loss_freq: 0.013804
[13:35:59.785] iteration 9354: loss: 0.122136, loss_s1: 0.050631, loss_fp: 0.001563, loss_freq: 0.055068
[13:36:00.410] iteration 9355: loss: 0.067567, loss_s1: 0.024271, loss_fp: 0.004127, loss_freq: 0.037728
[13:36:01.033] iteration 9356: loss: 0.077362, loss_s1: 0.039388, loss_fp: 0.004969, loss_freq: 0.016297
[13:36:01.658] iteration 9357: loss: 0.084970, loss_s1: 0.074273, loss_fp: 0.003892, loss_freq: 0.021873
[13:36:02.280] iteration 9358: loss: 0.114226, loss_s1: 0.050671, loss_fp: 0.001964, loss_freq: 0.040603
[13:36:02.902] iteration 9359: loss: 0.122120, loss_s1: 0.025723, loss_fp: 0.001398, loss_freq: 0.028105
[13:36:03.524] iteration 9360: loss: 0.091949, loss_s1: 0.025609, loss_fp: 0.003809, loss_freq: 0.031842
[13:36:04.151] iteration 9361: loss: 0.140716, loss_s1: 0.039797, loss_fp: 0.000838, loss_freq: 0.055264
[13:36:04.775] iteration 9362: loss: 0.137503, loss_s1: 0.104767, loss_fp: 0.002689, loss_freq: 0.091426
[13:36:05.403] iteration 9363: loss: 0.052225, loss_s1: 0.005997, loss_fp: 0.002517, loss_freq: 0.023525
[13:36:06.030] iteration 9364: loss: 0.048943, loss_s1: 0.020207, loss_fp: 0.001754, loss_freq: 0.018289
[13:36:06.656] iteration 9365: loss: 0.120882, loss_s1: 0.040155, loss_fp: 0.000912, loss_freq: 0.022286
[13:36:07.288] iteration 9366: loss: 0.090257, loss_s1: 0.031438, loss_fp: 0.000717, loss_freq: 0.013812
[13:36:07.913] iteration 9367: loss: 0.086506, loss_s1: 0.045174, loss_fp: 0.001878, loss_freq: 0.058689
[13:36:08.537] iteration 9368: loss: 0.092503, loss_s1: 0.070899, loss_fp: 0.022257, loss_freq: 0.014320
[13:36:09.160] iteration 9369: loss: 0.098588, loss_s1: 0.058246, loss_fp: 0.000987, loss_freq: 0.054587
[13:36:09.782] iteration 9370: loss: 0.098292, loss_s1: 0.070778, loss_fp: 0.007968, loss_freq: 0.045349
[13:36:10.409] iteration 9371: loss: 0.090134, loss_s1: 0.066423, loss_fp: 0.002256, loss_freq: 0.017230
[13:36:11.063] iteration 9372: loss: 0.068515, loss_s1: 0.069202, loss_fp: 0.004717, loss_freq: 0.017729
[13:36:11.723] iteration 9373: loss: 0.089742, loss_s1: 0.068700, loss_fp: 0.000495, loss_freq: 0.017633
[13:36:12.384] iteration 9374: loss: 0.082767, loss_s1: 0.039714, loss_fp: 0.007070, loss_freq: 0.038316
[13:36:13.037] iteration 9375: loss: 0.166863, loss_s1: 0.076545, loss_fp: 0.001731, loss_freq: 0.039644
[13:36:13.695] iteration 9376: loss: 0.062622, loss_s1: 0.016367, loss_fp: 0.001467, loss_freq: 0.037172
[13:36:14.354] iteration 9377: loss: 0.064623, loss_s1: 0.053076, loss_fp: 0.001710, loss_freq: 0.020644
[13:36:15.012] iteration 9378: loss: 0.071201, loss_s1: 0.018713, loss_fp: 0.003636, loss_freq: 0.030951
[13:36:15.673] iteration 9379: loss: 0.053356, loss_s1: 0.023773, loss_fp: 0.000634, loss_freq: 0.022403
[13:36:16.323] iteration 9380: loss: 0.064425, loss_s1: 0.031946, loss_fp: 0.001942, loss_freq: 0.007264
[13:36:16.988] iteration 9381: loss: 0.065271, loss_s1: 0.015434, loss_fp: 0.004104, loss_freq: 0.051468
[13:36:17.654] iteration 9382: loss: 0.097943, loss_s1: 0.032619, loss_fp: 0.000623, loss_freq: 0.030216
[13:36:18.294] iteration 9383: loss: 0.097783, loss_s1: 0.011662, loss_fp: 0.000496, loss_freq: 0.045891
[13:36:18.924] iteration 9384: loss: 0.049850, loss_s1: 0.036975, loss_fp: 0.002963, loss_freq: 0.009998
[13:36:19.600] iteration 9385: loss: 0.093721, loss_s1: 0.085354, loss_fp: 0.005154, loss_freq: 0.036626
[13:36:20.311] iteration 9386: loss: 0.078771, loss_s1: 0.017565, loss_fp: 0.001686, loss_freq: 0.018508
[13:36:21.007] iteration 9387: loss: 0.103341, loss_s1: 0.095675, loss_fp: 0.005634, loss_freq: 0.050274
[13:36:21.636] iteration 9388: loss: 0.049537, loss_s1: 0.016106, loss_fp: 0.004549, loss_freq: 0.021602
[13:36:22.259] iteration 9389: loss: 0.059626, loss_s1: 0.027306, loss_fp: 0.005343, loss_freq: 0.016383
[13:36:22.905] iteration 9390: loss: 0.071406, loss_s1: 0.040397, loss_fp: 0.001274, loss_freq: 0.023528
[13:36:23.552] iteration 9391: loss: 0.090890, loss_s1: 0.030740, loss_fp: 0.003716, loss_freq: 0.082130
[13:36:24.206] iteration 9392: loss: 0.126408, loss_s1: 0.057537, loss_fp: 0.002335, loss_freq: 0.108784
[13:36:24.862] iteration 9393: loss: 0.064244, loss_s1: 0.034130, loss_fp: 0.005822, loss_freq: 0.022014
[13:36:25.528] iteration 9394: loss: 0.089034, loss_s1: 0.035875, loss_fp: 0.002334, loss_freq: 0.042683
[13:36:26.165] iteration 9395: loss: 0.136129, loss_s1: 0.102061, loss_fp: 0.001802, loss_freq: 0.071676
[13:36:26.828] iteration 9396: loss: 0.096124, loss_s1: 0.043082, loss_fp: 0.001313, loss_freq: 0.065937
[13:36:27.521] iteration 9397: loss: 0.062070, loss_s1: 0.017223, loss_fp: 0.002289, loss_freq: 0.026914
[13:36:28.187] iteration 9398: loss: 0.062398, loss_s1: 0.046605, loss_fp: 0.001914, loss_freq: 0.011949
[13:36:28.815] iteration 9399: loss: 0.111004, loss_s1: 0.059956, loss_fp: 0.004808, loss_freq: 0.032449
[13:36:29.482] iteration 9400: loss: 0.119577, loss_s1: 0.050562, loss_fp: 0.002362, loss_freq: 0.047025
[13:36:32.983] iteration 9400 : mean_dice : 0.754119
[13:36:33.626] iteration 9401: loss: 0.072295, loss_s1: 0.057644, loss_fp: 0.001733, loss_freq: 0.026808
[13:36:34.246] iteration 9402: loss: 0.148563, loss_s1: 0.075851, loss_fp: 0.003829, loss_freq: 0.127180
[13:36:34.871] iteration 9403: loss: 0.096111, loss_s1: 0.068421, loss_fp: 0.001663, loss_freq: 0.077029
[13:36:35.492] iteration 9404: loss: 0.081451, loss_s1: 0.021218, loss_fp: 0.001241, loss_freq: 0.034662
[13:36:36.138] iteration 9405: loss: 0.117805, loss_s1: 0.136247, loss_fp: 0.003926, loss_freq: 0.035212
[13:36:36.797] iteration 9406: loss: 0.089584, loss_s1: 0.027898, loss_fp: 0.001960, loss_freq: 0.011700
[13:36:37.452] iteration 9407: loss: 0.064633, loss_s1: 0.042014, loss_fp: 0.001038, loss_freq: 0.047994
[13:36:38.115] iteration 9408: loss: 0.082078, loss_s1: 0.028797, loss_fp: 0.002699, loss_freq: 0.030908
[13:36:38.752] iteration 9409: loss: 0.103135, loss_s1: 0.084960, loss_fp: 0.005519, loss_freq: 0.051496
[13:36:39.406] iteration 9410: loss: 0.194648, loss_s1: 0.073981, loss_fp: 0.003746, loss_freq: 0.066689
[13:36:40.034] iteration 9411: loss: 0.059552, loss_s1: 0.019671, loss_fp: 0.002686, loss_freq: 0.010049
[13:36:40.656] iteration 9412: loss: 0.130760, loss_s1: 0.103524, loss_fp: 0.005886, loss_freq: 0.076121
[13:36:41.282] iteration 9413: loss: 0.101797, loss_s1: 0.085519, loss_fp: 0.000896, loss_freq: 0.034827
[13:36:41.906] iteration 9414: loss: 0.069877, loss_s1: 0.057596, loss_fp: 0.003888, loss_freq: 0.031705
[13:36:42.532] iteration 9415: loss: 0.063556, loss_s1: 0.028548, loss_fp: 0.005511, loss_freq: 0.027748
[13:36:43.159] iteration 9416: loss: 0.088929, loss_s1: 0.058417, loss_fp: 0.004410, loss_freq: 0.034694
[13:36:43.788] iteration 9417: loss: 0.068772, loss_s1: 0.040884, loss_fp: 0.001785, loss_freq: 0.009788
[13:36:44.410] iteration 9418: loss: 0.067327, loss_s1: 0.054154, loss_fp: 0.003930, loss_freq: 0.006630
[13:36:45.031] iteration 9419: loss: 0.074906, loss_s1: 0.057497, loss_fp: 0.001292, loss_freq: 0.029454
[13:36:45.701] iteration 9420: loss: 0.077621, loss_s1: 0.031379, loss_fp: 0.014397, loss_freq: 0.042410
[13:36:46.359] iteration 9421: loss: 0.100534, loss_s1: 0.069808, loss_fp: 0.002883, loss_freq: 0.029670
[13:36:47.049] iteration 9422: loss: 0.089530, loss_s1: 0.094980, loss_fp: 0.000911, loss_freq: 0.021349
[13:36:47.712] iteration 9423: loss: 0.059400, loss_s1: 0.028570, loss_fp: 0.004428, loss_freq: 0.025949
[13:36:48.373] iteration 9424: loss: 0.142760, loss_s1: 0.039308, loss_fp: 0.002214, loss_freq: 0.020070
[13:36:49.073] iteration 9425: loss: 0.051778, loss_s1: 0.009527, loss_fp: 0.003715, loss_freq: 0.033329
[13:36:49.726] iteration 9426: loss: 0.058008, loss_s1: 0.017729, loss_fp: 0.002369, loss_freq: 0.009809
[13:36:50.349] iteration 9427: loss: 0.141597, loss_s1: 0.062189, loss_fp: 0.002086, loss_freq: 0.045373
[13:36:50.969] iteration 9428: loss: 0.059357, loss_s1: 0.038266, loss_fp: 0.000889, loss_freq: 0.010940
[13:36:51.596] iteration 9429: loss: 0.133623, loss_s1: 0.118565, loss_fp: 0.004228, loss_freq: 0.050381
[13:36:52.224] iteration 9430: loss: 0.081007, loss_s1: 0.038735, loss_fp: 0.005042, loss_freq: 0.011969
[13:36:52.850] iteration 9431: loss: 0.075148, loss_s1: 0.062020, loss_fp: 0.003247, loss_freq: 0.024549
[13:36:53.477] iteration 9432: loss: 0.070766, loss_s1: 0.042336, loss_fp: 0.010732, loss_freq: 0.019901
[13:36:54.109] iteration 9433: loss: 0.071550, loss_s1: 0.030035, loss_fp: 0.001622, loss_freq: 0.007975
[13:36:54.734] iteration 9434: loss: 0.064734, loss_s1: 0.044618, loss_fp: 0.006258, loss_freq: 0.027800
[13:36:55.358] iteration 9435: loss: 0.137334, loss_s1: 0.043177, loss_fp: 0.003482, loss_freq: 0.026820
[13:36:55.984] iteration 9436: loss: 0.100957, loss_s1: 0.044662, loss_fp: 0.004060, loss_freq: 0.047573
[13:36:56.655] iteration 9437: loss: 0.231198, loss_s1: 0.165421, loss_fp: 0.008723, loss_freq: 0.201172
[13:36:57.307] iteration 9438: loss: 0.067605, loss_s1: 0.035278, loss_fp: 0.002079, loss_freq: 0.026797
[13:36:58.281] iteration 9439: loss: 0.074662, loss_s1: 0.056731, loss_fp: 0.007029, loss_freq: 0.006376
[13:36:58.941] iteration 9440: loss: 0.075886, loss_s1: 0.054322, loss_fp: 0.001767, loss_freq: 0.017429
[13:36:59.598] iteration 9441: loss: 0.068084, loss_s1: 0.068770, loss_fp: 0.001916, loss_freq: 0.016056
[13:37:00.264] iteration 9442: loss: 0.106266, loss_s1: 0.098108, loss_fp: 0.001129, loss_freq: 0.022155
[13:37:00.956] iteration 9443: loss: 0.112087, loss_s1: 0.065618, loss_fp: 0.005713, loss_freq: 0.090700
[13:37:01.655] iteration 9444: loss: 0.091348, loss_s1: 0.029488, loss_fp: 0.010567, loss_freq: 0.012149
[13:37:02.342] iteration 9445: loss: 0.077734, loss_s1: 0.050446, loss_fp: 0.001230, loss_freq: 0.051790
[13:37:03.003] iteration 9446: loss: 0.137300, loss_s1: 0.026134, loss_fp: 0.007881, loss_freq: 0.044658
[13:37:03.675] iteration 9447: loss: 0.095875, loss_s1: 0.081587, loss_fp: 0.001839, loss_freq: 0.030141
[13:37:04.318] iteration 9448: loss: 0.113873, loss_s1: 0.028817, loss_fp: 0.000802, loss_freq: 0.007569
[13:37:04.994] iteration 9449: loss: 0.107137, loss_s1: 0.047936, loss_fp: 0.012761, loss_freq: 0.045684
[13:37:05.652] iteration 9450: loss: 0.065740, loss_s1: 0.024338, loss_fp: 0.000871, loss_freq: 0.029912
[13:37:06.309] iteration 9451: loss: 0.079140, loss_s1: 0.047850, loss_fp: 0.003297, loss_freq: 0.026658
[13:37:06.963] iteration 9452: loss: 0.061629, loss_s1: 0.049853, loss_fp: 0.000991, loss_freq: 0.019926
[13:37:07.624] iteration 9453: loss: 0.062212, loss_s1: 0.034421, loss_fp: 0.002448, loss_freq: 0.029146
[13:37:08.261] iteration 9454: loss: 0.069380, loss_s1: 0.050660, loss_fp: 0.001781, loss_freq: 0.025277
[13:37:08.883] iteration 9455: loss: 0.080451, loss_s1: 0.033557, loss_fp: 0.002476, loss_freq: 0.020619
[13:37:09.534] iteration 9456: loss: 0.116599, loss_s1: 0.042183, loss_fp: 0.012146, loss_freq: 0.030270
[13:37:10.195] iteration 9457: loss: 0.059004, loss_s1: 0.042909, loss_fp: 0.000410, loss_freq: 0.013265
[13:37:10.860] iteration 9458: loss: 0.064837, loss_s1: 0.048797, loss_fp: 0.002212, loss_freq: 0.018259
[13:37:11.519] iteration 9459: loss: 0.136161, loss_s1: 0.049585, loss_fp: 0.001193, loss_freq: 0.056846
[13:37:12.203] iteration 9460: loss: 0.064485, loss_s1: 0.038213, loss_fp: 0.002828, loss_freq: 0.023196
[13:37:12.858] iteration 9461: loss: 0.061243, loss_s1: 0.047183, loss_fp: 0.001550, loss_freq: 0.028179
[13:37:13.518] iteration 9462: loss: 0.071577, loss_s1: 0.028059, loss_fp: 0.003626, loss_freq: 0.012939
[13:37:14.174] iteration 9463: loss: 0.083639, loss_s1: 0.068533, loss_fp: 0.001085, loss_freq: 0.020542
[13:37:14.819] iteration 9464: loss: 0.146599, loss_s1: 0.111784, loss_fp: 0.003929, loss_freq: 0.110947
[13:37:15.480] iteration 9465: loss: 0.096766, loss_s1: 0.052411, loss_fp: 0.003641, loss_freq: 0.063245
[13:37:16.137] iteration 9466: loss: 0.060781, loss_s1: 0.046095, loss_fp: 0.000991, loss_freq: 0.005787
[13:37:16.774] iteration 9467: loss: 0.095404, loss_s1: 0.043399, loss_fp: 0.002045, loss_freq: 0.060735
[13:37:17.397] iteration 9468: loss: 0.082074, loss_s1: 0.038025, loss_fp: 0.001104, loss_freq: 0.017025
[13:37:18.026] iteration 9469: loss: 0.070821, loss_s1: 0.016106, loss_fp: 0.000677, loss_freq: 0.008554
[13:37:18.648] iteration 9470: loss: 0.089117, loss_s1: 0.012740, loss_fp: 0.006813, loss_freq: 0.016462
[13:37:19.272] iteration 9471: loss: 0.053662, loss_s1: 0.043118, loss_fp: 0.003016, loss_freq: 0.014311
[13:37:19.913] iteration 9472: loss: 0.119074, loss_s1: 0.102437, loss_fp: 0.001918, loss_freq: 0.076106
[13:37:20.535] iteration 9473: loss: 0.144542, loss_s1: 0.092760, loss_fp: 0.002354, loss_freq: 0.011625
[13:37:21.154] iteration 9474: loss: 0.075370, loss_s1: 0.060981, loss_fp: 0.007309, loss_freq: 0.022846
[13:37:21.781] iteration 9475: loss: 0.118074, loss_s1: 0.079028, loss_fp: 0.002432, loss_freq: 0.079636
[13:37:22.401] iteration 9476: loss: 0.053894, loss_s1: 0.024902, loss_fp: 0.002200, loss_freq: 0.029094
[13:37:23.019] iteration 9477: loss: 0.066710, loss_s1: 0.025057, loss_fp: 0.005138, loss_freq: 0.034432
[13:37:23.643] iteration 9478: loss: 0.073346, loss_s1: 0.045192, loss_fp: 0.001699, loss_freq: 0.028669
[13:37:24.268] iteration 9479: loss: 0.113198, loss_s1: 0.074426, loss_fp: 0.002473, loss_freq: 0.014337
[13:37:24.891] iteration 9480: loss: 0.057966, loss_s1: 0.038383, loss_fp: 0.001379, loss_freq: 0.023652
[13:37:25.518] iteration 9481: loss: 0.079431, loss_s1: 0.026099, loss_fp: 0.000577, loss_freq: 0.011074
[13:37:26.139] iteration 9482: loss: 0.074279, loss_s1: 0.067734, loss_fp: 0.001459, loss_freq: 0.024586
[13:37:26.761] iteration 9483: loss: 0.143176, loss_s1: 0.029317, loss_fp: 0.001277, loss_freq: 0.019556
[13:37:27.383] iteration 9484: loss: 0.097853, loss_s1: 0.064056, loss_fp: 0.001672, loss_freq: 0.040171
[13:37:28.044] iteration 9485: loss: 0.075647, loss_s1: 0.037595, loss_fp: 0.001071, loss_freq: 0.021967
[13:37:28.687] iteration 9486: loss: 0.076177, loss_s1: 0.041295, loss_fp: 0.002749, loss_freq: 0.025231
[13:37:29.306] iteration 9487: loss: 0.053183, loss_s1: 0.038999, loss_fp: 0.001817, loss_freq: 0.013434
[13:37:29.932] iteration 9488: loss: 0.111884, loss_s1: 0.056357, loss_fp: 0.000492, loss_freq: 0.083667
[13:37:30.558] iteration 9489: loss: 0.093558, loss_s1: 0.034545, loss_fp: 0.005540, loss_freq: 0.016486
[13:37:31.180] iteration 9490: loss: 0.078345, loss_s1: 0.027910, loss_fp: 0.001196, loss_freq: 0.041883
[13:37:31.804] iteration 9491: loss: 0.121916, loss_s1: 0.026339, loss_fp: 0.001797, loss_freq: 0.004826
[13:37:32.425] iteration 9492: loss: 0.070727, loss_s1: 0.053249, loss_fp: 0.004122, loss_freq: 0.010339
[13:37:33.046] iteration 9493: loss: 0.063696, loss_s1: 0.039282, loss_fp: 0.000667, loss_freq: 0.037571
[13:37:33.670] iteration 9494: loss: 0.103952, loss_s1: 0.016032, loss_fp: 0.004889, loss_freq: 0.006049
[13:37:34.297] iteration 9495: loss: 0.080881, loss_s1: 0.063812, loss_fp: 0.002344, loss_freq: 0.035863
[13:37:34.939] iteration 9496: loss: 0.069206, loss_s1: 0.018472, loss_fp: 0.002255, loss_freq: 0.018845
[13:37:35.586] iteration 9497: loss: 0.116615, loss_s1: 0.047985, loss_fp: 0.009336, loss_freq: 0.067578
[13:37:36.245] iteration 9498: loss: 0.061513, loss_s1: 0.041658, loss_fp: 0.005074, loss_freq: 0.023977
[13:37:36.868] iteration 9499: loss: 0.076184, loss_s1: 0.039465, loss_fp: 0.004823, loss_freq: 0.031399
[13:37:37.494] iteration 9500: loss: 0.091844, loss_s1: 0.093633, loss_fp: 0.002864, loss_freq: 0.015982
[13:37:38.123] iteration 9501: loss: 0.131040, loss_s1: 0.110472, loss_fp: 0.002246, loss_freq: 0.055898
[13:37:38.748] iteration 9502: loss: 0.094211, loss_s1: 0.051422, loss_fp: 0.002094, loss_freq: 0.018283
[13:37:39.368] iteration 9503: loss: 0.103602, loss_s1: 0.055996, loss_fp: 0.003349, loss_freq: 0.022641
[13:37:39.993] iteration 9504: loss: 0.107997, loss_s1: 0.083876, loss_fp: 0.004524, loss_freq: 0.023871
[13:37:40.616] iteration 9505: loss: 0.108017, loss_s1: 0.057912, loss_fp: 0.005745, loss_freq: 0.058943
[13:37:41.236] iteration 9506: loss: 0.065593, loss_s1: 0.042839, loss_fp: 0.002811, loss_freq: 0.026387
[13:37:41.852] iteration 9507: loss: 0.072893, loss_s1: 0.070845, loss_fp: 0.001400, loss_freq: 0.016968
[13:37:42.471] iteration 9508: loss: 0.110671, loss_s1: 0.039570, loss_fp: 0.002124, loss_freq: 0.035284
[13:37:43.093] iteration 9509: loss: 0.072438, loss_s1: 0.029970, loss_fp: 0.001335, loss_freq: 0.028600
[13:37:43.716] iteration 9510: loss: 0.086837, loss_s1: 0.077553, loss_fp: 0.001538, loss_freq: 0.023794
[13:37:44.338] iteration 9511: loss: 0.115751, loss_s1: 0.087513, loss_fp: 0.002140, loss_freq: 0.067649
[13:37:44.958] iteration 9512: loss: 0.103863, loss_s1: 0.049348, loss_fp: 0.011717, loss_freq: 0.070277
[13:37:45.582] iteration 9513: loss: 0.085231, loss_s1: 0.044554, loss_fp: 0.001702, loss_freq: 0.067460
[13:37:46.206] iteration 9514: loss: 0.094916, loss_s1: 0.048014, loss_fp: 0.009196, loss_freq: 0.016350
[13:37:46.827] iteration 9515: loss: 0.085127, loss_s1: 0.108918, loss_fp: 0.001517, loss_freq: 0.015549
[13:37:47.448] iteration 9516: loss: 0.069958, loss_s1: 0.032849, loss_fp: 0.002223, loss_freq: 0.013123
[13:37:48.068] iteration 9517: loss: 0.109799, loss_s1: 0.108569, loss_fp: 0.004033, loss_freq: 0.049199
[13:37:48.689] iteration 9518: loss: 0.143753, loss_s1: 0.066965, loss_fp: 0.006209, loss_freq: 0.060220
[13:37:49.316] iteration 9519: loss: 0.087182, loss_s1: 0.032602, loss_fp: 0.001363, loss_freq: 0.057304
[13:37:49.935] iteration 9520: loss: 0.111062, loss_s1: 0.084922, loss_fp: 0.001097, loss_freq: 0.044402
[13:37:50.563] iteration 9521: loss: 0.074840, loss_s1: 0.024543, loss_fp: 0.002870, loss_freq: 0.030507
[13:37:51.224] iteration 9522: loss: 0.046800, loss_s1: 0.018693, loss_fp: 0.002226, loss_freq: 0.032694
[13:37:51.846] iteration 9523: loss: 0.084090, loss_s1: 0.052691, loss_fp: 0.002080, loss_freq: 0.035507
[13:37:52.469] iteration 9524: loss: 0.080929, loss_s1: 0.071888, loss_fp: 0.002247, loss_freq: 0.041175
[13:37:53.090] iteration 9525: loss: 0.155258, loss_s1: 0.027609, loss_fp: 0.003540, loss_freq: 0.018848
[13:37:53.712] iteration 9526: loss: 0.081932, loss_s1: 0.012165, loss_fp: 0.000682, loss_freq: 0.026387
[13:37:54.334] iteration 9527: loss: 0.090241, loss_s1: 0.076973, loss_fp: 0.001051, loss_freq: 0.009605
[13:37:54.956] iteration 9528: loss: 0.067967, loss_s1: 0.038634, loss_fp: 0.005564, loss_freq: 0.032325
[13:37:55.583] iteration 9529: loss: 0.089217, loss_s1: 0.039167, loss_fp: 0.000383, loss_freq: 0.014863
[13:37:56.207] iteration 9530: loss: 0.082682, loss_s1: 0.054527, loss_fp: 0.004085, loss_freq: 0.043027
[13:37:56.830] iteration 9531: loss: 0.053011, loss_s1: 0.033630, loss_fp: 0.005368, loss_freq: 0.013385
[13:37:57.487] iteration 9532: loss: 0.072599, loss_s1: 0.041439, loss_fp: 0.004021, loss_freq: 0.025701
[13:37:58.112] iteration 9533: loss: 0.088124, loss_s1: 0.038305, loss_fp: 0.000625, loss_freq: 0.037126
[13:37:58.736] iteration 9534: loss: 0.090691, loss_s1: 0.037879, loss_fp: 0.001676, loss_freq: 0.044998
[13:37:59.363] iteration 9535: loss: 0.108249, loss_s1: 0.117899, loss_fp: 0.002301, loss_freq: 0.035729
[13:38:00.004] iteration 9536: loss: 0.055332, loss_s1: 0.033273, loss_fp: 0.002800, loss_freq: 0.010662
[13:38:00.641] iteration 9537: loss: 0.104755, loss_s1: 0.069208, loss_fp: 0.001318, loss_freq: 0.031045
[13:38:01.272] iteration 9538: loss: 0.079779, loss_s1: 0.041748, loss_fp: 0.004300, loss_freq: 0.031908
[13:38:01.911] iteration 9539: loss: 0.097726, loss_s1: 0.024516, loss_fp: 0.005326, loss_freq: 0.054653
[13:38:02.560] iteration 9540: loss: 0.062158, loss_s1: 0.035590, loss_fp: 0.002352, loss_freq: 0.028904
[13:38:03.179] iteration 9541: loss: 0.054873, loss_s1: 0.021808, loss_fp: 0.003516, loss_freq: 0.005872
[13:38:03.812] iteration 9542: loss: 0.079244, loss_s1: 0.033240, loss_fp: 0.006548, loss_freq: 0.028947
[13:38:04.436] iteration 9543: loss: 0.135030, loss_s1: 0.070688, loss_fp: 0.004942, loss_freq: 0.026222
[13:38:05.059] iteration 9544: loss: 0.068542, loss_s1: 0.016383, loss_fp: 0.001042, loss_freq: 0.035481
[13:38:05.686] iteration 9545: loss: 0.096407, loss_s1: 0.066411, loss_fp: 0.001984, loss_freq: 0.064478
[13:38:06.312] iteration 9546: loss: 0.080161, loss_s1: 0.040315, loss_fp: 0.001428, loss_freq: 0.051688
[13:38:06.931] iteration 9547: loss: 0.071901, loss_s1: 0.014498, loss_fp: 0.000956, loss_freq: 0.018538
[13:38:07.554] iteration 9548: loss: 0.053724, loss_s1: 0.010553, loss_fp: 0.003413, loss_freq: 0.016244
[13:38:08.184] iteration 9549: loss: 0.077210, loss_s1: 0.026444, loss_fp: 0.000822, loss_freq: 0.016220
[13:38:08.813] iteration 9550: loss: 0.065170, loss_s1: 0.019498, loss_fp: 0.007959, loss_freq: 0.053487
[13:38:09.439] iteration 9551: loss: 0.100468, loss_s1: 0.049912, loss_fp: 0.005440, loss_freq: 0.008263
[13:38:10.065] iteration 9552: loss: 0.106404, loss_s1: 0.055203, loss_fp: 0.003830, loss_freq: 0.082742
[13:38:10.694] iteration 9553: loss: 0.155118, loss_s1: 0.082622, loss_fp: 0.001387, loss_freq: 0.046799
[13:38:11.319] iteration 9554: loss: 0.070886, loss_s1: 0.026989, loss_fp: 0.000691, loss_freq: 0.009182
[13:38:11.939] iteration 9555: loss: 0.109960, loss_s1: 0.063908, loss_fp: 0.003088, loss_freq: 0.073101
[13:38:12.561] iteration 9556: loss: 0.080427, loss_s1: 0.050963, loss_fp: 0.005914, loss_freq: 0.023605
[13:38:13.183] iteration 9557: loss: 0.068901, loss_s1: 0.065376, loss_fp: 0.002373, loss_freq: 0.022695
[13:38:13.806] iteration 9558: loss: 0.087092, loss_s1: 0.062428, loss_fp: 0.001734, loss_freq: 0.046625
[13:38:14.429] iteration 9559: loss: 0.089467, loss_s1: 0.059782, loss_fp: 0.000634, loss_freq: 0.059528
[13:38:15.050] iteration 9560: loss: 0.158923, loss_s1: 0.049828, loss_fp: 0.004791, loss_freq: 0.034091
[13:38:15.681] iteration 9561: loss: 0.040574, loss_s1: 0.017674, loss_fp: 0.001108, loss_freq: 0.013038
[13:38:16.303] iteration 9562: loss: 0.122099, loss_s1: 0.088612, loss_fp: 0.001504, loss_freq: 0.039194
[13:38:16.925] iteration 9563: loss: 0.092253, loss_s1: 0.033201, loss_fp: 0.006752, loss_freq: 0.022055
[13:38:17.547] iteration 9564: loss: 0.076431, loss_s1: 0.022128, loss_fp: 0.002783, loss_freq: 0.022976
[13:38:18.177] iteration 9565: loss: 0.054656, loss_s1: 0.017447, loss_fp: 0.002829, loss_freq: 0.022337
[13:38:18.799] iteration 9566: loss: 0.069902, loss_s1: 0.050828, loss_fp: 0.001161, loss_freq: 0.027490
[13:38:19.443] iteration 9567: loss: 0.171681, loss_s1: 0.067828, loss_fp: 0.002784, loss_freq: 0.066691
[13:38:20.066] iteration 9568: loss: 0.091972, loss_s1: 0.058794, loss_fp: 0.008106, loss_freq: 0.023585
[13:38:20.725] iteration 9569: loss: 0.087403, loss_s1: 0.034954, loss_fp: 0.001067, loss_freq: 0.021738
[13:38:21.381] iteration 9570: loss: 0.130608, loss_s1: 0.033675, loss_fp: 0.002747, loss_freq: 0.035894
[13:38:22.020] iteration 9571: loss: 0.098175, loss_s1: 0.068831, loss_fp: 0.007440, loss_freq: 0.034437
[13:38:22.643] iteration 9572: loss: 0.115145, loss_s1: 0.046597, loss_fp: 0.001237, loss_freq: 0.069514
[13:38:23.262] iteration 9573: loss: 0.089540, loss_s1: 0.055259, loss_fp: 0.008057, loss_freq: 0.043814
[13:38:23.882] iteration 9574: loss: 0.085427, loss_s1: 0.026241, loss_fp: 0.016203, loss_freq: 0.021329
[13:38:24.506] iteration 9575: loss: 0.096748, loss_s1: 0.047477, loss_fp: 0.004323, loss_freq: 0.025979
[13:38:25.130] iteration 9576: loss: 0.101629, loss_s1: 0.007682, loss_fp: 0.000710, loss_freq: 0.026102
[13:38:25.752] iteration 9577: loss: 0.054974, loss_s1: 0.038776, loss_fp: 0.001759, loss_freq: 0.015137
[13:38:26.377] iteration 9578: loss: 0.079771, loss_s1: 0.014091, loss_fp: 0.002162, loss_freq: 0.025182
[13:38:27.001] iteration 9579: loss: 0.072366, loss_s1: 0.036559, loss_fp: 0.004739, loss_freq: 0.036335
[13:38:27.616] iteration 9580: loss: 0.079725, loss_s1: 0.049652, loss_fp: 0.003721, loss_freq: 0.046192
[13:38:28.233] iteration 9581: loss: 0.055104, loss_s1: 0.011342, loss_fp: 0.004139, loss_freq: 0.008872
[13:38:29.199] iteration 9582: loss: 0.068746, loss_s1: 0.010271, loss_fp: 0.001211, loss_freq: 0.024253
[13:38:29.852] iteration 9583: loss: 0.065345, loss_s1: 0.028299, loss_fp: 0.002748, loss_freq: 0.020263
[13:38:30.520] iteration 9584: loss: 0.060342, loss_s1: 0.028007, loss_fp: 0.001835, loss_freq: 0.029940
[13:38:31.182] iteration 9585: loss: 0.095383, loss_s1: 0.066141, loss_fp: 0.001188, loss_freq: 0.033621
[13:38:31.839] iteration 9586: loss: 0.075466, loss_s1: 0.038896, loss_fp: 0.001725, loss_freq: 0.051867
[13:38:32.490] iteration 9587: loss: 0.074264, loss_s1: 0.024000, loss_fp: 0.002432, loss_freq: 0.002599
[13:38:33.112] iteration 9588: loss: 0.040415, loss_s1: 0.024867, loss_fp: 0.001888, loss_freq: 0.011411
[13:38:33.734] iteration 9589: loss: 0.109187, loss_s1: 0.051557, loss_fp: 0.002080, loss_freq: 0.056101
[13:38:34.359] iteration 9590: loss: 0.046946, loss_s1: 0.012753, loss_fp: 0.002652, loss_freq: 0.016541
[13:38:34.976] iteration 9591: loss: 0.089140, loss_s1: 0.026924, loss_fp: 0.000619, loss_freq: 0.014999
[13:38:35.594] iteration 9592: loss: 0.102583, loss_s1: 0.072457, loss_fp: 0.004500, loss_freq: 0.062943
[13:38:36.216] iteration 9593: loss: 0.079995, loss_s1: 0.041964, loss_fp: 0.001394, loss_freq: 0.058643
[13:38:36.837] iteration 9594: loss: 0.075744, loss_s1: 0.059250, loss_fp: 0.000534, loss_freq: 0.019395
[13:38:37.521] iteration 9595: loss: 0.048083, loss_s1: 0.013208, loss_fp: 0.000762, loss_freq: 0.033217
[13:38:38.190] iteration 9596: loss: 0.073841, loss_s1: 0.045620, loss_fp: 0.003740, loss_freq: 0.030734
[13:38:38.891] iteration 9597: loss: 0.058402, loss_s1: 0.045760, loss_fp: 0.002644, loss_freq: 0.011125
[13:38:39.549] iteration 9598: loss: 0.182318, loss_s1: 0.100429, loss_fp: 0.003329, loss_freq: 0.010577
[13:38:40.190] iteration 9599: loss: 0.109868, loss_s1: 0.034294, loss_fp: 0.011275, loss_freq: 0.020025
[13:38:40.817] iteration 9600: loss: 0.058310, loss_s1: 0.041157, loss_fp: 0.001481, loss_freq: 0.016555
[13:38:44.096] iteration 9600 : mean_dice : 0.717282
[13:38:44.742] iteration 9601: loss: 0.062570, loss_s1: 0.038868, loss_fp: 0.001592, loss_freq: 0.020042
[13:38:45.366] iteration 9602: loss: 0.124726, loss_s1: 0.058379, loss_fp: 0.001231, loss_freq: 0.051188
[13:38:45.988] iteration 9603: loss: 0.066281, loss_s1: 0.042628, loss_fp: 0.001901, loss_freq: 0.026937
[13:38:46.614] iteration 9604: loss: 0.063255, loss_s1: 0.017769, loss_fp: 0.001200, loss_freq: 0.028046
[13:38:47.242] iteration 9605: loss: 0.099258, loss_s1: 0.041632, loss_fp: 0.001705, loss_freq: 0.023149
[13:38:47.863] iteration 9606: loss: 0.077675, loss_s1: 0.064689, loss_fp: 0.002208, loss_freq: 0.021032
[13:38:48.488] iteration 9607: loss: 0.130622, loss_s1: 0.095520, loss_fp: 0.002206, loss_freq: 0.065171
[13:38:49.119] iteration 9608: loss: 0.069871, loss_s1: 0.016669, loss_fp: 0.006032, loss_freq: 0.049362
[13:38:49.742] iteration 9609: loss: 0.088036, loss_s1: 0.034082, loss_fp: 0.000691, loss_freq: 0.016889
[13:38:50.367] iteration 9610: loss: 0.101204, loss_s1: 0.039876, loss_fp: 0.011899, loss_freq: 0.056968
[13:38:50.988] iteration 9611: loss: 0.069789, loss_s1: 0.030201, loss_fp: 0.001916, loss_freq: 0.008210
[13:38:51.613] iteration 9612: loss: 0.056562, loss_s1: 0.031374, loss_fp: 0.001076, loss_freq: 0.014781
[13:38:52.227] iteration 9613: loss: 0.057706, loss_s1: 0.019076, loss_fp: 0.001641, loss_freq: 0.018063
[13:38:52.851] iteration 9614: loss: 0.042995, loss_s1: 0.022256, loss_fp: 0.002811, loss_freq: 0.018436
[13:38:53.473] iteration 9615: loss: 0.092955, loss_s1: 0.071026, loss_fp: 0.005129, loss_freq: 0.051578
[13:38:54.098] iteration 9616: loss: 0.115154, loss_s1: 0.086409, loss_fp: 0.001586, loss_freq: 0.026710
[13:38:54.719] iteration 9617: loss: 0.083751, loss_s1: 0.052748, loss_fp: 0.001885, loss_freq: 0.038858
[13:38:55.378] iteration 9618: loss: 0.107983, loss_s1: 0.091032, loss_fp: 0.002406, loss_freq: 0.040766
[13:38:56.034] iteration 9619: loss: 0.063290, loss_s1: 0.015112, loss_fp: 0.005622, loss_freq: 0.036126
[13:38:56.656] iteration 9620: loss: 0.122084, loss_s1: 0.051196, loss_fp: 0.002618, loss_freq: 0.062797
[13:38:57.291] iteration 9621: loss: 0.045497, loss_s1: 0.014442, loss_fp: 0.007972, loss_freq: 0.003815
[13:38:57.916] iteration 9622: loss: 0.094681, loss_s1: 0.067140, loss_fp: 0.002946, loss_freq: 0.011881
[13:38:58.548] iteration 9623: loss: 0.075520, loss_s1: 0.054737, loss_fp: 0.007464, loss_freq: 0.044790
[13:38:59.185] iteration 9624: loss: 0.100990, loss_s1: 0.033683, loss_fp: 0.000346, loss_freq: 0.017938
[13:38:59.810] iteration 9625: loss: 0.072828, loss_s1: 0.043372, loss_fp: 0.023171, loss_freq: 0.019945
[13:39:00.431] iteration 9626: loss: 0.114741, loss_s1: 0.031477, loss_fp: 0.002311, loss_freq: 0.051921
[13:39:01.056] iteration 9627: loss: 0.083451, loss_s1: 0.064660, loss_fp: 0.001207, loss_freq: 0.035472
[13:39:01.710] iteration 9628: loss: 0.066700, loss_s1: 0.018311, loss_fp: 0.001862, loss_freq: 0.019721
[13:39:02.336] iteration 9629: loss: 0.055109, loss_s1: 0.023111, loss_fp: 0.001622, loss_freq: 0.021340
[13:39:02.965] iteration 9630: loss: 0.043936, loss_s1: 0.019096, loss_fp: 0.001072, loss_freq: 0.018828
[13:39:03.592] iteration 9631: loss: 0.081123, loss_s1: 0.072438, loss_fp: 0.002021, loss_freq: 0.022725
[13:39:04.223] iteration 9632: loss: 0.067627, loss_s1: 0.048589, loss_fp: 0.001401, loss_freq: 0.026672
[13:39:04.850] iteration 9633: loss: 0.127613, loss_s1: 0.020618, loss_fp: 0.000644, loss_freq: 0.022326
[13:39:05.473] iteration 9634: loss: 0.076077, loss_s1: 0.049241, loss_fp: 0.000533, loss_freq: 0.022445
[13:39:06.144] iteration 9635: loss: 0.059587, loss_s1: 0.055738, loss_fp: 0.006553, loss_freq: 0.014047
[13:39:06.817] iteration 9636: loss: 0.093811, loss_s1: 0.024528, loss_fp: 0.003122, loss_freq: 0.025754
[13:39:07.485] iteration 9637: loss: 0.078604, loss_s1: 0.014894, loss_fp: 0.000819, loss_freq: 0.010199
[13:39:08.138] iteration 9638: loss: 0.081232, loss_s1: 0.096316, loss_fp: 0.002854, loss_freq: 0.017082
[13:39:08.798] iteration 9639: loss: 0.083649, loss_s1: 0.036649, loss_fp: 0.008696, loss_freq: 0.031114
[13:39:09.456] iteration 9640: loss: 0.150520, loss_s1: 0.044469, loss_fp: 0.003872, loss_freq: 0.113395
[13:39:10.112] iteration 9641: loss: 0.094887, loss_s1: 0.064758, loss_fp: 0.003851, loss_freq: 0.045729
[13:39:10.733] iteration 9642: loss: 0.067095, loss_s1: 0.029558, loss_fp: 0.001632, loss_freq: 0.018101
[13:39:11.354] iteration 9643: loss: 0.078134, loss_s1: 0.058702, loss_fp: 0.007162, loss_freq: 0.022618
[13:39:11.976] iteration 9644: loss: 0.092685, loss_s1: 0.094240, loss_fp: 0.002488, loss_freq: 0.028330
[13:39:12.599] iteration 9645: loss: 0.072929, loss_s1: 0.033993, loss_fp: 0.000958, loss_freq: 0.015058
[13:39:13.222] iteration 9646: loss: 0.151212, loss_s1: 0.062337, loss_fp: 0.000879, loss_freq: 0.038685
[13:39:13.848] iteration 9647: loss: 0.088141, loss_s1: 0.064628, loss_fp: 0.002007, loss_freq: 0.019397
[13:39:14.469] iteration 9648: loss: 0.149421, loss_s1: 0.090174, loss_fp: 0.003617, loss_freq: 0.077509
[13:39:15.090] iteration 9649: loss: 0.096242, loss_s1: 0.010179, loss_fp: 0.001691, loss_freq: 0.034351
[13:39:15.713] iteration 9650: loss: 0.048864, loss_s1: 0.017158, loss_fp: 0.000652, loss_freq: 0.020993
[13:39:16.338] iteration 9651: loss: 0.079020, loss_s1: 0.031180, loss_fp: 0.002607, loss_freq: 0.009554
[13:39:16.967] iteration 9652: loss: 0.059407, loss_s1: 0.027183, loss_fp: 0.002025, loss_freq: 0.011488
[13:39:17.597] iteration 9653: loss: 0.071402, loss_s1: 0.024232, loss_fp: 0.000827, loss_freq: 0.037378
[13:39:18.222] iteration 9654: loss: 0.080460, loss_s1: 0.012961, loss_fp: 0.001107, loss_freq: 0.064828
[13:39:18.849] iteration 9655: loss: 0.112703, loss_s1: 0.121473, loss_fp: 0.001670, loss_freq: 0.023704
[13:39:19.472] iteration 9656: loss: 0.065334, loss_s1: 0.026982, loss_fp: 0.000970, loss_freq: 0.048111
[13:39:20.094] iteration 9657: loss: 0.079947, loss_s1: 0.031223, loss_fp: 0.001006, loss_freq: 0.014242
[13:39:20.719] iteration 9658: loss: 0.072905, loss_s1: 0.060327, loss_fp: 0.003573, loss_freq: 0.034745
[13:39:21.342] iteration 9659: loss: 0.056354, loss_s1: 0.016655, loss_fp: 0.001561, loss_freq: 0.010057
[13:39:21.970] iteration 9660: loss: 0.066813, loss_s1: 0.040461, loss_fp: 0.001185, loss_freq: 0.027798
[13:39:22.591] iteration 9661: loss: 0.201031, loss_s1: 0.078115, loss_fp: 0.001006, loss_freq: 0.028866
[13:39:23.212] iteration 9662: loss: 0.062059, loss_s1: 0.014402, loss_fp: 0.001337, loss_freq: 0.026700
[13:39:23.835] iteration 9663: loss: 0.087989, loss_s1: 0.056654, loss_fp: 0.001580, loss_freq: 0.027776
[13:39:24.455] iteration 9664: loss: 0.074495, loss_s1: 0.031225, loss_fp: 0.000606, loss_freq: 0.024266
[13:39:25.077] iteration 9665: loss: 0.042423, loss_s1: 0.018067, loss_fp: 0.001047, loss_freq: 0.011319
[13:39:25.697] iteration 9666: loss: 0.045792, loss_s1: 0.009112, loss_fp: 0.000784, loss_freq: 0.010911
[13:39:26.318] iteration 9667: loss: 0.087136, loss_s1: 0.070130, loss_fp: 0.007727, loss_freq: 0.039260
[13:39:26.995] iteration 9668: loss: 0.104952, loss_s1: 0.074712, loss_fp: 0.003047, loss_freq: 0.040953
[13:39:27.644] iteration 9669: loss: 0.093694, loss_s1: 0.017216, loss_fp: 0.001067, loss_freq: 0.021786
[13:39:28.293] iteration 9670: loss: 0.070161, loss_s1: 0.059249, loss_fp: 0.000873, loss_freq: 0.019139
[13:39:28.942] iteration 9671: loss: 0.066718, loss_s1: 0.049747, loss_fp: 0.002791, loss_freq: 0.020395
[13:39:29.574] iteration 9672: loss: 0.061596, loss_s1: 0.011492, loss_fp: 0.000957, loss_freq: 0.023837
[13:39:30.191] iteration 9673: loss: 0.080801, loss_s1: 0.045434, loss_fp: 0.006365, loss_freq: 0.057302
[13:39:30.812] iteration 9674: loss: 0.063021, loss_s1: 0.042764, loss_fp: 0.001762, loss_freq: 0.010292
[13:39:31.433] iteration 9675: loss: 0.069320, loss_s1: 0.040739, loss_fp: 0.000775, loss_freq: 0.020750
[13:39:32.053] iteration 9676: loss: 0.075292, loss_s1: 0.045446, loss_fp: 0.001553, loss_freq: 0.030717
[13:39:32.678] iteration 9677: loss: 0.057705, loss_s1: 0.022192, loss_fp: 0.002481, loss_freq: 0.028038
[13:39:33.302] iteration 9678: loss: 0.153966, loss_s1: 0.168763, loss_fp: 0.003195, loss_freq: 0.051355
[13:39:33.924] iteration 9679: loss: 0.053703, loss_s1: 0.028574, loss_fp: 0.003539, loss_freq: 0.021181
[13:39:34.554] iteration 9680: loss: 0.077343, loss_s1: 0.003149, loss_fp: 0.006054, loss_freq: 0.057522
[13:39:35.178] iteration 9681: loss: 0.114805, loss_s1: 0.078009, loss_fp: 0.006014, loss_freq: 0.051528
[13:39:35.796] iteration 9682: loss: 0.103879, loss_s1: 0.038423, loss_fp: 0.007861, loss_freq: 0.050902
[13:39:36.416] iteration 9683: loss: 0.077035, loss_s1: 0.033387, loss_fp: 0.004715, loss_freq: 0.015831
[13:39:37.098] iteration 9684: loss: 0.097269, loss_s1: 0.058369, loss_fp: 0.005843, loss_freq: 0.029541
[13:39:37.716] iteration 9685: loss: 0.081316, loss_s1: 0.035338, loss_fp: 0.002453, loss_freq: 0.036472
[13:39:38.335] iteration 9686: loss: 0.096340, loss_s1: 0.050577, loss_fp: 0.001240, loss_freq: 0.041898
[13:39:38.993] iteration 9687: loss: 0.085428, loss_s1: 0.022867, loss_fp: 0.001288, loss_freq: 0.066379
[13:39:39.719] iteration 9688: loss: 0.115612, loss_s1: 0.034182, loss_fp: 0.001166, loss_freq: 0.127568
[13:39:40.476] iteration 9689: loss: 0.095369, loss_s1: 0.099898, loss_fp: 0.008578, loss_freq: 0.026647
[13:39:41.197] iteration 9690: loss: 0.058319, loss_s1: 0.015716, loss_fp: 0.004740, loss_freq: 0.016036
[13:39:41.914] iteration 9691: loss: 0.097322, loss_s1: 0.054578, loss_fp: 0.002920, loss_freq: 0.060185
[13:39:42.575] iteration 9692: loss: 0.083259, loss_s1: 0.018643, loss_fp: 0.001467, loss_freq: 0.033989
[13:39:43.230] iteration 9693: loss: 0.073782, loss_s1: 0.021797, loss_fp: 0.004778, loss_freq: 0.036745
[13:39:43.883] iteration 9694: loss: 0.067926, loss_s1: 0.046221, loss_fp: 0.000730, loss_freq: 0.013465
[13:39:44.537] iteration 9695: loss: 0.064322, loss_s1: 0.027910, loss_fp: 0.001899, loss_freq: 0.043452
[13:39:45.170] iteration 9696: loss: 0.158095, loss_s1: 0.052125, loss_fp: 0.001945, loss_freq: 0.036880
[13:39:45.795] iteration 9697: loss: 0.087688, loss_s1: 0.054722, loss_fp: 0.001717, loss_freq: 0.013646
[13:39:46.417] iteration 9698: loss: 0.103380, loss_s1: 0.037684, loss_fp: 0.005781, loss_freq: 0.081195
[13:39:47.038] iteration 9699: loss: 0.129936, loss_s1: 0.125223, loss_fp: 0.001089, loss_freq: 0.051047
[13:39:47.659] iteration 9700: loss: 0.084293, loss_s1: 0.076937, loss_fp: 0.005602, loss_freq: 0.038946
[13:39:48.281] iteration 9701: loss: 0.071416, loss_s1: 0.038473, loss_fp: 0.001094, loss_freq: 0.044157
[13:39:48.905] iteration 9702: loss: 0.085885, loss_s1: 0.053494, loss_fp: 0.001885, loss_freq: 0.046384
[13:39:49.529] iteration 9703: loss: 0.117701, loss_s1: 0.038169, loss_fp: 0.002056, loss_freq: 0.039884
[13:39:50.151] iteration 9704: loss: 0.083196, loss_s1: 0.024131, loss_fp: 0.000741, loss_freq: 0.014633
[13:39:50.775] iteration 9705: loss: 0.053419, loss_s1: 0.035357, loss_fp: 0.002228, loss_freq: 0.017603
[13:39:51.397] iteration 9706: loss: 0.059316, loss_s1: 0.030079, loss_fp: 0.001772, loss_freq: 0.041120
[13:39:52.018] iteration 9707: loss: 0.075632, loss_s1: 0.014425, loss_fp: 0.007517, loss_freq: 0.022945
[13:39:52.644] iteration 9708: loss: 0.075136, loss_s1: 0.072151, loss_fp: 0.001039, loss_freq: 0.028393
[13:39:53.270] iteration 9709: loss: 0.056721, loss_s1: 0.028972, loss_fp: 0.002187, loss_freq: 0.021569
[13:39:53.902] iteration 9710: loss: 0.105076, loss_s1: 0.064696, loss_fp: 0.002691, loss_freq: 0.014107
[13:39:54.524] iteration 9711: loss: 0.054154, loss_s1: 0.037553, loss_fp: 0.001334, loss_freq: 0.011620
[13:39:55.147] iteration 9712: loss: 0.068370, loss_s1: 0.039298, loss_fp: 0.001397, loss_freq: 0.022510
[13:39:55.769] iteration 9713: loss: 0.095088, loss_s1: 0.055520, loss_fp: 0.009200, loss_freq: 0.022420
[13:39:56.391] iteration 9714: loss: 0.075160, loss_s1: 0.036588, loss_fp: 0.005920, loss_freq: 0.012246
[13:39:57.016] iteration 9715: loss: 0.119775, loss_s1: 0.069723, loss_fp: 0.000956, loss_freq: 0.049094
[13:39:57.636] iteration 9716: loss: 0.098246, loss_s1: 0.037059, loss_fp: 0.001572, loss_freq: 0.035029
[13:39:58.269] iteration 9717: loss: 0.060349, loss_s1: 0.058972, loss_fp: 0.001746, loss_freq: 0.012463
[13:39:58.933] iteration 9718: loss: 0.068732, loss_s1: 0.050076, loss_fp: 0.003217, loss_freq: 0.024937
[13:39:59.592] iteration 9719: loss: 0.057064, loss_s1: 0.017167, loss_fp: 0.000976, loss_freq: 0.015332
[13:40:00.247] iteration 9720: loss: 0.068695, loss_s1: 0.017726, loss_fp: 0.003345, loss_freq: 0.046922
[13:40:00.897] iteration 9721: loss: 0.073347, loss_s1: 0.022464, loss_fp: 0.003749, loss_freq: 0.004479
[13:40:01.547] iteration 9722: loss: 0.103984, loss_s1: 0.079323, loss_fp: 0.001969, loss_freq: 0.034061
[13:40:02.175] iteration 9723: loss: 0.127801, loss_s1: 0.127777, loss_fp: 0.010973, loss_freq: 0.035611
[13:40:02.824] iteration 9724: loss: 0.073133, loss_s1: 0.043765, loss_fp: 0.002041, loss_freq: 0.030396
[13:40:03.796] iteration 9725: loss: 0.058916, loss_s1: 0.024050, loss_fp: 0.002821, loss_freq: 0.031537
[13:40:04.449] iteration 9726: loss: 0.052042, loss_s1: 0.019062, loss_fp: 0.003604, loss_freq: 0.018133
[13:40:05.103] iteration 9727: loss: 0.057029, loss_s1: 0.015656, loss_fp: 0.002477, loss_freq: 0.032911
[13:40:05.753] iteration 9728: loss: 0.109309, loss_s1: 0.034158, loss_fp: 0.001005, loss_freq: 0.012114
[13:40:06.406] iteration 9729: loss: 0.093227, loss_s1: 0.083987, loss_fp: 0.001549, loss_freq: 0.039750
[13:40:07.075] iteration 9730: loss: 0.100332, loss_s1: 0.037112, loss_fp: 0.000420, loss_freq: 0.006294
[13:40:07.699] iteration 9731: loss: 0.051360, loss_s1: 0.037976, loss_fp: 0.002604, loss_freq: 0.019151
[13:40:08.317] iteration 9732: loss: 0.161357, loss_s1: 0.109921, loss_fp: 0.002602, loss_freq: 0.061620
[13:40:08.966] iteration 9733: loss: 0.051661, loss_s1: 0.017470, loss_fp: 0.001086, loss_freq: 0.027027
[13:40:09.587] iteration 9734: loss: 0.109655, loss_s1: 0.062543, loss_fp: 0.004090, loss_freq: 0.026843
[13:40:10.208] iteration 9735: loss: 0.065305, loss_s1: 0.026317, loss_fp: 0.001716, loss_freq: 0.038532
[13:40:10.863] iteration 9736: loss: 0.095155, loss_s1: 0.072087, loss_fp: 0.001862, loss_freq: 0.044176
[13:40:11.484] iteration 9737: loss: 0.054720, loss_s1: 0.028337, loss_fp: 0.000986, loss_freq: 0.015091
[13:40:12.105] iteration 9738: loss: 0.037825, loss_s1: 0.010254, loss_fp: 0.001743, loss_freq: 0.004860
[13:40:12.727] iteration 9739: loss: 0.075583, loss_s1: 0.054411, loss_fp: 0.003814, loss_freq: 0.036639
[13:40:13.350] iteration 9740: loss: 0.058380, loss_s1: 0.050861, loss_fp: 0.002682, loss_freq: 0.008209
[13:40:13.983] iteration 9741: loss: 0.116864, loss_s1: 0.022634, loss_fp: 0.001855, loss_freq: 0.011311
[13:40:14.606] iteration 9742: loss: 0.126150, loss_s1: 0.113834, loss_fp: 0.000860, loss_freq: 0.010381
[13:40:15.230] iteration 9743: loss: 0.057190, loss_s1: 0.043405, loss_fp: 0.005308, loss_freq: 0.011612
[13:40:15.850] iteration 9744: loss: 0.110640, loss_s1: 0.066546, loss_fp: 0.001060, loss_freq: 0.029900
[13:40:16.470] iteration 9745: loss: 0.111818, loss_s1: 0.033769, loss_fp: 0.004211, loss_freq: 0.055371
[13:40:17.090] iteration 9746: loss: 0.071369, loss_s1: 0.060224, loss_fp: 0.000585, loss_freq: 0.014956
[13:40:17.707] iteration 9747: loss: 0.076760, loss_s1: 0.076616, loss_fp: 0.000271, loss_freq: 0.017572
[13:40:18.324] iteration 9748: loss: 0.067081, loss_s1: 0.018744, loss_fp: 0.002216, loss_freq: 0.009883
[13:40:18.939] iteration 9749: loss: 0.094699, loss_s1: 0.069921, loss_fp: 0.007712, loss_freq: 0.029896
[13:40:19.562] iteration 9750: loss: 0.105399, loss_s1: 0.038789, loss_fp: 0.028700, loss_freq: 0.039795
[13:40:20.186] iteration 9751: loss: 0.076324, loss_s1: 0.046108, loss_fp: 0.001280, loss_freq: 0.032524
[13:40:20.807] iteration 9752: loss: 0.077564, loss_s1: 0.043932, loss_fp: 0.004082, loss_freq: 0.016734
[13:40:21.459] iteration 9753: loss: 0.085660, loss_s1: 0.043634, loss_fp: 0.005172, loss_freq: 0.051387
[13:40:22.080] iteration 9754: loss: 0.065614, loss_s1: 0.018958, loss_fp: 0.001792, loss_freq: 0.018117
[13:40:22.749] iteration 9755: loss: 0.045428, loss_s1: 0.029345, loss_fp: 0.003738, loss_freq: 0.008999
[13:40:23.371] iteration 9756: loss: 0.070677, loss_s1: 0.037753, loss_fp: 0.001023, loss_freq: 0.027129
[13:40:23.998] iteration 9757: loss: 0.090411, loss_s1: 0.076178, loss_fp: 0.002469, loss_freq: 0.043317
[13:40:24.627] iteration 9758: loss: 0.094550, loss_s1: 0.060950, loss_fp: 0.003838, loss_freq: 0.063614
[13:40:25.250] iteration 9759: loss: 0.133398, loss_s1: 0.038490, loss_fp: 0.007386, loss_freq: 0.055857
[13:40:25.872] iteration 9760: loss: 0.107457, loss_s1: 0.047549, loss_fp: 0.004504, loss_freq: 0.057567
[13:40:26.498] iteration 9761: loss: 0.087561, loss_s1: 0.065155, loss_fp: 0.003806, loss_freq: 0.037671
[13:40:27.120] iteration 9762: loss: 0.070565, loss_s1: 0.058917, loss_fp: 0.001168, loss_freq: 0.029196
[13:40:27.742] iteration 9763: loss: 0.100650, loss_s1: 0.037263, loss_fp: 0.006650, loss_freq: 0.048270
[13:40:28.362] iteration 9764: loss: 0.070339, loss_s1: 0.067727, loss_fp: 0.000596, loss_freq: 0.021714
[13:40:28.979] iteration 9765: loss: 0.115884, loss_s1: 0.052252, loss_fp: 0.003872, loss_freq: 0.026610
[13:40:29.601] iteration 9766: loss: 0.089834, loss_s1: 0.062704, loss_fp: 0.003592, loss_freq: 0.020010
[13:40:30.221] iteration 9767: loss: 0.060094, loss_s1: 0.026868, loss_fp: 0.000474, loss_freq: 0.011149
[13:40:30.843] iteration 9768: loss: 0.112602, loss_s1: 0.117799, loss_fp: 0.001656, loss_freq: 0.053314
[13:40:31.465] iteration 9769: loss: 0.139649, loss_s1: 0.034732, loss_fp: 0.002122, loss_freq: 0.073414
[13:40:32.087] iteration 9770: loss: 0.143979, loss_s1: 0.071753, loss_fp: 0.004411, loss_freq: 0.076985
[13:40:32.709] iteration 9771: loss: 0.075342, loss_s1: 0.021148, loss_fp: 0.005609, loss_freq: 0.043587
[13:40:33.331] iteration 9772: loss: 0.095314, loss_s1: 0.075465, loss_fp: 0.001162, loss_freq: 0.023932
[13:40:33.948] iteration 9773: loss: 0.055239, loss_s1: 0.063208, loss_fp: 0.002245, loss_freq: 0.005401
[13:40:34.568] iteration 9774: loss: 0.080959, loss_s1: 0.051823, loss_fp: 0.002020, loss_freq: 0.049199
[13:40:35.189] iteration 9775: loss: 0.078764, loss_s1: 0.046911, loss_fp: 0.001051, loss_freq: 0.030992
[13:40:35.811] iteration 9776: loss: 0.114868, loss_s1: 0.041205, loss_fp: 0.000416, loss_freq: 0.022860
[13:40:36.431] iteration 9777: loss: 0.072000, loss_s1: 0.029348, loss_fp: 0.002647, loss_freq: 0.018116
[13:40:37.056] iteration 9778: loss: 0.065071, loss_s1: 0.052171, loss_fp: 0.002588, loss_freq: 0.008459
[13:40:37.684] iteration 9779: loss: 0.051879, loss_s1: 0.042264, loss_fp: 0.003279, loss_freq: 0.019296
[13:40:38.303] iteration 9780: loss: 0.095973, loss_s1: 0.027232, loss_fp: 0.002487, loss_freq: 0.014914
[13:40:38.944] iteration 9781: loss: 0.081706, loss_s1: 0.044596, loss_fp: 0.003322, loss_freq: 0.044959
[13:40:39.560] iteration 9782: loss: 0.068805, loss_s1: 0.043625, loss_fp: 0.001052, loss_freq: 0.018893
[13:40:40.179] iteration 9783: loss: 0.093927, loss_s1: 0.032080, loss_fp: 0.015000, loss_freq: 0.057495
[13:40:40.804] iteration 9784: loss: 0.063976, loss_s1: 0.030540, loss_fp: 0.001277, loss_freq: 0.020107
[13:40:41.428] iteration 9785: loss: 0.093401, loss_s1: 0.054109, loss_fp: 0.008320, loss_freq: 0.025359
[13:40:42.066] iteration 9786: loss: 0.103545, loss_s1: 0.043841, loss_fp: 0.004513, loss_freq: 0.022364
[13:40:42.715] iteration 9787: loss: 0.071434, loss_s1: 0.034474, loss_fp: 0.002851, loss_freq: 0.043122
[13:40:43.369] iteration 9788: loss: 0.078543, loss_s1: 0.021888, loss_fp: 0.000525, loss_freq: 0.020462
[13:40:44.019] iteration 9789: loss: 0.083614, loss_s1: 0.046110, loss_fp: 0.001053, loss_freq: 0.027678
[13:40:44.671] iteration 9790: loss: 0.156171, loss_s1: 0.078373, loss_fp: 0.001998, loss_freq: 0.029074
[13:40:45.360] iteration 9791: loss: 0.114116, loss_s1: 0.070599, loss_fp: 0.003844, loss_freq: 0.068427
[13:40:46.012] iteration 9792: loss: 0.044746, loss_s1: 0.011415, loss_fp: 0.006516, loss_freq: 0.009740
[13:40:46.665] iteration 9793: loss: 0.078855, loss_s1: 0.067768, loss_fp: 0.002383, loss_freq: 0.022202
[13:40:47.317] iteration 9794: loss: 0.085267, loss_s1: 0.042222, loss_fp: 0.001895, loss_freq: 0.011106
[13:40:47.953] iteration 9795: loss: 0.069318, loss_s1: 0.031243, loss_fp: 0.008371, loss_freq: 0.025555
[13:40:48.572] iteration 9796: loss: 0.070577, loss_s1: 0.054606, loss_fp: 0.000720, loss_freq: 0.012595
[13:40:49.194] iteration 9797: loss: 0.086355, loss_s1: 0.044087, loss_fp: 0.001075, loss_freq: 0.032666
[13:40:49.812] iteration 9798: loss: 0.154885, loss_s1: 0.128240, loss_fp: 0.002642, loss_freq: 0.066013
[13:40:50.434] iteration 9799: loss: 0.060807, loss_s1: 0.017891, loss_fp: 0.010335, loss_freq: 0.029219
[13:40:51.054] iteration 9800: loss: 0.093574, loss_s1: 0.061542, loss_fp: 0.001989, loss_freq: 0.011690
[13:40:54.374] iteration 9800 : mean_dice : 0.739009
[13:40:55.016] iteration 9801: loss: 0.062714, loss_s1: 0.034036, loss_fp: 0.001674, loss_freq: 0.019527
[13:40:55.638] iteration 9802: loss: 0.071436, loss_s1: 0.027957, loss_fp: 0.000807, loss_freq: 0.012898
[13:40:56.257] iteration 9803: loss: 0.070371, loss_s1: 0.031569, loss_fp: 0.003599, loss_freq: 0.047747
[13:40:56.878] iteration 9804: loss: 0.205203, loss_s1: 0.117923, loss_fp: 0.012360, loss_freq: 0.066119
[13:40:57.500] iteration 9805: loss: 0.082492, loss_s1: 0.034064, loss_fp: 0.000753, loss_freq: 0.042462
[13:40:58.117] iteration 9806: loss: 0.080273, loss_s1: 0.047850, loss_fp: 0.001961, loss_freq: 0.023567
[13:40:58.740] iteration 9807: loss: 0.112453, loss_s1: 0.069739, loss_fp: 0.004095, loss_freq: 0.029014
[13:40:59.359] iteration 9808: loss: 0.040146, loss_s1: 0.012168, loss_fp: 0.001398, loss_freq: 0.004263
[13:40:59.978] iteration 9809: loss: 0.101111, loss_s1: 0.015830, loss_fp: 0.000444, loss_freq: 0.017876
[13:41:00.608] iteration 9810: loss: 0.081679, loss_s1: 0.046606, loss_fp: 0.001845, loss_freq: 0.057490
[13:41:01.233] iteration 9811: loss: 0.103640, loss_s1: 0.029515, loss_fp: 0.000873, loss_freq: 0.012442
[13:41:01.851] iteration 9812: loss: 0.082079, loss_s1: 0.033158, loss_fp: 0.000584, loss_freq: 0.014358
[13:41:02.472] iteration 9813: loss: 0.057373, loss_s1: 0.054840, loss_fp: 0.000805, loss_freq: 0.012889
[13:41:03.094] iteration 9814: loss: 0.116982, loss_s1: 0.057677, loss_fp: 0.010052, loss_freq: 0.087901
[13:41:03.718] iteration 9815: loss: 0.099252, loss_s1: 0.032380, loss_fp: 0.001000, loss_freq: 0.028761
[13:41:04.343] iteration 9816: loss: 0.086911, loss_s1: 0.033992, loss_fp: 0.003712, loss_freq: 0.063393
[13:41:04.968] iteration 9817: loss: 0.050381, loss_s1: 0.011527, loss_fp: 0.004451, loss_freq: 0.025320
[13:41:05.588] iteration 9818: loss: 0.099214, loss_s1: 0.061803, loss_fp: 0.018397, loss_freq: 0.007472
[13:41:06.216] iteration 9819: loss: 0.070348, loss_s1: 0.030354, loss_fp: 0.003857, loss_freq: 0.037243
[13:41:06.836] iteration 9820: loss: 0.087824, loss_s1: 0.047222, loss_fp: 0.002079, loss_freq: 0.063170
[13:41:07.456] iteration 9821: loss: 0.109221, loss_s1: 0.054262, loss_fp: 0.002611, loss_freq: 0.077922
[13:41:08.074] iteration 9822: loss: 0.078427, loss_s1: 0.049278, loss_fp: 0.004975, loss_freq: 0.044024
[13:41:08.692] iteration 9823: loss: 0.098529, loss_s1: 0.066539, loss_fp: 0.003072, loss_freq: 0.020788
[13:41:09.308] iteration 9824: loss: 0.104753, loss_s1: 0.075904, loss_fp: 0.009994, loss_freq: 0.021573
[13:41:09.922] iteration 9825: loss: 0.092105, loss_s1: 0.042988, loss_fp: 0.000834, loss_freq: 0.039039
[13:41:10.545] iteration 9826: loss: 0.057935, loss_s1: 0.039668, loss_fp: 0.001998, loss_freq: 0.014864
[13:41:11.166] iteration 9827: loss: 0.049030, loss_s1: 0.037764, loss_fp: 0.000803, loss_freq: 0.014917
[13:41:11.788] iteration 9828: loss: 0.048510, loss_s1: 0.011115, loss_fp: 0.001718, loss_freq: 0.032593
[13:41:12.411] iteration 9829: loss: 0.109807, loss_s1: 0.041256, loss_fp: 0.002570, loss_freq: 0.022849
[13:41:13.031] iteration 9830: loss: 0.087890, loss_s1: 0.019749, loss_fp: 0.001707, loss_freq: 0.040221
[13:41:13.653] iteration 9831: loss: 0.140718, loss_s1: 0.117897, loss_fp: 0.001501, loss_freq: 0.075994
[13:41:14.273] iteration 9832: loss: 0.128029, loss_s1: 0.140374, loss_fp: 0.004052, loss_freq: 0.043554
[13:41:14.896] iteration 9833: loss: 0.062856, loss_s1: 0.022505, loss_fp: 0.002743, loss_freq: 0.011486
[13:41:15.518] iteration 9834: loss: 0.065855, loss_s1: 0.037803, loss_fp: 0.006969, loss_freq: 0.022092
[13:41:16.144] iteration 9835: loss: 0.072119, loss_s1: 0.027903, loss_fp: 0.003652, loss_freq: 0.006752
[13:41:16.768] iteration 9836: loss: 0.083197, loss_s1: 0.076224, loss_fp: 0.000654, loss_freq: 0.026729
[13:41:17.391] iteration 9837: loss: 0.098065, loss_s1: 0.050075, loss_fp: 0.000720, loss_freq: 0.043628
[13:41:18.012] iteration 9838: loss: 0.085049, loss_s1: 0.086670, loss_fp: 0.002905, loss_freq: 0.021899
[13:41:18.639] iteration 9839: loss: 0.145467, loss_s1: 0.050734, loss_fp: 0.006802, loss_freq: 0.040155
[13:41:19.268] iteration 9840: loss: 0.048017, loss_s1: 0.021305, loss_fp: 0.000838, loss_freq: 0.011675
[13:41:19.890] iteration 9841: loss: 0.103620, loss_s1: 0.099826, loss_fp: 0.002203, loss_freq: 0.040027
[13:41:20.515] iteration 9842: loss: 0.096138, loss_s1: 0.083728, loss_fp: 0.001736, loss_freq: 0.035810
[13:41:21.140] iteration 9843: loss: 0.067569, loss_s1: 0.052886, loss_fp: 0.001219, loss_freq: 0.026840
[13:41:21.765] iteration 9844: loss: 0.095944, loss_s1: 0.101004, loss_fp: 0.003064, loss_freq: 0.035533
[13:41:22.391] iteration 9845: loss: 0.106010, loss_s1: 0.073818, loss_fp: 0.003887, loss_freq: 0.070786
[13:41:23.016] iteration 9846: loss: 0.092020, loss_s1: 0.031296, loss_fp: 0.005292, loss_freq: 0.030148
[13:41:23.642] iteration 9847: loss: 0.068040, loss_s1: 0.069268, loss_fp: 0.001169, loss_freq: 0.012680
[13:41:24.268] iteration 9848: loss: 0.076935, loss_s1: 0.060719, loss_fp: 0.002629, loss_freq: 0.031867
[13:41:24.894] iteration 9849: loss: 0.069791, loss_s1: 0.057179, loss_fp: 0.003692, loss_freq: 0.037162
[13:41:25.520] iteration 9850: loss: 0.071985, loss_s1: 0.036505, loss_fp: 0.001828, loss_freq: 0.016626
[13:41:26.140] iteration 9851: loss: 0.088122, loss_s1: 0.074848, loss_fp: 0.001434, loss_freq: 0.033308
[13:41:26.759] iteration 9852: loss: 0.051250, loss_s1: 0.011215, loss_fp: 0.001033, loss_freq: 0.011803
[13:41:27.382] iteration 9853: loss: 0.129388, loss_s1: 0.081925, loss_fp: 0.003680, loss_freq: 0.014937
[13:41:28.002] iteration 9854: loss: 0.059774, loss_s1: 0.020544, loss_fp: 0.002428, loss_freq: 0.030607
[13:41:28.621] iteration 9855: loss: 0.054960, loss_s1: 0.023481, loss_fp: 0.002109, loss_freq: 0.010379
[13:41:29.241] iteration 9856: loss: 0.117653, loss_s1: 0.057205, loss_fp: 0.020016, loss_freq: 0.016387
[13:41:29.860] iteration 9857: loss: 0.064449, loss_s1: 0.040944, loss_fp: 0.001465, loss_freq: 0.019488
[13:41:30.480] iteration 9858: loss: 0.123455, loss_s1: 0.060138, loss_fp: 0.003353, loss_freq: 0.054501
[13:41:31.101] iteration 9859: loss: 0.091408, loss_s1: 0.019728, loss_fp: 0.005517, loss_freq: 0.047302
[13:41:31.723] iteration 9860: loss: 0.086464, loss_s1: 0.041549, loss_fp: 0.005476, loss_freq: 0.013617
[13:41:32.395] iteration 9861: loss: 0.096895, loss_s1: 0.051465, loss_fp: 0.001830, loss_freq: 0.032270
[13:41:33.049] iteration 9862: loss: 0.074463, loss_s1: 0.010994, loss_fp: 0.001711, loss_freq: 0.014112
[13:41:33.698] iteration 9863: loss: 0.071746, loss_s1: 0.052701, loss_fp: 0.003941, loss_freq: 0.027088
[13:41:34.350] iteration 9864: loss: 0.127217, loss_s1: 0.056838, loss_fp: 0.002423, loss_freq: 0.013504
[13:41:34.995] iteration 9865: loss: 0.088438, loss_s1: 0.073025, loss_fp: 0.004873, loss_freq: 0.047901
[13:41:35.608] iteration 9866: loss: 0.104990, loss_s1: 0.095870, loss_fp: 0.007032, loss_freq: 0.032924
[13:41:36.228] iteration 9867: loss: 0.069355, loss_s1: 0.052202, loss_fp: 0.001211, loss_freq: 0.017548
[13:41:37.204] iteration 9868: loss: 0.072529, loss_s1: 0.071685, loss_fp: 0.001561, loss_freq: 0.017718
[13:41:37.867] iteration 9869: loss: 0.071711, loss_s1: 0.029832, loss_fp: 0.002219, loss_freq: 0.035670
[13:41:38.523] iteration 9870: loss: 0.093242, loss_s1: 0.059935, loss_fp: 0.007252, loss_freq: 0.054573
[13:41:39.191] iteration 9871: loss: 0.090159, loss_s1: 0.031679, loss_fp: 0.000927, loss_freq: 0.014224
[13:41:39.844] iteration 9872: loss: 0.111151, loss_s1: 0.091589, loss_fp: 0.011899, loss_freq: 0.046833
[13:41:40.470] iteration 9873: loss: 0.092386, loss_s1: 0.028436, loss_fp: 0.006362, loss_freq: 0.012190
[13:41:41.131] iteration 9874: loss: 0.072461, loss_s1: 0.061884, loss_fp: 0.001517, loss_freq: 0.042533
[13:41:41.788] iteration 9875: loss: 0.154610, loss_s1: 0.126418, loss_fp: 0.001141, loss_freq: 0.022981
[13:41:42.453] iteration 9876: loss: 0.104176, loss_s1: 0.080493, loss_fp: 0.003668, loss_freq: 0.057241
[13:41:43.124] iteration 9877: loss: 0.092732, loss_s1: 0.035661, loss_fp: 0.001238, loss_freq: 0.025206
[13:41:43.756] iteration 9878: loss: 0.105599, loss_s1: 0.081089, loss_fp: 0.002288, loss_freq: 0.060747
[13:41:44.396] iteration 9879: loss: 0.063426, loss_s1: 0.005816, loss_fp: 0.002027, loss_freq: 0.053059
[13:41:45.037] iteration 9880: loss: 0.050907, loss_s1: 0.012310, loss_fp: 0.001014, loss_freq: 0.010071
[13:41:45.696] iteration 9881: loss: 0.106538, loss_s1: 0.076406, loss_fp: 0.002158, loss_freq: 0.078634
[13:41:46.361] iteration 9882: loss: 0.098293, loss_s1: 0.086930, loss_fp: 0.001256, loss_freq: 0.025419
[13:41:47.095] iteration 9883: loss: 0.061719, loss_s1: 0.032962, loss_fp: 0.001042, loss_freq: 0.014617
[13:41:47.716] iteration 9884: loss: 0.108506, loss_s1: 0.041591, loss_fp: 0.000436, loss_freq: 0.018460
[13:41:48.337] iteration 9885: loss: 0.124145, loss_s1: 0.067246, loss_fp: 0.003027, loss_freq: 0.030797
[13:41:48.960] iteration 9886: loss: 0.087411, loss_s1: 0.073541, loss_fp: 0.001770, loss_freq: 0.025079
[13:41:49.587] iteration 9887: loss: 0.074675, loss_s1: 0.042729, loss_fp: 0.007199, loss_freq: 0.016240
[13:41:50.210] iteration 9888: loss: 0.114207, loss_s1: 0.037996, loss_fp: 0.001278, loss_freq: 0.055136
[13:41:50.848] iteration 9889: loss: 0.086832, loss_s1: 0.041244, loss_fp: 0.003651, loss_freq: 0.058534
[13:41:51.507] iteration 9890: loss: 0.069710, loss_s1: 0.040937, loss_fp: 0.002790, loss_freq: 0.018531
[13:41:52.181] iteration 9891: loss: 0.078935, loss_s1: 0.051596, loss_fp: 0.007669, loss_freq: 0.019936
[13:41:52.840] iteration 9892: loss: 0.063496, loss_s1: 0.026115, loss_fp: 0.001015, loss_freq: 0.028696
[13:41:53.470] iteration 9893: loss: 0.125050, loss_s1: 0.113257, loss_fp: 0.002488, loss_freq: 0.067207
[13:41:54.094] iteration 9894: loss: 0.097076, loss_s1: 0.030346, loss_fp: 0.001824, loss_freq: 0.047284
[13:41:54.710] iteration 9895: loss: 0.068466, loss_s1: 0.049896, loss_fp: 0.001974, loss_freq: 0.020507
[13:41:55.333] iteration 9896: loss: 0.098408, loss_s1: 0.043751, loss_fp: 0.001147, loss_freq: 0.049271
[13:41:55.983] iteration 9897: loss: 0.122777, loss_s1: 0.031435, loss_fp: 0.004848, loss_freq: 0.017208
[13:41:56.602] iteration 9898: loss: 0.085415, loss_s1: 0.034926, loss_fp: 0.001087, loss_freq: 0.013097
[13:41:57.226] iteration 9899: loss: 0.097968, loss_s1: 0.071509, loss_fp: 0.001182, loss_freq: 0.022167
[13:41:57.843] iteration 9900: loss: 0.051024, loss_s1: 0.030329, loss_fp: 0.002469, loss_freq: 0.016068
[13:41:58.494] iteration 9901: loss: 0.096792, loss_s1: 0.041336, loss_fp: 0.002009, loss_freq: 0.034055
[13:41:59.153] iteration 9902: loss: 0.133571, loss_s1: 0.036100, loss_fp: 0.000459, loss_freq: 0.028618
[13:41:59.807] iteration 9903: loss: 0.080528, loss_s1: 0.062384, loss_fp: 0.003756, loss_freq: 0.024709
[13:42:00.469] iteration 9904: loss: 0.103519, loss_s1: 0.078094, loss_fp: 0.001862, loss_freq: 0.042834
[13:42:01.170] iteration 9905: loss: 0.065175, loss_s1: 0.028736, loss_fp: 0.001563, loss_freq: 0.042740
[13:42:01.794] iteration 9906: loss: 0.083967, loss_s1: 0.039017, loss_fp: 0.002331, loss_freq: 0.026555
[13:42:02.436] iteration 9907: loss: 0.069133, loss_s1: 0.047898, loss_fp: 0.005554, loss_freq: 0.020728
[13:42:03.130] iteration 9908: loss: 0.089917, loss_s1: 0.023358, loss_fp: 0.001360, loss_freq: 0.006874
[13:42:03.785] iteration 9909: loss: 0.039547, loss_s1: 0.030456, loss_fp: 0.001915, loss_freq: 0.009274
[13:42:04.439] iteration 9910: loss: 0.104847, loss_s1: 0.073045, loss_fp: 0.000532, loss_freq: 0.027244
[13:42:05.087] iteration 9911: loss: 0.052658, loss_s1: 0.027337, loss_fp: 0.002319, loss_freq: 0.030551
[13:42:05.709] iteration 9912: loss: 0.143077, loss_s1: 0.049043, loss_fp: 0.010231, loss_freq: 0.007114
[13:42:06.329] iteration 9913: loss: 0.090707, loss_s1: 0.051348, loss_fp: 0.002390, loss_freq: 0.057761
[13:42:06.950] iteration 9914: loss: 0.075791, loss_s1: 0.023529, loss_fp: 0.002590, loss_freq: 0.028628
[13:42:07.571] iteration 9915: loss: 0.057634, loss_s1: 0.020629, loss_fp: 0.001037, loss_freq: 0.028836
[13:42:08.190] iteration 9916: loss: 0.046636, loss_s1: 0.021477, loss_fp: 0.002149, loss_freq: 0.018587
[13:42:08.810] iteration 9917: loss: 0.059030, loss_s1: 0.034272, loss_fp: 0.002205, loss_freq: 0.023798
[13:42:09.430] iteration 9918: loss: 0.063484, loss_s1: 0.032604, loss_fp: 0.000890, loss_freq: 0.014009
[13:42:10.052] iteration 9919: loss: 0.172449, loss_s1: 0.022304, loss_fp: 0.001370, loss_freq: 0.031238
[13:42:10.674] iteration 9920: loss: 0.057035, loss_s1: 0.008750, loss_fp: 0.001158, loss_freq: 0.008280
[13:42:11.294] iteration 9921: loss: 0.067942, loss_s1: 0.027008, loss_fp: 0.001671, loss_freq: 0.014608
[13:42:11.915] iteration 9922: loss: 0.058115, loss_s1: 0.034413, loss_fp: 0.002925, loss_freq: 0.014625
[13:42:12.550] iteration 9923: loss: 0.050617, loss_s1: 0.003072, loss_fp: 0.000327, loss_freq: 0.013090
[13:42:13.232] iteration 9924: loss: 0.084919, loss_s1: 0.040441, loss_fp: 0.006931, loss_freq: 0.032750
[13:42:13.899] iteration 9925: loss: 0.095452, loss_s1: 0.054787, loss_fp: 0.001504, loss_freq: 0.019085
[13:42:14.561] iteration 9926: loss: 0.122622, loss_s1: 0.062134, loss_fp: 0.007187, loss_freq: 0.068151
[13:42:15.216] iteration 9927: loss: 0.069568, loss_s1: 0.027274, loss_fp: 0.007527, loss_freq: 0.030923
[13:42:15.868] iteration 9928: loss: 0.084536, loss_s1: 0.036607, loss_fp: 0.002870, loss_freq: 0.025321
[13:42:16.498] iteration 9929: loss: 0.079531, loss_s1: 0.041965, loss_fp: 0.004054, loss_freq: 0.034462
[13:42:17.147] iteration 9930: loss: 0.072293, loss_s1: 0.054371, loss_fp: 0.001792, loss_freq: 0.011865
[13:42:17.803] iteration 9931: loss: 0.067373, loss_s1: 0.041391, loss_fp: 0.001940, loss_freq: 0.010754
[13:42:18.463] iteration 9932: loss: 0.115536, loss_s1: 0.068600, loss_fp: 0.007018, loss_freq: 0.068734
[13:42:19.111] iteration 9933: loss: 0.098535, loss_s1: 0.074877, loss_fp: 0.002088, loss_freq: 0.017508
[13:42:19.753] iteration 9934: loss: 0.074907, loss_s1: 0.026236, loss_fp: 0.001652, loss_freq: 0.059116
[13:42:20.375] iteration 9935: loss: 0.061381, loss_s1: 0.040803, loss_fp: 0.002684, loss_freq: 0.023313
[13:42:21.005] iteration 9936: loss: 0.076381, loss_s1: 0.064912, loss_fp: 0.002050, loss_freq: 0.015955
[13:42:21.646] iteration 9937: loss: 0.097973, loss_s1: 0.038771, loss_fp: 0.001991, loss_freq: 0.011200
[13:42:22.267] iteration 9938: loss: 0.093574, loss_s1: 0.072120, loss_fp: 0.001217, loss_freq: 0.037342
[13:42:22.895] iteration 9939: loss: 0.068478, loss_s1: 0.028947, loss_fp: 0.008439, loss_freq: 0.032956
[13:42:23.509] iteration 9940: loss: 0.085216, loss_s1: 0.054325, loss_fp: 0.002806, loss_freq: 0.048852
[13:42:24.198] iteration 9941: loss: 0.120048, loss_s1: 0.076717, loss_fp: 0.007711, loss_freq: 0.041393
[13:42:24.858] iteration 9942: loss: 0.098617, loss_s1: 0.072731, loss_fp: 0.016937, loss_freq: 0.062610
[13:42:25.514] iteration 9943: loss: 0.088463, loss_s1: 0.056303, loss_fp: 0.007772, loss_freq: 0.017266
[13:42:26.155] iteration 9944: loss: 0.047962, loss_s1: 0.047318, loss_fp: 0.001524, loss_freq: 0.008994
[13:42:26.775] iteration 9945: loss: 0.062555, loss_s1: 0.033579, loss_fp: 0.001434, loss_freq: 0.009826
[13:42:27.398] iteration 9946: loss: 0.064375, loss_s1: 0.033298, loss_fp: 0.008033, loss_freq: 0.025929
[13:42:28.018] iteration 9947: loss: 0.145797, loss_s1: 0.089557, loss_fp: 0.000802, loss_freq: 0.028240
[13:42:28.639] iteration 9948: loss: 0.048939, loss_s1: 0.019283, loss_fp: 0.000884, loss_freq: 0.013249
[13:42:29.260] iteration 9949: loss: 0.086634, loss_s1: 0.065839, loss_fp: 0.000863, loss_freq: 0.020848
[13:42:29.884] iteration 9950: loss: 0.082628, loss_s1: 0.061805, loss_fp: 0.001311, loss_freq: 0.015901
[13:42:30.531] iteration 9951: loss: 0.073640, loss_s1: 0.070111, loss_fp: 0.001842, loss_freq: 0.026541
[13:42:31.150] iteration 9952: loss: 0.078370, loss_s1: 0.036787, loss_fp: 0.006708, loss_freq: 0.029445
[13:42:31.772] iteration 9953: loss: 0.063302, loss_s1: 0.036839, loss_fp: 0.002137, loss_freq: 0.035447
[13:42:32.393] iteration 9954: loss: 0.074619, loss_s1: 0.028158, loss_fp: 0.002935, loss_freq: 0.009164
[13:42:33.019] iteration 9955: loss: 0.105141, loss_s1: 0.053237, loss_fp: 0.001324, loss_freq: 0.034834
[13:42:33.644] iteration 9956: loss: 0.087825, loss_s1: 0.071079, loss_fp: 0.002250, loss_freq: 0.016416
[13:42:34.268] iteration 9957: loss: 0.061030, loss_s1: 0.035231, loss_fp: 0.001903, loss_freq: 0.027535
[13:42:34.916] iteration 9958: loss: 0.078598, loss_s1: 0.025933, loss_fp: 0.001133, loss_freq: 0.024649
[13:42:35.540] iteration 9959: loss: 0.062850, loss_s1: 0.036410, loss_fp: 0.003345, loss_freq: 0.037364
[13:42:36.163] iteration 9960: loss: 0.073448, loss_s1: 0.075713, loss_fp: 0.000926, loss_freq: 0.018488
[13:42:36.793] iteration 9961: loss: 0.111267, loss_s1: 0.021096, loss_fp: 0.007495, loss_freq: 0.011523
[13:42:37.415] iteration 9962: loss: 0.040366, loss_s1: 0.015717, loss_fp: 0.002060, loss_freq: 0.011361
[13:42:38.041] iteration 9963: loss: 0.069730, loss_s1: 0.025763, loss_fp: 0.001002, loss_freq: 0.022810
[13:42:38.664] iteration 9964: loss: 0.129533, loss_s1: 0.065894, loss_fp: 0.006626, loss_freq: 0.118592
[13:42:39.286] iteration 9965: loss: 0.086538, loss_s1: 0.033317, loss_fp: 0.006519, loss_freq: 0.034153
[13:42:39.908] iteration 9966: loss: 0.085972, loss_s1: 0.033118, loss_fp: 0.002688, loss_freq: 0.048172
[13:42:40.540] iteration 9967: loss: 0.076019, loss_s1: 0.023374, loss_fp: 0.002950, loss_freq: 0.042812
[13:42:41.164] iteration 9968: loss: 0.067376, loss_s1: 0.027613, loss_fp: 0.002486, loss_freq: 0.035385
[13:42:41.789] iteration 9969: loss: 0.110657, loss_s1: 0.039809, loss_fp: 0.001568, loss_freq: 0.021289
[13:42:42.411] iteration 9970: loss: 0.080817, loss_s1: 0.055407, loss_fp: 0.005928, loss_freq: 0.026522
[13:42:43.037] iteration 9971: loss: 0.059897, loss_s1: 0.017037, loss_fp: 0.002538, loss_freq: 0.027761
[13:42:43.660] iteration 9972: loss: 0.144931, loss_s1: 0.052180, loss_fp: 0.005677, loss_freq: 0.029301
[13:42:44.282] iteration 9973: loss: 0.081776, loss_s1: 0.042362, loss_fp: 0.002407, loss_freq: 0.039214
[13:42:44.903] iteration 9974: loss: 0.151512, loss_s1: 0.108785, loss_fp: 0.000688, loss_freq: 0.111118
[13:42:45.525] iteration 9975: loss: 0.060498, loss_s1: 0.025184, loss_fp: 0.002657, loss_freq: 0.032138
[13:42:46.139] iteration 9976: loss: 0.069742, loss_s1: 0.064002, loss_fp: 0.001263, loss_freq: 0.009333
[13:42:46.756] iteration 9977: loss: 0.110313, loss_s1: 0.075980, loss_fp: 0.002949, loss_freq: 0.075232
[13:42:47.377] iteration 9978: loss: 0.078818, loss_s1: 0.020762, loss_fp: 0.001025, loss_freq: 0.022377
[13:42:47.998] iteration 9979: loss: 0.094401, loss_s1: 0.076067, loss_fp: 0.004634, loss_freq: 0.034062
[13:42:48.617] iteration 9980: loss: 0.076340, loss_s1: 0.036498, loss_fp: 0.004941, loss_freq: 0.016459
[13:42:49.245] iteration 9981: loss: 0.073026, loss_s1: 0.049057, loss_fp: 0.001578, loss_freq: 0.043505
[13:42:49.895] iteration 9982: loss: 0.152688, loss_s1: 0.055711, loss_fp: 0.003833, loss_freq: 0.050056
[13:42:50.553] iteration 9983: loss: 0.105325, loss_s1: 0.062290, loss_fp: 0.003116, loss_freq: 0.025101
[13:42:51.207] iteration 9984: loss: 0.099186, loss_s1: 0.065224, loss_fp: 0.001600, loss_freq: 0.053061
[13:42:51.872] iteration 9985: loss: 0.067580, loss_s1: 0.026162, loss_fp: 0.002916, loss_freq: 0.042301
[13:42:52.538] iteration 9986: loss: 0.061003, loss_s1: 0.056009, loss_fp: 0.001179, loss_freq: 0.014044
[13:42:53.198] iteration 9987: loss: 0.075740, loss_s1: 0.056113, loss_fp: 0.002171, loss_freq: 0.016886
[13:42:53.844] iteration 9988: loss: 0.098396, loss_s1: 0.080509, loss_fp: 0.002873, loss_freq: 0.061309
[13:42:54.503] iteration 9989: loss: 0.082500, loss_s1: 0.051557, loss_fp: 0.002752, loss_freq: 0.018600
[13:42:55.154] iteration 9990: loss: 0.066149, loss_s1: 0.046224, loss_fp: 0.001077, loss_freq: 0.013403
[13:42:55.811] iteration 9991: loss: 0.067425, loss_s1: 0.051171, loss_fp: 0.005235, loss_freq: 0.034872
[13:42:56.432] iteration 9992: loss: 0.078246, loss_s1: 0.083507, loss_fp: 0.005903, loss_freq: 0.026904
[13:42:57.055] iteration 9993: loss: 0.119329, loss_s1: 0.031190, loss_fp: 0.001312, loss_freq: 0.027242
[13:42:57.708] iteration 9994: loss: 0.053392, loss_s1: 0.024670, loss_fp: 0.001269, loss_freq: 0.014321
[13:42:58.333] iteration 9995: loss: 0.082882, loss_s1: 0.062803, loss_fp: 0.001330, loss_freq: 0.023969
[13:42:58.972] iteration 9996: loss: 0.058846, loss_s1: 0.039451, loss_fp: 0.001298, loss_freq: 0.008047
[13:42:59.596] iteration 9997: loss: 0.056223, loss_s1: 0.034448, loss_fp: 0.004374, loss_freq: 0.009395
[13:43:00.216] iteration 9998: loss: 0.051944, loss_s1: 0.021385, loss_fp: 0.001190, loss_freq: 0.011016
[13:43:00.839] iteration 9999: loss: 0.091462, loss_s1: 0.051497, loss_fp: 0.005529, loss_freq: 0.032750
[13:43:01.465] iteration 10000: loss: 0.076520, loss_s1: 0.048518, loss_fp: 0.006301, loss_freq: 0.031529
[13:43:04.678] iteration 10000 : mean_dice : 0.743284
[13:43:05.325] iteration 10001: loss: 0.091317, loss_s1: 0.056804, loss_fp: 0.004291, loss_freq: 0.035635
[13:43:05.947] iteration 10002: loss: 0.068642, loss_s1: 0.022975, loss_fp: 0.001843, loss_freq: 0.023876
[13:43:06.568] iteration 10003: loss: 0.091752, loss_s1: 0.091841, loss_fp: 0.002326, loss_freq: 0.024871
[13:43:07.196] iteration 10004: loss: 0.055949, loss_s1: 0.034127, loss_fp: 0.003920, loss_freq: 0.010896
[13:43:07.817] iteration 10005: loss: 0.050275, loss_s1: 0.017805, loss_fp: 0.000671, loss_freq: 0.015476
[13:43:08.442] iteration 10006: loss: 0.078802, loss_s1: 0.037467, loss_fp: 0.001978, loss_freq: 0.032259
[13:43:09.069] iteration 10007: loss: 0.127943, loss_s1: 0.058388, loss_fp: 0.010950, loss_freq: 0.033381
[13:43:09.686] iteration 10008: loss: 0.089656, loss_s1: 0.054097, loss_fp: 0.001826, loss_freq: 0.031134
[13:43:10.305] iteration 10009: loss: 0.096892, loss_s1: 0.097407, loss_fp: 0.001321, loss_freq: 0.019161
[13:43:10.919] iteration 10010: loss: 0.058959, loss_s1: 0.026336, loss_fp: 0.000745, loss_freq: 0.035737
[13:43:11.949] iteration 10011: loss: 0.060939, loss_s1: 0.035408, loss_fp: 0.001347, loss_freq: 0.016574
[13:43:12.612] iteration 10012: loss: 0.084538, loss_s1: 0.059315, loss_fp: 0.000961, loss_freq: 0.019182
[13:43:13.265] iteration 10013: loss: 0.044064, loss_s1: 0.023012, loss_fp: 0.000899, loss_freq: 0.016401
[13:43:13.914] iteration 10014: loss: 0.062573, loss_s1: 0.024724, loss_fp: 0.014656, loss_freq: 0.018327
[13:43:14.566] iteration 10015: loss: 0.073216, loss_s1: 0.037475, loss_fp: 0.001987, loss_freq: 0.026323
[13:43:15.216] iteration 10016: loss: 0.073293, loss_s1: 0.015854, loss_fp: 0.000677, loss_freq: 0.010519
[13:43:15.845] iteration 10017: loss: 0.064187, loss_s1: 0.065452, loss_fp: 0.004113, loss_freq: 0.020876
[13:43:16.464] iteration 10018: loss: 0.129100, loss_s1: 0.097995, loss_fp: 0.001275, loss_freq: 0.037058
[13:43:17.104] iteration 10019: loss: 0.050915, loss_s1: 0.009871, loss_fp: 0.001750, loss_freq: 0.013042
[13:43:17.717] iteration 10020: loss: 0.150147, loss_s1: 0.008000, loss_fp: 0.001039, loss_freq: 0.006733
[13:43:18.340] iteration 10021: loss: 0.092883, loss_s1: 0.062519, loss_fp: 0.007771, loss_freq: 0.037273
[13:43:18.992] iteration 10022: loss: 0.063430, loss_s1: 0.023683, loss_fp: 0.001697, loss_freq: 0.030860
[13:43:19.646] iteration 10023: loss: 0.099358, loss_s1: 0.106632, loss_fp: 0.001770, loss_freq: 0.016480
[13:43:20.300] iteration 10024: loss: 0.064187, loss_s1: 0.035091, loss_fp: 0.003319, loss_freq: 0.033495
[13:43:20.955] iteration 10025: loss: 0.084356, loss_s1: 0.070863, loss_fp: 0.002791, loss_freq: 0.037294
[13:43:21.600] iteration 10026: loss: 0.059689, loss_s1: 0.043299, loss_fp: 0.002062, loss_freq: 0.021414
[13:43:22.251] iteration 10027: loss: 0.149074, loss_s1: 0.064577, loss_fp: 0.000910, loss_freq: 0.018559
[13:43:22.867] iteration 10028: loss: 0.122892, loss_s1: 0.092035, loss_fp: 0.016499, loss_freq: 0.029520
[13:43:23.494] iteration 10029: loss: 0.055407, loss_s1: 0.021960, loss_fp: 0.001899, loss_freq: 0.022509
[13:43:24.154] iteration 10030: loss: 0.101039, loss_s1: 0.045805, loss_fp: 0.000816, loss_freq: 0.023832
[13:43:24.815] iteration 10031: loss: 0.105780, loss_s1: 0.036618, loss_fp: 0.004865, loss_freq: 0.064345
[13:43:25.455] iteration 10032: loss: 0.085900, loss_s1: 0.051468, loss_fp: 0.003094, loss_freq: 0.022895
[13:43:26.083] iteration 10033: loss: 0.049361, loss_s1: 0.020797, loss_fp: 0.003360, loss_freq: 0.023141
[13:43:26.705] iteration 10034: loss: 0.100795, loss_s1: 0.045942, loss_fp: 0.001839, loss_freq: 0.013513
[13:43:27.330] iteration 10035: loss: 0.048306, loss_s1: 0.024336, loss_fp: 0.002124, loss_freq: 0.017950
[13:43:27.950] iteration 10036: loss: 0.075977, loss_s1: 0.037599, loss_fp: 0.001465, loss_freq: 0.032324
[13:43:28.578] iteration 10037: loss: 0.087484, loss_s1: 0.045049, loss_fp: 0.001182, loss_freq: 0.065846
[13:43:29.195] iteration 10038: loss: 0.066650, loss_s1: 0.042853, loss_fp: 0.002579, loss_freq: 0.018412
[13:43:29.857] iteration 10039: loss: 0.136072, loss_s1: 0.114274, loss_fp: 0.001372, loss_freq: 0.049854
[13:43:30.484] iteration 10040: loss: 0.085136, loss_s1: 0.035898, loss_fp: 0.006253, loss_freq: 0.011263
[13:43:31.109] iteration 10041: loss: 0.054894, loss_s1: 0.043466, loss_fp: 0.001668, loss_freq: 0.010365
[13:43:31.739] iteration 10042: loss: 0.088264, loss_s1: 0.029104, loss_fp: 0.002361, loss_freq: 0.040070
[13:43:32.371] iteration 10043: loss: 0.059779, loss_s1: 0.032613, loss_fp: 0.002154, loss_freq: 0.008741
[13:43:33.000] iteration 10044: loss: 0.086444, loss_s1: 0.070926, loss_fp: 0.002707, loss_freq: 0.029134
[13:43:33.627] iteration 10045: loss: 0.120403, loss_s1: 0.046252, loss_fp: 0.002652, loss_freq: 0.040380
[13:43:34.261] iteration 10046: loss: 0.091784, loss_s1: 0.037004, loss_fp: 0.032895, loss_freq: 0.037445
[13:43:34.890] iteration 10047: loss: 0.092015, loss_s1: 0.054858, loss_fp: 0.009178, loss_freq: 0.029659
[13:43:35.516] iteration 10048: loss: 0.053734, loss_s1: 0.012688, loss_fp: 0.007692, loss_freq: 0.012641
[13:43:36.151] iteration 10049: loss: 0.086760, loss_s1: 0.062403, loss_fp: 0.001569, loss_freq: 0.037794
[13:43:36.767] iteration 10050: loss: 0.083608, loss_s1: 0.089030, loss_fp: 0.010016, loss_freq: 0.008423
[13:43:37.421] iteration 10051: loss: 0.094394, loss_s1: 0.064368, loss_fp: 0.002827, loss_freq: 0.013586
[13:43:38.040] iteration 10052: loss: 0.050683, loss_s1: 0.026407, loss_fp: 0.002871, loss_freq: 0.025069
[13:43:38.658] iteration 10053: loss: 0.071228, loss_s1: 0.039509, loss_fp: 0.000736, loss_freq: 0.012506
[13:43:39.279] iteration 10054: loss: 0.085697, loss_s1: 0.072688, loss_fp: 0.006176, loss_freq: 0.044327
[13:43:39.893] iteration 10055: loss: 0.089703, loss_s1: 0.015304, loss_fp: 0.001464, loss_freq: 0.005302
[13:43:40.507] iteration 10056: loss: 0.126736, loss_s1: 0.160866, loss_fp: 0.004130, loss_freq: 0.030343
[13:43:41.124] iteration 10057: loss: 0.077206, loss_s1: 0.027998, loss_fp: 0.005168, loss_freq: 0.041745
[13:43:41.738] iteration 10058: loss: 0.078580, loss_s1: 0.047068, loss_fp: 0.003210, loss_freq: 0.031677
[13:43:42.357] iteration 10059: loss: 0.050832, loss_s1: 0.033733, loss_fp: 0.002146, loss_freq: 0.023379
[13:43:42.966] iteration 10060: loss: 0.084344, loss_s1: 0.042148, loss_fp: 0.000758, loss_freq: 0.042577
[13:43:43.583] iteration 10061: loss: 0.079141, loss_s1: 0.052931, loss_fp: 0.001263, loss_freq: 0.015331
[13:43:44.200] iteration 10062: loss: 0.144994, loss_s1: 0.027996, loss_fp: 0.001184, loss_freq: 0.039159
[13:43:44.813] iteration 10063: loss: 0.058305, loss_s1: 0.039506, loss_fp: 0.000798, loss_freq: 0.018516
[13:43:45.429] iteration 10064: loss: 0.048861, loss_s1: 0.036569, loss_fp: 0.001683, loss_freq: 0.008018
[13:43:46.044] iteration 10065: loss: 0.071373, loss_s1: 0.043269, loss_fp: 0.005650, loss_freq: 0.038281
[13:43:46.672] iteration 10066: loss: 0.072695, loss_s1: 0.032593, loss_fp: 0.010932, loss_freq: 0.006866
[13:43:47.304] iteration 10067: loss: 0.088431, loss_s1: 0.053905, loss_fp: 0.003186, loss_freq: 0.045603
[13:43:47.982] iteration 10068: loss: 0.090554, loss_s1: 0.071180, loss_fp: 0.005613, loss_freq: 0.037506
[13:43:48.638] iteration 10069: loss: 0.108233, loss_s1: 0.052593, loss_fp: 0.001417, loss_freq: 0.103216
[13:43:49.293] iteration 10070: loss: 0.071090, loss_s1: 0.029049, loss_fp: 0.005188, loss_freq: 0.036870
[13:43:49.959] iteration 10071: loss: 0.087592, loss_s1: 0.037470, loss_fp: 0.004174, loss_freq: 0.016879
[13:43:50.731] iteration 10072: loss: 0.096927, loss_s1: 0.033288, loss_fp: 0.008031, loss_freq: 0.011780
[13:43:51.368] iteration 10073: loss: 0.121248, loss_s1: 0.076501, loss_fp: 0.001885, loss_freq: 0.085017
[13:43:52.065] iteration 10074: loss: 0.123868, loss_s1: 0.025981, loss_fp: 0.003981, loss_freq: 0.015286
[13:43:52.697] iteration 10075: loss: 0.098486, loss_s1: 0.018804, loss_fp: 0.001153, loss_freq: 0.095430
[13:43:53.333] iteration 10076: loss: 0.078409, loss_s1: 0.021443, loss_fp: 0.002564, loss_freq: 0.027495
[13:43:53.953] iteration 10077: loss: 0.139218, loss_s1: 0.097124, loss_fp: 0.002322, loss_freq: 0.062529
[13:43:54.565] iteration 10078: loss: 0.048008, loss_s1: 0.021504, loss_fp: 0.002376, loss_freq: 0.015389
[13:43:55.186] iteration 10079: loss: 0.099733, loss_s1: 0.082530, loss_fp: 0.003672, loss_freq: 0.031514
[13:43:55.803] iteration 10080: loss: 0.084809, loss_s1: 0.022881, loss_fp: 0.003479, loss_freq: 0.020716
[13:43:56.438] iteration 10081: loss: 0.055603, loss_s1: 0.021722, loss_fp: 0.002119, loss_freq: 0.019602
[13:43:57.054] iteration 10082: loss: 0.125045, loss_s1: 0.134551, loss_fp: 0.000682, loss_freq: 0.030832
[13:43:57.662] iteration 10083: loss: 0.076352, loss_s1: 0.009194, loss_fp: 0.017816, loss_freq: 0.067733
[13:43:58.276] iteration 10084: loss: 0.100516, loss_s1: 0.080611, loss_fp: 0.014753, loss_freq: 0.022866
[13:43:58.896] iteration 10085: loss: 0.083217, loss_s1: 0.081249, loss_fp: 0.006202, loss_freq: 0.015583
[13:43:59.518] iteration 10086: loss: 0.088491, loss_s1: 0.049615, loss_fp: 0.001490, loss_freq: 0.008596
[13:44:00.132] iteration 10087: loss: 0.054342, loss_s1: 0.053444, loss_fp: 0.001472, loss_freq: 0.008389
[13:44:00.786] iteration 10088: loss: 0.080227, loss_s1: 0.041249, loss_fp: 0.002006, loss_freq: 0.007780
[13:44:01.447] iteration 10089: loss: 0.088451, loss_s1: 0.084444, loss_fp: 0.001749, loss_freq: 0.021739
[13:44:02.109] iteration 10090: loss: 0.135899, loss_s1: 0.053281, loss_fp: 0.004535, loss_freq: 0.052574
[13:44:02.748] iteration 10091: loss: 0.065590, loss_s1: 0.018388, loss_fp: 0.000696, loss_freq: 0.049446
[13:44:03.365] iteration 10092: loss: 0.094959, loss_s1: 0.067164, loss_fp: 0.002315, loss_freq: 0.044010
[13:44:03.979] iteration 10093: loss: 0.075240, loss_s1: 0.053846, loss_fp: 0.001628, loss_freq: 0.026226
[13:44:04.594] iteration 10094: loss: 0.045381, loss_s1: 0.031923, loss_fp: 0.002584, loss_freq: 0.013364
[13:44:05.215] iteration 10095: loss: 0.059885, loss_s1: 0.034996, loss_fp: 0.009251, loss_freq: 0.009916
[13:44:05.832] iteration 10096: loss: 0.059661, loss_s1: 0.022917, loss_fp: 0.000584, loss_freq: 0.038430
[13:44:06.451] iteration 10097: loss: 0.062450, loss_s1: 0.025614, loss_fp: 0.001143, loss_freq: 0.004892
[13:44:07.066] iteration 10098: loss: 0.099449, loss_s1: 0.036902, loss_fp: 0.001289, loss_freq: 0.031465
[13:44:07.724] iteration 10099: loss: 0.074899, loss_s1: 0.074038, loss_fp: 0.000499, loss_freq: 0.011027
[13:44:08.365] iteration 10100: loss: 0.102066, loss_s1: 0.070471, loss_fp: 0.002383, loss_freq: 0.027868
[13:44:08.988] iteration 10101: loss: 0.094567, loss_s1: 0.015218, loss_fp: 0.002422, loss_freq: 0.030712
[13:44:09.608] iteration 10102: loss: 0.128178, loss_s1: 0.095672, loss_fp: 0.002220, loss_freq: 0.039025
[13:44:10.225] iteration 10103: loss: 0.076840, loss_s1: 0.057996, loss_fp: 0.002333, loss_freq: 0.019727
[13:44:10.848] iteration 10104: loss: 0.085703, loss_s1: 0.044026, loss_fp: 0.001355, loss_freq: 0.022028
[13:44:11.472] iteration 10105: loss: 0.056112, loss_s1: 0.020169, loss_fp: 0.002092, loss_freq: 0.025130
[13:44:12.096] iteration 10106: loss: 0.075771, loss_s1: 0.068136, loss_fp: 0.003677, loss_freq: 0.016615
[13:44:12.709] iteration 10107: loss: 0.092143, loss_s1: 0.047845, loss_fp: 0.002889, loss_freq: 0.077373
[13:44:13.325] iteration 10108: loss: 0.080390, loss_s1: 0.032709, loss_fp: 0.004960, loss_freq: 0.055819
[13:44:13.944] iteration 10109: loss: 0.063067, loss_s1: 0.037891, loss_fp: 0.003050, loss_freq: 0.020734
[13:44:14.560] iteration 10110: loss: 0.117340, loss_s1: 0.048947, loss_fp: 0.007424, loss_freq: 0.058605
[13:44:15.180] iteration 10111: loss: 0.072451, loss_s1: 0.046872, loss_fp: 0.000701, loss_freq: 0.017439
[13:44:15.799] iteration 10112: loss: 0.079779, loss_s1: 0.048177, loss_fp: 0.002482, loss_freq: 0.037004
[13:44:16.422] iteration 10113: loss: 0.080740, loss_s1: 0.052306, loss_fp: 0.006226, loss_freq: 0.012152
[13:44:17.034] iteration 10114: loss: 0.071630, loss_s1: 0.049301, loss_fp: 0.000663, loss_freq: 0.031069
[13:44:17.653] iteration 10115: loss: 0.102498, loss_s1: 0.025597, loss_fp: 0.002036, loss_freq: 0.035798
[13:44:18.269] iteration 10116: loss: 0.081909, loss_s1: 0.055243, loss_fp: 0.000571, loss_freq: 0.018934
[13:44:18.891] iteration 10117: loss: 0.117460, loss_s1: 0.089030, loss_fp: 0.001733, loss_freq: 0.078600
[13:44:19.507] iteration 10118: loss: 0.076344, loss_s1: 0.041969, loss_fp: 0.005469, loss_freq: 0.048515
[13:44:20.123] iteration 10119: loss: 0.060129, loss_s1: 0.032455, loss_fp: 0.000664, loss_freq: 0.009050
[13:44:20.747] iteration 10120: loss: 0.061651, loss_s1: 0.029631, loss_fp: 0.003155, loss_freq: 0.025437
[13:44:21.366] iteration 10121: loss: 0.103004, loss_s1: 0.057935, loss_fp: 0.001937, loss_freq: 0.025855
[13:44:21.983] iteration 10122: loss: 0.074611, loss_s1: 0.069578, loss_fp: 0.000863, loss_freq: 0.032121
[13:44:22.598] iteration 10123: loss: 0.086558, loss_s1: 0.047013, loss_fp: 0.001069, loss_freq: 0.024357
[13:44:23.221] iteration 10124: loss: 0.047562, loss_s1: 0.014834, loss_fp: 0.002980, loss_freq: 0.025056
[13:44:23.833] iteration 10125: loss: 0.121638, loss_s1: 0.026543, loss_fp: 0.001153, loss_freq: 0.017027
[13:44:24.443] iteration 10126: loss: 0.083755, loss_s1: 0.046953, loss_fp: 0.002510, loss_freq: 0.009345
[13:44:25.056] iteration 10127: loss: 0.087825, loss_s1: 0.060102, loss_fp: 0.000782, loss_freq: 0.043678
[13:44:25.681] iteration 10128: loss: 0.099790, loss_s1: 0.076004, loss_fp: 0.001264, loss_freq: 0.017077
[13:44:26.291] iteration 10129: loss: 0.071680, loss_s1: 0.067580, loss_fp: 0.001272, loss_freq: 0.025024
[13:44:26.914] iteration 10130: loss: 0.096671, loss_s1: 0.038847, loss_fp: 0.002861, loss_freq: 0.035544
[13:44:27.525] iteration 10131: loss: 0.078994, loss_s1: 0.022305, loss_fp: 0.002341, loss_freq: 0.052333
[13:44:28.161] iteration 10132: loss: 0.135885, loss_s1: 0.056899, loss_fp: 0.014020, loss_freq: 0.022201
[13:44:28.784] iteration 10133: loss: 0.041073, loss_s1: 0.023974, loss_fp: 0.001391, loss_freq: 0.005714
[13:44:29.404] iteration 10134: loss: 0.095777, loss_s1: 0.087209, loss_fp: 0.001792, loss_freq: 0.058272
[13:44:30.015] iteration 10135: loss: 0.065694, loss_s1: 0.071017, loss_fp: 0.000891, loss_freq: 0.013209
[13:44:30.637] iteration 10136: loss: 0.093371, loss_s1: 0.033270, loss_fp: 0.002076, loss_freq: 0.031668
[13:44:31.248] iteration 10137: loss: 0.055633, loss_s1: 0.015328, loss_fp: 0.003865, loss_freq: 0.046121
[13:44:31.857] iteration 10138: loss: 0.050321, loss_s1: 0.022391, loss_fp: 0.003418, loss_freq: 0.016821
[13:44:32.467] iteration 10139: loss: 0.079934, loss_s1: 0.042533, loss_fp: 0.004254, loss_freq: 0.022176
[13:44:33.078] iteration 10140: loss: 0.058937, loss_s1: 0.014334, loss_fp: 0.007353, loss_freq: 0.027093
[13:44:33.692] iteration 10141: loss: 0.058477, loss_s1: 0.031506, loss_fp: 0.001486, loss_freq: 0.007357
[13:44:34.310] iteration 10142: loss: 0.066481, loss_s1: 0.033052, loss_fp: 0.005844, loss_freq: 0.018736
[13:44:34.924] iteration 10143: loss: 0.067784, loss_s1: 0.048051, loss_fp: 0.001838, loss_freq: 0.020957
[13:44:35.543] iteration 10144: loss: 0.117605, loss_s1: 0.059831, loss_fp: 0.001649, loss_freq: 0.070824
[13:44:36.155] iteration 10145: loss: 0.137250, loss_s1: 0.052260, loss_fp: 0.002506, loss_freq: 0.057984
[13:44:36.766] iteration 10146: loss: 0.126176, loss_s1: 0.110804, loss_fp: 0.003600, loss_freq: 0.030852
[13:44:37.424] iteration 10147: loss: 0.099027, loss_s1: 0.047466, loss_fp: 0.006849, loss_freq: 0.018088
[13:44:38.085] iteration 10148: loss: 0.102730, loss_s1: 0.014314, loss_fp: 0.003343, loss_freq: 0.044487
[13:44:38.741] iteration 10149: loss: 0.052298, loss_s1: 0.021871, loss_fp: 0.007568, loss_freq: 0.015199
[13:44:39.396] iteration 10150: loss: 0.090910, loss_s1: 0.027030, loss_fp: 0.001955, loss_freq: 0.029428
[13:44:40.019] iteration 10151: loss: 0.095094, loss_s1: 0.069063, loss_fp: 0.005045, loss_freq: 0.030497
[13:44:40.630] iteration 10152: loss: 0.084873, loss_s1: 0.074851, loss_fp: 0.002678, loss_freq: 0.030180
[13:44:41.248] iteration 10153: loss: 0.073652, loss_s1: 0.031018, loss_fp: 0.001151, loss_freq: 0.029361
[13:44:42.215] iteration 10154: loss: 0.087177, loss_s1: 0.072813, loss_fp: 0.000712, loss_freq: 0.018963
[13:44:42.870] iteration 10155: loss: 0.083097, loss_s1: 0.069829, loss_fp: 0.005745, loss_freq: 0.022451
[13:44:43.529] iteration 10156: loss: 0.063670, loss_s1: 0.026588, loss_fp: 0.000910, loss_freq: 0.052748
[13:44:44.164] iteration 10157: loss: 0.064629, loss_s1: 0.026617, loss_fp: 0.002936, loss_freq: 0.030362
[13:44:44.823] iteration 10158: loss: 0.108785, loss_s1: 0.049337, loss_fp: 0.006520, loss_freq: 0.046978
[13:44:45.531] iteration 10159: loss: 0.080088, loss_s1: 0.039215, loss_fp: 0.000630, loss_freq: 0.003815
[13:44:46.193] iteration 10160: loss: 0.058846, loss_s1: 0.037805, loss_fp: 0.001515, loss_freq: 0.025325
[13:44:46.868] iteration 10161: loss: 0.100098, loss_s1: 0.052062, loss_fp: 0.002137, loss_freq: 0.042765
[13:44:47.515] iteration 10162: loss: 0.056370, loss_s1: 0.025904, loss_fp: 0.001102, loss_freq: 0.025261
[13:44:48.136] iteration 10163: loss: 0.087359, loss_s1: 0.026019, loss_fp: 0.000939, loss_freq: 0.006780
[13:44:48.765] iteration 10164: loss: 0.086352, loss_s1: 0.058359, loss_fp: 0.001066, loss_freq: 0.025706
[13:44:49.393] iteration 10165: loss: 0.083986, loss_s1: 0.024226, loss_fp: 0.003888, loss_freq: 0.012388
[13:44:50.015] iteration 10166: loss: 0.055871, loss_s1: 0.046532, loss_fp: 0.001831, loss_freq: 0.009024
[13:44:50.632] iteration 10167: loss: 0.038928, loss_s1: 0.015704, loss_fp: 0.001429, loss_freq: 0.009058
[13:44:51.250] iteration 10168: loss: 0.083605, loss_s1: 0.056019, loss_fp: 0.001519, loss_freq: 0.042734
[13:44:51.908] iteration 10169: loss: 0.054518, loss_s1: 0.040815, loss_fp: 0.003190, loss_freq: 0.014665
[13:44:52.570] iteration 10170: loss: 0.139445, loss_s1: 0.020518, loss_fp: 0.000826, loss_freq: 0.023246
[13:44:53.231] iteration 10171: loss: 0.114629, loss_s1: 0.086468, loss_fp: 0.005427, loss_freq: 0.035589
[13:44:53.854] iteration 10172: loss: 0.072825, loss_s1: 0.032314, loss_fp: 0.003603, loss_freq: 0.022825
[13:44:54.472] iteration 10173: loss: 0.062799, loss_s1: 0.025948, loss_fp: 0.002910, loss_freq: 0.012049
[13:44:55.089] iteration 10174: loss: 0.116092, loss_s1: 0.047765, loss_fp: 0.001697, loss_freq: 0.064029
[13:44:55.784] iteration 10175: loss: 0.115720, loss_s1: 0.090803, loss_fp: 0.002268, loss_freq: 0.047064
[13:44:56.444] iteration 10176: loss: 0.059811, loss_s1: 0.027600, loss_fp: 0.002132, loss_freq: 0.023194
[13:44:57.104] iteration 10177: loss: 0.081672, loss_s1: 0.026864, loss_fp: 0.001045, loss_freq: 0.017416
[13:44:57.762] iteration 10178: loss: 0.088034, loss_s1: 0.069477, loss_fp: 0.007600, loss_freq: 0.031675
[13:44:58.426] iteration 10179: loss: 0.081670, loss_s1: 0.019160, loss_fp: 0.008677, loss_freq: 0.028413
[13:44:59.082] iteration 10180: loss: 0.162872, loss_s1: 0.062399, loss_fp: 0.002064, loss_freq: 0.092875
[13:44:59.712] iteration 10181: loss: 0.069206, loss_s1: 0.048405, loss_fp: 0.000742, loss_freq: 0.010248
[13:45:00.336] iteration 10182: loss: 0.075907, loss_s1: 0.047652, loss_fp: 0.000553, loss_freq: 0.014047
[13:45:00.952] iteration 10183: loss: 0.081890, loss_s1: 0.062940, loss_fp: 0.005311, loss_freq: 0.021133
[13:45:01.572] iteration 10184: loss: 0.069214, loss_s1: 0.021095, loss_fp: 0.003264, loss_freq: 0.014254
[13:45:02.196] iteration 10185: loss: 0.091159, loss_s1: 0.058225, loss_fp: 0.002701, loss_freq: 0.032846
[13:45:02.812] iteration 10186: loss: 0.083092, loss_s1: 0.077708, loss_fp: 0.000851, loss_freq: 0.040971
[13:45:03.432] iteration 10187: loss: 0.073041, loss_s1: 0.053722, loss_fp: 0.002074, loss_freq: 0.031019
[13:45:04.052] iteration 10188: loss: 0.082603, loss_s1: 0.078199, loss_fp: 0.003140, loss_freq: 0.013613
[13:45:04.663] iteration 10189: loss: 0.121120, loss_s1: 0.051798, loss_fp: 0.007831, loss_freq: 0.048093
[13:45:05.285] iteration 10190: loss: 0.129771, loss_s1: 0.121262, loss_fp: 0.004705, loss_freq: 0.040639
[13:45:05.908] iteration 10191: loss: 0.077733, loss_s1: 0.078366, loss_fp: 0.002296, loss_freq: 0.023456
[13:45:06.529] iteration 10192: loss: 0.081177, loss_s1: 0.058233, loss_fp: 0.005666, loss_freq: 0.029365
[13:45:07.153] iteration 10193: loss: 0.094222, loss_s1: 0.051804, loss_fp: 0.009509, loss_freq: 0.017344
[13:45:07.782] iteration 10194: loss: 0.070982, loss_s1: 0.030291, loss_fp: 0.003006, loss_freq: 0.006074
[13:45:08.402] iteration 10195: loss: 0.049588, loss_s1: 0.038416, loss_fp: 0.000930, loss_freq: 0.009872
[13:45:09.022] iteration 10196: loss: 0.071669, loss_s1: 0.022843, loss_fp: 0.000684, loss_freq: 0.016335
[13:45:09.637] iteration 10197: loss: 0.074261, loss_s1: 0.057316, loss_fp: 0.004450, loss_freq: 0.033374
[13:45:10.250] iteration 10198: loss: 0.111720, loss_s1: 0.036690, loss_fp: 0.006342, loss_freq: 0.005180
[13:45:10.867] iteration 10199: loss: 0.077511, loss_s1: 0.056733, loss_fp: 0.001144, loss_freq: 0.043068
[13:45:11.487] iteration 10200: loss: 0.080212, loss_s1: 0.052160, loss_fp: 0.001494, loss_freq: 0.023437
[13:45:15.015] iteration 10200 : mean_dice : 0.734299
[13:45:15.665] iteration 10201: loss: 0.054359, loss_s1: 0.026158, loss_fp: 0.002092, loss_freq: 0.020254
[13:45:16.295] iteration 10202: loss: 0.065516, loss_s1: 0.045434, loss_fp: 0.001110, loss_freq: 0.023399
[13:45:16.937] iteration 10203: loss: 0.049470, loss_s1: 0.007089, loss_fp: 0.012571, loss_freq: 0.024289
[13:45:17.576] iteration 10204: loss: 0.071050, loss_s1: 0.036166, loss_fp: 0.003024, loss_freq: 0.030772
[13:45:18.212] iteration 10205: loss: 0.157519, loss_s1: 0.033763, loss_fp: 0.001555, loss_freq: 0.065058
[13:45:18.826] iteration 10206: loss: 0.090691, loss_s1: 0.061169, loss_fp: 0.002872, loss_freq: 0.010980
[13:45:19.445] iteration 10207: loss: 0.048745, loss_s1: 0.036211, loss_fp: 0.003439, loss_freq: 0.012778
[13:45:20.065] iteration 10208: loss: 0.074543, loss_s1: 0.021267, loss_fp: 0.002074, loss_freq: 0.014450
[13:45:20.709] iteration 10209: loss: 0.066330, loss_s1: 0.031262, loss_fp: 0.001880, loss_freq: 0.020836
[13:45:21.327] iteration 10210: loss: 0.052869, loss_s1: 0.013533, loss_fp: 0.001685, loss_freq: 0.032104
[13:45:21.957] iteration 10211: loss: 0.074177, loss_s1: 0.024539, loss_fp: 0.000994, loss_freq: 0.040748
[13:45:22.591] iteration 10212: loss: 0.103374, loss_s1: 0.033341, loss_fp: 0.007270, loss_freq: 0.057756
[13:45:23.216] iteration 10213: loss: 0.050383, loss_s1: 0.025112, loss_fp: 0.003498, loss_freq: 0.019514
[13:45:23.845] iteration 10214: loss: 0.063845, loss_s1: 0.027453, loss_fp: 0.001796, loss_freq: 0.014895
[13:45:24.481] iteration 10215: loss: 0.076766, loss_s1: 0.069725, loss_fp: 0.004026, loss_freq: 0.020009
[13:45:25.109] iteration 10216: loss: 0.075726, loss_s1: 0.049832, loss_fp: 0.001583, loss_freq: 0.024586
[13:45:25.743] iteration 10217: loss: 0.075659, loss_s1: 0.040855, loss_fp: 0.002120, loss_freq: 0.026403
[13:45:26.376] iteration 10218: loss: 0.105611, loss_s1: 0.071071, loss_fp: 0.005990, loss_freq: 0.033990
[13:45:27.011] iteration 10219: loss: 0.095842, loss_s1: 0.035116, loss_fp: 0.000894, loss_freq: 0.017928
[13:45:27.646] iteration 10220: loss: 0.110175, loss_s1: 0.062875, loss_fp: 0.016086, loss_freq: 0.059462
[13:45:28.303] iteration 10221: loss: 0.077675, loss_s1: 0.033267, loss_fp: 0.006027, loss_freq: 0.042548
[13:45:28.939] iteration 10222: loss: 0.093809, loss_s1: 0.081854, loss_fp: 0.010541, loss_freq: 0.015918
[13:45:29.571] iteration 10223: loss: 0.120003, loss_s1: 0.025098, loss_fp: 0.008675, loss_freq: 0.029700
[13:45:30.202] iteration 10224: loss: 0.093910, loss_s1: 0.049281, loss_fp: 0.001410, loss_freq: 0.017721
[13:45:30.827] iteration 10225: loss: 0.075785, loss_s1: 0.065721, loss_fp: 0.000707, loss_freq: 0.018991
[13:45:31.451] iteration 10226: loss: 0.052104, loss_s1: 0.008571, loss_fp: 0.005769, loss_freq: 0.025307
[13:45:32.078] iteration 10227: loss: 0.154960, loss_s1: 0.179511, loss_fp: 0.002918, loss_freq: 0.052301
[13:45:32.700] iteration 10228: loss: 0.070093, loss_s1: 0.061722, loss_fp: 0.001810, loss_freq: 0.029022
[13:45:33.363] iteration 10229: loss: 0.109441, loss_s1: 0.066059, loss_fp: 0.000569, loss_freq: 0.022016
[13:45:33.993] iteration 10230: loss: 0.055672, loss_s1: 0.046895, loss_fp: 0.001105, loss_freq: 0.018543
[13:45:34.610] iteration 10231: loss: 0.106347, loss_s1: 0.103692, loss_fp: 0.002765, loss_freq: 0.008817
[13:45:35.237] iteration 10232: loss: 0.090909, loss_s1: 0.077282, loss_fp: 0.005445, loss_freq: 0.049212
[13:45:35.895] iteration 10233: loss: 0.220606, loss_s1: 0.130501, loss_fp: 0.002948, loss_freq: 0.048015
[13:45:36.553] iteration 10234: loss: 0.055906, loss_s1: 0.014903, loss_fp: 0.000830, loss_freq: 0.033304
[13:45:37.209] iteration 10235: loss: 0.092199, loss_s1: 0.073215, loss_fp: 0.004985, loss_freq: 0.045929
[13:45:37.868] iteration 10236: loss: 0.122684, loss_s1: 0.095223, loss_fp: 0.010707, loss_freq: 0.050573
[13:45:38.526] iteration 10237: loss: 0.042980, loss_s1: 0.015292, loss_fp: 0.002806, loss_freq: 0.024536
[13:45:39.183] iteration 10238: loss: 0.078029, loss_s1: 0.039951, loss_fp: 0.002970, loss_freq: 0.017974
[13:45:39.815] iteration 10239: loss: 0.067382, loss_s1: 0.042909, loss_fp: 0.003728, loss_freq: 0.039639
[13:45:40.441] iteration 10240: loss: 0.083430, loss_s1: 0.045272, loss_fp: 0.001238, loss_freq: 0.007863
[13:45:41.075] iteration 10241: loss: 0.071714, loss_s1: 0.026398, loss_fp: 0.000617, loss_freq: 0.031174
[13:45:41.733] iteration 10242: loss: 0.052369, loss_s1: 0.042082, loss_fp: 0.000875, loss_freq: 0.009173
[13:45:42.360] iteration 10243: loss: 0.072809, loss_s1: 0.062565, loss_fp: 0.002497, loss_freq: 0.035284
[13:45:42.987] iteration 10244: loss: 0.073007, loss_s1: 0.024271, loss_fp: 0.004150, loss_freq: 0.012831
[13:45:43.602] iteration 10245: loss: 0.074639, loss_s1: 0.049404, loss_fp: 0.002395, loss_freq: 0.049467
[13:45:44.229] iteration 10246: loss: 0.054555, loss_s1: 0.032858, loss_fp: 0.001395, loss_freq: 0.012964
[13:45:44.856] iteration 10247: loss: 0.094759, loss_s1: 0.056598, loss_fp: 0.003284, loss_freq: 0.017949
[13:45:45.491] iteration 10248: loss: 0.058158, loss_s1: 0.027963, loss_fp: 0.002688, loss_freq: 0.014705
[13:45:46.137] iteration 10249: loss: 0.075476, loss_s1: 0.032910, loss_fp: 0.007660, loss_freq: 0.037388
[13:45:46.766] iteration 10250: loss: 0.135314, loss_s1: 0.116263, loss_fp: 0.004162, loss_freq: 0.076782
[13:45:47.388] iteration 10251: loss: 0.080927, loss_s1: 0.077042, loss_fp: 0.003111, loss_freq: 0.022205
[13:45:48.021] iteration 10252: loss: 0.116927, loss_s1: 0.034208, loss_fp: 0.016516, loss_freq: 0.026321
[13:45:48.648] iteration 10253: loss: 0.149274, loss_s1: 0.049571, loss_fp: 0.001626, loss_freq: 0.078574
[13:45:49.267] iteration 10254: loss: 0.108085, loss_s1: 0.093766, loss_fp: 0.001783, loss_freq: 0.045181
[13:45:49.895] iteration 10255: loss: 0.090245, loss_s1: 0.026440, loss_fp: 0.009364, loss_freq: 0.019013
[13:45:50.520] iteration 10256: loss: 0.067784, loss_s1: 0.034719, loss_fp: 0.007897, loss_freq: 0.029596
[13:45:51.146] iteration 10257: loss: 0.093670, loss_s1: 0.013731, loss_fp: 0.003654, loss_freq: 0.032373
[13:45:51.771] iteration 10258: loss: 0.086572, loss_s1: 0.028977, loss_fp: 0.003542, loss_freq: 0.049545
[13:45:52.402] iteration 10259: loss: 0.084466, loss_s1: 0.036319, loss_fp: 0.000998, loss_freq: 0.029641
[13:45:53.028] iteration 10260: loss: 0.158526, loss_s1: 0.140770, loss_fp: 0.001913, loss_freq: 0.063781
[13:45:53.648] iteration 10261: loss: 0.111944, loss_s1: 0.065525, loss_fp: 0.002622, loss_freq: 0.096472
[13:45:54.269] iteration 10262: loss: 0.098807, loss_s1: 0.069107, loss_fp: 0.000694, loss_freq: 0.013717
[13:45:54.944] iteration 10263: loss: 0.067765, loss_s1: 0.020299, loss_fp: 0.004165, loss_freq: 0.010352
[13:45:55.581] iteration 10264: loss: 0.083771, loss_s1: 0.042558, loss_fp: 0.000992, loss_freq: 0.008809
[13:45:56.545] iteration 10265: loss: 0.082182, loss_s1: 0.034527, loss_fp: 0.003204, loss_freq: 0.067365
[13:45:57.250] iteration 10266: loss: 0.083360, loss_s1: 0.042478, loss_fp: 0.001021, loss_freq: 0.018257
[13:45:57.870] iteration 10267: loss: 0.077112, loss_s1: 0.046743, loss_fp: 0.000947, loss_freq: 0.039819
[13:45:58.494] iteration 10268: loss: 0.122453, loss_s1: 0.030353, loss_fp: 0.001565, loss_freq: 0.024358
[13:45:59.116] iteration 10269: loss: 0.096215, loss_s1: 0.062943, loss_fp: 0.000700, loss_freq: 0.007829
[13:45:59.764] iteration 10270: loss: 0.105652, loss_s1: 0.049494, loss_fp: 0.008962, loss_freq: 0.044495
[13:46:00.384] iteration 10271: loss: 0.071302, loss_s1: 0.037080, loss_fp: 0.001743, loss_freq: 0.012950
[13:46:01.002] iteration 10272: loss: 0.080356, loss_s1: 0.064200, loss_fp: 0.008838, loss_freq: 0.040660
[13:46:01.630] iteration 10273: loss: 0.070649, loss_s1: 0.048457, loss_fp: 0.001232, loss_freq: 0.017915
[13:46:02.261] iteration 10274: loss: 0.128761, loss_s1: 0.091469, loss_fp: 0.005052, loss_freq: 0.070029
[13:46:02.887] iteration 10275: loss: 0.131769, loss_s1: 0.087310, loss_fp: 0.001500, loss_freq: 0.020591
[13:46:03.510] iteration 10276: loss: 0.061552, loss_s1: 0.030701, loss_fp: 0.002753, loss_freq: 0.002646
[13:46:04.131] iteration 10277: loss: 0.055235, loss_s1: 0.023741, loss_fp: 0.007289, loss_freq: 0.044124
[13:46:04.755] iteration 10278: loss: 0.079587, loss_s1: 0.049400, loss_fp: 0.005262, loss_freq: 0.052863
[13:46:05.380] iteration 10279: loss: 0.105617, loss_s1: 0.062084, loss_fp: 0.004180, loss_freq: 0.022994
[13:46:06.009] iteration 10280: loss: 0.070497, loss_s1: 0.028671, loss_fp: 0.000761, loss_freq: 0.045512
[13:46:06.636] iteration 10281: loss: 0.088894, loss_s1: 0.085035, loss_fp: 0.001356, loss_freq: 0.020854
[13:46:07.304] iteration 10282: loss: 0.096933, loss_s1: 0.044766, loss_fp: 0.001532, loss_freq: 0.025320
[13:46:07.926] iteration 10283: loss: 0.071937, loss_s1: 0.033676, loss_fp: 0.000716, loss_freq: 0.020677
[13:46:08.548] iteration 10284: loss: 0.119155, loss_s1: 0.082036, loss_fp: 0.001893, loss_freq: 0.039992
[13:46:09.194] iteration 10285: loss: 0.094703, loss_s1: 0.073628, loss_fp: 0.001473, loss_freq: 0.020391
[13:46:09.839] iteration 10286: loss: 0.114593, loss_s1: 0.075790, loss_fp: 0.001673, loss_freq: 0.042848
[13:46:10.476] iteration 10287: loss: 0.106632, loss_s1: 0.026944, loss_fp: 0.000805, loss_freq: 0.056365
[13:46:11.117] iteration 10288: loss: 0.066845, loss_s1: 0.009605, loss_fp: 0.001095, loss_freq: 0.013970
[13:46:11.761] iteration 10289: loss: 0.090968, loss_s1: 0.069953, loss_fp: 0.003291, loss_freq: 0.005668
[13:46:12.401] iteration 10290: loss: 0.066606, loss_s1: 0.032119, loss_fp: 0.005379, loss_freq: 0.032176
[13:46:13.043] iteration 10291: loss: 0.054070, loss_s1: 0.028147, loss_fp: 0.002251, loss_freq: 0.010489
[13:46:13.684] iteration 10292: loss: 0.084584, loss_s1: 0.024410, loss_fp: 0.002948, loss_freq: 0.034603
[13:46:14.318] iteration 10293: loss: 0.122902, loss_s1: 0.059495, loss_fp: 0.003087, loss_freq: 0.019315
[13:46:14.943] iteration 10294: loss: 0.082110, loss_s1: 0.068465, loss_fp: 0.001109, loss_freq: 0.045283
[13:46:15.567] iteration 10295: loss: 0.129108, loss_s1: 0.125404, loss_fp: 0.003783, loss_freq: 0.034794
[13:46:16.183] iteration 10296: loss: 0.056891, loss_s1: 0.037438, loss_fp: 0.001374, loss_freq: 0.022023
[13:46:17.205] iteration 10297: loss: 0.096856, loss_s1: 0.092388, loss_fp: 0.002110, loss_freq: 0.018638
[13:46:17.867] iteration 10298: loss: 0.084061, loss_s1: 0.074322, loss_fp: 0.001202, loss_freq: 0.020206
[13:46:18.574] iteration 10299: loss: 0.049975, loss_s1: 0.024864, loss_fp: 0.003860, loss_freq: 0.017657
[13:46:19.230] iteration 10300: loss: 0.082121, loss_s1: 0.039488, loss_fp: 0.001517, loss_freq: 0.030363
[13:46:19.887] iteration 10301: loss: 0.071301, loss_s1: 0.052557, loss_fp: 0.004149, loss_freq: 0.036450
[13:46:20.548] iteration 10302: loss: 0.074951, loss_s1: 0.012354, loss_fp: 0.002748, loss_freq: 0.008194
[13:46:21.213] iteration 10303: loss: 0.100458, loss_s1: 0.115597, loss_fp: 0.002882, loss_freq: 0.034841
[13:46:21.845] iteration 10304: loss: 0.154617, loss_s1: 0.091304, loss_fp: 0.003707, loss_freq: 0.049055
[13:46:22.480] iteration 10305: loss: 0.073799, loss_s1: 0.029772, loss_fp: 0.002604, loss_freq: 0.023661
[13:46:23.115] iteration 10306: loss: 0.086276, loss_s1: 0.029441, loss_fp: 0.000890, loss_freq: 0.029513
[13:46:23.753] iteration 10307: loss: 0.129725, loss_s1: 0.061378, loss_fp: 0.003913, loss_freq: 0.067059
[13:46:24.380] iteration 10308: loss: 0.059511, loss_s1: 0.025564, loss_fp: 0.001520, loss_freq: 0.015823
[13:46:25.015] iteration 10309: loss: 0.089164, loss_s1: 0.062293, loss_fp: 0.000735, loss_freq: 0.052367
[13:46:25.643] iteration 10310: loss: 0.031288, loss_s1: 0.005131, loss_fp: 0.000375, loss_freq: 0.009282
[13:46:26.273] iteration 10311: loss: 0.058368, loss_s1: 0.035938, loss_fp: 0.000870, loss_freq: 0.025026
[13:46:26.907] iteration 10312: loss: 0.051083, loss_s1: 0.027267, loss_fp: 0.003707, loss_freq: 0.012614
[13:46:27.543] iteration 10313: loss: 0.101134, loss_s1: 0.043551, loss_fp: 0.002429, loss_freq: 0.037725
[13:46:28.171] iteration 10314: loss: 0.082278, loss_s1: 0.024660, loss_fp: 0.008805, loss_freq: 0.007980
[13:46:28.803] iteration 10315: loss: 0.036855, loss_s1: 0.032391, loss_fp: 0.000426, loss_freq: 0.005445
[13:46:29.436] iteration 10316: loss: 0.091370, loss_s1: 0.052703, loss_fp: 0.002761, loss_freq: 0.055328
[13:46:30.068] iteration 10317: loss: 0.123293, loss_s1: 0.042431, loss_fp: 0.007451, loss_freq: 0.056601
[13:46:30.704] iteration 10318: loss: 0.076787, loss_s1: 0.016575, loss_fp: 0.002156, loss_freq: 0.046649
[13:46:31.338] iteration 10319: loss: 0.065757, loss_s1: 0.025141, loss_fp: 0.002553, loss_freq: 0.042615
[13:46:31.972] iteration 10320: loss: 0.056897, loss_s1: 0.018195, loss_fp: 0.002206, loss_freq: 0.016775
[13:46:32.601] iteration 10321: loss: 0.070514, loss_s1: 0.047631, loss_fp: 0.000982, loss_freq: 0.025259
[13:46:33.230] iteration 10322: loss: 0.129901, loss_s1: 0.078423, loss_fp: 0.005451, loss_freq: 0.072013
[13:46:33.883] iteration 10323: loss: 0.089475, loss_s1: 0.047141, loss_fp: 0.003115, loss_freq: 0.034040
[13:46:34.508] iteration 10324: loss: 0.065749, loss_s1: 0.020115, loss_fp: 0.001752, loss_freq: 0.012462
[13:46:35.138] iteration 10325: loss: 0.116336, loss_s1: 0.052058, loss_fp: 0.009789, loss_freq: 0.065980
[13:46:35.770] iteration 10326: loss: 0.058925, loss_s1: 0.032598, loss_fp: 0.001586, loss_freq: 0.012814
[13:46:36.410] iteration 10327: loss: 0.078596, loss_s1: 0.044081, loss_fp: 0.003929, loss_freq: 0.015533
[13:46:37.073] iteration 10328: loss: 0.062568, loss_s1: 0.019313, loss_fp: 0.001735, loss_freq: 0.015386
[13:46:37.731] iteration 10329: loss: 0.072707, loss_s1: 0.053640, loss_fp: 0.008944, loss_freq: 0.028377
[13:46:38.387] iteration 10330: loss: 0.137377, loss_s1: 0.047732, loss_fp: 0.007247, loss_freq: 0.077560
[13:46:39.045] iteration 10331: loss: 0.136869, loss_s1: 0.063402, loss_fp: 0.010079, loss_freq: 0.026500
[13:46:39.706] iteration 10332: loss: 0.122606, loss_s1: 0.083118, loss_fp: 0.004650, loss_freq: 0.039600
[13:46:40.351] iteration 10333: loss: 0.100524, loss_s1: 0.072094, loss_fp: 0.002492, loss_freq: 0.032583
[13:46:40.979] iteration 10334: loss: 0.056524, loss_s1: 0.029629, loss_fp: 0.001677, loss_freq: 0.029965
[13:46:41.608] iteration 10335: loss: 0.066688, loss_s1: 0.013985, loss_fp: 0.003549, loss_freq: 0.045867
[13:46:42.267] iteration 10336: loss: 0.076572, loss_s1: 0.032775, loss_fp: 0.006052, loss_freq: 0.023638
[13:46:42.928] iteration 10337: loss: 0.122796, loss_s1: 0.047706, loss_fp: 0.001385, loss_freq: 0.030767
[13:46:43.591] iteration 10338: loss: 0.055947, loss_s1: 0.053263, loss_fp: 0.005544, loss_freq: 0.014741
[13:46:44.219] iteration 10339: loss: 0.074736, loss_s1: 0.037367, loss_fp: 0.001846, loss_freq: 0.007696
[13:46:44.848] iteration 10340: loss: 0.094112, loss_s1: 0.071534, loss_fp: 0.013462, loss_freq: 0.034119
[13:46:45.475] iteration 10341: loss: 0.100841, loss_s1: 0.025336, loss_fp: 0.000390, loss_freq: 0.008099
[13:46:46.098] iteration 10342: loss: 0.066948, loss_s1: 0.043336, loss_fp: 0.001274, loss_freq: 0.024129
[13:46:46.725] iteration 10343: loss: 0.054917, loss_s1: 0.012340, loss_fp: 0.001739, loss_freq: 0.016878
[13:46:47.344] iteration 10344: loss: 0.070524, loss_s1: 0.033424, loss_fp: 0.008424, loss_freq: 0.022236
[13:46:47.970] iteration 10345: loss: 0.051873, loss_s1: 0.036949, loss_fp: 0.001692, loss_freq: 0.019126
[13:46:48.593] iteration 10346: loss: 0.066838, loss_s1: 0.046136, loss_fp: 0.000644, loss_freq: 0.023390
[13:46:49.208] iteration 10347: loss: 0.073504, loss_s1: 0.062492, loss_fp: 0.008414, loss_freq: 0.012076
[13:46:49.837] iteration 10348: loss: 0.109500, loss_s1: 0.032470, loss_fp: 0.002726, loss_freq: 0.068074
[13:46:50.460] iteration 10349: loss: 0.077858, loss_s1: 0.028327, loss_fp: 0.001965, loss_freq: 0.007698
[13:46:51.089] iteration 10350: loss: 0.078026, loss_s1: 0.022172, loss_fp: 0.001378, loss_freq: 0.009019
[13:46:51.716] iteration 10351: loss: 0.063253, loss_s1: 0.046773, loss_fp: 0.001407, loss_freq: 0.015883
[13:46:52.337] iteration 10352: loss: 0.104317, loss_s1: 0.021013, loss_fp: 0.001189, loss_freq: 0.008670
[13:46:52.964] iteration 10353: loss: 0.069411, loss_s1: 0.057717, loss_fp: 0.002206, loss_freq: 0.020819
[13:46:53.587] iteration 10354: loss: 0.058245, loss_s1: 0.022285, loss_fp: 0.002206, loss_freq: 0.033985
[13:46:54.210] iteration 10355: loss: 0.113841, loss_s1: 0.040127, loss_fp: 0.002525, loss_freq: 0.095920
[13:46:54.835] iteration 10356: loss: 0.048934, loss_s1: 0.022037, loss_fp: 0.002340, loss_freq: 0.015843
[13:46:55.463] iteration 10357: loss: 0.053663, loss_s1: 0.023071, loss_fp: 0.007751, loss_freq: 0.017798
[13:46:56.086] iteration 10358: loss: 0.133102, loss_s1: 0.069433, loss_fp: 0.002589, loss_freq: 0.058685
[13:46:56.714] iteration 10359: loss: 0.111907, loss_s1: 0.040059, loss_fp: 0.021058, loss_freq: 0.029686
[13:46:57.340] iteration 10360: loss: 0.070360, loss_s1: 0.020408, loss_fp: 0.004407, loss_freq: 0.020385
[13:46:57.965] iteration 10361: loss: 0.090022, loss_s1: 0.045716, loss_fp: 0.002965, loss_freq: 0.034609
[13:46:58.592] iteration 10362: loss: 0.060204, loss_s1: 0.016375, loss_fp: 0.004868, loss_freq: 0.016005
[13:46:59.232] iteration 10363: loss: 0.146277, loss_s1: 0.092802, loss_fp: 0.003086, loss_freq: 0.092009
[13:46:59.856] iteration 10364: loss: 0.067305, loss_s1: 0.041057, loss_fp: 0.002576, loss_freq: 0.016277
[13:47:00.485] iteration 10365: loss: 0.056890, loss_s1: 0.019742, loss_fp: 0.002214, loss_freq: 0.037626
[13:47:01.112] iteration 10366: loss: 0.136940, loss_s1: 0.070670, loss_fp: 0.006602, loss_freq: 0.022049
[13:47:01.775] iteration 10367: loss: 0.049307, loss_s1: 0.025710, loss_fp: 0.003327, loss_freq: 0.009437
[13:47:02.430] iteration 10368: loss: 0.072052, loss_s1: 0.039925, loss_fp: 0.002163, loss_freq: 0.031371
[13:47:03.090] iteration 10369: loss: 0.083036, loss_s1: 0.052706, loss_fp: 0.001286, loss_freq: 0.060254
[13:47:03.717] iteration 10370: loss: 0.131272, loss_s1: 0.060881, loss_fp: 0.006610, loss_freq: 0.108784
[13:47:04.333] iteration 10371: loss: 0.071148, loss_s1: 0.055667, loss_fp: 0.003739, loss_freq: 0.035143
[13:47:04.963] iteration 10372: loss: 0.086893, loss_s1: 0.043949, loss_fp: 0.001021, loss_freq: 0.014142
[13:47:05.580] iteration 10373: loss: 0.042964, loss_s1: 0.024045, loss_fp: 0.002192, loss_freq: 0.018962
[13:47:06.193] iteration 10374: loss: 0.057868, loss_s1: 0.019891, loss_fp: 0.000589, loss_freq: 0.015146
[13:47:06.839] iteration 10375: loss: 0.122358, loss_s1: 0.122631, loss_fp: 0.012017, loss_freq: 0.014504
[13:47:07.462] iteration 10376: loss: 0.184454, loss_s1: 0.074505, loss_fp: 0.009724, loss_freq: 0.028567
[13:47:08.130] iteration 10377: loss: 0.069381, loss_s1: 0.060783, loss_fp: 0.001305, loss_freq: 0.013054
[13:47:08.740] iteration 10378: loss: 0.076217, loss_s1: 0.038550, loss_fp: 0.001553, loss_freq: 0.025021
[13:47:09.370] iteration 10379: loss: 0.067795, loss_s1: 0.036626, loss_fp: 0.002227, loss_freq: 0.019915
[13:47:09.998] iteration 10380: loss: 0.049781, loss_s1: 0.031282, loss_fp: 0.003261, loss_freq: 0.009768
[13:47:10.620] iteration 10381: loss: 0.070633, loss_s1: 0.058016, loss_fp: 0.001549, loss_freq: 0.016531
[13:47:11.240] iteration 10382: loss: 0.100194, loss_s1: 0.054958, loss_fp: 0.004277, loss_freq: 0.064564
[13:47:11.865] iteration 10383: loss: 0.181081, loss_s1: 0.065337, loss_fp: 0.001093, loss_freq: 0.018320
[13:47:12.522] iteration 10384: loss: 0.080924, loss_s1: 0.007695, loss_fp: 0.002665, loss_freq: 0.031443
[13:47:13.231] iteration 10385: loss: 0.066448, loss_s1: 0.044297, loss_fp: 0.001102, loss_freq: 0.022810
[13:47:13.890] iteration 10386: loss: 0.086528, loss_s1: 0.049154, loss_fp: 0.005884, loss_freq: 0.032327
[13:47:14.549] iteration 10387: loss: 0.081423, loss_s1: 0.068923, loss_fp: 0.003965, loss_freq: 0.012222
[13:47:15.187] iteration 10388: loss: 0.098272, loss_s1: 0.086976, loss_fp: 0.004055, loss_freq: 0.046338
[13:47:15.805] iteration 10389: loss: 0.049768, loss_s1: 0.030203, loss_fp: 0.000942, loss_freq: 0.014687
[13:47:16.455] iteration 10390: loss: 0.098590, loss_s1: 0.046055, loss_fp: 0.003745, loss_freq: 0.036369
[13:47:17.109] iteration 10391: loss: 0.061862, loss_s1: 0.026644, loss_fp: 0.002773, loss_freq: 0.030888
[13:47:17.766] iteration 10392: loss: 0.078170, loss_s1: 0.055183, loss_fp: 0.001822, loss_freq: 0.013922
[13:47:18.401] iteration 10393: loss: 0.110317, loss_s1: 0.099125, loss_fp: 0.004552, loss_freq: 0.048589
[13:47:19.027] iteration 10394: loss: 0.074513, loss_s1: 0.044297, loss_fp: 0.003927, loss_freq: 0.031834
[13:47:19.649] iteration 10395: loss: 0.086926, loss_s1: 0.016078, loss_fp: 0.004774, loss_freq: 0.025778
[13:47:20.273] iteration 10396: loss: 0.094576, loss_s1: 0.018941, loss_fp: 0.002757, loss_freq: 0.034591
[13:47:20.894] iteration 10397: loss: 0.112267, loss_s1: 0.046737, loss_fp: 0.011739, loss_freq: 0.047360
[13:47:21.518] iteration 10398: loss: 0.071303, loss_s1: 0.036285, loss_fp: 0.000949, loss_freq: 0.043384
[13:47:22.145] iteration 10399: loss: 0.109223, loss_s1: 0.071604, loss_fp: 0.007232, loss_freq: 0.025093
[13:47:22.763] iteration 10400: loss: 0.093217, loss_s1: 0.067818, loss_fp: 0.001794, loss_freq: 0.049343
[13:47:26.472] iteration 10400 : mean_dice : 0.768352
[13:47:27.156] iteration 10401: loss: 0.113595, loss_s1: 0.066721, loss_fp: 0.002766, loss_freq: 0.028119
[13:47:27.808] iteration 10402: loss: 0.058567, loss_s1: 0.033466, loss_fp: 0.003193, loss_freq: 0.019853
[13:47:28.461] iteration 10403: loss: 0.108145, loss_s1: 0.050456, loss_fp: 0.008924, loss_freq: 0.085225
[13:47:29.115] iteration 10404: loss: 0.084554, loss_s1: 0.064279, loss_fp: 0.004768, loss_freq: 0.061406
[13:47:29.767] iteration 10405: loss: 0.076916, loss_s1: 0.054657, loss_fp: 0.002539, loss_freq: 0.021412
[13:47:30.448] iteration 10406: loss: 0.085969, loss_s1: 0.073581, loss_fp: 0.008175, loss_freq: 0.044514
[13:47:31.073] iteration 10407: loss: 0.106268, loss_s1: 0.049250, loss_fp: 0.002169, loss_freq: 0.018940
[13:47:31.700] iteration 10408: loss: 0.045075, loss_s1: 0.019141, loss_fp: 0.002946, loss_freq: 0.026135
[13:47:32.320] iteration 10409: loss: 0.082130, loss_s1: 0.047070, loss_fp: 0.000926, loss_freq: 0.017630
[13:47:32.939] iteration 10410: loss: 0.062330, loss_s1: 0.027366, loss_fp: 0.013670, loss_freq: 0.027752
[13:47:33.557] iteration 10411: loss: 0.159695, loss_s1: 0.043044, loss_fp: 0.002008, loss_freq: 0.012730
[13:47:34.177] iteration 10412: loss: 0.070888, loss_s1: 0.071463, loss_fp: 0.000556, loss_freq: 0.003018
[13:47:34.793] iteration 10413: loss: 0.095708, loss_s1: 0.054874, loss_fp: 0.001142, loss_freq: 0.044914
[13:47:35.419] iteration 10414: loss: 0.088015, loss_s1: 0.062518, loss_fp: 0.003991, loss_freq: 0.027858
[13:47:36.043] iteration 10415: loss: 0.050546, loss_s1: 0.028384, loss_fp: 0.005710, loss_freq: 0.015645
[13:47:36.667] iteration 10416: loss: 0.075600, loss_s1: 0.056153, loss_fp: 0.002036, loss_freq: 0.018735
[13:47:37.292] iteration 10417: loss: 0.124822, loss_s1: 0.089713, loss_fp: 0.000920, loss_freq: 0.089332
[13:47:37.924] iteration 10418: loss: 0.134819, loss_s1: 0.066701, loss_fp: 0.002456, loss_freq: 0.014110
[13:47:38.550] iteration 10419: loss: 0.047146, loss_s1: 0.024276, loss_fp: 0.001470, loss_freq: 0.010065
[13:47:39.174] iteration 10420: loss: 0.052738, loss_s1: 0.047285, loss_fp: 0.002504, loss_freq: 0.009602
[13:47:39.802] iteration 10421: loss: 0.047532, loss_s1: 0.016814, loss_fp: 0.015222, loss_freq: 0.015535
[13:47:40.430] iteration 10422: loss: 0.085277, loss_s1: 0.055345, loss_fp: 0.003163, loss_freq: 0.028969
[13:47:41.092] iteration 10423: loss: 0.063220, loss_s1: 0.038876, loss_fp: 0.000684, loss_freq: 0.024435
[13:47:41.770] iteration 10424: loss: 0.064237, loss_s1: 0.031351, loss_fp: 0.000876, loss_freq: 0.039303
[13:47:42.457] iteration 10425: loss: 0.121952, loss_s1: 0.065445, loss_fp: 0.001691, loss_freq: 0.014768
[13:47:43.097] iteration 10426: loss: 0.069566, loss_s1: 0.039508, loss_fp: 0.002976, loss_freq: 0.016337
[13:47:43.727] iteration 10427: loss: 0.104734, loss_s1: 0.068890, loss_fp: 0.001721, loss_freq: 0.028142
[13:47:44.355] iteration 10428: loss: 0.091083, loss_s1: 0.079281, loss_fp: 0.001938, loss_freq: 0.019890
[13:47:44.992] iteration 10429: loss: 0.066977, loss_s1: 0.043739, loss_fp: 0.001150, loss_freq: 0.019167
[13:47:45.630] iteration 10430: loss: 0.108294, loss_s1: 0.057289, loss_fp: 0.000999, loss_freq: 0.041024
[13:47:46.263] iteration 10431: loss: 0.120420, loss_s1: 0.047472, loss_fp: 0.008507, loss_freq: 0.049738
[13:47:46.891] iteration 10432: loss: 0.058792, loss_s1: 0.017596, loss_fp: 0.001052, loss_freq: 0.021647
[13:47:47.519] iteration 10433: loss: 0.069486, loss_s1: 0.041555, loss_fp: 0.016708, loss_freq: 0.023698
[13:47:48.147] iteration 10434: loss: 0.065194, loss_s1: 0.023873, loss_fp: 0.000402, loss_freq: 0.020937
[13:47:48.772] iteration 10435: loss: 0.069209, loss_s1: 0.050559, loss_fp: 0.000514, loss_freq: 0.022210
[13:47:49.403] iteration 10436: loss: 0.078331, loss_s1: 0.033059, loss_fp: 0.001369, loss_freq: 0.021464
[13:47:50.034] iteration 10437: loss: 0.105652, loss_s1: 0.108127, loss_fp: 0.002278, loss_freq: 0.040914
[13:47:50.654] iteration 10438: loss: 0.156418, loss_s1: 0.190075, loss_fp: 0.010853, loss_freq: 0.042810
[13:47:51.276] iteration 10439: loss: 0.045030, loss_s1: 0.028238, loss_fp: 0.001185, loss_freq: 0.015898
[13:47:52.298] iteration 10440: loss: 0.051868, loss_s1: 0.030106, loss_fp: 0.001129, loss_freq: 0.011377
[13:47:52.960] iteration 10441: loss: 0.054625, loss_s1: 0.017670, loss_fp: 0.001281, loss_freq: 0.019055
[13:47:53.621] iteration 10442: loss: 0.069221, loss_s1: 0.057075, loss_fp: 0.000881, loss_freq: 0.033734
[13:47:54.290] iteration 10443: loss: 0.091737, loss_s1: 0.036814, loss_fp: 0.003240, loss_freq: 0.021291
[13:47:54.910] iteration 10444: loss: 0.108118, loss_s1: 0.086503, loss_fp: 0.000721, loss_freq: 0.045139
[13:47:55.541] iteration 10445: loss: 0.088264, loss_s1: 0.019381, loss_fp: 0.001131, loss_freq: 0.003936
[13:47:56.171] iteration 10446: loss: 0.065385, loss_s1: 0.028431, loss_fp: 0.003856, loss_freq: 0.040124
[13:47:56.801] iteration 10447: loss: 0.185688, loss_s1: 0.075783, loss_fp: 0.003817, loss_freq: 0.067773
[13:47:57.446] iteration 10448: loss: 0.081559, loss_s1: 0.038250, loss_fp: 0.002133, loss_freq: 0.049131
[13:47:58.136] iteration 10449: loss: 0.072469, loss_s1: 0.011162, loss_fp: 0.001535, loss_freq: 0.012231
[13:47:58.766] iteration 10450: loss: 0.092318, loss_s1: 0.053757, loss_fp: 0.001083, loss_freq: 0.043297
[13:47:59.561] iteration 10451: loss: 0.065613, loss_s1: 0.049514, loss_fp: 0.001614, loss_freq: 0.006316
[13:48:00.218] iteration 10452: loss: 0.058702, loss_s1: 0.025808, loss_fp: 0.001704, loss_freq: 0.015210
[13:48:00.985] iteration 10453: loss: 0.057172, loss_s1: 0.040128, loss_fp: 0.001346, loss_freq: 0.026108
[13:48:01.749] iteration 10454: loss: 0.143665, loss_s1: 0.130923, loss_fp: 0.002208, loss_freq: 0.041678
[13:48:02.372] iteration 10455: loss: 0.104221, loss_s1: 0.121611, loss_fp: 0.002757, loss_freq: 0.031811
[13:48:02.993] iteration 10456: loss: 0.079187, loss_s1: 0.029606, loss_fp: 0.000662, loss_freq: 0.026577
[13:48:03.608] iteration 10457: loss: 0.080288, loss_s1: 0.066694, loss_fp: 0.001119, loss_freq: 0.014811
[13:48:04.226] iteration 10458: loss: 0.083031, loss_s1: 0.063470, loss_fp: 0.000914, loss_freq: 0.033987
[13:48:04.846] iteration 10459: loss: 0.055588, loss_s1: 0.048201, loss_fp: 0.000996, loss_freq: 0.016871
[13:48:05.479] iteration 10460: loss: 0.087686, loss_s1: 0.041583, loss_fp: 0.004439, loss_freq: 0.042700
[13:48:06.108] iteration 10461: loss: 0.075683, loss_s1: 0.041103, loss_fp: 0.001090, loss_freq: 0.044497
[13:48:06.739] iteration 10462: loss: 0.054400, loss_s1: 0.017423, loss_fp: 0.001641, loss_freq: 0.034226
[13:48:07.366] iteration 10463: loss: 0.081173, loss_s1: 0.044426, loss_fp: 0.003056, loss_freq: 0.023212
[13:48:07.998] iteration 10464: loss: 0.052174, loss_s1: 0.034165, loss_fp: 0.001186, loss_freq: 0.019294
[13:48:08.629] iteration 10465: loss: 0.111437, loss_s1: 0.094863, loss_fp: 0.001604, loss_freq: 0.042977
[13:48:09.290] iteration 10466: loss: 0.118377, loss_s1: 0.075539, loss_fp: 0.003362, loss_freq: 0.084658
[13:48:09.959] iteration 10467: loss: 0.049928, loss_s1: 0.020360, loss_fp: 0.001978, loss_freq: 0.017219
[13:48:10.617] iteration 10468: loss: 0.086401, loss_s1: 0.029723, loss_fp: 0.002714, loss_freq: 0.039810
[13:48:11.266] iteration 10469: loss: 0.145423, loss_s1: 0.047281, loss_fp: 0.002041, loss_freq: 0.015009
[13:48:11.890] iteration 10470: loss: 0.067465, loss_s1: 0.056072, loss_fp: 0.001206, loss_freq: 0.023899
[13:48:12.520] iteration 10471: loss: 0.080872, loss_s1: 0.023336, loss_fp: 0.003321, loss_freq: 0.040651
[13:48:13.150] iteration 10472: loss: 0.068728, loss_s1: 0.074965, loss_fp: 0.001252, loss_freq: 0.019888
[13:48:13.771] iteration 10473: loss: 0.125928, loss_s1: 0.092418, loss_fp: 0.007251, loss_freq: 0.074336
[13:48:14.396] iteration 10474: loss: 0.107635, loss_s1: 0.042878, loss_fp: 0.001669, loss_freq: 0.044298
[13:48:15.026] iteration 10475: loss: 0.090033, loss_s1: 0.069743, loss_fp: 0.005734, loss_freq: 0.037248
[13:48:15.647] iteration 10476: loss: 0.097170, loss_s1: 0.073703, loss_fp: 0.001772, loss_freq: 0.029730
[13:48:16.285] iteration 10477: loss: 0.065423, loss_s1: 0.050977, loss_fp: 0.003344, loss_freq: 0.020631
[13:48:16.974] iteration 10478: loss: 0.102928, loss_s1: 0.042255, loss_fp: 0.002728, loss_freq: 0.073880
[13:48:17.634] iteration 10479: loss: 0.064801, loss_s1: 0.032532, loss_fp: 0.001712, loss_freq: 0.007543
[13:48:18.293] iteration 10480: loss: 0.117980, loss_s1: 0.044594, loss_fp: 0.004558, loss_freq: 0.040845
[13:48:18.950] iteration 10481: loss: 0.049990, loss_s1: 0.009888, loss_fp: 0.002445, loss_freq: 0.018848
[13:48:19.581] iteration 10482: loss: 0.061184, loss_s1: 0.040756, loss_fp: 0.002488, loss_freq: 0.008459
[13:48:20.208] iteration 10483: loss: 0.084310, loss_s1: 0.050691, loss_fp: 0.002396, loss_freq: 0.055709
[13:48:20.844] iteration 10484: loss: 0.107280, loss_s1: 0.036384, loss_fp: 0.002287, loss_freq: 0.044387
[13:48:21.472] iteration 10485: loss: 0.072543, loss_s1: 0.049766, loss_fp: 0.007149, loss_freq: 0.029563
[13:48:22.105] iteration 10486: loss: 0.078471, loss_s1: 0.037960, loss_fp: 0.003750, loss_freq: 0.029177
[13:48:22.731] iteration 10487: loss: 0.117869, loss_s1: 0.022816, loss_fp: 0.002193, loss_freq: 0.075138
[13:48:23.363] iteration 10488: loss: 0.056331, loss_s1: 0.024647, loss_fp: 0.001906, loss_freq: 0.029233
[13:48:23.994] iteration 10489: loss: 0.082473, loss_s1: 0.061031, loss_fp: 0.001692, loss_freq: 0.036109
[13:48:24.623] iteration 10490: loss: 0.057139, loss_s1: 0.036027, loss_fp: 0.002534, loss_freq: 0.016932
[13:48:25.249] iteration 10491: loss: 0.089267, loss_s1: 0.017479, loss_fp: 0.001348, loss_freq: 0.073134
[13:48:25.876] iteration 10492: loss: 0.059488, loss_s1: 0.038891, loss_fp: 0.002932, loss_freq: 0.021378
[13:48:26.510] iteration 10493: loss: 0.050549, loss_s1: 0.027922, loss_fp: 0.000523, loss_freq: 0.024880
[13:48:27.143] iteration 10494: loss: 0.077166, loss_s1: 0.067011, loss_fp: 0.002747, loss_freq: 0.015410
[13:48:27.768] iteration 10495: loss: 0.071152, loss_s1: 0.026168, loss_fp: 0.002336, loss_freq: 0.008181
[13:48:28.390] iteration 10496: loss: 0.119874, loss_s1: 0.150116, loss_fp: 0.001382, loss_freq: 0.027218
[13:48:29.018] iteration 10497: loss: 0.044133, loss_s1: 0.027558, loss_fp: 0.004804, loss_freq: 0.008335
[13:48:29.646] iteration 10498: loss: 0.094532, loss_s1: 0.040803, loss_fp: 0.002975, loss_freq: 0.068979
[13:48:30.265] iteration 10499: loss: 0.092696, loss_s1: 0.084160, loss_fp: 0.002226, loss_freq: 0.025827
[13:48:30.883] iteration 10500: loss: 0.059123, loss_s1: 0.027765, loss_fp: 0.001554, loss_freq: 0.016297
[13:48:31.509] iteration 10501: loss: 0.082479, loss_s1: 0.064426, loss_fp: 0.001063, loss_freq: 0.023911
[13:48:32.139] iteration 10502: loss: 0.068408, loss_s1: 0.053998, loss_fp: 0.001380, loss_freq: 0.025528
[13:48:32.767] iteration 10503: loss: 0.095786, loss_s1: 0.032320, loss_fp: 0.001310, loss_freq: 0.020907
[13:48:33.389] iteration 10504: loss: 0.109376, loss_s1: 0.017399, loss_fp: 0.026135, loss_freq: 0.036768
[13:48:34.020] iteration 10505: loss: 0.057790, loss_s1: 0.038783, loss_fp: 0.002356, loss_freq: 0.012987
[13:48:34.647] iteration 10506: loss: 0.114000, loss_s1: 0.088377, loss_fp: 0.000992, loss_freq: 0.066953
[13:48:35.273] iteration 10507: loss: 0.057018, loss_s1: 0.028095, loss_fp: 0.001174, loss_freq: 0.012747
[13:48:35.904] iteration 10508: loss: 0.068461, loss_s1: 0.034497, loss_fp: 0.001969, loss_freq: 0.018507
[13:48:36.533] iteration 10509: loss: 0.104497, loss_s1: 0.060152, loss_fp: 0.001821, loss_freq: 0.039929
[13:48:37.157] iteration 10510: loss: 0.064254, loss_s1: 0.030453, loss_fp: 0.001360, loss_freq: 0.033697
[13:48:37.781] iteration 10511: loss: 0.072926, loss_s1: 0.066816, loss_fp: 0.000658, loss_freq: 0.014886
[13:48:38.411] iteration 10512: loss: 0.085109, loss_s1: 0.027144, loss_fp: 0.001130, loss_freq: 0.080630
[13:48:39.041] iteration 10513: loss: 0.084037, loss_s1: 0.044813, loss_fp: 0.003337, loss_freq: 0.057868
[13:48:39.671] iteration 10514: loss: 0.080643, loss_s1: 0.053416, loss_fp: 0.001180, loss_freq: 0.059714
[13:48:40.293] iteration 10515: loss: 0.080564, loss_s1: 0.037845, loss_fp: 0.001968, loss_freq: 0.015528
[13:48:40.919] iteration 10516: loss: 0.061684, loss_s1: 0.048329, loss_fp: 0.006102, loss_freq: 0.023959
[13:48:41.547] iteration 10517: loss: 0.087348, loss_s1: 0.068223, loss_fp: 0.001100, loss_freq: 0.006933
[13:48:42.177] iteration 10518: loss: 0.125032, loss_s1: 0.103720, loss_fp: 0.012184, loss_freq: 0.066935
[13:48:42.807] iteration 10519: loss: 0.163834, loss_s1: 0.077796, loss_fp: 0.011455, loss_freq: 0.049137
[13:48:43.436] iteration 10520: loss: 0.089753, loss_s1: 0.068342, loss_fp: 0.001237, loss_freq: 0.049216
[13:48:44.079] iteration 10521: loss: 0.101254, loss_s1: 0.065362, loss_fp: 0.008945, loss_freq: 0.013433
[13:48:44.751] iteration 10522: loss: 0.076780, loss_s1: 0.037002, loss_fp: 0.002860, loss_freq: 0.032339
[13:48:45.375] iteration 10523: loss: 0.044645, loss_s1: 0.033772, loss_fp: 0.000848, loss_freq: 0.009480
[13:48:46.003] iteration 10524: loss: 0.091675, loss_s1: 0.080873, loss_fp: 0.001470, loss_freq: 0.045975
[13:48:46.628] iteration 10525: loss: 0.058303, loss_s1: 0.032082, loss_fp: 0.002687, loss_freq: 0.025619
[13:48:47.256] iteration 10526: loss: 0.089906, loss_s1: 0.062575, loss_fp: 0.000399, loss_freq: 0.021532
[13:48:47.886] iteration 10527: loss: 0.064860, loss_s1: 0.028647, loss_fp: 0.000483, loss_freq: 0.026219
[13:48:48.522] iteration 10528: loss: 0.052114, loss_s1: 0.019165, loss_fp: 0.001400, loss_freq: 0.022940
[13:48:49.167] iteration 10529: loss: 0.064587, loss_s1: 0.059318, loss_fp: 0.005138, loss_freq: 0.022336
[13:48:49.787] iteration 10530: loss: 0.073096, loss_s1: 0.026097, loss_fp: 0.001362, loss_freq: 0.031602
[13:48:50.409] iteration 10531: loss: 0.051417, loss_s1: 0.016574, loss_fp: 0.003446, loss_freq: 0.027233
[13:48:51.033] iteration 10532: loss: 0.057995, loss_s1: 0.042803, loss_fp: 0.001977, loss_freq: 0.014087
[13:48:51.658] iteration 10533: loss: 0.071746, loss_s1: 0.047049, loss_fp: 0.004232, loss_freq: 0.015583
[13:48:52.286] iteration 10534: loss: 0.046671, loss_s1: 0.017587, loss_fp: 0.001392, loss_freq: 0.015665
[13:48:52.909] iteration 10535: loss: 0.072524, loss_s1: 0.024321, loss_fp: 0.000974, loss_freq: 0.052337
[13:48:53.535] iteration 10536: loss: 0.176777, loss_s1: 0.048755, loss_fp: 0.007457, loss_freq: 0.133825
[13:48:54.163] iteration 10537: loss: 0.061484, loss_s1: 0.039774, loss_fp: 0.007369, loss_freq: 0.025004
[13:48:54.782] iteration 10538: loss: 0.078112, loss_s1: 0.031990, loss_fp: 0.005292, loss_freq: 0.042640
[13:48:55.414] iteration 10539: loss: 0.083907, loss_s1: 0.059050, loss_fp: 0.002515, loss_freq: 0.026322
[13:48:56.038] iteration 10540: loss: 0.064746, loss_s1: 0.021651, loss_fp: 0.001373, loss_freq: 0.015817
[13:48:56.669] iteration 10541: loss: 0.082214, loss_s1: 0.037039, loss_fp: 0.004775, loss_freq: 0.036985
[13:48:57.287] iteration 10542: loss: 0.060407, loss_s1: 0.038028, loss_fp: 0.009032, loss_freq: 0.025875
[13:48:57.912] iteration 10543: loss: 0.095744, loss_s1: 0.068879, loss_fp: 0.005152, loss_freq: 0.030083
[13:48:58.537] iteration 10544: loss: 0.093295, loss_s1: 0.061127, loss_fp: 0.000835, loss_freq: 0.026872
[13:48:59.162] iteration 10545: loss: 0.058053, loss_s1: 0.023672, loss_fp: 0.001435, loss_freq: 0.043318
[13:48:59.781] iteration 10546: loss: 0.165985, loss_s1: 0.129465, loss_fp: 0.005645, loss_freq: 0.127927
[13:49:00.428] iteration 10547: loss: 0.079291, loss_s1: 0.074198, loss_fp: 0.002231, loss_freq: 0.033891
[13:49:01.051] iteration 10548: loss: 0.065407, loss_s1: 0.043592, loss_fp: 0.001645, loss_freq: 0.005849
[13:49:01.670] iteration 10549: loss: 0.100808, loss_s1: 0.098945, loss_fp: 0.001248, loss_freq: 0.030451
[13:49:02.287] iteration 10550: loss: 0.059599, loss_s1: 0.014032, loss_fp: 0.001426, loss_freq: 0.007125
[13:49:02.913] iteration 10551: loss: 0.061596, loss_s1: 0.026901, loss_fp: 0.004576, loss_freq: 0.044625
[13:49:03.534] iteration 10552: loss: 0.061410, loss_s1: 0.033307, loss_fp: 0.000662, loss_freq: 0.012800
[13:49:04.157] iteration 10553: loss: 0.075134, loss_s1: 0.069538, loss_fp: 0.007162, loss_freq: 0.014999
[13:49:04.772] iteration 10554: loss: 0.107116, loss_s1: 0.020306, loss_fp: 0.003487, loss_freq: 0.016965
[13:49:05.393] iteration 10555: loss: 0.073846, loss_s1: 0.039943, loss_fp: 0.001003, loss_freq: 0.019921
[13:49:06.019] iteration 10556: loss: 0.103595, loss_s1: 0.062540, loss_fp: 0.003960, loss_freq: 0.042627
[13:49:06.646] iteration 10557: loss: 0.102047, loss_s1: 0.056926, loss_fp: 0.001652, loss_freq: 0.036896
[13:49:07.280] iteration 10558: loss: 0.050962, loss_s1: 0.036833, loss_fp: 0.006419, loss_freq: 0.007148
[13:49:07.917] iteration 10559: loss: 0.043185, loss_s1: 0.024510, loss_fp: 0.003097, loss_freq: 0.011692
[13:49:08.547] iteration 10560: loss: 0.080844, loss_s1: 0.027662, loss_fp: 0.004082, loss_freq: 0.049418
[13:49:09.183] iteration 10561: loss: 0.163112, loss_s1: 0.058454, loss_fp: 0.005562, loss_freq: 0.047508
[13:49:09.820] iteration 10562: loss: 0.056677, loss_s1: 0.049160, loss_fp: 0.000610, loss_freq: 0.017619
[13:49:10.451] iteration 10563: loss: 0.093996, loss_s1: 0.064540, loss_fp: 0.001140, loss_freq: 0.049171
[13:49:11.087] iteration 10564: loss: 0.096717, loss_s1: 0.104425, loss_fp: 0.002798, loss_freq: 0.046871
[13:49:11.735] iteration 10565: loss: 0.059824, loss_s1: 0.018068, loss_fp: 0.005271, loss_freq: 0.009631
[13:49:12.379] iteration 10566: loss: 0.076217, loss_s1: 0.039568, loss_fp: 0.005039, loss_freq: 0.062572
[13:49:13.019] iteration 10567: loss: 0.051886, loss_s1: 0.013050, loss_fp: 0.002426, loss_freq: 0.021046
[13:49:13.644] iteration 10568: loss: 0.111943, loss_s1: 0.062250, loss_fp: 0.002117, loss_freq: 0.013868
[13:49:14.271] iteration 10569: loss: 0.061135, loss_s1: 0.024112, loss_fp: 0.000842, loss_freq: 0.026618
[13:49:14.892] iteration 10570: loss: 0.087247, loss_s1: 0.017003, loss_fp: 0.003261, loss_freq: 0.009201
[13:49:15.549] iteration 10571: loss: 0.053251, loss_s1: 0.024871, loss_fp: 0.004023, loss_freq: 0.009530
[13:49:16.205] iteration 10572: loss: 0.080006, loss_s1: 0.039545, loss_fp: 0.002019, loss_freq: 0.037098
[13:49:16.868] iteration 10573: loss: 0.099815, loss_s1: 0.059445, loss_fp: 0.007504, loss_freq: 0.038508
[13:49:17.522] iteration 10574: loss: 0.101552, loss_s1: 0.032128, loss_fp: 0.001793, loss_freq: 0.029554
[13:49:18.183] iteration 10575: loss: 0.076428, loss_s1: 0.039350, loss_fp: 0.001714, loss_freq: 0.021347
[13:49:18.819] iteration 10576: loss: 0.063268, loss_s1: 0.045893, loss_fp: 0.001805, loss_freq: 0.011719
[13:49:19.451] iteration 10577: loss: 0.086267, loss_s1: 0.018359, loss_fp: 0.001932, loss_freq: 0.014579
[13:49:20.078] iteration 10578: loss: 0.063522, loss_s1: 0.037401, loss_fp: 0.004757, loss_freq: 0.018413
[13:49:20.704] iteration 10579: loss: 0.059856, loss_s1: 0.018219, loss_fp: 0.000928, loss_freq: 0.010610
[13:49:21.329] iteration 10580: loss: 0.100243, loss_s1: 0.081486, loss_fp: 0.004301, loss_freq: 0.023765
[13:49:21.948] iteration 10581: loss: 0.100596, loss_s1: 0.097220, loss_fp: 0.005973, loss_freq: 0.005844
[13:49:22.573] iteration 10582: loss: 0.055790, loss_s1: 0.021166, loss_fp: 0.003168, loss_freq: 0.017170
[13:49:23.522] iteration 10583: loss: 0.081972, loss_s1: 0.054624, loss_fp: 0.001689, loss_freq: 0.039719
[13:49:24.180] iteration 10584: loss: 0.072590, loss_s1: 0.057292, loss_fp: 0.006867, loss_freq: 0.023903
[13:49:24.839] iteration 10585: loss: 0.073743, loss_s1: 0.060034, loss_fp: 0.001417, loss_freq: 0.023305
[13:49:25.530] iteration 10586: loss: 0.090226, loss_s1: 0.034481, loss_fp: 0.005560, loss_freq: 0.022986
[13:49:26.174] iteration 10587: loss: 0.091194, loss_s1: 0.075264, loss_fp: 0.002727, loss_freq: 0.052944
[13:49:26.804] iteration 10588: loss: 0.054257, loss_s1: 0.010232, loss_fp: 0.001869, loss_freq: 0.003967
[13:49:27.434] iteration 10589: loss: 0.058309, loss_s1: 0.036448, loss_fp: 0.005357, loss_freq: 0.031640
[13:49:28.056] iteration 10590: loss: 0.124027, loss_s1: 0.037115, loss_fp: 0.035587, loss_freq: 0.054906
[13:49:28.684] iteration 10591: loss: 0.065914, loss_s1: 0.051991, loss_fp: 0.001883, loss_freq: 0.022935
[13:49:29.310] iteration 10592: loss: 0.074494, loss_s1: 0.038700, loss_fp: 0.000731, loss_freq: 0.017366
[13:49:29.969] iteration 10593: loss: 0.073827, loss_s1: 0.045401, loss_fp: 0.002643, loss_freq: 0.050367
[13:49:30.627] iteration 10594: loss: 0.058315, loss_s1: 0.044606, loss_fp: 0.001501, loss_freq: 0.015045
[13:49:31.283] iteration 10595: loss: 0.073949, loss_s1: 0.050629, loss_fp: 0.010767, loss_freq: 0.014885
[13:49:31.942] iteration 10596: loss: 0.038109, loss_s1: 0.016079, loss_fp: 0.001536, loss_freq: 0.008047
[13:49:32.563] iteration 10597: loss: 0.115867, loss_s1: 0.088930, loss_fp: 0.003134, loss_freq: 0.055439
[13:49:33.185] iteration 10598: loss: 0.065099, loss_s1: 0.041521, loss_fp: 0.002189, loss_freq: 0.026641
[13:49:33.812] iteration 10599: loss: 0.159350, loss_s1: 0.026085, loss_fp: 0.000415, loss_freq: 0.023650
[13:49:34.433] iteration 10600: loss: 0.089957, loss_s1: 0.047514, loss_fp: 0.001189, loss_freq: 0.018284
[13:49:37.733] iteration 10600 : mean_dice : 0.741578
[13:49:38.395] iteration 10601: loss: 0.082957, loss_s1: 0.057632, loss_fp: 0.002680, loss_freq: 0.037640
[13:49:39.021] iteration 10602: loss: 0.080915, loss_s1: 0.056441, loss_fp: 0.003485, loss_freq: 0.026937
[13:49:39.640] iteration 10603: loss: 0.081813, loss_s1: 0.028315, loss_fp: 0.003729, loss_freq: 0.054003
[13:49:40.272] iteration 10604: loss: 0.059124, loss_s1: 0.046507, loss_fp: 0.002183, loss_freq: 0.022651
[13:49:40.899] iteration 10605: loss: 0.063498, loss_s1: 0.024029, loss_fp: 0.001085, loss_freq: 0.031739
[13:49:41.527] iteration 10606: loss: 0.059866, loss_s1: 0.025398, loss_fp: 0.001900, loss_freq: 0.005734
[13:49:42.155] iteration 10607: loss: 0.054655, loss_s1: 0.035908, loss_fp: 0.007721, loss_freq: 0.009461
[13:49:42.784] iteration 10608: loss: 0.163351, loss_s1: 0.105298, loss_fp: 0.001067, loss_freq: 0.060406
[13:49:43.409] iteration 10609: loss: 0.110354, loss_s1: 0.058882, loss_fp: 0.003893, loss_freq: 0.065441
[13:49:44.039] iteration 10610: loss: 0.052055, loss_s1: 0.023871, loss_fp: 0.004192, loss_freq: 0.015538
[13:49:44.693] iteration 10611: loss: 0.102513, loss_s1: 0.024273, loss_fp: 0.008190, loss_freq: 0.078019
[13:49:45.365] iteration 10612: loss: 0.053075, loss_s1: 0.026522, loss_fp: 0.001095, loss_freq: 0.008644
[13:49:46.014] iteration 10613: loss: 0.062613, loss_s1: 0.057855, loss_fp: 0.003084, loss_freq: 0.009344
[13:49:46.672] iteration 10614: loss: 0.089969, loss_s1: 0.037019, loss_fp: 0.004135, loss_freq: 0.071491
[13:49:47.342] iteration 10615: loss: 0.062282, loss_s1: 0.044373, loss_fp: 0.002059, loss_freq: 0.041999
[13:49:48.030] iteration 10616: loss: 0.099492, loss_s1: 0.039817, loss_fp: 0.001619, loss_freq: 0.103242
[13:49:48.712] iteration 10617: loss: 0.135806, loss_s1: 0.044893, loss_fp: 0.004689, loss_freq: 0.035139
[13:49:49.363] iteration 10618: loss: 0.104247, loss_s1: 0.049003, loss_fp: 0.004048, loss_freq: 0.048169
[13:49:50.026] iteration 10619: loss: 0.064779, loss_s1: 0.051881, loss_fp: 0.001989, loss_freq: 0.011599
[13:49:50.680] iteration 10620: loss: 0.052519, loss_s1: 0.015816, loss_fp: 0.002367, loss_freq: 0.031980
[13:49:51.337] iteration 10621: loss: 0.082461, loss_s1: 0.043619, loss_fp: 0.003582, loss_freq: 0.035965
[13:49:51.968] iteration 10622: loss: 0.047533, loss_s1: 0.041233, loss_fp: 0.001724, loss_freq: 0.010946
[13:49:52.595] iteration 10623: loss: 0.173670, loss_s1: 0.168358, loss_fp: 0.014816, loss_freq: 0.022085
[13:49:53.252] iteration 10624: loss: 0.064875, loss_s1: 0.051828, loss_fp: 0.000564, loss_freq: 0.032891
[13:49:53.878] iteration 10625: loss: 0.082824, loss_s1: 0.039403, loss_fp: 0.001783, loss_freq: 0.010931
[13:49:54.502] iteration 10626: loss: 0.092727, loss_s1: 0.068151, loss_fp: 0.005322, loss_freq: 0.048188
[13:49:55.123] iteration 10627: loss: 0.092484, loss_s1: 0.048547, loss_fp: 0.000643, loss_freq: 0.031030
[13:49:55.751] iteration 10628: loss: 0.119049, loss_s1: 0.053716, loss_fp: 0.008060, loss_freq: 0.083156
[13:49:56.381] iteration 10629: loss: 0.075468, loss_s1: 0.041842, loss_fp: 0.001873, loss_freq: 0.044736
[13:49:57.073] iteration 10630: loss: 0.094865, loss_s1: 0.062626, loss_fp: 0.000787, loss_freq: 0.034603
[13:49:57.731] iteration 10631: loss: 0.056372, loss_s1: 0.045509, loss_fp: 0.000872, loss_freq: 0.020706
[13:49:58.387] iteration 10632: loss: 0.074932, loss_s1: 0.042011, loss_fp: 0.001680, loss_freq: 0.022069
[13:49:59.040] iteration 10633: loss: 0.079364, loss_s1: 0.061682, loss_fp: 0.004414, loss_freq: 0.026027
[13:49:59.697] iteration 10634: loss: 0.117290, loss_s1: 0.028587, loss_fp: 0.001090, loss_freq: 0.029627
[13:50:00.347] iteration 10635: loss: 0.052072, loss_s1: 0.030878, loss_fp: 0.001483, loss_freq: 0.007845
[13:50:00.995] iteration 10636: loss: 0.038825, loss_s1: 0.021124, loss_fp: 0.000431, loss_freq: 0.006722
[13:50:01.623] iteration 10637: loss: 0.040621, loss_s1: 0.023913, loss_fp: 0.000411, loss_freq: 0.007009
[13:50:02.251] iteration 10638: loss: 0.109169, loss_s1: 0.033890, loss_fp: 0.000560, loss_freq: 0.004792
[13:50:02.875] iteration 10639: loss: 0.093246, loss_s1: 0.067041, loss_fp: 0.001535, loss_freq: 0.026058
[13:50:03.559] iteration 10640: loss: 0.057542, loss_s1: 0.038791, loss_fp: 0.002015, loss_freq: 0.012352
[13:50:04.240] iteration 10641: loss: 0.086168, loss_s1: 0.052069, loss_fp: 0.017713, loss_freq: 0.048573
[13:50:04.944] iteration 10642: loss: 0.074158, loss_s1: 0.057050, loss_fp: 0.002061, loss_freq: 0.016205
[13:50:05.619] iteration 10643: loss: 0.052053, loss_s1: 0.024562, loss_fp: 0.005530, loss_freq: 0.016114
[13:50:06.305] iteration 10644: loss: 0.095919, loss_s1: 0.041074, loss_fp: 0.001218, loss_freq: 0.025877
[13:50:07.009] iteration 10645: loss: 0.091616, loss_s1: 0.078557, loss_fp: 0.003887, loss_freq: 0.020554
[13:50:07.640] iteration 10646: loss: 0.084181, loss_s1: 0.037191, loss_fp: 0.001579, loss_freq: 0.026913
[13:50:08.259] iteration 10647: loss: 0.126293, loss_s1: 0.075188, loss_fp: 0.008662, loss_freq: 0.029871
[13:50:08.885] iteration 10648: loss: 0.104358, loss_s1: 0.076971, loss_fp: 0.009576, loss_freq: 0.020824
[13:50:09.514] iteration 10649: loss: 0.131764, loss_s1: 0.047152, loss_fp: 0.002949, loss_freq: 0.080642
[13:50:10.141] iteration 10650: loss: 0.113054, loss_s1: 0.057281, loss_fp: 0.004557, loss_freq: 0.023123
[13:50:10.769] iteration 10651: loss: 0.067486, loss_s1: 0.060720, loss_fp: 0.001777, loss_freq: 0.014160
[13:50:11.392] iteration 10652: loss: 0.091752, loss_s1: 0.045664, loss_fp: 0.001572, loss_freq: 0.018458
[13:50:12.022] iteration 10653: loss: 0.086474, loss_s1: 0.032135, loss_fp: 0.003004, loss_freq: 0.025377
[13:50:12.636] iteration 10654: loss: 0.103591, loss_s1: 0.090689, loss_fp: 0.010105, loss_freq: 0.020994
[13:50:13.261] iteration 10655: loss: 0.049151, loss_s1: 0.010995, loss_fp: 0.004410, loss_freq: 0.028186
[13:50:13.887] iteration 10656: loss: 0.102548, loss_s1: 0.090592, loss_fp: 0.002939, loss_freq: 0.041112
[13:50:14.518] iteration 10657: loss: 0.060290, loss_s1: 0.040128, loss_fp: 0.011834, loss_freq: 0.027303
[13:50:15.144] iteration 10658: loss: 0.090275, loss_s1: 0.010904, loss_fp: 0.003373, loss_freq: 0.012418
[13:50:15.770] iteration 10659: loss: 0.085679, loss_s1: 0.052000, loss_fp: 0.000409, loss_freq: 0.066928
[13:50:16.391] iteration 10660: loss: 0.063371, loss_s1: 0.020399, loss_fp: 0.002045, loss_freq: 0.008210
[13:50:17.019] iteration 10661: loss: 0.074660, loss_s1: 0.021839, loss_fp: 0.002652, loss_freq: 0.064685
[13:50:17.647] iteration 10662: loss: 0.121129, loss_s1: 0.038186, loss_fp: 0.000828, loss_freq: 0.052467
[13:50:18.273] iteration 10663: loss: 0.083657, loss_s1: 0.035619, loss_fp: 0.000845, loss_freq: 0.051153
[13:50:18.896] iteration 10664: loss: 0.075311, loss_s1: 0.048532, loss_fp: 0.000366, loss_freq: 0.016852
[13:50:19.526] iteration 10665: loss: 0.069585, loss_s1: 0.010848, loss_fp: 0.000874, loss_freq: 0.035205
[13:50:20.147] iteration 10666: loss: 0.055135, loss_s1: 0.045633, loss_fp: 0.000409, loss_freq: 0.019398
[13:50:20.816] iteration 10667: loss: 0.112250, loss_s1: 0.044017, loss_fp: 0.001180, loss_freq: 0.009391
[13:50:21.443] iteration 10668: loss: 0.076230, loss_s1: 0.042951, loss_fp: 0.008525, loss_freq: 0.033730
[13:50:22.060] iteration 10669: loss: 0.113530, loss_s1: 0.046416, loss_fp: 0.005780, loss_freq: 0.015974
[13:50:22.687] iteration 10670: loss: 0.073678, loss_s1: 0.026808, loss_fp: 0.000755, loss_freq: 0.009307
[13:50:23.310] iteration 10671: loss: 0.099979, loss_s1: 0.038951, loss_fp: 0.004776, loss_freq: 0.035148
[13:50:23.936] iteration 10672: loss: 0.046318, loss_s1: 0.037419, loss_fp: 0.001328, loss_freq: 0.016034
[13:50:24.562] iteration 10673: loss: 0.101838, loss_s1: 0.041697, loss_fp: 0.002103, loss_freq: 0.020100
[13:50:25.218] iteration 10674: loss: 0.069553, loss_s1: 0.045870, loss_fp: 0.004163, loss_freq: 0.032939
[13:50:25.875] iteration 10675: loss: 0.064498, loss_s1: 0.066420, loss_fp: 0.000654, loss_freq: 0.016583
[13:50:26.531] iteration 10676: loss: 0.075646, loss_s1: 0.040768, loss_fp: 0.003052, loss_freq: 0.021910
[13:50:27.156] iteration 10677: loss: 0.053799, loss_s1: 0.034488, loss_fp: 0.000335, loss_freq: 0.004462
[13:50:27.790] iteration 10678: loss: 0.072836, loss_s1: 0.019964, loss_fp: 0.001780, loss_freq: 0.009560
[13:50:28.416] iteration 10679: loss: 0.086855, loss_s1: 0.022834, loss_fp: 0.005117, loss_freq: 0.043237
[13:50:29.047] iteration 10680: loss: 0.083294, loss_s1: 0.057780, loss_fp: 0.001589, loss_freq: 0.023745
[13:50:29.677] iteration 10681: loss: 0.073478, loss_s1: 0.008817, loss_fp: 0.002913, loss_freq: 0.019058
[13:50:30.302] iteration 10682: loss: 0.114459, loss_s1: 0.047346, loss_fp: 0.006099, loss_freq: 0.054450
[13:50:30.940] iteration 10683: loss: 0.090937, loss_s1: 0.068660, loss_fp: 0.001111, loss_freq: 0.025299
[13:50:31.563] iteration 10684: loss: 0.091472, loss_s1: 0.032216, loss_fp: 0.005002, loss_freq: 0.014678
[13:50:32.189] iteration 10685: loss: 0.043410, loss_s1: 0.018960, loss_fp: 0.006953, loss_freq: 0.005706
[13:50:32.820] iteration 10686: loss: 0.097475, loss_s1: 0.048733, loss_fp: 0.000871, loss_freq: 0.054044
[13:50:33.455] iteration 10687: loss: 0.058562, loss_s1: 0.024961, loss_fp: 0.001378, loss_freq: 0.021496
[13:50:34.078] iteration 10688: loss: 0.068666, loss_s1: 0.019695, loss_fp: 0.003287, loss_freq: 0.032370
[13:50:34.704] iteration 10689: loss: 0.116435, loss_s1: 0.089036, loss_fp: 0.000417, loss_freq: 0.076069
[13:50:35.334] iteration 10690: loss: 0.072403, loss_s1: 0.032751, loss_fp: 0.009316, loss_freq: 0.054386
[13:50:35.998] iteration 10691: loss: 0.071223, loss_s1: 0.034773, loss_fp: 0.002997, loss_freq: 0.012025
[13:50:36.649] iteration 10692: loss: 0.067679, loss_s1: 0.042367, loss_fp: 0.004779, loss_freq: 0.009817
[13:50:37.309] iteration 10693: loss: 0.083419, loss_s1: 0.018283, loss_fp: 0.000911, loss_freq: 0.020621
[13:50:37.982] iteration 10694: loss: 0.065889, loss_s1: 0.050454, loss_fp: 0.004136, loss_freq: 0.023101
[13:50:38.644] iteration 10695: loss: 0.073204, loss_s1: 0.037974, loss_fp: 0.001446, loss_freq: 0.008642
[13:50:39.310] iteration 10696: loss: 0.063674, loss_s1: 0.047902, loss_fp: 0.002402, loss_freq: 0.019583
[13:50:39.972] iteration 10697: loss: 0.101025, loss_s1: 0.052098, loss_fp: 0.002541, loss_freq: 0.032758
[13:50:40.624] iteration 10698: loss: 0.054047, loss_s1: 0.028762, loss_fp: 0.000662, loss_freq: 0.006087
[13:50:41.263] iteration 10699: loss: 0.086630, loss_s1: 0.058967, loss_fp: 0.002103, loss_freq: 0.047543
[13:50:41.895] iteration 10700: loss: 0.102268, loss_s1: 0.081119, loss_fp: 0.002391, loss_freq: 0.052359
[13:50:42.526] iteration 10701: loss: 0.062104, loss_s1: 0.036021, loss_fp: 0.004050, loss_freq: 0.030156
[13:50:43.156] iteration 10702: loss: 0.056177, loss_s1: 0.034262, loss_fp: 0.002185, loss_freq: 0.018646
[13:50:43.785] iteration 10703: loss: 0.073567, loss_s1: 0.038048, loss_fp: 0.004468, loss_freq: 0.028677
[13:50:44.407] iteration 10704: loss: 0.130334, loss_s1: 0.082194, loss_fp: 0.002729, loss_freq: 0.019485
[13:50:45.034] iteration 10705: loss: 0.057303, loss_s1: 0.039493, loss_fp: 0.000842, loss_freq: 0.019656
[13:50:45.671] iteration 10706: loss: 0.090067, loss_s1: 0.033336, loss_fp: 0.003298, loss_freq: 0.052861
[13:50:46.293] iteration 10707: loss: 0.084219, loss_s1: 0.078156, loss_fp: 0.005425, loss_freq: 0.028594
[13:50:46.916] iteration 10708: loss: 0.075334, loss_s1: 0.047687, loss_fp: 0.003255, loss_freq: 0.015922
[13:50:47.550] iteration 10709: loss: 0.063707, loss_s1: 0.025299, loss_fp: 0.003476, loss_freq: 0.013022
[13:50:48.179] iteration 10710: loss: 0.047271, loss_s1: 0.015222, loss_fp: 0.001990, loss_freq: 0.023284
[13:50:48.809] iteration 10711: loss: 0.103640, loss_s1: 0.104487, loss_fp: 0.001871, loss_freq: 0.018268
[13:50:49.437] iteration 10712: loss: 0.083468, loss_s1: 0.055955, loss_fp: 0.000923, loss_freq: 0.052001
[13:50:50.071] iteration 10713: loss: 0.065956, loss_s1: 0.015804, loss_fp: 0.007154, loss_freq: 0.021445
[13:50:50.702] iteration 10714: loss: 0.147435, loss_s1: 0.080871, loss_fp: 0.005173, loss_freq: 0.028675
[13:50:51.323] iteration 10715: loss: 0.077114, loss_s1: 0.061878, loss_fp: 0.003287, loss_freq: 0.026985
[13:50:51.953] iteration 10716: loss: 0.185269, loss_s1: 0.195152, loss_fp: 0.006399, loss_freq: 0.081433
[13:50:52.584] iteration 10717: loss: 0.105225, loss_s1: 0.058398, loss_fp: 0.006651, loss_freq: 0.032532
[13:50:53.209] iteration 10718: loss: 0.061457, loss_s1: 0.016784, loss_fp: 0.001192, loss_freq: 0.017553
[13:50:53.857] iteration 10719: loss: 0.115365, loss_s1: 0.140098, loss_fp: 0.002907, loss_freq: 0.033039
[13:50:54.543] iteration 10720: loss: 0.051096, loss_s1: 0.012493, loss_fp: 0.001417, loss_freq: 0.033132
[13:50:55.182] iteration 10721: loss: 0.058382, loss_s1: 0.026494, loss_fp: 0.003813, loss_freq: 0.014054
[13:50:55.815] iteration 10722: loss: 0.081449, loss_s1: 0.051054, loss_fp: 0.004481, loss_freq: 0.021681
[13:50:56.439] iteration 10723: loss: 0.087105, loss_s1: 0.056281, loss_fp: 0.003782, loss_freq: 0.034880
[13:50:57.064] iteration 10724: loss: 0.150100, loss_s1: 0.158685, loss_fp: 0.004893, loss_freq: 0.066069
[13:50:57.687] iteration 10725: loss: 0.058214, loss_s1: 0.044305, loss_fp: 0.002164, loss_freq: 0.021824
[13:50:58.683] iteration 10726: loss: 0.058401, loss_s1: 0.027970, loss_fp: 0.001408, loss_freq: 0.022778
[13:50:59.346] iteration 10727: loss: 0.100543, loss_s1: 0.113447, loss_fp: 0.001161, loss_freq: 0.032504
[13:51:00.005] iteration 10728: loss: 0.054930, loss_s1: 0.029414, loss_fp: 0.000970, loss_freq: 0.032144
[13:51:00.625] iteration 10729: loss: 0.062228, loss_s1: 0.036554, loss_fp: 0.001637, loss_freq: 0.016634
[13:51:01.288] iteration 10730: loss: 0.086525, loss_s1: 0.078524, loss_fp: 0.002466, loss_freq: 0.042695
[13:51:01.910] iteration 10731: loss: 0.065422, loss_s1: 0.024762, loss_fp: 0.000858, loss_freq: 0.002675
[13:51:02.539] iteration 10732: loss: 0.075602, loss_s1: 0.068268, loss_fp: 0.001586, loss_freq: 0.024443
[13:51:03.164] iteration 10733: loss: 0.128276, loss_s1: 0.094840, loss_fp: 0.006335, loss_freq: 0.045002
[13:51:03.789] iteration 10734: loss: 0.072827, loss_s1: 0.023597, loss_fp: 0.002124, loss_freq: 0.062578
[13:51:04.442] iteration 10735: loss: 0.076077, loss_s1: 0.029585, loss_fp: 0.001881, loss_freq: 0.012249
[13:51:05.102] iteration 10736: loss: 0.083185, loss_s1: 0.058830, loss_fp: 0.006338, loss_freq: 0.036037
[13:51:05.765] iteration 10737: loss: 0.058611, loss_s1: 0.018551, loss_fp: 0.001011, loss_freq: 0.034092
[13:51:06.430] iteration 10738: loss: 0.081225, loss_s1: 0.064486, loss_fp: 0.002119, loss_freq: 0.012925
[13:51:07.088] iteration 10739: loss: 0.056727, loss_s1: 0.017701, loss_fp: 0.000760, loss_freq: 0.029936
[13:51:07.749] iteration 10740: loss: 0.100485, loss_s1: 0.120124, loss_fp: 0.003320, loss_freq: 0.026831
[13:51:08.381] iteration 10741: loss: 0.055461, loss_s1: 0.040110, loss_fp: 0.001385, loss_freq: 0.020559
[13:51:09.006] iteration 10742: loss: 0.103403, loss_s1: 0.020658, loss_fp: 0.001614, loss_freq: 0.012869
[13:51:09.633] iteration 10743: loss: 0.099031, loss_s1: 0.051252, loss_fp: 0.003048, loss_freq: 0.016248
[13:51:10.262] iteration 10744: loss: 0.063192, loss_s1: 0.030376, loss_fp: 0.000631, loss_freq: 0.009728
[13:51:10.893] iteration 10745: loss: 0.062337, loss_s1: 0.022188, loss_fp: 0.003458, loss_freq: 0.039981
[13:51:11.516] iteration 10746: loss: 0.104936, loss_s1: 0.035643, loss_fp: 0.002317, loss_freq: 0.061610
[13:51:12.148] iteration 10747: loss: 0.055658, loss_s1: 0.025540, loss_fp: 0.000892, loss_freq: 0.028702
[13:51:12.779] iteration 10748: loss: 0.068758, loss_s1: 0.062135, loss_fp: 0.002913, loss_freq: 0.017305
[13:51:13.416] iteration 10749: loss: 0.077048, loss_s1: 0.074166, loss_fp: 0.002118, loss_freq: 0.015274
[13:51:14.036] iteration 10750: loss: 0.053592, loss_s1: 0.019508, loss_fp: 0.001472, loss_freq: 0.027714
[13:51:14.677] iteration 10751: loss: 0.098624, loss_s1: 0.066532, loss_fp: 0.003735, loss_freq: 0.017920
[13:51:15.329] iteration 10752: loss: 0.114749, loss_s1: 0.075654, loss_fp: 0.001919, loss_freq: 0.069358
[13:51:15.953] iteration 10753: loss: 0.053952, loss_s1: 0.034005, loss_fp: 0.002821, loss_freq: 0.019937
[13:51:16.580] iteration 10754: loss: 0.066984, loss_s1: 0.012330, loss_fp: 0.003028, loss_freq: 0.060145
[13:51:17.208] iteration 10755: loss: 0.054671, loss_s1: 0.023237, loss_fp: 0.000595, loss_freq: 0.017858
[13:51:17.829] iteration 10756: loss: 0.057348, loss_s1: 0.024451, loss_fp: 0.001367, loss_freq: 0.031748
[13:51:18.467] iteration 10757: loss: 0.072110, loss_s1: 0.037261, loss_fp: 0.002096, loss_freq: 0.021582
[13:51:19.097] iteration 10758: loss: 0.058416, loss_s1: 0.025163, loss_fp: 0.005446, loss_freq: 0.026212
[13:51:19.719] iteration 10759: loss: 0.086215, loss_s1: 0.076766, loss_fp: 0.005469, loss_freq: 0.036157
[13:51:20.339] iteration 10760: loss: 0.093446, loss_s1: 0.078893, loss_fp: 0.001126, loss_freq: 0.024387
[13:51:20.969] iteration 10761: loss: 0.135362, loss_s1: 0.080605, loss_fp: 0.004489, loss_freq: 0.095243
[13:51:21.602] iteration 10762: loss: 0.061821, loss_s1: 0.034516, loss_fp: 0.004201, loss_freq: 0.028960
[13:51:22.237] iteration 10763: loss: 0.092477, loss_s1: 0.037227, loss_fp: 0.015006, loss_freq: 0.070611
[13:51:22.863] iteration 10764: loss: 0.107532, loss_s1: 0.046647, loss_fp: 0.005828, loss_freq: 0.065560
[13:51:23.497] iteration 10765: loss: 0.053016, loss_s1: 0.023113, loss_fp: 0.002349, loss_freq: 0.031741
[13:51:24.128] iteration 10766: loss: 0.105862, loss_s1: 0.036257, loss_fp: 0.011954, loss_freq: 0.053864
[13:51:24.755] iteration 10767: loss: 0.084512, loss_s1: 0.075884, loss_fp: 0.001137, loss_freq: 0.040575
[13:51:25.375] iteration 10768: loss: 0.095155, loss_s1: 0.058778, loss_fp: 0.006302, loss_freq: 0.022561
[13:51:26.002] iteration 10769: loss: 0.076019, loss_s1: 0.030541, loss_fp: 0.000724, loss_freq: 0.056724
[13:51:26.631] iteration 10770: loss: 0.100476, loss_s1: 0.040237, loss_fp: 0.001065, loss_freq: 0.055791
[13:51:27.262] iteration 10771: loss: 0.113611, loss_s1: 0.098103, loss_fp: 0.000943, loss_freq: 0.057292
[13:51:27.909] iteration 10772: loss: 0.068899, loss_s1: 0.039166, loss_fp: 0.001794, loss_freq: 0.012843
[13:51:28.557] iteration 10773: loss: 0.063872, loss_s1: 0.023686, loss_fp: 0.004849, loss_freq: 0.034867
[13:51:29.193] iteration 10774: loss: 0.045623, loss_s1: 0.021362, loss_fp: 0.001140, loss_freq: 0.026119
[13:51:29.857] iteration 10775: loss: 0.085841, loss_s1: 0.054336, loss_fp: 0.001192, loss_freq: 0.017640
[13:51:30.489] iteration 10776: loss: 0.048877, loss_s1: 0.019058, loss_fp: 0.004720, loss_freq: 0.024677
[13:51:31.126] iteration 10777: loss: 0.128374, loss_s1: 0.028756, loss_fp: 0.000991, loss_freq: 0.022619
[13:51:31.755] iteration 10778: loss: 0.054106, loss_s1: 0.032550, loss_fp: 0.003207, loss_freq: 0.020456
[13:51:32.393] iteration 10779: loss: 0.064920, loss_s1: 0.044693, loss_fp: 0.007643, loss_freq: 0.028125
[13:51:33.029] iteration 10780: loss: 0.039716, loss_s1: 0.012352, loss_fp: 0.001334, loss_freq: 0.027577
[13:51:33.661] iteration 10781: loss: 0.110280, loss_s1: 0.021903, loss_fp: 0.004839, loss_freq: 0.005929
[13:51:34.289] iteration 10782: loss: 0.065524, loss_s1: 0.032339, loss_fp: 0.002186, loss_freq: 0.039823
[13:51:34.916] iteration 10783: loss: 0.061058, loss_s1: 0.043190, loss_fp: 0.006285, loss_freq: 0.008608
[13:51:35.540] iteration 10784: loss: 0.169057, loss_s1: 0.035689, loss_fp: 0.001604, loss_freq: 0.090771
[13:51:36.177] iteration 10785: loss: 0.068383, loss_s1: 0.044332, loss_fp: 0.001445, loss_freq: 0.018124
[13:51:36.799] iteration 10786: loss: 0.063239, loss_s1: 0.025096, loss_fp: 0.005781, loss_freq: 0.010591
[13:51:37.430] iteration 10787: loss: 0.071225, loss_s1: 0.041505, loss_fp: 0.002150, loss_freq: 0.019234
[13:51:38.054] iteration 10788: loss: 0.082057, loss_s1: 0.063635, loss_fp: 0.002801, loss_freq: 0.020699
[13:51:38.683] iteration 10789: loss: 0.061751, loss_s1: 0.010915, loss_fp: 0.003735, loss_freq: 0.024593
[13:51:39.311] iteration 10790: loss: 0.069745, loss_s1: 0.030522, loss_fp: 0.009054, loss_freq: 0.015391
[13:51:39.931] iteration 10791: loss: 0.071265, loss_s1: 0.031691, loss_fp: 0.001094, loss_freq: 0.030466
[13:51:40.554] iteration 10792: loss: 0.093922, loss_s1: 0.065629, loss_fp: 0.002911, loss_freq: 0.037974
[13:51:41.181] iteration 10793: loss: 0.102141, loss_s1: 0.035608, loss_fp: 0.002968, loss_freq: 0.031292
[13:51:41.831] iteration 10794: loss: 0.069766, loss_s1: 0.053537, loss_fp: 0.003162, loss_freq: 0.022305
[13:51:42.491] iteration 10795: loss: 0.106100, loss_s1: 0.044379, loss_fp: 0.004092, loss_freq: 0.077165
[13:51:43.148] iteration 10796: loss: 0.051748, loss_s1: 0.014896, loss_fp: 0.002522, loss_freq: 0.032065
[13:51:43.802] iteration 10797: loss: 0.053107, loss_s1: 0.021528, loss_fp: 0.002164, loss_freq: 0.026140
[13:51:44.461] iteration 10798: loss: 0.047476, loss_s1: 0.018659, loss_fp: 0.010022, loss_freq: 0.018174
[13:51:45.093] iteration 10799: loss: 0.116033, loss_s1: 0.119734, loss_fp: 0.003244, loss_freq: 0.013716
[13:51:45.720] iteration 10800: loss: 0.083449, loss_s1: 0.037800, loss_fp: 0.038806, loss_freq: 0.030613
[13:51:49.137] iteration 10800 : mean_dice : 0.758393
[13:51:49.785] iteration 10801: loss: 0.083750, loss_s1: 0.019687, loss_fp: 0.002655, loss_freq: 0.012323
[13:51:50.410] iteration 10802: loss: 0.047164, loss_s1: 0.025005, loss_fp: 0.011868, loss_freq: 0.016070
[13:51:51.032] iteration 10803: loss: 0.105673, loss_s1: 0.031464, loss_fp: 0.000976, loss_freq: 0.008624
[13:51:51.656] iteration 10804: loss: 0.104295, loss_s1: 0.102497, loss_fp: 0.002552, loss_freq: 0.038571
[13:51:52.282] iteration 10805: loss: 0.126537, loss_s1: 0.058100, loss_fp: 0.002684, loss_freq: 0.040639
[13:51:52.907] iteration 10806: loss: 0.080432, loss_s1: 0.036317, loss_fp: 0.001490, loss_freq: 0.036881
[13:51:53.529] iteration 10807: loss: 0.098842, loss_s1: 0.080785, loss_fp: 0.003380, loss_freq: 0.043099
[13:51:54.144] iteration 10808: loss: 0.087449, loss_s1: 0.031800, loss_fp: 0.005926, loss_freq: 0.020865
[13:51:54.773] iteration 10809: loss: 0.055463, loss_s1: 0.056984, loss_fp: 0.001216, loss_freq: 0.015100
[13:51:55.389] iteration 10810: loss: 0.075611, loss_s1: 0.026722, loss_fp: 0.001206, loss_freq: 0.017188
[13:51:56.012] iteration 10811: loss: 0.075962, loss_s1: 0.027791, loss_fp: 0.001312, loss_freq: 0.069878
[13:51:56.634] iteration 10812: loss: 0.083619, loss_s1: 0.039814, loss_fp: 0.000813, loss_freq: 0.018009
[13:51:57.265] iteration 10813: loss: 0.085060, loss_s1: 0.025297, loss_fp: 0.002166, loss_freq: 0.021143
[13:51:57.883] iteration 10814: loss: 0.039106, loss_s1: 0.014301, loss_fp: 0.002107, loss_freq: 0.013598
[13:51:58.506] iteration 10815: loss: 0.080851, loss_s1: 0.029238, loss_fp: 0.005431, loss_freq: 0.040219
[13:51:59.129] iteration 10816: loss: 0.099659, loss_s1: 0.029946, loss_fp: 0.002457, loss_freq: 0.033594
[13:51:59.756] iteration 10817: loss: 0.073820, loss_s1: 0.057334, loss_fp: 0.001362, loss_freq: 0.046983
[13:52:00.384] iteration 10818: loss: 0.068223, loss_s1: 0.066889, loss_fp: 0.001277, loss_freq: 0.019067
[13:52:01.018] iteration 10819: loss: 0.067078, loss_s1: 0.040321, loss_fp: 0.002463, loss_freq: 0.015451
[13:52:01.640] iteration 10820: loss: 0.053695, loss_s1: 0.037609, loss_fp: 0.001066, loss_freq: 0.016310
[13:52:02.264] iteration 10821: loss: 0.068296, loss_s1: 0.029994, loss_fp: 0.000601, loss_freq: 0.014874
[13:52:02.892] iteration 10822: loss: 0.085239, loss_s1: 0.056802, loss_fp: 0.002274, loss_freq: 0.054006
[13:52:03.521] iteration 10823: loss: 0.060953, loss_s1: 0.036226, loss_fp: 0.001172, loss_freq: 0.020722
[13:52:04.141] iteration 10824: loss: 0.087642, loss_s1: 0.049427, loss_fp: 0.002858, loss_freq: 0.033915
[13:52:04.769] iteration 10825: loss: 0.090092, loss_s1: 0.051418, loss_fp: 0.002813, loss_freq: 0.041102
[13:52:05.391] iteration 10826: loss: 0.082489, loss_s1: 0.047403, loss_fp: 0.007460, loss_freq: 0.025229
[13:52:06.010] iteration 10827: loss: 0.080347, loss_s1: 0.031334, loss_fp: 0.002034, loss_freq: 0.032134
[13:52:06.653] iteration 10828: loss: 0.075381, loss_s1: 0.076363, loss_fp: 0.004799, loss_freq: 0.022077
[13:52:07.340] iteration 10829: loss: 0.071528, loss_s1: 0.045053, loss_fp: 0.005579, loss_freq: 0.011976
[13:52:08.020] iteration 10830: loss: 0.129943, loss_s1: 0.043255, loss_fp: 0.003416, loss_freq: 0.085073
[13:52:08.724] iteration 10831: loss: 0.059629, loss_s1: 0.034963, loss_fp: 0.004199, loss_freq: 0.021118
[13:52:09.700] iteration 10832: loss: 0.152198, loss_s1: 0.062918, loss_fp: 0.006557, loss_freq: 0.174190
[13:52:10.504] iteration 10833: loss: 0.062147, loss_s1: 0.061530, loss_fp: 0.004014, loss_freq: 0.022012
[13:52:11.173] iteration 10834: loss: 0.051087, loss_s1: 0.018619, loss_fp: 0.000976, loss_freq: 0.009285
[13:52:11.801] iteration 10835: loss: 0.067031, loss_s1: 0.061629, loss_fp: 0.004992, loss_freq: 0.023932
[13:52:12.451] iteration 10836: loss: 0.074873, loss_s1: 0.016752, loss_fp: 0.001377, loss_freq: 0.044709
[13:52:13.076] iteration 10837: loss: 0.069764, loss_s1: 0.051271, loss_fp: 0.005720, loss_freq: 0.044558
[13:52:13.707] iteration 10838: loss: 0.075553, loss_s1: 0.037174, loss_fp: 0.002167, loss_freq: 0.021623
[13:52:14.334] iteration 10839: loss: 0.043136, loss_s1: 0.015694, loss_fp: 0.010638, loss_freq: 0.006691
[13:52:14.956] iteration 10840: loss: 0.098134, loss_s1: 0.046797, loss_fp: 0.001839, loss_freq: 0.026750
[13:52:15.575] iteration 10841: loss: 0.058599, loss_s1: 0.025099, loss_fp: 0.003233, loss_freq: 0.027147
[13:52:16.202] iteration 10842: loss: 0.076157, loss_s1: 0.030536, loss_fp: 0.002765, loss_freq: 0.042198
[13:52:16.820] iteration 10843: loss: 0.134467, loss_s1: 0.101358, loss_fp: 0.004655, loss_freq: 0.076052
[13:52:17.443] iteration 10844: loss: 0.080488, loss_s1: 0.052619, loss_fp: 0.016359, loss_freq: 0.027403
[13:52:18.076] iteration 10845: loss: 0.065497, loss_s1: 0.040936, loss_fp: 0.004686, loss_freq: 0.028496
[13:52:18.760] iteration 10846: loss: 0.101240, loss_s1: 0.065509, loss_fp: 0.001915, loss_freq: 0.074679
[13:52:19.420] iteration 10847: loss: 0.090053, loss_s1: 0.036536, loss_fp: 0.000699, loss_freq: 0.057861
[13:52:20.080] iteration 10848: loss: 0.052720, loss_s1: 0.029854, loss_fp: 0.008112, loss_freq: 0.010050
[13:52:20.736] iteration 10849: loss: 0.082983, loss_s1: 0.049555, loss_fp: 0.004672, loss_freq: 0.065081
[13:52:21.389] iteration 10850: loss: 0.080079, loss_s1: 0.077412, loss_fp: 0.010783, loss_freq: 0.021926
[13:52:22.055] iteration 10851: loss: 0.073092, loss_s1: 0.038505, loss_fp: 0.003682, loss_freq: 0.030289
[13:52:22.720] iteration 10852: loss: 0.072338, loss_s1: 0.052440, loss_fp: 0.000659, loss_freq: 0.041257
[13:52:23.355] iteration 10853: loss: 0.066109, loss_s1: 0.036071, loss_fp: 0.003323, loss_freq: 0.038946
[13:52:23.979] iteration 10854: loss: 0.095665, loss_s1: 0.054635, loss_fp: 0.002650, loss_freq: 0.028014
[13:52:24.606] iteration 10855: loss: 0.054496, loss_s1: 0.023402, loss_fp: 0.002565, loss_freq: 0.014049
[13:52:25.235] iteration 10856: loss: 0.118060, loss_s1: 0.076730, loss_fp: 0.006323, loss_freq: 0.016466
[13:52:25.858] iteration 10857: loss: 0.085698, loss_s1: 0.033947, loss_fp: 0.002301, loss_freq: 0.015132
[13:52:26.480] iteration 10858: loss: 0.070416, loss_s1: 0.042433, loss_fp: 0.004009, loss_freq: 0.029298
[13:52:27.106] iteration 10859: loss: 0.111434, loss_s1: 0.040822, loss_fp: 0.002650, loss_freq: 0.051446
[13:52:27.736] iteration 10860: loss: 0.092927, loss_s1: 0.044508, loss_fp: 0.001335, loss_freq: 0.020609
[13:52:28.393] iteration 10861: loss: 0.085243, loss_s1: 0.054960, loss_fp: 0.002012, loss_freq: 0.037184
[13:52:29.019] iteration 10862: loss: 0.083978, loss_s1: 0.061836, loss_fp: 0.007932, loss_freq: 0.029961
[13:52:29.649] iteration 10863: loss: 0.034215, loss_s1: 0.015200, loss_fp: 0.003911, loss_freq: 0.006057
[13:52:30.285] iteration 10864: loss: 0.056200, loss_s1: 0.024247, loss_fp: 0.001644, loss_freq: 0.012582
[13:52:30.913] iteration 10865: loss: 0.086695, loss_s1: 0.032177, loss_fp: 0.001437, loss_freq: 0.012936
[13:52:31.574] iteration 10866: loss: 0.070796, loss_s1: 0.036415, loss_fp: 0.004038, loss_freq: 0.045417
[13:52:32.194] iteration 10867: loss: 0.105819, loss_s1: 0.101583, loss_fp: 0.003264, loss_freq: 0.026891
[13:52:32.815] iteration 10868: loss: 0.080869, loss_s1: 0.037225, loss_fp: 0.000709, loss_freq: 0.037500
[13:52:33.781] iteration 10869: loss: 0.077395, loss_s1: 0.048633, loss_fp: 0.004434, loss_freq: 0.028411
[13:52:34.407] iteration 10870: loss: 0.067171, loss_s1: 0.037014, loss_fp: 0.002711, loss_freq: 0.030501
[13:52:35.037] iteration 10871: loss: 0.071787, loss_s1: 0.042428, loss_fp: 0.001450, loss_freq: 0.048639
[13:52:35.661] iteration 10872: loss: 0.099997, loss_s1: 0.063141, loss_fp: 0.000664, loss_freq: 0.024871
[13:52:36.289] iteration 10873: loss: 0.098773, loss_s1: 0.067109, loss_fp: 0.004145, loss_freq: 0.028589
[13:52:36.916] iteration 10874: loss: 0.099718, loss_s1: 0.026185, loss_fp: 0.001411, loss_freq: 0.003937
[13:52:37.578] iteration 10875: loss: 0.061721, loss_s1: 0.040559, loss_fp: 0.001147, loss_freq: 0.029964
[13:52:38.203] iteration 10876: loss: 0.119321, loss_s1: 0.051573, loss_fp: 0.006447, loss_freq: 0.032648
[13:52:38.858] iteration 10877: loss: 0.110627, loss_s1: 0.068140, loss_fp: 0.005499, loss_freq: 0.076971
[13:52:39.515] iteration 10878: loss: 0.095845, loss_s1: 0.020776, loss_fp: 0.000982, loss_freq: 0.009259
[13:52:40.175] iteration 10879: loss: 0.088736, loss_s1: 0.017123, loss_fp: 0.001908, loss_freq: 0.043732
[13:52:40.829] iteration 10880: loss: 0.052095, loss_s1: 0.009610, loss_fp: 0.001003, loss_freq: 0.009089
[13:52:41.484] iteration 10881: loss: 0.099224, loss_s1: 0.039926, loss_fp: 0.003347, loss_freq: 0.069501
[13:52:42.110] iteration 10882: loss: 0.034868, loss_s1: 0.014505, loss_fp: 0.001067, loss_freq: 0.009989
[13:52:42.785] iteration 10883: loss: 0.082487, loss_s1: 0.055667, loss_fp: 0.001085, loss_freq: 0.047588
[13:52:43.434] iteration 10884: loss: 0.082431, loss_s1: 0.061656, loss_fp: 0.000430, loss_freq: 0.016673
[13:52:44.097] iteration 10885: loss: 0.090148, loss_s1: 0.009338, loss_fp: 0.000832, loss_freq: 0.012380
[13:52:44.753] iteration 10886: loss: 0.074327, loss_s1: 0.045880, loss_fp: 0.002202, loss_freq: 0.013106
[13:52:45.411] iteration 10887: loss: 0.059978, loss_s1: 0.052087, loss_fp: 0.002238, loss_freq: 0.011648
[13:52:46.046] iteration 10888: loss: 0.069400, loss_s1: 0.073571, loss_fp: 0.005275, loss_freq: 0.007234
[13:52:46.668] iteration 10889: loss: 0.105572, loss_s1: 0.043124, loss_fp: 0.001700, loss_freq: 0.050495
[13:52:47.328] iteration 10890: loss: 0.061106, loss_s1: 0.019344, loss_fp: 0.000454, loss_freq: 0.051217
[13:52:47.966] iteration 10891: loss: 0.072055, loss_s1: 0.056035, loss_fp: 0.001621, loss_freq: 0.019984
[13:52:48.593] iteration 10892: loss: 0.071480, loss_s1: 0.022293, loss_fp: 0.005808, loss_freq: 0.012225
[13:52:49.227] iteration 10893: loss: 0.067799, loss_s1: 0.048571, loss_fp: 0.003197, loss_freq: 0.028237
[13:52:49.851] iteration 10894: loss: 0.131167, loss_s1: 0.043601, loss_fp: 0.007515, loss_freq: 0.098136
[13:52:50.482] iteration 10895: loss: 0.125711, loss_s1: 0.051152, loss_fp: 0.004501, loss_freq: 0.094104
[13:52:51.110] iteration 10896: loss: 0.059880, loss_s1: 0.061872, loss_fp: 0.002080, loss_freq: 0.006696
[13:52:51.735] iteration 10897: loss: 0.083214, loss_s1: 0.042362, loss_fp: 0.006850, loss_freq: 0.031034
[13:52:52.353] iteration 10898: loss: 0.116514, loss_s1: 0.027795, loss_fp: 0.003112, loss_freq: 0.017967
[13:52:52.981] iteration 10899: loss: 0.059398, loss_s1: 0.033099, loss_fp: 0.003277, loss_freq: 0.024738
[13:52:53.604] iteration 10900: loss: 0.093367, loss_s1: 0.072780, loss_fp: 0.008252, loss_freq: 0.035840
[13:52:54.232] iteration 10901: loss: 0.066167, loss_s1: 0.029456, loss_fp: 0.004324, loss_freq: 0.018174
[13:52:54.857] iteration 10902: loss: 0.111485, loss_s1: 0.143215, loss_fp: 0.004356, loss_freq: 0.021449
[13:52:55.478] iteration 10903: loss: 0.093857, loss_s1: 0.067505, loss_fp: 0.002189, loss_freq: 0.041296
[13:52:56.108] iteration 10904: loss: 0.068688, loss_s1: 0.038469, loss_fp: 0.001011, loss_freq: 0.045408
[13:52:56.728] iteration 10905: loss: 0.068741, loss_s1: 0.032166, loss_fp: 0.006649, loss_freq: 0.028970
[13:52:57.350] iteration 10906: loss: 0.076369, loss_s1: 0.073004, loss_fp: 0.003819, loss_freq: 0.025720
[13:52:57.970] iteration 10907: loss: 0.090957, loss_s1: 0.064938, loss_fp: 0.001051, loss_freq: 0.053495
[13:52:58.589] iteration 10908: loss: 0.060165, loss_s1: 0.037355, loss_fp: 0.004387, loss_freq: 0.014529
[13:52:59.211] iteration 10909: loss: 0.107257, loss_s1: 0.066678, loss_fp: 0.003536, loss_freq: 0.055353
[13:52:59.829] iteration 10910: loss: 0.035633, loss_s1: 0.012379, loss_fp: 0.000956, loss_freq: 0.020043
[13:53:00.486] iteration 10911: loss: 0.063243, loss_s1: 0.025083, loss_fp: 0.000514, loss_freq: 0.019009
[13:53:01.141] iteration 10912: loss: 0.085797, loss_s1: 0.043484, loss_fp: 0.010732, loss_freq: 0.059073
[13:53:01.802] iteration 10913: loss: 0.088942, loss_s1: 0.013539, loss_fp: 0.002809, loss_freq: 0.035579
[13:53:02.461] iteration 10914: loss: 0.085157, loss_s1: 0.048640, loss_fp: 0.002272, loss_freq: 0.057961
[13:53:03.099] iteration 10915: loss: 0.061890, loss_s1: 0.024313, loss_fp: 0.008190, loss_freq: 0.031076
[13:53:03.726] iteration 10916: loss: 0.056152, loss_s1: 0.027353, loss_fp: 0.004178, loss_freq: 0.029868
[13:53:04.347] iteration 10917: loss: 0.063478, loss_s1: 0.056968, loss_fp: 0.006813, loss_freq: 0.016708
[13:53:04.974] iteration 10918: loss: 0.059592, loss_s1: 0.045485, loss_fp: 0.002475, loss_freq: 0.020858
[13:53:05.618] iteration 10919: loss: 0.061726, loss_s1: 0.033341, loss_fp: 0.002344, loss_freq: 0.012079
[13:53:06.243] iteration 10920: loss: 0.097461, loss_s1: 0.025540, loss_fp: 0.000886, loss_freq: 0.055425
[13:53:06.870] iteration 10921: loss: 0.045614, loss_s1: 0.035064, loss_fp: 0.001539, loss_freq: 0.010565
[13:53:07.491] iteration 10922: loss: 0.054526, loss_s1: 0.036851, loss_fp: 0.006274, loss_freq: 0.022484
[13:53:08.109] iteration 10923: loss: 0.061760, loss_s1: 0.054867, loss_fp: 0.002533, loss_freq: 0.013066
[13:53:08.733] iteration 10924: loss: 0.071114, loss_s1: 0.019409, loss_fp: 0.001061, loss_freq: 0.017847
[13:53:09.365] iteration 10925: loss: 0.086696, loss_s1: 0.086493, loss_fp: 0.003070, loss_freq: 0.017768
[13:53:09.995] iteration 10926: loss: 0.059539, loss_s1: 0.027974, loss_fp: 0.001578, loss_freq: 0.033078
[13:53:10.620] iteration 10927: loss: 0.109171, loss_s1: 0.048790, loss_fp: 0.003916, loss_freq: 0.062512
[13:53:11.248] iteration 10928: loss: 0.101557, loss_s1: 0.077589, loss_fp: 0.001784, loss_freq: 0.056507
[13:53:11.874] iteration 10929: loss: 0.080154, loss_s1: 0.052072, loss_fp: 0.001710, loss_freq: 0.010122
[13:53:12.494] iteration 10930: loss: 0.058693, loss_s1: 0.051866, loss_fp: 0.002336, loss_freq: 0.010712
[13:53:13.121] iteration 10931: loss: 0.134593, loss_s1: 0.134290, loss_fp: 0.029563, loss_freq: 0.028478
[13:53:13.754] iteration 10932: loss: 0.098103, loss_s1: 0.023026, loss_fp: 0.004074, loss_freq: 0.015033
[13:53:14.380] iteration 10933: loss: 0.115344, loss_s1: 0.077924, loss_fp: 0.005628, loss_freq: 0.017803
[13:53:15.008] iteration 10934: loss: 0.061461, loss_s1: 0.026679, loss_fp: 0.001972, loss_freq: 0.026125
[13:53:15.640] iteration 10935: loss: 0.107064, loss_s1: 0.076888, loss_fp: 0.003207, loss_freq: 0.062295
[13:53:16.258] iteration 10936: loss: 0.059240, loss_s1: 0.033710, loss_fp: 0.005020, loss_freq: 0.036028
[13:53:16.902] iteration 10937: loss: 0.081354, loss_s1: 0.035170, loss_fp: 0.001438, loss_freq: 0.024692
[13:53:17.527] iteration 10938: loss: 0.107466, loss_s1: 0.062531, loss_fp: 0.009158, loss_freq: 0.046289
[13:53:18.150] iteration 10939: loss: 0.107358, loss_s1: 0.047132, loss_fp: 0.006165, loss_freq: 0.028017
[13:53:18.761] iteration 10940: loss: 0.123659, loss_s1: 0.079255, loss_fp: 0.005311, loss_freq: 0.102206
[13:53:19.376] iteration 10941: loss: 0.063911, loss_s1: 0.028527, loss_fp: 0.007842, loss_freq: 0.038744
[13:53:19.993] iteration 10942: loss: 0.080523, loss_s1: 0.050276, loss_fp: 0.005401, loss_freq: 0.039333
[13:53:20.614] iteration 10943: loss: 0.095246, loss_s1: 0.073144, loss_fp: 0.002553, loss_freq: 0.028519
[13:53:21.247] iteration 10944: loss: 0.093726, loss_s1: 0.043676, loss_fp: 0.001710, loss_freq: 0.016937
[13:53:21.869] iteration 10945: loss: 0.063342, loss_s1: 0.020576, loss_fp: 0.003567, loss_freq: 0.045748
[13:53:22.498] iteration 10946: loss: 0.069105, loss_s1: 0.018130, loss_fp: 0.001998, loss_freq: 0.017201
[13:53:23.122] iteration 10947: loss: 0.079143, loss_s1: 0.048882, loss_fp: 0.007416, loss_freq: 0.050777
[13:53:23.750] iteration 10948: loss: 0.166963, loss_s1: 0.028132, loss_fp: 0.004039, loss_freq: 0.046697
[13:53:24.381] iteration 10949: loss: 0.083433, loss_s1: 0.054284, loss_fp: 0.002393, loss_freq: 0.025024
[13:53:25.008] iteration 10950: loss: 0.095814, loss_s1: 0.075645, loss_fp: 0.019540, loss_freq: 0.027400
[13:53:25.634] iteration 10951: loss: 0.077346, loss_s1: 0.046562, loss_fp: 0.006991, loss_freq: 0.021897
[13:53:26.263] iteration 10952: loss: 0.062605, loss_s1: 0.051076, loss_fp: 0.000944, loss_freq: 0.023310
[13:53:26.893] iteration 10953: loss: 0.075538, loss_s1: 0.039451, loss_fp: 0.005824, loss_freq: 0.023341
[13:53:27.513] iteration 10954: loss: 0.105116, loss_s1: 0.069194, loss_fp: 0.004155, loss_freq: 0.079693
[13:53:28.141] iteration 10955: loss: 0.079892, loss_s1: 0.036118, loss_fp: 0.002692, loss_freq: 0.020197
[13:53:28.777] iteration 10956: loss: 0.060351, loss_s1: 0.007199, loss_fp: 0.000590, loss_freq: 0.025906
[13:53:29.408] iteration 10957: loss: 0.055303, loss_s1: 0.055545, loss_fp: 0.001397, loss_freq: 0.007440
[13:53:30.042] iteration 10958: loss: 0.078851, loss_s1: 0.023986, loss_fp: 0.001171, loss_freq: 0.035885
[13:53:30.672] iteration 10959: loss: 0.083013, loss_s1: 0.058707, loss_fp: 0.000534, loss_freq: 0.020093
[13:53:31.300] iteration 10960: loss: 0.067047, loss_s1: 0.068030, loss_fp: 0.002050, loss_freq: 0.024600
[13:53:31.924] iteration 10961: loss: 0.059615, loss_s1: 0.032803, loss_fp: 0.015521, loss_freq: 0.011992
[13:53:32.548] iteration 10962: loss: 0.163955, loss_s1: 0.100698, loss_fp: 0.004747, loss_freq: 0.032425
[13:53:33.173] iteration 10963: loss: 0.054425, loss_s1: 0.031257, loss_fp: 0.001787, loss_freq: 0.010769
[13:53:33.798] iteration 10964: loss: 0.079021, loss_s1: 0.035805, loss_fp: 0.004994, loss_freq: 0.048011
[13:53:34.430] iteration 10965: loss: 0.104528, loss_s1: 0.081721, loss_fp: 0.004585, loss_freq: 0.041911
[13:53:35.065] iteration 10966: loss: 0.075151, loss_s1: 0.051772, loss_fp: 0.004494, loss_freq: 0.040024
[13:53:35.748] iteration 10967: loss: 0.106795, loss_s1: 0.042811, loss_fp: 0.012107, loss_freq: 0.030375
[13:53:36.410] iteration 10968: loss: 0.088577, loss_s1: 0.053124, loss_fp: 0.004310, loss_freq: 0.024897
[13:53:37.070] iteration 10969: loss: 0.121126, loss_s1: 0.058977, loss_fp: 0.004358, loss_freq: 0.026203
[13:53:37.731] iteration 10970: loss: 0.055412, loss_s1: 0.023367, loss_fp: 0.001190, loss_freq: 0.016576
[13:53:38.381] iteration 10971: loss: 0.065783, loss_s1: 0.059563, loss_fp: 0.002798, loss_freq: 0.026156
[13:53:39.008] iteration 10972: loss: 0.086977, loss_s1: 0.089169, loss_fp: 0.003907, loss_freq: 0.019698
[13:53:39.636] iteration 10973: loss: 0.068536, loss_s1: 0.012694, loss_fp: 0.003158, loss_freq: 0.030511
[13:53:40.269] iteration 10974: loss: 0.084431, loss_s1: 0.033926, loss_fp: 0.001461, loss_freq: 0.026084
[13:53:40.899] iteration 10975: loss: 0.137119, loss_s1: 0.113289, loss_fp: 0.001146, loss_freq: 0.090361
[13:53:41.522] iteration 10976: loss: 0.053882, loss_s1: 0.023775, loss_fp: 0.001139, loss_freq: 0.034071
[13:53:42.147] iteration 10977: loss: 0.089744, loss_s1: 0.036683, loss_fp: 0.001244, loss_freq: 0.038613
[13:53:42.787] iteration 10978: loss: 0.089830, loss_s1: 0.056326, loss_fp: 0.004012, loss_freq: 0.040105
[13:53:43.416] iteration 10979: loss: 0.092846, loss_s1: 0.043847, loss_fp: 0.001796, loss_freq: 0.018993
[13:53:44.047] iteration 10980: loss: 0.036204, loss_s1: 0.017211, loss_fp: 0.002168, loss_freq: 0.012359
[13:53:44.677] iteration 10981: loss: 0.074881, loss_s1: 0.035389, loss_fp: 0.001008, loss_freq: 0.026062
[13:53:45.315] iteration 10982: loss: 0.055652, loss_s1: 0.017091, loss_fp: 0.001800, loss_freq: 0.036343
[13:53:45.954] iteration 10983: loss: 0.117546, loss_s1: 0.037988, loss_fp: 0.000988, loss_freq: 0.034167
[13:53:46.581] iteration 10984: loss: 0.047681, loss_s1: 0.016035, loss_fp: 0.004151, loss_freq: 0.010792
[13:53:47.215] iteration 10985: loss: 0.087161, loss_s1: 0.030849, loss_fp: 0.003161, loss_freq: 0.026079
[13:53:47.849] iteration 10986: loss: 0.080042, loss_s1: 0.074825, loss_fp: 0.002270, loss_freq: 0.025961
[13:53:48.475] iteration 10987: loss: 0.087322, loss_s1: 0.101950, loss_fp: 0.002131, loss_freq: 0.026676
[13:53:49.102] iteration 10988: loss: 0.058621, loss_s1: 0.023555, loss_fp: 0.008075, loss_freq: 0.040406
[13:53:49.738] iteration 10989: loss: 0.086618, loss_s1: 0.066901, loss_fp: 0.002992, loss_freq: 0.046192
[13:53:50.360] iteration 10990: loss: 0.100587, loss_s1: 0.023342, loss_fp: 0.005832, loss_freq: 0.024828
[13:53:51.024] iteration 10991: loss: 0.071559, loss_s1: 0.029691, loss_fp: 0.006100, loss_freq: 0.014982
[13:53:51.679] iteration 10992: loss: 0.059543, loss_s1: 0.037281, loss_fp: 0.002365, loss_freq: 0.033999
[13:53:52.331] iteration 10993: loss: 0.077109, loss_s1: 0.040635, loss_fp: 0.012589, loss_freq: 0.054274
[13:53:52.985] iteration 10994: loss: 0.082859, loss_s1: 0.042521, loss_fp: 0.005350, loss_freq: 0.014781
[13:53:53.633] iteration 10995: loss: 0.068611, loss_s1: 0.040585, loss_fp: 0.000949, loss_freq: 0.021774
[13:53:54.266] iteration 10996: loss: 0.075444, loss_s1: 0.058831, loss_fp: 0.000833, loss_freq: 0.042546
[13:53:54.916] iteration 10997: loss: 0.079419, loss_s1: 0.072071, loss_fp: 0.001272, loss_freq: 0.013844
[13:53:55.539] iteration 10998: loss: 0.066327, loss_s1: 0.071370, loss_fp: 0.001226, loss_freq: 0.012179
[13:53:56.157] iteration 10999: loss: 0.124352, loss_s1: 0.084310, loss_fp: 0.002987, loss_freq: 0.026736
[13:53:56.812] iteration 11000: loss: 0.125211, loss_s1: 0.033388, loss_fp: 0.006942, loss_freq: 0.029903
[13:54:00.164] iteration 11000 : mean_dice : 0.735752
[13:54:00.844] iteration 11001: loss: 0.070523, loss_s1: 0.044762, loss_fp: 0.009812, loss_freq: 0.021874
[13:54:01.471] iteration 11002: loss: 0.129972, loss_s1: 0.078661, loss_fp: 0.004263, loss_freq: 0.044294
[13:54:02.104] iteration 11003: loss: 0.086313, loss_s1: 0.023840, loss_fp: 0.005139, loss_freq: 0.046005
[13:54:02.725] iteration 11004: loss: 0.091082, loss_s1: 0.063086, loss_fp: 0.008534, loss_freq: 0.032761
[13:54:03.354] iteration 11005: loss: 0.084662, loss_s1: 0.058918, loss_fp: 0.008012, loss_freq: 0.040799
[13:54:03.984] iteration 11006: loss: 0.085375, loss_s1: 0.015248, loss_fp: 0.008221, loss_freq: 0.004116
[13:54:04.608] iteration 11007: loss: 0.045550, loss_s1: 0.017300, loss_fp: 0.001470, loss_freq: 0.020070
[13:54:05.236] iteration 11008: loss: 0.100306, loss_s1: 0.031983, loss_fp: 0.001443, loss_freq: 0.036095
[13:54:05.948] iteration 11009: loss: 0.094895, loss_s1: 0.072858, loss_fp: 0.006791, loss_freq: 0.048112
[13:54:06.596] iteration 11010: loss: 0.132122, loss_s1: 0.081076, loss_fp: 0.009765, loss_freq: 0.091882
[13:54:07.243] iteration 11011: loss: 0.045673, loss_s1: 0.018566, loss_fp: 0.001461, loss_freq: 0.019580
[13:54:08.207] iteration 11012: loss: 0.063921, loss_s1: 0.016278, loss_fp: 0.000606, loss_freq: 0.034070
[13:54:08.866] iteration 11013: loss: 0.074372, loss_s1: 0.062267, loss_fp: 0.002907, loss_freq: 0.019367
[13:54:09.523] iteration 11014: loss: 0.056515, loss_s1: 0.029414, loss_fp: 0.001051, loss_freq: 0.030809
[13:54:10.183] iteration 11015: loss: 0.097143, loss_s1: 0.043719, loss_fp: 0.000691, loss_freq: 0.032758
[13:54:10.818] iteration 11016: loss: 0.090288, loss_s1: 0.036905, loss_fp: 0.014396, loss_freq: 0.061543
[13:54:11.445] iteration 11017: loss: 0.080938, loss_s1: 0.022832, loss_fp: 0.000265, loss_freq: 0.005555
[13:54:12.075] iteration 11018: loss: 0.050378, loss_s1: 0.035938, loss_fp: 0.001824, loss_freq: 0.010668
[13:54:12.713] iteration 11019: loss: 0.112615, loss_s1: 0.071376, loss_fp: 0.004521, loss_freq: 0.024189
[13:54:13.351] iteration 11020: loss: 0.084305, loss_s1: 0.041696, loss_fp: 0.002387, loss_freq: 0.045281
[13:54:14.025] iteration 11021: loss: 0.084979, loss_s1: 0.016216, loss_fp: 0.002382, loss_freq: 0.004834
[13:54:14.697] iteration 11022: loss: 0.105298, loss_s1: 0.099803, loss_fp: 0.002578, loss_freq: 0.024985
[13:54:15.351] iteration 11023: loss: 0.059151, loss_s1: 0.022059, loss_fp: 0.004811, loss_freq: 0.027024
[13:54:16.013] iteration 11024: loss: 0.070413, loss_s1: 0.051025, loss_fp: 0.001940, loss_freq: 0.019499
[13:54:16.646] iteration 11025: loss: 0.062434, loss_s1: 0.027601, loss_fp: 0.000691, loss_freq: 0.027888
[13:54:17.264] iteration 11026: loss: 0.080834, loss_s1: 0.073605, loss_fp: 0.001494, loss_freq: 0.032348
[13:54:17.915] iteration 11027: loss: 0.067891, loss_s1: 0.056238, loss_fp: 0.001280, loss_freq: 0.017588
[13:54:18.544] iteration 11028: loss: 0.069217, loss_s1: 0.029759, loss_fp: 0.004457, loss_freq: 0.013741
[13:54:19.173] iteration 11029: loss: 0.075109, loss_s1: 0.024408, loss_fp: 0.006182, loss_freq: 0.015884
[13:54:19.802] iteration 11030: loss: 0.049710, loss_s1: 0.033248, loss_fp: 0.001085, loss_freq: 0.015455
[13:54:20.452] iteration 11031: loss: 0.041287, loss_s1: 0.022186, loss_fp: 0.000583, loss_freq: 0.022421
[13:54:21.069] iteration 11032: loss: 0.214248, loss_s1: 0.072953, loss_fp: 0.001712, loss_freq: 0.090083
[13:54:21.711] iteration 11033: loss: 0.059750, loss_s1: 0.039587, loss_fp: 0.002148, loss_freq: 0.023491
[13:54:22.349] iteration 11034: loss: 0.068401, loss_s1: 0.035779, loss_fp: 0.000724, loss_freq: 0.039314
[13:54:22.998] iteration 11035: loss: 0.075107, loss_s1: 0.028265, loss_fp: 0.000724, loss_freq: 0.013664
[13:54:23.652] iteration 11036: loss: 0.064537, loss_s1: 0.023847, loss_fp: 0.009467, loss_freq: 0.029489
[13:54:24.291] iteration 11037: loss: 0.116040, loss_s1: 0.079458, loss_fp: 0.004351, loss_freq: 0.055481
[13:54:24.925] iteration 11038: loss: 0.083623, loss_s1: 0.040024, loss_fp: 0.007737, loss_freq: 0.052276
[13:54:25.556] iteration 11039: loss: 0.064609, loss_s1: 0.051381, loss_fp: 0.002517, loss_freq: 0.010461
[13:54:26.186] iteration 11040: loss: 0.104210, loss_s1: 0.052428, loss_fp: 0.001081, loss_freq: 0.075742
[13:54:26.815] iteration 11041: loss: 0.110689, loss_s1: 0.072138, loss_fp: 0.000586, loss_freq: 0.008171
[13:54:27.439] iteration 11042: loss: 0.066750, loss_s1: 0.034779, loss_fp: 0.002291, loss_freq: 0.010219
[13:54:28.061] iteration 11043: loss: 0.112828, loss_s1: 0.077903, loss_fp: 0.003859, loss_freq: 0.025399
[13:54:28.682] iteration 11044: loss: 0.065024, loss_s1: 0.043785, loss_fp: 0.004505, loss_freq: 0.020543
[13:54:29.305] iteration 11045: loss: 0.108024, loss_s1: 0.115592, loss_fp: 0.003955, loss_freq: 0.045318
[13:54:29.921] iteration 11046: loss: 0.129415, loss_s1: 0.071326, loss_fp: 0.007079, loss_freq: 0.025635
[13:54:30.544] iteration 11047: loss: 0.069492, loss_s1: 0.028297, loss_fp: 0.002887, loss_freq: 0.035948
[13:54:31.166] iteration 11048: loss: 0.057388, loss_s1: 0.026420, loss_fp: 0.001701, loss_freq: 0.018029
[13:54:31.790] iteration 11049: loss: 0.059848, loss_s1: 0.030571, loss_fp: 0.002381, loss_freq: 0.036641
[13:54:32.417] iteration 11050: loss: 0.132760, loss_s1: 0.092222, loss_fp: 0.010544, loss_freq: 0.035251
[13:54:33.050] iteration 11051: loss: 0.078043, loss_s1: 0.038394, loss_fp: 0.003172, loss_freq: 0.025180
[13:54:33.682] iteration 11052: loss: 0.116296, loss_s1: 0.065452, loss_fp: 0.002298, loss_freq: 0.047607
[13:54:34.304] iteration 11053: loss: 0.082870, loss_s1: 0.059336, loss_fp: 0.002720, loss_freq: 0.040720
[13:54:34.926] iteration 11054: loss: 0.074253, loss_s1: 0.037540, loss_fp: 0.000794, loss_freq: 0.006177
[13:54:35.544] iteration 11055: loss: 0.085172, loss_s1: 0.092341, loss_fp: 0.001092, loss_freq: 0.019124
[13:54:36.176] iteration 11056: loss: 0.071194, loss_s1: 0.014843, loss_fp: 0.001080, loss_freq: 0.017953
[13:54:36.803] iteration 11057: loss: 0.088852, loss_s1: 0.066655, loss_fp: 0.001140, loss_freq: 0.045522
[13:54:37.433] iteration 11058: loss: 0.087427, loss_s1: 0.021118, loss_fp: 0.001222, loss_freq: 0.071048
[13:54:38.056] iteration 11059: loss: 0.075221, loss_s1: 0.025340, loss_fp: 0.003257, loss_freq: 0.013979
[13:54:38.683] iteration 11060: loss: 0.048533, loss_s1: 0.030469, loss_fp: 0.001062, loss_freq: 0.012867
[13:54:39.308] iteration 11061: loss: 0.058071, loss_s1: 0.050130, loss_fp: 0.004622, loss_freq: 0.010865
[13:54:39.933] iteration 11062: loss: 0.077516, loss_s1: 0.071707, loss_fp: 0.005778, loss_freq: 0.020199
[13:54:40.555] iteration 11063: loss: 0.112386, loss_s1: 0.029021, loss_fp: 0.000959, loss_freq: 0.025370
[13:54:41.177] iteration 11064: loss: 0.061301, loss_s1: 0.026034, loss_fp: 0.000473, loss_freq: 0.004356
[13:54:41.797] iteration 11065: loss: 0.053547, loss_s1: 0.038548, loss_fp: 0.002329, loss_freq: 0.008873
[13:54:42.427] iteration 11066: loss: 0.052943, loss_s1: 0.033436, loss_fp: 0.003124, loss_freq: 0.007719
[13:54:43.042] iteration 11067: loss: 0.081735, loss_s1: 0.020578, loss_fp: 0.002630, loss_freq: 0.007149
[13:54:43.658] iteration 11068: loss: 0.063537, loss_s1: 0.029673, loss_fp: 0.002382, loss_freq: 0.009889
[13:54:44.285] iteration 11069: loss: 0.045515, loss_s1: 0.006736, loss_fp: 0.001958, loss_freq: 0.007420
[13:54:44.918] iteration 11070: loss: 0.079468, loss_s1: 0.049725, loss_fp: 0.002707, loss_freq: 0.030789
[13:54:45.542] iteration 11071: loss: 0.056944, loss_s1: 0.032544, loss_fp: 0.002000, loss_freq: 0.021074
[13:54:46.166] iteration 11072: loss: 0.073376, loss_s1: 0.023083, loss_fp: 0.003465, loss_freq: 0.039461
[13:54:46.789] iteration 11073: loss: 0.058224, loss_s1: 0.033641, loss_fp: 0.001095, loss_freq: 0.005821
[13:54:47.405] iteration 11074: loss: 0.075762, loss_s1: 0.036138, loss_fp: 0.001530, loss_freq: 0.048580
[13:54:48.024] iteration 11075: loss: 0.075658, loss_s1: 0.034546, loss_fp: 0.002752, loss_freq: 0.015202
[13:54:48.644] iteration 11076: loss: 0.108104, loss_s1: 0.027741, loss_fp: 0.005835, loss_freq: 0.063598
[13:54:49.294] iteration 11077: loss: 0.099269, loss_s1: 0.044554, loss_fp: 0.002224, loss_freq: 0.013830
[13:54:49.947] iteration 11078: loss: 0.128394, loss_s1: 0.084520, loss_fp: 0.027569, loss_freq: 0.075082
[13:54:50.599] iteration 11079: loss: 0.055532, loss_s1: 0.030452, loss_fp: 0.002044, loss_freq: 0.015119
[13:54:51.230] iteration 11080: loss: 0.060021, loss_s1: 0.042600, loss_fp: 0.006521, loss_freq: 0.019552
[13:54:51.849] iteration 11081: loss: 0.079109, loss_s1: 0.016623, loss_fp: 0.002625, loss_freq: 0.011089
[13:54:52.489] iteration 11082: loss: 0.079278, loss_s1: 0.079368, loss_fp: 0.000809, loss_freq: 0.017716
[13:54:53.141] iteration 11083: loss: 0.074044, loss_s1: 0.046868, loss_fp: 0.005465, loss_freq: 0.038507
[13:54:53.797] iteration 11084: loss: 0.129808, loss_s1: 0.060359, loss_fp: 0.001778, loss_freq: 0.138061
[13:54:54.448] iteration 11085: loss: 0.131037, loss_s1: 0.100003, loss_fp: 0.009218, loss_freq: 0.089697
[13:54:55.105] iteration 11086: loss: 0.102618, loss_s1: 0.052639, loss_fp: 0.010858, loss_freq: 0.078485
[13:54:55.770] iteration 11087: loss: 0.087823, loss_s1: 0.046359, loss_fp: 0.003783, loss_freq: 0.017998
[13:54:56.398] iteration 11088: loss: 0.088200, loss_s1: 0.057006, loss_fp: 0.006176, loss_freq: 0.014287
[13:54:57.024] iteration 11089: loss: 0.065572, loss_s1: 0.038778, loss_fp: 0.001305, loss_freq: 0.011739
[13:54:57.643] iteration 11090: loss: 0.068470, loss_s1: 0.065604, loss_fp: 0.002155, loss_freq: 0.019257
[13:54:58.270] iteration 11091: loss: 0.183145, loss_s1: 0.081166, loss_fp: 0.002886, loss_freq: 0.030906
[13:54:58.896] iteration 11092: loss: 0.068736, loss_s1: 0.030150, loss_fp: 0.000282, loss_freq: 0.034142
[13:54:59.524] iteration 11093: loss: 0.094069, loss_s1: 0.051894, loss_fp: 0.016379, loss_freq: 0.049292
[13:55:00.148] iteration 11094: loss: 0.081810, loss_s1: 0.062124, loss_fp: 0.002270, loss_freq: 0.019959
[13:55:00.773] iteration 11095: loss: 0.048528, loss_s1: 0.019032, loss_fp: 0.001940, loss_freq: 0.027919
[13:55:01.388] iteration 11096: loss: 0.062720, loss_s1: 0.015770, loss_fp: 0.003188, loss_freq: 0.019031
[13:55:02.015] iteration 11097: loss: 0.103168, loss_s1: 0.060895, loss_fp: 0.005484, loss_freq: 0.067772
[13:55:02.647] iteration 11098: loss: 0.065345, loss_s1: 0.025113, loss_fp: 0.000477, loss_freq: 0.007023
[13:55:03.270] iteration 11099: loss: 0.055964, loss_s1: 0.012819, loss_fp: 0.000510, loss_freq: 0.013380
[13:55:03.896] iteration 11100: loss: 0.039125, loss_s1: 0.008783, loss_fp: 0.001537, loss_freq: 0.004964
[13:55:04.519] iteration 11101: loss: 0.097435, loss_s1: 0.049114, loss_fp: 0.001641, loss_freq: 0.036210
[13:55:05.135] iteration 11102: loss: 0.081263, loss_s1: 0.021760, loss_fp: 0.001259, loss_freq: 0.027657
[13:55:05.761] iteration 11103: loss: 0.087284, loss_s1: 0.066952, loss_fp: 0.008810, loss_freq: 0.033841
[13:55:06.412] iteration 11104: loss: 0.063074, loss_s1: 0.020450, loss_fp: 0.001522, loss_freq: 0.016489
[13:55:07.040] iteration 11105: loss: 0.101949, loss_s1: 0.049761, loss_fp: 0.001969, loss_freq: 0.015854
[13:55:07.669] iteration 11106: loss: 0.050880, loss_s1: 0.037851, loss_fp: 0.001237, loss_freq: 0.008755
[13:55:08.363] iteration 11107: loss: 0.060086, loss_s1: 0.018600, loss_fp: 0.001117, loss_freq: 0.020416
[13:55:09.012] iteration 11108: loss: 0.135181, loss_s1: 0.053299, loss_fp: 0.003652, loss_freq: 0.134883
[13:55:09.644] iteration 11109: loss: 0.069928, loss_s1: 0.040283, loss_fp: 0.006709, loss_freq: 0.017666
[13:55:10.266] iteration 11110: loss: 0.078311, loss_s1: 0.022974, loss_fp: 0.003735, loss_freq: 0.021757
[13:55:10.891] iteration 11111: loss: 0.126918, loss_s1: 0.086734, loss_fp: 0.001688, loss_freq: 0.025273
[13:55:11.522] iteration 11112: loss: 0.082208, loss_s1: 0.012162, loss_fp: 0.001941, loss_freq: 0.025334
[13:55:12.182] iteration 11113: loss: 0.079926, loss_s1: 0.033561, loss_fp: 0.000674, loss_freq: 0.025657
[13:55:12.834] iteration 11114: loss: 0.050291, loss_s1: 0.009043, loss_fp: 0.011892, loss_freq: 0.015184
[13:55:13.490] iteration 11115: loss: 0.088011, loss_s1: 0.044318, loss_fp: 0.003782, loss_freq: 0.064665
[13:55:14.148] iteration 11116: loss: 0.094720, loss_s1: 0.053840, loss_fp: 0.003198, loss_freq: 0.035976
[13:55:14.788] iteration 11117: loss: 0.064787, loss_s1: 0.013236, loss_fp: 0.002028, loss_freq: 0.025204
[13:55:15.414] iteration 11118: loss: 0.137667, loss_s1: 0.096470, loss_fp: 0.001659, loss_freq: 0.102897
[13:55:16.036] iteration 11119: loss: 0.079746, loss_s1: 0.075927, loss_fp: 0.001452, loss_freq: 0.021957
[13:55:16.661] iteration 11120: loss: 0.080665, loss_s1: 0.036941, loss_fp: 0.002197, loss_freq: 0.016036
[13:55:17.281] iteration 11121: loss: 0.060674, loss_s1: 0.041946, loss_fp: 0.001324, loss_freq: 0.017291
[13:55:17.900] iteration 11122: loss: 0.088940, loss_s1: 0.043850, loss_fp: 0.000666, loss_freq: 0.034771
[13:55:18.553] iteration 11123: loss: 0.067987, loss_s1: 0.042007, loss_fp: 0.007057, loss_freq: 0.048382
[13:55:19.170] iteration 11124: loss: 0.081970, loss_s1: 0.045035, loss_fp: 0.001293, loss_freq: 0.030079
[13:55:19.795] iteration 11125: loss: 0.075174, loss_s1: 0.062551, loss_fp: 0.003140, loss_freq: 0.017377
[13:55:20.419] iteration 11126: loss: 0.104184, loss_s1: 0.018324, loss_fp: 0.002936, loss_freq: 0.017568
[13:55:21.043] iteration 11127: loss: 0.059333, loss_s1: 0.047570, loss_fp: 0.001533, loss_freq: 0.017470
[13:55:21.659] iteration 11128: loss: 0.120656, loss_s1: 0.052360, loss_fp: 0.002270, loss_freq: 0.090784
[13:55:22.285] iteration 11129: loss: 0.061891, loss_s1: 0.046984, loss_fp: 0.001841, loss_freq: 0.020993
[13:55:22.905] iteration 11130: loss: 0.065891, loss_s1: 0.071264, loss_fp: 0.002027, loss_freq: 0.007437
[13:55:23.530] iteration 11131: loss: 0.072116, loss_s1: 0.048982, loss_fp: 0.001304, loss_freq: 0.031470
[13:55:24.180] iteration 11132: loss: 0.076606, loss_s1: 0.047486, loss_fp: 0.002839, loss_freq: 0.047646
[13:55:24.792] iteration 11133: loss: 0.098023, loss_s1: 0.048504, loss_fp: 0.003404, loss_freq: 0.031352
[13:55:25.416] iteration 11134: loss: 0.050393, loss_s1: 0.014906, loss_fp: 0.001445, loss_freq: 0.031885
[13:55:26.040] iteration 11135: loss: 0.086252, loss_s1: 0.056196, loss_fp: 0.003904, loss_freq: 0.063423
[13:55:26.664] iteration 11136: loss: 0.062635, loss_s1: 0.031608, loss_fp: 0.000999, loss_freq: 0.026182
[13:55:27.286] iteration 11137: loss: 0.067806, loss_s1: 0.024586, loss_fp: 0.001769, loss_freq: 0.021666
[13:55:27.905] iteration 11138: loss: 0.053569, loss_s1: 0.013285, loss_fp: 0.001269, loss_freq: 0.027669
[13:55:28.558] iteration 11139: loss: 0.083323, loss_s1: 0.062313, loss_fp: 0.001183, loss_freq: 0.018619
[13:55:29.187] iteration 11140: loss: 0.151897, loss_s1: 0.107318, loss_fp: 0.010673, loss_freq: 0.044853
[13:55:29.814] iteration 11141: loss: 0.049059, loss_s1: 0.009129, loss_fp: 0.003002, loss_freq: 0.016111
[13:55:30.436] iteration 11142: loss: 0.081661, loss_s1: 0.065727, loss_fp: 0.003231, loss_freq: 0.015250
[13:55:31.064] iteration 11143: loss: 0.120258, loss_s1: 0.037387, loss_fp: 0.005636, loss_freq: 0.043759
[13:55:31.693] iteration 11144: loss: 0.075242, loss_s1: 0.034445, loss_fp: 0.001053, loss_freq: 0.030481
[13:55:32.315] iteration 11145: loss: 0.115292, loss_s1: 0.037055, loss_fp: 0.005876, loss_freq: 0.094318
[13:55:32.938] iteration 11146: loss: 0.072459, loss_s1: 0.022013, loss_fp: 0.006751, loss_freq: 0.013223
[13:55:33.564] iteration 11147: loss: 0.053366, loss_s1: 0.033578, loss_fp: 0.005945, loss_freq: 0.013883
[13:55:34.190] iteration 11148: loss: 0.102691, loss_s1: 0.088997, loss_fp: 0.004277, loss_freq: 0.034934
[13:55:34.811] iteration 11149: loss: 0.062842, loss_s1: 0.053917, loss_fp: 0.001125, loss_freq: 0.024986
[13:55:35.436] iteration 11150: loss: 0.045419, loss_s1: 0.017259, loss_fp: 0.001739, loss_freq: 0.017357
[13:55:36.060] iteration 11151: loss: 0.080211, loss_s1: 0.047897, loss_fp: 0.001472, loss_freq: 0.020708
[13:55:36.705] iteration 11152: loss: 0.104493, loss_s1: 0.088594, loss_fp: 0.004839, loss_freq: 0.058533
[13:55:37.356] iteration 11153: loss: 0.118747, loss_s1: 0.105643, loss_fp: 0.004351, loss_freq: 0.053981
[13:55:38.011] iteration 11154: loss: 0.052837, loss_s1: 0.045255, loss_fp: 0.000535, loss_freq: 0.007074
[13:55:38.956] iteration 11155: loss: 0.063825, loss_s1: 0.065582, loss_fp: 0.002251, loss_freq: 0.006397
[13:55:39.612] iteration 11156: loss: 0.058799, loss_s1: 0.009094, loss_fp: 0.003684, loss_freq: 0.014787
[13:55:40.279] iteration 11157: loss: 0.053041, loss_s1: 0.030102, loss_fp: 0.000400, loss_freq: 0.023734
[13:55:40.902] iteration 11158: loss: 0.081792, loss_s1: 0.018009, loss_fp: 0.001755, loss_freq: 0.034252
[13:55:41.558] iteration 11159: loss: 0.090359, loss_s1: 0.057184, loss_fp: 0.003211, loss_freq: 0.030814
[13:55:42.214] iteration 11160: loss: 0.062972, loss_s1: 0.015655, loss_fp: 0.001217, loss_freq: 0.007769
[13:55:42.851] iteration 11161: loss: 0.073413, loss_s1: 0.087244, loss_fp: 0.003082, loss_freq: 0.021402
[13:55:43.476] iteration 11162: loss: 0.100833, loss_s1: 0.049182, loss_fp: 0.001397, loss_freq: 0.015664
[13:55:44.098] iteration 11163: loss: 0.052298, loss_s1: 0.030715, loss_fp: 0.002313, loss_freq: 0.023526
[13:55:44.719] iteration 11164: loss: 0.073070, loss_s1: 0.027703, loss_fp: 0.000609, loss_freq: 0.008238
[13:55:45.343] iteration 11165: loss: 0.073982, loss_s1: 0.035543, loss_fp: 0.005139, loss_freq: 0.045107
[13:55:45.971] iteration 11166: loss: 0.056808, loss_s1: 0.029003, loss_fp: 0.002317, loss_freq: 0.025556
[13:55:46.598] iteration 11167: loss: 0.097696, loss_s1: 0.097194, loss_fp: 0.003361, loss_freq: 0.018648
[13:55:47.220] iteration 11168: loss: 0.077924, loss_s1: 0.057536, loss_fp: 0.002602, loss_freq: 0.034932
[13:55:47.839] iteration 11169: loss: 0.087380, loss_s1: 0.085639, loss_fp: 0.001678, loss_freq: 0.037877
[13:55:48.461] iteration 11170: loss: 0.053747, loss_s1: 0.037208, loss_fp: 0.001461, loss_freq: 0.019401
[13:55:49.081] iteration 11171: loss: 0.071569, loss_s1: 0.031321, loss_fp: 0.000723, loss_freq: 0.011701
[13:55:49.714] iteration 11172: loss: 0.118779, loss_s1: 0.062792, loss_fp: 0.004480, loss_freq: 0.009831
[13:55:50.332] iteration 11173: loss: 0.055233, loss_s1: 0.033557, loss_fp: 0.004080, loss_freq: 0.020004
[13:55:50.952] iteration 11174: loss: 0.066493, loss_s1: 0.062013, loss_fp: 0.001899, loss_freq: 0.027779
[13:55:51.579] iteration 11175: loss: 0.074899, loss_s1: 0.009874, loss_fp: 0.002673, loss_freq: 0.052261
[13:55:52.204] iteration 11176: loss: 0.059244, loss_s1: 0.020365, loss_fp: 0.002669, loss_freq: 0.021261
[13:55:52.832] iteration 11177: loss: 0.067891, loss_s1: 0.057539, loss_fp: 0.000782, loss_freq: 0.022821
[13:55:53.454] iteration 11178: loss: 0.084434, loss_s1: 0.073236, loss_fp: 0.002880, loss_freq: 0.016226
[13:55:54.076] iteration 11179: loss: 0.062299, loss_s1: 0.041271, loss_fp: 0.001977, loss_freq: 0.030487
[13:55:54.744] iteration 11180: loss: 0.077028, loss_s1: 0.044826, loss_fp: 0.002123, loss_freq: 0.025276
[13:55:55.400] iteration 11181: loss: 0.092347, loss_s1: 0.017644, loss_fp: 0.006137, loss_freq: 0.081910
[13:55:56.054] iteration 11182: loss: 0.048494, loss_s1: 0.028909, loss_fp: 0.001715, loss_freq: 0.010233
[13:55:56.707] iteration 11183: loss: 0.079352, loss_s1: 0.050516, loss_fp: 0.001964, loss_freq: 0.014654
[13:55:57.352] iteration 11184: loss: 0.080453, loss_s1: 0.051154, loss_fp: 0.001248, loss_freq: 0.016584
[13:55:57.974] iteration 11185: loss: 0.076802, loss_s1: 0.052886, loss_fp: 0.004514, loss_freq: 0.016802
[13:55:58.604] iteration 11186: loss: 0.059589, loss_s1: 0.022708, loss_fp: 0.001851, loss_freq: 0.023224
[13:55:59.222] iteration 11187: loss: 0.061978, loss_s1: 0.050634, loss_fp: 0.001822, loss_freq: 0.018008
[13:55:59.839] iteration 11188: loss: 0.105910, loss_s1: 0.052857, loss_fp: 0.005999, loss_freq: 0.112338
[13:56:00.461] iteration 11189: loss: 0.074584, loss_s1: 0.056497, loss_fp: 0.012165, loss_freq: 0.016114
[13:56:01.096] iteration 11190: loss: 0.117918, loss_s1: 0.112079, loss_fp: 0.002970, loss_freq: 0.047790
[13:56:01.721] iteration 11191: loss: 0.097947, loss_s1: 0.101186, loss_fp: 0.003557, loss_freq: 0.015291
[13:56:02.348] iteration 11192: loss: 0.066963, loss_s1: 0.025749, loss_fp: 0.004560, loss_freq: 0.051180
[13:56:02.969] iteration 11193: loss: 0.121861, loss_s1: 0.063245, loss_fp: 0.001887, loss_freq: 0.074210
[13:56:03.598] iteration 11194: loss: 0.063731, loss_s1: 0.033821, loss_fp: 0.002554, loss_freq: 0.011100
[13:56:04.219] iteration 11195: loss: 0.083714, loss_s1: 0.030951, loss_fp: 0.001248, loss_freq: 0.023978
[13:56:04.840] iteration 11196: loss: 0.066527, loss_s1: 0.051523, loss_fp: 0.000948, loss_freq: 0.036322
[13:56:05.470] iteration 11197: loss: 0.071548, loss_s1: 0.041740, loss_fp: 0.005978, loss_freq: 0.008795
[13:56:06.102] iteration 11198: loss: 0.101947, loss_s1: 0.079961, loss_fp: 0.005419, loss_freq: 0.055470
[13:56:06.739] iteration 11199: loss: 0.095446, loss_s1: 0.039449, loss_fp: 0.001653, loss_freq: 0.013083
[13:56:07.372] iteration 11200: loss: 0.120829, loss_s1: 0.085588, loss_fp: 0.002305, loss_freq: 0.063564
[13:56:11.061] iteration 11200 : mean_dice : 0.747749
[13:56:11.762] iteration 11201: loss: 0.074073, loss_s1: 0.049166, loss_fp: 0.006034, loss_freq: 0.009382
[13:56:12.422] iteration 11202: loss: 0.076205, loss_s1: 0.029556, loss_fp: 0.003612, loss_freq: 0.035761
[13:56:13.076] iteration 11203: loss: 0.056244, loss_s1: 0.031461, loss_fp: 0.004585, loss_freq: 0.033636
[13:56:13.720] iteration 11204: loss: 0.069793, loss_s1: 0.079488, loss_fp: 0.001168, loss_freq: 0.012733
[13:56:14.341] iteration 11205: loss: 0.055439, loss_s1: 0.034660, loss_fp: 0.003563, loss_freq: 0.013014
[13:56:14.972] iteration 11206: loss: 0.152785, loss_s1: 0.013765, loss_fp: 0.000992, loss_freq: 0.008831
[13:56:15.607] iteration 11207: loss: 0.056068, loss_s1: 0.023929, loss_fp: 0.001598, loss_freq: 0.012691
[13:56:16.229] iteration 11208: loss: 0.035701, loss_s1: 0.022443, loss_fp: 0.000795, loss_freq: 0.008161
[13:56:16.849] iteration 11209: loss: 0.074958, loss_s1: 0.033136, loss_fp: 0.018804, loss_freq: 0.009976
[13:56:17.478] iteration 11210: loss: 0.064450, loss_s1: 0.034437, loss_fp: 0.001986, loss_freq: 0.023749
[13:56:18.155] iteration 11211: loss: 0.082066, loss_s1: 0.053101, loss_fp: 0.007261, loss_freq: 0.048382
[13:56:18.830] iteration 11212: loss: 0.065140, loss_s1: 0.030316, loss_fp: 0.000607, loss_freq: 0.026162
[13:56:19.526] iteration 11213: loss: 0.077891, loss_s1: 0.042259, loss_fp: 0.005263, loss_freq: 0.042296
[13:56:20.200] iteration 11214: loss: 0.079378, loss_s1: 0.046406, loss_fp: 0.004904, loss_freq: 0.032813
[13:56:20.822] iteration 11215: loss: 0.077061, loss_s1: 0.052680, loss_fp: 0.003162, loss_freq: 0.023339
[13:56:21.443] iteration 11216: loss: 0.080370, loss_s1: 0.066840, loss_fp: 0.002815, loss_freq: 0.034614
[13:56:22.065] iteration 11217: loss: 0.100996, loss_s1: 0.048562, loss_fp: 0.002269, loss_freq: 0.066003
[13:56:22.691] iteration 11218: loss: 0.055266, loss_s1: 0.017850, loss_fp: 0.001796, loss_freq: 0.011894
[13:56:23.311] iteration 11219: loss: 0.116089, loss_s1: 0.091647, loss_fp: 0.000782, loss_freq: 0.014617
[13:56:23.927] iteration 11220: loss: 0.099252, loss_s1: 0.050579, loss_fp: 0.002736, loss_freq: 0.041690
[13:56:24.552] iteration 11221: loss: 0.150996, loss_s1: 0.126031, loss_fp: 0.002523, loss_freq: 0.091731
[13:56:25.175] iteration 11222: loss: 0.062499, loss_s1: 0.019951, loss_fp: 0.006293, loss_freq: 0.011811
[13:56:25.800] iteration 11223: loss: 0.049181, loss_s1: 0.016949, loss_fp: 0.001570, loss_freq: 0.021342
[13:56:26.422] iteration 11224: loss: 0.082855, loss_s1: 0.040186, loss_fp: 0.002829, loss_freq: 0.016831
[13:56:27.049] iteration 11225: loss: 0.059419, loss_s1: 0.042418, loss_fp: 0.011968, loss_freq: 0.013091
[13:56:27.665] iteration 11226: loss: 0.072967, loss_s1: 0.048179, loss_fp: 0.004337, loss_freq: 0.020387
[13:56:28.289] iteration 11227: loss: 0.065116, loss_s1: 0.041065, loss_fp: 0.006055, loss_freq: 0.029306
[13:56:28.910] iteration 11228: loss: 0.086836, loss_s1: 0.063586, loss_fp: 0.002572, loss_freq: 0.031669
[13:56:29.531] iteration 11229: loss: 0.077213, loss_s1: 0.063525, loss_fp: 0.006231, loss_freq: 0.036311
[13:56:30.150] iteration 11230: loss: 0.096814, loss_s1: 0.082665, loss_fp: 0.004117, loss_freq: 0.011308
[13:56:30.773] iteration 11231: loss: 0.046924, loss_s1: 0.023662, loss_fp: 0.003256, loss_freq: 0.016449
[13:56:31.395] iteration 11232: loss: 0.073667, loss_s1: 0.034019, loss_fp: 0.001571, loss_freq: 0.015988
[13:56:32.048] iteration 11233: loss: 0.071407, loss_s1: 0.015325, loss_fp: 0.012755, loss_freq: 0.048955
[13:56:32.718] iteration 11234: loss: 0.147749, loss_s1: 0.077371, loss_fp: 0.004166, loss_freq: 0.049007
[13:56:33.391] iteration 11235: loss: 0.069107, loss_s1: 0.018770, loss_fp: 0.000987, loss_freq: 0.014314
[13:56:34.063] iteration 11236: loss: 0.076088, loss_s1: 0.044243, loss_fp: 0.007048, loss_freq: 0.042060
[13:56:34.721] iteration 11237: loss: 0.051768, loss_s1: 0.022023, loss_fp: 0.000816, loss_freq: 0.026787
[13:56:35.369] iteration 11238: loss: 0.053329, loss_s1: 0.030521, loss_fp: 0.004204, loss_freq: 0.027737
[13:56:36.012] iteration 11239: loss: 0.086613, loss_s1: 0.079447, loss_fp: 0.005278, loss_freq: 0.017266
[13:56:36.632] iteration 11240: loss: 0.083454, loss_s1: 0.040703, loss_fp: 0.004104, loss_freq: 0.039550
[13:56:37.254] iteration 11241: loss: 0.056122, loss_s1: 0.039044, loss_fp: 0.002242, loss_freq: 0.013819
[13:56:37.880] iteration 11242: loss: 0.104193, loss_s1: 0.025158, loss_fp: 0.000893, loss_freq: 0.035409
[13:56:38.506] iteration 11243: loss: 0.100412, loss_s1: 0.082298, loss_fp: 0.002678, loss_freq: 0.020303
[13:56:39.125] iteration 11244: loss: 0.066227, loss_s1: 0.061094, loss_fp: 0.003516, loss_freq: 0.015228
[13:56:39.748] iteration 11245: loss: 0.112728, loss_s1: 0.024501, loss_fp: 0.002505, loss_freq: 0.039807
[13:56:40.373] iteration 11246: loss: 0.068355, loss_s1: 0.046112, loss_fp: 0.005490, loss_freq: 0.035527
[13:56:40.989] iteration 11247: loss: 0.057520, loss_s1: 0.029445, loss_fp: 0.000787, loss_freq: 0.019412
[13:56:41.612] iteration 11248: loss: 0.089983, loss_s1: 0.061272, loss_fp: 0.004014, loss_freq: 0.010756
[13:56:42.233] iteration 11249: loss: 0.044826, loss_s1: 0.010866, loss_fp: 0.001432, loss_freq: 0.018550
[13:56:42.859] iteration 11250: loss: 0.108147, loss_s1: 0.050648, loss_fp: 0.009969, loss_freq: 0.063023
[13:56:43.478] iteration 11251: loss: 0.112697, loss_s1: 0.028605, loss_fp: 0.005212, loss_freq: 0.128197
[13:56:44.104] iteration 11252: loss: 0.079564, loss_s1: 0.048947, loss_fp: 0.004002, loss_freq: 0.042165
[13:56:44.732] iteration 11253: loss: 0.057246, loss_s1: 0.010898, loss_fp: 0.003947, loss_freq: 0.027428
[13:56:45.353] iteration 11254: loss: 0.136134, loss_s1: 0.062619, loss_fp: 0.004796, loss_freq: 0.060777
[13:56:45.968] iteration 11255: loss: 0.083829, loss_s1: 0.034704, loss_fp: 0.002985, loss_freq: 0.056631
[13:56:46.588] iteration 11256: loss: 0.069549, loss_s1: 0.048212, loss_fp: 0.000942, loss_freq: 0.020477
[13:56:47.206] iteration 11257: loss: 0.063103, loss_s1: 0.017254, loss_fp: 0.016581, loss_freq: 0.043626
[13:56:47.824] iteration 11258: loss: 0.073853, loss_s1: 0.061743, loss_fp: 0.013591, loss_freq: 0.025370
[13:56:48.435] iteration 11259: loss: 0.097903, loss_s1: 0.049354, loss_fp: 0.001939, loss_freq: 0.059967
[13:56:49.092] iteration 11260: loss: 0.099191, loss_s1: 0.062282, loss_fp: 0.000661, loss_freq: 0.037988
[13:56:49.746] iteration 11261: loss: 0.120958, loss_s1: 0.094296, loss_fp: 0.008591, loss_freq: 0.076781
[13:56:50.401] iteration 11262: loss: 0.074026, loss_s1: 0.058612, loss_fp: 0.003035, loss_freq: 0.037368
[13:56:51.065] iteration 11263: loss: 0.081691, loss_s1: 0.039160, loss_fp: 0.002881, loss_freq: 0.028212
[13:56:51.712] iteration 11264: loss: 0.068028, loss_s1: 0.059454, loss_fp: 0.002083, loss_freq: 0.025758
[13:56:52.340] iteration 11265: loss: 0.069849, loss_s1: 0.023858, loss_fp: 0.000448, loss_freq: 0.013669
[13:56:52.963] iteration 11266: loss: 0.091569, loss_s1: 0.053752, loss_fp: 0.004171, loss_freq: 0.083757
[13:56:53.582] iteration 11267: loss: 0.071144, loss_s1: 0.032566, loss_fp: 0.000933, loss_freq: 0.006837
[13:56:54.198] iteration 11268: loss: 0.094089, loss_s1: 0.062233, loss_fp: 0.002891, loss_freq: 0.066469
[13:56:54.830] iteration 11269: loss: 0.082452, loss_s1: 0.021659, loss_fp: 0.000187, loss_freq: 0.048967
[13:56:55.463] iteration 11270: loss: 0.066149, loss_s1: 0.036291, loss_fp: 0.002143, loss_freq: 0.009421
[13:56:56.090] iteration 11271: loss: 0.066018, loss_s1: 0.029554, loss_fp: 0.001893, loss_freq: 0.039619
[13:56:56.711] iteration 11272: loss: 0.076207, loss_s1: 0.074541, loss_fp: 0.003140, loss_freq: 0.011588
[13:56:57.327] iteration 11273: loss: 0.062466, loss_s1: 0.039174, loss_fp: 0.007476, loss_freq: 0.033594
[13:56:57.949] iteration 11274: loss: 0.083948, loss_s1: 0.063281, loss_fp: 0.003554, loss_freq: 0.056023
[13:56:58.570] iteration 11275: loss: 0.077155, loss_s1: 0.053639, loss_fp: 0.004558, loss_freq: 0.035990
[13:56:59.195] iteration 11276: loss: 0.126777, loss_s1: 0.026220, loss_fp: 0.007883, loss_freq: 0.044448
[13:56:59.872] iteration 11277: loss: 0.045232, loss_s1: 0.025541, loss_fp: 0.000846, loss_freq: 0.013941
[13:57:00.491] iteration 11278: loss: 0.082887, loss_s1: 0.036333, loss_fp: 0.003176, loss_freq: 0.036207
[13:57:01.118] iteration 11279: loss: 0.051169, loss_s1: 0.013770, loss_fp: 0.002051, loss_freq: 0.046785
[13:57:01.752] iteration 11280: loss: 0.123108, loss_s1: 0.103852, loss_fp: 0.002233, loss_freq: 0.026801
[13:57:02.380] iteration 11281: loss: 0.054545, loss_s1: 0.012884, loss_fp: 0.000420, loss_freq: 0.029816
[13:57:03.007] iteration 11282: loss: 0.051240, loss_s1: 0.032596, loss_fp: 0.004109, loss_freq: 0.009274
[13:57:03.637] iteration 11283: loss: 0.089902, loss_s1: 0.070123, loss_fp: 0.002758, loss_freq: 0.014358
[13:57:04.266] iteration 11284: loss: 0.066978, loss_s1: 0.018093, loss_fp: 0.003571, loss_freq: 0.030323
[13:57:04.890] iteration 11285: loss: 0.062030, loss_s1: 0.011108, loss_fp: 0.000924, loss_freq: 0.009853
[13:57:05.513] iteration 11286: loss: 0.136277, loss_s1: 0.052240, loss_fp: 0.003896, loss_freq: 0.038008
[13:57:06.148] iteration 11287: loss: 0.085462, loss_s1: 0.075909, loss_fp: 0.008044, loss_freq: 0.020487
[13:57:06.767] iteration 11288: loss: 0.104274, loss_s1: 0.054099, loss_fp: 0.000686, loss_freq: 0.047416
[13:57:07.393] iteration 11289: loss: 0.130543, loss_s1: 0.048439, loss_fp: 0.003187, loss_freq: 0.059442
[13:57:08.021] iteration 11290: loss: 0.104037, loss_s1: 0.072997, loss_fp: 0.004211, loss_freq: 0.027815
[13:57:08.650] iteration 11291: loss: 0.077383, loss_s1: 0.062689, loss_fp: 0.003415, loss_freq: 0.035635
[13:57:09.268] iteration 11292: loss: 0.051755, loss_s1: 0.034372, loss_fp: 0.001630, loss_freq: 0.013108
[13:57:09.890] iteration 11293: loss: 0.099180, loss_s1: 0.069835, loss_fp: 0.006033, loss_freq: 0.024178
[13:57:10.516] iteration 11294: loss: 0.095144, loss_s1: 0.049512, loss_fp: 0.001804, loss_freq: 0.015744
[13:57:11.183] iteration 11295: loss: 0.073762, loss_s1: 0.049151, loss_fp: 0.007660, loss_freq: 0.031143
[13:57:11.834] iteration 11296: loss: 0.096553, loss_s1: 0.069620, loss_fp: 0.002012, loss_freq: 0.024550
[13:57:12.491] iteration 11297: loss: 0.049312, loss_s1: 0.007399, loss_fp: 0.002227, loss_freq: 0.028463
[13:57:13.477] iteration 11298: loss: 0.056274, loss_s1: 0.029360, loss_fp: 0.001138, loss_freq: 0.027915
[13:57:14.106] iteration 11299: loss: 0.108325, loss_s1: 0.099797, loss_fp: 0.001471, loss_freq: 0.037503
[13:57:14.732] iteration 11300: loss: 0.062585, loss_s1: 0.049167, loss_fp: 0.001505, loss_freq: 0.033993
[13:57:15.429] iteration 11301: loss: 0.069739, loss_s1: 0.047288, loss_fp: 0.001320, loss_freq: 0.023360
[13:57:16.055] iteration 11302: loss: 0.078027, loss_s1: 0.067412, loss_fp: 0.000860, loss_freq: 0.044577
[13:57:16.685] iteration 11303: loss: 0.080833, loss_s1: 0.029415, loss_fp: 0.000858, loss_freq: 0.007026
[13:57:17.304] iteration 11304: loss: 0.042712, loss_s1: 0.024650, loss_fp: 0.001544, loss_freq: 0.021496
[13:57:17.928] iteration 11305: loss: 0.138049, loss_s1: 0.126087, loss_fp: 0.005683, loss_freq: 0.041079
[13:57:18.552] iteration 11306: loss: 0.073658, loss_s1: 0.044169, loss_fp: 0.001830, loss_freq: 0.036605
[13:57:19.170] iteration 11307: loss: 0.072824, loss_s1: 0.024084, loss_fp: 0.001098, loss_freq: 0.018160
[13:57:19.794] iteration 11308: loss: 0.072759, loss_s1: 0.048113, loss_fp: 0.001954, loss_freq: 0.047524
[13:57:20.418] iteration 11309: loss: 0.061236, loss_s1: 0.048680, loss_fp: 0.001200, loss_freq: 0.012365
[13:57:21.042] iteration 11310: loss: 0.070960, loss_s1: 0.074914, loss_fp: 0.000629, loss_freq: 0.012189
[13:57:21.669] iteration 11311: loss: 0.071277, loss_s1: 0.025573, loss_fp: 0.000555, loss_freq: 0.047240
[13:57:22.292] iteration 11312: loss: 0.076258, loss_s1: 0.073774, loss_fp: 0.004229, loss_freq: 0.024566
[13:57:22.919] iteration 11313: loss: 0.068589, loss_s1: 0.055554, loss_fp: 0.001941, loss_freq: 0.026999
[13:57:23.547] iteration 11314: loss: 0.084308, loss_s1: 0.035842, loss_fp: 0.000858, loss_freq: 0.012124
[13:57:24.174] iteration 11315: loss: 0.061299, loss_s1: 0.036768, loss_fp: 0.012882, loss_freq: 0.013832
[13:57:24.804] iteration 11316: loss: 0.048360, loss_s1: 0.033406, loss_fp: 0.000489, loss_freq: 0.012886
[13:57:25.428] iteration 11317: loss: 0.046700, loss_s1: 0.032707, loss_fp: 0.000759, loss_freq: 0.014484
[13:57:26.055] iteration 11318: loss: 0.136212, loss_s1: 0.062241, loss_fp: 0.001351, loss_freq: 0.063438
[13:57:26.678] iteration 11319: loss: 0.049926, loss_s1: 0.014595, loss_fp: 0.000820, loss_freq: 0.017961
[13:57:27.307] iteration 11320: loss: 0.086465, loss_s1: 0.056164, loss_fp: 0.012503, loss_freq: 0.034226
[13:57:27.929] iteration 11321: loss: 0.047038, loss_s1: 0.017140, loss_fp: 0.007750, loss_freq: 0.016746
[13:57:28.551] iteration 11322: loss: 0.051832, loss_s1: 0.031889, loss_fp: 0.005122, loss_freq: 0.014542
[13:57:29.178] iteration 11323: loss: 0.077942, loss_s1: 0.069969, loss_fp: 0.005255, loss_freq: 0.020342
[13:57:29.796] iteration 11324: loss: 0.075084, loss_s1: 0.026085, loss_fp: 0.001870, loss_freq: 0.058081
[13:57:30.426] iteration 11325: loss: 0.073751, loss_s1: 0.040405, loss_fp: 0.006858, loss_freq: 0.025767
[13:57:31.049] iteration 11326: loss: 0.109509, loss_s1: 0.070429, loss_fp: 0.003965, loss_freq: 0.046972
[13:57:31.674] iteration 11327: loss: 0.075266, loss_s1: 0.051237, loss_fp: 0.004813, loss_freq: 0.014712
[13:57:32.303] iteration 11328: loss: 0.062511, loss_s1: 0.055104, loss_fp: 0.002810, loss_freq: 0.005220
[13:57:32.966] iteration 11329: loss: 0.066835, loss_s1: 0.028853, loss_fp: 0.004923, loss_freq: 0.026399
[13:57:33.646] iteration 11330: loss: 0.038884, loss_s1: 0.013986, loss_fp: 0.006204, loss_freq: 0.018238
[13:57:34.276] iteration 11331: loss: 0.092538, loss_s1: 0.061630, loss_fp: 0.006567, loss_freq: 0.061460
[13:57:34.910] iteration 11332: loss: 0.101441, loss_s1: 0.054040, loss_fp: 0.005784, loss_freq: 0.032389
[13:57:35.548] iteration 11333: loss: 0.076281, loss_s1: 0.037049, loss_fp: 0.009378, loss_freq: 0.036821
[13:57:36.231] iteration 11334: loss: 0.079497, loss_s1: 0.034217, loss_fp: 0.002823, loss_freq: 0.055350
[13:57:36.849] iteration 11335: loss: 0.061770, loss_s1: 0.030908, loss_fp: 0.001981, loss_freq: 0.048562
[13:57:37.481] iteration 11336: loss: 0.090781, loss_s1: 0.050389, loss_fp: 0.004721, loss_freq: 0.047059
[13:57:38.099] iteration 11337: loss: 0.039534, loss_s1: 0.025349, loss_fp: 0.002615, loss_freq: 0.011388
[13:57:38.730] iteration 11338: loss: 0.077785, loss_s1: 0.032191, loss_fp: 0.001792, loss_freq: 0.023602
[13:57:39.356] iteration 11339: loss: 0.076617, loss_s1: 0.077220, loss_fp: 0.000428, loss_freq: 0.014875
[13:57:39.980] iteration 11340: loss: 0.075155, loss_s1: 0.021414, loss_fp: 0.001415, loss_freq: 0.011160
[13:57:40.609] iteration 11341: loss: 0.064926, loss_s1: 0.048097, loss_fp: 0.001499, loss_freq: 0.024895
[13:57:41.228] iteration 11342: loss: 0.102597, loss_s1: 0.018362, loss_fp: 0.000670, loss_freq: 0.023986
[13:57:41.858] iteration 11343: loss: 0.068981, loss_s1: 0.036763, loss_fp: 0.004212, loss_freq: 0.028042
[13:57:42.481] iteration 11344: loss: 0.076316, loss_s1: 0.067168, loss_fp: 0.003211, loss_freq: 0.028246
[13:57:43.107] iteration 11345: loss: 0.072818, loss_s1: 0.044316, loss_fp: 0.003828, loss_freq: 0.023149
[13:57:43.740] iteration 11346: loss: 0.056237, loss_s1: 0.053378, loss_fp: 0.000992, loss_freq: 0.012038
[13:57:44.374] iteration 11347: loss: 0.053506, loss_s1: 0.018495, loss_fp: 0.001282, loss_freq: 0.030897
[13:57:44.996] iteration 11348: loss: 0.067475, loss_s1: 0.040817, loss_fp: 0.004931, loss_freq: 0.035443
[13:57:45.620] iteration 11349: loss: 0.079376, loss_s1: 0.012040, loss_fp: 0.001425, loss_freq: 0.040858
[13:57:46.247] iteration 11350: loss: 0.050144, loss_s1: 0.011141, loss_fp: 0.003053, loss_freq: 0.005346
[13:57:46.872] iteration 11351: loss: 0.059243, loss_s1: 0.034260, loss_fp: 0.001779, loss_freq: 0.026482
[13:57:47.496] iteration 11352: loss: 0.069533, loss_s1: 0.060283, loss_fp: 0.002441, loss_freq: 0.023212
[13:57:48.115] iteration 11353: loss: 0.063452, loss_s1: 0.018193, loss_fp: 0.000847, loss_freq: 0.018304
[13:57:48.736] iteration 11354: loss: 0.080930, loss_s1: 0.072130, loss_fp: 0.005652, loss_freq: 0.029443
[13:57:49.359] iteration 11355: loss: 0.048086, loss_s1: 0.022027, loss_fp: 0.005651, loss_freq: 0.026426
[13:57:49.988] iteration 11356: loss: 0.082807, loss_s1: 0.048006, loss_fp: 0.002856, loss_freq: 0.056217
[13:57:50.643] iteration 11357: loss: 0.061186, loss_s1: 0.031387, loss_fp: 0.003553, loss_freq: 0.040062
[13:57:51.266] iteration 11358: loss: 0.104903, loss_s1: 0.054217, loss_fp: 0.001322, loss_freq: 0.017033
[13:57:51.894] iteration 11359: loss: 0.091512, loss_s1: 0.063829, loss_fp: 0.004505, loss_freq: 0.044116
[13:57:52.514] iteration 11360: loss: 0.078837, loss_s1: 0.052002, loss_fp: 0.000864, loss_freq: 0.045834
[13:57:53.140] iteration 11361: loss: 0.058413, loss_s1: 0.020689, loss_fp: 0.003282, loss_freq: 0.028980
[13:57:53.768] iteration 11362: loss: 0.103779, loss_s1: 0.058588, loss_fp: 0.001774, loss_freq: 0.028591
[13:57:54.395] iteration 11363: loss: 0.095212, loss_s1: 0.033709, loss_fp: 0.002789, loss_freq: 0.027339
[13:57:55.018] iteration 11364: loss: 0.116040, loss_s1: 0.071763, loss_fp: 0.003579, loss_freq: 0.077425
[13:57:55.648] iteration 11365: loss: 0.067836, loss_s1: 0.031862, loss_fp: 0.000972, loss_freq: 0.022329
[13:57:56.315] iteration 11366: loss: 0.079098, loss_s1: 0.088218, loss_fp: 0.003676, loss_freq: 0.014756
[13:57:56.934] iteration 11367: loss: 0.086270, loss_s1: 0.038677, loss_fp: 0.001753, loss_freq: 0.044787
[13:57:57.550] iteration 11368: loss: 0.060588, loss_s1: 0.021350, loss_fp: 0.004108, loss_freq: 0.032772
[13:57:58.177] iteration 11369: loss: 0.058312, loss_s1: 0.020293, loss_fp: 0.001772, loss_freq: 0.032559
[13:57:58.790] iteration 11370: loss: 0.061135, loss_s1: 0.019256, loss_fp: 0.001662, loss_freq: 0.053191
[13:57:59.412] iteration 11371: loss: 0.104998, loss_s1: 0.032179, loss_fp: 0.006004, loss_freq: 0.049682
[13:58:00.038] iteration 11372: loss: 0.078670, loss_s1: 0.071390, loss_fp: 0.005783, loss_freq: 0.037301
[13:58:00.663] iteration 11373: loss: 0.059613, loss_s1: 0.034279, loss_fp: 0.002525, loss_freq: 0.016127
[13:58:01.331] iteration 11374: loss: 0.040919, loss_s1: 0.021692, loss_fp: 0.001438, loss_freq: 0.017377
[13:58:01.955] iteration 11375: loss: 0.101181, loss_s1: 0.105120, loss_fp: 0.004405, loss_freq: 0.019559
[13:58:02.579] iteration 11376: loss: 0.091490, loss_s1: 0.082211, loss_fp: 0.010234, loss_freq: 0.027991
[13:58:03.206] iteration 11377: loss: 0.126377, loss_s1: 0.064756, loss_fp: 0.002508, loss_freq: 0.041362
[13:58:03.835] iteration 11378: loss: 0.094198, loss_s1: 0.044487, loss_fp: 0.001806, loss_freq: 0.065702
[13:58:04.458] iteration 11379: loss: 0.066625, loss_s1: 0.041219, loss_fp: 0.002068, loss_freq: 0.043448
[13:58:05.085] iteration 11380: loss: 0.061466, loss_s1: 0.037347, loss_fp: 0.000863, loss_freq: 0.020002
[13:58:05.711] iteration 11381: loss: 0.056598, loss_s1: 0.041342, loss_fp: 0.000921, loss_freq: 0.007182
[13:58:06.331] iteration 11382: loss: 0.036992, loss_s1: 0.009532, loss_fp: 0.001614, loss_freq: 0.008924
[13:58:07.018] iteration 11383: loss: 0.078610, loss_s1: 0.041228, loss_fp: 0.003436, loss_freq: 0.032371
[13:58:07.673] iteration 11384: loss: 0.094608, loss_s1: 0.049612, loss_fp: 0.010276, loss_freq: 0.012293
[13:58:08.326] iteration 11385: loss: 0.050761, loss_s1: 0.011688, loss_fp: 0.000448, loss_freq: 0.013919
[13:58:08.959] iteration 11386: loss: 0.068739, loss_s1: 0.053833, loss_fp: 0.002283, loss_freq: 0.022325
[13:58:09.582] iteration 11387: loss: 0.080096, loss_s1: 0.052112, loss_fp: 0.000911, loss_freq: 0.047783
[13:58:10.209] iteration 11388: loss: 0.077032, loss_s1: 0.024950, loss_fp: 0.002708, loss_freq: 0.024064
[13:58:10.833] iteration 11389: loss: 0.075860, loss_s1: 0.053202, loss_fp: 0.006375, loss_freq: 0.044613
[13:58:11.458] iteration 11390: loss: 0.058993, loss_s1: 0.048953, loss_fp: 0.004915, loss_freq: 0.007177
[13:58:12.138] iteration 11391: loss: 0.138336, loss_s1: 0.038005, loss_fp: 0.001132, loss_freq: 0.014853
[13:58:12.794] iteration 11392: loss: 0.064454, loss_s1: 0.040381, loss_fp: 0.000646, loss_freq: 0.013231
[13:58:13.456] iteration 11393: loss: 0.070809, loss_s1: 0.011960, loss_fp: 0.002129, loss_freq: 0.005228
[13:58:14.117] iteration 11394: loss: 0.161758, loss_s1: 0.065156, loss_fp: 0.005841, loss_freq: 0.090043
[13:58:14.743] iteration 11395: loss: 0.080866, loss_s1: 0.057484, loss_fp: 0.002781, loss_freq: 0.023644
[13:58:15.366] iteration 11396: loss: 0.110995, loss_s1: 0.047047, loss_fp: 0.003738, loss_freq: 0.031991
[13:58:15.982] iteration 11397: loss: 0.104177, loss_s1: 0.106063, loss_fp: 0.001479, loss_freq: 0.033516
[13:58:16.600] iteration 11398: loss: 0.094418, loss_s1: 0.031410, loss_fp: 0.003865, loss_freq: 0.016054
[13:58:17.219] iteration 11399: loss: 0.104102, loss_s1: 0.042994, loss_fp: 0.011894, loss_freq: 0.050285
[13:58:17.839] iteration 11400: loss: 0.073235, loss_s1: 0.040189, loss_fp: 0.002321, loss_freq: 0.021760
[13:58:21.315] iteration 11400 : mean_dice : 0.763152
[13:58:21.961] iteration 11401: loss: 0.094461, loss_s1: 0.044986, loss_fp: 0.006642, loss_freq: 0.043296
[13:58:22.576] iteration 11402: loss: 0.074240, loss_s1: 0.050977, loss_fp: 0.007147, loss_freq: 0.012545
[13:58:23.248] iteration 11403: loss: 0.097062, loss_s1: 0.028999, loss_fp: 0.000781, loss_freq: 0.087213
[13:58:24.084] iteration 11404: loss: 0.088832, loss_s1: 0.059600, loss_fp: 0.003169, loss_freq: 0.040789
[13:58:25.058] iteration 11405: loss: 0.071219, loss_s1: 0.038689, loss_fp: 0.001727, loss_freq: 0.026659
[13:58:25.745] iteration 11406: loss: 0.077099, loss_s1: 0.052735, loss_fp: 0.004597, loss_freq: 0.016878
[13:58:26.363] iteration 11407: loss: 0.047947, loss_s1: 0.023088, loss_fp: 0.000548, loss_freq: 0.013836
[13:58:26.977] iteration 11408: loss: 0.105649, loss_s1: 0.044114, loss_fp: 0.000536, loss_freq: 0.048635
[13:58:27.595] iteration 11409: loss: 0.061494, loss_s1: 0.055222, loss_fp: 0.003048, loss_freq: 0.023831
[13:58:28.213] iteration 11410: loss: 0.077620, loss_s1: 0.042814, loss_fp: 0.001257, loss_freq: 0.009910
[13:58:28.838] iteration 11411: loss: 0.077006, loss_s1: 0.048293, loss_fp: 0.002825, loss_freq: 0.043217
[13:58:29.471] iteration 11412: loss: 0.131406, loss_s1: 0.004232, loss_fp: 0.000530, loss_freq: 0.062711
[13:58:30.095] iteration 11413: loss: 0.073693, loss_s1: 0.075834, loss_fp: 0.001092, loss_freq: 0.015889
[13:58:30.730] iteration 11414: loss: 0.086566, loss_s1: 0.054323, loss_fp: 0.007384, loss_freq: 0.045058
[13:58:31.359] iteration 11415: loss: 0.070259, loss_s1: 0.015124, loss_fp: 0.001890, loss_freq: 0.019180
[13:58:31.991] iteration 11416: loss: 0.059071, loss_s1: 0.031570, loss_fp: 0.002069, loss_freq: 0.036695
[13:58:32.615] iteration 11417: loss: 0.045470, loss_s1: 0.011933, loss_fp: 0.004094, loss_freq: 0.025265
[13:58:33.247] iteration 11418: loss: 0.117421, loss_s1: 0.048888, loss_fp: 0.003088, loss_freq: 0.122014
[13:58:33.879] iteration 11419: loss: 0.065115, loss_s1: 0.045429, loss_fp: 0.002531, loss_freq: 0.018014
[13:58:34.507] iteration 11420: loss: 0.049631, loss_s1: 0.026408, loss_fp: 0.001619, loss_freq: 0.002236
[13:58:35.134] iteration 11421: loss: 0.074091, loss_s1: 0.032039, loss_fp: 0.006765, loss_freq: 0.027458
[13:58:35.755] iteration 11422: loss: 0.085920, loss_s1: 0.044830, loss_fp: 0.005390, loss_freq: 0.038835
[13:58:36.378] iteration 11423: loss: 0.092344, loss_s1: 0.071948, loss_fp: 0.005449, loss_freq: 0.013684
[13:58:37.003] iteration 11424: loss: 0.081040, loss_s1: 0.045852, loss_fp: 0.006034, loss_freq: 0.052845
[13:58:37.623] iteration 11425: loss: 0.074084, loss_s1: 0.032899, loss_fp: 0.003757, loss_freq: 0.045265
[13:58:38.238] iteration 11426: loss: 0.077216, loss_s1: 0.069833, loss_fp: 0.004054, loss_freq: 0.012960
[13:58:38.860] iteration 11427: loss: 0.074491, loss_s1: 0.068197, loss_fp: 0.005821, loss_freq: 0.025370
[13:58:39.505] iteration 11428: loss: 0.075658, loss_s1: 0.033347, loss_fp: 0.002773, loss_freq: 0.022660
[13:58:40.149] iteration 11429: loss: 0.124225, loss_s1: 0.079753, loss_fp: 0.008826, loss_freq: 0.030651
[13:58:40.853] iteration 11430: loss: 0.117791, loss_s1: 0.079877, loss_fp: 0.002286, loss_freq: 0.021214
[13:58:41.519] iteration 11431: loss: 0.166349, loss_s1: 0.156331, loss_fp: 0.003778, loss_freq: 0.080967
[13:58:42.171] iteration 11432: loss: 0.077115, loss_s1: 0.026901, loss_fp: 0.008108, loss_freq: 0.037821
[13:58:42.829] iteration 11433: loss: 0.083835, loss_s1: 0.051921, loss_fp: 0.001946, loss_freq: 0.030536
[13:58:43.483] iteration 11434: loss: 0.090271, loss_s1: 0.097283, loss_fp: 0.004074, loss_freq: 0.010092
[13:58:44.106] iteration 11435: loss: 0.055531, loss_s1: 0.017473, loss_fp: 0.004739, loss_freq: 0.028414
[13:58:44.764] iteration 11436: loss: 0.051172, loss_s1: 0.026570, loss_fp: 0.001881, loss_freq: 0.027627
[13:58:45.427] iteration 11437: loss: 0.116246, loss_s1: 0.067498, loss_fp: 0.007053, loss_freq: 0.012548
[13:58:46.081] iteration 11438: loss: 0.059001, loss_s1: 0.042031, loss_fp: 0.003109, loss_freq: 0.017308
[13:58:46.702] iteration 11439: loss: 0.131678, loss_s1: 0.149931, loss_fp: 0.008321, loss_freq: 0.039138
[13:58:47.327] iteration 11440: loss: 0.053171, loss_s1: 0.028285, loss_fp: 0.003989, loss_freq: 0.027139
[13:58:48.258] iteration 11441: loss: 0.070648, loss_s1: 0.032541, loss_fp: 0.000806, loss_freq: 0.016461
[13:58:48.886] iteration 11442: loss: 0.057412, loss_s1: 0.033574, loss_fp: 0.003752, loss_freq: 0.017277
[13:58:49.509] iteration 11443: loss: 0.042866, loss_s1: 0.023060, loss_fp: 0.001086, loss_freq: 0.013338
[13:58:50.120] iteration 11444: loss: 0.082206, loss_s1: 0.034970, loss_fp: 0.000870, loss_freq: 0.030279
[13:58:50.740] iteration 11445: loss: 0.071094, loss_s1: 0.045701, loss_fp: 0.000644, loss_freq: 0.036714
[13:58:51.359] iteration 11446: loss: 0.094319, loss_s1: 0.044992, loss_fp: 0.000843, loss_freq: 0.017461
[13:58:51.983] iteration 11447: loss: 0.046080, loss_s1: 0.035842, loss_fp: 0.003332, loss_freq: 0.015885
[13:58:52.609] iteration 11448: loss: 0.121758, loss_s1: 0.089216, loss_fp: 0.001032, loss_freq: 0.048554
[13:58:53.228] iteration 11449: loss: 0.057735, loss_s1: 0.017289, loss_fp: 0.001009, loss_freq: 0.027818
[13:58:53.853] iteration 11450: loss: 0.069957, loss_s1: 0.015762, loss_fp: 0.000855, loss_freq: 0.006778
[13:58:54.471] iteration 11451: loss: 0.088350, loss_s1: 0.033954, loss_fp: 0.002719, loss_freq: 0.043347
[13:58:55.101] iteration 11452: loss: 0.046968, loss_s1: 0.007852, loss_fp: 0.000750, loss_freq: 0.017454
[13:58:55.726] iteration 11453: loss: 0.068274, loss_s1: 0.038589, loss_fp: 0.027754, loss_freq: 0.006294
[13:58:56.350] iteration 11454: loss: 0.046410, loss_s1: 0.027925, loss_fp: 0.001022, loss_freq: 0.011956
[13:58:56.977] iteration 11455: loss: 0.076985, loss_s1: 0.049475, loss_fp: 0.002629, loss_freq: 0.029819
[13:58:57.606] iteration 11456: loss: 0.045357, loss_s1: 0.018012, loss_fp: 0.000832, loss_freq: 0.011539
[13:58:58.231] iteration 11457: loss: 0.083537, loss_s1: 0.030917, loss_fp: 0.000652, loss_freq: 0.016412
[13:58:58.856] iteration 11458: loss: 0.063226, loss_s1: 0.053244, loss_fp: 0.001378, loss_freq: 0.020726
[13:58:59.478] iteration 11459: loss: 0.054553, loss_s1: 0.036723, loss_fp: 0.001531, loss_freq: 0.015269
[13:59:00.103] iteration 11460: loss: 0.076726, loss_s1: 0.073259, loss_fp: 0.000337, loss_freq: 0.024962
[13:59:00.731] iteration 11461: loss: 0.090067, loss_s1: 0.020644, loss_fp: 0.003217, loss_freq: 0.046988
[13:59:01.362] iteration 11462: loss: 0.071952, loss_s1: 0.046461, loss_fp: 0.004273, loss_freq: 0.033763
[13:59:02.049] iteration 11463: loss: 0.106062, loss_s1: 0.064692, loss_fp: 0.009705, loss_freq: 0.073191
[13:59:02.714] iteration 11464: loss: 0.053638, loss_s1: 0.022271, loss_fp: 0.001393, loss_freq: 0.011913
[13:59:03.381] iteration 11465: loss: 0.061236, loss_s1: 0.020435, loss_fp: 0.001446, loss_freq: 0.031861
[13:59:04.012] iteration 11466: loss: 0.121071, loss_s1: 0.060622, loss_fp: 0.010800, loss_freq: 0.063379
[13:59:04.640] iteration 11467: loss: 0.098549, loss_s1: 0.066022, loss_fp: 0.002212, loss_freq: 0.068332
[13:59:05.269] iteration 11468: loss: 0.050524, loss_s1: 0.029604, loss_fp: 0.002767, loss_freq: 0.004078
[13:59:05.892] iteration 11469: loss: 0.070423, loss_s1: 0.029188, loss_fp: 0.002718, loss_freq: 0.045571
[13:59:06.516] iteration 11470: loss: 0.092869, loss_s1: 0.060844, loss_fp: 0.001462, loss_freq: 0.010937
[13:59:07.139] iteration 11471: loss: 0.056826, loss_s1: 0.024795, loss_fp: 0.001740, loss_freq: 0.014865
[13:59:07.764] iteration 11472: loss: 0.067718, loss_s1: 0.027704, loss_fp: 0.000861, loss_freq: 0.022368
[13:59:08.385] iteration 11473: loss: 0.070578, loss_s1: 0.038055, loss_fp: 0.005385, loss_freq: 0.040832
[13:59:09.000] iteration 11474: loss: 0.135682, loss_s1: 0.163461, loss_fp: 0.002028, loss_freq: 0.057321
[13:59:09.626] iteration 11475: loss: 0.102273, loss_s1: 0.042671, loss_fp: 0.012151, loss_freq: 0.025902
[13:59:10.235] iteration 11476: loss: 0.113775, loss_s1: 0.073821, loss_fp: 0.001606, loss_freq: 0.043412
[13:59:10.855] iteration 11477: loss: 0.089921, loss_s1: 0.077973, loss_fp: 0.007466, loss_freq: 0.025734
[13:59:11.473] iteration 11478: loss: 0.082314, loss_s1: 0.038809, loss_fp: 0.006683, loss_freq: 0.064094
[13:59:12.091] iteration 11479: loss: 0.108725, loss_s1: 0.035915, loss_fp: 0.013254, loss_freq: 0.078899
[13:59:12.708] iteration 11480: loss: 0.066323, loss_s1: 0.064386, loss_fp: 0.003383, loss_freq: 0.009861
[13:59:13.334] iteration 11481: loss: 0.102665, loss_s1: 0.049315, loss_fp: 0.001926, loss_freq: 0.013311
[13:59:13.955] iteration 11482: loss: 0.089219, loss_s1: 0.051581, loss_fp: 0.011131, loss_freq: 0.025105
[13:59:14.578] iteration 11483: loss: 0.071511, loss_s1: 0.048224, loss_fp: 0.002117, loss_freq: 0.014327
[13:59:15.209] iteration 11484: loss: 0.064782, loss_s1: 0.046331, loss_fp: 0.005701, loss_freq: 0.023916
[13:59:15.825] iteration 11485: loss: 0.084385, loss_s1: 0.069472, loss_fp: 0.001645, loss_freq: 0.011648
[13:59:16.440] iteration 11486: loss: 0.107921, loss_s1: 0.087133, loss_fp: 0.006096, loss_freq: 0.064077
[13:59:17.064] iteration 11487: loss: 0.086963, loss_s1: 0.040986, loss_fp: 0.004683, loss_freq: 0.036426
[13:59:17.725] iteration 11488: loss: 0.074626, loss_s1: 0.058416, loss_fp: 0.001550, loss_freq: 0.024083
[13:59:18.353] iteration 11489: loss: 0.044313, loss_s1: 0.032612, loss_fp: 0.000887, loss_freq: 0.016157
[13:59:18.979] iteration 11490: loss: 0.069089, loss_s1: 0.047883, loss_fp: 0.000897, loss_freq: 0.033588
[13:59:19.601] iteration 11491: loss: 0.070443, loss_s1: 0.049804, loss_fp: 0.002386, loss_freq: 0.023774
[13:59:20.259] iteration 11492: loss: 0.069425, loss_s1: 0.033590, loss_fp: 0.002623, loss_freq: 0.012857
[13:59:20.882] iteration 11493: loss: 0.060706, loss_s1: 0.036482, loss_fp: 0.002343, loss_freq: 0.011913
[13:59:21.504] iteration 11494: loss: 0.055969, loss_s1: 0.029607, loss_fp: 0.001726, loss_freq: 0.026325
[13:59:22.128] iteration 11495: loss: 0.052693, loss_s1: 0.038011, loss_fp: 0.000428, loss_freq: 0.007693
[13:59:22.747] iteration 11496: loss: 0.078329, loss_s1: 0.026068, loss_fp: 0.001512, loss_freq: 0.012916
[13:59:23.377] iteration 11497: loss: 0.076196, loss_s1: 0.042842, loss_fp: 0.003495, loss_freq: 0.027208
[13:59:24.006] iteration 11498: loss: 0.059086, loss_s1: 0.017898, loss_fp: 0.000340, loss_freq: 0.021096
[13:59:24.632] iteration 11499: loss: 0.123725, loss_s1: 0.076239, loss_fp: 0.001721, loss_freq: 0.067685
[13:59:25.257] iteration 11500: loss: 0.077101, loss_s1: 0.070084, loss_fp: 0.003049, loss_freq: 0.019716
[13:59:25.880] iteration 11501: loss: 0.124999, loss_s1: 0.040029, loss_fp: 0.008541, loss_freq: 0.033905
[13:59:26.495] iteration 11502: loss: 0.079904, loss_s1: 0.048653, loss_fp: 0.005405, loss_freq: 0.041906
[13:59:27.119] iteration 11503: loss: 0.113570, loss_s1: 0.079058, loss_fp: 0.005467, loss_freq: 0.065108
[13:59:27.750] iteration 11504: loss: 0.078735, loss_s1: 0.033557, loss_fp: 0.001567, loss_freq: 0.023338
[13:59:28.372] iteration 11505: loss: 0.079092, loss_s1: 0.032904, loss_fp: 0.002751, loss_freq: 0.008926
[13:59:28.995] iteration 11506: loss: 0.075071, loss_s1: 0.036857, loss_fp: 0.001222, loss_freq: 0.018304
[13:59:29.619] iteration 11507: loss: 0.117637, loss_s1: 0.070622, loss_fp: 0.004102, loss_freq: 0.075788
[13:59:30.247] iteration 11508: loss: 0.077672, loss_s1: 0.033142, loss_fp: 0.007560, loss_freq: 0.030886
[13:59:30.861] iteration 11509: loss: 0.052927, loss_s1: 0.018822, loss_fp: 0.002934, loss_freq: 0.020574
[13:59:31.479] iteration 11510: loss: 0.124278, loss_s1: 0.083570, loss_fp: 0.000976, loss_freq: 0.042831
[13:59:32.108] iteration 11511: loss: 0.068357, loss_s1: 0.033498, loss_fp: 0.003641, loss_freq: 0.025488
[13:59:32.727] iteration 11512: loss: 0.094429, loss_s1: 0.085478, loss_fp: 0.004421, loss_freq: 0.037263
[13:59:33.348] iteration 11513: loss: 0.100097, loss_s1: 0.093656, loss_fp: 0.006922, loss_freq: 0.058375
[13:59:33.978] iteration 11514: loss: 0.109996, loss_s1: 0.116108, loss_fp: 0.003251, loss_freq: 0.035577
[13:59:34.608] iteration 11515: loss: 0.078419, loss_s1: 0.064577, loss_fp: 0.001722, loss_freq: 0.028567
[13:59:35.239] iteration 11516: loss: 0.071258, loss_s1: 0.022138, loss_fp: 0.007066, loss_freq: 0.016341
[13:59:35.866] iteration 11517: loss: 0.040455, loss_s1: 0.013436, loss_fp: 0.000300, loss_freq: 0.022393
[13:59:36.492] iteration 11518: loss: 0.055831, loss_s1: 0.021843, loss_fp: 0.002195, loss_freq: 0.012034
[13:59:37.114] iteration 11519: loss: 0.068127, loss_s1: 0.029242, loss_fp: 0.005613, loss_freq: 0.048137
[13:59:37.735] iteration 11520: loss: 0.116563, loss_s1: 0.043416, loss_fp: 0.008868, loss_freq: 0.023201
[13:59:38.353] iteration 11521: loss: 0.077628, loss_s1: 0.066967, loss_fp: 0.001795, loss_freq: 0.033880
[13:59:38.972] iteration 11522: loss: 0.077743, loss_s1: 0.048753, loss_fp: 0.002741, loss_freq: 0.026284
[13:59:39.587] iteration 11523: loss: 0.063896, loss_s1: 0.021473, loss_fp: 0.001232, loss_freq: 0.009529
[13:59:40.228] iteration 11524: loss: 0.048712, loss_s1: 0.034728, loss_fp: 0.005017, loss_freq: 0.018628
[13:59:40.880] iteration 11525: loss: 0.064489, loss_s1: 0.037009, loss_fp: 0.001315, loss_freq: 0.037877
[13:59:41.514] iteration 11526: loss: 0.085797, loss_s1: 0.065370, loss_fp: 0.002920, loss_freq: 0.047508
[13:59:42.146] iteration 11527: loss: 0.056604, loss_s1: 0.021352, loss_fp: 0.001205, loss_freq: 0.006351
[13:59:42.770] iteration 11528: loss: 0.071706, loss_s1: 0.040511, loss_fp: 0.001434, loss_freq: 0.028698
[13:59:43.395] iteration 11529: loss: 0.058345, loss_s1: 0.040065, loss_fp: 0.002806, loss_freq: 0.015134
[13:59:44.054] iteration 11530: loss: 0.069785, loss_s1: 0.066476, loss_fp: 0.003277, loss_freq: 0.012611
[13:59:44.715] iteration 11531: loss: 0.088583, loss_s1: 0.037233, loss_fp: 0.001297, loss_freq: 0.024069
[13:59:45.330] iteration 11532: loss: 0.065487, loss_s1: 0.036158, loss_fp: 0.003969, loss_freq: 0.028855
[13:59:45.956] iteration 11533: loss: 0.049028, loss_s1: 0.010664, loss_fp: 0.003909, loss_freq: 0.024492
[13:59:46.573] iteration 11534: loss: 0.075285, loss_s1: 0.033810, loss_fp: 0.001872, loss_freq: 0.022798
[13:59:47.220] iteration 11535: loss: 0.055357, loss_s1: 0.031785, loss_fp: 0.000369, loss_freq: 0.012415
[13:59:47.833] iteration 11536: loss: 0.087239, loss_s1: 0.052438, loss_fp: 0.001968, loss_freq: 0.013474
[13:59:48.456] iteration 11537: loss: 0.144246, loss_s1: 0.098297, loss_fp: 0.007573, loss_freq: 0.111685
[13:59:49.074] iteration 11538: loss: 0.059370, loss_s1: 0.024871, loss_fp: 0.001066, loss_freq: 0.025747
[13:59:49.694] iteration 11539: loss: 0.079979, loss_s1: 0.012737, loss_fp: 0.006996, loss_freq: 0.031912
[13:59:50.313] iteration 11540: loss: 0.145144, loss_s1: 0.023190, loss_fp: 0.005418, loss_freq: 0.038923
[13:59:50.932] iteration 11541: loss: 0.055290, loss_s1: 0.023516, loss_fp: 0.001046, loss_freq: 0.033658
[13:59:51.551] iteration 11542: loss: 0.083422, loss_s1: 0.020824, loss_fp: 0.000868, loss_freq: 0.032119
[13:59:52.170] iteration 11543: loss: 0.064243, loss_s1: 0.052595, loss_fp: 0.000629, loss_freq: 0.010958
[13:59:52.793] iteration 11544: loss: 0.058587, loss_s1: 0.015396, loss_fp: 0.005212, loss_freq: 0.034592
[13:59:53.422] iteration 11545: loss: 0.094809, loss_s1: 0.071435, loss_fp: 0.003271, loss_freq: 0.021561
[13:59:54.040] iteration 11546: loss: 0.059773, loss_s1: 0.034620, loss_fp: 0.002767, loss_freq: 0.018715
[13:59:54.659] iteration 11547: loss: 0.112008, loss_s1: 0.079884, loss_fp: 0.002207, loss_freq: 0.076069
[13:59:55.309] iteration 11548: loss: 0.050609, loss_s1: 0.015055, loss_fp: 0.004482, loss_freq: 0.022829
[13:59:55.966] iteration 11549: loss: 0.101347, loss_s1: 0.089980, loss_fp: 0.001538, loss_freq: 0.017336
[13:59:56.602] iteration 11550: loss: 0.077509, loss_s1: 0.068536, loss_fp: 0.002116, loss_freq: 0.040882
[13:59:57.221] iteration 11551: loss: 0.099717, loss_s1: 0.036805, loss_fp: 0.000525, loss_freq: 0.010934
[13:59:57.836] iteration 11552: loss: 0.055687, loss_s1: 0.022800, loss_fp: 0.001937, loss_freq: 0.046704
[13:59:58.460] iteration 11553: loss: 0.062962, loss_s1: 0.043828, loss_fp: 0.002985, loss_freq: 0.011164
[13:59:59.084] iteration 11554: loss: 0.059481, loss_s1: 0.039656, loss_fp: 0.002614, loss_freq: 0.019566
[13:59:59.708] iteration 11555: loss: 0.107661, loss_s1: 0.085859, loss_fp: 0.000546, loss_freq: 0.034978
[14:00:00.329] iteration 11556: loss: 0.065805, loss_s1: 0.040848, loss_fp: 0.001650, loss_freq: 0.018501
[14:00:00.953] iteration 11557: loss: 0.071856, loss_s1: 0.018124, loss_fp: 0.000857, loss_freq: 0.049898
[14:00:01.591] iteration 11558: loss: 0.103605, loss_s1: 0.087038, loss_fp: 0.003054, loss_freq: 0.032746
[14:00:02.226] iteration 11559: loss: 0.078483, loss_s1: 0.086941, loss_fp: 0.004521, loss_freq: 0.016999
[14:00:02.852] iteration 11560: loss: 0.065278, loss_s1: 0.035755, loss_fp: 0.002650, loss_freq: 0.029884
[14:00:03.475] iteration 11561: loss: 0.086093, loss_s1: 0.064765, loss_fp: 0.000955, loss_freq: 0.050606
[14:00:04.100] iteration 11562: loss: 0.103523, loss_s1: 0.052742, loss_fp: 0.002162, loss_freq: 0.020175
[14:00:04.724] iteration 11563: loss: 0.044655, loss_s1: 0.037444, loss_fp: 0.001211, loss_freq: 0.006665
[14:00:05.347] iteration 11564: loss: 0.084737, loss_s1: 0.048331, loss_fp: 0.000939, loss_freq: 0.073420
[14:00:05.972] iteration 11565: loss: 0.075645, loss_s1: 0.063467, loss_fp: 0.001332, loss_freq: 0.045321
[14:00:06.642] iteration 11566: loss: 0.095680, loss_s1: 0.072275, loss_fp: 0.001199, loss_freq: 0.025123
[14:00:07.274] iteration 11567: loss: 0.068651, loss_s1: 0.024683, loss_fp: 0.001033, loss_freq: 0.039297
[14:00:07.888] iteration 11568: loss: 0.056034, loss_s1: 0.029418, loss_fp: 0.002842, loss_freq: 0.020687
[14:00:08.517] iteration 11569: loss: 0.123225, loss_s1: 0.108771, loss_fp: 0.006118, loss_freq: 0.014373
[14:00:09.136] iteration 11570: loss: 0.081182, loss_s1: 0.066956, loss_fp: 0.007339, loss_freq: 0.016109
[14:00:09.803] iteration 11571: loss: 0.058430, loss_s1: 0.027100, loss_fp: 0.004592, loss_freq: 0.023075
[14:00:10.462] iteration 11572: loss: 0.080980, loss_s1: 0.043787, loss_fp: 0.009090, loss_freq: 0.044618
[14:00:11.082] iteration 11573: loss: 0.055861, loss_s1: 0.018128, loss_fp: 0.000752, loss_freq: 0.025242
[14:00:11.704] iteration 11574: loss: 0.104611, loss_s1: 0.068399, loss_fp: 0.000225, loss_freq: 0.051875
[14:00:12.331] iteration 11575: loss: 0.101831, loss_s1: 0.062634, loss_fp: 0.003323, loss_freq: 0.059854
[14:00:12.951] iteration 11576: loss: 0.071134, loss_s1: 0.054120, loss_fp: 0.001870, loss_freq: 0.017124
[14:00:13.576] iteration 11577: loss: 0.081689, loss_s1: 0.071083, loss_fp: 0.004308, loss_freq: 0.024941
[14:00:14.196] iteration 11578: loss: 0.058748, loss_s1: 0.033509, loss_fp: 0.000787, loss_freq: 0.010374
[14:00:14.818] iteration 11579: loss: 0.058865, loss_s1: 0.031638, loss_fp: 0.002970, loss_freq: 0.029171
[14:00:15.443] iteration 11580: loss: 0.073072, loss_s1: 0.021358, loss_fp: 0.002134, loss_freq: 0.011722
[14:00:16.062] iteration 11581: loss: 0.101134, loss_s1: 0.078048, loss_fp: 0.003674, loss_freq: 0.043078
[14:00:16.683] iteration 11582: loss: 0.131474, loss_s1: 0.097167, loss_fp: 0.008248, loss_freq: 0.083108
[14:00:17.305] iteration 11583: loss: 0.055103, loss_s1: 0.025665, loss_fp: 0.001269, loss_freq: 0.040125
[14:00:18.239] iteration 11584: loss: 0.073262, loss_s1: 0.058028, loss_fp: 0.001240, loss_freq: 0.022984
[14:00:18.854] iteration 11585: loss: 0.072444, loss_s1: 0.047627, loss_fp: 0.002153, loss_freq: 0.032065
[14:00:19.478] iteration 11586: loss: 0.049260, loss_s1: 0.039340, loss_fp: 0.000595, loss_freq: 0.021543
[14:00:20.100] iteration 11587: loss: 0.071802, loss_s1: 0.035363, loss_fp: 0.004765, loss_freq: 0.033912
[14:00:20.717] iteration 11588: loss: 0.070423, loss_s1: 0.032143, loss_fp: 0.003660, loss_freq: 0.042556
[14:00:21.366] iteration 11589: loss: 0.065306, loss_s1: 0.008000, loss_fp: 0.002691, loss_freq: 0.012461
[14:00:21.984] iteration 11590: loss: 0.042608, loss_s1: 0.024775, loss_fp: 0.002440, loss_freq: 0.017202
[14:00:22.610] iteration 11591: loss: 0.125783, loss_s1: 0.098441, loss_fp: 0.001046, loss_freq: 0.061670
[14:00:23.283] iteration 11592: loss: 0.054976, loss_s1: 0.033834, loss_fp: 0.002815, loss_freq: 0.025622
[14:00:23.932] iteration 11593: loss: 0.060408, loss_s1: 0.011208, loss_fp: 0.001176, loss_freq: 0.006161
[14:00:24.591] iteration 11594: loss: 0.099192, loss_s1: 0.082004, loss_fp: 0.002403, loss_freq: 0.041761
[14:00:25.249] iteration 11595: loss: 0.058004, loss_s1: 0.032285, loss_fp: 0.001402, loss_freq: 0.001852
[14:00:25.902] iteration 11596: loss: 0.059209, loss_s1: 0.035730, loss_fp: 0.002511, loss_freq: 0.019138
[14:00:26.552] iteration 11597: loss: 0.050419, loss_s1: 0.024982, loss_fp: 0.001056, loss_freq: 0.027062
[14:00:27.172] iteration 11598: loss: 0.072469, loss_s1: 0.028350, loss_fp: 0.002984, loss_freq: 0.044128
[14:00:27.793] iteration 11599: loss: 0.085784, loss_s1: 0.066139, loss_fp: 0.005123, loss_freq: 0.030843
[14:00:28.418] iteration 11600: loss: 0.144251, loss_s1: 0.022863, loss_fp: 0.005418, loss_freq: 0.028843
[14:00:31.885] iteration 11600 : mean_dice : 0.738600
[14:00:32.543] iteration 11601: loss: 0.094538, loss_s1: 0.022949, loss_fp: 0.006423, loss_freq: 0.006238
[14:00:33.160] iteration 11602: loss: 0.056793, loss_s1: 0.037916, loss_fp: 0.001996, loss_freq: 0.022536
[14:00:33.785] iteration 11603: loss: 0.096018, loss_s1: 0.054398, loss_fp: 0.006291, loss_freq: 0.024771
[14:00:34.409] iteration 11604: loss: 0.092713, loss_s1: 0.045734, loss_fp: 0.002447, loss_freq: 0.067067
[14:00:35.036] iteration 11605: loss: 0.075723, loss_s1: 0.029352, loss_fp: 0.000979, loss_freq: 0.023018
[14:00:35.657] iteration 11606: loss: 0.070624, loss_s1: 0.050059, loss_fp: 0.002386, loss_freq: 0.024466
[14:00:36.281] iteration 11607: loss: 0.090502, loss_s1: 0.047254, loss_fp: 0.007806, loss_freq: 0.028992
[14:00:36.897] iteration 11608: loss: 0.086218, loss_s1: 0.071446, loss_fp: 0.003255, loss_freq: 0.040769
[14:00:37.527] iteration 11609: loss: 0.095094, loss_s1: 0.063993, loss_fp: 0.005746, loss_freq: 0.056912
[14:00:38.157] iteration 11610: loss: 0.091613, loss_s1: 0.052686, loss_fp: 0.002657, loss_freq: 0.053392
[14:00:38.778] iteration 11611: loss: 0.036666, loss_s1: 0.016855, loss_fp: 0.000763, loss_freq: 0.004983
[14:00:39.402] iteration 11612: loss: 0.103750, loss_s1: 0.063770, loss_fp: 0.012266, loss_freq: 0.063650
[14:00:40.033] iteration 11613: loss: 0.065616, loss_s1: 0.027088, loss_fp: 0.003104, loss_freq: 0.010386
[14:00:40.694] iteration 11614: loss: 0.072030, loss_s1: 0.047793, loss_fp: 0.001546, loss_freq: 0.005778
[14:00:41.356] iteration 11615: loss: 0.081696, loss_s1: 0.082506, loss_fp: 0.003623, loss_freq: 0.019462
[14:00:42.012] iteration 11616: loss: 0.063593, loss_s1: 0.026382, loss_fp: 0.006174, loss_freq: 0.009998
[14:00:42.646] iteration 11617: loss: 0.102440, loss_s1: 0.050638, loss_fp: 0.009993, loss_freq: 0.054418
[14:00:43.259] iteration 11618: loss: 0.079259, loss_s1: 0.042230, loss_fp: 0.011172, loss_freq: 0.041013
[14:00:43.881] iteration 11619: loss: 0.079040, loss_s1: 0.035758, loss_fp: 0.002303, loss_freq: 0.051766
[14:00:44.499] iteration 11620: loss: 0.072246, loss_s1: 0.038241, loss_fp: 0.001889, loss_freq: 0.014191
[14:00:45.116] iteration 11621: loss: 0.042308, loss_s1: 0.021796, loss_fp: 0.004226, loss_freq: 0.021463
[14:00:45.744] iteration 11622: loss: 0.069728, loss_s1: 0.032394, loss_fp: 0.004050, loss_freq: 0.040602
[14:00:46.369] iteration 11623: loss: 0.038609, loss_s1: 0.030699, loss_fp: 0.002743, loss_freq: 0.006570
[14:00:46.985] iteration 11624: loss: 0.100820, loss_s1: 0.040310, loss_fp: 0.001114, loss_freq: 0.014681
[14:00:47.610] iteration 11625: loss: 0.051316, loss_s1: 0.045832, loss_fp: 0.000849, loss_freq: 0.020898
[14:00:48.239] iteration 11626: loss: 0.066926, loss_s1: 0.043578, loss_fp: 0.001591, loss_freq: 0.015028
[14:00:48.864] iteration 11627: loss: 0.087201, loss_s1: 0.077640, loss_fp: 0.005764, loss_freq: 0.034406
[14:00:49.489] iteration 11628: loss: 0.089754, loss_s1: 0.070676, loss_fp: 0.000626, loss_freq: 0.005524
[14:00:50.110] iteration 11629: loss: 0.143731, loss_s1: 0.113617, loss_fp: 0.001237, loss_freq: 0.059999
[14:00:50.733] iteration 11630: loss: 0.096515, loss_s1: 0.052036, loss_fp: 0.004358, loss_freq: 0.068233
[14:00:51.351] iteration 11631: loss: 0.041881, loss_s1: 0.016572, loss_fp: 0.003670, loss_freq: 0.016309
[14:00:51.977] iteration 11632: loss: 0.071055, loss_s1: 0.020396, loss_fp: 0.006277, loss_freq: 0.061713
[14:00:52.599] iteration 11633: loss: 0.054036, loss_s1: 0.024823, loss_fp: 0.001358, loss_freq: 0.026186
[14:00:53.224] iteration 11634: loss: 0.050090, loss_s1: 0.017216, loss_fp: 0.001329, loss_freq: 0.024184
[14:00:53.868] iteration 11635: loss: 0.088371, loss_s1: 0.021181, loss_fp: 0.005247, loss_freq: 0.039137
[14:00:54.511] iteration 11636: loss: 0.094878, loss_s1: 0.014895, loss_fp: 0.003255, loss_freq: 0.014151
[14:00:55.154] iteration 11637: loss: 0.046319, loss_s1: 0.030797, loss_fp: 0.001093, loss_freq: 0.011757
[14:00:55.792] iteration 11638: loss: 0.032739, loss_s1: 0.008950, loss_fp: 0.002354, loss_freq: 0.009927
[14:00:56.423] iteration 11639: loss: 0.105437, loss_s1: 0.088436, loss_fp: 0.000488, loss_freq: 0.005372
[14:00:57.109] iteration 11640: loss: 0.076082, loss_s1: 0.060941, loss_fp: 0.005628, loss_freq: 0.038299
[14:00:57.762] iteration 11641: loss: 0.099286, loss_s1: 0.100937, loss_fp: 0.008057, loss_freq: 0.033193
[14:00:58.414] iteration 11642: loss: 0.097203, loss_s1: 0.066091, loss_fp: 0.002151, loss_freq: 0.039984
[14:00:59.077] iteration 11643: loss: 0.064905, loss_s1: 0.034771, loss_fp: 0.009296, loss_freq: 0.017146
[14:00:59.729] iteration 11644: loss: 0.073540, loss_s1: 0.041286, loss_fp: 0.002719, loss_freq: 0.027309
[14:01:00.381] iteration 11645: loss: 0.054127, loss_s1: 0.029506, loss_fp: 0.002466, loss_freq: 0.018250
[14:01:01.009] iteration 11646: loss: 0.060231, loss_s1: 0.024090, loss_fp: 0.001787, loss_freq: 0.010127
[14:01:01.622] iteration 11647: loss: 0.072425, loss_s1: 0.030533, loss_fp: 0.002605, loss_freq: 0.013840
[14:01:02.245] iteration 11648: loss: 0.075852, loss_s1: 0.047661, loss_fp: 0.007307, loss_freq: 0.031987
[14:01:02.868] iteration 11649: loss: 0.082041, loss_s1: 0.033386, loss_fp: 0.005396, loss_freq: 0.015638
[14:01:03.490] iteration 11650: loss: 0.122194, loss_s1: 0.074955, loss_fp: 0.026954, loss_freq: 0.057661
[14:01:04.114] iteration 11651: loss: 0.038816, loss_s1: 0.010862, loss_fp: 0.002791, loss_freq: 0.015976
[14:01:04.740] iteration 11652: loss: 0.075833, loss_s1: 0.066410, loss_fp: 0.001759, loss_freq: 0.027539
[14:01:05.366] iteration 11653: loss: 0.090977, loss_s1: 0.028168, loss_fp: 0.009471, loss_freq: 0.022246
[14:01:05.983] iteration 11654: loss: 0.065625, loss_s1: 0.065176, loss_fp: 0.001428, loss_freq: 0.016173
[14:01:06.612] iteration 11655: loss: 0.067933, loss_s1: 0.015330, loss_fp: 0.005361, loss_freq: 0.042713
[14:01:07.238] iteration 11656: loss: 0.117838, loss_s1: 0.094454, loss_fp: 0.003828, loss_freq: 0.085424
[14:01:07.861] iteration 11657: loss: 0.115661, loss_s1: 0.090929, loss_fp: 0.014356, loss_freq: 0.054868
[14:01:08.485] iteration 11658: loss: 0.092944, loss_s1: 0.053815, loss_fp: 0.005022, loss_freq: 0.084436
[14:01:09.120] iteration 11659: loss: 0.083298, loss_s1: 0.063668, loss_fp: 0.004010, loss_freq: 0.010850
[14:01:09.736] iteration 11660: loss: 0.075708, loss_s1: 0.086231, loss_fp: 0.001831, loss_freq: 0.028680
[14:01:10.357] iteration 11661: loss: 0.055147, loss_s1: 0.022739, loss_fp: 0.000696, loss_freq: 0.010342
[14:01:10.979] iteration 11662: loss: 0.092668, loss_s1: 0.081220, loss_fp: 0.008770, loss_freq: 0.035879
[14:01:11.605] iteration 11663: loss: 0.155240, loss_s1: 0.124647, loss_fp: 0.002481, loss_freq: 0.059537
[14:01:12.215] iteration 11664: loss: 0.056047, loss_s1: 0.019208, loss_fp: 0.001053, loss_freq: 0.037187
[14:01:12.835] iteration 11665: loss: 0.086714, loss_s1: 0.071397, loss_fp: 0.002207, loss_freq: 0.029000
[14:01:13.460] iteration 11666: loss: 0.045174, loss_s1: 0.011944, loss_fp: 0.001357, loss_freq: 0.025684
[14:01:14.082] iteration 11667: loss: 0.047780, loss_s1: 0.039214, loss_fp: 0.000911, loss_freq: 0.015124
[14:01:14.697] iteration 11668: loss: 0.067782, loss_s1: 0.051776, loss_fp: 0.000362, loss_freq: 0.016042
[14:01:15.313] iteration 11669: loss: 0.080714, loss_s1: 0.087398, loss_fp: 0.003740, loss_freq: 0.023104
[14:01:15.932] iteration 11670: loss: 0.056398, loss_s1: 0.017359, loss_fp: 0.004025, loss_freq: 0.016569
[14:01:16.549] iteration 11671: loss: 0.066736, loss_s1: 0.034602, loss_fp: 0.001452, loss_freq: 0.029028
[14:01:17.164] iteration 11672: loss: 0.072169, loss_s1: 0.053208, loss_fp: 0.002972, loss_freq: 0.014789
[14:01:17.823] iteration 11673: loss: 0.086511, loss_s1: 0.065598, loss_fp: 0.002438, loss_freq: 0.049969
[14:01:18.475] iteration 11674: loss: 0.061809, loss_s1: 0.025265, loss_fp: 0.005752, loss_freq: 0.018119
[14:01:19.132] iteration 11675: loss: 0.108954, loss_s1: 0.113832, loss_fp: 0.004452, loss_freq: 0.045253
[14:01:19.788] iteration 11676: loss: 0.059475, loss_s1: 0.041966, loss_fp: 0.001156, loss_freq: 0.014343
[14:01:20.409] iteration 11677: loss: 0.076931, loss_s1: 0.028800, loss_fp: 0.002805, loss_freq: 0.018489
[14:01:21.036] iteration 11678: loss: 0.059311, loss_s1: 0.024454, loss_fp: 0.000916, loss_freq: 0.015264
[14:01:21.668] iteration 11679: loss: 0.082854, loss_s1: 0.038338, loss_fp: 0.001568, loss_freq: 0.016501
[14:01:22.293] iteration 11680: loss: 0.113530, loss_s1: 0.053118, loss_fp: 0.003605, loss_freq: 0.113239
[14:01:22.914] iteration 11681: loss: 0.051575, loss_s1: 0.018126, loss_fp: 0.000533, loss_freq: 0.029490
[14:01:23.533] iteration 11682: loss: 0.065867, loss_s1: 0.028488, loss_fp: 0.004452, loss_freq: 0.023830
[14:01:24.159] iteration 11683: loss: 0.126493, loss_s1: 0.022286, loss_fp: 0.008849, loss_freq: 0.096229
[14:01:24.783] iteration 11684: loss: 0.072536, loss_s1: 0.054115, loss_fp: 0.001929, loss_freq: 0.022222
[14:01:25.399] iteration 11685: loss: 0.049177, loss_s1: 0.016336, loss_fp: 0.001955, loss_freq: 0.019446
[14:01:26.051] iteration 11686: loss: 0.099138, loss_s1: 0.126251, loss_fp: 0.001408, loss_freq: 0.020555
[14:01:26.677] iteration 11687: loss: 0.040923, loss_s1: 0.011257, loss_fp: 0.001068, loss_freq: 0.014792
[14:01:27.297] iteration 11688: loss: 0.093994, loss_s1: 0.059113, loss_fp: 0.001759, loss_freq: 0.013634
[14:01:27.917] iteration 11689: loss: 0.057129, loss_s1: 0.035079, loss_fp: 0.001676, loss_freq: 0.028735
[14:01:28.540] iteration 11690: loss: 0.100969, loss_s1: 0.065873, loss_fp: 0.005178, loss_freq: 0.067278
[14:01:29.167] iteration 11691: loss: 0.037062, loss_s1: 0.020244, loss_fp: 0.002218, loss_freq: 0.012855
[14:01:29.784] iteration 11692: loss: 0.068344, loss_s1: 0.034055, loss_fp: 0.001664, loss_freq: 0.011586
[14:01:30.404] iteration 11693: loss: 0.094907, loss_s1: 0.060862, loss_fp: 0.009607, loss_freq: 0.027783
[14:01:31.028] iteration 11694: loss: 0.135198, loss_s1: 0.040510, loss_fp: 0.001723, loss_freq: 0.062549
[14:01:31.645] iteration 11695: loss: 0.061572, loss_s1: 0.053411, loss_fp: 0.002355, loss_freq: 0.031719
[14:01:32.265] iteration 11696: loss: 0.059739, loss_s1: 0.013707, loss_fp: 0.000894, loss_freq: 0.018053
[14:01:32.888] iteration 11697: loss: 0.093868, loss_s1: 0.090444, loss_fp: 0.003787, loss_freq: 0.042448
[14:01:33.533] iteration 11698: loss: 0.075518, loss_s1: 0.023899, loss_fp: 0.001584, loss_freq: 0.027692
[14:01:34.191] iteration 11699: loss: 0.060990, loss_s1: 0.049371, loss_fp: 0.002684, loss_freq: 0.012654
[14:01:34.851] iteration 11700: loss: 0.102904, loss_s1: 0.058582, loss_fp: 0.009409, loss_freq: 0.064147
[14:01:35.476] iteration 11701: loss: 0.057566, loss_s1: 0.032342, loss_fp: 0.004864, loss_freq: 0.031008
[14:01:36.090] iteration 11702: loss: 0.051659, loss_s1: 0.032495, loss_fp: 0.002382, loss_freq: 0.014030
[14:01:36.706] iteration 11703: loss: 0.062224, loss_s1: 0.035000, loss_fp: 0.001631, loss_freq: 0.023986
[14:01:37.329] iteration 11704: loss: 0.097895, loss_s1: 0.077888, loss_fp: 0.002176, loss_freq: 0.065217
[14:01:37.955] iteration 11705: loss: 0.064116, loss_s1: 0.020959, loss_fp: 0.001266, loss_freq: 0.027779
[14:01:38.577] iteration 11706: loss: 0.069143, loss_s1: 0.060411, loss_fp: 0.000688, loss_freq: 0.013691
[14:01:39.205] iteration 11707: loss: 0.056644, loss_s1: 0.042254, loss_fp: 0.003578, loss_freq: 0.016598
[14:01:39.824] iteration 11708: loss: 0.077005, loss_s1: 0.057573, loss_fp: 0.004403, loss_freq: 0.053237
[14:01:40.444] iteration 11709: loss: 0.148785, loss_s1: 0.023595, loss_fp: 0.002432, loss_freq: 0.027335
[14:01:41.076] iteration 11710: loss: 0.069372, loss_s1: 0.047796, loss_fp: 0.000771, loss_freq: 0.051833
[14:01:41.702] iteration 11711: loss: 0.060512, loss_s1: 0.016186, loss_fp: 0.002617, loss_freq: 0.039839
[14:01:42.334] iteration 11712: loss: 0.098810, loss_s1: 0.105353, loss_fp: 0.003194, loss_freq: 0.013302
[14:01:42.954] iteration 11713: loss: 0.081495, loss_s1: 0.059620, loss_fp: 0.003142, loss_freq: 0.036359
[14:01:43.580] iteration 11714: loss: 0.075432, loss_s1: 0.045405, loss_fp: 0.005171, loss_freq: 0.018107
[14:01:44.204] iteration 11715: loss: 0.100555, loss_s1: 0.058047, loss_fp: 0.006004, loss_freq: 0.032775
[14:01:44.832] iteration 11716: loss: 0.071621, loss_s1: 0.062624, loss_fp: 0.008803, loss_freq: 0.016320
[14:01:45.455] iteration 11717: loss: 0.090857, loss_s1: 0.041136, loss_fp: 0.001657, loss_freq: 0.053253
[14:01:46.075] iteration 11718: loss: 0.083321, loss_s1: 0.026316, loss_fp: 0.001146, loss_freq: 0.034285
[14:01:46.698] iteration 11719: loss: 0.077543, loss_s1: 0.071827, loss_fp: 0.001820, loss_freq: 0.027181
[14:01:47.308] iteration 11720: loss: 0.093780, loss_s1: 0.047008, loss_fp: 0.004978, loss_freq: 0.029882
[14:01:47.929] iteration 11721: loss: 0.058809, loss_s1: 0.022709, loss_fp: 0.000900, loss_freq: 0.023371
[14:01:48.542] iteration 11722: loss: 0.082270, loss_s1: 0.069518, loss_fp: 0.002766, loss_freq: 0.024002
[14:01:49.172] iteration 11723: loss: 0.090528, loss_s1: 0.037717, loss_fp: 0.002578, loss_freq: 0.016146
[14:01:49.790] iteration 11724: loss: 0.077236, loss_s1: 0.036598, loss_fp: 0.006661, loss_freq: 0.023114
[14:01:50.407] iteration 11725: loss: 0.134791, loss_s1: 0.138977, loss_fp: 0.003915, loss_freq: 0.060049
[14:01:51.019] iteration 11726: loss: 0.049140, loss_s1: 0.026546, loss_fp: 0.000655, loss_freq: 0.024355
[14:01:51.995] iteration 11727: loss: 0.125087, loss_s1: 0.083913, loss_fp: 0.001039, loss_freq: 0.022707
[14:01:52.638] iteration 11728: loss: 0.062927, loss_s1: 0.047645, loss_fp: 0.002839, loss_freq: 0.017357
[14:01:53.286] iteration 11729: loss: 0.057318, loss_s1: 0.038843, loss_fp: 0.001590, loss_freq: 0.024004
[14:01:53.944] iteration 11730: loss: 0.061462, loss_s1: 0.025374, loss_fp: 0.003713, loss_freq: 0.021402
[14:01:54.592] iteration 11731: loss: 0.083249, loss_s1: 0.040407, loss_fp: 0.001011, loss_freq: 0.035747
[14:01:55.242] iteration 11732: loss: 0.084247, loss_s1: 0.019243, loss_fp: 0.000496, loss_freq: 0.009961
[14:01:55.893] iteration 11733: loss: 0.047949, loss_s1: 0.032742, loss_fp: 0.002996, loss_freq: 0.020439
[14:01:56.590] iteration 11734: loss: 0.098332, loss_s1: 0.065660, loss_fp: 0.005099, loss_freq: 0.009115
[14:01:57.250] iteration 11735: loss: 0.068148, loss_s1: 0.037323, loss_fp: 0.001658, loss_freq: 0.011091
[14:01:57.909] iteration 11736: loss: 0.073155, loss_s1: 0.017496, loss_fp: 0.001938, loss_freq: 0.015416
[14:01:58.551] iteration 11737: loss: 0.074141, loss_s1: 0.048519, loss_fp: 0.004087, loss_freq: 0.035404
[14:01:59.175] iteration 11738: loss: 0.064516, loss_s1: 0.024856, loss_fp: 0.000565, loss_freq: 0.030541
[14:01:59.800] iteration 11739: loss: 0.065418, loss_s1: 0.045334, loss_fp: 0.000906, loss_freq: 0.029305
[14:02:00.424] iteration 11740: loss: 0.044649, loss_s1: 0.024344, loss_fp: 0.000303, loss_freq: 0.014875
[14:02:01.062] iteration 11741: loss: 0.084808, loss_s1: 0.065840, loss_fp: 0.001955, loss_freq: 0.039030
[14:02:01.687] iteration 11742: loss: 0.067547, loss_s1: 0.044865, loss_fp: 0.000953, loss_freq: 0.017618
[14:02:02.313] iteration 11743: loss: 0.108137, loss_s1: 0.007495, loss_fp: 0.000640, loss_freq: 0.007235
[14:02:02.937] iteration 11744: loss: 0.092585, loss_s1: 0.040720, loss_fp: 0.003291, loss_freq: 0.011364
[14:02:03.588] iteration 11745: loss: 0.036186, loss_s1: 0.016304, loss_fp: 0.001636, loss_freq: 0.015010
[14:02:04.253] iteration 11746: loss: 0.036476, loss_s1: 0.011881, loss_fp: 0.000427, loss_freq: 0.011259
[14:02:04.917] iteration 11747: loss: 0.110219, loss_s1: 0.043679, loss_fp: 0.000917, loss_freq: 0.065264
[14:02:05.579] iteration 11748: loss: 0.056696, loss_s1: 0.039449, loss_fp: 0.001024, loss_freq: 0.027223
[14:02:06.246] iteration 11749: loss: 0.075016, loss_s1: 0.059430, loss_fp: 0.001438, loss_freq: 0.048289
[14:02:06.906] iteration 11750: loss: 0.065359, loss_s1: 0.036814, loss_fp: 0.002688, loss_freq: 0.016844
[14:02:07.538] iteration 11751: loss: 0.060478, loss_s1: 0.043885, loss_fp: 0.002187, loss_freq: 0.012043
[14:02:08.166] iteration 11752: loss: 0.102267, loss_s1: 0.075820, loss_fp: 0.006436, loss_freq: 0.038378
[14:02:08.794] iteration 11753: loss: 0.066130, loss_s1: 0.034770, loss_fp: 0.001461, loss_freq: 0.039450
[14:02:09.421] iteration 11754: loss: 0.082395, loss_s1: 0.055146, loss_fp: 0.001555, loss_freq: 0.017128
[14:02:10.048] iteration 11755: loss: 0.118865, loss_s1: 0.075266, loss_fp: 0.002709, loss_freq: 0.077837
[14:02:10.666] iteration 11756: loss: 0.065801, loss_s1: 0.025434, loss_fp: 0.001356, loss_freq: 0.016485
[14:02:11.287] iteration 11757: loss: 0.085176, loss_s1: 0.056907, loss_fp: 0.001231, loss_freq: 0.021331
[14:02:11.911] iteration 11758: loss: 0.057101, loss_s1: 0.038962, loss_fp: 0.006168, loss_freq: 0.017820
[14:02:12.532] iteration 11759: loss: 0.070091, loss_s1: 0.066364, loss_fp: 0.001520, loss_freq: 0.036997
[14:02:13.150] iteration 11760: loss: 0.126176, loss_s1: 0.097579, loss_fp: 0.010964, loss_freq: 0.086147
[14:02:13.772] iteration 11761: loss: 0.099108, loss_s1: 0.035321, loss_fp: 0.003522, loss_freq: 0.039593
[14:02:14.438] iteration 11762: loss: 0.063054, loss_s1: 0.045142, loss_fp: 0.001898, loss_freq: 0.021794
[14:02:15.098] iteration 11763: loss: 0.058191, loss_s1: 0.033745, loss_fp: 0.001759, loss_freq: 0.024150
[14:02:15.732] iteration 11764: loss: 0.066170, loss_s1: 0.039772, loss_fp: 0.002057, loss_freq: 0.045097
[14:02:16.362] iteration 11765: loss: 0.093353, loss_s1: 0.017400, loss_fp: 0.001767, loss_freq: 0.079263
[14:02:17.027] iteration 11766: loss: 0.066995, loss_s1: 0.050153, loss_fp: 0.001874, loss_freq: 0.020652
[14:02:17.658] iteration 11767: loss: 0.084075, loss_s1: 0.062596, loss_fp: 0.006234, loss_freq: 0.013870
[14:02:18.287] iteration 11768: loss: 0.029054, loss_s1: 0.004087, loss_fp: 0.005198, loss_freq: 0.015814
[14:02:18.911] iteration 11769: loss: 0.050225, loss_s1: 0.020501, loss_fp: 0.000845, loss_freq: 0.005601
[14:02:19.532] iteration 11770: loss: 0.064970, loss_s1: 0.037197, loss_fp: 0.004511, loss_freq: 0.038772
[14:02:20.159] iteration 11771: loss: 0.075239, loss_s1: 0.040227, loss_fp: 0.002843, loss_freq: 0.015600
[14:02:20.780] iteration 11772: loss: 0.074015, loss_s1: 0.047687, loss_fp: 0.004383, loss_freq: 0.031686
[14:02:21.408] iteration 11773: loss: 0.081383, loss_s1: 0.041719, loss_fp: 0.003860, loss_freq: 0.040461
[14:02:22.038] iteration 11774: loss: 0.081962, loss_s1: 0.055178, loss_fp: 0.000863, loss_freq: 0.045139
[14:02:22.667] iteration 11775: loss: 0.055860, loss_s1: 0.028144, loss_fp: 0.001900, loss_freq: 0.042133
[14:02:23.292] iteration 11776: loss: 0.069547, loss_s1: 0.054499, loss_fp: 0.002180, loss_freq: 0.037593
[14:02:23.916] iteration 11777: loss: 0.072889, loss_s1: 0.062931, loss_fp: 0.006500, loss_freq: 0.021977
[14:02:24.562] iteration 11778: loss: 0.064556, loss_s1: 0.016288, loss_fp: 0.009610, loss_freq: 0.024466
[14:02:25.224] iteration 11779: loss: 0.053987, loss_s1: 0.024509, loss_fp: 0.000551, loss_freq: 0.005713
[14:02:25.880] iteration 11780: loss: 0.060520, loss_s1: 0.050086, loss_fp: 0.002761, loss_freq: 0.010182
[14:02:26.538] iteration 11781: loss: 0.038015, loss_s1: 0.030562, loss_fp: 0.000874, loss_freq: 0.005587
[14:02:27.241] iteration 11782: loss: 0.044617, loss_s1: 0.014084, loss_fp: 0.001680, loss_freq: 0.016501
[14:02:27.902] iteration 11783: loss: 0.058923, loss_s1: 0.027635, loss_fp: 0.005143, loss_freq: 0.027622
[14:02:28.559] iteration 11784: loss: 0.066388, loss_s1: 0.048512, loss_fp: 0.001786, loss_freq: 0.025581
[14:02:29.188] iteration 11785: loss: 0.101255, loss_s1: 0.035665, loss_fp: 0.001028, loss_freq: 0.070525
[14:02:29.808] iteration 11786: loss: 0.075999, loss_s1: 0.061196, loss_fp: 0.005121, loss_freq: 0.028169
[14:02:30.433] iteration 11787: loss: 0.044876, loss_s1: 0.023164, loss_fp: 0.003710, loss_freq: 0.006558
[14:02:31.057] iteration 11788: loss: 0.101243, loss_s1: 0.102099, loss_fp: 0.000623, loss_freq: 0.025834
[14:02:31.686] iteration 11789: loss: 0.090286, loss_s1: 0.103709, loss_fp: 0.003767, loss_freq: 0.028115
[14:02:32.315] iteration 11790: loss: 0.051772, loss_s1: 0.017633, loss_fp: 0.000905, loss_freq: 0.014265
[14:02:32.939] iteration 11791: loss: 0.097255, loss_s1: 0.056406, loss_fp: 0.001909, loss_freq: 0.038181
[14:02:33.588] iteration 11792: loss: 0.064987, loss_s1: 0.038107, loss_fp: 0.003908, loss_freq: 0.045285
[14:02:34.433] iteration 11793: loss: 0.139155, loss_s1: 0.067695, loss_fp: 0.003459, loss_freq: 0.115849
[14:02:35.144] iteration 11794: loss: 0.063253, loss_s1: 0.029955, loss_fp: 0.001121, loss_freq: 0.018400
[14:02:35.806] iteration 11795: loss: 0.101804, loss_s1: 0.098175, loss_fp: 0.005291, loss_freq: 0.033665
[14:02:36.475] iteration 11796: loss: 0.075912, loss_s1: 0.041749, loss_fp: 0.001578, loss_freq: 0.020114
[14:02:37.101] iteration 11797: loss: 0.067027, loss_s1: 0.040011, loss_fp: 0.003126, loss_freq: 0.013944
[14:02:37.732] iteration 11798: loss: 0.062408, loss_s1: 0.043199, loss_fp: 0.003628, loss_freq: 0.025747
[14:02:38.382] iteration 11799: loss: 0.058379, loss_s1: 0.014442, loss_fp: 0.000707, loss_freq: 0.041209
[14:02:39.010] iteration 11800: loss: 0.063298, loss_s1: 0.028391, loss_fp: 0.018460, loss_freq: 0.019112
[14:02:42.334] iteration 11800 : mean_dice : 0.763381
[14:02:43.004] iteration 11801: loss: 0.075432, loss_s1: 0.045647, loss_fp: 0.002018, loss_freq: 0.057989
[14:02:43.627] iteration 11802: loss: 0.084801, loss_s1: 0.036573, loss_fp: 0.002310, loss_freq: 0.016985
[14:02:44.254] iteration 11803: loss: 0.073064, loss_s1: 0.030250, loss_fp: 0.002303, loss_freq: 0.068049
[14:02:44.878] iteration 11804: loss: 0.064524, loss_s1: 0.027302, loss_fp: 0.003770, loss_freq: 0.011579
[14:02:45.504] iteration 11805: loss: 0.100881, loss_s1: 0.045256, loss_fp: 0.003699, loss_freq: 0.088852
[14:02:46.123] iteration 11806: loss: 0.122395, loss_s1: 0.069735, loss_fp: 0.004085, loss_freq: 0.059913
[14:02:46.746] iteration 11807: loss: 0.102208, loss_s1: 0.038489, loss_fp: 0.003924, loss_freq: 0.035462
[14:02:47.367] iteration 11808: loss: 0.108156, loss_s1: 0.109068, loss_fp: 0.003261, loss_freq: 0.032847
[14:02:47.985] iteration 11809: loss: 0.047408, loss_s1: 0.018060, loss_fp: 0.001493, loss_freq: 0.008338
[14:02:48.610] iteration 11810: loss: 0.059528, loss_s1: 0.020693, loss_fp: 0.009761, loss_freq: 0.035583
[14:02:49.236] iteration 11811: loss: 0.072785, loss_s1: 0.049190, loss_fp: 0.001528, loss_freq: 0.039432
[14:02:49.865] iteration 11812: loss: 0.086372, loss_s1: 0.053621, loss_fp: 0.006543, loss_freq: 0.037942
[14:02:50.496] iteration 11813: loss: 0.053181, loss_s1: 0.025917, loss_fp: 0.005869, loss_freq: 0.011756
[14:02:51.124] iteration 11814: loss: 0.060295, loss_s1: 0.025102, loss_fp: 0.001248, loss_freq: 0.034251
[14:02:51.750] iteration 11815: loss: 0.058706, loss_s1: 0.045329, loss_fp: 0.000586, loss_freq: 0.027680
[14:02:52.379] iteration 11816: loss: 0.073285, loss_s1: 0.051787, loss_fp: 0.003189, loss_freq: 0.057342
[14:02:53.002] iteration 11817: loss: 0.093369, loss_s1: 0.052077, loss_fp: 0.005993, loss_freq: 0.023913
[14:02:53.652] iteration 11818: loss: 0.092120, loss_s1: 0.045101, loss_fp: 0.008505, loss_freq: 0.027141
[14:02:54.311] iteration 11819: loss: 0.043747, loss_s1: 0.018798, loss_fp: 0.002268, loss_freq: 0.007388
[14:02:54.980] iteration 11820: loss: 0.080334, loss_s1: 0.042342, loss_fp: 0.003544, loss_freq: 0.012688
[14:02:55.647] iteration 11821: loss: 0.073135, loss_s1: 0.069648, loss_fp: 0.001518, loss_freq: 0.020003
[14:02:56.310] iteration 11822: loss: 0.072445, loss_s1: 0.038470, loss_fp: 0.000791, loss_freq: 0.037991
[14:02:56.972] iteration 11823: loss: 0.081544, loss_s1: 0.073263, loss_fp: 0.002184, loss_freq: 0.030167
[14:02:57.616] iteration 11824: loss: 0.080367, loss_s1: 0.048570, loss_fp: 0.003751, loss_freq: 0.033605
[14:02:58.250] iteration 11825: loss: 0.080697, loss_s1: 0.043930, loss_fp: 0.000886, loss_freq: 0.023868
[14:02:58.873] iteration 11826: loss: 0.101962, loss_s1: 0.080426, loss_fp: 0.014068, loss_freq: 0.052245
[14:02:59.495] iteration 11827: loss: 0.079475, loss_s1: 0.016315, loss_fp: 0.005044, loss_freq: 0.080427
[14:03:00.118] iteration 11828: loss: 0.074242, loss_s1: 0.023025, loss_fp: 0.014814, loss_freq: 0.042687
[14:03:00.747] iteration 11829: loss: 0.068391, loss_s1: 0.059567, loss_fp: 0.005585, loss_freq: 0.018025
[14:03:01.382] iteration 11830: loss: 0.052532, loss_s1: 0.026758, loss_fp: 0.006906, loss_freq: 0.010132
[14:03:02.013] iteration 11831: loss: 0.086322, loss_s1: 0.065254, loss_fp: 0.001738, loss_freq: 0.025167
[14:03:02.633] iteration 11832: loss: 0.076072, loss_s1: 0.006909, loss_fp: 0.000870, loss_freq: 0.028701
[14:03:03.262] iteration 11833: loss: 0.089256, loss_s1: 0.064894, loss_fp: 0.001422, loss_freq: 0.051972
[14:03:03.884] iteration 11834: loss: 0.070718, loss_s1: 0.022309, loss_fp: 0.004252, loss_freq: 0.072459
[14:03:04.501] iteration 11835: loss: 0.063645, loss_s1: 0.014768, loss_fp: 0.004713, loss_freq: 0.018944
[14:03:05.122] iteration 11836: loss: 0.107094, loss_s1: 0.092591, loss_fp: 0.007994, loss_freq: 0.064734
[14:03:05.747] iteration 11837: loss: 0.102157, loss_s1: 0.050290, loss_fp: 0.003123, loss_freq: 0.035492
[14:03:06.366] iteration 11838: loss: 0.053004, loss_s1: 0.012792, loss_fp: 0.004231, loss_freq: 0.039814
[14:03:06.985] iteration 11839: loss: 0.055991, loss_s1: 0.031277, loss_fp: 0.000681, loss_freq: 0.007422
[14:03:07.602] iteration 11840: loss: 0.081204, loss_s1: 0.053124, loss_fp: 0.001837, loss_freq: 0.036771
[14:03:08.222] iteration 11841: loss: 0.142827, loss_s1: 0.124009, loss_fp: 0.005043, loss_freq: 0.042913
[14:03:08.841] iteration 11842: loss: 0.070379, loss_s1: 0.069562, loss_fp: 0.003292, loss_freq: 0.007628
[14:03:09.468] iteration 11843: loss: 0.098144, loss_s1: 0.043897, loss_fp: 0.003105, loss_freq: 0.081936
[14:03:10.098] iteration 11844: loss: 0.098245, loss_s1: 0.063691, loss_fp: 0.003241, loss_freq: 0.033098
[14:03:10.727] iteration 11845: loss: 0.073228, loss_s1: 0.046882, loss_fp: 0.002097, loss_freq: 0.047264
[14:03:11.345] iteration 11846: loss: 0.065919, loss_s1: 0.034667, loss_fp: 0.004420, loss_freq: 0.032560
[14:03:11.973] iteration 11847: loss: 0.076057, loss_s1: 0.033443, loss_fp: 0.002044, loss_freq: 0.056774
[14:03:12.598] iteration 11848: loss: 0.074273, loss_s1: 0.028610, loss_fp: 0.002634, loss_freq: 0.019344
[14:03:13.227] iteration 11849: loss: 0.061277, loss_s1: 0.024831, loss_fp: 0.001105, loss_freq: 0.007789
[14:03:13.852] iteration 11850: loss: 0.062524, loss_s1: 0.034693, loss_fp: 0.002268, loss_freq: 0.042730
[14:03:14.476] iteration 11851: loss: 0.053269, loss_s1: 0.051607, loss_fp: 0.003404, loss_freq: 0.014773
[14:03:15.104] iteration 11852: loss: 0.114469, loss_s1: 0.025213, loss_fp: 0.000662, loss_freq: 0.019972
[14:03:15.733] iteration 11853: loss: 0.064758, loss_s1: 0.018528, loss_fp: 0.002976, loss_freq: 0.020645
[14:03:16.359] iteration 11854: loss: 0.055014, loss_s1: 0.012557, loss_fp: 0.007060, loss_freq: 0.038704
[14:03:16.986] iteration 11855: loss: 0.088212, loss_s1: 0.096086, loss_fp: 0.002745, loss_freq: 0.017626
[14:03:17.609] iteration 11856: loss: 0.055244, loss_s1: 0.030056, loss_fp: 0.013717, loss_freq: 0.016986
[14:03:18.230] iteration 11857: loss: 0.089725, loss_s1: 0.035158, loss_fp: 0.002063, loss_freq: 0.035332
[14:03:18.848] iteration 11858: loss: 0.052935, loss_s1: 0.030663, loss_fp: 0.007485, loss_freq: 0.009793
[14:03:19.479] iteration 11859: loss: 0.072951, loss_s1: 0.042677, loss_fp: 0.008209, loss_freq: 0.037074
[14:03:20.111] iteration 11860: loss: 0.127592, loss_s1: 0.055812, loss_fp: 0.003136, loss_freq: 0.063970
[14:03:20.742] iteration 11861: loss: 0.110660, loss_s1: 0.040549, loss_fp: 0.007809, loss_freq: 0.070697
[14:03:21.368] iteration 11862: loss: 0.079866, loss_s1: 0.044845, loss_fp: 0.004060, loss_freq: 0.033258
[14:03:21.996] iteration 11863: loss: 0.070338, loss_s1: 0.052983, loss_fp: 0.002077, loss_freq: 0.028712
[14:03:22.626] iteration 11864: loss: 0.045446, loss_s1: 0.020108, loss_fp: 0.001630, loss_freq: 0.014071
[14:03:23.256] iteration 11865: loss: 0.068904, loss_s1: 0.037528, loss_fp: 0.000371, loss_freq: 0.046052
[14:03:23.872] iteration 11866: loss: 0.093028, loss_s1: 0.047852, loss_fp: 0.000989, loss_freq: 0.012574
[14:03:24.489] iteration 11867: loss: 0.091454, loss_s1: 0.085341, loss_fp: 0.005212, loss_freq: 0.047068
[14:03:25.107] iteration 11868: loss: 0.096704, loss_s1: 0.068436, loss_fp: 0.026309, loss_freq: 0.036139
[14:03:25.727] iteration 11869: loss: 0.070995, loss_s1: 0.067796, loss_fp: 0.002931, loss_freq: 0.030838
[14:03:26.777] iteration 11870: loss: 0.070095, loss_s1: 0.047974, loss_fp: 0.003370, loss_freq: 0.031568
[14:03:27.437] iteration 11871: loss: 0.065505, loss_s1: 0.047646, loss_fp: 0.001904, loss_freq: 0.016929
[14:03:28.091] iteration 11872: loss: 0.047045, loss_s1: 0.031494, loss_fp: 0.000630, loss_freq: 0.013264
[14:03:28.749] iteration 11873: loss: 0.068516, loss_s1: 0.012652, loss_fp: 0.001099, loss_freq: 0.034253
[14:03:29.400] iteration 11874: loss: 0.092413, loss_s1: 0.068286, loss_fp: 0.001738, loss_freq: 0.060689
[14:03:30.054] iteration 11875: loss: 0.080096, loss_s1: 0.016079, loss_fp: 0.005295, loss_freq: 0.001984
[14:03:30.707] iteration 11876: loss: 0.043323, loss_s1: 0.029811, loss_fp: 0.001235, loss_freq: 0.013938
[14:03:31.329] iteration 11877: loss: 0.096539, loss_s1: 0.056116, loss_fp: 0.001202, loss_freq: 0.032579
[14:03:31.946] iteration 11878: loss: 0.083226, loss_s1: 0.060407, loss_fp: 0.001785, loss_freq: 0.040278
[14:03:32.579] iteration 11879: loss: 0.110458, loss_s1: 0.020972, loss_fp: 0.000796, loss_freq: 0.019242
[14:03:33.202] iteration 11880: loss: 0.084498, loss_s1: 0.048513, loss_fp: 0.001291, loss_freq: 0.048476
[14:03:33.817] iteration 11881: loss: 0.052071, loss_s1: 0.024669, loss_fp: 0.000569, loss_freq: 0.003350
[14:03:34.437] iteration 11882: loss: 0.063079, loss_s1: 0.046367, loss_fp: 0.000754, loss_freq: 0.018645
[14:03:35.057] iteration 11883: loss: 0.042018, loss_s1: 0.020774, loss_fp: 0.003285, loss_freq: 0.007877
[14:03:35.672] iteration 11884: loss: 0.103316, loss_s1: 0.101077, loss_fp: 0.004331, loss_freq: 0.049590
[14:03:36.291] iteration 11885: loss: 0.056879, loss_s1: 0.052168, loss_fp: 0.001366, loss_freq: 0.012579
[14:03:36.940] iteration 11886: loss: 0.063839, loss_s1: 0.015806, loss_fp: 0.002862, loss_freq: 0.033306
[14:03:37.587] iteration 11887: loss: 0.104263, loss_s1: 0.093899, loss_fp: 0.000612, loss_freq: 0.022382
[14:03:38.206] iteration 11888: loss: 0.082226, loss_s1: 0.020092, loss_fp: 0.004463, loss_freq: 0.024459
[14:03:38.835] iteration 11889: loss: 0.046283, loss_s1: 0.025962, loss_fp: 0.000772, loss_freq: 0.011644
[14:03:39.460] iteration 11890: loss: 0.146001, loss_s1: 0.034620, loss_fp: 0.001010, loss_freq: 0.035183
[14:03:40.085] iteration 11891: loss: 0.072913, loss_s1: 0.077873, loss_fp: 0.002678, loss_freq: 0.021005
[14:03:40.709] iteration 11892: loss: 0.063195, loss_s1: 0.044619, loss_fp: 0.003337, loss_freq: 0.026747
[14:03:41.342] iteration 11893: loss: 0.099457, loss_s1: 0.060786, loss_fp: 0.002881, loss_freq: 0.021863
[14:03:41.971] iteration 11894: loss: 0.064199, loss_s1: 0.054995, loss_fp: 0.000877, loss_freq: 0.017349
[14:03:42.597] iteration 11895: loss: 0.097903, loss_s1: 0.091581, loss_fp: 0.002317, loss_freq: 0.032101
[14:03:43.229] iteration 11896: loss: 0.103100, loss_s1: 0.080701, loss_fp: 0.005091, loss_freq: 0.066688
[14:03:43.855] iteration 11897: loss: 0.058781, loss_s1: 0.017328, loss_fp: 0.001833, loss_freq: 0.008460
[14:03:44.491] iteration 11898: loss: 0.101791, loss_s1: 0.042417, loss_fp: 0.006671, loss_freq: 0.018505
[14:03:45.120] iteration 11899: loss: 0.099749, loss_s1: 0.026663, loss_fp: 0.004097, loss_freq: 0.013656
[14:03:45.742] iteration 11900: loss: 0.065123, loss_s1: 0.026724, loss_fp: 0.000938, loss_freq: 0.040659
[14:03:46.371] iteration 11901: loss: 0.086568, loss_s1: 0.063198, loss_fp: 0.001886, loss_freq: 0.022110
[14:03:46.999] iteration 11902: loss: 0.073581, loss_s1: 0.043315, loss_fp: 0.007187, loss_freq: 0.037376
[14:03:47.611] iteration 11903: loss: 0.050006, loss_s1: 0.030933, loss_fp: 0.005292, loss_freq: 0.012868
[14:03:48.241] iteration 11904: loss: 0.099525, loss_s1: 0.071240, loss_fp: 0.006810, loss_freq: 0.029063
[14:03:48.866] iteration 11905: loss: 0.137985, loss_s1: 0.062981, loss_fp: 0.004532, loss_freq: 0.100935
[14:03:49.492] iteration 11906: loss: 0.077962, loss_s1: 0.038066, loss_fp: 0.009150, loss_freq: 0.021400
[14:03:50.114] iteration 11907: loss: 0.061515, loss_s1: 0.046979, loss_fp: 0.010024, loss_freq: 0.020038
[14:03:50.731] iteration 11908: loss: 0.132243, loss_s1: 0.072254, loss_fp: 0.003760, loss_freq: 0.053442
[14:03:51.350] iteration 11909: loss: 0.065747, loss_s1: 0.049100, loss_fp: 0.002315, loss_freq: 0.009113
[14:03:51.962] iteration 11910: loss: 0.070399, loss_s1: 0.039595, loss_fp: 0.002556, loss_freq: 0.015906
[14:03:52.578] iteration 11911: loss: 0.063676, loss_s1: 0.051784, loss_fp: 0.002045, loss_freq: 0.024788
[14:03:53.205] iteration 11912: loss: 0.066467, loss_s1: 0.020639, loss_fp: 0.001258, loss_freq: 0.004367
[14:03:53.859] iteration 11913: loss: 0.098975, loss_s1: 0.079725, loss_fp: 0.010535, loss_freq: 0.050381
[14:03:54.517] iteration 11914: loss: 0.071095, loss_s1: 0.034144, loss_fp: 0.001247, loss_freq: 0.010017
[14:03:55.169] iteration 11915: loss: 0.094575, loss_s1: 0.053185, loss_fp: 0.004630, loss_freq: 0.052135
[14:03:55.820] iteration 11916: loss: 0.051068, loss_s1: 0.029612, loss_fp: 0.001175, loss_freq: 0.011477
[14:03:56.472] iteration 11917: loss: 0.065559, loss_s1: 0.013417, loss_fp: 0.004750, loss_freq: 0.048086
[14:03:57.101] iteration 11918: loss: 0.063409, loss_s1: 0.043450, loss_fp: 0.001726, loss_freq: 0.035360
[14:03:57.730] iteration 11919: loss: 0.057511, loss_s1: 0.028202, loss_fp: 0.000703, loss_freq: 0.016812
[14:03:58.355] iteration 11920: loss: 0.076338, loss_s1: 0.038412, loss_fp: 0.002154, loss_freq: 0.043863
[14:03:58.981] iteration 11921: loss: 0.093147, loss_s1: 0.035899, loss_fp: 0.002057, loss_freq: 0.018139
[14:03:59.611] iteration 11922: loss: 0.044905, loss_s1: 0.013648, loss_fp: 0.001984, loss_freq: 0.010914
[14:04:00.235] iteration 11923: loss: 0.043118, loss_s1: 0.014829, loss_fp: 0.001083, loss_freq: 0.012855
[14:04:00.862] iteration 11924: loss: 0.061390, loss_s1: 0.070026, loss_fp: 0.000742, loss_freq: 0.016168
[14:04:01.494] iteration 11925: loss: 0.084274, loss_s1: 0.009154, loss_fp: 0.000939, loss_freq: 0.012780
[14:04:02.125] iteration 11926: loss: 0.099845, loss_s1: 0.064619, loss_fp: 0.009282, loss_freq: 0.044098
[14:04:02.755] iteration 11927: loss: 0.068194, loss_s1: 0.023478, loss_fp: 0.001562, loss_freq: 0.046656
[14:04:03.376] iteration 11928: loss: 0.085132, loss_s1: 0.025937, loss_fp: 0.003863, loss_freq: 0.062567
[14:04:04.004] iteration 11929: loss: 0.077216, loss_s1: 0.032080, loss_fp: 0.002243, loss_freq: 0.036894
[14:04:04.640] iteration 11930: loss: 0.075069, loss_s1: 0.027264, loss_fp: 0.002919, loss_freq: 0.010365
[14:04:05.330] iteration 11931: loss: 0.103129, loss_s1: 0.034890, loss_fp: 0.009010, loss_freq: 0.025016
[14:04:05.999] iteration 11932: loss: 0.095020, loss_s1: 0.067404, loss_fp: 0.017550, loss_freq: 0.036013
[14:04:06.644] iteration 11933: loss: 0.080868, loss_s1: 0.018550, loss_fp: 0.003151, loss_freq: 0.015445
[14:04:07.281] iteration 11934: loss: 0.060184, loss_s1: 0.024542, loss_fp: 0.001506, loss_freq: 0.010120
[14:04:07.915] iteration 11935: loss: 0.059073, loss_s1: 0.023659, loss_fp: 0.002773, loss_freq: 0.015646
[14:04:08.556] iteration 11936: loss: 0.099721, loss_s1: 0.050140, loss_fp: 0.006696, loss_freq: 0.055051
[14:04:09.224] iteration 11937: loss: 0.050545, loss_s1: 0.036683, loss_fp: 0.002797, loss_freq: 0.011931
[14:04:09.902] iteration 11938: loss: 0.073558, loss_s1: 0.066056, loss_fp: 0.002610, loss_freq: 0.024845
[14:04:10.588] iteration 11939: loss: 0.087733, loss_s1: 0.082275, loss_fp: 0.002568, loss_freq: 0.019883
[14:04:11.245] iteration 11940: loss: 0.069210, loss_s1: 0.043351, loss_fp: 0.000812, loss_freq: 0.014022
[14:04:11.913] iteration 11941: loss: 0.085955, loss_s1: 0.055057, loss_fp: 0.002282, loss_freq: 0.057816
[14:04:12.536] iteration 11942: loss: 0.058446, loss_s1: 0.051281, loss_fp: 0.008417, loss_freq: 0.016640
[14:04:13.170] iteration 11943: loss: 0.124631, loss_s1: 0.124462, loss_fp: 0.007126, loss_freq: 0.048927
[14:04:13.795] iteration 11944: loss: 0.073201, loss_s1: 0.030837, loss_fp: 0.001448, loss_freq: 0.057976
[14:04:14.423] iteration 11945: loss: 0.070901, loss_s1: 0.032537, loss_fp: 0.002391, loss_freq: 0.019954
[14:04:15.059] iteration 11946: loss: 0.068930, loss_s1: 0.049104, loss_fp: 0.004831, loss_freq: 0.044250
[14:04:15.687] iteration 11947: loss: 0.083736, loss_s1: 0.031004, loss_fp: 0.000684, loss_freq: 0.011377
[14:04:16.309] iteration 11948: loss: 0.070259, loss_s1: 0.035633, loss_fp: 0.002424, loss_freq: 0.021107
[14:04:16.939] iteration 11949: loss: 0.115429, loss_s1: 0.045921, loss_fp: 0.001139, loss_freq: 0.048333
[14:04:17.577] iteration 11950: loss: 0.068307, loss_s1: 0.028561, loss_fp: 0.001162, loss_freq: 0.026157
[14:04:18.194] iteration 11951: loss: 0.055624, loss_s1: 0.021780, loss_fp: 0.002182, loss_freq: 0.031360
[14:04:18.819] iteration 11952: loss: 0.064012, loss_s1: 0.046866, loss_fp: 0.001660, loss_freq: 0.017881
[14:04:19.445] iteration 11953: loss: 0.069094, loss_s1: 0.051347, loss_fp: 0.004775, loss_freq: 0.031986
[14:04:20.071] iteration 11954: loss: 0.077170, loss_s1: 0.047358, loss_fp: 0.002853, loss_freq: 0.008571
[14:04:20.699] iteration 11955: loss: 0.056074, loss_s1: 0.023694, loss_fp: 0.002933, loss_freq: 0.038081
[14:04:21.327] iteration 11956: loss: 0.058486, loss_s1: 0.032003, loss_fp: 0.001645, loss_freq: 0.012682
[14:04:21.960] iteration 11957: loss: 0.060968, loss_s1: 0.016777, loss_fp: 0.001063, loss_freq: 0.049190
[14:04:22.601] iteration 11958: loss: 0.067024, loss_s1: 0.055447, loss_fp: 0.002103, loss_freq: 0.024607
[14:04:23.241] iteration 11959: loss: 0.106181, loss_s1: 0.051921, loss_fp: 0.002751, loss_freq: 0.017302
[14:04:23.879] iteration 11960: loss: 0.072667, loss_s1: 0.045251, loss_fp: 0.001651, loss_freq: 0.026409
[14:04:24.522] iteration 11961: loss: 0.052797, loss_s1: 0.008906, loss_fp: 0.001090, loss_freq: 0.034788
[14:04:25.157] iteration 11962: loss: 0.041675, loss_s1: 0.018796, loss_fp: 0.001975, loss_freq: 0.007771
[14:04:25.782] iteration 11963: loss: 0.073695, loss_s1: 0.044774, loss_fp: 0.003245, loss_freq: 0.021036
[14:04:26.408] iteration 11964: loss: 0.045740, loss_s1: 0.030298, loss_fp: 0.001130, loss_freq: 0.012604
[14:04:27.035] iteration 11965: loss: 0.073049, loss_s1: 0.081450, loss_fp: 0.001709, loss_freq: 0.012127
[14:04:27.666] iteration 11966: loss: 0.123903, loss_s1: 0.097716, loss_fp: 0.003132, loss_freq: 0.084084
[14:04:28.292] iteration 11967: loss: 0.067800, loss_s1: 0.044098, loss_fp: 0.003658, loss_freq: 0.032351
[14:04:28.919] iteration 11968: loss: 0.058143, loss_s1: 0.019844, loss_fp: 0.006393, loss_freq: 0.037470
[14:04:29.547] iteration 11969: loss: 0.082216, loss_s1: 0.066408, loss_fp: 0.003464, loss_freq: 0.015958
[14:04:30.174] iteration 11970: loss: 0.069687, loss_s1: 0.026225, loss_fp: 0.001716, loss_freq: 0.051896
[14:04:30.802] iteration 11971: loss: 0.081285, loss_s1: 0.030711, loss_fp: 0.009620, loss_freq: 0.028301
[14:04:31.419] iteration 11972: loss: 0.074438, loss_s1: 0.065520, loss_fp: 0.001347, loss_freq: 0.005481
[14:04:32.050] iteration 11973: loss: 0.097679, loss_s1: 0.040811, loss_fp: 0.006189, loss_freq: 0.019645
[14:04:32.682] iteration 11974: loss: 0.098334, loss_s1: 0.018715, loss_fp: 0.002389, loss_freq: 0.023930
[14:04:33.319] iteration 11975: loss: 0.053648, loss_s1: 0.025685, loss_fp: 0.000850, loss_freq: 0.024828
[14:04:33.951] iteration 11976: loss: 0.156353, loss_s1: 0.154789, loss_fp: 0.001496, loss_freq: 0.086669
[14:04:34.587] iteration 11977: loss: 0.055778, loss_s1: 0.026910, loss_fp: 0.005186, loss_freq: 0.025165
[14:04:35.221] iteration 11978: loss: 0.061981, loss_s1: 0.019297, loss_fp: 0.000785, loss_freq: 0.006647
[14:04:35.849] iteration 11979: loss: 0.067493, loss_s1: 0.052130, loss_fp: 0.002612, loss_freq: 0.016387
[14:04:36.481] iteration 11980: loss: 0.092333, loss_s1: 0.031719, loss_fp: 0.000748, loss_freq: 0.005305
[14:04:37.109] iteration 11981: loss: 0.065299, loss_s1: 0.033287, loss_fp: 0.003790, loss_freq: 0.059786
[14:04:37.753] iteration 11982: loss: 0.061243, loss_s1: 0.052515, loss_fp: 0.000758, loss_freq: 0.010163
[14:04:38.628] iteration 11983: loss: 0.093652, loss_s1: 0.084199, loss_fp: 0.001988, loss_freq: 0.039321
[14:04:39.323] iteration 11984: loss: 0.116190, loss_s1: 0.021297, loss_fp: 0.002855, loss_freq: 0.065145
[14:04:39.998] iteration 11985: loss: 0.048342, loss_s1: 0.013154, loss_fp: 0.001757, loss_freq: 0.017529
[14:04:40.650] iteration 11986: loss: 0.086370, loss_s1: 0.051148, loss_fp: 0.001238, loss_freq: 0.062694
[14:04:41.297] iteration 11987: loss: 0.127576, loss_s1: 0.130894, loss_fp: 0.004014, loss_freq: 0.026756
[14:04:41.926] iteration 11988: loss: 0.065920, loss_s1: 0.059923, loss_fp: 0.003867, loss_freq: 0.024731
[14:04:42.558] iteration 11989: loss: 0.068112, loss_s1: 0.029687, loss_fp: 0.004753, loss_freq: 0.044036
[14:04:43.210] iteration 11990: loss: 0.094084, loss_s1: 0.054626, loss_fp: 0.001426, loss_freq: 0.067637
[14:04:43.898] iteration 11991: loss: 0.070359, loss_s1: 0.051143, loss_fp: 0.000829, loss_freq: 0.035594
[14:04:44.559] iteration 11992: loss: 0.070390, loss_s1: 0.029735, loss_fp: 0.003539, loss_freq: 0.006314
[14:04:45.200] iteration 11993: loss: 0.064494, loss_s1: 0.061660, loss_fp: 0.001592, loss_freq: 0.026158
[14:04:45.835] iteration 11994: loss: 0.079089, loss_s1: 0.039591, loss_fp: 0.002790, loss_freq: 0.050392
[14:04:46.460] iteration 11995: loss: 0.071329, loss_s1: 0.017337, loss_fp: 0.002101, loss_freq: 0.031138
[14:04:47.092] iteration 11996: loss: 0.054563, loss_s1: 0.029034, loss_fp: 0.001190, loss_freq: 0.033403
[14:04:47.723] iteration 11997: loss: 0.041787, loss_s1: 0.012336, loss_fp: 0.001196, loss_freq: 0.017347
[14:04:48.347] iteration 11998: loss: 0.134047, loss_s1: 0.102890, loss_fp: 0.007169, loss_freq: 0.020835
[14:04:48.979] iteration 11999: loss: 0.055041, loss_s1: 0.025050, loss_fp: 0.005103, loss_freq: 0.030811
[14:04:49.608] iteration 12000: loss: 0.072999, loss_s1: 0.039314, loss_fp: 0.002481, loss_freq: 0.026301
[14:04:52.933] iteration 12000 : mean_dice : 0.745012
[14:04:53.617] iteration 12001: loss: 0.076532, loss_s1: 0.056181, loss_fp: 0.002362, loss_freq: 0.023767
[14:04:54.249] iteration 12002: loss: 0.101682, loss_s1: 0.060890, loss_fp: 0.002163, loss_freq: 0.025210
[14:04:54.884] iteration 12003: loss: 0.112581, loss_s1: 0.089860, loss_fp: 0.006786, loss_freq: 0.030492
[14:04:55.512] iteration 12004: loss: 0.083871, loss_s1: 0.043133, loss_fp: 0.003409, loss_freq: 0.025468
[14:04:56.144] iteration 12005: loss: 0.071248, loss_s1: 0.035360, loss_fp: 0.005150, loss_freq: 0.033203
[14:04:56.772] iteration 12006: loss: 0.124675, loss_s1: 0.120287, loss_fp: 0.005301, loss_freq: 0.014956
[14:04:57.404] iteration 12007: loss: 0.038584, loss_s1: 0.015469, loss_fp: 0.000555, loss_freq: 0.016718
[14:04:58.064] iteration 12008: loss: 0.074528, loss_s1: 0.066517, loss_fp: 0.006884, loss_freq: 0.029062
[14:04:58.694] iteration 12009: loss: 0.086193, loss_s1: 0.054646, loss_fp: 0.006770, loss_freq: 0.023917
[14:04:59.325] iteration 12010: loss: 0.075974, loss_s1: 0.035162, loss_fp: 0.005737, loss_freq: 0.052826
[14:04:59.954] iteration 12011: loss: 0.091730, loss_s1: 0.065647, loss_fp: 0.010437, loss_freq: 0.050436
[14:05:00.572] iteration 12012: loss: 0.082897, loss_s1: 0.055083, loss_fp: 0.001078, loss_freq: 0.040666
[14:05:01.603] iteration 12013: loss: 0.070492, loss_s1: 0.044555, loss_fp: 0.006291, loss_freq: 0.008977
[14:05:02.259] iteration 12014: loss: 0.063702, loss_s1: 0.054654, loss_fp: 0.008110, loss_freq: 0.014098
[14:05:02.914] iteration 12015: loss: 0.051242, loss_s1: 0.024346, loss_fp: 0.000338, loss_freq: 0.023066
[14:05:03.545] iteration 12016: loss: 0.085664, loss_s1: 0.066099, loss_fp: 0.005067, loss_freq: 0.019246
[14:05:04.179] iteration 12017: loss: 0.115229, loss_s1: 0.053546, loss_fp: 0.003633, loss_freq: 0.045674
[14:05:04.807] iteration 12018: loss: 0.073754, loss_s1: 0.028865, loss_fp: 0.003990, loss_freq: 0.004406
[14:05:05.465] iteration 12019: loss: 0.043413, loss_s1: 0.038000, loss_fp: 0.001311, loss_freq: 0.014801
[14:05:06.097] iteration 12020: loss: 0.105918, loss_s1: 0.082908, loss_fp: 0.004538, loss_freq: 0.027481
[14:05:06.725] iteration 12021: loss: 0.083409, loss_s1: 0.050868, loss_fp: 0.008134, loss_freq: 0.058121
[14:05:07.358] iteration 12022: loss: 0.094325, loss_s1: 0.002552, loss_fp: 0.001186, loss_freq: 0.006344
[14:05:07.989] iteration 12023: loss: 0.063336, loss_s1: 0.044651, loss_fp: 0.003111, loss_freq: 0.028638
[14:05:08.618] iteration 12024: loss: 0.062041, loss_s1: 0.025042, loss_fp: 0.001373, loss_freq: 0.032830
[14:05:09.246] iteration 12025: loss: 0.056690, loss_s1: 0.027011, loss_fp: 0.000699, loss_freq: 0.014858
[14:05:09.876] iteration 12026: loss: 0.060294, loss_s1: 0.037299, loss_fp: 0.000986, loss_freq: 0.025948
[14:05:10.534] iteration 12027: loss: 0.114114, loss_s1: 0.133629, loss_fp: 0.002551, loss_freq: 0.046935
[14:05:11.199] iteration 12028: loss: 0.058624, loss_s1: 0.040259, loss_fp: 0.001618, loss_freq: 0.018681
[14:05:11.848] iteration 12029: loss: 0.061259, loss_s1: 0.029761, loss_fp: 0.001111, loss_freq: 0.014479
[14:05:12.477] iteration 12030: loss: 0.086517, loss_s1: 0.020142, loss_fp: 0.004087, loss_freq: 0.009990
[14:05:13.096] iteration 12031: loss: 0.041655, loss_s1: 0.015029, loss_fp: 0.001750, loss_freq: 0.023490
[14:05:13.720] iteration 12032: loss: 0.060221, loss_s1: 0.047416, loss_fp: 0.000882, loss_freq: 0.027223
[14:05:14.347] iteration 12033: loss: 0.127679, loss_s1: 0.051362, loss_fp: 0.001413, loss_freq: 0.075027
[14:05:14.968] iteration 12034: loss: 0.051411, loss_s1: 0.029282, loss_fp: 0.004228, loss_freq: 0.024026
[14:05:15.593] iteration 12035: loss: 0.106246, loss_s1: 0.091486, loss_fp: 0.000661, loss_freq: 0.071256
[14:05:16.218] iteration 12036: loss: 0.053170, loss_s1: 0.015777, loss_fp: 0.001613, loss_freq: 0.010404
[14:05:16.843] iteration 12037: loss: 0.044534, loss_s1: 0.021344, loss_fp: 0.000605, loss_freq: 0.025776
[14:05:17.470] iteration 12038: loss: 0.106437, loss_s1: 0.077696, loss_fp: 0.003077, loss_freq: 0.046778
[14:05:18.095] iteration 12039: loss: 0.095946, loss_s1: 0.068163, loss_fp: 0.005617, loss_freq: 0.065707
[14:05:18.717] iteration 12040: loss: 0.053230, loss_s1: 0.026333, loss_fp: 0.001494, loss_freq: 0.011425
[14:05:19.335] iteration 12041: loss: 0.067473, loss_s1: 0.031790, loss_fp: 0.000410, loss_freq: 0.035588
[14:05:19.951] iteration 12042: loss: 0.068951, loss_s1: 0.042865, loss_fp: 0.000915, loss_freq: 0.030073
[14:05:20.577] iteration 12043: loss: 0.069822, loss_s1: 0.057101, loss_fp: 0.003373, loss_freq: 0.010540
[14:05:21.214] iteration 12044: loss: 0.069104, loss_s1: 0.040885, loss_fp: 0.005807, loss_freq: 0.038415
[14:05:21.850] iteration 12045: loss: 0.076379, loss_s1: 0.056962, loss_fp: 0.007373, loss_freq: 0.052975
[14:05:22.475] iteration 12046: loss: 0.076405, loss_s1: 0.056850, loss_fp: 0.001804, loss_freq: 0.044609
[14:05:23.106] iteration 12047: loss: 0.107533, loss_s1: 0.068233, loss_fp: 0.012646, loss_freq: 0.034332
[14:05:23.736] iteration 12048: loss: 0.132463, loss_s1: 0.114123, loss_fp: 0.009076, loss_freq: 0.065130
[14:05:24.373] iteration 12049: loss: 0.090080, loss_s1: 0.076703, loss_fp: 0.003903, loss_freq: 0.042216
[14:05:25.004] iteration 12050: loss: 0.059924, loss_s1: 0.034899, loss_fp: 0.003575, loss_freq: 0.032253
[14:05:25.634] iteration 12051: loss: 0.097835, loss_s1: 0.064394, loss_fp: 0.005749, loss_freq: 0.020857
[14:05:26.255] iteration 12052: loss: 0.061574, loss_s1: 0.027681, loss_fp: 0.002381, loss_freq: 0.010474
[14:05:26.900] iteration 12053: loss: 0.097223, loss_s1: 0.041958, loss_fp: 0.028179, loss_freq: 0.014222
[14:05:27.538] iteration 12054: loss: 0.059553, loss_s1: 0.015593, loss_fp: 0.008144, loss_freq: 0.037536
[14:05:28.162] iteration 12055: loss: 0.047750, loss_s1: 0.016494, loss_fp: 0.000849, loss_freq: 0.018939
[14:05:28.796] iteration 12056: loss: 0.063673, loss_s1: 0.028365, loss_fp: 0.001840, loss_freq: 0.051338
[14:05:29.424] iteration 12057: loss: 0.074076, loss_s1: 0.011059, loss_fp: 0.001130, loss_freq: 0.025750
[14:05:30.063] iteration 12058: loss: 0.068870, loss_s1: 0.041226, loss_fp: 0.002367, loss_freq: 0.019162
[14:05:30.693] iteration 12059: loss: 0.099963, loss_s1: 0.052647, loss_fp: 0.018699, loss_freq: 0.049609
[14:05:31.323] iteration 12060: loss: 0.082470, loss_s1: 0.025657, loss_fp: 0.002370, loss_freq: 0.054990
[14:05:31.955] iteration 12061: loss: 0.069936, loss_s1: 0.043856, loss_fp: 0.003597, loss_freq: 0.052559
[14:05:32.576] iteration 12062: loss: 0.080037, loss_s1: 0.076399, loss_fp: 0.002008, loss_freq: 0.031012
[14:05:33.200] iteration 12063: loss: 0.051582, loss_s1: 0.033440, loss_fp: 0.001044, loss_freq: 0.014744
[14:05:33.824] iteration 12064: loss: 0.108738, loss_s1: 0.037397, loss_fp: 0.001970, loss_freq: 0.020729
[14:05:34.457] iteration 12065: loss: 0.045403, loss_s1: 0.026962, loss_fp: 0.003154, loss_freq: 0.003865
[14:05:35.083] iteration 12066: loss: 0.067181, loss_s1: 0.065444, loss_fp: 0.001626, loss_freq: 0.021895
[14:05:35.707] iteration 12067: loss: 0.068312, loss_s1: 0.060957, loss_fp: 0.000760, loss_freq: 0.016353
[14:05:36.342] iteration 12068: loss: 0.061287, loss_s1: 0.033426, loss_fp: 0.001025, loss_freq: 0.006788
[14:05:36.969] iteration 12069: loss: 0.072801, loss_s1: 0.068245, loss_fp: 0.002111, loss_freq: 0.007227
[14:05:37.628] iteration 12070: loss: 0.042604, loss_s1: 0.024015, loss_fp: 0.000769, loss_freq: 0.010535
[14:05:38.252] iteration 12071: loss: 0.079247, loss_s1: 0.042247, loss_fp: 0.001637, loss_freq: 0.049051
[14:05:38.888] iteration 12072: loss: 0.080107, loss_s1: 0.057582, loss_fp: 0.005402, loss_freq: 0.042952
[14:05:39.533] iteration 12073: loss: 0.067014, loss_s1: 0.031545, loss_fp: 0.005666, loss_freq: 0.020918
[14:05:40.175] iteration 12074: loss: 0.093813, loss_s1: 0.074938, loss_fp: 0.004650, loss_freq: 0.053528
[14:05:40.818] iteration 12075: loss: 0.078839, loss_s1: 0.030216, loss_fp: 0.001002, loss_freq: 0.052150
[14:05:41.448] iteration 12076: loss: 0.053685, loss_s1: 0.025928, loss_fp: 0.003219, loss_freq: 0.024011
[14:05:42.069] iteration 12077: loss: 0.107935, loss_s1: 0.062371, loss_fp: 0.001738, loss_freq: 0.064153
[14:05:42.726] iteration 12078: loss: 0.053393, loss_s1: 0.033826, loss_fp: 0.001950, loss_freq: 0.013543
[14:05:43.382] iteration 12079: loss: 0.133354, loss_s1: 0.065589, loss_fp: 0.004370, loss_freq: 0.077174
[14:05:44.038] iteration 12080: loss: 0.045163, loss_s1: 0.015575, loss_fp: 0.002886, loss_freq: 0.015471
[14:05:44.655] iteration 12081: loss: 0.079950, loss_s1: 0.041295, loss_fp: 0.000930, loss_freq: 0.029602
[14:05:45.275] iteration 12082: loss: 0.084277, loss_s1: 0.050731, loss_fp: 0.001404, loss_freq: 0.009481
[14:05:45.894] iteration 12083: loss: 0.070757, loss_s1: 0.045773, loss_fp: 0.004194, loss_freq: 0.025681
[14:05:46.554] iteration 12084: loss: 0.078664, loss_s1: 0.026235, loss_fp: 0.001045, loss_freq: 0.067012
[14:05:47.210] iteration 12085: loss: 0.083641, loss_s1: 0.033390, loss_fp: 0.006489, loss_freq: 0.057734
[14:05:47.864] iteration 12086: loss: 0.101155, loss_s1: 0.098749, loss_fp: 0.006249, loss_freq: 0.037299
[14:05:48.491] iteration 12087: loss: 0.073122, loss_s1: 0.058803, loss_fp: 0.002753, loss_freq: 0.044756
[14:05:49.111] iteration 12088: loss: 0.058019, loss_s1: 0.013667, loss_fp: 0.002519, loss_freq: 0.009528
[14:05:49.746] iteration 12089: loss: 0.094111, loss_s1: 0.084175, loss_fp: 0.004478, loss_freq: 0.048059
[14:05:50.371] iteration 12090: loss: 0.048977, loss_s1: 0.024418, loss_fp: 0.001737, loss_freq: 0.012017
[14:05:51.000] iteration 12091: loss: 0.066582, loss_s1: 0.057268, loss_fp: 0.001481, loss_freq: 0.022727
[14:05:51.628] iteration 12092: loss: 0.168199, loss_s1: 0.078770, loss_fp: 0.001122, loss_freq: 0.053007
[14:05:52.256] iteration 12093: loss: 0.071408, loss_s1: 0.037457, loss_fp: 0.001077, loss_freq: 0.037786
[14:05:52.883] iteration 12094: loss: 0.077886, loss_s1: 0.052475, loss_fp: 0.002950, loss_freq: 0.039862
[14:05:53.508] iteration 12095: loss: 0.054198, loss_s1: 0.019267, loss_fp: 0.007815, loss_freq: 0.020495
[14:05:54.141] iteration 12096: loss: 0.054186, loss_s1: 0.040189, loss_fp: 0.004071, loss_freq: 0.022213
[14:05:54.771] iteration 12097: loss: 0.050345, loss_s1: 0.024211, loss_fp: 0.001115, loss_freq: 0.021206
[14:05:55.400] iteration 12098: loss: 0.098025, loss_s1: 0.033614, loss_fp: 0.002961, loss_freq: 0.077407
[14:05:56.030] iteration 12099: loss: 0.062807, loss_s1: 0.022215, loss_fp: 0.006911, loss_freq: 0.028148
[14:05:56.657] iteration 12100: loss: 0.058312, loss_s1: 0.030151, loss_fp: 0.000647, loss_freq: 0.024484
[14:05:57.286] iteration 12101: loss: 0.049591, loss_s1: 0.028545, loss_fp: 0.000854, loss_freq: 0.019144
[14:05:57.910] iteration 12102: loss: 0.041596, loss_s1: 0.020501, loss_fp: 0.003027, loss_freq: 0.020134
[14:05:58.538] iteration 12103: loss: 0.086315, loss_s1: 0.032277, loss_fp: 0.002277, loss_freq: 0.030448
[14:05:59.168] iteration 12104: loss: 0.065913, loss_s1: 0.036468, loss_fp: 0.002525, loss_freq: 0.039836
[14:05:59.792] iteration 12105: loss: 0.037562, loss_s1: 0.030196, loss_fp: 0.002166, loss_freq: 0.006552
[14:06:00.421] iteration 12106: loss: 0.059811, loss_s1: 0.026576, loss_fp: 0.001059, loss_freq: 0.016008
[14:06:01.051] iteration 12107: loss: 0.063555, loss_s1: 0.029393, loss_fp: 0.000689, loss_freq: 0.035901
[14:06:01.676] iteration 12108: loss: 0.057887, loss_s1: 0.033094, loss_fp: 0.002164, loss_freq: 0.012439
[14:06:02.301] iteration 12109: loss: 0.119967, loss_s1: 0.111783, loss_fp: 0.001886, loss_freq: 0.046828
[14:06:02.961] iteration 12110: loss: 0.048544, loss_s1: 0.020047, loss_fp: 0.004387, loss_freq: 0.011978
[14:06:03.628] iteration 12111: loss: 0.053107, loss_s1: 0.027603, loss_fp: 0.002658, loss_freq: 0.009927
[14:06:04.286] iteration 12112: loss: 0.085772, loss_s1: 0.040276, loss_fp: 0.001764, loss_freq: 0.014985
[14:06:04.951] iteration 12113: loss: 0.063138, loss_s1: 0.028403, loss_fp: 0.003128, loss_freq: 0.043121
[14:06:05.594] iteration 12114: loss: 0.100796, loss_s1: 0.095441, loss_fp: 0.000852, loss_freq: 0.044385
[14:06:06.223] iteration 12115: loss: 0.060655, loss_s1: 0.044214, loss_fp: 0.003195, loss_freq: 0.026896
[14:06:06.841] iteration 12116: loss: 0.075766, loss_s1: 0.055332, loss_fp: 0.001223, loss_freq: 0.030280
[14:06:07.471] iteration 12117: loss: 0.088898, loss_s1: 0.049589, loss_fp: 0.004854, loss_freq: 0.016952
[14:06:08.124] iteration 12118: loss: 0.086066, loss_s1: 0.025220, loss_fp: 0.001588, loss_freq: 0.053307
[14:06:08.782] iteration 12119: loss: 0.146946, loss_s1: 0.095208, loss_fp: 0.007768, loss_freq: 0.123419
[14:06:09.448] iteration 12120: loss: 0.116007, loss_s1: 0.079618, loss_fp: 0.007745, loss_freq: 0.078093
[14:06:10.101] iteration 12121: loss: 0.038291, loss_s1: 0.006246, loss_fp: 0.000903, loss_freq: 0.014133
[14:06:10.747] iteration 12122: loss: 0.087935, loss_s1: 0.090010, loss_fp: 0.002586, loss_freq: 0.026545
[14:06:11.391] iteration 12123: loss: 0.068258, loss_s1: 0.007077, loss_fp: 0.003112, loss_freq: 0.031372
[14:06:12.020] iteration 12124: loss: 0.062972, loss_s1: 0.046661, loss_fp: 0.003750, loss_freq: 0.032556
[14:06:12.642] iteration 12125: loss: 0.065039, loss_s1: 0.046261, loss_fp: 0.004405, loss_freq: 0.012977
[14:06:13.273] iteration 12126: loss: 0.069505, loss_s1: 0.039368, loss_fp: 0.002803, loss_freq: 0.034873
[14:06:13.900] iteration 12127: loss: 0.105774, loss_s1: 0.039243, loss_fp: 0.008362, loss_freq: 0.028956
[14:06:14.535] iteration 12128: loss: 0.066084, loss_s1: 0.069217, loss_fp: 0.000861, loss_freq: 0.013599
[14:06:15.168] iteration 12129: loss: 0.082825, loss_s1: 0.026172, loss_fp: 0.004393, loss_freq: 0.051460
[14:06:15.798] iteration 12130: loss: 0.087807, loss_s1: 0.097089, loss_fp: 0.002255, loss_freq: 0.027193
[14:06:16.438] iteration 12131: loss: 0.062233, loss_s1: 0.049327, loss_fp: 0.005223, loss_freq: 0.035641
[14:06:17.069] iteration 12132: loss: 0.064941, loss_s1: 0.047994, loss_fp: 0.003999, loss_freq: 0.028648
[14:06:17.700] iteration 12133: loss: 0.093469, loss_s1: 0.070615, loss_fp: 0.001577, loss_freq: 0.057196
[14:06:18.335] iteration 12134: loss: 0.072262, loss_s1: 0.029309, loss_fp: 0.002772, loss_freq: 0.014013
[14:06:18.968] iteration 12135: loss: 0.046544, loss_s1: 0.014683, loss_fp: 0.002305, loss_freq: 0.012696
[14:06:19.593] iteration 12136: loss: 0.059687, loss_s1: 0.054289, loss_fp: 0.003121, loss_freq: 0.018913
[14:06:20.225] iteration 12137: loss: 0.078727, loss_s1: 0.081878, loss_fp: 0.003871, loss_freq: 0.011911
[14:06:20.855] iteration 12138: loss: 0.057405, loss_s1: 0.038960, loss_fp: 0.003014, loss_freq: 0.013131
[14:06:21.481] iteration 12139: loss: 0.071392, loss_s1: 0.026172, loss_fp: 0.000578, loss_freq: 0.052879
[14:06:22.105] iteration 12140: loss: 0.060362, loss_s1: 0.051797, loss_fp: 0.001395, loss_freq: 0.028130
[14:06:22.730] iteration 12141: loss: 0.092895, loss_s1: 0.077257, loss_fp: 0.002679, loss_freq: 0.019542
[14:06:23.360] iteration 12142: loss: 0.058862, loss_s1: 0.021696, loss_fp: 0.007016, loss_freq: 0.014168
[14:06:23.980] iteration 12143: loss: 0.077478, loss_s1: 0.043632, loss_fp: 0.002824, loss_freq: 0.033879
[14:06:24.606] iteration 12144: loss: 0.057188, loss_s1: 0.039646, loss_fp: 0.004677, loss_freq: 0.014330
[14:06:25.222] iteration 12145: loss: 0.078353, loss_s1: 0.043147, loss_fp: 0.003173, loss_freq: 0.054739
[14:06:25.847] iteration 12146: loss: 0.164272, loss_s1: 0.123639, loss_fp: 0.018222, loss_freq: 0.048567
[14:06:26.468] iteration 12147: loss: 0.083390, loss_s1: 0.046241, loss_fp: 0.004598, loss_freq: 0.034247
[14:06:27.088] iteration 12148: loss: 0.072700, loss_s1: 0.043344, loss_fp: 0.004547, loss_freq: 0.029186
[14:06:27.708] iteration 12149: loss: 0.101276, loss_s1: 0.053235, loss_fp: 0.005040, loss_freq: 0.030716
[14:06:28.327] iteration 12150: loss: 0.056292, loss_s1: 0.031322, loss_fp: 0.002163, loss_freq: 0.010479
[14:06:28.956] iteration 12151: loss: 0.056130, loss_s1: 0.028720, loss_fp: 0.006212, loss_freq: 0.025227
[14:06:29.581] iteration 12152: loss: 0.076880, loss_s1: 0.022026, loss_fp: 0.002212, loss_freq: 0.014965
[14:06:30.216] iteration 12153: loss: 0.066840, loss_s1: 0.048946, loss_fp: 0.002168, loss_freq: 0.019804
[14:06:30.835] iteration 12154: loss: 0.120111, loss_s1: 0.118940, loss_fp: 0.028130, loss_freq: 0.029902
[14:06:31.451] iteration 12155: loss: 0.057507, loss_s1: 0.040325, loss_fp: 0.001372, loss_freq: 0.014809
[14:06:32.378] iteration 12156: loss: 0.060380, loss_s1: 0.053810, loss_fp: 0.000740, loss_freq: 0.014522
[14:06:33.006] iteration 12157: loss: 0.068753, loss_s1: 0.043950, loss_fp: 0.001768, loss_freq: 0.019976
[14:06:33.643] iteration 12158: loss: 0.094238, loss_s1: 0.076067, loss_fp: 0.002901, loss_freq: 0.057618
[14:06:34.265] iteration 12159: loss: 0.076315, loss_s1: 0.042242, loss_fp: 0.001086, loss_freq: 0.028180
[14:06:34.895] iteration 12160: loss: 0.088295, loss_s1: 0.077802, loss_fp: 0.000693, loss_freq: 0.056925
[14:06:35.515] iteration 12161: loss: 0.074047, loss_s1: 0.026632, loss_fp: 0.002520, loss_freq: 0.010666
[14:06:36.141] iteration 12162: loss: 0.061653, loss_s1: 0.061860, loss_fp: 0.001582, loss_freq: 0.020907
[14:06:36.770] iteration 12163: loss: 0.061189, loss_s1: 0.036132, loss_fp: 0.008519, loss_freq: 0.016047
[14:06:37.396] iteration 12164: loss: 0.079705, loss_s1: 0.037669, loss_fp: 0.001798, loss_freq: 0.043372
[14:06:38.016] iteration 12165: loss: 0.055143, loss_s1: 0.026043, loss_fp: 0.000721, loss_freq: 0.003791
[14:06:38.639] iteration 12166: loss: 0.084700, loss_s1: 0.072822, loss_fp: 0.003830, loss_freq: 0.046688
[14:06:39.266] iteration 12167: loss: 0.082209, loss_s1: 0.073866, loss_fp: 0.002623, loss_freq: 0.025867
[14:06:39.892] iteration 12168: loss: 0.105057, loss_s1: 0.063867, loss_fp: 0.001950, loss_freq: 0.029818
[14:06:40.519] iteration 12169: loss: 0.042140, loss_s1: 0.014899, loss_fp: 0.000623, loss_freq: 0.015617
[14:06:41.148] iteration 12170: loss: 0.075930, loss_s1: 0.045652, loss_fp: 0.003964, loss_freq: 0.045776
[14:06:41.769] iteration 12171: loss: 0.058338, loss_s1: 0.029403, loss_fp: 0.005440, loss_freq: 0.019289
[14:06:42.424] iteration 12172: loss: 0.073139, loss_s1: 0.022356, loss_fp: 0.005762, loss_freq: 0.019720
[14:06:43.078] iteration 12173: loss: 0.090003, loss_s1: 0.084404, loss_fp: 0.007568, loss_freq: 0.020578
[14:06:43.697] iteration 12174: loss: 0.050642, loss_s1: 0.036356, loss_fp: 0.004058, loss_freq: 0.018843
[14:06:44.320] iteration 12175: loss: 0.069717, loss_s1: 0.066576, loss_fp: 0.001808, loss_freq: 0.028671
[14:06:44.948] iteration 12176: loss: 0.104415, loss_s1: 0.019665, loss_fp: 0.002583, loss_freq: 0.071168
[14:06:45.574] iteration 12177: loss: 0.060629, loss_s1: 0.032710, loss_fp: 0.001612, loss_freq: 0.035050
[14:06:46.261] iteration 12178: loss: 0.067242, loss_s1: 0.059764, loss_fp: 0.002744, loss_freq: 0.019797
[14:06:46.982] iteration 12179: loss: 0.067647, loss_s1: 0.033627, loss_fp: 0.001017, loss_freq: 0.010102
[14:06:47.631] iteration 12180: loss: 0.052035, loss_s1: 0.032145, loss_fp: 0.002171, loss_freq: 0.018919
[14:06:48.287] iteration 12181: loss: 0.099087, loss_s1: 0.105841, loss_fp: 0.004064, loss_freq: 0.032224
[14:06:48.906] iteration 12182: loss: 0.087935, loss_s1: 0.052816, loss_fp: 0.011730, loss_freq: 0.062905
[14:06:49.528] iteration 12183: loss: 0.051096, loss_s1: 0.025366, loss_fp: 0.001774, loss_freq: 0.012789
[14:06:50.150] iteration 12184: loss: 0.097753, loss_s1: 0.040591, loss_fp: 0.004745, loss_freq: 0.024442
[14:06:50.768] iteration 12185: loss: 0.106123, loss_s1: 0.018118, loss_fp: 0.003701, loss_freq: 0.018741
[14:06:51.379] iteration 12186: loss: 0.073228, loss_s1: 0.033773, loss_fp: 0.002547, loss_freq: 0.022787
[14:06:52.000] iteration 12187: loss: 0.071566, loss_s1: 0.017604, loss_fp: 0.009660, loss_freq: 0.040165
[14:06:52.623] iteration 12188: loss: 0.088615, loss_s1: 0.074191, loss_fp: 0.011278, loss_freq: 0.038593
[14:06:53.245] iteration 12189: loss: 0.081793, loss_s1: 0.063617, loss_fp: 0.010359, loss_freq: 0.043613
[14:06:53.875] iteration 12190: loss: 0.098591, loss_s1: 0.068044, loss_fp: 0.007938, loss_freq: 0.022972
[14:06:54.504] iteration 12191: loss: 0.104024, loss_s1: 0.082117, loss_fp: 0.002572, loss_freq: 0.036975
[14:06:55.152] iteration 12192: loss: 0.098983, loss_s1: 0.085039, loss_fp: 0.001676, loss_freq: 0.054708
[14:06:55.797] iteration 12193: loss: 0.074809, loss_s1: 0.065679, loss_fp: 0.004784, loss_freq: 0.019874
[14:06:56.437] iteration 12194: loss: 0.078548, loss_s1: 0.037732, loss_fp: 0.005873, loss_freq: 0.034881
[14:06:57.080] iteration 12195: loss: 0.074155, loss_s1: 0.053733, loss_fp: 0.009141, loss_freq: 0.016843
[14:06:57.722] iteration 12196: loss: 0.078401, loss_s1: 0.037112, loss_fp: 0.003735, loss_freq: 0.032218
[14:06:58.364] iteration 12197: loss: 0.045817, loss_s1: 0.041191, loss_fp: 0.005476, loss_freq: 0.004276
[14:06:59.008] iteration 12198: loss: 0.077797, loss_s1: 0.032708, loss_fp: 0.002967, loss_freq: 0.011727
[14:06:59.647] iteration 12199: loss: 0.086221, loss_s1: 0.053507, loss_fp: 0.017831, loss_freq: 0.044553
[14:07:00.324] iteration 12200: loss: 0.091978, loss_s1: 0.029782, loss_fp: 0.001082, loss_freq: 0.040549
[14:07:03.693] iteration 12200 : mean_dice : 0.761517
[14:07:04.406] iteration 12201: loss: 0.103185, loss_s1: 0.083279, loss_fp: 0.005032, loss_freq: 0.026718
[14:07:05.032] iteration 12202: loss: 0.076174, loss_s1: 0.056451, loss_fp: 0.002166, loss_freq: 0.032357
[14:07:05.662] iteration 12203: loss: 0.042779, loss_s1: 0.011744, loss_fp: 0.000690, loss_freq: 0.018534
[14:07:06.290] iteration 12204: loss: 0.086552, loss_s1: 0.084354, loss_fp: 0.007394, loss_freq: 0.039587
[14:07:06.919] iteration 12205: loss: 0.070151, loss_s1: 0.039549, loss_fp: 0.002155, loss_freq: 0.016677
[14:07:07.549] iteration 12206: loss: 0.045222, loss_s1: 0.024573, loss_fp: 0.001088, loss_freq: 0.010333
[14:07:08.186] iteration 12207: loss: 0.124381, loss_s1: 0.024237, loss_fp: 0.004845, loss_freq: 0.033713
[14:07:08.806] iteration 12208: loss: 0.038129, loss_s1: 0.015705, loss_fp: 0.000325, loss_freq: 0.015095
[14:07:09.440] iteration 12209: loss: 0.044501, loss_s1: 0.017236, loss_fp: 0.005608, loss_freq: 0.019482
[14:07:10.063] iteration 12210: loss: 0.033532, loss_s1: 0.008279, loss_fp: 0.002438, loss_freq: 0.006290
[14:07:10.699] iteration 12211: loss: 0.124165, loss_s1: 0.036507, loss_fp: 0.001814, loss_freq: 0.017514
[14:07:11.329] iteration 12212: loss: 0.050318, loss_s1: 0.015911, loss_fp: 0.001883, loss_freq: 0.009610
[14:07:11.953] iteration 12213: loss: 0.055407, loss_s1: 0.025572, loss_fp: 0.002995, loss_freq: 0.023005
[14:07:12.583] iteration 12214: loss: 0.084142, loss_s1: 0.041683, loss_fp: 0.002024, loss_freq: 0.035236
[14:07:13.211] iteration 12215: loss: 0.043590, loss_s1: 0.017626, loss_fp: 0.007089, loss_freq: 0.017483
[14:07:13.847] iteration 12216: loss: 0.046786, loss_s1: 0.020579, loss_fp: 0.003553, loss_freq: 0.020207
[14:07:14.478] iteration 12217: loss: 0.063910, loss_s1: 0.033802, loss_fp: 0.000977, loss_freq: 0.018147
[14:07:15.100] iteration 12218: loss: 0.093329, loss_s1: 0.106219, loss_fp: 0.001494, loss_freq: 0.014992
[14:07:15.783] iteration 12219: loss: 0.073584, loss_s1: 0.037055, loss_fp: 0.002703, loss_freq: 0.029234
[14:07:16.442] iteration 12220: loss: 0.070488, loss_s1: 0.058499, loss_fp: 0.004942, loss_freq: 0.022805
[14:07:17.105] iteration 12221: loss: 0.040046, loss_s1: 0.022582, loss_fp: 0.002239, loss_freq: 0.006017
[14:07:17.764] iteration 12222: loss: 0.074230, loss_s1: 0.037695, loss_fp: 0.017566, loss_freq: 0.033903
[14:07:18.414] iteration 12223: loss: 0.052407, loss_s1: 0.036131, loss_fp: 0.001833, loss_freq: 0.021799
[14:07:19.046] iteration 12224: loss: 0.055338, loss_s1: 0.038163, loss_fp: 0.002528, loss_freq: 0.005916
[14:07:19.684] iteration 12225: loss: 0.080734, loss_s1: 0.032386, loss_fp: 0.001708, loss_freq: 0.032763
[14:07:20.314] iteration 12226: loss: 0.088135, loss_s1: 0.032135, loss_fp: 0.001139, loss_freq: 0.033537
[14:07:20.939] iteration 12227: loss: 0.058465, loss_s1: 0.026084, loss_fp: 0.005055, loss_freq: 0.028774
[14:07:21.604] iteration 12228: loss: 0.070432, loss_s1: 0.025932, loss_fp: 0.005401, loss_freq: 0.049618
[14:07:22.259] iteration 12229: loss: 0.080198, loss_s1: 0.055199, loss_fp: 0.004944, loss_freq: 0.026088
[14:07:22.924] iteration 12230: loss: 0.079557, loss_s1: 0.056136, loss_fp: 0.004888, loss_freq: 0.041948
[14:07:23.579] iteration 12231: loss: 0.069646, loss_s1: 0.038190, loss_fp: 0.003295, loss_freq: 0.014598
[14:07:24.207] iteration 12232: loss: 0.055029, loss_s1: 0.015675, loss_fp: 0.001536, loss_freq: 0.025575
[14:07:24.883] iteration 12233: loss: 0.053364, loss_s1: 0.028159, loss_fp: 0.002530, loss_freq: 0.012979
[14:07:25.545] iteration 12234: loss: 0.075363, loss_s1: 0.065021, loss_fp: 0.003499, loss_freq: 0.022892
[14:07:26.235] iteration 12235: loss: 0.080988, loss_s1: 0.032844, loss_fp: 0.005066, loss_freq: 0.017996
[14:07:26.902] iteration 12236: loss: 0.092084, loss_s1: 0.023501, loss_fp: 0.001511, loss_freq: 0.042778
[14:07:27.560] iteration 12237: loss: 0.081965, loss_s1: 0.045884, loss_fp: 0.003632, loss_freq: 0.030836
[14:07:28.211] iteration 12238: loss: 0.056916, loss_s1: 0.015965, loss_fp: 0.000940, loss_freq: 0.030671
[14:07:28.887] iteration 12239: loss: 0.052614, loss_s1: 0.024805, loss_fp: 0.005241, loss_freq: 0.028703
[14:07:29.511] iteration 12240: loss: 0.051936, loss_s1: 0.019000, loss_fp: 0.003469, loss_freq: 0.017147
[14:07:30.131] iteration 12241: loss: 0.081696, loss_s1: 0.046870, loss_fp: 0.005770, loss_freq: 0.048209
[14:07:30.765] iteration 12242: loss: 0.124826, loss_s1: 0.039437, loss_fp: 0.000955, loss_freq: 0.010288
[14:07:31.397] iteration 12243: loss: 0.065139, loss_s1: 0.015342, loss_fp: 0.000432, loss_freq: 0.046900
[14:07:32.034] iteration 12244: loss: 0.055479, loss_s1: 0.041101, loss_fp: 0.002959, loss_freq: 0.014467
[14:07:32.692] iteration 12245: loss: 0.097340, loss_s1: 0.115632, loss_fp: 0.003867, loss_freq: 0.022974
[14:07:33.354] iteration 12246: loss: 0.078657, loss_s1: 0.053081, loss_fp: 0.002529, loss_freq: 0.012273
[14:07:34.012] iteration 12247: loss: 0.063199, loss_s1: 0.053775, loss_fp: 0.002779, loss_freq: 0.030854
[14:07:34.690] iteration 12248: loss: 0.060007, loss_s1: 0.037893, loss_fp: 0.002255, loss_freq: 0.016082
[14:07:35.320] iteration 12249: loss: 0.079987, loss_s1: 0.064119, loss_fp: 0.005642, loss_freq: 0.019803
[14:07:35.953] iteration 12250: loss: 0.056862, loss_s1: 0.008789, loss_fp: 0.001905, loss_freq: 0.053242
[14:07:36.612] iteration 12251: loss: 0.067671, loss_s1: 0.046301, loss_fp: 0.002619, loss_freq: 0.023939
[14:07:37.287] iteration 12252: loss: 0.112169, loss_s1: 0.051727, loss_fp: 0.000898, loss_freq: 0.106939
[14:07:37.949] iteration 12253: loss: 0.039601, loss_s1: 0.017301, loss_fp: 0.001472, loss_freq: 0.011913
[14:07:38.599] iteration 12254: loss: 0.072474, loss_s1: 0.051218, loss_fp: 0.004581, loss_freq: 0.023763
[14:07:39.220] iteration 12255: loss: 0.058857, loss_s1: 0.030539, loss_fp: 0.001723, loss_freq: 0.026065
[14:07:39.852] iteration 12256: loss: 0.071301, loss_s1: 0.048026, loss_fp: 0.001652, loss_freq: 0.037209
[14:07:40.484] iteration 12257: loss: 0.060929, loss_s1: 0.031482, loss_fp: 0.001127, loss_freq: 0.026093
[14:07:41.114] iteration 12258: loss: 0.082498, loss_s1: 0.096937, loss_fp: 0.003840, loss_freq: 0.020046
[14:07:41.745] iteration 12259: loss: 0.059012, loss_s1: 0.054309, loss_fp: 0.000976, loss_freq: 0.015653
[14:07:42.383] iteration 12260: loss: 0.057074, loss_s1: 0.024228, loss_fp: 0.001412, loss_freq: 0.029728
[14:07:43.004] iteration 12261: loss: 0.040719, loss_s1: 0.011851, loss_fp: 0.002283, loss_freq: 0.018762
[14:07:43.633] iteration 12262: loss: 0.134005, loss_s1: 0.135543, loss_fp: 0.001027, loss_freq: 0.070574
[14:07:44.263] iteration 12263: loss: 0.090790, loss_s1: 0.067752, loss_fp: 0.005651, loss_freq: 0.047472
[14:07:44.890] iteration 12264: loss: 0.093512, loss_s1: 0.029194, loss_fp: 0.000758, loss_freq: 0.020653
[14:07:45.518] iteration 12265: loss: 0.106799, loss_s1: 0.062044, loss_fp: 0.004213, loss_freq: 0.082305
[14:07:46.146] iteration 12266: loss: 0.098646, loss_s1: 0.079858, loss_fp: 0.005243, loss_freq: 0.008004
[14:07:46.759] iteration 12267: loss: 0.043435, loss_s1: 0.031883, loss_fp: 0.001329, loss_freq: 0.018949
[14:07:47.380] iteration 12268: loss: 0.059175, loss_s1: 0.027796, loss_fp: 0.002811, loss_freq: 0.018651
[14:07:48.011] iteration 12269: loss: 0.058365, loss_s1: 0.030146, loss_fp: 0.003597, loss_freq: 0.035183
[14:07:48.643] iteration 12270: loss: 0.134071, loss_s1: 0.090555, loss_fp: 0.006801, loss_freq: 0.036279
[14:07:49.272] iteration 12271: loss: 0.067739, loss_s1: 0.020901, loss_fp: 0.003412, loss_freq: 0.027747
[14:07:49.890] iteration 12272: loss: 0.063900, loss_s1: 0.023434, loss_fp: 0.002225, loss_freq: 0.051615
[14:07:50.523] iteration 12273: loss: 0.108263, loss_s1: 0.091407, loss_fp: 0.001761, loss_freq: 0.072302
[14:07:51.157] iteration 12274: loss: 0.057939, loss_s1: 0.049093, loss_fp: 0.001195, loss_freq: 0.021828
[14:07:51.817] iteration 12275: loss: 0.078341, loss_s1: 0.040851, loss_fp: 0.002708, loss_freq: 0.046422
[14:07:52.449] iteration 12276: loss: 0.098148, loss_s1: 0.035714, loss_fp: 0.008586, loss_freq: 0.092372
[14:07:53.097] iteration 12277: loss: 0.069513, loss_s1: 0.056648, loss_fp: 0.003500, loss_freq: 0.026431
[14:07:53.739] iteration 12278: loss: 0.068265, loss_s1: 0.032102, loss_fp: 0.006214, loss_freq: 0.019341
[14:07:54.384] iteration 12279: loss: 0.084677, loss_s1: 0.040239, loss_fp: 0.009668, loss_freq: 0.024787
[14:07:55.029] iteration 12280: loss: 0.068556, loss_s1: 0.058260, loss_fp: 0.000756, loss_freq: 0.012896
[14:07:55.672] iteration 12281: loss: 0.069175, loss_s1: 0.016144, loss_fp: 0.000954, loss_freq: 0.029250
[14:07:56.316] iteration 12282: loss: 0.109030, loss_s1: 0.048831, loss_fp: 0.002889, loss_freq: 0.067226
[14:07:56.967] iteration 12283: loss: 0.087535, loss_s1: 0.075435, loss_fp: 0.002957, loss_freq: 0.013603
[14:07:57.612] iteration 12284: loss: 0.114879, loss_s1: 0.099240, loss_fp: 0.005475, loss_freq: 0.039430
[14:07:58.254] iteration 12285: loss: 0.057750, loss_s1: 0.025510, loss_fp: 0.001475, loss_freq: 0.016828
[14:07:58.885] iteration 12286: loss: 0.054035, loss_s1: 0.044782, loss_fp: 0.001569, loss_freq: 0.008745
[14:07:59.508] iteration 12287: loss: 0.095888, loss_s1: 0.079904, loss_fp: 0.004169, loss_freq: 0.036340
[14:08:00.122] iteration 12288: loss: 0.061377, loss_s1: 0.023596, loss_fp: 0.003050, loss_freq: 0.023951
[14:08:00.742] iteration 12289: loss: 0.100126, loss_s1: 0.070083, loss_fp: 0.005512, loss_freq: 0.043820
[14:08:01.367] iteration 12290: loss: 0.073716, loss_s1: 0.034168, loss_fp: 0.001869, loss_freq: 0.019501
[14:08:01.992] iteration 12291: loss: 0.076252, loss_s1: 0.053523, loss_fp: 0.001424, loss_freq: 0.028278
[14:08:02.634] iteration 12292: loss: 0.079210, loss_s1: 0.080467, loss_fp: 0.006740, loss_freq: 0.015115
[14:08:03.304] iteration 12293: loss: 0.068916, loss_s1: 0.033552, loss_fp: 0.000548, loss_freq: 0.013078
[14:08:03.961] iteration 12294: loss: 0.061999, loss_s1: 0.046437, loss_fp: 0.003132, loss_freq: 0.025662
[14:08:04.618] iteration 12295: loss: 0.116188, loss_s1: 0.036936, loss_fp: 0.006598, loss_freq: 0.028400
[14:08:05.248] iteration 12296: loss: 0.067644, loss_s1: 0.039459, loss_fp: 0.011834, loss_freq: 0.016350
[14:08:05.862] iteration 12297: loss: 0.092502, loss_s1: 0.067542, loss_fp: 0.006501, loss_freq: 0.048670
[14:08:06.478] iteration 12298: loss: 0.061792, loss_s1: 0.043365, loss_fp: 0.001089, loss_freq: 0.031864
[14:08:07.468] iteration 12299: loss: 0.051050, loss_s1: 0.033156, loss_fp: 0.004506, loss_freq: 0.017323
[14:08:08.121] iteration 12300: loss: 0.087476, loss_s1: 0.061784, loss_fp: 0.001150, loss_freq: 0.053418
[14:08:08.781] iteration 12301: loss: 0.064091, loss_s1: 0.048159, loss_fp: 0.000343, loss_freq: 0.034714
[14:08:09.435] iteration 12302: loss: 0.060215, loss_s1: 0.031671, loss_fp: 0.003754, loss_freq: 0.015173
[14:08:10.099] iteration 12303: loss: 0.111466, loss_s1: 0.080766, loss_fp: 0.004153, loss_freq: 0.085561
[14:08:10.736] iteration 12304: loss: 0.061562, loss_s1: 0.012442, loss_fp: 0.001288, loss_freq: 0.009072
[14:08:11.367] iteration 12305: loss: 0.044628, loss_s1: 0.030839, loss_fp: 0.001238, loss_freq: 0.017148
[14:08:12.009] iteration 12306: loss: 0.142095, loss_s1: 0.148912, loss_fp: 0.024485, loss_freq: 0.023391
[14:08:12.665] iteration 12307: loss: 0.091956, loss_s1: 0.060956, loss_fp: 0.006305, loss_freq: 0.029226
[14:08:13.324] iteration 12308: loss: 0.069711, loss_s1: 0.027756, loss_fp: 0.003406, loss_freq: 0.010843
[14:08:13.992] iteration 12309: loss: 0.094734, loss_s1: 0.076358, loss_fp: 0.004575, loss_freq: 0.049583
[14:08:14.671] iteration 12310: loss: 0.067574, loss_s1: 0.045051, loss_fp: 0.001916, loss_freq: 0.018813
[14:08:15.328] iteration 12311: loss: 0.046638, loss_s1: 0.026488, loss_fp: 0.000705, loss_freq: 0.011895
[14:08:15.990] iteration 12312: loss: 0.045199, loss_s1: 0.023917, loss_fp: 0.001451, loss_freq: 0.015689
[14:08:16.658] iteration 12313: loss: 0.078060, loss_s1: 0.077308, loss_fp: 0.000946, loss_freq: 0.032104
[14:08:17.291] iteration 12314: loss: 0.045731, loss_s1: 0.011699, loss_fp: 0.001070, loss_freq: 0.016390
[14:08:17.920] iteration 12315: loss: 0.113228, loss_s1: 0.040010, loss_fp: 0.001011, loss_freq: 0.028995
[14:08:18.543] iteration 12316: loss: 0.098171, loss_s1: 0.036097, loss_fp: 0.002099, loss_freq: 0.030502
[14:08:19.171] iteration 12317: loss: 0.048581, loss_s1: 0.024939, loss_fp: 0.005991, loss_freq: 0.025792
[14:08:19.820] iteration 12318: loss: 0.036977, loss_s1: 0.022098, loss_fp: 0.001899, loss_freq: 0.010796
[14:08:20.483] iteration 12319: loss: 0.125098, loss_s1: 0.021473, loss_fp: 0.002099, loss_freq: 0.051272
[14:08:21.172] iteration 12320: loss: 0.082712, loss_s1: 0.079679, loss_fp: 0.000968, loss_freq: 0.025277
[14:08:21.842] iteration 12321: loss: 0.046602, loss_s1: 0.021905, loss_fp: 0.005945, loss_freq: 0.011728
[14:08:22.517] iteration 12322: loss: 0.066575, loss_s1: 0.054562, loss_fp: 0.003304, loss_freq: 0.008462
[14:08:23.189] iteration 12323: loss: 0.053431, loss_s1: 0.039412, loss_fp: 0.004192, loss_freq: 0.009596
[14:08:23.911] iteration 12324: loss: 0.067765, loss_s1: 0.040181, loss_fp: 0.005675, loss_freq: 0.036704
[14:08:24.563] iteration 12325: loss: 0.098981, loss_s1: 0.059662, loss_fp: 0.006778, loss_freq: 0.058988
[14:08:25.225] iteration 12326: loss: 0.069778, loss_s1: 0.039385, loss_fp: 0.001959, loss_freq: 0.039546
[14:08:25.878] iteration 12327: loss: 0.111323, loss_s1: 0.044601, loss_fp: 0.002067, loss_freq: 0.085496
[14:08:26.543] iteration 12328: loss: 0.066629, loss_s1: 0.016812, loss_fp: 0.005775, loss_freq: 0.007308
[14:08:27.196] iteration 12329: loss: 0.048688, loss_s1: 0.024098, loss_fp: 0.004996, loss_freq: 0.005296
[14:08:27.859] iteration 12330: loss: 0.054245, loss_s1: 0.026972, loss_fp: 0.003149, loss_freq: 0.021116
[14:08:28.515] iteration 12331: loss: 0.071590, loss_s1: 0.079095, loss_fp: 0.003357, loss_freq: 0.020554
[14:08:29.175] iteration 12332: loss: 0.059991, loss_s1: 0.039772, loss_fp: 0.001399, loss_freq: 0.028654
[14:08:29.830] iteration 12333: loss: 0.087917, loss_s1: 0.074018, loss_fp: 0.003997, loss_freq: 0.026605
[14:08:30.490] iteration 12334: loss: 0.085783, loss_s1: 0.046771, loss_fp: 0.001480, loss_freq: 0.068147
[14:08:31.142] iteration 12335: loss: 0.061398, loss_s1: 0.031320, loss_fp: 0.019142, loss_freq: 0.023937
[14:08:31.801] iteration 12336: loss: 0.053772, loss_s1: 0.029615, loss_fp: 0.005974, loss_freq: 0.024883
[14:08:32.425] iteration 12337: loss: 0.085415, loss_s1: 0.052633, loss_fp: 0.009118, loss_freq: 0.028314
[14:08:33.115] iteration 12338: loss: 0.044464, loss_s1: 0.030447, loss_fp: 0.004028, loss_freq: 0.011313
[14:08:33.755] iteration 12339: loss: 0.082742, loss_s1: 0.040714, loss_fp: 0.005705, loss_freq: 0.043314
[14:08:34.420] iteration 12340: loss: 0.037215, loss_s1: 0.008593, loss_fp: 0.002835, loss_freq: 0.025393
[14:08:35.092] iteration 12341: loss: 0.051255, loss_s1: 0.025506, loss_fp: 0.002676, loss_freq: 0.013594
[14:08:35.744] iteration 12342: loss: 0.122702, loss_s1: 0.109894, loss_fp: 0.010831, loss_freq: 0.066042
[14:08:36.408] iteration 12343: loss: 0.057072, loss_s1: 0.025504, loss_fp: 0.001181, loss_freq: 0.014700
[14:08:37.068] iteration 12344: loss: 0.082541, loss_s1: 0.063614, loss_fp: 0.002631, loss_freq: 0.037137
[14:08:37.698] iteration 12345: loss: 0.066230, loss_s1: 0.043937, loss_fp: 0.002011, loss_freq: 0.036291
[14:08:38.327] iteration 12346: loss: 0.081725, loss_s1: 0.030219, loss_fp: 0.006822, loss_freq: 0.037228
[14:08:39.010] iteration 12347: loss: 0.080804, loss_s1: 0.036103, loss_fp: 0.003194, loss_freq: 0.025329
[14:08:39.635] iteration 12348: loss: 0.070380, loss_s1: 0.051872, loss_fp: 0.003118, loss_freq: 0.018749
[14:08:40.255] iteration 12349: loss: 0.063591, loss_s1: 0.019608, loss_fp: 0.008614, loss_freq: 0.044604
[14:08:40.880] iteration 12350: loss: 0.142565, loss_s1: 0.035072, loss_fp: 0.004711, loss_freq: 0.033082
[14:08:41.511] iteration 12351: loss: 0.053514, loss_s1: 0.029256, loss_fp: 0.004727, loss_freq: 0.010587
[14:08:42.144] iteration 12352: loss: 0.045498, loss_s1: 0.031584, loss_fp: 0.002697, loss_freq: 0.014653
[14:08:42.774] iteration 12353: loss: 0.050984, loss_s1: 0.043078, loss_fp: 0.001523, loss_freq: 0.005226
[14:08:43.393] iteration 12354: loss: 0.084443, loss_s1: 0.036653, loss_fp: 0.001547, loss_freq: 0.011331
[14:08:44.014] iteration 12355: loss: 0.081295, loss_s1: 0.036048, loss_fp: 0.005374, loss_freq: 0.020676
[14:08:44.680] iteration 12356: loss: 0.076790, loss_s1: 0.055627, loss_fp: 0.001291, loss_freq: 0.032508
[14:08:45.335] iteration 12357: loss: 0.107772, loss_s1: 0.046845, loss_fp: 0.003363, loss_freq: 0.088324
[14:08:45.991] iteration 12358: loss: 0.058670, loss_s1: 0.028848, loss_fp: 0.001831, loss_freq: 0.015717
[14:08:46.649] iteration 12359: loss: 0.086365, loss_s1: 0.031563, loss_fp: 0.003751, loss_freq: 0.022558
[14:08:47.307] iteration 12360: loss: 0.083791, loss_s1: 0.036224, loss_fp: 0.005367, loss_freq: 0.016985
[14:08:47.961] iteration 12361: loss: 0.067816, loss_s1: 0.044719, loss_fp: 0.010267, loss_freq: 0.012317
[14:08:48.626] iteration 12362: loss: 0.062603, loss_s1: 0.023947, loss_fp: 0.003948, loss_freq: 0.030411
[14:08:49.287] iteration 12363: loss: 0.109596, loss_s1: 0.031623, loss_fp: 0.001530, loss_freq: 0.116814
[14:08:50.067] iteration 12364: loss: 0.061994, loss_s1: 0.006787, loss_fp: 0.002814, loss_freq: 0.052295
[14:08:50.732] iteration 12365: loss: 0.152740, loss_s1: 0.060826, loss_fp: 0.011428, loss_freq: 0.051480
[14:08:51.489] iteration 12366: loss: 0.047206, loss_s1: 0.030500, loss_fp: 0.001165, loss_freq: 0.023515
[14:08:52.159] iteration 12367: loss: 0.084680, loss_s1: 0.067935, loss_fp: 0.002293, loss_freq: 0.036706
[14:08:52.818] iteration 12368: loss: 0.048749, loss_s1: 0.011153, loss_fp: 0.000827, loss_freq: 0.027492
[14:08:53.456] iteration 12369: loss: 0.072535, loss_s1: 0.065957, loss_fp: 0.003310, loss_freq: 0.024799
[14:08:54.099] iteration 12370: loss: 0.089138, loss_s1: 0.074222, loss_fp: 0.003339, loss_freq: 0.030568
[14:08:54.732] iteration 12371: loss: 0.085628, loss_s1: 0.054409, loss_fp: 0.002702, loss_freq: 0.074877
[14:08:55.367] iteration 12372: loss: 0.085712, loss_s1: 0.042329, loss_fp: 0.005761, loss_freq: 0.055834
[14:08:55.999] iteration 12373: loss: 0.073359, loss_s1: 0.043222, loss_fp: 0.000984, loss_freq: 0.025901
[14:08:56.626] iteration 12374: loss: 0.086355, loss_s1: 0.033637, loss_fp: 0.000846, loss_freq: 0.005650
[14:08:57.256] iteration 12375: loss: 0.111817, loss_s1: 0.052541, loss_fp: 0.002886, loss_freq: 0.058677
[14:08:57.894] iteration 12376: loss: 0.085946, loss_s1: 0.025976, loss_fp: 0.002156, loss_freq: 0.007937
[14:08:58.522] iteration 12377: loss: 0.077112, loss_s1: 0.043650, loss_fp: 0.020502, loss_freq: 0.026628
[14:08:59.157] iteration 12378: loss: 0.115061, loss_s1: 0.035230, loss_fp: 0.001445, loss_freq: 0.020920
[14:08:59.885] iteration 12379: loss: 0.080111, loss_s1: 0.022109, loss_fp: 0.000421, loss_freq: 0.039078
[14:09:00.550] iteration 12380: loss: 0.077314, loss_s1: 0.046786, loss_fp: 0.000788, loss_freq: 0.039966
[14:09:01.201] iteration 12381: loss: 0.067185, loss_s1: 0.035881, loss_fp: 0.000618, loss_freq: 0.031594
[14:09:01.829] iteration 12382: loss: 0.056383, loss_s1: 0.041654, loss_fp: 0.001808, loss_freq: 0.023133
[14:09:02.450] iteration 12383: loss: 0.045996, loss_s1: 0.036044, loss_fp: 0.001686, loss_freq: 0.006709
[14:09:03.071] iteration 12384: loss: 0.066684, loss_s1: 0.044670, loss_fp: 0.005380, loss_freq: 0.033167
[14:09:03.692] iteration 12385: loss: 0.057819, loss_s1: 0.025308, loss_fp: 0.001671, loss_freq: 0.016014
[14:09:04.323] iteration 12386: loss: 0.064750, loss_s1: 0.038862, loss_fp: 0.000822, loss_freq: 0.020276
[14:09:04.964] iteration 12387: loss: 0.049564, loss_s1: 0.047975, loss_fp: 0.001599, loss_freq: 0.006550
[14:09:05.614] iteration 12388: loss: 0.058494, loss_s1: 0.063518, loss_fp: 0.003560, loss_freq: 0.013649
[14:09:06.268] iteration 12389: loss: 0.068772, loss_s1: 0.027686, loss_fp: 0.001087, loss_freq: 0.012463
[14:09:06.932] iteration 12390: loss: 0.078755, loss_s1: 0.082350, loss_fp: 0.001480, loss_freq: 0.033689
[14:09:07.573] iteration 12391: loss: 0.053301, loss_s1: 0.031287, loss_fp: 0.004144, loss_freq: 0.007630
[14:09:08.254] iteration 12392: loss: 0.084765, loss_s1: 0.047929, loss_fp: 0.001684, loss_freq: 0.012983
[14:09:08.905] iteration 12393: loss: 0.068345, loss_s1: 0.024602, loss_fp: 0.028618, loss_freq: 0.009853
[14:09:09.526] iteration 12394: loss: 0.049816, loss_s1: 0.036379, loss_fp: 0.001193, loss_freq: 0.008999
[14:09:10.140] iteration 12395: loss: 0.194634, loss_s1: 0.238139, loss_fp: 0.003417, loss_freq: 0.099188
[14:09:10.771] iteration 12396: loss: 0.080780, loss_s1: 0.035506, loss_fp: 0.008058, loss_freq: 0.038724
[14:09:11.396] iteration 12397: loss: 0.073104, loss_s1: 0.052298, loss_fp: 0.000822, loss_freq: 0.023031
[14:09:12.042] iteration 12398: loss: 0.081249, loss_s1: 0.031112, loss_fp: 0.003540, loss_freq: 0.052591
[14:09:12.674] iteration 12399: loss: 0.081935, loss_s1: 0.056963, loss_fp: 0.004239, loss_freq: 0.058653
[14:09:13.301] iteration 12400: loss: 0.076904, loss_s1: 0.021204, loss_fp: 0.002418, loss_freq: 0.032700
[14:09:16.569] iteration 12400 : mean_dice : 0.763145
[14:09:17.288] iteration 12401: loss: 0.055645, loss_s1: 0.040185, loss_fp: 0.002477, loss_freq: 0.019926
[14:09:17.941] iteration 12402: loss: 0.089548, loss_s1: 0.025782, loss_fp: 0.000908, loss_freq: 0.054098
[14:09:18.601] iteration 12403: loss: 0.083741, loss_s1: 0.038247, loss_fp: 0.004476, loss_freq: 0.009885
[14:09:19.260] iteration 12404: loss: 0.046057, loss_s1: 0.019164, loss_fp: 0.005493, loss_freq: 0.019667
[14:09:19.915] iteration 12405: loss: 0.107854, loss_s1: 0.096703, loss_fp: 0.001133, loss_freq: 0.048078
[14:09:20.559] iteration 12406: loss: 0.079308, loss_s1: 0.071658, loss_fp: 0.006188, loss_freq: 0.038371
[14:09:21.191] iteration 12407: loss: 0.076661, loss_s1: 0.053241, loss_fp: 0.002264, loss_freq: 0.040185
[14:09:21.816] iteration 12408: loss: 0.082669, loss_s1: 0.097646, loss_fp: 0.000855, loss_freq: 0.028207
[14:09:22.440] iteration 12409: loss: 0.086161, loss_s1: 0.033482, loss_fp: 0.004146, loss_freq: 0.021341
[14:09:23.062] iteration 12410: loss: 0.058635, loss_s1: 0.045303, loss_fp: 0.002932, loss_freq: 0.037721
[14:09:23.674] iteration 12411: loss: 0.070709, loss_s1: 0.026336, loss_fp: 0.002430, loss_freq: 0.020494
[14:09:24.290] iteration 12412: loss: 0.054926, loss_s1: 0.024540, loss_fp: 0.002823, loss_freq: 0.030638
[14:09:24.908] iteration 12413: loss: 0.108418, loss_s1: 0.070818, loss_fp: 0.000976, loss_freq: 0.033658
[14:09:25.530] iteration 12414: loss: 0.055828, loss_s1: 0.032605, loss_fp: 0.001848, loss_freq: 0.006349
[14:09:26.162] iteration 12415: loss: 0.068509, loss_s1: 0.040346, loss_fp: 0.005344, loss_freq: 0.032987
[14:09:26.795] iteration 12416: loss: 0.062501, loss_s1: 0.033597, loss_fp: 0.002370, loss_freq: 0.028909
[14:09:27.426] iteration 12417: loss: 0.050061, loss_s1: 0.041178, loss_fp: 0.001882, loss_freq: 0.012303
[14:09:28.052] iteration 12418: loss: 0.057969, loss_s1: 0.032887, loss_fp: 0.001269, loss_freq: 0.034597
[14:09:28.686] iteration 12419: loss: 0.128150, loss_s1: 0.059743, loss_fp: 0.012157, loss_freq: 0.096416
[14:09:29.330] iteration 12420: loss: 0.082958, loss_s1: 0.061979, loss_fp: 0.001686, loss_freq: 0.038860
[14:09:29.949] iteration 12421: loss: 0.032225, loss_s1: 0.004335, loss_fp: 0.001856, loss_freq: 0.010229
[14:09:30.602] iteration 12422: loss: 0.072417, loss_s1: 0.043787, loss_fp: 0.004933, loss_freq: 0.028209
[14:09:31.238] iteration 12423: loss: 0.044012, loss_s1: 0.030236, loss_fp: 0.003170, loss_freq: 0.014438
[14:09:31.883] iteration 12424: loss: 0.088233, loss_s1: 0.051566, loss_fp: 0.001752, loss_freq: 0.040850
[14:09:32.520] iteration 12425: loss: 0.083426, loss_s1: 0.028810, loss_fp: 0.008851, loss_freq: 0.049411
[14:09:33.201] iteration 12426: loss: 0.075903, loss_s1: 0.064789, loss_fp: 0.006956, loss_freq: 0.030960
[14:09:33.857] iteration 12427: loss: 0.055138, loss_s1: 0.031050, loss_fp: 0.002628, loss_freq: 0.009905
[14:09:34.512] iteration 12428: loss: 0.058496, loss_s1: 0.038406, loss_fp: 0.001962, loss_freq: 0.016579
[14:09:35.170] iteration 12429: loss: 0.035995, loss_s1: 0.011031, loss_fp: 0.004337, loss_freq: 0.002387
[14:09:35.821] iteration 12430: loss: 0.081225, loss_s1: 0.043448, loss_fp: 0.004962, loss_freq: 0.034369
[14:09:36.448] iteration 12431: loss: 0.070811, loss_s1: 0.062572, loss_fp: 0.000844, loss_freq: 0.012424
[14:09:37.095] iteration 12432: loss: 0.103602, loss_s1: 0.070241, loss_fp: 0.007458, loss_freq: 0.070887
[14:09:37.737] iteration 12433: loss: 0.096112, loss_s1: 0.061195, loss_fp: 0.003465, loss_freq: 0.022228
[14:09:38.378] iteration 12434: loss: 0.060204, loss_s1: 0.035417, loss_fp: 0.001719, loss_freq: 0.038090
[14:09:39.025] iteration 12435: loss: 0.113158, loss_s1: 0.080465, loss_fp: 0.011838, loss_freq: 0.039860
[14:09:39.645] iteration 12436: loss: 0.069530, loss_s1: 0.066627, loss_fp: 0.002100, loss_freq: 0.020725
[14:09:40.263] iteration 12437: loss: 0.058710, loss_s1: 0.026539, loss_fp: 0.001092, loss_freq: 0.037646
[14:09:40.888] iteration 12438: loss: 0.075656, loss_s1: 0.045958, loss_fp: 0.002586, loss_freq: 0.018462
[14:09:41.513] iteration 12439: loss: 0.092919, loss_s1: 0.070458, loss_fp: 0.016846, loss_freq: 0.043492
[14:09:42.134] iteration 12440: loss: 0.094689, loss_s1: 0.082679, loss_fp: 0.004696, loss_freq: 0.045519
[14:09:42.751] iteration 12441: loss: 0.054757, loss_s1: 0.039568, loss_fp: 0.003211, loss_freq: 0.025290
[14:09:43.650] iteration 12442: loss: 0.052668, loss_s1: 0.044829, loss_fp: 0.002579, loss_freq: 0.006906
[14:09:44.299] iteration 12443: loss: 0.051360, loss_s1: 0.016590, loss_fp: 0.002571, loss_freq: 0.034067
[14:09:44.930] iteration 12444: loss: 0.063373, loss_s1: 0.039566, loss_fp: 0.002175, loss_freq: 0.036500
[14:09:45.553] iteration 12445: loss: 0.055745, loss_s1: 0.013261, loss_fp: 0.001149, loss_freq: 0.042365
[14:09:46.175] iteration 12446: loss: 0.065532, loss_s1: 0.032068, loss_fp: 0.001518, loss_freq: 0.056834
[14:09:46.797] iteration 12447: loss: 0.088293, loss_s1: 0.023370, loss_fp: 0.001342, loss_freq: 0.002489
[14:09:47.421] iteration 12448: loss: 0.035788, loss_s1: 0.018404, loss_fp: 0.002041, loss_freq: 0.016790
[14:09:48.049] iteration 12449: loss: 0.115822, loss_s1: 0.055973, loss_fp: 0.006909, loss_freq: 0.037893
[14:09:48.671] iteration 12450: loss: 0.100699, loss_s1: 0.099431, loss_fp: 0.003166, loss_freq: 0.041075
[14:09:49.292] iteration 12451: loss: 0.047000, loss_s1: 0.012414, loss_fp: 0.001034, loss_freq: 0.005528
[14:09:49.916] iteration 12452: loss: 0.071071, loss_s1: 0.028593, loss_fp: 0.006029, loss_freq: 0.044267
[14:09:50.538] iteration 12453: loss: 0.055751, loss_s1: 0.037871, loss_fp: 0.002096, loss_freq: 0.022765
[14:09:51.154] iteration 12454: loss: 0.076438, loss_s1: 0.056157, loss_fp: 0.003269, loss_freq: 0.017650
[14:09:51.773] iteration 12455: loss: 0.033436, loss_s1: 0.021719, loss_fp: 0.001570, loss_freq: 0.005772
[14:09:52.395] iteration 12456: loss: 0.061164, loss_s1: 0.028927, loss_fp: 0.000796, loss_freq: 0.028613
[14:09:53.012] iteration 12457: loss: 0.059733, loss_s1: 0.042085, loss_fp: 0.000953, loss_freq: 0.015482
[14:09:53.629] iteration 12458: loss: 0.097316, loss_s1: 0.017096, loss_fp: 0.001549, loss_freq: 0.024297
[14:09:54.257] iteration 12459: loss: 0.077227, loss_s1: 0.046759, loss_fp: 0.005062, loss_freq: 0.013468
[14:09:54.884] iteration 12460: loss: 0.058927, loss_s1: 0.029665, loss_fp: 0.005657, loss_freq: 0.040921
[14:09:55.506] iteration 12461: loss: 0.053216, loss_s1: 0.028158, loss_fp: 0.002783, loss_freq: 0.026770
[14:09:56.153] iteration 12462: loss: 0.106062, loss_s1: 0.058172, loss_fp: 0.001262, loss_freq: 0.065996
[14:09:56.814] iteration 12463: loss: 0.048484, loss_s1: 0.025048, loss_fp: 0.002169, loss_freq: 0.022776
[14:09:57.473] iteration 12464: loss: 0.059288, loss_s1: 0.028519, loss_fp: 0.001012, loss_freq: 0.033356
[14:09:58.146] iteration 12465: loss: 0.080457, loss_s1: 0.057072, loss_fp: 0.000513, loss_freq: 0.014070
[14:09:58.772] iteration 12466: loss: 0.064397, loss_s1: 0.032272, loss_fp: 0.001236, loss_freq: 0.033240
[14:09:59.403] iteration 12467: loss: 0.083536, loss_s1: 0.041765, loss_fp: 0.012741, loss_freq: 0.025336
[14:10:00.043] iteration 12468: loss: 0.086379, loss_s1: 0.049802, loss_fp: 0.001086, loss_freq: 0.052573
[14:10:00.675] iteration 12469: loss: 0.081740, loss_s1: 0.049551, loss_fp: 0.003253, loss_freq: 0.026608
[14:10:01.304] iteration 12470: loss: 0.082905, loss_s1: 0.060844, loss_fp: 0.002015, loss_freq: 0.028809
[14:10:01.924] iteration 12471: loss: 0.059841, loss_s1: 0.047213, loss_fp: 0.002159, loss_freq: 0.011233
[14:10:02.546] iteration 12472: loss: 0.049495, loss_s1: 0.028478, loss_fp: 0.002354, loss_freq: 0.015497
[14:10:03.180] iteration 12473: loss: 0.086090, loss_s1: 0.045651, loss_fp: 0.002822, loss_freq: 0.024495
[14:10:03.806] iteration 12474: loss: 0.101763, loss_s1: 0.100237, loss_fp: 0.008018, loss_freq: 0.054303
[14:10:04.427] iteration 12475: loss: 0.124280, loss_s1: 0.077696, loss_fp: 0.008918, loss_freq: 0.079983
[14:10:05.048] iteration 12476: loss: 0.094965, loss_s1: 0.029089, loss_fp: 0.001543, loss_freq: 0.048356
[14:10:05.675] iteration 12477: loss: 0.076460, loss_s1: 0.068810, loss_fp: 0.002032, loss_freq: 0.025096
[14:10:06.308] iteration 12478: loss: 0.101356, loss_s1: 0.054733, loss_fp: 0.022223, loss_freq: 0.036569
[14:10:06.935] iteration 12479: loss: 0.049277, loss_s1: 0.035911, loss_fp: 0.000778, loss_freq: 0.019175
[14:10:07.566] iteration 12480: loss: 0.102910, loss_s1: 0.039710, loss_fp: 0.003301, loss_freq: 0.058405
[14:10:08.196] iteration 12481: loss: 0.075997, loss_s1: 0.049253, loss_fp: 0.001364, loss_freq: 0.005457
[14:10:08.852] iteration 12482: loss: 0.082141, loss_s1: 0.049275, loss_fp: 0.008476, loss_freq: 0.011757
[14:10:09.484] iteration 12483: loss: 0.052277, loss_s1: 0.025417, loss_fp: 0.002386, loss_freq: 0.025522
[14:10:10.114] iteration 12484: loss: 0.069654, loss_s1: 0.032983, loss_fp: 0.000863, loss_freq: 0.022888
[14:10:10.741] iteration 12485: loss: 0.073129, loss_s1: 0.059483, loss_fp: 0.000958, loss_freq: 0.042892
[14:10:11.371] iteration 12486: loss: 0.119444, loss_s1: 0.035521, loss_fp: 0.002066, loss_freq: 0.006821
[14:10:12.008] iteration 12487: loss: 0.094467, loss_s1: 0.062813, loss_fp: 0.001802, loss_freq: 0.017414
[14:10:12.632] iteration 12488: loss: 0.058258, loss_s1: 0.038150, loss_fp: 0.001632, loss_freq: 0.024282
[14:10:13.298] iteration 12489: loss: 0.084212, loss_s1: 0.039263, loss_fp: 0.001636, loss_freq: 0.010652
[14:10:13.922] iteration 12490: loss: 0.067247, loss_s1: 0.059024, loss_fp: 0.009500, loss_freq: 0.015370
[14:10:14.548] iteration 12491: loss: 0.058185, loss_s1: 0.044578, loss_fp: 0.002266, loss_freq: 0.016056
[14:10:15.172] iteration 12492: loss: 0.105112, loss_s1: 0.071030, loss_fp: 0.001367, loss_freq: 0.022982
[14:10:15.801] iteration 12493: loss: 0.082942, loss_s1: 0.051660, loss_fp: 0.002324, loss_freq: 0.049883
[14:10:16.428] iteration 12494: loss: 0.039670, loss_s1: 0.021692, loss_fp: 0.000839, loss_freq: 0.010222
[14:10:17.060] iteration 12495: loss: 0.052432, loss_s1: 0.039657, loss_fp: 0.002097, loss_freq: 0.013539
[14:10:17.683] iteration 12496: loss: 0.040304, loss_s1: 0.016522, loss_fp: 0.003126, loss_freq: 0.016706
[14:10:18.356] iteration 12497: loss: 0.068693, loss_s1: 0.033953, loss_fp: 0.000941, loss_freq: 0.021748
[14:10:19.015] iteration 12498: loss: 0.072751, loss_s1: 0.055666, loss_fp: 0.005443, loss_freq: 0.032219
[14:10:19.673] iteration 12499: loss: 0.084497, loss_s1: 0.053503, loss_fp: 0.000662, loss_freq: 0.054629
[14:10:20.324] iteration 12500: loss: 0.091515, loss_s1: 0.066670, loss_fp: 0.006888, loss_freq: 0.060435
[14:10:20.949] iteration 12501: loss: 0.061598, loss_s1: 0.025060, loss_fp: 0.001507, loss_freq: 0.047754
[14:10:21.579] iteration 12502: loss: 0.069048, loss_s1: 0.032947, loss_fp: 0.001632, loss_freq: 0.014140
[14:10:22.237] iteration 12503: loss: 0.069845, loss_s1: 0.035582, loss_fp: 0.006984, loss_freq: 0.016166
[14:10:22.867] iteration 12504: loss: 0.104242, loss_s1: 0.043087, loss_fp: 0.000605, loss_freq: 0.097654
[14:10:23.496] iteration 12505: loss: 0.081099, loss_s1: 0.049449, loss_fp: 0.000999, loss_freq: 0.021239
[14:10:24.133] iteration 12506: loss: 0.077435, loss_s1: 0.040267, loss_fp: 0.016786, loss_freq: 0.029361
[14:10:24.770] iteration 12507: loss: 0.093746, loss_s1: 0.032423, loss_fp: 0.002072, loss_freq: 0.029319
[14:10:25.403] iteration 12508: loss: 0.082125, loss_s1: 0.067843, loss_fp: 0.000849, loss_freq: 0.029136
[14:10:26.039] iteration 12509: loss: 0.056787, loss_s1: 0.044470, loss_fp: 0.000378, loss_freq: 0.020193
[14:10:26.672] iteration 12510: loss: 0.057841, loss_s1: 0.043700, loss_fp: 0.001952, loss_freq: 0.007095
[14:10:27.304] iteration 12511: loss: 0.099403, loss_s1: 0.079424, loss_fp: 0.001253, loss_freq: 0.021471
[14:10:27.935] iteration 12512: loss: 0.055927, loss_s1: 0.038068, loss_fp: 0.001533, loss_freq: 0.013589
[14:10:28.567] iteration 12513: loss: 0.060265, loss_s1: 0.024122, loss_fp: 0.001424, loss_freq: 0.044859
[14:10:29.200] iteration 12514: loss: 0.057217, loss_s1: 0.013315, loss_fp: 0.000758, loss_freq: 0.052354
[14:10:29.835] iteration 12515: loss: 0.130050, loss_s1: 0.153726, loss_fp: 0.008643, loss_freq: 0.045962
[14:10:30.465] iteration 12516: loss: 0.050902, loss_s1: 0.024507, loss_fp: 0.002506, loss_freq: 0.026736
[14:10:31.100] iteration 12517: loss: 0.085965, loss_s1: 0.050020, loss_fp: 0.002566, loss_freq: 0.016602
[14:10:31.724] iteration 12518: loss: 0.073505, loss_s1: 0.055994, loss_fp: 0.001850, loss_freq: 0.053843
[14:10:32.363] iteration 12519: loss: 0.057827, loss_s1: 0.020460, loss_fp: 0.000357, loss_freq: 0.008891
[14:10:32.996] iteration 12520: loss: 0.108984, loss_s1: 0.079176, loss_fp: 0.003469, loss_freq: 0.076207
[14:10:33.680] iteration 12521: loss: 0.112542, loss_s1: 0.050453, loss_fp: 0.001229, loss_freq: 0.019846
[14:10:34.341] iteration 12522: loss: 0.066913, loss_s1: 0.035367, loss_fp: 0.000758, loss_freq: 0.049065
[14:10:35.000] iteration 12523: loss: 0.076154, loss_s1: 0.063691, loss_fp: 0.003419, loss_freq: 0.029025
[14:10:35.654] iteration 12524: loss: 0.083904, loss_s1: 0.077574, loss_fp: 0.000708, loss_freq: 0.015394
[14:10:36.288] iteration 12525: loss: 0.041099, loss_s1: 0.022581, loss_fp: 0.002447, loss_freq: 0.016906
[14:10:36.910] iteration 12526: loss: 0.056776, loss_s1: 0.050673, loss_fp: 0.001350, loss_freq: 0.010341
[14:10:37.526] iteration 12527: loss: 0.096297, loss_s1: 0.077604, loss_fp: 0.000876, loss_freq: 0.064528
[14:10:38.163] iteration 12528: loss: 0.050715, loss_s1: 0.019767, loss_fp: 0.002923, loss_freq: 0.007057
[14:10:38.790] iteration 12529: loss: 0.038713, loss_s1: 0.022816, loss_fp: 0.000651, loss_freq: 0.009660
[14:10:39.420] iteration 12530: loss: 0.052635, loss_s1: 0.017269, loss_fp: 0.000666, loss_freq: 0.026863
[14:10:40.046] iteration 12531: loss: 0.072097, loss_s1: 0.071147, loss_fp: 0.004490, loss_freq: 0.023306
[14:10:40.704] iteration 12532: loss: 0.057038, loss_s1: 0.018047, loss_fp: 0.001589, loss_freq: 0.027803
[14:10:41.382] iteration 12533: loss: 0.077559, loss_s1: 0.035073, loss_fp: 0.001360, loss_freq: 0.063817
[14:10:42.045] iteration 12534: loss: 0.056639, loss_s1: 0.034155, loss_fp: 0.002272, loss_freq: 0.010580
[14:10:42.710] iteration 12535: loss: 0.054705, loss_s1: 0.030601, loss_fp: 0.006324, loss_freq: 0.014743
[14:10:43.370] iteration 12536: loss: 0.052492, loss_s1: 0.028534, loss_fp: 0.001855, loss_freq: 0.022747
[14:10:44.038] iteration 12537: loss: 0.079826, loss_s1: 0.037897, loss_fp: 0.000747, loss_freq: 0.025928
[14:10:44.667] iteration 12538: loss: 0.099307, loss_s1: 0.055725, loss_fp: 0.008841, loss_freq: 0.058593
[14:10:45.298] iteration 12539: loss: 0.085648, loss_s1: 0.050798, loss_fp: 0.002687, loss_freq: 0.059346
[14:10:45.951] iteration 12540: loss: 0.059852, loss_s1: 0.030227, loss_fp: 0.006688, loss_freq: 0.017531
[14:10:46.615] iteration 12541: loss: 0.075552, loss_s1: 0.042480, loss_fp: 0.013108, loss_freq: 0.032889
[14:10:47.280] iteration 12542: loss: 0.069199, loss_s1: 0.052119, loss_fp: 0.002883, loss_freq: 0.028856
[14:10:47.960] iteration 12543: loss: 0.058217, loss_s1: 0.028660, loss_fp: 0.005822, loss_freq: 0.020053
[14:10:48.620] iteration 12544: loss: 0.043462, loss_s1: 0.039499, loss_fp: 0.001764, loss_freq: 0.002524
[14:10:49.260] iteration 12545: loss: 0.043538, loss_s1: 0.021174, loss_fp: 0.002809, loss_freq: 0.019188
[14:10:49.889] iteration 12546: loss: 0.048367, loss_s1: 0.023778, loss_fp: 0.001935, loss_freq: 0.016875
[14:10:50.515] iteration 12547: loss: 0.050313, loss_s1: 0.029583, loss_fp: 0.002064, loss_freq: 0.020050
[14:10:51.144] iteration 12548: loss: 0.121353, loss_s1: 0.105120, loss_fp: 0.001090, loss_freq: 0.066629
[14:10:51.775] iteration 12549: loss: 0.083098, loss_s1: 0.075615, loss_fp: 0.018652, loss_freq: 0.023384
[14:10:52.403] iteration 12550: loss: 0.058793, loss_s1: 0.039891, loss_fp: 0.001559, loss_freq: 0.016301
[14:10:53.034] iteration 12551: loss: 0.052435, loss_s1: 0.042513, loss_fp: 0.002963, loss_freq: 0.008471
[14:10:53.665] iteration 12552: loss: 0.055299, loss_s1: 0.004624, loss_fp: 0.001184, loss_freq: 0.010512
[14:10:54.305] iteration 12553: loss: 0.068521, loss_s1: 0.071629, loss_fp: 0.009762, loss_freq: 0.017020
[14:10:55.023] iteration 12554: loss: 0.072774, loss_s1: 0.054171, loss_fp: 0.003030, loss_freq: 0.006109
[14:10:55.980] iteration 12555: loss: 0.047441, loss_s1: 0.017740, loss_fp: 0.007795, loss_freq: 0.019583
[14:10:56.889] iteration 12556: loss: 0.092125, loss_s1: 0.029984, loss_fp: 0.002796, loss_freq: 0.036847
[14:10:57.507] iteration 12557: loss: 0.047454, loss_s1: 0.027140, loss_fp: 0.001051, loss_freq: 0.006669
[14:10:58.126] iteration 12558: loss: 0.090546, loss_s1: 0.053660, loss_fp: 0.001395, loss_freq: 0.065281
[14:10:58.794] iteration 12559: loss: 0.075043, loss_s1: 0.072351, loss_fp: 0.003287, loss_freq: 0.021553
[14:10:59.414] iteration 12560: loss: 0.042070, loss_s1: 0.022919, loss_fp: 0.002261, loss_freq: 0.016814
[14:11:00.039] iteration 12561: loss: 0.044083, loss_s1: 0.029838, loss_fp: 0.000220, loss_freq: 0.014306
[14:11:00.665] iteration 12562: loss: 0.121580, loss_s1: 0.090465, loss_fp: 0.003668, loss_freq: 0.087253
[14:11:01.285] iteration 12563: loss: 0.108244, loss_s1: 0.057600, loss_fp: 0.002764, loss_freq: 0.028355
[14:11:01.934] iteration 12564: loss: 0.045646, loss_s1: 0.021135, loss_fp: 0.005236, loss_freq: 0.002801
[14:11:02.564] iteration 12565: loss: 0.043637, loss_s1: 0.019159, loss_fp: 0.002539, loss_freq: 0.012191
[14:11:03.191] iteration 12566: loss: 0.079895, loss_s1: 0.061972, loss_fp: 0.001184, loss_freq: 0.057959
[14:11:03.844] iteration 12567: loss: 0.081106, loss_s1: 0.028069, loss_fp: 0.001023, loss_freq: 0.015177
[14:11:04.471] iteration 12568: loss: 0.055822, loss_s1: 0.031738, loss_fp: 0.002895, loss_freq: 0.018283
[14:11:05.097] iteration 12569: loss: 0.072285, loss_s1: 0.056575, loss_fp: 0.000772, loss_freq: 0.024814
[14:11:05.719] iteration 12570: loss: 0.072815, loss_s1: 0.061259, loss_fp: 0.001614, loss_freq: 0.012388
[14:11:06.339] iteration 12571: loss: 0.055758, loss_s1: 0.020761, loss_fp: 0.020469, loss_freq: 0.018662
[14:11:06.967] iteration 12572: loss: 0.063933, loss_s1: 0.033010, loss_fp: 0.007789, loss_freq: 0.024077
[14:11:07.595] iteration 12573: loss: 0.082420, loss_s1: 0.058991, loss_fp: 0.004632, loss_freq: 0.043865
[14:11:08.220] iteration 12574: loss: 0.041248, loss_s1: 0.012113, loss_fp: 0.003107, loss_freq: 0.018138
[14:11:08.847] iteration 12575: loss: 0.101657, loss_s1: 0.061485, loss_fp: 0.003330, loss_freq: 0.059934
[14:11:09.474] iteration 12576: loss: 0.107591, loss_s1: 0.057461, loss_fp: 0.009644, loss_freq: 0.045188
[14:11:10.101] iteration 12577: loss: 0.139860, loss_s1: 0.095898, loss_fp: 0.002757, loss_freq: 0.042157
[14:11:10.726] iteration 12578: loss: 0.100721, loss_s1: 0.089737, loss_fp: 0.003875, loss_freq: 0.017492
[14:11:11.355] iteration 12579: loss: 0.093983, loss_s1: 0.028170, loss_fp: 0.001917, loss_freq: 0.008169
[14:11:11.978] iteration 12580: loss: 0.055763, loss_s1: 0.037077, loss_fp: 0.001344, loss_freq: 0.023477
[14:11:12.603] iteration 12581: loss: 0.094825, loss_s1: 0.040311, loss_fp: 0.009047, loss_freq: 0.027541
[14:11:13.227] iteration 12582: loss: 0.082200, loss_s1: 0.058383, loss_fp: 0.001606, loss_freq: 0.054039
[14:11:13.852] iteration 12583: loss: 0.104865, loss_s1: 0.098294, loss_fp: 0.002084, loss_freq: 0.053136
[14:11:14.468] iteration 12584: loss: 0.055260, loss_s1: 0.023230, loss_fp: 0.001589, loss_freq: 0.035305
[14:11:15.429] iteration 12585: loss: 0.060111, loss_s1: 0.020997, loss_fp: 0.005965, loss_freq: 0.039939
[14:11:16.071] iteration 12586: loss: 0.090162, loss_s1: 0.072018, loss_fp: 0.007657, loss_freq: 0.048587
[14:11:16.703] iteration 12587: loss: 0.042774, loss_s1: 0.021631, loss_fp: 0.000717, loss_freq: 0.011377
[14:11:17.333] iteration 12588: loss: 0.109143, loss_s1: 0.066920, loss_fp: 0.001895, loss_freq: 0.031079
[14:11:17.968] iteration 12589: loss: 0.095430, loss_s1: 0.072233, loss_fp: 0.000532, loss_freq: 0.068316
[14:11:18.605] iteration 12590: loss: 0.082293, loss_s1: 0.022343, loss_fp: 0.001426, loss_freq: 0.006248
[14:11:19.238] iteration 12591: loss: 0.054185, loss_s1: 0.033687, loss_fp: 0.002784, loss_freq: 0.033452
[14:11:19.873] iteration 12592: loss: 0.078970, loss_s1: 0.042066, loss_fp: 0.002775, loss_freq: 0.012657
[14:11:20.522] iteration 12593: loss: 0.080653, loss_s1: 0.029209, loss_fp: 0.001853, loss_freq: 0.073555
[14:11:21.155] iteration 12594: loss: 0.063773, loss_s1: 0.036410, loss_fp: 0.000352, loss_freq: 0.007338
[14:11:21.787] iteration 12595: loss: 0.071541, loss_s1: 0.058861, loss_fp: 0.001468, loss_freq: 0.028679
[14:11:22.443] iteration 12596: loss: 0.067694, loss_s1: 0.016506, loss_fp: 0.001313, loss_freq: 0.055112
[14:11:23.099] iteration 12597: loss: 0.093634, loss_s1: 0.078173, loss_fp: 0.000745, loss_freq: 0.048881
[14:11:23.756] iteration 12598: loss: 0.030398, loss_s1: 0.017718, loss_fp: 0.000464, loss_freq: 0.003548
[14:11:24.416] iteration 12599: loss: 0.098526, loss_s1: 0.088888, loss_fp: 0.007356, loss_freq: 0.048410
[14:11:25.086] iteration 12600: loss: 0.046997, loss_s1: 0.028421, loss_fp: 0.000269, loss_freq: 0.014469
[14:11:28.738] iteration 12600 : mean_dice : 0.753531
[14:11:29.391] iteration 12601: loss: 0.096160, loss_s1: 0.026280, loss_fp: 0.001325, loss_freq: 0.014448
[14:11:30.026] iteration 12602: loss: 0.060935, loss_s1: 0.031023, loss_fp: 0.002178, loss_freq: 0.008039
[14:11:30.655] iteration 12603: loss: 0.053341, loss_s1: 0.029126, loss_fp: 0.000718, loss_freq: 0.016079
[14:11:31.310] iteration 12604: loss: 0.065977, loss_s1: 0.070688, loss_fp: 0.002205, loss_freq: 0.015329
[14:11:31.937] iteration 12605: loss: 0.073691, loss_s1: 0.021609, loss_fp: 0.002049, loss_freq: 0.053425
[14:11:32.553] iteration 12606: loss: 0.067177, loss_s1: 0.027743, loss_fp: 0.006198, loss_freq: 0.025457
[14:11:33.169] iteration 12607: loss: 0.060194, loss_s1: 0.042385, loss_fp: 0.000997, loss_freq: 0.036486
[14:11:33.856] iteration 12608: loss: 0.048230, loss_s1: 0.022487, loss_fp: 0.000637, loss_freq: 0.007444
[14:11:34.511] iteration 12609: loss: 0.085215, loss_s1: 0.085725, loss_fp: 0.001792, loss_freq: 0.028653
[14:11:35.162] iteration 12610: loss: 0.085194, loss_s1: 0.047998, loss_fp: 0.004174, loss_freq: 0.048905
[14:11:35.817] iteration 12611: loss: 0.072327, loss_s1: 0.036619, loss_fp: 0.007081, loss_freq: 0.038867
[14:11:36.460] iteration 12612: loss: 0.062336, loss_s1: 0.021903, loss_fp: 0.003902, loss_freq: 0.022975
[14:11:37.078] iteration 12613: loss: 0.074266, loss_s1: 0.026109, loss_fp: 0.001194, loss_freq: 0.016779
[14:11:37.701] iteration 12614: loss: 0.058973, loss_s1: 0.041949, loss_fp: 0.002713, loss_freq: 0.008569
[14:11:38.324] iteration 12615: loss: 0.075122, loss_s1: 0.039125, loss_fp: 0.000890, loss_freq: 0.021611
[14:11:38.943] iteration 12616: loss: 0.052014, loss_s1: 0.029027, loss_fp: 0.000779, loss_freq: 0.020068
[14:11:39.562] iteration 12617: loss: 0.051434, loss_s1: 0.030952, loss_fp: 0.004284, loss_freq: 0.013772
[14:11:40.185] iteration 12618: loss: 0.086942, loss_s1: 0.063157, loss_fp: 0.002460, loss_freq: 0.039040
[14:11:40.811] iteration 12619: loss: 0.078984, loss_s1: 0.040290, loss_fp: 0.003709, loss_freq: 0.026758
[14:11:41.435] iteration 12620: loss: 0.077325, loss_s1: 0.067537, loss_fp: 0.002860, loss_freq: 0.032576
[14:11:42.056] iteration 12621: loss: 0.064236, loss_s1: 0.049122, loss_fp: 0.001323, loss_freq: 0.023644
[14:11:42.703] iteration 12622: loss: 0.053303, loss_s1: 0.018381, loss_fp: 0.001295, loss_freq: 0.040281
[14:11:43.331] iteration 12623: loss: 0.070870, loss_s1: 0.021997, loss_fp: 0.005949, loss_freq: 0.039414
[14:11:43.969] iteration 12624: loss: 0.043889, loss_s1: 0.031567, loss_fp: 0.001406, loss_freq: 0.014949
[14:11:44.591] iteration 12625: loss: 0.066805, loss_s1: 0.054544, loss_fp: 0.004354, loss_freq: 0.014078
[14:11:45.239] iteration 12626: loss: 0.038731, loss_s1: 0.026039, loss_fp: 0.003443, loss_freq: 0.008734
[14:11:45.877] iteration 12627: loss: 0.073973, loss_s1: 0.041763, loss_fp: 0.003790, loss_freq: 0.015358
[14:11:46.530] iteration 12628: loss: 0.086500, loss_s1: 0.048808, loss_fp: 0.006251, loss_freq: 0.070205
[14:11:47.174] iteration 12629: loss: 0.086378, loss_s1: 0.055761, loss_fp: 0.001808, loss_freq: 0.006424
[14:11:47.833] iteration 12630: loss: 0.084232, loss_s1: 0.071121, loss_fp: 0.000377, loss_freq: 0.045190
[14:11:48.491] iteration 12631: loss: 0.070985, loss_s1: 0.037351, loss_fp: 0.002668, loss_freq: 0.047943
[14:11:49.115] iteration 12632: loss: 0.060286, loss_s1: 0.032257, loss_fp: 0.004423, loss_freq: 0.031871
[14:11:49.735] iteration 12633: loss: 0.054079, loss_s1: 0.034192, loss_fp: 0.008424, loss_freq: 0.027317
[14:11:50.355] iteration 12634: loss: 0.052212, loss_s1: 0.040157, loss_fp: 0.001438, loss_freq: 0.013867
[14:11:50.976] iteration 12635: loss: 0.043446, loss_s1: 0.023664, loss_fp: 0.000900, loss_freq: 0.017176
[14:11:51.602] iteration 12636: loss: 0.087181, loss_s1: 0.021236, loss_fp: 0.000560, loss_freq: 0.061529
[14:11:52.228] iteration 12637: loss: 0.058774, loss_s1: 0.021623, loss_fp: 0.004943, loss_freq: 0.028032
[14:11:52.849] iteration 12638: loss: 0.048805, loss_s1: 0.038497, loss_fp: 0.003298, loss_freq: 0.017374
[14:11:53.469] iteration 12639: loss: 0.039292, loss_s1: 0.023879, loss_fp: 0.007965, loss_freq: 0.006944
[14:11:54.094] iteration 12640: loss: 0.049976, loss_s1: 0.014551, loss_fp: 0.003840, loss_freq: 0.005545
[14:11:54.720] iteration 12641: loss: 0.073570, loss_s1: 0.061077, loss_fp: 0.001116, loss_freq: 0.010380
[14:11:55.356] iteration 12642: loss: 0.044619, loss_s1: 0.014621, loss_fp: 0.007238, loss_freq: 0.013722
[14:11:55.985] iteration 12643: loss: 0.126751, loss_s1: 0.068242, loss_fp: 0.004201, loss_freq: 0.061558
[14:11:56.653] iteration 12644: loss: 0.043296, loss_s1: 0.009018, loss_fp: 0.001908, loss_freq: 0.020741
[14:11:57.313] iteration 12645: loss: 0.039711, loss_s1: 0.017982, loss_fp: 0.002417, loss_freq: 0.011125
[14:11:57.972] iteration 12646: loss: 0.065005, loss_s1: 0.065601, loss_fp: 0.003409, loss_freq: 0.013890
[14:11:58.632] iteration 12647: loss: 0.087471, loss_s1: 0.082940, loss_fp: 0.004521, loss_freq: 0.031789
[14:11:59.266] iteration 12648: loss: 0.085370, loss_s1: 0.020435, loss_fp: 0.002226, loss_freq: 0.020187
[14:11:59.894] iteration 12649: loss: 0.111789, loss_s1: 0.045759, loss_fp: 0.012691, loss_freq: 0.037401
[14:12:00.552] iteration 12650: loss: 0.077959, loss_s1: 0.044850, loss_fp: 0.001083, loss_freq: 0.012650
[14:12:01.178] iteration 12651: loss: 0.089366, loss_s1: 0.060757, loss_fp: 0.002431, loss_freq: 0.042982
[14:12:01.800] iteration 12652: loss: 0.054237, loss_s1: 0.029535, loss_fp: 0.003631, loss_freq: 0.022330
[14:12:02.420] iteration 12653: loss: 0.050307, loss_s1: 0.034944, loss_fp: 0.002228, loss_freq: 0.015632
[14:12:03.047] iteration 12654: loss: 0.079224, loss_s1: 0.023337, loss_fp: 0.004459, loss_freq: 0.018980
[14:12:03.673] iteration 12655: loss: 0.059039, loss_s1: 0.029709, loss_fp: 0.000831, loss_freq: 0.022926
[14:12:04.297] iteration 12656: loss: 0.075531, loss_s1: 0.025143, loss_fp: 0.004040, loss_freq: 0.055314
[14:12:04.930] iteration 12657: loss: 0.087312, loss_s1: 0.068156, loss_fp: 0.009127, loss_freq: 0.034985
[14:12:05.553] iteration 12658: loss: 0.060266, loss_s1: 0.041275, loss_fp: 0.007288, loss_freq: 0.015019
[14:12:06.179] iteration 12659: loss: 0.063617, loss_s1: 0.029825, loss_fp: 0.006151, loss_freq: 0.045609
[14:12:06.803] iteration 12660: loss: 0.087387, loss_s1: 0.028914, loss_fp: 0.000997, loss_freq: 0.035377
[14:12:07.431] iteration 12661: loss: 0.058729, loss_s1: 0.049016, loss_fp: 0.003516, loss_freq: 0.028442
[14:12:08.055] iteration 12662: loss: 0.079479, loss_s1: 0.045378, loss_fp: 0.002155, loss_freq: 0.014909
[14:12:08.677] iteration 12663: loss: 0.074541, loss_s1: 0.052518, loss_fp: 0.002283, loss_freq: 0.039439
[14:12:09.295] iteration 12664: loss: 0.123889, loss_s1: 0.043221, loss_fp: 0.001970, loss_freq: 0.014426
[14:12:09.925] iteration 12665: loss: 0.090371, loss_s1: 0.056772, loss_fp: 0.000950, loss_freq: 0.017087
[14:12:10.546] iteration 12666: loss: 0.059803, loss_s1: 0.040918, loss_fp: 0.004629, loss_freq: 0.026420
[14:12:11.179] iteration 12667: loss: 0.064851, loss_s1: 0.025554, loss_fp: 0.002222, loss_freq: 0.020426
[14:12:11.806] iteration 12668: loss: 0.046566, loss_s1: 0.024281, loss_fp: 0.005590, loss_freq: 0.013701
[14:12:12.433] iteration 12669: loss: 0.073973, loss_s1: 0.065505, loss_fp: 0.002358, loss_freq: 0.011417
[14:12:13.101] iteration 12670: loss: 0.077882, loss_s1: 0.033468, loss_fp: 0.003099, loss_freq: 0.059966
[14:12:13.764] iteration 12671: loss: 0.078465, loss_s1: 0.062031, loss_fp: 0.003186, loss_freq: 0.003752
[14:12:14.435] iteration 12672: loss: 0.090916, loss_s1: 0.055248, loss_fp: 0.001261, loss_freq: 0.024235
[14:12:15.099] iteration 12673: loss: 0.056726, loss_s1: 0.035855, loss_fp: 0.002963, loss_freq: 0.030292
[14:12:15.732] iteration 12674: loss: 0.069053, loss_s1: 0.046661, loss_fp: 0.005841, loss_freq: 0.033918
[14:12:16.365] iteration 12675: loss: 0.102622, loss_s1: 0.052967, loss_fp: 0.003498, loss_freq: 0.025267
[14:12:17.027] iteration 12676: loss: 0.089487, loss_s1: 0.043576, loss_fp: 0.002001, loss_freq: 0.051965
[14:12:17.682] iteration 12677: loss: 0.054077, loss_s1: 0.053815, loss_fp: 0.001994, loss_freq: 0.012744
[14:12:18.338] iteration 12678: loss: 0.064203, loss_s1: 0.047068, loss_fp: 0.010519, loss_freq: 0.018445
[14:12:18.993] iteration 12679: loss: 0.043299, loss_s1: 0.012246, loss_fp: 0.001158, loss_freq: 0.017873
[14:12:19.654] iteration 12680: loss: 0.051305, loss_s1: 0.024860, loss_fp: 0.001895, loss_freq: 0.009208
[14:12:20.305] iteration 12681: loss: 0.099675, loss_s1: 0.069670, loss_fp: 0.001841, loss_freq: 0.041281
[14:12:20.933] iteration 12682: loss: 0.083442, loss_s1: 0.084080, loss_fp: 0.000733, loss_freq: 0.017316
[14:12:21.564] iteration 12683: loss: 0.059901, loss_s1: 0.023680, loss_fp: 0.005407, loss_freq: 0.019064
[14:12:22.219] iteration 12684: loss: 0.110661, loss_s1: 0.025528, loss_fp: 0.006013, loss_freq: 0.058109
[14:12:22.893] iteration 12685: loss: 0.078662, loss_s1: 0.038413, loss_fp: 0.014895, loss_freq: 0.014545
[14:12:23.546] iteration 12686: loss: 0.066521, loss_s1: 0.039157, loss_fp: 0.001189, loss_freq: 0.027841
[14:12:24.203] iteration 12687: loss: 0.055389, loss_s1: 0.046540, loss_fp: 0.002305, loss_freq: 0.018251
[14:12:24.866] iteration 12688: loss: 0.048069, loss_s1: 0.032027, loss_fp: 0.006130, loss_freq: 0.010493
[14:12:25.530] iteration 12689: loss: 0.059069, loss_s1: 0.018620, loss_fp: 0.001216, loss_freq: 0.024663
[14:12:26.168] iteration 12690: loss: 0.047071, loss_s1: 0.010112, loss_fp: 0.001986, loss_freq: 0.020024
[14:12:26.842] iteration 12691: loss: 0.116549, loss_s1: 0.140724, loss_fp: 0.004311, loss_freq: 0.038376
[14:12:27.498] iteration 12692: loss: 0.086923, loss_s1: 0.083160, loss_fp: 0.002095, loss_freq: 0.029310
[14:12:28.186] iteration 12693: loss: 0.087710, loss_s1: 0.046068, loss_fp: 0.003585, loss_freq: 0.037915
[14:12:28.839] iteration 12694: loss: 0.051269, loss_s1: 0.032494, loss_fp: 0.000998, loss_freq: 0.026976
[14:12:29.489] iteration 12695: loss: 0.078372, loss_s1: 0.030854, loss_fp: 0.001039, loss_freq: 0.023741
[14:12:30.142] iteration 12696: loss: 0.077584, loss_s1: 0.074883, loss_fp: 0.004659, loss_freq: 0.035110
[14:12:30.801] iteration 12697: loss: 0.052428, loss_s1: 0.023126, loss_fp: 0.002026, loss_freq: 0.009835
[14:12:31.455] iteration 12698: loss: 0.088956, loss_s1: 0.085073, loss_fp: 0.011827, loss_freq: 0.017506
[14:12:32.085] iteration 12699: loss: 0.074200, loss_s1: 0.033021, loss_fp: 0.001924, loss_freq: 0.042852
[14:12:32.707] iteration 12700: loss: 0.052433, loss_s1: 0.024928, loss_fp: 0.000390, loss_freq: 0.010794
[14:12:33.324] iteration 12701: loss: 0.096461, loss_s1: 0.048767, loss_fp: 0.001523, loss_freq: 0.067296
[14:12:33.948] iteration 12702: loss: 0.099740, loss_s1: 0.099550, loss_fp: 0.003996, loss_freq: 0.036900
[14:12:34.561] iteration 12703: loss: 0.034325, loss_s1: 0.014503, loss_fp: 0.004084, loss_freq: 0.014077
[14:12:35.193] iteration 12704: loss: 0.051354, loss_s1: 0.026047, loss_fp: 0.001637, loss_freq: 0.031462
[14:12:35.846] iteration 12705: loss: 0.100079, loss_s1: 0.037416, loss_fp: 0.001103, loss_freq: 0.088024
[14:12:36.474] iteration 12706: loss: 0.073492, loss_s1: 0.052556, loss_fp: 0.002372, loss_freq: 0.020892
[14:12:37.105] iteration 12707: loss: 0.042729, loss_s1: 0.013274, loss_fp: 0.015473, loss_freq: 0.010095
[14:12:37.736] iteration 12708: loss: 0.054658, loss_s1: 0.021539, loss_fp: 0.003431, loss_freq: 0.027578
[14:12:38.361] iteration 12709: loss: 0.085130, loss_s1: 0.024080, loss_fp: 0.002374, loss_freq: 0.055018
[14:12:38.988] iteration 12710: loss: 0.112909, loss_s1: 0.027745, loss_fp: 0.002759, loss_freq: 0.022331
[14:12:39.614] iteration 12711: loss: 0.058443, loss_s1: 0.045188, loss_fp: 0.000660, loss_freq: 0.029334
[14:12:40.234] iteration 12712: loss: 0.050499, loss_s1: 0.022376, loss_fp: 0.003703, loss_freq: 0.030409
[14:12:40.855] iteration 12713: loss: 0.088655, loss_s1: 0.092778, loss_fp: 0.004958, loss_freq: 0.024509
[14:12:41.463] iteration 12714: loss: 0.070073, loss_s1: 0.067441, loss_fp: 0.002005, loss_freq: 0.018332
[14:12:42.076] iteration 12715: loss: 0.073575, loss_s1: 0.050874, loss_fp: 0.004690, loss_freq: 0.025389
[14:12:42.695] iteration 12716: loss: 0.106669, loss_s1: 0.098293, loss_fp: 0.004124, loss_freq: 0.015652
[14:12:43.321] iteration 12717: loss: 0.088595, loss_s1: 0.058901, loss_fp: 0.012274, loss_freq: 0.030554
[14:12:43.945] iteration 12718: loss: 0.129167, loss_s1: 0.110395, loss_fp: 0.001490, loss_freq: 0.055667
[14:12:44.578] iteration 12719: loss: 0.080389, loss_s1: 0.043261, loss_fp: 0.010016, loss_freq: 0.047968
[14:12:45.211] iteration 12720: loss: 0.076166, loss_s1: 0.055560, loss_fp: 0.005937, loss_freq: 0.044295
[14:12:45.841] iteration 12721: loss: 0.097768, loss_s1: 0.077531, loss_fp: 0.008877, loss_freq: 0.048825
[14:12:46.469] iteration 12722: loss: 0.041890, loss_s1: 0.014376, loss_fp: 0.004323, loss_freq: 0.013902
[14:12:47.103] iteration 12723: loss: 0.045306, loss_s1: 0.019821, loss_fp: 0.004204, loss_freq: 0.020835
[14:12:47.732] iteration 12724: loss: 0.067953, loss_s1: 0.025276, loss_fp: 0.000998, loss_freq: 0.012974
[14:12:48.359] iteration 12725: loss: 0.093956, loss_s1: 0.067549, loss_fp: 0.006090, loss_freq: 0.056741
[14:12:48.980] iteration 12726: loss: 0.117285, loss_s1: 0.076639, loss_fp: 0.002613, loss_freq: 0.088557
[14:12:49.600] iteration 12727: loss: 0.080059, loss_s1: 0.037042, loss_fp: 0.001869, loss_freq: 0.042490
[14:12:50.533] iteration 12728: loss: 0.067646, loss_s1: 0.060277, loss_fp: 0.000670, loss_freq: 0.015717
[14:12:51.161] iteration 12729: loss: 0.049605, loss_s1: 0.027994, loss_fp: 0.002772, loss_freq: 0.019987
[14:12:51.780] iteration 12730: loss: 0.077504, loss_s1: 0.067238, loss_fp: 0.001305, loss_freq: 0.026095
[14:12:52.407] iteration 12731: loss: 0.067331, loss_s1: 0.053254, loss_fp: 0.000893, loss_freq: 0.015907
[14:12:53.024] iteration 12732: loss: 0.113588, loss_s1: 0.122208, loss_fp: 0.002147, loss_freq: 0.032736
[14:12:53.682] iteration 12733: loss: 0.088018, loss_s1: 0.048854, loss_fp: 0.000829, loss_freq: 0.012337
[14:12:54.304] iteration 12734: loss: 0.048154, loss_s1: 0.030121, loss_fp: 0.001841, loss_freq: 0.027432
[14:12:54.918] iteration 12735: loss: 0.110559, loss_s1: 0.065160, loss_fp: 0.007392, loss_freq: 0.032729
[14:12:55.547] iteration 12736: loss: 0.074376, loss_s1: 0.042728, loss_fp: 0.002069, loss_freq: 0.047937
[14:12:56.164] iteration 12737: loss: 0.074548, loss_s1: 0.043244, loss_fp: 0.000444, loss_freq: 0.015907
[14:12:56.785] iteration 12738: loss: 0.104690, loss_s1: 0.070763, loss_fp: 0.013369, loss_freq: 0.051607
[14:12:57.447] iteration 12739: loss: 0.044822, loss_s1: 0.011722, loss_fp: 0.000940, loss_freq: 0.011921
[14:12:58.107] iteration 12740: loss: 0.067589, loss_s1: 0.068408, loss_fp: 0.004706, loss_freq: 0.003884
[14:12:58.810] iteration 12741: loss: 0.049810, loss_s1: 0.034162, loss_fp: 0.002024, loss_freq: 0.010613
[14:12:59.523] iteration 12742: loss: 0.054821, loss_s1: 0.030534, loss_fp: 0.006814, loss_freq: 0.009532
[14:13:00.194] iteration 12743: loss: 0.073517, loss_s1: 0.048807, loss_fp: 0.000305, loss_freq: 0.023387
[14:13:00.812] iteration 12744: loss: 0.051970, loss_s1: 0.016599, loss_fp: 0.000672, loss_freq: 0.023053
[14:13:01.446] iteration 12745: loss: 0.045332, loss_s1: 0.033605, loss_fp: 0.000720, loss_freq: 0.008658
[14:13:02.074] iteration 12746: loss: 0.049124, loss_s1: 0.023971, loss_fp: 0.002622, loss_freq: 0.031543
[14:13:02.700] iteration 12747: loss: 0.054230, loss_s1: 0.030564, loss_fp: 0.000786, loss_freq: 0.026594
[14:13:03.319] iteration 12748: loss: 0.103420, loss_s1: 0.047345, loss_fp: 0.003090, loss_freq: 0.045906
[14:13:03.951] iteration 12749: loss: 0.054977, loss_s1: 0.026527, loss_fp: 0.000237, loss_freq: 0.022831
[14:13:04.570] iteration 12750: loss: 0.079685, loss_s1: 0.017333, loss_fp: 0.002785, loss_freq: 0.072018
[14:13:05.194] iteration 12751: loss: 0.065654, loss_s1: 0.057596, loss_fp: 0.002498, loss_freq: 0.009203
[14:13:05.840] iteration 12752: loss: 0.055226, loss_s1: 0.029903, loss_fp: 0.001216, loss_freq: 0.029949
[14:13:06.511] iteration 12753: loss: 0.061781, loss_s1: 0.029464, loss_fp: 0.001638, loss_freq: 0.024031
[14:13:07.140] iteration 12754: loss: 0.130941, loss_s1: 0.117956, loss_fp: 0.008159, loss_freq: 0.074418
[14:13:07.773] iteration 12755: loss: 0.038617, loss_s1: 0.020381, loss_fp: 0.001152, loss_freq: 0.004636
[14:13:08.399] iteration 12756: loss: 0.085265, loss_s1: 0.058577, loss_fp: 0.001510, loss_freq: 0.040733
[14:13:09.023] iteration 12757: loss: 0.183521, loss_s1: 0.026148, loss_fp: 0.002845, loss_freq: 0.012868
[14:13:09.649] iteration 12758: loss: 0.065528, loss_s1: 0.030698, loss_fp: 0.001175, loss_freq: 0.015089
[14:13:10.278] iteration 12759: loss: 0.079192, loss_s1: 0.042496, loss_fp: 0.003772, loss_freq: 0.023209
[14:13:10.903] iteration 12760: loss: 0.059399, loss_s1: 0.059856, loss_fp: 0.006298, loss_freq: 0.020431
[14:13:11.553] iteration 12761: loss: 0.062857, loss_s1: 0.043855, loss_fp: 0.002363, loss_freq: 0.031926
[14:13:12.205] iteration 12762: loss: 0.089915, loss_s1: 0.070257, loss_fp: 0.004949, loss_freq: 0.034048
[14:13:12.861] iteration 12763: loss: 0.080160, loss_s1: 0.071381, loss_fp: 0.003594, loss_freq: 0.020886
[14:13:13.486] iteration 12764: loss: 0.082114, loss_s1: 0.043291, loss_fp: 0.002103, loss_freq: 0.034382
[14:13:14.112] iteration 12765: loss: 0.060109, loss_s1: 0.043785, loss_fp: 0.002109, loss_freq: 0.029619
[14:13:14.735] iteration 12766: loss: 0.067731, loss_s1: 0.023727, loss_fp: 0.001670, loss_freq: 0.057271
[14:13:15.378] iteration 12767: loss: 0.043760, loss_s1: 0.026082, loss_fp: 0.001439, loss_freq: 0.010880
[14:13:16.030] iteration 12768: loss: 0.039837, loss_s1: 0.022379, loss_fp: 0.002404, loss_freq: 0.007021
[14:13:16.681] iteration 12769: loss: 0.045752, loss_s1: 0.042373, loss_fp: 0.007809, loss_freq: 0.006963
[14:13:17.336] iteration 12770: loss: 0.045213, loss_s1: 0.024579, loss_fp: 0.001306, loss_freq: 0.006476
[14:13:17.992] iteration 12771: loss: 0.075761, loss_s1: 0.061073, loss_fp: 0.002494, loss_freq: 0.036191
[14:13:18.650] iteration 12772: loss: 0.096228, loss_s1: 0.059503, loss_fp: 0.003969, loss_freq: 0.004873
[14:13:19.287] iteration 12773: loss: 0.082115, loss_s1: 0.057586, loss_fp: 0.004247, loss_freq: 0.057339
[14:13:19.902] iteration 12774: loss: 0.053331, loss_s1: 0.015972, loss_fp: 0.002042, loss_freq: 0.034195
[14:13:20.521] iteration 12775: loss: 0.054364, loss_s1: 0.025245, loss_fp: 0.004857, loss_freq: 0.018479
[14:13:21.148] iteration 12776: loss: 0.070299, loss_s1: 0.061311, loss_fp: 0.001798, loss_freq: 0.023797
[14:13:21.768] iteration 12777: loss: 0.068482, loss_s1: 0.046342, loss_fp: 0.001789, loss_freq: 0.027103
[14:13:22.387] iteration 12778: loss: 0.061317, loss_s1: 0.038353, loss_fp: 0.002534, loss_freq: 0.018481
[14:13:23.006] iteration 12779: loss: 0.111156, loss_s1: 0.055787, loss_fp: 0.000718, loss_freq: 0.018821
[14:13:23.627] iteration 12780: loss: 0.036248, loss_s1: 0.022109, loss_fp: 0.002519, loss_freq: 0.003710
[14:13:24.255] iteration 12781: loss: 0.041491, loss_s1: 0.018727, loss_fp: 0.003086, loss_freq: 0.022537
[14:13:24.882] iteration 12782: loss: 0.071084, loss_s1: 0.058423, loss_fp: 0.004622, loss_freq: 0.008607
[14:13:25.512] iteration 12783: loss: 0.091432, loss_s1: 0.017645, loss_fp: 0.002032, loss_freq: 0.031226
[14:13:26.137] iteration 12784: loss: 0.083095, loss_s1: 0.088457, loss_fp: 0.008514, loss_freq: 0.029324
[14:13:26.764] iteration 12785: loss: 0.069711, loss_s1: 0.020765, loss_fp: 0.002666, loss_freq: 0.059199
[14:13:27.398] iteration 12786: loss: 0.148714, loss_s1: 0.090670, loss_fp: 0.003844, loss_freq: 0.060220
[14:13:28.025] iteration 12787: loss: 0.055831, loss_s1: 0.023093, loss_fp: 0.005934, loss_freq: 0.026406
[14:13:28.657] iteration 12788: loss: 0.082617, loss_s1: 0.035895, loss_fp: 0.001406, loss_freq: 0.005690
[14:13:29.276] iteration 12789: loss: 0.058354, loss_s1: 0.037106, loss_fp: 0.005836, loss_freq: 0.026359
[14:13:29.896] iteration 12790: loss: 0.078215, loss_s1: 0.053566, loss_fp: 0.001060, loss_freq: 0.033754
[14:13:30.565] iteration 12791: loss: 0.055564, loss_s1: 0.011727, loss_fp: 0.006668, loss_freq: 0.022689
[14:13:31.190] iteration 12792: loss: 0.075502, loss_s1: 0.033644, loss_fp: 0.002066, loss_freq: 0.018906
[14:13:31.808] iteration 12793: loss: 0.075108, loss_s1: 0.061078, loss_fp: 0.003804, loss_freq: 0.027880
[14:13:32.436] iteration 12794: loss: 0.063000, loss_s1: 0.034229, loss_fp: 0.003240, loss_freq: 0.036959
[14:13:33.063] iteration 12795: loss: 0.082017, loss_s1: 0.022776, loss_fp: 0.018092, loss_freq: 0.017383
[14:13:33.687] iteration 12796: loss: 0.066378, loss_s1: 0.052734, loss_fp: 0.005943, loss_freq: 0.025787
[14:13:34.306] iteration 12797: loss: 0.051129, loss_s1: 0.021964, loss_fp: 0.000900, loss_freq: 0.008900
[14:13:34.931] iteration 12798: loss: 0.062296, loss_s1: 0.046156, loss_fp: 0.001281, loss_freq: 0.026664
[14:13:35.551] iteration 12799: loss: 0.085359, loss_s1: 0.058644, loss_fp: 0.002618, loss_freq: 0.024218
[14:13:36.176] iteration 12800: loss: 0.067034, loss_s1: 0.040014, loss_fp: 0.000944, loss_freq: 0.037895
[14:13:39.414] iteration 12800 : mean_dice : 0.763491
[14:13:40.068] iteration 12801: loss: 0.099919, loss_s1: 0.043624, loss_fp: 0.006762, loss_freq: 0.069104
[14:13:40.690] iteration 12802: loss: 0.082775, loss_s1: 0.073917, loss_fp: 0.002242, loss_freq: 0.033987
[14:13:41.304] iteration 12803: loss: 0.094386, loss_s1: 0.030011, loss_fp: 0.005198, loss_freq: 0.014037
[14:13:41.926] iteration 12804: loss: 0.077521, loss_s1: 0.066451, loss_fp: 0.006444, loss_freq: 0.041539
[14:13:42.545] iteration 12805: loss: 0.067924, loss_s1: 0.055904, loss_fp: 0.000679, loss_freq: 0.010456
[14:13:43.168] iteration 12806: loss: 0.102425, loss_s1: 0.070684, loss_fp: 0.008743, loss_freq: 0.076299
[14:13:43.788] iteration 12807: loss: 0.148789, loss_s1: 0.097991, loss_fp: 0.001761, loss_freq: 0.043730
[14:13:44.416] iteration 12808: loss: 0.068536, loss_s1: 0.023946, loss_fp: 0.005493, loss_freq: 0.040489
[14:13:45.092] iteration 12809: loss: 0.059772, loss_s1: 0.055431, loss_fp: 0.003636, loss_freq: 0.014410
[14:13:45.717] iteration 12810: loss: 0.069658, loss_s1: 0.021595, loss_fp: 0.003840, loss_freq: 0.042759
[14:13:46.342] iteration 12811: loss: 0.062069, loss_s1: 0.043548, loss_fp: 0.003969, loss_freq: 0.029970
[14:13:46.972] iteration 12812: loss: 0.039678, loss_s1: 0.010419, loss_fp: 0.002850, loss_freq: 0.008955
[14:13:47.599] iteration 12813: loss: 0.109022, loss_s1: 0.075517, loss_fp: 0.027160, loss_freq: 0.051573
[14:13:48.222] iteration 12814: loss: 0.056699, loss_s1: 0.023552, loss_fp: 0.001138, loss_freq: 0.008499
[14:13:48.841] iteration 12815: loss: 0.037994, loss_s1: 0.016634, loss_fp: 0.001263, loss_freq: 0.009427
[14:13:49.463] iteration 12816: loss: 0.064458, loss_s1: 0.050370, loss_fp: 0.001308, loss_freq: 0.010948
[14:13:50.090] iteration 12817: loss: 0.044885, loss_s1: 0.024326, loss_fp: 0.010228, loss_freq: 0.013680
[14:13:50.717] iteration 12818: loss: 0.086817, loss_s1: 0.039470, loss_fp: 0.002809, loss_freq: 0.035112
[14:13:51.345] iteration 12819: loss: 0.075566, loss_s1: 0.069419, loss_fp: 0.001438, loss_freq: 0.029912
[14:13:51.972] iteration 12820: loss: 0.070185, loss_s1: 0.076153, loss_fp: 0.003428, loss_freq: 0.011270
[14:13:52.603] iteration 12821: loss: 0.059655, loss_s1: 0.030625, loss_fp: 0.001230, loss_freq: 0.012280
[14:13:53.229] iteration 12822: loss: 0.048069, loss_s1: 0.016957, loss_fp: 0.003290, loss_freq: 0.027374
[14:13:53.859] iteration 12823: loss: 0.056414, loss_s1: 0.039164, loss_fp: 0.001585, loss_freq: 0.007235
[14:13:54.479] iteration 12824: loss: 0.111517, loss_s1: 0.114037, loss_fp: 0.002542, loss_freq: 0.063149
[14:13:55.104] iteration 12825: loss: 0.047049, loss_s1: 0.034327, loss_fp: 0.001177, loss_freq: 0.006862
[14:13:55.747] iteration 12826: loss: 0.061429, loss_s1: 0.023823, loss_fp: 0.009475, loss_freq: 0.033841
[14:13:56.441] iteration 12827: loss: 0.105325, loss_s1: 0.036072, loss_fp: 0.013136, loss_freq: 0.024604
[14:13:57.107] iteration 12828: loss: 0.090054, loss_s1: 0.085337, loss_fp: 0.002217, loss_freq: 0.048584
[14:13:57.765] iteration 12829: loss: 0.063941, loss_s1: 0.020308, loss_fp: 0.002917, loss_freq: 0.023161
[14:13:58.425] iteration 12830: loss: 0.057881, loss_s1: 0.045137, loss_fp: 0.002798, loss_freq: 0.028695
[14:13:59.095] iteration 12831: loss: 0.045514, loss_s1: 0.020249, loss_fp: 0.001640, loss_freq: 0.016637
[14:13:59.769] iteration 12832: loss: 0.064243, loss_s1: 0.023971, loss_fp: 0.004018, loss_freq: 0.023424
[14:14:00.398] iteration 12833: loss: 0.063482, loss_s1: 0.037192, loss_fp: 0.001041, loss_freq: 0.035842
[14:14:01.036] iteration 12834: loss: 0.118556, loss_s1: 0.023107, loss_fp: 0.003649, loss_freq: 0.150773
[14:14:01.674] iteration 12835: loss: 0.046390, loss_s1: 0.017297, loss_fp: 0.005154, loss_freq: 0.027521
[14:14:02.309] iteration 12836: loss: 0.076776, loss_s1: 0.029303, loss_fp: 0.001116, loss_freq: 0.018362
[14:14:02.933] iteration 12837: loss: 0.076122, loss_s1: 0.035027, loss_fp: 0.005453, loss_freq: 0.011299
[14:14:03.576] iteration 12838: loss: 0.084819, loss_s1: 0.042022, loss_fp: 0.011049, loss_freq: 0.026792
[14:14:04.209] iteration 12839: loss: 0.060202, loss_s1: 0.051841, loss_fp: 0.002006, loss_freq: 0.031702
[14:14:04.835] iteration 12840: loss: 0.088513, loss_s1: 0.080562, loss_fp: 0.000645, loss_freq: 0.008535
[14:14:05.460] iteration 12841: loss: 0.080256, loss_s1: 0.095095, loss_fp: 0.002187, loss_freq: 0.007924
[14:14:06.096] iteration 12842: loss: 0.179226, loss_s1: 0.069200, loss_fp: 0.000608, loss_freq: 0.071398
[14:14:06.724] iteration 12843: loss: 0.067739, loss_s1: 0.043883, loss_fp: 0.001253, loss_freq: 0.022905
[14:14:07.363] iteration 12844: loss: 0.093140, loss_s1: 0.057595, loss_fp: 0.008886, loss_freq: 0.031669
[14:14:07.994] iteration 12845: loss: 0.075757, loss_s1: 0.081218, loss_fp: 0.003532, loss_freq: 0.015801
[14:14:08.630] iteration 12846: loss: 0.047821, loss_s1: 0.035360, loss_fp: 0.004128, loss_freq: 0.015451
[14:14:09.262] iteration 12847: loss: 0.102132, loss_s1: 0.090044, loss_fp: 0.000987, loss_freq: 0.036831
[14:14:09.898] iteration 12848: loss: 0.088616, loss_s1: 0.043849, loss_fp: 0.001853, loss_freq: 0.072305
[14:14:10.533] iteration 12849: loss: 0.069964, loss_s1: 0.026738, loss_fp: 0.000588, loss_freq: 0.027228
[14:14:11.165] iteration 12850: loss: 0.045313, loss_s1: 0.029323, loss_fp: 0.002108, loss_freq: 0.004950
[14:14:11.820] iteration 12851: loss: 0.060241, loss_s1: 0.060986, loss_fp: 0.002997, loss_freq: 0.012074
[14:14:12.455] iteration 12852: loss: 0.108287, loss_s1: 0.039301, loss_fp: 0.003221, loss_freq: 0.045754
[14:14:13.089] iteration 12853: loss: 0.073449, loss_s1: 0.057006, loss_fp: 0.000786, loss_freq: 0.019880
[14:14:13.723] iteration 12854: loss: 0.039176, loss_s1: 0.029558, loss_fp: 0.001126, loss_freq: 0.008734
[14:14:14.360] iteration 12855: loss: 0.060319, loss_s1: 0.040864, loss_fp: 0.000771, loss_freq: 0.024600
[14:14:14.991] iteration 12856: loss: 0.066129, loss_s1: 0.068757, loss_fp: 0.001363, loss_freq: 0.010172
[14:14:15.614] iteration 12857: loss: 0.043986, loss_s1: 0.008709, loss_fp: 0.006771, loss_freq: 0.020425
[14:14:16.249] iteration 12858: loss: 0.070922, loss_s1: 0.048256, loss_fp: 0.002521, loss_freq: 0.023235
[14:14:16.870] iteration 12859: loss: 0.111704, loss_s1: 0.051914, loss_fp: 0.004925, loss_freq: 0.027333
[14:14:17.487] iteration 12860: loss: 0.067837, loss_s1: 0.046932, loss_fp: 0.004035, loss_freq: 0.017440
[14:14:18.112] iteration 12861: loss: 0.099660, loss_s1: 0.073009, loss_fp: 0.007870, loss_freq: 0.048927
[14:14:18.738] iteration 12862: loss: 0.077222, loss_s1: 0.034065, loss_fp: 0.003236, loss_freq: 0.049035
[14:14:19.357] iteration 12863: loss: 0.084180, loss_s1: 0.058372, loss_fp: 0.010479, loss_freq: 0.036561
[14:14:19.978] iteration 12864: loss: 0.088333, loss_s1: 0.077379, loss_fp: 0.009580, loss_freq: 0.035355
[14:14:20.607] iteration 12865: loss: 0.050715, loss_s1: 0.034657, loss_fp: 0.000261, loss_freq: 0.005270
[14:14:21.235] iteration 12866: loss: 0.083907, loss_s1: 0.065678, loss_fp: 0.001067, loss_freq: 0.039795
[14:14:21.858] iteration 12867: loss: 0.089301, loss_s1: 0.067254, loss_fp: 0.002326, loss_freq: 0.019875
[14:14:22.481] iteration 12868: loss: 0.072620, loss_s1: 0.028972, loss_fp: 0.002186, loss_freq: 0.042483
[14:14:23.100] iteration 12869: loss: 0.075185, loss_s1: 0.019678, loss_fp: 0.029659, loss_freq: 0.037605
[14:14:23.723] iteration 12870: loss: 0.051297, loss_s1: 0.022397, loss_fp: 0.003803, loss_freq: 0.036289
[14:14:24.725] iteration 12871: loss: 0.076574, loss_s1: 0.081845, loss_fp: 0.000897, loss_freq: 0.021624
[14:14:25.392] iteration 12872: loss: 0.072790, loss_s1: 0.026827, loss_fp: 0.001574, loss_freq: 0.038370
[14:14:26.059] iteration 12873: loss: 0.037615, loss_s1: 0.012622, loss_fp: 0.000385, loss_freq: 0.022568
[14:14:26.747] iteration 12874: loss: 0.074265, loss_s1: 0.036412, loss_fp: 0.001979, loss_freq: 0.043176
[14:14:27.411] iteration 12875: loss: 0.083112, loss_s1: 0.053198, loss_fp: 0.004821, loss_freq: 0.062402
[14:14:28.074] iteration 12876: loss: 0.053185, loss_s1: 0.006814, loss_fp: 0.000548, loss_freq: 0.002293
[14:14:28.708] iteration 12877: loss: 0.042289, loss_s1: 0.019196, loss_fp: 0.001842, loss_freq: 0.016975
[14:14:29.338] iteration 12878: loss: 0.134496, loss_s1: 0.098942, loss_fp: 0.003507, loss_freq: 0.050394
[14:14:30.021] iteration 12879: loss: 0.071217, loss_s1: 0.039327, loss_fp: 0.016554, loss_freq: 0.039827
[14:14:30.681] iteration 12880: loss: 0.055109, loss_s1: 0.013238, loss_fp: 0.002864, loss_freq: 0.012409
[14:14:31.344] iteration 12881: loss: 0.067802, loss_s1: 0.033570, loss_fp: 0.001502, loss_freq: 0.050087
[14:14:32.001] iteration 12882: loss: 0.052221, loss_s1: 0.043190, loss_fp: 0.000699, loss_freq: 0.007326
[14:14:32.659] iteration 12883: loss: 0.073329, loss_s1: 0.062185, loss_fp: 0.010944, loss_freq: 0.013578
[14:14:33.311] iteration 12884: loss: 0.050378, loss_s1: 0.015611, loss_fp: 0.001762, loss_freq: 0.030822
[14:14:33.937] iteration 12885: loss: 0.058237, loss_s1: 0.025760, loss_fp: 0.002202, loss_freq: 0.039461
[14:14:34.569] iteration 12886: loss: 0.044165, loss_s1: 0.021811, loss_fp: 0.001544, loss_freq: 0.008332
[14:14:35.200] iteration 12887: loss: 0.073587, loss_s1: 0.037426, loss_fp: 0.002150, loss_freq: 0.030846
[14:14:35.825] iteration 12888: loss: 0.041869, loss_s1: 0.021761, loss_fp: 0.004474, loss_freq: 0.011194
[14:14:36.449] iteration 12889: loss: 0.045898, loss_s1: 0.025855, loss_fp: 0.001982, loss_freq: 0.022380
[14:14:37.077] iteration 12890: loss: 0.046558, loss_s1: 0.032249, loss_fp: 0.000845, loss_freq: 0.011988
[14:14:37.699] iteration 12891: loss: 0.167154, loss_s1: 0.047600, loss_fp: 0.000749, loss_freq: 0.072220
[14:14:38.318] iteration 12892: loss: 0.049489, loss_s1: 0.028112, loss_fp: 0.000947, loss_freq: 0.029968
[14:14:38.941] iteration 12893: loss: 0.053983, loss_s1: 0.016519, loss_fp: 0.000751, loss_freq: 0.040415
[14:14:39.570] iteration 12894: loss: 0.077100, loss_s1: 0.056763, loss_fp: 0.001732, loss_freq: 0.016128
[14:14:40.200] iteration 12895: loss: 0.051334, loss_s1: 0.040085, loss_fp: 0.000501, loss_freq: 0.011972
[14:14:40.828] iteration 12896: loss: 0.114974, loss_s1: 0.091536, loss_fp: 0.010702, loss_freq: 0.050649
[14:14:41.453] iteration 12897: loss: 0.106768, loss_s1: 0.076738, loss_fp: 0.006450, loss_freq: 0.058270
[14:14:42.075] iteration 12898: loss: 0.051232, loss_s1: 0.027133, loss_fp: 0.001860, loss_freq: 0.012091
[14:14:42.707] iteration 12899: loss: 0.057376, loss_s1: 0.035272, loss_fp: 0.000943, loss_freq: 0.017913
[14:14:43.330] iteration 12900: loss: 0.056765, loss_s1: 0.019525, loss_fp: 0.006083, loss_freq: 0.015433
[14:14:43.956] iteration 12901: loss: 0.066666, loss_s1: 0.049503, loss_fp: 0.000788, loss_freq: 0.033960
[14:14:44.582] iteration 12902: loss: 0.061941, loss_s1: 0.034537, loss_fp: 0.001964, loss_freq: 0.016953
[14:14:45.204] iteration 12903: loss: 0.066357, loss_s1: 0.039443, loss_fp: 0.009616, loss_freq: 0.034497
[14:14:45.838] iteration 12904: loss: 0.110702, loss_s1: 0.093821, loss_fp: 0.011752, loss_freq: 0.040066
[14:14:46.465] iteration 12905: loss: 0.106004, loss_s1: 0.024913, loss_fp: 0.007922, loss_freq: 0.037259
[14:14:47.092] iteration 12906: loss: 0.136156, loss_s1: 0.081123, loss_fp: 0.008403, loss_freq: 0.101958
[14:14:47.715] iteration 12907: loss: 0.065971, loss_s1: 0.046760, loss_fp: 0.001336, loss_freq: 0.034323
[14:14:48.341] iteration 12908: loss: 0.075334, loss_s1: 0.075439, loss_fp: 0.002048, loss_freq: 0.037786
[14:14:48.969] iteration 12909: loss: 0.124446, loss_s1: 0.087426, loss_fp: 0.002574, loss_freq: 0.072536
[14:14:49.595] iteration 12910: loss: 0.079236, loss_s1: 0.043246, loss_fp: 0.005565, loss_freq: 0.010175
[14:14:50.222] iteration 12911: loss: 0.092442, loss_s1: 0.052485, loss_fp: 0.010379, loss_freq: 0.018526
[14:14:50.845] iteration 12912: loss: 0.052548, loss_s1: 0.047613, loss_fp: 0.002498, loss_freq: 0.008679
[14:14:51.470] iteration 12913: loss: 0.051916, loss_s1: 0.026909, loss_fp: 0.002507, loss_freq: 0.005485
[14:14:52.092] iteration 12914: loss: 0.091261, loss_s1: 0.087210, loss_fp: 0.004734, loss_freq: 0.039638
[14:14:52.718] iteration 12915: loss: 0.058495, loss_s1: 0.013352, loss_fp: 0.000737, loss_freq: 0.008741
[14:14:53.379] iteration 12916: loss: 0.076012, loss_s1: 0.056655, loss_fp: 0.002833, loss_freq: 0.025008
[14:14:54.033] iteration 12917: loss: 0.082673, loss_s1: 0.034894, loss_fp: 0.001175, loss_freq: 0.031409
[14:14:54.690] iteration 12918: loss: 0.068878, loss_s1: 0.052623, loss_fp: 0.008455, loss_freq: 0.021190
[14:14:55.346] iteration 12919: loss: 0.069180, loss_s1: 0.060780, loss_fp: 0.002337, loss_freq: 0.035553
[14:14:55.994] iteration 12920: loss: 0.093313, loss_s1: 0.093143, loss_fp: 0.004694, loss_freq: 0.030470
[14:14:56.615] iteration 12921: loss: 0.059935, loss_s1: 0.030063, loss_fp: 0.017988, loss_freq: 0.015403
[14:14:57.239] iteration 12922: loss: 0.064111, loss_s1: 0.017358, loss_fp: 0.001831, loss_freq: 0.031105
[14:14:57.854] iteration 12923: loss: 0.046731, loss_s1: 0.044071, loss_fp: 0.001330, loss_freq: 0.003879
[14:14:58.484] iteration 12924: loss: 0.048194, loss_s1: 0.032986, loss_fp: 0.002255, loss_freq: 0.018263
[14:14:59.109] iteration 12925: loss: 0.050207, loss_s1: 0.032886, loss_fp: 0.000484, loss_freq: 0.012383
[14:14:59.728] iteration 12926: loss: 0.069604, loss_s1: 0.067408, loss_fp: 0.001398, loss_freq: 0.008081
[14:15:00.350] iteration 12927: loss: 0.106896, loss_s1: 0.095674, loss_fp: 0.002776, loss_freq: 0.053510
[14:15:00.993] iteration 12928: loss: 0.069047, loss_s1: 0.045942, loss_fp: 0.002586, loss_freq: 0.030387
[14:15:01.615] iteration 12929: loss: 0.103612, loss_s1: 0.039817, loss_fp: 0.004331, loss_freq: 0.053585
[14:15:02.249] iteration 12930: loss: 0.057166, loss_s1: 0.022696, loss_fp: 0.001897, loss_freq: 0.031946
[14:15:02.880] iteration 12931: loss: 0.086768, loss_s1: 0.015898, loss_fp: 0.006027, loss_freq: 0.032551
[14:15:03.550] iteration 12932: loss: 0.081894, loss_s1: 0.047859, loss_fp: 0.000960, loss_freq: 0.041280
[14:15:04.178] iteration 12933: loss: 0.078939, loss_s1: 0.041301, loss_fp: 0.002599, loss_freq: 0.061851
[14:15:04.812] iteration 12934: loss: 0.059189, loss_s1: 0.026333, loss_fp: 0.001132, loss_freq: 0.012820
[14:15:05.441] iteration 12935: loss: 0.076273, loss_s1: 0.028549, loss_fp: 0.000282, loss_freq: 0.047868
[14:15:06.070] iteration 12936: loss: 0.063275, loss_s1: 0.021432, loss_fp: 0.001688, loss_freq: 0.005535
[14:15:06.721] iteration 12937: loss: 0.120077, loss_s1: 0.074787, loss_fp: 0.011263, loss_freq: 0.054425
[14:15:07.343] iteration 12938: loss: 0.058544, loss_s1: 0.023255, loss_fp: 0.003217, loss_freq: 0.017703
[14:15:07.974] iteration 12939: loss: 0.068751, loss_s1: 0.057331, loss_fp: 0.003191, loss_freq: 0.020333
[14:15:08.601] iteration 12940: loss: 0.070896, loss_s1: 0.027183, loss_fp: 0.001598, loss_freq: 0.009617
[14:15:09.225] iteration 12941: loss: 0.074058, loss_s1: 0.030302, loss_fp: 0.001766, loss_freq: 0.032312
[14:15:09.851] iteration 12942: loss: 0.071688, loss_s1: 0.040451, loss_fp: 0.004821, loss_freq: 0.041582
[14:15:10.477] iteration 12943: loss: 0.073892, loss_s1: 0.029696, loss_fp: 0.002591, loss_freq: 0.067358
[14:15:11.112] iteration 12944: loss: 0.084969, loss_s1: 0.025296, loss_fp: 0.009822, loss_freq: 0.053719
[14:15:11.744] iteration 12945: loss: 0.057132, loss_s1: 0.038446, loss_fp: 0.001398, loss_freq: 0.035393
[14:15:12.376] iteration 12946: loss: 0.072751, loss_s1: 0.044519, loss_fp: 0.004170, loss_freq: 0.010625
[14:15:12.999] iteration 12947: loss: 0.052917, loss_s1: 0.041618, loss_fp: 0.010590, loss_freq: 0.004397
[14:15:13.637] iteration 12948: loss: 0.078468, loss_s1: 0.033001, loss_fp: 0.003325, loss_freq: 0.020142
[14:15:14.268] iteration 12949: loss: 0.106392, loss_s1: 0.113909, loss_fp: 0.006535, loss_freq: 0.039867
[14:15:14.898] iteration 12950: loss: 0.084188, loss_s1: 0.064028, loss_fp: 0.001656, loss_freq: 0.029092
[14:15:15.561] iteration 12951: loss: 0.076832, loss_s1: 0.039662, loss_fp: 0.007060, loss_freq: 0.049839
[14:15:16.213] iteration 12952: loss: 0.094692, loss_s1: 0.090605, loss_fp: 0.004804, loss_freq: 0.036616
[14:15:16.850] iteration 12953: loss: 0.061815, loss_s1: 0.031011, loss_fp: 0.002607, loss_freq: 0.027732
[14:15:17.472] iteration 12954: loss: 0.055599, loss_s1: 0.050190, loss_fp: 0.003510, loss_freq: 0.020513
[14:15:18.101] iteration 12955: loss: 0.087369, loss_s1: 0.050624, loss_fp: 0.004119, loss_freq: 0.022980
[14:15:18.730] iteration 12956: loss: 0.096117, loss_s1: 0.071352, loss_fp: 0.001848, loss_freq: 0.068044
[14:15:19.356] iteration 12957: loss: 0.049800, loss_s1: 0.018427, loss_fp: 0.002589, loss_freq: 0.015344
[14:15:19.980] iteration 12958: loss: 0.065000, loss_s1: 0.020475, loss_fp: 0.002072, loss_freq: 0.022156
[14:15:20.607] iteration 12959: loss: 0.054218, loss_s1: 0.056535, loss_fp: 0.001737, loss_freq: 0.015575
[14:15:21.229] iteration 12960: loss: 0.083731, loss_s1: 0.079304, loss_fp: 0.007615, loss_freq: 0.038612
[14:15:21.884] iteration 12961: loss: 0.057097, loss_s1: 0.019298, loss_fp: 0.001617, loss_freq: 0.017125
[14:15:22.541] iteration 12962: loss: 0.067202, loss_s1: 0.042125, loss_fp: 0.002087, loss_freq: 0.046103
[14:15:23.200] iteration 12963: loss: 0.058896, loss_s1: 0.030142, loss_fp: 0.003354, loss_freq: 0.024499
[14:15:23.855] iteration 12964: loss: 0.043813, loss_s1: 0.021625, loss_fp: 0.008252, loss_freq: 0.013634
[14:15:24.489] iteration 12965: loss: 0.065828, loss_s1: 0.028875, loss_fp: 0.001939, loss_freq: 0.025627
[14:15:25.114] iteration 12966: loss: 0.074686, loss_s1: 0.050611, loss_fp: 0.007904, loss_freq: 0.032793
[14:15:25.730] iteration 12967: loss: 0.127522, loss_s1: 0.065991, loss_fp: 0.003275, loss_freq: 0.115986
[14:15:26.358] iteration 12968: loss: 0.049630, loss_s1: 0.025964, loss_fp: 0.002007, loss_freq: 0.024685
[14:15:26.984] iteration 12969: loss: 0.053728, loss_s1: 0.020012, loss_fp: 0.004541, loss_freq: 0.012926
[14:15:27.611] iteration 12970: loss: 0.081313, loss_s1: 0.031265, loss_fp: 0.001292, loss_freq: 0.037568
[14:15:28.240] iteration 12971: loss: 0.075201, loss_s1: 0.071145, loss_fp: 0.002281, loss_freq: 0.020471
[14:15:28.862] iteration 12972: loss: 0.092065, loss_s1: 0.037459, loss_fp: 0.002328, loss_freq: 0.065094
[14:15:29.495] iteration 12973: loss: 0.042894, loss_s1: 0.032979, loss_fp: 0.003653, loss_freq: 0.014423
[14:15:30.122] iteration 12974: loss: 0.078767, loss_s1: 0.050911, loss_fp: 0.007434, loss_freq: 0.041401
[14:15:30.753] iteration 12975: loss: 0.070004, loss_s1: 0.029308, loss_fp: 0.003465, loss_freq: 0.027644
[14:15:31.390] iteration 12976: loss: 0.062524, loss_s1: 0.017689, loss_fp: 0.001700, loss_freq: 0.020109
[14:15:32.050] iteration 12977: loss: 0.081638, loss_s1: 0.050875, loss_fp: 0.001992, loss_freq: 0.041194
[14:15:32.759] iteration 12978: loss: 0.065853, loss_s1: 0.063423, loss_fp: 0.003691, loss_freq: 0.019926
[14:15:33.428] iteration 12979: loss: 0.098856, loss_s1: 0.092415, loss_fp: 0.002714, loss_freq: 0.019338
[14:15:34.085] iteration 12980: loss: 0.081696, loss_s1: 0.117701, loss_fp: 0.003655, loss_freq: 0.010412
[14:15:34.717] iteration 12981: loss: 0.070566, loss_s1: 0.036564, loss_fp: 0.002984, loss_freq: 0.006495
[14:15:35.344] iteration 12982: loss: 0.054141, loss_s1: 0.053456, loss_fp: 0.001360, loss_freq: 0.019251
[14:15:35.977] iteration 12983: loss: 0.084614, loss_s1: 0.072328, loss_fp: 0.000839, loss_freq: 0.011059
[14:15:36.603] iteration 12984: loss: 0.094180, loss_s1: 0.108502, loss_fp: 0.009325, loss_freq: 0.013327
[14:15:37.229] iteration 12985: loss: 0.093577, loss_s1: 0.021227, loss_fp: 0.012105, loss_freq: 0.035831
[14:15:37.845] iteration 12986: loss: 0.080787, loss_s1: 0.092588, loss_fp: 0.001262, loss_freq: 0.018061
[14:15:38.469] iteration 12987: loss: 0.076236, loss_s1: 0.047244, loss_fp: 0.002005, loss_freq: 0.036963
[14:15:39.089] iteration 12988: loss: 0.111941, loss_s1: 0.104888, loss_fp: 0.009843, loss_freq: 0.022203
[14:15:39.712] iteration 12989: loss: 0.061263, loss_s1: 0.059371, loss_fp: 0.003518, loss_freq: 0.014898
[14:15:40.330] iteration 12990: loss: 0.074693, loss_s1: 0.057172, loss_fp: 0.003558, loss_freq: 0.025025
[14:15:40.960] iteration 12991: loss: 0.094253, loss_s1: 0.086020, loss_fp: 0.005184, loss_freq: 0.052972
[14:15:41.590] iteration 12992: loss: 0.072212, loss_s1: 0.041490, loss_fp: 0.001103, loss_freq: 0.018537
[14:15:42.257] iteration 12993: loss: 0.051518, loss_s1: 0.028872, loss_fp: 0.001846, loss_freq: 0.003161
[14:15:42.917] iteration 12994: loss: 0.050947, loss_s1: 0.025696, loss_fp: 0.007693, loss_freq: 0.019271
[14:15:43.551] iteration 12995: loss: 0.065731, loss_s1: 0.035583, loss_fp: 0.004366, loss_freq: 0.048908
[14:15:44.185] iteration 12996: loss: 0.077136, loss_s1: 0.023626, loss_fp: 0.008257, loss_freq: 0.020422
[14:15:44.807] iteration 12997: loss: 0.110224, loss_s1: 0.109655, loss_fp: 0.000884, loss_freq: 0.026328
[14:15:45.436] iteration 12998: loss: 0.057263, loss_s1: 0.041331, loss_fp: 0.007266, loss_freq: 0.027912
[14:15:46.065] iteration 12999: loss: 0.069612, loss_s1: 0.051842, loss_fp: 0.008905, loss_freq: 0.016415
[14:15:46.692] iteration 13000: loss: 0.047610, loss_s1: 0.018699, loss_fp: 0.003518, loss_freq: 0.013337
[14:15:50.000] iteration 13000 : mean_dice : 0.762175
[14:15:50.671] iteration 13001: loss: 0.092143, loss_s1: 0.066198, loss_fp: 0.002299, loss_freq: 0.017128
[14:15:51.286] iteration 13002: loss: 0.139032, loss_s1: 0.035940, loss_fp: 0.002038, loss_freq: 0.024099
[14:15:51.905] iteration 13003: loss: 0.096776, loss_s1: 0.082117, loss_fp: 0.006683, loss_freq: 0.038349
[14:15:52.523] iteration 13004: loss: 0.074129, loss_s1: 0.022699, loss_fp: 0.001123, loss_freq: 0.042587
[14:15:53.152] iteration 13005: loss: 0.197823, loss_s1: 0.059165, loss_fp: 0.010735, loss_freq: 0.045263
[14:15:53.777] iteration 13006: loss: 0.084604, loss_s1: 0.059218, loss_fp: 0.001233, loss_freq: 0.024935
[14:15:54.403] iteration 13007: loss: 0.061072, loss_s1: 0.039073, loss_fp: 0.001660, loss_freq: 0.030226
[14:15:55.026] iteration 13008: loss: 0.028607, loss_s1: 0.003191, loss_fp: 0.001035, loss_freq: 0.005036
[14:15:55.679] iteration 13009: loss: 0.061658, loss_s1: 0.047260, loss_fp: 0.000618, loss_freq: 0.019854
[14:15:56.343] iteration 13010: loss: 0.082825, loss_s1: 0.052196, loss_fp: 0.002727, loss_freq: 0.006054
[14:15:56.999] iteration 13011: loss: 0.089208, loss_s1: 0.017440, loss_fp: 0.003100, loss_freq: 0.059637
[14:15:57.639] iteration 13012: loss: 0.101106, loss_s1: 0.086526, loss_fp: 0.025588, loss_freq: 0.025977
[14:15:58.263] iteration 13013: loss: 0.065618, loss_s1: 0.048429, loss_fp: 0.001052, loss_freq: 0.008634
[14:15:59.257] iteration 13014: loss: 0.064843, loss_s1: 0.034059, loss_fp: 0.002115, loss_freq: 0.017375
[14:15:59.890] iteration 13015: loss: 0.046878, loss_s1: 0.022230, loss_fp: 0.003321, loss_freq: 0.017616
[14:16:00.547] iteration 13016: loss: 0.036026, loss_s1: 0.018055, loss_fp: 0.001213, loss_freq: 0.010995
[14:16:01.168] iteration 13017: loss: 0.059638, loss_s1: 0.048039, loss_fp: 0.001343, loss_freq: 0.010270
[14:16:01.800] iteration 13018: loss: 0.088770, loss_s1: 0.098468, loss_fp: 0.002006, loss_freq: 0.032636
[14:16:02.438] iteration 13019: loss: 0.045368, loss_s1: 0.026637, loss_fp: 0.000953, loss_freq: 0.002785
[14:16:03.078] iteration 13020: loss: 0.071090, loss_s1: 0.077816, loss_fp: 0.000473, loss_freq: 0.025460
[14:16:03.724] iteration 13021: loss: 0.103926, loss_s1: 0.041106, loss_fp: 0.002465, loss_freq: 0.034343
[14:16:04.366] iteration 13022: loss: 0.049678, loss_s1: 0.021759, loss_fp: 0.000767, loss_freq: 0.013993
[14:16:05.003] iteration 13023: loss: 0.065660, loss_s1: 0.007473, loss_fp: 0.000579, loss_freq: 0.003366
[14:16:05.641] iteration 13024: loss: 0.084522, loss_s1: 0.081052, loss_fp: 0.001157, loss_freq: 0.044729
[14:16:06.303] iteration 13025: loss: 0.051515, loss_s1: 0.032782, loss_fp: 0.002146, loss_freq: 0.010719
[14:16:06.984] iteration 13026: loss: 0.086905, loss_s1: 0.098027, loss_fp: 0.002797, loss_freq: 0.011337
[14:16:07.624] iteration 13027: loss: 0.059174, loss_s1: 0.038782, loss_fp: 0.001200, loss_freq: 0.024914
[14:16:08.276] iteration 13028: loss: 0.071053, loss_s1: 0.069269, loss_fp: 0.002198, loss_freq: 0.028059
[14:16:08.912] iteration 13029: loss: 0.067552, loss_s1: 0.041899, loss_fp: 0.009319, loss_freq: 0.017558
[14:16:09.548] iteration 13030: loss: 0.069412, loss_s1: 0.046067, loss_fp: 0.000986, loss_freq: 0.043076
[14:16:10.228] iteration 13031: loss: 0.036555, loss_s1: 0.020053, loss_fp: 0.003179, loss_freq: 0.012444
[14:16:10.889] iteration 13032: loss: 0.051074, loss_s1: 0.032950, loss_fp: 0.001375, loss_freq: 0.020198
[14:16:11.546] iteration 13033: loss: 0.067822, loss_s1: 0.070021, loss_fp: 0.005043, loss_freq: 0.018972
[14:16:12.203] iteration 13034: loss: 0.097662, loss_s1: 0.047330, loss_fp: 0.001382, loss_freq: 0.027470
[14:16:12.864] iteration 13035: loss: 0.056162, loss_s1: 0.014493, loss_fp: 0.002001, loss_freq: 0.019396
[14:16:13.499] iteration 13036: loss: 0.063786, loss_s1: 0.020656, loss_fp: 0.001796, loss_freq: 0.041490
[14:16:14.118] iteration 13037: loss: 0.054772, loss_s1: 0.027632, loss_fp: 0.005780, loss_freq: 0.013904
[14:16:14.755] iteration 13038: loss: 0.055059, loss_s1: 0.056439, loss_fp: 0.003055, loss_freq: 0.008030
[14:16:15.453] iteration 13039: loss: 0.075802, loss_s1: 0.049400, loss_fp: 0.006738, loss_freq: 0.025798
[14:16:16.118] iteration 13040: loss: 0.099189, loss_s1: 0.055735, loss_fp: 0.003635, loss_freq: 0.068545
[14:16:16.796] iteration 13041: loss: 0.067810, loss_s1: 0.061691, loss_fp: 0.002689, loss_freq: 0.018502
[14:16:17.477] iteration 13042: loss: 0.115182, loss_s1: 0.068084, loss_fp: 0.002292, loss_freq: 0.046448
[14:16:18.142] iteration 13043: loss: 0.084847, loss_s1: 0.060790, loss_fp: 0.002182, loss_freq: 0.008403
[14:16:18.789] iteration 13044: loss: 0.105877, loss_s1: 0.046693, loss_fp: 0.001693, loss_freq: 0.019885
[14:16:19.414] iteration 13045: loss: 0.092721, loss_s1: 0.088962, loss_fp: 0.001300, loss_freq: 0.036333
[14:16:20.040] iteration 13046: loss: 0.042782, loss_s1: 0.031463, loss_fp: 0.003155, loss_freq: 0.011457
[14:16:20.663] iteration 13047: loss: 0.101711, loss_s1: 0.080649, loss_fp: 0.007577, loss_freq: 0.071170
[14:16:21.291] iteration 13048: loss: 0.079344, loss_s1: 0.036282, loss_fp: 0.004516, loss_freq: 0.036667
[14:16:21.920] iteration 13049: loss: 0.068144, loss_s1: 0.037790, loss_fp: 0.002064, loss_freq: 0.040825
[14:16:22.552] iteration 13050: loss: 0.083605, loss_s1: 0.049974, loss_fp: 0.008350, loss_freq: 0.036092
[14:16:23.180] iteration 13051: loss: 0.056798, loss_s1: 0.028656, loss_fp: 0.006593, loss_freq: 0.035014
[14:16:23.813] iteration 13052: loss: 0.088837, loss_s1: 0.048905, loss_fp: 0.007751, loss_freq: 0.050311
[14:16:24.476] iteration 13053: loss: 0.036515, loss_s1: 0.021558, loss_fp: 0.001650, loss_freq: 0.008587
[14:16:25.125] iteration 13054: loss: 0.080189, loss_s1: 0.009245, loss_fp: 0.001024, loss_freq: 0.032169
[14:16:25.774] iteration 13055: loss: 0.059691, loss_s1: 0.034943, loss_fp: 0.001516, loss_freq: 0.024994
[14:16:26.400] iteration 13056: loss: 0.052434, loss_s1: 0.017868, loss_fp: 0.002750, loss_freq: 0.010824
[14:16:27.037] iteration 13057: loss: 0.107860, loss_s1: 0.113605, loss_fp: 0.006613, loss_freq: 0.044199
[14:16:27.711] iteration 13058: loss: 0.061968, loss_s1: 0.012523, loss_fp: 0.000606, loss_freq: 0.017504
[14:16:28.360] iteration 13059: loss: 0.085937, loss_s1: 0.051808, loss_fp: 0.001027, loss_freq: 0.059079
[14:16:28.987] iteration 13060: loss: 0.055929, loss_s1: 0.009596, loss_fp: 0.001642, loss_freq: 0.021695
[14:16:29.607] iteration 13061: loss: 0.056248, loss_s1: 0.039046, loss_fp: 0.002262, loss_freq: 0.023369
[14:16:30.230] iteration 13062: loss: 0.058863, loss_s1: 0.067926, loss_fp: 0.001117, loss_freq: 0.006601
[14:16:30.920] iteration 13063: loss: 0.059452, loss_s1: 0.038784, loss_fp: 0.001603, loss_freq: 0.027913
[14:16:31.582] iteration 13064: loss: 0.069076, loss_s1: 0.047655, loss_fp: 0.011955, loss_freq: 0.017402
[14:16:32.246] iteration 13065: loss: 0.071205, loss_s1: 0.055660, loss_fp: 0.000621, loss_freq: 0.030287
[14:16:32.905] iteration 13066: loss: 0.044193, loss_s1: 0.032275, loss_fp: 0.002379, loss_freq: 0.014043
[14:16:33.575] iteration 13067: loss: 0.052929, loss_s1: 0.042142, loss_fp: 0.002028, loss_freq: 0.018549
[14:16:34.209] iteration 13068: loss: 0.055343, loss_s1: 0.043124, loss_fp: 0.000691, loss_freq: 0.008185
[14:16:34.846] iteration 13069: loss: 0.060511, loss_s1: 0.017197, loss_fp: 0.000583, loss_freq: 0.007890
[14:16:35.491] iteration 13070: loss: 0.095134, loss_s1: 0.098387, loss_fp: 0.004109, loss_freq: 0.017528
[14:16:36.180] iteration 13071: loss: 0.084282, loss_s1: 0.055666, loss_fp: 0.001712, loss_freq: 0.048661
[14:16:36.837] iteration 13072: loss: 0.078059, loss_s1: 0.019794, loss_fp: 0.008369, loss_freq: 0.052710
[14:16:37.497] iteration 13073: loss: 0.069135, loss_s1: 0.025795, loss_fp: 0.002792, loss_freq: 0.048826
[14:16:38.158] iteration 13074: loss: 0.048787, loss_s1: 0.027555, loss_fp: 0.003011, loss_freq: 0.017400
[14:16:38.816] iteration 13075: loss: 0.044870, loss_s1: 0.026556, loss_fp: 0.000632, loss_freq: 0.014290
[14:16:39.472] iteration 13076: loss: 0.084302, loss_s1: 0.074297, loss_fp: 0.001735, loss_freq: 0.040289
[14:16:40.154] iteration 13077: loss: 0.065083, loss_s1: 0.029863, loss_fp: 0.008069, loss_freq: 0.014429
[14:16:40.828] iteration 13078: loss: 0.077427, loss_s1: 0.034326, loss_fp: 0.002611, loss_freq: 0.044929
[14:16:41.500] iteration 13079: loss: 0.096249, loss_s1: 0.053930, loss_fp: 0.008838, loss_freq: 0.022096
[14:16:42.128] iteration 13080: loss: 0.088632, loss_s1: 0.054628, loss_fp: 0.003687, loss_freq: 0.056919
[14:16:42.753] iteration 13081: loss: 0.051234, loss_s1: 0.025312, loss_fp: 0.010291, loss_freq: 0.015643
[14:16:43.386] iteration 13082: loss: 0.086947, loss_s1: 0.091955, loss_fp: 0.002101, loss_freq: 0.016088
[14:16:44.018] iteration 13083: loss: 0.115175, loss_s1: 0.038382, loss_fp: 0.000333, loss_freq: 0.034438
[14:16:44.707] iteration 13084: loss: 0.097957, loss_s1: 0.072021, loss_fp: 0.001642, loss_freq: 0.029902
[14:16:45.368] iteration 13085: loss: 0.085724, loss_s1: 0.035602, loss_fp: 0.003520, loss_freq: 0.070790
[14:16:46.042] iteration 13086: loss: 0.089555, loss_s1: 0.055162, loss_fp: 0.001335, loss_freq: 0.038843
[14:16:46.714] iteration 13087: loss: 0.096696, loss_s1: 0.078128, loss_fp: 0.004014, loss_freq: 0.032955
[14:16:47.347] iteration 13088: loss: 0.055382, loss_s1: 0.026165, loss_fp: 0.005116, loss_freq: 0.036262
[14:16:47.984] iteration 13089: loss: 0.082177, loss_s1: 0.043828, loss_fp: 0.005486, loss_freq: 0.016836
[14:16:48.618] iteration 13090: loss: 0.072859, loss_s1: 0.059782, loss_fp: 0.009510, loss_freq: 0.016585
[14:16:49.245] iteration 13091: loss: 0.068612, loss_s1: 0.044575, loss_fp: 0.001350, loss_freq: 0.006760
[14:16:49.872] iteration 13092: loss: 0.068633, loss_s1: 0.030452, loss_fp: 0.002380, loss_freq: 0.048245
[14:16:50.503] iteration 13093: loss: 0.142022, loss_s1: 0.120758, loss_fp: 0.001960, loss_freq: 0.034091
[14:16:51.130] iteration 13094: loss: 0.080604, loss_s1: 0.034690, loss_fp: 0.001958, loss_freq: 0.036815
[14:16:51.747] iteration 13095: loss: 0.086872, loss_s1: 0.059461, loss_fp: 0.007437, loss_freq: 0.041490
[14:16:52.374] iteration 13096: loss: 0.078938, loss_s1: 0.057679, loss_fp: 0.002448, loss_freq: 0.017615
[14:16:53.001] iteration 13097: loss: 0.060581, loss_s1: 0.053241, loss_fp: 0.001944, loss_freq: 0.027563
[14:16:53.628] iteration 13098: loss: 0.045837, loss_s1: 0.024311, loss_fp: 0.002070, loss_freq: 0.006576
[14:16:54.249] iteration 13099: loss: 0.075122, loss_s1: 0.039898, loss_fp: 0.004948, loss_freq: 0.048659
[14:16:54.877] iteration 13100: loss: 0.095189, loss_s1: 0.074237, loss_fp: 0.002790, loss_freq: 0.024712
[14:16:55.514] iteration 13101: loss: 0.051420, loss_s1: 0.020904, loss_fp: 0.001311, loss_freq: 0.014166
[14:16:56.181] iteration 13102: loss: 0.033770, loss_s1: 0.014039, loss_fp: 0.001426, loss_freq: 0.010777
[14:16:56.844] iteration 13103: loss: 0.059364, loss_s1: 0.035880, loss_fp: 0.005302, loss_freq: 0.036247
[14:16:57.514] iteration 13104: loss: 0.066623, loss_s1: 0.026583, loss_fp: 0.005063, loss_freq: 0.021313
[14:16:58.174] iteration 13105: loss: 0.064272, loss_s1: 0.041553, loss_fp: 0.000858, loss_freq: 0.023520
[14:16:58.851] iteration 13106: loss: 0.060583, loss_s1: 0.040899, loss_fp: 0.001220, loss_freq: 0.016506
[14:16:59.512] iteration 13107: loss: 0.052552, loss_s1: 0.025880, loss_fp: 0.001877, loss_freq: 0.013016
[14:17:00.188] iteration 13108: loss: 0.041117, loss_s1: 0.016867, loss_fp: 0.001500, loss_freq: 0.003751
[14:17:00.846] iteration 13109: loss: 0.085017, loss_s1: 0.072571, loss_fp: 0.001000, loss_freq: 0.048204
[14:17:01.499] iteration 13110: loss: 0.123510, loss_s1: 0.059829, loss_fp: 0.012687, loss_freq: 0.062121
[14:17:02.157] iteration 13111: loss: 0.064272, loss_s1: 0.040258, loss_fp: 0.016846, loss_freq: 0.017357
[14:17:02.799] iteration 13112: loss: 0.105984, loss_s1: 0.065091, loss_fp: 0.005840, loss_freq: 0.019066
[14:17:03.423] iteration 13113: loss: 0.138988, loss_s1: 0.014198, loss_fp: 0.001459, loss_freq: 0.033824
[14:17:04.073] iteration 13114: loss: 0.061582, loss_s1: 0.048253, loss_fp: 0.002860, loss_freq: 0.026143
[14:17:04.926] iteration 13115: loss: 0.076111, loss_s1: 0.036551, loss_fp: 0.000987, loss_freq: 0.015245
[14:17:05.544] iteration 13116: loss: 0.049826, loss_s1: 0.031001, loss_fp: 0.002429, loss_freq: 0.024173
[14:17:06.391] iteration 13117: loss: 0.041362, loss_s1: 0.023105, loss_fp: 0.003998, loss_freq: 0.014786
[14:17:07.031] iteration 13118: loss: 0.093375, loss_s1: 0.051650, loss_fp: 0.001423, loss_freq: 0.023504
[14:17:07.662] iteration 13119: loss: 0.071072, loss_s1: 0.023640, loss_fp: 0.001213, loss_freq: 0.036018
[14:17:08.294] iteration 13120: loss: 0.107585, loss_s1: 0.060554, loss_fp: 0.002837, loss_freq: 0.076434
[14:17:08.928] iteration 13121: loss: 0.045067, loss_s1: 0.013270, loss_fp: 0.002051, loss_freq: 0.029054
[14:17:09.545] iteration 13122: loss: 0.063202, loss_s1: 0.030552, loss_fp: 0.002169, loss_freq: 0.027897
[14:17:10.171] iteration 13123: loss: 0.062152, loss_s1: 0.034089, loss_fp: 0.001992, loss_freq: 0.040073
[14:17:10.786] iteration 13124: loss: 0.048955, loss_s1: 0.022692, loss_fp: 0.000543, loss_freq: 0.007732
[14:17:11.407] iteration 13125: loss: 0.091110, loss_s1: 0.091035, loss_fp: 0.001375, loss_freq: 0.044549
[14:17:12.056] iteration 13126: loss: 0.083349, loss_s1: 0.055707, loss_fp: 0.001823, loss_freq: 0.008906
[14:17:12.698] iteration 13127: loss: 0.062086, loss_s1: 0.053196, loss_fp: 0.002458, loss_freq: 0.010643
[14:17:13.350] iteration 13128: loss: 0.115521, loss_s1: 0.025797, loss_fp: 0.001490, loss_freq: 0.022149
[14:17:13.996] iteration 13129: loss: 0.069576, loss_s1: 0.066278, loss_fp: 0.000382, loss_freq: 0.007425
[14:17:14.652] iteration 13130: loss: 0.058518, loss_s1: 0.012320, loss_fp: 0.000944, loss_freq: 0.054460
[14:17:15.309] iteration 13131: loss: 0.061299, loss_s1: 0.057515, loss_fp: 0.001520, loss_freq: 0.018780
[14:17:15.964] iteration 13132: loss: 0.039236, loss_s1: 0.027588, loss_fp: 0.004646, loss_freq: 0.007327
[14:17:16.640] iteration 13133: loss: 0.062012, loss_s1: 0.046057, loss_fp: 0.000407, loss_freq: 0.027107
[14:17:17.313] iteration 13134: loss: 0.065208, loss_s1: 0.025241, loss_fp: 0.007822, loss_freq: 0.024039
[14:17:17.947] iteration 13135: loss: 0.131793, loss_s1: 0.052215, loss_fp: 0.000819, loss_freq: 0.044724
[14:17:18.579] iteration 13136: loss: 0.053953, loss_s1: 0.040655, loss_fp: 0.003482, loss_freq: 0.020053
[14:17:19.200] iteration 13137: loss: 0.089296, loss_s1: 0.055181, loss_fp: 0.001463, loss_freq: 0.072821
[14:17:19.825] iteration 13138: loss: 0.057982, loss_s1: 0.031412, loss_fp: 0.003502, loss_freq: 0.035539
[14:17:20.457] iteration 13139: loss: 0.050460, loss_s1: 0.023333, loss_fp: 0.003772, loss_freq: 0.011015
[14:17:21.089] iteration 13140: loss: 0.070964, loss_s1: 0.038562, loss_fp: 0.001326, loss_freq: 0.062088
[14:17:21.712] iteration 13141: loss: 0.051914, loss_s1: 0.028528, loss_fp: 0.002744, loss_freq: 0.025014
[14:17:22.331] iteration 13142: loss: 0.093079, loss_s1: 0.033175, loss_fp: 0.003360, loss_freq: 0.008500
[14:17:22.964] iteration 13143: loss: 0.076999, loss_s1: 0.071645, loss_fp: 0.002266, loss_freq: 0.025416
[14:17:23.591] iteration 13144: loss: 0.078040, loss_s1: 0.045682, loss_fp: 0.005470, loss_freq: 0.029449
[14:17:24.228] iteration 13145: loss: 0.138823, loss_s1: 0.069314, loss_fp: 0.009481, loss_freq: 0.052596
[14:17:24.857] iteration 13146: loss: 0.077993, loss_s1: 0.053606, loss_fp: 0.001033, loss_freq: 0.019974
[14:17:25.519] iteration 13147: loss: 0.063959, loss_s1: 0.018680, loss_fp: 0.001160, loss_freq: 0.042048
[14:17:26.171] iteration 13148: loss: 0.093450, loss_s1: 0.033549, loss_fp: 0.003910, loss_freq: 0.038619
[14:17:26.801] iteration 13149: loss: 0.080820, loss_s1: 0.052911, loss_fp: 0.004346, loss_freq: 0.018379
[14:17:27.428] iteration 13150: loss: 0.096031, loss_s1: 0.093754, loss_fp: 0.006739, loss_freq: 0.017006
[14:17:28.058] iteration 13151: loss: 0.056607, loss_s1: 0.041372, loss_fp: 0.002007, loss_freq: 0.011232
[14:17:28.680] iteration 13152: loss: 0.067085, loss_s1: 0.054622, loss_fp: 0.001391, loss_freq: 0.009871
[14:17:29.298] iteration 13153: loss: 0.051482, loss_s1: 0.014693, loss_fp: 0.001056, loss_freq: 0.011721
[14:17:29.919] iteration 13154: loss: 0.072910, loss_s1: 0.034646, loss_fp: 0.001315, loss_freq: 0.038604
[14:17:30.536] iteration 13155: loss: 0.089952, loss_s1: 0.080064, loss_fp: 0.006945, loss_freq: 0.037989
[14:17:31.158] iteration 13156: loss: 0.055279, loss_s1: 0.042630, loss_fp: 0.002241, loss_freq: 0.023601
[14:17:32.078] iteration 13157: loss: 0.057969, loss_s1: 0.041974, loss_fp: 0.003318, loss_freq: 0.022219
[14:17:32.740] iteration 13158: loss: 0.063895, loss_s1: 0.027858, loss_fp: 0.001888, loss_freq: 0.034767
[14:17:33.377] iteration 13159: loss: 0.065112, loss_s1: 0.033664, loss_fp: 0.001770, loss_freq: 0.039645
[14:17:34.009] iteration 13160: loss: 0.049967, loss_s1: 0.027454, loss_fp: 0.001878, loss_freq: 0.018493
[14:17:34.645] iteration 13161: loss: 0.065473, loss_s1: 0.037479, loss_fp: 0.001532, loss_freq: 0.036885
[14:17:35.270] iteration 13162: loss: 0.050808, loss_s1: 0.013061, loss_fp: 0.001318, loss_freq: 0.010856
[14:17:35.898] iteration 13163: loss: 0.042813, loss_s1: 0.028213, loss_fp: 0.002313, loss_freq: 0.017613
[14:17:36.526] iteration 13164: loss: 0.080005, loss_s1: 0.039923, loss_fp: 0.006210, loss_freq: 0.018605
[14:17:37.157] iteration 13165: loss: 0.081611, loss_s1: 0.039053, loss_fp: 0.001630, loss_freq: 0.064919
[14:17:37.784] iteration 13166: loss: 0.057639, loss_s1: 0.008422, loss_fp: 0.000830, loss_freq: 0.016456
[14:17:38.406] iteration 13167: loss: 0.083223, loss_s1: 0.048770, loss_fp: 0.004009, loss_freq: 0.047791
[14:17:39.033] iteration 13168: loss: 0.077090, loss_s1: 0.054192, loss_fp: 0.001279, loss_freq: 0.023288
[14:17:39.671] iteration 13169: loss: 0.084926, loss_s1: 0.062573, loss_fp: 0.001915, loss_freq: 0.015321
[14:17:40.300] iteration 13170: loss: 0.045332, loss_s1: 0.025992, loss_fp: 0.001696, loss_freq: 0.018371
[14:17:40.940] iteration 13171: loss: 0.109073, loss_s1: 0.135134, loss_fp: 0.007503, loss_freq: 0.020285
[14:17:41.560] iteration 13172: loss: 0.040590, loss_s1: 0.013667, loss_fp: 0.002428, loss_freq: 0.011006
[14:17:42.215] iteration 13173: loss: 0.058238, loss_s1: 0.020898, loss_fp: 0.002360, loss_freq: 0.016820
[14:17:42.845] iteration 13174: loss: 0.060726, loss_s1: 0.042850, loss_fp: 0.003753, loss_freq: 0.023786
[14:17:43.474] iteration 13175: loss: 0.054731, loss_s1: 0.033955, loss_fp: 0.007537, loss_freq: 0.023361
[14:17:44.122] iteration 13176: loss: 0.050612, loss_s1: 0.053692, loss_fp: 0.005256, loss_freq: 0.009643
[14:17:44.760] iteration 13177: loss: 0.134918, loss_s1: 0.045430, loss_fp: 0.001892, loss_freq: 0.064378
[14:17:45.385] iteration 13178: loss: 0.040705, loss_s1: 0.017861, loss_fp: 0.003805, loss_freq: 0.018682
[14:17:46.030] iteration 13179: loss: 0.057526, loss_s1: 0.041463, loss_fp: 0.002166, loss_freq: 0.022478
[14:17:46.669] iteration 13180: loss: 0.075440, loss_s1: 0.025250, loss_fp: 0.003013, loss_freq: 0.008890
[14:17:47.306] iteration 13181: loss: 0.053703, loss_s1: 0.024430, loss_fp: 0.004806, loss_freq: 0.023192
[14:17:47.939] iteration 13182: loss: 0.069836, loss_s1: 0.067168, loss_fp: 0.001440, loss_freq: 0.021878
[14:17:48.567] iteration 13183: loss: 0.089713, loss_s1: 0.061181, loss_fp: 0.003022, loss_freq: 0.064609
[14:17:49.204] iteration 13184: loss: 0.045563, loss_s1: 0.022974, loss_fp: 0.001568, loss_freq: 0.018401
[14:17:49.841] iteration 13185: loss: 0.099166, loss_s1: 0.066709, loss_fp: 0.002802, loss_freq: 0.052246
[14:17:50.479] iteration 13186: loss: 0.103928, loss_s1: 0.071991, loss_fp: 0.001101, loss_freq: 0.010885
[14:17:51.118] iteration 13187: loss: 0.043127, loss_s1: 0.030812, loss_fp: 0.002083, loss_freq: 0.011432
[14:17:51.752] iteration 13188: loss: 0.117003, loss_s1: 0.044775, loss_fp: 0.025065, loss_freq: 0.015953
[14:17:52.395] iteration 13189: loss: 0.057568, loss_s1: 0.047574, loss_fp: 0.000816, loss_freq: 0.028687
[14:17:53.029] iteration 13190: loss: 0.104952, loss_s1: 0.081668, loss_fp: 0.002662, loss_freq: 0.059944
[14:17:53.660] iteration 13191: loss: 0.079561, loss_s1: 0.069695, loss_fp: 0.009878, loss_freq: 0.024896
[14:17:54.286] iteration 13192: loss: 0.076022, loss_s1: 0.069592, loss_fp: 0.003634, loss_freq: 0.020975
[14:17:54.924] iteration 13193: loss: 0.074576, loss_s1: 0.059232, loss_fp: 0.001919, loss_freq: 0.038675
[14:17:55.562] iteration 13194: loss: 0.061143, loss_s1: 0.053372, loss_fp: 0.001129, loss_freq: 0.016307
[14:17:56.191] iteration 13195: loss: 0.090248, loss_s1: 0.067004, loss_fp: 0.003517, loss_freq: 0.029266
[14:17:56.831] iteration 13196: loss: 0.040476, loss_s1: 0.038582, loss_fp: 0.002263, loss_freq: 0.004086
[14:17:57.463] iteration 13197: loss: 0.071582, loss_s1: 0.017649, loss_fp: 0.002946, loss_freq: 0.005800
[14:17:58.099] iteration 13198: loss: 0.034332, loss_s1: 0.009629, loss_fp: 0.002530, loss_freq: 0.008691
[14:17:58.730] iteration 13199: loss: 0.060596, loss_s1: 0.028552, loss_fp: 0.000372, loss_freq: 0.011225
[14:17:59.354] iteration 13200: loss: 0.083792, loss_s1: 0.061828, loss_fp: 0.001294, loss_freq: 0.038934
[14:18:02.782] iteration 13200 : mean_dice : 0.765985
[14:18:03.451] iteration 13201: loss: 0.078624, loss_s1: 0.018849, loss_fp: 0.000799, loss_freq: 0.029426
[14:18:04.088] iteration 13202: loss: 0.059779, loss_s1: 0.030995, loss_fp: 0.001389, loss_freq: 0.028243
[14:18:04.726] iteration 13203: loss: 0.055852, loss_s1: 0.020501, loss_fp: 0.000967, loss_freq: 0.038967
[14:18:05.359] iteration 13204: loss: 0.043955, loss_s1: 0.011977, loss_fp: 0.000848, loss_freq: 0.016948
[14:18:05.987] iteration 13205: loss: 0.058193, loss_s1: 0.053831, loss_fp: 0.004159, loss_freq: 0.010817
[14:18:06.622] iteration 13206: loss: 0.055678, loss_s1: 0.035471, loss_fp: 0.004397, loss_freq: 0.021920
[14:18:07.261] iteration 13207: loss: 0.061916, loss_s1: 0.048001, loss_fp: 0.002305, loss_freq: 0.014191
[14:18:07.892] iteration 13208: loss: 0.129405, loss_s1: 0.047978, loss_fp: 0.005533, loss_freq: 0.051774
[14:18:08.522] iteration 13209: loss: 0.030339, loss_s1: 0.011110, loss_fp: 0.001563, loss_freq: 0.005993
[14:18:09.162] iteration 13210: loss: 0.044973, loss_s1: 0.041283, loss_fp: 0.001293, loss_freq: 0.010726
[14:18:09.788] iteration 13211: loss: 0.057487, loss_s1: 0.064113, loss_fp: 0.001751, loss_freq: 0.007737
[14:18:10.417] iteration 13212: loss: 0.064394, loss_s1: 0.033837, loss_fp: 0.001017, loss_freq: 0.004715
[14:18:11.051] iteration 13213: loss: 0.067677, loss_s1: 0.062313, loss_fp: 0.001952, loss_freq: 0.014941
[14:18:11.687] iteration 13214: loss: 0.037174, loss_s1: 0.019685, loss_fp: 0.001538, loss_freq: 0.008672
[14:18:12.330] iteration 13215: loss: 0.083039, loss_s1: 0.033365, loss_fp: 0.001267, loss_freq: 0.065196
[14:18:12.952] iteration 13216: loss: 0.066020, loss_s1: 0.019751, loss_fp: 0.004524, loss_freq: 0.052699
[14:18:13.578] iteration 13217: loss: 0.058470, loss_s1: 0.037299, loss_fp: 0.004894, loss_freq: 0.019273
[14:18:14.207] iteration 13218: loss: 0.065655, loss_s1: 0.060875, loss_fp: 0.001726, loss_freq: 0.012768
[14:18:14.840] iteration 13219: loss: 0.078202, loss_s1: 0.048553, loss_fp: 0.003218, loss_freq: 0.036736
[14:18:15.483] iteration 13220: loss: 0.048510, loss_s1: 0.009713, loss_fp: 0.001033, loss_freq: 0.022456
[14:18:16.112] iteration 13221: loss: 0.117453, loss_s1: 0.077764, loss_fp: 0.002953, loss_freq: 0.068415
[14:18:16.753] iteration 13222: loss: 0.084795, loss_s1: 0.033502, loss_fp: 0.001405, loss_freq: 0.044488
[14:18:17.383] iteration 13223: loss: 0.091581, loss_s1: 0.045220, loss_fp: 0.008420, loss_freq: 0.057071
[14:18:18.027] iteration 13224: loss: 0.042488, loss_s1: 0.018575, loss_fp: 0.007098, loss_freq: 0.023105
[14:18:18.661] iteration 13225: loss: 0.063725, loss_s1: 0.061852, loss_fp: 0.000781, loss_freq: 0.008442
[14:18:19.294] iteration 13226: loss: 0.067289, loss_s1: 0.019843, loss_fp: 0.001044, loss_freq: 0.009824
[14:18:19.928] iteration 13227: loss: 0.066231, loss_s1: 0.061000, loss_fp: 0.006609, loss_freq: 0.016920
[14:18:20.561] iteration 13228: loss: 0.057933, loss_s1: 0.023141, loss_fp: 0.006665, loss_freq: 0.039086
[14:18:21.198] iteration 13229: loss: 0.062943, loss_s1: 0.031027, loss_fp: 0.001439, loss_freq: 0.049304
[14:18:21.833] iteration 13230: loss: 0.104984, loss_s1: 0.051912, loss_fp: 0.009912, loss_freq: 0.044205
[14:18:22.471] iteration 13231: loss: 0.082491, loss_s1: 0.076966, loss_fp: 0.016602, loss_freq: 0.038480
[14:18:23.098] iteration 13232: loss: 0.075491, loss_s1: 0.043645, loss_fp: 0.000980, loss_freq: 0.012244
[14:18:23.729] iteration 13233: loss: 0.035013, loss_s1: 0.021498, loss_fp: 0.005989, loss_freq: 0.009929
[14:18:24.357] iteration 13234: loss: 0.062488, loss_s1: 0.038020, loss_fp: 0.001143, loss_freq: 0.016406
[14:18:24.989] iteration 13235: loss: 0.094686, loss_s1: 0.065729, loss_fp: 0.012062, loss_freq: 0.061427
[14:18:25.628] iteration 13236: loss: 0.082484, loss_s1: 0.060270, loss_fp: 0.003326, loss_freq: 0.026351
[14:18:26.260] iteration 13237: loss: 0.045718, loss_s1: 0.021698, loss_fp: 0.004373, loss_freq: 0.013802
[14:18:26.886] iteration 13238: loss: 0.066885, loss_s1: 0.063472, loss_fp: 0.001380, loss_freq: 0.010464
[14:18:27.524] iteration 13239: loss: 0.043932, loss_s1: 0.012663, loss_fp: 0.001318, loss_freq: 0.019144
[14:18:28.151] iteration 13240: loss: 0.068577, loss_s1: 0.066418, loss_fp: 0.004168, loss_freq: 0.029359
[14:18:28.785] iteration 13241: loss: 0.089546, loss_s1: 0.080899, loss_fp: 0.012399, loss_freq: 0.031896
[14:18:29.406] iteration 13242: loss: 0.065775, loss_s1: 0.045901, loss_fp: 0.005110, loss_freq: 0.027685
[14:18:30.037] iteration 13243: loss: 0.069170, loss_s1: 0.022299, loss_fp: 0.005006, loss_freq: 0.026837
[14:18:30.663] iteration 13244: loss: 0.077261, loss_s1: 0.040174, loss_fp: 0.000881, loss_freq: 0.015795
[14:18:31.291] iteration 13245: loss: 0.051392, loss_s1: 0.028236, loss_fp: 0.007250, loss_freq: 0.018995
[14:18:31.918] iteration 13246: loss: 0.071529, loss_s1: 0.075795, loss_fp: 0.001788, loss_freq: 0.018771
[14:18:32.543] iteration 13247: loss: 0.071449, loss_s1: 0.028409, loss_fp: 0.002483, loss_freq: 0.015514
[14:18:33.175] iteration 13248: loss: 0.074014, loss_s1: 0.064279, loss_fp: 0.002859, loss_freq: 0.039045
[14:18:33.820] iteration 13249: loss: 0.053215, loss_s1: 0.027037, loss_fp: 0.007138, loss_freq: 0.011047
[14:18:34.450] iteration 13250: loss: 0.044107, loss_s1: 0.025852, loss_fp: 0.000755, loss_freq: 0.007704
[14:18:35.084] iteration 13251: loss: 0.043716, loss_s1: 0.022692, loss_fp: 0.002131, loss_freq: 0.021033
[14:18:35.716] iteration 13252: loss: 0.044434, loss_s1: 0.020265, loss_fp: 0.000953, loss_freq: 0.008757
[14:18:36.350] iteration 13253: loss: 0.084247, loss_s1: 0.068736, loss_fp: 0.002382, loss_freq: 0.042194
[14:18:36.992] iteration 13254: loss: 0.066720, loss_s1: 0.047794, loss_fp: 0.001808, loss_freq: 0.029846
[14:18:37.631] iteration 13255: loss: 0.053475, loss_s1: 0.013970, loss_fp: 0.000757, loss_freq: 0.022696
[14:18:38.276] iteration 13256: loss: 0.073926, loss_s1: 0.050257, loss_fp: 0.006827, loss_freq: 0.040912
[14:18:38.912] iteration 13257: loss: 0.074088, loss_s1: 0.051531, loss_fp: 0.002380, loss_freq: 0.045916
[14:18:39.545] iteration 13258: loss: 0.067183, loss_s1: 0.041197, loss_fp: 0.001237, loss_freq: 0.026572
[14:18:40.179] iteration 13259: loss: 0.043578, loss_s1: 0.030374, loss_fp: 0.003343, loss_freq: 0.014242
[14:18:40.823] iteration 13260: loss: 0.051432, loss_s1: 0.012209, loss_fp: 0.003011, loss_freq: 0.010488
[14:18:41.457] iteration 13261: loss: 0.059907, loss_s1: 0.030293, loss_fp: 0.004429, loss_freq: 0.019211
[14:18:42.091] iteration 13262: loss: 0.055582, loss_s1: 0.035208, loss_fp: 0.002114, loss_freq: 0.029442
[14:18:42.725] iteration 13263: loss: 0.149687, loss_s1: 0.083412, loss_fp: 0.017111, loss_freq: 0.148976
[14:18:43.358] iteration 13264: loss: 0.090433, loss_s1: 0.047955, loss_fp: 0.002633, loss_freq: 0.086197
[14:18:43.998] iteration 13265: loss: 0.057336, loss_s1: 0.029316, loss_fp: 0.000840, loss_freq: 0.006701
[14:18:44.635] iteration 13266: loss: 0.060432, loss_s1: 0.047012, loss_fp: 0.003795, loss_freq: 0.024629
[14:18:45.270] iteration 13267: loss: 0.106886, loss_s1: 0.053848, loss_fp: 0.002306, loss_freq: 0.010128
[14:18:45.955] iteration 13268: loss: 0.047308, loss_s1: 0.028048, loss_fp: 0.003741, loss_freq: 0.030667
[14:18:46.616] iteration 13269: loss: 0.069708, loss_s1: 0.039595, loss_fp: 0.001349, loss_freq: 0.013989
[14:18:47.275] iteration 13270: loss: 0.087340, loss_s1: 0.059478, loss_fp: 0.007241, loss_freq: 0.048238
[14:18:47.926] iteration 13271: loss: 0.075501, loss_s1: 0.022890, loss_fp: 0.002597, loss_freq: 0.033986
[14:18:48.589] iteration 13272: loss: 0.058621, loss_s1: 0.056982, loss_fp: 0.000492, loss_freq: 0.011318
[14:18:49.238] iteration 13273: loss: 0.049610, loss_s1: 0.015832, loss_fp: 0.001779, loss_freq: 0.031088
[14:18:49.875] iteration 13274: loss: 0.080223, loss_s1: 0.064831, loss_fp: 0.002336, loss_freq: 0.017572
[14:18:50.507] iteration 13275: loss: 0.060984, loss_s1: 0.056512, loss_fp: 0.002664, loss_freq: 0.009220
[14:18:51.133] iteration 13276: loss: 0.069340, loss_s1: 0.045477, loss_fp: 0.001407, loss_freq: 0.046900
[14:18:51.762] iteration 13277: loss: 0.090583, loss_s1: 0.042636, loss_fp: 0.003176, loss_freq: 0.078352
[14:18:52.388] iteration 13278: loss: 0.104826, loss_s1: 0.071245, loss_fp: 0.008068, loss_freq: 0.014280
[14:18:53.013] iteration 13279: loss: 0.044747, loss_s1: 0.035245, loss_fp: 0.001057, loss_freq: 0.003550
[14:18:53.636] iteration 13280: loss: 0.050912, loss_s1: 0.028798, loss_fp: 0.001943, loss_freq: 0.023403
[14:18:54.303] iteration 13281: loss: 0.044923, loss_s1: 0.029454, loss_fp: 0.001180, loss_freq: 0.028452
[14:18:54.969] iteration 13282: loss: 0.053204, loss_s1: 0.023148, loss_fp: 0.001100, loss_freq: 0.009624
[14:18:55.641] iteration 13283: loss: 0.056822, loss_s1: 0.027111, loss_fp: 0.003194, loss_freq: 0.038171
[14:18:56.315] iteration 13284: loss: 0.065761, loss_s1: 0.064654, loss_fp: 0.008593, loss_freq: 0.017515
[14:18:56.992] iteration 13285: loss: 0.083163, loss_s1: 0.082346, loss_fp: 0.002984, loss_freq: 0.017270
[14:18:57.624] iteration 13286: loss: 0.044007, loss_s1: 0.015623, loss_fp: 0.000711, loss_freq: 0.016969
[14:18:58.258] iteration 13287: loss: 0.067011, loss_s1: 0.037641, loss_fp: 0.003918, loss_freq: 0.034450
[14:18:58.910] iteration 13288: loss: 0.111587, loss_s1: 0.046712, loss_fp: 0.003540, loss_freq: 0.028446
[14:18:59.582] iteration 13289: loss: 0.075429, loss_s1: 0.067198, loss_fp: 0.004445, loss_freq: 0.017834
[14:19:00.248] iteration 13290: loss: 0.084691, loss_s1: 0.024705, loss_fp: 0.003740, loss_freq: 0.069683
[14:19:00.918] iteration 13291: loss: 0.062669, loss_s1: 0.018037, loss_fp: 0.007885, loss_freq: 0.018047
[14:19:01.578] iteration 13292: loss: 0.105442, loss_s1: 0.076354, loss_fp: 0.008782, loss_freq: 0.037205
[14:19:02.244] iteration 13293: loss: 0.102572, loss_s1: 0.079445, loss_fp: 0.008061, loss_freq: 0.041463
[14:19:02.865] iteration 13294: loss: 0.043942, loss_s1: 0.009971, loss_fp: 0.001712, loss_freq: 0.015850
[14:19:03.495] iteration 13295: loss: 0.085520, loss_s1: 0.037734, loss_fp: 0.008319, loss_freq: 0.042315
[14:19:04.120] iteration 13296: loss: 0.068069, loss_s1: 0.033871, loss_fp: 0.006258, loss_freq: 0.025203
[14:19:04.749] iteration 13297: loss: 0.075406, loss_s1: 0.074819, loss_fp: 0.002748, loss_freq: 0.021310
[14:19:05.368] iteration 13298: loss: 0.102400, loss_s1: 0.046890, loss_fp: 0.012783, loss_freq: 0.094396
[14:19:05.992] iteration 13299: loss: 0.069750, loss_s1: 0.028666, loss_fp: 0.001817, loss_freq: 0.033719
[14:19:06.956] iteration 13300: loss: 0.048502, loss_s1: 0.020377, loss_fp: 0.001870, loss_freq: 0.013389
[14:19:07.587] iteration 13301: loss: 0.060013, loss_s1: 0.035312, loss_fp: 0.003189, loss_freq: 0.025177
[14:19:08.414] iteration 13302: loss: 0.042080, loss_s1: 0.022403, loss_fp: 0.001593, loss_freq: 0.017136
[14:19:09.282] iteration 13303: loss: 0.070215, loss_s1: 0.050615, loss_fp: 0.015891, loss_freq: 0.025108
[14:19:10.040] iteration 13304: loss: 0.087201, loss_s1: 0.068706, loss_fp: 0.003263, loss_freq: 0.055024
[14:19:10.743] iteration 13305: loss: 0.042621, loss_s1: 0.019519, loss_fp: 0.000698, loss_freq: 0.003420
[14:19:11.361] iteration 13306: loss: 0.050534, loss_s1: 0.037587, loss_fp: 0.000441, loss_freq: 0.018079
[14:19:11.986] iteration 13307: loss: 0.077384, loss_s1: 0.047769, loss_fp: 0.000505, loss_freq: 0.008321
[14:19:12.614] iteration 13308: loss: 0.055379, loss_s1: 0.022902, loss_fp: 0.003982, loss_freq: 0.038356
[14:19:13.237] iteration 13309: loss: 0.071521, loss_s1: 0.023836, loss_fp: 0.000518, loss_freq: 0.005984
[14:19:13.859] iteration 13310: loss: 0.068854, loss_s1: 0.032511, loss_fp: 0.001203, loss_freq: 0.039759
[14:19:14.505] iteration 13311: loss: 0.045154, loss_s1: 0.016523, loss_fp: 0.002832, loss_freq: 0.014502
[14:19:15.153] iteration 13312: loss: 0.070006, loss_s1: 0.072519, loss_fp: 0.000704, loss_freq: 0.018571
[14:19:15.791] iteration 13313: loss: 0.045380, loss_s1: 0.022251, loss_fp: 0.000760, loss_freq: 0.012039
[14:19:16.432] iteration 13314: loss: 0.051195, loss_s1: 0.008613, loss_fp: 0.006064, loss_freq: 0.036637
[14:19:17.068] iteration 13315: loss: 0.050995, loss_s1: 0.042826, loss_fp: 0.000539, loss_freq: 0.018280
[14:19:17.712] iteration 13316: loss: 0.063829, loss_s1: 0.038672, loss_fp: 0.001342, loss_freq: 0.036316
[14:19:18.350] iteration 13317: loss: 0.059377, loss_s1: 0.031026, loss_fp: 0.002526, loss_freq: 0.021336
[14:19:18.989] iteration 13318: loss: 0.050671, loss_s1: 0.046892, loss_fp: 0.001276, loss_freq: 0.017700
[14:19:19.629] iteration 13319: loss: 0.072531, loss_s1: 0.070051, loss_fp: 0.001808, loss_freq: 0.022276
[14:19:20.267] iteration 13320: loss: 0.145712, loss_s1: 0.038528, loss_fp: 0.000628, loss_freq: 0.070775
[14:19:20.920] iteration 13321: loss: 0.056346, loss_s1: 0.032022, loss_fp: 0.002512, loss_freq: 0.018338
[14:19:21.542] iteration 13322: loss: 0.069452, loss_s1: 0.056796, loss_fp: 0.005244, loss_freq: 0.024429
[14:19:22.162] iteration 13323: loss: 0.078844, loss_s1: 0.062220, loss_fp: 0.002674, loss_freq: 0.008120
[14:19:22.798] iteration 13324: loss: 0.045947, loss_s1: 0.023191, loss_fp: 0.003531, loss_freq: 0.008386
[14:19:23.426] iteration 13325: loss: 0.102399, loss_s1: 0.076352, loss_fp: 0.010189, loss_freq: 0.042910
[14:19:24.054] iteration 13326: loss: 0.082104, loss_s1: 0.029737, loss_fp: 0.005037, loss_freq: 0.059248
[14:19:24.679] iteration 13327: loss: 0.099277, loss_s1: 0.052856, loss_fp: 0.002168, loss_freq: 0.026903
[14:19:25.305] iteration 13328: loss: 0.068762, loss_s1: 0.039951, loss_fp: 0.002206, loss_freq: 0.025189
[14:19:25.938] iteration 13329: loss: 0.093353, loss_s1: 0.053671, loss_fp: 0.000963, loss_freq: 0.019752
[14:19:26.566] iteration 13330: loss: 0.054863, loss_s1: 0.031535, loss_fp: 0.001725, loss_freq: 0.031824
[14:19:27.249] iteration 13331: loss: 0.065645, loss_s1: 0.034718, loss_fp: 0.006588, loss_freq: 0.020190
[14:19:27.906] iteration 13332: loss: 0.062932, loss_s1: 0.043735, loss_fp: 0.011203, loss_freq: 0.026665
[14:19:28.568] iteration 13333: loss: 0.120055, loss_s1: 0.078111, loss_fp: 0.004114, loss_freq: 0.086676
[14:19:29.223] iteration 13334: loss: 0.070211, loss_s1: 0.031925, loss_fp: 0.005014, loss_freq: 0.031976
[14:19:29.863] iteration 13335: loss: 0.082984, loss_s1: 0.070796, loss_fp: 0.002515, loss_freq: 0.041106
[14:19:30.495] iteration 13336: loss: 0.057406, loss_s1: 0.029033, loss_fp: 0.001668, loss_freq: 0.020249
[14:19:31.125] iteration 13337: loss: 0.067471, loss_s1: 0.055478, loss_fp: 0.007284, loss_freq: 0.028841
[14:19:31.751] iteration 13338: loss: 0.087599, loss_s1: 0.054856, loss_fp: 0.001308, loss_freq: 0.039737
[14:19:32.373] iteration 13339: loss: 0.049830, loss_s1: 0.027302, loss_fp: 0.004330, loss_freq: 0.015982
[14:19:32.996] iteration 13340: loss: 0.080203, loss_s1: 0.039517, loss_fp: 0.001892, loss_freq: 0.013784
[14:19:33.621] iteration 13341: loss: 0.042846, loss_s1: 0.035280, loss_fp: 0.002058, loss_freq: 0.007356
[14:19:34.245] iteration 13342: loss: 0.095143, loss_s1: 0.046485, loss_fp: 0.000885, loss_freq: 0.033919
[14:19:34.872] iteration 13343: loss: 0.055379, loss_s1: 0.036400, loss_fp: 0.001537, loss_freq: 0.034548
[14:19:35.495] iteration 13344: loss: 0.051331, loss_s1: 0.027786, loss_fp: 0.000355, loss_freq: 0.012921
[14:19:36.127] iteration 13345: loss: 0.087362, loss_s1: 0.065221, loss_fp: 0.000758, loss_freq: 0.061482
[14:19:36.749] iteration 13346: loss: 0.059608, loss_s1: 0.019015, loss_fp: 0.006442, loss_freq: 0.046651
[14:19:37.368] iteration 13347: loss: 0.071776, loss_s1: 0.046164, loss_fp: 0.000950, loss_freq: 0.040222
[14:19:37.991] iteration 13348: loss: 0.060917, loss_s1: 0.037851, loss_fp: 0.000524, loss_freq: 0.026223
[14:19:38.612] iteration 13349: loss: 0.042935, loss_s1: 0.019711, loss_fp: 0.001804, loss_freq: 0.010094
[14:19:39.239] iteration 13350: loss: 0.102700, loss_s1: 0.089065, loss_fp: 0.001366, loss_freq: 0.032778
[14:19:39.865] iteration 13351: loss: 0.089442, loss_s1: 0.057432, loss_fp: 0.003214, loss_freq: 0.030499
[14:19:40.484] iteration 13352: loss: 0.042211, loss_s1: 0.018856, loss_fp: 0.001559, loss_freq: 0.008547
[14:19:41.112] iteration 13353: loss: 0.034449, loss_s1: 0.019508, loss_fp: 0.001336, loss_freq: 0.010238
[14:19:41.740] iteration 13354: loss: 0.027080, loss_s1: 0.007997, loss_fp: 0.001839, loss_freq: 0.008274
[14:19:42.371] iteration 13355: loss: 0.055272, loss_s1: 0.032879, loss_fp: 0.001062, loss_freq: 0.017547
[14:19:42.994] iteration 13356: loss: 0.108471, loss_s1: 0.080705, loss_fp: 0.003234, loss_freq: 0.020397
[14:19:43.619] iteration 13357: loss: 0.040945, loss_s1: 0.033646, loss_fp: 0.000591, loss_freq: 0.009012
[14:19:44.247] iteration 13358: loss: 0.106269, loss_s1: 0.043525, loss_fp: 0.001451, loss_freq: 0.096960
[14:19:44.875] iteration 13359: loss: 0.062305, loss_s1: 0.037480, loss_fp: 0.002423, loss_freq: 0.031606
[14:19:45.501] iteration 13360: loss: 0.070336, loss_s1: 0.045217, loss_fp: 0.001215, loss_freq: 0.013778
[14:19:46.131] iteration 13361: loss: 0.059005, loss_s1: 0.045341, loss_fp: 0.000872, loss_freq: 0.018235
[14:19:46.758] iteration 13362: loss: 0.064115, loss_s1: 0.041534, loss_fp: 0.001171, loss_freq: 0.021427
[14:19:47.389] iteration 13363: loss: 0.070323, loss_s1: 0.031170, loss_fp: 0.001224, loss_freq: 0.033611
[14:19:48.017] iteration 13364: loss: 0.070520, loss_s1: 0.028184, loss_fp: 0.001231, loss_freq: 0.033815
[14:19:48.644] iteration 13365: loss: 0.066138, loss_s1: 0.040752, loss_fp: 0.006244, loss_freq: 0.029187
[14:19:49.279] iteration 13366: loss: 0.097292, loss_s1: 0.062844, loss_fp: 0.003730, loss_freq: 0.067226
[14:19:49.906] iteration 13367: loss: 0.059799, loss_s1: 0.024742, loss_fp: 0.000637, loss_freq: 0.047469
[14:19:50.534] iteration 13368: loss: 0.070921, loss_s1: 0.049137, loss_fp: 0.002792, loss_freq: 0.029134
[14:19:51.168] iteration 13369: loss: 0.047642, loss_s1: 0.022809, loss_fp: 0.000737, loss_freq: 0.010330
[14:19:51.798] iteration 13370: loss: 0.070540, loss_s1: 0.048492, loss_fp: 0.006336, loss_freq: 0.037266
[14:19:52.458] iteration 13371: loss: 0.067619, loss_s1: 0.044695, loss_fp: 0.002147, loss_freq: 0.024047
[14:19:53.112] iteration 13372: loss: 0.039351, loss_s1: 0.009363, loss_fp: 0.000365, loss_freq: 0.026183
[14:19:53.764] iteration 13373: loss: 0.073302, loss_s1: 0.044806, loss_fp: 0.003597, loss_freq: 0.009239
[14:19:54.427] iteration 13374: loss: 0.094029, loss_s1: 0.082166, loss_fp: 0.013160, loss_freq: 0.050423
[14:19:55.078] iteration 13375: loss: 0.101583, loss_s1: 0.023421, loss_fp: 0.001930, loss_freq: 0.014454
[14:19:55.734] iteration 13376: loss: 0.056010, loss_s1: 0.056506, loss_fp: 0.002812, loss_freq: 0.011873
[14:19:56.408] iteration 13377: loss: 0.090002, loss_s1: 0.104300, loss_fp: 0.002014, loss_freq: 0.005915
[14:19:57.086] iteration 13378: loss: 0.081414, loss_s1: 0.043019, loss_fp: 0.021805, loss_freq: 0.048765
[14:19:57.751] iteration 13379: loss: 0.139755, loss_s1: 0.049920, loss_fp: 0.008674, loss_freq: 0.041612
[14:19:58.412] iteration 13380: loss: 0.073875, loss_s1: 0.034924, loss_fp: 0.001069, loss_freq: 0.050347
[14:19:59.065] iteration 13381: loss: 0.068438, loss_s1: 0.042254, loss_fp: 0.001541, loss_freq: 0.038247
[14:19:59.723] iteration 13382: loss: 0.071460, loss_s1: 0.066138, loss_fp: 0.000865, loss_freq: 0.022093
[14:20:00.380] iteration 13383: loss: 0.052974, loss_s1: 0.040941, loss_fp: 0.000897, loss_freq: 0.026298
[14:20:01.010] iteration 13384: loss: 0.043257, loss_s1: 0.015730, loss_fp: 0.001525, loss_freq: 0.012947
[14:20:01.685] iteration 13385: loss: 0.085717, loss_s1: 0.052588, loss_fp: 0.004125, loss_freq: 0.068590
[14:20:02.311] iteration 13386: loss: 0.065097, loss_s1: 0.030637, loss_fp: 0.001085, loss_freq: 0.037197
[14:20:03.011] iteration 13387: loss: 0.051214, loss_s1: 0.033898, loss_fp: 0.002180, loss_freq: 0.008152
[14:20:03.673] iteration 13388: loss: 0.064478, loss_s1: 0.017173, loss_fp: 0.003656, loss_freq: 0.012761
[14:20:04.341] iteration 13389: loss: 0.095484, loss_s1: 0.110628, loss_fp: 0.003922, loss_freq: 0.025642
[14:20:04.998] iteration 13390: loss: 0.061012, loss_s1: 0.028923, loss_fp: 0.001106, loss_freq: 0.015841
[14:20:05.617] iteration 13391: loss: 0.058768, loss_s1: 0.037125, loss_fp: 0.005823, loss_freq: 0.027172
[14:20:06.248] iteration 13392: loss: 0.052439, loss_s1: 0.050661, loss_fp: 0.000802, loss_freq: 0.007735
[14:20:06.871] iteration 13393: loss: 0.042336, loss_s1: 0.014324, loss_fp: 0.002367, loss_freq: 0.007973
[14:20:07.495] iteration 13394: loss: 0.050071, loss_s1: 0.039008, loss_fp: 0.002023, loss_freq: 0.009084
[14:20:08.128] iteration 13395: loss: 0.058274, loss_s1: 0.045250, loss_fp: 0.000801, loss_freq: 0.015623
[14:20:08.755] iteration 13396: loss: 0.098279, loss_s1: 0.038957, loss_fp: 0.000831, loss_freq: 0.086886
[14:20:09.446] iteration 13397: loss: 0.054203, loss_s1: 0.040323, loss_fp: 0.001880, loss_freq: 0.018238
[14:20:10.090] iteration 13398: loss: 0.075423, loss_s1: 0.051225, loss_fp: 0.002785, loss_freq: 0.016240
[14:20:10.706] iteration 13399: loss: 0.084661, loss_s1: 0.056275, loss_fp: 0.001283, loss_freq: 0.039538
[14:20:11.327] iteration 13400: loss: 0.061495, loss_s1: 0.032135, loss_fp: 0.003116, loss_freq: 0.034855
[14:20:14.778] iteration 13400 : mean_dice : 0.779494
[14:20:15.450] iteration 13401: loss: 0.073047, loss_s1: 0.024409, loss_fp: 0.002236, loss_freq: 0.034893
[14:20:16.102] iteration 13402: loss: 0.072610, loss_s1: 0.064041, loss_fp: 0.001139, loss_freq: 0.025889
[14:20:16.761] iteration 13403: loss: 0.048210, loss_s1: 0.023217, loss_fp: 0.004753, loss_freq: 0.022308
[14:20:17.395] iteration 13404: loss: 0.116168, loss_s1: 0.052098, loss_fp: 0.008777, loss_freq: 0.013492
[14:20:18.022] iteration 13405: loss: 0.070948, loss_s1: 0.041694, loss_fp: 0.000573, loss_freq: 0.020641
[14:20:18.658] iteration 13406: loss: 0.127087, loss_s1: 0.151853, loss_fp: 0.002901, loss_freq: 0.038725
[14:20:19.291] iteration 13407: loss: 0.068661, loss_s1: 0.032525, loss_fp: 0.007086, loss_freq: 0.021246
[14:20:19.914] iteration 13408: loss: 0.066639, loss_s1: 0.026154, loss_fp: 0.002384, loss_freq: 0.034690
[14:20:20.540] iteration 13409: loss: 0.074367, loss_s1: 0.045569, loss_fp: 0.003944, loss_freq: 0.051461
[14:20:21.164] iteration 13410: loss: 0.076261, loss_s1: 0.016070, loss_fp: 0.001154, loss_freq: 0.025041
[14:20:21.795] iteration 13411: loss: 0.053534, loss_s1: 0.041340, loss_fp: 0.002347, loss_freq: 0.027037
[14:20:22.419] iteration 13412: loss: 0.061425, loss_s1: 0.031168, loss_fp: 0.001187, loss_freq: 0.007523
[14:20:23.039] iteration 13413: loss: 0.073113, loss_s1: 0.067081, loss_fp: 0.005076, loss_freq: 0.012235
[14:20:23.669] iteration 13414: loss: 0.072768, loss_s1: 0.048065, loss_fp: 0.001937, loss_freq: 0.018171
[14:20:24.298] iteration 13415: loss: 0.045732, loss_s1: 0.013555, loss_fp: 0.002516, loss_freq: 0.019969
[14:20:24.966] iteration 13416: loss: 0.099692, loss_s1: 0.061260, loss_fp: 0.002660, loss_freq: 0.070605
[14:20:25.652] iteration 13417: loss: 0.091925, loss_s1: 0.110009, loss_fp: 0.002034, loss_freq: 0.021674
[14:20:26.312] iteration 13418: loss: 0.061207, loss_s1: 0.050659, loss_fp: 0.001000, loss_freq: 0.035158
[14:20:26.963] iteration 13419: loss: 0.052239, loss_s1: 0.028443, loss_fp: 0.002134, loss_freq: 0.022652
[14:20:27.595] iteration 13420: loss: 0.059493, loss_s1: 0.035045, loss_fp: 0.007274, loss_freq: 0.029127
[14:20:28.225] iteration 13421: loss: 0.054090, loss_s1: 0.035085, loss_fp: 0.001635, loss_freq: 0.013326
[14:20:28.856] iteration 13422: loss: 0.040778, loss_s1: 0.036006, loss_fp: 0.000469, loss_freq: 0.002349
[14:20:29.485] iteration 13423: loss: 0.057665, loss_s1: 0.054238, loss_fp: 0.004758, loss_freq: 0.020623
[14:20:30.108] iteration 13424: loss: 0.057944, loss_s1: 0.037395, loss_fp: 0.003326, loss_freq: 0.016211
[14:20:30.730] iteration 13425: loss: 0.086992, loss_s1: 0.035259, loss_fp: 0.006368, loss_freq: 0.010554
[14:20:31.348] iteration 13426: loss: 0.036170, loss_s1: 0.014488, loss_fp: 0.001082, loss_freq: 0.014128
[14:20:31.974] iteration 13427: loss: 0.070730, loss_s1: 0.046904, loss_fp: 0.005384, loss_freq: 0.030504
[14:20:32.605] iteration 13428: loss: 0.061423, loss_s1: 0.055809, loss_fp: 0.003352, loss_freq: 0.010316
[14:20:33.237] iteration 13429: loss: 0.051539, loss_s1: 0.033988, loss_fp: 0.001507, loss_freq: 0.014751
[14:20:33.882] iteration 13430: loss: 0.069103, loss_s1: 0.039425, loss_fp: 0.001926, loss_freq: 0.030054
[14:20:34.542] iteration 13431: loss: 0.093447, loss_s1: 0.046826, loss_fp: 0.009752, loss_freq: 0.029132
[14:20:35.239] iteration 13432: loss: 0.067895, loss_s1: 0.056404, loss_fp: 0.002163, loss_freq: 0.017290
[14:20:35.905] iteration 13433: loss: 0.126801, loss_s1: 0.064433, loss_fp: 0.001040, loss_freq: 0.060930
[14:20:36.546] iteration 13434: loss: 0.079988, loss_s1: 0.058244, loss_fp: 0.004358, loss_freq: 0.027143
[14:20:37.189] iteration 13435: loss: 0.071870, loss_s1: 0.064871, loss_fp: 0.008503, loss_freq: 0.031843
[14:20:37.852] iteration 13436: loss: 0.093842, loss_s1: 0.046110, loss_fp: 0.006703, loss_freq: 0.058236
[14:20:38.475] iteration 13437: loss: 0.038855, loss_s1: 0.012426, loss_fp: 0.002975, loss_freq: 0.026810
[14:20:39.102] iteration 13438: loss: 0.050057, loss_s1: 0.035574, loss_fp: 0.002053, loss_freq: 0.018564
[14:20:39.732] iteration 13439: loss: 0.065595, loss_s1: 0.035327, loss_fp: 0.002830, loss_freq: 0.018799
[14:20:40.363] iteration 13440: loss: 0.084910, loss_s1: 0.069311, loss_fp: 0.005885, loss_freq: 0.050414
[14:20:40.984] iteration 13441: loss: 0.114516, loss_s1: 0.065679, loss_fp: 0.004325, loss_freq: 0.109584
[14:20:41.612] iteration 13442: loss: 0.055286, loss_s1: 0.040234, loss_fp: 0.001321, loss_freq: 0.023552
[14:20:42.572] iteration 13443: loss: 0.054685, loss_s1: 0.037744, loss_fp: 0.002906, loss_freq: 0.014729
[14:20:43.257] iteration 13444: loss: 0.091631, loss_s1: 0.076611, loss_fp: 0.002241, loss_freq: 0.039938
[14:20:43.913] iteration 13445: loss: 0.050403, loss_s1: 0.026113, loss_fp: 0.005679, loss_freq: 0.024774
[14:20:44.539] iteration 13446: loss: 0.065621, loss_s1: 0.038898, loss_fp: 0.001165, loss_freq: 0.025354
[14:20:45.166] iteration 13447: loss: 0.066822, loss_s1: 0.037520, loss_fp: 0.005932, loss_freq: 0.021346
[14:20:45.848] iteration 13448: loss: 0.069128, loss_s1: 0.018244, loss_fp: 0.000520, loss_freq: 0.003849
[14:20:46.517] iteration 13449: loss: 0.034160, loss_s1: 0.022406, loss_fp: 0.003237, loss_freq: 0.008404
[14:20:47.189] iteration 13450: loss: 0.103523, loss_s1: 0.092366, loss_fp: 0.000815, loss_freq: 0.018579
[14:20:47.861] iteration 13451: loss: 0.061521, loss_s1: 0.045038, loss_fp: 0.002114, loss_freq: 0.018715
[14:20:48.520] iteration 13452: loss: 0.066297, loss_s1: 0.016270, loss_fp: 0.000767, loss_freq: 0.011422
[14:20:49.155] iteration 13453: loss: 0.081760, loss_s1: 0.042154, loss_fp: 0.005050, loss_freq: 0.058173
[14:20:49.798] iteration 13454: loss: 0.049631, loss_s1: 0.020192, loss_fp: 0.002233, loss_freq: 0.028334
[14:20:50.419] iteration 13455: loss: 0.065081, loss_s1: 0.050538, loss_fp: 0.002524, loss_freq: 0.007744
[14:20:51.043] iteration 13456: loss: 0.036517, loss_s1: 0.015769, loss_fp: 0.002404, loss_freq: 0.013563
[14:20:51.674] iteration 13457: loss: 0.066715, loss_s1: 0.035050, loss_fp: 0.001456, loss_freq: 0.047726
[14:20:52.300] iteration 13458: loss: 0.059190, loss_s1: 0.034456, loss_fp: 0.001664, loss_freq: 0.013182
[14:20:52.939] iteration 13459: loss: 0.082883, loss_s1: 0.021848, loss_fp: 0.000464, loss_freq: 0.036745
[14:20:53.603] iteration 13460: loss: 0.113398, loss_s1: 0.091151, loss_fp: 0.004207, loss_freq: 0.019166
[14:20:54.242] iteration 13461: loss: 0.052826, loss_s1: 0.038869, loss_fp: 0.001248, loss_freq: 0.013427
[14:20:54.871] iteration 13462: loss: 0.051383, loss_s1: 0.038810, loss_fp: 0.004301, loss_freq: 0.016054
[14:20:55.508] iteration 13463: loss: 0.110505, loss_s1: 0.074465, loss_fp: 0.001213, loss_freq: 0.058377
[14:20:56.141] iteration 13464: loss: 0.061964, loss_s1: 0.037385, loss_fp: 0.005766, loss_freq: 0.019243
[14:20:56.773] iteration 13465: loss: 0.055456, loss_s1: 0.045763, loss_fp: 0.008915, loss_freq: 0.015616
[14:20:57.404] iteration 13466: loss: 0.063666, loss_s1: 0.045469, loss_fp: 0.000584, loss_freq: 0.024064
[14:20:58.040] iteration 13467: loss: 0.062763, loss_s1: 0.053406, loss_fp: 0.003997, loss_freq: 0.015024
[14:20:58.671] iteration 13468: loss: 0.129538, loss_s1: 0.143927, loss_fp: 0.015388, loss_freq: 0.031957
[14:20:59.328] iteration 13469: loss: 0.074333, loss_s1: 0.033735, loss_fp: 0.007442, loss_freq: 0.051087
[14:20:59.995] iteration 13470: loss: 0.072048, loss_s1: 0.074700, loss_fp: 0.002758, loss_freq: 0.006820
[14:21:00.660] iteration 13471: loss: 0.073425, loss_s1: 0.048366, loss_fp: 0.004634, loss_freq: 0.016670
[14:21:01.315] iteration 13472: loss: 0.086157, loss_s1: 0.020564, loss_fp: 0.001178, loss_freq: 0.011200
[14:21:01.960] iteration 13473: loss: 0.062036, loss_s1: 0.058186, loss_fp: 0.001697, loss_freq: 0.011597
[14:21:02.590] iteration 13474: loss: 0.087566, loss_s1: 0.040074, loss_fp: 0.002883, loss_freq: 0.014507
[14:21:03.225] iteration 13475: loss: 0.058596, loss_s1: 0.038879, loss_fp: 0.001166, loss_freq: 0.046244
[14:21:03.885] iteration 13476: loss: 0.101253, loss_s1: 0.079794, loss_fp: 0.000939, loss_freq: 0.075800
[14:21:04.544] iteration 13477: loss: 0.110822, loss_s1: 0.051318, loss_fp: 0.006015, loss_freq: 0.025466
[14:21:05.240] iteration 13478: loss: 0.090502, loss_s1: 0.049166, loss_fp: 0.001901, loss_freq: 0.058043
[14:21:05.903] iteration 13479: loss: 0.108249, loss_s1: 0.060453, loss_fp: 0.001840, loss_freq: 0.088663
[14:21:06.556] iteration 13480: loss: 0.079809, loss_s1: 0.068707, loss_fp: 0.008303, loss_freq: 0.033506
[14:21:07.230] iteration 13481: loss: 0.103249, loss_s1: 0.023743, loss_fp: 0.002239, loss_freq: 0.074087
[14:21:07.864] iteration 13482: loss: 0.039049, loss_s1: 0.019211, loss_fp: 0.007039, loss_freq: 0.009267
[14:21:08.492] iteration 13483: loss: 0.088670, loss_s1: 0.080958, loss_fp: 0.009676, loss_freq: 0.029075
[14:21:09.124] iteration 13484: loss: 0.042303, loss_s1: 0.033118, loss_fp: 0.002769, loss_freq: 0.009177
[14:21:09.749] iteration 13485: loss: 0.074642, loss_s1: 0.044437, loss_fp: 0.003266, loss_freq: 0.016730
[14:21:10.375] iteration 13486: loss: 0.134732, loss_s1: 0.095476, loss_fp: 0.041513, loss_freq: 0.066635
[14:21:11.062] iteration 13487: loss: 0.094932, loss_s1: 0.055017, loss_fp: 0.003402, loss_freq: 0.023762
[14:21:11.736] iteration 13488: loss: 0.063507, loss_s1: 0.037161, loss_fp: 0.003644, loss_freq: 0.035896
[14:21:12.380] iteration 13489: loss: 0.069102, loss_s1: 0.030016, loss_fp: 0.002530, loss_freq: 0.039015
[14:21:13.205] iteration 13490: loss: 0.070880, loss_s1: 0.031085, loss_fp: 0.002630, loss_freq: 0.014553
[14:21:14.124] iteration 13491: loss: 0.037925, loss_s1: 0.017288, loss_fp: 0.002448, loss_freq: 0.017379
[14:21:14.859] iteration 13492: loss: 0.048807, loss_s1: 0.024596, loss_fp: 0.002058, loss_freq: 0.022126
[14:21:15.517] iteration 13493: loss: 0.060860, loss_s1: 0.046167, loss_fp: 0.002274, loss_freq: 0.019302
[14:21:16.153] iteration 13494: loss: 0.070547, loss_s1: 0.010120, loss_fp: 0.002801, loss_freq: 0.024916
[14:21:16.788] iteration 13495: loss: 0.044377, loss_s1: 0.015926, loss_fp: 0.001559, loss_freq: 0.010097
[14:21:17.418] iteration 13496: loss: 0.057002, loss_s1: 0.055553, loss_fp: 0.004901, loss_freq: 0.014058
[14:21:18.054] iteration 13497: loss: 0.064551, loss_s1: 0.007119, loss_fp: 0.015062, loss_freq: 0.020477
[14:21:18.694] iteration 13498: loss: 0.073357, loss_s1: 0.044006, loss_fp: 0.002783, loss_freq: 0.013428
[14:21:19.338] iteration 13499: loss: 0.066325, loss_s1: 0.072632, loss_fp: 0.003170, loss_freq: 0.020770
[14:21:19.971] iteration 13500: loss: 0.068754, loss_s1: 0.030208, loss_fp: 0.000720, loss_freq: 0.055585
[14:21:20.609] iteration 13501: loss: 0.079389, loss_s1: 0.050716, loss_fp: 0.000698, loss_freq: 0.051985
[14:21:21.255] iteration 13502: loss: 0.078448, loss_s1: 0.045510, loss_fp: 0.003734, loss_freq: 0.049859
[14:21:21.898] iteration 13503: loss: 0.037758, loss_s1: 0.010324, loss_fp: 0.004865, loss_freq: 0.010493
[14:21:22.537] iteration 13504: loss: 0.050816, loss_s1: 0.027280, loss_fp: 0.005085, loss_freq: 0.015283
[14:21:23.214] iteration 13505: loss: 0.094370, loss_s1: 0.038076, loss_fp: 0.017005, loss_freq: 0.022770
[14:21:23.843] iteration 13506: loss: 0.068984, loss_s1: 0.057454, loss_fp: 0.002409, loss_freq: 0.024497
[14:21:24.480] iteration 13507: loss: 0.094676, loss_s1: 0.073927, loss_fp: 0.016887, loss_freq: 0.015663
[14:21:25.107] iteration 13508: loss: 0.088008, loss_s1: 0.039286, loss_fp: 0.006963, loss_freq: 0.022112
[14:21:25.738] iteration 13509: loss: 0.134523, loss_s1: 0.127220, loss_fp: 0.022530, loss_freq: 0.057293
[14:21:26.362] iteration 13510: loss: 0.047717, loss_s1: 0.030278, loss_fp: 0.003128, loss_freq: 0.023568
[14:21:26.998] iteration 13511: loss: 0.049002, loss_s1: 0.024954, loss_fp: 0.004787, loss_freq: 0.018914
[14:21:27.631] iteration 13512: loss: 0.050717, loss_s1: 0.012009, loss_fp: 0.002270, loss_freq: 0.010360
[14:21:28.259] iteration 13513: loss: 0.088026, loss_s1: 0.079174, loss_fp: 0.008667, loss_freq: 0.014225
[14:21:28.897] iteration 13514: loss: 0.083765, loss_s1: 0.058306, loss_fp: 0.001185, loss_freq: 0.044666
[14:21:29.527] iteration 13515: loss: 0.059639, loss_s1: 0.035908, loss_fp: 0.001401, loss_freq: 0.042017
[14:21:30.148] iteration 13516: loss: 0.066987, loss_s1: 0.025727, loss_fp: 0.005984, loss_freq: 0.037816
[14:21:30.776] iteration 13517: loss: 0.064203, loss_s1: 0.044486, loss_fp: 0.001254, loss_freq: 0.039195
[14:21:31.412] iteration 13518: loss: 0.075634, loss_s1: 0.038462, loss_fp: 0.001446, loss_freq: 0.022233
[14:21:32.038] iteration 13519: loss: 0.052321, loss_s1: 0.018651, loss_fp: 0.003906, loss_freq: 0.039437
[14:21:32.662] iteration 13520: loss: 0.044097, loss_s1: 0.017438, loss_fp: 0.000689, loss_freq: 0.007080
[14:21:33.281] iteration 13521: loss: 0.108908, loss_s1: 0.083533, loss_fp: 0.007766, loss_freq: 0.064960
[14:21:33.909] iteration 13522: loss: 0.128305, loss_s1: 0.120242, loss_fp: 0.026343, loss_freq: 0.038458
[14:21:34.540] iteration 13523: loss: 0.055727, loss_s1: 0.029523, loss_fp: 0.003029, loss_freq: 0.020500
[14:21:35.173] iteration 13524: loss: 0.064074, loss_s1: 0.033169, loss_fp: 0.011146, loss_freq: 0.034338
[14:21:35.804] iteration 13525: loss: 0.053222, loss_s1: 0.023164, loss_fp: 0.006255, loss_freq: 0.012450
[14:21:36.429] iteration 13526: loss: 0.048731, loss_s1: 0.040901, loss_fp: 0.001229, loss_freq: 0.018822
[14:21:37.062] iteration 13527: loss: 0.058362, loss_s1: 0.040856, loss_fp: 0.002267, loss_freq: 0.005003
[14:21:37.689] iteration 13528: loss: 0.068627, loss_s1: 0.044010, loss_fp: 0.002170, loss_freq: 0.033340
[14:21:38.314] iteration 13529: loss: 0.051956, loss_s1: 0.034463, loss_fp: 0.000853, loss_freq: 0.012760
[14:21:38.940] iteration 13530: loss: 0.063814, loss_s1: 0.022146, loss_fp: 0.001021, loss_freq: 0.021482
[14:21:39.567] iteration 13531: loss: 0.059745, loss_s1: 0.055315, loss_fp: 0.002027, loss_freq: 0.015638
[14:21:40.193] iteration 13532: loss: 0.082082, loss_s1: 0.058300, loss_fp: 0.001977, loss_freq: 0.045088
[14:21:40.813] iteration 13533: loss: 0.068841, loss_s1: 0.046886, loss_fp: 0.002021, loss_freq: 0.025723
[14:21:41.439] iteration 13534: loss: 0.069891, loss_s1: 0.062869, loss_fp: 0.002351, loss_freq: 0.022887
[14:21:42.068] iteration 13535: loss: 0.052142, loss_s1: 0.021971, loss_fp: 0.001097, loss_freq: 0.005793
[14:21:42.703] iteration 13536: loss: 0.064877, loss_s1: 0.026086, loss_fp: 0.011015, loss_freq: 0.009962
[14:21:43.328] iteration 13537: loss: 0.074916, loss_s1: 0.059159, loss_fp: 0.004199, loss_freq: 0.038883
[14:21:43.948] iteration 13538: loss: 0.057308, loss_s1: 0.020071, loss_fp: 0.002784, loss_freq: 0.016672
[14:21:44.572] iteration 13539: loss: 0.100683, loss_s1: 0.078974, loss_fp: 0.009887, loss_freq: 0.057424
[14:21:45.223] iteration 13540: loss: 0.061024, loss_s1: 0.020106, loss_fp: 0.001382, loss_freq: 0.036116
[14:21:45.924] iteration 13541: loss: 0.080336, loss_s1: 0.027464, loss_fp: 0.005930, loss_freq: 0.019048
[14:21:46.579] iteration 13542: loss: 0.126078, loss_s1: 0.084382, loss_fp: 0.004430, loss_freq: 0.075254
[14:21:47.238] iteration 13543: loss: 0.065099, loss_s1: 0.038390, loss_fp: 0.002421, loss_freq: 0.033884
[14:21:47.903] iteration 13544: loss: 0.079146, loss_s1: 0.011773, loss_fp: 0.001663, loss_freq: 0.025990
[14:21:48.544] iteration 13545: loss: 0.067010, loss_s1: 0.056932, loss_fp: 0.003956, loss_freq: 0.032484
[14:21:49.168] iteration 13546: loss: 0.060247, loss_s1: 0.044453, loss_fp: 0.000949, loss_freq: 0.017007
[14:21:49.793] iteration 13547: loss: 0.085661, loss_s1: 0.063569, loss_fp: 0.000631, loss_freq: 0.037317
[14:21:50.423] iteration 13548: loss: 0.072851, loss_s1: 0.030261, loss_fp: 0.000570, loss_freq: 0.038436
[14:21:51.042] iteration 13549: loss: 0.104018, loss_s1: 0.117951, loss_fp: 0.001444, loss_freq: 0.039052
[14:21:51.658] iteration 13550: loss: 0.098551, loss_s1: 0.055988, loss_fp: 0.007109, loss_freq: 0.094772
[14:21:52.279] iteration 13551: loss: 0.131531, loss_s1: 0.084580, loss_fp: 0.002123, loss_freq: 0.036264
[14:21:52.906] iteration 13552: loss: 0.067532, loss_s1: 0.044083, loss_fp: 0.007061, loss_freq: 0.021092
[14:21:53.531] iteration 13553: loss: 0.065799, loss_s1: 0.010757, loss_fp: 0.002737, loss_freq: 0.034717
[14:21:54.154] iteration 13554: loss: 0.055314, loss_s1: 0.034644, loss_fp: 0.001240, loss_freq: 0.040688
[14:21:54.783] iteration 13555: loss: 0.071919, loss_s1: 0.041439, loss_fp: 0.001285, loss_freq: 0.007684
[14:21:55.406] iteration 13556: loss: 0.060231, loss_s1: 0.032175, loss_fp: 0.002682, loss_freq: 0.030984
[14:21:56.031] iteration 13557: loss: 0.098475, loss_s1: 0.094421, loss_fp: 0.003206, loss_freq: 0.017697
[14:21:56.661] iteration 13558: loss: 0.061490, loss_s1: 0.056345, loss_fp: 0.001435, loss_freq: 0.011615
[14:21:57.280] iteration 13559: loss: 0.104835, loss_s1: 0.046315, loss_fp: 0.002144, loss_freq: 0.080603
[14:21:57.906] iteration 13560: loss: 0.077204, loss_s1: 0.082234, loss_fp: 0.002689, loss_freq: 0.017804
[14:21:58.577] iteration 13561: loss: 0.078067, loss_s1: 0.099722, loss_fp: 0.003959, loss_freq: 0.005653
[14:21:59.259] iteration 13562: loss: 0.103783, loss_s1: 0.113702, loss_fp: 0.013115, loss_freq: 0.024013
[14:21:59.879] iteration 13563: loss: 0.063791, loss_s1: 0.042387, loss_fp: 0.001352, loss_freq: 0.027372
[14:22:00.508] iteration 13564: loss: 0.060230, loss_s1: 0.033567, loss_fp: 0.000738, loss_freq: 0.018684
[14:22:01.132] iteration 13565: loss: 0.029495, loss_s1: 0.003366, loss_fp: 0.000456, loss_freq: 0.002237
[14:22:01.748] iteration 13566: loss: 0.065891, loss_s1: 0.053861, loss_fp: 0.026149, loss_freq: 0.020808
[14:22:02.375] iteration 13567: loss: 0.065604, loss_s1: 0.059796, loss_fp: 0.000984, loss_freq: 0.027265
[14:22:03.002] iteration 13568: loss: 0.081868, loss_s1: 0.027651, loss_fp: 0.001322, loss_freq: 0.034297
[14:22:03.628] iteration 13569: loss: 0.081846, loss_s1: 0.049989, loss_fp: 0.000940, loss_freq: 0.066133
[14:22:04.277] iteration 13570: loss: 0.057698, loss_s1: 0.026697, loss_fp: 0.001201, loss_freq: 0.029321
[14:22:04.945] iteration 13571: loss: 0.090257, loss_s1: 0.070499, loss_fp: 0.005226, loss_freq: 0.028501
[14:22:05.626] iteration 13572: loss: 0.047338, loss_s1: 0.018165, loss_fp: 0.001345, loss_freq: 0.012651
[14:22:06.244] iteration 13573: loss: 0.099170, loss_s1: 0.054346, loss_fp: 0.006290, loss_freq: 0.047270
[14:22:06.866] iteration 13574: loss: 0.091738, loss_s1: 0.044734, loss_fp: 0.021383, loss_freq: 0.045347
[14:22:07.489] iteration 13575: loss: 0.074891, loss_s1: 0.068108, loss_fp: 0.002064, loss_freq: 0.023495
[14:22:08.115] iteration 13576: loss: 0.082472, loss_s1: 0.056298, loss_fp: 0.004623, loss_freq: 0.042581
[14:22:08.741] iteration 13577: loss: 0.095411, loss_s1: 0.050932, loss_fp: 0.003132, loss_freq: 0.056534
[14:22:09.360] iteration 13578: loss: 0.053745, loss_s1: 0.046523, loss_fp: 0.007624, loss_freq: 0.020205
[14:22:09.974] iteration 13579: loss: 0.081975, loss_s1: 0.083139, loss_fp: 0.008383, loss_freq: 0.012461
[14:22:10.599] iteration 13580: loss: 0.058293, loss_s1: 0.048158, loss_fp: 0.002836, loss_freq: 0.017677
[14:22:11.225] iteration 13581: loss: 0.055567, loss_s1: 0.042286, loss_fp: 0.002400, loss_freq: 0.022220
[14:22:11.844] iteration 13582: loss: 0.077019, loss_s1: 0.040743, loss_fp: 0.005409, loss_freq: 0.027982
[14:22:12.479] iteration 13583: loss: 0.093297, loss_s1: 0.087008, loss_fp: 0.004601, loss_freq: 0.056110
[14:22:13.097] iteration 13584: loss: 0.195145, loss_s1: 0.196379, loss_fp: 0.003467, loss_freq: 0.123304
[14:22:13.724] iteration 13585: loss: 0.038472, loss_s1: 0.012427, loss_fp: 0.000813, loss_freq: 0.009184
[14:22:14.685] iteration 13586: loss: 0.048780, loss_s1: 0.039357, loss_fp: 0.001951, loss_freq: 0.005254
[14:22:15.364] iteration 13587: loss: 0.060103, loss_s1: 0.045030, loss_fp: 0.001193, loss_freq: 0.026563
[14:22:16.029] iteration 13588: loss: 0.033657, loss_s1: 0.015625, loss_fp: 0.001229, loss_freq: 0.011625
[14:22:16.699] iteration 13589: loss: 0.067025, loss_s1: 0.025674, loss_fp: 0.000511, loss_freq: 0.025964
[14:22:17.366] iteration 13590: loss: 0.072770, loss_s1: 0.071465, loss_fp: 0.000715, loss_freq: 0.025824
[14:22:18.030] iteration 13591: loss: 0.067173, loss_s1: 0.023329, loss_fp: 0.002947, loss_freq: 0.004887
[14:22:18.672] iteration 13592: loss: 0.041384, loss_s1: 0.012815, loss_fp: 0.003597, loss_freq: 0.027832
[14:22:19.297] iteration 13593: loss: 0.072164, loss_s1: 0.042130, loss_fp: 0.009554, loss_freq: 0.024135
[14:22:19.927] iteration 13594: loss: 0.069834, loss_s1: 0.051427, loss_fp: 0.000830, loss_freq: 0.029829
[14:22:20.552] iteration 13595: loss: 0.066403, loss_s1: 0.006359, loss_fp: 0.000516, loss_freq: 0.017686
[14:22:21.184] iteration 13596: loss: 0.073291, loss_s1: 0.036726, loss_fp: 0.004914, loss_freq: 0.037295
[14:22:21.873] iteration 13597: loss: 0.055964, loss_s1: 0.023637, loss_fp: 0.006585, loss_freq: 0.017209
[14:22:22.549] iteration 13598: loss: 0.064816, loss_s1: 0.036453, loss_fp: 0.002416, loss_freq: 0.030650
[14:22:23.218] iteration 13599: loss: 0.044240, loss_s1: 0.032458, loss_fp: 0.003470, loss_freq: 0.009138
[14:22:23.886] iteration 13600: loss: 0.084637, loss_s1: 0.061819, loss_fp: 0.001564, loss_freq: 0.052927
[14:22:27.331] iteration 13600 : mean_dice : 0.756919
[14:22:27.971] iteration 13601: loss: 0.056617, loss_s1: 0.033375, loss_fp: 0.003685, loss_freq: 0.029861
[14:22:28.595] iteration 13602: loss: 0.064721, loss_s1: 0.035278, loss_fp: 0.000463, loss_freq: 0.043209
[14:22:29.256] iteration 13603: loss: 0.064335, loss_s1: 0.029646, loss_fp: 0.004212, loss_freq: 0.021242
[14:22:29.939] iteration 13604: loss: 0.051021, loss_s1: 0.034349, loss_fp: 0.001653, loss_freq: 0.016861
[14:22:30.575] iteration 13605: loss: 0.063224, loss_s1: 0.051619, loss_fp: 0.001125, loss_freq: 0.034620
[14:22:31.198] iteration 13606: loss: 0.105425, loss_s1: 0.054183, loss_fp: 0.003352, loss_freq: 0.072723
[14:22:31.855] iteration 13607: loss: 0.045461, loss_s1: 0.022653, loss_fp: 0.001291, loss_freq: 0.018594
[14:22:32.512] iteration 13608: loss: 0.056804, loss_s1: 0.026199, loss_fp: 0.002512, loss_freq: 0.028559
[14:22:33.156] iteration 13609: loss: 0.043591, loss_s1: 0.032743, loss_fp: 0.003140, loss_freq: 0.009655
[14:22:33.786] iteration 13610: loss: 0.052073, loss_s1: 0.042675, loss_fp: 0.002200, loss_freq: 0.014661
[14:22:34.429] iteration 13611: loss: 0.117703, loss_s1: 0.110500, loss_fp: 0.006007, loss_freq: 0.051746
[14:22:35.092] iteration 13612: loss: 0.099200, loss_s1: 0.065266, loss_fp: 0.002097, loss_freq: 0.083708
[14:22:35.751] iteration 13613: loss: 0.071213, loss_s1: 0.059632, loss_fp: 0.002708, loss_freq: 0.008472
[14:22:36.407] iteration 13614: loss: 0.078672, loss_s1: 0.044006, loss_fp: 0.001029, loss_freq: 0.028979
[14:22:37.053] iteration 13615: loss: 0.054128, loss_s1: 0.026694, loss_fp: 0.001132, loss_freq: 0.009340
[14:22:37.677] iteration 13616: loss: 0.062464, loss_s1: 0.038223, loss_fp: 0.001380, loss_freq: 0.016748
[14:22:38.304] iteration 13617: loss: 0.057487, loss_s1: 0.039395, loss_fp: 0.003176, loss_freq: 0.025557
[14:22:38.932] iteration 13618: loss: 0.058483, loss_s1: 0.044042, loss_fp: 0.007126, loss_freq: 0.031194
[14:22:39.559] iteration 13619: loss: 0.091451, loss_s1: 0.073897, loss_fp: 0.007517, loss_freq: 0.055527
[14:22:40.181] iteration 13620: loss: 0.094393, loss_s1: 0.057998, loss_fp: 0.001505, loss_freq: 0.038368
[14:22:40.804] iteration 13621: loss: 0.052275, loss_s1: 0.033138, loss_fp: 0.002382, loss_freq: 0.022332
[14:22:41.438] iteration 13622: loss: 0.097095, loss_s1: 0.086164, loss_fp: 0.010122, loss_freq: 0.036165
[14:22:42.062] iteration 13623: loss: 0.062316, loss_s1: 0.043525, loss_fp: 0.007833, loss_freq: 0.023854
[14:22:42.687] iteration 13624: loss: 0.088550, loss_s1: 0.062964, loss_fp: 0.004389, loss_freq: 0.040135
[14:22:43.311] iteration 13625: loss: 0.055972, loss_s1: 0.057412, loss_fp: 0.003202, loss_freq: 0.007416
[14:22:43.938] iteration 13626: loss: 0.111487, loss_s1: 0.065689, loss_fp: 0.005046, loss_freq: 0.043412
[14:22:44.560] iteration 13627: loss: 0.036657, loss_s1: 0.016587, loss_fp: 0.000980, loss_freq: 0.016716
[14:22:45.178] iteration 13628: loss: 0.076083, loss_s1: 0.015704, loss_fp: 0.001244, loss_freq: 0.005736
[14:22:45.807] iteration 13629: loss: 0.083148, loss_s1: 0.057035, loss_fp: 0.006462, loss_freq: 0.050164
[14:22:46.433] iteration 13630: loss: 0.102742, loss_s1: 0.057418, loss_fp: 0.004551, loss_freq: 0.010474
[14:22:47.056] iteration 13631: loss: 0.078744, loss_s1: 0.035207, loss_fp: 0.000859, loss_freq: 0.057243
[14:22:47.676] iteration 13632: loss: 0.082594, loss_s1: 0.043877, loss_fp: 0.001491, loss_freq: 0.058812
[14:22:48.303] iteration 13633: loss: 0.110035, loss_s1: 0.136712, loss_fp: 0.000972, loss_freq: 0.026741
[14:22:48.927] iteration 13634: loss: 0.078818, loss_s1: 0.061087, loss_fp: 0.003803, loss_freq: 0.039436
[14:22:49.547] iteration 13635: loss: 0.057892, loss_s1: 0.021105, loss_fp: 0.001301, loss_freq: 0.024661
[14:22:50.166] iteration 13636: loss: 0.068219, loss_s1: 0.076755, loss_fp: 0.002756, loss_freq: 0.015110
[14:22:50.789] iteration 13637: loss: 0.067527, loss_s1: 0.023364, loss_fp: 0.001382, loss_freq: 0.057121
[14:22:51.416] iteration 13638: loss: 0.033232, loss_s1: 0.021141, loss_fp: 0.002367, loss_freq: 0.006043
[14:22:52.038] iteration 13639: loss: 0.043342, loss_s1: 0.023264, loss_fp: 0.002570, loss_freq: 0.014641
[14:22:52.666] iteration 13640: loss: 0.042954, loss_s1: 0.033051, loss_fp: 0.000807, loss_freq: 0.009624
[14:22:53.299] iteration 13641: loss: 0.070330, loss_s1: 0.040867, loss_fp: 0.000658, loss_freq: 0.012659
[14:22:53.924] iteration 13642: loss: 0.103381, loss_s1: 0.130875, loss_fp: 0.000836, loss_freq: 0.021913
[14:22:54.556] iteration 13643: loss: 0.061487, loss_s1: 0.033510, loss_fp: 0.001408, loss_freq: 0.010647
[14:22:55.176] iteration 13644: loss: 0.076317, loss_s1: 0.043897, loss_fp: 0.004687, loss_freq: 0.055691
[14:22:55.814] iteration 13645: loss: 0.057949, loss_s1: 0.033186, loss_fp: 0.001529, loss_freq: 0.017027
[14:22:56.442] iteration 13646: loss: 0.045764, loss_s1: 0.017966, loss_fp: 0.003376, loss_freq: 0.019685
[14:22:57.131] iteration 13647: loss: 0.087751, loss_s1: 0.037262, loss_fp: 0.002418, loss_freq: 0.027844
[14:22:57.776] iteration 13648: loss: 0.069790, loss_s1: 0.067111, loss_fp: 0.001034, loss_freq: 0.009798
[14:22:58.459] iteration 13649: loss: 0.090925, loss_s1: 0.049522, loss_fp: 0.001611, loss_freq: 0.033899
[14:22:59.092] iteration 13650: loss: 0.060119, loss_s1: 0.017015, loss_fp: 0.003244, loss_freq: 0.025861
[14:22:59.710] iteration 13651: loss: 0.061803, loss_s1: 0.029089, loss_fp: 0.027929, loss_freq: 0.024143
[14:23:00.341] iteration 13652: loss: 0.109510, loss_s1: 0.076851, loss_fp: 0.010859, loss_freq: 0.065617
[14:23:00.967] iteration 13653: loss: 0.043811, loss_s1: 0.024927, loss_fp: 0.003672, loss_freq: 0.020103
[14:23:01.642] iteration 13654: loss: 0.058217, loss_s1: 0.030930, loss_fp: 0.004510, loss_freq: 0.021060
[14:23:02.281] iteration 13655: loss: 0.055899, loss_s1: 0.019045, loss_fp: 0.001805, loss_freq: 0.011783
[14:23:02.914] iteration 13656: loss: 0.061838, loss_s1: 0.040426, loss_fp: 0.002622, loss_freq: 0.022705
[14:23:03.548] iteration 13657: loss: 0.056054, loss_s1: 0.025357, loss_fp: 0.003603, loss_freq: 0.018861
[14:23:04.181] iteration 13658: loss: 0.071262, loss_s1: 0.039392, loss_fp: 0.003004, loss_freq: 0.051078
[14:23:04.815] iteration 13659: loss: 0.073884, loss_s1: 0.022575, loss_fp: 0.006598, loss_freq: 0.048125
[14:23:05.448] iteration 13660: loss: 0.080063, loss_s1: 0.057887, loss_fp: 0.001934, loss_freq: 0.059750
[14:23:06.090] iteration 13661: loss: 0.060540, loss_s1: 0.042989, loss_fp: 0.003382, loss_freq: 0.022155
[14:23:06.720] iteration 13662: loss: 0.070480, loss_s1: 0.051562, loss_fp: 0.002195, loss_freq: 0.047484
[14:23:07.347] iteration 13663: loss: 0.074469, loss_s1: 0.067080, loss_fp: 0.002200, loss_freq: 0.012444
[14:23:07.977] iteration 13664: loss: 0.057086, loss_s1: 0.046085, loss_fp: 0.006376, loss_freq: 0.020517
[14:23:08.602] iteration 13665: loss: 0.114854, loss_s1: 0.082449, loss_fp: 0.005534, loss_freq: 0.038026
[14:23:09.233] iteration 13666: loss: 0.040143, loss_s1: 0.016318, loss_fp: 0.002445, loss_freq: 0.012746
[14:23:09.885] iteration 13667: loss: 0.089147, loss_s1: 0.064906, loss_fp: 0.005497, loss_freq: 0.053203
[14:23:10.545] iteration 13668: loss: 0.060277, loss_s1: 0.041590, loss_fp: 0.003283, loss_freq: 0.014994
[14:23:11.205] iteration 13669: loss: 0.044567, loss_s1: 0.022935, loss_fp: 0.000903, loss_freq: 0.021921
[14:23:11.837] iteration 13670: loss: 0.088068, loss_s1: 0.058412, loss_fp: 0.001055, loss_freq: 0.025529
[14:23:12.468] iteration 13671: loss: 0.077478, loss_s1: 0.040556, loss_fp: 0.006371, loss_freq: 0.032039
[14:23:13.091] iteration 13672: loss: 0.048783, loss_s1: 0.033907, loss_fp: 0.002611, loss_freq: 0.009112
[14:23:13.714] iteration 13673: loss: 0.043089, loss_s1: 0.018558, loss_fp: 0.005283, loss_freq: 0.019067
[14:23:14.348] iteration 13674: loss: 0.053076, loss_s1: 0.041375, loss_fp: 0.001005, loss_freq: 0.013942
[14:23:14.977] iteration 13675: loss: 0.054247, loss_s1: 0.052146, loss_fp: 0.001112, loss_freq: 0.017912
[14:23:15.611] iteration 13676: loss: 0.078137, loss_s1: 0.029484, loss_fp: 0.000368, loss_freq: 0.020369
[14:23:16.242] iteration 13677: loss: 0.077984, loss_s1: 0.074206, loss_fp: 0.003609, loss_freq: 0.033583
[14:23:16.985] iteration 13678: loss: 0.037727, loss_s1: 0.028161, loss_fp: 0.002944, loss_freq: 0.004765
[14:23:17.836] iteration 13679: loss: 0.057636, loss_s1: 0.040395, loss_fp: 0.005328, loss_freq: 0.007126
[14:23:18.554] iteration 13680: loss: 0.050769, loss_s1: 0.017100, loss_fp: 0.000560, loss_freq: 0.029333
[14:23:19.210] iteration 13681: loss: 0.042051, loss_s1: 0.020971, loss_fp: 0.004726, loss_freq: 0.015153
[14:23:19.837] iteration 13682: loss: 0.101780, loss_s1: 0.069289, loss_fp: 0.015022, loss_freq: 0.035239
[14:23:20.479] iteration 13683: loss: 0.069171, loss_s1: 0.058478, loss_fp: 0.001211, loss_freq: 0.021568
[14:23:21.110] iteration 13684: loss: 0.039359, loss_s1: 0.008547, loss_fp: 0.001484, loss_freq: 0.005718
[14:23:21.737] iteration 13685: loss: 0.095640, loss_s1: 0.035716, loss_fp: 0.005928, loss_freq: 0.067482
[14:23:22.358] iteration 13686: loss: 0.045876, loss_s1: 0.032773, loss_fp: 0.001898, loss_freq: 0.015430
[14:23:22.979] iteration 13687: loss: 0.083726, loss_s1: 0.078543, loss_fp: 0.003552, loss_freq: 0.027069
[14:23:23.606] iteration 13688: loss: 0.044473, loss_s1: 0.023252, loss_fp: 0.008250, loss_freq: 0.012406
[14:23:24.238] iteration 13689: loss: 0.055250, loss_s1: 0.020953, loss_fp: 0.007591, loss_freq: 0.033623
[14:23:24.866] iteration 13690: loss: 0.091181, loss_s1: 0.041394, loss_fp: 0.014583, loss_freq: 0.039772
[14:23:25.519] iteration 13691: loss: 0.052431, loss_s1: 0.015761, loss_fp: 0.004507, loss_freq: 0.034847
[14:23:26.179] iteration 13692: loss: 0.199347, loss_s1: 0.186334, loss_fp: 0.006772, loss_freq: 0.139583
[14:23:26.841] iteration 13693: loss: 0.084482, loss_s1: 0.043574, loss_fp: 0.009962, loss_freq: 0.069184
[14:23:27.501] iteration 13694: loss: 0.109298, loss_s1: 0.041088, loss_fp: 0.007839, loss_freq: 0.045201
[14:23:28.158] iteration 13695: loss: 0.077854, loss_s1: 0.067879, loss_fp: 0.007106, loss_freq: 0.013931
[14:23:28.836] iteration 13696: loss: 0.072364, loss_s1: 0.030346, loss_fp: 0.005363, loss_freq: 0.011179
[14:23:29.495] iteration 13697: loss: 0.052468, loss_s1: 0.031971, loss_fp: 0.001918, loss_freq: 0.034524
[14:23:30.151] iteration 13698: loss: 0.072830, loss_s1: 0.015747, loss_fp: 0.001730, loss_freq: 0.011990
[14:23:30.790] iteration 13699: loss: 0.072520, loss_s1: 0.065369, loss_fp: 0.014264, loss_freq: 0.015280
[14:23:31.421] iteration 13700: loss: 0.100041, loss_s1: 0.040369, loss_fp: 0.000360, loss_freq: 0.024699
[14:23:32.053] iteration 13701: loss: 0.052468, loss_s1: 0.049841, loss_fp: 0.000540, loss_freq: 0.003949
[14:23:32.684] iteration 13702: loss: 0.120726, loss_s1: 0.079837, loss_fp: 0.001608, loss_freq: 0.087078
[14:23:33.310] iteration 13703: loss: 0.067538, loss_s1: 0.041517, loss_fp: 0.002419, loss_freq: 0.030851
[14:23:33.941] iteration 13704: loss: 0.064719, loss_s1: 0.056127, loss_fp: 0.000988, loss_freq: 0.032674
[14:23:34.573] iteration 13705: loss: 0.058746, loss_s1: 0.044527, loss_fp: 0.001166, loss_freq: 0.023712
[14:23:35.202] iteration 13706: loss: 0.077516, loss_s1: 0.060207, loss_fp: 0.003743, loss_freq: 0.040648
[14:23:35.828] iteration 13707: loss: 0.066863, loss_s1: 0.035841, loss_fp: 0.005820, loss_freq: 0.027066
[14:23:36.456] iteration 13708: loss: 0.038262, loss_s1: 0.018152, loss_fp: 0.000769, loss_freq: 0.010818
[14:23:37.081] iteration 13709: loss: 0.070257, loss_s1: 0.061971, loss_fp: 0.003855, loss_freq: 0.037327
[14:23:37.706] iteration 13710: loss: 0.082992, loss_s1: 0.094324, loss_fp: 0.003058, loss_freq: 0.020980
[14:23:38.336] iteration 13711: loss: 0.088758, loss_s1: 0.043640, loss_fp: 0.002677, loss_freq: 0.016864
[14:23:38.969] iteration 13712: loss: 0.039441, loss_s1: 0.022212, loss_fp: 0.001139, loss_freq: 0.018112
[14:23:39.605] iteration 13713: loss: 0.069817, loss_s1: 0.060366, loss_fp: 0.001558, loss_freq: 0.030507
[14:23:40.238] iteration 13714: loss: 0.080266, loss_s1: 0.086626, loss_fp: 0.003616, loss_freq: 0.029756
[14:23:40.870] iteration 13715: loss: 0.057088, loss_s1: 0.056651, loss_fp: 0.003170, loss_freq: 0.010230
[14:23:41.502] iteration 13716: loss: 0.050842, loss_s1: 0.013505, loss_fp: 0.008969, loss_freq: 0.018199
[14:23:42.129] iteration 13717: loss: 0.066400, loss_s1: 0.059839, loss_fp: 0.008408, loss_freq: 0.014927
[14:23:42.759] iteration 13718: loss: 0.070709, loss_s1: 0.035594, loss_fp: 0.007504, loss_freq: 0.031919
[14:23:43.387] iteration 13719: loss: 0.114441, loss_s1: 0.099796, loss_fp: 0.012680, loss_freq: 0.048086
[14:23:44.007] iteration 13720: loss: 0.050268, loss_s1: 0.007129, loss_fp: 0.004573, loss_freq: 0.040627
[14:23:44.706] iteration 13721: loss: 0.093092, loss_s1: 0.085562, loss_fp: 0.002778, loss_freq: 0.035233
[14:23:45.364] iteration 13722: loss: 0.079711, loss_s1: 0.057377, loss_fp: 0.018224, loss_freq: 0.032007
[14:23:46.019] iteration 13723: loss: 0.039252, loss_s1: 0.007395, loss_fp: 0.006098, loss_freq: 0.008199
[14:23:46.676] iteration 13724: loss: 0.058783, loss_s1: 0.044740, loss_fp: 0.002851, loss_freq: 0.024225
[14:23:47.343] iteration 13725: loss: 0.090263, loss_s1: 0.033070, loss_fp: 0.006934, loss_freq: 0.038138
[14:23:48.007] iteration 13726: loss: 0.070399, loss_s1: 0.029991, loss_fp: 0.003726, loss_freq: 0.048663
[14:23:48.664] iteration 13727: loss: 0.098081, loss_s1: 0.062726, loss_fp: 0.013997, loss_freq: 0.058284
[14:23:49.325] iteration 13728: loss: 0.034259, loss_s1: 0.017628, loss_fp: 0.000399, loss_freq: 0.010972
[14:23:50.334] iteration 13729: loss: 0.063076, loss_s1: 0.064652, loss_fp: 0.000519, loss_freq: 0.009208
[14:23:50.984] iteration 13730: loss: 0.100868, loss_s1: 0.098921, loss_fp: 0.004225, loss_freq: 0.045298
[14:23:51.668] iteration 13731: loss: 0.059657, loss_s1: 0.026857, loss_fp: 0.000880, loss_freq: 0.054968
[14:23:52.329] iteration 13732: loss: 0.135532, loss_s1: 0.123124, loss_fp: 0.005240, loss_freq: 0.062651
[14:23:53.020] iteration 13733: loss: 0.069897, loss_s1: 0.046725, loss_fp: 0.006519, loss_freq: 0.041009
[14:23:53.645] iteration 13734: loss: 0.060297, loss_s1: 0.048262, loss_fp: 0.000771, loss_freq: 0.011038
[14:23:54.276] iteration 13735: loss: 0.043350, loss_s1: 0.017805, loss_fp: 0.002129, loss_freq: 0.031559
[14:23:54.909] iteration 13736: loss: 0.094283, loss_s1: 0.033824, loss_fp: 0.006308, loss_freq: 0.073083
[14:23:55.538] iteration 13737: loss: 0.068747, loss_s1: 0.035855, loss_fp: 0.002926, loss_freq: 0.035108
[14:23:56.161] iteration 13738: loss: 0.048570, loss_s1: 0.023565, loss_fp: 0.000730, loss_freq: 0.004952
[14:23:56.791] iteration 13739: loss: 0.069159, loss_s1: 0.047589, loss_fp: 0.006010, loss_freq: 0.031688
[14:23:57.421] iteration 13740: loss: 0.059222, loss_s1: 0.010483, loss_fp: 0.001396, loss_freq: 0.009970
[14:23:58.045] iteration 13741: loss: 0.085849, loss_s1: 0.070288, loss_fp: 0.002311, loss_freq: 0.013438
[14:23:58.716] iteration 13742: loss: 0.065790, loss_s1: 0.030522, loss_fp: 0.006542, loss_freq: 0.042316
[14:23:59.393] iteration 13743: loss: 0.071825, loss_s1: 0.020017, loss_fp: 0.005846, loss_freq: 0.044068
[14:24:00.054] iteration 13744: loss: 0.070326, loss_s1: 0.057626, loss_fp: 0.005724, loss_freq: 0.023105
[14:24:00.712] iteration 13745: loss: 0.071128, loss_s1: 0.028350, loss_fp: 0.001128, loss_freq: 0.029652
[14:24:01.369] iteration 13746: loss: 0.057764, loss_s1: 0.040762, loss_fp: 0.003139, loss_freq: 0.023933
[14:24:02.027] iteration 13747: loss: 0.045827, loss_s1: 0.011252, loss_fp: 0.004922, loss_freq: 0.015008
[14:24:02.715] iteration 13748: loss: 0.066885, loss_s1: 0.032581, loss_fp: 0.005857, loss_freq: 0.010747
[14:24:03.377] iteration 13749: loss: 0.094794, loss_s1: 0.066565, loss_fp: 0.001988, loss_freq: 0.049875
[14:24:04.037] iteration 13750: loss: 0.052106, loss_s1: 0.025554, loss_fp: 0.006181, loss_freq: 0.033187
[14:24:04.693] iteration 13751: loss: 0.050565, loss_s1: 0.010834, loss_fp: 0.003130, loss_freq: 0.035621
[14:24:05.351] iteration 13752: loss: 0.079833, loss_s1: 0.031037, loss_fp: 0.001530, loss_freq: 0.015886
[14:24:06.000] iteration 13753: loss: 0.060957, loss_s1: 0.024137, loss_fp: 0.001186, loss_freq: 0.023256
[14:24:06.629] iteration 13754: loss: 0.165873, loss_s1: 0.119782, loss_fp: 0.001475, loss_freq: 0.069560
[14:24:07.259] iteration 13755: loss: 0.089666, loss_s1: 0.053774, loss_fp: 0.003415, loss_freq: 0.042793
[14:24:07.886] iteration 13756: loss: 0.059036, loss_s1: 0.020724, loss_fp: 0.006262, loss_freq: 0.011569
[14:24:08.504] iteration 13757: loss: 0.082570, loss_s1: 0.014132, loss_fp: 0.004060, loss_freq: 0.038555
[14:24:09.135] iteration 13758: loss: 0.073341, loss_s1: 0.037860, loss_fp: 0.000452, loss_freq: 0.021194
[14:24:09.757] iteration 13759: loss: 0.044784, loss_s1: 0.017859, loss_fp: 0.002908, loss_freq: 0.004897
[14:24:10.378] iteration 13760: loss: 0.052335, loss_s1: 0.039633, loss_fp: 0.002082, loss_freq: 0.013739
[14:24:11.007] iteration 13761: loss: 0.049769, loss_s1: 0.037580, loss_fp: 0.004984, loss_freq: 0.023815
[14:24:11.626] iteration 13762: loss: 0.069329, loss_s1: 0.056615, loss_fp: 0.003758, loss_freq: 0.037272
[14:24:12.246] iteration 13763: loss: 0.069083, loss_s1: 0.032617, loss_fp: 0.002888, loss_freq: 0.015370
[14:24:12.867] iteration 13764: loss: 0.076121, loss_s1: 0.069124, loss_fp: 0.004057, loss_freq: 0.016063
[14:24:13.498] iteration 13765: loss: 0.068294, loss_s1: 0.043826, loss_fp: 0.001304, loss_freq: 0.039411
[14:24:14.127] iteration 13766: loss: 0.033089, loss_s1: 0.017675, loss_fp: 0.001658, loss_freq: 0.012198
[14:24:14.748] iteration 13767: loss: 0.093843, loss_s1: 0.066757, loss_fp: 0.001550, loss_freq: 0.022728
[14:24:15.365] iteration 13768: loss: 0.066048, loss_s1: 0.063005, loss_fp: 0.006836, loss_freq: 0.022440
[14:24:15.996] iteration 13769: loss: 0.076759, loss_s1: 0.031152, loss_fp: 0.001742, loss_freq: 0.012311
[14:24:16.624] iteration 13770: loss: 0.062857, loss_s1: 0.064709, loss_fp: 0.000955, loss_freq: 0.025920
[14:24:17.255] iteration 13771: loss: 0.069460, loss_s1: 0.030573, loss_fp: 0.001700, loss_freq: 0.029508
[14:24:17.892] iteration 13772: loss: 0.072318, loss_s1: 0.031822, loss_fp: 0.005081, loss_freq: 0.051036
[14:24:18.529] iteration 13773: loss: 0.080109, loss_s1: 0.055805, loss_fp: 0.002500, loss_freq: 0.010538
[14:24:19.158] iteration 13774: loss: 0.087248, loss_s1: 0.072454, loss_fp: 0.000698, loss_freq: 0.035656
[14:24:19.809] iteration 13775: loss: 0.070187, loss_s1: 0.034819, loss_fp: 0.001601, loss_freq: 0.057124
[14:24:20.425] iteration 13776: loss: 0.061310, loss_s1: 0.024740, loss_fp: 0.002477, loss_freq: 0.030906
[14:24:21.052] iteration 13777: loss: 0.048314, loss_s1: 0.041922, loss_fp: 0.001706, loss_freq: 0.015330
[14:24:21.677] iteration 13778: loss: 0.067749, loss_s1: 0.048546, loss_fp: 0.001451, loss_freq: 0.031945
[14:24:22.307] iteration 13779: loss: 0.074382, loss_s1: 0.056940, loss_fp: 0.006306, loss_freq: 0.032558
[14:24:22.924] iteration 13780: loss: 0.064422, loss_s1: 0.029109, loss_fp: 0.001050, loss_freq: 0.022718
[14:24:23.544] iteration 13781: loss: 0.055482, loss_s1: 0.022210, loss_fp: 0.003108, loss_freq: 0.021460
[14:24:24.168] iteration 13782: loss: 0.042698, loss_s1: 0.034468, loss_fp: 0.001616, loss_freq: 0.012251
[14:24:24.791] iteration 13783: loss: 0.046942, loss_s1: 0.007598, loss_fp: 0.001501, loss_freq: 0.010486
[14:24:25.411] iteration 13784: loss: 0.069161, loss_s1: 0.034399, loss_fp: 0.000828, loss_freq: 0.013805
[14:24:26.037] iteration 13785: loss: 0.075842, loss_s1: 0.062386, loss_fp: 0.001512, loss_freq: 0.019388
[14:24:26.666] iteration 13786: loss: 0.047202, loss_s1: 0.015722, loss_fp: 0.001456, loss_freq: 0.015293
[14:24:27.298] iteration 13787: loss: 0.109038, loss_s1: 0.035380, loss_fp: 0.006945, loss_freq: 0.082251
[14:24:27.920] iteration 13788: loss: 0.042371, loss_s1: 0.016955, loss_fp: 0.001099, loss_freq: 0.022039
[14:24:28.553] iteration 13789: loss: 0.059468, loss_s1: 0.018121, loss_fp: 0.006966, loss_freq: 0.010105
[14:24:29.188] iteration 13790: loss: 0.072205, loss_s1: 0.036336, loss_fp: 0.003931, loss_freq: 0.023661
[14:24:29.821] iteration 13791: loss: 0.057235, loss_s1: 0.033080, loss_fp: 0.004164, loss_freq: 0.026688
[14:24:30.451] iteration 13792: loss: 0.051448, loss_s1: 0.022923, loss_fp: 0.001003, loss_freq: 0.020918
[14:24:31.081] iteration 13793: loss: 0.095815, loss_s1: 0.047051, loss_fp: 0.001922, loss_freq: 0.077444
[14:24:31.718] iteration 13794: loss: 0.061547, loss_s1: 0.013524, loss_fp: 0.001652, loss_freq: 0.011532
[14:24:32.352] iteration 13795: loss: 0.115256, loss_s1: 0.101713, loss_fp: 0.005645, loss_freq: 0.061049
[14:24:32.979] iteration 13796: loss: 0.060423, loss_s1: 0.019539, loss_fp: 0.001993, loss_freq: 0.021170
[14:24:33.621] iteration 13797: loss: 0.051266, loss_s1: 0.032396, loss_fp: 0.001359, loss_freq: 0.016275
[14:24:34.252] iteration 13798: loss: 0.051143, loss_s1: 0.028369, loss_fp: 0.001200, loss_freq: 0.009321
[14:24:34.894] iteration 13799: loss: 0.071502, loss_s1: 0.076237, loss_fp: 0.002345, loss_freq: 0.018040
[14:24:35.548] iteration 13800: loss: 0.078456, loss_s1: 0.037685, loss_fp: 0.000984, loss_freq: 0.025423
[14:24:39.239] iteration 13800 : mean_dice : 0.766644
[14:24:39.919] iteration 13801: loss: 0.066932, loss_s1: 0.036732, loss_fp: 0.002031, loss_freq: 0.050467
[14:24:40.538] iteration 13802: loss: 0.064329, loss_s1: 0.032508, loss_fp: 0.013747, loss_freq: 0.022182
[14:24:41.164] iteration 13803: loss: 0.071745, loss_s1: 0.034669, loss_fp: 0.002902, loss_freq: 0.056396
[14:24:41.788] iteration 13804: loss: 0.078382, loss_s1: 0.041174, loss_fp: 0.003463, loss_freq: 0.025216
[14:24:42.407] iteration 13805: loss: 0.040498, loss_s1: 0.028395, loss_fp: 0.002796, loss_freq: 0.010498
[14:24:43.033] iteration 13806: loss: 0.074444, loss_s1: 0.054176, loss_fp: 0.002408, loss_freq: 0.014262
[14:24:43.656] iteration 13807: loss: 0.064562, loss_s1: 0.042966, loss_fp: 0.003117, loss_freq: 0.031342
[14:24:44.283] iteration 13808: loss: 0.195677, loss_s1: 0.076551, loss_fp: 0.001161, loss_freq: 0.021288
[14:24:44.912] iteration 13809: loss: 0.054922, loss_s1: 0.020293, loss_fp: 0.003255, loss_freq: 0.034748
[14:24:45.530] iteration 13810: loss: 0.082874, loss_s1: 0.031140, loss_fp: 0.001309, loss_freq: 0.057507
[14:24:46.155] iteration 13811: loss: 0.053648, loss_s1: 0.012652, loss_fp: 0.004254, loss_freq: 0.016387
[14:24:46.789] iteration 13812: loss: 0.052934, loss_s1: 0.040927, loss_fp: 0.003390, loss_freq: 0.021091
[14:24:47.416] iteration 13813: loss: 0.064150, loss_s1: 0.052519, loss_fp: 0.004077, loss_freq: 0.025227
[14:24:48.039] iteration 13814: loss: 0.056635, loss_s1: 0.024182, loss_fp: 0.002167, loss_freq: 0.033460
[14:24:48.661] iteration 13815: loss: 0.081013, loss_s1: 0.044327, loss_fp: 0.001600, loss_freq: 0.026907
[14:24:49.275] iteration 13816: loss: 0.050391, loss_s1: 0.044200, loss_fp: 0.001208, loss_freq: 0.013627
[14:24:49.902] iteration 13817: loss: 0.052481, loss_s1: 0.032240, loss_fp: 0.003016, loss_freq: 0.014043
[14:24:50.527] iteration 13818: loss: 0.058452, loss_s1: 0.041058, loss_fp: 0.013428, loss_freq: 0.015496
[14:24:51.156] iteration 13819: loss: 0.074739, loss_s1: 0.019280, loss_fp: 0.003042, loss_freq: 0.034705
[14:24:51.779] iteration 13820: loss: 0.087772, loss_s1: 0.077404, loss_fp: 0.011533, loss_freq: 0.046912
[14:24:52.408] iteration 13821: loss: 0.041192, loss_s1: 0.031461, loss_fp: 0.000984, loss_freq: 0.005500
[14:24:53.034] iteration 13822: loss: 0.081932, loss_s1: 0.069204, loss_fp: 0.002139, loss_freq: 0.007655
[14:24:53.656] iteration 13823: loss: 0.040687, loss_s1: 0.015043, loss_fp: 0.000853, loss_freq: 0.017063
[14:24:54.279] iteration 13824: loss: 0.078929, loss_s1: 0.044901, loss_fp: 0.004503, loss_freq: 0.015795
[14:24:54.907] iteration 13825: loss: 0.099720, loss_s1: 0.073484, loss_fp: 0.002418, loss_freq: 0.064529
[14:24:55.534] iteration 13826: loss: 0.071354, loss_s1: 0.042831, loss_fp: 0.000868, loss_freq: 0.050176
[14:24:56.156] iteration 13827: loss: 0.076678, loss_s1: 0.031895, loss_fp: 0.007128, loss_freq: 0.026830
[14:24:56.803] iteration 13828: loss: 0.095175, loss_s1: 0.035835, loss_fp: 0.006378, loss_freq: 0.040198
[14:24:57.434] iteration 13829: loss: 0.088646, loss_s1: 0.048469, loss_fp: 0.001868, loss_freq: 0.033915
[14:24:58.067] iteration 13830: loss: 0.097422, loss_s1: 0.023624, loss_fp: 0.001596, loss_freq: 0.038461
[14:24:58.685] iteration 13831: loss: 0.053009, loss_s1: 0.042417, loss_fp: 0.003622, loss_freq: 0.014282
[14:24:59.326] iteration 13832: loss: 0.108394, loss_s1: 0.070726, loss_fp: 0.002542, loss_freq: 0.009853
[14:24:59.952] iteration 13833: loss: 0.094536, loss_s1: 0.049199, loss_fp: 0.002681, loss_freq: 0.013400
[14:25:00.575] iteration 13834: loss: 0.083599, loss_s1: 0.090557, loss_fp: 0.002099, loss_freq: 0.027861
[14:25:01.207] iteration 13835: loss: 0.097298, loss_s1: 0.072214, loss_fp: 0.001701, loss_freq: 0.066675
[14:25:01.832] iteration 13836: loss: 0.056775, loss_s1: 0.031275, loss_fp: 0.005541, loss_freq: 0.013302
[14:25:02.455] iteration 13837: loss: 0.059841, loss_s1: 0.039895, loss_fp: 0.000637, loss_freq: 0.019056
[14:25:03.078] iteration 13838: loss: 0.076467, loss_s1: 0.059395, loss_fp: 0.002989, loss_freq: 0.041320
[14:25:03.760] iteration 13839: loss: 0.080675, loss_s1: 0.061060, loss_fp: 0.001158, loss_freq: 0.011895
[14:25:04.426] iteration 13840: loss: 0.064807, loss_s1: 0.058193, loss_fp: 0.000647, loss_freq: 0.033822
[14:25:05.052] iteration 13841: loss: 0.045406, loss_s1: 0.019876, loss_fp: 0.000539, loss_freq: 0.008987
[14:25:05.680] iteration 13842: loss: 0.060714, loss_s1: 0.060320, loss_fp: 0.003199, loss_freq: 0.011013
[14:25:06.308] iteration 13843: loss: 0.078904, loss_s1: 0.050845, loss_fp: 0.004304, loss_freq: 0.010023
[14:25:06.933] iteration 13844: loss: 0.076685, loss_s1: 0.093838, loss_fp: 0.001529, loss_freq: 0.004340
[14:25:07.555] iteration 13845: loss: 0.082246, loss_s1: 0.046193, loss_fp: 0.002139, loss_freq: 0.034322
[14:25:08.179] iteration 13846: loss: 0.088277, loss_s1: 0.090627, loss_fp: 0.002895, loss_freq: 0.022510
[14:25:08.803] iteration 13847: loss: 0.043229, loss_s1: 0.014963, loss_fp: 0.005211, loss_freq: 0.009699
[14:25:09.434] iteration 13848: loss: 0.075458, loss_s1: 0.073170, loss_fp: 0.000766, loss_freq: 0.033407
[14:25:10.055] iteration 13849: loss: 0.081074, loss_s1: 0.058313, loss_fp: 0.003933, loss_freq: 0.046080
[14:25:10.685] iteration 13850: loss: 0.079911, loss_s1: 0.048950, loss_fp: 0.002741, loss_freq: 0.040734
[14:25:11.356] iteration 13851: loss: 0.062199, loss_s1: 0.023336, loss_fp: 0.002104, loss_freq: 0.018556
[14:25:12.023] iteration 13852: loss: 0.081364, loss_s1: 0.046257, loss_fp: 0.003142, loss_freq: 0.028794
[14:25:12.686] iteration 13853: loss: 0.049731, loss_s1: 0.052561, loss_fp: 0.003698, loss_freq: 0.009399
[14:25:13.350] iteration 13854: loss: 0.090161, loss_s1: 0.048874, loss_fp: 0.004720, loss_freq: 0.014020
[14:25:13.976] iteration 13855: loss: 0.038164, loss_s1: 0.007047, loss_fp: 0.001736, loss_freq: 0.023529
[14:25:14.616] iteration 13856: loss: 0.048731, loss_s1: 0.042699, loss_fp: 0.001381, loss_freq: 0.014184
[14:25:15.242] iteration 13857: loss: 0.067548, loss_s1: 0.063138, loss_fp: 0.001203, loss_freq: 0.008013
[14:25:15.871] iteration 13858: loss: 0.062645, loss_s1: 0.017516, loss_fp: 0.007593, loss_freq: 0.016315
[14:25:16.499] iteration 13859: loss: 0.063016, loss_s1: 0.061005, loss_fp: 0.002834, loss_freq: 0.010440
[14:25:17.127] iteration 13860: loss: 0.098515, loss_s1: 0.041620, loss_fp: 0.002780, loss_freq: 0.053213
[14:25:17.755] iteration 13861: loss: 0.055434, loss_s1: 0.039805, loss_fp: 0.005386, loss_freq: 0.018957
[14:25:18.381] iteration 13862: loss: 0.090211, loss_s1: 0.058424, loss_fp: 0.001461, loss_freq: 0.055659
[14:25:19.005] iteration 13863: loss: 0.106492, loss_s1: 0.058503, loss_fp: 0.007442, loss_freq: 0.033987
[14:25:19.644] iteration 13864: loss: 0.087617, loss_s1: 0.058312, loss_fp: 0.008061, loss_freq: 0.028033
[14:25:20.299] iteration 13865: loss: 0.088751, loss_s1: 0.057486, loss_fp: 0.005656, loss_freq: 0.038781
[14:25:20.948] iteration 13866: loss: 0.043796, loss_s1: 0.011114, loss_fp: 0.001528, loss_freq: 0.021932
[14:25:21.586] iteration 13867: loss: 0.067052, loss_s1: 0.032289, loss_fp: 0.002248, loss_freq: 0.036106
[14:25:22.220] iteration 13868: loss: 0.078356, loss_s1: 0.011622, loss_fp: 0.006293, loss_freq: 0.024121
[14:25:22.860] iteration 13869: loss: 0.071788, loss_s1: 0.028182, loss_fp: 0.002676, loss_freq: 0.044739
[14:25:23.821] iteration 13870: loss: 0.111639, loss_s1: 0.125729, loss_fp: 0.017163, loss_freq: 0.021868
[14:25:24.781] iteration 13871: loss: 0.051276, loss_s1: 0.039373, loss_fp: 0.005146, loss_freq: 0.018553
[14:25:25.818] iteration 13872: loss: 0.053911, loss_s1: 0.043349, loss_fp: 0.000759, loss_freq: 0.013016
[14:25:26.439] iteration 13873: loss: 0.066157, loss_s1: 0.055356, loss_fp: 0.008269, loss_freq: 0.020243
[14:25:27.069] iteration 13874: loss: 0.038732, loss_s1: 0.007263, loss_fp: 0.003051, loss_freq: 0.026849
[14:25:27.698] iteration 13875: loss: 0.061497, loss_s1: 0.035365, loss_fp: 0.002414, loss_freq: 0.021312
[14:25:28.327] iteration 13876: loss: 0.078893, loss_s1: 0.055447, loss_fp: 0.002646, loss_freq: 0.052287
[14:25:28.956] iteration 13877: loss: 0.066350, loss_s1: 0.019633, loss_fp: 0.000817, loss_freq: 0.003168
[14:25:29.587] iteration 13878: loss: 0.062806, loss_s1: 0.066851, loss_fp: 0.001842, loss_freq: 0.024482
[14:25:30.217] iteration 13879: loss: 0.102474, loss_s1: 0.047079, loss_fp: 0.004595, loss_freq: 0.034069
[14:25:30.847] iteration 13880: loss: 0.056208, loss_s1: 0.025929, loss_fp: 0.006537, loss_freq: 0.036717
[14:25:31.477] iteration 13881: loss: 0.066276, loss_s1: 0.008789, loss_fp: 0.000888, loss_freq: 0.003812
[14:25:32.105] iteration 13882: loss: 0.105746, loss_s1: 0.068823, loss_fp: 0.010190, loss_freq: 0.040172
[14:25:32.724] iteration 13883: loss: 0.059916, loss_s1: 0.045414, loss_fp: 0.001375, loss_freq: 0.023196
[14:25:33.349] iteration 13884: loss: 0.089279, loss_s1: 0.091361, loss_fp: 0.005777, loss_freq: 0.030559
[14:25:33.977] iteration 13885: loss: 0.048671, loss_s1: 0.020488, loss_fp: 0.002990, loss_freq: 0.014884
[14:25:34.601] iteration 13886: loss: 0.075369, loss_s1: 0.042880, loss_fp: 0.001946, loss_freq: 0.065596
[14:25:35.232] iteration 13887: loss: 0.047017, loss_s1: 0.021081, loss_fp: 0.003099, loss_freq: 0.017490
[14:25:35.855] iteration 13888: loss: 0.163051, loss_s1: 0.025166, loss_fp: 0.000419, loss_freq: 0.020170
[14:25:36.487] iteration 13889: loss: 0.050723, loss_s1: 0.025747, loss_fp: 0.001356, loss_freq: 0.019395
[14:25:37.112] iteration 13890: loss: 0.037620, loss_s1: 0.022219, loss_fp: 0.000321, loss_freq: 0.013546
[14:25:37.742] iteration 13891: loss: 0.038066, loss_s1: 0.020810, loss_fp: 0.001425, loss_freq: 0.016014
[14:25:38.401] iteration 13892: loss: 0.118502, loss_s1: 0.044678, loss_fp: 0.012116, loss_freq: 0.081967
[14:25:39.058] iteration 13893: loss: 0.057378, loss_s1: 0.020877, loss_fp: 0.012172, loss_freq: 0.019198
[14:25:39.718] iteration 13894: loss: 0.070092, loss_s1: 0.052197, loss_fp: 0.001410, loss_freq: 0.035835
[14:25:40.344] iteration 13895: loss: 0.099506, loss_s1: 0.047399, loss_fp: 0.001718, loss_freq: 0.010012
[14:25:40.970] iteration 13896: loss: 0.070871, loss_s1: 0.036696, loss_fp: 0.002274, loss_freq: 0.043745
[14:25:41.608] iteration 13897: loss: 0.104307, loss_s1: 0.051272, loss_fp: 0.001824, loss_freq: 0.045395
[14:25:42.243] iteration 13898: loss: 0.103951, loss_s1: 0.038104, loss_fp: 0.003214, loss_freq: 0.049528
[14:25:42.877] iteration 13899: loss: 0.043533, loss_s1: 0.021967, loss_fp: 0.004096, loss_freq: 0.006602
[14:25:43.514] iteration 13900: loss: 0.067680, loss_s1: 0.023675, loss_fp: 0.001141, loss_freq: 0.036404
[14:25:44.183] iteration 13901: loss: 0.058603, loss_s1: 0.019522, loss_fp: 0.001631, loss_freq: 0.010377
[14:25:44.855] iteration 13902: loss: 0.043119, loss_s1: 0.033294, loss_fp: 0.003333, loss_freq: 0.005713
[14:25:45.504] iteration 13903: loss: 0.064177, loss_s1: 0.040500, loss_fp: 0.007543, loss_freq: 0.014284
[14:25:46.148] iteration 13904: loss: 0.073075, loss_s1: 0.083988, loss_fp: 0.001088, loss_freq: 0.023972
[14:25:46.795] iteration 13905: loss: 0.119882, loss_s1: 0.114825, loss_fp: 0.003497, loss_freq: 0.067265
[14:25:47.445] iteration 13906: loss: 0.073924, loss_s1: 0.049817, loss_fp: 0.010456, loss_freq: 0.028220
[14:25:48.083] iteration 13907: loss: 0.066413, loss_s1: 0.037285, loss_fp: 0.001332, loss_freq: 0.036455
[14:25:48.717] iteration 13908: loss: 0.057264, loss_s1: 0.021765, loss_fp: 0.004810, loss_freq: 0.014192
[14:25:49.378] iteration 13909: loss: 0.057829, loss_s1: 0.048616, loss_fp: 0.001785, loss_freq: 0.027561
[14:25:50.043] iteration 13910: loss: 0.122907, loss_s1: 0.071342, loss_fp: 0.005312, loss_freq: 0.038895
[14:25:50.674] iteration 13911: loss: 0.054791, loss_s1: 0.029108, loss_fp: 0.001707, loss_freq: 0.014494
[14:25:51.307] iteration 13912: loss: 0.073788, loss_s1: 0.060635, loss_fp: 0.002457, loss_freq: 0.015319
[14:25:51.934] iteration 13913: loss: 0.065306, loss_s1: 0.012991, loss_fp: 0.005688, loss_freq: 0.041861
[14:25:52.568] iteration 13914: loss: 0.047450, loss_s1: 0.015999, loss_fp: 0.005929, loss_freq: 0.011035
[14:25:53.267] iteration 13915: loss: 0.056111, loss_s1: 0.041797, loss_fp: 0.005296, loss_freq: 0.018903
[14:25:53.898] iteration 13916: loss: 0.094106, loss_s1: 0.022610, loss_fp: 0.001702, loss_freq: 0.033701
[14:25:54.529] iteration 13917: loss: 0.093408, loss_s1: 0.086254, loss_fp: 0.001722, loss_freq: 0.035569
[14:25:55.157] iteration 13918: loss: 0.073765, loss_s1: 0.048303, loss_fp: 0.003816, loss_freq: 0.025372
[14:25:55.782] iteration 13919: loss: 0.095587, loss_s1: 0.114936, loss_fp: 0.001971, loss_freq: 0.012246
[14:25:56.443] iteration 13920: loss: 0.063011, loss_s1: 0.049132, loss_fp: 0.005107, loss_freq: 0.018376
[14:25:57.088] iteration 13921: loss: 0.079566, loss_s1: 0.048900, loss_fp: 0.001278, loss_freq: 0.061878
[14:25:57.773] iteration 13922: loss: 0.046196, loss_s1: 0.014934, loss_fp: 0.009474, loss_freq: 0.011399
[14:25:58.397] iteration 13923: loss: 0.095710, loss_s1: 0.025502, loss_fp: 0.005184, loss_freq: 0.036585
[14:25:59.023] iteration 13924: loss: 0.039933, loss_s1: 0.024226, loss_fp: 0.000394, loss_freq: 0.006676
[14:25:59.653] iteration 13925: loss: 0.065312, loss_s1: 0.047008, loss_fp: 0.001308, loss_freq: 0.030909
[14:26:00.287] iteration 13926: loss: 0.047041, loss_s1: 0.040563, loss_fp: 0.001147, loss_freq: 0.009243
[14:26:00.924] iteration 13927: loss: 0.071519, loss_s1: 0.066718, loss_fp: 0.000747, loss_freq: 0.005429
[14:26:01.559] iteration 13928: loss: 0.093726, loss_s1: 0.101741, loss_fp: 0.002353, loss_freq: 0.031715
[14:26:02.202] iteration 13929: loss: 0.045279, loss_s1: 0.026766, loss_fp: 0.000687, loss_freq: 0.018944
[14:26:02.836] iteration 13930: loss: 0.082701, loss_s1: 0.041561, loss_fp: 0.000906, loss_freq: 0.056059
[14:26:03.464] iteration 13931: loss: 0.070130, loss_s1: 0.054563, loss_fp: 0.004341, loss_freq: 0.034820
[14:26:04.099] iteration 13932: loss: 0.040978, loss_s1: 0.026478, loss_fp: 0.000954, loss_freq: 0.013375
[14:26:04.792] iteration 13933: loss: 0.050601, loss_s1: 0.040608, loss_fp: 0.002123, loss_freq: 0.011409
[14:26:05.450] iteration 13934: loss: 0.066431, loss_s1: 0.043874, loss_fp: 0.004301, loss_freq: 0.020580
[14:26:06.111] iteration 13935: loss: 0.067582, loss_s1: 0.038537, loss_fp: 0.004587, loss_freq: 0.026642
[14:26:06.768] iteration 13936: loss: 0.078378, loss_s1: 0.047210, loss_fp: 0.003831, loss_freq: 0.023664
[14:26:07.419] iteration 13937: loss: 0.064750, loss_s1: 0.025242, loss_fp: 0.002769, loss_freq: 0.053249
[14:26:08.078] iteration 13938: loss: 0.092705, loss_s1: 0.056348, loss_fp: 0.007124, loss_freq: 0.064833
[14:26:08.728] iteration 13939: loss: 0.061144, loss_s1: 0.016822, loss_fp: 0.001074, loss_freq: 0.028400
[14:26:09.358] iteration 13940: loss: 0.067024, loss_s1: 0.070698, loss_fp: 0.001269, loss_freq: 0.014401
[14:26:09.987] iteration 13941: loss: 0.056222, loss_s1: 0.021916, loss_fp: 0.003241, loss_freq: 0.022713
[14:26:10.619] iteration 13942: loss: 0.054161, loss_s1: 0.024497, loss_fp: 0.001746, loss_freq: 0.031883
[14:26:11.248] iteration 13943: loss: 0.087621, loss_s1: 0.071865, loss_fp: 0.003358, loss_freq: 0.054379
[14:26:11.878] iteration 13944: loss: 0.050167, loss_s1: 0.009640, loss_fp: 0.001181, loss_freq: 0.051833
[14:26:12.500] iteration 13945: loss: 0.085216, loss_s1: 0.042847, loss_fp: 0.004760, loss_freq: 0.025039
[14:26:13.125] iteration 13946: loss: 0.067805, loss_s1: 0.043903, loss_fp: 0.003269, loss_freq: 0.045448
[14:26:13.754] iteration 13947: loss: 0.039966, loss_s1: 0.008852, loss_fp: 0.003886, loss_freq: 0.016181
[14:26:14.382] iteration 13948: loss: 0.060299, loss_s1: 0.032080, loss_fp: 0.006640, loss_freq: 0.045753
[14:26:15.007] iteration 13949: loss: 0.077679, loss_s1: 0.048656, loss_fp: 0.002051, loss_freq: 0.027852
[14:26:15.627] iteration 13950: loss: 0.101881, loss_s1: 0.072691, loss_fp: 0.012333, loss_freq: 0.066735
[14:26:16.248] iteration 13951: loss: 0.131653, loss_s1: 0.048296, loss_fp: 0.010356, loss_freq: 0.063696
[14:26:16.874] iteration 13952: loss: 0.055277, loss_s1: 0.028720, loss_fp: 0.001110, loss_freq: 0.027606
[14:26:17.557] iteration 13953: loss: 0.048698, loss_s1: 0.022842, loss_fp: 0.001102, loss_freq: 0.023580
[14:26:18.226] iteration 13954: loss: 0.058819, loss_s1: 0.025819, loss_fp: 0.002870, loss_freq: 0.014604
[14:26:18.902] iteration 13955: loss: 0.060280, loss_s1: 0.043448, loss_fp: 0.005683, loss_freq: 0.031090
[14:26:19.568] iteration 13956: loss: 0.063535, loss_s1: 0.035842, loss_fp: 0.000693, loss_freq: 0.043207
[14:26:20.229] iteration 13957: loss: 0.080821, loss_s1: 0.053618, loss_fp: 0.004650, loss_freq: 0.049291
[14:26:20.886] iteration 13958: loss: 0.048939, loss_s1: 0.012989, loss_fp: 0.002913, loss_freq: 0.004515
[14:26:21.540] iteration 13959: loss: 0.046510, loss_s1: 0.014704, loss_fp: 0.002985, loss_freq: 0.016117
[14:26:22.214] iteration 13960: loss: 0.065826, loss_s1: 0.024279, loss_fp: 0.001649, loss_freq: 0.027803
[14:26:22.844] iteration 13961: loss: 0.058206, loss_s1: 0.030820, loss_fp: 0.009210, loss_freq: 0.011584
[14:26:23.462] iteration 13962: loss: 0.096981, loss_s1: 0.061711, loss_fp: 0.002057, loss_freq: 0.019637
[14:26:24.091] iteration 13963: loss: 0.054469, loss_s1: 0.027674, loss_fp: 0.008342, loss_freq: 0.028325
[14:26:24.726] iteration 13964: loss: 0.058424, loss_s1: 0.042997, loss_fp: 0.003027, loss_freq: 0.020192
[14:26:25.406] iteration 13965: loss: 0.057260, loss_s1: 0.030713, loss_fp: 0.005467, loss_freq: 0.016697
[14:26:26.058] iteration 13966: loss: 0.046289, loss_s1: 0.032756, loss_fp: 0.001579, loss_freq: 0.007779
[14:26:26.712] iteration 13967: loss: 0.059997, loss_s1: 0.021408, loss_fp: 0.001590, loss_freq: 0.038456
[14:26:27.359] iteration 13968: loss: 0.119614, loss_s1: 0.077035, loss_fp: 0.006698, loss_freq: 0.091490
[14:26:27.983] iteration 13969: loss: 0.063214, loss_s1: 0.036716, loss_fp: 0.001889, loss_freq: 0.027392
[14:26:28.607] iteration 13970: loss: 0.086206, loss_s1: 0.064493, loss_fp: 0.003684, loss_freq: 0.040451
[14:26:29.227] iteration 13971: loss: 0.090558, loss_s1: 0.050855, loss_fp: 0.003091, loss_freq: 0.067760
[14:26:29.857] iteration 13972: loss: 0.108314, loss_s1: 0.084224, loss_fp: 0.005439, loss_freq: 0.070553
[14:26:30.475] iteration 13973: loss: 0.061023, loss_s1: 0.043614, loss_fp: 0.001545, loss_freq: 0.018124
[14:26:31.097] iteration 13974: loss: 0.090283, loss_s1: 0.088697, loss_fp: 0.003539, loss_freq: 0.038122
[14:26:31.724] iteration 13975: loss: 0.033286, loss_s1: 0.011294, loss_fp: 0.000840, loss_freq: 0.009545
[14:26:32.351] iteration 13976: loss: 0.067963, loss_s1: 0.017032, loss_fp: 0.002215, loss_freq: 0.021159
[14:26:32.999] iteration 13977: loss: 0.057972, loss_s1: 0.033558, loss_fp: 0.001343, loss_freq: 0.016971
[14:26:33.657] iteration 13978: loss: 0.136723, loss_s1: 0.115255, loss_fp: 0.007507, loss_freq: 0.096255
[14:26:34.296] iteration 13979: loss: 0.052612, loss_s1: 0.034939, loss_fp: 0.001544, loss_freq: 0.022594
[14:26:34.926] iteration 13980: loss: 0.052190, loss_s1: 0.030774, loss_fp: 0.009687, loss_freq: 0.014257
[14:26:35.549] iteration 13981: loss: 0.078226, loss_s1: 0.096599, loss_fp: 0.001045, loss_freq: 0.012514
[14:26:36.184] iteration 13982: loss: 0.044690, loss_s1: 0.017190, loss_fp: 0.001392, loss_freq: 0.004834
[14:26:36.823] iteration 13983: loss: 0.066246, loss_s1: 0.030717, loss_fp: 0.003940, loss_freq: 0.033144
[14:26:37.468] iteration 13984: loss: 0.069804, loss_s1: 0.035326, loss_fp: 0.000966, loss_freq: 0.034301
[14:26:38.135] iteration 13985: loss: 0.109026, loss_s1: 0.059602, loss_fp: 0.005082, loss_freq: 0.107583
[14:26:38.815] iteration 13986: loss: 0.090867, loss_s1: 0.031130, loss_fp: 0.002046, loss_freq: 0.039749
[14:26:39.494] iteration 13987: loss: 0.061896, loss_s1: 0.061222, loss_fp: 0.002169, loss_freq: 0.016021
[14:26:40.159] iteration 13988: loss: 0.108427, loss_s1: 0.074433, loss_fp: 0.002034, loss_freq: 0.072348
[14:26:40.791] iteration 13989: loss: 0.067139, loss_s1: 0.055818, loss_fp: 0.001140, loss_freq: 0.032118
[14:26:41.415] iteration 13990: loss: 0.068194, loss_s1: 0.074345, loss_fp: 0.004368, loss_freq: 0.013374
[14:26:42.041] iteration 13991: loss: 0.080128, loss_s1: 0.079987, loss_fp: 0.011087, loss_freq: 0.022460
[14:26:42.662] iteration 13992: loss: 0.085232, loss_s1: 0.080552, loss_fp: 0.000981, loss_freq: 0.045821
[14:26:43.290] iteration 13993: loss: 0.109895, loss_s1: 0.099522, loss_fp: 0.000763, loss_freq: 0.021513
[14:26:43.920] iteration 13994: loss: 0.039740, loss_s1: 0.032667, loss_fp: 0.000863, loss_freq: 0.005184
[14:26:44.544] iteration 13995: loss: 0.051415, loss_s1: 0.040586, loss_fp: 0.003886, loss_freq: 0.019390
[14:26:45.165] iteration 13996: loss: 0.056225, loss_s1: 0.039520, loss_fp: 0.002596, loss_freq: 0.038529
[14:26:45.780] iteration 13997: loss: 0.089680, loss_s1: 0.052639, loss_fp: 0.006522, loss_freq: 0.028515
[14:26:46.401] iteration 13998: loss: 0.067933, loss_s1: 0.050487, loss_fp: 0.001142, loss_freq: 0.034078
[14:26:47.025] iteration 13999: loss: 0.065531, loss_s1: 0.030724, loss_fp: 0.001876, loss_freq: 0.051748
[14:26:47.649] iteration 14000: loss: 0.075282, loss_s1: 0.053565, loss_fp: 0.002082, loss_freq: 0.017948
[14:26:50.876] iteration 14000 : mean_dice : 0.768240
[14:26:51.529] iteration 14001: loss: 0.048934, loss_s1: 0.043837, loss_fp: 0.004130, loss_freq: 0.008194
[14:26:52.157] iteration 14002: loss: 0.051203, loss_s1: 0.031899, loss_fp: 0.001478, loss_freq: 0.023949
[14:26:52.780] iteration 14003: loss: 0.073939, loss_s1: 0.045015, loss_fp: 0.005116, loss_freq: 0.017345
[14:26:53.399] iteration 14004: loss: 0.063637, loss_s1: 0.058953, loss_fp: 0.004369, loss_freq: 0.014554
[14:26:54.022] iteration 14005: loss: 0.146225, loss_s1: 0.111469, loss_fp: 0.000826, loss_freq: 0.081117
[14:26:54.671] iteration 14006: loss: 0.059840, loss_s1: 0.014910, loss_fp: 0.009683, loss_freq: 0.027783
[14:26:55.356] iteration 14007: loss: 0.099344, loss_s1: 0.057566, loss_fp: 0.002302, loss_freq: 0.029931
[14:26:56.014] iteration 14008: loss: 0.078955, loss_s1: 0.094675, loss_fp: 0.010357, loss_freq: 0.010901
[14:26:56.643] iteration 14009: loss: 0.049261, loss_s1: 0.037088, loss_fp: 0.001475, loss_freq: 0.012968
[14:26:57.273] iteration 14010: loss: 0.062701, loss_s1: 0.033569, loss_fp: 0.001825, loss_freq: 0.027415
[14:26:57.902] iteration 14011: loss: 0.085793, loss_s1: 0.024289, loss_fp: 0.001846, loss_freq: 0.010183
[14:26:58.532] iteration 14012: loss: 0.080586, loss_s1: 0.030695, loss_fp: 0.002630, loss_freq: 0.024873
[14:26:59.160] iteration 14013: loss: 0.094331, loss_s1: 0.072328, loss_fp: 0.006968, loss_freq: 0.060577
[14:26:59.785] iteration 14014: loss: 0.059040, loss_s1: 0.040179, loss_fp: 0.001041, loss_freq: 0.013321
[14:27:00.727] iteration 14015: loss: 0.064392, loss_s1: 0.027717, loss_fp: 0.000568, loss_freq: 0.008193
[14:27:01.385] iteration 14016: loss: 0.065118, loss_s1: 0.043710, loss_fp: 0.005916, loss_freq: 0.032741
[14:27:02.049] iteration 14017: loss: 0.044122, loss_s1: 0.025836, loss_fp: 0.002881, loss_freq: 0.025100
[14:27:02.706] iteration 14018: loss: 0.069662, loss_s1: 0.066846, loss_fp: 0.002396, loss_freq: 0.018781
[14:27:03.362] iteration 14019: loss: 0.056582, loss_s1: 0.033550, loss_fp: 0.000942, loss_freq: 0.041165
[14:27:03.987] iteration 14020: loss: 0.049994, loss_s1: 0.040177, loss_fp: 0.001294, loss_freq: 0.007061
[14:27:04.612] iteration 14021: loss: 0.056463, loss_s1: 0.042568, loss_fp: 0.000671, loss_freq: 0.024807
[14:27:05.236] iteration 14022: loss: 0.071469, loss_s1: 0.037107, loss_fp: 0.001572, loss_freq: 0.006855
[14:27:05.855] iteration 14023: loss: 0.063497, loss_s1: 0.019667, loss_fp: 0.006069, loss_freq: 0.055599
[14:27:06.482] iteration 14024: loss: 0.047672, loss_s1: 0.008713, loss_fp: 0.001087, loss_freq: 0.011932
[14:27:07.119] iteration 14025: loss: 0.072063, loss_s1: 0.043197, loss_fp: 0.003489, loss_freq: 0.042092
[14:27:07.740] iteration 14026: loss: 0.049933, loss_s1: 0.021538, loss_fp: 0.004372, loss_freq: 0.009714
[14:27:08.369] iteration 14027: loss: 0.096971, loss_s1: 0.088955, loss_fp: 0.000632, loss_freq: 0.043621
[14:27:08.986] iteration 14028: loss: 0.036061, loss_s1: 0.014954, loss_fp: 0.000339, loss_freq: 0.013355
[14:27:09.646] iteration 14029: loss: 0.080942, loss_s1: 0.064146, loss_fp: 0.001039, loss_freq: 0.039076
[14:27:10.308] iteration 14030: loss: 0.039455, loss_s1: 0.019873, loss_fp: 0.002545, loss_freq: 0.015559
[14:27:10.971] iteration 14031: loss: 0.067076, loss_s1: 0.038411, loss_fp: 0.001894, loss_freq: 0.026827
[14:27:11.632] iteration 14032: loss: 0.057282, loss_s1: 0.028460, loss_fp: 0.001882, loss_freq: 0.016303
[14:27:12.293] iteration 14033: loss: 0.070812, loss_s1: 0.035793, loss_fp: 0.002844, loss_freq: 0.039465
[14:27:12.928] iteration 14034: loss: 0.029200, loss_s1: 0.007452, loss_fp: 0.004506, loss_freq: 0.012285
[14:27:13.559] iteration 14035: loss: 0.099764, loss_s1: 0.030442, loss_fp: 0.007227, loss_freq: 0.077590
[14:27:14.204] iteration 14036: loss: 0.035176, loss_s1: 0.013807, loss_fp: 0.001303, loss_freq: 0.015368
[14:27:14.834] iteration 14037: loss: 0.052974, loss_s1: 0.022981, loss_fp: 0.001506, loss_freq: 0.028276
[14:27:15.473] iteration 14038: loss: 0.052207, loss_s1: 0.015637, loss_fp: 0.001519, loss_freq: 0.012190
[14:27:16.098] iteration 14039: loss: 0.068437, loss_s1: 0.054820, loss_fp: 0.002280, loss_freq: 0.013484
[14:27:16.725] iteration 14040: loss: 0.099373, loss_s1: 0.040028, loss_fp: 0.007226, loss_freq: 0.073190
[14:27:17.359] iteration 14041: loss: 0.114592, loss_s1: 0.037121, loss_fp: 0.001630, loss_freq: 0.091430
[14:27:17.988] iteration 14042: loss: 0.065777, loss_s1: 0.056482, loss_fp: 0.003334, loss_freq: 0.010026
[14:27:18.618] iteration 14043: loss: 0.070187, loss_s1: 0.050096, loss_fp: 0.000906, loss_freq: 0.010419
[14:27:19.250] iteration 14044: loss: 0.054248, loss_s1: 0.038439, loss_fp: 0.003044, loss_freq: 0.007971
[14:27:19.878] iteration 14045: loss: 0.045484, loss_s1: 0.021474, loss_fp: 0.001413, loss_freq: 0.012769
[14:27:20.505] iteration 14046: loss: 0.072106, loss_s1: 0.035236, loss_fp: 0.005156, loss_freq: 0.031410
[14:27:21.135] iteration 14047: loss: 0.068409, loss_s1: 0.059492, loss_fp: 0.002667, loss_freq: 0.037913
[14:27:21.761] iteration 14048: loss: 0.096545, loss_s1: 0.077873, loss_fp: 0.002525, loss_freq: 0.060407
[14:27:22.387] iteration 14049: loss: 0.077816, loss_s1: 0.036377, loss_fp: 0.005606, loss_freq: 0.052207
[14:27:23.019] iteration 14050: loss: 0.078263, loss_s1: 0.049997, loss_fp: 0.003490, loss_freq: 0.046499
[14:27:23.654] iteration 14051: loss: 0.063197, loss_s1: 0.027101, loss_fp: 0.005166, loss_freq: 0.016117
[14:27:24.282] iteration 14052: loss: 0.048379, loss_s1: 0.033492, loss_fp: 0.002196, loss_freq: 0.024147
[14:27:24.922] iteration 14053: loss: 0.105095, loss_s1: 0.053578, loss_fp: 0.006436, loss_freq: 0.043691
[14:27:25.566] iteration 14054: loss: 0.060033, loss_s1: 0.059180, loss_fp: 0.007942, loss_freq: 0.012594
[14:27:26.189] iteration 14055: loss: 0.077018, loss_s1: 0.026564, loss_fp: 0.001031, loss_freq: 0.017595
[14:27:26.818] iteration 14056: loss: 0.072268, loss_s1: 0.053543, loss_fp: 0.003894, loss_freq: 0.030840
[14:27:27.445] iteration 14057: loss: 0.051688, loss_s1: 0.023335, loss_fp: 0.001736, loss_freq: 0.003977
[14:27:28.125] iteration 14058: loss: 0.072028, loss_s1: 0.036752, loss_fp: 0.005226, loss_freq: 0.045007
[14:27:28.800] iteration 14059: loss: 0.055994, loss_s1: 0.006581, loss_fp: 0.000893, loss_freq: 0.014865
[14:27:29.508] iteration 14060: loss: 0.058803, loss_s1: 0.044764, loss_fp: 0.002400, loss_freq: 0.026861
[14:27:30.187] iteration 14061: loss: 0.073748, loss_s1: 0.043951, loss_fp: 0.003455, loss_freq: 0.024541
[14:27:31.044] iteration 14062: loss: 0.067600, loss_s1: 0.032406, loss_fp: 0.002191, loss_freq: 0.013007
[14:27:31.698] iteration 14063: loss: 0.067798, loss_s1: 0.062900, loss_fp: 0.001816, loss_freq: 0.029291
[14:27:32.355] iteration 14064: loss: 0.051699, loss_s1: 0.039877, loss_fp: 0.001401, loss_freq: 0.017028
[14:27:33.015] iteration 14065: loss: 0.041846, loss_s1: 0.015373, loss_fp: 0.000379, loss_freq: 0.011801
[14:27:33.659] iteration 14066: loss: 0.108904, loss_s1: 0.039114, loss_fp: 0.001220, loss_freq: 0.023003
[14:27:34.279] iteration 14067: loss: 0.090870, loss_s1: 0.034450, loss_fp: 0.002089, loss_freq: 0.006124
[14:27:34.901] iteration 14068: loss: 0.032817, loss_s1: 0.018396, loss_fp: 0.000270, loss_freq: 0.009966
[14:27:35.526] iteration 14069: loss: 0.055178, loss_s1: 0.032890, loss_fp: 0.001902, loss_freq: 0.015555
[14:27:36.150] iteration 14070: loss: 0.074854, loss_s1: 0.032714, loss_fp: 0.002342, loss_freq: 0.016586
[14:27:36.780] iteration 14071: loss: 0.051573, loss_s1: 0.022809, loss_fp: 0.004165, loss_freq: 0.015958
[14:27:37.419] iteration 14072: loss: 0.068669, loss_s1: 0.032304, loss_fp: 0.000920, loss_freq: 0.050640
[14:27:38.040] iteration 14073: loss: 0.068105, loss_s1: 0.040583, loss_fp: 0.002578, loss_freq: 0.035574
[14:27:38.670] iteration 14074: loss: 0.064065, loss_s1: 0.032170, loss_fp: 0.004007, loss_freq: 0.039550
[14:27:39.299] iteration 14075: loss: 0.063025, loss_s1: 0.037773, loss_fp: 0.001356, loss_freq: 0.019204
[14:27:39.923] iteration 14076: loss: 0.078416, loss_s1: 0.042786, loss_fp: 0.004714, loss_freq: 0.009292
[14:27:40.559] iteration 14077: loss: 0.053186, loss_s1: 0.021593, loss_fp: 0.001564, loss_freq: 0.026325
[14:27:41.176] iteration 14078: loss: 0.095339, loss_s1: 0.034130, loss_fp: 0.002904, loss_freq: 0.023856
[14:27:41.804] iteration 14079: loss: 0.096672, loss_s1: 0.058886, loss_fp: 0.001010, loss_freq: 0.072683
[14:27:42.429] iteration 14080: loss: 0.087843, loss_s1: 0.040036, loss_fp: 0.003778, loss_freq: 0.011385
[14:27:43.049] iteration 14081: loss: 0.134855, loss_s1: 0.117349, loss_fp: 0.005173, loss_freq: 0.083481
[14:27:43.673] iteration 14082: loss: 0.060289, loss_s1: 0.020071, loss_fp: 0.009588, loss_freq: 0.014477
[14:27:44.293] iteration 14083: loss: 0.054204, loss_s1: 0.034843, loss_fp: 0.001999, loss_freq: 0.020831
[14:27:44.904] iteration 14084: loss: 0.108135, loss_s1: 0.097566, loss_fp: 0.002764, loss_freq: 0.021986
[14:27:45.523] iteration 14085: loss: 0.094070, loss_s1: 0.050311, loss_fp: 0.002181, loss_freq: 0.019750
[14:27:46.149] iteration 14086: loss: 0.056879, loss_s1: 0.039432, loss_fp: 0.004033, loss_freq: 0.016935
[14:27:46.768] iteration 14087: loss: 0.082896, loss_s1: 0.045062, loss_fp: 0.003633, loss_freq: 0.083558
[14:27:47.389] iteration 14088: loss: 0.055519, loss_s1: 0.016475, loss_fp: 0.014211, loss_freq: 0.016158
[14:27:48.012] iteration 14089: loss: 0.078591, loss_s1: 0.032581, loss_fp: 0.001472, loss_freq: 0.063785
[14:27:48.631] iteration 14090: loss: 0.083353, loss_s1: 0.056099, loss_fp: 0.008757, loss_freq: 0.012820
[14:27:49.259] iteration 14091: loss: 0.041999, loss_s1: 0.032247, loss_fp: 0.002014, loss_freq: 0.012748
[14:27:49.879] iteration 14092: loss: 0.071072, loss_s1: 0.054644, loss_fp: 0.014522, loss_freq: 0.006135
[14:27:50.504] iteration 14093: loss: 0.084643, loss_s1: 0.038419, loss_fp: 0.005231, loss_freq: 0.070571
[14:27:51.123] iteration 14094: loss: 0.106468, loss_s1: 0.038068, loss_fp: 0.010792, loss_freq: 0.020417
[14:27:51.748] iteration 14095: loss: 0.052170, loss_s1: 0.019783, loss_fp: 0.000843, loss_freq: 0.015680
[14:27:52.375] iteration 14096: loss: 0.087805, loss_s1: 0.078479, loss_fp: 0.001269, loss_freq: 0.031421
[14:27:53.003] iteration 14097: loss: 0.064716, loss_s1: 0.026892, loss_fp: 0.001265, loss_freq: 0.036723
[14:27:53.627] iteration 14098: loss: 0.059406, loss_s1: 0.064403, loss_fp: 0.000878, loss_freq: 0.018776
[14:27:54.249] iteration 14099: loss: 0.049124, loss_s1: 0.036533, loss_fp: 0.002179, loss_freq: 0.008366
[14:27:54.869] iteration 14100: loss: 0.087365, loss_s1: 0.061202, loss_fp: 0.001566, loss_freq: 0.045372
[14:27:55.495] iteration 14101: loss: 0.088227, loss_s1: 0.060120, loss_fp: 0.002547, loss_freq: 0.019770
[14:27:56.116] iteration 14102: loss: 0.043185, loss_s1: 0.009828, loss_fp: 0.001978, loss_freq: 0.015280
[14:27:56.739] iteration 14103: loss: 0.039929, loss_s1: 0.011004, loss_fp: 0.017266, loss_freq: 0.018780
[14:27:57.377] iteration 14104: loss: 0.071475, loss_s1: 0.042643, loss_fp: 0.004476, loss_freq: 0.054077
[14:27:57.995] iteration 14105: loss: 0.055535, loss_s1: 0.013547, loss_fp: 0.003242, loss_freq: 0.010951
[14:27:58.619] iteration 14106: loss: 0.100961, loss_s1: 0.094505, loss_fp: 0.006346, loss_freq: 0.029128
[14:27:59.240] iteration 14107: loss: 0.059714, loss_s1: 0.040889, loss_fp: 0.004840, loss_freq: 0.023364
[14:27:59.906] iteration 14108: loss: 0.048806, loss_s1: 0.028551, loss_fp: 0.003887, loss_freq: 0.009965
[14:28:00.534] iteration 14109: loss: 0.058289, loss_s1: 0.026123, loss_fp: 0.006574, loss_freq: 0.026429
[14:28:01.158] iteration 14110: loss: 0.068330, loss_s1: 0.041384, loss_fp: 0.022589, loss_freq: 0.014426
[14:28:01.782] iteration 14111: loss: 0.093768, loss_s1: 0.065612, loss_fp: 0.002780, loss_freq: 0.064858
[14:28:02.402] iteration 14112: loss: 0.053426, loss_s1: 0.025124, loss_fp: 0.003172, loss_freq: 0.015388
[14:28:03.063] iteration 14113: loss: 0.064733, loss_s1: 0.039837, loss_fp: 0.001039, loss_freq: 0.016617
[14:28:03.723] iteration 14114: loss: 0.064369, loss_s1: 0.055981, loss_fp: 0.004294, loss_freq: 0.018243
[14:28:04.383] iteration 14115: loss: 0.056749, loss_s1: 0.015861, loss_fp: 0.010350, loss_freq: 0.047766
[14:28:05.038] iteration 14116: loss: 0.061414, loss_s1: 0.027270, loss_fp: 0.002793, loss_freq: 0.016982
[14:28:05.692] iteration 14117: loss: 0.043145, loss_s1: 0.017486, loss_fp: 0.004277, loss_freq: 0.019667
[14:28:06.328] iteration 14118: loss: 0.068130, loss_s1: 0.025361, loss_fp: 0.007243, loss_freq: 0.022435
[14:28:06.951] iteration 14119: loss: 0.062999, loss_s1: 0.033736, loss_fp: 0.002584, loss_freq: 0.026180
[14:28:07.579] iteration 14120: loss: 0.066920, loss_s1: 0.035112, loss_fp: 0.001669, loss_freq: 0.025745
[14:28:08.206] iteration 14121: loss: 0.065630, loss_s1: 0.024581, loss_fp: 0.001591, loss_freq: 0.040790
[14:28:08.850] iteration 14122: loss: 0.073684, loss_s1: 0.043915, loss_fp: 0.003856, loss_freq: 0.049758
[14:28:09.492] iteration 14123: loss: 0.071092, loss_s1: 0.035310, loss_fp: 0.002370, loss_freq: 0.008767
[14:28:10.135] iteration 14124: loss: 0.040773, loss_s1: 0.011347, loss_fp: 0.016172, loss_freq: 0.017438
[14:28:10.773] iteration 14125: loss: 0.071942, loss_s1: 0.027758, loss_fp: 0.003949, loss_freq: 0.013269
[14:28:11.402] iteration 14126: loss: 0.054327, loss_s1: 0.050930, loss_fp: 0.002636, loss_freq: 0.015346
[14:28:12.037] iteration 14127: loss: 0.058710, loss_s1: 0.026218, loss_fp: 0.001941, loss_freq: 0.012477
[14:28:12.660] iteration 14128: loss: 0.068556, loss_s1: 0.027923, loss_fp: 0.001651, loss_freq: 0.053490
[14:28:13.290] iteration 14129: loss: 0.124778, loss_s1: 0.084425, loss_fp: 0.000928, loss_freq: 0.007375
[14:28:13.954] iteration 14130: loss: 0.067481, loss_s1: 0.034563, loss_fp: 0.004542, loss_freq: 0.018253
[14:28:14.607] iteration 14131: loss: 0.054239, loss_s1: 0.027288, loss_fp: 0.004730, loss_freq: 0.029580
[14:28:15.262] iteration 14132: loss: 0.058043, loss_s1: 0.030941, loss_fp: 0.004144, loss_freq: 0.018217
[14:28:15.912] iteration 14133: loss: 0.065768, loss_s1: 0.055950, loss_fp: 0.000846, loss_freq: 0.010220
[14:28:16.553] iteration 14134: loss: 0.047533, loss_s1: 0.028061, loss_fp: 0.002675, loss_freq: 0.017623
[14:28:17.179] iteration 14135: loss: 0.088569, loss_s1: 0.064385, loss_fp: 0.001801, loss_freq: 0.063062
[14:28:17.802] iteration 14136: loss: 0.071121, loss_s1: 0.041015, loss_fp: 0.002243, loss_freq: 0.027813
[14:28:18.425] iteration 14137: loss: 0.042461, loss_s1: 0.006718, loss_fp: 0.002353, loss_freq: 0.028520
[14:28:19.100] iteration 14138: loss: 0.061474, loss_s1: 0.034929, loss_fp: 0.005446, loss_freq: 0.035580
[14:28:19.764] iteration 14139: loss: 0.094398, loss_s1: 0.099987, loss_fp: 0.001707, loss_freq: 0.042167
[14:28:20.421] iteration 14140: loss: 0.070001, loss_s1: 0.051366, loss_fp: 0.001802, loss_freq: 0.019330
[14:28:21.054] iteration 14141: loss: 0.060277, loss_s1: 0.014654, loss_fp: 0.002114, loss_freq: 0.052024
[14:28:21.685] iteration 14142: loss: 0.064119, loss_s1: 0.047877, loss_fp: 0.004629, loss_freq: 0.037365
[14:28:22.313] iteration 14143: loss: 0.075058, loss_s1: 0.051917, loss_fp: 0.014237, loss_freq: 0.018942
[14:28:22.950] iteration 14144: loss: 0.047139, loss_s1: 0.019469, loss_fp: 0.001908, loss_freq: 0.013804
[14:28:23.605] iteration 14145: loss: 0.060074, loss_s1: 0.031967, loss_fp: 0.005507, loss_freq: 0.023189
[14:28:24.259] iteration 14146: loss: 0.098469, loss_s1: 0.064569, loss_fp: 0.003055, loss_freq: 0.028484
[14:28:24.919] iteration 14147: loss: 0.061340, loss_s1: 0.040107, loss_fp: 0.009414, loss_freq: 0.023536
[14:28:25.572] iteration 14148: loss: 0.068745, loss_s1: 0.028652, loss_fp: 0.001078, loss_freq: 0.027284
[14:28:26.227] iteration 14149: loss: 0.092608, loss_s1: 0.019204, loss_fp: 0.004217, loss_freq: 0.023199
[14:28:26.848] iteration 14150: loss: 0.053458, loss_s1: 0.037602, loss_fp: 0.004172, loss_freq: 0.022467
[14:28:27.476] iteration 14151: loss: 0.061879, loss_s1: 0.030157, loss_fp: 0.009494, loss_freq: 0.039812
[14:28:28.096] iteration 14152: loss: 0.037935, loss_s1: 0.023627, loss_fp: 0.001319, loss_freq: 0.012468
[14:28:28.724] iteration 14153: loss: 0.069518, loss_s1: 0.069544, loss_fp: 0.002966, loss_freq: 0.010968
[14:28:29.382] iteration 14154: loss: 0.084776, loss_s1: 0.083901, loss_fp: 0.004184, loss_freq: 0.016457
[14:28:30.002] iteration 14155: loss: 0.062397, loss_s1: 0.020163, loss_fp: 0.002913, loss_freq: 0.030169
[14:28:30.621] iteration 14156: loss: 0.144110, loss_s1: 0.137298, loss_fp: 0.010431, loss_freq: 0.067787
[14:28:31.243] iteration 14157: loss: 0.044250, loss_s1: 0.023610, loss_fp: 0.004511, loss_freq: 0.014829
[14:28:32.191] iteration 14158: loss: 0.043156, loss_s1: 0.018274, loss_fp: 0.001150, loss_freq: 0.017363
[14:28:32.817] iteration 14159: loss: 0.070783, loss_s1: 0.057339, loss_fp: 0.004963, loss_freq: 0.023377
[14:28:33.480] iteration 14160: loss: 0.049680, loss_s1: 0.022374, loss_fp: 0.001141, loss_freq: 0.022312
[14:28:34.109] iteration 14161: loss: 0.079452, loss_s1: 0.074151, loss_fp: 0.001525, loss_freq: 0.029263
[14:28:34.738] iteration 14162: loss: 0.055931, loss_s1: 0.031201, loss_fp: 0.001692, loss_freq: 0.028393
[14:28:35.368] iteration 14163: loss: 0.098180, loss_s1: 0.027461, loss_fp: 0.002965, loss_freq: 0.009776
[14:28:35.991] iteration 14164: loss: 0.034690, loss_s1: 0.014321, loss_fp: 0.005647, loss_freq: 0.014985
[14:28:36.616] iteration 14165: loss: 0.070612, loss_s1: 0.033939, loss_fp: 0.014705, loss_freq: 0.020660
[14:28:37.242] iteration 14166: loss: 0.103932, loss_s1: 0.105957, loss_fp: 0.003455, loss_freq: 0.050000
[14:28:37.875] iteration 14167: loss: 0.032864, loss_s1: 0.009165, loss_fp: 0.001644, loss_freq: 0.002267
[14:28:38.493] iteration 14168: loss: 0.076527, loss_s1: 0.049083, loss_fp: 0.006799, loss_freq: 0.044954
[14:28:39.117] iteration 14169: loss: 0.058540, loss_s1: 0.048182, loss_fp: 0.001043, loss_freq: 0.017343
[14:28:39.810] iteration 14170: loss: 0.082747, loss_s1: 0.033093, loss_fp: 0.001106, loss_freq: 0.015404
[14:28:40.446] iteration 14171: loss: 0.045633, loss_s1: 0.017738, loss_fp: 0.004320, loss_freq: 0.016876
[14:28:41.075] iteration 14172: loss: 0.089930, loss_s1: 0.065327, loss_fp: 0.002064, loss_freq: 0.064006
[14:28:41.691] iteration 14173: loss: 0.068306, loss_s1: 0.051121, loss_fp: 0.001238, loss_freq: 0.013422
[14:28:42.315] iteration 14174: loss: 0.053093, loss_s1: 0.031277, loss_fp: 0.001018, loss_freq: 0.020412
[14:28:42.935] iteration 14175: loss: 0.102394, loss_s1: 0.074829, loss_fp: 0.003638, loss_freq: 0.025672
[14:28:43.563] iteration 14176: loss: 0.066936, loss_s1: 0.063988, loss_fp: 0.005423, loss_freq: 0.029194
[14:28:44.182] iteration 14177: loss: 0.045922, loss_s1: 0.041741, loss_fp: 0.007833, loss_freq: 0.011073
[14:28:44.802] iteration 14178: loss: 0.064776, loss_s1: 0.011493, loss_fp: 0.002259, loss_freq: 0.054509
[14:28:45.428] iteration 14179: loss: 0.067602, loss_s1: 0.058729, loss_fp: 0.007802, loss_freq: 0.020049
[14:28:46.056] iteration 14180: loss: 0.079393, loss_s1: 0.046979, loss_fp: 0.000654, loss_freq: 0.044091
[14:28:46.685] iteration 14181: loss: 0.061968, loss_s1: 0.037480, loss_fp: 0.000828, loss_freq: 0.014655
[14:28:47.305] iteration 14182: loss: 0.046692, loss_s1: 0.023418, loss_fp: 0.004422, loss_freq: 0.018114
[14:28:47.948] iteration 14183: loss: 0.086274, loss_s1: 0.050227, loss_fp: 0.009051, loss_freq: 0.034700
[14:28:48.568] iteration 14184: loss: 0.075557, loss_s1: 0.029259, loss_fp: 0.005354, loss_freq: 0.060600
[14:28:49.200] iteration 14185: loss: 0.082603, loss_s1: 0.073891, loss_fp: 0.003193, loss_freq: 0.037347
[14:28:49.823] iteration 14186: loss: 0.071984, loss_s1: 0.022123, loss_fp: 0.001975, loss_freq: 0.057490
[14:28:50.448] iteration 14187: loss: 0.063343, loss_s1: 0.039279, loss_fp: 0.001740, loss_freq: 0.013729
[14:28:51.079] iteration 14188: loss: 0.042256, loss_s1: 0.014177, loss_fp: 0.002164, loss_freq: 0.025724
[14:28:51.708] iteration 14189: loss: 0.043869, loss_s1: 0.015685, loss_fp: 0.001718, loss_freq: 0.018904
[14:28:52.327] iteration 14190: loss: 0.070361, loss_s1: 0.083786, loss_fp: 0.005298, loss_freq: 0.015757
[14:28:52.974] iteration 14191: loss: 0.115452, loss_s1: 0.120292, loss_fp: 0.005736, loss_freq: 0.055609
[14:28:53.615] iteration 14192: loss: 0.106640, loss_s1: 0.075477, loss_fp: 0.006995, loss_freq: 0.048195
[14:28:54.250] iteration 14193: loss: 0.057697, loss_s1: 0.013320, loss_fp: 0.001374, loss_freq: 0.035943
[14:28:54.885] iteration 14194: loss: 0.075213, loss_s1: 0.063792, loss_fp: 0.003684, loss_freq: 0.029613
[14:28:55.513] iteration 14195: loss: 0.085528, loss_s1: 0.083452, loss_fp: 0.004332, loss_freq: 0.026555
[14:28:56.143] iteration 14196: loss: 0.113625, loss_s1: 0.097413, loss_fp: 0.005099, loss_freq: 0.046196
[14:28:56.778] iteration 14197: loss: 0.041551, loss_s1: 0.020852, loss_fp: 0.001087, loss_freq: 0.018685
[14:28:57.431] iteration 14198: loss: 0.107000, loss_s1: 0.081225, loss_fp: 0.007482, loss_freq: 0.025520
[14:28:58.084] iteration 14199: loss: 0.041420, loss_s1: 0.032511, loss_fp: 0.000731, loss_freq: 0.015730
[14:28:58.741] iteration 14200: loss: 0.069839, loss_s1: 0.026468, loss_fp: 0.001047, loss_freq: 0.033002
[14:29:02.378] iteration 14200 : mean_dice : 0.771184
[14:29:03.062] iteration 14201: loss: 0.098150, loss_s1: 0.047578, loss_fp: 0.009622, loss_freq: 0.064183
[14:29:03.716] iteration 14202: loss: 0.071912, loss_s1: 0.034140, loss_fp: 0.000832, loss_freq: 0.035603
[14:29:04.372] iteration 14203: loss: 0.073304, loss_s1: 0.053005, loss_fp: 0.000537, loss_freq: 0.048866
[14:29:05.024] iteration 14204: loss: 0.047765, loss_s1: 0.024762, loss_fp: 0.001732, loss_freq: 0.022147
[14:29:05.674] iteration 14205: loss: 0.064934, loss_s1: 0.025161, loss_fp: 0.002646, loss_freq: 0.039657
[14:29:06.329] iteration 14206: loss: 0.112869, loss_s1: 0.117934, loss_fp: 0.004842, loss_freq: 0.035747
[14:29:06.946] iteration 14207: loss: 0.054508, loss_s1: 0.046352, loss_fp: 0.001314, loss_freq: 0.012772
[14:29:07.564] iteration 14208: loss: 0.039940, loss_s1: 0.020101, loss_fp: 0.002388, loss_freq: 0.009913
[14:29:08.236] iteration 14209: loss: 0.081813, loss_s1: 0.054098, loss_fp: 0.002098, loss_freq: 0.042747
[14:29:08.912] iteration 14210: loss: 0.067996, loss_s1: 0.078480, loss_fp: 0.003100, loss_freq: 0.012744
[14:29:09.587] iteration 14211: loss: 0.046053, loss_s1: 0.014472, loss_fp: 0.001784, loss_freq: 0.006155
[14:29:10.254] iteration 14212: loss: 0.031270, loss_s1: 0.012861, loss_fp: 0.000564, loss_freq: 0.017517
[14:29:10.904] iteration 14213: loss: 0.112904, loss_s1: 0.040458, loss_fp: 0.000771, loss_freq: 0.015655
[14:29:11.540] iteration 14214: loss: 0.061806, loss_s1: 0.053844, loss_fp: 0.002807, loss_freq: 0.022041
[14:29:12.168] iteration 14215: loss: 0.056244, loss_s1: 0.046013, loss_fp: 0.002214, loss_freq: 0.020346
[14:29:12.805] iteration 14216: loss: 0.065392, loss_s1: 0.024601, loss_fp: 0.000479, loss_freq: 0.051987
[14:29:13.438] iteration 14217: loss: 0.067547, loss_s1: 0.038770, loss_fp: 0.004595, loss_freq: 0.042066
[14:29:14.070] iteration 14218: loss: 0.080373, loss_s1: 0.046639, loss_fp: 0.002862, loss_freq: 0.015169
[14:29:14.701] iteration 14219: loss: 0.054510, loss_s1: 0.029340, loss_fp: 0.002992, loss_freq: 0.029170
[14:29:15.334] iteration 14220: loss: 0.086306, loss_s1: 0.055006, loss_fp: 0.003998, loss_freq: 0.042405
[14:29:15.966] iteration 14221: loss: 0.056579, loss_s1: 0.026403, loss_fp: 0.004819, loss_freq: 0.014582
[14:29:16.597] iteration 14222: loss: 0.064059, loss_s1: 0.053685, loss_fp: 0.004703, loss_freq: 0.008064
[14:29:17.239] iteration 14223: loss: 0.051687, loss_s1: 0.011599, loss_fp: 0.004916, loss_freq: 0.022876
[14:29:17.876] iteration 14224: loss: 0.126012, loss_s1: 0.062904, loss_fp: 0.020941, loss_freq: 0.065799
[14:29:18.516] iteration 14225: loss: 0.046728, loss_s1: 0.024887, loss_fp: 0.004418, loss_freq: 0.018660
[14:29:19.155] iteration 14226: loss: 0.067351, loss_s1: 0.065724, loss_fp: 0.001018, loss_freq: 0.022591
[14:29:19.794] iteration 14227: loss: 0.062659, loss_s1: 0.026925, loss_fp: 0.000864, loss_freq: 0.015228
[14:29:20.432] iteration 14228: loss: 0.075936, loss_s1: 0.048919, loss_fp: 0.007197, loss_freq: 0.030485
[14:29:21.063] iteration 14229: loss: 0.069195, loss_s1: 0.044068, loss_fp: 0.008242, loss_freq: 0.024770
[14:29:21.712] iteration 14230: loss: 0.063539, loss_s1: 0.037339, loss_fp: 0.000833, loss_freq: 0.043744
[14:29:22.343] iteration 14231: loss: 0.084218, loss_s1: 0.045928, loss_fp: 0.005635, loss_freq: 0.050656
[14:29:22.985] iteration 14232: loss: 0.101856, loss_s1: 0.076922, loss_fp: 0.006453, loss_freq: 0.055523
[14:29:23.618] iteration 14233: loss: 0.055900, loss_s1: 0.030773, loss_fp: 0.003117, loss_freq: 0.015615
[14:29:24.272] iteration 14234: loss: 0.057367, loss_s1: 0.067489, loss_fp: 0.004532, loss_freq: 0.009436
[14:29:24.899] iteration 14235: loss: 0.045702, loss_s1: 0.010636, loss_fp: 0.001433, loss_freq: 0.010996
[14:29:25.578] iteration 14236: loss: 0.092377, loss_s1: 0.073985, loss_fp: 0.003665, loss_freq: 0.051555
[14:29:26.251] iteration 14237: loss: 0.105809, loss_s1: 0.063177, loss_fp: 0.004920, loss_freq: 0.026424
[14:29:26.926] iteration 14238: loss: 0.052850, loss_s1: 0.028262, loss_fp: 0.001255, loss_freq: 0.019339
[14:29:27.556] iteration 14239: loss: 0.067924, loss_s1: 0.011061, loss_fp: 0.000777, loss_freq: 0.055005
[14:29:28.184] iteration 14240: loss: 0.063946, loss_s1: 0.012804, loss_fp: 0.001005, loss_freq: 0.053332
[14:29:28.842] iteration 14241: loss: 0.048539, loss_s1: 0.043789, loss_fp: 0.000503, loss_freq: 0.015615
[14:29:29.500] iteration 14242: loss: 0.053438, loss_s1: 0.043938, loss_fp: 0.000945, loss_freq: 0.008841
[14:29:30.179] iteration 14243: loss: 0.064431, loss_s1: 0.009397, loss_fp: 0.007296, loss_freq: 0.066293
[14:29:30.873] iteration 14244: loss: 0.046362, loss_s1: 0.036525, loss_fp: 0.000430, loss_freq: 0.006203
[14:29:31.536] iteration 14245: loss: 0.059373, loss_s1: 0.017741, loss_fp: 0.003895, loss_freq: 0.011523
[14:29:32.203] iteration 14246: loss: 0.040419, loss_s1: 0.023200, loss_fp: 0.001636, loss_freq: 0.015290
[14:29:32.858] iteration 14247: loss: 0.068910, loss_s1: 0.057007, loss_fp: 0.011750, loss_freq: 0.019379
[14:29:33.494] iteration 14248: loss: 0.077660, loss_s1: 0.031959, loss_fp: 0.013444, loss_freq: 0.029767
[14:29:34.234] iteration 14249: loss: 0.069661, loss_s1: 0.032883, loss_fp: 0.003262, loss_freq: 0.056168
[14:29:34.864] iteration 14250: loss: 0.045081, loss_s1: 0.025916, loss_fp: 0.000650, loss_freq: 0.015343
[14:29:35.544] iteration 14251: loss: 0.066668, loss_s1: 0.020988, loss_fp: 0.009229, loss_freq: 0.014190
[14:29:36.220] iteration 14252: loss: 0.072105, loss_s1: 0.050386, loss_fp: 0.000665, loss_freq: 0.039187
[14:29:36.840] iteration 14253: loss: 0.055556, loss_s1: 0.023272, loss_fp: 0.000820, loss_freq: 0.011645
[14:29:37.465] iteration 14254: loss: 0.085401, loss_s1: 0.039434, loss_fp: 0.003531, loss_freq: 0.055772
[14:29:38.085] iteration 14255: loss: 0.062046, loss_s1: 0.022992, loss_fp: 0.001239, loss_freq: 0.046625
[14:29:38.715] iteration 14256: loss: 0.115479, loss_s1: 0.054851, loss_fp: 0.010295, loss_freq: 0.035209
[14:29:39.335] iteration 14257: loss: 0.078216, loss_s1: 0.046366, loss_fp: 0.003211, loss_freq: 0.052264
[14:29:39.968] iteration 14258: loss: 0.052158, loss_s1: 0.037974, loss_fp: 0.002061, loss_freq: 0.018588
[14:29:40.600] iteration 14259: loss: 0.084128, loss_s1: 0.058645, loss_fp: 0.000901, loss_freq: 0.047289
[14:29:41.229] iteration 14260: loss: 0.057617, loss_s1: 0.037697, loss_fp: 0.004739, loss_freq: 0.034942
[14:29:41.856] iteration 14261: loss: 0.045685, loss_s1: 0.010943, loss_fp: 0.010157, loss_freq: 0.014192
[14:29:42.510] iteration 14262: loss: 0.064591, loss_s1: 0.044809, loss_fp: 0.002790, loss_freq: 0.008531
[14:29:43.167] iteration 14263: loss: 0.055830, loss_s1: 0.044764, loss_fp: 0.001246, loss_freq: 0.022699
[14:29:43.823] iteration 14264: loss: 0.135953, loss_s1: 0.122329, loss_fp: 0.010244, loss_freq: 0.070839
[14:29:44.480] iteration 14265: loss: 0.062362, loss_s1: 0.033236, loss_fp: 0.006523, loss_freq: 0.046252
[14:29:45.127] iteration 14266: loss: 0.064609, loss_s1: 0.037961, loss_fp: 0.001880, loss_freq: 0.020611
[14:29:45.767] iteration 14267: loss: 0.101303, loss_s1: 0.054669, loss_fp: 0.032506, loss_freq: 0.064624
[14:29:46.387] iteration 14268: loss: 0.052429, loss_s1: 0.030458, loss_fp: 0.000722, loss_freq: 0.020122
[14:29:47.014] iteration 14269: loss: 0.057273, loss_s1: 0.046022, loss_fp: 0.004024, loss_freq: 0.025339
[14:29:47.685] iteration 14270: loss: 0.048695, loss_s1: 0.024395, loss_fp: 0.001935, loss_freq: 0.013604
[14:29:48.333] iteration 14271: loss: 0.059958, loss_s1: 0.056602, loss_fp: 0.004541, loss_freq: 0.008772
[14:29:49.000] iteration 14272: loss: 0.067457, loss_s1: 0.034830, loss_fp: 0.000627, loss_freq: 0.016854
[14:29:49.671] iteration 14273: loss: 0.057944, loss_s1: 0.062598, loss_fp: 0.001902, loss_freq: 0.007912
[14:29:50.338] iteration 14274: loss: 0.071793, loss_s1: 0.033615, loss_fp: 0.009990, loss_freq: 0.028984
[14:29:50.975] iteration 14275: loss: 0.065295, loss_s1: 0.034808, loss_fp: 0.001857, loss_freq: 0.024441
[14:29:51.613] iteration 14276: loss: 0.093374, loss_s1: 0.121133, loss_fp: 0.003053, loss_freq: 0.025632
[14:29:52.249] iteration 14277: loss: 0.077014, loss_s1: 0.033846, loss_fp: 0.004165, loss_freq: 0.048570
[14:29:52.881] iteration 14278: loss: 0.082609, loss_s1: 0.041526, loss_fp: 0.002002, loss_freq: 0.046166
[14:29:53.507] iteration 14279: loss: 0.077676, loss_s1: 0.055735, loss_fp: 0.001451, loss_freq: 0.024028
[14:29:54.144] iteration 14280: loss: 0.048446, loss_s1: 0.023956, loss_fp: 0.005452, loss_freq: 0.001610
[14:29:54.781] iteration 14281: loss: 0.060337, loss_s1: 0.044984, loss_fp: 0.006062, loss_freq: 0.027955
[14:29:55.405] iteration 14282: loss: 0.040289, loss_s1: 0.034103, loss_fp: 0.000741, loss_freq: 0.011443
[14:29:56.030] iteration 14283: loss: 0.078888, loss_s1: 0.037193, loss_fp: 0.003607, loss_freq: 0.009346
[14:29:56.690] iteration 14284: loss: 0.054994, loss_s1: 0.016964, loss_fp: 0.001614, loss_freq: 0.029412
[14:29:57.347] iteration 14285: loss: 0.051251, loss_s1: 0.035291, loss_fp: 0.001096, loss_freq: 0.020796
[14:29:57.978] iteration 14286: loss: 0.078182, loss_s1: 0.086617, loss_fp: 0.006265, loss_freq: 0.010584
[14:29:58.605] iteration 14287: loss: 0.072747, loss_s1: 0.041202, loss_fp: 0.002613, loss_freq: 0.023315
[14:29:59.230] iteration 14288: loss: 0.057865, loss_s1: 0.049090, loss_fp: 0.001173, loss_freq: 0.011325
[14:29:59.851] iteration 14289: loss: 0.051835, loss_s1: 0.025855, loss_fp: 0.002734, loss_freq: 0.020224
[14:30:00.512] iteration 14290: loss: 0.064779, loss_s1: 0.051283, loss_fp: 0.003248, loss_freq: 0.026947
[14:30:01.177] iteration 14291: loss: 0.145195, loss_s1: 0.147873, loss_fp: 0.001351, loss_freq: 0.061537
[14:30:01.797] iteration 14292: loss: 0.071375, loss_s1: 0.014009, loss_fp: 0.001627, loss_freq: 0.031148
[14:30:02.410] iteration 14293: loss: 0.069529, loss_s1: 0.050495, loss_fp: 0.002885, loss_freq: 0.047201
[14:30:03.022] iteration 14294: loss: 0.067049, loss_s1: 0.039761, loss_fp: 0.003724, loss_freq: 0.014477
[14:30:03.651] iteration 14295: loss: 0.047834, loss_s1: 0.029704, loss_fp: 0.000552, loss_freq: 0.006681
[14:30:04.273] iteration 14296: loss: 0.067638, loss_s1: 0.052880, loss_fp: 0.003170, loss_freq: 0.025307
[14:30:04.886] iteration 14297: loss: 0.050189, loss_s1: 0.026901, loss_fp: 0.002012, loss_freq: 0.013186
[14:30:05.504] iteration 14298: loss: 0.062993, loss_s1: 0.054343, loss_fp: 0.003245, loss_freq: 0.014244
[14:30:06.127] iteration 14299: loss: 0.148898, loss_s1: 0.147655, loss_fp: 0.011682, loss_freq: 0.080583
[14:30:06.755] iteration 14300: loss: 0.047241, loss_s1: 0.029447, loss_fp: 0.004818, loss_freq: 0.026388
[14:30:07.679] iteration 14301: loss: 0.060952, loss_s1: 0.029595, loss_fp: 0.001421, loss_freq: 0.021658
[14:30:08.361] iteration 14302: loss: 0.060068, loss_s1: 0.041383, loss_fp: 0.002852, loss_freq: 0.023524
[14:30:09.036] iteration 14303: loss: 0.078782, loss_s1: 0.033722, loss_fp: 0.006102, loss_freq: 0.034742
[14:30:09.733] iteration 14304: loss: 0.069647, loss_s1: 0.059877, loss_fp: 0.003552, loss_freq: 0.013439
[14:30:10.390] iteration 14305: loss: 0.073172, loss_s1: 0.044968, loss_fp: 0.001978, loss_freq: 0.049938
[14:30:11.044] iteration 14306: loss: 0.080144, loss_s1: 0.031519, loss_fp: 0.002108, loss_freq: 0.015978
[14:30:11.711] iteration 14307: loss: 0.044963, loss_s1: 0.035620, loss_fp: 0.002982, loss_freq: 0.019582
[14:30:12.350] iteration 14308: loss: 0.070204, loss_s1: 0.060556, loss_fp: 0.001702, loss_freq: 0.016358
[14:30:13.013] iteration 14309: loss: 0.083282, loss_s1: 0.035276, loss_fp: 0.006811, loss_freq: 0.066187
[14:30:13.684] iteration 14310: loss: 0.052893, loss_s1: 0.026480, loss_fp: 0.000647, loss_freq: 0.004648
[14:30:14.342] iteration 14311: loss: 0.084243, loss_s1: 0.040579, loss_fp: 0.006646, loss_freq: 0.058207
[14:30:14.999] iteration 14312: loss: 0.060720, loss_s1: 0.030745, loss_fp: 0.005171, loss_freq: 0.011835
[14:30:15.636] iteration 14313: loss: 0.070004, loss_s1: 0.048077, loss_fp: 0.006024, loss_freq: 0.025214
[14:30:16.272] iteration 14314: loss: 0.070163, loss_s1: 0.050388, loss_fp: 0.001009, loss_freq: 0.043832
[14:30:16.906] iteration 14315: loss: 0.059180, loss_s1: 0.026413, loss_fp: 0.011922, loss_freq: 0.033490
[14:30:17.527] iteration 14316: loss: 0.068338, loss_s1: 0.052454, loss_fp: 0.001720, loss_freq: 0.012153
[14:30:18.152] iteration 14317: loss: 0.154904, loss_s1: 0.042783, loss_fp: 0.005106, loss_freq: 0.034864
[14:30:18.782] iteration 14318: loss: 0.040391, loss_s1: 0.022570, loss_fp: 0.001288, loss_freq: 0.020928
[14:30:19.410] iteration 14319: loss: 0.063780, loss_s1: 0.049906, loss_fp: 0.002721, loss_freq: 0.035385
[14:30:20.038] iteration 14320: loss: 0.050575, loss_s1: 0.041572, loss_fp: 0.001774, loss_freq: 0.011471
[14:30:20.662] iteration 14321: loss: 0.082753, loss_s1: 0.035765, loss_fp: 0.005369, loss_freq: 0.047887
[14:30:21.290] iteration 14322: loss: 0.057877, loss_s1: 0.048071, loss_fp: 0.002994, loss_freq: 0.015737
[14:30:21.916] iteration 14323: loss: 0.068038, loss_s1: 0.068962, loss_fp: 0.001665, loss_freq: 0.015666
[14:30:22.545] iteration 14324: loss: 0.052389, loss_s1: 0.021868, loss_fp: 0.004434, loss_freq: 0.011023
[14:30:23.169] iteration 14325: loss: 0.055578, loss_s1: 0.035464, loss_fp: 0.001979, loss_freq: 0.015972
[14:30:23.803] iteration 14326: loss: 0.080145, loss_s1: 0.053770, loss_fp: 0.001877, loss_freq: 0.020922
[14:30:24.429] iteration 14327: loss: 0.087211, loss_s1: 0.056851, loss_fp: 0.003025, loss_freq: 0.060515
[14:30:25.055] iteration 14328: loss: 0.052496, loss_s1: 0.026304, loss_fp: 0.000936, loss_freq: 0.009564
[14:30:25.691] iteration 14329: loss: 0.087765, loss_s1: 0.056230, loss_fp: 0.005379, loss_freq: 0.065922
[14:30:26.326] iteration 14330: loss: 0.060483, loss_s1: 0.030847, loss_fp: 0.000888, loss_freq: 0.018257
[14:30:26.958] iteration 14331: loss: 0.059239, loss_s1: 0.032177, loss_fp: 0.001849, loss_freq: 0.023983
[14:30:27.593] iteration 14332: loss: 0.080988, loss_s1: 0.036624, loss_fp: 0.003486, loss_freq: 0.044718
[14:30:28.221] iteration 14333: loss: 0.046878, loss_s1: 0.022353, loss_fp: 0.004065, loss_freq: 0.032283
[14:30:28.857] iteration 14334: loss: 0.111937, loss_s1: 0.097196, loss_fp: 0.004091, loss_freq: 0.055809
[14:30:29.489] iteration 14335: loss: 0.092047, loss_s1: 0.082096, loss_fp: 0.014591, loss_freq: 0.024003
[14:30:30.117] iteration 14336: loss: 0.055559, loss_s1: 0.031142, loss_fp: 0.004591, loss_freq: 0.025971
[14:30:30.745] iteration 14337: loss: 0.055154, loss_s1: 0.035216, loss_fp: 0.002406, loss_freq: 0.019568
[14:30:31.387] iteration 14338: loss: 0.067940, loss_s1: 0.033258, loss_fp: 0.001718, loss_freq: 0.041969
[14:30:32.020] iteration 14339: loss: 0.083547, loss_s1: 0.035944, loss_fp: 0.006222, loss_freq: 0.054827
[14:30:32.688] iteration 14340: loss: 0.068219, loss_s1: 0.046903, loss_fp: 0.016248, loss_freq: 0.008748
[14:30:33.351] iteration 14341: loss: 0.053422, loss_s1: 0.033752, loss_fp: 0.012192, loss_freq: 0.008872
[14:30:33.982] iteration 14342: loss: 0.074504, loss_s1: 0.054955, loss_fp: 0.007368, loss_freq: 0.042220
[14:30:34.624] iteration 14343: loss: 0.051336, loss_s1: 0.016301, loss_fp: 0.000743, loss_freq: 0.010421
[14:30:35.264] iteration 14344: loss: 0.098585, loss_s1: 0.062059, loss_fp: 0.004381, loss_freq: 0.083738
[14:30:35.913] iteration 14345: loss: 0.057783, loss_s1: 0.019626, loss_fp: 0.003779, loss_freq: 0.010109
[14:30:36.572] iteration 14346: loss: 0.061715, loss_s1: 0.036668, loss_fp: 0.002650, loss_freq: 0.014878
[14:30:37.223] iteration 14347: loss: 0.053016, loss_s1: 0.010174, loss_fp: 0.009760, loss_freq: 0.032009
[14:30:37.879] iteration 14348: loss: 0.055347, loss_s1: 0.038408, loss_fp: 0.001432, loss_freq: 0.023335
[14:30:38.534] iteration 14349: loss: 0.076217, loss_s1: 0.045443, loss_fp: 0.013493, loss_freq: 0.059929
[14:30:39.192] iteration 14350: loss: 0.055033, loss_s1: 0.044078, loss_fp: 0.003142, loss_freq: 0.020862
[14:30:39.834] iteration 14351: loss: 0.064838, loss_s1: 0.060027, loss_fp: 0.002399, loss_freq: 0.016882
[14:30:40.452] iteration 14352: loss: 0.065224, loss_s1: 0.025243, loss_fp: 0.000607, loss_freq: 0.045322
[14:30:41.075] iteration 14353: loss: 0.080702, loss_s1: 0.041991, loss_fp: 0.002529, loss_freq: 0.012528
[14:30:41.696] iteration 14354: loss: 0.041191, loss_s1: 0.031915, loss_fp: 0.006297, loss_freq: 0.009212
[14:30:42.320] iteration 14355: loss: 0.068529, loss_s1: 0.062651, loss_fp: 0.020934, loss_freq: 0.013945
[14:30:42.944] iteration 14356: loss: 0.062975, loss_s1: 0.038612, loss_fp: 0.001150, loss_freq: 0.016764
[14:30:43.573] iteration 14357: loss: 0.065071, loss_s1: 0.071694, loss_fp: 0.003130, loss_freq: 0.018003
[14:30:44.204] iteration 14358: loss: 0.076159, loss_s1: 0.052332, loss_fp: 0.007447, loss_freq: 0.019999
[14:30:44.821] iteration 14359: loss: 0.085017, loss_s1: 0.074813, loss_fp: 0.001297, loss_freq: 0.050712
[14:30:45.480] iteration 14360: loss: 0.066944, loss_s1: 0.050304, loss_fp: 0.002652, loss_freq: 0.010867
[14:30:46.156] iteration 14361: loss: 0.066778, loss_s1: 0.044714, loss_fp: 0.001774, loss_freq: 0.039704
[14:30:46.809] iteration 14362: loss: 0.061670, loss_s1: 0.041958, loss_fp: 0.000855, loss_freq: 0.021244
[14:30:47.462] iteration 14363: loss: 0.090551, loss_s1: 0.081460, loss_fp: 0.004853, loss_freq: 0.046846
[14:30:48.104] iteration 14364: loss: 0.043025, loss_s1: 0.020574, loss_fp: 0.001779, loss_freq: 0.017981
[14:30:48.731] iteration 14365: loss: 0.164385, loss_s1: 0.051889, loss_fp: 0.011682, loss_freq: 0.034390
[14:30:49.358] iteration 14366: loss: 0.039657, loss_s1: 0.008508, loss_fp: 0.003179, loss_freq: 0.014162
[14:30:49.985] iteration 14367: loss: 0.080987, loss_s1: 0.072488, loss_fp: 0.003327, loss_freq: 0.034936
[14:30:50.614] iteration 14368: loss: 0.046699, loss_s1: 0.030939, loss_fp: 0.002757, loss_freq: 0.026242
[14:30:51.237] iteration 14369: loss: 0.074697, loss_s1: 0.073766, loss_fp: 0.000973, loss_freq: 0.031025
[14:30:51.859] iteration 14370: loss: 0.096311, loss_s1: 0.027024, loss_fp: 0.003812, loss_freq: 0.021428
[14:30:52.489] iteration 14371: loss: 0.048252, loss_s1: 0.024333, loss_fp: 0.001688, loss_freq: 0.021850
[14:30:53.114] iteration 14372: loss: 0.062357, loss_s1: 0.040872, loss_fp: 0.006066, loss_freq: 0.023697
[14:30:53.744] iteration 14373: loss: 0.083655, loss_s1: 0.028451, loss_fp: 0.000956, loss_freq: 0.057204
[14:30:54.371] iteration 14374: loss: 0.094094, loss_s1: 0.069821, loss_fp: 0.001978, loss_freq: 0.044403
[14:30:54.996] iteration 14375: loss: 0.069314, loss_s1: 0.043858, loss_fp: 0.011926, loss_freq: 0.048958
[14:30:55.627] iteration 14376: loss: 0.082368, loss_s1: 0.053006, loss_fp: 0.003721, loss_freq: 0.019378
[14:30:56.243] iteration 14377: loss: 0.063374, loss_s1: 0.060517, loss_fp: 0.002381, loss_freq: 0.025573
[14:30:56.861] iteration 14378: loss: 0.050849, loss_s1: 0.019464, loss_fp: 0.001061, loss_freq: 0.011970
[14:30:57.493] iteration 14379: loss: 0.059793, loss_s1: 0.036568, loss_fp: 0.004945, loss_freq: 0.025578
[14:30:58.111] iteration 14380: loss: 0.099954, loss_s1: 0.062351, loss_fp: 0.007059, loss_freq: 0.017988
[14:30:58.744] iteration 14381: loss: 0.072295, loss_s1: 0.035214, loss_fp: 0.002659, loss_freq: 0.032277
[14:30:59.370] iteration 14382: loss: 0.061324, loss_s1: 0.046313, loss_fp: 0.002400, loss_freq: 0.018512
[14:31:00.002] iteration 14383: loss: 0.076685, loss_s1: 0.037628, loss_fp: 0.001828, loss_freq: 0.029400
[14:31:00.627] iteration 14384: loss: 0.050316, loss_s1: 0.027875, loss_fp: 0.001039, loss_freq: 0.022682
[14:31:01.251] iteration 14385: loss: 0.087243, loss_s1: 0.068399, loss_fp: 0.002936, loss_freq: 0.033558
[14:31:01.875] iteration 14386: loss: 0.056788, loss_s1: 0.024574, loss_fp: 0.003980, loss_freq: 0.027497
[14:31:02.498] iteration 14387: loss: 0.064096, loss_s1: 0.027456, loss_fp: 0.001943, loss_freq: 0.007293
[14:31:03.129] iteration 14388: loss: 0.041166, loss_s1: 0.025699, loss_fp: 0.000965, loss_freq: 0.013973
[14:31:03.759] iteration 14389: loss: 0.056203, loss_s1: 0.053569, loss_fp: 0.001635, loss_freq: 0.013839
[14:31:04.387] iteration 14390: loss: 0.076373, loss_s1: 0.082656, loss_fp: 0.001532, loss_freq: 0.022900
[14:31:05.014] iteration 14391: loss: 0.067039, loss_s1: 0.014529, loss_fp: 0.001867, loss_freq: 0.020900
[14:31:05.635] iteration 14392: loss: 0.107553, loss_s1: 0.055091, loss_fp: 0.010008, loss_freq: 0.060544
[14:31:06.255] iteration 14393: loss: 0.051536, loss_s1: 0.022822, loss_fp: 0.000984, loss_freq: 0.014256
[14:31:06.874] iteration 14394: loss: 0.049641, loss_s1: 0.026975, loss_fp: 0.001083, loss_freq: 0.008195
[14:31:07.501] iteration 14395: loss: 0.061083, loss_s1: 0.050573, loss_fp: 0.000929, loss_freq: 0.008091
[14:31:08.121] iteration 14396: loss: 0.049789, loss_s1: 0.011357, loss_fp: 0.002684, loss_freq: 0.021465
[14:31:08.746] iteration 14397: loss: 0.113148, loss_s1: 0.076133, loss_fp: 0.011250, loss_freq: 0.048580
[14:31:09.408] iteration 14398: loss: 0.050181, loss_s1: 0.030399, loss_fp: 0.001984, loss_freq: 0.021779
[14:31:10.071] iteration 14399: loss: 0.043610, loss_s1: 0.009330, loss_fp: 0.002324, loss_freq: 0.021502
[14:31:10.729] iteration 14400: loss: 0.080023, loss_s1: 0.036839, loss_fp: 0.006139, loss_freq: 0.042620
[14:31:14.201] iteration 14400 : mean_dice : 0.788699
[14:31:14.896] iteration 14401: loss: 0.054507, loss_s1: 0.031988, loss_fp: 0.004449, loss_freq: 0.031624
[14:31:15.573] iteration 14402: loss: 0.073116, loss_s1: 0.030599, loss_fp: 0.004038, loss_freq: 0.015307
[14:31:16.248] iteration 14403: loss: 0.048207, loss_s1: 0.026309, loss_fp: 0.002329, loss_freq: 0.025383
[14:31:16.924] iteration 14404: loss: 0.047797, loss_s1: 0.030700, loss_fp: 0.000724, loss_freq: 0.018474
[14:31:17.565] iteration 14405: loss: 0.118850, loss_s1: 0.038091, loss_fp: 0.002224, loss_freq: 0.016927
[14:31:18.195] iteration 14406: loss: 0.065386, loss_s1: 0.038694, loss_fp: 0.003733, loss_freq: 0.026967
[14:31:18.837] iteration 14407: loss: 0.106683, loss_s1: 0.104554, loss_fp: 0.004600, loss_freq: 0.040999
[14:31:19.477] iteration 14408: loss: 0.058145, loss_s1: 0.022244, loss_fp: 0.012977, loss_freq: 0.024580
[14:31:20.118] iteration 14409: loss: 0.062414, loss_s1: 0.030033, loss_fp: 0.003279, loss_freq: 0.032446
[14:31:20.748] iteration 14410: loss: 0.065242, loss_s1: 0.033129, loss_fp: 0.002883, loss_freq: 0.053266
[14:31:21.411] iteration 14411: loss: 0.048706, loss_s1: 0.020675, loss_fp: 0.001995, loss_freq: 0.010208
[14:31:22.051] iteration 14412: loss: 0.055908, loss_s1: 0.020791, loss_fp: 0.013549, loss_freq: 0.043868
[14:31:22.683] iteration 14413: loss: 0.040990, loss_s1: 0.012426, loss_fp: 0.001689, loss_freq: 0.009222
[14:31:23.315] iteration 14414: loss: 0.095754, loss_s1: 0.075515, loss_fp: 0.014194, loss_freq: 0.028342
[14:31:23.940] iteration 14415: loss: 0.075777, loss_s1: 0.016678, loss_fp: 0.002010, loss_freq: 0.022236
[14:31:24.573] iteration 14416: loss: 0.057726, loss_s1: 0.014042, loss_fp: 0.008121, loss_freq: 0.028343
[14:31:25.205] iteration 14417: loss: 0.077265, loss_s1: 0.056403, loss_fp: 0.005317, loss_freq: 0.048459
[14:31:25.841] iteration 14418: loss: 0.070403, loss_s1: 0.047217, loss_fp: 0.004145, loss_freq: 0.038646
[14:31:26.495] iteration 14419: loss: 0.070422, loss_s1: 0.058842, loss_fp: 0.002188, loss_freq: 0.017456
[14:31:27.136] iteration 14420: loss: 0.058501, loss_s1: 0.043112, loss_fp: 0.001446, loss_freq: 0.027375
[14:31:27.784] iteration 14421: loss: 0.082321, loss_s1: 0.035683, loss_fp: 0.001869, loss_freq: 0.058458
[14:31:28.428] iteration 14422: loss: 0.087964, loss_s1: 0.061804, loss_fp: 0.001246, loss_freq: 0.014486
[14:31:29.076] iteration 14423: loss: 0.046439, loss_s1: 0.032505, loss_fp: 0.001800, loss_freq: 0.003069
[14:31:29.716] iteration 14424: loss: 0.065894, loss_s1: 0.049571, loss_fp: 0.004083, loss_freq: 0.034405
[14:31:30.349] iteration 14425: loss: 0.059810, loss_s1: 0.051656, loss_fp: 0.000785, loss_freq: 0.030514
[14:31:30.983] iteration 14426: loss: 0.071509, loss_s1: 0.052227, loss_fp: 0.000864, loss_freq: 0.015012
[14:31:31.614] iteration 14427: loss: 0.066297, loss_s1: 0.037561, loss_fp: 0.001158, loss_freq: 0.059590
[14:31:32.271] iteration 14428: loss: 0.043363, loss_s1: 0.012294, loss_fp: 0.001418, loss_freq: 0.016515
[14:31:32.931] iteration 14429: loss: 0.091380, loss_s1: 0.066450, loss_fp: 0.001094, loss_freq: 0.019634
[14:31:33.589] iteration 14430: loss: 0.057120, loss_s1: 0.050858, loss_fp: 0.000735, loss_freq: 0.004864
[14:31:34.249] iteration 14431: loss: 0.085656, loss_s1: 0.042837, loss_fp: 0.004793, loss_freq: 0.016630
[14:31:34.913] iteration 14432: loss: 0.103584, loss_s1: 0.046523, loss_fp: 0.002837, loss_freq: 0.028567
[14:31:35.550] iteration 14433: loss: 0.069785, loss_s1: 0.040781, loss_fp: 0.002470, loss_freq: 0.037389
[14:31:36.188] iteration 14434: loss: 0.088145, loss_s1: 0.030933, loss_fp: 0.001503, loss_freq: 0.038769
[14:31:36.821] iteration 14435: loss: 0.060804, loss_s1: 0.024195, loss_fp: 0.000804, loss_freq: 0.027903
[14:31:37.486] iteration 14436: loss: 0.082081, loss_s1: 0.068922, loss_fp: 0.004277, loss_freq: 0.021285
[14:31:38.139] iteration 14437: loss: 0.068066, loss_s1: 0.033298, loss_fp: 0.006145, loss_freq: 0.037309
[14:31:38.789] iteration 14438: loss: 0.039816, loss_s1: 0.022225, loss_fp: 0.003155, loss_freq: 0.011673
[14:31:39.479] iteration 14439: loss: 0.051708, loss_s1: 0.038036, loss_fp: 0.001576, loss_freq: 0.021080
[14:31:40.326] iteration 14440: loss: 0.055515, loss_s1: 0.017054, loss_fp: 0.007115, loss_freq: 0.013459
[14:31:41.221] iteration 14441: loss: 0.087198, loss_s1: 0.053768, loss_fp: 0.005610, loss_freq: 0.061273
[14:31:41.856] iteration 14442: loss: 0.131552, loss_s1: 0.103025, loss_fp: 0.001931, loss_freq: 0.096052
[14:31:42.482] iteration 14443: loss: 0.051338, loss_s1: 0.013090, loss_fp: 0.022597, loss_freq: 0.031400
[14:31:43.422] iteration 14444: loss: 0.042674, loss_s1: 0.016894, loss_fp: 0.002836, loss_freq: 0.012282
[14:31:44.065] iteration 14445: loss: 0.082784, loss_s1: 0.060241, loss_fp: 0.010502, loss_freq: 0.026377
[14:31:44.707] iteration 14446: loss: 0.056556, loss_s1: 0.019403, loss_fp: 0.001145, loss_freq: 0.029659
[14:31:45.328] iteration 14447: loss: 0.094157, loss_s1: 0.095732, loss_fp: 0.003097, loss_freq: 0.011783
[14:31:45.956] iteration 14448: loss: 0.063357, loss_s1: 0.049821, loss_fp: 0.002751, loss_freq: 0.040002
[14:31:46.582] iteration 14449: loss: 0.044575, loss_s1: 0.021914, loss_fp: 0.003789, loss_freq: 0.010818
[14:31:47.208] iteration 14450: loss: 0.054074, loss_s1: 0.047054, loss_fp: 0.001585, loss_freq: 0.022268
[14:31:47.837] iteration 14451: loss: 0.083647, loss_s1: 0.026096, loss_fp: 0.008002, loss_freq: 0.069134
[14:31:48.471] iteration 14452: loss: 0.051753, loss_s1: 0.032219, loss_fp: 0.002172, loss_freq: 0.016214
[14:31:49.097] iteration 14453: loss: 0.061005, loss_s1: 0.038626, loss_fp: 0.002876, loss_freq: 0.004885
[14:31:49.719] iteration 14454: loss: 0.077062, loss_s1: 0.032611, loss_fp: 0.001463, loss_freq: 0.062484
[14:31:50.346] iteration 14455: loss: 0.062665, loss_s1: 0.040140, loss_fp: 0.004216, loss_freq: 0.024903
[14:31:50.970] iteration 14456: loss: 0.043556, loss_s1: 0.027826, loss_fp: 0.000610, loss_freq: 0.008631
[14:31:51.606] iteration 14457: loss: 0.062687, loss_s1: 0.029768, loss_fp: 0.001454, loss_freq: 0.028616
[14:31:52.237] iteration 14458: loss: 0.075467, loss_s1: 0.052571, loss_fp: 0.000922, loss_freq: 0.044975
[14:31:52.872] iteration 14459: loss: 0.059589, loss_s1: 0.033453, loss_fp: 0.001925, loss_freq: 0.017481
[14:31:53.504] iteration 14460: loss: 0.052931, loss_s1: 0.047413, loss_fp: 0.000532, loss_freq: 0.011448
[14:31:54.131] iteration 14461: loss: 0.100567, loss_s1: 0.026700, loss_fp: 0.002393, loss_freq: 0.012898
[14:31:54.764] iteration 14462: loss: 0.059930, loss_s1: 0.054949, loss_fp: 0.006621, loss_freq: 0.024137
[14:31:55.392] iteration 14463: loss: 0.035457, loss_s1: 0.021504, loss_fp: 0.000484, loss_freq: 0.012475
[14:31:56.011] iteration 14464: loss: 0.166054, loss_s1: 0.042954, loss_fp: 0.001975, loss_freq: 0.092566
[14:31:56.639] iteration 14465: loss: 0.069217, loss_s1: 0.069383, loss_fp: 0.001222, loss_freq: 0.016322
[14:31:57.261] iteration 14466: loss: 0.055540, loss_s1: 0.050524, loss_fp: 0.001621, loss_freq: 0.016074
[14:31:57.890] iteration 14467: loss: 0.047748, loss_s1: 0.013819, loss_fp: 0.000940, loss_freq: 0.010723
[14:31:58.502] iteration 14468: loss: 0.054265, loss_s1: 0.034448, loss_fp: 0.000893, loss_freq: 0.027258
[14:31:59.129] iteration 14469: loss: 0.062187, loss_s1: 0.019763, loss_fp: 0.002818, loss_freq: 0.032693
[14:31:59.757] iteration 14470: loss: 0.063025, loss_s1: 0.018665, loss_fp: 0.008217, loss_freq: 0.045890
[14:32:00.380] iteration 14471: loss: 0.035353, loss_s1: 0.014889, loss_fp: 0.001543, loss_freq: 0.011414
[14:32:01.008] iteration 14472: loss: 0.086215, loss_s1: 0.036841, loss_fp: 0.003708, loss_freq: 0.034818
[14:32:01.636] iteration 14473: loss: 0.059484, loss_s1: 0.030527, loss_fp: 0.000575, loss_freq: 0.010547
[14:32:02.260] iteration 14474: loss: 0.048147, loss_s1: 0.030223, loss_fp: 0.003675, loss_freq: 0.011648
[14:32:02.888] iteration 14475: loss: 0.058774, loss_s1: 0.022690, loss_fp: 0.001494, loss_freq: 0.019709
[14:32:03.512] iteration 14476: loss: 0.075565, loss_s1: 0.069688, loss_fp: 0.001668, loss_freq: 0.044834
[14:32:04.134] iteration 14477: loss: 0.095600, loss_s1: 0.081643, loss_fp: 0.002797, loss_freq: 0.059202
[14:32:04.766] iteration 14478: loss: 0.061659, loss_s1: 0.030214, loss_fp: 0.002239, loss_freq: 0.021580
[14:32:05.399] iteration 14479: loss: 0.136139, loss_s1: 0.068480, loss_fp: 0.007911, loss_freq: 0.072343
[14:32:06.031] iteration 14480: loss: 0.051531, loss_s1: 0.024248, loss_fp: 0.002542, loss_freq: 0.025722
[14:32:06.660] iteration 14481: loss: 0.046828, loss_s1: 0.027937, loss_fp: 0.005362, loss_freq: 0.016884
[14:32:07.293] iteration 14482: loss: 0.097389, loss_s1: 0.069801, loss_fp: 0.001656, loss_freq: 0.037010
[14:32:07.917] iteration 14483: loss: 0.039304, loss_s1: 0.030023, loss_fp: 0.002817, loss_freq: 0.007369
[14:32:08.551] iteration 14484: loss: 0.095475, loss_s1: 0.062558, loss_fp: 0.006910, loss_freq: 0.033335
[14:32:09.180] iteration 14485: loss: 0.042106, loss_s1: 0.015402, loss_fp: 0.002824, loss_freq: 0.019212
[14:32:09.812] iteration 14486: loss: 0.061505, loss_s1: 0.046209, loss_fp: 0.000201, loss_freq: 0.007979
[14:32:10.441] iteration 14487: loss: 0.071084, loss_s1: 0.051163, loss_fp: 0.004511, loss_freq: 0.043236
[14:32:11.072] iteration 14488: loss: 0.069872, loss_s1: 0.036837, loss_fp: 0.000362, loss_freq: 0.008520
[14:32:11.691] iteration 14489: loss: 0.109183, loss_s1: 0.067696, loss_fp: 0.001893, loss_freq: 0.017695
[14:32:12.322] iteration 14490: loss: 0.051704, loss_s1: 0.011353, loss_fp: 0.001559, loss_freq: 0.037401
[14:32:12.996] iteration 14491: loss: 0.069852, loss_s1: 0.066294, loss_fp: 0.001207, loss_freq: 0.034424
[14:32:13.622] iteration 14492: loss: 0.038142, loss_s1: 0.012354, loss_fp: 0.001131, loss_freq: 0.014093
[14:32:14.234] iteration 14493: loss: 0.066859, loss_s1: 0.041330, loss_fp: 0.001178, loss_freq: 0.046120
[14:32:14.864] iteration 14494: loss: 0.084145, loss_s1: 0.084962, loss_fp: 0.002493, loss_freq: 0.031278
[14:32:15.491] iteration 14495: loss: 0.086322, loss_s1: 0.041495, loss_fp: 0.002998, loss_freq: 0.042271
[14:32:16.122] iteration 14496: loss: 0.042004, loss_s1: 0.025167, loss_fp: 0.004559, loss_freq: 0.003031
[14:32:16.743] iteration 14497: loss: 0.047600, loss_s1: 0.034016, loss_fp: 0.001096, loss_freq: 0.011409
[14:32:17.361] iteration 14498: loss: 0.053032, loss_s1: 0.048477, loss_fp: 0.001207, loss_freq: 0.012123
[14:32:17.982] iteration 14499: loss: 0.046951, loss_s1: 0.018146, loss_fp: 0.000699, loss_freq: 0.006473
[14:32:18.593] iteration 14500: loss: 0.051394, loss_s1: 0.050387, loss_fp: 0.000951, loss_freq: 0.014304
[14:32:19.215] iteration 14501: loss: 0.045509, loss_s1: 0.034189, loss_fp: 0.001341, loss_freq: 0.009069
[14:32:19.840] iteration 14502: loss: 0.067265, loss_s1: 0.017555, loss_fp: 0.002734, loss_freq: 0.040011
[14:32:20.468] iteration 14503: loss: 0.067523, loss_s1: 0.046646, loss_fp: 0.003151, loss_freq: 0.030618
[14:32:21.101] iteration 14504: loss: 0.057649, loss_s1: 0.018092, loss_fp: 0.002769, loss_freq: 0.020054
[14:32:21.732] iteration 14505: loss: 0.073962, loss_s1: 0.065569, loss_fp: 0.002106, loss_freq: 0.015551
[14:32:22.368] iteration 14506: loss: 0.069551, loss_s1: 0.039685, loss_fp: 0.002457, loss_freq: 0.040646
[14:32:22.990] iteration 14507: loss: 0.069456, loss_s1: 0.024771, loss_fp: 0.002177, loss_freq: 0.021656
[14:32:23.613] iteration 14508: loss: 0.118318, loss_s1: 0.112087, loss_fp: 0.004146, loss_freq: 0.053092
[14:32:24.241] iteration 14509: loss: 0.090815, loss_s1: 0.040408, loss_fp: 0.005791, loss_freq: 0.014757
[14:32:24.861] iteration 14510: loss: 0.092032, loss_s1: 0.056880, loss_fp: 0.019925, loss_freq: 0.051652
[14:32:25.485] iteration 14511: loss: 0.056667, loss_s1: 0.011853, loss_fp: 0.000948, loss_freq: 0.016275
[14:32:26.109] iteration 14512: loss: 0.049247, loss_s1: 0.027075, loss_fp: 0.001940, loss_freq: 0.015231
[14:32:26.734] iteration 14513: loss: 0.057969, loss_s1: 0.021736, loss_fp: 0.000451, loss_freq: 0.021948
[14:32:27.415] iteration 14514: loss: 0.046048, loss_s1: 0.017807, loss_fp: 0.001728, loss_freq: 0.027655
[14:32:28.085] iteration 14515: loss: 0.073637, loss_s1: 0.044111, loss_fp: 0.003158, loss_freq: 0.042939
[14:32:28.733] iteration 14516: loss: 0.077549, loss_s1: 0.070471, loss_fp: 0.000811, loss_freq: 0.012702
[14:32:29.378] iteration 14517: loss: 0.076811, loss_s1: 0.048460, loss_fp: 0.003423, loss_freq: 0.045272
[14:32:30.061] iteration 14518: loss: 0.095183, loss_s1: 0.087910, loss_fp: 0.002468, loss_freq: 0.069556
[14:32:30.693] iteration 14519: loss: 0.036249, loss_s1: 0.021106, loss_fp: 0.000690, loss_freq: 0.012262
[14:32:31.320] iteration 14520: loss: 0.063798, loss_s1: 0.036017, loss_fp: 0.001996, loss_freq: 0.037468
[14:32:31.956] iteration 14521: loss: 0.079756, loss_s1: 0.038073, loss_fp: 0.000515, loss_freq: 0.057731
[14:32:32.586] iteration 14522: loss: 0.074792, loss_s1: 0.062343, loss_fp: 0.008797, loss_freq: 0.035958
[14:32:33.217] iteration 14523: loss: 0.067656, loss_s1: 0.021075, loss_fp: 0.002660, loss_freq: 0.013115
[14:32:33.845] iteration 14524: loss: 0.111889, loss_s1: 0.039209, loss_fp: 0.001462, loss_freq: 0.046586
[14:32:34.476] iteration 14525: loss: 0.085893, loss_s1: 0.065844, loss_fp: 0.001204, loss_freq: 0.049059
[14:32:35.106] iteration 14526: loss: 0.068790, loss_s1: 0.053343, loss_fp: 0.001994, loss_freq: 0.033215
[14:32:35.768] iteration 14527: loss: 0.047337, loss_s1: 0.028199, loss_fp: 0.002218, loss_freq: 0.020533
[14:32:36.392] iteration 14528: loss: 0.055675, loss_s1: 0.050713, loss_fp: 0.001924, loss_freq: 0.014619
[14:32:37.011] iteration 14529: loss: 0.087189, loss_s1: 0.050780, loss_fp: 0.006818, loss_freq: 0.070255
[14:32:37.644] iteration 14530: loss: 0.063577, loss_s1: 0.046859, loss_fp: 0.001753, loss_freq: 0.019302
[14:32:38.273] iteration 14531: loss: 0.046018, loss_s1: 0.018860, loss_fp: 0.000293, loss_freq: 0.033921
[14:32:38.898] iteration 14532: loss: 0.057397, loss_s1: 0.051217, loss_fp: 0.003688, loss_freq: 0.029455
[14:32:39.531] iteration 14533: loss: 0.065352, loss_s1: 0.047627, loss_fp: 0.001690, loss_freq: 0.027461
[14:32:40.224] iteration 14534: loss: 0.068946, loss_s1: 0.032255, loss_fp: 0.003771, loss_freq: 0.029122
[14:32:40.914] iteration 14535: loss: 0.073848, loss_s1: 0.047507, loss_fp: 0.003237, loss_freq: 0.057962
[14:32:41.563] iteration 14536: loss: 0.058182, loss_s1: 0.054012, loss_fp: 0.001254, loss_freq: 0.007157
[14:32:42.192] iteration 14537: loss: 0.071427, loss_s1: 0.035292, loss_fp: 0.007982, loss_freq: 0.024913
[14:32:42.829] iteration 14538: loss: 0.050177, loss_s1: 0.022149, loss_fp: 0.000536, loss_freq: 0.016331
[14:32:43.463] iteration 14539: loss: 0.044605, loss_s1: 0.017092, loss_fp: 0.000772, loss_freq: 0.003468
[14:32:44.099] iteration 14540: loss: 0.088359, loss_s1: 0.051362, loss_fp: 0.003137, loss_freq: 0.057447
[14:32:44.733] iteration 14541: loss: 0.058946, loss_s1: 0.024985, loss_fp: 0.019519, loss_freq: 0.015598
[14:32:45.363] iteration 14542: loss: 0.059901, loss_s1: 0.029553, loss_fp: 0.002934, loss_freq: 0.025198
[14:32:45.994] iteration 14543: loss: 0.097455, loss_s1: 0.052220, loss_fp: 0.007059, loss_freq: 0.074832
[14:32:46.617] iteration 14544: loss: 0.069787, loss_s1: 0.055143, loss_fp: 0.000966, loss_freq: 0.036725
[14:32:47.247] iteration 14545: loss: 0.061199, loss_s1: 0.036892, loss_fp: 0.000405, loss_freq: 0.030719
[14:32:47.878] iteration 14546: loss: 0.086678, loss_s1: 0.062466, loss_fp: 0.003415, loss_freq: 0.032116
[14:32:48.536] iteration 14547: loss: 0.087842, loss_s1: 0.062120, loss_fp: 0.002732, loss_freq: 0.015863
[14:32:49.189] iteration 14548: loss: 0.092904, loss_s1: 0.050999, loss_fp: 0.000946, loss_freq: 0.013623
[14:32:49.821] iteration 14549: loss: 0.068580, loss_s1: 0.026276, loss_fp: 0.001487, loss_freq: 0.038257
[14:32:50.455] iteration 14550: loss: 0.103771, loss_s1: 0.055859, loss_fp: 0.003016, loss_freq: 0.061838
[14:32:51.089] iteration 14551: loss: 0.055829, loss_s1: 0.042277, loss_fp: 0.008249, loss_freq: 0.025749
[14:32:51.718] iteration 14552: loss: 0.082978, loss_s1: 0.069755, loss_fp: 0.000623, loss_freq: 0.033198
[14:32:52.366] iteration 14553: loss: 0.049291, loss_s1: 0.015764, loss_fp: 0.004720, loss_freq: 0.027910
[14:32:52.997] iteration 14554: loss: 0.078160, loss_s1: 0.041248, loss_fp: 0.004138, loss_freq: 0.010715
[14:32:53.614] iteration 14555: loss: 0.062767, loss_s1: 0.054752, loss_fp: 0.008924, loss_freq: 0.026913
[14:32:54.243] iteration 14556: loss: 0.067735, loss_s1: 0.056922, loss_fp: 0.002365, loss_freq: 0.015379
[14:32:54.883] iteration 14557: loss: 0.046540, loss_s1: 0.017169, loss_fp: 0.002936, loss_freq: 0.017379
[14:32:55.497] iteration 14558: loss: 0.104127, loss_s1: 0.068200, loss_fp: 0.000474, loss_freq: 0.051507
[14:32:56.120] iteration 14559: loss: 0.043122, loss_s1: 0.028574, loss_fp: 0.000556, loss_freq: 0.014030
[14:32:56.746] iteration 14560: loss: 0.065309, loss_s1: 0.046794, loss_fp: 0.002685, loss_freq: 0.021518
[14:32:57.366] iteration 14561: loss: 0.100365, loss_s1: 0.115954, loss_fp: 0.001466, loss_freq: 0.028097
[14:32:57.989] iteration 14562: loss: 0.054739, loss_s1: 0.023463, loss_fp: 0.006137, loss_freq: 0.036278
[14:32:58.621] iteration 14563: loss: 0.070255, loss_s1: 0.075631, loss_fp: 0.003201, loss_freq: 0.018518
[14:32:59.245] iteration 14564: loss: 0.112088, loss_s1: 0.049556, loss_fp: 0.003699, loss_freq: 0.121334
[14:32:59.870] iteration 14565: loss: 0.121339, loss_s1: 0.047405, loss_fp: 0.002466, loss_freq: 0.021281
[14:33:00.492] iteration 14566: loss: 0.041874, loss_s1: 0.025155, loss_fp: 0.008505, loss_freq: 0.002972
[14:33:01.117] iteration 14567: loss: 0.081268, loss_s1: 0.084223, loss_fp: 0.004665, loss_freq: 0.030494
[14:33:01.743] iteration 14568: loss: 0.066392, loss_s1: 0.072270, loss_fp: 0.003789, loss_freq: 0.009615
[14:33:02.407] iteration 14569: loss: 0.092375, loss_s1: 0.040743, loss_fp: 0.002462, loss_freq: 0.021950
[14:33:03.088] iteration 14570: loss: 0.088870, loss_s1: 0.080169, loss_fp: 0.003067, loss_freq: 0.056023
[14:33:03.762] iteration 14571: loss: 0.049068, loss_s1: 0.028776, loss_fp: 0.005217, loss_freq: 0.025044
[14:33:04.443] iteration 14572: loss: 0.109171, loss_s1: 0.117774, loss_fp: 0.002239, loss_freq: 0.009185
[14:33:05.134] iteration 14573: loss: 0.053621, loss_s1: 0.030514, loss_fp: 0.002009, loss_freq: 0.019099
[14:33:05.812] iteration 14574: loss: 0.082667, loss_s1: 0.068434, loss_fp: 0.002771, loss_freq: 0.035036
[14:33:06.450] iteration 14575: loss: 0.066383, loss_s1: 0.047800, loss_fp: 0.003564, loss_freq: 0.023348
[14:33:07.095] iteration 14576: loss: 0.072687, loss_s1: 0.066885, loss_fp: 0.003310, loss_freq: 0.019349
[14:33:07.729] iteration 14577: loss: 0.103300, loss_s1: 0.044617, loss_fp: 0.007320, loss_freq: 0.091282
[14:33:08.373] iteration 14578: loss: 0.089914, loss_s1: 0.050633, loss_fp: 0.002551, loss_freq: 0.018894
[14:33:09.038] iteration 14579: loss: 0.105467, loss_s1: 0.072578, loss_fp: 0.011528, loss_freq: 0.035152
[14:33:09.692] iteration 14580: loss: 0.104413, loss_s1: 0.112688, loss_fp: 0.002494, loss_freq: 0.026266
[14:33:10.351] iteration 14581: loss: 0.044103, loss_s1: 0.032305, loss_fp: 0.000632, loss_freq: 0.013216
[14:33:10.995] iteration 14582: loss: 0.052034, loss_s1: 0.031070, loss_fp: 0.002565, loss_freq: 0.008218
[14:33:11.621] iteration 14583: loss: 0.052912, loss_s1: 0.019144, loss_fp: 0.001489, loss_freq: 0.010245
[14:33:12.248] iteration 14584: loss: 0.079555, loss_s1: 0.068057, loss_fp: 0.001398, loss_freq: 0.031204
[14:33:12.875] iteration 14585: loss: 0.072808, loss_s1: 0.045746, loss_fp: 0.008587, loss_freq: 0.029690
[14:33:13.503] iteration 14586: loss: 0.050927, loss_s1: 0.019856, loss_fp: 0.000484, loss_freq: 0.040238
[14:33:14.475] iteration 14587: loss: 0.068882, loss_s1: 0.072353, loss_fp: 0.006960, loss_freq: 0.005686
[14:33:15.104] iteration 14588: loss: 0.057801, loss_s1: 0.030884, loss_fp: 0.001227, loss_freq: 0.025504
[14:33:15.731] iteration 14589: loss: 0.051111, loss_s1: 0.036795, loss_fp: 0.000863, loss_freq: 0.025631
[14:33:16.361] iteration 14590: loss: 0.060335, loss_s1: 0.040688, loss_fp: 0.002811, loss_freq: 0.019949
[14:33:16.985] iteration 14591: loss: 0.083553, loss_s1: 0.072805, loss_fp: 0.006881, loss_freq: 0.046400
[14:33:17.616] iteration 14592: loss: 0.051350, loss_s1: 0.040447, loss_fp: 0.002398, loss_freq: 0.005072
[14:33:18.246] iteration 14593: loss: 0.076327, loss_s1: 0.089474, loss_fp: 0.005256, loss_freq: 0.019647
[14:33:18.869] iteration 14594: loss: 0.129599, loss_s1: 0.079628, loss_fp: 0.002830, loss_freq: 0.048685
[14:33:19.491] iteration 14595: loss: 0.072368, loss_s1: 0.044519, loss_fp: 0.006729, loss_freq: 0.034367
[14:33:20.118] iteration 14596: loss: 0.076862, loss_s1: 0.024219, loss_fp: 0.001759, loss_freq: 0.042429
[14:33:20.738] iteration 14597: loss: 0.080572, loss_s1: 0.036810, loss_fp: 0.006451, loss_freq: 0.063585
[14:33:21.364] iteration 14598: loss: 0.066388, loss_s1: 0.041135, loss_fp: 0.005941, loss_freq: 0.016302
[14:33:21.995] iteration 14599: loss: 0.036520, loss_s1: 0.017223, loss_fp: 0.001072, loss_freq: 0.015771
[14:33:22.625] iteration 14600: loss: 0.054213, loss_s1: 0.030552, loss_fp: 0.001429, loss_freq: 0.034812
[14:33:25.905] iteration 14600 : mean_dice : 0.749279
[14:33:26.564] iteration 14601: loss: 0.114309, loss_s1: 0.108395, loss_fp: 0.001575, loss_freq: 0.066002
[14:33:27.188] iteration 14602: loss: 0.044183, loss_s1: 0.032642, loss_fp: 0.001296, loss_freq: 0.011247
[14:33:27.819] iteration 14603: loss: 0.072557, loss_s1: 0.010323, loss_fp: 0.001334, loss_freq: 0.010799
[14:33:28.449] iteration 14604: loss: 0.052698, loss_s1: 0.022627, loss_fp: 0.010336, loss_freq: 0.011608
[14:33:29.085] iteration 14605: loss: 0.050415, loss_s1: 0.021868, loss_fp: 0.001098, loss_freq: 0.025747
[14:33:29.705] iteration 14606: loss: 0.035376, loss_s1: 0.024544, loss_fp: 0.001901, loss_freq: 0.011025
[14:33:30.337] iteration 14607: loss: 0.086382, loss_s1: 0.039450, loss_fp: 0.002337, loss_freq: 0.057331
[14:33:30.987] iteration 14608: loss: 0.045318, loss_s1: 0.026572, loss_fp: 0.004804, loss_freq: 0.024465
[14:33:31.614] iteration 14609: loss: 0.062735, loss_s1: 0.015959, loss_fp: 0.000995, loss_freq: 0.052560
[14:33:32.244] iteration 14610: loss: 0.054411, loss_s1: 0.031963, loss_fp: 0.000389, loss_freq: 0.016591
[14:33:32.876] iteration 14611: loss: 0.070608, loss_s1: 0.066656, loss_fp: 0.002266, loss_freq: 0.014850
[14:33:33.504] iteration 14612: loss: 0.069319, loss_s1: 0.026329, loss_fp: 0.009285, loss_freq: 0.021164
[14:33:34.153] iteration 14613: loss: 0.093610, loss_s1: 0.044022, loss_fp: 0.002255, loss_freq: 0.075433
[14:33:34.788] iteration 14614: loss: 0.060084, loss_s1: 0.057346, loss_fp: 0.000852, loss_freq: 0.016242
[14:33:35.411] iteration 14615: loss: 0.073672, loss_s1: 0.048232, loss_fp: 0.003074, loss_freq: 0.033280
[14:33:36.046] iteration 14616: loss: 0.088068, loss_s1: 0.020494, loss_fp: 0.001946, loss_freq: 0.005827
[14:33:36.670] iteration 14617: loss: 0.052736, loss_s1: 0.041142, loss_fp: 0.000638, loss_freq: 0.007547
[14:33:37.300] iteration 14618: loss: 0.056443, loss_s1: 0.049307, loss_fp: 0.003185, loss_freq: 0.013544
[14:33:37.934] iteration 14619: loss: 0.075693, loss_s1: 0.066954, loss_fp: 0.001600, loss_freq: 0.050010
[14:33:38.554] iteration 14620: loss: 0.108253, loss_s1: 0.117621, loss_fp: 0.006708, loss_freq: 0.050033
[14:33:39.189] iteration 14621: loss: 0.088050, loss_s1: 0.082450, loss_fp: 0.003947, loss_freq: 0.032249
[14:33:39.810] iteration 14622: loss: 0.095494, loss_s1: 0.081591, loss_fp: 0.007487, loss_freq: 0.052352
[14:33:40.444] iteration 14623: loss: 0.063893, loss_s1: 0.035428, loss_fp: 0.009788, loss_freq: 0.019559
[14:33:41.073] iteration 14624: loss: 0.079836, loss_s1: 0.063966, loss_fp: 0.001722, loss_freq: 0.052703
[14:33:41.709] iteration 14625: loss: 0.089936, loss_s1: 0.106629, loss_fp: 0.002759, loss_freq: 0.020002
[14:33:42.341] iteration 14626: loss: 0.055831, loss_s1: 0.033290, loss_fp: 0.002714, loss_freq: 0.025802
[14:33:42.961] iteration 14627: loss: 0.137482, loss_s1: 0.077795, loss_fp: 0.006207, loss_freq: 0.037877
[14:33:43.583] iteration 14628: loss: 0.048918, loss_s1: 0.031260, loss_fp: 0.011966, loss_freq: 0.025583
[14:33:44.219] iteration 14629: loss: 0.073980, loss_s1: 0.042560, loss_fp: 0.002408, loss_freq: 0.018226
[14:33:44.897] iteration 14630: loss: 0.089068, loss_s1: 0.057134, loss_fp: 0.013485, loss_freq: 0.056145
[14:33:45.524] iteration 14631: loss: 0.084770, loss_s1: 0.046963, loss_fp: 0.001315, loss_freq: 0.020143
[14:33:46.169] iteration 14632: loss: 0.082188, loss_s1: 0.071557, loss_fp: 0.002717, loss_freq: 0.021569
[14:33:46.810] iteration 14633: loss: 0.050390, loss_s1: 0.034754, loss_fp: 0.000764, loss_freq: 0.013515
[14:33:47.446] iteration 14634: loss: 0.059535, loss_s1: 0.045170, loss_fp: 0.002710, loss_freq: 0.012548
[14:33:48.080] iteration 14635: loss: 0.084525, loss_s1: 0.052764, loss_fp: 0.001660, loss_freq: 0.076864
[14:33:48.709] iteration 14636: loss: 0.043876, loss_s1: 0.013936, loss_fp: 0.002074, loss_freq: 0.021059
[14:33:49.329] iteration 14637: loss: 0.062529, loss_s1: 0.047960, loss_fp: 0.004473, loss_freq: 0.011817
[14:33:49.991] iteration 14638: loss: 0.060260, loss_s1: 0.024404, loss_fp: 0.001403, loss_freq: 0.021809
[14:33:50.651] iteration 14639: loss: 0.057227, loss_s1: 0.035111, loss_fp: 0.003321, loss_freq: 0.029229
[14:33:51.309] iteration 14640: loss: 0.046229, loss_s1: 0.034197, loss_fp: 0.000383, loss_freq: 0.010815
[14:33:51.968] iteration 14641: loss: 0.060424, loss_s1: 0.056051, loss_fp: 0.006419, loss_freq: 0.012674
[14:33:52.604] iteration 14642: loss: 0.057575, loss_s1: 0.022879, loss_fp: 0.002790, loss_freq: 0.017121
[14:33:53.249] iteration 14643: loss: 0.115826, loss_s1: 0.095276, loss_fp: 0.000917, loss_freq: 0.047163
[14:33:53.900] iteration 14644: loss: 0.028522, loss_s1: 0.016849, loss_fp: 0.001239, loss_freq: 0.006440
[14:33:54.527] iteration 14645: loss: 0.122403, loss_s1: 0.053220, loss_fp: 0.009144, loss_freq: 0.061486
[14:33:55.153] iteration 14646: loss: 0.060768, loss_s1: 0.021024, loss_fp: 0.008563, loss_freq: 0.052456
[14:33:55.784] iteration 14647: loss: 0.049021, loss_s1: 0.023874, loss_fp: 0.001771, loss_freq: 0.012880
[14:33:56.411] iteration 14648: loss: 0.077414, loss_s1: 0.046725, loss_fp: 0.001637, loss_freq: 0.043564
[14:33:57.038] iteration 14649: loss: 0.096842, loss_s1: 0.113114, loss_fp: 0.003791, loss_freq: 0.031716
[14:33:57.657] iteration 14650: loss: 0.078959, loss_s1: 0.066528, loss_fp: 0.001062, loss_freq: 0.027391
[14:33:58.291] iteration 14651: loss: 0.065253, loss_s1: 0.033172, loss_fp: 0.008078, loss_freq: 0.026594
[14:33:58.910] iteration 14652: loss: 0.064273, loss_s1: 0.041583, loss_fp: 0.001596, loss_freq: 0.023574
[14:33:59.530] iteration 14653: loss: 0.115949, loss_s1: 0.080141, loss_fp: 0.007350, loss_freq: 0.086980
[14:34:00.156] iteration 14654: loss: 0.099359, loss_s1: 0.040386, loss_fp: 0.003034, loss_freq: 0.030917
[14:34:00.783] iteration 14655: loss: 0.094035, loss_s1: 0.083536, loss_fp: 0.001198, loss_freq: 0.038906
[14:34:01.408] iteration 14656: loss: 0.059686, loss_s1: 0.038910, loss_fp: 0.003586, loss_freq: 0.012755
[14:34:02.026] iteration 14657: loss: 0.048829, loss_s1: 0.018767, loss_fp: 0.005522, loss_freq: 0.025761
[14:34:02.684] iteration 14658: loss: 0.063353, loss_s1: 0.034215, loss_fp: 0.000959, loss_freq: 0.027082
[14:34:03.348] iteration 14659: loss: 0.066308, loss_s1: 0.020420, loss_fp: 0.001591, loss_freq: 0.064522
[14:34:04.001] iteration 14660: loss: 0.073693, loss_s1: 0.060782, loss_fp: 0.003854, loss_freq: 0.018313
[14:34:04.660] iteration 14661: loss: 0.067485, loss_s1: 0.046297, loss_fp: 0.004022, loss_freq: 0.047840
[14:34:05.295] iteration 14662: loss: 0.052403, loss_s1: 0.012419, loss_fp: 0.001837, loss_freq: 0.016623
[14:34:05.919] iteration 14663: loss: 0.046459, loss_s1: 0.024304, loss_fp: 0.004691, loss_freq: 0.022291
[14:34:06.547] iteration 14664: loss: 0.045440, loss_s1: 0.027776, loss_fp: 0.002805, loss_freq: 0.008857
[14:34:07.179] iteration 14665: loss: 0.113490, loss_s1: 0.060845, loss_fp: 0.063817, loss_freq: 0.049338
[14:34:07.799] iteration 14666: loss: 0.112562, loss_s1: 0.071980, loss_fp: 0.004912, loss_freq: 0.027207
[14:34:08.431] iteration 14667: loss: 0.068488, loss_s1: 0.034072, loss_fp: 0.000916, loss_freq: 0.041790
[14:34:09.059] iteration 14668: loss: 0.059179, loss_s1: 0.026199, loss_fp: 0.003493, loss_freq: 0.028467
[14:34:09.687] iteration 14669: loss: 0.054846, loss_s1: 0.015294, loss_fp: 0.000899, loss_freq: 0.036348
[14:34:10.309] iteration 14670: loss: 0.056696, loss_s1: 0.043879, loss_fp: 0.000686, loss_freq: 0.025789
[14:34:10.929] iteration 14671: loss: 0.055326, loss_s1: 0.028849, loss_fp: 0.005654, loss_freq: 0.017964
[14:34:11.545] iteration 14672: loss: 0.064592, loss_s1: 0.040166, loss_fp: 0.004222, loss_freq: 0.032290
[14:34:12.190] iteration 14673: loss: 0.061507, loss_s1: 0.034048, loss_fp: 0.001701, loss_freq: 0.032641
[14:34:12.839] iteration 14674: loss: 0.053407, loss_s1: 0.016449, loss_fp: 0.000740, loss_freq: 0.034066
[14:34:13.467] iteration 14675: loss: 0.044851, loss_s1: 0.023867, loss_fp: 0.009003, loss_freq: 0.014611
[14:34:14.090] iteration 14676: loss: 0.096360, loss_s1: 0.057298, loss_fp: 0.002339, loss_freq: 0.020702
[14:34:14.717] iteration 14677: loss: 0.055593, loss_s1: 0.010333, loss_fp: 0.001646, loss_freq: 0.014517
[14:34:15.347] iteration 14678: loss: 0.060056, loss_s1: 0.044828, loss_fp: 0.001324, loss_freq: 0.019698
[14:34:15.975] iteration 14679: loss: 0.065997, loss_s1: 0.066271, loss_fp: 0.001204, loss_freq: 0.014792
[14:34:16.600] iteration 14680: loss: 0.058965, loss_s1: 0.047946, loss_fp: 0.001794, loss_freq: 0.013228
[14:34:17.224] iteration 14681: loss: 0.067058, loss_s1: 0.023632, loss_fp: 0.001049, loss_freq: 0.047638
[14:34:17.851] iteration 14682: loss: 0.047586, loss_s1: 0.023954, loss_fp: 0.005806, loss_freq: 0.015183
[14:34:18.478] iteration 14683: loss: 0.100561, loss_s1: 0.046784, loss_fp: 0.006497, loss_freq: 0.071447
[14:34:19.103] iteration 14684: loss: 0.049976, loss_s1: 0.025737, loss_fp: 0.001292, loss_freq: 0.021985
[14:34:19.728] iteration 14685: loss: 0.057540, loss_s1: 0.057216, loss_fp: 0.001000, loss_freq: 0.009114
[14:34:20.354] iteration 14686: loss: 0.081464, loss_s1: 0.069622, loss_fp: 0.001399, loss_freq: 0.040507
[14:34:20.982] iteration 14687: loss: 0.067915, loss_s1: 0.051388, loss_fp: 0.003892, loss_freq: 0.021540
[14:34:21.606] iteration 14688: loss: 0.083417, loss_s1: 0.036423, loss_fp: 0.012665, loss_freq: 0.037867
[14:34:22.230] iteration 14689: loss: 0.084400, loss_s1: 0.087172, loss_fp: 0.002358, loss_freq: 0.028315
[14:34:22.851] iteration 14690: loss: 0.049560, loss_s1: 0.035614, loss_fp: 0.002991, loss_freq: 0.011525
[14:34:23.474] iteration 14691: loss: 0.082997, loss_s1: 0.041629, loss_fp: 0.002766, loss_freq: 0.029380
[14:34:24.099] iteration 14692: loss: 0.051369, loss_s1: 0.036629, loss_fp: 0.001134, loss_freq: 0.009715
[14:34:24.724] iteration 14693: loss: 0.087286, loss_s1: 0.070254, loss_fp: 0.000705, loss_freq: 0.047319
[14:34:25.351] iteration 14694: loss: 0.091053, loss_s1: 0.042086, loss_fp: 0.003043, loss_freq: 0.066480
[14:34:25.970] iteration 14695: loss: 0.068525, loss_s1: 0.036194, loss_fp: 0.001092, loss_freq: 0.039414
[14:34:26.588] iteration 14696: loss: 0.053312, loss_s1: 0.024217, loss_fp: 0.002713, loss_freq: 0.021132
[14:34:27.212] iteration 14697: loss: 0.076607, loss_s1: 0.054186, loss_fp: 0.001031, loss_freq: 0.007896
[14:34:27.840] iteration 14698: loss: 0.042002, loss_s1: 0.026511, loss_fp: 0.002889, loss_freq: 0.018555
[14:34:28.463] iteration 14699: loss: 0.040248, loss_s1: 0.013798, loss_fp: 0.002362, loss_freq: 0.014067
[14:34:29.078] iteration 14700: loss: 0.099951, loss_s1: 0.099780, loss_fp: 0.004535, loss_freq: 0.038678
[14:34:29.700] iteration 14701: loss: 0.063366, loss_s1: 0.020356, loss_fp: 0.000710, loss_freq: 0.016806
[14:34:30.325] iteration 14702: loss: 0.050205, loss_s1: 0.047876, loss_fp: 0.002113, loss_freq: 0.009489
[14:34:30.949] iteration 14703: loss: 0.066581, loss_s1: 0.036085, loss_fp: 0.001174, loss_freq: 0.035342
[14:34:31.576] iteration 14704: loss: 0.083880, loss_s1: 0.063451, loss_fp: 0.000721, loss_freq: 0.018776
[14:34:32.193] iteration 14705: loss: 0.068176, loss_s1: 0.054114, loss_fp: 0.002285, loss_freq: 0.039137
[14:34:32.823] iteration 14706: loss: 0.056019, loss_s1: 0.037266, loss_fp: 0.002149, loss_freq: 0.024873
[14:34:33.441] iteration 14707: loss: 0.096460, loss_s1: 0.062071, loss_fp: 0.001431, loss_freq: 0.071863
[14:34:34.058] iteration 14708: loss: 0.146966, loss_s1: 0.078891, loss_fp: 0.002201, loss_freq: 0.014911
[14:34:34.682] iteration 14709: loss: 0.029066, loss_s1: 0.010868, loss_fp: 0.001895, loss_freq: 0.006272
[14:34:35.304] iteration 14710: loss: 0.043372, loss_s1: 0.027794, loss_fp: 0.001392, loss_freq: 0.016105
[14:34:35.927] iteration 14711: loss: 0.066825, loss_s1: 0.045948, loss_fp: 0.003798, loss_freq: 0.039699
[14:34:36.551] iteration 14712: loss: 0.071160, loss_s1: 0.014892, loss_fp: 0.002526, loss_freq: 0.023334
[14:34:37.174] iteration 14713: loss: 0.064776, loss_s1: 0.050375, loss_fp: 0.002453, loss_freq: 0.030814
[14:34:37.799] iteration 14714: loss: 0.062191, loss_s1: 0.066870, loss_fp: 0.002538, loss_freq: 0.020766
[14:34:38.422] iteration 14715: loss: 0.070424, loss_s1: 0.054099, loss_fp: 0.005910, loss_freq: 0.007955
[14:34:39.042] iteration 14716: loss: 0.061921, loss_s1: 0.052054, loss_fp: 0.004875, loss_freq: 0.005553
[14:34:39.669] iteration 14717: loss: 0.072414, loss_s1: 0.031561, loss_fp: 0.007496, loss_freq: 0.028129
[14:34:40.298] iteration 14718: loss: 0.111905, loss_s1: 0.087392, loss_fp: 0.014733, loss_freq: 0.046964
[14:34:40.922] iteration 14719: loss: 0.081444, loss_s1: 0.067946, loss_fp: 0.005081, loss_freq: 0.021035
[14:34:41.544] iteration 14720: loss: 0.059816, loss_s1: 0.014244, loss_fp: 0.000601, loss_freq: 0.041195
[14:34:42.170] iteration 14721: loss: 0.067698, loss_s1: 0.037901, loss_fp: 0.008380, loss_freq: 0.026208
[14:34:42.794] iteration 14722: loss: 0.090666, loss_s1: 0.057702, loss_fp: 0.002334, loss_freq: 0.036953
[14:34:43.419] iteration 14723: loss: 0.083265, loss_s1: 0.050880, loss_fp: 0.006437, loss_freq: 0.036246
[14:34:44.038] iteration 14724: loss: 0.056998, loss_s1: 0.030066, loss_fp: 0.006704, loss_freq: 0.009631
[14:34:44.662] iteration 14725: loss: 0.060662, loss_s1: 0.019253, loss_fp: 0.006568, loss_freq: 0.034717
[14:34:45.286] iteration 14726: loss: 0.063602, loss_s1: 0.023272, loss_fp: 0.010339, loss_freq: 0.028443
[14:34:45.911] iteration 14727: loss: 0.066718, loss_s1: 0.025344, loss_fp: 0.002860, loss_freq: 0.032811
[14:34:46.533] iteration 14728: loss: 0.090040, loss_s1: 0.044703, loss_fp: 0.024831, loss_freq: 0.061725
[14:34:47.158] iteration 14729: loss: 0.047771, loss_s1: 0.016906, loss_fp: 0.001625, loss_freq: 0.027267
[14:34:48.173] iteration 14730: loss: 0.048015, loss_s1: 0.036732, loss_fp: 0.001763, loss_freq: 0.004673
[14:34:48.827] iteration 14731: loss: 0.054005, loss_s1: 0.025510, loss_fp: 0.004295, loss_freq: 0.016268
[14:34:49.487] iteration 14732: loss: 0.034773, loss_s1: 0.018577, loss_fp: 0.000483, loss_freq: 0.013496
[14:34:50.144] iteration 14733: loss: 0.049412, loss_s1: 0.019746, loss_fp: 0.003139, loss_freq: 0.020597
[14:34:50.795] iteration 14734: loss: 0.083736, loss_s1: 0.097505, loss_fp: 0.003620, loss_freq: 0.032226
[14:34:51.451] iteration 14735: loss: 0.065887, loss_s1: 0.022892, loss_fp: 0.002288, loss_freq: 0.003978
[14:34:52.084] iteration 14736: loss: 0.035572, loss_s1: 0.016835, loss_fp: 0.004406, loss_freq: 0.013823
[14:34:52.719] iteration 14737: loss: 0.117958, loss_s1: 0.112636, loss_fp: 0.006012, loss_freq: 0.043796
[14:34:53.342] iteration 14738: loss: 0.063038, loss_s1: 0.055921, loss_fp: 0.002218, loss_freq: 0.029438
[14:34:53.962] iteration 14739: loss: 0.071296, loss_s1: 0.031020, loss_fp: 0.000663, loss_freq: 0.009151
[14:34:54.587] iteration 14740: loss: 0.070561, loss_s1: 0.031671, loss_fp: 0.001970, loss_freq: 0.061258
[14:34:55.211] iteration 14741: loss: 0.071912, loss_s1: 0.039461, loss_fp: 0.003659, loss_freq: 0.036344
[14:34:55.830] iteration 14742: loss: 0.042737, loss_s1: 0.016053, loss_fp: 0.003627, loss_freq: 0.015384
[14:34:56.457] iteration 14743: loss: 0.041514, loss_s1: 0.019985, loss_fp: 0.001886, loss_freq: 0.011140
[14:34:57.081] iteration 14744: loss: 0.059317, loss_s1: 0.048640, loss_fp: 0.003354, loss_freq: 0.022785
[14:34:57.696] iteration 14745: loss: 0.056570, loss_s1: 0.035690, loss_fp: 0.002027, loss_freq: 0.020486
[14:34:58.320] iteration 14746: loss: 0.101475, loss_s1: 0.014181, loss_fp: 0.000722, loss_freq: 0.016100
[14:34:58.945] iteration 14747: loss: 0.050551, loss_s1: 0.029865, loss_fp: 0.005221, loss_freq: 0.016464
[14:34:59.571] iteration 14748: loss: 0.051094, loss_s1: 0.052891, loss_fp: 0.002164, loss_freq: 0.010326
[14:35:00.257] iteration 14749: loss: 0.038089, loss_s1: 0.029054, loss_fp: 0.001835, loss_freq: 0.013886
[14:35:00.918] iteration 14750: loss: 0.097124, loss_s1: 0.018042, loss_fp: 0.002227, loss_freq: 0.054003
[14:35:01.579] iteration 14751: loss: 0.046564, loss_s1: 0.023963, loss_fp: 0.003213, loss_freq: 0.028235
[14:35:02.240] iteration 14752: loss: 0.036438, loss_s1: 0.019978, loss_fp: 0.003562, loss_freq: 0.010080
[14:35:02.896] iteration 14753: loss: 0.044743, loss_s1: 0.016429, loss_fp: 0.003772, loss_freq: 0.008060
[14:35:03.539] iteration 14754: loss: 0.057093, loss_s1: 0.052684, loss_fp: 0.002226, loss_freq: 0.012820
[14:35:04.168] iteration 14755: loss: 0.134080, loss_s1: 0.160774, loss_fp: 0.009959, loss_freq: 0.045798
[14:35:04.797] iteration 14756: loss: 0.091688, loss_s1: 0.078681, loss_fp: 0.001580, loss_freq: 0.058831
[14:35:05.420] iteration 14757: loss: 0.041689, loss_s1: 0.034388, loss_fp: 0.002133, loss_freq: 0.006864
[14:35:06.048] iteration 14758: loss: 0.094521, loss_s1: 0.084068, loss_fp: 0.006677, loss_freq: 0.020064
[14:35:06.676] iteration 14759: loss: 0.041425, loss_s1: 0.026868, loss_fp: 0.000671, loss_freq: 0.008078
[14:35:07.297] iteration 14760: loss: 0.044695, loss_s1: 0.011435, loss_fp: 0.002751, loss_freq: 0.027574
[14:35:07.923] iteration 14761: loss: 0.057231, loss_s1: 0.024918, loss_fp: 0.003324, loss_freq: 0.022930
[14:35:08.553] iteration 14762: loss: 0.044916, loss_s1: 0.029494, loss_fp: 0.001707, loss_freq: 0.021129
[14:35:09.175] iteration 14763: loss: 0.098869, loss_s1: 0.067581, loss_fp: 0.008837, loss_freq: 0.054817
[14:35:09.801] iteration 14764: loss: 0.122776, loss_s1: 0.024713, loss_fp: 0.003107, loss_freq: 0.034839
[14:35:10.425] iteration 14765: loss: 0.052699, loss_s1: 0.024987, loss_fp: 0.010888, loss_freq: 0.012894
[14:35:11.061] iteration 14766: loss: 0.062283, loss_s1: 0.036660, loss_fp: 0.002927, loss_freq: 0.026108
[14:35:11.679] iteration 14767: loss: 0.041462, loss_s1: 0.013267, loss_fp: 0.002543, loss_freq: 0.031253
[14:35:12.350] iteration 14768: loss: 0.108534, loss_s1: 0.066755, loss_fp: 0.002481, loss_freq: 0.034309
[14:35:12.978] iteration 14769: loss: 0.049049, loss_s1: 0.035558, loss_fp: 0.001601, loss_freq: 0.013236
[14:35:13.605] iteration 14770: loss: 0.091961, loss_s1: 0.052476, loss_fp: 0.001137, loss_freq: 0.011360
[14:35:14.232] iteration 14771: loss: 0.049071, loss_s1: 0.033124, loss_fp: 0.005695, loss_freq: 0.023416
[14:35:14.852] iteration 14772: loss: 0.051263, loss_s1: 0.028619, loss_fp: 0.000899, loss_freq: 0.022042
[14:35:15.476] iteration 14773: loss: 0.051024, loss_s1: 0.013852, loss_fp: 0.004569, loss_freq: 0.024108
[14:35:16.097] iteration 14774: loss: 0.079376, loss_s1: 0.077652, loss_fp: 0.001789, loss_freq: 0.007623
[14:35:16.748] iteration 14775: loss: 0.046286, loss_s1: 0.020659, loss_fp: 0.000621, loss_freq: 0.031488
[14:35:17.405] iteration 14776: loss: 0.070469, loss_s1: 0.014900, loss_fp: 0.004585, loss_freq: 0.065208
[14:35:18.022] iteration 14777: loss: 0.040752, loss_s1: 0.025365, loss_fp: 0.001770, loss_freq: 0.011484
[14:35:18.644] iteration 14778: loss: 0.077943, loss_s1: 0.078086, loss_fp: 0.001395, loss_freq: 0.027113
[14:35:19.270] iteration 14779: loss: 0.047190, loss_s1: 0.026852, loss_fp: 0.000617, loss_freq: 0.013261
[14:35:19.897] iteration 14780: loss: 0.045309, loss_s1: 0.018702, loss_fp: 0.012846, loss_freq: 0.009502
[14:35:20.526] iteration 14781: loss: 0.104366, loss_s1: 0.005129, loss_fp: 0.003289, loss_freq: 0.026983
[14:35:21.156] iteration 14782: loss: 0.064075, loss_s1: 0.055838, loss_fp: 0.000398, loss_freq: 0.026313
[14:35:21.786] iteration 14783: loss: 0.037728, loss_s1: 0.023740, loss_fp: 0.000940, loss_freq: 0.017578
[14:35:22.415] iteration 14784: loss: 0.054323, loss_s1: 0.042582, loss_fp: 0.005046, loss_freq: 0.015195
[14:35:23.040] iteration 14785: loss: 0.076046, loss_s1: 0.028308, loss_fp: 0.003551, loss_freq: 0.029184
[14:35:23.665] iteration 14786: loss: 0.072243, loss_s1: 0.070756, loss_fp: 0.001087, loss_freq: 0.031993
[14:35:24.293] iteration 14787: loss: 0.052167, loss_s1: 0.029994, loss_fp: 0.003112, loss_freq: 0.015245
[14:35:24.916] iteration 14788: loss: 0.068921, loss_s1: 0.041410, loss_fp: 0.003559, loss_freq: 0.033708
[14:35:25.539] iteration 14789: loss: 0.049188, loss_s1: 0.032283, loss_fp: 0.000784, loss_freq: 0.018868
[14:35:26.165] iteration 14790: loss: 0.045037, loss_s1: 0.013142, loss_fp: 0.003206, loss_freq: 0.010649
[14:35:26.792] iteration 14791: loss: 0.062870, loss_s1: 0.061007, loss_fp: 0.008053, loss_freq: 0.013781
[14:35:27.412] iteration 14792: loss: 0.043155, loss_s1: 0.023191, loss_fp: 0.002418, loss_freq: 0.014026
[14:35:28.039] iteration 14793: loss: 0.049294, loss_s1: 0.008528, loss_fp: 0.000591, loss_freq: 0.016044
[14:35:28.665] iteration 14794: loss: 0.092143, loss_s1: 0.056449, loss_fp: 0.007673, loss_freq: 0.034910
[14:35:29.295] iteration 14795: loss: 0.071240, loss_s1: 0.021331, loss_fp: 0.006646, loss_freq: 0.021309
[14:35:29.944] iteration 14796: loss: 0.080448, loss_s1: 0.051731, loss_fp: 0.004232, loss_freq: 0.052308
[14:35:30.603] iteration 14797: loss: 0.052007, loss_s1: 0.015292, loss_fp: 0.003186, loss_freq: 0.043275
[14:35:31.259] iteration 14798: loss: 0.076145, loss_s1: 0.070447, loss_fp: 0.005982, loss_freq: 0.026539
[14:35:31.915] iteration 14799: loss: 0.076228, loss_s1: 0.037957, loss_fp: 0.002535, loss_freq: 0.003205
[14:35:32.566] iteration 14800: loss: 0.048127, loss_s1: 0.029400, loss_fp: 0.006691, loss_freq: 0.015558
[14:35:36.294] iteration 14800 : mean_dice : 0.778399
[14:35:36.989] iteration 14801: loss: 0.065118, loss_s1: 0.033927, loss_fp: 0.001924, loss_freq: 0.045136
[14:35:37.644] iteration 14802: loss: 0.062276, loss_s1: 0.052039, loss_fp: 0.002835, loss_freq: 0.028707
[14:35:38.304] iteration 14803: loss: 0.100966, loss_s1: 0.070794, loss_fp: 0.002714, loss_freq: 0.053925
[14:35:38.962] iteration 14804: loss: 0.090675, loss_s1: 0.066776, loss_fp: 0.001952, loss_freq: 0.065642
[14:35:39.595] iteration 14805: loss: 0.071203, loss_s1: 0.043578, loss_fp: 0.001426, loss_freq: 0.019724
[14:35:40.226] iteration 14806: loss: 0.081420, loss_s1: 0.098980, loss_fp: 0.002749, loss_freq: 0.027175
[14:35:40.859] iteration 14807: loss: 0.082814, loss_s1: 0.038444, loss_fp: 0.002795, loss_freq: 0.010574
[14:35:41.562] iteration 14808: loss: 0.057250, loss_s1: 0.059912, loss_fp: 0.003987, loss_freq: 0.007354
[14:35:42.227] iteration 14809: loss: 0.109590, loss_s1: 0.100639, loss_fp: 0.002785, loss_freq: 0.042874
[14:35:42.892] iteration 14810: loss: 0.058649, loss_s1: 0.026280, loss_fp: 0.002668, loss_freq: 0.039918
[14:35:43.531] iteration 14811: loss: 0.055699, loss_s1: 0.035342, loss_fp: 0.002215, loss_freq: 0.018590
[14:35:44.160] iteration 14812: loss: 0.058568, loss_s1: 0.051126, loss_fp: 0.001252, loss_freq: 0.021457
[14:35:44.776] iteration 14813: loss: 0.038334, loss_s1: 0.028676, loss_fp: 0.000716, loss_freq: 0.011616
[14:35:45.408] iteration 14814: loss: 0.037681, loss_s1: 0.012428, loss_fp: 0.002647, loss_freq: 0.005043
[14:35:46.038] iteration 14815: loss: 0.087665, loss_s1: 0.082934, loss_fp: 0.000878, loss_freq: 0.043484
[14:35:46.664] iteration 14816: loss: 0.107605, loss_s1: 0.045608, loss_fp: 0.001169, loss_freq: 0.004858
[14:35:47.298] iteration 14817: loss: 0.067049, loss_s1: 0.057998, loss_fp: 0.000608, loss_freq: 0.016514
[14:35:47.958] iteration 14818: loss: 0.059719, loss_s1: 0.060855, loss_fp: 0.001344, loss_freq: 0.013648
[14:35:48.587] iteration 14819: loss: 0.098585, loss_s1: 0.078786, loss_fp: 0.001846, loss_freq: 0.068080
[14:35:49.330] iteration 14820: loss: 0.073094, loss_s1: 0.015999, loss_fp: 0.000682, loss_freq: 0.024418
[14:35:50.221] iteration 14821: loss: 0.070027, loss_s1: 0.056564, loss_fp: 0.002056, loss_freq: 0.032932
[14:35:50.885] iteration 14822: loss: 0.045692, loss_s1: 0.024786, loss_fp: 0.002328, loss_freq: 0.026190
[14:35:51.518] iteration 14823: loss: 0.073202, loss_s1: 0.076903, loss_fp: 0.002560, loss_freq: 0.011327
[14:35:52.189] iteration 14824: loss: 0.047052, loss_s1: 0.018721, loss_fp: 0.004279, loss_freq: 0.022043
[14:35:52.818] iteration 14825: loss: 0.064772, loss_s1: 0.022399, loss_fp: 0.003435, loss_freq: 0.030048
[14:35:53.443] iteration 14826: loss: 0.104287, loss_s1: 0.038390, loss_fp: 0.007457, loss_freq: 0.094195
[14:35:54.066] iteration 14827: loss: 0.051090, loss_s1: 0.030427, loss_fp: 0.000788, loss_freq: 0.017159
[14:35:54.686] iteration 14828: loss: 0.130337, loss_s1: 0.049610, loss_fp: 0.003197, loss_freq: 0.012503
[14:35:55.315] iteration 14829: loss: 0.110791, loss_s1: 0.074585, loss_fp: 0.005907, loss_freq: 0.047006
[14:35:55.943] iteration 14830: loss: 0.058056, loss_s1: 0.037321, loss_fp: 0.001518, loss_freq: 0.026392
[14:35:56.575] iteration 14831: loss: 0.067206, loss_s1: 0.018878, loss_fp: 0.002882, loss_freq: 0.047622
[14:35:57.220] iteration 14832: loss: 0.060012, loss_s1: 0.041246, loss_fp: 0.005395, loss_freq: 0.030707
[14:35:57.855] iteration 14833: loss: 0.060622, loss_s1: 0.048564, loss_fp: 0.000914, loss_freq: 0.026692
[14:35:58.483] iteration 14834: loss: 0.069009, loss_s1: 0.045531, loss_fp: 0.003946, loss_freq: 0.031317
[14:35:59.117] iteration 14835: loss: 0.079105, loss_s1: 0.072680, loss_fp: 0.002614, loss_freq: 0.016434
[14:35:59.766] iteration 14836: loss: 0.140429, loss_s1: 0.079080, loss_fp: 0.007366, loss_freq: 0.139361
[14:36:00.429] iteration 14837: loss: 0.055288, loss_s1: 0.041412, loss_fp: 0.001744, loss_freq: 0.029102
[14:36:01.084] iteration 14838: loss: 0.090289, loss_s1: 0.062409, loss_fp: 0.006766, loss_freq: 0.023889
[14:36:01.746] iteration 14839: loss: 0.095699, loss_s1: 0.054462, loss_fp: 0.030252, loss_freq: 0.062158
[14:36:02.416] iteration 14840: loss: 0.051743, loss_s1: 0.022880, loss_fp: 0.001870, loss_freq: 0.028337
[14:36:03.056] iteration 14841: loss: 0.071965, loss_s1: 0.040875, loss_fp: 0.006136, loss_freq: 0.037513
[14:36:03.693] iteration 14842: loss: 0.052301, loss_s1: 0.031417, loss_fp: 0.001430, loss_freq: 0.008596
[14:36:04.318] iteration 14843: loss: 0.061179, loss_s1: 0.015449, loss_fp: 0.010258, loss_freq: 0.045092
[14:36:04.958] iteration 14844: loss: 0.117886, loss_s1: 0.032955, loss_fp: 0.004340, loss_freq: 0.035640
[14:36:05.615] iteration 14845: loss: 0.042782, loss_s1: 0.012135, loss_fp: 0.002406, loss_freq: 0.016174
[14:36:06.259] iteration 14846: loss: 0.103101, loss_s1: 0.073109, loss_fp: 0.017151, loss_freq: 0.070961
[14:36:06.892] iteration 14847: loss: 0.061529, loss_s1: 0.035607, loss_fp: 0.003228, loss_freq: 0.035072
[14:36:07.527] iteration 14848: loss: 0.049072, loss_s1: 0.029010, loss_fp: 0.002568, loss_freq: 0.028544
[14:36:08.160] iteration 14849: loss: 0.088624, loss_s1: 0.087896, loss_fp: 0.002001, loss_freq: 0.016182
[14:36:08.787] iteration 14850: loss: 0.072120, loss_s1: 0.047071, loss_fp: 0.002133, loss_freq: 0.041132
[14:36:09.451] iteration 14851: loss: 0.079789, loss_s1: 0.027945, loss_fp: 0.001813, loss_freq: 0.013317
[14:36:10.132] iteration 14852: loss: 0.035211, loss_s1: 0.016502, loss_fp: 0.000959, loss_freq: 0.004902
[14:36:10.801] iteration 14853: loss: 0.071721, loss_s1: 0.068983, loss_fp: 0.003197, loss_freq: 0.021024
[14:36:11.484] iteration 14854: loss: 0.073099, loss_s1: 0.048054, loss_fp: 0.007702, loss_freq: 0.036233
[14:36:12.140] iteration 14855: loss: 0.054815, loss_s1: 0.024616, loss_fp: 0.002994, loss_freq: 0.013149
[14:36:12.782] iteration 14856: loss: 0.047704, loss_s1: 0.029948, loss_fp: 0.013540, loss_freq: 0.018057
[14:36:13.425] iteration 14857: loss: 0.062026, loss_s1: 0.040926, loss_fp: 0.000563, loss_freq: 0.032296
[14:36:14.075] iteration 14858: loss: 0.061808, loss_s1: 0.049351, loss_fp: 0.002070, loss_freq: 0.011003
[14:36:14.737] iteration 14859: loss: 0.044452, loss_s1: 0.019394, loss_fp: 0.002132, loss_freq: 0.014233
[14:36:15.401] iteration 14860: loss: 0.070554, loss_s1: 0.041952, loss_fp: 0.001923, loss_freq: 0.047981
[14:36:16.062] iteration 14861: loss: 0.087479, loss_s1: 0.061751, loss_fp: 0.005628, loss_freq: 0.040976
[14:36:16.718] iteration 14862: loss: 0.103565, loss_s1: 0.074437, loss_fp: 0.005020, loss_freq: 0.032643
[14:36:17.375] iteration 14863: loss: 0.058493, loss_s1: 0.024250, loss_fp: 0.001242, loss_freq: 0.026556
[14:36:18.038] iteration 14864: loss: 0.069191, loss_s1: 0.016207, loss_fp: 0.006081, loss_freq: 0.017030
[14:36:18.671] iteration 14865: loss: 0.056953, loss_s1: 0.036123, loss_fp: 0.004787, loss_freq: 0.026071
[14:36:19.306] iteration 14866: loss: 0.076617, loss_s1: 0.039142, loss_fp: 0.005037, loss_freq: 0.035575
[14:36:19.943] iteration 14867: loss: 0.048730, loss_s1: 0.034773, loss_fp: 0.006541, loss_freq: 0.010111
[14:36:20.607] iteration 14868: loss: 0.059841, loss_s1: 0.051039, loss_fp: 0.001290, loss_freq: 0.019623
[14:36:21.225] iteration 14869: loss: 0.054912, loss_s1: 0.038509, loss_fp: 0.001350, loss_freq: 0.009289
[14:36:21.857] iteration 14870: loss: 0.096144, loss_s1: 0.066679, loss_fp: 0.006305, loss_freq: 0.045773
[14:36:22.484] iteration 14871: loss: 0.117512, loss_s1: 0.092400, loss_fp: 0.009750, loss_freq: 0.080482
[14:36:23.106] iteration 14872: loss: 0.056498, loss_s1: 0.037200, loss_fp: 0.001987, loss_freq: 0.027005
[14:36:24.106] iteration 14873: loss: 0.056743, loss_s1: 0.039175, loss_fp: 0.001038, loss_freq: 0.003771
[14:36:24.759] iteration 14874: loss: 0.063340, loss_s1: 0.043899, loss_fp: 0.001163, loss_freq: 0.025822
[14:36:25.412] iteration 14875: loss: 0.054316, loss_s1: 0.021423, loss_fp: 0.007856, loss_freq: 0.015054
[14:36:26.061] iteration 14876: loss: 0.064265, loss_s1: 0.028769, loss_fp: 0.000625, loss_freq: 0.034091
[14:36:26.734] iteration 14877: loss: 0.077673, loss_s1: 0.091829, loss_fp: 0.005395, loss_freq: 0.022593
[14:36:27.363] iteration 14878: loss: 0.058065, loss_s1: 0.031905, loss_fp: 0.002625, loss_freq: 0.010777
[14:36:27.991] iteration 14879: loss: 0.051236, loss_s1: 0.049543, loss_fp: 0.000618, loss_freq: 0.020898
[14:36:28.619] iteration 14880: loss: 0.106643, loss_s1: 0.073872, loss_fp: 0.009112, loss_freq: 0.030844
[14:36:29.247] iteration 14881: loss: 0.050545, loss_s1: 0.018928, loss_fp: 0.001825, loss_freq: 0.025186
[14:36:29.876] iteration 14882: loss: 0.050931, loss_s1: 0.007168, loss_fp: 0.001057, loss_freq: 0.010890
[14:36:30.495] iteration 14883: loss: 0.095022, loss_s1: 0.078843, loss_fp: 0.003164, loss_freq: 0.059674
[14:36:31.121] iteration 14884: loss: 0.044899, loss_s1: 0.019155, loss_fp: 0.006270, loss_freq: 0.010964
[14:36:31.746] iteration 14885: loss: 0.075190, loss_s1: 0.070402, loss_fp: 0.003250, loss_freq: 0.011997
[14:36:32.372] iteration 14886: loss: 0.038996, loss_s1: 0.030835, loss_fp: 0.000719, loss_freq: 0.014170
[14:36:32.993] iteration 14887: loss: 0.085206, loss_s1: 0.059191, loss_fp: 0.002815, loss_freq: 0.042902
[14:36:33.620] iteration 14888: loss: 0.050461, loss_s1: 0.036034, loss_fp: 0.001951, loss_freq: 0.007339
[14:36:34.243] iteration 14889: loss: 0.056106, loss_s1: 0.028868, loss_fp: 0.003768, loss_freq: 0.014841
[14:36:34.874] iteration 14890: loss: 0.108543, loss_s1: 0.027570, loss_fp: 0.004856, loss_freq: 0.030268
[14:36:35.498] iteration 14891: loss: 0.045273, loss_s1: 0.032353, loss_fp: 0.001981, loss_freq: 0.013657
[14:36:36.123] iteration 14892: loss: 0.046709, loss_s1: 0.041327, loss_fp: 0.001030, loss_freq: 0.012147
[14:36:36.756] iteration 14893: loss: 0.089440, loss_s1: 0.016256, loss_fp: 0.001941, loss_freq: 0.082708
[14:36:37.411] iteration 14894: loss: 0.060443, loss_s1: 0.022521, loss_fp: 0.000618, loss_freq: 0.039120
[14:36:38.070] iteration 14895: loss: 0.046387, loss_s1: 0.008872, loss_fp: 0.002379, loss_freq: 0.041466
[14:36:38.724] iteration 14896: loss: 0.066577, loss_s1: 0.046610, loss_fp: 0.002065, loss_freq: 0.006444
[14:36:39.344] iteration 14897: loss: 0.049037, loss_s1: 0.030281, loss_fp: 0.002505, loss_freq: 0.021910
[14:36:39.966] iteration 14898: loss: 0.100239, loss_s1: 0.095321, loss_fp: 0.001729, loss_freq: 0.033459
[14:36:40.589] iteration 14899: loss: 0.074007, loss_s1: 0.056179, loss_fp: 0.001828, loss_freq: 0.046297
[14:36:41.217] iteration 14900: loss: 0.050061, loss_s1: 0.037758, loss_fp: 0.000831, loss_freq: 0.007621
[14:36:41.835] iteration 14901: loss: 0.073384, loss_s1: 0.031740, loss_fp: 0.005294, loss_freq: 0.039705
[14:36:42.450] iteration 14902: loss: 0.068728, loss_s1: 0.040822, loss_fp: 0.000836, loss_freq: 0.011802
[14:36:43.081] iteration 14903: loss: 0.063730, loss_s1: 0.021480, loss_fp: 0.004935, loss_freq: 0.025185
[14:36:43.714] iteration 14904: loss: 0.064331, loss_s1: 0.042977, loss_fp: 0.002941, loss_freq: 0.013265
[14:36:44.347] iteration 14905: loss: 0.073133, loss_s1: 0.044425, loss_fp: 0.011609, loss_freq: 0.053706
[14:36:44.974] iteration 14906: loss: 0.095306, loss_s1: 0.078589, loss_fp: 0.002573, loss_freq: 0.060911
[14:36:45.605] iteration 14907: loss: 0.085748, loss_s1: 0.054177, loss_fp: 0.002882, loss_freq: 0.022404
[14:36:46.234] iteration 14908: loss: 0.070864, loss_s1: 0.048069, loss_fp: 0.002246, loss_freq: 0.029160
[14:36:46.862] iteration 14909: loss: 0.067138, loss_s1: 0.058306, loss_fp: 0.002324, loss_freq: 0.017584
[14:36:47.490] iteration 14910: loss: 0.044171, loss_s1: 0.036606, loss_fp: 0.002510, loss_freq: 0.016806
[14:36:48.116] iteration 14911: loss: 0.109720, loss_s1: 0.080162, loss_fp: 0.003174, loss_freq: 0.069152
[14:36:48.740] iteration 14912: loss: 0.055538, loss_s1: 0.048234, loss_fp: 0.002863, loss_freq: 0.016341
[14:36:49.374] iteration 14913: loss: 0.088916, loss_s1: 0.046112, loss_fp: 0.005831, loss_freq: 0.023285
[14:36:50.003] iteration 14914: loss: 0.055971, loss_s1: 0.044233, loss_fp: 0.000892, loss_freq: 0.037763
[14:36:50.636] iteration 14915: loss: 0.060216, loss_s1: 0.025754, loss_fp: 0.000603, loss_freq: 0.007252
[14:36:51.256] iteration 14916: loss: 0.079464, loss_s1: 0.094699, loss_fp: 0.000637, loss_freq: 0.013808
[14:36:51.874] iteration 14917: loss: 0.052748, loss_s1: 0.016670, loss_fp: 0.000763, loss_freq: 0.003251
[14:36:52.496] iteration 14918: loss: 0.072530, loss_s1: 0.059803, loss_fp: 0.000600, loss_freq: 0.044254
[14:36:53.125] iteration 14919: loss: 0.072587, loss_s1: 0.052594, loss_fp: 0.002227, loss_freq: 0.043171
[14:36:53.779] iteration 14920: loss: 0.082677, loss_s1: 0.078635, loss_fp: 0.001262, loss_freq: 0.012156
[14:36:54.441] iteration 14921: loss: 0.045576, loss_s1: 0.023663, loss_fp: 0.003458, loss_freq: 0.021290
[14:36:55.080] iteration 14922: loss: 0.040593, loss_s1: 0.014860, loss_fp: 0.005337, loss_freq: 0.014848
[14:36:55.716] iteration 14923: loss: 0.046312, loss_s1: 0.031978, loss_fp: 0.009068, loss_freq: 0.004895
[14:36:56.343] iteration 14924: loss: 0.067357, loss_s1: 0.032089, loss_fp: 0.000851, loss_freq: 0.040897
[14:36:56.991] iteration 14925: loss: 0.041961, loss_s1: 0.022834, loss_fp: 0.002110, loss_freq: 0.015537
[14:36:57.649] iteration 14926: loss: 0.052239, loss_s1: 0.031036, loss_fp: 0.001747, loss_freq: 0.016829
[14:36:58.307] iteration 14927: loss: 0.054016, loss_s1: 0.055732, loss_fp: 0.001207, loss_freq: 0.009991
[14:36:58.948] iteration 14928: loss: 0.040977, loss_s1: 0.021421, loss_fp: 0.001518, loss_freq: 0.006853
[14:36:59.571] iteration 14929: loss: 0.049786, loss_s1: 0.045782, loss_fp: 0.001213, loss_freq: 0.011554
[14:37:00.198] iteration 14930: loss: 0.042424, loss_s1: 0.030327, loss_fp: 0.001852, loss_freq: 0.010707
[14:37:00.827] iteration 14931: loss: 0.085254, loss_s1: 0.054068, loss_fp: 0.001297, loss_freq: 0.055208
[14:37:01.446] iteration 14932: loss: 0.063246, loss_s1: 0.053238, loss_fp: 0.001262, loss_freq: 0.020136
[14:37:02.069] iteration 14933: loss: 0.051974, loss_s1: 0.026775, loss_fp: 0.005562, loss_freq: 0.017273
[14:37:02.703] iteration 14934: loss: 0.065084, loss_s1: 0.046578, loss_fp: 0.010270, loss_freq: 0.019046
[14:37:03.330] iteration 14935: loss: 0.090577, loss_s1: 0.043684, loss_fp: 0.005137, loss_freq: 0.073672
[14:37:03.957] iteration 14936: loss: 0.070214, loss_s1: 0.030110, loss_fp: 0.004468, loss_freq: 0.022340
[14:37:04.579] iteration 14937: loss: 0.077665, loss_s1: 0.035810, loss_fp: 0.026451, loss_freq: 0.025237
[14:37:05.208] iteration 14938: loss: 0.057992, loss_s1: 0.026109, loss_fp: 0.001323, loss_freq: 0.019846
[14:37:05.850] iteration 14939: loss: 0.090739, loss_s1: 0.034161, loss_fp: 0.008781, loss_freq: 0.074760
[14:37:06.474] iteration 14940: loss: 0.039784, loss_s1: 0.020271, loss_fp: 0.001358, loss_freq: 0.020313
[14:37:07.107] iteration 14941: loss: 0.072585, loss_s1: 0.084580, loss_fp: 0.002917, loss_freq: 0.015758
[14:37:07.742] iteration 14942: loss: 0.065166, loss_s1: 0.040995, loss_fp: 0.005025, loss_freq: 0.012398
[14:37:08.363] iteration 14943: loss: 0.062051, loss_s1: 0.048252, loss_fp: 0.004371, loss_freq: 0.032598
[14:37:08.987] iteration 14944: loss: 0.059228, loss_s1: 0.039244, loss_fp: 0.003944, loss_freq: 0.017932
[14:37:09.613] iteration 14945: loss: 0.076140, loss_s1: 0.064441, loss_fp: 0.001792, loss_freq: 0.039777
[14:37:10.251] iteration 14946: loss: 0.093337, loss_s1: 0.061391, loss_fp: 0.015693, loss_freq: 0.024677
[14:37:10.886] iteration 14947: loss: 0.081016, loss_s1: 0.056601, loss_fp: 0.006604, loss_freq: 0.064083
[14:37:11.514] iteration 14948: loss: 0.092643, loss_s1: 0.042321, loss_fp: 0.002211, loss_freq: 0.011032
[14:37:12.141] iteration 14949: loss: 0.053221, loss_s1: 0.052140, loss_fp: 0.007570, loss_freq: 0.011517
[14:37:12.768] iteration 14950: loss: 0.052022, loss_s1: 0.032704, loss_fp: 0.000584, loss_freq: 0.010505
[14:37:13.398] iteration 14951: loss: 0.078053, loss_s1: 0.052776, loss_fp: 0.003070, loss_freq: 0.054838
[14:37:14.029] iteration 14952: loss: 0.153395, loss_s1: 0.106983, loss_fp: 0.002606, loss_freq: 0.044330
[14:37:14.662] iteration 14953: loss: 0.074478, loss_s1: 0.026482, loss_fp: 0.006630, loss_freq: 0.043141
[14:37:15.293] iteration 14954: loss: 0.077164, loss_s1: 0.097202, loss_fp: 0.002336, loss_freq: 0.010133
[14:37:15.927] iteration 14955: loss: 0.066658, loss_s1: 0.043898, loss_fp: 0.003413, loss_freq: 0.034707
[14:37:16.556] iteration 14956: loss: 0.048972, loss_s1: 0.028246, loss_fp: 0.001863, loss_freq: 0.021024
[14:37:17.189] iteration 14957: loss: 0.053063, loss_s1: 0.049853, loss_fp: 0.002214, loss_freq: 0.012172
[14:37:17.876] iteration 14958: loss: 0.061955, loss_s1: 0.037067, loss_fp: 0.001247, loss_freq: 0.038525
[14:37:18.554] iteration 14959: loss: 0.049012, loss_s1: 0.050833, loss_fp: 0.001399, loss_freq: 0.005154
[14:37:19.229] iteration 14960: loss: 0.049386, loss_s1: 0.027797, loss_fp: 0.005327, loss_freq: 0.026734
[14:37:19.902] iteration 14961: loss: 0.042916, loss_s1: 0.032104, loss_fp: 0.001602, loss_freq: 0.012205
[14:37:20.585] iteration 14962: loss: 0.068001, loss_s1: 0.046173, loss_fp: 0.004065, loss_freq: 0.023634
[14:37:21.215] iteration 14963: loss: 0.093136, loss_s1: 0.071174, loss_fp: 0.011685, loss_freq: 0.037861
[14:37:21.875] iteration 14964: loss: 0.062143, loss_s1: 0.045678, loss_fp: 0.004114, loss_freq: 0.030634
[14:37:22.519] iteration 14965: loss: 0.041174, loss_s1: 0.030385, loss_fp: 0.002363, loss_freq: 0.005935
[14:37:23.150] iteration 14966: loss: 0.036624, loss_s1: 0.022163, loss_fp: 0.003147, loss_freq: 0.006214
[14:37:23.780] iteration 14967: loss: 0.030789, loss_s1: 0.008707, loss_fp: 0.001759, loss_freq: 0.007026
[14:37:24.420] iteration 14968: loss: 0.033989, loss_s1: 0.013525, loss_fp: 0.002200, loss_freq: 0.009396
[14:37:25.059] iteration 14969: loss: 0.121428, loss_s1: 0.055726, loss_fp: 0.006306, loss_freq: 0.093167
[14:37:25.734] iteration 14970: loss: 0.057994, loss_s1: 0.028089, loss_fp: 0.002456, loss_freq: 0.031351
[14:37:26.398] iteration 14971: loss: 0.063839, loss_s1: 0.028900, loss_fp: 0.002737, loss_freq: 0.028315
[14:37:27.087] iteration 14972: loss: 0.067906, loss_s1: 0.027463, loss_fp: 0.003378, loss_freq: 0.042302
[14:37:27.774] iteration 14973: loss: 0.062724, loss_s1: 0.050558, loss_fp: 0.001759, loss_freq: 0.024102
[14:37:28.457] iteration 14974: loss: 0.059240, loss_s1: 0.027225, loss_fp: 0.001780, loss_freq: 0.035982
[14:37:29.150] iteration 14975: loss: 0.100322, loss_s1: 0.095423, loss_fp: 0.006083, loss_freq: 0.051668
[14:37:29.827] iteration 14976: loss: 0.046482, loss_s1: 0.036681, loss_fp: 0.008045, loss_freq: 0.007382
[14:37:30.479] iteration 14977: loss: 0.061438, loss_s1: 0.036033, loss_fp: 0.005654, loss_freq: 0.016305
[14:37:31.130] iteration 14978: loss: 0.051371, loss_s1: 0.019837, loss_fp: 0.000847, loss_freq: 0.024856
[14:37:31.783] iteration 14979: loss: 0.088977, loss_s1: 0.078454, loss_fp: 0.001732, loss_freq: 0.049610
[14:37:32.416] iteration 14980: loss: 0.059788, loss_s1: 0.065821, loss_fp: 0.002226, loss_freq: 0.015186
[14:37:33.056] iteration 14981: loss: 0.083060, loss_s1: 0.051979, loss_fp: 0.001708, loss_freq: 0.018621
[14:37:33.696] iteration 14982: loss: 0.065447, loss_s1: 0.059190, loss_fp: 0.013530, loss_freq: 0.024495
[14:37:34.321] iteration 14983: loss: 0.055371, loss_s1: 0.032440, loss_fp: 0.002322, loss_freq: 0.009074
[14:37:34.947] iteration 14984: loss: 0.060644, loss_s1: 0.026859, loss_fp: 0.006290, loss_freq: 0.052859
[14:37:35.573] iteration 14985: loss: 0.074627, loss_s1: 0.054745, loss_fp: 0.003001, loss_freq: 0.008000
[14:37:36.231] iteration 14986: loss: 0.071272, loss_s1: 0.054865, loss_fp: 0.021860, loss_freq: 0.023338
[14:37:36.907] iteration 14987: loss: 0.111514, loss_s1: 0.060232, loss_fp: 0.000909, loss_freq: 0.052919
[14:37:37.567] iteration 14988: loss: 0.064048, loss_s1: 0.067543, loss_fp: 0.001680, loss_freq: 0.006845
[14:37:38.198] iteration 14989: loss: 0.071415, loss_s1: 0.026414, loss_fp: 0.003196, loss_freq: 0.043903
[14:37:38.822] iteration 14990: loss: 0.091428, loss_s1: 0.122902, loss_fp: 0.001344, loss_freq: 0.017748
[14:37:39.491] iteration 14991: loss: 0.083341, loss_s1: 0.088785, loss_fp: 0.002869, loss_freq: 0.029128
[14:37:40.141] iteration 14992: loss: 0.068151, loss_s1: 0.046321, loss_fp: 0.002968, loss_freq: 0.032751
[14:37:40.776] iteration 14993: loss: 0.060964, loss_s1: 0.033799, loss_fp: 0.004388, loss_freq: 0.028702
[14:37:41.409] iteration 14994: loss: 0.047996, loss_s1: 0.009361, loss_fp: 0.001073, loss_freq: 0.026390
[14:37:42.041] iteration 14995: loss: 0.048848, loss_s1: 0.045534, loss_fp: 0.004495, loss_freq: 0.003023
[14:37:42.681] iteration 14996: loss: 0.046038, loss_s1: 0.014371, loss_fp: 0.001386, loss_freq: 0.038030
[14:37:43.317] iteration 14997: loss: 0.048463, loss_s1: 0.044798, loss_fp: 0.002898, loss_freq: 0.014635
[14:37:43.967] iteration 14998: loss: 0.063324, loss_s1: 0.020557, loss_fp: 0.004162, loss_freq: 0.016794
[14:37:44.624] iteration 14999: loss: 0.074041, loss_s1: 0.040491, loss_fp: 0.000339, loss_freq: 0.029486
[14:37:45.287] iteration 15000: loss: 0.057040, loss_s1: 0.035665, loss_fp: 0.010358, loss_freq: 0.025105
[14:37:48.946] iteration 15000 : mean_dice : 0.771132
[14:37:49.620] iteration 15001: loss: 0.054062, loss_s1: 0.041207, loss_fp: 0.002192, loss_freq: 0.021705
[14:37:50.273] iteration 15002: loss: 0.051914, loss_s1: 0.030551, loss_fp: 0.003613, loss_freq: 0.012599
[14:37:50.923] iteration 15003: loss: 0.045396, loss_s1: 0.017576, loss_fp: 0.002128, loss_freq: 0.021639
[14:37:51.579] iteration 15004: loss: 0.079578, loss_s1: 0.047285, loss_fp: 0.010002, loss_freq: 0.052932
[14:37:52.208] iteration 15005: loss: 0.053910, loss_s1: 0.039125, loss_fp: 0.004565, loss_freq: 0.013974
[14:37:52.828] iteration 15006: loss: 0.067708, loss_s1: 0.036766, loss_fp: 0.001991, loss_freq: 0.036230
[14:37:53.454] iteration 15007: loss: 0.087906, loss_s1: 0.046296, loss_fp: 0.001153, loss_freq: 0.068868
[14:37:54.077] iteration 15008: loss: 0.072334, loss_s1: 0.063458, loss_fp: 0.002778, loss_freq: 0.034815
[14:37:54.706] iteration 15009: loss: 0.055292, loss_s1: 0.031297, loss_fp: 0.002794, loss_freq: 0.018742
[14:37:55.364] iteration 15010: loss: 0.036415, loss_s1: 0.018270, loss_fp: 0.004362, loss_freq: 0.010649
[14:37:56.040] iteration 15011: loss: 0.050506, loss_s1: 0.026092, loss_fp: 0.002811, loss_freq: 0.019656
[14:37:56.741] iteration 15012: loss: 0.069478, loss_s1: 0.054692, loss_fp: 0.017271, loss_freq: 0.012936
[14:37:57.360] iteration 15013: loss: 0.068711, loss_s1: 0.047376, loss_fp: 0.003442, loss_freq: 0.043620
[14:37:57.982] iteration 15014: loss: 0.108528, loss_s1: 0.114585, loss_fp: 0.008315, loss_freq: 0.049568
[14:37:58.608] iteration 15015: loss: 0.098674, loss_s1: 0.038700, loss_fp: 0.013464, loss_freq: 0.072433
[14:37:59.556] iteration 15016: loss: 0.050477, loss_s1: 0.034920, loss_fp: 0.006227, loss_freq: 0.010681
[14:38:00.220] iteration 15017: loss: 0.068109, loss_s1: 0.049661, loss_fp: 0.003773, loss_freq: 0.024544
[14:38:00.843] iteration 15018: loss: 0.036830, loss_s1: 0.012643, loss_fp: 0.000630, loss_freq: 0.024806
[14:38:01.475] iteration 15019: loss: 0.089389, loss_s1: 0.053431, loss_fp: 0.000578, loss_freq: 0.023804
[14:38:02.107] iteration 15020: loss: 0.083284, loss_s1: 0.048293, loss_fp: 0.001044, loss_freq: 0.029130
[14:38:02.730] iteration 15021: loss: 0.072939, loss_s1: 0.017907, loss_fp: 0.000910, loss_freq: 0.006641
[14:38:03.360] iteration 15022: loss: 0.034008, loss_s1: 0.020146, loss_fp: 0.002807, loss_freq: 0.005882
[14:38:03.994] iteration 15023: loss: 0.086702, loss_s1: 0.036718, loss_fp: 0.014746, loss_freq: 0.037123
[14:38:04.618] iteration 15024: loss: 0.080365, loss_s1: 0.054444, loss_fp: 0.003268, loss_freq: 0.035720
[14:38:05.258] iteration 15025: loss: 0.070792, loss_s1: 0.025306, loss_fp: 0.000685, loss_freq: 0.030074
[14:38:05.884] iteration 15026: loss: 0.070160, loss_s1: 0.043347, loss_fp: 0.003273, loss_freq: 0.034081
[14:38:06.520] iteration 15027: loss: 0.066148, loss_s1: 0.025063, loss_fp: 0.002735, loss_freq: 0.053055
[14:38:07.141] iteration 15028: loss: 0.072602, loss_s1: 0.068573, loss_fp: 0.002038, loss_freq: 0.026188
[14:38:07.758] iteration 15029: loss: 0.067758, loss_s1: 0.035729, loss_fp: 0.001304, loss_freq: 0.011443
[14:38:08.391] iteration 15030: loss: 0.076700, loss_s1: 0.066336, loss_fp: 0.001261, loss_freq: 0.044950
[14:38:09.023] iteration 15031: loss: 0.044938, loss_s1: 0.033291, loss_fp: 0.001385, loss_freq: 0.009852
[14:38:09.647] iteration 15032: loss: 0.051425, loss_s1: 0.011302, loss_fp: 0.001667, loss_freq: 0.012177
[14:38:10.280] iteration 15033: loss: 0.064391, loss_s1: 0.024413, loss_fp: 0.005246, loss_freq: 0.013868
[14:38:10.905] iteration 15034: loss: 0.051254, loss_s1: 0.030377, loss_fp: 0.002688, loss_freq: 0.029960
[14:38:11.531] iteration 15035: loss: 0.082927, loss_s1: 0.063115, loss_fp: 0.000420, loss_freq: 0.017042
[14:38:12.149] iteration 15036: loss: 0.084878, loss_s1: 0.031012, loss_fp: 0.001164, loss_freq: 0.058151
[14:38:12.769] iteration 15037: loss: 0.073703, loss_s1: 0.042330, loss_fp: 0.001008, loss_freq: 0.028182
[14:38:13.395] iteration 15038: loss: 0.072716, loss_s1: 0.040576, loss_fp: 0.002305, loss_freq: 0.054876
[14:38:14.025] iteration 15039: loss: 0.064276, loss_s1: 0.040231, loss_fp: 0.001018, loss_freq: 0.011687
[14:38:14.653] iteration 15040: loss: 0.055774, loss_s1: 0.035898, loss_fp: 0.002470, loss_freq: 0.030199
[14:38:15.291] iteration 15041: loss: 0.085577, loss_s1: 0.068717, loss_fp: 0.009894, loss_freq: 0.038082
[14:38:15.924] iteration 15042: loss: 0.078979, loss_s1: 0.044403, loss_fp: 0.008484, loss_freq: 0.057262
[14:38:16.561] iteration 15043: loss: 0.069397, loss_s1: 0.046603, loss_fp: 0.003133, loss_freq: 0.015782
[14:38:17.186] iteration 15044: loss: 0.063397, loss_s1: 0.022981, loss_fp: 0.003949, loss_freq: 0.027984
[14:38:17.816] iteration 15045: loss: 0.060805, loss_s1: 0.024753, loss_fp: 0.003724, loss_freq: 0.019604
[14:38:18.444] iteration 15046: loss: 0.049454, loss_s1: 0.033216, loss_fp: 0.001602, loss_freq: 0.022662
[14:38:19.105] iteration 15047: loss: 0.073083, loss_s1: 0.032392, loss_fp: 0.004753, loss_freq: 0.029991
[14:38:19.765] iteration 15048: loss: 0.067002, loss_s1: 0.056711, loss_fp: 0.009312, loss_freq: 0.033032
[14:38:20.421] iteration 15049: loss: 0.092590, loss_s1: 0.056383, loss_fp: 0.003742, loss_freq: 0.081887
[14:38:21.080] iteration 15050: loss: 0.083548, loss_s1: 0.042109, loss_fp: 0.007441, loss_freq: 0.028048
[14:38:21.737] iteration 15051: loss: 0.057811, loss_s1: 0.042892, loss_fp: 0.004867, loss_freq: 0.013667
[14:38:22.393] iteration 15052: loss: 0.072910, loss_s1: 0.059226, loss_fp: 0.003006, loss_freq: 0.017828
[14:38:23.022] iteration 15053: loss: 0.076592, loss_s1: 0.042574, loss_fp: 0.002419, loss_freq: 0.066686
[14:38:23.639] iteration 15054: loss: 0.093456, loss_s1: 0.056093, loss_fp: 0.001975, loss_freq: 0.069313
[14:38:24.263] iteration 15055: loss: 0.042505, loss_s1: 0.034072, loss_fp: 0.004389, loss_freq: 0.009980
[14:38:24.885] iteration 15056: loss: 0.084411, loss_s1: 0.054364, loss_fp: 0.006929, loss_freq: 0.019837
[14:38:25.516] iteration 15057: loss: 0.056300, loss_s1: 0.041163, loss_fp: 0.001487, loss_freq: 0.018044
[14:38:26.135] iteration 15058: loss: 0.073442, loss_s1: 0.031571, loss_fp: 0.008574, loss_freq: 0.024992
[14:38:26.759] iteration 15059: loss: 0.077374, loss_s1: 0.065690, loss_fp: 0.006259, loss_freq: 0.036993
[14:38:27.382] iteration 15060: loss: 0.077895, loss_s1: 0.052105, loss_fp: 0.000949, loss_freq: 0.017233
[14:38:28.014] iteration 15061: loss: 0.061556, loss_s1: 0.042786, loss_fp: 0.000574, loss_freq: 0.030613
[14:38:28.672] iteration 15062: loss: 0.054107, loss_s1: 0.026002, loss_fp: 0.001583, loss_freq: 0.034691
[14:38:29.298] iteration 15063: loss: 0.045486, loss_s1: 0.015327, loss_fp: 0.003413, loss_freq: 0.021623
[14:38:29.919] iteration 15064: loss: 0.042307, loss_s1: 0.025620, loss_fp: 0.001927, loss_freq: 0.014871
[14:38:30.543] iteration 15065: loss: 0.057503, loss_s1: 0.034776, loss_fp: 0.002131, loss_freq: 0.019712
[14:38:31.175] iteration 15066: loss: 0.081727, loss_s1: 0.071464, loss_fp: 0.012356, loss_freq: 0.027001
[14:38:31.799] iteration 15067: loss: 0.074676, loss_s1: 0.009247, loss_fp: 0.003251, loss_freq: 0.043860
[14:38:32.430] iteration 15068: loss: 0.038179, loss_s1: 0.021878, loss_fp: 0.000881, loss_freq: 0.010349
[14:38:33.055] iteration 15069: loss: 0.045637, loss_s1: 0.020376, loss_fp: 0.005899, loss_freq: 0.020773
[14:38:33.689] iteration 15070: loss: 0.058766, loss_s1: 0.075009, loss_fp: 0.001088, loss_freq: 0.006514
[14:38:34.317] iteration 15071: loss: 0.069509, loss_s1: 0.034619, loss_fp: 0.001629, loss_freq: 0.009097
[14:38:34.937] iteration 15072: loss: 0.079679, loss_s1: 0.065886, loss_fp: 0.011468, loss_freq: 0.029742
[14:38:35.564] iteration 15073: loss: 0.056990, loss_s1: 0.036579, loss_fp: 0.007419, loss_freq: 0.018135
[14:38:36.191] iteration 15074: loss: 0.076658, loss_s1: 0.052694, loss_fp: 0.001104, loss_freq: 0.045774
[14:38:36.820] iteration 15075: loss: 0.089600, loss_s1: 0.082513, loss_fp: 0.003769, loss_freq: 0.040977
[14:38:37.448] iteration 15076: loss: 0.044309, loss_s1: 0.025283, loss_fp: 0.004141, loss_freq: 0.010958
[14:38:38.078] iteration 15077: loss: 0.068413, loss_s1: 0.069559, loss_fp: 0.006085, loss_freq: 0.014098
[14:38:38.712] iteration 15078: loss: 0.097754, loss_s1: 0.094442, loss_fp: 0.001580, loss_freq: 0.037933
[14:38:39.342] iteration 15079: loss: 0.076621, loss_s1: 0.061193, loss_fp: 0.003740, loss_freq: 0.022884
[14:38:39.968] iteration 15080: loss: 0.073716, loss_s1: 0.029781, loss_fp: 0.003840, loss_freq: 0.064233
[14:38:40.626] iteration 15081: loss: 0.046667, loss_s1: 0.026674, loss_fp: 0.002617, loss_freq: 0.019337
[14:38:41.284] iteration 15082: loss: 0.110792, loss_s1: 0.065598, loss_fp: 0.007653, loss_freq: 0.063461
[14:38:41.943] iteration 15083: loss: 0.040761, loss_s1: 0.013040, loss_fp: 0.001237, loss_freq: 0.025415
[14:38:42.573] iteration 15084: loss: 0.040889, loss_s1: 0.028408, loss_fp: 0.000490, loss_freq: 0.010176
[14:38:43.200] iteration 15085: loss: 0.074846, loss_s1: 0.013820, loss_fp: 0.003745, loss_freq: 0.006258
[14:38:43.822] iteration 15086: loss: 0.054776, loss_s1: 0.032956, loss_fp: 0.001057, loss_freq: 0.019127
[14:38:44.447] iteration 15087: loss: 0.065356, loss_s1: 0.027320, loss_fp: 0.002510, loss_freq: 0.035426
[14:38:45.080] iteration 15088: loss: 0.075882, loss_s1: 0.050235, loss_fp: 0.007318, loss_freq: 0.049840
[14:38:45.711] iteration 15089: loss: 0.082263, loss_s1: 0.062806, loss_fp: 0.013929, loss_freq: 0.020893
[14:38:46.365] iteration 15090: loss: 0.072451, loss_s1: 0.060021, loss_fp: 0.004827, loss_freq: 0.038321
[14:38:46.990] iteration 15091: loss: 0.047462, loss_s1: 0.034950, loss_fp: 0.001481, loss_freq: 0.011104
[14:38:47.614] iteration 15092: loss: 0.043895, loss_s1: 0.030390, loss_fp: 0.000723, loss_freq: 0.023196
[14:38:48.263] iteration 15093: loss: 0.070539, loss_s1: 0.042274, loss_fp: 0.001528, loss_freq: 0.022304
[14:38:48.886] iteration 15094: loss: 0.091961, loss_s1: 0.067255, loss_fp: 0.003945, loss_freq: 0.049469
[14:38:49.510] iteration 15095: loss: 0.170681, loss_s1: 0.087772, loss_fp: 0.004071, loss_freq: 0.069076
[14:38:50.141] iteration 15096: loss: 0.054768, loss_s1: 0.020315, loss_fp: 0.005011, loss_freq: 0.016289
[14:38:50.766] iteration 15097: loss: 0.084960, loss_s1: 0.052330, loss_fp: 0.004741, loss_freq: 0.033315
[14:38:51.442] iteration 15098: loss: 0.062168, loss_s1: 0.032940, loss_fp: 0.002058, loss_freq: 0.032808
[14:38:52.097] iteration 15099: loss: 0.061260, loss_s1: 0.060369, loss_fp: 0.001939, loss_freq: 0.017797
[14:38:52.750] iteration 15100: loss: 0.054331, loss_s1: 0.027234, loss_fp: 0.002180, loss_freq: 0.020114
[14:38:53.401] iteration 15101: loss: 0.059736, loss_s1: 0.007492, loss_fp: 0.011437, loss_freq: 0.050411
[14:38:54.026] iteration 15102: loss: 0.050834, loss_s1: 0.026946, loss_fp: 0.002172, loss_freq: 0.017647
[14:38:54.641] iteration 15103: loss: 0.048730, loss_s1: 0.010890, loss_fp: 0.000391, loss_freq: 0.023331
[14:38:55.268] iteration 15104: loss: 0.061404, loss_s1: 0.054916, loss_fp: 0.008391, loss_freq: 0.005841
[14:38:55.890] iteration 15105: loss: 0.050343, loss_s1: 0.042947, loss_fp: 0.000904, loss_freq: 0.023734
[14:38:56.515] iteration 15106: loss: 0.065888, loss_s1: 0.026804, loss_fp: 0.003167, loss_freq: 0.018334
[14:38:57.152] iteration 15107: loss: 0.058431, loss_s1: 0.052281, loss_fp: 0.001877, loss_freq: 0.020591
[14:38:57.784] iteration 15108: loss: 0.056250, loss_s1: 0.044492, loss_fp: 0.002348, loss_freq: 0.016050
[14:38:58.412] iteration 15109: loss: 0.052441, loss_s1: 0.020159, loss_fp: 0.008099, loss_freq: 0.014436
[14:38:59.043] iteration 15110: loss: 0.055657, loss_s1: 0.036104, loss_fp: 0.000956, loss_freq: 0.028239
[14:38:59.671] iteration 15111: loss: 0.032209, loss_s1: 0.010857, loss_fp: 0.000458, loss_freq: 0.007143
[14:39:00.300] iteration 15112: loss: 0.074572, loss_s1: 0.026198, loss_fp: 0.001452, loss_freq: 0.065306
[14:39:00.925] iteration 15113: loss: 0.045583, loss_s1: 0.023240, loss_fp: 0.002699, loss_freq: 0.018543
[14:39:01.557] iteration 15114: loss: 0.066505, loss_s1: 0.016090, loss_fp: 0.004194, loss_freq: 0.043766
[14:39:02.178] iteration 15115: loss: 0.079341, loss_s1: 0.036531, loss_fp: 0.003972, loss_freq: 0.027885
[14:39:02.799] iteration 15116: loss: 0.096600, loss_s1: 0.074946, loss_fp: 0.003392, loss_freq: 0.020437
[14:39:03.423] iteration 15117: loss: 0.070996, loss_s1: 0.065084, loss_fp: 0.000688, loss_freq: 0.015030
[14:39:04.048] iteration 15118: loss: 0.082079, loss_s1: 0.104073, loss_fp: 0.002841, loss_freq: 0.007542
[14:39:04.671] iteration 15119: loss: 0.071616, loss_s1: 0.053569, loss_fp: 0.000301, loss_freq: 0.047221
[14:39:05.296] iteration 15120: loss: 0.051117, loss_s1: 0.024203, loss_fp: 0.000636, loss_freq: 0.011023
[14:39:05.926] iteration 15121: loss: 0.044489, loss_s1: 0.010268, loss_fp: 0.002130, loss_freq: 0.025996
[14:39:06.553] iteration 15122: loss: 0.126165, loss_s1: 0.097693, loss_fp: 0.015828, loss_freq: 0.082623
[14:39:07.176] iteration 15123: loss: 0.070037, loss_s1: 0.018761, loss_fp: 0.007173, loss_freq: 0.067944
[14:39:07.803] iteration 15124: loss: 0.052090, loss_s1: 0.026195, loss_fp: 0.003355, loss_freq: 0.020509
[14:39:08.432] iteration 15125: loss: 0.076335, loss_s1: 0.073091, loss_fp: 0.013703, loss_freq: 0.026798
[14:39:09.060] iteration 15126: loss: 0.060159, loss_s1: 0.025048, loss_fp: 0.000933, loss_freq: 0.011112
[14:39:09.678] iteration 15127: loss: 0.065544, loss_s1: 0.057349, loss_fp: 0.004629, loss_freq: 0.037327
[14:39:10.298] iteration 15128: loss: 0.051752, loss_s1: 0.028521, loss_fp: 0.001912, loss_freq: 0.010398
[14:39:10.920] iteration 15129: loss: 0.123286, loss_s1: 0.070618, loss_fp: 0.051137, loss_freq: 0.075193
[14:39:11.539] iteration 15130: loss: 0.057395, loss_s1: 0.034512, loss_fp: 0.003571, loss_freq: 0.013108
[14:39:12.215] iteration 15131: loss: 0.048034, loss_s1: 0.029442, loss_fp: 0.001710, loss_freq: 0.011922
[14:39:12.884] iteration 15132: loss: 0.089121, loss_s1: 0.061244, loss_fp: 0.000837, loss_freq: 0.060806
[14:39:13.564] iteration 15133: loss: 0.121724, loss_s1: 0.147839, loss_fp: 0.003113, loss_freq: 0.046702
[14:39:14.239] iteration 15134: loss: 0.032751, loss_s1: 0.024561, loss_fp: 0.002496, loss_freq: 0.002684
[14:39:14.872] iteration 15135: loss: 0.050941, loss_s1: 0.023976, loss_fp: 0.002668, loss_freq: 0.024403
[14:39:15.505] iteration 15136: loss: 0.110124, loss_s1: 0.112920, loss_fp: 0.011683, loss_freq: 0.049333
[14:39:16.139] iteration 15137: loss: 0.074232, loss_s1: 0.065358, loss_fp: 0.004561, loss_freq: 0.012790
[14:39:16.772] iteration 15138: loss: 0.060286, loss_s1: 0.042821, loss_fp: 0.001642, loss_freq: 0.038974
[14:39:17.403] iteration 15139: loss: 0.077640, loss_s1: 0.053635, loss_fp: 0.011369, loss_freq: 0.052025
[14:39:18.025] iteration 15140: loss: 0.035001, loss_s1: 0.020129, loss_fp: 0.002263, loss_freq: 0.013417
[14:39:18.694] iteration 15141: loss: 0.112601, loss_s1: 0.060296, loss_fp: 0.002267, loss_freq: 0.031167
[14:39:19.358] iteration 15142: loss: 0.048068, loss_s1: 0.014138, loss_fp: 0.000484, loss_freq: 0.027543
[14:39:20.015] iteration 15143: loss: 0.063426, loss_s1: 0.044381, loss_fp: 0.002781, loss_freq: 0.028928
[14:39:20.687] iteration 15144: loss: 0.085040, loss_s1: 0.058538, loss_fp: 0.005581, loss_freq: 0.011809
[14:39:21.331] iteration 15145: loss: 0.051862, loss_s1: 0.035951, loss_fp: 0.003830, loss_freq: 0.023601
[14:39:21.966] iteration 15146: loss: 0.056887, loss_s1: 0.025581, loss_fp: 0.012373, loss_freq: 0.018960
[14:39:22.601] iteration 15147: loss: 0.081552, loss_s1: 0.029291, loss_fp: 0.015768, loss_freq: 0.046177
[14:39:23.243] iteration 15148: loss: 0.066314, loss_s1: 0.046688, loss_fp: 0.004493, loss_freq: 0.020762
[14:39:23.911] iteration 15149: loss: 0.102134, loss_s1: 0.045432, loss_fp: 0.000835, loss_freq: 0.065247
[14:39:24.585] iteration 15150: loss: 0.069827, loss_s1: 0.033215, loss_fp: 0.006675, loss_freq: 0.050796
[14:39:25.220] iteration 15151: loss: 0.088203, loss_s1: 0.063706, loss_fp: 0.016339, loss_freq: 0.036148
[14:39:25.850] iteration 15152: loss: 0.061764, loss_s1: 0.021447, loss_fp: 0.003817, loss_freq: 0.023206
[14:39:26.488] iteration 15153: loss: 0.047345, loss_s1: 0.009978, loss_fp: 0.004378, loss_freq: 0.015843
[14:39:27.126] iteration 15154: loss: 0.042701, loss_s1: 0.021394, loss_fp: 0.000524, loss_freq: 0.017577
[14:39:27.754] iteration 15155: loss: 0.063188, loss_s1: 0.029276, loss_fp: 0.001873, loss_freq: 0.012322
[14:39:28.392] iteration 15156: loss: 0.090855, loss_s1: 0.079831, loss_fp: 0.004670, loss_freq: 0.053419
[14:39:29.011] iteration 15157: loss: 0.095318, loss_s1: 0.060300, loss_fp: 0.007172, loss_freq: 0.074551
[14:39:29.638] iteration 15158: loss: 0.057237, loss_s1: 0.061888, loss_fp: 0.001902, loss_freq: 0.016320
[14:39:30.580] iteration 15159: loss: 0.047337, loss_s1: 0.024344, loss_fp: 0.001602, loss_freq: 0.024574
[14:39:31.201] iteration 15160: loss: 0.068242, loss_s1: 0.043288, loss_fp: 0.005172, loss_freq: 0.024374
[14:39:31.826] iteration 15161: loss: 0.042634, loss_s1: 0.023122, loss_fp: 0.001902, loss_freq: 0.028256
[14:39:32.453] iteration 15162: loss: 0.074741, loss_s1: 0.039777, loss_fp: 0.008218, loss_freq: 0.030942
[14:39:33.082] iteration 15163: loss: 0.073275, loss_s1: 0.054742, loss_fp: 0.000847, loss_freq: 0.051681
[14:39:33.712] iteration 15164: loss: 0.085799, loss_s1: 0.019132, loss_fp: 0.000855, loss_freq: 0.018909
[14:39:34.345] iteration 15165: loss: 0.066736, loss_s1: 0.077347, loss_fp: 0.004208, loss_freq: 0.016991
[14:39:34.963] iteration 15166: loss: 0.068980, loss_s1: 0.022070, loss_fp: 0.005326, loss_freq: 0.033840
[14:39:35.626] iteration 15167: loss: 0.091649, loss_s1: 0.097480, loss_fp: 0.005275, loss_freq: 0.023966
[14:39:36.284] iteration 15168: loss: 0.068848, loss_s1: 0.010801, loss_fp: 0.002611, loss_freq: 0.007352
[14:39:36.929] iteration 15169: loss: 0.068411, loss_s1: 0.034986, loss_fp: 0.001855, loss_freq: 0.046997
[14:39:37.556] iteration 15170: loss: 0.044038, loss_s1: 0.021714, loss_fp: 0.001074, loss_freq: 0.009407
[14:39:38.186] iteration 15171: loss: 0.123212, loss_s1: 0.088723, loss_fp: 0.002873, loss_freq: 0.041806
[14:39:38.856] iteration 15172: loss: 0.059532, loss_s1: 0.032881, loss_fp: 0.001338, loss_freq: 0.014883
[14:39:39.476] iteration 15173: loss: 0.077541, loss_s1: 0.067453, loss_fp: 0.009745, loss_freq: 0.022140
[14:39:40.099] iteration 15174: loss: 0.052363, loss_s1: 0.021185, loss_fp: 0.000735, loss_freq: 0.020741
[14:39:40.729] iteration 15175: loss: 0.094845, loss_s1: 0.020681, loss_fp: 0.000691, loss_freq: 0.024230
[14:39:41.359] iteration 15176: loss: 0.103486, loss_s1: 0.037297, loss_fp: 0.000823, loss_freq: 0.010038
[14:39:41.981] iteration 15177: loss: 0.058940, loss_s1: 0.039902, loss_fp: 0.000317, loss_freq: 0.031740
[14:39:42.606] iteration 15178: loss: 0.050220, loss_s1: 0.045366, loss_fp: 0.003533, loss_freq: 0.022687
[14:39:43.235] iteration 15179: loss: 0.094324, loss_s1: 0.025228, loss_fp: 0.000550, loss_freq: 0.062757
[14:39:43.863] iteration 15180: loss: 0.046464, loss_s1: 0.032572, loss_fp: 0.001444, loss_freq: 0.014609
[14:39:44.490] iteration 15181: loss: 0.075704, loss_s1: 0.020375, loss_fp: 0.000896, loss_freq: 0.076229
[14:39:45.120] iteration 15182: loss: 0.041603, loss_s1: 0.021728, loss_fp: 0.005394, loss_freq: 0.013285
[14:39:45.752] iteration 15183: loss: 0.049474, loss_s1: 0.034215, loss_fp: 0.002903, loss_freq: 0.018670
[14:39:46.390] iteration 15184: loss: 0.062346, loss_s1: 0.043081, loss_fp: 0.005207, loss_freq: 0.028353
[14:39:47.061] iteration 15185: loss: 0.074624, loss_s1: 0.038897, loss_fp: 0.005697, loss_freq: 0.046772
[14:39:47.719] iteration 15186: loss: 0.033760, loss_s1: 0.010473, loss_fp: 0.004291, loss_freq: 0.003439
[14:39:48.374] iteration 15187: loss: 0.066464, loss_s1: 0.037740, loss_fp: 0.000653, loss_freq: 0.033028
[14:39:49.014] iteration 15188: loss: 0.075025, loss_s1: 0.024257, loss_fp: 0.000654, loss_freq: 0.005566
[14:39:49.633] iteration 15189: loss: 0.062715, loss_s1: 0.031440, loss_fp: 0.002191, loss_freq: 0.026678
[14:39:50.255] iteration 15190: loss: 0.068162, loss_s1: 0.052532, loss_fp: 0.003897, loss_freq: 0.021336
[14:39:50.880] iteration 15191: loss: 0.061805, loss_s1: 0.049546, loss_fp: 0.003926, loss_freq: 0.027107
[14:39:51.514] iteration 15192: loss: 0.107955, loss_s1: 0.089888, loss_fp: 0.005001, loss_freq: 0.073458
[14:39:52.147] iteration 15193: loss: 0.087336, loss_s1: 0.063262, loss_fp: 0.003013, loss_freq: 0.028727
[14:39:52.772] iteration 15194: loss: 0.064370, loss_s1: 0.030313, loss_fp: 0.002794, loss_freq: 0.042393
[14:39:53.401] iteration 15195: loss: 0.082214, loss_s1: 0.034225, loss_fp: 0.003294, loss_freq: 0.049396
[14:39:54.032] iteration 15196: loss: 0.079208, loss_s1: 0.051981, loss_fp: 0.004929, loss_freq: 0.065116
[14:39:54.659] iteration 15197: loss: 0.084455, loss_s1: 0.052986, loss_fp: 0.010095, loss_freq: 0.048900
[14:39:55.290] iteration 15198: loss: 0.071663, loss_s1: 0.040969, loss_fp: 0.005287, loss_freq: 0.029818
[14:39:55.923] iteration 15199: loss: 0.112321, loss_s1: 0.048338, loss_fp: 0.005872, loss_freq: 0.060152
[14:39:56.592] iteration 15200: loss: 0.066335, loss_s1: 0.045143, loss_fp: 0.004309, loss_freq: 0.033217
[14:40:00.173] iteration 15200 : mean_dice : 0.776589
[14:40:01.019] iteration 15201: loss: 0.067966, loss_s1: 0.019401, loss_fp: 0.001640, loss_freq: 0.019127
[14:40:01.929] iteration 15202: loss: 0.081118, loss_s1: 0.043221, loss_fp: 0.005435, loss_freq: 0.026774
[14:40:02.556] iteration 15203: loss: 0.084949, loss_s1: 0.039800, loss_fp: 0.000858, loss_freq: 0.043827
[14:40:03.177] iteration 15204: loss: 0.098493, loss_s1: 0.045259, loss_fp: 0.009017, loss_freq: 0.075023
[14:40:03.796] iteration 15205: loss: 0.056436, loss_s1: 0.019293, loss_fp: 0.003961, loss_freq: 0.030023
[14:40:04.424] iteration 15206: loss: 0.051603, loss_s1: 0.026860, loss_fp: 0.000834, loss_freq: 0.031422
[14:40:05.066] iteration 15207: loss: 0.064868, loss_s1: 0.043895, loss_fp: 0.002754, loss_freq: 0.036623
[14:40:05.693] iteration 15208: loss: 0.044946, loss_s1: 0.026356, loss_fp: 0.000860, loss_freq: 0.016948
[14:40:06.332] iteration 15209: loss: 0.062785, loss_s1: 0.033683, loss_fp: 0.001115, loss_freq: 0.012360
[14:40:06.963] iteration 15210: loss: 0.105811, loss_s1: 0.045968, loss_fp: 0.004227, loss_freq: 0.027587
[14:40:07.589] iteration 15211: loss: 0.041189, loss_s1: 0.034629, loss_fp: 0.001317, loss_freq: 0.003337
[14:40:08.253] iteration 15212: loss: 0.054732, loss_s1: 0.061228, loss_fp: 0.000503, loss_freq: 0.008898
[14:40:08.896] iteration 15213: loss: 0.039689, loss_s1: 0.030276, loss_fp: 0.001563, loss_freq: 0.010902
[14:40:09.532] iteration 15214: loss: 0.074045, loss_s1: 0.037513, loss_fp: 0.002541, loss_freq: 0.009187
[14:40:10.176] iteration 15215: loss: 0.067612, loss_s1: 0.040668, loss_fp: 0.001092, loss_freq: 0.047702
[14:40:10.844] iteration 15216: loss: 0.046839, loss_s1: 0.037449, loss_fp: 0.001414, loss_freq: 0.008035
[14:40:11.482] iteration 15217: loss: 0.086913, loss_s1: 0.042284, loss_fp: 0.000501, loss_freq: 0.032171
[14:40:12.126] iteration 15218: loss: 0.079760, loss_s1: 0.073712, loss_fp: 0.007375, loss_freq: 0.026957
[14:40:12.795] iteration 15219: loss: 0.101743, loss_s1: 0.041741, loss_fp: 0.003246, loss_freq: 0.011438
[14:40:13.463] iteration 15220: loss: 0.066207, loss_s1: 0.035617, loss_fp: 0.001145, loss_freq: 0.021157
[14:40:14.130] iteration 15221: loss: 0.082748, loss_s1: 0.055197, loss_fp: 0.004720, loss_freq: 0.019145
[14:40:14.801] iteration 15222: loss: 0.085403, loss_s1: 0.029387, loss_fp: 0.000934, loss_freq: 0.027859
[14:40:15.468] iteration 15223: loss: 0.051354, loss_s1: 0.021414, loss_fp: 0.004072, loss_freq: 0.017699
[14:40:16.126] iteration 15224: loss: 0.068896, loss_s1: 0.037466, loss_fp: 0.006041, loss_freq: 0.015129
[14:40:16.791] iteration 15225: loss: 0.078194, loss_s1: 0.051312, loss_fp: 0.006505, loss_freq: 0.030180
[14:40:17.420] iteration 15226: loss: 0.053456, loss_s1: 0.034224, loss_fp: 0.006086, loss_freq: 0.011056
[14:40:18.083] iteration 15227: loss: 0.064648, loss_s1: 0.045412, loss_fp: 0.009574, loss_freq: 0.029612
[14:40:18.759] iteration 15228: loss: 0.077819, loss_s1: 0.029703, loss_fp: 0.007057, loss_freq: 0.033224
[14:40:19.423] iteration 15229: loss: 0.072969, loss_s1: 0.039505, loss_fp: 0.004277, loss_freq: 0.032398
[14:40:20.063] iteration 15230: loss: 0.082511, loss_s1: 0.079813, loss_fp: 0.005079, loss_freq: 0.034720
[14:40:20.688] iteration 15231: loss: 0.075096, loss_s1: 0.077185, loss_fp: 0.001596, loss_freq: 0.036724
[14:40:21.377] iteration 15232: loss: 0.070780, loss_s1: 0.049591, loss_fp: 0.004061, loss_freq: 0.018469
[14:40:22.077] iteration 15233: loss: 0.069567, loss_s1: 0.042600, loss_fp: 0.003919, loss_freq: 0.029278
[14:40:22.699] iteration 15234: loss: 0.066012, loss_s1: 0.024993, loss_fp: 0.001856, loss_freq: 0.008642
[14:40:23.335] iteration 15235: loss: 0.067472, loss_s1: 0.060041, loss_fp: 0.017618, loss_freq: 0.010001
[14:40:23.965] iteration 15236: loss: 0.045977, loss_s1: 0.028024, loss_fp: 0.000350, loss_freq: 0.006184
[14:40:24.597] iteration 15237: loss: 0.081417, loss_s1: 0.063141, loss_fp: 0.009435, loss_freq: 0.030034
[14:40:25.237] iteration 15238: loss: 0.102084, loss_s1: 0.065932, loss_fp: 0.004039, loss_freq: 0.027590
[14:40:25.877] iteration 15239: loss: 0.081854, loss_s1: 0.077315, loss_fp: 0.001227, loss_freq: 0.041181
[14:40:26.512] iteration 15240: loss: 0.076498, loss_s1: 0.058741, loss_fp: 0.004594, loss_freq: 0.039414
[14:40:27.150] iteration 15241: loss: 0.050275, loss_s1: 0.026700, loss_fp: 0.000999, loss_freq: 0.014630
[14:40:27.775] iteration 15242: loss: 0.047521, loss_s1: 0.036340, loss_fp: 0.002933, loss_freq: 0.018559
[14:40:28.409] iteration 15243: loss: 0.063088, loss_s1: 0.057844, loss_fp: 0.002652, loss_freq: 0.009851
[14:40:29.030] iteration 15244: loss: 0.070373, loss_s1: 0.058021, loss_fp: 0.003544, loss_freq: 0.025691
[14:40:29.657] iteration 15245: loss: 0.095946, loss_s1: 0.021269, loss_fp: 0.004411, loss_freq: 0.013356
[14:40:30.289] iteration 15246: loss: 0.036741, loss_s1: 0.016980, loss_fp: 0.003162, loss_freq: 0.012396
[14:40:30.913] iteration 15247: loss: 0.054580, loss_s1: 0.016768, loss_fp: 0.002562, loss_freq: 0.015257
[14:40:31.547] iteration 15248: loss: 0.058291, loss_s1: 0.044893, loss_fp: 0.009713, loss_freq: 0.012181
[14:40:32.180] iteration 15249: loss: 0.061517, loss_s1: 0.027951, loss_fp: 0.000739, loss_freq: 0.017477
[14:40:32.816] iteration 15250: loss: 0.054205, loss_s1: 0.031329, loss_fp: 0.002243, loss_freq: 0.027295
[14:40:33.446] iteration 15251: loss: 0.054375, loss_s1: 0.033612, loss_fp: 0.007816, loss_freq: 0.009333
[14:40:34.074] iteration 15252: loss: 0.087187, loss_s1: 0.075988, loss_fp: 0.007901, loss_freq: 0.016570
[14:40:34.704] iteration 15253: loss: 0.049419, loss_s1: 0.037774, loss_fp: 0.003217, loss_freq: 0.007406
[14:40:35.336] iteration 15254: loss: 0.056522, loss_s1: 0.038115, loss_fp: 0.002537, loss_freq: 0.005808
[14:40:35.973] iteration 15255: loss: 0.119906, loss_s1: 0.098625, loss_fp: 0.006348, loss_freq: 0.080640
[14:40:36.606] iteration 15256: loss: 0.051499, loss_s1: 0.034829, loss_fp: 0.001313, loss_freq: 0.022385
[14:40:37.234] iteration 15257: loss: 0.059909, loss_s1: 0.039830, loss_fp: 0.008098, loss_freq: 0.013703
[14:40:37.867] iteration 15258: loss: 0.081997, loss_s1: 0.060569, loss_fp: 0.002823, loss_freq: 0.024221
[14:40:38.499] iteration 15259: loss: 0.070074, loss_s1: 0.024269, loss_fp: 0.009354, loss_freq: 0.060267
[14:40:39.160] iteration 15260: loss: 0.086590, loss_s1: 0.034971, loss_fp: 0.005773, loss_freq: 0.041513
[14:40:39.870] iteration 15261: loss: 0.079005, loss_s1: 0.084787, loss_fp: 0.001470, loss_freq: 0.036944
[14:40:40.546] iteration 15262: loss: 0.049047, loss_s1: 0.030225, loss_fp: 0.005429, loss_freq: 0.017807
[14:40:41.222] iteration 15263: loss: 0.065203, loss_s1: 0.045978, loss_fp: 0.002895, loss_freq: 0.013607
[14:40:41.885] iteration 15264: loss: 0.062356, loss_s1: 0.030322, loss_fp: 0.001961, loss_freq: 0.031419
[14:40:42.584] iteration 15265: loss: 0.093586, loss_s1: 0.041357, loss_fp: 0.003802, loss_freq: 0.084167
[14:40:43.240] iteration 15266: loss: 0.039889, loss_s1: 0.019770, loss_fp: 0.007893, loss_freq: 0.020613
[14:40:43.903] iteration 15267: loss: 0.058610, loss_s1: 0.024503, loss_fp: 0.003650, loss_freq: 0.034530
[14:40:44.550] iteration 15268: loss: 0.059783, loss_s1: 0.043581, loss_fp: 0.005923, loss_freq: 0.021495
[14:40:45.180] iteration 15269: loss: 0.068566, loss_s1: 0.007967, loss_fp: 0.001039, loss_freq: 0.033293
[14:40:45.804] iteration 15270: loss: 0.064624, loss_s1: 0.052196, loss_fp: 0.002843, loss_freq: 0.034172
[14:40:46.435] iteration 15271: loss: 0.060131, loss_s1: 0.055450, loss_fp: 0.000650, loss_freq: 0.007480
[14:40:47.066] iteration 15272: loss: 0.068082, loss_s1: 0.029263, loss_fp: 0.007756, loss_freq: 0.041944
[14:40:47.703] iteration 15273: loss: 0.127141, loss_s1: 0.153620, loss_fp: 0.008821, loss_freq: 0.017753
[14:40:48.322] iteration 15274: loss: 0.042229, loss_s1: 0.009070, loss_fp: 0.001513, loss_freq: 0.016787
[14:40:48.948] iteration 15275: loss: 0.070740, loss_s1: 0.045116, loss_fp: 0.006582, loss_freq: 0.031339
[14:40:49.582] iteration 15276: loss: 0.059138, loss_s1: 0.057290, loss_fp: 0.004985, loss_freq: 0.012882
[14:40:50.240] iteration 15277: loss: 0.027055, loss_s1: 0.012484, loss_fp: 0.001053, loss_freq: 0.002684
[14:40:50.902] iteration 15278: loss: 0.072858, loss_s1: 0.057724, loss_fp: 0.008115, loss_freq: 0.033189
[14:40:51.522] iteration 15279: loss: 0.057103, loss_s1: 0.021757, loss_fp: 0.001747, loss_freq: 0.043648
[14:40:52.148] iteration 15280: loss: 0.101664, loss_s1: 0.018725, loss_fp: 0.004551, loss_freq: 0.013718
[14:40:52.778] iteration 15281: loss: 0.030766, loss_s1: 0.007012, loss_fp: 0.000748, loss_freq: 0.005211
[14:40:53.400] iteration 15282: loss: 0.054944, loss_s1: 0.035188, loss_fp: 0.004831, loss_freq: 0.032487
[14:40:54.030] iteration 15283: loss: 0.044318, loss_s1: 0.023695, loss_fp: 0.002357, loss_freq: 0.021663
[14:40:54.657] iteration 15284: loss: 0.081551, loss_s1: 0.062059, loss_fp: 0.003874, loss_freq: 0.017243
[14:40:55.288] iteration 15285: loss: 0.076206, loss_s1: 0.087477, loss_fp: 0.000988, loss_freq: 0.032284
[14:40:55.922] iteration 15286: loss: 0.042751, loss_s1: 0.027939, loss_fp: 0.001663, loss_freq: 0.020371
[14:40:56.551] iteration 15287: loss: 0.087817, loss_s1: 0.102337, loss_fp: 0.003804, loss_freq: 0.019601
[14:40:57.184] iteration 15288: loss: 0.049197, loss_s1: 0.027166, loss_fp: 0.002738, loss_freq: 0.008874
[14:40:57.808] iteration 15289: loss: 0.050527, loss_s1: 0.030750, loss_fp: 0.001268, loss_freq: 0.008272
[14:40:58.438] iteration 15290: loss: 0.077209, loss_s1: 0.068777, loss_fp: 0.005259, loss_freq: 0.027679
[14:40:59.063] iteration 15291: loss: 0.080536, loss_s1: 0.046554, loss_fp: 0.001654, loss_freq: 0.059706
[14:40:59.683] iteration 15292: loss: 0.101859, loss_s1: 0.033661, loss_fp: 0.001922, loss_freq: 0.083120
[14:41:00.333] iteration 15293: loss: 0.074984, loss_s1: 0.021746, loss_fp: 0.002632, loss_freq: 0.031708
[14:41:00.993] iteration 15294: loss: 0.067232, loss_s1: 0.063619, loss_fp: 0.007290, loss_freq: 0.014680
[14:41:01.651] iteration 15295: loss: 0.079809, loss_s1: 0.052145, loss_fp: 0.009378, loss_freq: 0.032562
[14:41:02.310] iteration 15296: loss: 0.051903, loss_s1: 0.032169, loss_fp: 0.000810, loss_freq: 0.024746
[14:41:02.936] iteration 15297: loss: 0.051227, loss_s1: 0.041912, loss_fp: 0.005434, loss_freq: 0.009097
[14:41:03.561] iteration 15298: loss: 0.079953, loss_s1: 0.063761, loss_fp: 0.004435, loss_freq: 0.009674
[14:41:04.219] iteration 15299: loss: 0.066313, loss_s1: 0.049997, loss_fp: 0.006414, loss_freq: 0.031069
[14:41:04.843] iteration 15300: loss: 0.074488, loss_s1: 0.069148, loss_fp: 0.007094, loss_freq: 0.022559
[14:41:05.464] iteration 15301: loss: 0.045959, loss_s1: 0.038645, loss_fp: 0.002196, loss_freq: 0.014511
[14:41:06.413] iteration 15302: loss: 0.047075, loss_s1: 0.021840, loss_fp: 0.001435, loss_freq: 0.013825
[14:41:07.038] iteration 15303: loss: 0.086005, loss_s1: 0.087274, loss_fp: 0.001728, loss_freq: 0.028633
[14:41:07.659] iteration 15304: loss: 0.041746, loss_s1: 0.010056, loss_fp: 0.002277, loss_freq: 0.017378
[14:41:08.286] iteration 15305: loss: 0.079399, loss_s1: 0.053245, loss_fp: 0.001522, loss_freq: 0.035925
[14:41:08.914] iteration 15306: loss: 0.077519, loss_s1: 0.051790, loss_fp: 0.004271, loss_freq: 0.056899
[14:41:09.536] iteration 15307: loss: 0.063057, loss_s1: 0.018590, loss_fp: 0.001930, loss_freq: 0.008057
[14:41:10.160] iteration 15308: loss: 0.040273, loss_s1: 0.023976, loss_fp: 0.001520, loss_freq: 0.019385
[14:41:10.824] iteration 15309: loss: 0.065779, loss_s1: 0.026815, loss_fp: 0.001215, loss_freq: 0.045421
[14:41:11.475] iteration 15310: loss: 0.052740, loss_s1: 0.028275, loss_fp: 0.003989, loss_freq: 0.026400
[14:41:12.132] iteration 15311: loss: 0.074291, loss_s1: 0.050551, loss_fp: 0.001423, loss_freq: 0.016592
[14:41:12.767] iteration 15312: loss: 0.063248, loss_s1: 0.036711, loss_fp: 0.002477, loss_freq: 0.044277
[14:41:13.392] iteration 15313: loss: 0.050473, loss_s1: 0.021379, loss_fp: 0.002267, loss_freq: 0.010872
[14:41:14.033] iteration 15314: loss: 0.069973, loss_s1: 0.074300, loss_fp: 0.000533, loss_freq: 0.014901
[14:41:14.666] iteration 15315: loss: 0.032658, loss_s1: 0.023607, loss_fp: 0.001213, loss_freq: 0.006328
[14:41:15.294] iteration 15316: loss: 0.097374, loss_s1: 0.071232, loss_fp: 0.003660, loss_freq: 0.072858
[14:41:15.923] iteration 15317: loss: 0.042971, loss_s1: 0.024587, loss_fp: 0.001970, loss_freq: 0.012404
[14:41:16.556] iteration 15318: loss: 0.048066, loss_s1: 0.011632, loss_fp: 0.001176, loss_freq: 0.037262
[14:41:17.180] iteration 15319: loss: 0.055597, loss_s1: 0.053546, loss_fp: 0.004698, loss_freq: 0.016441
[14:41:17.802] iteration 15320: loss: 0.049560, loss_s1: 0.037607, loss_fp: 0.002340, loss_freq: 0.022853
[14:41:18.421] iteration 15321: loss: 0.051334, loss_s1: 0.027813, loss_fp: 0.005137, loss_freq: 0.036334
[14:41:19.038] iteration 15322: loss: 0.083098, loss_s1: 0.029315, loss_fp: 0.001102, loss_freq: 0.055950
[14:41:19.661] iteration 15323: loss: 0.057548, loss_s1: 0.056004, loss_fp: 0.001399, loss_freq: 0.014888
[14:41:20.286] iteration 15324: loss: 0.054640, loss_s1: 0.021782, loss_fp: 0.001850, loss_freq: 0.030819
[14:41:20.904] iteration 15325: loss: 0.077050, loss_s1: 0.062651, loss_fp: 0.000555, loss_freq: 0.020418
[14:41:21.527] iteration 15326: loss: 0.059335, loss_s1: 0.037862, loss_fp: 0.001646, loss_freq: 0.024929
[14:41:22.152] iteration 15327: loss: 0.069971, loss_s1: 0.042144, loss_fp: 0.004635, loss_freq: 0.041381
[14:41:22.777] iteration 15328: loss: 0.138597, loss_s1: 0.077990, loss_fp: 0.005606, loss_freq: 0.086289
[14:41:23.410] iteration 15329: loss: 0.047922, loss_s1: 0.034118, loss_fp: 0.003055, loss_freq: 0.007568
[14:41:24.025] iteration 15330: loss: 0.086643, loss_s1: 0.052170, loss_fp: 0.005551, loss_freq: 0.058339
[14:41:24.648] iteration 15331: loss: 0.056820, loss_s1: 0.042953, loss_fp: 0.001268, loss_freq: 0.008248
[14:41:25.269] iteration 15332: loss: 0.048439, loss_s1: 0.037976, loss_fp: 0.001582, loss_freq: 0.006559
[14:41:25.908] iteration 15333: loss: 0.072997, loss_s1: 0.055408, loss_fp: 0.008924, loss_freq: 0.029063
[14:41:26.549] iteration 15334: loss: 0.068967, loss_s1: 0.049794, loss_fp: 0.006190, loss_freq: 0.032496
[14:41:27.194] iteration 15335: loss: 0.102826, loss_s1: 0.093010, loss_fp: 0.006843, loss_freq: 0.053340
[14:41:27.840] iteration 15336: loss: 0.064360, loss_s1: 0.040806, loss_fp: 0.005304, loss_freq: 0.029130
[14:41:28.468] iteration 15337: loss: 0.114147, loss_s1: 0.107168, loss_fp: 0.009015, loss_freq: 0.043102
[14:41:29.096] iteration 15338: loss: 0.077170, loss_s1: 0.037170, loss_fp: 0.013481, loss_freq: 0.038503
[14:41:29.716] iteration 15339: loss: 0.052136, loss_s1: 0.022952, loss_fp: 0.005296, loss_freq: 0.042796
[14:41:30.340] iteration 15340: loss: 0.114940, loss_s1: 0.045291, loss_fp: 0.012629, loss_freq: 0.083845
[14:41:30.970] iteration 15341: loss: 0.048630, loss_s1: 0.045938, loss_fp: 0.002212, loss_freq: 0.004900
[14:41:31.600] iteration 15342: loss: 0.040929, loss_s1: 0.017563, loss_fp: 0.001113, loss_freq: 0.016358
[14:41:32.235] iteration 15343: loss: 0.056003, loss_s1: 0.045968, loss_fp: 0.001729, loss_freq: 0.029577
[14:41:32.855] iteration 15344: loss: 0.044062, loss_s1: 0.010219, loss_fp: 0.001574, loss_freq: 0.011859
[14:41:33.483] iteration 15345: loss: 0.083211, loss_s1: 0.060983, loss_fp: 0.002553, loss_freq: 0.054484
[14:41:34.115] iteration 15346: loss: 0.092707, loss_s1: 0.097310, loss_fp: 0.004696, loss_freq: 0.011198
[14:41:34.742] iteration 15347: loss: 0.101891, loss_s1: 0.050224, loss_fp: 0.001815, loss_freq: 0.077386
[14:41:35.370] iteration 15348: loss: 0.069073, loss_s1: 0.021650, loss_fp: 0.009129, loss_freq: 0.040241
[14:41:35.999] iteration 15349: loss: 0.061662, loss_s1: 0.043793, loss_fp: 0.001991, loss_freq: 0.017925
[14:41:36.628] iteration 15350: loss: 0.057001, loss_s1: 0.061479, loss_fp: 0.005424, loss_freq: 0.013046
[14:41:37.259] iteration 15351: loss: 0.047205, loss_s1: 0.030412, loss_fp: 0.002703, loss_freq: 0.016197
[14:41:37.881] iteration 15352: loss: 0.045537, loss_s1: 0.017917, loss_fp: 0.003905, loss_freq: 0.017161
[14:41:38.536] iteration 15353: loss: 0.072814, loss_s1: 0.037911, loss_fp: 0.004035, loss_freq: 0.041070
[14:41:39.156] iteration 15354: loss: 0.043458, loss_s1: 0.020575, loss_fp: 0.001382, loss_freq: 0.012397
[14:41:39.787] iteration 15355: loss: 0.046844, loss_s1: 0.027059, loss_fp: 0.002427, loss_freq: 0.021815
[14:41:40.415] iteration 15356: loss: 0.079392, loss_s1: 0.016523, loss_fp: 0.003166, loss_freq: 0.012194
[14:41:41.042] iteration 15357: loss: 0.056764, loss_s1: 0.033855, loss_fp: 0.006695, loss_freq: 0.017617
[14:41:41.665] iteration 15358: loss: 0.059092, loss_s1: 0.045135, loss_fp: 0.001507, loss_freq: 0.029982
[14:41:42.288] iteration 15359: loss: 0.048992, loss_s1: 0.031501, loss_fp: 0.002267, loss_freq: 0.023080
[14:41:42.908] iteration 15360: loss: 0.081771, loss_s1: 0.046469, loss_fp: 0.002047, loss_freq: 0.055938
[14:41:43.540] iteration 15361: loss: 0.054385, loss_s1: 0.034353, loss_fp: 0.003537, loss_freq: 0.025500
[14:41:44.170] iteration 15362: loss: 0.047036, loss_s1: 0.027071, loss_fp: 0.002517, loss_freq: 0.013561
[14:41:44.792] iteration 15363: loss: 0.062867, loss_s1: 0.036480, loss_fp: 0.007148, loss_freq: 0.035477
[14:41:45.422] iteration 15364: loss: 0.087871, loss_s1: 0.092938, loss_fp: 0.002985, loss_freq: 0.038903
[14:41:46.041] iteration 15365: loss: 0.048369, loss_s1: 0.023550, loss_fp: 0.001916, loss_freq: 0.020680
[14:41:46.662] iteration 15366: loss: 0.073462, loss_s1: 0.066942, loss_fp: 0.004268, loss_freq: 0.019607
[14:41:47.286] iteration 15367: loss: 0.054987, loss_s1: 0.039985, loss_fp: 0.001987, loss_freq: 0.028074
[14:41:47.917] iteration 15368: loss: 0.132045, loss_s1: 0.058304, loss_fp: 0.004808, loss_freq: 0.100955
[14:41:48.542] iteration 15369: loss: 0.038403, loss_s1: 0.019472, loss_fp: 0.003473, loss_freq: 0.011330
[14:41:49.171] iteration 15370: loss: 0.052753, loss_s1: 0.027552, loss_fp: 0.001276, loss_freq: 0.018221
[14:41:49.798] iteration 15371: loss: 0.128426, loss_s1: 0.113166, loss_fp: 0.001520, loss_freq: 0.012863
[14:41:50.426] iteration 15372: loss: 0.055821, loss_s1: 0.025889, loss_fp: 0.003416, loss_freq: 0.027716
[14:41:51.055] iteration 15373: loss: 0.070143, loss_s1: 0.026110, loss_fp: 0.002629, loss_freq: 0.059383
[14:41:51.682] iteration 15374: loss: 0.051287, loss_s1: 0.037158, loss_fp: 0.001734, loss_freq: 0.022533
[14:41:52.309] iteration 15375: loss: 0.092647, loss_s1: 0.070831, loss_fp: 0.014306, loss_freq: 0.054156
[14:41:53.002] iteration 15376: loss: 0.080614, loss_s1: 0.069534, loss_fp: 0.001291, loss_freq: 0.049184
[14:41:53.658] iteration 15377: loss: 0.084736, loss_s1: 0.042224, loss_fp: 0.003352, loss_freq: 0.010648
[14:41:54.325] iteration 15378: loss: 0.049625, loss_s1: 0.034111, loss_fp: 0.002756, loss_freq: 0.025040
[14:41:54.996] iteration 15379: loss: 0.056886, loss_s1: 0.029271, loss_fp: 0.001568, loss_freq: 0.015976
[14:41:55.657] iteration 15380: loss: 0.107909, loss_s1: 0.100201, loss_fp: 0.030149, loss_freq: 0.020698
[14:41:56.320] iteration 15381: loss: 0.073258, loss_s1: 0.026991, loss_fp: 0.003254, loss_freq: 0.016574
[14:41:56.994] iteration 15382: loss: 0.059363, loss_s1: 0.038147, loss_fp: 0.001280, loss_freq: 0.032863
[14:41:57.665] iteration 15383: loss: 0.073683, loss_s1: 0.071378, loss_fp: 0.011310, loss_freq: 0.016645
[14:41:58.315] iteration 15384: loss: 0.042925, loss_s1: 0.025069, loss_fp: 0.001230, loss_freq: 0.004723
[14:41:58.945] iteration 15385: loss: 0.065528, loss_s1: 0.053753, loss_fp: 0.008588, loss_freq: 0.028258
[14:41:59.628] iteration 15386: loss: 0.065353, loss_s1: 0.060770, loss_fp: 0.002043, loss_freq: 0.009788
[14:42:00.263] iteration 15387: loss: 0.063427, loss_s1: 0.027088, loss_fp: 0.006493, loss_freq: 0.051129
[14:42:00.897] iteration 15388: loss: 0.047608, loss_s1: 0.041930, loss_fp: 0.001104, loss_freq: 0.007531
[14:42:01.523] iteration 15389: loss: 0.041072, loss_s1: 0.014574, loss_fp: 0.000270, loss_freq: 0.021212
[14:42:02.155] iteration 15390: loss: 0.062498, loss_s1: 0.049376, loss_fp: 0.001614, loss_freq: 0.027543
[14:42:02.782] iteration 15391: loss: 0.052933, loss_s1: 0.044077, loss_fp: 0.001553, loss_freq: 0.016834
[14:42:03.417] iteration 15392: loss: 0.130216, loss_s1: 0.052029, loss_fp: 0.002659, loss_freq: 0.038545
[14:42:04.064] iteration 15393: loss: 0.060983, loss_s1: 0.039058, loss_fp: 0.012945, loss_freq: 0.028997
[14:42:04.742] iteration 15394: loss: 0.064405, loss_s1: 0.042821, loss_fp: 0.005269, loss_freq: 0.029980
[14:42:05.409] iteration 15395: loss: 0.074680, loss_s1: 0.062943, loss_fp: 0.000807, loss_freq: 0.009268
[14:42:06.045] iteration 15396: loss: 0.066459, loss_s1: 0.038906, loss_fp: 0.000677, loss_freq: 0.039476
[14:42:06.688] iteration 15397: loss: 0.058254, loss_s1: 0.013463, loss_fp: 0.002465, loss_freq: 0.036495
[14:42:07.313] iteration 15398: loss: 0.089445, loss_s1: 0.035598, loss_fp: 0.006206, loss_freq: 0.088373
[14:42:07.943] iteration 15399: loss: 0.091659, loss_s1: 0.088882, loss_fp: 0.007733, loss_freq: 0.032958
[14:42:08.574] iteration 15400: loss: 0.042309, loss_s1: 0.029883, loss_fp: 0.006748, loss_freq: 0.008574
[14:42:11.909] iteration 15400 : mean_dice : 0.775209
[14:42:12.572] iteration 15401: loss: 0.098781, loss_s1: 0.068097, loss_fp: 0.003545, loss_freq: 0.036485
[14:42:13.207] iteration 15402: loss: 0.054659, loss_s1: 0.035178, loss_fp: 0.000890, loss_freq: 0.007446
[14:42:13.842] iteration 15403: loss: 0.072367, loss_s1: 0.039536, loss_fp: 0.002375, loss_freq: 0.019408
[14:42:14.468] iteration 15404: loss: 0.065845, loss_s1: 0.067933, loss_fp: 0.001605, loss_freq: 0.027690
[14:42:15.088] iteration 15405: loss: 0.055688, loss_s1: 0.036751, loss_fp: 0.006045, loss_freq: 0.030883
[14:42:15.723] iteration 15406: loss: 0.055980, loss_s1: 0.040719, loss_fp: 0.004877, loss_freq: 0.017756
[14:42:16.355] iteration 15407: loss: 0.042516, loss_s1: 0.011290, loss_fp: 0.002528, loss_freq: 0.020513
[14:42:16.983] iteration 15408: loss: 0.136234, loss_s1: 0.112808, loss_fp: 0.000813, loss_freq: 0.095874
[14:42:17.620] iteration 15409: loss: 0.068709, loss_s1: 0.034022, loss_fp: 0.009153, loss_freq: 0.057700
[14:42:18.255] iteration 15410: loss: 0.064598, loss_s1: 0.037777, loss_fp: 0.001883, loss_freq: 0.017147
[14:42:18.886] iteration 15411: loss: 0.044231, loss_s1: 0.042820, loss_fp: 0.002008, loss_freq: 0.010517
[14:42:19.516] iteration 15412: loss: 0.039226, loss_s1: 0.023113, loss_fp: 0.002581, loss_freq: 0.009807
[14:42:20.153] iteration 15413: loss: 0.060521, loss_s1: 0.046925, loss_fp: 0.002985, loss_freq: 0.040119
[14:42:20.781] iteration 15414: loss: 0.037842, loss_s1: 0.014974, loss_fp: 0.001159, loss_freq: 0.008410
[14:42:21.413] iteration 15415: loss: 0.054767, loss_s1: 0.026393, loss_fp: 0.018742, loss_freq: 0.019859
[14:42:22.044] iteration 15416: loss: 0.082362, loss_s1: 0.025674, loss_fp: 0.008201, loss_freq: 0.036680
[14:42:22.695] iteration 15417: loss: 0.074836, loss_s1: 0.080871, loss_fp: 0.001147, loss_freq: 0.012127
[14:42:23.322] iteration 15418: loss: 0.063981, loss_s1: 0.045365, loss_fp: 0.002432, loss_freq: 0.036108
[14:42:24.062] iteration 15419: loss: 0.089402, loss_s1: 0.076281, loss_fp: 0.001417, loss_freq: 0.043281
[14:42:24.695] iteration 15420: loss: 0.078286, loss_s1: 0.098921, loss_fp: 0.000927, loss_freq: 0.020713
[14:42:25.330] iteration 15421: loss: 0.065086, loss_s1: 0.032576, loss_fp: 0.001981, loss_freq: 0.040170
[14:42:25.961] iteration 15422: loss: 0.087327, loss_s1: 0.065022, loss_fp: 0.002864, loss_freq: 0.051385
[14:42:26.584] iteration 15423: loss: 0.056934, loss_s1: 0.047657, loss_fp: 0.000963, loss_freq: 0.014372
[14:42:27.201] iteration 15424: loss: 0.048753, loss_s1: 0.016947, loss_fp: 0.000362, loss_freq: 0.004366
[14:42:27.822] iteration 15425: loss: 0.037894, loss_s1: 0.022971, loss_fp: 0.001810, loss_freq: 0.012105
[14:42:28.446] iteration 15426: loss: 0.074447, loss_s1: 0.034645, loss_fp: 0.008051, loss_freq: 0.060234
[14:42:29.075] iteration 15427: loss: 0.077064, loss_s1: 0.043360, loss_fp: 0.003756, loss_freq: 0.026429
[14:42:29.701] iteration 15428: loss: 0.052910, loss_s1: 0.020610, loss_fp: 0.003989, loss_freq: 0.027140
[14:42:30.339] iteration 15429: loss: 0.068828, loss_s1: 0.027778, loss_fp: 0.002004, loss_freq: 0.035979
[14:42:30.967] iteration 15430: loss: 0.063061, loss_s1: 0.038313, loss_fp: 0.015557, loss_freq: 0.007445
[14:42:31.597] iteration 15431: loss: 0.055546, loss_s1: 0.030834, loss_fp: 0.007660, loss_freq: 0.014082
[14:42:32.219] iteration 15432: loss: 0.068832, loss_s1: 0.036664, loss_fp: 0.003820, loss_freq: 0.029646
[14:42:32.852] iteration 15433: loss: 0.068691, loss_s1: 0.032110, loss_fp: 0.008495, loss_freq: 0.040811
[14:42:33.478] iteration 15434: loss: 0.059957, loss_s1: 0.042549, loss_fp: 0.005278, loss_freq: 0.022149
[14:42:34.106] iteration 15435: loss: 0.088111, loss_s1: 0.042212, loss_fp: 0.001516, loss_freq: 0.044233
[14:42:34.735] iteration 15436: loss: 0.087583, loss_s1: 0.076499, loss_fp: 0.005402, loss_freq: 0.022715
[14:42:35.379] iteration 15437: loss: 0.101964, loss_s1: 0.096060, loss_fp: 0.004594, loss_freq: 0.051678
[14:42:36.007] iteration 15438: loss: 0.089574, loss_s1: 0.060370, loss_fp: 0.004191, loss_freq: 0.038804
[14:42:36.669] iteration 15439: loss: 0.042451, loss_s1: 0.020820, loss_fp: 0.000349, loss_freq: 0.004767
[14:42:37.312] iteration 15440: loss: 0.057665, loss_s1: 0.044413, loss_fp: 0.001589, loss_freq: 0.019459
[14:42:37.938] iteration 15441: loss: 0.073406, loss_s1: 0.047629, loss_fp: 0.006083, loss_freq: 0.022244
[14:42:38.570] iteration 15442: loss: 0.102520, loss_s1: 0.051863, loss_fp: 0.003143, loss_freq: 0.054975
[14:42:39.195] iteration 15443: loss: 0.100813, loss_s1: 0.064072, loss_fp: 0.013556, loss_freq: 0.047851
[14:42:39.821] iteration 15444: loss: 0.052074, loss_s1: 0.048862, loss_fp: 0.001323, loss_freq: 0.014221
[14:42:40.819] iteration 15445: loss: 0.048486, loss_s1: 0.036117, loss_fp: 0.001066, loss_freq: 0.015245
[14:42:41.459] iteration 15446: loss: 0.080110, loss_s1: 0.059277, loss_fp: 0.002540, loss_freq: 0.043313
[14:42:42.101] iteration 15447: loss: 0.051921, loss_s1: 0.024801, loss_fp: 0.001096, loss_freq: 0.035721
[14:42:42.726] iteration 15448: loss: 0.072562, loss_s1: 0.058976, loss_fp: 0.002751, loss_freq: 0.016264
[14:42:43.353] iteration 15449: loss: 0.073229, loss_s1: 0.062907, loss_fp: 0.003568, loss_freq: 0.037954
[14:42:43.982] iteration 15450: loss: 0.039818, loss_s1: 0.018396, loss_fp: 0.000679, loss_freq: 0.007291
[14:42:44.620] iteration 15451: loss: 0.047578, loss_s1: 0.042639, loss_fp: 0.001639, loss_freq: 0.011981
[14:42:45.254] iteration 15452: loss: 0.063975, loss_s1: 0.049995, loss_fp: 0.001371, loss_freq: 0.015485
[14:42:45.890] iteration 15453: loss: 0.067183, loss_s1: 0.068358, loss_fp: 0.002792, loss_freq: 0.022289
[14:42:46.518] iteration 15454: loss: 0.045441, loss_s1: 0.011023, loss_fp: 0.001352, loss_freq: 0.003605
[14:42:47.149] iteration 15455: loss: 0.082710, loss_s1: 0.049144, loss_fp: 0.004306, loss_freq: 0.049251
[14:42:47.777] iteration 15456: loss: 0.046312, loss_s1: 0.026384, loss_fp: 0.003640, loss_freq: 0.012633
[14:42:48.408] iteration 15457: loss: 0.095174, loss_s1: 0.090228, loss_fp: 0.004566, loss_freq: 0.042762
[14:42:49.030] iteration 15458: loss: 0.035200, loss_s1: 0.025136, loss_fp: 0.002236, loss_freq: 0.005547
[14:42:49.708] iteration 15459: loss: 0.063795, loss_s1: 0.046909, loss_fp: 0.001128, loss_freq: 0.020870
[14:42:50.398] iteration 15460: loss: 0.045461, loss_s1: 0.016128, loss_fp: 0.003888, loss_freq: 0.022091
[14:42:51.088] iteration 15461: loss: 0.041009, loss_s1: 0.024429, loss_fp: 0.003220, loss_freq: 0.010571
[14:42:51.749] iteration 15462: loss: 0.087281, loss_s1: 0.063887, loss_fp: 0.003094, loss_freq: 0.022871
[14:42:52.404] iteration 15463: loss: 0.068556, loss_s1: 0.039776, loss_fp: 0.000764, loss_freq: 0.044293
[14:42:53.035] iteration 15464: loss: 0.033535, loss_s1: 0.022170, loss_fp: 0.006722, loss_freq: 0.007154
[14:42:53.667] iteration 15465: loss: 0.066569, loss_s1: 0.019719, loss_fp: 0.001663, loss_freq: 0.038014
[14:42:54.314] iteration 15466: loss: 0.062298, loss_s1: 0.053797, loss_fp: 0.001484, loss_freq: 0.023906
[14:42:54.949] iteration 15467: loss: 0.055030, loss_s1: 0.030057, loss_fp: 0.001256, loss_freq: 0.028564
[14:42:55.580] iteration 15468: loss: 0.047262, loss_s1: 0.036869, loss_fp: 0.002225, loss_freq: 0.014783
[14:42:56.201] iteration 15469: loss: 0.038657, loss_s1: 0.013935, loss_fp: 0.003079, loss_freq: 0.011683
[14:42:56.850] iteration 15470: loss: 0.060622, loss_s1: 0.028791, loss_fp: 0.001070, loss_freq: 0.044893
[14:42:57.470] iteration 15471: loss: 0.118396, loss_s1: 0.075472, loss_fp: 0.005854, loss_freq: 0.073979
[14:42:58.094] iteration 15472: loss: 0.066153, loss_s1: 0.077913, loss_fp: 0.002433, loss_freq: 0.010164
[14:42:58.723] iteration 15473: loss: 0.081724, loss_s1: 0.062203, loss_fp: 0.002692, loss_freq: 0.034204
[14:42:59.346] iteration 15474: loss: 0.070593, loss_s1: 0.024109, loss_fp: 0.001920, loss_freq: 0.015725
[14:42:59.976] iteration 15475: loss: 0.059508, loss_s1: 0.032180, loss_fp: 0.003097, loss_freq: 0.017494
[14:43:00.607] iteration 15476: loss: 0.088324, loss_s1: 0.046623, loss_fp: 0.009117, loss_freq: 0.028130
[14:43:01.227] iteration 15477: loss: 0.089328, loss_s1: 0.089920, loss_fp: 0.005571, loss_freq: 0.043179
[14:43:01.853] iteration 15478: loss: 0.073028, loss_s1: 0.049997, loss_fp: 0.006849, loss_freq: 0.036615
[14:43:02.472] iteration 15479: loss: 0.064753, loss_s1: 0.046050, loss_fp: 0.016881, loss_freq: 0.019540
[14:43:03.103] iteration 15480: loss: 0.105156, loss_s1: 0.072157, loss_fp: 0.004749, loss_freq: 0.076502
[14:43:03.723] iteration 15481: loss: 0.070698, loss_s1: 0.047219, loss_fp: 0.014202, loss_freq: 0.021599
[14:43:04.347] iteration 15482: loss: 0.064727, loss_s1: 0.035942, loss_fp: 0.005957, loss_freq: 0.037078
[14:43:04.970] iteration 15483: loss: 0.077546, loss_s1: 0.055735, loss_fp: 0.009968, loss_freq: 0.030501
[14:43:05.601] iteration 15484: loss: 0.060507, loss_s1: 0.041630, loss_fp: 0.003983, loss_freq: 0.023551
[14:43:06.231] iteration 15485: loss: 0.085280, loss_s1: 0.053478, loss_fp: 0.004831, loss_freq: 0.019009
[14:43:06.858] iteration 15486: loss: 0.057354, loss_s1: 0.028220, loss_fp: 0.003047, loss_freq: 0.044278
[14:43:07.499] iteration 15487: loss: 0.085278, loss_s1: 0.041723, loss_fp: 0.005557, loss_freq: 0.028296
[14:43:08.143] iteration 15488: loss: 0.062223, loss_s1: 0.033925, loss_fp: 0.012944, loss_freq: 0.025578
[14:43:08.797] iteration 15489: loss: 0.063145, loss_s1: 0.028500, loss_fp: 0.001914, loss_freq: 0.007830
[14:43:09.428] iteration 15490: loss: 0.071195, loss_s1: 0.043454, loss_fp: 0.003202, loss_freq: 0.044977
[14:43:10.059] iteration 15491: loss: 0.052448, loss_s1: 0.021197, loss_fp: 0.002067, loss_freq: 0.007712
[14:43:10.686] iteration 15492: loss: 0.061767, loss_s1: 0.051368, loss_fp: 0.001606, loss_freq: 0.025870
[14:43:11.311] iteration 15493: loss: 0.067921, loss_s1: 0.053095, loss_fp: 0.002815, loss_freq: 0.035867
[14:43:11.934] iteration 15494: loss: 0.053539, loss_s1: 0.018099, loss_fp: 0.002785, loss_freq: 0.016527
[14:43:12.578] iteration 15495: loss: 0.055486, loss_s1: 0.042194, loss_fp: 0.003537, loss_freq: 0.015446
[14:43:13.276] iteration 15496: loss: 0.054527, loss_s1: 0.014672, loss_fp: 0.001848, loss_freq: 0.022846
[14:43:13.934] iteration 15497: loss: 0.066197, loss_s1: 0.030838, loss_fp: 0.000616, loss_freq: 0.019021
[14:43:14.598] iteration 15498: loss: 0.040111, loss_s1: 0.032524, loss_fp: 0.002442, loss_freq: 0.008207
[14:43:15.254] iteration 15499: loss: 0.050405, loss_s1: 0.057140, loss_fp: 0.008305, loss_freq: 0.007556
[14:43:15.897] iteration 15500: loss: 0.035228, loss_s1: 0.008067, loss_fp: 0.001349, loss_freq: 0.012240
[14:43:16.521] iteration 15501: loss: 0.087020, loss_s1: 0.078624, loss_fp: 0.003050, loss_freq: 0.046077
[14:43:17.141] iteration 15502: loss: 0.043243, loss_s1: 0.029367, loss_fp: 0.001582, loss_freq: 0.011051
[14:43:17.766] iteration 15503: loss: 0.081240, loss_s1: 0.036435, loss_fp: 0.004596, loss_freq: 0.080601
[14:43:18.402] iteration 15504: loss: 0.060292, loss_s1: 0.037587, loss_fp: 0.003063, loss_freq: 0.026102
[14:43:19.042] iteration 15505: loss: 0.049737, loss_s1: 0.021282, loss_fp: 0.001275, loss_freq: 0.014572
[14:43:19.665] iteration 15506: loss: 0.069647, loss_s1: 0.036406, loss_fp: 0.006280, loss_freq: 0.014577
[14:43:20.291] iteration 15507: loss: 0.079533, loss_s1: 0.069620, loss_fp: 0.008652, loss_freq: 0.026889
[14:43:20.913] iteration 15508: loss: 0.065975, loss_s1: 0.030279, loss_fp: 0.001209, loss_freq: 0.014780
[14:43:21.551] iteration 15509: loss: 0.052181, loss_s1: 0.026291, loss_fp: 0.003958, loss_freq: 0.012041
[14:43:22.174] iteration 15510: loss: 0.044677, loss_s1: 0.012994, loss_fp: 0.001287, loss_freq: 0.012890
[14:43:22.803] iteration 15511: loss: 0.064585, loss_s1: 0.041336, loss_fp: 0.005777, loss_freq: 0.032976
[14:43:23.432] iteration 15512: loss: 0.037598, loss_s1: 0.017435, loss_fp: 0.003132, loss_freq: 0.016230
[14:43:24.054] iteration 15513: loss: 0.044196, loss_s1: 0.020141, loss_fp: 0.001523, loss_freq: 0.011646
[14:43:24.663] iteration 15514: loss: 0.066624, loss_s1: 0.044477, loss_fp: 0.003022, loss_freq: 0.025942
[14:43:25.281] iteration 15515: loss: 0.046538, loss_s1: 0.016579, loss_fp: 0.003518, loss_freq: 0.014590
[14:43:25.910] iteration 15516: loss: 0.071759, loss_s1: 0.057787, loss_fp: 0.001283, loss_freq: 0.041527
[14:43:26.541] iteration 15517: loss: 0.117835, loss_s1: 0.081879, loss_fp: 0.003327, loss_freq: 0.093123
[14:43:27.163] iteration 15518: loss: 0.089359, loss_s1: 0.096556, loss_fp: 0.003958, loss_freq: 0.031449
[14:43:27.794] iteration 15519: loss: 0.098272, loss_s1: 0.097634, loss_fp: 0.007592, loss_freq: 0.054124
[14:43:28.417] iteration 15520: loss: 0.058398, loss_s1: 0.037930, loss_fp: 0.003215, loss_freq: 0.018309
[14:43:29.044] iteration 15521: loss: 0.059617, loss_s1: 0.041567, loss_fp: 0.004058, loss_freq: 0.042142
[14:43:29.675] iteration 15522: loss: 0.048030, loss_s1: 0.018635, loss_fp: 0.001862, loss_freq: 0.014003
[14:43:30.301] iteration 15523: loss: 0.093802, loss_s1: 0.103782, loss_fp: 0.008254, loss_freq: 0.032720
[14:43:30.927] iteration 15524: loss: 0.079336, loss_s1: 0.050654, loss_fp: 0.008891, loss_freq: 0.035087
[14:43:31.550] iteration 15525: loss: 0.092514, loss_s1: 0.052859, loss_fp: 0.007349, loss_freq: 0.026316
[14:43:32.202] iteration 15526: loss: 0.039334, loss_s1: 0.021540, loss_fp: 0.000873, loss_freq: 0.013481
[14:43:32.830] iteration 15527: loss: 0.044442, loss_s1: 0.018704, loss_fp: 0.003523, loss_freq: 0.013834
[14:43:33.455] iteration 15528: loss: 0.060827, loss_s1: 0.042567, loss_fp: 0.005298, loss_freq: 0.037180
[14:43:34.116] iteration 15529: loss: 0.039613, loss_s1: 0.017540, loss_fp: 0.002291, loss_freq: 0.012916
[14:43:34.773] iteration 15530: loss: 0.055799, loss_s1: 0.022903, loss_fp: 0.005039, loss_freq: 0.042048
[14:43:35.437] iteration 15531: loss: 0.078584, loss_s1: 0.041298, loss_fp: 0.001873, loss_freq: 0.010332
[14:43:36.105] iteration 15532: loss: 0.051346, loss_s1: 0.025895, loss_fp: 0.000389, loss_freq: 0.020972
[14:43:36.766] iteration 15533: loss: 0.040706, loss_s1: 0.030428, loss_fp: 0.001933, loss_freq: 0.010704
[14:43:37.415] iteration 15534: loss: 0.078353, loss_s1: 0.056321, loss_fp: 0.002203, loss_freq: 0.043253
[14:43:38.067] iteration 15535: loss: 0.083687, loss_s1: 0.019152, loss_fp: 0.002871, loss_freq: 0.042575
[14:43:38.687] iteration 15536: loss: 0.057783, loss_s1: 0.037625, loss_fp: 0.001689, loss_freq: 0.038642
[14:43:39.311] iteration 15537: loss: 0.052529, loss_s1: 0.036506, loss_fp: 0.003046, loss_freq: 0.009017
[14:43:39.932] iteration 15538: loss: 0.053961, loss_s1: 0.055395, loss_fp: 0.006749, loss_freq: 0.006562
[14:43:40.560] iteration 15539: loss: 0.046068, loss_s1: 0.030265, loss_fp: 0.002258, loss_freq: 0.013083
[14:43:41.242] iteration 15540: loss: 0.050968, loss_s1: 0.033735, loss_fp: 0.002566, loss_freq: 0.004362
[14:43:41.911] iteration 15541: loss: 0.148838, loss_s1: 0.104358, loss_fp: 0.007069, loss_freq: 0.116697
[14:43:42.576] iteration 15542: loss: 0.052385, loss_s1: 0.025200, loss_fp: 0.001389, loss_freq: 0.029021
[14:43:43.247] iteration 15543: loss: 0.055051, loss_s1: 0.029317, loss_fp: 0.002572, loss_freq: 0.006313
[14:43:43.929] iteration 15544: loss: 0.073572, loss_s1: 0.055207, loss_fp: 0.012849, loss_freq: 0.021031
[14:43:44.624] iteration 15545: loss: 0.033230, loss_s1: 0.020340, loss_fp: 0.001582, loss_freq: 0.011035
[14:43:45.259] iteration 15546: loss: 0.082888, loss_s1: 0.031048, loss_fp: 0.003934, loss_freq: 0.047642
[14:43:45.897] iteration 15547: loss: 0.066647, loss_s1: 0.061813, loss_fp: 0.002344, loss_freq: 0.030419
[14:43:46.529] iteration 15548: loss: 0.050814, loss_s1: 0.027756, loss_fp: 0.003556, loss_freq: 0.029209
[14:43:47.171] iteration 15549: loss: 0.048993, loss_s1: 0.018262, loss_fp: 0.003460, loss_freq: 0.021323
[14:43:47.801] iteration 15550: loss: 0.056146, loss_s1: 0.035688, loss_fp: 0.004172, loss_freq: 0.030566
[14:43:48.438] iteration 15551: loss: 0.094515, loss_s1: 0.101866, loss_fp: 0.000645, loss_freq: 0.032391
[14:43:49.072] iteration 15552: loss: 0.118139, loss_s1: 0.063073, loss_fp: 0.006490, loss_freq: 0.125779
[14:43:49.705] iteration 15553: loss: 0.073018, loss_s1: 0.034134, loss_fp: 0.002131, loss_freq: 0.029013
[14:43:50.331] iteration 15554: loss: 0.087499, loss_s1: 0.075799, loss_fp: 0.018097, loss_freq: 0.031363
[14:43:50.966] iteration 15555: loss: 0.071948, loss_s1: 0.025737, loss_fp: 0.000580, loss_freq: 0.006709
[14:43:51.596] iteration 15556: loss: 0.056539, loss_s1: 0.044059, loss_fp: 0.000658, loss_freq: 0.037838
[14:43:52.221] iteration 15557: loss: 0.066539, loss_s1: 0.045222, loss_fp: 0.000628, loss_freq: 0.019262
[14:43:52.853] iteration 15558: loss: 0.064292, loss_s1: 0.051243, loss_fp: 0.011330, loss_freq: 0.015452
[14:43:53.481] iteration 15559: loss: 0.076000, loss_s1: 0.023402, loss_fp: 0.001044, loss_freq: 0.005160
[14:43:54.140] iteration 15560: loss: 0.047887, loss_s1: 0.023740, loss_fp: 0.001244, loss_freq: 0.014059
[14:43:54.772] iteration 15561: loss: 0.080718, loss_s1: 0.038456, loss_fp: 0.002741, loss_freq: 0.061909
[14:43:55.415] iteration 15562: loss: 0.061691, loss_s1: 0.053426, loss_fp: 0.002696, loss_freq: 0.016340
[14:43:56.067] iteration 15563: loss: 0.054360, loss_s1: 0.039291, loss_fp: 0.001123, loss_freq: 0.033126
[14:43:56.700] iteration 15564: loss: 0.051508, loss_s1: 0.030180, loss_fp: 0.002178, loss_freq: 0.027910
[14:43:57.325] iteration 15565: loss: 0.073079, loss_s1: 0.049847, loss_fp: 0.000783, loss_freq: 0.044704
[14:43:57.977] iteration 15566: loss: 0.069527, loss_s1: 0.028316, loss_fp: 0.002474, loss_freq: 0.036199
[14:43:58.649] iteration 15567: loss: 0.034606, loss_s1: 0.011693, loss_fp: 0.000829, loss_freq: 0.010065
[14:43:59.323] iteration 15568: loss: 0.048946, loss_s1: 0.044804, loss_fp: 0.003609, loss_freq: 0.017066
[14:43:59.989] iteration 15569: loss: 0.051904, loss_s1: 0.037859, loss_fp: 0.001993, loss_freq: 0.027883
[14:44:00.610] iteration 15570: loss: 0.059976, loss_s1: 0.049701, loss_fp: 0.001090, loss_freq: 0.004653
[14:44:01.241] iteration 15571: loss: 0.049191, loss_s1: 0.019620, loss_fp: 0.001937, loss_freq: 0.024028
[14:44:01.872] iteration 15572: loss: 0.059567, loss_s1: 0.024729, loss_fp: 0.001402, loss_freq: 0.049978
[14:44:02.501] iteration 15573: loss: 0.061055, loss_s1: 0.044133, loss_fp: 0.002497, loss_freq: 0.006952
[14:44:03.121] iteration 15574: loss: 0.049372, loss_s1: 0.036635, loss_fp: 0.001595, loss_freq: 0.012250
[14:44:03.755] iteration 15575: loss: 0.151582, loss_s1: 0.075002, loss_fp: 0.006581, loss_freq: 0.017318
[14:44:04.383] iteration 15576: loss: 0.070781, loss_s1: 0.032526, loss_fp: 0.007446, loss_freq: 0.023788
[14:44:05.003] iteration 15577: loss: 0.068445, loss_s1: 0.046177, loss_fp: 0.001776, loss_freq: 0.027156
[14:44:05.623] iteration 15578: loss: 0.132448, loss_s1: 0.095590, loss_fp: 0.002423, loss_freq: 0.076323
[14:44:06.261] iteration 15579: loss: 0.064115, loss_s1: 0.026469, loss_fp: 0.001296, loss_freq: 0.047122
[14:44:06.901] iteration 15580: loss: 0.075861, loss_s1: 0.055698, loss_fp: 0.004158, loss_freq: 0.051491
[14:44:07.535] iteration 15581: loss: 0.071643, loss_s1: 0.050040, loss_fp: 0.005915, loss_freq: 0.035720
[14:44:08.170] iteration 15582: loss: 0.055546, loss_s1: 0.046894, loss_fp: 0.002660, loss_freq: 0.015880
[14:44:08.812] iteration 15583: loss: 0.042467, loss_s1: 0.028990, loss_fp: 0.001904, loss_freq: 0.015545
[14:44:09.463] iteration 15584: loss: 0.072502, loss_s1: 0.049006, loss_fp: 0.006242, loss_freq: 0.019495
[14:44:10.330] iteration 15585: loss: 0.057644, loss_s1: 0.042281, loss_fp: 0.002715, loss_freq: 0.025436
[14:44:11.081] iteration 15586: loss: 0.087036, loss_s1: 0.062907, loss_fp: 0.002833, loss_freq: 0.031804
[14:44:11.778] iteration 15587: loss: 0.045511, loss_s1: 0.032330, loss_fp: 0.001848, loss_freq: 0.017659
[14:44:12.704] iteration 15588: loss: 0.058012, loss_s1: 0.037276, loss_fp: 0.004384, loss_freq: 0.023392
[14:44:13.380] iteration 15589: loss: 0.075526, loss_s1: 0.068163, loss_fp: 0.003693, loss_freq: 0.031047
[14:44:14.004] iteration 15590: loss: 0.047449, loss_s1: 0.017518, loss_fp: 0.001160, loss_freq: 0.024763
[14:44:14.638] iteration 15591: loss: 0.093683, loss_s1: 0.057237, loss_fp: 0.001672, loss_freq: 0.018526
[14:44:15.261] iteration 15592: loss: 0.069458, loss_s1: 0.054037, loss_fp: 0.001260, loss_freq: 0.043511
[14:44:15.895] iteration 15593: loss: 0.062273, loss_s1: 0.025036, loss_fp: 0.001020, loss_freq: 0.004253
[14:44:16.521] iteration 15594: loss: 0.042558, loss_s1: 0.024426, loss_fp: 0.003136, loss_freq: 0.009825
[14:44:17.139] iteration 15595: loss: 0.089605, loss_s1: 0.055418, loss_fp: 0.003627, loss_freq: 0.063127
[14:44:17.763] iteration 15596: loss: 0.040929, loss_s1: 0.014850, loss_fp: 0.001640, loss_freq: 0.017935
[14:44:18.425] iteration 15597: loss: 0.050465, loss_s1: 0.020581, loss_fp: 0.000997, loss_freq: 0.005471
[14:44:19.043] iteration 15598: loss: 0.076676, loss_s1: 0.052051, loss_fp: 0.003280, loss_freq: 0.049199
[14:44:19.655] iteration 15599: loss: 0.056379, loss_s1: 0.027444, loss_fp: 0.000695, loss_freq: 0.024932
[14:44:20.281] iteration 15600: loss: 0.066434, loss_s1: 0.055997, loss_fp: 0.003782, loss_freq: 0.015538
[14:44:23.589] iteration 15600 : mean_dice : 0.757930
[14:44:24.250] iteration 15601: loss: 0.042400, loss_s1: 0.021248, loss_fp: 0.000569, loss_freq: 0.025251
[14:44:24.883] iteration 15602: loss: 0.059327, loss_s1: 0.024411, loss_fp: 0.009090, loss_freq: 0.024388
[14:44:25.502] iteration 15603: loss: 0.040820, loss_s1: 0.025553, loss_fp: 0.001455, loss_freq: 0.008566
[14:44:26.129] iteration 15604: loss: 0.066130, loss_s1: 0.059286, loss_fp: 0.001120, loss_freq: 0.026988
[14:44:26.759] iteration 15605: loss: 0.037059, loss_s1: 0.022988, loss_fp: 0.000958, loss_freq: 0.014300
[14:44:27.399] iteration 15606: loss: 0.054358, loss_s1: 0.037802, loss_fp: 0.001633, loss_freq: 0.035092
[14:44:28.082] iteration 15607: loss: 0.039514, loss_s1: 0.022785, loss_fp: 0.002883, loss_freq: 0.013933
[14:44:28.755] iteration 15608: loss: 0.084392, loss_s1: 0.056553, loss_fp: 0.000469, loss_freq: 0.054669
[14:44:29.431] iteration 15609: loss: 0.053591, loss_s1: 0.052614, loss_fp: 0.000829, loss_freq: 0.021045
[14:44:30.100] iteration 15610: loss: 0.061318, loss_s1: 0.062331, loss_fp: 0.001447, loss_freq: 0.009825
[14:44:30.779] iteration 15611: loss: 0.044094, loss_s1: 0.036366, loss_fp: 0.002711, loss_freq: 0.013433
[14:44:31.470] iteration 15612: loss: 0.041399, loss_s1: 0.014521, loss_fp: 0.003341, loss_freq: 0.011711
[14:44:32.144] iteration 15613: loss: 0.049995, loss_s1: 0.025052, loss_fp: 0.004930, loss_freq: 0.010455
[14:44:32.772] iteration 15614: loss: 0.072565, loss_s1: 0.027264, loss_fp: 0.001978, loss_freq: 0.062243
[14:44:33.388] iteration 15615: loss: 0.067368, loss_s1: 0.020056, loss_fp: 0.004160, loss_freq: 0.009139
[14:44:34.014] iteration 15616: loss: 0.118696, loss_s1: 0.072138, loss_fp: 0.001691, loss_freq: 0.052132
[14:44:34.641] iteration 15617: loss: 0.073668, loss_s1: 0.038887, loss_fp: 0.000809, loss_freq: 0.015158
[14:44:35.271] iteration 15618: loss: 0.029424, loss_s1: 0.008838, loss_fp: 0.001677, loss_freq: 0.011120
[14:44:35.892] iteration 15619: loss: 0.083179, loss_s1: 0.049224, loss_fp: 0.003426, loss_freq: 0.016862
[14:44:36.520] iteration 15620: loss: 0.074628, loss_s1: 0.074989, loss_fp: 0.002023, loss_freq: 0.039078
[14:44:37.147] iteration 15621: loss: 0.093273, loss_s1: 0.059471, loss_fp: 0.006955, loss_freq: 0.054595
[14:44:37.771] iteration 15622: loss: 0.091948, loss_s1: 0.018593, loss_fp: 0.004579, loss_freq: 0.032344
[14:44:38.443] iteration 15623: loss: 0.067453, loss_s1: 0.032648, loss_fp: 0.002632, loss_freq: 0.049973
[14:44:39.066] iteration 15624: loss: 0.069910, loss_s1: 0.074940, loss_fp: 0.002434, loss_freq: 0.013029
[14:44:39.692] iteration 15625: loss: 0.048786, loss_s1: 0.041619, loss_fp: 0.007205, loss_freq: 0.014031
[14:44:40.326] iteration 15626: loss: 0.091283, loss_s1: 0.047719, loss_fp: 0.009838, loss_freq: 0.064294
[14:44:40.963] iteration 15627: loss: 0.046208, loss_s1: 0.024120, loss_fp: 0.006745, loss_freq: 0.026643
[14:44:41.601] iteration 15628: loss: 0.068943, loss_s1: 0.038491, loss_fp: 0.002728, loss_freq: 0.019495
[14:44:42.233] iteration 15629: loss: 0.067550, loss_s1: 0.068081, loss_fp: 0.016183, loss_freq: 0.016729
[14:44:42.869] iteration 15630: loss: 0.061715, loss_s1: 0.024865, loss_fp: 0.000756, loss_freq: 0.014694
[14:44:43.504] iteration 15631: loss: 0.070325, loss_s1: 0.044354, loss_fp: 0.003725, loss_freq: 0.039384
[14:44:44.135] iteration 15632: loss: 0.094747, loss_s1: 0.050824, loss_fp: 0.000992, loss_freq: 0.019289
[14:44:44.780] iteration 15633: loss: 0.059771, loss_s1: 0.046837, loss_fp: 0.001281, loss_freq: 0.022775
[14:44:45.415] iteration 15634: loss: 0.048512, loss_s1: 0.026266, loss_fp: 0.002853, loss_freq: 0.024446
[14:44:46.047] iteration 15635: loss: 0.091267, loss_s1: 0.063479, loss_fp: 0.001154, loss_freq: 0.060066
[14:44:46.683] iteration 15636: loss: 0.076432, loss_s1: 0.063594, loss_fp: 0.011813, loss_freq: 0.040168
[14:44:47.305] iteration 15637: loss: 0.050532, loss_s1: 0.030151, loss_fp: 0.001199, loss_freq: 0.015710
[14:44:47.946] iteration 15638: loss: 0.064217, loss_s1: 0.052484, loss_fp: 0.003081, loss_freq: 0.011923
[14:44:48.581] iteration 15639: loss: 0.172322, loss_s1: 0.030846, loss_fp: 0.010258, loss_freq: 0.047335
[14:44:49.235] iteration 15640: loss: 0.044383, loss_s1: 0.018866, loss_fp: 0.000687, loss_freq: 0.018724
[14:44:49.906] iteration 15641: loss: 0.032850, loss_s1: 0.021697, loss_fp: 0.001453, loss_freq: 0.006437
[14:44:50.572] iteration 15642: loss: 0.038891, loss_s1: 0.020803, loss_fp: 0.002947, loss_freq: 0.015126
[14:44:51.223] iteration 15643: loss: 0.052262, loss_s1: 0.022017, loss_fp: 0.002010, loss_freq: 0.017050
[14:44:51.857] iteration 15644: loss: 0.049821, loss_s1: 0.037416, loss_fp: 0.001234, loss_freq: 0.012052
[14:44:52.486] iteration 15645: loss: 0.086335, loss_s1: 0.095901, loss_fp: 0.009011, loss_freq: 0.016230
[14:44:53.117] iteration 15646: loss: 0.094095, loss_s1: 0.055639, loss_fp: 0.004097, loss_freq: 0.072064
[14:44:53.744] iteration 15647: loss: 0.075964, loss_s1: 0.070772, loss_fp: 0.002774, loss_freq: 0.028307
[14:44:54.383] iteration 15648: loss: 0.078342, loss_s1: 0.026122, loss_fp: 0.001923, loss_freq: 0.009374
[14:44:55.024] iteration 15649: loss: 0.048698, loss_s1: 0.029448, loss_fp: 0.001645, loss_freq: 0.028117
[14:44:55.661] iteration 15650: loss: 0.100004, loss_s1: 0.112010, loss_fp: 0.005590, loss_freq: 0.035372
[14:44:56.304] iteration 15651: loss: 0.060023, loss_s1: 0.013213, loss_fp: 0.001567, loss_freq: 0.030444
[14:44:56.935] iteration 15652: loss: 0.056850, loss_s1: 0.032818, loss_fp: 0.005561, loss_freq: 0.027585
[14:44:57.562] iteration 15653: loss: 0.058376, loss_s1: 0.033515, loss_fp: 0.004334, loss_freq: 0.035768
[14:44:58.183] iteration 15654: loss: 0.093090, loss_s1: 0.034726, loss_fp: 0.001789, loss_freq: 0.066844
[14:44:58.802] iteration 15655: loss: 0.064660, loss_s1: 0.061485, loss_fp: 0.001982, loss_freq: 0.028605
[14:44:59.420] iteration 15656: loss: 0.053970, loss_s1: 0.025952, loss_fp: 0.002488, loss_freq: 0.017777
[14:45:00.059] iteration 15657: loss: 0.066685, loss_s1: 0.017977, loss_fp: 0.003242, loss_freq: 0.014958
[14:45:00.691] iteration 15658: loss: 0.068710, loss_s1: 0.032516, loss_fp: 0.002568, loss_freq: 0.012284
[14:45:01.330] iteration 15659: loss: 0.068081, loss_s1: 0.058658, loss_fp: 0.004148, loss_freq: 0.022184
[14:45:01.949] iteration 15660: loss: 0.067014, loss_s1: 0.014267, loss_fp: 0.003450, loss_freq: 0.063356
[14:45:02.582] iteration 15661: loss: 0.086254, loss_s1: 0.074975, loss_fp: 0.008602, loss_freq: 0.034353
[14:45:03.209] iteration 15662: loss: 0.065656, loss_s1: 0.030552, loss_fp: 0.010006, loss_freq: 0.046977
[14:45:03.841] iteration 15663: loss: 0.049162, loss_s1: 0.020766, loss_fp: 0.001957, loss_freq: 0.023859
[14:45:04.505] iteration 15664: loss: 0.073090, loss_s1: 0.065082, loss_fp: 0.004289, loss_freq: 0.032394
[14:45:05.123] iteration 15665: loss: 0.045135, loss_s1: 0.025958, loss_fp: 0.001248, loss_freq: 0.004243
[14:45:05.746] iteration 15666: loss: 0.083305, loss_s1: 0.064414, loss_fp: 0.010833, loss_freq: 0.042531
[14:45:06.362] iteration 15667: loss: 0.075705, loss_s1: 0.043171, loss_fp: 0.014964, loss_freq: 0.017696
[14:45:06.987] iteration 15668: loss: 0.089655, loss_s1: 0.051032, loss_fp: 0.003567, loss_freq: 0.041035
[14:45:07.603] iteration 15669: loss: 0.085108, loss_s1: 0.092835, loss_fp: 0.000899, loss_freq: 0.013741
[14:45:08.240] iteration 15670: loss: 0.069933, loss_s1: 0.066800, loss_fp: 0.000632, loss_freq: 0.017136
[14:45:08.884] iteration 15671: loss: 0.072226, loss_s1: 0.043581, loss_fp: 0.008944, loss_freq: 0.058817
[14:45:09.525] iteration 15672: loss: 0.072313, loss_s1: 0.082804, loss_fp: 0.002047, loss_freq: 0.014168
[14:45:10.153] iteration 15673: loss: 0.076205, loss_s1: 0.053882, loss_fp: 0.002887, loss_freq: 0.044159
[14:45:10.791] iteration 15674: loss: 0.047529, loss_s1: 0.043092, loss_fp: 0.000663, loss_freq: 0.002406
[14:45:11.439] iteration 15675: loss: 0.056190, loss_s1: 0.026449, loss_fp: 0.001667, loss_freq: 0.040563
[14:45:12.091] iteration 15676: loss: 0.045747, loss_s1: 0.031913, loss_fp: 0.001093, loss_freq: 0.020899
[14:45:12.729] iteration 15677: loss: 0.064414, loss_s1: 0.049415, loss_fp: 0.004972, loss_freq: 0.034971
[14:45:13.364] iteration 15678: loss: 0.078566, loss_s1: 0.042008, loss_fp: 0.011143, loss_freq: 0.030710
[14:45:14.032] iteration 15679: loss: 0.078087, loss_s1: 0.043031, loss_fp: 0.002163, loss_freq: 0.070415
[14:45:14.685] iteration 15680: loss: 0.072624, loss_s1: 0.097776, loss_fp: 0.003927, loss_freq: 0.005380
[14:45:15.343] iteration 15681: loss: 0.083285, loss_s1: 0.015849, loss_fp: 0.001419, loss_freq: 0.007527
[14:45:15.982] iteration 15682: loss: 0.039779, loss_s1: 0.018193, loss_fp: 0.000875, loss_freq: 0.005757
[14:45:16.613] iteration 15683: loss: 0.052119, loss_s1: 0.035516, loss_fp: 0.003464, loss_freq: 0.014744
[14:45:17.297] iteration 15684: loss: 0.091618, loss_s1: 0.043942, loss_fp: 0.004957, loss_freq: 0.086400
[14:45:17.973] iteration 15685: loss: 0.058381, loss_s1: 0.048066, loss_fp: 0.005615, loss_freq: 0.017802
[14:45:18.650] iteration 15686: loss: 0.082927, loss_s1: 0.062071, loss_fp: 0.007045, loss_freq: 0.026179
[14:45:19.323] iteration 15687: loss: 0.071796, loss_s1: 0.029111, loss_fp: 0.004019, loss_freq: 0.053297
[14:45:19.972] iteration 15688: loss: 0.083216, loss_s1: 0.057756, loss_fp: 0.005129, loss_freq: 0.045184
[14:45:20.610] iteration 15689: loss: 0.084314, loss_s1: 0.031263, loss_fp: 0.004169, loss_freq: 0.045086
[14:45:21.243] iteration 15690: loss: 0.073790, loss_s1: 0.066164, loss_fp: 0.002750, loss_freq: 0.029431
[14:45:21.896] iteration 15691: loss: 0.068371, loss_s1: 0.059011, loss_fp: 0.011681, loss_freq: 0.018868
[14:45:22.540] iteration 15692: loss: 0.082148, loss_s1: 0.017354, loss_fp: 0.001286, loss_freq: 0.012019
[14:45:23.182] iteration 15693: loss: 0.051368, loss_s1: 0.027315, loss_fp: 0.001692, loss_freq: 0.022185
[14:45:23.831] iteration 15694: loss: 0.070838, loss_s1: 0.039293, loss_fp: 0.002949, loss_freq: 0.044049
[14:45:24.466] iteration 15695: loss: 0.092269, loss_s1: 0.075926, loss_fp: 0.000921, loss_freq: 0.066074
[14:45:25.114] iteration 15696: loss: 0.087812, loss_s1: 0.059654, loss_fp: 0.005531, loss_freq: 0.030860
[14:45:25.750] iteration 15697: loss: 0.088415, loss_s1: 0.081504, loss_fp: 0.006959, loss_freq: 0.043323
[14:45:26.379] iteration 15698: loss: 0.057860, loss_s1: 0.039500, loss_fp: 0.005764, loss_freq: 0.018368
[14:45:27.008] iteration 15699: loss: 0.048583, loss_s1: 0.041954, loss_fp: 0.002591, loss_freq: 0.019440
[14:45:27.631] iteration 15700: loss: 0.067498, loss_s1: 0.041104, loss_fp: 0.002059, loss_freq: 0.017364
[14:45:28.249] iteration 15701: loss: 0.082539, loss_s1: 0.074347, loss_fp: 0.006527, loss_freq: 0.026270
[14:45:28.877] iteration 15702: loss: 0.063424, loss_s1: 0.035767, loss_fp: 0.001730, loss_freq: 0.013725
[14:45:29.501] iteration 15703: loss: 0.087923, loss_s1: 0.060144, loss_fp: 0.002227, loss_freq: 0.022805
[14:45:30.122] iteration 15704: loss: 0.070678, loss_s1: 0.043308, loss_fp: 0.002595, loss_freq: 0.036196
[14:45:30.790] iteration 15705: loss: 0.071024, loss_s1: 0.062687, loss_fp: 0.004160, loss_freq: 0.024770
[14:45:31.452] iteration 15706: loss: 0.067881, loss_s1: 0.066051, loss_fp: 0.004589, loss_freq: 0.034005
[14:45:32.155] iteration 15707: loss: 0.067570, loss_s1: 0.034381, loss_fp: 0.002206, loss_freq: 0.046201
[14:45:32.843] iteration 15708: loss: 0.075213, loss_s1: 0.063051, loss_fp: 0.005346, loss_freq: 0.035668
[14:45:33.524] iteration 15709: loss: 0.091395, loss_s1: 0.033670, loss_fp: 0.001942, loss_freq: 0.057721
[14:45:34.194] iteration 15710: loss: 0.041250, loss_s1: 0.020472, loss_fp: 0.000780, loss_freq: 0.017537
[14:45:34.866] iteration 15711: loss: 0.060208, loss_s1: 0.053364, loss_fp: 0.006800, loss_freq: 0.027975
[14:45:35.542] iteration 15712: loss: 0.045369, loss_s1: 0.041778, loss_fp: 0.003698, loss_freq: 0.013440
[14:45:36.190] iteration 15713: loss: 0.081141, loss_s1: 0.067482, loss_fp: 0.000877, loss_freq: 0.017889
[14:45:36.822] iteration 15714: loss: 0.098495, loss_s1: 0.059956, loss_fp: 0.003353, loss_freq: 0.044696
[14:45:37.497] iteration 15715: loss: 0.050449, loss_s1: 0.032378, loss_fp: 0.004284, loss_freq: 0.014231
[14:45:38.150] iteration 15716: loss: 0.090031, loss_s1: 0.060264, loss_fp: 0.002147, loss_freq: 0.035956
[14:45:38.806] iteration 15717: loss: 0.053788, loss_s1: 0.043328, loss_fp: 0.007272, loss_freq: 0.013714
[14:45:39.489] iteration 15718: loss: 0.057470, loss_s1: 0.028954, loss_fp: 0.002821, loss_freq: 0.017812
[14:45:40.150] iteration 15719: loss: 0.064465, loss_s1: 0.022934, loss_fp: 0.009399, loss_freq: 0.035142
[14:45:40.834] iteration 15720: loss: 0.076798, loss_s1: 0.079582, loss_fp: 0.002291, loss_freq: 0.016249
[14:45:41.474] iteration 15721: loss: 0.071429, loss_s1: 0.038527, loss_fp: 0.002551, loss_freq: 0.039728
[14:45:42.111] iteration 15722: loss: 0.057936, loss_s1: 0.038108, loss_fp: 0.003773, loss_freq: 0.019741
[14:45:42.736] iteration 15723: loss: 0.081038, loss_s1: 0.065140, loss_fp: 0.004151, loss_freq: 0.044517
[14:45:43.354] iteration 15724: loss: 0.073525, loss_s1: 0.056494, loss_fp: 0.005393, loss_freq: 0.028161
[14:45:43.975] iteration 15725: loss: 0.038875, loss_s1: 0.028645, loss_fp: 0.001781, loss_freq: 0.007283
[14:45:44.613] iteration 15726: loss: 0.048922, loss_s1: 0.032390, loss_fp: 0.009497, loss_freq: 0.011257
[14:45:45.236] iteration 15727: loss: 0.054579, loss_s1: 0.042285, loss_fp: 0.004516, loss_freq: 0.009908
[14:45:45.919] iteration 15728: loss: 0.084123, loss_s1: 0.071360, loss_fp: 0.002578, loss_freq: 0.029266
[14:45:46.540] iteration 15729: loss: 0.065318, loss_s1: 0.040158, loss_fp: 0.000866, loss_freq: 0.034482
[14:45:47.152] iteration 15730: loss: 0.038600, loss_s1: 0.013499, loss_fp: 0.001790, loss_freq: 0.024244
[14:45:48.127] iteration 15731: loss: 0.042386, loss_s1: 0.028351, loss_fp: 0.001391, loss_freq: 0.012349
[14:45:48.777] iteration 15732: loss: 0.056143, loss_s1: 0.027495, loss_fp: 0.007294, loss_freq: 0.024855
[14:45:49.434] iteration 15733: loss: 0.074174, loss_s1: 0.053802, loss_fp: 0.002267, loss_freq: 0.052411
[14:45:50.085] iteration 15734: loss: 0.070410, loss_s1: 0.044496, loss_fp: 0.005133, loss_freq: 0.031883
[14:45:50.711] iteration 15735: loss: 0.080666, loss_s1: 0.060040, loss_fp: 0.005334, loss_freq: 0.040319
[14:45:51.340] iteration 15736: loss: 0.069030, loss_s1: 0.017757, loss_fp: 0.000911, loss_freq: 0.013763
[14:45:51.972] iteration 15737: loss: 0.040248, loss_s1: 0.020768, loss_fp: 0.004043, loss_freq: 0.023317
[14:45:52.612] iteration 15738: loss: 0.096828, loss_s1: 0.079872, loss_fp: 0.015131, loss_freq: 0.026266
[14:45:53.252] iteration 15739: loss: 0.074607, loss_s1: 0.051418, loss_fp: 0.008437, loss_freq: 0.040329
[14:45:53.877] iteration 15740: loss: 0.041644, loss_s1: 0.010594, loss_fp: 0.000748, loss_freq: 0.006068
[14:45:54.505] iteration 15741: loss: 0.099546, loss_s1: 0.092690, loss_fp: 0.004588, loss_freq: 0.054105
[14:45:55.131] iteration 15742: loss: 0.056655, loss_s1: 0.042606, loss_fp: 0.000547, loss_freq: 0.008847
[14:45:55.789] iteration 15743: loss: 0.048445, loss_s1: 0.033906, loss_fp: 0.013602, loss_freq: 0.004675
[14:45:56.451] iteration 15744: loss: 0.045305, loss_s1: 0.037017, loss_fp: 0.000889, loss_freq: 0.010711
[14:45:57.113] iteration 15745: loss: 0.076181, loss_s1: 0.060811, loss_fp: 0.002498, loss_freq: 0.043414
[14:45:57.773] iteration 15746: loss: 0.055564, loss_s1: 0.039323, loss_fp: 0.002052, loss_freq: 0.013864
[14:45:58.413] iteration 15747: loss: 0.075987, loss_s1: 0.023516, loss_fp: 0.004032, loss_freq: 0.032709
[14:45:59.079] iteration 15748: loss: 0.035853, loss_s1: 0.024899, loss_fp: 0.000693, loss_freq: 0.006027
[14:45:59.722] iteration 15749: loss: 0.037068, loss_s1: 0.013421, loss_fp: 0.003375, loss_freq: 0.015494
[14:46:00.358] iteration 15750: loss: 0.036022, loss_s1: 0.028013, loss_fp: 0.000535, loss_freq: 0.010819
[14:46:00.988] iteration 15751: loss: 0.079751, loss_s1: 0.036992, loss_fp: 0.003483, loss_freq: 0.060129
[14:46:01.619] iteration 15752: loss: 0.056111, loss_s1: 0.044925, loss_fp: 0.002191, loss_freq: 0.019181
[14:46:02.246] iteration 15753: loss: 0.058200, loss_s1: 0.035761, loss_fp: 0.002288, loss_freq: 0.028754
[14:46:02.874] iteration 15754: loss: 0.075624, loss_s1: 0.052512, loss_fp: 0.003184, loss_freq: 0.008612
[14:46:03.502] iteration 15755: loss: 0.053931, loss_s1: 0.028082, loss_fp: 0.002787, loss_freq: 0.032797
[14:46:04.191] iteration 15756: loss: 0.085514, loss_s1: 0.069777, loss_fp: 0.003708, loss_freq: 0.026699
[14:46:04.852] iteration 15757: loss: 0.094319, loss_s1: 0.038886, loss_fp: 0.003027, loss_freq: 0.095190
[14:46:05.515] iteration 15758: loss: 0.064080, loss_s1: 0.037323, loss_fp: 0.005360, loss_freq: 0.012057
[14:46:06.175] iteration 15759: loss: 0.093053, loss_s1: 0.075450, loss_fp: 0.001536, loss_freq: 0.059167
[14:46:06.832] iteration 15760: loss: 0.053535, loss_s1: 0.024302, loss_fp: 0.003712, loss_freq: 0.025561
[14:46:07.493] iteration 15761: loss: 0.044687, loss_s1: 0.014794, loss_fp: 0.000846, loss_freq: 0.007336
[14:46:08.120] iteration 15762: loss: 0.069884, loss_s1: 0.057248, loss_fp: 0.000646, loss_freq: 0.023483
[14:46:08.749] iteration 15763: loss: 0.051053, loss_s1: 0.024365, loss_fp: 0.005091, loss_freq: 0.042365
[14:46:09.375] iteration 15764: loss: 0.095438, loss_s1: 0.095954, loss_fp: 0.007165, loss_freq: 0.047280
[14:46:09.998] iteration 15765: loss: 0.093668, loss_s1: 0.050857, loss_fp: 0.006068, loss_freq: 0.022091
[14:46:10.631] iteration 15766: loss: 0.086633, loss_s1: 0.030226, loss_fp: 0.001944, loss_freq: 0.047523
[14:46:11.264] iteration 15767: loss: 0.100744, loss_s1: 0.107419, loss_fp: 0.005164, loss_freq: 0.028714
[14:46:11.931] iteration 15768: loss: 0.081714, loss_s1: 0.068269, loss_fp: 0.000818, loss_freq: 0.054699
[14:46:12.644] iteration 15769: loss: 0.094170, loss_s1: 0.060897, loss_fp: 0.002743, loss_freq: 0.069529
[14:46:13.329] iteration 15770: loss: 0.057646, loss_s1: 0.052738, loss_fp: 0.002570, loss_freq: 0.014636
[14:46:14.032] iteration 15771: loss: 0.068184, loss_s1: 0.047285, loss_fp: 0.003317, loss_freq: 0.011130
[14:46:14.754] iteration 15772: loss: 0.052050, loss_s1: 0.040054, loss_fp: 0.001973, loss_freq: 0.019042
[14:46:15.412] iteration 15773: loss: 0.082003, loss_s1: 0.045092, loss_fp: 0.005164, loss_freq: 0.026517
[14:46:16.071] iteration 15774: loss: 0.092287, loss_s1: 0.074987, loss_fp: 0.005570, loss_freq: 0.055314
[14:46:16.734] iteration 15775: loss: 0.114886, loss_s1: 0.104830, loss_fp: 0.002085, loss_freq: 0.012535
[14:46:17.365] iteration 15776: loss: 0.089195, loss_s1: 0.053179, loss_fp: 0.001594, loss_freq: 0.058639
[14:46:17.998] iteration 15777: loss: 0.063926, loss_s1: 0.042668, loss_fp: 0.005960, loss_freq: 0.032590
[14:46:18.631] iteration 15778: loss: 0.072147, loss_s1: 0.023965, loss_fp: 0.033374, loss_freq: 0.022745
[14:46:19.256] iteration 15779: loss: 0.056605, loss_s1: 0.025753, loss_fp: 0.010285, loss_freq: 0.039310
[14:46:19.888] iteration 15780: loss: 0.052460, loss_s1: 0.036932, loss_fp: 0.001227, loss_freq: 0.022000
[14:46:20.512] iteration 15781: loss: 0.064826, loss_s1: 0.027244, loss_fp: 0.002401, loss_freq: 0.022750
[14:46:21.140] iteration 15782: loss: 0.093046, loss_s1: 0.030376, loss_fp: 0.001519, loss_freq: 0.034442
[14:46:21.774] iteration 15783: loss: 0.070514, loss_s1: 0.027302, loss_fp: 0.009065, loss_freq: 0.013792
[14:46:22.397] iteration 15784: loss: 0.043131, loss_s1: 0.028327, loss_fp: 0.002592, loss_freq: 0.015475
[14:46:23.031] iteration 15785: loss: 0.068166, loss_s1: 0.061523, loss_fp: 0.000527, loss_freq: 0.006855
[14:46:23.657] iteration 15786: loss: 0.033863, loss_s1: 0.013036, loss_fp: 0.001696, loss_freq: 0.008785
[14:46:24.302] iteration 15787: loss: 0.067608, loss_s1: 0.066383, loss_fp: 0.003529, loss_freq: 0.021902
[14:46:24.939] iteration 15788: loss: 0.062315, loss_s1: 0.055591, loss_fp: 0.002307, loss_freq: 0.012792
[14:46:25.568] iteration 15789: loss: 0.108327, loss_s1: 0.027087, loss_fp: 0.001569, loss_freq: 0.080032
[14:46:26.198] iteration 15790: loss: 0.034684, loss_s1: 0.014210, loss_fp: 0.003977, loss_freq: 0.011844
[14:46:26.827] iteration 15791: loss: 0.051646, loss_s1: 0.033078, loss_fp: 0.004062, loss_freq: 0.017261
[14:46:27.482] iteration 15792: loss: 0.050481, loss_s1: 0.034151, loss_fp: 0.006404, loss_freq: 0.007514
[14:46:28.143] iteration 15793: loss: 0.065195, loss_s1: 0.049110, loss_fp: 0.003998, loss_freq: 0.025575
[14:46:28.770] iteration 15794: loss: 0.075737, loss_s1: 0.056417, loss_fp: 0.001645, loss_freq: 0.023256
[14:46:29.397] iteration 15795: loss: 0.158882, loss_s1: 0.095164, loss_fp: 0.007029, loss_freq: 0.069578
[14:46:30.034] iteration 15796: loss: 0.053802, loss_s1: 0.035581, loss_fp: 0.000787, loss_freq: 0.018174
[14:46:30.660] iteration 15797: loss: 0.085933, loss_s1: 0.055668, loss_fp: 0.009001, loss_freq: 0.056455
[14:46:31.287] iteration 15798: loss: 0.054414, loss_s1: 0.029713, loss_fp: 0.002720, loss_freq: 0.035091
[14:46:31.969] iteration 15799: loss: 0.060520, loss_s1: 0.026496, loss_fp: 0.005509, loss_freq: 0.037159
[14:46:32.627] iteration 15800: loss: 0.060547, loss_s1: 0.017848, loss_fp: 0.003117, loss_freq: 0.030891
[14:46:35.902] iteration 15800 : mean_dice : 0.774241
[14:46:36.556] iteration 15801: loss: 0.050078, loss_s1: 0.034460, loss_fp: 0.001402, loss_freq: 0.013357
[14:46:37.174] iteration 15802: loss: 0.057827, loss_s1: 0.041490, loss_fp: 0.002700, loss_freq: 0.020485
[14:46:37.795] iteration 15803: loss: 0.075768, loss_s1: 0.028334, loss_fp: 0.002408, loss_freq: 0.080182
[14:46:38.421] iteration 15804: loss: 0.114419, loss_s1: 0.077289, loss_fp: 0.003006, loss_freq: 0.050700
[14:46:39.044] iteration 15805: loss: 0.061358, loss_s1: 0.043769, loss_fp: 0.000632, loss_freq: 0.027484
[14:46:39.752] iteration 15806: loss: 0.040600, loss_s1: 0.018668, loss_fp: 0.001564, loss_freq: 0.013339
[14:46:40.385] iteration 15807: loss: 0.035595, loss_s1: 0.029239, loss_fp: 0.004021, loss_freq: 0.003499
[14:46:41.020] iteration 15808: loss: 0.074242, loss_s1: 0.067867, loss_fp: 0.004886, loss_freq: 0.009613
[14:46:41.649] iteration 15809: loss: 0.066959, loss_s1: 0.047705, loss_fp: 0.008168, loss_freq: 0.031306
[14:46:42.276] iteration 15810: loss: 0.122536, loss_s1: 0.046908, loss_fp: 0.004509, loss_freq: 0.022479
[14:46:42.911] iteration 15811: loss: 0.072105, loss_s1: 0.054119, loss_fp: 0.000829, loss_freq: 0.024596
[14:46:43.549] iteration 15812: loss: 0.047857, loss_s1: 0.021818, loss_fp: 0.002309, loss_freq: 0.031732
[14:46:44.178] iteration 15813: loss: 0.066510, loss_s1: 0.014220, loss_fp: 0.001432, loss_freq: 0.031741
[14:46:44.807] iteration 15814: loss: 0.046949, loss_s1: 0.047246, loss_fp: 0.001091, loss_freq: 0.012521
[14:46:45.424] iteration 15815: loss: 0.056463, loss_s1: 0.033475, loss_fp: 0.001697, loss_freq: 0.034110
[14:46:46.048] iteration 15816: loss: 0.055011, loss_s1: 0.032877, loss_fp: 0.008035, loss_freq: 0.029190
[14:46:46.680] iteration 15817: loss: 0.067018, loss_s1: 0.049221, loss_fp: 0.004857, loss_freq: 0.007707
[14:46:47.310] iteration 15818: loss: 0.037406, loss_s1: 0.027746, loss_fp: 0.001530, loss_freq: 0.005529
[14:46:47.937] iteration 15819: loss: 0.043761, loss_s1: 0.047967, loss_fp: 0.000963, loss_freq: 0.005541
[14:46:48.564] iteration 15820: loss: 0.079366, loss_s1: 0.038486, loss_fp: 0.002667, loss_freq: 0.063152
[14:46:49.191] iteration 15821: loss: 0.061250, loss_s1: 0.029564, loss_fp: 0.001166, loss_freq: 0.027305
[14:46:49.822] iteration 15822: loss: 0.061213, loss_s1: 0.047563, loss_fp: 0.003375, loss_freq: 0.025790
[14:46:50.447] iteration 15823: loss: 0.049006, loss_s1: 0.040071, loss_fp: 0.001537, loss_freq: 0.010067
[14:46:51.074] iteration 15824: loss: 0.088799, loss_s1: 0.072095, loss_fp: 0.005431, loss_freq: 0.006875
[14:46:51.696] iteration 15825: loss: 0.069918, loss_s1: 0.057686, loss_fp: 0.004222, loss_freq: 0.016667
[14:46:52.317] iteration 15826: loss: 0.056068, loss_s1: 0.042453, loss_fp: 0.003288, loss_freq: 0.018341
[14:46:52.941] iteration 15827: loss: 0.092495, loss_s1: 0.083472, loss_fp: 0.002650, loss_freq: 0.034163
[14:46:53.556] iteration 15828: loss: 0.045147, loss_s1: 0.017832, loss_fp: 0.001350, loss_freq: 0.012767
[14:46:54.172] iteration 15829: loss: 0.071412, loss_s1: 0.030150, loss_fp: 0.001625, loss_freq: 0.013872
[14:46:54.803] iteration 15830: loss: 0.118045, loss_s1: 0.101452, loss_fp: 0.001713, loss_freq: 0.054970
[14:46:55.495] iteration 15831: loss: 0.060579, loss_s1: 0.032870, loss_fp: 0.002674, loss_freq: 0.010495
[14:46:56.129] iteration 15832: loss: 0.083177, loss_s1: 0.057153, loss_fp: 0.003701, loss_freq: 0.027143
[14:46:57.090] iteration 15833: loss: 0.067953, loss_s1: 0.045760, loss_fp: 0.001779, loss_freq: 0.035098
[14:46:58.056] iteration 15834: loss: 0.051306, loss_s1: 0.044334, loss_fp: 0.001551, loss_freq: 0.014114
[14:46:59.021] iteration 15835: loss: 0.070984, loss_s1: 0.028347, loss_fp: 0.003211, loss_freq: 0.014639
[14:46:59.969] iteration 15836: loss: 0.088415, loss_s1: 0.034220, loss_fp: 0.001744, loss_freq: 0.038517
[14:47:00.942] iteration 15837: loss: 0.073485, loss_s1: 0.052661, loss_fp: 0.001507, loss_freq: 0.034461
[14:47:01.918] iteration 15838: loss: 0.043530, loss_s1: 0.023460, loss_fp: 0.002838, loss_freq: 0.025935
[14:47:02.665] iteration 15839: loss: 0.074340, loss_s1: 0.058719, loss_fp: 0.002620, loss_freq: 0.042141
[14:47:03.343] iteration 15840: loss: 0.086850, loss_s1: 0.057650, loss_fp: 0.001980, loss_freq: 0.029347
[14:47:03.984] iteration 15841: loss: 0.067506, loss_s1: 0.013865, loss_fp: 0.006644, loss_freq: 0.020474
[14:47:04.622] iteration 15842: loss: 0.057002, loss_s1: 0.045295, loss_fp: 0.003369, loss_freq: 0.033477
[14:47:05.253] iteration 15843: loss: 0.073675, loss_s1: 0.057177, loss_fp: 0.003461, loss_freq: 0.018823
[14:47:05.890] iteration 15844: loss: 0.071891, loss_s1: 0.035010, loss_fp: 0.017202, loss_freq: 0.028035
[14:47:06.523] iteration 15845: loss: 0.075033, loss_s1: 0.034963, loss_fp: 0.008671, loss_freq: 0.030924
[14:47:07.253] iteration 15846: loss: 0.071065, loss_s1: 0.050521, loss_fp: 0.001735, loss_freq: 0.018866
[14:47:07.889] iteration 15847: loss: 0.060739, loss_s1: 0.028211, loss_fp: 0.005352, loss_freq: 0.047940
[14:47:08.754] iteration 15848: loss: 0.077378, loss_s1: 0.078101, loss_fp: 0.001209, loss_freq: 0.028656
[14:47:09.644] iteration 15849: loss: 0.082682, loss_s1: 0.057379, loss_fp: 0.005098, loss_freq: 0.006994
[14:47:10.276] iteration 15850: loss: 0.052241, loss_s1: 0.018635, loss_fp: 0.005845, loss_freq: 0.035537
[14:47:10.908] iteration 15851: loss: 0.078558, loss_s1: 0.028538, loss_fp: 0.002486, loss_freq: 0.044370
[14:47:11.534] iteration 15852: loss: 0.072829, loss_s1: 0.058390, loss_fp: 0.002642, loss_freq: 0.028705
[14:47:12.166] iteration 15853: loss: 0.046076, loss_s1: 0.010498, loss_fp: 0.001246, loss_freq: 0.012006
[14:47:12.795] iteration 15854: loss: 0.042483, loss_s1: 0.026819, loss_fp: 0.002033, loss_freq: 0.017626
[14:47:13.414] iteration 15855: loss: 0.061300, loss_s1: 0.035706, loss_fp: 0.002440, loss_freq: 0.048376
[14:47:14.039] iteration 15856: loss: 0.091623, loss_s1: 0.075584, loss_fp: 0.007010, loss_freq: 0.011324
[14:47:14.666] iteration 15857: loss: 0.048214, loss_s1: 0.027080, loss_fp: 0.004444, loss_freq: 0.023160
[14:47:15.304] iteration 15858: loss: 0.068720, loss_s1: 0.056764, loss_fp: 0.003590, loss_freq: 0.030568
[14:47:15.941] iteration 15859: loss: 0.080190, loss_s1: 0.058850, loss_fp: 0.004368, loss_freq: 0.043256
[14:47:16.577] iteration 15860: loss: 0.047300, loss_s1: 0.022477, loss_fp: 0.004403, loss_freq: 0.012463
[14:47:17.206] iteration 15861: loss: 0.055304, loss_s1: 0.029024, loss_fp: 0.001570, loss_freq: 0.025334
[14:47:17.831] iteration 15862: loss: 0.074221, loss_s1: 0.040011, loss_fp: 0.005924, loss_freq: 0.048567
[14:47:18.459] iteration 15863: loss: 0.067606, loss_s1: 0.053536, loss_fp: 0.007085, loss_freq: 0.021729
[14:47:19.096] iteration 15864: loss: 0.108767, loss_s1: 0.044075, loss_fp: 0.009622, loss_freq: 0.115746
[14:47:19.756] iteration 15865: loss: 0.098696, loss_s1: 0.040671, loss_fp: 0.004816, loss_freq: 0.024006
[14:47:20.386] iteration 15866: loss: 0.066702, loss_s1: 0.048045, loss_fp: 0.003969, loss_freq: 0.024978
[14:47:21.012] iteration 15867: loss: 0.045497, loss_s1: 0.022187, loss_fp: 0.002665, loss_freq: 0.009962
[14:47:21.642] iteration 15868: loss: 0.040527, loss_s1: 0.027683, loss_fp: 0.000949, loss_freq: 0.014961
[14:47:22.275] iteration 15869: loss: 0.051954, loss_s1: 0.027311, loss_fp: 0.005225, loss_freq: 0.018842
[14:47:22.911] iteration 15870: loss: 0.082599, loss_s1: 0.055216, loss_fp: 0.003842, loss_freq: 0.014916
[14:47:23.535] iteration 15871: loss: 0.103041, loss_s1: 0.081345, loss_fp: 0.002847, loss_freq: 0.081091
[14:47:24.154] iteration 15872: loss: 0.096194, loss_s1: 0.079708, loss_fp: 0.007029, loss_freq: 0.059222
[14:47:24.777] iteration 15873: loss: 0.050635, loss_s1: 0.026823, loss_fp: 0.001569, loss_freq: 0.039361
[14:47:25.823] iteration 15874: loss: 0.058928, loss_s1: 0.065953, loss_fp: 0.001023, loss_freq: 0.006787
[14:47:26.509] iteration 15875: loss: 0.069457, loss_s1: 0.045217, loss_fp: 0.000864, loss_freq: 0.025332
[14:47:27.195] iteration 15876: loss: 0.052716, loss_s1: 0.025125, loss_fp: 0.001121, loss_freq: 0.022954
[14:47:27.867] iteration 15877: loss: 0.099106, loss_s1: 0.054537, loss_fp: 0.001716, loss_freq: 0.045585
[14:47:28.499] iteration 15878: loss: 0.086484, loss_s1: 0.089404, loss_fp: 0.004146, loss_freq: 0.042561
[14:47:29.151] iteration 15879: loss: 0.058093, loss_s1: 0.012464, loss_fp: 0.000334, loss_freq: 0.010175
[14:47:29.805] iteration 15880: loss: 0.085450, loss_s1: 0.112021, loss_fp: 0.002259, loss_freq: 0.023810
[14:47:30.450] iteration 15881: loss: 0.079484, loss_s1: 0.046262, loss_fp: 0.007596, loss_freq: 0.040799
[14:47:31.099] iteration 15882: loss: 0.087485, loss_s1: 0.081668, loss_fp: 0.001046, loss_freq: 0.037376
[14:47:31.745] iteration 15883: loss: 0.056073, loss_s1: 0.014278, loss_fp: 0.001353, loss_freq: 0.016282
[14:47:32.389] iteration 15884: loss: 0.072798, loss_s1: 0.040498, loss_fp: 0.004239, loss_freq: 0.042889
[14:47:33.037] iteration 15885: loss: 0.053579, loss_s1: 0.020650, loss_fp: 0.002216, loss_freq: 0.015188
[14:47:33.661] iteration 15886: loss: 0.054182, loss_s1: 0.044466, loss_fp: 0.006711, loss_freq: 0.003722
[14:47:34.304] iteration 15887: loss: 0.050590, loss_s1: 0.020303, loss_fp: 0.001476, loss_freq: 0.035654
[14:47:34.940] iteration 15888: loss: 0.054092, loss_s1: 0.041171, loss_fp: 0.001461, loss_freq: 0.022511
[14:47:35.572] iteration 15889: loss: 0.041476, loss_s1: 0.015609, loss_fp: 0.001126, loss_freq: 0.014968
[14:47:36.203] iteration 15890: loss: 0.057789, loss_s1: 0.025581, loss_fp: 0.000492, loss_freq: 0.016945
[14:47:36.832] iteration 15891: loss: 0.039827, loss_s1: 0.024146, loss_fp: 0.001117, loss_freq: 0.012649
[14:47:37.460] iteration 15892: loss: 0.038782, loss_s1: 0.019210, loss_fp: 0.004164, loss_freq: 0.019154
[14:47:38.086] iteration 15893: loss: 0.046748, loss_s1: 0.018912, loss_fp: 0.005434, loss_freq: 0.012272
[14:47:38.719] iteration 15894: loss: 0.105928, loss_s1: 0.029237, loss_fp: 0.002413, loss_freq: 0.052880
[14:47:39.343] iteration 15895: loss: 0.064166, loss_s1: 0.057427, loss_fp: 0.004741, loss_freq: 0.025054
[14:47:39.991] iteration 15896: loss: 0.033526, loss_s1: 0.019420, loss_fp: 0.002453, loss_freq: 0.007923
[14:47:40.614] iteration 15897: loss: 0.054955, loss_s1: 0.062212, loss_fp: 0.000746, loss_freq: 0.004695
[14:47:41.231] iteration 15898: loss: 0.051866, loss_s1: 0.032233, loss_fp: 0.003771, loss_freq: 0.015509
[14:47:41.850] iteration 15899: loss: 0.093358, loss_s1: 0.058236, loss_fp: 0.001199, loss_freq: 0.035108
[14:47:42.473] iteration 15900: loss: 0.084179, loss_s1: 0.054580, loss_fp: 0.003123, loss_freq: 0.046631
[14:47:43.089] iteration 15901: loss: 0.051025, loss_s1: 0.042347, loss_fp: 0.000530, loss_freq: 0.015715
[14:47:43.752] iteration 15902: loss: 0.067201, loss_s1: 0.041713, loss_fp: 0.004799, loss_freq: 0.019857
[14:47:44.416] iteration 15903: loss: 0.046232, loss_s1: 0.016584, loss_fp: 0.002292, loss_freq: 0.009329
[14:47:45.068] iteration 15904: loss: 0.068857, loss_s1: 0.048093, loss_fp: 0.000938, loss_freq: 0.015638
[14:47:45.726] iteration 15905: loss: 0.067217, loss_s1: 0.052407, loss_fp: 0.003618, loss_freq: 0.023745
[14:47:46.373] iteration 15906: loss: 0.074088, loss_s1: 0.057364, loss_fp: 0.008841, loss_freq: 0.041508
[14:47:47.051] iteration 15907: loss: 0.071582, loss_s1: 0.043008, loss_fp: 0.005587, loss_freq: 0.056423
[14:47:47.714] iteration 15908: loss: 0.090442, loss_s1: 0.078563, loss_fp: 0.002844, loss_freq: 0.018970
[14:47:48.372] iteration 15909: loss: 0.072311, loss_s1: 0.041226, loss_fp: 0.009032, loss_freq: 0.036604
[14:47:49.033] iteration 15910: loss: 0.068364, loss_s1: 0.054806, loss_fp: 0.000743, loss_freq: 0.013315
[14:47:49.684] iteration 15911: loss: 0.116211, loss_s1: 0.080733, loss_fp: 0.017502, loss_freq: 0.096863
[14:47:50.305] iteration 15912: loss: 0.120577, loss_s1: 0.056446, loss_fp: 0.004289, loss_freq: 0.058752
[14:47:50.935] iteration 15913: loss: 0.058285, loss_s1: 0.059121, loss_fp: 0.002346, loss_freq: 0.016285
[14:47:51.567] iteration 15914: loss: 0.070007, loss_s1: 0.050863, loss_fp: 0.004635, loss_freq: 0.007432
[14:47:52.200] iteration 15915: loss: 0.053611, loss_s1: 0.054179, loss_fp: 0.002175, loss_freq: 0.010071
[14:47:52.824] iteration 15916: loss: 0.043850, loss_s1: 0.012942, loss_fp: 0.001370, loss_freq: 0.013689
[14:47:53.453] iteration 15917: loss: 0.071430, loss_s1: 0.064766, loss_fp: 0.003447, loss_freq: 0.021896
[14:47:54.086] iteration 15918: loss: 0.065711, loss_s1: 0.029971, loss_fp: 0.001628, loss_freq: 0.005792
[14:47:54.713] iteration 15919: loss: 0.082666, loss_s1: 0.058339, loss_fp: 0.005222, loss_freq: 0.049101
[14:47:55.343] iteration 15920: loss: 0.052955, loss_s1: 0.021670, loss_fp: 0.002576, loss_freq: 0.030193
[14:47:55.975] iteration 15921: loss: 0.069276, loss_s1: 0.067517, loss_fp: 0.000666, loss_freq: 0.025136
[14:47:56.601] iteration 15922: loss: 0.051887, loss_s1: 0.030400, loss_fp: 0.004033, loss_freq: 0.037167
[14:47:57.264] iteration 15923: loss: 0.068578, loss_s1: 0.062070, loss_fp: 0.004644, loss_freq: 0.020750
[14:47:57.932] iteration 15924: loss: 0.048951, loss_s1: 0.023491, loss_fp: 0.002244, loss_freq: 0.018120
[14:47:58.558] iteration 15925: loss: 0.138946, loss_s1: 0.029927, loss_fp: 0.002335, loss_freq: 0.042948
[14:47:59.186] iteration 15926: loss: 0.045581, loss_s1: 0.029064, loss_fp: 0.001609, loss_freq: 0.005002
[14:47:59.819] iteration 15927: loss: 0.053853, loss_s1: 0.033467, loss_fp: 0.003095, loss_freq: 0.022086
[14:48:00.438] iteration 15928: loss: 0.032954, loss_s1: 0.012886, loss_fp: 0.012641, loss_freq: 0.004072
[14:48:01.080] iteration 15929: loss: 0.046965, loss_s1: 0.018894, loss_fp: 0.000972, loss_freq: 0.013246
[14:48:01.705] iteration 15930: loss: 0.091167, loss_s1: 0.062732, loss_fp: 0.006519, loss_freq: 0.025908
[14:48:02.333] iteration 15931: loss: 0.064958, loss_s1: 0.019846, loss_fp: 0.004828, loss_freq: 0.056406
[14:48:02.965] iteration 15932: loss: 0.080624, loss_s1: 0.025988, loss_fp: 0.003992, loss_freq: 0.073160
[14:48:03.605] iteration 15933: loss: 0.057589, loss_s1: 0.038568, loss_fp: 0.003653, loss_freq: 0.028218
[14:48:04.228] iteration 15934: loss: 0.060684, loss_s1: 0.042336, loss_fp: 0.007274, loss_freq: 0.012118
[14:48:04.847] iteration 15935: loss: 0.079348, loss_s1: 0.045208, loss_fp: 0.006179, loss_freq: 0.009712
[14:48:05.469] iteration 15936: loss: 0.072404, loss_s1: 0.017711, loss_fp: 0.007633, loss_freq: 0.051001
[14:48:06.097] iteration 15937: loss: 0.061543, loss_s1: 0.013840, loss_fp: 0.001995, loss_freq: 0.025434
[14:48:06.711] iteration 15938: loss: 0.034706, loss_s1: 0.013088, loss_fp: 0.000375, loss_freq: 0.011992
[14:48:07.333] iteration 15939: loss: 0.046052, loss_s1: 0.023453, loss_fp: 0.002555, loss_freq: 0.018561
[14:48:07.964] iteration 15940: loss: 0.110542, loss_s1: 0.074421, loss_fp: 0.011102, loss_freq: 0.056293
[14:48:08.586] iteration 15941: loss: 0.041417, loss_s1: 0.029128, loss_fp: 0.001283, loss_freq: 0.013256
[14:48:09.219] iteration 15942: loss: 0.065649, loss_s1: 0.037394, loss_fp: 0.003600, loss_freq: 0.012752
[14:48:09.846] iteration 15943: loss: 0.085663, loss_s1: 0.014635, loss_fp: 0.015196, loss_freq: 0.004222
[14:48:10.471] iteration 15944: loss: 0.064111, loss_s1: 0.060989, loss_fp: 0.001314, loss_freq: 0.021605
[14:48:11.095] iteration 15945: loss: 0.060310, loss_s1: 0.034155, loss_fp: 0.009391, loss_freq: 0.024283
[14:48:11.726] iteration 15946: loss: 0.075328, loss_s1: 0.048005, loss_fp: 0.001489, loss_freq: 0.033335
[14:48:12.397] iteration 15947: loss: 0.109575, loss_s1: 0.073642, loss_fp: 0.004658, loss_freq: 0.054660
[14:48:13.046] iteration 15948: loss: 0.075899, loss_s1: 0.038976, loss_fp: 0.003679, loss_freq: 0.057260
[14:48:13.687] iteration 15949: loss: 0.100470, loss_s1: 0.046352, loss_fp: 0.003641, loss_freq: 0.019446
[14:48:14.300] iteration 15950: loss: 0.047607, loss_s1: 0.029261, loss_fp: 0.001219, loss_freq: 0.027016
[14:48:14.921] iteration 15951: loss: 0.048002, loss_s1: 0.037472, loss_fp: 0.000410, loss_freq: 0.008246
[14:48:15.544] iteration 15952: loss: 0.095437, loss_s1: 0.083839, loss_fp: 0.009047, loss_freq: 0.051143
[14:48:16.168] iteration 15953: loss: 0.095018, loss_s1: 0.085522, loss_fp: 0.006468, loss_freq: 0.032733
[14:48:16.796] iteration 15954: loss: 0.048889, loss_s1: 0.028926, loss_fp: 0.001056, loss_freq: 0.027888
[14:48:17.427] iteration 15955: loss: 0.068850, loss_s1: 0.052734, loss_fp: 0.001863, loss_freq: 0.026096
[14:48:18.075] iteration 15956: loss: 0.047289, loss_s1: 0.029120, loss_fp: 0.002234, loss_freq: 0.019682
[14:48:18.743] iteration 15957: loss: 0.051727, loss_s1: 0.037581, loss_fp: 0.004195, loss_freq: 0.015416
[14:48:19.369] iteration 15958: loss: 0.069422, loss_s1: 0.037204, loss_fp: 0.004019, loss_freq: 0.047163
[14:48:19.991] iteration 15959: loss: 0.056833, loss_s1: 0.028908, loss_fp: 0.002352, loss_freq: 0.031793
[14:48:20.616] iteration 15960: loss: 0.046018, loss_s1: 0.018537, loss_fp: 0.001154, loss_freq: 0.012882
[14:48:21.241] iteration 15961: loss: 0.056980, loss_s1: 0.027516, loss_fp: 0.000812, loss_freq: 0.020006
[14:48:21.856] iteration 15962: loss: 0.042215, loss_s1: 0.036537, loss_fp: 0.001177, loss_freq: 0.008648
[14:48:22.486] iteration 15963: loss: 0.059958, loss_s1: 0.043730, loss_fp: 0.004285, loss_freq: 0.035570
[14:48:23.111] iteration 15964: loss: 0.058525, loss_s1: 0.026324, loss_fp: 0.000708, loss_freq: 0.019690
[14:48:23.734] iteration 15965: loss: 0.099497, loss_s1: 0.076136, loss_fp: 0.005961, loss_freq: 0.045567
[14:48:24.357] iteration 15966: loss: 0.053291, loss_s1: 0.033203, loss_fp: 0.001946, loss_freq: 0.012123
[14:48:24.990] iteration 15967: loss: 0.048277, loss_s1: 0.019907, loss_fp: 0.005934, loss_freq: 0.008130
[14:48:25.621] iteration 15968: loss: 0.070005, loss_s1: 0.061826, loss_fp: 0.004257, loss_freq: 0.020777
[14:48:26.252] iteration 15969: loss: 0.044315, loss_s1: 0.018910, loss_fp: 0.001427, loss_freq: 0.010654
[14:48:26.878] iteration 15970: loss: 0.144511, loss_s1: 0.157252, loss_fp: 0.015772, loss_freq: 0.044270
[14:48:27.509] iteration 15971: loss: 0.043119, loss_s1: 0.018731, loss_fp: 0.006292, loss_freq: 0.013144
[14:48:28.130] iteration 15972: loss: 0.063870, loss_s1: 0.048030, loss_fp: 0.004168, loss_freq: 0.021450
[14:48:28.755] iteration 15973: loss: 0.074726, loss_s1: 0.045721, loss_fp: 0.000863, loss_freq: 0.032447
[14:48:29.409] iteration 15974: loss: 0.056630, loss_s1: 0.016255, loss_fp: 0.001704, loss_freq: 0.045871
[14:48:30.073] iteration 15975: loss: 0.042753, loss_s1: 0.017164, loss_fp: 0.002130, loss_freq: 0.011174
[14:48:30.736] iteration 15976: loss: 0.062393, loss_s1: 0.028585, loss_fp: 0.006814, loss_freq: 0.050087
[14:48:31.371] iteration 15977: loss: 0.047157, loss_s1: 0.035887, loss_fp: 0.001945, loss_freq: 0.012068
[14:48:32.005] iteration 15978: loss: 0.055949, loss_s1: 0.036795, loss_fp: 0.002593, loss_freq: 0.008458
[14:48:32.633] iteration 15979: loss: 0.077125, loss_s1: 0.012370, loss_fp: 0.005560, loss_freq: 0.024064
[14:48:33.258] iteration 15980: loss: 0.133962, loss_s1: 0.071834, loss_fp: 0.002088, loss_freq: 0.117820
[14:48:33.879] iteration 15981: loss: 0.046723, loss_s1: 0.036733, loss_fp: 0.002868, loss_freq: 0.023977
[14:48:34.495] iteration 15982: loss: 0.070152, loss_s1: 0.046287, loss_fp: 0.001366, loss_freq: 0.031768
[14:48:35.124] iteration 15983: loss: 0.051812, loss_s1: 0.017008, loss_fp: 0.012928, loss_freq: 0.027020
[14:48:35.751] iteration 15984: loss: 0.079468, loss_s1: 0.027760, loss_fp: 0.002903, loss_freq: 0.029243
[14:48:36.389] iteration 15985: loss: 0.057487, loss_s1: 0.042755, loss_fp: 0.002842, loss_freq: 0.030650
[14:48:37.018] iteration 15986: loss: 0.073332, loss_s1: 0.051463, loss_fp: 0.002744, loss_freq: 0.028729
[14:48:37.650] iteration 15987: loss: 0.068193, loss_s1: 0.023318, loss_fp: 0.002780, loss_freq: 0.063085
[14:48:38.285] iteration 15988: loss: 0.080027, loss_s1: 0.037931, loss_fp: 0.001773, loss_freq: 0.029315
[14:48:38.953] iteration 15989: loss: 0.060360, loss_s1: 0.031127, loss_fp: 0.005316, loss_freq: 0.011364
[14:48:39.628] iteration 15990: loss: 0.055367, loss_s1: 0.039532, loss_fp: 0.001324, loss_freq: 0.027771
[14:48:40.301] iteration 15991: loss: 0.062378, loss_s1: 0.048875, loss_fp: 0.001525, loss_freq: 0.016394
[14:48:40.971] iteration 15992: loss: 0.064360, loss_s1: 0.068371, loss_fp: 0.002610, loss_freq: 0.024647
[14:48:41.606] iteration 15993: loss: 0.047986, loss_s1: 0.020674, loss_fp: 0.000962, loss_freq: 0.031262
[14:48:42.244] iteration 15994: loss: 0.130945, loss_s1: 0.070116, loss_fp: 0.001189, loss_freq: 0.104490
[14:48:42.871] iteration 15995: loss: 0.103572, loss_s1: 0.038318, loss_fp: 0.005318, loss_freq: 0.008447
[14:48:43.500] iteration 15996: loss: 0.045448, loss_s1: 0.025832, loss_fp: 0.011047, loss_freq: 0.002535
[14:48:44.180] iteration 15997: loss: 0.041348, loss_s1: 0.029861, loss_fp: 0.000547, loss_freq: 0.011174
[14:48:44.847] iteration 15998: loss: 0.065343, loss_s1: 0.050807, loss_fp: 0.005810, loss_freq: 0.040093
[14:48:45.484] iteration 15999: loss: 0.045512, loss_s1: 0.015112, loss_fp: 0.005510, loss_freq: 0.009502
[14:48:46.126] iteration 16000: loss: 0.041842, loss_s1: 0.018372, loss_fp: 0.000938, loss_freq: 0.024070
[14:48:49.663] iteration 16000 : mean_dice : 0.769105
[14:48:50.338] iteration 16001: loss: 0.073972, loss_s1: 0.067535, loss_fp: 0.003853, loss_freq: 0.029935
[14:48:50.980] iteration 16002: loss: 0.071977, loss_s1: 0.061650, loss_fp: 0.001892, loss_freq: 0.014420
[14:48:51.629] iteration 16003: loss: 0.037526, loss_s1: 0.011052, loss_fp: 0.003911, loss_freq: 0.012621
[14:48:52.267] iteration 16004: loss: 0.058439, loss_s1: 0.036597, loss_fp: 0.003523, loss_freq: 0.018157
[14:48:52.894] iteration 16005: loss: 0.069785, loss_s1: 0.035960, loss_fp: 0.006329, loss_freq: 0.028795
[14:48:53.532] iteration 16006: loss: 0.058680, loss_s1: 0.021756, loss_fp: 0.004243, loss_freq: 0.019142
[14:48:54.178] iteration 16007: loss: 0.076173, loss_s1: 0.051228, loss_fp: 0.002510, loss_freq: 0.042059
[14:48:54.827] iteration 16008: loss: 0.052516, loss_s1: 0.024528, loss_fp: 0.000963, loss_freq: 0.013322
[14:48:55.480] iteration 16009: loss: 0.090019, loss_s1: 0.089120, loss_fp: 0.002506, loss_freq: 0.022603
[14:48:56.135] iteration 16010: loss: 0.111698, loss_s1: 0.125306, loss_fp: 0.006672, loss_freq: 0.037885
[14:48:56.767] iteration 16011: loss: 0.042730, loss_s1: 0.015578, loss_fp: 0.001667, loss_freq: 0.008260
[14:48:57.412] iteration 16012: loss: 0.048815, loss_s1: 0.033646, loss_fp: 0.002765, loss_freq: 0.019393
[14:48:58.039] iteration 16013: loss: 0.050671, loss_s1: 0.017816, loss_fp: 0.013869, loss_freq: 0.014052
[14:48:58.658] iteration 16014: loss: 0.078593, loss_s1: 0.049638, loss_fp: 0.001241, loss_freq: 0.049162
[14:48:59.283] iteration 16015: loss: 0.069617, loss_s1: 0.063778, loss_fp: 0.000798, loss_freq: 0.026073
[14:48:59.905] iteration 16016: loss: 0.062181, loss_s1: 0.040411, loss_fp: 0.000791, loss_freq: 0.048214
[14:49:00.858] iteration 16017: loss: 0.052374, loss_s1: 0.036766, loss_fp: 0.004144, loss_freq: 0.011017
[14:49:01.516] iteration 16018: loss: 0.089136, loss_s1: 0.098220, loss_fp: 0.004827, loss_freq: 0.020136
[14:49:02.169] iteration 16019: loss: 0.054461, loss_s1: 0.051108, loss_fp: 0.000723, loss_freq: 0.020954
[14:49:02.827] iteration 16020: loss: 0.068608, loss_s1: 0.048864, loss_fp: 0.004744, loss_freq: 0.020754
[14:49:03.489] iteration 16021: loss: 0.077362, loss_s1: 0.066067, loss_fp: 0.002488, loss_freq: 0.047651
[14:49:04.116] iteration 16022: loss: 0.065840, loss_s1: 0.019543, loss_fp: 0.001908, loss_freq: 0.010577
[14:49:04.742] iteration 16023: loss: 0.053702, loss_s1: 0.043995, loss_fp: 0.006529, loss_freq: 0.023252
[14:49:05.359] iteration 16024: loss: 0.083131, loss_s1: 0.085125, loss_fp: 0.005021, loss_freq: 0.016974
[14:49:05.983] iteration 16025: loss: 0.047547, loss_s1: 0.032744, loss_fp: 0.002540, loss_freq: 0.023432
[14:49:06.606] iteration 16026: loss: 0.040024, loss_s1: 0.015867, loss_fp: 0.000679, loss_freq: 0.003550
[14:49:07.229] iteration 16027: loss: 0.063610, loss_s1: 0.029532, loss_fp: 0.003635, loss_freq: 0.051436
[14:49:07.851] iteration 16028: loss: 0.062893, loss_s1: 0.039060, loss_fp: 0.003684, loss_freq: 0.022202
[14:49:08.478] iteration 16029: loss: 0.054004, loss_s1: 0.038121, loss_fp: 0.003143, loss_freq: 0.017588
[14:49:09.101] iteration 16030: loss: 0.047069, loss_s1: 0.023262, loss_fp: 0.001588, loss_freq: 0.029935
[14:49:09.729] iteration 16031: loss: 0.052471, loss_s1: 0.040431, loss_fp: 0.002667, loss_freq: 0.018913
[14:49:10.344] iteration 16032: loss: 0.059202, loss_s1: 0.054650, loss_fp: 0.002306, loss_freq: 0.013539
[14:49:10.974] iteration 16033: loss: 0.050259, loss_s1: 0.032689, loss_fp: 0.002358, loss_freq: 0.019644
[14:49:11.594] iteration 16034: loss: 0.071452, loss_s1: 0.055346, loss_fp: 0.001597, loss_freq: 0.027041
[14:49:12.220] iteration 16035: loss: 0.066862, loss_s1: 0.056919, loss_fp: 0.000899, loss_freq: 0.034113
[14:49:12.841] iteration 16036: loss: 0.045129, loss_s1: 0.045494, loss_fp: 0.003086, loss_freq: 0.008019
[14:49:13.467] iteration 16037: loss: 0.101392, loss_s1: 0.041574, loss_fp: 0.001663, loss_freq: 0.107300
[14:49:14.093] iteration 16038: loss: 0.055530, loss_s1: 0.051316, loss_fp: 0.002037, loss_freq: 0.022627
[14:49:14.715] iteration 16039: loss: 0.057767, loss_s1: 0.053154, loss_fp: 0.001039, loss_freq: 0.012076
[14:49:15.344] iteration 16040: loss: 0.062798, loss_s1: 0.042747, loss_fp: 0.001272, loss_freq: 0.017288
[14:49:15.973] iteration 16041: loss: 0.069684, loss_s1: 0.068082, loss_fp: 0.000982, loss_freq: 0.024409
[14:49:16.597] iteration 16042: loss: 0.079622, loss_s1: 0.029648, loss_fp: 0.012485, loss_freq: 0.040502
[14:49:17.225] iteration 16043: loss: 0.081335, loss_s1: 0.046272, loss_fp: 0.002517, loss_freq: 0.043674
[14:49:17.849] iteration 16044: loss: 0.052476, loss_s1: 0.037132, loss_fp: 0.001005, loss_freq: 0.007647
[14:49:18.557] iteration 16045: loss: 0.074389, loss_s1: 0.052888, loss_fp: 0.002919, loss_freq: 0.026752
[14:49:19.214] iteration 16046: loss: 0.054505, loss_s1: 0.032220, loss_fp: 0.001991, loss_freq: 0.019720
[14:49:19.876] iteration 16047: loss: 0.053208, loss_s1: 0.034515, loss_fp: 0.001032, loss_freq: 0.009213
[14:49:20.535] iteration 16048: loss: 0.067981, loss_s1: 0.077868, loss_fp: 0.000721, loss_freq: 0.010724
[14:49:21.200] iteration 16049: loss: 0.102463, loss_s1: 0.098402, loss_fp: 0.002630, loss_freq: 0.059838
[14:49:21.851] iteration 16050: loss: 0.088373, loss_s1: 0.094410, loss_fp: 0.004535, loss_freq: 0.039673
[14:49:22.512] iteration 16051: loss: 0.071802, loss_s1: 0.045633, loss_fp: 0.008013, loss_freq: 0.027764
[14:49:23.159] iteration 16052: loss: 0.092005, loss_s1: 0.080116, loss_fp: 0.003923, loss_freq: 0.048278
[14:49:23.794] iteration 16053: loss: 0.067769, loss_s1: 0.043411, loss_fp: 0.005923, loss_freq: 0.031425
[14:49:24.421] iteration 16054: loss: 0.053086, loss_s1: 0.031566, loss_fp: 0.001474, loss_freq: 0.033400
[14:49:25.049] iteration 16055: loss: 0.103837, loss_s1: 0.068054, loss_fp: 0.003989, loss_freq: 0.082575
[14:49:25.684] iteration 16056: loss: 0.038910, loss_s1: 0.020326, loss_fp: 0.001356, loss_freq: 0.008956
[14:49:26.319] iteration 16057: loss: 0.060711, loss_s1: 0.060052, loss_fp: 0.007751, loss_freq: 0.013444
[14:49:26.938] iteration 16058: loss: 0.045449, loss_s1: 0.028969, loss_fp: 0.002145, loss_freq: 0.024013
[14:49:27.568] iteration 16059: loss: 0.055843, loss_s1: 0.019968, loss_fp: 0.001963, loss_freq: 0.008761
[14:49:28.187] iteration 16060: loss: 0.063013, loss_s1: 0.042255, loss_fp: 0.006513, loss_freq: 0.031047
[14:49:28.821] iteration 16061: loss: 0.062064, loss_s1: 0.042605, loss_fp: 0.003599, loss_freq: 0.007443
[14:49:29.442] iteration 16062: loss: 0.068183, loss_s1: 0.056582, loss_fp: 0.003479, loss_freq: 0.033480
[14:49:30.069] iteration 16063: loss: 0.065023, loss_s1: 0.024816, loss_fp: 0.004571, loss_freq: 0.042455
[14:49:30.696] iteration 16064: loss: 0.075771, loss_s1: 0.044385, loss_fp: 0.003302, loss_freq: 0.064234
[14:49:31.316] iteration 16065: loss: 0.055226, loss_s1: 0.055007, loss_fp: 0.000826, loss_freq: 0.017194
[14:49:31.941] iteration 16066: loss: 0.063499, loss_s1: 0.032608, loss_fp: 0.004001, loss_freq: 0.042631
[14:49:32.565] iteration 16067: loss: 0.064308, loss_s1: 0.054393, loss_fp: 0.005512, loss_freq: 0.019753
[14:49:33.190] iteration 16068: loss: 0.056320, loss_s1: 0.012175, loss_fp: 0.001600, loss_freq: 0.020533
[14:49:33.811] iteration 16069: loss: 0.035191, loss_s1: 0.019358, loss_fp: 0.000468, loss_freq: 0.007179
[14:49:34.432] iteration 16070: loss: 0.051564, loss_s1: 0.044037, loss_fp: 0.001263, loss_freq: 0.009830
[14:49:35.062] iteration 16071: loss: 0.046823, loss_s1: 0.045690, loss_fp: 0.002802, loss_freq: 0.015286
[14:49:35.685] iteration 16072: loss: 0.046151, loss_s1: 0.023323, loss_fp: 0.001594, loss_freq: 0.006571
[14:49:36.307] iteration 16073: loss: 0.066100, loss_s1: 0.080279, loss_fp: 0.003834, loss_freq: 0.015515
[14:49:36.931] iteration 16074: loss: 0.044230, loss_s1: 0.012460, loss_fp: 0.002190, loss_freq: 0.014055
[14:49:37.593] iteration 16075: loss: 0.057937, loss_s1: 0.031289, loss_fp: 0.001168, loss_freq: 0.049532
[14:49:38.232] iteration 16076: loss: 0.063005, loss_s1: 0.039964, loss_fp: 0.000836, loss_freq: 0.036285
[14:49:38.866] iteration 16077: loss: 0.065576, loss_s1: 0.036813, loss_fp: 0.001006, loss_freq: 0.020158
[14:49:39.492] iteration 16078: loss: 0.074270, loss_s1: 0.085620, loss_fp: 0.001611, loss_freq: 0.009509
[14:49:40.124] iteration 16079: loss: 0.035411, loss_s1: 0.016523, loss_fp: 0.003403, loss_freq: 0.009442
[14:49:40.775] iteration 16080: loss: 0.049771, loss_s1: 0.017679, loss_fp: 0.002217, loss_freq: 0.019211
[14:49:41.435] iteration 16081: loss: 0.165127, loss_s1: 0.078594, loss_fp: 0.003666, loss_freq: 0.043807
[14:49:42.128] iteration 16082: loss: 0.061228, loss_s1: 0.018781, loss_fp: 0.010590, loss_freq: 0.043811
[14:49:42.766] iteration 16083: loss: 0.119986, loss_s1: 0.098868, loss_fp: 0.030123, loss_freq: 0.059971
[14:49:43.397] iteration 16084: loss: 0.059499, loss_s1: 0.036987, loss_fp: 0.001910, loss_freq: 0.040264
[14:49:44.034] iteration 16085: loss: 0.058054, loss_s1: 0.050349, loss_fp: 0.003389, loss_freq: 0.017514
[14:49:44.672] iteration 16086: loss: 0.053741, loss_s1: 0.018147, loss_fp: 0.002551, loss_freq: 0.013431
[14:49:45.300] iteration 16087: loss: 0.068231, loss_s1: 0.049498, loss_fp: 0.002307, loss_freq: 0.028823
[14:49:45.932] iteration 16088: loss: 0.080629, loss_s1: 0.049761, loss_fp: 0.001245, loss_freq: 0.060276
[14:49:46.557] iteration 16089: loss: 0.059818, loss_s1: 0.054927, loss_fp: 0.001572, loss_freq: 0.027105
[14:49:47.181] iteration 16090: loss: 0.138516, loss_s1: 0.132110, loss_fp: 0.007219, loss_freq: 0.087837
[14:49:47.813] iteration 16091: loss: 0.067216, loss_s1: 0.047191, loss_fp: 0.008719, loss_freq: 0.044340
[14:49:48.437] iteration 16092: loss: 0.065118, loss_s1: 0.016912, loss_fp: 0.003224, loss_freq: 0.022532
[14:49:49.076] iteration 16093: loss: 0.072905, loss_s1: 0.030445, loss_fp: 0.003712, loss_freq: 0.017001
[14:49:49.705] iteration 16094: loss: 0.041611, loss_s1: 0.020009, loss_fp: 0.004323, loss_freq: 0.007480
[14:49:50.339] iteration 16095: loss: 0.057881, loss_s1: 0.029348, loss_fp: 0.006341, loss_freq: 0.037792
[14:49:51.007] iteration 16096: loss: 0.092508, loss_s1: 0.058614, loss_fp: 0.005119, loss_freq: 0.013071
[14:49:51.663] iteration 16097: loss: 0.085099, loss_s1: 0.039869, loss_fp: 0.002966, loss_freq: 0.045128
[14:49:52.317] iteration 16098: loss: 0.076667, loss_s1: 0.037646, loss_fp: 0.014045, loss_freq: 0.052049
[14:49:52.969] iteration 16099: loss: 0.045727, loss_s1: 0.013265, loss_fp: 0.005690, loss_freq: 0.024793
[14:49:53.622] iteration 16100: loss: 0.045342, loss_s1: 0.021125, loss_fp: 0.001368, loss_freq: 0.032919
[14:49:54.273] iteration 16101: loss: 0.063635, loss_s1: 0.044919, loss_fp: 0.010158, loss_freq: 0.022781
[14:49:54.930] iteration 16102: loss: 0.077608, loss_s1: 0.017262, loss_fp: 0.003906, loss_freq: 0.089751
[14:49:55.551] iteration 16103: loss: 0.054914, loss_s1: 0.022533, loss_fp: 0.000867, loss_freq: 0.011782
[14:49:56.178] iteration 16104: loss: 0.061633, loss_s1: 0.021906, loss_fp: 0.002272, loss_freq: 0.021019
[14:49:56.796] iteration 16105: loss: 0.058168, loss_s1: 0.043579, loss_fp: 0.001533, loss_freq: 0.029847
[14:49:57.419] iteration 16106: loss: 0.049103, loss_s1: 0.034521, loss_fp: 0.001668, loss_freq: 0.030160
[14:49:58.045] iteration 16107: loss: 0.052245, loss_s1: 0.012182, loss_fp: 0.003406, loss_freq: 0.010389
[14:49:58.676] iteration 16108: loss: 0.040390, loss_s1: 0.020003, loss_fp: 0.007568, loss_freq: 0.016660
[14:49:59.304] iteration 16109: loss: 0.063040, loss_s1: 0.038642, loss_fp: 0.003315, loss_freq: 0.016904
[14:49:59.956] iteration 16110: loss: 0.063942, loss_s1: 0.061015, loss_fp: 0.001575, loss_freq: 0.009726
[14:50:00.625] iteration 16111: loss: 0.036691, loss_s1: 0.013829, loss_fp: 0.003200, loss_freq: 0.016273
[14:50:01.272] iteration 16112: loss: 0.045179, loss_s1: 0.019166, loss_fp: 0.002479, loss_freq: 0.010687
[14:50:01.949] iteration 16113: loss: 0.115815, loss_s1: 0.081195, loss_fp: 0.008877, loss_freq: 0.093030
[14:50:02.606] iteration 16114: loss: 0.055557, loss_s1: 0.034208, loss_fp: 0.000519, loss_freq: 0.027970
[14:50:03.268] iteration 16115: loss: 0.059279, loss_s1: 0.028866, loss_fp: 0.001270, loss_freq: 0.030665
[14:50:03.935] iteration 16116: loss: 0.082381, loss_s1: 0.031439, loss_fp: 0.000949, loss_freq: 0.017314
[14:50:04.596] iteration 16117: loss: 0.067128, loss_s1: 0.035200, loss_fp: 0.003222, loss_freq: 0.026053
[14:50:05.255] iteration 16118: loss: 0.057931, loss_s1: 0.039702, loss_fp: 0.001027, loss_freq: 0.026171
[14:50:05.883] iteration 16119: loss: 0.068228, loss_s1: 0.078281, loss_fp: 0.003056, loss_freq: 0.021937
[14:50:06.515] iteration 16120: loss: 0.045043, loss_s1: 0.003070, loss_fp: 0.010094, loss_freq: 0.016436
[14:50:07.149] iteration 16121: loss: 0.077296, loss_s1: 0.053616, loss_fp: 0.003224, loss_freq: 0.018753
[14:50:07.784] iteration 16122: loss: 0.056694, loss_s1: 0.025181, loss_fp: 0.002030, loss_freq: 0.028770
[14:50:08.401] iteration 16123: loss: 0.087067, loss_s1: 0.063688, loss_fp: 0.004761, loss_freq: 0.041663
[14:50:09.018] iteration 16124: loss: 0.057262, loss_s1: 0.015844, loss_fp: 0.008358, loss_freq: 0.051372
[14:50:09.648] iteration 16125: loss: 0.087831, loss_s1: 0.058586, loss_fp: 0.002388, loss_freq: 0.059928
[14:50:10.273] iteration 16126: loss: 0.067186, loss_s1: 0.067020, loss_fp: 0.001398, loss_freq: 0.019881
[14:50:10.904] iteration 16127: loss: 0.102697, loss_s1: 0.053042, loss_fp: 0.001659, loss_freq: 0.012436
[14:50:11.532] iteration 16128: loss: 0.058744, loss_s1: 0.054485, loss_fp: 0.002911, loss_freq: 0.027743
[14:50:12.153] iteration 16129: loss: 0.053712, loss_s1: 0.046780, loss_fp: 0.000835, loss_freq: 0.008520
[14:50:12.775] iteration 16130: loss: 0.075603, loss_s1: 0.068660, loss_fp: 0.001988, loss_freq: 0.038072
[14:50:13.407] iteration 16131: loss: 0.108048, loss_s1: 0.035637, loss_fp: 0.003101, loss_freq: 0.029101
[14:50:14.036] iteration 16132: loss: 0.034569, loss_s1: 0.009912, loss_fp: 0.001026, loss_freq: 0.016280
[14:50:14.660] iteration 16133: loss: 0.057292, loss_s1: 0.023915, loss_fp: 0.009489, loss_freq: 0.032055
[14:50:15.286] iteration 16134: loss: 0.071888, loss_s1: 0.077276, loss_fp: 0.002399, loss_freq: 0.018055
[14:50:15.915] iteration 16135: loss: 0.039143, loss_s1: 0.032759, loss_fp: 0.001715, loss_freq: 0.010800
[14:50:16.543] iteration 16136: loss: 0.043010, loss_s1: 0.023475, loss_fp: 0.002011, loss_freq: 0.019964
[14:50:17.176] iteration 16137: loss: 0.070351, loss_s1: 0.032480, loss_fp: 0.002058, loss_freq: 0.045865
[14:50:17.838] iteration 16138: loss: 0.155833, loss_s1: 0.060542, loss_fp: 0.004016, loss_freq: 0.035765
[14:50:18.508] iteration 16139: loss: 0.053332, loss_s1: 0.045340, loss_fp: 0.013190, loss_freq: 0.009340
[14:50:19.170] iteration 16140: loss: 0.054631, loss_s1: 0.028944, loss_fp: 0.004998, loss_freq: 0.045502
[14:50:19.831] iteration 16141: loss: 0.050275, loss_s1: 0.029514, loss_fp: 0.002233, loss_freq: 0.023722
[14:50:20.509] iteration 16142: loss: 0.072370, loss_s1: 0.050459, loss_fp: 0.014527, loss_freq: 0.013593
[14:50:21.157] iteration 16143: loss: 0.041264, loss_s1: 0.015534, loss_fp: 0.001063, loss_freq: 0.030220
[14:50:21.777] iteration 16144: loss: 0.035410, loss_s1: 0.027735, loss_fp: 0.001819, loss_freq: 0.005707
[14:50:22.404] iteration 16145: loss: 0.084253, loss_s1: 0.082354, loss_fp: 0.004078, loss_freq: 0.029277
[14:50:23.036] iteration 16146: loss: 0.052139, loss_s1: 0.031051, loss_fp: 0.000627, loss_freq: 0.023049
[14:50:23.741] iteration 16147: loss: 0.056623, loss_s1: 0.030740, loss_fp: 0.003289, loss_freq: 0.019275
[14:50:24.391] iteration 16148: loss: 0.087164, loss_s1: 0.042094, loss_fp: 0.004707, loss_freq: 0.022883
[14:50:25.071] iteration 16149: loss: 0.061886, loss_s1: 0.029742, loss_fp: 0.003488, loss_freq: 0.041007
[14:50:25.707] iteration 16150: loss: 0.076276, loss_s1: 0.033514, loss_fp: 0.002718, loss_freq: 0.045581
[14:50:26.339] iteration 16151: loss: 0.060422, loss_s1: 0.020766, loss_fp: 0.005677, loss_freq: 0.033275
[14:50:26.969] iteration 16152: loss: 0.096072, loss_s1: 0.072864, loss_fp: 0.011498, loss_freq: 0.053203
[14:50:27.600] iteration 16153: loss: 0.080456, loss_s1: 0.079208, loss_fp: 0.003702, loss_freq: 0.029747
[14:50:28.222] iteration 16154: loss: 0.069764, loss_s1: 0.055802, loss_fp: 0.000574, loss_freq: 0.011493
[14:50:28.845] iteration 16155: loss: 0.067956, loss_s1: 0.050671, loss_fp: 0.003566, loss_freq: 0.033161
[14:50:29.471] iteration 16156: loss: 0.064726, loss_s1: 0.034489, loss_fp: 0.005553, loss_freq: 0.013387
[14:50:30.126] iteration 16157: loss: 0.066456, loss_s1: 0.052098, loss_fp: 0.004327, loss_freq: 0.036413
[14:50:30.755] iteration 16158: loss: 0.069096, loss_s1: 0.071031, loss_fp: 0.004276, loss_freq: 0.018137
[14:50:31.381] iteration 16159: loss: 0.053137, loss_s1: 0.023836, loss_fp: 0.005625, loss_freq: 0.026093
[14:50:32.327] iteration 16160: loss: 0.050986, loss_s1: 0.025685, loss_fp: 0.001271, loss_freq: 0.016860
[14:50:32.975] iteration 16161: loss: 0.061796, loss_s1: 0.033612, loss_fp: 0.003229, loss_freq: 0.016811
[14:50:33.610] iteration 16162: loss: 0.039513, loss_s1: 0.017136, loss_fp: 0.000824, loss_freq: 0.026216
[14:50:34.239] iteration 16163: loss: 0.076055, loss_s1: 0.030429, loss_fp: 0.004958, loss_freq: 0.010912
[14:50:34.885] iteration 16164: loss: 0.043585, loss_s1: 0.020574, loss_fp: 0.000797, loss_freq: 0.025514
[14:50:35.520] iteration 16165: loss: 0.054052, loss_s1: 0.032010, loss_fp: 0.002022, loss_freq: 0.003852
[14:50:36.155] iteration 16166: loss: 0.041285, loss_s1: 0.029150, loss_fp: 0.003805, loss_freq: 0.014950
[14:50:36.788] iteration 16167: loss: 0.095809, loss_s1: 0.094007, loss_fp: 0.004857, loss_freq: 0.026815
[14:50:37.487] iteration 16168: loss: 0.071163, loss_s1: 0.035252, loss_fp: 0.009812, loss_freq: 0.030277
[14:50:38.159] iteration 16169: loss: 0.050890, loss_s1: 0.023716, loss_fp: 0.001498, loss_freq: 0.006030
[14:50:38.828] iteration 16170: loss: 0.081358, loss_s1: 0.060544, loss_fp: 0.004192, loss_freq: 0.048394
[14:50:39.491] iteration 16171: loss: 0.050199, loss_s1: 0.032558, loss_fp: 0.001137, loss_freq: 0.008698
[14:50:40.160] iteration 16172: loss: 0.069152, loss_s1: 0.060865, loss_fp: 0.003486, loss_freq: 0.011181
[14:50:40.795] iteration 16173: loss: 0.036286, loss_s1: 0.022426, loss_fp: 0.000588, loss_freq: 0.012478
[14:50:41.426] iteration 16174: loss: 0.065063, loss_s1: 0.051302, loss_fp: 0.002627, loss_freq: 0.025751
[14:50:42.070] iteration 16175: loss: 0.031477, loss_s1: 0.009217, loss_fp: 0.001446, loss_freq: 0.008103
[14:50:42.705] iteration 16176: loss: 0.058059, loss_s1: 0.031459, loss_fp: 0.001246, loss_freq: 0.026473
[14:50:43.335] iteration 16177: loss: 0.053927, loss_s1: 0.035745, loss_fp: 0.004944, loss_freq: 0.028760
[14:50:43.973] iteration 16178: loss: 0.036790, loss_s1: 0.022270, loss_fp: 0.002298, loss_freq: 0.016635
[14:50:44.615] iteration 16179: loss: 0.030184, loss_s1: 0.012537, loss_fp: 0.001377, loss_freq: 0.013606
[14:50:45.294] iteration 16180: loss: 0.078101, loss_s1: 0.018859, loss_fp: 0.003347, loss_freq: 0.040563
[14:50:45.979] iteration 16181: loss: 0.044741, loss_s1: 0.032191, loss_fp: 0.000856, loss_freq: 0.015993
[14:50:46.661] iteration 16182: loss: 0.066729, loss_s1: 0.012676, loss_fp: 0.000771, loss_freq: 0.073322
[14:50:47.321] iteration 16183: loss: 0.051227, loss_s1: 0.024068, loss_fp: 0.001110, loss_freq: 0.011238
[14:50:47.979] iteration 16184: loss: 0.059890, loss_s1: 0.060142, loss_fp: 0.003177, loss_freq: 0.016600
[14:50:48.638] iteration 16185: loss: 0.080256, loss_s1: 0.049216, loss_fp: 0.002012, loss_freq: 0.047449
[14:50:49.300] iteration 16186: loss: 0.089610, loss_s1: 0.057240, loss_fp: 0.010663, loss_freq: 0.049450
[14:50:49.959] iteration 16187: loss: 0.048276, loss_s1: 0.032409, loss_fp: 0.001176, loss_freq: 0.014400
[14:50:50.600] iteration 16188: loss: 0.046249, loss_s1: 0.030998, loss_fp: 0.000957, loss_freq: 0.013608
[14:50:51.225] iteration 16189: loss: 0.038920, loss_s1: 0.016222, loss_fp: 0.002351, loss_freq: 0.007110
[14:50:51.849] iteration 16190: loss: 0.065755, loss_s1: 0.051974, loss_fp: 0.001797, loss_freq: 0.035390
[14:50:52.470] iteration 16191: loss: 0.077326, loss_s1: 0.018843, loss_fp: 0.002602, loss_freq: 0.032217
[14:50:53.126] iteration 16192: loss: 0.073577, loss_s1: 0.072352, loss_fp: 0.007514, loss_freq: 0.032708
[14:50:53.758] iteration 16193: loss: 0.063489, loss_s1: 0.035120, loss_fp: 0.004255, loss_freq: 0.034260
[14:50:54.384] iteration 16194: loss: 0.092580, loss_s1: 0.057147, loss_fp: 0.004938, loss_freq: 0.023948
[14:50:55.022] iteration 16195: loss: 0.077367, loss_s1: 0.073048, loss_fp: 0.003375, loss_freq: 0.035494
[14:50:55.681] iteration 16196: loss: 0.051249, loss_s1: 0.015550, loss_fp: 0.015295, loss_freq: 0.022578
[14:50:56.338] iteration 16197: loss: 0.092746, loss_s1: 0.032552, loss_fp: 0.008899, loss_freq: 0.101317
[14:50:56.978] iteration 16198: loss: 0.104941, loss_s1: 0.066160, loss_fp: 0.015193, loss_freq: 0.058614
[14:50:57.610] iteration 16199: loss: 0.048602, loss_s1: 0.025848, loss_fp: 0.002771, loss_freq: 0.026010
[14:50:58.240] iteration 16200: loss: 0.106300, loss_s1: 0.065378, loss_fp: 0.002992, loss_freq: 0.022566
[14:51:01.684] iteration 16200 : mean_dice : 0.784362
[14:51:02.343] iteration 16201: loss: 0.044457, loss_s1: 0.048382, loss_fp: 0.000534, loss_freq: 0.007609
[14:51:02.963] iteration 16202: loss: 0.056156, loss_s1: 0.032260, loss_fp: 0.001105, loss_freq: 0.029461
[14:51:03.584] iteration 16203: loss: 0.064226, loss_s1: 0.045016, loss_fp: 0.001927, loss_freq: 0.028253
[14:51:04.211] iteration 16204: loss: 0.057667, loss_s1: 0.025356, loss_fp: 0.000791, loss_freq: 0.009255
[14:51:04.833] iteration 16205: loss: 0.068264, loss_s1: 0.043919, loss_fp: 0.002741, loss_freq: 0.033586
[14:51:05.456] iteration 16206: loss: 0.055327, loss_s1: 0.034010, loss_fp: 0.004078, loss_freq: 0.019918
[14:51:06.080] iteration 16207: loss: 0.071812, loss_s1: 0.052591, loss_fp: 0.000730, loss_freq: 0.051954
[14:51:06.708] iteration 16208: loss: 0.074294, loss_s1: 0.062613, loss_fp: 0.015500, loss_freq: 0.016286
[14:51:07.328] iteration 16209: loss: 0.066649, loss_s1: 0.063042, loss_fp: 0.002687, loss_freq: 0.022667
[14:51:07.951] iteration 16210: loss: 0.061697, loss_s1: 0.062499, loss_fp: 0.001617, loss_freq: 0.010118
[14:51:08.572] iteration 16211: loss: 0.061335, loss_s1: 0.050424, loss_fp: 0.001455, loss_freq: 0.015587
[14:51:09.189] iteration 16212: loss: 0.041118, loss_s1: 0.019649, loss_fp: 0.001080, loss_freq: 0.017176
[14:51:09.812] iteration 16213: loss: 0.047239, loss_s1: 0.035453, loss_fp: 0.005060, loss_freq: 0.006529
[14:51:10.441] iteration 16214: loss: 0.054288, loss_s1: 0.007405, loss_fp: 0.001648, loss_freq: 0.007385
[14:51:11.100] iteration 16215: loss: 0.048651, loss_s1: 0.026113, loss_fp: 0.000783, loss_freq: 0.010311
[14:51:11.758] iteration 16216: loss: 0.116114, loss_s1: 0.128406, loss_fp: 0.002279, loss_freq: 0.035188
[14:51:12.418] iteration 16217: loss: 0.045657, loss_s1: 0.012832, loss_fp: 0.002034, loss_freq: 0.026305
[14:51:13.074] iteration 16218: loss: 0.091953, loss_s1: 0.053779, loss_fp: 0.001366, loss_freq: 0.072162
[14:51:13.694] iteration 16219: loss: 0.065644, loss_s1: 0.040672, loss_fp: 0.000764, loss_freq: 0.047700
[14:51:14.370] iteration 16220: loss: 0.044591, loss_s1: 0.015782, loss_fp: 0.003008, loss_freq: 0.009020
[14:51:15.001] iteration 16221: loss: 0.048911, loss_s1: 0.042171, loss_fp: 0.001297, loss_freq: 0.008908
[14:51:15.631] iteration 16222: loss: 0.068130, loss_s1: 0.056594, loss_fp: 0.005346, loss_freq: 0.030151
[14:51:16.272] iteration 16223: loss: 0.077030, loss_s1: 0.050325, loss_fp: 0.000526, loss_freq: 0.019703
[14:51:16.903] iteration 16224: loss: 0.098387, loss_s1: 0.052269, loss_fp: 0.005701, loss_freq: 0.077832
[14:51:17.544] iteration 16225: loss: 0.059067, loss_s1: 0.019006, loss_fp: 0.001117, loss_freq: 0.043798
[14:51:18.220] iteration 16226: loss: 0.131936, loss_s1: 0.106376, loss_fp: 0.008958, loss_freq: 0.098437
[14:51:18.897] iteration 16227: loss: 0.063061, loss_s1: 0.047688, loss_fp: 0.002900, loss_freq: 0.018550
[14:51:19.567] iteration 16228: loss: 0.075893, loss_s1: 0.081743, loss_fp: 0.002060, loss_freq: 0.021086
[14:51:20.237] iteration 16229: loss: 0.065302, loss_s1: 0.048946, loss_fp: 0.002637, loss_freq: 0.028329
[14:51:20.876] iteration 16230: loss: 0.052999, loss_s1: 0.035121, loss_fp: 0.004683, loss_freq: 0.019850
[14:51:21.506] iteration 16231: loss: 0.067293, loss_s1: 0.049241, loss_fp: 0.008552, loss_freq: 0.024785
[14:51:22.141] iteration 16232: loss: 0.062471, loss_s1: 0.030681, loss_fp: 0.002322, loss_freq: 0.035555
[14:51:22.770] iteration 16233: loss: 0.072732, loss_s1: 0.048725, loss_fp: 0.009223, loss_freq: 0.025441
[14:51:23.448] iteration 16234: loss: 0.078859, loss_s1: 0.070038, loss_fp: 0.015808, loss_freq: 0.040709
[14:51:24.082] iteration 16235: loss: 0.073410, loss_s1: 0.019379, loss_fp: 0.006515, loss_freq: 0.014773
[14:51:24.723] iteration 16236: loss: 0.053728, loss_s1: 0.052827, loss_fp: 0.002702, loss_freq: 0.012627
[14:51:25.354] iteration 16237: loss: 0.066879, loss_s1: 0.064036, loss_fp: 0.003127, loss_freq: 0.006019
[14:51:25.985] iteration 16238: loss: 0.068239, loss_s1: 0.046235, loss_fp: 0.004419, loss_freq: 0.027283
[14:51:26.631] iteration 16239: loss: 0.093995, loss_s1: 0.060350, loss_fp: 0.001420, loss_freq: 0.026972
[14:51:27.264] iteration 16240: loss: 0.072681, loss_s1: 0.076788, loss_fp: 0.002335, loss_freq: 0.018744
[14:51:27.903] iteration 16241: loss: 0.077832, loss_s1: 0.059725, loss_fp: 0.003034, loss_freq: 0.035294
[14:51:28.542] iteration 16242: loss: 0.045854, loss_s1: 0.019980, loss_fp: 0.001956, loss_freq: 0.010783
[14:51:29.183] iteration 16243: loss: 0.049902, loss_s1: 0.033275, loss_fp: 0.002195, loss_freq: 0.025989
[14:51:29.817] iteration 16244: loss: 0.060842, loss_s1: 0.045916, loss_fp: 0.004547, loss_freq: 0.023054
[14:51:30.452] iteration 16245: loss: 0.071743, loss_s1: 0.036511, loss_fp: 0.007158, loss_freq: 0.037851
[14:51:31.080] iteration 16246: loss: 0.043205, loss_s1: 0.014879, loss_fp: 0.001133, loss_freq: 0.005496
[14:51:31.706] iteration 16247: loss: 0.063754, loss_s1: 0.050677, loss_fp: 0.001252, loss_freq: 0.031690
[14:51:32.334] iteration 16248: loss: 0.041617, loss_s1: 0.040495, loss_fp: 0.000909, loss_freq: 0.007967
[14:51:32.963] iteration 16249: loss: 0.047021, loss_s1: 0.027822, loss_fp: 0.003159, loss_freq: 0.023971
[14:51:33.589] iteration 16250: loss: 0.069399, loss_s1: 0.012388, loss_fp: 0.000607, loss_freq: 0.034030
[14:51:34.211] iteration 16251: loss: 0.062641, loss_s1: 0.027750, loss_fp: 0.004895, loss_freq: 0.054482
[14:51:34.836] iteration 16252: loss: 0.052384, loss_s1: 0.033984, loss_fp: 0.000595, loss_freq: 0.009105
[14:51:35.462] iteration 16253: loss: 0.043293, loss_s1: 0.030015, loss_fp: 0.004620, loss_freq: 0.008751
[14:51:36.084] iteration 16254: loss: 0.035079, loss_s1: 0.012154, loss_fp: 0.001578, loss_freq: 0.012597
[14:51:36.712] iteration 16255: loss: 0.039435, loss_s1: 0.010793, loss_fp: 0.001160, loss_freq: 0.004022
[14:51:37.341] iteration 16256: loss: 0.115804, loss_s1: 0.088705, loss_fp: 0.002104, loss_freq: 0.083019
[14:51:38.000] iteration 16257: loss: 0.043321, loss_s1: 0.018976, loss_fp: 0.001450, loss_freq: 0.018112
[14:51:38.670] iteration 16258: loss: 0.069046, loss_s1: 0.013852, loss_fp: 0.003811, loss_freq: 0.040444
[14:51:39.338] iteration 16259: loss: 0.087180, loss_s1: 0.093976, loss_fp: 0.001846, loss_freq: 0.019585
[14:51:39.967] iteration 16260: loss: 0.065080, loss_s1: 0.035660, loss_fp: 0.001363, loss_freq: 0.021363
[14:51:40.650] iteration 16261: loss: 0.084316, loss_s1: 0.062283, loss_fp: 0.004647, loss_freq: 0.054698
[14:51:41.318] iteration 16262: loss: 0.111031, loss_s1: 0.094938, loss_fp: 0.002266, loss_freq: 0.041069
[14:51:41.999] iteration 16263: loss: 0.057923, loss_s1: 0.004828, loss_fp: 0.004148, loss_freq: 0.048188
[14:51:42.663] iteration 16264: loss: 0.062344, loss_s1: 0.033856, loss_fp: 0.001148, loss_freq: 0.018164
[14:51:43.322] iteration 16265: loss: 0.065691, loss_s1: 0.036316, loss_fp: 0.001046, loss_freq: 0.038787
[14:51:43.981] iteration 16266: loss: 0.066474, loss_s1: 0.041231, loss_fp: 0.008553, loss_freq: 0.031867
[14:51:44.642] iteration 16267: loss: 0.065931, loss_s1: 0.021957, loss_fp: 0.001298, loss_freq: 0.077365
[14:51:45.309] iteration 16268: loss: 0.074754, loss_s1: 0.057898, loss_fp: 0.001941, loss_freq: 0.042777
[14:51:45.941] iteration 16269: loss: 0.090322, loss_s1: 0.026960, loss_fp: 0.019417, loss_freq: 0.099232
[14:51:46.600] iteration 16270: loss: 0.071314, loss_s1: 0.013257, loss_fp: 0.000686, loss_freq: 0.014293
[14:51:47.233] iteration 16271: loss: 0.061964, loss_s1: 0.055679, loss_fp: 0.000761, loss_freq: 0.034733
[14:51:47.881] iteration 16272: loss: 0.057570, loss_s1: 0.040749, loss_fp: 0.001992, loss_freq: 0.018178
[14:51:48.507] iteration 16273: loss: 0.057632, loss_s1: 0.047068, loss_fp: 0.002609, loss_freq: 0.018453
[14:51:49.135] iteration 16274: loss: 0.072398, loss_s1: 0.043344, loss_fp: 0.001956, loss_freq: 0.029325
[14:51:49.768] iteration 16275: loss: 0.065375, loss_s1: 0.050540, loss_fp: 0.002013, loss_freq: 0.018295
[14:51:50.390] iteration 16276: loss: 0.056535, loss_s1: 0.040909, loss_fp: 0.001820, loss_freq: 0.016613
[14:51:51.021] iteration 16277: loss: 0.078859, loss_s1: 0.046901, loss_fp: 0.001704, loss_freq: 0.048439
[14:51:51.649] iteration 16278: loss: 0.077066, loss_s1: 0.069005, loss_fp: 0.001404, loss_freq: 0.023404
[14:51:52.276] iteration 16279: loss: 0.094092, loss_s1: 0.069368, loss_fp: 0.003668, loss_freq: 0.043365
[14:51:52.902] iteration 16280: loss: 0.070936, loss_s1: 0.023723, loss_fp: 0.002568, loss_freq: 0.060879
[14:51:53.552] iteration 16281: loss: 0.109827, loss_s1: 0.088354, loss_fp: 0.003844, loss_freq: 0.019318
[14:51:54.187] iteration 16282: loss: 0.032804, loss_s1: 0.016885, loss_fp: 0.001872, loss_freq: 0.007384
[14:51:54.817] iteration 16283: loss: 0.053815, loss_s1: 0.028973, loss_fp: 0.001693, loss_freq: 0.033486
[14:51:55.445] iteration 16284: loss: 0.042676, loss_s1: 0.035967, loss_fp: 0.003192, loss_freq: 0.007661
[14:51:56.074] iteration 16285: loss: 0.068246, loss_s1: 0.053229, loss_fp: 0.008200, loss_freq: 0.008054
[14:51:56.696] iteration 16286: loss: 0.045280, loss_s1: 0.023063, loss_fp: 0.000836, loss_freq: 0.026488
[14:51:57.329] iteration 16287: loss: 0.047184, loss_s1: 0.012794, loss_fp: 0.002442, loss_freq: 0.033623
[14:51:57.996] iteration 16288: loss: 0.072335, loss_s1: 0.054709, loss_fp: 0.001288, loss_freq: 0.009492
[14:51:58.649] iteration 16289: loss: 0.052994, loss_s1: 0.040319, loss_fp: 0.001909, loss_freq: 0.005919
[14:51:59.278] iteration 16290: loss: 0.066278, loss_s1: 0.045641, loss_fp: 0.005357, loss_freq: 0.020295
[14:51:59.900] iteration 16291: loss: 0.063502, loss_s1: 0.050817, loss_fp: 0.003805, loss_freq: 0.025932
[14:52:00.524] iteration 16292: loss: 0.066611, loss_s1: 0.051808, loss_fp: 0.001990, loss_freq: 0.026332
[14:52:01.157] iteration 16293: loss: 0.096302, loss_s1: 0.048009, loss_fp: 0.002446, loss_freq: 0.052943
[14:52:01.785] iteration 16294: loss: 0.082865, loss_s1: 0.065932, loss_fp: 0.006539, loss_freq: 0.021079
[14:52:02.419] iteration 16295: loss: 0.088940, loss_s1: 0.058013, loss_fp: 0.001122, loss_freq: 0.028152
[14:52:03.043] iteration 16296: loss: 0.058088, loss_s1: 0.025874, loss_fp: 0.006429, loss_freq: 0.035140
[14:52:03.671] iteration 16297: loss: 0.046106, loss_s1: 0.028677, loss_fp: 0.001377, loss_freq: 0.012220
[14:52:04.337] iteration 16298: loss: 0.055637, loss_s1: 0.041880, loss_fp: 0.000871, loss_freq: 0.016245
[14:52:04.964] iteration 16299: loss: 0.056701, loss_s1: 0.046068, loss_fp: 0.002118, loss_freq: 0.010612
[14:52:05.580] iteration 16300: loss: 0.057431, loss_s1: 0.041133, loss_fp: 0.001891, loss_freq: 0.027094
[14:52:06.226] iteration 16301: loss: 0.092377, loss_s1: 0.056041, loss_fp: 0.022103, loss_freq: 0.051544
[14:52:06.842] iteration 16302: loss: 0.059713, loss_s1: 0.041965, loss_fp: 0.004110, loss_freq: 0.027363
[14:52:07.787] iteration 16303: loss: 0.058397, loss_s1: 0.034428, loss_fp: 0.005775, loss_freq: 0.030927
[14:52:08.431] iteration 16304: loss: 0.073913, loss_s1: 0.070761, loss_fp: 0.001720, loss_freq: 0.023035
[14:52:09.064] iteration 16305: loss: 0.060701, loss_s1: 0.016102, loss_fp: 0.002507, loss_freq: 0.059611
[14:52:09.695] iteration 16306: loss: 0.055928, loss_s1: 0.038211, loss_fp: 0.004048, loss_freq: 0.013637
[14:52:10.338] iteration 16307: loss: 0.057715, loss_s1: 0.048699, loss_fp: 0.003239, loss_freq: 0.027080
[14:52:10.973] iteration 16308: loss: 0.083124, loss_s1: 0.045865, loss_fp: 0.001338, loss_freq: 0.002252
[14:52:11.642] iteration 16309: loss: 0.044781, loss_s1: 0.050116, loss_fp: 0.002235, loss_freq: 0.008096
[14:52:12.276] iteration 16310: loss: 0.073501, loss_s1: 0.032079, loss_fp: 0.004143, loss_freq: 0.024390
[14:52:12.908] iteration 16311: loss: 0.060338, loss_s1: 0.033135, loss_fp: 0.001980, loss_freq: 0.027107
[14:52:13.537] iteration 16312: loss: 0.050605, loss_s1: 0.013552, loss_fp: 0.001294, loss_freq: 0.008729
[14:52:14.184] iteration 16313: loss: 0.101269, loss_s1: 0.077926, loss_fp: 0.007607, loss_freq: 0.062619
[14:52:14.845] iteration 16314: loss: 0.054082, loss_s1: 0.020214, loss_fp: 0.004657, loss_freq: 0.019409
[14:52:15.486] iteration 16315: loss: 0.089487, loss_s1: 0.032526, loss_fp: 0.006423, loss_freq: 0.081541
[14:52:16.128] iteration 16316: loss: 0.044524, loss_s1: 0.022140, loss_fp: 0.005589, loss_freq: 0.007857
[14:52:16.777] iteration 16317: loss: 0.079500, loss_s1: 0.073060, loss_fp: 0.005044, loss_freq: 0.031797
[14:52:17.410] iteration 16318: loss: 0.046081, loss_s1: 0.030374, loss_fp: 0.002434, loss_freq: 0.017211
[14:52:18.042] iteration 16319: loss: 0.052956, loss_s1: 0.022861, loss_fp: 0.001892, loss_freq: 0.011923
[14:52:18.674] iteration 16320: loss: 0.039709, loss_s1: 0.017186, loss_fp: 0.002251, loss_freq: 0.014935
[14:52:19.310] iteration 16321: loss: 0.038245, loss_s1: 0.022907, loss_fp: 0.001262, loss_freq: 0.018810
[14:52:19.945] iteration 16322: loss: 0.063054, loss_s1: 0.028080, loss_fp: 0.000822, loss_freq: 0.013396
[14:52:20.588] iteration 16323: loss: 0.097633, loss_s1: 0.047785, loss_fp: 0.001404, loss_freq: 0.065898
[14:52:21.268] iteration 16324: loss: 0.059580, loss_s1: 0.049528, loss_fp: 0.001490, loss_freq: 0.021497
[14:52:21.945] iteration 16325: loss: 0.063998, loss_s1: 0.038301, loss_fp: 0.000892, loss_freq: 0.050333
[14:52:22.622] iteration 16326: loss: 0.050861, loss_s1: 0.044075, loss_fp: 0.004485, loss_freq: 0.010806
[14:52:23.297] iteration 16327: loss: 0.044744, loss_s1: 0.016913, loss_fp: 0.001950, loss_freq: 0.016006
[14:52:23.948] iteration 16328: loss: 0.040280, loss_s1: 0.006313, loss_fp: 0.016712, loss_freq: 0.011626
[14:52:24.571] iteration 16329: loss: 0.096711, loss_s1: 0.072202, loss_fp: 0.003581, loss_freq: 0.052910
[14:52:25.202] iteration 16330: loss: 0.039851, loss_s1: 0.018587, loss_fp: 0.003422, loss_freq: 0.011078
[14:52:25.836] iteration 16331: loss: 0.102215, loss_s1: 0.060835, loss_fp: 0.001351, loss_freq: 0.024985
[14:52:26.467] iteration 16332: loss: 0.063717, loss_s1: 0.037949, loss_fp: 0.000787, loss_freq: 0.020562
[14:52:27.099] iteration 16333: loss: 0.058691, loss_s1: 0.037265, loss_fp: 0.006828, loss_freq: 0.017090
[14:52:27.729] iteration 16334: loss: 0.104085, loss_s1: 0.121368, loss_fp: 0.006484, loss_freq: 0.031815
[14:52:28.568] iteration 16335: loss: 0.059423, loss_s1: 0.049618, loss_fp: 0.012514, loss_freq: 0.025604
[14:52:29.565] iteration 16336: loss: 0.106605, loss_s1: 0.117755, loss_fp: 0.005986, loss_freq: 0.040736
[14:52:30.547] iteration 16337: loss: 0.110197, loss_s1: 0.102226, loss_fp: 0.010532, loss_freq: 0.027739
[14:52:31.180] iteration 16338: loss: 0.047699, loss_s1: 0.026410, loss_fp: 0.002271, loss_freq: 0.014786
[14:52:31.813] iteration 16339: loss: 0.067554, loss_s1: 0.028967, loss_fp: 0.011153, loss_freq: 0.042243
[14:52:32.454] iteration 16340: loss: 0.064021, loss_s1: 0.039245, loss_fp: 0.004362, loss_freq: 0.036667
[14:52:33.090] iteration 16341: loss: 0.069795, loss_s1: 0.063208, loss_fp: 0.001462, loss_freq: 0.030231
[14:52:33.721] iteration 16342: loss: 0.058316, loss_s1: 0.058793, loss_fp: 0.011277, loss_freq: 0.009782
[14:52:34.359] iteration 16343: loss: 0.118536, loss_s1: 0.094946, loss_fp: 0.031656, loss_freq: 0.056820
[14:52:34.991] iteration 16344: loss: 0.067645, loss_s1: 0.039820, loss_fp: 0.011297, loss_freq: 0.036745
[14:52:35.626] iteration 16345: loss: 0.044008, loss_s1: 0.011351, loss_fp: 0.000760, loss_freq: 0.019255
[14:52:36.251] iteration 16346: loss: 0.065124, loss_s1: 0.051355, loss_fp: 0.002831, loss_freq: 0.017126
[14:52:36.877] iteration 16347: loss: 0.076692, loss_s1: 0.026984, loss_fp: 0.001353, loss_freq: 0.031049
[14:52:37.516] iteration 16348: loss: 0.066724, loss_s1: 0.033574, loss_fp: 0.000442, loss_freq: 0.028342
[14:52:38.148] iteration 16349: loss: 0.050177, loss_s1: 0.036205, loss_fp: 0.001637, loss_freq: 0.018466
[14:52:38.819] iteration 16350: loss: 0.055405, loss_s1: 0.018341, loss_fp: 0.006655, loss_freq: 0.042921
[14:52:39.461] iteration 16351: loss: 0.072666, loss_s1: 0.074888, loss_fp: 0.001987, loss_freq: 0.019945
[14:52:40.108] iteration 16352: loss: 0.043240, loss_s1: 0.026706, loss_fp: 0.002145, loss_freq: 0.014780
[14:52:40.744] iteration 16353: loss: 0.065939, loss_s1: 0.059083, loss_fp: 0.001161, loss_freq: 0.029939
[14:52:41.372] iteration 16354: loss: 0.062323, loss_s1: 0.019994, loss_fp: 0.002493, loss_freq: 0.038961
[14:52:42.002] iteration 16355: loss: 0.039174, loss_s1: 0.024487, loss_fp: 0.001768, loss_freq: 0.011731
[14:52:42.629] iteration 16356: loss: 0.041459, loss_s1: 0.023086, loss_fp: 0.000323, loss_freq: 0.012326
[14:52:43.275] iteration 16357: loss: 0.060094, loss_s1: 0.040901, loss_fp: 0.002532, loss_freq: 0.019524
[14:52:43.908] iteration 16358: loss: 0.087028, loss_s1: 0.017638, loss_fp: 0.002150, loss_freq: 0.011205
[14:52:44.553] iteration 16359: loss: 0.053967, loss_s1: 0.044274, loss_fp: 0.001396, loss_freq: 0.009089
[14:52:45.203] iteration 16360: loss: 0.063253, loss_s1: 0.043326, loss_fp: 0.003902, loss_freq: 0.026623
[14:52:45.848] iteration 16361: loss: 0.112371, loss_s1: 0.089966, loss_fp: 0.005498, loss_freq: 0.059990
[14:52:46.490] iteration 16362: loss: 0.063980, loss_s1: 0.045289, loss_fp: 0.001373, loss_freq: 0.031558
[14:52:47.157] iteration 16363: loss: 0.086762, loss_s1: 0.033450, loss_fp: 0.003440, loss_freq: 0.017889
[14:52:47.814] iteration 16364: loss: 0.048177, loss_s1: 0.036846, loss_fp: 0.002290, loss_freq: 0.011352
[14:52:48.444] iteration 16365: loss: 0.079376, loss_s1: 0.039895, loss_fp: 0.004504, loss_freq: 0.061899
[14:52:49.073] iteration 16366: loss: 0.059093, loss_s1: 0.025470, loss_fp: 0.003491, loss_freq: 0.038509
[14:52:49.695] iteration 16367: loss: 0.091659, loss_s1: 0.084049, loss_fp: 0.008432, loss_freq: 0.030295
[14:52:50.331] iteration 16368: loss: 0.074087, loss_s1: 0.050183, loss_fp: 0.003020, loss_freq: 0.015655
[14:52:50.960] iteration 16369: loss: 0.065666, loss_s1: 0.056114, loss_fp: 0.003548, loss_freq: 0.017830
[14:52:51.583] iteration 16370: loss: 0.057846, loss_s1: 0.044726, loss_fp: 0.003557, loss_freq: 0.026849
[14:52:52.208] iteration 16371: loss: 0.045299, loss_s1: 0.022840, loss_fp: 0.001727, loss_freq: 0.014414
[14:52:52.832] iteration 16372: loss: 0.048519, loss_s1: 0.023663, loss_fp: 0.001236, loss_freq: 0.012205
[14:52:53.457] iteration 16373: loss: 0.074622, loss_s1: 0.062420, loss_fp: 0.004476, loss_freq: 0.022895
[14:52:54.085] iteration 16374: loss: 0.069248, loss_s1: 0.042124, loss_fp: 0.011884, loss_freq: 0.030103
[14:52:54.765] iteration 16375: loss: 0.061172, loss_s1: 0.032179, loss_fp: 0.000634, loss_freq: 0.054173
[14:52:55.424] iteration 16376: loss: 0.072335, loss_s1: 0.060125, loss_fp: 0.006272, loss_freq: 0.027101
[14:52:56.083] iteration 16377: loss: 0.065331, loss_s1: 0.054448, loss_fp: 0.007829, loss_freq: 0.019282
[14:52:56.706] iteration 16378: loss: 0.055564, loss_s1: 0.058567, loss_fp: 0.002796, loss_freq: 0.009453
[14:52:57.328] iteration 16379: loss: 0.067806, loss_s1: 0.057037, loss_fp: 0.006767, loss_freq: 0.038620
[14:52:58.026] iteration 16380: loss: 0.040720, loss_s1: 0.020459, loss_fp: 0.002422, loss_freq: 0.014887
[14:52:58.695] iteration 16381: loss: 0.064895, loss_s1: 0.033352, loss_fp: 0.010807, loss_freq: 0.046999
[14:52:59.364] iteration 16382: loss: 0.124541, loss_s1: 0.066469, loss_fp: 0.002764, loss_freq: 0.043132
[14:53:00.016] iteration 16383: loss: 0.081819, loss_s1: 0.014687, loss_fp: 0.001835, loss_freq: 0.049600
[14:53:00.646] iteration 16384: loss: 0.064359, loss_s1: 0.041475, loss_fp: 0.010024, loss_freq: 0.019639
[14:53:01.281] iteration 16385: loss: 0.082476, loss_s1: 0.063613, loss_fp: 0.004712, loss_freq: 0.043067
[14:53:01.973] iteration 16386: loss: 0.050390, loss_s1: 0.035789, loss_fp: 0.002265, loss_freq: 0.023436
[14:53:02.672] iteration 16387: loss: 0.047925, loss_s1: 0.039581, loss_fp: 0.002497, loss_freq: 0.005538
[14:53:03.361] iteration 16388: loss: 0.060573, loss_s1: 0.032704, loss_fp: 0.006582, loss_freq: 0.035135
[14:53:04.038] iteration 16389: loss: 0.061513, loss_s1: 0.024708, loss_fp: 0.003185, loss_freq: 0.011708
[14:53:04.717] iteration 16390: loss: 0.061186, loss_s1: 0.022983, loss_fp: 0.000957, loss_freq: 0.055752
[14:53:05.370] iteration 16391: loss: 0.037040, loss_s1: 0.022207, loss_fp: 0.002712, loss_freq: 0.017047
[14:53:06.010] iteration 16392: loss: 0.069986, loss_s1: 0.063631, loss_fp: 0.003090, loss_freq: 0.033856
[14:53:06.649] iteration 16393: loss: 0.087605, loss_s1: 0.028094, loss_fp: 0.013170, loss_freq: 0.024744
[14:53:07.279] iteration 16394: loss: 0.060005, loss_s1: 0.033779, loss_fp: 0.002838, loss_freq: 0.041170
[14:53:07.917] iteration 16395: loss: 0.062524, loss_s1: 0.058883, loss_fp: 0.001630, loss_freq: 0.014428
[14:53:08.583] iteration 16396: loss: 0.070993, loss_s1: 0.040498, loss_fp: 0.000769, loss_freq: 0.010169
[14:53:09.255] iteration 16397: loss: 0.054661, loss_s1: 0.024211, loss_fp: 0.001963, loss_freq: 0.033307
[14:53:09.908] iteration 16398: loss: 0.057676, loss_s1: 0.035086, loss_fp: 0.000677, loss_freq: 0.009826
[14:53:10.612] iteration 16399: loss: 0.093696, loss_s1: 0.056683, loss_fp: 0.005125, loss_freq: 0.085123
[14:53:11.271] iteration 16400: loss: 0.056745, loss_s1: 0.038154, loss_fp: 0.002130, loss_freq: 0.019985
[14:53:15.039] iteration 16400 : mean_dice : 0.786082
[14:53:15.751] iteration 16401: loss: 0.053309, loss_s1: 0.022956, loss_fp: 0.001050, loss_freq: 0.019665
[14:53:16.422] iteration 16402: loss: 0.098123, loss_s1: 0.042475, loss_fp: 0.010065, loss_freq: 0.047568
[14:53:17.094] iteration 16403: loss: 0.068032, loss_s1: 0.051856, loss_fp: 0.002250, loss_freq: 0.021455
[14:53:17.758] iteration 16404: loss: 0.076482, loss_s1: 0.047403, loss_fp: 0.002629, loss_freq: 0.038573
[14:53:18.417] iteration 16405: loss: 0.074328, loss_s1: 0.056205, loss_fp: 0.002422, loss_freq: 0.052273
[14:53:19.051] iteration 16406: loss: 0.066904, loss_s1: 0.050865, loss_fp: 0.007171, loss_freq: 0.019371
[14:53:19.683] iteration 16407: loss: 0.059645, loss_s1: 0.033833, loss_fp: 0.001630, loss_freq: 0.019386
[14:53:20.312] iteration 16408: loss: 0.037759, loss_s1: 0.017976, loss_fp: 0.002629, loss_freq: 0.019776
[14:53:20.941] iteration 16409: loss: 0.107459, loss_s1: 0.117917, loss_fp: 0.002743, loss_freq: 0.036996
[14:53:21.574] iteration 16410: loss: 0.045496, loss_s1: 0.011440, loss_fp: 0.003130, loss_freq: 0.034811
[14:53:22.201] iteration 16411: loss: 0.061009, loss_s1: 0.028155, loss_fp: 0.002300, loss_freq: 0.022398
[14:53:22.824] iteration 16412: loss: 0.071725, loss_s1: 0.035272, loss_fp: 0.004020, loss_freq: 0.058339
[14:53:23.454] iteration 16413: loss: 0.100305, loss_s1: 0.072404, loss_fp: 0.003178, loss_freq: 0.023931
[14:53:24.088] iteration 16414: loss: 0.052421, loss_s1: 0.046941, loss_fp: 0.002354, loss_freq: 0.025374
[14:53:24.710] iteration 16415: loss: 0.051760, loss_s1: 0.035212, loss_fp: 0.001420, loss_freq: 0.012051
[14:53:25.337] iteration 16416: loss: 0.076444, loss_s1: 0.047234, loss_fp: 0.008936, loss_freq: 0.050739
[14:53:25.965] iteration 16417: loss: 0.065833, loss_s1: 0.046017, loss_fp: 0.003855, loss_freq: 0.023634
[14:53:26.591] iteration 16418: loss: 0.044439, loss_s1: 0.031360, loss_fp: 0.001722, loss_freq: 0.012084
[14:53:27.223] iteration 16419: loss: 0.057005, loss_s1: 0.025544, loss_fp: 0.006228, loss_freq: 0.030443
[14:53:27.853] iteration 16420: loss: 0.066210, loss_s1: 0.078149, loss_fp: 0.001850, loss_freq: 0.016468
[14:53:28.481] iteration 16421: loss: 0.039938, loss_s1: 0.021256, loss_fp: 0.001258, loss_freq: 0.020352
[14:53:29.109] iteration 16422: loss: 0.065513, loss_s1: 0.037243, loss_fp: 0.003111, loss_freq: 0.029486
[14:53:29.734] iteration 16423: loss: 0.086455, loss_s1: 0.063822, loss_fp: 0.001257, loss_freq: 0.054669
[14:53:30.353] iteration 16424: loss: 0.066631, loss_s1: 0.050517, loss_fp: 0.001879, loss_freq: 0.020647
[14:53:30.981] iteration 16425: loss: 0.052499, loss_s1: 0.040641, loss_fp: 0.002644, loss_freq: 0.005873
[14:53:31.598] iteration 16426: loss: 0.069795, loss_s1: 0.070352, loss_fp: 0.002784, loss_freq: 0.022681
[14:53:32.224] iteration 16427: loss: 0.067763, loss_s1: 0.048585, loss_fp: 0.010367, loss_freq: 0.036269
[14:53:32.849] iteration 16428: loss: 0.055077, loss_s1: 0.021551, loss_fp: 0.001130, loss_freq: 0.028339
[14:53:33.465] iteration 16429: loss: 0.054010, loss_s1: 0.046217, loss_fp: 0.001948, loss_freq: 0.023348
[14:53:34.127] iteration 16430: loss: 0.044290, loss_s1: 0.022227, loss_fp: 0.001776, loss_freq: 0.025702
[14:53:34.787] iteration 16431: loss: 0.059513, loss_s1: 0.059186, loss_fp: 0.002762, loss_freq: 0.008107
[14:53:35.432] iteration 16432: loss: 0.046159, loss_s1: 0.013642, loss_fp: 0.003855, loss_freq: 0.008794
[14:53:36.063] iteration 16433: loss: 0.055687, loss_s1: 0.035349, loss_fp: 0.008252, loss_freq: 0.018327
[14:53:36.690] iteration 16434: loss: 0.046728, loss_s1: 0.032315, loss_fp: 0.005122, loss_freq: 0.017923
[14:53:37.312] iteration 16435: loss: 0.053935, loss_s1: 0.032215, loss_fp: 0.006286, loss_freq: 0.022878
[14:53:37.970] iteration 16436: loss: 0.096401, loss_s1: 0.048076, loss_fp: 0.003577, loss_freq: 0.076692
[14:53:38.591] iteration 16437: loss: 0.086230, loss_s1: 0.034564, loss_fp: 0.012476, loss_freq: 0.049749
[14:53:39.204] iteration 16438: loss: 0.066104, loss_s1: 0.063157, loss_fp: 0.004580, loss_freq: 0.021968
[14:53:39.827] iteration 16439: loss: 0.076423, loss_s1: 0.071382, loss_fp: 0.003949, loss_freq: 0.023414
[14:53:40.490] iteration 16440: loss: 0.055273, loss_s1: 0.024388, loss_fp: 0.001290, loss_freq: 0.020564
[14:53:41.152] iteration 16441: loss: 0.054408, loss_s1: 0.036198, loss_fp: 0.001667, loss_freq: 0.032276
[14:53:41.810] iteration 16442: loss: 0.059259, loss_s1: 0.054127, loss_fp: 0.002230, loss_freq: 0.019376
[14:53:42.439] iteration 16443: loss: 0.058269, loss_s1: 0.039941, loss_fp: 0.005314, loss_freq: 0.032847
[14:53:43.070] iteration 16444: loss: 0.109112, loss_s1: 0.093015, loss_fp: 0.003871, loss_freq: 0.071292
[14:53:43.719] iteration 16445: loss: 0.037268, loss_s1: 0.010752, loss_fp: 0.001113, loss_freq: 0.028771
[14:53:44.673] iteration 16446: loss: 0.047474, loss_s1: 0.040930, loss_fp: 0.008516, loss_freq: 0.006614
[14:53:45.348] iteration 16447: loss: 0.059633, loss_s1: 0.051893, loss_fp: 0.002613, loss_freq: 0.016192
[14:53:46.027] iteration 16448: loss: 0.037397, loss_s1: 0.029317, loss_fp: 0.000568, loss_freq: 0.008699
[14:53:46.704] iteration 16449: loss: 0.074876, loss_s1: 0.060445, loss_fp: 0.001148, loss_freq: 0.019234
[14:53:47.363] iteration 16450: loss: 0.078004, loss_s1: 0.047329, loss_fp: 0.002025, loss_freq: 0.070847
[14:53:48.015] iteration 16451: loss: 0.065861, loss_s1: 0.015537, loss_fp: 0.002471, loss_freq: 0.012256
[14:53:48.641] iteration 16452: loss: 0.029299, loss_s1: 0.011754, loss_fp: 0.003174, loss_freq: 0.011248
[14:53:49.264] iteration 16453: loss: 0.102180, loss_s1: 0.066383, loss_fp: 0.004184, loss_freq: 0.035439
[14:53:49.898] iteration 16454: loss: 0.066223, loss_s1: 0.043633, loss_fp: 0.003920, loss_freq: 0.030521
[14:53:50.528] iteration 16455: loss: 0.054029, loss_s1: 0.028165, loss_fp: 0.000551, loss_freq: 0.010598
[14:53:51.182] iteration 16456: loss: 0.094789, loss_s1: 0.031847, loss_fp: 0.002957, loss_freq: 0.060633
[14:53:51.806] iteration 16457: loss: 0.063953, loss_s1: 0.012852, loss_fp: 0.001195, loss_freq: 0.050381
[14:53:52.449] iteration 16458: loss: 0.060420, loss_s1: 0.058637, loss_fp: 0.003097, loss_freq: 0.017231
[14:53:53.117] iteration 16459: loss: 0.029916, loss_s1: 0.018376, loss_fp: 0.002259, loss_freq: 0.004539
[14:53:53.750] iteration 16460: loss: 0.048310, loss_s1: 0.030106, loss_fp: 0.001196, loss_freq: 0.022364
[14:53:54.382] iteration 16461: loss: 0.038766, loss_s1: 0.014664, loss_fp: 0.000535, loss_freq: 0.009127
[14:53:55.007] iteration 16462: loss: 0.121212, loss_s1: 0.024716, loss_fp: 0.003092, loss_freq: 0.026441
[14:53:55.645] iteration 16463: loss: 0.035819, loss_s1: 0.017676, loss_fp: 0.004655, loss_freq: 0.011965
[14:53:56.276] iteration 16464: loss: 0.044700, loss_s1: 0.028593, loss_fp: 0.002048, loss_freq: 0.019481
[14:53:56.911] iteration 16465: loss: 0.051662, loss_s1: 0.045351, loss_fp: 0.001649, loss_freq: 0.014058
[14:53:57.533] iteration 16466: loss: 0.069416, loss_s1: 0.041363, loss_fp: 0.002123, loss_freq: 0.038231
[14:53:58.158] iteration 16467: loss: 0.050613, loss_s1: 0.051401, loss_fp: 0.001587, loss_freq: 0.013692
[14:53:58.791] iteration 16468: loss: 0.037575, loss_s1: 0.016640, loss_fp: 0.002760, loss_freq: 0.014986
[14:53:59.419] iteration 16469: loss: 0.043868, loss_s1: 0.013467, loss_fp: 0.001312, loss_freq: 0.012177
[14:54:00.050] iteration 16470: loss: 0.060581, loss_s1: 0.013602, loss_fp: 0.001908, loss_freq: 0.037506
[14:54:00.677] iteration 16471: loss: 0.080357, loss_s1: 0.051070, loss_fp: 0.001007, loss_freq: 0.047811
[14:54:01.302] iteration 16472: loss: 0.088905, loss_s1: 0.047882, loss_fp: 0.002066, loss_freq: 0.080484
[14:54:01.924] iteration 16473: loss: 0.036057, loss_s1: 0.019940, loss_fp: 0.001147, loss_freq: 0.008573
[14:54:02.552] iteration 16474: loss: 0.088736, loss_s1: 0.044723, loss_fp: 0.001322, loss_freq: 0.083166
[14:54:03.180] iteration 16475: loss: 0.057795, loss_s1: 0.025282, loss_fp: 0.001057, loss_freq: 0.016228
[14:54:03.851] iteration 16476: loss: 0.052555, loss_s1: 0.034639, loss_fp: 0.004426, loss_freq: 0.009529
[14:54:04.485] iteration 16477: loss: 0.066574, loss_s1: 0.039340, loss_fp: 0.004655, loss_freq: 0.032656
[14:54:05.111] iteration 16478: loss: 0.051567, loss_s1: 0.029871, loss_fp: 0.010411, loss_freq: 0.024748
[14:54:05.739] iteration 16479: loss: 0.097815, loss_s1: 0.067563, loss_fp: 0.007666, loss_freq: 0.072617
[14:54:06.372] iteration 16480: loss: 0.096167, loss_s1: 0.023170, loss_fp: 0.007594, loss_freq: 0.027754
[14:54:07.005] iteration 16481: loss: 0.078703, loss_s1: 0.060490, loss_fp: 0.004532, loss_freq: 0.033284
[14:54:07.641] iteration 16482: loss: 0.047183, loss_s1: 0.024264, loss_fp: 0.000805, loss_freq: 0.018955
[14:54:08.276] iteration 16483: loss: 0.061520, loss_s1: 0.030541, loss_fp: 0.001811, loss_freq: 0.052146
[14:54:08.913] iteration 16484: loss: 0.066991, loss_s1: 0.030865, loss_fp: 0.003594, loss_freq: 0.050020
[14:54:09.565] iteration 16485: loss: 0.043440, loss_s1: 0.029652, loss_fp: 0.007812, loss_freq: 0.014710
[14:54:10.217] iteration 16486: loss: 0.080403, loss_s1: 0.106043, loss_fp: 0.005033, loss_freq: 0.004669
[14:54:10.858] iteration 16487: loss: 0.039476, loss_s1: 0.028235, loss_fp: 0.001471, loss_freq: 0.019658
[14:54:11.515] iteration 16488: loss: 0.040940, loss_s1: 0.007393, loss_fp: 0.001052, loss_freq: 0.014110
[14:54:12.154] iteration 16489: loss: 0.077084, loss_s1: 0.068791, loss_fp: 0.007929, loss_freq: 0.031771
[14:54:12.795] iteration 16490: loss: 0.058416, loss_s1: 0.018289, loss_fp: 0.000813, loss_freq: 0.011806
[14:54:13.431] iteration 16491: loss: 0.059549, loss_s1: 0.024448, loss_fp: 0.001809, loss_freq: 0.027268
[14:54:14.074] iteration 16492: loss: 0.051795, loss_s1: 0.020844, loss_fp: 0.001434, loss_freq: 0.020142
[14:54:14.713] iteration 16493: loss: 0.079956, loss_s1: 0.073836, loss_fp: 0.006491, loss_freq: 0.031665
[14:54:15.354] iteration 16494: loss: 0.079301, loss_s1: 0.098065, loss_fp: 0.002142, loss_freq: 0.024166
[14:54:15.991] iteration 16495: loss: 0.051581, loss_s1: 0.040203, loss_fp: 0.004743, loss_freq: 0.011245
[14:54:16.634] iteration 16496: loss: 0.045151, loss_s1: 0.014903, loss_fp: 0.007389, loss_freq: 0.016462
[14:54:17.274] iteration 16497: loss: 0.070406, loss_s1: 0.059342, loss_fp: 0.004215, loss_freq: 0.023546
[14:54:17.901] iteration 16498: loss: 0.041131, loss_s1: 0.018030, loss_fp: 0.006290, loss_freq: 0.013610
[14:54:18.528] iteration 16499: loss: 0.039168, loss_s1: 0.025956, loss_fp: 0.001951, loss_freq: 0.015745
[14:54:19.147] iteration 16500: loss: 0.030285, loss_s1: 0.012736, loss_fp: 0.003467, loss_freq: 0.004085
[14:54:19.778] iteration 16501: loss: 0.041695, loss_s1: 0.018760, loss_fp: 0.001848, loss_freq: 0.011696
[14:54:20.467] iteration 16502: loss: 0.056921, loss_s1: 0.047795, loss_fp: 0.003701, loss_freq: 0.025590
[14:54:21.136] iteration 16503: loss: 0.043468, loss_s1: 0.030133, loss_fp: 0.003607, loss_freq: 0.006625
[14:54:21.801] iteration 16504: loss: 0.054698, loss_s1: 0.027354, loss_fp: 0.000904, loss_freq: 0.036162
[14:54:22.472] iteration 16505: loss: 0.067343, loss_s1: 0.044222, loss_fp: 0.000764, loss_freq: 0.042666
[14:54:23.152] iteration 16506: loss: 0.048455, loss_s1: 0.032406, loss_fp: 0.001390, loss_freq: 0.009498
[14:54:23.781] iteration 16507: loss: 0.063288, loss_s1: 0.036437, loss_fp: 0.000508, loss_freq: 0.011150
[14:54:24.411] iteration 16508: loss: 0.070648, loss_s1: 0.054323, loss_fp: 0.005536, loss_freq: 0.033373
[14:54:25.031] iteration 16509: loss: 0.057056, loss_s1: 0.039198, loss_fp: 0.001875, loss_freq: 0.022038
[14:54:25.657] iteration 16510: loss: 0.071360, loss_s1: 0.036368, loss_fp: 0.007722, loss_freq: 0.012735
[14:54:26.275] iteration 16511: loss: 0.073398, loss_s1: 0.035068, loss_fp: 0.000916, loss_freq: 0.044781
[14:54:26.902] iteration 16512: loss: 0.057591, loss_s1: 0.032122, loss_fp: 0.002703, loss_freq: 0.032314
[14:54:27.534] iteration 16513: loss: 0.045510, loss_s1: 0.029332, loss_fp: 0.001777, loss_freq: 0.011451
[14:54:28.159] iteration 16514: loss: 0.032000, loss_s1: 0.009301, loss_fp: 0.001906, loss_freq: 0.008007
[14:54:28.780] iteration 16515: loss: 0.035385, loss_s1: 0.019366, loss_fp: 0.006194, loss_freq: 0.001921
[14:54:29.407] iteration 16516: loss: 0.050114, loss_s1: 0.022008, loss_fp: 0.004101, loss_freq: 0.025344
[14:54:30.031] iteration 16517: loss: 0.063369, loss_s1: 0.035799, loss_fp: 0.005262, loss_freq: 0.038477
[14:54:30.646] iteration 16518: loss: 0.062161, loss_s1: 0.027025, loss_fp: 0.002550, loss_freq: 0.047611
[14:54:31.267] iteration 16519: loss: 0.089300, loss_s1: 0.071597, loss_fp: 0.014579, loss_freq: 0.025869
[14:54:31.890] iteration 16520: loss: 0.096900, loss_s1: 0.086405, loss_fp: 0.015470, loss_freq: 0.047568
[14:54:32.512] iteration 16521: loss: 0.052680, loss_s1: 0.039406, loss_fp: 0.003564, loss_freq: 0.017638
[14:54:33.130] iteration 16522: loss: 0.081371, loss_s1: 0.086603, loss_fp: 0.001772, loss_freq: 0.039445
[14:54:33.755] iteration 16523: loss: 0.072988, loss_s1: 0.045611, loss_fp: 0.004206, loss_freq: 0.022124
[14:54:34.499] iteration 16524: loss: 0.074279, loss_s1: 0.057405, loss_fp: 0.007714, loss_freq: 0.029517
[14:54:35.169] iteration 16525: loss: 0.112514, loss_s1: 0.103205, loss_fp: 0.008781, loss_freq: 0.023630
[14:54:35.824] iteration 16526: loss: 0.067652, loss_s1: 0.042624, loss_fp: 0.002677, loss_freq: 0.037019
[14:54:36.448] iteration 16527: loss: 0.064919, loss_s1: 0.053852, loss_fp: 0.001320, loss_freq: 0.032399
[14:54:37.073] iteration 16528: loss: 0.039469, loss_s1: 0.022528, loss_fp: 0.000457, loss_freq: 0.004353
[14:54:37.698] iteration 16529: loss: 0.054617, loss_s1: 0.039542, loss_fp: 0.000999, loss_freq: 0.024576
[14:54:38.321] iteration 16530: loss: 0.051810, loss_s1: 0.022988, loss_fp: 0.006717, loss_freq: 0.020608
[14:54:38.947] iteration 16531: loss: 0.098080, loss_s1: 0.040833, loss_fp: 0.006646, loss_freq: 0.045256
[14:54:39.578] iteration 16532: loss: 0.046475, loss_s1: 0.024897, loss_fp: 0.003070, loss_freq: 0.007517
[14:54:40.196] iteration 16533: loss: 0.063749, loss_s1: 0.047959, loss_fp: 0.002270, loss_freq: 0.031134
[14:54:40.825] iteration 16534: loss: 0.052493, loss_s1: 0.041326, loss_fp: 0.017406, loss_freq: 0.011197
[14:54:41.445] iteration 16535: loss: 0.086305, loss_s1: 0.073036, loss_fp: 0.002495, loss_freq: 0.040157
[14:54:42.071] iteration 16536: loss: 0.050271, loss_s1: 0.014797, loss_fp: 0.001298, loss_freq: 0.014465
[14:54:42.694] iteration 16537: loss: 0.047506, loss_s1: 0.024305, loss_fp: 0.003255, loss_freq: 0.032266
[14:54:43.322] iteration 16538: loss: 0.063025, loss_s1: 0.046543, loss_fp: 0.003595, loss_freq: 0.031282
[14:54:43.992] iteration 16539: loss: 0.109791, loss_s1: 0.042503, loss_fp: 0.003541, loss_freq: 0.032431
[14:54:44.617] iteration 16540: loss: 0.037632, loss_s1: 0.008863, loss_fp: 0.000791, loss_freq: 0.022427
[14:54:45.233] iteration 16541: loss: 0.035438, loss_s1: 0.012465, loss_fp: 0.003846, loss_freq: 0.008001
[14:54:45.851] iteration 16542: loss: 0.086341, loss_s1: 0.057656, loss_fp: 0.003604, loss_freq: 0.064191
[14:54:46.486] iteration 16543: loss: 0.046382, loss_s1: 0.024188, loss_fp: 0.001276, loss_freq: 0.017239
[14:54:47.119] iteration 16544: loss: 0.053380, loss_s1: 0.032804, loss_fp: 0.008614, loss_freq: 0.007580
[14:54:47.755] iteration 16545: loss: 0.064039, loss_s1: 0.035652, loss_fp: 0.004427, loss_freq: 0.022016
[14:54:48.390] iteration 16546: loss: 0.053974, loss_s1: 0.031250, loss_fp: 0.008126, loss_freq: 0.025887
[14:54:49.013] iteration 16547: loss: 0.074685, loss_s1: 0.037989, loss_fp: 0.005766, loss_freq: 0.041378
[14:54:49.645] iteration 16548: loss: 0.086456, loss_s1: 0.045739, loss_fp: 0.001956, loss_freq: 0.036851
[14:54:50.279] iteration 16549: loss: 0.048684, loss_s1: 0.027513, loss_fp: 0.004109, loss_freq: 0.022657
[14:54:50.910] iteration 16550: loss: 0.075494, loss_s1: 0.060437, loss_fp: 0.008864, loss_freq: 0.019348
[14:54:51.541] iteration 16551: loss: 0.100753, loss_s1: 0.084432, loss_fp: 0.003095, loss_freq: 0.029412
[14:54:52.168] iteration 16552: loss: 0.107615, loss_s1: 0.082705, loss_fp: 0.010706, loss_freq: 0.044757
[14:54:52.801] iteration 16553: loss: 0.040278, loss_s1: 0.022358, loss_fp: 0.006334, loss_freq: 0.022284
[14:54:53.435] iteration 16554: loss: 0.070974, loss_s1: 0.052494, loss_fp: 0.003731, loss_freq: 0.017852
[14:54:54.061] iteration 16555: loss: 0.069076, loss_s1: 0.040691, loss_fp: 0.031725, loss_freq: 0.020847
[14:54:54.687] iteration 16556: loss: 0.071295, loss_s1: 0.046056, loss_fp: 0.005001, loss_freq: 0.013497
[14:54:55.329] iteration 16557: loss: 0.110303, loss_s1: 0.124747, loss_fp: 0.000721, loss_freq: 0.061396
[14:54:55.969] iteration 16558: loss: 0.051272, loss_s1: 0.024673, loss_fp: 0.001776, loss_freq: 0.013716
[14:54:56.599] iteration 16559: loss: 0.059399, loss_s1: 0.036405, loss_fp: 0.003263, loss_freq: 0.032139
[14:54:57.275] iteration 16560: loss: 0.050687, loss_s1: 0.012471, loss_fp: 0.005144, loss_freq: 0.018744
[14:54:57.919] iteration 16561: loss: 0.044656, loss_s1: 0.030809, loss_fp: 0.001871, loss_freq: 0.018126
[14:54:58.581] iteration 16562: loss: 0.067996, loss_s1: 0.035084, loss_fp: 0.012642, loss_freq: 0.033973
[14:54:59.201] iteration 16563: loss: 0.042440, loss_s1: 0.019354, loss_fp: 0.002354, loss_freq: 0.011686
[14:54:59.827] iteration 16564: loss: 0.048741, loss_s1: 0.042265, loss_fp: 0.002992, loss_freq: 0.019672
[14:55:00.459] iteration 16565: loss: 0.071611, loss_s1: 0.038610, loss_fp: 0.001206, loss_freq: 0.024874
[14:55:01.113] iteration 16566: loss: 0.056224, loss_s1: 0.024739, loss_fp: 0.007259, loss_freq: 0.039738
[14:55:01.767] iteration 16567: loss: 0.050945, loss_s1: 0.026319, loss_fp: 0.004598, loss_freq: 0.022103
[14:55:02.412] iteration 16568: loss: 0.038465, loss_s1: 0.015920, loss_fp: 0.002289, loss_freq: 0.014738
[14:55:03.098] iteration 16569: loss: 0.053594, loss_s1: 0.042192, loss_fp: 0.007112, loss_freq: 0.023193
[14:55:03.779] iteration 16570: loss: 0.047331, loss_s1: 0.044053, loss_fp: 0.005135, loss_freq: 0.015195
[14:55:04.441] iteration 16571: loss: 0.059363, loss_s1: 0.045848, loss_fp: 0.003035, loss_freq: 0.019039
[14:55:05.092] iteration 16572: loss: 0.075631, loss_s1: 0.025205, loss_fp: 0.001214, loss_freq: 0.047018
[14:55:05.782] iteration 16573: loss: 0.054222, loss_s1: 0.030671, loss_fp: 0.006506, loss_freq: 0.026777
[14:55:06.443] iteration 16574: loss: 0.076656, loss_s1: 0.062974, loss_fp: 0.001083, loss_freq: 0.005530
[14:55:07.105] iteration 16575: loss: 0.044023, loss_s1: 0.024703, loss_fp: 0.002209, loss_freq: 0.012915
[14:55:07.765] iteration 16576: loss: 0.063677, loss_s1: 0.026094, loss_fp: 0.004211, loss_freq: 0.026157
[14:55:08.393] iteration 16577: loss: 0.042695, loss_s1: 0.024107, loss_fp: 0.002124, loss_freq: 0.009663
[14:55:09.015] iteration 16578: loss: 0.052757, loss_s1: 0.026408, loss_fp: 0.003771, loss_freq: 0.019901
[14:55:09.644] iteration 16579: loss: 0.101789, loss_s1: 0.051902, loss_fp: 0.002571, loss_freq: 0.074280
[14:55:10.267] iteration 16580: loss: 0.061970, loss_s1: 0.022719, loss_fp: 0.001480, loss_freq: 0.017331
[14:55:10.886] iteration 16581: loss: 0.051551, loss_s1: 0.043469, loss_fp: 0.006030, loss_freq: 0.013997
[14:55:11.566] iteration 16582: loss: 0.115694, loss_s1: 0.114210, loss_fp: 0.011854, loss_freq: 0.037024
[14:55:12.243] iteration 16583: loss: 0.069025, loss_s1: 0.029749, loss_fp: 0.004188, loss_freq: 0.015428
[14:55:12.919] iteration 16584: loss: 0.075962, loss_s1: 0.049919, loss_fp: 0.001146, loss_freq: 0.058292
[14:55:13.596] iteration 16585: loss: 0.052297, loss_s1: 0.034069, loss_fp: 0.005267, loss_freq: 0.018831
[14:55:14.243] iteration 16586: loss: 0.062265, loss_s1: 0.038186, loss_fp: 0.002429, loss_freq: 0.039671
[14:55:14.873] iteration 16587: loss: 0.145435, loss_s1: 0.109982, loss_fp: 0.012971, loss_freq: 0.083916
[14:55:15.511] iteration 16588: loss: 0.041882, loss_s1: 0.027306, loss_fp: 0.002178, loss_freq: 0.016231
[14:55:16.525] iteration 16589: loss: 0.046982, loss_s1: 0.036814, loss_fp: 0.000829, loss_freq: 0.008651
[14:55:17.145] iteration 16590: loss: 0.064136, loss_s1: 0.031664, loss_fp: 0.016622, loss_freq: 0.017796
[14:55:17.769] iteration 16591: loss: 0.028274, loss_s1: 0.009519, loss_fp: 0.001543, loss_freq: 0.007415
[14:55:18.394] iteration 16592: loss: 0.077256, loss_s1: 0.054775, loss_fp: 0.002946, loss_freq: 0.047696
[14:55:19.029] iteration 16593: loss: 0.086844, loss_s1: 0.077223, loss_fp: 0.027268, loss_freq: 0.032544
[14:55:19.675] iteration 16594: loss: 0.062856, loss_s1: 0.025359, loss_fp: 0.003798, loss_freq: 0.008100
[14:55:20.319] iteration 16595: loss: 0.042119, loss_s1: 0.023004, loss_fp: 0.002627, loss_freq: 0.025059
[14:55:20.956] iteration 16596: loss: 0.068566, loss_s1: 0.062795, loss_fp: 0.005313, loss_freq: 0.022946
[14:55:21.600] iteration 16597: loss: 0.100145, loss_s1: 0.080944, loss_fp: 0.008886, loss_freq: 0.059371
[14:55:22.252] iteration 16598: loss: 0.037523, loss_s1: 0.010510, loss_fp: 0.001586, loss_freq: 0.008269
[14:55:22.892] iteration 16599: loss: 0.058127, loss_s1: 0.019498, loss_fp: 0.004888, loss_freq: 0.039801
[14:55:23.535] iteration 16600: loss: 0.051452, loss_s1: 0.028750, loss_fp: 0.002092, loss_freq: 0.018603
[14:55:27.224] iteration 16600 : mean_dice : 0.768008
[14:55:27.911] iteration 16601: loss: 0.099940, loss_s1: 0.097320, loss_fp: 0.001692, loss_freq: 0.047693
[14:55:28.597] iteration 16602: loss: 0.068898, loss_s1: 0.041916, loss_fp: 0.000416, loss_freq: 0.046671
[14:55:29.263] iteration 16603: loss: 0.076087, loss_s1: 0.070368, loss_fp: 0.001740, loss_freq: 0.036812
[14:55:29.920] iteration 16604: loss: 0.052809, loss_s1: 0.041484, loss_fp: 0.003866, loss_freq: 0.017350
[14:55:30.573] iteration 16605: loss: 0.080779, loss_s1: 0.029709, loss_fp: 0.000827, loss_freq: 0.040185
[14:55:31.245] iteration 16606: loss: 0.082866, loss_s1: 0.030835, loss_fp: 0.003364, loss_freq: 0.020819
[14:55:31.899] iteration 16607: loss: 0.085790, loss_s1: 0.032797, loss_fp: 0.004070, loss_freq: 0.042493
[14:55:32.559] iteration 16608: loss: 0.071766, loss_s1: 0.054998, loss_fp: 0.001213, loss_freq: 0.049170
[14:55:33.307] iteration 16609: loss: 0.080398, loss_s1: 0.039620, loss_fp: 0.002649, loss_freq: 0.039290
[14:55:33.995] iteration 16610: loss: 0.055020, loss_s1: 0.042201, loss_fp: 0.002495, loss_freq: 0.030128
[14:55:34.683] iteration 16611: loss: 0.080138, loss_s1: 0.046765, loss_fp: 0.000944, loss_freq: 0.059709
[14:55:35.364] iteration 16612: loss: 0.053265, loss_s1: 0.030467, loss_fp: 0.001001, loss_freq: 0.024173
[14:55:36.036] iteration 16613: loss: 0.081899, loss_s1: 0.066077, loss_fp: 0.000639, loss_freq: 0.051918
[14:55:36.773] iteration 16614: loss: 0.093649, loss_s1: 0.066776, loss_fp: 0.001356, loss_freq: 0.063948
[14:55:37.482] iteration 16615: loss: 0.107253, loss_s1: 0.094699, loss_fp: 0.002672, loss_freq: 0.061954
[14:55:38.221] iteration 16616: loss: 0.056060, loss_s1: 0.042393, loss_fp: 0.001170, loss_freq: 0.013815
[14:55:38.888] iteration 16617: loss: 0.066197, loss_s1: 0.040051, loss_fp: 0.004654, loss_freq: 0.030568
[14:55:39.614] iteration 16618: loss: 0.063062, loss_s1: 0.032858, loss_fp: 0.001446, loss_freq: 0.009475
[14:55:40.317] iteration 16619: loss: 0.066356, loss_s1: 0.029368, loss_fp: 0.001435, loss_freq: 0.029239
[14:55:41.049] iteration 16620: loss: 0.064512, loss_s1: 0.025415, loss_fp: 0.006057, loss_freq: 0.014817
[14:55:41.722] iteration 16621: loss: 0.047295, loss_s1: 0.017147, loss_fp: 0.001678, loss_freq: 0.044914
[14:55:42.415] iteration 16622: loss: 0.075903, loss_s1: 0.072287, loss_fp: 0.005219, loss_freq: 0.027305
[14:55:43.051] iteration 16623: loss: 0.091981, loss_s1: 0.050670, loss_fp: 0.002821, loss_freq: 0.037836
[14:55:43.680] iteration 16624: loss: 0.080051, loss_s1: 0.032708, loss_fp: 0.003180, loss_freq: 0.073624
[14:55:44.314] iteration 16625: loss: 0.043965, loss_s1: 0.023201, loss_fp: 0.007425, loss_freq: 0.011759
[14:55:44.944] iteration 16626: loss: 0.115865, loss_s1: 0.157018, loss_fp: 0.004577, loss_freq: 0.034230
[14:55:45.622] iteration 16627: loss: 0.067734, loss_s1: 0.040090, loss_fp: 0.004001, loss_freq: 0.035791
[14:55:46.279] iteration 16628: loss: 0.035618, loss_s1: 0.024518, loss_fp: 0.002779, loss_freq: 0.009181
[14:55:46.940] iteration 16629: loss: 0.063356, loss_s1: 0.061074, loss_fp: 0.001900, loss_freq: 0.009600
[14:55:47.598] iteration 16630: loss: 0.054503, loss_s1: 0.056575, loss_fp: 0.002202, loss_freq: 0.017833
[14:55:48.264] iteration 16631: loss: 0.044542, loss_s1: 0.028316, loss_fp: 0.001461, loss_freq: 0.014256
[14:55:48.919] iteration 16632: loss: 0.057647, loss_s1: 0.047648, loss_fp: 0.005997, loss_freq: 0.021984
[14:55:49.578] iteration 16633: loss: 0.051783, loss_s1: 0.045438, loss_fp: 0.002219, loss_freq: 0.007055
[14:55:50.238] iteration 16634: loss: 0.088940, loss_s1: 0.090605, loss_fp: 0.006444, loss_freq: 0.035695
[14:55:50.895] iteration 16635: loss: 0.074202, loss_s1: 0.035415, loss_fp: 0.005005, loss_freq: 0.057799
[14:55:51.535] iteration 16636: loss: 0.041892, loss_s1: 0.021341, loss_fp: 0.002018, loss_freq: 0.022276
[14:55:52.203] iteration 16637: loss: 0.047009, loss_s1: 0.028847, loss_fp: 0.001726, loss_freq: 0.030267
[14:55:52.846] iteration 16638: loss: 0.070100, loss_s1: 0.062612, loss_fp: 0.002737, loss_freq: 0.031467
[14:55:53.516] iteration 16639: loss: 0.075238, loss_s1: 0.060077, loss_fp: 0.002615, loss_freq: 0.029321
[14:55:54.180] iteration 16640: loss: 0.068667, loss_s1: 0.045329, loss_fp: 0.001308, loss_freq: 0.019628
[14:55:54.863] iteration 16641: loss: 0.061809, loss_s1: 0.025708, loss_fp: 0.002294, loss_freq: 0.013005
[14:55:55.534] iteration 16642: loss: 0.038910, loss_s1: 0.024666, loss_fp: 0.001422, loss_freq: 0.010045
[14:55:56.177] iteration 16643: loss: 0.051779, loss_s1: 0.045926, loss_fp: 0.002488, loss_freq: 0.023809
[14:55:56.827] iteration 16644: loss: 0.053359, loss_s1: 0.017026, loss_fp: 0.000933, loss_freq: 0.024034
[14:55:57.496] iteration 16645: loss: 0.044987, loss_s1: 0.030995, loss_fp: 0.001032, loss_freq: 0.025900
[14:55:58.166] iteration 16646: loss: 0.037902, loss_s1: 0.021718, loss_fp: 0.000650, loss_freq: 0.014164
[14:55:58.809] iteration 16647: loss: 0.063058, loss_s1: 0.027838, loss_fp: 0.008475, loss_freq: 0.053083
[14:55:59.434] iteration 16648: loss: 0.048231, loss_s1: 0.040950, loss_fp: 0.001287, loss_freq: 0.014367
[14:56:00.064] iteration 16649: loss: 0.062634, loss_s1: 0.025306, loss_fp: 0.004424, loss_freq: 0.028022
[14:56:00.700] iteration 16650: loss: 0.072201, loss_s1: 0.041992, loss_fp: 0.001194, loss_freq: 0.016630
[14:56:01.331] iteration 16651: loss: 0.088366, loss_s1: 0.091044, loss_fp: 0.006104, loss_freq: 0.031376
[14:56:02.016] iteration 16652: loss: 0.065851, loss_s1: 0.035412, loss_fp: 0.001219, loss_freq: 0.023137
[14:56:02.650] iteration 16653: loss: 0.068504, loss_s1: 0.053222, loss_fp: 0.001455, loss_freq: 0.025600
[14:56:03.278] iteration 16654: loss: 0.059778, loss_s1: 0.029680, loss_fp: 0.004043, loss_freq: 0.026409
[14:56:03.955] iteration 16655: loss: 0.068115, loss_s1: 0.020737, loss_fp: 0.000878, loss_freq: 0.054304
[14:56:04.588] iteration 16656: loss: 0.041929, loss_s1: 0.018909, loss_fp: 0.000652, loss_freq: 0.016798
[14:56:05.206] iteration 16657: loss: 0.055613, loss_s1: 0.021395, loss_fp: 0.006198, loss_freq: 0.023510
[14:56:05.827] iteration 16658: loss: 0.066326, loss_s1: 0.012582, loss_fp: 0.002602, loss_freq: 0.008123
[14:56:06.458] iteration 16659: loss: 0.040186, loss_s1: 0.013767, loss_fp: 0.003043, loss_freq: 0.013182
[14:56:07.083] iteration 16660: loss: 0.063226, loss_s1: 0.021997, loss_fp: 0.000782, loss_freq: 0.031070
[14:56:07.716] iteration 16661: loss: 0.045059, loss_s1: 0.028185, loss_fp: 0.000844, loss_freq: 0.028309
[14:56:08.338] iteration 16662: loss: 0.135541, loss_s1: 0.150174, loss_fp: 0.005821, loss_freq: 0.058567
[14:56:08.960] iteration 16663: loss: 0.053480, loss_s1: 0.045095, loss_fp: 0.002652, loss_freq: 0.023932
[14:56:09.612] iteration 16664: loss: 0.075656, loss_s1: 0.020554, loss_fp: 0.000927, loss_freq: 0.023626
[14:56:10.243] iteration 16665: loss: 0.034110, loss_s1: 0.013342, loss_fp: 0.000757, loss_freq: 0.016151
[14:56:10.878] iteration 16666: loss: 0.048051, loss_s1: 0.023657, loss_fp: 0.001858, loss_freq: 0.010258
[14:56:11.524] iteration 16667: loss: 0.063215, loss_s1: 0.028111, loss_fp: 0.001616, loss_freq: 0.048810
[14:56:12.151] iteration 16668: loss: 0.082768, loss_s1: 0.036605, loss_fp: 0.008005, loss_freq: 0.013164
[14:56:12.777] iteration 16669: loss: 0.053215, loss_s1: 0.027760, loss_fp: 0.003941, loss_freq: 0.026546
[14:56:13.400] iteration 16670: loss: 0.072637, loss_s1: 0.046064, loss_fp: 0.003011, loss_freq: 0.049761
[14:56:14.023] iteration 16671: loss: 0.041463, loss_s1: 0.024317, loss_fp: 0.001109, loss_freq: 0.014641
[14:56:14.679] iteration 16672: loss: 0.052140, loss_s1: 0.048957, loss_fp: 0.001514, loss_freq: 0.016944
[14:56:15.307] iteration 16673: loss: 0.097116, loss_s1: 0.118318, loss_fp: 0.003653, loss_freq: 0.024636
[14:56:15.937] iteration 16674: loss: 0.107030, loss_s1: 0.079905, loss_fp: 0.003552, loss_freq: 0.080987
[14:56:16.589] iteration 16675: loss: 0.062470, loss_s1: 0.042452, loss_fp: 0.003008, loss_freq: 0.015485
[14:56:17.251] iteration 16676: loss: 0.053820, loss_s1: 0.023006, loss_fp: 0.001217, loss_freq: 0.032588
[14:56:17.910] iteration 16677: loss: 0.071188, loss_s1: 0.065159, loss_fp: 0.001180, loss_freq: 0.005522
[14:56:18.572] iteration 16678: loss: 0.071106, loss_s1: 0.067928, loss_fp: 0.007304, loss_freq: 0.012600
[14:56:19.209] iteration 16679: loss: 0.075031, loss_s1: 0.048831, loss_fp: 0.006538, loss_freq: 0.014822
[14:56:19.834] iteration 16680: loss: 0.078513, loss_s1: 0.029380, loss_fp: 0.009157, loss_freq: 0.044376
[14:56:20.454] iteration 16681: loss: 0.053068, loss_s1: 0.044246, loss_fp: 0.002966, loss_freq: 0.016229
[14:56:21.079] iteration 16682: loss: 0.059095, loss_s1: 0.049790, loss_fp: 0.004721, loss_freq: 0.017033
[14:56:21.709] iteration 16683: loss: 0.058453, loss_s1: 0.041674, loss_fp: 0.003027, loss_freq: 0.021316
[14:56:22.380] iteration 16684: loss: 0.046620, loss_s1: 0.028499, loss_fp: 0.001294, loss_freq: 0.008081
[14:56:23.009] iteration 16685: loss: 0.085616, loss_s1: 0.036974, loss_fp: 0.002104, loss_freq: 0.067049
[14:56:23.628] iteration 16686: loss: 0.061499, loss_s1: 0.035610, loss_fp: 0.001943, loss_freq: 0.031338
[14:56:24.259] iteration 16687: loss: 0.058558, loss_s1: 0.029192, loss_fp: 0.002892, loss_freq: 0.016349
[14:56:24.884] iteration 16688: loss: 0.078940, loss_s1: 0.065041, loss_fp: 0.008297, loss_freq: 0.032678
[14:56:25.545] iteration 16689: loss: 0.037701, loss_s1: 0.014632, loss_fp: 0.001126, loss_freq: 0.006470
[14:56:26.171] iteration 16690: loss: 0.062842, loss_s1: 0.047137, loss_fp: 0.004164, loss_freq: 0.028648
[14:56:26.791] iteration 16691: loss: 0.056089, loss_s1: 0.043365, loss_fp: 0.004793, loss_freq: 0.032725
[14:56:27.457] iteration 16692: loss: 0.053694, loss_s1: 0.038245, loss_fp: 0.000815, loss_freq: 0.014014
[14:56:28.089] iteration 16693: loss: 0.057977, loss_s1: 0.034369, loss_fp: 0.003551, loss_freq: 0.009783
[14:56:28.747] iteration 16694: loss: 0.058687, loss_s1: 0.041950, loss_fp: 0.002089, loss_freq: 0.029268
[14:56:29.413] iteration 16695: loss: 0.086626, loss_s1: 0.062312, loss_fp: 0.005546, loss_freq: 0.062747
[14:56:30.096] iteration 16696: loss: 0.065852, loss_s1: 0.060118, loss_fp: 0.005731, loss_freq: 0.031573
[14:56:30.809] iteration 16697: loss: 0.076777, loss_s1: 0.039493, loss_fp: 0.004654, loss_freq: 0.028199
[14:56:31.443] iteration 16698: loss: 0.050481, loss_s1: 0.035429, loss_fp: 0.009750, loss_freq: 0.017376
[14:56:32.074] iteration 16699: loss: 0.052593, loss_s1: 0.031109, loss_fp: 0.001547, loss_freq: 0.016739
[14:56:32.709] iteration 16700: loss: 0.050497, loss_s1: 0.042912, loss_fp: 0.002677, loss_freq: 0.027746
[14:56:33.350] iteration 16701: loss: 0.045177, loss_s1: 0.018895, loss_fp: 0.003324, loss_freq: 0.025542
[14:56:33.989] iteration 16702: loss: 0.113420, loss_s1: 0.099197, loss_fp: 0.011748, loss_freq: 0.059390
[14:56:34.633] iteration 16703: loss: 0.069589, loss_s1: 0.043906, loss_fp: 0.002093, loss_freq: 0.024266
[14:56:35.268] iteration 16704: loss: 0.054475, loss_s1: 0.019169, loss_fp: 0.002021, loss_freq: 0.019434
[14:56:35.913] iteration 16705: loss: 0.072082, loss_s1: 0.049976, loss_fp: 0.005988, loss_freq: 0.027153
[14:56:36.553] iteration 16706: loss: 0.109495, loss_s1: 0.130248, loss_fp: 0.002817, loss_freq: 0.028258
[14:56:37.192] iteration 16707: loss: 0.058995, loss_s1: 0.052949, loss_fp: 0.001872, loss_freq: 0.025669
[14:56:37.825] iteration 16708: loss: 0.054199, loss_s1: 0.032103, loss_fp: 0.004265, loss_freq: 0.031792
[14:56:38.459] iteration 16709: loss: 0.099283, loss_s1: 0.095497, loss_fp: 0.005876, loss_freq: 0.055055
[14:56:39.284] iteration 16710: loss: 0.105624, loss_s1: 0.119063, loss_fp: 0.006702, loss_freq: 0.032664
[14:56:40.126] iteration 16711: loss: 0.040966, loss_s1: 0.017357, loss_fp: 0.000515, loss_freq: 0.008125
[14:56:40.891] iteration 16712: loss: 0.052044, loss_s1: 0.037400, loss_fp: 0.004656, loss_freq: 0.031855
[14:56:41.584] iteration 16713: loss: 0.067196, loss_s1: 0.069049, loss_fp: 0.005034, loss_freq: 0.014765
[14:56:42.241] iteration 16714: loss: 0.078830, loss_s1: 0.058974, loss_fp: 0.002362, loss_freq: 0.010700
[14:56:42.897] iteration 16715: loss: 0.077187, loss_s1: 0.032275, loss_fp: 0.002948, loss_freq: 0.045186
[14:56:43.561] iteration 16716: loss: 0.053364, loss_s1: 0.035208, loss_fp: 0.004079, loss_freq: 0.024611
[14:56:44.235] iteration 16717: loss: 0.054405, loss_s1: 0.031700, loss_fp: 0.001947, loss_freq: 0.018323
[14:56:44.892] iteration 16718: loss: 0.039073, loss_s1: 0.026591, loss_fp: 0.003047, loss_freq: 0.008457
[14:56:45.597] iteration 16719: loss: 0.080241, loss_s1: 0.078567, loss_fp: 0.010946, loss_freq: 0.022205
[14:56:46.227] iteration 16720: loss: 0.101995, loss_s1: 0.044357, loss_fp: 0.003482, loss_freq: 0.039313
[14:56:46.864] iteration 16721: loss: 0.090940, loss_s1: 0.084966, loss_fp: 0.018625, loss_freq: 0.025990
[14:56:47.497] iteration 16722: loss: 0.060477, loss_s1: 0.025837, loss_fp: 0.002251, loss_freq: 0.036426
[14:56:48.131] iteration 16723: loss: 0.082399, loss_s1: 0.059200, loss_fp: 0.003825, loss_freq: 0.043367
[14:56:48.762] iteration 16724: loss: 0.070732, loss_s1: 0.072753, loss_fp: 0.006265, loss_freq: 0.020789
[14:56:49.398] iteration 16725: loss: 0.068770, loss_s1: 0.018585, loss_fp: 0.015236, loss_freq: 0.039870
[14:56:50.032] iteration 16726: loss: 0.049521, loss_s1: 0.031789, loss_fp: 0.004005, loss_freq: 0.012292
[14:56:50.665] iteration 16727: loss: 0.056895, loss_s1: 0.041239, loss_fp: 0.005294, loss_freq: 0.026069
[14:56:51.291] iteration 16728: loss: 0.062947, loss_s1: 0.037704, loss_fp: 0.001916, loss_freq: 0.018340
[14:56:51.918] iteration 16729: loss: 0.099368, loss_s1: 0.061117, loss_fp: 0.002139, loss_freq: 0.044613
[14:56:52.548] iteration 16730: loss: 0.067280, loss_s1: 0.047698, loss_fp: 0.016694, loss_freq: 0.029918
[14:56:53.174] iteration 16731: loss: 0.048114, loss_s1: 0.007637, loss_fp: 0.003026, loss_freq: 0.028673
[14:56:54.105] iteration 16732: loss: 0.060780, loss_s1: 0.052983, loss_fp: 0.002190, loss_freq: 0.012603
[14:56:54.750] iteration 16733: loss: 0.058151, loss_s1: 0.037814, loss_fp: 0.003967, loss_freq: 0.017112
[14:56:55.397] iteration 16734: loss: 0.048794, loss_s1: 0.019748, loss_fp: 0.001791, loss_freq: 0.039864
[14:56:56.024] iteration 16735: loss: 0.061267, loss_s1: 0.037810, loss_fp: 0.003417, loss_freq: 0.020753
[14:56:56.650] iteration 16736: loss: 0.085365, loss_s1: 0.057522, loss_fp: 0.002743, loss_freq: 0.037629
[14:56:57.267] iteration 16737: loss: 0.042025, loss_s1: 0.020038, loss_fp: 0.001355, loss_freq: 0.003822
[14:56:57.885] iteration 16738: loss: 0.027476, loss_s1: 0.015864, loss_fp: 0.000796, loss_freq: 0.008909
[14:56:58.519] iteration 16739: loss: 0.070093, loss_s1: 0.047390, loss_fp: 0.003511, loss_freq: 0.011047
[14:56:59.152] iteration 16740: loss: 0.066335, loss_s1: 0.046621, loss_fp: 0.006256, loss_freq: 0.037018
[14:56:59.784] iteration 16741: loss: 0.045508, loss_s1: 0.018521, loss_fp: 0.000666, loss_freq: 0.005149
[14:57:00.430] iteration 16742: loss: 0.058133, loss_s1: 0.027479, loss_fp: 0.001491, loss_freq: 0.037583
[14:57:01.084] iteration 16743: loss: 0.043448, loss_s1: 0.022673, loss_fp: 0.000964, loss_freq: 0.019280
[14:57:01.730] iteration 16744: loss: 0.055332, loss_s1: 0.057489, loss_fp: 0.000580, loss_freq: 0.012329
[14:57:02.409] iteration 16745: loss: 0.033363, loss_s1: 0.012595, loss_fp: 0.000743, loss_freq: 0.022664
[14:57:03.081] iteration 16746: loss: 0.093009, loss_s1: 0.102653, loss_fp: 0.007036, loss_freq: 0.029095
[14:57:03.755] iteration 16747: loss: 0.053998, loss_s1: 0.027511, loss_fp: 0.002537, loss_freq: 0.021636
[14:57:04.387] iteration 16748: loss: 0.044025, loss_s1: 0.010477, loss_fp: 0.001702, loss_freq: 0.032774
[14:57:05.014] iteration 16749: loss: 0.064777, loss_s1: 0.053733, loss_fp: 0.002848, loss_freq: 0.032156
[14:57:05.645] iteration 16750: loss: 0.049821, loss_s1: 0.027813, loss_fp: 0.003637, loss_freq: 0.020665
[14:57:06.276] iteration 16751: loss: 0.045602, loss_s1: 0.045578, loss_fp: 0.001524, loss_freq: 0.011148
[14:57:06.936] iteration 16752: loss: 0.090301, loss_s1: 0.046177, loss_fp: 0.009853, loss_freq: 0.070840
[14:57:07.568] iteration 16753: loss: 0.061098, loss_s1: 0.057024, loss_fp: 0.005663, loss_freq: 0.025317
[14:57:08.186] iteration 16754: loss: 0.051416, loss_s1: 0.049997, loss_fp: 0.000982, loss_freq: 0.006256
[14:57:08.812] iteration 16755: loss: 0.055742, loss_s1: 0.024816, loss_fp: 0.001427, loss_freq: 0.005533
[14:57:09.437] iteration 16756: loss: 0.052714, loss_s1: 0.031632, loss_fp: 0.003615, loss_freq: 0.019882
[14:57:10.053] iteration 16757: loss: 0.098856, loss_s1: 0.076715, loss_fp: 0.004800, loss_freq: 0.040973
[14:57:10.679] iteration 16758: loss: 0.088339, loss_s1: 0.065006, loss_fp: 0.006653, loss_freq: 0.045905
[14:57:11.308] iteration 16759: loss: 0.035021, loss_s1: 0.021457, loss_fp: 0.000569, loss_freq: 0.004646
[14:57:11.931] iteration 16760: loss: 0.082650, loss_s1: 0.070370, loss_fp: 0.001512, loss_freq: 0.040172
[14:57:12.564] iteration 16761: loss: 0.064679, loss_s1: 0.025780, loss_fp: 0.000896, loss_freq: 0.009082
[14:57:13.199] iteration 16762: loss: 0.048985, loss_s1: 0.033078, loss_fp: 0.001369, loss_freq: 0.013294
[14:57:13.821] iteration 16763: loss: 0.068664, loss_s1: 0.058503, loss_fp: 0.001893, loss_freq: 0.018758
[14:57:14.449] iteration 16764: loss: 0.062572, loss_s1: 0.053499, loss_fp: 0.008222, loss_freq: 0.033899
[14:57:15.079] iteration 16765: loss: 0.097475, loss_s1: 0.082242, loss_fp: 0.012138, loss_freq: 0.058258
[14:57:15.694] iteration 16766: loss: 0.081016, loss_s1: 0.022198, loss_fp: 0.005556, loss_freq: 0.015364
[14:57:16.324] iteration 16767: loss: 0.076361, loss_s1: 0.046668, loss_fp: 0.002834, loss_freq: 0.052040
[14:57:16.945] iteration 16768: loss: 0.053464, loss_s1: 0.021344, loss_fp: 0.001816, loss_freq: 0.025750
[14:57:17.572] iteration 16769: loss: 0.047529, loss_s1: 0.054472, loss_fp: 0.001614, loss_freq: 0.006058
[14:57:18.204] iteration 16770: loss: 0.089681, loss_s1: 0.071914, loss_fp: 0.005788, loss_freq: 0.035164
[14:57:18.829] iteration 16771: loss: 0.060254, loss_s1: 0.060314, loss_fp: 0.002670, loss_freq: 0.014423
[14:57:19.459] iteration 16772: loss: 0.052718, loss_s1: 0.041848, loss_fp: 0.006192, loss_freq: 0.008258
[14:57:20.087] iteration 16773: loss: 0.039497, loss_s1: 0.022714, loss_fp: 0.004676, loss_freq: 0.017076
[14:57:20.717] iteration 16774: loss: 0.077075, loss_s1: 0.040086, loss_fp: 0.001382, loss_freq: 0.024782
[14:57:21.347] iteration 16775: loss: 0.106583, loss_s1: 0.132807, loss_fp: 0.003570, loss_freq: 0.030009
[14:57:21.973] iteration 16776: loss: 0.065454, loss_s1: 0.036920, loss_fp: 0.000599, loss_freq: 0.010393
[14:57:22.605] iteration 16777: loss: 0.053514, loss_s1: 0.025014, loss_fp: 0.000467, loss_freq: 0.037995
[14:57:23.227] iteration 16778: loss: 0.047900, loss_s1: 0.016723, loss_fp: 0.002634, loss_freq: 0.019654
[14:57:23.899] iteration 16779: loss: 0.079557, loss_s1: 0.065603, loss_fp: 0.007496, loss_freq: 0.019172
[14:57:24.567] iteration 16780: loss: 0.042223, loss_s1: 0.024901, loss_fp: 0.002577, loss_freq: 0.020578
[14:57:25.236] iteration 16781: loss: 0.055891, loss_s1: 0.028868, loss_fp: 0.000470, loss_freq: 0.029579
[14:57:25.906] iteration 16782: loss: 0.052919, loss_s1: 0.053400, loss_fp: 0.001721, loss_freq: 0.007183
[14:57:26.572] iteration 16783: loss: 0.074407, loss_s1: 0.017509, loss_fp: 0.002059, loss_freq: 0.056402
[14:57:27.248] iteration 16784: loss: 0.060887, loss_s1: 0.027210, loss_fp: 0.000980, loss_freq: 0.021736
[14:57:27.926] iteration 16785: loss: 0.038922, loss_s1: 0.026971, loss_fp: 0.001170, loss_freq: 0.016513
[14:57:28.568] iteration 16786: loss: 0.048953, loss_s1: 0.052375, loss_fp: 0.001654, loss_freq: 0.008036
[14:57:29.196] iteration 16787: loss: 0.040094, loss_s1: 0.013360, loss_fp: 0.001341, loss_freq: 0.012273
[14:57:29.826] iteration 16788: loss: 0.065659, loss_s1: 0.050676, loss_fp: 0.009516, loss_freq: 0.013367
[14:57:30.454] iteration 16789: loss: 0.040855, loss_s1: 0.033288, loss_fp: 0.001471, loss_freq: 0.010660
[14:57:31.088] iteration 16790: loss: 0.094402, loss_s1: 0.073036, loss_fp: 0.001638, loss_freq: 0.062116
[14:57:31.719] iteration 16791: loss: 0.051204, loss_s1: 0.033645, loss_fp: 0.002840, loss_freq: 0.025807
[14:57:32.357] iteration 16792: loss: 0.060036, loss_s1: 0.030121, loss_fp: 0.008928, loss_freq: 0.016335
[14:57:32.987] iteration 16793: loss: 0.070126, loss_s1: 0.034421, loss_fp: 0.005528, loss_freq: 0.022143
[14:57:33.618] iteration 16794: loss: 0.120302, loss_s1: 0.094241, loss_fp: 0.005677, loss_freq: 0.085785
[14:57:34.294] iteration 16795: loss: 0.059373, loss_s1: 0.031279, loss_fp: 0.005552, loss_freq: 0.024548
[14:57:34.931] iteration 16796: loss: 0.084593, loss_s1: 0.040465, loss_fp: 0.006500, loss_freq: 0.060268
[14:57:35.575] iteration 16797: loss: 0.085730, loss_s1: 0.059171, loss_fp: 0.001326, loss_freq: 0.022161
[14:57:36.211] iteration 16798: loss: 0.139850, loss_s1: 0.123808, loss_fp: 0.032716, loss_freq: 0.069957
[14:57:36.855] iteration 16799: loss: 0.054156, loss_s1: 0.045002, loss_fp: 0.001888, loss_freq: 0.024790
[14:57:37.504] iteration 16800: loss: 0.060491, loss_s1: 0.056737, loss_fp: 0.004703, loss_freq: 0.015002
[14:57:41.170] iteration 16800 : mean_dice : 0.781673
[14:57:41.861] iteration 16801: loss: 0.047995, loss_s1: 0.024533, loss_fp: 0.003335, loss_freq: 0.017142
[14:57:42.516] iteration 16802: loss: 0.070689, loss_s1: 0.053790, loss_fp: 0.002436, loss_freq: 0.023132
[14:57:43.147] iteration 16803: loss: 0.052913, loss_s1: 0.024602, loss_fp: 0.004739, loss_freq: 0.026985
[14:57:43.794] iteration 16804: loss: 0.044219, loss_s1: 0.024415, loss_fp: 0.005406, loss_freq: 0.017899
[14:57:44.425] iteration 16805: loss: 0.088608, loss_s1: 0.088449, loss_fp: 0.002361, loss_freq: 0.028868
[14:57:45.087] iteration 16806: loss: 0.077797, loss_s1: 0.043306, loss_fp: 0.002728, loss_freq: 0.037166
[14:57:45.744] iteration 16807: loss: 0.042325, loss_s1: 0.027862, loss_fp: 0.000707, loss_freq: 0.009937
[14:57:46.398] iteration 16808: loss: 0.058251, loss_s1: 0.024224, loss_fp: 0.002921, loss_freq: 0.051070
[14:57:47.051] iteration 16809: loss: 0.073938, loss_s1: 0.064130, loss_fp: 0.002176, loss_freq: 0.025549
[14:57:47.669] iteration 16810: loss: 0.063685, loss_s1: 0.034950, loss_fp: 0.003753, loss_freq: 0.036162
[14:57:48.289] iteration 16811: loss: 0.107845, loss_s1: 0.085421, loss_fp: 0.005663, loss_freq: 0.022887
[14:57:48.915] iteration 16812: loss: 0.052972, loss_s1: 0.017482, loss_fp: 0.001057, loss_freq: 0.032092
[14:57:49.532] iteration 16813: loss: 0.089083, loss_s1: 0.092006, loss_fp: 0.001050, loss_freq: 0.023110
[14:57:50.152] iteration 16814: loss: 0.044770, loss_s1: 0.020017, loss_fp: 0.001798, loss_freq: 0.021361
[14:57:50.776] iteration 16815: loss: 0.042904, loss_s1: 0.036916, loss_fp: 0.003110, loss_freq: 0.012431
[14:57:51.406] iteration 16816: loss: 0.045871, loss_s1: 0.035461, loss_fp: 0.001807, loss_freq: 0.014344
[14:57:52.020] iteration 16817: loss: 0.063285, loss_s1: 0.041757, loss_fp: 0.006220, loss_freq: 0.031987
[14:57:52.643] iteration 16818: loss: 0.081557, loss_s1: 0.081117, loss_fp: 0.007820, loss_freq: 0.020783
[14:57:53.270] iteration 16819: loss: 0.070743, loss_s1: 0.036262, loss_fp: 0.001747, loss_freq: 0.024926
[14:57:53.899] iteration 16820: loss: 0.053921, loss_s1: 0.033940, loss_fp: 0.002503, loss_freq: 0.012759
[14:57:54.525] iteration 16821: loss: 0.051967, loss_s1: 0.050281, loss_fp: 0.003153, loss_freq: 0.017110
[14:57:55.139] iteration 16822: loss: 0.076458, loss_s1: 0.035896, loss_fp: 0.005956, loss_freq: 0.023755
[14:57:55.770] iteration 16823: loss: 0.079251, loss_s1: 0.039679, loss_fp: 0.002108, loss_freq: 0.082007
[14:57:56.429] iteration 16824: loss: 0.069449, loss_s1: 0.071030, loss_fp: 0.003931, loss_freq: 0.023913
[14:57:57.060] iteration 16825: loss: 0.054235, loss_s1: 0.032054, loss_fp: 0.008198, loss_freq: 0.010636
[14:57:57.679] iteration 16826: loss: 0.037757, loss_s1: 0.012341, loss_fp: 0.001055, loss_freq: 0.019527
[14:57:58.313] iteration 16827: loss: 0.055428, loss_s1: 0.015642, loss_fp: 0.002993, loss_freq: 0.011169
[14:57:58.935] iteration 16828: loss: 0.124035, loss_s1: 0.118442, loss_fp: 0.001788, loss_freq: 0.060636
[14:57:59.555] iteration 16829: loss: 0.053158, loss_s1: 0.034139, loss_fp: 0.001226, loss_freq: 0.029345
[14:58:00.196] iteration 16830: loss: 0.068680, loss_s1: 0.031237, loss_fp: 0.004097, loss_freq: 0.033279
[14:58:00.822] iteration 16831: loss: 0.056574, loss_s1: 0.022457, loss_fp: 0.002714, loss_freq: 0.031747
[14:58:01.439] iteration 16832: loss: 0.039399, loss_s1: 0.017688, loss_fp: 0.003904, loss_freq: 0.017714
[14:58:02.079] iteration 16833: loss: 0.068327, loss_s1: 0.020405, loss_fp: 0.004115, loss_freq: 0.015296
[14:58:02.706] iteration 16834: loss: 0.084405, loss_s1: 0.041819, loss_fp: 0.013830, loss_freq: 0.066941
[14:58:03.338] iteration 16835: loss: 0.058929, loss_s1: 0.049468, loss_fp: 0.000822, loss_freq: 0.021292
[14:58:04.022] iteration 16836: loss: 0.065076, loss_s1: 0.050888, loss_fp: 0.003769, loss_freq: 0.027814
[14:58:04.685] iteration 16837: loss: 0.044428, loss_s1: 0.009947, loss_fp: 0.001355, loss_freq: 0.022564
[14:58:05.314] iteration 16838: loss: 0.070517, loss_s1: 0.018299, loss_fp: 0.002638, loss_freq: 0.067559
[14:58:05.948] iteration 16839: loss: 0.075850, loss_s1: 0.058681, loss_fp: 0.004645, loss_freq: 0.050637
[14:58:06.581] iteration 16840: loss: 0.075923, loss_s1: 0.075437, loss_fp: 0.002712, loss_freq: 0.021916
[14:58:07.216] iteration 16841: loss: 0.067818, loss_s1: 0.076016, loss_fp: 0.011867, loss_freq: 0.017440
[14:58:07.855] iteration 16842: loss: 0.062488, loss_s1: 0.031962, loss_fp: 0.004465, loss_freq: 0.033083
[14:58:08.490] iteration 16843: loss: 0.052813, loss_s1: 0.041334, loss_fp: 0.005255, loss_freq: 0.024749
[14:58:09.122] iteration 16844: loss: 0.061594, loss_s1: 0.036766, loss_fp: 0.005386, loss_freq: 0.011505
[14:58:09.758] iteration 16845: loss: 0.092325, loss_s1: 0.097612, loss_fp: 0.007697, loss_freq: 0.026428
[14:58:10.388] iteration 16846: loss: 0.067958, loss_s1: 0.037664, loss_fp: 0.001551, loss_freq: 0.008370
[14:58:11.022] iteration 16847: loss: 0.039550, loss_s1: 0.018235, loss_fp: 0.000979, loss_freq: 0.015144
[14:58:11.652] iteration 16848: loss: 0.067248, loss_s1: 0.029510, loss_fp: 0.005345, loss_freq: 0.036825
[14:58:12.277] iteration 16849: loss: 0.080697, loss_s1: 0.081566, loss_fp: 0.004088, loss_freq: 0.025396
[14:58:12.909] iteration 16850: loss: 0.042152, loss_s1: 0.033802, loss_fp: 0.001509, loss_freq: 0.011438
[14:58:13.540] iteration 16851: loss: 0.057534, loss_s1: 0.043859, loss_fp: 0.002855, loss_freq: 0.028011
[14:58:14.182] iteration 16852: loss: 0.063972, loss_s1: 0.029027, loss_fp: 0.001178, loss_freq: 0.047609
[14:58:14.855] iteration 16853: loss: 0.058817, loss_s1: 0.041464, loss_fp: 0.002933, loss_freq: 0.013842
[14:58:15.518] iteration 16854: loss: 0.031875, loss_s1: 0.013542, loss_fp: 0.001377, loss_freq: 0.010495
[14:58:16.181] iteration 16855: loss: 0.035802, loss_s1: 0.014129, loss_fp: 0.001328, loss_freq: 0.028229
[14:58:16.890] iteration 16856: loss: 0.048936, loss_s1: 0.022734, loss_fp: 0.002927, loss_freq: 0.040986
[14:58:17.559] iteration 16857: loss: 0.068739, loss_s1: 0.062621, loss_fp: 0.002677, loss_freq: 0.023027
[14:58:18.236] iteration 16858: loss: 0.050414, loss_s1: 0.040355, loss_fp: 0.001806, loss_freq: 0.013875
[14:58:18.891] iteration 16859: loss: 0.072904, loss_s1: 0.059391, loss_fp: 0.000674, loss_freq: 0.038022
[14:58:19.546] iteration 16860: loss: 0.087472, loss_s1: 0.098891, loss_fp: 0.004158, loss_freq: 0.031649
[14:58:20.211] iteration 16861: loss: 0.040215, loss_s1: 0.030125, loss_fp: 0.003220, loss_freq: 0.008507
[14:58:20.892] iteration 16862: loss: 0.051941, loss_s1: 0.027448, loss_fp: 0.002979, loss_freq: 0.021441
[14:58:21.547] iteration 16863: loss: 0.080470, loss_s1: 0.065104, loss_fp: 0.002703, loss_freq: 0.040750
[14:58:22.193] iteration 16864: loss: 0.069114, loss_s1: 0.065053, loss_fp: 0.005812, loss_freq: 0.016387
[14:58:22.834] iteration 16865: loss: 0.090737, loss_s1: 0.051280, loss_fp: 0.008997, loss_freq: 0.034841
[14:58:23.469] iteration 16866: loss: 0.081689, loss_s1: 0.056367, loss_fp: 0.001717, loss_freq: 0.044985
[14:58:24.102] iteration 16867: loss: 0.103949, loss_s1: 0.124329, loss_fp: 0.002051, loss_freq: 0.041801
[14:58:24.723] iteration 16868: loss: 0.084807, loss_s1: 0.060073, loss_fp: 0.010438, loss_freq: 0.024558
[14:58:25.355] iteration 16869: loss: 0.055187, loss_s1: 0.035523, loss_fp: 0.001594, loss_freq: 0.026632
[14:58:25.986] iteration 16870: loss: 0.070028, loss_s1: 0.046113, loss_fp: 0.014178, loss_freq: 0.035731
[14:58:26.642] iteration 16871: loss: 0.068735, loss_s1: 0.032259, loss_fp: 0.007780, loss_freq: 0.016096
[14:58:27.290] iteration 16872: loss: 0.071344, loss_s1: 0.051317, loss_fp: 0.002254, loss_freq: 0.039757
[14:58:27.933] iteration 16873: loss: 0.064525, loss_s1: 0.040682, loss_fp: 0.017045, loss_freq: 0.013263
[14:58:28.570] iteration 16874: loss: 0.029081, loss_s1: 0.012799, loss_fp: 0.005210, loss_freq: 0.009469
[14:58:29.564] iteration 16875: loss: 0.065559, loss_s1: 0.050443, loss_fp: 0.002568, loss_freq: 0.021089
[14:58:30.245] iteration 16876: loss: 0.046814, loss_s1: 0.024206, loss_fp: 0.002425, loss_freq: 0.014569
[14:58:30.902] iteration 16877: loss: 0.051951, loss_s1: 0.034973, loss_fp: 0.000612, loss_freq: 0.019740
[14:58:31.544] iteration 16878: loss: 0.060193, loss_s1: 0.036432, loss_fp: 0.001336, loss_freq: 0.017288
[14:58:32.216] iteration 16879: loss: 0.062816, loss_s1: 0.042197, loss_fp: 0.005572, loss_freq: 0.024285
[14:58:32.856] iteration 16880: loss: 0.048338, loss_s1: 0.042864, loss_fp: 0.001037, loss_freq: 0.008216
[14:58:33.502] iteration 16881: loss: 0.032828, loss_s1: 0.020295, loss_fp: 0.004778, loss_freq: 0.008914
[14:58:34.138] iteration 16882: loss: 0.082489, loss_s1: 0.045047, loss_fp: 0.005240, loss_freq: 0.036187
[14:58:34.778] iteration 16883: loss: 0.051038, loss_s1: 0.037942, loss_fp: 0.004421, loss_freq: 0.016735
[14:58:35.421] iteration 16884: loss: 0.061382, loss_s1: 0.016252, loss_fp: 0.000863, loss_freq: 0.004175
[14:58:36.065] iteration 16885: loss: 0.066101, loss_s1: 0.057955, loss_fp: 0.002090, loss_freq: 0.027511
[14:58:36.695] iteration 16886: loss: 0.052299, loss_s1: 0.034043, loss_fp: 0.003235, loss_freq: 0.009454
[14:58:37.325] iteration 16887: loss: 0.078993, loss_s1: 0.078423, loss_fp: 0.000576, loss_freq: 0.027420
[14:58:37.958] iteration 16888: loss: 0.060336, loss_s1: 0.017890, loss_fp: 0.002566, loss_freq: 0.037773
[14:58:38.594] iteration 16889: loss: 0.075371, loss_s1: 0.051447, loss_fp: 0.012244, loss_freq: 0.044149
[14:58:39.237] iteration 16890: loss: 0.043528, loss_s1: 0.021300, loss_fp: 0.002578, loss_freq: 0.022734
[14:58:39.867] iteration 16891: loss: 0.110881, loss_s1: 0.012063, loss_fp: 0.001990, loss_freq: 0.026414
[14:58:40.505] iteration 16892: loss: 0.043420, loss_s1: 0.011433, loss_fp: 0.000293, loss_freq: 0.013712
[14:58:41.141] iteration 16893: loss: 0.041899, loss_s1: 0.020255, loss_fp: 0.002025, loss_freq: 0.023348
[14:58:41.778] iteration 16894: loss: 0.035526, loss_s1: 0.006984, loss_fp: 0.007234, loss_freq: 0.022329
[14:58:42.422] iteration 16895: loss: 0.106375, loss_s1: 0.073169, loss_fp: 0.002741, loss_freq: 0.062830
[14:58:43.052] iteration 16896: loss: 0.049608, loss_s1: 0.037375, loss_fp: 0.001032, loss_freq: 0.022531
[14:58:43.682] iteration 16897: loss: 0.059374, loss_s1: 0.022459, loss_fp: 0.006035, loss_freq: 0.021152
[14:58:44.312] iteration 16898: loss: 0.056936, loss_s1: 0.019144, loss_fp: 0.002152, loss_freq: 0.006549
[14:58:44.954] iteration 16899: loss: 0.062014, loss_s1: 0.047670, loss_fp: 0.002498, loss_freq: 0.018630
[14:58:45.656] iteration 16900: loss: 0.085858, loss_s1: 0.071726, loss_fp: 0.009168, loss_freq: 0.036769
[14:58:46.299] iteration 16901: loss: 0.079282, loss_s1: 0.035374, loss_fp: 0.001852, loss_freq: 0.066982
[14:58:47.049] iteration 16902: loss: 0.065359, loss_s1: 0.075558, loss_fp: 0.001039, loss_freq: 0.014359
[14:58:47.718] iteration 16903: loss: 0.073045, loss_s1: 0.051403, loss_fp: 0.001399, loss_freq: 0.037562
[14:58:48.373] iteration 16904: loss: 0.049980, loss_s1: 0.009915, loss_fp: 0.002040, loss_freq: 0.010667
[14:58:49.026] iteration 16905: loss: 0.034680, loss_s1: 0.014614, loss_fp: 0.004275, loss_freq: 0.010614
[14:58:49.683] iteration 16906: loss: 0.058011, loss_s1: 0.027813, loss_fp: 0.005608, loss_freq: 0.034970
[14:58:50.339] iteration 16907: loss: 0.077406, loss_s1: 0.059781, loss_fp: 0.006428, loss_freq: 0.049126
[14:58:50.978] iteration 16908: loss: 0.081155, loss_s1: 0.056282, loss_fp: 0.002396, loss_freq: 0.061390
[14:58:51.600] iteration 16909: loss: 0.071662, loss_s1: 0.058239, loss_fp: 0.006221, loss_freq: 0.012203
[14:58:52.220] iteration 16910: loss: 0.071454, loss_s1: 0.048398, loss_fp: 0.002400, loss_freq: 0.031443
[14:58:52.855] iteration 16911: loss: 0.054443, loss_s1: 0.031106, loss_fp: 0.001663, loss_freq: 0.030327
[14:58:53.487] iteration 16912: loss: 0.065103, loss_s1: 0.076779, loss_fp: 0.002934, loss_freq: 0.018261
[14:58:54.117] iteration 16913: loss: 0.081386, loss_s1: 0.059734, loss_fp: 0.002309, loss_freq: 0.036891
[14:58:54.748] iteration 16914: loss: 0.058682, loss_s1: 0.055240, loss_fp: 0.002058, loss_freq: 0.016732
[14:58:55.398] iteration 16915: loss: 0.077210, loss_s1: 0.035708, loss_fp: 0.003239, loss_freq: 0.026697
[14:58:56.028] iteration 16916: loss: 0.061345, loss_s1: 0.056680, loss_fp: 0.004310, loss_freq: 0.021771
[14:58:56.656] iteration 16917: loss: 0.065838, loss_s1: 0.030742, loss_fp: 0.002406, loss_freq: 0.033003
[14:58:57.285] iteration 16918: loss: 0.053606, loss_s1: 0.055995, loss_fp: 0.003804, loss_freq: 0.012581
[14:58:57.907] iteration 16919: loss: 0.050468, loss_s1: 0.013226, loss_fp: 0.000658, loss_freq: 0.017447
[14:58:58.530] iteration 16920: loss: 0.091317, loss_s1: 0.066130, loss_fp: 0.008321, loss_freq: 0.063647
[14:58:59.160] iteration 16921: loss: 0.052384, loss_s1: 0.044008, loss_fp: 0.002356, loss_freq: 0.011403
[14:58:59.823] iteration 16922: loss: 0.039946, loss_s1: 0.015933, loss_fp: 0.001515, loss_freq: 0.008717
[14:59:00.489] iteration 16923: loss: 0.065482, loss_s1: 0.073272, loss_fp: 0.003176, loss_freq: 0.013009
[14:59:01.150] iteration 16924: loss: 0.057878, loss_s1: 0.045066, loss_fp: 0.002408, loss_freq: 0.025709
[14:59:01.814] iteration 16925: loss: 0.055303, loss_s1: 0.045693, loss_fp: 0.000686, loss_freq: 0.015241
[14:59:02.448] iteration 16926: loss: 0.072764, loss_s1: 0.023838, loss_fp: 0.005926, loss_freq: 0.021771
[14:59:03.081] iteration 16927: loss: 0.066072, loss_s1: 0.050942, loss_fp: 0.001490, loss_freq: 0.020655
[14:59:03.712] iteration 16928: loss: 0.038680, loss_s1: 0.024754, loss_fp: 0.001034, loss_freq: 0.015745
[14:59:04.347] iteration 16929: loss: 0.058235, loss_s1: 0.059350, loss_fp: 0.003754, loss_freq: 0.008358
[14:59:04.977] iteration 16930: loss: 0.058065, loss_s1: 0.042564, loss_fp: 0.002046, loss_freq: 0.012787
[14:59:05.604] iteration 16931: loss: 0.044090, loss_s1: 0.023670, loss_fp: 0.004922, loss_freq: 0.028293
[14:59:06.337] iteration 16932: loss: 0.033347, loss_s1: 0.018528, loss_fp: 0.000807, loss_freq: 0.011702
[14:59:06.961] iteration 16933: loss: 0.057634, loss_s1: 0.027392, loss_fp: 0.001051, loss_freq: 0.044988
[14:59:07.671] iteration 16934: loss: 0.076728, loss_s1: 0.064484, loss_fp: 0.006583, loss_freq: 0.041200
[14:59:08.297] iteration 16935: loss: 0.051739, loss_s1: 0.045176, loss_fp: 0.001464, loss_freq: 0.016191
[14:59:08.936] iteration 16936: loss: 0.040952, loss_s1: 0.020094, loss_fp: 0.001245, loss_freq: 0.011376
[14:59:09.575] iteration 16937: loss: 0.061163, loss_s1: 0.036141, loss_fp: 0.003062, loss_freq: 0.043451
[14:59:10.212] iteration 16938: loss: 0.045887, loss_s1: 0.022412, loss_fp: 0.001750, loss_freq: 0.020511
[14:59:10.852] iteration 16939: loss: 0.094593, loss_s1: 0.037427, loss_fp: 0.000880, loss_freq: 0.030091
[14:59:11.489] iteration 16940: loss: 0.055360, loss_s1: 0.018163, loss_fp: 0.002328, loss_freq: 0.019328
[14:59:12.141] iteration 16941: loss: 0.121272, loss_s1: 0.064332, loss_fp: 0.001882, loss_freq: 0.127969
[14:59:12.803] iteration 16942: loss: 0.037331, loss_s1: 0.015267, loss_fp: 0.004208, loss_freq: 0.018517
[14:59:13.466] iteration 16943: loss: 0.054023, loss_s1: 0.056217, loss_fp: 0.001749, loss_freq: 0.008260
[14:59:14.132] iteration 16944: loss: 0.109347, loss_s1: 0.037013, loss_fp: 0.012295, loss_freq: 0.016528
[14:59:14.805] iteration 16945: loss: 0.047061, loss_s1: 0.020997, loss_fp: 0.003931, loss_freq: 0.016648
[14:59:15.436] iteration 16946: loss: 0.060790, loss_s1: 0.035839, loss_fp: 0.004196, loss_freq: 0.028997
[14:59:16.088] iteration 16947: loss: 0.061272, loss_s1: 0.034352, loss_fp: 0.004355, loss_freq: 0.029174
[14:59:16.726] iteration 16948: loss: 0.106444, loss_s1: 0.096889, loss_fp: 0.002888, loss_freq: 0.046316
[14:59:17.355] iteration 16949: loss: 0.059938, loss_s1: 0.033771, loss_fp: 0.006994, loss_freq: 0.035831
[14:59:17.981] iteration 16950: loss: 0.048065, loss_s1: 0.022289, loss_fp: 0.002572, loss_freq: 0.013762
[14:59:18.644] iteration 16951: loss: 0.052287, loss_s1: 0.039475, loss_fp: 0.011181, loss_freq: 0.023539
[14:59:19.312] iteration 16952: loss: 0.062345, loss_s1: 0.019603, loss_fp: 0.002244, loss_freq: 0.012299
[14:59:19.976] iteration 16953: loss: 0.099283, loss_s1: 0.100190, loss_fp: 0.004876, loss_freq: 0.044843
[14:59:20.691] iteration 16954: loss: 0.087074, loss_s1: 0.061870, loss_fp: 0.007450, loss_freq: 0.014296
[14:59:21.321] iteration 16955: loss: 0.082048, loss_s1: 0.071454, loss_fp: 0.000865, loss_freq: 0.035844
[14:59:21.987] iteration 16956: loss: 0.067717, loss_s1: 0.043041, loss_fp: 0.004155, loss_freq: 0.046366
[14:59:22.628] iteration 16957: loss: 0.054179, loss_s1: 0.034997, loss_fp: 0.002022, loss_freq: 0.019655
[14:59:23.262] iteration 16958: loss: 0.033603, loss_s1: 0.022711, loss_fp: 0.001228, loss_freq: 0.007497
[14:59:23.897] iteration 16959: loss: 0.050328, loss_s1: 0.022133, loss_fp: 0.002091, loss_freq: 0.031660
[14:59:24.534] iteration 16960: loss: 0.073186, loss_s1: 0.032691, loss_fp: 0.001611, loss_freq: 0.071213
[14:59:25.169] iteration 16961: loss: 0.041836, loss_s1: 0.016782, loss_fp: 0.007093, loss_freq: 0.018747
[14:59:25.795] iteration 16962: loss: 0.040286, loss_s1: 0.019299, loss_fp: 0.002688, loss_freq: 0.015604
[14:59:26.422] iteration 16963: loss: 0.041383, loss_s1: 0.032233, loss_fp: 0.001316, loss_freq: 0.008412
[14:59:27.059] iteration 16964: loss: 0.045398, loss_s1: 0.038403, loss_fp: 0.008204, loss_freq: 0.014222
[14:59:27.692] iteration 16965: loss: 0.077340, loss_s1: 0.038161, loss_fp: 0.002199, loss_freq: 0.026646
[14:59:28.326] iteration 16966: loss: 0.084546, loss_s1: 0.065547, loss_fp: 0.005043, loss_freq: 0.050336
[14:59:28.969] iteration 16967: loss: 0.052935, loss_s1: 0.047837, loss_fp: 0.002844, loss_freq: 0.018178
[14:59:29.615] iteration 16968: loss: 0.050860, loss_s1: 0.046399, loss_fp: 0.001311, loss_freq: 0.006101
[14:59:30.263] iteration 16969: loss: 0.051997, loss_s1: 0.026769, loss_fp: 0.004901, loss_freq: 0.030872
[14:59:30.921] iteration 16970: loss: 0.074406, loss_s1: 0.047770, loss_fp: 0.000658, loss_freq: 0.037012
[14:59:31.612] iteration 16971: loss: 0.081740, loss_s1: 0.056786, loss_fp: 0.007298, loss_freq: 0.046128
[14:59:32.274] iteration 16972: loss: 0.061406, loss_s1: 0.033995, loss_fp: 0.005294, loss_freq: 0.040939
[14:59:32.931] iteration 16973: loss: 0.054982, loss_s1: 0.038371, loss_fp: 0.000766, loss_freq: 0.012557
[14:59:33.591] iteration 16974: loss: 0.097910, loss_s1: 0.066492, loss_fp: 0.002342, loss_freq: 0.034738
[14:59:34.250] iteration 16975: loss: 0.084322, loss_s1: 0.084095, loss_fp: 0.002422, loss_freq: 0.037432
[14:59:34.904] iteration 16976: loss: 0.085152, loss_s1: 0.035972, loss_fp: 0.002917, loss_freq: 0.033614
[14:59:35.532] iteration 16977: loss: 0.054278, loss_s1: 0.038519, loss_fp: 0.000944, loss_freq: 0.032324
[14:59:36.157] iteration 16978: loss: 0.111254, loss_s1: 0.125353, loss_fp: 0.027124, loss_freq: 0.009121
[14:59:36.786] iteration 16979: loss: 0.067100, loss_s1: 0.031351, loss_fp: 0.005592, loss_freq: 0.019918
[14:59:37.408] iteration 16980: loss: 0.052779, loss_s1: 0.007929, loss_fp: 0.001497, loss_freq: 0.023195
[14:59:38.039] iteration 16981: loss: 0.125682, loss_s1: 0.093995, loss_fp: 0.002587, loss_freq: 0.108537
[14:59:38.666] iteration 16982: loss: 0.100163, loss_s1: 0.062052, loss_fp: 0.013152, loss_freq: 0.080640
[14:59:39.299] iteration 16983: loss: 0.067324, loss_s1: 0.031861, loss_fp: 0.003984, loss_freq: 0.024024
[14:59:39.933] iteration 16984: loss: 0.045842, loss_s1: 0.033590, loss_fp: 0.003076, loss_freq: 0.021336
[14:59:40.559] iteration 16985: loss: 0.056313, loss_s1: 0.046697, loss_fp: 0.001379, loss_freq: 0.022601
[14:59:41.190] iteration 16986: loss: 0.054305, loss_s1: 0.043071, loss_fp: 0.000616, loss_freq: 0.031910
[14:59:41.822] iteration 16987: loss: 0.067908, loss_s1: 0.051117, loss_fp: 0.001057, loss_freq: 0.012283
[14:59:42.449] iteration 16988: loss: 0.052415, loss_s1: 0.034450, loss_fp: 0.005714, loss_freq: 0.019147
[14:59:43.081] iteration 16989: loss: 0.086199, loss_s1: 0.056021, loss_fp: 0.001231, loss_freq: 0.028817
[14:59:43.710] iteration 16990: loss: 0.043461, loss_s1: 0.027132, loss_fp: 0.001450, loss_freq: 0.015290
[14:59:44.358] iteration 16991: loss: 0.063005, loss_s1: 0.041676, loss_fp: 0.001064, loss_freq: 0.026338
[14:59:44.983] iteration 16992: loss: 0.062922, loss_s1: 0.040888, loss_fp: 0.004247, loss_freq: 0.032868
[14:59:45.605] iteration 16993: loss: 0.058177, loss_s1: 0.058749, loss_fp: 0.002578, loss_freq: 0.018968
[14:59:46.231] iteration 16994: loss: 0.056400, loss_s1: 0.030200, loss_fp: 0.002598, loss_freq: 0.025609
[14:59:46.864] iteration 16995: loss: 0.069111, loss_s1: 0.054837, loss_fp: 0.007670, loss_freq: 0.039012
[14:59:47.507] iteration 16996: loss: 0.042766, loss_s1: 0.021152, loss_fp: 0.003294, loss_freq: 0.018885
[14:59:48.143] iteration 16997: loss: 0.031435, loss_s1: 0.013765, loss_fp: 0.002880, loss_freq: 0.005695
[14:59:48.782] iteration 16998: loss: 0.081713, loss_s1: 0.089415, loss_fp: 0.001271, loss_freq: 0.014963
[14:59:49.425] iteration 16999: loss: 0.073084, loss_s1: 0.048443, loss_fp: 0.009484, loss_freq: 0.026161
[14:59:50.063] iteration 17000: loss: 0.075414, loss_s1: 0.047182, loss_fp: 0.002481, loss_freq: 0.011294
[14:59:53.616] iteration 17000 : mean_dice : 0.782872
[14:59:54.302] iteration 17001: loss: 0.046717, loss_s1: 0.024645, loss_fp: 0.002487, loss_freq: 0.023247
[14:59:54.968] iteration 17002: loss: 0.058203, loss_s1: 0.040164, loss_fp: 0.003625, loss_freq: 0.030689
[14:59:55.638] iteration 17003: loss: 0.086102, loss_s1: 0.070517, loss_fp: 0.006690, loss_freq: 0.034133
[14:59:56.298] iteration 17004: loss: 0.053088, loss_s1: 0.021657, loss_fp: 0.004243, loss_freq: 0.015169
[14:59:56.954] iteration 17005: loss: 0.047811, loss_s1: 0.014711, loss_fp: 0.004925, loss_freq: 0.012274
[14:59:57.645] iteration 17006: loss: 0.077215, loss_s1: 0.050293, loss_fp: 0.007912, loss_freq: 0.024728
[14:59:58.275] iteration 17007: loss: 0.053732, loss_s1: 0.021291, loss_fp: 0.000767, loss_freq: 0.044930
[14:59:58.896] iteration 17008: loss: 0.136513, loss_s1: 0.023481, loss_fp: 0.001176, loss_freq: 0.068976
[14:59:59.511] iteration 17009: loss: 0.061400, loss_s1: 0.017260, loss_fp: 0.003130, loss_freq: 0.030794
[15:00:00.145] iteration 17010: loss: 0.059930, loss_s1: 0.051024, loss_fp: 0.008259, loss_freq: 0.026323
[15:00:00.780] iteration 17011: loss: 0.074895, loss_s1: 0.077678, loss_fp: 0.002430, loss_freq: 0.021811
[15:00:01.412] iteration 17012: loss: 0.024102, loss_s1: 0.008554, loss_fp: 0.000812, loss_freq: 0.004541
[15:00:02.056] iteration 17013: loss: 0.049529, loss_s1: 0.039658, loss_fp: 0.001435, loss_freq: 0.013480
[15:00:02.703] iteration 17014: loss: 0.045599, loss_s1: 0.018690, loss_fp: 0.004980, loss_freq: 0.016116
[15:00:03.354] iteration 17015: loss: 0.066993, loss_s1: 0.032476, loss_fp: 0.001999, loss_freq: 0.031934
[15:00:03.976] iteration 17016: loss: 0.094063, loss_s1: 0.079449, loss_fp: 0.012423, loss_freq: 0.043662
[15:00:04.605] iteration 17017: loss: 0.044996, loss_s1: 0.017961, loss_fp: 0.002852, loss_freq: 0.033674
[15:00:05.555] iteration 17018: loss: 0.053985, loss_s1: 0.042255, loss_fp: 0.000803, loss_freq: 0.019507
[15:00:06.206] iteration 17019: loss: 0.047220, loss_s1: 0.026856, loss_fp: 0.003868, loss_freq: 0.026902
[15:00:06.846] iteration 17020: loss: 0.050489, loss_s1: 0.027721, loss_fp: 0.001465, loss_freq: 0.026533
[15:00:07.478] iteration 17021: loss: 0.061526, loss_s1: 0.050734, loss_fp: 0.001588, loss_freq: 0.011117
[15:00:08.110] iteration 17022: loss: 0.072950, loss_s1: 0.037384, loss_fp: 0.006383, loss_freq: 0.064647
[15:00:08.776] iteration 17023: loss: 0.057534, loss_s1: 0.029739, loss_fp: 0.001291, loss_freq: 0.001076
[15:00:09.455] iteration 17024: loss: 0.066698, loss_s1: 0.075100, loss_fp: 0.003627, loss_freq: 0.022737
[15:00:10.104] iteration 17025: loss: 0.057948, loss_s1: 0.029612, loss_fp: 0.005064, loss_freq: 0.017138
[15:00:10.752] iteration 17026: loss: 0.064180, loss_s1: 0.042350, loss_fp: 0.008841, loss_freq: 0.023316
[15:00:11.391] iteration 17027: loss: 0.047942, loss_s1: 0.027292, loss_fp: 0.000718, loss_freq: 0.008645
[15:00:12.050] iteration 17028: loss: 0.067064, loss_s1: 0.037943, loss_fp: 0.006242, loss_freq: 0.045827
[15:00:12.696] iteration 17029: loss: 0.039583, loss_s1: 0.011824, loss_fp: 0.000689, loss_freq: 0.010155
[15:00:13.339] iteration 17030: loss: 0.060685, loss_s1: 0.073220, loss_fp: 0.002554, loss_freq: 0.005125
[15:00:14.056] iteration 17031: loss: 0.048085, loss_s1: 0.031528, loss_fp: 0.004112, loss_freq: 0.025482
[15:00:14.724] iteration 17032: loss: 0.091581, loss_s1: 0.097677, loss_fp: 0.000865, loss_freq: 0.044693
[15:00:15.427] iteration 17033: loss: 0.050663, loss_s1: 0.028354, loss_fp: 0.000656, loss_freq: 0.018442
[15:00:16.089] iteration 17034: loss: 0.051993, loss_s1: 0.024223, loss_fp: 0.000940, loss_freq: 0.016110
[15:00:16.761] iteration 17035: loss: 0.059939, loss_s1: 0.061569, loss_fp: 0.001411, loss_freq: 0.011249
[15:00:17.407] iteration 17036: loss: 0.051817, loss_s1: 0.032611, loss_fp: 0.004887, loss_freq: 0.023567
[15:00:18.035] iteration 17037: loss: 0.050756, loss_s1: 0.055494, loss_fp: 0.002597, loss_freq: 0.013751
[15:00:18.700] iteration 17038: loss: 0.057353, loss_s1: 0.029222, loss_fp: 0.003120, loss_freq: 0.020672
[15:00:19.371] iteration 17039: loss: 0.068160, loss_s1: 0.072623, loss_fp: 0.004442, loss_freq: 0.013884
[15:00:20.018] iteration 17040: loss: 0.073323, loss_s1: 0.077590, loss_fp: 0.002904, loss_freq: 0.018916
[15:00:20.661] iteration 17041: loss: 0.038812, loss_s1: 0.020937, loss_fp: 0.001888, loss_freq: 0.006868
[15:00:21.304] iteration 17042: loss: 0.056386, loss_s1: 0.039991, loss_fp: 0.001289, loss_freq: 0.022513
[15:00:21.942] iteration 17043: loss: 0.096512, loss_s1: 0.049745, loss_fp: 0.002308, loss_freq: 0.036400
[15:00:22.597] iteration 17044: loss: 0.095812, loss_s1: 0.068767, loss_fp: 0.006435, loss_freq: 0.073082
[15:00:23.226] iteration 17045: loss: 0.042171, loss_s1: 0.028242, loss_fp: 0.002908, loss_freq: 0.006589
[15:00:23.886] iteration 17046: loss: 0.071283, loss_s1: 0.035103, loss_fp: 0.001394, loss_freq: 0.037842
[15:00:24.550] iteration 17047: loss: 0.059017, loss_s1: 0.023354, loss_fp: 0.003944, loss_freq: 0.009127
[15:00:25.203] iteration 17048: loss: 0.069099, loss_s1: 0.062222, loss_fp: 0.002590, loss_freq: 0.025666
[15:00:25.858] iteration 17049: loss: 0.070556, loss_s1: 0.053682, loss_fp: 0.002911, loss_freq: 0.031442
[15:00:26.517] iteration 17050: loss: 0.057599, loss_s1: 0.033511, loss_fp: 0.007048, loss_freq: 0.034305
[15:00:27.174] iteration 17051: loss: 0.075560, loss_s1: 0.050172, loss_fp: 0.016376, loss_freq: 0.043219
[15:00:27.822] iteration 17052: loss: 0.049324, loss_s1: 0.032614, loss_fp: 0.002770, loss_freq: 0.019030
[15:00:28.450] iteration 17053: loss: 0.055784, loss_s1: 0.034429, loss_fp: 0.000811, loss_freq: 0.034173
[15:00:29.082] iteration 17054: loss: 0.088575, loss_s1: 0.061486, loss_fp: 0.004529, loss_freq: 0.048179
[15:00:29.708] iteration 17055: loss: 0.057129, loss_s1: 0.052559, loss_fp: 0.003178, loss_freq: 0.020922
[15:00:30.366] iteration 17056: loss: 0.067537, loss_s1: 0.049526, loss_fp: 0.013451, loss_freq: 0.018075
[15:00:30.991] iteration 17057: loss: 0.035336, loss_s1: 0.009157, loss_fp: 0.002413, loss_freq: 0.015462
[15:00:31.614] iteration 17058: loss: 0.063493, loss_s1: 0.043983, loss_fp: 0.004414, loss_freq: 0.026383
[15:00:32.239] iteration 17059: loss: 0.042151, loss_s1: 0.032483, loss_fp: 0.003841, loss_freq: 0.020480
[15:00:32.875] iteration 17060: loss: 0.039966, loss_s1: 0.016547, loss_fp: 0.001730, loss_freq: 0.009843
[15:00:33.507] iteration 17061: loss: 0.096411, loss_s1: 0.092213, loss_fp: 0.004811, loss_freq: 0.054250
[15:00:34.126] iteration 17062: loss: 0.060338, loss_s1: 0.021259, loss_fp: 0.004128, loss_freq: 0.006058
[15:00:34.751] iteration 17063: loss: 0.079124, loss_s1: 0.068613, loss_fp: 0.001885, loss_freq: 0.048867
[15:00:35.381] iteration 17064: loss: 0.069785, loss_s1: 0.056345, loss_fp: 0.006053, loss_freq: 0.032770
[15:00:36.014] iteration 17065: loss: 0.065683, loss_s1: 0.057440, loss_fp: 0.002364, loss_freq: 0.027724
[15:00:36.649] iteration 17066: loss: 0.058534, loss_s1: 0.041606, loss_fp: 0.002190, loss_freq: 0.031380
[15:00:37.280] iteration 17067: loss: 0.050075, loss_s1: 0.029833, loss_fp: 0.007569, loss_freq: 0.011631
[15:00:37.907] iteration 17068: loss: 0.050960, loss_s1: 0.029190, loss_fp: 0.006001, loss_freq: 0.028567
[15:00:38.538] iteration 17069: loss: 0.053899, loss_s1: 0.026501, loss_fp: 0.001126, loss_freq: 0.021855
[15:00:39.164] iteration 17070: loss: 0.043789, loss_s1: 0.024409, loss_fp: 0.003005, loss_freq: 0.015443
[15:00:39.795] iteration 17071: loss: 0.039422, loss_s1: 0.012377, loss_fp: 0.003315, loss_freq: 0.010159
[15:00:40.418] iteration 17072: loss: 0.042004, loss_s1: 0.036103, loss_fp: 0.001774, loss_freq: 0.012618
[15:00:41.058] iteration 17073: loss: 0.041108, loss_s1: 0.026846, loss_fp: 0.000820, loss_freq: 0.007595
[15:00:41.686] iteration 17074: loss: 0.081783, loss_s1: 0.097475, loss_fp: 0.007808, loss_freq: 0.018845
[15:00:42.311] iteration 17075: loss: 0.055213, loss_s1: 0.025841, loss_fp: 0.005388, loss_freq: 0.020391
[15:00:42.932] iteration 17076: loss: 0.097622, loss_s1: 0.043094, loss_fp: 0.004983, loss_freq: 0.065735
[15:00:43.560] iteration 17077: loss: 0.051736, loss_s1: 0.016412, loss_fp: 0.004106, loss_freq: 0.028630
[15:00:44.187] iteration 17078: loss: 0.045721, loss_s1: 0.018453, loss_fp: 0.008303, loss_freq: 0.009826
[15:00:44.818] iteration 17079: loss: 0.051961, loss_s1: 0.036242, loss_fp: 0.001731, loss_freq: 0.008766
[15:00:45.446] iteration 17080: loss: 0.046330, loss_s1: 0.019564, loss_fp: 0.004266, loss_freq: 0.026863
[15:00:46.069] iteration 17081: loss: 0.055781, loss_s1: 0.029816, loss_fp: 0.001757, loss_freq: 0.024023
[15:00:46.698] iteration 17082: loss: 0.110551, loss_s1: 0.023845, loss_fp: 0.004662, loss_freq: 0.034198
[15:00:47.326] iteration 17083: loss: 0.065764, loss_s1: 0.038752, loss_fp: 0.002985, loss_freq: 0.020865
[15:00:47.959] iteration 17084: loss: 0.103754, loss_s1: 0.081604, loss_fp: 0.022206, loss_freq: 0.044977
[15:00:48.587] iteration 17085: loss: 0.051949, loss_s1: 0.026452, loss_fp: 0.006990, loss_freq: 0.029353
[15:00:49.320] iteration 17086: loss: 0.049542, loss_s1: 0.042307, loss_fp: 0.003853, loss_freq: 0.010302
[15:00:50.213] iteration 17087: loss: 0.065205, loss_s1: 0.030960, loss_fp: 0.000736, loss_freq: 0.025414
[15:00:50.844] iteration 17088: loss: 0.058991, loss_s1: 0.030996, loss_fp: 0.000624, loss_freq: 0.023513
[15:00:51.483] iteration 17089: loss: 0.112260, loss_s1: 0.087646, loss_fp: 0.008349, loss_freq: 0.071046
[15:00:52.149] iteration 17090: loss: 0.068893, loss_s1: 0.028780, loss_fp: 0.010524, loss_freq: 0.061279
[15:00:52.788] iteration 17091: loss: 0.051708, loss_s1: 0.032649, loss_fp: 0.004062, loss_freq: 0.020284
[15:00:53.414] iteration 17092: loss: 0.060722, loss_s1: 0.039571, loss_fp: 0.005244, loss_freq: 0.047144
[15:00:54.043] iteration 17093: loss: 0.088358, loss_s1: 0.057246, loss_fp: 0.003627, loss_freq: 0.030337
[15:00:54.673] iteration 17094: loss: 0.063467, loss_s1: 0.065858, loss_fp: 0.002506, loss_freq: 0.029104
[15:00:55.303] iteration 17095: loss: 0.057218, loss_s1: 0.014780, loss_fp: 0.002239, loss_freq: 0.016062
[15:00:55.984] iteration 17096: loss: 0.125478, loss_s1: 0.106817, loss_fp: 0.006683, loss_freq: 0.062613
[15:00:56.650] iteration 17097: loss: 0.113465, loss_s1: 0.081993, loss_fp: 0.011961, loss_freq: 0.036297
[15:00:57.295] iteration 17098: loss: 0.087042, loss_s1: 0.064108, loss_fp: 0.000674, loss_freq: 0.056572
[15:00:57.947] iteration 17099: loss: 0.045870, loss_s1: 0.022177, loss_fp: 0.002185, loss_freq: 0.025346
[15:00:58.597] iteration 17100: loss: 0.079897, loss_s1: 0.039938, loss_fp: 0.007372, loss_freq: 0.035929
[15:00:59.241] iteration 17101: loss: 0.040114, loss_s1: 0.027613, loss_fp: 0.003984, loss_freq: 0.013180
[15:00:59.878] iteration 17102: loss: 0.083451, loss_s1: 0.064285, loss_fp: 0.008212, loss_freq: 0.042936
[15:01:00.525] iteration 17103: loss: 0.061801, loss_s1: 0.031691, loss_fp: 0.006100, loss_freq: 0.046285
[15:01:01.167] iteration 17104: loss: 0.044761, loss_s1: 0.013321, loss_fp: 0.001971, loss_freq: 0.010359
[15:01:01.827] iteration 17105: loss: 0.046750, loss_s1: 0.022290, loss_fp: 0.000907, loss_freq: 0.011334
[15:01:02.478] iteration 17106: loss: 0.046617, loss_s1: 0.037424, loss_fp: 0.007623, loss_freq: 0.007554
[15:01:03.131] iteration 17107: loss: 0.056382, loss_s1: 0.040798, loss_fp: 0.002119, loss_freq: 0.023362
[15:01:03.783] iteration 17108: loss: 0.073412, loss_s1: 0.019119, loss_fp: 0.013468, loss_freq: 0.025798
[15:01:04.439] iteration 17109: loss: 0.075294, loss_s1: 0.050340, loss_fp: 0.008695, loss_freq: 0.059110
[15:01:05.072] iteration 17110: loss: 0.066259, loss_s1: 0.041123, loss_fp: 0.002612, loss_freq: 0.030421
[15:01:05.704] iteration 17111: loss: 0.052669, loss_s1: 0.020534, loss_fp: 0.001370, loss_freq: 0.010295
[15:01:06.333] iteration 17112: loss: 0.050698, loss_s1: 0.034354, loss_fp: 0.001958, loss_freq: 0.015686
[15:01:07.012] iteration 17113: loss: 0.055040, loss_s1: 0.041336, loss_fp: 0.010726, loss_freq: 0.008821
[15:01:07.644] iteration 17114: loss: 0.116739, loss_s1: 0.052745, loss_fp: 0.000926, loss_freq: 0.105051
[15:01:08.272] iteration 17115: loss: 0.052873, loss_s1: 0.028551, loss_fp: 0.010208, loss_freq: 0.022409
[15:01:08.901] iteration 17116: loss: 0.079739, loss_s1: 0.037019, loss_fp: 0.005012, loss_freq: 0.041091
[15:01:09.529] iteration 17117: loss: 0.092808, loss_s1: 0.044993, loss_fp: 0.012245, loss_freq: 0.071896
[15:01:10.161] iteration 17118: loss: 0.039007, loss_s1: 0.024682, loss_fp: 0.001151, loss_freq: 0.007449
[15:01:10.793] iteration 17119: loss: 0.045391, loss_s1: 0.014525, loss_fp: 0.000838, loss_freq: 0.015988
[15:01:11.426] iteration 17120: loss: 0.038098, loss_s1: 0.021841, loss_fp: 0.002364, loss_freq: 0.018326
[15:01:12.054] iteration 17121: loss: 0.046746, loss_s1: 0.013876, loss_fp: 0.002143, loss_freq: 0.015535
[15:01:12.686] iteration 17122: loss: 0.055882, loss_s1: 0.010736, loss_fp: 0.002618, loss_freq: 0.044683
[15:01:13.309] iteration 17123: loss: 0.037434, loss_s1: 0.015143, loss_fp: 0.001397, loss_freq: 0.016540
[15:01:13.932] iteration 17124: loss: 0.083540, loss_s1: 0.079755, loss_fp: 0.004892, loss_freq: 0.034369
[15:01:14.562] iteration 17125: loss: 0.048862, loss_s1: 0.043373, loss_fp: 0.003214, loss_freq: 0.020074
[15:01:15.186] iteration 17126: loss: 0.068810, loss_s1: 0.016980, loss_fp: 0.001232, loss_freq: 0.027186
[15:01:15.814] iteration 17127: loss: 0.053806, loss_s1: 0.018160, loss_fp: 0.004684, loss_freq: 0.020070
[15:01:16.439] iteration 17128: loss: 0.059123, loss_s1: 0.043161, loss_fp: 0.001918, loss_freq: 0.022981
[15:01:17.056] iteration 17129: loss: 0.056029, loss_s1: 0.033854, loss_fp: 0.001675, loss_freq: 0.045563
[15:01:17.680] iteration 17130: loss: 0.059560, loss_s1: 0.047865, loss_fp: 0.002460, loss_freq: 0.015671
[15:01:18.305] iteration 17131: loss: 0.061282, loss_s1: 0.030618, loss_fp: 0.013640, loss_freq: 0.028300
[15:01:18.931] iteration 17132: loss: 0.074009, loss_s1: 0.042810, loss_fp: 0.001917, loss_freq: 0.025490
[15:01:19.580] iteration 17133: loss: 0.067121, loss_s1: 0.030721, loss_fp: 0.015186, loss_freq: 0.014646
[15:01:20.237] iteration 17134: loss: 0.078793, loss_s1: 0.053843, loss_fp: 0.004807, loss_freq: 0.043336
[15:01:20.918] iteration 17135: loss: 0.048170, loss_s1: 0.042751, loss_fp: 0.001984, loss_freq: 0.015289
[15:01:21.552] iteration 17136: loss: 0.057534, loss_s1: 0.037752, loss_fp: 0.018648, loss_freq: 0.028865
[15:01:22.177] iteration 17137: loss: 0.069771, loss_s1: 0.064484, loss_fp: 0.002376, loss_freq: 0.030003
[15:01:22.810] iteration 17138: loss: 0.063725, loss_s1: 0.041920, loss_fp: 0.001866, loss_freq: 0.031932
[15:01:23.439] iteration 17139: loss: 0.069003, loss_s1: 0.051458, loss_fp: 0.004140, loss_freq: 0.012481
[15:01:24.075] iteration 17140: loss: 0.033127, loss_s1: 0.020473, loss_fp: 0.001105, loss_freq: 0.003973
[15:01:24.699] iteration 17141: loss: 0.042733, loss_s1: 0.018521, loss_fp: 0.001161, loss_freq: 0.028868
[15:01:25.320] iteration 17142: loss: 0.063279, loss_s1: 0.033734, loss_fp: 0.002937, loss_freq: 0.046970
[15:01:25.939] iteration 17143: loss: 0.062002, loss_s1: 0.044028, loss_fp: 0.000765, loss_freq: 0.026317
[15:01:26.560] iteration 17144: loss: 0.043068, loss_s1: 0.022627, loss_fp: 0.002212, loss_freq: 0.029481
[15:01:27.184] iteration 17145: loss: 0.057901, loss_s1: 0.043427, loss_fp: 0.002489, loss_freq: 0.020001
[15:01:27.805] iteration 17146: loss: 0.093859, loss_s1: 0.089493, loss_fp: 0.005786, loss_freq: 0.014557
[15:01:28.433] iteration 17147: loss: 0.040295, loss_s1: 0.012490, loss_fp: 0.000856, loss_freq: 0.008360
[15:01:29.060] iteration 17148: loss: 0.062755, loss_s1: 0.062956, loss_fp: 0.002152, loss_freq: 0.016002
[15:01:29.679] iteration 17149: loss: 0.114144, loss_s1: 0.089621, loss_fp: 0.004441, loss_freq: 0.042758
[15:01:30.306] iteration 17150: loss: 0.048467, loss_s1: 0.025699, loss_fp: 0.002435, loss_freq: 0.018856
[15:01:30.935] iteration 17151: loss: 0.097134, loss_s1: 0.041667, loss_fp: 0.000657, loss_freq: 0.048337
[15:01:31.579] iteration 17152: loss: 0.080085, loss_s1: 0.048690, loss_fp: 0.006018, loss_freq: 0.031131
[15:01:32.216] iteration 17153: loss: 0.077044, loss_s1: 0.032079, loss_fp: 0.006517, loss_freq: 0.047332
[15:01:32.850] iteration 17154: loss: 0.080905, loss_s1: 0.062779, loss_fp: 0.008128, loss_freq: 0.018926
[15:01:33.487] iteration 17155: loss: 0.056033, loss_s1: 0.043269, loss_fp: 0.001841, loss_freq: 0.012939
[15:01:34.121] iteration 17156: loss: 0.045522, loss_s1: 0.034861, loss_fp: 0.006129, loss_freq: 0.008224
[15:01:34.761] iteration 17157: loss: 0.072751, loss_s1: 0.021745, loss_fp: 0.004404, loss_freq: 0.011994
[15:01:35.393] iteration 17158: loss: 0.082006, loss_s1: 0.052601, loss_fp: 0.001020, loss_freq: 0.061552
[15:01:36.027] iteration 17159: loss: 0.154506, loss_s1: 0.139507, loss_fp: 0.025414, loss_freq: 0.089622
[15:01:36.656] iteration 17160: loss: 0.044502, loss_s1: 0.019998, loss_fp: 0.013360, loss_freq: 0.026371
[15:01:37.590] iteration 17161: loss: 0.054623, loss_s1: 0.052212, loss_fp: 0.004240, loss_freq: 0.009871
[15:01:38.249] iteration 17162: loss: 0.083325, loss_s1: 0.085676, loss_fp: 0.002610, loss_freq: 0.024766
[15:01:38.873] iteration 17163: loss: 0.053750, loss_s1: 0.015012, loss_fp: 0.000676, loss_freq: 0.020802
[15:01:39.507] iteration 17164: loss: 0.065045, loss_s1: 0.047169, loss_fp: 0.002833, loss_freq: 0.009052
[15:01:40.141] iteration 17165: loss: 0.097107, loss_s1: 0.095300, loss_fp: 0.003519, loss_freq: 0.059074
[15:01:40.768] iteration 17166: loss: 0.059919, loss_s1: 0.021869, loss_fp: 0.002306, loss_freq: 0.010172
[15:01:41.402] iteration 17167: loss: 0.039558, loss_s1: 0.021067, loss_fp: 0.004896, loss_freq: 0.018425
[15:01:42.033] iteration 17168: loss: 0.107931, loss_s1: 0.073318, loss_fp: 0.009544, loss_freq: 0.039575
[15:01:42.661] iteration 17169: loss: 0.069123, loss_s1: 0.046660, loss_fp: 0.001471, loss_freq: 0.028701
[15:01:43.291] iteration 17170: loss: 0.086742, loss_s1: 0.038287, loss_fp: 0.013515, loss_freq: 0.008120
[15:01:43.931] iteration 17171: loss: 0.068977, loss_s1: 0.019478, loss_fp: 0.003297, loss_freq: 0.044850
[15:01:44.562] iteration 17172: loss: 0.055430, loss_s1: 0.028343, loss_fp: 0.001875, loss_freq: 0.021999
[15:01:45.232] iteration 17173: loss: 0.065872, loss_s1: 0.042062, loss_fp: 0.003164, loss_freq: 0.016756
[15:01:45.865] iteration 17174: loss: 0.034130, loss_s1: 0.010762, loss_fp: 0.001149, loss_freq: 0.010530
[15:01:46.501] iteration 17175: loss: 0.060815, loss_s1: 0.055989, loss_fp: 0.000980, loss_freq: 0.010972
[15:01:47.121] iteration 17176: loss: 0.041722, loss_s1: 0.020611, loss_fp: 0.005887, loss_freq: 0.010422
[15:01:47.745] iteration 17177: loss: 0.081753, loss_s1: 0.043998, loss_fp: 0.000798, loss_freq: 0.035673
[15:01:48.378] iteration 17178: loss: 0.077680, loss_s1: 0.063040, loss_fp: 0.004295, loss_freq: 0.029030
[15:01:49.012] iteration 17179: loss: 0.053018, loss_s1: 0.039502, loss_fp: 0.000689, loss_freq: 0.027840
[15:01:49.645] iteration 17180: loss: 0.067653, loss_s1: 0.058968, loss_fp: 0.001181, loss_freq: 0.015472
[15:01:50.351] iteration 17181: loss: 0.060441, loss_s1: 0.019001, loss_fp: 0.001906, loss_freq: 0.046528
[15:01:51.024] iteration 17182: loss: 0.070549, loss_s1: 0.045856, loss_fp: 0.009027, loss_freq: 0.050648
[15:01:51.686] iteration 17183: loss: 0.061612, loss_s1: 0.037401, loss_fp: 0.003274, loss_freq: 0.037950
[15:01:52.343] iteration 17184: loss: 0.053784, loss_s1: 0.037109, loss_fp: 0.004035, loss_freq: 0.011632
[15:01:52.997] iteration 17185: loss: 0.074664, loss_s1: 0.063306, loss_fp: 0.002422, loss_freq: 0.020632
[15:01:53.673] iteration 17186: loss: 0.062529, loss_s1: 0.042981, loss_fp: 0.001781, loss_freq: 0.030972
[15:01:54.326] iteration 17187: loss: 0.088944, loss_s1: 0.055198, loss_fp: 0.002038, loss_freq: 0.059782
[15:01:54.982] iteration 17188: loss: 0.061989, loss_s1: 0.053130, loss_fp: 0.001742, loss_freq: 0.013510
[15:01:55.642] iteration 17189: loss: 0.083486, loss_s1: 0.052156, loss_fp: 0.004634, loss_freq: 0.014883
[15:01:56.298] iteration 17190: loss: 0.087663, loss_s1: 0.031902, loss_fp: 0.019462, loss_freq: 0.016751
[15:01:56.956] iteration 17191: loss: 0.036968, loss_s1: 0.025868, loss_fp: 0.001298, loss_freq: 0.005206
[15:01:57.603] iteration 17192: loss: 0.053947, loss_s1: 0.022383, loss_fp: 0.004617, loss_freq: 0.026546
[15:01:58.230] iteration 17193: loss: 0.101762, loss_s1: 0.096198, loss_fp: 0.003024, loss_freq: 0.065955
[15:01:58.903] iteration 17194: loss: 0.079720, loss_s1: 0.054898, loss_fp: 0.007443, loss_freq: 0.046022
[15:01:59.574] iteration 17195: loss: 0.056948, loss_s1: 0.039962, loss_fp: 0.006604, loss_freq: 0.016331
[15:02:00.252] iteration 17196: loss: 0.061764, loss_s1: 0.030130, loss_fp: 0.003318, loss_freq: 0.023549
[15:02:00.946] iteration 17197: loss: 0.072994, loss_s1: 0.048802, loss_fp: 0.001904, loss_freq: 0.015583
[15:02:01.574] iteration 17198: loss: 0.054364, loss_s1: 0.040395, loss_fp: 0.004036, loss_freq: 0.028612
[15:02:02.200] iteration 17199: loss: 0.081147, loss_s1: 0.071556, loss_fp: 0.004929, loss_freq: 0.029510
[15:02:02.827] iteration 17200: loss: 0.053129, loss_s1: 0.018868, loss_fp: 0.006112, loss_freq: 0.027258
[15:02:06.587] iteration 17200 : mean_dice : 0.785221
[15:02:07.278] iteration 17201: loss: 0.058800, loss_s1: 0.057274, loss_fp: 0.006080, loss_freq: 0.013107
[15:02:07.930] iteration 17202: loss: 0.063219, loss_s1: 0.056325, loss_fp: 0.009076, loss_freq: 0.031177
[15:02:08.574] iteration 17203: loss: 0.064566, loss_s1: 0.021433, loss_fp: 0.002285, loss_freq: 0.026140
[15:02:09.212] iteration 17204: loss: 0.060356, loss_s1: 0.048099, loss_fp: 0.002038, loss_freq: 0.031807
[15:02:09.858] iteration 17205: loss: 0.051175, loss_s1: 0.019281, loss_fp: 0.003182, loss_freq: 0.005620
[15:02:10.507] iteration 17206: loss: 0.079846, loss_s1: 0.074013, loss_fp: 0.001232, loss_freq: 0.031629
[15:02:11.150] iteration 17207: loss: 0.077479, loss_s1: 0.028764, loss_fp: 0.000567, loss_freq: 0.045762
[15:02:11.774] iteration 17208: loss: 0.075830, loss_s1: 0.081060, loss_fp: 0.003205, loss_freq: 0.026367
[15:02:12.405] iteration 17209: loss: 0.058532, loss_s1: 0.051076, loss_fp: 0.000846, loss_freq: 0.027593
[15:02:13.039] iteration 17210: loss: 0.034069, loss_s1: 0.011220, loss_fp: 0.001249, loss_freq: 0.015586
[15:02:13.680] iteration 17211: loss: 0.052642, loss_s1: 0.044190, loss_fp: 0.001913, loss_freq: 0.011795
[15:02:14.311] iteration 17212: loss: 0.045185, loss_s1: 0.008589, loss_fp: 0.001609, loss_freq: 0.019649
[15:02:14.953] iteration 17213: loss: 0.036310, loss_s1: 0.022155, loss_fp: 0.003021, loss_freq: 0.010896
[15:02:15.581] iteration 17214: loss: 0.039835, loss_s1: 0.023346, loss_fp: 0.002449, loss_freq: 0.013470
[15:02:16.213] iteration 17215: loss: 0.064411, loss_s1: 0.054080, loss_fp: 0.001253, loss_freq: 0.009500
[15:02:16.851] iteration 17216: loss: 0.041873, loss_s1: 0.006412, loss_fp: 0.000865, loss_freq: 0.014221
[15:02:17.491] iteration 17217: loss: 0.095203, loss_s1: 0.102200, loss_fp: 0.002170, loss_freq: 0.030129
[15:02:18.127] iteration 17218: loss: 0.054207, loss_s1: 0.026655, loss_fp: 0.000433, loss_freq: 0.039701
[15:02:18.763] iteration 17219: loss: 0.083656, loss_s1: 0.057299, loss_fp: 0.002054, loss_freq: 0.060345
[15:02:19.392] iteration 17220: loss: 0.058572, loss_s1: 0.035429, loss_fp: 0.001446, loss_freq: 0.036154
[15:02:20.043] iteration 17221: loss: 0.056034, loss_s1: 0.033311, loss_fp: 0.006748, loss_freq: 0.009024
[15:02:20.707] iteration 17222: loss: 0.053153, loss_s1: 0.047026, loss_fp: 0.001568, loss_freq: 0.016829
[15:02:21.368] iteration 17223: loss: 0.057188, loss_s1: 0.024181, loss_fp: 0.008504, loss_freq: 0.034898
[15:02:22.026] iteration 17224: loss: 0.041392, loss_s1: 0.012606, loss_fp: 0.000650, loss_freq: 0.012231
[15:02:22.687] iteration 17225: loss: 0.051046, loss_s1: 0.038518, loss_fp: 0.000905, loss_freq: 0.010745
[15:02:23.361] iteration 17226: loss: 0.049620, loss_s1: 0.047677, loss_fp: 0.001304, loss_freq: 0.006355
[15:02:24.051] iteration 17227: loss: 0.082626, loss_s1: 0.048874, loss_fp: 0.003030, loss_freq: 0.053340
[15:02:24.713] iteration 17228: loss: 0.042740, loss_s1: 0.035586, loss_fp: 0.001384, loss_freq: 0.014691
[15:02:25.376] iteration 17229: loss: 0.042463, loss_s1: 0.024227, loss_fp: 0.005526, loss_freq: 0.015765
[15:02:26.038] iteration 17230: loss: 0.087730, loss_s1: 0.060163, loss_fp: 0.007066, loss_freq: 0.012505
[15:02:26.679] iteration 17231: loss: 0.069764, loss_s1: 0.071744, loss_fp: 0.000580, loss_freq: 0.017657
[15:02:27.302] iteration 17232: loss: 0.067917, loss_s1: 0.035360, loss_fp: 0.004989, loss_freq: 0.041851
[15:02:27.931] iteration 17233: loss: 0.056372, loss_s1: 0.037413, loss_fp: 0.003185, loss_freq: 0.029426
[15:02:28.566] iteration 17234: loss: 0.093589, loss_s1: 0.063847, loss_fp: 0.003693, loss_freq: 0.019338
[15:02:29.207] iteration 17235: loss: 0.067193, loss_s1: 0.041814, loss_fp: 0.005683, loss_freq: 0.052708
[15:02:29.830] iteration 17236: loss: 0.043534, loss_s1: 0.031420, loss_fp: 0.001810, loss_freq: 0.016215
[15:02:30.455] iteration 17237: loss: 0.064623, loss_s1: 0.036108, loss_fp: 0.003221, loss_freq: 0.052218
[15:02:31.093] iteration 17238: loss: 0.055644, loss_s1: 0.018138, loss_fp: 0.003103, loss_freq: 0.032386
[15:02:31.731] iteration 17239: loss: 0.072536, loss_s1: 0.070159, loss_fp: 0.006578, loss_freq: 0.016970
[15:02:32.370] iteration 17240: loss: 0.140634, loss_s1: 0.097474, loss_fp: 0.006254, loss_freq: 0.037172
[15:02:33.010] iteration 17241: loss: 0.076939, loss_s1: 0.047067, loss_fp: 0.004539, loss_freq: 0.032480
[15:02:33.643] iteration 17242: loss: 0.054008, loss_s1: 0.029015, loss_fp: 0.002269, loss_freq: 0.018284
[15:02:34.308] iteration 17243: loss: 0.081654, loss_s1: 0.031117, loss_fp: 0.005154, loss_freq: 0.062285
[15:02:34.950] iteration 17244: loss: 0.044550, loss_s1: 0.026299, loss_fp: 0.001741, loss_freq: 0.026584
[15:02:35.586] iteration 17245: loss: 0.061200, loss_s1: 0.052212, loss_fp: 0.005726, loss_freq: 0.020929
[15:02:36.217] iteration 17246: loss: 0.052637, loss_s1: 0.013423, loss_fp: 0.003703, loss_freq: 0.035116
[15:02:36.851] iteration 17247: loss: 0.064758, loss_s1: 0.045114, loss_fp: 0.002058, loss_freq: 0.029048
[15:02:37.485] iteration 17248: loss: 0.050653, loss_s1: 0.038335, loss_fp: 0.001936, loss_freq: 0.015613
[15:02:38.168] iteration 17249: loss: 0.038012, loss_s1: 0.017935, loss_fp: 0.001725, loss_freq: 0.018334
[15:02:38.818] iteration 17250: loss: 0.057933, loss_s1: 0.042311, loss_fp: 0.002639, loss_freq: 0.020527
[15:02:39.453] iteration 17251: loss: 0.060401, loss_s1: 0.036857, loss_fp: 0.001133, loss_freq: 0.012719
[15:02:40.086] iteration 17252: loss: 0.068837, loss_s1: 0.069628, loss_fp: 0.007924, loss_freq: 0.027992
[15:02:40.724] iteration 17253: loss: 0.046101, loss_s1: 0.042915, loss_fp: 0.002969, loss_freq: 0.014485
[15:02:41.406] iteration 17254: loss: 0.051138, loss_s1: 0.059092, loss_fp: 0.002474, loss_freq: 0.007550
[15:02:42.066] iteration 17255: loss: 0.043822, loss_s1: 0.027890, loss_fp: 0.000704, loss_freq: 0.010832
[15:02:42.705] iteration 17256: loss: 0.046458, loss_s1: 0.024503, loss_fp: 0.001028, loss_freq: 0.012257
[15:02:43.334] iteration 17257: loss: 0.062789, loss_s1: 0.031189, loss_fp: 0.006566, loss_freq: 0.048243
[15:02:43.969] iteration 17258: loss: 0.063385, loss_s1: 0.049357, loss_fp: 0.001033, loss_freq: 0.037866
[15:02:44.586] iteration 17259: loss: 0.076709, loss_s1: 0.026294, loss_fp: 0.002844, loss_freq: 0.023804
[15:02:45.212] iteration 17260: loss: 0.092692, loss_s1: 0.073726, loss_fp: 0.001064, loss_freq: 0.041038
[15:02:45.841] iteration 17261: loss: 0.066796, loss_s1: 0.034190, loss_fp: 0.001071, loss_freq: 0.054864
[15:02:46.462] iteration 17262: loss: 0.052123, loss_s1: 0.036880, loss_fp: 0.005779, loss_freq: 0.016202
[15:02:47.091] iteration 17263: loss: 0.042093, loss_s1: 0.024812, loss_fp: 0.005579, loss_freq: 0.016333
[15:02:47.720] iteration 17264: loss: 0.044910, loss_s1: 0.022191, loss_fp: 0.002680, loss_freq: 0.020322
[15:02:48.343] iteration 17265: loss: 0.062717, loss_s1: 0.035364, loss_fp: 0.002512, loss_freq: 0.018403
[15:02:48.975] iteration 17266: loss: 0.055085, loss_s1: 0.037883, loss_fp: 0.002032, loss_freq: 0.023560
[15:02:49.609] iteration 17267: loss: 0.109217, loss_s1: 0.073138, loss_fp: 0.003177, loss_freq: 0.086409
[15:02:50.239] iteration 17268: loss: 0.075315, loss_s1: 0.046057, loss_fp: 0.007637, loss_freq: 0.063099
[15:02:50.871] iteration 17269: loss: 0.057545, loss_s1: 0.031984, loss_fp: 0.003641, loss_freq: 0.032537
[15:02:51.499] iteration 17270: loss: 0.078510, loss_s1: 0.060541, loss_fp: 0.003147, loss_freq: 0.048255
[15:02:52.130] iteration 17271: loss: 0.071770, loss_s1: 0.020223, loss_fp: 0.002587, loss_freq: 0.029123
[15:02:52.761] iteration 17272: loss: 0.059062, loss_s1: 0.055242, loss_fp: 0.003195, loss_freq: 0.028204
[15:02:53.395] iteration 17273: loss: 0.068803, loss_s1: 0.040071, loss_fp: 0.002686, loss_freq: 0.009835
[15:02:54.014] iteration 17274: loss: 0.080201, loss_s1: 0.061343, loss_fp: 0.023735, loss_freq: 0.029936
[15:02:54.821] iteration 17275: loss: 0.107543, loss_s1: 0.067458, loss_fp: 0.001348, loss_freq: 0.058529
[15:02:55.680] iteration 17276: loss: 0.051646, loss_s1: 0.021551, loss_fp: 0.002365, loss_freq: 0.022475
[15:02:56.648] iteration 17277: loss: 0.054284, loss_s1: 0.033885, loss_fp: 0.007256, loss_freq: 0.018184
[15:02:57.330] iteration 17278: loss: 0.065803, loss_s1: 0.066638, loss_fp: 0.001531, loss_freq: 0.016642
[15:02:57.975] iteration 17279: loss: 0.035407, loss_s1: 0.022620, loss_fp: 0.003652, loss_freq: 0.010655
[15:02:58.637] iteration 17280: loss: 0.049914, loss_s1: 0.019502, loss_fp: 0.004757, loss_freq: 0.034537
[15:02:59.270] iteration 17281: loss: 0.068363, loss_s1: 0.051843, loss_fp: 0.001366, loss_freq: 0.033999
[15:02:59.934] iteration 17282: loss: 0.067616, loss_s1: 0.053110, loss_fp: 0.001362, loss_freq: 0.016895
[15:03:00.599] iteration 17283: loss: 0.048727, loss_s1: 0.024438, loss_fp: 0.000460, loss_freq: 0.030102
[15:03:01.262] iteration 17284: loss: 0.078913, loss_s1: 0.063512, loss_fp: 0.010532, loss_freq: 0.054550
[15:03:01.919] iteration 17285: loss: 0.047529, loss_s1: 0.012192, loss_fp: 0.001554, loss_freq: 0.054776
[15:03:02.546] iteration 17286: loss: 0.071044, loss_s1: 0.030190, loss_fp: 0.002700, loss_freq: 0.012399
[15:03:03.193] iteration 17287: loss: 0.050462, loss_s1: 0.043248, loss_fp: 0.000716, loss_freq: 0.020152
[15:03:03.821] iteration 17288: loss: 0.059027, loss_s1: 0.038691, loss_fp: 0.002345, loss_freq: 0.024650
[15:03:04.445] iteration 17289: loss: 0.062158, loss_s1: 0.051936, loss_fp: 0.004021, loss_freq: 0.008704
[15:03:05.069] iteration 17290: loss: 0.044021, loss_s1: 0.021582, loss_fp: 0.004094, loss_freq: 0.013333
[15:03:05.703] iteration 17291: loss: 0.077859, loss_s1: 0.054465, loss_fp: 0.005169, loss_freq: 0.021143
[15:03:06.340] iteration 17292: loss: 0.095228, loss_s1: 0.070708, loss_fp: 0.006449, loss_freq: 0.025817
[15:03:06.971] iteration 17293: loss: 0.044699, loss_s1: 0.027450, loss_fp: 0.004423, loss_freq: 0.011037
[15:03:07.591] iteration 17294: loss: 0.076406, loss_s1: 0.029279, loss_fp: 0.004390, loss_freq: 0.071660
[15:03:08.211] iteration 17295: loss: 0.056015, loss_s1: 0.033828, loss_fp: 0.001159, loss_freq: 0.025129
[15:03:08.835] iteration 17296: loss: 0.076221, loss_s1: 0.068824, loss_fp: 0.003772, loss_freq: 0.031882
[15:03:09.466] iteration 17297: loss: 0.066191, loss_s1: 0.051782, loss_fp: 0.002466, loss_freq: 0.027225
[15:03:10.092] iteration 17298: loss: 0.053764, loss_s1: 0.040095, loss_fp: 0.004081, loss_freq: 0.011667
[15:03:10.716] iteration 17299: loss: 0.035641, loss_s1: 0.017005, loss_fp: 0.000903, loss_freq: 0.010149
[15:03:11.340] iteration 17300: loss: 0.058700, loss_s1: 0.026967, loss_fp: 0.003644, loss_freq: 0.007932
[15:03:11.993] iteration 17301: loss: 0.073020, loss_s1: 0.052137, loss_fp: 0.002974, loss_freq: 0.045115
[15:03:12.652] iteration 17302: loss: 0.102904, loss_s1: 0.078885, loss_fp: 0.007096, loss_freq: 0.071581
[15:03:13.307] iteration 17303: loss: 0.041964, loss_s1: 0.015418, loss_fp: 0.001144, loss_freq: 0.018064
[15:03:14.289] iteration 17304: loss: 0.046426, loss_s1: 0.033440, loss_fp: 0.001723, loss_freq: 0.017202
[15:03:14.965] iteration 17305: loss: 0.064019, loss_s1: 0.057003, loss_fp: 0.003557, loss_freq: 0.023028
[15:03:15.635] iteration 17306: loss: 0.035836, loss_s1: 0.008722, loss_fp: 0.006250, loss_freq: 0.012378
[15:03:16.301] iteration 17307: loss: 0.054008, loss_s1: 0.014972, loss_fp: 0.006673, loss_freq: 0.029414
[15:03:16.960] iteration 17308: loss: 0.061843, loss_s1: 0.039256, loss_fp: 0.000933, loss_freq: 0.036807
[15:03:17.602] iteration 17309: loss: 0.062286, loss_s1: 0.046834, loss_fp: 0.003348, loss_freq: 0.010569
[15:03:18.284] iteration 17310: loss: 0.042092, loss_s1: 0.019784, loss_fp: 0.004984, loss_freq: 0.018301
[15:03:18.913] iteration 17311: loss: 0.082317, loss_s1: 0.052219, loss_fp: 0.002693, loss_freq: 0.043969
[15:03:19.541] iteration 17312: loss: 0.049224, loss_s1: 0.020608, loss_fp: 0.002786, loss_freq: 0.029477
[15:03:20.164] iteration 17313: loss: 0.038614, loss_s1: 0.017194, loss_fp: 0.000377, loss_freq: 0.002672
[15:03:20.808] iteration 17314: loss: 0.085001, loss_s1: 0.062705, loss_fp: 0.003556, loss_freq: 0.064743
[15:03:21.443] iteration 17315: loss: 0.042442, loss_s1: 0.014400, loss_fp: 0.002201, loss_freq: 0.007829
[15:03:22.095] iteration 17316: loss: 0.098220, loss_s1: 0.093765, loss_fp: 0.013003, loss_freq: 0.033901
[15:03:22.730] iteration 17317: loss: 0.044088, loss_s1: 0.023808, loss_fp: 0.004294, loss_freq: 0.030959
[15:03:23.355] iteration 17318: loss: 0.047639, loss_s1: 0.034183, loss_fp: 0.002334, loss_freq: 0.022300
[15:03:23.989] iteration 17319: loss: 0.043752, loss_s1: 0.011741, loss_fp: 0.005483, loss_freq: 0.016641
[15:03:24.629] iteration 17320: loss: 0.049796, loss_s1: 0.015349, loss_fp: 0.003006, loss_freq: 0.038575
[15:03:25.268] iteration 17321: loss: 0.032459, loss_s1: 0.021329, loss_fp: 0.001734, loss_freq: 0.008390
[15:03:25.900] iteration 17322: loss: 0.035541, loss_s1: 0.018195, loss_fp: 0.000375, loss_freq: 0.023238
[15:03:26.535] iteration 17323: loss: 0.068006, loss_s1: 0.036608, loss_fp: 0.004298, loss_freq: 0.030004
[15:03:27.178] iteration 17324: loss: 0.126496, loss_s1: 0.070949, loss_fp: 0.002641, loss_freq: 0.088154
[15:03:27.814] iteration 17325: loss: 0.055890, loss_s1: 0.024901, loss_fp: 0.002654, loss_freq: 0.028502
[15:03:28.448] iteration 17326: loss: 0.049033, loss_s1: 0.037646, loss_fp: 0.003664, loss_freq: 0.012478
[15:03:29.083] iteration 17327: loss: 0.041708, loss_s1: 0.036047, loss_fp: 0.000822, loss_freq: 0.003332
[15:03:29.706] iteration 17328: loss: 0.036634, loss_s1: 0.009920, loss_fp: 0.002957, loss_freq: 0.014656
[15:03:30.344] iteration 17329: loss: 0.072112, loss_s1: 0.078813, loss_fp: 0.003782, loss_freq: 0.022390
[15:03:31.023] iteration 17330: loss: 0.097761, loss_s1: 0.058049, loss_fp: 0.005582, loss_freq: 0.086088
[15:03:31.707] iteration 17331: loss: 0.033312, loss_s1: 0.008146, loss_fp: 0.001447, loss_freq: 0.010881
[15:03:32.360] iteration 17332: loss: 0.098608, loss_s1: 0.103425, loss_fp: 0.002889, loss_freq: 0.034575
[15:03:33.030] iteration 17333: loss: 0.073872, loss_s1: 0.071807, loss_fp: 0.001674, loss_freq: 0.010143
[15:03:33.691] iteration 17334: loss: 0.045367, loss_s1: 0.035546, loss_fp: 0.004883, loss_freq: 0.012206
[15:03:34.350] iteration 17335: loss: 0.054052, loss_s1: 0.040032, loss_fp: 0.003703, loss_freq: 0.016654
[15:03:34.994] iteration 17336: loss: 0.063503, loss_s1: 0.063924, loss_fp: 0.001426, loss_freq: 0.029273
[15:03:35.623] iteration 17337: loss: 0.076785, loss_s1: 0.076958, loss_fp: 0.001151, loss_freq: 0.034918
[15:03:36.251] iteration 17338: loss: 0.057204, loss_s1: 0.028738, loss_fp: 0.002940, loss_freq: 0.036583
[15:03:36.893] iteration 17339: loss: 0.100370, loss_s1: 0.105341, loss_fp: 0.006201, loss_freq: 0.036491
[15:03:37.533] iteration 17340: loss: 0.072124, loss_s1: 0.041903, loss_fp: 0.005411, loss_freq: 0.027752
[15:03:38.189] iteration 17341: loss: 0.082032, loss_s1: 0.079269, loss_fp: 0.003683, loss_freq: 0.044187
[15:03:38.828] iteration 17342: loss: 0.077430, loss_s1: 0.061645, loss_fp: 0.002918, loss_freq: 0.041428
[15:03:39.506] iteration 17343: loss: 0.053397, loss_s1: 0.050354, loss_fp: 0.001749, loss_freq: 0.008617
[15:03:40.165] iteration 17344: loss: 0.064968, loss_s1: 0.016841, loss_fp: 0.001610, loss_freq: 0.017726
[15:03:40.824] iteration 17345: loss: 0.045277, loss_s1: 0.031221, loss_fp: 0.003824, loss_freq: 0.016223
[15:03:41.467] iteration 17346: loss: 0.056251, loss_s1: 0.034730, loss_fp: 0.004537, loss_freq: 0.009535
[15:03:42.092] iteration 17347: loss: 0.063397, loss_s1: 0.060820, loss_fp: 0.001222, loss_freq: 0.022731
[15:03:42.725] iteration 17348: loss: 0.070225, loss_s1: 0.062957, loss_fp: 0.001530, loss_freq: 0.006105
[15:03:43.360] iteration 17349: loss: 0.092193, loss_s1: 0.100354, loss_fp: 0.003657, loss_freq: 0.023437
[15:03:43.997] iteration 17350: loss: 0.053302, loss_s1: 0.011690, loss_fp: 0.001481, loss_freq: 0.044077
[15:03:44.632] iteration 17351: loss: 0.054570, loss_s1: 0.050914, loss_fp: 0.010139, loss_freq: 0.005966
[15:03:45.269] iteration 17352: loss: 0.065780, loss_s1: 0.036863, loss_fp: 0.002291, loss_freq: 0.055083
[15:03:45.902] iteration 17353: loss: 0.061873, loss_s1: 0.055978, loss_fp: 0.005900, loss_freq: 0.017896
[15:03:46.530] iteration 17354: loss: 0.042005, loss_s1: 0.021832, loss_fp: 0.000909, loss_freq: 0.012553
[15:03:47.158] iteration 17355: loss: 0.081291, loss_s1: 0.066526, loss_fp: 0.003308, loss_freq: 0.033753
[15:03:47.789] iteration 17356: loss: 0.046073, loss_s1: 0.036006, loss_fp: 0.002814, loss_freq: 0.017868
[15:03:48.418] iteration 17357: loss: 0.036043, loss_s1: 0.023178, loss_fp: 0.004042, loss_freq: 0.017230
[15:03:49.090] iteration 17358: loss: 0.042077, loss_s1: 0.038308, loss_fp: 0.001078, loss_freq: 0.012879
[15:03:49.726] iteration 17359: loss: 0.044026, loss_s1: 0.020982, loss_fp: 0.000809, loss_freq: 0.010184
[15:03:50.364] iteration 17360: loss: 0.061232, loss_s1: 0.024796, loss_fp: 0.004777, loss_freq: 0.022438
[15:03:51.003] iteration 17361: loss: 0.061828, loss_s1: 0.061782, loss_fp: 0.001361, loss_freq: 0.015210
[15:03:51.634] iteration 17362: loss: 0.059423, loss_s1: 0.055565, loss_fp: 0.002161, loss_freq: 0.024144
[15:03:52.272] iteration 17363: loss: 0.061261, loss_s1: 0.025370, loss_fp: 0.002646, loss_freq: 0.029805
[15:03:52.909] iteration 17364: loss: 0.052757, loss_s1: 0.024657, loss_fp: 0.004249, loss_freq: 0.015381
[15:03:53.543] iteration 17365: loss: 0.047606, loss_s1: 0.014560, loss_fp: 0.017272, loss_freq: 0.019146
[15:03:54.189] iteration 17366: loss: 0.042284, loss_s1: 0.030866, loss_fp: 0.001622, loss_freq: 0.014290
[15:03:54.878] iteration 17367: loss: 0.067262, loss_s1: 0.041759, loss_fp: 0.002941, loss_freq: 0.022208
[15:03:55.517] iteration 17368: loss: 0.119801, loss_s1: 0.038770, loss_fp: 0.002168, loss_freq: 0.071305
[15:03:56.159] iteration 17369: loss: 0.060004, loss_s1: 0.040826, loss_fp: 0.006640, loss_freq: 0.013228
[15:03:56.798] iteration 17370: loss: 0.076583, loss_s1: 0.033501, loss_fp: 0.004552, loss_freq: 0.054271
[15:03:57.430] iteration 17371: loss: 0.050070, loss_s1: 0.021126, loss_fp: 0.003343, loss_freq: 0.015208
[15:03:58.065] iteration 17372: loss: 0.058442, loss_s1: 0.050589, loss_fp: 0.002003, loss_freq: 0.014376
[15:03:58.697] iteration 17373: loss: 0.086038, loss_s1: 0.055131, loss_fp: 0.002408, loss_freq: 0.006599
[15:03:59.334] iteration 17374: loss: 0.057336, loss_s1: 0.036129, loss_fp: 0.003141, loss_freq: 0.036934
[15:03:59.957] iteration 17375: loss: 0.081346, loss_s1: 0.065398, loss_fp: 0.002311, loss_freq: 0.040187
[15:04:00.593] iteration 17376: loss: 0.110478, loss_s1: 0.116505, loss_fp: 0.001880, loss_freq: 0.065962
[15:04:01.235] iteration 17377: loss: 0.062349, loss_s1: 0.053914, loss_fp: 0.001664, loss_freq: 0.015361
[15:04:01.875] iteration 17378: loss: 0.093543, loss_s1: 0.064703, loss_fp: 0.001790, loss_freq: 0.074767
[15:04:02.500] iteration 17379: loss: 0.071024, loss_s1: 0.033527, loss_fp: 0.002896, loss_freq: 0.021829
[15:04:03.143] iteration 17380: loss: 0.039523, loss_s1: 0.012725, loss_fp: 0.005238, loss_freq: 0.026566
[15:04:03.778] iteration 17381: loss: 0.048397, loss_s1: 0.022659, loss_fp: 0.000986, loss_freq: 0.021748
[15:04:04.411] iteration 17382: loss: 0.070851, loss_s1: 0.043735, loss_fp: 0.003321, loss_freq: 0.041746
[15:04:05.049] iteration 17383: loss: 0.092845, loss_s1: 0.084630, loss_fp: 0.007439, loss_freq: 0.028621
[15:04:05.685] iteration 17384: loss: 0.054462, loss_s1: 0.033827, loss_fp: 0.000811, loss_freq: 0.017034
[15:04:06.314] iteration 17385: loss: 0.048129, loss_s1: 0.033481, loss_fp: 0.002000, loss_freq: 0.018136
[15:04:06.953] iteration 17386: loss: 0.045487, loss_s1: 0.007768, loss_fp: 0.008447, loss_freq: 0.028670
[15:04:07.595] iteration 17387: loss: 0.063337, loss_s1: 0.040479, loss_fp: 0.002301, loss_freq: 0.020810
[15:04:08.218] iteration 17388: loss: 0.076547, loss_s1: 0.066567, loss_fp: 0.008509, loss_freq: 0.034636
[15:04:08.845] iteration 17389: loss: 0.073272, loss_s1: 0.023641, loss_fp: 0.003056, loss_freq: 0.046493
[15:04:09.474] iteration 17390: loss: 0.068795, loss_s1: 0.046226, loss_fp: 0.001238, loss_freq: 0.039802
[15:04:10.106] iteration 17391: loss: 0.043113, loss_s1: 0.014799, loss_fp: 0.001117, loss_freq: 0.024985
[15:04:10.735] iteration 17392: loss: 0.033671, loss_s1: 0.014817, loss_fp: 0.002541, loss_freq: 0.013613
[15:04:11.361] iteration 17393: loss: 0.045958, loss_s1: 0.034579, loss_fp: 0.002464, loss_freq: 0.023729
[15:04:11.997] iteration 17394: loss: 0.066728, loss_s1: 0.041423, loss_fp: 0.003052, loss_freq: 0.028539
[15:04:12.654] iteration 17395: loss: 0.049930, loss_s1: 0.040196, loss_fp: 0.005569, loss_freq: 0.014988
[15:04:13.317] iteration 17396: loss: 0.047485, loss_s1: 0.028088, loss_fp: 0.001479, loss_freq: 0.016690
[15:04:13.985] iteration 17397: loss: 0.055230, loss_s1: 0.030104, loss_fp: 0.004741, loss_freq: 0.016515
[15:04:14.640] iteration 17398: loss: 0.045721, loss_s1: 0.018675, loss_fp: 0.001252, loss_freq: 0.031595
[15:04:15.308] iteration 17399: loss: 0.067199, loss_s1: 0.038273, loss_fp: 0.000719, loss_freq: 0.015455
[15:04:15.962] iteration 17400: loss: 0.123330, loss_s1: 0.113391, loss_fp: 0.001801, loss_freq: 0.065726
[15:04:19.564] iteration 17400 : mean_dice : 0.786990
[15:04:20.247] iteration 17401: loss: 0.055576, loss_s1: 0.038140, loss_fp: 0.001334, loss_freq: 0.032404
[15:04:20.872] iteration 17402: loss: 0.085581, loss_s1: 0.029172, loss_fp: 0.006598, loss_freq: 0.039427
[15:04:21.499] iteration 17403: loss: 0.048485, loss_s1: 0.009761, loss_fp: 0.004977, loss_freq: 0.034671
[15:04:22.123] iteration 17404: loss: 0.075796, loss_s1: 0.072814, loss_fp: 0.002276, loss_freq: 0.039067
[15:04:22.744] iteration 17405: loss: 0.062089, loss_s1: 0.023268, loss_fp: 0.007882, loss_freq: 0.045610
[15:04:23.373] iteration 17406: loss: 0.067462, loss_s1: 0.043185, loss_fp: 0.009565, loss_freq: 0.024916
[15:04:24.048] iteration 17407: loss: 0.060576, loss_s1: 0.029474, loss_fp: 0.001056, loss_freq: 0.004182
[15:04:24.668] iteration 17408: loss: 0.044085, loss_s1: 0.024152, loss_fp: 0.001120, loss_freq: 0.015970
[15:04:25.292] iteration 17409: loss: 0.055126, loss_s1: 0.030750, loss_fp: 0.002676, loss_freq: 0.035806
[15:04:25.912] iteration 17410: loss: 0.075900, loss_s1: 0.058220, loss_fp: 0.002760, loss_freq: 0.048331
[15:04:26.537] iteration 17411: loss: 0.060592, loss_s1: 0.024166, loss_fp: 0.007704, loss_freq: 0.046866
[15:04:27.163] iteration 17412: loss: 0.063111, loss_s1: 0.051323, loss_fp: 0.001968, loss_freq: 0.023313
[15:04:27.799] iteration 17413: loss: 0.082190, loss_s1: 0.057995, loss_fp: 0.006355, loss_freq: 0.059299
[15:04:28.424] iteration 17414: loss: 0.060204, loss_s1: 0.043248, loss_fp: 0.003135, loss_freq: 0.014944
[15:04:29.044] iteration 17415: loss: 0.050714, loss_s1: 0.050528, loss_fp: 0.002375, loss_freq: 0.019596
[15:04:29.669] iteration 17416: loss: 0.077073, loss_s1: 0.057344, loss_fp: 0.004815, loss_freq: 0.023343
[15:04:30.303] iteration 17417: loss: 0.078526, loss_s1: 0.062904, loss_fp: 0.003421, loss_freq: 0.039417
[15:04:30.930] iteration 17418: loss: 0.072052, loss_s1: 0.058535, loss_fp: 0.004596, loss_freq: 0.027324
[15:04:31.562] iteration 17419: loss: 0.079250, loss_s1: 0.049898, loss_fp: 0.003950, loss_freq: 0.025100
[15:04:32.191] iteration 17420: loss: 0.051798, loss_s1: 0.027210, loss_fp: 0.002114, loss_freq: 0.029660
[15:04:32.813] iteration 17421: loss: 0.056519, loss_s1: 0.030439, loss_fp: 0.004712, loss_freq: 0.031332
[15:04:33.436] iteration 17422: loss: 0.061163, loss_s1: 0.052862, loss_fp: 0.009869, loss_freq: 0.028588
[15:04:34.055] iteration 17423: loss: 0.053979, loss_s1: 0.025774, loss_fp: 0.007496, loss_freq: 0.031494
[15:04:34.688] iteration 17424: loss: 0.090801, loss_s1: 0.065585, loss_fp: 0.004198, loss_freq: 0.067441
[15:04:35.334] iteration 17425: loss: 0.111620, loss_s1: 0.025488, loss_fp: 0.003385, loss_freq: 0.027707
[15:04:35.982] iteration 17426: loss: 0.035219, loss_s1: 0.027561, loss_fp: 0.000212, loss_freq: 0.006446
[15:04:36.657] iteration 17427: loss: 0.077686, loss_s1: 0.053224, loss_fp: 0.004245, loss_freq: 0.063269
[15:04:37.282] iteration 17428: loss: 0.061376, loss_s1: 0.042843, loss_fp: 0.004724, loss_freq: 0.028737
[15:04:37.910] iteration 17429: loss: 0.063960, loss_s1: 0.033562, loss_fp: 0.008500, loss_freq: 0.012296
[15:04:38.533] iteration 17430: loss: 0.066473, loss_s1: 0.062924, loss_fp: 0.004655, loss_freq: 0.014530
[15:04:39.162] iteration 17431: loss: 0.050301, loss_s1: 0.032834, loss_fp: 0.002902, loss_freq: 0.017248
[15:04:39.789] iteration 17432: loss: 0.053856, loss_s1: 0.029478, loss_fp: 0.003876, loss_freq: 0.005085
[15:04:40.446] iteration 17433: loss: 0.040721, loss_s1: 0.024273, loss_fp: 0.002117, loss_freq: 0.014432
[15:04:41.107] iteration 17434: loss: 0.057110, loss_s1: 0.027402, loss_fp: 0.002352, loss_freq: 0.030701
[15:04:41.770] iteration 17435: loss: 0.068487, loss_s1: 0.054517, loss_fp: 0.002180, loss_freq: 0.033289
[15:04:42.440] iteration 17436: loss: 0.042860, loss_s1: 0.032855, loss_fp: 0.003014, loss_freq: 0.010372
[15:04:43.145] iteration 17437: loss: 0.100954, loss_s1: 0.081016, loss_fp: 0.002255, loss_freq: 0.049981
[15:04:43.801] iteration 17438: loss: 0.066883, loss_s1: 0.040561, loss_fp: 0.001792, loss_freq: 0.032477
[15:04:44.460] iteration 17439: loss: 0.072670, loss_s1: 0.057924, loss_fp: 0.010081, loss_freq: 0.038763
[15:04:45.118] iteration 17440: loss: 0.069049, loss_s1: 0.069396, loss_fp: 0.005381, loss_freq: 0.017957
[15:04:45.759] iteration 17441: loss: 0.035351, loss_s1: 0.018306, loss_fp: 0.000884, loss_freq: 0.009235
[15:04:46.394] iteration 17442: loss: 0.043268, loss_s1: 0.014921, loss_fp: 0.002983, loss_freq: 0.023391
[15:04:47.025] iteration 17443: loss: 0.049813, loss_s1: 0.028777, loss_fp: 0.008174, loss_freq: 0.017979
[15:04:47.659] iteration 17444: loss: 0.071601, loss_s1: 0.057809, loss_fp: 0.006740, loss_freq: 0.036817
[15:04:48.289] iteration 17445: loss: 0.142003, loss_s1: 0.152916, loss_fp: 0.020200, loss_freq: 0.067050
[15:04:48.916] iteration 17446: loss: 0.045467, loss_s1: 0.025841, loss_fp: 0.001215, loss_freq: 0.029424
[15:04:49.849] iteration 17447: loss: 0.064430, loss_s1: 0.039540, loss_fp: 0.001020, loss_freq: 0.020523
[15:04:50.500] iteration 17448: loss: 0.065505, loss_s1: 0.059006, loss_fp: 0.004881, loss_freq: 0.010182
[15:04:51.135] iteration 17449: loss: 0.058010, loss_s1: 0.036861, loss_fp: 0.000393, loss_freq: 0.037951
[15:04:51.765] iteration 17450: loss: 0.071150, loss_s1: 0.024075, loss_fp: 0.003839, loss_freq: 0.043998
[15:04:52.403] iteration 17451: loss: 0.053350, loss_s1: 0.036395, loss_fp: 0.000767, loss_freq: 0.021328
[15:04:53.032] iteration 17452: loss: 0.068516, loss_s1: 0.019149, loss_fp: 0.002008, loss_freq: 0.005674
[15:04:53.668] iteration 17453: loss: 0.027663, loss_s1: 0.015793, loss_fp: 0.002785, loss_freq: 0.006541
[15:04:54.295] iteration 17454: loss: 0.073818, loss_s1: 0.036110, loss_fp: 0.013244, loss_freq: 0.027671
[15:04:54.922] iteration 17455: loss: 0.058514, loss_s1: 0.031107, loss_fp: 0.003290, loss_freq: 0.044846
[15:04:55.561] iteration 17456: loss: 0.039538, loss_s1: 0.004487, loss_fp: 0.005316, loss_freq: 0.005259
[15:04:56.185] iteration 17457: loss: 0.048710, loss_s1: 0.010642, loss_fp: 0.006334, loss_freq: 0.039743
[15:04:56.807] iteration 17458: loss: 0.054059, loss_s1: 0.023473, loss_fp: 0.002934, loss_freq: 0.027115
[15:04:57.440] iteration 17459: loss: 0.071681, loss_s1: 0.065634, loss_fp: 0.001965, loss_freq: 0.013801
[15:04:58.129] iteration 17460: loss: 0.047799, loss_s1: 0.038953, loss_fp: 0.001007, loss_freq: 0.018284
[15:04:58.794] iteration 17461: loss: 0.046967, loss_s1: 0.034783, loss_fp: 0.001762, loss_freq: 0.012548
[15:04:59.423] iteration 17462: loss: 0.060388, loss_s1: 0.062509, loss_fp: 0.001607, loss_freq: 0.008405
[15:05:00.065] iteration 17463: loss: 0.055168, loss_s1: 0.010849, loss_fp: 0.000892, loss_freq: 0.018383
[15:05:00.742] iteration 17464: loss: 0.044258, loss_s1: 0.036074, loss_fp: 0.003421, loss_freq: 0.005812
[15:05:01.430] iteration 17465: loss: 0.035562, loss_s1: 0.021826, loss_fp: 0.000853, loss_freq: 0.017593
[15:05:02.112] iteration 17466: loss: 0.032678, loss_s1: 0.013243, loss_fp: 0.002579, loss_freq: 0.012772
[15:05:02.762] iteration 17467: loss: 0.110103, loss_s1: 0.022231, loss_fp: 0.002029, loss_freq: 0.077222
[15:05:03.392] iteration 17468: loss: 0.045359, loss_s1: 0.030647, loss_fp: 0.002149, loss_freq: 0.022175
[15:05:04.025] iteration 17469: loss: 0.067004, loss_s1: 0.028022, loss_fp: 0.001671, loss_freq: 0.061057
[15:05:04.659] iteration 17470: loss: 0.052897, loss_s1: 0.037986, loss_fp: 0.002121, loss_freq: 0.016616
[15:05:05.287] iteration 17471: loss: 0.060105, loss_s1: 0.051125, loss_fp: 0.003217, loss_freq: 0.025273
[15:05:05.926] iteration 17472: loss: 0.102700, loss_s1: 0.077179, loss_fp: 0.002361, loss_freq: 0.056338
[15:05:06.558] iteration 17473: loss: 0.081594, loss_s1: 0.056521, loss_fp: 0.001256, loss_freq: 0.054642
[15:05:07.191] iteration 17474: loss: 0.056639, loss_s1: 0.053212, loss_fp: 0.001522, loss_freq: 0.009810
[15:05:07.825] iteration 17475: loss: 0.061433, loss_s1: 0.023685, loss_fp: 0.002281, loss_freq: 0.051494
[15:05:08.453] iteration 17476: loss: 0.113110, loss_s1: 0.014949, loss_fp: 0.004088, loss_freq: 0.006384
[15:05:09.081] iteration 17477: loss: 0.042647, loss_s1: 0.023109, loss_fp: 0.000478, loss_freq: 0.013448
[15:05:09.757] iteration 17478: loss: 0.083072, loss_s1: 0.077347, loss_fp: 0.003559, loss_freq: 0.034478
[15:05:10.431] iteration 17479: loss: 0.124766, loss_s1: 0.110618, loss_fp: 0.035665, loss_freq: 0.070901
[15:05:11.099] iteration 17480: loss: 0.092827, loss_s1: 0.081319, loss_fp: 0.013254, loss_freq: 0.053016
[15:05:11.759] iteration 17481: loss: 0.069651, loss_s1: 0.031062, loss_fp: 0.009942, loss_freq: 0.021875
[15:05:12.419] iteration 17482: loss: 0.098605, loss_s1: 0.095624, loss_fp: 0.002557, loss_freq: 0.052051
[15:05:13.078] iteration 17483: loss: 0.057380, loss_s1: 0.019081, loss_fp: 0.003017, loss_freq: 0.024032
[15:05:13.741] iteration 17484: loss: 0.082988, loss_s1: 0.058809, loss_fp: 0.002824, loss_freq: 0.064617
[15:05:14.404] iteration 17485: loss: 0.109138, loss_s1: 0.052049, loss_fp: 0.006651, loss_freq: 0.064573
[15:05:15.033] iteration 17486: loss: 0.060859, loss_s1: 0.035027, loss_fp: 0.007552, loss_freq: 0.021886
[15:05:15.656] iteration 17487: loss: 0.085827, loss_s1: 0.044252, loss_fp: 0.009613, loss_freq: 0.021979
[15:05:16.286] iteration 17488: loss: 0.038302, loss_s1: 0.021065, loss_fp: 0.000966, loss_freq: 0.018822
[15:05:16.919] iteration 17489: loss: 0.077949, loss_s1: 0.033540, loss_fp: 0.002854, loss_freq: 0.044012
[15:05:17.617] iteration 17490: loss: 0.074643, loss_s1: 0.052721, loss_fp: 0.012005, loss_freq: 0.024483
[15:05:18.296] iteration 17491: loss: 0.071737, loss_s1: 0.030369, loss_fp: 0.001596, loss_freq: 0.014777
[15:05:18.971] iteration 17492: loss: 0.077577, loss_s1: 0.063276, loss_fp: 0.007139, loss_freq: 0.024502
[15:05:19.597] iteration 17493: loss: 0.063951, loss_s1: 0.038071, loss_fp: 0.005075, loss_freq: 0.036908
[15:05:20.250] iteration 17494: loss: 0.050719, loss_s1: 0.046685, loss_fp: 0.000982, loss_freq: 0.009286
[15:05:20.887] iteration 17495: loss: 0.049646, loss_s1: 0.027956, loss_fp: 0.005035, loss_freq: 0.026473
[15:05:21.527] iteration 17496: loss: 0.071290, loss_s1: 0.048574, loss_fp: 0.000595, loss_freq: 0.044707
[15:05:22.164] iteration 17497: loss: 0.049779, loss_s1: 0.018764, loss_fp: 0.002076, loss_freq: 0.011789
[15:05:22.837] iteration 17498: loss: 0.161519, loss_s1: 0.023062, loss_fp: 0.003565, loss_freq: 0.029206
[15:05:23.506] iteration 17499: loss: 0.042033, loss_s1: 0.013910, loss_fp: 0.001495, loss_freq: 0.017233
[15:05:24.141] iteration 17500: loss: 0.040066, loss_s1: 0.019522, loss_fp: 0.003791, loss_freq: 0.020513
[15:05:24.772] iteration 17501: loss: 0.038132, loss_s1: 0.019899, loss_fp: 0.006017, loss_freq: 0.016123
[15:05:25.404] iteration 17502: loss: 0.082779, loss_s1: 0.040312, loss_fp: 0.001084, loss_freq: 0.011391
[15:05:26.034] iteration 17503: loss: 0.067257, loss_s1: 0.049247, loss_fp: 0.000923, loss_freq: 0.018362
[15:05:26.672] iteration 17504: loss: 0.046900, loss_s1: 0.039020, loss_fp: 0.000708, loss_freq: 0.007466
[15:05:27.308] iteration 17505: loss: 0.090587, loss_s1: 0.038967, loss_fp: 0.001113, loss_freq: 0.077087
[15:05:27.940] iteration 17506: loss: 0.069107, loss_s1: 0.050308, loss_fp: 0.001671, loss_freq: 0.041228
[15:05:28.569] iteration 17507: loss: 0.054578, loss_s1: 0.032286, loss_fp: 0.001424, loss_freq: 0.016078
[15:05:29.202] iteration 17508: loss: 0.078608, loss_s1: 0.087827, loss_fp: 0.002511, loss_freq: 0.015884
[15:05:29.844] iteration 17509: loss: 0.053646, loss_s1: 0.029621, loss_fp: 0.000746, loss_freq: 0.033360
[15:05:30.473] iteration 17510: loss: 0.045005, loss_s1: 0.014745, loss_fp: 0.002331, loss_freq: 0.021525
[15:05:31.104] iteration 17511: loss: 0.064057, loss_s1: 0.052648, loss_fp: 0.003224, loss_freq: 0.017634
[15:05:31.736] iteration 17512: loss: 0.104899, loss_s1: 0.071630, loss_fp: 0.001576, loss_freq: 0.078857
[15:05:32.388] iteration 17513: loss: 0.080956, loss_s1: 0.042633, loss_fp: 0.024080, loss_freq: 0.021829
[15:05:33.023] iteration 17514: loss: 0.057779, loss_s1: 0.042364, loss_fp: 0.001690, loss_freq: 0.025716
[15:05:33.658] iteration 17515: loss: 0.063143, loss_s1: 0.068426, loss_fp: 0.002561, loss_freq: 0.012204
[15:05:34.287] iteration 17516: loss: 0.055951, loss_s1: 0.034028, loss_fp: 0.003567, loss_freq: 0.005717
[15:05:34.933] iteration 17517: loss: 0.051479, loss_s1: 0.020171, loss_fp: 0.000555, loss_freq: 0.027154
[15:05:35.592] iteration 17518: loss: 0.067469, loss_s1: 0.020152, loss_fp: 0.002800, loss_freq: 0.034338
[15:05:36.288] iteration 17519: loss: 0.039674, loss_s1: 0.025139, loss_fp: 0.005621, loss_freq: 0.017804
[15:05:36.955] iteration 17520: loss: 0.081372, loss_s1: 0.072712, loss_fp: 0.005491, loss_freq: 0.037291
[15:05:37.618] iteration 17521: loss: 0.099563, loss_s1: 0.049489, loss_fp: 0.003285, loss_freq: 0.111828
[15:05:38.281] iteration 17522: loss: 0.078045, loss_s1: 0.031989, loss_fp: 0.002712, loss_freq: 0.019335
[15:05:38.947] iteration 17523: loss: 0.060226, loss_s1: 0.034087, loss_fp: 0.003350, loss_freq: 0.048742
[15:05:39.576] iteration 17524: loss: 0.044051, loss_s1: 0.023104, loss_fp: 0.001129, loss_freq: 0.021914
[15:05:40.227] iteration 17525: loss: 0.083854, loss_s1: 0.084391, loss_fp: 0.004906, loss_freq: 0.021387
[15:05:40.858] iteration 17526: loss: 0.068947, loss_s1: 0.024733, loss_fp: 0.007837, loss_freq: 0.025156
[15:05:41.485] iteration 17527: loss: 0.094395, loss_s1: 0.058144, loss_fp: 0.002318, loss_freq: 0.039419
[15:05:42.151] iteration 17528: loss: 0.059017, loss_s1: 0.036844, loss_fp: 0.005714, loss_freq: 0.025513
[15:05:42.823] iteration 17529: loss: 0.040900, loss_s1: 0.026362, loss_fp: 0.001404, loss_freq: 0.009710
[15:05:43.488] iteration 17530: loss: 0.055378, loss_s1: 0.047281, loss_fp: 0.003713, loss_freq: 0.023374
[15:05:44.148] iteration 17531: loss: 0.082319, loss_s1: 0.058596, loss_fp: 0.003719, loss_freq: 0.055668
[15:05:44.804] iteration 17532: loss: 0.057606, loss_s1: 0.032593, loss_fp: 0.001382, loss_freq: 0.036359
[15:05:45.461] iteration 17533: loss: 0.080780, loss_s1: 0.025414, loss_fp: 0.000740, loss_freq: 0.026754
[15:05:46.135] iteration 17534: loss: 0.049308, loss_s1: 0.021427, loss_fp: 0.001047, loss_freq: 0.035603
[15:05:46.794] iteration 17535: loss: 0.066872, loss_s1: 0.057014, loss_fp: 0.003326, loss_freq: 0.013351
[15:05:47.443] iteration 17536: loss: 0.060477, loss_s1: 0.055567, loss_fp: 0.016717, loss_freq: 0.010021
[15:05:48.092] iteration 17537: loss: 0.057649, loss_s1: 0.022035, loss_fp: 0.008720, loss_freq: 0.031138
[15:05:48.751] iteration 17538: loss: 0.049618, loss_s1: 0.033513, loss_fp: 0.002719, loss_freq: 0.030614
[15:05:49.413] iteration 17539: loss: 0.049190, loss_s1: 0.036178, loss_fp: 0.004046, loss_freq: 0.016849
[15:05:50.067] iteration 17540: loss: 0.055518, loss_s1: 0.046082, loss_fp: 0.002242, loss_freq: 0.006819
[15:05:50.732] iteration 17541: loss: 0.050488, loss_s1: 0.021551, loss_fp: 0.002383, loss_freq: 0.035011
[15:05:51.396] iteration 17542: loss: 0.050403, loss_s1: 0.040589, loss_fp: 0.002419, loss_freq: 0.005403
[15:05:52.042] iteration 17543: loss: 0.068288, loss_s1: 0.025596, loss_fp: 0.006239, loss_freq: 0.056692
[15:05:52.676] iteration 17544: loss: 0.068101, loss_s1: 0.044987, loss_fp: 0.014031, loss_freq: 0.028327
[15:05:53.310] iteration 17545: loss: 0.061552, loss_s1: 0.017179, loss_fp: 0.003964, loss_freq: 0.019658
[15:05:53.962] iteration 17546: loss: 0.076709, loss_s1: 0.044431, loss_fp: 0.002432, loss_freq: 0.047325
[15:05:54.594] iteration 17547: loss: 0.052806, loss_s1: 0.040030, loss_fp: 0.000963, loss_freq: 0.026097
[15:05:55.219] iteration 17548: loss: 0.082711, loss_s1: 0.078491, loss_fp: 0.001620, loss_freq: 0.034655
[15:05:55.844] iteration 17549: loss: 0.068491, loss_s1: 0.057604, loss_fp: 0.005771, loss_freq: 0.037131
[15:05:56.470] iteration 17550: loss: 0.053316, loss_s1: 0.026728, loss_fp: 0.006233, loss_freq: 0.026020
[15:05:57.097] iteration 17551: loss: 0.060316, loss_s1: 0.038975, loss_fp: 0.002057, loss_freq: 0.007619
[15:05:57.728] iteration 17552: loss: 0.060205, loss_s1: 0.009559, loss_fp: 0.001753, loss_freq: 0.053388
[15:05:58.356] iteration 17553: loss: 0.055004, loss_s1: 0.028213, loss_fp: 0.004046, loss_freq: 0.032433
[15:05:58.978] iteration 17554: loss: 0.081805, loss_s1: 0.056658, loss_fp: 0.006481, loss_freq: 0.050819
[15:05:59.603] iteration 17555: loss: 0.072825, loss_s1: 0.050845, loss_fp: 0.001772, loss_freq: 0.031718
[15:06:00.228] iteration 17556: loss: 0.106129, loss_s1: 0.069611, loss_fp: 0.007028, loss_freq: 0.103752
[15:06:00.857] iteration 17557: loss: 0.041936, loss_s1: 0.019534, loss_fp: 0.002061, loss_freq: 0.017031
[15:06:01.478] iteration 17558: loss: 0.070272, loss_s1: 0.064871, loss_fp: 0.002702, loss_freq: 0.043907
[15:06:02.101] iteration 17559: loss: 0.053896, loss_s1: 0.029864, loss_fp: 0.001219, loss_freq: 0.015006
[15:06:02.718] iteration 17560: loss: 0.064935, loss_s1: 0.041560, loss_fp: 0.007974, loss_freq: 0.030276
[15:06:03.345] iteration 17561: loss: 0.056712, loss_s1: 0.039237, loss_fp: 0.002180, loss_freq: 0.012727
[15:06:03.967] iteration 17562: loss: 0.045525, loss_s1: 0.047489, loss_fp: 0.001040, loss_freq: 0.006408
[15:06:04.591] iteration 17563: loss: 0.093079, loss_s1: 0.060209, loss_fp: 0.004878, loss_freq: 0.051128
[15:06:05.209] iteration 17564: loss: 0.068534, loss_s1: 0.072217, loss_fp: 0.000995, loss_freq: 0.020342
[15:06:05.833] iteration 17565: loss: 0.048889, loss_s1: 0.038263, loss_fp: 0.003367, loss_freq: 0.014250
[15:06:06.454] iteration 17566: loss: 0.072832, loss_s1: 0.062802, loss_fp: 0.000800, loss_freq: 0.033605
[15:06:07.079] iteration 17567: loss: 0.079495, loss_s1: 0.053737, loss_fp: 0.002356, loss_freq: 0.057865
[15:06:07.708] iteration 17568: loss: 0.064216, loss_s1: 0.053858, loss_fp: 0.003735, loss_freq: 0.021779
[15:06:08.327] iteration 17569: loss: 0.032439, loss_s1: 0.021437, loss_fp: 0.002183, loss_freq: 0.005288
[15:06:08.967] iteration 17570: loss: 0.040554, loss_s1: 0.033477, loss_fp: 0.001139, loss_freq: 0.013410
[15:06:09.602] iteration 17571: loss: 0.048489, loss_s1: 0.022128, loss_fp: 0.001748, loss_freq: 0.017427
[15:06:10.222] iteration 17572: loss: 0.053484, loss_s1: 0.013281, loss_fp: 0.001405, loss_freq: 0.013044
[15:06:10.888] iteration 17573: loss: 0.071682, loss_s1: 0.045034, loss_fp: 0.006402, loss_freq: 0.050242
[15:06:11.517] iteration 17574: loss: 0.044557, loss_s1: 0.014838, loss_fp: 0.002144, loss_freq: 0.019673
[15:06:12.150] iteration 17575: loss: 0.061945, loss_s1: 0.054278, loss_fp: 0.001211, loss_freq: 0.012935
[15:06:12.776] iteration 17576: loss: 0.071171, loss_s1: 0.085324, loss_fp: 0.004922, loss_freq: 0.011191
[15:06:13.404] iteration 17577: loss: 0.051559, loss_s1: 0.023127, loss_fp: 0.001387, loss_freq: 0.019064
[15:06:14.037] iteration 17578: loss: 0.054426, loss_s1: 0.037319, loss_fp: 0.006092, loss_freq: 0.015089
[15:06:14.670] iteration 17579: loss: 0.052492, loss_s1: 0.039016, loss_fp: 0.001786, loss_freq: 0.012436
[15:06:15.299] iteration 17580: loss: 0.078371, loss_s1: 0.034637, loss_fp: 0.002692, loss_freq: 0.058065
[15:06:15.930] iteration 17581: loss: 0.067278, loss_s1: 0.041560, loss_fp: 0.006223, loss_freq: 0.033386
[15:06:16.568] iteration 17582: loss: 0.071513, loss_s1: 0.052812, loss_fp: 0.009548, loss_freq: 0.039317
[15:06:17.198] iteration 17583: loss: 0.094943, loss_s1: 0.065017, loss_fp: 0.004633, loss_freq: 0.028214
[15:06:17.826] iteration 17584: loss: 0.046116, loss_s1: 0.035264, loss_fp: 0.000529, loss_freq: 0.011558
[15:06:18.452] iteration 17585: loss: 0.075986, loss_s1: 0.057797, loss_fp: 0.002327, loss_freq: 0.037511
[15:06:19.085] iteration 17586: loss: 0.063633, loss_s1: 0.029967, loss_fp: 0.005469, loss_freq: 0.012353
[15:06:19.716] iteration 17587: loss: 0.067572, loss_s1: 0.043921, loss_fp: 0.003408, loss_freq: 0.047433
[15:06:20.341] iteration 17588: loss: 0.119066, loss_s1: 0.112489, loss_fp: 0.016708, loss_freq: 0.054583
[15:06:20.957] iteration 17589: loss: 0.037376, loss_s1: 0.018221, loss_fp: 0.003173, loss_freq: 0.021439
[15:06:21.937] iteration 17590: loss: 0.051566, loss_s1: 0.015649, loss_fp: 0.001067, loss_freq: 0.008402
[15:06:22.564] iteration 17591: loss: 0.081511, loss_s1: 0.052256, loss_fp: 0.003039, loss_freq: 0.039388
[15:06:23.196] iteration 17592: loss: 0.053217, loss_s1: 0.043088, loss_fp: 0.001147, loss_freq: 0.013811
[15:06:23.827] iteration 17593: loss: 0.063327, loss_s1: 0.051734, loss_fp: 0.003041, loss_freq: 0.017044
[15:06:24.449] iteration 17594: loss: 0.085435, loss_s1: 0.069135, loss_fp: 0.003491, loss_freq: 0.034418
[15:06:25.076] iteration 17595: loss: 0.044567, loss_s1: 0.029708, loss_fp: 0.001879, loss_freq: 0.009978
[15:06:25.705] iteration 17596: loss: 0.032000, loss_s1: 0.018639, loss_fp: 0.004692, loss_freq: 0.012368
[15:06:26.333] iteration 17597: loss: 0.124647, loss_s1: 0.126321, loss_fp: 0.018186, loss_freq: 0.032510
[15:06:26.966] iteration 17598: loss: 0.081776, loss_s1: 0.076530, loss_fp: 0.003127, loss_freq: 0.040436
[15:06:27.600] iteration 17599: loss: 0.049761, loss_s1: 0.016945, loss_fp: 0.001406, loss_freq: 0.013144
[15:06:28.224] iteration 17600: loss: 0.074774, loss_s1: 0.059166, loss_fp: 0.003640, loss_freq: 0.045565
[15:06:31.898] iteration 17600 : mean_dice : 0.782995
[15:06:32.607] iteration 17601: loss: 0.046320, loss_s1: 0.023790, loss_fp: 0.006965, loss_freq: 0.009543
[15:06:33.288] iteration 17602: loss: 0.050297, loss_s1: 0.035112, loss_fp: 0.007138, loss_freq: 0.005430
[15:06:33.946] iteration 17603: loss: 0.045403, loss_s1: 0.026794, loss_fp: 0.003515, loss_freq: 0.024936
[15:06:34.602] iteration 17604: loss: 0.047910, loss_s1: 0.040527, loss_fp: 0.000843, loss_freq: 0.011600
[15:06:35.239] iteration 17605: loss: 0.040073, loss_s1: 0.019130, loss_fp: 0.004619, loss_freq: 0.015695
[15:06:35.873] iteration 17606: loss: 0.050862, loss_s1: 0.004584, loss_fp: 0.000969, loss_freq: 0.016086
[15:06:36.509] iteration 17607: loss: 0.083352, loss_s1: 0.072420, loss_fp: 0.002619, loss_freq: 0.017465
[15:06:37.141] iteration 17608: loss: 0.051945, loss_s1: 0.023839, loss_fp: 0.004209, loss_freq: 0.037897
[15:06:37.769] iteration 17609: loss: 0.036821, loss_s1: 0.023475, loss_fp: 0.001664, loss_freq: 0.013085
[15:06:38.402] iteration 17610: loss: 0.090911, loss_s1: 0.038848, loss_fp: 0.001545, loss_freq: 0.074755
[15:06:39.033] iteration 17611: loss: 0.047154, loss_s1: 0.024228, loss_fp: 0.001261, loss_freq: 0.020761
[15:06:39.668] iteration 17612: loss: 0.034642, loss_s1: 0.008324, loss_fp: 0.001285, loss_freq: 0.019581
[15:06:40.320] iteration 17613: loss: 0.053006, loss_s1: 0.011651, loss_fp: 0.002844, loss_freq: 0.010062
[15:06:40.980] iteration 17614: loss: 0.062969, loss_s1: 0.042518, loss_fp: 0.002150, loss_freq: 0.034541
[15:06:41.638] iteration 17615: loss: 0.059758, loss_s1: 0.028430, loss_fp: 0.004029, loss_freq: 0.039223
[15:06:42.297] iteration 17616: loss: 0.073811, loss_s1: 0.041088, loss_fp: 0.002728, loss_freq: 0.050433
[15:06:42.956] iteration 17617: loss: 0.050306, loss_s1: 0.040564, loss_fp: 0.002352, loss_freq: 0.006861
[15:06:43.607] iteration 17618: loss: 0.064577, loss_s1: 0.057186, loss_fp: 0.001078, loss_freq: 0.019588
[15:06:44.237] iteration 17619: loss: 0.051405, loss_s1: 0.025112, loss_fp: 0.000763, loss_freq: 0.021987
[15:06:44.861] iteration 17620: loss: 0.043974, loss_s1: 0.020685, loss_fp: 0.003536, loss_freq: 0.008797
[15:06:45.488] iteration 17621: loss: 0.067956, loss_s1: 0.030545, loss_fp: 0.005496, loss_freq: 0.014029
[15:06:46.116] iteration 17622: loss: 0.107240, loss_s1: 0.108079, loss_fp: 0.014792, loss_freq: 0.052745
[15:06:46.751] iteration 17623: loss: 0.090869, loss_s1: 0.088875, loss_fp: 0.003470, loss_freq: 0.053181
[15:06:47.379] iteration 17624: loss: 0.066057, loss_s1: 0.032953, loss_fp: 0.004209, loss_freq: 0.018333
[15:06:48.009] iteration 17625: loss: 0.055797, loss_s1: 0.053011, loss_fp: 0.002558, loss_freq: 0.013654
[15:06:48.644] iteration 17626: loss: 0.059706, loss_s1: 0.024092, loss_fp: 0.001859, loss_freq: 0.043134
[15:06:49.273] iteration 17627: loss: 0.044030, loss_s1: 0.037954, loss_fp: 0.002540, loss_freq: 0.011832
[15:06:49.913] iteration 17628: loss: 0.075679, loss_s1: 0.040543, loss_fp: 0.010097, loss_freq: 0.036927
[15:06:50.568] iteration 17629: loss: 0.035877, loss_s1: 0.029467, loss_fp: 0.005767, loss_freq: 0.005982
[15:06:51.195] iteration 17630: loss: 0.053050, loss_s1: 0.031747, loss_fp: 0.002939, loss_freq: 0.008912
[15:06:51.825] iteration 17631: loss: 0.033647, loss_s1: 0.010784, loss_fp: 0.003116, loss_freq: 0.023905
[15:06:52.454] iteration 17632: loss: 0.062501, loss_s1: 0.032909, loss_fp: 0.001547, loss_freq: 0.026729
[15:06:53.115] iteration 17633: loss: 0.065323, loss_s1: 0.042006, loss_fp: 0.018332, loss_freq: 0.021937
[15:06:53.754] iteration 17634: loss: 0.064977, loss_s1: 0.064269, loss_fp: 0.002121, loss_freq: 0.003243
[15:06:54.394] iteration 17635: loss: 0.128390, loss_s1: 0.129376, loss_fp: 0.004341, loss_freq: 0.077473
[15:06:55.027] iteration 17636: loss: 0.054593, loss_s1: 0.033496, loss_fp: 0.000893, loss_freq: 0.026071
[15:06:55.718] iteration 17637: loss: 0.070754, loss_s1: 0.056438, loss_fp: 0.010239, loss_freq: 0.023692
[15:06:56.373] iteration 17638: loss: 0.076766, loss_s1: 0.085744, loss_fp: 0.003159, loss_freq: 0.020335
[15:06:57.024] iteration 17639: loss: 0.041380, loss_s1: 0.024851, loss_fp: 0.000498, loss_freq: 0.012269
[15:06:57.669] iteration 17640: loss: 0.053439, loss_s1: 0.024981, loss_fp: 0.008004, loss_freq: 0.031707
[15:06:58.288] iteration 17641: loss: 0.044106, loss_s1: 0.028600, loss_fp: 0.001680, loss_freq: 0.019152
[15:06:58.943] iteration 17642: loss: 0.068421, loss_s1: 0.033786, loss_fp: 0.013399, loss_freq: 0.033967
[15:06:59.604] iteration 17643: loss: 0.030450, loss_s1: 0.012387, loss_fp: 0.005632, loss_freq: 0.008804
[15:07:00.264] iteration 17644: loss: 0.031288, loss_s1: 0.017569, loss_fp: 0.001699, loss_freq: 0.008336
[15:07:00.928] iteration 17645: loss: 0.054565, loss_s1: 0.027821, loss_fp: 0.000602, loss_freq: 0.015650
[15:07:01.583] iteration 17646: loss: 0.065926, loss_s1: 0.045039, loss_fp: 0.002751, loss_freq: 0.049898
[15:07:02.248] iteration 17647: loss: 0.051920, loss_s1: 0.044225, loss_fp: 0.002657, loss_freq: 0.015001
[15:07:02.920] iteration 17648: loss: 0.105351, loss_s1: 0.058253, loss_fp: 0.008229, loss_freq: 0.094740
[15:07:03.608] iteration 17649: loss: 0.054987, loss_s1: 0.029069, loss_fp: 0.001856, loss_freq: 0.024751
[15:07:04.364] iteration 17650: loss: 0.043471, loss_s1: 0.026514, loss_fp: 0.002937, loss_freq: 0.014861
[15:07:05.057] iteration 17651: loss: 0.043817, loss_s1: 0.033875, loss_fp: 0.004116, loss_freq: 0.009285
[15:07:05.768] iteration 17652: loss: 0.093895, loss_s1: 0.049603, loss_fp: 0.005843, loss_freq: 0.088334
[15:07:06.748] iteration 17653: loss: 0.059057, loss_s1: 0.024375, loss_fp: 0.000894, loss_freq: 0.020176
[15:07:07.424] iteration 17654: loss: 0.116128, loss_s1: 0.116172, loss_fp: 0.001801, loss_freq: 0.050622
[15:07:08.112] iteration 17655: loss: 0.050365, loss_s1: 0.036764, loss_fp: 0.001739, loss_freq: 0.016931
[15:07:08.771] iteration 17656: loss: 0.079495, loss_s1: 0.043408, loss_fp: 0.018310, loss_freq: 0.025366
[15:07:09.478] iteration 17657: loss: 0.057117, loss_s1: 0.026519, loss_fp: 0.002950, loss_freq: 0.011811
[15:07:10.145] iteration 17658: loss: 0.056726, loss_s1: 0.055182, loss_fp: 0.002947, loss_freq: 0.014883
[15:07:10.791] iteration 17659: loss: 0.049190, loss_s1: 0.025101, loss_fp: 0.004604, loss_freq: 0.007415
[15:07:11.422] iteration 17660: loss: 0.048841, loss_s1: 0.027384, loss_fp: 0.000664, loss_freq: 0.023777
[15:07:12.076] iteration 17661: loss: 0.060475, loss_s1: 0.033027, loss_fp: 0.004927, loss_freq: 0.033435
[15:07:12.734] iteration 17662: loss: 0.072781, loss_s1: 0.018316, loss_fp: 0.008789, loss_freq: 0.079281
[15:07:13.368] iteration 17663: loss: 0.085121, loss_s1: 0.089480, loss_fp: 0.004285, loss_freq: 0.018097
[15:07:13.995] iteration 17664: loss: 0.087113, loss_s1: 0.076142, loss_fp: 0.003173, loss_freq: 0.060119
[15:07:14.626] iteration 17665: loss: 0.063621, loss_s1: 0.023193, loss_fp: 0.001517, loss_freq: 0.008916
[15:07:15.258] iteration 17666: loss: 0.089165, loss_s1: 0.056816, loss_fp: 0.005299, loss_freq: 0.082095
[15:07:15.879] iteration 17667: loss: 0.065393, loss_s1: 0.029407, loss_fp: 0.005695, loss_freq: 0.009974
[15:07:16.512] iteration 17668: loss: 0.077646, loss_s1: 0.052395, loss_fp: 0.007259, loss_freq: 0.047898
[15:07:17.143] iteration 17669: loss: 0.140460, loss_s1: 0.090078, loss_fp: 0.005393, loss_freq: 0.037022
[15:07:17.768] iteration 17670: loss: 0.095592, loss_s1: 0.074284, loss_fp: 0.018046, loss_freq: 0.055109
[15:07:18.389] iteration 17671: loss: 0.056951, loss_s1: 0.038162, loss_fp: 0.000858, loss_freq: 0.026406
[15:07:19.026] iteration 17672: loss: 0.040857, loss_s1: 0.022294, loss_fp: 0.000793, loss_freq: 0.020419
[15:07:19.682] iteration 17673: loss: 0.052558, loss_s1: 0.045237, loss_fp: 0.004748, loss_freq: 0.024766
[15:07:20.321] iteration 17674: loss: 0.053620, loss_s1: 0.036043, loss_fp: 0.004004, loss_freq: 0.024182
[15:07:20.972] iteration 17675: loss: 0.070007, loss_s1: 0.049892, loss_fp: 0.005604, loss_freq: 0.044673
[15:07:21.620] iteration 17676: loss: 0.075085, loss_s1: 0.051263, loss_fp: 0.003935, loss_freq: 0.028877
[15:07:22.261] iteration 17677: loss: 0.051324, loss_s1: 0.024600, loss_fp: 0.000872, loss_freq: 0.036867
[15:07:22.948] iteration 17678: loss: 0.062692, loss_s1: 0.056335, loss_fp: 0.003171, loss_freq: 0.028119
[15:07:23.585] iteration 17679: loss: 0.046495, loss_s1: 0.043297, loss_fp: 0.002416, loss_freq: 0.012942
[15:07:24.243] iteration 17680: loss: 0.073596, loss_s1: 0.043195, loss_fp: 0.004446, loss_freq: 0.033568
[15:07:24.867] iteration 17681: loss: 0.079014, loss_s1: 0.026577, loss_fp: 0.003929, loss_freq: 0.093171
[15:07:25.512] iteration 17682: loss: 0.042471, loss_s1: 0.034381, loss_fp: 0.001043, loss_freq: 0.009183
[15:07:26.194] iteration 17683: loss: 0.060639, loss_s1: 0.029567, loss_fp: 0.003727, loss_freq: 0.007208
[15:07:26.852] iteration 17684: loss: 0.041780, loss_s1: 0.029844, loss_fp: 0.000542, loss_freq: 0.007405
[15:07:27.485] iteration 17685: loss: 0.054210, loss_s1: 0.043679, loss_fp: 0.010273, loss_freq: 0.007125
[15:07:28.121] iteration 17686: loss: 0.083316, loss_s1: 0.036421, loss_fp: 0.014841, loss_freq: 0.065736
[15:07:28.762] iteration 17687: loss: 0.034819, loss_s1: 0.011794, loss_fp: 0.001668, loss_freq: 0.015501
[15:07:29.400] iteration 17688: loss: 0.071561, loss_s1: 0.059218, loss_fp: 0.002382, loss_freq: 0.024408
[15:07:30.046] iteration 17689: loss: 0.076817, loss_s1: 0.058164, loss_fp: 0.001208, loss_freq: 0.036139
[15:07:30.678] iteration 17690: loss: 0.062099, loss_s1: 0.060562, loss_fp: 0.006366, loss_freq: 0.010595
[15:07:31.313] iteration 17691: loss: 0.067297, loss_s1: 0.018119, loss_fp: 0.003641, loss_freq: 0.043100
[15:07:31.951] iteration 17692: loss: 0.074330, loss_s1: 0.046471, loss_fp: 0.002663, loss_freq: 0.056911
[15:07:32.585] iteration 17693: loss: 0.058492, loss_s1: 0.021510, loss_fp: 0.003727, loss_freq: 0.043155
[15:07:33.218] iteration 17694: loss: 0.048165, loss_s1: 0.036880, loss_fp: 0.001480, loss_freq: 0.017616
[15:07:33.869] iteration 17695: loss: 0.037969, loss_s1: 0.012241, loss_fp: 0.003646, loss_freq: 0.021511
[15:07:34.554] iteration 17696: loss: 0.120050, loss_s1: 0.099934, loss_fp: 0.006562, loss_freq: 0.056583
[15:07:35.227] iteration 17697: loss: 0.042563, loss_s1: 0.017444, loss_fp: 0.005473, loss_freq: 0.028771
[15:07:35.903] iteration 17698: loss: 0.085121, loss_s1: 0.076210, loss_fp: 0.001820, loss_freq: 0.037475
[15:07:36.565] iteration 17699: loss: 0.052422, loss_s1: 0.044836, loss_fp: 0.002991, loss_freq: 0.021858
[15:07:37.224] iteration 17700: loss: 0.095948, loss_s1: 0.043096, loss_fp: 0.013892, loss_freq: 0.028704
[15:07:37.885] iteration 17701: loss: 0.061117, loss_s1: 0.048936, loss_fp: 0.001746, loss_freq: 0.039775
[15:07:38.515] iteration 17702: loss: 0.051074, loss_s1: 0.044038, loss_fp: 0.001891, loss_freq: 0.012357
[15:07:39.147] iteration 17703: loss: 0.109696, loss_s1: 0.140401, loss_fp: 0.006501, loss_freq: 0.022538
[15:07:39.773] iteration 17704: loss: 0.079831, loss_s1: 0.061080, loss_fp: 0.005688, loss_freq: 0.033190
[15:07:40.411] iteration 17705: loss: 0.054521, loss_s1: 0.023636, loss_fp: 0.000800, loss_freq: 0.038912
[15:07:41.039] iteration 17706: loss: 0.052303, loss_s1: 0.023451, loss_fp: 0.012691, loss_freq: 0.018129
[15:07:41.667] iteration 17707: loss: 0.066477, loss_s1: 0.052674, loss_fp: 0.002308, loss_freq: 0.028366
[15:07:42.297] iteration 17708: loss: 0.048502, loss_s1: 0.025420, loss_fp: 0.001610, loss_freq: 0.032252
[15:07:42.935] iteration 17709: loss: 0.068914, loss_s1: 0.040157, loss_fp: 0.000712, loss_freq: 0.045143
[15:07:43.560] iteration 17710: loss: 0.046423, loss_s1: 0.023385, loss_fp: 0.001015, loss_freq: 0.024412
[15:07:44.215] iteration 17711: loss: 0.110910, loss_s1: 0.016649, loss_fp: 0.000968, loss_freq: 0.017723
[15:07:44.878] iteration 17712: loss: 0.031540, loss_s1: 0.007969, loss_fp: 0.002982, loss_freq: 0.006747
[15:07:45.509] iteration 17713: loss: 0.035771, loss_s1: 0.022744, loss_fp: 0.004358, loss_freq: 0.014859
[15:07:46.134] iteration 17714: loss: 0.060791, loss_s1: 0.049622, loss_fp: 0.011852, loss_freq: 0.025327
[15:07:46.786] iteration 17715: loss: 0.078034, loss_s1: 0.053527, loss_fp: 0.001459, loss_freq: 0.008417
[15:07:47.432] iteration 17716: loss: 0.055194, loss_s1: 0.025831, loss_fp: 0.001016, loss_freq: 0.016097
[15:07:48.062] iteration 17717: loss: 0.045392, loss_s1: 0.021981, loss_fp: 0.011226, loss_freq: 0.022857
[15:07:48.694] iteration 17718: loss: 0.046347, loss_s1: 0.042658, loss_fp: 0.004512, loss_freq: 0.011337
[15:07:49.324] iteration 17719: loss: 0.040786, loss_s1: 0.020155, loss_fp: 0.001307, loss_freq: 0.010702
[15:07:49.944] iteration 17720: loss: 0.089471, loss_s1: 0.060297, loss_fp: 0.002739, loss_freq: 0.042196
[15:07:50.576] iteration 17721: loss: 0.067410, loss_s1: 0.035382, loss_fp: 0.006221, loss_freq: 0.023414
[15:07:51.199] iteration 17722: loss: 0.048857, loss_s1: 0.019876, loss_fp: 0.013053, loss_freq: 0.016248
[15:07:51.822] iteration 17723: loss: 0.089683, loss_s1: 0.083916, loss_fp: 0.003118, loss_freq: 0.031304
[15:07:52.450] iteration 17724: loss: 0.079981, loss_s1: 0.071469, loss_fp: 0.013132, loss_freq: 0.023333
[15:07:53.075] iteration 17725: loss: 0.070794, loss_s1: 0.034317, loss_fp: 0.006701, loss_freq: 0.045073
[15:07:53.704] iteration 17726: loss: 0.106556, loss_s1: 0.099607, loss_fp: 0.008388, loss_freq: 0.047745
[15:07:54.325] iteration 17727: loss: 0.052195, loss_s1: 0.023292, loss_fp: 0.001400, loss_freq: 0.016809
[15:07:54.957] iteration 17728: loss: 0.058595, loss_s1: 0.046456, loss_fp: 0.006157, loss_freq: 0.020045
[15:07:55.592] iteration 17729: loss: 0.074919, loss_s1: 0.040706, loss_fp: 0.001843, loss_freq: 0.018358
[15:07:56.221] iteration 17730: loss: 0.093463, loss_s1: 0.024218, loss_fp: 0.001821, loss_freq: 0.041763
[15:07:56.844] iteration 17731: loss: 0.095876, loss_s1: 0.109615, loss_fp: 0.004004, loss_freq: 0.034259
[15:07:57.500] iteration 17732: loss: 0.034436, loss_s1: 0.012822, loss_fp: 0.001910, loss_freq: 0.020403
[15:07:58.446] iteration 17733: loss: 0.057387, loss_s1: 0.038121, loss_fp: 0.005339, loss_freq: 0.019223
[15:07:59.078] iteration 17734: loss: 0.065914, loss_s1: 0.033245, loss_fp: 0.006428, loss_freq: 0.033147
[15:07:59.713] iteration 17735: loss: 0.043526, loss_s1: 0.033711, loss_fp: 0.000886, loss_freq: 0.012120
[15:08:00.338] iteration 17736: loss: 0.060824, loss_s1: 0.027162, loss_fp: 0.001961, loss_freq: 0.031462
[15:08:01.005] iteration 17737: loss: 0.082559, loss_s1: 0.053594, loss_fp: 0.003465, loss_freq: 0.078839
[15:08:01.666] iteration 17738: loss: 0.026416, loss_s1: 0.006037, loss_fp: 0.001318, loss_freq: 0.002743
[15:08:02.337] iteration 17739: loss: 0.046708, loss_s1: 0.022577, loss_fp: 0.014643, loss_freq: 0.020141
[15:08:03.002] iteration 17740: loss: 0.053678, loss_s1: 0.031912, loss_fp: 0.005271, loss_freq: 0.021393
[15:08:03.664] iteration 17741: loss: 0.068690, loss_s1: 0.070141, loss_fp: 0.002690, loss_freq: 0.021906
[15:08:04.331] iteration 17742: loss: 0.040471, loss_s1: 0.007240, loss_fp: 0.000925, loss_freq: 0.006438
[15:08:04.996] iteration 17743: loss: 0.089930, loss_s1: 0.038345, loss_fp: 0.005187, loss_freq: 0.039468
[15:08:05.659] iteration 17744: loss: 0.062923, loss_s1: 0.023509, loss_fp: 0.007661, loss_freq: 0.030637
[15:08:06.333] iteration 17745: loss: 0.050379, loss_s1: 0.032492, loss_fp: 0.001716, loss_freq: 0.010717
[15:08:07.005] iteration 17746: loss: 0.047003, loss_s1: 0.052096, loss_fp: 0.001249, loss_freq: 0.008579
[15:08:07.664] iteration 17747: loss: 0.064104, loss_s1: 0.026996, loss_fp: 0.004302, loss_freq: 0.050822
[15:08:08.324] iteration 17748: loss: 0.043924, loss_s1: 0.018161, loss_fp: 0.003204, loss_freq: 0.022918
[15:08:08.983] iteration 17749: loss: 0.089176, loss_s1: 0.024760, loss_fp: 0.000919, loss_freq: 0.009078
[15:08:09.622] iteration 17750: loss: 0.049436, loss_s1: 0.032015, loss_fp: 0.008787, loss_freq: 0.004818
[15:08:10.252] iteration 17751: loss: 0.055322, loss_s1: 0.036139, loss_fp: 0.013096, loss_freq: 0.030221
[15:08:10.882] iteration 17752: loss: 0.027919, loss_s1: 0.010561, loss_fp: 0.001106, loss_freq: 0.013720
[15:08:11.508] iteration 17753: loss: 0.116267, loss_s1: 0.029144, loss_fp: 0.002775, loss_freq: 0.051073
[15:08:12.182] iteration 17754: loss: 0.045891, loss_s1: 0.015966, loss_fp: 0.000279, loss_freq: 0.021133
[15:08:12.858] iteration 17755: loss: 0.039101, loss_s1: 0.022864, loss_fp: 0.001456, loss_freq: 0.015065
[15:08:13.543] iteration 17756: loss: 0.053488, loss_s1: 0.060080, loss_fp: 0.001675, loss_freq: 0.012985
[15:08:14.226] iteration 17757: loss: 0.046092, loss_s1: 0.026974, loss_fp: 0.002302, loss_freq: 0.006259
[15:08:14.912] iteration 17758: loss: 0.094289, loss_s1: 0.067400, loss_fp: 0.004686, loss_freq: 0.063177
[15:08:15.565] iteration 17759: loss: 0.054459, loss_s1: 0.025530, loss_fp: 0.001946, loss_freq: 0.039501
[15:08:16.268] iteration 17760: loss: 0.058408, loss_s1: 0.033858, loss_fp: 0.000706, loss_freq: 0.004948
[15:08:16.927] iteration 17761: loss: 0.062823, loss_s1: 0.032125, loss_fp: 0.005230, loss_freq: 0.037582
[15:08:17.588] iteration 17762: loss: 0.062297, loss_s1: 0.027213, loss_fp: 0.002120, loss_freq: 0.014464
[15:08:18.269] iteration 17763: loss: 0.042128, loss_s1: 0.026005, loss_fp: 0.001423, loss_freq: 0.018902
[15:08:18.944] iteration 17764: loss: 0.051793, loss_s1: 0.037145, loss_fp: 0.007247, loss_freq: 0.015395
[15:08:19.604] iteration 17765: loss: 0.059272, loss_s1: 0.050637, loss_fp: 0.004845, loss_freq: 0.033346
[15:08:20.254] iteration 17766: loss: 0.098912, loss_s1: 0.046985, loss_fp: 0.006293, loss_freq: 0.073861
[15:08:20.904] iteration 17767: loss: 0.076297, loss_s1: 0.061785, loss_fp: 0.004456, loss_freq: 0.031696
[15:08:21.551] iteration 17768: loss: 0.053243, loss_s1: 0.036230, loss_fp: 0.005267, loss_freq: 0.025769
[15:08:22.197] iteration 17769: loss: 0.051756, loss_s1: 0.019381, loss_fp: 0.003240, loss_freq: 0.025404
[15:08:22.837] iteration 17770: loss: 0.061834, loss_s1: 0.045150, loss_fp: 0.013527, loss_freq: 0.021077
[15:08:23.482] iteration 17771: loss: 0.086215, loss_s1: 0.078991, loss_fp: 0.002278, loss_freq: 0.038091
[15:08:24.121] iteration 17772: loss: 0.045269, loss_s1: 0.043353, loss_fp: 0.002047, loss_freq: 0.011342
[15:08:24.755] iteration 17773: loss: 0.056294, loss_s1: 0.031591, loss_fp: 0.007464, loss_freq: 0.028076
[15:08:25.392] iteration 17774: loss: 0.054201, loss_s1: 0.037999, loss_fp: 0.003886, loss_freq: 0.039445
[15:08:26.032] iteration 17775: loss: 0.065795, loss_s1: 0.023914, loss_fp: 0.001096, loss_freq: 0.025263
[15:08:26.674] iteration 17776: loss: 0.053805, loss_s1: 0.032555, loss_fp: 0.002160, loss_freq: 0.025320
[15:08:27.318] iteration 17777: loss: 0.072346, loss_s1: 0.068432, loss_fp: 0.002476, loss_freq: 0.007265
[15:08:27.966] iteration 17778: loss: 0.075604, loss_s1: 0.030217, loss_fp: 0.004657, loss_freq: 0.023061
[15:08:28.599] iteration 17779: loss: 0.048881, loss_s1: 0.033240, loss_fp: 0.003473, loss_freq: 0.014605
[15:08:29.231] iteration 17780: loss: 0.069788, loss_s1: 0.023490, loss_fp: 0.008579, loss_freq: 0.015231
[15:08:29.880] iteration 17781: loss: 0.040151, loss_s1: 0.025538, loss_fp: 0.003765, loss_freq: 0.014803
[15:08:30.520] iteration 17782: loss: 0.037944, loss_s1: 0.016616, loss_fp: 0.001354, loss_freq: 0.010818
[15:08:31.206] iteration 17783: loss: 0.035938, loss_s1: 0.016726, loss_fp: 0.003087, loss_freq: 0.007252
[15:08:31.873] iteration 17784: loss: 0.061079, loss_s1: 0.042434, loss_fp: 0.001362, loss_freq: 0.023486
[15:08:32.571] iteration 17785: loss: 0.048516, loss_s1: 0.029599, loss_fp: 0.001149, loss_freq: 0.023526
[15:08:33.224] iteration 17786: loss: 0.046745, loss_s1: 0.039151, loss_fp: 0.002689, loss_freq: 0.013759
[15:08:33.884] iteration 17787: loss: 0.058046, loss_s1: 0.060332, loss_fp: 0.000284, loss_freq: 0.022822
[15:08:34.543] iteration 17788: loss: 0.078827, loss_s1: 0.026345, loss_fp: 0.002661, loss_freq: 0.020765
[15:08:35.195] iteration 17789: loss: 0.072233, loss_s1: 0.067375, loss_fp: 0.004005, loss_freq: 0.040942
[15:08:35.849] iteration 17790: loss: 0.030222, loss_s1: 0.012078, loss_fp: 0.001302, loss_freq: 0.010250
[15:08:36.527] iteration 17791: loss: 0.081957, loss_s1: 0.042638, loss_fp: 0.001377, loss_freq: 0.065347
[15:08:37.169] iteration 17792: loss: 0.050076, loss_s1: 0.021995, loss_fp: 0.002174, loss_freq: 0.019237
[15:08:37.795] iteration 17793: loss: 0.068358, loss_s1: 0.038085, loss_fp: 0.003222, loss_freq: 0.028603
[15:08:38.419] iteration 17794: loss: 0.062527, loss_s1: 0.043021, loss_fp: 0.012777, loss_freq: 0.023453
[15:08:39.044] iteration 17795: loss: 0.080766, loss_s1: 0.085224, loss_fp: 0.002043, loss_freq: 0.028134
[15:08:39.674] iteration 17796: loss: 0.055088, loss_s1: 0.032724, loss_fp: 0.002236, loss_freq: 0.017017
[15:08:40.304] iteration 17797: loss: 0.095727, loss_s1: 0.081351, loss_fp: 0.009963, loss_freq: 0.029030
[15:08:40.927] iteration 17798: loss: 0.053824, loss_s1: 0.021532, loss_fp: 0.003585, loss_freq: 0.020700
[15:08:41.549] iteration 17799: loss: 0.117299, loss_s1: 0.124894, loss_fp: 0.007344, loss_freq: 0.060130
[15:08:42.182] iteration 17800: loss: 0.050691, loss_s1: 0.025555, loss_fp: 0.005463, loss_freq: 0.010311
[15:08:45.592] iteration 17800 : mean_dice : 0.790799
[15:08:46.243] iteration 17801: loss: 0.066536, loss_s1: 0.041500, loss_fp: 0.003313, loss_freq: 0.014736
[15:08:46.872] iteration 17802: loss: 0.061032, loss_s1: 0.036144, loss_fp: 0.002306, loss_freq: 0.012916
[15:08:47.502] iteration 17803: loss: 0.058894, loss_s1: 0.056168, loss_fp: 0.001347, loss_freq: 0.020823
[15:08:48.131] iteration 17804: loss: 0.063525, loss_s1: 0.037979, loss_fp: 0.004278, loss_freq: 0.024994
[15:08:48.754] iteration 17805: loss: 0.047105, loss_s1: 0.017885, loss_fp: 0.009384, loss_freq: 0.033816
[15:08:49.384] iteration 17806: loss: 0.087124, loss_s1: 0.066941, loss_fp: 0.011020, loss_freq: 0.049177
[15:08:50.045] iteration 17807: loss: 0.084615, loss_s1: 0.049121, loss_fp: 0.007600, loss_freq: 0.052603
[15:08:50.710] iteration 17808: loss: 0.073867, loss_s1: 0.041378, loss_fp: 0.005325, loss_freq: 0.014803
[15:08:51.377] iteration 17809: loss: 0.051000, loss_s1: 0.053136, loss_fp: 0.005553, loss_freq: 0.012558
[15:08:52.035] iteration 17810: loss: 0.062495, loss_s1: 0.048950, loss_fp: 0.002330, loss_freq: 0.020851
[15:08:52.691] iteration 17811: loss: 0.073790, loss_s1: 0.038384, loss_fp: 0.005670, loss_freq: 0.053047
[15:08:53.354] iteration 17812: loss: 0.116771, loss_s1: 0.083275, loss_fp: 0.009807, loss_freq: 0.040462
[15:08:54.015] iteration 17813: loss: 0.061091, loss_s1: 0.024704, loss_fp: 0.001069, loss_freq: 0.039105
[15:08:54.678] iteration 17814: loss: 0.056310, loss_s1: 0.033487, loss_fp: 0.010384, loss_freq: 0.018196
[15:08:55.343] iteration 17815: loss: 0.040999, loss_s1: 0.016891, loss_fp: 0.000574, loss_freq: 0.012250
[15:08:55.984] iteration 17816: loss: 0.044641, loss_s1: 0.033700, loss_fp: 0.002959, loss_freq: 0.022218
[15:08:56.657] iteration 17817: loss: 0.054720, loss_s1: 0.024962, loss_fp: 0.007533, loss_freq: 0.028672
[15:08:57.291] iteration 17818: loss: 0.075838, loss_s1: 0.045232, loss_fp: 0.002688, loss_freq: 0.059114
[15:08:57.921] iteration 17819: loss: 0.097723, loss_s1: 0.044508, loss_fp: 0.001847, loss_freq: 0.029881
[15:08:58.540] iteration 17820: loss: 0.057613, loss_s1: 0.044299, loss_fp: 0.000689, loss_freq: 0.013760
[15:08:59.159] iteration 17821: loss: 0.032900, loss_s1: 0.017985, loss_fp: 0.001387, loss_freq: 0.006758
[15:08:59.788] iteration 17822: loss: 0.037351, loss_s1: 0.026531, loss_fp: 0.004316, loss_freq: 0.008578
[15:09:00.410] iteration 17823: loss: 0.073630, loss_s1: 0.026935, loss_fp: 0.001153, loss_freq: 0.032618
[15:09:01.037] iteration 17824: loss: 0.056937, loss_s1: 0.053634, loss_fp: 0.001118, loss_freq: 0.015668
[15:09:01.665] iteration 17825: loss: 0.063609, loss_s1: 0.041593, loss_fp: 0.002944, loss_freq: 0.039395
[15:09:02.285] iteration 17826: loss: 0.042279, loss_s1: 0.021379, loss_fp: 0.002260, loss_freq: 0.009176
[15:09:02.928] iteration 17827: loss: 0.046121, loss_s1: 0.008751, loss_fp: 0.001175, loss_freq: 0.028849
[15:09:03.560] iteration 17828: loss: 0.051494, loss_s1: 0.009202, loss_fp: 0.000294, loss_freq: 0.012384
[15:09:04.221] iteration 17829: loss: 0.093092, loss_s1: 0.064200, loss_fp: 0.008000, loss_freq: 0.069116
[15:09:04.857] iteration 17830: loss: 0.039977, loss_s1: 0.027523, loss_fp: 0.001961, loss_freq: 0.011652
[15:09:05.489] iteration 17831: loss: 0.065513, loss_s1: 0.057539, loss_fp: 0.004747, loss_freq: 0.015663
[15:09:06.118] iteration 17832: loss: 0.089720, loss_s1: 0.031542, loss_fp: 0.012891, loss_freq: 0.029812
[15:09:06.747] iteration 17833: loss: 0.057640, loss_s1: 0.047314, loss_fp: 0.001756, loss_freq: 0.018144
[15:09:07.381] iteration 17834: loss: 0.075754, loss_s1: 0.033452, loss_fp: 0.005863, loss_freq: 0.042656
[15:09:08.423] iteration 17835: loss: 0.068798, loss_s1: 0.059203, loss_fp: 0.017444, loss_freq: 0.026286
[15:09:09.424] iteration 17836: loss: 0.037571, loss_s1: 0.013742, loss_fp: 0.006488, loss_freq: 0.009864
[15:09:10.306] iteration 17837: loss: 0.083061, loss_s1: 0.055767, loss_fp: 0.005226, loss_freq: 0.026819
[15:09:10.927] iteration 17838: loss: 0.077347, loss_s1: 0.040851, loss_fp: 0.002982, loss_freq: 0.050200
[15:09:11.602] iteration 17839: loss: 0.083629, loss_s1: 0.058826, loss_fp: 0.006005, loss_freq: 0.053133
[15:09:12.299] iteration 17840: loss: 0.042480, loss_s1: 0.016130, loss_fp: 0.002013, loss_freq: 0.031121
[15:09:12.976] iteration 17841: loss: 0.078337, loss_s1: 0.052099, loss_fp: 0.001140, loss_freq: 0.031309
[15:09:13.614] iteration 17842: loss: 0.078247, loss_s1: 0.060434, loss_fp: 0.003471, loss_freq: 0.053246
[15:09:14.247] iteration 17843: loss: 0.061684, loss_s1: 0.025770, loss_fp: 0.004070, loss_freq: 0.011312
[15:09:14.879] iteration 17844: loss: 0.063315, loss_s1: 0.062551, loss_fp: 0.002599, loss_freq: 0.031985
[15:09:15.511] iteration 17845: loss: 0.041290, loss_s1: 0.019054, loss_fp: 0.001430, loss_freq: 0.011387
[15:09:16.139] iteration 17846: loss: 0.054110, loss_s1: 0.036053, loss_fp: 0.002335, loss_freq: 0.020526
[15:09:16.769] iteration 17847: loss: 0.051239, loss_s1: 0.014504, loss_fp: 0.001379, loss_freq: 0.022447
[15:09:17.392] iteration 17848: loss: 0.036635, loss_s1: 0.009918, loss_fp: 0.001613, loss_freq: 0.015606
[15:09:18.026] iteration 17849: loss: 0.044362, loss_s1: 0.018724, loss_fp: 0.000948, loss_freq: 0.028936
[15:09:18.651] iteration 17850: loss: 0.070907, loss_s1: 0.076893, loss_fp: 0.002982, loss_freq: 0.021033
[15:09:19.281] iteration 17851: loss: 0.039646, loss_s1: 0.021121, loss_fp: 0.005195, loss_freq: 0.019861
[15:09:19.907] iteration 17852: loss: 0.041482, loss_s1: 0.025382, loss_fp: 0.002094, loss_freq: 0.012532
[15:09:20.527] iteration 17853: loss: 0.062649, loss_s1: 0.029932, loss_fp: 0.003155, loss_freq: 0.047632
[15:09:21.152] iteration 17854: loss: 0.058284, loss_s1: 0.021996, loss_fp: 0.002366, loss_freq: 0.023098
[15:09:21.781] iteration 17855: loss: 0.040589, loss_s1: 0.031127, loss_fp: 0.000544, loss_freq: 0.004847
[15:09:22.440] iteration 17856: loss: 0.034457, loss_s1: 0.027123, loss_fp: 0.003684, loss_freq: 0.011109
[15:09:23.098] iteration 17857: loss: 0.078730, loss_s1: 0.057534, loss_fp: 0.004955, loss_freq: 0.026829
[15:09:23.770] iteration 17858: loss: 0.115247, loss_s1: 0.027176, loss_fp: 0.003872, loss_freq: 0.036760
[15:09:24.439] iteration 17859: loss: 0.052069, loss_s1: 0.031271, loss_fp: 0.003972, loss_freq: 0.037014
[15:09:25.091] iteration 17860: loss: 0.062623, loss_s1: 0.054406, loss_fp: 0.001640, loss_freq: 0.029572
[15:09:25.717] iteration 17861: loss: 0.074879, loss_s1: 0.039752, loss_fp: 0.002070, loss_freq: 0.022491
[15:09:26.351] iteration 17862: loss: 0.046831, loss_s1: 0.020567, loss_fp: 0.003163, loss_freq: 0.013132
[15:09:26.983] iteration 17863: loss: 0.073421, loss_s1: 0.057285, loss_fp: 0.001037, loss_freq: 0.019859
[15:09:27.609] iteration 17864: loss: 0.092080, loss_s1: 0.074665, loss_fp: 0.008481, loss_freq: 0.061854
[15:09:28.227] iteration 17865: loss: 0.042813, loss_s1: 0.012511, loss_fp: 0.005741, loss_freq: 0.009825
[15:09:28.843] iteration 17866: loss: 0.127658, loss_s1: 0.086889, loss_fp: 0.003189, loss_freq: 0.083620
[15:09:29.468] iteration 17867: loss: 0.090943, loss_s1: 0.044192, loss_fp: 0.009286, loss_freq: 0.039654
[15:09:30.119] iteration 17868: loss: 0.092806, loss_s1: 0.101212, loss_fp: 0.006728, loss_freq: 0.021717
[15:09:30.782] iteration 17869: loss: 0.071742, loss_s1: 0.044756, loss_fp: 0.005973, loss_freq: 0.047025
[15:09:31.441] iteration 17870: loss: 0.038101, loss_s1: 0.015273, loss_fp: 0.000318, loss_freq: 0.011687
[15:09:32.100] iteration 17871: loss: 0.055397, loss_s1: 0.038819, loss_fp: 0.006742, loss_freq: 0.027718
[15:09:32.755] iteration 17872: loss: 0.055513, loss_s1: 0.020541, loss_fp: 0.005000, loss_freq: 0.020221
[15:09:33.393] iteration 17873: loss: 0.052815, loss_s1: 0.037245, loss_fp: 0.000467, loss_freq: 0.026033
[15:09:34.011] iteration 17874: loss: 0.100273, loss_s1: 0.052667, loss_fp: 0.015046, loss_freq: 0.085837
[15:09:34.635] iteration 17875: loss: 0.047213, loss_s1: 0.018754, loss_fp: 0.001232, loss_freq: 0.037444
[15:09:35.571] iteration 17876: loss: 0.044445, loss_s1: 0.026973, loss_fp: 0.000397, loss_freq: 0.010401
[15:09:36.223] iteration 17877: loss: 0.064846, loss_s1: 0.035718, loss_fp: 0.002655, loss_freq: 0.018452
[15:09:36.902] iteration 17878: loss: 0.076507, loss_s1: 0.053053, loss_fp: 0.003965, loss_freq: 0.050168
[15:09:37.577] iteration 17879: loss: 0.066318, loss_s1: 0.042485, loss_fp: 0.003316, loss_freq: 0.015319
[15:09:38.249] iteration 17880: loss: 0.082092, loss_s1: 0.067529, loss_fp: 0.002277, loss_freq: 0.039206
[15:09:38.936] iteration 17881: loss: 0.043569, loss_s1: 0.015814, loss_fp: 0.000369, loss_freq: 0.002870
[15:09:39.608] iteration 17882: loss: 0.042282, loss_s1: 0.027335, loss_fp: 0.001391, loss_freq: 0.021212
[15:09:40.279] iteration 17883: loss: 0.077147, loss_s1: 0.060636, loss_fp: 0.001739, loss_freq: 0.035050
[15:09:40.949] iteration 17884: loss: 0.032360, loss_s1: 0.012798, loss_fp: 0.000820, loss_freq: 0.008459
[15:09:41.592] iteration 17885: loss: 0.038526, loss_s1: 0.014391, loss_fp: 0.000749, loss_freq: 0.003932
[15:09:42.227] iteration 17886: loss: 0.085368, loss_s1: 0.060789, loss_fp: 0.007270, loss_freq: 0.060753
[15:09:42.870] iteration 17887: loss: 0.044957, loss_s1: 0.022828, loss_fp: 0.002378, loss_freq: 0.009148
[15:09:43.513] iteration 17888: loss: 0.078390, loss_s1: 0.053694, loss_fp: 0.000783, loss_freq: 0.016084
[15:09:44.225] iteration 17889: loss: 0.028434, loss_s1: 0.010172, loss_fp: 0.000528, loss_freq: 0.012287
[15:09:44.875] iteration 17890: loss: 0.061153, loss_s1: 0.046756, loss_fp: 0.003079, loss_freq: 0.033256
[15:09:45.518] iteration 17891: loss: 0.044432, loss_s1: 0.030432, loss_fp: 0.000684, loss_freq: 0.009604
[15:09:46.157] iteration 17892: loss: 0.066453, loss_s1: 0.033985, loss_fp: 0.001040, loss_freq: 0.033761
[15:09:46.793] iteration 17893: loss: 0.056046, loss_s1: 0.035014, loss_fp: 0.004353, loss_freq: 0.017009
[15:09:47.471] iteration 17894: loss: 0.050193, loss_s1: 0.037692, loss_fp: 0.002861, loss_freq: 0.023415
[15:09:48.142] iteration 17895: loss: 0.045565, loss_s1: 0.025276, loss_fp: 0.000737, loss_freq: 0.028409
[15:09:48.818] iteration 17896: loss: 0.103595, loss_s1: 0.017239, loss_fp: 0.004748, loss_freq: 0.059221
[15:09:49.481] iteration 17897: loss: 0.036212, loss_s1: 0.014773, loss_fp: 0.005375, loss_freq: 0.018504
[15:09:50.145] iteration 17898: loss: 0.039291, loss_s1: 0.028245, loss_fp: 0.000475, loss_freq: 0.017778
[15:09:50.805] iteration 17899: loss: 0.060901, loss_s1: 0.056062, loss_fp: 0.002907, loss_freq: 0.011854
[15:09:51.462] iteration 17900: loss: 0.058325, loss_s1: 0.048316, loss_fp: 0.002209, loss_freq: 0.016562
[15:09:52.114] iteration 17901: loss: 0.095296, loss_s1: 0.104569, loss_fp: 0.003635, loss_freq: 0.028365
[15:09:52.772] iteration 17902: loss: 0.098087, loss_s1: 0.060507, loss_fp: 0.005718, loss_freq: 0.076536
[15:09:53.432] iteration 17903: loss: 0.047147, loss_s1: 0.031844, loss_fp: 0.003174, loss_freq: 0.010476
[15:09:54.139] iteration 17904: loss: 0.064910, loss_s1: 0.036240, loss_fp: 0.003331, loss_freq: 0.038027
[15:09:54.804] iteration 17905: loss: 0.073028, loss_s1: 0.021384, loss_fp: 0.000932, loss_freq: 0.013252
[15:09:55.477] iteration 17906: loss: 0.065900, loss_s1: 0.075740, loss_fp: 0.002205, loss_freq: 0.016167
[15:09:56.160] iteration 17907: loss: 0.060355, loss_s1: 0.031850, loss_fp: 0.003100, loss_freq: 0.038413
[15:09:56.833] iteration 17908: loss: 0.048492, loss_s1: 0.032650, loss_fp: 0.012886, loss_freq: 0.015867
[15:09:57.506] iteration 17909: loss: 0.079700, loss_s1: 0.069216, loss_fp: 0.003121, loss_freq: 0.044370
[15:09:58.161] iteration 17910: loss: 0.062906, loss_s1: 0.036400, loss_fp: 0.004670, loss_freq: 0.034140
[15:09:58.831] iteration 17911: loss: 0.111748, loss_s1: 0.108306, loss_fp: 0.001805, loss_freq: 0.047842
[15:09:59.483] iteration 17912: loss: 0.064081, loss_s1: 0.050108, loss_fp: 0.002357, loss_freq: 0.026232
[15:10:00.167] iteration 17913: loss: 0.093134, loss_s1: 0.073378, loss_fp: 0.001563, loss_freq: 0.080742
[15:10:00.851] iteration 17914: loss: 0.096572, loss_s1: 0.042124, loss_fp: 0.008520, loss_freq: 0.052702
[15:10:01.537] iteration 17915: loss: 0.039200, loss_s1: 0.018793, loss_fp: 0.019475, loss_freq: 0.007510
[15:10:02.173] iteration 17916: loss: 0.086526, loss_s1: 0.057251, loss_fp: 0.002412, loss_freq: 0.015668
[15:10:02.812] iteration 17917: loss: 0.054071, loss_s1: 0.040467, loss_fp: 0.005327, loss_freq: 0.026989
[15:10:03.441] iteration 17918: loss: 0.049490, loss_s1: 0.020299, loss_fp: 0.003557, loss_freq: 0.018020
[15:10:04.083] iteration 17919: loss: 0.071717, loss_s1: 0.066268, loss_fp: 0.003406, loss_freq: 0.029021
[15:10:04.753] iteration 17920: loss: 0.068426, loss_s1: 0.034314, loss_fp: 0.000367, loss_freq: 0.006390
[15:10:05.392] iteration 17921: loss: 0.045218, loss_s1: 0.023847, loss_fp: 0.000987, loss_freq: 0.018861
[15:10:06.043] iteration 17922: loss: 0.062009, loss_s1: 0.010763, loss_fp: 0.017290, loss_freq: 0.054415
[15:10:06.683] iteration 17923: loss: 0.064650, loss_s1: 0.056147, loss_fp: 0.002031, loss_freq: 0.027852
[15:10:07.354] iteration 17924: loss: 0.053540, loss_s1: 0.062246, loss_fp: 0.001061, loss_freq: 0.009314
[15:10:08.003] iteration 17925: loss: 0.075651, loss_s1: 0.076424, loss_fp: 0.002226, loss_freq: 0.027027
[15:10:08.654] iteration 17926: loss: 0.066955, loss_s1: 0.042940, loss_fp: 0.007912, loss_freq: 0.030588
[15:10:09.297] iteration 17927: loss: 0.047435, loss_s1: 0.023508, loss_fp: 0.003102, loss_freq: 0.022266
[15:10:09.939] iteration 17928: loss: 0.054068, loss_s1: 0.052482, loss_fp: 0.001685, loss_freq: 0.007739
[15:10:10.632] iteration 17929: loss: 0.035608, loss_s1: 0.020037, loss_fp: 0.004125, loss_freq: 0.015200
[15:10:11.295] iteration 17930: loss: 0.046433, loss_s1: 0.032162, loss_fp: 0.004503, loss_freq: 0.016812
[15:10:11.956] iteration 17931: loss: 0.071587, loss_s1: 0.046400, loss_fp: 0.000403, loss_freq: 0.011218
[15:10:12.617] iteration 17932: loss: 0.091407, loss_s1: 0.048349, loss_fp: 0.002368, loss_freq: 0.045769
[15:10:13.255] iteration 17933: loss: 0.054541, loss_s1: 0.048780, loss_fp: 0.003013, loss_freq: 0.013562
[15:10:13.883] iteration 17934: loss: 0.084561, loss_s1: 0.053702, loss_fp: 0.002070, loss_freq: 0.039789
[15:10:14.547] iteration 17935: loss: 0.068129, loss_s1: 0.056547, loss_fp: 0.001847, loss_freq: 0.038354
[15:10:15.205] iteration 17936: loss: 0.072197, loss_s1: 0.027275, loss_fp: 0.001795, loss_freq: 0.009756
[15:10:15.834] iteration 17937: loss: 0.056834, loss_s1: 0.034785, loss_fp: 0.015847, loss_freq: 0.013012
[15:10:16.493] iteration 17938: loss: 0.069685, loss_s1: 0.054413, loss_fp: 0.004744, loss_freq: 0.033777
[15:10:17.152] iteration 17939: loss: 0.076664, loss_s1: 0.031587, loss_fp: 0.001032, loss_freq: 0.035539
[15:10:17.797] iteration 17940: loss: 0.075099, loss_s1: 0.083005, loss_fp: 0.004732, loss_freq: 0.011901
[15:10:18.423] iteration 17941: loss: 0.050705, loss_s1: 0.042236, loss_fp: 0.000791, loss_freq: 0.012946
[15:10:19.041] iteration 17942: loss: 0.090291, loss_s1: 0.038266, loss_fp: 0.021553, loss_freq: 0.058448
[15:10:19.658] iteration 17943: loss: 0.039219, loss_s1: 0.014187, loss_fp: 0.001033, loss_freq: 0.021680
[15:10:20.278] iteration 17944: loss: 0.044119, loss_s1: 0.014183, loss_fp: 0.004393, loss_freq: 0.026678
[15:10:20.897] iteration 17945: loss: 0.063632, loss_s1: 0.032607, loss_fp: 0.004619, loss_freq: 0.007306
[15:10:21.517] iteration 17946: loss: 0.053769, loss_s1: 0.044798, loss_fp: 0.011660, loss_freq: 0.008863
[15:10:22.155] iteration 17947: loss: 0.046002, loss_s1: 0.015543, loss_fp: 0.004821, loss_freq: 0.028142
[15:10:22.782] iteration 17948: loss: 0.072565, loss_s1: 0.056604, loss_fp: 0.002453, loss_freq: 0.038013
[15:10:23.409] iteration 17949: loss: 0.103168, loss_s1: 0.082949, loss_fp: 0.003071, loss_freq: 0.063778
[15:10:24.030] iteration 17950: loss: 0.059761, loss_s1: 0.032429, loss_fp: 0.009337, loss_freq: 0.038273
[15:10:24.659] iteration 17951: loss: 0.095876, loss_s1: 0.082530, loss_fp: 0.001230, loss_freq: 0.017494
[15:10:25.291] iteration 17952: loss: 0.051245, loss_s1: 0.036837, loss_fp: 0.002086, loss_freq: 0.027350
[15:10:25.919] iteration 17953: loss: 0.052407, loss_s1: 0.011973, loss_fp: 0.002233, loss_freq: 0.021419
[15:10:26.544] iteration 17954: loss: 0.056240, loss_s1: 0.041413, loss_fp: 0.003050, loss_freq: 0.024278
[15:10:27.161] iteration 17955: loss: 0.094645, loss_s1: 0.065806, loss_fp: 0.002702, loss_freq: 0.031343
[15:10:27.791] iteration 17956: loss: 0.071941, loss_s1: 0.066901, loss_fp: 0.000859, loss_freq: 0.019188
[15:10:28.424] iteration 17957: loss: 0.066387, loss_s1: 0.043511, loss_fp: 0.002144, loss_freq: 0.029649
[15:10:29.057] iteration 17958: loss: 0.064229, loss_s1: 0.032156, loss_fp: 0.006086, loss_freq: 0.025752
[15:10:29.682] iteration 17959: loss: 0.052017, loss_s1: 0.049436, loss_fp: 0.002574, loss_freq: 0.015600
[15:10:30.301] iteration 17960: loss: 0.062355, loss_s1: 0.041919, loss_fp: 0.011986, loss_freq: 0.017972
[15:10:30.932] iteration 17961: loss: 0.084627, loss_s1: 0.068437, loss_fp: 0.001826, loss_freq: 0.044889
[15:10:31.563] iteration 17962: loss: 0.059549, loss_s1: 0.030168, loss_fp: 0.014191, loss_freq: 0.004483
[15:10:32.186] iteration 17963: loss: 0.061209, loss_s1: 0.035685, loss_fp: 0.001528, loss_freq: 0.020616
[15:10:32.806] iteration 17964: loss: 0.057890, loss_s1: 0.059669, loss_fp: 0.001419, loss_freq: 0.017246
[15:10:33.474] iteration 17965: loss: 0.059562, loss_s1: 0.062202, loss_fp: 0.004631, loss_freq: 0.019542
[15:10:34.131] iteration 17966: loss: 0.066521, loss_s1: 0.046389, loss_fp: 0.003414, loss_freq: 0.023972
[15:10:34.794] iteration 17967: loss: 0.054868, loss_s1: 0.050981, loss_fp: 0.002331, loss_freq: 0.019481
[15:10:35.457] iteration 17968: loss: 0.044189, loss_s1: 0.036654, loss_fp: 0.003011, loss_freq: 0.011652
[15:10:36.150] iteration 17969: loss: 0.055487, loss_s1: 0.022110, loss_fp: 0.001851, loss_freq: 0.018270
[15:10:36.802] iteration 17970: loss: 0.050527, loss_s1: 0.022539, loss_fp: 0.002303, loss_freq: 0.024250
[15:10:37.433] iteration 17971: loss: 0.050146, loss_s1: 0.043681, loss_fp: 0.000906, loss_freq: 0.005249
[15:10:38.064] iteration 17972: loss: 0.097748, loss_s1: 0.080415, loss_fp: 0.009633, loss_freq: 0.041475
[15:10:38.713] iteration 17973: loss: 0.041020, loss_s1: 0.010485, loss_fp: 0.002999, loss_freq: 0.028006
[15:10:39.341] iteration 17974: loss: 0.062998, loss_s1: 0.037232, loss_fp: 0.004191, loss_freq: 0.030445
[15:10:39.972] iteration 17975: loss: 0.083814, loss_s1: 0.038877, loss_fp: 0.001766, loss_freq: 0.050865
[15:10:40.604] iteration 17976: loss: 0.046179, loss_s1: 0.018679, loss_fp: 0.005214, loss_freq: 0.026664
[15:10:41.238] iteration 17977: loss: 0.051973, loss_s1: 0.025666, loss_fp: 0.003160, loss_freq: 0.011684
[15:10:41.922] iteration 17978: loss: 0.083859, loss_s1: 0.123465, loss_fp: 0.003131, loss_freq: 0.007188
[15:10:42.547] iteration 17979: loss: 0.036102, loss_s1: 0.015845, loss_fp: 0.001085, loss_freq: 0.011556
[15:10:43.179] iteration 17980: loss: 0.072088, loss_s1: 0.028382, loss_fp: 0.003476, loss_freq: 0.022040
[15:10:43.807] iteration 17981: loss: 0.065551, loss_s1: 0.043346, loss_fp: 0.000651, loss_freq: 0.028403
[15:10:44.467] iteration 17982: loss: 0.062019, loss_s1: 0.051015, loss_fp: 0.004264, loss_freq: 0.022526
[15:10:45.080] iteration 17983: loss: 0.050529, loss_s1: 0.020878, loss_fp: 0.004884, loss_freq: 0.028438
[15:10:45.702] iteration 17984: loss: 0.055710, loss_s1: 0.047256, loss_fp: 0.001125, loss_freq: 0.023094
[15:10:46.328] iteration 17985: loss: 0.042935, loss_s1: 0.025435, loss_fp: 0.010047, loss_freq: 0.018708
[15:10:46.956] iteration 17986: loss: 0.075275, loss_s1: 0.044330, loss_fp: 0.004781, loss_freq: 0.024039
[15:10:47.587] iteration 17987: loss: 0.054610, loss_s1: 0.057528, loss_fp: 0.004356, loss_freq: 0.018390
[15:10:48.216] iteration 17988: loss: 0.050357, loss_s1: 0.032642, loss_fp: 0.001952, loss_freq: 0.011631
[15:10:48.847] iteration 17989: loss: 0.049669, loss_s1: 0.024376, loss_fp: 0.013631, loss_freq: 0.012131
[15:10:49.476] iteration 17990: loss: 0.068735, loss_s1: 0.033311, loss_fp: 0.002557, loss_freq: 0.039094
[15:10:50.104] iteration 17991: loss: 0.053464, loss_s1: 0.056560, loss_fp: 0.001038, loss_freq: 0.015754
[15:10:50.726] iteration 17992: loss: 0.049101, loss_s1: 0.030013, loss_fp: 0.003161, loss_freq: 0.014204
[15:10:51.352] iteration 17993: loss: 0.073403, loss_s1: 0.063758, loss_fp: 0.008673, loss_freq: 0.022687
[15:10:51.969] iteration 17994: loss: 0.045821, loss_s1: 0.045007, loss_fp: 0.003517, loss_freq: 0.014283
[15:10:52.596] iteration 17995: loss: 0.041612, loss_s1: 0.014578, loss_fp: 0.002799, loss_freq: 0.019691
[15:10:53.214] iteration 17996: loss: 0.073503, loss_s1: 0.055271, loss_fp: 0.001288, loss_freq: 0.051226
[15:10:53.847] iteration 17997: loss: 0.075479, loss_s1: 0.080917, loss_fp: 0.010352, loss_freq: 0.015237
[15:10:54.529] iteration 17998: loss: 0.037033, loss_s1: 0.019608, loss_fp: 0.002352, loss_freq: 0.005797
[15:10:55.228] iteration 17999: loss: 0.060393, loss_s1: 0.047311, loss_fp: 0.002742, loss_freq: 0.034700
[15:10:55.881] iteration 18000: loss: 0.051708, loss_s1: 0.035773, loss_fp: 0.004271, loss_freq: 0.018112
[15:10:59.569] iteration 18000 : mean_dice : 0.783314
[15:11:00.280] iteration 18001: loss: 0.048333, loss_s1: 0.031127, loss_fp: 0.001555, loss_freq: 0.011522
[15:11:00.947] iteration 18002: loss: 0.051611, loss_s1: 0.049715, loss_fp: 0.001843, loss_freq: 0.016113
[15:11:01.604] iteration 18003: loss: 0.044750, loss_s1: 0.019098, loss_fp: 0.009156, loss_freq: 0.018118
[15:11:02.250] iteration 18004: loss: 0.048980, loss_s1: 0.033436, loss_fp: 0.001279, loss_freq: 0.013319
[15:11:02.896] iteration 18005: loss: 0.042900, loss_s1: 0.025861, loss_fp: 0.003587, loss_freq: 0.014165
[15:11:03.522] iteration 18006: loss: 0.076229, loss_s1: 0.058049, loss_fp: 0.001989, loss_freq: 0.046354
[15:11:04.154] iteration 18007: loss: 0.074247, loss_s1: 0.064007, loss_fp: 0.004658, loss_freq: 0.034171
[15:11:04.785] iteration 18008: loss: 0.054733, loss_s1: 0.045988, loss_fp: 0.004761, loss_freq: 0.022626
[15:11:05.411] iteration 18009: loss: 0.069329, loss_s1: 0.064316, loss_fp: 0.002112, loss_freq: 0.030120
[15:11:06.038] iteration 18010: loss: 0.075169, loss_s1: 0.024457, loss_fp: 0.000976, loss_freq: 0.023222
[15:11:06.664] iteration 18011: loss: 0.074905, loss_s1: 0.076370, loss_fp: 0.002387, loss_freq: 0.027681
[15:11:07.297] iteration 18012: loss: 0.083828, loss_s1: 0.054771, loss_fp: 0.009023, loss_freq: 0.023207
[15:11:07.931] iteration 18013: loss: 0.040124, loss_s1: 0.026898, loss_fp: 0.000565, loss_freq: 0.006977
[15:11:08.547] iteration 18014: loss: 0.044928, loss_s1: 0.019701, loss_fp: 0.001264, loss_freq: 0.028869
[15:11:09.176] iteration 18015: loss: 0.065847, loss_s1: 0.014741, loss_fp: 0.010408, loss_freq: 0.034899
[15:11:09.832] iteration 18016: loss: 0.064980, loss_s1: 0.053114, loss_fp: 0.003014, loss_freq: 0.029050
[15:11:10.466] iteration 18017: loss: 0.116180, loss_s1: 0.155802, loss_fp: 0.004742, loss_freq: 0.024313
[15:11:11.097] iteration 18018: loss: 0.042045, loss_s1: 0.020098, loss_fp: 0.001080, loss_freq: 0.022227
[15:11:12.347] iteration 18019: loss: 0.046714, loss_s1: 0.034180, loss_fp: 0.008569, loss_freq: 0.007776
[15:11:13.139] iteration 18020: loss: 0.069165, loss_s1: 0.058103, loss_fp: 0.001576, loss_freq: 0.023192
[15:11:13.815] iteration 18021: loss: 0.048334, loss_s1: 0.035017, loss_fp: 0.000739, loss_freq: 0.024199
[15:11:14.453] iteration 18022: loss: 0.080254, loss_s1: 0.052329, loss_fp: 0.006188, loss_freq: 0.041124
[15:11:15.087] iteration 18023: loss: 0.070920, loss_s1: 0.051210, loss_fp: 0.003994, loss_freq: 0.031746
[15:11:15.766] iteration 18024: loss: 0.055122, loss_s1: 0.044586, loss_fp: 0.001774, loss_freq: 0.005641
[15:11:16.429] iteration 18025: loss: 0.039169, loss_s1: 0.025364, loss_fp: 0.005067, loss_freq: 0.016386
[15:11:17.081] iteration 18026: loss: 0.064676, loss_s1: 0.029972, loss_fp: 0.020366, loss_freq: 0.028038
[15:11:17.727] iteration 18027: loss: 0.048687, loss_s1: 0.017858, loss_fp: 0.004643, loss_freq: 0.025920
[15:11:18.358] iteration 18028: loss: 0.049816, loss_s1: 0.016365, loss_fp: 0.000677, loss_freq: 0.009620
[15:11:18.981] iteration 18029: loss: 0.057232, loss_s1: 0.028198, loss_fp: 0.007029, loss_freq: 0.036247
[15:11:19.607] iteration 18030: loss: 0.051112, loss_s1: 0.022781, loss_fp: 0.002525, loss_freq: 0.019218
[15:11:20.243] iteration 18031: loss: 0.065773, loss_s1: 0.057881, loss_fp: 0.001838, loss_freq: 0.024414
[15:11:20.855] iteration 18032: loss: 0.044337, loss_s1: 0.023444, loss_fp: 0.000375, loss_freq: 0.030289
[15:11:21.481] iteration 18033: loss: 0.055213, loss_s1: 0.023778, loss_fp: 0.001559, loss_freq: 0.042806
[15:11:22.111] iteration 18034: loss: 0.039302, loss_s1: 0.021514, loss_fp: 0.002094, loss_freq: 0.014918
[15:11:22.739] iteration 18035: loss: 0.075482, loss_s1: 0.020545, loss_fp: 0.001979, loss_freq: 0.062773
[15:11:23.421] iteration 18036: loss: 0.081437, loss_s1: 0.076342, loss_fp: 0.001364, loss_freq: 0.014704
[15:11:24.063] iteration 18037: loss: 0.055253, loss_s1: 0.043516, loss_fp: 0.001553, loss_freq: 0.031844
[15:11:24.727] iteration 18038: loss: 0.055535, loss_s1: 0.024418, loss_fp: 0.005388, loss_freq: 0.018679
[15:11:25.370] iteration 18039: loss: 0.109559, loss_s1: 0.039701, loss_fp: 0.000779, loss_freq: 0.069462
[15:11:26.041] iteration 18040: loss: 0.056756, loss_s1: 0.034934, loss_fp: 0.006694, loss_freq: 0.035795
[15:11:26.701] iteration 18041: loss: 0.054886, loss_s1: 0.027176, loss_fp: 0.000768, loss_freq: 0.040728
[15:11:27.361] iteration 18042: loss: 0.052420, loss_s1: 0.041925, loss_fp: 0.001161, loss_freq: 0.018249
[15:11:28.029] iteration 18043: loss: 0.060163, loss_s1: 0.068747, loss_fp: 0.000890, loss_freq: 0.004893
[15:11:28.704] iteration 18044: loss: 0.093704, loss_s1: 0.097658, loss_fp: 0.004539, loss_freq: 0.033850
[15:11:29.337] iteration 18045: loss: 0.076449, loss_s1: 0.057664, loss_fp: 0.001913, loss_freq: 0.052500
[15:11:30.028] iteration 18046: loss: 0.056121, loss_s1: 0.049032, loss_fp: 0.002478, loss_freq: 0.016930
[15:11:30.686] iteration 18047: loss: 0.089263, loss_s1: 0.069072, loss_fp: 0.003043, loss_freq: 0.041781
[15:11:31.358] iteration 18048: loss: 0.043206, loss_s1: 0.023968, loss_fp: 0.000869, loss_freq: 0.021909
[15:11:32.028] iteration 18049: loss: 0.043584, loss_s1: 0.029728, loss_fp: 0.001353, loss_freq: 0.013108
[15:11:32.691] iteration 18050: loss: 0.066242, loss_s1: 0.035839, loss_fp: 0.022781, loss_freq: 0.024527
[15:11:33.338] iteration 18051: loss: 0.070639, loss_s1: 0.046025, loss_fp: 0.006152, loss_freq: 0.053413
[15:11:34.041] iteration 18052: loss: 0.097894, loss_s1: 0.072930, loss_fp: 0.004288, loss_freq: 0.066814
[15:11:34.712] iteration 18053: loss: 0.067911, loss_s1: 0.047071, loss_fp: 0.002938, loss_freq: 0.030871
[15:11:35.380] iteration 18054: loss: 0.065163, loss_s1: 0.042496, loss_fp: 0.002175, loss_freq: 0.040614
[15:11:36.048] iteration 18055: loss: 0.059570, loss_s1: 0.024195, loss_fp: 0.008845, loss_freq: 0.028781
[15:11:36.734] iteration 18056: loss: 0.108503, loss_s1: 0.075065, loss_fp: 0.021997, loss_freq: 0.080763
[15:11:37.392] iteration 18057: loss: 0.093417, loss_s1: 0.079234, loss_fp: 0.002731, loss_freq: 0.049176
[15:11:38.045] iteration 18058: loss: 0.055680, loss_s1: 0.022294, loss_fp: 0.009083, loss_freq: 0.021462
[15:11:38.697] iteration 18059: loss: 0.044860, loss_s1: 0.032410, loss_fp: 0.006259, loss_freq: 0.011533
[15:11:39.314] iteration 18060: loss: 0.056418, loss_s1: 0.043759, loss_fp: 0.002111, loss_freq: 0.030449
[15:11:39.939] iteration 18061: loss: 0.037733, loss_s1: 0.018889, loss_fp: 0.002222, loss_freq: 0.007394
[15:11:40.611] iteration 18062: loss: 0.072085, loss_s1: 0.063748, loss_fp: 0.011857, loss_freq: 0.018146
[15:11:41.266] iteration 18063: loss: 0.057672, loss_s1: 0.025060, loss_fp: 0.004529, loss_freq: 0.009919
[15:11:41.923] iteration 18064: loss: 0.075705, loss_s1: 0.078933, loss_fp: 0.002633, loss_freq: 0.031739
[15:11:42.579] iteration 18065: loss: 0.082231, loss_s1: 0.040865, loss_fp: 0.001726, loss_freq: 0.065213
[15:11:43.235] iteration 18066: loss: 0.044010, loss_s1: 0.020529, loss_fp: 0.002892, loss_freq: 0.013970
[15:11:43.859] iteration 18067: loss: 0.068508, loss_s1: 0.065147, loss_fp: 0.005853, loss_freq: 0.023106
[15:11:44.478] iteration 18068: loss: 0.056994, loss_s1: 0.054589, loss_fp: 0.002714, loss_freq: 0.015094
[15:11:45.100] iteration 18069: loss: 0.089689, loss_s1: 0.101184, loss_fp: 0.000668, loss_freq: 0.024804
[15:11:45.729] iteration 18070: loss: 0.044734, loss_s1: 0.010585, loss_fp: 0.001031, loss_freq: 0.024431
[15:11:46.413] iteration 18071: loss: 0.042794, loss_s1: 0.011905, loss_fp: 0.003545, loss_freq: 0.026162
[15:11:47.079] iteration 18072: loss: 0.033183, loss_s1: 0.018349, loss_fp: 0.001709, loss_freq: 0.005160
[15:11:47.746] iteration 18073: loss: 0.038732, loss_s1: 0.030284, loss_fp: 0.000809, loss_freq: 0.009486
[15:11:48.419] iteration 18074: loss: 0.048761, loss_s1: 0.026249, loss_fp: 0.001428, loss_freq: 0.006709
[15:11:49.086] iteration 18075: loss: 0.053503, loss_s1: 0.054445, loss_fp: 0.006285, loss_freq: 0.011404
[15:11:49.752] iteration 18076: loss: 0.045363, loss_s1: 0.029481, loss_fp: 0.001065, loss_freq: 0.008605
[15:11:50.419] iteration 18077: loss: 0.078970, loss_s1: 0.040599, loss_fp: 0.001431, loss_freq: 0.061481
[15:11:51.078] iteration 18078: loss: 0.056543, loss_s1: 0.050173, loss_fp: 0.001811, loss_freq: 0.020271
[15:11:51.702] iteration 18079: loss: 0.058644, loss_s1: 0.028350, loss_fp: 0.017851, loss_freq: 0.011356
[15:11:52.338] iteration 18080: loss: 0.045383, loss_s1: 0.032579, loss_fp: 0.001983, loss_freq: 0.011607
[15:11:52.971] iteration 18081: loss: 0.069932, loss_s1: 0.046791, loss_fp: 0.002531, loss_freq: 0.043681
[15:11:53.601] iteration 18082: loss: 0.045714, loss_s1: 0.014075, loss_fp: 0.000874, loss_freq: 0.014452
[15:11:54.233] iteration 18083: loss: 0.082912, loss_s1: 0.070672, loss_fp: 0.007142, loss_freq: 0.021348
[15:11:54.874] iteration 18084: loss: 0.047654, loss_s1: 0.029317, loss_fp: 0.000640, loss_freq: 0.031670
[15:11:55.549] iteration 18085: loss: 0.112443, loss_s1: 0.092018, loss_fp: 0.008156, loss_freq: 0.062444
[15:11:56.211] iteration 18086: loss: 0.037985, loss_s1: 0.026056, loss_fp: 0.002005, loss_freq: 0.010139
[15:11:56.870] iteration 18087: loss: 0.072797, loss_s1: 0.076701, loss_fp: 0.003561, loss_freq: 0.023826
[15:11:57.533] iteration 18088: loss: 0.052989, loss_s1: 0.042254, loss_fp: 0.005767, loss_freq: 0.006753
[15:11:58.200] iteration 18089: loss: 0.070515, loss_s1: 0.080781, loss_fp: 0.002021, loss_freq: 0.015343
[15:11:58.870] iteration 18090: loss: 0.063466, loss_s1: 0.044029, loss_fp: 0.005499, loss_freq: 0.019515
[15:11:59.543] iteration 18091: loss: 0.069621, loss_s1: 0.024095, loss_fp: 0.004502, loss_freq: 0.073193
[15:12:00.211] iteration 18092: loss: 0.066612, loss_s1: 0.043495, loss_fp: 0.007047, loss_freq: 0.028794
[15:12:00.870] iteration 18093: loss: 0.102778, loss_s1: 0.097226, loss_fp: 0.002608, loss_freq: 0.069588
[15:12:01.506] iteration 18094: loss: 0.050679, loss_s1: 0.019482, loss_fp: 0.001134, loss_freq: 0.036336
[15:12:02.135] iteration 18095: loss: 0.078519, loss_s1: 0.077831, loss_fp: 0.002302, loss_freq: 0.041689
[15:12:02.766] iteration 18096: loss: 0.050700, loss_s1: 0.036622, loss_fp: 0.002077, loss_freq: 0.018609
[15:12:03.403] iteration 18097: loss: 0.085558, loss_s1: 0.074503, loss_fp: 0.005055, loss_freq: 0.033942
[15:12:04.042] iteration 18098: loss: 0.095758, loss_s1: 0.055694, loss_fp: 0.013156, loss_freq: 0.037777
[15:12:04.679] iteration 18099: loss: 0.065331, loss_s1: 0.047461, loss_fp: 0.001305, loss_freq: 0.020617
[15:12:05.307] iteration 18100: loss: 0.066155, loss_s1: 0.075228, loss_fp: 0.001443, loss_freq: 0.018211
[15:12:05.948] iteration 18101: loss: 0.049371, loss_s1: 0.034015, loss_fp: 0.001881, loss_freq: 0.018826
[15:12:06.579] iteration 18102: loss: 0.043606, loss_s1: 0.040775, loss_fp: 0.001729, loss_freq: 0.009855
[15:12:07.209] iteration 18103: loss: 0.079565, loss_s1: 0.074637, loss_fp: 0.016236, loss_freq: 0.025832
[15:12:07.839] iteration 18104: loss: 0.059962, loss_s1: 0.034869, loss_fp: 0.001992, loss_freq: 0.046275
[15:12:08.462] iteration 18105: loss: 0.038804, loss_s1: 0.025633, loss_fp: 0.001234, loss_freq: 0.012546
[15:12:09.091] iteration 18106: loss: 0.068398, loss_s1: 0.013492, loss_fp: 0.011271, loss_freq: 0.038288
[15:12:09.723] iteration 18107: loss: 0.032941, loss_s1: 0.021880, loss_fp: 0.001458, loss_freq: 0.006147
[15:12:10.355] iteration 18108: loss: 0.038954, loss_s1: 0.020364, loss_fp: 0.003377, loss_freq: 0.013624
[15:12:10.990] iteration 18109: loss: 0.057740, loss_s1: 0.040645, loss_fp: 0.000629, loss_freq: 0.026458
[15:12:11.619] iteration 18110: loss: 0.054687, loss_s1: 0.044474, loss_fp: 0.003990, loss_freq: 0.023119
[15:12:12.256] iteration 18111: loss: 0.056898, loss_s1: 0.041434, loss_fp: 0.006197, loss_freq: 0.014498
[15:12:12.884] iteration 18112: loss: 0.064546, loss_s1: 0.039699, loss_fp: 0.003512, loss_freq: 0.010953
[15:12:13.518] iteration 18113: loss: 0.040498, loss_s1: 0.019561, loss_fp: 0.000899, loss_freq: 0.020521
[15:12:14.154] iteration 18114: loss: 0.034524, loss_s1: 0.007778, loss_fp: 0.000386, loss_freq: 0.011614
[15:12:14.788] iteration 18115: loss: 0.091545, loss_s1: 0.045479, loss_fp: 0.002955, loss_freq: 0.064486
[15:12:15.433] iteration 18116: loss: 0.047921, loss_s1: 0.035453, loss_fp: 0.001265, loss_freq: 0.009597
[15:12:16.091] iteration 18117: loss: 0.085673, loss_s1: 0.041438, loss_fp: 0.010623, loss_freq: 0.059495
[15:12:16.756] iteration 18118: loss: 0.101162, loss_s1: 0.030548, loss_fp: 0.001743, loss_freq: 0.038292
[15:12:17.419] iteration 18119: loss: 0.040175, loss_s1: 0.028254, loss_fp: 0.002058, loss_freq: 0.006084
[15:12:18.086] iteration 18120: loss: 0.062588, loss_s1: 0.031265, loss_fp: 0.001189, loss_freq: 0.049634
[15:12:18.714] iteration 18121: loss: 0.052905, loss_s1: 0.040069, loss_fp: 0.004679, loss_freq: 0.026447
[15:12:19.372] iteration 18122: loss: 0.074924, loss_s1: 0.059075, loss_fp: 0.003295, loss_freq: 0.044883
[15:12:20.034] iteration 18123: loss: 0.069725, loss_s1: 0.048666, loss_fp: 0.007729, loss_freq: 0.011379
[15:12:20.690] iteration 18124: loss: 0.054570, loss_s1: 0.041422, loss_fp: 0.000541, loss_freq: 0.029860
[15:12:21.362] iteration 18125: loss: 0.104774, loss_s1: 0.101009, loss_fp: 0.015870, loss_freq: 0.047823
[15:12:21.993] iteration 18126: loss: 0.059435, loss_s1: 0.028094, loss_fp: 0.013416, loss_freq: 0.031595
[15:12:22.624] iteration 18127: loss: 0.082845, loss_s1: 0.083017, loss_fp: 0.001172, loss_freq: 0.038098
[15:12:23.251] iteration 18128: loss: 0.060692, loss_s1: 0.056256, loss_fp: 0.001585, loss_freq: 0.029371
[15:12:23.883] iteration 18129: loss: 0.054230, loss_s1: 0.047259, loss_fp: 0.000575, loss_freq: 0.011870
[15:12:24.516] iteration 18130: loss: 0.053187, loss_s1: 0.051543, loss_fp: 0.000830, loss_freq: 0.025091
[15:12:25.147] iteration 18131: loss: 0.063277, loss_s1: 0.049004, loss_fp: 0.000558, loss_freq: 0.011214
[15:12:25.799] iteration 18132: loss: 0.065760, loss_s1: 0.057326, loss_fp: 0.009532, loss_freq: 0.017977
[15:12:26.427] iteration 18133: loss: 0.069344, loss_s1: 0.060533, loss_fp: 0.000886, loss_freq: 0.011683
[15:12:27.065] iteration 18134: loss: 0.061235, loss_s1: 0.055073, loss_fp: 0.001042, loss_freq: 0.023515
[15:12:27.696] iteration 18135: loss: 0.062547, loss_s1: 0.021074, loss_fp: 0.001515, loss_freq: 0.054043
[15:12:28.324] iteration 18136: loss: 0.057965, loss_s1: 0.043256, loss_fp: 0.002126, loss_freq: 0.027415
[15:12:28.949] iteration 18137: loss: 0.044965, loss_s1: 0.035253, loss_fp: 0.003157, loss_freq: 0.021375
[15:12:29.579] iteration 18138: loss: 0.051453, loss_s1: 0.034825, loss_fp: 0.001796, loss_freq: 0.027804
[15:12:30.210] iteration 18139: loss: 0.062403, loss_s1: 0.044962, loss_fp: 0.001518, loss_freq: 0.037371
[15:12:30.883] iteration 18140: loss: 0.082237, loss_s1: 0.059887, loss_fp: 0.001047, loss_freq: 0.041456
[15:12:31.504] iteration 18141: loss: 0.045641, loss_s1: 0.016984, loss_fp: 0.005345, loss_freq: 0.011121
[15:12:32.133] iteration 18142: loss: 0.056413, loss_s1: 0.034392, loss_fp: 0.011180, loss_freq: 0.020678
[15:12:32.774] iteration 18143: loss: 0.055988, loss_s1: 0.031712, loss_fp: 0.013724, loss_freq: 0.033446
[15:12:33.394] iteration 18144: loss: 0.098034, loss_s1: 0.076835, loss_fp: 0.001614, loss_freq: 0.020510
[15:12:34.012] iteration 18145: loss: 0.042590, loss_s1: 0.017004, loss_fp: 0.003038, loss_freq: 0.029940
[15:12:34.632] iteration 18146: loss: 0.049848, loss_s1: 0.028022, loss_fp: 0.003634, loss_freq: 0.021392
[15:12:35.263] iteration 18147: loss: 0.071766, loss_s1: 0.069593, loss_fp: 0.006724, loss_freq: 0.031982
[15:12:35.890] iteration 18148: loss: 0.052719, loss_s1: 0.023050, loss_fp: 0.003756, loss_freq: 0.011189
[15:12:36.516] iteration 18149: loss: 0.079269, loss_s1: 0.036557, loss_fp: 0.004014, loss_freq: 0.019765
[15:12:37.145] iteration 18150: loss: 0.068546, loss_s1: 0.031273, loss_fp: 0.006606, loss_freq: 0.055078
[15:12:37.811] iteration 18151: loss: 0.064225, loss_s1: 0.016931, loss_fp: 0.008574, loss_freq: 0.033725
[15:12:38.445] iteration 18152: loss: 0.075458, loss_s1: 0.029961, loss_fp: 0.006014, loss_freq: 0.047434
[15:12:39.094] iteration 18153: loss: 0.069745, loss_s1: 0.037401, loss_fp: 0.005976, loss_freq: 0.042844
[15:12:39.747] iteration 18154: loss: 0.072365, loss_s1: 0.038398, loss_fp: 0.006257, loss_freq: 0.044807
[15:12:40.435] iteration 18155: loss: 0.061794, loss_s1: 0.044369, loss_fp: 0.002511, loss_freq: 0.035011
[15:12:41.090] iteration 18156: loss: 0.035145, loss_s1: 0.015631, loss_fp: 0.001263, loss_freq: 0.020159
[15:12:41.729] iteration 18157: loss: 0.066730, loss_s1: 0.042455, loss_fp: 0.001857, loss_freq: 0.042716
[15:12:42.417] iteration 18158: loss: 0.061790, loss_s1: 0.063362, loss_fp: 0.003943, loss_freq: 0.017473
[15:12:43.061] iteration 18159: loss: 0.062387, loss_s1: 0.053328, loss_fp: 0.003344, loss_freq: 0.033369
[15:12:43.693] iteration 18160: loss: 0.082326, loss_s1: 0.037328, loss_fp: 0.004365, loss_freq: 0.062395
[15:12:44.343] iteration 18161: loss: 0.066749, loss_s1: 0.053953, loss_fp: 0.001071, loss_freq: 0.041816
[15:12:45.369] iteration 18162: loss: 0.058637, loss_s1: 0.044753, loss_fp: 0.003177, loss_freq: 0.025472
[15:12:46.057] iteration 18163: loss: 0.052755, loss_s1: 0.049797, loss_fp: 0.001713, loss_freq: 0.011828
[15:12:46.720] iteration 18164: loss: 0.051362, loss_s1: 0.047637, loss_fp: 0.002211, loss_freq: 0.016057
[15:12:47.410] iteration 18165: loss: 0.064936, loss_s1: 0.048307, loss_fp: 0.001346, loss_freq: 0.017529
[15:12:48.099] iteration 18166: loss: 0.078676, loss_s1: 0.060558, loss_fp: 0.001797, loss_freq: 0.050433
[15:12:48.771] iteration 18167: loss: 0.039935, loss_s1: 0.021711, loss_fp: 0.004131, loss_freq: 0.008217
[15:12:49.475] iteration 18168: loss: 0.042065, loss_s1: 0.033313, loss_fp: 0.005010, loss_freq: 0.018659
[15:12:50.143] iteration 18169: loss: 0.060417, loss_s1: 0.025114, loss_fp: 0.003079, loss_freq: 0.035662
[15:12:50.820] iteration 18170: loss: 0.078243, loss_s1: 0.079196, loss_fp: 0.008123, loss_freq: 0.026622
[15:12:51.481] iteration 18171: loss: 0.046592, loss_s1: 0.017066, loss_fp: 0.002185, loss_freq: 0.012100
[15:12:52.162] iteration 18172: loss: 0.080214, loss_s1: 0.032678, loss_fp: 0.001439, loss_freq: 0.052024
[15:12:52.841] iteration 18173: loss: 0.061464, loss_s1: 0.017898, loss_fp: 0.003548, loss_freq: 0.038817
[15:12:53.465] iteration 18174: loss: 0.062270, loss_s1: 0.040917, loss_fp: 0.003743, loss_freq: 0.016478
[15:12:54.092] iteration 18175: loss: 0.035144, loss_s1: 0.026480, loss_fp: 0.005836, loss_freq: 0.007645
[15:12:54.778] iteration 18176: loss: 0.071293, loss_s1: 0.076691, loss_fp: 0.000672, loss_freq: 0.022572
[15:12:55.407] iteration 18177: loss: 0.055821, loss_s1: 0.043196, loss_fp: 0.006699, loss_freq: 0.024007
[15:12:56.035] iteration 18178: loss: 0.066286, loss_s1: 0.036038, loss_fp: 0.005639, loss_freq: 0.025468
[15:12:56.662] iteration 18179: loss: 0.063893, loss_s1: 0.056531, loss_fp: 0.002800, loss_freq: 0.020521
[15:12:57.301] iteration 18180: loss: 0.043376, loss_s1: 0.024113, loss_fp: 0.001424, loss_freq: 0.030457
[15:12:57.989] iteration 18181: loss: 0.047219, loss_s1: 0.042093, loss_fp: 0.002974, loss_freq: 0.013322
[15:12:58.621] iteration 18182: loss: 0.068415, loss_s1: 0.027992, loss_fp: 0.002937, loss_freq: 0.042512
[15:12:59.237] iteration 18183: loss: 0.060680, loss_s1: 0.033626, loss_fp: 0.001640, loss_freq: 0.018101
[15:12:59.885] iteration 18184: loss: 0.056429, loss_s1: 0.029029, loss_fp: 0.002713, loss_freq: 0.022400
[15:13:00.512] iteration 18185: loss: 0.037534, loss_s1: 0.014925, loss_fp: 0.000588, loss_freq: 0.012477
[15:13:01.159] iteration 18186: loss: 0.057444, loss_s1: 0.013840, loss_fp: 0.006500, loss_freq: 0.039516
[15:13:01.791] iteration 18187: loss: 0.047780, loss_s1: 0.016777, loss_fp: 0.011374, loss_freq: 0.025178
[15:13:02.413] iteration 18188: loss: 0.105290, loss_s1: 0.083936, loss_fp: 0.006378, loss_freq: 0.059186
[15:13:03.049] iteration 18189: loss: 0.039084, loss_s1: 0.016073, loss_fp: 0.000670, loss_freq: 0.008571
[15:13:03.678] iteration 18190: loss: 0.051264, loss_s1: 0.026603, loss_fp: 0.005071, loss_freq: 0.019721
[15:13:04.375] iteration 18191: loss: 0.065018, loss_s1: 0.017819, loss_fp: 0.003457, loss_freq: 0.017814
[15:13:05.045] iteration 18192: loss: 0.045926, loss_s1: 0.019806, loss_fp: 0.001722, loss_freq: 0.027828
[15:13:05.696] iteration 18193: loss: 0.081512, loss_s1: 0.049582, loss_fp: 0.003635, loss_freq: 0.034791
[15:13:06.359] iteration 18194: loss: 0.089853, loss_s1: 0.088957, loss_fp: 0.009337, loss_freq: 0.048049
[15:13:07.012] iteration 18195: loss: 0.092373, loss_s1: 0.089605, loss_fp: 0.005030, loss_freq: 0.049732
[15:13:07.671] iteration 18196: loss: 0.077858, loss_s1: 0.075506, loss_fp: 0.002890, loss_freq: 0.016048
[15:13:08.300] iteration 18197: loss: 0.113374, loss_s1: 0.128897, loss_fp: 0.006988, loss_freq: 0.041101
[15:13:08.989] iteration 18198: loss: 0.077210, loss_s1: 0.067222, loss_fp: 0.001130, loss_freq: 0.016781
[15:13:09.643] iteration 18199: loss: 0.064511, loss_s1: 0.037324, loss_fp: 0.012322, loss_freq: 0.036062
[15:13:10.300] iteration 18200: loss: 0.121974, loss_s1: 0.069168, loss_fp: 0.006729, loss_freq: 0.107244
[15:13:13.804] iteration 18200 : mean_dice : 0.790134
[15:13:14.500] iteration 18201: loss: 0.042344, loss_s1: 0.029976, loss_fp: 0.002303, loss_freq: 0.015429
[15:13:15.158] iteration 18202: loss: 0.085458, loss_s1: 0.035104, loss_fp: 0.004617, loss_freq: 0.035198
[15:13:15.831] iteration 18203: loss: 0.039412, loss_s1: 0.024102, loss_fp: 0.001275, loss_freq: 0.022796
[15:13:16.480] iteration 18204: loss: 0.057840, loss_s1: 0.041496, loss_fp: 0.007236, loss_freq: 0.008611
[15:13:17.129] iteration 18205: loss: 0.060445, loss_s1: 0.049091, loss_fp: 0.002284, loss_freq: 0.029249
[15:13:18.008] iteration 18206: loss: 0.070417, loss_s1: 0.036764, loss_fp: 0.005575, loss_freq: 0.032216
[15:13:18.681] iteration 18207: loss: 0.046021, loss_s1: 0.018797, loss_fp: 0.001195, loss_freq: 0.030054
[15:13:19.479] iteration 18208: loss: 0.041123, loss_s1: 0.018741, loss_fp: 0.001740, loss_freq: 0.015544
[15:13:20.144] iteration 18209: loss: 0.059050, loss_s1: 0.033236, loss_fp: 0.005512, loss_freq: 0.020627
[15:13:20.780] iteration 18210: loss: 0.059385, loss_s1: 0.053715, loss_fp: 0.002398, loss_freq: 0.023830
[15:13:21.475] iteration 18211: loss: 0.041617, loss_s1: 0.016381, loss_fp: 0.000439, loss_freq: 0.019030
[15:13:22.154] iteration 18212: loss: 0.031502, loss_s1: 0.007992, loss_fp: 0.004094, loss_freq: 0.018282
[15:13:22.981] iteration 18213: loss: 0.100334, loss_s1: 0.044797, loss_fp: 0.000699, loss_freq: 0.041573
[15:13:23.649] iteration 18214: loss: 0.038126, loss_s1: 0.017238, loss_fp: 0.000839, loss_freq: 0.004372
[15:13:24.378] iteration 18215: loss: 0.030841, loss_s1: 0.014411, loss_fp: 0.001268, loss_freq: 0.011286
[15:13:25.061] iteration 18216: loss: 0.043626, loss_s1: 0.030244, loss_fp: 0.002103, loss_freq: 0.024032
[15:13:25.808] iteration 18217: loss: 0.070597, loss_s1: 0.046814, loss_fp: 0.005339, loss_freq: 0.009244
[15:13:26.497] iteration 18218: loss: 0.050645, loss_s1: 0.051570, loss_fp: 0.006127, loss_freq: 0.009665
[15:13:27.174] iteration 18219: loss: 0.057294, loss_s1: 0.036811, loss_fp: 0.004448, loss_freq: 0.034254
[15:13:27.844] iteration 18220: loss: 0.067664, loss_s1: 0.031067, loss_fp: 0.000931, loss_freq: 0.067377
[15:13:28.503] iteration 18221: loss: 0.052229, loss_s1: 0.021182, loss_fp: 0.003452, loss_freq: 0.037637
[15:13:29.127] iteration 18222: loss: 0.050063, loss_s1: 0.030823, loss_fp: 0.003986, loss_freq: 0.017625
[15:13:29.760] iteration 18223: loss: 0.066735, loss_s1: 0.068896, loss_fp: 0.000318, loss_freq: 0.021777
[15:13:30.390] iteration 18224: loss: 0.105580, loss_s1: 0.070291, loss_fp: 0.003747, loss_freq: 0.081079
[15:13:31.020] iteration 18225: loss: 0.060323, loss_s1: 0.019174, loss_fp: 0.001705, loss_freq: 0.016956
[15:13:31.651] iteration 18226: loss: 0.063981, loss_s1: 0.042348, loss_fp: 0.005511, loss_freq: 0.015280
[15:13:32.283] iteration 18227: loss: 0.049268, loss_s1: 0.021235, loss_fp: 0.004115, loss_freq: 0.011084
[15:13:32.915] iteration 18228: loss: 0.134521, loss_s1: 0.127209, loss_fp: 0.007972, loss_freq: 0.059593
[15:13:33.546] iteration 18229: loss: 0.065782, loss_s1: 0.067834, loss_fp: 0.008389, loss_freq: 0.023290
[15:13:34.174] iteration 18230: loss: 0.066699, loss_s1: 0.062794, loss_fp: 0.004793, loss_freq: 0.015945
[15:13:34.802] iteration 18231: loss: 0.141074, loss_s1: 0.029129, loss_fp: 0.031172, loss_freq: 0.027364
[15:13:35.490] iteration 18232: loss: 0.053373, loss_s1: 0.035527, loss_fp: 0.000429, loss_freq: 0.017923
[15:13:36.219] iteration 18233: loss: 0.074636, loss_s1: 0.040082, loss_fp: 0.033259, loss_freq: 0.036401
[15:13:36.872] iteration 18234: loss: 0.044690, loss_s1: 0.028159, loss_fp: 0.003487, loss_freq: 0.022085
[15:13:37.557] iteration 18235: loss: 0.096524, loss_s1: 0.045118, loss_fp: 0.026334, loss_freq: 0.066339
[15:13:38.216] iteration 18236: loss: 0.081098, loss_s1: 0.040476, loss_fp: 0.003251, loss_freq: 0.048992
[15:13:38.878] iteration 18237: loss: 0.049852, loss_s1: 0.031435, loss_fp: 0.001565, loss_freq: 0.021345
[15:13:39.538] iteration 18238: loss: 0.062487, loss_s1: 0.047698, loss_fp: 0.002991, loss_freq: 0.045824
[15:13:40.191] iteration 18239: loss: 0.068297, loss_s1: 0.017994, loss_fp: 0.006370, loss_freq: 0.012771
[15:13:40.827] iteration 18240: loss: 0.086853, loss_s1: 0.083852, loss_fp: 0.010970, loss_freq: 0.040423
[15:13:41.471] iteration 18241: loss: 0.109621, loss_s1: 0.083744, loss_fp: 0.005685, loss_freq: 0.025222
[15:13:42.107] iteration 18242: loss: 0.080928, loss_s1: 0.073152, loss_fp: 0.006425, loss_freq: 0.016722
[15:13:42.736] iteration 18243: loss: 0.068361, loss_s1: 0.051860, loss_fp: 0.001998, loss_freq: 0.040975
[15:13:43.375] iteration 18244: loss: 0.068794, loss_s1: 0.050465, loss_fp: 0.002031, loss_freq: 0.025922
[15:13:44.008] iteration 18245: loss: 0.029037, loss_s1: 0.015923, loss_fp: 0.001524, loss_freq: 0.007479
[15:13:44.646] iteration 18246: loss: 0.065146, loss_s1: 0.046201, loss_fp: 0.002521, loss_freq: 0.034585
[15:13:45.314] iteration 18247: loss: 0.049927, loss_s1: 0.029926, loss_fp: 0.001270, loss_freq: 0.033458
[15:13:45.949] iteration 18248: loss: 0.043413, loss_s1: 0.025720, loss_fp: 0.000916, loss_freq: 0.002544
[15:13:46.587] iteration 18249: loss: 0.071161, loss_s1: 0.026988, loss_fp: 0.000665, loss_freq: 0.023259
[15:13:47.210] iteration 18250: loss: 0.038004, loss_s1: 0.027390, loss_fp: 0.010481, loss_freq: 0.004335
[15:13:47.838] iteration 18251: loss: 0.050070, loss_s1: 0.045734, loss_fp: 0.004947, loss_freq: 0.012276
[15:13:48.517] iteration 18252: loss: 0.055197, loss_s1: 0.034283, loss_fp: 0.000839, loss_freq: 0.019163
[15:13:49.193] iteration 18253: loss: 0.067406, loss_s1: 0.049086, loss_fp: 0.002946, loss_freq: 0.043303
[15:13:49.855] iteration 18254: loss: 0.079439, loss_s1: 0.072334, loss_fp: 0.002559, loss_freq: 0.022393
[15:13:50.514] iteration 18255: loss: 0.043208, loss_s1: 0.023296, loss_fp: 0.006641, loss_freq: 0.006906
[15:13:51.159] iteration 18256: loss: 0.037558, loss_s1: 0.013997, loss_fp: 0.002813, loss_freq: 0.011500
[15:13:51.827] iteration 18257: loss: 0.036249, loss_s1: 0.012477, loss_fp: 0.003210, loss_freq: 0.013426
[15:13:52.506] iteration 18258: loss: 0.099864, loss_s1: 0.070944, loss_fp: 0.008292, loss_freq: 0.069923
[15:13:53.169] iteration 18259: loss: 0.050559, loss_s1: 0.019013, loss_fp: 0.003240, loss_freq: 0.023690
[15:13:53.795] iteration 18260: loss: 0.051997, loss_s1: 0.032207, loss_fp: 0.004063, loss_freq: 0.012616
[15:13:54.420] iteration 18261: loss: 0.047831, loss_s1: 0.020272, loss_fp: 0.005911, loss_freq: 0.025432
[15:13:55.049] iteration 18262: loss: 0.050935, loss_s1: 0.020528, loss_fp: 0.008985, loss_freq: 0.018512
[15:13:55.679] iteration 18263: loss: 0.060248, loss_s1: 0.024797, loss_fp: 0.001792, loss_freq: 0.049395
[15:13:56.307] iteration 18264: loss: 0.115161, loss_s1: 0.142310, loss_fp: 0.004725, loss_freq: 0.032809
[15:13:56.949] iteration 18265: loss: 0.036781, loss_s1: 0.017311, loss_fp: 0.006305, loss_freq: 0.010513
[15:13:57.582] iteration 18266: loss: 0.056246, loss_s1: 0.045445, loss_fp: 0.002093, loss_freq: 0.018859
[15:13:58.320] iteration 18267: loss: 0.046257, loss_s1: 0.012034, loss_fp: 0.001609, loss_freq: 0.033053
[15:13:59.019] iteration 18268: loss: 0.085840, loss_s1: 0.083950, loss_fp: 0.001818, loss_freq: 0.035267
[15:13:59.702] iteration 18269: loss: 0.102277, loss_s1: 0.069539, loss_fp: 0.004883, loss_freq: 0.090626
[15:14:00.354] iteration 18270: loss: 0.054745, loss_s1: 0.018444, loss_fp: 0.001426, loss_freq: 0.027059
[15:14:01.020] iteration 18271: loss: 0.102157, loss_s1: 0.103973, loss_fp: 0.009129, loss_freq: 0.047353
[15:14:01.651] iteration 18272: loss: 0.049701, loss_s1: 0.043226, loss_fp: 0.007942, loss_freq: 0.009472
[15:14:02.339] iteration 18273: loss: 0.050749, loss_s1: 0.038237, loss_fp: 0.002252, loss_freq: 0.031912
[15:14:02.963] iteration 18274: loss: 0.051721, loss_s1: 0.020263, loss_fp: 0.005834, loss_freq: 0.013270
[15:14:03.590] iteration 18275: loss: 0.052311, loss_s1: 0.040678, loss_fp: 0.001177, loss_freq: 0.022389
[15:14:04.223] iteration 18276: loss: 0.099360, loss_s1: 0.098194, loss_fp: 0.002086, loss_freq: 0.021305
[15:14:04.853] iteration 18277: loss: 0.053573, loss_s1: 0.035852, loss_fp: 0.001352, loss_freq: 0.024545
[15:14:05.483] iteration 18278: loss: 0.055807, loss_s1: 0.031708, loss_fp: 0.004680, loss_freq: 0.028356
[15:14:06.115] iteration 18279: loss: 0.061209, loss_s1: 0.065108, loss_fp: 0.003314, loss_freq: 0.011882
[15:14:06.761] iteration 18280: loss: 0.067221, loss_s1: 0.075626, loss_fp: 0.006182, loss_freq: 0.009570
[15:14:07.394] iteration 18281: loss: 0.044920, loss_s1: 0.028526, loss_fp: 0.002517, loss_freq: 0.014070
[15:14:08.055] iteration 18282: loss: 0.060479, loss_s1: 0.048579, loss_fp: 0.006286, loss_freq: 0.020317
[15:14:08.687] iteration 18283: loss: 0.059270, loss_s1: 0.042859, loss_fp: 0.001232, loss_freq: 0.023563
[15:14:09.325] iteration 18284: loss: 0.059925, loss_s1: 0.027964, loss_fp: 0.001287, loss_freq: 0.004551
[15:14:09.955] iteration 18285: loss: 0.054913, loss_s1: 0.054803, loss_fp: 0.001949, loss_freq: 0.022966
[15:14:10.592] iteration 18286: loss: 0.067132, loss_s1: 0.048106, loss_fp: 0.003362, loss_freq: 0.024293
[15:14:11.232] iteration 18287: loss: 0.055106, loss_s1: 0.037838, loss_fp: 0.000724, loss_freq: 0.012160
[15:14:11.878] iteration 18288: loss: 0.064525, loss_s1: 0.045096, loss_fp: 0.002399, loss_freq: 0.047366
[15:14:12.512] iteration 18289: loss: 0.054713, loss_s1: 0.036011, loss_fp: 0.002319, loss_freq: 0.038031
[15:14:13.168] iteration 18290: loss: 0.079826, loss_s1: 0.058032, loss_fp: 0.001594, loss_freq: 0.043915
[15:14:13.803] iteration 18291: loss: 0.068070, loss_s1: 0.060402, loss_fp: 0.003618, loss_freq: 0.018301
[15:14:14.433] iteration 18292: loss: 0.053903, loss_s1: 0.047077, loss_fp: 0.007512, loss_freq: 0.014357
[15:14:15.064] iteration 18293: loss: 0.048952, loss_s1: 0.035140, loss_fp: 0.002001, loss_freq: 0.025458
[15:14:15.696] iteration 18294: loss: 0.048500, loss_s1: 0.029735, loss_fp: 0.002128, loss_freq: 0.011664
[15:14:16.344] iteration 18295: loss: 0.069191, loss_s1: 0.058218, loss_fp: 0.001076, loss_freq: 0.033900
[15:14:16.993] iteration 18296: loss: 0.079837, loss_s1: 0.051885, loss_fp: 0.002925, loss_freq: 0.020553
[15:14:17.637] iteration 18297: loss: 0.066064, loss_s1: 0.043938, loss_fp: 0.007543, loss_freq: 0.016943
[15:14:18.298] iteration 18298: loss: 0.073156, loss_s1: 0.035196, loss_fp: 0.009077, loss_freq: 0.029974
[15:14:18.940] iteration 18299: loss: 0.038576, loss_s1: 0.016797, loss_fp: 0.000668, loss_freq: 0.006417
[15:14:19.644] iteration 18300: loss: 0.052462, loss_s1: 0.036328, loss_fp: 0.011788, loss_freq: 0.016401
[15:14:20.360] iteration 18301: loss: 0.064572, loss_s1: 0.060848, loss_fp: 0.001577, loss_freq: 0.009593
[15:14:21.012] iteration 18302: loss: 0.069519, loss_s1: 0.053764, loss_fp: 0.005954, loss_freq: 0.030770
[15:14:21.665] iteration 18303: loss: 0.108588, loss_s1: 0.070346, loss_fp: 0.008914, loss_freq: 0.085866
[15:14:22.318] iteration 18304: loss: 0.031288, loss_s1: 0.007120, loss_fp: 0.002647, loss_freq: 0.022086
[15:14:23.251] iteration 18305: loss: 0.046863, loss_s1: 0.025867, loss_fp: 0.001187, loss_freq: 0.021766
[15:14:23.880] iteration 18306: loss: 0.083328, loss_s1: 0.077050, loss_fp: 0.007288, loss_freq: 0.040630
[15:14:24.521] iteration 18307: loss: 0.029741, loss_s1: 0.018868, loss_fp: 0.000278, loss_freq: 0.012087
[15:14:25.154] iteration 18308: loss: 0.128823, loss_s1: 0.062979, loss_fp: 0.005379, loss_freq: 0.038404
[15:14:25.856] iteration 18309: loss: 0.066740, loss_s1: 0.062208, loss_fp: 0.001769, loss_freq: 0.033677
[15:14:26.516] iteration 18310: loss: 0.068604, loss_s1: 0.037818, loss_fp: 0.001939, loss_freq: 0.005832
[15:14:27.180] iteration 18311: loss: 0.039437, loss_s1: 0.022151, loss_fp: 0.014216, loss_freq: 0.010357
[15:14:27.803] iteration 18312: loss: 0.066656, loss_s1: 0.027991, loss_fp: 0.002133, loss_freq: 0.016318
[15:14:28.440] iteration 18313: loss: 0.070901, loss_s1: 0.076870, loss_fp: 0.004389, loss_freq: 0.016111
[15:14:29.076] iteration 18314: loss: 0.034421, loss_s1: 0.003933, loss_fp: 0.000404, loss_freq: 0.008909
[15:14:29.734] iteration 18315: loss: 0.053962, loss_s1: 0.031995, loss_fp: 0.001577, loss_freq: 0.026576
[15:14:30.473] iteration 18316: loss: 0.088729, loss_s1: 0.077938, loss_fp: 0.002615, loss_freq: 0.048715
[15:14:31.137] iteration 18317: loss: 0.076919, loss_s1: 0.081544, loss_fp: 0.002613, loss_freq: 0.020923
[15:14:31.793] iteration 18318: loss: 0.057199, loss_s1: 0.035670, loss_fp: 0.001059, loss_freq: 0.009002
[15:14:32.457] iteration 18319: loss: 0.072099, loss_s1: 0.058930, loss_fp: 0.003390, loss_freq: 0.036426
[15:14:33.106] iteration 18320: loss: 0.063682, loss_s1: 0.062137, loss_fp: 0.002962, loss_freq: 0.012785
[15:14:33.739] iteration 18321: loss: 0.045658, loss_s1: 0.017886, loss_fp: 0.001174, loss_freq: 0.023971
[15:14:34.371] iteration 18322: loss: 0.043509, loss_s1: 0.025955, loss_fp: 0.004212, loss_freq: 0.016424
[15:14:35.004] iteration 18323: loss: 0.044316, loss_s1: 0.020676, loss_fp: 0.004510, loss_freq: 0.029559
[15:14:35.644] iteration 18324: loss: 0.040355, loss_s1: 0.032925, loss_fp: 0.001693, loss_freq: 0.008779
[15:14:36.279] iteration 18325: loss: 0.081128, loss_s1: 0.051426, loss_fp: 0.000896, loss_freq: 0.036592
[15:14:36.913] iteration 18326: loss: 0.049219, loss_s1: 0.035775, loss_fp: 0.001914, loss_freq: 0.028304
[15:14:37.564] iteration 18327: loss: 0.053289, loss_s1: 0.027679, loss_fp: 0.001665, loss_freq: 0.024173
[15:14:38.244] iteration 18328: loss: 0.061154, loss_s1: 0.051492, loss_fp: 0.002148, loss_freq: 0.010348
[15:14:38.880] iteration 18329: loss: 0.057165, loss_s1: 0.056517, loss_fp: 0.001103, loss_freq: 0.009068
[15:14:39.511] iteration 18330: loss: 0.110648, loss_s1: 0.110680, loss_fp: 0.012237, loss_freq: 0.031809
[15:14:40.175] iteration 18331: loss: 0.117143, loss_s1: 0.087520, loss_fp: 0.004076, loss_freq: 0.076417
[15:14:40.822] iteration 18332: loss: 0.041729, loss_s1: 0.028496, loss_fp: 0.003863, loss_freq: 0.008745
[15:14:41.498] iteration 18333: loss: 0.062274, loss_s1: 0.034465, loss_fp: 0.001625, loss_freq: 0.036813
[15:14:42.126] iteration 18334: loss: 0.063023, loss_s1: 0.053091, loss_fp: 0.001788, loss_freq: 0.023235
[15:14:42.760] iteration 18335: loss: 0.029621, loss_s1: 0.017742, loss_fp: 0.000661, loss_freq: 0.005998
[15:14:43.406] iteration 18336: loss: 0.084333, loss_s1: 0.032278, loss_fp: 0.005207, loss_freq: 0.055947
[15:14:44.037] iteration 18337: loss: 0.053943, loss_s1: 0.055878, loss_fp: 0.002751, loss_freq: 0.021111
[15:14:44.668] iteration 18338: loss: 0.099759, loss_s1: 0.068981, loss_fp: 0.010456, loss_freq: 0.081453
[15:14:45.301] iteration 18339: loss: 0.074741, loss_s1: 0.034042, loss_fp: 0.005160, loss_freq: 0.036872
[15:14:45.942] iteration 18340: loss: 0.072663, loss_s1: 0.028447, loss_fp: 0.003150, loss_freq: 0.044812
[15:14:46.561] iteration 18341: loss: 0.058721, loss_s1: 0.031405, loss_fp: 0.002315, loss_freq: 0.037169
[15:14:47.192] iteration 18342: loss: 0.036807, loss_s1: 0.022776, loss_fp: 0.002052, loss_freq: 0.013738
[15:14:47.822] iteration 18343: loss: 0.105835, loss_s1: 0.081976, loss_fp: 0.022170, loss_freq: 0.031543
[15:14:48.449] iteration 18344: loss: 0.039424, loss_s1: 0.024333, loss_fp: 0.003326, loss_freq: 0.012301
[15:14:49.103] iteration 18345: loss: 0.062581, loss_s1: 0.038363, loss_fp: 0.007594, loss_freq: 0.032053
[15:14:49.731] iteration 18346: loss: 0.043469, loss_s1: 0.041962, loss_fp: 0.002630, loss_freq: 0.014169
[15:14:50.358] iteration 18347: loss: 0.050980, loss_s1: 0.023636, loss_fp: 0.000814, loss_freq: 0.011857
[15:14:50.986] iteration 18348: loss: 0.055064, loss_s1: 0.051562, loss_fp: 0.002982, loss_freq: 0.014854
[15:14:51.615] iteration 18349: loss: 0.051748, loss_s1: 0.015635, loss_fp: 0.001594, loss_freq: 0.006667
[15:14:52.232] iteration 18350: loss: 0.084531, loss_s1: 0.085780, loss_fp: 0.004351, loss_freq: 0.040598
[15:14:52.864] iteration 18351: loss: 0.042218, loss_s1: 0.023870, loss_fp: 0.002159, loss_freq: 0.020797
[15:14:53.495] iteration 18352: loss: 0.056932, loss_s1: 0.042379, loss_fp: 0.003053, loss_freq: 0.017636
[15:14:54.226] iteration 18353: loss: 0.055800, loss_s1: 0.040141, loss_fp: 0.003150, loss_freq: 0.035080
[15:14:54.855] iteration 18354: loss: 0.065317, loss_s1: 0.051463, loss_fp: 0.003027, loss_freq: 0.026769
[15:14:55.486] iteration 18355: loss: 0.057183, loss_s1: 0.026861, loss_fp: 0.000888, loss_freq: 0.031382
[15:14:56.112] iteration 18356: loss: 0.085860, loss_s1: 0.021596, loss_fp: 0.000639, loss_freq: 0.020670
[15:14:56.768] iteration 18357: loss: 0.049872, loss_s1: 0.036267, loss_fp: 0.001416, loss_freq: 0.021649
[15:14:57.396] iteration 18358: loss: 0.068284, loss_s1: 0.053957, loss_fp: 0.003433, loss_freq: 0.040522
[15:14:58.029] iteration 18359: loss: 0.040583, loss_s1: 0.022909, loss_fp: 0.003703, loss_freq: 0.012864
[15:14:58.675] iteration 18360: loss: 0.056015, loss_s1: 0.033003, loss_fp: 0.001577, loss_freq: 0.005385
[15:14:59.332] iteration 18361: loss: 0.077241, loss_s1: 0.064399, loss_fp: 0.008337, loss_freq: 0.047917
[15:14:59.982] iteration 18362: loss: 0.057851, loss_s1: 0.061816, loss_fp: 0.000738, loss_freq: 0.009539
[15:15:00.660] iteration 18363: loss: 0.065772, loss_s1: 0.031553, loss_fp: 0.002607, loss_freq: 0.042138
[15:15:01.315] iteration 18364: loss: 0.056484, loss_s1: 0.057389, loss_fp: 0.002593, loss_freq: 0.014088
[15:15:02.023] iteration 18365: loss: 0.041746, loss_s1: 0.018665, loss_fp: 0.003167, loss_freq: 0.014509
[15:15:02.658] iteration 18366: loss: 0.046199, loss_s1: 0.017224, loss_fp: 0.003918, loss_freq: 0.023464
[15:15:03.284] iteration 18367: loss: 0.072816, loss_s1: 0.051752, loss_fp: 0.003887, loss_freq: 0.045732
[15:15:03.917] iteration 18368: loss: 0.047281, loss_s1: 0.024707, loss_fp: 0.003108, loss_freq: 0.019636
[15:15:04.552] iteration 18369: loss: 0.077161, loss_s1: 0.048469, loss_fp: 0.014612, loss_freq: 0.017335
[15:15:05.185] iteration 18370: loss: 0.051597, loss_s1: 0.041459, loss_fp: 0.006646, loss_freq: 0.013240
[15:15:05.810] iteration 18371: loss: 0.105762, loss_s1: 0.053280, loss_fp: 0.002354, loss_freq: 0.111403
[15:15:06.437] iteration 18372: loss: 0.042048, loss_s1: 0.026653, loss_fp: 0.008110, loss_freq: 0.013099
[15:15:07.114] iteration 18373: loss: 0.059426, loss_s1: 0.056048, loss_fp: 0.004321, loss_freq: 0.012997
[15:15:07.771] iteration 18374: loss: 0.098124, loss_s1: 0.055876, loss_fp: 0.000956, loss_freq: 0.021310
[15:15:08.427] iteration 18375: loss: 0.054174, loss_s1: 0.048328, loss_fp: 0.000558, loss_freq: 0.017465
[15:15:09.083] iteration 18376: loss: 0.061480, loss_s1: 0.030428, loss_fp: 0.002257, loss_freq: 0.034121
[15:15:09.736] iteration 18377: loss: 0.055794, loss_s1: 0.026485, loss_fp: 0.016292, loss_freq: 0.031027
[15:15:10.390] iteration 18378: loss: 0.053399, loss_s1: 0.035892, loss_fp: 0.002836, loss_freq: 0.015227
[15:15:11.029] iteration 18379: loss: 0.089537, loss_s1: 0.059329, loss_fp: 0.014736, loss_freq: 0.072755
[15:15:11.654] iteration 18380: loss: 0.075992, loss_s1: 0.049985, loss_fp: 0.000886, loss_freq: 0.013866
[15:15:12.282] iteration 18381: loss: 0.060348, loss_s1: 0.055742, loss_fp: 0.004551, loss_freq: 0.031102
[15:15:12.934] iteration 18382: loss: 0.067786, loss_s1: 0.044738, loss_fp: 0.001213, loss_freq: 0.024848
[15:15:13.591] iteration 18383: loss: 0.090455, loss_s1: 0.078138, loss_fp: 0.004528, loss_freq: 0.055281
[15:15:14.245] iteration 18384: loss: 0.143812, loss_s1: 0.059793, loss_fp: 0.006048, loss_freq: 0.028173
[15:15:14.883] iteration 18385: loss: 0.082561, loss_s1: 0.056897, loss_fp: 0.004714, loss_freq: 0.053668
[15:15:15.517] iteration 18386: loss: 0.063715, loss_s1: 0.064388, loss_fp: 0.001619, loss_freq: 0.015862
[15:15:16.162] iteration 18387: loss: 0.044445, loss_s1: 0.031821, loss_fp: 0.001096, loss_freq: 0.016992
[15:15:16.829] iteration 18388: loss: 0.052491, loss_s1: 0.035641, loss_fp: 0.003303, loss_freq: 0.030508
[15:15:17.453] iteration 18389: loss: 0.072656, loss_s1: 0.081307, loss_fp: 0.005824, loss_freq: 0.019920
[15:15:18.087] iteration 18390: loss: 0.064021, loss_s1: 0.041099, loss_fp: 0.002716, loss_freq: 0.045840
[15:15:18.713] iteration 18391: loss: 0.045513, loss_s1: 0.033936, loss_fp: 0.001215, loss_freq: 0.006340
[15:15:19.389] iteration 18392: loss: 0.057693, loss_s1: 0.010657, loss_fp: 0.001527, loss_freq: 0.017640
[15:15:20.019] iteration 18393: loss: 0.030240, loss_s1: 0.017353, loss_fp: 0.001470, loss_freq: 0.007059
[15:15:20.640] iteration 18394: loss: 0.049521, loss_s1: 0.052751, loss_fp: 0.002300, loss_freq: 0.011229
[15:15:21.292] iteration 18395: loss: 0.081641, loss_s1: 0.037891, loss_fp: 0.004287, loss_freq: 0.036506
[15:15:21.915] iteration 18396: loss: 0.050586, loss_s1: 0.038339, loss_fp: 0.002373, loss_freq: 0.015950
[15:15:22.550] iteration 18397: loss: 0.049779, loss_s1: 0.033833, loss_fp: 0.001197, loss_freq: 0.014490
[15:15:23.532] iteration 18398: loss: 0.069655, loss_s1: 0.027966, loss_fp: 0.001469, loss_freq: 0.011193
[15:15:24.297] iteration 18399: loss: 0.046360, loss_s1: 0.021529, loss_fp: 0.000866, loss_freq: 0.029752
[15:15:24.987] iteration 18400: loss: 0.039913, loss_s1: 0.016287, loss_fp: 0.001288, loss_freq: 0.008072
[15:15:28.806] iteration 18400 : mean_dice : 0.774086
[15:15:29.497] iteration 18401: loss: 0.105925, loss_s1: 0.092741, loss_fp: 0.002265, loss_freq: 0.077242
[15:15:30.161] iteration 18402: loss: 0.038071, loss_s1: 0.010372, loss_fp: 0.003218, loss_freq: 0.019327
[15:15:30.783] iteration 18403: loss: 0.043423, loss_s1: 0.025925, loss_fp: 0.001528, loss_freq: 0.005835
[15:15:31.412] iteration 18404: loss: 0.075405, loss_s1: 0.073190, loss_fp: 0.001560, loss_freq: 0.021679
[15:15:32.046] iteration 18405: loss: 0.037307, loss_s1: 0.019189, loss_fp: 0.001523, loss_freq: 0.016002
[15:15:32.681] iteration 18406: loss: 0.070398, loss_s1: 0.029464, loss_fp: 0.000982, loss_freq: 0.044473
[15:15:33.309] iteration 18407: loss: 0.078461, loss_s1: 0.062201, loss_fp: 0.001798, loss_freq: 0.049267
[15:15:33.935] iteration 18408: loss: 0.053403, loss_s1: 0.037911, loss_fp: 0.003232, loss_freq: 0.024915
[15:15:34.559] iteration 18409: loss: 0.064527, loss_s1: 0.055188, loss_fp: 0.002493, loss_freq: 0.021768
[15:15:35.196] iteration 18410: loss: 0.051592, loss_s1: 0.029868, loss_fp: 0.000491, loss_freq: 0.023814
[15:15:35.826] iteration 18411: loss: 0.074173, loss_s1: 0.054642, loss_fp: 0.001945, loss_freq: 0.044171
[15:15:36.452] iteration 18412: loss: 0.048871, loss_s1: 0.027526, loss_fp: 0.002962, loss_freq: 0.034969
[15:15:37.071] iteration 18413: loss: 0.066478, loss_s1: 0.053447, loss_fp: 0.001139, loss_freq: 0.034951
[15:15:37.719] iteration 18414: loss: 0.061261, loss_s1: 0.055854, loss_fp: 0.001506, loss_freq: 0.038875
[15:15:38.341] iteration 18415: loss: 0.066968, loss_s1: 0.043411, loss_fp: 0.003700, loss_freq: 0.029728
[15:15:38.970] iteration 18416: loss: 0.051469, loss_s1: 0.049727, loss_fp: 0.004289, loss_freq: 0.012940
[15:15:39.600] iteration 18417: loss: 0.037297, loss_s1: 0.019029, loss_fp: 0.001152, loss_freq: 0.010787
[15:15:40.225] iteration 18418: loss: 0.069259, loss_s1: 0.038800, loss_fp: 0.008856, loss_freq: 0.034092
[15:15:40.847] iteration 18419: loss: 0.088144, loss_s1: 0.032244, loss_fp: 0.005293, loss_freq: 0.056108
[15:15:41.474] iteration 18420: loss: 0.046881, loss_s1: 0.031784, loss_fp: 0.002653, loss_freq: 0.011845
[15:15:42.102] iteration 18421: loss: 0.050053, loss_s1: 0.032120, loss_fp: 0.007279, loss_freq: 0.016712
[15:15:42.731] iteration 18422: loss: 0.083234, loss_s1: 0.061878, loss_fp: 0.004392, loss_freq: 0.029599
[15:15:43.354] iteration 18423: loss: 0.071242, loss_s1: 0.085420, loss_fp: 0.001972, loss_freq: 0.022487
[15:15:43.978] iteration 18424: loss: 0.053051, loss_s1: 0.042437, loss_fp: 0.003007, loss_freq: 0.018158
[15:15:44.606] iteration 18425: loss: 0.062745, loss_s1: 0.033430, loss_fp: 0.001930, loss_freq: 0.048442
[15:15:45.233] iteration 18426: loss: 0.052965, loss_s1: 0.008451, loss_fp: 0.002685, loss_freq: 0.032969
[15:15:45.863] iteration 18427: loss: 0.044183, loss_s1: 0.032489, loss_fp: 0.002491, loss_freq: 0.003673
[15:15:46.498] iteration 18428: loss: 0.063297, loss_s1: 0.023510, loss_fp: 0.004114, loss_freq: 0.033769
[15:15:47.129] iteration 18429: loss: 0.037721, loss_s1: 0.019167, loss_fp: 0.001631, loss_freq: 0.012044
[15:15:47.755] iteration 18430: loss: 0.057188, loss_s1: 0.006993, loss_fp: 0.002946, loss_freq: 0.007412
[15:15:48.387] iteration 18431: loss: 0.062400, loss_s1: 0.034110, loss_fp: 0.001581, loss_freq: 0.017316
[15:15:49.024] iteration 18432: loss: 0.038939, loss_s1: 0.014550, loss_fp: 0.002223, loss_freq: 0.016809
[15:15:49.677] iteration 18433: loss: 0.060837, loss_s1: 0.041092, loss_fp: 0.006810, loss_freq: 0.022040
[15:15:50.324] iteration 18434: loss: 0.047630, loss_s1: 0.033148, loss_fp: 0.005513, loss_freq: 0.009351
[15:15:50.974] iteration 18435: loss: 0.052044, loss_s1: 0.035466, loss_fp: 0.006062, loss_freq: 0.025607
[15:15:51.616] iteration 18436: loss: 0.067388, loss_s1: 0.032192, loss_fp: 0.010557, loss_freq: 0.045294
[15:15:52.263] iteration 18437: loss: 0.059748, loss_s1: 0.045774, loss_fp: 0.001341, loss_freq: 0.011478
[15:15:52.971] iteration 18438: loss: 0.069508, loss_s1: 0.028367, loss_fp: 0.001715, loss_freq: 0.041270
[15:15:53.594] iteration 18439: loss: 0.083971, loss_s1: 0.045033, loss_fp: 0.006929, loss_freq: 0.043739
[15:15:54.229] iteration 18440: loss: 0.070273, loss_s1: 0.061819, loss_fp: 0.004683, loss_freq: 0.035242
[15:15:54.907] iteration 18441: loss: 0.075845, loss_s1: 0.033109, loss_fp: 0.005624, loss_freq: 0.036861
[15:15:55.540] iteration 18442: loss: 0.056631, loss_s1: 0.029879, loss_fp: 0.002083, loss_freq: 0.008287
[15:15:56.177] iteration 18443: loss: 0.063914, loss_s1: 0.055852, loss_fp: 0.001066, loss_freq: 0.029270
[15:15:56.862] iteration 18444: loss: 0.071424, loss_s1: 0.038084, loss_fp: 0.002128, loss_freq: 0.018064
[15:15:57.507] iteration 18445: loss: 0.077804, loss_s1: 0.054244, loss_fp: 0.003499, loss_freq: 0.060362
[15:15:58.142] iteration 18446: loss: 0.133741, loss_s1: 0.105036, loss_fp: 0.034495, loss_freq: 0.080943
[15:15:58.775] iteration 18447: loss: 0.053213, loss_s1: 0.046821, loss_fp: 0.004494, loss_freq: 0.009640
[15:15:59.791] iteration 18448: loss: 0.046643, loss_s1: 0.034760, loss_fp: 0.001935, loss_freq: 0.010429
[15:16:00.447] iteration 18449: loss: 0.060297, loss_s1: 0.057423, loss_fp: 0.002112, loss_freq: 0.017884
[15:16:01.080] iteration 18450: loss: 0.035126, loss_s1: 0.017713, loss_fp: 0.002140, loss_freq: 0.012063
[15:16:01.713] iteration 18451: loss: 0.077357, loss_s1: 0.063115, loss_fp: 0.006189, loss_freq: 0.023673
[15:16:02.355] iteration 18452: loss: 0.057797, loss_s1: 0.045589, loss_fp: 0.001865, loss_freq: 0.032868
[15:16:02.988] iteration 18453: loss: 0.080015, loss_s1: 0.027601, loss_fp: 0.004280, loss_freq: 0.010880
[15:16:03.611] iteration 18454: loss: 0.040779, loss_s1: 0.026974, loss_fp: 0.002208, loss_freq: 0.018015
[15:16:04.264] iteration 18455: loss: 0.071014, loss_s1: 0.058435, loss_fp: 0.001061, loss_freq: 0.032353
[15:16:04.921] iteration 18456: loss: 0.074718, loss_s1: 0.036181, loss_fp: 0.008588, loss_freq: 0.047411
[15:16:05.552] iteration 18457: loss: 0.059092, loss_s1: 0.035031, loss_fp: 0.001275, loss_freq: 0.007675
[15:16:06.185] iteration 18458: loss: 0.071596, loss_s1: 0.051967, loss_fp: 0.001369, loss_freq: 0.048629
[15:16:06.814] iteration 18459: loss: 0.040431, loss_s1: 0.021488, loss_fp: 0.003949, loss_freq: 0.004282
[15:16:07.510] iteration 18460: loss: 0.066319, loss_s1: 0.021102, loss_fp: 0.002316, loss_freq: 0.052820
[15:16:08.144] iteration 18461: loss: 0.057235, loss_s1: 0.015510, loss_fp: 0.002822, loss_freq: 0.017738
[15:16:08.787] iteration 18462: loss: 0.068482, loss_s1: 0.029934, loss_fp: 0.005066, loss_freq: 0.058204
[15:16:09.416] iteration 18463: loss: 0.040985, loss_s1: 0.018791, loss_fp: 0.002221, loss_freq: 0.018014
[15:16:10.049] iteration 18464: loss: 0.061585, loss_s1: 0.028149, loss_fp: 0.000648, loss_freq: 0.027623
[15:16:10.680] iteration 18465: loss: 0.067992, loss_s1: 0.023112, loss_fp: 0.001164, loss_freq: 0.011034
[15:16:11.320] iteration 18466: loss: 0.037074, loss_s1: 0.027033, loss_fp: 0.000730, loss_freq: 0.011505
[15:16:11.978] iteration 18467: loss: 0.036454, loss_s1: 0.023098, loss_fp: 0.002461, loss_freq: 0.013577
[15:16:12.598] iteration 18468: loss: 0.120206, loss_s1: 0.091732, loss_fp: 0.003339, loss_freq: 0.058291
[15:16:13.231] iteration 18469: loss: 0.056873, loss_s1: 0.041167, loss_fp: 0.003925, loss_freq: 0.024561
[15:16:13.879] iteration 18470: loss: 0.068029, loss_s1: 0.052033, loss_fp: 0.001233, loss_freq: 0.043247
[15:16:14.540] iteration 18471: loss: 0.041363, loss_s1: 0.019971, loss_fp: 0.001353, loss_freq: 0.012008
[15:16:15.172] iteration 18472: loss: 0.045105, loss_s1: 0.021525, loss_fp: 0.002783, loss_freq: 0.018086
[15:16:15.796] iteration 18473: loss: 0.064970, loss_s1: 0.026121, loss_fp: 0.004795, loss_freq: 0.038377
[15:16:16.472] iteration 18474: loss: 0.075340, loss_s1: 0.036604, loss_fp: 0.001565, loss_freq: 0.057077
[15:16:17.147] iteration 18475: loss: 0.047147, loss_s1: 0.030579, loss_fp: 0.000496, loss_freq: 0.010803
[15:16:17.819] iteration 18476: loss: 0.056154, loss_s1: 0.054263, loss_fp: 0.002468, loss_freq: 0.007331
[15:16:18.454] iteration 18477: loss: 0.047470, loss_s1: 0.017649, loss_fp: 0.001991, loss_freq: 0.023585
[15:16:19.118] iteration 18478: loss: 0.047654, loss_s1: 0.025335, loss_fp: 0.002457, loss_freq: 0.010232
[15:16:19.753] iteration 18479: loss: 0.065507, loss_s1: 0.047562, loss_fp: 0.004873, loss_freq: 0.023533
[15:16:20.382] iteration 18480: loss: 0.062077, loss_s1: 0.048947, loss_fp: 0.019477, loss_freq: 0.026472
[15:16:21.003] iteration 18481: loss: 0.089531, loss_s1: 0.079421, loss_fp: 0.006832, loss_freq: 0.022549
[15:16:21.634] iteration 18482: loss: 0.065951, loss_s1: 0.064897, loss_fp: 0.003476, loss_freq: 0.018783
[15:16:22.269] iteration 18483: loss: 0.076171, loss_s1: 0.037907, loss_fp: 0.001203, loss_freq: 0.055369
[15:16:22.928] iteration 18484: loss: 0.058202, loss_s1: 0.037764, loss_fp: 0.005471, loss_freq: 0.017143
[15:16:23.567] iteration 18485: loss: 0.052889, loss_s1: 0.037774, loss_fp: 0.007743, loss_freq: 0.020675
[15:16:24.199] iteration 18486: loss: 0.072563, loss_s1: 0.057256, loss_fp: 0.004192, loss_freq: 0.038593
[15:16:24.882] iteration 18487: loss: 0.030829, loss_s1: 0.016296, loss_fp: 0.003119, loss_freq: 0.007407
[15:16:25.514] iteration 18488: loss: 0.067288, loss_s1: 0.048770, loss_fp: 0.004011, loss_freq: 0.005387
[15:16:26.144] iteration 18489: loss: 0.069629, loss_s1: 0.071403, loss_fp: 0.009950, loss_freq: 0.025482
[15:16:26.782] iteration 18490: loss: 0.046281, loss_s1: 0.028627, loss_fp: 0.001916, loss_freq: 0.024505
[15:16:27.417] iteration 18491: loss: 0.082985, loss_s1: 0.086019, loss_fp: 0.001973, loss_freq: 0.033526
[15:16:28.062] iteration 18492: loss: 0.043431, loss_s1: 0.010262, loss_fp: 0.003305, loss_freq: 0.002666
[15:16:28.688] iteration 18493: loss: 0.053743, loss_s1: 0.039697, loss_fp: 0.001560, loss_freq: 0.018574
[15:16:29.311] iteration 18494: loss: 0.039868, loss_s1: 0.023346, loss_fp: 0.002962, loss_freq: 0.018989
[15:16:29.962] iteration 18495: loss: 0.046998, loss_s1: 0.020988, loss_fp: 0.004364, loss_freq: 0.026765
[15:16:30.614] iteration 18496: loss: 0.068769, loss_s1: 0.034162, loss_fp: 0.005755, loss_freq: 0.065264
[15:16:31.237] iteration 18497: loss: 0.046950, loss_s1: 0.027265, loss_fp: 0.005620, loss_freq: 0.020226
[15:16:31.862] iteration 18498: loss: 0.042101, loss_s1: 0.025485, loss_fp: 0.000590, loss_freq: 0.012346
[15:16:32.493] iteration 18499: loss: 0.077512, loss_s1: 0.044777, loss_fp: 0.005068, loss_freq: 0.025352
[15:16:33.127] iteration 18500: loss: 0.029689, loss_s1: 0.011702, loss_fp: 0.000930, loss_freq: 0.010399
[15:16:33.746] iteration 18501: loss: 0.042121, loss_s1: 0.024909, loss_fp: 0.004970, loss_freq: 0.015901
[15:16:34.373] iteration 18502: loss: 0.064969, loss_s1: 0.052659, loss_fp: 0.002394, loss_freq: 0.017165
[15:16:34.999] iteration 18503: loss: 0.070720, loss_s1: 0.039712, loss_fp: 0.001330, loss_freq: 0.026730
[15:16:35.664] iteration 18504: loss: 0.045072, loss_s1: 0.039612, loss_fp: 0.003155, loss_freq: 0.018815
[15:16:36.288] iteration 18505: loss: 0.043346, loss_s1: 0.027676, loss_fp: 0.001680, loss_freq: 0.014125
[15:16:36.914] iteration 18506: loss: 0.085134, loss_s1: 0.031203, loss_fp: 0.003911, loss_freq: 0.059445
[15:16:37.543] iteration 18507: loss: 0.102287, loss_s1: 0.056495, loss_fp: 0.001769, loss_freq: 0.066394
[15:16:38.173] iteration 18508: loss: 0.066339, loss_s1: 0.046428, loss_fp: 0.001815, loss_freq: 0.029408
[15:16:38.801] iteration 18509: loss: 0.060885, loss_s1: 0.052170, loss_fp: 0.001263, loss_freq: 0.015877
[15:16:39.416] iteration 18510: loss: 0.070483, loss_s1: 0.033021, loss_fp: 0.008236, loss_freq: 0.040962
[15:16:40.053] iteration 18511: loss: 0.051187, loss_s1: 0.009825, loss_fp: 0.002626, loss_freq: 0.029580
[15:16:40.714] iteration 18512: loss: 0.072458, loss_s1: 0.029511, loss_fp: 0.000720, loss_freq: 0.009832
[15:16:41.348] iteration 18513: loss: 0.068090, loss_s1: 0.067102, loss_fp: 0.001271, loss_freq: 0.027306
[15:16:41.969] iteration 18514: loss: 0.090949, loss_s1: 0.063677, loss_fp: 0.005365, loss_freq: 0.065753
[15:16:42.619] iteration 18515: loss: 0.038130, loss_s1: 0.025429, loss_fp: 0.004126, loss_freq: 0.011717
[15:16:43.245] iteration 18516: loss: 0.045643, loss_s1: 0.029963, loss_fp: 0.001049, loss_freq: 0.018042
[15:16:43.900] iteration 18517: loss: 0.047626, loss_s1: 0.016640, loss_fp: 0.005007, loss_freq: 0.017204
[15:16:44.538] iteration 18518: loss: 0.058917, loss_s1: 0.048635, loss_fp: 0.008471, loss_freq: 0.018805
[15:16:45.203] iteration 18519: loss: 0.068020, loss_s1: 0.035249, loss_fp: 0.003221, loss_freq: 0.052615
[15:16:45.842] iteration 18520: loss: 0.088440, loss_s1: 0.049422, loss_fp: 0.007296, loss_freq: 0.081796
[15:16:46.491] iteration 18521: loss: 0.108330, loss_s1: 0.074746, loss_fp: 0.005756, loss_freq: 0.048243
[15:16:47.125] iteration 18522: loss: 0.076438, loss_s1: 0.041433, loss_fp: 0.001486, loss_freq: 0.079291
[15:16:47.764] iteration 18523: loss: 0.054610, loss_s1: 0.032114, loss_fp: 0.001774, loss_freq: 0.014112
[15:16:48.420] iteration 18524: loss: 0.069340, loss_s1: 0.052864, loss_fp: 0.004997, loss_freq: 0.039569
[15:16:49.104] iteration 18525: loss: 0.053872, loss_s1: 0.019592, loss_fp: 0.002170, loss_freq: 0.023809
[15:16:49.810] iteration 18526: loss: 0.115842, loss_s1: 0.095763, loss_fp: 0.007074, loss_freq: 0.073941
[15:16:50.456] iteration 18527: loss: 0.123602, loss_s1: 0.066128, loss_fp: 0.017264, loss_freq: 0.034321
[15:16:51.090] iteration 18528: loss: 0.065723, loss_s1: 0.036514, loss_fp: 0.003749, loss_freq: 0.037738
[15:16:51.756] iteration 18529: loss: 0.062898, loss_s1: 0.052369, loss_fp: 0.005302, loss_freq: 0.021130
[15:16:52.416] iteration 18530: loss: 0.056511, loss_s1: 0.030793, loss_fp: 0.001702, loss_freq: 0.032590
[15:16:53.073] iteration 18531: loss: 0.047628, loss_s1: 0.036260, loss_fp: 0.001356, loss_freq: 0.022300
[15:16:53.730] iteration 18532: loss: 0.077178, loss_s1: 0.079017, loss_fp: 0.003373, loss_freq: 0.019666
[15:16:54.388] iteration 18533: loss: 0.070621, loss_s1: 0.036362, loss_fp: 0.009320, loss_freq: 0.048068
[15:16:55.048] iteration 18534: loss: 0.058619, loss_s1: 0.069738, loss_fp: 0.001456, loss_freq: 0.006912
[15:16:55.731] iteration 18535: loss: 0.072263, loss_s1: 0.029248, loss_fp: 0.003336, loss_freq: 0.035093
[15:16:56.396] iteration 18536: loss: 0.057013, loss_s1: 0.048016, loss_fp: 0.000954, loss_freq: 0.027181
[15:16:57.048] iteration 18537: loss: 0.068516, loss_s1: 0.073864, loss_fp: 0.004485, loss_freq: 0.025179
[15:16:57.710] iteration 18538: loss: 0.083481, loss_s1: 0.065628, loss_fp: 0.005427, loss_freq: 0.031336
[15:16:58.368] iteration 18539: loss: 0.062258, loss_s1: 0.031078, loss_fp: 0.009440, loss_freq: 0.046924
[15:16:59.041] iteration 18540: loss: 0.057577, loss_s1: 0.062248, loss_fp: 0.002402, loss_freq: 0.007749
[15:16:59.676] iteration 18541: loss: 0.071171, loss_s1: 0.055714, loss_fp: 0.000989, loss_freq: 0.011519
[15:17:00.308] iteration 18542: loss: 0.051559, loss_s1: 0.026678, loss_fp: 0.000676, loss_freq: 0.016803
[15:17:00.940] iteration 18543: loss: 0.037332, loss_s1: 0.009212, loss_fp: 0.001053, loss_freq: 0.005800
[15:17:01.574] iteration 18544: loss: 0.084720, loss_s1: 0.066714, loss_fp: 0.003549, loss_freq: 0.045608
[15:17:02.199] iteration 18545: loss: 0.053470, loss_s1: 0.018003, loss_fp: 0.003799, loss_freq: 0.019608
[15:17:02.826] iteration 18546: loss: 0.060471, loss_s1: 0.034908, loss_fp: 0.000871, loss_freq: 0.020911
[15:17:03.500] iteration 18547: loss: 0.082470, loss_s1: 0.048859, loss_fp: 0.002200, loss_freq: 0.046659
[15:17:04.151] iteration 18548: loss: 0.057516, loss_s1: 0.042810, loss_fp: 0.001309, loss_freq: 0.011695
[15:17:04.786] iteration 18549: loss: 0.092539, loss_s1: 0.054449, loss_fp: 0.005399, loss_freq: 0.019758
[15:17:05.450] iteration 18550: loss: 0.078389, loss_s1: 0.084662, loss_fp: 0.004307, loss_freq: 0.018144
[15:17:06.094] iteration 18551: loss: 0.037972, loss_s1: 0.017128, loss_fp: 0.005182, loss_freq: 0.010693
[15:17:06.725] iteration 18552: loss: 0.070222, loss_s1: 0.010810, loss_fp: 0.001391, loss_freq: 0.047558
[15:17:07.357] iteration 18553: loss: 0.042180, loss_s1: 0.022989, loss_fp: 0.001213, loss_freq: 0.021527
[15:17:07.991] iteration 18554: loss: 0.108241, loss_s1: 0.052753, loss_fp: 0.002395, loss_freq: 0.086591
[15:17:08.624] iteration 18555: loss: 0.043687, loss_s1: 0.015965, loss_fp: 0.005823, loss_freq: 0.027350
[15:17:09.251] iteration 18556: loss: 0.058798, loss_s1: 0.030129, loss_fp: 0.001915, loss_freq: 0.024129
[15:17:09.886] iteration 18557: loss: 0.086474, loss_s1: 0.053267, loss_fp: 0.001425, loss_freq: 0.079493
[15:17:10.524] iteration 18558: loss: 0.096127, loss_s1: 0.074192, loss_fp: 0.001728, loss_freq: 0.012152
[15:17:11.156] iteration 18559: loss: 0.059555, loss_s1: 0.039953, loss_fp: 0.007732, loss_freq: 0.041024
[15:17:11.812] iteration 18560: loss: 0.050978, loss_s1: 0.027588, loss_fp: 0.000493, loss_freq: 0.017622
[15:17:12.441] iteration 18561: loss: 0.087539, loss_s1: 0.053005, loss_fp: 0.001413, loss_freq: 0.052767
[15:17:13.104] iteration 18562: loss: 0.057993, loss_s1: 0.039800, loss_fp: 0.001058, loss_freq: 0.010386
[15:17:13.734] iteration 18563: loss: 0.045540, loss_s1: 0.021500, loss_fp: 0.002564, loss_freq: 0.025401
[15:17:14.373] iteration 18564: loss: 0.080692, loss_s1: 0.050568, loss_fp: 0.004252, loss_freq: 0.060358
[15:17:15.014] iteration 18565: loss: 0.077348, loss_s1: 0.083985, loss_fp: 0.009423, loss_freq: 0.017351
[15:17:15.639] iteration 18566: loss: 0.053036, loss_s1: 0.043062, loss_fp: 0.001810, loss_freq: 0.028087
[15:17:16.289] iteration 18567: loss: 0.059764, loss_s1: 0.020927, loss_fp: 0.000707, loss_freq: 0.034974
[15:17:16.944] iteration 18568: loss: 0.068153, loss_s1: 0.032277, loss_fp: 0.002229, loss_freq: 0.045729
[15:17:17.608] iteration 18569: loss: 0.085459, loss_s1: 0.042147, loss_fp: 0.003170, loss_freq: 0.010818
[15:17:18.241] iteration 18570: loss: 0.059779, loss_s1: 0.038984, loss_fp: 0.001271, loss_freq: 0.033550
[15:17:18.866] iteration 18571: loss: 0.053664, loss_s1: 0.043147, loss_fp: 0.003658, loss_freq: 0.021948
[15:17:19.530] iteration 18572: loss: 0.053078, loss_s1: 0.051180, loss_fp: 0.002966, loss_freq: 0.019106
[15:17:20.176] iteration 18573: loss: 0.086920, loss_s1: 0.094733, loss_fp: 0.000848, loss_freq: 0.024143
[15:17:20.808] iteration 18574: loss: 0.051920, loss_s1: 0.037137, loss_fp: 0.005146, loss_freq: 0.029577
[15:17:21.450] iteration 18575: loss: 0.039074, loss_s1: 0.021074, loss_fp: 0.001432, loss_freq: 0.017263
[15:17:22.086] iteration 18576: loss: 0.081826, loss_s1: 0.069403, loss_fp: 0.003329, loss_freq: 0.013013
[15:17:22.714] iteration 18577: loss: 0.044523, loss_s1: 0.018130, loss_fp: 0.006519, loss_freq: 0.013609
[15:17:23.354] iteration 18578: loss: 0.055715, loss_s1: 0.025184, loss_fp: 0.003522, loss_freq: 0.018836
[15:17:23.998] iteration 18579: loss: 0.113581, loss_s1: 0.074033, loss_fp: 0.002247, loss_freq: 0.059661
[15:17:24.647] iteration 18580: loss: 0.060973, loss_s1: 0.033579, loss_fp: 0.002899, loss_freq: 0.038272
[15:17:25.275] iteration 18581: loss: 0.061086, loss_s1: 0.023695, loss_fp: 0.002229, loss_freq: 0.035691
[15:17:25.906] iteration 18582: loss: 0.086195, loss_s1: 0.027434, loss_fp: 0.008925, loss_freq: 0.023696
[15:17:26.539] iteration 18583: loss: 0.046263, loss_s1: 0.030229, loss_fp: 0.005927, loss_freq: 0.010090
[15:17:27.174] iteration 18584: loss: 0.073604, loss_s1: 0.056359, loss_fp: 0.005726, loss_freq: 0.035767
[15:17:27.957] iteration 18585: loss: 0.046191, loss_s1: 0.040649, loss_fp: 0.000589, loss_freq: 0.008892
[15:17:28.785] iteration 18586: loss: 0.055813, loss_s1: 0.055324, loss_fp: 0.001088, loss_freq: 0.017159
[15:17:29.431] iteration 18587: loss: 0.094877, loss_s1: 0.040822, loss_fp: 0.005257, loss_freq: 0.028510
[15:17:30.075] iteration 18588: loss: 0.095049, loss_s1: 0.064007, loss_fp: 0.002182, loss_freq: 0.086184
[15:17:30.714] iteration 18589: loss: 0.140990, loss_s1: 0.149074, loss_fp: 0.008142, loss_freq: 0.086860
[15:17:31.342] iteration 18590: loss: 0.045237, loss_s1: 0.039230, loss_fp: 0.002242, loss_freq: 0.018450
[15:17:32.354] iteration 18591: loss: 0.056947, loss_s1: 0.038602, loss_fp: 0.000913, loss_freq: 0.020971
[15:17:32.988] iteration 18592: loss: 0.061623, loss_s1: 0.038501, loss_fp: 0.003909, loss_freq: 0.033422
[15:17:33.627] iteration 18593: loss: 0.047318, loss_s1: 0.030842, loss_fp: 0.003617, loss_freq: 0.013482
[15:17:34.253] iteration 18594: loss: 0.069812, loss_s1: 0.045450, loss_fp: 0.005411, loss_freq: 0.027486
[15:17:34.885] iteration 18595: loss: 0.084596, loss_s1: 0.059000, loss_fp: 0.008336, loss_freq: 0.049468
[15:17:35.501] iteration 18596: loss: 0.044522, loss_s1: 0.038759, loss_fp: 0.001092, loss_freq: 0.004936
[15:17:36.133] iteration 18597: loss: 0.029854, loss_s1: 0.013284, loss_fp: 0.002083, loss_freq: 0.015102
[15:17:36.761] iteration 18598: loss: 0.066574, loss_s1: 0.032015, loss_fp: 0.002858, loss_freq: 0.026255
[15:17:37.379] iteration 18599: loss: 0.078359, loss_s1: 0.058016, loss_fp: 0.003328, loss_freq: 0.047768
[15:17:38.012] iteration 18600: loss: 0.060641, loss_s1: 0.028986, loss_fp: 0.001845, loss_freq: 0.013357
[15:17:41.447] iteration 18600 : mean_dice : 0.778029
[15:17:42.091] iteration 18601: loss: 0.068501, loss_s1: 0.018400, loss_fp: 0.010708, loss_freq: 0.059160
[15:17:42.791] iteration 18602: loss: 0.069612, loss_s1: 0.025021, loss_fp: 0.005338, loss_freq: 0.029186
[15:17:43.454] iteration 18603: loss: 0.049185, loss_s1: 0.029094, loss_fp: 0.002102, loss_freq: 0.012057
[15:17:44.116] iteration 18604: loss: 0.049092, loss_s1: 0.005749, loss_fp: 0.004359, loss_freq: 0.023512
[15:17:44.769] iteration 18605: loss: 0.051799, loss_s1: 0.016335, loss_fp: 0.000292, loss_freq: 0.040294
[15:17:45.427] iteration 18606: loss: 0.051702, loss_s1: 0.041918, loss_fp: 0.001990, loss_freq: 0.023010
[15:17:46.062] iteration 18607: loss: 0.061915, loss_s1: 0.018018, loss_fp: 0.002321, loss_freq: 0.029150
[15:17:46.757] iteration 18608: loss: 0.053780, loss_s1: 0.022676, loss_fp: 0.019622, loss_freq: 0.011540
[15:17:47.425] iteration 18609: loss: 0.050027, loss_s1: 0.044903, loss_fp: 0.004212, loss_freq: 0.021330
[15:17:48.084] iteration 18610: loss: 0.043580, loss_s1: 0.028179, loss_fp: 0.005749, loss_freq: 0.017321
[15:17:48.740] iteration 18611: loss: 0.072812, loss_s1: 0.029354, loss_fp: 0.002309, loss_freq: 0.055304
[15:17:49.395] iteration 18612: loss: 0.038412, loss_s1: 0.021113, loss_fp: 0.001034, loss_freq: 0.013787
[15:17:50.045] iteration 18613: loss: 0.066689, loss_s1: 0.054018, loss_fp: 0.001916, loss_freq: 0.037043
[15:17:50.687] iteration 18614: loss: 0.044218, loss_s1: 0.036977, loss_fp: 0.001442, loss_freq: 0.012793
[15:17:51.323] iteration 18615: loss: 0.048301, loss_s1: 0.012385, loss_fp: 0.001117, loss_freq: 0.033979
[15:17:51.958] iteration 18616: loss: 0.073664, loss_s1: 0.039568, loss_fp: 0.005668, loss_freq: 0.049085
[15:17:52.592] iteration 18617: loss: 0.080039, loss_s1: 0.054110, loss_fp: 0.001297, loss_freq: 0.047273
[15:17:53.223] iteration 18618: loss: 0.038753, loss_s1: 0.029124, loss_fp: 0.001134, loss_freq: 0.006927
[15:17:53.864] iteration 18619: loss: 0.054555, loss_s1: 0.030622, loss_fp: 0.001498, loss_freq: 0.029241
[15:17:54.535] iteration 18620: loss: 0.071020, loss_s1: 0.034448, loss_fp: 0.002178, loss_freq: 0.011158
[15:17:55.187] iteration 18621: loss: 0.043151, loss_s1: 0.039590, loss_fp: 0.001390, loss_freq: 0.007185
[15:17:55.807] iteration 18622: loss: 0.077162, loss_s1: 0.069060, loss_fp: 0.001842, loss_freq: 0.029392
[15:17:56.439] iteration 18623: loss: 0.085568, loss_s1: 0.070999, loss_fp: 0.005398, loss_freq: 0.062693
[15:17:57.068] iteration 18624: loss: 0.068390, loss_s1: 0.044009, loss_fp: 0.004588, loss_freq: 0.049478
[15:17:57.698] iteration 18625: loss: 0.074468, loss_s1: 0.054364, loss_fp: 0.007427, loss_freq: 0.025520
[15:17:58.339] iteration 18626: loss: 0.073935, loss_s1: 0.046322, loss_fp: 0.001362, loss_freq: 0.060063
[15:17:58.979] iteration 18627: loss: 0.059449, loss_s1: 0.038740, loss_fp: 0.004129, loss_freq: 0.019631
[15:17:59.607] iteration 18628: loss: 0.068531, loss_s1: 0.062406, loss_fp: 0.013325, loss_freq: 0.020720
[15:18:00.245] iteration 18629: loss: 0.128896, loss_s1: 0.164420, loss_fp: 0.004284, loss_freq: 0.037069
[15:18:00.873] iteration 18630: loss: 0.073765, loss_s1: 0.074976, loss_fp: 0.004470, loss_freq: 0.028257
[15:18:01.498] iteration 18631: loss: 0.061299, loss_s1: 0.037756, loss_fp: 0.009928, loss_freq: 0.019600
[15:18:02.130] iteration 18632: loss: 0.058579, loss_s1: 0.042119, loss_fp: 0.006037, loss_freq: 0.039835
[15:18:02.778] iteration 18633: loss: 0.043423, loss_s1: 0.017865, loss_fp: 0.000769, loss_freq: 0.016918
[15:18:03.403] iteration 18634: loss: 0.055776, loss_s1: 0.037360, loss_fp: 0.007877, loss_freq: 0.025109
[15:18:04.035] iteration 18635: loss: 0.052929, loss_s1: 0.017188, loss_fp: 0.001534, loss_freq: 0.017534
[15:18:04.677] iteration 18636: loss: 0.062251, loss_s1: 0.048792, loss_fp: 0.001076, loss_freq: 0.024556
[15:18:05.297] iteration 18637: loss: 0.062884, loss_s1: 0.025011, loss_fp: 0.003136, loss_freq: 0.046951
[15:18:05.970] iteration 18638: loss: 0.055249, loss_s1: 0.036764, loss_fp: 0.006773, loss_freq: 0.021735
[15:18:06.606] iteration 18639: loss: 0.064077, loss_s1: 0.045257, loss_fp: 0.001423, loss_freq: 0.046689
[15:18:07.230] iteration 18640: loss: 0.040470, loss_s1: 0.031894, loss_fp: 0.002095, loss_freq: 0.008967
[15:18:07.859] iteration 18641: loss: 0.056071, loss_s1: 0.037373, loss_fp: 0.003278, loss_freq: 0.030855
[15:18:08.489] iteration 18642: loss: 0.084477, loss_s1: 0.044729, loss_fp: 0.001419, loss_freq: 0.060453
[15:18:09.118] iteration 18643: loss: 0.041283, loss_s1: 0.020637, loss_fp: 0.002123, loss_freq: 0.012666
[15:18:09.739] iteration 18644: loss: 0.058562, loss_s1: 0.051180, loss_fp: 0.008940, loss_freq: 0.025507
[15:18:10.362] iteration 18645: loss: 0.037997, loss_s1: 0.028532, loss_fp: 0.000349, loss_freq: 0.015920
[15:18:10.986] iteration 18646: loss: 0.040766, loss_s1: 0.014126, loss_fp: 0.001100, loss_freq: 0.010676
[15:18:11.611] iteration 18647: loss: 0.080280, loss_s1: 0.099741, loss_fp: 0.000840, loss_freq: 0.027606
[15:18:12.237] iteration 18648: loss: 0.051168, loss_s1: 0.035937, loss_fp: 0.001584, loss_freq: 0.027939
[15:18:12.890] iteration 18649: loss: 0.074513, loss_s1: 0.024475, loss_fp: 0.002679, loss_freq: 0.059743
[15:18:13.538] iteration 18650: loss: 0.047886, loss_s1: 0.030214, loss_fp: 0.002489, loss_freq: 0.019821
[15:18:14.172] iteration 18651: loss: 0.046509, loss_s1: 0.013726, loss_fp: 0.002623, loss_freq: 0.016173
[15:18:14.811] iteration 18652: loss: 0.073610, loss_s1: 0.057554, loss_fp: 0.005687, loss_freq: 0.022263
[15:18:15.469] iteration 18653: loss: 0.098839, loss_s1: 0.081966, loss_fp: 0.002173, loss_freq: 0.069362
[15:18:16.108] iteration 18654: loss: 0.048991, loss_s1: 0.026557, loss_fp: 0.001069, loss_freq: 0.023084
[15:18:16.747] iteration 18655: loss: 0.038190, loss_s1: 0.017206, loss_fp: 0.001667, loss_freq: 0.008075
[15:18:17.383] iteration 18656: loss: 0.059252, loss_s1: 0.054363, loss_fp: 0.002556, loss_freq: 0.014688
[15:18:18.018] iteration 18657: loss: 0.106918, loss_s1: 0.033255, loss_fp: 0.001885, loss_freq: 0.109150
[15:18:18.668] iteration 18658: loss: 0.040551, loss_s1: 0.031092, loss_fp: 0.005933, loss_freq: 0.008374
[15:18:19.315] iteration 18659: loss: 0.052595, loss_s1: 0.037687, loss_fp: 0.001617, loss_freq: 0.020751
[15:18:19.954] iteration 18660: loss: 0.044916, loss_s1: 0.013509, loss_fp: 0.001642, loss_freq: 0.010224
[15:18:20.591] iteration 18661: loss: 0.063445, loss_s1: 0.035333, loss_fp: 0.002511, loss_freq: 0.039169
[15:18:21.262] iteration 18662: loss: 0.075892, loss_s1: 0.067498, loss_fp: 0.011498, loss_freq: 0.025731
[15:18:21.903] iteration 18663: loss: 0.114429, loss_s1: 0.085080, loss_fp: 0.041336, loss_freq: 0.049887
[15:18:22.543] iteration 18664: loss: 0.065105, loss_s1: 0.036146, loss_fp: 0.003832, loss_freq: 0.032144
[15:18:23.164] iteration 18665: loss: 0.071407, loss_s1: 0.042949, loss_fp: 0.011247, loss_freq: 0.047469
[15:18:23.812] iteration 18666: loss: 0.070109, loss_s1: 0.057697, loss_fp: 0.003126, loss_freq: 0.024797
[15:18:24.440] iteration 18667: loss: 0.044186, loss_s1: 0.041393, loss_fp: 0.004900, loss_freq: 0.012816
[15:18:25.064] iteration 18668: loss: 0.064129, loss_s1: 0.026392, loss_fp: 0.001534, loss_freq: 0.010100
[15:18:25.690] iteration 18669: loss: 0.108471, loss_s1: 0.059385, loss_fp: 0.009553, loss_freq: 0.092597
[15:18:26.372] iteration 18670: loss: 0.087492, loss_s1: 0.074513, loss_fp: 0.003325, loss_freq: 0.022303
[15:18:26.990] iteration 18671: loss: 0.081295, loss_s1: 0.086477, loss_fp: 0.014035, loss_freq: 0.013689
[15:18:27.617] iteration 18672: loss: 0.045956, loss_s1: 0.040935, loss_fp: 0.001404, loss_freq: 0.009993
[15:18:28.241] iteration 18673: loss: 0.061090, loss_s1: 0.046745, loss_fp: 0.004212, loss_freq: 0.028077
[15:18:28.861] iteration 18674: loss: 0.050590, loss_s1: 0.024417, loss_fp: 0.001745, loss_freq: 0.028454
[15:18:29.492] iteration 18675: loss: 0.058061, loss_s1: 0.016706, loss_fp: 0.016756, loss_freq: 0.040819
[15:18:30.123] iteration 18676: loss: 0.061277, loss_s1: 0.045016, loss_fp: 0.003308, loss_freq: 0.037002
[15:18:30.755] iteration 18677: loss: 0.045323, loss_s1: 0.029579, loss_fp: 0.000321, loss_freq: 0.010533
[15:18:31.383] iteration 18678: loss: 0.049605, loss_s1: 0.035516, loss_fp: 0.002601, loss_freq: 0.022769
[15:18:32.010] iteration 18679: loss: 0.046611, loss_s1: 0.019104, loss_fp: 0.000419, loss_freq: 0.025683
[15:18:32.681] iteration 18680: loss: 0.050147, loss_s1: 0.044253, loss_fp: 0.000690, loss_freq: 0.016905
[15:18:33.314] iteration 18681: loss: 0.058691, loss_s1: 0.043624, loss_fp: 0.001334, loss_freq: 0.016366
[15:18:33.942] iteration 18682: loss: 0.070611, loss_s1: 0.025339, loss_fp: 0.012391, loss_freq: 0.037833
[15:18:34.576] iteration 18683: loss: 0.049763, loss_s1: 0.039710, loss_fp: 0.001312, loss_freq: 0.017776
[15:18:35.196] iteration 18684: loss: 0.053509, loss_s1: 0.047128, loss_fp: 0.002201, loss_freq: 0.007499
[15:18:35.815] iteration 18685: loss: 0.057524, loss_s1: 0.021938, loss_fp: 0.003675, loss_freq: 0.035952
[15:18:36.477] iteration 18686: loss: 0.029514, loss_s1: 0.005749, loss_fp: 0.001082, loss_freq: 0.008656
[15:18:37.097] iteration 18687: loss: 0.073895, loss_s1: 0.043345, loss_fp: 0.007541, loss_freq: 0.033127
[15:18:37.721] iteration 18688: loss: 0.048594, loss_s1: 0.014762, loss_fp: 0.001481, loss_freq: 0.024201
[15:18:38.334] iteration 18689: loss: 0.071307, loss_s1: 0.016845, loss_fp: 0.004864, loss_freq: 0.017232
[15:18:38.970] iteration 18690: loss: 0.072228, loss_s1: 0.045765, loss_fp: 0.008495, loss_freq: 0.047869
[15:18:39.601] iteration 18691: loss: 0.055563, loss_s1: 0.025282, loss_fp: 0.003062, loss_freq: 0.044337
[15:18:40.231] iteration 18692: loss: 0.093471, loss_s1: 0.081405, loss_fp: 0.000751, loss_freq: 0.043513
[15:18:40.855] iteration 18693: loss: 0.071165, loss_s1: 0.072561, loss_fp: 0.007338, loss_freq: 0.017529
[15:18:41.476] iteration 18694: loss: 0.039596, loss_s1: 0.027177, loss_fp: 0.000833, loss_freq: 0.014996
[15:18:42.098] iteration 18695: loss: 0.050929, loss_s1: 0.022018, loss_fp: 0.008648, loss_freq: 0.029180
[15:18:42.726] iteration 18696: loss: 0.047926, loss_s1: 0.015327, loss_fp: 0.001035, loss_freq: 0.024338
[15:18:43.351] iteration 18697: loss: 0.085947, loss_s1: 0.076796, loss_fp: 0.010984, loss_freq: 0.037355
[15:18:43.972] iteration 18698: loss: 0.035094, loss_s1: 0.011373, loss_fp: 0.003614, loss_freq: 0.020420
[15:18:44.586] iteration 18699: loss: 0.065462, loss_s1: 0.029183, loss_fp: 0.004479, loss_freq: 0.023702
[15:18:45.206] iteration 18700: loss: 0.041927, loss_s1: 0.028236, loss_fp: 0.004592, loss_freq: 0.022352
[15:18:45.825] iteration 18701: loss: 0.079921, loss_s1: 0.043464, loss_fp: 0.003343, loss_freq: 0.021813
[15:18:46.452] iteration 18702: loss: 0.040077, loss_s1: 0.028618, loss_fp: 0.003511, loss_freq: 0.018666
[15:18:47.078] iteration 18703: loss: 0.048965, loss_s1: 0.030322, loss_fp: 0.000847, loss_freq: 0.006854
[15:18:47.697] iteration 18704: loss: 0.083574, loss_s1: 0.070403, loss_fp: 0.011701, loss_freq: 0.039458
[15:18:48.384] iteration 18705: loss: 0.077347, loss_s1: 0.061860, loss_fp: 0.004275, loss_freq: 0.020963
[15:18:49.042] iteration 18706: loss: 0.048608, loss_s1: 0.018361, loss_fp: 0.003197, loss_freq: 0.031621
[15:18:49.694] iteration 18707: loss: 0.048479, loss_s1: 0.030932, loss_fp: 0.000448, loss_freq: 0.011466
[15:18:50.343] iteration 18708: loss: 0.082821, loss_s1: 0.065913, loss_fp: 0.004957, loss_freq: 0.022653
[15:18:50.980] iteration 18709: loss: 0.038677, loss_s1: 0.034067, loss_fp: 0.003052, loss_freq: 0.004141
[15:18:51.616] iteration 18710: loss: 0.050933, loss_s1: 0.019968, loss_fp: 0.001583, loss_freq: 0.032338
[15:18:52.267] iteration 18711: loss: 0.055838, loss_s1: 0.028230, loss_fp: 0.001874, loss_freq: 0.046599
[15:18:52.900] iteration 18712: loss: 0.072116, loss_s1: 0.052696, loss_fp: 0.008262, loss_freq: 0.025626
[15:18:53.534] iteration 18713: loss: 0.058647, loss_s1: 0.053433, loss_fp: 0.000437, loss_freq: 0.020842
[15:18:54.153] iteration 18714: loss: 0.045789, loss_s1: 0.042492, loss_fp: 0.000815, loss_freq: 0.015349
[15:18:54.772] iteration 18715: loss: 0.062842, loss_s1: 0.023811, loss_fp: 0.004219, loss_freq: 0.021013
[15:18:55.395] iteration 18716: loss: 0.052340, loss_s1: 0.030033, loss_fp: 0.000535, loss_freq: 0.009130
[15:18:56.018] iteration 18717: loss: 0.039920, loss_s1: 0.020899, loss_fp: 0.001024, loss_freq: 0.024125
[15:18:56.642] iteration 18718: loss: 0.065852, loss_s1: 0.039617, loss_fp: 0.009782, loss_freq: 0.026141
[15:18:57.268] iteration 18719: loss: 0.090303, loss_s1: 0.090595, loss_fp: 0.004837, loss_freq: 0.011366
[15:18:57.887] iteration 18720: loss: 0.039415, loss_s1: 0.011059, loss_fp: 0.004027, loss_freq: 0.023360
[15:18:58.520] iteration 18721: loss: 0.055122, loss_s1: 0.035304, loss_fp: 0.004814, loss_freq: 0.019159
[15:18:59.144] iteration 18722: loss: 0.069341, loss_s1: 0.031857, loss_fp: 0.013123, loss_freq: 0.039449
[15:18:59.760] iteration 18723: loss: 0.043474, loss_s1: 0.022231, loss_fp: 0.004861, loss_freq: 0.022274
[15:19:00.400] iteration 18724: loss: 0.088652, loss_s1: 0.039529, loss_fp: 0.008254, loss_freq: 0.057613
[15:19:01.017] iteration 18725: loss: 0.055736, loss_s1: 0.021451, loss_fp: 0.007976, loss_freq: 0.032207
[15:19:01.633] iteration 18726: loss: 0.082972, loss_s1: 0.081759, loss_fp: 0.003482, loss_freq: 0.036729
[15:19:02.263] iteration 18727: loss: 0.069611, loss_s1: 0.054601, loss_fp: 0.003415, loss_freq: 0.039418
[15:19:02.885] iteration 18728: loss: 0.043493, loss_s1: 0.033458, loss_fp: 0.001842, loss_freq: 0.011102
[15:19:03.502] iteration 18729: loss: 0.074023, loss_s1: 0.049266, loss_fp: 0.024278, loss_freq: 0.014689
[15:19:04.119] iteration 18730: loss: 0.040286, loss_s1: 0.006497, loss_fp: 0.002221, loss_freq: 0.012299
[15:19:04.741] iteration 18731: loss: 0.064563, loss_s1: 0.030129, loss_fp: 0.006225, loss_freq: 0.046073
[15:19:05.354] iteration 18732: loss: 0.068024, loss_s1: 0.034491, loss_fp: 0.008532, loss_freq: 0.040825
[15:19:05.969] iteration 18733: loss: 0.047068, loss_s1: 0.029282, loss_fp: 0.003680, loss_freq: 0.018846
[15:19:06.930] iteration 18734: loss: 0.058147, loss_s1: 0.040931, loss_fp: 0.005648, loss_freq: 0.022981
[15:19:07.551] iteration 18735: loss: 0.063162, loss_s1: 0.041442, loss_fp: 0.001233, loss_freq: 0.018769
[15:19:08.172] iteration 18736: loss: 0.044477, loss_s1: 0.035822, loss_fp: 0.001073, loss_freq: 0.014858
[15:19:08.812] iteration 18737: loss: 0.067194, loss_s1: 0.032844, loss_fp: 0.001182, loss_freq: 0.033198
[15:19:09.447] iteration 18738: loss: 0.062567, loss_s1: 0.050427, loss_fp: 0.001779, loss_freq: 0.035708
[15:19:10.089] iteration 18739: loss: 0.036924, loss_s1: 0.022575, loss_fp: 0.001828, loss_freq: 0.008127
[15:19:10.729] iteration 18740: loss: 0.042476, loss_s1: 0.030647, loss_fp: 0.002917, loss_freq: 0.021817
[15:19:11.365] iteration 18741: loss: 0.113374, loss_s1: 0.110617, loss_fp: 0.020480, loss_freq: 0.026721
[15:19:11.984] iteration 18742: loss: 0.070247, loss_s1: 0.034128, loss_fp: 0.005539, loss_freq: 0.063826
[15:19:12.601] iteration 18743: loss: 0.039540, loss_s1: 0.008837, loss_fp: 0.002011, loss_freq: 0.017187
[15:19:13.227] iteration 18744: loss: 0.069376, loss_s1: 0.036941, loss_fp: 0.002205, loss_freq: 0.041510
[15:19:13.850] iteration 18745: loss: 0.048341, loss_s1: 0.044259, loss_fp: 0.001278, loss_freq: 0.008140
[15:19:14.469] iteration 18746: loss: 0.053175, loss_s1: 0.047351, loss_fp: 0.006673, loss_freq: 0.005661
[15:19:15.087] iteration 18747: loss: 0.038717, loss_s1: 0.030532, loss_fp: 0.002392, loss_freq: 0.014861
[15:19:15.711] iteration 18748: loss: 0.063782, loss_s1: 0.051779, loss_fp: 0.004808, loss_freq: 0.020881
[15:19:16.338] iteration 18749: loss: 0.039081, loss_s1: 0.010976, loss_fp: 0.001632, loss_freq: 0.006984
[15:19:16.973] iteration 18750: loss: 0.050564, loss_s1: 0.017987, loss_fp: 0.003600, loss_freq: 0.036719
[15:19:17.599] iteration 18751: loss: 0.036700, loss_s1: 0.020335, loss_fp: 0.000747, loss_freq: 0.009333
[15:19:18.225] iteration 18752: loss: 0.039191, loss_s1: 0.019312, loss_fp: 0.001635, loss_freq: 0.031864
[15:19:18.837] iteration 18753: loss: 0.028386, loss_s1: 0.016770, loss_fp: 0.001457, loss_freq: 0.012510
[15:19:19.458] iteration 18754: loss: 0.088882, loss_s1: 0.036741, loss_fp: 0.005242, loss_freq: 0.063798
[15:19:20.081] iteration 18755: loss: 0.038932, loss_s1: 0.016914, loss_fp: 0.005936, loss_freq: 0.023660
[15:19:20.702] iteration 18756: loss: 0.054502, loss_s1: 0.039333, loss_fp: 0.010767, loss_freq: 0.027060
[15:19:21.321] iteration 18757: loss: 0.048791, loss_s1: 0.013011, loss_fp: 0.000965, loss_freq: 0.004446
[15:19:21.960] iteration 18758: loss: 0.042839, loss_s1: 0.028142, loss_fp: 0.002139, loss_freq: 0.012509
[15:19:22.580] iteration 18759: loss: 0.054641, loss_s1: 0.021800, loss_fp: 0.003802, loss_freq: 0.034820
[15:19:23.212] iteration 18760: loss: 0.075718, loss_s1: 0.030630, loss_fp: 0.005464, loss_freq: 0.069542
[15:19:23.832] iteration 18761: loss: 0.037411, loss_s1: 0.018088, loss_fp: 0.002711, loss_freq: 0.015222
[15:19:24.452] iteration 18762: loss: 0.067307, loss_s1: 0.040478, loss_fp: 0.003729, loss_freq: 0.031382
[15:19:25.070] iteration 18763: loss: 0.039813, loss_s1: 0.013042, loss_fp: 0.000857, loss_freq: 0.007431
[15:19:25.688] iteration 18764: loss: 0.040378, loss_s1: 0.022306, loss_fp: 0.001353, loss_freq: 0.021468
[15:19:26.309] iteration 18765: loss: 0.073488, loss_s1: 0.055090, loss_fp: 0.004411, loss_freq: 0.031221
[15:19:26.929] iteration 18766: loss: 0.072480, loss_s1: 0.061866, loss_fp: 0.009893, loss_freq: 0.041855
[15:19:27.556] iteration 18767: loss: 0.065029, loss_s1: 0.041904, loss_fp: 0.006626, loss_freq: 0.031058
[15:19:28.184] iteration 18768: loss: 0.060033, loss_s1: 0.021617, loss_fp: 0.013931, loss_freq: 0.014934
[15:19:28.797] iteration 18769: loss: 0.091483, loss_s1: 0.066079, loss_fp: 0.004335, loss_freq: 0.065037
[15:19:29.454] iteration 18770: loss: 0.069050, loss_s1: 0.047212, loss_fp: 0.005277, loss_freq: 0.036508
[15:19:30.094] iteration 18771: loss: 0.090552, loss_s1: 0.085467, loss_fp: 0.005754, loss_freq: 0.057082
[15:19:30.735] iteration 18772: loss: 0.093725, loss_s1: 0.046468, loss_fp: 0.016419, loss_freq: 0.040430
[15:19:31.370] iteration 18773: loss: 0.049872, loss_s1: 0.045791, loss_fp: 0.003649, loss_freq: 0.012192
[15:19:31.996] iteration 18774: loss: 0.072956, loss_s1: 0.050998, loss_fp: 0.003678, loss_freq: 0.039566
[15:19:32.618] iteration 18775: loss: 0.051331, loss_s1: 0.035398, loss_fp: 0.009691, loss_freq: 0.023164
[15:19:33.238] iteration 18776: loss: 0.051608, loss_s1: 0.039807, loss_fp: 0.000510, loss_freq: 0.006289
[15:19:33.860] iteration 18777: loss: 0.061553, loss_s1: 0.044708, loss_fp: 0.002959, loss_freq: 0.036811
[15:19:34.504] iteration 18778: loss: 0.093698, loss_s1: 0.107931, loss_fp: 0.002447, loss_freq: 0.017532
[15:19:35.166] iteration 18779: loss: 0.052074, loss_s1: 0.031043, loss_fp: 0.002379, loss_freq: 0.032681
[15:19:35.831] iteration 18780: loss: 0.056316, loss_s1: 0.026319, loss_fp: 0.002620, loss_freq: 0.036041
[15:19:36.462] iteration 18781: loss: 0.060909, loss_s1: 0.042585, loss_fp: 0.002333, loss_freq: 0.016515
[15:19:37.131] iteration 18782: loss: 0.044248, loss_s1: 0.045984, loss_fp: 0.002944, loss_freq: 0.010297
[15:19:37.756] iteration 18783: loss: 0.078037, loss_s1: 0.075200, loss_fp: 0.002602, loss_freq: 0.043091
[15:19:38.374] iteration 18784: loss: 0.045037, loss_s1: 0.023524, loss_fp: 0.001323, loss_freq: 0.026367
[15:19:38.995] iteration 18785: loss: 0.053074, loss_s1: 0.030103, loss_fp: 0.004000, loss_freq: 0.019979
[15:19:39.638] iteration 18786: loss: 0.049621, loss_s1: 0.051713, loss_fp: 0.001705, loss_freq: 0.012878
[15:19:40.252] iteration 18787: loss: 0.034757, loss_s1: 0.013117, loss_fp: 0.005071, loss_freq: 0.017818
[15:19:40.881] iteration 18788: loss: 0.024078, loss_s1: 0.010448, loss_fp: 0.001260, loss_freq: 0.006431
[15:19:41.494] iteration 18789: loss: 0.068082, loss_s1: 0.063304, loss_fp: 0.000719, loss_freq: 0.004712
[15:19:42.110] iteration 18790: loss: 0.065256, loss_s1: 0.055353, loss_fp: 0.002778, loss_freq: 0.015961
[15:19:42.730] iteration 18791: loss: 0.047521, loss_s1: 0.041152, loss_fp: 0.000679, loss_freq: 0.012527
[15:19:43.352] iteration 18792: loss: 0.064996, loss_s1: 0.048433, loss_fp: 0.002475, loss_freq: 0.032877
[15:19:43.980] iteration 18793: loss: 0.060203, loss_s1: 0.041100, loss_fp: 0.002335, loss_freq: 0.034869
[15:19:44.601] iteration 18794: loss: 0.065356, loss_s1: 0.028083, loss_fp: 0.002215, loss_freq: 0.024746
[15:19:45.223] iteration 18795: loss: 0.076111, loss_s1: 0.095809, loss_fp: 0.005856, loss_freq: 0.012821
[15:19:45.839] iteration 18796: loss: 0.054046, loss_s1: 0.029732, loss_fp: 0.005138, loss_freq: 0.012656
[15:19:46.458] iteration 18797: loss: 0.066777, loss_s1: 0.059847, loss_fp: 0.001844, loss_freq: 0.023677
[15:19:47.080] iteration 18798: loss: 0.058091, loss_s1: 0.047638, loss_fp: 0.002888, loss_freq: 0.014022
[15:19:47.706] iteration 18799: loss: 0.041130, loss_s1: 0.024917, loss_fp: 0.003035, loss_freq: 0.021222
[15:19:48.333] iteration 18800: loss: 0.076909, loss_s1: 0.019280, loss_fp: 0.004792, loss_freq: 0.067027
[15:19:51.679] iteration 18800 : mean_dice : 0.792283
[15:19:52.349] iteration 18801: loss: 0.039880, loss_s1: 0.016916, loss_fp: 0.009020, loss_freq: 0.016613
[15:19:52.993] iteration 18802: loss: 0.052414, loss_s1: 0.029533, loss_fp: 0.002419, loss_freq: 0.021589
[15:19:53.638] iteration 18803: loss: 0.081231, loss_s1: 0.037761, loss_fp: 0.014707, loss_freq: 0.012536
[15:19:54.275] iteration 18804: loss: 0.070828, loss_s1: 0.064094, loss_fp: 0.006254, loss_freq: 0.019730
[15:19:54.893] iteration 18805: loss: 0.074031, loss_s1: 0.041154, loss_fp: 0.004784, loss_freq: 0.040275
[15:19:55.523] iteration 18806: loss: 0.040093, loss_s1: 0.028882, loss_fp: 0.004243, loss_freq: 0.014978
[15:19:56.140] iteration 18807: loss: 0.087817, loss_s1: 0.094338, loss_fp: 0.007534, loss_freq: 0.022254
[15:19:56.756] iteration 18808: loss: 0.067682, loss_s1: 0.065782, loss_fp: 0.003816, loss_freq: 0.031456
[15:19:57.368] iteration 18809: loss: 0.084772, loss_s1: 0.052472, loss_fp: 0.003008, loss_freq: 0.024803
[15:19:57.984] iteration 18810: loss: 0.060768, loss_s1: 0.063730, loss_fp: 0.005015, loss_freq: 0.024815
[15:19:58.599] iteration 18811: loss: 0.055233, loss_s1: 0.043154, loss_fp: 0.000799, loss_freq: 0.020054
[15:19:59.223] iteration 18812: loss: 0.095439, loss_s1: 0.066304, loss_fp: 0.015637, loss_freq: 0.057141
[15:19:59.910] iteration 18813: loss: 0.087461, loss_s1: 0.044512, loss_fp: 0.008255, loss_freq: 0.028061
[15:20:00.541] iteration 18814: loss: 0.068764, loss_s1: 0.043981, loss_fp: 0.001842, loss_freq: 0.049929
[15:20:01.175] iteration 18815: loss: 0.060254, loss_s1: 0.051430, loss_fp: 0.004602, loss_freq: 0.019510
[15:20:01.807] iteration 18816: loss: 0.051270, loss_s1: 0.027068, loss_fp: 0.009146, loss_freq: 0.015937
[15:20:02.431] iteration 18817: loss: 0.046185, loss_s1: 0.047549, loss_fp: 0.000712, loss_freq: 0.010801
[15:20:03.048] iteration 18818: loss: 0.056748, loss_s1: 0.033317, loss_fp: 0.001842, loss_freq: 0.026637
[15:20:03.736] iteration 18819: loss: 0.068761, loss_s1: 0.026549, loss_fp: 0.003462, loss_freq: 0.033506
[15:20:04.359] iteration 18820: loss: 0.057466, loss_s1: 0.047243, loss_fp: 0.000556, loss_freq: 0.017165
[15:20:04.978] iteration 18821: loss: 0.049976, loss_s1: 0.030176, loss_fp: 0.001841, loss_freq: 0.033113
[15:20:05.603] iteration 18822: loss: 0.038107, loss_s1: 0.035488, loss_fp: 0.001106, loss_freq: 0.004910
[15:20:06.227] iteration 18823: loss: 0.045411, loss_s1: 0.039864, loss_fp: 0.003339, loss_freq: 0.009830
[15:20:06.845] iteration 18824: loss: 0.053265, loss_s1: 0.018910, loss_fp: 0.001978, loss_freq: 0.024474
[15:20:07.478] iteration 18825: loss: 0.068423, loss_s1: 0.046859, loss_fp: 0.000573, loss_freq: 0.012477
[15:20:08.103] iteration 18826: loss: 0.035815, loss_s1: 0.014289, loss_fp: 0.002358, loss_freq: 0.007251
[15:20:08.720] iteration 18827: loss: 0.035137, loss_s1: 0.018662, loss_fp: 0.001843, loss_freq: 0.010603
[15:20:09.327] iteration 18828: loss: 0.040957, loss_s1: 0.014730, loss_fp: 0.001295, loss_freq: 0.017638
[15:20:09.939] iteration 18829: loss: 0.062751, loss_s1: 0.061752, loss_fp: 0.000638, loss_freq: 0.004108
[15:20:10.555] iteration 18830: loss: 0.075313, loss_s1: 0.052179, loss_fp: 0.003662, loss_freq: 0.048511
[15:20:11.192] iteration 18831: loss: 0.037392, loss_s1: 0.016460, loss_fp: 0.001626, loss_freq: 0.011644
[15:20:11.812] iteration 18832: loss: 0.059134, loss_s1: 0.047108, loss_fp: 0.000791, loss_freq: 0.014229
[15:20:12.431] iteration 18833: loss: 0.061847, loss_s1: 0.023280, loss_fp: 0.004499, loss_freq: 0.038488
[15:20:13.065] iteration 18834: loss: 0.043543, loss_s1: 0.027059, loss_fp: 0.002994, loss_freq: 0.010483
[15:20:13.716] iteration 18835: loss: 0.056776, loss_s1: 0.021265, loss_fp: 0.001660, loss_freq: 0.040551
[15:20:14.360] iteration 18836: loss: 0.105090, loss_s1: 0.125411, loss_fp: 0.003675, loss_freq: 0.051456
[15:20:14.992] iteration 18837: loss: 0.034899, loss_s1: 0.021787, loss_fp: 0.003215, loss_freq: 0.005429
[15:20:15.615] iteration 18838: loss: 0.096083, loss_s1: 0.053169, loss_fp: 0.007879, loss_freq: 0.012955
[15:20:16.231] iteration 18839: loss: 0.042215, loss_s1: 0.022875, loss_fp: 0.001041, loss_freq: 0.014957
[15:20:16.854] iteration 18840: loss: 0.079489, loss_s1: 0.037559, loss_fp: 0.004894, loss_freq: 0.062233
[15:20:17.475] iteration 18841: loss: 0.062728, loss_s1: 0.050040, loss_fp: 0.003156, loss_freq: 0.025481
[15:20:18.100] iteration 18842: loss: 0.061145, loss_s1: 0.041857, loss_fp: 0.003867, loss_freq: 0.031093
[15:20:18.720] iteration 18843: loss: 0.087066, loss_s1: 0.050441, loss_fp: 0.004515, loss_freq: 0.070813
[15:20:19.353] iteration 18844: loss: 0.067626, loss_s1: 0.038729, loss_fp: 0.001973, loss_freq: 0.014532
[15:20:20.024] iteration 18845: loss: 0.048610, loss_s1: 0.037556, loss_fp: 0.002706, loss_freq: 0.023060
[15:20:20.681] iteration 18846: loss: 0.046861, loss_s1: 0.015000, loss_fp: 0.003956, loss_freq: 0.007876
[15:20:21.337] iteration 18847: loss: 0.066871, loss_s1: 0.034998, loss_fp: 0.001912, loss_freq: 0.046905
[15:20:21.996] iteration 18848: loss: 0.095423, loss_s1: 0.086003, loss_fp: 0.000935, loss_freq: 0.048842
[15:20:22.650] iteration 18849: loss: 0.037958, loss_s1: 0.007087, loss_fp: 0.001446, loss_freq: 0.014785
[15:20:23.333] iteration 18850: loss: 0.054385, loss_s1: 0.021327, loss_fp: 0.004303, loss_freq: 0.032209
[15:20:24.002] iteration 18851: loss: 0.061892, loss_s1: 0.045721, loss_fp: 0.003035, loss_freq: 0.023041
[15:20:24.639] iteration 18852: loss: 0.042543, loss_s1: 0.026912, loss_fp: 0.005208, loss_freq: 0.015635
[15:20:25.292] iteration 18853: loss: 0.049718, loss_s1: 0.013889, loss_fp: 0.002091, loss_freq: 0.029256
[15:20:25.935] iteration 18854: loss: 0.082167, loss_s1: 0.047497, loss_fp: 0.005053, loss_freq: 0.064169
[15:20:26.625] iteration 18855: loss: 0.087121, loss_s1: 0.044701, loss_fp: 0.002403, loss_freq: 0.037424
[15:20:27.251] iteration 18856: loss: 0.039510, loss_s1: 0.020731, loss_fp: 0.003663, loss_freq: 0.018632
[15:20:27.876] iteration 18857: loss: 0.053686, loss_s1: 0.035328, loss_fp: 0.001409, loss_freq: 0.031815
[15:20:28.496] iteration 18858: loss: 0.039400, loss_s1: 0.026821, loss_fp: 0.005157, loss_freq: 0.017101
[15:20:29.117] iteration 18859: loss: 0.052233, loss_s1: 0.036289, loss_fp: 0.006057, loss_freq: 0.015616
[15:20:29.731] iteration 18860: loss: 0.033884, loss_s1: 0.021403, loss_fp: 0.001757, loss_freq: 0.013754
[15:20:30.359] iteration 18861: loss: 0.047779, loss_s1: 0.026668, loss_fp: 0.003386, loss_freq: 0.025933
[15:20:30.986] iteration 18862: loss: 0.081293, loss_s1: 0.059232, loss_fp: 0.002848, loss_freq: 0.044425
[15:20:31.667] iteration 18863: loss: 0.036111, loss_s1: 0.013602, loss_fp: 0.000812, loss_freq: 0.019852
[15:20:32.288] iteration 18864: loss: 0.059664, loss_s1: 0.049298, loss_fp: 0.003401, loss_freq: 0.015771
[15:20:32.914] iteration 18865: loss: 0.044949, loss_s1: 0.022228, loss_fp: 0.004881, loss_freq: 0.015072
[15:20:33.533] iteration 18866: loss: 0.071869, loss_s1: 0.056829, loss_fp: 0.005655, loss_freq: 0.036616
[15:20:34.155] iteration 18867: loss: 0.084635, loss_s1: 0.038519, loss_fp: 0.002086, loss_freq: 0.051858
[15:20:34.778] iteration 18868: loss: 0.051456, loss_s1: 0.020444, loss_fp: 0.003841, loss_freq: 0.024082
[15:20:35.397] iteration 18869: loss: 0.071977, loss_s1: 0.048149, loss_fp: 0.005622, loss_freq: 0.034851
[15:20:36.015] iteration 18870: loss: 0.064107, loss_s1: 0.043738, loss_fp: 0.004775, loss_freq: 0.019262
[15:20:36.635] iteration 18871: loss: 0.040875, loss_s1: 0.023647, loss_fp: 0.005641, loss_freq: 0.015769
[15:20:37.275] iteration 18872: loss: 0.056669, loss_s1: 0.049453, loss_fp: 0.001907, loss_freq: 0.024223
[15:20:37.896] iteration 18873: loss: 0.071259, loss_s1: 0.036472, loss_fp: 0.003405, loss_freq: 0.016032
[15:20:38.534] iteration 18874: loss: 0.060031, loss_s1: 0.038776, loss_fp: 0.008063, loss_freq: 0.031622
[15:20:39.169] iteration 18875: loss: 0.091507, loss_s1: 0.098458, loss_fp: 0.005156, loss_freq: 0.032718
[15:20:39.807] iteration 18876: loss: 0.038666, loss_s1: 0.028010, loss_fp: 0.002863, loss_freq: 0.013025
[15:20:40.782] iteration 18877: loss: 0.038099, loss_s1: 0.021449, loss_fp: 0.001900, loss_freq: 0.015302
[15:20:41.403] iteration 18878: loss: 0.073046, loss_s1: 0.062145, loss_fp: 0.000890, loss_freq: 0.031153
[15:20:42.066] iteration 18879: loss: 0.036207, loss_s1: 0.011409, loss_fp: 0.001877, loss_freq: 0.013943
[15:20:42.685] iteration 18880: loss: 0.060345, loss_s1: 0.043256, loss_fp: 0.008092, loss_freq: 0.022280
[15:20:43.306] iteration 18881: loss: 0.080829, loss_s1: 0.090381, loss_fp: 0.000531, loss_freq: 0.035194
[15:20:43.935] iteration 18882: loss: 0.049791, loss_s1: 0.024267, loss_fp: 0.001485, loss_freq: 0.014036
[15:20:44.554] iteration 18883: loss: 0.031702, loss_s1: 0.015682, loss_fp: 0.006041, loss_freq: 0.008488
[15:20:45.160] iteration 18884: loss: 0.069304, loss_s1: 0.027439, loss_fp: 0.004927, loss_freq: 0.017974
[15:20:45.777] iteration 18885: loss: 0.066572, loss_s1: 0.059898, loss_fp: 0.006998, loss_freq: 0.017607
[15:20:46.397] iteration 18886: loss: 0.048861, loss_s1: 0.014684, loss_fp: 0.001136, loss_freq: 0.006885
[15:20:47.016] iteration 18887: loss: 0.081319, loss_s1: 0.035140, loss_fp: 0.004348, loss_freq: 0.074706
[15:20:47.630] iteration 18888: loss: 0.050707, loss_s1: 0.028847, loss_fp: 0.006769, loss_freq: 0.006600
[15:20:48.283] iteration 18889: loss: 0.054440, loss_s1: 0.041565, loss_fp: 0.004639, loss_freq: 0.013876
[15:20:48.903] iteration 18890: loss: 0.040455, loss_s1: 0.020921, loss_fp: 0.008763, loss_freq: 0.018236
[15:20:49.552] iteration 18891: loss: 0.082068, loss_s1: 0.071136, loss_fp: 0.002132, loss_freq: 0.051433
[15:20:50.174] iteration 18892: loss: 0.057377, loss_s1: 0.049524, loss_fp: 0.001508, loss_freq: 0.027082
[15:20:50.824] iteration 18893: loss: 0.059495, loss_s1: 0.029577, loss_fp: 0.003631, loss_freq: 0.023794
[15:20:51.438] iteration 18894: loss: 0.033685, loss_s1: 0.022734, loss_fp: 0.001695, loss_freq: 0.008993
[15:20:52.059] iteration 18895: loss: 0.055974, loss_s1: 0.050965, loss_fp: 0.007153, loss_freq: 0.022345
[15:20:52.677] iteration 18896: loss: 0.039630, loss_s1: 0.027838, loss_fp: 0.001061, loss_freq: 0.012781
[15:20:53.297] iteration 18897: loss: 0.091597, loss_s1: 0.042062, loss_fp: 0.003277, loss_freq: 0.087460
[15:20:53.921] iteration 18898: loss: 0.059325, loss_s1: 0.031681, loss_fp: 0.009353, loss_freq: 0.025898
[15:20:54.545] iteration 18899: loss: 0.090260, loss_s1: 0.065756, loss_fp: 0.025767, loss_freq: 0.056969
[15:20:55.159] iteration 18900: loss: 0.056218, loss_s1: 0.042840, loss_fp: 0.000295, loss_freq: 0.004779
[15:20:55.783] iteration 18901: loss: 0.056424, loss_s1: 0.030702, loss_fp: 0.002510, loss_freq: 0.020434
[15:20:56.402] iteration 18902: loss: 0.074518, loss_s1: 0.058694, loss_fp: 0.004296, loss_freq: 0.042689
[15:20:57.023] iteration 18903: loss: 0.079632, loss_s1: 0.031644, loss_fp: 0.003061, loss_freq: 0.081802
[15:20:57.647] iteration 18904: loss: 0.048066, loss_s1: 0.054512, loss_fp: 0.001066, loss_freq: 0.005329
[15:20:58.264] iteration 18905: loss: 0.088485, loss_s1: 0.074279, loss_fp: 0.014021, loss_freq: 0.024972
[15:20:58.914] iteration 18906: loss: 0.041978, loss_s1: 0.036152, loss_fp: 0.001573, loss_freq: 0.006029
[15:20:59.539] iteration 18907: loss: 0.046752, loss_s1: 0.032064, loss_fp: 0.001881, loss_freq: 0.024950
[15:21:00.170] iteration 18908: loss: 0.081462, loss_s1: 0.083711, loss_fp: 0.008707, loss_freq: 0.021514
[15:21:00.850] iteration 18909: loss: 0.059452, loss_s1: 0.039238, loss_fp: 0.004930, loss_freq: 0.041760
[15:21:01.465] iteration 18910: loss: 0.062965, loss_s1: 0.052239, loss_fp: 0.002784, loss_freq: 0.035275
[15:21:02.083] iteration 18911: loss: 0.086313, loss_s1: 0.059698, loss_fp: 0.002801, loss_freq: 0.042955
[15:21:02.700] iteration 18912: loss: 0.075204, loss_s1: 0.051219, loss_fp: 0.004358, loss_freq: 0.051384
[15:21:03.316] iteration 18913: loss: 0.037423, loss_s1: 0.014175, loss_fp: 0.001604, loss_freq: 0.012738
[15:21:03.934] iteration 18914: loss: 0.057857, loss_s1: 0.051842, loss_fp: 0.003479, loss_freq: 0.020123
[15:21:04.551] iteration 18915: loss: 0.082955, loss_s1: 0.060386, loss_fp: 0.008837, loss_freq: 0.036329
[15:21:05.169] iteration 18916: loss: 0.048125, loss_s1: 0.030255, loss_fp: 0.002368, loss_freq: 0.022528
[15:21:05.790] iteration 18917: loss: 0.052549, loss_s1: 0.029371, loss_fp: 0.003690, loss_freq: 0.013154
[15:21:06.415] iteration 18918: loss: 0.035834, loss_s1: 0.027120, loss_fp: 0.000741, loss_freq: 0.013418
[15:21:07.043] iteration 18919: loss: 0.038961, loss_s1: 0.024308, loss_fp: 0.000624, loss_freq: 0.011304
[15:21:07.655] iteration 18920: loss: 0.052792, loss_s1: 0.039339, loss_fp: 0.002485, loss_freq: 0.024280
[15:21:08.287] iteration 18921: loss: 0.043660, loss_s1: 0.030570, loss_fp: 0.001809, loss_freq: 0.002118
[15:21:08.976] iteration 18922: loss: 0.104317, loss_s1: 0.095035, loss_fp: 0.001518, loss_freq: 0.035741
[15:21:09.602] iteration 18923: loss: 0.052168, loss_s1: 0.028536, loss_fp: 0.002836, loss_freq: 0.031631
[15:21:10.235] iteration 18924: loss: 0.064438, loss_s1: 0.062945, loss_fp: 0.009351, loss_freq: 0.010569
[15:21:10.854] iteration 18925: loss: 0.070337, loss_s1: 0.064346, loss_fp: 0.003081, loss_freq: 0.040257
[15:21:11.468] iteration 18926: loss: 0.054981, loss_s1: 0.039738, loss_fp: 0.006892, loss_freq: 0.022178
[15:21:12.081] iteration 18927: loss: 0.048606, loss_s1: 0.030312, loss_fp: 0.003423, loss_freq: 0.016224
[15:21:12.759] iteration 18928: loss: 0.046777, loss_s1: 0.023875, loss_fp: 0.006516, loss_freq: 0.018575
[15:21:13.383] iteration 18929: loss: 0.034156, loss_s1: 0.025385, loss_fp: 0.002869, loss_freq: 0.005651
[15:21:13.998] iteration 18930: loss: 0.055012, loss_s1: 0.051346, loss_fp: 0.002128, loss_freq: 0.021239
[15:21:14.624] iteration 18931: loss: 0.034407, loss_s1: 0.027320, loss_fp: 0.003792, loss_freq: 0.004037
[15:21:15.250] iteration 18932: loss: 0.050723, loss_s1: 0.024952, loss_fp: 0.001360, loss_freq: 0.010586
[15:21:15.865] iteration 18933: loss: 0.072115, loss_s1: 0.088831, loss_fp: 0.003462, loss_freq: 0.015559
[15:21:16.491] iteration 18934: loss: 0.035976, loss_s1: 0.017503, loss_fp: 0.001260, loss_freq: 0.012922
[15:21:17.129] iteration 18935: loss: 0.066385, loss_s1: 0.035222, loss_fp: 0.000748, loss_freq: 0.057062
[15:21:17.740] iteration 18936: loss: 0.061897, loss_s1: 0.064806, loss_fp: 0.006350, loss_freq: 0.015049
[15:21:18.358] iteration 18937: loss: 0.050228, loss_s1: 0.030823, loss_fp: 0.004667, loss_freq: 0.016571
[15:21:19.036] iteration 18938: loss: 0.044173, loss_s1: 0.038820, loss_fp: 0.001153, loss_freq: 0.005608
[15:21:19.666] iteration 18939: loss: 0.067956, loss_s1: 0.047096, loss_fp: 0.007593, loss_freq: 0.040733
[15:21:20.296] iteration 18940: loss: 0.069292, loss_s1: 0.034626, loss_fp: 0.002418, loss_freq: 0.012619
[15:21:20.923] iteration 18941: loss: 0.063873, loss_s1: 0.061190, loss_fp: 0.001601, loss_freq: 0.014544
[15:21:21.544] iteration 18942: loss: 0.066060, loss_s1: 0.029051, loss_fp: 0.002712, loss_freq: 0.031729
[15:21:22.174] iteration 18943: loss: 0.075591, loss_s1: 0.038445, loss_fp: 0.013106, loss_freq: 0.021587
[15:21:22.909] iteration 18944: loss: 0.058740, loss_s1: 0.031099, loss_fp: 0.001404, loss_freq: 0.046855
[15:21:23.680] iteration 18945: loss: 0.050175, loss_s1: 0.021745, loss_fp: 0.016414, loss_freq: 0.021753
[15:21:24.359] iteration 18946: loss: 0.076941, loss_s1: 0.050030, loss_fp: 0.002655, loss_freq: 0.023945
[15:21:24.986] iteration 18947: loss: 0.051035, loss_s1: 0.033915, loss_fp: 0.005597, loss_freq: 0.017199
[15:21:25.617] iteration 18948: loss: 0.074000, loss_s1: 0.043948, loss_fp: 0.007627, loss_freq: 0.042625
[15:21:26.236] iteration 18949: loss: 0.062762, loss_s1: 0.057605, loss_fp: 0.013472, loss_freq: 0.011896
[15:21:26.857] iteration 18950: loss: 0.087947, loss_s1: 0.074325, loss_fp: 0.017835, loss_freq: 0.027661
[15:21:27.487] iteration 18951: loss: 0.090080, loss_s1: 0.066324, loss_fp: 0.015507, loss_freq: 0.066213
[15:21:28.124] iteration 18952: loss: 0.068278, loss_s1: 0.026360, loss_fp: 0.008358, loss_freq: 0.017380
[15:21:28.744] iteration 18953: loss: 0.053799, loss_s1: 0.051275, loss_fp: 0.002507, loss_freq: 0.007059
[15:21:29.372] iteration 18954: loss: 0.061487, loss_s1: 0.028211, loss_fp: 0.007060, loss_freq: 0.030843
[15:21:29.994] iteration 18955: loss: 0.079169, loss_s1: 0.062893, loss_fp: 0.016356, loss_freq: 0.034840
[15:21:30.620] iteration 18956: loss: 0.121158, loss_s1: 0.146318, loss_fp: 0.022497, loss_freq: 0.021768
[15:21:31.235] iteration 18957: loss: 0.077768, loss_s1: 0.092848, loss_fp: 0.001393, loss_freq: 0.016373
[15:21:31.859] iteration 18958: loss: 0.049196, loss_s1: 0.024407, loss_fp: 0.004820, loss_freq: 0.024186
[15:21:32.479] iteration 18959: loss: 0.092287, loss_s1: 0.078868, loss_fp: 0.003512, loss_freq: 0.058826
[15:21:33.105] iteration 18960: loss: 0.041544, loss_s1: 0.036521, loss_fp: 0.002455, loss_freq: 0.013447
[15:21:33.722] iteration 18961: loss: 0.066843, loss_s1: 0.051947, loss_fp: 0.005638, loss_freq: 0.024773
[15:21:34.346] iteration 18962: loss: 0.055039, loss_s1: 0.018376, loss_fp: 0.000881, loss_freq: 0.051320
[15:21:34.962] iteration 18963: loss: 0.074159, loss_s1: 0.070104, loss_fp: 0.002115, loss_freq: 0.021329
[15:21:35.615] iteration 18964: loss: 0.043309, loss_s1: 0.033779, loss_fp: 0.002047, loss_freq: 0.015726
[15:21:36.231] iteration 18965: loss: 0.053611, loss_s1: 0.060483, loss_fp: 0.000330, loss_freq: 0.008237
[15:21:36.852] iteration 18966: loss: 0.060625, loss_s1: 0.046469, loss_fp: 0.007846, loss_freq: 0.026769
[15:21:37.472] iteration 18967: loss: 0.062760, loss_s1: 0.023317, loss_fp: 0.002811, loss_freq: 0.039053
[15:21:38.096] iteration 18968: loss: 0.070768, loss_s1: 0.052363, loss_fp: 0.008247, loss_freq: 0.019223
[15:21:38.723] iteration 18969: loss: 0.052461, loss_s1: 0.036501, loss_fp: 0.001304, loss_freq: 0.003339
[15:21:39.515] iteration 18970: loss: 0.055769, loss_s1: 0.059409, loss_fp: 0.003697, loss_freq: 0.010830
[15:21:40.209] iteration 18971: loss: 0.034676, loss_s1: 0.006481, loss_fp: 0.003136, loss_freq: 0.016212
[15:21:40.951] iteration 18972: loss: 0.040376, loss_s1: 0.024190, loss_fp: 0.001091, loss_freq: 0.008266
[15:21:41.626] iteration 18973: loss: 0.080494, loss_s1: 0.061589, loss_fp: 0.003106, loss_freq: 0.047336
[15:21:42.243] iteration 18974: loss: 0.043903, loss_s1: 0.013252, loss_fp: 0.002927, loss_freq: 0.026044
[15:21:42.913] iteration 18975: loss: 0.062515, loss_s1: 0.039158, loss_fp: 0.003140, loss_freq: 0.014519
[15:21:43.549] iteration 18976: loss: 0.088880, loss_s1: 0.071202, loss_fp: 0.002020, loss_freq: 0.056429
[15:21:44.170] iteration 18977: loss: 0.052915, loss_s1: 0.045380, loss_fp: 0.001982, loss_freq: 0.017006
[15:21:44.795] iteration 18978: loss: 0.052898, loss_s1: 0.022910, loss_fp: 0.001430, loss_freq: 0.033242
[15:21:45.420] iteration 18979: loss: 0.048901, loss_s1: 0.032549, loss_fp: 0.003633, loss_freq: 0.017358
[15:21:46.036] iteration 18980: loss: 0.044751, loss_s1: 0.020873, loss_fp: 0.001955, loss_freq: 0.015080
[15:21:46.659] iteration 18981: loss: 0.047427, loss_s1: 0.014406, loss_fp: 0.001634, loss_freq: 0.016409
[15:21:47.274] iteration 18982: loss: 0.041907, loss_s1: 0.009445, loss_fp: 0.001476, loss_freq: 0.023597
[15:21:47.903] iteration 18983: loss: 0.103382, loss_s1: 0.088570, loss_fp: 0.001944, loss_freq: 0.059209
[15:21:48.522] iteration 18984: loss: 0.039095, loss_s1: 0.018671, loss_fp: 0.003079, loss_freq: 0.023279
[15:21:49.142] iteration 18985: loss: 0.067631, loss_s1: 0.025372, loss_fp: 0.003407, loss_freq: 0.039984
[15:21:49.826] iteration 18986: loss: 0.042512, loss_s1: 0.029703, loss_fp: 0.001763, loss_freq: 0.016900
[15:21:50.471] iteration 18987: loss: 0.042151, loss_s1: 0.034293, loss_fp: 0.004778, loss_freq: 0.005584
[15:21:51.116] iteration 18988: loss: 0.078527, loss_s1: 0.078568, loss_fp: 0.003510, loss_freq: 0.040553
[15:21:51.758] iteration 18989: loss: 0.056169, loss_s1: 0.036650, loss_fp: 0.002120, loss_freq: 0.011125
[15:21:52.401] iteration 18990: loss: 0.058485, loss_s1: 0.040417, loss_fp: 0.002679, loss_freq: 0.018768
[15:21:53.044] iteration 18991: loss: 0.064963, loss_s1: 0.016719, loss_fp: 0.004528, loss_freq: 0.019484
[15:21:53.663] iteration 18992: loss: 0.052918, loss_s1: 0.031606, loss_fp: 0.004542, loss_freq: 0.013055
[15:21:54.289] iteration 18993: loss: 0.067714, loss_s1: 0.046191, loss_fp: 0.012869, loss_freq: 0.031183
[15:21:54.909] iteration 18994: loss: 0.074584, loss_s1: 0.072337, loss_fp: 0.000736, loss_freq: 0.015983
[15:21:55.529] iteration 18995: loss: 0.043830, loss_s1: 0.029713, loss_fp: 0.000546, loss_freq: 0.018579
[15:21:56.149] iteration 18996: loss: 0.080663, loss_s1: 0.064349, loss_fp: 0.001536, loss_freq: 0.048599
[15:21:56.777] iteration 18997: loss: 0.051893, loss_s1: 0.033128, loss_fp: 0.001666, loss_freq: 0.027757
[15:21:57.401] iteration 18998: loss: 0.097368, loss_s1: 0.058748, loss_fp: 0.001795, loss_freq: 0.020169
[15:21:58.024] iteration 18999: loss: 0.046793, loss_s1: 0.026159, loss_fp: 0.001673, loss_freq: 0.014098
[15:21:58.642] iteration 19000: loss: 0.048535, loss_s1: 0.029799, loss_fp: 0.002288, loss_freq: 0.036382
[15:22:02.122] iteration 19000 : mean_dice : 0.773995
[15:22:02.798] iteration 19001: loss: 0.059459, loss_s1: 0.040102, loss_fp: 0.008900, loss_freq: 0.031237
[15:22:03.418] iteration 19002: loss: 0.076852, loss_s1: 0.056567, loss_fp: 0.002937, loss_freq: 0.016434
[15:22:04.033] iteration 19003: loss: 0.044088, loss_s1: 0.018759, loss_fp: 0.001399, loss_freq: 0.034594
[15:22:04.672] iteration 19004: loss: 0.054446, loss_s1: 0.044017, loss_fp: 0.001244, loss_freq: 0.025466
[15:22:05.304] iteration 19005: loss: 0.062627, loss_s1: 0.055550, loss_fp: 0.003345, loss_freq: 0.007201
[15:22:05.938] iteration 19006: loss: 0.044198, loss_s1: 0.019170, loss_fp: 0.005911, loss_freq: 0.019350
[15:22:06.598] iteration 19007: loss: 0.063751, loss_s1: 0.063723, loss_fp: 0.002359, loss_freq: 0.015439
[15:22:07.241] iteration 19008: loss: 0.105438, loss_s1: 0.078133, loss_fp: 0.007965, loss_freq: 0.048709
[15:22:07.885] iteration 19009: loss: 0.060745, loss_s1: 0.028594, loss_fp: 0.003389, loss_freq: 0.037622
[15:22:08.523] iteration 19010: loss: 0.084333, loss_s1: 0.046361, loss_fp: 0.001083, loss_freq: 0.059218
[15:22:09.164] iteration 19011: loss: 0.075984, loss_s1: 0.037233, loss_fp: 0.003940, loss_freq: 0.040510
[15:22:09.788] iteration 19012: loss: 0.044529, loss_s1: 0.032047, loss_fp: 0.004780, loss_freq: 0.013053
[15:22:10.404] iteration 19013: loss: 0.070175, loss_s1: 0.025031, loss_fp: 0.007045, loss_freq: 0.047912
[15:22:11.058] iteration 19014: loss: 0.031345, loss_s1: 0.012481, loss_fp: 0.002953, loss_freq: 0.013812
[15:22:11.682] iteration 19015: loss: 0.045093, loss_s1: 0.030972, loss_fp: 0.001120, loss_freq: 0.008003
[15:22:12.304] iteration 19016: loss: 0.040878, loss_s1: 0.015008, loss_fp: 0.002455, loss_freq: 0.012201
[15:22:12.924] iteration 19017: loss: 0.075514, loss_s1: 0.066485, loss_fp: 0.001615, loss_freq: 0.040069
[15:22:13.537] iteration 19018: loss: 0.100164, loss_s1: 0.106482, loss_fp: 0.008932, loss_freq: 0.038138
[15:22:14.149] iteration 19019: loss: 0.048327, loss_s1: 0.047931, loss_fp: 0.001678, loss_freq: 0.018502
[15:22:15.086] iteration 19020: loss: 0.046371, loss_s1: 0.026908, loss_fp: 0.000739, loss_freq: 0.006608
[15:22:15.747] iteration 19021: loss: 0.054972, loss_s1: 0.042084, loss_fp: 0.004394, loss_freq: 0.016371
[15:22:16.366] iteration 19022: loss: 0.043884, loss_s1: 0.025771, loss_fp: 0.002558, loss_freq: 0.011903
[15:22:16.983] iteration 19023: loss: 0.067400, loss_s1: 0.046255, loss_fp: 0.002968, loss_freq: 0.027325
[15:22:17.606] iteration 19024: loss: 0.068218, loss_s1: 0.078791, loss_fp: 0.002137, loss_freq: 0.019047
[15:22:18.221] iteration 19025: loss: 0.029354, loss_s1: 0.015285, loss_fp: 0.001774, loss_freq: 0.003567
[15:22:18.841] iteration 19026: loss: 0.040368, loss_s1: 0.034751, loss_fp: 0.003050, loss_freq: 0.010835
[15:22:19.488] iteration 19027: loss: 0.102525, loss_s1: 0.093342, loss_fp: 0.007195, loss_freq: 0.042677
[15:22:20.106] iteration 19028: loss: 0.062925, loss_s1: 0.036425, loss_fp: 0.007531, loss_freq: 0.027584
[15:22:20.762] iteration 19029: loss: 0.046005, loss_s1: 0.013849, loss_fp: 0.000796, loss_freq: 0.004292
[15:22:21.383] iteration 19030: loss: 0.068775, loss_s1: 0.030425, loss_fp: 0.001900, loss_freq: 0.041292
[15:22:21.998] iteration 19031: loss: 0.060181, loss_s1: 0.035847, loss_fp: 0.003231, loss_freq: 0.021111
[15:22:22.611] iteration 19032: loss: 0.071287, loss_s1: 0.066537, loss_fp: 0.003344, loss_freq: 0.009315
[15:22:23.231] iteration 19033: loss: 0.029292, loss_s1: 0.014645, loss_fp: 0.000383, loss_freq: 0.006739
[15:22:23.846] iteration 19034: loss: 0.046311, loss_s1: 0.037268, loss_fp: 0.000672, loss_freq: 0.016633
[15:22:24.486] iteration 19035: loss: 0.061990, loss_s1: 0.040717, loss_fp: 0.001427, loss_freq: 0.034729
[15:22:25.147] iteration 19036: loss: 0.058455, loss_s1: 0.046639, loss_fp: 0.001009, loss_freq: 0.032550
[15:22:25.813] iteration 19037: loss: 0.053114, loss_s1: 0.040536, loss_fp: 0.005264, loss_freq: 0.015980
[15:22:26.436] iteration 19038: loss: 0.055413, loss_s1: 0.038920, loss_fp: 0.001882, loss_freq: 0.023187
[15:22:27.060] iteration 19039: loss: 0.032907, loss_s1: 0.018317, loss_fp: 0.000815, loss_freq: 0.009710
[15:22:27.677] iteration 19040: loss: 0.070738, loss_s1: 0.019540, loss_fp: 0.003985, loss_freq: 0.038405
[15:22:28.305] iteration 19041: loss: 0.065099, loss_s1: 0.066581, loss_fp: 0.003017, loss_freq: 0.026524
[15:22:28.926] iteration 19042: loss: 0.043143, loss_s1: 0.020874, loss_fp: 0.003174, loss_freq: 0.028120
[15:22:29.570] iteration 19043: loss: 0.079987, loss_s1: 0.031867, loss_fp: 0.002530, loss_freq: 0.012584
[15:22:30.246] iteration 19044: loss: 0.050463, loss_s1: 0.045163, loss_fp: 0.002905, loss_freq: 0.007051
[15:22:30.870] iteration 19045: loss: 0.095752, loss_s1: 0.088775, loss_fp: 0.002982, loss_freq: 0.058893
[15:22:31.486] iteration 19046: loss: 0.094354, loss_s1: 0.073044, loss_fp: 0.002163, loss_freq: 0.071992
[15:22:32.096] iteration 19047: loss: 0.047896, loss_s1: 0.045277, loss_fp: 0.001823, loss_freq: 0.005145
[15:22:32.718] iteration 19048: loss: 0.063078, loss_s1: 0.036384, loss_fp: 0.001868, loss_freq: 0.018932
[15:22:33.334] iteration 19049: loss: 0.039466, loss_s1: 0.021189, loss_fp: 0.000392, loss_freq: 0.008633
[15:22:33.947] iteration 19050: loss: 0.054618, loss_s1: 0.029652, loss_fp: 0.001759, loss_freq: 0.018301
[15:22:34.562] iteration 19051: loss: 0.052731, loss_s1: 0.018483, loss_fp: 0.003482, loss_freq: 0.024358
[15:22:35.176] iteration 19052: loss: 0.080046, loss_s1: 0.062357, loss_fp: 0.009794, loss_freq: 0.056914
[15:22:35.793] iteration 19053: loss: 0.085028, loss_s1: 0.086776, loss_fp: 0.006276, loss_freq: 0.043887
[15:22:36.413] iteration 19054: loss: 0.086156, loss_s1: 0.067447, loss_fp: 0.005598, loss_freq: 0.033049
[15:22:37.077] iteration 19055: loss: 0.091014, loss_s1: 0.077353, loss_fp: 0.002980, loss_freq: 0.050764
[15:22:37.688] iteration 19056: loss: 0.040725, loss_s1: 0.021454, loss_fp: 0.001802, loss_freq: 0.015930
[15:22:38.314] iteration 19057: loss: 0.074026, loss_s1: 0.068986, loss_fp: 0.004916, loss_freq: 0.026371
[15:22:38.924] iteration 19058: loss: 0.060814, loss_s1: 0.020741, loss_fp: 0.004316, loss_freq: 0.028276
[15:22:39.542] iteration 19059: loss: 0.032734, loss_s1: 0.020161, loss_fp: 0.002226, loss_freq: 0.007608
[15:22:40.165] iteration 19060: loss: 0.057783, loss_s1: 0.043367, loss_fp: 0.003926, loss_freq: 0.020827
[15:22:40.788] iteration 19061: loss: 0.048849, loss_s1: 0.049326, loss_fp: 0.000788, loss_freq: 0.019457
[15:22:41.408] iteration 19062: loss: 0.067835, loss_s1: 0.054881, loss_fp: 0.009076, loss_freq: 0.030198
[15:22:42.033] iteration 19063: loss: 0.060902, loss_s1: 0.034944, loss_fp: 0.002139, loss_freq: 0.034506
[15:22:42.656] iteration 19064: loss: 0.059299, loss_s1: 0.014080, loss_fp: 0.008384, loss_freq: 0.008820
[15:22:43.283] iteration 19065: loss: 0.077800, loss_s1: 0.081771, loss_fp: 0.005737, loss_freq: 0.026419
[15:22:43.901] iteration 19066: loss: 0.055686, loss_s1: 0.028485, loss_fp: 0.002374, loss_freq: 0.033917
[15:22:44.514] iteration 19067: loss: 0.062627, loss_s1: 0.038354, loss_fp: 0.004577, loss_freq: 0.040888
[15:22:45.130] iteration 19068: loss: 0.061126, loss_s1: 0.035766, loss_fp: 0.002971, loss_freq: 0.053517
[15:22:45.747] iteration 19069: loss: 0.052130, loss_s1: 0.018955, loss_fp: 0.003712, loss_freq: 0.026237
[15:22:46.373] iteration 19070: loss: 0.044699, loss_s1: 0.033310, loss_fp: 0.005649, loss_freq: 0.014460
[15:22:46.989] iteration 19071: loss: 0.054496, loss_s1: 0.022707, loss_fp: 0.008196, loss_freq: 0.022945
[15:22:47.601] iteration 19072: loss: 0.050050, loss_s1: 0.026925, loss_fp: 0.002921, loss_freq: 0.016091
[15:22:48.215] iteration 19073: loss: 0.045252, loss_s1: 0.023103, loss_fp: 0.010851, loss_freq: 0.025033
[15:22:48.831] iteration 19074: loss: 0.047848, loss_s1: 0.038434, loss_fp: 0.004597, loss_freq: 0.014701
[15:22:49.448] iteration 19075: loss: 0.059088, loss_s1: 0.026141, loss_fp: 0.003466, loss_freq: 0.020298
[15:22:50.063] iteration 19076: loss: 0.055449, loss_s1: 0.045403, loss_fp: 0.001732, loss_freq: 0.023373
[15:22:50.685] iteration 19077: loss: 0.049838, loss_s1: 0.029396, loss_fp: 0.009032, loss_freq: 0.016702
[15:22:51.308] iteration 19078: loss: 0.068288, loss_s1: 0.041897, loss_fp: 0.000705, loss_freq: 0.040887
[15:22:51.917] iteration 19079: loss: 0.064482, loss_s1: 0.055959, loss_fp: 0.004778, loss_freq: 0.029165
[15:22:52.593] iteration 19080: loss: 0.037301, loss_s1: 0.015612, loss_fp: 0.003600, loss_freq: 0.016296
[15:22:53.204] iteration 19081: loss: 0.060361, loss_s1: 0.051599, loss_fp: 0.001165, loss_freq: 0.018147
[15:22:53.825] iteration 19082: loss: 0.075403, loss_s1: 0.029463, loss_fp: 0.011182, loss_freq: 0.056054
[15:22:54.439] iteration 19083: loss: 0.061371, loss_s1: 0.036332, loss_fp: 0.002457, loss_freq: 0.022753
[15:22:55.100] iteration 19084: loss: 0.059645, loss_s1: 0.027024, loss_fp: 0.006240, loss_freq: 0.021898
[15:22:55.719] iteration 19085: loss: 0.047796, loss_s1: 0.036416, loss_fp: 0.006984, loss_freq: 0.018076
[15:22:56.339] iteration 19086: loss: 0.097669, loss_s1: 0.063922, loss_fp: 0.003097, loss_freq: 0.059353
[15:22:56.972] iteration 19087: loss: 0.050830, loss_s1: 0.031617, loss_fp: 0.003582, loss_freq: 0.015298
[15:22:57.588] iteration 19088: loss: 0.069548, loss_s1: 0.067731, loss_fp: 0.002737, loss_freq: 0.024752
[15:22:58.236] iteration 19089: loss: 0.050437, loss_s1: 0.021928, loss_fp: 0.004152, loss_freq: 0.004953
[15:22:58.884] iteration 19090: loss: 0.057459, loss_s1: 0.038182, loss_fp: 0.002119, loss_freq: 0.016700
[15:22:59.501] iteration 19091: loss: 0.062932, loss_s1: 0.058412, loss_fp: 0.002438, loss_freq: 0.022168
[15:23:00.128] iteration 19092: loss: 0.037735, loss_s1: 0.020761, loss_fp: 0.001845, loss_freq: 0.015019
[15:23:00.747] iteration 19093: loss: 0.085754, loss_s1: 0.067461, loss_fp: 0.006933, loss_freq: 0.040483
[15:23:01.371] iteration 19094: loss: 0.067334, loss_s1: 0.044433, loss_fp: 0.013237, loss_freq: 0.042648
[15:23:01.988] iteration 19095: loss: 0.079431, loss_s1: 0.057094, loss_fp: 0.001147, loss_freq: 0.016938
[15:23:02.612] iteration 19096: loss: 0.069535, loss_s1: 0.036041, loss_fp: 0.006003, loss_freq: 0.015795
[15:23:03.242] iteration 19097: loss: 0.058514, loss_s1: 0.051723, loss_fp: 0.002189, loss_freq: 0.012873
[15:23:03.921] iteration 19098: loss: 0.108312, loss_s1: 0.097931, loss_fp: 0.016084, loss_freq: 0.064489
[15:23:04.547] iteration 19099: loss: 0.068131, loss_s1: 0.031206, loss_fp: 0.004415, loss_freq: 0.025467
[15:23:05.165] iteration 19100: loss: 0.074115, loss_s1: 0.042464, loss_fp: 0.001543, loss_freq: 0.055818
[15:23:05.781] iteration 19101: loss: 0.052555, loss_s1: 0.031403, loss_fp: 0.002647, loss_freq: 0.036152
[15:23:06.408] iteration 19102: loss: 0.055820, loss_s1: 0.037294, loss_fp: 0.001106, loss_freq: 0.034784
[15:23:07.041] iteration 19103: loss: 0.053283, loss_s1: 0.053218, loss_fp: 0.003043, loss_freq: 0.017026
[15:23:07.705] iteration 19104: loss: 0.050924, loss_s1: 0.043254, loss_fp: 0.001669, loss_freq: 0.015135
[15:23:08.355] iteration 19105: loss: 0.064294, loss_s1: 0.035203, loss_fp: 0.002149, loss_freq: 0.050132
[15:23:08.989] iteration 19106: loss: 0.044468, loss_s1: 0.044032, loss_fp: 0.001345, loss_freq: 0.002623
[15:23:09.621] iteration 19107: loss: 0.039980, loss_s1: 0.013625, loss_fp: 0.000864, loss_freq: 0.012885
[15:23:10.239] iteration 19108: loss: 0.060421, loss_s1: 0.041881, loss_fp: 0.003012, loss_freq: 0.009718
[15:23:10.869] iteration 19109: loss: 0.081197, loss_s1: 0.061950, loss_fp: 0.003571, loss_freq: 0.013217
[15:23:11.488] iteration 19110: loss: 0.056427, loss_s1: 0.016039, loss_fp: 0.001345, loss_freq: 0.024658
[15:23:12.116] iteration 19111: loss: 0.057709, loss_s1: 0.068900, loss_fp: 0.002201, loss_freq: 0.010941
[15:23:12.738] iteration 19112: loss: 0.044574, loss_s1: 0.021538, loss_fp: 0.000937, loss_freq: 0.006039
[15:23:13.356] iteration 19113: loss: 0.049511, loss_s1: 0.022817, loss_fp: 0.009391, loss_freq: 0.013961
[15:23:13.976] iteration 19114: loss: 0.031104, loss_s1: 0.009162, loss_fp: 0.000732, loss_freq: 0.011355
[15:23:14.597] iteration 19115: loss: 0.037856, loss_s1: 0.013740, loss_fp: 0.001135, loss_freq: 0.010247
[15:23:15.216] iteration 19116: loss: 0.090245, loss_s1: 0.072853, loss_fp: 0.004509, loss_freq: 0.035816
[15:23:15.842] iteration 19117: loss: 0.067732, loss_s1: 0.060500, loss_fp: 0.002098, loss_freq: 0.014778
[15:23:16.461] iteration 19118: loss: 0.053423, loss_s1: 0.038428, loss_fp: 0.002058, loss_freq: 0.017781
[15:23:17.084] iteration 19119: loss: 0.102084, loss_s1: 0.051679, loss_fp: 0.003411, loss_freq: 0.053921
[15:23:17.703] iteration 19120: loss: 0.077270, loss_s1: 0.042036, loss_fp: 0.006773, loss_freq: 0.028058
[15:23:18.323] iteration 19121: loss: 0.083526, loss_s1: 0.056987, loss_fp: 0.002412, loss_freq: 0.041772
[15:23:18.943] iteration 19122: loss: 0.057006, loss_s1: 0.030424, loss_fp: 0.003178, loss_freq: 0.041432
[15:23:19.567] iteration 19123: loss: 0.052367, loss_s1: 0.055680, loss_fp: 0.003264, loss_freq: 0.008689
[15:23:20.189] iteration 19124: loss: 0.067276, loss_s1: 0.032864, loss_fp: 0.002052, loss_freq: 0.009896
[15:23:20.811] iteration 19125: loss: 0.050717, loss_s1: 0.048265, loss_fp: 0.001775, loss_freq: 0.017220
[15:23:21.429] iteration 19126: loss: 0.109058, loss_s1: 0.098447, loss_fp: 0.013478, loss_freq: 0.061477
[15:23:22.042] iteration 19127: loss: 0.069154, loss_s1: 0.043102, loss_fp: 0.005850, loss_freq: 0.048577
[15:23:22.655] iteration 19128: loss: 0.048426, loss_s1: 0.020612, loss_fp: 0.001841, loss_freq: 0.014575
[15:23:23.278] iteration 19129: loss: 0.045469, loss_s1: 0.043285, loss_fp: 0.004322, loss_freq: 0.010083
[15:23:23.957] iteration 19130: loss: 0.054430, loss_s1: 0.025292, loss_fp: 0.002257, loss_freq: 0.029861
[15:23:24.600] iteration 19131: loss: 0.071143, loss_s1: 0.068518, loss_fp: 0.001757, loss_freq: 0.041595
[15:23:25.232] iteration 19132: loss: 0.068718, loss_s1: 0.027571, loss_fp: 0.000923, loss_freq: 0.049469
[15:23:25.866] iteration 19133: loss: 0.050016, loss_s1: 0.032371, loss_fp: 0.001389, loss_freq: 0.020820
[15:23:26.547] iteration 19134: loss: 0.067195, loss_s1: 0.034482, loss_fp: 0.001243, loss_freq: 0.018430
[15:23:27.202] iteration 19135: loss: 0.040977, loss_s1: 0.017082, loss_fp: 0.000783, loss_freq: 0.019700
[15:23:27.845] iteration 19136: loss: 0.049106, loss_s1: 0.031827, loss_fp: 0.003670, loss_freq: 0.021155
[15:23:28.528] iteration 19137: loss: 0.086683, loss_s1: 0.106930, loss_fp: 0.006936, loss_freq: 0.017722
[15:23:29.156] iteration 19138: loss: 0.070263, loss_s1: 0.068558, loss_fp: 0.002945, loss_freq: 0.027599
[15:23:29.774] iteration 19139: loss: 0.051298, loss_s1: 0.032225, loss_fp: 0.001528, loss_freq: 0.032368
[15:23:30.397] iteration 19140: loss: 0.060593, loss_s1: 0.043915, loss_fp: 0.002222, loss_freq: 0.019854
[15:23:31.019] iteration 19141: loss: 0.069182, loss_s1: 0.046420, loss_fp: 0.014198, loss_freq: 0.021244
[15:23:31.641] iteration 19142: loss: 0.050101, loss_s1: 0.025211, loss_fp: 0.000788, loss_freq: 0.007671
[15:23:32.333] iteration 19143: loss: 0.042748, loss_s1: 0.019854, loss_fp: 0.002114, loss_freq: 0.013193
[15:23:33.011] iteration 19144: loss: 0.082296, loss_s1: 0.095649, loss_fp: 0.004442, loss_freq: 0.025258
[15:23:33.681] iteration 19145: loss: 0.073382, loss_s1: 0.057982, loss_fp: 0.002230, loss_freq: 0.006884
[15:23:34.307] iteration 19146: loss: 0.068216, loss_s1: 0.032337, loss_fp: 0.000628, loss_freq: 0.069355
[15:23:34.919] iteration 19147: loss: 0.068377, loss_s1: 0.078394, loss_fp: 0.000845, loss_freq: 0.021933
[15:23:35.539] iteration 19148: loss: 0.098078, loss_s1: 0.117873, loss_fp: 0.001835, loss_freq: 0.026383
[15:23:36.161] iteration 19149: loss: 0.048374, loss_s1: 0.034993, loss_fp: 0.004464, loss_freq: 0.014160
[15:23:36.780] iteration 19150: loss: 0.054063, loss_s1: 0.043442, loss_fp: 0.002838, loss_freq: 0.013556
[15:23:37.413] iteration 19151: loss: 0.073647, loss_s1: 0.075240, loss_fp: 0.002556, loss_freq: 0.013427
[15:23:38.082] iteration 19152: loss: 0.093653, loss_s1: 0.095281, loss_fp: 0.002985, loss_freq: 0.019275
[15:23:38.725] iteration 19153: loss: 0.097104, loss_s1: 0.077746, loss_fp: 0.005217, loss_freq: 0.050411
[15:23:39.392] iteration 19154: loss: 0.055145, loss_s1: 0.037120, loss_fp: 0.003499, loss_freq: 0.024944
[15:23:40.006] iteration 19155: loss: 0.075488, loss_s1: 0.058872, loss_fp: 0.004791, loss_freq: 0.035077
[15:23:40.667] iteration 19156: loss: 0.083319, loss_s1: 0.065743, loss_fp: 0.001346, loss_freq: 0.022767
[15:23:41.282] iteration 19157: loss: 0.033112, loss_s1: 0.015345, loss_fp: 0.000501, loss_freq: 0.010703
[15:23:41.899] iteration 19158: loss: 0.045285, loss_s1: 0.032533, loss_fp: 0.001329, loss_freq: 0.017623
[15:23:42.528] iteration 19159: loss: 0.106668, loss_s1: 0.090134, loss_fp: 0.004380, loss_freq: 0.021608
[15:23:43.157] iteration 19160: loss: 0.059497, loss_s1: 0.042069, loss_fp: 0.001347, loss_freq: 0.025980
[15:23:43.769] iteration 19161: loss: 0.058500, loss_s1: 0.047405, loss_fp: 0.001814, loss_freq: 0.022738
[15:23:44.630] iteration 19162: loss: 0.036171, loss_s1: 0.007119, loss_fp: 0.003155, loss_freq: 0.023638
[15:23:45.890] iteration 19163: loss: 0.035069, loss_s1: 0.017659, loss_fp: 0.002159, loss_freq: 0.006982
[15:23:46.618] iteration 19164: loss: 0.056580, loss_s1: 0.028016, loss_fp: 0.002806, loss_freq: 0.023760
[15:23:47.243] iteration 19165: loss: 0.047400, loss_s1: 0.023625, loss_fp: 0.000900, loss_freq: 0.033748
[15:23:47.862] iteration 19166: loss: 0.073149, loss_s1: 0.032593, loss_fp: 0.001437, loss_freq: 0.032390
[15:23:48.492] iteration 19167: loss: 0.067360, loss_s1: 0.039377, loss_fp: 0.002360, loss_freq: 0.034517
[15:23:49.111] iteration 19168: loss: 0.052864, loss_s1: 0.040107, loss_fp: 0.001858, loss_freq: 0.007065
[15:23:49.732] iteration 19169: loss: 0.044024, loss_s1: 0.037290, loss_fp: 0.003087, loss_freq: 0.016538
[15:23:50.351] iteration 19170: loss: 0.086918, loss_s1: 0.083852, loss_fp: 0.000404, loss_freq: 0.034219
[15:23:50.966] iteration 19171: loss: 0.063176, loss_s1: 0.055238, loss_fp: 0.009846, loss_freq: 0.023008
[15:23:51.591] iteration 19172: loss: 0.047685, loss_s1: 0.018347, loss_fp: 0.000186, loss_freq: 0.005363
[15:23:52.208] iteration 19173: loss: 0.053055, loss_s1: 0.011987, loss_fp: 0.011368, loss_freq: 0.033770
[15:23:52.836] iteration 19174: loss: 0.031593, loss_s1: 0.009339, loss_fp: 0.002189, loss_freq: 0.014769
[15:23:53.476] iteration 19175: loss: 0.063465, loss_s1: 0.046816, loss_fp: 0.001613, loss_freq: 0.033477
[15:23:54.091] iteration 19176: loss: 0.039199, loss_s1: 0.024392, loss_fp: 0.001175, loss_freq: 0.022852
[15:23:54.712] iteration 19177: loss: 0.106239, loss_s1: 0.104019, loss_fp: 0.002199, loss_freq: 0.057894
[15:23:55.340] iteration 19178: loss: 0.032776, loss_s1: 0.012214, loss_fp: 0.000663, loss_freq: 0.016294
[15:23:55.960] iteration 19179: loss: 0.038371, loss_s1: 0.016078, loss_fp: 0.000402, loss_freq: 0.021784
[15:23:56.577] iteration 19180: loss: 0.054456, loss_s1: 0.049384, loss_fp: 0.005299, loss_freq: 0.023013
[15:23:57.242] iteration 19181: loss: 0.041346, loss_s1: 0.017038, loss_fp: 0.001556, loss_freq: 0.029705
[15:23:57.868] iteration 19182: loss: 0.039235, loss_s1: 0.017374, loss_fp: 0.002983, loss_freq: 0.015225
[15:23:58.488] iteration 19183: loss: 0.107251, loss_s1: 0.075351, loss_fp: 0.004743, loss_freq: 0.066660
[15:23:59.105] iteration 19184: loss: 0.045605, loss_s1: 0.035818, loss_fp: 0.001316, loss_freq: 0.015814
[15:23:59.727] iteration 19185: loss: 0.049343, loss_s1: 0.021457, loss_fp: 0.004400, loss_freq: 0.042129
[15:24:00.349] iteration 19186: loss: 0.061940, loss_s1: 0.052433, loss_fp: 0.000576, loss_freq: 0.016619
[15:24:00.974] iteration 19187: loss: 0.045853, loss_s1: 0.016058, loss_fp: 0.005277, loss_freq: 0.013856
[15:24:01.595] iteration 19188: loss: 0.067942, loss_s1: 0.033974, loss_fp: 0.001746, loss_freq: 0.054191
[15:24:02.217] iteration 19189: loss: 0.114345, loss_s1: 0.064417, loss_fp: 0.007857, loss_freq: 0.105959
[15:24:02.863] iteration 19190: loss: 0.040972, loss_s1: 0.017833, loss_fp: 0.002644, loss_freq: 0.005384
[15:24:03.487] iteration 19191: loss: 0.055505, loss_s1: 0.032940, loss_fp: 0.001390, loss_freq: 0.014830
[15:24:04.100] iteration 19192: loss: 0.049782, loss_s1: 0.018602, loss_fp: 0.005991, loss_freq: 0.011686
[15:24:04.722] iteration 19193: loss: 0.080286, loss_s1: 0.044679, loss_fp: 0.002941, loss_freq: 0.009306
[15:24:05.341] iteration 19194: loss: 0.054513, loss_s1: 0.020195, loss_fp: 0.005250, loss_freq: 0.021456
[15:24:05.964] iteration 19195: loss: 0.050720, loss_s1: 0.029552, loss_fp: 0.011291, loss_freq: 0.031454
[15:24:06.585] iteration 19196: loss: 0.081369, loss_s1: 0.076557, loss_fp: 0.007467, loss_freq: 0.027067
[15:24:07.206] iteration 19197: loss: 0.063921, loss_s1: 0.036804, loss_fp: 0.005986, loss_freq: 0.027146
[15:24:07.827] iteration 19198: loss: 0.091598, loss_s1: 0.074362, loss_fp: 0.012551, loss_freq: 0.050773
[15:24:08.446] iteration 19199: loss: 0.045723, loss_s1: 0.028847, loss_fp: 0.002356, loss_freq: 0.019620
[15:24:09.057] iteration 19200: loss: 0.048587, loss_s1: 0.044210, loss_fp: 0.003876, loss_freq: 0.018406
[15:24:12.402] iteration 19200 : mean_dice : 0.779610
[15:24:13.044] iteration 19201: loss: 0.069277, loss_s1: 0.025724, loss_fp: 0.003457, loss_freq: 0.052988
[15:24:13.659] iteration 19202: loss: 0.053775, loss_s1: 0.069670, loss_fp: 0.001971, loss_freq: 0.006274
[15:24:14.280] iteration 19203: loss: 0.069050, loss_s1: 0.056435, loss_fp: 0.004419, loss_freq: 0.032865
[15:24:14.901] iteration 19204: loss: 0.051696, loss_s1: 0.045335, loss_fp: 0.002769, loss_freq: 0.027443
[15:24:15.513] iteration 19205: loss: 0.041031, loss_s1: 0.020711, loss_fp: 0.001595, loss_freq: 0.012808
[15:24:16.141] iteration 19206: loss: 0.072694, loss_s1: 0.054572, loss_fp: 0.004200, loss_freq: 0.037099
[15:24:16.760] iteration 19207: loss: 0.050623, loss_s1: 0.030328, loss_fp: 0.001803, loss_freq: 0.008148
[15:24:17.382] iteration 19208: loss: 0.048899, loss_s1: 0.035185, loss_fp: 0.001498, loss_freq: 0.018437
[15:24:17.995] iteration 19209: loss: 0.042456, loss_s1: 0.026453, loss_fp: 0.002866, loss_freq: 0.015792
[15:24:18.614] iteration 19210: loss: 0.060465, loss_s1: 0.032901, loss_fp: 0.001344, loss_freq: 0.015814
[15:24:19.289] iteration 19211: loss: 0.055079, loss_s1: 0.053647, loss_fp: 0.002388, loss_freq: 0.023293
[15:24:19.922] iteration 19212: loss: 0.044459, loss_s1: 0.017668, loss_fp: 0.003063, loss_freq: 0.017841
[15:24:20.534] iteration 19213: loss: 0.056403, loss_s1: 0.050718, loss_fp: 0.001217, loss_freq: 0.014388
[15:24:21.154] iteration 19214: loss: 0.063672, loss_s1: 0.041273, loss_fp: 0.001814, loss_freq: 0.047311
[15:24:21.767] iteration 19215: loss: 0.062451, loss_s1: 0.033837, loss_fp: 0.003527, loss_freq: 0.019105
[15:24:22.384] iteration 19216: loss: 0.033468, loss_s1: 0.020620, loss_fp: 0.005174, loss_freq: 0.011425
[15:24:23.025] iteration 19217: loss: 0.040223, loss_s1: 0.021989, loss_fp: 0.004518, loss_freq: 0.022639
[15:24:23.644] iteration 19218: loss: 0.048612, loss_s1: 0.018194, loss_fp: 0.003634, loss_freq: 0.017251
[15:24:24.310] iteration 19219: loss: 0.064558, loss_s1: 0.043425, loss_fp: 0.006016, loss_freq: 0.040198
[15:24:24.931] iteration 19220: loss: 0.057959, loss_s1: 0.039636, loss_fp: 0.000826, loss_freq: 0.029640
[15:24:25.552] iteration 19221: loss: 0.072242, loss_s1: 0.037377, loss_fp: 0.005716, loss_freq: 0.050027
[15:24:26.170] iteration 19222: loss: 0.048599, loss_s1: 0.037848, loss_fp: 0.003030, loss_freq: 0.007763
[15:24:26.788] iteration 19223: loss: 0.055399, loss_s1: 0.036641, loss_fp: 0.003825, loss_freq: 0.015584
[15:24:27.406] iteration 19224: loss: 0.079733, loss_s1: 0.091519, loss_fp: 0.000317, loss_freq: 0.011511
[15:24:28.017] iteration 19225: loss: 0.068654, loss_s1: 0.039269, loss_fp: 0.009240, loss_freq: 0.049074
[15:24:28.640] iteration 19226: loss: 0.067218, loss_s1: 0.028339, loss_fp: 0.003064, loss_freq: 0.031951
[15:24:29.258] iteration 19227: loss: 0.052833, loss_s1: 0.042651, loss_fp: 0.002194, loss_freq: 0.011833
[15:24:29.875] iteration 19228: loss: 0.065146, loss_s1: 0.068698, loss_fp: 0.005146, loss_freq: 0.017362
[15:24:30.493] iteration 19229: loss: 0.113829, loss_s1: 0.028531, loss_fp: 0.005695, loss_freq: 0.119113
[15:24:31.114] iteration 19230: loss: 0.046518, loss_s1: 0.040698, loss_fp: 0.005387, loss_freq: 0.014314
[15:24:31.731] iteration 19231: loss: 0.068413, loss_s1: 0.067524, loss_fp: 0.013971, loss_freq: 0.021912
[15:24:32.342] iteration 19232: loss: 0.046607, loss_s1: 0.022546, loss_fp: 0.000675, loss_freq: 0.011157
[15:24:32.958] iteration 19233: loss: 0.049954, loss_s1: 0.040377, loss_fp: 0.001372, loss_freq: 0.022589
[15:24:33.583] iteration 19234: loss: 0.070348, loss_s1: 0.033712, loss_fp: 0.001028, loss_freq: 0.065805
[15:24:34.197] iteration 19235: loss: 0.074114, loss_s1: 0.056464, loss_fp: 0.005431, loss_freq: 0.047745
[15:24:34.820] iteration 19236: loss: 0.073150, loss_s1: 0.056646, loss_fp: 0.005274, loss_freq: 0.033951
[15:24:35.444] iteration 19237: loss: 0.070887, loss_s1: 0.067265, loss_fp: 0.006802, loss_freq: 0.040043
[15:24:36.061] iteration 19238: loss: 0.047409, loss_s1: 0.018680, loss_fp: 0.002681, loss_freq: 0.016545
[15:24:36.679] iteration 19239: loss: 0.070620, loss_s1: 0.081506, loss_fp: 0.001636, loss_freq: 0.019392
[15:24:37.300] iteration 19240: loss: 0.049916, loss_s1: 0.033875, loss_fp: 0.001273, loss_freq: 0.014406
[15:24:37.919] iteration 19241: loss: 0.091392, loss_s1: 0.058867, loss_fp: 0.008769, loss_freq: 0.069550
[15:24:38.539] iteration 19242: loss: 0.084315, loss_s1: 0.069916, loss_fp: 0.005471, loss_freq: 0.017137
[15:24:39.174] iteration 19243: loss: 0.092002, loss_s1: 0.058572, loss_fp: 0.000579, loss_freq: 0.064761
[15:24:39.821] iteration 19244: loss: 0.063580, loss_s1: 0.051978, loss_fp: 0.003072, loss_freq: 0.027717
[15:24:40.440] iteration 19245: loss: 0.053540, loss_s1: 0.040934, loss_fp: 0.000742, loss_freq: 0.017906
[15:24:41.054] iteration 19246: loss: 0.047669, loss_s1: 0.053456, loss_fp: 0.000699, loss_freq: 0.011724
[15:24:41.671] iteration 19247: loss: 0.066627, loss_s1: 0.054097, loss_fp: 0.004925, loss_freq: 0.035135
[15:24:42.286] iteration 19248: loss: 0.063964, loss_s1: 0.040721, loss_fp: 0.007888, loss_freq: 0.018768
[15:24:42.902] iteration 19249: loss: 0.050547, loss_s1: 0.017004, loss_fp: 0.004665, loss_freq: 0.026032
[15:24:43.525] iteration 19250: loss: 0.041484, loss_s1: 0.027292, loss_fp: 0.001194, loss_freq: 0.008763
[15:24:44.144] iteration 19251: loss: 0.043648, loss_s1: 0.017022, loss_fp: 0.002810, loss_freq: 0.014264
[15:24:44.764] iteration 19252: loss: 0.047112, loss_s1: 0.037824, loss_fp: 0.004772, loss_freq: 0.022879
[15:24:45.387] iteration 19253: loss: 0.053891, loss_s1: 0.023307, loss_fp: 0.001794, loss_freq: 0.031918
[15:24:46.050] iteration 19254: loss: 0.068530, loss_s1: 0.051016, loss_fp: 0.007625, loss_freq: 0.049160
[15:24:46.667] iteration 19255: loss: 0.051686, loss_s1: 0.042044, loss_fp: 0.004624, loss_freq: 0.009067
[15:24:47.288] iteration 19256: loss: 0.073829, loss_s1: 0.069260, loss_fp: 0.003711, loss_freq: 0.010427
[15:24:47.926] iteration 19257: loss: 0.043973, loss_s1: 0.020773, loss_fp: 0.000747, loss_freq: 0.021921
[15:24:48.551] iteration 19258: loss: 0.054097, loss_s1: 0.003683, loss_fp: 0.004384, loss_freq: 0.023854
[15:24:49.170] iteration 19259: loss: 0.077152, loss_s1: 0.053779, loss_fp: 0.002503, loss_freq: 0.055893
[15:24:49.797] iteration 19260: loss: 0.044045, loss_s1: 0.030792, loss_fp: 0.001545, loss_freq: 0.013886
[15:24:50.418] iteration 19261: loss: 0.033988, loss_s1: 0.006273, loss_fp: 0.001404, loss_freq: 0.010478
[15:24:51.071] iteration 19262: loss: 0.072014, loss_s1: 0.063862, loss_fp: 0.002359, loss_freq: 0.022826
[15:24:51.696] iteration 19263: loss: 0.050433, loss_s1: 0.036388, loss_fp: 0.001276, loss_freq: 0.016677
[15:24:52.317] iteration 19264: loss: 0.067644, loss_s1: 0.043285, loss_fp: 0.001146, loss_freq: 0.043826
[15:24:52.936] iteration 19265: loss: 0.104967, loss_s1: 0.112219, loss_fp: 0.002330, loss_freq: 0.066030
[15:24:53.560] iteration 19266: loss: 0.039275, loss_s1: 0.023356, loss_fp: 0.001032, loss_freq: 0.017351
[15:24:54.188] iteration 19267: loss: 0.063455, loss_s1: 0.021468, loss_fp: 0.001442, loss_freq: 0.020842
[15:24:54.810] iteration 19268: loss: 0.062736, loss_s1: 0.039885, loss_fp: 0.002814, loss_freq: 0.023538
[15:24:55.437] iteration 19269: loss: 0.073873, loss_s1: 0.061210, loss_fp: 0.008728, loss_freq: 0.035308
[15:24:56.059] iteration 19270: loss: 0.075507, loss_s1: 0.041258, loss_fp: 0.015640, loss_freq: 0.041859
[15:24:56.682] iteration 19271: loss: 0.066197, loss_s1: 0.022157, loss_fp: 0.008789, loss_freq: 0.043895
[15:24:57.302] iteration 19272: loss: 0.089791, loss_s1: 0.081791, loss_fp: 0.006763, loss_freq: 0.053454
[15:24:57.919] iteration 19273: loss: 0.094900, loss_s1: 0.087253, loss_fp: 0.002523, loss_freq: 0.010630
[15:24:58.547] iteration 19274: loss: 0.060491, loss_s1: 0.058893, loss_fp: 0.002917, loss_freq: 0.026096
[15:24:59.171] iteration 19275: loss: 0.087530, loss_s1: 0.052048, loss_fp: 0.001945, loss_freq: 0.016804
[15:24:59.793] iteration 19276: loss: 0.070222, loss_s1: 0.055604, loss_fp: 0.006151, loss_freq: 0.035992
[15:25:00.419] iteration 19277: loss: 0.066137, loss_s1: 0.024603, loss_fp: 0.028084, loss_freq: 0.024464
[15:25:01.045] iteration 19278: loss: 0.050987, loss_s1: 0.030187, loss_fp: 0.002758, loss_freq: 0.019913
[15:25:01.673] iteration 19279: loss: 0.063674, loss_s1: 0.025387, loss_fp: 0.006542, loss_freq: 0.045953
[15:25:02.295] iteration 19280: loss: 0.058437, loss_s1: 0.051171, loss_fp: 0.001175, loss_freq: 0.017352
[15:25:02.910] iteration 19281: loss: 0.048195, loss_s1: 0.060742, loss_fp: 0.003261, loss_freq: 0.003742
[15:25:03.530] iteration 19282: loss: 0.061473, loss_s1: 0.047332, loss_fp: 0.003364, loss_freq: 0.030166
[15:25:04.150] iteration 19283: loss: 0.058905, loss_s1: 0.037028, loss_fp: 0.000882, loss_freq: 0.028404
[15:25:04.780] iteration 19284: loss: 0.078058, loss_s1: 0.042352, loss_fp: 0.016734, loss_freq: 0.046809
[15:25:05.406] iteration 19285: loss: 0.033303, loss_s1: 0.018415, loss_fp: 0.001483, loss_freq: 0.009832
[15:25:06.032] iteration 19286: loss: 0.045909, loss_s1: 0.026242, loss_fp: 0.001089, loss_freq: 0.034323
[15:25:06.651] iteration 19287: loss: 0.074449, loss_s1: 0.055641, loss_fp: 0.003814, loss_freq: 0.050728
[15:25:07.270] iteration 19288: loss: 0.088860, loss_s1: 0.033634, loss_fp: 0.003372, loss_freq: 0.008603
[15:25:07.886] iteration 19289: loss: 0.057093, loss_s1: 0.010285, loss_fp: 0.004220, loss_freq: 0.050925
[15:25:08.503] iteration 19290: loss: 0.038664, loss_s1: 0.020568, loss_fp: 0.003907, loss_freq: 0.022737
[15:25:09.176] iteration 19291: loss: 0.093546, loss_s1: 0.089386, loss_fp: 0.003474, loss_freq: 0.030156
[15:25:09.810] iteration 19292: loss: 0.043151, loss_s1: 0.027137, loss_fp: 0.003132, loss_freq: 0.009403
[15:25:10.452] iteration 19293: loss: 0.055980, loss_s1: 0.045238, loss_fp: 0.001535, loss_freq: 0.024850
[15:25:11.088] iteration 19294: loss: 0.068113, loss_s1: 0.040597, loss_fp: 0.001262, loss_freq: 0.018234
[15:25:11.756] iteration 19295: loss: 0.050824, loss_s1: 0.037294, loss_fp: 0.005844, loss_freq: 0.016095
[15:25:12.390] iteration 19296: loss: 0.058227, loss_s1: 0.026682, loss_fp: 0.002264, loss_freq: 0.040167
[15:25:13.007] iteration 19297: loss: 0.048448, loss_s1: 0.017018, loss_fp: 0.005229, loss_freq: 0.014002
[15:25:13.628] iteration 19298: loss: 0.067615, loss_s1: 0.052923, loss_fp: 0.003005, loss_freq: 0.033989
[15:25:14.251] iteration 19299: loss: 0.078557, loss_s1: 0.051143, loss_fp: 0.006641, loss_freq: 0.017270
[15:25:14.864] iteration 19300: loss: 0.031736, loss_s1: 0.020417, loss_fp: 0.002725, loss_freq: 0.006631
[15:25:15.487] iteration 19301: loss: 0.043288, loss_s1: 0.025310, loss_fp: 0.004144, loss_freq: 0.017574
[15:25:16.107] iteration 19302: loss: 0.052884, loss_s1: 0.030912, loss_fp: 0.007657, loss_freq: 0.004038
[15:25:16.724] iteration 19303: loss: 0.100410, loss_s1: 0.108032, loss_fp: 0.005532, loss_freq: 0.050388
[15:25:17.339] iteration 19304: loss: 0.066871, loss_s1: 0.057224, loss_fp: 0.014115, loss_freq: 0.013992
[15:25:18.004] iteration 19305: loss: 0.067322, loss_s1: 0.037151, loss_fp: 0.007396, loss_freq: 0.035953
[15:25:19.018] iteration 19306: loss: 0.056393, loss_s1: 0.054596, loss_fp: 0.007682, loss_freq: 0.013453
[15:25:19.690] iteration 19307: loss: 0.072513, loss_s1: 0.070467, loss_fp: 0.003567, loss_freq: 0.020322
[15:25:20.347] iteration 19308: loss: 0.054988, loss_s1: 0.028345, loss_fp: 0.004454, loss_freq: 0.038973
[15:25:20.996] iteration 19309: loss: 0.062804, loss_s1: 0.047317, loss_fp: 0.005044, loss_freq: 0.021824
[15:25:21.651] iteration 19310: loss: 0.078569, loss_s1: 0.061019, loss_fp: 0.015922, loss_freq: 0.034776
[15:25:22.275] iteration 19311: loss: 0.073026, loss_s1: 0.023845, loss_fp: 0.010836, loss_freq: 0.006040
[15:25:22.895] iteration 19312: loss: 0.047960, loss_s1: 0.049293, loss_fp: 0.001289, loss_freq: 0.012045
[15:25:23.523] iteration 19313: loss: 0.073223, loss_s1: 0.033504, loss_fp: 0.004443, loss_freq: 0.018898
[15:25:24.151] iteration 19314: loss: 0.082421, loss_s1: 0.064713, loss_fp: 0.008523, loss_freq: 0.041758
[15:25:24.823] iteration 19315: loss: 0.070494, loss_s1: 0.029654, loss_fp: 0.001962, loss_freq: 0.028587
[15:25:25.447] iteration 19316: loss: 0.065163, loss_s1: 0.043409, loss_fp: 0.001745, loss_freq: 0.040243
[15:25:26.127] iteration 19317: loss: 0.088637, loss_s1: 0.045804, loss_fp: 0.018385, loss_freq: 0.058639
[15:25:26.776] iteration 19318: loss: 0.069493, loss_s1: 0.050198, loss_fp: 0.001545, loss_freq: 0.037740
[15:25:27.419] iteration 19319: loss: 0.033587, loss_s1: 0.009224, loss_fp: 0.002103, loss_freq: 0.009640
[15:25:28.043] iteration 19320: loss: 0.061280, loss_s1: 0.063371, loss_fp: 0.004756, loss_freq: 0.013349
[15:25:28.664] iteration 19321: loss: 0.041683, loss_s1: 0.015851, loss_fp: 0.002387, loss_freq: 0.018820
[15:25:29.282] iteration 19322: loss: 0.142035, loss_s1: 0.057619, loss_fp: 0.000478, loss_freq: 0.025412
[15:25:29.910] iteration 19323: loss: 0.040390, loss_s1: 0.029518, loss_fp: 0.002917, loss_freq: 0.011826
[15:25:30.523] iteration 19324: loss: 0.045702, loss_s1: 0.014994, loss_fp: 0.000267, loss_freq: 0.030048
[15:25:31.147] iteration 19325: loss: 0.047242, loss_s1: 0.040286, loss_fp: 0.000787, loss_freq: 0.014818
[15:25:31.765] iteration 19326: loss: 0.083758, loss_s1: 0.033668, loss_fp: 0.002014, loss_freq: 0.034443
[15:25:32.389] iteration 19327: loss: 0.052564, loss_s1: 0.040027, loss_fp: 0.001411, loss_freq: 0.025553
[15:25:33.000] iteration 19328: loss: 0.055775, loss_s1: 0.034664, loss_fp: 0.002369, loss_freq: 0.045684
[15:25:33.614] iteration 19329: loss: 0.044321, loss_s1: 0.019244, loss_fp: 0.001657, loss_freq: 0.020068
[15:25:34.237] iteration 19330: loss: 0.057867, loss_s1: 0.030145, loss_fp: 0.005904, loss_freq: 0.032506
[15:25:34.855] iteration 19331: loss: 0.084973, loss_s1: 0.050952, loss_fp: 0.003115, loss_freq: 0.025507
[15:25:35.473] iteration 19332: loss: 0.082562, loss_s1: 0.056663, loss_fp: 0.006585, loss_freq: 0.059048
[15:25:36.096] iteration 19333: loss: 0.057402, loss_s1: 0.046729, loss_fp: 0.001289, loss_freq: 0.010864
[15:25:36.729] iteration 19334: loss: 0.099158, loss_s1: 0.060873, loss_fp: 0.005927, loss_freq: 0.079385
[15:25:37.372] iteration 19335: loss: 0.065707, loss_s1: 0.023709, loss_fp: 0.002152, loss_freq: 0.025124
[15:25:38.059] iteration 19336: loss: 0.048432, loss_s1: 0.045828, loss_fp: 0.001150, loss_freq: 0.003625
[15:25:38.704] iteration 19337: loss: 0.087360, loss_s1: 0.054919, loss_fp: 0.010886, loss_freq: 0.048682
[15:25:39.340] iteration 19338: loss: 0.115079, loss_s1: 0.079120, loss_fp: 0.026578, loss_freq: 0.074389
[15:25:39.968] iteration 19339: loss: 0.091244, loss_s1: 0.080790, loss_fp: 0.013260, loss_freq: 0.036515
[15:25:40.584] iteration 19340: loss: 0.084529, loss_s1: 0.065616, loss_fp: 0.009921, loss_freq: 0.032085
[15:25:41.203] iteration 19341: loss: 0.068569, loss_s1: 0.042765, loss_fp: 0.005530, loss_freq: 0.039538
[15:25:41.827] iteration 19342: loss: 0.084399, loss_s1: 0.073580, loss_fp: 0.009267, loss_freq: 0.029893
[15:25:42.453] iteration 19343: loss: 0.073573, loss_s1: 0.049929, loss_fp: 0.015732, loss_freq: 0.041532
[15:25:43.078] iteration 19344: loss: 0.141921, loss_s1: 0.074650, loss_fp: 0.012921, loss_freq: 0.112655
[15:25:43.703] iteration 19345: loss: 0.073507, loss_s1: 0.064109, loss_fp: 0.005851, loss_freq: 0.026517
[15:25:44.383] iteration 19346: loss: 0.084690, loss_s1: 0.021173, loss_fp: 0.004966, loss_freq: 0.025304
[15:25:45.055] iteration 19347: loss: 0.047403, loss_s1: 0.024562, loss_fp: 0.006219, loss_freq: 0.010196
[15:25:45.691] iteration 19348: loss: 0.053566, loss_s1: 0.033933, loss_fp: 0.000735, loss_freq: 0.008784
[15:25:46.315] iteration 19349: loss: 0.063970, loss_s1: 0.051686, loss_fp: 0.001822, loss_freq: 0.037315
[15:25:46.941] iteration 19350: loss: 0.076060, loss_s1: 0.063450, loss_fp: 0.000839, loss_freq: 0.016843
[15:25:47.560] iteration 19351: loss: 0.046230, loss_s1: 0.034013, loss_fp: 0.001813, loss_freq: 0.017504
[15:25:48.185] iteration 19352: loss: 0.066894, loss_s1: 0.039124, loss_fp: 0.002214, loss_freq: 0.032714
[15:25:48.809] iteration 19353: loss: 0.050913, loss_s1: 0.031229, loss_fp: 0.002347, loss_freq: 0.028748
[15:25:49.636] iteration 19354: loss: 0.049054, loss_s1: 0.026805, loss_fp: 0.001360, loss_freq: 0.038902
[15:25:50.506] iteration 19355: loss: 0.040594, loss_s1: 0.029071, loss_fp: 0.000718, loss_freq: 0.013441
[15:25:51.241] iteration 19356: loss: 0.045616, loss_s1: 0.026531, loss_fp: 0.001553, loss_freq: 0.013623
[15:25:51.966] iteration 19357: loss: 0.053299, loss_s1: 0.038769, loss_fp: 0.003902, loss_freq: 0.022885
[15:25:52.594] iteration 19358: loss: 0.052629, loss_s1: 0.016031, loss_fp: 0.000667, loss_freq: 0.022695
[15:25:53.215] iteration 19359: loss: 0.040364, loss_s1: 0.029901, loss_fp: 0.000921, loss_freq: 0.023389
[15:25:53.833] iteration 19360: loss: 0.042805, loss_s1: 0.039222, loss_fp: 0.001667, loss_freq: 0.008842
[15:25:54.500] iteration 19361: loss: 0.043158, loss_s1: 0.014737, loss_fp: 0.000768, loss_freq: 0.010081
[15:25:55.122] iteration 19362: loss: 0.051144, loss_s1: 0.047661, loss_fp: 0.002546, loss_freq: 0.012919
[15:25:55.742] iteration 19363: loss: 0.035996, loss_s1: 0.013187, loss_fp: 0.001863, loss_freq: 0.011340
[15:25:56.363] iteration 19364: loss: 0.060088, loss_s1: 0.032603, loss_fp: 0.000534, loss_freq: 0.048096
[15:25:56.989] iteration 19365: loss: 0.057978, loss_s1: 0.053287, loss_fp: 0.000749, loss_freq: 0.019745
[15:25:57.608] iteration 19366: loss: 0.082685, loss_s1: 0.036766, loss_fp: 0.001432, loss_freq: 0.013650
[15:25:58.231] iteration 19367: loss: 0.058217, loss_s1: 0.055888, loss_fp: 0.002416, loss_freq: 0.008449
[15:25:58.857] iteration 19368: loss: 0.120372, loss_s1: 0.114269, loss_fp: 0.001142, loss_freq: 0.066377
[15:25:59.543] iteration 19369: loss: 0.057119, loss_s1: 0.050271, loss_fp: 0.002790, loss_freq: 0.020272
[15:26:00.167] iteration 19370: loss: 0.070869, loss_s1: 0.029089, loss_fp: 0.003693, loss_freq: 0.028711
[15:26:00.839] iteration 19371: loss: 0.056851, loss_s1: 0.047911, loss_fp: 0.001797, loss_freq: 0.020202
[15:26:01.467] iteration 19372: loss: 0.091107, loss_s1: 0.058101, loss_fp: 0.007168, loss_freq: 0.067994
[15:26:02.088] iteration 19373: loss: 0.039763, loss_s1: 0.010322, loss_fp: 0.002681, loss_freq: 0.032444
[15:26:02.707] iteration 19374: loss: 0.061444, loss_s1: 0.050915, loss_fp: 0.002002, loss_freq: 0.019308
[15:26:03.324] iteration 19375: loss: 0.055475, loss_s1: 0.031471, loss_fp: 0.001538, loss_freq: 0.013672
[15:26:03.973] iteration 19376: loss: 0.047635, loss_s1: 0.034498, loss_fp: 0.000885, loss_freq: 0.017998
[15:26:04.589] iteration 19377: loss: 0.080691, loss_s1: 0.072556, loss_fp: 0.003658, loss_freq: 0.027770
[15:26:05.205] iteration 19378: loss: 0.066550, loss_s1: 0.037807, loss_fp: 0.012509, loss_freq: 0.036002
[15:26:05.830] iteration 19379: loss: 0.094697, loss_s1: 0.048470, loss_fp: 0.018922, loss_freq: 0.052754
[15:26:06.475] iteration 19380: loss: 0.069768, loss_s1: 0.021223, loss_fp: 0.006515, loss_freq: 0.026411
[15:26:07.097] iteration 19381: loss: 0.050952, loss_s1: 0.049818, loss_fp: 0.001426, loss_freq: 0.012245
[15:26:07.722] iteration 19382: loss: 0.066008, loss_s1: 0.043815, loss_fp: 0.004820, loss_freq: 0.042875
[15:26:08.341] iteration 19383: loss: 0.045056, loss_s1: 0.017925, loss_fp: 0.002954, loss_freq: 0.006541
[15:26:08.961] iteration 19384: loss: 0.070886, loss_s1: 0.058847, loss_fp: 0.018114, loss_freq: 0.017035
[15:26:09.586] iteration 19385: loss: 0.120586, loss_s1: 0.057967, loss_fp: 0.001362, loss_freq: 0.051927
[15:26:10.205] iteration 19386: loss: 0.041828, loss_s1: 0.020288, loss_fp: 0.001972, loss_freq: 0.015840
[15:26:10.850] iteration 19387: loss: 0.050712, loss_s1: 0.025444, loss_fp: 0.009841, loss_freq: 0.017539
[15:26:11.473] iteration 19388: loss: 0.052260, loss_s1: 0.036701, loss_fp: 0.003053, loss_freq: 0.016590
[15:26:12.138] iteration 19389: loss: 0.044958, loss_s1: 0.030415, loss_fp: 0.003713, loss_freq: 0.023544
[15:26:12.761] iteration 19390: loss: 0.063363, loss_s1: 0.052851, loss_fp: 0.002614, loss_freq: 0.025554
[15:26:13.389] iteration 19391: loss: 0.062404, loss_s1: 0.040938, loss_fp: 0.003351, loss_freq: 0.039249
[15:26:14.000] iteration 19392: loss: 0.068040, loss_s1: 0.031234, loss_fp: 0.006656, loss_freq: 0.021903
[15:26:14.624] iteration 19393: loss: 0.084939, loss_s1: 0.052052, loss_fp: 0.002577, loss_freq: 0.027359
[15:26:15.252] iteration 19394: loss: 0.038781, loss_s1: 0.027905, loss_fp: 0.000792, loss_freq: 0.005499
[15:26:15.876] iteration 19395: loss: 0.066111, loss_s1: 0.058227, loss_fp: 0.002740, loss_freq: 0.039536
[15:26:16.501] iteration 19396: loss: 0.061157, loss_s1: 0.020965, loss_fp: 0.000780, loss_freq: 0.034553
[15:26:17.120] iteration 19397: loss: 0.036802, loss_s1: 0.006268, loss_fp: 0.000967, loss_freq: 0.025933
[15:26:17.747] iteration 19398: loss: 0.061703, loss_s1: 0.067211, loss_fp: 0.001621, loss_freq: 0.007861
[15:26:18.365] iteration 19399: loss: 0.045154, loss_s1: 0.028932, loss_fp: 0.005430, loss_freq: 0.011749
[15:26:19.014] iteration 19400: loss: 0.039798, loss_s1: 0.019874, loss_fp: 0.001995, loss_freq: 0.017834
[15:26:22.390] iteration 19400 : mean_dice : 0.765502
[15:26:23.039] iteration 19401: loss: 0.037345, loss_s1: 0.026337, loss_fp: 0.002580, loss_freq: 0.007420
[15:26:23.663] iteration 19402: loss: 0.087935, loss_s1: 0.100599, loss_fp: 0.005122, loss_freq: 0.026862
[15:26:24.285] iteration 19403: loss: 0.064934, loss_s1: 0.043363, loss_fp: 0.007591, loss_freq: 0.035292
[15:26:24.897] iteration 19404: loss: 0.083584, loss_s1: 0.091769, loss_fp: 0.005463, loss_freq: 0.010378
[15:26:25.561] iteration 19405: loss: 0.090762, loss_s1: 0.035005, loss_fp: 0.000675, loss_freq: 0.051992
[15:26:26.181] iteration 19406: loss: 0.045575, loss_s1: 0.038345, loss_fp: 0.003301, loss_freq: 0.011576
[15:26:26.795] iteration 19407: loss: 0.057613, loss_s1: 0.039390, loss_fp: 0.001612, loss_freq: 0.011140
[15:26:27.415] iteration 19408: loss: 0.057205, loss_s1: 0.054953, loss_fp: 0.002573, loss_freq: 0.025101
[15:26:28.031] iteration 19409: loss: 0.052057, loss_s1: 0.018321, loss_fp: 0.001459, loss_freq: 0.040648
[15:26:28.651] iteration 19410: loss: 0.080303, loss_s1: 0.044658, loss_fp: 0.001156, loss_freq: 0.017272
[15:26:29.273] iteration 19411: loss: 0.044206, loss_s1: 0.011459, loss_fp: 0.004894, loss_freq: 0.022083
[15:26:29.896] iteration 19412: loss: 0.109528, loss_s1: 0.072204, loss_fp: 0.020910, loss_freq: 0.074881
[15:26:30.531] iteration 19413: loss: 0.068716, loss_s1: 0.036414, loss_fp: 0.002359, loss_freq: 0.061588
[15:26:31.192] iteration 19414: loss: 0.040931, loss_s1: 0.015032, loss_fp: 0.002620, loss_freq: 0.013158
[15:26:31.819] iteration 19415: loss: 0.091864, loss_s1: 0.043099, loss_fp: 0.006956, loss_freq: 0.030423
[15:26:32.439] iteration 19416: loss: 0.078481, loss_s1: 0.027930, loss_fp: 0.001607, loss_freq: 0.009419
[15:26:33.056] iteration 19417: loss: 0.074305, loss_s1: 0.070713, loss_fp: 0.006123, loss_freq: 0.041300
[15:26:33.674] iteration 19418: loss: 0.055600, loss_s1: 0.041360, loss_fp: 0.000919, loss_freq: 0.010190
[15:26:34.297] iteration 19419: loss: 0.104927, loss_s1: 0.084871, loss_fp: 0.011303, loss_freq: 0.059020
[15:26:34.923] iteration 19420: loss: 0.103311, loss_s1: 0.082106, loss_fp: 0.003568, loss_freq: 0.032764
[15:26:35.543] iteration 19421: loss: 0.066046, loss_s1: 0.035341, loss_fp: 0.005912, loss_freq: 0.031894
[15:26:36.168] iteration 19422: loss: 0.074658, loss_s1: 0.048150, loss_fp: 0.008355, loss_freq: 0.050392
[15:26:36.789] iteration 19423: loss: 0.033495, loss_s1: 0.019849, loss_fp: 0.003540, loss_freq: 0.007502
[15:26:37.418] iteration 19424: loss: 0.045601, loss_s1: 0.033368, loss_fp: 0.002334, loss_freq: 0.011737
[15:26:38.114] iteration 19425: loss: 0.061104, loss_s1: 0.038665, loss_fp: 0.002618, loss_freq: 0.040562
[15:26:38.733] iteration 19426: loss: 0.081500, loss_s1: 0.076230, loss_fp: 0.002039, loss_freq: 0.033716
[15:26:39.355] iteration 19427: loss: 0.049473, loss_s1: 0.044597, loss_fp: 0.001595, loss_freq: 0.007802
[15:26:39.977] iteration 19428: loss: 0.037955, loss_s1: 0.014544, loss_fp: 0.000341, loss_freq: 0.017482
[15:26:40.594] iteration 19429: loss: 0.048852, loss_s1: 0.035883, loss_fp: 0.007597, loss_freq: 0.021603
[15:26:41.219] iteration 19430: loss: 0.040785, loss_s1: 0.029750, loss_fp: 0.001701, loss_freq: 0.018611
[15:26:41.844] iteration 19431: loss: 0.072074, loss_s1: 0.038846, loss_fp: 0.001435, loss_freq: 0.008986
[15:26:42.510] iteration 19432: loss: 0.056237, loss_s1: 0.028170, loss_fp: 0.001228, loss_freq: 0.019604
[15:26:43.131] iteration 19433: loss: 0.052193, loss_s1: 0.021026, loss_fp: 0.001935, loss_freq: 0.028689
[15:26:43.753] iteration 19434: loss: 0.061795, loss_s1: 0.056526, loss_fp: 0.003113, loss_freq: 0.010746
[15:26:44.365] iteration 19435: loss: 0.043046, loss_s1: 0.032808, loss_fp: 0.001671, loss_freq: 0.011066
[15:26:44.990] iteration 19436: loss: 0.058022, loss_s1: 0.039746, loss_fp: 0.002586, loss_freq: 0.022082
[15:26:45.627] iteration 19437: loss: 0.057447, loss_s1: 0.029793, loss_fp: 0.008813, loss_freq: 0.028551
[15:26:46.273] iteration 19438: loss: 0.049057, loss_s1: 0.040600, loss_fp: 0.002203, loss_freq: 0.014253
[15:26:46.911] iteration 19439: loss: 0.056724, loss_s1: 0.029328, loss_fp: 0.001558, loss_freq: 0.035104
[15:26:47.565] iteration 19440: loss: 0.043650, loss_s1: 0.012444, loss_fp: 0.004044, loss_freq: 0.022281
[15:26:48.181] iteration 19441: loss: 0.057271, loss_s1: 0.040000, loss_fp: 0.002439, loss_freq: 0.029063
[15:26:48.841] iteration 19442: loss: 0.064741, loss_s1: 0.055086, loss_fp: 0.006055, loss_freq: 0.019335
[15:26:49.457] iteration 19443: loss: 0.036204, loss_s1: 0.032644, loss_fp: 0.001187, loss_freq: 0.004752
[15:26:50.076] iteration 19444: loss: 0.077888, loss_s1: 0.080046, loss_fp: 0.003218, loss_freq: 0.027881
[15:26:50.698] iteration 19445: loss: 0.048859, loss_s1: 0.035847, loss_fp: 0.010527, loss_freq: 0.005492
[15:26:51.319] iteration 19446: loss: 0.072658, loss_s1: 0.031987, loss_fp: 0.001218, loss_freq: 0.050637
[15:26:51.933] iteration 19447: loss: 0.080379, loss_s1: 0.084917, loss_fp: 0.003493, loss_freq: 0.013446
[15:26:52.551] iteration 19448: loss: 0.053902, loss_s1: 0.020978, loss_fp: 0.003059, loss_freq: 0.020058
[15:26:53.485] iteration 19449: loss: 0.048440, loss_s1: 0.033540, loss_fp: 0.001811, loss_freq: 0.019997
[15:26:54.142] iteration 19450: loss: 0.074147, loss_s1: 0.064085, loss_fp: 0.011977, loss_freq: 0.016661
[15:26:54.760] iteration 19451: loss: 0.054083, loss_s1: 0.057771, loss_fp: 0.002274, loss_freq: 0.012412
[15:26:55.408] iteration 19452: loss: 0.064935, loss_s1: 0.041906, loss_fp: 0.008753, loss_freq: 0.027413
[15:26:56.026] iteration 19453: loss: 0.074252, loss_s1: 0.047279, loss_fp: 0.003010, loss_freq: 0.060190
[15:26:56.642] iteration 19454: loss: 0.045390, loss_s1: 0.036850, loss_fp: 0.000576, loss_freq: 0.015798
[15:26:57.256] iteration 19455: loss: 0.037184, loss_s1: 0.027203, loss_fp: 0.002083, loss_freq: 0.013153
[15:26:57.873] iteration 19456: loss: 0.103205, loss_s1: 0.132263, loss_fp: 0.004010, loss_freq: 0.019157
[15:26:58.490] iteration 19457: loss: 0.063043, loss_s1: 0.048183, loss_fp: 0.009385, loss_freq: 0.026443
[15:26:59.111] iteration 19458: loss: 0.032111, loss_s1: 0.007425, loss_fp: 0.000682, loss_freq: 0.002791
[15:26:59.726] iteration 19459: loss: 0.061966, loss_s1: 0.035015, loss_fp: 0.007643, loss_freq: 0.033571
[15:27:00.367] iteration 19460: loss: 0.060983, loss_s1: 0.049655, loss_fp: 0.005051, loss_freq: 0.020905
[15:27:01.013] iteration 19461: loss: 0.053619, loss_s1: 0.036887, loss_fp: 0.001584, loss_freq: 0.023103
[15:27:01.648] iteration 19462: loss: 0.037637, loss_s1: 0.014149, loss_fp: 0.005087, loss_freq: 0.018302
[15:27:02.288] iteration 19463: loss: 0.048152, loss_s1: 0.027762, loss_fp: 0.001044, loss_freq: 0.023180
[15:27:02.906] iteration 19464: loss: 0.050255, loss_s1: 0.031033, loss_fp: 0.003753, loss_freq: 0.014094
[15:27:03.558] iteration 19465: loss: 0.038666, loss_s1: 0.023504, loss_fp: 0.001582, loss_freq: 0.010489
[15:27:04.177] iteration 19466: loss: 0.046996, loss_s1: 0.025459, loss_fp: 0.003754, loss_freq: 0.010229
[15:27:04.797] iteration 19467: loss: 0.038947, loss_s1: 0.019848, loss_fp: 0.001068, loss_freq: 0.028511
[15:27:05.412] iteration 19468: loss: 0.027686, loss_s1: 0.009799, loss_fp: 0.000962, loss_freq: 0.011803
[15:27:06.056] iteration 19469: loss: 0.087095, loss_s1: 0.049006, loss_fp: 0.004359, loss_freq: 0.048021
[15:27:06.672] iteration 19470: loss: 0.057849, loss_s1: 0.023371, loss_fp: 0.013864, loss_freq: 0.025400
[15:27:07.295] iteration 19471: loss: 0.051354, loss_s1: 0.025727, loss_fp: 0.001850, loss_freq: 0.026574
[15:27:07.913] iteration 19472: loss: 0.063408, loss_s1: 0.040888, loss_fp: 0.001695, loss_freq: 0.006860
[15:27:08.561] iteration 19473: loss: 0.049938, loss_s1: 0.036075, loss_fp: 0.000983, loss_freq: 0.017230
[15:27:09.191] iteration 19474: loss: 0.082683, loss_s1: 0.060397, loss_fp: 0.004885, loss_freq: 0.060758
[15:27:09.841] iteration 19475: loss: 0.105003, loss_s1: 0.065115, loss_fp: 0.008711, loss_freq: 0.073422
[15:27:10.478] iteration 19476: loss: 0.054671, loss_s1: 0.064402, loss_fp: 0.001893, loss_freq: 0.008254
[15:27:11.129] iteration 19477: loss: 0.087633, loss_s1: 0.095631, loss_fp: 0.003922, loss_freq: 0.018931
[15:27:11.760] iteration 19478: loss: 0.049485, loss_s1: 0.030346, loss_fp: 0.006021, loss_freq: 0.004853
[15:27:12.379] iteration 19479: loss: 0.055463, loss_s1: 0.035035, loss_fp: 0.000799, loss_freq: 0.039170
[15:27:12.998] iteration 19480: loss: 0.083386, loss_s1: 0.101436, loss_fp: 0.001935, loss_freq: 0.015013
[15:27:13.613] iteration 19481: loss: 0.058706, loss_s1: 0.036679, loss_fp: 0.004457, loss_freq: 0.046531
[15:27:14.224] iteration 19482: loss: 0.067555, loss_s1: 0.060388, loss_fp: 0.002872, loss_freq: 0.031538
[15:27:14.839] iteration 19483: loss: 0.073860, loss_s1: 0.069201, loss_fp: 0.003099, loss_freq: 0.025271
[15:27:15.453] iteration 19484: loss: 0.094757, loss_s1: 0.085368, loss_fp: 0.011220, loss_freq: 0.049985
[15:27:16.074] iteration 19485: loss: 0.060354, loss_s1: 0.052611, loss_fp: 0.001796, loss_freq: 0.015246
[15:27:16.686] iteration 19486: loss: 0.051062, loss_s1: 0.034979, loss_fp: 0.006499, loss_freq: 0.026063
[15:27:17.297] iteration 19487: loss: 0.100970, loss_s1: 0.082127, loss_fp: 0.006173, loss_freq: 0.062919
[15:27:17.917] iteration 19488: loss: 0.043829, loss_s1: 0.045670, loss_fp: 0.004155, loss_freq: 0.007134
[15:27:18.534] iteration 19489: loss: 0.094278, loss_s1: 0.056626, loss_fp: 0.002409, loss_freq: 0.031729
[15:27:19.146] iteration 19490: loss: 0.057330, loss_s1: 0.049027, loss_fp: 0.004787, loss_freq: 0.029565
[15:27:19.762] iteration 19491: loss: 0.047969, loss_s1: 0.019880, loss_fp: 0.000669, loss_freq: 0.018693
[15:27:20.373] iteration 19492: loss: 0.046718, loss_s1: 0.022252, loss_fp: 0.006838, loss_freq: 0.022536
[15:27:21.002] iteration 19493: loss: 0.058717, loss_s1: 0.032999, loss_fp: 0.002447, loss_freq: 0.013912
[15:27:21.618] iteration 19494: loss: 0.061449, loss_s1: 0.031906, loss_fp: 0.002974, loss_freq: 0.053436
[15:27:22.235] iteration 19495: loss: 0.044470, loss_s1: 0.025003, loss_fp: 0.003096, loss_freq: 0.023519
[15:27:22.871] iteration 19496: loss: 0.040394, loss_s1: 0.022666, loss_fp: 0.001735, loss_freq: 0.012960
[15:27:23.486] iteration 19497: loss: 0.043796, loss_s1: 0.014676, loss_fp: 0.001290, loss_freq: 0.034024
[15:27:24.105] iteration 19498: loss: 0.049880, loss_s1: 0.039767, loss_fp: 0.001777, loss_freq: 0.014271
[15:27:24.722] iteration 19499: loss: 0.048965, loss_s1: 0.034424, loss_fp: 0.002791, loss_freq: 0.018623
[15:27:25.375] iteration 19500: loss: 0.047209, loss_s1: 0.021178, loss_fp: 0.000814, loss_freq: 0.019407
[15:27:26.016] iteration 19501: loss: 0.040550, loss_s1: 0.021299, loss_fp: 0.001034, loss_freq: 0.011561
[15:27:26.631] iteration 19502: loss: 0.058479, loss_s1: 0.027291, loss_fp: 0.004329, loss_freq: 0.015773
[15:27:27.252] iteration 19503: loss: 0.036493, loss_s1: 0.028500, loss_fp: 0.000757, loss_freq: 0.009808
[15:27:27.871] iteration 19504: loss: 0.046725, loss_s1: 0.015621, loss_fp: 0.003794, loss_freq: 0.016057
[15:27:28.490] iteration 19505: loss: 0.047735, loss_s1: 0.034936, loss_fp: 0.001472, loss_freq: 0.021701
[15:27:29.112] iteration 19506: loss: 0.058897, loss_s1: 0.041982, loss_fp: 0.002275, loss_freq: 0.012550
[15:27:29.731] iteration 19507: loss: 0.056202, loss_s1: 0.012798, loss_fp: 0.001392, loss_freq: 0.043198
[15:27:30.349] iteration 19508: loss: 0.057247, loss_s1: 0.039082, loss_fp: 0.004242, loss_freq: 0.031478
[15:27:30.967] iteration 19509: loss: 0.043906, loss_s1: 0.023630, loss_fp: 0.005357, loss_freq: 0.016696
[15:27:31.632] iteration 19510: loss: 0.074742, loss_s1: 0.032551, loss_fp: 0.001496, loss_freq: 0.076486
[15:27:32.256] iteration 19511: loss: 0.047857, loss_s1: 0.029332, loss_fp: 0.003095, loss_freq: 0.011973
[15:27:32.875] iteration 19512: loss: 0.066284, loss_s1: 0.040659, loss_fp: 0.005057, loss_freq: 0.033428
[15:27:33.489] iteration 19513: loss: 0.038757, loss_s1: 0.023329, loss_fp: 0.005237, loss_freq: 0.005716
[15:27:34.112] iteration 19514: loss: 0.046724, loss_s1: 0.039026, loss_fp: 0.004101, loss_freq: 0.010344
[15:27:34.767] iteration 19515: loss: 0.127152, loss_s1: 0.147930, loss_fp: 0.002703, loss_freq: 0.055534
[15:27:35.386] iteration 19516: loss: 0.058316, loss_s1: 0.034560, loss_fp: 0.006046, loss_freq: 0.041552
[15:27:36.008] iteration 19517: loss: 0.055224, loss_s1: 0.046354, loss_fp: 0.001165, loss_freq: 0.023768
[15:27:36.632] iteration 19518: loss: 0.043619, loss_s1: 0.019318, loss_fp: 0.001417, loss_freq: 0.013851
[15:27:37.259] iteration 19519: loss: 0.052788, loss_s1: 0.021131, loss_fp: 0.001195, loss_freq: 0.032113
[15:27:37.876] iteration 19520: loss: 0.048821, loss_s1: 0.030472, loss_fp: 0.001728, loss_freq: 0.009465
[15:27:38.496] iteration 19521: loss: 0.071308, loss_s1: 0.032653, loss_fp: 0.013190, loss_freq: 0.056875
[15:27:39.114] iteration 19522: loss: 0.074582, loss_s1: 0.055107, loss_fp: 0.003797, loss_freq: 0.042196
[15:27:39.727] iteration 19523: loss: 0.057644, loss_s1: 0.042880, loss_fp: 0.009731, loss_freq: 0.030703
[15:27:40.346] iteration 19524: loss: 0.071359, loss_s1: 0.034148, loss_fp: 0.000448, loss_freq: 0.020667
[15:27:40.992] iteration 19525: loss: 0.038827, loss_s1: 0.028344, loss_fp: 0.002721, loss_freq: 0.016407
[15:27:41.643] iteration 19526: loss: 0.057339, loss_s1: 0.042387, loss_fp: 0.003871, loss_freq: 0.016742
[15:27:42.280] iteration 19527: loss: 0.096462, loss_s1: 0.061242, loss_fp: 0.012434, loss_freq: 0.062821
[15:27:42.933] iteration 19528: loss: 0.102071, loss_s1: 0.095482, loss_fp: 0.007843, loss_freq: 0.039195
[15:27:43.568] iteration 19529: loss: 0.051786, loss_s1: 0.042865, loss_fp: 0.001272, loss_freq: 0.015961
[15:27:44.200] iteration 19530: loss: 0.057350, loss_s1: 0.042131, loss_fp: 0.005453, loss_freq: 0.022325
[15:27:44.835] iteration 19531: loss: 0.048231, loss_s1: 0.035331, loss_fp: 0.003076, loss_freq: 0.015481
[15:27:45.468] iteration 19532: loss: 0.051416, loss_s1: 0.020814, loss_fp: 0.007506, loss_freq: 0.030322
[15:27:46.111] iteration 19533: loss: 0.053149, loss_s1: 0.041043, loss_fp: 0.000998, loss_freq: 0.024473
[15:27:46.753] iteration 19534: loss: 0.088831, loss_s1: 0.061180, loss_fp: 0.013943, loss_freq: 0.057074
[15:27:47.389] iteration 19535: loss: 0.060655, loss_s1: 0.024147, loss_fp: 0.000718, loss_freq: 0.052475
[15:27:48.031] iteration 19536: loss: 0.057043, loss_s1: 0.033721, loss_fp: 0.002216, loss_freq: 0.030539
[15:27:48.667] iteration 19537: loss: 0.036254, loss_s1: 0.030220, loss_fp: 0.001205, loss_freq: 0.008787
[15:27:49.308] iteration 19538: loss: 0.042933, loss_s1: 0.028954, loss_fp: 0.002932, loss_freq: 0.018505
[15:27:49.924] iteration 19539: loss: 0.056109, loss_s1: 0.031578, loss_fp: 0.001868, loss_freq: 0.022660
[15:27:50.541] iteration 19540: loss: 0.073654, loss_s1: 0.058148, loss_fp: 0.005288, loss_freq: 0.050638
[15:27:51.161] iteration 19541: loss: 0.046783, loss_s1: 0.044227, loss_fp: 0.001378, loss_freq: 0.007314
[15:27:51.771] iteration 19542: loss: 0.035352, loss_s1: 0.028999, loss_fp: 0.004110, loss_freq: 0.004736
[15:27:52.394] iteration 19543: loss: 0.042288, loss_s1: 0.010595, loss_fp: 0.000882, loss_freq: 0.020265
[15:27:53.005] iteration 19544: loss: 0.045065, loss_s1: 0.008768, loss_fp: 0.000670, loss_freq: 0.003339
[15:27:53.633] iteration 19545: loss: 0.141313, loss_s1: 0.132298, loss_fp: 0.002677, loss_freq: 0.031645
[15:27:54.246] iteration 19546: loss: 0.048829, loss_s1: 0.019202, loss_fp: 0.002968, loss_freq: 0.023246
[15:27:54.887] iteration 19547: loss: 0.037908, loss_s1: 0.011801, loss_fp: 0.003094, loss_freq: 0.013409
[15:27:55.723] iteration 19548: loss: 0.083001, loss_s1: 0.024657, loss_fp: 0.003122, loss_freq: 0.025385
[15:27:56.455] iteration 19549: loss: 0.049083, loss_s1: 0.033257, loss_fp: 0.003529, loss_freq: 0.023299
[15:27:57.105] iteration 19550: loss: 0.062090, loss_s1: 0.018921, loss_fp: 0.005327, loss_freq: 0.045542
[15:27:57.722] iteration 19551: loss: 0.081741, loss_s1: 0.087734, loss_fp: 0.003512, loss_freq: 0.038826
[15:27:58.337] iteration 19552: loss: 0.039866, loss_s1: 0.013322, loss_fp: 0.000723, loss_freq: 0.016818
[15:27:58.944] iteration 19553: loss: 0.056732, loss_s1: 0.039608, loss_fp: 0.005173, loss_freq: 0.023669
[15:27:59.562] iteration 19554: loss: 0.042567, loss_s1: 0.020797, loss_fp: 0.004058, loss_freq: 0.015618
[15:28:00.205] iteration 19555: loss: 0.116482, loss_s1: 0.097959, loss_fp: 0.003058, loss_freq: 0.066283
[15:28:00.832] iteration 19556: loss: 0.104365, loss_s1: 0.060404, loss_fp: 0.009734, loss_freq: 0.067870
[15:28:01.454] iteration 19557: loss: 0.080349, loss_s1: 0.071128, loss_fp: 0.004742, loss_freq: 0.029446
[15:28:02.075] iteration 19558: loss: 0.105614, loss_s1: 0.032560, loss_fp: 0.011446, loss_freq: 0.111011
[15:28:02.696] iteration 19559: loss: 0.080090, loss_s1: 0.018934, loss_fp: 0.005570, loss_freq: 0.013828
[15:28:03.315] iteration 19560: loss: 0.046378, loss_s1: 0.024726, loss_fp: 0.004106, loss_freq: 0.012018
[15:28:03.933] iteration 19561: loss: 0.055338, loss_s1: 0.026485, loss_fp: 0.001319, loss_freq: 0.013447
[15:28:04.547] iteration 19562: loss: 0.080521, loss_s1: 0.069560, loss_fp: 0.002965, loss_freq: 0.036726
[15:28:05.212] iteration 19563: loss: 0.081278, loss_s1: 0.035424, loss_fp: 0.000549, loss_freq: 0.061923
[15:28:05.830] iteration 19564: loss: 0.035522, loss_s1: 0.014042, loss_fp: 0.003355, loss_freq: 0.009832
[15:28:06.446] iteration 19565: loss: 0.069570, loss_s1: 0.040122, loss_fp: 0.002323, loss_freq: 0.056725
[15:28:07.065] iteration 19566: loss: 0.068956, loss_s1: 0.052701, loss_fp: 0.005251, loss_freq: 0.032408
[15:28:07.680] iteration 19567: loss: 0.050150, loss_s1: 0.043596, loss_fp: 0.002861, loss_freq: 0.018758
[15:28:08.298] iteration 19568: loss: 0.062908, loss_s1: 0.042659, loss_fp: 0.003665, loss_freq: 0.039239
[15:28:08.917] iteration 19569: loss: 0.059526, loss_s1: 0.033543, loss_fp: 0.001320, loss_freq: 0.045659
[15:28:09.532] iteration 19570: loss: 0.065300, loss_s1: 0.066869, loss_fp: 0.003633, loss_freq: 0.009762
[15:28:10.152] iteration 19571: loss: 0.071031, loss_s1: 0.064428, loss_fp: 0.008246, loss_freq: 0.026077
[15:28:10.773] iteration 19572: loss: 0.063256, loss_s1: 0.063495, loss_fp: 0.002851, loss_freq: 0.027980
[15:28:11.420] iteration 19573: loss: 0.065699, loss_s1: 0.061554, loss_fp: 0.005274, loss_freq: 0.027575
[15:28:12.061] iteration 19574: loss: 0.060406, loss_s1: 0.037194, loss_fp: 0.003812, loss_freq: 0.004762
[15:28:12.688] iteration 19575: loss: 0.038375, loss_s1: 0.017975, loss_fp: 0.001535, loss_freq: 0.016089
[15:28:13.299] iteration 19576: loss: 0.035716, loss_s1: 0.023541, loss_fp: 0.000952, loss_freq: 0.009019
[15:28:13.920] iteration 19577: loss: 0.077329, loss_s1: 0.061888, loss_fp: 0.009969, loss_freq: 0.027608
[15:28:14.542] iteration 19578: loss: 0.058977, loss_s1: 0.042303, loss_fp: 0.004138, loss_freq: 0.023444
[15:28:15.212] iteration 19579: loss: 0.053044, loss_s1: 0.037026, loss_fp: 0.010341, loss_freq: 0.011910
[15:28:15.833] iteration 19580: loss: 0.078654, loss_s1: 0.071371, loss_fp: 0.006777, loss_freq: 0.027815
[15:28:16.449] iteration 19581: loss: 0.043041, loss_s1: 0.015989, loss_fp: 0.002348, loss_freq: 0.009924
[15:28:17.079] iteration 19582: loss: 0.082033, loss_s1: 0.053892, loss_fp: 0.004024, loss_freq: 0.055782
[15:28:17.691] iteration 19583: loss: 0.083336, loss_s1: 0.022109, loss_fp: 0.005090, loss_freq: 0.042918
[15:28:18.304] iteration 19584: loss: 0.049093, loss_s1: 0.033628, loss_fp: 0.009383, loss_freq: 0.013558
[15:28:18.923] iteration 19585: loss: 0.095605, loss_s1: 0.055611, loss_fp: 0.006768, loss_freq: 0.062464
[15:28:19.542] iteration 19586: loss: 0.036250, loss_s1: 0.022586, loss_fp: 0.000292, loss_freq: 0.013824
[15:28:20.158] iteration 19587: loss: 0.061735, loss_s1: 0.061996, loss_fp: 0.000873, loss_freq: 0.020730
[15:28:20.781] iteration 19588: loss: 0.050410, loss_s1: 0.032677, loss_fp: 0.002877, loss_freq: 0.020041
[15:28:21.395] iteration 19589: loss: 0.072942, loss_s1: 0.065927, loss_fp: 0.003737, loss_freq: 0.035984
[15:28:22.010] iteration 19590: loss: 0.069637, loss_s1: 0.069157, loss_fp: 0.003912, loss_freq: 0.012527
[15:28:22.629] iteration 19591: loss: 0.039754, loss_s1: 0.013821, loss_fp: 0.001271, loss_freq: 0.021668
[15:28:23.625] iteration 19592: loss: 0.045554, loss_s1: 0.040758, loss_fp: 0.000539, loss_freq: 0.010591
[15:28:24.271] iteration 19593: loss: 0.072468, loss_s1: 0.043938, loss_fp: 0.003751, loss_freq: 0.042651
[15:28:24.934] iteration 19594: loss: 0.042700, loss_s1: 0.023653, loss_fp: 0.002521, loss_freq: 0.025734
[15:28:25.580] iteration 19595: loss: 0.059225, loss_s1: 0.029797, loss_fp: 0.003646, loss_freq: 0.022460
[15:28:26.226] iteration 19596: loss: 0.060958, loss_s1: 0.035619, loss_fp: 0.001024, loss_freq: 0.027236
[15:28:26.857] iteration 19597: loss: 0.034682, loss_s1: 0.018142, loss_fp: 0.001090, loss_freq: 0.005976
[15:28:27.483] iteration 19598: loss: 0.035762, loss_s1: 0.025667, loss_fp: 0.003850, loss_freq: 0.009665
[15:28:28.104] iteration 19599: loss: 0.080846, loss_s1: 0.077700, loss_fp: 0.001766, loss_freq: 0.026244
[15:28:28.727] iteration 19600: loss: 0.064725, loss_s1: 0.060681, loss_fp: 0.003166, loss_freq: 0.023526
[15:28:32.273] iteration 19600 : mean_dice : 0.773710
[15:28:32.935] iteration 19601: loss: 0.056842, loss_s1: 0.032384, loss_fp: 0.000724, loss_freq: 0.004336
[15:28:33.572] iteration 19602: loss: 0.087088, loss_s1: 0.058588, loss_fp: 0.004584, loss_freq: 0.074099
[15:28:34.200] iteration 19603: loss: 0.083319, loss_s1: 0.056592, loss_fp: 0.002308, loss_freq: 0.044797
[15:28:34.820] iteration 19604: loss: 0.096158, loss_s1: 0.073856, loss_fp: 0.008160, loss_freq: 0.029494
[15:28:35.441] iteration 19605: loss: 0.028926, loss_s1: 0.014723, loss_fp: 0.002519, loss_freq: 0.006202
[15:28:36.063] iteration 19606: loss: 0.066944, loss_s1: 0.036051, loss_fp: 0.003633, loss_freq: 0.031269
[15:28:36.687] iteration 19607: loss: 0.066454, loss_s1: 0.057522, loss_fp: 0.005262, loss_freq: 0.020859
[15:28:37.315] iteration 19608: loss: 0.077890, loss_s1: 0.047310, loss_fp: 0.001067, loss_freq: 0.025246
[15:28:37.943] iteration 19609: loss: 0.042665, loss_s1: 0.021480, loss_fp: 0.004679, loss_freq: 0.010563
[15:28:38.565] iteration 19610: loss: 0.043455, loss_s1: 0.035970, loss_fp: 0.002681, loss_freq: 0.014195
[15:28:39.188] iteration 19611: loss: 0.040816, loss_s1: 0.032185, loss_fp: 0.004529, loss_freq: 0.015171
[15:28:39.806] iteration 19612: loss: 0.061779, loss_s1: 0.046866, loss_fp: 0.002681, loss_freq: 0.030128
[15:28:40.427] iteration 19613: loss: 0.047972, loss_s1: 0.023062, loss_fp: 0.000863, loss_freq: 0.023719
[15:28:41.073] iteration 19614: loss: 0.042524, loss_s1: 0.026205, loss_fp: 0.002801, loss_freq: 0.020245
[15:28:41.715] iteration 19615: loss: 0.050636, loss_s1: 0.040660, loss_fp: 0.000709, loss_freq: 0.017238
[15:28:42.350] iteration 19616: loss: 0.043934, loss_s1: 0.024538, loss_fp: 0.005154, loss_freq: 0.009152
[15:28:42.965] iteration 19617: loss: 0.080993, loss_s1: 0.058097, loss_fp: 0.000952, loss_freq: 0.042375
[15:28:43.590] iteration 19618: loss: 0.082776, loss_s1: 0.046645, loss_fp: 0.004704, loss_freq: 0.054272
[15:28:44.211] iteration 19619: loss: 0.060660, loss_s1: 0.060184, loss_fp: 0.004912, loss_freq: 0.006284
[15:28:44.833] iteration 19620: loss: 0.085557, loss_s1: 0.083939, loss_fp: 0.000873, loss_freq: 0.039425
[15:28:45.450] iteration 19621: loss: 0.060927, loss_s1: 0.030923, loss_fp: 0.001163, loss_freq: 0.015287
[15:28:46.067] iteration 19622: loss: 0.055922, loss_s1: 0.034529, loss_fp: 0.001167, loss_freq: 0.022418
[15:28:46.691] iteration 19623: loss: 0.069054, loss_s1: 0.045494, loss_fp: 0.013290, loss_freq: 0.014648
[15:28:47.310] iteration 19624: loss: 0.116364, loss_s1: 0.149121, loss_fp: 0.007109, loss_freq: 0.046426
[15:28:47.930] iteration 19625: loss: 0.090840, loss_s1: 0.085050, loss_fp: 0.007001, loss_freq: 0.046789
[15:28:48.548] iteration 19626: loss: 0.074335, loss_s1: 0.033081, loss_fp: 0.005005, loss_freq: 0.039624
[15:28:49.164] iteration 19627: loss: 0.089092, loss_s1: 0.065856, loss_fp: 0.005878, loss_freq: 0.057297
[15:28:49.791] iteration 19628: loss: 0.077871, loss_s1: 0.064186, loss_fp: 0.003207, loss_freq: 0.033110
[15:28:50.409] iteration 19629: loss: 0.068654, loss_s1: 0.057109, loss_fp: 0.010177, loss_freq: 0.038184
[15:28:51.032] iteration 19630: loss: 0.082011, loss_s1: 0.017093, loss_fp: 0.005205, loss_freq: 0.059040
[15:28:51.651] iteration 19631: loss: 0.044723, loss_s1: 0.031747, loss_fp: 0.005844, loss_freq: 0.013575
[15:28:52.272] iteration 19632: loss: 0.105677, loss_s1: 0.072729, loss_fp: 0.006613, loss_freq: 0.023017
[15:28:52.892] iteration 19633: loss: 0.052699, loss_s1: 0.048597, loss_fp: 0.005848, loss_freq: 0.018669
[15:28:53.517] iteration 19634: loss: 0.075821, loss_s1: 0.033219, loss_fp: 0.004185, loss_freq: 0.020062
[15:28:54.181] iteration 19635: loss: 0.056320, loss_s1: 0.040491, loss_fp: 0.007376, loss_freq: 0.014534
[15:28:54.799] iteration 19636: loss: 0.036237, loss_s1: 0.011200, loss_fp: 0.001725, loss_freq: 0.003521
[15:28:55.444] iteration 19637: loss: 0.047582, loss_s1: 0.030687, loss_fp: 0.000720, loss_freq: 0.020272
[15:28:56.085] iteration 19638: loss: 0.036897, loss_s1: 0.018828, loss_fp: 0.000579, loss_freq: 0.017094
[15:28:56.719] iteration 19639: loss: 0.058201, loss_s1: 0.040022, loss_fp: 0.001890, loss_freq: 0.032644
[15:28:57.349] iteration 19640: loss: 0.065403, loss_s1: 0.061756, loss_fp: 0.002036, loss_freq: 0.029710
[15:28:58.016] iteration 19641: loss: 0.040362, loss_s1: 0.029625, loss_fp: 0.001558, loss_freq: 0.008852
[15:28:58.659] iteration 19642: loss: 0.043777, loss_s1: 0.018757, loss_fp: 0.001930, loss_freq: 0.008868
[15:28:59.287] iteration 19643: loss: 0.055207, loss_s1: 0.021166, loss_fp: 0.001175, loss_freq: 0.023082
[15:28:59.906] iteration 19644: loss: 0.053052, loss_s1: 0.022489, loss_fp: 0.001336, loss_freq: 0.026105
[15:29:00.539] iteration 19645: loss: 0.042589, loss_s1: 0.036277, loss_fp: 0.002392, loss_freq: 0.006396
[15:29:01.174] iteration 19646: loss: 0.050755, loss_s1: 0.048335, loss_fp: 0.001637, loss_freq: 0.007410
[15:29:01.818] iteration 19647: loss: 0.052549, loss_s1: 0.022821, loss_fp: 0.001412, loss_freq: 0.004791
[15:29:02.482] iteration 19648: loss: 0.084035, loss_s1: 0.064229, loss_fp: 0.010599, loss_freq: 0.016326
[15:29:03.111] iteration 19649: loss: 0.049989, loss_s1: 0.015325, loss_fp: 0.004012, loss_freq: 0.036828
[15:29:03.735] iteration 19650: loss: 0.075247, loss_s1: 0.021856, loss_fp: 0.003911, loss_freq: 0.068182
[15:29:04.363] iteration 19651: loss: 0.062034, loss_s1: 0.057097, loss_fp: 0.002353, loss_freq: 0.018167
[15:29:04.992] iteration 19652: loss: 0.080601, loss_s1: 0.052723, loss_fp: 0.006336, loss_freq: 0.031130
[15:29:05.621] iteration 19653: loss: 0.054030, loss_s1: 0.044690, loss_fp: 0.001136, loss_freq: 0.008798
[15:29:06.247] iteration 19654: loss: 0.087014, loss_s1: 0.049832, loss_fp: 0.018330, loss_freq: 0.043415
[15:29:06.869] iteration 19655: loss: 0.070247, loss_s1: 0.029083, loss_fp: 0.003350, loss_freq: 0.023366
[15:29:07.493] iteration 19656: loss: 0.069299, loss_s1: 0.059156, loss_fp: 0.007324, loss_freq: 0.028107
[15:29:08.158] iteration 19657: loss: 0.060395, loss_s1: 0.041492, loss_fp: 0.001859, loss_freq: 0.035120
[15:29:08.778] iteration 19658: loss: 0.081928, loss_s1: 0.046856, loss_fp: 0.007030, loss_freq: 0.053586
[15:29:09.389] iteration 19659: loss: 0.067016, loss_s1: 0.059987, loss_fp: 0.003978, loss_freq: 0.038144
[15:29:10.008] iteration 19660: loss: 0.091436, loss_s1: 0.114448, loss_fp: 0.000658, loss_freq: 0.017674
[15:29:10.628] iteration 19661: loss: 0.046322, loss_s1: 0.008461, loss_fp: 0.011847, loss_freq: 0.006955
[15:29:11.246] iteration 19662: loss: 0.044451, loss_s1: 0.017016, loss_fp: 0.001155, loss_freq: 0.026622
[15:29:11.862] iteration 19663: loss: 0.102295, loss_s1: 0.092750, loss_fp: 0.008073, loss_freq: 0.059969
[15:29:12.485] iteration 19664: loss: 0.069161, loss_s1: 0.028612, loss_fp: 0.000601, loss_freq: 0.073117
[15:29:13.109] iteration 19665: loss: 0.084537, loss_s1: 0.071706, loss_fp: 0.013680, loss_freq: 0.038179
[15:29:13.730] iteration 19666: loss: 0.074952, loss_s1: 0.061947, loss_fp: 0.005778, loss_freq: 0.050696
[15:29:14.349] iteration 19667: loss: 0.064166, loss_s1: 0.032567, loss_fp: 0.000529, loss_freq: 0.007064
[15:29:14.967] iteration 19668: loss: 0.062081, loss_s1: 0.062923, loss_fp: 0.002533, loss_freq: 0.024948
[15:29:15.590] iteration 19669: loss: 0.062688, loss_s1: 0.024958, loss_fp: 0.011937, loss_freq: 0.030339
[15:29:16.209] iteration 19670: loss: 0.074673, loss_s1: 0.057078, loss_fp: 0.005763, loss_freq: 0.046218
[15:29:16.823] iteration 19671: loss: 0.099797, loss_s1: 0.066890, loss_fp: 0.007972, loss_freq: 0.034004
[15:29:17.447] iteration 19672: loss: 0.068865, loss_s1: 0.041350, loss_fp: 0.001549, loss_freq: 0.032564
[15:29:18.067] iteration 19673: loss: 0.044277, loss_s1: 0.039896, loss_fp: 0.003177, loss_freq: 0.008132
[15:29:18.689] iteration 19674: loss: 0.058264, loss_s1: 0.025562, loss_fp: 0.008335, loss_freq: 0.020485
[15:29:19.333] iteration 19675: loss: 0.043247, loss_s1: 0.031860, loss_fp: 0.003227, loss_freq: 0.010560
[15:29:19.965] iteration 19676: loss: 0.093049, loss_s1: 0.078407, loss_fp: 0.006092, loss_freq: 0.049190
[15:29:20.585] iteration 19677: loss: 0.057600, loss_s1: 0.032419, loss_fp: 0.015284, loss_freq: 0.029339
[15:29:21.205] iteration 19678: loss: 0.043800, loss_s1: 0.033053, loss_fp: 0.001774, loss_freq: 0.005738
[15:29:21.837] iteration 19679: loss: 0.053059, loss_s1: 0.027916, loss_fp: 0.008592, loss_freq: 0.029390
[15:29:22.463] iteration 19680: loss: 0.036352, loss_s1: 0.022866, loss_fp: 0.002312, loss_freq: 0.007503
[15:29:23.123] iteration 19681: loss: 0.065287, loss_s1: 0.066042, loss_fp: 0.003759, loss_freq: 0.027135
[15:29:23.793] iteration 19682: loss: 0.061743, loss_s1: 0.023927, loss_fp: 0.003752, loss_freq: 0.020021
[15:29:24.459] iteration 19683: loss: 0.084157, loss_s1: 0.106893, loss_fp: 0.001473, loss_freq: 0.021047
[15:29:25.106] iteration 19684: loss: 0.060583, loss_s1: 0.041050, loss_fp: 0.000489, loss_freq: 0.024535
[15:29:25.733] iteration 19685: loss: 0.038675, loss_s1: 0.022998, loss_fp: 0.002927, loss_freq: 0.010585
[15:29:26.364] iteration 19686: loss: 0.035085, loss_s1: 0.018403, loss_fp: 0.003591, loss_freq: 0.008187
[15:29:27.015] iteration 19687: loss: 0.042365, loss_s1: 0.010210, loss_fp: 0.000820, loss_freq: 0.019089
[15:29:27.659] iteration 19688: loss: 0.080607, loss_s1: 0.054187, loss_fp: 0.002293, loss_freq: 0.041384
[15:29:28.305] iteration 19689: loss: 0.052244, loss_s1: 0.031758, loss_fp: 0.002961, loss_freq: 0.020229
[15:29:28.944] iteration 19690: loss: 0.098811, loss_s1: 0.056331, loss_fp: 0.004012, loss_freq: 0.066360
[15:29:29.576] iteration 19691: loss: 0.069528, loss_s1: 0.075223, loss_fp: 0.002612, loss_freq: 0.017780
[15:29:30.212] iteration 19692: loss: 0.040736, loss_s1: 0.018423, loss_fp: 0.001814, loss_freq: 0.017783
[15:29:30.859] iteration 19693: loss: 0.070152, loss_s1: 0.064579, loss_fp: 0.001278, loss_freq: 0.032572
[15:29:31.497] iteration 19694: loss: 0.067821, loss_s1: 0.058150, loss_fp: 0.006613, loss_freq: 0.031979
[15:29:32.125] iteration 19695: loss: 0.041184, loss_s1: 0.022597, loss_fp: 0.000524, loss_freq: 0.013260
[15:29:32.751] iteration 19696: loss: 0.045185, loss_s1: 0.016396, loss_fp: 0.001366, loss_freq: 0.014986
[15:29:33.368] iteration 19697: loss: 0.055904, loss_s1: 0.038784, loss_fp: 0.006671, loss_freq: 0.026439
[15:29:33.992] iteration 19698: loss: 0.060872, loss_s1: 0.039067, loss_fp: 0.004244, loss_freq: 0.039745
[15:29:34.616] iteration 19699: loss: 0.077955, loss_s1: 0.078365, loss_fp: 0.017535, loss_freq: 0.025013
[15:29:35.261] iteration 19700: loss: 0.055208, loss_s1: 0.040335, loss_fp: 0.001183, loss_freq: 0.017527
[15:29:35.877] iteration 19701: loss: 0.110457, loss_s1: 0.050591, loss_fp: 0.001812, loss_freq: 0.132386
[15:29:36.500] iteration 19702: loss: 0.055123, loss_s1: 0.015574, loss_fp: 0.001430, loss_freq: 0.032422
[15:29:37.117] iteration 19703: loss: 0.071346, loss_s1: 0.036973, loss_fp: 0.003551, loss_freq: 0.011863
[15:29:37.760] iteration 19704: loss: 0.057030, loss_s1: 0.060978, loss_fp: 0.001799, loss_freq: 0.008878
[15:29:38.383] iteration 19705: loss: 0.052845, loss_s1: 0.044331, loss_fp: 0.005083, loss_freq: 0.009502
[15:29:39.003] iteration 19706: loss: 0.156004, loss_s1: 0.141948, loss_fp: 0.016139, loss_freq: 0.097633
[15:29:39.623] iteration 19707: loss: 0.038119, loss_s1: 0.014328, loss_fp: 0.001184, loss_freq: 0.011623
[15:29:40.241] iteration 19708: loss: 0.059843, loss_s1: 0.044425, loss_fp: 0.004272, loss_freq: 0.021838
[15:29:40.859] iteration 19709: loss: 0.075904, loss_s1: 0.078404, loss_fp: 0.001916, loss_freq: 0.016635
[15:29:41.478] iteration 19710: loss: 0.099373, loss_s1: 0.137408, loss_fp: 0.003509, loss_freq: 0.015252
[15:29:42.092] iteration 19711: loss: 0.061159, loss_s1: 0.047334, loss_fp: 0.000609, loss_freq: 0.031583
[15:29:42.768] iteration 19712: loss: 0.068589, loss_s1: 0.059966, loss_fp: 0.001455, loss_freq: 0.037601
[15:29:43.408] iteration 19713: loss: 0.071021, loss_s1: 0.032763, loss_fp: 0.001606, loss_freq: 0.037479
[15:29:44.048] iteration 19714: loss: 0.035247, loss_s1: 0.027804, loss_fp: 0.001259, loss_freq: 0.003989
[15:29:44.665] iteration 19715: loss: 0.084629, loss_s1: 0.073632, loss_fp: 0.004423, loss_freq: 0.059603
[15:29:45.285] iteration 19716: loss: 0.057847, loss_s1: 0.071689, loss_fp: 0.001951, loss_freq: 0.012868
[15:29:45.951] iteration 19717: loss: 0.063436, loss_s1: 0.060771, loss_fp: 0.006007, loss_freq: 0.011457
[15:29:46.569] iteration 19718: loss: 0.048556, loss_s1: 0.018020, loss_fp: 0.001988, loss_freq: 0.022918
[15:29:47.189] iteration 19719: loss: 0.050089, loss_s1: 0.022656, loss_fp: 0.002198, loss_freq: 0.027001
[15:29:47.814] iteration 19720: loss: 0.054852, loss_s1: 0.045547, loss_fp: 0.001002, loss_freq: 0.011403
[15:29:48.439] iteration 19721: loss: 0.041682, loss_s1: 0.020886, loss_fp: 0.003719, loss_freq: 0.022426
[15:29:49.129] iteration 19722: loss: 0.056667, loss_s1: 0.023276, loss_fp: 0.006874, loss_freq: 0.042090
[15:29:49.780] iteration 19723: loss: 0.071643, loss_s1: 0.049302, loss_fp: 0.009774, loss_freq: 0.026918
[15:29:50.402] iteration 19724: loss: 0.062922, loss_s1: 0.056843, loss_fp: 0.002203, loss_freq: 0.015427
[15:29:51.030] iteration 19725: loss: 0.062687, loss_s1: 0.020260, loss_fp: 0.008600, loss_freq: 0.035325
[15:29:51.657] iteration 19726: loss: 0.078455, loss_s1: 0.029175, loss_fp: 0.004492, loss_freq: 0.050122
[15:29:52.280] iteration 19727: loss: 0.071230, loss_s1: 0.063620, loss_fp: 0.003967, loss_freq: 0.019091
[15:29:52.916] iteration 19728: loss: 0.073794, loss_s1: 0.063277, loss_fp: 0.009993, loss_freq: 0.010663
[15:29:53.545] iteration 19729: loss: 0.065980, loss_s1: 0.056313, loss_fp: 0.001864, loss_freq: 0.016053
[15:29:54.171] iteration 19730: loss: 0.047905, loss_s1: 0.032168, loss_fp: 0.005270, loss_freq: 0.016956
[15:29:54.791] iteration 19731: loss: 0.060296, loss_s1: 0.059768, loss_fp: 0.002152, loss_freq: 0.010504
[15:29:55.426] iteration 19732: loss: 0.057107, loss_s1: 0.039225, loss_fp: 0.003917, loss_freq: 0.030734
[15:29:56.049] iteration 19733: loss: 0.128239, loss_s1: 0.115929, loss_fp: 0.040714, loss_freq: 0.055040
[15:29:56.665] iteration 19734: loss: 0.055297, loss_s1: 0.025727, loss_fp: 0.001582, loss_freq: 0.028788
[15:29:57.635] iteration 19735: loss: 0.063807, loss_s1: 0.065462, loss_fp: 0.001745, loss_freq: 0.014274
[15:29:58.318] iteration 19736: loss: 0.071485, loss_s1: 0.052929, loss_fp: 0.003489, loss_freq: 0.036453
[15:29:58.975] iteration 19737: loss: 0.041381, loss_s1: 0.025234, loss_fp: 0.001554, loss_freq: 0.021162
[15:29:59.916] iteration 19738: loss: 0.049547, loss_s1: 0.020480, loss_fp: 0.001884, loss_freq: 0.024049
[15:30:00.778] iteration 19739: loss: 0.064823, loss_s1: 0.053003, loss_fp: 0.000520, loss_freq: 0.046002
[15:30:01.577] iteration 19740: loss: 0.071741, loss_s1: 0.040226, loss_fp: 0.005666, loss_freq: 0.012838
[15:30:02.249] iteration 19741: loss: 0.041067, loss_s1: 0.024529, loss_fp: 0.001394, loss_freq: 0.025167
[15:30:02.884] iteration 19742: loss: 0.085693, loss_s1: 0.077365, loss_fp: 0.001650, loss_freq: 0.021773
[15:30:03.498] iteration 19743: loss: 0.073020, loss_s1: 0.032086, loss_fp: 0.012174, loss_freq: 0.040853
[15:30:04.123] iteration 19744: loss: 0.036890, loss_s1: 0.002136, loss_fp: 0.000299, loss_freq: 0.008246
[15:30:04.740] iteration 19745: loss: 0.076519, loss_s1: 0.044717, loss_fp: 0.012313, loss_freq: 0.061867
[15:30:05.356] iteration 19746: loss: 0.051732, loss_s1: 0.029784, loss_fp: 0.001291, loss_freq: 0.006272
[15:30:05.972] iteration 19747: loss: 0.092384, loss_s1: 0.090976, loss_fp: 0.007900, loss_freq: 0.032852
[15:30:06.593] iteration 19748: loss: 0.038780, loss_s1: 0.038874, loss_fp: 0.000510, loss_freq: 0.010706
[15:30:07.216] iteration 19749: loss: 0.075687, loss_s1: 0.079267, loss_fp: 0.001205, loss_freq: 0.030867
[15:30:07.838] iteration 19750: loss: 0.047361, loss_s1: 0.036605, loss_fp: 0.002968, loss_freq: 0.016489
[15:30:08.501] iteration 19751: loss: 0.062229, loss_s1: 0.048666, loss_fp: 0.002144, loss_freq: 0.023502
[15:30:09.132] iteration 19752: loss: 0.065073, loss_s1: 0.048249, loss_fp: 0.002398, loss_freq: 0.037879
[15:30:09.755] iteration 19753: loss: 0.074091, loss_s1: 0.069921, loss_fp: 0.004046, loss_freq: 0.018193
[15:30:10.420] iteration 19754: loss: 0.040558, loss_s1: 0.025049, loss_fp: 0.003356, loss_freq: 0.011814
[15:30:11.047] iteration 19755: loss: 0.085313, loss_s1: 0.033661, loss_fp: 0.003792, loss_freq: 0.042634
[15:30:11.670] iteration 19756: loss: 0.066154, loss_s1: 0.054784, loss_fp: 0.000511, loss_freq: 0.039581
[15:30:12.292] iteration 19757: loss: 0.082697, loss_s1: 0.093395, loss_fp: 0.004005, loss_freq: 0.022967
[15:30:12.916] iteration 19758: loss: 0.037308, loss_s1: 0.020991, loss_fp: 0.001216, loss_freq: 0.004180
[15:30:13.543] iteration 19759: loss: 0.045376, loss_s1: 0.025555, loss_fp: 0.000988, loss_freq: 0.018751
[15:30:14.170] iteration 19760: loss: 0.044733, loss_s1: 0.025149, loss_fp: 0.002286, loss_freq: 0.026847
[15:30:14.788] iteration 19761: loss: 0.081181, loss_s1: 0.048394, loss_fp: 0.003567, loss_freq: 0.066643
[15:30:15.411] iteration 19762: loss: 0.055609, loss_s1: 0.045458, loss_fp: 0.001940, loss_freq: 0.010600
[15:30:16.028] iteration 19763: loss: 0.079397, loss_s1: 0.057856, loss_fp: 0.001799, loss_freq: 0.050042
[15:30:16.651] iteration 19764: loss: 0.035696, loss_s1: 0.020163, loss_fp: 0.004033, loss_freq: 0.003914
[15:30:17.276] iteration 19765: loss: 0.056541, loss_s1: 0.059118, loss_fp: 0.004556, loss_freq: 0.010775
[15:30:17.911] iteration 19766: loss: 0.075959, loss_s1: 0.048779, loss_fp: 0.002717, loss_freq: 0.031996
[15:30:18.540] iteration 19767: loss: 0.070394, loss_s1: 0.038538, loss_fp: 0.028766, loss_freq: 0.041806
[15:30:19.158] iteration 19768: loss: 0.107745, loss_s1: 0.117795, loss_fp: 0.015575, loss_freq: 0.046907
[15:30:19.786] iteration 19769: loss: 0.071049, loss_s1: 0.059160, loss_fp: 0.009837, loss_freq: 0.015674
[15:30:20.432] iteration 19770: loss: 0.070030, loss_s1: 0.028634, loss_fp: 0.022798, loss_freq: 0.035440
[15:30:21.053] iteration 19771: loss: 0.062864, loss_s1: 0.045716, loss_fp: 0.005389, loss_freq: 0.020381
[15:30:21.682] iteration 19772: loss: 0.072937, loss_s1: 0.063047, loss_fp: 0.016247, loss_freq: 0.029846
[15:30:22.303] iteration 19773: loss: 0.086198, loss_s1: 0.031024, loss_fp: 0.005185, loss_freq: 0.037487
[15:30:22.981] iteration 19774: loss: 0.065921, loss_s1: 0.042296, loss_fp: 0.008207, loss_freq: 0.024492
[15:30:23.617] iteration 19775: loss: 0.058711, loss_s1: 0.053258, loss_fp: 0.009048, loss_freq: 0.011409
[15:30:24.266] iteration 19776: loss: 0.043767, loss_s1: 0.022388, loss_fp: 0.001456, loss_freq: 0.027173
[15:30:24.904] iteration 19777: loss: 0.045054, loss_s1: 0.031317, loss_fp: 0.003897, loss_freq: 0.008040
[15:30:25.529] iteration 19778: loss: 0.084735, loss_s1: 0.047878, loss_fp: 0.012240, loss_freq: 0.059164
[15:30:26.153] iteration 19779: loss: 0.064905, loss_s1: 0.016166, loss_fp: 0.001971, loss_freq: 0.048677
[15:30:26.772] iteration 19780: loss: 0.081985, loss_s1: 0.070333, loss_fp: 0.001603, loss_freq: 0.045437
[15:30:27.388] iteration 19781: loss: 0.052662, loss_s1: 0.018531, loss_fp: 0.003034, loss_freq: 0.035659
[15:30:28.067] iteration 19782: loss: 0.045409, loss_s1: 0.015099, loss_fp: 0.008215, loss_freq: 0.011836
[15:30:28.691] iteration 19783: loss: 0.051543, loss_s1: 0.027454, loss_fp: 0.001699, loss_freq: 0.044923
[15:30:29.321] iteration 19784: loss: 0.056036, loss_s1: 0.037945, loss_fp: 0.005643, loss_freq: 0.018626
[15:30:29.940] iteration 19785: loss: 0.050116, loss_s1: 0.043938, loss_fp: 0.002549, loss_freq: 0.015867
[15:30:30.567] iteration 19786: loss: 0.040864, loss_s1: 0.018311, loss_fp: 0.000548, loss_freq: 0.018366
[15:30:31.189] iteration 19787: loss: 0.041994, loss_s1: 0.028852, loss_fp: 0.001302, loss_freq: 0.016639
[15:30:31.800] iteration 19788: loss: 0.046773, loss_s1: 0.046432, loss_fp: 0.003354, loss_freq: 0.014096
[15:30:32.424] iteration 19789: loss: 0.027091, loss_s1: 0.021311, loss_fp: 0.001878, loss_freq: 0.003465
[15:30:33.074] iteration 19790: loss: 0.046121, loss_s1: 0.018746, loss_fp: 0.000942, loss_freq: 0.008980
[15:30:33.699] iteration 19791: loss: 0.072370, loss_s1: 0.072651, loss_fp: 0.001793, loss_freq: 0.035018
[15:30:34.324] iteration 19792: loss: 0.035389, loss_s1: 0.013995, loss_fp: 0.003043, loss_freq: 0.002418
[15:30:34.943] iteration 19793: loss: 0.070363, loss_s1: 0.028583, loss_fp: 0.001551, loss_freq: 0.046805
[15:30:35.567] iteration 19794: loss: 0.039564, loss_s1: 0.009069, loss_fp: 0.002926, loss_freq: 0.023258
[15:30:36.189] iteration 19795: loss: 0.059880, loss_s1: 0.019656, loss_fp: 0.002021, loss_freq: 0.021706
[15:30:36.805] iteration 19796: loss: 0.045819, loss_s1: 0.033287, loss_fp: 0.001791, loss_freq: 0.004940
[15:30:37.418] iteration 19797: loss: 0.100544, loss_s1: 0.102867, loss_fp: 0.009344, loss_freq: 0.047748
[15:30:38.034] iteration 19798: loss: 0.055025, loss_s1: 0.028330, loss_fp: 0.000432, loss_freq: 0.019789
[15:30:38.654] iteration 19799: loss: 0.095108, loss_s1: 0.053944, loss_fp: 0.001143, loss_freq: 0.033954
[15:30:39.291] iteration 19800: loss: 0.053342, loss_s1: 0.025793, loss_fp: 0.001171, loss_freq: 0.036330
[15:30:42.663] iteration 19800 : mean_dice : 0.779302
[15:30:43.305] iteration 19801: loss: 0.077607, loss_s1: 0.049112, loss_fp: 0.007922, loss_freq: 0.049172
[15:30:43.930] iteration 19802: loss: 0.042134, loss_s1: 0.027252, loss_fp: 0.002347, loss_freq: 0.017249
[15:30:44.547] iteration 19803: loss: 0.046786, loss_s1: 0.038808, loss_fp: 0.001837, loss_freq: 0.009531
[15:30:45.157] iteration 19804: loss: 0.051794, loss_s1: 0.030325, loss_fp: 0.002481, loss_freq: 0.019703
[15:30:45.777] iteration 19805: loss: 0.045167, loss_s1: 0.024352, loss_fp: 0.003441, loss_freq: 0.016949
[15:30:46.401] iteration 19806: loss: 0.060933, loss_s1: 0.050293, loss_fp: 0.006161, loss_freq: 0.016017
[15:30:47.026] iteration 19807: loss: 0.071739, loss_s1: 0.043444, loss_fp: 0.003444, loss_freq: 0.062149
[15:30:47.650] iteration 19808: loss: 0.059707, loss_s1: 0.059843, loss_fp: 0.004402, loss_freq: 0.011463
[15:30:48.272] iteration 19809: loss: 0.072589, loss_s1: 0.042220, loss_fp: 0.005449, loss_freq: 0.058563
[15:30:48.888] iteration 19810: loss: 0.053101, loss_s1: 0.050539, loss_fp: 0.004005, loss_freq: 0.008212
[15:30:49.512] iteration 19811: loss: 0.055870, loss_s1: 0.035023, loss_fp: 0.002695, loss_freq: 0.030971
[15:30:50.132] iteration 19812: loss: 0.055510, loss_s1: 0.036549, loss_fp: 0.001232, loss_freq: 0.007787
[15:30:50.753] iteration 19813: loss: 0.120495, loss_s1: 0.074231, loss_fp: 0.004134, loss_freq: 0.099453
[15:30:51.376] iteration 19814: loss: 0.069728, loss_s1: 0.056550, loss_fp: 0.014648, loss_freq: 0.020253
[15:30:51.987] iteration 19815: loss: 0.126364, loss_s1: 0.066218, loss_fp: 0.006758, loss_freq: 0.105772
[15:30:52.608] iteration 19816: loss: 0.060660, loss_s1: 0.054580, loss_fp: 0.004616, loss_freq: 0.019236
[15:30:53.283] iteration 19817: loss: 0.032721, loss_s1: 0.013318, loss_fp: 0.000600, loss_freq: 0.009821
[15:30:53.938] iteration 19818: loss: 0.041301, loss_s1: 0.038527, loss_fp: 0.002396, loss_freq: 0.013464
[15:30:54.556] iteration 19819: loss: 0.052174, loss_s1: 0.041511, loss_fp: 0.000794, loss_freq: 0.022639
[15:30:55.172] iteration 19820: loss: 0.056542, loss_s1: 0.031402, loss_fp: 0.002423, loss_freq: 0.047473
[15:30:55.784] iteration 19821: loss: 0.058809, loss_s1: 0.033334, loss_fp: 0.002644, loss_freq: 0.021331
[15:30:56.396] iteration 19822: loss: 0.058643, loss_s1: 0.028939, loss_fp: 0.000484, loss_freq: 0.015712
[15:30:57.012] iteration 19823: loss: 0.034636, loss_s1: 0.033264, loss_fp: 0.000869, loss_freq: 0.007268
[15:30:57.635] iteration 19824: loss: 0.067037, loss_s1: 0.083757, loss_fp: 0.002182, loss_freq: 0.014833
[15:30:58.244] iteration 19825: loss: 0.075374, loss_s1: 0.033554, loss_fp: 0.002972, loss_freq: 0.050026
[15:30:58.912] iteration 19826: loss: 0.037991, loss_s1: 0.028548, loss_fp: 0.001989, loss_freq: 0.011597
[15:30:59.534] iteration 19827: loss: 0.041236, loss_s1: 0.014587, loss_fp: 0.001224, loss_freq: 0.010857
[15:31:00.188] iteration 19828: loss: 0.043295, loss_s1: 0.026334, loss_fp: 0.003637, loss_freq: 0.013835
[15:31:00.849] iteration 19829: loss: 0.067276, loss_s1: 0.066488, loss_fp: 0.001117, loss_freq: 0.022301
[15:31:01.534] iteration 19830: loss: 0.036129, loss_s1: 0.008306, loss_fp: 0.002457, loss_freq: 0.010306
[15:31:02.208] iteration 19831: loss: 0.074668, loss_s1: 0.044953, loss_fp: 0.003914, loss_freq: 0.051655
[15:31:02.849] iteration 19832: loss: 0.056980, loss_s1: 0.050365, loss_fp: 0.003516, loss_freq: 0.014712
[15:31:03.495] iteration 19833: loss: 0.047943, loss_s1: 0.018912, loss_fp: 0.001144, loss_freq: 0.016146
[15:31:04.142] iteration 19834: loss: 0.075029, loss_s1: 0.038433, loss_fp: 0.004910, loss_freq: 0.064882
[15:31:04.809] iteration 19835: loss: 0.084410, loss_s1: 0.099983, loss_fp: 0.003472, loss_freq: 0.030810
[15:31:05.430] iteration 19836: loss: 0.113621, loss_s1: 0.042491, loss_fp: 0.007319, loss_freq: 0.064292
[15:31:06.059] iteration 19837: loss: 0.073436, loss_s1: 0.050797, loss_fp: 0.001669, loss_freq: 0.039687
[15:31:06.682] iteration 19838: loss: 0.043503, loss_s1: 0.009429, loss_fp: 0.004056, loss_freq: 0.027342
[15:31:07.298] iteration 19839: loss: 0.053119, loss_s1: 0.041982, loss_fp: 0.004622, loss_freq: 0.014184
[15:31:07.916] iteration 19840: loss: 0.056725, loss_s1: 0.025856, loss_fp: 0.001378, loss_freq: 0.025997
[15:31:08.533] iteration 19841: loss: 0.094915, loss_s1: 0.077078, loss_fp: 0.009268, loss_freq: 0.050216
[15:31:09.176] iteration 19842: loss: 0.031858, loss_s1: 0.008306, loss_fp: 0.001387, loss_freq: 0.021446
[15:31:09.796] iteration 19843: loss: 0.068263, loss_s1: 0.035684, loss_fp: 0.007876, loss_freq: 0.043070
[15:31:10.451] iteration 19844: loss: 0.105574, loss_s1: 0.082571, loss_fp: 0.009842, loss_freq: 0.081001
[15:31:11.084] iteration 19845: loss: 0.095959, loss_s1: 0.054760, loss_fp: 0.002692, loss_freq: 0.012497
[15:31:11.704] iteration 19846: loss: 0.043065, loss_s1: 0.031831, loss_fp: 0.003205, loss_freq: 0.019560
[15:31:12.322] iteration 19847: loss: 0.057355, loss_s1: 0.050147, loss_fp: 0.000897, loss_freq: 0.007922
[15:31:12.950] iteration 19848: loss: 0.078041, loss_s1: 0.075990, loss_fp: 0.001618, loss_freq: 0.035196
[15:31:13.570] iteration 19849: loss: 0.093804, loss_s1: 0.055250, loss_fp: 0.005008, loss_freq: 0.036655
[15:31:14.181] iteration 19850: loss: 0.036361, loss_s1: 0.023311, loss_fp: 0.001147, loss_freq: 0.010439
[15:31:14.803] iteration 19851: loss: 0.057222, loss_s1: 0.019012, loss_fp: 0.002746, loss_freq: 0.027935
[15:31:15.423] iteration 19852: loss: 0.062719, loss_s1: 0.041905, loss_fp: 0.004915, loss_freq: 0.037808
[15:31:16.040] iteration 19853: loss: 0.056806, loss_s1: 0.063982, loss_fp: 0.001728, loss_freq: 0.007057
[15:31:16.659] iteration 19854: loss: 0.054605, loss_s1: 0.032932, loss_fp: 0.003082, loss_freq: 0.036373
[15:31:17.299] iteration 19855: loss: 0.076901, loss_s1: 0.047141, loss_fp: 0.009366, loss_freq: 0.045725
[15:31:17.952] iteration 19856: loss: 0.073716, loss_s1: 0.065771, loss_fp: 0.003627, loss_freq: 0.037673
[15:31:18.592] iteration 19857: loss: 0.038559, loss_s1: 0.019989, loss_fp: 0.002549, loss_freq: 0.003650
[15:31:19.234] iteration 19858: loss: 0.040781, loss_s1: 0.029102, loss_fp: 0.002533, loss_freq: 0.018993
[15:31:19.873] iteration 19859: loss: 0.049216, loss_s1: 0.028540, loss_fp: 0.007861, loss_freq: 0.011325
[15:31:20.488] iteration 19860: loss: 0.061250, loss_s1: 0.030855, loss_fp: 0.001517, loss_freq: 0.013594
[15:31:21.108] iteration 19861: loss: 0.034403, loss_s1: 0.016270, loss_fp: 0.006179, loss_freq: 0.013336
[15:31:21.726] iteration 19862: loss: 0.058493, loss_s1: 0.040983, loss_fp: 0.002599, loss_freq: 0.040894
[15:31:22.348] iteration 19863: loss: 0.089918, loss_s1: 0.075223, loss_fp: 0.005423, loss_freq: 0.030355
[15:31:22.973] iteration 19864: loss: 0.051128, loss_s1: 0.043476, loss_fp: 0.001514, loss_freq: 0.007592
[15:31:23.592] iteration 19865: loss: 0.055150, loss_s1: 0.033361, loss_fp: 0.001650, loss_freq: 0.025452
[15:31:24.217] iteration 19866: loss: 0.049830, loss_s1: 0.024750, loss_fp: 0.003952, loss_freq: 0.027765
[15:31:24.842] iteration 19867: loss: 0.052292, loss_s1: 0.041486, loss_fp: 0.000834, loss_freq: 0.025097
[15:31:25.467] iteration 19868: loss: 0.078107, loss_s1: 0.064957, loss_fp: 0.002544, loss_freq: 0.032197
[15:31:26.125] iteration 19869: loss: 0.064000, loss_s1: 0.038897, loss_fp: 0.006028, loss_freq: 0.032078
[15:31:26.751] iteration 19870: loss: 0.082854, loss_s1: 0.087956, loss_fp: 0.002299, loss_freq: 0.031918
[15:31:27.366] iteration 19871: loss: 0.065369, loss_s1: 0.040320, loss_fp: 0.006667, loss_freq: 0.008633
[15:31:27.980] iteration 19872: loss: 0.043035, loss_s1: 0.016735, loss_fp: 0.004684, loss_freq: 0.013994
[15:31:28.603] iteration 19873: loss: 0.041794, loss_s1: 0.025278, loss_fp: 0.002583, loss_freq: 0.018232
[15:31:29.220] iteration 19874: loss: 0.049627, loss_s1: 0.028482, loss_fp: 0.002336, loss_freq: 0.014268
[15:31:29.842] iteration 19875: loss: 0.049888, loss_s1: 0.035033, loss_fp: 0.003451, loss_freq: 0.018066
[15:31:30.461] iteration 19876: loss: 0.101459, loss_s1: 0.106600, loss_fp: 0.005472, loss_freq: 0.049497
[15:31:31.074] iteration 19877: loss: 0.059355, loss_s1: 0.051962, loss_fp: 0.006843, loss_freq: 0.017523
[15:31:32.041] iteration 19878: loss: 0.033663, loss_s1: 0.018007, loss_fp: 0.001005, loss_freq: 0.006468
[15:31:32.681] iteration 19879: loss: 0.042017, loss_s1: 0.021683, loss_fp: 0.003014, loss_freq: 0.018241
[15:31:33.324] iteration 19880: loss: 0.054899, loss_s1: 0.057697, loss_fp: 0.002098, loss_freq: 0.022090
[15:31:33.963] iteration 19881: loss: 0.049236, loss_s1: 0.021557, loss_fp: 0.001957, loss_freq: 0.018159
[15:31:34.592] iteration 19882: loss: 0.081452, loss_s1: 0.106560, loss_fp: 0.004692, loss_freq: 0.022893
[15:31:35.211] iteration 19883: loss: 0.036698, loss_s1: 0.025245, loss_fp: 0.002404, loss_freq: 0.009321
[15:31:35.831] iteration 19884: loss: 0.045800, loss_s1: 0.040264, loss_fp: 0.010000, loss_freq: 0.010032
[15:31:36.449] iteration 19885: loss: 0.066196, loss_s1: 0.058171, loss_fp: 0.002813, loss_freq: 0.027151
[15:31:37.079] iteration 19886: loss: 0.062878, loss_s1: 0.059941, loss_fp: 0.002654, loss_freq: 0.021124
[15:31:37.701] iteration 19887: loss: 0.039027, loss_s1: 0.019109, loss_fp: 0.001684, loss_freq: 0.005109
[15:31:38.329] iteration 19888: loss: 0.071671, loss_s1: 0.048102, loss_fp: 0.004190, loss_freq: 0.049858
[15:31:38.948] iteration 19889: loss: 0.044925, loss_s1: 0.029884, loss_fp: 0.003582, loss_freq: 0.016901
[15:31:39.567] iteration 19890: loss: 0.092577, loss_s1: 0.118955, loss_fp: 0.002456, loss_freq: 0.019444
[15:31:40.188] iteration 19891: loss: 0.043851, loss_s1: 0.034042, loss_fp: 0.001955, loss_freq: 0.006942
[15:31:40.822] iteration 19892: loss: 0.086950, loss_s1: 0.089915, loss_fp: 0.005595, loss_freq: 0.042637
[15:31:41.441] iteration 19893: loss: 0.045323, loss_s1: 0.025590, loss_fp: 0.005931, loss_freq: 0.013327
[15:31:42.062] iteration 19894: loss: 0.065424, loss_s1: 0.033899, loss_fp: 0.000604, loss_freq: 0.029410
[15:31:42.680] iteration 19895: loss: 0.062683, loss_s1: 0.025862, loss_fp: 0.008632, loss_freq: 0.024522
[15:31:43.299] iteration 19896: loss: 0.048533, loss_s1: 0.046322, loss_fp: 0.003932, loss_freq: 0.018644
[15:31:43.960] iteration 19897: loss: 0.035999, loss_s1: 0.016168, loss_fp: 0.004015, loss_freq: 0.015827
[15:31:44.629] iteration 19898: loss: 0.063685, loss_s1: 0.018078, loss_fp: 0.004431, loss_freq: 0.046003
[15:31:45.246] iteration 19899: loss: 0.045070, loss_s1: 0.024552, loss_fp: 0.000529, loss_freq: 0.016049
[15:31:45.916] iteration 19900: loss: 0.052903, loss_s1: 0.029818, loss_fp: 0.001312, loss_freq: 0.021304
[15:31:46.546] iteration 19901: loss: 0.074630, loss_s1: 0.058607, loss_fp: 0.001494, loss_freq: 0.034597
[15:31:47.165] iteration 19902: loss: 0.066462, loss_s1: 0.056084, loss_fp: 0.002244, loss_freq: 0.033241
[15:31:47.828] iteration 19903: loss: 0.068971, loss_s1: 0.044621, loss_fp: 0.004546, loss_freq: 0.040148
[15:31:48.450] iteration 19904: loss: 0.093118, loss_s1: 0.076539, loss_fp: 0.002631, loss_freq: 0.065088
[15:31:49.091] iteration 19905: loss: 0.066418, loss_s1: 0.077210, loss_fp: 0.000866, loss_freq: 0.012044
[15:31:49.793] iteration 19906: loss: 0.082062, loss_s1: 0.043748, loss_fp: 0.008962, loss_freq: 0.043137
[15:31:50.441] iteration 19907: loss: 0.047423, loss_s1: 0.018558, loss_fp: 0.001929, loss_freq: 0.014187
[15:31:51.080] iteration 19908: loss: 0.042794, loss_s1: 0.028085, loss_fp: 0.004037, loss_freq: 0.010418
[15:31:51.710] iteration 19909: loss: 0.090395, loss_s1: 0.068785, loss_fp: 0.005874, loss_freq: 0.028014
[15:31:52.332] iteration 19910: loss: 0.072601, loss_s1: 0.034734, loss_fp: 0.014579, loss_freq: 0.058931
[15:31:52.958] iteration 19911: loss: 0.057548, loss_s1: 0.034650, loss_fp: 0.006877, loss_freq: 0.032800
[15:31:53.584] iteration 19912: loss: 0.079115, loss_s1: 0.071871, loss_fp: 0.012318, loss_freq: 0.025372
[15:31:54.224] iteration 19913: loss: 0.067425, loss_s1: 0.034198, loss_fp: 0.002291, loss_freq: 0.054596
[15:31:54.842] iteration 19914: loss: 0.049543, loss_s1: 0.038919, loss_fp: 0.000916, loss_freq: 0.016021
[15:31:55.457] iteration 19915: loss: 0.046232, loss_s1: 0.040246, loss_fp: 0.003801, loss_freq: 0.019767
[15:31:56.070] iteration 19916: loss: 0.067093, loss_s1: 0.048012, loss_fp: 0.002641, loss_freq: 0.036114
[15:31:56.694] iteration 19917: loss: 0.056969, loss_s1: 0.034004, loss_fp: 0.001698, loss_freq: 0.020686
[15:31:57.310] iteration 19918: loss: 0.056178, loss_s1: 0.048372, loss_fp: 0.010735, loss_freq: 0.011096
[15:31:57.924] iteration 19919: loss: 0.059998, loss_s1: 0.063810, loss_fp: 0.001899, loss_freq: 0.015296
[15:31:58.542] iteration 19920: loss: 0.058832, loss_s1: 0.024722, loss_fp: 0.002350, loss_freq: 0.033705
[15:31:59.161] iteration 19921: loss: 0.061432, loss_s1: 0.054385, loss_fp: 0.005586, loss_freq: 0.025631
[15:31:59.781] iteration 19922: loss: 0.066826, loss_s1: 0.033309, loss_fp: 0.000839, loss_freq: 0.017278
[15:32:00.403] iteration 19923: loss: 0.076280, loss_s1: 0.073050, loss_fp: 0.005489, loss_freq: 0.033915
[15:32:01.029] iteration 19924: loss: 0.048457, loss_s1: 0.019010, loss_fp: 0.004213, loss_freq: 0.013646
[15:32:01.650] iteration 19925: loss: 0.056673, loss_s1: 0.042967, loss_fp: 0.004592, loss_freq: 0.026259
[15:32:02.297] iteration 19926: loss: 0.050444, loss_s1: 0.031496, loss_fp: 0.002670, loss_freq: 0.033809
[15:32:02.922] iteration 19927: loss: 0.054275, loss_s1: 0.026922, loss_fp: 0.007740, loss_freq: 0.022213
[15:32:03.542] iteration 19928: loss: 0.042388, loss_s1: 0.016955, loss_fp: 0.006794, loss_freq: 0.012493
[15:32:04.208] iteration 19929: loss: 0.091976, loss_s1: 0.037041, loss_fp: 0.001918, loss_freq: 0.019851
[15:32:05.022] iteration 19930: loss: 0.044773, loss_s1: 0.039322, loss_fp: 0.000966, loss_freq: 0.010673
[15:32:05.862] iteration 19931: loss: 0.043278, loss_s1: 0.025499, loss_fp: 0.001807, loss_freq: 0.009999
[15:32:06.473] iteration 19932: loss: 0.043019, loss_s1: 0.047778, loss_fp: 0.001078, loss_freq: 0.006158
[15:32:07.126] iteration 19933: loss: 0.053457, loss_s1: 0.021603, loss_fp: 0.001386, loss_freq: 0.024065
[15:32:07.793] iteration 19934: loss: 0.059058, loss_s1: 0.046191, loss_fp: 0.001233, loss_freq: 0.037345
[15:32:08.413] iteration 19935: loss: 0.057140, loss_s1: 0.043600, loss_fp: 0.007923, loss_freq: 0.015121
[15:32:09.027] iteration 19936: loss: 0.057386, loss_s1: 0.014695, loss_fp: 0.003585, loss_freq: 0.049659
[15:32:09.645] iteration 19937: loss: 0.047798, loss_s1: 0.040520, loss_fp: 0.001090, loss_freq: 0.017115
[15:32:10.267] iteration 19938: loss: 0.062779, loss_s1: 0.055218, loss_fp: 0.002540, loss_freq: 0.024047
[15:32:10.885] iteration 19939: loss: 0.062302, loss_s1: 0.040481, loss_fp: 0.002315, loss_freq: 0.009002
[15:32:11.512] iteration 19940: loss: 0.065363, loss_s1: 0.061513, loss_fp: 0.003145, loss_freq: 0.025965
[15:32:12.139] iteration 19941: loss: 0.056987, loss_s1: 0.027002, loss_fp: 0.000449, loss_freq: 0.017098
[15:32:12.767] iteration 19942: loss: 0.056517, loss_s1: 0.044793, loss_fp: 0.004760, loss_freq: 0.014185
[15:32:13.428] iteration 19943: loss: 0.039893, loss_s1: 0.012090, loss_fp: 0.001104, loss_freq: 0.013890
[15:32:14.050] iteration 19944: loss: 0.080713, loss_s1: 0.057709, loss_fp: 0.007209, loss_freq: 0.047304
[15:32:14.671] iteration 19945: loss: 0.043570, loss_s1: 0.041459, loss_fp: 0.001553, loss_freq: 0.013110
[15:32:15.289] iteration 19946: loss: 0.052595, loss_s1: 0.047405, loss_fp: 0.002204, loss_freq: 0.020390
[15:32:15.898] iteration 19947: loss: 0.055071, loss_s1: 0.037469, loss_fp: 0.000669, loss_freq: 0.003508
[15:32:16.505] iteration 19948: loss: 0.047738, loss_s1: 0.030303, loss_fp: 0.002562, loss_freq: 0.022253
[15:32:17.123] iteration 19949: loss: 0.050299, loss_s1: 0.027098, loss_fp: 0.001759, loss_freq: 0.021776
[15:32:17.744] iteration 19950: loss: 0.064165, loss_s1: 0.029796, loss_fp: 0.007962, loss_freq: 0.051624
[15:32:18.361] iteration 19951: loss: 0.059496, loss_s1: 0.037948, loss_fp: 0.004728, loss_freq: 0.015195
[15:32:18.981] iteration 19952: loss: 0.079215, loss_s1: 0.060526, loss_fp: 0.004712, loss_freq: 0.057955
[15:32:19.634] iteration 19953: loss: 0.040454, loss_s1: 0.032919, loss_fp: 0.002021, loss_freq: 0.010571
[15:32:20.261] iteration 19954: loss: 0.069434, loss_s1: 0.033486, loss_fp: 0.011826, loss_freq: 0.024966
[15:32:20.926] iteration 19955: loss: 0.054342, loss_s1: 0.038693, loss_fp: 0.003269, loss_freq: 0.014307
[15:32:21.547] iteration 19956: loss: 0.061557, loss_s1: 0.038201, loss_fp: 0.004301, loss_freq: 0.033789
[15:32:22.173] iteration 19957: loss: 0.116913, loss_s1: 0.099987, loss_fp: 0.004155, loss_freq: 0.044582
[15:32:22.792] iteration 19958: loss: 0.052274, loss_s1: 0.048271, loss_fp: 0.001578, loss_freq: 0.013285
[15:32:23.410] iteration 19959: loss: 0.051973, loss_s1: 0.040339, loss_fp: 0.004775, loss_freq: 0.013092
[15:32:24.038] iteration 19960: loss: 0.061106, loss_s1: 0.047571, loss_fp: 0.002292, loss_freq: 0.024770
[15:32:24.653] iteration 19961: loss: 0.043194, loss_s1: 0.042496, loss_fp: 0.004434, loss_freq: 0.008949
[15:32:25.270] iteration 19962: loss: 0.075181, loss_s1: 0.076009, loss_fp: 0.004534, loss_freq: 0.027497
[15:32:25.891] iteration 19963: loss: 0.061587, loss_s1: 0.029431, loss_fp: 0.004243, loss_freq: 0.045201
[15:32:26.514] iteration 19964: loss: 0.037008, loss_s1: 0.020085, loss_fp: 0.000878, loss_freq: 0.012859
[15:32:27.145] iteration 19965: loss: 0.038804, loss_s1: 0.011416, loss_fp: 0.000907, loss_freq: 0.020516
[15:32:27.759] iteration 19966: loss: 0.035861, loss_s1: 0.026539, loss_fp: 0.000461, loss_freq: 0.009430
[15:32:28.374] iteration 19967: loss: 0.057468, loss_s1: 0.049543, loss_fp: 0.006207, loss_freq: 0.026491
[15:32:28.983] iteration 19968: loss: 0.066071, loss_s1: 0.050362, loss_fp: 0.002289, loss_freq: 0.019831
[15:32:29.606] iteration 19969: loss: 0.070812, loss_s1: 0.071314, loss_fp: 0.001124, loss_freq: 0.024493
[15:32:30.242] iteration 19970: loss: 0.060639, loss_s1: 0.043305, loss_fp: 0.001218, loss_freq: 0.027027
[15:32:30.861] iteration 19971: loss: 0.050566, loss_s1: 0.047406, loss_fp: 0.001656, loss_freq: 0.010506
[15:32:31.490] iteration 19972: loss: 0.028487, loss_s1: 0.007410, loss_fp: 0.000817, loss_freq: 0.012012
[15:32:32.107] iteration 19973: loss: 0.040556, loss_s1: 0.033981, loss_fp: 0.001232, loss_freq: 0.006164
[15:32:32.729] iteration 19974: loss: 0.066112, loss_s1: 0.051341, loss_fp: 0.004864, loss_freq: 0.029524
[15:32:33.354] iteration 19975: loss: 0.054262, loss_s1: 0.030621, loss_fp: 0.009247, loss_freq: 0.026205
[15:32:34.024] iteration 19976: loss: 0.037774, loss_s1: 0.018701, loss_fp: 0.004543, loss_freq: 0.012969
[15:32:34.650] iteration 19977: loss: 0.104881, loss_s1: 0.104245, loss_fp: 0.010860, loss_freq: 0.049432
[15:32:35.276] iteration 19978: loss: 0.059062, loss_s1: 0.052941, loss_fp: 0.001138, loss_freq: 0.020961
[15:32:35.896] iteration 19979: loss: 0.066679, loss_s1: 0.036852, loss_fp: 0.002093, loss_freq: 0.015382
[15:32:36.512] iteration 19980: loss: 0.038743, loss_s1: 0.019001, loss_fp: 0.010629, loss_freq: 0.013574
[15:32:37.156] iteration 19981: loss: 0.054211, loss_s1: 0.043602, loss_fp: 0.002271, loss_freq: 0.025459
[15:32:37.822] iteration 19982: loss: 0.083506, loss_s1: 0.047163, loss_fp: 0.003167, loss_freq: 0.013328
[15:32:38.503] iteration 19983: loss: 0.061924, loss_s1: 0.033665, loss_fp: 0.000904, loss_freq: 0.039387
[15:32:39.116] iteration 19984: loss: 0.059524, loss_s1: 0.034167, loss_fp: 0.001789, loss_freq: 0.031823
[15:32:39.741] iteration 19985: loss: 0.056376, loss_s1: 0.043094, loss_fp: 0.002432, loss_freq: 0.018838
[15:32:40.366] iteration 19986: loss: 0.045359, loss_s1: 0.022675, loss_fp: 0.007604, loss_freq: 0.014049
[15:32:41.001] iteration 19987: loss: 0.066723, loss_s1: 0.033876, loss_fp: 0.002754, loss_freq: 0.058520
[15:32:41.626] iteration 19988: loss: 0.057280, loss_s1: 0.033250, loss_fp: 0.003626, loss_freq: 0.041143
[15:32:42.242] iteration 19989: loss: 0.045638, loss_s1: 0.041719, loss_fp: 0.004080, loss_freq: 0.017247
[15:32:42.867] iteration 19990: loss: 0.051970, loss_s1: 0.028717, loss_fp: 0.003318, loss_freq: 0.008685
[15:32:43.483] iteration 19991: loss: 0.056071, loss_s1: 0.047121, loss_fp: 0.004268, loss_freq: 0.016882
[15:32:44.107] iteration 19992: loss: 0.069442, loss_s1: 0.038327, loss_fp: 0.004480, loss_freq: 0.006672
[15:32:44.733] iteration 19993: loss: 0.042138, loss_s1: 0.013981, loss_fp: 0.003787, loss_freq: 0.012448
[15:32:45.349] iteration 19994: loss: 0.042453, loss_s1: 0.031072, loss_fp: 0.003590, loss_freq: 0.013383
[15:32:45.969] iteration 19995: loss: 0.063617, loss_s1: 0.057020, loss_fp: 0.003929, loss_freq: 0.029447
[15:32:46.596] iteration 19996: loss: 0.072695, loss_s1: 0.057539, loss_fp: 0.001367, loss_freq: 0.033102
[15:32:47.222] iteration 19997: loss: 0.049001, loss_s1: 0.029066, loss_fp: 0.004953, loss_freq: 0.027246
[15:32:47.843] iteration 19998: loss: 0.058659, loss_s1: 0.032256, loss_fp: 0.004012, loss_freq: 0.023860
[15:32:48.452] iteration 19999: loss: 0.045106, loss_s1: 0.031721, loss_fp: 0.001770, loss_freq: 0.014477
[15:32:49.064] iteration 20000: loss: 0.030073, loss_s1: 0.010152, loss_fp: 0.001026, loss_freq: 0.010954
[15:32:52.388] iteration 20000 : mean_dice : 0.789737
[15:32:53.032] iteration 20001: loss: 0.059611, loss_s1: 0.051671, loss_fp: 0.002117, loss_freq: 0.035217
[15:32:53.651] iteration 20002: loss: 0.050260, loss_s1: 0.035179, loss_fp: 0.002708, loss_freq: 0.024625
[15:32:54.265] iteration 20003: loss: 0.078243, loss_s1: 0.080487, loss_fp: 0.002553, loss_freq: 0.025361
[15:32:54.906] iteration 20004: loss: 0.090744, loss_s1: 0.062785, loss_fp: 0.005190, loss_freq: 0.078077
[15:32:55.531] iteration 20005: loss: 0.043226, loss_s1: 0.014520, loss_fp: 0.004328, loss_freq: 0.018489
[15:32:56.168] iteration 20006: loss: 0.088971, loss_s1: 0.103363, loss_fp: 0.002537, loss_freq: 0.018045
[15:32:56.808] iteration 20007: loss: 0.047688, loss_s1: 0.040249, loss_fp: 0.000595, loss_freq: 0.011294
[15:32:57.447] iteration 20008: loss: 0.040532, loss_s1: 0.023870, loss_fp: 0.000793, loss_freq: 0.013022
[15:32:58.070] iteration 20009: loss: 0.057838, loss_s1: 0.047506, loss_fp: 0.007840, loss_freq: 0.009759
[15:32:58.693] iteration 20010: loss: 0.066660, loss_s1: 0.058669, loss_fp: 0.011941, loss_freq: 0.017643
[15:32:59.321] iteration 20011: loss: 0.088219, loss_s1: 0.056757, loss_fp: 0.003606, loss_freq: 0.056400
[15:32:59.934] iteration 20012: loss: 0.086257, loss_s1: 0.051076, loss_fp: 0.005146, loss_freq: 0.039425
[15:33:00.598] iteration 20013: loss: 0.080908, loss_s1: 0.046321, loss_fp: 0.001622, loss_freq: 0.059453
[15:33:01.290] iteration 20014: loss: 0.072744, loss_s1: 0.062577, loss_fp: 0.009728, loss_freq: 0.021209
[15:33:01.913] iteration 20015: loss: 0.026332, loss_s1: 0.014263, loss_fp: 0.000998, loss_freq: 0.008524
[15:33:02.528] iteration 20016: loss: 0.053994, loss_s1: 0.038003, loss_fp: 0.002702, loss_freq: 0.028969
[15:33:03.165] iteration 20017: loss: 0.076271, loss_s1: 0.040363, loss_fp: 0.003194, loss_freq: 0.021104
[15:33:03.805] iteration 20018: loss: 0.094298, loss_s1: 0.083165, loss_fp: 0.002855, loss_freq: 0.041179
[15:33:04.419] iteration 20019: loss: 0.123218, loss_s1: 0.121377, loss_fp: 0.025221, loss_freq: 0.060626
[15:33:05.034] iteration 20020: loss: 0.030926, loss_s1: 0.010270, loss_fp: 0.000348, loss_freq: 0.012178
[15:33:06.057] iteration 20021: loss: 0.035115, loss_s1: 0.020617, loss_fp: 0.000991, loss_freq: 0.008494
[15:33:06.681] iteration 20022: loss: 0.072716, loss_s1: 0.066342, loss_fp: 0.005012, loss_freq: 0.026920
[15:33:07.308] iteration 20023: loss: 0.053597, loss_s1: 0.043470, loss_fp: 0.000893, loss_freq: 0.029101
[15:33:07.961] iteration 20024: loss: 0.075928, loss_s1: 0.069938, loss_fp: 0.012183, loss_freq: 0.023233
[15:33:08.598] iteration 20025: loss: 0.043312, loss_s1: 0.022620, loss_fp: 0.003829, loss_freq: 0.030301
[15:33:09.242] iteration 20026: loss: 0.064194, loss_s1: 0.058863, loss_fp: 0.003394, loss_freq: 0.010620
[15:33:09.882] iteration 20027: loss: 0.030622, loss_s1: 0.018754, loss_fp: 0.001857, loss_freq: 0.011435
[15:33:10.505] iteration 20028: loss: 0.097729, loss_s1: 0.092058, loss_fp: 0.010768, loss_freq: 0.044140
[15:33:11.129] iteration 20029: loss: 0.049997, loss_s1: 0.025966, loss_fp: 0.002053, loss_freq: 0.029248
[15:33:11.819] iteration 20030: loss: 0.046553, loss_s1: 0.014066, loss_fp: 0.003176, loss_freq: 0.008755
[15:33:12.465] iteration 20031: loss: 0.058273, loss_s1: 0.021930, loss_fp: 0.007249, loss_freq: 0.043436
[15:33:13.101] iteration 20032: loss: 0.047323, loss_s1: 0.019188, loss_fp: 0.002115, loss_freq: 0.026634
[15:33:13.742] iteration 20033: loss: 0.055478, loss_s1: 0.049796, loss_fp: 0.003800, loss_freq: 0.014263
[15:33:14.376] iteration 20034: loss: 0.033109, loss_s1: 0.020063, loss_fp: 0.005324, loss_freq: 0.006731
[15:33:15.022] iteration 20035: loss: 0.075278, loss_s1: 0.074420, loss_fp: 0.003634, loss_freq: 0.035434
[15:33:15.666] iteration 20036: loss: 0.059418, loss_s1: 0.026037, loss_fp: 0.002018, loss_freq: 0.037156
[15:33:16.302] iteration 20037: loss: 0.041929, loss_s1: 0.026820, loss_fp: 0.001985, loss_freq: 0.017653
[15:33:16.923] iteration 20038: loss: 0.091892, loss_s1: 0.057802, loss_fp: 0.002174, loss_freq: 0.030505
[15:33:17.563] iteration 20039: loss: 0.047246, loss_s1: 0.044791, loss_fp: 0.001641, loss_freq: 0.018397
[15:33:18.201] iteration 20040: loss: 0.037030, loss_s1: 0.027881, loss_fp: 0.001936, loss_freq: 0.009674
[15:33:18.837] iteration 20041: loss: 0.094368, loss_s1: 0.055134, loss_fp: 0.001576, loss_freq: 0.067086
[15:33:19.495] iteration 20042: loss: 0.059438, loss_s1: 0.038659, loss_fp: 0.001860, loss_freq: 0.040850
[15:33:20.130] iteration 20043: loss: 0.069782, loss_s1: 0.049261, loss_fp: 0.003728, loss_freq: 0.022647
[15:33:20.763] iteration 20044: loss: 0.051945, loss_s1: 0.047723, loss_fp: 0.001317, loss_freq: 0.019406
[15:33:21.389] iteration 20045: loss: 0.049916, loss_s1: 0.036139, loss_fp: 0.004845, loss_freq: 0.018717
[15:33:22.059] iteration 20046: loss: 0.069799, loss_s1: 0.046683, loss_fp: 0.014305, loss_freq: 0.022891
[15:33:22.683] iteration 20047: loss: 0.090398, loss_s1: 0.043245, loss_fp: 0.012759, loss_freq: 0.059433
[15:33:23.290] iteration 20048: loss: 0.054907, loss_s1: 0.043860, loss_fp: 0.002044, loss_freq: 0.012551
[15:33:23.906] iteration 20049: loss: 0.082361, loss_s1: 0.033501, loss_fp: 0.003190, loss_freq: 0.077306
[15:33:24.527] iteration 20050: loss: 0.050856, loss_s1: 0.032413, loss_fp: 0.001708, loss_freq: 0.011160
[15:33:25.148] iteration 20051: loss: 0.057501, loss_s1: 0.041363, loss_fp: 0.004426, loss_freq: 0.022437
[15:33:25.772] iteration 20052: loss: 0.056944, loss_s1: 0.021004, loss_fp: 0.001968, loss_freq: 0.026159
[15:33:26.388] iteration 20053: loss: 0.066099, loss_s1: 0.042159, loss_fp: 0.003571, loss_freq: 0.042084
[15:33:27.000] iteration 20054: loss: 0.075718, loss_s1: 0.069339, loss_fp: 0.005093, loss_freq: 0.034032
[15:33:27.619] iteration 20055: loss: 0.066049, loss_s1: 0.042839, loss_fp: 0.000891, loss_freq: 0.024601
[15:33:28.231] iteration 20056: loss: 0.066707, loss_s1: 0.071705, loss_fp: 0.001659, loss_freq: 0.024288
[15:33:28.850] iteration 20057: loss: 0.064691, loss_s1: 0.058742, loss_fp: 0.000894, loss_freq: 0.017225
[15:33:29.471] iteration 20058: loss: 0.043722, loss_s1: 0.022493, loss_fp: 0.006685, loss_freq: 0.018600
[15:33:30.126] iteration 20059: loss: 0.078043, loss_s1: 0.072165, loss_fp: 0.004046, loss_freq: 0.029523
[15:33:30.844] iteration 20060: loss: 0.053486, loss_s1: 0.065930, loss_fp: 0.003070, loss_freq: 0.005861
[15:33:31.514] iteration 20061: loss: 0.070070, loss_s1: 0.037789, loss_fp: 0.001221, loss_freq: 0.028340
[15:33:32.201] iteration 20062: loss: 0.048572, loss_s1: 0.040350, loss_fp: 0.008036, loss_freq: 0.019990
[15:33:32.830] iteration 20063: loss: 0.057370, loss_s1: 0.031269, loss_fp: 0.008274, loss_freq: 0.022926
[15:33:33.469] iteration 20064: loss: 0.050212, loss_s1: 0.038054, loss_fp: 0.001440, loss_freq: 0.022683
[15:33:34.106] iteration 20065: loss: 0.051345, loss_s1: 0.011074, loss_fp: 0.000510, loss_freq: 0.021044
[15:33:34.754] iteration 20066: loss: 0.067153, loss_s1: 0.041481, loss_fp: 0.001568, loss_freq: 0.013996
[15:33:35.373] iteration 20067: loss: 0.052367, loss_s1: 0.032738, loss_fp: 0.002253, loss_freq: 0.032554
[15:33:35.994] iteration 20068: loss: 0.046316, loss_s1: 0.032466, loss_fp: 0.004132, loss_freq: 0.015902
[15:33:36.615] iteration 20069: loss: 0.051796, loss_s1: 0.032721, loss_fp: 0.005088, loss_freq: 0.032674
[15:33:37.237] iteration 20070: loss: 0.042153, loss_s1: 0.030192, loss_fp: 0.001507, loss_freq: 0.009718
[15:33:37.861] iteration 20071: loss: 0.046276, loss_s1: 0.025215, loss_fp: 0.004170, loss_freq: 0.018795
[15:33:38.488] iteration 20072: loss: 0.085267, loss_s1: 0.080106, loss_fp: 0.002241, loss_freq: 0.040623
[15:33:39.113] iteration 20073: loss: 0.031501, loss_s1: 0.012083, loss_fp: 0.001670, loss_freq: 0.014874
[15:33:39.732] iteration 20074: loss: 0.023893, loss_s1: 0.009859, loss_fp: 0.002052, loss_freq: 0.008400
[15:33:40.343] iteration 20075: loss: 0.059696, loss_s1: 0.046591, loss_fp: 0.000933, loss_freq: 0.016367
[15:33:40.982] iteration 20076: loss: 0.050176, loss_s1: 0.017054, loss_fp: 0.002048, loss_freq: 0.018733
[15:33:41.601] iteration 20077: loss: 0.049752, loss_s1: 0.024884, loss_fp: 0.011554, loss_freq: 0.017673
[15:33:42.225] iteration 20078: loss: 0.049420, loss_s1: 0.025364, loss_fp: 0.006510, loss_freq: 0.012048
[15:33:42.851] iteration 20079: loss: 0.095445, loss_s1: 0.085545, loss_fp: 0.005376, loss_freq: 0.055234
[15:33:43.521] iteration 20080: loss: 0.042066, loss_s1: 0.010263, loss_fp: 0.002440, loss_freq: 0.027213
[15:33:44.201] iteration 20081: loss: 0.076140, loss_s1: 0.046819, loss_fp: 0.015611, loss_freq: 0.012922
[15:33:44.849] iteration 20082: loss: 0.063759, loss_s1: 0.066797, loss_fp: 0.003583, loss_freq: 0.014605
[15:33:45.477] iteration 20083: loss: 0.061291, loss_s1: 0.034738, loss_fp: 0.003516, loss_freq: 0.038700
[15:33:46.107] iteration 20084: loss: 0.047013, loss_s1: 0.006438, loss_fp: 0.002079, loss_freq: 0.017608
[15:33:46.735] iteration 20085: loss: 0.059976, loss_s1: 0.047429, loss_fp: 0.001906, loss_freq: 0.011442
[15:33:47.366] iteration 20086: loss: 0.045530, loss_s1: 0.031826, loss_fp: 0.004905, loss_freq: 0.018556
[15:33:47.994] iteration 20087: loss: 0.056840, loss_s1: 0.031067, loss_fp: 0.008145, loss_freq: 0.030443
[15:33:48.624] iteration 20088: loss: 0.043920, loss_s1: 0.011474, loss_fp: 0.002551, loss_freq: 0.034946
[15:33:49.247] iteration 20089: loss: 0.060534, loss_s1: 0.064315, loss_fp: 0.002769, loss_freq: 0.015453
[15:33:49.870] iteration 20090: loss: 0.054717, loss_s1: 0.006241, loss_fp: 0.021000, loss_freq: 0.019415
[15:33:50.495] iteration 20091: loss: 0.069456, loss_s1: 0.058916, loss_fp: 0.004283, loss_freq: 0.016896
[15:33:51.119] iteration 20092: loss: 0.078469, loss_s1: 0.024250, loss_fp: 0.005134, loss_freq: 0.071412
[15:33:51.743] iteration 20093: loss: 0.094982, loss_s1: 0.036475, loss_fp: 0.005060, loss_freq: 0.104850
[15:33:52.372] iteration 20094: loss: 0.118031, loss_s1: 0.098003, loss_fp: 0.004589, loss_freq: 0.058483
[15:33:52.997] iteration 20095: loss: 0.052126, loss_s1: 0.024336, loss_fp: 0.003991, loss_freq: 0.048719
[15:33:53.620] iteration 20096: loss: 0.095883, loss_s1: 0.048495, loss_fp: 0.006330, loss_freq: 0.014353
[15:33:54.239] iteration 20097: loss: 0.066377, loss_s1: 0.044635, loss_fp: 0.004805, loss_freq: 0.055149
[15:33:54.861] iteration 20098: loss: 0.053473, loss_s1: 0.023518, loss_fp: 0.007729, loss_freq: 0.023122
[15:33:55.479] iteration 20099: loss: 0.089012, loss_s1: 0.054018, loss_fp: 0.007703, loss_freq: 0.074428
[15:33:56.101] iteration 20100: loss: 0.131179, loss_s1: 0.097298, loss_fp: 0.006676, loss_freq: 0.053676
[15:33:56.720] iteration 20101: loss: 0.068898, loss_s1: 0.079072, loss_fp: 0.001516, loss_freq: 0.016738
[15:33:57.357] iteration 20102: loss: 0.075282, loss_s1: 0.048644, loss_fp: 0.002795, loss_freq: 0.039063
[15:33:57.982] iteration 20103: loss: 0.065161, loss_s1: 0.049315, loss_fp: 0.001380, loss_freq: 0.025064
[15:33:58.599] iteration 20104: loss: 0.049964, loss_s1: 0.039861, loss_fp: 0.011777, loss_freq: 0.015144
[15:33:59.221] iteration 20105: loss: 0.065265, loss_s1: 0.057914, loss_fp: 0.007083, loss_freq: 0.007981
[15:33:59.843] iteration 20106: loss: 0.046777, loss_s1: 0.024422, loss_fp: 0.002068, loss_freq: 0.030208
[15:34:00.467] iteration 20107: loss: 0.052976, loss_s1: 0.032524, loss_fp: 0.004679, loss_freq: 0.011953
[15:34:01.093] iteration 20108: loss: 0.041287, loss_s1: 0.017078, loss_fp: 0.000524, loss_freq: 0.020608
[15:34:01.716] iteration 20109: loss: 0.040943, loss_s1: 0.035298, loss_fp: 0.001067, loss_freq: 0.010738
[15:34:02.336] iteration 20110: loss: 0.041805, loss_s1: 0.031873, loss_fp: 0.001632, loss_freq: 0.010067
[15:34:03.002] iteration 20111: loss: 0.085216, loss_s1: 0.049808, loss_fp: 0.006485, loss_freq: 0.020350
[15:34:03.635] iteration 20112: loss: 0.066679, loss_s1: 0.050217, loss_fp: 0.002652, loss_freq: 0.042224
[15:34:04.270] iteration 20113: loss: 0.040045, loss_s1: 0.017098, loss_fp: 0.001708, loss_freq: 0.009925
[15:34:04.919] iteration 20114: loss: 0.045800, loss_s1: 0.011302, loss_fp: 0.003277, loss_freq: 0.004963
[15:34:05.542] iteration 20115: loss: 0.050973, loss_s1: 0.032015, loss_fp: 0.005365, loss_freq: 0.019687
[15:34:06.166] iteration 20116: loss: 0.053359, loss_s1: 0.019369, loss_fp: 0.013140, loss_freq: 0.013919
[15:34:06.780] iteration 20117: loss: 0.095080, loss_s1: 0.077537, loss_fp: 0.005797, loss_freq: 0.057620
[15:34:07.390] iteration 20118: loss: 0.038815, loss_s1: 0.030412, loss_fp: 0.002705, loss_freq: 0.011018
[15:34:08.012] iteration 20119: loss: 0.054687, loss_s1: 0.039629, loss_fp: 0.004827, loss_freq: 0.009303
[15:34:08.639] iteration 20120: loss: 0.055505, loss_s1: 0.020944, loss_fp: 0.002926, loss_freq: 0.045238
[15:34:09.268] iteration 20121: loss: 0.069798, loss_s1: 0.040894, loss_fp: 0.001168, loss_freq: 0.043988
[15:34:09.990] iteration 20122: loss: 0.088108, loss_s1: 0.034287, loss_fp: 0.002431, loss_freq: 0.050890
[15:34:10.634] iteration 20123: loss: 0.091433, loss_s1: 0.087413, loss_fp: 0.020106, loss_freq: 0.033668
[15:34:11.290] iteration 20124: loss: 0.068649, loss_s1: 0.050418, loss_fp: 0.013029, loss_freq: 0.012059
[15:34:11.941] iteration 20125: loss: 0.045864, loss_s1: 0.021460, loss_fp: 0.002864, loss_freq: 0.022245
[15:34:12.589] iteration 20126: loss: 0.052837, loss_s1: 0.031685, loss_fp: 0.000712, loss_freq: 0.022999
[15:34:13.215] iteration 20127: loss: 0.084792, loss_s1: 0.070721, loss_fp: 0.003120, loss_freq: 0.048330
[15:34:13.835] iteration 20128: loss: 0.073728, loss_s1: 0.076628, loss_fp: 0.002434, loss_freq: 0.037130
[15:34:14.455] iteration 20129: loss: 0.060215, loss_s1: 0.028255, loss_fp: 0.002767, loss_freq: 0.036312
[15:34:15.068] iteration 20130: loss: 0.092839, loss_s1: 0.083393, loss_fp: 0.003813, loss_freq: 0.065006
[15:34:15.738] iteration 20131: loss: 0.097504, loss_s1: 0.058612, loss_fp: 0.001468, loss_freq: 0.041999
[15:34:16.356] iteration 20132: loss: 0.038245, loss_s1: 0.027527, loss_fp: 0.001254, loss_freq: 0.018274
[15:34:16.977] iteration 20133: loss: 0.058045, loss_s1: 0.045004, loss_fp: 0.001815, loss_freq: 0.018911
[15:34:17.596] iteration 20134: loss: 0.061972, loss_s1: 0.042062, loss_fp: 0.014752, loss_freq: 0.023869
[15:34:18.218] iteration 20135: loss: 0.085776, loss_s1: 0.049509, loss_fp: 0.001571, loss_freq: 0.051847
[15:34:18.860] iteration 20136: loss: 0.069147, loss_s1: 0.065305, loss_fp: 0.001616, loss_freq: 0.030869
[15:34:19.514] iteration 20137: loss: 0.076160, loss_s1: 0.046496, loss_fp: 0.004236, loss_freq: 0.056101
[15:34:20.134] iteration 20138: loss: 0.064081, loss_s1: 0.054807, loss_fp: 0.001966, loss_freq: 0.023160
[15:34:20.757] iteration 20139: loss: 0.046517, loss_s1: 0.035504, loss_fp: 0.001751, loss_freq: 0.011545
[15:34:21.376] iteration 20140: loss: 0.055348, loss_s1: 0.018598, loss_fp: 0.001690, loss_freq: 0.036455
[15:34:21.999] iteration 20141: loss: 0.069721, loss_s1: 0.052950, loss_fp: 0.006369, loss_freq: 0.040037
[15:34:22.652] iteration 20142: loss: 0.060845, loss_s1: 0.050917, loss_fp: 0.001399, loss_freq: 0.018294
[15:34:23.274] iteration 20143: loss: 0.031020, loss_s1: 0.021373, loss_fp: 0.000405, loss_freq: 0.006236
[15:34:23.893] iteration 20144: loss: 0.061397, loss_s1: 0.066706, loss_fp: 0.002802, loss_freq: 0.017238
[15:34:24.513] iteration 20145: loss: 0.076717, loss_s1: 0.081634, loss_fp: 0.001090, loss_freq: 0.017350
[15:34:25.137] iteration 20146: loss: 0.070876, loss_s1: 0.068697, loss_fp: 0.004133, loss_freq: 0.012488
[15:34:25.759] iteration 20147: loss: 0.049224, loss_s1: 0.014140, loss_fp: 0.004127, loss_freq: 0.032673
[15:34:26.375] iteration 20148: loss: 0.063922, loss_s1: 0.050454, loss_fp: 0.001339, loss_freq: 0.025156
[15:34:26.998] iteration 20149: loss: 0.055822, loss_s1: 0.060076, loss_fp: 0.003114, loss_freq: 0.008632
[15:34:27.618] iteration 20150: loss: 0.052114, loss_s1: 0.024952, loss_fp: 0.005784, loss_freq: 0.017314
[15:34:28.241] iteration 20151: loss: 0.053138, loss_s1: 0.014335, loss_fp: 0.002753, loss_freq: 0.013527
[15:34:28.929] iteration 20152: loss: 0.077251, loss_s1: 0.054413, loss_fp: 0.001333, loss_freq: 0.019261
[15:34:29.575] iteration 20153: loss: 0.043618, loss_s1: 0.030431, loss_fp: 0.002204, loss_freq: 0.009428
[15:34:30.248] iteration 20154: loss: 0.081380, loss_s1: 0.069084, loss_fp: 0.003925, loss_freq: 0.027312
[15:34:30.885] iteration 20155: loss: 0.062383, loss_s1: 0.028950, loss_fp: 0.010853, loss_freq: 0.015877
[15:34:31.514] iteration 20156: loss: 0.099621, loss_s1: 0.109401, loss_fp: 0.009993, loss_freq: 0.015142
[15:34:32.137] iteration 20157: loss: 0.071606, loss_s1: 0.068225, loss_fp: 0.006028, loss_freq: 0.020114
[15:34:32.759] iteration 20158: loss: 0.031547, loss_s1: 0.019868, loss_fp: 0.000453, loss_freq: 0.011806
[15:34:33.388] iteration 20159: loss: 0.066152, loss_s1: 0.073225, loss_fp: 0.003238, loss_freq: 0.013646
[15:34:34.045] iteration 20160: loss: 0.044409, loss_s1: 0.020788, loss_fp: 0.004202, loss_freq: 0.007026
[15:34:34.685] iteration 20161: loss: 0.058352, loss_s1: 0.032438, loss_fp: 0.002668, loss_freq: 0.037281
[15:34:35.321] iteration 20162: loss: 0.101602, loss_s1: 0.086854, loss_fp: 0.011572, loss_freq: 0.051410
[15:34:35.961] iteration 20163: loss: 0.049349, loss_s1: 0.028071, loss_fp: 0.002740, loss_freq: 0.030767
[15:34:36.913] iteration 20164: loss: 0.032822, loss_s1: 0.011772, loss_fp: 0.001260, loss_freq: 0.006617
[15:34:37.539] iteration 20165: loss: 0.037433, loss_s1: 0.022645, loss_fp: 0.001895, loss_freq: 0.009039
[15:34:38.162] iteration 20166: loss: 0.060701, loss_s1: 0.028136, loss_fp: 0.003142, loss_freq: 0.048723
[15:34:38.787] iteration 20167: loss: 0.075634, loss_s1: 0.060992, loss_fp: 0.002067, loss_freq: 0.021952
[15:34:39.414] iteration 20168: loss: 0.044394, loss_s1: 0.026870, loss_fp: 0.001648, loss_freq: 0.028705
[15:34:40.036] iteration 20169: loss: 0.050257, loss_s1: 0.018743, loss_fp: 0.002611, loss_freq: 0.013710
[15:34:40.653] iteration 20170: loss: 0.033515, loss_s1: 0.021898, loss_fp: 0.002071, loss_freq: 0.012631
[15:34:41.268] iteration 20171: loss: 0.087580, loss_s1: 0.055624, loss_fp: 0.004112, loss_freq: 0.030355
[15:34:41.910] iteration 20172: loss: 0.057049, loss_s1: 0.027177, loss_fp: 0.005670, loss_freq: 0.032276
[15:34:42.564] iteration 20173: loss: 0.045066, loss_s1: 0.006208, loss_fp: 0.000727, loss_freq: 0.005073
[15:34:43.184] iteration 20174: loss: 0.059480, loss_s1: 0.038849, loss_fp: 0.002550, loss_freq: 0.039309
[15:34:43.802] iteration 20175: loss: 0.057973, loss_s1: 0.036864, loss_fp: 0.003721, loss_freq: 0.013761
[15:34:44.426] iteration 20176: loss: 0.056201, loss_s1: 0.051875, loss_fp: 0.001623, loss_freq: 0.011462
[15:34:45.046] iteration 20177: loss: 0.032351, loss_s1: 0.016687, loss_fp: 0.000860, loss_freq: 0.006708
[15:34:45.666] iteration 20178: loss: 0.050594, loss_s1: 0.033624, loss_fp: 0.001272, loss_freq: 0.022328
[15:34:46.283] iteration 20179: loss: 0.044204, loss_s1: 0.031543, loss_fp: 0.001427, loss_freq: 0.020873
[15:34:46.921] iteration 20180: loss: 0.084439, loss_s1: 0.049506, loss_fp: 0.001117, loss_freq: 0.046772
[15:34:47.532] iteration 20181: loss: 0.043904, loss_s1: 0.018967, loss_fp: 0.004494, loss_freq: 0.026427
[15:34:48.146] iteration 20182: loss: 0.051271, loss_s1: 0.022245, loss_fp: 0.010227, loss_freq: 0.035383
[15:34:48.769] iteration 20183: loss: 0.031590, loss_s1: 0.017673, loss_fp: 0.002578, loss_freq: 0.008881
[15:34:49.386] iteration 20184: loss: 0.081384, loss_s1: 0.035256, loss_fp: 0.005441, loss_freq: 0.060632
[15:34:50.006] iteration 20185: loss: 0.050330, loss_s1: 0.048259, loss_fp: 0.001506, loss_freq: 0.014972
[15:34:50.650] iteration 20186: loss: 0.048533, loss_s1: 0.028125, loss_fp: 0.004693, loss_freq: 0.016630
[15:34:51.332] iteration 20187: loss: 0.053560, loss_s1: 0.038403, loss_fp: 0.001086, loss_freq: 0.010642
[15:34:51.951] iteration 20188: loss: 0.059866, loss_s1: 0.047866, loss_fp: 0.004106, loss_freq: 0.024171
[15:34:52.570] iteration 20189: loss: 0.078114, loss_s1: 0.047811, loss_fp: 0.004287, loss_freq: 0.054039
[15:34:53.187] iteration 20190: loss: 0.095442, loss_s1: 0.085955, loss_fp: 0.003980, loss_freq: 0.056871
[15:34:53.805] iteration 20191: loss: 0.037410, loss_s1: 0.008764, loss_fp: 0.001819, loss_freq: 0.010715
[15:34:54.422] iteration 20192: loss: 0.044439, loss_s1: 0.026466, loss_fp: 0.000915, loss_freq: 0.014787
[15:34:55.039] iteration 20193: loss: 0.071067, loss_s1: 0.020329, loss_fp: 0.000976, loss_freq: 0.015736
[15:34:55.657] iteration 20194: loss: 0.036042, loss_s1: 0.026572, loss_fp: 0.001242, loss_freq: 0.007731
[15:34:56.272] iteration 20195: loss: 0.065842, loss_s1: 0.030682, loss_fp: 0.004445, loss_freq: 0.019997
[15:34:56.894] iteration 20196: loss: 0.105526, loss_s1: 0.118779, loss_fp: 0.011590, loss_freq: 0.053995
[15:34:57.514] iteration 20197: loss: 0.062294, loss_s1: 0.041779, loss_fp: 0.005348, loss_freq: 0.031211
[15:34:58.134] iteration 20198: loss: 0.065629, loss_s1: 0.041398, loss_fp: 0.005283, loss_freq: 0.034552
[15:34:58.753] iteration 20199: loss: 0.086941, loss_s1: 0.072494, loss_fp: 0.003376, loss_freq: 0.049674
[15:34:59.375] iteration 20200: loss: 0.062279, loss_s1: 0.020869, loss_fp: 0.003249, loss_freq: 0.034852
[15:35:02.847] iteration 20200 : mean_dice : 0.790126
[15:35:03.491] iteration 20201: loss: 0.064435, loss_s1: 0.060173, loss_fp: 0.016706, loss_freq: 0.012167
[15:35:04.110] iteration 20202: loss: 0.069579, loss_s1: 0.034731, loss_fp: 0.003257, loss_freq: 0.055798
[15:35:04.732] iteration 20203: loss: 0.028347, loss_s1: 0.022081, loss_fp: 0.000501, loss_freq: 0.007795
[15:35:05.389] iteration 20204: loss: 0.084924, loss_s1: 0.038788, loss_fp: 0.003549, loss_freq: 0.042531
[15:35:06.011] iteration 20205: loss: 0.035574, loss_s1: 0.025848, loss_fp: 0.002813, loss_freq: 0.015283
[15:35:06.628] iteration 20206: loss: 0.057767, loss_s1: 0.044677, loss_fp: 0.004754, loss_freq: 0.014333
[15:35:07.240] iteration 20207: loss: 0.044697, loss_s1: 0.027420, loss_fp: 0.001669, loss_freq: 0.007933
[15:35:07.911] iteration 20208: loss: 0.042781, loss_s1: 0.025662, loss_fp: 0.001423, loss_freq: 0.002512
[15:35:08.552] iteration 20209: loss: 0.060435, loss_s1: 0.046480, loss_fp: 0.001204, loss_freq: 0.021914
[15:35:09.192] iteration 20210: loss: 0.055982, loss_s1: 0.021683, loss_fp: 0.001086, loss_freq: 0.046742
[15:35:09.803] iteration 20211: loss: 0.048275, loss_s1: 0.046966, loss_fp: 0.004571, loss_freq: 0.010894
[15:35:10.431] iteration 20212: loss: 0.068494, loss_s1: 0.063653, loss_fp: 0.002750, loss_freq: 0.043118
[15:35:11.051] iteration 20213: loss: 0.047187, loss_s1: 0.029393, loss_fp: 0.004642, loss_freq: 0.019192
[15:35:11.676] iteration 20214: loss: 0.040063, loss_s1: 0.010989, loss_fp: 0.007423, loss_freq: 0.009181
[15:35:12.293] iteration 20215: loss: 0.070881, loss_s1: 0.057705, loss_fp: 0.002114, loss_freq: 0.029250
[15:35:12.914] iteration 20216: loss: 0.032204, loss_s1: 0.008189, loss_fp: 0.001991, loss_freq: 0.017879
[15:35:13.559] iteration 20217: loss: 0.039391, loss_s1: 0.026314, loss_fp: 0.004065, loss_freq: 0.022614
[15:35:14.229] iteration 20218: loss: 0.032113, loss_s1: 0.018282, loss_fp: 0.008835, loss_freq: 0.006808
[15:35:14.850] iteration 20219: loss: 0.048343, loss_s1: 0.016151, loss_fp: 0.000892, loss_freq: 0.007884
[15:35:15.468] iteration 20220: loss: 0.053266, loss_s1: 0.021535, loss_fp: 0.010322, loss_freq: 0.039642
[15:35:16.094] iteration 20221: loss: 0.031376, loss_s1: 0.007482, loss_fp: 0.000348, loss_freq: 0.020007
[15:35:16.715] iteration 20222: loss: 0.063835, loss_s1: 0.022426, loss_fp: 0.003283, loss_freq: 0.043774
[15:35:17.339] iteration 20223: loss: 0.055052, loss_s1: 0.052597, loss_fp: 0.000864, loss_freq: 0.017892
[15:35:17.956] iteration 20224: loss: 0.082983, loss_s1: 0.031826, loss_fp: 0.003711, loss_freq: 0.009005
[15:35:18.575] iteration 20225: loss: 0.059592, loss_s1: 0.055430, loss_fp: 0.006471, loss_freq: 0.011211
[15:35:19.195] iteration 20226: loss: 0.080390, loss_s1: 0.051120, loss_fp: 0.021237, loss_freq: 0.038090
[15:35:19.823] iteration 20227: loss: 0.051153, loss_s1: 0.028784, loss_fp: 0.001804, loss_freq: 0.017840
[15:35:20.433] iteration 20228: loss: 0.049334, loss_s1: 0.033038, loss_fp: 0.002270, loss_freq: 0.011007
[15:35:21.058] iteration 20229: loss: 0.053087, loss_s1: 0.015707, loss_fp: 0.002544, loss_freq: 0.036976
[15:35:21.683] iteration 20230: loss: 0.071156, loss_s1: 0.053085, loss_fp: 0.007698, loss_freq: 0.025389
[15:35:22.348] iteration 20231: loss: 0.044508, loss_s1: 0.029281, loss_fp: 0.003615, loss_freq: 0.023399
[15:35:22.983] iteration 20232: loss: 0.053041, loss_s1: 0.040320, loss_fp: 0.001826, loss_freq: 0.025884
[15:35:23.639] iteration 20233: loss: 0.080770, loss_s1: 0.067010, loss_fp: 0.006007, loss_freq: 0.008292
[15:35:24.263] iteration 20234: loss: 0.071631, loss_s1: 0.067862, loss_fp: 0.001691, loss_freq: 0.024774
[15:35:24.888] iteration 20235: loss: 0.062324, loss_s1: 0.047054, loss_fp: 0.005389, loss_freq: 0.026287
[15:35:25.530] iteration 20236: loss: 0.115905, loss_s1: 0.128303, loss_fp: 0.011539, loss_freq: 0.054146
[15:35:26.180] iteration 20237: loss: 0.087576, loss_s1: 0.070898, loss_fp: 0.004183, loss_freq: 0.040871
[15:35:26.841] iteration 20238: loss: 0.069113, loss_s1: 0.038095, loss_fp: 0.005939, loss_freq: 0.047945
[15:35:27.591] iteration 20239: loss: 0.050410, loss_s1: 0.026624, loss_fp: 0.002451, loss_freq: 0.024216
[15:35:28.234] iteration 20240: loss: 0.044838, loss_s1: 0.035730, loss_fp: 0.003854, loss_freq: 0.019719
[15:35:28.876] iteration 20241: loss: 0.058329, loss_s1: 0.024931, loss_fp: 0.000735, loss_freq: 0.014786
[15:35:29.503] iteration 20242: loss: 0.084599, loss_s1: 0.038941, loss_fp: 0.007079, loss_freq: 0.067516
[15:35:30.123] iteration 20243: loss: 0.098476, loss_s1: 0.050116, loss_fp: 0.006812, loss_freq: 0.024878
[15:35:30.744] iteration 20244: loss: 0.075557, loss_s1: 0.066274, loss_fp: 0.001396, loss_freq: 0.042245
[15:35:31.371] iteration 20245: loss: 0.053474, loss_s1: 0.027388, loss_fp: 0.001929, loss_freq: 0.022543
[15:35:31.996] iteration 20246: loss: 0.040916, loss_s1: 0.017601, loss_fp: 0.004550, loss_freq: 0.008543
[15:35:32.631] iteration 20247: loss: 0.061249, loss_s1: 0.046434, loss_fp: 0.002993, loss_freq: 0.029481
[15:35:33.261] iteration 20248: loss: 0.055620, loss_s1: 0.036327, loss_fp: 0.002869, loss_freq: 0.031672
[15:35:33.890] iteration 20249: loss: 0.066553, loss_s1: 0.026371, loss_fp: 0.005242, loss_freq: 0.050420
[15:35:34.507] iteration 20250: loss: 0.041052, loss_s1: 0.016814, loss_fp: 0.004551, loss_freq: 0.013712
[15:35:35.129] iteration 20251: loss: 0.036312, loss_s1: 0.011526, loss_fp: 0.001889, loss_freq: 0.007452
[15:35:35.750] iteration 20252: loss: 0.036710, loss_s1: 0.030130, loss_fp: 0.004661, loss_freq: 0.007624
[15:35:36.364] iteration 20253: loss: 0.054931, loss_s1: 0.047888, loss_fp: 0.004174, loss_freq: 0.025434
[15:35:36.998] iteration 20254: loss: 0.073965, loss_s1: 0.047335, loss_fp: 0.004324, loss_freq: 0.030211
[15:35:37.645] iteration 20255: loss: 0.047855, loss_s1: 0.029005, loss_fp: 0.005296, loss_freq: 0.025924
[15:35:38.260] iteration 20256: loss: 0.054768, loss_s1: 0.041642, loss_fp: 0.004461, loss_freq: 0.019136
[15:35:38.879] iteration 20257: loss: 0.037198, loss_s1: 0.019692, loss_fp: 0.003929, loss_freq: 0.008038
[15:35:39.507] iteration 20258: loss: 0.031266, loss_s1: 0.004057, loss_fp: 0.001027, loss_freq: 0.015337
[15:35:40.127] iteration 20259: loss: 0.026708, loss_s1: 0.007306, loss_fp: 0.001027, loss_freq: 0.006567
[15:35:40.739] iteration 20260: loss: 0.054305, loss_s1: 0.046167, loss_fp: 0.005549, loss_freq: 0.014229
[15:35:41.355] iteration 20261: loss: 0.037538, loss_s1: 0.016380, loss_fp: 0.005603, loss_freq: 0.016959
[15:35:41.973] iteration 20262: loss: 0.059031, loss_s1: 0.031355, loss_fp: 0.003531, loss_freq: 0.020334
[15:35:42.602] iteration 20263: loss: 0.075713, loss_s1: 0.051603, loss_fp: 0.002022, loss_freq: 0.052316
[15:35:43.228] iteration 20264: loss: 0.039410, loss_s1: 0.021088, loss_fp: 0.001923, loss_freq: 0.013151
[15:35:43.848] iteration 20265: loss: 0.053361, loss_s1: 0.027045, loss_fp: 0.004487, loss_freq: 0.028515
[15:35:44.467] iteration 20266: loss: 0.041707, loss_s1: 0.031760, loss_fp: 0.003798, loss_freq: 0.017145
[15:35:45.079] iteration 20267: loss: 0.055186, loss_s1: 0.051946, loss_fp: 0.000893, loss_freq: 0.020010
[15:35:45.693] iteration 20268: loss: 0.067924, loss_s1: 0.042442, loss_fp: 0.005067, loss_freq: 0.020479
[15:35:46.318] iteration 20269: loss: 0.050073, loss_s1: 0.040763, loss_fp: 0.003705, loss_freq: 0.015674
[15:35:46.942] iteration 20270: loss: 0.119375, loss_s1: 0.096144, loss_fp: 0.006737, loss_freq: 0.079394
[15:35:47.598] iteration 20271: loss: 0.050345, loss_s1: 0.026018, loss_fp: 0.007815, loss_freq: 0.031553
[15:35:48.211] iteration 20272: loss: 0.075130, loss_s1: 0.067012, loss_fp: 0.001607, loss_freq: 0.022198
[15:35:48.831] iteration 20273: loss: 0.073488, loss_s1: 0.069315, loss_fp: 0.004291, loss_freq: 0.037188
[15:35:49.481] iteration 20274: loss: 0.078041, loss_s1: 0.054251, loss_fp: 0.003533, loss_freq: 0.020557
[15:35:50.098] iteration 20275: loss: 0.037849, loss_s1: 0.032426, loss_fp: 0.001486, loss_freq: 0.014401
[15:35:50.715] iteration 20276: loss: 0.053840, loss_s1: 0.028693, loss_fp: 0.001252, loss_freq: 0.012943
[15:35:51.333] iteration 20277: loss: 0.072694, loss_s1: 0.057883, loss_fp: 0.012204, loss_freq: 0.037901
[15:35:51.945] iteration 20278: loss: 0.047923, loss_s1: 0.015856, loss_fp: 0.005429, loss_freq: 0.010436
[15:35:52.558] iteration 20279: loss: 0.038649, loss_s1: 0.017258, loss_fp: 0.001491, loss_freq: 0.023260
[15:35:53.183] iteration 20280: loss: 0.074938, loss_s1: 0.055011, loss_fp: 0.004538, loss_freq: 0.042819
[15:35:53.811] iteration 20281: loss: 0.067441, loss_s1: 0.056480, loss_fp: 0.002927, loss_freq: 0.035045
[15:35:54.445] iteration 20282: loss: 0.050592, loss_s1: 0.046547, loss_fp: 0.000530, loss_freq: 0.023199
[15:35:55.065] iteration 20283: loss: 0.043833, loss_s1: 0.029057, loss_fp: 0.000757, loss_freq: 0.018658
[15:35:55.679] iteration 20284: loss: 0.078679, loss_s1: 0.040054, loss_fp: 0.005379, loss_freq: 0.065752
[15:35:56.299] iteration 20285: loss: 0.088352, loss_s1: 0.081424, loss_fp: 0.005819, loss_freq: 0.039794
[15:35:56.911] iteration 20286: loss: 0.037268, loss_s1: 0.011495, loss_fp: 0.003942, loss_freq: 0.014383
[15:35:57.527] iteration 20287: loss: 0.055179, loss_s1: 0.057318, loss_fp: 0.002859, loss_freq: 0.022792
[15:35:58.139] iteration 20288: loss: 0.051334, loss_s1: 0.039890, loss_fp: 0.007156, loss_freq: 0.025488
[15:35:58.755] iteration 20289: loss: 0.043964, loss_s1: 0.027660, loss_fp: 0.004538, loss_freq: 0.009903
[15:35:59.372] iteration 20290: loss: 0.038879, loss_s1: 0.010345, loss_fp: 0.001557, loss_freq: 0.033861
[15:35:59.986] iteration 20291: loss: 0.045428, loss_s1: 0.023541, loss_fp: 0.004628, loss_freq: 0.024470
[15:36:00.603] iteration 20292: loss: 0.056620, loss_s1: 0.061490, loss_fp: 0.002237, loss_freq: 0.014753
[15:36:01.219] iteration 20293: loss: 0.050546, loss_s1: 0.034918, loss_fp: 0.002332, loss_freq: 0.018100
[15:36:01.839] iteration 20294: loss: 0.080741, loss_s1: 0.053707, loss_fp: 0.011878, loss_freq: 0.031952
[15:36:02.456] iteration 20295: loss: 0.083151, loss_s1: 0.056511, loss_fp: 0.007781, loss_freq: 0.029579
[15:36:03.111] iteration 20296: loss: 0.057014, loss_s1: 0.029238, loss_fp: 0.002481, loss_freq: 0.038567
[15:36:03.727] iteration 20297: loss: 0.073944, loss_s1: 0.040381, loss_fp: 0.001560, loss_freq: 0.041466
[15:36:04.358] iteration 20298: loss: 0.058253, loss_s1: 0.017191, loss_fp: 0.004919, loss_freq: 0.025966
[15:36:04.973] iteration 20299: loss: 0.081987, loss_s1: 0.067741, loss_fp: 0.003619, loss_freq: 0.039829
[15:36:05.630] iteration 20300: loss: 0.069537, loss_s1: 0.053745, loss_fp: 0.002520, loss_freq: 0.035417
[15:36:06.248] iteration 20301: loss: 0.040177, loss_s1: 0.029765, loss_fp: 0.001314, loss_freq: 0.011043
[15:36:06.866] iteration 20302: loss: 0.048082, loss_s1: 0.032739, loss_fp: 0.000852, loss_freq: 0.017019
[15:36:07.485] iteration 20303: loss: 0.048357, loss_s1: 0.038689, loss_fp: 0.003110, loss_freq: 0.014755
[15:36:08.148] iteration 20304: loss: 0.063270, loss_s1: 0.021449, loss_fp: 0.001113, loss_freq: 0.039290
[15:36:08.766] iteration 20305: loss: 0.059002, loss_s1: 0.059276, loss_fp: 0.001044, loss_freq: 0.014703
[15:36:09.381] iteration 20306: loss: 0.049965, loss_s1: 0.022791, loss_fp: 0.002279, loss_freq: 0.036479
[15:36:10.343] iteration 20307: loss: 0.039350, loss_s1: 0.028673, loss_fp: 0.004019, loss_freq: 0.007704
[15:36:10.971] iteration 20308: loss: 0.057270, loss_s1: 0.049450, loss_fp: 0.000542, loss_freq: 0.014795
[15:36:11.597] iteration 20309: loss: 0.030928, loss_s1: 0.014501, loss_fp: 0.000983, loss_freq: 0.015261
[15:36:12.216] iteration 20310: loss: 0.047583, loss_s1: 0.031077, loss_fp: 0.002685, loss_freq: 0.022062
[15:36:12.839] iteration 20311: loss: 0.061670, loss_s1: 0.058267, loss_fp: 0.002501, loss_freq: 0.031068
[15:36:13.462] iteration 20312: loss: 0.042118, loss_s1: 0.037561, loss_fp: 0.000813, loss_freq: 0.003934
[15:36:14.083] iteration 20313: loss: 0.051421, loss_s1: 0.055166, loss_fp: 0.002289, loss_freq: 0.016805
[15:36:14.890] iteration 20314: loss: 0.055810, loss_s1: 0.019948, loss_fp: 0.003679, loss_freq: 0.025872
[15:36:15.646] iteration 20315: loss: 0.072204, loss_s1: 0.085042, loss_fp: 0.003897, loss_freq: 0.013758
[15:36:16.407] iteration 20316: loss: 0.035312, loss_s1: 0.009649, loss_fp: 0.003675, loss_freq: 0.005854
[15:36:17.118] iteration 20317: loss: 0.051791, loss_s1: 0.025810, loss_fp: 0.002433, loss_freq: 0.030997
[15:36:17.743] iteration 20318: loss: 0.042284, loss_s1: 0.018804, loss_fp: 0.003092, loss_freq: 0.013436
[15:36:18.366] iteration 20319: loss: 0.047390, loss_s1: 0.043534, loss_fp: 0.002629, loss_freq: 0.004973
[15:36:18.986] iteration 20320: loss: 0.055954, loss_s1: 0.024798, loss_fp: 0.001775, loss_freq: 0.037369
[15:36:19.608] iteration 20321: loss: 0.073355, loss_s1: 0.081088, loss_fp: 0.003359, loss_freq: 0.016668
[15:36:20.280] iteration 20322: loss: 0.049676, loss_s1: 0.024893, loss_fp: 0.003504, loss_freq: 0.030408
[15:36:20.953] iteration 20323: loss: 0.058033, loss_s1: 0.035669, loss_fp: 0.001978, loss_freq: 0.028284
[15:36:21.564] iteration 20324: loss: 0.052110, loss_s1: 0.037498, loss_fp: 0.001063, loss_freq: 0.020436
[15:36:22.187] iteration 20325: loss: 0.033496, loss_s1: 0.014628, loss_fp: 0.001208, loss_freq: 0.018192
[15:36:22.809] iteration 20326: loss: 0.039319, loss_s1: 0.034937, loss_fp: 0.001117, loss_freq: 0.012153
[15:36:23.440] iteration 20327: loss: 0.072017, loss_s1: 0.020474, loss_fp: 0.002670, loss_freq: 0.061928
[15:36:24.071] iteration 20328: loss: 0.055334, loss_s1: 0.036373, loss_fp: 0.002138, loss_freq: 0.031488
[15:36:24.694] iteration 20329: loss: 0.043009, loss_s1: 0.031452, loss_fp: 0.002636, loss_freq: 0.017423
[15:36:25.317] iteration 20330: loss: 0.048125, loss_s1: 0.038697, loss_fp: 0.003870, loss_freq: 0.011540
[15:36:25.943] iteration 20331: loss: 0.048600, loss_s1: 0.009511, loss_fp: 0.001842, loss_freq: 0.027827
[15:36:26.601] iteration 20332: loss: 0.089435, loss_s1: 0.090986, loss_fp: 0.004552, loss_freq: 0.020610
[15:36:27.228] iteration 20333: loss: 0.060246, loss_s1: 0.033266, loss_fp: 0.001078, loss_freq: 0.034526
[15:36:27.854] iteration 20334: loss: 0.049576, loss_s1: 0.032391, loss_fp: 0.000607, loss_freq: 0.011817
[15:36:28.480] iteration 20335: loss: 0.079047, loss_s1: 0.076140, loss_fp: 0.002371, loss_freq: 0.025878
[15:36:29.138] iteration 20336: loss: 0.049222, loss_s1: 0.020626, loss_fp: 0.001213, loss_freq: 0.008881
[15:36:29.785] iteration 20337: loss: 0.051044, loss_s1: 0.044831, loss_fp: 0.001948, loss_freq: 0.014951
[15:36:30.414] iteration 20338: loss: 0.050277, loss_s1: 0.015074, loss_fp: 0.002319, loss_freq: 0.015390
[15:36:31.042] iteration 20339: loss: 0.065520, loss_s1: 0.050609, loss_fp: 0.002716, loss_freq: 0.042061
[15:36:31.669] iteration 20340: loss: 0.120524, loss_s1: 0.115754, loss_fp: 0.010603, loss_freq: 0.065415
[15:36:32.286] iteration 20341: loss: 0.096820, loss_s1: 0.041332, loss_fp: 0.003778, loss_freq: 0.031378
[15:36:32.905] iteration 20342: loss: 0.062643, loss_s1: 0.068307, loss_fp: 0.000801, loss_freq: 0.021147
[15:36:33.532] iteration 20343: loss: 0.067551, loss_s1: 0.036220, loss_fp: 0.004568, loss_freq: 0.038866
[15:36:34.147] iteration 20344: loss: 0.051322, loss_s1: 0.019505, loss_fp: 0.003745, loss_freq: 0.040797
[15:36:34.758] iteration 20345: loss: 0.079051, loss_s1: 0.051079, loss_fp: 0.004672, loss_freq: 0.044621
[15:36:35.372] iteration 20346: loss: 0.062865, loss_s1: 0.050870, loss_fp: 0.006062, loss_freq: 0.017703
[15:36:35.999] iteration 20347: loss: 0.055518, loss_s1: 0.036738, loss_fp: 0.007936, loss_freq: 0.013683
[15:36:36.622] iteration 20348: loss: 0.051999, loss_s1: 0.036760, loss_fp: 0.002016, loss_freq: 0.035035
[15:36:37.240] iteration 20349: loss: 0.060885, loss_s1: 0.012148, loss_fp: 0.003761, loss_freq: 0.009421
[15:36:37.849] iteration 20350: loss: 0.086826, loss_s1: 0.086331, loss_fp: 0.004215, loss_freq: 0.040080
[15:36:38.487] iteration 20351: loss: 0.069871, loss_s1: 0.029835, loss_fp: 0.003219, loss_freq: 0.044183
[15:36:39.120] iteration 20352: loss: 0.086918, loss_s1: 0.073076, loss_fp: 0.001234, loss_freq: 0.057587
[15:36:39.758] iteration 20353: loss: 0.057612, loss_s1: 0.015229, loss_fp: 0.004778, loss_freq: 0.035280
[15:36:40.386] iteration 20354: loss: 0.048294, loss_s1: 0.041306, loss_fp: 0.002224, loss_freq: 0.012272
[15:36:41.008] iteration 20355: loss: 0.066153, loss_s1: 0.074030, loss_fp: 0.000784, loss_freq: 0.027754
[15:36:41.626] iteration 20356: loss: 0.059405, loss_s1: 0.059292, loss_fp: 0.003344, loss_freq: 0.012639
[15:36:42.240] iteration 20357: loss: 0.073546, loss_s1: 0.086358, loss_fp: 0.003520, loss_freq: 0.021782
[15:36:42.888] iteration 20358: loss: 0.064436, loss_s1: 0.010861, loss_fp: 0.003855, loss_freq: 0.043074
[15:36:43.504] iteration 20359: loss: 0.037728, loss_s1: 0.031359, loss_fp: 0.000772, loss_freq: 0.009234
[15:36:44.122] iteration 20360: loss: 0.043562, loss_s1: 0.034543, loss_fp: 0.006047, loss_freq: 0.015805
[15:36:44.745] iteration 20361: loss: 0.025545, loss_s1: 0.009761, loss_fp: 0.003745, loss_freq: 0.007013
[15:36:45.366] iteration 20362: loss: 0.045908, loss_s1: 0.034978, loss_fp: 0.001061, loss_freq: 0.011534
[15:36:46.005] iteration 20363: loss: 0.058712, loss_s1: 0.050428, loss_fp: 0.001185, loss_freq: 0.025390
[15:36:46.640] iteration 20364: loss: 0.056235, loss_s1: 0.052712, loss_fp: 0.002946, loss_freq: 0.022118
[15:36:47.257] iteration 20365: loss: 0.054809, loss_s1: 0.043115, loss_fp: 0.001638, loss_freq: 0.028148
[15:36:47.880] iteration 20366: loss: 0.053142, loss_s1: 0.038035, loss_fp: 0.004645, loss_freq: 0.010108
[15:36:48.501] iteration 20367: loss: 0.053109, loss_s1: 0.045453, loss_fp: 0.002487, loss_freq: 0.012027
[15:36:49.128] iteration 20368: loss: 0.047498, loss_s1: 0.033080, loss_fp: 0.001805, loss_freq: 0.011361
[15:36:49.749] iteration 20369: loss: 0.066417, loss_s1: 0.022305, loss_fp: 0.009114, loss_freq: 0.059538
[15:36:50.378] iteration 20370: loss: 0.050787, loss_s1: 0.017556, loss_fp: 0.001503, loss_freq: 0.023052
[15:36:50.999] iteration 20371: loss: 0.066525, loss_s1: 0.025576, loss_fp: 0.001255, loss_freq: 0.028687
[15:36:51.621] iteration 20372: loss: 0.053916, loss_s1: 0.041064, loss_fp: 0.004453, loss_freq: 0.030121
[15:36:52.245] iteration 20373: loss: 0.058438, loss_s1: 0.036616, loss_fp: 0.001756, loss_freq: 0.015364
[15:36:52.891] iteration 20374: loss: 0.067084, loss_s1: 0.055066, loss_fp: 0.012686, loss_freq: 0.031229
[15:36:53.508] iteration 20375: loss: 0.057584, loss_s1: 0.048869, loss_fp: 0.002541, loss_freq: 0.019920
[15:36:54.119] iteration 20376: loss: 0.075122, loss_s1: 0.080884, loss_fp: 0.001075, loss_freq: 0.020647
[15:36:54.739] iteration 20377: loss: 0.050162, loss_s1: 0.040831, loss_fp: 0.006140, loss_freq: 0.014491
[15:36:55.388] iteration 20378: loss: 0.075269, loss_s1: 0.059807, loss_fp: 0.001705, loss_freq: 0.050775
[15:36:56.003] iteration 20379: loss: 0.093434, loss_s1: 0.096230, loss_fp: 0.006380, loss_freq: 0.035743
[15:36:56.618] iteration 20380: loss: 0.080591, loss_s1: 0.082571, loss_fp: 0.009152, loss_freq: 0.032023
[15:36:57.283] iteration 20381: loss: 0.075780, loss_s1: 0.055101, loss_fp: 0.007611, loss_freq: 0.038850
[15:36:57.953] iteration 20382: loss: 0.063323, loss_s1: 0.017839, loss_fp: 0.003710, loss_freq: 0.020823
[15:36:58.570] iteration 20383: loss: 0.041654, loss_s1: 0.018495, loss_fp: 0.004100, loss_freq: 0.017722
[15:36:59.190] iteration 20384: loss: 0.048487, loss_s1: 0.028578, loss_fp: 0.001912, loss_freq: 0.018178
[15:36:59.805] iteration 20385: loss: 0.081582, loss_s1: 0.071492, loss_fp: 0.005660, loss_freq: 0.039106
[15:37:00.422] iteration 20386: loss: 0.085323, loss_s1: 0.067857, loss_fp: 0.007182, loss_freq: 0.032698
[15:37:01.035] iteration 20387: loss: 0.079744, loss_s1: 0.076995, loss_fp: 0.001243, loss_freq: 0.022451
[15:37:01.655] iteration 20388: loss: 0.052249, loss_s1: 0.049893, loss_fp: 0.001614, loss_freq: 0.016750
[15:37:02.272] iteration 20389: loss: 0.046434, loss_s1: 0.034290, loss_fp: 0.005719, loss_freq: 0.015059
[15:37:02.889] iteration 20390: loss: 0.037671, loss_s1: 0.032249, loss_fp: 0.003057, loss_freq: 0.006586
[15:37:03.504] iteration 20391: loss: 0.059889, loss_s1: 0.041707, loss_fp: 0.001526, loss_freq: 0.029417
[15:37:04.214] iteration 20392: loss: 0.050751, loss_s1: 0.016012, loss_fp: 0.001358, loss_freq: 0.034637
[15:37:04.946] iteration 20393: loss: 0.036864, loss_s1: 0.026232, loss_fp: 0.001917, loss_freq: 0.006928
[15:37:05.595] iteration 20394: loss: 0.030321, loss_s1: 0.019884, loss_fp: 0.001048, loss_freq: 0.007136
[15:37:06.244] iteration 20395: loss: 0.041588, loss_s1: 0.016310, loss_fp: 0.008431, loss_freq: 0.026064
[15:37:06.878] iteration 20396: loss: 0.044507, loss_s1: 0.030759, loss_fp: 0.004026, loss_freq: 0.013600
[15:37:07.502] iteration 20397: loss: 0.064214, loss_s1: 0.014529, loss_fp: 0.001247, loss_freq: 0.008376
[15:37:08.124] iteration 20398: loss: 0.045869, loss_s1: 0.038560, loss_fp: 0.002259, loss_freq: 0.016137
[15:37:08.812] iteration 20399: loss: 0.040899, loss_s1: 0.022364, loss_fp: 0.000883, loss_freq: 0.020723
[15:37:09.451] iteration 20400: loss: 0.041197, loss_s1: 0.037361, loss_fp: 0.005340, loss_freq: 0.003629
[15:37:12.814] iteration 20400 : mean_dice : 0.775343
[15:37:13.498] iteration 20401: loss: 0.038382, loss_s1: 0.019930, loss_fp: 0.003570, loss_freq: 0.016718
[15:37:14.120] iteration 20402: loss: 0.069765, loss_s1: 0.058448, loss_fp: 0.000790, loss_freq: 0.005664
[15:37:14.801] iteration 20403: loss: 0.063712, loss_s1: 0.032384, loss_fp: 0.008040, loss_freq: 0.050271
[15:37:15.441] iteration 20404: loss: 0.039111, loss_s1: 0.023357, loss_fp: 0.004077, loss_freq: 0.010489
[15:37:16.069] iteration 20405: loss: 0.046160, loss_s1: 0.011743, loss_fp: 0.001670, loss_freq: 0.020327
[15:37:16.687] iteration 20406: loss: 0.080802, loss_s1: 0.050909, loss_fp: 0.003421, loss_freq: 0.050990
[15:37:17.313] iteration 20407: loss: 0.099972, loss_s1: 0.060398, loss_fp: 0.002696, loss_freq: 0.084743
[15:37:17.952] iteration 20408: loss: 0.092699, loss_s1: 0.039331, loss_fp: 0.001833, loss_freq: 0.075565
[15:37:18.574] iteration 20409: loss: 0.065283, loss_s1: 0.061168, loss_fp: 0.003416, loss_freq: 0.023112
[15:37:19.197] iteration 20410: loss: 0.049620, loss_s1: 0.045869, loss_fp: 0.003993, loss_freq: 0.012777
[15:37:19.814] iteration 20411: loss: 0.056704, loss_s1: 0.041339, loss_fp: 0.002120, loss_freq: 0.015294
[15:37:20.436] iteration 20412: loss: 0.060743, loss_s1: 0.047234, loss_fp: 0.001754, loss_freq: 0.013236
[15:37:21.062] iteration 20413: loss: 0.051716, loss_s1: 0.013481, loss_fp: 0.017893, loss_freq: 0.028624
[15:37:21.679] iteration 20414: loss: 0.105580, loss_s1: 0.060994, loss_fp: 0.006857, loss_freq: 0.108940
[15:37:22.299] iteration 20415: loss: 0.064925, loss_s1: 0.038879, loss_fp: 0.001922, loss_freq: 0.038426
[15:37:22.910] iteration 20416: loss: 0.048296, loss_s1: 0.018173, loss_fp: 0.002449, loss_freq: 0.035969
[15:37:23.528] iteration 20417: loss: 0.068651, loss_s1: 0.039495, loss_fp: 0.008717, loss_freq: 0.042835
[15:37:24.146] iteration 20418: loss: 0.032000, loss_s1: 0.015717, loss_fp: 0.001370, loss_freq: 0.019360
[15:37:24.803] iteration 20419: loss: 0.032176, loss_s1: 0.009260, loss_fp: 0.000801, loss_freq: 0.006878
[15:37:25.420] iteration 20420: loss: 0.054715, loss_s1: 0.057576, loss_fp: 0.003446, loss_freq: 0.011848
[15:37:26.044] iteration 20421: loss: 0.051148, loss_s1: 0.015972, loss_fp: 0.001020, loss_freq: 0.014064
[15:37:26.667] iteration 20422: loss: 0.039287, loss_s1: 0.014797, loss_fp: 0.006413, loss_freq: 0.017363
[15:37:27.287] iteration 20423: loss: 0.040580, loss_s1: 0.012229, loss_fp: 0.008588, loss_freq: 0.021916
[15:37:27.906] iteration 20424: loss: 0.076906, loss_s1: 0.049100, loss_fp: 0.001215, loss_freq: 0.054851
[15:37:28.656] iteration 20425: loss: 0.064896, loss_s1: 0.075527, loss_fp: 0.001768, loss_freq: 0.023030
[15:37:29.311] iteration 20426: loss: 0.049652, loss_s1: 0.016636, loss_fp: 0.002076, loss_freq: 0.037540
[15:37:29.957] iteration 20427: loss: 0.071350, loss_s1: 0.062227, loss_fp: 0.003933, loss_freq: 0.028733
[15:37:30.605] iteration 20428: loss: 0.049501, loss_s1: 0.035592, loss_fp: 0.005193, loss_freq: 0.021274
[15:37:31.247] iteration 20429: loss: 0.038167, loss_s1: 0.013666, loss_fp: 0.002566, loss_freq: 0.010848
[15:37:31.886] iteration 20430: loss: 0.047170, loss_s1: 0.038174, loss_fp: 0.008754, loss_freq: 0.018940
[15:37:32.507] iteration 20431: loss: 0.048989, loss_s1: 0.032353, loss_fp: 0.002943, loss_freq: 0.029159
[15:37:33.126] iteration 20432: loss: 0.068043, loss_s1: 0.035368, loss_fp: 0.001155, loss_freq: 0.011834
[15:37:33.753] iteration 20433: loss: 0.051464, loss_s1: 0.038752, loss_fp: 0.003465, loss_freq: 0.024856
[15:37:34.382] iteration 20434: loss: 0.058795, loss_s1: 0.029856, loss_fp: 0.003193, loss_freq: 0.050890
[15:37:35.005] iteration 20435: loss: 0.097901, loss_s1: 0.094068, loss_fp: 0.003094, loss_freq: 0.039698
[15:37:35.626] iteration 20436: loss: 0.051797, loss_s1: 0.031467, loss_fp: 0.004250, loss_freq: 0.024613
[15:37:36.252] iteration 20437: loss: 0.064807, loss_s1: 0.043243, loss_fp: 0.007398, loss_freq: 0.038277
[15:37:36.881] iteration 20438: loss: 0.056176, loss_s1: 0.037211, loss_fp: 0.006700, loss_freq: 0.027914
[15:37:37.503] iteration 20439: loss: 0.056450, loss_s1: 0.046071, loss_fp: 0.001192, loss_freq: 0.016239
[15:37:38.143] iteration 20440: loss: 0.061379, loss_s1: 0.035679, loss_fp: 0.000610, loss_freq: 0.032148
[15:37:38.808] iteration 20441: loss: 0.079640, loss_s1: 0.061956, loss_fp: 0.003392, loss_freq: 0.024889
[15:37:39.430] iteration 20442: loss: 0.061021, loss_s1: 0.038976, loss_fp: 0.009606, loss_freq: 0.015297
[15:37:40.056] iteration 20443: loss: 0.083410, loss_s1: 0.078571, loss_fp: 0.004297, loss_freq: 0.042548
[15:37:40.687] iteration 20444: loss: 0.040096, loss_s1: 0.016703, loss_fp: 0.005169, loss_freq: 0.022972
[15:37:41.316] iteration 20445: loss: 0.063674, loss_s1: 0.038614, loss_fp: 0.004601, loss_freq: 0.020186
[15:37:41.938] iteration 20446: loss: 0.054279, loss_s1: 0.041968, loss_fp: 0.005516, loss_freq: 0.015520
[15:37:42.558] iteration 20447: loss: 0.077179, loss_s1: 0.066829, loss_fp: 0.007997, loss_freq: 0.029160
[15:37:43.181] iteration 20448: loss: 0.098720, loss_s1: 0.074698, loss_fp: 0.003198, loss_freq: 0.074815
[15:37:43.803] iteration 20449: loss: 0.045943, loss_s1: 0.034748, loss_fp: 0.004285, loss_freq: 0.015108
[15:37:44.779] iteration 20450: loss: 0.049004, loss_s1: 0.038226, loss_fp: 0.001778, loss_freq: 0.006161
[15:37:45.413] iteration 20451: loss: 0.047604, loss_s1: 0.038300, loss_fp: 0.006760, loss_freq: 0.009726
[15:37:46.061] iteration 20452: loss: 0.048430, loss_s1: 0.026894, loss_fp: 0.002351, loss_freq: 0.031608
[15:37:46.712] iteration 20453: loss: 0.085324, loss_s1: 0.099223, loss_fp: 0.001831, loss_freq: 0.016442
[15:37:47.338] iteration 20454: loss: 0.054547, loss_s1: 0.040796, loss_fp: 0.003613, loss_freq: 0.034207
[15:37:47.965] iteration 20455: loss: 0.048166, loss_s1: 0.031547, loss_fp: 0.001454, loss_freq: 0.012047
[15:37:48.590] iteration 20456: loss: 0.032218, loss_s1: 0.016228, loss_fp: 0.001589, loss_freq: 0.014052
[15:37:49.234] iteration 20457: loss: 0.057640, loss_s1: 0.047226, loss_fp: 0.003185, loss_freq: 0.021755
[15:37:49.868] iteration 20458: loss: 0.049973, loss_s1: 0.017700, loss_fp: 0.014128, loss_freq: 0.016697
[15:37:50.492] iteration 20459: loss: 0.044235, loss_s1: 0.009738, loss_fp: 0.000830, loss_freq: 0.004013
[15:37:51.118] iteration 20460: loss: 0.068115, loss_s1: 0.031866, loss_fp: 0.004833, loss_freq: 0.027517
[15:37:51.795] iteration 20461: loss: 0.050722, loss_s1: 0.015699, loss_fp: 0.003601, loss_freq: 0.029094
[15:37:52.421] iteration 20462: loss: 0.084012, loss_s1: 0.076118, loss_fp: 0.006471, loss_freq: 0.030278
[15:37:53.048] iteration 20463: loss: 0.043645, loss_s1: 0.024672, loss_fp: 0.001245, loss_freq: 0.007705
[15:37:53.675] iteration 20464: loss: 0.053381, loss_s1: 0.041813, loss_fp: 0.003330, loss_freq: 0.018490
[15:37:54.294] iteration 20465: loss: 0.049688, loss_s1: 0.028273, loss_fp: 0.002463, loss_freq: 0.031187
[15:37:54.914] iteration 20466: loss: 0.128778, loss_s1: 0.037241, loss_fp: 0.001263, loss_freq: 0.032721
[15:37:55.529] iteration 20467: loss: 0.047058, loss_s1: 0.043766, loss_fp: 0.002803, loss_freq: 0.012749
[15:37:56.159] iteration 20468: loss: 0.054373, loss_s1: 0.031398, loss_fp: 0.000751, loss_freq: 0.014589
[15:37:56.787] iteration 20469: loss: 0.044013, loss_s1: 0.044536, loss_fp: 0.001621, loss_freq: 0.008211
[15:37:57.407] iteration 20470: loss: 0.090250, loss_s1: 0.053325, loss_fp: 0.001474, loss_freq: 0.047233
[15:37:58.032] iteration 20471: loss: 0.046899, loss_s1: 0.026201, loss_fp: 0.006137, loss_freq: 0.022654
[15:37:58.659] iteration 20472: loss: 0.084824, loss_s1: 0.064968, loss_fp: 0.003662, loss_freq: 0.054747
[15:37:59.286] iteration 20473: loss: 0.040561, loss_s1: 0.022537, loss_fp: 0.000876, loss_freq: 0.006742
[15:37:59.920] iteration 20474: loss: 0.040096, loss_s1: 0.019730, loss_fp: 0.002569, loss_freq: 0.016440
[15:38:00.545] iteration 20475: loss: 0.063758, loss_s1: 0.044984, loss_fp: 0.004653, loss_freq: 0.030879
[15:38:01.208] iteration 20476: loss: 0.076079, loss_s1: 0.032866, loss_fp: 0.001763, loss_freq: 0.050500
[15:38:01.855] iteration 20477: loss: 0.042509, loss_s1: 0.025864, loss_fp: 0.002846, loss_freq: 0.007493
[15:38:02.499] iteration 20478: loss: 0.071403, loss_s1: 0.044058, loss_fp: 0.005265, loss_freq: 0.049620
[15:38:03.137] iteration 20479: loss: 0.066145, loss_s1: 0.047253, loss_fp: 0.002017, loss_freq: 0.013245
[15:38:03.775] iteration 20480: loss: 0.048975, loss_s1: 0.029865, loss_fp: 0.003685, loss_freq: 0.023960
[15:38:04.415] iteration 20481: loss: 0.081640, loss_s1: 0.034021, loss_fp: 0.009832, loss_freq: 0.024559
[15:38:05.060] iteration 20482: loss: 0.100489, loss_s1: 0.098996, loss_fp: 0.010678, loss_freq: 0.055571
[15:38:05.689] iteration 20483: loss: 0.076724, loss_s1: 0.053149, loss_fp: 0.008538, loss_freq: 0.057266
[15:38:06.346] iteration 20484: loss: 0.075586, loss_s1: 0.044558, loss_fp: 0.005903, loss_freq: 0.027817
[15:38:06.967] iteration 20485: loss: 0.072684, loss_s1: 0.029792, loss_fp: 0.003238, loss_freq: 0.054036
[15:38:07.614] iteration 20486: loss: 0.076252, loss_s1: 0.065609, loss_fp: 0.001305, loss_freq: 0.028545
[15:38:08.233] iteration 20487: loss: 0.069519, loss_s1: 0.066383, loss_fp: 0.003097, loss_freq: 0.028310
[15:38:08.860] iteration 20488: loss: 0.107253, loss_s1: 0.083865, loss_fp: 0.003455, loss_freq: 0.032704
[15:38:09.486] iteration 20489: loss: 0.058251, loss_s1: 0.047229, loss_fp: 0.011111, loss_freq: 0.016033
[15:38:10.109] iteration 20490: loss: 0.089336, loss_s1: 0.070407, loss_fp: 0.004146, loss_freq: 0.051571
[15:38:10.773] iteration 20491: loss: 0.077712, loss_s1: 0.063569, loss_fp: 0.003760, loss_freq: 0.051399
[15:38:11.415] iteration 20492: loss: 0.057438, loss_s1: 0.023984, loss_fp: 0.004259, loss_freq: 0.032752
[15:38:12.063] iteration 20493: loss: 0.091850, loss_s1: 0.116331, loss_fp: 0.002530, loss_freq: 0.022683
[15:38:12.689] iteration 20494: loss: 0.077087, loss_s1: 0.051925, loss_fp: 0.002997, loss_freq: 0.022877
[15:38:13.316] iteration 20495: loss: 0.074300, loss_s1: 0.068946, loss_fp: 0.001611, loss_freq: 0.034923
[15:38:13.939] iteration 20496: loss: 0.050207, loss_s1: 0.029826, loss_fp: 0.002624, loss_freq: 0.021181
[15:38:14.568] iteration 20497: loss: 0.045851, loss_s1: 0.034869, loss_fp: 0.003185, loss_freq: 0.009763
[15:38:15.188] iteration 20498: loss: 0.063746, loss_s1: 0.057183, loss_fp: 0.001564, loss_freq: 0.026715
[15:38:15.810] iteration 20499: loss: 0.042731, loss_s1: 0.025449, loss_fp: 0.000488, loss_freq: 0.014732
[15:38:16.431] iteration 20500: loss: 0.063421, loss_s1: 0.059314, loss_fp: 0.004529, loss_freq: 0.022070
[15:38:17.079] iteration 20501: loss: 0.044291, loss_s1: 0.021343, loss_fp: 0.002847, loss_freq: 0.016218
[15:38:17.718] iteration 20502: loss: 0.040704, loss_s1: 0.018175, loss_fp: 0.001983, loss_freq: 0.018826
[15:38:18.372] iteration 20503: loss: 0.030887, loss_s1: 0.024616, loss_fp: 0.000244, loss_freq: 0.007091
[15:38:19.001] iteration 20504: loss: 0.046074, loss_s1: 0.014041, loss_fp: 0.003115, loss_freq: 0.014428
[15:38:19.854] iteration 20505: loss: 0.045406, loss_s1: 0.018705, loss_fp: 0.001009, loss_freq: 0.009630
[15:38:20.550] iteration 20506: loss: 0.079654, loss_s1: 0.106943, loss_fp: 0.010822, loss_freq: 0.006429
[15:38:21.290] iteration 20507: loss: 0.059050, loss_s1: 0.053267, loss_fp: 0.002829, loss_freq: 0.007498
[15:38:22.002] iteration 20508: loss: 0.063935, loss_s1: 0.050044, loss_fp: 0.000663, loss_freq: 0.024117
[15:38:22.625] iteration 20509: loss: 0.044249, loss_s1: 0.027798, loss_fp: 0.004016, loss_freq: 0.016585
[15:38:23.301] iteration 20510: loss: 0.043608, loss_s1: 0.028597, loss_fp: 0.000880, loss_freq: 0.009557
[15:38:23.921] iteration 20511: loss: 0.062710, loss_s1: 0.061839, loss_fp: 0.001342, loss_freq: 0.015684
[15:38:24.543] iteration 20512: loss: 0.068925, loss_s1: 0.048263, loss_fp: 0.005947, loss_freq: 0.036554
[15:38:25.168] iteration 20513: loss: 0.051326, loss_s1: 0.026071, loss_fp: 0.004527, loss_freq: 0.019339
[15:38:25.826] iteration 20514: loss: 0.064256, loss_s1: 0.024396, loss_fp: 0.001822, loss_freq: 0.024511
[15:38:26.451] iteration 20515: loss: 0.048373, loss_s1: 0.018478, loss_fp: 0.002440, loss_freq: 0.028114
[15:38:27.078] iteration 20516: loss: 0.071481, loss_s1: 0.048510, loss_fp: 0.010892, loss_freq: 0.037993
[15:38:27.696] iteration 20517: loss: 0.057296, loss_s1: 0.057906, loss_fp: 0.003917, loss_freq: 0.021151
[15:38:28.325] iteration 20518: loss: 0.043740, loss_s1: 0.026309, loss_fp: 0.000911, loss_freq: 0.017934
[15:38:28.950] iteration 20519: loss: 0.069076, loss_s1: 0.030294, loss_fp: 0.001642, loss_freq: 0.016646
[15:38:29.566] iteration 20520: loss: 0.054292, loss_s1: 0.043297, loss_fp: 0.001595, loss_freq: 0.018410
[15:38:30.185] iteration 20521: loss: 0.050629, loss_s1: 0.039386, loss_fp: 0.001748, loss_freq: 0.013285
[15:38:30.808] iteration 20522: loss: 0.056837, loss_s1: 0.030771, loss_fp: 0.003494, loss_freq: 0.031339
[15:38:31.437] iteration 20523: loss: 0.075972, loss_s1: 0.044704, loss_fp: 0.002454, loss_freq: 0.062265
[15:38:32.065] iteration 20524: loss: 0.081102, loss_s1: 0.060165, loss_fp: 0.005559, loss_freq: 0.055791
[15:38:32.681] iteration 20525: loss: 0.054035, loss_s1: 0.054570, loss_fp: 0.000913, loss_freq: 0.011689
[15:38:33.322] iteration 20526: loss: 0.035813, loss_s1: 0.020346, loss_fp: 0.002194, loss_freq: 0.009837
[15:38:33.958] iteration 20527: loss: 0.036238, loss_s1: 0.023095, loss_fp: 0.000485, loss_freq: 0.006608
[15:38:34.580] iteration 20528: loss: 0.077563, loss_s1: 0.053057, loss_fp: 0.008739, loss_freq: 0.040970
[15:38:35.203] iteration 20529: loss: 0.105621, loss_s1: 0.080383, loss_fp: 0.018892, loss_freq: 0.038687
[15:38:35.825] iteration 20530: loss: 0.072316, loss_s1: 0.050298, loss_fp: 0.001675, loss_freq: 0.038991
[15:38:36.451] iteration 20531: loss: 0.049556, loss_s1: 0.025056, loss_fp: 0.003579, loss_freq: 0.019341
[15:38:37.081] iteration 20532: loss: 0.061354, loss_s1: 0.037853, loss_fp: 0.002346, loss_freq: 0.039244
[15:38:37.698] iteration 20533: loss: 0.040804, loss_s1: 0.031001, loss_fp: 0.002840, loss_freq: 0.012139
[15:38:38.322] iteration 20534: loss: 0.039112, loss_s1: 0.028729, loss_fp: 0.001402, loss_freq: 0.006312
[15:38:38.948] iteration 20535: loss: 0.051792, loss_s1: 0.027783, loss_fp: 0.007553, loss_freq: 0.029872
[15:38:39.571] iteration 20536: loss: 0.046431, loss_s1: 0.032454, loss_fp: 0.001252, loss_freq: 0.023063
[15:38:40.192] iteration 20537: loss: 0.036244, loss_s1: 0.006596, loss_fp: 0.000377, loss_freq: 0.016958
[15:38:40.823] iteration 20538: loss: 0.055968, loss_s1: 0.041715, loss_fp: 0.000986, loss_freq: 0.009466
[15:38:41.493] iteration 20539: loss: 0.093073, loss_s1: 0.074613, loss_fp: 0.003924, loss_freq: 0.036405
[15:38:42.123] iteration 20540: loss: 0.055285, loss_s1: 0.019173, loss_fp: 0.004283, loss_freq: 0.019607
[15:38:42.780] iteration 20541: loss: 0.041891, loss_s1: 0.027730, loss_fp: 0.000740, loss_freq: 0.015920
[15:38:43.447] iteration 20542: loss: 0.040223, loss_s1: 0.030035, loss_fp: 0.004395, loss_freq: 0.007814
[15:38:44.074] iteration 20543: loss: 0.065052, loss_s1: 0.069345, loss_fp: 0.005870, loss_freq: 0.021671
[15:38:44.701] iteration 20544: loss: 0.035009, loss_s1: 0.013728, loss_fp: 0.001506, loss_freq: 0.011132
[15:38:45.327] iteration 20545: loss: 0.042861, loss_s1: 0.034825, loss_fp: 0.001907, loss_freq: 0.008005
[15:38:45.998] iteration 20546: loss: 0.070822, loss_s1: 0.061091, loss_fp: 0.003062, loss_freq: 0.031922
[15:38:46.655] iteration 20547: loss: 0.066550, loss_s1: 0.042251, loss_fp: 0.001879, loss_freq: 0.048438
[15:38:47.271] iteration 20548: loss: 0.038663, loss_s1: 0.009618, loss_fp: 0.003418, loss_freq: 0.011894
[15:38:47.944] iteration 20549: loss: 0.095625, loss_s1: 0.041896, loss_fp: 0.001867, loss_freq: 0.027305
[15:38:48.593] iteration 20550: loss: 0.048904, loss_s1: 0.024532, loss_fp: 0.001691, loss_freq: 0.036884
[15:38:49.234] iteration 20551: loss: 0.063222, loss_s1: 0.021613, loss_fp: 0.002457, loss_freq: 0.043489
[15:38:49.878] iteration 20552: loss: 0.103909, loss_s1: 0.127034, loss_fp: 0.006831, loss_freq: 0.045112
[15:38:50.550] iteration 20553: loss: 0.035345, loss_s1: 0.019506, loss_fp: 0.001704, loss_freq: 0.007244
[15:38:51.166] iteration 20554: loss: 0.058678, loss_s1: 0.043968, loss_fp: 0.009361, loss_freq: 0.026281
[15:38:51.792] iteration 20555: loss: 0.044823, loss_s1: 0.018339, loss_fp: 0.000641, loss_freq: 0.026348
[15:38:52.421] iteration 20556: loss: 0.067588, loss_s1: 0.036363, loss_fp: 0.003485, loss_freq: 0.055058
[15:38:53.041] iteration 20557: loss: 0.038349, loss_s1: 0.014084, loss_fp: 0.002653, loss_freq: 0.022944
[15:38:53.665] iteration 20558: loss: 0.077878, loss_s1: 0.042693, loss_fp: 0.012777, loss_freq: 0.033981
[15:38:54.288] iteration 20559: loss: 0.097699, loss_s1: 0.045001, loss_fp: 0.017202, loss_freq: 0.097237
[15:38:54.907] iteration 20560: loss: 0.076778, loss_s1: 0.074308, loss_fp: 0.005177, loss_freq: 0.038214
[15:38:55.534] iteration 20561: loss: 0.051884, loss_s1: 0.027406, loss_fp: 0.007448, loss_freq: 0.036708
[15:38:56.156] iteration 20562: loss: 0.038614, loss_s1: 0.016182, loss_fp: 0.003347, loss_freq: 0.016607
[15:38:56.781] iteration 20563: loss: 0.064859, loss_s1: 0.040083, loss_fp: 0.007765, loss_freq: 0.033835
[15:38:57.408] iteration 20564: loss: 0.085911, loss_s1: 0.051219, loss_fp: 0.010717, loss_freq: 0.035974
[15:38:58.039] iteration 20565: loss: 0.047400, loss_s1: 0.025367, loss_fp: 0.003542, loss_freq: 0.024594
[15:38:58.659] iteration 20566: loss: 0.062339, loss_s1: 0.039558, loss_fp: 0.010699, loss_freq: 0.030862
[15:38:59.273] iteration 20567: loss: 0.073889, loss_s1: 0.077142, loss_fp: 0.002252, loss_freq: 0.033820
[15:38:59.895] iteration 20568: loss: 0.042210, loss_s1: 0.034120, loss_fp: 0.002434, loss_freq: 0.014503
[15:39:00.514] iteration 20569: loss: 0.079441, loss_s1: 0.092963, loss_fp: 0.001556, loss_freq: 0.020692
[15:39:01.188] iteration 20570: loss: 0.059500, loss_s1: 0.018174, loss_fp: 0.001857, loss_freq: 0.056098
[15:39:01.812] iteration 20571: loss: 0.059173, loss_s1: 0.022363, loss_fp: 0.001410, loss_freq: 0.015901
[15:39:02.429] iteration 20572: loss: 0.054908, loss_s1: 0.028416, loss_fp: 0.000831, loss_freq: 0.014203
[15:39:03.057] iteration 20573: loss: 0.057712, loss_s1: 0.046363, loss_fp: 0.004435, loss_freq: 0.035095
[15:39:03.670] iteration 20574: loss: 0.084162, loss_s1: 0.060763, loss_fp: 0.004318, loss_freq: 0.027716
[15:39:04.299] iteration 20575: loss: 0.059846, loss_s1: 0.049922, loss_fp: 0.002701, loss_freq: 0.013900
[15:39:04.924] iteration 20576: loss: 0.044634, loss_s1: 0.015030, loss_fp: 0.006675, loss_freq: 0.020438
[15:39:05.540] iteration 20577: loss: 0.069592, loss_s1: 0.063694, loss_fp: 0.002548, loss_freq: 0.022656
[15:39:06.157] iteration 20578: loss: 0.080677, loss_s1: 0.083164, loss_fp: 0.005432, loss_freq: 0.016860
[15:39:06.781] iteration 20579: loss: 0.041806, loss_s1: 0.033758, loss_fp: 0.002554, loss_freq: 0.008048
[15:39:07.403] iteration 20580: loss: 0.055793, loss_s1: 0.032911, loss_fp: 0.002118, loss_freq: 0.012745
[15:39:08.029] iteration 20581: loss: 0.085358, loss_s1: 0.072162, loss_fp: 0.003540, loss_freq: 0.048006
[15:39:08.653] iteration 20582: loss: 0.044416, loss_s1: 0.022679, loss_fp: 0.003992, loss_freq: 0.016576
[15:39:09.272] iteration 20583: loss: 0.071207, loss_s1: 0.045095, loss_fp: 0.004878, loss_freq: 0.035771
[15:39:09.894] iteration 20584: loss: 0.081670, loss_s1: 0.020513, loss_fp: 0.002872, loss_freq: 0.023331
[15:39:10.515] iteration 20585: loss: 0.080452, loss_s1: 0.058480, loss_fp: 0.005925, loss_freq: 0.048272
[15:39:11.146] iteration 20586: loss: 0.078540, loss_s1: 0.052375, loss_fp: 0.014617, loss_freq: 0.027674
[15:39:11.773] iteration 20587: loss: 0.032588, loss_s1: 0.012625, loss_fp: 0.000508, loss_freq: 0.011054
[15:39:12.399] iteration 20588: loss: 0.064616, loss_s1: 0.040393, loss_fp: 0.006553, loss_freq: 0.031025
[15:39:13.024] iteration 20589: loss: 0.068025, loss_s1: 0.037689, loss_fp: 0.002754, loss_freq: 0.033440
[15:39:13.647] iteration 20590: loss: 0.069149, loss_s1: 0.024707, loss_fp: 0.007037, loss_freq: 0.030620
[15:39:14.268] iteration 20591: loss: 0.096003, loss_s1: 0.069163, loss_fp: 0.001996, loss_freq: 0.067323
[15:39:14.880] iteration 20592: loss: 0.036873, loss_s1: 0.007165, loss_fp: 0.001432, loss_freq: 0.027464
[15:39:15.874] iteration 20593: loss: 0.035575, loss_s1: 0.006689, loss_fp: 0.000742, loss_freq: 0.023314
[15:39:16.529] iteration 20594: loss: 0.054385, loss_s1: 0.036470, loss_fp: 0.001779, loss_freq: 0.016117
[15:39:17.162] iteration 20595: loss: 0.072676, loss_s1: 0.072196, loss_fp: 0.005663, loss_freq: 0.029731
[15:39:17.802] iteration 20596: loss: 0.047942, loss_s1: 0.018414, loss_fp: 0.001972, loss_freq: 0.028749
[15:39:18.435] iteration 20597: loss: 0.084891, loss_s1: 0.085848, loss_fp: 0.006202, loss_freq: 0.045436
[15:39:19.058] iteration 20598: loss: 0.042427, loss_s1: 0.034901, loss_fp: 0.000596, loss_freq: 0.006424
[15:39:19.683] iteration 20599: loss: 0.038874, loss_s1: 0.023333, loss_fp: 0.005102, loss_freq: 0.016138
[15:39:20.317] iteration 20600: loss: 0.035584, loss_s1: 0.006911, loss_fp: 0.005739, loss_freq: 0.017696
[15:39:23.951] iteration 20600 : mean_dice : 0.783113
[15:39:24.607] iteration 20601: loss: 0.037814, loss_s1: 0.010268, loss_fp: 0.001670, loss_freq: 0.010361
[15:39:25.236] iteration 20602: loss: 0.037924, loss_s1: 0.005483, loss_fp: 0.000733, loss_freq: 0.007673
[15:39:25.855] iteration 20603: loss: 0.082598, loss_s1: 0.046923, loss_fp: 0.001685, loss_freq: 0.074267
[15:39:26.488] iteration 20604: loss: 0.039753, loss_s1: 0.014463, loss_fp: 0.002742, loss_freq: 0.017770
[15:39:27.122] iteration 20605: loss: 0.053419, loss_s1: 0.029447, loss_fp: 0.002076, loss_freq: 0.025483
[15:39:27.771] iteration 20606: loss: 0.033035, loss_s1: 0.016392, loss_fp: 0.001450, loss_freq: 0.009468
[15:39:28.424] iteration 20607: loss: 0.071762, loss_s1: 0.071163, loss_fp: 0.003013, loss_freq: 0.021923
[15:39:29.050] iteration 20608: loss: 0.061209, loss_s1: 0.017098, loss_fp: 0.005884, loss_freq: 0.034147
[15:39:29.687] iteration 20609: loss: 0.122771, loss_s1: 0.026013, loss_fp: 0.001884, loss_freq: 0.027952
[15:39:30.312] iteration 20610: loss: 0.046573, loss_s1: 0.031850, loss_fp: 0.007001, loss_freq: 0.013543
[15:39:30.931] iteration 20611: loss: 0.043824, loss_s1: 0.034573, loss_fp: 0.003077, loss_freq: 0.019184
[15:39:31.552] iteration 20612: loss: 0.035640, loss_s1: 0.020206, loss_fp: 0.002811, loss_freq: 0.011600
[15:39:32.228] iteration 20613: loss: 0.065015, loss_s1: 0.023997, loss_fp: 0.002714, loss_freq: 0.042522
[15:39:32.858] iteration 20614: loss: 0.062226, loss_s1: 0.058340, loss_fp: 0.002298, loss_freq: 0.022935
[15:39:33.487] iteration 20615: loss: 0.043744, loss_s1: 0.026738, loss_fp: 0.002463, loss_freq: 0.028762
[15:39:34.130] iteration 20616: loss: 0.046672, loss_s1: 0.030716, loss_fp: 0.001316, loss_freq: 0.014032
[15:39:34.764] iteration 20617: loss: 0.041210, loss_s1: 0.013582, loss_fp: 0.002723, loss_freq: 0.020422
[15:39:35.393] iteration 20618: loss: 0.080093, loss_s1: 0.086944, loss_fp: 0.004042, loss_freq: 0.026790
[15:39:36.011] iteration 20619: loss: 0.072252, loss_s1: 0.053584, loss_fp: 0.004281, loss_freq: 0.039244
[15:39:36.665] iteration 20620: loss: 0.054246, loss_s1: 0.063158, loss_fp: 0.003543, loss_freq: 0.004368
[15:39:37.334] iteration 20621: loss: 0.094248, loss_s1: 0.033375, loss_fp: 0.002699, loss_freq: 0.046927
[15:39:37.993] iteration 20622: loss: 0.075668, loss_s1: 0.033066, loss_fp: 0.005620, loss_freq: 0.017762
[15:39:38.621] iteration 20623: loss: 0.035329, loss_s1: 0.023230, loss_fp: 0.001785, loss_freq: 0.012941
[15:39:39.300] iteration 20624: loss: 0.078271, loss_s1: 0.044842, loss_fp: 0.003824, loss_freq: 0.034112
[15:39:39.956] iteration 20625: loss: 0.046661, loss_s1: 0.020289, loss_fp: 0.001528, loss_freq: 0.034759
[15:39:40.580] iteration 20626: loss: 0.072525, loss_s1: 0.067344, loss_fp: 0.003991, loss_freq: 0.038364
[15:39:41.207] iteration 20627: loss: 0.056811, loss_s1: 0.054362, loss_fp: 0.002772, loss_freq: 0.012142
[15:39:41.861] iteration 20628: loss: 0.046853, loss_s1: 0.025764, loss_fp: 0.001861, loss_freq: 0.021561
[15:39:42.483] iteration 20629: loss: 0.059678, loss_s1: 0.043259, loss_fp: 0.001156, loss_freq: 0.030513
[15:39:43.113] iteration 20630: loss: 0.055363, loss_s1: 0.043503, loss_fp: 0.004398, loss_freq: 0.027366
[15:39:43.735] iteration 20631: loss: 0.077240, loss_s1: 0.048590, loss_fp: 0.010147, loss_freq: 0.046483
[15:39:44.359] iteration 20632: loss: 0.035082, loss_s1: 0.016814, loss_fp: 0.012730, loss_freq: 0.014212
[15:39:44.988] iteration 20633: loss: 0.078153, loss_s1: 0.035544, loss_fp: 0.002961, loss_freq: 0.027683
[15:39:45.612] iteration 20634: loss: 0.035957, loss_s1: 0.026787, loss_fp: 0.001341, loss_freq: 0.009063
[15:39:46.236] iteration 20635: loss: 0.059029, loss_s1: 0.017179, loss_fp: 0.007882, loss_freq: 0.005766
[15:39:46.857] iteration 20636: loss: 0.062475, loss_s1: 0.040093, loss_fp: 0.005169, loss_freq: 0.037622
[15:39:47.476] iteration 20637: loss: 0.074391, loss_s1: 0.050080, loss_fp: 0.003376, loss_freq: 0.021760
[15:39:48.102] iteration 20638: loss: 0.067733, loss_s1: 0.076745, loss_fp: 0.000683, loss_freq: 0.022769
[15:39:48.725] iteration 20639: loss: 0.047233, loss_s1: 0.034697, loss_fp: 0.003986, loss_freq: 0.016494
[15:39:49.344] iteration 20640: loss: 0.053182, loss_s1: 0.050391, loss_fp: 0.003971, loss_freq: 0.020549
[15:39:49.970] iteration 20641: loss: 0.034990, loss_s1: 0.011597, loss_fp: 0.005641, loss_freq: 0.021398
[15:39:50.595] iteration 20642: loss: 0.064290, loss_s1: 0.058282, loss_fp: 0.003228, loss_freq: 0.024217
[15:39:51.220] iteration 20643: loss: 0.035384, loss_s1: 0.023120, loss_fp: 0.001552, loss_freq: 0.005079
[15:39:51.839] iteration 20644: loss: 0.057886, loss_s1: 0.019772, loss_fp: 0.005913, loss_freq: 0.029298
[15:39:52.455] iteration 20645: loss: 0.038037, loss_s1: 0.022622, loss_fp: 0.000593, loss_freq: 0.008328
[15:39:53.076] iteration 20646: loss: 0.041321, loss_s1: 0.032877, loss_fp: 0.001596, loss_freq: 0.017090
[15:39:53.702] iteration 20647: loss: 0.028719, loss_s1: 0.018157, loss_fp: 0.003737, loss_freq: 0.005695
[15:39:54.370] iteration 20648: loss: 0.048711, loss_s1: 0.022010, loss_fp: 0.001235, loss_freq: 0.013667
[15:39:54.995] iteration 20649: loss: 0.060052, loss_s1: 0.066047, loss_fp: 0.002313, loss_freq: 0.010696
[15:39:55.618] iteration 20650: loss: 0.045088, loss_s1: 0.022615, loss_fp: 0.007679, loss_freq: 0.008612
[15:39:56.238] iteration 20651: loss: 0.071436, loss_s1: 0.015167, loss_fp: 0.000611, loss_freq: 0.057661
[15:39:56.869] iteration 20652: loss: 0.073903, loss_s1: 0.058863, loss_fp: 0.003619, loss_freq: 0.028698
[15:39:57.493] iteration 20653: loss: 0.051118, loss_s1: 0.026429, loss_fp: 0.001139, loss_freq: 0.030394
[15:39:58.114] iteration 20654: loss: 0.037932, loss_s1: 0.024870, loss_fp: 0.001528, loss_freq: 0.006608
[15:39:58.740] iteration 20655: loss: 0.061600, loss_s1: 0.051773, loss_fp: 0.004709, loss_freq: 0.020918
[15:39:59.365] iteration 20656: loss: 0.048899, loss_s1: 0.012061, loss_fp: 0.002408, loss_freq: 0.020644
[15:39:59.989] iteration 20657: loss: 0.076993, loss_s1: 0.057323, loss_fp: 0.003491, loss_freq: 0.029987
[15:40:00.610] iteration 20658: loss: 0.050194, loss_s1: 0.038988, loss_fp: 0.000484, loss_freq: 0.015490
[15:40:01.231] iteration 20659: loss: 0.090049, loss_s1: 0.059850, loss_fp: 0.009134, loss_freq: 0.052904
[15:40:01.866] iteration 20660: loss: 0.052520, loss_s1: 0.047697, loss_fp: 0.001500, loss_freq: 0.021223
[15:40:02.496] iteration 20661: loss: 0.055488, loss_s1: 0.045725, loss_fp: 0.001190, loss_freq: 0.021980
[15:40:03.127] iteration 20662: loss: 0.070410, loss_s1: 0.056872, loss_fp: 0.004641, loss_freq: 0.001292
[15:40:03.761] iteration 20663: loss: 0.038160, loss_s1: 0.024207, loss_fp: 0.001869, loss_freq: 0.013121
[15:40:04.430] iteration 20664: loss: 0.047719, loss_s1: 0.032940, loss_fp: 0.000812, loss_freq: 0.015376
[15:40:05.069] iteration 20665: loss: 0.069000, loss_s1: 0.010805, loss_fp: 0.010709, loss_freq: 0.076336
[15:40:05.710] iteration 20666: loss: 0.061011, loss_s1: 0.020825, loss_fp: 0.003685, loss_freq: 0.058065
[15:40:06.352] iteration 20667: loss: 0.065343, loss_s1: 0.050658, loss_fp: 0.009109, loss_freq: 0.045598
[15:40:07.013] iteration 20668: loss: 0.063286, loss_s1: 0.041275, loss_fp: 0.002743, loss_freq: 0.030268
[15:40:07.649] iteration 20669: loss: 0.065673, loss_s1: 0.067265, loss_fp: 0.004480, loss_freq: 0.030580
[15:40:08.282] iteration 20670: loss: 0.045356, loss_s1: 0.025922, loss_fp: 0.004085, loss_freq: 0.011616
[15:40:08.892] iteration 20671: loss: 0.089421, loss_s1: 0.078944, loss_fp: 0.041827, loss_freq: 0.024880
[15:40:09.550] iteration 20672: loss: 0.086426, loss_s1: 0.076728, loss_fp: 0.008796, loss_freq: 0.010157
[15:40:10.238] iteration 20673: loss: 0.053045, loss_s1: 0.022500, loss_fp: 0.003839, loss_freq: 0.029946
[15:40:10.888] iteration 20674: loss: 0.047377, loss_s1: 0.028365, loss_fp: 0.012291, loss_freq: 0.013055
[15:40:11.531] iteration 20675: loss: 0.042523, loss_s1: 0.032964, loss_fp: 0.001779, loss_freq: 0.010976
[15:40:12.185] iteration 20676: loss: 0.034847, loss_s1: 0.023700, loss_fp: 0.000737, loss_freq: 0.014111
[15:40:12.809] iteration 20677: loss: 0.064844, loss_s1: 0.038214, loss_fp: 0.012563, loss_freq: 0.023755
[15:40:13.437] iteration 20678: loss: 0.068518, loss_s1: 0.043646, loss_fp: 0.003940, loss_freq: 0.041699
[15:40:14.062] iteration 20679: loss: 0.040065, loss_s1: 0.030737, loss_fp: 0.002872, loss_freq: 0.006313
[15:40:14.685] iteration 20680: loss: 0.034147, loss_s1: 0.013711, loss_fp: 0.002208, loss_freq: 0.013764
[15:40:15.308] iteration 20681: loss: 0.035344, loss_s1: 0.018218, loss_fp: 0.007841, loss_freq: 0.010143
[15:40:15.930] iteration 20682: loss: 0.060300, loss_s1: 0.048058, loss_fp: 0.002437, loss_freq: 0.039436
[15:40:16.577] iteration 20683: loss: 0.060464, loss_s1: 0.030785, loss_fp: 0.000960, loss_freq: 0.010615
[15:40:17.230] iteration 20684: loss: 0.041080, loss_s1: 0.029963, loss_fp: 0.001669, loss_freq: 0.012483
[15:40:17.864] iteration 20685: loss: 0.063360, loss_s1: 0.068177, loss_fp: 0.004101, loss_freq: 0.010279
[15:40:18.492] iteration 20686: loss: 0.047111, loss_s1: 0.034772, loss_fp: 0.002039, loss_freq: 0.015671
[15:40:19.135] iteration 20687: loss: 0.038144, loss_s1: 0.017576, loss_fp: 0.001578, loss_freq: 0.018118
[15:40:19.770] iteration 20688: loss: 0.034759, loss_s1: 0.014124, loss_fp: 0.008680, loss_freq: 0.012272
[15:40:20.393] iteration 20689: loss: 0.095527, loss_s1: 0.087485, loss_fp: 0.002841, loss_freq: 0.060513
[15:40:21.020] iteration 20690: loss: 0.041918, loss_s1: 0.016334, loss_fp: 0.002442, loss_freq: 0.025000
[15:40:21.646] iteration 20691: loss: 0.079116, loss_s1: 0.064714, loss_fp: 0.001650, loss_freq: 0.018941
[15:40:22.277] iteration 20692: loss: 0.053768, loss_s1: 0.040141, loss_fp: 0.002172, loss_freq: 0.018663
[15:40:22.905] iteration 20693: loss: 0.062106, loss_s1: 0.036903, loss_fp: 0.004955, loss_freq: 0.040075
[15:40:23.541] iteration 20694: loss: 0.066022, loss_s1: 0.036749, loss_fp: 0.002307, loss_freq: 0.042967
[15:40:24.233] iteration 20695: loss: 0.064428, loss_s1: 0.040898, loss_fp: 0.008317, loss_freq: 0.044754
[15:40:24.893] iteration 20696: loss: 0.038123, loss_s1: 0.031651, loss_fp: 0.003010, loss_freq: 0.005262
[15:40:25.725] iteration 20697: loss: 0.059335, loss_s1: 0.038019, loss_fp: 0.010665, loss_freq: 0.023045
[15:40:26.473] iteration 20698: loss: 0.039535, loss_s1: 0.011283, loss_fp: 0.003467, loss_freq: 0.018090
[15:40:27.161] iteration 20699: loss: 0.063518, loss_s1: 0.019739, loss_fp: 0.005551, loss_freq: 0.059711
[15:40:27.808] iteration 20700: loss: 0.046946, loss_s1: 0.024690, loss_fp: 0.002626, loss_freq: 0.037554
[15:40:28.434] iteration 20701: loss: 0.056164, loss_s1: 0.023847, loss_fp: 0.001030, loss_freq: 0.031916
[15:40:29.057] iteration 20702: loss: 0.079653, loss_s1: 0.058657, loss_fp: 0.019591, loss_freq: 0.029712
[15:40:29.743] iteration 20703: loss: 0.084423, loss_s1: 0.060042, loss_fp: 0.002161, loss_freq: 0.024140
[15:40:30.394] iteration 20704: loss: 0.044683, loss_s1: 0.034764, loss_fp: 0.003048, loss_freq: 0.023949
[15:40:31.024] iteration 20705: loss: 0.060726, loss_s1: 0.050594, loss_fp: 0.001810, loss_freq: 0.009857
[15:40:31.650] iteration 20706: loss: 0.074290, loss_s1: 0.059018, loss_fp: 0.006066, loss_freq: 0.037465
[15:40:32.275] iteration 20707: loss: 0.079340, loss_s1: 0.069526, loss_fp: 0.001941, loss_freq: 0.008148
[15:40:32.914] iteration 20708: loss: 0.052762, loss_s1: 0.045497, loss_fp: 0.002898, loss_freq: 0.019334
[15:40:33.562] iteration 20709: loss: 0.046107, loss_s1: 0.025044, loss_fp: 0.007564, loss_freq: 0.016723
[15:40:34.203] iteration 20710: loss: 0.052544, loss_s1: 0.034766, loss_fp: 0.002192, loss_freq: 0.021735
[15:40:34.841] iteration 20711: loss: 0.041241, loss_s1: 0.028017, loss_fp: 0.006551, loss_freq: 0.017094
[15:40:35.479] iteration 20712: loss: 0.050120, loss_s1: 0.026859, loss_fp: 0.002887, loss_freq: 0.026331
[15:40:36.105] iteration 20713: loss: 0.094335, loss_s1: 0.057482, loss_fp: 0.001571, loss_freq: 0.089128
[15:40:36.736] iteration 20714: loss: 0.077658, loss_s1: 0.090120, loss_fp: 0.002364, loss_freq: 0.020787
[15:40:37.363] iteration 20715: loss: 0.032681, loss_s1: 0.021757, loss_fp: 0.001557, loss_freq: 0.006899
[15:40:37.979] iteration 20716: loss: 0.039843, loss_s1: 0.027244, loss_fp: 0.002535, loss_freq: 0.021143
[15:40:38.607] iteration 20717: loss: 0.072044, loss_s1: 0.072740, loss_fp: 0.003197, loss_freq: 0.034634
[15:40:39.261] iteration 20718: loss: 0.061595, loss_s1: 0.029456, loss_fp: 0.001603, loss_freq: 0.004933
[15:40:39.892] iteration 20719: loss: 0.055101, loss_s1: 0.049365, loss_fp: 0.004013, loss_freq: 0.024372
[15:40:40.537] iteration 20720: loss: 0.064016, loss_s1: 0.055468, loss_fp: 0.001128, loss_freq: 0.028492
[15:40:41.179] iteration 20721: loss: 0.052759, loss_s1: 0.037818, loss_fp: 0.009106, loss_freq: 0.012371
[15:40:41.814] iteration 20722: loss: 0.039944, loss_s1: 0.027876, loss_fp: 0.006590, loss_freq: 0.008616
[15:40:42.445] iteration 20723: loss: 0.051554, loss_s1: 0.034478, loss_fp: 0.003010, loss_freq: 0.025030
[15:40:43.066] iteration 20724: loss: 0.078324, loss_s1: 0.053681, loss_fp: 0.008005, loss_freq: 0.044903
[15:40:43.691] iteration 20725: loss: 0.068660, loss_s1: 0.063358, loss_fp: 0.003685, loss_freq: 0.027762
[15:40:44.311] iteration 20726: loss: 0.065682, loss_s1: 0.034823, loss_fp: 0.002750, loss_freq: 0.040817
[15:40:44.941] iteration 20727: loss: 0.043490, loss_s1: 0.027707, loss_fp: 0.000538, loss_freq: 0.015806
[15:40:45.570] iteration 20728: loss: 0.057928, loss_s1: 0.057437, loss_fp: 0.002608, loss_freq: 0.018085
[15:40:46.199] iteration 20729: loss: 0.076115, loss_s1: 0.080223, loss_fp: 0.001848, loss_freq: 0.021849
[15:40:46.823] iteration 20730: loss: 0.030654, loss_s1: 0.019086, loss_fp: 0.002295, loss_freq: 0.007113
[15:40:47.492] iteration 20731: loss: 0.056906, loss_s1: 0.046802, loss_fp: 0.004064, loss_freq: 0.021838
[15:40:48.123] iteration 20732: loss: 0.050980, loss_s1: 0.026668, loss_fp: 0.004505, loss_freq: 0.016596
[15:40:48.751] iteration 20733: loss: 0.049187, loss_s1: 0.026417, loss_fp: 0.001270, loss_freq: 0.029431
[15:40:49.373] iteration 20734: loss: 0.095028, loss_s1: 0.080733, loss_fp: 0.010816, loss_freq: 0.057601
[15:40:49.999] iteration 20735: loss: 0.032432, loss_s1: 0.022398, loss_fp: 0.002320, loss_freq: 0.008093
[15:40:50.953] iteration 20736: loss: 0.069334, loss_s1: 0.083376, loss_fp: 0.001523, loss_freq: 0.009167
[15:40:51.583] iteration 20737: loss: 0.087763, loss_s1: 0.108635, loss_fp: 0.003493, loss_freq: 0.020487
[15:40:52.218] iteration 20738: loss: 0.051282, loss_s1: 0.040218, loss_fp: 0.000851, loss_freq: 0.030168
[15:40:52.865] iteration 20739: loss: 0.045659, loss_s1: 0.013439, loss_fp: 0.007627, loss_freq: 0.013221
[15:40:53.522] iteration 20740: loss: 0.059294, loss_s1: 0.042265, loss_fp: 0.002552, loss_freq: 0.040903
[15:40:54.237] iteration 20741: loss: 0.072712, loss_s1: 0.014971, loss_fp: 0.008152, loss_freq: 0.003510
[15:40:54.859] iteration 20742: loss: 0.039675, loss_s1: 0.018689, loss_fp: 0.004722, loss_freq: 0.028327
[15:40:55.478] iteration 20743: loss: 0.067610, loss_s1: 0.048575, loss_fp: 0.000892, loss_freq: 0.037059
[15:40:56.100] iteration 20744: loss: 0.063290, loss_s1: 0.045024, loss_fp: 0.005030, loss_freq: 0.023053
[15:40:56.712] iteration 20745: loss: 0.050401, loss_s1: 0.027897, loss_fp: 0.002442, loss_freq: 0.002701
[15:40:57.334] iteration 20746: loss: 0.059081, loss_s1: 0.035708, loss_fp: 0.002615, loss_freq: 0.029236
[15:40:57.957] iteration 20747: loss: 0.053427, loss_s1: 0.037854, loss_fp: 0.000909, loss_freq: 0.016982
[15:40:58.655] iteration 20748: loss: 0.058744, loss_s1: 0.031217, loss_fp: 0.000912, loss_freq: 0.052750
[15:40:59.276] iteration 20749: loss: 0.044834, loss_s1: 0.040493, loss_fp: 0.004682, loss_freq: 0.011214
[15:40:59.898] iteration 20750: loss: 0.076898, loss_s1: 0.091264, loss_fp: 0.003076, loss_freq: 0.018240
[15:41:00.516] iteration 20751: loss: 0.044555, loss_s1: 0.026955, loss_fp: 0.001827, loss_freq: 0.011703
[15:41:01.139] iteration 20752: loss: 0.036140, loss_s1: 0.015701, loss_fp: 0.004877, loss_freq: 0.012144
[15:41:01.761] iteration 20753: loss: 0.051211, loss_s1: 0.038556, loss_fp: 0.001058, loss_freq: 0.016554
[15:41:02.377] iteration 20754: loss: 0.064169, loss_s1: 0.065972, loss_fp: 0.004482, loss_freq: 0.027991
[15:41:02.995] iteration 20755: loss: 0.024917, loss_s1: 0.004696, loss_fp: 0.002936, loss_freq: 0.006918
[15:41:03.616] iteration 20756: loss: 0.128185, loss_s1: 0.064835, loss_fp: 0.001441, loss_freq: 0.079778
[15:41:04.233] iteration 20757: loss: 0.049021, loss_s1: 0.032280, loss_fp: 0.001640, loss_freq: 0.023503
[15:41:04.851] iteration 20758: loss: 0.055363, loss_s1: 0.032169, loss_fp: 0.002838, loss_freq: 0.035755
[15:41:05.469] iteration 20759: loss: 0.046436, loss_s1: 0.030030, loss_fp: 0.005282, loss_freq: 0.004137
[15:41:06.085] iteration 20760: loss: 0.051917, loss_s1: 0.043104, loss_fp: 0.010042, loss_freq: 0.014835
[15:41:06.718] iteration 20761: loss: 0.075823, loss_s1: 0.058271, loss_fp: 0.007450, loss_freq: 0.030641
[15:41:07.338] iteration 20762: loss: 0.065152, loss_s1: 0.050506, loss_fp: 0.012620, loss_freq: 0.027531
[15:41:07.963] iteration 20763: loss: 0.045639, loss_s1: 0.030793, loss_fp: 0.003797, loss_freq: 0.014613
[15:41:08.586] iteration 20764: loss: 0.075972, loss_s1: 0.084863, loss_fp: 0.000977, loss_freq: 0.023746
[15:41:09.205] iteration 20765: loss: 0.052602, loss_s1: 0.031865, loss_fp: 0.002230, loss_freq: 0.008858
[15:41:09.825] iteration 20766: loss: 0.035746, loss_s1: 0.024983, loss_fp: 0.004436, loss_freq: 0.004600
[15:41:10.462] iteration 20767: loss: 0.059183, loss_s1: 0.039092, loss_fp: 0.002421, loss_freq: 0.024098
[15:41:11.071] iteration 20768: loss: 0.083293, loss_s1: 0.085854, loss_fp: 0.007713, loss_freq: 0.041653
[15:41:11.689] iteration 20769: loss: 0.067310, loss_s1: 0.061180, loss_fp: 0.006340, loss_freq: 0.027835
[15:41:12.312] iteration 20770: loss: 0.059288, loss_s1: 0.035210, loss_fp: 0.005481, loss_freq: 0.037029
[15:41:12.929] iteration 20771: loss: 0.107662, loss_s1: 0.079459, loss_fp: 0.003380, loss_freq: 0.030661
[15:41:13.571] iteration 20772: loss: 0.049402, loss_s1: 0.017203, loss_fp: 0.003759, loss_freq: 0.030541
[15:41:14.206] iteration 20773: loss: 0.084139, loss_s1: 0.094439, loss_fp: 0.008985, loss_freq: 0.028216
[15:41:14.865] iteration 20774: loss: 0.092250, loss_s1: 0.060967, loss_fp: 0.002549, loss_freq: 0.043837
[15:41:15.505] iteration 20775: loss: 0.066922, loss_s1: 0.045237, loss_fp: 0.009324, loss_freq: 0.023104
[15:41:16.147] iteration 20776: loss: 0.118673, loss_s1: 0.073060, loss_fp: 0.011927, loss_freq: 0.025769
[15:41:16.791] iteration 20777: loss: 0.054054, loss_s1: 0.040210, loss_fp: 0.000907, loss_freq: 0.035419
[15:41:17.429] iteration 20778: loss: 0.062601, loss_s1: 0.048646, loss_fp: 0.004511, loss_freq: 0.025282
[15:41:18.053] iteration 20779: loss: 0.059486, loss_s1: 0.060228, loss_fp: 0.004027, loss_freq: 0.018004
[15:41:18.735] iteration 20780: loss: 0.055396, loss_s1: 0.016165, loss_fp: 0.002822, loss_freq: 0.020610
[15:41:19.362] iteration 20781: loss: 0.056955, loss_s1: 0.023902, loss_fp: 0.004741, loss_freq: 0.023395
[15:41:20.046] iteration 20782: loss: 0.042102, loss_s1: 0.017984, loss_fp: 0.002880, loss_freq: 0.018159
[15:41:20.668] iteration 20783: loss: 0.046362, loss_s1: 0.034293, loss_fp: 0.002353, loss_freq: 0.009387
[15:41:21.290] iteration 20784: loss: 0.050365, loss_s1: 0.038106, loss_fp: 0.000753, loss_freq: 0.020139
[15:41:21.921] iteration 20785: loss: 0.037137, loss_s1: 0.018861, loss_fp: 0.002241, loss_freq: 0.013727
[15:41:22.547] iteration 20786: loss: 0.056041, loss_s1: 0.026176, loss_fp: 0.002603, loss_freq: 0.036168
[15:41:23.258] iteration 20787: loss: 0.053872, loss_s1: 0.036939, loss_fp: 0.000979, loss_freq: 0.028353
[15:41:23.891] iteration 20788: loss: 0.035662, loss_s1: 0.025831, loss_fp: 0.000503, loss_freq: 0.008559
[15:41:24.564] iteration 20789: loss: 0.046247, loss_s1: 0.034001, loss_fp: 0.003262, loss_freq: 0.009892
[15:41:25.183] iteration 20790: loss: 0.090847, loss_s1: 0.106615, loss_fp: 0.000914, loss_freq: 0.031548
[15:41:25.809] iteration 20791: loss: 0.046833, loss_s1: 0.020232, loss_fp: 0.000330, loss_freq: 0.018772
[15:41:26.435] iteration 20792: loss: 0.036765, loss_s1: 0.023176, loss_fp: 0.003262, loss_freq: 0.017073
[15:41:27.086] iteration 20793: loss: 0.066379, loss_s1: 0.056861, loss_fp: 0.002738, loss_freq: 0.019345
[15:41:27.714] iteration 20794: loss: 0.051646, loss_s1: 0.028646, loss_fp: 0.000916, loss_freq: 0.037159
[15:41:28.332] iteration 20795: loss: 0.043415, loss_s1: 0.018063, loss_fp: 0.000752, loss_freq: 0.028271
[15:41:28.950] iteration 20796: loss: 0.069215, loss_s1: 0.026881, loss_fp: 0.001003, loss_freq: 0.011874
[15:41:29.559] iteration 20797: loss: 0.057062, loss_s1: 0.034186, loss_fp: 0.002752, loss_freq: 0.009696
[15:41:30.189] iteration 20798: loss: 0.087152, loss_s1: 0.059262, loss_fp: 0.003056, loss_freq: 0.059847
[15:41:30.839] iteration 20799: loss: 0.051497, loss_s1: 0.023581, loss_fp: 0.000645, loss_freq: 0.022775
[15:41:31.459] iteration 20800: loss: 0.055836, loss_s1: 0.049792, loss_fp: 0.003359, loss_freq: 0.013519
[15:41:34.779] iteration 20800 : mean_dice : 0.779949
[15:41:35.457] iteration 20801: loss: 0.038380, loss_s1: 0.017375, loss_fp: 0.006411, loss_freq: 0.018688
[15:41:36.094] iteration 20802: loss: 0.087460, loss_s1: 0.063644, loss_fp: 0.005688, loss_freq: 0.062191
[15:41:36.734] iteration 20803: loss: 0.055682, loss_s1: 0.044082, loss_fp: 0.004115, loss_freq: 0.030642
[15:41:37.374] iteration 20804: loss: 0.043961, loss_s1: 0.028149, loss_fp: 0.001811, loss_freq: 0.018723
[15:41:38.003] iteration 20805: loss: 0.052867, loss_s1: 0.008574, loss_fp: 0.007122, loss_freq: 0.028194
[15:41:38.628] iteration 20806: loss: 0.040071, loss_s1: 0.015775, loss_fp: 0.002901, loss_freq: 0.020682
[15:41:39.252] iteration 20807: loss: 0.065696, loss_s1: 0.025150, loss_fp: 0.004166, loss_freq: 0.052303
[15:41:39.894] iteration 20808: loss: 0.049696, loss_s1: 0.024953, loss_fp: 0.009192, loss_freq: 0.027496
[15:41:40.588] iteration 20809: loss: 0.077268, loss_s1: 0.046846, loss_fp: 0.012203, loss_freq: 0.041356
[15:41:41.212] iteration 20810: loss: 0.052042, loss_s1: 0.040643, loss_fp: 0.002746, loss_freq: 0.030335
[15:41:41.838] iteration 20811: loss: 0.051749, loss_s1: 0.044244, loss_fp: 0.003505, loss_freq: 0.009108
[15:41:42.465] iteration 20812: loss: 0.051719, loss_s1: 0.045001, loss_fp: 0.007335, loss_freq: 0.019700
[15:41:43.085] iteration 20813: loss: 0.037340, loss_s1: 0.022225, loss_fp: 0.001271, loss_freq: 0.006645
[15:41:43.712] iteration 20814: loss: 0.085279, loss_s1: 0.086654, loss_fp: 0.009214, loss_freq: 0.033103
[15:41:44.331] iteration 20815: loss: 0.070407, loss_s1: 0.054156, loss_fp: 0.012456, loss_freq: 0.014551
[15:41:44.948] iteration 20816: loss: 0.055959, loss_s1: 0.009836, loss_fp: 0.011321, loss_freq: 0.032011
[15:41:45.558] iteration 20817: loss: 0.038037, loss_s1: 0.015202, loss_fp: 0.002021, loss_freq: 0.010190
[15:41:46.216] iteration 20818: loss: 0.045845, loss_s1: 0.021984, loss_fp: 0.003051, loss_freq: 0.019384
[15:41:46.838] iteration 20819: loss: 0.036160, loss_s1: 0.024580, loss_fp: 0.001649, loss_freq: 0.012893
[15:41:47.459] iteration 20820: loss: 0.073641, loss_s1: 0.059475, loss_fp: 0.004449, loss_freq: 0.031845
[15:41:48.073] iteration 20821: loss: 0.062696, loss_s1: 0.041355, loss_fp: 0.006006, loss_freq: 0.031299
[15:41:48.692] iteration 20822: loss: 0.072203, loss_s1: 0.054039, loss_fp: 0.004048, loss_freq: 0.029748
[15:41:49.311] iteration 20823: loss: 0.042188, loss_s1: 0.016951, loss_fp: 0.001829, loss_freq: 0.029979
[15:41:49.933] iteration 20824: loss: 0.042576, loss_s1: 0.027882, loss_fp: 0.009384, loss_freq: 0.018691
[15:41:50.545] iteration 20825: loss: 0.051064, loss_s1: 0.052819, loss_fp: 0.004902, loss_freq: 0.014260
[15:41:51.172] iteration 20826: loss: 0.054590, loss_s1: 0.026343, loss_fp: 0.001780, loss_freq: 0.021611
[15:41:51.789] iteration 20827: loss: 0.076435, loss_s1: 0.076764, loss_fp: 0.005447, loss_freq: 0.029035
[15:41:52.409] iteration 20828: loss: 0.053086, loss_s1: 0.040697, loss_fp: 0.009813, loss_freq: 0.005512
[15:41:53.088] iteration 20829: loss: 0.042182, loss_s1: 0.024065, loss_fp: 0.000802, loss_freq: 0.019395
[15:41:53.731] iteration 20830: loss: 0.035763, loss_s1: 0.008981, loss_fp: 0.001692, loss_freq: 0.005091
[15:41:54.412] iteration 20831: loss: 0.032164, loss_s1: 0.001989, loss_fp: 0.001289, loss_freq: 0.003651
[15:41:55.028] iteration 20832: loss: 0.079158, loss_s1: 0.070950, loss_fp: 0.005933, loss_freq: 0.040002
[15:41:55.647] iteration 20833: loss: 0.041437, loss_s1: 0.030005, loss_fp: 0.002610, loss_freq: 0.012670
[15:41:56.259] iteration 20834: loss: 0.055987, loss_s1: 0.042620, loss_fp: 0.001151, loss_freq: 0.020049
[15:41:56.876] iteration 20835: loss: 0.076365, loss_s1: 0.033371, loss_fp: 0.001916, loss_freq: 0.061864
[15:41:57.491] iteration 20836: loss: 0.059857, loss_s1: 0.039570, loss_fp: 0.010046, loss_freq: 0.035489
[15:41:58.109] iteration 20837: loss: 0.069050, loss_s1: 0.027350, loss_fp: 0.005608, loss_freq: 0.035557
[15:41:58.727] iteration 20838: loss: 0.070996, loss_s1: 0.049478, loss_fp: 0.005838, loss_freq: 0.056148
[15:41:59.344] iteration 20839: loss: 0.039689, loss_s1: 0.027661, loss_fp: 0.003614, loss_freq: 0.004509
[15:41:59.968] iteration 20840: loss: 0.051741, loss_s1: 0.047846, loss_fp: 0.001545, loss_freq: 0.008169
[15:42:00.589] iteration 20841: loss: 0.047298, loss_s1: 0.015993, loss_fp: 0.001555, loss_freq: 0.027325
[15:42:01.275] iteration 20842: loss: 0.078946, loss_s1: 0.063396, loss_fp: 0.009789, loss_freq: 0.044359
[15:42:01.907] iteration 20843: loss: 0.041438, loss_s1: 0.031908, loss_fp: 0.001935, loss_freq: 0.016827
[15:42:02.527] iteration 20844: loss: 0.067451, loss_s1: 0.029277, loss_fp: 0.002329, loss_freq: 0.004992
[15:42:03.151] iteration 20845: loss: 0.097716, loss_s1: 0.070297, loss_fp: 0.007045, loss_freq: 0.084845
[15:42:03.773] iteration 20846: loss: 0.046567, loss_s1: 0.017864, loss_fp: 0.003712, loss_freq: 0.013649
[15:42:04.398] iteration 20847: loss: 0.057901, loss_s1: 0.048321, loss_fp: 0.002368, loss_freq: 0.034618
[15:42:05.021] iteration 20848: loss: 0.048532, loss_s1: 0.031654, loss_fp: 0.001437, loss_freq: 0.012920
[15:42:05.648] iteration 20849: loss: 0.071912, loss_s1: 0.061924, loss_fp: 0.008476, loss_freq: 0.033467
[15:42:06.274] iteration 20850: loss: 0.079299, loss_s1: 0.051096, loss_fp: 0.013159, loss_freq: 0.029089
[15:42:06.892] iteration 20851: loss: 0.034409, loss_s1: 0.024226, loss_fp: 0.001303, loss_freq: 0.003737
[15:42:07.512] iteration 20852: loss: 0.080524, loss_s1: 0.045998, loss_fp: 0.010942, loss_freq: 0.044060
[15:42:08.137] iteration 20853: loss: 0.081916, loss_s1: 0.083885, loss_fp: 0.001701, loss_freq: 0.018959
[15:42:08.762] iteration 20854: loss: 0.047173, loss_s1: 0.047793, loss_fp: 0.001176, loss_freq: 0.014032
[15:42:09.384] iteration 20855: loss: 0.051355, loss_s1: 0.026995, loss_fp: 0.004114, loss_freq: 0.032036
[15:42:10.002] iteration 20856: loss: 0.049108, loss_s1: 0.025234, loss_fp: 0.003837, loss_freq: 0.022734
[15:42:10.624] iteration 20857: loss: 0.046285, loss_s1: 0.024804, loss_fp: 0.000849, loss_freq: 0.029864
[15:42:11.237] iteration 20858: loss: 0.027411, loss_s1: 0.010721, loss_fp: 0.001075, loss_freq: 0.011767
[15:42:11.888] iteration 20859: loss: 0.074448, loss_s1: 0.076918, loss_fp: 0.002277, loss_freq: 0.026305
[15:42:12.538] iteration 20860: loss: 0.063510, loss_s1: 0.058704, loss_fp: 0.003674, loss_freq: 0.031889
[15:42:13.230] iteration 20861: loss: 0.055000, loss_s1: 0.035854, loss_fp: 0.000606, loss_freq: 0.009404
[15:42:13.936] iteration 20862: loss: 0.051073, loss_s1: 0.033196, loss_fp: 0.004622, loss_freq: 0.034435
[15:42:14.582] iteration 20863: loss: 0.044254, loss_s1: 0.036866, loss_fp: 0.002650, loss_freq: 0.018150
[15:42:15.205] iteration 20864: loss: 0.063939, loss_s1: 0.043033, loss_fp: 0.010268, loss_freq: 0.015016
[15:42:15.818] iteration 20865: loss: 0.056354, loss_s1: 0.039615, loss_fp: 0.000697, loss_freq: 0.026810
[15:42:16.435] iteration 20866: loss: 0.080995, loss_s1: 0.040868, loss_fp: 0.004967, loss_freq: 0.037802
[15:42:17.064] iteration 20867: loss: 0.092195, loss_s1: 0.099262, loss_fp: 0.004610, loss_freq: 0.034653
[15:42:17.691] iteration 20868: loss: 0.076279, loss_s1: 0.048191, loss_fp: 0.010081, loss_freq: 0.053305
[15:42:18.315] iteration 20869: loss: 0.072878, loss_s1: 0.036511, loss_fp: 0.009707, loss_freq: 0.052638
[15:42:18.945] iteration 20870: loss: 0.053254, loss_s1: 0.032651, loss_fp: 0.002750, loss_freq: 0.014950
[15:42:19.563] iteration 20871: loss: 0.063887, loss_s1: 0.067109, loss_fp: 0.001422, loss_freq: 0.012611
[15:42:20.186] iteration 20872: loss: 0.102860, loss_s1: 0.064277, loss_fp: 0.005706, loss_freq: 0.028925
[15:42:20.804] iteration 20873: loss: 0.035359, loss_s1: 0.026210, loss_fp: 0.001146, loss_freq: 0.014112
[15:42:21.428] iteration 20874: loss: 0.046663, loss_s1: 0.035165, loss_fp: 0.001058, loss_freq: 0.020957
[15:42:22.073] iteration 20875: loss: 0.037616, loss_s1: 0.018361, loss_fp: 0.001908, loss_freq: 0.009719
[15:42:22.694] iteration 20876: loss: 0.072086, loss_s1: 0.042535, loss_fp: 0.007988, loss_freq: 0.055029
[15:42:23.313] iteration 20877: loss: 0.102576, loss_s1: 0.072081, loss_fp: 0.025296, loss_freq: 0.063195
[15:42:23.927] iteration 20878: loss: 0.042615, loss_s1: 0.012798, loss_fp: 0.004990, loss_freq: 0.031445
[15:42:24.858] iteration 20879: loss: 0.030567, loss_s1: 0.009513, loss_fp: 0.005151, loss_freq: 0.006317
[15:42:25.491] iteration 20880: loss: 0.075572, loss_s1: 0.077614, loss_fp: 0.003738, loss_freq: 0.033644
[15:42:26.117] iteration 20881: loss: 0.037943, loss_s1: 0.027609, loss_fp: 0.001867, loss_freq: 0.017675
[15:42:26.779] iteration 20882: loss: 0.069403, loss_s1: 0.058313, loss_fp: 0.003471, loss_freq: 0.018277
[15:42:27.439] iteration 20883: loss: 0.051613, loss_s1: 0.023889, loss_fp: 0.001280, loss_freq: 0.040034
[15:42:28.317] iteration 20884: loss: 0.059532, loss_s1: 0.030556, loss_fp: 0.005662, loss_freq: 0.012886
[15:42:29.103] iteration 20885: loss: 0.039379, loss_s1: 0.012482, loss_fp: 0.002758, loss_freq: 0.030913
[15:42:29.843] iteration 20886: loss: 0.102739, loss_s1: 0.062142, loss_fp: 0.003505, loss_freq: 0.039735
[15:42:30.506] iteration 20887: loss: 0.049023, loss_s1: 0.027341, loss_fp: 0.004641, loss_freq: 0.018887
[15:42:31.123] iteration 20888: loss: 0.064781, loss_s1: 0.023573, loss_fp: 0.000171, loss_freq: 0.021463
[15:42:31.739] iteration 20889: loss: 0.071414, loss_s1: 0.058883, loss_fp: 0.005724, loss_freq: 0.026741
[15:42:32.361] iteration 20890: loss: 0.048005, loss_s1: 0.021706, loss_fp: 0.001319, loss_freq: 0.018376
[15:42:32.986] iteration 20891: loss: 0.051579, loss_s1: 0.052543, loss_fp: 0.000793, loss_freq: 0.015498
[15:42:33.599] iteration 20892: loss: 0.043924, loss_s1: 0.038307, loss_fp: 0.002793, loss_freq: 0.015123
[15:42:34.213] iteration 20893: loss: 0.045448, loss_s1: 0.026716, loss_fp: 0.001584, loss_freq: 0.021706
[15:42:34.828] iteration 20894: loss: 0.037329, loss_s1: 0.022632, loss_fp: 0.001407, loss_freq: 0.006243
[15:42:35.450] iteration 20895: loss: 0.051434, loss_s1: 0.030797, loss_fp: 0.002300, loss_freq: 0.027411
[15:42:36.072] iteration 20896: loss: 0.080194, loss_s1: 0.074447, loss_fp: 0.008501, loss_freq: 0.033269
[15:42:36.697] iteration 20897: loss: 0.042633, loss_s1: 0.025687, loss_fp: 0.002197, loss_freq: 0.026851
[15:42:37.314] iteration 20898: loss: 0.073566, loss_s1: 0.041508, loss_fp: 0.006514, loss_freq: 0.011212
[15:42:37.937] iteration 20899: loss: 0.084663, loss_s1: 0.052544, loss_fp: 0.001968, loss_freq: 0.061307
[15:42:38.563] iteration 20900: loss: 0.051087, loss_s1: 0.032594, loss_fp: 0.002548, loss_freq: 0.028705
[15:42:39.195] iteration 20901: loss: 0.070644, loss_s1: 0.040398, loss_fp: 0.012905, loss_freq: 0.045524
[15:42:39.856] iteration 20902: loss: 0.034838, loss_s1: 0.018542, loss_fp: 0.001828, loss_freq: 0.010835
[15:42:40.474] iteration 20903: loss: 0.058943, loss_s1: 0.058172, loss_fp: 0.003160, loss_freq: 0.005821
[15:42:41.094] iteration 20904: loss: 0.066717, loss_s1: 0.052685, loss_fp: 0.002725, loss_freq: 0.038296
[15:42:41.714] iteration 20905: loss: 0.063074, loss_s1: 0.041940, loss_fp: 0.001125, loss_freq: 0.028261
[15:42:42.331] iteration 20906: loss: 0.051707, loss_s1: 0.036933, loss_fp: 0.003804, loss_freq: 0.012981
[15:42:42.950] iteration 20907: loss: 0.062714, loss_s1: 0.029282, loss_fp: 0.004395, loss_freq: 0.045191
[15:42:43.589] iteration 20908: loss: 0.038758, loss_s1: 0.010620, loss_fp: 0.001675, loss_freq: 0.006917
[15:42:44.215] iteration 20909: loss: 0.040109, loss_s1: 0.020010, loss_fp: 0.003641, loss_freq: 0.021741
[15:42:44.831] iteration 20910: loss: 0.079560, loss_s1: 0.040944, loss_fp: 0.005091, loss_freq: 0.073962
[15:42:45.453] iteration 20911: loss: 0.091680, loss_s1: 0.097765, loss_fp: 0.003450, loss_freq: 0.053077
[15:42:46.068] iteration 20912: loss: 0.070213, loss_s1: 0.024727, loss_fp: 0.004732, loss_freq: 0.051855
[15:42:46.686] iteration 20913: loss: 0.068343, loss_s1: 0.047776, loss_fp: 0.006418, loss_freq: 0.033038
[15:42:47.322] iteration 20914: loss: 0.060705, loss_s1: 0.037917, loss_fp: 0.001826, loss_freq: 0.039732
[15:42:47.949] iteration 20915: loss: 0.038257, loss_s1: 0.018790, loss_fp: 0.006158, loss_freq: 0.012461
[15:42:48.580] iteration 20916: loss: 0.056099, loss_s1: 0.048510, loss_fp: 0.007251, loss_freq: 0.015375
[15:42:49.206] iteration 20917: loss: 0.073479, loss_s1: 0.041567, loss_fp: 0.009537, loss_freq: 0.029452
[15:42:49.840] iteration 20918: loss: 0.042306, loss_s1: 0.036319, loss_fp: 0.002317, loss_freq: 0.011476
[15:42:50.453] iteration 20919: loss: 0.070295, loss_s1: 0.026618, loss_fp: 0.004211, loss_freq: 0.007256
[15:42:51.070] iteration 20920: loss: 0.040909, loss_s1: 0.026704, loss_fp: 0.003752, loss_freq: 0.023223
[15:42:51.681] iteration 20921: loss: 0.048622, loss_s1: 0.038265, loss_fp: 0.001333, loss_freq: 0.015446
[15:42:52.302] iteration 20922: loss: 0.051917, loss_s1: 0.039361, loss_fp: 0.002552, loss_freq: 0.022516
[15:42:52.921] iteration 20923: loss: 0.045836, loss_s1: 0.023073, loss_fp: 0.001098, loss_freq: 0.010843
[15:42:53.534] iteration 20924: loss: 0.051285, loss_s1: 0.028078, loss_fp: 0.001056, loss_freq: 0.026695
[15:42:54.153] iteration 20925: loss: 0.073560, loss_s1: 0.047619, loss_fp: 0.004139, loss_freq: 0.034376
[15:42:54.765] iteration 20926: loss: 0.053820, loss_s1: 0.032916, loss_fp: 0.007873, loss_freq: 0.033113
[15:42:55.382] iteration 20927: loss: 0.063175, loss_s1: 0.043725, loss_fp: 0.004608, loss_freq: 0.048155
[15:42:56.002] iteration 20928: loss: 0.054859, loss_s1: 0.036548, loss_fp: 0.002878, loss_freq: 0.011029
[15:42:56.625] iteration 20929: loss: 0.066094, loss_s1: 0.065370, loss_fp: 0.002239, loss_freq: 0.026925
[15:42:57.238] iteration 20930: loss: 0.047919, loss_s1: 0.024108, loss_fp: 0.001977, loss_freq: 0.031033
[15:42:57.853] iteration 20931: loss: 0.037423, loss_s1: 0.018042, loss_fp: 0.004180, loss_freq: 0.011204
[15:42:58.467] iteration 20932: loss: 0.055209, loss_s1: 0.033560, loss_fp: 0.000888, loss_freq: 0.026319
[15:42:59.082] iteration 20933: loss: 0.047315, loss_s1: 0.055744, loss_fp: 0.001657, loss_freq: 0.006976
[15:42:59.699] iteration 20934: loss: 0.064109, loss_s1: 0.035908, loss_fp: 0.000861, loss_freq: 0.016793
[15:43:00.356] iteration 20935: loss: 0.047812, loss_s1: 0.040355, loss_fp: 0.001136, loss_freq: 0.024637
[15:43:01.015] iteration 20936: loss: 0.046763, loss_s1: 0.019234, loss_fp: 0.008653, loss_freq: 0.025513
[15:43:01.668] iteration 20937: loss: 0.069977, loss_s1: 0.026231, loss_fp: 0.009372, loss_freq: 0.043349
[15:43:02.306] iteration 20938: loss: 0.033582, loss_s1: 0.018534, loss_fp: 0.000729, loss_freq: 0.010387
[15:43:02.944] iteration 20939: loss: 0.090016, loss_s1: 0.072330, loss_fp: 0.001370, loss_freq: 0.026672
[15:43:03.581] iteration 20940: loss: 0.067170, loss_s1: 0.065914, loss_fp: 0.006397, loss_freq: 0.007428
[15:43:04.225] iteration 20941: loss: 0.057297, loss_s1: 0.034337, loss_fp: 0.002130, loss_freq: 0.027701
[15:43:04.867] iteration 20942: loss: 0.047542, loss_s1: 0.019807, loss_fp: 0.001123, loss_freq: 0.017128
[15:43:05.498] iteration 20943: loss: 0.057146, loss_s1: 0.056555, loss_fp: 0.001414, loss_freq: 0.005641
[15:43:06.119] iteration 20944: loss: 0.047626, loss_s1: 0.026537, loss_fp: 0.002661, loss_freq: 0.017989
[15:43:06.737] iteration 20945: loss: 0.117267, loss_s1: 0.073691, loss_fp: 0.011183, loss_freq: 0.098816
[15:43:07.396] iteration 20946: loss: 0.040264, loss_s1: 0.026766, loss_fp: 0.001200, loss_freq: 0.019018
[15:43:08.009] iteration 20947: loss: 0.045085, loss_s1: 0.036558, loss_fp: 0.006879, loss_freq: 0.012888
[15:43:08.630] iteration 20948: loss: 0.042549, loss_s1: 0.031437, loss_fp: 0.001154, loss_freq: 0.013969
[15:43:09.258] iteration 20949: loss: 0.051092, loss_s1: 0.042398, loss_fp: 0.008117, loss_freq: 0.011942
[15:43:09.890] iteration 20950: loss: 0.057268, loss_s1: 0.034893, loss_fp: 0.007232, loss_freq: 0.030089
[15:43:10.511] iteration 20951: loss: 0.064513, loss_s1: 0.069527, loss_fp: 0.002653, loss_freq: 0.018992
[15:43:11.131] iteration 20952: loss: 0.136409, loss_s1: 0.071742, loss_fp: 0.025949, loss_freq: 0.098817
[15:43:11.755] iteration 20953: loss: 0.060980, loss_s1: 0.043810, loss_fp: 0.012420, loss_freq: 0.034249
[15:43:12.382] iteration 20954: loss: 0.058302, loss_s1: 0.032990, loss_fp: 0.000951, loss_freq: 0.011368
[15:43:13.003] iteration 20955: loss: 0.054558, loss_s1: 0.052809, loss_fp: 0.007489, loss_freq: 0.016493
[15:43:13.631] iteration 20956: loss: 0.067421, loss_s1: 0.042211, loss_fp: 0.003067, loss_freq: 0.016417
[15:43:14.254] iteration 20957: loss: 0.063691, loss_s1: 0.046277, loss_fp: 0.008836, loss_freq: 0.028136
[15:43:14.880] iteration 20958: loss: 0.107855, loss_s1: 0.062787, loss_fp: 0.036569, loss_freq: 0.048304
[15:43:15.500] iteration 20959: loss: 0.119493, loss_s1: 0.066298, loss_fp: 0.004079, loss_freq: 0.070280
[15:43:16.123] iteration 20960: loss: 0.061341, loss_s1: 0.059697, loss_fp: 0.003050, loss_freq: 0.024054
[15:43:16.748] iteration 20961: loss: 0.040847, loss_s1: 0.013606, loss_fp: 0.002904, loss_freq: 0.029537
[15:43:17.373] iteration 20962: loss: 0.055285, loss_s1: 0.038024, loss_fp: 0.003578, loss_freq: 0.036428
[15:43:17.994] iteration 20963: loss: 0.057238, loss_s1: 0.026024, loss_fp: 0.001628, loss_freq: 0.034373
[15:43:18.608] iteration 20964: loss: 0.065486, loss_s1: 0.025621, loss_fp: 0.013809, loss_freq: 0.045006
[15:43:19.223] iteration 20965: loss: 0.083374, loss_s1: 0.025211, loss_fp: 0.000924, loss_freq: 0.035655
[15:43:19.843] iteration 20966: loss: 0.038979, loss_s1: 0.019534, loss_fp: 0.000756, loss_freq: 0.015139
[15:43:20.463] iteration 20967: loss: 0.068303, loss_s1: 0.077687, loss_fp: 0.003236, loss_freq: 0.023746
[15:43:21.086] iteration 20968: loss: 0.047721, loss_s1: 0.050791, loss_fp: 0.001762, loss_freq: 0.011575
[15:43:21.751] iteration 20969: loss: 0.054124, loss_s1: 0.027050, loss_fp: 0.001352, loss_freq: 0.014294
[15:43:22.368] iteration 20970: loss: 0.063411, loss_s1: 0.040592, loss_fp: 0.002431, loss_freq: 0.032455
[15:43:22.991] iteration 20971: loss: 0.053486, loss_s1: 0.037010, loss_fp: 0.003091, loss_freq: 0.012126
[15:43:23.613] iteration 20972: loss: 0.062585, loss_s1: 0.037383, loss_fp: 0.005402, loss_freq: 0.021368
[15:43:24.235] iteration 20973: loss: 0.062763, loss_s1: 0.038121, loss_fp: 0.017743, loss_freq: 0.033324
[15:43:24.853] iteration 20974: loss: 0.062699, loss_s1: 0.066508, loss_fp: 0.000718, loss_freq: 0.001919
[15:43:25.560] iteration 20975: loss: 0.058251, loss_s1: 0.026533, loss_fp: 0.002449, loss_freq: 0.043888
[15:43:26.186] iteration 20976: loss: 0.044637, loss_s1: 0.026793, loss_fp: 0.005470, loss_freq: 0.019630
[15:43:26.815] iteration 20977: loss: 0.040236, loss_s1: 0.005463, loss_fp: 0.003877, loss_freq: 0.007537
[15:43:27.442] iteration 20978: loss: 0.085768, loss_s1: 0.040112, loss_fp: 0.004166, loss_freq: 0.035085
[15:43:28.064] iteration 20979: loss: 0.034424, loss_s1: 0.017778, loss_fp: 0.003144, loss_freq: 0.012963
[15:43:28.684] iteration 20980: loss: 0.071564, loss_s1: 0.047896, loss_fp: 0.001189, loss_freq: 0.010866
[15:43:29.304] iteration 20981: loss: 0.055151, loss_s1: 0.031941, loss_fp: 0.001907, loss_freq: 0.032354
[15:43:29.923] iteration 20982: loss: 0.034704, loss_s1: 0.024253, loss_fp: 0.002424, loss_freq: 0.005664
[15:43:30.553] iteration 20983: loss: 0.060163, loss_s1: 0.039374, loss_fp: 0.001251, loss_freq: 0.017838
[15:43:31.178] iteration 20984: loss: 0.063621, loss_s1: 0.017891, loss_fp: 0.001322, loss_freq: 0.032185
[15:43:31.796] iteration 20985: loss: 0.081718, loss_s1: 0.058817, loss_fp: 0.009507, loss_freq: 0.053282
[15:43:32.412] iteration 20986: loss: 0.075421, loss_s1: 0.060584, loss_fp: 0.002191, loss_freq: 0.057007
[15:43:33.028] iteration 20987: loss: 0.047221, loss_s1: 0.026014, loss_fp: 0.002773, loss_freq: 0.012283
[15:43:33.659] iteration 20988: loss: 0.040369, loss_s1: 0.030908, loss_fp: 0.007096, loss_freq: 0.011200
[15:43:34.287] iteration 20989: loss: 0.039173, loss_s1: 0.034526, loss_fp: 0.002759, loss_freq: 0.005131
[15:43:34.918] iteration 20990: loss: 0.065137, loss_s1: 0.070841, loss_fp: 0.001534, loss_freq: 0.028810
[15:43:35.556] iteration 20991: loss: 0.066740, loss_s1: 0.076849, loss_fp: 0.000654, loss_freq: 0.009133
[15:43:36.195] iteration 20992: loss: 0.060703, loss_s1: 0.041509, loss_fp: 0.029489, loss_freq: 0.010201
[15:43:36.813] iteration 20993: loss: 0.057683, loss_s1: 0.033182, loss_fp: 0.008701, loss_freq: 0.017545
[15:43:37.437] iteration 20994: loss: 0.036082, loss_s1: 0.008241, loss_fp: 0.001906, loss_freq: 0.015715
[15:43:38.064] iteration 20995: loss: 0.041992, loss_s1: 0.022118, loss_fp: 0.005118, loss_freq: 0.015118
[15:43:38.685] iteration 20996: loss: 0.070767, loss_s1: 0.076510, loss_fp: 0.004604, loss_freq: 0.014070
[15:43:39.302] iteration 20997: loss: 0.036494, loss_s1: 0.016241, loss_fp: 0.001174, loss_freq: 0.024347
[15:43:39.926] iteration 20998: loss: 0.057287, loss_s1: 0.035427, loss_fp: 0.001164, loss_freq: 0.033886
[15:43:40.569] iteration 20999: loss: 0.070373, loss_s1: 0.055507, loss_fp: 0.009982, loss_freq: 0.031495
[15:43:41.190] iteration 21000: loss: 0.063005, loss_s1: 0.043815, loss_fp: 0.001794, loss_freq: 0.038430
[15:43:44.376] iteration 21000 : mean_dice : 0.782099
[15:43:45.019] iteration 21001: loss: 0.065905, loss_s1: 0.040499, loss_fp: 0.010251, loss_freq: 0.039860
[15:43:45.675] iteration 21002: loss: 0.064618, loss_s1: 0.041517, loss_fp: 0.003565, loss_freq: 0.050045
[15:43:46.318] iteration 21003: loss: 0.044923, loss_s1: 0.028955, loss_fp: 0.003655, loss_freq: 0.023712
[15:43:46.958] iteration 21004: loss: 0.055539, loss_s1: 0.041179, loss_fp: 0.002143, loss_freq: 0.017093
[15:43:47.599] iteration 21005: loss: 0.045866, loss_s1: 0.024721, loss_fp: 0.000738, loss_freq: 0.037714
[15:43:48.233] iteration 21006: loss: 0.063611, loss_s1: 0.053366, loss_fp: 0.004458, loss_freq: 0.027469
[15:43:48.852] iteration 21007: loss: 0.087241, loss_s1: 0.095162, loss_fp: 0.007670, loss_freq: 0.006677
[15:43:49.475] iteration 21008: loss: 0.058518, loss_s1: 0.038971, loss_fp: 0.001852, loss_freq: 0.027517
[15:43:50.131] iteration 21009: loss: 0.050683, loss_s1: 0.034347, loss_fp: 0.004023, loss_freq: 0.014521
[15:43:50.755] iteration 21010: loss: 0.076417, loss_s1: 0.052744, loss_fp: 0.003933, loss_freq: 0.018759
[15:43:51.376] iteration 21011: loss: 0.071762, loss_s1: 0.073056, loss_fp: 0.006266, loss_freq: 0.019519
[15:43:52.000] iteration 21012: loss: 0.090324, loss_s1: 0.041548, loss_fp: 0.006232, loss_freq: 0.031607
[15:43:52.632] iteration 21013: loss: 0.064681, loss_s1: 0.027241, loss_fp: 0.002496, loss_freq: 0.012889
[15:43:53.253] iteration 21014: loss: 0.064745, loss_s1: 0.056116, loss_fp: 0.003352, loss_freq: 0.021431
[15:43:53.879] iteration 21015: loss: 0.068109, loss_s1: 0.072004, loss_fp: 0.002660, loss_freq: 0.021809
[15:43:54.502] iteration 21016: loss: 0.032260, loss_s1: 0.017577, loss_fp: 0.000602, loss_freq: 0.015864
[15:43:55.123] iteration 21017: loss: 0.052152, loss_s1: 0.051167, loss_fp: 0.001800, loss_freq: 0.016704
[15:43:55.743] iteration 21018: loss: 0.077577, loss_s1: 0.040872, loss_fp: 0.010952, loss_freq: 0.020987
[15:43:56.410] iteration 21019: loss: 0.052372, loss_s1: 0.033669, loss_fp: 0.005177, loss_freq: 0.020610
[15:43:57.058] iteration 21020: loss: 0.085306, loss_s1: 0.050424, loss_fp: 0.003900, loss_freq: 0.060719
[15:43:57.740] iteration 21021: loss: 0.039666, loss_s1: 0.026029, loss_fp: 0.000706, loss_freq: 0.020514
[15:43:58.708] iteration 21022: loss: 0.042534, loss_s1: 0.030104, loss_fp: 0.000872, loss_freq: 0.012808
[15:43:59.350] iteration 21023: loss: 0.071030, loss_s1: 0.066020, loss_fp: 0.016668, loss_freq: 0.018829
[15:43:59.988] iteration 21024: loss: 0.035301, loss_s1: 0.018247, loss_fp: 0.005151, loss_freq: 0.014586
[15:44:00.629] iteration 21025: loss: 0.047694, loss_s1: 0.029054, loss_fp: 0.001150, loss_freq: 0.022119
[15:44:01.260] iteration 21026: loss: 0.068590, loss_s1: 0.054535, loss_fp: 0.001988, loss_freq: 0.050708
[15:44:01.946] iteration 21027: loss: 0.068001, loss_s1: 0.044558, loss_fp: 0.000710, loss_freq: 0.004513
[15:44:02.615] iteration 21028: loss: 0.037478, loss_s1: 0.019165, loss_fp: 0.003459, loss_freq: 0.018455
[15:44:03.234] iteration 21029: loss: 0.045664, loss_s1: 0.014533, loss_fp: 0.001635, loss_freq: 0.008129
[15:44:03.869] iteration 21030: loss: 0.071557, loss_s1: 0.052051, loss_fp: 0.001617, loss_freq: 0.034486
[15:44:04.523] iteration 21031: loss: 0.043080, loss_s1: 0.016042, loss_fp: 0.000994, loss_freq: 0.007567
[15:44:05.161] iteration 21032: loss: 0.062024, loss_s1: 0.013117, loss_fp: 0.006381, loss_freq: 0.050641
[15:44:05.799] iteration 21033: loss: 0.050519, loss_s1: 0.022931, loss_fp: 0.007803, loss_freq: 0.028990
[15:44:06.431] iteration 21034: loss: 0.061785, loss_s1: 0.059705, loss_fp: 0.000678, loss_freq: 0.010730
[15:44:07.047] iteration 21035: loss: 0.030035, loss_s1: 0.013282, loss_fp: 0.002221, loss_freq: 0.010382
[15:44:07.673] iteration 21036: loss: 0.064037, loss_s1: 0.048353, loss_fp: 0.007114, loss_freq: 0.031693
[15:44:08.331] iteration 21037: loss: 0.044519, loss_s1: 0.039003, loss_fp: 0.002616, loss_freq: 0.013016
[15:44:08.962] iteration 21038: loss: 0.079736, loss_s1: 0.047401, loss_fp: 0.002008, loss_freq: 0.022827
[15:44:09.611] iteration 21039: loss: 0.053120, loss_s1: 0.050135, loss_fp: 0.002138, loss_freq: 0.016067
[15:44:10.229] iteration 21040: loss: 0.043739, loss_s1: 0.032454, loss_fp: 0.005553, loss_freq: 0.024331
[15:44:10.844] iteration 21041: loss: 0.042533, loss_s1: 0.030394, loss_fp: 0.001193, loss_freq: 0.019499
[15:44:11.514] iteration 21042: loss: 0.060591, loss_s1: 0.021516, loss_fp: 0.006471, loss_freq: 0.044125
[15:44:12.133] iteration 21043: loss: 0.042071, loss_s1: 0.030654, loss_fp: 0.006424, loss_freq: 0.018719
[15:44:12.758] iteration 21044: loss: 0.108813, loss_s1: 0.110861, loss_fp: 0.002446, loss_freq: 0.056343
[15:44:13.382] iteration 21045: loss: 0.064531, loss_s1: 0.060316, loss_fp: 0.006988, loss_freq: 0.014515
[15:44:14.055] iteration 21046: loss: 0.033270, loss_s1: 0.015999, loss_fp: 0.000656, loss_freq: 0.013750
[15:44:14.681] iteration 21047: loss: 0.081441, loss_s1: 0.042720, loss_fp: 0.003095, loss_freq: 0.051183
[15:44:15.295] iteration 21048: loss: 0.093875, loss_s1: 0.076678, loss_fp: 0.001384, loss_freq: 0.055019
[15:44:15.914] iteration 21049: loss: 0.032059, loss_s1: 0.011118, loss_fp: 0.000460, loss_freq: 0.013232
[15:44:16.540] iteration 21050: loss: 0.049342, loss_s1: 0.022856, loss_fp: 0.004275, loss_freq: 0.017623
[15:44:17.166] iteration 21051: loss: 0.063171, loss_s1: 0.026805, loss_fp: 0.006789, loss_freq: 0.023965
[15:44:17.789] iteration 21052: loss: 0.041959, loss_s1: 0.030532, loss_fp: 0.002639, loss_freq: 0.011467
[15:44:18.408] iteration 21053: loss: 0.062071, loss_s1: 0.030487, loss_fp: 0.010161, loss_freq: 0.026341
[15:44:19.030] iteration 21054: loss: 0.062803, loss_s1: 0.061439, loss_fp: 0.006991, loss_freq: 0.029558
[15:44:19.674] iteration 21055: loss: 0.081779, loss_s1: 0.075732, loss_fp: 0.006843, loss_freq: 0.044068
[15:44:20.296] iteration 21056: loss: 0.048346, loss_s1: 0.032254, loss_fp: 0.004608, loss_freq: 0.020589
[15:44:20.915] iteration 21057: loss: 0.063023, loss_s1: 0.027922, loss_fp: 0.005745, loss_freq: 0.020354
[15:44:21.533] iteration 21058: loss: 0.046381, loss_s1: 0.025590, loss_fp: 0.003067, loss_freq: 0.017759
[15:44:22.154] iteration 21059: loss: 0.032671, loss_s1: 0.013725, loss_fp: 0.004249, loss_freq: 0.013865
[15:44:22.779] iteration 21060: loss: 0.073044, loss_s1: 0.046648, loss_fp: 0.007236, loss_freq: 0.043222
[15:44:23.448] iteration 21061: loss: 0.046357, loss_s1: 0.048251, loss_fp: 0.005905, loss_freq: 0.008055
[15:44:24.095] iteration 21062: loss: 0.063227, loss_s1: 0.057905, loss_fp: 0.004067, loss_freq: 0.015110
[15:44:24.710] iteration 21063: loss: 0.031590, loss_s1: 0.018900, loss_fp: 0.003773, loss_freq: 0.012718
[15:44:25.336] iteration 21064: loss: 0.051085, loss_s1: 0.036757, loss_fp: 0.000506, loss_freq: 0.010061
[15:44:25.954] iteration 21065: loss: 0.064330, loss_s1: 0.049703, loss_fp: 0.007384, loss_freq: 0.035030
[15:44:26.572] iteration 21066: loss: 0.048570, loss_s1: 0.008722, loss_fp: 0.000298, loss_freq: 0.014796
[15:44:27.191] iteration 21067: loss: 0.055289, loss_s1: 0.020553, loss_fp: 0.000588, loss_freq: 0.046612
[15:44:27.813] iteration 21068: loss: 0.039813, loss_s1: 0.015564, loss_fp: 0.006514, loss_freq: 0.018601
[15:44:28.445] iteration 21069: loss: 0.048092, loss_s1: 0.028185, loss_fp: 0.003554, loss_freq: 0.026713
[15:44:29.071] iteration 21070: loss: 0.046000, loss_s1: 0.024066, loss_fp: 0.003805, loss_freq: 0.034129
[15:44:29.692] iteration 21071: loss: 0.038620, loss_s1: 0.020126, loss_fp: 0.001230, loss_freq: 0.017097
[15:44:30.316] iteration 21072: loss: 0.050105, loss_s1: 0.052201, loss_fp: 0.000894, loss_freq: 0.011302
[15:44:30.935] iteration 21073: loss: 0.054962, loss_s1: 0.039078, loss_fp: 0.002692, loss_freq: 0.033256
[15:44:31.559] iteration 21074: loss: 0.040835, loss_s1: 0.018770, loss_fp: 0.002513, loss_freq: 0.019621
[15:44:32.171] iteration 21075: loss: 0.056846, loss_s1: 0.042696, loss_fp: 0.002189, loss_freq: 0.024150
[15:44:32.788] iteration 21076: loss: 0.046613, loss_s1: 0.044557, loss_fp: 0.001663, loss_freq: 0.006361
[15:44:33.432] iteration 21077: loss: 0.046008, loss_s1: 0.016706, loss_fp: 0.000907, loss_freq: 0.022158
[15:44:34.058] iteration 21078: loss: 0.056613, loss_s1: 0.052750, loss_fp: 0.003105, loss_freq: 0.025238
[15:44:35.001] iteration 21079: loss: 0.066288, loss_s1: 0.031559, loss_fp: 0.001868, loss_freq: 0.047237
[15:44:35.831] iteration 21080: loss: 0.072175, loss_s1: 0.025525, loss_fp: 0.002559, loss_freq: 0.077320
[15:44:36.444] iteration 21081: loss: 0.043274, loss_s1: 0.019841, loss_fp: 0.000536, loss_freq: 0.014856
[15:44:37.062] iteration 21082: loss: 0.053385, loss_s1: 0.019714, loss_fp: 0.007499, loss_freq: 0.017064
[15:44:37.684] iteration 21083: loss: 0.063095, loss_s1: 0.052996, loss_fp: 0.009415, loss_freq: 0.012505
[15:44:38.300] iteration 21084: loss: 0.074917, loss_s1: 0.082835, loss_fp: 0.002570, loss_freq: 0.019452
[15:44:38.923] iteration 21085: loss: 0.055850, loss_s1: 0.040267, loss_fp: 0.002241, loss_freq: 0.022105
[15:44:39.591] iteration 21086: loss: 0.069134, loss_s1: 0.064067, loss_fp: 0.003875, loss_freq: 0.013078
[15:44:40.238] iteration 21087: loss: 0.076530, loss_s1: 0.051563, loss_fp: 0.009970, loss_freq: 0.044980
[15:44:40.873] iteration 21088: loss: 0.113413, loss_s1: 0.083693, loss_fp: 0.014187, loss_freq: 0.029533
[15:44:41.502] iteration 21089: loss: 0.054451, loss_s1: 0.042704, loss_fp: 0.003511, loss_freq: 0.029663
[15:44:42.130] iteration 21090: loss: 0.048270, loss_s1: 0.036692, loss_fp: 0.003388, loss_freq: 0.015370
[15:44:42.755] iteration 21091: loss: 0.050876, loss_s1: 0.027777, loss_fp: 0.003753, loss_freq: 0.017553
[15:44:43.416] iteration 21092: loss: 0.052154, loss_s1: 0.044038, loss_fp: 0.004555, loss_freq: 0.018689
[15:44:44.059] iteration 21093: loss: 0.076304, loss_s1: 0.075607, loss_fp: 0.002723, loss_freq: 0.029309
[15:44:44.699] iteration 21094: loss: 0.058781, loss_s1: 0.041645, loss_fp: 0.006557, loss_freq: 0.036039
[15:44:45.334] iteration 21095: loss: 0.102833, loss_s1: 0.077254, loss_fp: 0.003604, loss_freq: 0.050823
[15:44:45.960] iteration 21096: loss: 0.079051, loss_s1: 0.066230, loss_fp: 0.011246, loss_freq: 0.052433
[15:44:46.578] iteration 21097: loss: 0.063561, loss_s1: 0.035942, loss_fp: 0.006336, loss_freq: 0.022449
[15:44:47.200] iteration 21098: loss: 0.040568, loss_s1: 0.020051, loss_fp: 0.003276, loss_freq: 0.014524
[15:44:47.823] iteration 21099: loss: 0.059934, loss_s1: 0.058805, loss_fp: 0.002189, loss_freq: 0.018330
[15:44:48.446] iteration 21100: loss: 0.059131, loss_s1: 0.029194, loss_fp: 0.002518, loss_freq: 0.039430
[15:44:49.101] iteration 21101: loss: 0.109381, loss_s1: 0.103973, loss_fp: 0.009437, loss_freq: 0.041774
[15:44:49.769] iteration 21102: loss: 0.072369, loss_s1: 0.044853, loss_fp: 0.000776, loss_freq: 0.026834
[15:44:50.501] iteration 21103: loss: 0.056033, loss_s1: 0.043866, loss_fp: 0.002815, loss_freq: 0.021722
[15:44:51.160] iteration 21104: loss: 0.052712, loss_s1: 0.032452, loss_fp: 0.002232, loss_freq: 0.031103
[15:44:51.796] iteration 21105: loss: 0.053360, loss_s1: 0.046523, loss_fp: 0.007699, loss_freq: 0.022199
[15:44:52.424] iteration 21106: loss: 0.060833, loss_s1: 0.054744, loss_fp: 0.006750, loss_freq: 0.017963
[15:44:53.051] iteration 21107: loss: 0.067143, loss_s1: 0.051528, loss_fp: 0.001947, loss_freq: 0.042429
[15:44:53.677] iteration 21108: loss: 0.042747, loss_s1: 0.033576, loss_fp: 0.001354, loss_freq: 0.004456
[15:44:54.296] iteration 21109: loss: 0.035846, loss_s1: 0.011143, loss_fp: 0.003016, loss_freq: 0.015596
[15:44:54.955] iteration 21110: loss: 0.051847, loss_s1: 0.050206, loss_fp: 0.000627, loss_freq: 0.018047
[15:44:55.599] iteration 21111: loss: 0.039992, loss_s1: 0.018829, loss_fp: 0.002716, loss_freq: 0.020348
[15:44:56.286] iteration 21112: loss: 0.041653, loss_s1: 0.028959, loss_fp: 0.001142, loss_freq: 0.008904
[15:44:56.910] iteration 21113: loss: 0.056839, loss_s1: 0.038770, loss_fp: 0.014124, loss_freq: 0.021649
[15:44:57.531] iteration 21114: loss: 0.057415, loss_s1: 0.050200, loss_fp: 0.003873, loss_freq: 0.015104
[15:44:58.148] iteration 21115: loss: 0.109585, loss_s1: 0.067740, loss_fp: 0.004004, loss_freq: 0.011345
[15:44:58.773] iteration 21116: loss: 0.042877, loss_s1: 0.015447, loss_fp: 0.001309, loss_freq: 0.025140
[15:44:59.397] iteration 21117: loss: 0.033601, loss_s1: 0.020411, loss_fp: 0.004077, loss_freq: 0.006096
[15:45:00.023] iteration 21118: loss: 0.117654, loss_s1: 0.087882, loss_fp: 0.003726, loss_freq: 0.097274
[15:45:00.644] iteration 21119: loss: 0.042111, loss_s1: 0.017365, loss_fp: 0.007043, loss_freq: 0.020498
[15:45:01.253] iteration 21120: loss: 0.073077, loss_s1: 0.070603, loss_fp: 0.001717, loss_freq: 0.024395
[15:45:01.873] iteration 21121: loss: 0.064641, loss_s1: 0.049547, loss_fp: 0.004923, loss_freq: 0.020480
[15:45:02.575] iteration 21122: loss: 0.044126, loss_s1: 0.029237, loss_fp: 0.007885, loss_freq: 0.011654
[15:45:03.229] iteration 21123: loss: 0.062348, loss_s1: 0.039970, loss_fp: 0.000948, loss_freq: 0.025006
[15:45:03.858] iteration 21124: loss: 0.058385, loss_s1: 0.050916, loss_fp: 0.002052, loss_freq: 0.023144
[15:45:04.473] iteration 21125: loss: 0.038578, loss_s1: 0.019171, loss_fp: 0.002483, loss_freq: 0.008545
[15:45:05.099] iteration 21126: loss: 0.054061, loss_s1: 0.020314, loss_fp: 0.000989, loss_freq: 0.021234
[15:45:05.728] iteration 21127: loss: 0.064475, loss_s1: 0.024668, loss_fp: 0.002898, loss_freq: 0.039162
[15:45:06.365] iteration 21128: loss: 0.126002, loss_s1: 0.127930, loss_fp: 0.008446, loss_freq: 0.061019
[15:45:07.031] iteration 21129: loss: 0.106656, loss_s1: 0.102461, loss_fp: 0.004035, loss_freq: 0.078668
[15:45:07.703] iteration 21130: loss: 0.084035, loss_s1: 0.070980, loss_fp: 0.002563, loss_freq: 0.048665
[15:45:08.330] iteration 21131: loss: 0.072877, loss_s1: 0.064315, loss_fp: 0.002735, loss_freq: 0.050607
[15:45:08.954] iteration 21132: loss: 0.053179, loss_s1: 0.043446, loss_fp: 0.001675, loss_freq: 0.006454
[15:45:09.577] iteration 21133: loss: 0.029801, loss_s1: 0.013681, loss_fp: 0.001547, loss_freq: 0.015647
[15:45:10.209] iteration 21134: loss: 0.071674, loss_s1: 0.035386, loss_fp: 0.003324, loss_freq: 0.024590
[15:45:10.835] iteration 21135: loss: 0.059279, loss_s1: 0.049312, loss_fp: 0.006882, loss_freq: 0.018884
[15:45:11.458] iteration 21136: loss: 0.068795, loss_s1: 0.041788, loss_fp: 0.001065, loss_freq: 0.011448
[15:45:12.089] iteration 21137: loss: 0.038573, loss_s1: 0.017483, loss_fp: 0.008174, loss_freq: 0.014060
[15:45:12.710] iteration 21138: loss: 0.055450, loss_s1: 0.042834, loss_fp: 0.001759, loss_freq: 0.028074
[15:45:13.340] iteration 21139: loss: 0.067220, loss_s1: 0.052267, loss_fp: 0.004432, loss_freq: 0.018941
[15:45:13.968] iteration 21140: loss: 0.065112, loss_s1: 0.081289, loss_fp: 0.005422, loss_freq: 0.012931
[15:45:14.593] iteration 21141: loss: 0.051011, loss_s1: 0.039187, loss_fp: 0.002136, loss_freq: 0.022465
[15:45:15.218] iteration 21142: loss: 0.041406, loss_s1: 0.027779, loss_fp: 0.001395, loss_freq: 0.019052
[15:45:15.842] iteration 21143: loss: 0.108029, loss_s1: 0.015961, loss_fp: 0.013962, loss_freq: 0.022684
[15:45:16.456] iteration 21144: loss: 0.046773, loss_s1: 0.008866, loss_fp: 0.000884, loss_freq: 0.012927
[15:45:17.072] iteration 21145: loss: 0.042126, loss_s1: 0.037836, loss_fp: 0.003083, loss_freq: 0.013795
[15:45:17.714] iteration 21146: loss: 0.033579, loss_s1: 0.019398, loss_fp: 0.013030, loss_freq: 0.006905
[15:45:18.359] iteration 21147: loss: 0.055371, loss_s1: 0.049397, loss_fp: 0.001241, loss_freq: 0.010633
[15:45:19.002] iteration 21148: loss: 0.039618, loss_s1: 0.016129, loss_fp: 0.004223, loss_freq: 0.015876
[15:45:19.650] iteration 21149: loss: 0.038349, loss_s1: 0.013332, loss_fp: 0.003874, loss_freq: 0.022669
[15:45:20.303] iteration 21150: loss: 0.107420, loss_s1: 0.016108, loss_fp: 0.004428, loss_freq: 0.004415
[15:45:20.958] iteration 21151: loss: 0.045535, loss_s1: 0.022230, loss_fp: 0.004312, loss_freq: 0.017049
[15:45:21.582] iteration 21152: loss: 0.071381, loss_s1: 0.045747, loss_fp: 0.001374, loss_freq: 0.044137
[15:45:22.224] iteration 21153: loss: 0.077985, loss_s1: 0.063616, loss_fp: 0.006915, loss_freq: 0.038704
[15:45:22.869] iteration 21154: loss: 0.064378, loss_s1: 0.046493, loss_fp: 0.004001, loss_freq: 0.032004
[15:45:23.520] iteration 21155: loss: 0.070361, loss_s1: 0.032560, loss_fp: 0.002308, loss_freq: 0.033033
[15:45:24.168] iteration 21156: loss: 0.055791, loss_s1: 0.033894, loss_fp: 0.001505, loss_freq: 0.019746
[15:45:24.795] iteration 21157: loss: 0.070192, loss_s1: 0.043681, loss_fp: 0.001450, loss_freq: 0.046201
[15:45:25.404] iteration 21158: loss: 0.081877, loss_s1: 0.084880, loss_fp: 0.006357, loss_freq: 0.021485
[15:45:26.040] iteration 21159: loss: 0.051035, loss_s1: 0.025927, loss_fp: 0.000587, loss_freq: 0.008288
[15:45:26.696] iteration 21160: loss: 0.048656, loss_s1: 0.029146, loss_fp: 0.001807, loss_freq: 0.024865
[15:45:27.328] iteration 21161: loss: 0.053766, loss_s1: 0.027035, loss_fp: 0.002575, loss_freq: 0.026885
[15:45:27.961] iteration 21162: loss: 0.066053, loss_s1: 0.044948, loss_fp: 0.002690, loss_freq: 0.046198
[15:45:28.597] iteration 21163: loss: 0.077150, loss_s1: 0.074941, loss_fp: 0.010560, loss_freq: 0.017140
[15:45:29.234] iteration 21164: loss: 0.057948, loss_s1: 0.030794, loss_fp: 0.003971, loss_freq: 0.048192
[15:45:30.261] iteration 21165: loss: 0.031085, loss_s1: 0.016178, loss_fp: 0.001185, loss_freq: 0.005560
[15:45:30.896] iteration 21166: loss: 0.054474, loss_s1: 0.044374, loss_fp: 0.001379, loss_freq: 0.019795
[15:45:31.540] iteration 21167: loss: 0.028946, loss_s1: 0.008529, loss_fp: 0.000417, loss_freq: 0.015829
[15:45:32.180] iteration 21168: loss: 0.052709, loss_s1: 0.018391, loss_fp: 0.004650, loss_freq: 0.028057
[15:45:32.816] iteration 21169: loss: 0.051148, loss_s1: 0.036015, loss_fp: 0.001794, loss_freq: 0.029728
[15:45:33.441] iteration 21170: loss: 0.050977, loss_s1: 0.015360, loss_fp: 0.001189, loss_freq: 0.004533
[15:45:34.088] iteration 21171: loss: 0.028623, loss_s1: 0.017197, loss_fp: 0.002537, loss_freq: 0.008427
[15:45:34.704] iteration 21172: loss: 0.063682, loss_s1: 0.010116, loss_fp: 0.004726, loss_freq: 0.038993
[15:45:35.328] iteration 21173: loss: 0.048516, loss_s1: 0.047423, loss_fp: 0.004016, loss_freq: 0.006050
[15:45:35.955] iteration 21174: loss: 0.041813, loss_s1: 0.012086, loss_fp: 0.000988, loss_freq: 0.005586
[15:45:36.577] iteration 21175: loss: 0.043814, loss_s1: 0.022165, loss_fp: 0.001043, loss_freq: 0.025487
[15:45:37.199] iteration 21176: loss: 0.042301, loss_s1: 0.021381, loss_fp: 0.002350, loss_freq: 0.017930
[15:45:37.869] iteration 21177: loss: 0.062581, loss_s1: 0.067078, loss_fp: 0.001294, loss_freq: 0.023788
[15:45:38.499] iteration 21178: loss: 0.039797, loss_s1: 0.035719, loss_fp: 0.004964, loss_freq: 0.007983
[15:45:39.126] iteration 21179: loss: 0.058217, loss_s1: 0.044827, loss_fp: 0.001600, loss_freq: 0.023687
[15:45:39.747] iteration 21180: loss: 0.062401, loss_s1: 0.077106, loss_fp: 0.003525, loss_freq: 0.007175
[15:45:40.370] iteration 21181: loss: 0.074004, loss_s1: 0.018006, loss_fp: 0.003839, loss_freq: 0.042728
[15:45:40.998] iteration 21182: loss: 0.047524, loss_s1: 0.040167, loss_fp: 0.002972, loss_freq: 0.014893
[15:45:41.618] iteration 21183: loss: 0.057506, loss_s1: 0.047637, loss_fp: 0.001615, loss_freq: 0.026784
[15:45:42.295] iteration 21184: loss: 0.028848, loss_s1: 0.020409, loss_fp: 0.001370, loss_freq: 0.003879
[15:45:42.923] iteration 21185: loss: 0.067110, loss_s1: 0.036092, loss_fp: 0.005622, loss_freq: 0.042137
[15:45:43.550] iteration 21186: loss: 0.041664, loss_s1: 0.031640, loss_fp: 0.004173, loss_freq: 0.006983
[15:45:44.175] iteration 21187: loss: 0.050038, loss_s1: 0.036654, loss_fp: 0.000486, loss_freq: 0.022784
[15:45:44.801] iteration 21188: loss: 0.033094, loss_s1: 0.013573, loss_fp: 0.002176, loss_freq: 0.005869
[15:45:45.425] iteration 21189: loss: 0.062678, loss_s1: 0.017179, loss_fp: 0.004689, loss_freq: 0.046146
[15:45:46.052] iteration 21190: loss: 0.064712, loss_s1: 0.030521, loss_fp: 0.009654, loss_freq: 0.037386
[15:45:46.675] iteration 21191: loss: 0.064905, loss_s1: 0.045989, loss_fp: 0.007581, loss_freq: 0.026943
[15:45:47.300] iteration 21192: loss: 0.043254, loss_s1: 0.034749, loss_fp: 0.002330, loss_freq: 0.016469
[15:45:47.929] iteration 21193: loss: 0.088942, loss_s1: 0.094654, loss_fp: 0.000902, loss_freq: 0.030376
[15:45:48.554] iteration 21194: loss: 0.041241, loss_s1: 0.019692, loss_fp: 0.002240, loss_freq: 0.005591
[15:45:49.173] iteration 21195: loss: 0.029698, loss_s1: 0.015237, loss_fp: 0.002478, loss_freq: 0.007387
[15:45:49.800] iteration 21196: loss: 0.055904, loss_s1: 0.040945, loss_fp: 0.008330, loss_freq: 0.019013
[15:45:50.467] iteration 21197: loss: 0.072505, loss_s1: 0.058446, loss_fp: 0.003360, loss_freq: 0.050285
[15:45:51.078] iteration 21198: loss: 0.080188, loss_s1: 0.039882, loss_fp: 0.015349, loss_freq: 0.032044
[15:45:51.693] iteration 21199: loss: 0.076675, loss_s1: 0.039153, loss_fp: 0.009320, loss_freq: 0.024014
[15:45:52.323] iteration 21200: loss: 0.059662, loss_s1: 0.032723, loss_fp: 0.007255, loss_freq: 0.039162
[15:45:55.834] iteration 21200 : mean_dice : 0.792890
[15:45:56.476] iteration 21201: loss: 0.058792, loss_s1: 0.030555, loss_fp: 0.002061, loss_freq: 0.029529
[15:45:57.107] iteration 21202: loss: 0.078923, loss_s1: 0.109128, loss_fp: 0.002850, loss_freq: 0.013773
[15:45:57.743] iteration 21203: loss: 0.049539, loss_s1: 0.030017, loss_fp: 0.002570, loss_freq: 0.021219
[15:45:58.382] iteration 21204: loss: 0.035489, loss_s1: 0.015123, loss_fp: 0.002678, loss_freq: 0.014372
[15:45:59.016] iteration 21205: loss: 0.054572, loss_s1: 0.038485, loss_fp: 0.003305, loss_freq: 0.014110
[15:45:59.632] iteration 21206: loss: 0.061217, loss_s1: 0.062406, loss_fp: 0.002333, loss_freq: 0.015550
[15:46:00.259] iteration 21207: loss: 0.039251, loss_s1: 0.023467, loss_fp: 0.000458, loss_freq: 0.006323
[15:46:00.879] iteration 21208: loss: 0.051554, loss_s1: 0.043648, loss_fp: 0.003339, loss_freq: 0.010332
[15:46:01.589] iteration 21209: loss: 0.039896, loss_s1: 0.007622, loss_fp: 0.004145, loss_freq: 0.009339
[15:46:02.216] iteration 21210: loss: 0.086803, loss_s1: 0.083092, loss_fp: 0.000744, loss_freq: 0.051097
[15:46:02.845] iteration 21211: loss: 0.068901, loss_s1: 0.045156, loss_fp: 0.001640, loss_freq: 0.034957
[15:46:03.509] iteration 21212: loss: 0.069620, loss_s1: 0.046937, loss_fp: 0.003961, loss_freq: 0.017910
[15:46:04.126] iteration 21213: loss: 0.057081, loss_s1: 0.024707, loss_fp: 0.003790, loss_freq: 0.048877
[15:46:04.749] iteration 21214: loss: 0.043186, loss_s1: 0.026105, loss_fp: 0.003015, loss_freq: 0.017646
[15:46:05.372] iteration 21215: loss: 0.042149, loss_s1: 0.031412, loss_fp: 0.002933, loss_freq: 0.010932
[15:46:06.045] iteration 21216: loss: 0.070306, loss_s1: 0.047106, loss_fp: 0.001647, loss_freq: 0.044287
[15:46:06.671] iteration 21217: loss: 0.052064, loss_s1: 0.019720, loss_fp: 0.002850, loss_freq: 0.037763
[15:46:07.322] iteration 21218: loss: 0.036379, loss_s1: 0.023324, loss_fp: 0.001047, loss_freq: 0.011295
[15:46:07.947] iteration 21219: loss: 0.059033, loss_s1: 0.072102, loss_fp: 0.005396, loss_freq: 0.008973
[15:46:08.576] iteration 21220: loss: 0.059881, loss_s1: 0.044369, loss_fp: 0.000819, loss_freq: 0.011291
[15:46:09.202] iteration 21221: loss: 0.066041, loss_s1: 0.063283, loss_fp: 0.001947, loss_freq: 0.031378
[15:46:09.864] iteration 21222: loss: 0.032427, loss_s1: 0.013754, loss_fp: 0.001282, loss_freq: 0.006990
[15:46:10.485] iteration 21223: loss: 0.066911, loss_s1: 0.039676, loss_fp: 0.004519, loss_freq: 0.027221
[15:46:11.116] iteration 21224: loss: 0.047787, loss_s1: 0.017589, loss_fp: 0.000463, loss_freq: 0.021283
[15:46:11.746] iteration 21225: loss: 0.064353, loss_s1: 0.061671, loss_fp: 0.001836, loss_freq: 0.016720
[15:46:12.367] iteration 21226: loss: 0.059980, loss_s1: 0.037095, loss_fp: 0.002260, loss_freq: 0.030646
[15:46:12.994] iteration 21227: loss: 0.101950, loss_s1: 0.092711, loss_fp: 0.010467, loss_freq: 0.048767
[15:46:13.618] iteration 21228: loss: 0.059137, loss_s1: 0.043825, loss_fp: 0.000598, loss_freq: 0.017175
[15:46:14.240] iteration 21229: loss: 0.066775, loss_s1: 0.051476, loss_fp: 0.003432, loss_freq: 0.023894
[15:46:14.860] iteration 21230: loss: 0.037184, loss_s1: 0.022039, loss_fp: 0.001687, loss_freq: 0.014039
[15:46:15.482] iteration 21231: loss: 0.086136, loss_s1: 0.058635, loss_fp: 0.012814, loss_freq: 0.046771
[15:46:16.100] iteration 21232: loss: 0.058357, loss_s1: 0.024923, loss_fp: 0.003450, loss_freq: 0.020281
[15:46:16.723] iteration 21233: loss: 0.039024, loss_s1: 0.022190, loss_fp: 0.003683, loss_freq: 0.011502
[15:46:17.345] iteration 21234: loss: 0.054754, loss_s1: 0.042876, loss_fp: 0.001462, loss_freq: 0.016514
[15:46:17.962] iteration 21235: loss: 0.049085, loss_s1: 0.032940, loss_fp: 0.004084, loss_freq: 0.020113
[15:46:18.639] iteration 21236: loss: 0.067882, loss_s1: 0.055486, loss_fp: 0.002977, loss_freq: 0.038054
[15:46:19.278] iteration 21237: loss: 0.047349, loss_s1: 0.016868, loss_fp: 0.004059, loss_freq: 0.040485
[15:46:19.921] iteration 21238: loss: 0.051435, loss_s1: 0.033179, loss_fp: 0.005859, loss_freq: 0.024620
[15:46:20.557] iteration 21239: loss: 0.061145, loss_s1: 0.035623, loss_fp: 0.010692, loss_freq: 0.047306
[15:46:21.182] iteration 21240: loss: 0.051616, loss_s1: 0.030752, loss_fp: 0.004785, loss_freq: 0.015611
[15:46:21.847] iteration 21241: loss: 0.056782, loss_s1: 0.026208, loss_fp: 0.006460, loss_freq: 0.050074
[15:46:22.502] iteration 21242: loss: 0.037853, loss_s1: 0.017756, loss_fp: 0.001450, loss_freq: 0.008565
[15:46:23.133] iteration 21243: loss: 0.059304, loss_s1: 0.051444, loss_fp: 0.004502, loss_freq: 0.019045
[15:46:23.791] iteration 21244: loss: 0.058744, loss_s1: 0.043139, loss_fp: 0.004479, loss_freq: 0.011404
[15:46:24.426] iteration 21245: loss: 0.072418, loss_s1: 0.042127, loss_fp: 0.002674, loss_freq: 0.051259
[15:46:25.094] iteration 21246: loss: 0.045958, loss_s1: 0.014457, loss_fp: 0.002395, loss_freq: 0.019113
[15:46:25.744] iteration 21247: loss: 0.041407, loss_s1: 0.028506, loss_fp: 0.001386, loss_freq: 0.014029
[15:46:26.381] iteration 21248: loss: 0.049262, loss_s1: 0.039961, loss_fp: 0.001771, loss_freq: 0.026746
[15:46:27.004] iteration 21249: loss: 0.066414, loss_s1: 0.041038, loss_fp: 0.011994, loss_freq: 0.035329
[15:46:27.645] iteration 21250: loss: 0.071017, loss_s1: 0.040209, loss_fp: 0.014503, loss_freq: 0.040945
[15:46:28.271] iteration 21251: loss: 0.067810, loss_s1: 0.061754, loss_fp: 0.001567, loss_freq: 0.007456
[15:46:28.905] iteration 21252: loss: 0.038304, loss_s1: 0.022234, loss_fp: 0.002777, loss_freq: 0.012941
[15:46:29.529] iteration 21253: loss: 0.030799, loss_s1: 0.019278, loss_fp: 0.002236, loss_freq: 0.006622
[15:46:30.182] iteration 21254: loss: 0.083579, loss_s1: 0.077902, loss_fp: 0.002115, loss_freq: 0.045103
[15:46:30.821] iteration 21255: loss: 0.051911, loss_s1: 0.029352, loss_fp: 0.005780, loss_freq: 0.013052
[15:46:31.455] iteration 21256: loss: 0.050719, loss_s1: 0.041409, loss_fp: 0.003499, loss_freq: 0.021379
[15:46:32.086] iteration 21257: loss: 0.052179, loss_s1: 0.041949, loss_fp: 0.001799, loss_freq: 0.012242
[15:46:32.719] iteration 21258: loss: 0.048819, loss_s1: 0.050580, loss_fp: 0.002913, loss_freq: 0.008958
[15:46:33.357] iteration 21259: loss: 0.033885, loss_s1: 0.014837, loss_fp: 0.000428, loss_freq: 0.011381
[15:46:34.018] iteration 21260: loss: 0.075757, loss_s1: 0.037325, loss_fp: 0.002930, loss_freq: 0.062453
[15:46:34.663] iteration 21261: loss: 0.058456, loss_s1: 0.031688, loss_fp: 0.002213, loss_freq: 0.043346
[15:46:35.285] iteration 21262: loss: 0.058685, loss_s1: 0.017332, loss_fp: 0.006817, loss_freq: 0.036817
[15:46:35.903] iteration 21263: loss: 0.064502, loss_s1: 0.050651, loss_fp: 0.001102, loss_freq: 0.027984
[15:46:36.530] iteration 21264: loss: 0.061963, loss_s1: 0.029106, loss_fp: 0.008243, loss_freq: 0.042108
[15:46:37.151] iteration 21265: loss: 0.071695, loss_s1: 0.069594, loss_fp: 0.003514, loss_freq: 0.028593
[15:46:37.774] iteration 21266: loss: 0.054763, loss_s1: 0.032628, loss_fp: 0.002548, loss_freq: 0.034507
[15:46:38.401] iteration 21267: loss: 0.062593, loss_s1: 0.033779, loss_fp: 0.022481, loss_freq: 0.038318
[15:46:39.030] iteration 21268: loss: 0.032882, loss_s1: 0.012166, loss_fp: 0.000865, loss_freq: 0.010019
[15:46:39.676] iteration 21269: loss: 0.046184, loss_s1: 0.014996, loss_fp: 0.000853, loss_freq: 0.015568
[15:46:40.300] iteration 21270: loss: 0.056384, loss_s1: 0.039755, loss_fp: 0.001235, loss_freq: 0.023144
[15:46:40.962] iteration 21271: loss: 0.091360, loss_s1: 0.064291, loss_fp: 0.012603, loss_freq: 0.055714
[15:46:41.600] iteration 21272: loss: 0.059837, loss_s1: 0.023378, loss_fp: 0.006388, loss_freq: 0.057630
[15:46:42.240] iteration 21273: loss: 0.076490, loss_s1: 0.043861, loss_fp: 0.029193, loss_freq: 0.028578
[15:46:42.877] iteration 21274: loss: 0.076614, loss_s1: 0.046076, loss_fp: 0.003171, loss_freq: 0.076359
[15:46:43.506] iteration 21275: loss: 0.040059, loss_s1: 0.025529, loss_fp: 0.001779, loss_freq: 0.013593
[15:46:44.135] iteration 21276: loss: 0.069989, loss_s1: 0.077523, loss_fp: 0.003097, loss_freq: 0.031652
[15:46:44.814] iteration 21277: loss: 0.054288, loss_s1: 0.021671, loss_fp: 0.005218, loss_freq: 0.026444
[15:46:45.430] iteration 21278: loss: 0.089277, loss_s1: 0.078154, loss_fp: 0.023624, loss_freq: 0.031037
[15:46:46.077] iteration 21279: loss: 0.084981, loss_s1: 0.082790, loss_fp: 0.000871, loss_freq: 0.030014
[15:46:46.693] iteration 21280: loss: 0.041815, loss_s1: 0.014616, loss_fp: 0.002917, loss_freq: 0.034608
[15:46:47.319] iteration 21281: loss: 0.068194, loss_s1: 0.038436, loss_fp: 0.009839, loss_freq: 0.044338
[15:46:47.940] iteration 21282: loss: 0.067841, loss_s1: 0.070239, loss_fp: 0.003503, loss_freq: 0.023827
[15:46:48.569] iteration 21283: loss: 0.059862, loss_s1: 0.066370, loss_fp: 0.007316, loss_freq: 0.011760
[15:46:49.190] iteration 21284: loss: 0.067813, loss_s1: 0.044929, loss_fp: 0.001707, loss_freq: 0.045397
[15:46:49.816] iteration 21285: loss: 0.068664, loss_s1: 0.047002, loss_fp: 0.008028, loss_freq: 0.028012
[15:46:50.433] iteration 21286: loss: 0.066974, loss_s1: 0.054194, loss_fp: 0.002541, loss_freq: 0.029655
[15:46:51.055] iteration 21287: loss: 0.058532, loss_s1: 0.022197, loss_fp: 0.011290, loss_freq: 0.007878
[15:46:51.673] iteration 21288: loss: 0.053496, loss_s1: 0.027889, loss_fp: 0.004841, loss_freq: 0.036813
[15:46:52.291] iteration 21289: loss: 0.047239, loss_s1: 0.039721, loss_fp: 0.007252, loss_freq: 0.011576
[15:46:52.907] iteration 21290: loss: 0.048015, loss_s1: 0.021888, loss_fp: 0.001166, loss_freq: 0.012874
[15:46:53.532] iteration 21291: loss: 0.039924, loss_s1: 0.022862, loss_fp: 0.000243, loss_freq: 0.022868
[15:46:54.147] iteration 21292: loss: 0.042215, loss_s1: 0.029602, loss_fp: 0.001862, loss_freq: 0.017779
[15:46:54.775] iteration 21293: loss: 0.051636, loss_s1: 0.035786, loss_fp: 0.001752, loss_freq: 0.018606
[15:46:55.484] iteration 21294: loss: 0.049772, loss_s1: 0.029714, loss_fp: 0.005775, loss_freq: 0.024668
[15:46:56.110] iteration 21295: loss: 0.048541, loss_s1: 0.025417, loss_fp: 0.005112, loss_freq: 0.017535
[15:46:56.733] iteration 21296: loss: 0.051482, loss_s1: 0.035673, loss_fp: 0.002995, loss_freq: 0.023477
[15:46:57.364] iteration 21297: loss: 0.044906, loss_s1: 0.033448, loss_fp: 0.004984, loss_freq: 0.011166
[15:46:57.987] iteration 21298: loss: 0.069848, loss_s1: 0.026765, loss_fp: 0.005459, loss_freq: 0.045295
[15:46:58.609] iteration 21299: loss: 0.073389, loss_s1: 0.049641, loss_fp: 0.009074, loss_freq: 0.033158
[15:46:59.236] iteration 21300: loss: 0.051488, loss_s1: 0.031408, loss_fp: 0.004317, loss_freq: 0.036057
[15:46:59.861] iteration 21301: loss: 0.069743, loss_s1: 0.058523, loss_fp: 0.004260, loss_freq: 0.023380
[15:47:00.494] iteration 21302: loss: 0.046161, loss_s1: 0.032202, loss_fp: 0.002706, loss_freq: 0.024206
[15:47:01.119] iteration 21303: loss: 0.055946, loss_s1: 0.045967, loss_fp: 0.002619, loss_freq: 0.024863
[15:47:01.797] iteration 21304: loss: 0.064112, loss_s1: 0.036686, loss_fp: 0.003895, loss_freq: 0.026565
[15:47:02.445] iteration 21305: loss: 0.072647, loss_s1: 0.066167, loss_fp: 0.004531, loss_freq: 0.034157
[15:47:03.075] iteration 21306: loss: 0.066562, loss_s1: 0.052442, loss_fp: 0.002069, loss_freq: 0.034025
[15:47:03.714] iteration 21307: loss: 0.053036, loss_s1: 0.028019, loss_fp: 0.003365, loss_freq: 0.037393
[15:47:04.680] iteration 21308: loss: 0.041623, loss_s1: 0.023820, loss_fp: 0.001696, loss_freq: 0.021044
[15:47:05.369] iteration 21309: loss: 0.083830, loss_s1: 0.084134, loss_fp: 0.001238, loss_freq: 0.040716
[15:47:06.005] iteration 21310: loss: 0.042341, loss_s1: 0.024544, loss_fp: 0.001517, loss_freq: 0.027171
[15:47:06.619] iteration 21311: loss: 0.062558, loss_s1: 0.037461, loss_fp: 0.002530, loss_freq: 0.038214
[15:47:07.240] iteration 21312: loss: 0.048539, loss_s1: 0.018523, loss_fp: 0.003896, loss_freq: 0.042516
[15:47:07.886] iteration 21313: loss: 0.069040, loss_s1: 0.029589, loss_fp: 0.001820, loss_freq: 0.003577
[15:47:08.535] iteration 21314: loss: 0.043912, loss_s1: 0.022041, loss_fp: 0.006712, loss_freq: 0.017375
[15:47:09.191] iteration 21315: loss: 0.049707, loss_s1: 0.032183, loss_fp: 0.004547, loss_freq: 0.013124
[15:47:09.844] iteration 21316: loss: 0.045209, loss_s1: 0.031976, loss_fp: 0.003380, loss_freq: 0.017671
[15:47:10.493] iteration 21317: loss: 0.030731, loss_s1: 0.005829, loss_fp: 0.001056, loss_freq: 0.006440
[15:47:11.140] iteration 21318: loss: 0.052882, loss_s1: 0.019868, loss_fp: 0.006123, loss_freq: 0.035081
[15:47:11.787] iteration 21319: loss: 0.038255, loss_s1: 0.019896, loss_fp: 0.002998, loss_freq: 0.014251
[15:47:12.405] iteration 21320: loss: 0.051063, loss_s1: 0.034343, loss_fp: 0.000723, loss_freq: 0.025477
[15:47:13.060] iteration 21321: loss: 0.039960, loss_s1: 0.025533, loss_fp: 0.001910, loss_freq: 0.017529
[15:47:13.682] iteration 21322: loss: 0.061303, loss_s1: 0.045574, loss_fp: 0.001555, loss_freq: 0.036932
[15:47:14.304] iteration 21323: loss: 0.042583, loss_s1: 0.016373, loss_fp: 0.009433, loss_freq: 0.010413
[15:47:14.932] iteration 21324: loss: 0.046851, loss_s1: 0.021665, loss_fp: 0.009098, loss_freq: 0.007798
[15:47:15.550] iteration 21325: loss: 0.064083, loss_s1: 0.036750, loss_fp: 0.002319, loss_freq: 0.024922
[15:47:16.180] iteration 21326: loss: 0.050198, loss_s1: 0.030721, loss_fp: 0.000861, loss_freq: 0.041497
[15:47:16.813] iteration 21327: loss: 0.038222, loss_s1: 0.030212, loss_fp: 0.000836, loss_freq: 0.012099
[15:47:17.451] iteration 21328: loss: 0.058058, loss_s1: 0.034213, loss_fp: 0.001575, loss_freq: 0.035116
[15:47:18.081] iteration 21329: loss: 0.042930, loss_s1: 0.024882, loss_fp: 0.003529, loss_freq: 0.028360
[15:47:18.706] iteration 21330: loss: 0.032093, loss_s1: 0.016532, loss_fp: 0.003784, loss_freq: 0.014422
[15:47:19.328] iteration 21331: loss: 0.036678, loss_s1: 0.028486, loss_fp: 0.000766, loss_freq: 0.010425
[15:47:19.960] iteration 21332: loss: 0.063328, loss_s1: 0.051831, loss_fp: 0.004813, loss_freq: 0.021742
[15:47:20.583] iteration 21333: loss: 0.063441, loss_s1: 0.037925, loss_fp: 0.001899, loss_freq: 0.027365
[15:47:21.250] iteration 21334: loss: 0.070253, loss_s1: 0.062669, loss_fp: 0.005004, loss_freq: 0.029875
[15:47:21.894] iteration 21335: loss: 0.057332, loss_s1: 0.056810, loss_fp: 0.003296, loss_freq: 0.010132
[15:47:22.517] iteration 21336: loss: 0.044337, loss_s1: 0.024797, loss_fp: 0.002375, loss_freq: 0.012509
[15:47:23.139] iteration 21337: loss: 0.055109, loss_s1: 0.028148, loss_fp: 0.004830, loss_freq: 0.015252
[15:47:23.759] iteration 21338: loss: 0.045788, loss_s1: 0.037215, loss_fp: 0.003371, loss_freq: 0.008948
[15:47:24.384] iteration 21339: loss: 0.049536, loss_s1: 0.018798, loss_fp: 0.002058, loss_freq: 0.022502
[15:47:25.007] iteration 21340: loss: 0.053129, loss_s1: 0.033491, loss_fp: 0.005064, loss_freq: 0.033095
[15:47:25.622] iteration 21341: loss: 0.075526, loss_s1: 0.057560, loss_fp: 0.015536, loss_freq: 0.039149
[15:47:26.244] iteration 21342: loss: 0.051480, loss_s1: 0.038319, loss_fp: 0.008259, loss_freq: 0.018328
[15:47:26.907] iteration 21343: loss: 0.058906, loss_s1: 0.061905, loss_fp: 0.003270, loss_freq: 0.010488
[15:47:27.571] iteration 21344: loss: 0.042343, loss_s1: 0.024798, loss_fp: 0.002172, loss_freq: 0.010271
[15:47:28.200] iteration 21345: loss: 0.067946, loss_s1: 0.061039, loss_fp: 0.002085, loss_freq: 0.039413
[15:47:28.824] iteration 21346: loss: 0.075531, loss_s1: 0.040877, loss_fp: 0.007648, loss_freq: 0.046612
[15:47:29.470] iteration 21347: loss: 0.032619, loss_s1: 0.021069, loss_fp: 0.003293, loss_freq: 0.012882
[15:47:30.119] iteration 21348: loss: 0.049935, loss_s1: 0.028308, loss_fp: 0.001481, loss_freq: 0.022159
[15:47:30.737] iteration 21349: loss: 0.034252, loss_s1: 0.013556, loss_fp: 0.001905, loss_freq: 0.016873
[15:47:31.354] iteration 21350: loss: 0.047606, loss_s1: 0.028405, loss_fp: 0.001710, loss_freq: 0.012357
[15:47:31.973] iteration 21351: loss: 0.095358, loss_s1: 0.092180, loss_fp: 0.009066, loss_freq: 0.054095
[15:47:32.591] iteration 21352: loss: 0.051905, loss_s1: 0.030968, loss_fp: 0.005812, loss_freq: 0.009234
[15:47:33.203] iteration 21353: loss: 0.065688, loss_s1: 0.068635, loss_fp: 0.003445, loss_freq: 0.024084
[15:47:33.823] iteration 21354: loss: 0.048017, loss_s1: 0.010522, loss_fp: 0.003978, loss_freq: 0.041549
[15:47:34.444] iteration 21355: loss: 0.053481, loss_s1: 0.062337, loss_fp: 0.001744, loss_freq: 0.010029
[15:47:35.064] iteration 21356: loss: 0.074592, loss_s1: 0.075185, loss_fp: 0.003772, loss_freq: 0.038729
[15:47:35.682] iteration 21357: loss: 0.053291, loss_s1: 0.042990, loss_fp: 0.000874, loss_freq: 0.021202
[15:47:36.301] iteration 21358: loss: 0.067674, loss_s1: 0.072685, loss_fp: 0.003987, loss_freq: 0.017573
[15:47:36.923] iteration 21359: loss: 0.055305, loss_s1: 0.031754, loss_fp: 0.000735, loss_freq: 0.020350
[15:47:37.607] iteration 21360: loss: 0.055953, loss_s1: 0.028534, loss_fp: 0.003791, loss_freq: 0.013925
[15:47:38.309] iteration 21361: loss: 0.041238, loss_s1: 0.028283, loss_fp: 0.003626, loss_freq: 0.018339
[15:47:39.038] iteration 21362: loss: 0.026246, loss_s1: 0.017178, loss_fp: 0.001095, loss_freq: 0.003780
[15:47:39.706] iteration 21363: loss: 0.046046, loss_s1: 0.015140, loss_fp: 0.000694, loss_freq: 0.007829
[15:47:40.345] iteration 21364: loss: 0.044345, loss_s1: 0.029022, loss_fp: 0.000726, loss_freq: 0.025045
[15:47:41.015] iteration 21365: loss: 0.030002, loss_s1: 0.010538, loss_fp: 0.000893, loss_freq: 0.014221
[15:47:41.638] iteration 21366: loss: 0.083251, loss_s1: 0.043651, loss_fp: 0.001984, loss_freq: 0.086519
[15:47:42.265] iteration 21367: loss: 0.042440, loss_s1: 0.017806, loss_fp: 0.001991, loss_freq: 0.024872
[15:47:42.905] iteration 21368: loss: 0.035573, loss_s1: 0.024019, loss_fp: 0.003327, loss_freq: 0.009570
[15:47:43.571] iteration 21369: loss: 0.070149, loss_s1: 0.079669, loss_fp: 0.000723, loss_freq: 0.023018
[15:47:44.232] iteration 21370: loss: 0.071618, loss_s1: 0.065399, loss_fp: 0.010211, loss_freq: 0.024690
[15:47:44.909] iteration 21371: loss: 0.043291, loss_s1: 0.020221, loss_fp: 0.002842, loss_freq: 0.017765
[15:47:45.567] iteration 21372: loss: 0.049943, loss_s1: 0.014425, loss_fp: 0.004570, loss_freq: 0.012743
[15:47:46.225] iteration 21373: loss: 0.048257, loss_s1: 0.044864, loss_fp: 0.001157, loss_freq: 0.010024
[15:47:46.864] iteration 21374: loss: 0.098731, loss_s1: 0.041626, loss_fp: 0.004307, loss_freq: 0.101884
[15:47:47.504] iteration 21375: loss: 0.056156, loss_s1: 0.034983, loss_fp: 0.001764, loss_freq: 0.040923
[15:47:48.134] iteration 21376: loss: 0.050091, loss_s1: 0.031544, loss_fp: 0.003195, loss_freq: 0.022287
[15:47:48.805] iteration 21377: loss: 0.034509, loss_s1: 0.018925, loss_fp: 0.000878, loss_freq: 0.003477
[15:47:49.429] iteration 21378: loss: 0.047022, loss_s1: 0.035542, loss_fp: 0.004181, loss_freq: 0.014515
[15:47:50.053] iteration 21379: loss: 0.073102, loss_s1: 0.078377, loss_fp: 0.008399, loss_freq: 0.017246
[15:47:50.673] iteration 21380: loss: 0.052746, loss_s1: 0.015817, loss_fp: 0.000959, loss_freq: 0.061359
[15:47:51.293] iteration 21381: loss: 0.048725, loss_s1: 0.013059, loss_fp: 0.004828, loss_freq: 0.025333
[15:47:51.911] iteration 21382: loss: 0.051399, loss_s1: 0.019298, loss_fp: 0.004346, loss_freq: 0.048317
[15:47:52.534] iteration 21383: loss: 0.076517, loss_s1: 0.034426, loss_fp: 0.001831, loss_freq: 0.013009
[15:47:53.152] iteration 21384: loss: 0.044747, loss_s1: 0.050637, loss_fp: 0.002338, loss_freq: 0.009560
[15:47:53.780] iteration 21385: loss: 0.042788, loss_s1: 0.026218, loss_fp: 0.002152, loss_freq: 0.013076
[15:47:54.402] iteration 21386: loss: 0.039952, loss_s1: 0.014774, loss_fp: 0.004976, loss_freq: 0.020495
[15:47:55.027] iteration 21387: loss: 0.117433, loss_s1: 0.058262, loss_fp: 0.013899, loss_freq: 0.066901
[15:47:55.654] iteration 21388: loss: 0.056881, loss_s1: 0.050437, loss_fp: 0.002696, loss_freq: 0.021459
[15:47:56.268] iteration 21389: loss: 0.050222, loss_s1: 0.040309, loss_fp: 0.006726, loss_freq: 0.004974
[15:47:56.890] iteration 21390: loss: 0.045773, loss_s1: 0.044504, loss_fp: 0.002020, loss_freq: 0.006340
[15:47:57.507] iteration 21391: loss: 0.046056, loss_s1: 0.043667, loss_fp: 0.003603, loss_freq: 0.012909
[15:47:58.152] iteration 21392: loss: 0.069829, loss_s1: 0.066074, loss_fp: 0.004498, loss_freq: 0.027252
[15:47:58.778] iteration 21393: loss: 0.052574, loss_s1: 0.022164, loss_fp: 0.007857, loss_freq: 0.029959
[15:47:59.405] iteration 21394: loss: 0.055178, loss_s1: 0.042806, loss_fp: 0.001500, loss_freq: 0.028706
[15:48:00.031] iteration 21395: loss: 0.029414, loss_s1: 0.009623, loss_fp: 0.001732, loss_freq: 0.005573
[15:48:00.657] iteration 21396: loss: 0.056878, loss_s1: 0.064921, loss_fp: 0.002930, loss_freq: 0.018923
[15:48:01.280] iteration 21397: loss: 0.069995, loss_s1: 0.051159, loss_fp: 0.008903, loss_freq: 0.042150
[15:48:01.902] iteration 21398: loss: 0.085190, loss_s1: 0.043396, loss_fp: 0.006923, loss_freq: 0.015705
[15:48:02.515] iteration 21399: loss: 0.044190, loss_s1: 0.016996, loss_fp: 0.002614, loss_freq: 0.023873
[15:48:03.189] iteration 21400: loss: 0.045806, loss_s1: 0.034635, loss_fp: 0.002200, loss_freq: 0.010510
[15:48:06.594] iteration 21400 : mean_dice : 0.783218
[15:48:07.247] iteration 21401: loss: 0.048629, loss_s1: 0.029400, loss_fp: 0.016104, loss_freq: 0.009688
[15:48:07.877] iteration 21402: loss: 0.041789, loss_s1: 0.028847, loss_fp: 0.004162, loss_freq: 0.016119
[15:48:08.506] iteration 21403: loss: 0.066876, loss_s1: 0.054490, loss_fp: 0.003885, loss_freq: 0.036201
[15:48:09.198] iteration 21404: loss: 0.101768, loss_s1: 0.058383, loss_fp: 0.012745, loss_freq: 0.052417
[15:48:09.827] iteration 21405: loss: 0.060350, loss_s1: 0.026906, loss_fp: 0.001473, loss_freq: 0.029785
[15:48:10.503] iteration 21406: loss: 0.071759, loss_s1: 0.059441, loss_fp: 0.006418, loss_freq: 0.029887
[15:48:11.113] iteration 21407: loss: 0.077260, loss_s1: 0.071031, loss_fp: 0.003752, loss_freq: 0.028000
[15:48:11.733] iteration 21408: loss: 0.049280, loss_s1: 0.036502, loss_fp: 0.004756, loss_freq: 0.019621
[15:48:12.351] iteration 21409: loss: 0.081216, loss_s1: 0.065375, loss_fp: 0.001915, loss_freq: 0.034505
[15:48:12.972] iteration 21410: loss: 0.075548, loss_s1: 0.058547, loss_fp: 0.000727, loss_freq: 0.047566
[15:48:13.596] iteration 21411: loss: 0.038092, loss_s1: 0.015472, loss_fp: 0.003563, loss_freq: 0.018664
[15:48:14.219] iteration 21412: loss: 0.040017, loss_s1: 0.016919, loss_fp: 0.001564, loss_freq: 0.010935
[15:48:14.864] iteration 21413: loss: 0.056045, loss_s1: 0.015809, loss_fp: 0.002597, loss_freq: 0.023088
[15:48:15.483] iteration 21414: loss: 0.102322, loss_s1: 0.111736, loss_fp: 0.006141, loss_freq: 0.033643
[15:48:16.105] iteration 21415: loss: 0.085199, loss_s1: 0.095066, loss_fp: 0.003015, loss_freq: 0.033372
[15:48:16.724] iteration 21416: loss: 0.064551, loss_s1: 0.055957, loss_fp: 0.001821, loss_freq: 0.034898
[15:48:17.359] iteration 21417: loss: 0.029337, loss_s1: 0.012190, loss_fp: 0.002073, loss_freq: 0.015361
[15:48:18.000] iteration 21418: loss: 0.054481, loss_s1: 0.013458, loss_fp: 0.007181, loss_freq: 0.010043
[15:48:18.705] iteration 21419: loss: 0.065674, loss_s1: 0.047836, loss_fp: 0.021687, loss_freq: 0.030770
[15:48:19.333] iteration 21420: loss: 0.049580, loss_s1: 0.031748, loss_fp: 0.001395, loss_freq: 0.012914
[15:48:19.960] iteration 21421: loss: 0.069171, loss_s1: 0.034276, loss_fp: 0.002913, loss_freq: 0.048863
[15:48:20.589] iteration 21422: loss: 0.043361, loss_s1: 0.004521, loss_fp: 0.002419, loss_freq: 0.008073
[15:48:21.210] iteration 21423: loss: 0.043395, loss_s1: 0.025121, loss_fp: 0.000534, loss_freq: 0.018272
[15:48:21.826] iteration 21424: loss: 0.059034, loss_s1: 0.039237, loss_fp: 0.003791, loss_freq: 0.028255
[15:48:22.451] iteration 21425: loss: 0.061329, loss_s1: 0.062251, loss_fp: 0.001251, loss_freq: 0.017475
[15:48:23.073] iteration 21426: loss: 0.035271, loss_s1: 0.023182, loss_fp: 0.001220, loss_freq: 0.012012
[15:48:23.696] iteration 21427: loss: 0.042407, loss_s1: 0.015489, loss_fp: 0.002948, loss_freq: 0.021977
[15:48:24.314] iteration 21428: loss: 0.086392, loss_s1: 0.059814, loss_fp: 0.004651, loss_freq: 0.062828
[15:48:24.936] iteration 21429: loss: 0.064125, loss_s1: 0.053478, loss_fp: 0.003283, loss_freq: 0.032183
[15:48:25.555] iteration 21430: loss: 0.055560, loss_s1: 0.039079, loss_fp: 0.000708, loss_freq: 0.010119
[15:48:26.177] iteration 21431: loss: 0.047770, loss_s1: 0.027239, loss_fp: 0.006334, loss_freq: 0.035848
[15:48:26.802] iteration 21432: loss: 0.062473, loss_s1: 0.062586, loss_fp: 0.002948, loss_freq: 0.020539
[15:48:27.425] iteration 21433: loss: 0.049140, loss_s1: 0.028037, loss_fp: 0.005712, loss_freq: 0.010914
[15:48:28.047] iteration 21434: loss: 0.059779, loss_s1: 0.050560, loss_fp: 0.002565, loss_freq: 0.035664
[15:48:28.667] iteration 21435: loss: 0.040108, loss_s1: 0.015534, loss_fp: 0.009886, loss_freq: 0.022712
[15:48:29.288] iteration 21436: loss: 0.058137, loss_s1: 0.051610, loss_fp: 0.001838, loss_freq: 0.015480
[15:48:29.914] iteration 21437: loss: 0.029761, loss_s1: 0.014157, loss_fp: 0.001070, loss_freq: 0.006145
[15:48:30.541] iteration 21438: loss: 0.063801, loss_s1: 0.038144, loss_fp: 0.004027, loss_freq: 0.023979
[15:48:31.163] iteration 21439: loss: 0.070140, loss_s1: 0.045775, loss_fp: 0.004261, loss_freq: 0.017687
[15:48:31.785] iteration 21440: loss: 0.040531, loss_s1: 0.025407, loss_fp: 0.006431, loss_freq: 0.008548
[15:48:32.411] iteration 21441: loss: 0.064879, loss_s1: 0.038967, loss_fp: 0.004229, loss_freq: 0.039661
[15:48:33.080] iteration 21442: loss: 0.049373, loss_s1: 0.010819, loss_fp: 0.007519, loss_freq: 0.035504
[15:48:33.707] iteration 21443: loss: 0.056846, loss_s1: 0.032293, loss_fp: 0.008364, loss_freq: 0.026900
[15:48:34.329] iteration 21444: loss: 0.092305, loss_s1: 0.094248, loss_fp: 0.006929, loss_freq: 0.038540
[15:48:34.947] iteration 21445: loss: 0.033272, loss_s1: 0.021975, loss_fp: 0.000517, loss_freq: 0.008270
[15:48:35.560] iteration 21446: loss: 0.059997, loss_s1: 0.032271, loss_fp: 0.003575, loss_freq: 0.018961
[15:48:36.181] iteration 21447: loss: 0.062200, loss_s1: 0.050942, loss_fp: 0.001732, loss_freq: 0.014592
[15:48:36.800] iteration 21448: loss: 0.057152, loss_s1: 0.043985, loss_fp: 0.003057, loss_freq: 0.030800
[15:48:37.417] iteration 21449: loss: 0.147392, loss_s1: 0.183406, loss_fp: 0.014776, loss_freq: 0.054350
[15:48:38.032] iteration 21450: loss: 0.046601, loss_s1: 0.013230, loss_fp: 0.004230, loss_freq: 0.034464
[15:48:38.997] iteration 21451: loss: 0.035421, loss_s1: 0.028910, loss_fp: 0.001040, loss_freq: 0.004917
[15:48:39.681] iteration 21452: loss: 0.066166, loss_s1: 0.059606, loss_fp: 0.003828, loss_freq: 0.026138
[15:48:40.329] iteration 21453: loss: 0.031805, loss_s1: 0.013303, loss_fp: 0.000813, loss_freq: 0.020319
[15:48:40.971] iteration 21454: loss: 0.080886, loss_s1: 0.044116, loss_fp: 0.002378, loss_freq: 0.056745
[15:48:41.643] iteration 21455: loss: 0.039956, loss_s1: 0.021351, loss_fp: 0.001238, loss_freq: 0.024724
[15:48:42.353] iteration 21456: loss: 0.047746, loss_s1: 0.047150, loss_fp: 0.000779, loss_freq: 0.003676
[15:48:43.037] iteration 21457: loss: 0.042723, loss_s1: 0.028998, loss_fp: 0.012674, loss_freq: 0.013099
[15:48:43.707] iteration 21458: loss: 0.062426, loss_s1: 0.036345, loss_fp: 0.002669, loss_freq: 0.023947
[15:48:44.440] iteration 21459: loss: 0.046730, loss_s1: 0.027049, loss_fp: 0.007116, loss_freq: 0.021493
[15:48:45.097] iteration 21460: loss: 0.040462, loss_s1: 0.012215, loss_fp: 0.003769, loss_freq: 0.009195
[15:48:45.718] iteration 21461: loss: 0.079726, loss_s1: 0.077490, loss_fp: 0.001207, loss_freq: 0.039410
[15:48:46.349] iteration 21462: loss: 0.058019, loss_s1: 0.034055, loss_fp: 0.007479, loss_freq: 0.023222
[15:48:46.970] iteration 21463: loss: 0.055106, loss_s1: 0.057061, loss_fp: 0.002593, loss_freq: 0.007832
[15:48:47.597] iteration 21464: loss: 0.040190, loss_s1: 0.019202, loss_fp: 0.002426, loss_freq: 0.013433
[15:48:48.229] iteration 21465: loss: 0.075934, loss_s1: 0.063683, loss_fp: 0.010570, loss_freq: 0.030284
[15:48:48.865] iteration 21466: loss: 0.052915, loss_s1: 0.030680, loss_fp: 0.012597, loss_freq: 0.026613
[15:48:49.525] iteration 21467: loss: 0.061272, loss_s1: 0.036928, loss_fp: 0.000974, loss_freq: 0.022212
[15:48:50.154] iteration 21468: loss: 0.041618, loss_s1: 0.032988, loss_fp: 0.000642, loss_freq: 0.012062
[15:48:50.777] iteration 21469: loss: 0.054086, loss_s1: 0.037941, loss_fp: 0.002439, loss_freq: 0.031092
[15:48:51.389] iteration 21470: loss: 0.035894, loss_s1: 0.021831, loss_fp: 0.008130, loss_freq: 0.013899
[15:48:52.001] iteration 21471: loss: 0.067418, loss_s1: 0.035908, loss_fp: 0.006567, loss_freq: 0.042671
[15:48:52.618] iteration 21472: loss: 0.041937, loss_s1: 0.022584, loss_fp: 0.001400, loss_freq: 0.020487
[15:48:53.243] iteration 21473: loss: 0.092967, loss_s1: 0.084059, loss_fp: 0.001031, loss_freq: 0.046008
[15:48:53.871] iteration 21474: loss: 0.053687, loss_s1: 0.050827, loss_fp: 0.000542, loss_freq: 0.019137
[15:48:54.488] iteration 21475: loss: 0.042674, loss_s1: 0.016891, loss_fp: 0.008772, loss_freq: 0.018684
[15:48:55.105] iteration 21476: loss: 0.070388, loss_s1: 0.069387, loss_fp: 0.002151, loss_freq: 0.025534
[15:48:55.727] iteration 21477: loss: 0.056471, loss_s1: 0.029159, loss_fp: 0.002087, loss_freq: 0.033094
[15:48:56.352] iteration 21478: loss: 0.039180, loss_s1: 0.021157, loss_fp: 0.002842, loss_freq: 0.013451
[15:48:56.975] iteration 21479: loss: 0.065157, loss_s1: 0.057149, loss_fp: 0.002766, loss_freq: 0.023629
[15:48:57.644] iteration 21480: loss: 0.059428, loss_s1: 0.038489, loss_fp: 0.002231, loss_freq: 0.017623
[15:48:58.280] iteration 21481: loss: 0.037081, loss_s1: 0.027347, loss_fp: 0.001761, loss_freq: 0.006454
[15:48:58.954] iteration 21482: loss: 0.062755, loss_s1: 0.047162, loss_fp: 0.006795, loss_freq: 0.030414
[15:48:59.570] iteration 21483: loss: 0.066787, loss_s1: 0.060070, loss_fp: 0.009314, loss_freq: 0.034629
[15:49:00.191] iteration 21484: loss: 0.113705, loss_s1: 0.120515, loss_fp: 0.004472, loss_freq: 0.049948
[15:49:00.811] iteration 21485: loss: 0.081128, loss_s1: 0.052183, loss_fp: 0.004289, loss_freq: 0.025939
[15:49:01.483] iteration 21486: loss: 0.052053, loss_s1: 0.034496, loss_fp: 0.005740, loss_freq: 0.015872
[15:49:02.141] iteration 21487: loss: 0.048746, loss_s1: 0.027166, loss_fp: 0.003442, loss_freq: 0.018597
[15:49:02.772] iteration 21488: loss: 0.057370, loss_s1: 0.053660, loss_fp: 0.000652, loss_freq: 0.021756
[15:49:03.396] iteration 21489: loss: 0.051581, loss_s1: 0.035052, loss_fp: 0.003937, loss_freq: 0.018778
[15:49:04.013] iteration 21490: loss: 0.033070, loss_s1: 0.018119, loss_fp: 0.003989, loss_freq: 0.016260
[15:49:04.639] iteration 21491: loss: 0.080941, loss_s1: 0.027161, loss_fp: 0.004145, loss_freq: 0.019370
[15:49:05.263] iteration 21492: loss: 0.062741, loss_s1: 0.055840, loss_fp: 0.006411, loss_freq: 0.034099
[15:49:05.882] iteration 21493: loss: 0.057730, loss_s1: 0.026155, loss_fp: 0.001890, loss_freq: 0.040617
[15:49:06.518] iteration 21494: loss: 0.054013, loss_s1: 0.040141, loss_fp: 0.013586, loss_freq: 0.010946
[15:49:07.147] iteration 21495: loss: 0.054931, loss_s1: 0.018573, loss_fp: 0.011068, loss_freq: 0.019141
[15:49:07.766] iteration 21496: loss: 0.077620, loss_s1: 0.040454, loss_fp: 0.007763, loss_freq: 0.053413
[15:49:08.389] iteration 21497: loss: 0.056180, loss_s1: 0.015721, loss_fp: 0.006191, loss_freq: 0.029283
[15:49:09.058] iteration 21498: loss: 0.051412, loss_s1: 0.028561, loss_fp: 0.004500, loss_freq: 0.025650
[15:49:09.676] iteration 21499: loss: 0.056995, loss_s1: 0.032462, loss_fp: 0.007126, loss_freq: 0.031921
[15:49:10.360] iteration 21500: loss: 0.038417, loss_s1: 0.014241, loss_fp: 0.004522, loss_freq: 0.018412
[15:49:10.981] iteration 21501: loss: 0.073432, loss_s1: 0.068521, loss_fp: 0.005544, loss_freq: 0.032147
[15:49:11.612] iteration 21502: loss: 0.089932, loss_s1: 0.066442, loss_fp: 0.010706, loss_freq: 0.051453
[15:49:12.247] iteration 21503: loss: 0.050404, loss_s1: 0.040711, loss_fp: 0.001183, loss_freq: 0.016356
[15:49:12.863] iteration 21504: loss: 0.050338, loss_s1: 0.036108, loss_fp: 0.004917, loss_freq: 0.025421
[15:49:13.485] iteration 21505: loss: 0.040962, loss_s1: 0.039262, loss_fp: 0.002672, loss_freq: 0.008654
[15:49:14.109] iteration 21506: loss: 0.060093, loss_s1: 0.046346, loss_fp: 0.002654, loss_freq: 0.020396
[15:49:14.732] iteration 21507: loss: 0.088325, loss_s1: 0.101075, loss_fp: 0.000585, loss_freq: 0.040078
[15:49:15.351] iteration 21508: loss: 0.072340, loss_s1: 0.084913, loss_fp: 0.003760, loss_freq: 0.025042
[15:49:15.976] iteration 21509: loss: 0.078579, loss_s1: 0.031387, loss_fp: 0.007447, loss_freq: 0.069014
[15:49:16.599] iteration 21510: loss: 0.053199, loss_s1: 0.041303, loss_fp: 0.000846, loss_freq: 0.023732
[15:49:17.215] iteration 21511: loss: 0.050397, loss_s1: 0.041959, loss_fp: 0.001637, loss_freq: 0.014786
[15:49:17.839] iteration 21512: loss: 0.054326, loss_s1: 0.030830, loss_fp: 0.011621, loss_freq: 0.010462
[15:49:18.462] iteration 21513: loss: 0.079329, loss_s1: 0.059713, loss_fp: 0.003957, loss_freq: 0.058834
[15:49:19.088] iteration 21514: loss: 0.058217, loss_s1: 0.041625, loss_fp: 0.000995, loss_freq: 0.021133
[15:49:19.703] iteration 21515: loss: 0.082579, loss_s1: 0.047380, loss_fp: 0.000977, loss_freq: 0.017054
[15:49:20.323] iteration 21516: loss: 0.053442, loss_s1: 0.055549, loss_fp: 0.000904, loss_freq: 0.014731
[15:49:20.948] iteration 21517: loss: 0.076861, loss_s1: 0.073501, loss_fp: 0.007609, loss_freq: 0.028198
[15:49:21.576] iteration 21518: loss: 0.051541, loss_s1: 0.033263, loss_fp: 0.007390, loss_freq: 0.025846
[15:49:22.199] iteration 21519: loss: 0.059211, loss_s1: 0.066227, loss_fp: 0.005549, loss_freq: 0.014044
[15:49:22.819] iteration 21520: loss: 0.054761, loss_s1: 0.026339, loss_fp: 0.003195, loss_freq: 0.005195
[15:49:23.443] iteration 21521: loss: 0.066714, loss_s1: 0.062459, loss_fp: 0.001335, loss_freq: 0.016710
[15:49:24.063] iteration 21522: loss: 0.064835, loss_s1: 0.041305, loss_fp: 0.006387, loss_freq: 0.032483
[15:49:24.682] iteration 21523: loss: 0.081009, loss_s1: 0.035281, loss_fp: 0.002718, loss_freq: 0.084229
[15:49:25.302] iteration 21524: loss: 0.099753, loss_s1: 0.086797, loss_fp: 0.004767, loss_freq: 0.049468
[15:49:25.918] iteration 21525: loss: 0.096947, loss_s1: 0.112476, loss_fp: 0.004969, loss_freq: 0.045704
[15:49:26.532] iteration 21526: loss: 0.083899, loss_s1: 0.033755, loss_fp: 0.003235, loss_freq: 0.037864
[15:49:27.153] iteration 21527: loss: 0.053875, loss_s1: 0.051791, loss_fp: 0.009501, loss_freq: 0.016730
[15:49:27.819] iteration 21528: loss: 0.041133, loss_s1: 0.015256, loss_fp: 0.001346, loss_freq: 0.014977
[15:49:28.441] iteration 21529: loss: 0.087056, loss_s1: 0.091624, loss_fp: 0.010847, loss_freq: 0.036439
[15:49:29.067] iteration 21530: loss: 0.101097, loss_s1: 0.073005, loss_fp: 0.006987, loss_freq: 0.052562
[15:49:29.688] iteration 21531: loss: 0.066390, loss_s1: 0.051203, loss_fp: 0.002376, loss_freq: 0.024682
[15:49:30.310] iteration 21532: loss: 0.060328, loss_s1: 0.053154, loss_fp: 0.003738, loss_freq: 0.013800
[15:49:30.928] iteration 21533: loss: 0.048475, loss_s1: 0.043240, loss_fp: 0.004167, loss_freq: 0.014448
[15:49:31.543] iteration 21534: loss: 0.047054, loss_s1: 0.035461, loss_fp: 0.001604, loss_freq: 0.021225
[15:49:32.165] iteration 21535: loss: 0.058653, loss_s1: 0.048226, loss_fp: 0.003150, loss_freq: 0.017921
[15:49:32.788] iteration 21536: loss: 0.086123, loss_s1: 0.055102, loss_fp: 0.004550, loss_freq: 0.050027
[15:49:33.402] iteration 21537: loss: 0.049004, loss_s1: 0.042657, loss_fp: 0.012972, loss_freq: 0.008505
[15:49:34.020] iteration 21538: loss: 0.025817, loss_s1: 0.005949, loss_fp: 0.000421, loss_freq: 0.008183
[15:49:34.639] iteration 21539: loss: 0.028276, loss_s1: 0.021380, loss_fp: 0.001634, loss_freq: 0.004854
[15:49:35.254] iteration 21540: loss: 0.038030, loss_s1: 0.032839, loss_fp: 0.006449, loss_freq: 0.008114
[15:49:35.907] iteration 21541: loss: 0.062841, loss_s1: 0.038892, loss_fp: 0.001656, loss_freq: 0.029533
[15:49:36.529] iteration 21542: loss: 0.057009, loss_s1: 0.056129, loss_fp: 0.013527, loss_freq: 0.018298
[15:49:37.152] iteration 21543: loss: 0.052501, loss_s1: 0.050418, loss_fp: 0.002649, loss_freq: 0.012886
[15:49:37.769] iteration 21544: loss: 0.040255, loss_s1: 0.022281, loss_fp: 0.013084, loss_freq: 0.003662
[15:49:38.389] iteration 21545: loss: 0.064104, loss_s1: 0.034422, loss_fp: 0.001032, loss_freq: 0.005270
[15:49:39.012] iteration 21546: loss: 0.034392, loss_s1: 0.007919, loss_fp: 0.008567, loss_freq: 0.006413
[15:49:39.629] iteration 21547: loss: 0.101610, loss_s1: 0.070755, loss_fp: 0.004952, loss_freq: 0.083916
[15:49:40.247] iteration 21548: loss: 0.067654, loss_s1: 0.049509, loss_fp: 0.008414, loss_freq: 0.017038
[15:49:40.864] iteration 21549: loss: 0.045472, loss_s1: 0.035895, loss_fp: 0.003031, loss_freq: 0.009165
[15:49:41.484] iteration 21550: loss: 0.083313, loss_s1: 0.036384, loss_fp: 0.009265, loss_freq: 0.082566
[15:49:42.105] iteration 21551: loss: 0.037522, loss_s1: 0.025116, loss_fp: 0.002283, loss_freq: 0.014872
[15:49:42.728] iteration 21552: loss: 0.068131, loss_s1: 0.056538, loss_fp: 0.002289, loss_freq: 0.034760
[15:49:43.394] iteration 21553: loss: 0.066744, loss_s1: 0.042674, loss_fp: 0.001440, loss_freq: 0.055521
[15:49:44.038] iteration 21554: loss: 0.035952, loss_s1: 0.018475, loss_fp: 0.008453, loss_freq: 0.009724
[15:49:44.683] iteration 21555: loss: 0.042034, loss_s1: 0.024125, loss_fp: 0.001693, loss_freq: 0.017905
[15:49:45.318] iteration 21556: loss: 0.066674, loss_s1: 0.026016, loss_fp: 0.001703, loss_freq: 0.062709
[15:49:45.931] iteration 21557: loss: 0.068581, loss_s1: 0.047267, loss_fp: 0.002651, loss_freq: 0.035464
[15:49:46.556] iteration 21558: loss: 0.061924, loss_s1: 0.040214, loss_fp: 0.010521, loss_freq: 0.040102
[15:49:47.171] iteration 21559: loss: 0.062301, loss_s1: 0.024666, loss_fp: 0.003789, loss_freq: 0.051829
[15:49:47.795] iteration 21560: loss: 0.083624, loss_s1: 0.060722, loss_fp: 0.004476, loss_freq: 0.070414
[15:49:48.409] iteration 21561: loss: 0.067530, loss_s1: 0.033367, loss_fp: 0.002135, loss_freq: 0.009430
[15:49:49.023] iteration 21562: loss: 0.041955, loss_s1: 0.030110, loss_fp: 0.003015, loss_freq: 0.024099
[15:49:49.658] iteration 21563: loss: 0.054379, loss_s1: 0.035449, loss_fp: 0.001047, loss_freq: 0.011927
[15:49:50.276] iteration 21564: loss: 0.058991, loss_s1: 0.061002, loss_fp: 0.002559, loss_freq: 0.012587
[15:49:50.889] iteration 21565: loss: 0.052710, loss_s1: 0.019053, loss_fp: 0.000998, loss_freq: 0.029447
[15:49:51.503] iteration 21566: loss: 0.041815, loss_s1: 0.008597, loss_fp: 0.009855, loss_freq: 0.024603
[15:49:52.122] iteration 21567: loss: 0.063035, loss_s1: 0.041383, loss_fp: 0.001894, loss_freq: 0.038643
[15:49:52.784] iteration 21568: loss: 0.063574, loss_s1: 0.058440, loss_fp: 0.002304, loss_freq: 0.021805
[15:49:53.422] iteration 21569: loss: 0.036631, loss_s1: 0.032167, loss_fp: 0.004498, loss_freq: 0.005998
[15:49:54.073] iteration 21570: loss: 0.054188, loss_s1: 0.040365, loss_fp: 0.002809, loss_freq: 0.018883
[15:49:54.714] iteration 21571: loss: 0.061728, loss_s1: 0.060334, loss_fp: 0.005304, loss_freq: 0.016952
[15:49:55.348] iteration 21572: loss: 0.096273, loss_s1: 0.079240, loss_fp: 0.009383, loss_freq: 0.043926
[15:49:55.974] iteration 21573: loss: 0.046053, loss_s1: 0.029189, loss_fp: 0.001081, loss_freq: 0.005848
[15:49:56.593] iteration 21574: loss: 0.043505, loss_s1: 0.027563, loss_fp: 0.005448, loss_freq: 0.028969
[15:49:57.211] iteration 21575: loss: 0.050032, loss_s1: 0.056710, loss_fp: 0.006944, loss_freq: 0.006774
[15:49:57.823] iteration 21576: loss: 0.049842, loss_s1: 0.030202, loss_fp: 0.000582, loss_freq: 0.006529
[15:49:58.442] iteration 21577: loss: 0.027168, loss_s1: 0.013315, loss_fp: 0.003156, loss_freq: 0.012220
[15:49:59.059] iteration 21578: loss: 0.054429, loss_s1: 0.040616, loss_fp: 0.001809, loss_freq: 0.026937
[15:49:59.674] iteration 21579: loss: 0.052590, loss_s1: 0.042180, loss_fp: 0.002773, loss_freq: 0.016876
[15:50:00.319] iteration 21580: loss: 0.031189, loss_s1: 0.009909, loss_fp: 0.004663, loss_freq: 0.006333
[15:50:00.944] iteration 21581: loss: 0.050707, loss_s1: 0.036767, loss_fp: 0.002630, loss_freq: 0.017511
[15:50:01.566] iteration 21582: loss: 0.059666, loss_s1: 0.041142, loss_fp: 0.008012, loss_freq: 0.019947
[15:50:02.191] iteration 21583: loss: 0.068889, loss_s1: 0.060075, loss_fp: 0.019247, loss_freq: 0.020399
[15:50:02.860] iteration 21584: loss: 0.072504, loss_s1: 0.026382, loss_fp: 0.000406, loss_freq: 0.064914
[15:50:03.483] iteration 21585: loss: 0.037321, loss_s1: 0.018363, loss_fp: 0.001965, loss_freq: 0.013772
[15:50:04.108] iteration 21586: loss: 0.060532, loss_s1: 0.048582, loss_fp: 0.006205, loss_freq: 0.028795
[15:50:04.739] iteration 21587: loss: 0.084660, loss_s1: 0.061264, loss_fp: 0.002057, loss_freq: 0.031512
[15:50:05.359] iteration 21588: loss: 0.047045, loss_s1: 0.042958, loss_fp: 0.002408, loss_freq: 0.015501
[15:50:05.972] iteration 21589: loss: 0.056127, loss_s1: 0.044537, loss_fp: 0.002896, loss_freq: 0.020386
[15:50:06.597] iteration 21590: loss: 0.057804, loss_s1: 0.039954, loss_fp: 0.010297, loss_freq: 0.024270
[15:50:07.215] iteration 21591: loss: 0.055965, loss_s1: 0.042581, loss_fp: 0.001492, loss_freq: 0.025309
[15:50:07.834] iteration 21592: loss: 0.083819, loss_s1: 0.041297, loss_fp: 0.030454, loss_freq: 0.054182
[15:50:08.453] iteration 21593: loss: 0.048581, loss_s1: 0.037040, loss_fp: 0.004255, loss_freq: 0.019888
[15:50:09.395] iteration 21594: loss: 0.051935, loss_s1: 0.044945, loss_fp: 0.001291, loss_freq: 0.014256
[15:50:10.018] iteration 21595: loss: 0.063767, loss_s1: 0.052038, loss_fp: 0.001421, loss_freq: 0.021772
[15:50:10.638] iteration 21596: loss: 0.042038, loss_s1: 0.023519, loss_fp: 0.002537, loss_freq: 0.026813
[15:50:11.263] iteration 21597: loss: 0.075090, loss_s1: 0.028821, loss_fp: 0.009304, loss_freq: 0.061690
[15:50:11.936] iteration 21598: loss: 0.079586, loss_s1: 0.068617, loss_fp: 0.011620, loss_freq: 0.040767
[15:50:12.577] iteration 21599: loss: 0.071109, loss_s1: 0.056931, loss_fp: 0.003438, loss_freq: 0.006584
[15:50:13.215] iteration 21600: loss: 0.028330, loss_s1: 0.007468, loss_fp: 0.002450, loss_freq: 0.013545
[15:50:16.670] iteration 21600 : mean_dice : 0.781202
[15:50:17.311] iteration 21601: loss: 0.132271, loss_s1: 0.106598, loss_fp: 0.011578, loss_freq: 0.078913
[15:50:17.929] iteration 21602: loss: 0.066087, loss_s1: 0.073433, loss_fp: 0.001648, loss_freq: 0.023041
[15:50:18.548] iteration 21603: loss: 0.058344, loss_s1: 0.020334, loss_fp: 0.003157, loss_freq: 0.010359
[15:50:19.165] iteration 21604: loss: 0.049897, loss_s1: 0.031635, loss_fp: 0.002058, loss_freq: 0.028400
[15:50:19.781] iteration 21605: loss: 0.041740, loss_s1: 0.026254, loss_fp: 0.001649, loss_freq: 0.017095
[15:50:20.401] iteration 21606: loss: 0.053834, loss_s1: 0.038346, loss_fp: 0.001787, loss_freq: 0.030820
[15:50:21.021] iteration 21607: loss: 0.026758, loss_s1: 0.015599, loss_fp: 0.001678, loss_freq: 0.004168
[15:50:21.649] iteration 21608: loss: 0.042584, loss_s1: 0.032320, loss_fp: 0.001891, loss_freq: 0.012492
[15:50:22.267] iteration 21609: loss: 0.037380, loss_s1: 0.013257, loss_fp: 0.006407, loss_freq: 0.017861
[15:50:22.928] iteration 21610: loss: 0.049638, loss_s1: 0.016006, loss_fp: 0.002536, loss_freq: 0.025906
[15:50:23.591] iteration 21611: loss: 0.065421, loss_s1: 0.040552, loss_fp: 0.005059, loss_freq: 0.035316
[15:50:24.222] iteration 21612: loss: 0.041721, loss_s1: 0.026169, loss_fp: 0.001197, loss_freq: 0.025875
[15:50:24.849] iteration 21613: loss: 0.053894, loss_s1: 0.031306, loss_fp: 0.005971, loss_freq: 0.034471
[15:50:25.479] iteration 21614: loss: 0.069564, loss_s1: 0.040229, loss_fp: 0.002553, loss_freq: 0.041289
[15:50:26.098] iteration 21615: loss: 0.046632, loss_s1: 0.028459, loss_fp: 0.002942, loss_freq: 0.027202
[15:50:26.747] iteration 21616: loss: 0.068019, loss_s1: 0.063737, loss_fp: 0.003121, loss_freq: 0.026362
[15:50:27.392] iteration 21617: loss: 0.060820, loss_s1: 0.037099, loss_fp: 0.000522, loss_freq: 0.019422
[15:50:28.036] iteration 21618: loss: 0.046189, loss_s1: 0.022124, loss_fp: 0.002043, loss_freq: 0.025572
[15:50:28.682] iteration 21619: loss: 0.084718, loss_s1: 0.100009, loss_fp: 0.001797, loss_freq: 0.022249
[15:50:29.364] iteration 21620: loss: 0.058120, loss_s1: 0.043744, loss_fp: 0.001758, loss_freq: 0.021028
[15:50:29.991] iteration 21621: loss: 0.030733, loss_s1: 0.014376, loss_fp: 0.000976, loss_freq: 0.006817
[15:50:30.643] iteration 21622: loss: 0.076868, loss_s1: 0.020937, loss_fp: 0.002903, loss_freq: 0.079251
[15:50:31.294] iteration 21623: loss: 0.065632, loss_s1: 0.015419, loss_fp: 0.003425, loss_freq: 0.025359
[15:50:31.941] iteration 21624: loss: 0.045374, loss_s1: 0.015741, loss_fp: 0.003280, loss_freq: 0.027000
[15:50:32.593] iteration 21625: loss: 0.057957, loss_s1: 0.043240, loss_fp: 0.005021, loss_freq: 0.015754
[15:50:33.292] iteration 21626: loss: 0.069654, loss_s1: 0.039090, loss_fp: 0.033516, loss_freq: 0.031196
[15:50:33.933] iteration 21627: loss: 0.070211, loss_s1: 0.050710, loss_fp: 0.014558, loss_freq: 0.034808
[15:50:34.555] iteration 21628: loss: 0.070094, loss_s1: 0.051965, loss_fp: 0.004812, loss_freq: 0.034798
[15:50:35.192] iteration 21629: loss: 0.053081, loss_s1: 0.040911, loss_fp: 0.001446, loss_freq: 0.024617
[15:50:35.838] iteration 21630: loss: 0.052203, loss_s1: 0.024345, loss_fp: 0.004927, loss_freq: 0.021741
[15:50:36.469] iteration 21631: loss: 0.068487, loss_s1: 0.043565, loss_fp: 0.010283, loss_freq: 0.047209
[15:50:37.090] iteration 21632: loss: 0.078437, loss_s1: 0.053251, loss_fp: 0.016938, loss_freq: 0.033890
[15:50:37.717] iteration 21633: loss: 0.055852, loss_s1: 0.042653, loss_fp: 0.003200, loss_freq: 0.019590
[15:50:38.338] iteration 21634: loss: 0.055418, loss_s1: 0.028639, loss_fp: 0.002441, loss_freq: 0.018423
[15:50:38.968] iteration 21635: loss: 0.072495, loss_s1: 0.077068, loss_fp: 0.004557, loss_freq: 0.032582
[15:50:39.588] iteration 21636: loss: 0.066507, loss_s1: 0.050944, loss_fp: 0.013545, loss_freq: 0.017847
[15:50:40.209] iteration 21637: loss: 0.086497, loss_s1: 0.089548, loss_fp: 0.009454, loss_freq: 0.030952
[15:50:40.829] iteration 21638: loss: 0.058391, loss_s1: 0.034122, loss_fp: 0.001138, loss_freq: 0.011287
[15:50:41.455] iteration 21639: loss: 0.085549, loss_s1: 0.072819, loss_fp: 0.008818, loss_freq: 0.050899
[15:50:42.075] iteration 21640: loss: 0.051189, loss_s1: 0.025374, loss_fp: 0.001821, loss_freq: 0.033296
[15:50:42.723] iteration 21641: loss: 0.059721, loss_s1: 0.029513, loss_fp: 0.007476, loss_freq: 0.016034
[15:50:43.346] iteration 21642: loss: 0.055476, loss_s1: 0.044160, loss_fp: 0.001907, loss_freq: 0.014766
[15:50:43.963] iteration 21643: loss: 0.064839, loss_s1: 0.066270, loss_fp: 0.001718, loss_freq: 0.022075
[15:50:44.585] iteration 21644: loss: 0.062358, loss_s1: 0.063867, loss_fp: 0.003331, loss_freq: 0.018325
[15:50:45.213] iteration 21645: loss: 0.077394, loss_s1: 0.064732, loss_fp: 0.001714, loss_freq: 0.042572
[15:50:45.832] iteration 21646: loss: 0.076879, loss_s1: 0.089192, loss_fp: 0.000596, loss_freq: 0.018505
[15:50:46.461] iteration 21647: loss: 0.029163, loss_s1: 0.014228, loss_fp: 0.005682, loss_freq: 0.005756
[15:50:47.183] iteration 21648: loss: 0.047265, loss_s1: 0.049529, loss_fp: 0.001806, loss_freq: 0.006326
[15:50:47.810] iteration 21649: loss: 0.056127, loss_s1: 0.030981, loss_fp: 0.001012, loss_freq: 0.014973
[15:50:48.442] iteration 21650: loss: 0.052250, loss_s1: 0.033100, loss_fp: 0.013602, loss_freq: 0.016046
[15:50:49.163] iteration 21651: loss: 0.037490, loss_s1: 0.014950, loss_fp: 0.008868, loss_freq: 0.015658
[15:50:49.774] iteration 21652: loss: 0.095188, loss_s1: 0.068437, loss_fp: 0.002138, loss_freq: 0.075442
[15:50:50.391] iteration 21653: loss: 0.066939, loss_s1: 0.052378, loss_fp: 0.003155, loss_freq: 0.035251
[15:50:51.014] iteration 21654: loss: 0.055711, loss_s1: 0.034335, loss_fp: 0.000929, loss_freq: 0.016561
[15:50:51.631] iteration 21655: loss: 0.046916, loss_s1: 0.038905, loss_fp: 0.002106, loss_freq: 0.007227
[15:50:52.251] iteration 21656: loss: 0.058854, loss_s1: 0.047836, loss_fp: 0.002442, loss_freq: 0.030418
[15:50:52.867] iteration 21657: loss: 0.058136, loss_s1: 0.046634, loss_fp: 0.002906, loss_freq: 0.027200
[15:50:53.513] iteration 21658: loss: 0.041319, loss_s1: 0.033055, loss_fp: 0.002218, loss_freq: 0.006585
[15:50:54.151] iteration 21659: loss: 0.053464, loss_s1: 0.039346, loss_fp: 0.000966, loss_freq: 0.030125
[15:50:54.881] iteration 21660: loss: 0.059878, loss_s1: 0.059726, loss_fp: 0.002960, loss_freq: 0.011247
[15:50:55.502] iteration 21661: loss: 0.045290, loss_s1: 0.036592, loss_fp: 0.002526, loss_freq: 0.017922
[15:50:56.123] iteration 21662: loss: 0.030598, loss_s1: 0.005808, loss_fp: 0.000854, loss_freq: 0.015987
[15:50:56.752] iteration 21663: loss: 0.077300, loss_s1: 0.034976, loss_fp: 0.012411, loss_freq: 0.017837
[15:50:57.373] iteration 21664: loss: 0.043281, loss_s1: 0.025142, loss_fp: 0.001379, loss_freq: 0.022388
[15:50:58.017] iteration 21665: loss: 0.049534, loss_s1: 0.033776, loss_fp: 0.007109, loss_freq: 0.017154
[15:50:58.647] iteration 21666: loss: 0.082014, loss_s1: 0.066242, loss_fp: 0.000569, loss_freq: 0.061888
[15:50:59.269] iteration 21667: loss: 0.072014, loss_s1: 0.046362, loss_fp: 0.004399, loss_freq: 0.046656
[15:50:59.893] iteration 21668: loss: 0.073805, loss_s1: 0.043930, loss_fp: 0.018730, loss_freq: 0.053701
[15:51:00.554] iteration 21669: loss: 0.067767, loss_s1: 0.026435, loss_fp: 0.002043, loss_freq: 0.020256
[15:51:01.183] iteration 21670: loss: 0.052270, loss_s1: 0.050846, loss_fp: 0.001665, loss_freq: 0.015544
[15:51:01.810] iteration 21671: loss: 0.084535, loss_s1: 0.075465, loss_fp: 0.004621, loss_freq: 0.021944
[15:51:02.431] iteration 21672: loss: 0.071975, loss_s1: 0.068064, loss_fp: 0.003412, loss_freq: 0.022722
[15:51:03.089] iteration 21673: loss: 0.113996, loss_s1: 0.094198, loss_fp: 0.002732, loss_freq: 0.034306
[15:51:03.720] iteration 21674: loss: 0.069039, loss_s1: 0.045903, loss_fp: 0.002893, loss_freq: 0.023569
[15:51:04.353] iteration 21675: loss: 0.049810, loss_s1: 0.029065, loss_fp: 0.005540, loss_freq: 0.030441
[15:51:05.019] iteration 21676: loss: 0.047887, loss_s1: 0.025647, loss_fp: 0.001685, loss_freq: 0.013643
[15:51:05.668] iteration 21677: loss: 0.038319, loss_s1: 0.036329, loss_fp: 0.001503, loss_freq: 0.012628
[15:51:06.299] iteration 21678: loss: 0.050424, loss_s1: 0.026405, loss_fp: 0.007871, loss_freq: 0.021669
[15:51:06.922] iteration 21679: loss: 0.082078, loss_s1: 0.031050, loss_fp: 0.020791, loss_freq: 0.057622
[15:51:07.586] iteration 21680: loss: 0.038627, loss_s1: 0.033711, loss_fp: 0.001416, loss_freq: 0.007294
[15:51:08.232] iteration 21681: loss: 0.036592, loss_s1: 0.015815, loss_fp: 0.001821, loss_freq: 0.020990
[15:51:08.865] iteration 21682: loss: 0.049280, loss_s1: 0.041800, loss_fp: 0.017613, loss_freq: 0.008238
[15:51:09.505] iteration 21683: loss: 0.041199, loss_s1: 0.031039, loss_fp: 0.004102, loss_freq: 0.016453
[15:51:10.170] iteration 21684: loss: 0.055221, loss_s1: 0.051454, loss_fp: 0.002069, loss_freq: 0.014019
[15:51:10.833] iteration 21685: loss: 0.055381, loss_s1: 0.056252, loss_fp: 0.003153, loss_freq: 0.022112
[15:51:11.481] iteration 21686: loss: 0.035315, loss_s1: 0.027124, loss_fp: 0.001677, loss_freq: 0.002659
[15:51:12.118] iteration 21687: loss: 0.057797, loss_s1: 0.047497, loss_fp: 0.005717, loss_freq: 0.008141
[15:51:12.756] iteration 21688: loss: 0.040782, loss_s1: 0.022134, loss_fp: 0.003608, loss_freq: 0.008908
[15:51:13.396] iteration 21689: loss: 0.039472, loss_s1: 0.021963, loss_fp: 0.001538, loss_freq: 0.013760
[15:51:14.038] iteration 21690: loss: 0.090479, loss_s1: 0.073887, loss_fp: 0.001623, loss_freq: 0.042407
[15:51:14.680] iteration 21691: loss: 0.039884, loss_s1: 0.022767, loss_fp: 0.002561, loss_freq: 0.010078
[15:51:15.325] iteration 21692: loss: 0.049056, loss_s1: 0.010211, loss_fp: 0.001665, loss_freq: 0.008691
[15:51:15.966] iteration 21693: loss: 0.086546, loss_s1: 0.030926, loss_fp: 0.006112, loss_freq: 0.061591
[15:51:16.590] iteration 21694: loss: 0.050594, loss_s1: 0.045523, loss_fp: 0.007248, loss_freq: 0.011859
[15:51:17.218] iteration 21695: loss: 0.062767, loss_s1: 0.027982, loss_fp: 0.004417, loss_freq: 0.034277
[15:51:17.838] iteration 21696: loss: 0.065099, loss_s1: 0.065902, loss_fp: 0.002537, loss_freq: 0.032580
[15:51:18.450] iteration 21697: loss: 0.049597, loss_s1: 0.038421, loss_fp: 0.001082, loss_freq: 0.010550
[15:51:19.063] iteration 21698: loss: 0.048125, loss_s1: 0.020911, loss_fp: 0.002573, loss_freq: 0.018897
[15:51:19.720] iteration 21699: loss: 0.053097, loss_s1: 0.035950, loss_fp: 0.000987, loss_freq: 0.021409
[15:51:20.343] iteration 21700: loss: 0.068744, loss_s1: 0.047163, loss_fp: 0.015533, loss_freq: 0.028950
[15:51:20.970] iteration 21701: loss: 0.083861, loss_s1: 0.054080, loss_fp: 0.015541, loss_freq: 0.063171
[15:51:21.590] iteration 21702: loss: 0.054346, loss_s1: 0.035835, loss_fp: 0.003349, loss_freq: 0.028470
[15:51:22.260] iteration 21703: loss: 0.132553, loss_s1: 0.091301, loss_fp: 0.006844, loss_freq: 0.134279
[15:51:22.881] iteration 21704: loss: 0.083061, loss_s1: 0.036667, loss_fp: 0.006174, loss_freq: 0.012210
[15:51:23.508] iteration 21705: loss: 0.052475, loss_s1: 0.041810, loss_fp: 0.001932, loss_freq: 0.031887
[15:51:24.129] iteration 21706: loss: 0.038889, loss_s1: 0.027106, loss_fp: 0.004082, loss_freq: 0.009463
[15:51:24.746] iteration 21707: loss: 0.068731, loss_s1: 0.042388, loss_fp: 0.008193, loss_freq: 0.046954
[15:51:25.373] iteration 21708: loss: 0.137586, loss_s1: 0.141043, loss_fp: 0.003635, loss_freq: 0.058834
[15:51:25.998] iteration 21709: loss: 0.039514, loss_s1: 0.029216, loss_fp: 0.000405, loss_freq: 0.012663
[15:51:26.624] iteration 21710: loss: 0.045472, loss_s1: 0.016782, loss_fp: 0.006667, loss_freq: 0.024826
[15:51:27.304] iteration 21711: loss: 0.075611, loss_s1: 0.097534, loss_fp: 0.003407, loss_freq: 0.009377
[15:51:27.959] iteration 21712: loss: 0.076630, loss_s1: 0.086519, loss_fp: 0.016910, loss_freq: 0.020960
[15:51:28.618] iteration 21713: loss: 0.042761, loss_s1: 0.016812, loss_fp: 0.002415, loss_freq: 0.026026
[15:51:29.267] iteration 21714: loss: 0.072174, loss_s1: 0.029375, loss_fp: 0.003207, loss_freq: 0.026853
[15:51:29.907] iteration 21715: loss: 0.066305, loss_s1: 0.064744, loss_fp: 0.002652, loss_freq: 0.016659
[15:51:30.550] iteration 21716: loss: 0.039756, loss_s1: 0.019818, loss_fp: 0.000766, loss_freq: 0.005259
[15:51:31.218] iteration 21717: loss: 0.103453, loss_s1: 0.075751, loss_fp: 0.004448, loss_freq: 0.079161
[15:51:31.844] iteration 21718: loss: 0.036714, loss_s1: 0.022829, loss_fp: 0.003259, loss_freq: 0.019894
[15:51:32.471] iteration 21719: loss: 0.039776, loss_s1: 0.013627, loss_fp: 0.002220, loss_freq: 0.010416
[15:51:33.093] iteration 21720: loss: 0.078164, loss_s1: 0.050862, loss_fp: 0.000694, loss_freq: 0.055403
[15:51:33.731] iteration 21721: loss: 0.050353, loss_s1: 0.039384, loss_fp: 0.001695, loss_freq: 0.015023
[15:51:34.367] iteration 21722: loss: 0.067604, loss_s1: 0.069920, loss_fp: 0.001771, loss_freq: 0.009427
[15:51:35.007] iteration 21723: loss: 0.044693, loss_s1: 0.018861, loss_fp: 0.004292, loss_freq: 0.025998
[15:51:35.645] iteration 21724: loss: 0.039839, loss_s1: 0.019422, loss_fp: 0.006487, loss_freq: 0.011148
[15:51:36.276] iteration 21725: loss: 0.040467, loss_s1: 0.015530, loss_fp: 0.002762, loss_freq: 0.014629
[15:51:36.921] iteration 21726: loss: 0.049258, loss_s1: 0.039493, loss_fp: 0.000600, loss_freq: 0.016240
[15:51:37.564] iteration 21727: loss: 0.048161, loss_s1: 0.014951, loss_fp: 0.001291, loss_freq: 0.040837
[15:51:38.207] iteration 21728: loss: 0.057780, loss_s1: 0.063577, loss_fp: 0.001466, loss_freq: 0.009209
[15:51:38.843] iteration 21729: loss: 0.063393, loss_s1: 0.064832, loss_fp: 0.005841, loss_freq: 0.016093
[15:51:39.485] iteration 21730: loss: 0.061207, loss_s1: 0.040264, loss_fp: 0.004377, loss_freq: 0.031998
[15:51:40.108] iteration 21731: loss: 0.042167, loss_s1: 0.031570, loss_fp: 0.000313, loss_freq: 0.013623
[15:51:40.748] iteration 21732: loss: 0.046843, loss_s1: 0.029171, loss_fp: 0.007275, loss_freq: 0.020735
[15:51:41.390] iteration 21733: loss: 0.064737, loss_s1: 0.026508, loss_fp: 0.010744, loss_freq: 0.013174
[15:51:42.027] iteration 21734: loss: 0.044573, loss_s1: 0.032562, loss_fp: 0.005316, loss_freq: 0.017509
[15:51:42.645] iteration 21735: loss: 0.073126, loss_s1: 0.069776, loss_fp: 0.009861, loss_freq: 0.024734
[15:51:43.268] iteration 21736: loss: 0.032024, loss_s1: 0.014982, loss_fp: 0.000790, loss_freq: 0.015849
[15:51:44.247] iteration 21737: loss: 0.042336, loss_s1: 0.032661, loss_fp: 0.003283, loss_freq: 0.012333
[15:51:44.871] iteration 21738: loss: 0.052580, loss_s1: 0.030017, loss_fp: 0.005662, loss_freq: 0.016480
[15:51:45.493] iteration 21739: loss: 0.040346, loss_s1: 0.013529, loss_fp: 0.003844, loss_freq: 0.023688
[15:51:46.162] iteration 21740: loss: 0.072939, loss_s1: 0.029076, loss_fp: 0.000840, loss_freq: 0.024718
[15:51:46.789] iteration 21741: loss: 0.054845, loss_s1: 0.040015, loss_fp: 0.002386, loss_freq: 0.039530
[15:51:47.408] iteration 21742: loss: 0.047619, loss_s1: 0.039826, loss_fp: 0.000788, loss_freq: 0.006292
[15:51:48.026] iteration 21743: loss: 0.039360, loss_s1: 0.024495, loss_fp: 0.003845, loss_freq: 0.022096
[15:51:48.650] iteration 21744: loss: 0.056891, loss_s1: 0.039956, loss_fp: 0.002958, loss_freq: 0.022489
[15:51:49.270] iteration 21745: loss: 0.090680, loss_s1: 0.076940, loss_fp: 0.003149, loss_freq: 0.052346
[15:51:49.893] iteration 21746: loss: 0.040365, loss_s1: 0.016855, loss_fp: 0.001203, loss_freq: 0.007095
[15:51:50.503] iteration 21747: loss: 0.061417, loss_s1: 0.044195, loss_fp: 0.001301, loss_freq: 0.039208
[15:51:51.127] iteration 21748: loss: 0.049108, loss_s1: 0.026283, loss_fp: 0.001235, loss_freq: 0.017846
[15:51:51.748] iteration 21749: loss: 0.063305, loss_s1: 0.066004, loss_fp: 0.001292, loss_freq: 0.015967
[15:51:52.369] iteration 21750: loss: 0.039568, loss_s1: 0.008789, loss_fp: 0.001402, loss_freq: 0.027331
[15:51:52.992] iteration 21751: loss: 0.075801, loss_s1: 0.058591, loss_fp: 0.003860, loss_freq: 0.046273
[15:51:53.613] iteration 21752: loss: 0.046402, loss_s1: 0.029764, loss_fp: 0.005983, loss_freq: 0.023704
[15:51:54.238] iteration 21753: loss: 0.063779, loss_s1: 0.025140, loss_fp: 0.011136, loss_freq: 0.026883
[15:51:54.880] iteration 21754: loss: 0.055932, loss_s1: 0.055974, loss_fp: 0.004825, loss_freq: 0.015709
[15:51:55.514] iteration 21755: loss: 0.053453, loss_s1: 0.022817, loss_fp: 0.003610, loss_freq: 0.017337
[15:51:56.143] iteration 21756: loss: 0.040856, loss_s1: 0.029705, loss_fp: 0.002757, loss_freq: 0.011436
[15:51:56.778] iteration 21757: loss: 0.083095, loss_s1: 0.061024, loss_fp: 0.002065, loss_freq: 0.046638
[15:51:57.472] iteration 21758: loss: 0.066446, loss_s1: 0.076152, loss_fp: 0.001436, loss_freq: 0.023714
[15:51:58.098] iteration 21759: loss: 0.055952, loss_s1: 0.024070, loss_fp: 0.005724, loss_freq: 0.040959
[15:51:58.724] iteration 21760: loss: 0.035655, loss_s1: 0.023115, loss_fp: 0.002747, loss_freq: 0.008663
[15:51:59.348] iteration 21761: loss: 0.040314, loss_s1: 0.014240, loss_fp: 0.003760, loss_freq: 0.021903
[15:51:59.986] iteration 21762: loss: 0.094050, loss_s1: 0.115378, loss_fp: 0.008795, loss_freq: 0.018718
[15:52:00.619] iteration 21763: loss: 0.105597, loss_s1: 0.073227, loss_fp: 0.004511, loss_freq: 0.073317
[15:52:01.245] iteration 21764: loss: 0.049169, loss_s1: 0.052973, loss_fp: 0.001139, loss_freq: 0.008514
[15:52:01.912] iteration 21765: loss: 0.048322, loss_s1: 0.027066, loss_fp: 0.001517, loss_freq: 0.020198
[15:52:02.541] iteration 21766: loss: 0.046651, loss_s1: 0.024653, loss_fp: 0.001319, loss_freq: 0.011922
[15:52:03.165] iteration 21767: loss: 0.034865, loss_s1: 0.028404, loss_fp: 0.001476, loss_freq: 0.007355
[15:52:03.827] iteration 21768: loss: 0.073707, loss_s1: 0.057123, loss_fp: 0.008839, loss_freq: 0.031671
[15:52:04.479] iteration 21769: loss: 0.055503, loss_s1: 0.030580, loss_fp: 0.010867, loss_freq: 0.038422
[15:52:05.097] iteration 21770: loss: 0.075030, loss_s1: 0.055638, loss_fp: 0.012694, loss_freq: 0.049196
[15:52:05.729] iteration 21771: loss: 0.070548, loss_s1: 0.030105, loss_fp: 0.006799, loss_freq: 0.016364
[15:52:06.358] iteration 21772: loss: 0.067210, loss_s1: 0.052097, loss_fp: 0.002382, loss_freq: 0.041056
[15:52:06.980] iteration 21773: loss: 0.040009, loss_s1: 0.025858, loss_fp: 0.003786, loss_freq: 0.010281
[15:52:07.629] iteration 21774: loss: 0.054938, loss_s1: 0.035102, loss_fp: 0.005171, loss_freq: 0.039010
[15:52:08.247] iteration 21775: loss: 0.051596, loss_s1: 0.047351, loss_fp: 0.002593, loss_freq: 0.017283
[15:52:08.868] iteration 21776: loss: 0.036995, loss_s1: 0.026764, loss_fp: 0.005873, loss_freq: 0.009509
[15:52:09.547] iteration 21777: loss: 0.070905, loss_s1: 0.024915, loss_fp: 0.002299, loss_freq: 0.022629
[15:52:10.179] iteration 21778: loss: 0.048512, loss_s1: 0.036615, loss_fp: 0.001473, loss_freq: 0.029692
[15:52:10.799] iteration 21779: loss: 0.040039, loss_s1: 0.021859, loss_fp: 0.001083, loss_freq: 0.016003
[15:52:11.422] iteration 21780: loss: 0.052664, loss_s1: 0.036099, loss_fp: 0.002473, loss_freq: 0.022275
[15:52:12.041] iteration 21781: loss: 0.038896, loss_s1: 0.005581, loss_fp: 0.003902, loss_freq: 0.005792
[15:52:12.662] iteration 21782: loss: 0.073363, loss_s1: 0.081795, loss_fp: 0.002044, loss_freq: 0.023723
[15:52:13.304] iteration 21783: loss: 0.051197, loss_s1: 0.030263, loss_fp: 0.001711, loss_freq: 0.026244
[15:52:13.918] iteration 21784: loss: 0.044211, loss_s1: 0.029705, loss_fp: 0.005704, loss_freq: 0.015726
[15:52:14.557] iteration 21785: loss: 0.059977, loss_s1: 0.058969, loss_fp: 0.000970, loss_freq: 0.030491
[15:52:15.191] iteration 21786: loss: 0.051484, loss_s1: 0.025990, loss_fp: 0.001709, loss_freq: 0.030428
[15:52:15.878] iteration 21787: loss: 0.046102, loss_s1: 0.035641, loss_fp: 0.001225, loss_freq: 0.015975
[15:52:16.519] iteration 21788: loss: 0.053853, loss_s1: 0.026040, loss_fp: 0.003120, loss_freq: 0.032103
[15:52:17.147] iteration 21789: loss: 0.043664, loss_s1: 0.010846, loss_fp: 0.003344, loss_freq: 0.019177
[15:52:17.770] iteration 21790: loss: 0.053402, loss_s1: 0.031060, loss_fp: 0.002081, loss_freq: 0.041586
[15:52:18.386] iteration 21791: loss: 0.038298, loss_s1: 0.024901, loss_fp: 0.001810, loss_freq: 0.007857
[15:52:19.009] iteration 21792: loss: 0.045187, loss_s1: 0.035433, loss_fp: 0.001753, loss_freq: 0.012780
[15:52:19.628] iteration 21793: loss: 0.048144, loss_s1: 0.051109, loss_fp: 0.005439, loss_freq: 0.009803
[15:52:20.245] iteration 21794: loss: 0.044759, loss_s1: 0.039028, loss_fp: 0.004191, loss_freq: 0.012769
[15:52:20.867] iteration 21795: loss: 0.087189, loss_s1: 0.023234, loss_fp: 0.005527, loss_freq: 0.058304
[15:52:21.490] iteration 21796: loss: 0.056511, loss_s1: 0.031633, loss_fp: 0.001405, loss_freq: 0.015070
[15:52:22.119] iteration 21797: loss: 0.035563, loss_s1: 0.017458, loss_fp: 0.001582, loss_freq: 0.015206
[15:52:22.746] iteration 21798: loss: 0.047020, loss_s1: 0.040075, loss_fp: 0.001957, loss_freq: 0.013091
[15:52:23.370] iteration 21799: loss: 0.064915, loss_s1: 0.061428, loss_fp: 0.003041, loss_freq: 0.026259
[15:52:23.993] iteration 21800: loss: 0.046985, loss_s1: 0.023664, loss_fp: 0.001071, loss_freq: 0.022130
[15:52:27.305] iteration 21800 : mean_dice : 0.786575
[15:52:27.958] iteration 21801: loss: 0.086054, loss_s1: 0.045594, loss_fp: 0.009513, loss_freq: 0.069676
[15:52:28.582] iteration 21802: loss: 0.062019, loss_s1: 0.059890, loss_fp: 0.013850, loss_freq: 0.011528
[15:52:29.207] iteration 21803: loss: 0.053232, loss_s1: 0.029736, loss_fp: 0.005699, loss_freq: 0.021375
[15:52:29.834] iteration 21804: loss: 0.044587, loss_s1: 0.039787, loss_fp: 0.004586, loss_freq: 0.013351
[15:52:30.457] iteration 21805: loss: 0.051461, loss_s1: 0.048151, loss_fp: 0.004712, loss_freq: 0.008652
[15:52:31.077] iteration 21806: loss: 0.055170, loss_s1: 0.026150, loss_fp: 0.006078, loss_freq: 0.010263
[15:52:31.706] iteration 21807: loss: 0.051372, loss_s1: 0.040598, loss_fp: 0.000323, loss_freq: 0.014978
[15:52:32.321] iteration 21808: loss: 0.055291, loss_s1: 0.022658, loss_fp: 0.002784, loss_freq: 0.043241
[15:52:32.942] iteration 21809: loss: 0.068946, loss_s1: 0.058547, loss_fp: 0.005845, loss_freq: 0.041742
[15:52:33.554] iteration 21810: loss: 0.083572, loss_s1: 0.068057, loss_fp: 0.004060, loss_freq: 0.048376
[15:52:34.166] iteration 21811: loss: 0.084495, loss_s1: 0.095468, loss_fp: 0.004073, loss_freq: 0.035348
[15:52:34.823] iteration 21812: loss: 0.046244, loss_s1: 0.040813, loss_fp: 0.005059, loss_freq: 0.010795
[15:52:35.460] iteration 21813: loss: 0.057691, loss_s1: 0.064019, loss_fp: 0.000865, loss_freq: 0.022381
[15:52:36.091] iteration 21814: loss: 0.067431, loss_s1: 0.048674, loss_fp: 0.002310, loss_freq: 0.019968
[15:52:36.707] iteration 21815: loss: 0.060555, loss_s1: 0.058877, loss_fp: 0.007752, loss_freq: 0.018561
[15:52:37.324] iteration 21816: loss: 0.100342, loss_s1: 0.059065, loss_fp: 0.017400, loss_freq: 0.025547
[15:52:37.941] iteration 21817: loss: 0.052551, loss_s1: 0.041306, loss_fp: 0.012431, loss_freq: 0.013811
[15:52:38.673] iteration 21818: loss: 0.037327, loss_s1: 0.016865, loss_fp: 0.003864, loss_freq: 0.010585
[15:52:39.301] iteration 21819: loss: 0.039436, loss_s1: 0.034192, loss_fp: 0.000643, loss_freq: 0.004017
[15:52:39.944] iteration 21820: loss: 0.043732, loss_s1: 0.027397, loss_fp: 0.003080, loss_freq: 0.024098
[15:52:40.568] iteration 21821: loss: 0.039418, loss_s1: 0.016701, loss_fp: 0.004693, loss_freq: 0.017228
[15:52:41.192] iteration 21822: loss: 0.061804, loss_s1: 0.012279, loss_fp: 0.003830, loss_freq: 0.048879
[15:52:41.816] iteration 21823: loss: 0.053649, loss_s1: 0.041612, loss_fp: 0.001189, loss_freq: 0.007346
[15:52:42.458] iteration 21824: loss: 0.064370, loss_s1: 0.046413, loss_fp: 0.002518, loss_freq: 0.024249
[15:52:43.082] iteration 21825: loss: 0.034789, loss_s1: 0.031066, loss_fp: 0.001291, loss_freq: 0.010231
[15:52:43.700] iteration 21826: loss: 0.060498, loss_s1: 0.024440, loss_fp: 0.002518, loss_freq: 0.061673
[15:52:44.356] iteration 21827: loss: 0.050747, loss_s1: 0.028965, loss_fp: 0.003575, loss_freq: 0.024561
[15:52:45.012] iteration 21828: loss: 0.069896, loss_s1: 0.058998, loss_fp: 0.009758, loss_freq: 0.034988
[15:52:45.669] iteration 21829: loss: 0.046281, loss_s1: 0.028780, loss_fp: 0.002964, loss_freq: 0.022689
[15:52:46.326] iteration 21830: loss: 0.046969, loss_s1: 0.029010, loss_fp: 0.000967, loss_freq: 0.010180
[15:52:46.967] iteration 21831: loss: 0.040522, loss_s1: 0.026487, loss_fp: 0.001129, loss_freq: 0.014966
[15:52:47.651] iteration 21832: loss: 0.045374, loss_s1: 0.027599, loss_fp: 0.003185, loss_freq: 0.014279
[15:52:48.296] iteration 21833: loss: 0.069019, loss_s1: 0.030883, loss_fp: 0.002372, loss_freq: 0.063400
[15:52:48.933] iteration 21834: loss: 0.041533, loss_s1: 0.015750, loss_fp: 0.004354, loss_freq: 0.020262
[15:52:49.569] iteration 21835: loss: 0.044849, loss_s1: 0.014337, loss_fp: 0.007132, loss_freq: 0.016969
[15:52:50.198] iteration 21836: loss: 0.082247, loss_s1: 0.053326, loss_fp: 0.003567, loss_freq: 0.050911
[15:52:50.827] iteration 21837: loss: 0.051406, loss_s1: 0.036179, loss_fp: 0.004265, loss_freq: 0.013208
[15:52:51.443] iteration 21838: loss: 0.074586, loss_s1: 0.031643, loss_fp: 0.001697, loss_freq: 0.045993
[15:52:52.074] iteration 21839: loss: 0.077314, loss_s1: 0.059244, loss_fp: 0.001843, loss_freq: 0.062422
[15:52:52.697] iteration 21840: loss: 0.041173, loss_s1: 0.029313, loss_fp: 0.002108, loss_freq: 0.007197
[15:52:53.319] iteration 21841: loss: 0.046130, loss_s1: 0.019650, loss_fp: 0.003796, loss_freq: 0.021337
[15:52:53.941] iteration 21842: loss: 0.052856, loss_s1: 0.009404, loss_fp: 0.003822, loss_freq: 0.035925
[15:52:54.567] iteration 21843: loss: 0.112099, loss_s1: 0.100651, loss_fp: 0.003774, loss_freq: 0.078645
[15:52:55.185] iteration 21844: loss: 0.042086, loss_s1: 0.009630, loss_fp: 0.001986, loss_freq: 0.031898
[15:52:55.824] iteration 21845: loss: 0.042048, loss_s1: 0.009600, loss_fp: 0.002717, loss_freq: 0.022772
[15:52:56.451] iteration 21846: loss: 0.063659, loss_s1: 0.030687, loss_fp: 0.024252, loss_freq: 0.032145
[15:52:57.076] iteration 21847: loss: 0.063705, loss_s1: 0.030747, loss_fp: 0.001365, loss_freq: 0.025319
[15:52:57.696] iteration 21848: loss: 0.045362, loss_s1: 0.029438, loss_fp: 0.001595, loss_freq: 0.031190
[15:52:58.321] iteration 21849: loss: 0.054337, loss_s1: 0.028992, loss_fp: 0.001433, loss_freq: 0.010115
[15:52:58.950] iteration 21850: loss: 0.063929, loss_s1: 0.053926, loss_fp: 0.001901, loss_freq: 0.031355
[15:52:59.579] iteration 21851: loss: 0.058792, loss_s1: 0.033697, loss_fp: 0.005846, loss_freq: 0.009035
[15:53:00.207] iteration 21852: loss: 0.065119, loss_s1: 0.047093, loss_fp: 0.009108, loss_freq: 0.038429
[15:53:00.836] iteration 21853: loss: 0.074670, loss_s1: 0.034085, loss_fp: 0.001908, loss_freq: 0.058938
[15:53:01.465] iteration 21854: loss: 0.061698, loss_s1: 0.056989, loss_fp: 0.005459, loss_freq: 0.022280
[15:53:02.090] iteration 21855: loss: 0.063746, loss_s1: 0.071593, loss_fp: 0.005257, loss_freq: 0.019936
[15:53:02.723] iteration 21856: loss: 0.051957, loss_s1: 0.013182, loss_fp: 0.004196, loss_freq: 0.041164
[15:53:03.391] iteration 21857: loss: 0.065988, loss_s1: 0.043691, loss_fp: 0.002932, loss_freq: 0.038290
[15:53:04.011] iteration 21858: loss: 0.088679, loss_s1: 0.061956, loss_fp: 0.002173, loss_freq: 0.017563
[15:53:04.639] iteration 21859: loss: 0.028823, loss_s1: 0.013149, loss_fp: 0.001514, loss_freq: 0.008040
[15:53:05.261] iteration 21860: loss: 0.044915, loss_s1: 0.032143, loss_fp: 0.000821, loss_freq: 0.027563
[15:53:05.884] iteration 21861: loss: 0.068739, loss_s1: 0.061397, loss_fp: 0.005713, loss_freq: 0.033879
[15:53:06.515] iteration 21862: loss: 0.053540, loss_s1: 0.036518, loss_fp: 0.001913, loss_freq: 0.020283
[15:53:07.136] iteration 21863: loss: 0.042518, loss_s1: 0.016853, loss_fp: 0.004734, loss_freq: 0.026737
[15:53:07.752] iteration 21864: loss: 0.058858, loss_s1: 0.020955, loss_fp: 0.004737, loss_freq: 0.036545
[15:53:08.377] iteration 21865: loss: 0.062344, loss_s1: 0.042109, loss_fp: 0.004572, loss_freq: 0.024307
[15:53:09.040] iteration 21866: loss: 0.046712, loss_s1: 0.031081, loss_fp: 0.005498, loss_freq: 0.014019
[15:53:09.664] iteration 21867: loss: 0.086141, loss_s1: 0.061257, loss_fp: 0.001698, loss_freq: 0.040160
[15:53:10.282] iteration 21868: loss: 0.070174, loss_s1: 0.028371, loss_fp: 0.008090, loss_freq: 0.029122
[15:53:10.903] iteration 21869: loss: 0.044766, loss_s1: 0.021032, loss_fp: 0.013389, loss_freq: 0.011771
[15:53:11.557] iteration 21870: loss: 0.072521, loss_s1: 0.043815, loss_fp: 0.001826, loss_freq: 0.053699
[15:53:12.179] iteration 21871: loss: 0.054512, loss_s1: 0.027404, loss_fp: 0.003387, loss_freq: 0.019710
[15:53:12.797] iteration 21872: loss: 0.063347, loss_s1: 0.045837, loss_fp: 0.006431, loss_freq: 0.029944
[15:53:13.445] iteration 21873: loss: 0.050393, loss_s1: 0.027684, loss_fp: 0.005245, loss_freq: 0.011240
[15:53:14.088] iteration 21874: loss: 0.040132, loss_s1: 0.019853, loss_fp: 0.004180, loss_freq: 0.008478
[15:53:14.709] iteration 21875: loss: 0.060653, loss_s1: 0.060375, loss_fp: 0.001031, loss_freq: 0.015120
[15:53:15.332] iteration 21876: loss: 0.051636, loss_s1: 0.036697, loss_fp: 0.008219, loss_freq: 0.011298
[15:53:15.952] iteration 21877: loss: 0.069421, loss_s1: 0.063148, loss_fp: 0.005351, loss_freq: 0.033454
[15:53:16.563] iteration 21878: loss: 0.104869, loss_s1: 0.119413, loss_fp: 0.006909, loss_freq: 0.038509
[15:53:17.170] iteration 21879: loss: 0.039531, loss_s1: 0.006359, loss_fp: 0.000806, loss_freq: 0.023496
[15:53:18.129] iteration 21880: loss: 0.058970, loss_s1: 0.070580, loss_fp: 0.002546, loss_freq: 0.006542
[15:53:18.798] iteration 21881: loss: 0.061863, loss_s1: 0.048834, loss_fp: 0.001286, loss_freq: 0.027691
[15:53:19.443] iteration 21882: loss: 0.033091, loss_s1: 0.019855, loss_fp: 0.003260, loss_freq: 0.016980
[15:53:20.097] iteration 21883: loss: 0.084806, loss_s1: 0.043941, loss_fp: 0.001712, loss_freq: 0.033860
[15:53:20.743] iteration 21884: loss: 0.058187, loss_s1: 0.054869, loss_fp: 0.000975, loss_freq: 0.019608
[15:53:21.366] iteration 21885: loss: 0.033335, loss_s1: 0.021751, loss_fp: 0.001865, loss_freq: 0.006280
[15:53:21.991] iteration 21886: loss: 0.037259, loss_s1: 0.021228, loss_fp: 0.001186, loss_freq: 0.020065
[15:53:22.615] iteration 21887: loss: 0.056519, loss_s1: 0.027937, loss_fp: 0.002138, loss_freq: 0.022042
[15:53:23.235] iteration 21888: loss: 0.058318, loss_s1: 0.037999, loss_fp: 0.004323, loss_freq: 0.034653
[15:53:23.883] iteration 21889: loss: 0.037599, loss_s1: 0.016008, loss_fp: 0.001265, loss_freq: 0.005682
[15:53:24.502] iteration 21890: loss: 0.073832, loss_s1: 0.054017, loss_fp: 0.005653, loss_freq: 0.028477
[15:53:25.115] iteration 21891: loss: 0.040597, loss_s1: 0.020075, loss_fp: 0.004725, loss_freq: 0.016989
[15:53:25.740] iteration 21892: loss: 0.070603, loss_s1: 0.065915, loss_fp: 0.001000, loss_freq: 0.030787
[15:53:26.359] iteration 21893: loss: 0.042647, loss_s1: 0.032441, loss_fp: 0.002876, loss_freq: 0.018181
[15:53:26.973] iteration 21894: loss: 0.051719, loss_s1: 0.038215, loss_fp: 0.001004, loss_freq: 0.020981
[15:53:27.591] iteration 21895: loss: 0.047874, loss_s1: 0.031399, loss_fp: 0.003286, loss_freq: 0.021934
[15:53:28.217] iteration 21896: loss: 0.077291, loss_s1: 0.073981, loss_fp: 0.002698, loss_freq: 0.030311
[15:53:28.843] iteration 21897: loss: 0.044839, loss_s1: 0.024186, loss_fp: 0.003500, loss_freq: 0.027113
[15:53:29.458] iteration 21898: loss: 0.036739, loss_s1: 0.026257, loss_fp: 0.004662, loss_freq: 0.016554
[15:53:30.086] iteration 21899: loss: 0.035529, loss_s1: 0.021991, loss_fp: 0.000441, loss_freq: 0.016622
[15:53:30.710] iteration 21900: loss: 0.076361, loss_s1: 0.038844, loss_fp: 0.004133, loss_freq: 0.044934
[15:53:31.375] iteration 21901: loss: 0.046608, loss_s1: 0.038083, loss_fp: 0.002974, loss_freq: 0.020217
[15:53:32.063] iteration 21902: loss: 0.035314, loss_s1: 0.016564, loss_fp: 0.004255, loss_freq: 0.018981
[15:53:32.708] iteration 21903: loss: 0.058133, loss_s1: 0.025523, loss_fp: 0.006086, loss_freq: 0.009145
[15:53:33.360] iteration 21904: loss: 0.033395, loss_s1: 0.015585, loss_fp: 0.002485, loss_freq: 0.009369
[15:53:33.977] iteration 21905: loss: 0.076669, loss_s1: 0.094791, loss_fp: 0.001182, loss_freq: 0.020030
[15:53:34.628] iteration 21906: loss: 0.084333, loss_s1: 0.043611, loss_fp: 0.005248, loss_freq: 0.079399
[15:53:35.265] iteration 21907: loss: 0.048893, loss_s1: 0.025575, loss_fp: 0.002373, loss_freq: 0.027085
[15:53:35.885] iteration 21908: loss: 0.058961, loss_s1: 0.058802, loss_fp: 0.001964, loss_freq: 0.017465
[15:53:36.506] iteration 21909: loss: 0.055860, loss_s1: 0.010660, loss_fp: 0.002325, loss_freq: 0.008630
[15:53:37.122] iteration 21910: loss: 0.035807, loss_s1: 0.018612, loss_fp: 0.001768, loss_freq: 0.011250
[15:53:37.746] iteration 21911: loss: 0.059770, loss_s1: 0.052158, loss_fp: 0.003208, loss_freq: 0.018946
[15:53:38.367] iteration 21912: loss: 0.098476, loss_s1: 0.095684, loss_fp: 0.011071, loss_freq: 0.058702
[15:53:38.984] iteration 21913: loss: 0.060593, loss_s1: 0.037207, loss_fp: 0.002974, loss_freq: 0.033489
[15:53:39.600] iteration 21914: loss: 0.066680, loss_s1: 0.058208, loss_fp: 0.003743, loss_freq: 0.024649
[15:53:40.221] iteration 21915: loss: 0.059564, loss_s1: 0.063148, loss_fp: 0.002201, loss_freq: 0.013631
[15:53:40.833] iteration 21916: loss: 0.053105, loss_s1: 0.033367, loss_fp: 0.002757, loss_freq: 0.026765
[15:53:41.449] iteration 21917: loss: 0.052802, loss_s1: 0.040905, loss_fp: 0.001693, loss_freq: 0.015868
[15:53:42.064] iteration 21918: loss: 0.062560, loss_s1: 0.042380, loss_fp: 0.011172, loss_freq: 0.029596
[15:53:42.680] iteration 21919: loss: 0.072060, loss_s1: 0.085532, loss_fp: 0.005101, loss_freq: 0.010645
[15:53:43.294] iteration 21920: loss: 0.058155, loss_s1: 0.043356, loss_fp: 0.007665, loss_freq: 0.014638
[15:53:43.915] iteration 21921: loss: 0.040057, loss_s1: 0.027190, loss_fp: 0.001285, loss_freq: 0.024220
[15:53:44.531] iteration 21922: loss: 0.046559, loss_s1: 0.035504, loss_fp: 0.000886, loss_freq: 0.015335
[15:53:45.190] iteration 21923: loss: 0.072639, loss_s1: 0.049146, loss_fp: 0.005648, loss_freq: 0.043009
[15:53:45.835] iteration 21924: loss: 0.060942, loss_s1: 0.029042, loss_fp: 0.001995, loss_freq: 0.015224
[15:53:46.470] iteration 21925: loss: 0.111228, loss_s1: 0.112332, loss_fp: 0.005935, loss_freq: 0.062994
[15:53:47.128] iteration 21926: loss: 0.060885, loss_s1: 0.030005, loss_fp: 0.003892, loss_freq: 0.032573
[15:53:47.767] iteration 21927: loss: 0.041371, loss_s1: 0.019740, loss_fp: 0.002875, loss_freq: 0.011731
[15:53:48.399] iteration 21928: loss: 0.065838, loss_s1: 0.071897, loss_fp: 0.000882, loss_freq: 0.029115
[15:53:49.018] iteration 21929: loss: 0.043183, loss_s1: 0.012416, loss_fp: 0.002453, loss_freq: 0.023398
[15:53:49.631] iteration 21930: loss: 0.046222, loss_s1: 0.021879, loss_fp: 0.001241, loss_freq: 0.022775
[15:53:50.254] iteration 21931: loss: 0.075757, loss_s1: 0.050853, loss_fp: 0.001966, loss_freq: 0.042438
[15:53:50.871] iteration 21932: loss: 0.028611, loss_s1: 0.013377, loss_fp: 0.002388, loss_freq: 0.006754
[15:53:51.485] iteration 21933: loss: 0.052435, loss_s1: 0.033116, loss_fp: 0.001299, loss_freq: 0.025689
[15:53:52.109] iteration 21934: loss: 0.033940, loss_s1: 0.025066, loss_fp: 0.001043, loss_freq: 0.003786
[15:53:52.725] iteration 21935: loss: 0.043362, loss_s1: 0.012917, loss_fp: 0.000934, loss_freq: 0.025297
[15:53:53.347] iteration 21936: loss: 0.053707, loss_s1: 0.024036, loss_fp: 0.002386, loss_freq: 0.040715
[15:53:53.965] iteration 21937: loss: 0.035422, loss_s1: 0.007180, loss_fp: 0.000429, loss_freq: 0.013764
[15:53:54.664] iteration 21938: loss: 0.072614, loss_s1: 0.033596, loss_fp: 0.001612, loss_freq: 0.063250
[15:53:55.323] iteration 21939: loss: 0.059591, loss_s1: 0.033342, loss_fp: 0.005948, loss_freq: 0.038574
[15:53:55.947] iteration 21940: loss: 0.060976, loss_s1: 0.029520, loss_fp: 0.007395, loss_freq: 0.014208
[15:53:56.563] iteration 21941: loss: 0.049456, loss_s1: 0.044153, loss_fp: 0.001941, loss_freq: 0.005519
[15:53:57.200] iteration 21942: loss: 0.057073, loss_s1: 0.050576, loss_fp: 0.002893, loss_freq: 0.023918
[15:53:57.819] iteration 21943: loss: 0.056229, loss_s1: 0.017869, loss_fp: 0.001089, loss_freq: 0.021249
[15:53:58.472] iteration 21944: loss: 0.054403, loss_s1: 0.038318, loss_fp: 0.004460, loss_freq: 0.024621
[15:53:59.112] iteration 21945: loss: 0.047491, loss_s1: 0.020021, loss_fp: 0.003854, loss_freq: 0.033102
[15:53:59.735] iteration 21946: loss: 0.095313, loss_s1: 0.050024, loss_fp: 0.003235, loss_freq: 0.089433
[15:54:00.357] iteration 21947: loss: 0.066501, loss_s1: 0.087422, loss_fp: 0.001893, loss_freq: 0.007606
[15:54:00.984] iteration 21948: loss: 0.038097, loss_s1: 0.017496, loss_fp: 0.002741, loss_freq: 0.019658
[15:54:01.606] iteration 21949: loss: 0.061539, loss_s1: 0.021236, loss_fp: 0.001872, loss_freq: 0.014393
[15:54:02.275] iteration 21950: loss: 0.037348, loss_s1: 0.018373, loss_fp: 0.000336, loss_freq: 0.017236
[15:54:02.890] iteration 21951: loss: 0.088572, loss_s1: 0.054603, loss_fp: 0.012442, loss_freq: 0.064804
[15:54:03.519] iteration 21952: loss: 0.059607, loss_s1: 0.014674, loss_fp: 0.013746, loss_freq: 0.061997
[15:54:04.154] iteration 21953: loss: 0.085327, loss_s1: 0.051051, loss_fp: 0.006069, loss_freq: 0.065348
[15:54:04.805] iteration 21954: loss: 0.086357, loss_s1: 0.072054, loss_fp: 0.029279, loss_freq: 0.040767
[15:54:05.447] iteration 21955: loss: 0.047800, loss_s1: 0.030865, loss_fp: 0.009709, loss_freq: 0.019529
[15:54:06.099] iteration 21956: loss: 0.037835, loss_s1: 0.029339, loss_fp: 0.001396, loss_freq: 0.014954
[15:54:06.716] iteration 21957: loss: 0.041843, loss_s1: 0.014657, loss_fp: 0.010346, loss_freq: 0.009101
[15:54:07.364] iteration 21958: loss: 0.082555, loss_s1: 0.071439, loss_fp: 0.009518, loss_freq: 0.027573
[15:54:08.016] iteration 21959: loss: 0.059821, loss_s1: 0.028017, loss_fp: 0.006635, loss_freq: 0.025950
[15:54:08.704] iteration 21960: loss: 0.109987, loss_s1: 0.036827, loss_fp: 0.004925, loss_freq: 0.047019
[15:54:09.324] iteration 21961: loss: 0.050219, loss_s1: 0.045879, loss_fp: 0.003349, loss_freq: 0.008873
[15:54:09.942] iteration 21962: loss: 0.055892, loss_s1: 0.037668, loss_fp: 0.000914, loss_freq: 0.037758
[15:54:10.563] iteration 21963: loss: 0.044523, loss_s1: 0.033313, loss_fp: 0.003443, loss_freq: 0.020586
[15:54:11.183] iteration 21964: loss: 0.055679, loss_s1: 0.036467, loss_fp: 0.002968, loss_freq: 0.032163
[15:54:11.804] iteration 21965: loss: 0.074464, loss_s1: 0.039482, loss_fp: 0.010265, loss_freq: 0.032695
[15:54:12.428] iteration 21966: loss: 0.035020, loss_s1: 0.028990, loss_fp: 0.001119, loss_freq: 0.004961
[15:54:13.044] iteration 21967: loss: 0.033515, loss_s1: 0.006673, loss_fp: 0.000830, loss_freq: 0.020347
[15:54:13.663] iteration 21968: loss: 0.039478, loss_s1: 0.015529, loss_fp: 0.003192, loss_freq: 0.021301
[15:54:14.287] iteration 21969: loss: 0.062231, loss_s1: 0.073004, loss_fp: 0.006237, loss_freq: 0.014631
[15:54:14.911] iteration 21970: loss: 0.052493, loss_s1: 0.039099, loss_fp: 0.001608, loss_freq: 0.012196
[15:54:15.539] iteration 21971: loss: 0.042840, loss_s1: 0.017867, loss_fp: 0.004007, loss_freq: 0.020354
[15:54:16.240] iteration 21972: loss: 0.054713, loss_s1: 0.047242, loss_fp: 0.009122, loss_freq: 0.017398
[15:54:16.882] iteration 21973: loss: 0.033906, loss_s1: 0.025643, loss_fp: 0.001879, loss_freq: 0.005211
[15:54:17.562] iteration 21974: loss: 0.047815, loss_s1: 0.040381, loss_fp: 0.000457, loss_freq: 0.009411
[15:54:18.224] iteration 21975: loss: 0.051135, loss_s1: 0.012857, loss_fp: 0.001785, loss_freq: 0.011378
[15:54:18.903] iteration 21976: loss: 0.056511, loss_s1: 0.042710, loss_fp: 0.001748, loss_freq: 0.032040
[15:54:19.556] iteration 21977: loss: 0.031984, loss_s1: 0.018001, loss_fp: 0.002705, loss_freq: 0.007849
[15:54:20.253] iteration 21978: loss: 0.059113, loss_s1: 0.049146, loss_fp: 0.001928, loss_freq: 0.014749
[15:54:20.936] iteration 21979: loss: 0.079107, loss_s1: 0.037167, loss_fp: 0.008436, loss_freq: 0.036720
[15:54:21.582] iteration 21980: loss: 0.056421, loss_s1: 0.043417, loss_fp: 0.003471, loss_freq: 0.026890
[15:54:22.248] iteration 21981: loss: 0.068645, loss_s1: 0.035166, loss_fp: 0.008542, loss_freq: 0.044221
[15:54:22.887] iteration 21982: loss: 0.067895, loss_s1: 0.044405, loss_fp: 0.007842, loss_freq: 0.049686
[15:54:23.512] iteration 21983: loss: 0.043990, loss_s1: 0.028692, loss_fp: 0.002449, loss_freq: 0.021783
[15:54:24.140] iteration 21984: loss: 0.053220, loss_s1: 0.034454, loss_fp: 0.000699, loss_freq: 0.008997
[15:54:24.764] iteration 21985: loss: 0.076989, loss_s1: 0.040325, loss_fp: 0.002468, loss_freq: 0.030851
[15:54:25.394] iteration 21986: loss: 0.123020, loss_s1: 0.105259, loss_fp: 0.009535, loss_freq: 0.081838
[15:54:26.018] iteration 21987: loss: 0.052588, loss_s1: 0.053255, loss_fp: 0.001243, loss_freq: 0.014829
[15:54:26.646] iteration 21988: loss: 0.067733, loss_s1: 0.026581, loss_fp: 0.004802, loss_freq: 0.043678
[15:54:27.333] iteration 21989: loss: 0.063985, loss_s1: 0.054459, loss_fp: 0.003541, loss_freq: 0.039550
[15:54:27.965] iteration 21990: loss: 0.068197, loss_s1: 0.021658, loss_fp: 0.025989, loss_freq: 0.029991
[15:54:28.591] iteration 21991: loss: 0.054141, loss_s1: 0.033702, loss_fp: 0.006537, loss_freq: 0.036007
[15:54:29.218] iteration 21992: loss: 0.033802, loss_s1: 0.013696, loss_fp: 0.000846, loss_freq: 0.007945
[15:54:29.837] iteration 21993: loss: 0.059945, loss_s1: 0.034379, loss_fp: 0.005404, loss_freq: 0.038590
[15:54:30.458] iteration 21994: loss: 0.049444, loss_s1: 0.017192, loss_fp: 0.007335, loss_freq: 0.008523
[15:54:31.077] iteration 21995: loss: 0.032917, loss_s1: 0.009763, loss_fp: 0.001112, loss_freq: 0.014428
[15:54:31.701] iteration 21996: loss: 0.064383, loss_s1: 0.043741, loss_fp: 0.001970, loss_freq: 0.036976
[15:54:32.321] iteration 21997: loss: 0.078626, loss_s1: 0.092146, loss_fp: 0.002706, loss_freq: 0.026236
[15:54:32.939] iteration 21998: loss: 0.040061, loss_s1: 0.020353, loss_fp: 0.001100, loss_freq: 0.019018
[15:54:33.566] iteration 21999: loss: 0.057168, loss_s1: 0.026514, loss_fp: 0.003523, loss_freq: 0.037372
[15:54:34.198] iteration 22000: loss: 0.049856, loss_s1: 0.023591, loss_fp: 0.006742, loss_freq: 0.035395
[15:54:37.649] iteration 22000 : mean_dice : 0.785528
[15:54:38.289] iteration 22001: loss: 0.035834, loss_s1: 0.011075, loss_fp: 0.001769, loss_freq: 0.020958
[15:54:38.920] iteration 22002: loss: 0.031482, loss_s1: 0.024676, loss_fp: 0.001628, loss_freq: 0.006004
[15:54:39.537] iteration 22003: loss: 0.066842, loss_s1: 0.074937, loss_fp: 0.002358, loss_freq: 0.029742
[15:54:40.152] iteration 22004: loss: 0.057823, loss_s1: 0.057666, loss_fp: 0.005385, loss_freq: 0.023668
[15:54:40.768] iteration 22005: loss: 0.073715, loss_s1: 0.059258, loss_fp: 0.002925, loss_freq: 0.021939
[15:54:41.392] iteration 22006: loss: 0.051583, loss_s1: 0.033314, loss_fp: 0.001547, loss_freq: 0.032930
[15:54:42.008] iteration 22007: loss: 0.055750, loss_s1: 0.047494, loss_fp: 0.004692, loss_freq: 0.017715
[15:54:42.632] iteration 22008: loss: 0.053511, loss_s1: 0.044972, loss_fp: 0.008662, loss_freq: 0.007109
[15:54:43.245] iteration 22009: loss: 0.053405, loss_s1: 0.039421, loss_fp: 0.001737, loss_freq: 0.020521
[15:54:43.860] iteration 22010: loss: 0.050382, loss_s1: 0.020898, loss_fp: 0.004492, loss_freq: 0.016264
[15:54:44.487] iteration 22011: loss: 0.047510, loss_s1: 0.023073, loss_fp: 0.004410, loss_freq: 0.018213
[15:54:45.108] iteration 22012: loss: 0.056174, loss_s1: 0.047508, loss_fp: 0.009121, loss_freq: 0.017510
[15:54:45.773] iteration 22013: loss: 0.056435, loss_s1: 0.025952, loss_fp: 0.001483, loss_freq: 0.034305
[15:54:46.408] iteration 22014: loss: 0.042070, loss_s1: 0.017348, loss_fp: 0.002346, loss_freq: 0.013097
[15:54:47.051] iteration 22015: loss: 0.084280, loss_s1: 0.063938, loss_fp: 0.007317, loss_freq: 0.055658
[15:54:47.698] iteration 22016: loss: 0.040554, loss_s1: 0.022630, loss_fp: 0.003783, loss_freq: 0.011236
[15:54:48.318] iteration 22017: loss: 0.041216, loss_s1: 0.036557, loss_fp: 0.002162, loss_freq: 0.006128
[15:54:48.938] iteration 22018: loss: 0.055294, loss_s1: 0.047129, loss_fp: 0.002516, loss_freq: 0.020543
[15:54:49.564] iteration 22019: loss: 0.079370, loss_s1: 0.037508, loss_fp: 0.011977, loss_freq: 0.020419
[15:54:50.184] iteration 22020: loss: 0.094160, loss_s1: 0.068305, loss_fp: 0.007704, loss_freq: 0.071294
[15:54:50.794] iteration 22021: loss: 0.094888, loss_s1: 0.120558, loss_fp: 0.014458, loss_freq: 0.013286
[15:54:51.410] iteration 22022: loss: 0.029521, loss_s1: 0.007749, loss_fp: 0.000451, loss_freq: 0.015454
[15:54:52.435] iteration 22023: loss: 0.038819, loss_s1: 0.030801, loss_fp: 0.000505, loss_freq: 0.006261
[15:54:53.058] iteration 22024: loss: 0.039096, loss_s1: 0.022082, loss_fp: 0.005778, loss_freq: 0.015188
[15:54:53.698] iteration 22025: loss: 0.038779, loss_s1: 0.014142, loss_fp: 0.001886, loss_freq: 0.025661
[15:54:54.457] iteration 22026: loss: 0.057523, loss_s1: 0.035874, loss_fp: 0.005600, loss_freq: 0.023823
[15:54:55.386] iteration 22027: loss: 0.042353, loss_s1: 0.040606, loss_fp: 0.000881, loss_freq: 0.015513
[15:54:56.341] iteration 22028: loss: 0.036552, loss_s1: 0.025322, loss_fp: 0.001086, loss_freq: 0.009679
[15:54:57.186] iteration 22029: loss: 0.033454, loss_s1: 0.020609, loss_fp: 0.004469, loss_freq: 0.013059
[15:54:57.855] iteration 22030: loss: 0.063018, loss_s1: 0.039118, loss_fp: 0.000521, loss_freq: 0.025139
[15:54:58.486] iteration 22031: loss: 0.046037, loss_s1: 0.030606, loss_fp: 0.006639, loss_freq: 0.017161
[15:54:59.163] iteration 22032: loss: 0.060024, loss_s1: 0.055890, loss_fp: 0.000525, loss_freq: 0.011067
[15:54:59.797] iteration 22033: loss: 0.087573, loss_s1: 0.074691, loss_fp: 0.010941, loss_freq: 0.047690
[15:55:00.426] iteration 22034: loss: 0.052935, loss_s1: 0.019370, loss_fp: 0.003046, loss_freq: 0.023407
[15:55:01.050] iteration 22035: loss: 0.051315, loss_s1: 0.042706, loss_fp: 0.001587, loss_freq: 0.010313
[15:55:01.687] iteration 22036: loss: 0.044683, loss_s1: 0.013965, loss_fp: 0.003548, loss_freq: 0.040860
[15:55:02.316] iteration 22037: loss: 0.032828, loss_s1: 0.016459, loss_fp: 0.000921, loss_freq: 0.010898
[15:55:02.937] iteration 22038: loss: 0.047878, loss_s1: 0.035149, loss_fp: 0.004207, loss_freq: 0.019357
[15:55:03.606] iteration 22039: loss: 0.062979, loss_s1: 0.035444, loss_fp: 0.005322, loss_freq: 0.049432
[15:55:04.232] iteration 22040: loss: 0.060557, loss_s1: 0.059450, loss_fp: 0.011126, loss_freq: 0.018175
[15:55:04.850] iteration 22041: loss: 0.040161, loss_s1: 0.030088, loss_fp: 0.000879, loss_freq: 0.019832
[15:55:05.469] iteration 22042: loss: 0.050809, loss_s1: 0.044676, loss_fp: 0.004228, loss_freq: 0.012364
[15:55:06.091] iteration 22043: loss: 0.075588, loss_s1: 0.042787, loss_fp: 0.005090, loss_freq: 0.047933
[15:55:06.708] iteration 22044: loss: 0.040874, loss_s1: 0.027055, loss_fp: 0.001317, loss_freq: 0.025594
[15:55:07.321] iteration 22045: loss: 0.079992, loss_s1: 0.071855, loss_fp: 0.003759, loss_freq: 0.028299
[15:55:07.939] iteration 22046: loss: 0.031819, loss_s1: 0.020935, loss_fp: 0.000691, loss_freq: 0.011367
[15:55:08.563] iteration 22047: loss: 0.053827, loss_s1: 0.029510, loss_fp: 0.001965, loss_freq: 0.024247
[15:55:09.203] iteration 22048: loss: 0.061838, loss_s1: 0.052240, loss_fp: 0.004149, loss_freq: 0.022298
[15:55:09.821] iteration 22049: loss: 0.062574, loss_s1: 0.062320, loss_fp: 0.001851, loss_freq: 0.021080
[15:55:10.440] iteration 22050: loss: 0.040946, loss_s1: 0.033482, loss_fp: 0.003499, loss_freq: 0.010088
[15:55:11.059] iteration 22051: loss: 0.076223, loss_s1: 0.059663, loss_fp: 0.003284, loss_freq: 0.042213
[15:55:11.671] iteration 22052: loss: 0.058116, loss_s1: 0.043713, loss_fp: 0.004619, loss_freq: 0.016343
[15:55:12.292] iteration 22053: loss: 0.053813, loss_s1: 0.022567, loss_fp: 0.001891, loss_freq: 0.007625
[15:55:12.914] iteration 22054: loss: 0.044420, loss_s1: 0.026489, loss_fp: 0.002771, loss_freq: 0.021299
[15:55:13.531] iteration 22055: loss: 0.072859, loss_s1: 0.063016, loss_fp: 0.005210, loss_freq: 0.044903
[15:55:14.147] iteration 22056: loss: 0.076634, loss_s1: 0.060792, loss_fp: 0.013567, loss_freq: 0.040547
[15:55:14.774] iteration 22057: loss: 0.105745, loss_s1: 0.057497, loss_fp: 0.006916, loss_freq: 0.019969
[15:55:15.399] iteration 22058: loss: 0.060800, loss_s1: 0.053691, loss_fp: 0.001612, loss_freq: 0.021723
[15:55:16.023] iteration 22059: loss: 0.072756, loss_s1: 0.042499, loss_fp: 0.005564, loss_freq: 0.040438
[15:55:16.645] iteration 22060: loss: 0.058034, loss_s1: 0.042753, loss_fp: 0.006903, loss_freq: 0.029354
[15:55:17.264] iteration 22061: loss: 0.082311, loss_s1: 0.039772, loss_fp: 0.014776, loss_freq: 0.068467
[15:55:17.888] iteration 22062: loss: 0.046392, loss_s1: 0.045518, loss_fp: 0.008171, loss_freq: 0.007993
[15:55:18.517] iteration 22063: loss: 0.074564, loss_s1: 0.072099, loss_fp: 0.010028, loss_freq: 0.014600
[15:55:19.134] iteration 22064: loss: 0.061839, loss_s1: 0.029928, loss_fp: 0.004342, loss_freq: 0.010918
[15:55:19.754] iteration 22065: loss: 0.044807, loss_s1: 0.024383, loss_fp: 0.001513, loss_freq: 0.011179
[15:55:20.375] iteration 22066: loss: 0.052678, loss_s1: 0.024569, loss_fp: 0.004286, loss_freq: 0.036576
[15:55:20.993] iteration 22067: loss: 0.052032, loss_s1: 0.005680, loss_fp: 0.003445, loss_freq: 0.016955
[15:55:21.659] iteration 22068: loss: 0.054397, loss_s1: 0.030441, loss_fp: 0.001388, loss_freq: 0.039014
[15:55:22.277] iteration 22069: loss: 0.048142, loss_s1: 0.028979, loss_fp: 0.003390, loss_freq: 0.019206
[15:55:22.891] iteration 22070: loss: 0.085970, loss_s1: 0.112001, loss_fp: 0.001266, loss_freq: 0.013944
[15:55:23.502] iteration 22071: loss: 0.062502, loss_s1: 0.042639, loss_fp: 0.005239, loss_freq: 0.044916
[15:55:24.116] iteration 22072: loss: 0.071023, loss_s1: 0.045785, loss_fp: 0.002631, loss_freq: 0.048445
[15:55:24.743] iteration 22073: loss: 0.040385, loss_s1: 0.025960, loss_fp: 0.004036, loss_freq: 0.010710
[15:55:25.363] iteration 22074: loss: 0.087679, loss_s1: 0.030136, loss_fp: 0.002469, loss_freq: 0.023771
[15:55:25.979] iteration 22075: loss: 0.044187, loss_s1: 0.037826, loss_fp: 0.003368, loss_freq: 0.011307
[15:55:26.596] iteration 22076: loss: 0.044908, loss_s1: 0.037948, loss_fp: 0.001700, loss_freq: 0.018288
[15:55:27.213] iteration 22077: loss: 0.054740, loss_s1: 0.059593, loss_fp: 0.002132, loss_freq: 0.016046
[15:55:27.838] iteration 22078: loss: 0.042327, loss_s1: 0.009696, loss_fp: 0.002088, loss_freq: 0.010163
[15:55:28.454] iteration 22079: loss: 0.032922, loss_s1: 0.025177, loss_fp: 0.002059, loss_freq: 0.002189
[15:55:29.072] iteration 22080: loss: 0.032615, loss_s1: 0.017505, loss_fp: 0.000851, loss_freq: 0.012656
[15:55:29.694] iteration 22081: loss: 0.056285, loss_s1: 0.033200, loss_fp: 0.002088, loss_freq: 0.036862
[15:55:30.367] iteration 22082: loss: 0.065815, loss_s1: 0.057618, loss_fp: 0.001189, loss_freq: 0.030613
[15:55:30.988] iteration 22083: loss: 0.074805, loss_s1: 0.071314, loss_fp: 0.004663, loss_freq: 0.021985
[15:55:31.607] iteration 22084: loss: 0.049217, loss_s1: 0.030577, loss_fp: 0.008126, loss_freq: 0.013729
[15:55:32.228] iteration 22085: loss: 0.131271, loss_s1: 0.110740, loss_fp: 0.004761, loss_freq: 0.100401
[15:55:32.843] iteration 22086: loss: 0.044532, loss_s1: 0.020366, loss_fp: 0.004124, loss_freq: 0.016844
[15:55:33.455] iteration 22087: loss: 0.060917, loss_s1: 0.028941, loss_fp: 0.006258, loss_freq: 0.039981
[15:55:34.072] iteration 22088: loss: 0.042940, loss_s1: 0.023198, loss_fp: 0.004407, loss_freq: 0.015959
[15:55:34.689] iteration 22089: loss: 0.057454, loss_s1: 0.034271, loss_fp: 0.010458, loss_freq: 0.033380
[15:55:35.305] iteration 22090: loss: 0.047055, loss_s1: 0.031973, loss_fp: 0.011288, loss_freq: 0.012560
[15:55:35.921] iteration 22091: loss: 0.055314, loss_s1: 0.061799, loss_fp: 0.002137, loss_freq: 0.011402
[15:55:36.572] iteration 22092: loss: 0.042389, loss_s1: 0.028713, loss_fp: 0.003304, loss_freq: 0.010850
[15:55:37.197] iteration 22093: loss: 0.041708, loss_s1: 0.014049, loss_fp: 0.004375, loss_freq: 0.011654
[15:55:37.820] iteration 22094: loss: 0.079737, loss_s1: 0.058824, loss_fp: 0.006049, loss_freq: 0.037091
[15:55:38.450] iteration 22095: loss: 0.069746, loss_s1: 0.037906, loss_fp: 0.006351, loss_freq: 0.065555
[15:55:39.080] iteration 22096: loss: 0.094875, loss_s1: 0.115969, loss_fp: 0.003577, loss_freq: 0.014806
[15:55:39.714] iteration 22097: loss: 0.062569, loss_s1: 0.063921, loss_fp: 0.002507, loss_freq: 0.031556
[15:55:40.366] iteration 22098: loss: 0.073098, loss_s1: 0.024185, loss_fp: 0.002984, loss_freq: 0.018704
[15:55:40.991] iteration 22099: loss: 0.048782, loss_s1: 0.043010, loss_fp: 0.002246, loss_freq: 0.020734
[15:55:41.621] iteration 22100: loss: 0.052320, loss_s1: 0.043870, loss_fp: 0.002311, loss_freq: 0.012246
[15:55:42.241] iteration 22101: loss: 0.048603, loss_s1: 0.032561, loss_fp: 0.004649, loss_freq: 0.021852
[15:55:42.853] iteration 22102: loss: 0.088977, loss_s1: 0.057161, loss_fp: 0.007301, loss_freq: 0.021893
[15:55:43.477] iteration 22103: loss: 0.042744, loss_s1: 0.035021, loss_fp: 0.001086, loss_freq: 0.008813
[15:55:44.095] iteration 22104: loss: 0.055083, loss_s1: 0.017409, loss_fp: 0.002272, loss_freq: 0.029570
[15:55:44.710] iteration 22105: loss: 0.049634, loss_s1: 0.024844, loss_fp: 0.000539, loss_freq: 0.011866
[15:55:45.326] iteration 22106: loss: 0.037285, loss_s1: 0.032094, loss_fp: 0.001799, loss_freq: 0.009611
[15:55:45.952] iteration 22107: loss: 0.082637, loss_s1: 0.064687, loss_fp: 0.003643, loss_freq: 0.046387
[15:55:46.577] iteration 22108: loss: 0.072144, loss_s1: 0.042349, loss_fp: 0.008399, loss_freq: 0.035826
[15:55:47.191] iteration 22109: loss: 0.035443, loss_s1: 0.013851, loss_fp: 0.001435, loss_freq: 0.012006
[15:55:47.809] iteration 22110: loss: 0.042202, loss_s1: 0.015883, loss_fp: 0.002428, loss_freq: 0.017416
[15:55:48.431] iteration 22111: loss: 0.062989, loss_s1: 0.057788, loss_fp: 0.002141, loss_freq: 0.013798
[15:55:49.052] iteration 22112: loss: 0.049994, loss_s1: 0.053184, loss_fp: 0.002335, loss_freq: 0.016146
[15:55:49.696] iteration 22113: loss: 0.071216, loss_s1: 0.053648, loss_fp: 0.004321, loss_freq: 0.033614
[15:55:50.322] iteration 22114: loss: 0.050960, loss_s1: 0.049760, loss_fp: 0.005068, loss_freq: 0.017471
[15:55:50.992] iteration 22115: loss: 0.043308, loss_s1: 0.029280, loss_fp: 0.001493, loss_freq: 0.011823
[15:55:51.613] iteration 22116: loss: 0.039608, loss_s1: 0.030470, loss_fp: 0.003652, loss_freq: 0.008482
[15:55:52.229] iteration 22117: loss: 0.033882, loss_s1: 0.015561, loss_fp: 0.001629, loss_freq: 0.009749
[15:55:52.851] iteration 22118: loss: 0.031905, loss_s1: 0.009496, loss_fp: 0.001006, loss_freq: 0.003341
[15:55:53.475] iteration 22119: loss: 0.075355, loss_s1: 0.051350, loss_fp: 0.009535, loss_freq: 0.029112
[15:55:54.092] iteration 22120: loss: 0.074622, loss_s1: 0.066372, loss_fp: 0.001930, loss_freq: 0.044420
[15:55:54.718] iteration 22121: loss: 0.071262, loss_s1: 0.058711, loss_fp: 0.002778, loss_freq: 0.020211
[15:55:55.336] iteration 22122: loss: 0.069239, loss_s1: 0.040608, loss_fp: 0.001876, loss_freq: 0.048037
[15:55:55.959] iteration 22123: loss: 0.049303, loss_s1: 0.026073, loss_fp: 0.002417, loss_freq: 0.026532
[15:55:56.583] iteration 22124: loss: 0.074636, loss_s1: 0.023635, loss_fp: 0.001063, loss_freq: 0.030206
[15:55:57.202] iteration 22125: loss: 0.043438, loss_s1: 0.023026, loss_fp: 0.003665, loss_freq: 0.024067
[15:55:57.833] iteration 22126: loss: 0.061098, loss_s1: 0.054955, loss_fp: 0.002347, loss_freq: 0.024647
[15:55:58.453] iteration 22127: loss: 0.043305, loss_s1: 0.014370, loss_fp: 0.003272, loss_freq: 0.028950
[15:55:59.081] iteration 22128: loss: 0.065401, loss_s1: 0.012631, loss_fp: 0.002129, loss_freq: 0.060363
[15:55:59.709] iteration 22129: loss: 0.095289, loss_s1: 0.081232, loss_fp: 0.007929, loss_freq: 0.037508
[15:56:00.334] iteration 22130: loss: 0.065073, loss_s1: 0.051855, loss_fp: 0.005525, loss_freq: 0.031336
[15:56:00.962] iteration 22131: loss: 0.059801, loss_s1: 0.055237, loss_fp: 0.003697, loss_freq: 0.010214
[15:56:01.633] iteration 22132: loss: 0.105766, loss_s1: 0.079142, loss_fp: 0.010815, loss_freq: 0.079837
[15:56:02.284] iteration 22133: loss: 0.073569, loss_s1: 0.015844, loss_fp: 0.000988, loss_freq: 0.050642
[15:56:02.933] iteration 22134: loss: 0.041877, loss_s1: 0.020457, loss_fp: 0.001571, loss_freq: 0.031010
[15:56:03.583] iteration 22135: loss: 0.055532, loss_s1: 0.037396, loss_fp: 0.004101, loss_freq: 0.009828
[15:56:04.248] iteration 22136: loss: 0.093283, loss_s1: 0.072117, loss_fp: 0.004704, loss_freq: 0.070381
[15:56:04.904] iteration 22137: loss: 0.061837, loss_s1: 0.051349, loss_fp: 0.001092, loss_freq: 0.015949
[15:56:05.541] iteration 22138: loss: 0.038212, loss_s1: 0.008121, loss_fp: 0.002812, loss_freq: 0.028328
[15:56:06.167] iteration 22139: loss: 0.058197, loss_s1: 0.034924, loss_fp: 0.007695, loss_freq: 0.033870
[15:56:06.791] iteration 22140: loss: 0.051681, loss_s1: 0.034081, loss_fp: 0.002425, loss_freq: 0.017881
[15:56:07.417] iteration 22141: loss: 0.062416, loss_s1: 0.039172, loss_fp: 0.004584, loss_freq: 0.031832
[15:56:08.039] iteration 22142: loss: 0.046489, loss_s1: 0.022024, loss_fp: 0.003197, loss_freq: 0.024947
[15:56:08.654] iteration 22143: loss: 0.089591, loss_s1: 0.054770, loss_fp: 0.002695, loss_freq: 0.075050
[15:56:09.266] iteration 22144: loss: 0.047551, loss_s1: 0.024155, loss_fp: 0.003103, loss_freq: 0.014620
[15:56:09.893] iteration 22145: loss: 0.028366, loss_s1: 0.015185, loss_fp: 0.000411, loss_freq: 0.006501
[15:56:10.511] iteration 22146: loss: 0.042311, loss_s1: 0.047220, loss_fp: 0.000612, loss_freq: 0.011481
[15:56:11.129] iteration 22147: loss: 0.087250, loss_s1: 0.058902, loss_fp: 0.003713, loss_freq: 0.070417
[15:56:11.750] iteration 22148: loss: 0.064217, loss_s1: 0.034078, loss_fp: 0.000843, loss_freq: 0.022367
[15:56:12.370] iteration 22149: loss: 0.063685, loss_s1: 0.064696, loss_fp: 0.001675, loss_freq: 0.029699
[15:56:12.988] iteration 22150: loss: 0.057007, loss_s1: 0.029799, loss_fp: 0.001386, loss_freq: 0.042223
[15:56:13.604] iteration 22151: loss: 0.060235, loss_s1: 0.062588, loss_fp: 0.001657, loss_freq: 0.006901
[15:56:14.223] iteration 22152: loss: 0.037131, loss_s1: 0.017927, loss_fp: 0.003890, loss_freq: 0.011617
[15:56:14.838] iteration 22153: loss: 0.058807, loss_s1: 0.024095, loss_fp: 0.000986, loss_freq: 0.037052
[15:56:15.453] iteration 22154: loss: 0.069040, loss_s1: 0.041509, loss_fp: 0.007466, loss_freq: 0.032113
[15:56:16.120] iteration 22155: loss: 0.081964, loss_s1: 0.058945, loss_fp: 0.008752, loss_freq: 0.029329
[15:56:16.736] iteration 22156: loss: 0.058669, loss_s1: 0.043679, loss_fp: 0.002246, loss_freq: 0.028702
[15:56:17.355] iteration 22157: loss: 0.057025, loss_s1: 0.014450, loss_fp: 0.002830, loss_freq: 0.049790
[15:56:18.021] iteration 22158: loss: 0.072673, loss_s1: 0.061003, loss_fp: 0.001614, loss_freq: 0.039861
[15:56:18.667] iteration 22159: loss: 0.061403, loss_s1: 0.062974, loss_fp: 0.003074, loss_freq: 0.017381
[15:56:19.317] iteration 22160: loss: 0.028695, loss_s1: 0.006188, loss_fp: 0.001672, loss_freq: 0.009565
[15:56:19.960] iteration 22161: loss: 0.065896, loss_s1: 0.059563, loss_fp: 0.001123, loss_freq: 0.026525
[15:56:20.607] iteration 22162: loss: 0.057805, loss_s1: 0.047921, loss_fp: 0.004137, loss_freq: 0.014458
[15:56:21.227] iteration 22163: loss: 0.064995, loss_s1: 0.065079, loss_fp: 0.003487, loss_freq: 0.030482
[15:56:21.844] iteration 22164: loss: 0.082111, loss_s1: 0.084359, loss_fp: 0.013430, loss_freq: 0.018722
[15:56:22.478] iteration 22165: loss: 0.045560, loss_s1: 0.009248, loss_fp: 0.000756, loss_freq: 0.051858
[15:56:23.501] iteration 22166: loss: 0.047539, loss_s1: 0.041028, loss_fp: 0.004187, loss_freq: 0.010479
[15:56:24.155] iteration 22167: loss: 0.075577, loss_s1: 0.087214, loss_fp: 0.002559, loss_freq: 0.015256
[15:56:24.789] iteration 22168: loss: 0.049481, loss_s1: 0.018388, loss_fp: 0.003604, loss_freq: 0.011539
[15:56:25.415] iteration 22169: loss: 0.040556, loss_s1: 0.021704, loss_fp: 0.001088, loss_freq: 0.016110
[15:56:26.086] iteration 22170: loss: 0.065754, loss_s1: 0.070120, loss_fp: 0.000408, loss_freq: 0.032565
[15:56:26.704] iteration 22171: loss: 0.080185, loss_s1: 0.058453, loss_fp: 0.000590, loss_freq: 0.008792
[15:56:27.323] iteration 22172: loss: 0.028692, loss_s1: 0.004294, loss_fp: 0.003663, loss_freq: 0.019555
[15:56:27.940] iteration 22173: loss: 0.042653, loss_s1: 0.012953, loss_fp: 0.001903, loss_freq: 0.019148
[15:56:28.559] iteration 22174: loss: 0.096024, loss_s1: 0.081128, loss_fp: 0.029078, loss_freq: 0.048668
[15:56:29.241] iteration 22175: loss: 0.042037, loss_s1: 0.003356, loss_fp: 0.000494, loss_freq: 0.003549
[15:56:29.858] iteration 22176: loss: 0.068090, loss_s1: 0.070201, loss_fp: 0.006316, loss_freq: 0.018946
[15:56:30.521] iteration 22177: loss: 0.047259, loss_s1: 0.022692, loss_fp: 0.001280, loss_freq: 0.026135
[15:56:31.145] iteration 22178: loss: 0.058691, loss_s1: 0.066057, loss_fp: 0.001456, loss_freq: 0.015677
[15:56:31.761] iteration 22179: loss: 0.045173, loss_s1: 0.021749, loss_fp: 0.002759, loss_freq: 0.028152
[15:56:32.387] iteration 22180: loss: 0.079316, loss_s1: 0.083471, loss_fp: 0.000437, loss_freq: 0.036235
[15:56:33.011] iteration 22181: loss: 0.036921, loss_s1: 0.018972, loss_fp: 0.003076, loss_freq: 0.020144
[15:56:33.646] iteration 22182: loss: 0.068452, loss_s1: 0.047716, loss_fp: 0.003643, loss_freq: 0.027589
[15:56:34.268] iteration 22183: loss: 0.046761, loss_s1: 0.018496, loss_fp: 0.004373, loss_freq: 0.034294
[15:56:34.885] iteration 22184: loss: 0.040482, loss_s1: 0.035637, loss_fp: 0.002683, loss_freq: 0.012456
[15:56:35.505] iteration 22185: loss: 0.036107, loss_s1: 0.027372, loss_fp: 0.001844, loss_freq: 0.011518
[15:56:36.118] iteration 22186: loss: 0.069466, loss_s1: 0.029008, loss_fp: 0.003179, loss_freq: 0.061427
[15:56:36.747] iteration 22187: loss: 0.065458, loss_s1: 0.058289, loss_fp: 0.002678, loss_freq: 0.035684
[15:56:37.362] iteration 22188: loss: 0.056939, loss_s1: 0.046310, loss_fp: 0.006940, loss_freq: 0.024608
[15:56:37.978] iteration 22189: loss: 0.054175, loss_s1: 0.053649, loss_fp: 0.001189, loss_freq: 0.015422
[15:56:38.595] iteration 22190: loss: 0.042148, loss_s1: 0.027020, loss_fp: 0.002698, loss_freq: 0.016449
[15:56:39.226] iteration 22191: loss: 0.061133, loss_s1: 0.039974, loss_fp: 0.005271, loss_freq: 0.029759
[15:56:39.851] iteration 22192: loss: 0.076439, loss_s1: 0.035612, loss_fp: 0.004847, loss_freq: 0.038360
[15:56:40.466] iteration 22193: loss: 0.051128, loss_s1: 0.054390, loss_fp: 0.001325, loss_freq: 0.004985
[15:56:41.090] iteration 22194: loss: 0.070278, loss_s1: 0.066367, loss_fp: 0.003397, loss_freq: 0.022184
[15:56:41.706] iteration 22195: loss: 0.082164, loss_s1: 0.077128, loss_fp: 0.000542, loss_freq: 0.016605
[15:56:42.324] iteration 22196: loss: 0.032533, loss_s1: 0.014989, loss_fp: 0.000811, loss_freq: 0.010122
[15:56:42.949] iteration 22197: loss: 0.075622, loss_s1: 0.079809, loss_fp: 0.007748, loss_freq: 0.024237
[15:56:43.586] iteration 22198: loss: 0.089519, loss_s1: 0.088332, loss_fp: 0.007475, loss_freq: 0.051003
[15:56:44.213] iteration 22199: loss: 0.087622, loss_s1: 0.075500, loss_fp: 0.005623, loss_freq: 0.054371
[15:56:44.843] iteration 22200: loss: 0.058598, loss_s1: 0.054394, loss_fp: 0.005836, loss_freq: 0.016716
[15:56:48.248] iteration 22200 : mean_dice : 0.787292
[15:56:48.937] iteration 22201: loss: 0.097526, loss_s1: 0.065527, loss_fp: 0.007999, loss_freq: 0.077198
[15:56:49.572] iteration 22202: loss: 0.044371, loss_s1: 0.028442, loss_fp: 0.003538, loss_freq: 0.008573
[15:56:50.194] iteration 22203: loss: 0.039365, loss_s1: 0.029275, loss_fp: 0.002547, loss_freq: 0.013590
[15:56:50.818] iteration 22204: loss: 0.080438, loss_s1: 0.084322, loss_fp: 0.012016, loss_freq: 0.024895
[15:56:51.476] iteration 22205: loss: 0.050217, loss_s1: 0.056376, loss_fp: 0.001965, loss_freq: 0.014288
[15:56:52.095] iteration 22206: loss: 0.056853, loss_s1: 0.060667, loss_fp: 0.003438, loss_freq: 0.004871
[15:56:52.720] iteration 22207: loss: 0.036585, loss_s1: 0.028091, loss_fp: 0.000772, loss_freq: 0.010244
[15:56:53.348] iteration 22208: loss: 0.036499, loss_s1: 0.018761, loss_fp: 0.000674, loss_freq: 0.014919
[15:56:53.981] iteration 22209: loss: 0.065690, loss_s1: 0.048967, loss_fp: 0.003854, loss_freq: 0.043410
[15:56:54.612] iteration 22210: loss: 0.098916, loss_s1: 0.055453, loss_fp: 0.004183, loss_freq: 0.029788
[15:56:55.242] iteration 22211: loss: 0.085677, loss_s1: 0.059553, loss_fp: 0.002545, loss_freq: 0.046509
[15:56:55.865] iteration 22212: loss: 0.053226, loss_s1: 0.028275, loss_fp: 0.000974, loss_freq: 0.037753
[15:56:56.532] iteration 22213: loss: 0.058873, loss_s1: 0.033196, loss_fp: 0.005533, loss_freq: 0.043543
[15:56:57.153] iteration 22214: loss: 0.068449, loss_s1: 0.051717, loss_fp: 0.004186, loss_freq: 0.041986
[15:56:57.773] iteration 22215: loss: 0.039288, loss_s1: 0.013687, loss_fp: 0.001367, loss_freq: 0.025187
[15:56:58.391] iteration 22216: loss: 0.030554, loss_s1: 0.017674, loss_fp: 0.001512, loss_freq: 0.006864
[15:56:59.017] iteration 22217: loss: 0.031079, loss_s1: 0.015957, loss_fp: 0.002658, loss_freq: 0.008898
[15:56:59.908] iteration 22218: loss: 0.056593, loss_s1: 0.058562, loss_fp: 0.000696, loss_freq: 0.017517
[15:57:00.717] iteration 22219: loss: 0.080464, loss_s1: 0.051448, loss_fp: 0.010057, loss_freq: 0.065249
[15:57:01.453] iteration 22220: loss: 0.032666, loss_s1: 0.018823, loss_fp: 0.001180, loss_freq: 0.008144
[15:57:02.135] iteration 22221: loss: 0.040251, loss_s1: 0.020603, loss_fp: 0.001292, loss_freq: 0.010422
[15:57:02.760] iteration 22222: loss: 0.072374, loss_s1: 0.061000, loss_fp: 0.003901, loss_freq: 0.042302
[15:57:03.386] iteration 22223: loss: 0.043115, loss_s1: 0.016340, loss_fp: 0.001890, loss_freq: 0.012443
[15:57:04.002] iteration 22224: loss: 0.080998, loss_s1: 0.065205, loss_fp: 0.003392, loss_freq: 0.056450
[15:57:04.625] iteration 22225: loss: 0.065319, loss_s1: 0.049903, loss_fp: 0.003079, loss_freq: 0.034576
[15:57:05.248] iteration 22226: loss: 0.039221, loss_s1: 0.012631, loss_fp: 0.002330, loss_freq: 0.012843
[15:57:05.873] iteration 22227: loss: 0.055832, loss_s1: 0.040261, loss_fp: 0.009156, loss_freq: 0.008865
[15:57:06.492] iteration 22228: loss: 0.046690, loss_s1: 0.020208, loss_fp: 0.003482, loss_freq: 0.030954
[15:57:07.119] iteration 22229: loss: 0.052189, loss_s1: 0.024647, loss_fp: 0.002807, loss_freq: 0.029499
[15:57:07.731] iteration 22230: loss: 0.039288, loss_s1: 0.027521, loss_fp: 0.000949, loss_freq: 0.004774
[15:57:08.388] iteration 22231: loss: 0.054143, loss_s1: 0.018528, loss_fp: 0.005674, loss_freq: 0.012555
[15:57:09.018] iteration 22232: loss: 0.125971, loss_s1: 0.064815, loss_fp: 0.012307, loss_freq: 0.116166
[15:57:09.636] iteration 22233: loss: 0.056169, loss_s1: 0.028196, loss_fp: 0.005365, loss_freq: 0.044789
[15:57:10.257] iteration 22234: loss: 0.048682, loss_s1: 0.049396, loss_fp: 0.004773, loss_freq: 0.011714
[15:57:10.888] iteration 22235: loss: 0.068164, loss_s1: 0.036700, loss_fp: 0.002147, loss_freq: 0.011296
[15:57:11.518] iteration 22236: loss: 0.037715, loss_s1: 0.011298, loss_fp: 0.001240, loss_freq: 0.016261
[15:57:12.150] iteration 22237: loss: 0.078310, loss_s1: 0.063029, loss_fp: 0.022876, loss_freq: 0.037208
[15:57:12.782] iteration 22238: loss: 0.078105, loss_s1: 0.035068, loss_fp: 0.003309, loss_freq: 0.087633
[15:57:13.422] iteration 22239: loss: 0.071772, loss_s1: 0.060853, loss_fp: 0.010690, loss_freq: 0.007381
[15:57:14.045] iteration 22240: loss: 0.063658, loss_s1: 0.046050, loss_fp: 0.011251, loss_freq: 0.038905
[15:57:14.665] iteration 22241: loss: 0.065331, loss_s1: 0.040873, loss_fp: 0.002821, loss_freq: 0.026606
[15:57:15.286] iteration 22242: loss: 0.034272, loss_s1: 0.019017, loss_fp: 0.004899, loss_freq: 0.011869
[15:57:15.897] iteration 22243: loss: 0.042125, loss_s1: 0.028761, loss_fp: 0.003181, loss_freq: 0.010178
[15:57:16.519] iteration 22244: loss: 0.109303, loss_s1: 0.081759, loss_fp: 0.016493, loss_freq: 0.055067
[15:57:17.176] iteration 22245: loss: 0.113617, loss_s1: 0.108516, loss_fp: 0.005702, loss_freq: 0.040479
[15:57:17.818] iteration 22246: loss: 0.063966, loss_s1: 0.047414, loss_fp: 0.010723, loss_freq: 0.031881
[15:57:18.453] iteration 22247: loss: 0.042231, loss_s1: 0.028741, loss_fp: 0.005219, loss_freq: 0.016089
[15:57:19.123] iteration 22248: loss: 0.062962, loss_s1: 0.041703, loss_fp: 0.001629, loss_freq: 0.033922
[15:57:19.740] iteration 22249: loss: 0.040492, loss_s1: 0.020699, loss_fp: 0.001683, loss_freq: 0.013490
[15:57:20.363] iteration 22250: loss: 0.041616, loss_s1: 0.014886, loss_fp: 0.003865, loss_freq: 0.023898
[15:57:20.981] iteration 22251: loss: 0.054625, loss_s1: 0.037782, loss_fp: 0.003287, loss_freq: 0.031207
[15:57:21.605] iteration 22252: loss: 0.045267, loss_s1: 0.038273, loss_fp: 0.004028, loss_freq: 0.008513
[15:57:22.221] iteration 22253: loss: 0.037985, loss_s1: 0.028057, loss_fp: 0.000553, loss_freq: 0.012568
[15:57:22.841] iteration 22254: loss: 0.034781, loss_s1: 0.020892, loss_fp: 0.003163, loss_freq: 0.013222
[15:57:23.461] iteration 22255: loss: 0.059421, loss_s1: 0.044444, loss_fp: 0.006971, loss_freq: 0.015862
[15:57:24.129] iteration 22256: loss: 0.057966, loss_s1: 0.023208, loss_fp: 0.004403, loss_freq: 0.031892
[15:57:24.747] iteration 22257: loss: 0.034789, loss_s1: 0.022659, loss_fp: 0.000869, loss_freq: 0.013939
[15:57:25.376] iteration 22258: loss: 0.045745, loss_s1: 0.040667, loss_fp: 0.000823, loss_freq: 0.012085
[15:57:25.998] iteration 22259: loss: 0.045559, loss_s1: 0.035820, loss_fp: 0.002171, loss_freq: 0.017031
[15:57:26.617] iteration 22260: loss: 0.042322, loss_s1: 0.022914, loss_fp: 0.005656, loss_freq: 0.017776
[15:57:27.241] iteration 22261: loss: 0.038750, loss_s1: 0.023399, loss_fp: 0.003726, loss_freq: 0.006322
[15:57:27.864] iteration 22262: loss: 0.063601, loss_s1: 0.048396, loss_fp: 0.008022, loss_freq: 0.035699
[15:57:28.531] iteration 22263: loss: 0.045832, loss_s1: 0.024130, loss_fp: 0.001127, loss_freq: 0.029649
[15:57:29.179] iteration 22264: loss: 0.051022, loss_s1: 0.036266, loss_fp: 0.002653, loss_freq: 0.018221
[15:57:29.827] iteration 22265: loss: 0.113765, loss_s1: 0.017558, loss_fp: 0.005304, loss_freq: 0.037590
[15:57:30.466] iteration 22266: loss: 0.039472, loss_s1: 0.015725, loss_fp: 0.001006, loss_freq: 0.010491
[15:57:31.095] iteration 22267: loss: 0.079026, loss_s1: 0.064653, loss_fp: 0.001463, loss_freq: 0.048409
[15:57:31.710] iteration 22268: loss: 0.072030, loss_s1: 0.069277, loss_fp: 0.006258, loss_freq: 0.036080
[15:57:32.335] iteration 22269: loss: 0.027034, loss_s1: 0.007212, loss_fp: 0.007529, loss_freq: 0.004606
[15:57:32.955] iteration 22270: loss: 0.062020, loss_s1: 0.025242, loss_fp: 0.003322, loss_freq: 0.013224
[15:57:33.568] iteration 22271: loss: 0.047949, loss_s1: 0.035377, loss_fp: 0.002891, loss_freq: 0.019282
[15:57:34.207] iteration 22272: loss: 0.108865, loss_s1: 0.107088, loss_fp: 0.005609, loss_freq: 0.059792
[15:57:34.826] iteration 22273: loss: 0.050291, loss_s1: 0.033117, loss_fp: 0.006683, loss_freq: 0.023109
[15:57:35.452] iteration 22274: loss: 0.074723, loss_s1: 0.073209, loss_fp: 0.001547, loss_freq: 0.030580
[15:57:36.080] iteration 22275: loss: 0.096103, loss_s1: 0.049735, loss_fp: 0.007944, loss_freq: 0.050968
[15:57:36.723] iteration 22276: loss: 0.035538, loss_s1: 0.028365, loss_fp: 0.000971, loss_freq: 0.006738
[15:57:37.336] iteration 22277: loss: 0.071955, loss_s1: 0.063804, loss_fp: 0.011549, loss_freq: 0.037464
[15:57:37.959] iteration 22278: loss: 0.050238, loss_s1: 0.024500, loss_fp: 0.001388, loss_freq: 0.010092
[15:57:38.596] iteration 22279: loss: 0.059422, loss_s1: 0.046536, loss_fp: 0.008279, loss_freq: 0.018488
[15:57:39.245] iteration 22280: loss: 0.038264, loss_s1: 0.006343, loss_fp: 0.003341, loss_freq: 0.010436
[15:57:39.857] iteration 22281: loss: 0.040477, loss_s1: 0.030245, loss_fp: 0.000472, loss_freq: 0.009061
[15:57:40.475] iteration 22282: loss: 0.068169, loss_s1: 0.069818, loss_fp: 0.003650, loss_freq: 0.023068
[15:57:41.094] iteration 22283: loss: 0.055064, loss_s1: 0.045204, loss_fp: 0.004195, loss_freq: 0.024625
[15:57:41.705] iteration 22284: loss: 0.034780, loss_s1: 0.031382, loss_fp: 0.002077, loss_freq: 0.008182
[15:57:42.319] iteration 22285: loss: 0.052920, loss_s1: 0.034139, loss_fp: 0.002808, loss_freq: 0.022324
[15:57:42.967] iteration 22286: loss: 0.063069, loss_s1: 0.044129, loss_fp: 0.001776, loss_freq: 0.035045
[15:57:43.619] iteration 22287: loss: 0.075338, loss_s1: 0.050906, loss_fp: 0.005024, loss_freq: 0.012200
[15:57:44.306] iteration 22288: loss: 0.030171, loss_s1: 0.010307, loss_fp: 0.001070, loss_freq: 0.007998
[15:57:44.922] iteration 22289: loss: 0.044173, loss_s1: 0.041570, loss_fp: 0.002322, loss_freq: 0.015780
[15:57:45.545] iteration 22290: loss: 0.060631, loss_s1: 0.067506, loss_fp: 0.011200, loss_freq: 0.011151
[15:57:46.172] iteration 22291: loss: 0.051066, loss_s1: 0.043698, loss_fp: 0.001970, loss_freq: 0.019697
[15:57:46.795] iteration 22292: loss: 0.071568, loss_s1: 0.032966, loss_fp: 0.001763, loss_freq: 0.040961
[15:57:47.415] iteration 22293: loss: 0.066909, loss_s1: 0.063246, loss_fp: 0.002088, loss_freq: 0.031180
[15:57:48.084] iteration 22294: loss: 0.040517, loss_s1: 0.042852, loss_fp: 0.001309, loss_freq: 0.008561
[15:57:48.700] iteration 22295: loss: 0.053254, loss_s1: 0.038194, loss_fp: 0.003702, loss_freq: 0.014432
[15:57:49.315] iteration 22296: loss: 0.054473, loss_s1: 0.024933, loss_fp: 0.004679, loss_freq: 0.024087
[15:57:49.934] iteration 22297: loss: 0.053494, loss_s1: 0.044381, loss_fp: 0.003571, loss_freq: 0.016788
[15:57:50.598] iteration 22298: loss: 0.070336, loss_s1: 0.076135, loss_fp: 0.004662, loss_freq: 0.017660
[15:57:51.224] iteration 22299: loss: 0.083159, loss_s1: 0.047597, loss_fp: 0.013334, loss_freq: 0.043095
[15:57:51.846] iteration 22300: loss: 0.047510, loss_s1: 0.017568, loss_fp: 0.011663, loss_freq: 0.015823
[15:57:52.473] iteration 22301: loss: 0.049352, loss_s1: 0.044972, loss_fp: 0.003864, loss_freq: 0.010855
[15:57:53.092] iteration 22302: loss: 0.057401, loss_s1: 0.036864, loss_fp: 0.005968, loss_freq: 0.030963
[15:57:53.716] iteration 22303: loss: 0.034189, loss_s1: 0.022568, loss_fp: 0.003202, loss_freq: 0.007483
[15:57:54.342] iteration 22304: loss: 0.075658, loss_s1: 0.082612, loss_fp: 0.003497, loss_freq: 0.024397
[15:57:54.972] iteration 22305: loss: 0.085437, loss_s1: 0.039128, loss_fp: 0.014562, loss_freq: 0.013072
[15:57:55.601] iteration 22306: loss: 0.069038, loss_s1: 0.061720, loss_fp: 0.005086, loss_freq: 0.027110
[15:57:56.216] iteration 22307: loss: 0.069027, loss_s1: 0.061847, loss_fp: 0.004807, loss_freq: 0.017734
[15:57:56.839] iteration 22308: loss: 0.047419, loss_s1: 0.017240, loss_fp: 0.003203, loss_freq: 0.036524
[15:57:57.803] iteration 22309: loss: 0.038458, loss_s1: 0.020971, loss_fp: 0.001673, loss_freq: 0.013144
[15:57:58.467] iteration 22310: loss: 0.043120, loss_s1: 0.028457, loss_fp: 0.002945, loss_freq: 0.012684
[15:57:59.111] iteration 22311: loss: 0.032167, loss_s1: 0.014562, loss_fp: 0.001989, loss_freq: 0.016043
[15:57:59.728] iteration 22312: loss: 0.056812, loss_s1: 0.036917, loss_fp: 0.003844, loss_freq: 0.018872
[15:58:00.346] iteration 22313: loss: 0.074244, loss_s1: 0.060552, loss_fp: 0.005618, loss_freq: 0.046545
[15:58:00.965] iteration 22314: loss: 0.043994, loss_s1: 0.036188, loss_fp: 0.001810, loss_freq: 0.009765
[15:58:01.581] iteration 22315: loss: 0.046793, loss_s1: 0.026814, loss_fp: 0.002553, loss_freq: 0.033244
[15:58:02.201] iteration 22316: loss: 0.046685, loss_s1: 0.034407, loss_fp: 0.002713, loss_freq: 0.011755
[15:58:02.818] iteration 22317: loss: 0.054724, loss_s1: 0.038394, loss_fp: 0.007727, loss_freq: 0.019336
[15:58:03.466] iteration 22318: loss: 0.045910, loss_s1: 0.027742, loss_fp: 0.000374, loss_freq: 0.008581
[15:58:04.111] iteration 22319: loss: 0.055597, loss_s1: 0.042028, loss_fp: 0.003652, loss_freq: 0.023858
[15:58:04.742] iteration 22320: loss: 0.056175, loss_s1: 0.036262, loss_fp: 0.001863, loss_freq: 0.015985
[15:58:05.380] iteration 22321: loss: 0.053921, loss_s1: 0.057971, loss_fp: 0.001248, loss_freq: 0.008545
[15:58:06.016] iteration 22322: loss: 0.036894, loss_s1: 0.019525, loss_fp: 0.002230, loss_freq: 0.023701
[15:58:06.638] iteration 22323: loss: 0.060070, loss_s1: 0.035695, loss_fp: 0.003261, loss_freq: 0.037151
[15:58:07.268] iteration 22324: loss: 0.053967, loss_s1: 0.048196, loss_fp: 0.004443, loss_freq: 0.025364
[15:58:07.890] iteration 22325: loss: 0.068129, loss_s1: 0.038604, loss_fp: 0.001430, loss_freq: 0.028169
[15:58:08.544] iteration 22326: loss: 0.054497, loss_s1: 0.021010, loss_fp: 0.010204, loss_freq: 0.018355
[15:58:09.168] iteration 22327: loss: 0.033938, loss_s1: 0.028839, loss_fp: 0.001690, loss_freq: 0.009119
[15:58:09.787] iteration 22328: loss: 0.028614, loss_s1: 0.011810, loss_fp: 0.002293, loss_freq: 0.011013
[15:58:10.401] iteration 22329: loss: 0.072351, loss_s1: 0.052699, loss_fp: 0.008773, loss_freq: 0.033704
[15:58:11.023] iteration 22330: loss: 0.049890, loss_s1: 0.042019, loss_fp: 0.004526, loss_freq: 0.020404
[15:58:11.650] iteration 22331: loss: 0.059469, loss_s1: 0.079830, loss_fp: 0.002963, loss_freq: 0.004825
[15:58:12.275] iteration 22332: loss: 0.039928, loss_s1: 0.013319, loss_fp: 0.003110, loss_freq: 0.004846
[15:58:12.946] iteration 22333: loss: 0.041582, loss_s1: 0.024441, loss_fp: 0.002146, loss_freq: 0.017644
[15:58:13.572] iteration 22334: loss: 0.084732, loss_s1: 0.055284, loss_fp: 0.006286, loss_freq: 0.061230
[15:58:14.220] iteration 22335: loss: 0.063471, loss_s1: 0.024649, loss_fp: 0.002115, loss_freq: 0.053966
[15:58:14.832] iteration 22336: loss: 0.048167, loss_s1: 0.031393, loss_fp: 0.005467, loss_freq: 0.019581
[15:58:15.455] iteration 22337: loss: 0.060266, loss_s1: 0.050000, loss_fp: 0.008443, loss_freq: 0.018731
[15:58:16.073] iteration 22338: loss: 0.047626, loss_s1: 0.026622, loss_fp: 0.001199, loss_freq: 0.007487
[15:58:16.738] iteration 22339: loss: 0.056664, loss_s1: 0.060855, loss_fp: 0.000890, loss_freq: 0.011436
[15:58:17.363] iteration 22340: loss: 0.057319, loss_s1: 0.037417, loss_fp: 0.003180, loss_freq: 0.018122
[15:58:17.987] iteration 22341: loss: 0.116311, loss_s1: 0.110284, loss_fp: 0.001481, loss_freq: 0.088044
[15:58:18.600] iteration 22342: loss: 0.098712, loss_s1: 0.090124, loss_fp: 0.003486, loss_freq: 0.055133
[15:58:19.212] iteration 22343: loss: 0.077982, loss_s1: 0.037747, loss_fp: 0.006214, loss_freq: 0.025050
[15:58:19.831] iteration 22344: loss: 0.049757, loss_s1: 0.044085, loss_fp: 0.001272, loss_freq: 0.011462
[15:58:20.443] iteration 22345: loss: 0.073839, loss_s1: 0.060722, loss_fp: 0.000641, loss_freq: 0.045608
[15:58:21.061] iteration 22346: loss: 0.051885, loss_s1: 0.010724, loss_fp: 0.008958, loss_freq: 0.044649
[15:58:21.681] iteration 22347: loss: 0.070451, loss_s1: 0.038108, loss_fp: 0.002139, loss_freq: 0.038919
[15:58:22.300] iteration 22348: loss: 0.033021, loss_s1: 0.023624, loss_fp: 0.001159, loss_freq: 0.009045
[15:58:22.920] iteration 22349: loss: 0.078328, loss_s1: 0.072408, loss_fp: 0.003082, loss_freq: 0.028760
[15:58:23.542] iteration 22350: loss: 0.039490, loss_s1: 0.032952, loss_fp: 0.000805, loss_freq: 0.014291
[15:58:24.185] iteration 22351: loss: 0.054630, loss_s1: 0.024596, loss_fp: 0.003517, loss_freq: 0.028363
[15:58:24.831] iteration 22352: loss: 0.068716, loss_s1: 0.057268, loss_fp: 0.002586, loss_freq: 0.027557
[15:58:25.474] iteration 22353: loss: 0.070664, loss_s1: 0.048562, loss_fp: 0.006357, loss_freq: 0.020276
[15:58:26.109] iteration 22354: loss: 0.055497, loss_s1: 0.046725, loss_fp: 0.001893, loss_freq: 0.025873
[15:58:26.743] iteration 22355: loss: 0.057436, loss_s1: 0.026586, loss_fp: 0.001835, loss_freq: 0.038895
[15:58:27.358] iteration 22356: loss: 0.049444, loss_s1: 0.035946, loss_fp: 0.003085, loss_freq: 0.020812
[15:58:27.963] iteration 22357: loss: 0.070690, loss_s1: 0.049357, loss_fp: 0.002822, loss_freq: 0.054788
[15:58:28.625] iteration 22358: loss: 0.055564, loss_s1: 0.055222, loss_fp: 0.004369, loss_freq: 0.014059
[15:58:29.247] iteration 22359: loss: 0.040594, loss_s1: 0.024115, loss_fp: 0.004412, loss_freq: 0.020630
[15:58:29.868] iteration 22360: loss: 0.060118, loss_s1: 0.041241, loss_fp: 0.001316, loss_freq: 0.025698
[15:58:30.487] iteration 22361: loss: 0.037118, loss_s1: 0.022065, loss_fp: 0.000646, loss_freq: 0.016319
[15:58:31.108] iteration 22362: loss: 0.065705, loss_s1: 0.052249, loss_fp: 0.000542, loss_freq: 0.045029
[15:58:31.732] iteration 22363: loss: 0.086858, loss_s1: 0.105940, loss_fp: 0.007109, loss_freq: 0.019807
[15:58:32.356] iteration 22364: loss: 0.053076, loss_s1: 0.015003, loss_fp: 0.001744, loss_freq: 0.025821
[15:58:32.976] iteration 22365: loss: 0.065425, loss_s1: 0.085077, loss_fp: 0.006170, loss_freq: 0.008651
[15:58:33.592] iteration 22366: loss: 0.051380, loss_s1: 0.036256, loss_fp: 0.000611, loss_freq: 0.029285
[15:58:34.209] iteration 22367: loss: 0.058106, loss_s1: 0.033635, loss_fp: 0.001837, loss_freq: 0.034745
[15:58:34.831] iteration 22368: loss: 0.066257, loss_s1: 0.047989, loss_fp: 0.003475, loss_freq: 0.032989
[15:58:35.447] iteration 22369: loss: 0.054730, loss_s1: 0.030102, loss_fp: 0.001968, loss_freq: 0.024779
[15:58:36.057] iteration 22370: loss: 0.034651, loss_s1: 0.018292, loss_fp: 0.000296, loss_freq: 0.014898
[15:58:36.684] iteration 22371: loss: 0.108497, loss_s1: 0.087932, loss_fp: 0.012911, loss_freq: 0.059570
[15:58:37.311] iteration 22372: loss: 0.036896, loss_s1: 0.016833, loss_fp: 0.001310, loss_freq: 0.020693
[15:58:37.932] iteration 22373: loss: 0.052701, loss_s1: 0.044022, loss_fp: 0.002506, loss_freq: 0.016898
[15:58:38.596] iteration 22374: loss: 0.033578, loss_s1: 0.012615, loss_fp: 0.001109, loss_freq: 0.018411
[15:58:39.241] iteration 22375: loss: 0.091207, loss_s1: 0.059443, loss_fp: 0.002136, loss_freq: 0.031877
[15:58:39.887] iteration 22376: loss: 0.052347, loss_s1: 0.058631, loss_fp: 0.002116, loss_freq: 0.013392
[15:58:40.513] iteration 22377: loss: 0.058949, loss_s1: 0.057308, loss_fp: 0.001045, loss_freq: 0.020724
[15:58:41.192] iteration 22378: loss: 0.043718, loss_s1: 0.017403, loss_fp: 0.001360, loss_freq: 0.016884
[15:58:41.854] iteration 22379: loss: 0.036457, loss_s1: 0.015564, loss_fp: 0.004159, loss_freq: 0.018363
[15:58:42.516] iteration 22380: loss: 0.066224, loss_s1: 0.044690, loss_fp: 0.002077, loss_freq: 0.025097
[15:58:43.151] iteration 22381: loss: 0.069844, loss_s1: 0.054053, loss_fp: 0.001601, loss_freq: 0.049807
[15:58:43.792] iteration 22382: loss: 0.074195, loss_s1: 0.056688, loss_fp: 0.009631, loss_freq: 0.027518
[15:58:44.437] iteration 22383: loss: 0.077058, loss_s1: 0.050023, loss_fp: 0.002102, loss_freq: 0.070010
[15:58:45.091] iteration 22384: loss: 0.054300, loss_s1: 0.039195, loss_fp: 0.015868, loss_freq: 0.011031
[15:58:45.735] iteration 22385: loss: 0.039550, loss_s1: 0.015506, loss_fp: 0.001898, loss_freq: 0.032677
[15:58:46.436] iteration 22386: loss: 0.060610, loss_s1: 0.066419, loss_fp: 0.003323, loss_freq: 0.012375
[15:58:47.087] iteration 22387: loss: 0.087584, loss_s1: 0.071914, loss_fp: 0.006042, loss_freq: 0.051932
[15:58:47.722] iteration 22388: loss: 0.091014, loss_s1: 0.057390, loss_fp: 0.019222, loss_freq: 0.042070
[15:58:48.350] iteration 22389: loss: 0.065677, loss_s1: 0.030178, loss_fp: 0.003674, loss_freq: 0.052157
[15:58:48.977] iteration 22390: loss: 0.029676, loss_s1: 0.010109, loss_fp: 0.010171, loss_freq: 0.009548
[15:58:49.616] iteration 22391: loss: 0.043111, loss_s1: 0.036773, loss_fp: 0.002686, loss_freq: 0.009278
[15:58:50.247] iteration 22392: loss: 0.037062, loss_s1: 0.031486, loss_fp: 0.003519, loss_freq: 0.010120
[15:58:50.870] iteration 22393: loss: 0.071529, loss_s1: 0.068906, loss_fp: 0.003169, loss_freq: 0.028159
[15:58:51.487] iteration 22394: loss: 0.059571, loss_s1: 0.031482, loss_fp: 0.002167, loss_freq: 0.041821
[15:58:52.119] iteration 22395: loss: 0.048306, loss_s1: 0.026759, loss_fp: 0.000626, loss_freq: 0.023477
[15:58:52.742] iteration 22396: loss: 0.046694, loss_s1: 0.016841, loss_fp: 0.001151, loss_freq: 0.038536
[15:58:53.366] iteration 22397: loss: 0.044231, loss_s1: 0.025684, loss_fp: 0.001780, loss_freq: 0.005862
[15:58:53.986] iteration 22398: loss: 0.053433, loss_s1: 0.051222, loss_fp: 0.004202, loss_freq: 0.024158
[15:58:54.613] iteration 22399: loss: 0.061920, loss_s1: 0.048573, loss_fp: 0.004616, loss_freq: 0.023531
[15:58:55.229] iteration 22400: loss: 0.072830, loss_s1: 0.058862, loss_fp: 0.007716, loss_freq: 0.045282
[15:58:58.531] iteration 22400 : mean_dice : 0.794320
[15:58:59.175] iteration 22401: loss: 0.043102, loss_s1: 0.022628, loss_fp: 0.005080, loss_freq: 0.019920
[15:58:59.805] iteration 22402: loss: 0.053077, loss_s1: 0.026905, loss_fp: 0.001871, loss_freq: 0.011064
[15:59:00.444] iteration 22403: loss: 0.053275, loss_s1: 0.031845, loss_fp: 0.001165, loss_freq: 0.028983
[15:59:01.114] iteration 22404: loss: 0.041138, loss_s1: 0.032684, loss_fp: 0.001084, loss_freq: 0.006295
[15:59:01.779] iteration 22405: loss: 0.089317, loss_s1: 0.035791, loss_fp: 0.006942, loss_freq: 0.074790
[15:59:02.425] iteration 22406: loss: 0.041350, loss_s1: 0.019448, loss_fp: 0.001280, loss_freq: 0.024221
[15:59:03.063] iteration 22407: loss: 0.057980, loss_s1: 0.013697, loss_fp: 0.002283, loss_freq: 0.012546
[15:59:03.683] iteration 22408: loss: 0.071778, loss_s1: 0.034108, loss_fp: 0.004079, loss_freq: 0.040276
[15:59:04.449] iteration 22409: loss: 0.077487, loss_s1: 0.048874, loss_fp: 0.002748, loss_freq: 0.038486
[15:59:05.392] iteration 22410: loss: 0.065734, loss_s1: 0.036284, loss_fp: 0.013081, loss_freq: 0.035767
[15:59:06.333] iteration 22411: loss: 0.045156, loss_s1: 0.028755, loss_fp: 0.003259, loss_freq: 0.029816
[15:59:07.179] iteration 22412: loss: 0.044577, loss_s1: 0.025108, loss_fp: 0.001693, loss_freq: 0.017090
[15:59:07.797] iteration 22413: loss: 0.074772, loss_s1: 0.085038, loss_fp: 0.000692, loss_freq: 0.010680
[15:59:08.428] iteration 22414: loss: 0.029539, loss_s1: 0.005438, loss_fp: 0.000656, loss_freq: 0.018555
[15:59:09.047] iteration 22415: loss: 0.068465, loss_s1: 0.042401, loss_fp: 0.001619, loss_freq: 0.049545
[15:59:09.691] iteration 22416: loss: 0.045820, loss_s1: 0.027941, loss_fp: 0.003991, loss_freq: 0.023135
[15:59:10.359] iteration 22417: loss: 0.060040, loss_s1: 0.038511, loss_fp: 0.008541, loss_freq: 0.020945
[15:59:10.970] iteration 22418: loss: 0.067429, loss_s1: 0.038673, loss_fp: 0.007888, loss_freq: 0.047140
[15:59:11.590] iteration 22419: loss: 0.056492, loss_s1: 0.024955, loss_fp: 0.007629, loss_freq: 0.011085
[15:59:12.206] iteration 22420: loss: 0.043977, loss_s1: 0.026331, loss_fp: 0.004590, loss_freq: 0.026268
[15:59:12.821] iteration 22421: loss: 0.040515, loss_s1: 0.025614, loss_fp: 0.001924, loss_freq: 0.009100
[15:59:13.443] iteration 22422: loss: 0.079855, loss_s1: 0.083367, loss_fp: 0.015282, loss_freq: 0.025870
[15:59:14.068] iteration 22423: loss: 0.030653, loss_s1: 0.004553, loss_fp: 0.002877, loss_freq: 0.006664
[15:59:14.692] iteration 22424: loss: 0.032333, loss_s1: 0.016860, loss_fp: 0.001117, loss_freq: 0.014969
[15:59:15.315] iteration 22425: loss: 0.064415, loss_s1: 0.056078, loss_fp: 0.002629, loss_freq: 0.026665
[15:59:15.945] iteration 22426: loss: 0.068883, loss_s1: 0.075139, loss_fp: 0.003552, loss_freq: 0.025961
[15:59:16.567] iteration 22427: loss: 0.049197, loss_s1: 0.053379, loss_fp: 0.000674, loss_freq: 0.013700
[15:59:17.195] iteration 22428: loss: 0.043900, loss_s1: 0.020793, loss_fp: 0.001048, loss_freq: 0.027482
[15:59:17.819] iteration 22429: loss: 0.066913, loss_s1: 0.040444, loss_fp: 0.002447, loss_freq: 0.053023
[15:59:18.446] iteration 22430: loss: 0.053893, loss_s1: 0.042907, loss_fp: 0.005980, loss_freq: 0.010942
[15:59:19.067] iteration 22431: loss: 0.026078, loss_s1: 0.003634, loss_fp: 0.003854, loss_freq: 0.007587
[15:59:19.691] iteration 22432: loss: 0.053026, loss_s1: 0.053817, loss_fp: 0.011558, loss_freq: 0.010533
[15:59:20.319] iteration 22433: loss: 0.043584, loss_s1: 0.040718, loss_fp: 0.004520, loss_freq: 0.009149
[15:59:20.948] iteration 22434: loss: 0.045072, loss_s1: 0.026713, loss_fp: 0.001036, loss_freq: 0.011881
[15:59:21.577] iteration 22435: loss: 0.033804, loss_s1: 0.009279, loss_fp: 0.003670, loss_freq: 0.023703
[15:59:22.246] iteration 22436: loss: 0.058459, loss_s1: 0.059244, loss_fp: 0.001577, loss_freq: 0.016865
[15:59:22.869] iteration 22437: loss: 0.084381, loss_s1: 0.092973, loss_fp: 0.006309, loss_freq: 0.022786
[15:59:23.518] iteration 22438: loss: 0.037786, loss_s1: 0.018520, loss_fp: 0.005035, loss_freq: 0.015693
[15:59:24.138] iteration 22439: loss: 0.053934, loss_s1: 0.026502, loss_fp: 0.002739, loss_freq: 0.011799
[15:59:24.757] iteration 22440: loss: 0.089754, loss_s1: 0.078819, loss_fp: 0.016688, loss_freq: 0.038065
[15:59:25.396] iteration 22441: loss: 0.072403, loss_s1: 0.047483, loss_fp: 0.017931, loss_freq: 0.026765
[15:59:26.020] iteration 22442: loss: 0.074040, loss_s1: 0.026648, loss_fp: 0.001360, loss_freq: 0.062554
[15:59:26.642] iteration 22443: loss: 0.059085, loss_s1: 0.030062, loss_fp: 0.003260, loss_freq: 0.039874
[15:59:27.260] iteration 22444: loss: 0.044234, loss_s1: 0.040184, loss_fp: 0.009146, loss_freq: 0.007453
[15:59:27.871] iteration 22445: loss: 0.097255, loss_s1: 0.085512, loss_fp: 0.012398, loss_freq: 0.039683
[15:59:28.486] iteration 22446: loss: 0.036292, loss_s1: 0.016852, loss_fp: 0.002128, loss_freq: 0.017215
[15:59:29.104] iteration 22447: loss: 0.047252, loss_s1: 0.028641, loss_fp: 0.003745, loss_freq: 0.025799
[15:59:29.723] iteration 22448: loss: 0.064241, loss_s1: 0.043992, loss_fp: 0.005258, loss_freq: 0.018570
[15:59:30.345] iteration 22449: loss: 0.054171, loss_s1: 0.037287, loss_fp: 0.001459, loss_freq: 0.033251
[15:59:30.964] iteration 22450: loss: 0.061377, loss_s1: 0.041401, loss_fp: 0.005024, loss_freq: 0.020796
[15:59:31.585] iteration 22451: loss: 0.046252, loss_s1: 0.018281, loss_fp: 0.001655, loss_freq: 0.037719
[15:59:32.529] iteration 22452: loss: 0.079349, loss_s1: 0.104914, loss_fp: 0.000836, loss_freq: 0.014955
[15:59:33.200] iteration 22453: loss: 0.060529, loss_s1: 0.049108, loss_fp: 0.005369, loss_freq: 0.023499
[15:59:33.838] iteration 22454: loss: 0.038536, loss_s1: 0.029036, loss_fp: 0.000953, loss_freq: 0.015726
[15:59:34.476] iteration 22455: loss: 0.042044, loss_s1: 0.020545, loss_fp: 0.004319, loss_freq: 0.015002
[15:59:35.105] iteration 22456: loss: 0.061058, loss_s1: 0.039318, loss_fp: 0.007595, loss_freq: 0.042937
[15:59:35.784] iteration 22457: loss: 0.057747, loss_s1: 0.055215, loss_fp: 0.010214, loss_freq: 0.012075
[15:59:36.428] iteration 22458: loss: 0.043470, loss_s1: 0.019509, loss_fp: 0.003241, loss_freq: 0.036669
[15:59:37.058] iteration 22459: loss: 0.040496, loss_s1: 0.021288, loss_fp: 0.005493, loss_freq: 0.013258
[15:59:37.681] iteration 22460: loss: 0.067073, loss_s1: 0.049381, loss_fp: 0.005731, loss_freq: 0.036560
[15:59:38.302] iteration 22461: loss: 0.052489, loss_s1: 0.027079, loss_fp: 0.000984, loss_freq: 0.005487
[15:59:38.923] iteration 22462: loss: 0.075335, loss_s1: 0.046830, loss_fp: 0.002233, loss_freq: 0.057945
[15:59:39.544] iteration 22463: loss: 0.071757, loss_s1: 0.054306, loss_fp: 0.010529, loss_freq: 0.026857
[15:59:40.166] iteration 22464: loss: 0.067433, loss_s1: 0.069379, loss_fp: 0.009321, loss_freq: 0.007152
[15:59:40.787] iteration 22465: loss: 0.050891, loss_s1: 0.012439, loss_fp: 0.005502, loss_freq: 0.050380
[15:59:41.412] iteration 22466: loss: 0.035962, loss_s1: 0.019988, loss_fp: 0.002155, loss_freq: 0.014407
[15:59:42.069] iteration 22467: loss: 0.051949, loss_s1: 0.022787, loss_fp: 0.002213, loss_freq: 0.036157
[15:59:42.712] iteration 22468: loss: 0.070928, loss_s1: 0.029716, loss_fp: 0.002879, loss_freq: 0.059606
[15:59:43.357] iteration 22469: loss: 0.042253, loss_s1: 0.029107, loss_fp: 0.002107, loss_freq: 0.018018
[15:59:44.002] iteration 22470: loss: 0.062556, loss_s1: 0.053275, loss_fp: 0.007679, loss_freq: 0.035280
[15:59:44.651] iteration 22471: loss: 0.041009, loss_s1: 0.028703, loss_fp: 0.006522, loss_freq: 0.013516
[15:59:45.328] iteration 22472: loss: 0.072204, loss_s1: 0.032232, loss_fp: 0.001256, loss_freq: 0.052565
[15:59:45.953] iteration 22473: loss: 0.067916, loss_s1: 0.044861, loss_fp: 0.002341, loss_freq: 0.049153
[15:59:46.582] iteration 22474: loss: 0.058215, loss_s1: 0.034020, loss_fp: 0.004483, loss_freq: 0.027632
[15:59:47.227] iteration 22475: loss: 0.044112, loss_s1: 0.037356, loss_fp: 0.000668, loss_freq: 0.010347
[15:59:47.882] iteration 22476: loss: 0.047386, loss_s1: 0.025105, loss_fp: 0.004168, loss_freq: 0.022513
[15:59:48.526] iteration 22477: loss: 0.070745, loss_s1: 0.038345, loss_fp: 0.004293, loss_freq: 0.049440
[15:59:49.173] iteration 22478: loss: 0.104427, loss_s1: 0.105660, loss_fp: 0.004414, loss_freq: 0.032809
[15:59:49.820] iteration 22479: loss: 0.034108, loss_s1: 0.022625, loss_fp: 0.002377, loss_freq: 0.006815
[15:59:50.446] iteration 22480: loss: 0.043922, loss_s1: 0.023989, loss_fp: 0.001675, loss_freq: 0.007651
[15:59:51.076] iteration 22481: loss: 0.058720, loss_s1: 0.047403, loss_fp: 0.001217, loss_freq: 0.009886
[15:59:51.696] iteration 22482: loss: 0.038609, loss_s1: 0.018923, loss_fp: 0.001766, loss_freq: 0.019231
[15:59:52.327] iteration 22483: loss: 0.049374, loss_s1: 0.029741, loss_fp: 0.001195, loss_freq: 0.019647
[15:59:52.946] iteration 22484: loss: 0.064196, loss_s1: 0.041033, loss_fp: 0.004215, loss_freq: 0.048957
[15:59:53.565] iteration 22485: loss: 0.091540, loss_s1: 0.099020, loss_fp: 0.008359, loss_freq: 0.038712
[15:59:54.187] iteration 22486: loss: 0.086044, loss_s1: 0.076045, loss_fp: 0.006992, loss_freq: 0.028856
[15:59:54.806] iteration 22487: loss: 0.062763, loss_s1: 0.055211, loss_fp: 0.002614, loss_freq: 0.031544
[15:59:55.425] iteration 22488: loss: 0.072295, loss_s1: 0.061495, loss_fp: 0.003244, loss_freq: 0.031049
[15:59:56.044] iteration 22489: loss: 0.061392, loss_s1: 0.048545, loss_fp: 0.001834, loss_freq: 0.038068
[15:59:56.665] iteration 22490: loss: 0.074065, loss_s1: 0.055361, loss_fp: 0.011325, loss_freq: 0.038320
[15:59:57.299] iteration 22491: loss: 0.047368, loss_s1: 0.040949, loss_fp: 0.006729, loss_freq: 0.015697
[15:59:57.923] iteration 22492: loss: 0.061653, loss_s1: 0.018282, loss_fp: 0.005951, loss_freq: 0.038918
[15:59:58.596] iteration 22493: loss: 0.076412, loss_s1: 0.053117, loss_fp: 0.007425, loss_freq: 0.024849
[15:59:59.234] iteration 22494: loss: 0.056196, loss_s1: 0.013657, loss_fp: 0.001177, loss_freq: 0.014352
[15:59:59.873] iteration 22495: loss: 0.060040, loss_s1: 0.033665, loss_fp: 0.004008, loss_freq: 0.039971
[16:00:00.568] iteration 22496: loss: 0.077796, loss_s1: 0.043174, loss_fp: 0.004413, loss_freq: 0.032939
[16:00:01.207] iteration 22497: loss: 0.078719, loss_s1: 0.073708, loss_fp: 0.006818, loss_freq: 0.022516
[16:00:01.859] iteration 22498: loss: 0.057179, loss_s1: 0.041119, loss_fp: 0.003521, loss_freq: 0.024982
[16:00:02.495] iteration 22499: loss: 0.037318, loss_s1: 0.019477, loss_fp: 0.001662, loss_freq: 0.008348
[16:00:03.124] iteration 22500: loss: 0.065537, loss_s1: 0.053360, loss_fp: 0.010464, loss_freq: 0.025682
[16:00:03.748] iteration 22501: loss: 0.061124, loss_s1: 0.062460, loss_fp: 0.001573, loss_freq: 0.015908
[16:00:04.402] iteration 22502: loss: 0.061212, loss_s1: 0.048909, loss_fp: 0.002300, loss_freq: 0.024318
[16:00:05.020] iteration 22503: loss: 0.051668, loss_s1: 0.023147, loss_fp: 0.001750, loss_freq: 0.026224
[16:00:05.697] iteration 22504: loss: 0.032439, loss_s1: 0.017516, loss_fp: 0.001211, loss_freq: 0.010549
[16:00:06.339] iteration 22505: loss: 0.049835, loss_s1: 0.048769, loss_fp: 0.002967, loss_freq: 0.015868
[16:00:06.964] iteration 22506: loss: 0.036201, loss_s1: 0.021779, loss_fp: 0.003647, loss_freq: 0.008135
[16:00:07.585] iteration 22507: loss: 0.044216, loss_s1: 0.026863, loss_fp: 0.002020, loss_freq: 0.005394
[16:00:08.212] iteration 22508: loss: 0.062706, loss_s1: 0.072957, loss_fp: 0.001142, loss_freq: 0.013854
[16:00:08.839] iteration 22509: loss: 0.058757, loss_s1: 0.062452, loss_fp: 0.002358, loss_freq: 0.009328
[16:00:09.466] iteration 22510: loss: 0.115902, loss_s1: 0.087892, loss_fp: 0.008994, loss_freq: 0.095253
[16:00:10.089] iteration 22511: loss: 0.072331, loss_s1: 0.064485, loss_fp: 0.006894, loss_freq: 0.031756
[16:00:10.707] iteration 22512: loss: 0.071398, loss_s1: 0.057353, loss_fp: 0.005359, loss_freq: 0.024270
[16:00:11.329] iteration 22513: loss: 0.054384, loss_s1: 0.034639, loss_fp: 0.001088, loss_freq: 0.017215
[16:00:11.949] iteration 22514: loss: 0.045391, loss_s1: 0.033027, loss_fp: 0.003429, loss_freq: 0.021370
[16:00:12.618] iteration 22515: loss: 0.096195, loss_s1: 0.041399, loss_fp: 0.000892, loss_freq: 0.023673
[16:00:13.243] iteration 22516: loss: 0.110827, loss_s1: 0.058435, loss_fp: 0.002181, loss_freq: 0.031100
[16:00:13.858] iteration 22517: loss: 0.044097, loss_s1: 0.023265, loss_fp: 0.001561, loss_freq: 0.025159
[16:00:14.476] iteration 22518: loss: 0.115364, loss_s1: 0.063203, loss_fp: 0.012071, loss_freq: 0.094664
[16:00:15.096] iteration 22519: loss: 0.047201, loss_s1: 0.039774, loss_fp: 0.001834, loss_freq: 0.017127
[16:00:15.722] iteration 22520: loss: 0.073730, loss_s1: 0.074143, loss_fp: 0.005074, loss_freq: 0.020654
[16:00:16.352] iteration 22521: loss: 0.063510, loss_s1: 0.049584, loss_fp: 0.003623, loss_freq: 0.014321
[16:00:16.967] iteration 22522: loss: 0.044766, loss_s1: 0.027735, loss_fp: 0.002673, loss_freq: 0.024619
[16:00:17.589] iteration 22523: loss: 0.076027, loss_s1: 0.056110, loss_fp: 0.010749, loss_freq: 0.043869
[16:00:18.206] iteration 22524: loss: 0.116690, loss_s1: 0.121352, loss_fp: 0.008996, loss_freq: 0.066911
[16:00:18.828] iteration 22525: loss: 0.094293, loss_s1: 0.059741, loss_fp: 0.008115, loss_freq: 0.047255
[16:00:19.452] iteration 22526: loss: 0.062612, loss_s1: 0.039774, loss_fp: 0.007122, loss_freq: 0.039920
[16:00:20.073] iteration 22527: loss: 0.066165, loss_s1: 0.060890, loss_fp: 0.003156, loss_freq: 0.024492
[16:00:20.686] iteration 22528: loss: 0.092203, loss_s1: 0.092410, loss_fp: 0.003842, loss_freq: 0.036720
[16:00:21.309] iteration 22529: loss: 0.090666, loss_s1: 0.044856, loss_fp: 0.009107, loss_freq: 0.035654
[16:00:21.929] iteration 22530: loss: 0.120056, loss_s1: 0.118962, loss_fp: 0.009699, loss_freq: 0.059865
[16:00:22.643] iteration 22531: loss: 0.096339, loss_s1: 0.048872, loss_fp: 0.002784, loss_freq: 0.064834
[16:00:23.287] iteration 22532: loss: 0.065440, loss_s1: 0.046971, loss_fp: 0.002618, loss_freq: 0.013544
[16:00:23.986] iteration 22533: loss: 0.046759, loss_s1: 0.011004, loss_fp: 0.004649, loss_freq: 0.024752
[16:00:24.625] iteration 22534: loss: 0.035913, loss_s1: 0.016728, loss_fp: 0.001684, loss_freq: 0.017687
[16:00:25.249] iteration 22535: loss: 0.051876, loss_s1: 0.050040, loss_fp: 0.003568, loss_freq: 0.016469
[16:00:25.868] iteration 22536: loss: 0.050907, loss_s1: 0.039781, loss_fp: 0.003603, loss_freq: 0.018471
[16:00:26.489] iteration 22537: loss: 0.071226, loss_s1: 0.032553, loss_fp: 0.004367, loss_freq: 0.057150
[16:00:27.119] iteration 22538: loss: 0.030963, loss_s1: 0.007170, loss_fp: 0.002572, loss_freq: 0.007743
[16:00:27.742] iteration 22539: loss: 0.042087, loss_s1: 0.013422, loss_fp: 0.001159, loss_freq: 0.015308
[16:00:28.357] iteration 22540: loss: 0.042023, loss_s1: 0.023991, loss_fp: 0.000507, loss_freq: 0.019224
[16:00:28.979] iteration 22541: loss: 0.045952, loss_s1: 0.038352, loss_fp: 0.013635, loss_freq: 0.009367
[16:00:29.593] iteration 22542: loss: 0.050037, loss_s1: 0.024452, loss_fp: 0.001567, loss_freq: 0.028009
[16:00:30.217] iteration 22543: loss: 0.074709, loss_s1: 0.072641, loss_fp: 0.001843, loss_freq: 0.039500
[16:00:30.839] iteration 22544: loss: 0.039088, loss_s1: 0.031471, loss_fp: 0.004498, loss_freq: 0.006720
[16:00:31.487] iteration 22545: loss: 0.049543, loss_s1: 0.025201, loss_fp: 0.005872, loss_freq: 0.010114
[16:00:32.105] iteration 22546: loss: 0.051253, loss_s1: 0.040818, loss_fp: 0.001892, loss_freq: 0.008829
[16:00:32.718] iteration 22547: loss: 0.038051, loss_s1: 0.016752, loss_fp: 0.003658, loss_freq: 0.008672
[16:00:33.336] iteration 22548: loss: 0.052683, loss_s1: 0.027500, loss_fp: 0.004966, loss_freq: 0.028909
[16:00:33.957] iteration 22549: loss: 0.030916, loss_s1: 0.013981, loss_fp: 0.001703, loss_freq: 0.009093
[16:00:34.580] iteration 22550: loss: 0.070547, loss_s1: 0.024243, loss_fp: 0.011434, loss_freq: 0.052103
[16:00:35.191] iteration 22551: loss: 0.061751, loss_s1: 0.051555, loss_fp: 0.004416, loss_freq: 0.029293
[16:00:35.805] iteration 22552: loss: 0.068475, loss_s1: 0.089786, loss_fp: 0.000972, loss_freq: 0.006781
[16:00:36.446] iteration 22553: loss: 0.058720, loss_s1: 0.027076, loss_fp: 0.005646, loss_freq: 0.041452
[16:00:37.057] iteration 22554: loss: 0.103644, loss_s1: 0.055704, loss_fp: 0.011207, loss_freq: 0.065936
[16:00:37.675] iteration 22555: loss: 0.044586, loss_s1: 0.036166, loss_fp: 0.001106, loss_freq: 0.008612
[16:00:38.290] iteration 22556: loss: 0.069968, loss_s1: 0.058871, loss_fp: 0.002255, loss_freq: 0.014577
[16:00:38.909] iteration 22557: loss: 0.047579, loss_s1: 0.023619, loss_fp: 0.001422, loss_freq: 0.034024
[16:00:39.530] iteration 22558: loss: 0.079449, loss_s1: 0.034986, loss_fp: 0.008282, loss_freq: 0.072000
[16:00:40.151] iteration 22559: loss: 0.049696, loss_s1: 0.031075, loss_fp: 0.010443, loss_freq: 0.022463
[16:00:40.771] iteration 22560: loss: 0.064484, loss_s1: 0.042407, loss_fp: 0.000945, loss_freq: 0.032178
[16:00:41.393] iteration 22561: loss: 0.094491, loss_s1: 0.073955, loss_fp: 0.019799, loss_freq: 0.061884
[16:00:42.016] iteration 22562: loss: 0.061847, loss_s1: 0.023382, loss_fp: 0.005704, loss_freq: 0.030213
[16:00:42.634] iteration 22563: loss: 0.047634, loss_s1: 0.041006, loss_fp: 0.004089, loss_freq: 0.021668
[16:00:43.301] iteration 22564: loss: 0.054339, loss_s1: 0.035902, loss_fp: 0.001696, loss_freq: 0.017048
[16:00:43.931] iteration 22565: loss: 0.047539, loss_s1: 0.025371, loss_fp: 0.005123, loss_freq: 0.027005
[16:00:44.558] iteration 22566: loss: 0.063888, loss_s1: 0.026002, loss_fp: 0.001286, loss_freq: 0.013868
[16:00:45.192] iteration 22567: loss: 0.030967, loss_s1: 0.010200, loss_fp: 0.001528, loss_freq: 0.008693
[16:00:45.810] iteration 22568: loss: 0.053883, loss_s1: 0.043686, loss_fp: 0.003909, loss_freq: 0.027284
[16:00:46.437] iteration 22569: loss: 0.089525, loss_s1: 0.064335, loss_fp: 0.003241, loss_freq: 0.065878
[16:00:47.050] iteration 22570: loss: 0.051432, loss_s1: 0.029941, loss_fp: 0.001502, loss_freq: 0.023661
[16:00:47.670] iteration 22571: loss: 0.039622, loss_s1: 0.026058, loss_fp: 0.000469, loss_freq: 0.006886
[16:00:48.288] iteration 22572: loss: 0.056019, loss_s1: 0.041939, loss_fp: 0.005469, loss_freq: 0.026274
[16:00:48.908] iteration 22573: loss: 0.050143, loss_s1: 0.041546, loss_fp: 0.001239, loss_freq: 0.017958
[16:00:49.528] iteration 22574: loss: 0.027392, loss_s1: 0.006551, loss_fp: 0.000804, loss_freq: 0.009813
[16:00:50.155] iteration 22575: loss: 0.050641, loss_s1: 0.042532, loss_fp: 0.002944, loss_freq: 0.022435
[16:00:50.773] iteration 22576: loss: 0.047021, loss_s1: 0.026443, loss_fp: 0.003984, loss_freq: 0.032511
[16:00:51.393] iteration 22577: loss: 0.064970, loss_s1: 0.064277, loss_fp: 0.003328, loss_freq: 0.012634
[16:00:52.007] iteration 22578: loss: 0.028482, loss_s1: 0.007230, loss_fp: 0.003675, loss_freq: 0.014700
[16:00:52.624] iteration 22579: loss: 0.041908, loss_s1: 0.021461, loss_fp: 0.008360, loss_freq: 0.013458
[16:00:53.244] iteration 22580: loss: 0.041449, loss_s1: 0.033622, loss_fp: 0.001373, loss_freq: 0.014128
[16:00:53.915] iteration 22581: loss: 0.029629, loss_s1: 0.012016, loss_fp: 0.004771, loss_freq: 0.007814
[16:00:54.536] iteration 22582: loss: 0.047725, loss_s1: 0.039284, loss_fp: 0.002326, loss_freq: 0.016988
[16:00:55.163] iteration 22583: loss: 0.080079, loss_s1: 0.051866, loss_fp: 0.004334, loss_freq: 0.047168
[16:00:55.783] iteration 22584: loss: 0.095348, loss_s1: 0.115127, loss_fp: 0.013974, loss_freq: 0.015487
[16:00:56.400] iteration 22585: loss: 0.072560, loss_s1: 0.037057, loss_fp: 0.013368, loss_freq: 0.048347
[16:00:57.021] iteration 22586: loss: 0.048462, loss_s1: 0.016772, loss_fp: 0.001685, loss_freq: 0.016881
[16:00:57.700] iteration 22587: loss: 0.060751, loss_s1: 0.044092, loss_fp: 0.006849, loss_freq: 0.020444
[16:00:58.343] iteration 22588: loss: 0.089047, loss_s1: 0.043054, loss_fp: 0.006059, loss_freq: 0.023610
[16:00:58.994] iteration 22589: loss: 0.024698, loss_s1: 0.006521, loss_fp: 0.000477, loss_freq: 0.006678
[16:00:59.608] iteration 22590: loss: 0.041054, loss_s1: 0.022175, loss_fp: 0.001050, loss_freq: 0.021475
[16:01:00.227] iteration 22591: loss: 0.064714, loss_s1: 0.049519, loss_fp: 0.002729, loss_freq: 0.032766
[16:01:00.846] iteration 22592: loss: 0.061303, loss_s1: 0.025341, loss_fp: 0.011206, loss_freq: 0.045020
[16:01:01.466] iteration 22593: loss: 0.097856, loss_s1: 0.109900, loss_fp: 0.010948, loss_freq: 0.040480
[16:01:02.087] iteration 22594: loss: 0.061260, loss_s1: 0.060373, loss_fp: 0.003735, loss_freq: 0.028593
[16:01:03.038] iteration 22595: loss: 0.067697, loss_s1: 0.067959, loss_fp: 0.001703, loss_freq: 0.012193
[16:01:03.667] iteration 22596: loss: 0.059994, loss_s1: 0.053383, loss_fp: 0.004572, loss_freq: 0.023553
[16:01:04.290] iteration 22597: loss: 0.050838, loss_s1: 0.034235, loss_fp: 0.002166, loss_freq: 0.018770
[16:01:04.909] iteration 22598: loss: 0.064686, loss_s1: 0.054669, loss_fp: 0.000475, loss_freq: 0.025256
[16:01:05.541] iteration 22599: loss: 0.062496, loss_s1: 0.057240, loss_fp: 0.008128, loss_freq: 0.024232
[16:01:06.216] iteration 22600: loss: 0.034102, loss_s1: 0.016404, loss_fp: 0.001432, loss_freq: 0.005953
[16:01:09.549] iteration 22600 : mean_dice : 0.786062
[16:01:10.494] iteration 22601: loss: 0.043212, loss_s1: 0.024342, loss_fp: 0.003966, loss_freq: 0.026249
[16:01:11.430] iteration 22602: loss: 0.076009, loss_s1: 0.045417, loss_fp: 0.001546, loss_freq: 0.050884
[16:01:12.178] iteration 22603: loss: 0.095447, loss_s1: 0.079525, loss_fp: 0.007134, loss_freq: 0.063782
[16:01:12.795] iteration 22604: loss: 0.046388, loss_s1: 0.020513, loss_fp: 0.002404, loss_freq: 0.010857
[16:01:13.421] iteration 22605: loss: 0.075205, loss_s1: 0.045911, loss_fp: 0.003957, loss_freq: 0.057315
[16:01:14.042] iteration 22606: loss: 0.039839, loss_s1: 0.024680, loss_fp: 0.003301, loss_freq: 0.018035
[16:01:14.702] iteration 22607: loss: 0.053367, loss_s1: 0.032476, loss_fp: 0.005238, loss_freq: 0.025198
[16:01:15.324] iteration 22608: loss: 0.038134, loss_s1: 0.025302, loss_fp: 0.006331, loss_freq: 0.008430
[16:01:15.948] iteration 22609: loss: 0.076514, loss_s1: 0.040190, loss_fp: 0.030902, loss_freq: 0.044048
[16:01:16.571] iteration 22610: loss: 0.045156, loss_s1: 0.021867, loss_fp: 0.002699, loss_freq: 0.030770
[16:01:17.185] iteration 22611: loss: 0.060041, loss_s1: 0.047603, loss_fp: 0.000661, loss_freq: 0.026514
[16:01:17.807] iteration 22612: loss: 0.075199, loss_s1: 0.077654, loss_fp: 0.004434, loss_freq: 0.036298
[16:01:18.436] iteration 22613: loss: 0.039318, loss_s1: 0.028901, loss_fp: 0.004310, loss_freq: 0.012280
[16:01:19.064] iteration 22614: loss: 0.034922, loss_s1: 0.024415, loss_fp: 0.001059, loss_freq: 0.013355
[16:01:19.690] iteration 22615: loss: 0.073956, loss_s1: 0.019753, loss_fp: 0.003043, loss_freq: 0.069329
[16:01:20.304] iteration 22616: loss: 0.042448, loss_s1: 0.023846, loss_fp: 0.006410, loss_freq: 0.016533
[16:01:20.922] iteration 22617: loss: 0.052832, loss_s1: 0.040539, loss_fp: 0.006160, loss_freq: 0.010315
[16:01:21.540] iteration 22618: loss: 0.032775, loss_s1: 0.013863, loss_fp: 0.001899, loss_freq: 0.012203
[16:01:22.160] iteration 22619: loss: 0.041203, loss_s1: 0.027343, loss_fp: 0.001051, loss_freq: 0.017152
[16:01:22.792] iteration 22620: loss: 0.064651, loss_s1: 0.033444, loss_fp: 0.011217, loss_freq: 0.036900
[16:01:23.437] iteration 22621: loss: 0.057790, loss_s1: 0.035335, loss_fp: 0.007335, loss_freq: 0.028698
[16:01:24.064] iteration 22622: loss: 0.046528, loss_s1: 0.033668, loss_fp: 0.001974, loss_freq: 0.013406
[16:01:24.695] iteration 22623: loss: 0.068595, loss_s1: 0.039384, loss_fp: 0.000700, loss_freq: 0.023286
[16:01:25.337] iteration 22624: loss: 0.076381, loss_s1: 0.040900, loss_fp: 0.002387, loss_freq: 0.007841
[16:01:25.963] iteration 22625: loss: 0.040204, loss_s1: 0.020833, loss_fp: 0.001893, loss_freq: 0.015954
[16:01:26.597] iteration 22626: loss: 0.054496, loss_s1: 0.040096, loss_fp: 0.001729, loss_freq: 0.026430
[16:01:27.209] iteration 22627: loss: 0.095479, loss_s1: 0.077005, loss_fp: 0.013623, loss_freq: 0.063825
[16:01:27.838] iteration 22628: loss: 0.081029, loss_s1: 0.058110, loss_fp: 0.004067, loss_freq: 0.063174
[16:01:28.464] iteration 22629: loss: 0.075609, loss_s1: 0.040617, loss_fp: 0.008427, loss_freq: 0.042413
[16:01:29.089] iteration 22630: loss: 0.088700, loss_s1: 0.065217, loss_fp: 0.006423, loss_freq: 0.053980
[16:01:29.707] iteration 22631: loss: 0.054405, loss_s1: 0.032764, loss_fp: 0.001000, loss_freq: 0.026891
[16:01:30.332] iteration 22632: loss: 0.061677, loss_s1: 0.051956, loss_fp: 0.006153, loss_freq: 0.036676
[16:01:30.955] iteration 22633: loss: 0.071147, loss_s1: 0.034205, loss_fp: 0.003685, loss_freq: 0.043984
[16:01:31.576] iteration 22634: loss: 0.031941, loss_s1: 0.014613, loss_fp: 0.001219, loss_freq: 0.020570
[16:01:32.197] iteration 22635: loss: 0.076727, loss_s1: 0.074722, loss_fp: 0.008164, loss_freq: 0.010398
[16:01:32.809] iteration 22636: loss: 0.046992, loss_s1: 0.051413, loss_fp: 0.003967, loss_freq: 0.011046
[16:01:33.419] iteration 22637: loss: 0.037752, loss_s1: 0.014241, loss_fp: 0.007010, loss_freq: 0.011189
[16:01:34.044] iteration 22638: loss: 0.047719, loss_s1: 0.038901, loss_fp: 0.004547, loss_freq: 0.018696
[16:01:34.667] iteration 22639: loss: 0.065670, loss_s1: 0.049838, loss_fp: 0.001322, loss_freq: 0.014387
[16:01:35.317] iteration 22640: loss: 0.072697, loss_s1: 0.073089, loss_fp: 0.006470, loss_freq: 0.027958
[16:01:35.949] iteration 22641: loss: 0.047288, loss_s1: 0.017133, loss_fp: 0.004410, loss_freq: 0.037613
[16:01:36.583] iteration 22642: loss: 0.070482, loss_s1: 0.060881, loss_fp: 0.006801, loss_freq: 0.025249
[16:01:37.211] iteration 22643: loss: 0.066765, loss_s1: 0.054556, loss_fp: 0.004215, loss_freq: 0.042647
[16:01:37.826] iteration 22644: loss: 0.038771, loss_s1: 0.033601, loss_fp: 0.002550, loss_freq: 0.008216
[16:01:38.448] iteration 22645: loss: 0.037351, loss_s1: 0.006836, loss_fp: 0.003639, loss_freq: 0.019267
[16:01:39.069] iteration 22646: loss: 0.057933, loss_s1: 0.013069, loss_fp: 0.006624, loss_freq: 0.037347
[16:01:39.747] iteration 22647: loss: 0.041200, loss_s1: 0.022963, loss_fp: 0.001076, loss_freq: 0.025341
[16:01:40.364] iteration 22648: loss: 0.047326, loss_s1: 0.028425, loss_fp: 0.005564, loss_freq: 0.031435
[16:01:40.980] iteration 22649: loss: 0.047646, loss_s1: 0.012570, loss_fp: 0.001933, loss_freq: 0.010254
[16:01:41.646] iteration 22650: loss: 0.041396, loss_s1: 0.009519, loss_fp: 0.005105, loss_freq: 0.006552
[16:01:42.258] iteration 22651: loss: 0.044863, loss_s1: 0.034094, loss_fp: 0.002645, loss_freq: 0.023655
[16:01:42.877] iteration 22652: loss: 0.037648, loss_s1: 0.015964, loss_fp: 0.001031, loss_freq: 0.015929
[16:01:43.504] iteration 22653: loss: 0.073424, loss_s1: 0.022487, loss_fp: 0.000706, loss_freq: 0.084928
[16:01:44.116] iteration 22654: loss: 0.036306, loss_s1: 0.016775, loss_fp: 0.001625, loss_freq: 0.015378
[16:01:44.735] iteration 22655: loss: 0.047986, loss_s1: 0.016905, loss_fp: 0.004373, loss_freq: 0.023523
[16:01:45.352] iteration 22656: loss: 0.048540, loss_s1: 0.030230, loss_fp: 0.002290, loss_freq: 0.015067
[16:01:45.973] iteration 22657: loss: 0.057958, loss_s1: 0.051018, loss_fp: 0.002548, loss_freq: 0.026102
[16:01:46.599] iteration 22658: loss: 0.050350, loss_s1: 0.018719, loss_fp: 0.001206, loss_freq: 0.022295
[16:01:47.222] iteration 22659: loss: 0.112309, loss_s1: 0.111669, loss_fp: 0.009699, loss_freq: 0.052217
[16:01:47.897] iteration 22660: loss: 0.074023, loss_s1: 0.055353, loss_fp: 0.003952, loss_freq: 0.014203
[16:01:48.523] iteration 22661: loss: 0.063571, loss_s1: 0.025152, loss_fp: 0.013120, loss_freq: 0.028584
[16:01:49.139] iteration 22662: loss: 0.034675, loss_s1: 0.021847, loss_fp: 0.001306, loss_freq: 0.018392
[16:01:49.765] iteration 22663: loss: 0.050821, loss_s1: 0.051066, loss_fp: 0.002471, loss_freq: 0.010164
[16:01:50.384] iteration 22664: loss: 0.038702, loss_s1: 0.016246, loss_fp: 0.003888, loss_freq: 0.006684
[16:01:51.057] iteration 22665: loss: 0.030961, loss_s1: 0.017862, loss_fp: 0.003187, loss_freq: 0.006127
[16:01:51.677] iteration 22666: loss: 0.077710, loss_s1: 0.037707, loss_fp: 0.006307, loss_freq: 0.052226
[16:01:52.305] iteration 22667: loss: 0.065179, loss_s1: 0.044437, loss_fp: 0.008002, loss_freq: 0.034443
[16:01:52.932] iteration 22668: loss: 0.055853, loss_s1: 0.048521, loss_fp: 0.006867, loss_freq: 0.008069
[16:01:53.559] iteration 22669: loss: 0.052898, loss_s1: 0.045354, loss_fp: 0.003719, loss_freq: 0.027960
[16:01:54.187] iteration 22670: loss: 0.068300, loss_s1: 0.024452, loss_fp: 0.001692, loss_freq: 0.008717
[16:01:54.813] iteration 22671: loss: 0.042693, loss_s1: 0.036811, loss_fp: 0.001775, loss_freq: 0.013642
[16:01:55.439] iteration 22672: loss: 0.052698, loss_s1: 0.042000, loss_fp: 0.001277, loss_freq: 0.006369
[16:01:56.060] iteration 22673: loss: 0.086391, loss_s1: 0.058806, loss_fp: 0.005133, loss_freq: 0.065035
[16:01:56.680] iteration 22674: loss: 0.101870, loss_s1: 0.085452, loss_fp: 0.006911, loss_freq: 0.048748
[16:01:57.316] iteration 22675: loss: 0.035230, loss_s1: 0.012523, loss_fp: 0.001367, loss_freq: 0.010147
[16:01:57.953] iteration 22676: loss: 0.047165, loss_s1: 0.037327, loss_fp: 0.001935, loss_freq: 0.014779
[16:01:58.581] iteration 22677: loss: 0.047983, loss_s1: 0.030750, loss_fp: 0.001937, loss_freq: 0.022119
[16:01:59.196] iteration 22678: loss: 0.037203, loss_s1: 0.027544, loss_fp: 0.003442, loss_freq: 0.009014
[16:01:59.816] iteration 22679: loss: 0.065350, loss_s1: 0.042636, loss_fp: 0.010714, loss_freq: 0.041804
[16:02:00.427] iteration 22680: loss: 0.075710, loss_s1: 0.043782, loss_fp: 0.004385, loss_freq: 0.053070
[16:02:01.044] iteration 22681: loss: 0.038129, loss_s1: 0.022064, loss_fp: 0.005220, loss_freq: 0.010104
[16:02:01.681] iteration 22682: loss: 0.037144, loss_s1: 0.004937, loss_fp: 0.001044, loss_freq: 0.008258
[16:02:02.353] iteration 22683: loss: 0.043413, loss_s1: 0.023196, loss_fp: 0.002832, loss_freq: 0.006773
[16:02:02.968] iteration 22684: loss: 0.078775, loss_s1: 0.101269, loss_fp: 0.005901, loss_freq: 0.013950
[16:02:03.591] iteration 22685: loss: 0.056214, loss_s1: 0.028886, loss_fp: 0.003605, loss_freq: 0.023380
[16:02:04.205] iteration 22686: loss: 0.064321, loss_s1: 0.061773, loss_fp: 0.006683, loss_freq: 0.013326
[16:02:04.816] iteration 22687: loss: 0.056971, loss_s1: 0.048593, loss_fp: 0.002391, loss_freq: 0.015727
[16:02:05.433] iteration 22688: loss: 0.034752, loss_s1: 0.023556, loss_fp: 0.004192, loss_freq: 0.009210
[16:02:06.057] iteration 22689: loss: 0.033550, loss_s1: 0.010816, loss_fp: 0.000987, loss_freq: 0.020699
[16:02:06.692] iteration 22690: loss: 0.038110, loss_s1: 0.023590, loss_fp: 0.000367, loss_freq: 0.009791
[16:02:07.307] iteration 22691: loss: 0.088324, loss_s1: 0.087291, loss_fp: 0.010473, loss_freq: 0.026656
[16:02:07.930] iteration 22692: loss: 0.040400, loss_s1: 0.009100, loss_fp: 0.003515, loss_freq: 0.030649
[16:02:08.552] iteration 22693: loss: 0.057128, loss_s1: 0.028270, loss_fp: 0.001872, loss_freq: 0.019476
[16:02:09.176] iteration 22694: loss: 0.059134, loss_s1: 0.030100, loss_fp: 0.003040, loss_freq: 0.035791
[16:02:09.787] iteration 22695: loss: 0.089925, loss_s1: 0.103324, loss_fp: 0.004573, loss_freq: 0.028959
[16:02:10.400] iteration 22696: loss: 0.066840, loss_s1: 0.022317, loss_fp: 0.002103, loss_freq: 0.021924
[16:02:11.013] iteration 22697: loss: 0.081274, loss_s1: 0.040202, loss_fp: 0.003325, loss_freq: 0.026082
[16:02:11.631] iteration 22698: loss: 0.054080, loss_s1: 0.045269, loss_fp: 0.004058, loss_freq: 0.019512
[16:02:12.246] iteration 22699: loss: 0.042384, loss_s1: 0.015488, loss_fp: 0.000839, loss_freq: 0.006803
[16:02:12.875] iteration 22700: loss: 0.079374, loss_s1: 0.021846, loss_fp: 0.001210, loss_freq: 0.066948
[16:02:13.505] iteration 22701: loss: 0.147870, loss_s1: 0.102881, loss_fp: 0.004538, loss_freq: 0.131257
[16:02:14.134] iteration 22702: loss: 0.044661, loss_s1: 0.015023, loss_fp: 0.009094, loss_freq: 0.030047
[16:02:14.760] iteration 22703: loss: 0.070419, loss_s1: 0.040871, loss_fp: 0.002858, loss_freq: 0.025515
[16:02:15.382] iteration 22704: loss: 0.115167, loss_s1: 0.130683, loss_fp: 0.006969, loss_freq: 0.057350
[16:02:16.004] iteration 22705: loss: 0.060741, loss_s1: 0.048563, loss_fp: 0.000744, loss_freq: 0.025748
[16:02:16.631] iteration 22706: loss: 0.032967, loss_s1: 0.016453, loss_fp: 0.001199, loss_freq: 0.021289
[16:02:17.258] iteration 22707: loss: 0.062836, loss_s1: 0.053443, loss_fp: 0.001312, loss_freq: 0.013233
[16:02:17.884] iteration 22708: loss: 0.071657, loss_s1: 0.051665, loss_fp: 0.011550, loss_freq: 0.042520
[16:02:18.508] iteration 22709: loss: 0.070249, loss_s1: 0.026424, loss_fp: 0.001764, loss_freq: 0.031608
[16:02:19.125] iteration 22710: loss: 0.063484, loss_s1: 0.078863, loss_fp: 0.002248, loss_freq: 0.015653
[16:02:19.757] iteration 22711: loss: 0.064672, loss_s1: 0.059533, loss_fp: 0.001796, loss_freq: 0.012828
[16:02:20.381] iteration 22712: loss: 0.058628, loss_s1: 0.061165, loss_fp: 0.003242, loss_freq: 0.012137
[16:02:21.011] iteration 22713: loss: 0.066894, loss_s1: 0.042265, loss_fp: 0.002411, loss_freq: 0.045163
[16:02:21.638] iteration 22714: loss: 0.050187, loss_s1: 0.031515, loss_fp: 0.002603, loss_freq: 0.027968
[16:02:22.270] iteration 22715: loss: 0.056919, loss_s1: 0.018942, loss_fp: 0.003696, loss_freq: 0.049656
[16:02:22.897] iteration 22716: loss: 0.069246, loss_s1: 0.056309, loss_fp: 0.007276, loss_freq: 0.028037
[16:02:23.519] iteration 22717: loss: 0.053851, loss_s1: 0.041010, loss_fp: 0.002225, loss_freq: 0.004936
[16:02:24.135] iteration 22718: loss: 0.039468, loss_s1: 0.019763, loss_fp: 0.002935, loss_freq: 0.027048
[16:02:24.795] iteration 22719: loss: 0.075458, loss_s1: 0.086105, loss_fp: 0.005002, loss_freq: 0.026730
[16:02:25.418] iteration 22720: loss: 0.054373, loss_s1: 0.038439, loss_fp: 0.003470, loss_freq: 0.026882
[16:02:26.041] iteration 22721: loss: 0.051842, loss_s1: 0.034559, loss_fp: 0.010534, loss_freq: 0.028073
[16:02:26.664] iteration 22722: loss: 0.055324, loss_s1: 0.060216, loss_fp: 0.000761, loss_freq: 0.013302
[16:02:27.290] iteration 22723: loss: 0.052835, loss_s1: 0.058151, loss_fp: 0.001828, loss_freq: 0.010375
[16:02:27.909] iteration 22724: loss: 0.049276, loss_s1: 0.035840, loss_fp: 0.002122, loss_freq: 0.016007
[16:02:28.524] iteration 22725: loss: 0.069680, loss_s1: 0.050095, loss_fp: 0.002067, loss_freq: 0.028448
[16:02:29.147] iteration 22726: loss: 0.070327, loss_s1: 0.046838, loss_fp: 0.002568, loss_freq: 0.048232
[16:02:29.784] iteration 22727: loss: 0.059832, loss_s1: 0.061495, loss_fp: 0.002278, loss_freq: 0.020995
[16:02:30.412] iteration 22728: loss: 0.112942, loss_s1: 0.080049, loss_fp: 0.001249, loss_freq: 0.038593
[16:02:31.030] iteration 22729: loss: 0.049108, loss_s1: 0.018877, loss_fp: 0.003442, loss_freq: 0.014341
[16:02:31.649] iteration 22730: loss: 0.083805, loss_s1: 0.093421, loss_fp: 0.004988, loss_freq: 0.028580
[16:02:32.261] iteration 22731: loss: 0.067312, loss_s1: 0.046284, loss_fp: 0.005803, loss_freq: 0.037121
[16:02:32.878] iteration 22732: loss: 0.044515, loss_s1: 0.048364, loss_fp: 0.001818, loss_freq: 0.006506
[16:02:33.496] iteration 22733: loss: 0.049996, loss_s1: 0.059895, loss_fp: 0.001435, loss_freq: 0.004179
[16:02:34.111] iteration 22734: loss: 0.049038, loss_s1: 0.030092, loss_fp: 0.003554, loss_freq: 0.010669
[16:02:34.727] iteration 22735: loss: 0.079161, loss_s1: 0.055478, loss_fp: 0.002617, loss_freq: 0.026732
[16:02:35.333] iteration 22736: loss: 0.136426, loss_s1: 0.137302, loss_fp: 0.020671, loss_freq: 0.069939
[16:02:35.953] iteration 22737: loss: 0.038336, loss_s1: 0.021103, loss_fp: 0.001813, loss_freq: 0.018436
[16:02:36.922] iteration 22738: loss: 0.066172, loss_s1: 0.079666, loss_fp: 0.001945, loss_freq: 0.013050
[16:02:37.544] iteration 22739: loss: 0.045980, loss_s1: 0.031177, loss_fp: 0.001830, loss_freq: 0.017071
[16:02:38.166] iteration 22740: loss: 0.036787, loss_s1: 0.025532, loss_fp: 0.000476, loss_freq: 0.013476
[16:02:38.795] iteration 22741: loss: 0.061755, loss_s1: 0.039291, loss_fp: 0.003882, loss_freq: 0.032110
[16:02:39.435] iteration 22742: loss: 0.081489, loss_s1: 0.100896, loss_fp: 0.000958, loss_freq: 0.023165
[16:02:40.078] iteration 22743: loss: 0.044872, loss_s1: 0.019191, loss_fp: 0.001835, loss_freq: 0.011709
[16:02:40.762] iteration 22744: loss: 0.029678, loss_s1: 0.023321, loss_fp: 0.001491, loss_freq: 0.005231
[16:02:41.388] iteration 22745: loss: 0.082557, loss_s1: 0.062404, loss_fp: 0.005837, loss_freq: 0.032797
[16:02:42.052] iteration 22746: loss: 0.057457, loss_s1: 0.038998, loss_fp: 0.009634, loss_freq: 0.016268
[16:02:42.675] iteration 22747: loss: 0.032535, loss_s1: 0.012563, loss_fp: 0.000802, loss_freq: 0.004521
[16:02:43.300] iteration 22748: loss: 0.052018, loss_s1: 0.028798, loss_fp: 0.005233, loss_freq: 0.029626
[16:02:43.925] iteration 22749: loss: 0.064723, loss_s1: 0.071814, loss_fp: 0.002820, loss_freq: 0.009680
[16:02:44.587] iteration 22750: loss: 0.072002, loss_s1: 0.048931, loss_fp: 0.001147, loss_freq: 0.054127
[16:02:45.210] iteration 22751: loss: 0.048774, loss_s1: 0.052647, loss_fp: 0.002756, loss_freq: 0.006031
[16:02:45.837] iteration 22752: loss: 0.078063, loss_s1: 0.064528, loss_fp: 0.007027, loss_freq: 0.042527
[16:02:46.459] iteration 22753: loss: 0.036912, loss_s1: 0.020382, loss_fp: 0.003075, loss_freq: 0.016257
[16:02:47.077] iteration 22754: loss: 0.064142, loss_s1: 0.045131, loss_fp: 0.001461, loss_freq: 0.020011
[16:02:47.750] iteration 22755: loss: 0.062665, loss_s1: 0.022766, loss_fp: 0.006363, loss_freq: 0.013823
[16:02:48.400] iteration 22756: loss: 0.044248, loss_s1: 0.023549, loss_fp: 0.001890, loss_freq: 0.018477
[16:02:49.047] iteration 22757: loss: 0.027902, loss_s1: 0.009032, loss_fp: 0.002371, loss_freq: 0.011114
[16:02:49.688] iteration 22758: loss: 0.084591, loss_s1: 0.043593, loss_fp: 0.004827, loss_freq: 0.042817
[16:02:50.312] iteration 22759: loss: 0.040153, loss_s1: 0.015712, loss_fp: 0.002349, loss_freq: 0.019938
[16:02:50.954] iteration 22760: loss: 0.082650, loss_s1: 0.046809, loss_fp: 0.004486, loss_freq: 0.057097
[16:02:51.616] iteration 22761: loss: 0.043147, loss_s1: 0.018532, loss_fp: 0.001682, loss_freq: 0.014944
[16:02:52.233] iteration 22762: loss: 0.058037, loss_s1: 0.053059, loss_fp: 0.004364, loss_freq: 0.022738
[16:02:52.852] iteration 22763: loss: 0.076755, loss_s1: 0.047863, loss_fp: 0.002338, loss_freq: 0.040795
[16:02:53.465] iteration 22764: loss: 0.047808, loss_s1: 0.022490, loss_fp: 0.001843, loss_freq: 0.020524
[16:02:54.092] iteration 22765: loss: 0.045055, loss_s1: 0.014811, loss_fp: 0.000812, loss_freq: 0.034424
[16:02:54.707] iteration 22766: loss: 0.048068, loss_s1: 0.023232, loss_fp: 0.001641, loss_freq: 0.029214
[16:02:55.317] iteration 22767: loss: 0.040667, loss_s1: 0.022906, loss_fp: 0.002311, loss_freq: 0.015916
[16:02:55.931] iteration 22768: loss: 0.046573, loss_s1: 0.037319, loss_fp: 0.001878, loss_freq: 0.007257
[16:02:56.545] iteration 22769: loss: 0.062640, loss_s1: 0.032701, loss_fp: 0.004033, loss_freq: 0.020685
[16:02:57.167] iteration 22770: loss: 0.090387, loss_s1: 0.074642, loss_fp: 0.009971, loss_freq: 0.064205
[16:02:57.795] iteration 22771: loss: 0.087032, loss_s1: 0.078469, loss_fp: 0.003944, loss_freq: 0.053671
[16:02:58.453] iteration 22772: loss: 0.065686, loss_s1: 0.044037, loss_fp: 0.012995, loss_freq: 0.029684
[16:02:59.091] iteration 22773: loss: 0.039626, loss_s1: 0.025255, loss_fp: 0.004537, loss_freq: 0.008081
[16:02:59.736] iteration 22774: loss: 0.072252, loss_s1: 0.057252, loss_fp: 0.013461, loss_freq: 0.031253
[16:03:00.376] iteration 22775: loss: 0.043814, loss_s1: 0.033490, loss_fp: 0.002007, loss_freq: 0.021365
[16:03:01.047] iteration 22776: loss: 0.063692, loss_s1: 0.047667, loss_fp: 0.001817, loss_freq: 0.025681
[16:03:01.706] iteration 22777: loss: 0.042880, loss_s1: 0.041757, loss_fp: 0.002762, loss_freq: 0.009272
[16:03:02.335] iteration 22778: loss: 0.083083, loss_s1: 0.039297, loss_fp: 0.005320, loss_freq: 0.024140
[16:03:02.954] iteration 22779: loss: 0.026997, loss_s1: 0.017269, loss_fp: 0.001426, loss_freq: 0.009471
[16:03:03.606] iteration 22780: loss: 0.050609, loss_s1: 0.050885, loss_fp: 0.001350, loss_freq: 0.008626
[16:03:04.267] iteration 22781: loss: 0.050644, loss_s1: 0.045207, loss_fp: 0.007447, loss_freq: 0.011676
[16:03:04.928] iteration 22782: loss: 0.052020, loss_s1: 0.013125, loss_fp: 0.000696, loss_freq: 0.011399
[16:03:05.574] iteration 22783: loss: 0.067778, loss_s1: 0.038599, loss_fp: 0.002641, loss_freq: 0.050028
[16:03:06.207] iteration 22784: loss: 0.057777, loss_s1: 0.047764, loss_fp: 0.007143, loss_freq: 0.020526
[16:03:06.825] iteration 22785: loss: 0.060932, loss_s1: 0.040216, loss_fp: 0.006037, loss_freq: 0.010776
[16:03:07.461] iteration 22786: loss: 0.050948, loss_s1: 0.041520, loss_fp: 0.004332, loss_freq: 0.029763
[16:03:08.101] iteration 22787: loss: 0.057274, loss_s1: 0.034116, loss_fp: 0.000749, loss_freq: 0.034463
[16:03:08.736] iteration 22788: loss: 0.065717, loss_s1: 0.027025, loss_fp: 0.006683, loss_freq: 0.043716
[16:03:09.360] iteration 22789: loss: 0.048690, loss_s1: 0.023615, loss_fp: 0.001409, loss_freq: 0.025669
[16:03:09.980] iteration 22790: loss: 0.048399, loss_s1: 0.044439, loss_fp: 0.001121, loss_freq: 0.014826
[16:03:10.609] iteration 22791: loss: 0.043005, loss_s1: 0.017330, loss_fp: 0.001293, loss_freq: 0.022151
[16:03:11.241] iteration 22792: loss: 0.032260, loss_s1: 0.027136, loss_fp: 0.002944, loss_freq: 0.006377
[16:03:11.880] iteration 22793: loss: 0.033621, loss_s1: 0.011814, loss_fp: 0.003037, loss_freq: 0.011226
[16:03:12.512] iteration 22794: loss: 0.042053, loss_s1: 0.028197, loss_fp: 0.005134, loss_freq: 0.016393
[16:03:13.136] iteration 22795: loss: 0.043607, loss_s1: 0.025179, loss_fp: 0.000984, loss_freq: 0.020733
[16:03:13.775] iteration 22796: loss: 0.058346, loss_s1: 0.022004, loss_fp: 0.000942, loss_freq: 0.048828
[16:03:14.432] iteration 22797: loss: 0.056932, loss_s1: 0.052153, loss_fp: 0.001841, loss_freq: 0.023010
[16:03:15.070] iteration 22798: loss: 0.059046, loss_s1: 0.036742, loss_fp: 0.001843, loss_freq: 0.019662
[16:03:15.711] iteration 22799: loss: 0.052646, loss_s1: 0.022572, loss_fp: 0.002991, loss_freq: 0.004058
[16:03:16.331] iteration 22800: loss: 0.067172, loss_s1: 0.075585, loss_fp: 0.004352, loss_freq: 0.010262
[16:03:19.499] iteration 22800 : mean_dice : 0.788120
[16:03:20.144] iteration 22801: loss: 0.072760, loss_s1: 0.015361, loss_fp: 0.000966, loss_freq: 0.016099
[16:03:20.759] iteration 22802: loss: 0.060780, loss_s1: 0.036237, loss_fp: 0.002369, loss_freq: 0.018279
[16:03:21.376] iteration 22803: loss: 0.041389, loss_s1: 0.020966, loss_fp: 0.003245, loss_freq: 0.015966
[16:03:22.001] iteration 22804: loss: 0.089523, loss_s1: 0.086354, loss_fp: 0.006528, loss_freq: 0.045105
[16:03:22.621] iteration 22805: loss: 0.046424, loss_s1: 0.030670, loss_fp: 0.002889, loss_freq: 0.023270
[16:03:23.240] iteration 22806: loss: 0.039997, loss_s1: 0.028547, loss_fp: 0.001775, loss_freq: 0.014016
[16:03:23.858] iteration 22807: loss: 0.066145, loss_s1: 0.032227, loss_fp: 0.002887, loss_freq: 0.030033
[16:03:24.478] iteration 22808: loss: 0.053648, loss_s1: 0.038012, loss_fp: 0.001100, loss_freq: 0.018253
[16:03:25.087] iteration 22809: loss: 0.117367, loss_s1: 0.086022, loss_fp: 0.005138, loss_freq: 0.092418
[16:03:25.701] iteration 22810: loss: 0.092391, loss_s1: 0.047408, loss_fp: 0.011734, loss_freq: 0.096501
[16:03:26.324] iteration 22811: loss: 0.079679, loss_s1: 0.063691, loss_fp: 0.010912, loss_freq: 0.042531
[16:03:26.942] iteration 22812: loss: 0.068193, loss_s1: 0.049305, loss_fp: 0.013617, loss_freq: 0.047384
[16:03:27.593] iteration 22813: loss: 0.042865, loss_s1: 0.026105, loss_fp: 0.002003, loss_freq: 0.020117
[16:03:28.207] iteration 22814: loss: 0.060508, loss_s1: 0.045602, loss_fp: 0.002881, loss_freq: 0.044965
[16:03:28.825] iteration 22815: loss: 0.051200, loss_s1: 0.035472, loss_fp: 0.006811, loss_freq: 0.015753
[16:03:29.449] iteration 22816: loss: 0.088704, loss_s1: 0.078372, loss_fp: 0.005207, loss_freq: 0.056966
[16:03:30.072] iteration 22817: loss: 0.090701, loss_s1: 0.074180, loss_fp: 0.006692, loss_freq: 0.039563
[16:03:30.722] iteration 22818: loss: 0.080528, loss_s1: 0.047137, loss_fp: 0.002649, loss_freq: 0.008674
[16:03:31.366] iteration 22819: loss: 0.060358, loss_s1: 0.048776, loss_fp: 0.001747, loss_freq: 0.019194
[16:03:31.983] iteration 22820: loss: 0.059621, loss_s1: 0.030769, loss_fp: 0.005906, loss_freq: 0.023102
[16:03:32.601] iteration 22821: loss: 0.037030, loss_s1: 0.013998, loss_fp: 0.003798, loss_freq: 0.013659
[16:03:33.286] iteration 22822: loss: 0.035819, loss_s1: 0.021671, loss_fp: 0.003139, loss_freq: 0.011177
[16:03:33.925] iteration 22823: loss: 0.078371, loss_s1: 0.056817, loss_fp: 0.009473, loss_freq: 0.040794
[16:03:34.564] iteration 22824: loss: 0.047905, loss_s1: 0.023632, loss_fp: 0.001553, loss_freq: 0.023521
[16:03:35.184] iteration 22825: loss: 0.031888, loss_s1: 0.016446, loss_fp: 0.001897, loss_freq: 0.012306
[16:03:35.813] iteration 22826: loss: 0.037783, loss_s1: 0.034062, loss_fp: 0.002027, loss_freq: 0.009255
[16:03:36.443] iteration 22827: loss: 0.044661, loss_s1: 0.037923, loss_fp: 0.002241, loss_freq: 0.018843
[16:03:37.067] iteration 22828: loss: 0.063555, loss_s1: 0.044571, loss_fp: 0.002712, loss_freq: 0.011790
[16:03:37.694] iteration 22829: loss: 0.066263, loss_s1: 0.039651, loss_fp: 0.004617, loss_freq: 0.040144
[16:03:38.406] iteration 22830: loss: 0.040711, loss_s1: 0.025526, loss_fp: 0.000841, loss_freq: 0.014488
[16:03:39.037] iteration 22831: loss: 0.044207, loss_s1: 0.033535, loss_fp: 0.002868, loss_freq: 0.009114
[16:03:39.714] iteration 22832: loss: 0.048825, loss_s1: 0.017621, loss_fp: 0.003942, loss_freq: 0.028400
[16:03:40.345] iteration 22833: loss: 0.047656, loss_s1: 0.013483, loss_fp: 0.002018, loss_freq: 0.007442
[16:03:40.968] iteration 22834: loss: 0.058373, loss_s1: 0.033307, loss_fp: 0.003088, loss_freq: 0.033245
[16:03:41.593] iteration 22835: loss: 0.066738, loss_s1: 0.040034, loss_fp: 0.002361, loss_freq: 0.041496
[16:03:42.217] iteration 22836: loss: 0.080562, loss_s1: 0.076167, loss_fp: 0.002733, loss_freq: 0.029514
[16:03:42.859] iteration 22837: loss: 0.099688, loss_s1: 0.085640, loss_fp: 0.002924, loss_freq: 0.057893
[16:03:43.482] iteration 22838: loss: 0.052603, loss_s1: 0.048674, loss_fp: 0.001883, loss_freq: 0.010854
[16:03:44.106] iteration 22839: loss: 0.063479, loss_s1: 0.042638, loss_fp: 0.007272, loss_freq: 0.026868
[16:03:44.731] iteration 22840: loss: 0.051357, loss_s1: 0.034873, loss_fp: 0.004299, loss_freq: 0.031310
[16:03:45.355] iteration 22841: loss: 0.044761, loss_s1: 0.029311, loss_fp: 0.009410, loss_freq: 0.013095
[16:03:45.981] iteration 22842: loss: 0.056322, loss_s1: 0.040256, loss_fp: 0.003268, loss_freq: 0.018411
[16:03:46.608] iteration 22843: loss: 0.056608, loss_s1: 0.023430, loss_fp: 0.001193, loss_freq: 0.045521
[16:03:47.236] iteration 22844: loss: 0.118491, loss_s1: 0.143530, loss_fp: 0.002342, loss_freq: 0.048834
[16:03:47.853] iteration 22845: loss: 0.048691, loss_s1: 0.043459, loss_fp: 0.001750, loss_freq: 0.022122
[16:03:48.475] iteration 22846: loss: 0.054839, loss_s1: 0.027858, loss_fp: 0.001946, loss_freq: 0.028911
[16:03:49.089] iteration 22847: loss: 0.087195, loss_s1: 0.068926, loss_fp: 0.009126, loss_freq: 0.067501
[16:03:49.707] iteration 22848: loss: 0.045393, loss_s1: 0.034396, loss_fp: 0.002327, loss_freq: 0.009601
[16:03:50.369] iteration 22849: loss: 0.088239, loss_s1: 0.083267, loss_fp: 0.009141, loss_freq: 0.056533
[16:03:50.988] iteration 22850: loss: 0.046500, loss_s1: 0.009536, loss_fp: 0.005020, loss_freq: 0.018734
[16:03:51.609] iteration 22851: loss: 0.089966, loss_s1: 0.068279, loss_fp: 0.009225, loss_freq: 0.058249
[16:03:52.221] iteration 22852: loss: 0.062410, loss_s1: 0.034308, loss_fp: 0.002268, loss_freq: 0.027920
[16:03:52.842] iteration 22853: loss: 0.037068, loss_s1: 0.023508, loss_fp: 0.002989, loss_freq: 0.008986
[16:03:53.454] iteration 22854: loss: 0.051846, loss_s1: 0.026381, loss_fp: 0.003638, loss_freq: 0.032638
[16:03:54.081] iteration 22855: loss: 0.069065, loss_s1: 0.072718, loss_fp: 0.002213, loss_freq: 0.022162
[16:03:54.700] iteration 22856: loss: 0.040202, loss_s1: 0.029820, loss_fp: 0.001033, loss_freq: 0.008816
[16:03:55.325] iteration 22857: loss: 0.068238, loss_s1: 0.060824, loss_fp: 0.002292, loss_freq: 0.039196
[16:03:55.949] iteration 22858: loss: 0.052012, loss_s1: 0.026143, loss_fp: 0.005258, loss_freq: 0.020758
[16:03:56.571] iteration 22859: loss: 0.051015, loss_s1: 0.025838, loss_fp: 0.002350, loss_freq: 0.018391
[16:03:57.190] iteration 22860: loss: 0.029272, loss_s1: 0.014170, loss_fp: 0.001156, loss_freq: 0.006284
[16:03:57.856] iteration 22861: loss: 0.054865, loss_s1: 0.046751, loss_fp: 0.006719, loss_freq: 0.021391
[16:03:58.482] iteration 22862: loss: 0.063452, loss_s1: 0.070730, loss_fp: 0.005319, loss_freq: 0.018941
[16:03:59.104] iteration 22863: loss: 0.070965, loss_s1: 0.065993, loss_fp: 0.001572, loss_freq: 0.025675
[16:03:59.729] iteration 22864: loss: 0.059047, loss_s1: 0.019207, loss_fp: 0.005248, loss_freq: 0.058937
[16:04:00.344] iteration 22865: loss: 0.046245, loss_s1: 0.027330, loss_fp: 0.001709, loss_freq: 0.016180
[16:04:00.969] iteration 22866: loss: 0.043106, loss_s1: 0.042118, loss_fp: 0.001049, loss_freq: 0.010947
[16:04:01.588] iteration 22867: loss: 0.059352, loss_s1: 0.058628, loss_fp: 0.004747, loss_freq: 0.017798
[16:04:02.213] iteration 22868: loss: 0.066203, loss_s1: 0.047299, loss_fp: 0.002607, loss_freq: 0.015683
[16:04:02.837] iteration 22869: loss: 0.059827, loss_s1: 0.040516, loss_fp: 0.001635, loss_freq: 0.031367
[16:04:03.465] iteration 22870: loss: 0.060122, loss_s1: 0.052284, loss_fp: 0.004870, loss_freq: 0.017976
[16:04:04.086] iteration 22871: loss: 0.071211, loss_s1: 0.053555, loss_fp: 0.005092, loss_freq: 0.025221
[16:04:04.713] iteration 22872: loss: 0.076981, loss_s1: 0.035959, loss_fp: 0.009272, loss_freq: 0.046169
[16:04:05.334] iteration 22873: loss: 0.035395, loss_s1: 0.025201, loss_fp: 0.004450, loss_freq: 0.007181
[16:04:05.951] iteration 22874: loss: 0.088324, loss_s1: 0.089234, loss_fp: 0.006074, loss_freq: 0.040912
[16:04:06.562] iteration 22875: loss: 0.028579, loss_s1: 0.010474, loss_fp: 0.002390, loss_freq: 0.010139
[16:04:07.173] iteration 22876: loss: 0.056098, loss_s1: 0.030949, loss_fp: 0.003000, loss_freq: 0.024873
[16:04:07.796] iteration 22877: loss: 0.050177, loss_s1: 0.028481, loss_fp: 0.001923, loss_freq: 0.015869
[16:04:08.415] iteration 22878: loss: 0.071928, loss_s1: 0.042352, loss_fp: 0.008452, loss_freq: 0.051338
[16:04:09.032] iteration 22879: loss: 0.102747, loss_s1: 0.089143, loss_fp: 0.025116, loss_freq: 0.051700
[16:04:09.649] iteration 22880: loss: 0.036747, loss_s1: 0.026123, loss_fp: 0.001638, loss_freq: 0.015170
[16:04:10.587] iteration 22881: loss: 0.053921, loss_s1: 0.038903, loss_fp: 0.001594, loss_freq: 0.018259
[16:04:11.210] iteration 22882: loss: 0.041677, loss_s1: 0.021433, loss_fp: 0.004177, loss_freq: 0.017323
[16:04:11.833] iteration 22883: loss: 0.039195, loss_s1: 0.008995, loss_fp: 0.003188, loss_freq: 0.025677
[16:04:12.444] iteration 22884: loss: 0.047278, loss_s1: 0.019749, loss_fp: 0.001972, loss_freq: 0.026980
[16:04:13.057] iteration 22885: loss: 0.052530, loss_s1: 0.026944, loss_fp: 0.002800, loss_freq: 0.041401
[16:04:13.678] iteration 22886: loss: 0.076931, loss_s1: 0.050387, loss_fp: 0.000840, loss_freq: 0.011436
[16:04:14.301] iteration 22887: loss: 0.050346, loss_s1: 0.035730, loss_fp: 0.004037, loss_freq: 0.017578
[16:04:14.960] iteration 22888: loss: 0.064051, loss_s1: 0.045245, loss_fp: 0.001028, loss_freq: 0.035423
[16:04:15.584] iteration 22889: loss: 0.061420, loss_s1: 0.053381, loss_fp: 0.002953, loss_freq: 0.020709
[16:04:16.207] iteration 22890: loss: 0.030851, loss_s1: 0.007052, loss_fp: 0.001270, loss_freq: 0.003100
[16:04:16.835] iteration 22891: loss: 0.061674, loss_s1: 0.041499, loss_fp: 0.002335, loss_freq: 0.045516
[16:04:17.455] iteration 22892: loss: 0.061647, loss_s1: 0.040366, loss_fp: 0.004706, loss_freq: 0.018520
[16:04:18.083] iteration 22893: loss: 0.044635, loss_s1: 0.036942, loss_fp: 0.002517, loss_freq: 0.009264
[16:04:18.708] iteration 22894: loss: 0.044106, loss_s1: 0.037493, loss_fp: 0.002302, loss_freq: 0.008599
[16:04:19.334] iteration 22895: loss: 0.060117, loss_s1: 0.048770, loss_fp: 0.000423, loss_freq: 0.021412
[16:04:19.956] iteration 22896: loss: 0.053730, loss_s1: 0.043621, loss_fp: 0.003153, loss_freq: 0.016397
[16:04:20.603] iteration 22897: loss: 0.051819, loss_s1: 0.041337, loss_fp: 0.001727, loss_freq: 0.007225
[16:04:21.256] iteration 22898: loss: 0.060019, loss_s1: 0.061374, loss_fp: 0.003072, loss_freq: 0.016823
[16:04:21.881] iteration 22899: loss: 0.043326, loss_s1: 0.033107, loss_fp: 0.002223, loss_freq: 0.028039
[16:04:22.502] iteration 22900: loss: 0.042531, loss_s1: 0.036446, loss_fp: 0.003010, loss_freq: 0.014725
[16:04:23.117] iteration 22901: loss: 0.084606, loss_s1: 0.040781, loss_fp: 0.003361, loss_freq: 0.061760
[16:04:23.736] iteration 22902: loss: 0.052455, loss_s1: 0.042945, loss_fp: 0.002124, loss_freq: 0.027281
[16:04:24.360] iteration 22903: loss: 0.037167, loss_s1: 0.020487, loss_fp: 0.001329, loss_freq: 0.014714
[16:04:24.984] iteration 22904: loss: 0.050859, loss_s1: 0.023721, loss_fp: 0.001267, loss_freq: 0.014422
[16:04:25.617] iteration 22905: loss: 0.043030, loss_s1: 0.019698, loss_fp: 0.002369, loss_freq: 0.025438
[16:04:26.239] iteration 22906: loss: 0.082412, loss_s1: 0.065008, loss_fp: 0.004362, loss_freq: 0.046948
[16:04:26.900] iteration 22907: loss: 0.089877, loss_s1: 0.059597, loss_fp: 0.002563, loss_freq: 0.073404
[16:04:27.517] iteration 22908: loss: 0.043593, loss_s1: 0.028596, loss_fp: 0.003399, loss_freq: 0.012749
[16:04:28.141] iteration 22909: loss: 0.069420, loss_s1: 0.056663, loss_fp: 0.002033, loss_freq: 0.015474
[16:04:28.759] iteration 22910: loss: 0.048483, loss_s1: 0.021496, loss_fp: 0.003797, loss_freq: 0.014192
[16:04:29.383] iteration 22911: loss: 0.037456, loss_s1: 0.024607, loss_fp: 0.001407, loss_freq: 0.007514
[16:04:30.008] iteration 22912: loss: 0.074289, loss_s1: 0.050601, loss_fp: 0.009664, loss_freq: 0.033187
[16:04:30.631] iteration 22913: loss: 0.081202, loss_s1: 0.076745, loss_fp: 0.014747, loss_freq: 0.041438
[16:04:31.259] iteration 22914: loss: 0.089093, loss_s1: 0.093420, loss_fp: 0.003546, loss_freq: 0.044274
[16:04:31.884] iteration 22915: loss: 0.059180, loss_s1: 0.037623, loss_fp: 0.011035, loss_freq: 0.026151
[16:04:32.507] iteration 22916: loss: 0.092544, loss_s1: 0.071382, loss_fp: 0.021027, loss_freq: 0.057858
[16:04:33.129] iteration 22917: loss: 0.067040, loss_s1: 0.040924, loss_fp: 0.002898, loss_freq: 0.042107
[16:04:33.754] iteration 22918: loss: 0.047937, loss_s1: 0.028392, loss_fp: 0.006715, loss_freq: 0.027544
[16:04:34.376] iteration 22919: loss: 0.075408, loss_s1: 0.028158, loss_fp: 0.015894, loss_freq: 0.040617
[16:04:34.992] iteration 22920: loss: 0.042771, loss_s1: 0.023689, loss_fp: 0.006186, loss_freq: 0.018471
[16:04:35.622] iteration 22921: loss: 0.051709, loss_s1: 0.042609, loss_fp: 0.006831, loss_freq: 0.019420
[16:04:36.233] iteration 22922: loss: 0.027351, loss_s1: 0.010650, loss_fp: 0.000868, loss_freq: 0.015161
[16:04:36.871] iteration 22923: loss: 0.047475, loss_s1: 0.033939, loss_fp: 0.005167, loss_freq: 0.007286
[16:04:37.490] iteration 22924: loss: 0.069433, loss_s1: 0.042794, loss_fp: 0.008446, loss_freq: 0.045401
[16:04:38.110] iteration 22925: loss: 0.052783, loss_s1: 0.019614, loss_fp: 0.001323, loss_freq: 0.006085
[16:04:38.792] iteration 22926: loss: 0.076747, loss_s1: 0.085054, loss_fp: 0.003168, loss_freq: 0.033543
[16:04:39.410] iteration 22927: loss: 0.059310, loss_s1: 0.050452, loss_fp: 0.005758, loss_freq: 0.026249
[16:04:40.032] iteration 22928: loss: 0.042962, loss_s1: 0.020138, loss_fp: 0.003982, loss_freq: 0.015020
[16:04:40.676] iteration 22929: loss: 0.058043, loss_s1: 0.064205, loss_fp: 0.006825, loss_freq: 0.015608
[16:04:41.296] iteration 22930: loss: 0.058543, loss_s1: 0.056933, loss_fp: 0.000769, loss_freq: 0.013730
[16:04:41.934] iteration 22931: loss: 0.043892, loss_s1: 0.034075, loss_fp: 0.006542, loss_freq: 0.005307
[16:04:42.572] iteration 22932: loss: 0.059525, loss_s1: 0.013077, loss_fp: 0.000804, loss_freq: 0.039470
[16:04:43.218] iteration 22933: loss: 0.041774, loss_s1: 0.024718, loss_fp: 0.000487, loss_freq: 0.019962
[16:04:43.829] iteration 22934: loss: 0.040269, loss_s1: 0.021259, loss_fp: 0.005800, loss_freq: 0.019489
[16:04:44.455] iteration 22935: loss: 0.052074, loss_s1: 0.033268, loss_fp: 0.000748, loss_freq: 0.038020
[16:04:45.077] iteration 22936: loss: 0.035976, loss_s1: 0.017059, loss_fp: 0.000933, loss_freq: 0.006408
[16:04:45.703] iteration 22937: loss: 0.073021, loss_s1: 0.086192, loss_fp: 0.005573, loss_freq: 0.022491
[16:04:46.334] iteration 22938: loss: 0.042556, loss_s1: 0.032866, loss_fp: 0.000576, loss_freq: 0.019702
[16:04:46.957] iteration 22939: loss: 0.057441, loss_s1: 0.043840, loss_fp: 0.002045, loss_freq: 0.031530
[16:04:47.575] iteration 22940: loss: 0.055624, loss_s1: 0.048300, loss_fp: 0.001670, loss_freq: 0.028476
[16:04:48.192] iteration 22941: loss: 0.039818, loss_s1: 0.031903, loss_fp: 0.001843, loss_freq: 0.010434
[16:04:48.809] iteration 22942: loss: 0.031440, loss_s1: 0.018901, loss_fp: 0.000512, loss_freq: 0.005929
[16:04:49.433] iteration 22943: loss: 0.054267, loss_s1: 0.036554, loss_fp: 0.005959, loss_freq: 0.032081
[16:04:50.059] iteration 22944: loss: 0.047021, loss_s1: 0.010438, loss_fp: 0.002206, loss_freq: 0.020793
[16:04:50.689] iteration 22945: loss: 0.152492, loss_s1: 0.044324, loss_fp: 0.002023, loss_freq: 0.039817
[16:04:51.309] iteration 22946: loss: 0.034787, loss_s1: 0.018722, loss_fp: 0.002459, loss_freq: 0.010143
[16:04:51.923] iteration 22947: loss: 0.077614, loss_s1: 0.075464, loss_fp: 0.007958, loss_freq: 0.031964
[16:04:52.547] iteration 22948: loss: 0.046801, loss_s1: 0.033631, loss_fp: 0.003055, loss_freq: 0.027870
[16:04:53.167] iteration 22949: loss: 0.032950, loss_s1: 0.019531, loss_fp: 0.001516, loss_freq: 0.014591
[16:04:53.784] iteration 22950: loss: 0.036006, loss_s1: 0.018647, loss_fp: 0.002609, loss_freq: 0.004440
[16:04:54.415] iteration 22951: loss: 0.038622, loss_s1: 0.016799, loss_fp: 0.000960, loss_freq: 0.019612
[16:04:55.043] iteration 22952: loss: 0.049352, loss_s1: 0.023071, loss_fp: 0.003442, loss_freq: 0.029926
[16:04:55.661] iteration 22953: loss: 0.049192, loss_s1: 0.046631, loss_fp: 0.001731, loss_freq: 0.021826
[16:04:56.266] iteration 22954: loss: 0.079744, loss_s1: 0.089666, loss_fp: 0.007927, loss_freq: 0.010636
[16:04:56.921] iteration 22955: loss: 0.070823, loss_s1: 0.050345, loss_fp: 0.004281, loss_freq: 0.053197
[16:04:57.539] iteration 22956: loss: 0.058152, loss_s1: 0.043861, loss_fp: 0.004188, loss_freq: 0.008633
[16:04:58.158] iteration 22957: loss: 0.085135, loss_s1: 0.071632, loss_fp: 0.013144, loss_freq: 0.052660
[16:04:58.777] iteration 22958: loss: 0.050192, loss_s1: 0.032810, loss_fp: 0.004721, loss_freq: 0.017644
[16:04:59.394] iteration 22959: loss: 0.070329, loss_s1: 0.042234, loss_fp: 0.018763, loss_freq: 0.037670
[16:05:00.018] iteration 22960: loss: 0.088654, loss_s1: 0.037235, loss_fp: 0.020644, loss_freq: 0.028154
[16:05:00.630] iteration 22961: loss: 0.070325, loss_s1: 0.033029, loss_fp: 0.008263, loss_freq: 0.033543
[16:05:01.242] iteration 22962: loss: 0.039909, loss_s1: 0.021363, loss_fp: 0.004202, loss_freq: 0.020979
[16:05:01.865] iteration 22963: loss: 0.053895, loss_s1: 0.049136, loss_fp: 0.005766, loss_freq: 0.016690
[16:05:02.478] iteration 22964: loss: 0.038938, loss_s1: 0.031351, loss_fp: 0.003180, loss_freq: 0.012839
[16:05:03.097] iteration 22965: loss: 0.063814, loss_s1: 0.045928, loss_fp: 0.026416, loss_freq: 0.016364
[16:05:03.714] iteration 22966: loss: 0.059524, loss_s1: 0.043068, loss_fp: 0.004091, loss_freq: 0.036942
[16:05:04.334] iteration 22967: loss: 0.040220, loss_s1: 0.030670, loss_fp: 0.000589, loss_freq: 0.011908
[16:05:04.958] iteration 22968: loss: 0.042655, loss_s1: 0.020154, loss_fp: 0.000369, loss_freq: 0.020129
[16:05:05.579] iteration 22969: loss: 0.054603, loss_s1: 0.065475, loss_fp: 0.002235, loss_freq: 0.011044
[16:05:06.207] iteration 22970: loss: 0.055237, loss_s1: 0.043759, loss_fp: 0.006084, loss_freq: 0.029294
[16:05:06.825] iteration 22971: loss: 0.054576, loss_s1: 0.032079, loss_fp: 0.004643, loss_freq: 0.024032
[16:05:07.453] iteration 22972: loss: 0.057297, loss_s1: 0.035520, loss_fp: 0.008142, loss_freq: 0.027781
[16:05:08.127] iteration 22973: loss: 0.037957, loss_s1: 0.020642, loss_fp: 0.003743, loss_freq: 0.010006
[16:05:08.753] iteration 22974: loss: 0.040993, loss_s1: 0.033042, loss_fp: 0.000685, loss_freq: 0.008868
[16:05:09.391] iteration 22975: loss: 0.052664, loss_s1: 0.016016, loss_fp: 0.000910, loss_freq: 0.019333
[16:05:10.027] iteration 22976: loss: 0.040480, loss_s1: 0.029432, loss_fp: 0.000460, loss_freq: 0.005407
[16:05:10.664] iteration 22977: loss: 0.086247, loss_s1: 0.038684, loss_fp: 0.005836, loss_freq: 0.083886
[16:05:11.288] iteration 22978: loss: 0.036110, loss_s1: 0.013757, loss_fp: 0.003482, loss_freq: 0.015151
[16:05:11.907] iteration 22979: loss: 0.036749, loss_s1: 0.019937, loss_fp: 0.001569, loss_freq: 0.009662
[16:05:12.525] iteration 22980: loss: 0.093376, loss_s1: 0.062287, loss_fp: 0.002834, loss_freq: 0.063154
[16:05:13.154] iteration 22981: loss: 0.045012, loss_s1: 0.030250, loss_fp: 0.002607, loss_freq: 0.016465
[16:05:13.813] iteration 22982: loss: 0.073780, loss_s1: 0.038585, loss_fp: 0.001971, loss_freq: 0.028329
[16:05:14.475] iteration 22983: loss: 0.043319, loss_s1: 0.031219, loss_fp: 0.003389, loss_freq: 0.022801
[16:05:15.108] iteration 22984: loss: 0.061026, loss_s1: 0.039805, loss_fp: 0.001070, loss_freq: 0.033768
[16:05:15.732] iteration 22985: loss: 0.093585, loss_s1: 0.046205, loss_fp: 0.002080, loss_freq: 0.021226
[16:05:16.351] iteration 22986: loss: 0.062392, loss_s1: 0.045865, loss_fp: 0.009349, loss_freq: 0.023257
[16:05:17.145] iteration 22987: loss: 0.081609, loss_s1: 0.067578, loss_fp: 0.003222, loss_freq: 0.051427
[16:05:18.067] iteration 22988: loss: 0.099918, loss_s1: 0.094586, loss_fp: 0.012630, loss_freq: 0.060606
[16:05:18.874] iteration 22989: loss: 0.080590, loss_s1: 0.059472, loss_fp: 0.000908, loss_freq: 0.035556
[16:05:19.643] iteration 22990: loss: 0.052844, loss_s1: 0.043098, loss_fp: 0.002966, loss_freq: 0.030927
[16:05:20.305] iteration 22991: loss: 0.050690, loss_s1: 0.052697, loss_fp: 0.003660, loss_freq: 0.007493
[16:05:20.926] iteration 22992: loss: 0.048116, loss_s1: 0.028627, loss_fp: 0.011939, loss_freq: 0.025632
[16:05:21.549] iteration 22993: loss: 0.055298, loss_s1: 0.063200, loss_fp: 0.000842, loss_freq: 0.004687
[16:05:22.214] iteration 22994: loss: 0.060352, loss_s1: 0.055024, loss_fp: 0.006126, loss_freq: 0.026989
[16:05:22.844] iteration 22995: loss: 0.082437, loss_s1: 0.056308, loss_fp: 0.003089, loss_freq: 0.045845
[16:05:23.466] iteration 22996: loss: 0.041165, loss_s1: 0.023749, loss_fp: 0.001713, loss_freq: 0.015876
[16:05:24.087] iteration 22997: loss: 0.078110, loss_s1: 0.043656, loss_fp: 0.004368, loss_freq: 0.034693
[16:05:24.762] iteration 22998: loss: 0.066172, loss_s1: 0.070193, loss_fp: 0.003070, loss_freq: 0.021082
[16:05:25.383] iteration 22999: loss: 0.046993, loss_s1: 0.052693, loss_fp: 0.002453, loss_freq: 0.009791
[16:05:26.010] iteration 23000: loss: 0.045357, loss_s1: 0.031340, loss_fp: 0.000976, loss_freq: 0.017054
[16:05:29.459] iteration 23000 : mean_dice : 0.784062
[16:05:30.103] iteration 23001: loss: 0.101863, loss_s1: 0.061876, loss_fp: 0.006454, loss_freq: 0.091063
[16:05:30.732] iteration 23002: loss: 0.057375, loss_s1: 0.016955, loss_fp: 0.004311, loss_freq: 0.014621
[16:05:31.352] iteration 23003: loss: 0.041848, loss_s1: 0.028153, loss_fp: 0.001667, loss_freq: 0.011346
[16:05:31.978] iteration 23004: loss: 0.057991, loss_s1: 0.062539, loss_fp: 0.002144, loss_freq: 0.025304
[16:05:32.608] iteration 23005: loss: 0.051715, loss_s1: 0.040774, loss_fp: 0.001983, loss_freq: 0.030191
[16:05:33.237] iteration 23006: loss: 0.064921, loss_s1: 0.044497, loss_fp: 0.002860, loss_freq: 0.018293
[16:05:33.865] iteration 23007: loss: 0.063775, loss_s1: 0.065258, loss_fp: 0.003964, loss_freq: 0.020574
[16:05:34.498] iteration 23008: loss: 0.051921, loss_s1: 0.043886, loss_fp: 0.008305, loss_freq: 0.012000
[16:05:35.125] iteration 23009: loss: 0.084389, loss_s1: 0.059207, loss_fp: 0.012400, loss_freq: 0.029195
[16:05:35.770] iteration 23010: loss: 0.044026, loss_s1: 0.017729, loss_fp: 0.003496, loss_freq: 0.022245
[16:05:36.423] iteration 23011: loss: 0.075910, loss_s1: 0.056095, loss_fp: 0.005373, loss_freq: 0.020876
[16:05:37.124] iteration 23012: loss: 0.063739, loss_s1: 0.037844, loss_fp: 0.002319, loss_freq: 0.031107
[16:05:37.785] iteration 23013: loss: 0.073055, loss_s1: 0.037117, loss_fp: 0.012589, loss_freq: 0.047377
[16:05:38.427] iteration 23014: loss: 0.049880, loss_s1: 0.012717, loss_fp: 0.005205, loss_freq: 0.032377
[16:05:39.072] iteration 23015: loss: 0.066598, loss_s1: 0.020788, loss_fp: 0.004873, loss_freq: 0.039206
[16:05:39.718] iteration 23016: loss: 0.053647, loss_s1: 0.034262, loss_fp: 0.010141, loss_freq: 0.025823
[16:05:40.367] iteration 23017: loss: 0.092018, loss_s1: 0.068220, loss_fp: 0.006577, loss_freq: 0.037860
[16:05:41.046] iteration 23018: loss: 0.066015, loss_s1: 0.065867, loss_fp: 0.001375, loss_freq: 0.019350
[16:05:41.694] iteration 23019: loss: 0.050798, loss_s1: 0.029340, loss_fp: 0.002676, loss_freq: 0.019388
[16:05:42.327] iteration 23020: loss: 0.049128, loss_s1: 0.033489, loss_fp: 0.003001, loss_freq: 0.013221
[16:05:42.955] iteration 23021: loss: 0.052199, loss_s1: 0.042807, loss_fp: 0.003039, loss_freq: 0.020530
[16:05:43.583] iteration 23022: loss: 0.090023, loss_s1: 0.106461, loss_fp: 0.008412, loss_freq: 0.011456
[16:05:44.236] iteration 23023: loss: 0.031159, loss_s1: 0.010767, loss_fp: 0.002069, loss_freq: 0.021718
[16:05:45.197] iteration 23024: loss: 0.034894, loss_s1: 0.018205, loss_fp: 0.001883, loss_freq: 0.006619
[16:05:45.826] iteration 23025: loss: 0.048006, loss_s1: 0.019817, loss_fp: 0.002187, loss_freq: 0.019674
[16:05:46.449] iteration 23026: loss: 0.047005, loss_s1: 0.035702, loss_fp: 0.004121, loss_freq: 0.018232
[16:05:47.105] iteration 23027: loss: 0.043734, loss_s1: 0.025541, loss_fp: 0.003023, loss_freq: 0.016395
[16:05:47.716] iteration 23028: loss: 0.059635, loss_s1: 0.055509, loss_fp: 0.001354, loss_freq: 0.031644
[16:05:48.336] iteration 23029: loss: 0.077110, loss_s1: 0.016014, loss_fp: 0.005355, loss_freq: 0.009154
[16:05:48.955] iteration 23030: loss: 0.033683, loss_s1: 0.020569, loss_fp: 0.002596, loss_freq: 0.013603
[16:05:49.581] iteration 23031: loss: 0.068820, loss_s1: 0.074549, loss_fp: 0.002826, loss_freq: 0.013295
[16:05:50.196] iteration 23032: loss: 0.044524, loss_s1: 0.017490, loss_fp: 0.004381, loss_freq: 0.018223
[16:05:50.838] iteration 23033: loss: 0.047154, loss_s1: 0.017794, loss_fp: 0.001062, loss_freq: 0.010069
[16:05:51.488] iteration 23034: loss: 0.058018, loss_s1: 0.053539, loss_fp: 0.005400, loss_freq: 0.024220
[16:05:52.105] iteration 23035: loss: 0.046831, loss_s1: 0.018156, loss_fp: 0.002623, loss_freq: 0.022469
[16:05:52.730] iteration 23036: loss: 0.051875, loss_s1: 0.050946, loss_fp: 0.002419, loss_freq: 0.012344
[16:05:53.346] iteration 23037: loss: 0.035415, loss_s1: 0.021480, loss_fp: 0.001389, loss_freq: 0.012518
[16:05:54.013] iteration 23038: loss: 0.067700, loss_s1: 0.065273, loss_fp: 0.009622, loss_freq: 0.020586
[16:05:54.631] iteration 23039: loss: 0.036621, loss_s1: 0.008178, loss_fp: 0.001686, loss_freq: 0.027553
[16:05:55.251] iteration 23040: loss: 0.046956, loss_s1: 0.024730, loss_fp: 0.002406, loss_freq: 0.027491
[16:05:55.869] iteration 23041: loss: 0.056789, loss_s1: 0.056473, loss_fp: 0.001931, loss_freq: 0.021433
[16:05:56.493] iteration 23042: loss: 0.039821, loss_s1: 0.022175, loss_fp: 0.002701, loss_freq: 0.021414
[16:05:57.115] iteration 23043: loss: 0.038996, loss_s1: 0.022958, loss_fp: 0.001828, loss_freq: 0.013463
[16:05:57.734] iteration 23044: loss: 0.094717, loss_s1: 0.048678, loss_fp: 0.001702, loss_freq: 0.041032
[16:05:58.349] iteration 23045: loss: 0.050989, loss_s1: 0.040160, loss_fp: 0.005207, loss_freq: 0.020431
[16:05:58.971] iteration 23046: loss: 0.047460, loss_s1: 0.037088, loss_fp: 0.001836, loss_freq: 0.025563
[16:05:59.593] iteration 23047: loss: 0.053270, loss_s1: 0.028708, loss_fp: 0.001565, loss_freq: 0.012607
[16:06:00.264] iteration 23048: loss: 0.040139, loss_s1: 0.026217, loss_fp: 0.003255, loss_freq: 0.010541
[16:06:00.884] iteration 23049: loss: 0.102745, loss_s1: 0.087946, loss_fp: 0.001737, loss_freq: 0.058349
[16:06:01.502] iteration 23050: loss: 0.103631, loss_s1: 0.087108, loss_fp: 0.006429, loss_freq: 0.076560
[16:06:02.124] iteration 23051: loss: 0.039859, loss_s1: 0.027137, loss_fp: 0.006620, loss_freq: 0.011820
[16:06:02.745] iteration 23052: loss: 0.065556, loss_s1: 0.036779, loss_fp: 0.007162, loss_freq: 0.032761
[16:06:03.358] iteration 23053: loss: 0.043705, loss_s1: 0.020351, loss_fp: 0.002193, loss_freq: 0.009240
[16:06:03.977] iteration 23054: loss: 0.039357, loss_s1: 0.034431, loss_fp: 0.004507, loss_freq: 0.003720
[16:06:04.619] iteration 23055: loss: 0.055200, loss_s1: 0.026668, loss_fp: 0.000867, loss_freq: 0.019867
[16:06:05.235] iteration 23056: loss: 0.083594, loss_s1: 0.074410, loss_fp: 0.004141, loss_freq: 0.058377
[16:06:05.851] iteration 23057: loss: 0.080217, loss_s1: 0.060311, loss_fp: 0.005150, loss_freq: 0.059310
[16:06:06.475] iteration 23058: loss: 0.091043, loss_s1: 0.102481, loss_fp: 0.001255, loss_freq: 0.036845
[16:06:07.099] iteration 23059: loss: 0.048119, loss_s1: 0.030249, loss_fp: 0.002558, loss_freq: 0.017253
[16:06:07.725] iteration 23060: loss: 0.082551, loss_s1: 0.043925, loss_fp: 0.002581, loss_freq: 0.063827
[16:06:08.341] iteration 23061: loss: 0.032209, loss_s1: 0.017215, loss_fp: 0.002742, loss_freq: 0.011680
[16:06:08.963] iteration 23062: loss: 0.079516, loss_s1: 0.074274, loss_fp: 0.002996, loss_freq: 0.025306
[16:06:09.594] iteration 23063: loss: 0.046936, loss_s1: 0.043839, loss_fp: 0.005255, loss_freq: 0.011281
[16:06:10.214] iteration 23064: loss: 0.079072, loss_s1: 0.034451, loss_fp: 0.005725, loss_freq: 0.028665
[16:06:10.843] iteration 23065: loss: 0.036024, loss_s1: 0.013747, loss_fp: 0.002787, loss_freq: 0.026566
[16:06:11.464] iteration 23066: loss: 0.038804, loss_s1: 0.028073, loss_fp: 0.001130, loss_freq: 0.015207
[16:06:12.082] iteration 23067: loss: 0.048549, loss_s1: 0.040796, loss_fp: 0.001933, loss_freq: 0.010784
[16:06:12.700] iteration 23068: loss: 0.064261, loss_s1: 0.033520, loss_fp: 0.004885, loss_freq: 0.019167
[16:06:13.321] iteration 23069: loss: 0.075839, loss_s1: 0.069524, loss_fp: 0.002059, loss_freq: 0.040351
[16:06:13.949] iteration 23070: loss: 0.047859, loss_s1: 0.023119, loss_fp: 0.006569, loss_freq: 0.035005
[16:06:14.570] iteration 23071: loss: 0.052226, loss_s1: 0.048173, loss_fp: 0.000865, loss_freq: 0.019294
[16:06:15.191] iteration 23072: loss: 0.069095, loss_s1: 0.048247, loss_fp: 0.004509, loss_freq: 0.050032
[16:06:15.808] iteration 23073: loss: 0.044926, loss_s1: 0.034948, loss_fp: 0.000827, loss_freq: 0.012654
[16:06:16.421] iteration 23074: loss: 0.056685, loss_s1: 0.045382, loss_fp: 0.007273, loss_freq: 0.021535
[16:06:17.043] iteration 23075: loss: 0.069119, loss_s1: 0.040053, loss_fp: 0.007814, loss_freq: 0.043690
[16:06:17.709] iteration 23076: loss: 0.051079, loss_s1: 0.042128, loss_fp: 0.004725, loss_freq: 0.022412
[16:06:18.333] iteration 23077: loss: 0.046754, loss_s1: 0.028328, loss_fp: 0.003374, loss_freq: 0.019994
[16:06:18.953] iteration 23078: loss: 0.042229, loss_s1: 0.029320, loss_fp: 0.000796, loss_freq: 0.011244
[16:06:19.618] iteration 23079: loss: 0.042460, loss_s1: 0.028398, loss_fp: 0.002938, loss_freq: 0.009054
[16:06:20.264] iteration 23080: loss: 0.043792, loss_s1: 0.040774, loss_fp: 0.001866, loss_freq: 0.014568
[16:06:20.915] iteration 23081: loss: 0.038123, loss_s1: 0.038632, loss_fp: 0.001768, loss_freq: 0.007538
[16:06:21.555] iteration 23082: loss: 0.058184, loss_s1: 0.039696, loss_fp: 0.001373, loss_freq: 0.028809
[16:06:22.174] iteration 23083: loss: 0.060282, loss_s1: 0.049173, loss_fp: 0.002750, loss_freq: 0.034560
[16:06:22.791] iteration 23084: loss: 0.049858, loss_s1: 0.029071, loss_fp: 0.005820, loss_freq: 0.016163
[16:06:23.410] iteration 23085: loss: 0.048442, loss_s1: 0.037520, loss_fp: 0.001881, loss_freq: 0.014767
[16:06:24.085] iteration 23086: loss: 0.084734, loss_s1: 0.080779, loss_fp: 0.003268, loss_freq: 0.047953
[16:06:24.703] iteration 23087: loss: 0.053996, loss_s1: 0.019442, loss_fp: 0.003374, loss_freq: 0.023553
[16:06:25.381] iteration 23088: loss: 0.062432, loss_s1: 0.033600, loss_fp: 0.002239, loss_freq: 0.013510
[16:06:26.020] iteration 23089: loss: 0.051288, loss_s1: 0.030783, loss_fp: 0.001076, loss_freq: 0.029244
[16:06:26.633] iteration 23090: loss: 0.096252, loss_s1: 0.068697, loss_fp: 0.010201, loss_freq: 0.032358
[16:06:27.251] iteration 23091: loss: 0.037716, loss_s1: 0.023399, loss_fp: 0.004290, loss_freq: 0.013377
[16:06:27.900] iteration 23092: loss: 0.058976, loss_s1: 0.047272, loss_fp: 0.002338, loss_freq: 0.023263
[16:06:28.542] iteration 23093: loss: 0.057415, loss_s1: 0.035635, loss_fp: 0.005311, loss_freq: 0.010889
[16:06:29.190] iteration 23094: loss: 0.042461, loss_s1: 0.018854, loss_fp: 0.003718, loss_freq: 0.024683
[16:06:29.859] iteration 23095: loss: 0.084284, loss_s1: 0.039351, loss_fp: 0.003333, loss_freq: 0.062839
[16:06:30.478] iteration 23096: loss: 0.045867, loss_s1: 0.023654, loss_fp: 0.005702, loss_freq: 0.033293
[16:06:31.122] iteration 23097: loss: 0.050726, loss_s1: 0.033376, loss_fp: 0.002396, loss_freq: 0.021014
[16:06:31.748] iteration 23098: loss: 0.072359, loss_s1: 0.052067, loss_fp: 0.007739, loss_freq: 0.057987
[16:06:32.361] iteration 23099: loss: 0.052103, loss_s1: 0.017350, loss_fp: 0.002451, loss_freq: 0.008660
[16:06:32.991] iteration 23100: loss: 0.074134, loss_s1: 0.064324, loss_fp: 0.005695, loss_freq: 0.030844
[16:06:33.613] iteration 23101: loss: 0.055778, loss_s1: 0.052168, loss_fp: 0.001340, loss_freq: 0.017753
[16:06:34.234] iteration 23102: loss: 0.063059, loss_s1: 0.044318, loss_fp: 0.016244, loss_freq: 0.020871
[16:06:34.855] iteration 23103: loss: 0.093362, loss_s1: 0.074538, loss_fp: 0.014997, loss_freq: 0.032361
[16:06:35.484] iteration 23104: loss: 0.073757, loss_s1: 0.043877, loss_fp: 0.001880, loss_freq: 0.059142
[16:06:36.099] iteration 23105: loss: 0.055605, loss_s1: 0.043972, loss_fp: 0.001709, loss_freq: 0.018805
[16:06:36.725] iteration 23106: loss: 0.061562, loss_s1: 0.049034, loss_fp: 0.001550, loss_freq: 0.031852
[16:06:37.364] iteration 23107: loss: 0.049178, loss_s1: 0.046254, loss_fp: 0.001459, loss_freq: 0.012670
[16:06:38.012] iteration 23108: loss: 0.044343, loss_s1: 0.013525, loss_fp: 0.002204, loss_freq: 0.022721
[16:06:38.655] iteration 23109: loss: 0.052899, loss_s1: 0.024040, loss_fp: 0.002389, loss_freq: 0.034841
[16:06:39.276] iteration 23110: loss: 0.046927, loss_s1: 0.030182, loss_fp: 0.002922, loss_freq: 0.025799
[16:06:39.900] iteration 23111: loss: 0.048781, loss_s1: 0.020457, loss_fp: 0.001610, loss_freq: 0.041034
[16:06:40.517] iteration 23112: loss: 0.048031, loss_s1: 0.048640, loss_fp: 0.000835, loss_freq: 0.016270
[16:06:41.244] iteration 23113: loss: 0.038858, loss_s1: 0.031140, loss_fp: 0.002940, loss_freq: 0.016285
[16:06:41.880] iteration 23114: loss: 0.044426, loss_s1: 0.013912, loss_fp: 0.004322, loss_freq: 0.024448
[16:06:42.509] iteration 23115: loss: 0.072124, loss_s1: 0.074589, loss_fp: 0.003527, loss_freq: 0.033882
[16:06:43.137] iteration 23116: loss: 0.041216, loss_s1: 0.033595, loss_fp: 0.002636, loss_freq: 0.012765
[16:06:43.768] iteration 23117: loss: 0.033039, loss_s1: 0.013990, loss_fp: 0.002793, loss_freq: 0.013592
[16:06:44.381] iteration 23118: loss: 0.028347, loss_s1: 0.006127, loss_fp: 0.001027, loss_freq: 0.011984
[16:06:45.011] iteration 23119: loss: 0.044030, loss_s1: 0.046424, loss_fp: 0.001333, loss_freq: 0.002703
[16:06:45.630] iteration 23120: loss: 0.071656, loss_s1: 0.047012, loss_fp: 0.002541, loss_freq: 0.039245
[16:06:46.246] iteration 23121: loss: 0.039537, loss_s1: 0.022336, loss_fp: 0.004148, loss_freq: 0.017273
[16:06:46.863] iteration 23122: loss: 0.060987, loss_s1: 0.048047, loss_fp: 0.001355, loss_freq: 0.012027
[16:06:47.485] iteration 23123: loss: 0.053103, loss_s1: 0.023560, loss_fp: 0.002394, loss_freq: 0.041449
[16:06:48.108] iteration 23124: loss: 0.056946, loss_s1: 0.068816, loss_fp: 0.005034, loss_freq: 0.004266
[16:06:48.724] iteration 23125: loss: 0.052649, loss_s1: 0.022227, loss_fp: 0.002456, loss_freq: 0.026502
[16:06:49.337] iteration 23126: loss: 0.083954, loss_s1: 0.086004, loss_fp: 0.006435, loss_freq: 0.044557
[16:06:49.958] iteration 23127: loss: 0.038096, loss_s1: 0.019165, loss_fp: 0.002824, loss_freq: 0.014384
[16:06:50.572] iteration 23128: loss: 0.071045, loss_s1: 0.050503, loss_fp: 0.002108, loss_freq: 0.019901
[16:06:51.189] iteration 23129: loss: 0.031683, loss_s1: 0.011858, loss_fp: 0.002144, loss_freq: 0.012108
[16:06:51.808] iteration 23130: loss: 0.066600, loss_s1: 0.044395, loss_fp: 0.008728, loss_freq: 0.032851
[16:06:52.440] iteration 23131: loss: 0.050993, loss_s1: 0.043016, loss_fp: 0.004805, loss_freq: 0.025675
[16:06:53.062] iteration 23132: loss: 0.074444, loss_s1: 0.056049, loss_fp: 0.012855, loss_freq: 0.036461
[16:06:53.683] iteration 23133: loss: 0.096442, loss_s1: 0.049979, loss_fp: 0.001090, loss_freq: 0.111162
[16:06:54.307] iteration 23134: loss: 0.045987, loss_s1: 0.046287, loss_fp: 0.000589, loss_freq: 0.010538
[16:06:54.920] iteration 23135: loss: 0.043381, loss_s1: 0.033281, loss_fp: 0.003543, loss_freq: 0.023342
[16:06:55.538] iteration 23136: loss: 0.039408, loss_s1: 0.023583, loss_fp: 0.000739, loss_freq: 0.005860
[16:06:56.154] iteration 23137: loss: 0.067387, loss_s1: 0.053515, loss_fp: 0.011834, loss_freq: 0.033405
[16:06:56.764] iteration 23138: loss: 0.064831, loss_s1: 0.029321, loss_fp: 0.001689, loss_freq: 0.006971
[16:06:57.383] iteration 23139: loss: 0.036401, loss_s1: 0.023641, loss_fp: 0.001143, loss_freq: 0.012413
[16:06:57.999] iteration 23140: loss: 0.065648, loss_s1: 0.041934, loss_fp: 0.002101, loss_freq: 0.040557
[16:06:58.615] iteration 23141: loss: 0.058610, loss_s1: 0.063954, loss_fp: 0.001102, loss_freq: 0.010202
[16:06:59.234] iteration 23142: loss: 0.056422, loss_s1: 0.050834, loss_fp: 0.002206, loss_freq: 0.031787
[16:06:59.857] iteration 23143: loss: 0.047523, loss_s1: 0.016165, loss_fp: 0.002004, loss_freq: 0.032860
[16:07:00.481] iteration 23144: loss: 0.045702, loss_s1: 0.029881, loss_fp: 0.001498, loss_freq: 0.028407
[16:07:01.090] iteration 23145: loss: 0.053078, loss_s1: 0.029877, loss_fp: 0.001684, loss_freq: 0.029348
[16:07:01.708] iteration 23146: loss: 0.034701, loss_s1: 0.026608, loss_fp: 0.001750, loss_freq: 0.008909
[16:07:02.329] iteration 23147: loss: 0.072741, loss_s1: 0.054600, loss_fp: 0.001345, loss_freq: 0.053990
[16:07:02.953] iteration 23148: loss: 0.087227, loss_s1: 0.075218, loss_fp: 0.005888, loss_freq: 0.059070
[16:07:03.576] iteration 23149: loss: 0.059972, loss_s1: 0.050002, loss_fp: 0.002227, loss_freq: 0.017935
[16:07:04.191] iteration 23150: loss: 0.036369, loss_s1: 0.013106, loss_fp: 0.001358, loss_freq: 0.017104
[16:07:04.815] iteration 23151: loss: 0.063459, loss_s1: 0.046588, loss_fp: 0.011337, loss_freq: 0.029917
[16:07:05.436] iteration 23152: loss: 0.062324, loss_s1: 0.056746, loss_fp: 0.005050, loss_freq: 0.005161
[16:07:06.054] iteration 23153: loss: 0.039045, loss_s1: 0.017166, loss_fp: 0.003380, loss_freq: 0.020102
[16:07:06.683] iteration 23154: loss: 0.046100, loss_s1: 0.013446, loss_fp: 0.004526, loss_freq: 0.025933
[16:07:07.300] iteration 23155: loss: 0.061500, loss_s1: 0.027611, loss_fp: 0.002711, loss_freq: 0.042472
[16:07:07.918] iteration 23156: loss: 0.052971, loss_s1: 0.037678, loss_fp: 0.002155, loss_freq: 0.013878
[16:07:08.541] iteration 23157: loss: 0.098286, loss_s1: 0.098357, loss_fp: 0.004917, loss_freq: 0.051193
[16:07:09.157] iteration 23158: loss: 0.052385, loss_s1: 0.037195, loss_fp: 0.004089, loss_freq: 0.023540
[16:07:09.772] iteration 23159: loss: 0.062092, loss_s1: 0.063019, loss_fp: 0.003024, loss_freq: 0.018216
[16:07:10.390] iteration 23160: loss: 0.070666, loss_s1: 0.047699, loss_fp: 0.007568, loss_freq: 0.038464
[16:07:11.003] iteration 23161: loss: 0.059394, loss_s1: 0.060745, loss_fp: 0.001643, loss_freq: 0.023249
[16:07:11.623] iteration 23162: loss: 0.048923, loss_s1: 0.037818, loss_fp: 0.002561, loss_freq: 0.007737
[16:07:12.239] iteration 23163: loss: 0.058786, loss_s1: 0.039615, loss_fp: 0.005938, loss_freq: 0.025979
[16:07:12.889] iteration 23164: loss: 0.058730, loss_s1: 0.058816, loss_fp: 0.002624, loss_freq: 0.019236
[16:07:13.512] iteration 23165: loss: 0.078803, loss_s1: 0.071683, loss_fp: 0.010150, loss_freq: 0.028661
[16:07:14.130] iteration 23166: loss: 0.024167, loss_s1: 0.007015, loss_fp: 0.000608, loss_freq: 0.009050
[16:07:15.108] iteration 23167: loss: 0.049350, loss_s1: 0.049169, loss_fp: 0.002665, loss_freq: 0.010324
[16:07:15.748] iteration 23168: loss: 0.050517, loss_s1: 0.038594, loss_fp: 0.002343, loss_freq: 0.021470
[16:07:16.372] iteration 23169: loss: 0.037927, loss_s1: 0.025020, loss_fp: 0.004490, loss_freq: 0.012200
[16:07:16.995] iteration 23170: loss: 0.047868, loss_s1: 0.025509, loss_fp: 0.005034, loss_freq: 0.019293
[16:07:17.612] iteration 23171: loss: 0.054547, loss_s1: 0.052130, loss_fp: 0.002847, loss_freq: 0.025392
[16:07:18.236] iteration 23172: loss: 0.037752, loss_s1: 0.010639, loss_fp: 0.004667, loss_freq: 0.008672
[16:07:18.857] iteration 23173: loss: 0.033615, loss_s1: 0.030142, loss_fp: 0.004126, loss_freq: 0.009005
[16:07:19.513] iteration 23174: loss: 0.105077, loss_s1: 0.078636, loss_fp: 0.006557, loss_freq: 0.081435
[16:07:20.138] iteration 23175: loss: 0.080741, loss_s1: 0.086150, loss_fp: 0.003827, loss_freq: 0.025909
[16:07:20.756] iteration 23176: loss: 0.056013, loss_s1: 0.016545, loss_fp: 0.000214, loss_freq: 0.020135
[16:07:21.372] iteration 23177: loss: 0.055716, loss_s1: 0.023529, loss_fp: 0.008817, loss_freq: 0.025210
[16:07:21.991] iteration 23178: loss: 0.041935, loss_s1: 0.015813, loss_fp: 0.003322, loss_freq: 0.016552
[16:07:22.699] iteration 23179: loss: 0.046913, loss_s1: 0.038114, loss_fp: 0.002497, loss_freq: 0.013547
[16:07:23.418] iteration 23180: loss: 0.034547, loss_s1: 0.026188, loss_fp: 0.001316, loss_freq: 0.014141
[16:07:24.129] iteration 23181: loss: 0.071186, loss_s1: 0.083201, loss_fp: 0.000752, loss_freq: 0.018467
[16:07:24.849] iteration 23182: loss: 0.051506, loss_s1: 0.032109, loss_fp: 0.002282, loss_freq: 0.015943
[16:07:25.470] iteration 23183: loss: 0.050567, loss_s1: 0.014801, loss_fp: 0.001457, loss_freq: 0.033878
[16:07:26.092] iteration 23184: loss: 0.048213, loss_s1: 0.034572, loss_fp: 0.003288, loss_freq: 0.023348
[16:07:26.714] iteration 23185: loss: 0.043784, loss_s1: 0.031403, loss_fp: 0.001102, loss_freq: 0.025895
[16:07:27.334] iteration 23186: loss: 0.039238, loss_s1: 0.025824, loss_fp: 0.001200, loss_freq: 0.015154
[16:07:27.967] iteration 23187: loss: 0.089324, loss_s1: 0.057644, loss_fp: 0.002523, loss_freq: 0.048773
[16:07:28.582] iteration 23188: loss: 0.039737, loss_s1: 0.016470, loss_fp: 0.000929, loss_freq: 0.018652
[16:07:29.204] iteration 23189: loss: 0.095064, loss_s1: 0.056793, loss_fp: 0.002106, loss_freq: 0.073857
[16:07:29.827] iteration 23190: loss: 0.051734, loss_s1: 0.065904, loss_fp: 0.002243, loss_freq: 0.006154
[16:07:30.445] iteration 23191: loss: 0.041761, loss_s1: 0.027884, loss_fp: 0.002125, loss_freq: 0.018389
[16:07:31.064] iteration 23192: loss: 0.077543, loss_s1: 0.037836, loss_fp: 0.006997, loss_freq: 0.067077
[16:07:31.686] iteration 23193: loss: 0.086852, loss_s1: 0.071625, loss_fp: 0.003672, loss_freq: 0.040463
[16:07:32.307] iteration 23194: loss: 0.036071, loss_s1: 0.022191, loss_fp: 0.003070, loss_freq: 0.008753
[16:07:32.938] iteration 23195: loss: 0.067992, loss_s1: 0.049002, loss_fp: 0.002899, loss_freq: 0.043201
[16:07:33.601] iteration 23196: loss: 0.047395, loss_s1: 0.038709, loss_fp: 0.002447, loss_freq: 0.017731
[16:07:34.225] iteration 23197: loss: 0.045875, loss_s1: 0.029452, loss_fp: 0.001578, loss_freq: 0.021381
[16:07:34.848] iteration 23198: loss: 0.050327, loss_s1: 0.025530, loss_fp: 0.005093, loss_freq: 0.014114
[16:07:35.469] iteration 23199: loss: 0.089429, loss_s1: 0.038678, loss_fp: 0.002266, loss_freq: 0.081327
[16:07:36.088] iteration 23200: loss: 0.085782, loss_s1: 0.084864, loss_fp: 0.008222, loss_freq: 0.038959
[16:07:39.561] iteration 23200 : mean_dice : 0.789590
[16:07:40.205] iteration 23201: loss: 0.084094, loss_s1: 0.048821, loss_fp: 0.005331, loss_freq: 0.030596
[16:07:40.830] iteration 23202: loss: 0.068043, loss_s1: 0.037345, loss_fp: 0.009411, loss_freq: 0.041756
[16:07:41.445] iteration 23203: loss: 0.051556, loss_s1: 0.041138, loss_fp: 0.002526, loss_freq: 0.018855
[16:07:42.059] iteration 23204: loss: 0.048130, loss_s1: 0.026997, loss_fp: 0.005265, loss_freq: 0.029942
[16:07:42.680] iteration 23205: loss: 0.076250, loss_s1: 0.041890, loss_fp: 0.004817, loss_freq: 0.045865
[16:07:43.321] iteration 23206: loss: 0.049396, loss_s1: 0.048092, loss_fp: 0.003177, loss_freq: 0.018089
[16:07:43.937] iteration 23207: loss: 0.092860, loss_s1: 0.060341, loss_fp: 0.002463, loss_freq: 0.015981
[16:07:44.565] iteration 23208: loss: 0.048824, loss_s1: 0.036901, loss_fp: 0.007457, loss_freq: 0.026214
[16:07:45.188] iteration 23209: loss: 0.055067, loss_s1: 0.032226, loss_fp: 0.005140, loss_freq: 0.016828
[16:07:45.811] iteration 23210: loss: 0.056177, loss_s1: 0.026221, loss_fp: 0.006322, loss_freq: 0.040378
[16:07:46.437] iteration 23211: loss: 0.053804, loss_s1: 0.014740, loss_fp: 0.003328, loss_freq: 0.021239
[16:07:47.062] iteration 23212: loss: 0.073936, loss_s1: 0.076764, loss_fp: 0.004702, loss_freq: 0.032483
[16:07:47.679] iteration 23213: loss: 0.052044, loss_s1: 0.039701, loss_fp: 0.012657, loss_freq: 0.017645
[16:07:48.303] iteration 23214: loss: 0.074114, loss_s1: 0.059997, loss_fp: 0.008935, loss_freq: 0.026184
[16:07:48.930] iteration 23215: loss: 0.069483, loss_s1: 0.068299, loss_fp: 0.007794, loss_freq: 0.032452
[16:07:49.568] iteration 23216: loss: 0.040795, loss_s1: 0.012317, loss_fp: 0.008296, loss_freq: 0.018819
[16:07:50.191] iteration 23217: loss: 0.039618, loss_s1: 0.014259, loss_fp: 0.000549, loss_freq: 0.014163
[16:07:50.819] iteration 23218: loss: 0.064550, loss_s1: 0.016511, loss_fp: 0.003374, loss_freq: 0.027973
[16:07:51.446] iteration 23219: loss: 0.030852, loss_s1: 0.013520, loss_fp: 0.003476, loss_freq: 0.006739
[16:07:52.075] iteration 23220: loss: 0.065114, loss_s1: 0.043440, loss_fp: 0.010031, loss_freq: 0.045010
[16:07:52.697] iteration 23221: loss: 0.038120, loss_s1: 0.033173, loss_fp: 0.003230, loss_freq: 0.007674
[16:07:53.324] iteration 23222: loss: 0.038468, loss_s1: 0.017617, loss_fp: 0.000887, loss_freq: 0.007673
[16:07:53.934] iteration 23223: loss: 0.085651, loss_s1: 0.092508, loss_fp: 0.002213, loss_freq: 0.041714
[16:07:54.551] iteration 23224: loss: 0.066617, loss_s1: 0.078259, loss_fp: 0.001845, loss_freq: 0.018232
[16:07:55.182] iteration 23225: loss: 0.091207, loss_s1: 0.038390, loss_fp: 0.007765, loss_freq: 0.062810
[16:07:55.805] iteration 23226: loss: 0.053165, loss_s1: 0.047989, loss_fp: 0.001216, loss_freq: 0.017096
[16:07:56.427] iteration 23227: loss: 0.044894, loss_s1: 0.025542, loss_fp: 0.002933, loss_freq: 0.023110
[16:07:57.047] iteration 23228: loss: 0.047805, loss_s1: 0.025985, loss_fp: 0.002553, loss_freq: 0.028175
[16:07:57.669] iteration 23229: loss: 0.048310, loss_s1: 0.038914, loss_fp: 0.003967, loss_freq: 0.021951
[16:07:58.294] iteration 23230: loss: 0.044228, loss_s1: 0.026531, loss_fp: 0.001337, loss_freq: 0.026425
[16:07:58.906] iteration 23231: loss: 0.068524, loss_s1: 0.057042, loss_fp: 0.002756, loss_freq: 0.022426
[16:07:59.540] iteration 23232: loss: 0.056868, loss_s1: 0.040607, loss_fp: 0.003780, loss_freq: 0.016213
[16:08:00.154] iteration 23233: loss: 0.084110, loss_s1: 0.077322, loss_fp: 0.006502, loss_freq: 0.033156
[16:08:00.772] iteration 23234: loss: 0.035779, loss_s1: 0.026691, loss_fp: 0.001884, loss_freq: 0.010561
[16:08:01.399] iteration 23235: loss: 0.040714, loss_s1: 0.031841, loss_fp: 0.001629, loss_freq: 0.011352
[16:08:02.031] iteration 23236: loss: 0.047607, loss_s1: 0.032340, loss_fp: 0.001637, loss_freq: 0.005967
[16:08:02.656] iteration 23237: loss: 0.035413, loss_s1: 0.016856, loss_fp: 0.001769, loss_freq: 0.018815
[16:08:03.271] iteration 23238: loss: 0.057874, loss_s1: 0.014614, loss_fp: 0.003156, loss_freq: 0.036144
[16:08:03.942] iteration 23239: loss: 0.052216, loss_s1: 0.020824, loss_fp: 0.016371, loss_freq: 0.032950
[16:08:04.655] iteration 23240: loss: 0.065964, loss_s1: 0.042261, loss_fp: 0.008349, loss_freq: 0.020987
[16:08:05.325] iteration 23241: loss: 0.043292, loss_s1: 0.016795, loss_fp: 0.002138, loss_freq: 0.024160
[16:08:05.966] iteration 23242: loss: 0.065897, loss_s1: 0.027165, loss_fp: 0.001205, loss_freq: 0.011468
[16:08:06.589] iteration 23243: loss: 0.036956, loss_s1: 0.029267, loss_fp: 0.001116, loss_freq: 0.014201
[16:08:07.204] iteration 23244: loss: 0.060675, loss_s1: 0.016570, loss_fp: 0.004132, loss_freq: 0.014296
[16:08:07.875] iteration 23245: loss: 0.062763, loss_s1: 0.047489, loss_fp: 0.007211, loss_freq: 0.022919
[16:08:08.535] iteration 23246: loss: 0.092923, loss_s1: 0.049850, loss_fp: 0.014225, loss_freq: 0.038593
[16:08:09.154] iteration 23247: loss: 0.043797, loss_s1: 0.021932, loss_fp: 0.002475, loss_freq: 0.023525
[16:08:09.806] iteration 23248: loss: 0.046592, loss_s1: 0.047121, loss_fp: 0.000872, loss_freq: 0.012310
[16:08:10.424] iteration 23249: loss: 0.040949, loss_s1: 0.013767, loss_fp: 0.002764, loss_freq: 0.023849
[16:08:11.037] iteration 23250: loss: 0.033739, loss_s1: 0.021744, loss_fp: 0.002448, loss_freq: 0.014217
[16:08:11.648] iteration 23251: loss: 0.048940, loss_s1: 0.019308, loss_fp: 0.004927, loss_freq: 0.025534
[16:08:12.277] iteration 23252: loss: 0.067937, loss_s1: 0.050841, loss_fp: 0.007504, loss_freq: 0.029691
[16:08:12.896] iteration 23253: loss: 0.042506, loss_s1: 0.034395, loss_fp: 0.005283, loss_freq: 0.007004
[16:08:13.530] iteration 23254: loss: 0.032179, loss_s1: 0.013199, loss_fp: 0.002197, loss_freq: 0.005115
[16:08:14.146] iteration 23255: loss: 0.058945, loss_s1: 0.076140, loss_fp: 0.001154, loss_freq: 0.012071
[16:08:14.761] iteration 23256: loss: 0.051595, loss_s1: 0.023892, loss_fp: 0.003278, loss_freq: 0.047311
[16:08:15.382] iteration 23257: loss: 0.056026, loss_s1: 0.038213, loss_fp: 0.002530, loss_freq: 0.024906
[16:08:16.013] iteration 23258: loss: 0.054062, loss_s1: 0.037616, loss_fp: 0.008388, loss_freq: 0.031153
[16:08:16.639] iteration 23259: loss: 0.044377, loss_s1: 0.039053, loss_fp: 0.001980, loss_freq: 0.002786
[16:08:17.260] iteration 23260: loss: 0.060270, loss_s1: 0.065581, loss_fp: 0.004564, loss_freq: 0.004584
[16:08:17.935] iteration 23261: loss: 0.055871, loss_s1: 0.050468, loss_fp: 0.002770, loss_freq: 0.014312
[16:08:18.576] iteration 23262: loss: 0.036833, loss_s1: 0.014546, loss_fp: 0.001311, loss_freq: 0.005591
[16:08:19.248] iteration 23263: loss: 0.063280, loss_s1: 0.039580, loss_fp: 0.003237, loss_freq: 0.037135
[16:08:19.883] iteration 23264: loss: 0.041376, loss_s1: 0.019779, loss_fp: 0.001957, loss_freq: 0.020119
[16:08:20.522] iteration 23265: loss: 0.062246, loss_s1: 0.052209, loss_fp: 0.002617, loss_freq: 0.024202
[16:08:21.164] iteration 23266: loss: 0.165406, loss_s1: 0.107123, loss_fp: 0.005145, loss_freq: 0.068472
[16:08:21.800] iteration 23267: loss: 0.041351, loss_s1: 0.031051, loss_fp: 0.001850, loss_freq: 0.012363
[16:08:22.415] iteration 23268: loss: 0.049040, loss_s1: 0.021526, loss_fp: 0.006986, loss_freq: 0.013929
[16:08:23.035] iteration 23269: loss: 0.062740, loss_s1: 0.032449, loss_fp: 0.005959, loss_freq: 0.037632
[16:08:23.652] iteration 23270: loss: 0.047694, loss_s1: 0.026103, loss_fp: 0.003682, loss_freq: 0.025056
[16:08:24.274] iteration 23271: loss: 0.057910, loss_s1: 0.045113, loss_fp: 0.001419, loss_freq: 0.014883
[16:08:24.893] iteration 23272: loss: 0.041038, loss_s1: 0.014122, loss_fp: 0.002949, loss_freq: 0.028442
[16:08:25.514] iteration 23273: loss: 0.062992, loss_s1: 0.041582, loss_fp: 0.011810, loss_freq: 0.032341
[16:08:26.135] iteration 23274: loss: 0.094422, loss_s1: 0.053818, loss_fp: 0.015755, loss_freq: 0.083447
[16:08:26.760] iteration 23275: loss: 0.056508, loss_s1: 0.035565, loss_fp: 0.003025, loss_freq: 0.023666
[16:08:27.378] iteration 23276: loss: 0.055692, loss_s1: 0.048537, loss_fp: 0.002157, loss_freq: 0.033314
[16:08:27.996] iteration 23277: loss: 0.066326, loss_s1: 0.041537, loss_fp: 0.007802, loss_freq: 0.023448
[16:08:28.608] iteration 23278: loss: 0.064599, loss_s1: 0.033447, loss_fp: 0.003493, loss_freq: 0.036043
[16:08:29.229] iteration 23279: loss: 0.047532, loss_s1: 0.038866, loss_fp: 0.001833, loss_freq: 0.010056
[16:08:29.844] iteration 23280: loss: 0.057835, loss_s1: 0.035832, loss_fp: 0.002742, loss_freq: 0.045015
[16:08:30.471] iteration 23281: loss: 0.079305, loss_s1: 0.057029, loss_fp: 0.002100, loss_freq: 0.049843
[16:08:31.086] iteration 23282: loss: 0.043014, loss_s1: 0.030925, loss_fp: 0.003444, loss_freq: 0.014185
[16:08:31.700] iteration 23283: loss: 0.065564, loss_s1: 0.028422, loss_fp: 0.001222, loss_freq: 0.047622
[16:08:32.355] iteration 23284: loss: 0.056267, loss_s1: 0.044779, loss_fp: 0.004977, loss_freq: 0.023799
[16:08:32.980] iteration 23285: loss: 0.043708, loss_s1: 0.032841, loss_fp: 0.000667, loss_freq: 0.022649
[16:08:33.595] iteration 23286: loss: 0.041487, loss_s1: 0.026553, loss_fp: 0.001904, loss_freq: 0.023176
[16:08:34.230] iteration 23287: loss: 0.064755, loss_s1: 0.035529, loss_fp: 0.000617, loss_freq: 0.056013
[16:08:34.876] iteration 23288: loss: 0.073977, loss_s1: 0.057307, loss_fp: 0.017723, loss_freq: 0.023311
[16:08:35.524] iteration 23289: loss: 0.026625, loss_s1: 0.014548, loss_fp: 0.001178, loss_freq: 0.003249
[16:08:36.154] iteration 23290: loss: 0.059149, loss_s1: 0.037333, loss_fp: 0.006727, loss_freq: 0.048262
[16:08:36.780] iteration 23291: loss: 0.095597, loss_s1: 0.093709, loss_fp: 0.005593, loss_freq: 0.052484
[16:08:37.400] iteration 23292: loss: 0.036505, loss_s1: 0.011524, loss_fp: 0.004968, loss_freq: 0.009660
[16:08:38.028] iteration 23293: loss: 0.052758, loss_s1: 0.039761, loss_fp: 0.001174, loss_freq: 0.016640
[16:08:38.646] iteration 23294: loss: 0.037739, loss_s1: 0.021071, loss_fp: 0.001749, loss_freq: 0.020349
[16:08:39.264] iteration 23295: loss: 0.067930, loss_s1: 0.047103, loss_fp: 0.010789, loss_freq: 0.016853
[16:08:39.884] iteration 23296: loss: 0.042935, loss_s1: 0.017563, loss_fp: 0.001661, loss_freq: 0.013984
[16:08:40.505] iteration 23297: loss: 0.055088, loss_s1: 0.036426, loss_fp: 0.002521, loss_freq: 0.016387
[16:08:41.126] iteration 23298: loss: 0.063415, loss_s1: 0.045879, loss_fp: 0.004733, loss_freq: 0.031354
[16:08:41.749] iteration 23299: loss: 0.050953, loss_s1: 0.043943, loss_fp: 0.002254, loss_freq: 0.015636
[16:08:42.372] iteration 23300: loss: 0.089739, loss_s1: 0.087901, loss_fp: 0.002296, loss_freq: 0.049452
[16:08:43.043] iteration 23301: loss: 0.056367, loss_s1: 0.022133, loss_fp: 0.001714, loss_freq: 0.027080
[16:08:43.676] iteration 23302: loss: 0.057512, loss_s1: 0.047220, loss_fp: 0.003919, loss_freq: 0.016123
[16:08:44.326] iteration 23303: loss: 0.082906, loss_s1: 0.053382, loss_fp: 0.006112, loss_freq: 0.051722
[16:08:44.961] iteration 23304: loss: 0.024969, loss_s1: 0.006279, loss_fp: 0.001165, loss_freq: 0.007751
[16:08:45.584] iteration 23305: loss: 0.049874, loss_s1: 0.030914, loss_fp: 0.000384, loss_freq: 0.027290
[16:08:46.212] iteration 23306: loss: 0.039228, loss_s1: 0.025137, loss_fp: 0.003187, loss_freq: 0.007210
[16:08:46.829] iteration 23307: loss: 0.054601, loss_s1: 0.040251, loss_fp: 0.002271, loss_freq: 0.028817
[16:08:47.443] iteration 23308: loss: 0.106261, loss_s1: 0.088604, loss_fp: 0.016171, loss_freq: 0.064979
[16:08:48.075] iteration 23309: loss: 0.036641, loss_s1: 0.013781, loss_fp: 0.002320, loss_freq: 0.029661
[16:08:49.066] iteration 23310: loss: 0.055424, loss_s1: 0.043839, loss_fp: 0.001951, loss_freq: 0.022845
[16:08:49.712] iteration 23311: loss: 0.058747, loss_s1: 0.048983, loss_fp: 0.002298, loss_freq: 0.019967
[16:08:50.355] iteration 23312: loss: 0.047422, loss_s1: 0.038374, loss_fp: 0.001563, loss_freq: 0.026500
[16:08:51.002] iteration 23313: loss: 0.066836, loss_s1: 0.027269, loss_fp: 0.003270, loss_freq: 0.040470
[16:08:51.626] iteration 23314: loss: 0.041998, loss_s1: 0.025085, loss_fp: 0.001478, loss_freq: 0.027079
[16:08:52.244] iteration 23315: loss: 0.040883, loss_s1: 0.028491, loss_fp: 0.002000, loss_freq: 0.005488
[16:08:52.860] iteration 23316: loss: 0.049520, loss_s1: 0.033277, loss_fp: 0.001136, loss_freq: 0.034824
[16:08:53.483] iteration 23317: loss: 0.043051, loss_s1: 0.032651, loss_fp: 0.003544, loss_freq: 0.006040
[16:08:54.104] iteration 23318: loss: 0.065889, loss_s1: 0.063259, loss_fp: 0.012841, loss_freq: 0.015871
[16:08:54.739] iteration 23319: loss: 0.070588, loss_s1: 0.047001, loss_fp: 0.001239, loss_freq: 0.006924
[16:08:55.372] iteration 23320: loss: 0.063030, loss_s1: 0.047077, loss_fp: 0.004845, loss_freq: 0.036423
[16:08:56.021] iteration 23321: loss: 0.043332, loss_s1: 0.018651, loss_fp: 0.002816, loss_freq: 0.012269
[16:08:56.657] iteration 23322: loss: 0.053832, loss_s1: 0.045794, loss_fp: 0.003556, loss_freq: 0.012837
[16:08:57.275] iteration 23323: loss: 0.053777, loss_s1: 0.034106, loss_fp: 0.003873, loss_freq: 0.024748
[16:08:57.898] iteration 23324: loss: 0.058738, loss_s1: 0.059714, loss_fp: 0.001394, loss_freq: 0.019871
[16:08:58.519] iteration 23325: loss: 0.037463, loss_s1: 0.014408, loss_fp: 0.004919, loss_freq: 0.022684
[16:08:59.187] iteration 23326: loss: 0.057483, loss_s1: 0.044532, loss_fp: 0.000624, loss_freq: 0.026238
[16:08:59.803] iteration 23327: loss: 0.050948, loss_s1: 0.038022, loss_fp: 0.007246, loss_freq: 0.013486
[16:09:00.422] iteration 23328: loss: 0.034201, loss_s1: 0.016781, loss_fp: 0.003421, loss_freq: 0.019779
[16:09:01.051] iteration 23329: loss: 0.035258, loss_s1: 0.027939, loss_fp: 0.003919, loss_freq: 0.010680
[16:09:01.662] iteration 23330: loss: 0.073782, loss_s1: 0.029931, loss_fp: 0.001915, loss_freq: 0.055263
[16:09:02.282] iteration 23331: loss: 0.052889, loss_s1: 0.052032, loss_fp: 0.001635, loss_freq: 0.017861
[16:09:02.913] iteration 23332: loss: 0.060591, loss_s1: 0.034203, loss_fp: 0.007894, loss_freq: 0.042901
[16:09:03.596] iteration 23333: loss: 0.043523, loss_s1: 0.014879, loss_fp: 0.003207, loss_freq: 0.009091
[16:09:04.244] iteration 23334: loss: 0.048971, loss_s1: 0.028618, loss_fp: 0.001985, loss_freq: 0.020420
[16:09:04.887] iteration 23335: loss: 0.066683, loss_s1: 0.038460, loss_fp: 0.028265, loss_freq: 0.032462
[16:09:05.526] iteration 23336: loss: 0.066192, loss_s1: 0.043391, loss_fp: 0.003684, loss_freq: 0.043610
[16:09:06.161] iteration 23337: loss: 0.047741, loss_s1: 0.043550, loss_fp: 0.002419, loss_freq: 0.015882
[16:09:06.785] iteration 23338: loss: 0.047652, loss_s1: 0.034235, loss_fp: 0.003336, loss_freq: 0.015346
[16:09:07.407] iteration 23339: loss: 0.036657, loss_s1: 0.019837, loss_fp: 0.002785, loss_freq: 0.004566
[16:09:08.027] iteration 23340: loss: 0.037763, loss_s1: 0.026496, loss_fp: 0.002196, loss_freq: 0.005153
[16:09:08.649] iteration 23341: loss: 0.044322, loss_s1: 0.021146, loss_fp: 0.003480, loss_freq: 0.018606
[16:09:09.331] iteration 23342: loss: 0.067629, loss_s1: 0.053518, loss_fp: 0.011344, loss_freq: 0.039926
[16:09:09.968] iteration 23343: loss: 0.109987, loss_s1: 0.097488, loss_fp: 0.003927, loss_freq: 0.083627
[16:09:10.605] iteration 23344: loss: 0.039514, loss_s1: 0.018743, loss_fp: 0.005840, loss_freq: 0.014497
[16:09:11.234] iteration 23345: loss: 0.056105, loss_s1: 0.049603, loss_fp: 0.002824, loss_freq: 0.017310
[16:09:11.871] iteration 23346: loss: 0.067149, loss_s1: 0.057401, loss_fp: 0.005560, loss_freq: 0.024850
[16:09:12.500] iteration 23347: loss: 0.045995, loss_s1: 0.028370, loss_fp: 0.008340, loss_freq: 0.022380
[16:09:13.124] iteration 23348: loss: 0.071369, loss_s1: 0.047770, loss_fp: 0.007620, loss_freq: 0.040702
[16:09:13.750] iteration 23349: loss: 0.038885, loss_s1: 0.020781, loss_fp: 0.006261, loss_freq: 0.011091
[16:09:14.375] iteration 23350: loss: 0.041844, loss_s1: 0.018473, loss_fp: 0.005938, loss_freq: 0.023140
[16:09:14.989] iteration 23351: loss: 0.036594, loss_s1: 0.019520, loss_fp: 0.006426, loss_freq: 0.018386
[16:09:15.610] iteration 23352: loss: 0.040700, loss_s1: 0.021302, loss_fp: 0.007219, loss_freq: 0.016139
[16:09:16.233] iteration 23353: loss: 0.067154, loss_s1: 0.052585, loss_fp: 0.008080, loss_freq: 0.027394
[16:09:16.853] iteration 23354: loss: 0.053133, loss_s1: 0.022683, loss_fp: 0.002047, loss_freq: 0.018615
[16:09:17.465] iteration 23355: loss: 0.064586, loss_s1: 0.049756, loss_fp: 0.005836, loss_freq: 0.036455
[16:09:18.083] iteration 23356: loss: 0.057399, loss_s1: 0.025333, loss_fp: 0.004342, loss_freq: 0.041323
[16:09:18.700] iteration 23357: loss: 0.066208, loss_s1: 0.047403, loss_fp: 0.002967, loss_freq: 0.031220
[16:09:19.325] iteration 23358: loss: 0.058500, loss_s1: 0.027331, loss_fp: 0.013363, loss_freq: 0.044574
[16:09:19.948] iteration 23359: loss: 0.044989, loss_s1: 0.040748, loss_fp: 0.003219, loss_freq: 0.004099
[16:09:20.563] iteration 23360: loss: 0.059566, loss_s1: 0.034208, loss_fp: 0.007896, loss_freq: 0.037471
[16:09:21.176] iteration 23361: loss: 0.051161, loss_s1: 0.020659, loss_fp: 0.002381, loss_freq: 0.032307
[16:09:21.800] iteration 23362: loss: 0.040586, loss_s1: 0.016382, loss_fp: 0.001696, loss_freq: 0.017502
[16:09:22.419] iteration 23363: loss: 0.049030, loss_s1: 0.040734, loss_fp: 0.004013, loss_freq: 0.024803
[16:09:23.037] iteration 23364: loss: 0.048116, loss_s1: 0.054010, loss_fp: 0.002719, loss_freq: 0.008519
[16:09:23.654] iteration 23365: loss: 0.065499, loss_s1: 0.019223, loss_fp: 0.001823, loss_freq: 0.029278
[16:09:24.271] iteration 23366: loss: 0.070201, loss_s1: 0.072198, loss_fp: 0.001923, loss_freq: 0.031375
[16:09:24.896] iteration 23367: loss: 0.055525, loss_s1: 0.043831, loss_fp: 0.005070, loss_freq: 0.025984
[16:09:25.510] iteration 23368: loss: 0.065845, loss_s1: 0.026642, loss_fp: 0.001807, loss_freq: 0.067414
[16:09:26.123] iteration 23369: loss: 0.040077, loss_s1: 0.022461, loss_fp: 0.001061, loss_freq: 0.015281
[16:09:26.747] iteration 23370: loss: 0.062399, loss_s1: 0.035633, loss_fp: 0.005368, loss_freq: 0.010063
[16:09:27.361] iteration 23371: loss: 0.039989, loss_s1: 0.028842, loss_fp: 0.001134, loss_freq: 0.007474
[16:09:27.977] iteration 23372: loss: 0.086069, loss_s1: 0.064410, loss_fp: 0.014846, loss_freq: 0.053936
[16:09:28.649] iteration 23373: loss: 0.046917, loss_s1: 0.014970, loss_fp: 0.000651, loss_freq: 0.028253
[16:09:29.288] iteration 23374: loss: 0.097344, loss_s1: 0.039310, loss_fp: 0.009821, loss_freq: 0.093154
[16:09:29.936] iteration 23375: loss: 0.038296, loss_s1: 0.030254, loss_fp: 0.001488, loss_freq: 0.014865
[16:09:30.601] iteration 23376: loss: 0.075890, loss_s1: 0.043327, loss_fp: 0.016740, loss_freq: 0.038215
[16:09:31.283] iteration 23377: loss: 0.095903, loss_s1: 0.079247, loss_fp: 0.001584, loss_freq: 0.015262
[16:09:31.893] iteration 23378: loss: 0.062096, loss_s1: 0.068714, loss_fp: 0.002910, loss_freq: 0.010799
[16:09:32.515] iteration 23379: loss: 0.037509, loss_s1: 0.022382, loss_fp: 0.004919, loss_freq: 0.008330
[16:09:33.132] iteration 23380: loss: 0.056810, loss_s1: 0.057359, loss_fp: 0.003727, loss_freq: 0.011212
[16:09:33.749] iteration 23381: loss: 0.061172, loss_s1: 0.034404, loss_fp: 0.001929, loss_freq: 0.023141
[16:09:34.362] iteration 23382: loss: 0.076787, loss_s1: 0.056708, loss_fp: 0.000909, loss_freq: 0.065501
[16:09:34.978] iteration 23383: loss: 0.065252, loss_s1: 0.041949, loss_fp: 0.009091, loss_freq: 0.030487
[16:09:35.594] iteration 23384: loss: 0.076808, loss_s1: 0.051484, loss_fp: 0.005630, loss_freq: 0.070540
[16:09:36.238] iteration 23385: loss: 0.057293, loss_s1: 0.062513, loss_fp: 0.001542, loss_freq: 0.014966
[16:09:36.910] iteration 23386: loss: 0.045938, loss_s1: 0.025814, loss_fp: 0.006928, loss_freq: 0.030535
[16:09:37.561] iteration 23387: loss: 0.042622, loss_s1: 0.017382, loss_fp: 0.003838, loss_freq: 0.025583
[16:09:38.196] iteration 23388: loss: 0.080304, loss_s1: 0.052588, loss_fp: 0.009234, loss_freq: 0.056676
[16:09:38.824] iteration 23389: loss: 0.105405, loss_s1: 0.072228, loss_fp: 0.017072, loss_freq: 0.028544
[16:09:39.440] iteration 23390: loss: 0.075198, loss_s1: 0.076372, loss_fp: 0.001885, loss_freq: 0.028255
[16:09:40.060] iteration 23391: loss: 0.059103, loss_s1: 0.031948, loss_fp: 0.010725, loss_freq: 0.022123
[16:09:40.687] iteration 23392: loss: 0.040489, loss_s1: 0.026912, loss_fp: 0.000907, loss_freq: 0.009761
[16:09:41.309] iteration 23393: loss: 0.073099, loss_s1: 0.037590, loss_fp: 0.020315, loss_freq: 0.053281
[16:09:41.927] iteration 23394: loss: 0.066180, loss_s1: 0.068171, loss_fp: 0.006434, loss_freq: 0.023158
[16:09:42.546] iteration 23395: loss: 0.059258, loss_s1: 0.024388, loss_fp: 0.003755, loss_freq: 0.046204
[16:09:43.162] iteration 23396: loss: 0.036573, loss_s1: 0.018110, loss_fp: 0.000324, loss_freq: 0.012053
[16:09:43.777] iteration 23397: loss: 0.038305, loss_s1: 0.024389, loss_fp: 0.002264, loss_freq: 0.010377
[16:09:44.401] iteration 23398: loss: 0.036737, loss_s1: 0.026709, loss_fp: 0.002474, loss_freq: 0.015951
[16:09:45.021] iteration 23399: loss: 0.057461, loss_s1: 0.058375, loss_fp: 0.004271, loss_freq: 0.021738
[16:09:45.640] iteration 23400: loss: 0.056429, loss_s1: 0.025790, loss_fp: 0.006277, loss_freq: 0.016685
[16:09:48.934] iteration 23400 : mean_dice : 0.790053
[16:09:49.584] iteration 23401: loss: 0.064090, loss_s1: 0.047449, loss_fp: 0.027562, loss_freq: 0.014782
[16:09:50.201] iteration 23402: loss: 0.037375, loss_s1: 0.029802, loss_fp: 0.003799, loss_freq: 0.007118
[16:09:50.821] iteration 23403: loss: 0.043991, loss_s1: 0.047775, loss_fp: 0.001015, loss_freq: 0.008077
[16:09:51.474] iteration 23404: loss: 0.070098, loss_s1: 0.079505, loss_fp: 0.001336, loss_freq: 0.017325
[16:09:52.087] iteration 23405: loss: 0.038217, loss_s1: 0.018063, loss_fp: 0.000999, loss_freq: 0.017050
[16:09:52.696] iteration 23406: loss: 0.071886, loss_s1: 0.052615, loss_fp: 0.001757, loss_freq: 0.048552
[16:09:53.305] iteration 23407: loss: 0.043464, loss_s1: 0.031836, loss_fp: 0.001010, loss_freq: 0.017957
[16:09:53.926] iteration 23408: loss: 0.029714, loss_s1: 0.005075, loss_fp: 0.001569, loss_freq: 0.003872
[16:09:54.543] iteration 23409: loss: 0.094741, loss_s1: 0.098113, loss_fp: 0.001705, loss_freq: 0.043256
[16:09:55.161] iteration 23410: loss: 0.061851, loss_s1: 0.052791, loss_fp: 0.010628, loss_freq: 0.021636
[16:09:55.778] iteration 23411: loss: 0.046233, loss_s1: 0.028180, loss_fp: 0.002533, loss_freq: 0.018957
[16:09:56.399] iteration 23412: loss: 0.087565, loss_s1: 0.094265, loss_fp: 0.004248, loss_freq: 0.046321
[16:09:57.008] iteration 23413: loss: 0.030353, loss_s1: 0.017869, loss_fp: 0.000683, loss_freq: 0.007695
[16:09:57.624] iteration 23414: loss: 0.056721, loss_s1: 0.044659, loss_fp: 0.003040, loss_freq: 0.010561
[16:09:58.241] iteration 23415: loss: 0.054518, loss_s1: 0.034117, loss_fp: 0.002428, loss_freq: 0.033045
[16:09:58.855] iteration 23416: loss: 0.064286, loss_s1: 0.040267, loss_fp: 0.007910, loss_freq: 0.039490
[16:09:59.471] iteration 23417: loss: 0.057160, loss_s1: 0.051605, loss_fp: 0.002089, loss_freq: 0.022329
[16:10:00.086] iteration 23418: loss: 0.051481, loss_s1: 0.034760, loss_fp: 0.009044, loss_freq: 0.020997
[16:10:00.702] iteration 23419: loss: 0.082918, loss_s1: 0.070627, loss_fp: 0.006237, loss_freq: 0.057335
[16:10:01.319] iteration 23420: loss: 0.044421, loss_s1: 0.030038, loss_fp: 0.007926, loss_freq: 0.016084
[16:10:01.933] iteration 23421: loss: 0.047298, loss_s1: 0.026887, loss_fp: 0.002196, loss_freq: 0.027889
[16:10:02.551] iteration 23422: loss: 0.052199, loss_s1: 0.024328, loss_fp: 0.001033, loss_freq: 0.010405
[16:10:03.165] iteration 23423: loss: 0.063412, loss_s1: 0.065250, loss_fp: 0.004774, loss_freq: 0.018952
[16:10:03.781] iteration 23424: loss: 0.052419, loss_s1: 0.026204, loss_fp: 0.004544, loss_freq: 0.014100
[16:10:04.391] iteration 23425: loss: 0.053556, loss_s1: 0.044329, loss_fp: 0.001436, loss_freq: 0.022493
[16:10:05.001] iteration 23426: loss: 0.059298, loss_s1: 0.033167, loss_fp: 0.007771, loss_freq: 0.033423
[16:10:05.620] iteration 23427: loss: 0.055698, loss_s1: 0.056239, loss_fp: 0.005351, loss_freq: 0.016492
[16:10:06.244] iteration 23428: loss: 0.044082, loss_s1: 0.033550, loss_fp: 0.001165, loss_freq: 0.021637
[16:10:06.857] iteration 23429: loss: 0.064896, loss_s1: 0.043392, loss_fp: 0.001251, loss_freq: 0.042370
[16:10:07.474] iteration 23430: loss: 0.079758, loss_s1: 0.056994, loss_fp: 0.002526, loss_freq: 0.054212
[16:10:08.097] iteration 23431: loss: 0.043279, loss_s1: 0.026472, loss_fp: 0.003464, loss_freq: 0.017382
[16:10:08.714] iteration 23432: loss: 0.029187, loss_s1: 0.015531, loss_fp: 0.002274, loss_freq: 0.010238
[16:10:09.331] iteration 23433: loss: 0.038162, loss_s1: 0.029812, loss_fp: 0.002485, loss_freq: 0.016169
[16:10:09.946] iteration 23434: loss: 0.074622, loss_s1: 0.068990, loss_fp: 0.006159, loss_freq: 0.047460
[16:10:10.567] iteration 23435: loss: 0.037642, loss_s1: 0.018184, loss_fp: 0.002285, loss_freq: 0.014265
[16:10:11.183] iteration 23436: loss: 0.060976, loss_s1: 0.060673, loss_fp: 0.001647, loss_freq: 0.023318
[16:10:11.799] iteration 23437: loss: 0.034358, loss_s1: 0.012289, loss_fp: 0.007840, loss_freq: 0.017035
[16:10:12.417] iteration 23438: loss: 0.050035, loss_s1: 0.044136, loss_fp: 0.001178, loss_freq: 0.007941
[16:10:13.035] iteration 23439: loss: 0.044924, loss_s1: 0.035644, loss_fp: 0.002392, loss_freq: 0.009657
[16:10:13.655] iteration 23440: loss: 0.052814, loss_s1: 0.046488, loss_fp: 0.003147, loss_freq: 0.008948
[16:10:14.272] iteration 23441: loss: 0.089373, loss_s1: 0.041607, loss_fp: 0.006119, loss_freq: 0.039112
[16:10:14.888] iteration 23442: loss: 0.045458, loss_s1: 0.038723, loss_fp: 0.002147, loss_freq: 0.019734
[16:10:15.496] iteration 23443: loss: 0.070484, loss_s1: 0.044875, loss_fp: 0.003270, loss_freq: 0.047697
[16:10:16.114] iteration 23444: loss: 0.062542, loss_s1: 0.034708, loss_fp: 0.002128, loss_freq: 0.051794
[16:10:16.731] iteration 23445: loss: 0.039383, loss_s1: 0.030946, loss_fp: 0.003258, loss_freq: 0.012786
[16:10:17.342] iteration 23446: loss: 0.088053, loss_s1: 0.048851, loss_fp: 0.007461, loss_freq: 0.019784
[16:10:17.956] iteration 23447: loss: 0.038522, loss_s1: 0.034609, loss_fp: 0.001484, loss_freq: 0.008527
[16:10:18.576] iteration 23448: loss: 0.051677, loss_s1: 0.043431, loss_fp: 0.001699, loss_freq: 0.020561
[16:10:19.186] iteration 23449: loss: 0.047340, loss_s1: 0.027920, loss_fp: 0.002256, loss_freq: 0.017638
[16:10:19.811] iteration 23450: loss: 0.058057, loss_s1: 0.056027, loss_fp: 0.003861, loss_freq: 0.018899
[16:10:20.423] iteration 23451: loss: 0.064511, loss_s1: 0.058438, loss_fp: 0.001018, loss_freq: 0.027980
[16:10:21.039] iteration 23452: loss: 0.055318, loss_s1: 0.043632, loss_fp: 0.003572, loss_freq: 0.028701
[16:10:22.002] iteration 23453: loss: 0.041022, loss_s1: 0.019936, loss_fp: 0.006204, loss_freq: 0.013359
[16:10:22.638] iteration 23454: loss: 0.050502, loss_s1: 0.035170, loss_fp: 0.001486, loss_freq: 0.015858
[16:10:23.263] iteration 23455: loss: 0.047281, loss_s1: 0.038650, loss_fp: 0.003816, loss_freq: 0.019566
[16:10:23.880] iteration 23456: loss: 0.060980, loss_s1: 0.039096, loss_fp: 0.009525, loss_freq: 0.026183
[16:10:24.509] iteration 23457: loss: 0.047626, loss_s1: 0.043669, loss_fp: 0.002789, loss_freq: 0.020874
[16:10:25.129] iteration 23458: loss: 0.033311, loss_s1: 0.019317, loss_fp: 0.000902, loss_freq: 0.006134
[16:10:25.842] iteration 23459: loss: 0.027397, loss_s1: 0.008668, loss_fp: 0.001401, loss_freq: 0.014446
[16:10:26.458] iteration 23460: loss: 0.057129, loss_s1: 0.031177, loss_fp: 0.004144, loss_freq: 0.027366
[16:10:27.118] iteration 23461: loss: 0.048854, loss_s1: 0.034233, loss_fp: 0.003558, loss_freq: 0.013919
[16:10:27.849] iteration 23462: loss: 0.044156, loss_s1: 0.027270, loss_fp: 0.002136, loss_freq: 0.007086
[16:10:28.474] iteration 23463: loss: 0.065211, loss_s1: 0.037586, loss_fp: 0.009914, loss_freq: 0.031993
[16:10:29.099] iteration 23464: loss: 0.058526, loss_s1: 0.047579, loss_fp: 0.003446, loss_freq: 0.020008
[16:10:29.775] iteration 23465: loss: 0.051803, loss_s1: 0.039382, loss_fp: 0.003455, loss_freq: 0.022552
[16:10:30.460] iteration 23466: loss: 0.041605, loss_s1: 0.026743, loss_fp: 0.002048, loss_freq: 0.022309
[16:10:31.119] iteration 23467: loss: 0.060608, loss_s1: 0.039380, loss_fp: 0.002324, loss_freq: 0.033549
[16:10:31.749] iteration 23468: loss: 0.067547, loss_s1: 0.074525, loss_fp: 0.001694, loss_freq: 0.026447
[16:10:32.371] iteration 23469: loss: 0.043561, loss_s1: 0.025185, loss_fp: 0.001643, loss_freq: 0.027408
[16:10:33.035] iteration 23470: loss: 0.051625, loss_s1: 0.040860, loss_fp: 0.003661, loss_freq: 0.025467
[16:10:33.693] iteration 23471: loss: 0.055283, loss_s1: 0.039689, loss_fp: 0.004010, loss_freq: 0.040279
[16:10:34.352] iteration 23472: loss: 0.030382, loss_s1: 0.011489, loss_fp: 0.000648, loss_freq: 0.009971
[16:10:35.001] iteration 23473: loss: 0.081238, loss_s1: 0.040365, loss_fp: 0.001676, loss_freq: 0.058734
[16:10:35.620] iteration 23474: loss: 0.041081, loss_s1: 0.025284, loss_fp: 0.001752, loss_freq: 0.021161
[16:10:36.254] iteration 23475: loss: 0.028421, loss_s1: 0.016061, loss_fp: 0.001002, loss_freq: 0.011098
[16:10:36.878] iteration 23476: loss: 0.041581, loss_s1: 0.018179, loss_fp: 0.004241, loss_freq: 0.016433
[16:10:37.499] iteration 23477: loss: 0.042455, loss_s1: 0.025577, loss_fp: 0.001428, loss_freq: 0.021337
[16:10:38.123] iteration 23478: loss: 0.049243, loss_s1: 0.015229, loss_fp: 0.004417, loss_freq: 0.020736
[16:10:38.740] iteration 23479: loss: 0.074831, loss_s1: 0.029596, loss_fp: 0.002053, loss_freq: 0.079414
[16:10:39.361] iteration 23480: loss: 0.044415, loss_s1: 0.032647, loss_fp: 0.001719, loss_freq: 0.013823
[16:10:39.981] iteration 23481: loss: 0.068690, loss_s1: 0.049516, loss_fp: 0.001242, loss_freq: 0.044698
[16:10:40.660] iteration 23482: loss: 0.036543, loss_s1: 0.017983, loss_fp: 0.002564, loss_freq: 0.015401
[16:10:41.284] iteration 23483: loss: 0.036598, loss_s1: 0.024854, loss_fp: 0.003939, loss_freq: 0.012117
[16:10:41.912] iteration 23484: loss: 0.049806, loss_s1: 0.027434, loss_fp: 0.001516, loss_freq: 0.022749
[16:10:42.549] iteration 23485: loss: 0.064476, loss_s1: 0.030884, loss_fp: 0.008587, loss_freq: 0.057553
[16:10:43.203] iteration 23486: loss: 0.069136, loss_s1: 0.054787, loss_fp: 0.010099, loss_freq: 0.039215
[16:10:43.838] iteration 23487: loss: 0.093658, loss_s1: 0.052533, loss_fp: 0.004279, loss_freq: 0.025117
[16:10:44.471] iteration 23488: loss: 0.071010, loss_s1: 0.061084, loss_fp: 0.012503, loss_freq: 0.032228
[16:10:45.110] iteration 23489: loss: 0.062851, loss_s1: 0.038101, loss_fp: 0.001562, loss_freq: 0.037683
[16:10:45.785] iteration 23490: loss: 0.044450, loss_s1: 0.037242, loss_fp: 0.004306, loss_freq: 0.019867
[16:10:46.478] iteration 23491: loss: 0.050620, loss_s1: 0.019216, loss_fp: 0.011725, loss_freq: 0.028329
[16:10:47.131] iteration 23492: loss: 0.042497, loss_s1: 0.037089, loss_fp: 0.004822, loss_freq: 0.010630
[16:10:47.758] iteration 23493: loss: 0.062199, loss_s1: 0.038893, loss_fp: 0.003230, loss_freq: 0.025591
[16:10:48.385] iteration 23494: loss: 0.044956, loss_s1: 0.043658, loss_fp: 0.001389, loss_freq: 0.016022
[16:10:49.001] iteration 23495: loss: 0.036213, loss_s1: 0.007236, loss_fp: 0.001334, loss_freq: 0.022088
[16:10:49.622] iteration 23496: loss: 0.054731, loss_s1: 0.040207, loss_fp: 0.004433, loss_freq: 0.015762
[16:10:50.239] iteration 23497: loss: 0.046911, loss_s1: 0.012091, loss_fp: 0.003640, loss_freq: 0.011838
[16:10:50.854] iteration 23498: loss: 0.081580, loss_s1: 0.092925, loss_fp: 0.006434, loss_freq: 0.022066
[16:10:51.476] iteration 23499: loss: 0.059296, loss_s1: 0.040982, loss_fp: 0.007935, loss_freq: 0.030338
[16:10:52.100] iteration 23500: loss: 0.046484, loss_s1: 0.017182, loss_fp: 0.012192, loss_freq: 0.010457
[16:10:52.728] iteration 23501: loss: 0.061337, loss_s1: 0.075518, loss_fp: 0.003894, loss_freq: 0.012382
[16:10:53.367] iteration 23502: loss: 0.044866, loss_s1: 0.049056, loss_fp: 0.001140, loss_freq: 0.005204
[16:10:53.998] iteration 23503: loss: 0.059747, loss_s1: 0.035147, loss_fp: 0.010613, loss_freq: 0.036491
[16:10:54.688] iteration 23504: loss: 0.074730, loss_s1: 0.028192, loss_fp: 0.007519, loss_freq: 0.030842
[16:10:55.327] iteration 23505: loss: 0.040547, loss_s1: 0.011523, loss_fp: 0.005809, loss_freq: 0.029914
[16:10:55.984] iteration 23506: loss: 0.047167, loss_s1: 0.022206, loss_fp: 0.003846, loss_freq: 0.042554
[16:10:56.604] iteration 23507: loss: 0.042902, loss_s1: 0.040814, loss_fp: 0.006083, loss_freq: 0.011692
[16:10:57.218] iteration 23508: loss: 0.067839, loss_s1: 0.025279, loss_fp: 0.005962, loss_freq: 0.030563
[16:10:57.844] iteration 23509: loss: 0.038083, loss_s1: 0.036033, loss_fp: 0.001920, loss_freq: 0.008599
[16:10:58.477] iteration 23510: loss: 0.039758, loss_s1: 0.029734, loss_fp: 0.000996, loss_freq: 0.014990
[16:10:59.109] iteration 23511: loss: 0.055388, loss_s1: 0.030990, loss_fp: 0.003503, loss_freq: 0.041349
[16:10:59.746] iteration 23512: loss: 0.052716, loss_s1: 0.035948, loss_fp: 0.007350, loss_freq: 0.026377
[16:11:00.390] iteration 23513: loss: 0.039234, loss_s1: 0.026128, loss_fp: 0.002498, loss_freq: 0.011811
[16:11:01.023] iteration 23514: loss: 0.042741, loss_s1: 0.030650, loss_fp: 0.002046, loss_freq: 0.008704
[16:11:01.658] iteration 23515: loss: 0.046201, loss_s1: 0.023079, loss_fp: 0.003064, loss_freq: 0.031591
[16:11:02.286] iteration 23516: loss: 0.048746, loss_s1: 0.019799, loss_fp: 0.003090, loss_freq: 0.030630
[16:11:02.904] iteration 23517: loss: 0.069011, loss_s1: 0.023049, loss_fp: 0.001660, loss_freq: 0.036969
[16:11:03.554] iteration 23518: loss: 0.062604, loss_s1: 0.059703, loss_fp: 0.005069, loss_freq: 0.019697
[16:11:04.187] iteration 23519: loss: 0.088335, loss_s1: 0.093434, loss_fp: 0.008909, loss_freq: 0.013856
[16:11:04.804] iteration 23520: loss: 0.033897, loss_s1: 0.017445, loss_fp: 0.002555, loss_freq: 0.013334
[16:11:05.430] iteration 23521: loss: 0.035472, loss_s1: 0.013185, loss_fp: 0.001989, loss_freq: 0.013031
[16:11:06.052] iteration 23522: loss: 0.053823, loss_s1: 0.042739, loss_fp: 0.008746, loss_freq: 0.008272
[16:11:06.671] iteration 23523: loss: 0.043916, loss_s1: 0.023133, loss_fp: 0.006098, loss_freq: 0.020787
[16:11:07.295] iteration 23524: loss: 0.083357, loss_s1: 0.061740, loss_fp: 0.003107, loss_freq: 0.052683
[16:11:07.911] iteration 23525: loss: 0.058621, loss_s1: 0.074398, loss_fp: 0.002435, loss_freq: 0.013134
[16:11:08.532] iteration 23526: loss: 0.080314, loss_s1: 0.046918, loss_fp: 0.012878, loss_freq: 0.042936
[16:11:09.154] iteration 23527: loss: 0.080428, loss_s1: 0.053388, loss_fp: 0.006614, loss_freq: 0.073805
[16:11:09.769] iteration 23528: loss: 0.032321, loss_s1: 0.015356, loss_fp: 0.001956, loss_freq: 0.008522
[16:11:10.382] iteration 23529: loss: 0.045191, loss_s1: 0.035366, loss_fp: 0.003484, loss_freq: 0.024108
[16:11:11.000] iteration 23530: loss: 0.063058, loss_s1: 0.058460, loss_fp: 0.000839, loss_freq: 0.018854
[16:11:11.613] iteration 23531: loss: 0.097968, loss_s1: 0.088747, loss_fp: 0.029206, loss_freq: 0.035393
[16:11:12.226] iteration 23532: loss: 0.083117, loss_s1: 0.065677, loss_fp: 0.004159, loss_freq: 0.027294
[16:11:12.842] iteration 23533: loss: 0.056037, loss_s1: 0.024799, loss_fp: 0.007136, loss_freq: 0.041534
[16:11:13.459] iteration 23534: loss: 0.038986, loss_s1: 0.020670, loss_fp: 0.004754, loss_freq: 0.014445
[16:11:14.075] iteration 23535: loss: 0.038802, loss_s1: 0.037284, loss_fp: 0.003948, loss_freq: 0.006275
[16:11:14.691] iteration 23536: loss: 0.041158, loss_s1: 0.021320, loss_fp: 0.003579, loss_freq: 0.015559
[16:11:15.327] iteration 23537: loss: 0.041019, loss_s1: 0.011251, loss_fp: 0.006209, loss_freq: 0.029568
[16:11:15.964] iteration 23538: loss: 0.048886, loss_s1: 0.026422, loss_fp: 0.003179, loss_freq: 0.029541
[16:11:16.604] iteration 23539: loss: 0.028239, loss_s1: 0.011163, loss_fp: 0.002171, loss_freq: 0.006080
[16:11:17.224] iteration 23540: loss: 0.037684, loss_s1: 0.017278, loss_fp: 0.002697, loss_freq: 0.011634
[16:11:17.848] iteration 23541: loss: 0.034060, loss_s1: 0.022326, loss_fp: 0.000981, loss_freq: 0.009171
[16:11:18.476] iteration 23542: loss: 0.054174, loss_s1: 0.041658, loss_fp: 0.004677, loss_freq: 0.026964
[16:11:19.090] iteration 23543: loss: 0.081478, loss_s1: 0.043563, loss_fp: 0.005169, loss_freq: 0.021770
[16:11:19.813] iteration 23544: loss: 0.093098, loss_s1: 0.057294, loss_fp: 0.004070, loss_freq: 0.086042
[16:11:20.446] iteration 23545: loss: 0.042381, loss_s1: 0.044403, loss_fp: 0.000931, loss_freq: 0.007277
[16:11:21.072] iteration 23546: loss: 0.034681, loss_s1: 0.029523, loss_fp: 0.003382, loss_freq: 0.003729
[16:11:21.696] iteration 23547: loss: 0.050907, loss_s1: 0.043171, loss_fp: 0.004089, loss_freq: 0.019648
[16:11:22.322] iteration 23548: loss: 0.041928, loss_s1: 0.031577, loss_fp: 0.000441, loss_freq: 0.015344
[16:11:22.997] iteration 23549: loss: 0.062662, loss_s1: 0.031793, loss_fp: 0.001703, loss_freq: 0.043605
[16:11:23.616] iteration 23550: loss: 0.033897, loss_s1: 0.011883, loss_fp: 0.005621, loss_freq: 0.015462
[16:11:24.240] iteration 23551: loss: 0.061903, loss_s1: 0.047427, loss_fp: 0.002640, loss_freq: 0.028752
[16:11:24.876] iteration 23552: loss: 0.073249, loss_s1: 0.042152, loss_fp: 0.010747, loss_freq: 0.051524
[16:11:25.508] iteration 23553: loss: 0.047675, loss_s1: 0.022194, loss_fp: 0.003521, loss_freq: 0.038107
[16:11:26.129] iteration 23554: loss: 0.066080, loss_s1: 0.012540, loss_fp: 0.009275, loss_freq: 0.024836
[16:11:26.753] iteration 23555: loss: 0.075403, loss_s1: 0.085099, loss_fp: 0.003388, loss_freq: 0.010386
[16:11:27.373] iteration 23556: loss: 0.037021, loss_s1: 0.017856, loss_fp: 0.006639, loss_freq: 0.010142
[16:11:27.990] iteration 23557: loss: 0.053851, loss_s1: 0.040062, loss_fp: 0.007105, loss_freq: 0.012508
[16:11:28.664] iteration 23558: loss: 0.044832, loss_s1: 0.027719, loss_fp: 0.003709, loss_freq: 0.022834
[16:11:29.290] iteration 23559: loss: 0.100285, loss_s1: 0.099078, loss_fp: 0.004012, loss_freq: 0.053828
[16:11:29.921] iteration 23560: loss: 0.055708, loss_s1: 0.022251, loss_fp: 0.006602, loss_freq: 0.044779
[16:11:30.551] iteration 23561: loss: 0.053012, loss_s1: 0.034317, loss_fp: 0.006154, loss_freq: 0.020831
[16:11:31.177] iteration 23562: loss: 0.060792, loss_s1: 0.037254, loss_fp: 0.005794, loss_freq: 0.048933
[16:11:31.806] iteration 23563: loss: 0.045793, loss_s1: 0.025261, loss_fp: 0.004161, loss_freq: 0.026948
[16:11:32.443] iteration 23564: loss: 0.053622, loss_s1: 0.044342, loss_fp: 0.001470, loss_freq: 0.031751
[16:11:33.172] iteration 23565: loss: 0.070096, loss_s1: 0.065956, loss_fp: 0.000708, loss_freq: 0.009379
[16:11:33.884] iteration 23566: loss: 0.101680, loss_s1: 0.095972, loss_fp: 0.003555, loss_freq: 0.065498
[16:11:34.517] iteration 23567: loss: 0.055218, loss_s1: 0.021612, loss_fp: 0.000909, loss_freq: 0.021657
[16:11:35.147] iteration 23568: loss: 0.040567, loss_s1: 0.022736, loss_fp: 0.002787, loss_freq: 0.007746
[16:11:35.805] iteration 23569: loss: 0.063966, loss_s1: 0.032525, loss_fp: 0.009218, loss_freq: 0.041301
[16:11:36.426] iteration 23570: loss: 0.067716, loss_s1: 0.079590, loss_fp: 0.003187, loss_freq: 0.017463
[16:11:37.087] iteration 23571: loss: 0.034381, loss_s1: 0.034750, loss_fp: 0.000862, loss_freq: 0.006278
[16:11:37.733] iteration 23572: loss: 0.054266, loss_s1: 0.025617, loss_fp: 0.004415, loss_freq: 0.040277
[16:11:38.353] iteration 23573: loss: 0.083083, loss_s1: 0.090938, loss_fp: 0.001621, loss_freq: 0.030481
[16:11:38.974] iteration 23574: loss: 0.059541, loss_s1: 0.060197, loss_fp: 0.005221, loss_freq: 0.018647
[16:11:39.587] iteration 23575: loss: 0.031102, loss_s1: 0.007249, loss_fp: 0.000619, loss_freq: 0.021142
[16:11:40.204] iteration 23576: loss: 0.063543, loss_s1: 0.063439, loss_fp: 0.005255, loss_freq: 0.030492
[16:11:40.819] iteration 23577: loss: 0.062599, loss_s1: 0.062205, loss_fp: 0.006483, loss_freq: 0.024758
[16:11:41.437] iteration 23578: loss: 0.056201, loss_s1: 0.022357, loss_fp: 0.001050, loss_freq: 0.008040
[16:11:42.063] iteration 23579: loss: 0.050694, loss_s1: 0.035498, loss_fp: 0.001687, loss_freq: 0.027411
[16:11:42.685] iteration 23580: loss: 0.044328, loss_s1: 0.027597, loss_fp: 0.001604, loss_freq: 0.024303
[16:11:43.298] iteration 23581: loss: 0.093306, loss_s1: 0.063266, loss_fp: 0.003708, loss_freq: 0.011730
[16:11:43.915] iteration 23582: loss: 0.048508, loss_s1: 0.043741, loss_fp: 0.003408, loss_freq: 0.010133
[16:11:44.527] iteration 23583: loss: 0.055154, loss_s1: 0.046846, loss_fp: 0.002456, loss_freq: 0.023392
[16:11:45.149] iteration 23584: loss: 0.056802, loss_s1: 0.031501, loss_fp: 0.011251, loss_freq: 0.033754
[16:11:45.762] iteration 23585: loss: 0.060411, loss_s1: 0.042087, loss_fp: 0.001740, loss_freq: 0.032962
[16:11:46.376] iteration 23586: loss: 0.062121, loss_s1: 0.033407, loss_fp: 0.007448, loss_freq: 0.041321
[16:11:46.995] iteration 23587: loss: 0.053413, loss_s1: 0.026844, loss_fp: 0.001135, loss_freq: 0.021958
[16:11:47.615] iteration 23588: loss: 0.071607, loss_s1: 0.068515, loss_fp: 0.005812, loss_freq: 0.032979
[16:11:48.232] iteration 23589: loss: 0.055759, loss_s1: 0.055833, loss_fp: 0.004520, loss_freq: 0.007816
[16:11:48.846] iteration 23590: loss: 0.034657, loss_s1: 0.020927, loss_fp: 0.002620, loss_freq: 0.010025
[16:11:49.454] iteration 23591: loss: 0.059428, loss_s1: 0.067370, loss_fp: 0.002599, loss_freq: 0.012730
[16:11:50.066] iteration 23592: loss: 0.044332, loss_s1: 0.041131, loss_fp: 0.002822, loss_freq: 0.011084
[16:11:50.683] iteration 23593: loss: 0.064488, loss_s1: 0.063730, loss_fp: 0.003200, loss_freq: 0.023721
[16:11:51.296] iteration 23594: loss: 0.041246, loss_s1: 0.020652, loss_fp: 0.007219, loss_freq: 0.019795
[16:11:51.913] iteration 23595: loss: 0.044319, loss_s1: 0.019249, loss_fp: 0.001968, loss_freq: 0.026096
[16:11:52.867] iteration 23596: loss: 0.090427, loss_s1: 0.036954, loss_fp: 0.001577, loss_freq: 0.009274
[16:11:53.557] iteration 23597: loss: 0.059078, loss_s1: 0.052615, loss_fp: 0.005895, loss_freq: 0.021804
[16:11:54.240] iteration 23598: loss: 0.050346, loss_s1: 0.035704, loss_fp: 0.000837, loss_freq: 0.024006
[16:11:54.855] iteration 23599: loss: 0.050348, loss_s1: 0.044365, loss_fp: 0.001078, loss_freq: 0.015144
[16:11:55.467] iteration 23600: loss: 0.071072, loss_s1: 0.067780, loss_fp: 0.002043, loss_freq: 0.023946
[16:11:58.838] iteration 23600 : mean_dice : 0.795481
[16:11:59.489] iteration 23601: loss: 0.045063, loss_s1: 0.035264, loss_fp: 0.004186, loss_freq: 0.004654
[16:12:00.114] iteration 23602: loss: 0.030983, loss_s1: 0.018443, loss_fp: 0.001462, loss_freq: 0.014000
[16:12:00.743] iteration 23603: loss: 0.047357, loss_s1: 0.011598, loss_fp: 0.009045, loss_freq: 0.014161
[16:12:01.367] iteration 23604: loss: 0.087914, loss_s1: 0.083187, loss_fp: 0.002333, loss_freq: 0.053479
[16:12:01.986] iteration 23605: loss: 0.035235, loss_s1: 0.010715, loss_fp: 0.000862, loss_freq: 0.004783
[16:12:02.604] iteration 23606: loss: 0.043692, loss_s1: 0.023549, loss_fp: 0.002027, loss_freq: 0.029273
[16:12:03.241] iteration 23607: loss: 0.049194, loss_s1: 0.018210, loss_fp: 0.002876, loss_freq: 0.043473
[16:12:03.904] iteration 23608: loss: 0.063316, loss_s1: 0.064029, loss_fp: 0.002722, loss_freq: 0.020632
[16:12:04.522] iteration 23609: loss: 0.049991, loss_s1: 0.034424, loss_fp: 0.002376, loss_freq: 0.029698
[16:12:05.143] iteration 23610: loss: 0.058768, loss_s1: 0.055007, loss_fp: 0.001056, loss_freq: 0.023339
[16:12:05.803] iteration 23611: loss: 0.039732, loss_s1: 0.016462, loss_fp: 0.001779, loss_freq: 0.022179
[16:12:06.419] iteration 23612: loss: 0.050476, loss_s1: 0.030284, loss_fp: 0.003173, loss_freq: 0.032193
[16:12:07.046] iteration 23613: loss: 0.041705, loss_s1: 0.040495, loss_fp: 0.002287, loss_freq: 0.011040
[16:12:07.671] iteration 23614: loss: 0.054579, loss_s1: 0.043246, loss_fp: 0.004578, loss_freq: 0.025949
[16:12:08.297] iteration 23615: loss: 0.034604, loss_s1: 0.029492, loss_fp: 0.002384, loss_freq: 0.009091
[16:12:08.920] iteration 23616: loss: 0.086761, loss_s1: 0.041057, loss_fp: 0.002964, loss_freq: 0.072357
[16:12:09.547] iteration 23617: loss: 0.049558, loss_s1: 0.034270, loss_fp: 0.001712, loss_freq: 0.025471
[16:12:10.162] iteration 23618: loss: 0.059235, loss_s1: 0.052037, loss_fp: 0.001428, loss_freq: 0.032694
[16:12:10.778] iteration 23619: loss: 0.051086, loss_s1: 0.024975, loss_fp: 0.006635, loss_freq: 0.006670
[16:12:11.392] iteration 23620: loss: 0.058423, loss_s1: 0.046140, loss_fp: 0.003830, loss_freq: 0.023212
[16:12:12.058] iteration 23621: loss: 0.055909, loss_s1: 0.038757, loss_fp: 0.006306, loss_freq: 0.026527
[16:12:12.678] iteration 23622: loss: 0.063133, loss_s1: 0.051557, loss_fp: 0.005725, loss_freq: 0.029104
[16:12:13.298] iteration 23623: loss: 0.033709, loss_s1: 0.020284, loss_fp: 0.000668, loss_freq: 0.010740
[16:12:13.915] iteration 23624: loss: 0.049064, loss_s1: 0.014693, loss_fp: 0.000307, loss_freq: 0.026720
[16:12:14.536] iteration 23625: loss: 0.055694, loss_s1: 0.017525, loss_fp: 0.001184, loss_freq: 0.016011
[16:12:15.208] iteration 23626: loss: 0.048665, loss_s1: 0.037104, loss_fp: 0.006097, loss_freq: 0.017912
[16:12:15.828] iteration 23627: loss: 0.087260, loss_s1: 0.069751, loss_fp: 0.002503, loss_freq: 0.030168
[16:12:16.447] iteration 23628: loss: 0.048259, loss_s1: 0.018226, loss_fp: 0.010500, loss_freq: 0.038637
[16:12:17.063] iteration 23629: loss: 0.112753, loss_s1: 0.132368, loss_fp: 0.013667, loss_freq: 0.036962
[16:12:17.687] iteration 23630: loss: 0.046565, loss_s1: 0.020089, loss_fp: 0.003949, loss_freq: 0.023651
[16:12:18.310] iteration 23631: loss: 0.055819, loss_s1: 0.048089, loss_fp: 0.001320, loss_freq: 0.014445
[16:12:18.931] iteration 23632: loss: 0.043861, loss_s1: 0.029566, loss_fp: 0.001115, loss_freq: 0.012792
[16:12:19.555] iteration 23633: loss: 0.045313, loss_s1: 0.032707, loss_fp: 0.004317, loss_freq: 0.020560
[16:12:20.182] iteration 23634: loss: 0.077061, loss_s1: 0.087943, loss_fp: 0.005468, loss_freq: 0.023977
[16:12:20.810] iteration 23635: loss: 0.036579, loss_s1: 0.024202, loss_fp: 0.006124, loss_freq: 0.011368
[16:12:21.436] iteration 23636: loss: 0.042992, loss_s1: 0.034360, loss_fp: 0.004456, loss_freq: 0.011835
[16:12:22.068] iteration 23637: loss: 0.051120, loss_s1: 0.034460, loss_fp: 0.011862, loss_freq: 0.024109
[16:12:22.691] iteration 23638: loss: 0.055269, loss_s1: 0.035455, loss_fp: 0.000530, loss_freq: 0.035078
[16:12:23.330] iteration 23639: loss: 0.044866, loss_s1: 0.028320, loss_fp: 0.004574, loss_freq: 0.021711
[16:12:23.958] iteration 23640: loss: 0.054693, loss_s1: 0.009621, loss_fp: 0.001028, loss_freq: 0.019059
[16:12:24.582] iteration 23641: loss: 0.060772, loss_s1: 0.050987, loss_fp: 0.006022, loss_freq: 0.025604
[16:12:25.207] iteration 23642: loss: 0.066900, loss_s1: 0.052677, loss_fp: 0.001688, loss_freq: 0.025989
[16:12:25.874] iteration 23643: loss: 0.060934, loss_s1: 0.036499, loss_fp: 0.006394, loss_freq: 0.030012
[16:12:26.499] iteration 23644: loss: 0.050106, loss_s1: 0.038331, loss_fp: 0.002892, loss_freq: 0.023185
[16:12:27.173] iteration 23645: loss: 0.064991, loss_s1: 0.060104, loss_fp: 0.004135, loss_freq: 0.018458
[16:12:27.791] iteration 23646: loss: 0.072887, loss_s1: 0.068325, loss_fp: 0.006808, loss_freq: 0.011521
[16:12:28.418] iteration 23647: loss: 0.074282, loss_s1: 0.053978, loss_fp: 0.001364, loss_freq: 0.033977
[16:12:29.027] iteration 23648: loss: 0.048950, loss_s1: 0.025820, loss_fp: 0.001333, loss_freq: 0.030808
[16:12:29.652] iteration 23649: loss: 0.033730, loss_s1: 0.019964, loss_fp: 0.003705, loss_freq: 0.011499
[16:12:30.286] iteration 23650: loss: 0.030298, loss_s1: 0.010522, loss_fp: 0.000685, loss_freq: 0.007582
[16:12:30.905] iteration 23651: loss: 0.056482, loss_s1: 0.031164, loss_fp: 0.000591, loss_freq: 0.019332
[16:12:31.532] iteration 23652: loss: 0.063340, loss_s1: 0.065328, loss_fp: 0.004604, loss_freq: 0.027506
[16:12:32.151] iteration 23653: loss: 0.060534, loss_s1: 0.053514, loss_fp: 0.002105, loss_freq: 0.029224
[16:12:32.775] iteration 23654: loss: 0.046387, loss_s1: 0.027987, loss_fp: 0.000879, loss_freq: 0.034939
[16:12:33.437] iteration 23655: loss: 0.050861, loss_s1: 0.035997, loss_fp: 0.001298, loss_freq: 0.025817
[16:12:34.060] iteration 23656: loss: 0.045758, loss_s1: 0.023721, loss_fp: 0.001341, loss_freq: 0.012776
[16:12:34.683] iteration 23657: loss: 0.059662, loss_s1: 0.057070, loss_fp: 0.002697, loss_freq: 0.010537
[16:12:35.305] iteration 23658: loss: 0.078904, loss_s1: 0.078787, loss_fp: 0.006725, loss_freq: 0.024333
[16:12:35.931] iteration 23659: loss: 0.055129, loss_s1: 0.032407, loss_fp: 0.002458, loss_freq: 0.022907
[16:12:36.593] iteration 23660: loss: 0.091342, loss_s1: 0.036599, loss_fp: 0.010022, loss_freq: 0.024733
[16:12:37.209] iteration 23661: loss: 0.074313, loss_s1: 0.085599, loss_fp: 0.002701, loss_freq: 0.020647
[16:12:37.830] iteration 23662: loss: 0.059324, loss_s1: 0.046017, loss_fp: 0.002588, loss_freq: 0.025050
[16:12:38.449] iteration 23663: loss: 0.052462, loss_s1: 0.019520, loss_fp: 0.005477, loss_freq: 0.044700
[16:12:39.112] iteration 23664: loss: 0.049190, loss_s1: 0.041240, loss_fp: 0.001609, loss_freq: 0.009894
[16:12:39.729] iteration 23665: loss: 0.046491, loss_s1: 0.025794, loss_fp: 0.005676, loss_freq: 0.014074
[16:12:40.353] iteration 23666: loss: 0.029080, loss_s1: 0.008688, loss_fp: 0.001241, loss_freq: 0.012754
[16:12:40.968] iteration 23667: loss: 0.064024, loss_s1: 0.054144, loss_fp: 0.007327, loss_freq: 0.030160
[16:12:41.588] iteration 23668: loss: 0.066727, loss_s1: 0.055466, loss_fp: 0.000953, loss_freq: 0.035058
[16:12:42.225] iteration 23669: loss: 0.064875, loss_s1: 0.035786, loss_fp: 0.001696, loss_freq: 0.047103
[16:12:42.848] iteration 23670: loss: 0.047485, loss_s1: 0.029089, loss_fp: 0.001466, loss_freq: 0.024735
[16:12:43.468] iteration 23671: loss: 0.039329, loss_s1: 0.018303, loss_fp: 0.003754, loss_freq: 0.015056
[16:12:44.085] iteration 23672: loss: 0.046521, loss_s1: 0.038949, loss_fp: 0.006418, loss_freq: 0.021538
[16:12:44.702] iteration 23673: loss: 0.044544, loss_s1: 0.015382, loss_fp: 0.001882, loss_freq: 0.027869
[16:12:45.339] iteration 23674: loss: 0.049496, loss_s1: 0.028809, loss_fp: 0.003038, loss_freq: 0.014462
[16:12:45.975] iteration 23675: loss: 0.092849, loss_s1: 0.099748, loss_fp: 0.003603, loss_freq: 0.024812
[16:12:46.618] iteration 23676: loss: 0.068747, loss_s1: 0.051032, loss_fp: 0.001466, loss_freq: 0.033383
[16:12:47.225] iteration 23677: loss: 0.028962, loss_s1: 0.012404, loss_fp: 0.002201, loss_freq: 0.011442
[16:12:47.891] iteration 23678: loss: 0.042803, loss_s1: 0.027347, loss_fp: 0.005567, loss_freq: 0.017890
[16:12:48.536] iteration 23679: loss: 0.041754, loss_s1: 0.032275, loss_fp: 0.002255, loss_freq: 0.008621
[16:12:49.166] iteration 23680: loss: 0.062119, loss_s1: 0.063604, loss_fp: 0.003384, loss_freq: 0.017979
[16:12:49.784] iteration 23681: loss: 0.061654, loss_s1: 0.038078, loss_fp: 0.002103, loss_freq: 0.031340
[16:12:50.405] iteration 23682: loss: 0.061010, loss_s1: 0.052981, loss_fp: 0.003326, loss_freq: 0.025664
[16:12:51.028] iteration 23683: loss: 0.061679, loss_s1: 0.032030, loss_fp: 0.001471, loss_freq: 0.055523
[16:12:51.647] iteration 23684: loss: 0.042581, loss_s1: 0.033596, loss_fp: 0.002606, loss_freq: 0.017440
[16:12:52.313] iteration 23685: loss: 0.049145, loss_s1: 0.034940, loss_fp: 0.006900, loss_freq: 0.027378
[16:12:52.939] iteration 23686: loss: 0.048523, loss_s1: 0.034081, loss_fp: 0.004405, loss_freq: 0.013874
[16:12:53.565] iteration 23687: loss: 0.101887, loss_s1: 0.095223, loss_fp: 0.015461, loss_freq: 0.048382
[16:12:54.184] iteration 23688: loss: 0.042305, loss_s1: 0.035327, loss_fp: 0.001643, loss_freq: 0.010986
[16:12:54.811] iteration 23689: loss: 0.036258, loss_s1: 0.026635, loss_fp: 0.002560, loss_freq: 0.005894
[16:12:55.440] iteration 23690: loss: 0.031645, loss_s1: 0.016774, loss_fp: 0.002052, loss_freq: 0.006649
[16:12:56.066] iteration 23691: loss: 0.043311, loss_s1: 0.022856, loss_fp: 0.001981, loss_freq: 0.019062
[16:12:56.682] iteration 23692: loss: 0.061645, loss_s1: 0.050477, loss_fp: 0.000996, loss_freq: 0.030879
[16:12:57.319] iteration 23693: loss: 0.053482, loss_s1: 0.052236, loss_fp: 0.001889, loss_freq: 0.018734
[16:12:57.950] iteration 23694: loss: 0.046182, loss_s1: 0.015286, loss_fp: 0.001986, loss_freq: 0.014112
[16:12:58.582] iteration 23695: loss: 0.081657, loss_s1: 0.054219, loss_fp: 0.005309, loss_freq: 0.039294
[16:12:59.205] iteration 23696: loss: 0.060599, loss_s1: 0.032909, loss_fp: 0.024421, loss_freq: 0.030196
[16:12:59.835] iteration 23697: loss: 0.062545, loss_s1: 0.033150, loss_fp: 0.005701, loss_freq: 0.021297
[16:13:00.467] iteration 23698: loss: 0.058137, loss_s1: 0.065197, loss_fp: 0.005149, loss_freq: 0.015462
[16:13:01.086] iteration 23699: loss: 0.043039, loss_s1: 0.034578, loss_fp: 0.002389, loss_freq: 0.012881
[16:13:01.705] iteration 23700: loss: 0.077080, loss_s1: 0.035763, loss_fp: 0.001124, loss_freq: 0.025632
[16:13:02.335] iteration 23701: loss: 0.061780, loss_s1: 0.028909, loss_fp: 0.002615, loss_freq: 0.029884
[16:13:02.960] iteration 23702: loss: 0.078261, loss_s1: 0.067427, loss_fp: 0.002549, loss_freq: 0.047772
[16:13:03.630] iteration 23703: loss: 0.060961, loss_s1: 0.050614, loss_fp: 0.002160, loss_freq: 0.036781
[16:13:04.286] iteration 23704: loss: 0.055448, loss_s1: 0.028796, loss_fp: 0.008554, loss_freq: 0.036425
[16:13:04.904] iteration 23705: loss: 0.066619, loss_s1: 0.028528, loss_fp: 0.005317, loss_freq: 0.069611
[16:13:05.531] iteration 23706: loss: 0.096588, loss_s1: 0.059299, loss_fp: 0.007690, loss_freq: 0.045738
[16:13:06.156] iteration 23707: loss: 0.042652, loss_s1: 0.041480, loss_fp: 0.001004, loss_freq: 0.016984
[16:13:06.782] iteration 23708: loss: 0.043036, loss_s1: 0.030913, loss_fp: 0.001053, loss_freq: 0.009384
[16:13:07.406] iteration 23709: loss: 0.077185, loss_s1: 0.070256, loss_fp: 0.002950, loss_freq: 0.043282
[16:13:08.037] iteration 23710: loss: 0.053432, loss_s1: 0.017340, loss_fp: 0.001769, loss_freq: 0.036579
[16:13:08.661] iteration 23711: loss: 0.054989, loss_s1: 0.023670, loss_fp: 0.001323, loss_freq: 0.040569
[16:13:09.288] iteration 23712: loss: 0.045807, loss_s1: 0.042217, loss_fp: 0.003557, loss_freq: 0.011040
[16:13:09.910] iteration 23713: loss: 0.038926, loss_s1: 0.025401, loss_fp: 0.004960, loss_freq: 0.015494
[16:13:10.534] iteration 23714: loss: 0.044184, loss_s1: 0.032398, loss_fp: 0.001471, loss_freq: 0.024100
[16:13:11.158] iteration 23715: loss: 0.038102, loss_s1: 0.015290, loss_fp: 0.002907, loss_freq: 0.016213
[16:13:11.787] iteration 23716: loss: 0.052513, loss_s1: 0.027476, loss_fp: 0.002865, loss_freq: 0.042733
[16:13:12.415] iteration 23717: loss: 0.051797, loss_s1: 0.038211, loss_fp: 0.003799, loss_freq: 0.017097
[16:13:13.040] iteration 23718: loss: 0.047004, loss_s1: 0.046135, loss_fp: 0.002334, loss_freq: 0.005477
[16:13:13.662] iteration 23719: loss: 0.026480, loss_s1: 0.009280, loss_fp: 0.002770, loss_freq: 0.015377
[16:13:14.335] iteration 23720: loss: 0.057560, loss_s1: 0.061710, loss_fp: 0.005659, loss_freq: 0.015938
[16:13:14.992] iteration 23721: loss: 0.040460, loss_s1: 0.016055, loss_fp: 0.005855, loss_freq: 0.012574
[16:13:15.683] iteration 23722: loss: 0.041217, loss_s1: 0.019127, loss_fp: 0.001133, loss_freq: 0.027545
[16:13:16.337] iteration 23723: loss: 0.054758, loss_s1: 0.056457, loss_fp: 0.000838, loss_freq: 0.021921
[16:13:16.986] iteration 23724: loss: 0.038544, loss_s1: 0.021642, loss_fp: 0.007493, loss_freq: 0.009861
[16:13:17.636] iteration 23725: loss: 0.054598, loss_s1: 0.053719, loss_fp: 0.000518, loss_freq: 0.008826
[16:13:18.285] iteration 23726: loss: 0.055805, loss_s1: 0.023327, loss_fp: 0.002944, loss_freq: 0.020521
[16:13:18.956] iteration 23727: loss: 0.055455, loss_s1: 0.038682, loss_fp: 0.008566, loss_freq: 0.024157
[16:13:19.634] iteration 23728: loss: 0.036481, loss_s1: 0.024632, loss_fp: 0.010079, loss_freq: 0.003975
[16:13:20.271] iteration 23729: loss: 0.085453, loss_s1: 0.066462, loss_fp: 0.004240, loss_freq: 0.062011
[16:13:20.908] iteration 23730: loss: 0.055946, loss_s1: 0.027846, loss_fp: 0.005039, loss_freq: 0.010090
[16:13:21.545] iteration 23731: loss: 0.061663, loss_s1: 0.056054, loss_fp: 0.001561, loss_freq: 0.030526
[16:13:22.175] iteration 23732: loss: 0.078576, loss_s1: 0.065725, loss_fp: 0.005502, loss_freq: 0.009463
[16:13:22.802] iteration 23733: loss: 0.055855, loss_s1: 0.063817, loss_fp: 0.004144, loss_freq: 0.009843
[16:13:23.431] iteration 23734: loss: 0.047029, loss_s1: 0.027122, loss_fp: 0.001572, loss_freq: 0.020467
[16:13:24.060] iteration 23735: loss: 0.060357, loss_s1: 0.036239, loss_fp: 0.005588, loss_freq: 0.016733
[16:13:24.678] iteration 23736: loss: 0.051177, loss_s1: 0.043628, loss_fp: 0.003496, loss_freq: 0.020369
[16:13:25.345] iteration 23737: loss: 0.077984, loss_s1: 0.075756, loss_fp: 0.011802, loss_freq: 0.023914
[16:13:26.003] iteration 23738: loss: 0.041894, loss_s1: 0.025848, loss_fp: 0.006042, loss_freq: 0.020527
[16:13:26.964] iteration 23739: loss: 0.033837, loss_s1: 0.015902, loss_fp: 0.002221, loss_freq: 0.013550
[16:13:27.605] iteration 23740: loss: 0.053145, loss_s1: 0.036941, loss_fp: 0.002405, loss_freq: 0.017432
[16:13:28.266] iteration 23741: loss: 0.048674, loss_s1: 0.035115, loss_fp: 0.003401, loss_freq: 0.018226
[16:13:28.936] iteration 23742: loss: 0.057472, loss_s1: 0.039025, loss_fp: 0.003240, loss_freq: 0.031015
[16:13:29.603] iteration 23743: loss: 0.054329, loss_s1: 0.030872, loss_fp: 0.001616, loss_freq: 0.050490
[16:13:30.243] iteration 23744: loss: 0.035481, loss_s1: 0.010344, loss_fp: 0.004773, loss_freq: 0.011480
[16:13:30.865] iteration 23745: loss: 0.029213, loss_s1: 0.014114, loss_fp: 0.001586, loss_freq: 0.015981
[16:13:31.496] iteration 23746: loss: 0.054846, loss_s1: 0.045566, loss_fp: 0.002664, loss_freq: 0.018910
[16:13:32.124] iteration 23747: loss: 0.046922, loss_s1: 0.040493, loss_fp: 0.003749, loss_freq: 0.008325
[16:13:32.748] iteration 23748: loss: 0.056473, loss_s1: 0.026907, loss_fp: 0.000868, loss_freq: 0.020675
[16:13:33.379] iteration 23749: loss: 0.043954, loss_s1: 0.026437, loss_fp: 0.000694, loss_freq: 0.024636
[16:13:34.004] iteration 23750: loss: 0.045314, loss_s1: 0.023706, loss_fp: 0.002630, loss_freq: 0.016043
[16:13:34.615] iteration 23751: loss: 0.041173, loss_s1: 0.035335, loss_fp: 0.003040, loss_freq: 0.009096
[16:13:35.237] iteration 23752: loss: 0.045205, loss_s1: 0.027485, loss_fp: 0.002721, loss_freq: 0.015837
[16:13:35.864] iteration 23753: loss: 0.068136, loss_s1: 0.038870, loss_fp: 0.003421, loss_freq: 0.049527
[16:13:36.504] iteration 23754: loss: 0.072120, loss_s1: 0.033527, loss_fp: 0.004053, loss_freq: 0.034478
[16:13:37.144] iteration 23755: loss: 0.053640, loss_s1: 0.010421, loss_fp: 0.005610, loss_freq: 0.017403
[16:13:37.828] iteration 23756: loss: 0.073501, loss_s1: 0.054292, loss_fp: 0.007110, loss_freq: 0.053168
[16:13:38.621] iteration 23757: loss: 0.051335, loss_s1: 0.034893, loss_fp: 0.002221, loss_freq: 0.033933
[16:13:39.519] iteration 23758: loss: 0.035389, loss_s1: 0.023351, loss_fp: 0.002065, loss_freq: 0.010461
[16:13:40.264] iteration 23759: loss: 0.098249, loss_s1: 0.068244, loss_fp: 0.005059, loss_freq: 0.074853
[16:13:41.032] iteration 23760: loss: 0.054457, loss_s1: 0.023936, loss_fp: 0.014293, loss_freq: 0.030173
[16:13:41.658] iteration 23761: loss: 0.050703, loss_s1: 0.026154, loss_fp: 0.002120, loss_freq: 0.030146
[16:13:42.266] iteration 23762: loss: 0.039605, loss_s1: 0.042107, loss_fp: 0.001289, loss_freq: 0.005301
[16:13:42.884] iteration 23763: loss: 0.041014, loss_s1: 0.020054, loss_fp: 0.002460, loss_freq: 0.022424
[16:13:43.506] iteration 23764: loss: 0.052144, loss_s1: 0.034278, loss_fp: 0.008969, loss_freq: 0.023611
[16:13:44.133] iteration 23765: loss: 0.054809, loss_s1: 0.021581, loss_fp: 0.002771, loss_freq: 0.038120
[16:13:44.757] iteration 23766: loss: 0.042486, loss_s1: 0.036283, loss_fp: 0.001074, loss_freq: 0.015550
[16:13:45.384] iteration 23767: loss: 0.054601, loss_s1: 0.048180, loss_fp: 0.003633, loss_freq: 0.011646
[16:13:46.007] iteration 23768: loss: 0.064295, loss_s1: 0.064732, loss_fp: 0.001049, loss_freq: 0.010771
[16:13:46.625] iteration 23769: loss: 0.056787, loss_s1: 0.052309, loss_fp: 0.000705, loss_freq: 0.009447
[16:13:47.270] iteration 23770: loss: 0.082054, loss_s1: 0.083973, loss_fp: 0.004633, loss_freq: 0.026947
[16:13:47.896] iteration 23771: loss: 0.054703, loss_s1: 0.044679, loss_fp: 0.011905, loss_freq: 0.020107
[16:13:48.526] iteration 23772: loss: 0.075120, loss_s1: 0.076183, loss_fp: 0.002069, loss_freq: 0.033306
[16:13:49.157] iteration 23773: loss: 0.078117, loss_s1: 0.072960, loss_fp: 0.003596, loss_freq: 0.030867
[16:13:49.781] iteration 23774: loss: 0.047022, loss_s1: 0.037967, loss_fp: 0.000785, loss_freq: 0.017787
[16:13:50.403] iteration 23775: loss: 0.075993, loss_s1: 0.056214, loss_fp: 0.001951, loss_freq: 0.053392
[16:13:51.024] iteration 23776: loss: 0.055521, loss_s1: 0.052902, loss_fp: 0.003730, loss_freq: 0.023875
[16:13:51.642] iteration 23777: loss: 0.059034, loss_s1: 0.042600, loss_fp: 0.003808, loss_freq: 0.030089
[16:13:52.269] iteration 23778: loss: 0.034351, loss_s1: 0.030977, loss_fp: 0.004234, loss_freq: 0.007298
[16:13:52.889] iteration 23779: loss: 0.091802, loss_s1: 0.065620, loss_fp: 0.012925, loss_freq: 0.025411
[16:13:53.511] iteration 23780: loss: 0.040091, loss_s1: 0.032894, loss_fp: 0.003983, loss_freq: 0.017107
[16:13:54.129] iteration 23781: loss: 0.048389, loss_s1: 0.020660, loss_fp: 0.007456, loss_freq: 0.031861
[16:13:54.744] iteration 23782: loss: 0.056706, loss_s1: 0.030083, loss_fp: 0.002111, loss_freq: 0.044705
[16:13:55.370] iteration 23783: loss: 0.063994, loss_s1: 0.037695, loss_fp: 0.008268, loss_freq: 0.012810
[16:13:55.987] iteration 23784: loss: 0.066485, loss_s1: 0.053710, loss_fp: 0.003477, loss_freq: 0.040221
[16:13:56.601] iteration 23785: loss: 0.057003, loss_s1: 0.035274, loss_fp: 0.006814, loss_freq: 0.026396
[16:13:57.222] iteration 23786: loss: 0.060012, loss_s1: 0.040748, loss_fp: 0.009559, loss_freq: 0.029529
[16:13:57.841] iteration 23787: loss: 0.055330, loss_s1: 0.043693, loss_fp: 0.006191, loss_freq: 0.031314
[16:13:58.463] iteration 23788: loss: 0.067695, loss_s1: 0.052935, loss_fp: 0.002602, loss_freq: 0.018095
[16:13:59.084] iteration 23789: loss: 0.060951, loss_s1: 0.052356, loss_fp: 0.005447, loss_freq: 0.015042
[16:13:59.701] iteration 23790: loss: 0.053735, loss_s1: 0.028791, loss_fp: 0.001036, loss_freq: 0.028447
[16:14:00.321] iteration 23791: loss: 0.050206, loss_s1: 0.030327, loss_fp: 0.001698, loss_freq: 0.022355
[16:14:00.928] iteration 23792: loss: 0.059736, loss_s1: 0.037102, loss_fp: 0.010476, loss_freq: 0.020546
[16:14:01.536] iteration 23793: loss: 0.037855, loss_s1: 0.035001, loss_fp: 0.000703, loss_freq: 0.006696
[16:14:02.149] iteration 23794: loss: 0.042609, loss_s1: 0.009412, loss_fp: 0.001251, loss_freq: 0.019819
[16:14:02.774] iteration 23795: loss: 0.044183, loss_s1: 0.038592, loss_fp: 0.001650, loss_freq: 0.010976
[16:14:03.391] iteration 23796: loss: 0.038705, loss_s1: 0.025266, loss_fp: 0.002352, loss_freq: 0.015489
[16:14:04.012] iteration 23797: loss: 0.043115, loss_s1: 0.018283, loss_fp: 0.000690, loss_freq: 0.015840
[16:14:04.627] iteration 23798: loss: 0.052548, loss_s1: 0.032873, loss_fp: 0.005051, loss_freq: 0.020627
[16:14:05.250] iteration 23799: loss: 0.048899, loss_s1: 0.016637, loss_fp: 0.010991, loss_freq: 0.022995
[16:14:05.906] iteration 23800: loss: 0.044216, loss_s1: 0.019253, loss_fp: 0.002825, loss_freq: 0.013465
[16:14:09.443] iteration 23800 : mean_dice : 0.771482
[16:14:10.095] iteration 23801: loss: 0.071695, loss_s1: 0.060511, loss_fp: 0.008030, loss_freq: 0.026167
[16:14:10.708] iteration 23802: loss: 0.059424, loss_s1: 0.045596, loss_fp: 0.000717, loss_freq: 0.020752
[16:14:11.438] iteration 23803: loss: 0.065649, loss_s1: 0.043767, loss_fp: 0.004005, loss_freq: 0.013377
[16:14:12.057] iteration 23804: loss: 0.043151, loss_s1: 0.041797, loss_fp: 0.004015, loss_freq: 0.007118
[16:14:12.675] iteration 23805: loss: 0.061142, loss_s1: 0.035780, loss_fp: 0.008985, loss_freq: 0.033976
[16:14:13.298] iteration 23806: loss: 0.046310, loss_s1: 0.024387, loss_fp: 0.012094, loss_freq: 0.018932
[16:14:13.921] iteration 23807: loss: 0.040600, loss_s1: 0.021483, loss_fp: 0.000616, loss_freq: 0.021671
[16:14:14.551] iteration 23808: loss: 0.061382, loss_s1: 0.044474, loss_fp: 0.002040, loss_freq: 0.020611
[16:14:15.265] iteration 23809: loss: 0.029555, loss_s1: 0.017996, loss_fp: 0.001235, loss_freq: 0.011062
[16:14:15.922] iteration 23810: loss: 0.041538, loss_s1: 0.025331, loss_fp: 0.002023, loss_freq: 0.015989
[16:14:16.555] iteration 23811: loss: 0.037014, loss_s1: 0.009801, loss_fp: 0.002794, loss_freq: 0.019487
[16:14:17.188] iteration 23812: loss: 0.097845, loss_s1: 0.066717, loss_fp: 0.018507, loss_freq: 0.039087
[16:14:17.821] iteration 23813: loss: 0.055001, loss_s1: 0.042573, loss_fp: 0.004606, loss_freq: 0.031591
[16:14:18.460] iteration 23814: loss: 0.049700, loss_s1: 0.030079, loss_fp: 0.003091, loss_freq: 0.009315
[16:14:19.101] iteration 23815: loss: 0.045823, loss_s1: 0.040882, loss_fp: 0.003292, loss_freq: 0.021765
[16:14:19.743] iteration 23816: loss: 0.045695, loss_s1: 0.008428, loss_fp: 0.001733, loss_freq: 0.034182
[16:14:20.380] iteration 23817: loss: 0.045163, loss_s1: 0.024605, loss_fp: 0.007713, loss_freq: 0.022763
[16:14:21.080] iteration 23818: loss: 0.095192, loss_s1: 0.079330, loss_fp: 0.005199, loss_freq: 0.038837
[16:14:21.704] iteration 23819: loss: 0.042446, loss_s1: 0.033890, loss_fp: 0.000807, loss_freq: 0.013087
[16:14:22.327] iteration 23820: loss: 0.048682, loss_s1: 0.034423, loss_fp: 0.008820, loss_freq: 0.011461
[16:14:22.940] iteration 23821: loss: 0.049273, loss_s1: 0.035743, loss_fp: 0.006136, loss_freq: 0.017091
[16:14:23.561] iteration 23822: loss: 0.061250, loss_s1: 0.050342, loss_fp: 0.005549, loss_freq: 0.038604
[16:14:24.235] iteration 23823: loss: 0.068645, loss_s1: 0.055544, loss_fp: 0.005912, loss_freq: 0.032010
[16:14:24.852] iteration 23824: loss: 0.053648, loss_s1: 0.014353, loss_fp: 0.011266, loss_freq: 0.036635
[16:14:25.473] iteration 23825: loss: 0.048253, loss_s1: 0.032544, loss_fp: 0.002654, loss_freq: 0.022645
[16:14:26.091] iteration 23826: loss: 0.053825, loss_s1: 0.020433, loss_fp: 0.007392, loss_freq: 0.017567
[16:14:26.713] iteration 23827: loss: 0.038900, loss_s1: 0.013412, loss_fp: 0.002767, loss_freq: 0.024086
[16:14:27.337] iteration 23828: loss: 0.049346, loss_s1: 0.023039, loss_fp: 0.003336, loss_freq: 0.031020
[16:14:27.956] iteration 23829: loss: 0.069389, loss_s1: 0.043796, loss_fp: 0.005612, loss_freq: 0.046668
[16:14:28.575] iteration 23830: loss: 0.064907, loss_s1: 0.051024, loss_fp: 0.005263, loss_freq: 0.037991
[16:14:29.192] iteration 23831: loss: 0.042316, loss_s1: 0.043595, loss_fp: 0.001339, loss_freq: 0.006206
[16:14:29.807] iteration 23832: loss: 0.051876, loss_s1: 0.041757, loss_fp: 0.002744, loss_freq: 0.014106
[16:14:30.427] iteration 23833: loss: 0.042675, loss_s1: 0.028181, loss_fp: 0.001564, loss_freq: 0.017688
[16:14:31.044] iteration 23834: loss: 0.032457, loss_s1: 0.011050, loss_fp: 0.001998, loss_freq: 0.007323
[16:14:31.667] iteration 23835: loss: 0.063633, loss_s1: 0.023197, loss_fp: 0.005022, loss_freq: 0.048974
[16:14:32.281] iteration 23836: loss: 0.048836, loss_s1: 0.026060, loss_fp: 0.002055, loss_freq: 0.029102
[16:14:32.900] iteration 23837: loss: 0.058024, loss_s1: 0.064543, loss_fp: 0.002689, loss_freq: 0.008612
[16:14:33.555] iteration 23838: loss: 0.053473, loss_s1: 0.024224, loss_fp: 0.005058, loss_freq: 0.028063
[16:14:34.214] iteration 23839: loss: 0.076148, loss_s1: 0.078808, loss_fp: 0.003721, loss_freq: 0.024760
[16:14:34.873] iteration 23840: loss: 0.083875, loss_s1: 0.064612, loss_fp: 0.004569, loss_freq: 0.058448
[16:14:35.508] iteration 23841: loss: 0.043601, loss_s1: 0.037845, loss_fp: 0.007568, loss_freq: 0.012664
[16:14:36.137] iteration 23842: loss: 0.048318, loss_s1: 0.017966, loss_fp: 0.023651, loss_freq: 0.019372
[16:14:36.774] iteration 23843: loss: 0.045013, loss_s1: 0.035543, loss_fp: 0.002165, loss_freq: 0.012776
[16:14:37.414] iteration 23844: loss: 0.043802, loss_s1: 0.016268, loss_fp: 0.000997, loss_freq: 0.024203
[16:14:38.060] iteration 23845: loss: 0.118462, loss_s1: 0.105213, loss_fp: 0.001711, loss_freq: 0.084848
[16:14:38.699] iteration 23846: loss: 0.029054, loss_s1: 0.008523, loss_fp: 0.002248, loss_freq: 0.014430
[16:14:39.337] iteration 23847: loss: 0.047257, loss_s1: 0.019166, loss_fp: 0.002671, loss_freq: 0.025550
[16:14:39.986] iteration 23848: loss: 0.055979, loss_s1: 0.053995, loss_fp: 0.002445, loss_freq: 0.019219
[16:14:40.631] iteration 23849: loss: 0.043038, loss_s1: 0.031741, loss_fp: 0.001562, loss_freq: 0.012003
[16:14:41.261] iteration 23850: loss: 0.049843, loss_s1: 0.043198, loss_fp: 0.003067, loss_freq: 0.025430
[16:14:41.886] iteration 23851: loss: 0.039907, loss_s1: 0.020371, loss_fp: 0.002635, loss_freq: 0.016099
[16:14:42.505] iteration 23852: loss: 0.052514, loss_s1: 0.050148, loss_fp: 0.005536, loss_freq: 0.016143
[16:14:43.114] iteration 23853: loss: 0.047381, loss_s1: 0.033336, loss_fp: 0.000388, loss_freq: 0.014618
[16:14:43.736] iteration 23854: loss: 0.043113, loss_s1: 0.035867, loss_fp: 0.003001, loss_freq: 0.009281
[16:14:44.359] iteration 23855: loss: 0.057106, loss_s1: 0.029848, loss_fp: 0.011030, loss_freq: 0.029239
[16:14:44.973] iteration 23856: loss: 0.071729, loss_s1: 0.068277, loss_fp: 0.003130, loss_freq: 0.034554
[16:14:45.588] iteration 23857: loss: 0.035706, loss_s1: 0.030446, loss_fp: 0.001334, loss_freq: 0.012879
[16:14:46.203] iteration 23858: loss: 0.054629, loss_s1: 0.030326, loss_fp: 0.005056, loss_freq: 0.037423
[16:14:46.856] iteration 23859: loss: 0.055684, loss_s1: 0.034068, loss_fp: 0.009649, loss_freq: 0.027792
[16:14:47.495] iteration 23860: loss: 0.069432, loss_s1: 0.058056, loss_fp: 0.001566, loss_freq: 0.036210
[16:14:48.135] iteration 23861: loss: 0.031933, loss_s1: 0.018042, loss_fp: 0.003018, loss_freq: 0.007323
[16:14:48.772] iteration 23862: loss: 0.049854, loss_s1: 0.035526, loss_fp: 0.003963, loss_freq: 0.029551
[16:14:49.408] iteration 23863: loss: 0.061659, loss_s1: 0.053059, loss_fp: 0.002303, loss_freq: 0.037341
[16:14:50.030] iteration 23864: loss: 0.059859, loss_s1: 0.031708, loss_fp: 0.002120, loss_freq: 0.017263
[16:14:50.644] iteration 23865: loss: 0.036155, loss_s1: 0.013634, loss_fp: 0.002458, loss_freq: 0.021242
[16:14:51.267] iteration 23866: loss: 0.059606, loss_s1: 0.051185, loss_fp: 0.002488, loss_freq: 0.023935
[16:14:51.890] iteration 23867: loss: 0.053714, loss_s1: 0.033418, loss_fp: 0.018078, loss_freq: 0.019175
[16:14:52.511] iteration 23868: loss: 0.048222, loss_s1: 0.025298, loss_fp: 0.002221, loss_freq: 0.008820
[16:14:53.134] iteration 23869: loss: 0.049697, loss_s1: 0.020015, loss_fp: 0.002318, loss_freq: 0.020483
[16:14:53.751] iteration 23870: loss: 0.054341, loss_s1: 0.015673, loss_fp: 0.003789, loss_freq: 0.045601
[16:14:54.369] iteration 23871: loss: 0.038403, loss_s1: 0.020733, loss_fp: 0.002948, loss_freq: 0.022627
[16:14:54.983] iteration 23872: loss: 0.070876, loss_s1: 0.053749, loss_fp: 0.005914, loss_freq: 0.036982
[16:14:55.606] iteration 23873: loss: 0.062562, loss_s1: 0.036909, loss_fp: 0.007684, loss_freq: 0.019615
[16:14:56.227] iteration 23874: loss: 0.061898, loss_s1: 0.060884, loss_fp: 0.002729, loss_freq: 0.015648
[16:14:56.849] iteration 23875: loss: 0.057161, loss_s1: 0.034672, loss_fp: 0.006711, loss_freq: 0.033519
[16:14:57.471] iteration 23876: loss: 0.031520, loss_s1: 0.018684, loss_fp: 0.001454, loss_freq: 0.012860
[16:14:58.112] iteration 23877: loss: 0.036090, loss_s1: 0.015761, loss_fp: 0.002837, loss_freq: 0.018188
[16:14:58.746] iteration 23878: loss: 0.053085, loss_s1: 0.035923, loss_fp: 0.007189, loss_freq: 0.010318
[16:14:59.375] iteration 23879: loss: 0.059791, loss_s1: 0.038160, loss_fp: 0.007615, loss_freq: 0.026672
[16:14:59.988] iteration 23880: loss: 0.090972, loss_s1: 0.087417, loss_fp: 0.033545, loss_freq: 0.019518
[16:15:00.603] iteration 23881: loss: 0.044715, loss_s1: 0.029874, loss_fp: 0.003065, loss_freq: 0.027134
[16:15:01.548] iteration 23882: loss: 0.043067, loss_s1: 0.018367, loss_fp: 0.001146, loss_freq: 0.013516
[16:15:02.170] iteration 23883: loss: 0.053940, loss_s1: 0.042405, loss_fp: 0.001747, loss_freq: 0.021128
[16:15:02.790] iteration 23884: loss: 0.039972, loss_s1: 0.026381, loss_fp: 0.001720, loss_freq: 0.019544
[16:15:03.453] iteration 23885: loss: 0.075615, loss_s1: 0.071745, loss_fp: 0.003732, loss_freq: 0.027221
[16:15:04.076] iteration 23886: loss: 0.045464, loss_s1: 0.049239, loss_fp: 0.000459, loss_freq: 0.013590
[16:15:04.703] iteration 23887: loss: 0.040353, loss_s1: 0.019205, loss_fp: 0.006381, loss_freq: 0.006310
[16:15:05.376] iteration 23888: loss: 0.048366, loss_s1: 0.031244, loss_fp: 0.004536, loss_freq: 0.029266
[16:15:06.034] iteration 23889: loss: 0.065990, loss_s1: 0.068037, loss_fp: 0.004520, loss_freq: 0.010266
[16:15:06.658] iteration 23890: loss: 0.079736, loss_s1: 0.064227, loss_fp: 0.008541, loss_freq: 0.037367
[16:15:07.287] iteration 23891: loss: 0.043203, loss_s1: 0.018823, loss_fp: 0.004177, loss_freq: 0.005085
[16:15:07.905] iteration 23892: loss: 0.055373, loss_s1: 0.040891, loss_fp: 0.007873, loss_freq: 0.017632
[16:15:08.526] iteration 23893: loss: 0.040719, loss_s1: 0.026465, loss_fp: 0.003516, loss_freq: 0.008429
[16:15:09.153] iteration 23894: loss: 0.050420, loss_s1: 0.038584, loss_fp: 0.001348, loss_freq: 0.012392
[16:15:09.771] iteration 23895: loss: 0.040673, loss_s1: 0.025307, loss_fp: 0.001335, loss_freq: 0.021501
[16:15:10.389] iteration 23896: loss: 0.074008, loss_s1: 0.084509, loss_fp: 0.000653, loss_freq: 0.027030
[16:15:11.082] iteration 23897: loss: 0.050558, loss_s1: 0.044361, loss_fp: 0.001538, loss_freq: 0.011866
[16:15:11.721] iteration 23898: loss: 0.074286, loss_s1: 0.051935, loss_fp: 0.002638, loss_freq: 0.056179
[16:15:12.376] iteration 23899: loss: 0.047017, loss_s1: 0.033902, loss_fp: 0.002014, loss_freq: 0.018063
[16:15:12.995] iteration 23900: loss: 0.069486, loss_s1: 0.055495, loss_fp: 0.009172, loss_freq: 0.043392
[16:15:13.622] iteration 23901: loss: 0.028007, loss_s1: 0.009579, loss_fp: 0.003231, loss_freq: 0.015555
[16:15:14.251] iteration 23902: loss: 0.116003, loss_s1: 0.088365, loss_fp: 0.003044, loss_freq: 0.074158
[16:15:14.915] iteration 23903: loss: 0.043266, loss_s1: 0.028044, loss_fp: 0.001459, loss_freq: 0.025516
[16:15:15.540] iteration 23904: loss: 0.040308, loss_s1: 0.017632, loss_fp: 0.001892, loss_freq: 0.021239
[16:15:16.168] iteration 23905: loss: 0.030246, loss_s1: 0.014287, loss_fp: 0.002962, loss_freq: 0.005964
[16:15:16.800] iteration 23906: loss: 0.056546, loss_s1: 0.041699, loss_fp: 0.001285, loss_freq: 0.024176
[16:15:17.424] iteration 23907: loss: 0.061240, loss_s1: 0.043550, loss_fp: 0.002056, loss_freq: 0.008117
[16:15:18.044] iteration 23908: loss: 0.089884, loss_s1: 0.088097, loss_fp: 0.002890, loss_freq: 0.049529
[16:15:18.683] iteration 23909: loss: 0.042893, loss_s1: 0.040235, loss_fp: 0.002481, loss_freq: 0.008443
[16:15:19.310] iteration 23910: loss: 0.046175, loss_s1: 0.027553, loss_fp: 0.001548, loss_freq: 0.026384
[16:15:19.928] iteration 23911: loss: 0.038120, loss_s1: 0.020333, loss_fp: 0.005071, loss_freq: 0.006846
[16:15:20.545] iteration 23912: loss: 0.033158, loss_s1: 0.016613, loss_fp: 0.003430, loss_freq: 0.005626
[16:15:21.164] iteration 23913: loss: 0.048346, loss_s1: 0.027917, loss_fp: 0.002495, loss_freq: 0.014170
[16:15:21.779] iteration 23914: loss: 0.086879, loss_s1: 0.099364, loss_fp: 0.025562, loss_freq: 0.021619
[16:15:22.399] iteration 23915: loss: 0.067655, loss_s1: 0.063248, loss_fp: 0.008516, loss_freq: 0.029481
[16:15:23.102] iteration 23916: loss: 0.068333, loss_s1: 0.049412, loss_fp: 0.005903, loss_freq: 0.018188
[16:15:23.757] iteration 23917: loss: 0.058383, loss_s1: 0.068103, loss_fp: 0.003200, loss_freq: 0.011836
[16:15:24.382] iteration 23918: loss: 0.061382, loss_s1: 0.045577, loss_fp: 0.005193, loss_freq: 0.029283
[16:15:25.004] iteration 23919: loss: 0.041982, loss_s1: 0.029790, loss_fp: 0.004571, loss_freq: 0.018318
[16:15:25.624] iteration 23920: loss: 0.073838, loss_s1: 0.042038, loss_fp: 0.005990, loss_freq: 0.058893
[16:15:26.244] iteration 23921: loss: 0.023773, loss_s1: 0.007028, loss_fp: 0.002552, loss_freq: 0.013325
[16:15:26.882] iteration 23922: loss: 0.045183, loss_s1: 0.016071, loss_fp: 0.000836, loss_freq: 0.028420
[16:15:27.542] iteration 23923: loss: 0.032779, loss_s1: 0.010740, loss_fp: 0.003598, loss_freq: 0.025783
[16:15:28.170] iteration 23924: loss: 0.042059, loss_s1: 0.024119, loss_fp: 0.003169, loss_freq: 0.011170
[16:15:28.827] iteration 23925: loss: 0.080966, loss_s1: 0.085265, loss_fp: 0.005461, loss_freq: 0.030421
[16:15:29.535] iteration 23926: loss: 0.046057, loss_s1: 0.008081, loss_fp: 0.003757, loss_freq: 0.005219
[16:15:30.175] iteration 23927: loss: 0.054021, loss_s1: 0.037562, loss_fp: 0.002101, loss_freq: 0.036294
[16:15:30.790] iteration 23928: loss: 0.060166, loss_s1: 0.024456, loss_fp: 0.003453, loss_freq: 0.044418
[16:15:31.412] iteration 23929: loss: 0.042173, loss_s1: 0.033202, loss_fp: 0.001553, loss_freq: 0.009824
[16:15:32.034] iteration 23930: loss: 0.052181, loss_s1: 0.030957, loss_fp: 0.002376, loss_freq: 0.032432
[16:15:32.663] iteration 23931: loss: 0.047897, loss_s1: 0.033507, loss_fp: 0.001200, loss_freq: 0.012336
[16:15:33.288] iteration 23932: loss: 0.054657, loss_s1: 0.038348, loss_fp: 0.001849, loss_freq: 0.029380
[16:15:33.903] iteration 23933: loss: 0.049042, loss_s1: 0.030749, loss_fp: 0.004574, loss_freq: 0.020487
[16:15:34.528] iteration 23934: loss: 0.045725, loss_s1: 0.019337, loss_fp: 0.002943, loss_freq: 0.014036
[16:15:35.153] iteration 23935: loss: 0.052969, loss_s1: 0.046326, loss_fp: 0.001166, loss_freq: 0.022743
[16:15:35.774] iteration 23936: loss: 0.038617, loss_s1: 0.040472, loss_fp: 0.002667, loss_freq: 0.009555
[16:15:36.392] iteration 23937: loss: 0.056327, loss_s1: 0.022145, loss_fp: 0.001980, loss_freq: 0.012810
[16:15:37.009] iteration 23938: loss: 0.061529, loss_s1: 0.022920, loss_fp: 0.020752, loss_freq: 0.016818
[16:15:37.638] iteration 23939: loss: 0.046841, loss_s1: 0.025968, loss_fp: 0.003215, loss_freq: 0.021696
[16:15:38.258] iteration 23940: loss: 0.061967, loss_s1: 0.027648, loss_fp: 0.003214, loss_freq: 0.053853
[16:15:38.874] iteration 23941: loss: 0.067523, loss_s1: 0.047199, loss_fp: 0.026397, loss_freq: 0.026467
[16:15:39.488] iteration 23942: loss: 0.048397, loss_s1: 0.044585, loss_fp: 0.003475, loss_freq: 0.011980
[16:15:40.115] iteration 23943: loss: 0.045699, loss_s1: 0.029599, loss_fp: 0.003663, loss_freq: 0.019373
[16:15:40.733] iteration 23944: loss: 0.064072, loss_s1: 0.034152, loss_fp: 0.007758, loss_freq: 0.025058
[16:15:41.355] iteration 23945: loss: 0.069150, loss_s1: 0.043994, loss_fp: 0.003478, loss_freq: 0.020602
[16:15:41.978] iteration 23946: loss: 0.065604, loss_s1: 0.071751, loss_fp: 0.001368, loss_freq: 0.011832
[16:15:42.602] iteration 23947: loss: 0.062985, loss_s1: 0.064833, loss_fp: 0.001391, loss_freq: 0.022369
[16:15:43.224] iteration 23948: loss: 0.082598, loss_s1: 0.092509, loss_fp: 0.004854, loss_freq: 0.030900
[16:15:43.853] iteration 23949: loss: 0.052603, loss_s1: 0.033154, loss_fp: 0.006701, loss_freq: 0.030071
[16:15:44.486] iteration 23950: loss: 0.045336, loss_s1: 0.035451, loss_fp: 0.001654, loss_freq: 0.008802
[16:15:45.111] iteration 23951: loss: 0.052007, loss_s1: 0.019040, loss_fp: 0.004186, loss_freq: 0.018449
[16:15:45.737] iteration 23952: loss: 0.052542, loss_s1: 0.049995, loss_fp: 0.001333, loss_freq: 0.013473
[16:15:46.357] iteration 23953: loss: 0.063965, loss_s1: 0.049292, loss_fp: 0.002448, loss_freq: 0.022122
[16:15:46.978] iteration 23954: loss: 0.077944, loss_s1: 0.046892, loss_fp: 0.003253, loss_freq: 0.077035
[16:15:47.598] iteration 23955: loss: 0.056554, loss_s1: 0.041044, loss_fp: 0.003859, loss_freq: 0.013887
[16:15:48.228] iteration 23956: loss: 0.051849, loss_s1: 0.027217, loss_fp: 0.006579, loss_freq: 0.046109
[16:15:48.845] iteration 23957: loss: 0.032908, loss_s1: 0.019488, loss_fp: 0.002174, loss_freq: 0.013391
[16:15:49.467] iteration 23958: loss: 0.035973, loss_s1: 0.033363, loss_fp: 0.001058, loss_freq: 0.010541
[16:15:50.091] iteration 23959: loss: 0.060852, loss_s1: 0.065116, loss_fp: 0.000548, loss_freq: 0.011799
[16:15:50.715] iteration 23960: loss: 0.063999, loss_s1: 0.050931, loss_fp: 0.018683, loss_freq: 0.015222
[16:15:51.336] iteration 23961: loss: 0.112410, loss_s1: 0.054270, loss_fp: 0.037985, loss_freq: 0.040596
[16:15:51.959] iteration 23962: loss: 0.045969, loss_s1: 0.031610, loss_fp: 0.000984, loss_freq: 0.011851
[16:15:52.585] iteration 23963: loss: 0.092244, loss_s1: 0.073684, loss_fp: 0.007987, loss_freq: 0.049179
[16:15:53.195] iteration 23964: loss: 0.040176, loss_s1: 0.014542, loss_fp: 0.002406, loss_freq: 0.021434
[16:15:53.811] iteration 23965: loss: 0.044821, loss_s1: 0.035517, loss_fp: 0.001212, loss_freq: 0.013107
[16:15:54.429] iteration 23966: loss: 0.054154, loss_s1: 0.036719, loss_fp: 0.009303, loss_freq: 0.022746
[16:15:55.050] iteration 23967: loss: 0.060890, loss_s1: 0.047985, loss_fp: 0.004438, loss_freq: 0.035251
[16:15:55.660] iteration 23968: loss: 0.050742, loss_s1: 0.015248, loss_fp: 0.002380, loss_freq: 0.031960
[16:15:56.278] iteration 23969: loss: 0.045408, loss_s1: 0.035296, loss_fp: 0.000509, loss_freq: 0.019001
[16:15:56.899] iteration 23970: loss: 0.048644, loss_s1: 0.027102, loss_fp: 0.002378, loss_freq: 0.009565
[16:15:57.528] iteration 23971: loss: 0.060682, loss_s1: 0.041580, loss_fp: 0.004989, loss_freq: 0.021601
[16:15:58.138] iteration 23972: loss: 0.072006, loss_s1: 0.021495, loss_fp: 0.003226, loss_freq: 0.025164
[16:15:58.761] iteration 23973: loss: 0.043717, loss_s1: 0.025417, loss_fp: 0.003339, loss_freq: 0.020593
[16:15:59.381] iteration 23974: loss: 0.047957, loss_s1: 0.051778, loss_fp: 0.002386, loss_freq: 0.004446
[16:16:00.011] iteration 23975: loss: 0.037424, loss_s1: 0.021759, loss_fp: 0.001840, loss_freq: 0.012324
[16:16:00.630] iteration 23976: loss: 0.051669, loss_s1: 0.032559, loss_fp: 0.000965, loss_freq: 0.022243
[16:16:01.255] iteration 23977: loss: 0.052255, loss_s1: 0.039290, loss_fp: 0.003631, loss_freq: 0.008845
[16:16:01.875] iteration 23978: loss: 0.071942, loss_s1: 0.021641, loss_fp: 0.010091, loss_freq: 0.068365
[16:16:02.497] iteration 23979: loss: 0.043145, loss_s1: 0.019833, loss_fp: 0.007941, loss_freq: 0.015570
[16:16:03.115] iteration 23980: loss: 0.044269, loss_s1: 0.026996, loss_fp: 0.005293, loss_freq: 0.012914
[16:16:03.751] iteration 23981: loss: 0.067266, loss_s1: 0.024315, loss_fp: 0.003326, loss_freq: 0.046495
[16:16:04.424] iteration 23982: loss: 0.039962, loss_s1: 0.034441, loss_fp: 0.000906, loss_freq: 0.006566
[16:16:05.042] iteration 23983: loss: 0.062646, loss_s1: 0.027888, loss_fp: 0.008075, loss_freq: 0.035008
[16:16:05.658] iteration 23984: loss: 0.057033, loss_s1: 0.059391, loss_fp: 0.002662, loss_freq: 0.023174
[16:16:06.281] iteration 23985: loss: 0.039472, loss_s1: 0.010845, loss_fp: 0.017047, loss_freq: 0.012065
[16:16:06.897] iteration 23986: loss: 0.061445, loss_s1: 0.040471, loss_fp: 0.002877, loss_freq: 0.013173
[16:16:07.528] iteration 23987: loss: 0.050475, loss_s1: 0.031291, loss_fp: 0.007601, loss_freq: 0.020193
[16:16:08.155] iteration 23988: loss: 0.065785, loss_s1: 0.044992, loss_fp: 0.007740, loss_freq: 0.033704
[16:16:08.784] iteration 23989: loss: 0.064302, loss_s1: 0.023600, loss_fp: 0.004971, loss_freq: 0.065445
[16:16:09.405] iteration 23990: loss: 0.050800, loss_s1: 0.031459, loss_fp: 0.004262, loss_freq: 0.019643
[16:16:10.026] iteration 23991: loss: 0.070587, loss_s1: 0.060412, loss_fp: 0.002435, loss_freq: 0.043703
[16:16:10.649] iteration 23992: loss: 0.048218, loss_s1: 0.042580, loss_fp: 0.002103, loss_freq: 0.015317
[16:16:11.270] iteration 23993: loss: 0.062966, loss_s1: 0.041759, loss_fp: 0.002144, loss_freq: 0.053024
[16:16:11.894] iteration 23994: loss: 0.049088, loss_s1: 0.038829, loss_fp: 0.001678, loss_freq: 0.013313
[16:16:12.514] iteration 23995: loss: 0.046491, loss_s1: 0.023543, loss_fp: 0.008037, loss_freq: 0.019998
[16:16:13.154] iteration 23996: loss: 0.072468, loss_s1: 0.046380, loss_fp: 0.008484, loss_freq: 0.022627
[16:16:13.796] iteration 23997: loss: 0.037154, loss_s1: 0.026924, loss_fp: 0.002562, loss_freq: 0.012533
[16:16:14.438] iteration 23998: loss: 0.047488, loss_s1: 0.044250, loss_fp: 0.003503, loss_freq: 0.010362
[16:16:15.060] iteration 23999: loss: 0.068963, loss_s1: 0.078044, loss_fp: 0.001301, loss_freq: 0.023828
[16:16:15.682] iteration 24000: loss: 0.041485, loss_s1: 0.042613, loss_fp: 0.001188, loss_freq: 0.008102
[16:16:19.018] iteration 24000 : mean_dice : 0.788519
[16:16:19.680] iteration 24001: loss: 0.051817, loss_s1: 0.047926, loss_fp: 0.000759, loss_freq: 0.013979
[16:16:20.297] iteration 24002: loss: 0.060648, loss_s1: 0.039106, loss_fp: 0.006174, loss_freq: 0.042359
[16:16:20.954] iteration 24003: loss: 0.053197, loss_s1: 0.033777, loss_fp: 0.001307, loss_freq: 0.024777
[16:16:21.570] iteration 24004: loss: 0.051172, loss_s1: 0.050175, loss_fp: 0.007824, loss_freq: 0.010732
[16:16:22.182] iteration 24005: loss: 0.048140, loss_s1: 0.049732, loss_fp: 0.004423, loss_freq: 0.017496
[16:16:22.803] iteration 24006: loss: 0.052302, loss_s1: 0.042349, loss_fp: 0.003144, loss_freq: 0.031942
[16:16:23.423] iteration 24007: loss: 0.049116, loss_s1: 0.032999, loss_fp: 0.002120, loss_freq: 0.011143
[16:16:24.044] iteration 24008: loss: 0.032571, loss_s1: 0.004853, loss_fp: 0.001498, loss_freq: 0.022570
[16:16:24.676] iteration 24009: loss: 0.056307, loss_s1: 0.032057, loss_fp: 0.015091, loss_freq: 0.018111
[16:16:25.300] iteration 24010: loss: 0.046834, loss_s1: 0.045747, loss_fp: 0.003536, loss_freq: 0.007996
[16:16:25.927] iteration 24011: loss: 0.036506, loss_s1: 0.022965, loss_fp: 0.001359, loss_freq: 0.014259
[16:16:26.550] iteration 24012: loss: 0.056219, loss_s1: 0.034599, loss_fp: 0.006047, loss_freq: 0.026330
[16:16:27.164] iteration 24013: loss: 0.085670, loss_s1: 0.023801, loss_fp: 0.010251, loss_freq: 0.029712
[16:16:27.788] iteration 24014: loss: 0.061505, loss_s1: 0.048049, loss_fp: 0.008619, loss_freq: 0.027835
[16:16:28.412] iteration 24015: loss: 0.068487, loss_s1: 0.033070, loss_fp: 0.001720, loss_freq: 0.054540
[16:16:29.027] iteration 24016: loss: 0.087002, loss_s1: 0.028733, loss_fp: 0.002445, loss_freq: 0.041409
[16:16:29.687] iteration 24017: loss: 0.061474, loss_s1: 0.056231, loss_fp: 0.004484, loss_freq: 0.029891
[16:16:30.342] iteration 24018: loss: 0.054812, loss_s1: 0.044259, loss_fp: 0.005333, loss_freq: 0.015647
[16:16:30.979] iteration 24019: loss: 0.040351, loss_s1: 0.011493, loss_fp: 0.001561, loss_freq: 0.021292
[16:16:31.618] iteration 24020: loss: 0.040325, loss_s1: 0.034096, loss_fp: 0.004149, loss_freq: 0.007186
[16:16:32.250] iteration 24021: loss: 0.050503, loss_s1: 0.015777, loss_fp: 0.006895, loss_freq: 0.018095
[16:16:32.886] iteration 24022: loss: 0.063973, loss_s1: 0.036130, loss_fp: 0.001879, loss_freq: 0.051538
[16:16:33.519] iteration 24023: loss: 0.069705, loss_s1: 0.071257, loss_fp: 0.003820, loss_freq: 0.016507
[16:16:34.159] iteration 24024: loss: 0.041144, loss_s1: 0.007406, loss_fp: 0.011242, loss_freq: 0.022399
[16:16:35.128] iteration 24025: loss: 0.044721, loss_s1: 0.026052, loss_fp: 0.003933, loss_freq: 0.009420
[16:16:35.770] iteration 24026: loss: 0.049925, loss_s1: 0.027046, loss_fp: 0.003010, loss_freq: 0.021539
[16:16:36.414] iteration 24027: loss: 0.043068, loss_s1: 0.029063, loss_fp: 0.002174, loss_freq: 0.018510
[16:16:37.064] iteration 24028: loss: 0.056449, loss_s1: 0.043569, loss_fp: 0.005731, loss_freq: 0.020388
[16:16:37.696] iteration 24029: loss: 0.051157, loss_s1: 0.027714, loss_fp: 0.002669, loss_freq: 0.040244
[16:16:38.363] iteration 24030: loss: 0.040150, loss_s1: 0.028974, loss_fp: 0.009117, loss_freq: 0.008271
[16:16:39.007] iteration 24031: loss: 0.042986, loss_s1: 0.033876, loss_fp: 0.003625, loss_freq: 0.018094
[16:16:39.643] iteration 24032: loss: 0.078736, loss_s1: 0.067059, loss_fp: 0.013473, loss_freq: 0.033586
[16:16:40.281] iteration 24033: loss: 0.047784, loss_s1: 0.034514, loss_fp: 0.007397, loss_freq: 0.006246
[16:16:40.909] iteration 24034: loss: 0.042353, loss_s1: 0.022796, loss_fp: 0.001217, loss_freq: 0.011463
[16:16:41.541] iteration 24035: loss: 0.050815, loss_s1: 0.027247, loss_fp: 0.001577, loss_freq: 0.025652
[16:16:42.164] iteration 24036: loss: 0.041907, loss_s1: 0.020956, loss_fp: 0.001809, loss_freq: 0.015853
[16:16:42.777] iteration 24037: loss: 0.067183, loss_s1: 0.052004, loss_fp: 0.002719, loss_freq: 0.045106
[16:16:43.402] iteration 24038: loss: 0.034654, loss_s1: 0.022402, loss_fp: 0.001847, loss_freq: 0.014796
[16:16:44.019] iteration 24039: loss: 0.052146, loss_s1: 0.048175, loss_fp: 0.000426, loss_freq: 0.016151
[16:16:44.644] iteration 24040: loss: 0.052258, loss_s1: 0.052738, loss_fp: 0.003638, loss_freq: 0.014926
[16:16:45.262] iteration 24041: loss: 0.048775, loss_s1: 0.015065, loss_fp: 0.000898, loss_freq: 0.048376
[16:16:45.883] iteration 24042: loss: 0.058988, loss_s1: 0.044004, loss_fp: 0.010295, loss_freq: 0.028633
[16:16:46.531] iteration 24043: loss: 0.040083, loss_s1: 0.031959, loss_fp: 0.000707, loss_freq: 0.014605
[16:16:47.151] iteration 24044: loss: 0.042042, loss_s1: 0.032674, loss_fp: 0.003581, loss_freq: 0.015098
[16:16:47.826] iteration 24045: loss: 0.084884, loss_s1: 0.062403, loss_fp: 0.003581, loss_freq: 0.030130
[16:16:48.446] iteration 24046: loss: 0.065645, loss_s1: 0.066089, loss_fp: 0.008860, loss_freq: 0.019626
[16:16:49.085] iteration 24047: loss: 0.057504, loss_s1: 0.030593, loss_fp: 0.001205, loss_freq: 0.047468
[16:16:49.697] iteration 24048: loss: 0.039728, loss_s1: 0.025003, loss_fp: 0.001557, loss_freq: 0.011005
[16:16:50.324] iteration 24049: loss: 0.041687, loss_s1: 0.035384, loss_fp: 0.001679, loss_freq: 0.006610
[16:16:50.955] iteration 24050: loss: 0.055252, loss_s1: 0.020480, loss_fp: 0.005800, loss_freq: 0.047629
[16:16:51.569] iteration 24051: loss: 0.057974, loss_s1: 0.037221, loss_fp: 0.002020, loss_freq: 0.036643
[16:16:52.190] iteration 24052: loss: 0.036268, loss_s1: 0.025438, loss_fp: 0.004814, loss_freq: 0.012429
[16:16:52.812] iteration 24053: loss: 0.030288, loss_s1: 0.006968, loss_fp: 0.000926, loss_freq: 0.016582
[16:16:53.430] iteration 24054: loss: 0.035942, loss_s1: 0.013577, loss_fp: 0.001368, loss_freq: 0.018660
[16:16:54.051] iteration 24055: loss: 0.034571, loss_s1: 0.024294, loss_fp: 0.002156, loss_freq: 0.012004
[16:16:54.679] iteration 24056: loss: 0.055642, loss_s1: 0.025471, loss_fp: 0.005823, loss_freq: 0.029458
[16:16:55.290] iteration 24057: loss: 0.098659, loss_s1: 0.078453, loss_fp: 0.033169, loss_freq: 0.050524
[16:16:55.911] iteration 24058: loss: 0.102267, loss_s1: 0.105626, loss_fp: 0.018562, loss_freq: 0.039107
[16:16:56.531] iteration 24059: loss: 0.064751, loss_s1: 0.055000, loss_fp: 0.004142, loss_freq: 0.029526
[16:16:57.152] iteration 24060: loss: 0.046475, loss_s1: 0.041915, loss_fp: 0.002181, loss_freq: 0.011452
[16:16:57.769] iteration 24061: loss: 0.039243, loss_s1: 0.008631, loss_fp: 0.001637, loss_freq: 0.023361
[16:16:58.391] iteration 24062: loss: 0.079999, loss_s1: 0.067839, loss_fp: 0.021647, loss_freq: 0.042045
[16:16:59.005] iteration 24063: loss: 0.100129, loss_s1: 0.082778, loss_fp: 0.017676, loss_freq: 0.045958
[16:16:59.624] iteration 24064: loss: 0.036042, loss_s1: 0.029776, loss_fp: 0.002706, loss_freq: 0.011663
[16:17:00.242] iteration 24065: loss: 0.059220, loss_s1: 0.044195, loss_fp: 0.011052, loss_freq: 0.007158
[16:17:00.904] iteration 24066: loss: 0.041508, loss_s1: 0.031424, loss_fp: 0.002054, loss_freq: 0.023447
[16:17:01.598] iteration 24067: loss: 0.055875, loss_s1: 0.032045, loss_fp: 0.003103, loss_freq: 0.030453
[16:17:02.277] iteration 24068: loss: 0.094617, loss_s1: 0.102237, loss_fp: 0.006872, loss_freq: 0.037952
[16:17:02.922] iteration 24069: loss: 0.062415, loss_s1: 0.023668, loss_fp: 0.007026, loss_freq: 0.021851
[16:17:03.556] iteration 24070: loss: 0.054252, loss_s1: 0.032509, loss_fp: 0.003202, loss_freq: 0.034420
[16:17:04.188] iteration 24071: loss: 0.060822, loss_s1: 0.047016, loss_fp: 0.001441, loss_freq: 0.033575
[16:17:04.819] iteration 24072: loss: 0.048335, loss_s1: 0.021669, loss_fp: 0.002759, loss_freq: 0.028508
[16:17:05.440] iteration 24073: loss: 0.050769, loss_s1: 0.040271, loss_fp: 0.003138, loss_freq: 0.027852
[16:17:06.057] iteration 24074: loss: 0.053602, loss_s1: 0.042062, loss_fp: 0.002854, loss_freq: 0.014551
[16:17:06.676] iteration 24075: loss: 0.092968, loss_s1: 0.083009, loss_fp: 0.005853, loss_freq: 0.046294
[16:17:07.288] iteration 24076: loss: 0.048402, loss_s1: 0.025164, loss_fp: 0.007321, loss_freq: 0.029861
[16:17:07.910] iteration 24077: loss: 0.056524, loss_s1: 0.026609, loss_fp: 0.004026, loss_freq: 0.021034
[16:17:08.535] iteration 24078: loss: 0.060235, loss_s1: 0.037125, loss_fp: 0.006437, loss_freq: 0.034343
[16:17:09.151] iteration 24079: loss: 0.023917, loss_s1: 0.013982, loss_fp: 0.002020, loss_freq: 0.007120
[16:17:09.774] iteration 24080: loss: 0.049734, loss_s1: 0.034791, loss_fp: 0.001651, loss_freq: 0.010321
[16:17:10.401] iteration 24081: loss: 0.073766, loss_s1: 0.085897, loss_fp: 0.002607, loss_freq: 0.026661
[16:17:11.014] iteration 24082: loss: 0.057599, loss_s1: 0.036661, loss_fp: 0.013107, loss_freq: 0.014024
[16:17:11.630] iteration 24083: loss: 0.050043, loss_s1: 0.033230, loss_fp: 0.000463, loss_freq: 0.025724
[16:17:12.239] iteration 24084: loss: 0.053948, loss_s1: 0.033079, loss_fp: 0.008585, loss_freq: 0.022794
[16:17:12.854] iteration 24085: loss: 0.059437, loss_s1: 0.036768, loss_fp: 0.004064, loss_freq: 0.038811
[16:17:13.473] iteration 24086: loss: 0.063660, loss_s1: 0.035433, loss_fp: 0.005615, loss_freq: 0.034740
[16:17:14.090] iteration 24087: loss: 0.034395, loss_s1: 0.022591, loss_fp: 0.006237, loss_freq: 0.005643
[16:17:14.729] iteration 24088: loss: 0.055827, loss_s1: 0.028821, loss_fp: 0.004262, loss_freq: 0.022579
[16:17:15.352] iteration 24089: loss: 0.051663, loss_s1: 0.041667, loss_fp: 0.002575, loss_freq: 0.014523
[16:17:16.029] iteration 24090: loss: 0.039475, loss_s1: 0.021090, loss_fp: 0.002105, loss_freq: 0.019629
[16:17:16.668] iteration 24091: loss: 0.078231, loss_s1: 0.056913, loss_fp: 0.002744, loss_freq: 0.020584
[16:17:17.316] iteration 24092: loss: 0.050488, loss_s1: 0.044150, loss_fp: 0.002664, loss_freq: 0.024428
[16:17:17.962] iteration 24093: loss: 0.035017, loss_s1: 0.018584, loss_fp: 0.001351, loss_freq: 0.008127
[16:17:18.591] iteration 24094: loss: 0.043401, loss_s1: 0.035093, loss_fp: 0.000944, loss_freq: 0.008690
[16:17:19.239] iteration 24095: loss: 0.041436, loss_s1: 0.028192, loss_fp: 0.004249, loss_freq: 0.012257
[16:17:19.855] iteration 24096: loss: 0.064945, loss_s1: 0.039238, loss_fp: 0.002334, loss_freq: 0.032022
[16:17:20.479] iteration 24097: loss: 0.042204, loss_s1: 0.019680, loss_fp: 0.004314, loss_freq: 0.019469
[16:17:21.107] iteration 24098: loss: 0.117554, loss_s1: 0.137714, loss_fp: 0.010280, loss_freq: 0.035250
[16:17:21.724] iteration 24099: loss: 0.075464, loss_s1: 0.063810, loss_fp: 0.012398, loss_freq: 0.047625
[16:17:22.358] iteration 24100: loss: 0.039070, loss_s1: 0.018284, loss_fp: 0.001628, loss_freq: 0.012326
[16:17:22.986] iteration 24101: loss: 0.054255, loss_s1: 0.038882, loss_fp: 0.003905, loss_freq: 0.034635
[16:17:23.605] iteration 24102: loss: 0.036609, loss_s1: 0.017875, loss_fp: 0.003272, loss_freq: 0.007432
[16:17:24.228] iteration 24103: loss: 0.038715, loss_s1: 0.018332, loss_fp: 0.002001, loss_freq: 0.020417
[16:17:24.857] iteration 24104: loss: 0.110519, loss_s1: 0.067011, loss_fp: 0.017937, loss_freq: 0.040317
[16:17:25.479] iteration 24105: loss: 0.063962, loss_s1: 0.041109, loss_fp: 0.001356, loss_freq: 0.009873
[16:17:26.097] iteration 24106: loss: 0.062206, loss_s1: 0.044508, loss_fp: 0.002160, loss_freq: 0.032478
[16:17:26.711] iteration 24107: loss: 0.043793, loss_s1: 0.034207, loss_fp: 0.001795, loss_freq: 0.013981
[16:17:27.360] iteration 24108: loss: 0.037231, loss_s1: 0.028398, loss_fp: 0.002339, loss_freq: 0.008762
[16:17:28.005] iteration 24109: loss: 0.044823, loss_s1: 0.027356, loss_fp: 0.002529, loss_freq: 0.019348
[16:17:28.621] iteration 24110: loss: 0.060756, loss_s1: 0.044978, loss_fp: 0.004431, loss_freq: 0.033897
[16:17:29.250] iteration 24111: loss: 0.032694, loss_s1: 0.011586, loss_fp: 0.004499, loss_freq: 0.008390
[16:17:29.873] iteration 24112: loss: 0.053197, loss_s1: 0.023373, loss_fp: 0.000336, loss_freq: 0.014465
[16:17:30.505] iteration 24113: loss: 0.032017, loss_s1: 0.025255, loss_fp: 0.002919, loss_freq: 0.006324
[16:17:31.122] iteration 24114: loss: 0.050147, loss_s1: 0.036365, loss_fp: 0.002981, loss_freq: 0.012287
[16:17:31.806] iteration 24115: loss: 0.051567, loss_s1: 0.021509, loss_fp: 0.001804, loss_freq: 0.010486
[16:17:32.437] iteration 24116: loss: 0.035603, loss_s1: 0.017320, loss_fp: 0.003719, loss_freq: 0.009993
[16:17:33.122] iteration 24117: loss: 0.062006, loss_s1: 0.072015, loss_fp: 0.003697, loss_freq: 0.010062
[16:17:33.752] iteration 24118: loss: 0.039965, loss_s1: 0.025408, loss_fp: 0.002000, loss_freq: 0.009893
[16:17:34.366] iteration 24119: loss: 0.042548, loss_s1: 0.019647, loss_fp: 0.001029, loss_freq: 0.025123
[16:17:34.995] iteration 24120: loss: 0.069857, loss_s1: 0.035081, loss_fp: 0.007794, loss_freq: 0.016124
[16:17:35.622] iteration 24121: loss: 0.103822, loss_s1: 0.127165, loss_fp: 0.002779, loss_freq: 0.036124
[16:17:36.246] iteration 24122: loss: 0.056863, loss_s1: 0.042893, loss_fp: 0.000769, loss_freq: 0.034039
[16:17:36.869] iteration 24123: loss: 0.046053, loss_s1: 0.033122, loss_fp: 0.001445, loss_freq: 0.021498
[16:17:37.541] iteration 24124: loss: 0.048781, loss_s1: 0.033579, loss_fp: 0.001597, loss_freq: 0.021113
[16:17:38.186] iteration 24125: loss: 0.049811, loss_s1: 0.026602, loss_fp: 0.005873, loss_freq: 0.023154
[16:17:38.812] iteration 24126: loss: 0.059530, loss_s1: 0.041603, loss_fp: 0.012118, loss_freq: 0.015862
[16:17:39.433] iteration 24127: loss: 0.072759, loss_s1: 0.063057, loss_fp: 0.018099, loss_freq: 0.033555
[16:17:40.068] iteration 24128: loss: 0.041806, loss_s1: 0.022407, loss_fp: 0.008829, loss_freq: 0.020330
[16:17:40.699] iteration 24129: loss: 0.071172, loss_s1: 0.053800, loss_fp: 0.001281, loss_freq: 0.029397
[16:17:41.332] iteration 24130: loss: 0.052742, loss_s1: 0.039043, loss_fp: 0.005341, loss_freq: 0.024675
[16:17:41.957] iteration 24131: loss: 0.073169, loss_s1: 0.026041, loss_fp: 0.011380, loss_freq: 0.068025
[16:17:42.584] iteration 24132: loss: 0.053694, loss_s1: 0.022191, loss_fp: 0.008017, loss_freq: 0.050830
[16:17:43.212] iteration 24133: loss: 0.057646, loss_s1: 0.027439, loss_fp: 0.004564, loss_freq: 0.037876
[16:17:43.835] iteration 24134: loss: 0.062131, loss_s1: 0.027099, loss_fp: 0.012360, loss_freq: 0.025521
[16:17:44.456] iteration 24135: loss: 0.037801, loss_s1: 0.023018, loss_fp: 0.004191, loss_freq: 0.012523
[16:17:45.081] iteration 24136: loss: 0.048352, loss_s1: 0.028804, loss_fp: 0.002458, loss_freq: 0.035782
[16:17:45.703] iteration 24137: loss: 0.034337, loss_s1: 0.015147, loss_fp: 0.000711, loss_freq: 0.005479
[16:17:46.332] iteration 24138: loss: 0.088929, loss_s1: 0.068234, loss_fp: 0.006267, loss_freq: 0.055471
[16:17:46.955] iteration 24139: loss: 0.041206, loss_s1: 0.009958, loss_fp: 0.001156, loss_freq: 0.009902
[16:17:47.583] iteration 24140: loss: 0.065844, loss_s1: 0.065066, loss_fp: 0.001776, loss_freq: 0.008421
[16:17:48.208] iteration 24141: loss: 0.068502, loss_s1: 0.054800, loss_fp: 0.006857, loss_freq: 0.036744
[16:17:48.839] iteration 24142: loss: 0.083116, loss_s1: 0.077930, loss_fp: 0.002527, loss_freq: 0.032974
[16:17:49.476] iteration 24143: loss: 0.036665, loss_s1: 0.025163, loss_fp: 0.008822, loss_freq: 0.012056
[16:17:50.135] iteration 24144: loss: 0.054254, loss_s1: 0.052121, loss_fp: 0.003244, loss_freq: 0.011884
[16:17:50.759] iteration 24145: loss: 0.081237, loss_s1: 0.061131, loss_fp: 0.012444, loss_freq: 0.051979
[16:17:51.380] iteration 24146: loss: 0.056691, loss_s1: 0.021024, loss_fp: 0.006243, loss_freq: 0.019649
[16:17:51.997] iteration 24147: loss: 0.041624, loss_s1: 0.018384, loss_fp: 0.000833, loss_freq: 0.030753
[16:17:52.614] iteration 24148: loss: 0.053476, loss_s1: 0.039394, loss_fp: 0.001339, loss_freq: 0.033392
[16:17:53.235] iteration 24149: loss: 0.046618, loss_s1: 0.033876, loss_fp: 0.009660, loss_freq: 0.021028
[16:17:53.853] iteration 24150: loss: 0.045570, loss_s1: 0.019096, loss_fp: 0.002211, loss_freq: 0.011692
[16:17:54.512] iteration 24151: loss: 0.045416, loss_s1: 0.027306, loss_fp: 0.001701, loss_freq: 0.024830
[16:17:55.133] iteration 24152: loss: 0.049856, loss_s1: 0.027330, loss_fp: 0.000930, loss_freq: 0.036626
[16:17:55.754] iteration 24153: loss: 0.037263, loss_s1: 0.040957, loss_fp: 0.000909, loss_freq: 0.003940
[16:17:56.375] iteration 24154: loss: 0.048858, loss_s1: 0.025105, loss_fp: 0.004883, loss_freq: 0.027299
[16:17:56.995] iteration 24155: loss: 0.054899, loss_s1: 0.044972, loss_fp: 0.001301, loss_freq: 0.028053
[16:17:57.618] iteration 24156: loss: 0.047254, loss_s1: 0.024776, loss_fp: 0.007350, loss_freq: 0.020730
[16:17:58.244] iteration 24157: loss: 0.048317, loss_s1: 0.038950, loss_fp: 0.002304, loss_freq: 0.013605
[16:17:58.867] iteration 24158: loss: 0.084458, loss_s1: 0.059452, loss_fp: 0.002719, loss_freq: 0.053717
[16:17:59.489] iteration 24159: loss: 0.071141, loss_s1: 0.045299, loss_fp: 0.005086, loss_freq: 0.021999
[16:18:00.117] iteration 24160: loss: 0.076076, loss_s1: 0.056705, loss_fp: 0.011466, loss_freq: 0.042190
[16:18:00.734] iteration 24161: loss: 0.064567, loss_s1: 0.066377, loss_fp: 0.002642, loss_freq: 0.017032
[16:18:01.354] iteration 24162: loss: 0.023862, loss_s1: 0.007941, loss_fp: 0.002952, loss_freq: 0.005220
[16:18:01.975] iteration 24163: loss: 0.063830, loss_s1: 0.039991, loss_fp: 0.002062, loss_freq: 0.028292
[16:18:02.608] iteration 24164: loss: 0.053392, loss_s1: 0.016685, loss_fp: 0.003602, loss_freq: 0.025664
[16:18:03.238] iteration 24165: loss: 0.039100, loss_s1: 0.024749, loss_fp: 0.002240, loss_freq: 0.014486
[16:18:03.859] iteration 24166: loss: 0.111618, loss_s1: 0.097386, loss_fp: 0.013393, loss_freq: 0.067521
[16:18:04.475] iteration 24167: loss: 0.038803, loss_s1: 0.028068, loss_fp: 0.002860, loss_freq: 0.019347
[16:18:05.393] iteration 24168: loss: 0.028423, loss_s1: 0.013827, loss_fp: 0.000421, loss_freq: 0.009226
[16:18:06.016] iteration 24169: loss: 0.054744, loss_s1: 0.031526, loss_fp: 0.003691, loss_freq: 0.037692
[16:18:06.632] iteration 24170: loss: 0.032146, loss_s1: 0.012655, loss_fp: 0.003539, loss_freq: 0.012528
[16:18:07.248] iteration 24171: loss: 0.049115, loss_s1: 0.036569, loss_fp: 0.003452, loss_freq: 0.011752
[16:18:07.903] iteration 24172: loss: 0.057803, loss_s1: 0.058267, loss_fp: 0.002068, loss_freq: 0.019420
[16:18:08.540] iteration 24173: loss: 0.040909, loss_s1: 0.021237, loss_fp: 0.006688, loss_freq: 0.009678
[16:18:09.179] iteration 24174: loss: 0.037394, loss_s1: 0.016985, loss_fp: 0.006488, loss_freq: 0.020503
[16:18:09.805] iteration 24175: loss: 0.087251, loss_s1: 0.079016, loss_fp: 0.003510, loss_freq: 0.028621
[16:18:10.420] iteration 24176: loss: 0.058017, loss_s1: 0.035412, loss_fp: 0.005092, loss_freq: 0.034110
[16:18:11.038] iteration 24177: loss: 0.037469, loss_s1: 0.011275, loss_fp: 0.001560, loss_freq: 0.004641
[16:18:11.661] iteration 24178: loss: 0.051082, loss_s1: 0.039609, loss_fp: 0.002312, loss_freq: 0.028959
[16:18:12.279] iteration 24179: loss: 0.034313, loss_s1: 0.015660, loss_fp: 0.002634, loss_freq: 0.013500
[16:18:12.925] iteration 24180: loss: 0.055563, loss_s1: 0.055311, loss_fp: 0.004030, loss_freq: 0.014524
[16:18:13.540] iteration 24181: loss: 0.051564, loss_s1: 0.034779, loss_fp: 0.011070, loss_freq: 0.024983
[16:18:14.161] iteration 24182: loss: 0.042443, loss_s1: 0.015650, loss_fp: 0.004906, loss_freq: 0.024167
[16:18:14.795] iteration 24183: loss: 0.063683, loss_s1: 0.057865, loss_fp: 0.004729, loss_freq: 0.025437
[16:18:15.411] iteration 24184: loss: 0.053683, loss_s1: 0.010592, loss_fp: 0.009718, loss_freq: 0.031345
[16:18:16.029] iteration 24185: loss: 0.048629, loss_s1: 0.030589, loss_fp: 0.001861, loss_freq: 0.027498
[16:18:16.652] iteration 24186: loss: 0.040950, loss_s1: 0.033091, loss_fp: 0.001296, loss_freq: 0.020281
[16:18:17.275] iteration 24187: loss: 0.028685, loss_s1: 0.021082, loss_fp: 0.000486, loss_freq: 0.007821
[16:18:17.892] iteration 24188: loss: 0.068404, loss_s1: 0.027776, loss_fp: 0.003540, loss_freq: 0.047122
[16:18:18.510] iteration 24189: loss: 0.041528, loss_s1: 0.029237, loss_fp: 0.000866, loss_freq: 0.018372
[16:18:19.131] iteration 24190: loss: 0.049492, loss_s1: 0.032896, loss_fp: 0.003224, loss_freq: 0.024082
[16:18:19.746] iteration 24191: loss: 0.061067, loss_s1: 0.036454, loss_fp: 0.015719, loss_freq: 0.035051
[16:18:20.367] iteration 24192: loss: 0.045093, loss_s1: 0.037608, loss_fp: 0.000364, loss_freq: 0.014517
[16:18:21.008] iteration 24193: loss: 0.066132, loss_s1: 0.023313, loss_fp: 0.002607, loss_freq: 0.060157
[16:18:21.638] iteration 24194: loss: 0.048249, loss_s1: 0.035022, loss_fp: 0.001696, loss_freq: 0.022731
[16:18:22.277] iteration 24195: loss: 0.047523, loss_s1: 0.029424, loss_fp: 0.001084, loss_freq: 0.007230
[16:18:22.900] iteration 24196: loss: 0.041723, loss_s1: 0.021721, loss_fp: 0.003160, loss_freq: 0.020587
[16:18:23.521] iteration 24197: loss: 0.036171, loss_s1: 0.015320, loss_fp: 0.005202, loss_freq: 0.015307
[16:18:24.140] iteration 24198: loss: 0.041890, loss_s1: 0.034049, loss_fp: 0.004822, loss_freq: 0.009067
[16:18:24.763] iteration 24199: loss: 0.071207, loss_s1: 0.067579, loss_fp: 0.000843, loss_freq: 0.026593
[16:18:25.386] iteration 24200: loss: 0.093840, loss_s1: 0.090829, loss_fp: 0.017531, loss_freq: 0.043507
[16:18:28.821] iteration 24200 : mean_dice : 0.797956
[16:18:29.461] iteration 24201: loss: 0.086753, loss_s1: 0.097969, loss_fp: 0.006163, loss_freq: 0.025415
[16:18:30.081] iteration 24202: loss: 0.066695, loss_s1: 0.033299, loss_fp: 0.006383, loss_freq: 0.015978
[16:18:30.718] iteration 24203: loss: 0.070437, loss_s1: 0.061786, loss_fp: 0.001064, loss_freq: 0.037309
[16:18:31.336] iteration 24204: loss: 0.050509, loss_s1: 0.024450, loss_fp: 0.002794, loss_freq: 0.021492
[16:18:31.960] iteration 24205: loss: 0.042066, loss_s1: 0.036184, loss_fp: 0.003317, loss_freq: 0.012509
[16:18:32.655] iteration 24206: loss: 0.070984, loss_s1: 0.065767, loss_fp: 0.002469, loss_freq: 0.024791
[16:18:33.278] iteration 24207: loss: 0.042407, loss_s1: 0.028109, loss_fp: 0.003233, loss_freq: 0.019542
[16:18:33.905] iteration 24208: loss: 0.044872, loss_s1: 0.042818, loss_fp: 0.002738, loss_freq: 0.010838
[16:18:34.528] iteration 24209: loss: 0.047833, loss_s1: 0.030202, loss_fp: 0.007796, loss_freq: 0.030742
[16:18:35.193] iteration 24210: loss: 0.042672, loss_s1: 0.038492, loss_fp: 0.000683, loss_freq: 0.007542
[16:18:35.821] iteration 24211: loss: 0.056717, loss_s1: 0.055789, loss_fp: 0.002419, loss_freq: 0.014865
[16:18:36.442] iteration 24212: loss: 0.044896, loss_s1: 0.019045, loss_fp: 0.004964, loss_freq: 0.011903
[16:18:37.066] iteration 24213: loss: 0.053737, loss_s1: 0.028798, loss_fp: 0.010966, loss_freq: 0.032356
[16:18:37.687] iteration 24214: loss: 0.052842, loss_s1: 0.039402, loss_fp: 0.002481, loss_freq: 0.023684
[16:18:38.308] iteration 24215: loss: 0.049204, loss_s1: 0.028288, loss_fp: 0.003777, loss_freq: 0.009223
[16:18:38.939] iteration 24216: loss: 0.052469, loss_s1: 0.043322, loss_fp: 0.001267, loss_freq: 0.030279
[16:18:39.564] iteration 24217: loss: 0.039912, loss_s1: 0.021068, loss_fp: 0.001655, loss_freq: 0.016022
[16:18:40.224] iteration 24218: loss: 0.034795, loss_s1: 0.020947, loss_fp: 0.003845, loss_freq: 0.009188
[16:18:40.864] iteration 24219: loss: 0.059386, loss_s1: 0.034773, loss_fp: 0.000966, loss_freq: 0.049227
[16:18:41.530] iteration 24220: loss: 0.041308, loss_s1: 0.014642, loss_fp: 0.004603, loss_freq: 0.028576
[16:18:42.183] iteration 24221: loss: 0.054857, loss_s1: 0.036362, loss_fp: 0.005025, loss_freq: 0.039137
[16:18:42.836] iteration 24222: loss: 0.034416, loss_s1: 0.019121, loss_fp: 0.007075, loss_freq: 0.009045
[16:18:43.475] iteration 24223: loss: 0.037679, loss_s1: 0.024674, loss_fp: 0.000825, loss_freq: 0.006242
[16:18:44.112] iteration 24224: loss: 0.061172, loss_s1: 0.058738, loss_fp: 0.002038, loss_freq: 0.022444
[16:18:44.754] iteration 24225: loss: 0.035436, loss_s1: 0.018910, loss_fp: 0.001272, loss_freq: 0.019083
[16:18:45.399] iteration 24226: loss: 0.059541, loss_s1: 0.026801, loss_fp: 0.002863, loss_freq: 0.055080
[16:18:46.033] iteration 24227: loss: 0.060360, loss_s1: 0.048767, loss_fp: 0.000928, loss_freq: 0.024960
[16:18:46.673] iteration 24228: loss: 0.058868, loss_s1: 0.043560, loss_fp: 0.001975, loss_freq: 0.016964
[16:18:47.315] iteration 24229: loss: 0.043021, loss_s1: 0.023370, loss_fp: 0.007923, loss_freq: 0.012970
[16:18:47.950] iteration 24230: loss: 0.098637, loss_s1: 0.111941, loss_fp: 0.005183, loss_freq: 0.042810
[16:18:48.582] iteration 24231: loss: 0.043918, loss_s1: 0.026222, loss_fp: 0.000755, loss_freq: 0.017941
[16:18:49.201] iteration 24232: loss: 0.037382, loss_s1: 0.023976, loss_fp: 0.001593, loss_freq: 0.011740
[16:18:49.827] iteration 24233: loss: 0.058823, loss_s1: 0.036443, loss_fp: 0.002687, loss_freq: 0.029504
[16:18:50.445] iteration 24234: loss: 0.044570, loss_s1: 0.027298, loss_fp: 0.002129, loss_freq: 0.020780
[16:18:51.070] iteration 24235: loss: 0.050882, loss_s1: 0.033830, loss_fp: 0.004056, loss_freq: 0.022682
[16:18:51.691] iteration 24236: loss: 0.050583, loss_s1: 0.046906, loss_fp: 0.007518, loss_freq: 0.011496
[16:18:52.313] iteration 24237: loss: 0.063123, loss_s1: 0.046802, loss_fp: 0.003160, loss_freq: 0.007438
[16:18:52.931] iteration 24238: loss: 0.040998, loss_s1: 0.027260, loss_fp: 0.004467, loss_freq: 0.018592
[16:18:53.547] iteration 24239: loss: 0.041266, loss_s1: 0.018504, loss_fp: 0.002631, loss_freq: 0.018033
[16:18:54.167] iteration 24240: loss: 0.036761, loss_s1: 0.012392, loss_fp: 0.004804, loss_freq: 0.022196
[16:18:54.778] iteration 24241: loss: 0.094251, loss_s1: 0.083231, loss_fp: 0.008296, loss_freq: 0.048217
[16:18:55.394] iteration 24242: loss: 0.056473, loss_s1: 0.051421, loss_fp: 0.005039, loss_freq: 0.029261
[16:18:56.010] iteration 24243: loss: 0.040736, loss_s1: 0.023420, loss_fp: 0.003300, loss_freq: 0.015907
[16:18:56.635] iteration 24244: loss: 0.037748, loss_s1: 0.031452, loss_fp: 0.007093, loss_freq: 0.011267
[16:18:57.270] iteration 24245: loss: 0.052759, loss_s1: 0.049736, loss_fp: 0.003735, loss_freq: 0.013432
[16:18:57.896] iteration 24246: loss: 0.078521, loss_s1: 0.070834, loss_fp: 0.010732, loss_freq: 0.036693
[16:18:58.516] iteration 24247: loss: 0.095341, loss_s1: 0.046604, loss_fp: 0.018515, loss_freq: 0.026650
[16:18:59.136] iteration 24248: loss: 0.044533, loss_s1: 0.040269, loss_fp: 0.003886, loss_freq: 0.011202
[16:18:59.764] iteration 24249: loss: 0.043681, loss_s1: 0.029182, loss_fp: 0.003613, loss_freq: 0.024084
[16:19:00.392] iteration 24250: loss: 0.065237, loss_s1: 0.055326, loss_fp: 0.004497, loss_freq: 0.034046
[16:19:01.020] iteration 24251: loss: 0.043356, loss_s1: 0.031795, loss_fp: 0.002774, loss_freq: 0.023254
[16:19:01.651] iteration 24252: loss: 0.056841, loss_s1: 0.053410, loss_fp: 0.002186, loss_freq: 0.015776
[16:19:02.278] iteration 24253: loss: 0.043125, loss_s1: 0.015367, loss_fp: 0.008606, loss_freq: 0.024727
[16:19:02.896] iteration 24254: loss: 0.028826, loss_s1: 0.011775, loss_fp: 0.002649, loss_freq: 0.006022
[16:19:03.524] iteration 24255: loss: 0.037899, loss_s1: 0.030644, loss_fp: 0.001421, loss_freq: 0.009985
[16:19:04.156] iteration 24256: loss: 0.042756, loss_s1: 0.033220, loss_fp: 0.002942, loss_freq: 0.016337
[16:19:04.786] iteration 24257: loss: 0.048231, loss_s1: 0.052602, loss_fp: 0.001116, loss_freq: 0.011617
[16:19:05.405] iteration 24258: loss: 0.048076, loss_s1: 0.030728, loss_fp: 0.001908, loss_freq: 0.026434
[16:19:06.027] iteration 24259: loss: 0.053145, loss_s1: 0.023694, loss_fp: 0.002423, loss_freq: 0.051263
[16:19:06.652] iteration 24260: loss: 0.049792, loss_s1: 0.048011, loss_fp: 0.002004, loss_freq: 0.018578
[16:19:07.275] iteration 24261: loss: 0.039066, loss_s1: 0.025542, loss_fp: 0.003134, loss_freq: 0.013481
[16:19:07.894] iteration 24262: loss: 0.035659, loss_s1: 0.029272, loss_fp: 0.000806, loss_freq: 0.008297
[16:19:08.529] iteration 24263: loss: 0.051171, loss_s1: 0.033519, loss_fp: 0.004234, loss_freq: 0.009739
[16:19:09.169] iteration 24264: loss: 0.110375, loss_s1: 0.095507, loss_fp: 0.007254, loss_freq: 0.067105
[16:19:09.814] iteration 24265: loss: 0.042876, loss_s1: 0.020912, loss_fp: 0.004226, loss_freq: 0.017169
[16:19:10.457] iteration 24266: loss: 0.063028, loss_s1: 0.053688, loss_fp: 0.005923, loss_freq: 0.021961
[16:19:11.098] iteration 24267: loss: 0.061577, loss_s1: 0.027949, loss_fp: 0.002532, loss_freq: 0.024139
[16:19:11.741] iteration 24268: loss: 0.047048, loss_s1: 0.030638, loss_fp: 0.003897, loss_freq: 0.012500
[16:19:12.370] iteration 24269: loss: 0.028169, loss_s1: 0.011774, loss_fp: 0.000938, loss_freq: 0.006324
[16:19:12.985] iteration 24270: loss: 0.055096, loss_s1: 0.048806, loss_fp: 0.005497, loss_freq: 0.023824
[16:19:13.609] iteration 24271: loss: 0.042110, loss_s1: 0.042183, loss_fp: 0.000990, loss_freq: 0.005012
[16:19:14.230] iteration 24272: loss: 0.038062, loss_s1: 0.006141, loss_fp: 0.004427, loss_freq: 0.005483
[16:19:14.864] iteration 24273: loss: 0.060039, loss_s1: 0.041474, loss_fp: 0.002354, loss_freq: 0.029704
[16:19:15.506] iteration 24274: loss: 0.065656, loss_s1: 0.044759, loss_fp: 0.009061, loss_freq: 0.039131
[16:19:16.150] iteration 24275: loss: 0.064186, loss_s1: 0.084509, loss_fp: 0.003811, loss_freq: 0.008680
[16:19:16.773] iteration 24276: loss: 0.065064, loss_s1: 0.032383, loss_fp: 0.004305, loss_freq: 0.035718
[16:19:17.400] iteration 24277: loss: 0.042974, loss_s1: 0.020020, loss_fp: 0.007109, loss_freq: 0.027875
[16:19:18.032] iteration 24278: loss: 0.051469, loss_s1: 0.039989, loss_fp: 0.002975, loss_freq: 0.014189
[16:19:18.652] iteration 24279: loss: 0.044309, loss_s1: 0.032193, loss_fp: 0.003768, loss_freq: 0.025018
[16:19:19.268] iteration 24280: loss: 0.045095, loss_s1: 0.038719, loss_fp: 0.001597, loss_freq: 0.005935
[16:19:19.897] iteration 24281: loss: 0.092010, loss_s1: 0.088650, loss_fp: 0.007567, loss_freq: 0.041176
[16:19:20.516] iteration 24282: loss: 0.046645, loss_s1: 0.023893, loss_fp: 0.002293, loss_freq: 0.006720
[16:19:21.137] iteration 24283: loss: 0.048193, loss_s1: 0.045685, loss_fp: 0.001869, loss_freq: 0.010570
[16:19:21.764] iteration 24284: loss: 0.068516, loss_s1: 0.047302, loss_fp: 0.014997, loss_freq: 0.035534
[16:19:22.376] iteration 24285: loss: 0.044434, loss_s1: 0.031566, loss_fp: 0.002455, loss_freq: 0.018573
[16:19:23.002] iteration 24286: loss: 0.053086, loss_s1: 0.044103, loss_fp: 0.002244, loss_freq: 0.021463
[16:19:23.617] iteration 24287: loss: 0.047611, loss_s1: 0.015050, loss_fp: 0.004190, loss_freq: 0.030748
[16:19:24.239] iteration 24288: loss: 0.072527, loss_s1: 0.070418, loss_fp: 0.002834, loss_freq: 0.025183
[16:19:24.866] iteration 24289: loss: 0.049781, loss_s1: 0.030332, loss_fp: 0.000822, loss_freq: 0.019473
[16:19:25.487] iteration 24290: loss: 0.035071, loss_s1: 0.025766, loss_fp: 0.003068, loss_freq: 0.009524
[16:19:26.102] iteration 24291: loss: 0.039478, loss_s1: 0.033945, loss_fp: 0.005811, loss_freq: 0.012636
[16:19:26.723] iteration 24292: loss: 0.055449, loss_s1: 0.047036, loss_fp: 0.014219, loss_freq: 0.021010
[16:19:27.388] iteration 24293: loss: 0.054618, loss_s1: 0.017056, loss_fp: 0.002147, loss_freq: 0.022642
[16:19:28.008] iteration 24294: loss: 0.047771, loss_s1: 0.040280, loss_fp: 0.002773, loss_freq: 0.026160
[16:19:28.665] iteration 24295: loss: 0.044508, loss_s1: 0.016566, loss_fp: 0.001524, loss_freq: 0.018599
[16:19:29.331] iteration 24296: loss: 0.073598, loss_s1: 0.083761, loss_fp: 0.012023, loss_freq: 0.023220
[16:19:29.952] iteration 24297: loss: 0.049127, loss_s1: 0.033123, loss_fp: 0.005554, loss_freq: 0.017987
[16:19:30.574] iteration 24298: loss: 0.058337, loss_s1: 0.049239, loss_fp: 0.004455, loss_freq: 0.028158
[16:19:31.192] iteration 24299: loss: 0.079870, loss_s1: 0.068258, loss_fp: 0.002664, loss_freq: 0.045370
[16:19:31.816] iteration 24300: loss: 0.055123, loss_s1: 0.050668, loss_fp: 0.008221, loss_freq: 0.017242
[16:19:32.436] iteration 24301: loss: 0.068982, loss_s1: 0.046805, loss_fp: 0.004426, loss_freq: 0.038279
[16:19:33.058] iteration 24302: loss: 0.049008, loss_s1: 0.030511, loss_fp: 0.004003, loss_freq: 0.016176
[16:19:33.684] iteration 24303: loss: 0.071687, loss_s1: 0.083037, loss_fp: 0.005333, loss_freq: 0.024551
[16:19:34.297] iteration 24304: loss: 0.073454, loss_s1: 0.062024, loss_fp: 0.005580, loss_freq: 0.020180
[16:19:34.917] iteration 24305: loss: 0.036391, loss_s1: 0.026763, loss_fp: 0.001626, loss_freq: 0.012703
[16:19:35.538] iteration 24306: loss: 0.061952, loss_s1: 0.034556, loss_fp: 0.000729, loss_freq: 0.027924
[16:19:36.162] iteration 24307: loss: 0.049071, loss_s1: 0.024515, loss_fp: 0.002108, loss_freq: 0.021336
[16:19:36.785] iteration 24308: loss: 0.062775, loss_s1: 0.046530, loss_fp: 0.006928, loss_freq: 0.032264
[16:19:37.407] iteration 24309: loss: 0.077087, loss_s1: 0.047592, loss_fp: 0.004393, loss_freq: 0.060268
[16:19:38.027] iteration 24310: loss: 0.027082, loss_s1: 0.009484, loss_fp: 0.000481, loss_freq: 0.009203
[16:19:38.995] iteration 24311: loss: 0.034066, loss_s1: 0.013249, loss_fp: 0.001928, loss_freq: 0.016999
[16:19:39.687] iteration 24312: loss: 0.078967, loss_s1: 0.074640, loss_fp: 0.004273, loss_freq: 0.037188
[16:19:40.334] iteration 24313: loss: 0.030693, loss_s1: 0.008014, loss_fp: 0.001588, loss_freq: 0.017191
[16:19:40.967] iteration 24314: loss: 0.043718, loss_s1: 0.025881, loss_fp: 0.006008, loss_freq: 0.013899
[16:19:41.598] iteration 24315: loss: 0.056250, loss_s1: 0.048721, loss_fp: 0.001116, loss_freq: 0.032196
[16:19:42.226] iteration 24316: loss: 0.034223, loss_s1: 0.007988, loss_fp: 0.005506, loss_freq: 0.012528
[16:19:42.860] iteration 24317: loss: 0.038207, loss_s1: 0.022875, loss_fp: 0.004153, loss_freq: 0.024682
[16:19:43.490] iteration 24318: loss: 0.054971, loss_s1: 0.014167, loss_fp: 0.001668, loss_freq: 0.036191
[16:19:44.129] iteration 24319: loss: 0.054703, loss_s1: 0.039492, loss_fp: 0.002109, loss_freq: 0.029894
[16:19:44.767] iteration 24320: loss: 0.031657, loss_s1: 0.008913, loss_fp: 0.000903, loss_freq: 0.002713
[16:19:45.409] iteration 24321: loss: 0.078833, loss_s1: 0.066871, loss_fp: 0.006744, loss_freq: 0.050822
[16:19:46.036] iteration 24322: loss: 0.064008, loss_s1: 0.027518, loss_fp: 0.025651, loss_freq: 0.030128
[16:19:46.651] iteration 24323: loss: 0.067374, loss_s1: 0.042653, loss_fp: 0.000736, loss_freq: 0.055685
[16:19:47.276] iteration 24324: loss: 0.037461, loss_s1: 0.027733, loss_fp: 0.001627, loss_freq: 0.014485
[16:19:47.896] iteration 24325: loss: 0.072157, loss_s1: 0.067542, loss_fp: 0.003668, loss_freq: 0.033539
[16:19:48.510] iteration 24326: loss: 0.040507, loss_s1: 0.034211, loss_fp: 0.000742, loss_freq: 0.017937
[16:19:49.139] iteration 24327: loss: 0.072641, loss_s1: 0.050070, loss_fp: 0.008168, loss_freq: 0.039841
[16:19:49.761] iteration 24328: loss: 0.054027, loss_s1: 0.041482, loss_fp: 0.003151, loss_freq: 0.024007
[16:19:50.421] iteration 24329: loss: 0.053715, loss_s1: 0.030299, loss_fp: 0.002072, loss_freq: 0.035839
[16:19:51.065] iteration 24330: loss: 0.030884, loss_s1: 0.015224, loss_fp: 0.001390, loss_freq: 0.011371
[16:19:51.713] iteration 24331: loss: 0.114486, loss_s1: 0.032008, loss_fp: 0.008946, loss_freq: 0.069081
[16:19:52.392] iteration 24332: loss: 0.059594, loss_s1: 0.060847, loss_fp: 0.007895, loss_freq: 0.020622
[16:19:53.014] iteration 24333: loss: 0.067211, loss_s1: 0.055713, loss_fp: 0.001428, loss_freq: 0.030317
[16:19:53.644] iteration 24334: loss: 0.038577, loss_s1: 0.028448, loss_fp: 0.001163, loss_freq: 0.014672
[16:19:54.342] iteration 24335: loss: 0.060357, loss_s1: 0.062392, loss_fp: 0.002048, loss_freq: 0.015863
[16:19:54.973] iteration 24336: loss: 0.058333, loss_s1: 0.050940, loss_fp: 0.001871, loss_freq: 0.022416
[16:19:55.606] iteration 24337: loss: 0.071880, loss_s1: 0.040477, loss_fp: 0.006713, loss_freq: 0.050114
[16:19:56.229] iteration 24338: loss: 0.036945, loss_s1: 0.016415, loss_fp: 0.003146, loss_freq: 0.013088
[16:19:56.856] iteration 24339: loss: 0.078673, loss_s1: 0.071444, loss_fp: 0.004180, loss_freq: 0.030523
[16:19:57.480] iteration 24340: loss: 0.050393, loss_s1: 0.041532, loss_fp: 0.001428, loss_freq: 0.008603
[16:19:58.102] iteration 24341: loss: 0.033797, loss_s1: 0.024348, loss_fp: 0.002176, loss_freq: 0.004351
[16:19:58.733] iteration 24342: loss: 0.052059, loss_s1: 0.031256, loss_fp: 0.004190, loss_freq: 0.021546
[16:19:59.358] iteration 24343: loss: 0.083922, loss_s1: 0.096460, loss_fp: 0.004336, loss_freq: 0.034479
[16:19:59.995] iteration 24344: loss: 0.105403, loss_s1: 0.088684, loss_fp: 0.005822, loss_freq: 0.085933
[16:20:00.608] iteration 24345: loss: 0.058147, loss_s1: 0.039382, loss_fp: 0.007124, loss_freq: 0.022300
[16:20:01.228] iteration 24346: loss: 0.057165, loss_s1: 0.048714, loss_fp: 0.002159, loss_freq: 0.029715
[16:20:01.852] iteration 24347: loss: 0.064508, loss_s1: 0.052191, loss_fp: 0.002145, loss_freq: 0.032778
[16:20:02.482] iteration 24348: loss: 0.032552, loss_s1: 0.016249, loss_fp: 0.000736, loss_freq: 0.015711
[16:20:03.113] iteration 24349: loss: 0.094615, loss_s1: 0.102302, loss_fp: 0.003798, loss_freq: 0.035769
[16:20:03.734] iteration 24350: loss: 0.043528, loss_s1: 0.031538, loss_fp: 0.002287, loss_freq: 0.009132
[16:20:04.385] iteration 24351: loss: 0.085026, loss_s1: 0.036695, loss_fp: 0.003603, loss_freq: 0.028570
[16:20:05.016] iteration 24352: loss: 0.032347, loss_s1: 0.019172, loss_fp: 0.002657, loss_freq: 0.016588
[16:20:05.652] iteration 24353: loss: 0.032024, loss_s1: 0.015215, loss_fp: 0.002028, loss_freq: 0.006719
[16:20:06.276] iteration 24354: loss: 0.047105, loss_s1: 0.041393, loss_fp: 0.002745, loss_freq: 0.015663
[16:20:06.894] iteration 24355: loss: 0.045110, loss_s1: 0.020813, loss_fp: 0.001448, loss_freq: 0.002528
[16:20:07.521] iteration 24356: loss: 0.073550, loss_s1: 0.065114, loss_fp: 0.004074, loss_freq: 0.039040
[16:20:08.151] iteration 24357: loss: 0.045851, loss_s1: 0.031700, loss_fp: 0.006040, loss_freq: 0.020291
[16:20:08.775] iteration 24358: loss: 0.059223, loss_s1: 0.046447, loss_fp: 0.003092, loss_freq: 0.032973
[16:20:09.398] iteration 24359: loss: 0.067492, loss_s1: 0.054378, loss_fp: 0.000844, loss_freq: 0.047784
[16:20:10.025] iteration 24360: loss: 0.051809, loss_s1: 0.025373, loss_fp: 0.003450, loss_freq: 0.024577
[16:20:10.653] iteration 24361: loss: 0.080679, loss_s1: 0.049368, loss_fp: 0.009199, loss_freq: 0.031963
[16:20:11.280] iteration 24362: loss: 0.067951, loss_s1: 0.049104, loss_fp: 0.004174, loss_freq: 0.037603
[16:20:11.900] iteration 24363: loss: 0.046872, loss_s1: 0.031612, loss_fp: 0.002121, loss_freq: 0.018378
[16:20:12.528] iteration 24364: loss: 0.048776, loss_s1: 0.036083, loss_fp: 0.004231, loss_freq: 0.027260
[16:20:13.155] iteration 24365: loss: 0.022569, loss_s1: 0.004977, loss_fp: 0.005291, loss_freq: 0.004919
[16:20:13.804] iteration 24366: loss: 0.042048, loss_s1: 0.017222, loss_fp: 0.000697, loss_freq: 0.020876
[16:20:14.427] iteration 24367: loss: 0.063156, loss_s1: 0.061330, loss_fp: 0.005597, loss_freq: 0.023692
[16:20:15.052] iteration 24368: loss: 0.066801, loss_s1: 0.074326, loss_fp: 0.002047, loss_freq: 0.022267
[16:20:15.668] iteration 24369: loss: 0.049907, loss_s1: 0.037004, loss_fp: 0.001316, loss_freq: 0.014656
[16:20:16.291] iteration 24370: loss: 0.051727, loss_s1: 0.041006, loss_fp: 0.001078, loss_freq: 0.019778
[16:20:16.916] iteration 24371: loss: 0.038021, loss_s1: 0.018152, loss_fp: 0.001322, loss_freq: 0.014000
[16:20:17.528] iteration 24372: loss: 0.093561, loss_s1: 0.082847, loss_fp: 0.003160, loss_freq: 0.023904
[16:20:18.146] iteration 24373: loss: 0.104911, loss_s1: 0.074130, loss_fp: 0.004915, loss_freq: 0.056091
[16:20:18.771] iteration 24374: loss: 0.046106, loss_s1: 0.030588, loss_fp: 0.000730, loss_freq: 0.021374
[16:20:19.395] iteration 24375: loss: 0.053190, loss_s1: 0.027306, loss_fp: 0.005525, loss_freq: 0.020735
[16:20:20.016] iteration 24376: loss: 0.044557, loss_s1: 0.024867, loss_fp: 0.003993, loss_freq: 0.019713
[16:20:20.633] iteration 24377: loss: 0.073484, loss_s1: 0.021720, loss_fp: 0.007429, loss_freq: 0.064528
[16:20:21.257] iteration 24378: loss: 0.049084, loss_s1: 0.032085, loss_fp: 0.003462, loss_freq: 0.015554
[16:20:21.878] iteration 24379: loss: 0.035475, loss_s1: 0.024242, loss_fp: 0.001974, loss_freq: 0.010909
[16:20:22.498] iteration 24380: loss: 0.041769, loss_s1: 0.010287, loss_fp: 0.001242, loss_freq: 0.007856
[16:20:23.159] iteration 24381: loss: 0.055699, loss_s1: 0.053697, loss_fp: 0.000698, loss_freq: 0.016106
[16:20:23.786] iteration 24382: loss: 0.041907, loss_s1: 0.036865, loss_fp: 0.004415, loss_freq: 0.009292
[16:20:24.415] iteration 24383: loss: 0.060222, loss_s1: 0.036023, loss_fp: 0.003599, loss_freq: 0.053489
[16:20:25.036] iteration 24384: loss: 0.084995, loss_s1: 0.051978, loss_fp: 0.002674, loss_freq: 0.066889
[16:20:25.648] iteration 24385: loss: 0.061684, loss_s1: 0.035048, loss_fp: 0.013408, loss_freq: 0.041378
[16:20:26.277] iteration 24386: loss: 0.057543, loss_s1: 0.042761, loss_fp: 0.001069, loss_freq: 0.029917
[16:20:26.907] iteration 24387: loss: 0.074973, loss_s1: 0.072753, loss_fp: 0.002967, loss_freq: 0.029937
[16:20:27.533] iteration 24388: loss: 0.035458, loss_s1: 0.026664, loss_fp: 0.001208, loss_freq: 0.006256
[16:20:28.156] iteration 24389: loss: 0.066911, loss_s1: 0.072599, loss_fp: 0.006279, loss_freq: 0.012375
[16:20:28.788] iteration 24390: loss: 0.069373, loss_s1: 0.059653, loss_fp: 0.004579, loss_freq: 0.020802
[16:20:29.411] iteration 24391: loss: 0.063763, loss_s1: 0.044427, loss_fp: 0.000726, loss_freq: 0.037905
[16:20:30.036] iteration 24392: loss: 0.048859, loss_s1: 0.043202, loss_fp: 0.011488, loss_freq: 0.012316
[16:20:30.647] iteration 24393: loss: 0.036526, loss_s1: 0.009792, loss_fp: 0.005305, loss_freq: 0.005236
[16:20:31.276] iteration 24394: loss: 0.052518, loss_s1: 0.055633, loss_fp: 0.003046, loss_freq: 0.010960
[16:20:31.896] iteration 24395: loss: 0.074309, loss_s1: 0.071064, loss_fp: 0.003530, loss_freq: 0.027490
[16:20:32.515] iteration 24396: loss: 0.070781, loss_s1: 0.035225, loss_fp: 0.011597, loss_freq: 0.058528
[16:20:33.136] iteration 24397: loss: 0.075466, loss_s1: 0.064727, loss_fp: 0.022839, loss_freq: 0.025706
[16:20:33.759] iteration 24398: loss: 0.042434, loss_s1: 0.030287, loss_fp: 0.001027, loss_freq: 0.009256
[16:20:34.387] iteration 24399: loss: 0.036245, loss_s1: 0.039008, loss_fp: 0.001058, loss_freq: 0.006741
[16:20:34.998] iteration 24400: loss: 0.050956, loss_s1: 0.054132, loss_fp: 0.006904, loss_freq: 0.011249
[16:20:38.420] iteration 24400 : mean_dice : 0.787834
[16:20:39.069] iteration 24401: loss: 0.042397, loss_s1: 0.022942, loss_fp: 0.003194, loss_freq: 0.019001
[16:20:39.699] iteration 24402: loss: 0.032780, loss_s1: 0.022419, loss_fp: 0.004065, loss_freq: 0.011666
[16:20:40.323] iteration 24403: loss: 0.052391, loss_s1: 0.055444, loss_fp: 0.006596, loss_freq: 0.011332
[16:20:41.003] iteration 24404: loss: 0.056734, loss_s1: 0.072486, loss_fp: 0.004359, loss_freq: 0.007125
[16:20:41.637] iteration 24405: loss: 0.048786, loss_s1: 0.033259, loss_fp: 0.001064, loss_freq: 0.023427
[16:20:42.267] iteration 24406: loss: 0.030259, loss_s1: 0.017153, loss_fp: 0.000446, loss_freq: 0.004836
[16:20:42.918] iteration 24407: loss: 0.086788, loss_s1: 0.056766, loss_fp: 0.010260, loss_freq: 0.066179
[16:20:43.560] iteration 24408: loss: 0.041538, loss_s1: 0.020651, loss_fp: 0.001924, loss_freq: 0.029342
[16:20:44.201] iteration 24409: loss: 0.051263, loss_s1: 0.055221, loss_fp: 0.002678, loss_freq: 0.010528
[16:20:44.817] iteration 24410: loss: 0.085750, loss_s1: 0.056059, loss_fp: 0.001250, loss_freq: 0.052351
[16:20:45.444] iteration 24411: loss: 0.055382, loss_s1: 0.019272, loss_fp: 0.003141, loss_freq: 0.043643
[16:20:46.059] iteration 24412: loss: 0.049763, loss_s1: 0.016010, loss_fp: 0.001882, loss_freq: 0.023652
[16:20:46.676] iteration 24413: loss: 0.101751, loss_s1: 0.134554, loss_fp: 0.004069, loss_freq: 0.031810
[16:20:47.313] iteration 24414: loss: 0.038997, loss_s1: 0.031798, loss_fp: 0.001404, loss_freq: 0.011495
[16:20:47.929] iteration 24415: loss: 0.033461, loss_s1: 0.013724, loss_fp: 0.003534, loss_freq: 0.010906
[16:20:48.548] iteration 24416: loss: 0.040101, loss_s1: 0.016525, loss_fp: 0.002794, loss_freq: 0.019947
[16:20:49.162] iteration 24417: loss: 0.089857, loss_s1: 0.069945, loss_fp: 0.003298, loss_freq: 0.059404
[16:20:49.782] iteration 24418: loss: 0.076460, loss_s1: 0.054968, loss_fp: 0.007045, loss_freq: 0.057194
[16:20:50.401] iteration 24419: loss: 0.066511, loss_s1: 0.021673, loss_fp: 0.011034, loss_freq: 0.052546
[16:20:51.020] iteration 24420: loss: 0.068610, loss_s1: 0.058256, loss_fp: 0.004824, loss_freq: 0.045676
[16:20:51.642] iteration 24421: loss: 0.051289, loss_s1: 0.027878, loss_fp: 0.001001, loss_freq: 0.028449
[16:20:52.262] iteration 24422: loss: 0.051175, loss_s1: 0.035155, loss_fp: 0.013602, loss_freq: 0.024934
[16:20:52.872] iteration 24423: loss: 0.044325, loss_s1: 0.023439, loss_fp: 0.003922, loss_freq: 0.008212
[16:20:53.489] iteration 24424: loss: 0.094002, loss_s1: 0.086672, loss_fp: 0.005710, loss_freq: 0.049640
[16:20:54.100] iteration 24425: loss: 0.071702, loss_s1: 0.056019, loss_fp: 0.001611, loss_freq: 0.022800
[16:20:54.719] iteration 24426: loss: 0.062593, loss_s1: 0.075696, loss_fp: 0.001489, loss_freq: 0.011841
[16:20:55.332] iteration 24427: loss: 0.085415, loss_s1: 0.072075, loss_fp: 0.010545, loss_freq: 0.051352
[16:20:55.988] iteration 24428: loss: 0.086178, loss_s1: 0.105574, loss_fp: 0.002025, loss_freq: 0.017759
[16:20:56.605] iteration 24429: loss: 0.070440, loss_s1: 0.067011, loss_fp: 0.004628, loss_freq: 0.034255
[16:20:57.219] iteration 24430: loss: 0.063323, loss_s1: 0.057240, loss_fp: 0.009606, loss_freq: 0.020761
[16:20:57.839] iteration 24431: loss: 0.067292, loss_s1: 0.058286, loss_fp: 0.002623, loss_freq: 0.031182
[16:20:58.456] iteration 24432: loss: 0.036414, loss_s1: 0.024539, loss_fp: 0.001589, loss_freq: 0.011809
[16:20:59.080] iteration 24433: loss: 0.022211, loss_s1: 0.004706, loss_fp: 0.003986, loss_freq: 0.001929
[16:20:59.695] iteration 24434: loss: 0.039915, loss_s1: 0.021772, loss_fp: 0.001771, loss_freq: 0.027827
[16:21:00.312] iteration 24435: loss: 0.064517, loss_s1: 0.071028, loss_fp: 0.001397, loss_freq: 0.028927
[16:21:00.933] iteration 24436: loss: 0.038311, loss_s1: 0.014757, loss_fp: 0.004119, loss_freq: 0.010867
[16:21:01.552] iteration 24437: loss: 0.048286, loss_s1: 0.041365, loss_fp: 0.002673, loss_freq: 0.024065
[16:21:02.172] iteration 24438: loss: 0.048129, loss_s1: 0.026415, loss_fp: 0.001321, loss_freq: 0.033144
[16:21:02.802] iteration 24439: loss: 0.062999, loss_s1: 0.055267, loss_fp: 0.014137, loss_freq: 0.008761
[16:21:03.422] iteration 24440: loss: 0.029528, loss_s1: 0.010960, loss_fp: 0.003131, loss_freq: 0.005732
[16:21:04.039] iteration 24441: loss: 0.047822, loss_s1: 0.046562, loss_fp: 0.000968, loss_freq: 0.017461
[16:21:04.667] iteration 24442: loss: 0.053996, loss_s1: 0.044444, loss_fp: 0.002008, loss_freq: 0.017288
[16:21:05.286] iteration 24443: loss: 0.051420, loss_s1: 0.039368, loss_fp: 0.003087, loss_freq: 0.020974
[16:21:05.906] iteration 24444: loss: 0.089237, loss_s1: 0.035202, loss_fp: 0.000807, loss_freq: 0.074304
[16:21:06.517] iteration 24445: loss: 0.049042, loss_s1: 0.020454, loss_fp: 0.006171, loss_freq: 0.020798
[16:21:07.142] iteration 24446: loss: 0.045061, loss_s1: 0.044494, loss_fp: 0.001204, loss_freq: 0.010639
[16:21:07.759] iteration 24447: loss: 0.071820, loss_s1: 0.062392, loss_fp: 0.006129, loss_freq: 0.029336
[16:21:08.391] iteration 24448: loss: 0.035249, loss_s1: 0.019092, loss_fp: 0.002114, loss_freq: 0.021876
[16:21:09.012] iteration 24449: loss: 0.059896, loss_s1: 0.055559, loss_fp: 0.002827, loss_freq: 0.018457
[16:21:09.634] iteration 24450: loss: 0.042808, loss_s1: 0.028754, loss_fp: 0.002763, loss_freq: 0.008530
[16:21:10.260] iteration 24451: loss: 0.068413, loss_s1: 0.037084, loss_fp: 0.003025, loss_freq: 0.041144
[16:21:10.879] iteration 24452: loss: 0.049838, loss_s1: 0.038964, loss_fp: 0.006365, loss_freq: 0.015167
[16:21:11.502] iteration 24453: loss: 0.038258, loss_s1: 0.016717, loss_fp: 0.000586, loss_freq: 0.019306
[16:21:12.547] iteration 24454: loss: 0.056288, loss_s1: 0.039238, loss_fp: 0.005335, loss_freq: 0.024778
[16:21:13.193] iteration 24455: loss: 0.044985, loss_s1: 0.028188, loss_fp: 0.002124, loss_freq: 0.014304
[16:21:13.816] iteration 24456: loss: 0.038484, loss_s1: 0.018941, loss_fp: 0.001301, loss_freq: 0.029520
[16:21:14.429] iteration 24457: loss: 0.051313, loss_s1: 0.032442, loss_fp: 0.000957, loss_freq: 0.026880
[16:21:15.053] iteration 24458: loss: 0.063442, loss_s1: 0.050453, loss_fp: 0.004555, loss_freq: 0.044025
[16:21:15.672] iteration 24459: loss: 0.061329, loss_s1: 0.044307, loss_fp: 0.002482, loss_freq: 0.015714
[16:21:16.301] iteration 24460: loss: 0.030747, loss_s1: 0.018590, loss_fp: 0.003034, loss_freq: 0.008787
[16:21:16.927] iteration 24461: loss: 0.074085, loss_s1: 0.045542, loss_fp: 0.001339, loss_freq: 0.043798
[16:21:17.550] iteration 24462: loss: 0.047849, loss_s1: 0.037949, loss_fp: 0.004347, loss_freq: 0.015605
[16:21:18.161] iteration 24463: loss: 0.032000, loss_s1: 0.009296, loss_fp: 0.000711, loss_freq: 0.005700
[16:21:18.786] iteration 24464: loss: 0.046005, loss_s1: 0.029475, loss_fp: 0.001118, loss_freq: 0.031323
[16:21:19.401] iteration 24465: loss: 0.049847, loss_s1: 0.019047, loss_fp: 0.001873, loss_freq: 0.027717
[16:21:20.021] iteration 24466: loss: 0.058215, loss_s1: 0.053339, loss_fp: 0.001480, loss_freq: 0.009219
[16:21:20.632] iteration 24467: loss: 0.027486, loss_s1: 0.013319, loss_fp: 0.002691, loss_freq: 0.006615
[16:21:21.262] iteration 24468: loss: 0.047010, loss_s1: 0.012214, loss_fp: 0.001132, loss_freq: 0.031914
[16:21:21.903] iteration 24469: loss: 0.045776, loss_s1: 0.019763, loss_fp: 0.002178, loss_freq: 0.022025
[16:21:22.539] iteration 24470: loss: 0.050191, loss_s1: 0.020894, loss_fp: 0.001862, loss_freq: 0.041385
[16:21:23.187] iteration 24471: loss: 0.038862, loss_s1: 0.016152, loss_fp: 0.003506, loss_freq: 0.012829
[16:21:23.832] iteration 24472: loss: 0.054881, loss_s1: 0.062182, loss_fp: 0.001297, loss_freq: 0.017009
[16:21:24.482] iteration 24473: loss: 0.029242, loss_s1: 0.016405, loss_fp: 0.001325, loss_freq: 0.011070
[16:21:25.109] iteration 24474: loss: 0.087674, loss_s1: 0.044747, loss_fp: 0.003094, loss_freq: 0.070587
[16:21:25.736] iteration 24475: loss: 0.045296, loss_s1: 0.027165, loss_fp: 0.001101, loss_freq: 0.022190
[16:21:26.371] iteration 24476: loss: 0.047211, loss_s1: 0.021922, loss_fp: 0.002074, loss_freq: 0.041623
[16:21:26.997] iteration 24477: loss: 0.045129, loss_s1: 0.040663, loss_fp: 0.002477, loss_freq: 0.005092
[16:21:27.628] iteration 24478: loss: 0.044643, loss_s1: 0.034027, loss_fp: 0.002032, loss_freq: 0.013470
[16:21:28.255] iteration 24479: loss: 0.063108, loss_s1: 0.038722, loss_fp: 0.001368, loss_freq: 0.022961
[16:21:28.888] iteration 24480: loss: 0.081437, loss_s1: 0.065226, loss_fp: 0.011238, loss_freq: 0.043931
[16:21:29.514] iteration 24481: loss: 0.030636, loss_s1: 0.015463, loss_fp: 0.000628, loss_freq: 0.007702
[16:21:30.134] iteration 24482: loss: 0.066137, loss_s1: 0.046434, loss_fp: 0.001980, loss_freq: 0.038499
[16:21:30.759] iteration 24483: loss: 0.061657, loss_s1: 0.019297, loss_fp: 0.002079, loss_freq: 0.012876
[16:21:31.379] iteration 24484: loss: 0.025001, loss_s1: 0.012852, loss_fp: 0.001440, loss_freq: 0.004072
[16:21:31.992] iteration 24485: loss: 0.053791, loss_s1: 0.021244, loss_fp: 0.004999, loss_freq: 0.025460
[16:21:32.616] iteration 24486: loss: 0.068608, loss_s1: 0.052792, loss_fp: 0.008536, loss_freq: 0.044948
[16:21:33.237] iteration 24487: loss: 0.077388, loss_s1: 0.073097, loss_fp: 0.004311, loss_freq: 0.034683
[16:21:33.854] iteration 24488: loss: 0.077433, loss_s1: 0.069802, loss_fp: 0.008146, loss_freq: 0.024694
[16:21:34.510] iteration 24489: loss: 0.056497, loss_s1: 0.062501, loss_fp: 0.002995, loss_freq: 0.008147
[16:21:35.150] iteration 24490: loss: 0.035106, loss_s1: 0.008348, loss_fp: 0.003285, loss_freq: 0.016634
[16:21:35.784] iteration 24491: loss: 0.048470, loss_s1: 0.041525, loss_fp: 0.001622, loss_freq: 0.019434
[16:21:36.436] iteration 24492: loss: 0.112766, loss_s1: 0.124533, loss_fp: 0.003369, loss_freq: 0.048358
[16:21:37.076] iteration 24493: loss: 0.044144, loss_s1: 0.032338, loss_fp: 0.002493, loss_freq: 0.012314
[16:21:37.691] iteration 24494: loss: 0.064704, loss_s1: 0.055036, loss_fp: 0.013852, loss_freq: 0.015743
[16:21:38.320] iteration 24495: loss: 0.047598, loss_s1: 0.054912, loss_fp: 0.004905, loss_freq: 0.007130
[16:21:38.932] iteration 24496: loss: 0.042926, loss_s1: 0.013682, loss_fp: 0.003039, loss_freq: 0.026296
[16:21:39.550] iteration 24497: loss: 0.067427, loss_s1: 0.055281, loss_fp: 0.012488, loss_freq: 0.031629
[16:21:40.178] iteration 24498: loss: 0.099470, loss_s1: 0.098179, loss_fp: 0.000819, loss_freq: 0.040089
[16:21:40.804] iteration 24499: loss: 0.068000, loss_s1: 0.067285, loss_fp: 0.001491, loss_freq: 0.023646
[16:21:41.428] iteration 24500: loss: 0.047765, loss_s1: 0.026778, loss_fp: 0.004686, loss_freq: 0.029918
[16:21:42.045] iteration 24501: loss: 0.054540, loss_s1: 0.049716, loss_fp: 0.002250, loss_freq: 0.014375
[16:21:42.669] iteration 24502: loss: 0.060283, loss_s1: 0.035804, loss_fp: 0.002859, loss_freq: 0.030818
[16:21:43.301] iteration 24503: loss: 0.056508, loss_s1: 0.060311, loss_fp: 0.002323, loss_freq: 0.014001
[16:21:43.924] iteration 24504: loss: 0.042734, loss_s1: 0.026032, loss_fp: 0.005345, loss_freq: 0.016106
[16:21:44.544] iteration 24505: loss: 0.061271, loss_s1: 0.022673, loss_fp: 0.003544, loss_freq: 0.058072
[16:21:45.162] iteration 24506: loss: 0.047662, loss_s1: 0.034542, loss_fp: 0.003033, loss_freq: 0.013779
[16:21:45.779] iteration 24507: loss: 0.067083, loss_s1: 0.054249, loss_fp: 0.004738, loss_freq: 0.033542
[16:21:46.403] iteration 24508: loss: 0.048471, loss_s1: 0.034517, loss_fp: 0.001834, loss_freq: 0.005306
[16:21:47.021] iteration 24509: loss: 0.042000, loss_s1: 0.016962, loss_fp: 0.001326, loss_freq: 0.017525
[16:21:47.639] iteration 24510: loss: 0.043666, loss_s1: 0.033800, loss_fp: 0.002994, loss_freq: 0.013217
[16:21:48.302] iteration 24511: loss: 0.051390, loss_s1: 0.058911, loss_fp: 0.001089, loss_freq: 0.008009
[16:21:48.926] iteration 24512: loss: 0.044873, loss_s1: 0.034671, loss_fp: 0.001075, loss_freq: 0.020110
[16:21:49.548] iteration 24513: loss: 0.060803, loss_s1: 0.032763, loss_fp: 0.001184, loss_freq: 0.042877
[16:21:50.169] iteration 24514: loss: 0.060659, loss_s1: 0.043449, loss_fp: 0.002633, loss_freq: 0.017830
[16:21:50.788] iteration 24515: loss: 0.060565, loss_s1: 0.072891, loss_fp: 0.001001, loss_freq: 0.005312
[16:21:51.412] iteration 24516: loss: 0.051669, loss_s1: 0.040036, loss_fp: 0.005345, loss_freq: 0.020432
[16:21:52.025] iteration 24517: loss: 0.053178, loss_s1: 0.017270, loss_fp: 0.001033, loss_freq: 0.025356
[16:21:52.642] iteration 24518: loss: 0.079695, loss_s1: 0.030720, loss_fp: 0.001535, loss_freq: 0.009749
[16:21:53.254] iteration 24519: loss: 0.050367, loss_s1: 0.020668, loss_fp: 0.003359, loss_freq: 0.035828
[16:21:53.876] iteration 24520: loss: 0.066189, loss_s1: 0.059435, loss_fp: 0.002635, loss_freq: 0.021708
[16:21:54.491] iteration 24521: loss: 0.044551, loss_s1: 0.036781, loss_fp: 0.002113, loss_freq: 0.018803
[16:21:55.106] iteration 24522: loss: 0.047360, loss_s1: 0.043768, loss_fp: 0.004951, loss_freq: 0.011282
[16:21:55.731] iteration 24523: loss: 0.044019, loss_s1: 0.018527, loss_fp: 0.007057, loss_freq: 0.011528
[16:21:56.351] iteration 24524: loss: 0.048944, loss_s1: 0.030019, loss_fp: 0.003922, loss_freq: 0.020933
[16:21:56.991] iteration 24525: loss: 0.082090, loss_s1: 0.050984, loss_fp: 0.003835, loss_freq: 0.071097
[16:21:57.607] iteration 24526: loss: 0.031959, loss_s1: 0.017495, loss_fp: 0.001191, loss_freq: 0.015555
[16:21:58.220] iteration 24527: loss: 0.060324, loss_s1: 0.057061, loss_fp: 0.007954, loss_freq: 0.009667
[16:21:58.850] iteration 24528: loss: 0.064765, loss_s1: 0.037187, loss_fp: 0.011250, loss_freq: 0.049412
[16:21:59.714] iteration 24529: loss: 0.057777, loss_s1: 0.035098, loss_fp: 0.011269, loss_freq: 0.025823
[16:22:00.609] iteration 24530: loss: 0.037361, loss_s1: 0.015527, loss_fp: 0.004700, loss_freq: 0.027708
[16:22:01.364] iteration 24531: loss: 0.051871, loss_s1: 0.019048, loss_fp: 0.001896, loss_freq: 0.010668
[16:22:02.053] iteration 24532: loss: 0.072491, loss_s1: 0.064142, loss_fp: 0.005967, loss_freq: 0.029788
[16:22:02.674] iteration 24533: loss: 0.074514, loss_s1: 0.057172, loss_fp: 0.009844, loss_freq: 0.030458
[16:22:03.290] iteration 24534: loss: 0.054944, loss_s1: 0.032741, loss_fp: 0.000535, loss_freq: 0.039968
[16:22:03.911] iteration 24535: loss: 0.047137, loss_s1: 0.024580, loss_fp: 0.003615, loss_freq: 0.013969
[16:22:04.527] iteration 24536: loss: 0.038517, loss_s1: 0.032667, loss_fp: 0.002505, loss_freq: 0.008487
[16:22:05.140] iteration 24537: loss: 0.063726, loss_s1: 0.054953, loss_fp: 0.004958, loss_freq: 0.029619
[16:22:05.759] iteration 24538: loss: 0.051409, loss_s1: 0.032001, loss_fp: 0.008916, loss_freq: 0.023186
[16:22:06.384] iteration 24539: loss: 0.052444, loss_s1: 0.033646, loss_fp: 0.002091, loss_freq: 0.037803
[16:22:07.035] iteration 24540: loss: 0.046194, loss_s1: 0.018773, loss_fp: 0.003666, loss_freq: 0.028159
[16:22:07.647] iteration 24541: loss: 0.027995, loss_s1: 0.009577, loss_fp: 0.001168, loss_freq: 0.007318
[16:22:08.261] iteration 24542: loss: 0.051107, loss_s1: 0.038350, loss_fp: 0.001128, loss_freq: 0.019241
[16:22:08.882] iteration 24543: loss: 0.029850, loss_s1: 0.013992, loss_fp: 0.002904, loss_freq: 0.016272
[16:22:09.503] iteration 24544: loss: 0.053001, loss_s1: 0.030070, loss_fp: 0.000455, loss_freq: 0.014846
[16:22:10.123] iteration 24545: loss: 0.048596, loss_s1: 0.029536, loss_fp: 0.002198, loss_freq: 0.032295
[16:22:10.747] iteration 24546: loss: 0.045306, loss_s1: 0.038383, loss_fp: 0.001619, loss_freq: 0.003566
[16:22:11.371] iteration 24547: loss: 0.037184, loss_s1: 0.032634, loss_fp: 0.001562, loss_freq: 0.006560
[16:22:12.003] iteration 24548: loss: 0.036639, loss_s1: 0.011620, loss_fp: 0.000750, loss_freq: 0.021142
[16:22:12.619] iteration 24549: loss: 0.038357, loss_s1: 0.013619, loss_fp: 0.001365, loss_freq: 0.004476
[16:22:13.241] iteration 24550: loss: 0.076477, loss_s1: 0.036868, loss_fp: 0.003275, loss_freq: 0.057787
[16:22:13.870] iteration 24551: loss: 0.039117, loss_s1: 0.022526, loss_fp: 0.004658, loss_freq: 0.011426
[16:22:14.480] iteration 24552: loss: 0.044151, loss_s1: 0.010000, loss_fp: 0.002632, loss_freq: 0.012512
[16:22:15.104] iteration 24553: loss: 0.071331, loss_s1: 0.057247, loss_fp: 0.004080, loss_freq: 0.038724
[16:22:15.732] iteration 24554: loss: 0.044507, loss_s1: 0.038171, loss_fp: 0.000616, loss_freq: 0.017917
[16:22:16.357] iteration 24555: loss: 0.052638, loss_s1: 0.042398, loss_fp: 0.000552, loss_freq: 0.019137
[16:22:16.976] iteration 24556: loss: 0.053081, loss_s1: 0.051451, loss_fp: 0.005665, loss_freq: 0.019028
[16:22:17.610] iteration 24557: loss: 0.035594, loss_s1: 0.017294, loss_fp: 0.002178, loss_freq: 0.013951
[16:22:18.279] iteration 24558: loss: 0.039333, loss_s1: 0.021530, loss_fp: 0.002469, loss_freq: 0.011799
[16:22:18.895] iteration 24559: loss: 0.059704, loss_s1: 0.057281, loss_fp: 0.000533, loss_freq: 0.019353
[16:22:19.535] iteration 24560: loss: 0.055614, loss_s1: 0.025659, loss_fp: 0.002505, loss_freq: 0.047244
[16:22:20.170] iteration 24561: loss: 0.056526, loss_s1: 0.067183, loss_fp: 0.001346, loss_freq: 0.009473
[16:22:20.793] iteration 24562: loss: 0.068057, loss_s1: 0.047614, loss_fp: 0.009453, loss_freq: 0.030778
[16:22:21.418] iteration 24563: loss: 0.045920, loss_s1: 0.043079, loss_fp: 0.003792, loss_freq: 0.015573
[16:22:22.037] iteration 24564: loss: 0.044167, loss_s1: 0.043906, loss_fp: 0.001925, loss_freq: 0.007038
[16:22:22.666] iteration 24565: loss: 0.049801, loss_s1: 0.045054, loss_fp: 0.003776, loss_freq: 0.021700
[16:22:23.301] iteration 24566: loss: 0.036584, loss_s1: 0.016828, loss_fp: 0.001747, loss_freq: 0.008121
[16:22:23.937] iteration 24567: loss: 0.064059, loss_s1: 0.058123, loss_fp: 0.005178, loss_freq: 0.029738
[16:22:24.572] iteration 24568: loss: 0.048307, loss_s1: 0.007983, loss_fp: 0.000620, loss_freq: 0.024909
[16:22:25.206] iteration 24569: loss: 0.052569, loss_s1: 0.052774, loss_fp: 0.002858, loss_freq: 0.019119
[16:22:25.851] iteration 24570: loss: 0.035449, loss_s1: 0.019096, loss_fp: 0.001912, loss_freq: 0.011947
[16:22:26.472] iteration 24571: loss: 0.062998, loss_s1: 0.072568, loss_fp: 0.005520, loss_freq: 0.015466
[16:22:27.100] iteration 24572: loss: 0.044515, loss_s1: 0.041066, loss_fp: 0.001128, loss_freq: 0.017960
[16:22:27.724] iteration 24573: loss: 0.046225, loss_s1: 0.028394, loss_fp: 0.003109, loss_freq: 0.012124
[16:22:28.383] iteration 24574: loss: 0.075911, loss_s1: 0.061570, loss_fp: 0.004571, loss_freq: 0.027033
[16:22:29.005] iteration 24575: loss: 0.067912, loss_s1: 0.072111, loss_fp: 0.003217, loss_freq: 0.016834
[16:22:29.623] iteration 24576: loss: 0.059604, loss_s1: 0.048617, loss_fp: 0.004672, loss_freq: 0.010116
[16:22:30.247] iteration 24577: loss: 0.054275, loss_s1: 0.064449, loss_fp: 0.009039, loss_freq: 0.010097
[16:22:30.861] iteration 24578: loss: 0.080994, loss_s1: 0.064430, loss_fp: 0.004083, loss_freq: 0.063495
[16:22:31.478] iteration 24579: loss: 0.049344, loss_s1: 0.025758, loss_fp: 0.002661, loss_freq: 0.012504
[16:22:32.091] iteration 24580: loss: 0.047506, loss_s1: 0.031017, loss_fp: 0.004878, loss_freq: 0.028535
[16:22:32.756] iteration 24581: loss: 0.065072, loss_s1: 0.047661, loss_fp: 0.005115, loss_freq: 0.025567
[16:22:33.375] iteration 24582: loss: 0.050586, loss_s1: 0.035247, loss_fp: 0.002450, loss_freq: 0.015951
[16:22:33.999] iteration 24583: loss: 0.057081, loss_s1: 0.052351, loss_fp: 0.004742, loss_freq: 0.023161
[16:22:34.687] iteration 24584: loss: 0.049705, loss_s1: 0.029471, loss_fp: 0.008681, loss_freq: 0.019312
[16:22:35.329] iteration 24585: loss: 0.067362, loss_s1: 0.052906, loss_fp: 0.000690, loss_freq: 0.038249
[16:22:35.958] iteration 24586: loss: 0.064154, loss_s1: 0.065068, loss_fp: 0.005906, loss_freq: 0.020498
[16:22:36.573] iteration 24587: loss: 0.062024, loss_s1: 0.049501, loss_fp: 0.000944, loss_freq: 0.021883
[16:22:37.194] iteration 24588: loss: 0.062740, loss_s1: 0.032349, loss_fp: 0.008568, loss_freq: 0.048477
[16:22:37.815] iteration 24589: loss: 0.042160, loss_s1: 0.024573, loss_fp: 0.002928, loss_freq: 0.021002
[16:22:38.439] iteration 24590: loss: 0.081831, loss_s1: 0.069540, loss_fp: 0.006233, loss_freq: 0.013987
[16:22:39.064] iteration 24591: loss: 0.036215, loss_s1: 0.026365, loss_fp: 0.006172, loss_freq: 0.007542
[16:22:39.686] iteration 24592: loss: 0.032637, loss_s1: 0.010672, loss_fp: 0.003454, loss_freq: 0.022824
[16:22:40.327] iteration 24593: loss: 0.052071, loss_s1: 0.037016, loss_fp: 0.008011, loss_freq: 0.012399
[16:22:40.949] iteration 24594: loss: 0.065265, loss_s1: 0.051347, loss_fp: 0.001282, loss_freq: 0.041560
[16:22:41.565] iteration 24595: loss: 0.084026, loss_s1: 0.087922, loss_fp: 0.021327, loss_freq: 0.020097
[16:22:42.186] iteration 24596: loss: 0.060625, loss_s1: 0.030123, loss_fp: 0.001609, loss_freq: 0.041256
[16:22:43.156] iteration 24597: loss: 0.047169, loss_s1: 0.037667, loss_fp: 0.001541, loss_freq: 0.005429
[16:22:43.809] iteration 24598: loss: 0.050724, loss_s1: 0.049405, loss_fp: 0.001965, loss_freq: 0.011725
[16:22:44.455] iteration 24599: loss: 0.034538, loss_s1: 0.009159, loss_fp: 0.001634, loss_freq: 0.020276
[16:22:45.093] iteration 24600: loss: 0.087938, loss_s1: 0.054376, loss_fp: 0.002870, loss_freq: 0.020312
[16:22:48.694] iteration 24600 : mean_dice : 0.801077
[16:22:49.356] iteration 24601: loss: 0.056792, loss_s1: 0.045075, loss_fp: 0.002940, loss_freq: 0.031655
[16:22:49.988] iteration 24602: loss: 0.070737, loss_s1: 0.013122, loss_fp: 0.001701, loss_freq: 0.017173
[16:22:50.617] iteration 24603: loss: 0.041556, loss_s1: 0.036584, loss_fp: 0.003103, loss_freq: 0.013821
[16:22:51.247] iteration 24604: loss: 0.060692, loss_s1: 0.045359, loss_fp: 0.012142, loss_freq: 0.024912
[16:22:51.865] iteration 24605: loss: 0.046835, loss_s1: 0.037365, loss_fp: 0.004461, loss_freq: 0.007543
[16:22:52.485] iteration 24606: loss: 0.045487, loss_s1: 0.014078, loss_fp: 0.000306, loss_freq: 0.011700
[16:22:53.120] iteration 24607: loss: 0.057382, loss_s1: 0.051121, loss_fp: 0.002061, loss_freq: 0.016785
[16:22:53.742] iteration 24608: loss: 0.046520, loss_s1: 0.018009, loss_fp: 0.017017, loss_freq: 0.018449
[16:22:54.368] iteration 24609: loss: 0.041735, loss_s1: 0.041120, loss_fp: 0.001369, loss_freq: 0.008342
[16:22:54.987] iteration 24610: loss: 0.048969, loss_s1: 0.042295, loss_fp: 0.003516, loss_freq: 0.017469
[16:22:55.651] iteration 24611: loss: 0.049453, loss_s1: 0.049976, loss_fp: 0.001973, loss_freq: 0.013351
[16:22:56.277] iteration 24612: loss: 0.056205, loss_s1: 0.054884, loss_fp: 0.002527, loss_freq: 0.020906
[16:22:56.905] iteration 24613: loss: 0.081170, loss_s1: 0.043307, loss_fp: 0.002708, loss_freq: 0.026565
[16:22:57.526] iteration 24614: loss: 0.057855, loss_s1: 0.048768, loss_fp: 0.006420, loss_freq: 0.027927
[16:22:58.155] iteration 24615: loss: 0.052009, loss_s1: 0.030433, loss_fp: 0.004617, loss_freq: 0.035716
[16:22:58.787] iteration 24616: loss: 0.033785, loss_s1: 0.026440, loss_fp: 0.001048, loss_freq: 0.008541
[16:22:59.412] iteration 24617: loss: 0.100488, loss_s1: 0.059211, loss_fp: 0.004166, loss_freq: 0.080326
[16:23:00.038] iteration 24618: loss: 0.038331, loss_s1: 0.028145, loss_fp: 0.001659, loss_freq: 0.015768
[16:23:00.660] iteration 24619: loss: 0.043301, loss_s1: 0.019302, loss_fp: 0.003850, loss_freq: 0.017110
[16:23:01.282] iteration 24620: loss: 0.044797, loss_s1: 0.020847, loss_fp: 0.005675, loss_freq: 0.014536
[16:23:01.897] iteration 24621: loss: 0.045080, loss_s1: 0.036923, loss_fp: 0.001380, loss_freq: 0.010511
[16:23:02.515] iteration 24622: loss: 0.070301, loss_s1: 0.031577, loss_fp: 0.020899, loss_freq: 0.038559
[16:23:03.140] iteration 24623: loss: 0.074322, loss_s1: 0.038792, loss_fp: 0.009568, loss_freq: 0.027431
[16:23:03.763] iteration 24624: loss: 0.043599, loss_s1: 0.027736, loss_fp: 0.000792, loss_freq: 0.013915
[16:23:04.391] iteration 24625: loss: 0.054111, loss_s1: 0.033598, loss_fp: 0.003568, loss_freq: 0.027034
[16:23:05.108] iteration 24626: loss: 0.051325, loss_s1: 0.030316, loss_fp: 0.000948, loss_freq: 0.021901
[16:23:05.766] iteration 24627: loss: 0.048139, loss_s1: 0.034832, loss_fp: 0.001230, loss_freq: 0.027743
[16:23:06.390] iteration 24628: loss: 0.078900, loss_s1: 0.046347, loss_fp: 0.008015, loss_freq: 0.051247
[16:23:07.023] iteration 24629: loss: 0.067492, loss_s1: 0.055239, loss_fp: 0.012342, loss_freq: 0.036306
[16:23:07.653] iteration 24630: loss: 0.052512, loss_s1: 0.027747, loss_fp: 0.006265, loss_freq: 0.033365
[16:23:08.291] iteration 24631: loss: 0.055322, loss_s1: 0.053900, loss_fp: 0.003551, loss_freq: 0.011884
[16:23:08.936] iteration 24632: loss: 0.060524, loss_s1: 0.045640, loss_fp: 0.003685, loss_freq: 0.030909
[16:23:09.558] iteration 24633: loss: 0.056351, loss_s1: 0.033852, loss_fp: 0.001501, loss_freq: 0.031560
[16:23:10.185] iteration 24634: loss: 0.038051, loss_s1: 0.037146, loss_fp: 0.006077, loss_freq: 0.005035
[16:23:10.807] iteration 24635: loss: 0.100458, loss_s1: 0.070595, loss_fp: 0.031083, loss_freq: 0.053056
[16:23:11.430] iteration 24636: loss: 0.028107, loss_s1: 0.022178, loss_fp: 0.003775, loss_freq: 0.005380
[16:23:12.054] iteration 24637: loss: 0.056394, loss_s1: 0.060868, loss_fp: 0.004405, loss_freq: 0.008898
[16:23:12.679] iteration 24638: loss: 0.046252, loss_s1: 0.020012, loss_fp: 0.009020, loss_freq: 0.032169
[16:23:13.306] iteration 24639: loss: 0.054464, loss_s1: 0.038270, loss_fp: 0.000784, loss_freq: 0.021279
[16:23:13.919] iteration 24640: loss: 0.049735, loss_s1: 0.022746, loss_fp: 0.001741, loss_freq: 0.038094
[16:23:14.541] iteration 24641: loss: 0.049122, loss_s1: 0.007107, loss_fp: 0.000485, loss_freq: 0.008480
[16:23:15.155] iteration 24642: loss: 0.055512, loss_s1: 0.054064, loss_fp: 0.000926, loss_freq: 0.024558
[16:23:15.773] iteration 24643: loss: 0.075417, loss_s1: 0.080797, loss_fp: 0.006343, loss_freq: 0.020815
[16:23:16.396] iteration 24644: loss: 0.064028, loss_s1: 0.048698, loss_fp: 0.002383, loss_freq: 0.035258
[16:23:17.012] iteration 24645: loss: 0.068770, loss_s1: 0.047195, loss_fp: 0.005449, loss_freq: 0.052124
[16:23:17.627] iteration 24646: loss: 0.034385, loss_s1: 0.015886, loss_fp: 0.002589, loss_freq: 0.016250
[16:23:18.244] iteration 24647: loss: 0.061627, loss_s1: 0.056232, loss_fp: 0.001341, loss_freq: 0.033028
[16:23:18.868] iteration 24648: loss: 0.041944, loss_s1: 0.012136, loss_fp: 0.001073, loss_freq: 0.027578
[16:23:19.500] iteration 24649: loss: 0.040873, loss_s1: 0.025287, loss_fp: 0.003953, loss_freq: 0.014296
[16:23:20.124] iteration 24650: loss: 0.076618, loss_s1: 0.057061, loss_fp: 0.012326, loss_freq: 0.046795
[16:23:20.749] iteration 24651: loss: 0.039445, loss_s1: 0.030655, loss_fp: 0.002271, loss_freq: 0.004428
[16:23:21.370] iteration 24652: loss: 0.068653, loss_s1: 0.058777, loss_fp: 0.001116, loss_freq: 0.022460
[16:23:21.991] iteration 24653: loss: 0.050137, loss_s1: 0.038492, loss_fp: 0.010426, loss_freq: 0.023123
[16:23:22.618] iteration 24654: loss: 0.048757, loss_s1: 0.039073, loss_fp: 0.007014, loss_freq: 0.011774
[16:23:23.237] iteration 24655: loss: 0.075688, loss_s1: 0.043839, loss_fp: 0.001783, loss_freq: 0.069923
[16:23:23.859] iteration 24656: loss: 0.068486, loss_s1: 0.071474, loss_fp: 0.003319, loss_freq: 0.022243
[16:23:24.478] iteration 24657: loss: 0.048383, loss_s1: 0.020902, loss_fp: 0.002767, loss_freq: 0.014064
[16:23:25.096] iteration 24658: loss: 0.074370, loss_s1: 0.080660, loss_fp: 0.004752, loss_freq: 0.024111
[16:23:25.720] iteration 24659: loss: 0.071339, loss_s1: 0.068375, loss_fp: 0.002567, loss_freq: 0.039167
[16:23:26.338] iteration 24660: loss: 0.034246, loss_s1: 0.009605, loss_fp: 0.001639, loss_freq: 0.012464
[16:23:26.963] iteration 24661: loss: 0.063193, loss_s1: 0.032934, loss_fp: 0.001681, loss_freq: 0.038036
[16:23:27.587] iteration 24662: loss: 0.047610, loss_s1: 0.030011, loss_fp: 0.002948, loss_freq: 0.024733
[16:23:28.204] iteration 24663: loss: 0.086529, loss_s1: 0.068653, loss_fp: 0.009558, loss_freq: 0.046299
[16:23:28.828] iteration 24664: loss: 0.054693, loss_s1: 0.036461, loss_fp: 0.008487, loss_freq: 0.015533
[16:23:29.448] iteration 24665: loss: 0.027389, loss_s1: 0.014303, loss_fp: 0.003784, loss_freq: 0.005251
[16:23:30.119] iteration 24666: loss: 0.044031, loss_s1: 0.021971, loss_fp: 0.000883, loss_freq: 0.012152
[16:23:30.779] iteration 24667: loss: 0.039261, loss_s1: 0.021663, loss_fp: 0.003025, loss_freq: 0.022078
[16:23:31.447] iteration 24668: loss: 0.043167, loss_s1: 0.039076, loss_fp: 0.003923, loss_freq: 0.007602
[16:23:32.103] iteration 24669: loss: 0.079666, loss_s1: 0.036459, loss_fp: 0.007884, loss_freq: 0.075747
[16:23:32.733] iteration 24670: loss: 0.105316, loss_s1: 0.054496, loss_fp: 0.026637, loss_freq: 0.070945
[16:23:33.363] iteration 24671: loss: 0.047088, loss_s1: 0.038980, loss_fp: 0.002660, loss_freq: 0.025398
[16:23:33.984] iteration 24672: loss: 0.049147, loss_s1: 0.038154, loss_fp: 0.000732, loss_freq: 0.016666
[16:23:34.600] iteration 24673: loss: 0.045324, loss_s1: 0.037029, loss_fp: 0.004086, loss_freq: 0.010752
[16:23:35.221] iteration 24674: loss: 0.034894, loss_s1: 0.008648, loss_fp: 0.000618, loss_freq: 0.012116
[16:23:35.839] iteration 24675: loss: 0.054395, loss_s1: 0.027109, loss_fp: 0.006016, loss_freq: 0.034358
[16:23:36.461] iteration 24676: loss: 0.058512, loss_s1: 0.027964, loss_fp: 0.007621, loss_freq: 0.026161
[16:23:37.079] iteration 24677: loss: 0.059395, loss_s1: 0.039375, loss_fp: 0.011874, loss_freq: 0.025864
[16:23:37.697] iteration 24678: loss: 0.061528, loss_s1: 0.057249, loss_fp: 0.002971, loss_freq: 0.026347
[16:23:38.321] iteration 24679: loss: 0.063144, loss_s1: 0.046783, loss_fp: 0.003137, loss_freq: 0.028524
[16:23:38.952] iteration 24680: loss: 0.045203, loss_s1: 0.038490, loss_fp: 0.001698, loss_freq: 0.010703
[16:23:39.569] iteration 24681: loss: 0.049162, loss_s1: 0.028137, loss_fp: 0.002818, loss_freq: 0.030572
[16:23:40.198] iteration 24682: loss: 0.060759, loss_s1: 0.024656, loss_fp: 0.016708, loss_freq: 0.042145
[16:23:40.819] iteration 24683: loss: 0.042088, loss_s1: 0.029181, loss_fp: 0.000586, loss_freq: 0.002961
[16:23:41.442] iteration 24684: loss: 0.032249, loss_s1: 0.006846, loss_fp: 0.002429, loss_freq: 0.019016
[16:23:42.059] iteration 24685: loss: 0.032820, loss_s1: 0.026692, loss_fp: 0.002723, loss_freq: 0.005286
[16:23:42.678] iteration 24686: loss: 0.039059, loss_s1: 0.033025, loss_fp: 0.005516, loss_freq: 0.015145
[16:23:43.297] iteration 24687: loss: 0.067321, loss_s1: 0.036123, loss_fp: 0.001523, loss_freq: 0.030699
[16:23:43.915] iteration 24688: loss: 0.062097, loss_s1: 0.050003, loss_fp: 0.000601, loss_freq: 0.041833
[16:23:44.535] iteration 24689: loss: 0.040155, loss_s1: 0.023391, loss_fp: 0.004726, loss_freq: 0.013260
[16:23:45.174] iteration 24690: loss: 0.054315, loss_s1: 0.044477, loss_fp: 0.003815, loss_freq: 0.023642
[16:23:45.825] iteration 24691: loss: 0.051026, loss_s1: 0.032172, loss_fp: 0.006520, loss_freq: 0.029050
[16:23:46.456] iteration 24692: loss: 0.045624, loss_s1: 0.029777, loss_fp: 0.003222, loss_freq: 0.006860
[16:23:47.065] iteration 24693: loss: 0.078378, loss_s1: 0.075741, loss_fp: 0.001101, loss_freq: 0.041830
[16:23:47.686] iteration 24694: loss: 0.041660, loss_s1: 0.017756, loss_fp: 0.004680, loss_freq: 0.023351
[16:23:48.331] iteration 24695: loss: 0.038814, loss_s1: 0.013523, loss_fp: 0.002456, loss_freq: 0.019667
[16:23:48.960] iteration 24696: loss: 0.051630, loss_s1: 0.030488, loss_fp: 0.004900, loss_freq: 0.014056
[16:23:49.581] iteration 24697: loss: 0.037202, loss_s1: 0.021207, loss_fp: 0.000642, loss_freq: 0.010378
[16:23:50.205] iteration 24698: loss: 0.052832, loss_s1: 0.031597, loss_fp: 0.002391, loss_freq: 0.022855
[16:23:50.856] iteration 24699: loss: 0.076268, loss_s1: 0.081745, loss_fp: 0.005537, loss_freq: 0.032510
[16:23:51.480] iteration 24700: loss: 0.031931, loss_s1: 0.014179, loss_fp: 0.003415, loss_freq: 0.008515
[16:23:52.099] iteration 24701: loss: 0.058326, loss_s1: 0.037015, loss_fp: 0.001835, loss_freq: 0.011874
[16:23:52.724] iteration 24702: loss: 0.047764, loss_s1: 0.023654, loss_fp: 0.013557, loss_freq: 0.022261
[16:23:53.349] iteration 24703: loss: 0.070884, loss_s1: 0.049786, loss_fp: 0.008649, loss_freq: 0.034259
[16:23:53.977] iteration 24704: loss: 0.061215, loss_s1: 0.022693, loss_fp: 0.007899, loss_freq: 0.055204
[16:23:54.598] iteration 24705: loss: 0.063742, loss_s1: 0.037674, loss_fp: 0.005866, loss_freq: 0.032713
[16:23:55.227] iteration 24706: loss: 0.085468, loss_s1: 0.065172, loss_fp: 0.003902, loss_freq: 0.074071
[16:23:55.858] iteration 24707: loss: 0.045269, loss_s1: 0.026322, loss_fp: 0.004539, loss_freq: 0.019824
[16:23:56.481] iteration 24708: loss: 0.051983, loss_s1: 0.061378, loss_fp: 0.005973, loss_freq: 0.009061
[16:23:57.102] iteration 24709: loss: 0.061960, loss_s1: 0.057227, loss_fp: 0.003790, loss_freq: 0.016163
[16:23:57.729] iteration 24710: loss: 0.063409, loss_s1: 0.063628, loss_fp: 0.003703, loss_freq: 0.023810
[16:23:58.352] iteration 24711: loss: 0.069257, loss_s1: 0.054882, loss_fp: 0.002072, loss_freq: 0.012318
[16:23:58.974] iteration 24712: loss: 0.046098, loss_s1: 0.029481, loss_fp: 0.004803, loss_freq: 0.020084
[16:23:59.597] iteration 24713: loss: 0.038501, loss_s1: 0.026651, loss_fp: 0.003930, loss_freq: 0.016181
[16:24:00.224] iteration 24714: loss: 0.058782, loss_s1: 0.058047, loss_fp: 0.003322, loss_freq: 0.020311
[16:24:00.839] iteration 24715: loss: 0.056169, loss_s1: 0.052813, loss_fp: 0.002874, loss_freq: 0.028260
[16:24:01.483] iteration 24716: loss: 0.049773, loss_s1: 0.028174, loss_fp: 0.004002, loss_freq: 0.029822
[16:24:02.129] iteration 24717: loss: 0.054259, loss_s1: 0.041197, loss_fp: 0.002076, loss_freq: 0.019306
[16:24:02.777] iteration 24718: loss: 0.063572, loss_s1: 0.025921, loss_fp: 0.003072, loss_freq: 0.043930
[16:24:03.457] iteration 24719: loss: 0.052660, loss_s1: 0.032224, loss_fp: 0.008441, loss_freq: 0.028645
[16:24:04.077] iteration 24720: loss: 0.044147, loss_s1: 0.040024, loss_fp: 0.004282, loss_freq: 0.012567
[16:24:04.728] iteration 24721: loss: 0.075705, loss_s1: 0.066214, loss_fp: 0.001316, loss_freq: 0.058777
[16:24:05.580] iteration 24722: loss: 0.044391, loss_s1: 0.023327, loss_fp: 0.007661, loss_freq: 0.008189
[16:24:06.329] iteration 24723: loss: 0.045008, loss_s1: 0.025234, loss_fp: 0.000517, loss_freq: 0.034323
[16:24:07.029] iteration 24724: loss: 0.052409, loss_s1: 0.027151, loss_fp: 0.002709, loss_freq: 0.044536
[16:24:07.648] iteration 24725: loss: 0.048249, loss_s1: 0.038183, loss_fp: 0.002740, loss_freq: 0.016134
[16:24:08.273] iteration 24726: loss: 0.063563, loss_s1: 0.028000, loss_fp: 0.007573, loss_freq: 0.038655
[16:24:08.919] iteration 24727: loss: 0.053383, loss_s1: 0.035714, loss_fp: 0.001664, loss_freq: 0.020497
[16:24:09.560] iteration 24728: loss: 0.070605, loss_s1: 0.056500, loss_fp: 0.004749, loss_freq: 0.045835
[16:24:10.198] iteration 24729: loss: 0.031856, loss_s1: 0.017045, loss_fp: 0.005223, loss_freq: 0.010809
[16:24:10.854] iteration 24730: loss: 0.065472, loss_s1: 0.030845, loss_fp: 0.002844, loss_freq: 0.042149
[16:24:11.473] iteration 24731: loss: 0.047177, loss_s1: 0.027099, loss_fp: 0.003163, loss_freq: 0.023399
[16:24:12.112] iteration 24732: loss: 0.048658, loss_s1: 0.036506, loss_fp: 0.003138, loss_freq: 0.025421
[16:24:12.773] iteration 24733: loss: 0.059860, loss_s1: 0.033409, loss_fp: 0.007240, loss_freq: 0.029332
[16:24:13.428] iteration 24734: loss: 0.033780, loss_s1: 0.011382, loss_fp: 0.002932, loss_freq: 0.019426
[16:24:14.096] iteration 24735: loss: 0.038225, loss_s1: 0.023223, loss_fp: 0.001286, loss_freq: 0.016296
[16:24:14.736] iteration 24736: loss: 0.081959, loss_s1: 0.031395, loss_fp: 0.003009, loss_freq: 0.011308
[16:24:15.392] iteration 24737: loss: 0.046208, loss_s1: 0.031879, loss_fp: 0.006648, loss_freq: 0.018473
[16:24:16.013] iteration 24738: loss: 0.075364, loss_s1: 0.084352, loss_fp: 0.006021, loss_freq: 0.014643
[16:24:16.634] iteration 24739: loss: 0.034381, loss_s1: 0.022320, loss_fp: 0.001475, loss_freq: 0.014809
[16:24:17.652] iteration 24740: loss: 0.042472, loss_s1: 0.032617, loss_fp: 0.000635, loss_freq: 0.016695
[16:24:18.291] iteration 24741: loss: 0.060763, loss_s1: 0.062060, loss_fp: 0.005439, loss_freq: 0.013966
[16:24:18.929] iteration 24742: loss: 0.044698, loss_s1: 0.024546, loss_fp: 0.005460, loss_freq: 0.028726
[16:24:19.569] iteration 24743: loss: 0.058870, loss_s1: 0.043934, loss_fp: 0.007268, loss_freq: 0.027325
[16:24:20.210] iteration 24744: loss: 0.074528, loss_s1: 0.075966, loss_fp: 0.002094, loss_freq: 0.042532
[16:24:20.851] iteration 24745: loss: 0.072382, loss_s1: 0.019668, loss_fp: 0.003405, loss_freq: 0.008030
[16:24:21.475] iteration 24746: loss: 0.026707, loss_s1: 0.007582, loss_fp: 0.002421, loss_freq: 0.013200
[16:24:22.111] iteration 24747: loss: 0.038376, loss_s1: 0.015818, loss_fp: 0.005708, loss_freq: 0.020581
[16:24:22.734] iteration 24748: loss: 0.056325, loss_s1: 0.050810, loss_fp: 0.005563, loss_freq: 0.016087
[16:24:23.402] iteration 24749: loss: 0.043705, loss_s1: 0.020254, loss_fp: 0.000590, loss_freq: 0.005981
[16:24:24.019] iteration 24750: loss: 0.071509, loss_s1: 0.051392, loss_fp: 0.003799, loss_freq: 0.026795
[16:24:24.638] iteration 24751: loss: 0.049640, loss_s1: 0.024637, loss_fp: 0.002627, loss_freq: 0.019697
[16:24:25.248] iteration 24752: loss: 0.045691, loss_s1: 0.039259, loss_fp: 0.002490, loss_freq: 0.011923
[16:24:25.868] iteration 24753: loss: 0.038575, loss_s1: 0.016011, loss_fp: 0.001029, loss_freq: 0.009938
[16:24:26.489] iteration 24754: loss: 0.072134, loss_s1: 0.061495, loss_fp: 0.008759, loss_freq: 0.033735
[16:24:27.101] iteration 24755: loss: 0.061952, loss_s1: 0.048217, loss_fp: 0.005959, loss_freq: 0.026517
[16:24:27.716] iteration 24756: loss: 0.052941, loss_s1: 0.029739, loss_fp: 0.007495, loss_freq: 0.032867
[16:24:28.336] iteration 24757: loss: 0.059989, loss_s1: 0.043036, loss_fp: 0.002363, loss_freq: 0.040565
[16:24:29.022] iteration 24758: loss: 0.054029, loss_s1: 0.045231, loss_fp: 0.002539, loss_freq: 0.029020
[16:24:29.672] iteration 24759: loss: 0.025296, loss_s1: 0.010801, loss_fp: 0.001029, loss_freq: 0.010254
[16:24:30.285] iteration 24760: loss: 0.068790, loss_s1: 0.025106, loss_fp: 0.001881, loss_freq: 0.042752
[16:24:30.902] iteration 24761: loss: 0.038208, loss_s1: 0.022464, loss_fp: 0.005490, loss_freq: 0.021735
[16:24:31.529] iteration 24762: loss: 0.068745, loss_s1: 0.044775, loss_fp: 0.002951, loss_freq: 0.033215
[16:24:32.152] iteration 24763: loss: 0.054203, loss_s1: 0.051549, loss_fp: 0.001748, loss_freq: 0.007125
[16:24:32.789] iteration 24764: loss: 0.035306, loss_s1: 0.013762, loss_fp: 0.001542, loss_freq: 0.013739
[16:24:33.411] iteration 24765: loss: 0.062056, loss_s1: 0.032094, loss_fp: 0.010876, loss_freq: 0.019561
[16:24:34.022] iteration 24766: loss: 0.061057, loss_s1: 0.036959, loss_fp: 0.003193, loss_freq: 0.022137
[16:24:34.635] iteration 24767: loss: 0.039650, loss_s1: 0.035581, loss_fp: 0.002828, loss_freq: 0.005921
[16:24:35.254] iteration 24768: loss: 0.042369, loss_s1: 0.029414, loss_fp: 0.007694, loss_freq: 0.006448
[16:24:35.877] iteration 24769: loss: 0.035991, loss_s1: 0.013847, loss_fp: 0.002939, loss_freq: 0.011989
[16:24:36.496] iteration 24770: loss: 0.040743, loss_s1: 0.013462, loss_fp: 0.002157, loss_freq: 0.020196
[16:24:37.118] iteration 24771: loss: 0.053897, loss_s1: 0.015230, loss_fp: 0.004213, loss_freq: 0.017434
[16:24:37.742] iteration 24772: loss: 0.070295, loss_s1: 0.046205, loss_fp: 0.006152, loss_freq: 0.052940
[16:24:38.360] iteration 24773: loss: 0.111970, loss_s1: 0.135148, loss_fp: 0.006294, loss_freq: 0.048811
[16:24:38.982] iteration 24774: loss: 0.091768, loss_s1: 0.084448, loss_fp: 0.005086, loss_freq: 0.035936
[16:24:39.601] iteration 24775: loss: 0.042982, loss_s1: 0.030542, loss_fp: 0.002255, loss_freq: 0.017405
[16:24:40.221] iteration 24776: loss: 0.042954, loss_s1: 0.009521, loss_fp: 0.000997, loss_freq: 0.016136
[16:24:40.870] iteration 24777: loss: 0.043647, loss_s1: 0.023278, loss_fp: 0.004520, loss_freq: 0.014264
[16:24:41.519] iteration 24778: loss: 0.068487, loss_s1: 0.038131, loss_fp: 0.003393, loss_freq: 0.047755
[16:24:42.154] iteration 24779: loss: 0.043215, loss_s1: 0.033601, loss_fp: 0.003886, loss_freq: 0.016276
[16:24:42.770] iteration 24780: loss: 0.070796, loss_s1: 0.034120, loss_fp: 0.003555, loss_freq: 0.017820
[16:24:43.413] iteration 24781: loss: 0.034571, loss_s1: 0.022338, loss_fp: 0.004200, loss_freq: 0.011399
[16:24:44.026] iteration 24782: loss: 0.053474, loss_s1: 0.038265, loss_fp: 0.007270, loss_freq: 0.018215
[16:24:44.650] iteration 24783: loss: 0.060593, loss_s1: 0.031816, loss_fp: 0.003556, loss_freq: 0.046076
[16:24:45.262] iteration 24784: loss: 0.050198, loss_s1: 0.013355, loss_fp: 0.002172, loss_freq: 0.011386
[16:24:45.879] iteration 24785: loss: 0.086126, loss_s1: 0.088035, loss_fp: 0.002306, loss_freq: 0.046808
[16:24:46.496] iteration 24786: loss: 0.042534, loss_s1: 0.022777, loss_fp: 0.013536, loss_freq: 0.010676
[16:24:47.117] iteration 24787: loss: 0.049650, loss_s1: 0.031436, loss_fp: 0.005807, loss_freq: 0.025025
[16:24:47.739] iteration 24788: loss: 0.068308, loss_s1: 0.063119, loss_fp: 0.006859, loss_freq: 0.027631
[16:24:48.357] iteration 24789: loss: 0.042036, loss_s1: 0.023584, loss_fp: 0.001094, loss_freq: 0.008939
[16:24:48.976] iteration 24790: loss: 0.058999, loss_s1: 0.035791, loss_fp: 0.005207, loss_freq: 0.042687
[16:24:49.598] iteration 24791: loss: 0.050644, loss_s1: 0.035794, loss_fp: 0.004113, loss_freq: 0.026218
[16:24:50.216] iteration 24792: loss: 0.041631, loss_s1: 0.033160, loss_fp: 0.003615, loss_freq: 0.011608
[16:24:50.883] iteration 24793: loss: 0.047182, loss_s1: 0.030753, loss_fp: 0.006476, loss_freq: 0.027145
[16:24:51.524] iteration 24794: loss: 0.034320, loss_s1: 0.015065, loss_fp: 0.003563, loss_freq: 0.005481
[16:24:52.162] iteration 24795: loss: 0.050035, loss_s1: 0.020361, loss_fp: 0.005139, loss_freq: 0.016559
[16:24:52.802] iteration 24796: loss: 0.054079, loss_s1: 0.040278, loss_fp: 0.002161, loss_freq: 0.038015
[16:24:53.432] iteration 24797: loss: 0.045963, loss_s1: 0.019459, loss_fp: 0.002864, loss_freq: 0.014001
[16:24:54.051] iteration 24798: loss: 0.072202, loss_s1: 0.048945, loss_fp: 0.005935, loss_freq: 0.048607
[16:24:54.672] iteration 24799: loss: 0.053303, loss_s1: 0.050550, loss_fp: 0.001617, loss_freq: 0.017979
[16:24:55.292] iteration 24800: loss: 0.040944, loss_s1: 0.017304, loss_fp: 0.008501, loss_freq: 0.017776
[16:24:58.526] iteration 24800 : mean_dice : 0.778992
[16:24:59.179] iteration 24801: loss: 0.073508, loss_s1: 0.061068, loss_fp: 0.004492, loss_freq: 0.006367
[16:24:59.797] iteration 24802: loss: 0.107113, loss_s1: 0.060871, loss_fp: 0.018016, loss_freq: 0.069011
[16:25:00.419] iteration 24803: loss: 0.049807, loss_s1: 0.038458, loss_fp: 0.001852, loss_freq: 0.012471
[16:25:01.057] iteration 24804: loss: 0.044866, loss_s1: 0.016214, loss_fp: 0.001430, loss_freq: 0.022191
[16:25:01.704] iteration 24805: loss: 0.040482, loss_s1: 0.028315, loss_fp: 0.002430, loss_freq: 0.009604
[16:25:02.395] iteration 24806: loss: 0.080245, loss_s1: 0.081718, loss_fp: 0.004013, loss_freq: 0.034767
[16:25:03.022] iteration 24807: loss: 0.047007, loss_s1: 0.046216, loss_fp: 0.001046, loss_freq: 0.016985
[16:25:03.644] iteration 24808: loss: 0.035513, loss_s1: 0.021839, loss_fp: 0.003228, loss_freq: 0.010598
[16:25:04.272] iteration 24809: loss: 0.063710, loss_s1: 0.030632, loss_fp: 0.010539, loss_freq: 0.012382
[16:25:04.897] iteration 24810: loss: 0.038793, loss_s1: 0.026509, loss_fp: 0.003363, loss_freq: 0.005422
[16:25:05.518] iteration 24811: loss: 0.060652, loss_s1: 0.047982, loss_fp: 0.004222, loss_freq: 0.030626
[16:25:06.151] iteration 24812: loss: 0.040826, loss_s1: 0.025238, loss_fp: 0.005091, loss_freq: 0.022465
[16:25:06.774] iteration 24813: loss: 0.069039, loss_s1: 0.039807, loss_fp: 0.004713, loss_freq: 0.040280
[16:25:07.401] iteration 24814: loss: 0.077950, loss_s1: 0.096971, loss_fp: 0.004266, loss_freq: 0.025256
[16:25:08.014] iteration 24815: loss: 0.057981, loss_s1: 0.061059, loss_fp: 0.002283, loss_freq: 0.012373
[16:25:08.635] iteration 24816: loss: 0.069964, loss_s1: 0.066521, loss_fp: 0.005647, loss_freq: 0.041569
[16:25:09.264] iteration 24817: loss: 0.049829, loss_s1: 0.036291, loss_fp: 0.006778, loss_freq: 0.019052
[16:25:09.882] iteration 24818: loss: 0.065516, loss_s1: 0.032538, loss_fp: 0.011249, loss_freq: 0.045165
[16:25:10.504] iteration 24819: loss: 0.086040, loss_s1: 0.067607, loss_fp: 0.008855, loss_freq: 0.019516
[16:25:11.147] iteration 24820: loss: 0.061355, loss_s1: 0.039526, loss_fp: 0.005987, loss_freq: 0.022779
[16:25:11.764] iteration 24821: loss: 0.042161, loss_s1: 0.023525, loss_fp: 0.004808, loss_freq: 0.014327
[16:25:12.381] iteration 24822: loss: 0.038391, loss_s1: 0.027942, loss_fp: 0.001395, loss_freq: 0.015137
[16:25:13.002] iteration 24823: loss: 0.040219, loss_s1: 0.023000, loss_fp: 0.006033, loss_freq: 0.016636
[16:25:13.623] iteration 24824: loss: 0.078034, loss_s1: 0.076933, loss_fp: 0.016219, loss_freq: 0.022802
[16:25:14.249] iteration 24825: loss: 0.050878, loss_s1: 0.029207, loss_fp: 0.002575, loss_freq: 0.037182
[16:25:14.919] iteration 24826: loss: 0.053183, loss_s1: 0.049777, loss_fp: 0.001388, loss_freq: 0.011189
[16:25:15.582] iteration 24827: loss: 0.030226, loss_s1: 0.009801, loss_fp: 0.000614, loss_freq: 0.014409
[16:25:16.225] iteration 24828: loss: 0.033693, loss_s1: 0.027056, loss_fp: 0.001748, loss_freq: 0.008950
[16:25:16.900] iteration 24829: loss: 0.043605, loss_s1: 0.039969, loss_fp: 0.004650, loss_freq: 0.010929
[16:25:17.524] iteration 24830: loss: 0.062593, loss_s1: 0.027212, loss_fp: 0.005661, loss_freq: 0.037540
[16:25:18.151] iteration 24831: loss: 0.048247, loss_s1: 0.026378, loss_fp: 0.003095, loss_freq: 0.024244
[16:25:18.774] iteration 24832: loss: 0.059694, loss_s1: 0.061834, loss_fp: 0.008972, loss_freq: 0.014485
[16:25:19.395] iteration 24833: loss: 0.037536, loss_s1: 0.026227, loss_fp: 0.002311, loss_freq: 0.009429
[16:25:20.015] iteration 24834: loss: 0.040171, loss_s1: 0.025521, loss_fp: 0.003405, loss_freq: 0.016946
[16:25:20.638] iteration 24835: loss: 0.040099, loss_s1: 0.021892, loss_fp: 0.001603, loss_freq: 0.014525
[16:25:21.275] iteration 24836: loss: 0.057311, loss_s1: 0.036511, loss_fp: 0.003800, loss_freq: 0.024262
[16:25:21.892] iteration 24837: loss: 0.042151, loss_s1: 0.021069, loss_fp: 0.003578, loss_freq: 0.017479
[16:25:22.513] iteration 24838: loss: 0.041148, loss_s1: 0.015618, loss_fp: 0.002480, loss_freq: 0.018841
[16:25:23.127] iteration 24839: loss: 0.070727, loss_s1: 0.026966, loss_fp: 0.013438, loss_freq: 0.043004
[16:25:23.752] iteration 24840: loss: 0.048309, loss_s1: 0.046724, loss_fp: 0.003471, loss_freq: 0.012725
[16:25:24.409] iteration 24841: loss: 0.057307, loss_s1: 0.035744, loss_fp: 0.001618, loss_freq: 0.036128
[16:25:25.039] iteration 24842: loss: 0.070655, loss_s1: 0.073131, loss_fp: 0.007035, loss_freq: 0.029513
[16:25:25.659] iteration 24843: loss: 0.082636, loss_s1: 0.089986, loss_fp: 0.001247, loss_freq: 0.032742
[16:25:26.279] iteration 24844: loss: 0.032588, loss_s1: 0.013145, loss_fp: 0.003704, loss_freq: 0.011514
[16:25:26.908] iteration 24845: loss: 0.037573, loss_s1: 0.020356, loss_fp: 0.002887, loss_freq: 0.018589
[16:25:27.525] iteration 24846: loss: 0.067254, loss_s1: 0.046365, loss_fp: 0.010538, loss_freq: 0.031806
[16:25:28.164] iteration 24847: loss: 0.092184, loss_s1: 0.074054, loss_fp: 0.010980, loss_freq: 0.062767
[16:25:28.793] iteration 24848: loss: 0.050666, loss_s1: 0.029180, loss_fp: 0.009179, loss_freq: 0.023795
[16:25:29.416] iteration 24849: loss: 0.045059, loss_s1: 0.034763, loss_fp: 0.007143, loss_freq: 0.019867
[16:25:30.051] iteration 24850: loss: 0.052205, loss_s1: 0.035930, loss_fp: 0.002945, loss_freq: 0.013223
[16:25:30.690] iteration 24851: loss: 0.053342, loss_s1: 0.052966, loss_fp: 0.005536, loss_freq: 0.024010
[16:25:31.323] iteration 24852: loss: 0.051399, loss_s1: 0.024903, loss_fp: 0.000384, loss_freq: 0.017012
[16:25:31.946] iteration 24853: loss: 0.099672, loss_s1: 0.095911, loss_fp: 0.005099, loss_freq: 0.060476
[16:25:32.567] iteration 24854: loss: 0.065958, loss_s1: 0.033368, loss_fp: 0.000600, loss_freq: 0.009825
[16:25:33.195] iteration 24855: loss: 0.049809, loss_s1: 0.024195, loss_fp: 0.004020, loss_freq: 0.025342
[16:25:33.824] iteration 24856: loss: 0.078566, loss_s1: 0.039701, loss_fp: 0.009437, loss_freq: 0.059816
[16:25:34.445] iteration 24857: loss: 0.065060, loss_s1: 0.072656, loss_fp: 0.004123, loss_freq: 0.018507
[16:25:35.065] iteration 24858: loss: 0.051454, loss_s1: 0.038617, loss_fp: 0.000718, loss_freq: 0.027169
[16:25:35.692] iteration 24859: loss: 0.051350, loss_s1: 0.031626, loss_fp: 0.000653, loss_freq: 0.033905
[16:25:36.317] iteration 24860: loss: 0.054162, loss_s1: 0.038350, loss_fp: 0.002991, loss_freq: 0.024795
[16:25:36.940] iteration 24861: loss: 0.101809, loss_s1: 0.025794, loss_fp: 0.000696, loss_freq: 0.030651
[16:25:37.571] iteration 24862: loss: 0.039441, loss_s1: 0.014198, loss_fp: 0.004116, loss_freq: 0.024985
[16:25:38.196] iteration 24863: loss: 0.072776, loss_s1: 0.048565, loss_fp: 0.006272, loss_freq: 0.062484
[16:25:38.818] iteration 24864: loss: 0.066204, loss_s1: 0.073920, loss_fp: 0.004602, loss_freq: 0.022540
[16:25:39.444] iteration 24865: loss: 0.044729, loss_s1: 0.026936, loss_fp: 0.001109, loss_freq: 0.010924
[16:25:40.066] iteration 24866: loss: 0.043735, loss_s1: 0.028425, loss_fp: 0.003145, loss_freq: 0.023513
[16:25:40.695] iteration 24867: loss: 0.062875, loss_s1: 0.053443, loss_fp: 0.004992, loss_freq: 0.032460
[16:25:41.318] iteration 24868: loss: 0.058639, loss_s1: 0.058797, loss_fp: 0.002965, loss_freq: 0.020343
[16:25:41.943] iteration 24869: loss: 0.050681, loss_s1: 0.051850, loss_fp: 0.001675, loss_freq: 0.011397
[16:25:42.566] iteration 24870: loss: 0.048674, loss_s1: 0.022050, loss_fp: 0.004990, loss_freq: 0.017728
[16:25:43.185] iteration 24871: loss: 0.059580, loss_s1: 0.044702, loss_fp: 0.002682, loss_freq: 0.034284
[16:25:43.804] iteration 24872: loss: 0.047599, loss_s1: 0.020076, loss_fp: 0.014414, loss_freq: 0.020470
[16:25:44.420] iteration 24873: loss: 0.075420, loss_s1: 0.065641, loss_fp: 0.011496, loss_freq: 0.022871
[16:25:45.041] iteration 24874: loss: 0.057817, loss_s1: 0.028054, loss_fp: 0.002419, loss_freq: 0.037170
[16:25:45.660] iteration 24875: loss: 0.072991, loss_s1: 0.070918, loss_fp: 0.009654, loss_freq: 0.026623
[16:25:46.280] iteration 24876: loss: 0.065344, loss_s1: 0.039710, loss_fp: 0.016803, loss_freq: 0.022745
[16:25:46.901] iteration 24877: loss: 0.030259, loss_s1: 0.012008, loss_fp: 0.005218, loss_freq: 0.013426
[16:25:47.525] iteration 24878: loss: 0.030397, loss_s1: 0.013233, loss_fp: 0.002465, loss_freq: 0.015112
[16:25:48.150] iteration 24879: loss: 0.061041, loss_s1: 0.042595, loss_fp: 0.002787, loss_freq: 0.024030
[16:25:48.775] iteration 24880: loss: 0.055253, loss_s1: 0.050250, loss_fp: 0.004129, loss_freq: 0.023315
[16:25:49.393] iteration 24881: loss: 0.091373, loss_s1: 0.112992, loss_fp: 0.006521, loss_freq: 0.024406
[16:25:50.016] iteration 24882: loss: 0.030860, loss_s1: 0.017721, loss_fp: 0.000809, loss_freq: 0.011464
[16:25:50.982] iteration 24883: loss: 0.046910, loss_s1: 0.024757, loss_fp: 0.000700, loss_freq: 0.028275
[16:25:51.619] iteration 24884: loss: 0.063193, loss_s1: 0.072276, loss_fp: 0.003866, loss_freq: 0.012149
[16:25:52.255] iteration 24885: loss: 0.030528, loss_s1: 0.014601, loss_fp: 0.001673, loss_freq: 0.012559
[16:25:52.884] iteration 24886: loss: 0.054425, loss_s1: 0.015796, loss_fp: 0.002065, loss_freq: 0.032632
[16:25:53.517] iteration 24887: loss: 0.054748, loss_s1: 0.063509, loss_fp: 0.003260, loss_freq: 0.015296
[16:25:54.145] iteration 24888: loss: 0.033652, loss_s1: 0.023048, loss_fp: 0.002302, loss_freq: 0.008002
[16:25:54.772] iteration 24889: loss: 0.036529, loss_s1: 0.027881, loss_fp: 0.003511, loss_freq: 0.014425
[16:25:55.397] iteration 24890: loss: 0.045236, loss_s1: 0.030044, loss_fp: 0.000874, loss_freq: 0.017185
[16:25:56.023] iteration 24891: loss: 0.069397, loss_s1: 0.075323, loss_fp: 0.003028, loss_freq: 0.025746
[16:25:56.651] iteration 24892: loss: 0.043681, loss_s1: 0.014549, loss_fp: 0.000216, loss_freq: 0.015880
[16:25:57.281] iteration 24893: loss: 0.055001, loss_s1: 0.022576, loss_fp: 0.002226, loss_freq: 0.041207
[16:25:57.902] iteration 24894: loss: 0.064957, loss_s1: 0.058439, loss_fp: 0.008408, loss_freq: 0.021866
[16:25:58.517] iteration 24895: loss: 0.040854, loss_s1: 0.021192, loss_fp: 0.001843, loss_freq: 0.023039
[16:25:59.131] iteration 24896: loss: 0.038161, loss_s1: 0.027666, loss_fp: 0.002242, loss_freq: 0.012651
[16:25:59.751] iteration 24897: loss: 0.090057, loss_s1: 0.064868, loss_fp: 0.010424, loss_freq: 0.032781
[16:26:00.412] iteration 24898: loss: 0.049743, loss_s1: 0.032226, loss_fp: 0.002797, loss_freq: 0.024661
[16:26:01.074] iteration 24899: loss: 0.074867, loss_s1: 0.066578, loss_fp: 0.000822, loss_freq: 0.045257
[16:26:01.737] iteration 24900: loss: 0.054716, loss_s1: 0.041187, loss_fp: 0.003238, loss_freq: 0.026069
[16:26:02.384] iteration 24901: loss: 0.048840, loss_s1: 0.048331, loss_fp: 0.001131, loss_freq: 0.010801
[16:26:03.027] iteration 24902: loss: 0.033665, loss_s1: 0.019274, loss_fp: 0.001640, loss_freq: 0.015601
[16:26:03.673] iteration 24903: loss: 0.057455, loss_s1: 0.030336, loss_fp: 0.002935, loss_freq: 0.037720
[16:26:04.343] iteration 24904: loss: 0.036964, loss_s1: 0.019436, loss_fp: 0.001897, loss_freq: 0.020877
[16:26:04.969] iteration 24905: loss: 0.052451, loss_s1: 0.044023, loss_fp: 0.006345, loss_freq: 0.024594
[16:26:05.600] iteration 24906: loss: 0.034968, loss_s1: 0.008390, loss_fp: 0.001351, loss_freq: 0.010874
[16:26:06.271] iteration 24907: loss: 0.053237, loss_s1: 0.048684, loss_fp: 0.004677, loss_freq: 0.014091
[16:26:06.956] iteration 24908: loss: 0.041467, loss_s1: 0.025934, loss_fp: 0.006038, loss_freq: 0.018788
[16:26:07.664] iteration 24909: loss: 0.057571, loss_s1: 0.033485, loss_fp: 0.003507, loss_freq: 0.038196
[16:26:08.563] iteration 24910: loss: 0.033108, loss_s1: 0.019532, loss_fp: 0.006068, loss_freq: 0.008030
[16:26:09.341] iteration 24911: loss: 0.059067, loss_s1: 0.047084, loss_fp: 0.001748, loss_freq: 0.032021
[16:26:10.071] iteration 24912: loss: 0.038298, loss_s1: 0.023524, loss_fp: 0.002931, loss_freq: 0.009681
[16:26:10.704] iteration 24913: loss: 0.052490, loss_s1: 0.054539, loss_fp: 0.002074, loss_freq: 0.010443
[16:26:11.358] iteration 24914: loss: 0.041191, loss_s1: 0.018071, loss_fp: 0.002299, loss_freq: 0.025145
[16:26:11.976] iteration 24915: loss: 0.049503, loss_s1: 0.045675, loss_fp: 0.004678, loss_freq: 0.020793
[16:26:12.612] iteration 24916: loss: 0.085613, loss_s1: 0.083744, loss_fp: 0.014555, loss_freq: 0.040997
[16:26:13.237] iteration 24917: loss: 0.068817, loss_s1: 0.057261, loss_fp: 0.006905, loss_freq: 0.017287
[16:26:13.851] iteration 24918: loss: 0.051164, loss_s1: 0.036434, loss_fp: 0.009522, loss_freq: 0.021283
[16:26:14.472] iteration 24919: loss: 0.059777, loss_s1: 0.055998, loss_fp: 0.003026, loss_freq: 0.022080
[16:26:15.097] iteration 24920: loss: 0.049739, loss_s1: 0.043938, loss_fp: 0.003148, loss_freq: 0.025705
[16:26:15.717] iteration 24921: loss: 0.096773, loss_s1: 0.091219, loss_fp: 0.002873, loss_freq: 0.022360
[16:26:16.335] iteration 24922: loss: 0.032372, loss_s1: 0.018652, loss_fp: 0.002100, loss_freq: 0.010394
[16:26:16.960] iteration 24923: loss: 0.038389, loss_s1: 0.028798, loss_fp: 0.001762, loss_freq: 0.012466
[16:26:17.582] iteration 24924: loss: 0.041434, loss_s1: 0.046918, loss_fp: 0.001651, loss_freq: 0.007734
[16:26:18.210] iteration 24925: loss: 0.063797, loss_s1: 0.057345, loss_fp: 0.002591, loss_freq: 0.020283
[16:26:18.836] iteration 24926: loss: 0.076894, loss_s1: 0.073749, loss_fp: 0.003517, loss_freq: 0.039289
[16:26:19.461] iteration 24927: loss: 0.048070, loss_s1: 0.029628, loss_fp: 0.003339, loss_freq: 0.011171
[16:26:20.088] iteration 24928: loss: 0.060243, loss_s1: 0.050068, loss_fp: 0.005086, loss_freq: 0.033636
[16:26:20.705] iteration 24929: loss: 0.052973, loss_s1: 0.031271, loss_fp: 0.002712, loss_freq: 0.020116
[16:26:21.323] iteration 24930: loss: 0.043245, loss_s1: 0.017709, loss_fp: 0.003716, loss_freq: 0.009075
[16:26:21.942] iteration 24931: loss: 0.064983, loss_s1: 0.038371, loss_fp: 0.011929, loss_freq: 0.036739
[16:26:22.566] iteration 24932: loss: 0.041032, loss_s1: 0.020843, loss_fp: 0.002853, loss_freq: 0.015382
[16:26:23.191] iteration 24933: loss: 0.067005, loss_s1: 0.038757, loss_fp: 0.006854, loss_freq: 0.055753
[16:26:23.819] iteration 24934: loss: 0.047472, loss_s1: 0.030849, loss_fp: 0.002760, loss_freq: 0.024624
[16:26:24.443] iteration 24935: loss: 0.040648, loss_s1: 0.032204, loss_fp: 0.003095, loss_freq: 0.012164
[16:26:25.066] iteration 24936: loss: 0.088211, loss_s1: 0.057745, loss_fp: 0.009257, loss_freq: 0.082324
[16:26:25.691] iteration 24937: loss: 0.046283, loss_s1: 0.035698, loss_fp: 0.002616, loss_freq: 0.008081
[16:26:26.340] iteration 24938: loss: 0.044189, loss_s1: 0.022402, loss_fp: 0.000628, loss_freq: 0.019364
[16:26:27.002] iteration 24939: loss: 0.084897, loss_s1: 0.062012, loss_fp: 0.010013, loss_freq: 0.062110
[16:26:27.625] iteration 24940: loss: 0.037382, loss_s1: 0.026072, loss_fp: 0.000646, loss_freq: 0.016403
[16:26:28.246] iteration 24941: loss: 0.068917, loss_s1: 0.024486, loss_fp: 0.001396, loss_freq: 0.044793
[16:26:28.870] iteration 24942: loss: 0.055859, loss_s1: 0.054498, loss_fp: 0.001293, loss_freq: 0.016604
[16:26:29.547] iteration 24943: loss: 0.046830, loss_s1: 0.033613, loss_fp: 0.001584, loss_freq: 0.023430
[16:26:30.190] iteration 24944: loss: 0.062182, loss_s1: 0.060790, loss_fp: 0.002713, loss_freq: 0.020250
[16:26:30.816] iteration 24945: loss: 0.087530, loss_s1: 0.068269, loss_fp: 0.008316, loss_freq: 0.066294
[16:26:31.438] iteration 24946: loss: 0.053893, loss_s1: 0.028895, loss_fp: 0.000911, loss_freq: 0.034338
[16:26:32.070] iteration 24947: loss: 0.063806, loss_s1: 0.033338, loss_fp: 0.002794, loss_freq: 0.041022
[16:26:32.696] iteration 24948: loss: 0.050064, loss_s1: 0.038352, loss_fp: 0.005272, loss_freq: 0.014468
[16:26:33.314] iteration 24949: loss: 0.092451, loss_s1: 0.085913, loss_fp: 0.003974, loss_freq: 0.054799
[16:26:33.934] iteration 24950: loss: 0.049322, loss_s1: 0.043004, loss_fp: 0.003349, loss_freq: 0.021770
[16:26:34.555] iteration 24951: loss: 0.045771, loss_s1: 0.034045, loss_fp: 0.001259, loss_freq: 0.018233
[16:26:35.179] iteration 24952: loss: 0.042870, loss_s1: 0.019157, loss_fp: 0.005192, loss_freq: 0.007692
[16:26:35.799] iteration 24953: loss: 0.037557, loss_s1: 0.020384, loss_fp: 0.002679, loss_freq: 0.020092
[16:26:36.430] iteration 24954: loss: 0.058453, loss_s1: 0.055710, loss_fp: 0.002810, loss_freq: 0.022508
[16:26:37.104] iteration 24955: loss: 0.058571, loss_s1: 0.034511, loss_fp: 0.002334, loss_freq: 0.053293
[16:26:37.779] iteration 24956: loss: 0.062851, loss_s1: 0.045337, loss_fp: 0.006835, loss_freq: 0.013493
[16:26:38.415] iteration 24957: loss: 0.077696, loss_s1: 0.081901, loss_fp: 0.002415, loss_freq: 0.041930
[16:26:39.078] iteration 24958: loss: 0.044958, loss_s1: 0.041168, loss_fp: 0.000986, loss_freq: 0.005680
[16:26:39.694] iteration 24959: loss: 0.046549, loss_s1: 0.035007, loss_fp: 0.002535, loss_freq: 0.024208
[16:26:40.310] iteration 24960: loss: 0.044542, loss_s1: 0.032311, loss_fp: 0.001811, loss_freq: 0.010986
[16:26:40.936] iteration 24961: loss: 0.062766, loss_s1: 0.071102, loss_fp: 0.004344, loss_freq: 0.008818
[16:26:41.558] iteration 24962: loss: 0.068820, loss_s1: 0.050844, loss_fp: 0.002504, loss_freq: 0.024828
[16:26:42.177] iteration 24963: loss: 0.055313, loss_s1: 0.034221, loss_fp: 0.006159, loss_freq: 0.020989
[16:26:42.803] iteration 24964: loss: 0.053645, loss_s1: 0.028289, loss_fp: 0.004015, loss_freq: 0.029168
[16:26:43.429] iteration 24965: loss: 0.037158, loss_s1: 0.023539, loss_fp: 0.000804, loss_freq: 0.018020
[16:26:44.055] iteration 24966: loss: 0.038325, loss_s1: 0.033738, loss_fp: 0.002192, loss_freq: 0.015824
[16:26:44.672] iteration 24967: loss: 0.069398, loss_s1: 0.051438, loss_fp: 0.004224, loss_freq: 0.043670
[16:26:45.289] iteration 24968: loss: 0.106843, loss_s1: 0.105051, loss_fp: 0.002958, loss_freq: 0.043500
[16:26:45.903] iteration 24969: loss: 0.040148, loss_s1: 0.018964, loss_fp: 0.001914, loss_freq: 0.019317
[16:26:46.522] iteration 24970: loss: 0.035827, loss_s1: 0.021222, loss_fp: 0.002998, loss_freq: 0.013265
[16:26:47.148] iteration 24971: loss: 0.034635, loss_s1: 0.027414, loss_fp: 0.001396, loss_freq: 0.012727
[16:26:47.793] iteration 24972: loss: 0.046324, loss_s1: 0.041690, loss_fp: 0.004176, loss_freq: 0.019478
[16:26:48.430] iteration 24973: loss: 0.065181, loss_s1: 0.019458, loss_fp: 0.004287, loss_freq: 0.014823
[16:26:49.071] iteration 24974: loss: 0.045486, loss_s1: 0.037164, loss_fp: 0.001107, loss_freq: 0.021316
[16:26:49.704] iteration 24975: loss: 0.041220, loss_s1: 0.028403, loss_fp: 0.006911, loss_freq: 0.015568
[16:26:50.321] iteration 24976: loss: 0.045736, loss_s1: 0.041422, loss_fp: 0.002345, loss_freq: 0.011587
[16:26:50.939] iteration 24977: loss: 0.049359, loss_s1: 0.019074, loss_fp: 0.003590, loss_freq: 0.033516
[16:26:51.564] iteration 24978: loss: 0.037358, loss_s1: 0.019415, loss_fp: 0.001843, loss_freq: 0.014203
[16:26:52.191] iteration 24979: loss: 0.076209, loss_s1: 0.031819, loss_fp: 0.004731, loss_freq: 0.080650
[16:26:52.808] iteration 24980: loss: 0.067522, loss_s1: 0.052714, loss_fp: 0.006489, loss_freq: 0.020131
[16:26:53.426] iteration 24981: loss: 0.044793, loss_s1: 0.029010, loss_fp: 0.006119, loss_freq: 0.020436
[16:26:54.047] iteration 24982: loss: 0.066203, loss_s1: 0.064131, loss_fp: 0.002714, loss_freq: 0.029336
[16:26:54.669] iteration 24983: loss: 0.083285, loss_s1: 0.077250, loss_fp: 0.014597, loss_freq: 0.041558
[16:26:55.289] iteration 24984: loss: 0.065332, loss_s1: 0.053651, loss_fp: 0.003448, loss_freq: 0.032066
[16:26:55.906] iteration 24985: loss: 0.077242, loss_s1: 0.082356, loss_fp: 0.001671, loss_freq: 0.041682
[16:26:56.518] iteration 24986: loss: 0.057136, loss_s1: 0.049613, loss_fp: 0.009142, loss_freq: 0.009247
[16:26:57.131] iteration 24987: loss: 0.056768, loss_s1: 0.018328, loss_fp: 0.002788, loss_freq: 0.026115
[16:26:57.752] iteration 24988: loss: 0.054615, loss_s1: 0.026344, loss_fp: 0.004324, loss_freq: 0.016219
[16:26:58.373] iteration 24989: loss: 0.070145, loss_s1: 0.034863, loss_fp: 0.003631, loss_freq: 0.038396
[16:26:59.011] iteration 24990: loss: 0.057333, loss_s1: 0.032830, loss_fp: 0.006440, loss_freq: 0.042271
[16:26:59.640] iteration 24991: loss: 0.053269, loss_s1: 0.026565, loss_fp: 0.004976, loss_freq: 0.031133
[16:27:00.272] iteration 24992: loss: 0.085576, loss_s1: 0.069459, loss_fp: 0.019044, loss_freq: 0.047275
[16:27:00.886] iteration 24993: loss: 0.070461, loss_s1: 0.054006, loss_fp: 0.003226, loss_freq: 0.039895
[16:27:01.508] iteration 24994: loss: 0.056399, loss_s1: 0.061894, loss_fp: 0.004865, loss_freq: 0.017306
[16:27:02.132] iteration 24995: loss: 0.049722, loss_s1: 0.030100, loss_fp: 0.000881, loss_freq: 0.029185
[16:27:02.756] iteration 24996: loss: 0.075464, loss_s1: 0.067559, loss_fp: 0.002886, loss_freq: 0.040190
[16:27:03.382] iteration 24997: loss: 0.049037, loss_s1: 0.015778, loss_fp: 0.002054, loss_freq: 0.028836
[16:27:03.995] iteration 24998: loss: 0.049864, loss_s1: 0.034366, loss_fp: 0.002450, loss_freq: 0.020606
[16:27:04.613] iteration 24999: loss: 0.055657, loss_s1: 0.031689, loss_fp: 0.008298, loss_freq: 0.020988
[16:27:05.233] iteration 25000: loss: 0.062637, loss_s1: 0.078477, loss_fp: 0.003431, loss_freq: 0.011840
[16:27:08.685] iteration 25000 : mean_dice : 0.797060
[16:27:09.364] iteration 25001: loss: 0.038278, loss_s1: 0.022954, loss_fp: 0.002510, loss_freq: 0.012794
[16:27:09.984] iteration 25002: loss: 0.053055, loss_s1: 0.021547, loss_fp: 0.003446, loss_freq: 0.040171
[16:27:10.659] iteration 25003: loss: 0.064449, loss_s1: 0.038132, loss_fp: 0.002949, loss_freq: 0.038327
[16:27:11.269] iteration 25004: loss: 0.067111, loss_s1: 0.059912, loss_fp: 0.008642, loss_freq: 0.017002
[16:27:11.898] iteration 25005: loss: 0.046441, loss_s1: 0.035270, loss_fp: 0.001479, loss_freq: 0.005970
[16:27:12.520] iteration 25006: loss: 0.028897, loss_s1: 0.017036, loss_fp: 0.001442, loss_freq: 0.004999
[16:27:13.143] iteration 25007: loss: 0.037875, loss_s1: 0.015202, loss_fp: 0.001282, loss_freq: 0.022682
[16:27:13.760] iteration 25008: loss: 0.085999, loss_s1: 0.085667, loss_fp: 0.005285, loss_freq: 0.013956
[16:27:14.372] iteration 25009: loss: 0.041110, loss_s1: 0.021505, loss_fp: 0.003656, loss_freq: 0.021246
[16:27:14.992] iteration 25010: loss: 0.060134, loss_s1: 0.053230, loss_fp: 0.001837, loss_freq: 0.020843
[16:27:15.612] iteration 25011: loss: 0.054113, loss_s1: 0.057292, loss_fp: 0.003539, loss_freq: 0.006621
[16:27:16.237] iteration 25012: loss: 0.060212, loss_s1: 0.032994, loss_fp: 0.015725, loss_freq: 0.018311
[16:27:16.864] iteration 25013: loss: 0.051247, loss_s1: 0.037280, loss_fp: 0.004397, loss_freq: 0.021962
[16:27:17.489] iteration 25014: loss: 0.066790, loss_s1: 0.039689, loss_fp: 0.008827, loss_freq: 0.045025
[16:27:18.109] iteration 25015: loss: 0.052257, loss_s1: 0.015413, loss_fp: 0.021547, loss_freq: 0.029741
[16:27:18.776] iteration 25016: loss: 0.088145, loss_s1: 0.054731, loss_fp: 0.002587, loss_freq: 0.040725
[16:27:19.424] iteration 25017: loss: 0.060250, loss_s1: 0.013581, loss_fp: 0.012302, loss_freq: 0.031206
[16:27:20.060] iteration 25018: loss: 0.048034, loss_s1: 0.043324, loss_fp: 0.003405, loss_freq: 0.012649
[16:27:20.724] iteration 25019: loss: 0.066694, loss_s1: 0.038251, loss_fp: 0.005320, loss_freq: 0.014780
[16:27:21.348] iteration 25020: loss: 0.034807, loss_s1: 0.026136, loss_fp: 0.003323, loss_freq: 0.012202
[16:27:21.964] iteration 25021: loss: 0.049195, loss_s1: 0.043974, loss_fp: 0.002207, loss_freq: 0.019197
[16:27:22.588] iteration 25022: loss: 0.086025, loss_s1: 0.048732, loss_fp: 0.012601, loss_freq: 0.022040
[16:27:23.203] iteration 25023: loss: 0.060576, loss_s1: 0.041572, loss_fp: 0.007189, loss_freq: 0.030507
[16:27:23.828] iteration 25024: loss: 0.058189, loss_s1: 0.043568, loss_fp: 0.014605, loss_freq: 0.015838
[16:27:24.444] iteration 25025: loss: 0.041541, loss_s1: 0.027648, loss_fp: 0.001125, loss_freq: 0.024732
[16:27:25.392] iteration 25026: loss: 0.035907, loss_s1: 0.022511, loss_fp: 0.002667, loss_freq: 0.003634
[16:27:26.033] iteration 25027: loss: 0.053489, loss_s1: 0.036190, loss_fp: 0.013168, loss_freq: 0.018604
[16:27:26.683] iteration 25028: loss: 0.039574, loss_s1: 0.020059, loss_fp: 0.002283, loss_freq: 0.021716
[16:27:27.312] iteration 25029: loss: 0.046287, loss_s1: 0.028844, loss_fp: 0.005976, loss_freq: 0.020592
[16:27:27.943] iteration 25030: loss: 0.079166, loss_s1: 0.087332, loss_fp: 0.007676, loss_freq: 0.028402
[16:27:28.575] iteration 25031: loss: 0.044527, loss_s1: 0.027082, loss_fp: 0.000558, loss_freq: 0.007734
[16:27:29.209] iteration 25032: loss: 0.026653, loss_s1: 0.018981, loss_fp: 0.001558, loss_freq: 0.006924
[16:27:29.853] iteration 25033: loss: 0.067765, loss_s1: 0.037334, loss_fp: 0.004132, loss_freq: 0.020930
[16:27:30.482] iteration 25034: loss: 0.060366, loss_s1: 0.063360, loss_fp: 0.004465, loss_freq: 0.017925
[16:27:31.114] iteration 25035: loss: 0.035844, loss_s1: 0.015367, loss_fp: 0.000449, loss_freq: 0.004164
[16:27:31.738] iteration 25036: loss: 0.066403, loss_s1: 0.045789, loss_fp: 0.004987, loss_freq: 0.036895
[16:27:32.375] iteration 25037: loss: 0.042710, loss_s1: 0.021105, loss_fp: 0.002082, loss_freq: 0.028306
[16:27:33.003] iteration 25038: loss: 0.055421, loss_s1: 0.035584, loss_fp: 0.000502, loss_freq: 0.008091
[16:27:33.635] iteration 25039: loss: 0.048531, loss_s1: 0.046313, loss_fp: 0.007330, loss_freq: 0.012425
[16:27:34.267] iteration 25040: loss: 0.062117, loss_s1: 0.034877, loss_fp: 0.022753, loss_freq: 0.027740
[16:27:34.890] iteration 25041: loss: 0.042896, loss_s1: 0.028068, loss_fp: 0.004055, loss_freq: 0.021542
[16:27:35.506] iteration 25042: loss: 0.054453, loss_s1: 0.027039, loss_fp: 0.001009, loss_freq: 0.042933
[16:27:36.127] iteration 25043: loss: 0.051681, loss_s1: 0.025699, loss_fp: 0.001841, loss_freq: 0.039714
[16:27:36.739] iteration 25044: loss: 0.032196, loss_s1: 0.025255, loss_fp: 0.000812, loss_freq: 0.011920
[16:27:37.362] iteration 25045: loss: 0.032331, loss_s1: 0.022722, loss_fp: 0.002531, loss_freq: 0.011917
[16:27:37.987] iteration 25046: loss: 0.067979, loss_s1: 0.033806, loss_fp: 0.002667, loss_freq: 0.042694
[16:27:38.599] iteration 25047: loss: 0.051978, loss_s1: 0.047660, loss_fp: 0.003280, loss_freq: 0.023499
[16:27:39.220] iteration 25048: loss: 0.046785, loss_s1: 0.028483, loss_fp: 0.001599, loss_freq: 0.020325
[16:27:39.841] iteration 25049: loss: 0.036290, loss_s1: 0.005376, loss_fp: 0.001913, loss_freq: 0.016625
[16:27:40.481] iteration 25050: loss: 0.035435, loss_s1: 0.016667, loss_fp: 0.001075, loss_freq: 0.015877
[16:27:41.117] iteration 25051: loss: 0.051670, loss_s1: 0.030848, loss_fp: 0.006596, loss_freq: 0.021949
[16:27:41.759] iteration 25052: loss: 0.065919, loss_s1: 0.046559, loss_fp: 0.002629, loss_freq: 0.038928
[16:27:42.400] iteration 25053: loss: 0.037403, loss_s1: 0.021797, loss_fp: 0.001645, loss_freq: 0.011386
[16:27:43.038] iteration 25054: loss: 0.034378, loss_s1: 0.014549, loss_fp: 0.002875, loss_freq: 0.007651
[16:27:43.670] iteration 25055: loss: 0.041829, loss_s1: 0.013345, loss_fp: 0.002231, loss_freq: 0.013901
[16:27:44.293] iteration 25056: loss: 0.038529, loss_s1: 0.025022, loss_fp: 0.003958, loss_freq: 0.017926
[16:27:44.918] iteration 25057: loss: 0.046544, loss_s1: 0.007229, loss_fp: 0.006233, loss_freq: 0.017049
[16:27:45.538] iteration 25058: loss: 0.050844, loss_s1: 0.037688, loss_fp: 0.003196, loss_freq: 0.032431
[16:27:46.172] iteration 25059: loss: 0.057712, loss_s1: 0.045674, loss_fp: 0.006630, loss_freq: 0.026009
[16:27:46.834] iteration 25060: loss: 0.059637, loss_s1: 0.054949, loss_fp: 0.006116, loss_freq: 0.016007
[16:27:47.467] iteration 25061: loss: 0.074479, loss_s1: 0.045025, loss_fp: 0.001749, loss_freq: 0.049078
[16:27:48.110] iteration 25062: loss: 0.059767, loss_s1: 0.039415, loss_fp: 0.004049, loss_freq: 0.038680
[16:27:48.754] iteration 25063: loss: 0.038403, loss_s1: 0.028607, loss_fp: 0.001452, loss_freq: 0.018268
[16:27:49.393] iteration 25064: loss: 0.105364, loss_s1: 0.110295, loss_fp: 0.003789, loss_freq: 0.059481
[16:27:50.027] iteration 25065: loss: 0.049483, loss_s1: 0.038951, loss_fp: 0.004879, loss_freq: 0.010436
[16:27:50.664] iteration 25066: loss: 0.063379, loss_s1: 0.051281, loss_fp: 0.004672, loss_freq: 0.021093
[16:27:51.304] iteration 25067: loss: 0.050995, loss_s1: 0.036430, loss_fp: 0.005528, loss_freq: 0.031803
[16:27:51.943] iteration 25068: loss: 0.045197, loss_s1: 0.024848, loss_fp: 0.003788, loss_freq: 0.018260
[16:27:52.577] iteration 25069: loss: 0.070316, loss_s1: 0.073465, loss_fp: 0.006409, loss_freq: 0.025301
[16:27:53.214] iteration 25070: loss: 0.049042, loss_s1: 0.034881, loss_fp: 0.003673, loss_freq: 0.009680
[16:27:53.856] iteration 25071: loss: 0.053615, loss_s1: 0.038788, loss_fp: 0.000711, loss_freq: 0.027081
[16:27:54.484] iteration 25072: loss: 0.048422, loss_s1: 0.031988, loss_fp: 0.009086, loss_freq: 0.017427
[16:27:55.118] iteration 25073: loss: 0.033810, loss_s1: 0.013086, loss_fp: 0.002836, loss_freq: 0.015355
[16:27:55.760] iteration 25074: loss: 0.058666, loss_s1: 0.047624, loss_fp: 0.002396, loss_freq: 0.036596
[16:27:56.395] iteration 25075: loss: 0.031620, loss_s1: 0.015601, loss_fp: 0.004188, loss_freq: 0.009583
[16:27:57.035] iteration 25076: loss: 0.039764, loss_s1: 0.016254, loss_fp: 0.005888, loss_freq: 0.020963
[16:27:57.684] iteration 25077: loss: 0.052731, loss_s1: 0.029587, loss_fp: 0.007857, loss_freq: 0.034238
[16:27:58.323] iteration 25078: loss: 0.038852, loss_s1: 0.016647, loss_fp: 0.001995, loss_freq: 0.015440
[16:27:58.961] iteration 25079: loss: 0.044477, loss_s1: 0.034204, loss_fp: 0.001313, loss_freq: 0.025732
[16:27:59.597] iteration 25080: loss: 0.031666, loss_s1: 0.020705, loss_fp: 0.000773, loss_freq: 0.007554
[16:28:00.251] iteration 25081: loss: 0.050651, loss_s1: 0.035697, loss_fp: 0.001545, loss_freq: 0.008371
[16:28:00.897] iteration 25082: loss: 0.051899, loss_s1: 0.033358, loss_fp: 0.006169, loss_freq: 0.027587
[16:28:01.545] iteration 25083: loss: 0.061437, loss_s1: 0.070774, loss_fp: 0.002487, loss_freq: 0.017898
[16:28:02.172] iteration 25084: loss: 0.068564, loss_s1: 0.030953, loss_fp: 0.001419, loss_freq: 0.070653
[16:28:02.798] iteration 25085: loss: 0.075206, loss_s1: 0.053507, loss_fp: 0.004416, loss_freq: 0.011596
[16:28:03.417] iteration 25086: loss: 0.057749, loss_s1: 0.047021, loss_fp: 0.004154, loss_freq: 0.017756
[16:28:04.042] iteration 25087: loss: 0.064499, loss_s1: 0.066459, loss_fp: 0.001779, loss_freq: 0.024404
[16:28:04.672] iteration 25088: loss: 0.070493, loss_s1: 0.037184, loss_fp: 0.003662, loss_freq: 0.043184
[16:28:05.296] iteration 25089: loss: 0.051937, loss_s1: 0.022710, loss_fp: 0.001437, loss_freq: 0.035935
[16:28:05.921] iteration 25090: loss: 0.055187, loss_s1: 0.026071, loss_fp: 0.002120, loss_freq: 0.014898
[16:28:06.562] iteration 25091: loss: 0.051513, loss_s1: 0.046657, loss_fp: 0.001225, loss_freq: 0.025837
[16:28:07.192] iteration 25092: loss: 0.094074, loss_s1: 0.104793, loss_fp: 0.011995, loss_freq: 0.027131
[16:28:07.821] iteration 25093: loss: 0.041373, loss_s1: 0.026767, loss_fp: 0.007499, loss_freq: 0.014110
[16:28:08.448] iteration 25094: loss: 0.045964, loss_s1: 0.028139, loss_fp: 0.003473, loss_freq: 0.025232
[16:28:09.072] iteration 25095: loss: 0.048317, loss_s1: 0.046345, loss_fp: 0.000633, loss_freq: 0.009520
[16:28:09.689] iteration 25096: loss: 0.058190, loss_s1: 0.051457, loss_fp: 0.004974, loss_freq: 0.025025
[16:28:10.313] iteration 25097: loss: 0.078288, loss_s1: 0.058196, loss_fp: 0.004747, loss_freq: 0.042571
[16:28:10.937] iteration 25098: loss: 0.039680, loss_s1: 0.020383, loss_fp: 0.004666, loss_freq: 0.020113
[16:28:11.566] iteration 25099: loss: 0.105159, loss_s1: 0.080409, loss_fp: 0.010480, loss_freq: 0.033373
[16:28:12.207] iteration 25100: loss: 0.053319, loss_s1: 0.041535, loss_fp: 0.009986, loss_freq: 0.029985
[16:28:12.996] iteration 25101: loss: 0.050503, loss_s1: 0.052250, loss_fp: 0.001968, loss_freq: 0.014966
[16:28:13.754] iteration 25102: loss: 0.035072, loss_s1: 0.030661, loss_fp: 0.002233, loss_freq: 0.007071
[16:28:14.369] iteration 25103: loss: 0.053560, loss_s1: 0.039923, loss_fp: 0.002598, loss_freq: 0.017837
[16:28:14.990] iteration 25104: loss: 0.066744, loss_s1: 0.056284, loss_fp: 0.016650, loss_freq: 0.018866
[16:28:15.612] iteration 25105: loss: 0.093597, loss_s1: 0.054946, loss_fp: 0.018355, loss_freq: 0.050151
[16:28:16.236] iteration 25106: loss: 0.048197, loss_s1: 0.034299, loss_fp: 0.001639, loss_freq: 0.025491
[16:28:16.858] iteration 25107: loss: 0.046266, loss_s1: 0.037117, loss_fp: 0.004840, loss_freq: 0.013387
[16:28:17.482] iteration 25108: loss: 0.036597, loss_s1: 0.023971, loss_fp: 0.001911, loss_freq: 0.014317
[16:28:18.106] iteration 25109: loss: 0.034856, loss_s1: 0.019435, loss_fp: 0.001677, loss_freq: 0.018522
[16:28:18.724] iteration 25110: loss: 0.060667, loss_s1: 0.032417, loss_fp: 0.013425, loss_freq: 0.038081
[16:28:19.348] iteration 25111: loss: 0.054212, loss_s1: 0.018090, loss_fp: 0.011293, loss_freq: 0.040190
[16:28:19.978] iteration 25112: loss: 0.031594, loss_s1: 0.015470, loss_fp: 0.001805, loss_freq: 0.006830
[16:28:20.605] iteration 25113: loss: 0.042733, loss_s1: 0.031466, loss_fp: 0.001001, loss_freq: 0.022249
[16:28:21.224] iteration 25114: loss: 0.044255, loss_s1: 0.026834, loss_fp: 0.002452, loss_freq: 0.014339
[16:28:21.847] iteration 25115: loss: 0.047007, loss_s1: 0.038806, loss_fp: 0.003737, loss_freq: 0.020334
[16:28:22.473] iteration 25116: loss: 0.051604, loss_s1: 0.028806, loss_fp: 0.003458, loss_freq: 0.022235
[16:28:23.099] iteration 25117: loss: 0.056706, loss_s1: 0.042210, loss_fp: 0.011792, loss_freq: 0.027250
[16:28:23.721] iteration 25118: loss: 0.035230, loss_s1: 0.024239, loss_fp: 0.001566, loss_freq: 0.004455
[16:28:24.342] iteration 25119: loss: 0.043217, loss_s1: 0.041058, loss_fp: 0.005035, loss_freq: 0.005793
[16:28:24.965] iteration 25120: loss: 0.044895, loss_s1: 0.022810, loss_fp: 0.002396, loss_freq: 0.018060
[16:28:25.590] iteration 25121: loss: 0.046782, loss_s1: 0.049870, loss_fp: 0.002688, loss_freq: 0.006333
[16:28:26.213] iteration 25122: loss: 0.086775, loss_s1: 0.063718, loss_fp: 0.004385, loss_freq: 0.061314
[16:28:26.833] iteration 25123: loss: 0.050998, loss_s1: 0.033339, loss_fp: 0.005010, loss_freq: 0.023933
[16:28:27.457] iteration 25124: loss: 0.032023, loss_s1: 0.009981, loss_fp: 0.004405, loss_freq: 0.011794
[16:28:28.071] iteration 25125: loss: 0.061565, loss_s1: 0.021989, loss_fp: 0.006150, loss_freq: 0.060537
[16:28:28.690] iteration 25126: loss: 0.065832, loss_s1: 0.041628, loss_fp: 0.002893, loss_freq: 0.046769
[16:28:29.309] iteration 25127: loss: 0.069896, loss_s1: 0.040097, loss_fp: 0.004250, loss_freq: 0.018041
[16:28:29.934] iteration 25128: loss: 0.082522, loss_s1: 0.051730, loss_fp: 0.006819, loss_freq: 0.030742
[16:28:30.551] iteration 25129: loss: 0.034671, loss_s1: 0.023913, loss_fp: 0.000639, loss_freq: 0.011698
[16:28:31.213] iteration 25130: loss: 0.030676, loss_s1: 0.014593, loss_fp: 0.000577, loss_freq: 0.008189
[16:28:31.859] iteration 25131: loss: 0.055742, loss_s1: 0.039014, loss_fp: 0.001140, loss_freq: 0.037230
[16:28:32.506] iteration 25132: loss: 0.066206, loss_s1: 0.043341, loss_fp: 0.004407, loss_freq: 0.041444
[16:28:33.142] iteration 25133: loss: 0.034176, loss_s1: 0.006829, loss_fp: 0.004502, loss_freq: 0.027886
[16:28:33.782] iteration 25134: loss: 0.057713, loss_s1: 0.022604, loss_fp: 0.002276, loss_freq: 0.024008
[16:28:34.419] iteration 25135: loss: 0.030118, loss_s1: 0.016294, loss_fp: 0.005177, loss_freq: 0.012437
[16:28:35.074] iteration 25136: loss: 0.086550, loss_s1: 0.096683, loss_fp: 0.009172, loss_freq: 0.018589
[16:28:35.708] iteration 25137: loss: 0.052478, loss_s1: 0.052894, loss_fp: 0.002920, loss_freq: 0.022306
[16:28:36.351] iteration 25138: loss: 0.048009, loss_s1: 0.016128, loss_fp: 0.002304, loss_freq: 0.013336
[16:28:36.991] iteration 25139: loss: 0.101642, loss_s1: 0.080068, loss_fp: 0.012845, loss_freq: 0.066597
[16:28:37.618] iteration 25140: loss: 0.064668, loss_s1: 0.066087, loss_fp: 0.002297, loss_freq: 0.005162
[16:28:38.244] iteration 25141: loss: 0.033798, loss_s1: 0.022729, loss_fp: 0.004008, loss_freq: 0.006122
[16:28:38.865] iteration 25142: loss: 0.053520, loss_s1: 0.039404, loss_fp: 0.009281, loss_freq: 0.023019
[16:28:39.501] iteration 25143: loss: 0.072491, loss_s1: 0.063827, loss_fp: 0.004844, loss_freq: 0.039555
[16:28:40.116] iteration 25144: loss: 0.030401, loss_s1: 0.023832, loss_fp: 0.001979, loss_freq: 0.007104
[16:28:40.728] iteration 25145: loss: 0.051342, loss_s1: 0.027448, loss_fp: 0.002540, loss_freq: 0.026855
[16:28:41.350] iteration 25146: loss: 0.081408, loss_s1: 0.057129, loss_fp: 0.010688, loss_freq: 0.052650
[16:28:41.981] iteration 25147: loss: 0.070973, loss_s1: 0.045189, loss_fp: 0.003748, loss_freq: 0.055595
[16:28:42.608] iteration 25148: loss: 0.032170, loss_s1: 0.012396, loss_fp: 0.003495, loss_freq: 0.008102
[16:28:43.232] iteration 25149: loss: 0.045811, loss_s1: 0.023502, loss_fp: 0.004186, loss_freq: 0.037857
[16:28:43.855] iteration 25150: loss: 0.065478, loss_s1: 0.047142, loss_fp: 0.007955, loss_freq: 0.042049
[16:28:44.478] iteration 25151: loss: 0.062978, loss_s1: 0.060763, loss_fp: 0.001019, loss_freq: 0.007353
[16:28:45.095] iteration 25152: loss: 0.046317, loss_s1: 0.012395, loss_fp: 0.001237, loss_freq: 0.043291
[16:28:45.710] iteration 25153: loss: 0.031342, loss_s1: 0.019698, loss_fp: 0.001210, loss_freq: 0.011973
[16:28:46.327] iteration 25154: loss: 0.068732, loss_s1: 0.072739, loss_fp: 0.006012, loss_freq: 0.016236
[16:28:46.980] iteration 25155: loss: 0.048241, loss_s1: 0.037037, loss_fp: 0.004292, loss_freq: 0.013676
[16:28:47.622] iteration 25156: loss: 0.055433, loss_s1: 0.042527, loss_fp: 0.003277, loss_freq: 0.014319
[16:28:48.239] iteration 25157: loss: 0.065562, loss_s1: 0.050715, loss_fp: 0.003954, loss_freq: 0.036677
[16:28:48.869] iteration 25158: loss: 0.078314, loss_s1: 0.077975, loss_fp: 0.004014, loss_freq: 0.022254
[16:28:49.493] iteration 25159: loss: 0.090014, loss_s1: 0.048030, loss_fp: 0.007392, loss_freq: 0.044779
[16:28:50.113] iteration 25160: loss: 0.065970, loss_s1: 0.029892, loss_fp: 0.006280, loss_freq: 0.040497
[16:28:50.739] iteration 25161: loss: 0.070708, loss_s1: 0.066937, loss_fp: 0.002347, loss_freq: 0.015560
[16:28:51.359] iteration 25162: loss: 0.061352, loss_s1: 0.052615, loss_fp: 0.004205, loss_freq: 0.029422
[16:28:51.983] iteration 25163: loss: 0.026196, loss_s1: 0.014456, loss_fp: 0.001105, loss_freq: 0.004925
[16:28:52.596] iteration 25164: loss: 0.059256, loss_s1: 0.039729, loss_fp: 0.002720, loss_freq: 0.026586
[16:28:53.213] iteration 25165: loss: 0.048140, loss_s1: 0.032115, loss_fp: 0.004922, loss_freq: 0.014500
[16:28:53.835] iteration 25166: loss: 0.084098, loss_s1: 0.079472, loss_fp: 0.002766, loss_freq: 0.051978
[16:28:54.449] iteration 25167: loss: 0.093063, loss_s1: 0.080630, loss_fp: 0.029346, loss_freq: 0.034115
[16:28:55.071] iteration 25168: loss: 0.034350, loss_s1: 0.027917, loss_fp: 0.001551, loss_freq: 0.008301
[16:28:56.089] iteration 25169: loss: 0.041749, loss_s1: 0.024347, loss_fp: 0.003409, loss_freq: 0.017064
[16:28:56.733] iteration 25170: loss: 0.078057, loss_s1: 0.056291, loss_fp: 0.011471, loss_freq: 0.042030
[16:28:57.368] iteration 25171: loss: 0.042309, loss_s1: 0.031138, loss_fp: 0.001430, loss_freq: 0.021463
[16:28:58.006] iteration 25172: loss: 0.040016, loss_s1: 0.017910, loss_fp: 0.004030, loss_freq: 0.013034
[16:28:58.631] iteration 25173: loss: 0.039614, loss_s1: 0.036460, loss_fp: 0.002138, loss_freq: 0.014063
[16:28:59.249] iteration 25174: loss: 0.038314, loss_s1: 0.023419, loss_fp: 0.003214, loss_freq: 0.004280
[16:28:59.867] iteration 25175: loss: 0.042729, loss_s1: 0.031571, loss_fp: 0.003625, loss_freq: 0.022723
[16:29:00.489] iteration 25176: loss: 0.090747, loss_s1: 0.095378, loss_fp: 0.004482, loss_freq: 0.029109
[16:29:01.134] iteration 25177: loss: 0.047783, loss_s1: 0.018485, loss_fp: 0.006309, loss_freq: 0.026407
[16:29:01.773] iteration 25178: loss: 0.039094, loss_s1: 0.019853, loss_fp: 0.001540, loss_freq: 0.003312
[16:29:02.412] iteration 25179: loss: 0.038161, loss_s1: 0.016314, loss_fp: 0.002395, loss_freq: 0.022548
[16:29:03.045] iteration 25180: loss: 0.046992, loss_s1: 0.034394, loss_fp: 0.003037, loss_freq: 0.011110
[16:29:03.674] iteration 25181: loss: 0.050215, loss_s1: 0.055074, loss_fp: 0.002827, loss_freq: 0.009163
[16:29:04.299] iteration 25182: loss: 0.040743, loss_s1: 0.022938, loss_fp: 0.002835, loss_freq: 0.025181
[16:29:04.963] iteration 25183: loss: 0.057005, loss_s1: 0.036125, loss_fp: 0.003300, loss_freq: 0.032281
[16:29:05.584] iteration 25184: loss: 0.046543, loss_s1: 0.024206, loss_fp: 0.006769, loss_freq: 0.021331
[16:29:06.238] iteration 25185: loss: 0.049514, loss_s1: 0.026503, loss_fp: 0.002291, loss_freq: 0.032409
[16:29:06.873] iteration 25186: loss: 0.052097, loss_s1: 0.035328, loss_fp: 0.006760, loss_freq: 0.027727
[16:29:07.496] iteration 25187: loss: 0.051182, loss_s1: 0.039887, loss_fp: 0.005695, loss_freq: 0.031296
[16:29:08.125] iteration 25188: loss: 0.027268, loss_s1: 0.012815, loss_fp: 0.003859, loss_freq: 0.009109
[16:29:08.747] iteration 25189: loss: 0.063124, loss_s1: 0.023684, loss_fp: 0.004955, loss_freq: 0.045665
[16:29:09.375] iteration 25190: loss: 0.054441, loss_s1: 0.062425, loss_fp: 0.002886, loss_freq: 0.015842
[16:29:09.993] iteration 25191: loss: 0.046766, loss_s1: 0.050704, loss_fp: 0.000762, loss_freq: 0.012894
[16:29:10.619] iteration 25192: loss: 0.077011, loss_s1: 0.016131, loss_fp: 0.002681, loss_freq: 0.009599
[16:29:11.242] iteration 25193: loss: 0.040376, loss_s1: 0.033211, loss_fp: 0.000944, loss_freq: 0.008658
[16:29:11.867] iteration 25194: loss: 0.043913, loss_s1: 0.025302, loss_fp: 0.003178, loss_freq: 0.023057
[16:29:12.494] iteration 25195: loss: 0.070990, loss_s1: 0.029148, loss_fp: 0.004047, loss_freq: 0.038529
[16:29:13.109] iteration 25196: loss: 0.046116, loss_s1: 0.046456, loss_fp: 0.001535, loss_freq: 0.009709
[16:29:13.726] iteration 25197: loss: 0.063506, loss_s1: 0.047299, loss_fp: 0.002514, loss_freq: 0.029120
[16:29:14.352] iteration 25198: loss: 0.038841, loss_s1: 0.022999, loss_fp: 0.002187, loss_freq: 0.008256
[16:29:14.983] iteration 25199: loss: 0.044368, loss_s1: 0.021467, loss_fp: 0.001835, loss_freq: 0.032556
[16:29:15.610] iteration 25200: loss: 0.051473, loss_s1: 0.046132, loss_fp: 0.001348, loss_freq: 0.016212
[16:29:18.905] iteration 25200 : mean_dice : 0.795700
[16:29:19.558] iteration 25201: loss: 0.072626, loss_s1: 0.054470, loss_fp: 0.007047, loss_freq: 0.055231
[16:29:20.210] iteration 25202: loss: 0.076154, loss_s1: 0.065171, loss_fp: 0.009573, loss_freq: 0.038906
[16:29:20.835] iteration 25203: loss: 0.053560, loss_s1: 0.032414, loss_fp: 0.003064, loss_freq: 0.015614
[16:29:21.459] iteration 25204: loss: 0.045032, loss_s1: 0.031884, loss_fp: 0.001454, loss_freq: 0.024331
[16:29:22.081] iteration 25205: loss: 0.041656, loss_s1: 0.021093, loss_fp: 0.000998, loss_freq: 0.024533
[16:29:22.701] iteration 25206: loss: 0.047890, loss_s1: 0.053930, loss_fp: 0.002617, loss_freq: 0.009200
[16:29:23.323] iteration 25207: loss: 0.083187, loss_s1: 0.069242, loss_fp: 0.006242, loss_freq: 0.046405
[16:29:23.955] iteration 25208: loss: 0.026648, loss_s1: 0.014185, loss_fp: 0.003982, loss_freq: 0.006582
[16:29:24.583] iteration 25209: loss: 0.040910, loss_s1: 0.026280, loss_fp: 0.002049, loss_freq: 0.004385
[16:29:25.202] iteration 25210: loss: 0.059240, loss_s1: 0.036008, loss_fp: 0.001109, loss_freq: 0.036956
[16:29:25.823] iteration 25211: loss: 0.048734, loss_s1: 0.030282, loss_fp: 0.003436, loss_freq: 0.016085
[16:29:26.444] iteration 25212: loss: 0.054530, loss_s1: 0.044345, loss_fp: 0.002478, loss_freq: 0.029335
[16:29:27.070] iteration 25213: loss: 0.065747, loss_s1: 0.026772, loss_fp: 0.003524, loss_freq: 0.019955
[16:29:27.694] iteration 25214: loss: 0.034916, loss_s1: 0.012907, loss_fp: 0.008175, loss_freq: 0.012650
[16:29:28.313] iteration 25215: loss: 0.048516, loss_s1: 0.026227, loss_fp: 0.001702, loss_freq: 0.033142
[16:29:28.935] iteration 25216: loss: 0.051308, loss_s1: 0.041786, loss_fp: 0.003993, loss_freq: 0.016776
[16:29:29.560] iteration 25217: loss: 0.050227, loss_s1: 0.046585, loss_fp: 0.000843, loss_freq: 0.022897
[16:29:30.184] iteration 25218: loss: 0.046033, loss_s1: 0.029421, loss_fp: 0.007549, loss_freq: 0.020920
[16:29:30.844] iteration 25219: loss: 0.043097, loss_s1: 0.014150, loss_fp: 0.004660, loss_freq: 0.031194
[16:29:31.469] iteration 25220: loss: 0.080247, loss_s1: 0.037244, loss_fp: 0.002748, loss_freq: 0.029187
[16:29:32.094] iteration 25221: loss: 0.037950, loss_s1: 0.021417, loss_fp: 0.001296, loss_freq: 0.020888
[16:29:32.711] iteration 25222: loss: 0.045810, loss_s1: 0.039993, loss_fp: 0.001777, loss_freq: 0.022695
[16:29:33.334] iteration 25223: loss: 0.036913, loss_s1: 0.035339, loss_fp: 0.002745, loss_freq: 0.006359
[16:29:33.958] iteration 25224: loss: 0.044986, loss_s1: 0.031026, loss_fp: 0.001651, loss_freq: 0.015194
[16:29:34.584] iteration 25225: loss: 0.036876, loss_s1: 0.029705, loss_fp: 0.001350, loss_freq: 0.008642
[16:29:35.206] iteration 25226: loss: 0.036338, loss_s1: 0.019207, loss_fp: 0.000599, loss_freq: 0.013563
[16:29:35.825] iteration 25227: loss: 0.071593, loss_s1: 0.027425, loss_fp: 0.004303, loss_freq: 0.084483
[16:29:36.446] iteration 25228: loss: 0.041019, loss_s1: 0.038600, loss_fp: 0.001208, loss_freq: 0.009611
[16:29:37.106] iteration 25229: loss: 0.038240, loss_s1: 0.027591, loss_fp: 0.000607, loss_freq: 0.017263
[16:29:37.728] iteration 25230: loss: 0.035728, loss_s1: 0.021532, loss_fp: 0.004403, loss_freq: 0.007408
[16:29:38.351] iteration 25231: loss: 0.073806, loss_s1: 0.060651, loss_fp: 0.001606, loss_freq: 0.041385
[16:29:38.974] iteration 25232: loss: 0.050634, loss_s1: 0.035390, loss_fp: 0.003903, loss_freq: 0.024342
[16:29:39.599] iteration 25233: loss: 0.044537, loss_s1: 0.039051, loss_fp: 0.001382, loss_freq: 0.008770
[16:29:40.225] iteration 25234: loss: 0.030214, loss_s1: 0.015591, loss_fp: 0.003556, loss_freq: 0.009155
[16:29:40.844] iteration 25235: loss: 0.059842, loss_s1: 0.053311, loss_fp: 0.012487, loss_freq: 0.011807
[16:29:41.459] iteration 25236: loss: 0.042705, loss_s1: 0.021192, loss_fp: 0.000997, loss_freq: 0.017874
[16:29:42.076] iteration 25237: loss: 0.051936, loss_s1: 0.053530, loss_fp: 0.000679, loss_freq: 0.010781
[16:29:42.699] iteration 25238: loss: 0.071520, loss_s1: 0.023225, loss_fp: 0.012270, loss_freq: 0.006619
[16:29:43.317] iteration 25239: loss: 0.035633, loss_s1: 0.013888, loss_fp: 0.002265, loss_freq: 0.020197
[16:29:43.948] iteration 25240: loss: 0.056675, loss_s1: 0.033116, loss_fp: 0.004101, loss_freq: 0.037544
[16:29:44.571] iteration 25241: loss: 0.072718, loss_s1: 0.047180, loss_fp: 0.001530, loss_freq: 0.069556
[16:29:45.194] iteration 25242: loss: 0.072864, loss_s1: 0.057333, loss_fp: 0.008429, loss_freq: 0.028637
[16:29:45.814] iteration 25243: loss: 0.079403, loss_s1: 0.075697, loss_fp: 0.003914, loss_freq: 0.047111
[16:29:46.439] iteration 25244: loss: 0.054937, loss_s1: 0.058282, loss_fp: 0.002897, loss_freq: 0.016008
[16:29:47.056] iteration 25245: loss: 0.034360, loss_s1: 0.028405, loss_fp: 0.003216, loss_freq: 0.010598
[16:29:47.711] iteration 25246: loss: 0.054164, loss_s1: 0.045031, loss_fp: 0.004917, loss_freq: 0.008666
[16:29:48.333] iteration 25247: loss: 0.068808, loss_s1: 0.048462, loss_fp: 0.024990, loss_freq: 0.023148
[16:29:48.958] iteration 25248: loss: 0.087820, loss_s1: 0.079478, loss_fp: 0.013483, loss_freq: 0.022467
[16:29:49.583] iteration 25249: loss: 0.057046, loss_s1: 0.041538, loss_fp: 0.004878, loss_freq: 0.024632
[16:29:50.202] iteration 25250: loss: 0.055479, loss_s1: 0.047091, loss_fp: 0.002207, loss_freq: 0.032045
[16:29:50.822] iteration 25251: loss: 0.051417, loss_s1: 0.024036, loss_fp: 0.001624, loss_freq: 0.041714
[16:29:51.446] iteration 25252: loss: 0.048247, loss_s1: 0.049311, loss_fp: 0.003985, loss_freq: 0.016418
[16:29:52.071] iteration 25253: loss: 0.066654, loss_s1: 0.064155, loss_fp: 0.012386, loss_freq: 0.022138
[16:29:52.696] iteration 25254: loss: 0.059867, loss_s1: 0.044650, loss_fp: 0.002985, loss_freq: 0.035598
[16:29:53.325] iteration 25255: loss: 0.050154, loss_s1: 0.036590, loss_fp: 0.000354, loss_freq: 0.004162
[16:29:53.947] iteration 25256: loss: 0.030424, loss_s1: 0.010980, loss_fp: 0.001184, loss_freq: 0.008884
[16:29:54.567] iteration 25257: loss: 0.031475, loss_s1: 0.011885, loss_fp: 0.005412, loss_freq: 0.013842
[16:29:55.191] iteration 25258: loss: 0.049148, loss_s1: 0.029976, loss_fp: 0.008071, loss_freq: 0.027948
[16:29:55.812] iteration 25259: loss: 0.082702, loss_s1: 0.053597, loss_fp: 0.006716, loss_freq: 0.035633
[16:29:56.424] iteration 25260: loss: 0.061336, loss_s1: 0.046101, loss_fp: 0.006270, loss_freq: 0.035135
[16:29:57.035] iteration 25261: loss: 0.040202, loss_s1: 0.027440, loss_fp: 0.004016, loss_freq: 0.018121
[16:29:57.643] iteration 25262: loss: 0.042160, loss_s1: 0.027785, loss_fp: 0.001742, loss_freq: 0.012076
[16:29:58.278] iteration 25263: loss: 0.039772, loss_s1: 0.011493, loss_fp: 0.009697, loss_freq: 0.019323
[16:29:58.937] iteration 25264: loss: 0.037039, loss_s1: 0.006834, loss_fp: 0.003307, loss_freq: 0.014139
[16:29:59.587] iteration 25265: loss: 0.093676, loss_s1: 0.097087, loss_fp: 0.004005, loss_freq: 0.032543
[16:30:00.219] iteration 25266: loss: 0.063374, loss_s1: 0.034052, loss_fp: 0.006355, loss_freq: 0.036736
[16:30:00.850] iteration 25267: loss: 0.046800, loss_s1: 0.009470, loss_fp: 0.001850, loss_freq: 0.016370
[16:30:01.469] iteration 25268: loss: 0.073985, loss_s1: 0.041330, loss_fp: 0.002005, loss_freq: 0.059649
[16:30:02.091] iteration 25269: loss: 0.049901, loss_s1: 0.036120, loss_fp: 0.001278, loss_freq: 0.011070
[16:30:02.719] iteration 25270: loss: 0.063324, loss_s1: 0.043326, loss_fp: 0.007012, loss_freq: 0.031526
[16:30:03.335] iteration 25271: loss: 0.090648, loss_s1: 0.066027, loss_fp: 0.022440, loss_freq: 0.060351
[16:30:03.971] iteration 25272: loss: 0.040019, loss_s1: 0.011110, loss_fp: 0.001552, loss_freq: 0.027036
[16:30:04.601] iteration 25273: loss: 0.061882, loss_s1: 0.040556, loss_fp: 0.001700, loss_freq: 0.039639
[16:30:05.287] iteration 25274: loss: 0.034038, loss_s1: 0.007276, loss_fp: 0.002080, loss_freq: 0.026942
[16:30:05.932] iteration 25275: loss: 0.073698, loss_s1: 0.058206, loss_fp: 0.007012, loss_freq: 0.041424
[16:30:06.566] iteration 25276: loss: 0.087493, loss_s1: 0.058970, loss_fp: 0.009084, loss_freq: 0.078214
[16:30:07.187] iteration 25277: loss: 0.066262, loss_s1: 0.069247, loss_fp: 0.002079, loss_freq: 0.020423
[16:30:07.805] iteration 25278: loss: 0.064727, loss_s1: 0.035614, loss_fp: 0.009323, loss_freq: 0.057106
[16:30:08.428] iteration 25279: loss: 0.045847, loss_s1: 0.030885, loss_fp: 0.010245, loss_freq: 0.008127
[16:30:09.053] iteration 25280: loss: 0.049499, loss_s1: 0.047664, loss_fp: 0.003929, loss_freq: 0.020292
[16:30:09.679] iteration 25281: loss: 0.045495, loss_s1: 0.032254, loss_fp: 0.000814, loss_freq: 0.009213
[16:30:10.300] iteration 25282: loss: 0.070322, loss_s1: 0.042751, loss_fp: 0.033357, loss_freq: 0.023250
[16:30:10.916] iteration 25283: loss: 0.050677, loss_s1: 0.020068, loss_fp: 0.001751, loss_freq: 0.008552
[16:30:11.538] iteration 25284: loss: 0.059309, loss_s1: 0.067080, loss_fp: 0.009076, loss_freq: 0.010077
[16:30:12.156] iteration 25285: loss: 0.085665, loss_s1: 0.055947, loss_fp: 0.004804, loss_freq: 0.075646
[16:30:12.776] iteration 25286: loss: 0.066396, loss_s1: 0.055651, loss_fp: 0.002738, loss_freq: 0.038815
[16:30:13.397] iteration 25287: loss: 0.041593, loss_s1: 0.032355, loss_fp: 0.004293, loss_freq: 0.017830
[16:30:14.076] iteration 25288: loss: 0.041670, loss_s1: 0.020005, loss_fp: 0.002022, loss_freq: 0.026860
[16:30:14.740] iteration 25289: loss: 0.040238, loss_s1: 0.022524, loss_fp: 0.002237, loss_freq: 0.025023
[16:30:15.435] iteration 25290: loss: 0.061446, loss_s1: 0.057494, loss_fp: 0.003206, loss_freq: 0.014139
[16:30:16.088] iteration 25291: loss: 0.048426, loss_s1: 0.046174, loss_fp: 0.003333, loss_freq: 0.008941
[16:30:16.731] iteration 25292: loss: 0.044018, loss_s1: 0.027238, loss_fp: 0.001332, loss_freq: 0.020630
[16:30:17.362] iteration 25293: loss: 0.056829, loss_s1: 0.060602, loss_fp: 0.005178, loss_freq: 0.020042
[16:30:17.976] iteration 25294: loss: 0.064407, loss_s1: 0.037076, loss_fp: 0.002504, loss_freq: 0.016732
[16:30:18.654] iteration 25295: loss: 0.053909, loss_s1: 0.018063, loss_fp: 0.002544, loss_freq: 0.029110
[16:30:19.297] iteration 25296: loss: 0.059233, loss_s1: 0.045787, loss_fp: 0.001610, loss_freq: 0.041254
[16:30:19.926] iteration 25297: loss: 0.062190, loss_s1: 0.044435, loss_fp: 0.003440, loss_freq: 0.011681
[16:30:20.549] iteration 25298: loss: 0.037530, loss_s1: 0.018105, loss_fp: 0.003886, loss_freq: 0.018484
[16:30:21.222] iteration 25299: loss: 0.056425, loss_s1: 0.050242, loss_fp: 0.004601, loss_freq: 0.011196
[16:30:21.862] iteration 25300: loss: 0.073841, loss_s1: 0.040364, loss_fp: 0.002706, loss_freq: 0.027743
[16:30:22.499] iteration 25301: loss: 0.049737, loss_s1: 0.031022, loss_fp: 0.003602, loss_freq: 0.023827
[16:30:23.121] iteration 25302: loss: 0.051924, loss_s1: 0.022585, loss_fp: 0.003468, loss_freq: 0.024530
[16:30:23.739] iteration 25303: loss: 0.057813, loss_s1: 0.038913, loss_fp: 0.004173, loss_freq: 0.023202
[16:30:24.367] iteration 25304: loss: 0.070510, loss_s1: 0.073009, loss_fp: 0.001514, loss_freq: 0.026101
[16:30:24.992] iteration 25305: loss: 0.095869, loss_s1: 0.101234, loss_fp: 0.000982, loss_freq: 0.023077
[16:30:25.619] iteration 25306: loss: 0.031149, loss_s1: 0.014314, loss_fp: 0.002983, loss_freq: 0.005476
[16:30:26.276] iteration 25307: loss: 0.035970, loss_s1: 0.033743, loss_fp: 0.002588, loss_freq: 0.005461
[16:30:26.891] iteration 25308: loss: 0.069531, loss_s1: 0.034222, loss_fp: 0.012708, loss_freq: 0.026222
[16:30:27.504] iteration 25309: loss: 0.047034, loss_s1: 0.029269, loss_fp: 0.005182, loss_freq: 0.022795
[16:30:28.118] iteration 25310: loss: 0.105521, loss_s1: 0.101230, loss_fp: 0.003191, loss_freq: 0.065173
[16:30:28.733] iteration 25311: loss: 0.059441, loss_s1: 0.033641, loss_fp: 0.003434, loss_freq: 0.038522
[16:30:29.675] iteration 25312: loss: 0.037902, loss_s1: 0.026043, loss_fp: 0.002551, loss_freq: 0.010973
[16:30:30.300] iteration 25313: loss: 0.056117, loss_s1: 0.038744, loss_fp: 0.004620, loss_freq: 0.023598
[16:30:30.919] iteration 25314: loss: 0.041844, loss_s1: 0.029359, loss_fp: 0.001384, loss_freq: 0.026080
[16:30:31.564] iteration 25315: loss: 0.053180, loss_s1: 0.036882, loss_fp: 0.001535, loss_freq: 0.023979
[16:30:32.171] iteration 25316: loss: 0.061089, loss_s1: 0.045471, loss_fp: 0.001618, loss_freq: 0.043205
[16:30:32.789] iteration 25317: loss: 0.036514, loss_s1: 0.014489, loss_fp: 0.005881, loss_freq: 0.009063
[16:30:33.407] iteration 25318: loss: 0.048424, loss_s1: 0.037122, loss_fp: 0.019073, loss_freq: 0.014263
[16:30:34.060] iteration 25319: loss: 0.054145, loss_s1: 0.024332, loss_fp: 0.001910, loss_freq: 0.029278
[16:30:34.684] iteration 25320: loss: 0.042014, loss_s1: 0.022669, loss_fp: 0.001554, loss_freq: 0.015421
[16:30:35.309] iteration 25321: loss: 0.038097, loss_s1: 0.009060, loss_fp: 0.000325, loss_freq: 0.007165
[16:30:35.933] iteration 25322: loss: 0.048274, loss_s1: 0.026064, loss_fp: 0.009705, loss_freq: 0.023728
[16:30:36.568] iteration 25323: loss: 0.053791, loss_s1: 0.025236, loss_fp: 0.002538, loss_freq: 0.019360
[16:30:37.206] iteration 25324: loss: 0.057608, loss_s1: 0.046089, loss_fp: 0.006030, loss_freq: 0.005088
[16:30:37.837] iteration 25325: loss: 0.037705, loss_s1: 0.013941, loss_fp: 0.012695, loss_freq: 0.016856
[16:30:38.462] iteration 25326: loss: 0.048572, loss_s1: 0.037397, loss_fp: 0.001538, loss_freq: 0.020758
[16:30:39.095] iteration 25327: loss: 0.038117, loss_s1: 0.011428, loss_fp: 0.004395, loss_freq: 0.017182
[16:30:39.725] iteration 25328: loss: 0.092891, loss_s1: 0.087278, loss_fp: 0.001791, loss_freq: 0.046903
[16:30:40.367] iteration 25329: loss: 0.042990, loss_s1: 0.013560, loss_fp: 0.004468, loss_freq: 0.034485
[16:30:41.004] iteration 25330: loss: 0.037290, loss_s1: 0.026631, loss_fp: 0.003037, loss_freq: 0.016416
[16:30:41.644] iteration 25331: loss: 0.033372, loss_s1: 0.025221, loss_fp: 0.002958, loss_freq: 0.005436
[16:30:42.286] iteration 25332: loss: 0.063155, loss_s1: 0.022906, loss_fp: 0.005578, loss_freq: 0.057947
[16:30:42.922] iteration 25333: loss: 0.051843, loss_s1: 0.062090, loss_fp: 0.002982, loss_freq: 0.011122
[16:30:43.559] iteration 25334: loss: 0.050251, loss_s1: 0.026997, loss_fp: 0.006536, loss_freq: 0.032907
[16:30:44.188] iteration 25335: loss: 0.050672, loss_s1: 0.035088, loss_fp: 0.000998, loss_freq: 0.028600
[16:30:44.824] iteration 25336: loss: 0.025739, loss_s1: 0.006193, loss_fp: 0.000308, loss_freq: 0.006713
[16:30:45.460] iteration 25337: loss: 0.062860, loss_s1: 0.070913, loss_fp: 0.002159, loss_freq: 0.015114
[16:30:46.081] iteration 25338: loss: 0.042202, loss_s1: 0.020802, loss_fp: 0.002475, loss_freq: 0.024673
[16:30:46.748] iteration 25339: loss: 0.050834, loss_s1: 0.042771, loss_fp: 0.003798, loss_freq: 0.010970
[16:30:47.373] iteration 25340: loss: 0.057034, loss_s1: 0.050959, loss_fp: 0.000884, loss_freq: 0.020854
[16:30:47.995] iteration 25341: loss: 0.041599, loss_s1: 0.017544, loss_fp: 0.002740, loss_freq: 0.014151
[16:30:48.618] iteration 25342: loss: 0.053271, loss_s1: 0.046452, loss_fp: 0.006996, loss_freq: 0.011125
[16:30:49.254] iteration 25343: loss: 0.063763, loss_s1: 0.034211, loss_fp: 0.006901, loss_freq: 0.024783
[16:30:49.901] iteration 25344: loss: 0.117280, loss_s1: 0.140730, loss_fp: 0.003959, loss_freq: 0.054653
[16:30:50.539] iteration 25345: loss: 0.077514, loss_s1: 0.083235, loss_fp: 0.005392, loss_freq: 0.034773
[16:30:51.179] iteration 25346: loss: 0.063791, loss_s1: 0.061848, loss_fp: 0.008054, loss_freq: 0.021750
[16:30:51.815] iteration 25347: loss: 0.069758, loss_s1: 0.035118, loss_fp: 0.000985, loss_freq: 0.032922
[16:30:52.461] iteration 25348: loss: 0.051665, loss_s1: 0.042075, loss_fp: 0.002760, loss_freq: 0.016097
[16:30:53.088] iteration 25349: loss: 0.057110, loss_s1: 0.040673, loss_fp: 0.002682, loss_freq: 0.038136
[16:30:53.727] iteration 25350: loss: 0.071159, loss_s1: 0.040707, loss_fp: 0.002923, loss_freq: 0.036410
[16:30:54.361] iteration 25351: loss: 0.037176, loss_s1: 0.027521, loss_fp: 0.002107, loss_freq: 0.016486
[16:30:54.997] iteration 25352: loss: 0.065052, loss_s1: 0.056743, loss_fp: 0.005816, loss_freq: 0.033165
[16:30:55.650] iteration 25353: loss: 0.053619, loss_s1: 0.055656, loss_fp: 0.010350, loss_freq: 0.014063
[16:30:56.271] iteration 25354: loss: 0.040713, loss_s1: 0.025553, loss_fp: 0.001884, loss_freq: 0.016917
[16:30:56.891] iteration 25355: loss: 0.061566, loss_s1: 0.041324, loss_fp: 0.002888, loss_freq: 0.020084
[16:30:57.515] iteration 25356: loss: 0.039029, loss_s1: 0.009726, loss_fp: 0.002694, loss_freq: 0.004971
[16:30:58.138] iteration 25357: loss: 0.036422, loss_s1: 0.014281, loss_fp: 0.003822, loss_freq: 0.013624
[16:30:58.768] iteration 25358: loss: 0.040135, loss_s1: 0.020212, loss_fp: 0.005755, loss_freq: 0.019805
[16:30:59.395] iteration 25359: loss: 0.031467, loss_s1: 0.018191, loss_fp: 0.003343, loss_freq: 0.008232
[16:31:00.019] iteration 25360: loss: 0.069607, loss_s1: 0.075850, loss_fp: 0.000975, loss_freq: 0.023582
[16:31:00.643] iteration 25361: loss: 0.056748, loss_s1: 0.054477, loss_fp: 0.004126, loss_freq: 0.011127
[16:31:01.275] iteration 25362: loss: 0.050078, loss_s1: 0.046500, loss_fp: 0.000995, loss_freq: 0.015526
[16:31:01.902] iteration 25363: loss: 0.065235, loss_s1: 0.051048, loss_fp: 0.007644, loss_freq: 0.028406
[16:31:02.525] iteration 25364: loss: 0.052204, loss_s1: 0.031111, loss_fp: 0.001823, loss_freq: 0.013343
[16:31:03.156] iteration 25365: loss: 0.083530, loss_s1: 0.061260, loss_fp: 0.002548, loss_freq: 0.076340
[16:31:03.791] iteration 25366: loss: 0.030479, loss_s1: 0.027093, loss_fp: 0.001911, loss_freq: 0.004549
[16:31:04.429] iteration 25367: loss: 0.054793, loss_s1: 0.031654, loss_fp: 0.001334, loss_freq: 0.032177
[16:31:05.075] iteration 25368: loss: 0.065171, loss_s1: 0.078860, loss_fp: 0.001253, loss_freq: 0.021303
[16:31:05.700] iteration 25369: loss: 0.036687, loss_s1: 0.018951, loss_fp: 0.005568, loss_freq: 0.014395
[16:31:06.328] iteration 25370: loss: 0.035714, loss_s1: 0.006203, loss_fp: 0.000558, loss_freq: 0.031650
[16:31:06.955] iteration 25371: loss: 0.045004, loss_s1: 0.032151, loss_fp: 0.001478, loss_freq: 0.017032
[16:31:07.576] iteration 25372: loss: 0.054802, loss_s1: 0.029522, loss_fp: 0.004393, loss_freq: 0.021609
[16:31:08.201] iteration 25373: loss: 0.047568, loss_s1: 0.045526, loss_fp: 0.000842, loss_freq: 0.011375
[16:31:08.827] iteration 25374: loss: 0.094561, loss_s1: 0.066383, loss_fp: 0.005747, loss_freq: 0.065408
[16:31:09.449] iteration 25375: loss: 0.058139, loss_s1: 0.049542, loss_fp: 0.009781, loss_freq: 0.013019
[16:31:10.075] iteration 25376: loss: 0.086902, loss_s1: 0.050073, loss_fp: 0.013856, loss_freq: 0.030219
[16:31:10.698] iteration 25377: loss: 0.034011, loss_s1: 0.016775, loss_fp: 0.000750, loss_freq: 0.014487
[16:31:11.322] iteration 25378: loss: 0.116110, loss_s1: 0.051286, loss_fp: 0.007994, loss_freq: 0.129566
[16:31:11.953] iteration 25379: loss: 0.060973, loss_s1: 0.058650, loss_fp: 0.001564, loss_freq: 0.016395
[16:31:12.574] iteration 25380: loss: 0.036405, loss_s1: 0.026292, loss_fp: 0.001434, loss_freq: 0.008197
[16:31:13.197] iteration 25381: loss: 0.043784, loss_s1: 0.032779, loss_fp: 0.003516, loss_freq: 0.008912
[16:31:13.820] iteration 25382: loss: 0.048784, loss_s1: 0.041207, loss_fp: 0.001007, loss_freq: 0.017199
[16:31:14.458] iteration 25383: loss: 0.036424, loss_s1: 0.011547, loss_fp: 0.009150, loss_freq: 0.012186
[16:31:15.077] iteration 25384: loss: 0.054831, loss_s1: 0.061946, loss_fp: 0.002619, loss_freq: 0.017051
[16:31:15.723] iteration 25385: loss: 0.063512, loss_s1: 0.063750, loss_fp: 0.004392, loss_freq: 0.015584
[16:31:16.343] iteration 25386: loss: 0.086398, loss_s1: 0.096632, loss_fp: 0.002556, loss_freq: 0.045975
[16:31:17.008] iteration 25387: loss: 0.052863, loss_s1: 0.055978, loss_fp: 0.002072, loss_freq: 0.011285
[16:31:17.629] iteration 25388: loss: 0.041541, loss_s1: 0.050596, loss_fp: 0.001661, loss_freq: 0.004364
[16:31:18.248] iteration 25389: loss: 0.048203, loss_s1: 0.029563, loss_fp: 0.002772, loss_freq: 0.011837
[16:31:18.872] iteration 25390: loss: 0.066545, loss_s1: 0.039522, loss_fp: 0.005354, loss_freq: 0.051877
[16:31:19.497] iteration 25391: loss: 0.091961, loss_s1: 0.059138, loss_fp: 0.003430, loss_freq: 0.034424
[16:31:20.138] iteration 25392: loss: 0.051136, loss_s1: 0.047266, loss_fp: 0.001374, loss_freq: 0.011198
[16:31:20.761] iteration 25393: loss: 0.059249, loss_s1: 0.055228, loss_fp: 0.004868, loss_freq: 0.014902
[16:31:21.386] iteration 25394: loss: 0.037133, loss_s1: 0.028299, loss_fp: 0.001654, loss_freq: 0.008477
[16:31:22.010] iteration 25395: loss: 0.051825, loss_s1: 0.033240, loss_fp: 0.004518, loss_freq: 0.035993
[16:31:22.658] iteration 25396: loss: 0.076128, loss_s1: 0.074300, loss_fp: 0.017523, loss_freq: 0.023005
[16:31:23.299] iteration 25397: loss: 0.069599, loss_s1: 0.054803, loss_fp: 0.006667, loss_freq: 0.044383
[16:31:23.938] iteration 25398: loss: 0.045189, loss_s1: 0.049246, loss_fp: 0.001094, loss_freq: 0.003730
[16:31:24.574] iteration 25399: loss: 0.031415, loss_s1: 0.007024, loss_fp: 0.000374, loss_freq: 0.015119
[16:31:25.207] iteration 25400: loss: 0.060348, loss_s1: 0.050477, loss_fp: 0.006651, loss_freq: 0.017973
[16:31:28.729] iteration 25400 : mean_dice : 0.799784
[16:31:29.403] iteration 25401: loss: 0.054717, loss_s1: 0.056587, loss_fp: 0.006357, loss_freq: 0.013391
[16:31:30.035] iteration 25402: loss: 0.069677, loss_s1: 0.071056, loss_fp: 0.001992, loss_freq: 0.015970
[16:31:30.662] iteration 25403: loss: 0.055624, loss_s1: 0.046149, loss_fp: 0.009506, loss_freq: 0.017907
[16:31:31.301] iteration 25404: loss: 0.044909, loss_s1: 0.043252, loss_fp: 0.002844, loss_freq: 0.008679
[16:31:31.921] iteration 25405: loss: 0.048661, loss_s1: 0.046147, loss_fp: 0.002481, loss_freq: 0.003352
[16:31:32.551] iteration 25406: loss: 0.037818, loss_s1: 0.030120, loss_fp: 0.001352, loss_freq: 0.008917
[16:31:33.214] iteration 25407: loss: 0.045174, loss_s1: 0.022993, loss_fp: 0.002167, loss_freq: 0.015257
[16:31:33.836] iteration 25408: loss: 0.053339, loss_s1: 0.018649, loss_fp: 0.004609, loss_freq: 0.043760
[16:31:34.461] iteration 25409: loss: 0.037804, loss_s1: 0.017378, loss_fp: 0.001701, loss_freq: 0.011788
[16:31:35.100] iteration 25410: loss: 0.042928, loss_s1: 0.017201, loss_fp: 0.003796, loss_freq: 0.016655
[16:31:35.726] iteration 25411: loss: 0.052755, loss_s1: 0.030158, loss_fp: 0.002765, loss_freq: 0.018390
[16:31:36.355] iteration 25412: loss: 0.041109, loss_s1: 0.017053, loss_fp: 0.001460, loss_freq: 0.015224
[16:31:36.979] iteration 25413: loss: 0.042251, loss_s1: 0.021415, loss_fp: 0.002991, loss_freq: 0.017758
[16:31:37.606] iteration 25414: loss: 0.066354, loss_s1: 0.069345, loss_fp: 0.005893, loss_freq: 0.022658
[16:31:38.229] iteration 25415: loss: 0.034550, loss_s1: 0.021749, loss_fp: 0.001300, loss_freq: 0.008910
[16:31:38.851] iteration 25416: loss: 0.033755, loss_s1: 0.020039, loss_fp: 0.001564, loss_freq: 0.007256
[16:31:39.476] iteration 25417: loss: 0.034681, loss_s1: 0.009385, loss_fp: 0.001106, loss_freq: 0.021258
[16:31:40.097] iteration 25418: loss: 0.054447, loss_s1: 0.037970, loss_fp: 0.001738, loss_freq: 0.025815
[16:31:40.714] iteration 25419: loss: 0.078707, loss_s1: 0.023372, loss_fp: 0.009304, loss_freq: 0.092429
[16:31:41.333] iteration 25420: loss: 0.053493, loss_s1: 0.037623, loss_fp: 0.003408, loss_freq: 0.031344
[16:31:41.962] iteration 25421: loss: 0.041718, loss_s1: 0.022984, loss_fp: 0.008095, loss_freq: 0.028368
[16:31:42.584] iteration 25422: loss: 0.041002, loss_s1: 0.022116, loss_fp: 0.012875, loss_freq: 0.016092
[16:31:43.208] iteration 25423: loss: 0.038117, loss_s1: 0.028550, loss_fp: 0.002254, loss_freq: 0.017560
[16:31:43.848] iteration 25424: loss: 0.042053, loss_s1: 0.021022, loss_fp: 0.000900, loss_freq: 0.012732
[16:31:44.478] iteration 25425: loss: 0.096279, loss_s1: 0.120055, loss_fp: 0.004979, loss_freq: 0.025693
[16:31:45.101] iteration 25426: loss: 0.073409, loss_s1: 0.037270, loss_fp: 0.017638, loss_freq: 0.006527
[16:31:45.729] iteration 25427: loss: 0.037460, loss_s1: 0.012522, loss_fp: 0.001647, loss_freq: 0.007880
[16:31:46.356] iteration 25428: loss: 0.036350, loss_s1: 0.017936, loss_fp: 0.005081, loss_freq: 0.007036
[16:31:46.978] iteration 25429: loss: 0.059719, loss_s1: 0.060953, loss_fp: 0.001063, loss_freq: 0.020067
[16:31:47.611] iteration 25430: loss: 0.044540, loss_s1: 0.031384, loss_fp: 0.001443, loss_freq: 0.010887
[16:31:48.224] iteration 25431: loss: 0.042448, loss_s1: 0.020289, loss_fp: 0.005539, loss_freq: 0.023142
[16:31:48.848] iteration 25432: loss: 0.047219, loss_s1: 0.024360, loss_fp: 0.005016, loss_freq: 0.028252
[16:31:49.472] iteration 25433: loss: 0.059818, loss_s1: 0.042825, loss_fp: 0.003149, loss_freq: 0.016325
[16:31:50.098] iteration 25434: loss: 0.035835, loss_s1: 0.029608, loss_fp: 0.001189, loss_freq: 0.005869
[16:31:50.724] iteration 25435: loss: 0.059474, loss_s1: 0.056044, loss_fp: 0.003190, loss_freq: 0.032405
[16:31:51.336] iteration 25436: loss: 0.080111, loss_s1: 0.089039, loss_fp: 0.009955, loss_freq: 0.033272
[16:31:51.958] iteration 25437: loss: 0.072001, loss_s1: 0.070941, loss_fp: 0.001252, loss_freq: 0.015720
[16:31:52.601] iteration 25438: loss: 0.036653, loss_s1: 0.023494, loss_fp: 0.007160, loss_freq: 0.008134
[16:31:53.252] iteration 25439: loss: 0.060894, loss_s1: 0.050356, loss_fp: 0.003289, loss_freq: 0.025616
[16:31:53.874] iteration 25440: loss: 0.064741, loss_s1: 0.054986, loss_fp: 0.003335, loss_freq: 0.028660
[16:31:54.500] iteration 25441: loss: 0.047277, loss_s1: 0.044690, loss_fp: 0.002255, loss_freq: 0.007689
[16:31:55.116] iteration 25442: loss: 0.070603, loss_s1: 0.053082, loss_fp: 0.002083, loss_freq: 0.040959
[16:31:55.730] iteration 25443: loss: 0.095234, loss_s1: 0.054375, loss_fp: 0.008243, loss_freq: 0.053544
[16:31:56.365] iteration 25444: loss: 0.041267, loss_s1: 0.032621, loss_fp: 0.000684, loss_freq: 0.014490
[16:31:57.008] iteration 25445: loss: 0.066162, loss_s1: 0.049699, loss_fp: 0.003319, loss_freq: 0.039801
[16:31:57.670] iteration 25446: loss: 0.057267, loss_s1: 0.044987, loss_fp: 0.006764, loss_freq: 0.016901
[16:31:58.322] iteration 25447: loss: 0.051872, loss_s1: 0.036584, loss_fp: 0.004787, loss_freq: 0.026458
[16:31:58.992] iteration 25448: loss: 0.074044, loss_s1: 0.054435, loss_fp: 0.006404, loss_freq: 0.040409
[16:31:59.652] iteration 25449: loss: 0.027913, loss_s1: 0.020853, loss_fp: 0.000777, loss_freq: 0.003335
[16:32:00.319] iteration 25450: loss: 0.044608, loss_s1: 0.022083, loss_fp: 0.003837, loss_freq: 0.024913
[16:32:01.265] iteration 25451: loss: 0.051365, loss_s1: 0.035488, loss_fp: 0.004136, loss_freq: 0.013687
[16:32:02.216] iteration 25452: loss: 0.060713, loss_s1: 0.056114, loss_fp: 0.010238, loss_freq: 0.019479
[16:32:03.117] iteration 25453: loss: 0.053269, loss_s1: 0.035719, loss_fp: 0.008392, loss_freq: 0.013943
[16:32:04.054] iteration 25454: loss: 0.043642, loss_s1: 0.019094, loss_fp: 0.005325, loss_freq: 0.020121
[16:32:05.440] iteration 25455: loss: 0.029290, loss_s1: 0.017528, loss_fp: 0.000718, loss_freq: 0.008213
[16:32:06.377] iteration 25456: loss: 0.061514, loss_s1: 0.049875, loss_fp: 0.002567, loss_freq: 0.018170
[16:32:07.320] iteration 25457: loss: 0.027846, loss_s1: 0.018647, loss_fp: 0.000684, loss_freq: 0.008004
[16:32:08.139] iteration 25458: loss: 0.047347, loss_s1: 0.041414, loss_fp: 0.002206, loss_freq: 0.010325
[16:32:08.767] iteration 25459: loss: 0.046051, loss_s1: 0.045206, loss_fp: 0.002882, loss_freq: 0.018990
[16:32:09.469] iteration 25460: loss: 0.036413, loss_s1: 0.018864, loss_fp: 0.001788, loss_freq: 0.011459
[16:32:10.262] iteration 25461: loss: 0.034667, loss_s1: 0.021686, loss_fp: 0.006657, loss_freq: 0.014803
[16:32:10.889] iteration 25462: loss: 0.053931, loss_s1: 0.050141, loss_fp: 0.003126, loss_freq: 0.014473
[16:32:11.511] iteration 25463: loss: 0.045618, loss_s1: 0.029167, loss_fp: 0.004969, loss_freq: 0.015944
[16:32:12.140] iteration 25464: loss: 0.046867, loss_s1: 0.036286, loss_fp: 0.001219, loss_freq: 0.003895
[16:32:12.771] iteration 25465: loss: 0.059777, loss_s1: 0.048346, loss_fp: 0.001492, loss_freq: 0.030932
[16:32:13.398] iteration 25466: loss: 0.042118, loss_s1: 0.037980, loss_fp: 0.003298, loss_freq: 0.008628
[16:32:14.024] iteration 25467: loss: 0.052311, loss_s1: 0.043187, loss_fp: 0.002691, loss_freq: 0.026583
[16:32:14.653] iteration 25468: loss: 0.028441, loss_s1: 0.016219, loss_fp: 0.000568, loss_freq: 0.011906
[16:32:15.282] iteration 25469: loss: 0.072824, loss_s1: 0.061496, loss_fp: 0.003067, loss_freq: 0.038411
[16:32:15.925] iteration 25470: loss: 0.035390, loss_s1: 0.027416, loss_fp: 0.001448, loss_freq: 0.008903
[16:32:16.547] iteration 25471: loss: 0.058649, loss_s1: 0.050809, loss_fp: 0.001781, loss_freq: 0.020257
[16:32:17.170] iteration 25472: loss: 0.045771, loss_s1: 0.027816, loss_fp: 0.010766, loss_freq: 0.018001
[16:32:17.788] iteration 25473: loss: 0.048394, loss_s1: 0.030292, loss_fp: 0.001778, loss_freq: 0.034792
[16:32:18.414] iteration 25474: loss: 0.026764, loss_s1: 0.012972, loss_fp: 0.001089, loss_freq: 0.012984
[16:32:19.048] iteration 25475: loss: 0.074771, loss_s1: 0.061632, loss_fp: 0.003769, loss_freq: 0.046698
[16:32:19.922] iteration 25476: loss: 0.038615, loss_s1: 0.021211, loss_fp: 0.002572, loss_freq: 0.020799
[16:32:20.711] iteration 25477: loss: 0.062074, loss_s1: 0.044159, loss_fp: 0.002235, loss_freq: 0.045217
[16:32:21.409] iteration 25478: loss: 0.040111, loss_s1: 0.033604, loss_fp: 0.000692, loss_freq: 0.009312
[16:32:22.075] iteration 25479: loss: 0.034106, loss_s1: 0.015096, loss_fp: 0.000794, loss_freq: 0.014963
[16:32:22.729] iteration 25480: loss: 0.098593, loss_s1: 0.124714, loss_fp: 0.008963, loss_freq: 0.020171
[16:32:23.343] iteration 25481: loss: 0.083884, loss_s1: 0.057031, loss_fp: 0.003778, loss_freq: 0.048340
[16:32:23.970] iteration 25482: loss: 0.039043, loss_s1: 0.019655, loss_fp: 0.002966, loss_freq: 0.012305
[16:32:24.595] iteration 25483: loss: 0.072200, loss_s1: 0.027438, loss_fp: 0.002753, loss_freq: 0.070075
[16:32:25.216] iteration 25484: loss: 0.033156, loss_s1: 0.016507, loss_fp: 0.000970, loss_freq: 0.004528
[16:32:25.835] iteration 25485: loss: 0.042206, loss_s1: 0.023211, loss_fp: 0.002603, loss_freq: 0.017814
[16:32:26.461] iteration 25486: loss: 0.049818, loss_s1: 0.035961, loss_fp: 0.004388, loss_freq: 0.022413
[16:32:27.088] iteration 25487: loss: 0.072704, loss_s1: 0.058833, loss_fp: 0.002361, loss_freq: 0.054775
[16:32:27.704] iteration 25488: loss: 0.073893, loss_s1: 0.055858, loss_fp: 0.017143, loss_freq: 0.044427
[16:32:28.333] iteration 25489: loss: 0.070981, loss_s1: 0.033795, loss_fp: 0.007866, loss_freq: 0.020556
[16:32:28.960] iteration 25490: loss: 0.048664, loss_s1: 0.038496, loss_fp: 0.002425, loss_freq: 0.017286
[16:32:29.581] iteration 25491: loss: 0.051914, loss_s1: 0.022407, loss_fp: 0.001607, loss_freq: 0.035064
[16:32:30.192] iteration 25492: loss: 0.033901, loss_s1: 0.023893, loss_fp: 0.001506, loss_freq: 0.009033
[16:32:30.816] iteration 25493: loss: 0.076304, loss_s1: 0.051134, loss_fp: 0.001545, loss_freq: 0.036206
[16:32:31.435] iteration 25494: loss: 0.049732, loss_s1: 0.057854, loss_fp: 0.001279, loss_freq: 0.010368
[16:32:32.058] iteration 25495: loss: 0.048900, loss_s1: 0.037731, loss_fp: 0.005721, loss_freq: 0.011144
[16:32:32.680] iteration 25496: loss: 0.042019, loss_s1: 0.031651, loss_fp: 0.002304, loss_freq: 0.022430
[16:32:33.303] iteration 25497: loss: 0.044740, loss_s1: 0.036207, loss_fp: 0.002263, loss_freq: 0.012940
[16:32:33.927] iteration 25498: loss: 0.043137, loss_s1: 0.029369, loss_fp: 0.008767, loss_freq: 0.007874
[16:32:34.536] iteration 25499: loss: 0.050995, loss_s1: 0.006551, loss_fp: 0.005431, loss_freq: 0.027015
[16:32:35.162] iteration 25500: loss: 0.059079, loss_s1: 0.025504, loss_fp: 0.006989, loss_freq: 0.045672
[16:32:35.781] iteration 25501: loss: 0.048584, loss_s1: 0.028282, loss_fp: 0.003444, loss_freq: 0.024430
[16:32:36.399] iteration 25502: loss: 0.057259, loss_s1: 0.057427, loss_fp: 0.007851, loss_freq: 0.011714
[16:32:37.019] iteration 25503: loss: 0.047292, loss_s1: 0.037716, loss_fp: 0.001437, loss_freq: 0.022483
[16:32:37.641] iteration 25504: loss: 0.047876, loss_s1: 0.038002, loss_fp: 0.007346, loss_freq: 0.014516
[16:32:38.261] iteration 25505: loss: 0.056116, loss_s1: 0.023838, loss_fp: 0.007812, loss_freq: 0.028710
[16:32:38.884] iteration 25506: loss: 0.072169, loss_s1: 0.043495, loss_fp: 0.011923, loss_freq: 0.018346
[16:32:39.507] iteration 25507: loss: 0.065454, loss_s1: 0.054316, loss_fp: 0.006114, loss_freq: 0.019298
[16:32:40.123] iteration 25508: loss: 0.050472, loss_s1: 0.031356, loss_fp: 0.002569, loss_freq: 0.039641
[16:32:40.748] iteration 25509: loss: 0.028662, loss_s1: 0.022682, loss_fp: 0.001150, loss_freq: 0.005224
[16:32:41.376] iteration 25510: loss: 0.032981, loss_s1: 0.009705, loss_fp: 0.001981, loss_freq: 0.013309
[16:32:41.996] iteration 25511: loss: 0.055552, loss_s1: 0.069031, loss_fp: 0.000945, loss_freq: 0.014042
[16:32:42.622] iteration 25512: loss: 0.055337, loss_s1: 0.053797, loss_fp: 0.004379, loss_freq: 0.020973
[16:32:43.247] iteration 25513: loss: 0.104790, loss_s1: 0.069469, loss_fp: 0.001967, loss_freq: 0.103279
[16:32:43.858] iteration 25514: loss: 0.063840, loss_s1: 0.061887, loss_fp: 0.000549, loss_freq: 0.022114
[16:32:44.488] iteration 25515: loss: 0.043533, loss_s1: 0.023726, loss_fp: 0.001551, loss_freq: 0.020976
[16:32:45.117] iteration 25516: loss: 0.051473, loss_s1: 0.049025, loss_fp: 0.001034, loss_freq: 0.009438
[16:32:45.750] iteration 25517: loss: 0.082952, loss_s1: 0.082559, loss_fp: 0.008702, loss_freq: 0.030817
[16:32:46.383] iteration 25518: loss: 0.042363, loss_s1: 0.033640, loss_fp: 0.001945, loss_freq: 0.013297
[16:32:47.000] iteration 25519: loss: 0.067268, loss_s1: 0.037943, loss_fp: 0.003218, loss_freq: 0.036031
[16:32:47.627] iteration 25520: loss: 0.073929, loss_s1: 0.067347, loss_fp: 0.017946, loss_freq: 0.025232
[16:32:48.261] iteration 25521: loss: 0.062663, loss_s1: 0.051654, loss_fp: 0.001509, loss_freq: 0.015743
[16:32:48.889] iteration 25522: loss: 0.045545, loss_s1: 0.029542, loss_fp: 0.005385, loss_freq: 0.026528
[16:32:49.516] iteration 25523: loss: 0.030292, loss_s1: 0.014135, loss_fp: 0.001726, loss_freq: 0.013635
[16:32:50.141] iteration 25524: loss: 0.070047, loss_s1: 0.039043, loss_fp: 0.007811, loss_freq: 0.021532
[16:32:50.765] iteration 25525: loss: 0.048305, loss_s1: 0.034898, loss_fp: 0.003647, loss_freq: 0.021101
[16:32:51.394] iteration 25526: loss: 0.057347, loss_s1: 0.033884, loss_fp: 0.003197, loss_freq: 0.033219
[16:32:52.017] iteration 25527: loss: 0.065966, loss_s1: 0.024500, loss_fp: 0.015962, loss_freq: 0.064912
[16:32:52.638] iteration 25528: loss: 0.079386, loss_s1: 0.045913, loss_fp: 0.005596, loss_freq: 0.055343
[16:32:53.264] iteration 25529: loss: 0.100979, loss_s1: 0.092779, loss_fp: 0.008470, loss_freq: 0.064243
[16:32:53.884] iteration 25530: loss: 0.036521, loss_s1: 0.025552, loss_fp: 0.003447, loss_freq: 0.013963
[16:32:54.508] iteration 25531: loss: 0.045630, loss_s1: 0.048150, loss_fp: 0.002263, loss_freq: 0.012390
[16:32:55.123] iteration 25532: loss: 0.040440, loss_s1: 0.035522, loss_fp: 0.001565, loss_freq: 0.006051
[16:32:55.741] iteration 25533: loss: 0.082164, loss_s1: 0.062580, loss_fp: 0.016314, loss_freq: 0.049638
[16:32:56.359] iteration 25534: loss: 0.081686, loss_s1: 0.059673, loss_fp: 0.006701, loss_freq: 0.025572
[16:32:56.989] iteration 25535: loss: 0.046454, loss_s1: 0.022952, loss_fp: 0.000593, loss_freq: 0.033419
[16:32:57.607] iteration 25536: loss: 0.043961, loss_s1: 0.028491, loss_fp: 0.003933, loss_freq: 0.019863
[16:32:58.224] iteration 25537: loss: 0.038264, loss_s1: 0.016235, loss_fp: 0.003623, loss_freq: 0.018827
[16:32:58.847] iteration 25538: loss: 0.040336, loss_s1: 0.032612, loss_fp: 0.004203, loss_freq: 0.016593
[16:32:59.468] iteration 25539: loss: 0.060272, loss_s1: 0.038340, loss_fp: 0.007187, loss_freq: 0.034575
[16:33:00.132] iteration 25540: loss: 0.078544, loss_s1: 0.052834, loss_fp: 0.002155, loss_freq: 0.044535
[16:33:00.751] iteration 25541: loss: 0.045904, loss_s1: 0.030531, loss_fp: 0.003255, loss_freq: 0.016111
[16:33:01.372] iteration 25542: loss: 0.035552, loss_s1: 0.015321, loss_fp: 0.000875, loss_freq: 0.015170
[16:33:01.989] iteration 25543: loss: 0.040101, loss_s1: 0.023550, loss_fp: 0.005353, loss_freq: 0.006662
[16:33:02.606] iteration 25544: loss: 0.049109, loss_s1: 0.034159, loss_fp: 0.006582, loss_freq: 0.019659
[16:33:03.221] iteration 25545: loss: 0.061020, loss_s1: 0.037622, loss_fp: 0.003524, loss_freq: 0.036662
[16:33:03.847] iteration 25546: loss: 0.057436, loss_s1: 0.059101, loss_fp: 0.000659, loss_freq: 0.023503
[16:33:04.471] iteration 25547: loss: 0.040677, loss_s1: 0.022559, loss_fp: 0.002714, loss_freq: 0.015640
[16:33:05.098] iteration 25548: loss: 0.063674, loss_s1: 0.055145, loss_fp: 0.002979, loss_freq: 0.013043
[16:33:05.719] iteration 25549: loss: 0.027540, loss_s1: 0.009171, loss_fp: 0.001887, loss_freq: 0.008327
[16:33:06.339] iteration 25550: loss: 0.046124, loss_s1: 0.029835, loss_fp: 0.000951, loss_freq: 0.008961
[16:33:06.964] iteration 25551: loss: 0.063271, loss_s1: 0.036428, loss_fp: 0.008909, loss_freq: 0.033402
[16:33:07.590] iteration 25552: loss: 0.040649, loss_s1: 0.027397, loss_fp: 0.004154, loss_freq: 0.017951
[16:33:08.211] iteration 25553: loss: 0.044746, loss_s1: 0.017092, loss_fp: 0.002873, loss_freq: 0.022009
[16:33:08.832] iteration 25554: loss: 0.060098, loss_s1: 0.045072, loss_fp: 0.001549, loss_freq: 0.036556
[16:33:09.444] iteration 25555: loss: 0.063033, loss_s1: 0.039084, loss_fp: 0.002563, loss_freq: 0.045821
[16:33:10.071] iteration 25556: loss: 0.075253, loss_s1: 0.060085, loss_fp: 0.003332, loss_freq: 0.030559
[16:33:10.687] iteration 25557: loss: 0.078447, loss_s1: 0.053105, loss_fp: 0.007290, loss_freq: 0.065019
[16:33:11.313] iteration 25558: loss: 0.031316, loss_s1: 0.006733, loss_fp: 0.002855, loss_freq: 0.011331
[16:33:11.940] iteration 25559: loss: 0.053068, loss_s1: 0.039610, loss_fp: 0.002872, loss_freq: 0.020236
[16:33:12.565] iteration 25560: loss: 0.053790, loss_s1: 0.049186, loss_fp: 0.002299, loss_freq: 0.015458
[16:33:13.190] iteration 25561: loss: 0.068163, loss_s1: 0.042996, loss_fp: 0.002135, loss_freq: 0.056594
[16:33:13.818] iteration 25562: loss: 0.040203, loss_s1: 0.013014, loss_fp: 0.002898, loss_freq: 0.031750
[16:33:14.441] iteration 25563: loss: 0.086146, loss_s1: 0.070347, loss_fp: 0.000866, loss_freq: 0.039240
[16:33:15.056] iteration 25564: loss: 0.048860, loss_s1: 0.038360, loss_fp: 0.005843, loss_freq: 0.022650
[16:33:15.679] iteration 25565: loss: 0.038778, loss_s1: 0.023079, loss_fp: 0.004465, loss_freq: 0.017149
[16:33:16.303] iteration 25566: loss: 0.061257, loss_s1: 0.043624, loss_fp: 0.004569, loss_freq: 0.041764
[16:33:16.935] iteration 25567: loss: 0.038297, loss_s1: 0.016236, loss_fp: 0.001511, loss_freq: 0.015746
[16:33:17.562] iteration 25568: loss: 0.067126, loss_s1: 0.041870, loss_fp: 0.028947, loss_freq: 0.020039
[16:33:18.188] iteration 25569: loss: 0.043781, loss_s1: 0.016410, loss_fp: 0.000788, loss_freq: 0.008348
[16:33:18.811] iteration 25570: loss: 0.028762, loss_s1: 0.012261, loss_fp: 0.004449, loss_freq: 0.011336
[16:33:19.440] iteration 25571: loss: 0.077383, loss_s1: 0.055680, loss_fp: 0.005049, loss_freq: 0.053692
[16:33:20.071] iteration 25572: loss: 0.078021, loss_s1: 0.089260, loss_fp: 0.003075, loss_freq: 0.024052
[16:33:20.698] iteration 25573: loss: 0.031874, loss_s1: 0.030596, loss_fp: 0.003682, loss_freq: 0.004366
[16:33:21.327] iteration 25574: loss: 0.047210, loss_s1: 0.028134, loss_fp: 0.000926, loss_freq: 0.031205
[16:33:21.954] iteration 25575: loss: 0.061860, loss_s1: 0.051792, loss_fp: 0.004247, loss_freq: 0.032814
[16:33:22.581] iteration 25576: loss: 0.054788, loss_s1: 0.041034, loss_fp: 0.002070, loss_freq: 0.022353
[16:33:23.202] iteration 25577: loss: 0.035445, loss_s1: 0.024527, loss_fp: 0.000761, loss_freq: 0.010688
[16:33:23.826] iteration 25578: loss: 0.042151, loss_s1: 0.023722, loss_fp: 0.001903, loss_freq: 0.022794
[16:33:24.454] iteration 25579: loss: 0.050731, loss_s1: 0.044710, loss_fp: 0.005936, loss_freq: 0.021455
[16:33:25.076] iteration 25580: loss: 0.035575, loss_s1: 0.021950, loss_fp: 0.003077, loss_freq: 0.006959
[16:33:25.700] iteration 25581: loss: 0.037419, loss_s1: 0.009938, loss_fp: 0.006850, loss_freq: 0.029656
[16:33:26.323] iteration 25582: loss: 0.060950, loss_s1: 0.052965, loss_fp: 0.001642, loss_freq: 0.032446
[16:33:26.942] iteration 25583: loss: 0.042393, loss_s1: 0.030076, loss_fp: 0.009574, loss_freq: 0.009718
[16:33:27.561] iteration 25584: loss: 0.036697, loss_s1: 0.024617, loss_fp: 0.004995, loss_freq: 0.007156
[16:33:28.185] iteration 25585: loss: 0.043326, loss_s1: 0.020654, loss_fp: 0.002931, loss_freq: 0.015061
[16:33:28.806] iteration 25586: loss: 0.051880, loss_s1: 0.039142, loss_fp: 0.005433, loss_freq: 0.022807
[16:33:29.421] iteration 25587: loss: 0.062587, loss_s1: 0.047496, loss_fp: 0.003226, loss_freq: 0.034215
[16:33:30.047] iteration 25588: loss: 0.058417, loss_s1: 0.036688, loss_fp: 0.005228, loss_freq: 0.029438
[16:33:30.670] iteration 25589: loss: 0.059873, loss_s1: 0.026669, loss_fp: 0.000566, loss_freq: 0.019454
[16:33:31.296] iteration 25590: loss: 0.065474, loss_s1: 0.051021, loss_fp: 0.014715, loss_freq: 0.029501
[16:33:31.918] iteration 25591: loss: 0.050026, loss_s1: 0.023518, loss_fp: 0.004997, loss_freq: 0.025936
[16:33:32.539] iteration 25592: loss: 0.026920, loss_s1: 0.011443, loss_fp: 0.001787, loss_freq: 0.005889
[16:33:33.161] iteration 25593: loss: 0.060336, loss_s1: 0.059249, loss_fp: 0.011533, loss_freq: 0.019505
[16:33:33.795] iteration 25594: loss: 0.063426, loss_s1: 0.059420, loss_fp: 0.007042, loss_freq: 0.020297
[16:33:34.439] iteration 25595: loss: 0.068791, loss_s1: 0.060514, loss_fp: 0.000950, loss_freq: 0.034428
[16:33:35.067] iteration 25596: loss: 0.080304, loss_s1: 0.065653, loss_fp: 0.008973, loss_freq: 0.038735
[16:33:35.700] iteration 25597: loss: 0.047055, loss_s1: 0.042184, loss_fp: 0.001470, loss_freq: 0.016017
[16:33:36.683] iteration 25598: loss: 0.056650, loss_s1: 0.057677, loss_fp: 0.004333, loss_freq: 0.008881
[16:33:37.408] iteration 25599: loss: 0.063539, loss_s1: 0.060575, loss_fp: 0.004362, loss_freq: 0.022636
[16:33:38.046] iteration 25600: loss: 0.041972, loss_s1: 0.034504, loss_fp: 0.001681, loss_freq: 0.018896
[16:33:41.495] iteration 25600 : mean_dice : 0.796715
[16:33:42.144] iteration 25601: loss: 0.065290, loss_s1: 0.048578, loss_fp: 0.006063, loss_freq: 0.037630
[16:33:42.781] iteration 25602: loss: 0.044822, loss_s1: 0.031530, loss_fp: 0.003335, loss_freq: 0.027533
[16:33:43.415] iteration 25603: loss: 0.048722, loss_s1: 0.032386, loss_fp: 0.004973, loss_freq: 0.022177
[16:33:44.042] iteration 25604: loss: 0.028616, loss_s1: 0.009272, loss_fp: 0.002475, loss_freq: 0.020599
[16:33:44.669] iteration 25605: loss: 0.061208, loss_s1: 0.048732, loss_fp: 0.002517, loss_freq: 0.026981
[16:33:45.287] iteration 25606: loss: 0.045805, loss_s1: 0.038060, loss_fp: 0.008371, loss_freq: 0.009238
[16:33:45.921] iteration 25607: loss: 0.047310, loss_s1: 0.017472, loss_fp: 0.002243, loss_freq: 0.018398
[16:33:46.550] iteration 25608: loss: 0.046428, loss_s1: 0.030465, loss_fp: 0.001983, loss_freq: 0.025214
[16:33:47.179] iteration 25609: loss: 0.048464, loss_s1: 0.022739, loss_fp: 0.004591, loss_freq: 0.028721
[16:33:47.806] iteration 25610: loss: 0.045316, loss_s1: 0.050130, loss_fp: 0.001017, loss_freq: 0.004667
[16:33:48.431] iteration 25611: loss: 0.033302, loss_s1: 0.019402, loss_fp: 0.002548, loss_freq: 0.009214
[16:33:49.058] iteration 25612: loss: 0.053774, loss_s1: 0.039979, loss_fp: 0.001293, loss_freq: 0.029918
[16:33:49.701] iteration 25613: loss: 0.050962, loss_s1: 0.039885, loss_fp: 0.002639, loss_freq: 0.019870
[16:33:50.326] iteration 25614: loss: 0.063005, loss_s1: 0.035798, loss_fp: 0.006833, loss_freq: 0.042165
[16:33:50.947] iteration 25615: loss: 0.037663, loss_s1: 0.015832, loss_fp: 0.001215, loss_freq: 0.012003
[16:33:51.576] iteration 25616: loss: 0.041147, loss_s1: 0.026468, loss_fp: 0.005199, loss_freq: 0.019804
[16:33:52.204] iteration 25617: loss: 0.026086, loss_s1: 0.014956, loss_fp: 0.002573, loss_freq: 0.009064
[16:33:52.825] iteration 25618: loss: 0.082582, loss_s1: 0.043493, loss_fp: 0.002544, loss_freq: 0.049957
[16:33:53.453] iteration 25619: loss: 0.035006, loss_s1: 0.020630, loss_fp: 0.001444, loss_freq: 0.019556
[16:33:54.101] iteration 25620: loss: 0.059089, loss_s1: 0.054195, loss_fp: 0.002253, loss_freq: 0.031000
[16:33:54.729] iteration 25621: loss: 0.039703, loss_s1: 0.011530, loss_fp: 0.016644, loss_freq: 0.014198
[16:33:55.362] iteration 25622: loss: 0.035803, loss_s1: 0.012936, loss_fp: 0.004045, loss_freq: 0.010856
[16:33:56.006] iteration 25623: loss: 0.052459, loss_s1: 0.041938, loss_fp: 0.000809, loss_freq: 0.018371
[16:33:56.653] iteration 25624: loss: 0.083285, loss_s1: 0.072720, loss_fp: 0.002012, loss_freq: 0.046318
[16:33:57.297] iteration 25625: loss: 0.051553, loss_s1: 0.055054, loss_fp: 0.000495, loss_freq: 0.010290
[16:33:57.928] iteration 25626: loss: 0.053204, loss_s1: 0.029330, loss_fp: 0.001749, loss_freq: 0.023723
[16:33:58.575] iteration 25627: loss: 0.049333, loss_s1: 0.049817, loss_fp: 0.001460, loss_freq: 0.011709
[16:33:59.194] iteration 25628: loss: 0.053775, loss_s1: 0.061767, loss_fp: 0.003055, loss_freq: 0.007599
[16:33:59.839] iteration 25629: loss: 0.058148, loss_s1: 0.047342, loss_fp: 0.002529, loss_freq: 0.024356
[16:34:00.472] iteration 25630: loss: 0.070998, loss_s1: 0.043383, loss_fp: 0.012154, loss_freq: 0.055756
[16:34:01.105] iteration 25631: loss: 0.070555, loss_s1: 0.057677, loss_fp: 0.011745, loss_freq: 0.039610
[16:34:01.737] iteration 25632: loss: 0.052534, loss_s1: 0.033261, loss_fp: 0.004704, loss_freq: 0.028877
[16:34:02.364] iteration 25633: loss: 0.058227, loss_s1: 0.034167, loss_fp: 0.007263, loss_freq: 0.022200
[16:34:03.000] iteration 25634: loss: 0.063136, loss_s1: 0.026096, loss_fp: 0.005881, loss_freq: 0.056616
[16:34:03.636] iteration 25635: loss: 0.057304, loss_s1: 0.052274, loss_fp: 0.002238, loss_freq: 0.025145
[16:34:04.253] iteration 25636: loss: 0.093298, loss_s1: 0.089678, loss_fp: 0.000792, loss_freq: 0.055681
[16:34:04.906] iteration 25637: loss: 0.041125, loss_s1: 0.029904, loss_fp: 0.003606, loss_freq: 0.014751
[16:34:05.558] iteration 25638: loss: 0.058161, loss_s1: 0.044311, loss_fp: 0.003085, loss_freq: 0.010838
[16:34:06.175] iteration 25639: loss: 0.033472, loss_s1: 0.025279, loss_fp: 0.002578, loss_freq: 0.014463
[16:34:06.799] iteration 25640: loss: 0.060057, loss_s1: 0.031508, loss_fp: 0.001318, loss_freq: 0.055564
[16:34:07.458] iteration 25641: loss: 0.049688, loss_s1: 0.027310, loss_fp: 0.007107, loss_freq: 0.019688
[16:34:08.078] iteration 25642: loss: 0.038423, loss_s1: 0.019707, loss_fp: 0.001873, loss_freq: 0.007426
[16:34:08.700] iteration 25643: loss: 0.088455, loss_s1: 0.084014, loss_fp: 0.006849, loss_freq: 0.053137
[16:34:09.327] iteration 25644: loss: 0.051284, loss_s1: 0.022783, loss_fp: 0.007739, loss_freq: 0.026505
[16:34:09.955] iteration 25645: loss: 0.047867, loss_s1: 0.040028, loss_fp: 0.001651, loss_freq: 0.017192
[16:34:10.588] iteration 25646: loss: 0.049004, loss_s1: 0.021043, loss_fp: 0.003642, loss_freq: 0.046250
[16:34:11.212] iteration 25647: loss: 0.033585, loss_s1: 0.011167, loss_fp: 0.002056, loss_freq: 0.018534
[16:34:11.837] iteration 25648: loss: 0.059425, loss_s1: 0.040521, loss_fp: 0.003452, loss_freq: 0.029938
[16:34:12.459] iteration 25649: loss: 0.061203, loss_s1: 0.060384, loss_fp: 0.003367, loss_freq: 0.020396
[16:34:13.085] iteration 25650: loss: 0.043661, loss_s1: 0.027692, loss_fp: 0.002653, loss_freq: 0.015291
[16:34:13.708] iteration 25651: loss: 0.068465, loss_s1: 0.045849, loss_fp: 0.007346, loss_freq: 0.056848
[16:34:14.325] iteration 25652: loss: 0.026374, loss_s1: 0.012244, loss_fp: 0.000422, loss_freq: 0.006573
[16:34:14.944] iteration 25653: loss: 0.037407, loss_s1: 0.029917, loss_fp: 0.002662, loss_freq: 0.006046
[16:34:15.559] iteration 25654: loss: 0.068113, loss_s1: 0.070548, loss_fp: 0.001466, loss_freq: 0.028164
[16:34:16.178] iteration 25655: loss: 0.039977, loss_s1: 0.035121, loss_fp: 0.002411, loss_freq: 0.012866
[16:34:16.802] iteration 25656: loss: 0.050813, loss_s1: 0.017256, loss_fp: 0.007814, loss_freq: 0.024194
[16:34:17.423] iteration 25657: loss: 0.053811, loss_s1: 0.039979, loss_fp: 0.001215, loss_freq: 0.023537
[16:34:18.046] iteration 25658: loss: 0.049724, loss_s1: 0.039149, loss_fp: 0.005150, loss_freq: 0.017440
[16:34:18.666] iteration 25659: loss: 0.054301, loss_s1: 0.045602, loss_fp: 0.006170, loss_freq: 0.016744
[16:34:19.280] iteration 25660: loss: 0.132669, loss_s1: 0.104227, loss_fp: 0.010942, loss_freq: 0.105740
[16:34:19.904] iteration 25661: loss: 0.064066, loss_s1: 0.044466, loss_fp: 0.006417, loss_freq: 0.028413
[16:34:20.528] iteration 25662: loss: 0.073790, loss_s1: 0.083255, loss_fp: 0.013408, loss_freq: 0.015726
[16:34:21.165] iteration 25663: loss: 0.046216, loss_s1: 0.035664, loss_fp: 0.003267, loss_freq: 0.016788
[16:34:21.788] iteration 25664: loss: 0.097399, loss_s1: 0.093601, loss_fp: 0.005326, loss_freq: 0.055488
[16:34:22.411] iteration 25665: loss: 0.038640, loss_s1: 0.019106, loss_fp: 0.003754, loss_freq: 0.021543
[16:34:23.173] iteration 25666: loss: 0.048614, loss_s1: 0.030850, loss_fp: 0.011082, loss_freq: 0.018687
[16:34:23.863] iteration 25667: loss: 0.064987, loss_s1: 0.022903, loss_fp: 0.001050, loss_freq: 0.015696
[16:34:24.614] iteration 25668: loss: 0.052733, loss_s1: 0.042306, loss_fp: 0.001268, loss_freq: 0.023506
[16:34:25.291] iteration 25669: loss: 0.047817, loss_s1: 0.026513, loss_fp: 0.009996, loss_freq: 0.021478
[16:34:25.976] iteration 25670: loss: 0.042658, loss_s1: 0.037478, loss_fp: 0.005614, loss_freq: 0.013958
[16:34:26.630] iteration 25671: loss: 0.110740, loss_s1: 0.082664, loss_fp: 0.037320, loss_freq: 0.035651
[16:34:27.262] iteration 25672: loss: 0.050759, loss_s1: 0.029839, loss_fp: 0.004695, loss_freq: 0.031372
[16:34:27.881] iteration 25673: loss: 0.065700, loss_s1: 0.024539, loss_fp: 0.002943, loss_freq: 0.015254
[16:34:28.500] iteration 25674: loss: 0.065440, loss_s1: 0.054270, loss_fp: 0.001791, loss_freq: 0.043900
[16:34:29.114] iteration 25675: loss: 0.055468, loss_s1: 0.040205, loss_fp: 0.001559, loss_freq: 0.027712
[16:34:29.732] iteration 25676: loss: 0.057912, loss_s1: 0.034775, loss_fp: 0.009261, loss_freq: 0.032747
[16:34:30.349] iteration 25677: loss: 0.076455, loss_s1: 0.050933, loss_fp: 0.009017, loss_freq: 0.016958
[16:34:30.970] iteration 25678: loss: 0.034189, loss_s1: 0.008768, loss_fp: 0.005883, loss_freq: 0.013439
[16:34:31.590] iteration 25679: loss: 0.079838, loss_s1: 0.075550, loss_fp: 0.003176, loss_freq: 0.020076
[16:34:32.215] iteration 25680: loss: 0.037462, loss_s1: 0.012718, loss_fp: 0.009556, loss_freq: 0.018670
[16:34:32.835] iteration 25681: loss: 0.052566, loss_s1: 0.037599, loss_fp: 0.002303, loss_freq: 0.031456
[16:34:33.459] iteration 25682: loss: 0.065180, loss_s1: 0.055209, loss_fp: 0.004887, loss_freq: 0.023437
[16:34:34.076] iteration 25683: loss: 0.074692, loss_s1: 0.077402, loss_fp: 0.004033, loss_freq: 0.033098
[16:34:34.696] iteration 25684: loss: 0.070634, loss_s1: 0.063122, loss_fp: 0.005057, loss_freq: 0.030418
[16:34:35.323] iteration 25685: loss: 0.032053, loss_s1: 0.018351, loss_fp: 0.001095, loss_freq: 0.006324
[16:34:35.945] iteration 25686: loss: 0.032394, loss_s1: 0.020615, loss_fp: 0.002230, loss_freq: 0.006969
[16:34:36.559] iteration 25687: loss: 0.044917, loss_s1: 0.042372, loss_fp: 0.002705, loss_freq: 0.014720
[16:34:37.176] iteration 25688: loss: 0.072610, loss_s1: 0.044487, loss_fp: 0.000916, loss_freq: 0.016434
[16:34:37.809] iteration 25689: loss: 0.047385, loss_s1: 0.036326, loss_fp: 0.003038, loss_freq: 0.024540
[16:34:38.434] iteration 25690: loss: 0.057542, loss_s1: 0.047185, loss_fp: 0.008460, loss_freq: 0.018064
[16:34:39.054] iteration 25691: loss: 0.031094, loss_s1: 0.017850, loss_fp: 0.001044, loss_freq: 0.004451
[16:34:39.678] iteration 25692: loss: 0.035420, loss_s1: 0.019771, loss_fp: 0.001837, loss_freq: 0.013993
[16:34:40.296] iteration 25693: loss: 0.046574, loss_s1: 0.010997, loss_fp: 0.001791, loss_freq: 0.042531
[16:34:40.916] iteration 25694: loss: 0.060990, loss_s1: 0.042494, loss_fp: 0.003010, loss_freq: 0.028355
[16:34:41.533] iteration 25695: loss: 0.059565, loss_s1: 0.035324, loss_fp: 0.002750, loss_freq: 0.019294
[16:34:42.160] iteration 25696: loss: 0.043017, loss_s1: 0.022968, loss_fp: 0.002228, loss_freq: 0.008280
[16:34:42.788] iteration 25697: loss: 0.050364, loss_s1: 0.017810, loss_fp: 0.002258, loss_freq: 0.030865
[16:34:43.413] iteration 25698: loss: 0.077790, loss_s1: 0.074479, loss_fp: 0.002997, loss_freq: 0.034549
[16:34:44.038] iteration 25699: loss: 0.056336, loss_s1: 0.025802, loss_fp: 0.001346, loss_freq: 0.033023
[16:34:44.668] iteration 25700: loss: 0.086362, loss_s1: 0.076124, loss_fp: 0.004189, loss_freq: 0.062003
[16:34:45.293] iteration 25701: loss: 0.036291, loss_s1: 0.027512, loss_fp: 0.000827, loss_freq: 0.007056
[16:34:45.916] iteration 25702: loss: 0.049096, loss_s1: 0.044557, loss_fp: 0.002901, loss_freq: 0.009455
[16:34:46.541] iteration 25703: loss: 0.084134, loss_s1: 0.046202, loss_fp: 0.012297, loss_freq: 0.045450
[16:34:47.164] iteration 25704: loss: 0.064365, loss_s1: 0.038961, loss_fp: 0.003081, loss_freq: 0.030348
[16:34:47.803] iteration 25705: loss: 0.116022, loss_s1: 0.074797, loss_fp: 0.033874, loss_freq: 0.097317
[16:34:48.418] iteration 25706: loss: 0.058950, loss_s1: 0.040971, loss_fp: 0.001174, loss_freq: 0.030243
[16:34:49.043] iteration 25707: loss: 0.096345, loss_s1: 0.094328, loss_fp: 0.003551, loss_freq: 0.059493
[16:34:49.667] iteration 25708: loss: 0.098306, loss_s1: 0.064405, loss_fp: 0.014304, loss_freq: 0.076442
[16:34:50.297] iteration 25709: loss: 0.049635, loss_s1: 0.034726, loss_fp: 0.001670, loss_freq: 0.035120
[16:34:50.920] iteration 25710: loss: 0.043362, loss_s1: 0.021025, loss_fp: 0.000542, loss_freq: 0.015898
[16:34:51.547] iteration 25711: loss: 0.040609, loss_s1: 0.035955, loss_fp: 0.001761, loss_freq: 0.010946
[16:34:52.167] iteration 25712: loss: 0.122077, loss_s1: 0.120441, loss_fp: 0.002132, loss_freq: 0.040476
[16:34:52.784] iteration 25713: loss: 0.032562, loss_s1: 0.021906, loss_fp: 0.002518, loss_freq: 0.008457
[16:34:53.410] iteration 25714: loss: 0.055346, loss_s1: 0.021730, loss_fp: 0.004347, loss_freq: 0.034307
[16:34:54.028] iteration 25715: loss: 0.072694, loss_s1: 0.090692, loss_fp: 0.001666, loss_freq: 0.015631
[16:34:54.647] iteration 25716: loss: 0.067385, loss_s1: 0.076577, loss_fp: 0.006931, loss_freq: 0.022600
[16:34:55.265] iteration 25717: loss: 0.039109, loss_s1: 0.023197, loss_fp: 0.003057, loss_freq: 0.012199
[16:34:55.887] iteration 25718: loss: 0.051772, loss_s1: 0.030079, loss_fp: 0.003146, loss_freq: 0.031753
[16:34:56.503] iteration 25719: loss: 0.059571, loss_s1: 0.067966, loss_fp: 0.002282, loss_freq: 0.013418
[16:34:57.123] iteration 25720: loss: 0.044210, loss_s1: 0.037773, loss_fp: 0.001756, loss_freq: 0.005121
[16:34:57.747] iteration 25721: loss: 0.051551, loss_s1: 0.044597, loss_fp: 0.001891, loss_freq: 0.020803
[16:34:58.365] iteration 25722: loss: 0.068315, loss_s1: 0.065453, loss_fp: 0.005397, loss_freq: 0.028385
[16:34:58.999] iteration 25723: loss: 0.066968, loss_s1: 0.038643, loss_fp: 0.002591, loss_freq: 0.013785
[16:34:59.652] iteration 25724: loss: 0.073852, loss_s1: 0.023747, loss_fp: 0.012174, loss_freq: 0.081737
[16:35:00.300] iteration 25725: loss: 0.042730, loss_s1: 0.033344, loss_fp: 0.001916, loss_freq: 0.018602
[16:35:00.917] iteration 25726: loss: 0.079441, loss_s1: 0.093842, loss_fp: 0.003733, loss_freq: 0.019198
[16:35:01.546] iteration 25727: loss: 0.032767, loss_s1: 0.017963, loss_fp: 0.003879, loss_freq: 0.008579
[16:35:02.165] iteration 25728: loss: 0.081481, loss_s1: 0.035448, loss_fp: 0.006275, loss_freq: 0.038278
[16:35:02.794] iteration 25729: loss: 0.113745, loss_s1: 0.105195, loss_fp: 0.002949, loss_freq: 0.050783
[16:35:03.452] iteration 25730: loss: 0.067946, loss_s1: 0.059678, loss_fp: 0.005075, loss_freq: 0.020664
[16:35:04.107] iteration 25731: loss: 0.082716, loss_s1: 0.037921, loss_fp: 0.002760, loss_freq: 0.046746
[16:35:04.762] iteration 25732: loss: 0.041436, loss_s1: 0.019288, loss_fp: 0.001695, loss_freq: 0.016661
[16:35:05.397] iteration 25733: loss: 0.077301, loss_s1: 0.101742, loss_fp: 0.002372, loss_freq: 0.015221
[16:35:06.024] iteration 25734: loss: 0.071837, loss_s1: 0.072783, loss_fp: 0.002489, loss_freq: 0.026867
[16:35:06.651] iteration 25735: loss: 0.033555, loss_s1: 0.016253, loss_fp: 0.001549, loss_freq: 0.006966
[16:35:07.269] iteration 25736: loss: 0.049057, loss_s1: 0.039118, loss_fp: 0.004589, loss_freq: 0.024260
[16:35:07.894] iteration 25737: loss: 0.058921, loss_s1: 0.033851, loss_fp: 0.005105, loss_freq: 0.022273
[16:35:08.510] iteration 25738: loss: 0.046443, loss_s1: 0.030913, loss_fp: 0.002188, loss_freq: 0.026367
[16:35:09.141] iteration 25739: loss: 0.053806, loss_s1: 0.034536, loss_fp: 0.004409, loss_freq: 0.033121
[16:35:09.766] iteration 25740: loss: 0.033195, loss_s1: 0.009407, loss_fp: 0.003187, loss_freq: 0.017425
[16:35:10.744] iteration 25741: loss: 0.048672, loss_s1: 0.037242, loss_fp: 0.000896, loss_freq: 0.014427
[16:35:11.362] iteration 25742: loss: 0.050879, loss_s1: 0.035193, loss_fp: 0.003798, loss_freq: 0.026577
[16:35:11.979] iteration 25743: loss: 0.034564, loss_s1: 0.020755, loss_fp: 0.000974, loss_freq: 0.012421
[16:35:12.595] iteration 25744: loss: 0.042567, loss_s1: 0.016301, loss_fp: 0.001030, loss_freq: 0.026478
[16:35:13.241] iteration 25745: loss: 0.073538, loss_s1: 0.083763, loss_fp: 0.001289, loss_freq: 0.020308
[16:35:13.857] iteration 25746: loss: 0.061364, loss_s1: 0.024954, loss_fp: 0.002452, loss_freq: 0.004791
[16:35:14.477] iteration 25747: loss: 0.035108, loss_s1: 0.013572, loss_fp: 0.001087, loss_freq: 0.014129
[16:35:15.121] iteration 25748: loss: 0.072566, loss_s1: 0.052768, loss_fp: 0.006748, loss_freq: 0.040998
[16:35:15.742] iteration 25749: loss: 0.054807, loss_s1: 0.050268, loss_fp: 0.001066, loss_freq: 0.025760
[16:35:16.368] iteration 25750: loss: 0.036057, loss_s1: 0.016676, loss_fp: 0.000622, loss_freq: 0.003637
[16:35:16.991] iteration 25751: loss: 0.050202, loss_s1: 0.031425, loss_fp: 0.002415, loss_freq: 0.027765
[16:35:17.613] iteration 25752: loss: 0.059589, loss_s1: 0.042941, loss_fp: 0.005548, loss_freq: 0.025910
[16:35:18.243] iteration 25753: loss: 0.068225, loss_s1: 0.047273, loss_fp: 0.000671, loss_freq: 0.039559
[16:35:18.862] iteration 25754: loss: 0.037944, loss_s1: 0.018495, loss_fp: 0.007460, loss_freq: 0.021818
[16:35:19.479] iteration 25755: loss: 0.038909, loss_s1: 0.024220, loss_fp: 0.002244, loss_freq: 0.016927
[16:35:20.094] iteration 25756: loss: 0.039845, loss_s1: 0.030316, loss_fp: 0.001591, loss_freq: 0.011349
[16:35:20.714] iteration 25757: loss: 0.057750, loss_s1: 0.021854, loss_fp: 0.000273, loss_freq: 0.049464
[16:35:21.335] iteration 25758: loss: 0.057520, loss_s1: 0.021373, loss_fp: 0.006269, loss_freq: 0.033031
[16:35:21.960] iteration 25759: loss: 0.045528, loss_s1: 0.052126, loss_fp: 0.001977, loss_freq: 0.011245
[16:35:22.579] iteration 25760: loss: 0.039524, loss_s1: 0.036393, loss_fp: 0.000598, loss_freq: 0.012736
[16:35:23.195] iteration 25761: loss: 0.069020, loss_s1: 0.028452, loss_fp: 0.002916, loss_freq: 0.035494
[16:35:23.822] iteration 25762: loss: 0.067030, loss_s1: 0.067282, loss_fp: 0.001841, loss_freq: 0.037373
[16:35:24.442] iteration 25763: loss: 0.052317, loss_s1: 0.021610, loss_fp: 0.002282, loss_freq: 0.037359
[16:35:25.063] iteration 25764: loss: 0.055249, loss_s1: 0.036775, loss_fp: 0.002299, loss_freq: 0.003141
[16:35:25.697] iteration 25765: loss: 0.036804, loss_s1: 0.018817, loss_fp: 0.002600, loss_freq: 0.018113
[16:35:26.321] iteration 25766: loss: 0.106595, loss_s1: 0.119388, loss_fp: 0.001181, loss_freq: 0.053968
[16:35:26.936] iteration 25767: loss: 0.048746, loss_s1: 0.036194, loss_fp: 0.001775, loss_freq: 0.017975
[16:35:27.553] iteration 25768: loss: 0.042490, loss_s1: 0.024629, loss_fp: 0.007840, loss_freq: 0.014185
[16:35:28.174] iteration 25769: loss: 0.058933, loss_s1: 0.026416, loss_fp: 0.003470, loss_freq: 0.018736
[16:35:28.787] iteration 25770: loss: 0.082437, loss_s1: 0.028283, loss_fp: 0.015041, loss_freq: 0.011302
[16:35:29.404] iteration 25771: loss: 0.037447, loss_s1: 0.028006, loss_fp: 0.004115, loss_freq: 0.011286
[16:35:30.034] iteration 25772: loss: 0.054124, loss_s1: 0.041301, loss_fp: 0.007236, loss_freq: 0.022790
[16:35:30.674] iteration 25773: loss: 0.074074, loss_s1: 0.045702, loss_fp: 0.006743, loss_freq: 0.053021
[16:35:31.311] iteration 25774: loss: 0.068709, loss_s1: 0.072690, loss_fp: 0.003828, loss_freq: 0.026100
[16:35:31.945] iteration 25775: loss: 0.075280, loss_s1: 0.059257, loss_fp: 0.002692, loss_freq: 0.026698
[16:35:32.589] iteration 25776: loss: 0.056278, loss_s1: 0.042092, loss_fp: 0.001479, loss_freq: 0.018629
[16:35:33.217] iteration 25777: loss: 0.046033, loss_s1: 0.021917, loss_fp: 0.001420, loss_freq: 0.025404
[16:35:33.836] iteration 25778: loss: 0.073913, loss_s1: 0.102346, loss_fp: 0.001552, loss_freq: 0.013883
[16:35:34.466] iteration 25779: loss: 0.064646, loss_s1: 0.046116, loss_fp: 0.003213, loss_freq: 0.031775
[16:35:35.091] iteration 25780: loss: 0.050439, loss_s1: 0.037230, loss_fp: 0.003863, loss_freq: 0.016979
[16:35:35.712] iteration 25781: loss: 0.071513, loss_s1: 0.052029, loss_fp: 0.008355, loss_freq: 0.025741
[16:35:36.343] iteration 25782: loss: 0.033110, loss_s1: 0.026484, loss_fp: 0.001889, loss_freq: 0.012235
[16:35:36.966] iteration 25783: loss: 0.032677, loss_s1: 0.005129, loss_fp: 0.005449, loss_freq: 0.007873
[16:35:37.578] iteration 25784: loss: 0.038361, loss_s1: 0.033155, loss_fp: 0.002584, loss_freq: 0.007042
[16:35:38.197] iteration 25785: loss: 0.044395, loss_s1: 0.012178, loss_fp: 0.006100, loss_freq: 0.011158
[16:35:38.811] iteration 25786: loss: 0.069668, loss_s1: 0.069259, loss_fp: 0.006842, loss_freq: 0.026340
[16:35:39.443] iteration 25787: loss: 0.055601, loss_s1: 0.025148, loss_fp: 0.004583, loss_freq: 0.044780
[16:35:40.064] iteration 25788: loss: 0.038240, loss_s1: 0.019147, loss_fp: 0.004757, loss_freq: 0.011942
[16:35:40.689] iteration 25789: loss: 0.052015, loss_s1: 0.038620, loss_fp: 0.003333, loss_freq: 0.029192
[16:35:41.315] iteration 25790: loss: 0.057834, loss_s1: 0.050149, loss_fp: 0.005368, loss_freq: 0.028301
[16:35:41.937] iteration 25791: loss: 0.057980, loss_s1: 0.039317, loss_fp: 0.001406, loss_freq: 0.036719
[16:35:42.562] iteration 25792: loss: 0.058271, loss_s1: 0.018187, loss_fp: 0.001874, loss_freq: 0.046021
[16:35:43.193] iteration 25793: loss: 0.043333, loss_s1: 0.032913, loss_fp: 0.003839, loss_freq: 0.017139
[16:35:43.823] iteration 25794: loss: 0.075280, loss_s1: 0.066729, loss_fp: 0.005583, loss_freq: 0.053074
[16:35:44.446] iteration 25795: loss: 0.029529, loss_s1: 0.018084, loss_fp: 0.001434, loss_freq: 0.010495
[16:35:45.064] iteration 25796: loss: 0.051316, loss_s1: 0.029095, loss_fp: 0.001660, loss_freq: 0.020590
[16:35:45.688] iteration 25797: loss: 0.056024, loss_s1: 0.058868, loss_fp: 0.002267, loss_freq: 0.022813
[16:35:46.307] iteration 25798: loss: 0.047744, loss_s1: 0.027215, loss_fp: 0.000516, loss_freq: 0.013666
[16:35:46.927] iteration 25799: loss: 0.041299, loss_s1: 0.018155, loss_fp: 0.001302, loss_freq: 0.027110
[16:35:47.551] iteration 25800: loss: 0.028698, loss_s1: 0.012510, loss_fp: 0.000538, loss_freq: 0.012094
[16:35:50.785] iteration 25800 : mean_dice : 0.791981
[16:35:51.447] iteration 25801: loss: 0.056226, loss_s1: 0.026628, loss_fp: 0.008033, loss_freq: 0.020756
[16:35:52.087] iteration 25802: loss: 0.041678, loss_s1: 0.030714, loss_fp: 0.004889, loss_freq: 0.008452
[16:35:52.718] iteration 25803: loss: 0.090475, loss_s1: 0.072789, loss_fp: 0.006220, loss_freq: 0.052209
[16:35:53.346] iteration 25804: loss: 0.053371, loss_s1: 0.034092, loss_fp: 0.001344, loss_freq: 0.026552
[16:35:53.979] iteration 25805: loss: 0.039757, loss_s1: 0.018986, loss_fp: 0.005176, loss_freq: 0.017884
[16:35:54.597] iteration 25806: loss: 0.042809, loss_s1: 0.026575, loss_fp: 0.001074, loss_freq: 0.024060
[16:35:55.229] iteration 25807: loss: 0.058509, loss_s1: 0.033881, loss_fp: 0.003469, loss_freq: 0.040133
[16:35:55.843] iteration 25808: loss: 0.055368, loss_s1: 0.052184, loss_fp: 0.004003, loss_freq: 0.024908
[16:35:56.458] iteration 25809: loss: 0.043203, loss_s1: 0.036127, loss_fp: 0.002304, loss_freq: 0.011081
[16:35:57.090] iteration 25810: loss: 0.056493, loss_s1: 0.032399, loss_fp: 0.005872, loss_freq: 0.030584
[16:35:57.725] iteration 25811: loss: 0.039558, loss_s1: 0.024312, loss_fp: 0.002409, loss_freq: 0.013036
[16:35:58.366] iteration 25812: loss: 0.047928, loss_s1: 0.039248, loss_fp: 0.003268, loss_freq: 0.014855
[16:35:58.989] iteration 25813: loss: 0.049542, loss_s1: 0.026300, loss_fp: 0.008528, loss_freq: 0.032396
[16:35:59.611] iteration 25814: loss: 0.087989, loss_s1: 0.053059, loss_fp: 0.010834, loss_freq: 0.056442
[16:36:00.231] iteration 25815: loss: 0.073042, loss_s1: 0.050205, loss_fp: 0.006240, loss_freq: 0.066335
[16:36:00.849] iteration 25816: loss: 0.046474, loss_s1: 0.043108, loss_fp: 0.001140, loss_freq: 0.019734
[16:36:01.469] iteration 25817: loss: 0.085715, loss_s1: 0.088961, loss_fp: 0.007944, loss_freq: 0.043992
[16:36:02.088] iteration 25818: loss: 0.041476, loss_s1: 0.027336, loss_fp: 0.000681, loss_freq: 0.017017
[16:36:02.711] iteration 25819: loss: 0.068106, loss_s1: 0.047256, loss_fp: 0.013532, loss_freq: 0.032894
[16:36:03.343] iteration 25820: loss: 0.110294, loss_s1: 0.107771, loss_fp: 0.012569, loss_freq: 0.020975
[16:36:03.978] iteration 25821: loss: 0.064834, loss_s1: 0.051989, loss_fp: 0.005931, loss_freq: 0.031420
[16:36:04.628] iteration 25822: loss: 0.059103, loss_s1: 0.051517, loss_fp: 0.003351, loss_freq: 0.016267
[16:36:05.267] iteration 25823: loss: 0.054300, loss_s1: 0.037762, loss_fp: 0.002607, loss_freq: 0.019112
[16:36:05.894] iteration 25824: loss: 0.047760, loss_s1: 0.028275, loss_fp: 0.001576, loss_freq: 0.039841
[16:36:06.508] iteration 25825: loss: 0.035435, loss_s1: 0.016670, loss_fp: 0.001290, loss_freq: 0.018493
[16:36:07.127] iteration 25826: loss: 0.059403, loss_s1: 0.016841, loss_fp: 0.017473, loss_freq: 0.039322
[16:36:07.748] iteration 25827: loss: 0.042283, loss_s1: 0.031014, loss_fp: 0.001804, loss_freq: 0.004536
[16:36:08.371] iteration 25828: loss: 0.038718, loss_s1: 0.027589, loss_fp: 0.000343, loss_freq: 0.012002
[16:36:08.989] iteration 25829: loss: 0.040452, loss_s1: 0.041073, loss_fp: 0.001396, loss_freq: 0.008964
[16:36:09.602] iteration 25830: loss: 0.046425, loss_s1: 0.041458, loss_fp: 0.008024, loss_freq: 0.009818
[16:36:10.214] iteration 25831: loss: 0.063291, loss_s1: 0.029494, loss_fp: 0.003391, loss_freq: 0.022486
[16:36:10.841] iteration 25832: loss: 0.067597, loss_s1: 0.051086, loss_fp: 0.002566, loss_freq: 0.041352
[16:36:11.454] iteration 25833: loss: 0.039863, loss_s1: 0.030580, loss_fp: 0.005405, loss_freq: 0.006902
[16:36:12.078] iteration 25834: loss: 0.044162, loss_s1: 0.042144, loss_fp: 0.001194, loss_freq: 0.013838
[16:36:12.694] iteration 25835: loss: 0.045170, loss_s1: 0.022611, loss_fp: 0.001754, loss_freq: 0.014670
[16:36:13.306] iteration 25836: loss: 0.041867, loss_s1: 0.019020, loss_fp: 0.000700, loss_freq: 0.004713
[16:36:13.915] iteration 25837: loss: 0.093813, loss_s1: 0.080218, loss_fp: 0.003737, loss_freq: 0.065400
[16:36:14.586] iteration 25838: loss: 0.063562, loss_s1: 0.048301, loss_fp: 0.011191, loss_freq: 0.022302
[16:36:15.194] iteration 25839: loss: 0.041002, loss_s1: 0.031876, loss_fp: 0.002149, loss_freq: 0.005267
[16:36:15.816] iteration 25840: loss: 0.057665, loss_s1: 0.038186, loss_fp: 0.004214, loss_freq: 0.037986
[16:36:16.466] iteration 25841: loss: 0.043640, loss_s1: 0.020887, loss_fp: 0.000562, loss_freq: 0.014413
[16:36:17.101] iteration 25842: loss: 0.064208, loss_s1: 0.048969, loss_fp: 0.005436, loss_freq: 0.034000
[16:36:17.742] iteration 25843: loss: 0.073053, loss_s1: 0.063626, loss_fp: 0.002298, loss_freq: 0.052185
[16:36:18.373] iteration 25844: loss: 0.029545, loss_s1: 0.020570, loss_fp: 0.001529, loss_freq: 0.004928
[16:36:18.996] iteration 25845: loss: 0.075331, loss_s1: 0.018945, loss_fp: 0.003656, loss_freq: 0.021242
[16:36:19.613] iteration 25846: loss: 0.045293, loss_s1: 0.013710, loss_fp: 0.002062, loss_freq: 0.018456
[16:36:20.232] iteration 25847: loss: 0.079595, loss_s1: 0.070012, loss_fp: 0.000927, loss_freq: 0.049073
[16:36:20.843] iteration 25848: loss: 0.086612, loss_s1: 0.093616, loss_fp: 0.010275, loss_freq: 0.036702
[16:36:21.456] iteration 25849: loss: 0.066079, loss_s1: 0.027755, loss_fp: 0.000800, loss_freq: 0.025321
[16:36:22.064] iteration 25850: loss: 0.052514, loss_s1: 0.048943, loss_fp: 0.012991, loss_freq: 0.018040
[16:36:22.686] iteration 25851: loss: 0.034424, loss_s1: 0.024121, loss_fp: 0.001870, loss_freq: 0.007694
[16:36:23.316] iteration 25852: loss: 0.037242, loss_s1: 0.023052, loss_fp: 0.000922, loss_freq: 0.022005
[16:36:23.936] iteration 25853: loss: 0.048741, loss_s1: 0.031979, loss_fp: 0.001096, loss_freq: 0.021482
[16:36:24.558] iteration 25854: loss: 0.069574, loss_s1: 0.067045, loss_fp: 0.022176, loss_freq: 0.018012
[16:36:25.178] iteration 25855: loss: 0.043332, loss_s1: 0.015529, loss_fp: 0.001260, loss_freq: 0.007717
[16:36:25.797] iteration 25856: loss: 0.059821, loss_s1: 0.049752, loss_fp: 0.002425, loss_freq: 0.016930
[16:36:26.416] iteration 25857: loss: 0.056352, loss_s1: 0.028294, loss_fp: 0.017795, loss_freq: 0.026502
[16:36:27.035] iteration 25858: loss: 0.068648, loss_s1: 0.059477, loss_fp: 0.005553, loss_freq: 0.040195
[16:36:27.667] iteration 25859: loss: 0.038982, loss_s1: 0.038676, loss_fp: 0.003883, loss_freq: 0.006331
[16:36:28.302] iteration 25860: loss: 0.048494, loss_s1: 0.018345, loss_fp: 0.004290, loss_freq: 0.033543
[16:36:28.942] iteration 25861: loss: 0.056701, loss_s1: 0.046684, loss_fp: 0.001687, loss_freq: 0.021536
[16:36:29.588] iteration 25862: loss: 0.072622, loss_s1: 0.075323, loss_fp: 0.009232, loss_freq: 0.020419
[16:36:30.221] iteration 25863: loss: 0.063949, loss_s1: 0.017334, loss_fp: 0.000715, loss_freq: 0.015055
[16:36:30.856] iteration 25864: loss: 0.045650, loss_s1: 0.049409, loss_fp: 0.003384, loss_freq: 0.010683
[16:36:31.492] iteration 25865: loss: 0.048982, loss_s1: 0.035513, loss_fp: 0.006125, loss_freq: 0.026831
[16:36:32.117] iteration 25866: loss: 0.048869, loss_s1: 0.032082, loss_fp: 0.007795, loss_freq: 0.008388
[16:36:32.751] iteration 25867: loss: 0.051054, loss_s1: 0.045567, loss_fp: 0.007585, loss_freq: 0.023071
[16:36:33.390] iteration 25868: loss: 0.060048, loss_s1: 0.036118, loss_fp: 0.004867, loss_freq: 0.021054
[16:36:34.032] iteration 25869: loss: 0.054248, loss_s1: 0.055642, loss_fp: 0.000724, loss_freq: 0.011274
[16:36:34.670] iteration 25870: loss: 0.044434, loss_s1: 0.030601, loss_fp: 0.003837, loss_freq: 0.015608
[16:36:35.314] iteration 25871: loss: 0.056494, loss_s1: 0.039828, loss_fp: 0.004635, loss_freq: 0.027438
[16:36:35.962] iteration 25872: loss: 0.073324, loss_s1: 0.049819, loss_fp: 0.003845, loss_freq: 0.051343
[16:36:36.592] iteration 25873: loss: 0.083708, loss_s1: 0.105805, loss_fp: 0.004463, loss_freq: 0.017900
[16:36:37.231] iteration 25874: loss: 0.073314, loss_s1: 0.067947, loss_fp: 0.000946, loss_freq: 0.037025
[16:36:37.849] iteration 25875: loss: 0.057083, loss_s1: 0.023915, loss_fp: 0.004490, loss_freq: 0.033846
[16:36:38.468] iteration 25876: loss: 0.037410, loss_s1: 0.020876, loss_fp: 0.006739, loss_freq: 0.015610
[16:36:39.095] iteration 25877: loss: 0.039022, loss_s1: 0.021545, loss_fp: 0.003832, loss_freq: 0.014655
[16:36:39.711] iteration 25878: loss: 0.030956, loss_s1: 0.013261, loss_fp: 0.001030, loss_freq: 0.011646
[16:36:40.329] iteration 25879: loss: 0.056882, loss_s1: 0.050814, loss_fp: 0.002440, loss_freq: 0.024363
[16:36:40.946] iteration 25880: loss: 0.050124, loss_s1: 0.036052, loss_fp: 0.006089, loss_freq: 0.012336
[16:36:41.571] iteration 25881: loss: 0.056952, loss_s1: 0.036480, loss_fp: 0.005957, loss_freq: 0.037768
[16:36:42.184] iteration 25882: loss: 0.077651, loss_s1: 0.077072, loss_fp: 0.012279, loss_freq: 0.025599
[16:36:42.796] iteration 25883: loss: 0.064877, loss_s1: 0.080389, loss_fp: 0.001207, loss_freq: 0.013071
[16:36:43.715] iteration 25884: loss: 0.034812, loss_s1: 0.010768, loss_fp: 0.002858, loss_freq: 0.011714
[16:36:44.331] iteration 25885: loss: 0.034611, loss_s1: 0.016498, loss_fp: 0.003510, loss_freq: 0.009664
[16:36:44.993] iteration 25886: loss: 0.046043, loss_s1: 0.042449, loss_fp: 0.003479, loss_freq: 0.014846
[16:36:45.610] iteration 25887: loss: 0.051755, loss_s1: 0.032678, loss_fp: 0.002628, loss_freq: 0.024874
[16:36:46.231] iteration 25888: loss: 0.042364, loss_s1: 0.022075, loss_fp: 0.005265, loss_freq: 0.028386
[16:36:46.847] iteration 25889: loss: 0.036691, loss_s1: 0.017771, loss_fp: 0.002820, loss_freq: 0.005106
[16:36:47.465] iteration 25890: loss: 0.083161, loss_s1: 0.092012, loss_fp: 0.003594, loss_freq: 0.038133
[16:36:48.135] iteration 25891: loss: 0.065620, loss_s1: 0.033027, loss_fp: 0.003895, loss_freq: 0.021559
[16:36:48.758] iteration 25892: loss: 0.044803, loss_s1: 0.025897, loss_fp: 0.006092, loss_freq: 0.023655
[16:36:49.378] iteration 25893: loss: 0.038693, loss_s1: 0.010766, loss_fp: 0.001350, loss_freq: 0.004592
[16:36:50.005] iteration 25894: loss: 0.063107, loss_s1: 0.046076, loss_fp: 0.002417, loss_freq: 0.039350
[16:36:50.641] iteration 25895: loss: 0.078681, loss_s1: 0.034568, loss_fp: 0.004984, loss_freq: 0.054140
[16:36:51.280] iteration 25896: loss: 0.053722, loss_s1: 0.037796, loss_fp: 0.002743, loss_freq: 0.027497
[16:36:52.003] iteration 25897: loss: 0.050940, loss_s1: 0.040730, loss_fp: 0.002942, loss_freq: 0.021766
[16:36:52.641] iteration 25898: loss: 0.045243, loss_s1: 0.028907, loss_fp: 0.003026, loss_freq: 0.020041
[16:36:53.279] iteration 25899: loss: 0.029744, loss_s1: 0.012847, loss_fp: 0.007493, loss_freq: 0.007455
[16:36:53.899] iteration 25900: loss: 0.087461, loss_s1: 0.039824, loss_fp: 0.002853, loss_freq: 0.025937
[16:36:54.527] iteration 25901: loss: 0.047678, loss_s1: 0.028327, loss_fp: 0.001756, loss_freq: 0.013009
[16:36:55.156] iteration 25902: loss: 0.043489, loss_s1: 0.021075, loss_fp: 0.001987, loss_freq: 0.037054
[16:36:55.773] iteration 25903: loss: 0.048125, loss_s1: 0.045221, loss_fp: 0.002703, loss_freq: 0.014872
[16:36:56.398] iteration 25904: loss: 0.069803, loss_s1: 0.052116, loss_fp: 0.003400, loss_freq: 0.037415
[16:36:57.011] iteration 25905: loss: 0.036811, loss_s1: 0.021176, loss_fp: 0.002358, loss_freq: 0.017994
[16:36:57.630] iteration 25906: loss: 0.047009, loss_s1: 0.017620, loss_fp: 0.002062, loss_freq: 0.027715
[16:36:58.252] iteration 25907: loss: 0.042241, loss_s1: 0.017270, loss_fp: 0.002116, loss_freq: 0.005250
[16:36:58.871] iteration 25908: loss: 0.033918, loss_s1: 0.017145, loss_fp: 0.005697, loss_freq: 0.009499
[16:36:59.486] iteration 25909: loss: 0.058108, loss_s1: 0.049965, loss_fp: 0.002991, loss_freq: 0.016797
[16:37:00.102] iteration 25910: loss: 0.057312, loss_s1: 0.049549, loss_fp: 0.003219, loss_freq: 0.025492
[16:37:00.720] iteration 25911: loss: 0.034454, loss_s1: 0.016363, loss_fp: 0.002432, loss_freq: 0.012079
[16:37:01.338] iteration 25912: loss: 0.065229, loss_s1: 0.052524, loss_fp: 0.002318, loss_freq: 0.022524
[16:37:01.956] iteration 25913: loss: 0.087253, loss_s1: 0.010523, loss_fp: 0.002477, loss_freq: 0.020710
[16:37:02.580] iteration 25914: loss: 0.040693, loss_s1: 0.035459, loss_fp: 0.003094, loss_freq: 0.007369
[16:37:03.197] iteration 25915: loss: 0.048114, loss_s1: 0.024694, loss_fp: 0.002865, loss_freq: 0.024167
[16:37:03.813] iteration 25916: loss: 0.065670, loss_s1: 0.039126, loss_fp: 0.003247, loss_freq: 0.060034
[16:37:04.428] iteration 25917: loss: 0.077572, loss_s1: 0.056564, loss_fp: 0.019508, loss_freq: 0.035633
[16:37:05.046] iteration 25918: loss: 0.058054, loss_s1: 0.042034, loss_fp: 0.002156, loss_freq: 0.031080
[16:37:05.674] iteration 25919: loss: 0.059855, loss_s1: 0.053881, loss_fp: 0.001317, loss_freq: 0.027579
[16:37:06.289] iteration 25920: loss: 0.063194, loss_s1: 0.043882, loss_fp: 0.001305, loss_freq: 0.047080
[16:37:06.905] iteration 25921: loss: 0.031120, loss_s1: 0.011799, loss_fp: 0.003250, loss_freq: 0.014628
[16:37:07.523] iteration 25922: loss: 0.092677, loss_s1: 0.074593, loss_fp: 0.001750, loss_freq: 0.056571
[16:37:08.139] iteration 25923: loss: 0.034157, loss_s1: 0.020358, loss_fp: 0.001187, loss_freq: 0.018926
[16:37:08.774] iteration 25924: loss: 0.057017, loss_s1: 0.043734, loss_fp: 0.004060, loss_freq: 0.017743
[16:37:09.391] iteration 25925: loss: 0.036608, loss_s1: 0.026044, loss_fp: 0.002980, loss_freq: 0.018034
[16:37:10.014] iteration 25926: loss: 0.036526, loss_s1: 0.021116, loss_fp: 0.001039, loss_freq: 0.011381
[16:37:10.628] iteration 25927: loss: 0.076589, loss_s1: 0.069943, loss_fp: 0.003493, loss_freq: 0.040436
[16:37:11.249] iteration 25928: loss: 0.066016, loss_s1: 0.043139, loss_fp: 0.000970, loss_freq: 0.013701
[16:37:11.870] iteration 25929: loss: 0.052528, loss_s1: 0.026721, loss_fp: 0.005134, loss_freq: 0.033637
[16:37:12.505] iteration 25930: loss: 0.059349, loss_s1: 0.044659, loss_fp: 0.002936, loss_freq: 0.025536
[16:37:13.137] iteration 25931: loss: 0.036228, loss_s1: 0.024790, loss_fp: 0.001199, loss_freq: 0.014312
[16:37:13.797] iteration 25932: loss: 0.072986, loss_s1: 0.045775, loss_fp: 0.003697, loss_freq: 0.049138
[16:37:14.412] iteration 25933: loss: 0.049756, loss_s1: 0.024509, loss_fp: 0.003037, loss_freq: 0.031134
[16:37:15.035] iteration 25934: loss: 0.060474, loss_s1: 0.049377, loss_fp: 0.002293, loss_freq: 0.014569
[16:37:15.657] iteration 25935: loss: 0.054602, loss_s1: 0.033812, loss_fp: 0.003661, loss_freq: 0.034847
[16:37:16.282] iteration 25936: loss: 0.036371, loss_s1: 0.013727, loss_fp: 0.001310, loss_freq: 0.018211
[16:37:16.896] iteration 25937: loss: 0.072434, loss_s1: 0.041173, loss_fp: 0.001603, loss_freq: 0.068226
[16:37:17.519] iteration 25938: loss: 0.043140, loss_s1: 0.030602, loss_fp: 0.001213, loss_freq: 0.014123
[16:37:18.135] iteration 25939: loss: 0.040595, loss_s1: 0.019045, loss_fp: 0.002363, loss_freq: 0.008476
[16:37:18.752] iteration 25940: loss: 0.046141, loss_s1: 0.041741, loss_fp: 0.003736, loss_freq: 0.008005
[16:37:19.369] iteration 25941: loss: 0.034232, loss_s1: 0.019299, loss_fp: 0.005416, loss_freq: 0.012719
[16:37:19.991] iteration 25942: loss: 0.062345, loss_s1: 0.048624, loss_fp: 0.007073, loss_freq: 0.027980
[16:37:20.608] iteration 25943: loss: 0.047459, loss_s1: 0.041574, loss_fp: 0.001174, loss_freq: 0.014234
[16:37:21.216] iteration 25944: loss: 0.046826, loss_s1: 0.027111, loss_fp: 0.002662, loss_freq: 0.028519
[16:37:21.831] iteration 25945: loss: 0.068786, loss_s1: 0.044963, loss_fp: 0.006734, loss_freq: 0.025933
[16:37:22.455] iteration 25946: loss: 0.072742, loss_s1: 0.067146, loss_fp: 0.007513, loss_freq: 0.040375
[16:37:23.064] iteration 25947: loss: 0.039353, loss_s1: 0.021092, loss_fp: 0.001264, loss_freq: 0.013282
[16:37:23.684] iteration 25948: loss: 0.083856, loss_s1: 0.053594, loss_fp: 0.006932, loss_freq: 0.051773
[16:37:24.298] iteration 25949: loss: 0.041454, loss_s1: 0.023449, loss_fp: 0.001244, loss_freq: 0.014832
[16:37:24.914] iteration 25950: loss: 0.072211, loss_s1: 0.063244, loss_fp: 0.017248, loss_freq: 0.028590
[16:37:25.534] iteration 25951: loss: 0.046875, loss_s1: 0.041803, loss_fp: 0.001580, loss_freq: 0.023613
[16:37:26.155] iteration 25952: loss: 0.051368, loss_s1: 0.054778, loss_fp: 0.005200, loss_freq: 0.010834
[16:37:26.770] iteration 25953: loss: 0.049949, loss_s1: 0.038544, loss_fp: 0.000440, loss_freq: 0.016766
[16:37:27.391] iteration 25954: loss: 0.053178, loss_s1: 0.044434, loss_fp: 0.001230, loss_freq: 0.023818
[16:37:28.004] iteration 25955: loss: 0.055551, loss_s1: 0.047529, loss_fp: 0.006415, loss_freq: 0.025288
[16:37:28.627] iteration 25956: loss: 0.032506, loss_s1: 0.014536, loss_fp: 0.008562, loss_freq: 0.009163
[16:37:29.250] iteration 25957: loss: 0.074123, loss_s1: 0.066078, loss_fp: 0.003104, loss_freq: 0.035242
[16:37:29.881] iteration 25958: loss: 0.058126, loss_s1: 0.028241, loss_fp: 0.002488, loss_freq: 0.058064
[16:37:30.504] iteration 25959: loss: 0.042392, loss_s1: 0.040426, loss_fp: 0.002697, loss_freq: 0.008908
[16:37:31.125] iteration 25960: loss: 0.048257, loss_s1: 0.052282, loss_fp: 0.002407, loss_freq: 0.015224
[16:37:31.748] iteration 25961: loss: 0.042697, loss_s1: 0.015667, loss_fp: 0.001388, loss_freq: 0.028443
[16:37:32.364] iteration 25962: loss: 0.086296, loss_s1: 0.078379, loss_fp: 0.028742, loss_freq: 0.029644
[16:37:33.021] iteration 25963: loss: 0.072075, loss_s1: 0.043981, loss_fp: 0.008652, loss_freq: 0.019027
[16:37:33.645] iteration 25964: loss: 0.046355, loss_s1: 0.034869, loss_fp: 0.004914, loss_freq: 0.015107
[16:37:34.270] iteration 25965: loss: 0.044855, loss_s1: 0.030105, loss_fp: 0.004876, loss_freq: 0.019231
[16:37:34.896] iteration 25966: loss: 0.043330, loss_s1: 0.024109, loss_fp: 0.003863, loss_freq: 0.020020
[16:37:35.513] iteration 25967: loss: 0.050380, loss_s1: 0.051485, loss_fp: 0.004809, loss_freq: 0.014119
[16:37:36.126] iteration 25968: loss: 0.049678, loss_s1: 0.029473, loss_fp: 0.006282, loss_freq: 0.026557
[16:37:36.745] iteration 25969: loss: 0.049735, loss_s1: 0.028644, loss_fp: 0.002221, loss_freq: 0.035836
[16:37:37.366] iteration 25970: loss: 0.044025, loss_s1: 0.027450, loss_fp: 0.006060, loss_freq: 0.004423
[16:37:37.991] iteration 25971: loss: 0.027582, loss_s1: 0.005781, loss_fp: 0.000932, loss_freq: 0.011744
[16:37:38.616] iteration 25972: loss: 0.042721, loss_s1: 0.038856, loss_fp: 0.001473, loss_freq: 0.007551
[16:37:39.236] iteration 25973: loss: 0.043504, loss_s1: 0.036757, loss_fp: 0.002661, loss_freq: 0.007213
[16:37:39.877] iteration 25974: loss: 0.051030, loss_s1: 0.018256, loss_fp: 0.001285, loss_freq: 0.029793
[16:37:40.502] iteration 25975: loss: 0.070560, loss_s1: 0.056698, loss_fp: 0.010877, loss_freq: 0.042770
[16:37:41.129] iteration 25976: loss: 0.047888, loss_s1: 0.025352, loss_fp: 0.001023, loss_freq: 0.025180
[16:37:41.806] iteration 25977: loss: 0.042526, loss_s1: 0.036357, loss_fp: 0.003394, loss_freq: 0.010348
[16:37:42.443] iteration 25978: loss: 0.029544, loss_s1: 0.015315, loss_fp: 0.002096, loss_freq: 0.009204
[16:37:43.118] iteration 25979: loss: 0.031793, loss_s1: 0.020083, loss_fp: 0.002122, loss_freq: 0.004016
[16:37:43.752] iteration 25980: loss: 0.062234, loss_s1: 0.037840, loss_fp: 0.012029, loss_freq: 0.034435
[16:37:44.387] iteration 25981: loss: 0.051368, loss_s1: 0.048847, loss_fp: 0.002730, loss_freq: 0.016226
[16:37:45.020] iteration 25982: loss: 0.056535, loss_s1: 0.037235, loss_fp: 0.002261, loss_freq: 0.028189
[16:37:45.639] iteration 25983: loss: 0.054810, loss_s1: 0.045942, loss_fp: 0.005385, loss_freq: 0.017404
[16:37:46.258] iteration 25984: loss: 0.051813, loss_s1: 0.031487, loss_fp: 0.005029, loss_freq: 0.012619
[16:37:46.874] iteration 25985: loss: 0.054130, loss_s1: 0.030339, loss_fp: 0.003578, loss_freq: 0.025620
[16:37:47.494] iteration 25986: loss: 0.047982, loss_s1: 0.023612, loss_fp: 0.019157, loss_freq: 0.024644
[16:37:48.112] iteration 25987: loss: 0.042119, loss_s1: 0.041025, loss_fp: 0.002595, loss_freq: 0.009775
[16:37:48.732] iteration 25988: loss: 0.079001, loss_s1: 0.063501, loss_fp: 0.007595, loss_freq: 0.027770
[16:37:49.349] iteration 25989: loss: 0.053641, loss_s1: 0.030322, loss_fp: 0.000947, loss_freq: 0.024926
[16:37:49.971] iteration 25990: loss: 0.066477, loss_s1: 0.042130, loss_fp: 0.002528, loss_freq: 0.040704
[16:37:50.652] iteration 25991: loss: 0.056761, loss_s1: 0.031574, loss_fp: 0.003454, loss_freq: 0.048747
[16:37:51.316] iteration 25992: loss: 0.038508, loss_s1: 0.014999, loss_fp: 0.001842, loss_freq: 0.015843
[16:37:51.995] iteration 25993: loss: 0.074801, loss_s1: 0.062636, loss_fp: 0.005334, loss_freq: 0.053941
[16:37:52.646] iteration 25994: loss: 0.047190, loss_s1: 0.024655, loss_fp: 0.008760, loss_freq: 0.031086
[16:37:53.313] iteration 25995: loss: 0.040591, loss_s1: 0.028757, loss_fp: 0.001467, loss_freq: 0.021017
[16:37:53.931] iteration 25996: loss: 0.048387, loss_s1: 0.028444, loss_fp: 0.002006, loss_freq: 0.021305
[16:37:54.552] iteration 25997: loss: 0.067748, loss_s1: 0.056850, loss_fp: 0.008851, loss_freq: 0.035664
[16:37:55.176] iteration 25998: loss: 0.050377, loss_s1: 0.039939, loss_fp: 0.001729, loss_freq: 0.007460
[16:37:55.797] iteration 25999: loss: 0.040180, loss_s1: 0.038811, loss_fp: 0.002790, loss_freq: 0.006997
[16:37:56.418] iteration 26000: loss: 0.049747, loss_s1: 0.028055, loss_fp: 0.005219, loss_freq: 0.022019
[16:37:59.938] iteration 26000 : mean_dice : 0.799677
[16:38:00.606] iteration 26001: loss: 0.050933, loss_s1: 0.043290, loss_fp: 0.001771, loss_freq: 0.021751
[16:38:01.231] iteration 26002: loss: 0.037357, loss_s1: 0.029829, loss_fp: 0.002703, loss_freq: 0.010308
[16:38:01.857] iteration 26003: loss: 0.058746, loss_s1: 0.044137, loss_fp: 0.001770, loss_freq: 0.035872
[16:38:02.484] iteration 26004: loss: 0.065420, loss_s1: 0.065420, loss_fp: 0.005032, loss_freq: 0.016736
[16:38:03.107] iteration 26005: loss: 0.054673, loss_s1: 0.030300, loss_fp: 0.002938, loss_freq: 0.026854
[16:38:03.731] iteration 26006: loss: 0.039693, loss_s1: 0.036084, loss_fp: 0.002257, loss_freq: 0.008924
[16:38:04.351] iteration 26007: loss: 0.054702, loss_s1: 0.022919, loss_fp: 0.010496, loss_freq: 0.020462
[16:38:04.983] iteration 26008: loss: 0.063548, loss_s1: 0.056486, loss_fp: 0.011200, loss_freq: 0.030411
[16:38:05.606] iteration 26009: loss: 0.036917, loss_s1: 0.017935, loss_fp: 0.000897, loss_freq: 0.016205
[16:38:06.234] iteration 26010: loss: 0.054455, loss_s1: 0.043914, loss_fp: 0.001523, loss_freq: 0.024266
[16:38:06.852] iteration 26011: loss: 0.042964, loss_s1: 0.018272, loss_fp: 0.003060, loss_freq: 0.021941
[16:38:07.523] iteration 26012: loss: 0.057931, loss_s1: 0.022930, loss_fp: 0.002594, loss_freq: 0.009910
[16:38:08.146] iteration 26013: loss: 0.044043, loss_s1: 0.023340, loss_fp: 0.006810, loss_freq: 0.021885
[16:38:08.767] iteration 26014: loss: 0.062257, loss_s1: 0.054262, loss_fp: 0.003094, loss_freq: 0.015815
[16:38:09.383] iteration 26015: loss: 0.050044, loss_s1: 0.024516, loss_fp: 0.003317, loss_freq: 0.029852
[16:38:10.003] iteration 26016: loss: 0.054257, loss_s1: 0.037297, loss_fp: 0.008154, loss_freq: 0.014686
[16:38:10.620] iteration 26017: loss: 0.063849, loss_s1: 0.027868, loss_fp: 0.000758, loss_freq: 0.037153
[16:38:11.244] iteration 26018: loss: 0.046070, loss_s1: 0.023557, loss_fp: 0.003878, loss_freq: 0.011086
[16:38:11.865] iteration 26019: loss: 0.065297, loss_s1: 0.047062, loss_fp: 0.014148, loss_freq: 0.038850
[16:38:12.491] iteration 26020: loss: 0.077794, loss_s1: 0.059228, loss_fp: 0.012137, loss_freq: 0.038775
[16:38:13.123] iteration 26021: loss: 0.037641, loss_s1: 0.029226, loss_fp: 0.000580, loss_freq: 0.011721
[16:38:13.739] iteration 26022: loss: 0.056706, loss_s1: 0.055034, loss_fp: 0.003027, loss_freq: 0.020609
[16:38:14.359] iteration 26023: loss: 0.056488, loss_s1: 0.024468, loss_fp: 0.004452, loss_freq: 0.018552
[16:38:14.988] iteration 26024: loss: 0.058956, loss_s1: 0.029645, loss_fp: 0.005299, loss_freq: 0.027954
[16:38:15.605] iteration 26025: loss: 0.095403, loss_s1: 0.105627, loss_fp: 0.005826, loss_freq: 0.040052
[16:38:16.224] iteration 26026: loss: 0.053325, loss_s1: 0.044704, loss_fp: 0.002989, loss_freq: 0.027953
[16:38:17.203] iteration 26027: loss: 0.033536, loss_s1: 0.019153, loss_fp: 0.002913, loss_freq: 0.010534
[16:38:17.846] iteration 26028: loss: 0.048701, loss_s1: 0.029783, loss_fp: 0.010714, loss_freq: 0.016296
[16:38:18.481] iteration 26029: loss: 0.036289, loss_s1: 0.021189, loss_fp: 0.002895, loss_freq: 0.018692
[16:38:19.095] iteration 26030: loss: 0.054534, loss_s1: 0.035489, loss_fp: 0.003283, loss_freq: 0.021009
[16:38:19.786] iteration 26031: loss: 0.074317, loss_s1: 0.076990, loss_fp: 0.002950, loss_freq: 0.025778
[16:38:20.415] iteration 26032: loss: 0.046707, loss_s1: 0.018854, loss_fp: 0.009372, loss_freq: 0.021574
[16:38:21.039] iteration 26033: loss: 0.035165, loss_s1: 0.024171, loss_fp: 0.001788, loss_freq: 0.007979
[16:38:21.663] iteration 26034: loss: 0.078569, loss_s1: 0.037811, loss_fp: 0.006359, loss_freq: 0.063012
[16:38:22.289] iteration 26035: loss: 0.036159, loss_s1: 0.016191, loss_fp: 0.003552, loss_freq: 0.018266
[16:38:22.912] iteration 26036: loss: 0.051103, loss_s1: 0.038474, loss_fp: 0.000995, loss_freq: 0.005058
[16:38:23.526] iteration 26037: loss: 0.037377, loss_s1: 0.018557, loss_fp: 0.002834, loss_freq: 0.015442
[16:38:24.141] iteration 26038: loss: 0.038278, loss_s1: 0.017285, loss_fp: 0.008917, loss_freq: 0.013344
[16:38:24.756] iteration 26039: loss: 0.056405, loss_s1: 0.055408, loss_fp: 0.003846, loss_freq: 0.019190
[16:38:25.380] iteration 26040: loss: 0.043831, loss_s1: 0.030217, loss_fp: 0.000491, loss_freq: 0.018266
[16:38:26.003] iteration 26041: loss: 0.063099, loss_s1: 0.057504, loss_fp: 0.001882, loss_freq: 0.018120
[16:38:26.629] iteration 26042: loss: 0.052454, loss_s1: 0.032411, loss_fp: 0.003267, loss_freq: 0.032617
[16:38:27.257] iteration 26043: loss: 0.043197, loss_s1: 0.028646, loss_fp: 0.000699, loss_freq: 0.017665
[16:38:27.876] iteration 26044: loss: 0.053315, loss_s1: 0.039840, loss_fp: 0.008842, loss_freq: 0.022256
[16:38:28.499] iteration 26045: loss: 0.039475, loss_s1: 0.026003, loss_fp: 0.002622, loss_freq: 0.020169
[16:38:29.120] iteration 26046: loss: 0.036777, loss_s1: 0.017050, loss_fp: 0.004354, loss_freq: 0.012560
[16:38:29.734] iteration 26047: loss: 0.065442, loss_s1: 0.028203, loss_fp: 0.002949, loss_freq: 0.059834
[16:38:30.350] iteration 26048: loss: 0.038307, loss_s1: 0.020528, loss_fp: 0.001314, loss_freq: 0.029572
[16:38:31.006] iteration 26049: loss: 0.047711, loss_s1: 0.035629, loss_fp: 0.006159, loss_freq: 0.018390
[16:38:31.631] iteration 26050: loss: 0.030578, loss_s1: 0.017482, loss_fp: 0.002332, loss_freq: 0.004805
[16:38:32.251] iteration 26051: loss: 0.041598, loss_s1: 0.025104, loss_fp: 0.000963, loss_freq: 0.020482
[16:38:32.883] iteration 26052: loss: 0.074038, loss_s1: 0.042025, loss_fp: 0.007159, loss_freq: 0.059823
[16:38:33.509] iteration 26053: loss: 0.074983, loss_s1: 0.054363, loss_fp: 0.003825, loss_freq: 0.049368
[16:38:34.149] iteration 26054: loss: 0.037295, loss_s1: 0.022846, loss_fp: 0.001395, loss_freq: 0.009313
[16:38:34.770] iteration 26055: loss: 0.038515, loss_s1: 0.013463, loss_fp: 0.002173, loss_freq: 0.016281
[16:38:35.406] iteration 26056: loss: 0.034656, loss_s1: 0.021170, loss_fp: 0.000909, loss_freq: 0.007529
[16:38:36.038] iteration 26057: loss: 0.045680, loss_s1: 0.021955, loss_fp: 0.002145, loss_freq: 0.024947
[16:38:36.660] iteration 26058: loss: 0.055073, loss_s1: 0.041383, loss_fp: 0.006771, loss_freq: 0.019230
[16:38:37.281] iteration 26059: loss: 0.069184, loss_s1: 0.047010, loss_fp: 0.010121, loss_freq: 0.047216
[16:38:37.896] iteration 26060: loss: 0.083288, loss_s1: 0.055243, loss_fp: 0.009066, loss_freq: 0.062964
[16:38:38.515] iteration 26061: loss: 0.051339, loss_s1: 0.019912, loss_fp: 0.007109, loss_freq: 0.027127
[16:38:39.135] iteration 26062: loss: 0.046617, loss_s1: 0.044891, loss_fp: 0.001298, loss_freq: 0.014016
[16:38:39.759] iteration 26063: loss: 0.052499, loss_s1: 0.035897, loss_fp: 0.002250, loss_freq: 0.018160
[16:38:40.385] iteration 26064: loss: 0.053384, loss_s1: 0.036304, loss_fp: 0.001313, loss_freq: 0.033161
[16:38:41.023] iteration 26065: loss: 0.074925, loss_s1: 0.082192, loss_fp: 0.001391, loss_freq: 0.024496
[16:38:41.643] iteration 26066: loss: 0.048306, loss_s1: 0.040354, loss_fp: 0.006421, loss_freq: 0.016196
[16:38:42.272] iteration 26067: loss: 0.065403, loss_s1: 0.038479, loss_fp: 0.002546, loss_freq: 0.041192
[16:38:42.900] iteration 26068: loss: 0.043009, loss_s1: 0.021152, loss_fp: 0.007406, loss_freq: 0.027402
[16:38:43.523] iteration 26069: loss: 0.036639, loss_s1: 0.015998, loss_fp: 0.001433, loss_freq: 0.006840
[16:38:44.141] iteration 26070: loss: 0.043376, loss_s1: 0.037723, loss_fp: 0.002338, loss_freq: 0.011895
[16:38:44.764] iteration 26071: loss: 0.053067, loss_s1: 0.042428, loss_fp: 0.000731, loss_freq: 0.004665
[16:38:45.391] iteration 26072: loss: 0.099292, loss_s1: 0.117791, loss_fp: 0.002632, loss_freq: 0.046584
[16:38:46.010] iteration 26073: loss: 0.040717, loss_s1: 0.018845, loss_fp: 0.001314, loss_freq: 0.019668
[16:38:46.625] iteration 26074: loss: 0.067309, loss_s1: 0.061589, loss_fp: 0.002555, loss_freq: 0.016551
[16:38:47.279] iteration 26075: loss: 0.038885, loss_s1: 0.030255, loss_fp: 0.004130, loss_freq: 0.014008
[16:38:47.899] iteration 26076: loss: 0.049772, loss_s1: 0.032625, loss_fp: 0.000797, loss_freq: 0.025333
[16:38:48.520] iteration 26077: loss: 0.049193, loss_s1: 0.022600, loss_fp: 0.003800, loss_freq: 0.021836
[16:38:49.151] iteration 26078: loss: 0.075186, loss_s1: 0.087240, loss_fp: 0.002280, loss_freq: 0.022817
[16:38:49.785] iteration 26079: loss: 0.035428, loss_s1: 0.015005, loss_fp: 0.001403, loss_freq: 0.013921
[16:38:50.409] iteration 26080: loss: 0.061085, loss_s1: 0.036979, loss_fp: 0.006170, loss_freq: 0.041851
[16:38:51.061] iteration 26081: loss: 0.044139, loss_s1: 0.029351, loss_fp: 0.002070, loss_freq: 0.007021
[16:38:51.692] iteration 26082: loss: 0.028686, loss_s1: 0.009103, loss_fp: 0.000958, loss_freq: 0.005436
[16:38:52.332] iteration 26083: loss: 0.071658, loss_s1: 0.055990, loss_fp: 0.004147, loss_freq: 0.044521
[16:38:52.971] iteration 26084: loss: 0.043692, loss_s1: 0.023226, loss_fp: 0.000909, loss_freq: 0.021251
[16:38:53.606] iteration 26085: loss: 0.048738, loss_s1: 0.023927, loss_fp: 0.003779, loss_freq: 0.038753
[16:38:54.237] iteration 26086: loss: 0.060268, loss_s1: 0.062924, loss_fp: 0.003215, loss_freq: 0.019527
[16:38:54.858] iteration 26087: loss: 0.049776, loss_s1: 0.034522, loss_fp: 0.003176, loss_freq: 0.020140
[16:38:55.478] iteration 26088: loss: 0.047474, loss_s1: 0.030123, loss_fp: 0.002018, loss_freq: 0.022646
[16:38:56.102] iteration 26089: loss: 0.052549, loss_s1: 0.028122, loss_fp: 0.007389, loss_freq: 0.031429
[16:38:56.728] iteration 26090: loss: 0.043333, loss_s1: 0.025804, loss_fp: 0.003989, loss_freq: 0.012576
[16:38:57.352] iteration 26091: loss: 0.097726, loss_s1: 0.092262, loss_fp: 0.020070, loss_freq: 0.043123
[16:38:57.980] iteration 26092: loss: 0.041539, loss_s1: 0.029512, loss_fp: 0.002766, loss_freq: 0.017174
[16:38:58.601] iteration 26093: loss: 0.106675, loss_s1: 0.063398, loss_fp: 0.008411, loss_freq: 0.069718
[16:38:59.304] iteration 26094: loss: 0.062226, loss_s1: 0.033101, loss_fp: 0.001815, loss_freq: 0.028203
[16:38:59.967] iteration 26095: loss: 0.047774, loss_s1: 0.033255, loss_fp: 0.000617, loss_freq: 0.022129
[16:39:00.592] iteration 26096: loss: 0.055597, loss_s1: 0.030659, loss_fp: 0.009665, loss_freq: 0.011980
[16:39:01.204] iteration 26097: loss: 0.056518, loss_s1: 0.033537, loss_fp: 0.006177, loss_freq: 0.032074
[16:39:01.825] iteration 26098: loss: 0.056220, loss_s1: 0.025978, loss_fp: 0.003546, loss_freq: 0.039220
[16:39:02.443] iteration 26099: loss: 0.068813, loss_s1: 0.034014, loss_fp: 0.002423, loss_freq: 0.071124
[16:39:03.113] iteration 26100: loss: 0.114094, loss_s1: 0.117245, loss_fp: 0.005333, loss_freq: 0.056504
[16:39:03.746] iteration 26101: loss: 0.068665, loss_s1: 0.054404, loss_fp: 0.005804, loss_freq: 0.045005
[16:39:04.392] iteration 26102: loss: 0.056788, loss_s1: 0.068209, loss_fp: 0.001423, loss_freq: 0.007584
[16:39:05.037] iteration 26103: loss: 0.069024, loss_s1: 0.058052, loss_fp: 0.010286, loss_freq: 0.039379
[16:39:05.679] iteration 26104: loss: 0.071125, loss_s1: 0.053562, loss_fp: 0.003373, loss_freq: 0.034312
[16:39:06.312] iteration 26105: loss: 0.062126, loss_s1: 0.065077, loss_fp: 0.007168, loss_freq: 0.017081
[16:39:06.928] iteration 26106: loss: 0.072582, loss_s1: 0.079205, loss_fp: 0.005708, loss_freq: 0.015388
[16:39:07.547] iteration 26107: loss: 0.100232, loss_s1: 0.076388, loss_fp: 0.008210, loss_freq: 0.026954
[16:39:08.164] iteration 26108: loss: 0.072132, loss_s1: 0.059021, loss_fp: 0.008615, loss_freq: 0.039316
[16:39:08.782] iteration 26109: loss: 0.050063, loss_s1: 0.047440, loss_fp: 0.000731, loss_freq: 0.017538
[16:39:09.404] iteration 26110: loss: 0.043287, loss_s1: 0.035385, loss_fp: 0.003438, loss_freq: 0.012761
[16:39:10.041] iteration 26111: loss: 0.050648, loss_s1: 0.036762, loss_fp: 0.002917, loss_freq: 0.015371
[16:39:10.687] iteration 26112: loss: 0.070350, loss_s1: 0.034240, loss_fp: 0.011940, loss_freq: 0.047884
[16:39:11.329] iteration 26113: loss: 0.039384, loss_s1: 0.028731, loss_fp: 0.002125, loss_freq: 0.009252
[16:39:11.967] iteration 26114: loss: 0.038246, loss_s1: 0.034763, loss_fp: 0.001142, loss_freq: 0.010682
[16:39:12.612] iteration 26115: loss: 0.046281, loss_s1: 0.036412, loss_fp: 0.002290, loss_freq: 0.027023
[16:39:13.241] iteration 26116: loss: 0.053744, loss_s1: 0.066208, loss_fp: 0.001096, loss_freq: 0.015091
[16:39:13.864] iteration 26117: loss: 0.047630, loss_s1: 0.025942, loss_fp: 0.003884, loss_freq: 0.019331
[16:39:14.485] iteration 26118: loss: 0.048520, loss_s1: 0.035216, loss_fp: 0.002131, loss_freq: 0.030637
[16:39:15.120] iteration 26119: loss: 0.052798, loss_s1: 0.062102, loss_fp: 0.006694, loss_freq: 0.004686
[16:39:15.748] iteration 26120: loss: 0.054066, loss_s1: 0.046280, loss_fp: 0.002500, loss_freq: 0.010129
[16:39:16.378] iteration 26121: loss: 0.039450, loss_s1: 0.024722, loss_fp: 0.000669, loss_freq: 0.008240
[16:39:17.022] iteration 26122: loss: 0.034665, loss_s1: 0.021164, loss_fp: 0.009408, loss_freq: 0.003978
[16:39:17.635] iteration 26123: loss: 0.067985, loss_s1: 0.043556, loss_fp: 0.003945, loss_freq: 0.035722
[16:39:18.256] iteration 26124: loss: 0.041181, loss_s1: 0.014481, loss_fp: 0.003921, loss_freq: 0.030360
[16:39:18.872] iteration 26125: loss: 0.044660, loss_s1: 0.018569, loss_fp: 0.002602, loss_freq: 0.017101
[16:39:19.492] iteration 26126: loss: 0.094443, loss_s1: 0.030098, loss_fp: 0.010625, loss_freq: 0.037430
[16:39:20.110] iteration 26127: loss: 0.047702, loss_s1: 0.037394, loss_fp: 0.001859, loss_freq: 0.010410
[16:39:20.721] iteration 26128: loss: 0.078679, loss_s1: 0.046225, loss_fp: 0.005667, loss_freq: 0.034037
[16:39:21.343] iteration 26129: loss: 0.078713, loss_s1: 0.067776, loss_fp: 0.007171, loss_freq: 0.055195
[16:39:21.964] iteration 26130: loss: 0.050133, loss_s1: 0.036969, loss_fp: 0.015680, loss_freq: 0.015615
[16:39:22.604] iteration 26131: loss: 0.033173, loss_s1: 0.010108, loss_fp: 0.002706, loss_freq: 0.009605
[16:39:23.244] iteration 26132: loss: 0.041469, loss_s1: 0.022449, loss_fp: 0.004715, loss_freq: 0.021266
[16:39:23.876] iteration 26133: loss: 0.079590, loss_s1: 0.075825, loss_fp: 0.007119, loss_freq: 0.036325
[16:39:24.512] iteration 26134: loss: 0.038706, loss_s1: 0.016277, loss_fp: 0.003646, loss_freq: 0.027751
[16:39:25.153] iteration 26135: loss: 0.066040, loss_s1: 0.035088, loss_fp: 0.012780, loss_freq: 0.040995
[16:39:25.788] iteration 26136: loss: 0.081846, loss_s1: 0.076292, loss_fp: 0.010482, loss_freq: 0.044307
[16:39:26.408] iteration 26137: loss: 0.047746, loss_s1: 0.046429, loss_fp: 0.002482, loss_freq: 0.007097
[16:39:27.034] iteration 26138: loss: 0.041395, loss_s1: 0.029872, loss_fp: 0.002575, loss_freq: 0.021844
[16:39:27.652] iteration 26139: loss: 0.048486, loss_s1: 0.032089, loss_fp: 0.000582, loss_freq: 0.006328
[16:39:28.268] iteration 26140: loss: 0.097412, loss_s1: 0.074003, loss_fp: 0.016708, loss_freq: 0.073284
[16:39:28.884] iteration 26141: loss: 0.054091, loss_s1: 0.032261, loss_fp: 0.002358, loss_freq: 0.007286
[16:39:29.556] iteration 26142: loss: 0.057415, loss_s1: 0.067465, loss_fp: 0.002818, loss_freq: 0.013711
[16:39:30.183] iteration 26143: loss: 0.076418, loss_s1: 0.067149, loss_fp: 0.002557, loss_freq: 0.023181
[16:39:30.797] iteration 26144: loss: 0.074815, loss_s1: 0.071995, loss_fp: 0.002645, loss_freq: 0.027667
[16:39:31.420] iteration 26145: loss: 0.058205, loss_s1: 0.059924, loss_fp: 0.003996, loss_freq: 0.020777
[16:39:32.035] iteration 26146: loss: 0.066198, loss_s1: 0.071970, loss_fp: 0.003067, loss_freq: 0.017795
[16:39:32.687] iteration 26147: loss: 0.044721, loss_s1: 0.023096, loss_fp: 0.003085, loss_freq: 0.025994
[16:39:33.298] iteration 26148: loss: 0.066510, loss_s1: 0.046146, loss_fp: 0.003448, loss_freq: 0.045734
[16:39:33.916] iteration 26149: loss: 0.028183, loss_s1: 0.015066, loss_fp: 0.002775, loss_freq: 0.006226
[16:39:34.539] iteration 26150: loss: 0.040090, loss_s1: 0.021098, loss_fp: 0.002755, loss_freq: 0.013810
[16:39:35.163] iteration 26151: loss: 0.054676, loss_s1: 0.046542, loss_fp: 0.006670, loss_freq: 0.025309
[16:39:35.781] iteration 26152: loss: 0.057026, loss_s1: 0.040738, loss_fp: 0.003504, loss_freq: 0.006905
[16:39:36.404] iteration 26153: loss: 0.035693, loss_s1: 0.015970, loss_fp: 0.001233, loss_freq: 0.027967
[16:39:37.020] iteration 26154: loss: 0.047783, loss_s1: 0.031599, loss_fp: 0.002925, loss_freq: 0.028089
[16:39:37.646] iteration 26155: loss: 0.058052, loss_s1: 0.035395, loss_fp: 0.004540, loss_freq: 0.007272
[16:39:38.266] iteration 26156: loss: 0.044205, loss_s1: 0.029957, loss_fp: 0.003771, loss_freq: 0.013268
[16:39:38.886] iteration 26157: loss: 0.063050, loss_s1: 0.064502, loss_fp: 0.005487, loss_freq: 0.015284
[16:39:39.533] iteration 26158: loss: 0.076851, loss_s1: 0.046739, loss_fp: 0.009484, loss_freq: 0.049440
[16:39:40.162] iteration 26159: loss: 0.053273, loss_s1: 0.024213, loss_fp: 0.002880, loss_freq: 0.034566
[16:39:40.823] iteration 26160: loss: 0.060824, loss_s1: 0.033733, loss_fp: 0.003517, loss_freq: 0.047595
[16:39:41.456] iteration 26161: loss: 0.050121, loss_s1: 0.021067, loss_fp: 0.007621, loss_freq: 0.018315
[16:39:42.130] iteration 26162: loss: 0.045412, loss_s1: 0.030229, loss_fp: 0.001277, loss_freq: 0.025733
[16:39:42.769] iteration 26163: loss: 0.081090, loss_s1: 0.076011, loss_fp: 0.003657, loss_freq: 0.038489
[16:39:43.430] iteration 26164: loss: 0.027555, loss_s1: 0.007492, loss_fp: 0.003518, loss_freq: 0.014033
[16:39:44.086] iteration 26165: loss: 0.074796, loss_s1: 0.083919, loss_fp: 0.001811, loss_freq: 0.033178
[16:39:44.721] iteration 26166: loss: 0.046978, loss_s1: 0.029824, loss_fp: 0.002516, loss_freq: 0.017343
[16:39:45.370] iteration 26167: loss: 0.065183, loss_s1: 0.033948, loss_fp: 0.010971, loss_freq: 0.041453
[16:39:45.989] iteration 26168: loss: 0.072872, loss_s1: 0.081279, loss_fp: 0.004529, loss_freq: 0.016678
[16:39:46.608] iteration 26169: loss: 0.037921, loss_s1: 0.017211, loss_fp: 0.001057, loss_freq: 0.025597
[16:39:47.581] iteration 26170: loss: 0.068440, loss_s1: 0.075555, loss_fp: 0.001927, loss_freq: 0.014798
[16:39:48.227] iteration 26171: loss: 0.036229, loss_s1: 0.020770, loss_fp: 0.006663, loss_freq: 0.010534
[16:39:48.903] iteration 26172: loss: 0.028647, loss_s1: 0.015473, loss_fp: 0.003385, loss_freq: 0.008798
[16:39:49.560] iteration 26173: loss: 0.053048, loss_s1: 0.044345, loss_fp: 0.003595, loss_freq: 0.018452
[16:39:50.218] iteration 26174: loss: 0.051020, loss_s1: 0.028729, loss_fp: 0.004344, loss_freq: 0.038151
[16:39:50.868] iteration 26175: loss: 0.052076, loss_s1: 0.035843, loss_fp: 0.002482, loss_freq: 0.006554
[16:39:51.513] iteration 26176: loss: 0.035695, loss_s1: 0.016133, loss_fp: 0.000943, loss_freq: 0.027221
[16:39:52.139] iteration 26177: loss: 0.064936, loss_s1: 0.025029, loss_fp: 0.006820, loss_freq: 0.018663
[16:39:52.756] iteration 26178: loss: 0.045705, loss_s1: 0.019556, loss_fp: 0.005376, loss_freq: 0.027243
[16:39:53.376] iteration 26179: loss: 0.041832, loss_s1: 0.012207, loss_fp: 0.000683, loss_freq: 0.004159
[16:39:53.999] iteration 26180: loss: 0.050208, loss_s1: 0.055102, loss_fp: 0.002972, loss_freq: 0.008127
[16:39:54.627] iteration 26181: loss: 0.042742, loss_s1: 0.020686, loss_fp: 0.002728, loss_freq: 0.015507
[16:39:55.246] iteration 26182: loss: 0.041624, loss_s1: 0.030106, loss_fp: 0.002673, loss_freq: 0.012472
[16:39:55.864] iteration 26183: loss: 0.026643, loss_s1: 0.011847, loss_fp: 0.000897, loss_freq: 0.011302
[16:39:56.483] iteration 26184: loss: 0.044772, loss_s1: 0.032398, loss_fp: 0.000827, loss_freq: 0.015782
[16:39:57.099] iteration 26185: loss: 0.044164, loss_s1: 0.017386, loss_fp: 0.003052, loss_freq: 0.026053
[16:39:57.718] iteration 26186: loss: 0.096865, loss_s1: 0.033127, loss_fp: 0.003737, loss_freq: 0.040975
[16:39:58.332] iteration 26187: loss: 0.053537, loss_s1: 0.054023, loss_fp: 0.003617, loss_freq: 0.014597
[16:39:58.946] iteration 26188: loss: 0.033343, loss_s1: 0.011017, loss_fp: 0.001357, loss_freq: 0.019765
[16:39:59.564] iteration 26189: loss: 0.054483, loss_s1: 0.065999, loss_fp: 0.005578, loss_freq: 0.008265
[16:40:00.179] iteration 26190: loss: 0.088379, loss_s1: 0.051083, loss_fp: 0.005199, loss_freq: 0.049274
[16:40:00.813] iteration 26191: loss: 0.060693, loss_s1: 0.042457, loss_fp: 0.001402, loss_freq: 0.046154
[16:40:01.444] iteration 26192: loss: 0.047115, loss_s1: 0.017069, loss_fp: 0.004669, loss_freq: 0.028839
[16:40:02.082] iteration 26193: loss: 0.043978, loss_s1: 0.048722, loss_fp: 0.001121, loss_freq: 0.008931
[16:40:02.710] iteration 26194: loss: 0.045962, loss_s1: 0.037008, loss_fp: 0.000992, loss_freq: 0.016040
[16:40:03.345] iteration 26195: loss: 0.061222, loss_s1: 0.044472, loss_fp: 0.002665, loss_freq: 0.029212
[16:40:03.962] iteration 26196: loss: 0.050615, loss_s1: 0.027838, loss_fp: 0.007968, loss_freq: 0.024915
[16:40:04.576] iteration 26197: loss: 0.068074, loss_s1: 0.083075, loss_fp: 0.002302, loss_freq: 0.017934
[16:40:05.200] iteration 26198: loss: 0.058901, loss_s1: 0.049115, loss_fp: 0.001008, loss_freq: 0.018755
[16:40:05.824] iteration 26199: loss: 0.036295, loss_s1: 0.017837, loss_fp: 0.002943, loss_freq: 0.008360
[16:40:06.456] iteration 26200: loss: 0.041641, loss_s1: 0.033749, loss_fp: 0.002459, loss_freq: 0.013946
[16:40:09.672] iteration 26200 : mean_dice : 0.798334
[16:40:10.320] iteration 26201: loss: 0.039770, loss_s1: 0.019133, loss_fp: 0.005236, loss_freq: 0.019029
[16:40:10.941] iteration 26202: loss: 0.071251, loss_s1: 0.053261, loss_fp: 0.005016, loss_freq: 0.056101
[16:40:11.565] iteration 26203: loss: 0.105532, loss_s1: 0.104138, loss_fp: 0.005486, loss_freq: 0.067786
[16:40:12.187] iteration 26204: loss: 0.042218, loss_s1: 0.021416, loss_fp: 0.006761, loss_freq: 0.017348
[16:40:12.809] iteration 26205: loss: 0.048813, loss_s1: 0.028855, loss_fp: 0.003257, loss_freq: 0.029058
[16:40:13.431] iteration 26206: loss: 0.032681, loss_s1: 0.007684, loss_fp: 0.001909, loss_freq: 0.016660
[16:40:14.045] iteration 26207: loss: 0.030580, loss_s1: 0.013788, loss_fp: 0.003753, loss_freq: 0.015237
[16:40:14.684] iteration 26208: loss: 0.048962, loss_s1: 0.030767, loss_fp: 0.001471, loss_freq: 0.028431
[16:40:15.361] iteration 26209: loss: 0.049365, loss_s1: 0.055062, loss_fp: 0.007120, loss_freq: 0.011477
[16:40:15.995] iteration 26210: loss: 0.039958, loss_s1: 0.020788, loss_fp: 0.002530, loss_freq: 0.015226
[16:40:16.636] iteration 26211: loss: 0.048442, loss_s1: 0.041099, loss_fp: 0.001591, loss_freq: 0.027920
[16:40:17.253] iteration 26212: loss: 0.058399, loss_s1: 0.043411, loss_fp: 0.006310, loss_freq: 0.022349
[16:40:17.916] iteration 26213: loss: 0.061355, loss_s1: 0.061063, loss_fp: 0.006847, loss_freq: 0.019004
[16:40:18.542] iteration 26214: loss: 0.044556, loss_s1: 0.005733, loss_fp: 0.001173, loss_freq: 0.007202
[16:40:19.162] iteration 26215: loss: 0.050911, loss_s1: 0.034711, loss_fp: 0.003669, loss_freq: 0.035687
[16:40:19.781] iteration 26216: loss: 0.053802, loss_s1: 0.026469, loss_fp: 0.007621, loss_freq: 0.034999
[16:40:20.398] iteration 26217: loss: 0.057471, loss_s1: 0.043184, loss_fp: 0.008455, loss_freq: 0.017697
[16:40:21.011] iteration 26218: loss: 0.044240, loss_s1: 0.021507, loss_fp: 0.002030, loss_freq: 0.036976
[16:40:21.629] iteration 26219: loss: 0.044912, loss_s1: 0.024435, loss_fp: 0.000975, loss_freq: 0.022250
[16:40:22.252] iteration 26220: loss: 0.050072, loss_s1: 0.040578, loss_fp: 0.004678, loss_freq: 0.016035
[16:40:22.871] iteration 26221: loss: 0.055350, loss_s1: 0.011816, loss_fp: 0.003798, loss_freq: 0.041975
[16:40:23.491] iteration 26222: loss: 0.040815, loss_s1: 0.017925, loss_fp: 0.002017, loss_freq: 0.017514
[16:40:24.107] iteration 26223: loss: 0.073799, loss_s1: 0.060583, loss_fp: 0.012567, loss_freq: 0.051823
[16:40:24.735] iteration 26224: loss: 0.038244, loss_s1: 0.033331, loss_fp: 0.001080, loss_freq: 0.004776
[16:40:25.379] iteration 26225: loss: 0.043221, loss_s1: 0.019023, loss_fp: 0.001389, loss_freq: 0.024798
[16:40:26.022] iteration 26226: loss: 0.029417, loss_s1: 0.018711, loss_fp: 0.004552, loss_freq: 0.008114
[16:40:26.680] iteration 26227: loss: 0.045257, loss_s1: 0.035028, loss_fp: 0.005860, loss_freq: 0.012742
[16:40:27.320] iteration 26228: loss: 0.083852, loss_s1: 0.051456, loss_fp: 0.001719, loss_freq: 0.046537
[16:40:28.018] iteration 26229: loss: 0.050517, loss_s1: 0.042134, loss_fp: 0.004238, loss_freq: 0.017787
[16:40:28.664] iteration 26230: loss: 0.050458, loss_s1: 0.038602, loss_fp: 0.005398, loss_freq: 0.021394
[16:40:29.361] iteration 26231: loss: 0.049569, loss_s1: 0.034206, loss_fp: 0.004336, loss_freq: 0.012304
[16:40:30.013] iteration 26232: loss: 0.091991, loss_s1: 0.081604, loss_fp: 0.035039, loss_freq: 0.028769
[16:40:30.657] iteration 26233: loss: 0.053467, loss_s1: 0.042659, loss_fp: 0.001828, loss_freq: 0.021577
[16:40:31.295] iteration 26234: loss: 0.061993, loss_s1: 0.045375, loss_fp: 0.007715, loss_freq: 0.023986
[16:40:31.917] iteration 26235: loss: 0.029122, loss_s1: 0.013911, loss_fp: 0.004365, loss_freq: 0.006926
[16:40:32.559] iteration 26236: loss: 0.081357, loss_s1: 0.076061, loss_fp: 0.008494, loss_freq: 0.043079
[16:40:33.201] iteration 26237: loss: 0.053120, loss_s1: 0.043003, loss_fp: 0.005326, loss_freq: 0.009514
[16:40:33.841] iteration 26238: loss: 0.035684, loss_s1: 0.019014, loss_fp: 0.002865, loss_freq: 0.013556
[16:40:34.482] iteration 26239: loss: 0.063081, loss_s1: 0.042281, loss_fp: 0.001646, loss_freq: 0.024816
[16:40:35.107] iteration 26240: loss: 0.042962, loss_s1: 0.027621, loss_fp: 0.004423, loss_freq: 0.017409
[16:40:35.720] iteration 26241: loss: 0.053171, loss_s1: 0.020954, loss_fp: 0.007999, loss_freq: 0.027486
[16:40:36.337] iteration 26242: loss: 0.040766, loss_s1: 0.027410, loss_fp: 0.002982, loss_freq: 0.016310
[16:40:37.044] iteration 26243: loss: 0.087340, loss_s1: 0.043198, loss_fp: 0.015507, loss_freq: 0.077276
[16:40:37.677] iteration 26244: loss: 0.076509, loss_s1: 0.041697, loss_fp: 0.010677, loss_freq: 0.061864
[16:40:38.303] iteration 26245: loss: 0.028131, loss_s1: 0.011143, loss_fp: 0.001613, loss_freq: 0.014828
[16:40:39.167] iteration 26246: loss: 0.035202, loss_s1: 0.030960, loss_fp: 0.002168, loss_freq: 0.008634
[16:40:39.977] iteration 26247: loss: 0.062747, loss_s1: 0.081499, loss_fp: 0.000666, loss_freq: 0.011355
[16:40:40.713] iteration 26248: loss: 0.101229, loss_s1: 0.109740, loss_fp: 0.010317, loss_freq: 0.037554
[16:40:41.374] iteration 26249: loss: 0.110712, loss_s1: 0.067508, loss_fp: 0.003860, loss_freq: 0.036930
[16:40:42.005] iteration 26250: loss: 0.048936, loss_s1: 0.052359, loss_fp: 0.003816, loss_freq: 0.006418
[16:40:42.626] iteration 26251: loss: 0.052119, loss_s1: 0.041561, loss_fp: 0.005753, loss_freq: 0.015647
[16:40:43.241] iteration 26252: loss: 0.056459, loss_s1: 0.031276, loss_fp: 0.003249, loss_freq: 0.044151
[16:40:43.865] iteration 26253: loss: 0.052952, loss_s1: 0.051036, loss_fp: 0.005291, loss_freq: 0.020735
[16:40:44.480] iteration 26254: loss: 0.082632, loss_s1: 0.109145, loss_fp: 0.002994, loss_freq: 0.019227
[16:40:45.092] iteration 26255: loss: 0.060901, loss_s1: 0.039251, loss_fp: 0.003382, loss_freq: 0.041555
[16:40:45.708] iteration 26256: loss: 0.047322, loss_s1: 0.023419, loss_fp: 0.001046, loss_freq: 0.022106
[16:40:46.328] iteration 26257: loss: 0.032576, loss_s1: 0.012835, loss_fp: 0.003756, loss_freq: 0.014440
[16:40:46.951] iteration 26258: loss: 0.038570, loss_s1: 0.039842, loss_fp: 0.002722, loss_freq: 0.007558
[16:40:47.575] iteration 26259: loss: 0.074696, loss_s1: 0.099550, loss_fp: 0.001942, loss_freq: 0.021000
[16:40:48.198] iteration 26260: loss: 0.070494, loss_s1: 0.047585, loss_fp: 0.001820, loss_freq: 0.026680
[16:40:48.822] iteration 26261: loss: 0.043432, loss_s1: 0.016600, loss_fp: 0.013884, loss_freq: 0.030417
[16:40:49.450] iteration 26262: loss: 0.034824, loss_s1: 0.027851, loss_fp: 0.001263, loss_freq: 0.004659
[16:40:50.073] iteration 26263: loss: 0.038911, loss_s1: 0.017008, loss_fp: 0.003607, loss_freq: 0.020163
[16:40:50.698] iteration 26264: loss: 0.041021, loss_s1: 0.030427, loss_fp: 0.001189, loss_freq: 0.014401
[16:40:51.312] iteration 26265: loss: 0.029579, loss_s1: 0.007317, loss_fp: 0.003894, loss_freq: 0.010014
[16:40:51.932] iteration 26266: loss: 0.059405, loss_s1: 0.042528, loss_fp: 0.012523, loss_freq: 0.028489
[16:40:52.557] iteration 26267: loss: 0.032414, loss_s1: 0.018683, loss_fp: 0.001158, loss_freq: 0.010317
[16:40:53.176] iteration 26268: loss: 0.044164, loss_s1: 0.027410, loss_fp: 0.003958, loss_freq: 0.010668
[16:40:53.792] iteration 26269: loss: 0.140483, loss_s1: 0.064094, loss_fp: 0.003250, loss_freq: 0.034300
[16:40:54.414] iteration 26270: loss: 0.066322, loss_s1: 0.035650, loss_fp: 0.002649, loss_freq: 0.029558
[16:40:55.037] iteration 26271: loss: 0.088135, loss_s1: 0.039291, loss_fp: 0.010719, loss_freq: 0.052916
[16:40:55.660] iteration 26272: loss: 0.072165, loss_s1: 0.055609, loss_fp: 0.002667, loss_freq: 0.027991
[16:40:56.285] iteration 26273: loss: 0.036219, loss_s1: 0.018363, loss_fp: 0.001582, loss_freq: 0.013131
[16:40:56.903] iteration 26274: loss: 0.051503, loss_s1: 0.033823, loss_fp: 0.002446, loss_freq: 0.024849
[16:40:57.517] iteration 26275: loss: 0.046226, loss_s1: 0.010338, loss_fp: 0.002847, loss_freq: 0.031098
[16:40:58.138] iteration 26276: loss: 0.088530, loss_s1: 0.053083, loss_fp: 0.005888, loss_freq: 0.077320
[16:40:58.749] iteration 26277: loss: 0.105594, loss_s1: 0.076750, loss_fp: 0.002226, loss_freq: 0.095135
[16:40:59.368] iteration 26278: loss: 0.073131, loss_s1: 0.065525, loss_fp: 0.004236, loss_freq: 0.027911
[16:40:59.993] iteration 26279: loss: 0.075642, loss_s1: 0.064638, loss_fp: 0.003613, loss_freq: 0.045731
[16:41:00.617] iteration 26280: loss: 0.071550, loss_s1: 0.043044, loss_fp: 0.001050, loss_freq: 0.016323
[16:41:01.243] iteration 26281: loss: 0.057161, loss_s1: 0.040415, loss_fp: 0.007959, loss_freq: 0.039770
[16:41:01.872] iteration 26282: loss: 0.050533, loss_s1: 0.020223, loss_fp: 0.001939, loss_freq: 0.029092
[16:41:02.491] iteration 26283: loss: 0.066083, loss_s1: 0.063376, loss_fp: 0.012886, loss_freq: 0.005961
[16:41:03.100] iteration 26284: loss: 0.051597, loss_s1: 0.027521, loss_fp: 0.002641, loss_freq: 0.016691
[16:41:03.719] iteration 26285: loss: 0.040225, loss_s1: 0.036533, loss_fp: 0.002050, loss_freq: 0.007151
[16:41:04.339] iteration 26286: loss: 0.060035, loss_s1: 0.033799, loss_fp: 0.004136, loss_freq: 0.031297
[16:41:04.964] iteration 26287: loss: 0.050586, loss_s1: 0.034464, loss_fp: 0.003435, loss_freq: 0.018132
[16:41:05.581] iteration 26288: loss: 0.049205, loss_s1: 0.050510, loss_fp: 0.002540, loss_freq: 0.019064
[16:41:06.195] iteration 26289: loss: 0.058945, loss_s1: 0.044949, loss_fp: 0.006316, loss_freq: 0.024287
[16:41:06.815] iteration 26290: loss: 0.048541, loss_s1: 0.023162, loss_fp: 0.003809, loss_freq: 0.034419
[16:41:07.433] iteration 26291: loss: 0.071402, loss_s1: 0.087013, loss_fp: 0.002326, loss_freq: 0.009315
[16:41:08.061] iteration 26292: loss: 0.020367, loss_s1: 0.007440, loss_fp: 0.000693, loss_freq: 0.001396
[16:41:08.681] iteration 26293: loss: 0.046668, loss_s1: 0.033169, loss_fp: 0.002974, loss_freq: 0.023595
[16:41:09.293] iteration 26294: loss: 0.067476, loss_s1: 0.058798, loss_fp: 0.004697, loss_freq: 0.040359
[16:41:09.912] iteration 26295: loss: 0.057887, loss_s1: 0.030200, loss_fp: 0.005562, loss_freq: 0.006277
[16:41:10.538] iteration 26296: loss: 0.048106, loss_s1: 0.041181, loss_fp: 0.001270, loss_freq: 0.024369
[16:41:11.149] iteration 26297: loss: 0.041565, loss_s1: 0.037998, loss_fp: 0.001547, loss_freq: 0.014500
[16:41:11.764] iteration 26298: loss: 0.083473, loss_s1: 0.091403, loss_fp: 0.008802, loss_freq: 0.020340
[16:41:12.381] iteration 26299: loss: 0.031326, loss_s1: 0.017777, loss_fp: 0.001732, loss_freq: 0.003631
[16:41:13.004] iteration 26300: loss: 0.053346, loss_s1: 0.032737, loss_fp: 0.003248, loss_freq: 0.020738
[16:41:13.695] iteration 26301: loss: 0.100973, loss_s1: 0.067608, loss_fp: 0.007927, loss_freq: 0.064335
[16:41:14.348] iteration 26302: loss: 0.059557, loss_s1: 0.057839, loss_fp: 0.002659, loss_freq: 0.015944
[16:41:15.002] iteration 26303: loss: 0.060501, loss_s1: 0.034208, loss_fp: 0.005016, loss_freq: 0.031520
[16:41:15.660] iteration 26304: loss: 0.056583, loss_s1: 0.019901, loss_fp: 0.005506, loss_freq: 0.016959
[16:41:16.315] iteration 26305: loss: 0.057019, loss_s1: 0.067621, loss_fp: 0.002230, loss_freq: 0.011149
[16:41:16.959] iteration 26306: loss: 0.071971, loss_s1: 0.057115, loss_fp: 0.005492, loss_freq: 0.025522
[16:41:17.596] iteration 26307: loss: 0.028790, loss_s1: 0.015173, loss_fp: 0.004318, loss_freq: 0.009341
[16:41:18.238] iteration 26308: loss: 0.049141, loss_s1: 0.056064, loss_fp: 0.000415, loss_freq: 0.006797
[16:41:18.874] iteration 26309: loss: 0.037685, loss_s1: 0.025751, loss_fp: 0.001954, loss_freq: 0.005138
[16:41:19.501] iteration 26310: loss: 0.065522, loss_s1: 0.040827, loss_fp: 0.001285, loss_freq: 0.054180
[16:41:20.120] iteration 26311: loss: 0.113186, loss_s1: 0.084051, loss_fp: 0.014285, loss_freq: 0.092364
[16:41:20.732] iteration 26312: loss: 0.041052, loss_s1: 0.023876, loss_fp: 0.002798, loss_freq: 0.013347
[16:41:21.699] iteration 26313: loss: 0.046831, loss_s1: 0.042238, loss_fp: 0.001378, loss_freq: 0.014417
[16:41:22.317] iteration 26314: loss: 0.055289, loss_s1: 0.051307, loss_fp: 0.002865, loss_freq: 0.021198
[16:41:22.944] iteration 26315: loss: 0.038963, loss_s1: 0.019624, loss_fp: 0.001905, loss_freq: 0.009719
[16:41:23.561] iteration 26316: loss: 0.060747, loss_s1: 0.048429, loss_fp: 0.001245, loss_freq: 0.021851
[16:41:24.176] iteration 26317: loss: 0.044020, loss_s1: 0.022038, loss_fp: 0.001832, loss_freq: 0.032960
[16:41:24.810] iteration 26318: loss: 0.036710, loss_s1: 0.021134, loss_fp: 0.003658, loss_freq: 0.009950
[16:41:25.431] iteration 26319: loss: 0.036967, loss_s1: 0.036223, loss_fp: 0.001653, loss_freq: 0.008581
[16:41:26.055] iteration 26320: loss: 0.035178, loss_s1: 0.013220, loss_fp: 0.002793, loss_freq: 0.012623
[16:41:26.731] iteration 26321: loss: 0.045911, loss_s1: 0.031136, loss_fp: 0.008751, loss_freq: 0.009786
[16:41:27.360] iteration 26322: loss: 0.045655, loss_s1: 0.009667, loss_fp: 0.000734, loss_freq: 0.002836
[16:41:27.987] iteration 26323: loss: 0.033681, loss_s1: 0.023510, loss_fp: 0.002083, loss_freq: 0.008438
[16:41:28.613] iteration 26324: loss: 0.040635, loss_s1: 0.017767, loss_fp: 0.008436, loss_freq: 0.016657
[16:41:29.239] iteration 26325: loss: 0.057577, loss_s1: 0.061966, loss_fp: 0.001369, loss_freq: 0.012055
[16:41:29.863] iteration 26326: loss: 0.035184, loss_s1: 0.021105, loss_fp: 0.003823, loss_freq: 0.011674
[16:41:30.487] iteration 26327: loss: 0.052564, loss_s1: 0.040326, loss_fp: 0.001499, loss_freq: 0.015101
[16:41:31.111] iteration 26328: loss: 0.051637, loss_s1: 0.044683, loss_fp: 0.005202, loss_freq: 0.025122
[16:41:31.739] iteration 26329: loss: 0.035922, loss_s1: 0.019571, loss_fp: 0.001518, loss_freq: 0.011038
[16:41:32.362] iteration 26330: loss: 0.058688, loss_s1: 0.043125, loss_fp: 0.001350, loss_freq: 0.036551
[16:41:32.987] iteration 26331: loss: 0.033738, loss_s1: 0.021589, loss_fp: 0.001711, loss_freq: 0.010485
[16:41:33.613] iteration 26332: loss: 0.033490, loss_s1: 0.010284, loss_fp: 0.003539, loss_freq: 0.006751
[16:41:34.236] iteration 26333: loss: 0.063248, loss_s1: 0.022035, loss_fp: 0.004557, loss_freq: 0.059417
[16:41:34.882] iteration 26334: loss: 0.042256, loss_s1: 0.028798, loss_fp: 0.003073, loss_freq: 0.021546
[16:41:35.526] iteration 26335: loss: 0.054162, loss_s1: 0.035447, loss_fp: 0.001046, loss_freq: 0.035776
[16:41:36.167] iteration 26336: loss: 0.043303, loss_s1: 0.043867, loss_fp: 0.002950, loss_freq: 0.003762
[16:41:36.816] iteration 26337: loss: 0.039958, loss_s1: 0.034041, loss_fp: 0.001322, loss_freq: 0.008241
[16:41:37.459] iteration 26338: loss: 0.065522, loss_s1: 0.060474, loss_fp: 0.009372, loss_freq: 0.017085
[16:41:38.094] iteration 26339: loss: 0.053792, loss_s1: 0.030102, loss_fp: 0.002293, loss_freq: 0.034488
[16:41:38.718] iteration 26340: loss: 0.030579, loss_s1: 0.014909, loss_fp: 0.000837, loss_freq: 0.008008
[16:41:39.351] iteration 26341: loss: 0.069446, loss_s1: 0.036453, loss_fp: 0.012158, loss_freq: 0.041965
[16:41:40.033] iteration 26342: loss: 0.038367, loss_s1: 0.023580, loss_fp: 0.003835, loss_freq: 0.011291
[16:41:40.703] iteration 26343: loss: 0.046408, loss_s1: 0.042381, loss_fp: 0.003100, loss_freq: 0.004765
[16:41:41.351] iteration 26344: loss: 0.054374, loss_s1: 0.026925, loss_fp: 0.001695, loss_freq: 0.015332
[16:41:42.014] iteration 26345: loss: 0.088823, loss_s1: 0.077935, loss_fp: 0.013776, loss_freq: 0.055268
[16:41:42.668] iteration 26346: loss: 0.093887, loss_s1: 0.070099, loss_fp: 0.007930, loss_freq: 0.075732
[16:41:43.323] iteration 26347: loss: 0.059521, loss_s1: 0.034766, loss_fp: 0.003873, loss_freq: 0.020912
[16:41:43.969] iteration 26348: loss: 0.059107, loss_s1: 0.055517, loss_fp: 0.001055, loss_freq: 0.020659
[16:41:44.647] iteration 26349: loss: 0.055318, loss_s1: 0.047365, loss_fp: 0.001368, loss_freq: 0.026530
[16:41:45.308] iteration 26350: loss: 0.055461, loss_s1: 0.047403, loss_fp: 0.004241, loss_freq: 0.025858
[16:41:45.951] iteration 26351: loss: 0.060796, loss_s1: 0.055202, loss_fp: 0.003032, loss_freq: 0.018930
[16:41:46.600] iteration 26352: loss: 0.026022, loss_s1: 0.016862, loss_fp: 0.004804, loss_freq: 0.005525
[16:41:47.244] iteration 26353: loss: 0.061094, loss_s1: 0.047105, loss_fp: 0.003062, loss_freq: 0.031079
[16:41:47.877] iteration 26354: loss: 0.038359, loss_s1: 0.033550, loss_fp: 0.003219, loss_freq: 0.014480
[16:41:48.515] iteration 26355: loss: 0.045569, loss_s1: 0.017767, loss_fp: 0.004908, loss_freq: 0.026599
[16:41:49.156] iteration 26356: loss: 0.085088, loss_s1: 0.083523, loss_fp: 0.001633, loss_freq: 0.052102
[16:41:49.795] iteration 26357: loss: 0.043311, loss_s1: 0.017279, loss_fp: 0.002693, loss_freq: 0.005767
[16:41:50.444] iteration 26358: loss: 0.086336, loss_s1: 0.086268, loss_fp: 0.004593, loss_freq: 0.046351
[16:41:51.090] iteration 26359: loss: 0.063414, loss_s1: 0.040181, loss_fp: 0.002835, loss_freq: 0.043402
[16:41:51.730] iteration 26360: loss: 0.058556, loss_s1: 0.035156, loss_fp: 0.002259, loss_freq: 0.010977
[16:41:52.385] iteration 26361: loss: 0.042216, loss_s1: 0.024802, loss_fp: 0.002284, loss_freq: 0.029450
[16:41:53.028] iteration 26362: loss: 0.033872, loss_s1: 0.015122, loss_fp: 0.001093, loss_freq: 0.016423
[16:41:53.673] iteration 26363: loss: 0.055011, loss_s1: 0.028015, loss_fp: 0.006013, loss_freq: 0.039288
[16:41:54.311] iteration 26364: loss: 0.048246, loss_s1: 0.029711, loss_fp: 0.002996, loss_freq: 0.022782
[16:41:54.948] iteration 26365: loss: 0.034412, loss_s1: 0.018820, loss_fp: 0.005057, loss_freq: 0.016116
[16:41:55.595] iteration 26366: loss: 0.060971, loss_s1: 0.037897, loss_fp: 0.006498, loss_freq: 0.045384
[16:41:56.239] iteration 26367: loss: 0.041187, loss_s1: 0.019430, loss_fp: 0.002269, loss_freq: 0.012962
[16:41:56.885] iteration 26368: loss: 0.057789, loss_s1: 0.029809, loss_fp: 0.000414, loss_freq: 0.031755
[16:41:57.541] iteration 26369: loss: 0.064854, loss_s1: 0.038984, loss_fp: 0.010387, loss_freq: 0.037650
[16:41:58.223] iteration 26370: loss: 0.041949, loss_s1: 0.017903, loss_fp: 0.002742, loss_freq: 0.023066
[16:41:58.855] iteration 26371: loss: 0.049009, loss_s1: 0.048299, loss_fp: 0.001162, loss_freq: 0.013201
[16:41:59.499] iteration 26372: loss: 0.066704, loss_s1: 0.062051, loss_fp: 0.003076, loss_freq: 0.026038
[16:42:00.135] iteration 26373: loss: 0.059921, loss_s1: 0.036656, loss_fp: 0.008619, loss_freq: 0.031025
[16:42:00.774] iteration 26374: loss: 0.038501, loss_s1: 0.027203, loss_fp: 0.001404, loss_freq: 0.007729
[16:42:01.414] iteration 26375: loss: 0.066911, loss_s1: 0.033287, loss_fp: 0.002167, loss_freq: 0.064100
[16:42:02.048] iteration 26376: loss: 0.044300, loss_s1: 0.031252, loss_fp: 0.001074, loss_freq: 0.012317
[16:42:02.690] iteration 26377: loss: 0.062521, loss_s1: 0.037209, loss_fp: 0.002915, loss_freq: 0.020139
[16:42:03.335] iteration 26378: loss: 0.065301, loss_s1: 0.042728, loss_fp: 0.003506, loss_freq: 0.050439
[16:42:03.976] iteration 26379: loss: 0.061500, loss_s1: 0.033112, loss_fp: 0.015459, loss_freq: 0.026104
[16:42:04.617] iteration 26380: loss: 0.035703, loss_s1: 0.021815, loss_fp: 0.001902, loss_freq: 0.019973
[16:42:05.255] iteration 26381: loss: 0.032310, loss_s1: 0.017813, loss_fp: 0.001393, loss_freq: 0.008943
[16:42:05.885] iteration 26382: loss: 0.076712, loss_s1: 0.041898, loss_fp: 0.004895, loss_freq: 0.032202
[16:42:06.514] iteration 26383: loss: 0.071240, loss_s1: 0.039687, loss_fp: 0.011053, loss_freq: 0.023204
[16:42:07.148] iteration 26384: loss: 0.077917, loss_s1: 0.040713, loss_fp: 0.001743, loss_freq: 0.058607
[16:42:07.785] iteration 26385: loss: 0.054565, loss_s1: 0.020548, loss_fp: 0.001844, loss_freq: 0.044966
[16:42:08.421] iteration 26386: loss: 0.079119, loss_s1: 0.033020, loss_fp: 0.014507, loss_freq: 0.051522
[16:42:09.066] iteration 26387: loss: 0.072520, loss_s1: 0.059351, loss_fp: 0.004826, loss_freq: 0.051790
[16:42:09.701] iteration 26388: loss: 0.046632, loss_s1: 0.024794, loss_fp: 0.008827, loss_freq: 0.014332
[16:42:10.332] iteration 26389: loss: 0.082002, loss_s1: 0.075411, loss_fp: 0.009969, loss_freq: 0.052663
[16:42:10.959] iteration 26390: loss: 0.027480, loss_s1: 0.004935, loss_fp: 0.000643, loss_freq: 0.010972
[16:42:11.593] iteration 26391: loss: 0.054440, loss_s1: 0.040306, loss_fp: 0.004963, loss_freq: 0.024854
[16:42:12.222] iteration 26392: loss: 0.071026, loss_s1: 0.050625, loss_fp: 0.012899, loss_freq: 0.024256
[16:42:12.857] iteration 26393: loss: 0.054139, loss_s1: 0.043568, loss_fp: 0.010819, loss_freq: 0.011098
[16:42:13.494] iteration 26394: loss: 0.034694, loss_s1: 0.021271, loss_fp: 0.002187, loss_freq: 0.014055
[16:42:14.125] iteration 26395: loss: 0.059545, loss_s1: 0.040572, loss_fp: 0.000403, loss_freq: 0.025194
[16:42:14.766] iteration 26396: loss: 0.042585, loss_s1: 0.020376, loss_fp: 0.001838, loss_freq: 0.034367
[16:42:15.398] iteration 26397: loss: 0.086672, loss_s1: 0.086185, loss_fp: 0.009548, loss_freq: 0.035619
[16:42:16.027] iteration 26398: loss: 0.072887, loss_s1: 0.070028, loss_fp: 0.003149, loss_freq: 0.026162
[16:42:16.667] iteration 26399: loss: 0.062462, loss_s1: 0.029528, loss_fp: 0.000372, loss_freq: 0.005797
[16:42:17.302] iteration 26400: loss: 0.029150, loss_s1: 0.020149, loss_fp: 0.000395, loss_freq: 0.005463
[16:42:20.695] iteration 26400 : mean_dice : 0.802424
[16:42:21.344] iteration 26401: loss: 0.050508, loss_s1: 0.044449, loss_fp: 0.005473, loss_freq: 0.021420
[16:42:22.056] iteration 26402: loss: 0.050446, loss_s1: 0.044304, loss_fp: 0.002947, loss_freq: 0.024210
[16:42:22.690] iteration 26403: loss: 0.065932, loss_s1: 0.036694, loss_fp: 0.001277, loss_freq: 0.022977
[16:42:23.359] iteration 26404: loss: 0.050591, loss_s1: 0.026965, loss_fp: 0.006805, loss_freq: 0.035849
[16:42:24.034] iteration 26405: loss: 0.050283, loss_s1: 0.048003, loss_fp: 0.002201, loss_freq: 0.014279
[16:42:24.732] iteration 26406: loss: 0.043224, loss_s1: 0.039093, loss_fp: 0.001728, loss_freq: 0.003665
[16:42:25.380] iteration 26407: loss: 0.037755, loss_s1: 0.027848, loss_fp: 0.001960, loss_freq: 0.009689
[16:42:26.020] iteration 26408: loss: 0.059987, loss_s1: 0.065522, loss_fp: 0.000643, loss_freq: 0.006933
[16:42:26.658] iteration 26409: loss: 0.062565, loss_s1: 0.036813, loss_fp: 0.005115, loss_freq: 0.046747
[16:42:27.301] iteration 26410: loss: 0.037464, loss_s1: 0.012958, loss_fp: 0.000931, loss_freq: 0.019979
[16:42:27.939] iteration 26411: loss: 0.058633, loss_s1: 0.032292, loss_fp: 0.001947, loss_freq: 0.040303
[16:42:28.588] iteration 26412: loss: 0.070222, loss_s1: 0.041090, loss_fp: 0.001579, loss_freq: 0.058373
[16:42:29.225] iteration 26413: loss: 0.069681, loss_s1: 0.066578, loss_fp: 0.000814, loss_freq: 0.034403
[16:42:29.860] iteration 26414: loss: 0.054416, loss_s1: 0.041225, loss_fp: 0.003067, loss_freq: 0.020513
[16:42:30.549] iteration 26415: loss: 0.059111, loss_s1: 0.061600, loss_fp: 0.005465, loss_freq: 0.024084
[16:42:31.184] iteration 26416: loss: 0.026316, loss_s1: 0.010483, loss_fp: 0.001557, loss_freq: 0.005218
[16:42:31.821] iteration 26417: loss: 0.051739, loss_s1: 0.037177, loss_fp: 0.003580, loss_freq: 0.015130
[16:42:32.504] iteration 26418: loss: 0.053458, loss_s1: 0.045901, loss_fp: 0.003872, loss_freq: 0.016111
[16:42:33.175] iteration 26419: loss: 0.066105, loss_s1: 0.035596, loss_fp: 0.004482, loss_freq: 0.049172
[16:42:33.833] iteration 26420: loss: 0.058943, loss_s1: 0.053217, loss_fp: 0.007681, loss_freq: 0.027022
[16:42:34.529] iteration 26421: loss: 0.041169, loss_s1: 0.020136, loss_fp: 0.001373, loss_freq: 0.021230
[16:42:35.215] iteration 26422: loss: 0.072931, loss_s1: 0.074707, loss_fp: 0.004776, loss_freq: 0.038814
[16:42:35.849] iteration 26423: loss: 0.038290, loss_s1: 0.025578, loss_fp: 0.000543, loss_freq: 0.019003
[16:42:36.500] iteration 26424: loss: 0.053181, loss_s1: 0.053681, loss_fp: 0.004923, loss_freq: 0.020683
[16:42:37.141] iteration 26425: loss: 0.058257, loss_s1: 0.054545, loss_fp: 0.001453, loss_freq: 0.014891
[16:42:37.779] iteration 26426: loss: 0.045991, loss_s1: 0.040779, loss_fp: 0.005972, loss_freq: 0.012506
[16:42:38.418] iteration 26427: loss: 0.037824, loss_s1: 0.015071, loss_fp: 0.001214, loss_freq: 0.006912
[16:42:39.052] iteration 26428: loss: 0.063134, loss_s1: 0.062546, loss_fp: 0.002350, loss_freq: 0.026371
[16:42:39.689] iteration 26429: loss: 0.071914, loss_s1: 0.055109, loss_fp: 0.012174, loss_freq: 0.040797
[16:42:40.333] iteration 26430: loss: 0.067959, loss_s1: 0.069244, loss_fp: 0.002207, loss_freq: 0.022645
[16:42:40.968] iteration 26431: loss: 0.043294, loss_s1: 0.048548, loss_fp: 0.001673, loss_freq: 0.009306
[16:42:41.600] iteration 26432: loss: 0.055706, loss_s1: 0.038864, loss_fp: 0.000932, loss_freq: 0.036450
[16:42:42.228] iteration 26433: loss: 0.041847, loss_s1: 0.022695, loss_fp: 0.002585, loss_freq: 0.019450
[16:42:42.863] iteration 26434: loss: 0.070969, loss_s1: 0.063362, loss_fp: 0.002813, loss_freq: 0.017367
[16:42:43.488] iteration 26435: loss: 0.037708, loss_s1: 0.015567, loss_fp: 0.001769, loss_freq: 0.023711
[16:42:44.124] iteration 26436: loss: 0.049635, loss_s1: 0.028567, loss_fp: 0.003490, loss_freq: 0.040982
[16:42:44.976] iteration 26437: loss: 0.046499, loss_s1: 0.040866, loss_fp: 0.006102, loss_freq: 0.017432
[16:42:45.923] iteration 26438: loss: 0.065245, loss_s1: 0.061201, loss_fp: 0.003286, loss_freq: 0.017362
[16:42:46.734] iteration 26439: loss: 0.034827, loss_s1: 0.019288, loss_fp: 0.004557, loss_freq: 0.010969
[16:42:47.376] iteration 26440: loss: 0.047499, loss_s1: 0.036640, loss_fp: 0.001197, loss_freq: 0.020675
[16:42:48.018] iteration 26441: loss: 0.065146, loss_s1: 0.061636, loss_fp: 0.012861, loss_freq: 0.021797
[16:42:48.658] iteration 26442: loss: 0.046539, loss_s1: 0.038314, loss_fp: 0.008886, loss_freq: 0.009248
[16:42:49.290] iteration 26443: loss: 0.062495, loss_s1: 0.030756, loss_fp: 0.004836, loss_freq: 0.034419
[16:42:49.930] iteration 26444: loss: 0.051224, loss_s1: 0.038092, loss_fp: 0.001987, loss_freq: 0.017494
[16:42:50.561] iteration 26445: loss: 0.049130, loss_s1: 0.037982, loss_fp: 0.005887, loss_freq: 0.019008
[16:42:51.199] iteration 26446: loss: 0.084839, loss_s1: 0.061683, loss_fp: 0.002860, loss_freq: 0.063375
[16:42:51.837] iteration 26447: loss: 0.071486, loss_s1: 0.062978, loss_fp: 0.006033, loss_freq: 0.029273
[16:42:52.478] iteration 26448: loss: 0.050363, loss_s1: 0.041501, loss_fp: 0.003407, loss_freq: 0.016492
[16:42:53.110] iteration 26449: loss: 0.065074, loss_s1: 0.042084, loss_fp: 0.005219, loss_freq: 0.038519
[16:42:53.749] iteration 26450: loss: 0.033638, loss_s1: 0.021748, loss_fp: 0.003223, loss_freq: 0.007986
[16:42:54.380] iteration 26451: loss: 0.045361, loss_s1: 0.040437, loss_fp: 0.001267, loss_freq: 0.016281
[16:42:55.020] iteration 26452: loss: 0.040285, loss_s1: 0.021016, loss_fp: 0.007429, loss_freq: 0.019036
[16:42:55.654] iteration 26453: loss: 0.060652, loss_s1: 0.063114, loss_fp: 0.004028, loss_freq: 0.020998
[16:42:56.280] iteration 26454: loss: 0.052742, loss_s1: 0.049962, loss_fp: 0.001644, loss_freq: 0.016789
[16:42:56.918] iteration 26455: loss: 0.037677, loss_s1: 0.021934, loss_fp: 0.001944, loss_freq: 0.022868
[16:42:57.892] iteration 26456: loss: 0.038596, loss_s1: 0.026548, loss_fp: 0.001218, loss_freq: 0.004885
[16:42:58.608] iteration 26457: loss: 0.055422, loss_s1: 0.031538, loss_fp: 0.003590, loss_freq: 0.029011
[16:42:59.287] iteration 26458: loss: 0.058302, loss_s1: 0.038666, loss_fp: 0.007792, loss_freq: 0.039826
[16:42:59.981] iteration 26459: loss: 0.066060, loss_s1: 0.055323, loss_fp: 0.006442, loss_freq: 0.028899
[16:43:00.662] iteration 26460: loss: 0.047739, loss_s1: 0.044043, loss_fp: 0.000851, loss_freq: 0.023988
[16:43:01.318] iteration 26461: loss: 0.030319, loss_s1: 0.014226, loss_fp: 0.002653, loss_freq: 0.004526
[16:43:01.956] iteration 26462: loss: 0.031676, loss_s1: 0.012453, loss_fp: 0.005434, loss_freq: 0.014348
[16:43:02.593] iteration 26463: loss: 0.053182, loss_s1: 0.032719, loss_fp: 0.014458, loss_freq: 0.022139
[16:43:03.229] iteration 26464: loss: 0.037643, loss_s1: 0.019764, loss_fp: 0.002253, loss_freq: 0.014800
[16:43:03.866] iteration 26465: loss: 0.046699, loss_s1: 0.015525, loss_fp: 0.000498, loss_freq: 0.017493
[16:43:04.509] iteration 26466: loss: 0.058699, loss_s1: 0.027729, loss_fp: 0.003350, loss_freq: 0.035396
[16:43:05.143] iteration 26467: loss: 0.034750, loss_s1: 0.019437, loss_fp: 0.007845, loss_freq: 0.006898
[16:43:05.776] iteration 26468: loss: 0.055207, loss_s1: 0.049902, loss_fp: 0.004454, loss_freq: 0.022361
[16:43:06.416] iteration 26469: loss: 0.031167, loss_s1: 0.027349, loss_fp: 0.000973, loss_freq: 0.005175
[16:43:07.056] iteration 26470: loss: 0.060693, loss_s1: 0.065418, loss_fp: 0.002890, loss_freq: 0.020283
[16:43:07.708] iteration 26471: loss: 0.037556, loss_s1: 0.032895, loss_fp: 0.002979, loss_freq: 0.005739
[16:43:08.364] iteration 26472: loss: 0.040631, loss_s1: 0.017164, loss_fp: 0.000857, loss_freq: 0.026062
[16:43:09.016] iteration 26473: loss: 0.044265, loss_s1: 0.031484, loss_fp: 0.002968, loss_freq: 0.021074
[16:43:09.653] iteration 26474: loss: 0.036871, loss_s1: 0.021721, loss_fp: 0.002293, loss_freq: 0.026608
[16:43:10.304] iteration 26475: loss: 0.033853, loss_s1: 0.014940, loss_fp: 0.000841, loss_freq: 0.012035
[16:43:10.952] iteration 26476: loss: 0.085734, loss_s1: 0.018738, loss_fp: 0.006276, loss_freq: 0.081933
[16:43:11.595] iteration 26477: loss: 0.039285, loss_s1: 0.030168, loss_fp: 0.003715, loss_freq: 0.017489
[16:43:12.236] iteration 26478: loss: 0.056876, loss_s1: 0.060828, loss_fp: 0.002413, loss_freq: 0.017581
[16:43:12.886] iteration 26479: loss: 0.031849, loss_s1: 0.024463, loss_fp: 0.002010, loss_freq: 0.004400
[16:43:13.530] iteration 26480: loss: 0.046555, loss_s1: 0.034790, loss_fp: 0.002190, loss_freq: 0.016434
[16:43:14.176] iteration 26481: loss: 0.039003, loss_s1: 0.025438, loss_fp: 0.004192, loss_freq: 0.017055
[16:43:14.832] iteration 26482: loss: 0.077479, loss_s1: 0.040621, loss_fp: 0.006093, loss_freq: 0.059039
[16:43:15.468] iteration 26483: loss: 0.057666, loss_s1: 0.056439, loss_fp: 0.003572, loss_freq: 0.006085
[16:43:16.111] iteration 26484: loss: 0.044602, loss_s1: 0.021823, loss_fp: 0.004733, loss_freq: 0.021440
[16:43:16.754] iteration 26485: loss: 0.035809, loss_s1: 0.026217, loss_fp: 0.002510, loss_freq: 0.005243
[16:43:17.394] iteration 26486: loss: 0.050698, loss_s1: 0.052042, loss_fp: 0.001329, loss_freq: 0.014451
[16:43:18.048] iteration 26487: loss: 0.057071, loss_s1: 0.032113, loss_fp: 0.014212, loss_freq: 0.018336
[16:43:18.691] iteration 26488: loss: 0.076278, loss_s1: 0.096852, loss_fp: 0.003775, loss_freq: 0.024888
[16:43:19.331] iteration 26489: loss: 0.086594, loss_s1: 0.083033, loss_fp: 0.006679, loss_freq: 0.042534
[16:43:19.974] iteration 26490: loss: 0.054734, loss_s1: 0.049936, loss_fp: 0.001492, loss_freq: 0.023238
[16:43:20.632] iteration 26491: loss: 0.044377, loss_s1: 0.032169, loss_fp: 0.001379, loss_freq: 0.020311
[16:43:21.303] iteration 26492: loss: 0.048145, loss_s1: 0.017628, loss_fp: 0.001533, loss_freq: 0.029565
[16:43:21.944] iteration 26493: loss: 0.033795, loss_s1: 0.019612, loss_fp: 0.001577, loss_freq: 0.019115
[16:43:22.615] iteration 26494: loss: 0.077133, loss_s1: 0.079496, loss_fp: 0.005121, loss_freq: 0.028195
[16:43:23.251] iteration 26495: loss: 0.031935, loss_s1: 0.018751, loss_fp: 0.001117, loss_freq: 0.015344
[16:43:23.893] iteration 26496: loss: 0.044630, loss_s1: 0.022048, loss_fp: 0.002440, loss_freq: 0.023375
[16:43:24.531] iteration 26497: loss: 0.054781, loss_s1: 0.066076, loss_fp: 0.001752, loss_freq: 0.011809
[16:43:25.168] iteration 26498: loss: 0.047987, loss_s1: 0.034290, loss_fp: 0.004253, loss_freq: 0.014171
[16:43:25.807] iteration 26499: loss: 0.068077, loss_s1: 0.071267, loss_fp: 0.002354, loss_freq: 0.032339
[16:43:26.453] iteration 26500: loss: 0.035751, loss_s1: 0.013478, loss_fp: 0.002716, loss_freq: 0.008381
[16:43:27.104] iteration 26501: loss: 0.058510, loss_s1: 0.041226, loss_fp: 0.007023, loss_freq: 0.034116
[16:43:27.745] iteration 26502: loss: 0.065716, loss_s1: 0.067440, loss_fp: 0.008001, loss_freq: 0.017659
[16:43:28.379] iteration 26503: loss: 0.042879, loss_s1: 0.030873, loss_fp: 0.002987, loss_freq: 0.016168
[16:43:29.011] iteration 26504: loss: 0.047575, loss_s1: 0.042128, loss_fp: 0.001450, loss_freq: 0.016914
[16:43:29.656] iteration 26505: loss: 0.039525, loss_s1: 0.012010, loss_fp: 0.001680, loss_freq: 0.025136
[16:43:30.303] iteration 26506: loss: 0.048136, loss_s1: 0.035137, loss_fp: 0.001552, loss_freq: 0.018983
[16:43:30.946] iteration 26507: loss: 0.097728, loss_s1: 0.021882, loss_fp: 0.005784, loss_freq: 0.029784
[16:43:31.589] iteration 26508: loss: 0.047381, loss_s1: 0.025339, loss_fp: 0.001791, loss_freq: 0.032829
[16:43:32.221] iteration 26509: loss: 0.094529, loss_s1: 0.072304, loss_fp: 0.009354, loss_freq: 0.075054
[16:43:32.864] iteration 26510: loss: 0.028655, loss_s1: 0.021397, loss_fp: 0.000745, loss_freq: 0.003784
[16:43:33.497] iteration 26511: loss: 0.050259, loss_s1: 0.018016, loss_fp: 0.001640, loss_freq: 0.019986
[16:43:34.186] iteration 26512: loss: 0.055320, loss_s1: 0.050951, loss_fp: 0.001557, loss_freq: 0.021375
[16:43:34.824] iteration 26513: loss: 0.069214, loss_s1: 0.041415, loss_fp: 0.003711, loss_freq: 0.050463
[16:43:35.478] iteration 26514: loss: 0.064865, loss_s1: 0.046995, loss_fp: 0.000589, loss_freq: 0.036638
[16:43:36.106] iteration 26515: loss: 0.053841, loss_s1: 0.051864, loss_fp: 0.000837, loss_freq: 0.015953
[16:43:36.735] iteration 26516: loss: 0.050419, loss_s1: 0.024225, loss_fp: 0.006456, loss_freq: 0.026933
[16:43:37.366] iteration 26517: loss: 0.066315, loss_s1: 0.073117, loss_fp: 0.000750, loss_freq: 0.018332
[16:43:37.997] iteration 26518: loss: 0.076292, loss_s1: 0.071617, loss_fp: 0.007869, loss_freq: 0.032246
[16:43:38.621] iteration 26519: loss: 0.050515, loss_s1: 0.018217, loss_fp: 0.003926, loss_freq: 0.029134
[16:43:39.250] iteration 26520: loss: 0.055012, loss_s1: 0.017445, loss_fp: 0.008675, loss_freq: 0.014425
[16:43:39.887] iteration 26521: loss: 0.043720, loss_s1: 0.044687, loss_fp: 0.002860, loss_freq: 0.012084
[16:43:40.531] iteration 26522: loss: 0.109702, loss_s1: 0.087128, loss_fp: 0.001191, loss_freq: 0.076531
[16:43:41.173] iteration 26523: loss: 0.038314, loss_s1: 0.026070, loss_fp: 0.002138, loss_freq: 0.013209
[16:43:41.803] iteration 26524: loss: 0.042505, loss_s1: 0.025750, loss_fp: 0.003389, loss_freq: 0.011744
[16:43:42.438] iteration 26525: loss: 0.056380, loss_s1: 0.031681, loss_fp: 0.002279, loss_freq: 0.014608
[16:43:43.071] iteration 26526: loss: 0.044133, loss_s1: 0.022488, loss_fp: 0.003174, loss_freq: 0.014689
[16:43:43.700] iteration 26527: loss: 0.080413, loss_s1: 0.045815, loss_fp: 0.003945, loss_freq: 0.059718
[16:43:44.337] iteration 26528: loss: 0.033618, loss_s1: 0.019258, loss_fp: 0.006807, loss_freq: 0.006172
[16:43:44.994] iteration 26529: loss: 0.036781, loss_s1: 0.006448, loss_fp: 0.003119, loss_freq: 0.013165
[16:43:45.625] iteration 26530: loss: 0.063999, loss_s1: 0.054659, loss_fp: 0.011784, loss_freq: 0.035536
[16:43:46.267] iteration 26531: loss: 0.038612, loss_s1: 0.031725, loss_fp: 0.002680, loss_freq: 0.007816
[16:43:46.951] iteration 26532: loss: 0.049253, loss_s1: 0.053863, loss_fp: 0.001743, loss_freq: 0.015340
[16:43:47.656] iteration 26533: loss: 0.076498, loss_s1: 0.074182, loss_fp: 0.002129, loss_freq: 0.016100
[16:43:48.347] iteration 26534: loss: 0.042742, loss_s1: 0.039271, loss_fp: 0.008990, loss_freq: 0.008166
[16:43:49.027] iteration 26535: loss: 0.068478, loss_s1: 0.034091, loss_fp: 0.009261, loss_freq: 0.020389
[16:43:49.710] iteration 26536: loss: 0.052332, loss_s1: 0.047643, loss_fp: 0.006291, loss_freq: 0.014867
[16:43:50.392] iteration 26537: loss: 0.051463, loss_s1: 0.028952, loss_fp: 0.000580, loss_freq: 0.029444
[16:43:51.060] iteration 26538: loss: 0.044770, loss_s1: 0.033866, loss_fp: 0.000843, loss_freq: 0.013813
[16:43:51.699] iteration 26539: loss: 0.056596, loss_s1: 0.062875, loss_fp: 0.007561, loss_freq: 0.012345
[16:43:52.338] iteration 26540: loss: 0.073323, loss_s1: 0.070889, loss_fp: 0.010018, loss_freq: 0.029604
[16:43:52.983] iteration 26541: loss: 0.072645, loss_s1: 0.036979, loss_fp: 0.009258, loss_freq: 0.056691
[16:43:53.621] iteration 26542: loss: 0.068446, loss_s1: 0.048959, loss_fp: 0.002802, loss_freq: 0.026665
[16:43:54.261] iteration 26543: loss: 0.037975, loss_s1: 0.033948, loss_fp: 0.000792, loss_freq: 0.008645
[16:43:54.907] iteration 26544: loss: 0.043614, loss_s1: 0.034508, loss_fp: 0.001124, loss_freq: 0.021030
[16:43:55.548] iteration 26545: loss: 0.036665, loss_s1: 0.027812, loss_fp: 0.005782, loss_freq: 0.012188
[16:43:56.204] iteration 26546: loss: 0.049240, loss_s1: 0.030348, loss_fp: 0.010259, loss_freq: 0.018146
[16:43:56.839] iteration 26547: loss: 0.075721, loss_s1: 0.095940, loss_fp: 0.006529, loss_freq: 0.019313
[16:43:57.473] iteration 26548: loss: 0.043078, loss_s1: 0.033293, loss_fp: 0.002549, loss_freq: 0.007417
[16:43:58.158] iteration 26549: loss: 0.042921, loss_s1: 0.010892, loss_fp: 0.001034, loss_freq: 0.005903
[16:43:58.835] iteration 26550: loss: 0.024190, loss_s1: 0.007347, loss_fp: 0.000893, loss_freq: 0.004656
[16:43:59.486] iteration 26551: loss: 0.044293, loss_s1: 0.032312, loss_fp: 0.000790, loss_freq: 0.014154
[16:44:00.120] iteration 26552: loss: 0.065473, loss_s1: 0.050067, loss_fp: 0.006059, loss_freq: 0.036774
[16:44:00.801] iteration 26553: loss: 0.040258, loss_s1: 0.017721, loss_fp: 0.005697, loss_freq: 0.020420
[16:44:01.484] iteration 26554: loss: 0.037340, loss_s1: 0.025609, loss_fp: 0.001323, loss_freq: 0.009873
[16:44:02.161] iteration 26555: loss: 0.052664, loss_s1: 0.031892, loss_fp: 0.012714, loss_freq: 0.020653
[16:44:02.793] iteration 26556: loss: 0.055011, loss_s1: 0.055000, loss_fp: 0.004987, loss_freq: 0.018508
[16:44:03.431] iteration 26557: loss: 0.044428, loss_s1: 0.018573, loss_fp: 0.004282, loss_freq: 0.019349
[16:44:04.069] iteration 26558: loss: 0.068164, loss_s1: 0.065018, loss_fp: 0.002809, loss_freq: 0.038291
[16:44:04.713] iteration 26559: loss: 0.058001, loss_s1: 0.062288, loss_fp: 0.006479, loss_freq: 0.014819
[16:44:05.357] iteration 26560: loss: 0.048772, loss_s1: 0.028839, loss_fp: 0.002730, loss_freq: 0.025656
[16:44:06.033] iteration 26561: loss: 0.043535, loss_s1: 0.014921, loss_fp: 0.002191, loss_freq: 0.027183
[16:44:06.681] iteration 26562: loss: 0.057581, loss_s1: 0.019507, loss_fp: 0.005157, loss_freq: 0.047233
[16:44:07.315] iteration 26563: loss: 0.029863, loss_s1: 0.009878, loss_fp: 0.005769, loss_freq: 0.014618
[16:44:07.960] iteration 26564: loss: 0.063313, loss_s1: 0.023935, loss_fp: 0.006534, loss_freq: 0.014170
[16:44:08.600] iteration 26565: loss: 0.041963, loss_s1: 0.034393, loss_fp: 0.002773, loss_freq: 0.023022
[16:44:09.242] iteration 26566: loss: 0.043465, loss_s1: 0.016987, loss_fp: 0.012633, loss_freq: 0.011529
[16:44:09.894] iteration 26567: loss: 0.060182, loss_s1: 0.050474, loss_fp: 0.003832, loss_freq: 0.038322
[16:44:10.547] iteration 26568: loss: 0.051758, loss_s1: 0.035925, loss_fp: 0.002170, loss_freq: 0.021033
[16:44:11.181] iteration 26569: loss: 0.060367, loss_s1: 0.047950, loss_fp: 0.006515, loss_freq: 0.032051
[16:44:11.827] iteration 26570: loss: 0.061142, loss_s1: 0.007435, loss_fp: 0.000852, loss_freq: 0.048713
[16:44:12.467] iteration 26571: loss: 0.050801, loss_s1: 0.034657, loss_fp: 0.001775, loss_freq: 0.012681
[16:44:13.127] iteration 26572: loss: 0.043102, loss_s1: 0.021109, loss_fp: 0.015066, loss_freq: 0.012211
[16:44:13.777] iteration 26573: loss: 0.067682, loss_s1: 0.064071, loss_fp: 0.009756, loss_freq: 0.020928
[16:44:14.414] iteration 26574: loss: 0.042288, loss_s1: 0.037171, loss_fp: 0.000961, loss_freq: 0.014796
[16:44:15.080] iteration 26575: loss: 0.058125, loss_s1: 0.032477, loss_fp: 0.001608, loss_freq: 0.033539
[16:44:15.751] iteration 26576: loss: 0.043316, loss_s1: 0.024385, loss_fp: 0.003577, loss_freq: 0.023387
[16:44:16.438] iteration 26577: loss: 0.055024, loss_s1: 0.034397, loss_fp: 0.012267, loss_freq: 0.012414
[16:44:17.110] iteration 26578: loss: 0.029320, loss_s1: 0.014969, loss_fp: 0.001476, loss_freq: 0.002972
[16:44:17.760] iteration 26579: loss: 0.035850, loss_s1: 0.025363, loss_fp: 0.002274, loss_freq: 0.013487
[16:44:18.401] iteration 26580: loss: 0.085720, loss_s1: 0.090837, loss_fp: 0.008311, loss_freq: 0.033720
[16:44:19.048] iteration 26581: loss: 0.045213, loss_s1: 0.020015, loss_fp: 0.004570, loss_freq: 0.024199
[16:44:19.689] iteration 26582: loss: 0.036471, loss_s1: 0.011670, loss_fp: 0.000707, loss_freq: 0.022010
[16:44:20.323] iteration 26583: loss: 0.057981, loss_s1: 0.043852, loss_fp: 0.001979, loss_freq: 0.024151
[16:44:20.956] iteration 26584: loss: 0.065513, loss_s1: 0.061447, loss_fp: 0.004481, loss_freq: 0.009153
[16:44:21.595] iteration 26585: loss: 0.038154, loss_s1: 0.020070, loss_fp: 0.006184, loss_freq: 0.014688
[16:44:22.231] iteration 26586: loss: 0.077942, loss_s1: 0.060031, loss_fp: 0.002092, loss_freq: 0.048571
[16:44:22.871] iteration 26587: loss: 0.061411, loss_s1: 0.048283, loss_fp: 0.005277, loss_freq: 0.026197
[16:44:23.511] iteration 26588: loss: 0.061698, loss_s1: 0.045709, loss_fp: 0.012962, loss_freq: 0.018887
[16:44:24.154] iteration 26589: loss: 0.068100, loss_s1: 0.050883, loss_fp: 0.008443, loss_freq: 0.032574
[16:44:24.796] iteration 26590: loss: 0.045294, loss_s1: 0.024013, loss_fp: 0.006936, loss_freq: 0.018600
[16:44:25.427] iteration 26591: loss: 0.055281, loss_s1: 0.033234, loss_fp: 0.005128, loss_freq: 0.031550
[16:44:26.055] iteration 26592: loss: 0.080625, loss_s1: 0.063428, loss_fp: 0.006958, loss_freq: 0.045940
[16:44:26.704] iteration 26593: loss: 0.027296, loss_s1: 0.010288, loss_fp: 0.002244, loss_freq: 0.009156
[16:44:27.334] iteration 26594: loss: 0.045892, loss_s1: 0.022707, loss_fp: 0.004731, loss_freq: 0.026053
[16:44:27.990] iteration 26595: loss: 0.064270, loss_s1: 0.033666, loss_fp: 0.005970, loss_freq: 0.020059
[16:44:28.633] iteration 26596: loss: 0.069179, loss_s1: 0.070357, loss_fp: 0.002625, loss_freq: 0.031722
[16:44:29.268] iteration 26597: loss: 0.095874, loss_s1: 0.065812, loss_fp: 0.010822, loss_freq: 0.067570
[16:44:29.912] iteration 26598: loss: 0.044647, loss_s1: 0.023505, loss_fp: 0.004771, loss_freq: 0.030954
[16:44:30.871] iteration 26599: loss: 0.039691, loss_s1: 0.031134, loss_fp: 0.000666, loss_freq: 0.009444
[16:44:31.515] iteration 26600: loss: 0.041196, loss_s1: 0.022781, loss_fp: 0.001780, loss_freq: 0.013190
[16:44:35.023] iteration 26600 : mean_dice : 0.794053
[16:44:35.707] iteration 26601: loss: 0.049326, loss_s1: 0.027647, loss_fp: 0.003039, loss_freq: 0.035216
[16:44:36.387] iteration 26602: loss: 0.056452, loss_s1: 0.038929, loss_fp: 0.004854, loss_freq: 0.027606
[16:44:37.074] iteration 26603: loss: 0.062371, loss_s1: 0.065349, loss_fp: 0.001520, loss_freq: 0.028262
[16:44:37.754] iteration 26604: loss: 0.076193, loss_s1: 0.038118, loss_fp: 0.007071, loss_freq: 0.013634
[16:44:38.433] iteration 26605: loss: 0.034557, loss_s1: 0.023661, loss_fp: 0.003622, loss_freq: 0.012965
[16:44:39.079] iteration 26606: loss: 0.054012, loss_s1: 0.035794, loss_fp: 0.007786, loss_freq: 0.015429
[16:44:39.723] iteration 26607: loss: 0.050808, loss_s1: 0.035116, loss_fp: 0.007251, loss_freq: 0.016796
[16:44:40.365] iteration 26608: loss: 0.035537, loss_s1: 0.012610, loss_fp: 0.004681, loss_freq: 0.004931
[16:44:40.993] iteration 26609: loss: 0.048012, loss_s1: 0.030506, loss_fp: 0.004342, loss_freq: 0.027530
[16:44:41.663] iteration 26610: loss: 0.030610, loss_s1: 0.014269, loss_fp: 0.000853, loss_freq: 0.010877
[16:44:42.350] iteration 26611: loss: 0.080273, loss_s1: 0.104733, loss_fp: 0.006621, loss_freq: 0.013428
[16:44:43.035] iteration 26612: loss: 0.044733, loss_s1: 0.032878, loss_fp: 0.003113, loss_freq: 0.023390
[16:44:43.677] iteration 26613: loss: 0.039787, loss_s1: 0.016587, loss_fp: 0.002865, loss_freq: 0.026234
[16:44:44.306] iteration 26614: loss: 0.046252, loss_s1: 0.013870, loss_fp: 0.005567, loss_freq: 0.035224
[16:44:44.947] iteration 26615: loss: 0.062214, loss_s1: 0.043552, loss_fp: 0.000963, loss_freq: 0.040708
[16:44:45.622] iteration 26616: loss: 0.034906, loss_s1: 0.021200, loss_fp: 0.002482, loss_freq: 0.011073
[16:44:46.265] iteration 26617: loss: 0.039591, loss_s1: 0.023007, loss_fp: 0.001482, loss_freq: 0.022483
[16:44:46.898] iteration 26618: loss: 0.041273, loss_s1: 0.027222, loss_fp: 0.002015, loss_freq: 0.011775
[16:44:47.534] iteration 26619: loss: 0.055562, loss_s1: 0.027363, loss_fp: 0.006065, loss_freq: 0.030004
[16:44:48.183] iteration 26620: loss: 0.041374, loss_s1: 0.018536, loss_fp: 0.002876, loss_freq: 0.026614
[16:44:48.841] iteration 26621: loss: 0.050008, loss_s1: 0.044890, loss_fp: 0.002644, loss_freq: 0.014150
[16:44:49.494] iteration 26622: loss: 0.043860, loss_s1: 0.048831, loss_fp: 0.001166, loss_freq: 0.008318
[16:44:50.143] iteration 26623: loss: 0.032852, loss_s1: 0.012880, loss_fp: 0.002940, loss_freq: 0.012498
[16:44:51.144] iteration 26624: loss: 0.057067, loss_s1: 0.037909, loss_fp: 0.001921, loss_freq: 0.032529
[16:44:51.993] iteration 26625: loss: 0.074074, loss_s1: 0.033561, loss_fp: 0.003444, loss_freq: 0.067161
[16:44:52.612] iteration 26626: loss: 0.042966, loss_s1: 0.037610, loss_fp: 0.003902, loss_freq: 0.006431
[16:44:53.241] iteration 26627: loss: 0.046483, loss_s1: 0.015643, loss_fp: 0.000588, loss_freq: 0.030515
[16:44:53.883] iteration 26628: loss: 0.044349, loss_s1: 0.012968, loss_fp: 0.003458, loss_freq: 0.018112
[16:44:54.516] iteration 26629: loss: 0.030104, loss_s1: 0.019292, loss_fp: 0.003476, loss_freq: 0.006777
[16:44:55.179] iteration 26630: loss: 0.053197, loss_s1: 0.047548, loss_fp: 0.001216, loss_freq: 0.019043
[16:44:55.860] iteration 26631: loss: 0.066831, loss_s1: 0.056942, loss_fp: 0.009125, loss_freq: 0.034715
[16:44:56.526] iteration 26632: loss: 0.096855, loss_s1: 0.104318, loss_fp: 0.004775, loss_freq: 0.048052
[16:44:57.199] iteration 26633: loss: 0.065963, loss_s1: 0.045453, loss_fp: 0.001122, loss_freq: 0.015549
[16:44:57.837] iteration 26634: loss: 0.074130, loss_s1: 0.051555, loss_fp: 0.003432, loss_freq: 0.027236
[16:44:58.477] iteration 26635: loss: 0.037981, loss_s1: 0.015338, loss_fp: 0.000845, loss_freq: 0.027279
[16:44:59.115] iteration 26636: loss: 0.030639, loss_s1: 0.024595, loss_fp: 0.001578, loss_freq: 0.005541
[16:44:59.759] iteration 26637: loss: 0.064215, loss_s1: 0.042329, loss_fp: 0.009722, loss_freq: 0.029532
[16:45:00.393] iteration 26638: loss: 0.038303, loss_s1: 0.031705, loss_fp: 0.005303, loss_freq: 0.011940
[16:45:01.045] iteration 26639: loss: 0.049360, loss_s1: 0.028091, loss_fp: 0.005669, loss_freq: 0.021043
[16:45:01.726] iteration 26640: loss: 0.025858, loss_s1: 0.015851, loss_fp: 0.000514, loss_freq: 0.010712
[16:45:02.396] iteration 26641: loss: 0.030786, loss_s1: 0.008368, loss_fp: 0.000652, loss_freq: 0.005988
[16:45:03.047] iteration 26642: loss: 0.047057, loss_s1: 0.032119, loss_fp: 0.007742, loss_freq: 0.019713
[16:45:03.685] iteration 26643: loss: 0.061129, loss_s1: 0.041032, loss_fp: 0.004991, loss_freq: 0.011489
[16:45:04.396] iteration 26644: loss: 0.041035, loss_s1: 0.023987, loss_fp: 0.003089, loss_freq: 0.026219
[16:45:05.046] iteration 26645: loss: 0.068359, loss_s1: 0.038967, loss_fp: 0.002549, loss_freq: 0.051945
[16:45:05.692] iteration 26646: loss: 0.062411, loss_s1: 0.069973, loss_fp: 0.003354, loss_freq: 0.008761
[16:45:06.346] iteration 26647: loss: 0.044820, loss_s1: 0.035410, loss_fp: 0.005989, loss_freq: 0.018549
[16:45:06.985] iteration 26648: loss: 0.053146, loss_s1: 0.041876, loss_fp: 0.002528, loss_freq: 0.013935
[16:45:07.633] iteration 26649: loss: 0.040211, loss_s1: 0.017929, loss_fp: 0.005468, loss_freq: 0.018697
[16:45:08.271] iteration 26650: loss: 0.060961, loss_s1: 0.050827, loss_fp: 0.003092, loss_freq: 0.024176
[16:45:08.909] iteration 26651: loss: 0.033395, loss_s1: 0.012502, loss_fp: 0.006128, loss_freq: 0.014400
[16:45:09.541] iteration 26652: loss: 0.090251, loss_s1: 0.087403, loss_fp: 0.002832, loss_freq: 0.054625
[16:45:10.221] iteration 26653: loss: 0.022052, loss_s1: 0.008798, loss_fp: 0.001851, loss_freq: 0.005154
[16:45:10.898] iteration 26654: loss: 0.042898, loss_s1: 0.007154, loss_fp: 0.000867, loss_freq: 0.019086
[16:45:11.550] iteration 26655: loss: 0.052534, loss_s1: 0.050989, loss_fp: 0.002993, loss_freq: 0.019502
[16:45:12.224] iteration 26656: loss: 0.033380, loss_s1: 0.019771, loss_fp: 0.001391, loss_freq: 0.013566
[16:45:12.934] iteration 26657: loss: 0.068025, loss_s1: 0.036363, loss_fp: 0.006430, loss_freq: 0.059532
[16:45:13.625] iteration 26658: loss: 0.062808, loss_s1: 0.053585, loss_fp: 0.010334, loss_freq: 0.029288
[16:45:14.297] iteration 26659: loss: 0.050452, loss_s1: 0.035569, loss_fp: 0.005700, loss_freq: 0.028744
[16:45:14.979] iteration 26660: loss: 0.048643, loss_s1: 0.043152, loss_fp: 0.001368, loss_freq: 0.011513
[16:45:15.632] iteration 26661: loss: 0.098739, loss_s1: 0.088187, loss_fp: 0.004310, loss_freq: 0.051937
[16:45:16.322] iteration 26662: loss: 0.043152, loss_s1: 0.030734, loss_fp: 0.002642, loss_freq: 0.010936
[16:45:16.997] iteration 26663: loss: 0.049525, loss_s1: 0.030185, loss_fp: 0.004090, loss_freq: 0.006492
[16:45:17.641] iteration 26664: loss: 0.070672, loss_s1: 0.080757, loss_fp: 0.003965, loss_freq: 0.018147
[16:45:18.289] iteration 26665: loss: 0.083277, loss_s1: 0.039024, loss_fp: 0.004716, loss_freq: 0.050946
[16:45:18.935] iteration 26666: loss: 0.029480, loss_s1: 0.015520, loss_fp: 0.005824, loss_freq: 0.012327
[16:45:19.577] iteration 26667: loss: 0.048630, loss_s1: 0.029161, loss_fp: 0.002974, loss_freq: 0.023760
[16:45:20.283] iteration 26668: loss: 0.043032, loss_s1: 0.024406, loss_fp: 0.001873, loss_freq: 0.011938
[16:45:20.988] iteration 26669: loss: 0.033319, loss_s1: 0.025057, loss_fp: 0.001644, loss_freq: 0.007383
[16:45:21.652] iteration 26670: loss: 0.045094, loss_s1: 0.009349, loss_fp: 0.005630, loss_freq: 0.017580
[16:45:22.296] iteration 26671: loss: 0.043351, loss_s1: 0.018865, loss_fp: 0.001559, loss_freq: 0.034273
[16:45:22.926] iteration 26672: loss: 0.081427, loss_s1: 0.058060, loss_fp: 0.003865, loss_freq: 0.046962
[16:45:23.560] iteration 26673: loss: 0.047368, loss_s1: 0.030028, loss_fp: 0.006341, loss_freq: 0.028672
[16:45:24.210] iteration 26674: loss: 0.063848, loss_s1: 0.030750, loss_fp: 0.003831, loss_freq: 0.006531
[16:45:24.885] iteration 26675: loss: 0.045983, loss_s1: 0.035996, loss_fp: 0.001037, loss_freq: 0.025419
[16:45:25.525] iteration 26676: loss: 0.043351, loss_s1: 0.022136, loss_fp: 0.001504, loss_freq: 0.011982
[16:45:26.167] iteration 26677: loss: 0.074396, loss_s1: 0.067981, loss_fp: 0.012937, loss_freq: 0.030456
[16:45:26.798] iteration 26678: loss: 0.069766, loss_s1: 0.049627, loss_fp: 0.003219, loss_freq: 0.024822
[16:45:27.439] iteration 26679: loss: 0.031920, loss_s1: 0.010573, loss_fp: 0.002505, loss_freq: 0.011263
[16:45:28.076] iteration 26680: loss: 0.047453, loss_s1: 0.025789, loss_fp: 0.003479, loss_freq: 0.019124
[16:45:28.716] iteration 26681: loss: 0.038513, loss_s1: 0.022736, loss_fp: 0.000507, loss_freq: 0.018769
[16:45:29.359] iteration 26682: loss: 0.046625, loss_s1: 0.033946, loss_fp: 0.002290, loss_freq: 0.027174
[16:45:30.003] iteration 26683: loss: 0.072095, loss_s1: 0.056880, loss_fp: 0.006883, loss_freq: 0.039393
[16:45:30.656] iteration 26684: loss: 0.051568, loss_s1: 0.031282, loss_fp: 0.003334, loss_freq: 0.034935
[16:45:31.299] iteration 26685: loss: 0.043630, loss_s1: 0.035538, loss_fp: 0.003706, loss_freq: 0.004090
[16:45:31.992] iteration 26686: loss: 0.034662, loss_s1: 0.031751, loss_fp: 0.000726, loss_freq: 0.007990
[16:45:32.627] iteration 26687: loss: 0.050260, loss_s1: 0.047327, loss_fp: 0.002027, loss_freq: 0.014249
[16:45:33.270] iteration 26688: loss: 0.060006, loss_s1: 0.046840, loss_fp: 0.002844, loss_freq: 0.035404
[16:45:33.927] iteration 26689: loss: 0.064080, loss_s1: 0.039052, loss_fp: 0.004829, loss_freq: 0.014219
[16:45:34.570] iteration 26690: loss: 0.088858, loss_s1: 0.085863, loss_fp: 0.002707, loss_freq: 0.058252
[16:45:35.218] iteration 26691: loss: 0.049502, loss_s1: 0.045053, loss_fp: 0.000969, loss_freq: 0.022561
[16:45:35.859] iteration 26692: loss: 0.035609, loss_s1: 0.024240, loss_fp: 0.002086, loss_freq: 0.003995
[16:45:36.504] iteration 26693: loss: 0.067125, loss_s1: 0.057019, loss_fp: 0.009003, loss_freq: 0.022450
[16:45:37.154] iteration 26694: loss: 0.052599, loss_s1: 0.058665, loss_fp: 0.005549, loss_freq: 0.005363
[16:45:37.804] iteration 26695: loss: 0.080919, loss_s1: 0.074552, loss_fp: 0.009477, loss_freq: 0.040630
[16:45:38.445] iteration 26696: loss: 0.045350, loss_s1: 0.021072, loss_fp: 0.004338, loss_freq: 0.023139
[16:45:39.081] iteration 26697: loss: 0.059900, loss_s1: 0.043703, loss_fp: 0.002534, loss_freq: 0.027880
[16:45:39.723] iteration 26698: loss: 0.047919, loss_s1: 0.016371, loss_fp: 0.002052, loss_freq: 0.039309
[16:45:40.363] iteration 26699: loss: 0.037793, loss_s1: 0.024661, loss_fp: 0.002990, loss_freq: 0.013103
[16:45:41.013] iteration 26700: loss: 0.060305, loss_s1: 0.030349, loss_fp: 0.003648, loss_freq: 0.047131
[16:45:41.651] iteration 26701: loss: 0.051419, loss_s1: 0.029703, loss_fp: 0.007230, loss_freq: 0.032479
[16:45:42.290] iteration 26702: loss: 0.056458, loss_s1: 0.045501, loss_fp: 0.002180, loss_freq: 0.033904
[16:45:42.928] iteration 26703: loss: 0.038075, loss_s1: 0.016085, loss_fp: 0.001707, loss_freq: 0.015861
[16:45:43.566] iteration 26704: loss: 0.047575, loss_s1: 0.028627, loss_fp: 0.001823, loss_freq: 0.023935
[16:45:44.201] iteration 26705: loss: 0.050579, loss_s1: 0.022137, loss_fp: 0.003264, loss_freq: 0.031242
[16:45:44.841] iteration 26706: loss: 0.035919, loss_s1: 0.008406, loss_fp: 0.003463, loss_freq: 0.031312
[16:45:45.479] iteration 26707: loss: 0.061261, loss_s1: 0.036275, loss_fp: 0.002806, loss_freq: 0.037860
[16:45:46.113] iteration 26708: loss: 0.039845, loss_s1: 0.023824, loss_fp: 0.004252, loss_freq: 0.022011
[16:45:46.753] iteration 26709: loss: 0.063253, loss_s1: 0.025196, loss_fp: 0.005394, loss_freq: 0.009818
[16:45:47.386] iteration 26710: loss: 0.064921, loss_s1: 0.044073, loss_fp: 0.006418, loss_freq: 0.044582
[16:45:48.030] iteration 26711: loss: 0.042164, loss_s1: 0.020767, loss_fp: 0.001181, loss_freq: 0.009270
[16:45:48.674] iteration 26712: loss: 0.052031, loss_s1: 0.044102, loss_fp: 0.002549, loss_freq: 0.012982
[16:45:49.321] iteration 26713: loss: 0.101588, loss_s1: 0.120320, loss_fp: 0.004275, loss_freq: 0.006616
[16:45:49.963] iteration 26714: loss: 0.046857, loss_s1: 0.006914, loss_fp: 0.001299, loss_freq: 0.029215
[16:45:50.608] iteration 26715: loss: 0.063956, loss_s1: 0.055573, loss_fp: 0.003042, loss_freq: 0.021910
[16:45:51.239] iteration 26716: loss: 0.091380, loss_s1: 0.109028, loss_fp: 0.007437, loss_freq: 0.029163
[16:45:51.881] iteration 26717: loss: 0.030476, loss_s1: 0.015795, loss_fp: 0.004297, loss_freq: 0.011597
[16:45:52.524] iteration 26718: loss: 0.078893, loss_s1: 0.079465, loss_fp: 0.003583, loss_freq: 0.036933
[16:45:53.157] iteration 26719: loss: 0.058337, loss_s1: 0.022033, loss_fp: 0.003442, loss_freq: 0.046741
[16:45:53.790] iteration 26720: loss: 0.066325, loss_s1: 0.064585, loss_fp: 0.001126, loss_freq: 0.016628
[16:45:54.436] iteration 26721: loss: 0.034632, loss_s1: 0.016477, loss_fp: 0.012592, loss_freq: 0.003382
[16:45:55.071] iteration 26722: loss: 0.035325, loss_s1: 0.031018, loss_fp: 0.004979, loss_freq: 0.009676
[16:45:55.786] iteration 26723: loss: 0.069378, loss_s1: 0.070271, loss_fp: 0.003747, loss_freq: 0.024850
[16:45:56.430] iteration 26724: loss: 0.059186, loss_s1: 0.052492, loss_fp: 0.004226, loss_freq: 0.015981
[16:45:57.065] iteration 26725: loss: 0.063583, loss_s1: 0.070559, loss_fp: 0.000874, loss_freq: 0.027122
[16:45:57.730] iteration 26726: loss: 0.053017, loss_s1: 0.044603, loss_fp: 0.004054, loss_freq: 0.024101
[16:45:58.407] iteration 26727: loss: 0.053023, loss_s1: 0.041293, loss_fp: 0.002104, loss_freq: 0.030840
[16:45:59.082] iteration 26728: loss: 0.046058, loss_s1: 0.027273, loss_fp: 0.007046, loss_freq: 0.012700
[16:45:59.763] iteration 26729: loss: 0.052156, loss_s1: 0.022693, loss_fp: 0.008064, loss_freq: 0.024212
[16:46:00.396] iteration 26730: loss: 0.069462, loss_s1: 0.053450, loss_fp: 0.001919, loss_freq: 0.043071
[16:46:01.038] iteration 26731: loss: 0.052770, loss_s1: 0.038047, loss_fp: 0.007299, loss_freq: 0.027452
[16:46:01.680] iteration 26732: loss: 0.081476, loss_s1: 0.052762, loss_fp: 0.002701, loss_freq: 0.053799
[16:46:02.321] iteration 26733: loss: 0.076350, loss_s1: 0.067752, loss_fp: 0.004961, loss_freq: 0.026485
[16:46:02.955] iteration 26734: loss: 0.044955, loss_s1: 0.032741, loss_fp: 0.002194, loss_freq: 0.014926
[16:46:03.621] iteration 26735: loss: 0.049612, loss_s1: 0.029769, loss_fp: 0.005896, loss_freq: 0.022697
[16:46:04.266] iteration 26736: loss: 0.028946, loss_s1: 0.017338, loss_fp: 0.001660, loss_freq: 0.005980
[16:46:04.900] iteration 26737: loss: 0.046940, loss_s1: 0.036776, loss_fp: 0.001507, loss_freq: 0.019666
[16:46:05.549] iteration 26738: loss: 0.048967, loss_s1: 0.041059, loss_fp: 0.005876, loss_freq: 0.011901
[16:46:06.186] iteration 26739: loss: 0.065524, loss_s1: 0.056617, loss_fp: 0.002790, loss_freq: 0.036246
[16:46:06.818] iteration 26740: loss: 0.045272, loss_s1: 0.024697, loss_fp: 0.003502, loss_freq: 0.020109
[16:46:07.458] iteration 26741: loss: 0.036774, loss_s1: 0.018911, loss_fp: 0.001604, loss_freq: 0.017741
[16:46:08.604] iteration 26742: loss: 0.036975, loss_s1: 0.018314, loss_fp: 0.001793, loss_freq: 0.008791
[16:46:09.239] iteration 26743: loss: 0.060152, loss_s1: 0.049128, loss_fp: 0.002282, loss_freq: 0.032552
[16:46:09.884] iteration 26744: loss: 0.040386, loss_s1: 0.025357, loss_fp: 0.002368, loss_freq: 0.025750
[16:46:10.526] iteration 26745: loss: 0.087701, loss_s1: 0.047948, loss_fp: 0.010964, loss_freq: 0.078654
[16:46:11.169] iteration 26746: loss: 0.052621, loss_s1: 0.034494, loss_fp: 0.001092, loss_freq: 0.036027
[16:46:11.899] iteration 26747: loss: 0.041141, loss_s1: 0.018359, loss_fp: 0.000967, loss_freq: 0.008397
[16:46:12.539] iteration 26748: loss: 0.029893, loss_s1: 0.008108, loss_fp: 0.001853, loss_freq: 0.020160
[16:46:13.195] iteration 26749: loss: 0.069195, loss_s1: 0.041762, loss_fp: 0.011952, loss_freq: 0.016929
[16:46:13.839] iteration 26750: loss: 0.047850, loss_s1: 0.034555, loss_fp: 0.004536, loss_freq: 0.009282
[16:46:14.484] iteration 26751: loss: 0.047511, loss_s1: 0.035687, loss_fp: 0.000460, loss_freq: 0.004267
[16:46:15.128] iteration 26752: loss: 0.055441, loss_s1: 0.039474, loss_fp: 0.002232, loss_freq: 0.024267
[16:46:15.771] iteration 26753: loss: 0.040866, loss_s1: 0.022269, loss_fp: 0.002584, loss_freq: 0.015366
[16:46:16.406] iteration 26754: loss: 0.042633, loss_s1: 0.023119, loss_fp: 0.000691, loss_freq: 0.021130
[16:46:17.040] iteration 26755: loss: 0.026427, loss_s1: 0.013674, loss_fp: 0.002493, loss_freq: 0.007129
[16:46:17.724] iteration 26756: loss: 0.052923, loss_s1: 0.052269, loss_fp: 0.000909, loss_freq: 0.014824
[16:46:18.361] iteration 26757: loss: 0.046416, loss_s1: 0.016920, loss_fp: 0.010231, loss_freq: 0.028622
[16:46:18.999] iteration 26758: loss: 0.050811, loss_s1: 0.025494, loss_fp: 0.002699, loss_freq: 0.036173
[16:46:19.645] iteration 26759: loss: 0.072434, loss_s1: 0.052907, loss_fp: 0.005358, loss_freq: 0.051050
[16:46:20.281] iteration 26760: loss: 0.053999, loss_s1: 0.057986, loss_fp: 0.002947, loss_freq: 0.017991
[16:46:20.953] iteration 26761: loss: 0.031342, loss_s1: 0.012762, loss_fp: 0.001882, loss_freq: 0.020019
[16:46:21.595] iteration 26762: loss: 0.078048, loss_s1: 0.044697, loss_fp: 0.002052, loss_freq: 0.068098
[16:46:22.239] iteration 26763: loss: 0.058926, loss_s1: 0.068800, loss_fp: 0.004315, loss_freq: 0.013008
[16:46:22.875] iteration 26764: loss: 0.029978, loss_s1: 0.004286, loss_fp: 0.003239, loss_freq: 0.019859
[16:46:23.537] iteration 26765: loss: 0.032579, loss_s1: 0.018106, loss_fp: 0.001056, loss_freq: 0.004889
[16:46:24.222] iteration 26766: loss: 0.042661, loss_s1: 0.013227, loss_fp: 0.007835, loss_freq: 0.020474
[16:46:24.900] iteration 26767: loss: 0.060451, loss_s1: 0.027033, loss_fp: 0.003147, loss_freq: 0.042176
[16:46:25.578] iteration 26768: loss: 0.063231, loss_s1: 0.057032, loss_fp: 0.001112, loss_freq: 0.023047
[16:46:26.254] iteration 26769: loss: 0.038837, loss_s1: 0.019592, loss_fp: 0.001429, loss_freq: 0.020954
[16:46:26.926] iteration 26770: loss: 0.057321, loss_s1: 0.038212, loss_fp: 0.002717, loss_freq: 0.022160
[16:46:27.598] iteration 26771: loss: 0.040663, loss_s1: 0.026510, loss_fp: 0.001383, loss_freq: 0.016952
[16:46:28.265] iteration 26772: loss: 0.040516, loss_s1: 0.044467, loss_fp: 0.000822, loss_freq: 0.005103
[16:46:28.942] iteration 26773: loss: 0.062911, loss_s1: 0.055337, loss_fp: 0.002185, loss_freq: 0.024963
[16:46:29.579] iteration 26774: loss: 0.062111, loss_s1: 0.051226, loss_fp: 0.002185, loss_freq: 0.041990
[16:46:30.216] iteration 26775: loss: 0.075036, loss_s1: 0.066266, loss_fp: 0.013136, loss_freq: 0.037164
[16:46:30.855] iteration 26776: loss: 0.048303, loss_s1: 0.024117, loss_fp: 0.004493, loss_freq: 0.017813
[16:46:31.495] iteration 26777: loss: 0.052271, loss_s1: 0.036824, loss_fp: 0.003477, loss_freq: 0.022624
[16:46:32.138] iteration 26778: loss: 0.050876, loss_s1: 0.023712, loss_fp: 0.001829, loss_freq: 0.023130
[16:46:32.772] iteration 26779: loss: 0.069381, loss_s1: 0.054059, loss_fp: 0.002452, loss_freq: 0.049734
[16:46:33.408] iteration 26780: loss: 0.091990, loss_s1: 0.100540, loss_fp: 0.002388, loss_freq: 0.041454
[16:46:34.038] iteration 26781: loss: 0.048921, loss_s1: 0.045635, loss_fp: 0.001074, loss_freq: 0.020242
[16:46:34.670] iteration 26782: loss: 0.049342, loss_s1: 0.038076, loss_fp: 0.005362, loss_freq: 0.013746
[16:46:35.349] iteration 26783: loss: 0.043223, loss_s1: 0.050016, loss_fp: 0.001587, loss_freq: 0.010176
[16:46:35.992] iteration 26784: loss: 0.036501, loss_s1: 0.024704, loss_fp: 0.000983, loss_freq: 0.008149
[16:46:36.633] iteration 26785: loss: 0.087182, loss_s1: 0.106373, loss_fp: 0.008843, loss_freq: 0.020176
[16:46:37.265] iteration 26786: loss: 0.059639, loss_s1: 0.018590, loss_fp: 0.001615, loss_freq: 0.012260
[16:46:37.903] iteration 26787: loss: 0.043194, loss_s1: 0.027187, loss_fp: 0.005768, loss_freq: 0.016650
[16:46:38.535] iteration 26788: loss: 0.049353, loss_s1: 0.031153, loss_fp: 0.002044, loss_freq: 0.019399
[16:46:39.166] iteration 26789: loss: 0.041762, loss_s1: 0.041958, loss_fp: 0.002100, loss_freq: 0.008099
[16:46:39.806] iteration 26790: loss: 0.080407, loss_s1: 0.055407, loss_fp: 0.009079, loss_freq: 0.053063
[16:46:40.443] iteration 26791: loss: 0.049790, loss_s1: 0.026292, loss_fp: 0.001215, loss_freq: 0.019827
[16:46:41.074] iteration 26792: loss: 0.060902, loss_s1: 0.034037, loss_fp: 0.009595, loss_freq: 0.027724
[16:46:41.709] iteration 26793: loss: 0.074524, loss_s1: 0.050251, loss_fp: 0.002959, loss_freq: 0.041648
[16:46:42.346] iteration 26794: loss: 0.033876, loss_s1: 0.019091, loss_fp: 0.001481, loss_freq: 0.012407
[16:46:42.990] iteration 26795: loss: 0.076345, loss_s1: 0.050064, loss_fp: 0.001919, loss_freq: 0.072353
[16:46:43.628] iteration 26796: loss: 0.029511, loss_s1: 0.010019, loss_fp: 0.002533, loss_freq: 0.007470
[16:46:44.306] iteration 26797: loss: 0.057345, loss_s1: 0.020433, loss_fp: 0.003531, loss_freq: 0.008193
[16:46:44.960] iteration 26798: loss: 0.077377, loss_s1: 0.108462, loss_fp: 0.001757, loss_freq: 0.016182
[16:46:45.603] iteration 26799: loss: 0.033070, loss_s1: 0.022223, loss_fp: 0.001458, loss_freq: 0.012399
[16:46:46.251] iteration 26800: loss: 0.048153, loss_s1: 0.046224, loss_fp: 0.001128, loss_freq: 0.014369
[16:46:49.553] iteration 26800 : mean_dice : 0.795506
[16:46:50.225] iteration 26801: loss: 0.059386, loss_s1: 0.058586, loss_fp: 0.003158, loss_freq: 0.017617
[16:46:50.864] iteration 26802: loss: 0.042723, loss_s1: 0.041906, loss_fp: 0.001775, loss_freq: 0.009750
[16:46:51.504] iteration 26803: loss: 0.047014, loss_s1: 0.030109, loss_fp: 0.002563, loss_freq: 0.020885
[16:46:52.135] iteration 26804: loss: 0.053038, loss_s1: 0.024313, loss_fp: 0.005415, loss_freq: 0.039706
[16:46:52.805] iteration 26805: loss: 0.059199, loss_s1: 0.046211, loss_fp: 0.002581, loss_freq: 0.013927
[16:46:53.477] iteration 26806: loss: 0.071527, loss_s1: 0.055703, loss_fp: 0.007033, loss_freq: 0.020238
[16:46:54.147] iteration 26807: loss: 0.035000, loss_s1: 0.013435, loss_fp: 0.001697, loss_freq: 0.017133
[16:46:54.801] iteration 26808: loss: 0.108620, loss_s1: 0.044747, loss_fp: 0.005809, loss_freq: 0.112096
[16:46:55.792] iteration 26809: loss: 0.061173, loss_s1: 0.067671, loss_fp: 0.002237, loss_freq: 0.021011
[16:46:56.731] iteration 26810: loss: 0.049703, loss_s1: 0.050550, loss_fp: 0.002738, loss_freq: 0.011128
[16:46:57.370] iteration 26811: loss: 0.044159, loss_s1: 0.021153, loss_fp: 0.002734, loss_freq: 0.005896
[16:46:58.020] iteration 26812: loss: 0.043963, loss_s1: 0.024577, loss_fp: 0.003784, loss_freq: 0.013548
[16:46:58.663] iteration 26813: loss: 0.045569, loss_s1: 0.017382, loss_fp: 0.007720, loss_freq: 0.021043
[16:46:59.299] iteration 26814: loss: 0.056757, loss_s1: 0.024487, loss_fp: 0.008792, loss_freq: 0.050848
[16:46:59.941] iteration 26815: loss: 0.076003, loss_s1: 0.072175, loss_fp: 0.001701, loss_freq: 0.032232
[16:47:00.578] iteration 26816: loss: 0.087821, loss_s1: 0.109206, loss_fp: 0.003543, loss_freq: 0.035216
[16:47:01.228] iteration 26817: loss: 0.039988, loss_s1: 0.030612, loss_fp: 0.004378, loss_freq: 0.009442
[16:47:01.911] iteration 26818: loss: 0.040084, loss_s1: 0.034406, loss_fp: 0.004181, loss_freq: 0.015606
[16:47:02.543] iteration 26819: loss: 0.040016, loss_s1: 0.022058, loss_fp: 0.004812, loss_freq: 0.011240
[16:47:03.183] iteration 26820: loss: 0.060475, loss_s1: 0.049127, loss_fp: 0.007539, loss_freq: 0.018210
[16:47:03.821] iteration 26821: loss: 0.075811, loss_s1: 0.056803, loss_fp: 0.007645, loss_freq: 0.029199
[16:47:04.473] iteration 26822: loss: 0.031849, loss_s1: 0.021356, loss_fp: 0.001300, loss_freq: 0.006011
[16:47:05.119] iteration 26823: loss: 0.065389, loss_s1: 0.059168, loss_fp: 0.013100, loss_freq: 0.022352
[16:47:05.756] iteration 26824: loss: 0.041376, loss_s1: 0.024516, loss_fp: 0.000860, loss_freq: 0.017817
[16:47:06.387] iteration 26825: loss: 0.036189, loss_s1: 0.028738, loss_fp: 0.007635, loss_freq: 0.008680
[16:47:07.033] iteration 26826: loss: 0.064511, loss_s1: 0.069615, loss_fp: 0.002942, loss_freq: 0.022258
[16:47:07.678] iteration 26827: loss: 0.044095, loss_s1: 0.010260, loss_fp: 0.007845, loss_freq: 0.035599
[16:47:08.314] iteration 26828: loss: 0.046170, loss_s1: 0.042650, loss_fp: 0.001861, loss_freq: 0.007644
[16:47:08.953] iteration 26829: loss: 0.041251, loss_s1: 0.022978, loss_fp: 0.000613, loss_freq: 0.023918
[16:47:09.600] iteration 26830: loss: 0.031604, loss_s1: 0.021464, loss_fp: 0.001736, loss_freq: 0.012894
[16:47:10.243] iteration 26831: loss: 0.045336, loss_s1: 0.045117, loss_fp: 0.003827, loss_freq: 0.007593
[16:47:10.877] iteration 26832: loss: 0.054589, loss_s1: 0.015337, loss_fp: 0.003289, loss_freq: 0.022492
[16:47:11.520] iteration 26833: loss: 0.045570, loss_s1: 0.021653, loss_fp: 0.002172, loss_freq: 0.038223
[16:47:12.158] iteration 26834: loss: 0.054319, loss_s1: 0.053978, loss_fp: 0.002146, loss_freq: 0.009930
[16:47:12.813] iteration 26835: loss: 0.040271, loss_s1: 0.037026, loss_fp: 0.001093, loss_freq: 0.004886
[16:47:13.449] iteration 26836: loss: 0.045598, loss_s1: 0.027738, loss_fp: 0.002860, loss_freq: 0.024181
[16:47:14.091] iteration 26837: loss: 0.032021, loss_s1: 0.011548, loss_fp: 0.001429, loss_freq: 0.003226
[16:47:14.736] iteration 26838: loss: 0.099839, loss_s1: 0.055724, loss_fp: 0.005907, loss_freq: 0.096109
[16:47:15.391] iteration 26839: loss: 0.036048, loss_s1: 0.017281, loss_fp: 0.001113, loss_freq: 0.016215
[16:47:16.030] iteration 26840: loss: 0.050003, loss_s1: 0.045477, loss_fp: 0.001731, loss_freq: 0.011222
[16:47:16.680] iteration 26841: loss: 0.084799, loss_s1: 0.067194, loss_fp: 0.005832, loss_freq: 0.051417
[16:47:17.318] iteration 26842: loss: 0.071811, loss_s1: 0.083532, loss_fp: 0.002246, loss_freq: 0.017190
[16:47:17.954] iteration 26843: loss: 0.065721, loss_s1: 0.049016, loss_fp: 0.003738, loss_freq: 0.033386
[16:47:18.583] iteration 26844: loss: 0.091032, loss_s1: 0.100259, loss_fp: 0.002521, loss_freq: 0.047642
[16:47:19.218] iteration 26845: loss: 0.038311, loss_s1: 0.027773, loss_fp: 0.000732, loss_freq: 0.014261
[16:47:19.863] iteration 26846: loss: 0.057346, loss_s1: 0.038409, loss_fp: 0.000503, loss_freq: 0.008729
[16:47:20.501] iteration 26847: loss: 0.048287, loss_s1: 0.025396, loss_fp: 0.002539, loss_freq: 0.029929
[16:47:21.143] iteration 26848: loss: 0.072739, loss_s1: 0.042695, loss_fp: 0.002732, loss_freq: 0.052371
[16:47:21.783] iteration 26849: loss: 0.081481, loss_s1: 0.108604, loss_fp: 0.006624, loss_freq: 0.018977
[16:47:22.433] iteration 26850: loss: 0.071506, loss_s1: 0.051641, loss_fp: 0.004338, loss_freq: 0.026219
[16:47:23.065] iteration 26851: loss: 0.063632, loss_s1: 0.048927, loss_fp: 0.009050, loss_freq: 0.038820
[16:47:23.702] iteration 26852: loss: 0.051124, loss_s1: 0.060660, loss_fp: 0.002215, loss_freq: 0.007851
[16:47:24.339] iteration 26853: loss: 0.048280, loss_s1: 0.027706, loss_fp: 0.009941, loss_freq: 0.032946
[16:47:24.980] iteration 26854: loss: 0.050812, loss_s1: 0.017315, loss_fp: 0.001888, loss_freq: 0.018301
[16:47:25.615] iteration 26855: loss: 0.052667, loss_s1: 0.026948, loss_fp: 0.018844, loss_freq: 0.023075
[16:47:26.260] iteration 26856: loss: 0.047597, loss_s1: 0.025187, loss_fp: 0.001704, loss_freq: 0.022948
[16:47:26.899] iteration 26857: loss: 0.041082, loss_s1: 0.031335, loss_fp: 0.003264, loss_freq: 0.012564
[16:47:27.531] iteration 26858: loss: 0.051298, loss_s1: 0.036648, loss_fp: 0.007477, loss_freq: 0.011734
[16:47:28.171] iteration 26859: loss: 0.065352, loss_s1: 0.051805, loss_fp: 0.023620, loss_freq: 0.022272
[16:47:28.809] iteration 26860: loss: 0.059538, loss_s1: 0.071474, loss_fp: 0.003116, loss_freq: 0.012473
[16:47:29.443] iteration 26861: loss: 0.039679, loss_s1: 0.012203, loss_fp: 0.000875, loss_freq: 0.030575
[16:47:30.076] iteration 26862: loss: 0.045210, loss_s1: 0.026129, loss_fp: 0.003162, loss_freq: 0.024870
[16:47:30.718] iteration 26863: loss: 0.049194, loss_s1: 0.035515, loss_fp: 0.003910, loss_freq: 0.022211
[16:47:31.353] iteration 26864: loss: 0.027586, loss_s1: 0.010058, loss_fp: 0.003226, loss_freq: 0.003376
[16:47:31.995] iteration 26865: loss: 0.063581, loss_s1: 0.062876, loss_fp: 0.003457, loss_freq: 0.032917
[16:47:32.628] iteration 26866: loss: 0.053299, loss_s1: 0.047730, loss_fp: 0.002085, loss_freq: 0.018401
[16:47:33.259] iteration 26867: loss: 0.049075, loss_s1: 0.037568, loss_fp: 0.002599, loss_freq: 0.012424
[16:47:33.900] iteration 26868: loss: 0.041602, loss_s1: 0.022488, loss_fp: 0.001683, loss_freq: 0.024506
[16:47:34.531] iteration 26869: loss: 0.039901, loss_s1: 0.037742, loss_fp: 0.001997, loss_freq: 0.012291
[16:47:35.161] iteration 26870: loss: 0.041189, loss_s1: 0.035108, loss_fp: 0.004709, loss_freq: 0.013693
[16:47:35.797] iteration 26871: loss: 0.050602, loss_s1: 0.050259, loss_fp: 0.002223, loss_freq: 0.013822
[16:47:36.439] iteration 26872: loss: 0.047206, loss_s1: 0.028163, loss_fp: 0.002056, loss_freq: 0.025546
[16:47:37.080] iteration 26873: loss: 0.065607, loss_s1: 0.048748, loss_fp: 0.002268, loss_freq: 0.035317
[16:47:37.719] iteration 26874: loss: 0.041439, loss_s1: 0.029417, loss_fp: 0.006188, loss_freq: 0.012088
[16:47:38.354] iteration 26875: loss: 0.070630, loss_s1: 0.060437, loss_fp: 0.004139, loss_freq: 0.028059
[16:47:39.017] iteration 26876: loss: 0.059684, loss_s1: 0.038061, loss_fp: 0.009287, loss_freq: 0.038287
[16:47:39.695] iteration 26877: loss: 0.084076, loss_s1: 0.093624, loss_fp: 0.017894, loss_freq: 0.014998
[16:47:40.371] iteration 26878: loss: 0.060620, loss_s1: 0.064203, loss_fp: 0.007044, loss_freq: 0.011021
[16:47:41.006] iteration 26879: loss: 0.028606, loss_s1: 0.012879, loss_fp: 0.001473, loss_freq: 0.010043
[16:47:41.634] iteration 26880: loss: 0.071747, loss_s1: 0.080134, loss_fp: 0.001589, loss_freq: 0.028001
[16:47:42.284] iteration 26881: loss: 0.052846, loss_s1: 0.027597, loss_fp: 0.004218, loss_freq: 0.012018
[16:47:42.929] iteration 26882: loss: 0.057026, loss_s1: 0.043806, loss_fp: 0.002845, loss_freq: 0.032668
[16:47:43.568] iteration 26883: loss: 0.085442, loss_s1: 0.073149, loss_fp: 0.005254, loss_freq: 0.038193
[16:47:44.203] iteration 26884: loss: 0.037658, loss_s1: 0.017137, loss_fp: 0.003104, loss_freq: 0.021961
[16:47:45.149] iteration 26885: loss: 0.045214, loss_s1: 0.040103, loss_fp: 0.003187, loss_freq: 0.007908
[16:47:45.786] iteration 26886: loss: 0.054984, loss_s1: 0.050901, loss_fp: 0.001502, loss_freq: 0.014146
[16:47:46.429] iteration 26887: loss: 0.035132, loss_s1: 0.018073, loss_fp: 0.005257, loss_freq: 0.015498
[16:47:47.070] iteration 26888: loss: 0.050180, loss_s1: 0.024904, loss_fp: 0.005287, loss_freq: 0.027894
[16:47:47.712] iteration 26889: loss: 0.068820, loss_s1: 0.091536, loss_fp: 0.005019, loss_freq: 0.013028
[16:47:48.354] iteration 26890: loss: 0.033667, loss_s1: 0.014576, loss_fp: 0.002620, loss_freq: 0.009246
[16:47:48.994] iteration 26891: loss: 0.026215, loss_s1: 0.007114, loss_fp: 0.002426, loss_freq: 0.016453
[16:47:49.643] iteration 26892: loss: 0.035722, loss_s1: 0.024172, loss_fp: 0.001482, loss_freq: 0.011528
[16:47:50.281] iteration 26893: loss: 0.044911, loss_s1: 0.034292, loss_fp: 0.000684, loss_freq: 0.013438
[16:47:50.928] iteration 26894: loss: 0.031958, loss_s1: 0.006426, loss_fp: 0.001915, loss_freq: 0.007500
[16:47:51.569] iteration 26895: loss: 0.060521, loss_s1: 0.056429, loss_fp: 0.003439, loss_freq: 0.031049
[16:47:52.213] iteration 26896: loss: 0.038926, loss_s1: 0.023414, loss_fp: 0.004224, loss_freq: 0.008874
[16:47:52.853] iteration 26897: loss: 0.061718, loss_s1: 0.065040, loss_fp: 0.002693, loss_freq: 0.017998
[16:47:53.492] iteration 26898: loss: 0.044785, loss_s1: 0.018137, loss_fp: 0.015826, loss_freq: 0.025970
[16:47:54.128] iteration 26899: loss: 0.037528, loss_s1: 0.014049, loss_fp: 0.003090, loss_freq: 0.014916
[16:47:54.771] iteration 26900: loss: 0.037677, loss_s1: 0.023086, loss_fp: 0.007730, loss_freq: 0.015512
[16:47:55.402] iteration 26901: loss: 0.043373, loss_s1: 0.024102, loss_fp: 0.001693, loss_freq: 0.021944
[16:47:56.049] iteration 26902: loss: 0.047161, loss_s1: 0.038079, loss_fp: 0.004020, loss_freq: 0.019782
[16:47:56.703] iteration 26903: loss: 0.065749, loss_s1: 0.079897, loss_fp: 0.002561, loss_freq: 0.018625
[16:47:57.350] iteration 26904: loss: 0.032292, loss_s1: 0.018141, loss_fp: 0.005326, loss_freq: 0.012544
[16:47:57.985] iteration 26905: loss: 0.063949, loss_s1: 0.016848, loss_fp: 0.001757, loss_freq: 0.032290
[16:47:58.623] iteration 26906: loss: 0.042065, loss_s1: 0.029349, loss_fp: 0.002682, loss_freq: 0.020556
[16:47:59.254] iteration 26907: loss: 0.046813, loss_s1: 0.031924, loss_fp: 0.004444, loss_freq: 0.026504
[16:47:59.954] iteration 26908: loss: 0.038520, loss_s1: 0.026843, loss_fp: 0.001940, loss_freq: 0.020837
[16:48:00.625] iteration 26909: loss: 0.033487, loss_s1: 0.013155, loss_fp: 0.002317, loss_freq: 0.017905
[16:48:01.297] iteration 26910: loss: 0.074917, loss_s1: 0.038356, loss_fp: 0.003924, loss_freq: 0.057793
[16:48:01.937] iteration 26911: loss: 0.086134, loss_s1: 0.061435, loss_fp: 0.005597, loss_freq: 0.056014
[16:48:02.634] iteration 26912: loss: 0.053694, loss_s1: 0.025372, loss_fp: 0.001310, loss_freq: 0.037015
[16:48:03.311] iteration 26913: loss: 0.065485, loss_s1: 0.052527, loss_fp: 0.001522, loss_freq: 0.035992
[16:48:03.968] iteration 26914: loss: 0.043630, loss_s1: 0.021931, loss_fp: 0.004701, loss_freq: 0.013871
[16:48:04.612] iteration 26915: loss: 0.060150, loss_s1: 0.041069, loss_fp: 0.001901, loss_freq: 0.027972
[16:48:05.259] iteration 26916: loss: 0.048145, loss_s1: 0.019350, loss_fp: 0.005451, loss_freq: 0.015810
[16:48:05.903] iteration 26917: loss: 0.089899, loss_s1: 0.084572, loss_fp: 0.003460, loss_freq: 0.064896
[16:48:06.543] iteration 26918: loss: 0.064387, loss_s1: 0.060667, loss_fp: 0.005086, loss_freq: 0.027084
[16:48:07.185] iteration 26919: loss: 0.050424, loss_s1: 0.042237, loss_fp: 0.005375, loss_freq: 0.015561
[16:48:07.823] iteration 26920: loss: 0.061540, loss_s1: 0.042414, loss_fp: 0.001479, loss_freq: 0.030367
[16:48:08.508] iteration 26921: loss: 0.057530, loss_s1: 0.037708, loss_fp: 0.004249, loss_freq: 0.023855
[16:48:09.186] iteration 26922: loss: 0.060631, loss_s1: 0.049442, loss_fp: 0.006728, loss_freq: 0.036191
[16:48:09.840] iteration 26923: loss: 0.111714, loss_s1: 0.090244, loss_fp: 0.000887, loss_freq: 0.073846
[16:48:10.485] iteration 26924: loss: 0.045723, loss_s1: 0.046109, loss_fp: 0.005946, loss_freq: 0.012091
[16:48:11.119] iteration 26925: loss: 0.080290, loss_s1: 0.053654, loss_fp: 0.001458, loss_freq: 0.018261
[16:48:11.751] iteration 26926: loss: 0.041762, loss_s1: 0.015173, loss_fp: 0.005168, loss_freq: 0.035979
[16:48:12.396] iteration 26927: loss: 0.039708, loss_s1: 0.017250, loss_fp: 0.002838, loss_freq: 0.021210
[16:48:13.040] iteration 26928: loss: 0.061214, loss_s1: 0.057276, loss_fp: 0.002388, loss_freq: 0.029258
[16:48:13.699] iteration 26929: loss: 0.034604, loss_s1: 0.010605, loss_fp: 0.000886, loss_freq: 0.002478
[16:48:14.351] iteration 26930: loss: 0.064734, loss_s1: 0.052006, loss_fp: 0.006695, loss_freq: 0.034906
[16:48:14.994] iteration 26931: loss: 0.051287, loss_s1: 0.036374, loss_fp: 0.001060, loss_freq: 0.026204
[16:48:15.637] iteration 26932: loss: 0.047208, loss_s1: 0.028192, loss_fp: 0.004195, loss_freq: 0.028042
[16:48:16.278] iteration 26933: loss: 0.075003, loss_s1: 0.063867, loss_fp: 0.005080, loss_freq: 0.033708
[16:48:16.916] iteration 26934: loss: 0.045875, loss_s1: 0.020232, loss_fp: 0.001488, loss_freq: 0.021641
[16:48:17.563] iteration 26935: loss: 0.058144, loss_s1: 0.033908, loss_fp: 0.009567, loss_freq: 0.039686
[16:48:18.200] iteration 26936: loss: 0.038073, loss_s1: 0.021956, loss_fp: 0.002163, loss_freq: 0.020938
[16:48:18.841] iteration 26937: loss: 0.042219, loss_s1: 0.031758, loss_fp: 0.003179, loss_freq: 0.016754
[16:48:19.483] iteration 26938: loss: 0.099561, loss_s1: 0.079583, loss_fp: 0.016760, loss_freq: 0.064137
[16:48:20.127] iteration 26939: loss: 0.038997, loss_s1: 0.040565, loss_fp: 0.001238, loss_freq: 0.008338
[16:48:20.774] iteration 26940: loss: 0.038502, loss_s1: 0.019700, loss_fp: 0.000872, loss_freq: 0.006934
[16:48:21.417] iteration 26941: loss: 0.049681, loss_s1: 0.055453, loss_fp: 0.001056, loss_freq: 0.013904
[16:48:22.058] iteration 26942: loss: 0.051674, loss_s1: 0.051514, loss_fp: 0.003010, loss_freq: 0.013595
[16:48:22.703] iteration 26943: loss: 0.064656, loss_s1: 0.032555, loss_fp: 0.003061, loss_freq: 0.058749
[16:48:23.345] iteration 26944: loss: 0.049269, loss_s1: 0.032945, loss_fp: 0.007765, loss_freq: 0.020386
[16:48:23.966] iteration 26945: loss: 0.046643, loss_s1: 0.019048, loss_fp: 0.015640, loss_freq: 0.019930
[16:48:24.603] iteration 26946: loss: 0.053035, loss_s1: 0.055201, loss_fp: 0.000952, loss_freq: 0.012101
[16:48:25.239] iteration 26947: loss: 0.106149, loss_s1: 0.123839, loss_fp: 0.021384, loss_freq: 0.029631
[16:48:25.880] iteration 26948: loss: 0.047024, loss_s1: 0.026678, loss_fp: 0.004099, loss_freq: 0.022114
[16:48:26.522] iteration 26949: loss: 0.058392, loss_s1: 0.045440, loss_fp: 0.000773, loss_freq: 0.016358
[16:48:27.171] iteration 26950: loss: 0.064831, loss_s1: 0.067711, loss_fp: 0.001898, loss_freq: 0.019867
[16:48:27.808] iteration 26951: loss: 0.094430, loss_s1: 0.069634, loss_fp: 0.003199, loss_freq: 0.070094
[16:48:28.440] iteration 26952: loss: 0.037144, loss_s1: 0.024519, loss_fp: 0.002272, loss_freq: 0.017093
[16:48:29.081] iteration 26953: loss: 0.039414, loss_s1: 0.021263, loss_fp: 0.004098, loss_freq: 0.016126
[16:48:29.724] iteration 26954: loss: 0.056190, loss_s1: 0.039570, loss_fp: 0.006626, loss_freq: 0.022249
[16:48:30.360] iteration 26955: loss: 0.051062, loss_s1: 0.040792, loss_fp: 0.003203, loss_freq: 0.023479
[16:48:30.997] iteration 26956: loss: 0.068575, loss_s1: 0.051093, loss_fp: 0.008010, loss_freq: 0.035611
[16:48:31.635] iteration 26957: loss: 0.049434, loss_s1: 0.038636, loss_fp: 0.014005, loss_freq: 0.009975
[16:48:32.285] iteration 26958: loss: 0.055206, loss_s1: 0.035030, loss_fp: 0.012113, loss_freq: 0.025237
[16:48:32.925] iteration 26959: loss: 0.042100, loss_s1: 0.014662, loss_fp: 0.004079, loss_freq: 0.040127
[16:48:33.575] iteration 26960: loss: 0.049884, loss_s1: 0.020528, loss_fp: 0.004777, loss_freq: 0.009714
[16:48:34.211] iteration 26961: loss: 0.053228, loss_s1: 0.028403, loss_fp: 0.003813, loss_freq: 0.045489
[16:48:34.848] iteration 26962: loss: 0.037934, loss_s1: 0.008971, loss_fp: 0.009665, loss_freq: 0.019327
[16:48:35.484] iteration 26963: loss: 0.088972, loss_s1: 0.105200, loss_fp: 0.006590, loss_freq: 0.032808
[16:48:36.122] iteration 26964: loss: 0.098831, loss_s1: 0.086927, loss_fp: 0.022767, loss_freq: 0.032123
[16:48:36.773] iteration 26965: loss: 0.037269, loss_s1: 0.024121, loss_fp: 0.000894, loss_freq: 0.009810
[16:48:37.407] iteration 26966: loss: 0.064108, loss_s1: 0.024552, loss_fp: 0.001577, loss_freq: 0.051589
[16:48:38.053] iteration 26967: loss: 0.060612, loss_s1: 0.035506, loss_fp: 0.004070, loss_freq: 0.038679
[16:48:38.690] iteration 26968: loss: 0.039064, loss_s1: 0.029786, loss_fp: 0.004909, loss_freq: 0.017879
[16:48:39.330] iteration 26969: loss: 0.046385, loss_s1: 0.037151, loss_fp: 0.002316, loss_freq: 0.018831
[16:48:39.966] iteration 26970: loss: 0.057921, loss_s1: 0.028916, loss_fp: 0.007315, loss_freq: 0.044170
[16:48:40.598] iteration 26971: loss: 0.056720, loss_s1: 0.026474, loss_fp: 0.002761, loss_freq: 0.004579
[16:48:41.237] iteration 26972: loss: 0.032810, loss_s1: 0.009526, loss_fp: 0.001669, loss_freq: 0.019584
[16:48:41.875] iteration 26973: loss: 0.027596, loss_s1: 0.015181, loss_fp: 0.000880, loss_freq: 0.007844
[16:48:42.514] iteration 26974: loss: 0.063943, loss_s1: 0.073065, loss_fp: 0.004569, loss_freq: 0.016776
[16:48:43.151] iteration 26975: loss: 0.045363, loss_s1: 0.019493, loss_fp: 0.006105, loss_freq: 0.025251
[16:48:43.793] iteration 26976: loss: 0.046386, loss_s1: 0.034089, loss_fp: 0.002512, loss_freq: 0.024438
[16:48:44.437] iteration 26977: loss: 0.041102, loss_s1: 0.020986, loss_fp: 0.001471, loss_freq: 0.012607
[16:48:45.071] iteration 26978: loss: 0.032635, loss_s1: 0.012259, loss_fp: 0.001603, loss_freq: 0.007363
[16:48:45.725] iteration 26979: loss: 0.041431, loss_s1: 0.032998, loss_fp: 0.001830, loss_freq: 0.010034
[16:48:46.362] iteration 26980: loss: 0.049887, loss_s1: 0.038515, loss_fp: 0.004764, loss_freq: 0.014573
[16:48:46.998] iteration 26981: loss: 0.069828, loss_s1: 0.048239, loss_fp: 0.004640, loss_freq: 0.047950
[16:48:47.633] iteration 26982: loss: 0.035542, loss_s1: 0.016396, loss_fp: 0.000940, loss_freq: 0.012979
[16:48:48.273] iteration 26983: loss: 0.033327, loss_s1: 0.005253, loss_fp: 0.008685, loss_freq: 0.015856
[16:48:48.909] iteration 26984: loss: 0.055533, loss_s1: 0.033237, loss_fp: 0.007104, loss_freq: 0.022137
[16:48:49.542] iteration 26985: loss: 0.037042, loss_s1: 0.019035, loss_fp: 0.001654, loss_freq: 0.022916
[16:48:50.177] iteration 26986: loss: 0.053288, loss_s1: 0.036673, loss_fp: 0.004315, loss_freq: 0.019368
[16:48:50.815] iteration 26987: loss: 0.097620, loss_s1: 0.103179, loss_fp: 0.001909, loss_freq: 0.063949
[16:48:51.450] iteration 26988: loss: 0.042577, loss_s1: 0.022763, loss_fp: 0.001458, loss_freq: 0.024594
[16:48:52.097] iteration 26989: loss: 0.064097, loss_s1: 0.023443, loss_fp: 0.003277, loss_freq: 0.014024
[16:48:52.732] iteration 26990: loss: 0.047379, loss_s1: 0.012447, loss_fp: 0.003361, loss_freq: 0.041891
[16:48:53.362] iteration 26991: loss: 0.078461, loss_s1: 0.049637, loss_fp: 0.007165, loss_freq: 0.053859
[16:48:53.993] iteration 26992: loss: 0.103409, loss_s1: 0.083386, loss_fp: 0.004382, loss_freq: 0.084999
[16:48:54.627] iteration 26993: loss: 0.055080, loss_s1: 0.026615, loss_fp: 0.002644, loss_freq: 0.033209
[16:48:55.273] iteration 26994: loss: 0.071023, loss_s1: 0.058256, loss_fp: 0.005583, loss_freq: 0.052638
[16:48:55.920] iteration 26995: loss: 0.071877, loss_s1: 0.056640, loss_fp: 0.013477, loss_freq: 0.019260
[16:48:56.593] iteration 26996: loss: 0.046138, loss_s1: 0.030585, loss_fp: 0.003332, loss_freq: 0.032748
[16:48:57.292] iteration 26997: loss: 0.044007, loss_s1: 0.016446, loss_fp: 0.002037, loss_freq: 0.012400
[16:48:57.997] iteration 26998: loss: 0.074583, loss_s1: 0.075088, loss_fp: 0.006451, loss_freq: 0.026351
[16:48:58.644] iteration 26999: loss: 0.062994, loss_s1: 0.044567, loss_fp: 0.002889, loss_freq: 0.017626
[16:48:59.304] iteration 27000: loss: 0.035827, loss_s1: 0.014619, loss_fp: 0.001245, loss_freq: 0.019597
[16:49:03.558] iteration 27000 : mean_dice : 0.796500
[16:49:04.247] iteration 27001: loss: 0.086631, loss_s1: 0.040255, loss_fp: 0.008029, loss_freq: 0.085620
[16:49:04.892] iteration 27002: loss: 0.072465, loss_s1: 0.064535, loss_fp: 0.006849, loss_freq: 0.031453
[16:49:05.530] iteration 27003: loss: 0.055050, loss_s1: 0.048479, loss_fp: 0.001661, loss_freq: 0.031886
[16:49:06.170] iteration 27004: loss: 0.064718, loss_s1: 0.049819, loss_fp: 0.001493, loss_freq: 0.038009
[16:49:06.810] iteration 27005: loss: 0.102299, loss_s1: 0.066018, loss_fp: 0.003368, loss_freq: 0.059766
[16:49:07.460] iteration 27006: loss: 0.074960, loss_s1: 0.039087, loss_fp: 0.007385, loss_freq: 0.021933
[16:49:08.087] iteration 27007: loss: 0.030587, loss_s1: 0.013334, loss_fp: 0.001192, loss_freq: 0.008973
[16:49:08.717] iteration 27008: loss: 0.045361, loss_s1: 0.020881, loss_fp: 0.015125, loss_freq: 0.017687
[16:49:09.363] iteration 27009: loss: 0.056457, loss_s1: 0.066470, loss_fp: 0.006208, loss_freq: 0.014659
[16:49:10.016] iteration 27010: loss: 0.075292, loss_s1: 0.068000, loss_fp: 0.003741, loss_freq: 0.008024
[16:49:10.651] iteration 27011: loss: 0.052882, loss_s1: 0.049287, loss_fp: 0.001716, loss_freq: 0.018979
[16:49:11.289] iteration 27012: loss: 0.048406, loss_s1: 0.036801, loss_fp: 0.003510, loss_freq: 0.012321
[16:49:11.954] iteration 27013: loss: 0.078633, loss_s1: 0.053525, loss_fp: 0.000965, loss_freq: 0.025007
[16:49:12.596] iteration 27014: loss: 0.030066, loss_s1: 0.012209, loss_fp: 0.003023, loss_freq: 0.010789
[16:49:13.236] iteration 27015: loss: 0.054446, loss_s1: 0.055712, loss_fp: 0.003396, loss_freq: 0.009733
[16:49:13.908] iteration 27016: loss: 0.049077, loss_s1: 0.038597, loss_fp: 0.002634, loss_freq: 0.016744
[16:49:14.578] iteration 27017: loss: 0.040241, loss_s1: 0.028565, loss_fp: 0.003420, loss_freq: 0.012892
[16:49:15.260] iteration 27018: loss: 0.073422, loss_s1: 0.085076, loss_fp: 0.003845, loss_freq: 0.020053
[16:49:15.931] iteration 27019: loss: 0.049610, loss_s1: 0.034358, loss_fp: 0.005611, loss_freq: 0.017260
[16:49:16.565] iteration 27020: loss: 0.087358, loss_s1: 0.066613, loss_fp: 0.002109, loss_freq: 0.058178
[16:49:17.199] iteration 27021: loss: 0.058772, loss_s1: 0.031715, loss_fp: 0.002267, loss_freq: 0.024164
[16:49:17.827] iteration 27022: loss: 0.045172, loss_s1: 0.047739, loss_fp: 0.002405, loss_freq: 0.008972
[16:49:18.480] iteration 27023: loss: 0.039091, loss_s1: 0.033051, loss_fp: 0.000512, loss_freq: 0.011588
[16:49:19.120] iteration 27024: loss: 0.050350, loss_s1: 0.034722, loss_fp: 0.001620, loss_freq: 0.019281
[16:49:19.761] iteration 27025: loss: 0.058157, loss_s1: 0.061330, loss_fp: 0.000941, loss_freq: 0.019458
[16:49:20.388] iteration 27026: loss: 0.085999, loss_s1: 0.076962, loss_fp: 0.009438, loss_freq: 0.044230
[16:49:21.020] iteration 27027: loss: 0.045668, loss_s1: 0.040345, loss_fp: 0.001475, loss_freq: 0.019981
[16:49:21.990] iteration 27028: loss: 0.064872, loss_s1: 0.069675, loss_fp: 0.000879, loss_freq: 0.014541
[16:49:22.623] iteration 27029: loss: 0.048668, loss_s1: 0.033942, loss_fp: 0.002010, loss_freq: 0.017726
[16:49:23.252] iteration 27030: loss: 0.036874, loss_s1: 0.009575, loss_fp: 0.000872, loss_freq: 0.021125
[16:49:23.885] iteration 27031: loss: 0.060699, loss_s1: 0.073789, loss_fp: 0.000876, loss_freq: 0.010332
[16:49:24.523] iteration 27032: loss: 0.043360, loss_s1: 0.031051, loss_fp: 0.002096, loss_freq: 0.024942
[16:49:25.157] iteration 27033: loss: 0.045605, loss_s1: 0.038579, loss_fp: 0.001678, loss_freq: 0.010856
[16:49:25.790] iteration 27034: loss: 0.029281, loss_s1: 0.014537, loss_fp: 0.004489, loss_freq: 0.010272
[16:49:26.428] iteration 27035: loss: 0.049947, loss_s1: 0.026514, loss_fp: 0.004149, loss_freq: 0.025548
[16:49:27.065] iteration 27036: loss: 0.053397, loss_s1: 0.037813, loss_fp: 0.004228, loss_freq: 0.017298
[16:49:27.713] iteration 27037: loss: 0.035819, loss_s1: 0.023059, loss_fp: 0.001851, loss_freq: 0.003514
[16:49:28.383] iteration 27038: loss: 0.055666, loss_s1: 0.023582, loss_fp: 0.005140, loss_freq: 0.030743
[16:49:29.054] iteration 27039: loss: 0.056319, loss_s1: 0.027321, loss_fp: 0.001714, loss_freq: 0.042573
[16:49:29.725] iteration 27040: loss: 0.063446, loss_s1: 0.077682, loss_fp: 0.009286, loss_freq: 0.004797
[16:49:30.372] iteration 27041: loss: 0.033652, loss_s1: 0.013363, loss_fp: 0.002191, loss_freq: 0.010316
[16:49:31.003] iteration 27042: loss: 0.063220, loss_s1: 0.020608, loss_fp: 0.026469, loss_freq: 0.045438
[16:49:31.634] iteration 27043: loss: 0.039926, loss_s1: 0.024334, loss_fp: 0.004291, loss_freq: 0.018568
[16:49:32.266] iteration 27044: loss: 0.039887, loss_s1: 0.021518, loss_fp: 0.001894, loss_freq: 0.016760
[16:49:32.895] iteration 27045: loss: 0.043932, loss_s1: 0.027494, loss_fp: 0.000765, loss_freq: 0.025289
[16:49:33.535] iteration 27046: loss: 0.052744, loss_s1: 0.041603, loss_fp: 0.001417, loss_freq: 0.033582
[16:49:34.172] iteration 27047: loss: 0.040121, loss_s1: 0.021710, loss_fp: 0.001256, loss_freq: 0.017301
[16:49:34.807] iteration 27048: loss: 0.075142, loss_s1: 0.065449, loss_fp: 0.001433, loss_freq: 0.037296
[16:49:35.445] iteration 27049: loss: 0.046413, loss_s1: 0.039432, loss_fp: 0.000758, loss_freq: 0.014535
[16:49:36.088] iteration 27050: loss: 0.035788, loss_s1: 0.017413, loss_fp: 0.002830, loss_freq: 0.011149
[16:49:36.732] iteration 27051: loss: 0.033052, loss_s1: 0.010739, loss_fp: 0.000499, loss_freq: 0.009800
[16:49:37.376] iteration 27052: loss: 0.026843, loss_s1: 0.006770, loss_fp: 0.000701, loss_freq: 0.010873
[16:49:38.017] iteration 27053: loss: 0.061433, loss_s1: 0.049675, loss_fp: 0.004327, loss_freq: 0.013997
[16:49:38.666] iteration 27054: loss: 0.060388, loss_s1: 0.020152, loss_fp: 0.003331, loss_freq: 0.048423
[16:49:39.362] iteration 27055: loss: 0.044685, loss_s1: 0.035987, loss_fp: 0.000884, loss_freq: 0.007900
[16:49:40.050] iteration 27056: loss: 0.092824, loss_s1: 0.087283, loss_fp: 0.002124, loss_freq: 0.052730
[16:49:40.738] iteration 27057: loss: 0.060439, loss_s1: 0.016937, loss_fp: 0.000484, loss_freq: 0.018228
[16:49:41.436] iteration 27058: loss: 0.034533, loss_s1: 0.017901, loss_fp: 0.001934, loss_freq: 0.009204
[16:49:42.134] iteration 27059: loss: 0.048591, loss_s1: 0.034612, loss_fp: 0.004783, loss_freq: 0.019916
[16:49:42.780] iteration 27060: loss: 0.045141, loss_s1: 0.021763, loss_fp: 0.003106, loss_freq: 0.036431
[16:49:43.420] iteration 27061: loss: 0.044019, loss_s1: 0.018844, loss_fp: 0.013093, loss_freq: 0.020916
[16:49:44.061] iteration 27062: loss: 0.053814, loss_s1: 0.018399, loss_fp: 0.005864, loss_freq: 0.020802
[16:49:44.699] iteration 27063: loss: 0.055487, loss_s1: 0.029668, loss_fp: 0.002358, loss_freq: 0.021141
[16:49:45.351] iteration 27064: loss: 0.043017, loss_s1: 0.024755, loss_fp: 0.001721, loss_freq: 0.020552
[16:49:45.995] iteration 27065: loss: 0.042221, loss_s1: 0.027801, loss_fp: 0.002889, loss_freq: 0.021371
[16:49:46.635] iteration 27066: loss: 0.094927, loss_s1: 0.076482, loss_fp: 0.003615, loss_freq: 0.056195
[16:49:47.287] iteration 27067: loss: 0.034468, loss_s1: 0.024571, loss_fp: 0.003455, loss_freq: 0.010297
[16:49:47.941] iteration 27068: loss: 0.100503, loss_s1: 0.056348, loss_fp: 0.003312, loss_freq: 0.043511
[16:49:48.578] iteration 27069: loss: 0.034073, loss_s1: 0.012764, loss_fp: 0.001901, loss_freq: 0.027670
[16:49:49.217] iteration 27070: loss: 0.052416, loss_s1: 0.032498, loss_fp: 0.003242, loss_freq: 0.031424
[16:49:49.852] iteration 27071: loss: 0.039724, loss_s1: 0.031105, loss_fp: 0.004021, loss_freq: 0.015105
[16:49:50.494] iteration 27072: loss: 0.044462, loss_s1: 0.021607, loss_fp: 0.002067, loss_freq: 0.005279
[16:49:51.131] iteration 27073: loss: 0.076452, loss_s1: 0.081675, loss_fp: 0.000926, loss_freq: 0.036577
[16:49:51.775] iteration 27074: loss: 0.066825, loss_s1: 0.049510, loss_fp: 0.005358, loss_freq: 0.037348
[16:49:52.448] iteration 27075: loss: 0.035009, loss_s1: 0.024222, loss_fp: 0.004072, loss_freq: 0.007482
[16:49:53.114] iteration 27076: loss: 0.045145, loss_s1: 0.034595, loss_fp: 0.001363, loss_freq: 0.020929
[16:49:53.790] iteration 27077: loss: 0.049405, loss_s1: 0.030113, loss_fp: 0.003447, loss_freq: 0.027366
[16:49:54.458] iteration 27078: loss: 0.071065, loss_s1: 0.041818, loss_fp: 0.014206, loss_freq: 0.048206
[16:49:55.132] iteration 27079: loss: 0.045576, loss_s1: 0.017737, loss_fp: 0.002030, loss_freq: 0.030914
[16:49:55.839] iteration 27080: loss: 0.043278, loss_s1: 0.023176, loss_fp: 0.003508, loss_freq: 0.029213
[16:49:56.477] iteration 27081: loss: 0.091449, loss_s1: 0.088502, loss_fp: 0.004842, loss_freq: 0.065349
[16:49:57.111] iteration 27082: loss: 0.051801, loss_s1: 0.060787, loss_fp: 0.004817, loss_freq: 0.010410
[16:49:57.771] iteration 27083: loss: 0.052803, loss_s1: 0.034136, loss_fp: 0.004409, loss_freq: 0.026435
[16:49:58.412] iteration 27084: loss: 0.064468, loss_s1: 0.081814, loss_fp: 0.002342, loss_freq: 0.014253
[16:49:59.052] iteration 27085: loss: 0.033546, loss_s1: 0.016948, loss_fp: 0.001105, loss_freq: 0.013960
[16:49:59.697] iteration 27086: loss: 0.051050, loss_s1: 0.034614, loss_fp: 0.010428, loss_freq: 0.021963
[16:50:00.341] iteration 27087: loss: 0.041415, loss_s1: 0.017033, loss_fp: 0.002727, loss_freq: 0.018246
[16:50:00.981] iteration 27088: loss: 0.063866, loss_s1: 0.048787, loss_fp: 0.008651, loss_freq: 0.034818
[16:50:01.622] iteration 27089: loss: 0.049187, loss_s1: 0.043420, loss_fp: 0.003624, loss_freq: 0.010542
[16:50:02.261] iteration 27090: loss: 0.071699, loss_s1: 0.042880, loss_fp: 0.006184, loss_freq: 0.053225
[16:50:02.891] iteration 27091: loss: 0.044252, loss_s1: 0.023139, loss_fp: 0.001666, loss_freq: 0.018368
[16:50:03.519] iteration 27092: loss: 0.059078, loss_s1: 0.047826, loss_fp: 0.002863, loss_freq: 0.031955
[16:50:04.152] iteration 27093: loss: 0.031276, loss_s1: 0.016422, loss_fp: 0.001700, loss_freq: 0.007124
[16:50:04.782] iteration 27094: loss: 0.066999, loss_s1: 0.066146, loss_fp: 0.004613, loss_freq: 0.017481
[16:50:05.415] iteration 27095: loss: 0.048487, loss_s1: 0.045454, loss_fp: 0.006551, loss_freq: 0.018426
[16:50:06.049] iteration 27096: loss: 0.046812, loss_s1: 0.032629, loss_fp: 0.002221, loss_freq: 0.020364
[16:50:06.683] iteration 27097: loss: 0.052035, loss_s1: 0.033850, loss_fp: 0.001711, loss_freq: 0.007366
[16:50:07.311] iteration 27098: loss: 0.055724, loss_s1: 0.043053, loss_fp: 0.001730, loss_freq: 0.032206
[16:50:07.947] iteration 27099: loss: 0.061034, loss_s1: 0.029927, loss_fp: 0.003070, loss_freq: 0.045208
[16:50:08.580] iteration 27100: loss: 0.060747, loss_s1: 0.020489, loss_fp: 0.002549, loss_freq: 0.065546
[16:50:09.217] iteration 27101: loss: 0.066994, loss_s1: 0.031229, loss_fp: 0.002966, loss_freq: 0.054554
[16:50:09.854] iteration 27102: loss: 0.062268, loss_s1: 0.025594, loss_fp: 0.002744, loss_freq: 0.074724
[16:50:10.497] iteration 27103: loss: 0.029197, loss_s1: 0.019035, loss_fp: 0.001895, loss_freq: 0.004562
[16:50:11.149] iteration 27104: loss: 0.026917, loss_s1: 0.008608, loss_fp: 0.003136, loss_freq: 0.014181
[16:50:11.792] iteration 27105: loss: 0.054066, loss_s1: 0.027656, loss_fp: 0.002707, loss_freq: 0.026873
[16:50:12.434] iteration 27106: loss: 0.085809, loss_s1: 0.070328, loss_fp: 0.009172, loss_freq: 0.056801
[16:50:13.069] iteration 27107: loss: 0.068695, loss_s1: 0.049750, loss_fp: 0.005888, loss_freq: 0.019160
[16:50:13.698] iteration 27108: loss: 0.049010, loss_s1: 0.042767, loss_fp: 0.013337, loss_freq: 0.005447
[16:50:14.331] iteration 27109: loss: 0.036869, loss_s1: 0.020441, loss_fp: 0.007337, loss_freq: 0.012259
[16:50:14.968] iteration 27110: loss: 0.045443, loss_s1: 0.038932, loss_fp: 0.002556, loss_freq: 0.012234
[16:50:15.611] iteration 27111: loss: 0.030721, loss_s1: 0.019773, loss_fp: 0.009178, loss_freq: 0.005923
[16:50:16.254] iteration 27112: loss: 0.062341, loss_s1: 0.051450, loss_fp: 0.008004, loss_freq: 0.031001
[16:50:16.895] iteration 27113: loss: 0.081474, loss_s1: 0.071278, loss_fp: 0.010165, loss_freq: 0.047350
[16:50:17.542] iteration 27114: loss: 0.036628, loss_s1: 0.021778, loss_fp: 0.000514, loss_freq: 0.002032
[16:50:18.172] iteration 27115: loss: 0.032042, loss_s1: 0.011632, loss_fp: 0.003118, loss_freq: 0.008829
[16:50:18.818] iteration 27116: loss: 0.032465, loss_s1: 0.022117, loss_fp: 0.001271, loss_freq: 0.008545
[16:50:19.462] iteration 27117: loss: 0.053895, loss_s1: 0.046609, loss_fp: 0.002799, loss_freq: 0.025255
[16:50:20.116] iteration 27118: loss: 0.070924, loss_s1: 0.039535, loss_fp: 0.004575, loss_freq: 0.036432
[16:50:20.771] iteration 27119: loss: 0.048495, loss_s1: 0.030043, loss_fp: 0.006375, loss_freq: 0.009132
[16:50:21.419] iteration 27120: loss: 0.032983, loss_s1: 0.025192, loss_fp: 0.003629, loss_freq: 0.006330
[16:50:22.072] iteration 27121: loss: 0.027577, loss_s1: 0.014159, loss_fp: 0.001976, loss_freq: 0.008798
[16:50:22.733] iteration 27122: loss: 0.052271, loss_s1: 0.024588, loss_fp: 0.001948, loss_freq: 0.024861
[16:50:23.374] iteration 27123: loss: 0.047824, loss_s1: 0.054251, loss_fp: 0.003107, loss_freq: 0.007047
[16:50:24.016] iteration 27124: loss: 0.064342, loss_s1: 0.039198, loss_fp: 0.005290, loss_freq: 0.036920
[16:50:24.657] iteration 27125: loss: 0.031495, loss_s1: 0.011679, loss_fp: 0.003381, loss_freq: 0.007681
[16:50:25.296] iteration 27126: loss: 0.044276, loss_s1: 0.028009, loss_fp: 0.003885, loss_freq: 0.009637
[16:50:25.944] iteration 27127: loss: 0.042372, loss_s1: 0.029040, loss_fp: 0.001260, loss_freq: 0.015113
[16:50:26.579] iteration 27128: loss: 0.060033, loss_s1: 0.060441, loss_fp: 0.001418, loss_freq: 0.016911
[16:50:27.230] iteration 27129: loss: 0.049210, loss_s1: 0.027044, loss_fp: 0.009371, loss_freq: 0.014235
[16:50:27.867] iteration 27130: loss: 0.065427, loss_s1: 0.050954, loss_fp: 0.010077, loss_freq: 0.036630
[16:50:28.532] iteration 27131: loss: 0.030376, loss_s1: 0.017649, loss_fp: 0.000530, loss_freq: 0.007354
[16:50:29.167] iteration 27132: loss: 0.043389, loss_s1: 0.046120, loss_fp: 0.001119, loss_freq: 0.003491
[16:50:29.808] iteration 27133: loss: 0.064661, loss_s1: 0.056112, loss_fp: 0.001674, loss_freq: 0.033702
[16:50:30.449] iteration 27134: loss: 0.081761, loss_s1: 0.067855, loss_fp: 0.003089, loss_freq: 0.044803
[16:50:31.091] iteration 27135: loss: 0.102439, loss_s1: 0.065019, loss_fp: 0.017605, loss_freq: 0.087991
[16:50:31.732] iteration 27136: loss: 0.075817, loss_s1: 0.071810, loss_fp: 0.003980, loss_freq: 0.036929
[16:50:32.370] iteration 27137: loss: 0.068494, loss_s1: 0.066513, loss_fp: 0.004695, loss_freq: 0.036965
[16:50:33.016] iteration 27138: loss: 0.058538, loss_s1: 0.063457, loss_fp: 0.002224, loss_freq: 0.018745
[16:50:33.645] iteration 27139: loss: 0.051762, loss_s1: 0.050416, loss_fp: 0.001775, loss_freq: 0.023663
[16:50:34.277] iteration 27140: loss: 0.040622, loss_s1: 0.031597, loss_fp: 0.000665, loss_freq: 0.013816
[16:50:34.928] iteration 27141: loss: 0.056687, loss_s1: 0.031013, loss_fp: 0.002349, loss_freq: 0.043268
[16:50:35.567] iteration 27142: loss: 0.094516, loss_s1: 0.079774, loss_fp: 0.002846, loss_freq: 0.031097
[16:50:36.206] iteration 27143: loss: 0.048825, loss_s1: 0.040348, loss_fp: 0.002887, loss_freq: 0.017387
[16:50:36.850] iteration 27144: loss: 0.053670, loss_s1: 0.034726, loss_fp: 0.003063, loss_freq: 0.028764
[16:50:37.498] iteration 27145: loss: 0.057393, loss_s1: 0.042850, loss_fp: 0.008709, loss_freq: 0.017216
[16:50:38.139] iteration 27146: loss: 0.037270, loss_s1: 0.018072, loss_fp: 0.004247, loss_freq: 0.016743
[16:50:38.783] iteration 27147: loss: 0.063647, loss_s1: 0.060231, loss_fp: 0.001894, loss_freq: 0.029781
[16:50:39.438] iteration 27148: loss: 0.082294, loss_s1: 0.045346, loss_fp: 0.004545, loss_freq: 0.050502
[16:50:40.072] iteration 27149: loss: 0.058440, loss_s1: 0.040732, loss_fp: 0.005738, loss_freq: 0.021435
[16:50:40.700] iteration 27150: loss: 0.034996, loss_s1: 0.017794, loss_fp: 0.001489, loss_freq: 0.014388
[16:50:41.344] iteration 27151: loss: 0.030295, loss_s1: 0.015048, loss_fp: 0.001752, loss_freq: 0.011264
[16:50:41.980] iteration 27152: loss: 0.065499, loss_s1: 0.067166, loss_fp: 0.003052, loss_freq: 0.026627
[16:50:42.611] iteration 27153: loss: 0.041637, loss_s1: 0.021803, loss_fp: 0.002031, loss_freq: 0.016406
[16:50:43.255] iteration 27154: loss: 0.063704, loss_s1: 0.021932, loss_fp: 0.007029, loss_freq: 0.047895
[16:50:43.905] iteration 27155: loss: 0.065687, loss_s1: 0.059497, loss_fp: 0.011505, loss_freq: 0.025333
[16:50:44.540] iteration 27156: loss: 0.058291, loss_s1: 0.050270, loss_fp: 0.006027, loss_freq: 0.010390
[16:50:45.210] iteration 27157: loss: 0.034230, loss_s1: 0.025786, loss_fp: 0.006632, loss_freq: 0.003736
[16:50:45.878] iteration 27158: loss: 0.045992, loss_s1: 0.038329, loss_fp: 0.001844, loss_freq: 0.015996
[16:50:46.542] iteration 27159: loss: 0.051484, loss_s1: 0.024250, loss_fp: 0.004058, loss_freq: 0.038077
[16:50:47.184] iteration 27160: loss: 0.048749, loss_s1: 0.017631, loss_fp: 0.009108, loss_freq: 0.019493
[16:50:47.865] iteration 27161: loss: 0.097979, loss_s1: 0.110188, loss_fp: 0.006310, loss_freq: 0.036916
[16:50:48.532] iteration 27162: loss: 0.052303, loss_s1: 0.038846, loss_fp: 0.001249, loss_freq: 0.016379
[16:50:49.205] iteration 27163: loss: 0.041176, loss_s1: 0.025555, loss_fp: 0.004763, loss_freq: 0.007424
[16:50:49.868] iteration 27164: loss: 0.048146, loss_s1: 0.038914, loss_fp: 0.002642, loss_freq: 0.015963
[16:50:50.543] iteration 27165: loss: 0.039574, loss_s1: 0.034572, loss_fp: 0.009431, loss_freq: 0.004990
[16:50:51.182] iteration 27166: loss: 0.046564, loss_s1: 0.028734, loss_fp: 0.005445, loss_freq: 0.015796
[16:50:51.816] iteration 27167: loss: 0.064814, loss_s1: 0.054618, loss_fp: 0.009780, loss_freq: 0.023634
[16:50:52.447] iteration 27168: loss: 0.062951, loss_s1: 0.057321, loss_fp: 0.005130, loss_freq: 0.024343
[16:50:53.079] iteration 27169: loss: 0.057431, loss_s1: 0.049910, loss_fp: 0.004871, loss_freq: 0.015609
[16:50:53.777] iteration 27170: loss: 0.036088, loss_s1: 0.003904, loss_fp: 0.002613, loss_freq: 0.030311
[16:50:54.736] iteration 27171: loss: 0.062211, loss_s1: 0.058624, loss_fp: 0.000611, loss_freq: 0.025454
[16:50:55.387] iteration 27172: loss: 0.056927, loss_s1: 0.037782, loss_fp: 0.002410, loss_freq: 0.021673
[16:50:56.046] iteration 27173: loss: 0.039747, loss_s1: 0.018994, loss_fp: 0.002652, loss_freq: 0.018683
[16:50:56.695] iteration 27174: loss: 0.041213, loss_s1: 0.013923, loss_fp: 0.002668, loss_freq: 0.028539
[16:50:57.344] iteration 27175: loss: 0.054083, loss_s1: 0.051906, loss_fp: 0.005188, loss_freq: 0.027437
[16:50:58.020] iteration 27176: loss: 0.030619, loss_s1: 0.015486, loss_fp: 0.004645, loss_freq: 0.007318
[16:50:58.664] iteration 27177: loss: 0.034238, loss_s1: 0.030460, loss_fp: 0.002998, loss_freq: 0.009624
[16:50:59.303] iteration 27178: loss: 0.044836, loss_s1: 0.015389, loss_fp: 0.001592, loss_freq: 0.033901
[16:50:59.953] iteration 27179: loss: 0.057745, loss_s1: 0.048134, loss_fp: 0.003279, loss_freq: 0.022158
[16:51:00.597] iteration 27180: loss: 0.040998, loss_s1: 0.019099, loss_fp: 0.005049, loss_freq: 0.004251
[16:51:01.229] iteration 27181: loss: 0.072856, loss_s1: 0.040320, loss_fp: 0.010057, loss_freq: 0.045293
[16:51:01.877] iteration 27182: loss: 0.068887, loss_s1: 0.047090, loss_fp: 0.002395, loss_freq: 0.033816
[16:51:02.512] iteration 27183: loss: 0.055457, loss_s1: 0.050944, loss_fp: 0.002696, loss_freq: 0.015809
[16:51:03.142] iteration 27184: loss: 0.046266, loss_s1: 0.032745, loss_fp: 0.004623, loss_freq: 0.024883
[16:51:03.794] iteration 27185: loss: 0.056251, loss_s1: 0.057791, loss_fp: 0.001267, loss_freq: 0.013239
[16:51:04.434] iteration 27186: loss: 0.048753, loss_s1: 0.024175, loss_fp: 0.003511, loss_freq: 0.023496
[16:51:05.073] iteration 27187: loss: 0.050050, loss_s1: 0.020442, loss_fp: 0.004631, loss_freq: 0.038416
[16:51:05.773] iteration 27188: loss: 0.049694, loss_s1: 0.022355, loss_fp: 0.008742, loss_freq: 0.033019
[16:51:06.441] iteration 27189: loss: 0.028508, loss_s1: 0.017657, loss_fp: 0.001731, loss_freq: 0.013119
[16:51:07.220] iteration 27190: loss: 0.036180, loss_s1: 0.030059, loss_fp: 0.000912, loss_freq: 0.012435
[16:51:07.864] iteration 27191: loss: 0.090623, loss_s1: 0.072914, loss_fp: 0.004821, loss_freq: 0.044609
[16:51:08.499] iteration 27192: loss: 0.032323, loss_s1: 0.017186, loss_fp: 0.002283, loss_freq: 0.018449
[16:51:09.147] iteration 27193: loss: 0.067085, loss_s1: 0.046412, loss_fp: 0.001352, loss_freq: 0.054629
[16:51:09.798] iteration 27194: loss: 0.048036, loss_s1: 0.049185, loss_fp: 0.006515, loss_freq: 0.004691
[16:51:10.442] iteration 27195: loss: 0.035231, loss_s1: 0.018331, loss_fp: 0.001185, loss_freq: 0.007981
[16:51:11.073] iteration 27196: loss: 0.059808, loss_s1: 0.055576, loss_fp: 0.002612, loss_freq: 0.024928
[16:51:11.711] iteration 27197: loss: 0.039202, loss_s1: 0.019496, loss_fp: 0.001817, loss_freq: 0.018510
[16:51:12.331] iteration 27198: loss: 0.063448, loss_s1: 0.051331, loss_fp: 0.001782, loss_freq: 0.024405
[16:51:12.957] iteration 27199: loss: 0.067500, loss_s1: 0.067844, loss_fp: 0.008387, loss_freq: 0.025949
[16:51:13.592] iteration 27200: loss: 0.046766, loss_s1: 0.026776, loss_fp: 0.003897, loss_freq: 0.009537
[16:51:16.787] iteration 27200 : mean_dice : 0.791547
[16:51:17.447] iteration 27201: loss: 0.034315, loss_s1: 0.026579, loss_fp: 0.001022, loss_freq: 0.009522
[16:51:18.081] iteration 27202: loss: 0.048805, loss_s1: 0.032527, loss_fp: 0.002787, loss_freq: 0.013924
[16:51:18.722] iteration 27203: loss: 0.097152, loss_s1: 0.098350, loss_fp: 0.009899, loss_freq: 0.054790
[16:51:19.358] iteration 27204: loss: 0.060610, loss_s1: 0.040990, loss_fp: 0.004907, loss_freq: 0.039631
[16:51:20.003] iteration 27205: loss: 0.040158, loss_s1: 0.018502, loss_fp: 0.003610, loss_freq: 0.017360
[16:51:20.641] iteration 27206: loss: 0.056572, loss_s1: 0.041392, loss_fp: 0.001690, loss_freq: 0.026347
[16:51:21.275] iteration 27207: loss: 0.070999, loss_s1: 0.063057, loss_fp: 0.004594, loss_freq: 0.033671
[16:51:21.915] iteration 27208: loss: 0.079857, loss_s1: 0.079189, loss_fp: 0.008171, loss_freq: 0.039539
[16:51:22.555] iteration 27209: loss: 0.045376, loss_s1: 0.035315, loss_fp: 0.002261, loss_freq: 0.016511
[16:51:23.185] iteration 27210: loss: 0.037685, loss_s1: 0.033778, loss_fp: 0.000543, loss_freq: 0.005809
[16:51:23.823] iteration 27211: loss: 0.050044, loss_s1: 0.034196, loss_fp: 0.001967, loss_freq: 0.022150
[16:51:24.452] iteration 27212: loss: 0.052114, loss_s1: 0.045430, loss_fp: 0.002871, loss_freq: 0.028093
[16:51:25.089] iteration 27213: loss: 0.043011, loss_s1: 0.025853, loss_fp: 0.002175, loss_freq: 0.017920
[16:51:25.739] iteration 27214: loss: 0.049051, loss_s1: 0.030767, loss_fp: 0.003786, loss_freq: 0.030547
[16:51:26.377] iteration 27215: loss: 0.047149, loss_s1: 0.013911, loss_fp: 0.000770, loss_freq: 0.009649
[16:51:27.007] iteration 27216: loss: 0.066282, loss_s1: 0.077526, loss_fp: 0.006199, loss_freq: 0.023823
[16:51:27.669] iteration 27217: loss: 0.049955, loss_s1: 0.032259, loss_fp: 0.005015, loss_freq: 0.013311
[16:51:28.368] iteration 27218: loss: 0.049829, loss_s1: 0.024716, loss_fp: 0.008878, loss_freq: 0.015708
[16:51:29.043] iteration 27219: loss: 0.043074, loss_s1: 0.027518, loss_fp: 0.003744, loss_freq: 0.027160
[16:51:29.726] iteration 27220: loss: 0.055073, loss_s1: 0.038218, loss_fp: 0.001855, loss_freq: 0.027063
[16:51:30.404] iteration 27221: loss: 0.046977, loss_s1: 0.026766, loss_fp: 0.003544, loss_freq: 0.021063
[16:51:31.053] iteration 27222: loss: 0.052298, loss_s1: 0.029672, loss_fp: 0.006404, loss_freq: 0.024654
[16:51:31.727] iteration 27223: loss: 0.043174, loss_s1: 0.037381, loss_fp: 0.002402, loss_freq: 0.011735
[16:51:32.376] iteration 27224: loss: 0.056668, loss_s1: 0.031307, loss_fp: 0.001685, loss_freq: 0.049258
[16:51:33.012] iteration 27225: loss: 0.032243, loss_s1: 0.019537, loss_fp: 0.001347, loss_freq: 0.015113
[16:51:33.648] iteration 27226: loss: 0.053415, loss_s1: 0.041780, loss_fp: 0.003051, loss_freq: 0.025930
[16:51:34.287] iteration 27227: loss: 0.065761, loss_s1: 0.075670, loss_fp: 0.010934, loss_freq: 0.016985
[16:51:34.928] iteration 27228: loss: 0.040333, loss_s1: 0.028230, loss_fp: 0.001122, loss_freq: 0.011348
[16:51:35.560] iteration 27229: loss: 0.061326, loss_s1: 0.052453, loss_fp: 0.001424, loss_freq: 0.042123
[16:51:36.205] iteration 27230: loss: 0.045666, loss_s1: 0.028816, loss_fp: 0.002681, loss_freq: 0.015402
[16:51:36.841] iteration 27231: loss: 0.047105, loss_s1: 0.021571, loss_fp: 0.009452, loss_freq: 0.017623
[16:51:37.476] iteration 27232: loss: 0.050478, loss_s1: 0.023613, loss_fp: 0.003546, loss_freq: 0.027425
[16:51:38.104] iteration 27233: loss: 0.058717, loss_s1: 0.047284, loss_fp: 0.004339, loss_freq: 0.026248
[16:51:38.746] iteration 27234: loss: 0.038361, loss_s1: 0.010108, loss_fp: 0.003124, loss_freq: 0.021618
[16:51:39.381] iteration 27235: loss: 0.052548, loss_s1: 0.029750, loss_fp: 0.002169, loss_freq: 0.011843
[16:51:40.015] iteration 27236: loss: 0.041655, loss_s1: 0.025199, loss_fp: 0.007906, loss_freq: 0.015384
[16:51:40.659] iteration 27237: loss: 0.082653, loss_s1: 0.043069, loss_fp: 0.004072, loss_freq: 0.051648
[16:51:41.308] iteration 27238: loss: 0.063636, loss_s1: 0.068229, loss_fp: 0.003598, loss_freq: 0.028812
[16:51:41.947] iteration 27239: loss: 0.038450, loss_s1: 0.023388, loss_fp: 0.003435, loss_freq: 0.012945
[16:51:42.594] iteration 27240: loss: 0.048791, loss_s1: 0.020199, loss_fp: 0.006082, loss_freq: 0.003800
[16:51:43.270] iteration 27241: loss: 0.034473, loss_s1: 0.020961, loss_fp: 0.004272, loss_freq: 0.011477
[16:51:43.942] iteration 27242: loss: 0.081731, loss_s1: 0.107366, loss_fp: 0.003669, loss_freq: 0.017216
[16:51:44.621] iteration 27243: loss: 0.067512, loss_s1: 0.035605, loss_fp: 0.005182, loss_freq: 0.060832
[16:51:45.285] iteration 27244: loss: 0.123578, loss_s1: 0.080175, loss_fp: 0.012683, loss_freq: 0.100784
[16:51:45.968] iteration 27245: loss: 0.065053, loss_s1: 0.045692, loss_fp: 0.009012, loss_freq: 0.047012
[16:51:46.651] iteration 27246: loss: 0.045366, loss_s1: 0.031866, loss_fp: 0.002195, loss_freq: 0.021170
[16:51:47.329] iteration 27247: loss: 0.069164, loss_s1: 0.074324, loss_fp: 0.003984, loss_freq: 0.031726
[16:51:47.970] iteration 27248: loss: 0.043871, loss_s1: 0.023614, loss_fp: 0.006464, loss_freq: 0.017513
[16:51:48.612] iteration 27249: loss: 0.064518, loss_s1: 0.064844, loss_fp: 0.005723, loss_freq: 0.019470
[16:51:49.252] iteration 27250: loss: 0.100760, loss_s1: 0.108439, loss_fp: 0.004080, loss_freq: 0.026843
[16:51:49.901] iteration 27251: loss: 0.053551, loss_s1: 0.046528, loss_fp: 0.002250, loss_freq: 0.004935
[16:51:50.539] iteration 27252: loss: 0.038802, loss_s1: 0.019989, loss_fp: 0.002968, loss_freq: 0.014988
[16:51:51.179] iteration 27253: loss: 0.045664, loss_s1: 0.025914, loss_fp: 0.001336, loss_freq: 0.028998
[16:51:51.819] iteration 27254: loss: 0.041662, loss_s1: 0.037374, loss_fp: 0.003881, loss_freq: 0.009327
[16:51:52.472] iteration 27255: loss: 0.077141, loss_s1: 0.077449, loss_fp: 0.002367, loss_freq: 0.039331
[16:51:53.151] iteration 27256: loss: 0.064189, loss_s1: 0.030153, loss_fp: 0.002841, loss_freq: 0.030301
[16:51:53.808] iteration 27257: loss: 0.043533, loss_s1: 0.022462, loss_fp: 0.000872, loss_freq: 0.022856
[16:51:54.461] iteration 27258: loss: 0.040857, loss_s1: 0.022076, loss_fp: 0.001710, loss_freq: 0.008493
[16:51:55.117] iteration 27259: loss: 0.030750, loss_s1: 0.019710, loss_fp: 0.004942, loss_freq: 0.007050
[16:51:55.766] iteration 27260: loss: 0.049081, loss_s1: 0.032212, loss_fp: 0.005590, loss_freq: 0.024996
[16:51:56.420] iteration 27261: loss: 0.061782, loss_s1: 0.043041, loss_fp: 0.002772, loss_freq: 0.019679
[16:51:57.089] iteration 27262: loss: 0.043671, loss_s1: 0.030953, loss_fp: 0.002231, loss_freq: 0.024323
[16:51:57.752] iteration 27263: loss: 0.041183, loss_s1: 0.030917, loss_fp: 0.006974, loss_freq: 0.013549
[16:51:58.392] iteration 27264: loss: 0.022512, loss_s1: 0.010169, loss_fp: 0.000679, loss_freq: 0.006305
[16:51:59.038] iteration 27265: loss: 0.057643, loss_s1: 0.042655, loss_fp: 0.001859, loss_freq: 0.027953
[16:51:59.692] iteration 27266: loss: 0.036018, loss_s1: 0.007909, loss_fp: 0.012803, loss_freq: 0.012455
[16:52:00.343] iteration 27267: loss: 0.089874, loss_s1: 0.069550, loss_fp: 0.007784, loss_freq: 0.065803
[16:52:00.990] iteration 27268: loss: 0.035464, loss_s1: 0.007213, loss_fp: 0.007601, loss_freq: 0.018293
[16:52:01.650] iteration 27269: loss: 0.042393, loss_s1: 0.029675, loss_fp: 0.004075, loss_freq: 0.008305
[16:52:02.347] iteration 27270: loss: 0.066835, loss_s1: 0.039360, loss_fp: 0.002178, loss_freq: 0.028116
[16:52:03.026] iteration 27271: loss: 0.038863, loss_s1: 0.009989, loss_fp: 0.006671, loss_freq: 0.019410
[16:52:03.707] iteration 27272: loss: 0.056903, loss_s1: 0.050677, loss_fp: 0.002428, loss_freq: 0.022899
[16:52:04.383] iteration 27273: loss: 0.088824, loss_s1: 0.092927, loss_fp: 0.009741, loss_freq: 0.047993
[16:52:05.040] iteration 27274: loss: 0.051150, loss_s1: 0.031654, loss_fp: 0.012709, loss_freq: 0.020958
[16:52:05.675] iteration 27275: loss: 0.043026, loss_s1: 0.032793, loss_fp: 0.003468, loss_freq: 0.014440
[16:52:06.342] iteration 27276: loss: 0.048265, loss_s1: 0.025957, loss_fp: 0.001314, loss_freq: 0.021704
[16:52:06.997] iteration 27277: loss: 0.044745, loss_s1: 0.010922, loss_fp: 0.006220, loss_freq: 0.033186
[16:52:07.655] iteration 27278: loss: 0.048489, loss_s1: 0.019389, loss_fp: 0.007735, loss_freq: 0.034929
[16:52:08.298] iteration 27279: loss: 0.038699, loss_s1: 0.014794, loss_fp: 0.003710, loss_freq: 0.021699
[16:52:08.934] iteration 27280: loss: 0.051740, loss_s1: 0.036971, loss_fp: 0.001102, loss_freq: 0.014522
[16:52:09.570] iteration 27281: loss: 0.046139, loss_s1: 0.038397, loss_fp: 0.011722, loss_freq: 0.009996
[16:52:10.197] iteration 27282: loss: 0.060422, loss_s1: 0.049979, loss_fp: 0.005284, loss_freq: 0.036794
[16:52:10.840] iteration 27283: loss: 0.035895, loss_s1: 0.013373, loss_fp: 0.001672, loss_freq: 0.010506
[16:52:11.470] iteration 27284: loss: 0.056858, loss_s1: 0.055880, loss_fp: 0.002836, loss_freq: 0.012776
[16:52:12.106] iteration 27285: loss: 0.084112, loss_s1: 0.103103, loss_fp: 0.002545, loss_freq: 0.009416
[16:52:12.744] iteration 27286: loss: 0.044228, loss_s1: 0.023417, loss_fp: 0.001312, loss_freq: 0.014377
[16:52:13.397] iteration 27287: loss: 0.055413, loss_s1: 0.045718, loss_fp: 0.007813, loss_freq: 0.021405
[16:52:14.059] iteration 27288: loss: 0.084560, loss_s1: 0.081440, loss_fp: 0.004561, loss_freq: 0.045855
[16:52:14.684] iteration 27289: loss: 0.048414, loss_s1: 0.045870, loss_fp: 0.003747, loss_freq: 0.012065
[16:52:15.324] iteration 27290: loss: 0.052019, loss_s1: 0.036967, loss_fp: 0.003273, loss_freq: 0.031065
[16:52:15.959] iteration 27291: loss: 0.052878, loss_s1: 0.025445, loss_fp: 0.004993, loss_freq: 0.034726
[16:52:16.606] iteration 27292: loss: 0.044286, loss_s1: 0.036472, loss_fp: 0.001499, loss_freq: 0.016509
[16:52:17.275] iteration 27293: loss: 0.023578, loss_s1: 0.010841, loss_fp: 0.001144, loss_freq: 0.004439
[16:52:17.909] iteration 27294: loss: 0.034000, loss_s1: 0.021738, loss_fp: 0.002511, loss_freq: 0.020042
[16:52:18.561] iteration 27295: loss: 0.060184, loss_s1: 0.056279, loss_fp: 0.007535, loss_freq: 0.029878
[16:52:19.183] iteration 27296: loss: 0.056064, loss_s1: 0.024863, loss_fp: 0.001378, loss_freq: 0.030851
[16:52:19.806] iteration 27297: loss: 0.034704, loss_s1: 0.004731, loss_fp: 0.010965, loss_freq: 0.020884
[16:52:20.429] iteration 27298: loss: 0.045383, loss_s1: 0.017417, loss_fp: 0.000737, loss_freq: 0.022036
[16:52:21.058] iteration 27299: loss: 0.080522, loss_s1: 0.051542, loss_fp: 0.001412, loss_freq: 0.007601
[16:52:21.679] iteration 27300: loss: 0.050419, loss_s1: 0.037611, loss_fp: 0.006623, loss_freq: 0.014423
[16:52:22.307] iteration 27301: loss: 0.073071, loss_s1: 0.057592, loss_fp: 0.011694, loss_freq: 0.021581
[16:52:22.925] iteration 27302: loss: 0.079725, loss_s1: 0.074898, loss_fp: 0.002814, loss_freq: 0.039721
[16:52:23.548] iteration 27303: loss: 0.046349, loss_s1: 0.037169, loss_fp: 0.001161, loss_freq: 0.018573
[16:52:24.171] iteration 27304: loss: 0.069603, loss_s1: 0.049751, loss_fp: 0.002099, loss_freq: 0.044441
[16:52:24.795] iteration 27305: loss: 0.050431, loss_s1: 0.009781, loss_fp: 0.002764, loss_freq: 0.009303
[16:52:25.419] iteration 27306: loss: 0.052559, loss_s1: 0.040237, loss_fp: 0.005717, loss_freq: 0.019475
[16:52:26.075] iteration 27307: loss: 0.055829, loss_s1: 0.040878, loss_fp: 0.001015, loss_freq: 0.015782
[16:52:26.704] iteration 27308: loss: 0.024842, loss_s1: 0.011403, loss_fp: 0.002301, loss_freq: 0.008439
[16:52:27.333] iteration 27309: loss: 0.055412, loss_s1: 0.050202, loss_fp: 0.004730, loss_freq: 0.015876
[16:52:27.958] iteration 27310: loss: 0.056363, loss_s1: 0.019501, loss_fp: 0.001852, loss_freq: 0.010300
[16:52:28.573] iteration 27311: loss: 0.063465, loss_s1: 0.039073, loss_fp: 0.006276, loss_freq: 0.045943
[16:52:29.190] iteration 27312: loss: 0.068349, loss_s1: 0.084814, loss_fp: 0.009475, loss_freq: 0.006703
[16:52:29.811] iteration 27313: loss: 0.056506, loss_s1: 0.052691, loss_fp: 0.001751, loss_freq: 0.031397
[16:52:30.859] iteration 27314: loss: 0.029544, loss_s1: 0.009685, loss_fp: 0.000202, loss_freq: 0.016470
[16:52:31.483] iteration 27315: loss: 0.058149, loss_s1: 0.055755, loss_fp: 0.006329, loss_freq: 0.016910
[16:52:32.109] iteration 27316: loss: 0.045612, loss_s1: 0.024468, loss_fp: 0.003120, loss_freq: 0.015432
[16:52:32.744] iteration 27317: loss: 0.051391, loss_s1: 0.023637, loss_fp: 0.003305, loss_freq: 0.025917
[16:52:33.366] iteration 27318: loss: 0.042960, loss_s1: 0.037475, loss_fp: 0.003798, loss_freq: 0.013980
[16:52:34.015] iteration 27319: loss: 0.037455, loss_s1: 0.014806, loss_fp: 0.001054, loss_freq: 0.009527
[16:52:34.640] iteration 27320: loss: 0.046440, loss_s1: 0.040526, loss_fp: 0.001333, loss_freq: 0.012562
[16:52:35.270] iteration 27321: loss: 0.052065, loss_s1: 0.019778, loss_fp: 0.008112, loss_freq: 0.031610
[16:52:35.889] iteration 27322: loss: 0.038778, loss_s1: 0.026600, loss_fp: 0.001651, loss_freq: 0.012199
[16:52:36.508] iteration 27323: loss: 0.038482, loss_s1: 0.024083, loss_fp: 0.000928, loss_freq: 0.004601
[16:52:37.133] iteration 27324: loss: 0.043354, loss_s1: 0.017119, loss_fp: 0.009772, loss_freq: 0.022610
[16:52:37.752] iteration 27325: loss: 0.057234, loss_s1: 0.054682, loss_fp: 0.002167, loss_freq: 0.013568
[16:52:38.374] iteration 27326: loss: 0.083964, loss_s1: 0.108320, loss_fp: 0.001404, loss_freq: 0.023653
[16:52:39.005] iteration 27327: loss: 0.038115, loss_s1: 0.020601, loss_fp: 0.003960, loss_freq: 0.017133
[16:52:39.629] iteration 27328: loss: 0.054502, loss_s1: 0.047877, loss_fp: 0.002985, loss_freq: 0.020158
[16:52:40.260] iteration 27329: loss: 0.053706, loss_s1: 0.024713, loss_fp: 0.004394, loss_freq: 0.042658
[16:52:40.881] iteration 27330: loss: 0.050835, loss_s1: 0.019936, loss_fp: 0.002415, loss_freq: 0.033352
[16:52:41.506] iteration 27331: loss: 0.044496, loss_s1: 0.031555, loss_fp: 0.006999, loss_freq: 0.020841
[16:52:42.139] iteration 27332: loss: 0.038078, loss_s1: 0.026930, loss_fp: 0.001079, loss_freq: 0.015817
[16:52:42.756] iteration 27333: loss: 0.040048, loss_s1: 0.025145, loss_fp: 0.004363, loss_freq: 0.015130
[16:52:43.381] iteration 27334: loss: 0.082370, loss_s1: 0.057262, loss_fp: 0.003062, loss_freq: 0.052268
[16:52:44.001] iteration 27335: loss: 0.042883, loss_s1: 0.019286, loss_fp: 0.003067, loss_freq: 0.031686
[16:52:44.624] iteration 27336: loss: 0.031776, loss_s1: 0.017421, loss_fp: 0.000376, loss_freq: 0.013292
[16:52:45.242] iteration 27337: loss: 0.026896, loss_s1: 0.016305, loss_fp: 0.000746, loss_freq: 0.007838
[16:52:45.859] iteration 27338: loss: 0.056611, loss_s1: 0.057057, loss_fp: 0.002738, loss_freq: 0.009677
[16:52:46.478] iteration 27339: loss: 0.071352, loss_s1: 0.043760, loss_fp: 0.001538, loss_freq: 0.057844
[16:52:47.097] iteration 27340: loss: 0.069266, loss_s1: 0.048847, loss_fp: 0.003278, loss_freq: 0.046782
[16:52:47.707] iteration 27341: loss: 0.036819, loss_s1: 0.019477, loss_fp: 0.001442, loss_freq: 0.012531
[16:52:48.327] iteration 27342: loss: 0.049649, loss_s1: 0.030308, loss_fp: 0.002324, loss_freq: 0.029177
[16:52:48.949] iteration 27343: loss: 0.052278, loss_s1: 0.044333, loss_fp: 0.005207, loss_freq: 0.014535
[16:52:49.571] iteration 27344: loss: 0.044251, loss_s1: 0.038630, loss_fp: 0.001265, loss_freq: 0.008169
[16:52:50.192] iteration 27345: loss: 0.065165, loss_s1: 0.064912, loss_fp: 0.008796, loss_freq: 0.017061
[16:52:50.814] iteration 27346: loss: 0.055216, loss_s1: 0.030881, loss_fp: 0.010487, loss_freq: 0.041663
[16:52:51.490] iteration 27347: loss: 0.085713, loss_s1: 0.068765, loss_fp: 0.009582, loss_freq: 0.050357
[16:52:52.115] iteration 27348: loss: 0.070167, loss_s1: 0.067013, loss_fp: 0.004342, loss_freq: 0.021318
[16:52:52.745] iteration 27349: loss: 0.054786, loss_s1: 0.033017, loss_fp: 0.009643, loss_freq: 0.024925
[16:52:53.387] iteration 27350: loss: 0.044937, loss_s1: 0.035638, loss_fp: 0.001129, loss_freq: 0.015167
[16:52:54.039] iteration 27351: loss: 0.049097, loss_s1: 0.031298, loss_fp: 0.005967, loss_freq: 0.024939
[16:52:54.674] iteration 27352: loss: 0.066400, loss_s1: 0.050067, loss_fp: 0.003744, loss_freq: 0.029332
[16:52:55.342] iteration 27353: loss: 0.048539, loss_s1: 0.055528, loss_fp: 0.005000, loss_freq: 0.008272
[16:52:56.035] iteration 27354: loss: 0.053575, loss_s1: 0.053974, loss_fp: 0.012407, loss_freq: 0.008535
[16:52:56.696] iteration 27355: loss: 0.026403, loss_s1: 0.015018, loss_fp: 0.001111, loss_freq: 0.011095
[16:52:57.352] iteration 27356: loss: 0.030456, loss_s1: 0.015186, loss_fp: 0.002497, loss_freq: 0.006201
[16:52:57.985] iteration 27357: loss: 0.054466, loss_s1: 0.046918, loss_fp: 0.001972, loss_freq: 0.023327
[16:52:58.608] iteration 27358: loss: 0.071464, loss_s1: 0.061695, loss_fp: 0.000458, loss_freq: 0.029776
[16:52:59.227] iteration 27359: loss: 0.094593, loss_s1: 0.052292, loss_fp: 0.010872, loss_freq: 0.039744
[16:52:59.854] iteration 27360: loss: 0.041922, loss_s1: 0.025750, loss_fp: 0.003577, loss_freq: 0.022819
[16:53:00.481] iteration 27361: loss: 0.033590, loss_s1: 0.016323, loss_fp: 0.005170, loss_freq: 0.005757
[16:53:01.108] iteration 27362: loss: 0.062232, loss_s1: 0.043166, loss_fp: 0.000991, loss_freq: 0.030208
[16:53:01.729] iteration 27363: loss: 0.039851, loss_s1: 0.024685, loss_fp: 0.001612, loss_freq: 0.018451
[16:53:02.348] iteration 27364: loss: 0.054933, loss_s1: 0.037445, loss_fp: 0.010138, loss_freq: 0.016021
[16:53:02.968] iteration 27365: loss: 0.044922, loss_s1: 0.016923, loss_fp: 0.011415, loss_freq: 0.025018
[16:53:03.591] iteration 27366: loss: 0.048884, loss_s1: 0.031898, loss_fp: 0.002940, loss_freq: 0.019051
[16:53:04.207] iteration 27367: loss: 0.077537, loss_s1: 0.039026, loss_fp: 0.008830, loss_freq: 0.072667
[16:53:04.828] iteration 27368: loss: 0.027385, loss_s1: 0.014489, loss_fp: 0.003058, loss_freq: 0.008490
[16:53:05.446] iteration 27369: loss: 0.033459, loss_s1: 0.006276, loss_fp: 0.000903, loss_freq: 0.009830
[16:53:06.055] iteration 27370: loss: 0.048016, loss_s1: 0.041184, loss_fp: 0.006147, loss_freq: 0.014685
[16:53:06.675] iteration 27371: loss: 0.043163, loss_s1: 0.017884, loss_fp: 0.000402, loss_freq: 0.034958
[16:53:07.298] iteration 27372: loss: 0.083732, loss_s1: 0.070302, loss_fp: 0.002479, loss_freq: 0.053444
[16:53:07.933] iteration 27373: loss: 0.040206, loss_s1: 0.019469, loss_fp: 0.001250, loss_freq: 0.018005
[16:53:08.579] iteration 27374: loss: 0.032432, loss_s1: 0.005936, loss_fp: 0.004857, loss_freq: 0.011874
[16:53:09.354] iteration 27375: loss: 0.053784, loss_s1: 0.054742, loss_fp: 0.001474, loss_freq: 0.015943
[16:53:10.330] iteration 27376: loss: 0.120681, loss_s1: 0.128488, loss_fp: 0.017301, loss_freq: 0.060935
[16:53:11.070] iteration 27377: loss: 0.044346, loss_s1: 0.018905, loss_fp: 0.002266, loss_freq: 0.018735
[16:53:11.719] iteration 27378: loss: 0.067814, loss_s1: 0.060366, loss_fp: 0.005108, loss_freq: 0.016505
[16:53:12.344] iteration 27379: loss: 0.040106, loss_s1: 0.011252, loss_fp: 0.002880, loss_freq: 0.029207
[16:53:12.965] iteration 27380: loss: 0.085630, loss_s1: 0.042471, loss_fp: 0.001292, loss_freq: 0.080350
[16:53:13.586] iteration 27381: loss: 0.050661, loss_s1: 0.020894, loss_fp: 0.020616, loss_freq: 0.026783
[16:53:14.218] iteration 27382: loss: 0.064760, loss_s1: 0.047460, loss_fp: 0.001591, loss_freq: 0.007069
[16:53:14.835] iteration 27383: loss: 0.050753, loss_s1: 0.044622, loss_fp: 0.000863, loss_freq: 0.012928
[16:53:15.470] iteration 27384: loss: 0.048456, loss_s1: 0.023661, loss_fp: 0.002549, loss_freq: 0.025533
[16:53:16.111] iteration 27385: loss: 0.057171, loss_s1: 0.039065, loss_fp: 0.004701, loss_freq: 0.028471
[16:53:16.750] iteration 27386: loss: 0.042844, loss_s1: 0.043109, loss_fp: 0.004454, loss_freq: 0.009834
[16:53:17.396] iteration 27387: loss: 0.071472, loss_s1: 0.039567, loss_fp: 0.002465, loss_freq: 0.058087
[16:53:18.039] iteration 27388: loss: 0.069299, loss_s1: 0.046550, loss_fp: 0.003735, loss_freq: 0.048209
[16:53:18.668] iteration 27389: loss: 0.042000, loss_s1: 0.025289, loss_fp: 0.003328, loss_freq: 0.021677
[16:53:19.315] iteration 27390: loss: 0.067695, loss_s1: 0.079319, loss_fp: 0.003715, loss_freq: 0.026962
[16:53:19.959] iteration 27391: loss: 0.048706, loss_s1: 0.043542, loss_fp: 0.004921, loss_freq: 0.014849
[16:53:20.627] iteration 27392: loss: 0.064375, loss_s1: 0.062188, loss_fp: 0.012964, loss_freq: 0.016581
[16:53:21.265] iteration 27393: loss: 0.070802, loss_s1: 0.034144, loss_fp: 0.011524, loss_freq: 0.016572
[16:53:21.904] iteration 27394: loss: 0.053960, loss_s1: 0.042842, loss_fp: 0.000769, loss_freq: 0.015844
[16:53:22.533] iteration 27395: loss: 0.044378, loss_s1: 0.027172, loss_fp: 0.002230, loss_freq: 0.023135
[16:53:23.175] iteration 27396: loss: 0.032635, loss_s1: 0.019818, loss_fp: 0.003718, loss_freq: 0.006133
[16:53:23.816] iteration 27397: loss: 0.042360, loss_s1: 0.036009, loss_fp: 0.002577, loss_freq: 0.017267
[16:53:24.441] iteration 27398: loss: 0.059830, loss_s1: 0.063958, loss_fp: 0.003539, loss_freq: 0.017868
[16:53:25.060] iteration 27399: loss: 0.063120, loss_s1: 0.036259, loss_fp: 0.006489, loss_freq: 0.041775
[16:53:25.734] iteration 27400: loss: 0.038363, loss_s1: 0.021200, loss_fp: 0.000775, loss_freq: 0.004568
[16:53:28.967] iteration 27400 : mean_dice : 0.804825
[16:53:29.616] iteration 27401: loss: 0.044871, loss_s1: 0.016393, loss_fp: 0.001233, loss_freq: 0.025709
[16:53:30.234] iteration 27402: loss: 0.028304, loss_s1: 0.014435, loss_fp: 0.002923, loss_freq: 0.007607
[16:53:30.844] iteration 27403: loss: 0.046002, loss_s1: 0.037476, loss_fp: 0.003163, loss_freq: 0.019264
[16:53:31.462] iteration 27404: loss: 0.036466, loss_s1: 0.013398, loss_fp: 0.000899, loss_freq: 0.013146
[16:53:32.076] iteration 27405: loss: 0.052297, loss_s1: 0.056874, loss_fp: 0.001973, loss_freq: 0.014748
[16:53:32.701] iteration 27406: loss: 0.046655, loss_s1: 0.034797, loss_fp: 0.005454, loss_freq: 0.020284
[16:53:33.317] iteration 27407: loss: 0.052350, loss_s1: 0.041049, loss_fp: 0.003156, loss_freq: 0.006843
[16:53:33.932] iteration 27408: loss: 0.044537, loss_s1: 0.021244, loss_fp: 0.001589, loss_freq: 0.019482
[16:53:34.566] iteration 27409: loss: 0.043199, loss_s1: 0.037271, loss_fp: 0.002143, loss_freq: 0.008983
[16:53:35.182] iteration 27410: loss: 0.062905, loss_s1: 0.035064, loss_fp: 0.003861, loss_freq: 0.051704
[16:53:35.800] iteration 27411: loss: 0.042559, loss_s1: 0.036907, loss_fp: 0.002828, loss_freq: 0.010365
[16:53:36.419] iteration 27412: loss: 0.030095, loss_s1: 0.011951, loss_fp: 0.001593, loss_freq: 0.008061
[16:53:37.037] iteration 27413: loss: 0.101779, loss_s1: 0.067515, loss_fp: 0.002478, loss_freq: 0.019971
[16:53:37.650] iteration 27414: loss: 0.042652, loss_s1: 0.027195, loss_fp: 0.001793, loss_freq: 0.016090
[16:53:38.272] iteration 27415: loss: 0.052216, loss_s1: 0.018459, loss_fp: 0.003947, loss_freq: 0.029241
[16:53:38.889] iteration 27416: loss: 0.080282, loss_s1: 0.055991, loss_fp: 0.006970, loss_freq: 0.070430
[16:53:39.510] iteration 27417: loss: 0.054318, loss_s1: 0.046332, loss_fp: 0.002207, loss_freq: 0.028501
[16:53:40.135] iteration 27418: loss: 0.057466, loss_s1: 0.057039, loss_fp: 0.007358, loss_freq: 0.013472
[16:53:40.755] iteration 27419: loss: 0.053262, loss_s1: 0.020767, loss_fp: 0.001745, loss_freq: 0.024313
[16:53:41.379] iteration 27420: loss: 0.078686, loss_s1: 0.066636, loss_fp: 0.005328, loss_freq: 0.037104
[16:53:42.000] iteration 27421: loss: 0.047695, loss_s1: 0.040372, loss_fp: 0.005943, loss_freq: 0.017931
[16:53:42.661] iteration 27422: loss: 0.072216, loss_s1: 0.062070, loss_fp: 0.002678, loss_freq: 0.038744
[16:53:43.285] iteration 27423: loss: 0.066269, loss_s1: 0.041319, loss_fp: 0.004265, loss_freq: 0.063468
[16:53:43.903] iteration 27424: loss: 0.072642, loss_s1: 0.058822, loss_fp: 0.010235, loss_freq: 0.023278
[16:53:44.530] iteration 27425: loss: 0.046873, loss_s1: 0.046163, loss_fp: 0.005055, loss_freq: 0.017944
[16:53:45.157] iteration 27426: loss: 0.033263, loss_s1: 0.010628, loss_fp: 0.001880, loss_freq: 0.011746
[16:53:45.785] iteration 27427: loss: 0.063748, loss_s1: 0.032452, loss_fp: 0.009180, loss_freq: 0.053079
[16:53:46.400] iteration 27428: loss: 0.057533, loss_s1: 0.049002, loss_fp: 0.001611, loss_freq: 0.011977
[16:53:47.017] iteration 27429: loss: 0.038036, loss_s1: 0.027016, loss_fp: 0.001907, loss_freq: 0.014606
[16:53:47.644] iteration 27430: loss: 0.058188, loss_s1: 0.034991, loss_fp: 0.013268, loss_freq: 0.036353
[16:53:48.272] iteration 27431: loss: 0.056041, loss_s1: 0.056354, loss_fp: 0.001809, loss_freq: 0.018544
[16:53:48.899] iteration 27432: loss: 0.046264, loss_s1: 0.055471, loss_fp: 0.002313, loss_freq: 0.009397
[16:53:49.528] iteration 27433: loss: 0.056777, loss_s1: 0.046393, loss_fp: 0.001184, loss_freq: 0.027629
[16:53:50.170] iteration 27434: loss: 0.059941, loss_s1: 0.047262, loss_fp: 0.002754, loss_freq: 0.034205
[16:53:50.805] iteration 27435: loss: 0.044720, loss_s1: 0.018095, loss_fp: 0.006835, loss_freq: 0.020199
[16:53:51.439] iteration 27436: loss: 0.031164, loss_s1: 0.012173, loss_fp: 0.001359, loss_freq: 0.013506
[16:53:52.062] iteration 27437: loss: 0.049725, loss_s1: 0.044049, loss_fp: 0.003443, loss_freq: 0.027473
[16:53:52.683] iteration 27438: loss: 0.061867, loss_s1: 0.059700, loss_fp: 0.014486, loss_freq: 0.019694
[16:53:53.297] iteration 27439: loss: 0.055791, loss_s1: 0.044790, loss_fp: 0.000886, loss_freq: 0.007561
[16:53:53.933] iteration 27440: loss: 0.058069, loss_s1: 0.052113, loss_fp: 0.000848, loss_freq: 0.024081
[16:53:54.550] iteration 27441: loss: 0.045644, loss_s1: 0.018808, loss_fp: 0.004430, loss_freq: 0.034297
[16:53:55.166] iteration 27442: loss: 0.056494, loss_s1: 0.064324, loss_fp: 0.002887, loss_freq: 0.013045
[16:53:55.791] iteration 27443: loss: 0.037382, loss_s1: 0.026377, loss_fp: 0.001014, loss_freq: 0.009450
[16:53:56.411] iteration 27444: loss: 0.070834, loss_s1: 0.068824, loss_fp: 0.008018, loss_freq: 0.018383
[16:53:57.041] iteration 27445: loss: 0.054316, loss_s1: 0.031456, loss_fp: 0.002223, loss_freq: 0.030172
[16:53:57.661] iteration 27446: loss: 0.040221, loss_s1: 0.024896, loss_fp: 0.005553, loss_freq: 0.015233
[16:53:58.274] iteration 27447: loss: 0.079004, loss_s1: 0.061810, loss_fp: 0.006262, loss_freq: 0.036002
[16:53:58.907] iteration 27448: loss: 0.047489, loss_s1: 0.043962, loss_fp: 0.004778, loss_freq: 0.012633
[16:53:59.548] iteration 27449: loss: 0.044503, loss_s1: 0.039234, loss_fp: 0.007239, loss_freq: 0.011846
[16:54:00.184] iteration 27450: loss: 0.104301, loss_s1: 0.117711, loss_fp: 0.017166, loss_freq: 0.022662
[16:54:00.821] iteration 27451: loss: 0.023472, loss_s1: 0.010888, loss_fp: 0.000776, loss_freq: 0.007124
[16:54:01.447] iteration 27452: loss: 0.036072, loss_s1: 0.020996, loss_fp: 0.001247, loss_freq: 0.017273
[16:54:02.067] iteration 27453: loss: 0.057260, loss_s1: 0.050983, loss_fp: 0.002716, loss_freq: 0.019779
[16:54:02.685] iteration 27454: loss: 0.046768, loss_s1: 0.039958, loss_fp: 0.004954, loss_freq: 0.017896
[16:54:03.302] iteration 27455: loss: 0.126263, loss_s1: 0.142451, loss_fp: 0.009277, loss_freq: 0.063685
[16:54:03.921] iteration 27456: loss: 0.058862, loss_s1: 0.042687, loss_fp: 0.001558, loss_freq: 0.044905
[16:54:04.854] iteration 27457: loss: 0.032931, loss_s1: 0.015333, loss_fp: 0.001014, loss_freq: 0.007336
[16:54:05.470] iteration 27458: loss: 0.078874, loss_s1: 0.093851, loss_fp: 0.004006, loss_freq: 0.012050
[16:54:06.088] iteration 27459: loss: 0.037329, loss_s1: 0.026260, loss_fp: 0.001687, loss_freq: 0.016276
[16:54:06.696] iteration 27460: loss: 0.049577, loss_s1: 0.034190, loss_fp: 0.001195, loss_freq: 0.019939
[16:54:07.311] iteration 27461: loss: 0.069961, loss_s1: 0.066688, loss_fp: 0.002042, loss_freq: 0.030791
[16:54:07.941] iteration 27462: loss: 0.024942, loss_s1: 0.004513, loss_fp: 0.002970, loss_freq: 0.006539
[16:54:08.555] iteration 27463: loss: 0.046641, loss_s1: 0.047105, loss_fp: 0.000813, loss_freq: 0.017108
[16:54:09.169] iteration 27464: loss: 0.052029, loss_s1: 0.036263, loss_fp: 0.001513, loss_freq: 0.022441
[16:54:09.779] iteration 27465: loss: 0.037903, loss_s1: 0.019931, loss_fp: 0.001155, loss_freq: 0.013521
[16:54:10.397] iteration 27466: loss: 0.043984, loss_s1: 0.024518, loss_fp: 0.000780, loss_freq: 0.020970
[16:54:11.012] iteration 27467: loss: 0.060317, loss_s1: 0.055496, loss_fp: 0.005718, loss_freq: 0.013939
[16:54:11.635] iteration 27468: loss: 0.056013, loss_s1: 0.040836, loss_fp: 0.002037, loss_freq: 0.015892
[16:54:12.251] iteration 27469: loss: 0.076241, loss_s1: 0.079271, loss_fp: 0.028179, loss_freq: 0.006292
[16:54:12.876] iteration 27470: loss: 0.026091, loss_s1: 0.008850, loss_fp: 0.001612, loss_freq: 0.014397
[16:54:13.487] iteration 27471: loss: 0.076779, loss_s1: 0.087150, loss_fp: 0.005066, loss_freq: 0.023671
[16:54:14.100] iteration 27472: loss: 0.049930, loss_s1: 0.033371, loss_fp: 0.002777, loss_freq: 0.030613
[16:54:14.720] iteration 27473: loss: 0.051827, loss_s1: 0.028009, loss_fp: 0.006075, loss_freq: 0.034761
[16:54:15.346] iteration 27474: loss: 0.039389, loss_s1: 0.024475, loss_fp: 0.003427, loss_freq: 0.014901
[16:54:15.964] iteration 27475: loss: 0.045796, loss_s1: 0.035262, loss_fp: 0.001674, loss_freq: 0.028952
[16:54:16.580] iteration 27476: loss: 0.047976, loss_s1: 0.032087, loss_fp: 0.003764, loss_freq: 0.016042
[16:54:17.203] iteration 27477: loss: 0.081381, loss_s1: 0.051831, loss_fp: 0.003739, loss_freq: 0.059117
[16:54:17.821] iteration 27478: loss: 0.030018, loss_s1: 0.013912, loss_fp: 0.001547, loss_freq: 0.013492
[16:54:18.437] iteration 27479: loss: 0.045843, loss_s1: 0.035587, loss_fp: 0.001619, loss_freq: 0.021197
[16:54:19.060] iteration 27480: loss: 0.027154, loss_s1: 0.015019, loss_fp: 0.001453, loss_freq: 0.004572
[16:54:19.681] iteration 27481: loss: 0.033472, loss_s1: 0.010594, loss_fp: 0.007820, loss_freq: 0.008907
[16:54:20.308] iteration 27482: loss: 0.063599, loss_s1: 0.063277, loss_fp: 0.007571, loss_freq: 0.022320
[16:54:20.964] iteration 27483: loss: 0.099602, loss_s1: 0.054417, loss_fp: 0.003753, loss_freq: 0.071981
[16:54:21.605] iteration 27484: loss: 0.045660, loss_s1: 0.028565, loss_fp: 0.000500, loss_freq: 0.024484
[16:54:22.241] iteration 27485: loss: 0.074116, loss_s1: 0.066775, loss_fp: 0.006219, loss_freq: 0.036191
[16:54:22.876] iteration 27486: loss: 0.046709, loss_s1: 0.025067, loss_fp: 0.003750, loss_freq: 0.007484
[16:54:23.510] iteration 27487: loss: 0.034100, loss_s1: 0.022213, loss_fp: 0.003757, loss_freq: 0.010441
[16:54:24.133] iteration 27488: loss: 0.074876, loss_s1: 0.070566, loss_fp: 0.008828, loss_freq: 0.025252
[16:54:24.756] iteration 27489: loss: 0.052686, loss_s1: 0.026342, loss_fp: 0.006987, loss_freq: 0.045379
[16:54:25.373] iteration 27490: loss: 0.072704, loss_s1: 0.076739, loss_fp: 0.003925, loss_freq: 0.031365
[16:54:25.996] iteration 27491: loss: 0.065539, loss_s1: 0.059280, loss_fp: 0.006248, loss_freq: 0.024053
[16:54:26.615] iteration 27492: loss: 0.034620, loss_s1: 0.019260, loss_fp: 0.003864, loss_freq: 0.013258
[16:54:27.230] iteration 27493: loss: 0.034455, loss_s1: 0.011259, loss_fp: 0.002182, loss_freq: 0.013800
[16:54:27.843] iteration 27494: loss: 0.050612, loss_s1: 0.033070, loss_fp: 0.005587, loss_freq: 0.018385
[16:54:28.471] iteration 27495: loss: 0.084218, loss_s1: 0.064456, loss_fp: 0.009243, loss_freq: 0.055112
[16:54:29.085] iteration 27496: loss: 0.060454, loss_s1: 0.070581, loss_fp: 0.003607, loss_freq: 0.011621
[16:54:29.698] iteration 27497: loss: 0.058661, loss_s1: 0.039585, loss_fp: 0.010420, loss_freq: 0.032073
[16:54:30.317] iteration 27498: loss: 0.058824, loss_s1: 0.054298, loss_fp: 0.002434, loss_freq: 0.036306
[16:54:30.962] iteration 27499: loss: 0.046772, loss_s1: 0.028735, loss_fp: 0.002261, loss_freq: 0.016544
[16:54:31.596] iteration 27500: loss: 0.056257, loss_s1: 0.029333, loss_fp: 0.003435, loss_freq: 0.040165
[16:54:32.231] iteration 27501: loss: 0.030821, loss_s1: 0.003608, loss_fp: 0.001206, loss_freq: 0.015170
[16:54:32.869] iteration 27502: loss: 0.047133, loss_s1: 0.039730, loss_fp: 0.001560, loss_freq: 0.026577
[16:54:33.503] iteration 27503: loss: 0.043945, loss_s1: 0.037093, loss_fp: 0.009137, loss_freq: 0.008625
[16:54:34.123] iteration 27504: loss: 0.036919, loss_s1: 0.029840, loss_fp: 0.001896, loss_freq: 0.006162
[16:54:34.753] iteration 27505: loss: 0.042485, loss_s1: 0.036622, loss_fp: 0.005395, loss_freq: 0.016814
[16:54:35.370] iteration 27506: loss: 0.043822, loss_s1: 0.029820, loss_fp: 0.008377, loss_freq: 0.016190
[16:54:35.993] iteration 27507: loss: 0.039165, loss_s1: 0.018655, loss_fp: 0.005972, loss_freq: 0.017104
[16:54:36.613] iteration 27508: loss: 0.053694, loss_s1: 0.022351, loss_fp: 0.004840, loss_freq: 0.022354
[16:54:37.237] iteration 27509: loss: 0.047521, loss_s1: 0.036647, loss_fp: 0.003911, loss_freq: 0.021149
[16:54:37.855] iteration 27510: loss: 0.079176, loss_s1: 0.058058, loss_fp: 0.008931, loss_freq: 0.065519
[16:54:38.481] iteration 27511: loss: 0.032112, loss_s1: 0.016927, loss_fp: 0.001387, loss_freq: 0.005803
[16:54:39.136] iteration 27512: loss: 0.041600, loss_s1: 0.014880, loss_fp: 0.001525, loss_freq: 0.013001
[16:54:39.764] iteration 27513: loss: 0.079339, loss_s1: 0.080647, loss_fp: 0.005730, loss_freq: 0.042922
[16:54:40.409] iteration 27514: loss: 0.056818, loss_s1: 0.032826, loss_fp: 0.004548, loss_freq: 0.041928
[16:54:41.053] iteration 27515: loss: 0.072989, loss_s1: 0.038868, loss_fp: 0.000440, loss_freq: 0.069489
[16:54:41.697] iteration 27516: loss: 0.055542, loss_s1: 0.035992, loss_fp: 0.001565, loss_freq: 0.037442
[16:54:42.322] iteration 27517: loss: 0.058308, loss_s1: 0.037764, loss_fp: 0.003931, loss_freq: 0.033140
[16:54:42.972] iteration 27518: loss: 0.050023, loss_s1: 0.039228, loss_fp: 0.000413, loss_freq: 0.023086
[16:54:43.616] iteration 27519: loss: 0.077157, loss_s1: 0.068587, loss_fp: 0.005651, loss_freq: 0.035612
[16:54:44.260] iteration 27520: loss: 0.044942, loss_s1: 0.031458, loss_fp: 0.001284, loss_freq: 0.010807
[16:54:44.899] iteration 27521: loss: 0.052472, loss_s1: 0.034557, loss_fp: 0.004689, loss_freq: 0.023355
[16:54:45.533] iteration 27522: loss: 0.027918, loss_s1: 0.013887, loss_fp: 0.002044, loss_freq: 0.009309
[16:54:46.150] iteration 27523: loss: 0.071169, loss_s1: 0.061549, loss_fp: 0.013945, loss_freq: 0.021969
[16:54:46.764] iteration 27524: loss: 0.035802, loss_s1: 0.022390, loss_fp: 0.002009, loss_freq: 0.019425
[16:54:47.390] iteration 27525: loss: 0.053931, loss_s1: 0.062613, loss_fp: 0.002940, loss_freq: 0.012178
[16:54:48.009] iteration 27526: loss: 0.034622, loss_s1: 0.019157, loss_fp: 0.001592, loss_freq: 0.005591
[16:54:48.620] iteration 27527: loss: 0.043522, loss_s1: 0.032879, loss_fp: 0.003554, loss_freq: 0.010390
[16:54:49.254] iteration 27528: loss: 0.070116, loss_s1: 0.041332, loss_fp: 0.002105, loss_freq: 0.053713
[16:54:49.876] iteration 27529: loss: 0.026447, loss_s1: 0.011789, loss_fp: 0.002034, loss_freq: 0.009839
[16:54:50.493] iteration 27530: loss: 0.113471, loss_s1: 0.074393, loss_fp: 0.014140, loss_freq: 0.089743
[16:54:51.100] iteration 27531: loss: 0.091956, loss_s1: 0.089382, loss_fp: 0.003369, loss_freq: 0.064303
[16:54:51.720] iteration 27532: loss: 0.050252, loss_s1: 0.038000, loss_fp: 0.001670, loss_freq: 0.011559
[16:54:52.333] iteration 27533: loss: 0.039614, loss_s1: 0.041025, loss_fp: 0.004397, loss_freq: 0.008124
[16:54:52.950] iteration 27534: loss: 0.053081, loss_s1: 0.028747, loss_fp: 0.003832, loss_freq: 0.007377
[16:54:53.567] iteration 27535: loss: 0.054934, loss_s1: 0.031839, loss_fp: 0.003907, loss_freq: 0.030353
[16:54:54.187] iteration 27536: loss: 0.109891, loss_s1: 0.109134, loss_fp: 0.005585, loss_freq: 0.036711
[16:54:54.808] iteration 27537: loss: 0.056011, loss_s1: 0.046715, loss_fp: 0.004205, loss_freq: 0.021806
[16:54:55.428] iteration 27538: loss: 0.033810, loss_s1: 0.017196, loss_fp: 0.002485, loss_freq: 0.013290
[16:54:56.049] iteration 27539: loss: 0.035032, loss_s1: 0.016414, loss_fp: 0.001236, loss_freq: 0.019216
[16:54:56.663] iteration 27540: loss: 0.044798, loss_s1: 0.038412, loss_fp: 0.004054, loss_freq: 0.019625
[16:54:57.276] iteration 27541: loss: 0.070481, loss_s1: 0.082346, loss_fp: 0.002965, loss_freq: 0.020549
[16:54:57.896] iteration 27542: loss: 0.072431, loss_s1: 0.051363, loss_fp: 0.006779, loss_freq: 0.044314
[16:54:58.511] iteration 27543: loss: 0.028717, loss_s1: 0.016685, loss_fp: 0.000487, loss_freq: 0.004963
[16:54:59.129] iteration 27544: loss: 0.036500, loss_s1: 0.024345, loss_fp: 0.000288, loss_freq: 0.012518
[16:54:59.748] iteration 27545: loss: 0.030476, loss_s1: 0.009384, loss_fp: 0.008172, loss_freq: 0.010704
[16:55:00.363] iteration 27546: loss: 0.039923, loss_s1: 0.026100, loss_fp: 0.007203, loss_freq: 0.017194
[16:55:00.972] iteration 27547: loss: 0.062223, loss_s1: 0.041472, loss_fp: 0.004269, loss_freq: 0.018375
[16:55:01.587] iteration 27548: loss: 0.037859, loss_s1: 0.020673, loss_fp: 0.001538, loss_freq: 0.026392
[16:55:02.199] iteration 27549: loss: 0.053840, loss_s1: 0.061615, loss_fp: 0.002180, loss_freq: 0.007594
[16:55:02.811] iteration 27550: loss: 0.029418, loss_s1: 0.011880, loss_fp: 0.004178, loss_freq: 0.006622
[16:55:03.432] iteration 27551: loss: 0.029947, loss_s1: 0.017953, loss_fp: 0.001124, loss_freq: 0.007287
[16:55:04.055] iteration 27552: loss: 0.028697, loss_s1: 0.006748, loss_fp: 0.002304, loss_freq: 0.005625
[16:55:04.669] iteration 27553: loss: 0.062672, loss_s1: 0.036784, loss_fp: 0.002744, loss_freq: 0.046290
[16:55:05.291] iteration 27554: loss: 0.044830, loss_s1: 0.023035, loss_fp: 0.001772, loss_freq: 0.022768
[16:55:05.913] iteration 27555: loss: 0.054713, loss_s1: 0.049392, loss_fp: 0.002907, loss_freq: 0.015897
[16:55:06.518] iteration 27556: loss: 0.066137, loss_s1: 0.054457, loss_fp: 0.001938, loss_freq: 0.038028
[16:55:07.127] iteration 27557: loss: 0.057111, loss_s1: 0.055140, loss_fp: 0.002867, loss_freq: 0.026499
[16:55:07.748] iteration 27558: loss: 0.058090, loss_s1: 0.034178, loss_fp: 0.001778, loss_freq: 0.021219
[16:55:08.361] iteration 27559: loss: 0.082205, loss_s1: 0.074363, loss_fp: 0.002846, loss_freq: 0.041940
[16:55:08.981] iteration 27560: loss: 0.049143, loss_s1: 0.035623, loss_fp: 0.015200, loss_freq: 0.013228
[16:55:09.602] iteration 27561: loss: 0.046308, loss_s1: 0.007602, loss_fp: 0.001468, loss_freq: 0.014353
[16:55:10.233] iteration 27562: loss: 0.043902, loss_s1: 0.021598, loss_fp: 0.001351, loss_freq: 0.025460
[16:55:10.844] iteration 27563: loss: 0.077833, loss_s1: 0.066061, loss_fp: 0.002628, loss_freq: 0.042962
[16:55:11.462] iteration 27564: loss: 0.039088, loss_s1: 0.019115, loss_fp: 0.011385, loss_freq: 0.019873
[16:55:12.085] iteration 27565: loss: 0.039476, loss_s1: 0.023246, loss_fp: 0.001407, loss_freq: 0.016875
[16:55:12.731] iteration 27566: loss: 0.045253, loss_s1: 0.031946, loss_fp: 0.002293, loss_freq: 0.015065
[16:55:13.384] iteration 27567: loss: 0.041995, loss_s1: 0.020933, loss_fp: 0.010417, loss_freq: 0.007358
[16:55:14.024] iteration 27568: loss: 0.064914, loss_s1: 0.038673, loss_fp: 0.002353, loss_freq: 0.058139
[16:55:14.868] iteration 27569: loss: 0.028844, loss_s1: 0.016497, loss_fp: 0.002528, loss_freq: 0.007580
[16:55:15.735] iteration 27570: loss: 0.060439, loss_s1: 0.042218, loss_fp: 0.006051, loss_freq: 0.037326
[16:55:16.503] iteration 27571: loss: 0.050718, loss_s1: 0.046061, loss_fp: 0.001287, loss_freq: 0.004156
[16:55:17.158] iteration 27572: loss: 0.059781, loss_s1: 0.056556, loss_fp: 0.005306, loss_freq: 0.021215
[16:55:17.776] iteration 27573: loss: 0.045819, loss_s1: 0.035463, loss_fp: 0.007421, loss_freq: 0.011274
[16:55:18.398] iteration 27574: loss: 0.082136, loss_s1: 0.094214, loss_fp: 0.002875, loss_freq: 0.024798
[16:55:19.021] iteration 27575: loss: 0.068856, loss_s1: 0.045529, loss_fp: 0.003014, loss_freq: 0.044864
[16:55:19.650] iteration 27576: loss: 0.064009, loss_s1: 0.027754, loss_fp: 0.007106, loss_freq: 0.048437
[16:55:20.265] iteration 27577: loss: 0.060186, loss_s1: 0.031621, loss_fp: 0.001845, loss_freq: 0.041973
[16:55:20.883] iteration 27578: loss: 0.049579, loss_s1: 0.032933, loss_fp: 0.002095, loss_freq: 0.020528
[16:55:21.507] iteration 27579: loss: 0.027966, loss_s1: 0.013415, loss_fp: 0.001631, loss_freq: 0.008488
[16:55:22.125] iteration 27580: loss: 0.037191, loss_s1: 0.031137, loss_fp: 0.001331, loss_freq: 0.012572
[16:55:22.755] iteration 27581: loss: 0.072101, loss_s1: 0.049412, loss_fp: 0.014388, loss_freq: 0.051622
[16:55:23.397] iteration 27582: loss: 0.043885, loss_s1: 0.027895, loss_fp: 0.003739, loss_freq: 0.009074
[16:55:24.039] iteration 27583: loss: 0.057326, loss_s1: 0.050691, loss_fp: 0.001064, loss_freq: 0.035071
[16:55:24.675] iteration 27584: loss: 0.044706, loss_s1: 0.023499, loss_fp: 0.003861, loss_freq: 0.032284
[16:55:25.312] iteration 27585: loss: 0.070445, loss_s1: 0.075201, loss_fp: 0.007134, loss_freq: 0.018702
[16:55:25.944] iteration 27586: loss: 0.035829, loss_s1: 0.026129, loss_fp: 0.002452, loss_freq: 0.007286
[16:55:26.569] iteration 27587: loss: 0.041629, loss_s1: 0.031523, loss_fp: 0.004133, loss_freq: 0.010912
[16:55:27.182] iteration 27588: loss: 0.063801, loss_s1: 0.048110, loss_fp: 0.011187, loss_freq: 0.026080
[16:55:27.804] iteration 27589: loss: 0.041627, loss_s1: 0.035972, loss_fp: 0.005793, loss_freq: 0.011941
[16:55:28.420] iteration 27590: loss: 0.062668, loss_s1: 0.023134, loss_fp: 0.006335, loss_freq: 0.053387
[16:55:29.041] iteration 27591: loss: 0.068952, loss_s1: 0.053381, loss_fp: 0.010396, loss_freq: 0.027904
[16:55:29.661] iteration 27592: loss: 0.070992, loss_s1: 0.070086, loss_fp: 0.005449, loss_freq: 0.029516
[16:55:30.280] iteration 27593: loss: 0.084843, loss_s1: 0.065022, loss_fp: 0.009916, loss_freq: 0.042574
[16:55:30.898] iteration 27594: loss: 0.045199, loss_s1: 0.009209, loss_fp: 0.010321, loss_freq: 0.023363
[16:55:31.519] iteration 27595: loss: 0.046340, loss_s1: 0.033962, loss_fp: 0.002807, loss_freq: 0.024019
[16:55:32.136] iteration 27596: loss: 0.047219, loss_s1: 0.036020, loss_fp: 0.002264, loss_freq: 0.005660
[16:55:32.760] iteration 27597: loss: 0.044671, loss_s1: 0.029482, loss_fp: 0.003611, loss_freq: 0.021299
[16:55:33.379] iteration 27598: loss: 0.056487, loss_s1: 0.034921, loss_fp: 0.012357, loss_freq: 0.022740
[16:55:33.997] iteration 27599: loss: 0.037201, loss_s1: 0.016505, loss_fp: 0.002732, loss_freq: 0.023026
[16:55:34.945] iteration 27600: loss: 0.044296, loss_s1: 0.011629, loss_fp: 0.004097, loss_freq: 0.023084
[16:55:38.118] iteration 27600 : mean_dice : 0.791542
[16:55:38.760] iteration 27601: loss: 0.038979, loss_s1: 0.021112, loss_fp: 0.003707, loss_freq: 0.018098
[16:55:39.382] iteration 27602: loss: 0.050011, loss_s1: 0.043982, loss_fp: 0.003996, loss_freq: 0.014925
[16:55:40.004] iteration 27603: loss: 0.056603, loss_s1: 0.046768, loss_fp: 0.006967, loss_freq: 0.012563
[16:55:40.627] iteration 27604: loss: 0.051587, loss_s1: 0.050003, loss_fp: 0.004339, loss_freq: 0.019826
[16:55:41.249] iteration 27605: loss: 0.038670, loss_s1: 0.032346, loss_fp: 0.003447, loss_freq: 0.008352
[16:55:41.875] iteration 27606: loss: 0.032041, loss_s1: 0.018568, loss_fp: 0.003814, loss_freq: 0.013339
[16:55:42.491] iteration 27607: loss: 0.058363, loss_s1: 0.037843, loss_fp: 0.005660, loss_freq: 0.028717
[16:55:43.128] iteration 27608: loss: 0.044847, loss_s1: 0.022445, loss_fp: 0.010309, loss_freq: 0.013347
[16:55:43.817] iteration 27609: loss: 0.038408, loss_s1: 0.020870, loss_fp: 0.000567, loss_freq: 0.002506
[16:55:44.465] iteration 27610: loss: 0.054101, loss_s1: 0.030197, loss_fp: 0.002272, loss_freq: 0.044722
[16:55:45.095] iteration 27611: loss: 0.038677, loss_s1: 0.023649, loss_fp: 0.002983, loss_freq: 0.017698
[16:55:45.714] iteration 27612: loss: 0.058462, loss_s1: 0.059379, loss_fp: 0.009288, loss_freq: 0.005482
[16:55:46.355] iteration 27613: loss: 0.052232, loss_s1: 0.020523, loss_fp: 0.000760, loss_freq: 0.052523
[16:55:46.999] iteration 27614: loss: 0.058446, loss_s1: 0.046021, loss_fp: 0.002724, loss_freq: 0.034508
[16:55:47.645] iteration 27615: loss: 0.036534, loss_s1: 0.016898, loss_fp: 0.004214, loss_freq: 0.020010
[16:55:48.287] iteration 27616: loss: 0.039151, loss_s1: 0.010834, loss_fp: 0.004764, loss_freq: 0.020548
[16:55:48.933] iteration 27617: loss: 0.044998, loss_s1: 0.024744, loss_fp: 0.010303, loss_freq: 0.018626
[16:55:49.552] iteration 27618: loss: 0.046609, loss_s1: 0.023027, loss_fp: 0.004337, loss_freq: 0.036652
[16:55:50.172] iteration 27619: loss: 0.046762, loss_s1: 0.042590, loss_fp: 0.005713, loss_freq: 0.013469
[16:55:50.789] iteration 27620: loss: 0.089431, loss_s1: 0.039764, loss_fp: 0.007692, loss_freq: 0.091055
[16:55:51.413] iteration 27621: loss: 0.047087, loss_s1: 0.047036, loss_fp: 0.001148, loss_freq: 0.019094
[16:55:52.032] iteration 27622: loss: 0.043400, loss_s1: 0.023942, loss_fp: 0.003287, loss_freq: 0.022374
[16:55:52.657] iteration 27623: loss: 0.047245, loss_s1: 0.040646, loss_fp: 0.008875, loss_freq: 0.011287
[16:55:53.278] iteration 27624: loss: 0.037814, loss_s1: 0.019737, loss_fp: 0.002398, loss_freq: 0.010851
[16:55:53.901] iteration 27625: loss: 0.071541, loss_s1: 0.060765, loss_fp: 0.003211, loss_freq: 0.035940
[16:55:54.529] iteration 27626: loss: 0.049606, loss_s1: 0.035246, loss_fp: 0.001508, loss_freq: 0.022029
[16:55:55.144] iteration 27627: loss: 0.030891, loss_s1: 0.019559, loss_fp: 0.001886, loss_freq: 0.008136
[16:55:55.779] iteration 27628: loss: 0.078873, loss_s1: 0.059880, loss_fp: 0.005797, loss_freq: 0.041456
[16:55:56.413] iteration 27629: loss: 0.052516, loss_s1: 0.037296, loss_fp: 0.000867, loss_freq: 0.013637
[16:55:57.045] iteration 27630: loss: 0.027510, loss_s1: 0.016135, loss_fp: 0.000562, loss_freq: 0.006025
[16:55:57.688] iteration 27631: loss: 0.066707, loss_s1: 0.042216, loss_fp: 0.002711, loss_freq: 0.020781
[16:55:58.318] iteration 27632: loss: 0.059568, loss_s1: 0.053097, loss_fp: 0.002244, loss_freq: 0.031291
[16:55:58.949] iteration 27633: loss: 0.077462, loss_s1: 0.078426, loss_fp: 0.006500, loss_freq: 0.042499
[16:55:59.574] iteration 27634: loss: 0.051544, loss_s1: 0.044700, loss_fp: 0.004826, loss_freq: 0.020176
[16:56:00.198] iteration 27635: loss: 0.044940, loss_s1: 0.028868, loss_fp: 0.003099, loss_freq: 0.016365
[16:56:00.817] iteration 27636: loss: 0.056660, loss_s1: 0.036281, loss_fp: 0.005051, loss_freq: 0.016673
[16:56:01.436] iteration 27637: loss: 0.038040, loss_s1: 0.022016, loss_fp: 0.001732, loss_freq: 0.014052
[16:56:02.074] iteration 27638: loss: 0.068891, loss_s1: 0.073491, loss_fp: 0.004157, loss_freq: 0.015640
[16:56:02.740] iteration 27639: loss: 0.036382, loss_s1: 0.014073, loss_fp: 0.008266, loss_freq: 0.019899
[16:56:03.374] iteration 27640: loss: 0.052573, loss_s1: 0.031519, loss_fp: 0.003160, loss_freq: 0.017081
[16:56:04.020] iteration 27641: loss: 0.030872, loss_s1: 0.019525, loss_fp: 0.004599, loss_freq: 0.011423
[16:56:04.667] iteration 27642: loss: 0.037967, loss_s1: 0.015969, loss_fp: 0.002557, loss_freq: 0.015259
[16:56:05.302] iteration 27643: loss: 0.058473, loss_s1: 0.041858, loss_fp: 0.006096, loss_freq: 0.035756
[16:56:05.936] iteration 27644: loss: 0.061594, loss_s1: 0.034412, loss_fp: 0.002923, loss_freq: 0.015513
[16:56:06.574] iteration 27645: loss: 0.103367, loss_s1: 0.093601, loss_fp: 0.009584, loss_freq: 0.056558
[16:56:07.218] iteration 27646: loss: 0.052970, loss_s1: 0.032363, loss_fp: 0.003977, loss_freq: 0.036608
[16:56:07.861] iteration 27647: loss: 0.048071, loss_s1: 0.040728, loss_fp: 0.003713, loss_freq: 0.015051
[16:56:08.498] iteration 27648: loss: 0.061877, loss_s1: 0.053979, loss_fp: 0.011251, loss_freq: 0.032716
[16:56:09.142] iteration 27649: loss: 0.037910, loss_s1: 0.018557, loss_fp: 0.001720, loss_freq: 0.019583
[16:56:09.781] iteration 27650: loss: 0.040148, loss_s1: 0.019447, loss_fp: 0.007095, loss_freq: 0.019873
[16:56:10.425] iteration 27651: loss: 0.069935, loss_s1: 0.044044, loss_fp: 0.001413, loss_freq: 0.037834
[16:56:11.041] iteration 27652: loss: 0.061981, loss_s1: 0.055267, loss_fp: 0.001391, loss_freq: 0.034597
[16:56:11.655] iteration 27653: loss: 0.075602, loss_s1: 0.047166, loss_fp: 0.002451, loss_freq: 0.073419
[16:56:12.276] iteration 27654: loss: 0.061633, loss_s1: 0.046449, loss_fp: 0.000869, loss_freq: 0.033990
[16:56:12.894] iteration 27655: loss: 0.050817, loss_s1: 0.041505, loss_fp: 0.002914, loss_freq: 0.018263
[16:56:13.571] iteration 27656: loss: 0.037364, loss_s1: 0.025526, loss_fp: 0.003426, loss_freq: 0.019484
[16:56:14.200] iteration 27657: loss: 0.036854, loss_s1: 0.014782, loss_fp: 0.000789, loss_freq: 0.022818
[16:56:14.822] iteration 27658: loss: 0.060547, loss_s1: 0.036653, loss_fp: 0.001350, loss_freq: 0.046320
[16:56:15.445] iteration 27659: loss: 0.037380, loss_s1: 0.016647, loss_fp: 0.001851, loss_freq: 0.015778
[16:56:16.070] iteration 27660: loss: 0.050151, loss_s1: 0.034411, loss_fp: 0.003999, loss_freq: 0.018242
[16:56:16.688] iteration 27661: loss: 0.086371, loss_s1: 0.053391, loss_fp: 0.004472, loss_freq: 0.068340
[16:56:17.315] iteration 27662: loss: 0.089528, loss_s1: 0.077076, loss_fp: 0.011877, loss_freq: 0.051390
[16:56:17.929] iteration 27663: loss: 0.039086, loss_s1: 0.016196, loss_fp: 0.001262, loss_freq: 0.023264
[16:56:18.551] iteration 27664: loss: 0.064215, loss_s1: 0.014471, loss_fp: 0.003591, loss_freq: 0.029931
[16:56:19.170] iteration 27665: loss: 0.040959, loss_s1: 0.021636, loss_fp: 0.008267, loss_freq: 0.021085
[16:56:19.792] iteration 27666: loss: 0.097450, loss_s1: 0.096747, loss_fp: 0.010635, loss_freq: 0.041236
[16:56:20.413] iteration 27667: loss: 0.039099, loss_s1: 0.025627, loss_fp: 0.003522, loss_freq: 0.019234
[16:56:21.026] iteration 27668: loss: 0.052155, loss_s1: 0.053892, loss_fp: 0.002013, loss_freq: 0.011603
[16:56:21.649] iteration 27669: loss: 0.043738, loss_s1: 0.023752, loss_fp: 0.004258, loss_freq: 0.010847
[16:56:22.267] iteration 27670: loss: 0.033324, loss_s1: 0.021151, loss_fp: 0.001433, loss_freq: 0.009494
[16:56:22.907] iteration 27671: loss: 0.079258, loss_s1: 0.061056, loss_fp: 0.007935, loss_freq: 0.052171
[16:56:23.543] iteration 27672: loss: 0.047239, loss_s1: 0.006485, loss_fp: 0.007312, loss_freq: 0.042543
[16:56:24.192] iteration 27673: loss: 0.081084, loss_s1: 0.081661, loss_fp: 0.002943, loss_freq: 0.038190
[16:56:24.830] iteration 27674: loss: 0.069467, loss_s1: 0.060335, loss_fp: 0.005615, loss_freq: 0.044007
[16:56:25.473] iteration 27675: loss: 0.053045, loss_s1: 0.024666, loss_fp: 0.003926, loss_freq: 0.023633
[16:56:26.118] iteration 27676: loss: 0.047154, loss_s1: 0.021714, loss_fp: 0.002700, loss_freq: 0.045050
[16:56:26.739] iteration 27677: loss: 0.048109, loss_s1: 0.031846, loss_fp: 0.001256, loss_freq: 0.020862
[16:56:27.356] iteration 27678: loss: 0.062295, loss_s1: 0.057060, loss_fp: 0.006901, loss_freq: 0.026384
[16:56:27.980] iteration 27679: loss: 0.097219, loss_s1: 0.062452, loss_fp: 0.004571, loss_freq: 0.021883
[16:56:28.599] iteration 27680: loss: 0.060126, loss_s1: 0.047461, loss_fp: 0.003756, loss_freq: 0.012377
[16:56:29.222] iteration 27681: loss: 0.050488, loss_s1: 0.047581, loss_fp: 0.003267, loss_freq: 0.016723
[16:56:29.845] iteration 27682: loss: 0.062363, loss_s1: 0.073073, loss_fp: 0.000826, loss_freq: 0.013930
[16:56:30.464] iteration 27683: loss: 0.042371, loss_s1: 0.036631, loss_fp: 0.001179, loss_freq: 0.018690
[16:56:31.090] iteration 27684: loss: 0.057195, loss_s1: 0.052798, loss_fp: 0.003318, loss_freq: 0.028410
[16:56:31.707] iteration 27685: loss: 0.049163, loss_s1: 0.018293, loss_fp: 0.005013, loss_freq: 0.029720
[16:56:32.324] iteration 27686: loss: 0.038707, loss_s1: 0.011812, loss_fp: 0.001171, loss_freq: 0.004930
[16:56:32.940] iteration 27687: loss: 0.034169, loss_s1: 0.019401, loss_fp: 0.000595, loss_freq: 0.017743
[16:56:33.565] iteration 27688: loss: 0.040641, loss_s1: 0.045966, loss_fp: 0.001096, loss_freq: 0.009235
[16:56:34.191] iteration 27689: loss: 0.048451, loss_s1: 0.051934, loss_fp: 0.004148, loss_freq: 0.015783
[16:56:34.805] iteration 27690: loss: 0.064617, loss_s1: 0.049555, loss_fp: 0.008316, loss_freq: 0.032417
[16:56:35.424] iteration 27691: loss: 0.042852, loss_s1: 0.026689, loss_fp: 0.002405, loss_freq: 0.022520
[16:56:36.046] iteration 27692: loss: 0.037114, loss_s1: 0.029264, loss_fp: 0.004718, loss_freq: 0.002374
[16:56:36.667] iteration 27693: loss: 0.031443, loss_s1: 0.017756, loss_fp: 0.000727, loss_freq: 0.006606
[16:56:37.291] iteration 27694: loss: 0.064279, loss_s1: 0.063888, loss_fp: 0.000739, loss_freq: 0.017370
[16:56:37.915] iteration 27695: loss: 0.041020, loss_s1: 0.017086, loss_fp: 0.001030, loss_freq: 0.009211
[16:56:38.535] iteration 27696: loss: 0.055071, loss_s1: 0.040131, loss_fp: 0.000857, loss_freq: 0.031478
[16:56:39.161] iteration 27697: loss: 0.041003, loss_s1: 0.036313, loss_fp: 0.000587, loss_freq: 0.014904
[16:56:39.782] iteration 27698: loss: 0.065079, loss_s1: 0.030560, loss_fp: 0.001352, loss_freq: 0.006465
[16:56:40.402] iteration 27699: loss: 0.061199, loss_s1: 0.061096, loss_fp: 0.011861, loss_freq: 0.013673
[16:56:41.027] iteration 27700: loss: 0.044043, loss_s1: 0.032550, loss_fp: 0.000512, loss_freq: 0.018204
[16:56:41.661] iteration 27701: loss: 0.051563, loss_s1: 0.020007, loss_fp: 0.004530, loss_freq: 0.019794
[16:56:42.302] iteration 27702: loss: 0.048261, loss_s1: 0.039899, loss_fp: 0.001414, loss_freq: 0.017651
[16:56:42.942] iteration 27703: loss: 0.036210, loss_s1: 0.032916, loss_fp: 0.004404, loss_freq: 0.003381
[16:56:43.568] iteration 27704: loss: 0.038151, loss_s1: 0.014859, loss_fp: 0.004025, loss_freq: 0.013676
[16:56:44.207] iteration 27705: loss: 0.037685, loss_s1: 0.006738, loss_fp: 0.003040, loss_freq: 0.031465
[16:56:44.867] iteration 27706: loss: 0.087763, loss_s1: 0.059645, loss_fp: 0.005658, loss_freq: 0.065415
[16:56:45.510] iteration 27707: loss: 0.073037, loss_s1: 0.061453, loss_fp: 0.005505, loss_freq: 0.050726
[16:56:46.128] iteration 27708: loss: 0.065214, loss_s1: 0.043886, loss_fp: 0.001436, loss_freq: 0.035206
[16:56:46.780] iteration 27709: loss: 0.074009, loss_s1: 0.049237, loss_fp: 0.013742, loss_freq: 0.059377
[16:56:47.433] iteration 27710: loss: 0.042998, loss_s1: 0.039190, loss_fp: 0.001257, loss_freq: 0.003863
[16:56:48.055] iteration 27711: loss: 0.047671, loss_s1: 0.032230, loss_fp: 0.002127, loss_freq: 0.035285
[16:56:48.679] iteration 27712: loss: 0.040406, loss_s1: 0.028394, loss_fp: 0.000783, loss_freq: 0.008021
[16:56:49.307] iteration 27713: loss: 0.070397, loss_s1: 0.074336, loss_fp: 0.010082, loss_freq: 0.020124
[16:56:49.926] iteration 27714: loss: 0.048623, loss_s1: 0.018270, loss_fp: 0.002287, loss_freq: 0.007173
[16:56:50.545] iteration 27715: loss: 0.037456, loss_s1: 0.013996, loss_fp: 0.007463, loss_freq: 0.010757
[16:56:51.214] iteration 27716: loss: 0.073729, loss_s1: 0.052934, loss_fp: 0.004551, loss_freq: 0.039871
[16:56:51.835] iteration 27717: loss: 0.057907, loss_s1: 0.044698, loss_fp: 0.008876, loss_freq: 0.026618
[16:56:52.471] iteration 27718: loss: 0.053562, loss_s1: 0.047322, loss_fp: 0.013961, loss_freq: 0.016429
[16:56:53.135] iteration 27719: loss: 0.058759, loss_s1: 0.043567, loss_fp: 0.002926, loss_freq: 0.039318
[16:56:53.833] iteration 27720: loss: 0.065231, loss_s1: 0.043686, loss_fp: 0.016897, loss_freq: 0.022000
[16:56:54.506] iteration 27721: loss: 0.092125, loss_s1: 0.062046, loss_fp: 0.005734, loss_freq: 0.041391
[16:56:55.177] iteration 27722: loss: 0.026038, loss_s1: 0.015862, loss_fp: 0.001402, loss_freq: 0.006124
[16:56:55.810] iteration 27723: loss: 0.045945, loss_s1: 0.032367, loss_fp: 0.004718, loss_freq: 0.028226
[16:56:56.442] iteration 27724: loss: 0.066695, loss_s1: 0.067161, loss_fp: 0.024952, loss_freq: 0.012015
[16:56:57.081] iteration 27725: loss: 0.040752, loss_s1: 0.010123, loss_fp: 0.001534, loss_freq: 0.006899
[16:56:57.705] iteration 27726: loss: 0.044794, loss_s1: 0.041203, loss_fp: 0.002029, loss_freq: 0.019413
[16:56:58.331] iteration 27727: loss: 0.035259, loss_s1: 0.027643, loss_fp: 0.004402, loss_freq: 0.010414
[16:56:58.961] iteration 27728: loss: 0.079790, loss_s1: 0.068610, loss_fp: 0.000846, loss_freq: 0.017665
[16:56:59.589] iteration 27729: loss: 0.056557, loss_s1: 0.040853, loss_fp: 0.006836, loss_freq: 0.012639
[16:57:00.213] iteration 27730: loss: 0.074777, loss_s1: 0.037678, loss_fp: 0.001657, loss_freq: 0.051843
[16:57:00.838] iteration 27731: loss: 0.058026, loss_s1: 0.049331, loss_fp: 0.001879, loss_freq: 0.017704
[16:57:01.450] iteration 27732: loss: 0.039279, loss_s1: 0.012711, loss_fp: 0.008847, loss_freq: 0.015499
[16:57:02.066] iteration 27733: loss: 0.079266, loss_s1: 0.046031, loss_fp: 0.008157, loss_freq: 0.064631
[16:57:02.688] iteration 27734: loss: 0.061691, loss_s1: 0.019123, loss_fp: 0.004538, loss_freq: 0.027498
[16:57:03.309] iteration 27735: loss: 0.062814, loss_s1: 0.065621, loss_fp: 0.006378, loss_freq: 0.020616
[16:57:03.929] iteration 27736: loss: 0.069615, loss_s1: 0.047346, loss_fp: 0.006952, loss_freq: 0.015248
[16:57:04.551] iteration 27737: loss: 0.038389, loss_s1: 0.030823, loss_fp: 0.001422, loss_freq: 0.005080
[16:57:05.188] iteration 27738: loss: 0.042810, loss_s1: 0.027620, loss_fp: 0.000982, loss_freq: 0.009876
[16:57:05.817] iteration 27739: loss: 0.045397, loss_s1: 0.025584, loss_fp: 0.007303, loss_freq: 0.020923
[16:57:06.434] iteration 27740: loss: 0.048506, loss_s1: 0.036348, loss_fp: 0.002545, loss_freq: 0.023404
[16:57:07.055] iteration 27741: loss: 0.043428, loss_s1: 0.026922, loss_fp: 0.007026, loss_freq: 0.015316
[16:57:07.674] iteration 27742: loss: 0.029398, loss_s1: 0.011790, loss_fp: 0.002109, loss_freq: 0.017543
[16:57:08.661] iteration 27743: loss: 0.064743, loss_s1: 0.075895, loss_fp: 0.004118, loss_freq: 0.015562
[16:57:09.283] iteration 27744: loss: 0.049592, loss_s1: 0.034745, loss_fp: 0.001653, loss_freq: 0.013246
[16:57:09.913] iteration 27745: loss: 0.034167, loss_s1: 0.020449, loss_fp: 0.004303, loss_freq: 0.016177
[16:57:10.539] iteration 27746: loss: 0.063055, loss_s1: 0.038460, loss_fp: 0.015003, loss_freq: 0.025171
[16:57:11.170] iteration 27747: loss: 0.075275, loss_s1: 0.080788, loss_fp: 0.005751, loss_freq: 0.035084
[16:57:11.798] iteration 27748: loss: 0.047383, loss_s1: 0.055070, loss_fp: 0.001118, loss_freq: 0.002629
[16:57:12.436] iteration 27749: loss: 0.031154, loss_s1: 0.026592, loss_fp: 0.001386, loss_freq: 0.008573
[16:57:13.087] iteration 27750: loss: 0.074047, loss_s1: 0.044511, loss_fp: 0.007359, loss_freq: 0.037006
[16:57:13.726] iteration 27751: loss: 0.070777, loss_s1: 0.051430, loss_fp: 0.004568, loss_freq: 0.051969
[16:57:14.375] iteration 27752: loss: 0.027279, loss_s1: 0.006194, loss_fp: 0.000933, loss_freq: 0.003955
[16:57:15.016] iteration 27753: loss: 0.052797, loss_s1: 0.022641, loss_fp: 0.006046, loss_freq: 0.041537
[16:57:15.656] iteration 27754: loss: 0.063936, loss_s1: 0.043232, loss_fp: 0.001258, loss_freq: 0.025379
[16:57:16.307] iteration 27755: loss: 0.038663, loss_s1: 0.029460, loss_fp: 0.001579, loss_freq: 0.007991
[16:57:16.929] iteration 27756: loss: 0.038573, loss_s1: 0.028529, loss_fp: 0.000445, loss_freq: 0.020355
[16:57:17.560] iteration 27757: loss: 0.043492, loss_s1: 0.020385, loss_fp: 0.003800, loss_freq: 0.027372
[16:57:18.191] iteration 27758: loss: 0.047051, loss_s1: 0.031359, loss_fp: 0.001808, loss_freq: 0.020464
[16:57:18.807] iteration 27759: loss: 0.039539, loss_s1: 0.012868, loss_fp: 0.000762, loss_freq: 0.027956
[16:57:19.451] iteration 27760: loss: 0.069717, loss_s1: 0.055730, loss_fp: 0.007466, loss_freq: 0.023812
[16:57:20.177] iteration 27761: loss: 0.033769, loss_s1: 0.019315, loss_fp: 0.004783, loss_freq: 0.014055
[16:57:20.956] iteration 27762: loss: 0.029606, loss_s1: 0.016473, loss_fp: 0.003269, loss_freq: 0.011371
[16:57:21.866] iteration 27763: loss: 0.084735, loss_s1: 0.037594, loss_fp: 0.003029, loss_freq: 0.039065
[16:57:22.478] iteration 27764: loss: 0.055745, loss_s1: 0.056412, loss_fp: 0.002441, loss_freq: 0.023948
[16:57:23.092] iteration 27765: loss: 0.044388, loss_s1: 0.020905, loss_fp: 0.001952, loss_freq: 0.024524
[16:57:23.712] iteration 27766: loss: 0.036471, loss_s1: 0.024587, loss_fp: 0.003885, loss_freq: 0.014326
[16:57:24.330] iteration 27767: loss: 0.038786, loss_s1: 0.025082, loss_fp: 0.001449, loss_freq: 0.006155
[16:57:24.944] iteration 27768: loss: 0.069845, loss_s1: 0.047027, loss_fp: 0.004233, loss_freq: 0.036756
[16:57:25.568] iteration 27769: loss: 0.095609, loss_s1: 0.079673, loss_fp: 0.005803, loss_freq: 0.062113
[16:57:26.185] iteration 27770: loss: 0.040905, loss_s1: 0.034826, loss_fp: 0.002521, loss_freq: 0.003568
[16:57:26.827] iteration 27771: loss: 0.057846, loss_s1: 0.054764, loss_fp: 0.000764, loss_freq: 0.019238
[16:57:27.447] iteration 27772: loss: 0.046130, loss_s1: 0.011971, loss_fp: 0.003445, loss_freq: 0.012739
[16:57:28.089] iteration 27773: loss: 0.045315, loss_s1: 0.030085, loss_fp: 0.001321, loss_freq: 0.019997
[16:57:28.733] iteration 27774: loss: 0.042121, loss_s1: 0.012649, loss_fp: 0.004156, loss_freq: 0.019921
[16:57:29.377] iteration 27775: loss: 0.059597, loss_s1: 0.039343, loss_fp: 0.008797, loss_freq: 0.039700
[16:57:29.992] iteration 27776: loss: 0.079338, loss_s1: 0.070959, loss_fp: 0.006294, loss_freq: 0.051552
[16:57:30.620] iteration 27777: loss: 0.070984, loss_s1: 0.056589, loss_fp: 0.005660, loss_freq: 0.028510
[16:57:31.241] iteration 27778: loss: 0.058384, loss_s1: 0.053826, loss_fp: 0.007967, loss_freq: 0.022677
[16:57:31.861] iteration 27779: loss: 0.059894, loss_s1: 0.024524, loss_fp: 0.003141, loss_freq: 0.052808
[16:57:32.485] iteration 27780: loss: 0.030275, loss_s1: 0.014773, loss_fp: 0.002714, loss_freq: 0.007871
[16:57:33.100] iteration 27781: loss: 0.081594, loss_s1: 0.073538, loss_fp: 0.004289, loss_freq: 0.041467
[16:57:33.734] iteration 27782: loss: 0.033986, loss_s1: 0.032444, loss_fp: 0.003286, loss_freq: 0.008143
[16:57:34.353] iteration 27783: loss: 0.058216, loss_s1: 0.051288, loss_fp: 0.005676, loss_freq: 0.013734
[16:57:34.972] iteration 27784: loss: 0.052461, loss_s1: 0.055167, loss_fp: 0.001228, loss_freq: 0.021340
[16:57:35.627] iteration 27785: loss: 0.044794, loss_s1: 0.016098, loss_fp: 0.003513, loss_freq: 0.024347
[16:57:36.239] iteration 27786: loss: 0.060288, loss_s1: 0.039667, loss_fp: 0.004767, loss_freq: 0.041072
[16:57:36.863] iteration 27787: loss: 0.042883, loss_s1: 0.017550, loss_fp: 0.000429, loss_freq: 0.008449
[16:57:37.520] iteration 27788: loss: 0.088074, loss_s1: 0.105026, loss_fp: 0.001193, loss_freq: 0.040497
[16:57:38.139] iteration 27789: loss: 0.042083, loss_s1: 0.030789, loss_fp: 0.002046, loss_freq: 0.019059
[16:57:38.751] iteration 27790: loss: 0.038949, loss_s1: 0.015163, loss_fp: 0.005901, loss_freq: 0.020326
[16:57:39.368] iteration 27791: loss: 0.047366, loss_s1: 0.045185, loss_fp: 0.005070, loss_freq: 0.018364
[16:57:39.989] iteration 27792: loss: 0.035004, loss_s1: 0.013765, loss_fp: 0.006896, loss_freq: 0.015050
[16:57:40.603] iteration 27793: loss: 0.040627, loss_s1: 0.018303, loss_fp: 0.003992, loss_freq: 0.029409
[16:57:41.218] iteration 27794: loss: 0.047856, loss_s1: 0.017427, loss_fp: 0.002962, loss_freq: 0.031387
[16:57:41.848] iteration 27795: loss: 0.037086, loss_s1: 0.019439, loss_fp: 0.006193, loss_freq: 0.014212
[16:57:42.469] iteration 27796: loss: 0.066968, loss_s1: 0.049594, loss_fp: 0.008716, loss_freq: 0.046654
[16:57:43.095] iteration 27797: loss: 0.031136, loss_s1: 0.020256, loss_fp: 0.002659, loss_freq: 0.011175
[16:57:43.725] iteration 27798: loss: 0.046418, loss_s1: 0.028787, loss_fp: 0.000780, loss_freq: 0.009130
[16:57:44.351] iteration 27799: loss: 0.074905, loss_s1: 0.054793, loss_fp: 0.002242, loss_freq: 0.061889
[16:57:45.009] iteration 27800: loss: 0.051149, loss_s1: 0.043349, loss_fp: 0.006490, loss_freq: 0.021192
[16:57:48.448] iteration 27800 : mean_dice : 0.799486
[16:57:49.096] iteration 27801: loss: 0.060446, loss_s1: 0.037553, loss_fp: 0.000513, loss_freq: 0.045430
[16:57:49.721] iteration 27802: loss: 0.053534, loss_s1: 0.026155, loss_fp: 0.003009, loss_freq: 0.039871
[16:57:50.345] iteration 27803: loss: 0.056214, loss_s1: 0.046546, loss_fp: 0.003681, loss_freq: 0.011749
[16:57:50.971] iteration 27804: loss: 0.054139, loss_s1: 0.047168, loss_fp: 0.000659, loss_freq: 0.018647
[16:57:51.589] iteration 27805: loss: 0.085934, loss_s1: 0.088594, loss_fp: 0.016206, loss_freq: 0.026304
[16:57:52.216] iteration 27806: loss: 0.039535, loss_s1: 0.010921, loss_fp: 0.000731, loss_freq: 0.025563
[16:57:52.835] iteration 27807: loss: 0.054726, loss_s1: 0.044317, loss_fp: 0.004797, loss_freq: 0.022297
[16:57:53.461] iteration 27808: loss: 0.035490, loss_s1: 0.025408, loss_fp: 0.002234, loss_freq: 0.011154
[16:57:54.102] iteration 27809: loss: 0.066618, loss_s1: 0.050470, loss_fp: 0.014979, loss_freq: 0.021442
[16:57:54.742] iteration 27810: loss: 0.055632, loss_s1: 0.032949, loss_fp: 0.004964, loss_freq: 0.043121
[16:57:55.384] iteration 27811: loss: 0.032089, loss_s1: 0.014511, loss_fp: 0.005122, loss_freq: 0.005827
[16:57:56.017] iteration 27812: loss: 0.049390, loss_s1: 0.039642, loss_fp: 0.004832, loss_freq: 0.010172
[16:57:56.640] iteration 27813: loss: 0.044809, loss_s1: 0.034976, loss_fp: 0.002126, loss_freq: 0.012078
[16:57:57.252] iteration 27814: loss: 0.061511, loss_s1: 0.060459, loss_fp: 0.003676, loss_freq: 0.016497
[16:57:57.873] iteration 27815: loss: 0.065297, loss_s1: 0.052307, loss_fp: 0.001746, loss_freq: 0.025240
[16:57:58.509] iteration 27816: loss: 0.072709, loss_s1: 0.036316, loss_fp: 0.001736, loss_freq: 0.055502
[16:57:59.144] iteration 27817: loss: 0.058345, loss_s1: 0.046727, loss_fp: 0.003992, loss_freq: 0.043552
[16:57:59.768] iteration 27818: loss: 0.059720, loss_s1: 0.041558, loss_fp: 0.001484, loss_freq: 0.012072
[16:58:00.387] iteration 27819: loss: 0.037346, loss_s1: 0.035117, loss_fp: 0.003139, loss_freq: 0.008159
[16:58:01.004] iteration 27820: loss: 0.052583, loss_s1: 0.048427, loss_fp: 0.002071, loss_freq: 0.016818
[16:58:01.627] iteration 27821: loss: 0.093774, loss_s1: 0.112251, loss_fp: 0.015039, loss_freq: 0.026472
[16:58:02.248] iteration 27822: loss: 0.069393, loss_s1: 0.042839, loss_fp: 0.003222, loss_freq: 0.038877
[16:58:02.868] iteration 27823: loss: 0.050194, loss_s1: 0.031706, loss_fp: 0.001795, loss_freq: 0.034300
[16:58:03.490] iteration 27824: loss: 0.060400, loss_s1: 0.062239, loss_fp: 0.001240, loss_freq: 0.026646
[16:58:04.104] iteration 27825: loss: 0.039280, loss_s1: 0.018780, loss_fp: 0.004335, loss_freq: 0.022459
[16:58:04.719] iteration 27826: loss: 0.058311, loss_s1: 0.061002, loss_fp: 0.008400, loss_freq: 0.018305
[16:58:05.326] iteration 27827: loss: 0.050925, loss_s1: 0.051850, loss_fp: 0.003198, loss_freq: 0.015074
[16:58:05.943] iteration 27828: loss: 0.053653, loss_s1: 0.037594, loss_fp: 0.007114, loss_freq: 0.029763
[16:58:06.581] iteration 27829: loss: 0.051281, loss_s1: 0.023991, loss_fp: 0.002843, loss_freq: 0.018336
[16:58:07.200] iteration 27830: loss: 0.031395, loss_s1: 0.009136, loss_fp: 0.000700, loss_freq: 0.021704
[16:58:07.818] iteration 27831: loss: 0.032741, loss_s1: 0.030575, loss_fp: 0.001517, loss_freq: 0.008607
[16:58:08.440] iteration 27832: loss: 0.045103, loss_s1: 0.036111, loss_fp: 0.004530, loss_freq: 0.015034
[16:58:09.062] iteration 27833: loss: 0.050023, loss_s1: 0.035732, loss_fp: 0.003163, loss_freq: 0.025136
[16:58:09.677] iteration 27834: loss: 0.035480, loss_s1: 0.026154, loss_fp: 0.006881, loss_freq: 0.009547
[16:58:10.304] iteration 27835: loss: 0.039945, loss_s1: 0.039443, loss_fp: 0.002895, loss_freq: 0.008323
[16:58:10.919] iteration 27836: loss: 0.026864, loss_s1: 0.014708, loss_fp: 0.002768, loss_freq: 0.004144
[16:58:11.536] iteration 27837: loss: 0.031123, loss_s1: 0.023369, loss_fp: 0.000626, loss_freq: 0.006600
[16:58:12.159] iteration 27838: loss: 0.032807, loss_s1: 0.006572, loss_fp: 0.002551, loss_freq: 0.003632
[16:58:12.788] iteration 27839: loss: 0.047006, loss_s1: 0.019419, loss_fp: 0.007055, loss_freq: 0.028406
[16:58:13.415] iteration 27840: loss: 0.047324, loss_s1: 0.034742, loss_fp: 0.003209, loss_freq: 0.012912
[16:58:14.039] iteration 27841: loss: 0.055550, loss_s1: 0.024586, loss_fp: 0.008379, loss_freq: 0.020575
[16:58:14.671] iteration 27842: loss: 0.066586, loss_s1: 0.030336, loss_fp: 0.007684, loss_freq: 0.052582
[16:58:15.299] iteration 27843: loss: 0.048365, loss_s1: 0.038623, loss_fp: 0.006405, loss_freq: 0.019678
[16:58:15.925] iteration 27844: loss: 0.046886, loss_s1: 0.019467, loss_fp: 0.002268, loss_freq: 0.016620
[16:58:16.544] iteration 27845: loss: 0.099187, loss_s1: 0.077611, loss_fp: 0.002818, loss_freq: 0.064525
[16:58:17.167] iteration 27846: loss: 0.062549, loss_s1: 0.076263, loss_fp: 0.002578, loss_freq: 0.010436
[16:58:17.795] iteration 27847: loss: 0.057987, loss_s1: 0.057320, loss_fp: 0.001888, loss_freq: 0.010141
[16:58:18.415] iteration 27848: loss: 0.043512, loss_s1: 0.016885, loss_fp: 0.005229, loss_freq: 0.027750
[16:58:19.029] iteration 27849: loss: 0.066159, loss_s1: 0.035576, loss_fp: 0.002586, loss_freq: 0.047272
[16:58:19.660] iteration 27850: loss: 0.048220, loss_s1: 0.025904, loss_fp: 0.007261, loss_freq: 0.030887
[16:58:20.281] iteration 27851: loss: 0.061816, loss_s1: 0.036431, loss_fp: 0.005247, loss_freq: 0.040148
[16:58:20.922] iteration 27852: loss: 0.065135, loss_s1: 0.072996, loss_fp: 0.002367, loss_freq: 0.024282
[16:58:21.564] iteration 27853: loss: 0.048032, loss_s1: 0.026210, loss_fp: 0.003309, loss_freq: 0.019716
[16:58:22.206] iteration 27854: loss: 0.040779, loss_s1: 0.025913, loss_fp: 0.001499, loss_freq: 0.028135
[16:58:22.826] iteration 27855: loss: 0.044831, loss_s1: 0.028254, loss_fp: 0.003320, loss_freq: 0.006098
[16:58:23.444] iteration 27856: loss: 0.080613, loss_s1: 0.087269, loss_fp: 0.006464, loss_freq: 0.026394
[16:58:24.071] iteration 27857: loss: 0.044345, loss_s1: 0.022585, loss_fp: 0.001934, loss_freq: 0.006407
[16:58:24.696] iteration 27858: loss: 0.032978, loss_s1: 0.017045, loss_fp: 0.002923, loss_freq: 0.008869
[16:58:25.316] iteration 27859: loss: 0.053357, loss_s1: 0.039316, loss_fp: 0.001859, loss_freq: 0.032877
[16:58:25.935] iteration 27860: loss: 0.065146, loss_s1: 0.050005, loss_fp: 0.001872, loss_freq: 0.036380
[16:58:26.593] iteration 27861: loss: 0.045266, loss_s1: 0.048311, loss_fp: 0.001506, loss_freq: 0.011111
[16:58:27.221] iteration 27862: loss: 0.054589, loss_s1: 0.055350, loss_fp: 0.002744, loss_freq: 0.015198
[16:58:27.865] iteration 27863: loss: 0.045957, loss_s1: 0.027181, loss_fp: 0.002146, loss_freq: 0.025100
[16:58:28.486] iteration 27864: loss: 0.045280, loss_s1: 0.023953, loss_fp: 0.003447, loss_freq: 0.026146
[16:58:29.102] iteration 27865: loss: 0.030103, loss_s1: 0.017127, loss_fp: 0.001545, loss_freq: 0.010326
[16:58:29.725] iteration 27866: loss: 0.056615, loss_s1: 0.069434, loss_fp: 0.008819, loss_freq: 0.009948
[16:58:30.353] iteration 27867: loss: 0.080795, loss_s1: 0.077612, loss_fp: 0.011323, loss_freq: 0.045417
[16:58:30.973] iteration 27868: loss: 0.050308, loss_s1: 0.030003, loss_fp: 0.004330, loss_freq: 0.018807
[16:58:31.603] iteration 27869: loss: 0.048766, loss_s1: 0.021350, loss_fp: 0.003942, loss_freq: 0.038935
[16:58:32.224] iteration 27870: loss: 0.053902, loss_s1: 0.051197, loss_fp: 0.002213, loss_freq: 0.019992
[16:58:32.844] iteration 27871: loss: 0.047962, loss_s1: 0.035098, loss_fp: 0.006770, loss_freq: 0.009768
[16:58:33.463] iteration 27872: loss: 0.041157, loss_s1: 0.036423, loss_fp: 0.004300, loss_freq: 0.006072
[16:58:34.078] iteration 27873: loss: 0.067190, loss_s1: 0.035346, loss_fp: 0.005686, loss_freq: 0.034904
[16:58:34.695] iteration 27874: loss: 0.071979, loss_s1: 0.036564, loss_fp: 0.004052, loss_freq: 0.054445
[16:58:35.312] iteration 27875: loss: 0.049137, loss_s1: 0.040478, loss_fp: 0.003287, loss_freq: 0.022160
[16:58:35.937] iteration 27876: loss: 0.058632, loss_s1: 0.015857, loss_fp: 0.003513, loss_freq: 0.051534
[16:58:36.578] iteration 27877: loss: 0.043264, loss_s1: 0.030592, loss_fp: 0.002673, loss_freq: 0.007629
[16:58:37.193] iteration 27878: loss: 0.080875, loss_s1: 0.094018, loss_fp: 0.003654, loss_freq: 0.030710
[16:58:37.816] iteration 27879: loss: 0.056753, loss_s1: 0.039929, loss_fp: 0.004927, loss_freq: 0.025162
[16:58:38.434] iteration 27880: loss: 0.028948, loss_s1: 0.013803, loss_fp: 0.000370, loss_freq: 0.011274
[16:58:39.059] iteration 27881: loss: 0.042306, loss_s1: 0.034909, loss_fp: 0.002480, loss_freq: 0.014579
[16:58:39.678] iteration 27882: loss: 0.057454, loss_s1: 0.037580, loss_fp: 0.004721, loss_freq: 0.014824
[16:58:40.319] iteration 27883: loss: 0.067158, loss_s1: 0.043374, loss_fp: 0.002120, loss_freq: 0.049192
[16:58:40.994] iteration 27884: loss: 0.073339, loss_s1: 0.074252, loss_fp: 0.009502, loss_freq: 0.024839
[16:58:41.623] iteration 27885: loss: 0.053530, loss_s1: 0.057567, loss_fp: 0.000949, loss_freq: 0.018097
[16:58:42.587] iteration 27886: loss: 0.076380, loss_s1: 0.091385, loss_fp: 0.003154, loss_freq: 0.018251
[16:58:43.234] iteration 27887: loss: 0.062765, loss_s1: 0.049158, loss_fp: 0.019546, loss_freq: 0.019768
[16:58:43.908] iteration 27888: loss: 0.033223, loss_s1: 0.013949, loss_fp: 0.002143, loss_freq: 0.017337
[16:58:44.555] iteration 27889: loss: 0.055714, loss_s1: 0.032961, loss_fp: 0.002395, loss_freq: 0.033723
[16:58:45.193] iteration 27890: loss: 0.069338, loss_s1: 0.057900, loss_fp: 0.015953, loss_freq: 0.038665
[16:58:45.830] iteration 27891: loss: 0.044536, loss_s1: 0.035155, loss_fp: 0.005822, loss_freq: 0.004459
[16:58:46.471] iteration 27892: loss: 0.026794, loss_s1: 0.016419, loss_fp: 0.001814, loss_freq: 0.011722
[16:58:47.100] iteration 27893: loss: 0.040641, loss_s1: 0.014979, loss_fp: 0.005830, loss_freq: 0.013882
[16:58:47.729] iteration 27894: loss: 0.046171, loss_s1: 0.024333, loss_fp: 0.014494, loss_freq: 0.015817
[16:58:48.361] iteration 27895: loss: 0.039495, loss_s1: 0.019267, loss_fp: 0.001669, loss_freq: 0.002615
[16:58:48.993] iteration 27896: loss: 0.069265, loss_s1: 0.041621, loss_fp: 0.001880, loss_freq: 0.047030
[16:58:49.616] iteration 27897: loss: 0.057885, loss_s1: 0.046860, loss_fp: 0.004041, loss_freq: 0.022163
[16:58:50.246] iteration 27898: loss: 0.045233, loss_s1: 0.034644, loss_fp: 0.002499, loss_freq: 0.022422
[16:58:50.878] iteration 27899: loss: 0.035523, loss_s1: 0.015106, loss_fp: 0.002623, loss_freq: 0.023181
[16:58:51.511] iteration 27900: loss: 0.055826, loss_s1: 0.044121, loss_fp: 0.002905, loss_freq: 0.024543
[16:58:52.134] iteration 27901: loss: 0.034501, loss_s1: 0.014313, loss_fp: 0.002350, loss_freq: 0.011622
[16:58:52.758] iteration 27902: loss: 0.057758, loss_s1: 0.036741, loss_fp: 0.004987, loss_freq: 0.025057
[16:58:53.375] iteration 27903: loss: 0.052748, loss_s1: 0.040123, loss_fp: 0.001564, loss_freq: 0.030707
[16:58:53.991] iteration 27904: loss: 0.031960, loss_s1: 0.013995, loss_fp: 0.001599, loss_freq: 0.018378
[16:58:54.612] iteration 27905: loss: 0.029041, loss_s1: 0.014196, loss_fp: 0.004977, loss_freq: 0.009541
[16:58:55.228] iteration 27906: loss: 0.058396, loss_s1: 0.018657, loss_fp: 0.002288, loss_freq: 0.033464
[16:58:55.851] iteration 27907: loss: 0.030924, loss_s1: 0.018763, loss_fp: 0.001225, loss_freq: 0.011043
[16:58:56.482] iteration 27908: loss: 0.046124, loss_s1: 0.022651, loss_fp: 0.001381, loss_freq: 0.034582
[16:58:57.125] iteration 27909: loss: 0.039035, loss_s1: 0.024466, loss_fp: 0.004566, loss_freq: 0.018775
[16:58:57.742] iteration 27910: loss: 0.048338, loss_s1: 0.047505, loss_fp: 0.002165, loss_freq: 0.009452
[16:58:58.360] iteration 27911: loss: 0.061265, loss_s1: 0.068288, loss_fp: 0.002675, loss_freq: 0.013347
[16:58:58.987] iteration 27912: loss: 0.071618, loss_s1: 0.050236, loss_fp: 0.006250, loss_freq: 0.054337
[16:58:59.601] iteration 27913: loss: 0.030242, loss_s1: 0.015971, loss_fp: 0.007930, loss_freq: 0.006098
[16:59:00.221] iteration 27914: loss: 0.070922, loss_s1: 0.075396, loss_fp: 0.002468, loss_freq: 0.024867
[16:59:00.846] iteration 27915: loss: 0.051889, loss_s1: 0.034717, loss_fp: 0.004355, loss_freq: 0.015702
[16:59:01.464] iteration 27916: loss: 0.048594, loss_s1: 0.036941, loss_fp: 0.001361, loss_freq: 0.018633
[16:59:02.076] iteration 27917: loss: 0.036079, loss_s1: 0.012984, loss_fp: 0.002740, loss_freq: 0.016674
[16:59:02.697] iteration 27918: loss: 0.091854, loss_s1: 0.106674, loss_fp: 0.009418, loss_freq: 0.038089
[16:59:03.321] iteration 27919: loss: 0.099066, loss_s1: 0.109831, loss_fp: 0.004899, loss_freq: 0.053503
[16:59:03.941] iteration 27920: loss: 0.058670, loss_s1: 0.041126, loss_fp: 0.007523, loss_freq: 0.025727
[16:59:04.588] iteration 27921: loss: 0.059738, loss_s1: 0.040376, loss_fp: 0.001788, loss_freq: 0.041536
[16:59:05.264] iteration 27922: loss: 0.048148, loss_s1: 0.031256, loss_fp: 0.002623, loss_freq: 0.028515
[16:59:05.880] iteration 27923: loss: 0.060714, loss_s1: 0.050557, loss_fp: 0.005661, loss_freq: 0.033832
[16:59:06.502] iteration 27924: loss: 0.123703, loss_s1: 0.129828, loss_fp: 0.006038, loss_freq: 0.050399
[16:59:07.136] iteration 27925: loss: 0.041636, loss_s1: 0.041787, loss_fp: 0.003064, loss_freq: 0.011573
[16:59:07.758] iteration 27926: loss: 0.048505, loss_s1: 0.047889, loss_fp: 0.001167, loss_freq: 0.017450
[16:59:08.387] iteration 27927: loss: 0.051482, loss_s1: 0.044538, loss_fp: 0.003984, loss_freq: 0.031104
[16:59:09.008] iteration 27928: loss: 0.034884, loss_s1: 0.015872, loss_fp: 0.001573, loss_freq: 0.004130
[16:59:09.628] iteration 27929: loss: 0.066345, loss_s1: 0.042541, loss_fp: 0.006608, loss_freq: 0.041951
[16:59:10.253] iteration 27930: loss: 0.047718, loss_s1: 0.040734, loss_fp: 0.003343, loss_freq: 0.006155
[16:59:10.883] iteration 27931: loss: 0.056847, loss_s1: 0.050946, loss_fp: 0.007054, loss_freq: 0.021926
[16:59:11.511] iteration 27932: loss: 0.055147, loss_s1: 0.030192, loss_fp: 0.004354, loss_freq: 0.044333
[16:59:12.135] iteration 27933: loss: 0.045360, loss_s1: 0.027074, loss_fp: 0.004116, loss_freq: 0.020105
[16:59:12.744] iteration 27934: loss: 0.050118, loss_s1: 0.033627, loss_fp: 0.005244, loss_freq: 0.035315
[16:59:13.368] iteration 27935: loss: 0.044063, loss_s1: 0.026503, loss_fp: 0.006298, loss_freq: 0.017908
[16:59:13.991] iteration 27936: loss: 0.040804, loss_s1: 0.025281, loss_fp: 0.001200, loss_freq: 0.014319
[16:59:14.605] iteration 27937: loss: 0.068762, loss_s1: 0.046742, loss_fp: 0.002800, loss_freq: 0.035285
[16:59:15.228] iteration 27938: loss: 0.049607, loss_s1: 0.043477, loss_fp: 0.003885, loss_freq: 0.016970
[16:59:15.845] iteration 27939: loss: 0.047927, loss_s1: 0.037216, loss_fp: 0.009076, loss_freq: 0.025244
[16:59:16.469] iteration 27940: loss: 0.034681, loss_s1: 0.014761, loss_fp: 0.001604, loss_freq: 0.007759
[16:59:17.089] iteration 27941: loss: 0.035231, loss_s1: 0.020016, loss_fp: 0.000660, loss_freq: 0.012850
[16:59:17.709] iteration 27942: loss: 0.056577, loss_s1: 0.064989, loss_fp: 0.004492, loss_freq: 0.013894
[16:59:18.331] iteration 27943: loss: 0.075451, loss_s1: 0.067159, loss_fp: 0.007401, loss_freq: 0.047102
[16:59:18.951] iteration 27944: loss: 0.047158, loss_s1: 0.031183, loss_fp: 0.001206, loss_freq: 0.031934
[16:59:19.573] iteration 27945: loss: 0.048306, loss_s1: 0.042007, loss_fp: 0.001679, loss_freq: 0.019498
[16:59:20.199] iteration 27946: loss: 0.036342, loss_s1: 0.022168, loss_fp: 0.003953, loss_freq: 0.011269
[16:59:20.816] iteration 27947: loss: 0.046328, loss_s1: 0.025638, loss_fp: 0.003317, loss_freq: 0.011412
[16:59:21.439] iteration 27948: loss: 0.070040, loss_s1: 0.053162, loss_fp: 0.003664, loss_freq: 0.050581
[16:59:22.060] iteration 27949: loss: 0.053446, loss_s1: 0.025665, loss_fp: 0.002060, loss_freq: 0.028844
[16:59:22.705] iteration 27950: loss: 0.032126, loss_s1: 0.005358, loss_fp: 0.009954, loss_freq: 0.007245
[16:59:23.344] iteration 27951: loss: 0.028474, loss_s1: 0.009429, loss_fp: 0.005978, loss_freq: 0.009920
[16:59:23.971] iteration 27952: loss: 0.097288, loss_s1: 0.049891, loss_fp: 0.002471, loss_freq: 0.101505
[16:59:24.594] iteration 27953: loss: 0.051413, loss_s1: 0.039032, loss_fp: 0.006483, loss_freq: 0.024492
[16:59:25.234] iteration 27954: loss: 0.046097, loss_s1: 0.038795, loss_fp: 0.007496, loss_freq: 0.011245
[16:59:25.857] iteration 27955: loss: 0.050064, loss_s1: 0.040212, loss_fp: 0.001336, loss_freq: 0.017584
[16:59:26.471] iteration 27956: loss: 0.048353, loss_s1: 0.034720, loss_fp: 0.000859, loss_freq: 0.027177
[16:59:27.090] iteration 27957: loss: 0.057783, loss_s1: 0.022139, loss_fp: 0.009465, loss_freq: 0.029151
[16:59:27.699] iteration 27958: loss: 0.041902, loss_s1: 0.037021, loss_fp: 0.002026, loss_freq: 0.011937
[16:59:28.317] iteration 27959: loss: 0.067212, loss_s1: 0.078618, loss_fp: 0.002724, loss_freq: 0.015466
[16:59:28.943] iteration 27960: loss: 0.037088, loss_s1: 0.023327, loss_fp: 0.006709, loss_freq: 0.020203
[16:59:29.570] iteration 27961: loss: 0.087870, loss_s1: 0.066093, loss_fp: 0.003283, loss_freq: 0.016067
[16:59:30.199] iteration 27962: loss: 0.053836, loss_s1: 0.054562, loss_fp: 0.007414, loss_freq: 0.020470
[16:59:30.815] iteration 27963: loss: 0.056436, loss_s1: 0.045965, loss_fp: 0.000558, loss_freq: 0.012820
[16:59:31.435] iteration 27964: loss: 0.069379, loss_s1: 0.055619, loss_fp: 0.002751, loss_freq: 0.049867
[16:59:32.082] iteration 27965: loss: 0.110574, loss_s1: 0.066252, loss_fp: 0.005636, loss_freq: 0.027913
[16:59:32.729] iteration 27966: loss: 0.059744, loss_s1: 0.036459, loss_fp: 0.000776, loss_freq: 0.009169
[16:59:33.357] iteration 27967: loss: 0.050034, loss_s1: 0.042733, loss_fp: 0.003112, loss_freq: 0.026021
[16:59:33.970] iteration 27968: loss: 0.042016, loss_s1: 0.017166, loss_fp: 0.001429, loss_freq: 0.024956
[16:59:34.590] iteration 27969: loss: 0.045624, loss_s1: 0.045838, loss_fp: 0.001331, loss_freq: 0.016080
[16:59:35.211] iteration 27970: loss: 0.068317, loss_s1: 0.059138, loss_fp: 0.007048, loss_freq: 0.024008
[16:59:35.877] iteration 27971: loss: 0.057774, loss_s1: 0.030318, loss_fp: 0.011037, loss_freq: 0.032597
[16:59:36.497] iteration 27972: loss: 0.060525, loss_s1: 0.027927, loss_fp: 0.012189, loss_freq: 0.039732
[16:59:37.122] iteration 27973: loss: 0.041010, loss_s1: 0.015056, loss_fp: 0.003101, loss_freq: 0.017826
[16:59:37.735] iteration 27974: loss: 0.041009, loss_s1: 0.040976, loss_fp: 0.002304, loss_freq: 0.006927
[16:59:38.366] iteration 27975: loss: 0.045669, loss_s1: 0.032080, loss_fp: 0.005745, loss_freq: 0.012574
[16:59:38.984] iteration 27976: loss: 0.049212, loss_s1: 0.028048, loss_fp: 0.001081, loss_freq: 0.010077
[16:59:39.603] iteration 27977: loss: 0.068279, loss_s1: 0.060361, loss_fp: 0.000706, loss_freq: 0.046437
[16:59:40.231] iteration 27978: loss: 0.056156, loss_s1: 0.056430, loss_fp: 0.004065, loss_freq: 0.017616
[16:59:40.856] iteration 27979: loss: 0.052453, loss_s1: 0.040845, loss_fp: 0.002366, loss_freq: 0.006923
[16:59:41.475] iteration 27980: loss: 0.040565, loss_s1: 0.020012, loss_fp: 0.002392, loss_freq: 0.019494
[16:59:42.092] iteration 27981: loss: 0.045465, loss_s1: 0.040413, loss_fp: 0.003509, loss_freq: 0.003454
[16:59:42.714] iteration 27982: loss: 0.075680, loss_s1: 0.025992, loss_fp: 0.012157, loss_freq: 0.079048
[16:59:43.412] iteration 27983: loss: 0.030051, loss_s1: 0.010377, loss_fp: 0.002200, loss_freq: 0.014777
[16:59:44.060] iteration 27984: loss: 0.039680, loss_s1: 0.025604, loss_fp: 0.003816, loss_freq: 0.008144
[16:59:44.700] iteration 27985: loss: 0.049164, loss_s1: 0.031855, loss_fp: 0.002108, loss_freq: 0.017225
[16:59:45.328] iteration 27986: loss: 0.055277, loss_s1: 0.035035, loss_fp: 0.005989, loss_freq: 0.026777
[16:59:45.955] iteration 27987: loss: 0.056423, loss_s1: 0.031864, loss_fp: 0.005761, loss_freq: 0.033312
[16:59:46.575] iteration 27988: loss: 0.091433, loss_s1: 0.073161, loss_fp: 0.003217, loss_freq: 0.067946
[16:59:47.197] iteration 27989: loss: 0.029300, loss_s1: 0.020379, loss_fp: 0.000349, loss_freq: 0.005466
[16:59:47.810] iteration 27990: loss: 0.047151, loss_s1: 0.028204, loss_fp: 0.005787, loss_freq: 0.016959
[16:59:48.421] iteration 27991: loss: 0.041118, loss_s1: 0.016385, loss_fp: 0.002234, loss_freq: 0.028815
[16:59:49.043] iteration 27992: loss: 0.060321, loss_s1: 0.043464, loss_fp: 0.003175, loss_freq: 0.030632
[16:59:49.673] iteration 27993: loss: 0.063577, loss_s1: 0.060998, loss_fp: 0.005746, loss_freq: 0.026716
[16:59:50.294] iteration 27994: loss: 0.075469, loss_s1: 0.051924, loss_fp: 0.008026, loss_freq: 0.048850
[16:59:50.911] iteration 27995: loss: 0.057781, loss_s1: 0.039949, loss_fp: 0.020056, loss_freq: 0.033239
[16:59:51.531] iteration 27996: loss: 0.044225, loss_s1: 0.028817, loss_fp: 0.003238, loss_freq: 0.022488
[16:59:52.151] iteration 27997: loss: 0.043547, loss_s1: 0.034622, loss_fp: 0.003711, loss_freq: 0.019160
[16:59:52.773] iteration 27998: loss: 0.037535, loss_s1: 0.025195, loss_fp: 0.000450, loss_freq: 0.007823
[16:59:53.392] iteration 27999: loss: 0.103827, loss_s1: 0.080128, loss_fp: 0.031193, loss_freq: 0.056044
[16:59:54.019] iteration 28000: loss: 0.066370, loss_s1: 0.031164, loss_fp: 0.003981, loss_freq: 0.042385
[16:59:57.256] iteration 28000 : mean_dice : 0.804204
[16:59:57.896] iteration 28001: loss: 0.040994, loss_s1: 0.019838, loss_fp: 0.004178, loss_freq: 0.028904
[16:59:58.516] iteration 28002: loss: 0.041146, loss_s1: 0.024238, loss_fp: 0.008285, loss_freq: 0.009438
[16:59:59.134] iteration 28003: loss: 0.056602, loss_s1: 0.062243, loss_fp: 0.005443, loss_freq: 0.015451
[16:59:59.760] iteration 28004: loss: 0.032937, loss_s1: 0.022163, loss_fp: 0.002295, loss_freq: 0.012871
[17:00:00.381] iteration 28005: loss: 0.045303, loss_s1: 0.027966, loss_fp: 0.002533, loss_freq: 0.029963
[17:00:00.998] iteration 28006: loss: 0.057082, loss_s1: 0.040992, loss_fp: 0.000952, loss_freq: 0.037106
[17:00:01.626] iteration 28007: loss: 0.052348, loss_s1: 0.022188, loss_fp: 0.013072, loss_freq: 0.029670
[17:00:02.261] iteration 28008: loss: 0.039019, loss_s1: 0.023623, loss_fp: 0.007106, loss_freq: 0.017190
[17:00:02.884] iteration 28009: loss: 0.067831, loss_s1: 0.048851, loss_fp: 0.008950, loss_freq: 0.053449
[17:00:03.525] iteration 28010: loss: 0.042441, loss_s1: 0.040342, loss_fp: 0.000721, loss_freq: 0.015560
[17:00:04.164] iteration 28011: loss: 0.057255, loss_s1: 0.055705, loss_fp: 0.002003, loss_freq: 0.014733
[17:00:04.807] iteration 28012: loss: 0.049744, loss_s1: 0.037196, loss_fp: 0.001844, loss_freq: 0.030052
[17:00:05.479] iteration 28013: loss: 0.044341, loss_s1: 0.019981, loss_fp: 0.002177, loss_freq: 0.037754
[17:00:06.152] iteration 28014: loss: 0.044611, loss_s1: 0.041232, loss_fp: 0.002651, loss_freq: 0.010451
[17:00:06.795] iteration 28015: loss: 0.051057, loss_s1: 0.035555, loss_fp: 0.007705, loss_freq: 0.022087
[17:00:07.447] iteration 28016: loss: 0.072565, loss_s1: 0.061018, loss_fp: 0.020121, loss_freq: 0.018849
[17:00:08.086] iteration 28017: loss: 0.069745, loss_s1: 0.050897, loss_fp: 0.008056, loss_freq: 0.045969
[17:00:08.698] iteration 28018: loss: 0.053764, loss_s1: 0.041743, loss_fp: 0.004446, loss_freq: 0.017762
[17:00:09.321] iteration 28019: loss: 0.094898, loss_s1: 0.101851, loss_fp: 0.007553, loss_freq: 0.033712
[17:00:09.948] iteration 28020: loss: 0.088540, loss_s1: 0.037426, loss_fp: 0.002367, loss_freq: 0.015765
[17:00:10.561] iteration 28021: loss: 0.081510, loss_s1: 0.098991, loss_fp: 0.005208, loss_freq: 0.020655
[17:00:11.182] iteration 28022: loss: 0.054540, loss_s1: 0.038841, loss_fp: 0.005041, loss_freq: 0.013995
[17:00:11.805] iteration 28023: loss: 0.050478, loss_s1: 0.059999, loss_fp: 0.002040, loss_freq: 0.011569
[17:00:12.455] iteration 28024: loss: 0.058103, loss_s1: 0.044560, loss_fp: 0.002493, loss_freq: 0.014328
[17:00:13.102] iteration 28025: loss: 0.070094, loss_s1: 0.046188, loss_fp: 0.009346, loss_freq: 0.017089
[17:00:13.736] iteration 28026: loss: 0.042814, loss_s1: 0.030235, loss_fp: 0.003702, loss_freq: 0.014020
[17:00:14.355] iteration 28027: loss: 0.119247, loss_s1: 0.168356, loss_fp: 0.004299, loss_freq: 0.029410
[17:00:14.976] iteration 28028: loss: 0.033298, loss_s1: 0.021492, loss_fp: 0.001872, loss_freq: 0.010768
[17:00:15.982] iteration 28029: loss: 0.031862, loss_s1: 0.015235, loss_fp: 0.001844, loss_freq: 0.006909
[17:00:16.639] iteration 28030: loss: 0.073085, loss_s1: 0.075119, loss_fp: 0.007810, loss_freq: 0.016131
[17:00:17.255] iteration 28031: loss: 0.041001, loss_s1: 0.022817, loss_fp: 0.001484, loss_freq: 0.016727
[17:00:17.878] iteration 28032: loss: 0.051181, loss_s1: 0.033884, loss_fp: 0.003170, loss_freq: 0.029970
[17:00:18.557] iteration 28033: loss: 0.045491, loss_s1: 0.032805, loss_fp: 0.015370, loss_freq: 0.017581
[17:00:19.176] iteration 28034: loss: 0.027487, loss_s1: 0.014482, loss_fp: 0.001055, loss_freq: 0.004313
[17:00:19.803] iteration 28035: loss: 0.031717, loss_s1: 0.010053, loss_fp: 0.003122, loss_freq: 0.024689
[17:00:20.462] iteration 28036: loss: 0.041270, loss_s1: 0.018595, loss_fp: 0.002890, loss_freq: 0.015793
[17:00:21.111] iteration 28037: loss: 0.033583, loss_s1: 0.020354, loss_fp: 0.004652, loss_freq: 0.010203
[17:00:21.746] iteration 28038: loss: 0.035284, loss_s1: 0.006386, loss_fp: 0.000441, loss_freq: 0.011842
[17:00:22.376] iteration 28039: loss: 0.052364, loss_s1: 0.024143, loss_fp: 0.004087, loss_freq: 0.028530
[17:00:23.000] iteration 28040: loss: 0.036690, loss_s1: 0.017016, loss_fp: 0.001549, loss_freq: 0.015738
[17:00:23.627] iteration 28041: loss: 0.039224, loss_s1: 0.027868, loss_fp: 0.001749, loss_freq: 0.014659
[17:00:24.244] iteration 28042: loss: 0.041287, loss_s1: 0.019804, loss_fp: 0.001372, loss_freq: 0.031799
[17:00:24.869] iteration 28043: loss: 0.049807, loss_s1: 0.023768, loss_fp: 0.006445, loss_freq: 0.031790
[17:00:25.493] iteration 28044: loss: 0.051974, loss_s1: 0.039111, loss_fp: 0.010686, loss_freq: 0.018018
[17:00:26.116] iteration 28045: loss: 0.054254, loss_s1: 0.028850, loss_fp: 0.006567, loss_freq: 0.032347
[17:00:26.736] iteration 28046: loss: 0.052089, loss_s1: 0.055967, loss_fp: 0.005199, loss_freq: 0.013530
[17:00:27.359] iteration 28047: loss: 0.040764, loss_s1: 0.027914, loss_fp: 0.001104, loss_freq: 0.026710
[17:00:27.981] iteration 28048: loss: 0.034578, loss_s1: 0.026981, loss_fp: 0.001215, loss_freq: 0.012410
[17:00:28.623] iteration 28049: loss: 0.072356, loss_s1: 0.028298, loss_fp: 0.003353, loss_freq: 0.073222
[17:00:29.293] iteration 28050: loss: 0.039448, loss_s1: 0.024415, loss_fp: 0.006165, loss_freq: 0.020182
[17:00:29.945] iteration 28051: loss: 0.056640, loss_s1: 0.027510, loss_fp: 0.002112, loss_freq: 0.035804
[17:00:30.577] iteration 28052: loss: 0.036063, loss_s1: 0.027516, loss_fp: 0.000724, loss_freq: 0.004805
[17:00:31.212] iteration 28053: loss: 0.045061, loss_s1: 0.031544, loss_fp: 0.001607, loss_freq: 0.012777
[17:00:31.839] iteration 28054: loss: 0.112097, loss_s1: 0.134953, loss_fp: 0.003245, loss_freq: 0.045995
[17:00:32.468] iteration 28055: loss: 0.076344, loss_s1: 0.031504, loss_fp: 0.013806, loss_freq: 0.062215
[17:00:33.094] iteration 28056: loss: 0.034217, loss_s1: 0.018571, loss_fp: 0.001690, loss_freq: 0.010223
[17:00:33.731] iteration 28057: loss: 0.055850, loss_s1: 0.048668, loss_fp: 0.000879, loss_freq: 0.015286
[17:00:34.344] iteration 28058: loss: 0.050274, loss_s1: 0.027347, loss_fp: 0.001118, loss_freq: 0.020282
[17:00:34.959] iteration 28059: loss: 0.030422, loss_s1: 0.012430, loss_fp: 0.000567, loss_freq: 0.008188
[17:00:35.572] iteration 28060: loss: 0.054133, loss_s1: 0.037030, loss_fp: 0.005051, loss_freq: 0.022570
[17:00:36.190] iteration 28061: loss: 0.083850, loss_s1: 0.076150, loss_fp: 0.005444, loss_freq: 0.050517
[17:00:36.803] iteration 28062: loss: 0.050976, loss_s1: 0.040899, loss_fp: 0.005955, loss_freq: 0.024093
[17:00:37.420] iteration 28063: loss: 0.062955, loss_s1: 0.053878, loss_fp: 0.003996, loss_freq: 0.028991
[17:00:38.036] iteration 28064: loss: 0.044157, loss_s1: 0.030626, loss_fp: 0.000682, loss_freq: 0.017884
[17:00:38.650] iteration 28065: loss: 0.049472, loss_s1: 0.025784, loss_fp: 0.001565, loss_freq: 0.016510
[17:00:39.279] iteration 28066: loss: 0.046046, loss_s1: 0.044184, loss_fp: 0.003010, loss_freq: 0.012402
[17:00:39.894] iteration 28067: loss: 0.056439, loss_s1: 0.045790, loss_fp: 0.001961, loss_freq: 0.021308
[17:00:40.515] iteration 28068: loss: 0.051908, loss_s1: 0.062133, loss_fp: 0.006365, loss_freq: 0.007339
[17:00:41.129] iteration 28069: loss: 0.048868, loss_s1: 0.032000, loss_fp: 0.007582, loss_freq: 0.011384
[17:00:41.748] iteration 28070: loss: 0.041977, loss_s1: 0.037290, loss_fp: 0.000566, loss_freq: 0.019863
[17:00:42.368] iteration 28071: loss: 0.033968, loss_s1: 0.024188, loss_fp: 0.000973, loss_freq: 0.005648
[17:00:42.987] iteration 28072: loss: 0.075293, loss_s1: 0.078697, loss_fp: 0.007421, loss_freq: 0.028855
[17:00:43.665] iteration 28073: loss: 0.051446, loss_s1: 0.036721, loss_fp: 0.001048, loss_freq: 0.008944
[17:00:44.289] iteration 28074: loss: 0.041990, loss_s1: 0.036161, loss_fp: 0.001518, loss_freq: 0.016157
[17:00:44.906] iteration 28075: loss: 0.046797, loss_s1: 0.011258, loss_fp: 0.002369, loss_freq: 0.043682
[17:00:45.533] iteration 28076: loss: 0.048747, loss_s1: 0.030361, loss_fp: 0.002243, loss_freq: 0.022096
[17:00:46.154] iteration 28077: loss: 0.066420, loss_s1: 0.060076, loss_fp: 0.002808, loss_freq: 0.043368
[17:00:46.774] iteration 28078: loss: 0.032559, loss_s1: 0.016859, loss_fp: 0.004162, loss_freq: 0.009483
[17:00:47.399] iteration 28079: loss: 0.040793, loss_s1: 0.027778, loss_fp: 0.002631, loss_freq: 0.018483
[17:00:48.010] iteration 28080: loss: 0.049610, loss_s1: 0.024754, loss_fp: 0.001283, loss_freq: 0.033171
[17:00:48.621] iteration 28081: loss: 0.031692, loss_s1: 0.013226, loss_fp: 0.005071, loss_freq: 0.009755
[17:00:49.236] iteration 28082: loss: 0.078277, loss_s1: 0.066580, loss_fp: 0.006475, loss_freq: 0.058817
[17:00:49.854] iteration 28083: loss: 0.028557, loss_s1: 0.015594, loss_fp: 0.003113, loss_freq: 0.010483
[17:00:50.478] iteration 28084: loss: 0.069407, loss_s1: 0.040550, loss_fp: 0.001438, loss_freq: 0.035387
[17:00:51.103] iteration 28085: loss: 0.055099, loss_s1: 0.064809, loss_fp: 0.002451, loss_freq: 0.009837
[17:00:51.712] iteration 28086: loss: 0.040520, loss_s1: 0.020344, loss_fp: 0.002968, loss_freq: 0.017186
[17:00:52.335] iteration 28087: loss: 0.042970, loss_s1: 0.009857, loss_fp: 0.004051, loss_freq: 0.035893
[17:00:52.960] iteration 28088: loss: 0.048268, loss_s1: 0.038605, loss_fp: 0.001202, loss_freq: 0.023007
[17:00:53.600] iteration 28089: loss: 0.042507, loss_s1: 0.016006, loss_fp: 0.005323, loss_freq: 0.018631
[17:00:54.242] iteration 28090: loss: 0.058909, loss_s1: 0.053406, loss_fp: 0.001320, loss_freq: 0.029912
[17:00:54.882] iteration 28091: loss: 0.083439, loss_s1: 0.051936, loss_fp: 0.006991, loss_freq: 0.076024
[17:00:55.513] iteration 28092: loss: 0.057769, loss_s1: 0.043456, loss_fp: 0.004328, loss_freq: 0.023950
[17:00:56.129] iteration 28093: loss: 0.052933, loss_s1: 0.018974, loss_fp: 0.001212, loss_freq: 0.033781
[17:00:56.753] iteration 28094: loss: 0.049668, loss_s1: 0.028995, loss_fp: 0.005112, loss_freq: 0.020276
[17:00:57.377] iteration 28095: loss: 0.095336, loss_s1: 0.048311, loss_fp: 0.003772, loss_freq: 0.095220
[17:00:57.996] iteration 28096: loss: 0.039413, loss_s1: 0.028573, loss_fp: 0.002575, loss_freq: 0.019960
[17:00:58.613] iteration 28097: loss: 0.044126, loss_s1: 0.046510, loss_fp: 0.001828, loss_freq: 0.008050
[17:00:59.236] iteration 28098: loss: 0.040418, loss_s1: 0.025787, loss_fp: 0.000301, loss_freq: 0.005351
[17:00:59.853] iteration 28099: loss: 0.042840, loss_s1: 0.038582, loss_fp: 0.003104, loss_freq: 0.007560
[17:01:00.477] iteration 28100: loss: 0.065588, loss_s1: 0.060302, loss_fp: 0.006196, loss_freq: 0.021881
[17:01:01.103] iteration 28101: loss: 0.055615, loss_s1: 0.060280, loss_fp: 0.005163, loss_freq: 0.014463
[17:01:01.722] iteration 28102: loss: 0.094279, loss_s1: 0.054482, loss_fp: 0.043980, loss_freq: 0.042515
[17:01:02.345] iteration 28103: loss: 0.063212, loss_s1: 0.055982, loss_fp: 0.003768, loss_freq: 0.036831
[17:01:02.988] iteration 28104: loss: 0.033208, loss_s1: 0.019230, loss_fp: 0.001909, loss_freq: 0.010076
[17:01:03.608] iteration 28105: loss: 0.034635, loss_s1: 0.015024, loss_fp: 0.002940, loss_freq: 0.026383
[17:01:04.224] iteration 28106: loss: 0.051773, loss_s1: 0.027618, loss_fp: 0.004962, loss_freq: 0.019830
[17:01:04.844] iteration 28107: loss: 0.080411, loss_s1: 0.071755, loss_fp: 0.005921, loss_freq: 0.040849
[17:01:05.487] iteration 28108: loss: 0.077249, loss_s1: 0.037951, loss_fp: 0.012205, loss_freq: 0.030818
[17:01:06.130] iteration 28109: loss: 0.033221, loss_s1: 0.013773, loss_fp: 0.000619, loss_freq: 0.018662
[17:01:06.762] iteration 28110: loss: 0.044305, loss_s1: 0.038833, loss_fp: 0.005180, loss_freq: 0.009941
[17:01:07.379] iteration 28111: loss: 0.049572, loss_s1: 0.023295, loss_fp: 0.001118, loss_freq: 0.037762
[17:01:07.998] iteration 28112: loss: 0.046582, loss_s1: 0.046323, loss_fp: 0.002893, loss_freq: 0.015178
[17:01:08.623] iteration 28113: loss: 0.055139, loss_s1: 0.050871, loss_fp: 0.005011, loss_freq: 0.020738
[17:01:09.239] iteration 28114: loss: 0.060874, loss_s1: 0.041250, loss_fp: 0.005625, loss_freq: 0.036710
[17:01:09.852] iteration 28115: loss: 0.037075, loss_s1: 0.025833, loss_fp: 0.002874, loss_freq: 0.008679
[17:01:10.471] iteration 28116: loss: 0.035451, loss_s1: 0.025217, loss_fp: 0.000988, loss_freq: 0.009605
[17:01:11.090] iteration 28117: loss: 0.034925, loss_s1: 0.025412, loss_fp: 0.002364, loss_freq: 0.011136
[17:01:11.754] iteration 28118: loss: 0.044129, loss_s1: 0.024331, loss_fp: 0.003266, loss_freq: 0.023156
[17:01:12.375] iteration 28119: loss: 0.044079, loss_s1: 0.028162, loss_fp: 0.002057, loss_freq: 0.008812
[17:01:12.986] iteration 28120: loss: 0.043160, loss_s1: 0.027402, loss_fp: 0.014518, loss_freq: 0.016867
[17:01:13.602] iteration 28121: loss: 0.035747, loss_s1: 0.028742, loss_fp: 0.004858, loss_freq: 0.005470
[17:01:14.223] iteration 28122: loss: 0.035930, loss_s1: 0.026433, loss_fp: 0.001530, loss_freq: 0.015112
[17:01:14.840] iteration 28123: loss: 0.046413, loss_s1: 0.027435, loss_fp: 0.004572, loss_freq: 0.025609
[17:01:15.460] iteration 28124: loss: 0.040190, loss_s1: 0.030005, loss_fp: 0.001455, loss_freq: 0.003253
[17:01:16.075] iteration 28125: loss: 0.080303, loss_s1: 0.059180, loss_fp: 0.006511, loss_freq: 0.059841
[17:01:16.699] iteration 28126: loss: 0.042492, loss_s1: 0.017712, loss_fp: 0.003598, loss_freq: 0.014698
[17:01:17.323] iteration 28127: loss: 0.044944, loss_s1: 0.035642, loss_fp: 0.004007, loss_freq: 0.004752
[17:01:17.945] iteration 28128: loss: 0.072286, loss_s1: 0.050714, loss_fp: 0.004082, loss_freq: 0.037777
[17:01:18.567] iteration 28129: loss: 0.030740, loss_s1: 0.014377, loss_fp: 0.002627, loss_freq: 0.006076
[17:01:19.188] iteration 28130: loss: 0.046705, loss_s1: 0.017948, loss_fp: 0.001654, loss_freq: 0.022258
[17:01:19.811] iteration 28131: loss: 0.084257, loss_s1: 0.081576, loss_fp: 0.005435, loss_freq: 0.051292
[17:01:20.433] iteration 28132: loss: 0.038319, loss_s1: 0.017564, loss_fp: 0.003153, loss_freq: 0.007181
[17:01:21.097] iteration 28133: loss: 0.043680, loss_s1: 0.025367, loss_fp: 0.001629, loss_freq: 0.022813
[17:01:21.716] iteration 28134: loss: 0.051964, loss_s1: 0.031637, loss_fp: 0.003439, loss_freq: 0.021916
[17:01:22.327] iteration 28135: loss: 0.061244, loss_s1: 0.031451, loss_fp: 0.005398, loss_freq: 0.044086
[17:01:22.941] iteration 28136: loss: 0.095659, loss_s1: 0.093386, loss_fp: 0.005073, loss_freq: 0.065880
[17:01:23.572] iteration 28137: loss: 0.048360, loss_s1: 0.048530, loss_fp: 0.001995, loss_freq: 0.005309
[17:01:24.205] iteration 28138: loss: 0.097910, loss_s1: 0.119048, loss_fp: 0.005552, loss_freq: 0.042888
[17:01:24.818] iteration 28139: loss: 0.074056, loss_s1: 0.069520, loss_fp: 0.007027, loss_freq: 0.033332
[17:01:25.436] iteration 28140: loss: 0.060156, loss_s1: 0.056350, loss_fp: 0.002616, loss_freq: 0.035958
[17:01:26.051] iteration 28141: loss: 0.050624, loss_s1: 0.031742, loss_fp: 0.000938, loss_freq: 0.014295
[17:01:26.665] iteration 28142: loss: 0.043095, loss_s1: 0.040314, loss_fp: 0.007168, loss_freq: 0.007524
[17:01:27.289] iteration 28143: loss: 0.066951, loss_s1: 0.012983, loss_fp: 0.001622, loss_freq: 0.054657
[17:01:27.911] iteration 28144: loss: 0.030593, loss_s1: 0.010960, loss_fp: 0.003991, loss_freq: 0.014911
[17:01:28.648] iteration 28145: loss: 0.058914, loss_s1: 0.038812, loss_fp: 0.003760, loss_freq: 0.036210
[17:01:29.487] iteration 28146: loss: 0.068383, loss_s1: 0.068090, loss_fp: 0.005718, loss_freq: 0.023682
[17:01:30.192] iteration 28147: loss: 0.037513, loss_s1: 0.035685, loss_fp: 0.004117, loss_freq: 0.007622
[17:01:30.805] iteration 28148: loss: 0.061727, loss_s1: 0.052786, loss_fp: 0.001434, loss_freq: 0.029871
[17:01:31.436] iteration 28149: loss: 0.059261, loss_s1: 0.040637, loss_fp: 0.009389, loss_freq: 0.029082
[17:01:32.052] iteration 28150: loss: 0.040928, loss_s1: 0.015511, loss_fp: 0.012659, loss_freq: 0.019406
[17:01:32.674] iteration 28151: loss: 0.025015, loss_s1: 0.010368, loss_fp: 0.002239, loss_freq: 0.005303
[17:01:33.301] iteration 28152: loss: 0.031201, loss_s1: 0.018063, loss_fp: 0.000746, loss_freq: 0.017766
[17:01:33.926] iteration 28153: loss: 0.059478, loss_s1: 0.062182, loss_fp: 0.003937, loss_freq: 0.025131
[17:01:34.552] iteration 28154: loss: 0.063628, loss_s1: 0.059529, loss_fp: 0.002457, loss_freq: 0.022060
[17:01:35.164] iteration 28155: loss: 0.048467, loss_s1: 0.033445, loss_fp: 0.003535, loss_freq: 0.023324
[17:01:35.790] iteration 28156: loss: 0.041301, loss_s1: 0.020545, loss_fp: 0.001585, loss_freq: 0.028198
[17:01:36.413] iteration 28157: loss: 0.048183, loss_s1: 0.040838, loss_fp: 0.002345, loss_freq: 0.017376
[17:01:37.026] iteration 28158: loss: 0.049877, loss_s1: 0.033343, loss_fp: 0.004175, loss_freq: 0.013431
[17:01:37.644] iteration 28159: loss: 0.057541, loss_s1: 0.043051, loss_fp: 0.009842, loss_freq: 0.022689
[17:01:38.262] iteration 28160: loss: 0.057447, loss_s1: 0.032423, loss_fp: 0.004375, loss_freq: 0.022162
[17:01:38.886] iteration 28161: loss: 0.049034, loss_s1: 0.016148, loss_fp: 0.009439, loss_freq: 0.023352
[17:01:39.510] iteration 28162: loss: 0.072340, loss_s1: 0.066585, loss_fp: 0.003395, loss_freq: 0.026448
[17:01:40.156] iteration 28163: loss: 0.047093, loss_s1: 0.025347, loss_fp: 0.003578, loss_freq: 0.019041
[17:01:40.777] iteration 28164: loss: 0.081433, loss_s1: 0.084318, loss_fp: 0.013585, loss_freq: 0.023113
[17:01:41.392] iteration 28165: loss: 0.044254, loss_s1: 0.018801, loss_fp: 0.003817, loss_freq: 0.028300
[17:01:42.012] iteration 28166: loss: 0.030395, loss_s1: 0.011199, loss_fp: 0.001687, loss_freq: 0.016929
[17:01:42.629] iteration 28167: loss: 0.040317, loss_s1: 0.024900, loss_fp: 0.004516, loss_freq: 0.016139
[17:01:43.248] iteration 28168: loss: 0.052374, loss_s1: 0.030180, loss_fp: 0.010057, loss_freq: 0.023898
[17:01:43.857] iteration 28169: loss: 0.053338, loss_s1: 0.025087, loss_fp: 0.003449, loss_freq: 0.035442
[17:01:44.470] iteration 28170: loss: 0.035263, loss_s1: 0.018277, loss_fp: 0.004563, loss_freq: 0.009724
[17:01:45.076] iteration 28171: loss: 0.042486, loss_s1: 0.026894, loss_fp: 0.004165, loss_freq: 0.014364
[17:01:46.063] iteration 28172: loss: 0.053911, loss_s1: 0.057704, loss_fp: 0.001330, loss_freq: 0.020292
[17:01:46.709] iteration 28173: loss: 0.037508, loss_s1: 0.012020, loss_fp: 0.005977, loss_freq: 0.016611
[17:01:47.352] iteration 28174: loss: 0.031565, loss_s1: 0.012617, loss_fp: 0.003537, loss_freq: 0.016284
[17:01:47.998] iteration 28175: loss: 0.047026, loss_s1: 0.021526, loss_fp: 0.005969, loss_freq: 0.020851
[17:01:48.643] iteration 28176: loss: 0.057831, loss_s1: 0.053422, loss_fp: 0.003402, loss_freq: 0.030777
[17:01:49.290] iteration 28177: loss: 0.033846, loss_s1: 0.018309, loss_fp: 0.003805, loss_freq: 0.015927
[17:01:49.921] iteration 28178: loss: 0.037173, loss_s1: 0.022865, loss_fp: 0.005883, loss_freq: 0.019977
[17:01:50.547] iteration 28179: loss: 0.050158, loss_s1: 0.034019, loss_fp: 0.001621, loss_freq: 0.023063
[17:01:51.178] iteration 28180: loss: 0.052948, loss_s1: 0.051238, loss_fp: 0.006026, loss_freq: 0.008313
[17:01:51.801] iteration 28181: loss: 0.038375, loss_s1: 0.026787, loss_fp: 0.000802, loss_freq: 0.007779
[17:01:52.416] iteration 28182: loss: 0.074643, loss_s1: 0.072138, loss_fp: 0.001852, loss_freq: 0.046927
[17:01:53.038] iteration 28183: loss: 0.035786, loss_s1: 0.016068, loss_fp: 0.003248, loss_freq: 0.009565
[17:01:53.659] iteration 28184: loss: 0.054062, loss_s1: 0.033021, loss_fp: 0.000906, loss_freq: 0.031348
[17:01:54.282] iteration 28185: loss: 0.036033, loss_s1: 0.009064, loss_fp: 0.003016, loss_freq: 0.015475
[17:01:54.892] iteration 28186: loss: 0.056499, loss_s1: 0.036215, loss_fp: 0.001096, loss_freq: 0.037585
[17:01:55.509] iteration 28187: loss: 0.042823, loss_s1: 0.007592, loss_fp: 0.007887, loss_freq: 0.028317
[17:01:56.132] iteration 28188: loss: 0.049886, loss_s1: 0.027208, loss_fp: 0.005211, loss_freq: 0.026224
[17:01:56.756] iteration 28189: loss: 0.072454, loss_s1: 0.055617, loss_fp: 0.002754, loss_freq: 0.050601
[17:01:57.378] iteration 28190: loss: 0.043334, loss_s1: 0.034855, loss_fp: 0.003270, loss_freq: 0.019367
[17:01:57.998] iteration 28191: loss: 0.038396, loss_s1: 0.020537, loss_fp: 0.002234, loss_freq: 0.021256
[17:01:58.618] iteration 28192: loss: 0.051451, loss_s1: 0.024594, loss_fp: 0.002404, loss_freq: 0.035265
[17:01:59.240] iteration 28193: loss: 0.044583, loss_s1: 0.035390, loss_fp: 0.001914, loss_freq: 0.022766
[17:01:59.870] iteration 28194: loss: 0.037958, loss_s1: 0.023305, loss_fp: 0.004723, loss_freq: 0.017594
[17:02:00.494] iteration 28195: loss: 0.044102, loss_s1: 0.043865, loss_fp: 0.000793, loss_freq: 0.011654
[17:02:01.122] iteration 28196: loss: 0.031655, loss_s1: 0.019300, loss_fp: 0.001327, loss_freq: 0.008830
[17:02:01.744] iteration 28197: loss: 0.041458, loss_s1: 0.028039, loss_fp: 0.007800, loss_freq: 0.005744
[17:02:02.373] iteration 28198: loss: 0.077963, loss_s1: 0.055329, loss_fp: 0.002268, loss_freq: 0.057000
[17:02:02.986] iteration 28199: loss: 0.048098, loss_s1: 0.047933, loss_fp: 0.002156, loss_freq: 0.008449
[17:02:03.611] iteration 28200: loss: 0.041700, loss_s1: 0.027749, loss_fp: 0.003319, loss_freq: 0.015330
[17:02:06.838] iteration 28200 : mean_dice : 0.798607
[17:02:07.487] iteration 28201: loss: 0.039982, loss_s1: 0.016957, loss_fp: 0.001915, loss_freq: 0.017507
[17:02:08.110] iteration 28202: loss: 0.034489, loss_s1: 0.020273, loss_fp: 0.004516, loss_freq: 0.013645
[17:02:08.735] iteration 28203: loss: 0.040929, loss_s1: 0.017459, loss_fp: 0.001987, loss_freq: 0.019538
[17:02:09.359] iteration 28204: loss: 0.115692, loss_s1: 0.115592, loss_fp: 0.023690, loss_freq: 0.063971
[17:02:09.971] iteration 28205: loss: 0.064841, loss_s1: 0.031713, loss_fp: 0.013837, loss_freq: 0.050310
[17:02:10.597] iteration 28206: loss: 0.057839, loss_s1: 0.050152, loss_fp: 0.006076, loss_freq: 0.020303
[17:02:11.213] iteration 28207: loss: 0.055163, loss_s1: 0.050346, loss_fp: 0.003145, loss_freq: 0.011439
[17:02:11.873] iteration 28208: loss: 0.078864, loss_s1: 0.060158, loss_fp: 0.002134, loss_freq: 0.050886
[17:02:12.492] iteration 28209: loss: 0.049270, loss_s1: 0.049252, loss_fp: 0.001366, loss_freq: 0.019800
[17:02:13.122] iteration 28210: loss: 0.078314, loss_s1: 0.069148, loss_fp: 0.003506, loss_freq: 0.025876
[17:02:13.741] iteration 28211: loss: 0.045358, loss_s1: 0.037966, loss_fp: 0.006457, loss_freq: 0.013941
[17:02:14.359] iteration 28212: loss: 0.049586, loss_s1: 0.041853, loss_fp: 0.006503, loss_freq: 0.019169
[17:02:14.998] iteration 28213: loss: 0.040787, loss_s1: 0.044058, loss_fp: 0.001602, loss_freq: 0.010872
[17:02:15.621] iteration 28214: loss: 0.050693, loss_s1: 0.035789, loss_fp: 0.003601, loss_freq: 0.004378
[17:02:16.238] iteration 28215: loss: 0.046099, loss_s1: 0.040067, loss_fp: 0.000891, loss_freq: 0.017308
[17:02:16.864] iteration 28216: loss: 0.044485, loss_s1: 0.010151, loss_fp: 0.003105, loss_freq: 0.015898
[17:02:17.489] iteration 28217: loss: 0.055786, loss_s1: 0.023613, loss_fp: 0.005251, loss_freq: 0.019455
[17:02:18.116] iteration 28218: loss: 0.040362, loss_s1: 0.023780, loss_fp: 0.002086, loss_freq: 0.018905
[17:02:18.738] iteration 28219: loss: 0.052124, loss_s1: 0.032665, loss_fp: 0.005521, loss_freq: 0.024145
[17:02:19.357] iteration 28220: loss: 0.032509, loss_s1: 0.008653, loss_fp: 0.002232, loss_freq: 0.011779
[17:02:19.977] iteration 28221: loss: 0.042006, loss_s1: 0.015784, loss_fp: 0.004500, loss_freq: 0.023024
[17:02:20.611] iteration 28222: loss: 0.071961, loss_s1: 0.074042, loss_fp: 0.007589, loss_freq: 0.013096
[17:02:21.295] iteration 28223: loss: 0.063654, loss_s1: 0.026819, loss_fp: 0.005633, loss_freq: 0.021771
[17:02:21.937] iteration 28224: loss: 0.044180, loss_s1: 0.022129, loss_fp: 0.002964, loss_freq: 0.030561
[17:02:22.585] iteration 28225: loss: 0.068343, loss_s1: 0.036104, loss_fp: 0.009296, loss_freq: 0.067093
[17:02:23.232] iteration 28226: loss: 0.025144, loss_s1: 0.014273, loss_fp: 0.002335, loss_freq: 0.006017
[17:02:23.881] iteration 28227: loss: 0.068166, loss_s1: 0.041226, loss_fp: 0.001196, loss_freq: 0.008654
[17:02:24.525] iteration 28228: loss: 0.051136, loss_s1: 0.045017, loss_fp: 0.006917, loss_freq: 0.019577
[17:02:25.150] iteration 28229: loss: 0.053212, loss_s1: 0.030337, loss_fp: 0.015359, loss_freq: 0.025710
[17:02:25.768] iteration 28230: loss: 0.061706, loss_s1: 0.036361, loss_fp: 0.003145, loss_freq: 0.049813
[17:02:26.392] iteration 28231: loss: 0.059844, loss_s1: 0.061521, loss_fp: 0.004337, loss_freq: 0.012292
[17:02:27.016] iteration 28232: loss: 0.051926, loss_s1: 0.028393, loss_fp: 0.009577, loss_freq: 0.015992
[17:02:27.656] iteration 28233: loss: 0.046431, loss_s1: 0.037488, loss_fp: 0.005039, loss_freq: 0.018479
[17:02:28.272] iteration 28234: loss: 0.090524, loss_s1: 0.047765, loss_fp: 0.017805, loss_freq: 0.076964
[17:02:28.892] iteration 28235: loss: 0.036870, loss_s1: 0.017723, loss_fp: 0.001385, loss_freq: 0.015500
[17:02:29.518] iteration 28236: loss: 0.051401, loss_s1: 0.039205, loss_fp: 0.009106, loss_freq: 0.018029
[17:02:30.139] iteration 28237: loss: 0.037976, loss_s1: 0.023637, loss_fp: 0.001268, loss_freq: 0.020537
[17:02:30.762] iteration 28238: loss: 0.062261, loss_s1: 0.028471, loss_fp: 0.007156, loss_freq: 0.026748
[17:02:31.390] iteration 28239: loss: 0.045822, loss_s1: 0.051199, loss_fp: 0.001179, loss_freq: 0.010974
[17:02:32.015] iteration 28240: loss: 0.039550, loss_s1: 0.026261, loss_fp: 0.001859, loss_freq: 0.012843
[17:02:32.636] iteration 28241: loss: 0.048261, loss_s1: 0.037832, loss_fp: 0.002856, loss_freq: 0.002905
[17:02:33.260] iteration 28242: loss: 0.052955, loss_s1: 0.036942, loss_fp: 0.003847, loss_freq: 0.023739
[17:02:33.883] iteration 28243: loss: 0.039000, loss_s1: 0.022756, loss_fp: 0.003206, loss_freq: 0.013880
[17:02:34.512] iteration 28244: loss: 0.043290, loss_s1: 0.014965, loss_fp: 0.018443, loss_freq: 0.009828
[17:02:35.135] iteration 28245: loss: 0.037120, loss_s1: 0.018088, loss_fp: 0.001044, loss_freq: 0.015123
[17:02:35.759] iteration 28246: loss: 0.053695, loss_s1: 0.040241, loss_fp: 0.001349, loss_freq: 0.037751
[17:02:36.389] iteration 28247: loss: 0.058679, loss_s1: 0.056971, loss_fp: 0.003846, loss_freq: 0.016156
[17:02:37.013] iteration 28248: loss: 0.037953, loss_s1: 0.035805, loss_fp: 0.002220, loss_freq: 0.009073
[17:02:37.635] iteration 28249: loss: 0.044599, loss_s1: 0.034716, loss_fp: 0.002112, loss_freq: 0.016007
[17:02:38.260] iteration 28250: loss: 0.127090, loss_s1: 0.094446, loss_fp: 0.009197, loss_freq: 0.100563
[17:02:38.885] iteration 28251: loss: 0.079684, loss_s1: 0.060141, loss_fp: 0.005589, loss_freq: 0.040785
[17:02:39.500] iteration 28252: loss: 0.044806, loss_s1: 0.027078, loss_fp: 0.005827, loss_freq: 0.016484
[17:02:40.118] iteration 28253: loss: 0.040841, loss_s1: 0.019299, loss_fp: 0.005102, loss_freq: 0.016385
[17:02:40.733] iteration 28254: loss: 0.057016, loss_s1: 0.054790, loss_fp: 0.002819, loss_freq: 0.014461
[17:02:41.358] iteration 28255: loss: 0.045462, loss_s1: 0.043465, loss_fp: 0.004700, loss_freq: 0.015011
[17:02:41.991] iteration 28256: loss: 0.055806, loss_s1: 0.039354, loss_fp: 0.005766, loss_freq: 0.020096
[17:02:42.615] iteration 28257: loss: 0.061147, loss_s1: 0.040090, loss_fp: 0.003667, loss_freq: 0.036346
[17:02:43.244] iteration 28258: loss: 0.045674, loss_s1: 0.048274, loss_fp: 0.001234, loss_freq: 0.003585
[17:02:43.867] iteration 28259: loss: 0.042197, loss_s1: 0.027748, loss_fp: 0.000926, loss_freq: 0.022953
[17:02:44.494] iteration 28260: loss: 0.041550, loss_s1: 0.021835, loss_fp: 0.006521, loss_freq: 0.030675
[17:02:45.125] iteration 28261: loss: 0.066645, loss_s1: 0.075280, loss_fp: 0.007790, loss_freq: 0.024855
[17:02:45.746] iteration 28262: loss: 0.064009, loss_s1: 0.030384, loss_fp: 0.003400, loss_freq: 0.038534
[17:02:46.367] iteration 28263: loss: 0.060027, loss_s1: 0.037266, loss_fp: 0.009623, loss_freq: 0.034659
[17:02:46.994] iteration 28264: loss: 0.043228, loss_s1: 0.050410, loss_fp: 0.001291, loss_freq: 0.006208
[17:02:47.611] iteration 28265: loss: 0.054318, loss_s1: 0.057892, loss_fp: 0.000621, loss_freq: 0.016847
[17:02:48.231] iteration 28266: loss: 0.029662, loss_s1: 0.005721, loss_fp: 0.001227, loss_freq: 0.017680
[17:02:48.847] iteration 28267: loss: 0.033093, loss_s1: 0.010062, loss_fp: 0.000357, loss_freq: 0.003867
[17:02:49.467] iteration 28268: loss: 0.054306, loss_s1: 0.025075, loss_fp: 0.007102, loss_freq: 0.038609
[17:02:50.082] iteration 28269: loss: 0.040891, loss_s1: 0.012273, loss_fp: 0.010417, loss_freq: 0.019821
[17:02:50.707] iteration 28270: loss: 0.039124, loss_s1: 0.022247, loss_fp: 0.001039, loss_freq: 0.009528
[17:02:51.326] iteration 28271: loss: 0.063263, loss_s1: 0.039529, loss_fp: 0.012439, loss_freq: 0.028225
[17:02:51.947] iteration 28272: loss: 0.035135, loss_s1: 0.029749, loss_fp: 0.002233, loss_freq: 0.010449
[17:02:52.568] iteration 28273: loss: 0.029529, loss_s1: 0.015669, loss_fp: 0.002064, loss_freq: 0.007401
[17:02:53.190] iteration 28274: loss: 0.055392, loss_s1: 0.045349, loss_fp: 0.002616, loss_freq: 0.037021
[17:02:53.809] iteration 28275: loss: 0.040543, loss_s1: 0.031512, loss_fp: 0.006482, loss_freq: 0.007224
[17:02:54.426] iteration 28276: loss: 0.052669, loss_s1: 0.048268, loss_fp: 0.004694, loss_freq: 0.011616
[17:02:55.051] iteration 28277: loss: 0.066824, loss_s1: 0.064595, loss_fp: 0.001953, loss_freq: 0.024905
[17:02:55.664] iteration 28278: loss: 0.074200, loss_s1: 0.068610, loss_fp: 0.003946, loss_freq: 0.035324
[17:02:56.299] iteration 28279: loss: 0.037968, loss_s1: 0.011740, loss_fp: 0.004301, loss_freq: 0.020782
[17:02:56.943] iteration 28280: loss: 0.063608, loss_s1: 0.039361, loss_fp: 0.002019, loss_freq: 0.031096
[17:02:57.589] iteration 28281: loss: 0.067434, loss_s1: 0.054267, loss_fp: 0.017475, loss_freq: 0.035356
[17:02:58.244] iteration 28282: loss: 0.074903, loss_s1: 0.036380, loss_fp: 0.002786, loss_freq: 0.016390
[17:02:58.891] iteration 28283: loss: 0.040576, loss_s1: 0.033320, loss_fp: 0.003044, loss_freq: 0.021228
[17:02:59.544] iteration 28284: loss: 0.038480, loss_s1: 0.027515, loss_fp: 0.001443, loss_freq: 0.012910
[17:03:00.200] iteration 28285: loss: 0.068075, loss_s1: 0.066927, loss_fp: 0.005290, loss_freq: 0.023160
[17:03:00.820] iteration 28286: loss: 0.057785, loss_s1: 0.048568, loss_fp: 0.002891, loss_freq: 0.015679
[17:03:01.443] iteration 28287: loss: 0.043591, loss_s1: 0.027429, loss_fp: 0.000690, loss_freq: 0.020436
[17:03:02.069] iteration 28288: loss: 0.042819, loss_s1: 0.016229, loss_fp: 0.005885, loss_freq: 0.020884
[17:03:02.693] iteration 28289: loss: 0.052236, loss_s1: 0.047915, loss_fp: 0.004122, loss_freq: 0.015341
[17:03:03.322] iteration 28290: loss: 0.052843, loss_s1: 0.049611, loss_fp: 0.003474, loss_freq: 0.023393
[17:03:03.942] iteration 28291: loss: 0.066353, loss_s1: 0.057395, loss_fp: 0.000924, loss_freq: 0.033329
[17:03:04.565] iteration 28292: loss: 0.030405, loss_s1: 0.012403, loss_fp: 0.001506, loss_freq: 0.015937
[17:03:05.192] iteration 28293: loss: 0.029919, loss_s1: 0.011896, loss_fp: 0.001387, loss_freq: 0.009716
[17:03:05.815] iteration 28294: loss: 0.040347, loss_s1: 0.036181, loss_fp: 0.001337, loss_freq: 0.011559
[17:03:06.438] iteration 28295: loss: 0.040639, loss_s1: 0.032924, loss_fp: 0.008275, loss_freq: 0.013611
[17:03:07.058] iteration 28296: loss: 0.047422, loss_s1: 0.035728, loss_fp: 0.002052, loss_freq: 0.029826
[17:03:07.680] iteration 28297: loss: 0.049623, loss_s1: 0.031280, loss_fp: 0.000772, loss_freq: 0.007917
[17:03:08.303] iteration 28298: loss: 0.054079, loss_s1: 0.058537, loss_fp: 0.001313, loss_freq: 0.023190
[17:03:08.915] iteration 28299: loss: 0.042299, loss_s1: 0.023872, loss_fp: 0.003369, loss_freq: 0.017767
[17:03:09.541] iteration 28300: loss: 0.068210, loss_s1: 0.047381, loss_fp: 0.009058, loss_freq: 0.022565
[17:03:10.211] iteration 28301: loss: 0.045718, loss_s1: 0.028540, loss_fp: 0.006935, loss_freq: 0.019885
[17:03:10.831] iteration 28302: loss: 0.051383, loss_s1: 0.030158, loss_fp: 0.001706, loss_freq: 0.027687
[17:03:11.452] iteration 28303: loss: 0.068241, loss_s1: 0.034401, loss_fp: 0.005970, loss_freq: 0.058027
[17:03:12.081] iteration 28304: loss: 0.044406, loss_s1: 0.040545, loss_fp: 0.002002, loss_freq: 0.014556
[17:03:12.701] iteration 28305: loss: 0.086779, loss_s1: 0.057426, loss_fp: 0.001584, loss_freq: 0.073557
[17:03:13.330] iteration 28306: loss: 0.053127, loss_s1: 0.014863, loss_fp: 0.011283, loss_freq: 0.033748
[17:03:13.950] iteration 28307: loss: 0.040344, loss_s1: 0.023734, loss_fp: 0.003206, loss_freq: 0.017852
[17:03:14.563] iteration 28308: loss: 0.055697, loss_s1: 0.030212, loss_fp: 0.008652, loss_freq: 0.031026
[17:03:15.224] iteration 28309: loss: 0.034735, loss_s1: 0.025996, loss_fp: 0.001849, loss_freq: 0.011193
[17:03:15.836] iteration 28310: loss: 0.045375, loss_s1: 0.035539, loss_fp: 0.002462, loss_freq: 0.020656
[17:03:16.453] iteration 28311: loss: 0.057044, loss_s1: 0.037412, loss_fp: 0.004375, loss_freq: 0.026535
[17:03:17.078] iteration 28312: loss: 0.052670, loss_s1: 0.035683, loss_fp: 0.003270, loss_freq: 0.029046
[17:03:17.722] iteration 28313: loss: 0.069663, loss_s1: 0.077199, loss_fp: 0.004300, loss_freq: 0.020936
[17:03:18.361] iteration 28314: loss: 0.049317, loss_s1: 0.037943, loss_fp: 0.001128, loss_freq: 0.028653
[17:03:19.297] iteration 28315: loss: 0.033099, loss_s1: 0.018006, loss_fp: 0.004347, loss_freq: 0.005923
[17:03:19.923] iteration 28316: loss: 0.068828, loss_s1: 0.047590, loss_fp: 0.015881, loss_freq: 0.029352
[17:03:20.550] iteration 28317: loss: 0.059235, loss_s1: 0.040860, loss_fp: 0.006921, loss_freq: 0.043071
[17:03:21.171] iteration 28318: loss: 0.061096, loss_s1: 0.040044, loss_fp: 0.004663, loss_freq: 0.037104
[17:03:21.821] iteration 28319: loss: 0.059318, loss_s1: 0.065342, loss_fp: 0.003463, loss_freq: 0.025150
[17:03:22.472] iteration 28320: loss: 0.039390, loss_s1: 0.024661, loss_fp: 0.008296, loss_freq: 0.003409
[17:03:23.120] iteration 28321: loss: 0.031262, loss_s1: 0.026163, loss_fp: 0.001221, loss_freq: 0.009355
[17:03:23.744] iteration 28322: loss: 0.071970, loss_s1: 0.042628, loss_fp: 0.001038, loss_freq: 0.035429
[17:03:24.371] iteration 28323: loss: 0.042902, loss_s1: 0.015893, loss_fp: 0.004421, loss_freq: 0.019588
[17:03:24.995] iteration 28324: loss: 0.037196, loss_s1: 0.009139, loss_fp: 0.000408, loss_freq: 0.006421
[17:03:25.616] iteration 28325: loss: 0.084173, loss_s1: 0.039370, loss_fp: 0.007994, loss_freq: 0.041490
[17:03:26.255] iteration 28326: loss: 0.065466, loss_s1: 0.071967, loss_fp: 0.003311, loss_freq: 0.015812
[17:03:26.888] iteration 28327: loss: 0.055289, loss_s1: 0.047252, loss_fp: 0.006368, loss_freq: 0.019597
[17:03:27.507] iteration 28328: loss: 0.033065, loss_s1: 0.019132, loss_fp: 0.002662, loss_freq: 0.016483
[17:03:28.136] iteration 28329: loss: 0.070112, loss_s1: 0.040893, loss_fp: 0.011646, loss_freq: 0.040899
[17:03:28.755] iteration 28330: loss: 0.053934, loss_s1: 0.036732, loss_fp: 0.002991, loss_freq: 0.023670
[17:03:29.379] iteration 28331: loss: 0.069192, loss_s1: 0.025959, loss_fp: 0.008117, loss_freq: 0.052148
[17:03:30.003] iteration 28332: loss: 0.060296, loss_s1: 0.062453, loss_fp: 0.005608, loss_freq: 0.022187
[17:03:30.623] iteration 28333: loss: 0.037585, loss_s1: 0.022171, loss_fp: 0.002695, loss_freq: 0.022423
[17:03:31.245] iteration 28334: loss: 0.030686, loss_s1: 0.012069, loss_fp: 0.000835, loss_freq: 0.015706
[17:03:31.869] iteration 28335: loss: 0.087544, loss_s1: 0.034183, loss_fp: 0.001588, loss_freq: 0.082624
[17:03:32.537] iteration 28336: loss: 0.071543, loss_s1: 0.073861, loss_fp: 0.002857, loss_freq: 0.022432
[17:03:33.185] iteration 28337: loss: 0.040803, loss_s1: 0.023333, loss_fp: 0.001701, loss_freq: 0.023913
[17:03:33.909] iteration 28338: loss: 0.032745, loss_s1: 0.020624, loss_fp: 0.002047, loss_freq: 0.010326
[17:03:34.595] iteration 28339: loss: 0.023172, loss_s1: 0.006946, loss_fp: 0.002039, loss_freq: 0.007358
[17:03:35.222] iteration 28340: loss: 0.073821, loss_s1: 0.025022, loss_fp: 0.001183, loss_freq: 0.070085
[17:03:35.877] iteration 28341: loss: 0.038412, loss_s1: 0.022141, loss_fp: 0.007069, loss_freq: 0.015318
[17:03:36.514] iteration 28342: loss: 0.046340, loss_s1: 0.042082, loss_fp: 0.004019, loss_freq: 0.010326
[17:03:37.155] iteration 28343: loss: 0.054011, loss_s1: 0.048411, loss_fp: 0.002822, loss_freq: 0.011049
[17:03:37.829] iteration 28344: loss: 0.042156, loss_s1: 0.021608, loss_fp: 0.001323, loss_freq: 0.024256
[17:03:38.450] iteration 28345: loss: 0.044895, loss_s1: 0.022249, loss_fp: 0.001325, loss_freq: 0.008703
[17:03:39.063] iteration 28346: loss: 0.054027, loss_s1: 0.035612, loss_fp: 0.003145, loss_freq: 0.029828
[17:03:39.690] iteration 28347: loss: 0.068692, loss_s1: 0.067278, loss_fp: 0.005495, loss_freq: 0.034369
[17:03:40.302] iteration 28348: loss: 0.076425, loss_s1: 0.045212, loss_fp: 0.018432, loss_freq: 0.047225
[17:03:40.922] iteration 28349: loss: 0.056392, loss_s1: 0.054761, loss_fp: 0.003498, loss_freq: 0.015997
[17:03:41.553] iteration 28350: loss: 0.070832, loss_s1: 0.069014, loss_fp: 0.003377, loss_freq: 0.025929
[17:03:42.173] iteration 28351: loss: 0.067046, loss_s1: 0.026615, loss_fp: 0.001429, loss_freq: 0.065161
[17:03:42.849] iteration 28352: loss: 0.026364, loss_s1: 0.015244, loss_fp: 0.001505, loss_freq: 0.006676
[17:03:43.468] iteration 28353: loss: 0.043446, loss_s1: 0.024289, loss_fp: 0.006073, loss_freq: 0.014675
[17:03:44.095] iteration 28354: loss: 0.031079, loss_s1: 0.024960, loss_fp: 0.002519, loss_freq: 0.009503
[17:03:44.720] iteration 28355: loss: 0.064414, loss_s1: 0.053593, loss_fp: 0.010291, loss_freq: 0.033006
[17:03:45.342] iteration 28356: loss: 0.060920, loss_s1: 0.066473, loss_fp: 0.001946, loss_freq: 0.026176
[17:03:45.958] iteration 28357: loss: 0.041526, loss_s1: 0.031737, loss_fp: 0.002299, loss_freq: 0.013013
[17:03:46.574] iteration 28358: loss: 0.054900, loss_s1: 0.047883, loss_fp: 0.005081, loss_freq: 0.026803
[17:03:47.193] iteration 28359: loss: 0.035380, loss_s1: 0.011227, loss_fp: 0.013049, loss_freq: 0.003103
[17:03:47.822] iteration 28360: loss: 0.048354, loss_s1: 0.037797, loss_fp: 0.001605, loss_freq: 0.021882
[17:03:48.441] iteration 28361: loss: 0.043627, loss_s1: 0.017229, loss_fp: 0.000464, loss_freq: 0.034258
[17:03:49.061] iteration 28362: loss: 0.043183, loss_s1: 0.020351, loss_fp: 0.006790, loss_freq: 0.017060
[17:03:49.677] iteration 28363: loss: 0.035405, loss_s1: 0.015810, loss_fp: 0.002159, loss_freq: 0.023838
[17:03:50.330] iteration 28364: loss: 0.052557, loss_s1: 0.050101, loss_fp: 0.001913, loss_freq: 0.020417
[17:03:50.962] iteration 28365: loss: 0.048433, loss_s1: 0.029757, loss_fp: 0.006378, loss_freq: 0.028409
[17:03:51.608] iteration 28366: loss: 0.054169, loss_s1: 0.044235, loss_fp: 0.002312, loss_freq: 0.020684
[17:03:52.259] iteration 28367: loss: 0.037372, loss_s1: 0.023299, loss_fp: 0.002162, loss_freq: 0.015066
[17:03:52.899] iteration 28368: loss: 0.082322, loss_s1: 0.071265, loss_fp: 0.002773, loss_freq: 0.068253
[17:03:53.525] iteration 28369: loss: 0.046626, loss_s1: 0.052467, loss_fp: 0.004843, loss_freq: 0.008007
[17:03:54.147] iteration 28370: loss: 0.047347, loss_s1: 0.038267, loss_fp: 0.000875, loss_freq: 0.011343
[17:03:54.768] iteration 28371: loss: 0.038747, loss_s1: 0.046608, loss_fp: 0.000732, loss_freq: 0.003746
[17:03:55.386] iteration 28372: loss: 0.039438, loss_s1: 0.030403, loss_fp: 0.003506, loss_freq: 0.006969
[17:03:56.005] iteration 28373: loss: 0.084068, loss_s1: 0.076050, loss_fp: 0.000624, loss_freq: 0.061848
[17:03:56.624] iteration 28374: loss: 0.035511, loss_s1: 0.015134, loss_fp: 0.003928, loss_freq: 0.007882
[17:03:57.246] iteration 28375: loss: 0.060429, loss_s1: 0.040201, loss_fp: 0.001782, loss_freq: 0.022658
[17:03:57.859] iteration 28376: loss: 0.050337, loss_s1: 0.044424, loss_fp: 0.003917, loss_freq: 0.017117
[17:03:58.470] iteration 28377: loss: 0.073167, loss_s1: 0.079009, loss_fp: 0.002304, loss_freq: 0.025119
[17:03:59.093] iteration 28378: loss: 0.056695, loss_s1: 0.030046, loss_fp: 0.002598, loss_freq: 0.026044
[17:03:59.713] iteration 28379: loss: 0.071123, loss_s1: 0.029661, loss_fp: 0.001930, loss_freq: 0.006748
[17:04:00.336] iteration 28380: loss: 0.045239, loss_s1: 0.029678, loss_fp: 0.001585, loss_freq: 0.018250
[17:04:00.959] iteration 28381: loss: 0.054216, loss_s1: 0.029871, loss_fp: 0.008880, loss_freq: 0.026455
[17:04:01.580] iteration 28382: loss: 0.045417, loss_s1: 0.041630, loss_fp: 0.002616, loss_freq: 0.017260
[17:04:02.205] iteration 28383: loss: 0.062040, loss_s1: 0.070240, loss_fp: 0.001567, loss_freq: 0.010245
[17:04:02.825] iteration 28384: loss: 0.050407, loss_s1: 0.035712, loss_fp: 0.001599, loss_freq: 0.013509
[17:04:03.445] iteration 28385: loss: 0.044847, loss_s1: 0.034554, loss_fp: 0.002471, loss_freq: 0.016672
[17:04:04.070] iteration 28386: loss: 0.036788, loss_s1: 0.014556, loss_fp: 0.002982, loss_freq: 0.021250
[17:04:04.686] iteration 28387: loss: 0.041265, loss_s1: 0.024094, loss_fp: 0.006885, loss_freq: 0.013721
[17:04:05.331] iteration 28388: loss: 0.064853, loss_s1: 0.046594, loss_fp: 0.012957, loss_freq: 0.020367
[17:04:05.954] iteration 28389: loss: 0.061189, loss_s1: 0.055384, loss_fp: 0.003150, loss_freq: 0.030400
[17:04:06.574] iteration 28390: loss: 0.044465, loss_s1: 0.044601, loss_fp: 0.006726, loss_freq: 0.006238
[17:04:07.212] iteration 28391: loss: 0.048219, loss_s1: 0.035059, loss_fp: 0.004543, loss_freq: 0.029917
[17:04:07.832] iteration 28392: loss: 0.038452, loss_s1: 0.023852, loss_fp: 0.001204, loss_freq: 0.005804
[17:04:08.452] iteration 28393: loss: 0.087144, loss_s1: 0.074825, loss_fp: 0.012791, loss_freq: 0.046965
[17:04:09.075] iteration 28394: loss: 0.085772, loss_s1: 0.024003, loss_fp: 0.013144, loss_freq: 0.043194
[17:04:09.693] iteration 28395: loss: 0.037788, loss_s1: 0.009051, loss_fp: 0.011469, loss_freq: 0.011802
[17:04:10.327] iteration 28396: loss: 0.048630, loss_s1: 0.022817, loss_fp: 0.001972, loss_freq: 0.027611
[17:04:10.993] iteration 28397: loss: 0.047205, loss_s1: 0.029607, loss_fp: 0.008659, loss_freq: 0.012137
[17:04:11.635] iteration 28398: loss: 0.047344, loss_s1: 0.047542, loss_fp: 0.005705, loss_freq: 0.016522
[17:04:12.276] iteration 28399: loss: 0.054182, loss_s1: 0.050306, loss_fp: 0.003741, loss_freq: 0.018835
[17:04:12.899] iteration 28400: loss: 0.057206, loss_s1: 0.018322, loss_fp: 0.008640, loss_freq: 0.045332
[17:04:16.125] iteration 28400 : mean_dice : 0.799884
[17:04:16.816] iteration 28401: loss: 0.043784, loss_s1: 0.024382, loss_fp: 0.002078, loss_freq: 0.020389
[17:04:17.439] iteration 28402: loss: 0.033426, loss_s1: 0.021662, loss_fp: 0.000752, loss_freq: 0.009876
[17:04:18.062] iteration 28403: loss: 0.045713, loss_s1: 0.042250, loss_fp: 0.000790, loss_freq: 0.016149
[17:04:18.681] iteration 28404: loss: 0.068834, loss_s1: 0.066323, loss_fp: 0.002970, loss_freq: 0.039380
[17:04:19.298] iteration 28405: loss: 0.052571, loss_s1: 0.037296, loss_fp: 0.000448, loss_freq: 0.013164
[17:04:19.916] iteration 28406: loss: 0.049718, loss_s1: 0.034103, loss_fp: 0.007686, loss_freq: 0.031898
[17:04:20.544] iteration 28407: loss: 0.047598, loss_s1: 0.053069, loss_fp: 0.005428, loss_freq: 0.010533
[17:04:21.167] iteration 28408: loss: 0.037574, loss_s1: 0.020059, loss_fp: 0.002265, loss_freq: 0.021282
[17:04:21.833] iteration 28409: loss: 0.035664, loss_s1: 0.018442, loss_fp: 0.001776, loss_freq: 0.009740
[17:04:22.454] iteration 28410: loss: 0.051502, loss_s1: 0.029603, loss_fp: 0.001102, loss_freq: 0.011030
[17:04:23.073] iteration 28411: loss: 0.071091, loss_s1: 0.058347, loss_fp: 0.003349, loss_freq: 0.043527
[17:04:23.697] iteration 28412: loss: 0.037034, loss_s1: 0.006644, loss_fp: 0.002370, loss_freq: 0.014039
[17:04:24.345] iteration 28413: loss: 0.056367, loss_s1: 0.021711, loss_fp: 0.001917, loss_freq: 0.046138
[17:04:24.985] iteration 28414: loss: 0.078227, loss_s1: 0.057745, loss_fp: 0.004351, loss_freq: 0.035964
[17:04:25.623] iteration 28415: loss: 0.042927, loss_s1: 0.037266, loss_fp: 0.002651, loss_freq: 0.006400
[17:04:26.260] iteration 28416: loss: 0.053390, loss_s1: 0.037611, loss_fp: 0.005416, loss_freq: 0.024448
[17:04:26.896] iteration 28417: loss: 0.068288, loss_s1: 0.061737, loss_fp: 0.005235, loss_freq: 0.030159
[17:04:27.522] iteration 28418: loss: 0.038873, loss_s1: 0.029394, loss_fp: 0.001735, loss_freq: 0.009989
[17:04:28.144] iteration 28419: loss: 0.056011, loss_s1: 0.035985, loss_fp: 0.005737, loss_freq: 0.023429
[17:04:28.774] iteration 28420: loss: 0.040366, loss_s1: 0.023759, loss_fp: 0.000365, loss_freq: 0.020509
[17:04:29.399] iteration 28421: loss: 0.079961, loss_s1: 0.069096, loss_fp: 0.005660, loss_freq: 0.040289
[17:04:30.016] iteration 28422: loss: 0.068874, loss_s1: 0.037702, loss_fp: 0.006527, loss_freq: 0.043444
[17:04:30.641] iteration 28423: loss: 0.065470, loss_s1: 0.053487, loss_fp: 0.002871, loss_freq: 0.036919
[17:04:31.301] iteration 28424: loss: 0.069623, loss_s1: 0.066632, loss_fp: 0.005984, loss_freq: 0.025458
[17:04:31.965] iteration 28425: loss: 0.054845, loss_s1: 0.037672, loss_fp: 0.001056, loss_freq: 0.033019
[17:04:32.610] iteration 28426: loss: 0.049709, loss_s1: 0.039668, loss_fp: 0.002705, loss_freq: 0.027597
[17:04:33.261] iteration 28427: loss: 0.045636, loss_s1: 0.023966, loss_fp: 0.001470, loss_freq: 0.013002
[17:04:33.910] iteration 28428: loss: 0.055187, loss_s1: 0.057027, loss_fp: 0.001593, loss_freq: 0.017164
[17:04:34.542] iteration 28429: loss: 0.045834, loss_s1: 0.024177, loss_fp: 0.001382, loss_freq: 0.014509
[17:04:35.186] iteration 28430: loss: 0.030346, loss_s1: 0.021927, loss_fp: 0.002349, loss_freq: 0.007999
[17:04:35.811] iteration 28431: loss: 0.068233, loss_s1: 0.044980, loss_fp: 0.005759, loss_freq: 0.030393
[17:04:36.428] iteration 28432: loss: 0.063330, loss_s1: 0.069412, loss_fp: 0.002918, loss_freq: 0.014277
[17:04:37.061] iteration 28433: loss: 0.049712, loss_s1: 0.054315, loss_fp: 0.002198, loss_freq: 0.013533
[17:04:37.691] iteration 28434: loss: 0.059205, loss_s1: 0.034378, loss_fp: 0.000612, loss_freq: 0.043316
[17:04:38.317] iteration 28435: loss: 0.071882, loss_s1: 0.063597, loss_fp: 0.002725, loss_freq: 0.036804
[17:04:38.998] iteration 28436: loss: 0.035495, loss_s1: 0.022202, loss_fp: 0.002902, loss_freq: 0.009118
[17:04:39.645] iteration 28437: loss: 0.026698, loss_s1: 0.011025, loss_fp: 0.002217, loss_freq: 0.007696
[17:04:40.290] iteration 28438: loss: 0.040270, loss_s1: 0.040626, loss_fp: 0.002186, loss_freq: 0.007090
[17:04:40.915] iteration 28439: loss: 0.053266, loss_s1: 0.035740, loss_fp: 0.005149, loss_freq: 0.033941
[17:04:41.540] iteration 28440: loss: 0.043320, loss_s1: 0.016375, loss_fp: 0.003544, loss_freq: 0.025351
[17:04:42.175] iteration 28441: loss: 0.052492, loss_s1: 0.046347, loss_fp: 0.002655, loss_freq: 0.024844
[17:04:42.797] iteration 28442: loss: 0.049257, loss_s1: 0.038024, loss_fp: 0.002841, loss_freq: 0.023840
[17:04:43.423] iteration 28443: loss: 0.049850, loss_s1: 0.036387, loss_fp: 0.009717, loss_freq: 0.016164
[17:04:44.036] iteration 28444: loss: 0.045163, loss_s1: 0.026553, loss_fp: 0.004220, loss_freq: 0.021373
[17:04:44.658] iteration 28445: loss: 0.059335, loss_s1: 0.055214, loss_fp: 0.002082, loss_freq: 0.023400
[17:04:45.286] iteration 28446: loss: 0.048897, loss_s1: 0.022517, loss_fp: 0.003674, loss_freq: 0.036183
[17:04:45.918] iteration 28447: loss: 0.041664, loss_s1: 0.032020, loss_fp: 0.004426, loss_freq: 0.011364
[17:04:46.540] iteration 28448: loss: 0.059399, loss_s1: 0.037343, loss_fp: 0.003136, loss_freq: 0.032649
[17:04:47.160] iteration 28449: loss: 0.047137, loss_s1: 0.014528, loss_fp: 0.004288, loss_freq: 0.023828
[17:04:47.783] iteration 28450: loss: 0.049734, loss_s1: 0.056362, loss_fp: 0.001560, loss_freq: 0.006627
[17:04:48.407] iteration 28451: loss: 0.046630, loss_s1: 0.036807, loss_fp: 0.005888, loss_freq: 0.011511
[17:04:49.026] iteration 28452: loss: 0.028267, loss_s1: 0.018289, loss_fp: 0.000690, loss_freq: 0.006186
[17:04:49.659] iteration 28453: loss: 0.044532, loss_s1: 0.035825, loss_fp: 0.001116, loss_freq: 0.018366
[17:04:50.296] iteration 28454: loss: 0.038246, loss_s1: 0.028472, loss_fp: 0.003352, loss_freq: 0.009680
[17:04:50.908] iteration 28455: loss: 0.037753, loss_s1: 0.021620, loss_fp: 0.011003, loss_freq: 0.014644
[17:04:51.524] iteration 28456: loss: 0.062110, loss_s1: 0.054358, loss_fp: 0.008460, loss_freq: 0.019934
[17:04:52.141] iteration 28457: loss: 0.038215, loss_s1: 0.026442, loss_fp: 0.001074, loss_freq: 0.012538
[17:04:53.154] iteration 28458: loss: 0.028113, loss_s1: 0.010544, loss_fp: 0.000589, loss_freq: 0.004283
[17:04:53.795] iteration 28459: loss: 0.068311, loss_s1: 0.089001, loss_fp: 0.003291, loss_freq: 0.006979
[17:04:54.444] iteration 28460: loss: 0.041945, loss_s1: 0.028520, loss_fp: 0.005186, loss_freq: 0.021636
[17:04:55.094] iteration 28461: loss: 0.047111, loss_s1: 0.027252, loss_fp: 0.003438, loss_freq: 0.025756
[17:04:55.743] iteration 28462: loss: 0.072602, loss_s1: 0.078809, loss_fp: 0.015112, loss_freq: 0.026545
[17:04:56.384] iteration 28463: loss: 0.057970, loss_s1: 0.063159, loss_fp: 0.003902, loss_freq: 0.011693
[17:04:57.022] iteration 28464: loss: 0.039822, loss_s1: 0.019267, loss_fp: 0.003283, loss_freq: 0.028327
[17:04:57.649] iteration 28465: loss: 0.044548, loss_s1: 0.022517, loss_fp: 0.001984, loss_freq: 0.020584
[17:04:58.277] iteration 28466: loss: 0.041015, loss_s1: 0.027855, loss_fp: 0.003050, loss_freq: 0.020887
[17:04:58.896] iteration 28467: loss: 0.041750, loss_s1: 0.005244, loss_fp: 0.001529, loss_freq: 0.005309
[17:04:59.526] iteration 28468: loss: 0.069721, loss_s1: 0.023802, loss_fp: 0.005696, loss_freq: 0.068662
[17:05:00.140] iteration 28469: loss: 0.045695, loss_s1: 0.033323, loss_fp: 0.005549, loss_freq: 0.016410
[17:05:00.760] iteration 28470: loss: 0.037951, loss_s1: 0.025236, loss_fp: 0.000753, loss_freq: 0.009645
[17:05:01.375] iteration 28471: loss: 0.034967, loss_s1: 0.020630, loss_fp: 0.002309, loss_freq: 0.020006
[17:05:02.007] iteration 28472: loss: 0.036276, loss_s1: 0.015034, loss_fp: 0.001488, loss_freq: 0.018033
[17:05:02.655] iteration 28473: loss: 0.048674, loss_s1: 0.030749, loss_fp: 0.008929, loss_freq: 0.018549
[17:05:03.289] iteration 28474: loss: 0.053410, loss_s1: 0.027750, loss_fp: 0.003632, loss_freq: 0.032877
[17:05:03.910] iteration 28475: loss: 0.061249, loss_s1: 0.057951, loss_fp: 0.001424, loss_freq: 0.031488
[17:05:04.548] iteration 28476: loss: 0.058710, loss_s1: 0.037773, loss_fp: 0.001548, loss_freq: 0.038958
[17:05:05.191] iteration 28477: loss: 0.036637, loss_s1: 0.030650, loss_fp: 0.000966, loss_freq: 0.013947
[17:05:05.840] iteration 28478: loss: 0.088092, loss_s1: 0.063361, loss_fp: 0.004645, loss_freq: 0.058483
[17:05:06.470] iteration 28479: loss: 0.038511, loss_s1: 0.022153, loss_fp: 0.003218, loss_freq: 0.021372
[17:05:07.094] iteration 28480: loss: 0.041867, loss_s1: 0.016537, loss_fp: 0.003488, loss_freq: 0.018951
[17:05:07.719] iteration 28481: loss: 0.041700, loss_s1: 0.046961, loss_fp: 0.003174, loss_freq: 0.002426
[17:05:08.345] iteration 28482: loss: 0.056946, loss_s1: 0.056323, loss_fp: 0.002401, loss_freq: 0.007392
[17:05:08.984] iteration 28483: loss: 0.069950, loss_s1: 0.031206, loss_fp: 0.016861, loss_freq: 0.049936
[17:05:09.604] iteration 28484: loss: 0.075676, loss_s1: 0.077606, loss_fp: 0.008693, loss_freq: 0.027599
[17:05:10.220] iteration 28485: loss: 0.050081, loss_s1: 0.034682, loss_fp: 0.003498, loss_freq: 0.018607
[17:05:10.841] iteration 28486: loss: 0.054003, loss_s1: 0.036136, loss_fp: 0.006183, loss_freq: 0.023419
[17:05:11.466] iteration 28487: loss: 0.035583, loss_s1: 0.013081, loss_fp: 0.000923, loss_freq: 0.016207
[17:05:12.088] iteration 28488: loss: 0.037720, loss_s1: 0.021819, loss_fp: 0.001685, loss_freq: 0.016373
[17:05:12.709] iteration 28489: loss: 0.076813, loss_s1: 0.072135, loss_fp: 0.004132, loss_freq: 0.026235
[17:05:13.335] iteration 28490: loss: 0.049256, loss_s1: 0.030471, loss_fp: 0.002815, loss_freq: 0.037183
[17:05:13.963] iteration 28491: loss: 0.060424, loss_s1: 0.062407, loss_fp: 0.004591, loss_freq: 0.019661
[17:05:14.589] iteration 28492: loss: 0.065524, loss_s1: 0.035966, loss_fp: 0.008649, loss_freq: 0.026558
[17:05:15.211] iteration 28493: loss: 0.055255, loss_s1: 0.040482, loss_fp: 0.001747, loss_freq: 0.032547
[17:05:15.838] iteration 28494: loss: 0.038684, loss_s1: 0.021549, loss_fp: 0.001992, loss_freq: 0.019414
[17:05:16.455] iteration 28495: loss: 0.032935, loss_s1: 0.023295, loss_fp: 0.003927, loss_freq: 0.012248
[17:05:17.097] iteration 28496: loss: 0.078627, loss_s1: 0.080557, loss_fp: 0.003399, loss_freq: 0.034766
[17:05:17.739] iteration 28497: loss: 0.038481, loss_s1: 0.029972, loss_fp: 0.004948, loss_freq: 0.005995
[17:05:18.373] iteration 28498: loss: 0.045255, loss_s1: 0.026172, loss_fp: 0.005660, loss_freq: 0.015822
[17:05:19.016] iteration 28499: loss: 0.049202, loss_s1: 0.055930, loss_fp: 0.001673, loss_freq: 0.014840
[17:05:19.662] iteration 28500: loss: 0.033463, loss_s1: 0.003935, loss_fp: 0.001140, loss_freq: 0.023479
[17:05:20.293] iteration 28501: loss: 0.055982, loss_s1: 0.024145, loss_fp: 0.005858, loss_freq: 0.047434
[17:05:20.907] iteration 28502: loss: 0.044483, loss_s1: 0.010327, loss_fp: 0.001119, loss_freq: 0.010644
[17:05:21.527] iteration 28503: loss: 0.044513, loss_s1: 0.047452, loss_fp: 0.001256, loss_freq: 0.012071
[17:05:22.163] iteration 28504: loss: 0.049132, loss_s1: 0.016452, loss_fp: 0.001094, loss_freq: 0.037028
[17:05:22.785] iteration 28505: loss: 0.041030, loss_s1: 0.035205, loss_fp: 0.002120, loss_freq: 0.009403
[17:05:23.411] iteration 28506: loss: 0.059292, loss_s1: 0.073090, loss_fp: 0.001343, loss_freq: 0.016063
[17:05:24.037] iteration 28507: loss: 0.056897, loss_s1: 0.048010, loss_fp: 0.011353, loss_freq: 0.017858
[17:05:24.661] iteration 28508: loss: 0.041029, loss_s1: 0.026255, loss_fp: 0.001293, loss_freq: 0.021359
[17:05:25.282] iteration 28509: loss: 0.069706, loss_s1: 0.026334, loss_fp: 0.003435, loss_freq: 0.024546
[17:05:25.910] iteration 28510: loss: 0.037783, loss_s1: 0.027301, loss_fp: 0.002664, loss_freq: 0.016339
[17:05:26.531] iteration 28511: loss: 0.051141, loss_s1: 0.028581, loss_fp: 0.008849, loss_freq: 0.037017
[17:05:27.165] iteration 28512: loss: 0.031475, loss_s1: 0.013319, loss_fp: 0.000954, loss_freq: 0.006256
[17:05:27.805] iteration 28513: loss: 0.059300, loss_s1: 0.036607, loss_fp: 0.003864, loss_freq: 0.035605
[17:05:28.453] iteration 28514: loss: 0.049438, loss_s1: 0.040112, loss_fp: 0.007587, loss_freq: 0.019770
[17:05:29.095] iteration 28515: loss: 0.052274, loss_s1: 0.045170, loss_fp: 0.001281, loss_freq: 0.020645
[17:05:29.732] iteration 28516: loss: 0.065198, loss_s1: 0.028247, loss_fp: 0.001963, loss_freq: 0.063993
[17:05:30.373] iteration 28517: loss: 0.038956, loss_s1: 0.029668, loss_fp: 0.002758, loss_freq: 0.008864
[17:05:30.996] iteration 28518: loss: 0.039503, loss_s1: 0.025411, loss_fp: 0.005532, loss_freq: 0.012766
[17:05:31.643] iteration 28519: loss: 0.068843, loss_s1: 0.065537, loss_fp: 0.003947, loss_freq: 0.013085
[17:05:32.285] iteration 28520: loss: 0.064297, loss_s1: 0.059482, loss_fp: 0.006909, loss_freq: 0.023788
[17:05:32.931] iteration 28521: loss: 0.047159, loss_s1: 0.016836, loss_fp: 0.002018, loss_freq: 0.021673
[17:05:33.554] iteration 28522: loss: 0.071462, loss_s1: 0.032890, loss_fp: 0.007249, loss_freq: 0.025395
[17:05:34.172] iteration 28523: loss: 0.036885, loss_s1: 0.030197, loss_fp: 0.002564, loss_freq: 0.005422
[17:05:34.790] iteration 28524: loss: 0.082873, loss_s1: 0.049906, loss_fp: 0.011272, loss_freq: 0.065141
[17:05:35.412] iteration 28525: loss: 0.034403, loss_s1: 0.020702, loss_fp: 0.004156, loss_freq: 0.015168
[17:05:36.031] iteration 28526: loss: 0.035911, loss_s1: 0.026032, loss_fp: 0.000856, loss_freq: 0.007546
[17:05:36.657] iteration 28527: loss: 0.031565, loss_s1: 0.013080, loss_fp: 0.006496, loss_freq: 0.004757
[17:05:37.279] iteration 28528: loss: 0.039335, loss_s1: 0.025196, loss_fp: 0.000445, loss_freq: 0.016837
[17:05:37.913] iteration 28529: loss: 0.053185, loss_s1: 0.036733, loss_fp: 0.003882, loss_freq: 0.031856
[17:05:38.601] iteration 28530: loss: 0.036331, loss_s1: 0.020421, loss_fp: 0.002820, loss_freq: 0.018816
[17:05:39.541] iteration 28531: loss: 0.076890, loss_s1: 0.088552, loss_fp: 0.001481, loss_freq: 0.020574
[17:05:40.495] iteration 28532: loss: 0.094762, loss_s1: 0.062004, loss_fp: 0.017705, loss_freq: 0.080480
[17:05:41.216] iteration 28533: loss: 0.039729, loss_s1: 0.036898, loss_fp: 0.001833, loss_freq: 0.012920
[17:05:41.846] iteration 28534: loss: 0.039603, loss_s1: 0.032015, loss_fp: 0.007580, loss_freq: 0.011729
[17:05:42.463] iteration 28535: loss: 0.052245, loss_s1: 0.044727, loss_fp: 0.002102, loss_freq: 0.013644
[17:05:43.081] iteration 28536: loss: 0.093333, loss_s1: 0.075543, loss_fp: 0.010239, loss_freq: 0.054666
[17:05:43.694] iteration 28537: loss: 0.068236, loss_s1: 0.039593, loss_fp: 0.011775, loss_freq: 0.018249
[17:05:44.316] iteration 28538: loss: 0.045052, loss_s1: 0.043343, loss_fp: 0.000828, loss_freq: 0.014252
[17:05:44.940] iteration 28539: loss: 0.033818, loss_s1: 0.025436, loss_fp: 0.002226, loss_freq: 0.009911
[17:05:45.559] iteration 28540: loss: 0.043813, loss_s1: 0.043450, loss_fp: 0.000555, loss_freq: 0.013471
[17:05:46.172] iteration 28541: loss: 0.047330, loss_s1: 0.042455, loss_fp: 0.012233, loss_freq: 0.011490
[17:05:46.784] iteration 28542: loss: 0.052294, loss_s1: 0.029529, loss_fp: 0.009411, loss_freq: 0.027639
[17:05:47.444] iteration 28543: loss: 0.068537, loss_s1: 0.045712, loss_fp: 0.001369, loss_freq: 0.048422
[17:05:48.073] iteration 28544: loss: 0.044545, loss_s1: 0.045758, loss_fp: 0.001186, loss_freq: 0.006749
[17:05:48.692] iteration 28545: loss: 0.033547, loss_s1: 0.023571, loss_fp: 0.003976, loss_freq: 0.011867
[17:05:49.310] iteration 28546: loss: 0.040304, loss_s1: 0.034045, loss_fp: 0.001765, loss_freq: 0.010747
[17:05:49.933] iteration 28547: loss: 0.053232, loss_s1: 0.042477, loss_fp: 0.002700, loss_freq: 0.033188
[17:05:50.551] iteration 28548: loss: 0.061347, loss_s1: 0.041518, loss_fp: 0.004506, loss_freq: 0.029118
[17:05:51.166] iteration 28549: loss: 0.056603, loss_s1: 0.047020, loss_fp: 0.015992, loss_freq: 0.019785
[17:05:51.785] iteration 28550: loss: 0.051993, loss_s1: 0.058738, loss_fp: 0.001208, loss_freq: 0.013483
[17:05:52.412] iteration 28551: loss: 0.040264, loss_s1: 0.028967, loss_fp: 0.003520, loss_freq: 0.011414
[17:05:53.030] iteration 28552: loss: 0.060729, loss_s1: 0.030445, loss_fp: 0.010566, loss_freq: 0.032477
[17:05:53.646] iteration 28553: loss: 0.038707, loss_s1: 0.021891, loss_fp: 0.001661, loss_freq: 0.012889
[17:05:54.271] iteration 28554: loss: 0.086537, loss_s1: 0.058066, loss_fp: 0.010258, loss_freq: 0.060908
[17:05:54.883] iteration 28555: loss: 0.049756, loss_s1: 0.040639, loss_fp: 0.002791, loss_freq: 0.018367
[17:05:55.507] iteration 28556: loss: 0.043487, loss_s1: 0.032271, loss_fp: 0.002560, loss_freq: 0.007319
[17:05:56.127] iteration 28557: loss: 0.048996, loss_s1: 0.023156, loss_fp: 0.008206, loss_freq: 0.030958
[17:05:56.744] iteration 28558: loss: 0.048201, loss_s1: 0.036980, loss_fp: 0.001365, loss_freq: 0.010908
[17:05:57.357] iteration 28559: loss: 0.063047, loss_s1: 0.030883, loss_fp: 0.004594, loss_freq: 0.053583
[17:05:57.982] iteration 28560: loss: 0.048600, loss_s1: 0.032870, loss_fp: 0.004474, loss_freq: 0.029675
[17:05:58.603] iteration 28561: loss: 0.043519, loss_s1: 0.036595, loss_fp: 0.006289, loss_freq: 0.012524
[17:05:59.218] iteration 28562: loss: 0.048094, loss_s1: 0.030127, loss_fp: 0.003083, loss_freq: 0.022507
[17:05:59.841] iteration 28563: loss: 0.044313, loss_s1: 0.030098, loss_fp: 0.000702, loss_freq: 0.024663
[17:06:00.472] iteration 28564: loss: 0.077249, loss_s1: 0.070348, loss_fp: 0.010026, loss_freq: 0.034967
[17:06:01.092] iteration 28565: loss: 0.065571, loss_s1: 0.030590, loss_fp: 0.014417, loss_freq: 0.054341
[17:06:01.720] iteration 28566: loss: 0.073743, loss_s1: 0.048661, loss_fp: 0.006344, loss_freq: 0.045047
[17:06:02.338] iteration 28567: loss: 0.086676, loss_s1: 0.061477, loss_fp: 0.026967, loss_freq: 0.032097
[17:06:02.958] iteration 28568: loss: 0.041325, loss_s1: 0.024648, loss_fp: 0.004627, loss_freq: 0.013402
[17:06:03.575] iteration 28569: loss: 0.044562, loss_s1: 0.045410, loss_fp: 0.002847, loss_freq: 0.013748
[17:06:04.201] iteration 28570: loss: 0.038273, loss_s1: 0.011764, loss_fp: 0.000185, loss_freq: 0.011822
[17:06:04.816] iteration 28571: loss: 0.050370, loss_s1: 0.037113, loss_fp: 0.004852, loss_freq: 0.016970
[17:06:05.431] iteration 28572: loss: 0.041638, loss_s1: 0.026806, loss_fp: 0.001751, loss_freq: 0.012844
[17:06:06.057] iteration 28573: loss: 0.040643, loss_s1: 0.023317, loss_fp: 0.006336, loss_freq: 0.014293
[17:06:06.680] iteration 28574: loss: 0.048350, loss_s1: 0.020647, loss_fp: 0.010926, loss_freq: 0.020237
[17:06:07.323] iteration 28575: loss: 0.057898, loss_s1: 0.068622, loss_fp: 0.002566, loss_freq: 0.012770
[17:06:07.975] iteration 28576: loss: 0.031632, loss_s1: 0.026562, loss_fp: 0.002234, loss_freq: 0.007792
[17:06:08.611] iteration 28577: loss: 0.064151, loss_s1: 0.040820, loss_fp: 0.002124, loss_freq: 0.047967
[17:06:09.252] iteration 28578: loss: 0.060324, loss_s1: 0.026325, loss_fp: 0.000749, loss_freq: 0.045790
[17:06:09.883] iteration 28579: loss: 0.069303, loss_s1: 0.051300, loss_fp: 0.010079, loss_freq: 0.038600
[17:06:10.502] iteration 28580: loss: 0.038491, loss_s1: 0.036661, loss_fp: 0.001761, loss_freq: 0.003802
[17:06:11.130] iteration 28581: loss: 0.054854, loss_s1: 0.038886, loss_fp: 0.003520, loss_freq: 0.032836
[17:06:11.752] iteration 28582: loss: 0.081534, loss_s1: 0.095341, loss_fp: 0.002078, loss_freq: 0.038337
[17:06:12.378] iteration 28583: loss: 0.034517, loss_s1: 0.020011, loss_fp: 0.004256, loss_freq: 0.007207
[17:06:13.059] iteration 28584: loss: 0.049133, loss_s1: 0.038013, loss_fp: 0.002942, loss_freq: 0.029020
[17:06:13.698] iteration 28585: loss: 0.046033, loss_s1: 0.041187, loss_fp: 0.002918, loss_freq: 0.018069
[17:06:14.360] iteration 28586: loss: 0.039110, loss_s1: 0.036306, loss_fp: 0.002247, loss_freq: 0.010276
[17:06:15.001] iteration 28587: loss: 0.048067, loss_s1: 0.042729, loss_fp: 0.006729, loss_freq: 0.007794
[17:06:15.636] iteration 28588: loss: 0.051459, loss_s1: 0.029301, loss_fp: 0.009526, loss_freq: 0.012445
[17:06:16.268] iteration 28589: loss: 0.056545, loss_s1: 0.041606, loss_fp: 0.003780, loss_freq: 0.032815
[17:06:16.898] iteration 28590: loss: 0.064446, loss_s1: 0.066277, loss_fp: 0.008350, loss_freq: 0.019149
[17:06:17.516] iteration 28591: loss: 0.072574, loss_s1: 0.067701, loss_fp: 0.004749, loss_freq: 0.033465
[17:06:18.135] iteration 28592: loss: 0.074310, loss_s1: 0.063967, loss_fp: 0.004923, loss_freq: 0.023405
[17:06:18.771] iteration 28593: loss: 0.068405, loss_s1: 0.083218, loss_fp: 0.005230, loss_freq: 0.015690
[17:06:19.411] iteration 28594: loss: 0.047546, loss_s1: 0.032808, loss_fp: 0.004139, loss_freq: 0.023211
[17:06:20.100] iteration 28595: loss: 0.027383, loss_s1: 0.014814, loss_fp: 0.002416, loss_freq: 0.007706
[17:06:20.743] iteration 28596: loss: 0.063560, loss_s1: 0.043102, loss_fp: 0.001112, loss_freq: 0.041782
[17:06:21.379] iteration 28597: loss: 0.058961, loss_s1: 0.051707, loss_fp: 0.001878, loss_freq: 0.013112
[17:06:22.023] iteration 28598: loss: 0.070970, loss_s1: 0.074052, loss_fp: 0.002163, loss_freq: 0.032260
[17:06:22.669] iteration 28599: loss: 0.072638, loss_s1: 0.085341, loss_fp: 0.003047, loss_freq: 0.019667
[17:06:23.302] iteration 28600: loss: 0.026390, loss_s1: 0.012209, loss_fp: 0.001662, loss_freq: 0.009942
[17:06:26.993] iteration 28600 : mean_dice : 0.798222
[17:06:28.050] iteration 28601: loss: 0.047486, loss_s1: 0.033716, loss_fp: 0.000545, loss_freq: 0.004328
[17:06:28.705] iteration 28602: loss: 0.062011, loss_s1: 0.032357, loss_fp: 0.010430, loss_freq: 0.033067
[17:06:29.348] iteration 28603: loss: 0.038275, loss_s1: 0.016985, loss_fp: 0.002291, loss_freq: 0.019908
[17:06:29.982] iteration 28604: loss: 0.087548, loss_s1: 0.089915, loss_fp: 0.011593, loss_freq: 0.038346
[17:06:30.619] iteration 28605: loss: 0.061366, loss_s1: 0.067571, loss_fp: 0.002286, loss_freq: 0.028000
[17:06:31.247] iteration 28606: loss: 0.041783, loss_s1: 0.042856, loss_fp: 0.005309, loss_freq: 0.004211
[17:06:31.865] iteration 28607: loss: 0.030558, loss_s1: 0.016658, loss_fp: 0.000708, loss_freq: 0.010394
[17:06:32.481] iteration 28608: loss: 0.050353, loss_s1: 0.028108, loss_fp: 0.004252, loss_freq: 0.024784
[17:06:33.110] iteration 28609: loss: 0.094650, loss_s1: 0.081989, loss_fp: 0.025423, loss_freq: 0.041365
[17:06:33.751] iteration 28610: loss: 0.039258, loss_s1: 0.014835, loss_fp: 0.000866, loss_freq: 0.004414
[17:06:34.389] iteration 28611: loss: 0.043132, loss_s1: 0.026877, loss_fp: 0.005520, loss_freq: 0.018123
[17:06:35.042] iteration 28612: loss: 0.048954, loss_s1: 0.028816, loss_fp: 0.008400, loss_freq: 0.017231
[17:06:35.678] iteration 28613: loss: 0.048713, loss_s1: 0.031656, loss_fp: 0.000514, loss_freq: 0.021424
[17:06:36.303] iteration 28614: loss: 0.025594, loss_s1: 0.018785, loss_fp: 0.001596, loss_freq: 0.006185
[17:06:36.925] iteration 28615: loss: 0.052831, loss_s1: 0.042834, loss_fp: 0.000669, loss_freq: 0.025701
[17:06:37.542] iteration 28616: loss: 0.058359, loss_s1: 0.050121, loss_fp: 0.004602, loss_freq: 0.024032
[17:06:38.166] iteration 28617: loss: 0.057218, loss_s1: 0.012836, loss_fp: 0.004691, loss_freq: 0.019425
[17:06:38.779] iteration 28618: loss: 0.055517, loss_s1: 0.023906, loss_fp: 0.002075, loss_freq: 0.024971
[17:06:39.396] iteration 28619: loss: 0.059180, loss_s1: 0.048288, loss_fp: 0.007415, loss_freq: 0.027316
[17:06:40.020] iteration 28620: loss: 0.030648, loss_s1: 0.019807, loss_fp: 0.000988, loss_freq: 0.012998
[17:06:40.635] iteration 28621: loss: 0.092497, loss_s1: 0.047794, loss_fp: 0.003125, loss_freq: 0.090551
[17:06:41.257] iteration 28622: loss: 0.049118, loss_s1: 0.037345, loss_fp: 0.010089, loss_freq: 0.022238
[17:06:41.880] iteration 28623: loss: 0.042886, loss_s1: 0.025194, loss_fp: 0.006276, loss_freq: 0.010734
[17:06:42.504] iteration 28624: loss: 0.044257, loss_s1: 0.036359, loss_fp: 0.002697, loss_freq: 0.008480
[17:06:43.121] iteration 28625: loss: 0.049216, loss_s1: 0.049605, loss_fp: 0.001676, loss_freq: 0.007230
[17:06:43.761] iteration 28626: loss: 0.049087, loss_s1: 0.046624, loss_fp: 0.002000, loss_freq: 0.014267
[17:06:44.397] iteration 28627: loss: 0.057578, loss_s1: 0.027938, loss_fp: 0.004299, loss_freq: 0.041594
[17:06:45.030] iteration 28628: loss: 0.043621, loss_s1: 0.036177, loss_fp: 0.006389, loss_freq: 0.008813
[17:06:45.671] iteration 28629: loss: 0.039132, loss_s1: 0.014558, loss_fp: 0.004642, loss_freq: 0.014289
[17:06:46.343] iteration 28630: loss: 0.032853, loss_s1: 0.015371, loss_fp: 0.003094, loss_freq: 0.012266
[17:06:46.982] iteration 28631: loss: 0.044167, loss_s1: 0.036651, loss_fp: 0.001826, loss_freq: 0.012368
[17:06:47.615] iteration 28632: loss: 0.054444, loss_s1: 0.048513, loss_fp: 0.002771, loss_freq: 0.016104
[17:06:48.241] iteration 28633: loss: 0.088330, loss_s1: 0.087068, loss_fp: 0.005678, loss_freq: 0.050879
[17:06:48.876] iteration 28634: loss: 0.081377, loss_s1: 0.084359, loss_fp: 0.013217, loss_freq: 0.029807
[17:06:49.507] iteration 28635: loss: 0.046996, loss_s1: 0.021605, loss_fp: 0.003898, loss_freq: 0.026716
[17:06:50.131] iteration 28636: loss: 0.049269, loss_s1: 0.036878, loss_fp: 0.001060, loss_freq: 0.024208
[17:06:50.755] iteration 28637: loss: 0.043897, loss_s1: 0.035250, loss_fp: 0.001235, loss_freq: 0.016198
[17:06:51.372] iteration 28638: loss: 0.030109, loss_s1: 0.010579, loss_fp: 0.001389, loss_freq: 0.013104
[17:06:51.996] iteration 28639: loss: 0.049167, loss_s1: 0.037216, loss_fp: 0.003582, loss_freq: 0.020003
[17:06:52.617] iteration 28640: loss: 0.041460, loss_s1: 0.031009, loss_fp: 0.004374, loss_freq: 0.007560
[17:06:53.233] iteration 28641: loss: 0.057039, loss_s1: 0.051962, loss_fp: 0.007159, loss_freq: 0.013901
[17:06:53.855] iteration 28642: loss: 0.032915, loss_s1: 0.012413, loss_fp: 0.002454, loss_freq: 0.025712
[17:06:54.474] iteration 28643: loss: 0.039035, loss_s1: 0.019510, loss_fp: 0.002398, loss_freq: 0.019219
[17:06:55.091] iteration 28644: loss: 0.065350, loss_s1: 0.058779, loss_fp: 0.007380, loss_freq: 0.034286
[17:06:55.711] iteration 28645: loss: 0.052358, loss_s1: 0.039495, loss_fp: 0.002108, loss_freq: 0.008546
[17:06:56.329] iteration 28646: loss: 0.063413, loss_s1: 0.053952, loss_fp: 0.001710, loss_freq: 0.036404
[17:06:56.949] iteration 28647: loss: 0.037613, loss_s1: 0.015311, loss_fp: 0.001389, loss_freq: 0.016591
[17:06:57.573] iteration 28648: loss: 0.049592, loss_s1: 0.043171, loss_fp: 0.001345, loss_freq: 0.012271
[17:06:58.197] iteration 28649: loss: 0.045233, loss_s1: 0.028792, loss_fp: 0.002731, loss_freq: 0.023281
[17:06:58.820] iteration 28650: loss: 0.040589, loss_s1: 0.023700, loss_fp: 0.003581, loss_freq: 0.015853
[17:06:59.439] iteration 28651: loss: 0.040455, loss_s1: 0.037235, loss_fp: 0.001691, loss_freq: 0.008591
[17:07:00.067] iteration 28652: loss: 0.047309, loss_s1: 0.018516, loss_fp: 0.010108, loss_freq: 0.026036
[17:07:00.686] iteration 28653: loss: 0.032365, loss_s1: 0.016032, loss_fp: 0.001433, loss_freq: 0.015661
[17:07:01.306] iteration 28654: loss: 0.074716, loss_s1: 0.063480, loss_fp: 0.009426, loss_freq: 0.048204
[17:07:01.931] iteration 28655: loss: 0.026246, loss_s1: 0.003547, loss_fp: 0.002013, loss_freq: 0.013732
[17:07:02.552] iteration 28656: loss: 0.047171, loss_s1: 0.035308, loss_fp: 0.000492, loss_freq: 0.008682
[17:07:03.172] iteration 28657: loss: 0.043220, loss_s1: 0.033956, loss_fp: 0.004549, loss_freq: 0.008003
[17:07:03.801] iteration 28658: loss: 0.043606, loss_s1: 0.026668, loss_fp: 0.001357, loss_freq: 0.014551
[17:07:04.425] iteration 28659: loss: 0.047725, loss_s1: 0.027595, loss_fp: 0.003679, loss_freq: 0.034210
[17:07:05.044] iteration 28660: loss: 0.062747, loss_s1: 0.051692, loss_fp: 0.003402, loss_freq: 0.031850
[17:07:05.662] iteration 28661: loss: 0.035488, loss_s1: 0.015698, loss_fp: 0.004678, loss_freq: 0.008025
[17:07:06.284] iteration 28662: loss: 0.075324, loss_s1: 0.062665, loss_fp: 0.013177, loss_freq: 0.037975
[17:07:06.906] iteration 28663: loss: 0.070266, loss_s1: 0.076494, loss_fp: 0.007482, loss_freq: 0.023132
[17:07:07.529] iteration 28664: loss: 0.050041, loss_s1: 0.024457, loss_fp: 0.003041, loss_freq: 0.020723
[17:07:08.204] iteration 28665: loss: 0.088177, loss_s1: 0.097108, loss_fp: 0.011627, loss_freq: 0.027622
[17:07:08.826] iteration 28666: loss: 0.040243, loss_s1: 0.032089, loss_fp: 0.001223, loss_freq: 0.012910
[17:07:09.452] iteration 28667: loss: 0.104802, loss_s1: 0.039769, loss_fp: 0.007445, loss_freq: 0.106897
[17:07:10.072] iteration 28668: loss: 0.070584, loss_s1: 0.073058, loss_fp: 0.001705, loss_freq: 0.034777
[17:07:10.693] iteration 28669: loss: 0.031917, loss_s1: 0.015100, loss_fp: 0.001351, loss_freq: 0.013145
[17:07:11.316] iteration 28670: loss: 0.032870, loss_s1: 0.020356, loss_fp: 0.001592, loss_freq: 0.007717
[17:07:11.934] iteration 28671: loss: 0.052414, loss_s1: 0.041322, loss_fp: 0.003408, loss_freq: 0.015164
[17:07:12.557] iteration 28672: loss: 0.077429, loss_s1: 0.048410, loss_fp: 0.006273, loss_freq: 0.053368
[17:07:13.176] iteration 28673: loss: 0.077297, loss_s1: 0.039731, loss_fp: 0.004861, loss_freq: 0.072730
[17:07:13.808] iteration 28674: loss: 0.062772, loss_s1: 0.033730, loss_fp: 0.009026, loss_freq: 0.032566
[17:07:14.439] iteration 28675: loss: 0.074368, loss_s1: 0.080834, loss_fp: 0.003631, loss_freq: 0.037054
[17:07:15.064] iteration 28676: loss: 0.039828, loss_s1: 0.015561, loss_fp: 0.004613, loss_freq: 0.026011
[17:07:15.684] iteration 28677: loss: 0.045353, loss_s1: 0.025284, loss_fp: 0.004560, loss_freq: 0.036064
[17:07:16.304] iteration 28678: loss: 0.041185, loss_s1: 0.017912, loss_fp: 0.000621, loss_freq: 0.026492
[17:07:16.927] iteration 28679: loss: 0.081504, loss_s1: 0.038738, loss_fp: 0.015930, loss_freq: 0.064497
[17:07:17.550] iteration 28680: loss: 0.066466, loss_s1: 0.038459, loss_fp: 0.003187, loss_freq: 0.028378
[17:07:18.175] iteration 28681: loss: 0.072214, loss_s1: 0.086961, loss_fp: 0.001682, loss_freq: 0.015166
[17:07:18.803] iteration 28682: loss: 0.049595, loss_s1: 0.056275, loss_fp: 0.002013, loss_freq: 0.007444
[17:07:19.419] iteration 28683: loss: 0.037232, loss_s1: 0.019835, loss_fp: 0.001179, loss_freq: 0.018066
[17:07:20.047] iteration 28684: loss: 0.033621, loss_s1: 0.026856, loss_fp: 0.004245, loss_freq: 0.008775
[17:07:20.678] iteration 28685: loss: 0.059719, loss_s1: 0.053742, loss_fp: 0.007103, loss_freq: 0.017733
[17:07:21.320] iteration 28686: loss: 0.070206, loss_s1: 0.034470, loss_fp: 0.016361, loss_freq: 0.054531
[17:07:21.937] iteration 28687: loss: 0.045395, loss_s1: 0.026937, loss_fp: 0.003535, loss_freq: 0.024991
[17:07:22.552] iteration 28688: loss: 0.028322, loss_s1: 0.007355, loss_fp: 0.000474, loss_freq: 0.013208
[17:07:23.171] iteration 28689: loss: 0.030438, loss_s1: 0.015066, loss_fp: 0.002216, loss_freq: 0.014344
[17:07:23.794] iteration 28690: loss: 0.043997, loss_s1: 0.044388, loss_fp: 0.001655, loss_freq: 0.016569
[17:07:24.412] iteration 28691: loss: 0.050567, loss_s1: 0.028934, loss_fp: 0.005136, loss_freq: 0.031230
[17:07:25.038] iteration 28692: loss: 0.059722, loss_s1: 0.044582, loss_fp: 0.003942, loss_freq: 0.031989
[17:07:25.664] iteration 28693: loss: 0.054879, loss_s1: 0.052788, loss_fp: 0.004588, loss_freq: 0.012834
[17:07:26.282] iteration 28694: loss: 0.043910, loss_s1: 0.028178, loss_fp: 0.001294, loss_freq: 0.013274
[17:07:26.904] iteration 28695: loss: 0.038841, loss_s1: 0.026655, loss_fp: 0.001458, loss_freq: 0.013484
[17:07:27.516] iteration 28696: loss: 0.028302, loss_s1: 0.014465, loss_fp: 0.003522, loss_freq: 0.006595
[17:07:28.141] iteration 28697: loss: 0.053933, loss_s1: 0.015999, loss_fp: 0.008128, loss_freq: 0.042525
[17:07:28.769] iteration 28698: loss: 0.044151, loss_s1: 0.040922, loss_fp: 0.000984, loss_freq: 0.009423
[17:07:29.391] iteration 28699: loss: 0.072772, loss_s1: 0.022284, loss_fp: 0.009825, loss_freq: 0.026985
[17:07:30.015] iteration 28700: loss: 0.069431, loss_s1: 0.037572, loss_fp: 0.012323, loss_freq: 0.046728
[17:07:30.638] iteration 28701: loss: 0.037168, loss_s1: 0.025642, loss_fp: 0.001206, loss_freq: 0.005760
[17:07:31.264] iteration 28702: loss: 0.057965, loss_s1: 0.036867, loss_fp: 0.008673, loss_freq: 0.030567
[17:07:31.883] iteration 28703: loss: 0.076715, loss_s1: 0.064053, loss_fp: 0.012310, loss_freq: 0.051090
[17:07:32.514] iteration 28704: loss: 0.056862, loss_s1: 0.049771, loss_fp: 0.001902, loss_freq: 0.027378
[17:07:33.147] iteration 28705: loss: 0.059340, loss_s1: 0.017817, loss_fp: 0.003237, loss_freq: 0.016068
[17:07:33.773] iteration 28706: loss: 0.045023, loss_s1: 0.021614, loss_fp: 0.004889, loss_freq: 0.028617
[17:07:34.408] iteration 28707: loss: 0.088806, loss_s1: 0.079951, loss_fp: 0.005980, loss_freq: 0.052367
[17:07:35.044] iteration 28708: loss: 0.054411, loss_s1: 0.063340, loss_fp: 0.002068, loss_freq: 0.016074
[17:07:35.672] iteration 28709: loss: 0.053380, loss_s1: 0.036996, loss_fp: 0.004942, loss_freq: 0.027625
[17:07:36.311] iteration 28710: loss: 0.053133, loss_s1: 0.034957, loss_fp: 0.004561, loss_freq: 0.036944
[17:07:36.957] iteration 28711: loss: 0.050579, loss_s1: 0.047215, loss_fp: 0.001756, loss_freq: 0.016251
[17:07:37.605] iteration 28712: loss: 0.045063, loss_s1: 0.038143, loss_fp: 0.002577, loss_freq: 0.013099
[17:07:38.246] iteration 28713: loss: 0.040720, loss_s1: 0.031908, loss_fp: 0.001897, loss_freq: 0.006953
[17:07:38.872] iteration 28714: loss: 0.037344, loss_s1: 0.018373, loss_fp: 0.002226, loss_freq: 0.019879
[17:07:39.501] iteration 28715: loss: 0.037883, loss_s1: 0.014854, loss_fp: 0.001299, loss_freq: 0.011058
[17:07:40.129] iteration 28716: loss: 0.045490, loss_s1: 0.028853, loss_fp: 0.001325, loss_freq: 0.021975
[17:07:40.753] iteration 28717: loss: 0.041827, loss_s1: 0.020534, loss_fp: 0.007909, loss_freq: 0.011262
[17:07:41.374] iteration 28718: loss: 0.049852, loss_s1: 0.027622, loss_fp: 0.007819, loss_freq: 0.023537
[17:07:41.993] iteration 28719: loss: 0.065111, loss_s1: 0.082046, loss_fp: 0.006718, loss_freq: 0.008402
[17:07:42.620] iteration 28720: loss: 0.039833, loss_s1: 0.018979, loss_fp: 0.002755, loss_freq: 0.023165
[17:07:43.242] iteration 28721: loss: 0.050053, loss_s1: 0.053306, loss_fp: 0.005580, loss_freq: 0.009250
[17:07:43.866] iteration 28722: loss: 0.054857, loss_s1: 0.059186, loss_fp: 0.000740, loss_freq: 0.011012
[17:07:44.495] iteration 28723: loss: 0.030237, loss_s1: 0.012732, loss_fp: 0.000946, loss_freq: 0.006261
[17:07:45.229] iteration 28724: loss: 0.063353, loss_s1: 0.052122, loss_fp: 0.004679, loss_freq: 0.046381
[17:07:45.966] iteration 28725: loss: 0.055331, loss_s1: 0.059612, loss_fp: 0.005751, loss_freq: 0.015077
[17:07:46.626] iteration 28726: loss: 0.054240, loss_s1: 0.037060, loss_fp: 0.011712, loss_freq: 0.015219
[17:07:47.256] iteration 28727: loss: 0.036115, loss_s1: 0.017856, loss_fp: 0.001346, loss_freq: 0.025872
[17:07:47.892] iteration 28728: loss: 0.060627, loss_s1: 0.049127, loss_fp: 0.003043, loss_freq: 0.041969
[17:07:48.529] iteration 28729: loss: 0.044362, loss_s1: 0.036406, loss_fp: 0.005408, loss_freq: 0.007389
[17:07:49.165] iteration 28730: loss: 0.058241, loss_s1: 0.045067, loss_fp: 0.003705, loss_freq: 0.031259
[17:07:49.800] iteration 28731: loss: 0.061692, loss_s1: 0.042418, loss_fp: 0.001441, loss_freq: 0.035361
[17:07:50.425] iteration 28732: loss: 0.062970, loss_s1: 0.049747, loss_fp: 0.006819, loss_freq: 0.032569
[17:07:51.037] iteration 28733: loss: 0.037797, loss_s1: 0.027448, loss_fp: 0.007896, loss_freq: 0.009340
[17:07:51.658] iteration 28734: loss: 0.042559, loss_s1: 0.013310, loss_fp: 0.000704, loss_freq: 0.030631
[17:07:52.283] iteration 28735: loss: 0.064034, loss_s1: 0.052166, loss_fp: 0.012757, loss_freq: 0.016661
[17:07:52.911] iteration 28736: loss: 0.065930, loss_s1: 0.069673, loss_fp: 0.007094, loss_freq: 0.019346
[17:07:53.530] iteration 28737: loss: 0.073698, loss_s1: 0.066408, loss_fp: 0.006792, loss_freq: 0.033901
[17:07:54.161] iteration 28738: loss: 0.028209, loss_s1: 0.013418, loss_fp: 0.000627, loss_freq: 0.007352
[17:07:54.783] iteration 28739: loss: 0.062068, loss_s1: 0.064423, loss_fp: 0.001871, loss_freq: 0.025293
[17:07:55.400] iteration 28740: loss: 0.047486, loss_s1: 0.028217, loss_fp: 0.006228, loss_freq: 0.016226
[17:07:56.015] iteration 28741: loss: 0.054968, loss_s1: 0.029405, loss_fp: 0.003775, loss_freq: 0.013030
[17:07:56.631] iteration 28742: loss: 0.094620, loss_s1: 0.063366, loss_fp: 0.014764, loss_freq: 0.061119
[17:07:57.259] iteration 28743: loss: 0.053785, loss_s1: 0.055734, loss_fp: 0.002199, loss_freq: 0.018776
[17:07:58.190] iteration 28744: loss: 0.046579, loss_s1: 0.028023, loss_fp: 0.000784, loss_freq: 0.013182
[17:07:58.839] iteration 28745: loss: 0.057966, loss_s1: 0.057105, loss_fp: 0.001875, loss_freq: 0.019153
[17:07:59.486] iteration 28746: loss: 0.029279, loss_s1: 0.015053, loss_fp: 0.000817, loss_freq: 0.014046
[17:08:00.139] iteration 28747: loss: 0.045827, loss_s1: 0.009743, loss_fp: 0.001891, loss_freq: 0.029202
[17:08:00.772] iteration 28748: loss: 0.034269, loss_s1: 0.028237, loss_fp: 0.001166, loss_freq: 0.014048
[17:08:01.397] iteration 28749: loss: 0.030774, loss_s1: 0.005963, loss_fp: 0.009864, loss_freq: 0.007142
[17:08:02.066] iteration 28750: loss: 0.032731, loss_s1: 0.014962, loss_fp: 0.009407, loss_freq: 0.015370
[17:08:02.720] iteration 28751: loss: 0.041692, loss_s1: 0.021898, loss_fp: 0.002418, loss_freq: 0.009374
[17:08:03.364] iteration 28752: loss: 0.044736, loss_s1: 0.026975, loss_fp: 0.003710, loss_freq: 0.016850
[17:08:04.032] iteration 28753: loss: 0.044149, loss_s1: 0.012265, loss_fp: 0.000612, loss_freq: 0.003248
[17:08:04.682] iteration 28754: loss: 0.055443, loss_s1: 0.056161, loss_fp: 0.005696, loss_freq: 0.016625
[17:08:05.327] iteration 28755: loss: 0.053191, loss_s1: 0.041230, loss_fp: 0.001774, loss_freq: 0.024931
[17:08:05.954] iteration 28756: loss: 0.042937, loss_s1: 0.029236, loss_fp: 0.003890, loss_freq: 0.010512
[17:08:06.580] iteration 28757: loss: 0.020943, loss_s1: 0.003352, loss_fp: 0.000298, loss_freq: 0.010785
[17:08:07.202] iteration 28758: loss: 0.055742, loss_s1: 0.031592, loss_fp: 0.003217, loss_freq: 0.041865
[17:08:07.842] iteration 28759: loss: 0.047859, loss_s1: 0.012843, loss_fp: 0.019568, loss_freq: 0.029155
[17:08:08.482] iteration 28760: loss: 0.043071, loss_s1: 0.025400, loss_fp: 0.001998, loss_freq: 0.024114
[17:08:09.124] iteration 28761: loss: 0.039572, loss_s1: 0.023327, loss_fp: 0.006332, loss_freq: 0.018299
[17:08:09.763] iteration 28762: loss: 0.045424, loss_s1: 0.040415, loss_fp: 0.001698, loss_freq: 0.016052
[17:08:10.388] iteration 28763: loss: 0.041343, loss_s1: 0.033727, loss_fp: 0.005525, loss_freq: 0.014154
[17:08:11.006] iteration 28764: loss: 0.055768, loss_s1: 0.037694, loss_fp: 0.002105, loss_freq: 0.029566
[17:08:11.625] iteration 28765: loss: 0.035472, loss_s1: 0.022247, loss_fp: 0.002108, loss_freq: 0.020624
[17:08:12.249] iteration 28766: loss: 0.033596, loss_s1: 0.021820, loss_fp: 0.003013, loss_freq: 0.013605
[17:08:12.868] iteration 28767: loss: 0.037198, loss_s1: 0.017800, loss_fp: 0.002461, loss_freq: 0.005119
[17:08:13.493] iteration 28768: loss: 0.036342, loss_s1: 0.026458, loss_fp: 0.004954, loss_freq: 0.005349
[17:08:14.112] iteration 28769: loss: 0.087780, loss_s1: 0.095395, loss_fp: 0.001966, loss_freq: 0.018625
[17:08:14.732] iteration 28770: loss: 0.061816, loss_s1: 0.039294, loss_fp: 0.005266, loss_freq: 0.044614
[17:08:15.353] iteration 28771: loss: 0.044247, loss_s1: 0.041354, loss_fp: 0.001612, loss_freq: 0.010815
[17:08:15.979] iteration 28772: loss: 0.055211, loss_s1: 0.021137, loss_fp: 0.004429, loss_freq: 0.037216
[17:08:16.600] iteration 28773: loss: 0.038147, loss_s1: 0.017105, loss_fp: 0.003522, loss_freq: 0.009609
[17:08:17.219] iteration 28774: loss: 0.050398, loss_s1: 0.059675, loss_fp: 0.002954, loss_freq: 0.008618
[17:08:17.841] iteration 28775: loss: 0.039733, loss_s1: 0.015299, loss_fp: 0.001199, loss_freq: 0.012584
[17:08:18.462] iteration 28776: loss: 0.057094, loss_s1: 0.027783, loss_fp: 0.004709, loss_freq: 0.053318
[17:08:19.084] iteration 28777: loss: 0.072504, loss_s1: 0.048876, loss_fp: 0.005709, loss_freq: 0.053902
[17:08:19.703] iteration 28778: loss: 0.050669, loss_s1: 0.020631, loss_fp: 0.004975, loss_freq: 0.025788
[17:08:20.321] iteration 28779: loss: 0.058043, loss_s1: 0.056662, loss_fp: 0.005213, loss_freq: 0.022494
[17:08:20.941] iteration 28780: loss: 0.041294, loss_s1: 0.025292, loss_fp: 0.005041, loss_freq: 0.010932
[17:08:21.565] iteration 28781: loss: 0.048237, loss_s1: 0.029731, loss_fp: 0.002948, loss_freq: 0.018176
[17:08:22.183] iteration 28782: loss: 0.056751, loss_s1: 0.040205, loss_fp: 0.014586, loss_freq: 0.015016
[17:08:22.800] iteration 28783: loss: 0.045355, loss_s1: 0.041235, loss_fp: 0.007438, loss_freq: 0.016074
[17:08:23.415] iteration 28784: loss: 0.098190, loss_s1: 0.067122, loss_fp: 0.002542, loss_freq: 0.007986
[17:08:24.034] iteration 28785: loss: 0.048406, loss_s1: 0.043413, loss_fp: 0.001314, loss_freq: 0.026571
[17:08:24.656] iteration 28786: loss: 0.038328, loss_s1: 0.029406, loss_fp: 0.001184, loss_freq: 0.004936
[17:08:25.276] iteration 28787: loss: 0.046370, loss_s1: 0.035844, loss_fp: 0.004364, loss_freq: 0.023998
[17:08:25.896] iteration 28788: loss: 0.048908, loss_s1: 0.036500, loss_fp: 0.001579, loss_freq: 0.015916
[17:08:26.521] iteration 28789: loss: 0.048238, loss_s1: 0.049063, loss_fp: 0.001138, loss_freq: 0.018083
[17:08:27.139] iteration 28790: loss: 0.046965, loss_s1: 0.038779, loss_fp: 0.003827, loss_freq: 0.020105
[17:08:27.759] iteration 28791: loss: 0.080022, loss_s1: 0.090156, loss_fp: 0.001905, loss_freq: 0.031343
[17:08:28.393] iteration 28792: loss: 0.073429, loss_s1: 0.083244, loss_fp: 0.006379, loss_freq: 0.029800
[17:08:29.012] iteration 28793: loss: 0.035611, loss_s1: 0.018073, loss_fp: 0.004062, loss_freq: 0.012310
[17:08:29.624] iteration 28794: loss: 0.045728, loss_s1: 0.020067, loss_fp: 0.004848, loss_freq: 0.033892
[17:08:30.247] iteration 28795: loss: 0.040548, loss_s1: 0.021162, loss_fp: 0.001076, loss_freq: 0.021862
[17:08:30.875] iteration 28796: loss: 0.049248, loss_s1: 0.054349, loss_fp: 0.003361, loss_freq: 0.010651
[17:08:31.500] iteration 28797: loss: 0.055550, loss_s1: 0.031421, loss_fp: 0.009284, loss_freq: 0.045330
[17:08:32.142] iteration 28798: loss: 0.037709, loss_s1: 0.024691, loss_fp: 0.002690, loss_freq: 0.013243
[17:08:32.778] iteration 28799: loss: 0.044338, loss_s1: 0.023014, loss_fp: 0.001641, loss_freq: 0.022600
[17:08:33.414] iteration 28800: loss: 0.040301, loss_s1: 0.025799, loss_fp: 0.006398, loss_freq: 0.018713
[17:08:36.654] iteration 28800 : mean_dice : 0.798421
[17:08:37.323] iteration 28801: loss: 0.045228, loss_s1: 0.031953, loss_fp: 0.004984, loss_freq: 0.022095
[17:08:37.968] iteration 28802: loss: 0.093724, loss_s1: 0.082028, loss_fp: 0.001553, loss_freq: 0.051639
[17:08:38.613] iteration 28803: loss: 0.070689, loss_s1: 0.046817, loss_fp: 0.004624, loss_freq: 0.046133
[17:08:39.257] iteration 28804: loss: 0.045059, loss_s1: 0.027353, loss_fp: 0.002847, loss_freq: 0.014981
[17:08:39.878] iteration 28805: loss: 0.047191, loss_s1: 0.039455, loss_fp: 0.003958, loss_freq: 0.009871
[17:08:40.495] iteration 28806: loss: 0.080041, loss_s1: 0.065001, loss_fp: 0.004262, loss_freq: 0.048037
[17:08:41.124] iteration 28807: loss: 0.042610, loss_s1: 0.013877, loss_fp: 0.002877, loss_freq: 0.016135
[17:08:41.750] iteration 28808: loss: 0.071074, loss_s1: 0.055816, loss_fp: 0.002592, loss_freq: 0.022637
[17:08:42.366] iteration 28809: loss: 0.040400, loss_s1: 0.032394, loss_fp: 0.002313, loss_freq: 0.016176
[17:08:42.990] iteration 28810: loss: 0.137487, loss_s1: 0.093928, loss_fp: 0.038948, loss_freq: 0.093734
[17:08:43.612] iteration 28811: loss: 0.050384, loss_s1: 0.042299, loss_fp: 0.007034, loss_freq: 0.017282
[17:08:44.228] iteration 28812: loss: 0.035587, loss_s1: 0.020236, loss_fp: 0.003129, loss_freq: 0.008780
[17:08:44.859] iteration 28813: loss: 0.038165, loss_s1: 0.025530, loss_fp: 0.001635, loss_freq: 0.009757
[17:08:45.495] iteration 28814: loss: 0.064691, loss_s1: 0.080381, loss_fp: 0.003184, loss_freq: 0.012368
[17:08:46.130] iteration 28815: loss: 0.050862, loss_s1: 0.022798, loss_fp: 0.002814, loss_freq: 0.030329
[17:08:46.771] iteration 28816: loss: 0.031656, loss_s1: 0.015690, loss_fp: 0.010741, loss_freq: 0.007718
[17:08:47.408] iteration 28817: loss: 0.088858, loss_s1: 0.056454, loss_fp: 0.005190, loss_freq: 0.069473
[17:08:48.027] iteration 28818: loss: 0.069444, loss_s1: 0.050425, loss_fp: 0.010472, loss_freq: 0.051035
[17:08:48.644] iteration 28819: loss: 0.054321, loss_s1: 0.050813, loss_fp: 0.004758, loss_freq: 0.011712
[17:08:49.268] iteration 28820: loss: 0.045232, loss_s1: 0.040906, loss_fp: 0.004850, loss_freq: 0.011773
[17:08:49.884] iteration 28821: loss: 0.058668, loss_s1: 0.059982, loss_fp: 0.002424, loss_freq: 0.013736
[17:08:50.506] iteration 28822: loss: 0.058746, loss_s1: 0.047208, loss_fp: 0.010742, loss_freq: 0.024648
[17:08:51.127] iteration 28823: loss: 0.101699, loss_s1: 0.082824, loss_fp: 0.002633, loss_freq: 0.048810
[17:08:51.743] iteration 28824: loss: 0.053458, loss_s1: 0.034274, loss_fp: 0.011910, loss_freq: 0.018988
[17:08:52.359] iteration 28825: loss: 0.056726, loss_s1: 0.029470, loss_fp: 0.006840, loss_freq: 0.025766
[17:08:52.987] iteration 28826: loss: 0.050907, loss_s1: 0.036728, loss_fp: 0.003633, loss_freq: 0.011005
[17:08:53.605] iteration 28827: loss: 0.039811, loss_s1: 0.029728, loss_fp: 0.004731, loss_freq: 0.020117
[17:08:54.225] iteration 28828: loss: 0.064945, loss_s1: 0.048110, loss_fp: 0.020680, loss_freq: 0.022847
[17:08:54.863] iteration 28829: loss: 0.065918, loss_s1: 0.036100, loss_fp: 0.004097, loss_freq: 0.053280
[17:08:55.504] iteration 28830: loss: 0.036549, loss_s1: 0.030482, loss_fp: 0.004517, loss_freq: 0.005656
[17:08:56.140] iteration 28831: loss: 0.045431, loss_s1: 0.041232, loss_fp: 0.000964, loss_freq: 0.019535
[17:08:56.777] iteration 28832: loss: 0.041240, loss_s1: 0.042396, loss_fp: 0.002334, loss_freq: 0.005852
[17:08:57.414] iteration 28833: loss: 0.049236, loss_s1: 0.057901, loss_fp: 0.001049, loss_freq: 0.014973
[17:08:58.055] iteration 28834: loss: 0.040331, loss_s1: 0.023809, loss_fp: 0.000964, loss_freq: 0.019335
[17:08:58.696] iteration 28835: loss: 0.043325, loss_s1: 0.025054, loss_fp: 0.005162, loss_freq: 0.028686
[17:08:59.336] iteration 28836: loss: 0.049748, loss_s1: 0.026319, loss_fp: 0.010526, loss_freq: 0.021865
[17:08:59.975] iteration 28837: loss: 0.050499, loss_s1: 0.064169, loss_fp: 0.001203, loss_freq: 0.006493
[17:09:00.614] iteration 28838: loss: 0.032126, loss_s1: 0.018126, loss_fp: 0.002470, loss_freq: 0.010070
[17:09:01.255] iteration 28839: loss: 0.032373, loss_s1: 0.019107, loss_fp: 0.003375, loss_freq: 0.005147
[17:09:01.891] iteration 28840: loss: 0.100548, loss_s1: 0.086165, loss_fp: 0.004610, loss_freq: 0.077655
[17:09:02.528] iteration 28841: loss: 0.040360, loss_s1: 0.027186, loss_fp: 0.001172, loss_freq: 0.013698
[17:09:03.164] iteration 28842: loss: 0.057329, loss_s1: 0.062657, loss_fp: 0.000972, loss_freq: 0.012843
[17:09:03.799] iteration 28843: loss: 0.054320, loss_s1: 0.048652, loss_fp: 0.002178, loss_freq: 0.015754
[17:09:04.441] iteration 28844: loss: 0.027525, loss_s1: 0.012921, loss_fp: 0.001352, loss_freq: 0.006259
[17:09:05.072] iteration 28845: loss: 0.065304, loss_s1: 0.031682, loss_fp: 0.009930, loss_freq: 0.051154
[17:09:05.705] iteration 28846: loss: 0.097750, loss_s1: 0.066084, loss_fp: 0.012521, loss_freq: 0.083578
[17:09:06.340] iteration 28847: loss: 0.029299, loss_s1: 0.011666, loss_fp: 0.002585, loss_freq: 0.010067
[17:09:06.974] iteration 28848: loss: 0.049171, loss_s1: 0.036545, loss_fp: 0.003799, loss_freq: 0.004947
[17:09:07.601] iteration 28849: loss: 0.039003, loss_s1: 0.009589, loss_fp: 0.002923, loss_freq: 0.017543
[17:09:08.234] iteration 28850: loss: 0.052216, loss_s1: 0.024734, loss_fp: 0.002086, loss_freq: 0.038907
[17:09:08.866] iteration 28851: loss: 0.069013, loss_s1: 0.056289, loss_fp: 0.010652, loss_freq: 0.041249
[17:09:09.500] iteration 28852: loss: 0.064632, loss_s1: 0.044933, loss_fp: 0.003109, loss_freq: 0.038390
[17:09:10.137] iteration 28853: loss: 0.046534, loss_s1: 0.043632, loss_fp: 0.002741, loss_freq: 0.021551
[17:09:10.775] iteration 28854: loss: 0.048468, loss_s1: 0.030535, loss_fp: 0.004178, loss_freq: 0.015124
[17:09:11.408] iteration 28855: loss: 0.030095, loss_s1: 0.011492, loss_fp: 0.001421, loss_freq: 0.021407
[17:09:12.051] iteration 28856: loss: 0.052721, loss_s1: 0.051108, loss_fp: 0.005475, loss_freq: 0.009088
[17:09:12.706] iteration 28857: loss: 0.087606, loss_s1: 0.073261, loss_fp: 0.005777, loss_freq: 0.058338
[17:09:13.373] iteration 28858: loss: 0.044329, loss_s1: 0.009879, loss_fp: 0.010116, loss_freq: 0.014274
[17:09:14.013] iteration 28859: loss: 0.037876, loss_s1: 0.017074, loss_fp: 0.000998, loss_freq: 0.022611
[17:09:14.666] iteration 28860: loss: 0.077603, loss_s1: 0.077057, loss_fp: 0.012003, loss_freq: 0.026212
[17:09:15.312] iteration 28861: loss: 0.056455, loss_s1: 0.059461, loss_fp: 0.004502, loss_freq: 0.020594
[17:09:15.954] iteration 28862: loss: 0.043092, loss_s1: 0.045342, loss_fp: 0.000859, loss_freq: 0.014096
[17:09:16.576] iteration 28863: loss: 0.047169, loss_s1: 0.026446, loss_fp: 0.000647, loss_freq: 0.030990
[17:09:17.193] iteration 28864: loss: 0.073365, loss_s1: 0.038096, loss_fp: 0.003481, loss_freq: 0.070053
[17:09:17.811] iteration 28865: loss: 0.066254, loss_s1: 0.043660, loss_fp: 0.003650, loss_freq: 0.022037
[17:09:18.432] iteration 28866: loss: 0.025526, loss_s1: 0.011922, loss_fp: 0.001881, loss_freq: 0.006529
[17:09:19.053] iteration 28867: loss: 0.053302, loss_s1: 0.036117, loss_fp: 0.002156, loss_freq: 0.042730
[17:09:19.673] iteration 28868: loss: 0.055459, loss_s1: 0.053199, loss_fp: 0.002098, loss_freq: 0.017520
[17:09:20.293] iteration 28869: loss: 0.053973, loss_s1: 0.029016, loss_fp: 0.004884, loss_freq: 0.007961
[17:09:20.927] iteration 28870: loss: 0.040994, loss_s1: 0.038389, loss_fp: 0.000644, loss_freq: 0.016178
[17:09:21.549] iteration 28871: loss: 0.042408, loss_s1: 0.027456, loss_fp: 0.000933, loss_freq: 0.024258
[17:09:22.164] iteration 28872: loss: 0.075656, loss_s1: 0.086755, loss_fp: 0.003447, loss_freq: 0.010713
[17:09:22.783] iteration 28873: loss: 0.052510, loss_s1: 0.046911, loss_fp: 0.006970, loss_freq: 0.016800
[17:09:23.399] iteration 28874: loss: 0.046793, loss_s1: 0.019848, loss_fp: 0.000859, loss_freq: 0.033137
[17:09:24.018] iteration 28875: loss: 0.095084, loss_s1: 0.093506, loss_fp: 0.004661, loss_freq: 0.060039
[17:09:24.639] iteration 28876: loss: 0.044781, loss_s1: 0.018402, loss_fp: 0.010081, loss_freq: 0.018871
[17:09:25.250] iteration 28877: loss: 0.067429, loss_s1: 0.037110, loss_fp: 0.005330, loss_freq: 0.055919
[17:09:25.874] iteration 28878: loss: 0.044724, loss_s1: 0.025337, loss_fp: 0.006858, loss_freq: 0.014052
[17:09:26.496] iteration 28879: loss: 0.068725, loss_s1: 0.062762, loss_fp: 0.007503, loss_freq: 0.029822
[17:09:27.113] iteration 28880: loss: 0.062710, loss_s1: 0.046384, loss_fp: 0.006833, loss_freq: 0.022851
[17:09:27.734] iteration 28881: loss: 0.030035, loss_s1: 0.013386, loss_fp: 0.001594, loss_freq: 0.010239
[17:09:28.354] iteration 28882: loss: 0.053136, loss_s1: 0.050497, loss_fp: 0.006062, loss_freq: 0.016620
[17:09:28.978] iteration 28883: loss: 0.048450, loss_s1: 0.023960, loss_fp: 0.004441, loss_freq: 0.007761
[17:09:29.600] iteration 28884: loss: 0.065067, loss_s1: 0.041002, loss_fp: 0.003438, loss_freq: 0.048795
[17:09:30.210] iteration 28885: loss: 0.088984, loss_s1: 0.083958, loss_fp: 0.026485, loss_freq: 0.026069
[17:09:30.825] iteration 28886: loss: 0.038326, loss_s1: 0.009348, loss_fp: 0.007201, loss_freq: 0.029500
[17:09:31.768] iteration 28887: loss: 0.045142, loss_s1: 0.036537, loss_fp: 0.001091, loss_freq: 0.015675
[17:09:32.388] iteration 28888: loss: 0.074322, loss_s1: 0.079462, loss_fp: 0.001289, loss_freq: 0.024842
[17:09:33.011] iteration 28889: loss: 0.038420, loss_s1: 0.022558, loss_fp: 0.003413, loss_freq: 0.020323
[17:09:33.635] iteration 28890: loss: 0.073412, loss_s1: 0.040857, loss_fp: 0.012174, loss_freq: 0.045216
[17:09:34.256] iteration 28891: loss: 0.061532, loss_s1: 0.048928, loss_fp: 0.001281, loss_freq: 0.037466
[17:09:34.871] iteration 28892: loss: 0.040334, loss_s1: 0.013959, loss_fp: 0.004720, loss_freq: 0.016357
[17:09:35.491] iteration 28893: loss: 0.028097, loss_s1: 0.017831, loss_fp: 0.004100, loss_freq: 0.008405
[17:09:36.119] iteration 28894: loss: 0.033822, loss_s1: 0.013687, loss_fp: 0.003647, loss_freq: 0.012749
[17:09:36.743] iteration 28895: loss: 0.078732, loss_s1: 0.079239, loss_fp: 0.006420, loss_freq: 0.033438
[17:09:37.369] iteration 28896: loss: 0.037469, loss_s1: 0.009629, loss_fp: 0.004661, loss_freq: 0.008081
[17:09:37.994] iteration 28897: loss: 0.057799, loss_s1: 0.040474, loss_fp: 0.006385, loss_freq: 0.032991
[17:09:38.619] iteration 28898: loss: 0.043073, loss_s1: 0.031855, loss_fp: 0.002390, loss_freq: 0.017023
[17:09:39.240] iteration 28899: loss: 0.047911, loss_s1: 0.036984, loss_fp: 0.004570, loss_freq: 0.015121
[17:09:39.850] iteration 28900: loss: 0.033197, loss_s1: 0.015351, loss_fp: 0.001314, loss_freq: 0.024634
[17:09:40.474] iteration 28901: loss: 0.046253, loss_s1: 0.039079, loss_fp: 0.002304, loss_freq: 0.011372
[17:09:41.111] iteration 28902: loss: 0.052065, loss_s1: 0.034263, loss_fp: 0.004454, loss_freq: 0.033653
[17:09:41.784] iteration 28903: loss: 0.065089, loss_s1: 0.051633, loss_fp: 0.009642, loss_freq: 0.031115
[17:09:42.419] iteration 28904: loss: 0.034166, loss_s1: 0.025913, loss_fp: 0.004736, loss_freq: 0.008487
[17:09:43.056] iteration 28905: loss: 0.028927, loss_s1: 0.010694, loss_fp: 0.000673, loss_freq: 0.016036
[17:09:43.686] iteration 28906: loss: 0.032864, loss_s1: 0.024635, loss_fp: 0.002458, loss_freq: 0.008315
[17:09:44.304] iteration 28907: loss: 0.073293, loss_s1: 0.031700, loss_fp: 0.010541, loss_freq: 0.053472
[17:09:44.933] iteration 28908: loss: 0.049773, loss_s1: 0.014696, loss_fp: 0.006984, loss_freq: 0.020163
[17:09:45.558] iteration 28909: loss: 0.042632, loss_s1: 0.039540, loss_fp: 0.001133, loss_freq: 0.012464
[17:09:46.181] iteration 28910: loss: 0.037240, loss_s1: 0.030481, loss_fp: 0.001705, loss_freq: 0.004653
[17:09:46.805] iteration 28911: loss: 0.057062, loss_s1: 0.051177, loss_fp: 0.003050, loss_freq: 0.018613
[17:09:47.426] iteration 28912: loss: 0.097427, loss_s1: 0.109041, loss_fp: 0.001105, loss_freq: 0.041366
[17:09:48.051] iteration 28913: loss: 0.079313, loss_s1: 0.033108, loss_fp: 0.002380, loss_freq: 0.084246
[17:09:48.666] iteration 28914: loss: 0.032415, loss_s1: 0.017529, loss_fp: 0.003809, loss_freq: 0.005301
[17:09:49.288] iteration 28915: loss: 0.060935, loss_s1: 0.044669, loss_fp: 0.004282, loss_freq: 0.022836
[17:09:49.920] iteration 28916: loss: 0.044189, loss_s1: 0.024126, loss_fp: 0.001669, loss_freq: 0.016177
[17:09:50.554] iteration 28917: loss: 0.040831, loss_s1: 0.025372, loss_fp: 0.002662, loss_freq: 0.014269
[17:09:51.191] iteration 28918: loss: 0.062739, loss_s1: 0.061482, loss_fp: 0.005916, loss_freq: 0.013849
[17:09:51.824] iteration 28919: loss: 0.060677, loss_s1: 0.026063, loss_fp: 0.008833, loss_freq: 0.058547
[17:09:52.454] iteration 28920: loss: 0.081997, loss_s1: 0.109755, loss_fp: 0.005544, loss_freq: 0.018622
[17:09:53.086] iteration 28921: loss: 0.064534, loss_s1: 0.059976, loss_fp: 0.004540, loss_freq: 0.024972
[17:09:53.711] iteration 28922: loss: 0.068546, loss_s1: 0.061192, loss_fp: 0.001521, loss_freq: 0.033040
[17:09:54.334] iteration 28923: loss: 0.046074, loss_s1: 0.016292, loss_fp: 0.005978, loss_freq: 0.029656
[17:09:54.972] iteration 28924: loss: 0.047591, loss_s1: 0.033665, loss_fp: 0.005005, loss_freq: 0.015121
[17:09:55.593] iteration 28925: loss: 0.063675, loss_s1: 0.052852, loss_fp: 0.000914, loss_freq: 0.023233
[17:09:56.217] iteration 28926: loss: 0.037730, loss_s1: 0.029141, loss_fp: 0.001255, loss_freq: 0.022364
[17:09:56.841] iteration 28927: loss: 0.095139, loss_s1: 0.082855, loss_fp: 0.004412, loss_freq: 0.038001
[17:09:57.464] iteration 28928: loss: 0.055033, loss_s1: 0.068921, loss_fp: 0.001990, loss_freq: 0.014445
[17:09:58.093] iteration 28929: loss: 0.051034, loss_s1: 0.032571, loss_fp: 0.008032, loss_freq: 0.020592
[17:09:58.721] iteration 28930: loss: 0.077993, loss_s1: 0.065326, loss_fp: 0.011369, loss_freq: 0.039030
[17:09:59.353] iteration 28931: loss: 0.060652, loss_s1: 0.049907, loss_fp: 0.002261, loss_freq: 0.014750
[17:09:59.984] iteration 28932: loss: 0.075875, loss_s1: 0.074582, loss_fp: 0.000589, loss_freq: 0.044796
[17:10:00.611] iteration 28933: loss: 0.046483, loss_s1: 0.016933, loss_fp: 0.004501, loss_freq: 0.025924
[17:10:01.240] iteration 28934: loss: 0.053048, loss_s1: 0.040255, loss_fp: 0.008232, loss_freq: 0.019492
[17:10:01.869] iteration 28935: loss: 0.070781, loss_s1: 0.093547, loss_fp: 0.004000, loss_freq: 0.018629
[17:10:02.494] iteration 28936: loss: 0.043218, loss_s1: 0.025037, loss_fp: 0.001998, loss_freq: 0.024899
[17:10:03.125] iteration 28937: loss: 0.062528, loss_s1: 0.042674, loss_fp: 0.001863, loss_freq: 0.038751
[17:10:03.751] iteration 28938: loss: 0.043613, loss_s1: 0.028141, loss_fp: 0.001676, loss_freq: 0.023343
[17:10:04.378] iteration 28939: loss: 0.049662, loss_s1: 0.032962, loss_fp: 0.002970, loss_freq: 0.028040
[17:10:05.004] iteration 28940: loss: 0.072958, loss_s1: 0.043872, loss_fp: 0.004402, loss_freq: 0.069735
[17:10:05.629] iteration 28941: loss: 0.029478, loss_s1: 0.013707, loss_fp: 0.001520, loss_freq: 0.013608
[17:10:06.251] iteration 28942: loss: 0.050448, loss_s1: 0.025754, loss_fp: 0.006581, loss_freq: 0.008953
[17:10:06.876] iteration 28943: loss: 0.064579, loss_s1: 0.061107, loss_fp: 0.005320, loss_freq: 0.032959
[17:10:07.503] iteration 28944: loss: 0.041658, loss_s1: 0.015627, loss_fp: 0.011122, loss_freq: 0.012202
[17:10:08.120] iteration 28945: loss: 0.049646, loss_s1: 0.032208, loss_fp: 0.001073, loss_freq: 0.030398
[17:10:08.736] iteration 28946: loss: 0.031723, loss_s1: 0.015557, loss_fp: 0.000951, loss_freq: 0.009517
[17:10:09.358] iteration 28947: loss: 0.039297, loss_s1: 0.024984, loss_fp: 0.004558, loss_freq: 0.017534
[17:10:09.977] iteration 28948: loss: 0.052699, loss_s1: 0.051292, loss_fp: 0.001592, loss_freq: 0.012264
[17:10:10.603] iteration 28949: loss: 0.091572, loss_s1: 0.108453, loss_fp: 0.004872, loss_freq: 0.033501
[17:10:11.215] iteration 28950: loss: 0.049214, loss_s1: 0.019512, loss_fp: 0.009056, loss_freq: 0.020138
[17:10:11.833] iteration 28951: loss: 0.050907, loss_s1: 0.038795, loss_fp: 0.001929, loss_freq: 0.017956
[17:10:12.456] iteration 28952: loss: 0.064695, loss_s1: 0.052085, loss_fp: 0.009123, loss_freq: 0.022464
[17:10:13.075] iteration 28953: loss: 0.095611, loss_s1: 0.051276, loss_fp: 0.015393, loss_freq: 0.064243
[17:10:13.725] iteration 28954: loss: 0.046682, loss_s1: 0.037460, loss_fp: 0.006721, loss_freq: 0.014458
[17:10:14.366] iteration 28955: loss: 0.046740, loss_s1: 0.042876, loss_fp: 0.008092, loss_freq: 0.007391
[17:10:15.056] iteration 28956: loss: 0.036655, loss_s1: 0.026868, loss_fp: 0.005096, loss_freq: 0.003488
[17:10:15.727] iteration 28957: loss: 0.042783, loss_s1: 0.031531, loss_fp: 0.002898, loss_freq: 0.014981
[17:10:16.420] iteration 28958: loss: 0.053248, loss_s1: 0.036212, loss_fp: 0.002152, loss_freq: 0.028503
[17:10:17.049] iteration 28959: loss: 0.050211, loss_s1: 0.047199, loss_fp: 0.001460, loss_freq: 0.023193
[17:10:17.677] iteration 28960: loss: 0.051907, loss_s1: 0.034996, loss_fp: 0.008550, loss_freq: 0.024077
[17:10:18.306] iteration 28961: loss: 0.045330, loss_s1: 0.033595, loss_fp: 0.003573, loss_freq: 0.029280
[17:10:18.922] iteration 28962: loss: 0.034584, loss_s1: 0.017623, loss_fp: 0.002603, loss_freq: 0.015607
[17:10:19.550] iteration 28963: loss: 0.041953, loss_s1: 0.039578, loss_fp: 0.002367, loss_freq: 0.013559
[17:10:20.162] iteration 28964: loss: 0.049386, loss_s1: 0.030927, loss_fp: 0.001490, loss_freq: 0.022824
[17:10:20.786] iteration 28965: loss: 0.083753, loss_s1: 0.075268, loss_fp: 0.006798, loss_freq: 0.040462
[17:10:21.406] iteration 28966: loss: 0.069511, loss_s1: 0.040418, loss_fp: 0.003226, loss_freq: 0.039635
[17:10:22.039] iteration 28967: loss: 0.049435, loss_s1: 0.035164, loss_fp: 0.005051, loss_freq: 0.022100
[17:10:22.672] iteration 28968: loss: 0.044724, loss_s1: 0.025820, loss_fp: 0.005050, loss_freq: 0.013153
[17:10:23.304] iteration 28969: loss: 0.053729, loss_s1: 0.053138, loss_fp: 0.001754, loss_freq: 0.018697
[17:10:23.929] iteration 28970: loss: 0.028330, loss_s1: 0.019210, loss_fp: 0.002370, loss_freq: 0.009444
[17:10:24.555] iteration 28971: loss: 0.070286, loss_s1: 0.090492, loss_fp: 0.004288, loss_freq: 0.014296
[17:10:25.182] iteration 28972: loss: 0.062075, loss_s1: 0.029014, loss_fp: 0.002721, loss_freq: 0.064102
[17:10:25.812] iteration 28973: loss: 0.028948, loss_s1: 0.016002, loss_fp: 0.001363, loss_freq: 0.003785
[17:10:26.440] iteration 28974: loss: 0.031704, loss_s1: 0.020019, loss_fp: 0.000641, loss_freq: 0.011362
[17:10:27.090] iteration 28975: loss: 0.032580, loss_s1: 0.034067, loss_fp: 0.000538, loss_freq: 0.006923
[17:10:27.733] iteration 28976: loss: 0.040367, loss_s1: 0.033811, loss_fp: 0.004937, loss_freq: 0.010486
[17:10:28.373] iteration 28977: loss: 0.040223, loss_s1: 0.014917, loss_fp: 0.002646, loss_freq: 0.026081
[17:10:29.015] iteration 28978: loss: 0.059618, loss_s1: 0.052810, loss_fp: 0.008910, loss_freq: 0.030895
[17:10:29.650] iteration 28979: loss: 0.042017, loss_s1: 0.034757, loss_fp: 0.000484, loss_freq: 0.017088
[17:10:30.282] iteration 28980: loss: 0.036840, loss_s1: 0.021238, loss_fp: 0.005904, loss_freq: 0.008370
[17:10:30.906] iteration 28981: loss: 0.038724, loss_s1: 0.032012, loss_fp: 0.001001, loss_freq: 0.011201
[17:10:31.522] iteration 28982: loss: 0.037894, loss_s1: 0.020047, loss_fp: 0.000570, loss_freq: 0.014853
[17:10:32.146] iteration 28983: loss: 0.065380, loss_s1: 0.028101, loss_fp: 0.009591, loss_freq: 0.038472
[17:10:32.771] iteration 28984: loss: 0.031904, loss_s1: 0.016048, loss_fp: 0.002256, loss_freq: 0.012784
[17:10:33.400] iteration 28985: loss: 0.068370, loss_s1: 0.044183, loss_fp: 0.002312, loss_freq: 0.042238
[17:10:34.027] iteration 28986: loss: 0.076455, loss_s1: 0.053299, loss_fp: 0.004434, loss_freq: 0.042453
[17:10:34.656] iteration 28987: loss: 0.069220, loss_s1: 0.080570, loss_fp: 0.002760, loss_freq: 0.024236
[17:10:35.280] iteration 28988: loss: 0.065214, loss_s1: 0.033663, loss_fp: 0.003764, loss_freq: 0.038099
[17:10:35.897] iteration 28989: loss: 0.067693, loss_s1: 0.050587, loss_fp: 0.003037, loss_freq: 0.051484
[17:10:36.518] iteration 28990: loss: 0.040219, loss_s1: 0.026940, loss_fp: 0.003720, loss_freq: 0.014068
[17:10:37.144] iteration 28991: loss: 0.034843, loss_s1: 0.012049, loss_fp: 0.003905, loss_freq: 0.014919
[17:10:37.770] iteration 28992: loss: 0.039948, loss_s1: 0.008715, loss_fp: 0.002283, loss_freq: 0.027861
[17:10:38.393] iteration 28993: loss: 0.056390, loss_s1: 0.014604, loss_fp: 0.013579, loss_freq: 0.039458
[17:10:39.023] iteration 28994: loss: 0.081368, loss_s1: 0.050172, loss_fp: 0.020884, loss_freq: 0.054103
[17:10:39.663] iteration 28995: loss: 0.044828, loss_s1: 0.021660, loss_fp: 0.005199, loss_freq: 0.022644
[17:10:40.306] iteration 28996: loss: 0.055995, loss_s1: 0.041209, loss_fp: 0.003398, loss_freq: 0.037885
[17:10:40.952] iteration 28997: loss: 0.082606, loss_s1: 0.057238, loss_fp: 0.004574, loss_freq: 0.025450
[17:10:41.591] iteration 28998: loss: 0.049553, loss_s1: 0.041961, loss_fp: 0.004209, loss_freq: 0.024945
[17:10:42.230] iteration 28999: loss: 0.040973, loss_s1: 0.008489, loss_fp: 0.002456, loss_freq: 0.027835
[17:10:42.859] iteration 29000: loss: 0.060863, loss_s1: 0.076372, loss_fp: 0.000465, loss_freq: 0.014288
[17:10:46.121] iteration 29000 : mean_dice : 0.803635
[17:10:46.795] iteration 29001: loss: 0.049489, loss_s1: 0.029936, loss_fp: 0.001851, loss_freq: 0.010212
[17:10:47.421] iteration 29002: loss: 0.052476, loss_s1: 0.052290, loss_fp: 0.000526, loss_freq: 0.017721
[17:10:48.044] iteration 29003: loss: 0.043048, loss_s1: 0.023709, loss_fp: 0.002854, loss_freq: 0.020681
[17:10:48.672] iteration 29004: loss: 0.066041, loss_s1: 0.080197, loss_fp: 0.002723, loss_freq: 0.013154
[17:10:49.293] iteration 29005: loss: 0.058675, loss_s1: 0.072086, loss_fp: 0.002420, loss_freq: 0.015598
[17:10:49.925] iteration 29006: loss: 0.051063, loss_s1: 0.038604, loss_fp: 0.004153, loss_freq: 0.017807
[17:10:50.556] iteration 29007: loss: 0.063062, loss_s1: 0.053181, loss_fp: 0.007223, loss_freq: 0.026972
[17:10:51.182] iteration 29008: loss: 0.061733, loss_s1: 0.064149, loss_fp: 0.001903, loss_freq: 0.024141
[17:10:51.807] iteration 29009: loss: 0.016999, loss_s1: 0.003555, loss_fp: 0.001581, loss_freq: 0.001537
[17:10:52.424] iteration 29010: loss: 0.066258, loss_s1: 0.043539, loss_fp: 0.001181, loss_freq: 0.057028
[17:10:53.047] iteration 29011: loss: 0.076950, loss_s1: 0.101041, loss_fp: 0.004877, loss_freq: 0.021280
[17:10:53.668] iteration 29012: loss: 0.045353, loss_s1: 0.018505, loss_fp: 0.002023, loss_freq: 0.004614
[17:10:54.293] iteration 29013: loss: 0.037296, loss_s1: 0.017000, loss_fp: 0.003461, loss_freq: 0.022036
[17:10:54.910] iteration 29014: loss: 0.036629, loss_s1: 0.017926, loss_fp: 0.005778, loss_freq: 0.019041
[17:10:55.546] iteration 29015: loss: 0.049378, loss_s1: 0.030428, loss_fp: 0.008599, loss_freq: 0.029313
[17:10:56.177] iteration 29016: loss: 0.038576, loss_s1: 0.018280, loss_fp: 0.004928, loss_freq: 0.009766
[17:10:56.821] iteration 29017: loss: 0.065292, loss_s1: 0.055638, loss_fp: 0.007547, loss_freq: 0.027650
[17:10:57.473] iteration 29018: loss: 0.057564, loss_s1: 0.033651, loss_fp: 0.015833, loss_freq: 0.026982
[17:10:58.114] iteration 29019: loss: 0.049983, loss_s1: 0.024112, loss_fp: 0.001708, loss_freq: 0.040302
[17:10:58.747] iteration 29020: loss: 0.069920, loss_s1: 0.057127, loss_fp: 0.009245, loss_freq: 0.035357
[17:10:59.386] iteration 29021: loss: 0.058350, loss_s1: 0.022304, loss_fp: 0.004214, loss_freq: 0.033252
[17:11:00.011] iteration 29022: loss: 0.056484, loss_s1: 0.053528, loss_fp: 0.003821, loss_freq: 0.016760
[17:11:00.642] iteration 29023: loss: 0.075834, loss_s1: 0.090309, loss_fp: 0.002984, loss_freq: 0.020702
[17:11:01.268] iteration 29024: loss: 0.044658, loss_s1: 0.024646, loss_fp: 0.006899, loss_freq: 0.014875
[17:11:01.895] iteration 29025: loss: 0.047760, loss_s1: 0.034371, loss_fp: 0.006523, loss_freq: 0.018867
[17:11:02.524] iteration 29026: loss: 0.066651, loss_s1: 0.037634, loss_fp: 0.005675, loss_freq: 0.018839
[17:11:03.153] iteration 29027: loss: 0.058142, loss_s1: 0.046538, loss_fp: 0.006373, loss_freq: 0.027983
[17:11:03.777] iteration 29028: loss: 0.050625, loss_s1: 0.024159, loss_fp: 0.026131, loss_freq: 0.011431
[17:11:04.396] iteration 29029: loss: 0.047028, loss_s1: 0.039507, loss_fp: 0.001565, loss_freq: 0.021026
[17:11:05.400] iteration 29030: loss: 0.064126, loss_s1: 0.063901, loss_fp: 0.002288, loss_freq: 0.012669
[17:11:06.029] iteration 29031: loss: 0.045254, loss_s1: 0.024424, loss_fp: 0.010854, loss_freq: 0.017816
[17:11:06.657] iteration 29032: loss: 0.023865, loss_s1: 0.007108, loss_fp: 0.000903, loss_freq: 0.011887
[17:11:07.310] iteration 29033: loss: 0.055493, loss_s1: 0.025767, loss_fp: 0.004218, loss_freq: 0.042905
[17:11:07.965] iteration 29034: loss: 0.040179, loss_s1: 0.037214, loss_fp: 0.004739, loss_freq: 0.015106
[17:11:08.580] iteration 29035: loss: 0.033896, loss_s1: 0.012657, loss_fp: 0.003475, loss_freq: 0.002850
[17:11:09.202] iteration 29036: loss: 0.035618, loss_s1: 0.028136, loss_fp: 0.002698, loss_freq: 0.014268
[17:11:09.829] iteration 29037: loss: 0.040248, loss_s1: 0.008002, loss_fp: 0.004537, loss_freq: 0.029038
[17:11:10.457] iteration 29038: loss: 0.059548, loss_s1: 0.064676, loss_fp: 0.002753, loss_freq: 0.011456
[17:11:11.078] iteration 29039: loss: 0.042951, loss_s1: 0.013685, loss_fp: 0.001893, loss_freq: 0.007932
[17:11:11.707] iteration 29040: loss: 0.046167, loss_s1: 0.028057, loss_fp: 0.002783, loss_freq: 0.026832
[17:11:12.332] iteration 29041: loss: 0.035115, loss_s1: 0.018606, loss_fp: 0.001181, loss_freq: 0.014953
[17:11:12.955] iteration 29042: loss: 0.053981, loss_s1: 0.054157, loss_fp: 0.001986, loss_freq: 0.009063
[17:11:13.580] iteration 29043: loss: 0.029920, loss_s1: 0.019667, loss_fp: 0.001161, loss_freq: 0.011122
[17:11:14.202] iteration 29044: loss: 0.044573, loss_s1: 0.026462, loss_fp: 0.001904, loss_freq: 0.017463
[17:11:14.827] iteration 29045: loss: 0.052767, loss_s1: 0.033625, loss_fp: 0.011232, loss_freq: 0.022458
[17:11:15.453] iteration 29046: loss: 0.080417, loss_s1: 0.035411, loss_fp: 0.008395, loss_freq: 0.039889
[17:11:16.078] iteration 29047: loss: 0.041014, loss_s1: 0.032478, loss_fp: 0.005264, loss_freq: 0.013455
[17:11:16.711] iteration 29048: loss: 0.039550, loss_s1: 0.022174, loss_fp: 0.002795, loss_freq: 0.026186
[17:11:17.334] iteration 29049: loss: 0.031906, loss_s1: 0.018994, loss_fp: 0.002295, loss_freq: 0.010146
[17:11:17.966] iteration 29050: loss: 0.053765, loss_s1: 0.023331, loss_fp: 0.004064, loss_freq: 0.044066
[17:11:18.589] iteration 29051: loss: 0.034185, loss_s1: 0.021189, loss_fp: 0.001744, loss_freq: 0.019015
[17:11:19.214] iteration 29052: loss: 0.053347, loss_s1: 0.046125, loss_fp: 0.003612, loss_freq: 0.018619
[17:11:19.839] iteration 29053: loss: 0.027549, loss_s1: 0.010766, loss_fp: 0.001556, loss_freq: 0.011397
[17:11:20.467] iteration 29054: loss: 0.038392, loss_s1: 0.030864, loss_fp: 0.000548, loss_freq: 0.011201
[17:11:21.092] iteration 29055: loss: 0.039021, loss_s1: 0.025334, loss_fp: 0.001155, loss_freq: 0.010707
[17:11:21.723] iteration 29056: loss: 0.064264, loss_s1: 0.036805, loss_fp: 0.012202, loss_freq: 0.041440
[17:11:22.351] iteration 29057: loss: 0.042592, loss_s1: 0.027637, loss_fp: 0.002534, loss_freq: 0.009122
[17:11:22.975] iteration 29058: loss: 0.060427, loss_s1: 0.043126, loss_fp: 0.007050, loss_freq: 0.029792
[17:11:23.595] iteration 29059: loss: 0.043993, loss_s1: 0.026721, loss_fp: 0.001145, loss_freq: 0.009142
[17:11:24.219] iteration 29060: loss: 0.032737, loss_s1: 0.023318, loss_fp: 0.001114, loss_freq: 0.010841
[17:11:24.838] iteration 29061: loss: 0.043930, loss_s1: 0.013646, loss_fp: 0.001365, loss_freq: 0.009934
[17:11:25.464] iteration 29062: loss: 0.049165, loss_s1: 0.029617, loss_fp: 0.002700, loss_freq: 0.036550
[17:11:26.091] iteration 29063: loss: 0.060678, loss_s1: 0.048917, loss_fp: 0.004984, loss_freq: 0.025536
[17:11:26.713] iteration 29064: loss: 0.068379, loss_s1: 0.070315, loss_fp: 0.004711, loss_freq: 0.026033
[17:11:27.339] iteration 29065: loss: 0.084455, loss_s1: 0.071538, loss_fp: 0.005055, loss_freq: 0.048461
[17:11:27.960] iteration 29066: loss: 0.047264, loss_s1: 0.028778, loss_fp: 0.000961, loss_freq: 0.019523
[17:11:28.580] iteration 29067: loss: 0.051110, loss_s1: 0.048334, loss_fp: 0.003821, loss_freq: 0.020675
[17:11:29.224] iteration 29068: loss: 0.098896, loss_s1: 0.101179, loss_fp: 0.004010, loss_freq: 0.040261
[17:11:29.873] iteration 29069: loss: 0.049622, loss_s1: 0.035120, loss_fp: 0.002959, loss_freq: 0.013394
[17:11:30.518] iteration 29070: loss: 0.038942, loss_s1: 0.033088, loss_fp: 0.001135, loss_freq: 0.008427
[17:11:31.154] iteration 29071: loss: 0.030068, loss_s1: 0.023331, loss_fp: 0.001572, loss_freq: 0.009653
[17:11:31.781] iteration 29072: loss: 0.034673, loss_s1: 0.012031, loss_fp: 0.001416, loss_freq: 0.004618
[17:11:32.408] iteration 29073: loss: 0.047932, loss_s1: 0.028113, loss_fp: 0.003267, loss_freq: 0.029271
[17:11:33.039] iteration 29074: loss: 0.048706, loss_s1: 0.015545, loss_fp: 0.008327, loss_freq: 0.007919
[17:11:33.668] iteration 29075: loss: 0.063242, loss_s1: 0.045575, loss_fp: 0.003389, loss_freq: 0.037830
[17:11:34.283] iteration 29076: loss: 0.049848, loss_s1: 0.036293, loss_fp: 0.003010, loss_freq: 0.022257
[17:11:34.901] iteration 29077: loss: 0.035914, loss_s1: 0.032761, loss_fp: 0.001187, loss_freq: 0.006285
[17:11:35.526] iteration 29078: loss: 0.060771, loss_s1: 0.060055, loss_fp: 0.007992, loss_freq: 0.026351
[17:11:36.171] iteration 29079: loss: 0.048328, loss_s1: 0.029873, loss_fp: 0.004378, loss_freq: 0.010540
[17:11:36.811] iteration 29080: loss: 0.051707, loss_s1: 0.044175, loss_fp: 0.007563, loss_freq: 0.020201
[17:11:37.466] iteration 29081: loss: 0.046487, loss_s1: 0.024268, loss_fp: 0.001320, loss_freq: 0.028570
[17:11:38.104] iteration 29082: loss: 0.041974, loss_s1: 0.031557, loss_fp: 0.001169, loss_freq: 0.021076
[17:11:38.729] iteration 29083: loss: 0.086671, loss_s1: 0.055345, loss_fp: 0.008697, loss_freq: 0.079202
[17:11:39.357] iteration 29084: loss: 0.032760, loss_s1: 0.023210, loss_fp: 0.001349, loss_freq: 0.005724
[17:11:39.979] iteration 29085: loss: 0.027168, loss_s1: 0.005837, loss_fp: 0.001673, loss_freq: 0.008505
[17:11:40.600] iteration 29086: loss: 0.046808, loss_s1: 0.047248, loss_fp: 0.007662, loss_freq: 0.008613
[17:11:41.219] iteration 29087: loss: 0.050420, loss_s1: 0.037956, loss_fp: 0.002700, loss_freq: 0.023075
[17:11:41.842] iteration 29088: loss: 0.082313, loss_s1: 0.064302, loss_fp: 0.001299, loss_freq: 0.052456
[17:11:42.472] iteration 29089: loss: 0.051423, loss_s1: 0.035031, loss_fp: 0.005089, loss_freq: 0.033119
[17:11:43.099] iteration 29090: loss: 0.036938, loss_s1: 0.025753, loss_fp: 0.003391, loss_freq: 0.008306
[17:11:43.724] iteration 29091: loss: 0.062813, loss_s1: 0.028956, loss_fp: 0.007624, loss_freq: 0.052296
[17:11:44.351] iteration 29092: loss: 0.063029, loss_s1: 0.065142, loss_fp: 0.003502, loss_freq: 0.020611
[17:11:44.971] iteration 29093: loss: 0.037338, loss_s1: 0.007573, loss_fp: 0.003843, loss_freq: 0.021726
[17:11:45.590] iteration 29094: loss: 0.092808, loss_s1: 0.035569, loss_fp: 0.010985, loss_freq: 0.055498
[17:11:46.211] iteration 29095: loss: 0.067602, loss_s1: 0.032771, loss_fp: 0.022403, loss_freq: 0.034075
[17:11:46.839] iteration 29096: loss: 0.063060, loss_s1: 0.043540, loss_fp: 0.008908, loss_freq: 0.017449
[17:11:47.459] iteration 29097: loss: 0.039300, loss_s1: 0.024924, loss_fp: 0.008854, loss_freq: 0.018028
[17:11:48.087] iteration 29098: loss: 0.027439, loss_s1: 0.013212, loss_fp: 0.002960, loss_freq: 0.007002
[17:11:48.718] iteration 29099: loss: 0.038350, loss_s1: 0.026214, loss_fp: 0.002425, loss_freq: 0.009697
[17:11:49.348] iteration 29100: loss: 0.061054, loss_s1: 0.076440, loss_fp: 0.001724, loss_freq: 0.012441
[17:11:49.964] iteration 29101: loss: 0.082824, loss_s1: 0.046588, loss_fp: 0.002885, loss_freq: 0.072396
[17:11:50.583] iteration 29102: loss: 0.087386, loss_s1: 0.054858, loss_fp: 0.004531, loss_freq: 0.086375
[17:11:51.210] iteration 29103: loss: 0.083566, loss_s1: 0.083150, loss_fp: 0.006488, loss_freq: 0.037252
[17:11:51.842] iteration 29104: loss: 0.074402, loss_s1: 0.045189, loss_fp: 0.002126, loss_freq: 0.065309
[17:11:52.461] iteration 29105: loss: 0.033366, loss_s1: 0.010496, loss_fp: 0.005611, loss_freq: 0.015873
[17:11:53.100] iteration 29106: loss: 0.041353, loss_s1: 0.034395, loss_fp: 0.016733, loss_freq: 0.004582
[17:11:53.738] iteration 29107: loss: 0.041258, loss_s1: 0.013554, loss_fp: 0.000715, loss_freq: 0.024387
[17:11:54.387] iteration 29108: loss: 0.056469, loss_s1: 0.039059, loss_fp: 0.008292, loss_freq: 0.020727
[17:11:55.032] iteration 29109: loss: 0.078434, loss_s1: 0.059823, loss_fp: 0.013104, loss_freq: 0.016314
[17:11:55.683] iteration 29110: loss: 0.033667, loss_s1: 0.019426, loss_fp: 0.008316, loss_freq: 0.008921
[17:11:56.334] iteration 29111: loss: 0.066310, loss_s1: 0.054621, loss_fp: 0.001638, loss_freq: 0.033880
[17:11:56.990] iteration 29112: loss: 0.072381, loss_s1: 0.056008, loss_fp: 0.002586, loss_freq: 0.044695
[17:11:57.616] iteration 29113: loss: 0.042063, loss_s1: 0.024627, loss_fp: 0.002011, loss_freq: 0.026334
[17:11:58.255] iteration 29114: loss: 0.049435, loss_s1: 0.025268, loss_fp: 0.007673, loss_freq: 0.030410
[17:11:58.883] iteration 29115: loss: 0.061708, loss_s1: 0.029261, loss_fp: 0.009595, loss_freq: 0.032921
[17:11:59.501] iteration 29116: loss: 0.033623, loss_s1: 0.017290, loss_fp: 0.003021, loss_freq: 0.009489
[17:12:00.121] iteration 29117: loss: 0.029074, loss_s1: 0.009312, loss_fp: 0.000830, loss_freq: 0.013403
[17:12:00.747] iteration 29118: loss: 0.041578, loss_s1: 0.031547, loss_fp: 0.002965, loss_freq: 0.020553
[17:12:01.375] iteration 29119: loss: 0.039627, loss_s1: 0.035107, loss_fp: 0.005879, loss_freq: 0.010937
[17:12:02.004] iteration 29120: loss: 0.071405, loss_s1: 0.035757, loss_fp: 0.003060, loss_freq: 0.039424
[17:12:02.627] iteration 29121: loss: 0.038494, loss_s1: 0.022595, loss_fp: 0.001684, loss_freq: 0.020890
[17:12:03.250] iteration 29122: loss: 0.045529, loss_s1: 0.040833, loss_fp: 0.002103, loss_freq: 0.014336
[17:12:03.872] iteration 29123: loss: 0.065298, loss_s1: 0.075821, loss_fp: 0.004938, loss_freq: 0.013629
[17:12:04.501] iteration 29124: loss: 0.041130, loss_s1: 0.016746, loss_fp: 0.003640, loss_freq: 0.012297
[17:12:05.116] iteration 29125: loss: 0.044708, loss_s1: 0.029890, loss_fp: 0.003682, loss_freq: 0.021897
[17:12:05.740] iteration 29126: loss: 0.072921, loss_s1: 0.050090, loss_fp: 0.003427, loss_freq: 0.053925
[17:12:06.362] iteration 29127: loss: 0.034338, loss_s1: 0.007436, loss_fp: 0.003761, loss_freq: 0.010731
[17:12:06.979] iteration 29128: loss: 0.053341, loss_s1: 0.049499, loss_fp: 0.002089, loss_freq: 0.023779
[17:12:07.600] iteration 29129: loss: 0.070590, loss_s1: 0.044314, loss_fp: 0.001542, loss_freq: 0.034434
[17:12:08.221] iteration 29130: loss: 0.045988, loss_s1: 0.016602, loss_fp: 0.005671, loss_freq: 0.020239
[17:12:08.847] iteration 29131: loss: 0.066717, loss_s1: 0.062375, loss_fp: 0.001099, loss_freq: 0.020439
[17:12:09.469] iteration 29132: loss: 0.096541, loss_s1: 0.095992, loss_fp: 0.003857, loss_freq: 0.065867
[17:12:10.093] iteration 29133: loss: 0.047683, loss_s1: 0.029568, loss_fp: 0.001735, loss_freq: 0.024093
[17:12:10.709] iteration 29134: loss: 0.043741, loss_s1: 0.009054, loss_fp: 0.005181, loss_freq: 0.007968
[17:12:11.329] iteration 29135: loss: 0.036047, loss_s1: 0.016420, loss_fp: 0.002356, loss_freq: 0.017896
[17:12:11.944] iteration 29136: loss: 0.108271, loss_s1: 0.105572, loss_fp: 0.009099, loss_freq: 0.058123
[17:12:12.563] iteration 29137: loss: 0.041858, loss_s1: 0.012263, loss_fp: 0.007214, loss_freq: 0.011236
[17:12:13.176] iteration 29138: loss: 0.047652, loss_s1: 0.022742, loss_fp: 0.006019, loss_freq: 0.024928
[17:12:13.806] iteration 29139: loss: 0.055585, loss_s1: 0.055951, loss_fp: 0.003396, loss_freq: 0.027952
[17:12:14.427] iteration 29140: loss: 0.042956, loss_s1: 0.030286, loss_fp: 0.003658, loss_freq: 0.015051
[17:12:15.049] iteration 29141: loss: 0.042598, loss_s1: 0.025082, loss_fp: 0.004204, loss_freq: 0.028091
[17:12:15.672] iteration 29142: loss: 0.050469, loss_s1: 0.051304, loss_fp: 0.000917, loss_freq: 0.005383
[17:12:16.300] iteration 29143: loss: 0.049584, loss_s1: 0.041845, loss_fp: 0.003009, loss_freq: 0.014111
[17:12:16.928] iteration 29144: loss: 0.052266, loss_s1: 0.003113, loss_fp: 0.001024, loss_freq: 0.041323
[17:12:17.557] iteration 29145: loss: 0.035306, loss_s1: 0.032694, loss_fp: 0.001475, loss_freq: 0.007541
[17:12:18.178] iteration 29146: loss: 0.048236, loss_s1: 0.024720, loss_fp: 0.004596, loss_freq: 0.037150
[17:12:18.789] iteration 29147: loss: 0.056911, loss_s1: 0.063161, loss_fp: 0.002352, loss_freq: 0.015864
[17:12:19.415] iteration 29148: loss: 0.032254, loss_s1: 0.021796, loss_fp: 0.001632, loss_freq: 0.012091
[17:12:20.036] iteration 29149: loss: 0.067748, loss_s1: 0.065562, loss_fp: 0.000740, loss_freq: 0.030542
[17:12:20.653] iteration 29150: loss: 0.059871, loss_s1: 0.054627, loss_fp: 0.009062, loss_freq: 0.019561
[17:12:21.271] iteration 29151: loss: 0.033311, loss_s1: 0.012562, loss_fp: 0.003985, loss_freq: 0.010656
[17:12:21.894] iteration 29152: loss: 0.058474, loss_s1: 0.019912, loss_fp: 0.000832, loss_freq: 0.008435
[17:12:22.510] iteration 29153: loss: 0.044163, loss_s1: 0.030616, loss_fp: 0.005245, loss_freq: 0.014716
[17:12:23.135] iteration 29154: loss: 0.072381, loss_s1: 0.077149, loss_fp: 0.006493, loss_freq: 0.032609
[17:12:23.802] iteration 29155: loss: 0.042468, loss_s1: 0.035024, loss_fp: 0.000855, loss_freq: 0.009310
[17:12:24.424] iteration 29156: loss: 0.047501, loss_s1: 0.038964, loss_fp: 0.001929, loss_freq: 0.026632
[17:12:25.045] iteration 29157: loss: 0.037796, loss_s1: 0.026349, loss_fp: 0.001078, loss_freq: 0.015203
[17:12:25.673] iteration 29158: loss: 0.072917, loss_s1: 0.083641, loss_fp: 0.000840, loss_freq: 0.011535
[17:12:26.296] iteration 29159: loss: 0.041199, loss_s1: 0.023949, loss_fp: 0.002152, loss_freq: 0.016900
[17:12:26.915] iteration 29160: loss: 0.065620, loss_s1: 0.064795, loss_fp: 0.003887, loss_freq: 0.025509
[17:12:27.534] iteration 29161: loss: 0.076060, loss_s1: 0.062492, loss_fp: 0.006664, loss_freq: 0.019808
[17:12:28.158] iteration 29162: loss: 0.035001, loss_s1: 0.024245, loss_fp: 0.002324, loss_freq: 0.006272
[17:12:28.777] iteration 29163: loss: 0.050952, loss_s1: 0.035171, loss_fp: 0.001099, loss_freq: 0.025085
[17:12:29.409] iteration 29164: loss: 0.034458, loss_s1: 0.019706, loss_fp: 0.001755, loss_freq: 0.010931
[17:12:30.032] iteration 29165: loss: 0.048329, loss_s1: 0.033408, loss_fp: 0.002831, loss_freq: 0.024702
[17:12:30.646] iteration 29166: loss: 0.040907, loss_s1: 0.030819, loss_fp: 0.004146, loss_freq: 0.004939
[17:12:31.270] iteration 29167: loss: 0.026867, loss_s1: 0.013447, loss_fp: 0.001087, loss_freq: 0.011475
[17:12:31.888] iteration 29168: loss: 0.044548, loss_s1: 0.032103, loss_fp: 0.005770, loss_freq: 0.020166
[17:12:32.523] iteration 29169: loss: 0.056362, loss_s1: 0.028000, loss_fp: 0.010020, loss_freq: 0.028956
[17:12:33.159] iteration 29170: loss: 0.058113, loss_s1: 0.029769, loss_fp: 0.002756, loss_freq: 0.045908
[17:12:33.797] iteration 29171: loss: 0.060675, loss_s1: 0.037467, loss_fp: 0.004188, loss_freq: 0.037412
[17:12:34.439] iteration 29172: loss: 0.039178, loss_s1: 0.022365, loss_fp: 0.001626, loss_freq: 0.022753
[17:12:35.402] iteration 29173: loss: 0.038746, loss_s1: 0.029523, loss_fp: 0.001941, loss_freq: 0.014332
[17:12:36.019] iteration 29174: loss: 0.061746, loss_s1: 0.071703, loss_fp: 0.004443, loss_freq: 0.014213
[17:12:36.636] iteration 29175: loss: 0.040300, loss_s1: 0.030445, loss_fp: 0.002708, loss_freq: 0.013896
[17:12:37.252] iteration 29176: loss: 0.048341, loss_s1: 0.039436, loss_fp: 0.005337, loss_freq: 0.014095
[17:12:37.875] iteration 29177: loss: 0.039842, loss_s1: 0.032649, loss_fp: 0.003574, loss_freq: 0.018080
[17:12:38.496] iteration 29178: loss: 0.027600, loss_s1: 0.013643, loss_fp: 0.000418, loss_freq: 0.010518
[17:12:39.118] iteration 29179: loss: 0.050866, loss_s1: 0.050602, loss_fp: 0.003510, loss_freq: 0.020519
[17:12:39.739] iteration 29180: loss: 0.041694, loss_s1: 0.029266, loss_fp: 0.001837, loss_freq: 0.013754
[17:12:40.378] iteration 29181: loss: 0.047827, loss_s1: 0.037282, loss_fp: 0.008022, loss_freq: 0.015624
[17:12:41.005] iteration 29182: loss: 0.045712, loss_s1: 0.035805, loss_fp: 0.000453, loss_freq: 0.006633
[17:12:41.627] iteration 29183: loss: 0.044926, loss_s1: 0.039917, loss_fp: 0.002972, loss_freq: 0.015765
[17:12:42.254] iteration 29184: loss: 0.043415, loss_s1: 0.030112, loss_fp: 0.002442, loss_freq: 0.017705
[17:12:42.879] iteration 29185: loss: 0.046213, loss_s1: 0.047299, loss_fp: 0.000703, loss_freq: 0.014205
[17:12:43.506] iteration 29186: loss: 0.049038, loss_s1: 0.029771, loss_fp: 0.008924, loss_freq: 0.031184
[17:12:44.135] iteration 29187: loss: 0.051240, loss_s1: 0.046350, loss_fp: 0.000625, loss_freq: 0.013784
[17:12:44.754] iteration 29188: loss: 0.053111, loss_s1: 0.049585, loss_fp: 0.012431, loss_freq: 0.016222
[17:12:45.381] iteration 29189: loss: 0.088456, loss_s1: 0.085406, loss_fp: 0.004157, loss_freq: 0.043250
[17:12:46.007] iteration 29190: loss: 0.037026, loss_s1: 0.018443, loss_fp: 0.001637, loss_freq: 0.013763
[17:12:46.633] iteration 29191: loss: 0.043277, loss_s1: 0.018598, loss_fp: 0.001134, loss_freq: 0.028598
[17:12:47.255] iteration 29192: loss: 0.031900, loss_s1: 0.021442, loss_fp: 0.001965, loss_freq: 0.007796
[17:12:47.878] iteration 29193: loss: 0.063826, loss_s1: 0.019902, loss_fp: 0.002510, loss_freq: 0.047102
[17:12:48.506] iteration 29194: loss: 0.038283, loss_s1: 0.020175, loss_fp: 0.002708, loss_freq: 0.023342
[17:12:49.132] iteration 29195: loss: 0.046747, loss_s1: 0.039185, loss_fp: 0.001001, loss_freq: 0.017008
[17:12:49.754] iteration 29196: loss: 0.078053, loss_s1: 0.053158, loss_fp: 0.002110, loss_freq: 0.004352
[17:12:50.386] iteration 29197: loss: 0.035224, loss_s1: 0.013078, loss_fp: 0.002690, loss_freq: 0.009200
[17:12:51.035] iteration 29198: loss: 0.053635, loss_s1: 0.035111, loss_fp: 0.003593, loss_freq: 0.026424
[17:12:51.672] iteration 29199: loss: 0.048226, loss_s1: 0.031373, loss_fp: 0.008172, loss_freq: 0.016881
[17:12:52.306] iteration 29200: loss: 0.033262, loss_s1: 0.013888, loss_fp: 0.003921, loss_freq: 0.014120
[17:12:55.545] iteration 29200 : mean_dice : 0.795921
[17:12:56.212] iteration 29201: loss: 0.063569, loss_s1: 0.068887, loss_fp: 0.001040, loss_freq: 0.009630
[17:12:56.847] iteration 29202: loss: 0.033142, loss_s1: 0.004197, loss_fp: 0.000817, loss_freq: 0.013600
[17:12:57.491] iteration 29203: loss: 0.037324, loss_s1: 0.030255, loss_fp: 0.001863, loss_freq: 0.005832
[17:12:58.136] iteration 29204: loss: 0.043478, loss_s1: 0.016483, loss_fp: 0.005715, loss_freq: 0.025839
[17:12:58.778] iteration 29205: loss: 0.052972, loss_s1: 0.024754, loss_fp: 0.008557, loss_freq: 0.042787
[17:12:59.417] iteration 29206: loss: 0.085965, loss_s1: 0.070103, loss_fp: 0.006527, loss_freq: 0.062168
[17:13:00.057] iteration 29207: loss: 0.046872, loss_s1: 0.027697, loss_fp: 0.002359, loss_freq: 0.013273
[17:13:00.701] iteration 29208: loss: 0.058697, loss_s1: 0.064935, loss_fp: 0.001611, loss_freq: 0.016382
[17:13:01.352] iteration 29209: loss: 0.057683, loss_s1: 0.057243, loss_fp: 0.001316, loss_freq: 0.018993
[17:13:01.990] iteration 29210: loss: 0.051842, loss_s1: 0.041969, loss_fp: 0.015238, loss_freq: 0.012452
[17:13:02.618] iteration 29211: loss: 0.048973, loss_s1: 0.019151, loss_fp: 0.003287, loss_freq: 0.022182
[17:13:03.249] iteration 29212: loss: 0.040849, loss_s1: 0.028175, loss_fp: 0.002209, loss_freq: 0.010919
[17:13:03.886] iteration 29213: loss: 0.102722, loss_s1: 0.057401, loss_fp: 0.009003, loss_freq: 0.053396
[17:13:04.528] iteration 29214: loss: 0.039324, loss_s1: 0.036802, loss_fp: 0.000739, loss_freq: 0.017346
[17:13:05.176] iteration 29215: loss: 0.039081, loss_s1: 0.022308, loss_fp: 0.001542, loss_freq: 0.006445
[17:13:05.816] iteration 29216: loss: 0.050232, loss_s1: 0.023029, loss_fp: 0.005258, loss_freq: 0.043223
[17:13:06.472] iteration 29217: loss: 0.052648, loss_s1: 0.020121, loss_fp: 0.004293, loss_freq: 0.008567
[17:13:07.107] iteration 29218: loss: 0.047594, loss_s1: 0.045823, loss_fp: 0.002910, loss_freq: 0.017544
[17:13:07.745] iteration 29219: loss: 0.038660, loss_s1: 0.016243, loss_fp: 0.003239, loss_freq: 0.024429
[17:13:08.380] iteration 29220: loss: 0.046276, loss_s1: 0.031812, loss_fp: 0.006082, loss_freq: 0.015921
[17:13:09.032] iteration 29221: loss: 0.052033, loss_s1: 0.038181, loss_fp: 0.003741, loss_freq: 0.031795
[17:13:09.676] iteration 29222: loss: 0.048887, loss_s1: 0.030624, loss_fp: 0.005295, loss_freq: 0.018321
[17:13:10.360] iteration 29223: loss: 0.054148, loss_s1: 0.044656, loss_fp: 0.003457, loss_freq: 0.023715
[17:13:11.026] iteration 29224: loss: 0.090970, loss_s1: 0.070923, loss_fp: 0.004133, loss_freq: 0.028261
[17:13:11.696] iteration 29225: loss: 0.040507, loss_s1: 0.021763, loss_fp: 0.003856, loss_freq: 0.012804
[17:13:12.367] iteration 29226: loss: 0.027543, loss_s1: 0.013787, loss_fp: 0.004537, loss_freq: 0.008433
[17:13:13.030] iteration 29227: loss: 0.029243, loss_s1: 0.021037, loss_fp: 0.000825, loss_freq: 0.006721
[17:13:13.692] iteration 29228: loss: 0.034519, loss_s1: 0.018083, loss_fp: 0.000766, loss_freq: 0.007453
[17:13:14.362] iteration 29229: loss: 0.063655, loss_s1: 0.062781, loss_fp: 0.006660, loss_freq: 0.030951
[17:13:15.009] iteration 29230: loss: 0.041943, loss_s1: 0.026916, loss_fp: 0.002440, loss_freq: 0.022093
[17:13:15.644] iteration 29231: loss: 0.054975, loss_s1: 0.043566, loss_fp: 0.003012, loss_freq: 0.035050
[17:13:16.267] iteration 29232: loss: 0.043320, loss_s1: 0.021701, loss_fp: 0.005545, loss_freq: 0.021303
[17:13:16.892] iteration 29233: loss: 0.067173, loss_s1: 0.061460, loss_fp: 0.005194, loss_freq: 0.032737
[17:13:17.516] iteration 29234: loss: 0.046131, loss_s1: 0.022280, loss_fp: 0.001591, loss_freq: 0.020323
[17:13:18.138] iteration 29235: loss: 0.077566, loss_s1: 0.077412, loss_fp: 0.013146, loss_freq: 0.025452
[17:13:18.764] iteration 29236: loss: 0.043307, loss_s1: 0.026705, loss_fp: 0.002679, loss_freq: 0.018217
[17:13:19.392] iteration 29237: loss: 0.052708, loss_s1: 0.036439, loss_fp: 0.001899, loss_freq: 0.020240
[17:13:20.016] iteration 29238: loss: 0.037438, loss_s1: 0.027153, loss_fp: 0.001894, loss_freq: 0.016127
[17:13:20.642] iteration 29239: loss: 0.060984, loss_s1: 0.032398, loss_fp: 0.002952, loss_freq: 0.038465
[17:13:21.271] iteration 29240: loss: 0.043798, loss_s1: 0.012800, loss_fp: 0.002578, loss_freq: 0.035566
[17:13:21.897] iteration 29241: loss: 0.039196, loss_s1: 0.021501, loss_fp: 0.004808, loss_freq: 0.011362
[17:13:22.520] iteration 29242: loss: 0.042351, loss_s1: 0.019906, loss_fp: 0.004085, loss_freq: 0.017315
[17:13:23.139] iteration 29243: loss: 0.050060, loss_s1: 0.030734, loss_fp: 0.006656, loss_freq: 0.020708
[17:13:23.764] iteration 29244: loss: 0.060014, loss_s1: 0.037487, loss_fp: 0.004170, loss_freq: 0.036887
[17:13:24.391] iteration 29245: loss: 0.052939, loss_s1: 0.021960, loss_fp: 0.006175, loss_freq: 0.033815
[17:13:25.022] iteration 29246: loss: 0.071164, loss_s1: 0.045774, loss_fp: 0.006844, loss_freq: 0.046183
[17:13:25.649] iteration 29247: loss: 0.058157, loss_s1: 0.062607, loss_fp: 0.005430, loss_freq: 0.021837
[17:13:26.271] iteration 29248: loss: 0.034170, loss_s1: 0.018518, loss_fp: 0.002909, loss_freq: 0.011154
[17:13:26.890] iteration 29249: loss: 0.033126, loss_s1: 0.024284, loss_fp: 0.006032, loss_freq: 0.009260
[17:13:27.525] iteration 29250: loss: 0.034615, loss_s1: 0.017510, loss_fp: 0.002014, loss_freq: 0.013435
[17:13:28.161] iteration 29251: loss: 0.060408, loss_s1: 0.044163, loss_fp: 0.011096, loss_freq: 0.030685
[17:13:28.793] iteration 29252: loss: 0.063396, loss_s1: 0.035004, loss_fp: 0.017934, loss_freq: 0.024019
[17:13:29.424] iteration 29253: loss: 0.032250, loss_s1: 0.019838, loss_fp: 0.002084, loss_freq: 0.008140
[17:13:30.047] iteration 29254: loss: 0.062107, loss_s1: 0.073911, loss_fp: 0.002264, loss_freq: 0.011670
[17:13:30.679] iteration 29255: loss: 0.037083, loss_s1: 0.013627, loss_fp: 0.003552, loss_freq: 0.010166
[17:13:31.316] iteration 29256: loss: 0.043425, loss_s1: 0.033112, loss_fp: 0.003233, loss_freq: 0.020733
[17:13:31.931] iteration 29257: loss: 0.069960, loss_s1: 0.076951, loss_fp: 0.002630, loss_freq: 0.020251
[17:13:32.554] iteration 29258: loss: 0.042162, loss_s1: 0.016378, loss_fp: 0.004001, loss_freq: 0.033976
[17:13:33.192] iteration 29259: loss: 0.044235, loss_s1: 0.025354, loss_fp: 0.003068, loss_freq: 0.014730
[17:13:33.822] iteration 29260: loss: 0.029710, loss_s1: 0.005968, loss_fp: 0.000831, loss_freq: 0.015089
[17:13:34.453] iteration 29261: loss: 0.035531, loss_s1: 0.018526, loss_fp: 0.001820, loss_freq: 0.019937
[17:13:35.085] iteration 29262: loss: 0.047170, loss_s1: 0.037629, loss_fp: 0.004566, loss_freq: 0.026723
[17:13:35.724] iteration 29263: loss: 0.068206, loss_s1: 0.052602, loss_fp: 0.002177, loss_freq: 0.032271
[17:13:36.344] iteration 29264: loss: 0.061084, loss_s1: 0.031845, loss_fp: 0.004119, loss_freq: 0.058254
[17:13:36.974] iteration 29265: loss: 0.038199, loss_s1: 0.026530, loss_fp: 0.000526, loss_freq: 0.017549
[17:13:37.600] iteration 29266: loss: 0.043383, loss_s1: 0.020988, loss_fp: 0.003786, loss_freq: 0.004159
[17:13:38.216] iteration 29267: loss: 0.046187, loss_s1: 0.026997, loss_fp: 0.001445, loss_freq: 0.017774
[17:13:38.844] iteration 29268: loss: 0.033834, loss_s1: 0.020363, loss_fp: 0.004426, loss_freq: 0.005847
[17:13:39.470] iteration 29269: loss: 0.056477, loss_s1: 0.034294, loss_fp: 0.002139, loss_freq: 0.036309
[17:13:40.102] iteration 29270: loss: 0.043860, loss_s1: 0.029056, loss_fp: 0.005361, loss_freq: 0.015472
[17:13:40.721] iteration 29271: loss: 0.068219, loss_s1: 0.046492, loss_fp: 0.004930, loss_freq: 0.031534
[17:13:41.354] iteration 29272: loss: 0.049178, loss_s1: 0.018313, loss_fp: 0.004347, loss_freq: 0.032396
[17:13:41.982] iteration 29273: loss: 0.066415, loss_s1: 0.075824, loss_fp: 0.004632, loss_freq: 0.016800
[17:13:42.608] iteration 29274: loss: 0.061038, loss_s1: 0.018346, loss_fp: 0.002448, loss_freq: 0.042480
[17:13:43.234] iteration 29275: loss: 0.055838, loss_s1: 0.041987, loss_fp: 0.002916, loss_freq: 0.017748
[17:13:43.864] iteration 29276: loss: 0.038599, loss_s1: 0.021203, loss_fp: 0.000899, loss_freq: 0.016688
[17:13:44.497] iteration 29277: loss: 0.052643, loss_s1: 0.042843, loss_fp: 0.011681, loss_freq: 0.016998
[17:13:45.116] iteration 29278: loss: 0.073137, loss_s1: 0.023839, loss_fp: 0.002130, loss_freq: 0.031262
[17:13:45.750] iteration 29279: loss: 0.053599, loss_s1: 0.035530, loss_fp: 0.007145, loss_freq: 0.028423
[17:13:46.380] iteration 29280: loss: 0.115658, loss_s1: 0.113723, loss_fp: 0.005636, loss_freq: 0.083917
[17:13:47.008] iteration 29281: loss: 0.050942, loss_s1: 0.021433, loss_fp: 0.003410, loss_freq: 0.032318
[17:13:47.642] iteration 29282: loss: 0.069018, loss_s1: 0.067738, loss_fp: 0.013381, loss_freq: 0.027762
[17:13:48.275] iteration 29283: loss: 0.055828, loss_s1: 0.027620, loss_fp: 0.001686, loss_freq: 0.030621
[17:13:48.911] iteration 29284: loss: 0.051086, loss_s1: 0.049667, loss_fp: 0.004227, loss_freq: 0.020183
[17:13:49.572] iteration 29285: loss: 0.061044, loss_s1: 0.047474, loss_fp: 0.010161, loss_freq: 0.023757
[17:13:50.237] iteration 29286: loss: 0.098142, loss_s1: 0.084088, loss_fp: 0.016639, loss_freq: 0.059291
[17:13:50.897] iteration 29287: loss: 0.067961, loss_s1: 0.036790, loss_fp: 0.001397, loss_freq: 0.025561
[17:13:51.558] iteration 29288: loss: 0.031766, loss_s1: 0.014109, loss_fp: 0.002863, loss_freq: 0.010356
[17:13:52.190] iteration 29289: loss: 0.050680, loss_s1: 0.031091, loss_fp: 0.001058, loss_freq: 0.029826
[17:13:52.826] iteration 29290: loss: 0.068564, loss_s1: 0.081219, loss_fp: 0.001984, loss_freq: 0.020837
[17:13:53.459] iteration 29291: loss: 0.054201, loss_s1: 0.066053, loss_fp: 0.001036, loss_freq: 0.014059
[17:13:54.110] iteration 29292: loss: 0.049622, loss_s1: 0.030472, loss_fp: 0.002813, loss_freq: 0.022439
[17:13:54.754] iteration 29293: loss: 0.086028, loss_s1: 0.103160, loss_fp: 0.007247, loss_freq: 0.030091
[17:13:55.392] iteration 29294: loss: 0.051541, loss_s1: 0.040396, loss_fp: 0.012667, loss_freq: 0.011704
[17:13:56.016] iteration 29295: loss: 0.029049, loss_s1: 0.008382, loss_fp: 0.013269, loss_freq: 0.007633
[17:13:56.649] iteration 29296: loss: 0.042540, loss_s1: 0.042661, loss_fp: 0.003283, loss_freq: 0.013705
[17:13:57.323] iteration 29297: loss: 0.078414, loss_s1: 0.062531, loss_fp: 0.006696, loss_freq: 0.048938
[17:13:57.972] iteration 29298: loss: 0.054027, loss_s1: 0.019800, loss_fp: 0.010478, loss_freq: 0.008999
[17:13:58.629] iteration 29299: loss: 0.048850, loss_s1: 0.038720, loss_fp: 0.004510, loss_freq: 0.028193
[17:13:59.405] iteration 29300: loss: 0.049290, loss_s1: 0.016757, loss_fp: 0.004934, loss_freq: 0.022053
[17:14:00.113] iteration 29301: loss: 0.051747, loss_s1: 0.038327, loss_fp: 0.019266, loss_freq: 0.013155
[17:14:00.767] iteration 29302: loss: 0.054700, loss_s1: 0.042885, loss_fp: 0.002830, loss_freq: 0.021610
[17:14:01.450] iteration 29303: loss: 0.066268, loss_s1: 0.045639, loss_fp: 0.005230, loss_freq: 0.042178
[17:14:02.108] iteration 29304: loss: 0.054036, loss_s1: 0.029859, loss_fp: 0.003738, loss_freq: 0.029828
[17:14:02.737] iteration 29305: loss: 0.049748, loss_s1: 0.037141, loss_fp: 0.002793, loss_freq: 0.023578
[17:14:03.365] iteration 29306: loss: 0.056320, loss_s1: 0.027483, loss_fp: 0.002109, loss_freq: 0.041906
[17:14:03.999] iteration 29307: loss: 0.048035, loss_s1: 0.022521, loss_fp: 0.002947, loss_freq: 0.028360
[17:14:04.631] iteration 29308: loss: 0.038245, loss_s1: 0.017133, loss_fp: 0.002095, loss_freq: 0.026939
[17:14:05.264] iteration 29309: loss: 0.040697, loss_s1: 0.016223, loss_fp: 0.005563, loss_freq: 0.013970
[17:14:05.895] iteration 29310: loss: 0.020755, loss_s1: 0.005310, loss_fp: 0.000377, loss_freq: 0.006426
[17:14:06.523] iteration 29311: loss: 0.051824, loss_s1: 0.032980, loss_fp: 0.006038, loss_freq: 0.027374
[17:14:07.146] iteration 29312: loss: 0.050844, loss_s1: 0.045015, loss_fp: 0.003788, loss_freq: 0.009929
[17:14:07.774] iteration 29313: loss: 0.056122, loss_s1: 0.040420, loss_fp: 0.004746, loss_freq: 0.019642
[17:14:08.427] iteration 29314: loss: 0.064343, loss_s1: 0.042863, loss_fp: 0.001203, loss_freq: 0.042326
[17:14:09.063] iteration 29315: loss: 0.046038, loss_s1: 0.017896, loss_fp: 0.003361, loss_freq: 0.024696
[17:14:10.023] iteration 29316: loss: 0.054062, loss_s1: 0.065149, loss_fp: 0.000321, loss_freq: 0.005571
[17:14:10.656] iteration 29317: loss: 0.060474, loss_s1: 0.044204, loss_fp: 0.015721, loss_freq: 0.014405
[17:14:11.279] iteration 29318: loss: 0.059108, loss_s1: 0.047479, loss_fp: 0.003560, loss_freq: 0.037692
[17:14:11.922] iteration 29319: loss: 0.067676, loss_s1: 0.065596, loss_fp: 0.002013, loss_freq: 0.028006
[17:14:12.560] iteration 29320: loss: 0.053259, loss_s1: 0.051283, loss_fp: 0.003446, loss_freq: 0.028797
[17:14:13.192] iteration 29321: loss: 0.031686, loss_s1: 0.017753, loss_fp: 0.001213, loss_freq: 0.008743
[17:14:13.830] iteration 29322: loss: 0.035510, loss_s1: 0.019289, loss_fp: 0.003196, loss_freq: 0.015321
[17:14:14.448] iteration 29323: loss: 0.062139, loss_s1: 0.058974, loss_fp: 0.004098, loss_freq: 0.016149
[17:14:15.087] iteration 29324: loss: 0.030183, loss_s1: 0.012618, loss_fp: 0.003503, loss_freq: 0.008743
[17:14:15.708] iteration 29325: loss: 0.037746, loss_s1: 0.007862, loss_fp: 0.001683, loss_freq: 0.004981
[17:14:16.337] iteration 29326: loss: 0.066450, loss_s1: 0.050340, loss_fp: 0.002350, loss_freq: 0.049496
[17:14:16.967] iteration 29327: loss: 0.050298, loss_s1: 0.032244, loss_fp: 0.005124, loss_freq: 0.015496
[17:14:17.592] iteration 29328: loss: 0.069301, loss_s1: 0.087095, loss_fp: 0.007304, loss_freq: 0.008559
[17:14:18.220] iteration 29329: loss: 0.032302, loss_s1: 0.019574, loss_fp: 0.005703, loss_freq: 0.010170
[17:14:18.857] iteration 29330: loss: 0.050540, loss_s1: 0.024415, loss_fp: 0.003557, loss_freq: 0.038311
[17:14:19.493] iteration 29331: loss: 0.040109, loss_s1: 0.023694, loss_fp: 0.000706, loss_freq: 0.022500
[17:14:20.121] iteration 29332: loss: 0.047793, loss_s1: 0.019282, loss_fp: 0.005658, loss_freq: 0.018343
[17:14:20.808] iteration 29333: loss: 0.047077, loss_s1: 0.018315, loss_fp: 0.007979, loss_freq: 0.038651
[17:14:21.469] iteration 29334: loss: 0.039611, loss_s1: 0.023945, loss_fp: 0.001673, loss_freq: 0.026844
[17:14:22.116] iteration 29335: loss: 0.041492, loss_s1: 0.040469, loss_fp: 0.000729, loss_freq: 0.011108
[17:14:22.747] iteration 29336: loss: 0.058906, loss_s1: 0.032310, loss_fp: 0.002373, loss_freq: 0.047128
[17:14:23.374] iteration 29337: loss: 0.038408, loss_s1: 0.023532, loss_fp: 0.005302, loss_freq: 0.018531
[17:14:23.999] iteration 29338: loss: 0.035158, loss_s1: 0.016272, loss_fp: 0.001513, loss_freq: 0.023491
[17:14:24.623] iteration 29339: loss: 0.036914, loss_s1: 0.036403, loss_fp: 0.002342, loss_freq: 0.005617
[17:14:25.282] iteration 29340: loss: 0.030523, loss_s1: 0.016763, loss_fp: 0.002626, loss_freq: 0.008482
[17:14:25.916] iteration 29341: loss: 0.033669, loss_s1: 0.013270, loss_fp: 0.002123, loss_freq: 0.008421
[17:14:26.542] iteration 29342: loss: 0.062983, loss_s1: 0.027878, loss_fp: 0.002722, loss_freq: 0.042419
[17:14:27.181] iteration 29343: loss: 0.041576, loss_s1: 0.029437, loss_fp: 0.007500, loss_freq: 0.007007
[17:14:27.814] iteration 29344: loss: 0.042351, loss_s1: 0.017927, loss_fp: 0.001936, loss_freq: 0.016288
[17:14:28.444] iteration 29345: loss: 0.044083, loss_s1: 0.037491, loss_fp: 0.001540, loss_freq: 0.012346
[17:14:29.083] iteration 29346: loss: 0.038181, loss_s1: 0.027170, loss_fp: 0.004856, loss_freq: 0.008750
[17:14:29.707] iteration 29347: loss: 0.054563, loss_s1: 0.028558, loss_fp: 0.013133, loss_freq: 0.023118
[17:14:30.328] iteration 29348: loss: 0.059883, loss_s1: 0.040297, loss_fp: 0.003303, loss_freq: 0.050380
[17:14:30.955] iteration 29349: loss: 0.086918, loss_s1: 0.072065, loss_fp: 0.005958, loss_freq: 0.062718
[17:14:31.584] iteration 29350: loss: 0.039043, loss_s1: 0.014138, loss_fp: 0.001331, loss_freq: 0.011893
[17:14:32.217] iteration 29351: loss: 0.080266, loss_s1: 0.054479, loss_fp: 0.002652, loss_freq: 0.057739
[17:14:32.831] iteration 29352: loss: 0.045523, loss_s1: 0.033931, loss_fp: 0.000846, loss_freq: 0.019619
[17:14:33.463] iteration 29353: loss: 0.058969, loss_s1: 0.065433, loss_fp: 0.003576, loss_freq: 0.019038
[17:14:34.085] iteration 29354: loss: 0.101027, loss_s1: 0.102317, loss_fp: 0.006574, loss_freq: 0.041555
[17:14:34.713] iteration 29355: loss: 0.031624, loss_s1: 0.017998, loss_fp: 0.003513, loss_freq: 0.012633
[17:14:35.343] iteration 29356: loss: 0.031907, loss_s1: 0.014480, loss_fp: 0.004480, loss_freq: 0.004971
[17:14:35.986] iteration 29357: loss: 0.024727, loss_s1: 0.014636, loss_fp: 0.000992, loss_freq: 0.009214
[17:14:36.612] iteration 29358: loss: 0.042051, loss_s1: 0.043763, loss_fp: 0.001753, loss_freq: 0.005646
[17:14:37.242] iteration 29359: loss: 0.066161, loss_s1: 0.061374, loss_fp: 0.005817, loss_freq: 0.025808
[17:14:37.872] iteration 29360: loss: 0.038161, loss_s1: 0.015646, loss_fp: 0.000585, loss_freq: 0.003117
[17:14:38.496] iteration 29361: loss: 0.060947, loss_s1: 0.058363, loss_fp: 0.005151, loss_freq: 0.026804
[17:14:39.120] iteration 29362: loss: 0.063510, loss_s1: 0.064814, loss_fp: 0.003071, loss_freq: 0.018469
[17:14:39.741] iteration 29363: loss: 0.036662, loss_s1: 0.026816, loss_fp: 0.002446, loss_freq: 0.009869
[17:14:40.360] iteration 29364: loss: 0.046580, loss_s1: 0.041968, loss_fp: 0.001674, loss_freq: 0.022959
[17:14:40.982] iteration 29365: loss: 0.046117, loss_s1: 0.035506, loss_fp: 0.001393, loss_freq: 0.021612
[17:14:41.608] iteration 29366: loss: 0.033148, loss_s1: 0.019351, loss_fp: 0.005075, loss_freq: 0.005808
[17:14:42.226] iteration 29367: loss: 0.040494, loss_s1: 0.012818, loss_fp: 0.005877, loss_freq: 0.025286
[17:14:42.844] iteration 29368: loss: 0.027773, loss_s1: 0.012721, loss_fp: 0.002109, loss_freq: 0.008341
[17:14:43.478] iteration 29369: loss: 0.074876, loss_s1: 0.041268, loss_fp: 0.001711, loss_freq: 0.081927
[17:14:44.103] iteration 29370: loss: 0.054042, loss_s1: 0.066147, loss_fp: 0.001980, loss_freq: 0.008993
[17:14:44.722] iteration 29371: loss: 0.050647, loss_s1: 0.028718, loss_fp: 0.001560, loss_freq: 0.007256
[17:14:45.355] iteration 29372: loss: 0.052767, loss_s1: 0.052615, loss_fp: 0.007179, loss_freq: 0.015078
[17:14:45.978] iteration 29373: loss: 0.047028, loss_s1: 0.040920, loss_fp: 0.004258, loss_freq: 0.019425
[17:14:46.608] iteration 29374: loss: 0.077227, loss_s1: 0.026396, loss_fp: 0.002785, loss_freq: 0.035269
[17:14:47.236] iteration 29375: loss: 0.048335, loss_s1: 0.045121, loss_fp: 0.001331, loss_freq: 0.018268
[17:14:47.858] iteration 29376: loss: 0.037312, loss_s1: 0.018621, loss_fp: 0.008077, loss_freq: 0.014975
[17:14:48.483] iteration 29377: loss: 0.050472, loss_s1: 0.051223, loss_fp: 0.002654, loss_freq: 0.011562
[17:14:49.109] iteration 29378: loss: 0.075243, loss_s1: 0.066217, loss_fp: 0.008942, loss_freq: 0.029787
[17:14:49.738] iteration 29379: loss: 0.039517, loss_s1: 0.025386, loss_fp: 0.001320, loss_freq: 0.015273
[17:14:50.379] iteration 29380: loss: 0.059307, loss_s1: 0.053228, loss_fp: 0.004836, loss_freq: 0.022372
[17:14:51.067] iteration 29381: loss: 0.054330, loss_s1: 0.059047, loss_fp: 0.002256, loss_freq: 0.008686
[17:14:51.716] iteration 29382: loss: 0.120845, loss_s1: 0.106117, loss_fp: 0.020618, loss_freq: 0.061150
[17:14:52.364] iteration 29383: loss: 0.049009, loss_s1: 0.039782, loss_fp: 0.003788, loss_freq: 0.023718
[17:14:52.989] iteration 29384: loss: 0.036510, loss_s1: 0.022420, loss_fp: 0.003455, loss_freq: 0.012976
[17:14:53.608] iteration 29385: loss: 0.046325, loss_s1: 0.011601, loss_fp: 0.001502, loss_freq: 0.009097
[17:14:54.233] iteration 29386: loss: 0.033544, loss_s1: 0.020138, loss_fp: 0.001036, loss_freq: 0.015243
[17:14:54.854] iteration 29387: loss: 0.037408, loss_s1: 0.019120, loss_fp: 0.006395, loss_freq: 0.012981
[17:14:55.477] iteration 29388: loss: 0.049720, loss_s1: 0.032669, loss_fp: 0.005276, loss_freq: 0.032561
[17:14:56.102] iteration 29389: loss: 0.075155, loss_s1: 0.071206, loss_fp: 0.006245, loss_freq: 0.021487
[17:14:56.732] iteration 29390: loss: 0.057169, loss_s1: 0.045600, loss_fp: 0.003240, loss_freq: 0.030427
[17:14:57.359] iteration 29391: loss: 0.033858, loss_s1: 0.015244, loss_fp: 0.005838, loss_freq: 0.010955
[17:14:57.987] iteration 29392: loss: 0.033345, loss_s1: 0.031270, loss_fp: 0.003817, loss_freq: 0.006909
[17:14:58.610] iteration 29393: loss: 0.058913, loss_s1: 0.056514, loss_fp: 0.002112, loss_freq: 0.023299
[17:14:59.231] iteration 29394: loss: 0.043192, loss_s1: 0.025489, loss_fp: 0.002536, loss_freq: 0.022089
[17:14:59.854] iteration 29395: loss: 0.075616, loss_s1: 0.044324, loss_fp: 0.016846, loss_freq: 0.030487
[17:15:00.480] iteration 29396: loss: 0.030243, loss_s1: 0.014188, loss_fp: 0.004013, loss_freq: 0.006434
[17:15:01.105] iteration 29397: loss: 0.040195, loss_s1: 0.025179, loss_fp: 0.007104, loss_freq: 0.013255
[17:15:01.733] iteration 29398: loss: 0.044800, loss_s1: 0.027481, loss_fp: 0.002326, loss_freq: 0.021902
[17:15:02.356] iteration 29399: loss: 0.051779, loss_s1: 0.046375, loss_fp: 0.005973, loss_freq: 0.027601
[17:15:02.983] iteration 29400: loss: 0.043140, loss_s1: 0.024231, loss_fp: 0.001966, loss_freq: 0.018167
[17:15:06.174] iteration 29400 : mean_dice : 0.795308
[17:15:06.836] iteration 29401: loss: 0.068189, loss_s1: 0.024853, loss_fp: 0.007420, loss_freq: 0.071359
[17:15:07.468] iteration 29402: loss: 0.051881, loss_s1: 0.033001, loss_fp: 0.001416, loss_freq: 0.030714
[17:15:08.091] iteration 29403: loss: 0.030535, loss_s1: 0.024908, loss_fp: 0.000239, loss_freq: 0.004053
[17:15:08.804] iteration 29404: loss: 0.023788, loss_s1: 0.006062, loss_fp: 0.001296, loss_freq: 0.006670
[17:15:09.461] iteration 29405: loss: 0.060818, loss_s1: 0.064285, loss_fp: 0.004011, loss_freq: 0.024970
[17:15:10.130] iteration 29406: loss: 0.067901, loss_s1: 0.040831, loss_fp: 0.002704, loss_freq: 0.026509
[17:15:10.788] iteration 29407: loss: 0.039837, loss_s1: 0.022505, loss_fp: 0.002273, loss_freq: 0.023321
[17:15:11.414] iteration 29408: loss: 0.043930, loss_s1: 0.036145, loss_fp: 0.003521, loss_freq: 0.008027
[17:15:12.047] iteration 29409: loss: 0.054509, loss_s1: 0.070886, loss_fp: 0.001320, loss_freq: 0.009746
[17:15:12.683] iteration 29410: loss: 0.046021, loss_s1: 0.024844, loss_fp: 0.002977, loss_freq: 0.020188
[17:15:13.324] iteration 29411: loss: 0.055955, loss_s1: 0.048692, loss_fp: 0.000875, loss_freq: 0.018341
[17:15:13.963] iteration 29412: loss: 0.095290, loss_s1: 0.077819, loss_fp: 0.002753, loss_freq: 0.071885
[17:15:14.611] iteration 29413: loss: 0.034662, loss_s1: 0.018216, loss_fp: 0.007341, loss_freq: 0.010165
[17:15:15.259] iteration 29414: loss: 0.051166, loss_s1: 0.049906, loss_fp: 0.002469, loss_freq: 0.006140
[17:15:15.909] iteration 29415: loss: 0.047073, loss_s1: 0.029547, loss_fp: 0.002757, loss_freq: 0.021611
[17:15:16.542] iteration 29416: loss: 0.047061, loss_s1: 0.030182, loss_fp: 0.004586, loss_freq: 0.030114
[17:15:17.169] iteration 29417: loss: 0.079914, loss_s1: 0.044105, loss_fp: 0.010439, loss_freq: 0.057269
[17:15:17.809] iteration 29418: loss: 0.098049, loss_s1: 0.090517, loss_fp: 0.010914, loss_freq: 0.068484
[17:15:18.452] iteration 29419: loss: 0.027318, loss_s1: 0.007286, loss_fp: 0.001968, loss_freq: 0.012453
[17:15:19.083] iteration 29420: loss: 0.040325, loss_s1: 0.008035, loss_fp: 0.009587, loss_freq: 0.012504
[17:15:19.730] iteration 29421: loss: 0.054883, loss_s1: 0.047838, loss_fp: 0.001172, loss_freq: 0.026604
[17:15:20.359] iteration 29422: loss: 0.080773, loss_s1: 0.052454, loss_fp: 0.008370, loss_freq: 0.052615
[17:15:20.987] iteration 29423: loss: 0.061512, loss_s1: 0.032868, loss_fp: 0.003264, loss_freq: 0.058063
[17:15:21.623] iteration 29424: loss: 0.062673, loss_s1: 0.057455, loss_fp: 0.002553, loss_freq: 0.023164
[17:15:22.250] iteration 29425: loss: 0.072634, loss_s1: 0.061887, loss_fp: 0.016051, loss_freq: 0.029957
[17:15:22.875] iteration 29426: loss: 0.055383, loss_s1: 0.047259, loss_fp: 0.009043, loss_freq: 0.019502
[17:15:23.509] iteration 29427: loss: 0.035755, loss_s1: 0.024335, loss_fp: 0.002130, loss_freq: 0.017054
[17:15:24.133] iteration 29428: loss: 0.033996, loss_s1: 0.011659, loss_fp: 0.000685, loss_freq: 0.009205
[17:15:24.770] iteration 29429: loss: 0.090794, loss_s1: 0.089128, loss_fp: 0.013054, loss_freq: 0.028123
[17:15:25.391] iteration 29430: loss: 0.045057, loss_s1: 0.028775, loss_fp: 0.000814, loss_freq: 0.012379
[17:15:26.020] iteration 29431: loss: 0.049157, loss_s1: 0.032225, loss_fp: 0.001890, loss_freq: 0.025126
[17:15:26.644] iteration 29432: loss: 0.045529, loss_s1: 0.017029, loss_fp: 0.012974, loss_freq: 0.011441
[17:15:27.275] iteration 29433: loss: 0.058415, loss_s1: 0.051215, loss_fp: 0.009466, loss_freq: 0.022826
[17:15:27.910] iteration 29434: loss: 0.037682, loss_s1: 0.026227, loss_fp: 0.001229, loss_freq: 0.021136
[17:15:28.543] iteration 29435: loss: 0.058461, loss_s1: 0.049000, loss_fp: 0.002449, loss_freq: 0.033475
[17:15:29.182] iteration 29436: loss: 0.065652, loss_s1: 0.043472, loss_fp: 0.001073, loss_freq: 0.041417
[17:15:29.804] iteration 29437: loss: 0.051011, loss_s1: 0.040250, loss_fp: 0.009465, loss_freq: 0.010578
[17:15:30.435] iteration 29438: loss: 0.037399, loss_s1: 0.029348, loss_fp: 0.001483, loss_freq: 0.013123
[17:15:31.065] iteration 29439: loss: 0.033036, loss_s1: 0.020686, loss_fp: 0.007873, loss_freq: 0.010776
[17:15:31.696] iteration 29440: loss: 0.061693, loss_s1: 0.045361, loss_fp: 0.010980, loss_freq: 0.035752
[17:15:32.331] iteration 29441: loss: 0.053583, loss_s1: 0.021585, loss_fp: 0.001902, loss_freq: 0.010202
[17:15:32.960] iteration 29442: loss: 0.057380, loss_s1: 0.059404, loss_fp: 0.001168, loss_freq: 0.018035
[17:15:33.587] iteration 29443: loss: 0.047688, loss_s1: 0.052120, loss_fp: 0.002647, loss_freq: 0.012948
[17:15:34.218] iteration 29444: loss: 0.077979, loss_s1: 0.104431, loss_fp: 0.003076, loss_freq: 0.012846
[17:15:34.844] iteration 29445: loss: 0.043240, loss_s1: 0.029955, loss_fp: 0.003646, loss_freq: 0.015659
[17:15:35.473] iteration 29446: loss: 0.060304, loss_s1: 0.036719, loss_fp: 0.002160, loss_freq: 0.023735
[17:15:36.097] iteration 29447: loss: 0.051147, loss_s1: 0.023550, loss_fp: 0.002596, loss_freq: 0.036719
[17:15:36.723] iteration 29448: loss: 0.058188, loss_s1: 0.038559, loss_fp: 0.009473, loss_freq: 0.027208
[17:15:37.344] iteration 29449: loss: 0.080024, loss_s1: 0.052335, loss_fp: 0.002685, loss_freq: 0.053215
[17:15:38.006] iteration 29450: loss: 0.069150, loss_s1: 0.025787, loss_fp: 0.003176, loss_freq: 0.026310
[17:15:38.662] iteration 29451: loss: 0.060636, loss_s1: 0.037883, loss_fp: 0.005835, loss_freq: 0.042963
[17:15:39.321] iteration 29452: loss: 0.055663, loss_s1: 0.051493, loss_fp: 0.008237, loss_freq: 0.012656
[17:15:39.977] iteration 29453: loss: 0.029804, loss_s1: 0.020462, loss_fp: 0.001121, loss_freq: 0.011881
[17:15:40.624] iteration 29454: loss: 0.047713, loss_s1: 0.041120, loss_fp: 0.002886, loss_freq: 0.014119
[17:15:41.249] iteration 29455: loss: 0.047726, loss_s1: 0.040132, loss_fp: 0.001803, loss_freq: 0.019390
[17:15:41.868] iteration 29456: loss: 0.050177, loss_s1: 0.040652, loss_fp: 0.006089, loss_freq: 0.020413
[17:15:42.492] iteration 29457: loss: 0.047557, loss_s1: 0.042247, loss_fp: 0.007085, loss_freq: 0.006237
[17:15:43.118] iteration 29458: loss: 0.039358, loss_s1: 0.032847, loss_fp: 0.000657, loss_freq: 0.014339
[17:15:44.066] iteration 29459: loss: 0.036953, loss_s1: 0.028298, loss_fp: 0.001429, loss_freq: 0.006183
[17:15:44.704] iteration 29460: loss: 0.076322, loss_s1: 0.083922, loss_fp: 0.002244, loss_freq: 0.027329
[17:15:45.346] iteration 29461: loss: 0.036772, loss_s1: 0.017714, loss_fp: 0.001831, loss_freq: 0.029405
[17:15:45.999] iteration 29462: loss: 0.068439, loss_s1: 0.044744, loss_fp: 0.006100, loss_freq: 0.029147
[17:15:46.617] iteration 29463: loss: 0.047800, loss_s1: 0.022135, loss_fp: 0.006961, loss_freq: 0.042043
[17:15:47.254] iteration 29464: loss: 0.042785, loss_s1: 0.039207, loss_fp: 0.010938, loss_freq: 0.003694
[17:15:47.876] iteration 29465: loss: 0.039479, loss_s1: 0.046623, loss_fp: 0.001437, loss_freq: 0.006410
[17:15:48.495] iteration 29466: loss: 0.042762, loss_s1: 0.033340, loss_fp: 0.004301, loss_freq: 0.012565
[17:15:49.138] iteration 29467: loss: 0.048522, loss_s1: 0.049667, loss_fp: 0.008558, loss_freq: 0.008446
[17:15:49.757] iteration 29468: loss: 0.040440, loss_s1: 0.022476, loss_fp: 0.001129, loss_freq: 0.004331
[17:15:50.379] iteration 29469: loss: 0.048967, loss_s1: 0.033406, loss_fp: 0.002088, loss_freq: 0.025422
[17:15:51.022] iteration 29470: loss: 0.041466, loss_s1: 0.028538, loss_fp: 0.002794, loss_freq: 0.007799
[17:15:51.651] iteration 29471: loss: 0.034898, loss_s1: 0.016412, loss_fp: 0.001085, loss_freq: 0.013936
[17:15:52.285] iteration 29472: loss: 0.033896, loss_s1: 0.019534, loss_fp: 0.002842, loss_freq: 0.008344
[17:15:52.911] iteration 29473: loss: 0.035796, loss_s1: 0.021502, loss_fp: 0.001288, loss_freq: 0.016475
[17:15:53.538] iteration 29474: loss: 0.049810, loss_s1: 0.034570, loss_fp: 0.007211, loss_freq: 0.025452
[17:15:54.174] iteration 29475: loss: 0.060247, loss_s1: 0.045300, loss_fp: 0.002277, loss_freq: 0.031376
[17:15:54.806] iteration 29476: loss: 0.054160, loss_s1: 0.034848, loss_fp: 0.002330, loss_freq: 0.039227
[17:15:55.437] iteration 29477: loss: 0.060019, loss_s1: 0.032549, loss_fp: 0.000988, loss_freq: 0.028315
[17:15:56.064] iteration 29478: loss: 0.041735, loss_s1: 0.033482, loss_fp: 0.003260, loss_freq: 0.010315
[17:15:56.697] iteration 29479: loss: 0.079874, loss_s1: 0.039552, loss_fp: 0.002759, loss_freq: 0.046846
[17:15:57.330] iteration 29480: loss: 0.048108, loss_s1: 0.048706, loss_fp: 0.002992, loss_freq: 0.016292
[17:15:57.954] iteration 29481: loss: 0.065420, loss_s1: 0.047818, loss_fp: 0.005093, loss_freq: 0.046831
[17:15:58.580] iteration 29482: loss: 0.028626, loss_s1: 0.019661, loss_fp: 0.002550, loss_freq: 0.006519
[17:15:59.219] iteration 29483: loss: 0.038540, loss_s1: 0.026697, loss_fp: 0.002075, loss_freq: 0.007993
[17:15:59.851] iteration 29484: loss: 0.081826, loss_s1: 0.035798, loss_fp: 0.025415, loss_freq: 0.050629
[17:16:00.476] iteration 29485: loss: 0.056347, loss_s1: 0.047228, loss_fp: 0.004729, loss_freq: 0.023651
[17:16:01.109] iteration 29486: loss: 0.032533, loss_s1: 0.014976, loss_fp: 0.002877, loss_freq: 0.008931
[17:16:01.733] iteration 29487: loss: 0.062517, loss_s1: 0.065469, loss_fp: 0.001912, loss_freq: 0.009871
[17:16:02.363] iteration 29488: loss: 0.033975, loss_s1: 0.014961, loss_fp: 0.002573, loss_freq: 0.015802
[17:16:02.992] iteration 29489: loss: 0.036919, loss_s1: 0.027075, loss_fp: 0.003236, loss_freq: 0.006362
[17:16:03.615] iteration 29490: loss: 0.050379, loss_s1: 0.018010, loss_fp: 0.002343, loss_freq: 0.014062
[17:16:04.357] iteration 29491: loss: 0.102355, loss_s1: 0.116426, loss_fp: 0.011452, loss_freq: 0.047948
[17:16:05.273] iteration 29492: loss: 0.083703, loss_s1: 0.074772, loss_fp: 0.006966, loss_freq: 0.047678
[17:16:06.026] iteration 29493: loss: 0.087231, loss_s1: 0.083031, loss_fp: 0.018111, loss_freq: 0.012841
[17:16:06.744] iteration 29494: loss: 0.042955, loss_s1: 0.038690, loss_fp: 0.002401, loss_freq: 0.010659
[17:16:07.400] iteration 29495: loss: 0.047101, loss_s1: 0.021485, loss_fp: 0.005947, loss_freq: 0.020159
[17:16:08.030] iteration 29496: loss: 0.066039, loss_s1: 0.061403, loss_fp: 0.005570, loss_freq: 0.029966
[17:16:08.656] iteration 29497: loss: 0.083519, loss_s1: 0.047611, loss_fp: 0.001720, loss_freq: 0.026255
[17:16:09.272] iteration 29498: loss: 0.039527, loss_s1: 0.043864, loss_fp: 0.000948, loss_freq: 0.007324
[17:16:09.897] iteration 29499: loss: 0.037459, loss_s1: 0.019759, loss_fp: 0.001154, loss_freq: 0.021685
[17:16:10.527] iteration 29500: loss: 0.062033, loss_s1: 0.059133, loss_fp: 0.005865, loss_freq: 0.031998
[17:16:11.155] iteration 29501: loss: 0.025990, loss_s1: 0.003220, loss_fp: 0.001234, loss_freq: 0.007648
[17:16:11.777] iteration 29502: loss: 0.043643, loss_s1: 0.030145, loss_fp: 0.005368, loss_freq: 0.016687
[17:16:12.396] iteration 29503: loss: 0.042186, loss_s1: 0.012355, loss_fp: 0.001403, loss_freq: 0.015154
[17:16:13.024] iteration 29504: loss: 0.049608, loss_s1: 0.033062, loss_fp: 0.004749, loss_freq: 0.026255
[17:16:13.644] iteration 29505: loss: 0.035335, loss_s1: 0.014860, loss_fp: 0.001630, loss_freq: 0.020893
[17:16:14.275] iteration 29506: loss: 0.054407, loss_s1: 0.049805, loss_fp: 0.003903, loss_freq: 0.020264
[17:16:14.907] iteration 29507: loss: 0.060516, loss_s1: 0.058240, loss_fp: 0.004000, loss_freq: 0.028817
[17:16:15.540] iteration 29508: loss: 0.042639, loss_s1: 0.030890, loss_fp: 0.005332, loss_freq: 0.017125
[17:16:16.169] iteration 29509: loss: 0.028158, loss_s1: 0.019467, loss_fp: 0.001188, loss_freq: 0.007047
[17:16:16.797] iteration 29510: loss: 0.047828, loss_s1: 0.018509, loss_fp: 0.004173, loss_freq: 0.020503
[17:16:17.426] iteration 29511: loss: 0.050591, loss_s1: 0.021382, loss_fp: 0.001313, loss_freq: 0.029988
[17:16:18.050] iteration 29512: loss: 0.082873, loss_s1: 0.049852, loss_fp: 0.007648, loss_freq: 0.082711
[17:16:18.672] iteration 29513: loss: 0.048001, loss_s1: 0.027860, loss_fp: 0.001252, loss_freq: 0.013105
[17:16:19.302] iteration 29514: loss: 0.045466, loss_s1: 0.033559, loss_fp: 0.001204, loss_freq: 0.015677
[17:16:19.938] iteration 29515: loss: 0.034182, loss_s1: 0.024931, loss_fp: 0.003774, loss_freq: 0.010697
[17:16:20.568] iteration 29516: loss: 0.033661, loss_s1: 0.013897, loss_fp: 0.000742, loss_freq: 0.007717
[17:16:21.196] iteration 29517: loss: 0.046211, loss_s1: 0.015364, loss_fp: 0.004930, loss_freq: 0.042566
[17:16:21.877] iteration 29518: loss: 0.054429, loss_s1: 0.050176, loss_fp: 0.002079, loss_freq: 0.011393
[17:16:22.525] iteration 29519: loss: 0.055322, loss_s1: 0.062015, loss_fp: 0.002747, loss_freq: 0.009655
[17:16:23.174] iteration 29520: loss: 0.050364, loss_s1: 0.044622, loss_fp: 0.003221, loss_freq: 0.013244
[17:16:23.827] iteration 29521: loss: 0.071720, loss_s1: 0.054647, loss_fp: 0.015040, loss_freq: 0.042667
[17:16:24.455] iteration 29522: loss: 0.055549, loss_s1: 0.050825, loss_fp: 0.001401, loss_freq: 0.023234
[17:16:25.086] iteration 29523: loss: 0.066697, loss_s1: 0.031159, loss_fp: 0.001932, loss_freq: 0.054608
[17:16:25.714] iteration 29524: loss: 0.040625, loss_s1: 0.023174, loss_fp: 0.005778, loss_freq: 0.016257
[17:16:26.333] iteration 29525: loss: 0.054761, loss_s1: 0.031420, loss_fp: 0.008430, loss_freq: 0.031241
[17:16:26.959] iteration 29526: loss: 0.033907, loss_s1: 0.015096, loss_fp: 0.003899, loss_freq: 0.015358
[17:16:27.590] iteration 29527: loss: 0.039714, loss_s1: 0.030494, loss_fp: 0.002868, loss_freq: 0.009190
[17:16:28.213] iteration 29528: loss: 0.033179, loss_s1: 0.010218, loss_fp: 0.007160, loss_freq: 0.008854
[17:16:28.838] iteration 29529: loss: 0.043579, loss_s1: 0.034491, loss_fp: 0.001386, loss_freq: 0.012126
[17:16:29.458] iteration 29530: loss: 0.071446, loss_s1: 0.034214, loss_fp: 0.004479, loss_freq: 0.068005
[17:16:30.088] iteration 29531: loss: 0.080441, loss_s1: 0.104419, loss_fp: 0.002203, loss_freq: 0.016440
[17:16:30.713] iteration 29532: loss: 0.050197, loss_s1: 0.016287, loss_fp: 0.008465, loss_freq: 0.022978
[17:16:31.348] iteration 29533: loss: 0.092050, loss_s1: 0.060158, loss_fp: 0.006767, loss_freq: 0.095096
[17:16:31.975] iteration 29534: loss: 0.038496, loss_s1: 0.026569, loss_fp: 0.004256, loss_freq: 0.009275
[17:16:32.597] iteration 29535: loss: 0.044319, loss_s1: 0.032021, loss_fp: 0.010232, loss_freq: 0.014950
[17:16:33.230] iteration 29536: loss: 0.034684, loss_s1: 0.016323, loss_fp: 0.003115, loss_freq: 0.011685
[17:16:33.862] iteration 29537: loss: 0.066105, loss_s1: 0.050599, loss_fp: 0.016163, loss_freq: 0.031159
[17:16:34.485] iteration 29538: loss: 0.063940, loss_s1: 0.032880, loss_fp: 0.007564, loss_freq: 0.017669
[17:16:35.107] iteration 29539: loss: 0.046604, loss_s1: 0.015792, loss_fp: 0.010946, loss_freq: 0.034724
[17:16:35.736] iteration 29540: loss: 0.048438, loss_s1: 0.033358, loss_fp: 0.003352, loss_freq: 0.015185
[17:16:36.369] iteration 29541: loss: 0.055542, loss_s1: 0.060981, loss_fp: 0.000372, loss_freq: 0.017138
[17:16:36.993] iteration 29542: loss: 0.053532, loss_s1: 0.038803, loss_fp: 0.006666, loss_freq: 0.028607
[17:16:37.607] iteration 29543: loss: 0.064101, loss_s1: 0.046228, loss_fp: 0.023269, loss_freq: 0.018910
[17:16:38.235] iteration 29544: loss: 0.056948, loss_s1: 0.040146, loss_fp: 0.004874, loss_freq: 0.037378
[17:16:38.859] iteration 29545: loss: 0.048440, loss_s1: 0.030279, loss_fp: 0.001275, loss_freq: 0.012000
[17:16:39.482] iteration 29546: loss: 0.041643, loss_s1: 0.021329, loss_fp: 0.001417, loss_freq: 0.027385
[17:16:40.112] iteration 29547: loss: 0.036178, loss_s1: 0.023582, loss_fp: 0.000700, loss_freq: 0.012545
[17:16:40.743] iteration 29548: loss: 0.052765, loss_s1: 0.055545, loss_fp: 0.005644, loss_freq: 0.016363
[17:16:41.373] iteration 29549: loss: 0.045700, loss_s1: 0.033053, loss_fp: 0.003251, loss_freq: 0.017010
[17:16:42.001] iteration 29550: loss: 0.042841, loss_s1: 0.025878, loss_fp: 0.000884, loss_freq: 0.023126
[17:16:42.625] iteration 29551: loss: 0.044095, loss_s1: 0.017944, loss_fp: 0.001120, loss_freq: 0.018873
[17:16:43.251] iteration 29552: loss: 0.046281, loss_s1: 0.023696, loss_fp: 0.002856, loss_freq: 0.009163
[17:16:43.880] iteration 29553: loss: 0.041526, loss_s1: 0.022738, loss_fp: 0.005254, loss_freq: 0.021327
[17:16:44.506] iteration 29554: loss: 0.049426, loss_s1: 0.021874, loss_fp: 0.017251, loss_freq: 0.004319
[17:16:45.119] iteration 29555: loss: 0.052971, loss_s1: 0.033920, loss_fp: 0.002596, loss_freq: 0.032201
[17:16:45.792] iteration 29556: loss: 0.038920, loss_s1: 0.020969, loss_fp: 0.001392, loss_freq: 0.014506
[17:16:46.437] iteration 29557: loss: 0.049225, loss_s1: 0.037878, loss_fp: 0.001584, loss_freq: 0.019739
[17:16:47.082] iteration 29558: loss: 0.071298, loss_s1: 0.063803, loss_fp: 0.002189, loss_freq: 0.042270
[17:16:47.713] iteration 29559: loss: 0.036933, loss_s1: 0.024577, loss_fp: 0.000300, loss_freq: 0.018861
[17:16:48.337] iteration 29560: loss: 0.067824, loss_s1: 0.049572, loss_fp: 0.000846, loss_freq: 0.039699
[17:16:48.962] iteration 29561: loss: 0.101020, loss_s1: 0.128055, loss_fp: 0.007448, loss_freq: 0.034036
[17:16:49.592] iteration 29562: loss: 0.039142, loss_s1: 0.030261, loss_fp: 0.004508, loss_freq: 0.012539
[17:16:50.222] iteration 29563: loss: 0.062313, loss_s1: 0.045501, loss_fp: 0.012376, loss_freq: 0.018113
[17:16:50.841] iteration 29564: loss: 0.039514, loss_s1: 0.011052, loss_fp: 0.001238, loss_freq: 0.027137
[17:16:51.467] iteration 29565: loss: 0.077357, loss_s1: 0.065350, loss_fp: 0.011011, loss_freq: 0.038364
[17:16:52.095] iteration 29566: loss: 0.049178, loss_s1: 0.054237, loss_fp: 0.001595, loss_freq: 0.015707
[17:16:52.728] iteration 29567: loss: 0.086668, loss_s1: 0.054717, loss_fp: 0.008961, loss_freq: 0.058821
[17:16:53.352] iteration 29568: loss: 0.049852, loss_s1: 0.045706, loss_fp: 0.003476, loss_freq: 0.015682
[17:16:53.974] iteration 29569: loss: 0.045845, loss_s1: 0.017010, loss_fp: 0.002275, loss_freq: 0.037221
[17:16:54.602] iteration 29570: loss: 0.035486, loss_s1: 0.022390, loss_fp: 0.003871, loss_freq: 0.016721
[17:16:55.233] iteration 29571: loss: 0.047687, loss_s1: 0.035340, loss_fp: 0.001776, loss_freq: 0.010464
[17:16:55.855] iteration 29572: loss: 0.041270, loss_s1: 0.020822, loss_fp: 0.010996, loss_freq: 0.011703
[17:16:56.479] iteration 29573: loss: 0.052905, loss_s1: 0.050436, loss_fp: 0.001149, loss_freq: 0.010275
[17:16:57.107] iteration 29574: loss: 0.050670, loss_s1: 0.044797, loss_fp: 0.004155, loss_freq: 0.016697
[17:16:57.730] iteration 29575: loss: 0.068823, loss_s1: 0.064479, loss_fp: 0.008995, loss_freq: 0.024030
[17:16:58.347] iteration 29576: loss: 0.052099, loss_s1: 0.044229, loss_fp: 0.003153, loss_freq: 0.013630
[17:16:58.973] iteration 29577: loss: 0.034389, loss_s1: 0.018258, loss_fp: 0.002411, loss_freq: 0.020623
[17:16:59.603] iteration 29578: loss: 0.046861, loss_s1: 0.024050, loss_fp: 0.005916, loss_freq: 0.022826
[17:17:00.224] iteration 29579: loss: 0.048800, loss_s1: 0.039133, loss_fp: 0.002060, loss_freq: 0.019353
[17:17:00.841] iteration 29580: loss: 0.054914, loss_s1: 0.028724, loss_fp: 0.001629, loss_freq: 0.034053
[17:17:01.463] iteration 29581: loss: 0.027934, loss_s1: 0.007223, loss_fp: 0.002409, loss_freq: 0.015285
[17:17:02.083] iteration 29582: loss: 0.045580, loss_s1: 0.025755, loss_fp: 0.010723, loss_freq: 0.029020
[17:17:02.710] iteration 29583: loss: 0.049120, loss_s1: 0.045489, loss_fp: 0.009517, loss_freq: 0.014890
[17:17:03.358] iteration 29584: loss: 0.038248, loss_s1: 0.017971, loss_fp: 0.002552, loss_freq: 0.012786
[17:17:04.004] iteration 29585: loss: 0.042674, loss_s1: 0.026122, loss_fp: 0.001358, loss_freq: 0.029138
[17:17:04.653] iteration 29586: loss: 0.065653, loss_s1: 0.047320, loss_fp: 0.005953, loss_freq: 0.036733
[17:17:05.271] iteration 29587: loss: 0.043276, loss_s1: 0.030979, loss_fp: 0.008125, loss_freq: 0.014902
[17:17:05.901] iteration 29588: loss: 0.044831, loss_s1: 0.013151, loss_fp: 0.011638, loss_freq: 0.028199
[17:17:06.551] iteration 29589: loss: 0.049055, loss_s1: 0.031029, loss_fp: 0.005875, loss_freq: 0.024793
[17:17:07.210] iteration 29590: loss: 0.068236, loss_s1: 0.046025, loss_fp: 0.003027, loss_freq: 0.028717
[17:17:07.871] iteration 29591: loss: 0.035673, loss_s1: 0.019773, loss_fp: 0.002054, loss_freq: 0.014968
[17:17:08.528] iteration 29592: loss: 0.057927, loss_s1: 0.054740, loss_fp: 0.001412, loss_freq: 0.021806
[17:17:09.157] iteration 29593: loss: 0.044425, loss_s1: 0.022504, loss_fp: 0.001487, loss_freq: 0.031274
[17:17:09.784] iteration 29594: loss: 0.065075, loss_s1: 0.061784, loss_fp: 0.006623, loss_freq: 0.028704
[17:17:10.412] iteration 29595: loss: 0.074161, loss_s1: 0.082685, loss_fp: 0.005975, loss_freq: 0.021409
[17:17:11.041] iteration 29596: loss: 0.027647, loss_s1: 0.013355, loss_fp: 0.001550, loss_freq: 0.010444
[17:17:11.674] iteration 29597: loss: 0.056738, loss_s1: 0.045235, loss_fp: 0.005407, loss_freq: 0.017154
[17:17:12.301] iteration 29598: loss: 0.056999, loss_s1: 0.022968, loss_fp: 0.003907, loss_freq: 0.009173
[17:17:12.937] iteration 29599: loss: 0.041555, loss_s1: 0.024022, loss_fp: 0.004095, loss_freq: 0.018697
[17:17:13.581] iteration 29600: loss: 0.138038, loss_s1: 0.100367, loss_fp: 0.035122, loss_freq: 0.103321
[17:17:16.970] iteration 29600 : mean_dice : 0.799650
[17:17:17.657] iteration 29601: loss: 0.037122, loss_s1: 0.013936, loss_fp: 0.003356, loss_freq: 0.030159
[17:17:18.657] iteration 29602: loss: 0.041034, loss_s1: 0.028014, loss_fp: 0.002898, loss_freq: 0.010450
[17:17:19.337] iteration 29603: loss: 0.040472, loss_s1: 0.027858, loss_fp: 0.004316, loss_freq: 0.012319
[17:17:19.988] iteration 29604: loss: 0.034370, loss_s1: 0.026338, loss_fp: 0.000553, loss_freq: 0.013648
[17:17:20.637] iteration 29605: loss: 0.063609, loss_s1: 0.065194, loss_fp: 0.004966, loss_freq: 0.019586
[17:17:21.283] iteration 29606: loss: 0.044068, loss_s1: 0.022522, loss_fp: 0.000255, loss_freq: 0.037799
[17:17:21.920] iteration 29607: loss: 0.033599, loss_s1: 0.021855, loss_fp: 0.003955, loss_freq: 0.006819
[17:17:22.548] iteration 29608: loss: 0.034241, loss_s1: 0.022757, loss_fp: 0.001974, loss_freq: 0.016078
[17:17:23.171] iteration 29609: loss: 0.040183, loss_s1: 0.009585, loss_fp: 0.000903, loss_freq: 0.029257
[17:17:23.805] iteration 29610: loss: 0.052044, loss_s1: 0.045701, loss_fp: 0.005677, loss_freq: 0.019800
[17:17:24.431] iteration 29611: loss: 0.041312, loss_s1: 0.016347, loss_fp: 0.001288, loss_freq: 0.001622
[17:17:25.061] iteration 29612: loss: 0.076572, loss_s1: 0.052518, loss_fp: 0.009981, loss_freq: 0.059885
[17:17:25.696] iteration 29613: loss: 0.047351, loss_s1: 0.024289, loss_fp: 0.002633, loss_freq: 0.030592
[17:17:26.324] iteration 29614: loss: 0.061092, loss_s1: 0.053052, loss_fp: 0.010199, loss_freq: 0.025792
[17:17:26.956] iteration 29615: loss: 0.033430, loss_s1: 0.030468, loss_fp: 0.004482, loss_freq: 0.006499
[17:17:27.583] iteration 29616: loss: 0.064277, loss_s1: 0.059745, loss_fp: 0.006721, loss_freq: 0.023155
[17:17:28.206] iteration 29617: loss: 0.054684, loss_s1: 0.038258, loss_fp: 0.003641, loss_freq: 0.026845
[17:17:28.831] iteration 29618: loss: 0.049227, loss_s1: 0.033467, loss_fp: 0.003338, loss_freq: 0.024071
[17:17:29.465] iteration 29619: loss: 0.075297, loss_s1: 0.073139, loss_fp: 0.002903, loss_freq: 0.038692
[17:17:30.094] iteration 29620: loss: 0.052130, loss_s1: 0.038912, loss_fp: 0.001070, loss_freq: 0.035762
[17:17:30.716] iteration 29621: loss: 0.031150, loss_s1: 0.017867, loss_fp: 0.002659, loss_freq: 0.010999
[17:17:31.331] iteration 29622: loss: 0.071376, loss_s1: 0.030018, loss_fp: 0.005508, loss_freq: 0.055615
[17:17:31.959] iteration 29623: loss: 0.035616, loss_s1: 0.018777, loss_fp: 0.001708, loss_freq: 0.025351
[17:17:32.585] iteration 29624: loss: 0.051210, loss_s1: 0.043497, loss_fp: 0.002102, loss_freq: 0.028184
[17:17:33.217] iteration 29625: loss: 0.038319, loss_s1: 0.038451, loss_fp: 0.001601, loss_freq: 0.004143
[17:17:33.844] iteration 29626: loss: 0.046603, loss_s1: 0.042154, loss_fp: 0.006579, loss_freq: 0.009140
[17:17:34.477] iteration 29627: loss: 0.059480, loss_s1: 0.021187, loss_fp: 0.011015, loss_freq: 0.044825
[17:17:35.111] iteration 29628: loss: 0.039573, loss_s1: 0.014856, loss_fp: 0.000992, loss_freq: 0.024099
[17:17:35.733] iteration 29629: loss: 0.056500, loss_s1: 0.049033, loss_fp: 0.001770, loss_freq: 0.028863
[17:17:36.365] iteration 29630: loss: 0.052779, loss_s1: 0.037403, loss_fp: 0.002386, loss_freq: 0.029935
[17:17:36.987] iteration 29631: loss: 0.042791, loss_s1: 0.024381, loss_fp: 0.004635, loss_freq: 0.011584
[17:17:37.610] iteration 29632: loss: 0.041729, loss_s1: 0.034986, loss_fp: 0.002220, loss_freq: 0.008961
[17:17:38.232] iteration 29633: loss: 0.048917, loss_s1: 0.039775, loss_fp: 0.002441, loss_freq: 0.017533
[17:17:38.863] iteration 29634: loss: 0.065420, loss_s1: 0.042462, loss_fp: 0.006291, loss_freq: 0.051621
[17:17:39.492] iteration 29635: loss: 0.073469, loss_s1: 0.086062, loss_fp: 0.004628, loss_freq: 0.028040
[17:17:40.120] iteration 29636: loss: 0.075695, loss_s1: 0.079082, loss_fp: 0.008572, loss_freq: 0.019575
[17:17:40.749] iteration 29637: loss: 0.055858, loss_s1: 0.043848, loss_fp: 0.002168, loss_freq: 0.030745
[17:17:41.375] iteration 29638: loss: 0.063899, loss_s1: 0.049514, loss_fp: 0.002204, loss_freq: 0.032178
[17:17:42.009] iteration 29639: loss: 0.035431, loss_s1: 0.030425, loss_fp: 0.002529, loss_freq: 0.005857
[17:17:42.634] iteration 29640: loss: 0.077958, loss_s1: 0.065784, loss_fp: 0.005101, loss_freq: 0.036220
[17:17:43.264] iteration 29641: loss: 0.045143, loss_s1: 0.050703, loss_fp: 0.004474, loss_freq: 0.006767
[17:17:43.894] iteration 29642: loss: 0.040763, loss_s1: 0.040004, loss_fp: 0.003443, loss_freq: 0.003703
[17:17:44.516] iteration 29643: loss: 0.035094, loss_s1: 0.024861, loss_fp: 0.001569, loss_freq: 0.019030
[17:17:45.143] iteration 29644: loss: 0.050034, loss_s1: 0.036698, loss_fp: 0.004016, loss_freq: 0.005398
[17:17:45.767] iteration 29645: loss: 0.049970, loss_s1: 0.045519, loss_fp: 0.001902, loss_freq: 0.021860
[17:17:46.393] iteration 29646: loss: 0.046015, loss_s1: 0.019689, loss_fp: 0.001236, loss_freq: 0.006034
[17:17:47.019] iteration 29647: loss: 0.082148, loss_s1: 0.100301, loss_fp: 0.004613, loss_freq: 0.022268
[17:17:47.652] iteration 29648: loss: 0.049656, loss_s1: 0.024135, loss_fp: 0.004228, loss_freq: 0.034715
[17:17:48.279] iteration 29649: loss: 0.044557, loss_s1: 0.029828, loss_fp: 0.006632, loss_freq: 0.018354
[17:17:48.902] iteration 29650: loss: 0.039582, loss_s1: 0.021221, loss_fp: 0.003901, loss_freq: 0.022115
[17:17:49.523] iteration 29651: loss: 0.051982, loss_s1: 0.029460, loss_fp: 0.004961, loss_freq: 0.023598
[17:17:50.142] iteration 29652: loss: 0.033891, loss_s1: 0.011982, loss_fp: 0.004277, loss_freq: 0.012262
[17:17:50.765] iteration 29653: loss: 0.050224, loss_s1: 0.044425, loss_fp: 0.001787, loss_freq: 0.022556
[17:17:51.390] iteration 29654: loss: 0.039580, loss_s1: 0.021930, loss_fp: 0.000653, loss_freq: 0.017173
[17:17:52.016] iteration 29655: loss: 0.083261, loss_s1: 0.065562, loss_fp: 0.005980, loss_freq: 0.070029
[17:17:52.642] iteration 29656: loss: 0.032097, loss_s1: 0.028965, loss_fp: 0.000927, loss_freq: 0.005329
[17:17:53.273] iteration 29657: loss: 0.046198, loss_s1: 0.011005, loss_fp: 0.001870, loss_freq: 0.023605
[17:17:53.894] iteration 29658: loss: 0.057758, loss_s1: 0.052682, loss_fp: 0.010811, loss_freq: 0.013866
[17:17:54.517] iteration 29659: loss: 0.037172, loss_s1: 0.026583, loss_fp: 0.001615, loss_freq: 0.016924
[17:17:55.152] iteration 29660: loss: 0.048432, loss_s1: 0.033236, loss_fp: 0.001006, loss_freq: 0.024775
[17:17:55.784] iteration 29661: loss: 0.041211, loss_s1: 0.029455, loss_fp: 0.004906, loss_freq: 0.014270
[17:17:56.415] iteration 29662: loss: 0.049702, loss_s1: 0.022662, loss_fp: 0.005551, loss_freq: 0.019006
[17:17:57.049] iteration 29663: loss: 0.032966, loss_s1: 0.019012, loss_fp: 0.001586, loss_freq: 0.012829
[17:17:57.672] iteration 29664: loss: 0.064275, loss_s1: 0.047746, loss_fp: 0.004658, loss_freq: 0.032433
[17:17:58.293] iteration 29665: loss: 0.045215, loss_s1: 0.020820, loss_fp: 0.002074, loss_freq: 0.027255
[17:17:58.930] iteration 29666: loss: 0.082032, loss_s1: 0.062029, loss_fp: 0.003210, loss_freq: 0.028536
[17:17:59.561] iteration 29667: loss: 0.044314, loss_s1: 0.022475, loss_fp: 0.004801, loss_freq: 0.021994
[17:18:00.194] iteration 29668: loss: 0.085355, loss_s1: 0.088288, loss_fp: 0.016172, loss_freq: 0.017743
[17:18:00.820] iteration 29669: loss: 0.035165, loss_s1: 0.023169, loss_fp: 0.004359, loss_freq: 0.017133
[17:18:01.447] iteration 29670: loss: 0.027233, loss_s1: 0.011680, loss_fp: 0.002075, loss_freq: 0.007720
[17:18:02.072] iteration 29671: loss: 0.051580, loss_s1: 0.031778, loss_fp: 0.003885, loss_freq: 0.003173
[17:18:02.705] iteration 29672: loss: 0.048939, loss_s1: 0.044442, loss_fp: 0.003548, loss_freq: 0.013982
[17:18:03.336] iteration 29673: loss: 0.046768, loss_s1: 0.030183, loss_fp: 0.004974, loss_freq: 0.021562
[17:18:03.963] iteration 29674: loss: 0.107304, loss_s1: 0.162133, loss_fp: 0.002169, loss_freq: 0.016875
[17:18:04.588] iteration 29675: loss: 0.080759, loss_s1: 0.035246, loss_fp: 0.014378, loss_freq: 0.062478
[17:18:05.207] iteration 29676: loss: 0.056287, loss_s1: 0.044158, loss_fp: 0.008701, loss_freq: 0.036360
[17:18:05.838] iteration 29677: loss: 0.043030, loss_s1: 0.037388, loss_fp: 0.001399, loss_freq: 0.016612
[17:18:06.455] iteration 29678: loss: 0.055078, loss_s1: 0.040491, loss_fp: 0.001837, loss_freq: 0.039252
[17:18:07.080] iteration 29679: loss: 0.042891, loss_s1: 0.017269, loss_fp: 0.003922, loss_freq: 0.024939
[17:18:07.701] iteration 29680: loss: 0.093949, loss_s1: 0.085833, loss_fp: 0.003482, loss_freq: 0.061795
[17:18:08.326] iteration 29681: loss: 0.085180, loss_s1: 0.049898, loss_fp: 0.017005, loss_freq: 0.031071
[17:18:08.957] iteration 29682: loss: 0.085139, loss_s1: 0.111402, loss_fp: 0.000717, loss_freq: 0.012802
[17:18:09.623] iteration 29683: loss: 0.057599, loss_s1: 0.023457, loss_fp: 0.002987, loss_freq: 0.057017
[17:18:10.292] iteration 29684: loss: 0.043090, loss_s1: 0.032460, loss_fp: 0.002727, loss_freq: 0.015676
[17:18:10.935] iteration 29685: loss: 0.041984, loss_s1: 0.028215, loss_fp: 0.003376, loss_freq: 0.024582
[17:18:11.621] iteration 29686: loss: 0.068353, loss_s1: 0.037311, loss_fp: 0.009820, loss_freq: 0.037610
[17:18:12.275] iteration 29687: loss: 0.043745, loss_s1: 0.013505, loss_fp: 0.000841, loss_freq: 0.037990
[17:18:12.899] iteration 29688: loss: 0.031101, loss_s1: 0.002979, loss_fp: 0.001602, loss_freq: 0.001481
[17:18:13.522] iteration 29689: loss: 0.038027, loss_s1: 0.017496, loss_fp: 0.001266, loss_freq: 0.010515
[17:18:14.144] iteration 29690: loss: 0.051178, loss_s1: 0.036055, loss_fp: 0.002750, loss_freq: 0.027551
[17:18:14.779] iteration 29691: loss: 0.043890, loss_s1: 0.036935, loss_fp: 0.003103, loss_freq: 0.022408
[17:18:15.413] iteration 29692: loss: 0.055429, loss_s1: 0.041275, loss_fp: 0.004499, loss_freq: 0.016867
[17:18:16.037] iteration 29693: loss: 0.041422, loss_s1: 0.036141, loss_fp: 0.003146, loss_freq: 0.012218
[17:18:16.668] iteration 29694: loss: 0.066713, loss_s1: 0.092425, loss_fp: 0.001926, loss_freq: 0.008628
[17:18:17.308] iteration 29695: loss: 0.035010, loss_s1: 0.021576, loss_fp: 0.002359, loss_freq: 0.014835
[17:18:17.936] iteration 29696: loss: 0.041803, loss_s1: 0.008149, loss_fp: 0.001572, loss_freq: 0.032925
[17:18:18.560] iteration 29697: loss: 0.038107, loss_s1: 0.032659, loss_fp: 0.001305, loss_freq: 0.004915
[17:18:19.188] iteration 29698: loss: 0.052867, loss_s1: 0.029962, loss_fp: 0.005029, loss_freq: 0.026160
[17:18:19.821] iteration 29699: loss: 0.050663, loss_s1: 0.031077, loss_fp: 0.002410, loss_freq: 0.018247
[17:18:20.456] iteration 29700: loss: 0.035737, loss_s1: 0.020622, loss_fp: 0.004745, loss_freq: 0.010189
[17:18:21.128] iteration 29701: loss: 0.055888, loss_s1: 0.027981, loss_fp: 0.009806, loss_freq: 0.040639
[17:18:21.752] iteration 29702: loss: 0.045201, loss_s1: 0.028606, loss_fp: 0.001786, loss_freq: 0.028339
[17:18:22.378] iteration 29703: loss: 0.076135, loss_s1: 0.044743, loss_fp: 0.008761, loss_freq: 0.047470
[17:18:23.012] iteration 29704: loss: 0.041324, loss_s1: 0.028340, loss_fp: 0.002533, loss_freq: 0.019748
[17:18:23.639] iteration 29705: loss: 0.037202, loss_s1: 0.025118, loss_fp: 0.003071, loss_freq: 0.005689
[17:18:24.263] iteration 29706: loss: 0.054112, loss_s1: 0.026857, loss_fp: 0.003614, loss_freq: 0.012249
[17:18:24.888] iteration 29707: loss: 0.043899, loss_s1: 0.017174, loss_fp: 0.001783, loss_freq: 0.013632
[17:18:25.518] iteration 29708: loss: 0.082232, loss_s1: 0.079379, loss_fp: 0.005917, loss_freq: 0.037263
[17:18:26.142] iteration 29709: loss: 0.052323, loss_s1: 0.040564, loss_fp: 0.004842, loss_freq: 0.025841
[17:18:26.774] iteration 29710: loss: 0.068418, loss_s1: 0.044929, loss_fp: 0.003579, loss_freq: 0.026153
[17:18:27.400] iteration 29711: loss: 0.096068, loss_s1: 0.082652, loss_fp: 0.009931, loss_freq: 0.071294
[17:18:28.031] iteration 29712: loss: 0.037095, loss_s1: 0.028044, loss_fp: 0.001198, loss_freq: 0.012889
[17:18:28.660] iteration 29713: loss: 0.052151, loss_s1: 0.053467, loss_fp: 0.001655, loss_freq: 0.023964
[17:18:29.285] iteration 29714: loss: 0.036214, loss_s1: 0.014899, loss_fp: 0.001265, loss_freq: 0.008554
[17:18:29.947] iteration 29715: loss: 0.044697, loss_s1: 0.030148, loss_fp: 0.009131, loss_freq: 0.011469
[17:18:30.609] iteration 29716: loss: 0.050430, loss_s1: 0.044370, loss_fp: 0.001354, loss_freq: 0.011629
[17:18:31.276] iteration 29717: loss: 0.038419, loss_s1: 0.022473, loss_fp: 0.003063, loss_freq: 0.013330
[17:18:31.918] iteration 29718: loss: 0.052965, loss_s1: 0.051288, loss_fp: 0.008398, loss_freq: 0.010972
[17:18:32.555] iteration 29719: loss: 0.046054, loss_s1: 0.032626, loss_fp: 0.002191, loss_freq: 0.014361
[17:18:33.192] iteration 29720: loss: 0.035995, loss_s1: 0.023009, loss_fp: 0.005523, loss_freq: 0.014966
[17:18:33.827] iteration 29721: loss: 0.054968, loss_s1: 0.040010, loss_fp: 0.001059, loss_freq: 0.030451
[17:18:34.478] iteration 29722: loss: 0.081307, loss_s1: 0.085112, loss_fp: 0.003172, loss_freq: 0.033187
[17:18:35.119] iteration 29723: loss: 0.058733, loss_s1: 0.040737, loss_fp: 0.007329, loss_freq: 0.012911
[17:18:35.760] iteration 29724: loss: 0.043790, loss_s1: 0.018743, loss_fp: 0.007629, loss_freq: 0.029251
[17:18:36.402] iteration 29725: loss: 0.058844, loss_s1: 0.032156, loss_fp: 0.002321, loss_freq: 0.059244
[17:18:37.037] iteration 29726: loss: 0.062088, loss_s1: 0.059096, loss_fp: 0.002087, loss_freq: 0.032698
[17:18:37.700] iteration 29727: loss: 0.050663, loss_s1: 0.021787, loss_fp: 0.012522, loss_freq: 0.015193
[17:18:38.344] iteration 29728: loss: 0.039477, loss_s1: 0.024065, loss_fp: 0.003254, loss_freq: 0.019828
[17:18:38.996] iteration 29729: loss: 0.056127, loss_s1: 0.040186, loss_fp: 0.004842, loss_freq: 0.027040
[17:18:39.660] iteration 29730: loss: 0.078345, loss_s1: 0.077341, loss_fp: 0.004185, loss_freq: 0.048012
[17:18:40.308] iteration 29731: loss: 0.037966, loss_s1: 0.015360, loss_fp: 0.001708, loss_freq: 0.018206
[17:18:40.945] iteration 29732: loss: 0.053042, loss_s1: 0.043497, loss_fp: 0.002812, loss_freq: 0.017758
[17:18:41.567] iteration 29733: loss: 0.047036, loss_s1: 0.032763, loss_fp: 0.003337, loss_freq: 0.019474
[17:18:42.196] iteration 29734: loss: 0.044849, loss_s1: 0.040973, loss_fp: 0.002112, loss_freq: 0.008274
[17:18:42.833] iteration 29735: loss: 0.063401, loss_s1: 0.058955, loss_fp: 0.001289, loss_freq: 0.028236
[17:18:43.463] iteration 29736: loss: 0.046439, loss_s1: 0.034246, loss_fp: 0.004501, loss_freq: 0.019041
[17:18:44.089] iteration 29737: loss: 0.043891, loss_s1: 0.028752, loss_fp: 0.004982, loss_freq: 0.017251
[17:18:44.720] iteration 29738: loss: 0.048687, loss_s1: 0.049562, loss_fp: 0.003107, loss_freq: 0.009036
[17:18:45.346] iteration 29739: loss: 0.029595, loss_s1: 0.012313, loss_fp: 0.003316, loss_freq: 0.010682
[17:18:45.975] iteration 29740: loss: 0.044658, loss_s1: 0.038355, loss_fp: 0.004160, loss_freq: 0.015263
[17:18:46.599] iteration 29741: loss: 0.050484, loss_s1: 0.020555, loss_fp: 0.005604, loss_freq: 0.011973
[17:18:47.227] iteration 29742: loss: 0.062016, loss_s1: 0.062937, loss_fp: 0.004344, loss_freq: 0.017937
[17:18:47.852] iteration 29743: loss: 0.045219, loss_s1: 0.042198, loss_fp: 0.003091, loss_freq: 0.005602
[17:18:48.477] iteration 29744: loss: 0.038225, loss_s1: 0.008047, loss_fp: 0.001784, loss_freq: 0.040863
[17:18:49.464] iteration 29745: loss: 0.042129, loss_s1: 0.032790, loss_fp: 0.001959, loss_freq: 0.010402
[17:18:50.106] iteration 29746: loss: 0.065082, loss_s1: 0.059810, loss_fp: 0.003051, loss_freq: 0.018059
[17:18:50.761] iteration 29747: loss: 0.037028, loss_s1: 0.024980, loss_fp: 0.001919, loss_freq: 0.021520
[17:18:51.401] iteration 29748: loss: 0.060241, loss_s1: 0.048575, loss_fp: 0.002182, loss_freq: 0.025019
[17:18:52.045] iteration 29749: loss: 0.056020, loss_s1: 0.050105, loss_fp: 0.003640, loss_freq: 0.032068
[17:18:52.685] iteration 29750: loss: 0.036312, loss_s1: 0.010025, loss_fp: 0.004346, loss_freq: 0.009321
[17:18:53.309] iteration 29751: loss: 0.024059, loss_s1: 0.013008, loss_fp: 0.001760, loss_freq: 0.007606
[17:18:53.928] iteration 29752: loss: 0.041661, loss_s1: 0.017460, loss_fp: 0.009211, loss_freq: 0.010779
[17:18:54.571] iteration 29753: loss: 0.068031, loss_s1: 0.079484, loss_fp: 0.001680, loss_freq: 0.021097
[17:18:55.207] iteration 29754: loss: 0.033027, loss_s1: 0.014496, loss_fp: 0.000420, loss_freq: 0.003641
[17:18:55.843] iteration 29755: loss: 0.051184, loss_s1: 0.025227, loss_fp: 0.007689, loss_freq: 0.027680
[17:18:56.478] iteration 29756: loss: 0.049595, loss_s1: 0.032246, loss_fp: 0.007362, loss_freq: 0.019239
[17:18:57.120] iteration 29757: loss: 0.046249, loss_s1: 0.040366, loss_fp: 0.003091, loss_freq: 0.014654
[17:18:57.763] iteration 29758: loss: 0.027628, loss_s1: 0.015313, loss_fp: 0.004691, loss_freq: 0.006932
[17:18:58.418] iteration 29759: loss: 0.057841, loss_s1: 0.056243, loss_fp: 0.002860, loss_freq: 0.013235
[17:18:59.048] iteration 29760: loss: 0.037414, loss_s1: 0.021520, loss_fp: 0.006123, loss_freq: 0.019077
[17:18:59.673] iteration 29761: loss: 0.086480, loss_s1: 0.057718, loss_fp: 0.002743, loss_freq: 0.037746
[17:19:00.286] iteration 29762: loss: 0.049503, loss_s1: 0.039647, loss_fp: 0.003197, loss_freq: 0.026202
[17:19:00.922] iteration 29763: loss: 0.039749, loss_s1: 0.032191, loss_fp: 0.000934, loss_freq: 0.021708
[17:19:01.544] iteration 29764: loss: 0.031963, loss_s1: 0.023698, loss_fp: 0.001592, loss_freq: 0.012927
[17:19:02.168] iteration 29765: loss: 0.071085, loss_s1: 0.037402, loss_fp: 0.002986, loss_freq: 0.047555
[17:19:02.791] iteration 29766: loss: 0.032882, loss_s1: 0.010765, loss_fp: 0.004922, loss_freq: 0.017635
[17:19:03.429] iteration 29767: loss: 0.042390, loss_s1: 0.023776, loss_fp: 0.001661, loss_freq: 0.023842
[17:19:04.064] iteration 29768: loss: 0.033262, loss_s1: 0.017349, loss_fp: 0.003842, loss_freq: 0.006838
[17:19:04.692] iteration 29769: loss: 0.064896, loss_s1: 0.062858, loss_fp: 0.002170, loss_freq: 0.033622
[17:19:05.323] iteration 29770: loss: 0.039864, loss_s1: 0.025124, loss_fp: 0.001316, loss_freq: 0.016100
[17:19:05.939] iteration 29771: loss: 0.083586, loss_s1: 0.071638, loss_fp: 0.011458, loss_freq: 0.043546
[17:19:06.562] iteration 29772: loss: 0.038507, loss_s1: 0.031524, loss_fp: 0.000823, loss_freq: 0.008348
[17:19:07.185] iteration 29773: loss: 0.043560, loss_s1: 0.018302, loss_fp: 0.001345, loss_freq: 0.016298
[17:19:07.807] iteration 29774: loss: 0.040311, loss_s1: 0.015651, loss_fp: 0.003372, loss_freq: 0.012235
[17:19:08.421] iteration 29775: loss: 0.050639, loss_s1: 0.026347, loss_fp: 0.001010, loss_freq: 0.014811
[17:19:09.051] iteration 29776: loss: 0.048953, loss_s1: 0.033669, loss_fp: 0.006588, loss_freq: 0.023304
[17:19:09.683] iteration 29777: loss: 0.067652, loss_s1: 0.039062, loss_fp: 0.018854, loss_freq: 0.049882
[17:19:10.316] iteration 29778: loss: 0.080145, loss_s1: 0.051538, loss_fp: 0.008629, loss_freq: 0.061007
[17:19:10.942] iteration 29779: loss: 0.061628, loss_s1: 0.031986, loss_fp: 0.005998, loss_freq: 0.020276
[17:19:11.566] iteration 29780: loss: 0.039481, loss_s1: 0.029966, loss_fp: 0.003194, loss_freq: 0.012707
[17:19:12.192] iteration 29781: loss: 0.051973, loss_s1: 0.029080, loss_fp: 0.005460, loss_freq: 0.024380
[17:19:12.818] iteration 29782: loss: 0.032395, loss_s1: 0.022778, loss_fp: 0.002079, loss_freq: 0.010352
[17:19:13.437] iteration 29783: loss: 0.068985, loss_s1: 0.067979, loss_fp: 0.009029, loss_freq: 0.021980
[17:19:14.061] iteration 29784: loss: 0.036388, loss_s1: 0.024816, loss_fp: 0.002351, loss_freq: 0.016914
[17:19:14.689] iteration 29785: loss: 0.058129, loss_s1: 0.040589, loss_fp: 0.011119, loss_freq: 0.023002
[17:19:15.318] iteration 29786: loss: 0.033328, loss_s1: 0.027536, loss_fp: 0.004196, loss_freq: 0.007528
[17:19:15.945] iteration 29787: loss: 0.047244, loss_s1: 0.046468, loss_fp: 0.000402, loss_freq: 0.005451
[17:19:16.569] iteration 29788: loss: 0.091691, loss_s1: 0.073894, loss_fp: 0.008779, loss_freq: 0.067072
[17:19:17.187] iteration 29789: loss: 0.032350, loss_s1: 0.009808, loss_fp: 0.000692, loss_freq: 0.005206
[17:19:17.853] iteration 29790: loss: 0.065533, loss_s1: 0.032895, loss_fp: 0.003263, loss_freq: 0.056122
[17:19:18.508] iteration 29791: loss: 0.047428, loss_s1: 0.041211, loss_fp: 0.000841, loss_freq: 0.015351
[17:19:19.159] iteration 29792: loss: 0.040621, loss_s1: 0.021907, loss_fp: 0.004373, loss_freq: 0.023270
[17:19:19.781] iteration 29793: loss: 0.041426, loss_s1: 0.046159, loss_fp: 0.001174, loss_freq: 0.006425
[17:19:20.407] iteration 29794: loss: 0.047459, loss_s1: 0.046192, loss_fp: 0.001677, loss_freq: 0.014672
[17:19:21.032] iteration 29795: loss: 0.057957, loss_s1: 0.047658, loss_fp: 0.003656, loss_freq: 0.030547
[17:19:21.664] iteration 29796: loss: 0.042555, loss_s1: 0.019824, loss_fp: 0.004689, loss_freq: 0.024180
[17:19:22.304] iteration 29797: loss: 0.031459, loss_s1: 0.011701, loss_fp: 0.002110, loss_freq: 0.011447
[17:19:22.945] iteration 29798: loss: 0.125188, loss_s1: 0.116398, loss_fp: 0.004152, loss_freq: 0.093049
[17:19:23.569] iteration 29799: loss: 0.046273, loss_s1: 0.038078, loss_fp: 0.002390, loss_freq: 0.008281
[17:19:24.200] iteration 29800: loss: 0.055371, loss_s1: 0.030507, loss_fp: 0.001253, loss_freq: 0.017116
[17:19:27.515] iteration 29800 : mean_dice : 0.796326
[17:19:28.168] iteration 29801: loss: 0.068769, loss_s1: 0.061920, loss_fp: 0.008341, loss_freq: 0.034145
[17:19:28.790] iteration 29802: loss: 0.040734, loss_s1: 0.029542, loss_fp: 0.000692, loss_freq: 0.017351
[17:19:29.417] iteration 29803: loss: 0.039341, loss_s1: 0.025964, loss_fp: 0.001889, loss_freq: 0.013981
[17:19:30.050] iteration 29804: loss: 0.055690, loss_s1: 0.047705, loss_fp: 0.000877, loss_freq: 0.017127
[17:19:30.686] iteration 29805: loss: 0.045443, loss_s1: 0.029074, loss_fp: 0.004963, loss_freq: 0.020335
[17:19:31.309] iteration 29806: loss: 0.073908, loss_s1: 0.060993, loss_fp: 0.003594, loss_freq: 0.030917
[17:19:31.940] iteration 29807: loss: 0.056354, loss_s1: 0.046248, loss_fp: 0.008184, loss_freq: 0.021166
[17:19:32.571] iteration 29808: loss: 0.037748, loss_s1: 0.020274, loss_fp: 0.001213, loss_freq: 0.016142
[17:19:33.197] iteration 29809: loss: 0.058579, loss_s1: 0.063295, loss_fp: 0.004134, loss_freq: 0.009636
[17:19:33.821] iteration 29810: loss: 0.047999, loss_s1: 0.019638, loss_fp: 0.001497, loss_freq: 0.018686
[17:19:34.469] iteration 29811: loss: 0.083544, loss_s1: 0.081851, loss_fp: 0.004588, loss_freq: 0.044292
[17:19:35.115] iteration 29812: loss: 0.053641, loss_s1: 0.047158, loss_fp: 0.004224, loss_freq: 0.030387
[17:19:35.761] iteration 29813: loss: 0.032857, loss_s1: 0.015303, loss_fp: 0.002143, loss_freq: 0.012548
[17:19:36.416] iteration 29814: loss: 0.060877, loss_s1: 0.031573, loss_fp: 0.000442, loss_freq: 0.021509
[17:19:37.061] iteration 29815: loss: 0.036198, loss_s1: 0.024413, loss_fp: 0.002420, loss_freq: 0.011577
[17:19:37.723] iteration 29816: loss: 0.099251, loss_s1: 0.086876, loss_fp: 0.018823, loss_freq: 0.055979
[17:19:38.377] iteration 29817: loss: 0.047106, loss_s1: 0.052055, loss_fp: 0.002751, loss_freq: 0.012010
[17:19:39.026] iteration 29818: loss: 0.068207, loss_s1: 0.040816, loss_fp: 0.000974, loss_freq: 0.048124
[17:19:39.680] iteration 29819: loss: 0.081255, loss_s1: 0.095844, loss_fp: 0.004532, loss_freq: 0.035171
[17:19:40.345] iteration 29820: loss: 0.042928, loss_s1: 0.020929, loss_fp: 0.004918, loss_freq: 0.010393
[17:19:40.988] iteration 29821: loss: 0.053903, loss_s1: 0.037053, loss_fp: 0.001878, loss_freq: 0.040980
[17:19:41.618] iteration 29822: loss: 0.046803, loss_s1: 0.031343, loss_fp: 0.003903, loss_freq: 0.012576
[17:19:42.234] iteration 29823: loss: 0.071954, loss_s1: 0.077941, loss_fp: 0.003549, loss_freq: 0.026757
[17:19:42.853] iteration 29824: loss: 0.106957, loss_s1: 0.072306, loss_fp: 0.009305, loss_freq: 0.023693
[17:19:43.474] iteration 29825: loss: 0.045536, loss_s1: 0.029915, loss_fp: 0.000706, loss_freq: 0.022597
[17:19:44.103] iteration 29826: loss: 0.043815, loss_s1: 0.024407, loss_fp: 0.001965, loss_freq: 0.028447
[17:19:44.727] iteration 29827: loss: 0.048552, loss_s1: 0.046177, loss_fp: 0.005000, loss_freq: 0.009270
[17:19:45.346] iteration 29828: loss: 0.055149, loss_s1: 0.057745, loss_fp: 0.006815, loss_freq: 0.017891
[17:19:45.974] iteration 29829: loss: 0.059801, loss_s1: 0.053263, loss_fp: 0.002899, loss_freq: 0.024490
[17:19:46.602] iteration 29830: loss: 0.060010, loss_s1: 0.040273, loss_fp: 0.001865, loss_freq: 0.044659
[17:19:47.235] iteration 29831: loss: 0.049586, loss_s1: 0.030949, loss_fp: 0.003065, loss_freq: 0.027237
[17:19:47.859] iteration 29832: loss: 0.029619, loss_s1: 0.014157, loss_fp: 0.000495, loss_freq: 0.011671
[17:19:48.482] iteration 29833: loss: 0.041365, loss_s1: 0.026451, loss_fp: 0.003019, loss_freq: 0.021874
[17:19:49.107] iteration 29834: loss: 0.049922, loss_s1: 0.057391, loss_fp: 0.003497, loss_freq: 0.015432
[17:19:49.732] iteration 29835: loss: 0.058404, loss_s1: 0.018424, loss_fp: 0.002691, loss_freq: 0.048562
[17:19:50.351] iteration 29836: loss: 0.056651, loss_s1: 0.052937, loss_fp: 0.004971, loss_freq: 0.013649
[17:19:50.993] iteration 29837: loss: 0.063353, loss_s1: 0.070292, loss_fp: 0.007394, loss_freq: 0.007404
[17:19:51.646] iteration 29838: loss: 0.049594, loss_s1: 0.033296, loss_fp: 0.000988, loss_freq: 0.015125
[17:19:52.304] iteration 29839: loss: 0.039566, loss_s1: 0.011635, loss_fp: 0.001996, loss_freq: 0.029946
[17:19:52.950] iteration 29840: loss: 0.050699, loss_s1: 0.040481, loss_fp: 0.008051, loss_freq: 0.011508
[17:19:53.602] iteration 29841: loss: 0.063232, loss_s1: 0.050481, loss_fp: 0.011580, loss_freq: 0.030680
[17:19:54.244] iteration 29842: loss: 0.051477, loss_s1: 0.033824, loss_fp: 0.001405, loss_freq: 0.031563
[17:19:54.981] iteration 29843: loss: 0.029385, loss_s1: 0.010430, loss_fp: 0.004040, loss_freq: 0.006788
[17:19:55.633] iteration 29844: loss: 0.076328, loss_s1: 0.050915, loss_fp: 0.016226, loss_freq: 0.050170
[17:19:56.296] iteration 29845: loss: 0.028304, loss_s1: 0.014819, loss_fp: 0.002241, loss_freq: 0.009727
[17:19:56.967] iteration 29846: loss: 0.046441, loss_s1: 0.021058, loss_fp: 0.003160, loss_freq: 0.010489
[17:19:57.606] iteration 29847: loss: 0.048859, loss_s1: 0.049276, loss_fp: 0.001125, loss_freq: 0.017381
[17:19:58.247] iteration 29848: loss: 0.043890, loss_s1: 0.036212, loss_fp: 0.004824, loss_freq: 0.012066
[17:19:58.890] iteration 29849: loss: 0.047556, loss_s1: 0.030167, loss_fp: 0.001531, loss_freq: 0.021657
[17:19:59.545] iteration 29850: loss: 0.055754, loss_s1: 0.044639, loss_fp: 0.005307, loss_freq: 0.024352
[17:20:00.209] iteration 29851: loss: 0.075742, loss_s1: 0.054814, loss_fp: 0.003528, loss_freq: 0.035119
[17:20:00.833] iteration 29852: loss: 0.048349, loss_s1: 0.047582, loss_fp: 0.003877, loss_freq: 0.015933
[17:20:01.471] iteration 29853: loss: 0.069026, loss_s1: 0.058485, loss_fp: 0.004002, loss_freq: 0.035767
[17:20:02.097] iteration 29854: loss: 0.095758, loss_s1: 0.087325, loss_fp: 0.013814, loss_freq: 0.060194
[17:20:02.724] iteration 29855: loss: 0.056247, loss_s1: 0.053040, loss_fp: 0.006381, loss_freq: 0.014437
[17:20:03.389] iteration 29856: loss: 0.046295, loss_s1: 0.044196, loss_fp: 0.001979, loss_freq: 0.018731
[17:20:04.045] iteration 29857: loss: 0.036577, loss_s1: 0.012889, loss_fp: 0.005095, loss_freq: 0.008538
[17:20:04.689] iteration 29858: loss: 0.073909, loss_s1: 0.095419, loss_fp: 0.004613, loss_freq: 0.010113
[17:20:05.336] iteration 29859: loss: 0.054519, loss_s1: 0.007308, loss_fp: 0.002558, loss_freq: 0.038203
[17:20:05.972] iteration 29860: loss: 0.047696, loss_s1: 0.024705, loss_fp: 0.002551, loss_freq: 0.027861
[17:20:06.608] iteration 29861: loss: 0.055689, loss_s1: 0.042524, loss_fp: 0.013606, loss_freq: 0.021500
[17:20:07.260] iteration 29862: loss: 0.073391, loss_s1: 0.064865, loss_fp: 0.001548, loss_freq: 0.031105
[17:20:07.902] iteration 29863: loss: 0.037877, loss_s1: 0.028410, loss_fp: 0.004669, loss_freq: 0.013183
[17:20:08.548] iteration 29864: loss: 0.052482, loss_s1: 0.031698, loss_fp: 0.001662, loss_freq: 0.026082
[17:20:09.208] iteration 29865: loss: 0.074268, loss_s1: 0.070364, loss_fp: 0.001842, loss_freq: 0.047596
[17:20:09.865] iteration 29866: loss: 0.087819, loss_s1: 0.095281, loss_fp: 0.011509, loss_freq: 0.026282
[17:20:10.524] iteration 29867: loss: 0.042247, loss_s1: 0.041155, loss_fp: 0.002507, loss_freq: 0.010814
[17:20:11.172] iteration 29868: loss: 0.035289, loss_s1: 0.024735, loss_fp: 0.003217, loss_freq: 0.014705
[17:20:11.820] iteration 29869: loss: 0.071558, loss_s1: 0.080208, loss_fp: 0.009782, loss_freq: 0.021244
[17:20:12.491] iteration 29870: loss: 0.043054, loss_s1: 0.029434, loss_fp: 0.002439, loss_freq: 0.014264
[17:20:13.144] iteration 29871: loss: 0.049386, loss_s1: 0.034395, loss_fp: 0.001487, loss_freq: 0.032052
[17:20:13.801] iteration 29872: loss: 0.058739, loss_s1: 0.059968, loss_fp: 0.007010, loss_freq: 0.013749
[17:20:14.503] iteration 29873: loss: 0.048974, loss_s1: 0.029081, loss_fp: 0.014213, loss_freq: 0.024113
[17:20:15.156] iteration 29874: loss: 0.049145, loss_s1: 0.052566, loss_fp: 0.001478, loss_freq: 0.006719
[17:20:15.824] iteration 29875: loss: 0.066317, loss_s1: 0.051334, loss_fp: 0.005816, loss_freq: 0.034914
[17:20:16.478] iteration 29876: loss: 0.038185, loss_s1: 0.020324, loss_fp: 0.008377, loss_freq: 0.007107
[17:20:17.142] iteration 29877: loss: 0.042877, loss_s1: 0.039437, loss_fp: 0.010030, loss_freq: 0.006744
[17:20:17.770] iteration 29878: loss: 0.050162, loss_s1: 0.014107, loss_fp: 0.002057, loss_freq: 0.046947
[17:20:18.403] iteration 29879: loss: 0.041189, loss_s1: 0.011209, loss_fp: 0.005060, loss_freq: 0.015692
[17:20:19.034] iteration 29880: loss: 0.037732, loss_s1: 0.021946, loss_fp: 0.004716, loss_freq: 0.019450
[17:20:19.657] iteration 29881: loss: 0.053241, loss_s1: 0.025440, loss_fp: 0.006961, loss_freq: 0.036405
[17:20:20.314] iteration 29882: loss: 0.029005, loss_s1: 0.012039, loss_fp: 0.003913, loss_freq: 0.010635
[17:20:20.967] iteration 29883: loss: 0.036531, loss_s1: 0.028544, loss_fp: 0.008776, loss_freq: 0.009671
[17:20:21.622] iteration 29884: loss: 0.040774, loss_s1: 0.029318, loss_fp: 0.006614, loss_freq: 0.012046
[17:20:22.267] iteration 29885: loss: 0.051553, loss_s1: 0.023176, loss_fp: 0.002918, loss_freq: 0.023890
[17:20:22.881] iteration 29886: loss: 0.100941, loss_s1: 0.085914, loss_fp: 0.011188, loss_freq: 0.064748
[17:20:23.507] iteration 29887: loss: 0.042842, loss_s1: 0.047871, loss_fp: 0.001527, loss_freq: 0.004606
[17:20:24.503] iteration 29888: loss: 0.028454, loss_s1: 0.018041, loss_fp: 0.002176, loss_freq: 0.006220
[17:20:25.131] iteration 29889: loss: 0.060479, loss_s1: 0.045865, loss_fp: 0.001354, loss_freq: 0.031297
[17:20:25.752] iteration 29890: loss: 0.032016, loss_s1: 0.023164, loss_fp: 0.001665, loss_freq: 0.011924
[17:20:26.371] iteration 29891: loss: 0.037164, loss_s1: 0.018667, loss_fp: 0.003463, loss_freq: 0.012000
[17:20:27.008] iteration 29892: loss: 0.063208, loss_s1: 0.063869, loss_fp: 0.003591, loss_freq: 0.032174
[17:20:27.634] iteration 29893: loss: 0.071832, loss_s1: 0.027864, loss_fp: 0.001499, loss_freq: 0.003322
[17:20:28.262] iteration 29894: loss: 0.038238, loss_s1: 0.029784, loss_fp: 0.002854, loss_freq: 0.018306
[17:20:28.892] iteration 29895: loss: 0.039546, loss_s1: 0.013768, loss_fp: 0.002327, loss_freq: 0.016566
[17:20:29.521] iteration 29896: loss: 0.036731, loss_s1: 0.021148, loss_fp: 0.003641, loss_freq: 0.014136
[17:20:30.148] iteration 29897: loss: 0.038948, loss_s1: 0.014275, loss_fp: 0.002529, loss_freq: 0.006121
[17:20:30.765] iteration 29898: loss: 0.041633, loss_s1: 0.022189, loss_fp: 0.006883, loss_freq: 0.010321
[17:20:31.379] iteration 29899: loss: 0.045625, loss_s1: 0.022861, loss_fp: 0.007492, loss_freq: 0.015440
[17:20:32.003] iteration 29900: loss: 0.050188, loss_s1: 0.030551, loss_fp: 0.009091, loss_freq: 0.022948
[17:20:32.662] iteration 29901: loss: 0.039837, loss_s1: 0.035933, loss_fp: 0.001670, loss_freq: 0.008730
[17:20:33.321] iteration 29902: loss: 0.048093, loss_s1: 0.040938, loss_fp: 0.001072, loss_freq: 0.015270
[17:20:33.969] iteration 29903: loss: 0.046622, loss_s1: 0.039763, loss_fp: 0.003025, loss_freq: 0.018036
[17:20:34.623] iteration 29904: loss: 0.050896, loss_s1: 0.032989, loss_fp: 0.003277, loss_freq: 0.022409
[17:20:35.249] iteration 29905: loss: 0.032035, loss_s1: 0.009701, loss_fp: 0.004253, loss_freq: 0.020773
[17:20:35.876] iteration 29906: loss: 0.041136, loss_s1: 0.029916, loss_fp: 0.001679, loss_freq: 0.022327
[17:20:36.500] iteration 29907: loss: 0.037479, loss_s1: 0.030348, loss_fp: 0.002268, loss_freq: 0.013664
[17:20:37.126] iteration 29908: loss: 0.078832, loss_s1: 0.048387, loss_fp: 0.010267, loss_freq: 0.062190
[17:20:37.742] iteration 29909: loss: 0.047229, loss_s1: 0.041507, loss_fp: 0.002960, loss_freq: 0.020594
[17:20:38.399] iteration 29910: loss: 0.047616, loss_s1: 0.035550, loss_fp: 0.003795, loss_freq: 0.025773
[17:20:39.051] iteration 29911: loss: 0.048245, loss_s1: 0.046217, loss_fp: 0.001247, loss_freq: 0.005883
[17:20:39.709] iteration 29912: loss: 0.034081, loss_s1: 0.014444, loss_fp: 0.002295, loss_freq: 0.014151
[17:20:40.358] iteration 29913: loss: 0.053223, loss_s1: 0.031378, loss_fp: 0.001867, loss_freq: 0.033495
[17:20:40.985] iteration 29914: loss: 0.046155, loss_s1: 0.030135, loss_fp: 0.001289, loss_freq: 0.021817
[17:20:41.610] iteration 29915: loss: 0.038341, loss_s1: 0.032341, loss_fp: 0.003140, loss_freq: 0.003872
[17:20:42.234] iteration 29916: loss: 0.054294, loss_s1: 0.035020, loss_fp: 0.000953, loss_freq: 0.034046
[17:20:42.870] iteration 29917: loss: 0.050330, loss_s1: 0.014995, loss_fp: 0.003786, loss_freq: 0.027378
[17:20:43.512] iteration 29918: loss: 0.045049, loss_s1: 0.028492, loss_fp: 0.004798, loss_freq: 0.024716
[17:20:44.139] iteration 29919: loss: 0.050534, loss_s1: 0.041312, loss_fp: 0.003050, loss_freq: 0.009897
[17:20:44.768] iteration 29920: loss: 0.133421, loss_s1: 0.168629, loss_fp: 0.018345, loss_freq: 0.045884
[17:20:45.392] iteration 29921: loss: 0.071087, loss_s1: 0.072998, loss_fp: 0.007424, loss_freq: 0.030011
[17:20:46.016] iteration 29922: loss: 0.056163, loss_s1: 0.048721, loss_fp: 0.002718, loss_freq: 0.019078
[17:20:46.644] iteration 29923: loss: 0.050029, loss_s1: 0.056119, loss_fp: 0.000820, loss_freq: 0.009427
[17:20:47.268] iteration 29924: loss: 0.061414, loss_s1: 0.046212, loss_fp: 0.004128, loss_freq: 0.031664
[17:20:47.887] iteration 29925: loss: 0.031527, loss_s1: 0.013342, loss_fp: 0.002103, loss_freq: 0.016727
[17:20:48.511] iteration 29926: loss: 0.081598, loss_s1: 0.082724, loss_fp: 0.004551, loss_freq: 0.033116
[17:20:49.142] iteration 29927: loss: 0.038833, loss_s1: 0.032776, loss_fp: 0.003115, loss_freq: 0.011072
[17:20:49.768] iteration 29928: loss: 0.079882, loss_s1: 0.054141, loss_fp: 0.002779, loss_freq: 0.017565
[17:20:50.393] iteration 29929: loss: 0.052957, loss_s1: 0.061214, loss_fp: 0.004632, loss_freq: 0.014968
[17:20:51.019] iteration 29930: loss: 0.062128, loss_s1: 0.026766, loss_fp: 0.001540, loss_freq: 0.012537
[17:20:51.641] iteration 29931: loss: 0.064745, loss_s1: 0.046073, loss_fp: 0.004337, loss_freq: 0.045503
[17:20:52.269] iteration 29932: loss: 0.059370, loss_s1: 0.039566, loss_fp: 0.003254, loss_freq: 0.003934
[17:20:52.893] iteration 29933: loss: 0.063656, loss_s1: 0.066270, loss_fp: 0.001201, loss_freq: 0.029048
[17:20:53.520] iteration 29934: loss: 0.049052, loss_s1: 0.025954, loss_fp: 0.001857, loss_freq: 0.033342
[17:20:54.146] iteration 29935: loss: 0.044757, loss_s1: 0.030900, loss_fp: 0.003292, loss_freq: 0.022428
[17:20:54.776] iteration 29936: loss: 0.044175, loss_s1: 0.042091, loss_fp: 0.004547, loss_freq: 0.012383
[17:20:55.407] iteration 29937: loss: 0.031937, loss_s1: 0.006555, loss_fp: 0.008938, loss_freq: 0.010032
[17:20:56.038] iteration 29938: loss: 0.052765, loss_s1: 0.043475, loss_fp: 0.005249, loss_freq: 0.020316
[17:20:56.661] iteration 29939: loss: 0.046773, loss_s1: 0.015772, loss_fp: 0.001905, loss_freq: 0.035242
[17:20:57.281] iteration 29940: loss: 0.043571, loss_s1: 0.029650, loss_fp: 0.002115, loss_freq: 0.016120
[17:20:57.906] iteration 29941: loss: 0.060110, loss_s1: 0.052959, loss_fp: 0.003084, loss_freq: 0.040284
[17:20:58.531] iteration 29942: loss: 0.027991, loss_s1: 0.012877, loss_fp: 0.002434, loss_freq: 0.012503
[17:20:59.153] iteration 29943: loss: 0.058041, loss_s1: 0.038627, loss_fp: 0.000811, loss_freq: 0.023127
[17:20:59.773] iteration 29944: loss: 0.055200, loss_s1: 0.044307, loss_fp: 0.007385, loss_freq: 0.029007
[17:21:00.401] iteration 29945: loss: 0.030846, loss_s1: 0.017427, loss_fp: 0.002818, loss_freq: 0.014022
[17:21:01.016] iteration 29946: loss: 0.068743, loss_s1: 0.029021, loss_fp: 0.006408, loss_freq: 0.071891
[17:21:01.641] iteration 29947: loss: 0.062146, loss_s1: 0.056720, loss_fp: 0.002109, loss_freq: 0.028682
[17:21:02.265] iteration 29948: loss: 0.050828, loss_s1: 0.018967, loss_fp: 0.003934, loss_freq: 0.013619
[17:21:02.885] iteration 29949: loss: 0.058449, loss_s1: 0.064935, loss_fp: 0.001619, loss_freq: 0.013905
[17:21:03.511] iteration 29950: loss: 0.089515, loss_s1: 0.032964, loss_fp: 0.008010, loss_freq: 0.098597
[17:21:04.140] iteration 29951: loss: 0.042821, loss_s1: 0.028268, loss_fp: 0.001643, loss_freq: 0.017308
[17:21:04.819] iteration 29952: loss: 0.060300, loss_s1: 0.044447, loss_fp: 0.010229, loss_freq: 0.012143
[17:21:05.488] iteration 29953: loss: 0.029876, loss_s1: 0.020745, loss_fp: 0.002968, loss_freq: 0.008396
[17:21:06.157] iteration 29954: loss: 0.058827, loss_s1: 0.046850, loss_fp: 0.002057, loss_freq: 0.024165
[17:21:06.786] iteration 29955: loss: 0.038777, loss_s1: 0.032980, loss_fp: 0.001866, loss_freq: 0.013791
[17:21:07.416] iteration 29956: loss: 0.031359, loss_s1: 0.009178, loss_fp: 0.002960, loss_freq: 0.007445
[17:21:08.040] iteration 29957: loss: 0.049459, loss_s1: 0.015718, loss_fp: 0.005568, loss_freq: 0.008910
[17:21:08.673] iteration 29958: loss: 0.031462, loss_s1: 0.013519, loss_fp: 0.002101, loss_freq: 0.017128
[17:21:09.293] iteration 29959: loss: 0.058956, loss_s1: 0.053903, loss_fp: 0.005111, loss_freq: 0.016478
[17:21:09.942] iteration 29960: loss: 0.054423, loss_s1: 0.024488, loss_fp: 0.003943, loss_freq: 0.049070
[17:21:10.656] iteration 29961: loss: 0.094717, loss_s1: 0.049384, loss_fp: 0.008759, loss_freq: 0.090922
[17:21:11.315] iteration 29962: loss: 0.049655, loss_s1: 0.026630, loss_fp: 0.003919, loss_freq: 0.036618
[17:21:11.972] iteration 29963: loss: 0.043984, loss_s1: 0.032936, loss_fp: 0.000793, loss_freq: 0.008978
[17:21:12.638] iteration 29964: loss: 0.077239, loss_s1: 0.079412, loss_fp: 0.007257, loss_freq: 0.037552
[17:21:13.282] iteration 29965: loss: 0.047177, loss_s1: 0.039966, loss_fp: 0.001599, loss_freq: 0.009472
[17:21:13.917] iteration 29966: loss: 0.049490, loss_s1: 0.032155, loss_fp: 0.004739, loss_freq: 0.023770
[17:21:14.561] iteration 29967: loss: 0.081582, loss_s1: 0.051252, loss_fp: 0.012980, loss_freq: 0.043159
[17:21:15.208] iteration 29968: loss: 0.056677, loss_s1: 0.031488, loss_fp: 0.002241, loss_freq: 0.035458
[17:21:15.835] iteration 29969: loss: 0.048664, loss_s1: 0.036388, loss_fp: 0.002452, loss_freq: 0.019902
[17:21:16.481] iteration 29970: loss: 0.042237, loss_s1: 0.024023, loss_fp: 0.005043, loss_freq: 0.020966
[17:21:17.121] iteration 29971: loss: 0.052924, loss_s1: 0.053232, loss_fp: 0.002477, loss_freq: 0.021532
[17:21:17.756] iteration 29972: loss: 0.044633, loss_s1: 0.028287, loss_fp: 0.006534, loss_freq: 0.019797
[17:21:18.388] iteration 29973: loss: 0.052524, loss_s1: 0.039740, loss_fp: 0.003992, loss_freq: 0.031493
[17:21:19.014] iteration 29974: loss: 0.036191, loss_s1: 0.008463, loss_fp: 0.001245, loss_freq: 0.008177
[17:21:19.637] iteration 29975: loss: 0.024105, loss_s1: 0.007738, loss_fp: 0.001684, loss_freq: 0.009020
[17:21:20.283] iteration 29976: loss: 0.034201, loss_s1: 0.028884, loss_fp: 0.000689, loss_freq: 0.009646
[17:21:20.935] iteration 29977: loss: 0.063118, loss_s1: 0.066361, loss_fp: 0.012470, loss_freq: 0.013423
[17:21:21.587] iteration 29978: loss: 0.061475, loss_s1: 0.030877, loss_fp: 0.002921, loss_freq: 0.017991
[17:21:22.235] iteration 29979: loss: 0.043617, loss_s1: 0.029986, loss_fp: 0.002126, loss_freq: 0.026294
[17:21:22.897] iteration 29980: loss: 0.044743, loss_s1: 0.050275, loss_fp: 0.000902, loss_freq: 0.002959
[17:21:23.551] iteration 29981: loss: 0.041041, loss_s1: 0.032635, loss_fp: 0.000976, loss_freq: 0.003381
[17:21:24.199] iteration 29982: loss: 0.032706, loss_s1: 0.011181, loss_fp: 0.004502, loss_freq: 0.010138
[17:21:24.847] iteration 29983: loss: 0.052169, loss_s1: 0.054247, loss_fp: 0.000642, loss_freq: 0.007235
[17:21:25.497] iteration 29984: loss: 0.080379, loss_s1: 0.077191, loss_fp: 0.006701, loss_freq: 0.035682
[17:21:26.138] iteration 29985: loss: 0.030951, loss_s1: 0.012793, loss_fp: 0.001264, loss_freq: 0.012315
[17:21:26.776] iteration 29986: loss: 0.050565, loss_s1: 0.022124, loss_fp: 0.014664, loss_freq: 0.009860
[17:21:27.402] iteration 29987: loss: 0.046844, loss_s1: 0.023001, loss_fp: 0.007350, loss_freq: 0.027348
[17:21:28.037] iteration 29988: loss: 0.081317, loss_s1: 0.092027, loss_fp: 0.007975, loss_freq: 0.025924
[17:21:28.670] iteration 29989: loss: 0.062093, loss_s1: 0.041859, loss_fp: 0.004910, loss_freq: 0.027109
[17:21:29.298] iteration 29990: loss: 0.078854, loss_s1: 0.087505, loss_fp: 0.005561, loss_freq: 0.039927
[17:21:29.931] iteration 29991: loss: 0.052905, loss_s1: 0.059635, loss_fp: 0.002796, loss_freq: 0.011335
[17:21:30.563] iteration 29992: loss: 0.043826, loss_s1: 0.012952, loss_fp: 0.004653, loss_freq: 0.008648
[17:21:31.228] iteration 29993: loss: 0.046684, loss_s1: 0.026254, loss_fp: 0.001532, loss_freq: 0.030753
[17:21:31.852] iteration 29994: loss: 0.064287, loss_s1: 0.039822, loss_fp: 0.002806, loss_freq: 0.050293
[17:21:32.471] iteration 29995: loss: 0.033171, loss_s1: 0.015463, loss_fp: 0.005386, loss_freq: 0.017953
[17:21:33.096] iteration 29996: loss: 0.066349, loss_s1: 0.057422, loss_fp: 0.004347, loss_freq: 0.027558
[17:21:33.720] iteration 29997: loss: 0.073022, loss_s1: 0.049034, loss_fp: 0.005931, loss_freq: 0.062436
[17:21:34.343] iteration 29998: loss: 0.085996, loss_s1: 0.045029, loss_fp: 0.005351, loss_freq: 0.021456
[17:21:34.969] iteration 29999: loss: 0.043056, loss_s1: 0.020693, loss_fp: 0.003698, loss_freq: 0.031375
[17:21:35.600] iteration 30000: loss: 0.047137, loss_s1: 0.039448, loss_fp: 0.000855, loss_freq: 0.006147
[17:21:39.070] iteration 30000 : mean_dice : 0.800814
